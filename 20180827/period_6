Files already downloaded and verified
USE 1 GPUs!
Epoch: 0 | Batch_idx: 0 |  Loss: (2.3084) |  Loss2: (0.0000) | Acc: (10.00%) (13/128)
Epoch: 0 | Batch_idx: 10 |  Loss: (2.3077) |  Loss2: (0.0000) | Acc: (10.00%) (144/1408)
Epoch: 0 | Batch_idx: 20 |  Loss: (2.3010) |  Loss2: (0.0000) | Acc: (11.00%) (315/2688)
Epoch: 0 | Batch_idx: 30 |  Loss: (2.2936) |  Loss2: (0.0000) | Acc: (13.00%) (553/3968)
Epoch: 0 | Batch_idx: 40 |  Loss: (2.2859) |  Loss2: (0.0000) | Acc: (15.00%) (827/5248)
Epoch: 0 | Batch_idx: 50 |  Loss: (2.2774) |  Loss2: (0.0000) | Acc: (16.00%) (1109/6528)
Epoch: 0 | Batch_idx: 60 |  Loss: (2.2684) |  Loss2: (0.0000) | Acc: (17.00%) (1385/7808)
Epoch: 0 | Batch_idx: 70 |  Loss: (2.2594) |  Loss2: (0.0000) | Acc: (18.00%) (1662/9088)
Epoch: 0 | Batch_idx: 80 |  Loss: (2.2493) |  Loss2: (0.0000) | Acc: (18.00%) (1963/10368)
Epoch: 0 | Batch_idx: 90 |  Loss: (2.2408) |  Loss2: (0.0000) | Acc: (19.00%) (2273/11648)
Epoch: 0 | Batch_idx: 100 |  Loss: (2.2316) |  Loss2: (0.0000) | Acc: (19.00%) (2580/12928)
Epoch: 0 | Batch_idx: 110 |  Loss: (2.2210) |  Loss2: (0.0000) | Acc: (20.00%) (2893/14208)
Epoch: 0 | Batch_idx: 120 |  Loss: (2.2114) |  Loss2: (0.0000) | Acc: (20.00%) (3201/15488)
Epoch: 0 | Batch_idx: 130 |  Loss: (2.2025) |  Loss2: (0.0000) | Acc: (20.00%) (3506/16768)
Epoch: 0 | Batch_idx: 140 |  Loss: (2.1924) |  Loss2: (0.0000) | Acc: (21.00%) (3842/18048)
Epoch: 0 | Batch_idx: 150 |  Loss: (2.1837) |  Loss2: (0.0000) | Acc: (21.00%) (4180/19328)
Epoch: 0 | Batch_idx: 160 |  Loss: (2.1734) |  Loss2: (0.0000) | Acc: (22.00%) (4555/20608)
Epoch: 0 | Batch_idx: 170 |  Loss: (2.1646) |  Loss2: (0.0000) | Acc: (22.00%) (4921/21888)
Epoch: 0 | Batch_idx: 180 |  Loss: (2.1554) |  Loss2: (0.0000) | Acc: (22.00%) (5281/23168)
Epoch: 0 | Batch_idx: 190 |  Loss: (2.1473) |  Loss2: (0.0000) | Acc: (23.00%) (5645/24448)
Epoch: 0 | Batch_idx: 200 |  Loss: (2.1390) |  Loss2: (0.0000) | Acc: (23.00%) (6018/25728)
Epoch: 0 | Batch_idx: 210 |  Loss: (2.1300) |  Loss2: (0.0000) | Acc: (23.00%) (6421/27008)
Epoch: 0 | Batch_idx: 220 |  Loss: (2.1224) |  Loss2: (0.0000) | Acc: (23.00%) (6768/28288)
Epoch: 0 | Batch_idx: 230 |  Loss: (2.1151) |  Loss2: (0.0000) | Acc: (24.00%) (7169/29568)
Epoch: 0 | Batch_idx: 240 |  Loss: (2.1073) |  Loss2: (0.0000) | Acc: (24.00%) (7544/30848)
Epoch: 0 | Batch_idx: 250 |  Loss: (2.0993) |  Loss2: (0.0000) | Acc: (24.00%) (7938/32128)
Epoch: 0 | Batch_idx: 260 |  Loss: (2.0916) |  Loss2: (0.0000) | Acc: (24.00%) (8335/33408)
Epoch: 0 | Batch_idx: 270 |  Loss: (2.0854) |  Loss2: (0.0000) | Acc: (25.00%) (8698/34688)
Epoch: 0 | Batch_idx: 280 |  Loss: (2.0790) |  Loss2: (0.0000) | Acc: (25.00%) (9063/35968)
Epoch: 0 | Batch_idx: 290 |  Loss: (2.0725) |  Loss2: (0.0000) | Acc: (25.00%) (9470/37248)
Epoch: 0 | Batch_idx: 300 |  Loss: (2.0658) |  Loss2: (0.0000) | Acc: (25.00%) (9870/38528)
Epoch: 0 | Batch_idx: 310 |  Loss: (2.0591) |  Loss2: (0.0000) | Acc: (25.00%) (10302/39808)
Epoch: 0 | Batch_idx: 320 |  Loss: (2.0535) |  Loss2: (0.0000) | Acc: (26.00%) (10689/41088)
Epoch: 0 | Batch_idx: 330 |  Loss: (2.0477) |  Loss2: (0.0000) | Acc: (26.00%) (11078/42368)
Epoch: 0 | Batch_idx: 340 |  Loss: (2.0418) |  Loss2: (0.0000) | Acc: (26.00%) (11504/43648)
Epoch: 0 | Batch_idx: 350 |  Loss: (2.0365) |  Loss2: (0.0000) | Acc: (26.00%) (11934/44928)
Epoch: 0 | Batch_idx: 360 |  Loss: (2.0306) |  Loss2: (0.0000) | Acc: (26.00%) (12364/46208)
Epoch: 0 | Batch_idx: 370 |  Loss: (2.0254) |  Loss2: (0.0000) | Acc: (26.00%) (12754/47488)
Epoch: 0 | Batch_idx: 380 |  Loss: (2.0197) |  Loss2: (0.0000) | Acc: (27.00%) (13216/48768)
Epoch: 0 | Batch_idx: 390 |  Loss: (2.0138) |  Loss2: (0.0000) | Acc: (27.00%) (13623/50000)
/usr/local/lib/python3.6/dist-packages/torch/serialization.py:241: UserWarning: Couldn't retrieve source code for container of type ResNet. It won't be checked for correctness upon loading.
  "type " + obj.__name__ + ". It won't be checked "
/usr/local/lib/python3.6/dist-packages/torch/serialization.py:241: UserWarning: Couldn't retrieve source code for container of type BasicBlock. It won't be checked for correctness upon loading.
  "type " + obj.__name__ + ". It won't be checked "
/usr/local/lib/python3.6/dist-packages/torch/serialization.py:241: UserWarning: Couldn't retrieve source code for container of type _Gate. It won't be checked for correctness upon loading.
  "type " + obj.__name__ + ". It won't be checked "
=> saving checkpoint 'drive/app/torch/save_Schedule/checkpoint_000.pth.tar'
# TEST : Loss: (1.7803) | Acc: (33.00%) (3388/10000)
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 3, 3, 3]) tensor(165.5304, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(770.2573, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(765.6991, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([128, 64, 3, 3]) tensor(1531.7700, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([128, 64, 1, 1]) tensor(511.4232, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([128, 128, 3, 3]) tensor(2173.3867, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([256, 128, 3, 3]) tensor(4344.0913, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([256, 128, 1, 1]) tensor(1447.8434, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([256, 256, 3, 3]) tensor(6147.1606, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([512, 256, 3, 3]) tensor(12278.0371, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([512, 256, 1, 1]) tensor(4090.2266, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([512, 512, 3, 3]) tensor(17371.2832, device='cuda:0', grad_fn=<NormBackward0>)
Epoch: 1 | Batch_idx: 0 |  Loss: (1.8023) |  Loss2: (0.0000) | Acc: (30.00%) (39/128)
Epoch: 1 | Batch_idx: 10 |  Loss: (1.7941) |  Loss2: (0.0000) | Acc: (35.00%) (498/1408)
Epoch: 1 | Batch_idx: 20 |  Loss: (1.7993) |  Loss2: (0.0000) | Acc: (34.00%) (937/2688)
Epoch: 1 | Batch_idx: 30 |  Loss: (1.7960) |  Loss2: (0.0000) | Acc: (34.00%) (1374/3968)
Epoch: 1 | Batch_idx: 40 |  Loss: (1.7918) |  Loss2: (0.0000) | Acc: (34.00%) (1821/5248)
Epoch: 1 | Batch_idx: 50 |  Loss: (1.7903) |  Loss2: (0.0000) | Acc: (34.00%) (2264/6528)
Epoch: 1 | Batch_idx: 60 |  Loss: (1.7855) |  Loss2: (0.0000) | Acc: (34.00%) (2719/7808)
Epoch: 1 | Batch_idx: 70 |  Loss: (1.7828) |  Loss2: (0.0000) | Acc: (34.00%) (3169/9088)
Epoch: 1 | Batch_idx: 80 |  Loss: (1.7800) |  Loss2: (0.0000) | Acc: (35.00%) (3639/10368)
Epoch: 1 | Batch_idx: 90 |  Loss: (1.7776) |  Loss2: (0.0000) | Acc: (35.00%) (4100/11648)
Epoch: 1 | Batch_idx: 100 |  Loss: (1.7740) |  Loss2: (0.0000) | Acc: (35.00%) (4562/12928)
Epoch: 1 | Batch_idx: 110 |  Loss: (1.7695) |  Loss2: (0.0000) | Acc: (35.00%) (5066/14208)
Epoch: 1 | Batch_idx: 120 |  Loss: (1.7663) |  Loss2: (0.0000) | Acc: (35.00%) (5502/15488)
Epoch: 1 | Batch_idx: 130 |  Loss: (1.7622) |  Loss2: (0.0000) | Acc: (35.00%) (5983/16768)
Epoch: 1 | Batch_idx: 140 |  Loss: (1.7590) |  Loss2: (0.0000) | Acc: (35.00%) (6451/18048)
Epoch: 1 | Batch_idx: 150 |  Loss: (1.7552) |  Loss2: (0.0000) | Acc: (35.00%) (6937/19328)
Epoch: 1 | Batch_idx: 160 |  Loss: (1.7528) |  Loss2: (0.0000) | Acc: (35.00%) (7386/20608)
Epoch: 1 | Batch_idx: 170 |  Loss: (1.7497) |  Loss2: (0.0000) | Acc: (36.00%) (7882/21888)
Epoch: 1 | Batch_idx: 180 |  Loss: (1.7467) |  Loss2: (0.0000) | Acc: (36.00%) (8350/23168)
Epoch: 1 | Batch_idx: 190 |  Loss: (1.7436) |  Loss2: (0.0000) | Acc: (36.00%) (8828/24448)
Epoch: 1 | Batch_idx: 200 |  Loss: (1.7411) |  Loss2: (0.0000) | Acc: (36.00%) (9323/25728)
Epoch: 1 | Batch_idx: 210 |  Loss: (1.7377) |  Loss2: (0.0000) | Acc: (36.00%) (9835/27008)
Epoch: 1 | Batch_idx: 220 |  Loss: (1.7347) |  Loss2: (0.0000) | Acc: (36.00%) (10339/28288)
Epoch: 1 | Batch_idx: 230 |  Loss: (1.7319) |  Loss2: (0.0000) | Acc: (36.00%) (10837/29568)
Epoch: 1 | Batch_idx: 240 |  Loss: (1.7290) |  Loss2: (0.0000) | Acc: (36.00%) (11330/30848)
Epoch: 1 | Batch_idx: 250 |  Loss: (1.7266) |  Loss2: (0.0000) | Acc: (36.00%) (11810/32128)
Epoch: 1 | Batch_idx: 260 |  Loss: (1.7238) |  Loss2: (0.0000) | Acc: (36.00%) (12333/33408)
Epoch: 1 | Batch_idx: 270 |  Loss: (1.7203) |  Loss2: (0.0000) | Acc: (37.00%) (12854/34688)
Epoch: 1 | Batch_idx: 280 |  Loss: (1.7173) |  Loss2: (0.0000) | Acc: (37.00%) (13380/35968)
Epoch: 1 | Batch_idx: 290 |  Loss: (1.7145) |  Loss2: (0.0000) | Acc: (37.00%) (13896/37248)
Epoch: 1 | Batch_idx: 300 |  Loss: (1.7112) |  Loss2: (0.0000) | Acc: (37.00%) (14415/38528)
Epoch: 1 | Batch_idx: 310 |  Loss: (1.7086) |  Loss2: (0.0000) | Acc: (37.00%) (14911/39808)
Epoch: 1 | Batch_idx: 320 |  Loss: (1.7061) |  Loss2: (0.0000) | Acc: (37.00%) (15413/41088)
Epoch: 1 | Batch_idx: 330 |  Loss: (1.7034) |  Loss2: (0.0000) | Acc: (37.00%) (15908/42368)
Epoch: 1 | Batch_idx: 340 |  Loss: (1.7011) |  Loss2: (0.0000) | Acc: (37.00%) (16406/43648)
Epoch: 1 | Batch_idx: 350 |  Loss: (1.6985) |  Loss2: (0.0000) | Acc: (37.00%) (16923/44928)
Epoch: 1 | Batch_idx: 360 |  Loss: (1.6961) |  Loss2: (0.0000) | Acc: (37.00%) (17416/46208)
Epoch: 1 | Batch_idx: 370 |  Loss: (1.6950) |  Loss2: (0.0000) | Acc: (37.00%) (17931/47488)
Epoch: 1 | Batch_idx: 380 |  Loss: (1.6931) |  Loss2: (0.0000) | Acc: (37.00%) (18441/48768)
Epoch: 1 | Batch_idx: 390 |  Loss: (1.6909) |  Loss2: (0.0000) | Acc: (37.00%) (18928/50000)
# TEST : Loss: (1.6441) | Acc: (36.00%) (3697/10000)
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
Epoch: 2 | Batch_idx: 0 |  Loss: (1.6022) |  Loss2: (0.0000) | Acc: (35.00%) (45/128)
Epoch: 2 | Batch_idx: 10 |  Loss: (1.5859) |  Loss2: (0.0000) | Acc: (41.00%) (585/1408)
Epoch: 2 | Batch_idx: 20 |  Loss: (1.5913) |  Loss2: (0.0000) | Acc: (40.00%) (1098/2688)
Epoch: 2 | Batch_idx: 30 |  Loss: (1.5880) |  Loss2: (0.0000) | Acc: (40.00%) (1620/3968)
Epoch: 2 | Batch_idx: 40 |  Loss: (1.5877) |  Loss2: (0.0000) | Acc: (40.00%) (2150/5248)
Epoch: 2 | Batch_idx: 50 |  Loss: (1.5919) |  Loss2: (0.0000) | Acc: (40.00%) (2662/6528)
Epoch: 2 | Batch_idx: 60 |  Loss: (1.5864) |  Loss2: (0.0000) | Acc: (40.00%) (3199/7808)
Epoch: 2 | Batch_idx: 70 |  Loss: (1.5860) |  Loss2: (0.0000) | Acc: (41.00%) (3742/9088)
Epoch: 2 | Batch_idx: 80 |  Loss: (1.5871) |  Loss2: (0.0000) | Acc: (41.00%) (4284/10368)
Epoch: 2 | Batch_idx: 90 |  Loss: (1.5813) |  Loss2: (0.0000) | Acc: (41.00%) (4849/11648)
Epoch: 2 | Batch_idx: 100 |  Loss: (1.5754) |  Loss2: (0.0000) | Acc: (41.00%) (5405/12928)
Epoch: 2 | Batch_idx: 110 |  Loss: (1.5725) |  Loss2: (0.0000) | Acc: (41.00%) (5932/14208)
Epoch: 2 | Batch_idx: 120 |  Loss: (1.5730) |  Loss2: (0.0000) | Acc: (41.00%) (6483/15488)
Epoch: 2 | Batch_idx: 130 |  Loss: (1.5710) |  Loss2: (0.0000) | Acc: (41.00%) (7023/16768)
Epoch: 2 | Batch_idx: 140 |  Loss: (1.5687) |  Loss2: (0.0000) | Acc: (42.00%) (7606/18048)
Epoch: 2 | Batch_idx: 150 |  Loss: (1.5661) |  Loss2: (0.0000) | Acc: (42.00%) (8172/19328)
Epoch: 2 | Batch_idx: 160 |  Loss: (1.5647) |  Loss2: (0.0000) | Acc: (42.00%) (8728/20608)
Epoch: 2 | Batch_idx: 170 |  Loss: (1.5627) |  Loss2: (0.0000) | Acc: (42.00%) (9286/21888)
Epoch: 2 | Batch_idx: 180 |  Loss: (1.5606) |  Loss2: (0.0000) | Acc: (42.00%) (9857/23168)
Epoch: 2 | Batch_idx: 190 |  Loss: (1.5601) |  Loss2: (0.0000) | Acc: (42.00%) (10403/24448)
Epoch: 2 | Batch_idx: 200 |  Loss: (1.5569) |  Loss2: (0.0000) | Acc: (42.00%) (10984/25728)
Epoch: 2 | Batch_idx: 210 |  Loss: (1.5552) |  Loss2: (0.0000) | Acc: (42.00%) (11544/27008)
Epoch: 2 | Batch_idx: 220 |  Loss: (1.5532) |  Loss2: (0.0000) | Acc: (42.00%) (12123/28288)
Epoch: 2 | Batch_idx: 230 |  Loss: (1.5507) |  Loss2: (0.0000) | Acc: (42.00%) (12698/29568)
Epoch: 2 | Batch_idx: 240 |  Loss: (1.5492) |  Loss2: (0.0000) | Acc: (42.00%) (13252/30848)
Epoch: 2 | Batch_idx: 250 |  Loss: (1.5473) |  Loss2: (0.0000) | Acc: (43.00%) (13823/32128)
Epoch: 2 | Batch_idx: 260 |  Loss: (1.5445) |  Loss2: (0.0000) | Acc: (43.00%) (14427/33408)
Epoch: 2 | Batch_idx: 270 |  Loss: (1.5421) |  Loss2: (0.0000) | Acc: (43.00%) (15009/34688)
Epoch: 2 | Batch_idx: 280 |  Loss: (1.5404) |  Loss2: (0.0000) | Acc: (43.00%) (15582/35968)
Epoch: 2 | Batch_idx: 290 |  Loss: (1.5390) |  Loss2: (0.0000) | Acc: (43.00%) (16168/37248)
Epoch: 2 | Batch_idx: 300 |  Loss: (1.5369) |  Loss2: (0.0000) | Acc: (43.00%) (16755/38528)
Epoch: 2 | Batch_idx: 310 |  Loss: (1.5352) |  Loss2: (0.0000) | Acc: (43.00%) (17339/39808)
Epoch: 2 | Batch_idx: 320 |  Loss: (1.5338) |  Loss2: (0.0000) | Acc: (43.00%) (17957/41088)
Epoch: 2 | Batch_idx: 330 |  Loss: (1.5315) |  Loss2: (0.0000) | Acc: (43.00%) (18550/42368)
Epoch: 2 | Batch_idx: 340 |  Loss: (1.5302) |  Loss2: (0.0000) | Acc: (43.00%) (19120/43648)
Epoch: 2 | Batch_idx: 350 |  Loss: (1.5276) |  Loss2: (0.0000) | Acc: (43.00%) (19728/44928)
Epoch: 2 | Batch_idx: 360 |  Loss: (1.5257) |  Loss2: (0.0000) | Acc: (43.00%) (20322/46208)
Epoch: 2 | Batch_idx: 370 |  Loss: (1.5233) |  Loss2: (0.0000) | Acc: (44.00%) (20944/47488)
Epoch: 2 | Batch_idx: 380 |  Loss: (1.5224) |  Loss2: (0.0000) | Acc: (44.00%) (21539/48768)
Epoch: 2 | Batch_idx: 390 |  Loss: (1.5213) |  Loss2: (0.0000) | Acc: (44.00%) (22084/50000)
# TEST : Loss: (1.4249) | Acc: (47.00%) (4732/10000)
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
Epoch: 3 | Batch_idx: 0 |  Loss: (1.5620) |  Loss2: (0.0000) | Acc: (45.00%) (58/128)
Epoch: 3 | Batch_idx: 10 |  Loss: (1.4628) |  Loss2: (0.0000) | Acc: (49.00%) (695/1408)
Epoch: 3 | Batch_idx: 20 |  Loss: (1.4457) |  Loss2: (0.0000) | Acc: (49.00%) (1324/2688)
Epoch: 3 | Batch_idx: 30 |  Loss: (1.4386) |  Loss2: (0.0000) | Acc: (49.00%) (1945/3968)
Epoch: 3 | Batch_idx: 40 |  Loss: (1.4405) |  Loss2: (0.0000) | Acc: (48.00%) (2550/5248)
Epoch: 3 | Batch_idx: 50 |  Loss: (1.4361) |  Loss2: (0.0000) | Acc: (48.00%) (3178/6528)
Epoch: 3 | Batch_idx: 60 |  Loss: (1.4330) |  Loss2: (0.0000) | Acc: (48.00%) (3813/7808)
Epoch: 3 | Batch_idx: 70 |  Loss: (1.4290) |  Loss2: (0.0000) | Acc: (48.00%) (4430/9088)
Epoch: 3 | Batch_idx: 80 |  Loss: (1.4219) |  Loss2: (0.0000) | Acc: (49.00%) (5094/10368)
Epoch: 3 | Batch_idx: 90 |  Loss: (1.4188) |  Loss2: (0.0000) | Acc: (49.00%) (5714/11648)
Epoch: 3 | Batch_idx: 100 |  Loss: (1.4204) |  Loss2: (0.0000) | Acc: (49.00%) (6346/12928)
Epoch: 3 | Batch_idx: 110 |  Loss: (1.4177) |  Loss2: (0.0000) | Acc: (48.00%) (6959/14208)
Epoch: 3 | Batch_idx: 120 |  Loss: (1.4174) |  Loss2: (0.0000) | Acc: (48.00%) (7558/15488)
Epoch: 3 | Batch_idx: 130 |  Loss: (1.4153) |  Loss2: (0.0000) | Acc: (48.00%) (8206/16768)
Epoch: 3 | Batch_idx: 140 |  Loss: (1.4135) |  Loss2: (0.0000) | Acc: (48.00%) (8840/18048)
Epoch: 3 | Batch_idx: 150 |  Loss: (1.4116) |  Loss2: (0.0000) | Acc: (48.00%) (9457/19328)
Epoch: 3 | Batch_idx: 160 |  Loss: (1.4074) |  Loss2: (0.0000) | Acc: (49.00%) (10107/20608)
Epoch: 3 | Batch_idx: 170 |  Loss: (1.4057) |  Loss2: (0.0000) | Acc: (49.00%) (10755/21888)
Epoch: 3 | Batch_idx: 180 |  Loss: (1.4025) |  Loss2: (0.0000) | Acc: (49.00%) (11412/23168)
Epoch: 3 | Batch_idx: 190 |  Loss: (1.3986) |  Loss2: (0.0000) | Acc: (49.00%) (12086/24448)
Epoch: 3 | Batch_idx: 200 |  Loss: (1.3977) |  Loss2: (0.0000) | Acc: (49.00%) (12726/25728)
Epoch: 3 | Batch_idx: 210 |  Loss: (1.3955) |  Loss2: (0.0000) | Acc: (49.00%) (13395/27008)
Epoch: 3 | Batch_idx: 220 |  Loss: (1.3957) |  Loss2: (0.0000) | Acc: (49.00%) (14008/28288)
Epoch: 3 | Batch_idx: 230 |  Loss: (1.3966) |  Loss2: (0.0000) | Acc: (49.00%) (14638/29568)
Epoch: 3 | Batch_idx: 240 |  Loss: (1.3951) |  Loss2: (0.0000) | Acc: (49.00%) (15279/30848)
Epoch: 3 | Batch_idx: 250 |  Loss: (1.3926) |  Loss2: (0.0000) | Acc: (49.00%) (15940/32128)
Epoch: 3 | Batch_idx: 260 |  Loss: (1.3915) |  Loss2: (0.0000) | Acc: (49.00%) (16595/33408)
Epoch: 3 | Batch_idx: 270 |  Loss: (1.3905) |  Loss2: (0.0000) | Acc: (49.00%) (17238/34688)
Epoch: 3 | Batch_idx: 280 |  Loss: (1.3895) |  Loss2: (0.0000) | Acc: (49.00%) (17900/35968)
Epoch: 3 | Batch_idx: 290 |  Loss: (1.3867) |  Loss2: (0.0000) | Acc: (49.00%) (18573/37248)
Epoch: 3 | Batch_idx: 300 |  Loss: (1.3852) |  Loss2: (0.0000) | Acc: (49.00%) (19233/38528)
Epoch: 3 | Batch_idx: 310 |  Loss: (1.3839) |  Loss2: (0.0000) | Acc: (49.00%) (19897/39808)
Epoch: 3 | Batch_idx: 320 |  Loss: (1.3833) |  Loss2: (0.0000) | Acc: (50.00%) (20553/41088)
Epoch: 3 | Batch_idx: 330 |  Loss: (1.3814) |  Loss2: (0.0000) | Acc: (50.00%) (21229/42368)
Epoch: 3 | Batch_idx: 340 |  Loss: (1.3798) |  Loss2: (0.0000) | Acc: (50.00%) (21898/43648)
Epoch: 3 | Batch_idx: 350 |  Loss: (1.3783) |  Loss2: (0.0000) | Acc: (50.00%) (22546/44928)
Epoch: 3 | Batch_idx: 360 |  Loss: (1.3763) |  Loss2: (0.0000) | Acc: (50.00%) (23228/46208)
Epoch: 3 | Batch_idx: 370 |  Loss: (1.3751) |  Loss2: (0.0000) | Acc: (50.00%) (23868/47488)
Epoch: 3 | Batch_idx: 380 |  Loss: (1.3732) |  Loss2: (0.0000) | Acc: (50.00%) (24532/48768)
Epoch: 3 | Batch_idx: 390 |  Loss: (1.3714) |  Loss2: (0.0000) | Acc: (50.00%) (25182/50000)
# TEST : Loss: (1.3222) | Acc: (52.00%) (5211/10000)
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
Epoch: 4 | Batch_idx: 0 |  Loss: (1.3500) |  Loss2: (0.0000) | Acc: (51.00%) (66/128)
Epoch: 4 | Batch_idx: 10 |  Loss: (1.2974) |  Loss2: (0.0000) | Acc: (52.00%) (742/1408)
Epoch: 4 | Batch_idx: 20 |  Loss: (1.2926) |  Loss2: (0.0000) | Acc: (52.00%) (1421/2688)
Epoch: 4 | Batch_idx: 30 |  Loss: (1.3060) |  Loss2: (0.0000) | Acc: (52.00%) (2086/3968)
Epoch: 4 | Batch_idx: 40 |  Loss: (1.3012) |  Loss2: (0.0000) | Acc: (52.00%) (2780/5248)
Epoch: 4 | Batch_idx: 50 |  Loss: (1.2874) |  Loss2: (0.0000) | Acc: (53.00%) (3491/6528)
Epoch: 4 | Batch_idx: 60 |  Loss: (1.2899) |  Loss2: (0.0000) | Acc: (53.00%) (4169/7808)
Epoch: 4 | Batch_idx: 70 |  Loss: (1.2882) |  Loss2: (0.0000) | Acc: (53.00%) (4858/9088)
Epoch: 4 | Batch_idx: 80 |  Loss: (1.2860) |  Loss2: (0.0000) | Acc: (53.00%) (5551/10368)
Epoch: 4 | Batch_idx: 90 |  Loss: (1.2848) |  Loss2: (0.0000) | Acc: (53.00%) (6270/11648)
Epoch: 4 | Batch_idx: 100 |  Loss: (1.2837) |  Loss2: (0.0000) | Acc: (54.00%) (6984/12928)
Epoch: 4 | Batch_idx: 110 |  Loss: (1.2841) |  Loss2: (0.0000) | Acc: (54.00%) (7681/14208)
Epoch: 4 | Batch_idx: 120 |  Loss: (1.2837) |  Loss2: (0.0000) | Acc: (54.00%) (8370/15488)
Epoch: 4 | Batch_idx: 130 |  Loss: (1.2835) |  Loss2: (0.0000) | Acc: (54.00%) (9059/16768)
Epoch: 4 | Batch_idx: 140 |  Loss: (1.2800) |  Loss2: (0.0000) | Acc: (54.00%) (9762/18048)
Epoch: 4 | Batch_idx: 150 |  Loss: (1.2774) |  Loss2: (0.0000) | Acc: (54.00%) (10454/19328)
Epoch: 4 | Batch_idx: 160 |  Loss: (1.2744) |  Loss2: (0.0000) | Acc: (54.00%) (11173/20608)
Epoch: 4 | Batch_idx: 170 |  Loss: (1.2749) |  Loss2: (0.0000) | Acc: (54.00%) (11860/21888)
Epoch: 4 | Batch_idx: 180 |  Loss: (1.2725) |  Loss2: (0.0000) | Acc: (54.00%) (12574/23168)
Epoch: 4 | Batch_idx: 190 |  Loss: (1.2730) |  Loss2: (0.0000) | Acc: (54.00%) (13273/24448)
Epoch: 4 | Batch_idx: 200 |  Loss: (1.2716) |  Loss2: (0.0000) | Acc: (54.00%) (13990/25728)
Epoch: 4 | Batch_idx: 210 |  Loss: (1.2702) |  Loss2: (0.0000) | Acc: (54.00%) (14714/27008)
Epoch: 4 | Batch_idx: 220 |  Loss: (1.2693) |  Loss2: (0.0000) | Acc: (54.00%) (15410/28288)
Epoch: 4 | Batch_idx: 230 |  Loss: (1.2682) |  Loss2: (0.0000) | Acc: (54.00%) (16153/29568)
Epoch: 4 | Batch_idx: 240 |  Loss: (1.2660) |  Loss2: (0.0000) | Acc: (54.00%) (16876/30848)
Epoch: 4 | Batch_idx: 250 |  Loss: (1.2641) |  Loss2: (0.0000) | Acc: (54.00%) (17583/32128)
Epoch: 4 | Batch_idx: 260 |  Loss: (1.2631) |  Loss2: (0.0000) | Acc: (54.00%) (18288/33408)
Epoch: 4 | Batch_idx: 270 |  Loss: (1.2627) |  Loss2: (0.0000) | Acc: (54.00%) (18999/34688)
Epoch: 4 | Batch_idx: 280 |  Loss: (1.2612) |  Loss2: (0.0000) | Acc: (54.00%) (19729/35968)
Epoch: 4 | Batch_idx: 290 |  Loss: (1.2602) |  Loss2: (0.0000) | Acc: (54.00%) (20463/37248)
Epoch: 4 | Batch_idx: 300 |  Loss: (1.2599) |  Loss2: (0.0000) | Acc: (54.00%) (21179/38528)
Epoch: 4 | Batch_idx: 310 |  Loss: (1.2572) |  Loss2: (0.0000) | Acc: (55.00%) (21937/39808)
Epoch: 4 | Batch_idx: 320 |  Loss: (1.2559) |  Loss2: (0.0000) | Acc: (55.00%) (22665/41088)
Epoch: 4 | Batch_idx: 330 |  Loss: (1.2546) |  Loss2: (0.0000) | Acc: (55.00%) (23401/42368)
Epoch: 4 | Batch_idx: 340 |  Loss: (1.2541) |  Loss2: (0.0000) | Acc: (55.00%) (24122/43648)
Epoch: 4 | Batch_idx: 350 |  Loss: (1.2533) |  Loss2: (0.0000) | Acc: (55.00%) (24839/44928)
Epoch: 4 | Batch_idx: 360 |  Loss: (1.2518) |  Loss2: (0.0000) | Acc: (55.00%) (25578/46208)
Epoch: 4 | Batch_idx: 370 |  Loss: (1.2508) |  Loss2: (0.0000) | Acc: (55.00%) (26306/47488)
Epoch: 4 | Batch_idx: 380 |  Loss: (1.2497) |  Loss2: (0.0000) | Acc: (55.00%) (27020/48768)
Epoch: 4 | Batch_idx: 390 |  Loss: (1.2482) |  Loss2: (0.0000) | Acc: (55.00%) (27730/50000)
# TEST : Loss: (1.3308) | Acc: (52.00%) (5256/10000)
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
Epoch: 5 | Batch_idx: 0 |  Loss: (1.1637) |  Loss2: (0.0000) | Acc: (60.00%) (77/128)
Epoch: 5 | Batch_idx: 10 |  Loss: (1.1940) |  Loss2: (0.0000) | Acc: (57.00%) (804/1408)
Epoch: 5 | Batch_idx: 20 |  Loss: (1.2061) |  Loss2: (0.0000) | Acc: (56.00%) (1516/2688)
Epoch: 5 | Batch_idx: 30 |  Loss: (1.1788) |  Loss2: (0.0000) | Acc: (57.00%) (2287/3968)
Epoch: 5 | Batch_idx: 40 |  Loss: (1.1728) |  Loss2: (0.0000) | Acc: (57.00%) (3023/5248)
Epoch: 5 | Batch_idx: 50 |  Loss: (1.1805) |  Loss2: (0.0000) | Acc: (57.00%) (3737/6528)
Epoch: 5 | Batch_idx: 60 |  Loss: (1.1810) |  Loss2: (0.0000) | Acc: (57.00%) (4471/7808)
Epoch: 5 | Batch_idx: 70 |  Loss: (1.1843) |  Loss2: (0.0000) | Acc: (57.00%) (5194/9088)
Epoch: 5 | Batch_idx: 80 |  Loss: (1.1847) |  Loss2: (0.0000) | Acc: (57.00%) (5946/10368)
Epoch: 5 | Batch_idx: 90 |  Loss: (1.1855) |  Loss2: (0.0000) | Acc: (57.00%) (6674/11648)
Epoch: 5 | Batch_idx: 100 |  Loss: (1.1848) |  Loss2: (0.0000) | Acc: (57.00%) (7423/12928)
Epoch: 5 | Batch_idx: 110 |  Loss: (1.1810) |  Loss2: (0.0000) | Acc: (57.00%) (8171/14208)
Epoch: 5 | Batch_idx: 120 |  Loss: (1.1745) |  Loss2: (0.0000) | Acc: (57.00%) (8939/15488)
Epoch: 5 | Batch_idx: 130 |  Loss: (1.1731) |  Loss2: (0.0000) | Acc: (57.00%) (9686/16768)
Epoch: 5 | Batch_idx: 140 |  Loss: (1.1682) |  Loss2: (0.0000) | Acc: (57.00%) (10458/18048)
Epoch: 5 | Batch_idx: 150 |  Loss: (1.1673) |  Loss2: (0.0000) | Acc: (58.00%) (11224/19328)
Epoch: 5 | Batch_idx: 160 |  Loss: (1.1665) |  Loss2: (0.0000) | Acc: (58.00%) (11975/20608)
Epoch: 5 | Batch_idx: 170 |  Loss: (1.1658) |  Loss2: (0.0000) | Acc: (58.00%) (12709/21888)
Epoch: 5 | Batch_idx: 180 |  Loss: (1.1658) |  Loss2: (0.0000) | Acc: (58.00%) (13460/23168)
Epoch: 5 | Batch_idx: 190 |  Loss: (1.1625) |  Loss2: (0.0000) | Acc: (58.00%) (14239/24448)
Epoch: 5 | Batch_idx: 200 |  Loss: (1.1638) |  Loss2: (0.0000) | Acc: (58.00%) (14958/25728)
Epoch: 5 | Batch_idx: 210 |  Loss: (1.1611) |  Loss2: (0.0000) | Acc: (58.00%) (15730/27008)
Epoch: 5 | Batch_idx: 220 |  Loss: (1.1611) |  Loss2: (0.0000) | Acc: (58.00%) (16493/28288)
Epoch: 5 | Batch_idx: 230 |  Loss: (1.1607) |  Loss2: (0.0000) | Acc: (58.00%) (17259/29568)
Epoch: 5 | Batch_idx: 240 |  Loss: (1.1591) |  Loss2: (0.0000) | Acc: (58.00%) (18034/30848)
Epoch: 5 | Batch_idx: 250 |  Loss: (1.1590) |  Loss2: (0.0000) | Acc: (58.00%) (18787/32128)
Epoch: 5 | Batch_idx: 260 |  Loss: (1.1576) |  Loss2: (0.0000) | Acc: (58.00%) (19570/33408)
Epoch: 5 | Batch_idx: 270 |  Loss: (1.1566) |  Loss2: (0.0000) | Acc: (58.00%) (20338/34688)
Epoch: 5 | Batch_idx: 280 |  Loss: (1.1544) |  Loss2: (0.0000) | Acc: (58.00%) (21119/35968)
Epoch: 5 | Batch_idx: 290 |  Loss: (1.1538) |  Loss2: (0.0000) | Acc: (58.00%) (21903/37248)
Epoch: 5 | Batch_idx: 300 |  Loss: (1.1529) |  Loss2: (0.0000) | Acc: (58.00%) (22656/38528)
Epoch: 5 | Batch_idx: 310 |  Loss: (1.1511) |  Loss2: (0.0000) | Acc: (58.00%) (23436/39808)
Epoch: 5 | Batch_idx: 320 |  Loss: (1.1499) |  Loss2: (0.0000) | Acc: (58.00%) (24227/41088)
Epoch: 5 | Batch_idx: 330 |  Loss: (1.1492) |  Loss2: (0.0000) | Acc: (58.00%) (24983/42368)
Epoch: 5 | Batch_idx: 340 |  Loss: (1.1477) |  Loss2: (0.0000) | Acc: (59.00%) (25766/43648)
Epoch: 5 | Batch_idx: 350 |  Loss: (1.1474) |  Loss2: (0.0000) | Acc: (59.00%) (26513/44928)
Epoch: 5 | Batch_idx: 360 |  Loss: (1.1455) |  Loss2: (0.0000) | Acc: (59.00%) (27303/46208)
Epoch: 5 | Batch_idx: 370 |  Loss: (1.1444) |  Loss2: (0.0000) | Acc: (59.00%) (28083/47488)
Epoch: 5 | Batch_idx: 380 |  Loss: (1.1421) |  Loss2: (0.0000) | Acc: (59.00%) (28887/48768)
Epoch: 5 | Batch_idx: 390 |  Loss: (1.1410) |  Loss2: (0.0000) | Acc: (59.00%) (29638/50000)
=> saving checkpoint 'drive/app/torch/save_Schedule/checkpoint_005.pth.tar'
# TEST : Loss: (1.1079) | Acc: (60.00%) (6027/10000)
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
False Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=128, out_features=16, bias=False)
True Linear(in_features=16, out_features=2, bias=False)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=128, out_features=16, bias=False)
True Linear(in_features=16, out_features=2, bias=False)
False Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=256, out_features=32, bias=False)
True Linear(in_features=32, out_features=2, bias=False)
False Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=256, out_features=32, bias=False)
True Linear(in_features=32, out_features=2, bias=False)
False Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=512, out_features=64, bias=False)
True Linear(in_features=64, out_features=2, bias=False)
False Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=512, out_features=64, bias=False)
True Linear(in_features=64, out_features=2, bias=False)
False Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1024, out_features=128, bias=False)
True Linear(in_features=128, out_features=2, bias=False)
False Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1024, out_features=128, bias=False)
True Linear(in_features=128, out_features=2, bias=False)
False Linear(in_features=512, out_features=10, bias=True)
Epoch: 6 | Batch_idx: 0 |  Loss: (1.0510) |  Loss2: (0.0000) | Acc: (60.00%) (78/128)
Epoch: 6 | Batch_idx: 10 |  Loss: (1.1466) |  Loss2: (0.0000) | Acc: (59.00%) (836/1408)
Epoch: 6 | Batch_idx: 20 |  Loss: (1.1417) |  Loss2: (0.0000) | Acc: (59.00%) (1591/2688)
Epoch: 6 | Batch_idx: 30 |  Loss: (1.1638) |  Loss2: (0.0000) | Acc: (58.00%) (2305/3968)
Epoch: 6 | Batch_idx: 40 |  Loss: (1.1719) |  Loss2: (0.0000) | Acc: (57.00%) (3035/5248)
Epoch: 6 | Batch_idx: 50 |  Loss: (1.1650) |  Loss2: (0.0000) | Acc: (58.00%) (3794/6528)
Epoch: 6 | Batch_idx: 60 |  Loss: (1.1703) |  Loss2: (0.0000) | Acc: (58.00%) (4534/7808)
Epoch: 6 | Batch_idx: 70 |  Loss: (1.1700) |  Loss2: (0.0000) | Acc: (58.00%) (5273/9088)
Epoch: 6 | Batch_idx: 80 |  Loss: (1.1607) |  Loss2: (0.0000) | Acc: (58.00%) (6044/10368)
Epoch: 6 | Batch_idx: 90 |  Loss: (1.1560) |  Loss2: (0.0000) | Acc: (58.00%) (6833/11648)
Epoch: 6 | Batch_idx: 100 |  Loss: (1.1539) |  Loss2: (0.0000) | Acc: (58.00%) (7589/12928)
Epoch: 6 | Batch_idx: 110 |  Loss: (1.1541) |  Loss2: (0.0000) | Acc: (58.00%) (8342/14208)
Epoch: 6 | Batch_idx: 120 |  Loss: (1.1513) |  Loss2: (0.0000) | Acc: (58.00%) (9137/15488)
Epoch: 6 | Batch_idx: 130 |  Loss: (1.1501) |  Loss2: (0.0000) | Acc: (59.00%) (9902/16768)
Epoch: 6 | Batch_idx: 140 |  Loss: (1.1485) |  Loss2: (0.0000) | Acc: (59.00%) (10675/18048)
Epoch: 6 | Batch_idx: 150 |  Loss: (1.1444) |  Loss2: (0.0000) | Acc: (59.00%) (11461/19328)
Epoch: 6 | Batch_idx: 160 |  Loss: (1.1457) |  Loss2: (0.0000) | Acc: (59.00%) (12204/20608)
Epoch: 6 | Batch_idx: 170 |  Loss: (1.1450) |  Loss2: (0.0000) | Acc: (59.00%) (12968/21888)
Epoch: 6 | Batch_idx: 180 |  Loss: (1.1426) |  Loss2: (0.0000) | Acc: (59.00%) (13752/23168)
Epoch: 6 | Batch_idx: 190 |  Loss: (1.1428) |  Loss2: (0.0000) | Acc: (59.00%) (14506/24448)
Epoch: 6 | Batch_idx: 200 |  Loss: (1.1427) |  Loss2: (0.0000) | Acc: (59.00%) (15271/25728)
Epoch: 6 | Batch_idx: 210 |  Loss: (1.1419) |  Loss2: (0.0000) | Acc: (59.00%) (16035/27008)
Epoch: 6 | Batch_idx: 220 |  Loss: (1.1405) |  Loss2: (0.0000) | Acc: (59.00%) (16779/28288)
Epoch: 6 | Batch_idx: 230 |  Loss: (1.1409) |  Loss2: (0.0000) | Acc: (59.00%) (17534/29568)
Epoch: 6 | Batch_idx: 240 |  Loss: (1.1398) |  Loss2: (0.0000) | Acc: (59.00%) (18310/30848)
Epoch: 6 | Batch_idx: 250 |  Loss: (1.1398) |  Loss2: (0.0000) | Acc: (59.00%) (19070/32128)
Epoch: 6 | Batch_idx: 260 |  Loss: (1.1371) |  Loss2: (0.0000) | Acc: (59.00%) (19862/33408)
Epoch: 6 | Batch_idx: 270 |  Loss: (1.1356) |  Loss2: (0.0000) | Acc: (59.00%) (20663/34688)
Epoch: 6 | Batch_idx: 280 |  Loss: (1.1369) |  Loss2: (0.0000) | Acc: (59.00%) (21431/35968)
Epoch: 6 | Batch_idx: 290 |  Loss: (1.1358) |  Loss2: (0.0000) | Acc: (59.00%) (22196/37248)
Epoch: 6 | Batch_idx: 300 |  Loss: (1.1352) |  Loss2: (0.0000) | Acc: (59.00%) (22951/38528)
Epoch: 6 | Batch_idx: 310 |  Loss: (1.1343) |  Loss2: (0.0000) | Acc: (59.00%) (23713/39808)
Epoch: 6 | Batch_idx: 320 |  Loss: (1.1343) |  Loss2: (0.0000) | Acc: (59.00%) (24473/41088)
Epoch: 6 | Batch_idx: 330 |  Loss: (1.1320) |  Loss2: (0.0000) | Acc: (59.00%) (25268/42368)
Epoch: 6 | Batch_idx: 340 |  Loss: (1.1320) |  Loss2: (0.0000) | Acc: (59.00%) (26022/43648)
Epoch: 6 | Batch_idx: 350 |  Loss: (1.1331) |  Loss2: (0.0000) | Acc: (59.00%) (26762/44928)
Epoch: 6 | Batch_idx: 360 |  Loss: (1.1322) |  Loss2: (0.0000) | Acc: (59.00%) (27536/46208)
Epoch: 6 | Batch_idx: 370 |  Loss: (1.1319) |  Loss2: (0.0000) | Acc: (59.00%) (28298/47488)
Epoch: 6 | Batch_idx: 380 |  Loss: (1.1299) |  Loss2: (0.0000) | Acc: (59.00%) (29114/48768)
Epoch: 6 | Batch_idx: 390 |  Loss: (1.1295) |  Loss2: (0.0000) | Acc: (59.00%) (29866/50000)
# TEST : Loss: (1.1042) | Acc: (60.00%) (6055/10000)
percent tensor([0.4998, 0.4990, 0.5000, 0.4999, 0.5000, 0.4996, 0.4996, 0.4999, 0.4998,
        0.4995, 0.4993, 0.4999, 0.4997, 0.4990, 0.4994, 0.4995],
       device='cuda:0') torch.Size([16])
percent tensor([0.4984, 0.4974, 0.4963, 0.4974, 0.4967, 0.4995, 0.4971, 0.4967, 0.4977,
        0.4969, 0.4982, 0.4964, 0.4982, 0.4980, 0.4982, 0.4984],
       device='cuda:0') torch.Size([16])
percent tensor([0.4951, 0.4900, 0.4933, 0.4977, 0.4945, 0.4988, 0.4911, 0.4941, 0.4945,
        0.4904, 0.4906, 0.4917, 0.4927, 0.4953, 0.4933, 0.4953],
       device='cuda:0') torch.Size([16])
percent tensor([0.5018, 0.5018, 0.5019, 0.5015, 0.5020, 0.5008, 0.5023, 0.5025, 0.5020,
        0.5021, 0.5022, 0.5021, 0.5021, 0.5018, 0.5018, 0.5016],
       device='cuda:0') torch.Size([16])
percent tensor([0.5135, 0.5106, 0.5267, 0.5255, 0.5280, 0.5154, 0.5154, 0.5312, 0.5118,
        0.5120, 0.5085, 0.5235, 0.5088, 0.5083, 0.5135, 0.5169],
       device='cuda:0') torch.Size([16])
percent tensor([0.5083, 0.5077, 0.5169, 0.5167, 0.5169, 0.5090, 0.5093, 0.5199, 0.5085,
        0.5090, 0.5067, 0.5124, 0.5070, 0.5065, 0.5111, 0.5097],
       device='cuda:0') torch.Size([16])
percent tensor([0.4993, 0.5031, 0.5094, 0.5066, 0.5074, 0.4898, 0.5047, 0.5106, 0.5038,
        0.5057, 0.5021, 0.5063, 0.4987, 0.5006, 0.5023, 0.4997],
       device='cuda:0') torch.Size([16])
percent tensor([0.5884, 0.5665, 0.6005, 0.6112, 0.6277, 0.6036, 0.5803, 0.6458, 0.5873,
        0.6033, 0.5890, 0.5868, 0.5970, 0.5887, 0.6060, 0.6235],
       device='cuda:0') torch.Size([16])
Epoch: 7 | Batch_idx: 0 |  Loss: (1.1231) |  Loss2: (0.0000) | Acc: (62.00%) (80/128)
Epoch: 7 | Batch_idx: 10 |  Loss: (1.1231) |  Loss2: (0.0000) | Acc: (58.00%) (826/1408)
Epoch: 7 | Batch_idx: 20 |  Loss: (1.0964) |  Loss2: (0.0000) | Acc: (60.00%) (1616/2688)
Epoch: 7 | Batch_idx: 30 |  Loss: (1.0877) |  Loss2: (0.0000) | Acc: (60.00%) (2413/3968)
Epoch: 7 | Batch_idx: 40 |  Loss: (1.0934) |  Loss2: (0.0000) | Acc: (60.00%) (3192/5248)
Epoch: 7 | Batch_idx: 50 |  Loss: (1.0896) |  Loss2: (0.0000) | Acc: (60.00%) (3976/6528)
Epoch: 7 | Batch_idx: 60 |  Loss: (1.0883) |  Loss2: (0.0000) | Acc: (61.00%) (4770/7808)
Epoch: 7 | Batch_idx: 70 |  Loss: (1.0881) |  Loss2: (0.0000) | Acc: (61.00%) (5547/9088)
Epoch: 7 | Batch_idx: 80 |  Loss: (1.0936) |  Loss2: (0.0000) | Acc: (60.00%) (6282/10368)
Epoch: 7 | Batch_idx: 90 |  Loss: (1.0944) |  Loss2: (0.0000) | Acc: (60.00%) (7059/11648)
Epoch: 7 | Batch_idx: 100 |  Loss: (1.0899) |  Loss2: (0.0000) | Acc: (60.00%) (7846/12928)
Epoch: 7 | Batch_idx: 110 |  Loss: (1.0924) |  Loss2: (0.0000) | Acc: (60.00%) (8587/14208)
Epoch: 7 | Batch_idx: 120 |  Loss: (1.0940) |  Loss2: (0.0000) | Acc: (60.00%) (9350/15488)
Epoch: 7 | Batch_idx: 130 |  Loss: (1.0910) |  Loss2: (0.0000) | Acc: (60.00%) (10144/16768)
Epoch: 7 | Batch_idx: 140 |  Loss: (1.0976) |  Loss2: (0.0000) | Acc: (60.00%) (10838/18048)
Epoch: 7 | Batch_idx: 150 |  Loss: (1.0997) |  Loss2: (0.0000) | Acc: (60.00%) (11613/19328)
Epoch: 7 | Batch_idx: 160 |  Loss: (1.1013) |  Loss2: (0.0000) | Acc: (60.00%) (12370/20608)
Epoch: 7 | Batch_idx: 170 |  Loss: (1.1006) |  Loss2: (0.0000) | Acc: (60.00%) (13152/21888)
Epoch: 7 | Batch_idx: 180 |  Loss: (1.0998) |  Loss2: (0.0000) | Acc: (60.00%) (13929/23168)
Epoch: 7 | Batch_idx: 190 |  Loss: (1.0972) |  Loss2: (0.0000) | Acc: (60.00%) (14716/24448)
Epoch: 7 | Batch_idx: 200 |  Loss: (1.0966) |  Loss2: (0.0000) | Acc: (60.00%) (15509/25728)
Epoch: 7 | Batch_idx: 210 |  Loss: (1.0936) |  Loss2: (0.0000) | Acc: (60.00%) (16304/27008)
Epoch: 7 | Batch_idx: 220 |  Loss: (1.0924) |  Loss2: (0.0000) | Acc: (60.00%) (17079/28288)
Epoch: 7 | Batch_idx: 230 |  Loss: (1.0936) |  Loss2: (0.0000) | Acc: (60.00%) (17847/29568)
Epoch: 7 | Batch_idx: 240 |  Loss: (1.0959) |  Loss2: (0.0000) | Acc: (60.00%) (18612/30848)
Epoch: 7 | Batch_idx: 250 |  Loss: (1.0946) |  Loss2: (0.0000) | Acc: (60.00%) (19394/32128)
Epoch: 7 | Batch_idx: 260 |  Loss: (1.0943) |  Loss2: (0.0000) | Acc: (60.00%) (20189/33408)
Epoch: 7 | Batch_idx: 270 |  Loss: (1.0936) |  Loss2: (0.0000) | Acc: (60.00%) (20968/34688)
Epoch: 7 | Batch_idx: 280 |  Loss: (1.0927) |  Loss2: (0.0000) | Acc: (60.00%) (21743/35968)
Epoch: 7 | Batch_idx: 290 |  Loss: (1.0915) |  Loss2: (0.0000) | Acc: (60.00%) (22527/37248)
Epoch: 7 | Batch_idx: 300 |  Loss: (1.0913) |  Loss2: (0.0000) | Acc: (60.00%) (23292/38528)
Epoch: 7 | Batch_idx: 310 |  Loss: (1.0900) |  Loss2: (0.0000) | Acc: (60.00%) (24109/39808)
Epoch: 7 | Batch_idx: 320 |  Loss: (1.0891) |  Loss2: (0.0000) | Acc: (60.00%) (24901/41088)
Epoch: 7 | Batch_idx: 330 |  Loss: (1.0888) |  Loss2: (0.0000) | Acc: (60.00%) (25696/42368)
Epoch: 7 | Batch_idx: 340 |  Loss: (1.0891) |  Loss2: (0.0000) | Acc: (60.00%) (26460/43648)
Epoch: 7 | Batch_idx: 350 |  Loss: (1.0887) |  Loss2: (0.0000) | Acc: (60.00%) (27231/44928)
Epoch: 7 | Batch_idx: 360 |  Loss: (1.0880) |  Loss2: (0.0000) | Acc: (60.00%) (27996/46208)
Epoch: 7 | Batch_idx: 370 |  Loss: (1.0868) |  Loss2: (0.0000) | Acc: (60.00%) (28820/47488)
Epoch: 7 | Batch_idx: 380 |  Loss: (1.0872) |  Loss2: (0.0000) | Acc: (60.00%) (29616/48768)
Epoch: 7 | Batch_idx: 390 |  Loss: (1.0876) |  Loss2: (0.0000) | Acc: (60.00%) (30370/50000)
# TEST : Loss: (1.0852) | Acc: (61.00%) (6117/10000)
percent tensor([0.4998, 0.4982, 0.4998, 0.4998, 0.4997, 0.5000, 0.4991, 0.4995, 0.4994,
        0.4988, 0.4989, 0.4997, 0.4993, 0.4982, 0.4991, 0.4993],
       device='cuda:0') torch.Size([16])
percent tensor([0.4984, 0.4975, 0.4954, 0.4969, 0.4959, 0.5000, 0.4967, 0.4960, 0.4973,
        0.4967, 0.4983, 0.4957, 0.4982, 0.4979, 0.4985, 0.4985],
       device='cuda:0') torch.Size([16])
percent tensor([0.4947, 0.4836, 0.4918, 0.5004, 0.4939, 0.5047, 0.4857, 0.4924, 0.4915,
        0.4842, 0.4850, 0.4880, 0.4889, 0.4918, 0.4921, 0.4951],
       device='cuda:0') torch.Size([16])
percent tensor([0.5054, 0.5054, 0.5040, 0.5034, 0.5045, 0.5033, 0.5058, 0.5057, 0.5051,
        0.5056, 0.5063, 0.5048, 0.5061, 0.5053, 0.5053, 0.5049],
       device='cuda:0') torch.Size([16])
percent tensor([0.5214, 0.5179, 0.5474, 0.5452, 0.5498, 0.5233, 0.5264, 0.5541, 0.5212,
        0.5206, 0.5140, 0.5413, 0.5138, 0.5138, 0.5217, 0.5272],
       device='cuda:0') torch.Size([16])
percent tensor([0.5149, 0.5135, 0.5278, 0.5276, 0.5281, 0.5159, 0.5161, 0.5320, 0.5149,
        0.5154, 0.5121, 0.5204, 0.5129, 0.5120, 0.5187, 0.5173],
       device='cuda:0') torch.Size([16])
percent tensor([0.4993, 0.5045, 0.5158, 0.5115, 0.5124, 0.4834, 0.5074, 0.5172, 0.5062,
        0.5091, 0.5036, 0.5106, 0.4973, 0.5009, 0.5027, 0.5005],
       device='cuda:0') torch.Size([16])
percent tensor([0.7035, 0.6500, 0.7181, 0.7342, 0.7685, 0.7130, 0.6854, 0.7988, 0.6848,
        0.7279, 0.6902, 0.6920, 0.7034, 0.6924, 0.7282, 0.7710],
       device='cuda:0') torch.Size([16])
Epoch: 8 | Batch_idx: 0 |  Loss: (1.0345) |  Loss2: (0.0000) | Acc: (62.00%) (80/128)
Epoch: 8 | Batch_idx: 10 |  Loss: (1.0442) |  Loss2: (0.0000) | Acc: (62.00%) (873/1408)
Epoch: 8 | Batch_idx: 20 |  Loss: (1.0758) |  Loss2: (0.0000) | Acc: (61.00%) (1652/2688)
Epoch: 8 | Batch_idx: 30 |  Loss: (1.0616) |  Loss2: (0.0000) | Acc: (62.00%) (2473/3968)
Epoch: 8 | Batch_idx: 40 |  Loss: (1.0654) |  Loss2: (0.0000) | Acc: (61.00%) (3245/5248)
Epoch: 8 | Batch_idx: 50 |  Loss: (1.0675) |  Loss2: (0.0000) | Acc: (61.00%) (4022/6528)
Epoch: 8 | Batch_idx: 60 |  Loss: (1.0678) |  Loss2: (0.0000) | Acc: (61.00%) (4804/7808)
Epoch: 8 | Batch_idx: 70 |  Loss: (1.0682) |  Loss2: (0.0000) | Acc: (61.00%) (5593/9088)
Epoch: 8 | Batch_idx: 80 |  Loss: (1.0634) |  Loss2: (0.0000) | Acc: (61.00%) (6401/10368)
Epoch: 8 | Batch_idx: 90 |  Loss: (1.0628) |  Loss2: (0.0000) | Acc: (61.00%) (7182/11648)
Epoch: 8 | Batch_idx: 100 |  Loss: (1.0654) |  Loss2: (0.0000) | Acc: (61.00%) (7947/12928)
Epoch: 8 | Batch_idx: 110 |  Loss: (1.0701) |  Loss2: (0.0000) | Acc: (61.00%) (8706/14208)
Epoch: 8 | Batch_idx: 120 |  Loss: (1.0665) |  Loss2: (0.0000) | Acc: (61.00%) (9523/15488)
Epoch: 8 | Batch_idx: 130 |  Loss: (1.0624) |  Loss2: (0.0000) | Acc: (61.00%) (10339/16768)
Epoch: 8 | Batch_idx: 140 |  Loss: (1.0634) |  Loss2: (0.0000) | Acc: (61.00%) (11117/18048)
Epoch: 8 | Batch_idx: 150 |  Loss: (1.0648) |  Loss2: (0.0000) | Acc: (61.00%) (11899/19328)
Epoch: 8 | Batch_idx: 160 |  Loss: (1.0664) |  Loss2: (0.0000) | Acc: (61.00%) (12675/20608)
Epoch: 8 | Batch_idx: 170 |  Loss: (1.0651) |  Loss2: (0.0000) | Acc: (61.00%) (13469/21888)
Epoch: 8 | Batch_idx: 180 |  Loss: (1.0639) |  Loss2: (0.0000) | Acc: (61.00%) (14258/23168)
Epoch: 8 | Batch_idx: 190 |  Loss: (1.0621) |  Loss2: (0.0000) | Acc: (61.00%) (15084/24448)
Epoch: 8 | Batch_idx: 200 |  Loss: (1.0623) |  Loss2: (0.0000) | Acc: (61.00%) (15874/25728)
Epoch: 8 | Batch_idx: 210 |  Loss: (1.0631) |  Loss2: (0.0000) | Acc: (61.00%) (16655/27008)
Epoch: 8 | Batch_idx: 220 |  Loss: (1.0665) |  Loss2: (0.0000) | Acc: (61.00%) (17409/28288)
Epoch: 8 | Batch_idx: 230 |  Loss: (1.0683) |  Loss2: (0.0000) | Acc: (61.00%) (18184/29568)
Epoch: 8 | Batch_idx: 240 |  Loss: (1.0674) |  Loss2: (0.0000) | Acc: (61.00%) (18983/30848)
Epoch: 8 | Batch_idx: 250 |  Loss: (1.0669) |  Loss2: (0.0000) | Acc: (61.00%) (19778/32128)
Epoch: 8 | Batch_idx: 260 |  Loss: (1.0661) |  Loss2: (0.0000) | Acc: (61.00%) (20585/33408)
Epoch: 8 | Batch_idx: 270 |  Loss: (1.0665) |  Loss2: (0.0000) | Acc: (61.00%) (21350/34688)
Epoch: 8 | Batch_idx: 280 |  Loss: (1.0656) |  Loss2: (0.0000) | Acc: (61.00%) (22148/35968)
Epoch: 8 | Batch_idx: 290 |  Loss: (1.0656) |  Loss2: (0.0000) | Acc: (61.00%) (22934/37248)
Epoch: 8 | Batch_idx: 300 |  Loss: (1.0664) |  Loss2: (0.0000) | Acc: (61.00%) (23727/38528)
Epoch: 8 | Batch_idx: 310 |  Loss: (1.0658) |  Loss2: (0.0000) | Acc: (61.00%) (24511/39808)
Epoch: 8 | Batch_idx: 320 |  Loss: (1.0658) |  Loss2: (0.0000) | Acc: (61.00%) (25298/41088)
Epoch: 8 | Batch_idx: 330 |  Loss: (1.0647) |  Loss2: (0.0000) | Acc: (61.00%) (26109/42368)
Epoch: 8 | Batch_idx: 340 |  Loss: (1.0651) |  Loss2: (0.0000) | Acc: (61.00%) (26892/43648)
Epoch: 8 | Batch_idx: 350 |  Loss: (1.0650) |  Loss2: (0.0000) | Acc: (61.00%) (27698/44928)
Epoch: 8 | Batch_idx: 360 |  Loss: (1.0654) |  Loss2: (0.0000) | Acc: (61.00%) (28465/46208)
Epoch: 8 | Batch_idx: 370 |  Loss: (1.0645) |  Loss2: (0.0000) | Acc: (61.00%) (29276/47488)
Epoch: 8 | Batch_idx: 380 |  Loss: (1.0644) |  Loss2: (0.0000) | Acc: (61.00%) (30041/48768)
Epoch: 8 | Batch_idx: 390 |  Loss: (1.0639) |  Loss2: (0.0000) | Acc: (61.00%) (30820/50000)
# TEST : Loss: (1.0758) | Acc: (61.00%) (6163/10000)
percent tensor([0.4999, 0.4980, 0.4999, 0.4999, 0.4998, 0.5005, 0.4991, 0.4996, 0.4995,
        0.4987, 0.4989, 0.4997, 0.4994, 0.4978, 0.4992, 0.4993],
       device='cuda:0') torch.Size([16])
percent tensor([0.4989, 0.4986, 0.4956, 0.4974, 0.4962, 0.5008, 0.4974, 0.4964, 0.4977,
        0.4976, 0.4992, 0.4963, 0.4989, 0.4986, 0.4995, 0.4993],
       device='cuda:0') torch.Size([16])
percent tensor([0.4979, 0.4824, 0.4962, 0.5068, 0.4988, 0.5152, 0.4858, 0.4957, 0.4917,
        0.4826, 0.4837, 0.4899, 0.4884, 0.4910, 0.4965, 0.4991],
       device='cuda:0') torch.Size([16])
percent tensor([0.5097, 0.5098, 0.5067, 0.5058, 0.5077, 0.5065, 0.5101, 0.5096, 0.5089,
        0.5098, 0.5110, 0.5080, 0.5109, 0.5094, 0.5097, 0.5090],
       device='cuda:0') torch.Size([16])
percent tensor([0.5249, 0.5226, 0.5592, 0.5560, 0.5624, 0.5273, 0.5326, 0.5678, 0.5275,
        0.5254, 0.5178, 0.5513, 0.5165, 0.5176, 0.5255, 0.5329],
       device='cuda:0') torch.Size([16])
percent tensor([0.5218, 0.5193, 0.5368, 0.5369, 0.5375, 0.5235, 0.5228, 0.5426, 0.5212,
        0.5219, 0.5176, 0.5275, 0.5193, 0.5181, 0.5261, 0.5253],
       device='cuda:0') torch.Size([16])
percent tensor([0.4994, 0.5052, 0.5198, 0.5147, 0.5155, 0.4794, 0.5091, 0.5212, 0.5083,
        0.5118, 0.5047, 0.5132, 0.4970, 0.5010, 0.5023, 0.5014],
       device='cuda:0') torch.Size([16])
percent tensor([0.7564, 0.6843, 0.7666, 0.7845, 0.8194, 0.7640, 0.7293, 0.8530, 0.7246,
        0.7747, 0.7288, 0.7375, 0.7461, 0.7351, 0.7777, 0.8348],
       device='cuda:0') torch.Size([16])
Epoch: 9 | Batch_idx: 0 |  Loss: (1.0513) |  Loss2: (0.0000) | Acc: (66.00%) (85/128)
Epoch: 9 | Batch_idx: 10 |  Loss: (1.0211) |  Loss2: (0.0000) | Acc: (62.00%) (884/1408)
Epoch: 9 | Batch_idx: 20 |  Loss: (1.0396) |  Loss2: (0.0000) | Acc: (62.00%) (1671/2688)
Epoch: 9 | Batch_idx: 30 |  Loss: (1.0577) |  Loss2: (0.0000) | Acc: (61.00%) (2455/3968)
Epoch: 9 | Batch_idx: 40 |  Loss: (1.0615) |  Loss2: (0.0000) | Acc: (61.00%) (3221/5248)
Epoch: 9 | Batch_idx: 50 |  Loss: (1.0628) |  Loss2: (0.0000) | Acc: (61.00%) (4026/6528)
Epoch: 9 | Batch_idx: 60 |  Loss: (1.0622) |  Loss2: (0.0000) | Acc: (61.00%) (4819/7808)
Epoch: 9 | Batch_idx: 70 |  Loss: (1.0612) |  Loss2: (0.0000) | Acc: (61.00%) (5608/9088)
Epoch: 9 | Batch_idx: 80 |  Loss: (1.0579) |  Loss2: (0.0000) | Acc: (61.00%) (6397/10368)
Epoch: 9 | Batch_idx: 90 |  Loss: (1.0480) |  Loss2: (0.0000) | Acc: (62.00%) (7249/11648)
Epoch: 9 | Batch_idx: 100 |  Loss: (1.0518) |  Loss2: (0.0000) | Acc: (62.00%) (8022/12928)
Epoch: 9 | Batch_idx: 110 |  Loss: (1.0549) |  Loss2: (0.0000) | Acc: (61.00%) (8803/14208)
Epoch: 9 | Batch_idx: 120 |  Loss: (1.0607) |  Loss2: (0.0000) | Acc: (61.00%) (9558/15488)
Epoch: 9 | Batch_idx: 130 |  Loss: (1.0580) |  Loss2: (0.0000) | Acc: (61.00%) (10367/16768)
Epoch: 9 | Batch_idx: 140 |  Loss: (1.0566) |  Loss2: (0.0000) | Acc: (61.00%) (11155/18048)
Epoch: 9 | Batch_idx: 150 |  Loss: (1.0572) |  Loss2: (0.0000) | Acc: (61.00%) (11934/19328)
Epoch: 9 | Batch_idx: 160 |  Loss: (1.0610) |  Loss2: (0.0000) | Acc: (61.00%) (12709/20608)
Epoch: 9 | Batch_idx: 170 |  Loss: (1.0625) |  Loss2: (0.0000) | Acc: (61.00%) (13483/21888)
Epoch: 9 | Batch_idx: 180 |  Loss: (1.0635) |  Loss2: (0.0000) | Acc: (61.00%) (14266/23168)
Epoch: 9 | Batch_idx: 190 |  Loss: (1.0624) |  Loss2: (0.0000) | Acc: (61.00%) (15064/24448)
Epoch: 9 | Batch_idx: 200 |  Loss: (1.0609) |  Loss2: (0.0000) | Acc: (61.00%) (15879/25728)
Epoch: 9 | Batch_idx: 210 |  Loss: (1.0597) |  Loss2: (0.0000) | Acc: (61.00%) (16679/27008)
Epoch: 9 | Batch_idx: 220 |  Loss: (1.0620) |  Loss2: (0.0000) | Acc: (61.00%) (17460/28288)
Epoch: 9 | Batch_idx: 230 |  Loss: (1.0609) |  Loss2: (0.0000) | Acc: (61.00%) (18271/29568)
Epoch: 9 | Batch_idx: 240 |  Loss: (1.0617) |  Loss2: (0.0000) | Acc: (61.00%) (19067/30848)
Epoch: 9 | Batch_idx: 250 |  Loss: (1.0600) |  Loss2: (0.0000) | Acc: (61.00%) (19861/32128)
Epoch: 9 | Batch_idx: 260 |  Loss: (1.0599) |  Loss2: (0.0000) | Acc: (61.00%) (20648/33408)
Epoch: 9 | Batch_idx: 270 |  Loss: (1.0594) |  Loss2: (0.0000) | Acc: (61.00%) (21463/34688)
Epoch: 9 | Batch_idx: 280 |  Loss: (1.0601) |  Loss2: (0.0000) | Acc: (61.00%) (22244/35968)
Epoch: 9 | Batch_idx: 290 |  Loss: (1.0625) |  Loss2: (0.0000) | Acc: (61.00%) (23020/37248)
Epoch: 9 | Batch_idx: 300 |  Loss: (1.0617) |  Loss2: (0.0000) | Acc: (61.00%) (23818/38528)
Epoch: 9 | Batch_idx: 310 |  Loss: (1.0615) |  Loss2: (0.0000) | Acc: (61.00%) (24613/39808)
Epoch: 9 | Batch_idx: 320 |  Loss: (1.0612) |  Loss2: (0.0000) | Acc: (61.00%) (25403/41088)
Epoch: 9 | Batch_idx: 330 |  Loss: (1.0613) |  Loss2: (0.0000) | Acc: (61.00%) (26192/42368)
Epoch: 9 | Batch_idx: 340 |  Loss: (1.0610) |  Loss2: (0.0000) | Acc: (61.00%) (26986/43648)
Epoch: 9 | Batch_idx: 350 |  Loss: (1.0601) |  Loss2: (0.0000) | Acc: (61.00%) (27804/44928)
Epoch: 9 | Batch_idx: 360 |  Loss: (1.0601) |  Loss2: (0.0000) | Acc: (61.00%) (28563/46208)
Epoch: 9 | Batch_idx: 370 |  Loss: (1.0588) |  Loss2: (0.0000) | Acc: (61.00%) (29379/47488)
Epoch: 9 | Batch_idx: 380 |  Loss: (1.0575) |  Loss2: (0.0000) | Acc: (61.00%) (30174/48768)
Epoch: 9 | Batch_idx: 390 |  Loss: (1.0579) |  Loss2: (0.0000) | Acc: (61.00%) (30926/50000)
# TEST : Loss: (1.0707) | Acc: (61.00%) (6176/10000)
percent tensor([0.5002, 0.4980, 0.5002, 0.5001, 0.5001, 0.5011, 0.4993, 0.4999, 0.4997,
        0.4988, 0.4990, 0.5000, 0.4997, 0.4977, 0.4994, 0.4994],
       device='cuda:0') torch.Size([16])
percent tensor([0.4988, 0.4987, 0.4947, 0.4969, 0.4955, 0.5012, 0.4972, 0.4958, 0.4973,
        0.4975, 0.4993, 0.4957, 0.4988, 0.4986, 0.4997, 0.4994],
       device='cuda:0') torch.Size([16])
percent tensor([0.5010, 0.4821, 0.5001, 0.5125, 0.5034, 0.5251, 0.4864, 0.4985, 0.4924,
        0.4820, 0.4833, 0.4918, 0.4883, 0.4907, 0.5011, 0.5028],
       device='cuda:0') torch.Size([16])
percent tensor([0.5153, 0.5154, 0.5103, 0.5093, 0.5120, 0.5110, 0.5155, 0.5147, 0.5139,
        0.5152, 0.5170, 0.5122, 0.5170, 0.5147, 0.5153, 0.5144],
       device='cuda:0') torch.Size([16])
percent tensor([0.5277, 0.5265, 0.5681, 0.5652, 0.5716, 0.5303, 0.5376, 0.5784, 0.5322,
        0.5296, 0.5211, 0.5595, 0.5193, 0.5211, 0.5288, 0.5371],
       device='cuda:0') torch.Size([16])
percent tensor([0.5284, 0.5250, 0.5459, 0.5463, 0.5469, 0.5310, 0.5298, 0.5530, 0.5275,
        0.5282, 0.5232, 0.5351, 0.5257, 0.5241, 0.5331, 0.5333],
       device='cuda:0') torch.Size([16])
percent tensor([0.5015, 0.5068, 0.5239, 0.5191, 0.5197, 0.4794, 0.5114, 0.5264, 0.5103,
        0.5146, 0.5065, 0.5163, 0.4981, 0.5021, 0.5034, 0.5043],
       device='cuda:0') torch.Size([16])
percent tensor([0.7789, 0.6972, 0.7952, 0.8117, 0.8496, 0.7851, 0.7501, 0.8816, 0.7373,
        0.7904, 0.7373, 0.7593, 0.7577, 0.7455, 0.8036, 0.8605],
       device='cuda:0') torch.Size([16])
Epoch: 10 | Batch_idx: 0 |  Loss: (0.8873) |  Loss2: (0.0000) | Acc: (68.00%) (88/128)
Epoch: 10 | Batch_idx: 10 |  Loss: (1.0092) |  Loss2: (0.0000) | Acc: (63.00%) (892/1408)
Epoch: 10 | Batch_idx: 20 |  Loss: (1.0262) |  Loss2: (0.0000) | Acc: (62.00%) (1693/2688)
Epoch: 10 | Batch_idx: 30 |  Loss: (1.0383) |  Loss2: (0.0000) | Acc: (62.00%) (2490/3968)
Epoch: 10 | Batch_idx: 40 |  Loss: (1.0288) |  Loss2: (0.0000) | Acc: (63.00%) (3310/5248)
Epoch: 10 | Batch_idx: 50 |  Loss: (1.0307) |  Loss2: (0.0000) | Acc: (63.00%) (4127/6528)
Epoch: 10 | Batch_idx: 60 |  Loss: (1.0325) |  Loss2: (0.0000) | Acc: (62.00%) (4902/7808)
Epoch: 10 | Batch_idx: 70 |  Loss: (1.0347) |  Loss2: (0.0000) | Acc: (62.00%) (5690/9088)
Epoch: 10 | Batch_idx: 80 |  Loss: (1.0378) |  Loss2: (0.0000) | Acc: (62.00%) (6465/10368)
Epoch: 10 | Batch_idx: 90 |  Loss: (1.0420) |  Loss2: (0.0000) | Acc: (62.00%) (7253/11648)
Epoch: 10 | Batch_idx: 100 |  Loss: (1.0451) |  Loss2: (0.0000) | Acc: (62.00%) (8027/12928)
Epoch: 10 | Batch_idx: 110 |  Loss: (1.0467) |  Loss2: (0.0000) | Acc: (62.00%) (8821/14208)
Epoch: 10 | Batch_idx: 120 |  Loss: (1.0465) |  Loss2: (0.0000) | Acc: (62.00%) (9609/15488)
Epoch: 10 | Batch_idx: 130 |  Loss: (1.0474) |  Loss2: (0.0000) | Acc: (61.00%) (10395/16768)
Epoch: 10 | Batch_idx: 140 |  Loss: (1.0471) |  Loss2: (0.0000) | Acc: (62.00%) (11206/18048)
Epoch: 10 | Batch_idx: 150 |  Loss: (1.0467) |  Loss2: (0.0000) | Acc: (62.00%) (12012/19328)
Epoch: 10 | Batch_idx: 160 |  Loss: (1.0497) |  Loss2: (0.0000) | Acc: (61.00%) (12768/20608)
Epoch: 10 | Batch_idx: 170 |  Loss: (1.0514) |  Loss2: (0.0000) | Acc: (61.00%) (13523/21888)
Epoch: 10 | Batch_idx: 180 |  Loss: (1.0507) |  Loss2: (0.0000) | Acc: (61.00%) (14341/23168)
Epoch: 10 | Batch_idx: 190 |  Loss: (1.0495) |  Loss2: (0.0000) | Acc: (61.00%) (15132/24448)
Epoch: 10 | Batch_idx: 200 |  Loss: (1.0477) |  Loss2: (0.0000) | Acc: (61.00%) (15942/25728)
Epoch: 10 | Batch_idx: 210 |  Loss: (1.0459) |  Loss2: (0.0000) | Acc: (62.00%) (16756/27008)
Epoch: 10 | Batch_idx: 220 |  Loss: (1.0468) |  Loss2: (0.0000) | Acc: (61.00%) (17530/28288)
Epoch: 10 | Batch_idx: 230 |  Loss: (1.0486) |  Loss2: (0.0000) | Acc: (61.00%) (18317/29568)
Epoch: 10 | Batch_idx: 240 |  Loss: (1.0491) |  Loss2: (0.0000) | Acc: (61.00%) (19111/30848)
Epoch: 10 | Batch_idx: 250 |  Loss: (1.0481) |  Loss2: (0.0000) | Acc: (61.00%) (19903/32128)
Epoch: 10 | Batch_idx: 260 |  Loss: (1.0487) |  Loss2: (0.0000) | Acc: (61.00%) (20699/33408)
Epoch: 10 | Batch_idx: 270 |  Loss: (1.0483) |  Loss2: (0.0000) | Acc: (62.00%) (21510/34688)
Epoch: 10 | Batch_idx: 280 |  Loss: (1.0487) |  Loss2: (0.0000) | Acc: (61.00%) (22286/35968)
Epoch: 10 | Batch_idx: 290 |  Loss: (1.0495) |  Loss2: (0.0000) | Acc: (61.00%) (23077/37248)
Epoch: 10 | Batch_idx: 300 |  Loss: (1.0501) |  Loss2: (0.0000) | Acc: (61.00%) (23864/38528)
Epoch: 10 | Batch_idx: 310 |  Loss: (1.0499) |  Loss2: (0.0000) | Acc: (61.00%) (24662/39808)
Epoch: 10 | Batch_idx: 320 |  Loss: (1.0497) |  Loss2: (0.0000) | Acc: (61.00%) (25448/41088)
Epoch: 10 | Batch_idx: 330 |  Loss: (1.0482) |  Loss2: (0.0000) | Acc: (62.00%) (26279/42368)
Epoch: 10 | Batch_idx: 340 |  Loss: (1.0482) |  Loss2: (0.0000) | Acc: (62.00%) (27065/43648)
Epoch: 10 | Batch_idx: 350 |  Loss: (1.0489) |  Loss2: (0.0000) | Acc: (61.00%) (27835/44928)
Epoch: 10 | Batch_idx: 360 |  Loss: (1.0482) |  Loss2: (0.0000) | Acc: (61.00%) (28645/46208)
Epoch: 10 | Batch_idx: 370 |  Loss: (1.0490) |  Loss2: (0.0000) | Acc: (61.00%) (29415/47488)
Epoch: 10 | Batch_idx: 380 |  Loss: (1.0483) |  Loss2: (0.0000) | Acc: (61.00%) (30220/48768)
Epoch: 10 | Batch_idx: 390 |  Loss: (1.0489) |  Loss2: (0.0000) | Acc: (61.00%) (30992/50000)
=> saving checkpoint 'drive/app/torch/save_Schedule/checkpoint_010.pth.tar'
# TEST : Loss: (1.0642) | Acc: (62.00%) (6228/10000)
percent tensor([0.5003, 0.4979, 0.5003, 0.5001, 0.5002, 0.5014, 0.4994, 0.4999, 0.4999,
        0.4988, 0.4991, 0.5001, 0.4998, 0.4976, 0.4994, 0.4994],
       device='cuda:0') torch.Size([16])
percent tensor([0.4991, 0.4995, 0.4945, 0.4970, 0.4954, 0.5019, 0.4975, 0.4958, 0.4975,
        0.4980, 0.4999, 0.4958, 0.4993, 0.4990, 0.5005, 0.5000],
       device='cuda:0') torch.Size([16])
percent tensor([0.5039, 0.4808, 0.5032, 0.5185, 0.5071, 0.5354, 0.4860, 0.5005, 0.4922,
        0.4802, 0.4820, 0.4929, 0.4878, 0.4898, 0.5053, 0.5062],
       device='cuda:0') torch.Size([16])
percent tensor([0.5216, 0.5220, 0.5147, 0.5134, 0.5171, 0.5161, 0.5220, 0.5209, 0.5197,
        0.5215, 0.5239, 0.5171, 0.5238, 0.5209, 0.5218, 0.5207],
       device='cuda:0') torch.Size([16])
percent tensor([0.5282, 0.5292, 0.5740, 0.5698, 0.5773, 0.5315, 0.5405, 0.5855, 0.5354,
        0.5321, 0.5232, 0.5650, 0.5205, 0.5234, 0.5301, 0.5389],
       device='cuda:0') torch.Size([16])
percent tensor([0.5334, 0.5293, 0.5514, 0.5519, 0.5522, 0.5369, 0.5347, 0.5596, 0.5326,
        0.5327, 0.5277, 0.5402, 0.5308, 0.5291, 0.5378, 0.5394],
       device='cuda:0') torch.Size([16])
percent tensor([0.5038, 0.5087, 0.5285, 0.5230, 0.5235, 0.4790, 0.5146, 0.5324, 0.5129,
        0.5184, 0.5088, 0.5198, 0.4997, 0.5034, 0.5050, 0.5074],
       device='cuda:0') torch.Size([16])
percent tensor([0.8020, 0.7057, 0.8057, 0.8182, 0.8526, 0.8110, 0.7676, 0.8906, 0.7471,
        0.7983, 0.7451, 0.7726, 0.7685, 0.7583, 0.8200, 0.8861],
       device='cuda:0') torch.Size([16])
Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 3, 3, 3]) tensor(165.9142, device='cuda:0')
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(776.5017, device='cuda:0')
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(768.6211, device='cuda:0')
Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([128, 64, 3, 3]) tensor(1527.8657, device='cuda:0')
Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([128, 64, 1, 1]) tensor(509.3562, device='cuda:0')
Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([128, 128, 3, 3]) tensor(2166.9395, device='cuda:0')
Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([256, 128, 3, 3]) tensor(4326.1045, device='cuda:0')
Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([256, 128, 1, 1]) tensor(1441.9802, device='cuda:0')
Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([256, 256, 3, 3]) tensor(6117.0132, device='cuda:0')
Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([512, 256, 3, 3]) tensor(12222.7812, device='cuda:0')
Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([512, 256, 1, 1]) tensor(4073.3347, device='cuda:0')
Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([512, 512, 3, 3]) tensor(17282.6582, device='cuda:0')
Epoch: 11 | Batch_idx: 0 |  Loss: (1.1017) |  Loss2: (0.0000) | Acc: (59.00%) (76/128)
Epoch: 11 | Batch_idx: 10 |  Loss: (1.0603) |  Loss2: (0.0000) | Acc: (60.00%) (855/1408)
Epoch: 11 | Batch_idx: 20 |  Loss: (1.0728) |  Loss2: (0.0000) | Acc: (60.00%) (1630/2688)
Epoch: 11 | Batch_idx: 30 |  Loss: (1.0679) |  Loss2: (0.0000) | Acc: (60.00%) (2415/3968)
Epoch: 11 | Batch_idx: 40 |  Loss: (1.0647) |  Loss2: (0.0000) | Acc: (61.00%) (3229/5248)
Epoch: 11 | Batch_idx: 50 |  Loss: (1.0619) |  Loss2: (0.0000) | Acc: (61.00%) (4023/6528)
Epoch: 11 | Batch_idx: 60 |  Loss: (1.0609) |  Loss2: (0.0000) | Acc: (61.00%) (4816/7808)
Epoch: 11 | Batch_idx: 70 |  Loss: (1.0547) |  Loss2: (0.0000) | Acc: (61.00%) (5613/9088)
Epoch: 11 | Batch_idx: 80 |  Loss: (1.0556) |  Loss2: (0.0000) | Acc: (61.00%) (6395/10368)
Epoch: 11 | Batch_idx: 90 |  Loss: (1.0487) |  Loss2: (0.0000) | Acc: (61.00%) (7211/11648)
Epoch: 11 | Batch_idx: 100 |  Loss: (1.0483) |  Loss2: (0.0000) | Acc: (61.00%) (8012/12928)
Epoch: 11 | Batch_idx: 110 |  Loss: (1.0455) |  Loss2: (0.0000) | Acc: (62.00%) (8813/14208)
Epoch: 11 | Batch_idx: 120 |  Loss: (1.0462) |  Loss2: (0.0000) | Acc: (62.00%) (9611/15488)
Epoch: 11 | Batch_idx: 130 |  Loss: (1.0460) |  Loss2: (0.0000) | Acc: (62.00%) (10427/16768)
Epoch: 11 | Batch_idx: 140 |  Loss: (1.0484) |  Loss2: (0.0000) | Acc: (62.00%) (11204/18048)
Epoch: 11 | Batch_idx: 150 |  Loss: (1.0477) |  Loss2: (0.0000) | Acc: (62.00%) (12004/19328)
Epoch: 11 | Batch_idx: 160 |  Loss: (1.0473) |  Loss2: (0.0000) | Acc: (62.00%) (12791/20608)
Epoch: 11 | Batch_idx: 170 |  Loss: (1.0509) |  Loss2: (0.0000) | Acc: (61.00%) (13566/21888)
Epoch: 11 | Batch_idx: 180 |  Loss: (1.0507) |  Loss2: (0.0000) | Acc: (61.00%) (14363/23168)
Epoch: 11 | Batch_idx: 190 |  Loss: (1.0502) |  Loss2: (0.0000) | Acc: (62.00%) (15161/24448)
Epoch: 11 | Batch_idx: 200 |  Loss: (1.0493) |  Loss2: (0.0000) | Acc: (62.00%) (15967/25728)
Epoch: 11 | Batch_idx: 210 |  Loss: (1.0498) |  Loss2: (0.0000) | Acc: (62.00%) (16767/27008)
Epoch: 11 | Batch_idx: 220 |  Loss: (1.0508) |  Loss2: (0.0000) | Acc: (62.00%) (17555/28288)
Epoch: 11 | Batch_idx: 230 |  Loss: (1.0514) |  Loss2: (0.0000) | Acc: (62.00%) (18353/29568)
Epoch: 11 | Batch_idx: 240 |  Loss: (1.0495) |  Loss2: (0.0000) | Acc: (62.00%) (19188/30848)
Epoch: 11 | Batch_idx: 250 |  Loss: (1.0469) |  Loss2: (0.0000) | Acc: (62.00%) (20001/32128)
Epoch: 11 | Batch_idx: 260 |  Loss: (1.0474) |  Loss2: (0.0000) | Acc: (62.00%) (20813/33408)
Epoch: 11 | Batch_idx: 270 |  Loss: (1.0489) |  Loss2: (0.0000) | Acc: (62.00%) (21577/34688)
Epoch: 11 | Batch_idx: 280 |  Loss: (1.0478) |  Loss2: (0.0000) | Acc: (62.00%) (22408/35968)
Epoch: 11 | Batch_idx: 290 |  Loss: (1.0483) |  Loss2: (0.0000) | Acc: (62.00%) (23191/37248)
Epoch: 11 | Batch_idx: 300 |  Loss: (1.0479) |  Loss2: (0.0000) | Acc: (62.00%) (23999/38528)
Epoch: 11 | Batch_idx: 310 |  Loss: (1.0469) |  Loss2: (0.0000) | Acc: (62.00%) (24828/39808)
Epoch: 11 | Batch_idx: 320 |  Loss: (1.0456) |  Loss2: (0.0000) | Acc: (62.00%) (25643/41088)
Epoch: 11 | Batch_idx: 330 |  Loss: (1.0456) |  Loss2: (0.0000) | Acc: (62.00%) (26439/42368)
Epoch: 11 | Batch_idx: 340 |  Loss: (1.0460) |  Loss2: (0.0000) | Acc: (62.00%) (27228/43648)
Epoch: 11 | Batch_idx: 350 |  Loss: (1.0464) |  Loss2: (0.0000) | Acc: (62.00%) (28032/44928)
Epoch: 11 | Batch_idx: 360 |  Loss: (1.0464) |  Loss2: (0.0000) | Acc: (62.00%) (28829/46208)
Epoch: 11 | Batch_idx: 370 |  Loss: (1.0463) |  Loss2: (0.0000) | Acc: (62.00%) (29633/47488)
Epoch: 11 | Batch_idx: 380 |  Loss: (1.0458) |  Loss2: (0.0000) | Acc: (62.00%) (30443/48768)
Epoch: 11 | Batch_idx: 390 |  Loss: (1.0459) |  Loss2: (0.0000) | Acc: (62.00%) (31223/50000)
# TEST : Loss: (1.0605) | Acc: (62.00%) (6233/10000)
percent tensor([0.5005, 0.4981, 0.5004, 0.5002, 0.5004, 0.5016, 0.4996, 0.5001, 0.5002,
        0.4990, 0.4993, 0.5003, 0.5000, 0.4978, 0.4996, 0.4996],
       device='cuda:0') torch.Size([16])
percent tensor([0.4990, 0.4997, 0.4934, 0.4964, 0.4945, 0.5024, 0.4972, 0.4950, 0.4971,
        0.4978, 0.5001, 0.4951, 0.4993, 0.4991, 0.5008, 0.5002],
       device='cuda:0') torch.Size([16])
percent tensor([0.5071, 0.4810, 0.5073, 0.5247, 0.5120, 0.5444, 0.4874, 0.5040, 0.4933,
        0.4799, 0.4821, 0.4955, 0.4882, 0.4902, 0.5103, 0.5101],
       device='cuda:0') torch.Size([16])
percent tensor([0.5274, 0.5280, 0.5184, 0.5170, 0.5217, 0.5206, 0.5278, 0.5262, 0.5252,
        0.5272, 0.5304, 0.5215, 0.5303, 0.5266, 0.5276, 0.5264],
       device='cuda:0') torch.Size([16])
percent tensor([0.5291, 0.5312, 0.5746, 0.5716, 0.5780, 0.5326, 0.5419, 0.5874, 0.5371,
        0.5339, 0.5254, 0.5665, 0.5222, 0.5261, 0.5311, 0.5403],
       device='cuda:0') torch.Size([16])
percent tensor([0.5383, 0.5337, 0.5567, 0.5583, 0.5575, 0.5430, 0.5394, 0.5657, 0.5377,
        0.5371, 0.5322, 0.5453, 0.5361, 0.5346, 0.5422, 0.5455],
       device='cuda:0') torch.Size([16])
percent tensor([0.5063, 0.5108, 0.5336, 0.5284, 0.5288, 0.4800, 0.5174, 0.5387, 0.5155,
        0.5218, 0.5109, 0.5234, 0.5014, 0.5052, 0.5067, 0.5110],
       device='cuda:0') torch.Size([16])
percent tensor([0.8191, 0.7127, 0.8196, 0.8335, 0.8655, 0.8270, 0.7773, 0.9002, 0.7552,
        0.8047, 0.7530, 0.7869, 0.7792, 0.7692, 0.8324, 0.9004],
       device='cuda:0') torch.Size([16])
True Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=128, out_features=16, bias=False)
False Linear(in_features=16, out_features=2, bias=False)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=128, out_features=16, bias=False)
False Linear(in_features=16, out_features=2, bias=False)
True Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=256, out_features=32, bias=False)
False Linear(in_features=32, out_features=2, bias=False)
True Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=256, out_features=32, bias=False)
False Linear(in_features=32, out_features=2, bias=False)
True Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=512, out_features=64, bias=False)
False Linear(in_features=64, out_features=2, bias=False)
True Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=512, out_features=64, bias=False)
False Linear(in_features=64, out_features=2, bias=False)
True Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1024, out_features=128, bias=False)
False Linear(in_features=128, out_features=2, bias=False)
True Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1024, out_features=128, bias=False)
False Linear(in_features=128, out_features=2, bias=False)
True Linear(in_features=512, out_features=10, bias=True)
Epoch: 12 | Batch_idx: 0 |  Loss: (1.1458) |  Loss2: (0.0000) | Acc: (61.00%) (79/128)
Epoch: 12 | Batch_idx: 10 |  Loss: (1.0451) |  Loss2: (0.0000) | Acc: (63.00%) (889/1408)
Epoch: 12 | Batch_idx: 20 |  Loss: (1.0822) |  Loss2: (0.0000) | Acc: (61.00%) (1652/2688)
Epoch: 12 | Batch_idx: 30 |  Loss: (1.0889) |  Loss2: (0.0000) | Acc: (61.00%) (2428/3968)
Epoch: 12 | Batch_idx: 40 |  Loss: (1.0708) |  Loss2: (0.0000) | Acc: (61.00%) (3229/5248)
Epoch: 12 | Batch_idx: 50 |  Loss: (1.0728) |  Loss2: (0.0000) | Acc: (61.00%) (4005/6528)
Epoch: 12 | Batch_idx: 60 |  Loss: (1.0801) |  Loss2: (0.0000) | Acc: (61.00%) (4779/7808)
Epoch: 12 | Batch_idx: 70 |  Loss: (1.0858) |  Loss2: (0.0000) | Acc: (60.00%) (5531/9088)
Epoch: 12 | Batch_idx: 80 |  Loss: (1.0852) |  Loss2: (0.0000) | Acc: (60.00%) (6315/10368)
Epoch: 12 | Batch_idx: 90 |  Loss: (1.0801) |  Loss2: (0.0000) | Acc: (60.00%) (7105/11648)
Epoch: 12 | Batch_idx: 100 |  Loss: (1.0795) |  Loss2: (0.0000) | Acc: (60.00%) (7879/12928)
Epoch: 12 | Batch_idx: 110 |  Loss: (1.0803) |  Loss2: (0.0000) | Acc: (61.00%) (8667/14208)
Epoch: 12 | Batch_idx: 120 |  Loss: (1.0761) |  Loss2: (0.0000) | Acc: (61.00%) (9462/15488)
Epoch: 12 | Batch_idx: 130 |  Loss: (1.0749) |  Loss2: (0.0000) | Acc: (61.00%) (10240/16768)
Epoch: 12 | Batch_idx: 140 |  Loss: (1.0732) |  Loss2: (0.0000) | Acc: (61.00%) (11049/18048)
Epoch: 12 | Batch_idx: 150 |  Loss: (1.0716) |  Loss2: (0.0000) | Acc: (61.00%) (11842/19328)
Epoch: 12 | Batch_idx: 160 |  Loss: (1.0706) |  Loss2: (0.0000) | Acc: (61.00%) (12607/20608)
Epoch: 12 | Batch_idx: 170 |  Loss: (1.0690) |  Loss2: (0.0000) | Acc: (61.00%) (13410/21888)
Epoch: 12 | Batch_idx: 180 |  Loss: (1.0679) |  Loss2: (0.0000) | Acc: (61.00%) (14192/23168)
Epoch: 12 | Batch_idx: 190 |  Loss: (1.0663) |  Loss2: (0.0000) | Acc: (61.00%) (14989/24448)
Epoch: 12 | Batch_idx: 200 |  Loss: (1.0643) |  Loss2: (0.0000) | Acc: (61.00%) (15794/25728)
Epoch: 12 | Batch_idx: 210 |  Loss: (1.0608) |  Loss2: (0.0000) | Acc: (61.00%) (16618/27008)
Epoch: 12 | Batch_idx: 220 |  Loss: (1.0589) |  Loss2: (0.0000) | Acc: (61.00%) (17425/28288)
Epoch: 12 | Batch_idx: 230 |  Loss: (1.0575) |  Loss2: (0.0000) | Acc: (61.00%) (18239/29568)
Epoch: 12 | Batch_idx: 240 |  Loss: (1.0560) |  Loss2: (0.0000) | Acc: (61.00%) (19048/30848)
Epoch: 12 | Batch_idx: 250 |  Loss: (1.0552) |  Loss2: (0.0000) | Acc: (61.00%) (19864/32128)
Epoch: 12 | Batch_idx: 260 |  Loss: (1.0527) |  Loss2: (0.0000) | Acc: (61.00%) (20702/33408)
Epoch: 12 | Batch_idx: 270 |  Loss: (1.0506) |  Loss2: (0.0000) | Acc: (62.00%) (21537/34688)
Epoch: 12 | Batch_idx: 280 |  Loss: (1.0488) |  Loss2: (0.0000) | Acc: (62.00%) (22359/35968)
Epoch: 12 | Batch_idx: 290 |  Loss: (1.0480) |  Loss2: (0.0000) | Acc: (62.00%) (23164/37248)
Epoch: 12 | Batch_idx: 300 |  Loss: (1.0477) |  Loss2: (0.0000) | Acc: (62.00%) (23959/38528)
Epoch: 12 | Batch_idx: 310 |  Loss: (1.0460) |  Loss2: (0.0000) | Acc: (62.00%) (24772/39808)
Epoch: 12 | Batch_idx: 320 |  Loss: (1.0442) |  Loss2: (0.0000) | Acc: (62.00%) (25598/41088)
Epoch: 12 | Batch_idx: 330 |  Loss: (1.0420) |  Loss2: (0.0000) | Acc: (62.00%) (26430/42368)
Epoch: 12 | Batch_idx: 340 |  Loss: (1.0416) |  Loss2: (0.0000) | Acc: (62.00%) (27234/43648)
Epoch: 12 | Batch_idx: 350 |  Loss: (1.0410) |  Loss2: (0.0000) | Acc: (62.00%) (28076/44928)
Epoch: 12 | Batch_idx: 360 |  Loss: (1.0398) |  Loss2: (0.0000) | Acc: (62.00%) (28902/46208)
Epoch: 12 | Batch_idx: 370 |  Loss: (1.0385) |  Loss2: (0.0000) | Acc: (62.00%) (29719/47488)
Epoch: 12 | Batch_idx: 380 |  Loss: (1.0371) |  Loss2: (0.0000) | Acc: (62.00%) (30555/48768)
Epoch: 12 | Batch_idx: 390 |  Loss: (1.0364) |  Loss2: (0.0000) | Acc: (62.00%) (31350/50000)
# TEST : Loss: (1.1065) | Acc: (60.00%) (6069/10000)
percent tensor([0.5006, 0.4983, 0.5003, 0.5003, 0.5006, 0.5015, 0.4998, 0.4997, 0.5000,
        0.4990, 0.4992, 0.5004, 0.4999, 0.4983, 0.4997, 0.4996],
       device='cuda:0') torch.Size([16])
percent tensor([0.4989, 0.4995, 0.4950, 0.4968, 0.4956, 0.5018, 0.4974, 0.4956, 0.4974,
        0.4980, 0.4998, 0.4964, 0.4993, 0.4986, 0.5004, 0.4998],
       device='cuda:0') torch.Size([16])
percent tensor([0.5064, 0.4766, 0.5102, 0.5231, 0.5145, 0.5394, 0.4865, 0.5054, 0.4918,
        0.4779, 0.4772, 0.4967, 0.4864, 0.4869, 0.5044, 0.5067],
       device='cuda:0') torch.Size([16])
percent tensor([0.5278, 0.5310, 0.5183, 0.5169, 0.5222, 0.5223, 0.5283, 0.5252, 0.5255,
        0.5282, 0.5321, 0.5208, 0.5301, 0.5273, 0.5284, 0.5277],
       device='cuda:0') torch.Size([16])
percent tensor([0.5305, 0.5307, 0.5676, 0.5627, 0.5765, 0.5328, 0.5414, 0.5747, 0.5370,
        0.5369, 0.5237, 0.5610, 0.5232, 0.5287, 0.5308, 0.5380],
       device='cuda:0') torch.Size([16])
percent tensor([0.5414, 0.5354, 0.5551, 0.5565, 0.5574, 0.5467, 0.5403, 0.5612, 0.5387,
        0.5369, 0.5347, 0.5465, 0.5364, 0.5362, 0.5428, 0.5453],
       device='cuda:0') torch.Size([16])
percent tensor([0.5062, 0.5058, 0.5318, 0.5234, 0.5247, 0.4875, 0.5166, 0.5348, 0.5166,
        0.5181, 0.5126, 0.5191, 0.5018, 0.5081, 0.5014, 0.5089],
       device='cuda:0') torch.Size([16])
percent tensor([0.8571, 0.7561, 0.8283, 0.8323, 0.8293, 0.8225, 0.8148, 0.8922, 0.7748,
        0.8134, 0.8244, 0.8267, 0.8175, 0.7935, 0.8440, 0.8850],
       device='cuda:0') torch.Size([16])
Epoch: 13 | Batch_idx: 0 |  Loss: (0.9706) |  Loss2: (0.0000) | Acc: (69.00%) (89/128)
Epoch: 13 | Batch_idx: 10 |  Loss: (0.9622) |  Loss2: (0.0000) | Acc: (66.00%) (938/1408)
Epoch: 13 | Batch_idx: 20 |  Loss: (0.9921) |  Loss2: (0.0000) | Acc: (64.00%) (1743/2688)
Epoch: 13 | Batch_idx: 30 |  Loss: (0.9876) |  Loss2: (0.0000) | Acc: (65.00%) (2584/3968)
Epoch: 13 | Batch_idx: 40 |  Loss: (0.9929) |  Loss2: (0.0000) | Acc: (64.00%) (3389/5248)
Epoch: 13 | Batch_idx: 50 |  Loss: (0.9914) |  Loss2: (0.0000) | Acc: (64.00%) (4226/6528)
Epoch: 13 | Batch_idx: 60 |  Loss: (0.9879) |  Loss2: (0.0000) | Acc: (64.00%) (5067/7808)
Epoch: 13 | Batch_idx: 70 |  Loss: (0.9876) |  Loss2: (0.0000) | Acc: (64.00%) (5887/9088)
Epoch: 13 | Batch_idx: 80 |  Loss: (0.9869) |  Loss2: (0.0000) | Acc: (64.00%) (6705/10368)
Epoch: 13 | Batch_idx: 90 |  Loss: (0.9786) |  Loss2: (0.0000) | Acc: (65.00%) (7579/11648)
Epoch: 13 | Batch_idx: 100 |  Loss: (0.9787) |  Loss2: (0.0000) | Acc: (64.00%) (8402/12928)
Epoch: 13 | Batch_idx: 110 |  Loss: (0.9765) |  Loss2: (0.0000) | Acc: (65.00%) (9242/14208)
Epoch: 13 | Batch_idx: 120 |  Loss: (0.9794) |  Loss2: (0.0000) | Acc: (65.00%) (10072/15488)
Epoch: 13 | Batch_idx: 130 |  Loss: (0.9802) |  Loss2: (0.0000) | Acc: (65.00%) (10908/16768)
Epoch: 13 | Batch_idx: 140 |  Loss: (0.9802) |  Loss2: (0.0000) | Acc: (64.00%) (11729/18048)
Epoch: 13 | Batch_idx: 150 |  Loss: (0.9806) |  Loss2: (0.0000) | Acc: (64.00%) (12548/19328)
Epoch: 13 | Batch_idx: 160 |  Loss: (0.9812) |  Loss2: (0.0000) | Acc: (64.00%) (13378/20608)
Epoch: 13 | Batch_idx: 170 |  Loss: (0.9849) |  Loss2: (0.0000) | Acc: (64.00%) (14186/21888)
Epoch: 13 | Batch_idx: 180 |  Loss: (0.9831) |  Loss2: (0.0000) | Acc: (64.00%) (15030/23168)
Epoch: 13 | Batch_idx: 190 |  Loss: (0.9803) |  Loss2: (0.0000) | Acc: (65.00%) (15896/24448)
Epoch: 13 | Batch_idx: 200 |  Loss: (0.9787) |  Loss2: (0.0000) | Acc: (64.00%) (16721/25728)
Epoch: 13 | Batch_idx: 210 |  Loss: (0.9772) |  Loss2: (0.0000) | Acc: (65.00%) (17557/27008)
Epoch: 13 | Batch_idx: 220 |  Loss: (0.9751) |  Loss2: (0.0000) | Acc: (65.00%) (18422/28288)
Epoch: 13 | Batch_idx: 230 |  Loss: (0.9758) |  Loss2: (0.0000) | Acc: (65.00%) (19232/29568)
Epoch: 13 | Batch_idx: 240 |  Loss: (0.9723) |  Loss2: (0.0000) | Acc: (65.00%) (20107/30848)
Epoch: 13 | Batch_idx: 250 |  Loss: (0.9707) |  Loss2: (0.0000) | Acc: (65.00%) (20972/32128)
Epoch: 13 | Batch_idx: 260 |  Loss: (0.9691) |  Loss2: (0.0000) | Acc: (65.00%) (21823/33408)
Epoch: 13 | Batch_idx: 270 |  Loss: (0.9687) |  Loss2: (0.0000) | Acc: (65.00%) (22673/34688)
Epoch: 13 | Batch_idx: 280 |  Loss: (0.9671) |  Loss2: (0.0000) | Acc: (65.00%) (23526/35968)
Epoch: 13 | Batch_idx: 290 |  Loss: (0.9658) |  Loss2: (0.0000) | Acc: (65.00%) (24390/37248)
Epoch: 13 | Batch_idx: 300 |  Loss: (0.9643) |  Loss2: (0.0000) | Acc: (65.00%) (25246/38528)
Epoch: 13 | Batch_idx: 310 |  Loss: (0.9614) |  Loss2: (0.0000) | Acc: (65.00%) (26134/39808)
Epoch: 13 | Batch_idx: 320 |  Loss: (0.9627) |  Loss2: (0.0000) | Acc: (65.00%) (26964/41088)
Epoch: 13 | Batch_idx: 330 |  Loss: (0.9617) |  Loss2: (0.0000) | Acc: (65.00%) (27811/42368)
Epoch: 13 | Batch_idx: 340 |  Loss: (0.9608) |  Loss2: (0.0000) | Acc: (65.00%) (28659/43648)
Epoch: 13 | Batch_idx: 350 |  Loss: (0.9606) |  Loss2: (0.0000) | Acc: (65.00%) (29501/44928)
Epoch: 13 | Batch_idx: 360 |  Loss: (0.9591) |  Loss2: (0.0000) | Acc: (65.00%) (30381/46208)
Epoch: 13 | Batch_idx: 370 |  Loss: (0.9579) |  Loss2: (0.0000) | Acc: (65.00%) (31254/47488)
Epoch: 13 | Batch_idx: 380 |  Loss: (0.9571) |  Loss2: (0.0000) | Acc: (65.00%) (32103/48768)
Epoch: 13 | Batch_idx: 390 |  Loss: (0.9554) |  Loss2: (0.0000) | Acc: (65.00%) (32940/50000)
# TEST : Loss: (0.9723) | Acc: (64.00%) (6499/10000)
percent tensor([0.5006, 0.4983, 0.5002, 0.5002, 0.5005, 0.5014, 0.4996, 0.4995, 0.5000,
        0.4989, 0.4993, 0.5003, 0.4999, 0.4985, 0.4995, 0.4996],
       device='cuda:0') torch.Size([16])
percent tensor([0.4988, 0.4994, 0.4954, 0.4967, 0.4959, 0.5022, 0.4975, 0.4957, 0.4978,
        0.4979, 0.5000, 0.4967, 0.4994, 0.4984, 0.5005, 0.4997],
       device='cuda:0') torch.Size([16])
percent tensor([0.5075, 0.4775, 0.5037, 0.5211, 0.5106, 0.5403, 0.4856, 0.5030, 0.4911,
        0.4774, 0.4769, 0.4912, 0.4843, 0.4883, 0.5069, 0.5073],
       device='cuda:0') torch.Size([16])
percent tensor([0.5270, 0.5294, 0.5192, 0.5170, 0.5218, 0.5185, 0.5277, 0.5243, 0.5268,
        0.5277, 0.5316, 0.5230, 0.5306, 0.5267, 0.5266, 0.5255],
       device='cuda:0') torch.Size([16])
percent tensor([0.5324, 0.5319, 0.5604, 0.5609, 0.5676, 0.5387, 0.5417, 0.5686, 0.5341,
        0.5406, 0.5280, 0.5590, 0.5263, 0.5339, 0.5351, 0.5404],
       device='cuda:0') torch.Size([16])
percent tensor([0.5410, 0.5354, 0.5479, 0.5558, 0.5526, 0.5452, 0.5401, 0.5575, 0.5378,
        0.5375, 0.5339, 0.5427, 0.5363, 0.5383, 0.5395, 0.5444],
       device='cuda:0') torch.Size([16])
percent tensor([0.5131, 0.5078, 0.5245, 0.5239, 0.5244, 0.4890, 0.5169, 0.5319, 0.5136,
        0.5196, 0.5114, 0.5200, 0.5044, 0.5071, 0.5048, 0.5114],
       device='cuda:0') torch.Size([16])
percent tensor([0.8628, 0.7327, 0.7953, 0.8424, 0.8566, 0.8095, 0.8040, 0.8897, 0.7628,
        0.7930, 0.7863, 0.8087, 0.7923, 0.7704, 0.8002, 0.8766],
       device='cuda:0') torch.Size([16])
Epoch: 14 | Batch_idx: 0 |  Loss: (1.0268) |  Loss2: (0.0000) | Acc: (60.00%) (78/128)
Epoch: 14 | Batch_idx: 10 |  Loss: (0.9436) |  Loss2: (0.0000) | Acc: (65.00%) (922/1408)
Epoch: 14 | Batch_idx: 20 |  Loss: (0.9317) |  Loss2: (0.0000) | Acc: (66.00%) (1781/2688)
Epoch: 14 | Batch_idx: 30 |  Loss: (0.9291) |  Loss2: (0.0000) | Acc: (66.00%) (2638/3968)
Epoch: 14 | Batch_idx: 40 |  Loss: (0.9164) |  Loss2: (0.0000) | Acc: (67.00%) (3520/5248)
Epoch: 14 | Batch_idx: 50 |  Loss: (0.9108) |  Loss2: (0.0000) | Acc: (67.00%) (4397/6528)
Epoch: 14 | Batch_idx: 60 |  Loss: (0.9076) |  Loss2: (0.0000) | Acc: (67.00%) (5268/7808)
Epoch: 14 | Batch_idx: 70 |  Loss: (0.9022) |  Loss2: (0.0000) | Acc: (67.00%) (6160/9088)
Epoch: 14 | Batch_idx: 80 |  Loss: (0.9056) |  Loss2: (0.0000) | Acc: (67.00%) (7013/10368)
Epoch: 14 | Batch_idx: 90 |  Loss: (0.9071) |  Loss2: (0.0000) | Acc: (67.00%) (7853/11648)
Epoch: 14 | Batch_idx: 100 |  Loss: (0.9047) |  Loss2: (0.0000) | Acc: (67.00%) (8739/12928)
Epoch: 14 | Batch_idx: 110 |  Loss: (0.9032) |  Loss2: (0.0000) | Acc: (67.00%) (9596/14208)
Epoch: 14 | Batch_idx: 120 |  Loss: (0.9005) |  Loss2: (0.0000) | Acc: (67.00%) (10490/15488)
Epoch: 14 | Batch_idx: 130 |  Loss: (0.9001) |  Loss2: (0.0000) | Acc: (67.00%) (11368/16768)
Epoch: 14 | Batch_idx: 140 |  Loss: (0.9007) |  Loss2: (0.0000) | Acc: (67.00%) (12229/18048)
Epoch: 14 | Batch_idx: 150 |  Loss: (0.9018) |  Loss2: (0.0000) | Acc: (67.00%) (13083/19328)
Epoch: 14 | Batch_idx: 160 |  Loss: (0.9007) |  Loss2: (0.0000) | Acc: (67.00%) (13976/20608)
Epoch: 14 | Batch_idx: 170 |  Loss: (0.9012) |  Loss2: (0.0000) | Acc: (67.00%) (14862/21888)
Epoch: 14 | Batch_idx: 180 |  Loss: (0.9036) |  Loss2: (0.0000) | Acc: (67.00%) (15713/23168)
Epoch: 14 | Batch_idx: 190 |  Loss: (0.9035) |  Loss2: (0.0000) | Acc: (67.00%) (16573/24448)
Epoch: 14 | Batch_idx: 200 |  Loss: (0.9029) |  Loss2: (0.0000) | Acc: (67.00%) (17439/25728)
Epoch: 14 | Batch_idx: 210 |  Loss: (0.9022) |  Loss2: (0.0000) | Acc: (67.00%) (18308/27008)
Epoch: 14 | Batch_idx: 220 |  Loss: (0.9034) |  Loss2: (0.0000) | Acc: (67.00%) (19155/28288)
Epoch: 14 | Batch_idx: 230 |  Loss: (0.9044) |  Loss2: (0.0000) | Acc: (67.00%) (20022/29568)
Epoch: 14 | Batch_idx: 240 |  Loss: (0.9037) |  Loss2: (0.0000) | Acc: (67.00%) (20912/30848)
Epoch: 14 | Batch_idx: 250 |  Loss: (0.9038) |  Loss2: (0.0000) | Acc: (67.00%) (21786/32128)
Epoch: 14 | Batch_idx: 260 |  Loss: (0.9035) |  Loss2: (0.0000) | Acc: (67.00%) (22652/33408)
Epoch: 14 | Batch_idx: 270 |  Loss: (0.9026) |  Loss2: (0.0000) | Acc: (67.00%) (23524/34688)
Epoch: 14 | Batch_idx: 280 |  Loss: (0.9005) |  Loss2: (0.0000) | Acc: (67.00%) (24413/35968)
Epoch: 14 | Batch_idx: 290 |  Loss: (0.9002) |  Loss2: (0.0000) | Acc: (67.00%) (25282/37248)
Epoch: 14 | Batch_idx: 300 |  Loss: (0.8987) |  Loss2: (0.0000) | Acc: (67.00%) (26199/38528)
Epoch: 14 | Batch_idx: 310 |  Loss: (0.8983) |  Loss2: (0.0000) | Acc: (67.00%) (27059/39808)
Epoch: 14 | Batch_idx: 320 |  Loss: (0.8974) |  Loss2: (0.0000) | Acc: (67.00%) (27936/41088)
Epoch: 14 | Batch_idx: 330 |  Loss: (0.8961) |  Loss2: (0.0000) | Acc: (68.00%) (28827/42368)
Epoch: 14 | Batch_idx: 340 |  Loss: (0.8959) |  Loss2: (0.0000) | Acc: (68.00%) (29699/43648)
Epoch: 14 | Batch_idx: 350 |  Loss: (0.8946) |  Loss2: (0.0000) | Acc: (68.00%) (30594/44928)
Epoch: 14 | Batch_idx: 360 |  Loss: (0.8940) |  Loss2: (0.0000) | Acc: (68.00%) (31478/46208)
Epoch: 14 | Batch_idx: 370 |  Loss: (0.8924) |  Loss2: (0.0000) | Acc: (68.00%) (32385/47488)
Epoch: 14 | Batch_idx: 380 |  Loss: (0.8916) |  Loss2: (0.0000) | Acc: (68.00%) (33255/48768)
Epoch: 14 | Batch_idx: 390 |  Loss: (0.8910) |  Loss2: (0.0000) | Acc: (68.00%) (34095/50000)
# TEST : Loss: (0.9224) | Acc: (66.00%) (6697/10000)
percent tensor([0.5004, 0.4984, 0.5000, 0.5000, 0.5003, 0.5014, 0.4994, 0.4994, 0.5000,
        0.4990, 0.4994, 0.5001, 0.4998, 0.4986, 0.4995, 0.4996],
       device='cuda:0') torch.Size([16])
percent tensor([0.4984, 0.4994, 0.4955, 0.4968, 0.4958, 0.5018, 0.4975, 0.4954, 0.4973,
        0.4980, 0.4994, 0.4967, 0.4991, 0.4983, 0.5003, 0.4995],
       device='cuda:0') torch.Size([16])
percent tensor([0.5093, 0.4772, 0.5045, 0.5193, 0.5130, 0.5388, 0.4871, 0.5042, 0.4972,
        0.4772, 0.4825, 0.4909, 0.4867, 0.4883, 0.5075, 0.5093],
       device='cuda:0') torch.Size([16])
percent tensor([0.5267, 0.5303, 0.5197, 0.5177, 0.5223, 0.5187, 0.5281, 0.5246, 0.5251,
        0.5280, 0.5297, 0.5242, 0.5307, 0.5275, 0.5278, 0.5253],
       device='cuda:0') torch.Size([16])
percent tensor([0.5375, 0.5303, 0.5635, 0.5613, 0.5690, 0.5416, 0.5430, 0.5728, 0.5405,
        0.5389, 0.5284, 0.5589, 0.5263, 0.5359, 0.5384, 0.5410],
       device='cuda:0') torch.Size([16])
percent tensor([0.5430, 0.5357, 0.5509, 0.5577, 0.5539, 0.5480, 0.5411, 0.5600, 0.5403,
        0.5376, 0.5349, 0.5443, 0.5372, 0.5393, 0.5425, 0.5455],
       device='cuda:0') torch.Size([16])
percent tensor([0.5149, 0.5140, 0.5287, 0.5250, 0.5256, 0.4889, 0.5210, 0.5377, 0.5166,
        0.5235, 0.5157, 0.5231, 0.5036, 0.5112, 0.5119, 0.5135],
       device='cuda:0') torch.Size([16])
percent tensor([0.8842, 0.7761, 0.8041, 0.8454, 0.8276, 0.8062, 0.8215, 0.8849, 0.7600,
        0.8184, 0.7891, 0.8379, 0.7895, 0.7976, 0.8157, 0.8906],
       device='cuda:0') torch.Size([16])
Epoch: 15 | Batch_idx: 0 |  Loss: (0.8235) |  Loss2: (0.0000) | Acc: (74.00%) (95/128)
Epoch: 15 | Batch_idx: 10 |  Loss: (0.8278) |  Loss2: (0.0000) | Acc: (70.00%) (988/1408)
Epoch: 15 | Batch_idx: 20 |  Loss: (0.8614) |  Loss2: (0.0000) | Acc: (69.00%) (1869/2688)
Epoch: 15 | Batch_idx: 30 |  Loss: (0.8413) |  Loss2: (0.0000) | Acc: (70.00%) (2795/3968)
Epoch: 15 | Batch_idx: 40 |  Loss: (0.8374) |  Loss2: (0.0000) | Acc: (70.00%) (3693/5248)
Epoch: 15 | Batch_idx: 50 |  Loss: (0.8420) |  Loss2: (0.0000) | Acc: (70.00%) (4580/6528)
Epoch: 15 | Batch_idx: 60 |  Loss: (0.8400) |  Loss2: (0.0000) | Acc: (70.00%) (5483/7808)
Epoch: 15 | Batch_idx: 70 |  Loss: (0.8453) |  Loss2: (0.0000) | Acc: (70.00%) (6374/9088)
Epoch: 15 | Batch_idx: 80 |  Loss: (0.8439) |  Loss2: (0.0000) | Acc: (70.00%) (7285/10368)
Epoch: 15 | Batch_idx: 90 |  Loss: (0.8451) |  Loss2: (0.0000) | Acc: (70.00%) (8162/11648)
Epoch: 15 | Batch_idx: 100 |  Loss: (0.8425) |  Loss2: (0.0000) | Acc: (70.00%) (9072/12928)
Epoch: 15 | Batch_idx: 110 |  Loss: (0.8504) |  Loss2: (0.0000) | Acc: (69.00%) (9944/14208)
Epoch: 15 | Batch_idx: 120 |  Loss: (0.8483) |  Loss2: (0.0000) | Acc: (69.00%) (10841/15488)
Epoch: 15 | Batch_idx: 130 |  Loss: (0.8472) |  Loss2: (0.0000) | Acc: (69.00%) (11734/16768)
Epoch: 15 | Batch_idx: 140 |  Loss: (0.8495) |  Loss2: (0.0000) | Acc: (69.00%) (12607/18048)
Epoch: 15 | Batch_idx: 150 |  Loss: (0.8470) |  Loss2: (0.0000) | Acc: (70.00%) (13535/19328)
Epoch: 15 | Batch_idx: 160 |  Loss: (0.8450) |  Loss2: (0.0000) | Acc: (70.00%) (14456/20608)
Epoch: 15 | Batch_idx: 170 |  Loss: (0.8470) |  Loss2: (0.0000) | Acc: (70.00%) (15335/21888)
Epoch: 15 | Batch_idx: 180 |  Loss: (0.8464) |  Loss2: (0.0000) | Acc: (70.00%) (16234/23168)
Epoch: 15 | Batch_idx: 190 |  Loss: (0.8457) |  Loss2: (0.0000) | Acc: (70.00%) (17138/24448)
Epoch: 15 | Batch_idx: 200 |  Loss: (0.8450) |  Loss2: (0.0000) | Acc: (70.00%) (18042/25728)
Epoch: 15 | Batch_idx: 210 |  Loss: (0.8463) |  Loss2: (0.0000) | Acc: (70.00%) (18913/27008)
Epoch: 15 | Batch_idx: 220 |  Loss: (0.8455) |  Loss2: (0.0000) | Acc: (70.00%) (19816/28288)
Epoch: 15 | Batch_idx: 230 |  Loss: (0.8449) |  Loss2: (0.0000) | Acc: (70.00%) (20714/29568)
Epoch: 15 | Batch_idx: 240 |  Loss: (0.8449) |  Loss2: (0.0000) | Acc: (70.00%) (21613/30848)
Epoch: 15 | Batch_idx: 250 |  Loss: (0.8443) |  Loss2: (0.0000) | Acc: (70.00%) (22516/32128)
Epoch: 15 | Batch_idx: 260 |  Loss: (0.8432) |  Loss2: (0.0000) | Acc: (70.00%) (23436/33408)
Epoch: 15 | Batch_idx: 270 |  Loss: (0.8432) |  Loss2: (0.0000) | Acc: (70.00%) (24334/34688)
Epoch: 15 | Batch_idx: 280 |  Loss: (0.8432) |  Loss2: (0.0000) | Acc: (70.00%) (25233/35968)
Epoch: 15 | Batch_idx: 290 |  Loss: (0.8407) |  Loss2: (0.0000) | Acc: (70.00%) (26165/37248)
Epoch: 15 | Batch_idx: 300 |  Loss: (0.8410) |  Loss2: (0.0000) | Acc: (70.00%) (27058/38528)
Epoch: 15 | Batch_idx: 310 |  Loss: (0.8395) |  Loss2: (0.0000) | Acc: (70.00%) (27958/39808)
Epoch: 15 | Batch_idx: 320 |  Loss: (0.8391) |  Loss2: (0.0000) | Acc: (70.00%) (28871/41088)
Epoch: 15 | Batch_idx: 330 |  Loss: (0.8397) |  Loss2: (0.0000) | Acc: (70.00%) (29751/42368)
Epoch: 15 | Batch_idx: 340 |  Loss: (0.8405) |  Loss2: (0.0000) | Acc: (70.00%) (30642/43648)
Epoch: 15 | Batch_idx: 350 |  Loss: (0.8393) |  Loss2: (0.0000) | Acc: (70.00%) (31566/44928)
Epoch: 15 | Batch_idx: 360 |  Loss: (0.8387) |  Loss2: (0.0000) | Acc: (70.00%) (32470/46208)
Epoch: 15 | Batch_idx: 370 |  Loss: (0.8374) |  Loss2: (0.0000) | Acc: (70.00%) (33417/47488)
Epoch: 15 | Batch_idx: 380 |  Loss: (0.8367) |  Loss2: (0.0000) | Acc: (70.00%) (34332/48768)
Epoch: 15 | Batch_idx: 390 |  Loss: (0.8359) |  Loss2: (0.0000) | Acc: (70.00%) (35233/50000)
=> saving checkpoint 'drive/app/torch/save_Schedule/checkpoint_015.pth.tar'
# TEST : Loss: (0.9565) | Acc: (66.00%) (6631/10000)
percent tensor([0.5005, 0.4985, 0.5001, 0.5003, 0.5005, 0.5014, 0.4996, 0.4994, 0.5000,
        0.4991, 0.4993, 0.5002, 0.5000, 0.4986, 0.4995, 0.4997],
       device='cuda:0') torch.Size([16])
percent tensor([0.4987, 0.4993, 0.4953, 0.4970, 0.4957, 0.5018, 0.4973, 0.4956, 0.4976,
        0.4981, 0.4995, 0.4963, 0.4994, 0.4983, 0.5004, 0.4996],
       device='cuda:0') torch.Size([16])
percent tensor([0.5113, 0.4798, 0.5058, 0.5195, 0.5129, 0.5387, 0.4884, 0.5045, 0.4957,
        0.4805, 0.4832, 0.4929, 0.4883, 0.4890, 0.5085, 0.5100],
       device='cuda:0') torch.Size([16])
percent tensor([0.5273, 0.5305, 0.5190, 0.5179, 0.5226, 0.5193, 0.5289, 0.5251, 0.5267,
        0.5277, 0.5304, 0.5230, 0.5317, 0.5276, 0.5283, 0.5257],
       device='cuda:0') torch.Size([16])
percent tensor([0.5429, 0.5298, 0.5719, 0.5663, 0.5778, 0.5447, 0.5466, 0.5756, 0.5418,
        0.5381, 0.5286, 0.5623, 0.5283, 0.5364, 0.5395, 0.5445],
       device='cuda:0') torch.Size([16])
percent tensor([0.5436, 0.5350, 0.5577, 0.5588, 0.5590, 0.5503, 0.5430, 0.5611, 0.5411,
        0.5387, 0.5347, 0.5487, 0.5372, 0.5397, 0.5419, 0.5455],
       device='cuda:0') torch.Size([16])
percent tensor([0.5142, 0.5073, 0.5330, 0.5278, 0.5311, 0.4940, 0.5210, 0.5373, 0.5127,
        0.5198, 0.5116, 0.5259, 0.5012, 0.5085, 0.5061, 0.5119],
       device='cuda:0') torch.Size([16])
percent tensor([0.8836, 0.7732, 0.8604, 0.8635, 0.8655, 0.8380, 0.8504, 0.9081, 0.7650,
        0.8183, 0.8018, 0.8645, 0.8068, 0.7974, 0.8290, 0.8965],
       device='cuda:0') torch.Size([16])
Epoch: 16 | Batch_idx: 0 |  Loss: (0.7147) |  Loss2: (0.0000) | Acc: (75.00%) (96/128)
Epoch: 16 | Batch_idx: 10 |  Loss: (0.7693) |  Loss2: (0.0000) | Acc: (73.00%) (1034/1408)
Epoch: 16 | Batch_idx: 20 |  Loss: (0.7677) |  Loss2: (0.0000) | Acc: (73.00%) (1967/2688)
Epoch: 16 | Batch_idx: 30 |  Loss: (0.7829) |  Loss2: (0.0000) | Acc: (72.00%) (2867/3968)
Epoch: 16 | Batch_idx: 40 |  Loss: (0.7861) |  Loss2: (0.0000) | Acc: (72.00%) (3784/5248)
Epoch: 16 | Batch_idx: 50 |  Loss: (0.7897) |  Loss2: (0.0000) | Acc: (71.00%) (4694/6528)
Epoch: 16 | Batch_idx: 60 |  Loss: (0.7898) |  Loss2: (0.0000) | Acc: (72.00%) (5623/7808)
Epoch: 16 | Batch_idx: 70 |  Loss: (0.7836) |  Loss2: (0.0000) | Acc: (72.00%) (6562/9088)
Epoch: 16 | Batch_idx: 80 |  Loss: (0.7886) |  Loss2: (0.0000) | Acc: (71.00%) (7463/10368)
Epoch: 16 | Batch_idx: 90 |  Loss: (0.7920) |  Loss2: (0.0000) | Acc: (71.00%) (8371/11648)
Epoch: 16 | Batch_idx: 100 |  Loss: (0.7927) |  Loss2: (0.0000) | Acc: (71.00%) (9305/12928)
Epoch: 16 | Batch_idx: 110 |  Loss: (0.7919) |  Loss2: (0.0000) | Acc: (72.00%) (10246/14208)
Epoch: 16 | Batch_idx: 120 |  Loss: (0.7966) |  Loss2: (0.0000) | Acc: (71.00%) (11138/15488)
Epoch: 16 | Batch_idx: 130 |  Loss: (0.8004) |  Loss2: (0.0000) | Acc: (71.00%) (12021/16768)
Epoch: 16 | Batch_idx: 140 |  Loss: (0.8009) |  Loss2: (0.0000) | Acc: (71.00%) (12959/18048)
Epoch: 16 | Batch_idx: 150 |  Loss: (0.8000) |  Loss2: (0.0000) | Acc: (71.00%) (13891/19328)
Epoch: 16 | Batch_idx: 160 |  Loss: (0.7989) |  Loss2: (0.0000) | Acc: (71.00%) (14816/20608)
Epoch: 16 | Batch_idx: 170 |  Loss: (0.7996) |  Loss2: (0.0000) | Acc: (71.00%) (15716/21888)
Epoch: 16 | Batch_idx: 180 |  Loss: (0.7971) |  Loss2: (0.0000) | Acc: (71.00%) (16661/23168)
Epoch: 16 | Batch_idx: 190 |  Loss: (0.7970) |  Loss2: (0.0000) | Acc: (71.00%) (17579/24448)
Epoch: 16 | Batch_idx: 200 |  Loss: (0.7980) |  Loss2: (0.0000) | Acc: (71.00%) (18504/25728)
Epoch: 16 | Batch_idx: 210 |  Loss: (0.7997) |  Loss2: (0.0000) | Acc: (71.00%) (19424/27008)
Epoch: 16 | Batch_idx: 220 |  Loss: (0.7966) |  Loss2: (0.0000) | Acc: (71.00%) (20350/28288)
Epoch: 16 | Batch_idx: 230 |  Loss: (0.7974) |  Loss2: (0.0000) | Acc: (71.00%) (21278/29568)
Epoch: 16 | Batch_idx: 240 |  Loss: (0.7971) |  Loss2: (0.0000) | Acc: (71.00%) (22202/30848)
Epoch: 16 | Batch_idx: 250 |  Loss: (0.7962) |  Loss2: (0.0000) | Acc: (71.00%) (23116/32128)
Epoch: 16 | Batch_idx: 260 |  Loss: (0.7970) |  Loss2: (0.0000) | Acc: (71.00%) (24028/33408)
Epoch: 16 | Batch_idx: 270 |  Loss: (0.7968) |  Loss2: (0.0000) | Acc: (71.00%) (24969/34688)
Epoch: 16 | Batch_idx: 280 |  Loss: (0.7966) |  Loss2: (0.0000) | Acc: (72.00%) (25903/35968)
Epoch: 16 | Batch_idx: 290 |  Loss: (0.7955) |  Loss2: (0.0000) | Acc: (72.00%) (26845/37248)
Epoch: 16 | Batch_idx: 300 |  Loss: (0.7925) |  Loss2: (0.0000) | Acc: (72.00%) (27803/38528)
Epoch: 16 | Batch_idx: 310 |  Loss: (0.7927) |  Loss2: (0.0000) | Acc: (72.00%) (28723/39808)
Epoch: 16 | Batch_idx: 320 |  Loss: (0.7915) |  Loss2: (0.0000) | Acc: (72.00%) (29669/41088)
Epoch: 16 | Batch_idx: 330 |  Loss: (0.7915) |  Loss2: (0.0000) | Acc: (72.00%) (30581/42368)
Epoch: 16 | Batch_idx: 340 |  Loss: (0.7899) |  Loss2: (0.0000) | Acc: (72.00%) (31524/43648)
Epoch: 16 | Batch_idx: 350 |  Loss: (0.7894) |  Loss2: (0.0000) | Acc: (72.00%) (32458/44928)
Epoch: 16 | Batch_idx: 360 |  Loss: (0.7881) |  Loss2: (0.0000) | Acc: (72.00%) (33402/46208)
Epoch: 16 | Batch_idx: 370 |  Loss: (0.7870) |  Loss2: (0.0000) | Acc: (72.00%) (34347/47488)
Epoch: 16 | Batch_idx: 380 |  Loss: (0.7876) |  Loss2: (0.0000) | Acc: (72.00%) (35273/48768)
Epoch: 16 | Batch_idx: 390 |  Loss: (0.7878) |  Loss2: (0.0000) | Acc: (72.00%) (36153/50000)
# TEST : Loss: (0.8309) | Acc: (70.00%) (7068/10000)
percent tensor([0.5004, 0.4984, 0.5002, 0.5004, 0.5004, 0.5014, 0.4995, 0.4997, 0.4999,
        0.4992, 0.4993, 0.5002, 0.4999, 0.4984, 0.4995, 0.4998],
       device='cuda:0') torch.Size([16])
percent tensor([0.4988, 0.4993, 0.4966, 0.4975, 0.4967, 0.5019, 0.4978, 0.4961, 0.4979,
        0.4982, 0.4994, 0.4974, 0.4997, 0.4982, 0.5003, 0.4999],
       device='cuda:0') torch.Size([16])
percent tensor([0.5077, 0.4777, 0.5094, 0.5205, 0.5153, 0.5384, 0.4878, 0.5055, 0.4938,
        0.4775, 0.4788, 0.4922, 0.4834, 0.4879, 0.5079, 0.5081],
       device='cuda:0') torch.Size([16])
percent tensor([0.5269, 0.5290, 0.5199, 0.5189, 0.5227, 0.5172, 0.5280, 0.5243, 0.5263,
        0.5284, 0.5298, 0.5248, 0.5321, 0.5270, 0.5273, 0.5249],
       device='cuda:0') torch.Size([16])
percent tensor([0.5376, 0.5290, 0.5587, 0.5626, 0.5668, 0.5462, 0.5408, 0.5677, 0.5368,
        0.5340, 0.5287, 0.5518, 0.5265, 0.5368, 0.5397, 0.5417],
       device='cuda:0') torch.Size([16])
percent tensor([0.5427, 0.5356, 0.5484, 0.5556, 0.5520, 0.5478, 0.5399, 0.5556, 0.5381,
        0.5381, 0.5366, 0.5414, 0.5378, 0.5417, 0.5402, 0.5444],
       device='cuda:0') torch.Size([16])
percent tensor([0.5154, 0.5107, 0.5255, 0.5241, 0.5257, 0.4962, 0.5202, 0.5335, 0.5146,
        0.5196, 0.5146, 0.5192, 0.4991, 0.5106, 0.5079, 0.5115],
       device='cuda:0') torch.Size([16])
percent tensor([0.8728, 0.7861, 0.8462, 0.8423, 0.8548, 0.7998, 0.8413, 0.9071, 0.7730,
        0.8132, 0.7954, 0.8646, 0.7902, 0.7743, 0.7888, 0.8745],
       device='cuda:0') torch.Size([16])
Epoch: 17 | Batch_idx: 0 |  Loss: (0.8525) |  Loss2: (0.0000) | Acc: (73.00%) (94/128)
Epoch: 17 | Batch_idx: 10 |  Loss: (0.7894) |  Loss2: (0.0000) | Acc: (72.00%) (1020/1408)
Epoch: 17 | Batch_idx: 20 |  Loss: (0.7763) |  Loss2: (0.0000) | Acc: (72.00%) (1962/2688)
Epoch: 17 | Batch_idx: 30 |  Loss: (0.7733) |  Loss2: (0.0000) | Acc: (73.00%) (2910/3968)
Epoch: 17 | Batch_idx: 40 |  Loss: (0.7662) |  Loss2: (0.0000) | Acc: (73.00%) (3855/5248)
Epoch: 17 | Batch_idx: 50 |  Loss: (0.7680) |  Loss2: (0.0000) | Acc: (73.00%) (4786/6528)
Epoch: 17 | Batch_idx: 60 |  Loss: (0.7600) |  Loss2: (0.0000) | Acc: (73.00%) (5743/7808)
Epoch: 17 | Batch_idx: 70 |  Loss: (0.7636) |  Loss2: (0.0000) | Acc: (73.00%) (6680/9088)
Epoch: 17 | Batch_idx: 80 |  Loss: (0.7623) |  Loss2: (0.0000) | Acc: (73.00%) (7616/10368)
Epoch: 17 | Batch_idx: 90 |  Loss: (0.7571) |  Loss2: (0.0000) | Acc: (73.00%) (8576/11648)
Epoch: 17 | Batch_idx: 100 |  Loss: (0.7557) |  Loss2: (0.0000) | Acc: (73.00%) (9526/12928)
Epoch: 17 | Batch_idx: 110 |  Loss: (0.7554) |  Loss2: (0.0000) | Acc: (73.00%) (10457/14208)
Epoch: 17 | Batch_idx: 120 |  Loss: (0.7498) |  Loss2: (0.0000) | Acc: (73.00%) (11438/15488)
Epoch: 17 | Batch_idx: 130 |  Loss: (0.7465) |  Loss2: (0.0000) | Acc: (73.00%) (12405/16768)
Epoch: 17 | Batch_idx: 140 |  Loss: (0.7470) |  Loss2: (0.0000) | Acc: (73.00%) (13335/18048)
Epoch: 17 | Batch_idx: 150 |  Loss: (0.7476) |  Loss2: (0.0000) | Acc: (73.00%) (14280/19328)
Epoch: 17 | Batch_idx: 160 |  Loss: (0.7461) |  Loss2: (0.0000) | Acc: (73.00%) (15234/20608)
Epoch: 17 | Batch_idx: 170 |  Loss: (0.7486) |  Loss2: (0.0000) | Acc: (73.00%) (16153/21888)
Epoch: 17 | Batch_idx: 180 |  Loss: (0.7472) |  Loss2: (0.0000) | Acc: (73.00%) (17121/23168)
Epoch: 17 | Batch_idx: 190 |  Loss: (0.7453) |  Loss2: (0.0000) | Acc: (73.00%) (18070/24448)
Epoch: 17 | Batch_idx: 200 |  Loss: (0.7441) |  Loss2: (0.0000) | Acc: (73.00%) (19036/25728)
Epoch: 17 | Batch_idx: 210 |  Loss: (0.7445) |  Loss2: (0.0000) | Acc: (73.00%) (19979/27008)
Epoch: 17 | Batch_idx: 220 |  Loss: (0.7445) |  Loss2: (0.0000) | Acc: (73.00%) (20924/28288)
Epoch: 17 | Batch_idx: 230 |  Loss: (0.7456) |  Loss2: (0.0000) | Acc: (73.00%) (21858/29568)
Epoch: 17 | Batch_idx: 240 |  Loss: (0.7458) |  Loss2: (0.0000) | Acc: (73.00%) (22806/30848)
Epoch: 17 | Batch_idx: 250 |  Loss: (0.7467) |  Loss2: (0.0000) | Acc: (73.00%) (23723/32128)
Epoch: 17 | Batch_idx: 260 |  Loss: (0.7459) |  Loss2: (0.0000) | Acc: (73.00%) (24677/33408)
Epoch: 17 | Batch_idx: 270 |  Loss: (0.7455) |  Loss2: (0.0000) | Acc: (73.00%) (25642/34688)
Epoch: 17 | Batch_idx: 280 |  Loss: (0.7446) |  Loss2: (0.0000) | Acc: (73.00%) (26597/35968)
Epoch: 17 | Batch_idx: 290 |  Loss: (0.7436) |  Loss2: (0.0000) | Acc: (74.00%) (27565/37248)
Epoch: 17 | Batch_idx: 300 |  Loss: (0.7439) |  Loss2: (0.0000) | Acc: (74.00%) (28512/38528)
Epoch: 17 | Batch_idx: 310 |  Loss: (0.7426) |  Loss2: (0.0000) | Acc: (74.00%) (29467/39808)
Epoch: 17 | Batch_idx: 320 |  Loss: (0.7426) |  Loss2: (0.0000) | Acc: (73.00%) (30404/41088)
Epoch: 17 | Batch_idx: 330 |  Loss: (0.7415) |  Loss2: (0.0000) | Acc: (74.00%) (31388/42368)
Epoch: 17 | Batch_idx: 340 |  Loss: (0.7401) |  Loss2: (0.0000) | Acc: (74.00%) (32373/43648)
Epoch: 17 | Batch_idx: 350 |  Loss: (0.7397) |  Loss2: (0.0000) | Acc: (74.00%) (33335/44928)
Epoch: 17 | Batch_idx: 360 |  Loss: (0.7390) |  Loss2: (0.0000) | Acc: (74.00%) (34289/46208)
Epoch: 17 | Batch_idx: 370 |  Loss: (0.7403) |  Loss2: (0.0000) | Acc: (74.00%) (35213/47488)
Epoch: 17 | Batch_idx: 380 |  Loss: (0.7406) |  Loss2: (0.0000) | Acc: (74.00%) (36163/48768)
Epoch: 17 | Batch_idx: 390 |  Loss: (0.7407) |  Loss2: (0.0000) | Acc: (74.00%) (37087/50000)
# TEST : Loss: (0.8469) | Acc: (70.00%) (7031/10000)
percent tensor([0.5005, 0.4985, 0.5002, 0.5003, 0.5004, 0.5015, 0.4995, 0.4996, 0.5000,
        0.4992, 0.4994, 0.5003, 0.5001, 0.4986, 0.4996, 0.4998],
       device='cuda:0') torch.Size([16])
percent tensor([0.4990, 0.4994, 0.4963, 0.4977, 0.4965, 0.5020, 0.4978, 0.4959, 0.4982,
        0.4983, 0.4998, 0.4972, 0.4998, 0.4988, 0.5004, 0.5000],
       device='cuda:0') torch.Size([16])
percent tensor([0.5091, 0.4783, 0.5102, 0.5204, 0.5159, 0.5367, 0.4886, 0.5074, 0.4960,
        0.4775, 0.4800, 0.4939, 0.4850, 0.4891, 0.5078, 0.5088],
       device='cuda:0') torch.Size([16])
percent tensor([0.5260, 0.5301, 0.5209, 0.5191, 0.5231, 0.5160, 0.5285, 0.5246, 0.5264,
        0.5298, 0.5306, 0.5254, 0.5321, 0.5273, 0.5274, 0.5248],
       device='cuda:0') torch.Size([16])
percent tensor([0.5364, 0.5293, 0.5605, 0.5642, 0.5686, 0.5436, 0.5409, 0.5691, 0.5367,
        0.5339, 0.5279, 0.5534, 0.5271, 0.5381, 0.5386, 0.5409],
       device='cuda:0') torch.Size([16])
percent tensor([0.5425, 0.5344, 0.5510, 0.5571, 0.5531, 0.5464, 0.5397, 0.5568, 0.5399,
        0.5372, 0.5364, 0.5435, 0.5378, 0.5421, 0.5390, 0.5430],
       device='cuda:0') torch.Size([16])
percent tensor([0.5110, 0.5093, 0.5281, 0.5291, 0.5260, 0.4956, 0.5171, 0.5331, 0.5096,
        0.5191, 0.5106, 0.5227, 0.4962, 0.5091, 0.5085, 0.5087],
       device='cuda:0') torch.Size([16])
percent tensor([0.8625, 0.7843, 0.8505, 0.8534, 0.8756, 0.7888, 0.8282, 0.8875, 0.7663,
        0.8160, 0.7970, 0.8695, 0.7967, 0.7801, 0.7925, 0.8556],
       device='cuda:0') torch.Size([16])
False Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=128, out_features=16, bias=False)
True Linear(in_features=16, out_features=2, bias=False)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=128, out_features=16, bias=False)
True Linear(in_features=16, out_features=2, bias=False)
False Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=256, out_features=32, bias=False)
True Linear(in_features=32, out_features=2, bias=False)
False Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=256, out_features=32, bias=False)
True Linear(in_features=32, out_features=2, bias=False)
False Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=512, out_features=64, bias=False)
True Linear(in_features=64, out_features=2, bias=False)
False Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=512, out_features=64, bias=False)
True Linear(in_features=64, out_features=2, bias=False)
False Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1024, out_features=128, bias=False)
True Linear(in_features=128, out_features=2, bias=False)
False Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1024, out_features=128, bias=False)
True Linear(in_features=128, out_features=2, bias=False)
False Linear(in_features=512, out_features=10, bias=True)
Epoch: 18 | Batch_idx: 0 |  Loss: (0.6713) |  Loss2: (0.0000) | Acc: (75.00%) (97/128)
Epoch: 18 | Batch_idx: 10 |  Loss: (0.7886) |  Loss2: (0.0000) | Acc: (71.00%) (1013/1408)
Epoch: 18 | Batch_idx: 20 |  Loss: (0.8428) |  Loss2: (0.0000) | Acc: (70.00%) (1882/2688)
Epoch: 18 | Batch_idx: 30 |  Loss: (0.8437) |  Loss2: (0.0000) | Acc: (70.00%) (2786/3968)
Epoch: 18 | Batch_idx: 40 |  Loss: (0.8643) |  Loss2: (0.0000) | Acc: (69.00%) (3645/5248)
Epoch: 18 | Batch_idx: 50 |  Loss: (0.8755) |  Loss2: (0.0000) | Acc: (68.00%) (4493/6528)
Epoch: 18 | Batch_idx: 60 |  Loss: (0.8744) |  Loss2: (0.0000) | Acc: (68.00%) (5380/7808)
Epoch: 18 | Batch_idx: 70 |  Loss: (0.8736) |  Loss2: (0.0000) | Acc: (68.00%) (6260/9088)
Epoch: 18 | Batch_idx: 80 |  Loss: (0.8797) |  Loss2: (0.0000) | Acc: (68.00%) (7144/10368)
Epoch: 18 | Batch_idx: 90 |  Loss: (0.8756) |  Loss2: (0.0000) | Acc: (68.00%) (8036/11648)
Epoch: 18 | Batch_idx: 100 |  Loss: (0.8725) |  Loss2: (0.0000) | Acc: (69.00%) (8923/12928)
Epoch: 18 | Batch_idx: 110 |  Loss: (0.8699) |  Loss2: (0.0000) | Acc: (69.00%) (9812/14208)
Epoch: 18 | Batch_idx: 120 |  Loss: (0.8713) |  Loss2: (0.0000) | Acc: (69.00%) (10701/15488)
Epoch: 18 | Batch_idx: 130 |  Loss: (0.8718) |  Loss2: (0.0000) | Acc: (69.00%) (11588/16768)
Epoch: 18 | Batch_idx: 140 |  Loss: (0.8675) |  Loss2: (0.0000) | Acc: (69.00%) (12489/18048)
Epoch: 18 | Batch_idx: 150 |  Loss: (0.8643) |  Loss2: (0.0000) | Acc: (69.00%) (13406/19328)
Epoch: 18 | Batch_idx: 160 |  Loss: (0.8652) |  Loss2: (0.0000) | Acc: (69.00%) (14287/20608)
Epoch: 18 | Batch_idx: 170 |  Loss: (0.8659) |  Loss2: (0.0000) | Acc: (69.00%) (15171/21888)
Epoch: 18 | Batch_idx: 180 |  Loss: (0.8627) |  Loss2: (0.0000) | Acc: (69.00%) (16085/23168)
Epoch: 18 | Batch_idx: 190 |  Loss: (0.8610) |  Loss2: (0.0000) | Acc: (69.00%) (16995/24448)
Epoch: 18 | Batch_idx: 200 |  Loss: (0.8581) |  Loss2: (0.0000) | Acc: (69.00%) (17916/25728)
Epoch: 18 | Batch_idx: 210 |  Loss: (0.8578) |  Loss2: (0.0000) | Acc: (69.00%) (18818/27008)
Epoch: 18 | Batch_idx: 220 |  Loss: (0.8549) |  Loss2: (0.0000) | Acc: (69.00%) (19729/28288)
Epoch: 18 | Batch_idx: 230 |  Loss: (0.8503) |  Loss2: (0.0000) | Acc: (69.00%) (20647/29568)
Epoch: 18 | Batch_idx: 240 |  Loss: (0.8455) |  Loss2: (0.0000) | Acc: (69.00%) (21579/30848)
Epoch: 18 | Batch_idx: 250 |  Loss: (0.8434) |  Loss2: (0.0000) | Acc: (70.00%) (22497/32128)
Epoch: 18 | Batch_idx: 260 |  Loss: (0.8408) |  Loss2: (0.0000) | Acc: (70.00%) (23435/33408)
Epoch: 18 | Batch_idx: 270 |  Loss: (0.8371) |  Loss2: (0.0000) | Acc: (70.00%) (24392/34688)
Epoch: 18 | Batch_idx: 280 |  Loss: (0.8341) |  Loss2: (0.0000) | Acc: (70.00%) (25323/35968)
Epoch: 18 | Batch_idx: 290 |  Loss: (0.8323) |  Loss2: (0.0000) | Acc: (70.00%) (26240/37248)
Epoch: 18 | Batch_idx: 300 |  Loss: (0.8316) |  Loss2: (0.0000) | Acc: (70.00%) (27152/38528)
Epoch: 18 | Batch_idx: 310 |  Loss: (0.8281) |  Loss2: (0.0000) | Acc: (70.00%) (28096/39808)
Epoch: 18 | Batch_idx: 320 |  Loss: (0.8269) |  Loss2: (0.0000) | Acc: (70.00%) (29016/41088)
Epoch: 18 | Batch_idx: 330 |  Loss: (0.8264) |  Loss2: (0.0000) | Acc: (70.00%) (29948/42368)
Epoch: 18 | Batch_idx: 340 |  Loss: (0.8243) |  Loss2: (0.0000) | Acc: (70.00%) (30889/43648)
Epoch: 18 | Batch_idx: 350 |  Loss: (0.8240) |  Loss2: (0.0000) | Acc: (70.00%) (31797/44928)
Epoch: 18 | Batch_idx: 360 |  Loss: (0.8217) |  Loss2: (0.0000) | Acc: (70.00%) (32737/46208)
Epoch: 18 | Batch_idx: 370 |  Loss: (0.8205) |  Loss2: (0.0000) | Acc: (70.00%) (33667/47488)
Epoch: 18 | Batch_idx: 380 |  Loss: (0.8193) |  Loss2: (0.0000) | Acc: (70.00%) (34601/48768)
Epoch: 18 | Batch_idx: 390 |  Loss: (0.8179) |  Loss2: (0.0000) | Acc: (71.00%) (35506/50000)
# TEST : Loss: (0.7920) | Acc: (72.00%) (7245/10000)
percent tensor([0.5011, 0.4993, 0.5013, 0.5011, 0.5013, 0.5021, 0.5004, 0.5008, 0.5007,
        0.5002, 0.5001, 0.5012, 0.5009, 0.4991, 0.5005, 0.5007],
       device='cuda:0') torch.Size([16])
percent tensor([0.4950, 0.4913, 0.4890, 0.4925, 0.4893, 0.4982, 0.4897, 0.4893, 0.4922,
        0.4900, 0.4937, 0.4891, 0.4945, 0.4930, 0.4940, 0.4949],
       device='cuda:0') torch.Size([16])
percent tensor([0.5039, 0.4852, 0.5029, 0.5140, 0.5093, 0.5308, 0.4914, 0.5050, 0.4929,
        0.4814, 0.4822, 0.4903, 0.4838, 0.4886, 0.5086, 0.5053],
       device='cuda:0') torch.Size([16])
percent tensor([0.5639, 0.5651, 0.5585, 0.5579, 0.5635, 0.5568, 0.5659, 0.5662, 0.5605,
        0.5642, 0.5632, 0.5619, 0.5666, 0.5579, 0.5665, 0.5649],
       device='cuda:0') torch.Size([16])
percent tensor([0.5310, 0.5210, 0.5456, 0.5564, 0.5519, 0.5473, 0.5297, 0.5560, 0.5248,
        0.5264, 0.5177, 0.5418, 0.5212, 0.5230, 0.5333, 0.5376],
       device='cuda:0') torch.Size([16])
percent tensor([0.5394, 0.5290, 0.5473, 0.5613, 0.5500, 0.5531, 0.5330, 0.5530, 0.5351,
        0.5328, 0.5299, 0.5374, 0.5319, 0.5355, 0.5313, 0.5408],
       device='cuda:0') torch.Size([16])
percent tensor([0.5039, 0.5024, 0.5156, 0.5180, 0.5147, 0.4943, 0.5087, 0.5158, 0.5060,
        0.5097, 0.5047, 0.5117, 0.4949, 0.5016, 0.4995, 0.5022],
       device='cuda:0') torch.Size([16])
percent tensor([0.9284, 0.8443, 0.8579, 0.8692, 0.8794, 0.8800, 0.8792, 0.9044, 0.8521,
        0.8667, 0.8775, 0.8857, 0.8865, 0.8525, 0.8422, 0.9286],
       device='cuda:0') torch.Size([16])
Epoch: 19 | Batch_idx: 0 |  Loss: (0.8855) |  Loss2: (0.0000) | Acc: (67.00%) (87/128)
Epoch: 19 | Batch_idx: 10 |  Loss: (0.7664) |  Loss2: (0.0000) | Acc: (72.00%) (1024/1408)
Epoch: 19 | Batch_idx: 20 |  Loss: (0.7546) |  Loss2: (0.0000) | Acc: (72.00%) (1950/2688)
Epoch: 19 | Batch_idx: 30 |  Loss: (0.7597) |  Loss2: (0.0000) | Acc: (72.00%) (2886/3968)
Epoch: 19 | Batch_idx: 40 |  Loss: (0.7670) |  Loss2: (0.0000) | Acc: (72.00%) (3827/5248)
Epoch: 19 | Batch_idx: 50 |  Loss: (0.7605) |  Loss2: (0.0000) | Acc: (73.00%) (4781/6528)
Epoch: 19 | Batch_idx: 60 |  Loss: (0.7582) |  Loss2: (0.0000) | Acc: (73.00%) (5731/7808)
Epoch: 19 | Batch_idx: 70 |  Loss: (0.7576) |  Loss2: (0.0000) | Acc: (73.00%) (6659/9088)
Epoch: 19 | Batch_idx: 80 |  Loss: (0.7599) |  Loss2: (0.0000) | Acc: (73.00%) (7601/10368)
Epoch: 19 | Batch_idx: 90 |  Loss: (0.7582) |  Loss2: (0.0000) | Acc: (73.00%) (8546/11648)
Epoch: 19 | Batch_idx: 100 |  Loss: (0.7579) |  Loss2: (0.0000) | Acc: (73.00%) (9485/12928)
Epoch: 19 | Batch_idx: 110 |  Loss: (0.7578) |  Loss2: (0.0000) | Acc: (73.00%) (10413/14208)
Epoch: 19 | Batch_idx: 120 |  Loss: (0.7560) |  Loss2: (0.0000) | Acc: (73.00%) (11354/15488)
Epoch: 19 | Batch_idx: 130 |  Loss: (0.7529) |  Loss2: (0.0000) | Acc: (73.00%) (12307/16768)
Epoch: 19 | Batch_idx: 140 |  Loss: (0.7500) |  Loss2: (0.0000) | Acc: (73.00%) (13251/18048)
Epoch: 19 | Batch_idx: 150 |  Loss: (0.7519) |  Loss2: (0.0000) | Acc: (73.00%) (14185/19328)
Epoch: 19 | Batch_idx: 160 |  Loss: (0.7515) |  Loss2: (0.0000) | Acc: (73.00%) (15125/20608)
Epoch: 19 | Batch_idx: 170 |  Loss: (0.7518) |  Loss2: (0.0000) | Acc: (73.00%) (16053/21888)
Epoch: 19 | Batch_idx: 180 |  Loss: (0.7503) |  Loss2: (0.0000) | Acc: (73.00%) (17004/23168)
Epoch: 19 | Batch_idx: 190 |  Loss: (0.7499) |  Loss2: (0.0000) | Acc: (73.00%) (17931/24448)
Epoch: 19 | Batch_idx: 200 |  Loss: (0.7498) |  Loss2: (0.0000) | Acc: (73.00%) (18870/25728)
Epoch: 19 | Batch_idx: 210 |  Loss: (0.7501) |  Loss2: (0.0000) | Acc: (73.00%) (19804/27008)
Epoch: 19 | Batch_idx: 220 |  Loss: (0.7500) |  Loss2: (0.0000) | Acc: (73.00%) (20742/28288)
Epoch: 19 | Batch_idx: 230 |  Loss: (0.7494) |  Loss2: (0.0000) | Acc: (73.00%) (21692/29568)
Epoch: 19 | Batch_idx: 240 |  Loss: (0.7482) |  Loss2: (0.0000) | Acc: (73.00%) (22636/30848)
Epoch: 19 | Batch_idx: 250 |  Loss: (0.7483) |  Loss2: (0.0000) | Acc: (73.00%) (23580/32128)
Epoch: 19 | Batch_idx: 260 |  Loss: (0.7476) |  Loss2: (0.0000) | Acc: (73.00%) (24537/33408)
Epoch: 19 | Batch_idx: 270 |  Loss: (0.7478) |  Loss2: (0.0000) | Acc: (73.00%) (25490/34688)
Epoch: 19 | Batch_idx: 280 |  Loss: (0.7468) |  Loss2: (0.0000) | Acc: (73.00%) (26451/35968)
Epoch: 19 | Batch_idx: 290 |  Loss: (0.7467) |  Loss2: (0.0000) | Acc: (73.00%) (27400/37248)
Epoch: 19 | Batch_idx: 300 |  Loss: (0.7469) |  Loss2: (0.0000) | Acc: (73.00%) (28335/38528)
Epoch: 19 | Batch_idx: 310 |  Loss: (0.7464) |  Loss2: (0.0000) | Acc: (73.00%) (29278/39808)
Epoch: 19 | Batch_idx: 320 |  Loss: (0.7470) |  Loss2: (0.0000) | Acc: (73.00%) (30200/41088)
Epoch: 19 | Batch_idx: 330 |  Loss: (0.7465) |  Loss2: (0.0000) | Acc: (73.00%) (31138/42368)
Epoch: 19 | Batch_idx: 340 |  Loss: (0.7465) |  Loss2: (0.0000) | Acc: (73.00%) (32101/43648)
Epoch: 19 | Batch_idx: 350 |  Loss: (0.7461) |  Loss2: (0.0000) | Acc: (73.00%) (33048/44928)
Epoch: 19 | Batch_idx: 360 |  Loss: (0.7455) |  Loss2: (0.0000) | Acc: (73.00%) (34014/46208)
Epoch: 19 | Batch_idx: 370 |  Loss: (0.7462) |  Loss2: (0.0000) | Acc: (73.00%) (34958/47488)
Epoch: 19 | Batch_idx: 380 |  Loss: (0.7463) |  Loss2: (0.0000) | Acc: (73.00%) (35901/48768)
Epoch: 19 | Batch_idx: 390 |  Loss: (0.7454) |  Loss2: (0.0000) | Acc: (73.00%) (36823/50000)
# TEST : Loss: (0.7638) | Acc: (73.00%) (7346/10000)
percent tensor([0.5020, 0.5002, 0.5023, 0.5021, 0.5023, 0.5032, 0.5013, 0.5019, 0.5016,
        0.5012, 0.5010, 0.5022, 0.5018, 0.4999, 0.5015, 0.5018],
       device='cuda:0') torch.Size([16])
percent tensor([0.4947, 0.4895, 0.4880, 0.4921, 0.4883, 0.4980, 0.4881, 0.4878, 0.4914,
        0.4885, 0.4927, 0.4879, 0.4939, 0.4920, 0.4929, 0.4943],
       device='cuda:0') torch.Size([16])
percent tensor([0.5037, 0.4853, 0.5033, 0.5146, 0.5104, 0.5312, 0.4918, 0.5055, 0.4921,
        0.4810, 0.4806, 0.4906, 0.4823, 0.4889, 0.5089, 0.5059],
       device='cuda:0') torch.Size([16])
percent tensor([0.5769, 0.5729, 0.5708, 0.5727, 0.5773, 0.5734, 0.5755, 0.5806, 0.5693,
        0.5719, 0.5703, 0.5719, 0.5750, 0.5643, 0.5784, 0.5789],
       device='cuda:0') torch.Size([16])
percent tensor([0.5307, 0.5177, 0.5380, 0.5538, 0.5435, 0.5529, 0.5237, 0.5473, 0.5196,
        0.5235, 0.5135, 0.5371, 0.5203, 0.5208, 0.5303, 0.5402],
       device='cuda:0') torch.Size([16])
percent tensor([0.5448, 0.5322, 0.5533, 0.5708, 0.5556, 0.5626, 0.5362, 0.5577, 0.5397,
        0.5370, 0.5328, 0.5410, 0.5354, 0.5420, 0.5326, 0.5467],
       device='cuda:0') torch.Size([16])
percent tensor([0.5035, 0.5028, 0.5129, 0.5151, 0.5126, 0.4956, 0.5078, 0.5118, 0.5059,
        0.5091, 0.5041, 0.5101, 0.4982, 0.5020, 0.4984, 0.5028],
       device='cuda:0') torch.Size([16])
percent tensor([0.9615, 0.8985, 0.8948, 0.9119, 0.9072, 0.9279, 0.9249, 0.9374, 0.9082,
        0.9190, 0.9304, 0.9260, 0.9386, 0.9070, 0.8987, 0.9623],
       device='cuda:0') torch.Size([16])
Epoch: 20 | Batch_idx: 0 |  Loss: (0.6861) |  Loss2: (0.0000) | Acc: (75.00%) (96/128)
Epoch: 20 | Batch_idx: 10 |  Loss: (0.7700) |  Loss2: (0.0000) | Acc: (72.00%) (1023/1408)
Epoch: 20 | Batch_idx: 20 |  Loss: (0.7578) |  Loss2: (0.0000) | Acc: (73.00%) (1977/2688)
Epoch: 20 | Batch_idx: 30 |  Loss: (0.7429) |  Loss2: (0.0000) | Acc: (74.00%) (2937/3968)
Epoch: 20 | Batch_idx: 40 |  Loss: (0.7379) |  Loss2: (0.0000) | Acc: (73.00%) (3878/5248)
Epoch: 20 | Batch_idx: 50 |  Loss: (0.7355) |  Loss2: (0.0000) | Acc: (73.00%) (4822/6528)
Epoch: 20 | Batch_idx: 60 |  Loss: (0.7396) |  Loss2: (0.0000) | Acc: (73.00%) (5767/7808)
Epoch: 20 | Batch_idx: 70 |  Loss: (0.7451) |  Loss2: (0.0000) | Acc: (73.00%) (6689/9088)
Epoch: 20 | Batch_idx: 80 |  Loss: (0.7443) |  Loss2: (0.0000) | Acc: (73.00%) (7631/10368)
Epoch: 20 | Batch_idx: 90 |  Loss: (0.7420) |  Loss2: (0.0000) | Acc: (73.00%) (8588/11648)
Epoch: 20 | Batch_idx: 100 |  Loss: (0.7422) |  Loss2: (0.0000) | Acc: (73.00%) (9528/12928)
Epoch: 20 | Batch_idx: 110 |  Loss: (0.7428) |  Loss2: (0.0000) | Acc: (73.00%) (10469/14208)
Epoch: 20 | Batch_idx: 120 |  Loss: (0.7413) |  Loss2: (0.0000) | Acc: (73.00%) (11432/15488)
Epoch: 20 | Batch_idx: 130 |  Loss: (0.7412) |  Loss2: (0.0000) | Acc: (73.00%) (12390/16768)
Epoch: 20 | Batch_idx: 140 |  Loss: (0.7425) |  Loss2: (0.0000) | Acc: (73.00%) (13316/18048)
Epoch: 20 | Batch_idx: 150 |  Loss: (0.7401) |  Loss2: (0.0000) | Acc: (73.00%) (14273/19328)
Epoch: 20 | Batch_idx: 160 |  Loss: (0.7394) |  Loss2: (0.0000) | Acc: (73.00%) (15212/20608)
Epoch: 20 | Batch_idx: 170 |  Loss: (0.7403) |  Loss2: (0.0000) | Acc: (73.00%) (16133/21888)
Epoch: 20 | Batch_idx: 180 |  Loss: (0.7400) |  Loss2: (0.0000) | Acc: (73.00%) (17079/23168)
Epoch: 20 | Batch_idx: 190 |  Loss: (0.7375) |  Loss2: (0.0000) | Acc: (73.00%) (18038/24448)
Epoch: 20 | Batch_idx: 200 |  Loss: (0.7355) |  Loss2: (0.0000) | Acc: (73.00%) (18983/25728)
Epoch: 20 | Batch_idx: 210 |  Loss: (0.7328) |  Loss2: (0.0000) | Acc: (73.00%) (19974/27008)
Epoch: 20 | Batch_idx: 220 |  Loss: (0.7329) |  Loss2: (0.0000) | Acc: (73.00%) (20926/28288)
Epoch: 20 | Batch_idx: 230 |  Loss: (0.7323) |  Loss2: (0.0000) | Acc: (73.00%) (21879/29568)
Epoch: 20 | Batch_idx: 240 |  Loss: (0.7318) |  Loss2: (0.0000) | Acc: (74.00%) (22842/30848)
Epoch: 20 | Batch_idx: 250 |  Loss: (0.7314) |  Loss2: (0.0000) | Acc: (74.00%) (23782/32128)
Epoch: 20 | Batch_idx: 260 |  Loss: (0.7305) |  Loss2: (0.0000) | Acc: (74.00%) (24735/33408)
Epoch: 20 | Batch_idx: 270 |  Loss: (0.7315) |  Loss2: (0.0000) | Acc: (73.00%) (25658/34688)
Epoch: 20 | Batch_idx: 280 |  Loss: (0.7298) |  Loss2: (0.0000) | Acc: (74.00%) (26643/35968)
Epoch: 20 | Batch_idx: 290 |  Loss: (0.7300) |  Loss2: (0.0000) | Acc: (74.00%) (27595/37248)
Epoch: 20 | Batch_idx: 300 |  Loss: (0.7290) |  Loss2: (0.0000) | Acc: (74.00%) (28574/38528)
Epoch: 20 | Batch_idx: 310 |  Loss: (0.7280) |  Loss2: (0.0000) | Acc: (74.00%) (29547/39808)
Epoch: 20 | Batch_idx: 320 |  Loss: (0.7267) |  Loss2: (0.0000) | Acc: (74.00%) (30501/41088)
Epoch: 20 | Batch_idx: 330 |  Loss: (0.7260) |  Loss2: (0.0000) | Acc: (74.00%) (31469/42368)
Epoch: 20 | Batch_idx: 340 |  Loss: (0.7256) |  Loss2: (0.0000) | Acc: (74.00%) (32410/43648)
Epoch: 20 | Batch_idx: 350 |  Loss: (0.7263) |  Loss2: (0.0000) | Acc: (74.00%) (33345/44928)
Epoch: 20 | Batch_idx: 360 |  Loss: (0.7260) |  Loss2: (0.0000) | Acc: (74.00%) (34304/46208)
Epoch: 20 | Batch_idx: 370 |  Loss: (0.7264) |  Loss2: (0.0000) | Acc: (74.00%) (35256/47488)
Epoch: 20 | Batch_idx: 380 |  Loss: (0.7263) |  Loss2: (0.0000) | Acc: (74.00%) (36220/48768)
Epoch: 20 | Batch_idx: 390 |  Loss: (0.7258) |  Loss2: (0.0000) | Acc: (74.00%) (37160/50000)
=> saving checkpoint 'drive/app/torch/save_Schedule/checkpoint_020.pth.tar'
# TEST : Loss: (0.7416) | Acc: (74.00%) (7402/10000)
percent tensor([0.5033, 0.5017, 0.5034, 0.5035, 0.5035, 0.5048, 0.5027, 0.5034, 0.5028,
        0.5026, 0.5023, 0.5035, 0.5032, 0.5011, 0.5030, 0.5033],
       device='cuda:0') torch.Size([16])
percent tensor([0.4958, 0.4906, 0.4895, 0.4937, 0.4896, 0.4990, 0.4893, 0.4890, 0.4927,
        0.4898, 0.4938, 0.4893, 0.4952, 0.4931, 0.4940, 0.4954],
       device='cuda:0') torch.Size([16])
percent tensor([0.5009, 0.4831, 0.5028, 0.5156, 0.5104, 0.5318, 0.4901, 0.5052, 0.4896,
        0.4786, 0.4771, 0.4888, 0.4784, 0.4872, 0.5072, 0.5041],
       device='cuda:0') torch.Size([16])
percent tensor([0.5740, 0.5675, 0.5682, 0.5705, 0.5746, 0.5724, 0.5708, 0.5774, 0.5649,
        0.5665, 0.5646, 0.5675, 0.5699, 0.5589, 0.5745, 0.5764],
       device='cuda:0') torch.Size([16])
percent tensor([0.5276, 0.5146, 0.5300, 0.5496, 0.5358, 0.5548, 0.5183, 0.5397, 0.5142,
        0.5202, 0.5090, 0.5320, 0.5172, 0.5184, 0.5262, 0.5401],
       device='cuda:0') torch.Size([16])
percent tensor([0.5479, 0.5348, 0.5552, 0.5756, 0.5574, 0.5690, 0.5377, 0.5593, 0.5429,
        0.5403, 0.5351, 0.5423, 0.5386, 0.5468, 0.5323, 0.5501],
       device='cuda:0') torch.Size([16])
percent tensor([0.5046, 0.5044, 0.5126, 0.5145, 0.5126, 0.4974, 0.5083, 0.5116, 0.5072,
        0.5107, 0.5055, 0.5105, 0.5022, 0.5032, 0.4991, 0.5043],
       device='cuda:0') torch.Size([16])
percent tensor([0.9762, 0.9281, 0.9168, 0.9324, 0.9267, 0.9502, 0.9496, 0.9564, 0.9369,
        0.9452, 0.9529, 0.9449, 0.9604, 0.9337, 0.9296, 0.9769],
       device='cuda:0') torch.Size([16])
Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 3, 3, 3]) tensor(167.8844, device='cuda:0')
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(786.3612, device='cuda:0')
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(776.9703, device='cuda:0')
Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([128, 64, 3, 3]) tensor(1527.8711, device='cuda:0')
Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([128, 64, 1, 1]) tensor(507.8991, device='cuda:0')
Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([128, 128, 3, 3]) tensor(2176.3694, device='cuda:0')
Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([256, 128, 3, 3]) tensor(4315.1270, device='cuda:0')
Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([256, 128, 1, 1]) tensor(1436.5166, device='cuda:0')
Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([256, 256, 3, 3]) tensor(6102.7529, device='cuda:0')
Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([512, 256, 3, 3]) tensor(12172.3604, device='cuda:0')
Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([512, 256, 1, 1]) tensor(4057.1067, device='cuda:0')
Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([512, 512, 3, 3]) tensor(17200.1777, device='cuda:0')
Epoch: 21 | Batch_idx: 0 |  Loss: (0.6879) |  Loss2: (0.0000) | Acc: (75.00%) (96/128)
Epoch: 21 | Batch_idx: 10 |  Loss: (0.7266) |  Loss2: (0.0000) | Acc: (75.00%) (1056/1408)
Epoch: 21 | Batch_idx: 20 |  Loss: (0.7130) |  Loss2: (0.0000) | Acc: (75.00%) (2023/2688)
Epoch: 21 | Batch_idx: 30 |  Loss: (0.7137) |  Loss2: (0.0000) | Acc: (75.00%) (2982/3968)
Epoch: 21 | Batch_idx: 40 |  Loss: (0.7227) |  Loss2: (0.0000) | Acc: (74.00%) (3918/5248)
Epoch: 21 | Batch_idx: 50 |  Loss: (0.7219) |  Loss2: (0.0000) | Acc: (74.00%) (4875/6528)
Epoch: 21 | Batch_idx: 60 |  Loss: (0.7188) |  Loss2: (0.0000) | Acc: (74.00%) (5852/7808)
Epoch: 21 | Batch_idx: 70 |  Loss: (0.7152) |  Loss2: (0.0000) | Acc: (74.00%) (6809/9088)
Epoch: 21 | Batch_idx: 80 |  Loss: (0.7139) |  Loss2: (0.0000) | Acc: (74.00%) (7759/10368)
Epoch: 21 | Batch_idx: 90 |  Loss: (0.7145) |  Loss2: (0.0000) | Acc: (74.00%) (8696/11648)
Epoch: 21 | Batch_idx: 100 |  Loss: (0.7154) |  Loss2: (0.0000) | Acc: (74.00%) (9644/12928)
Epoch: 21 | Batch_idx: 110 |  Loss: (0.7117) |  Loss2: (0.0000) | Acc: (74.00%) (10618/14208)
Epoch: 21 | Batch_idx: 120 |  Loss: (0.7136) |  Loss2: (0.0000) | Acc: (74.00%) (11561/15488)
Epoch: 21 | Batch_idx: 130 |  Loss: (0.7160) |  Loss2: (0.0000) | Acc: (74.00%) (12509/16768)
Epoch: 21 | Batch_idx: 140 |  Loss: (0.7167) |  Loss2: (0.0000) | Acc: (74.00%) (13451/18048)
Epoch: 21 | Batch_idx: 150 |  Loss: (0.7152) |  Loss2: (0.0000) | Acc: (74.00%) (14428/19328)
Epoch: 21 | Batch_idx: 160 |  Loss: (0.7135) |  Loss2: (0.0000) | Acc: (74.00%) (15391/20608)
Epoch: 21 | Batch_idx: 170 |  Loss: (0.7160) |  Loss2: (0.0000) | Acc: (74.00%) (16352/21888)
Epoch: 21 | Batch_idx: 180 |  Loss: (0.7156) |  Loss2: (0.0000) | Acc: (74.00%) (17314/23168)
Epoch: 21 | Batch_idx: 190 |  Loss: (0.7136) |  Loss2: (0.0000) | Acc: (74.00%) (18280/24448)
Epoch: 21 | Batch_idx: 200 |  Loss: (0.7109) |  Loss2: (0.0000) | Acc: (74.00%) (19269/25728)
Epoch: 21 | Batch_idx: 210 |  Loss: (0.7099) |  Loss2: (0.0000) | Acc: (74.00%) (20225/27008)
Epoch: 21 | Batch_idx: 220 |  Loss: (0.7119) |  Loss2: (0.0000) | Acc: (74.00%) (21158/28288)
Epoch: 21 | Batch_idx: 230 |  Loss: (0.7100) |  Loss2: (0.0000) | Acc: (74.00%) (22145/29568)
Epoch: 21 | Batch_idx: 240 |  Loss: (0.7090) |  Loss2: (0.0000) | Acc: (74.00%) (23126/30848)
Epoch: 21 | Batch_idx: 250 |  Loss: (0.7070) |  Loss2: (0.0000) | Acc: (74.00%) (24090/32128)
Epoch: 21 | Batch_idx: 260 |  Loss: (0.7085) |  Loss2: (0.0000) | Acc: (74.00%) (25051/33408)
Epoch: 21 | Batch_idx: 270 |  Loss: (0.7075) |  Loss2: (0.0000) | Acc: (75.00%) (26030/34688)
Epoch: 21 | Batch_idx: 280 |  Loss: (0.7074) |  Loss2: (0.0000) | Acc: (75.00%) (26987/35968)
Epoch: 21 | Batch_idx: 290 |  Loss: (0.7073) |  Loss2: (0.0000) | Acc: (75.00%) (27947/37248)
Epoch: 21 | Batch_idx: 300 |  Loss: (0.7076) |  Loss2: (0.0000) | Acc: (74.00%) (28888/38528)
Epoch: 21 | Batch_idx: 310 |  Loss: (0.7085) |  Loss2: (0.0000) | Acc: (74.00%) (29822/39808)
Epoch: 21 | Batch_idx: 320 |  Loss: (0.7071) |  Loss2: (0.0000) | Acc: (74.00%) (30797/41088)
Epoch: 21 | Batch_idx: 330 |  Loss: (0.7084) |  Loss2: (0.0000) | Acc: (74.00%) (31746/42368)
Epoch: 21 | Batch_idx: 340 |  Loss: (0.7095) |  Loss2: (0.0000) | Acc: (74.00%) (32697/43648)
Epoch: 21 | Batch_idx: 350 |  Loss: (0.7084) |  Loss2: (0.0000) | Acc: (74.00%) (33660/44928)
Epoch: 21 | Batch_idx: 360 |  Loss: (0.7091) |  Loss2: (0.0000) | Acc: (74.00%) (34597/46208)
Epoch: 21 | Batch_idx: 370 |  Loss: (0.7097) |  Loss2: (0.0000) | Acc: (74.00%) (35554/47488)
Epoch: 21 | Batch_idx: 380 |  Loss: (0.7112) |  Loss2: (0.0000) | Acc: (74.00%) (36507/48768)
Epoch: 21 | Batch_idx: 390 |  Loss: (0.7119) |  Loss2: (0.0000) | Acc: (74.00%) (37411/50000)
# TEST : Loss: (0.7360) | Acc: (74.00%) (7449/10000)
percent tensor([0.5048, 0.5033, 0.5050, 0.5051, 0.5051, 0.5065, 0.5044, 0.5052, 0.5042,
        0.5044, 0.5039, 0.5052, 0.5048, 0.5024, 0.5047, 0.5049],
       device='cuda:0') torch.Size([16])
percent tensor([0.4966, 0.4914, 0.4903, 0.4947, 0.4903, 0.4997, 0.4901, 0.4895, 0.4936,
        0.4908, 0.4947, 0.4902, 0.4962, 0.4940, 0.4948, 0.4962],
       device='cuda:0') torch.Size([16])
percent tensor([0.5022, 0.4856, 0.5047, 0.5181, 0.5124, 0.5339, 0.4921, 0.5068, 0.4907,
        0.4806, 0.4782, 0.4905, 0.4796, 0.4893, 0.5096, 0.5063],
       device='cuda:0') torch.Size([16])
percent tensor([0.5726, 0.5643, 0.5669, 0.5698, 0.5732, 0.5732, 0.5679, 0.5759, 0.5621,
        0.5630, 0.5611, 0.5648, 0.5669, 0.5558, 0.5726, 0.5755],
       device='cuda:0') torch.Size([16])
percent tensor([0.5262, 0.5122, 0.5258, 0.5490, 0.5316, 0.5594, 0.5147, 0.5350, 0.5106,
        0.5181, 0.5053, 0.5285, 0.5152, 0.5168, 0.5237, 0.5416],
       device='cuda:0') torch.Size([16])
percent tensor([0.5544, 0.5396, 0.5615, 0.5848, 0.5632, 0.5795, 0.5419, 0.5642, 0.5493,
        0.5461, 0.5400, 0.5468, 0.5448, 0.5545, 0.5347, 0.5564],
       device='cuda:0') torch.Size([16])
percent tensor([0.5081, 0.5079, 0.5162, 0.5178, 0.5167, 0.5012, 0.5114, 0.5168, 0.5103,
        0.5144, 0.5084, 0.5139, 0.5070, 0.5062, 0.5027, 0.5080],
       device='cuda:0') torch.Size([16])
percent tensor([0.9837, 0.9461, 0.9346, 0.9478, 0.9414, 0.9640, 0.9628, 0.9677, 0.9536,
        0.9597, 0.9672, 0.9584, 0.9729, 0.9513, 0.9479, 0.9842],
       device='cuda:0') torch.Size([16])
Epoch: 22 | Batch_idx: 0 |  Loss: (0.7321) |  Loss2: (0.0000) | Acc: (75.00%) (97/128)
Epoch: 22 | Batch_idx: 10 |  Loss: (0.6902) |  Loss2: (0.0000) | Acc: (76.00%) (1077/1408)
Epoch: 22 | Batch_idx: 20 |  Loss: (0.7087) |  Loss2: (0.0000) | Acc: (75.00%) (2029/2688)
Epoch: 22 | Batch_idx: 30 |  Loss: (0.7073) |  Loss2: (0.0000) | Acc: (75.00%) (3007/3968)
Epoch: 22 | Batch_idx: 40 |  Loss: (0.7162) |  Loss2: (0.0000) | Acc: (75.00%) (3956/5248)
Epoch: 22 | Batch_idx: 50 |  Loss: (0.7183) |  Loss2: (0.0000) | Acc: (75.00%) (4899/6528)
Epoch: 22 | Batch_idx: 60 |  Loss: (0.7139) |  Loss2: (0.0000) | Acc: (75.00%) (5864/7808)
Epoch: 22 | Batch_idx: 70 |  Loss: (0.7116) |  Loss2: (0.0000) | Acc: (75.00%) (6828/9088)
Epoch: 22 | Batch_idx: 80 |  Loss: (0.7125) |  Loss2: (0.0000) | Acc: (75.00%) (7790/10368)
Epoch: 22 | Batch_idx: 90 |  Loss: (0.7149) |  Loss2: (0.0000) | Acc: (75.00%) (8759/11648)
Epoch: 22 | Batch_idx: 100 |  Loss: (0.7088) |  Loss2: (0.0000) | Acc: (75.00%) (9739/12928)
Epoch: 22 | Batch_idx: 110 |  Loss: (0.7126) |  Loss2: (0.0000) | Acc: (75.00%) (10678/14208)
Epoch: 22 | Batch_idx: 120 |  Loss: (0.7128) |  Loss2: (0.0000) | Acc: (75.00%) (11624/15488)
Epoch: 22 | Batch_idx: 130 |  Loss: (0.7100) |  Loss2: (0.0000) | Acc: (75.00%) (12610/16768)
Epoch: 22 | Batch_idx: 140 |  Loss: (0.7092) |  Loss2: (0.0000) | Acc: (75.00%) (13580/18048)
Epoch: 22 | Batch_idx: 150 |  Loss: (0.7089) |  Loss2: (0.0000) | Acc: (75.00%) (14554/19328)
Epoch: 22 | Batch_idx: 160 |  Loss: (0.7071) |  Loss2: (0.0000) | Acc: (75.00%) (15518/20608)
Epoch: 22 | Batch_idx: 170 |  Loss: (0.7100) |  Loss2: (0.0000) | Acc: (75.00%) (16460/21888)
Epoch: 22 | Batch_idx: 180 |  Loss: (0.7099) |  Loss2: (0.0000) | Acc: (75.00%) (17427/23168)
Epoch: 22 | Batch_idx: 190 |  Loss: (0.7115) |  Loss2: (0.0000) | Acc: (75.00%) (18371/24448)
Epoch: 22 | Batch_idx: 200 |  Loss: (0.7104) |  Loss2: (0.0000) | Acc: (75.00%) (19344/25728)
Epoch: 22 | Batch_idx: 210 |  Loss: (0.7102) |  Loss2: (0.0000) | Acc: (75.00%) (20305/27008)
Epoch: 22 | Batch_idx: 220 |  Loss: (0.7098) |  Loss2: (0.0000) | Acc: (75.00%) (21244/28288)
Epoch: 22 | Batch_idx: 230 |  Loss: (0.7080) |  Loss2: (0.0000) | Acc: (75.00%) (22201/29568)
Epoch: 22 | Batch_idx: 240 |  Loss: (0.7075) |  Loss2: (0.0000) | Acc: (75.00%) (23152/30848)
Epoch: 22 | Batch_idx: 250 |  Loss: (0.7064) |  Loss2: (0.0000) | Acc: (75.00%) (24131/32128)
Epoch: 22 | Batch_idx: 260 |  Loss: (0.7069) |  Loss2: (0.0000) | Acc: (75.00%) (25093/33408)
Epoch: 22 | Batch_idx: 270 |  Loss: (0.7061) |  Loss2: (0.0000) | Acc: (75.00%) (26050/34688)
Epoch: 22 | Batch_idx: 280 |  Loss: (0.7054) |  Loss2: (0.0000) | Acc: (75.00%) (27015/35968)
Epoch: 22 | Batch_idx: 290 |  Loss: (0.7071) |  Loss2: (0.0000) | Acc: (75.00%) (27954/37248)
Epoch: 22 | Batch_idx: 300 |  Loss: (0.7078) |  Loss2: (0.0000) | Acc: (75.00%) (28899/38528)
Epoch: 22 | Batch_idx: 310 |  Loss: (0.7087) |  Loss2: (0.0000) | Acc: (74.00%) (29846/39808)
Epoch: 22 | Batch_idx: 320 |  Loss: (0.7089) |  Loss2: (0.0000) | Acc: (74.00%) (30802/41088)
Epoch: 22 | Batch_idx: 330 |  Loss: (0.7089) |  Loss2: (0.0000) | Acc: (74.00%) (31743/42368)
Epoch: 22 | Batch_idx: 340 |  Loss: (0.7092) |  Loss2: (0.0000) | Acc: (74.00%) (32708/43648)
Epoch: 22 | Batch_idx: 350 |  Loss: (0.7084) |  Loss2: (0.0000) | Acc: (74.00%) (33677/44928)
Epoch: 22 | Batch_idx: 360 |  Loss: (0.7082) |  Loss2: (0.0000) | Acc: (74.00%) (34652/46208)
Epoch: 22 | Batch_idx: 370 |  Loss: (0.7085) |  Loss2: (0.0000) | Acc: (74.00%) (35595/47488)
Epoch: 22 | Batch_idx: 380 |  Loss: (0.7083) |  Loss2: (0.0000) | Acc: (74.00%) (36558/48768)
Epoch: 22 | Batch_idx: 390 |  Loss: (0.7077) |  Loss2: (0.0000) | Acc: (74.00%) (37496/50000)
# TEST : Loss: (0.7289) | Acc: (74.00%) (7480/10000)
percent tensor([0.5060, 0.5046, 0.5061, 0.5063, 0.5063, 0.5080, 0.5057, 0.5065, 0.5054,
        0.5057, 0.5051, 0.5063, 0.5061, 0.5037, 0.5061, 0.5061],
       device='cuda:0') torch.Size([16])
percent tensor([0.4969, 0.4916, 0.4903, 0.4950, 0.4903, 0.5002, 0.4902, 0.4893, 0.4939,
        0.4910, 0.4951, 0.4903, 0.4966, 0.4943, 0.4950, 0.4965],
       device='cuda:0') torch.Size([16])
percent tensor([0.5027, 0.4850, 0.5061, 0.5211, 0.5142, 0.5374, 0.4918, 0.5079, 0.4900,
        0.4799, 0.4764, 0.4906, 0.4784, 0.4889, 0.5110, 0.5075],
       device='cuda:0') torch.Size([16])
percent tensor([0.5704, 0.5609, 0.5653, 0.5683, 0.5714, 0.5725, 0.5648, 0.5739, 0.5591,
        0.5594, 0.5574, 0.5620, 0.5637, 0.5523, 0.5700, 0.5736],
       device='cuda:0') torch.Size([16])
percent tensor([0.5244, 0.5097, 0.5232, 0.5498, 0.5291, 0.5638, 0.5118, 0.5316, 0.5073,
        0.5162, 0.5019, 0.5265, 0.5127, 0.5153, 0.5209, 0.5425],
       device='cuda:0') torch.Size([16])
percent tensor([0.5564, 0.5411, 0.5647, 0.5896, 0.5660, 0.5841, 0.5429, 0.5657, 0.5517,
        0.5482, 0.5412, 0.5481, 0.5465, 0.5574, 0.5340, 0.5585],
       device='cuda:0') torch.Size([16])
percent tensor([0.5105, 0.5104, 0.5195, 0.5203, 0.5202, 0.5033, 0.5142, 0.5208, 0.5124,
        0.5172, 0.5108, 0.5171, 0.5102, 0.5078, 0.5055, 0.5109],
       device='cuda:0') torch.Size([16])
percent tensor([0.9874, 0.9551, 0.9476, 0.9594, 0.9535, 0.9707, 0.9706, 0.9755, 0.9597,
        0.9661, 0.9722, 0.9680, 0.9770, 0.9587, 0.9576, 0.9883],
       device='cuda:0') torch.Size([16])
Epoch: 23 | Batch_idx: 0 |  Loss: (0.6846) |  Loss2: (0.0000) | Acc: (72.00%) (93/128)
Epoch: 23 | Batch_idx: 10 |  Loss: (0.7089) |  Loss2: (0.0000) | Acc: (74.00%) (1046/1408)
Epoch: 23 | Batch_idx: 20 |  Loss: (0.7131) |  Loss2: (0.0000) | Acc: (73.00%) (1989/2688)
Epoch: 23 | Batch_idx: 30 |  Loss: (0.6928) |  Loss2: (0.0000) | Acc: (75.00%) (2982/3968)
Epoch: 23 | Batch_idx: 40 |  Loss: (0.6859) |  Loss2: (0.0000) | Acc: (75.00%) (3956/5248)
Epoch: 23 | Batch_idx: 50 |  Loss: (0.6801) |  Loss2: (0.0000) | Acc: (75.00%) (4936/6528)
Epoch: 23 | Batch_idx: 60 |  Loss: (0.6797) |  Loss2: (0.0000) | Acc: (75.00%) (5895/7808)
Epoch: 23 | Batch_idx: 70 |  Loss: (0.6768) |  Loss2: (0.0000) | Acc: (75.00%) (6858/9088)
Epoch: 23 | Batch_idx: 80 |  Loss: (0.6820) |  Loss2: (0.0000) | Acc: (75.00%) (7823/10368)
Epoch: 23 | Batch_idx: 90 |  Loss: (0.6873) |  Loss2: (0.0000) | Acc: (75.00%) (8788/11648)
Epoch: 23 | Batch_idx: 100 |  Loss: (0.6882) |  Loss2: (0.0000) | Acc: (75.00%) (9767/12928)
Epoch: 23 | Batch_idx: 110 |  Loss: (0.6904) |  Loss2: (0.0000) | Acc: (75.00%) (10730/14208)
Epoch: 23 | Batch_idx: 120 |  Loss: (0.6900) |  Loss2: (0.0000) | Acc: (75.00%) (11705/15488)
Epoch: 23 | Batch_idx: 130 |  Loss: (0.6912) |  Loss2: (0.0000) | Acc: (75.00%) (12676/16768)
Epoch: 23 | Batch_idx: 140 |  Loss: (0.6925) |  Loss2: (0.0000) | Acc: (75.00%) (13633/18048)
Epoch: 23 | Batch_idx: 150 |  Loss: (0.6952) |  Loss2: (0.0000) | Acc: (75.00%) (14589/19328)
Epoch: 23 | Batch_idx: 160 |  Loss: (0.7002) |  Loss2: (0.0000) | Acc: (75.00%) (15523/20608)
Epoch: 23 | Batch_idx: 170 |  Loss: (0.6965) |  Loss2: (0.0000) | Acc: (75.00%) (16526/21888)
Epoch: 23 | Batch_idx: 180 |  Loss: (0.7003) |  Loss2: (0.0000) | Acc: (75.00%) (17475/23168)
Epoch: 23 | Batch_idx: 190 |  Loss: (0.6994) |  Loss2: (0.0000) | Acc: (75.00%) (18444/24448)
Epoch: 23 | Batch_idx: 200 |  Loss: (0.6977) |  Loss2: (0.0000) | Acc: (75.00%) (19425/25728)
Epoch: 23 | Batch_idx: 210 |  Loss: (0.6953) |  Loss2: (0.0000) | Acc: (75.00%) (20416/27008)
Epoch: 23 | Batch_idx: 220 |  Loss: (0.6986) |  Loss2: (0.0000) | Acc: (75.00%) (21358/28288)
Epoch: 23 | Batch_idx: 230 |  Loss: (0.7001) |  Loss2: (0.0000) | Acc: (75.00%) (22304/29568)
Epoch: 23 | Batch_idx: 240 |  Loss: (0.6999) |  Loss2: (0.0000) | Acc: (75.00%) (23269/30848)
Epoch: 23 | Batch_idx: 250 |  Loss: (0.6990) |  Loss2: (0.0000) | Acc: (75.00%) (24229/32128)
Epoch: 23 | Batch_idx: 260 |  Loss: (0.6994) |  Loss2: (0.0000) | Acc: (75.00%) (25195/33408)
Epoch: 23 | Batch_idx: 270 |  Loss: (0.6991) |  Loss2: (0.0000) | Acc: (75.00%) (26157/34688)
Epoch: 23 | Batch_idx: 280 |  Loss: (0.6994) |  Loss2: (0.0000) | Acc: (75.00%) (27118/35968)
Epoch: 23 | Batch_idx: 290 |  Loss: (0.6997) |  Loss2: (0.0000) | Acc: (75.00%) (28078/37248)
Epoch: 23 | Batch_idx: 300 |  Loss: (0.6980) |  Loss2: (0.0000) | Acc: (75.00%) (29069/38528)
Epoch: 23 | Batch_idx: 310 |  Loss: (0.6975) |  Loss2: (0.0000) | Acc: (75.00%) (30039/39808)
Epoch: 23 | Batch_idx: 320 |  Loss: (0.6972) |  Loss2: (0.0000) | Acc: (75.00%) (30998/41088)
Epoch: 23 | Batch_idx: 330 |  Loss: (0.6980) |  Loss2: (0.0000) | Acc: (75.00%) (31953/42368)
Epoch: 23 | Batch_idx: 340 |  Loss: (0.6991) |  Loss2: (0.0000) | Acc: (75.00%) (32904/43648)
Epoch: 23 | Batch_idx: 350 |  Loss: (0.6994) |  Loss2: (0.0000) | Acc: (75.00%) (33859/44928)
Epoch: 23 | Batch_idx: 360 |  Loss: (0.6994) |  Loss2: (0.0000) | Acc: (75.00%) (34820/46208)
Epoch: 23 | Batch_idx: 370 |  Loss: (0.6994) |  Loss2: (0.0000) | Acc: (75.00%) (35772/47488)
Epoch: 23 | Batch_idx: 380 |  Loss: (0.7004) |  Loss2: (0.0000) | Acc: (75.00%) (36713/48768)
Epoch: 23 | Batch_idx: 390 |  Loss: (0.7011) |  Loss2: (0.0000) | Acc: (75.00%) (37630/50000)
# TEST : Loss: (0.7245) | Acc: (74.00%) (7492/10000)
percent tensor([0.5074, 0.5062, 0.5076, 0.5078, 0.5079, 0.5096, 0.5073, 0.5082, 0.5068,
        0.5073, 0.5066, 0.5079, 0.5076, 0.5051, 0.5077, 0.5076],
       device='cuda:0') torch.Size([16])
percent tensor([0.4965, 0.4904, 0.4889, 0.4940, 0.4888, 0.5000, 0.4888, 0.4876, 0.4930,
        0.4897, 0.4944, 0.4889, 0.4961, 0.4935, 0.4940, 0.4960],
       device='cuda:0') torch.Size([16])
percent tensor([0.5024, 0.4871, 0.5063, 0.5221, 0.5147, 0.5380, 0.4938, 0.5082, 0.4907,
        0.4814, 0.4772, 0.4917, 0.4784, 0.4911, 0.5120, 0.5081],
       device='cuda:0') torch.Size([16])
percent tensor([0.5719, 0.5617, 0.5666, 0.5697, 0.5726, 0.5748, 0.5658, 0.5754, 0.5598,
        0.5600, 0.5580, 0.5629, 0.5646, 0.5530, 0.5714, 0.5754],
       device='cuda:0') torch.Size([16])
percent tensor([0.5237, 0.5085, 0.5221, 0.5510, 0.5279, 0.5667, 0.5104, 0.5304, 0.5055,
        0.5155, 0.4999, 0.5264, 0.5117, 0.5147, 0.5201, 0.5444],
       device='cuda:0') torch.Size([16])
percent tensor([0.5534, 0.5386, 0.5600, 0.5866, 0.5610, 0.5833, 0.5386, 0.5580, 0.5504,
        0.5463, 0.5388, 0.5434, 0.5450, 0.5570, 0.5274, 0.5557],
       device='cuda:0') torch.Size([16])
percent tensor([0.5148, 0.5146, 0.5251, 0.5257, 0.5262, 0.5081, 0.5184, 0.5280, 0.5162,
        0.5217, 0.5147, 0.5221, 0.5153, 0.5118, 0.5100, 0.5157],
       device='cuda:0') torch.Size([16])
percent tensor([0.9901, 0.9633, 0.9557, 0.9668, 0.9608, 0.9766, 0.9758, 0.9804, 0.9664,
        0.9729, 0.9780, 0.9740, 0.9818, 0.9663, 0.9657, 0.9907],
       device='cuda:0') torch.Size([16])
True Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=128, out_features=16, bias=False)
False Linear(in_features=16, out_features=2, bias=False)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=128, out_features=16, bias=False)
False Linear(in_features=16, out_features=2, bias=False)
True Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=256, out_features=32, bias=False)
False Linear(in_features=32, out_features=2, bias=False)
True Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=256, out_features=32, bias=False)
False Linear(in_features=32, out_features=2, bias=False)
True Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=512, out_features=64, bias=False)
False Linear(in_features=64, out_features=2, bias=False)
True Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=512, out_features=64, bias=False)
False Linear(in_features=64, out_features=2, bias=False)
True Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1024, out_features=128, bias=False)
False Linear(in_features=128, out_features=2, bias=False)
True Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1024, out_features=128, bias=False)
False Linear(in_features=128, out_features=2, bias=False)
True Linear(in_features=512, out_features=10, bias=True)
Epoch: 24 | Batch_idx: 0 |  Loss: (0.5743) |  Loss2: (0.0000) | Acc: (81.00%) (104/128)
Epoch: 24 | Batch_idx: 10 |  Loss: (0.7133) |  Loss2: (0.0000) | Acc: (74.00%) (1054/1408)
Epoch: 24 | Batch_idx: 20 |  Loss: (0.7055) |  Loss2: (0.0000) | Acc: (75.00%) (2023/2688)
Epoch: 24 | Batch_idx: 30 |  Loss: (0.7065) |  Loss2: (0.0000) | Acc: (75.00%) (2976/3968)
Epoch: 24 | Batch_idx: 40 |  Loss: (0.7158) |  Loss2: (0.0000) | Acc: (74.00%) (3922/5248)
Epoch: 24 | Batch_idx: 50 |  Loss: (0.7212) |  Loss2: (0.0000) | Acc: (74.00%) (4885/6528)
Epoch: 24 | Batch_idx: 60 |  Loss: (0.7186) |  Loss2: (0.0000) | Acc: (74.00%) (5843/7808)
Epoch: 24 | Batch_idx: 70 |  Loss: (0.7219) |  Loss2: (0.0000) | Acc: (74.00%) (6793/9088)
Epoch: 24 | Batch_idx: 80 |  Loss: (0.7182) |  Loss2: (0.0000) | Acc: (74.00%) (7750/10368)
Epoch: 24 | Batch_idx: 90 |  Loss: (0.7170) |  Loss2: (0.0000) | Acc: (74.00%) (8708/11648)
Epoch: 24 | Batch_idx: 100 |  Loss: (0.7148) |  Loss2: (0.0000) | Acc: (74.00%) (9663/12928)
Epoch: 24 | Batch_idx: 110 |  Loss: (0.7128) |  Loss2: (0.0000) | Acc: (74.00%) (10631/14208)
Epoch: 24 | Batch_idx: 120 |  Loss: (0.7114) |  Loss2: (0.0000) | Acc: (74.00%) (11593/15488)
Epoch: 24 | Batch_idx: 130 |  Loss: (0.7094) |  Loss2: (0.0000) | Acc: (74.00%) (12572/16768)
Epoch: 24 | Batch_idx: 140 |  Loss: (0.7077) |  Loss2: (0.0000) | Acc: (75.00%) (13549/18048)
Epoch: 24 | Batch_idx: 150 |  Loss: (0.7057) |  Loss2: (0.0000) | Acc: (75.00%) (14514/19328)
Epoch: 24 | Batch_idx: 160 |  Loss: (0.7091) |  Loss2: (0.0000) | Acc: (75.00%) (15462/20608)
Epoch: 24 | Batch_idx: 170 |  Loss: (0.7067) |  Loss2: (0.0000) | Acc: (75.00%) (16426/21888)
Epoch: 24 | Batch_idx: 180 |  Loss: (0.7084) |  Loss2: (0.0000) | Acc: (74.00%) (17373/23168)
Epoch: 24 | Batch_idx: 190 |  Loss: (0.7067) |  Loss2: (0.0000) | Acc: (75.00%) (18362/24448)
Epoch: 24 | Batch_idx: 200 |  Loss: (0.7063) |  Loss2: (0.0000) | Acc: (75.00%) (19309/25728)
Epoch: 24 | Batch_idx: 210 |  Loss: (0.7054) |  Loss2: (0.0000) | Acc: (75.00%) (20286/27008)
Epoch: 24 | Batch_idx: 220 |  Loss: (0.7046) |  Loss2: (0.0000) | Acc: (75.00%) (21252/28288)
Epoch: 24 | Batch_idx: 230 |  Loss: (0.7055) |  Loss2: (0.0000) | Acc: (75.00%) (22202/29568)
Epoch: 24 | Batch_idx: 240 |  Loss: (0.7048) |  Loss2: (0.0000) | Acc: (75.00%) (23176/30848)
Epoch: 24 | Batch_idx: 250 |  Loss: (0.7043) |  Loss2: (0.0000) | Acc: (75.00%) (24154/32128)
Epoch: 24 | Batch_idx: 260 |  Loss: (0.7054) |  Loss2: (0.0000) | Acc: (75.00%) (25107/33408)
Epoch: 24 | Batch_idx: 270 |  Loss: (0.7036) |  Loss2: (0.0000) | Acc: (75.00%) (26091/34688)
Epoch: 24 | Batch_idx: 280 |  Loss: (0.7042) |  Loss2: (0.0000) | Acc: (75.00%) (27060/35968)
Epoch: 24 | Batch_idx: 290 |  Loss: (0.7028) |  Loss2: (0.0000) | Acc: (75.00%) (28055/37248)
Epoch: 24 | Batch_idx: 300 |  Loss: (0.7016) |  Loss2: (0.0000) | Acc: (75.00%) (29020/38528)
Epoch: 24 | Batch_idx: 310 |  Loss: (0.7022) |  Loss2: (0.0000) | Acc: (75.00%) (29977/39808)
Epoch: 24 | Batch_idx: 320 |  Loss: (0.7017) |  Loss2: (0.0000) | Acc: (75.00%) (30946/41088)
Epoch: 24 | Batch_idx: 330 |  Loss: (0.7012) |  Loss2: (0.0000) | Acc: (75.00%) (31910/42368)
Epoch: 24 | Batch_idx: 340 |  Loss: (0.7012) |  Loss2: (0.0000) | Acc: (75.00%) (32887/43648)
Epoch: 24 | Batch_idx: 350 |  Loss: (0.7008) |  Loss2: (0.0000) | Acc: (75.00%) (33852/44928)
Epoch: 24 | Batch_idx: 360 |  Loss: (0.7012) |  Loss2: (0.0000) | Acc: (75.00%) (34806/46208)
Epoch: 24 | Batch_idx: 370 |  Loss: (0.7006) |  Loss2: (0.0000) | Acc: (75.00%) (35766/47488)
Epoch: 24 | Batch_idx: 380 |  Loss: (0.7008) |  Loss2: (0.0000) | Acc: (75.00%) (36728/48768)
Epoch: 24 | Batch_idx: 390 |  Loss: (0.7007) |  Loss2: (0.0000) | Acc: (75.00%) (37658/50000)
# TEST : Loss: (0.9824) | Acc: (66.00%) (6643/10000)
percent tensor([0.5070, 0.5065, 0.5063, 0.5075, 0.5069, 0.5096, 0.5073, 0.5076, 0.5065,
        0.5070, 0.5066, 0.5070, 0.5074, 0.5061, 0.5077, 0.5076],
       device='cuda:0') torch.Size([16])
percent tensor([0.4960, 0.4898, 0.4898, 0.4941, 0.4895, 0.4992, 0.4885, 0.4889, 0.4928,
        0.4893, 0.4937, 0.4896, 0.4955, 0.4932, 0.4937, 0.4954],
       device='cuda:0') torch.Size([16])
percent tensor([0.5029, 0.4868, 0.5106, 0.5231, 0.5195, 0.5373, 0.4988, 0.5100, 0.4927,
        0.4863, 0.4789, 0.4969, 0.4771, 0.4892, 0.5123, 0.5087],
       device='cuda:0') torch.Size([16])
percent tensor([0.5695, 0.5608, 0.5692, 0.5699, 0.5749, 0.5699, 0.5666, 0.5754, 0.5620,
        0.5596, 0.5581, 0.5648, 0.5627, 0.5587, 0.5682, 0.5724],
       device='cuda:0') torch.Size([16])
percent tensor([0.5189, 0.5063, 0.5393, 0.5544, 0.5438, 0.5568, 0.5148, 0.5374, 0.5120,
        0.5152, 0.5039, 0.5342, 0.5064, 0.5126, 0.5167, 0.5419],
       device='cuda:0') torch.Size([16])
percent tensor([0.5479, 0.5347, 0.5675, 0.5822, 0.5634, 0.5730, 0.5347, 0.5532, 0.5508,
        0.5470, 0.5402, 0.5447, 0.5397, 0.5520, 0.5243, 0.5507],
       device='cuda:0') torch.Size([16])
percent tensor([0.5135, 0.5133, 0.5246, 0.5253, 0.5216, 0.5088, 0.5143, 0.5267, 0.5151,
        0.5177, 0.5144, 0.5211, 0.5142, 0.5085, 0.5093, 0.5138],
       device='cuda:0') torch.Size([16])
percent tensor([0.9910, 0.9674, 0.9606, 0.9766, 0.9510, 0.9715, 0.9810, 0.9873, 0.9681,
        0.9745, 0.9801, 0.9784, 0.9816, 0.9751, 0.9748, 0.9880],
       device='cuda:0') torch.Size([16])
Epoch: 25 | Batch_idx: 0 |  Loss: (0.6115) |  Loss2: (0.0000) | Acc: (78.00%) (100/128)
Epoch: 25 | Batch_idx: 10 |  Loss: (0.6384) |  Loss2: (0.0000) | Acc: (77.00%) (1095/1408)
Epoch: 25 | Batch_idx: 20 |  Loss: (0.6601) |  Loss2: (0.0000) | Acc: (76.00%) (2067/2688)
Epoch: 25 | Batch_idx: 30 |  Loss: (0.6467) |  Loss2: (0.0000) | Acc: (77.00%) (3061/3968)
Epoch: 25 | Batch_idx: 40 |  Loss: (0.6498) |  Loss2: (0.0000) | Acc: (77.00%) (4047/5248)
Epoch: 25 | Batch_idx: 50 |  Loss: (0.6525) |  Loss2: (0.0000) | Acc: (77.00%) (5036/6528)
Epoch: 25 | Batch_idx: 60 |  Loss: (0.6509) |  Loss2: (0.0000) | Acc: (77.00%) (6034/7808)
Epoch: 25 | Batch_idx: 70 |  Loss: (0.6558) |  Loss2: (0.0000) | Acc: (77.00%) (7000/9088)
Epoch: 25 | Batch_idx: 80 |  Loss: (0.6584) |  Loss2: (0.0000) | Acc: (76.00%) (7965/10368)
Epoch: 25 | Batch_idx: 90 |  Loss: (0.6599) |  Loss2: (0.0000) | Acc: (76.00%) (8944/11648)
Epoch: 25 | Batch_idx: 100 |  Loss: (0.6557) |  Loss2: (0.0000) | Acc: (77.00%) (9958/12928)
Epoch: 25 | Batch_idx: 110 |  Loss: (0.6565) |  Loss2: (0.0000) | Acc: (76.00%) (10938/14208)
Epoch: 25 | Batch_idx: 120 |  Loss: (0.6576) |  Loss2: (0.0000) | Acc: (76.00%) (11915/15488)
Epoch: 25 | Batch_idx: 130 |  Loss: (0.6621) |  Loss2: (0.0000) | Acc: (76.00%) (12856/16768)
Epoch: 25 | Batch_idx: 140 |  Loss: (0.6620) |  Loss2: (0.0000) | Acc: (76.00%) (13838/18048)
Epoch: 25 | Batch_idx: 150 |  Loss: (0.6650) |  Loss2: (0.0000) | Acc: (76.00%) (14812/19328)
Epoch: 25 | Batch_idx: 160 |  Loss: (0.6666) |  Loss2: (0.0000) | Acc: (76.00%) (15777/20608)
Epoch: 25 | Batch_idx: 170 |  Loss: (0.6674) |  Loss2: (0.0000) | Acc: (76.00%) (16748/21888)
Epoch: 25 | Batch_idx: 180 |  Loss: (0.6685) |  Loss2: (0.0000) | Acc: (76.00%) (17733/23168)
Epoch: 25 | Batch_idx: 190 |  Loss: (0.6695) |  Loss2: (0.0000) | Acc: (76.00%) (18697/24448)
Epoch: 25 | Batch_idx: 200 |  Loss: (0.6698) |  Loss2: (0.0000) | Acc: (76.00%) (19658/25728)
Epoch: 25 | Batch_idx: 210 |  Loss: (0.6694) |  Loss2: (0.0000) | Acc: (76.00%) (20629/27008)
Epoch: 25 | Batch_idx: 220 |  Loss: (0.6672) |  Loss2: (0.0000) | Acc: (76.00%) (21642/28288)
Epoch: 25 | Batch_idx: 230 |  Loss: (0.6670) |  Loss2: (0.0000) | Acc: (76.00%) (22620/29568)
Epoch: 25 | Batch_idx: 240 |  Loss: (0.6664) |  Loss2: (0.0000) | Acc: (76.00%) (23604/30848)
Epoch: 25 | Batch_idx: 250 |  Loss: (0.6652) |  Loss2: (0.0000) | Acc: (76.00%) (24597/32128)
Epoch: 25 | Batch_idx: 260 |  Loss: (0.6648) |  Loss2: (0.0000) | Acc: (76.00%) (25570/33408)
Epoch: 25 | Batch_idx: 270 |  Loss: (0.6631) |  Loss2: (0.0000) | Acc: (76.00%) (26562/34688)
Epoch: 25 | Batch_idx: 280 |  Loss: (0.6626) |  Loss2: (0.0000) | Acc: (76.00%) (27567/35968)
Epoch: 25 | Batch_idx: 290 |  Loss: (0.6624) |  Loss2: (0.0000) | Acc: (76.00%) (28562/37248)
Epoch: 25 | Batch_idx: 300 |  Loss: (0.6632) |  Loss2: (0.0000) | Acc: (76.00%) (29530/38528)
Epoch: 25 | Batch_idx: 310 |  Loss: (0.6634) |  Loss2: (0.0000) | Acc: (76.00%) (30506/39808)
Epoch: 25 | Batch_idx: 320 |  Loss: (0.6627) |  Loss2: (0.0000) | Acc: (76.00%) (31499/41088)
Epoch: 25 | Batch_idx: 330 |  Loss: (0.6626) |  Loss2: (0.0000) | Acc: (76.00%) (32481/42368)
Epoch: 25 | Batch_idx: 340 |  Loss: (0.6619) |  Loss2: (0.0000) | Acc: (76.00%) (33482/43648)
Epoch: 25 | Batch_idx: 350 |  Loss: (0.6607) |  Loss2: (0.0000) | Acc: (76.00%) (34502/44928)
Epoch: 25 | Batch_idx: 360 |  Loss: (0.6613) |  Loss2: (0.0000) | Acc: (76.00%) (35470/46208)
Epoch: 25 | Batch_idx: 370 |  Loss: (0.6606) |  Loss2: (0.0000) | Acc: (76.00%) (36468/47488)
Epoch: 25 | Batch_idx: 380 |  Loss: (0.6596) |  Loss2: (0.0000) | Acc: (76.00%) (37478/48768)
Epoch: 25 | Batch_idx: 390 |  Loss: (0.6595) |  Loss2: (0.0000) | Acc: (76.00%) (38418/50000)
=> saving checkpoint 'drive/app/torch/save_Schedule/checkpoint_025.pth.tar'
# TEST : Loss: (0.7146) | Acc: (75.00%) (7565/10000)
percent tensor([0.5070, 0.5058, 0.5063, 0.5071, 0.5068, 0.5094, 0.5067, 0.5073, 0.5065,
        0.5065, 0.5064, 0.5067, 0.5073, 0.5049, 0.5073, 0.5073],
       device='cuda:0') torch.Size([16])
percent tensor([0.4963, 0.4900, 0.4909, 0.4939, 0.4899, 0.4996, 0.4891, 0.4895, 0.4939,
        0.4898, 0.4943, 0.4905, 0.4959, 0.4934, 0.4939, 0.4956],
       device='cuda:0') torch.Size([16])
percent tensor([0.4991, 0.4852, 0.5081, 0.5194, 0.5153, 0.5383, 0.4961, 0.5079, 0.4913,
        0.4826, 0.4783, 0.4923, 0.4744, 0.4911, 0.5108, 0.5042],
       device='cuda:0') torch.Size([16])
percent tensor([0.5700, 0.5617, 0.5684, 0.5675, 0.5737, 0.5727, 0.5659, 0.5739, 0.5618,
        0.5600, 0.5590, 0.5635, 0.5632, 0.5567, 0.5694, 0.5725],
       device='cuda:0') torch.Size([16])
percent tensor([0.5169, 0.5061, 0.5262, 0.5410, 0.5299, 0.5578, 0.5101, 0.5231, 0.5073,
        0.5137, 0.5024, 0.5288, 0.5061, 0.5177, 0.5161, 0.5397],
       device='cuda:0') torch.Size([16])
percent tensor([0.5463, 0.5386, 0.5615, 0.5747, 0.5586, 0.5722, 0.5400, 0.5519, 0.5487,
        0.5481, 0.5424, 0.5505, 0.5411, 0.5597, 0.5272, 0.5501],
       device='cuda:0') torch.Size([16])
percent tensor([0.5160, 0.5175, 0.5228, 0.5239, 0.5231, 0.5072, 0.5190, 0.5266, 0.5188,
        0.5223, 0.5182, 0.5219, 0.5182, 0.5143, 0.5103, 0.5153],
       device='cuda:0') torch.Size([16])
percent tensor([0.9880, 0.9707, 0.9584, 0.9700, 0.9644, 0.9670, 0.9817, 0.9890, 0.9667,
        0.9722, 0.9779, 0.9713, 0.9781, 0.9709, 0.9712, 0.9838],
       device='cuda:0') torch.Size([16])
Epoch: 26 | Batch_idx: 0 |  Loss: (0.6546) |  Loss2: (0.0000) | Acc: (74.00%) (95/128)
Epoch: 26 | Batch_idx: 10 |  Loss: (0.6261) |  Loss2: (0.0000) | Acc: (77.00%) (1097/1408)
Epoch: 26 | Batch_idx: 20 |  Loss: (0.6138) |  Loss2: (0.0000) | Acc: (78.00%) (2104/2688)
Epoch: 26 | Batch_idx: 30 |  Loss: (0.6187) |  Loss2: (0.0000) | Acc: (78.00%) (3114/3968)
Epoch: 26 | Batch_idx: 40 |  Loss: (0.6194) |  Loss2: (0.0000) | Acc: (78.00%) (4122/5248)
Epoch: 26 | Batch_idx: 50 |  Loss: (0.6200) |  Loss2: (0.0000) | Acc: (78.00%) (5115/6528)
Epoch: 26 | Batch_idx: 60 |  Loss: (0.6246) |  Loss2: (0.0000) | Acc: (78.00%) (6095/7808)
Epoch: 26 | Batch_idx: 70 |  Loss: (0.6318) |  Loss2: (0.0000) | Acc: (77.00%) (7070/9088)
Epoch: 26 | Batch_idx: 80 |  Loss: (0.6375) |  Loss2: (0.0000) | Acc: (77.00%) (8042/10368)
Epoch: 26 | Batch_idx: 90 |  Loss: (0.6437) |  Loss2: (0.0000) | Acc: (77.00%) (9014/11648)
Epoch: 26 | Batch_idx: 100 |  Loss: (0.6402) |  Loss2: (0.0000) | Acc: (77.00%) (10017/12928)
Epoch: 26 | Batch_idx: 110 |  Loss: (0.6396) |  Loss2: (0.0000) | Acc: (77.00%) (11011/14208)
Epoch: 26 | Batch_idx: 120 |  Loss: (0.6424) |  Loss2: (0.0000) | Acc: (77.00%) (11995/15488)
Epoch: 26 | Batch_idx: 130 |  Loss: (0.6370) |  Loss2: (0.0000) | Acc: (77.00%) (13018/16768)
Epoch: 26 | Batch_idx: 140 |  Loss: (0.6346) |  Loss2: (0.0000) | Acc: (77.00%) (14027/18048)
Epoch: 26 | Batch_idx: 150 |  Loss: (0.6342) |  Loss2: (0.0000) | Acc: (77.00%) (15026/19328)
Epoch: 26 | Batch_idx: 160 |  Loss: (0.6319) |  Loss2: (0.0000) | Acc: (77.00%) (16042/20608)
Epoch: 26 | Batch_idx: 170 |  Loss: (0.6322) |  Loss2: (0.0000) | Acc: (77.00%) (17031/21888)
Epoch: 26 | Batch_idx: 180 |  Loss: (0.6325) |  Loss2: (0.0000) | Acc: (77.00%) (18025/23168)
Epoch: 26 | Batch_idx: 190 |  Loss: (0.6327) |  Loss2: (0.0000) | Acc: (77.00%) (19018/24448)
Epoch: 26 | Batch_idx: 200 |  Loss: (0.6319) |  Loss2: (0.0000) | Acc: (77.00%) (20020/25728)
Epoch: 26 | Batch_idx: 210 |  Loss: (0.6312) |  Loss2: (0.0000) | Acc: (77.00%) (21036/27008)
Epoch: 26 | Batch_idx: 220 |  Loss: (0.6315) |  Loss2: (0.0000) | Acc: (77.00%) (22020/28288)
Epoch: 26 | Batch_idx: 230 |  Loss: (0.6305) |  Loss2: (0.0000) | Acc: (77.00%) (23031/29568)
Epoch: 26 | Batch_idx: 240 |  Loss: (0.6304) |  Loss2: (0.0000) | Acc: (77.00%) (24022/30848)
Epoch: 26 | Batch_idx: 250 |  Loss: (0.6306) |  Loss2: (0.0000) | Acc: (77.00%) (25027/32128)
Epoch: 26 | Batch_idx: 260 |  Loss: (0.6287) |  Loss2: (0.0000) | Acc: (78.00%) (26060/33408)
Epoch: 26 | Batch_idx: 270 |  Loss: (0.6291) |  Loss2: (0.0000) | Acc: (77.00%) (27047/34688)
Epoch: 26 | Batch_idx: 280 |  Loss: (0.6303) |  Loss2: (0.0000) | Acc: (77.00%) (28041/35968)
Epoch: 26 | Batch_idx: 290 |  Loss: (0.6296) |  Loss2: (0.0000) | Acc: (78.00%) (29065/37248)
Epoch: 26 | Batch_idx: 300 |  Loss: (0.6295) |  Loss2: (0.0000) | Acc: (78.00%) (30058/38528)
Epoch: 26 | Batch_idx: 310 |  Loss: (0.6285) |  Loss2: (0.0000) | Acc: (78.00%) (31069/39808)
Epoch: 26 | Batch_idx: 320 |  Loss: (0.6284) |  Loss2: (0.0000) | Acc: (78.00%) (32075/41088)
Epoch: 26 | Batch_idx: 330 |  Loss: (0.6288) |  Loss2: (0.0000) | Acc: (78.00%) (33060/42368)
Epoch: 26 | Batch_idx: 340 |  Loss: (0.6293) |  Loss2: (0.0000) | Acc: (78.00%) (34052/43648)
Epoch: 26 | Batch_idx: 350 |  Loss: (0.6282) |  Loss2: (0.0000) | Acc: (78.00%) (35060/44928)
Epoch: 26 | Batch_idx: 360 |  Loss: (0.6268) |  Loss2: (0.0000) | Acc: (78.00%) (36082/46208)
Epoch: 26 | Batch_idx: 370 |  Loss: (0.6262) |  Loss2: (0.0000) | Acc: (78.00%) (37099/47488)
Epoch: 26 | Batch_idx: 380 |  Loss: (0.6264) |  Loss2: (0.0000) | Acc: (78.00%) (38101/48768)
Epoch: 26 | Batch_idx: 390 |  Loss: (0.6266) |  Loss2: (0.0000) | Acc: (78.00%) (39068/50000)
# TEST : Loss: (0.7249) | Acc: (74.00%) (7464/10000)
percent tensor([0.5073, 0.5063, 0.5068, 0.5074, 0.5072, 0.5094, 0.5071, 0.5078, 0.5068,
        0.5069, 0.5065, 0.5074, 0.5076, 0.5057, 0.5075, 0.5076],
       device='cuda:0') torch.Size([16])
percent tensor([0.4966, 0.4906, 0.4911, 0.4943, 0.4903, 0.5000, 0.4895, 0.4892, 0.4937,
        0.4903, 0.4948, 0.4905, 0.4961, 0.4933, 0.4943, 0.4960],
       device='cuda:0') torch.Size([16])
percent tensor([0.5011, 0.4806, 0.5089, 0.5212, 0.5180, 0.5406, 0.4924, 0.5098, 0.4885,
        0.4789, 0.4726, 0.4902, 0.4728, 0.4856, 0.5109, 0.5044],
       device='cuda:0') torch.Size([16])
percent tensor([0.5724, 0.5644, 0.5681, 0.5689, 0.5730, 0.5715, 0.5669, 0.5763, 0.5634,
        0.5618, 0.5611, 0.5669, 0.5672, 0.5598, 0.5708, 0.5729],
       device='cuda:0') torch.Size([16])
percent tensor([0.5233, 0.5099, 0.5300, 0.5502, 0.5301, 0.5539, 0.5138, 0.5347, 0.5134,
        0.5207, 0.5087, 0.5359, 0.5138, 0.5286, 0.5194, 0.5439],
       device='cuda:0') torch.Size([16])
percent tensor([0.5468, 0.5389, 0.5563, 0.5755, 0.5548, 0.5694, 0.5389, 0.5546, 0.5475,
        0.5476, 0.5447, 0.5429, 0.5381, 0.5643, 0.5273, 0.5532],
       device='cuda:0') torch.Size([16])
percent tensor([0.5170, 0.5173, 0.5215, 0.5227, 0.5207, 0.5092, 0.5183, 0.5260, 0.5165,
        0.5206, 0.5177, 0.5210, 0.5157, 0.5148, 0.5130, 0.5163],
       device='cuda:0') torch.Size([16])
percent tensor([0.9929, 0.9668, 0.9572, 0.9686, 0.9528, 0.9761, 0.9794, 0.9875, 0.9659,
        0.9752, 0.9797, 0.9689, 0.9822, 0.9729, 0.9738, 0.9861],
       device='cuda:0') torch.Size([16])
Epoch: 27 | Batch_idx: 0 |  Loss: (0.5754) |  Loss2: (0.0000) | Acc: (78.00%) (101/128)
Epoch: 27 | Batch_idx: 10 |  Loss: (0.5976) |  Loss2: (0.0000) | Acc: (78.00%) (1101/1408)
Epoch: 27 | Batch_idx: 20 |  Loss: (0.6029) |  Loss2: (0.0000) | Acc: (78.00%) (2117/2688)
Epoch: 27 | Batch_idx: 30 |  Loss: (0.6131) |  Loss2: (0.0000) | Acc: (78.00%) (3100/3968)
Epoch: 27 | Batch_idx: 40 |  Loss: (0.6066) |  Loss2: (0.0000) | Acc: (78.00%) (4122/5248)
Epoch: 27 | Batch_idx: 50 |  Loss: (0.6033) |  Loss2: (0.0000) | Acc: (78.00%) (5126/6528)
Epoch: 27 | Batch_idx: 60 |  Loss: (0.6044) |  Loss2: (0.0000) | Acc: (78.00%) (6128/7808)
Epoch: 27 | Batch_idx: 70 |  Loss: (0.6004) |  Loss2: (0.0000) | Acc: (78.00%) (7157/9088)
Epoch: 27 | Batch_idx: 80 |  Loss: (0.6043) |  Loss2: (0.0000) | Acc: (78.00%) (8161/10368)
Epoch: 27 | Batch_idx: 90 |  Loss: (0.6035) |  Loss2: (0.0000) | Acc: (78.00%) (9174/11648)
Epoch: 27 | Batch_idx: 100 |  Loss: (0.6051) |  Loss2: (0.0000) | Acc: (78.00%) (10188/12928)
Epoch: 27 | Batch_idx: 110 |  Loss: (0.6047) |  Loss2: (0.0000) | Acc: (78.00%) (11200/14208)
Epoch: 27 | Batch_idx: 120 |  Loss: (0.6050) |  Loss2: (0.0000) | Acc: (78.00%) (12227/15488)
Epoch: 27 | Batch_idx: 130 |  Loss: (0.6065) |  Loss2: (0.0000) | Acc: (78.00%) (13231/16768)
Epoch: 27 | Batch_idx: 140 |  Loss: (0.6070) |  Loss2: (0.0000) | Acc: (78.00%) (14227/18048)
Epoch: 27 | Batch_idx: 150 |  Loss: (0.6080) |  Loss2: (0.0000) | Acc: (78.00%) (15223/19328)
Epoch: 27 | Batch_idx: 160 |  Loss: (0.6061) |  Loss2: (0.0000) | Acc: (78.00%) (16245/20608)
Epoch: 27 | Batch_idx: 170 |  Loss: (0.6072) |  Loss2: (0.0000) | Acc: (78.00%) (17238/21888)
Epoch: 27 | Batch_idx: 180 |  Loss: (0.6105) |  Loss2: (0.0000) | Acc: (78.00%) (18215/23168)
Epoch: 27 | Batch_idx: 190 |  Loss: (0.6085) |  Loss2: (0.0000) | Acc: (78.00%) (19232/24448)
Epoch: 27 | Batch_idx: 200 |  Loss: (0.6075) |  Loss2: (0.0000) | Acc: (78.00%) (20250/25728)
Epoch: 27 | Batch_idx: 210 |  Loss: (0.6032) |  Loss2: (0.0000) | Acc: (78.00%) (21299/27008)
Epoch: 27 | Batch_idx: 220 |  Loss: (0.6026) |  Loss2: (0.0000) | Acc: (78.00%) (22314/28288)
Epoch: 27 | Batch_idx: 230 |  Loss: (0.6022) |  Loss2: (0.0000) | Acc: (78.00%) (23315/29568)
Epoch: 27 | Batch_idx: 240 |  Loss: (0.6039) |  Loss2: (0.0000) | Acc: (78.00%) (24318/30848)
Epoch: 27 | Batch_idx: 250 |  Loss: (0.6027) |  Loss2: (0.0000) | Acc: (78.00%) (25348/32128)
Epoch: 27 | Batch_idx: 260 |  Loss: (0.6051) |  Loss2: (0.0000) | Acc: (78.00%) (26324/33408)
Epoch: 27 | Batch_idx: 270 |  Loss: (0.6057) |  Loss2: (0.0000) | Acc: (78.00%) (27328/34688)
Epoch: 27 | Batch_idx: 280 |  Loss: (0.6054) |  Loss2: (0.0000) | Acc: (78.00%) (28325/35968)
Epoch: 27 | Batch_idx: 290 |  Loss: (0.6049) |  Loss2: (0.0000) | Acc: (78.00%) (29337/37248)
Epoch: 27 | Batch_idx: 300 |  Loss: (0.6045) |  Loss2: (0.0000) | Acc: (78.00%) (30359/38528)
Epoch: 27 | Batch_idx: 310 |  Loss: (0.6051) |  Loss2: (0.0000) | Acc: (78.00%) (31355/39808)
Epoch: 27 | Batch_idx: 320 |  Loss: (0.6048) |  Loss2: (0.0000) | Acc: (78.00%) (32360/41088)
Epoch: 27 | Batch_idx: 330 |  Loss: (0.6036) |  Loss2: (0.0000) | Acc: (78.00%) (33404/42368)
Epoch: 27 | Batch_idx: 340 |  Loss: (0.6031) |  Loss2: (0.0000) | Acc: (78.00%) (34431/43648)
Epoch: 27 | Batch_idx: 350 |  Loss: (0.6020) |  Loss2: (0.0000) | Acc: (78.00%) (35484/44928)
Epoch: 27 | Batch_idx: 360 |  Loss: (0.6011) |  Loss2: (0.0000) | Acc: (79.00%) (36523/46208)
Epoch: 27 | Batch_idx: 370 |  Loss: (0.6008) |  Loss2: (0.0000) | Acc: (79.00%) (37534/47488)
Epoch: 27 | Batch_idx: 380 |  Loss: (0.6004) |  Loss2: (0.0000) | Acc: (79.00%) (38550/48768)
Epoch: 27 | Batch_idx: 390 |  Loss: (0.6008) |  Loss2: (0.0000) | Acc: (79.00%) (39509/50000)
# TEST : Loss: (0.7691) | Acc: (74.00%) (7415/10000)
percent tensor([0.5071, 0.5058, 0.5067, 0.5070, 0.5070, 0.5088, 0.5070, 0.5077, 0.5064,
        0.5068, 0.5064, 0.5073, 0.5074, 0.5052, 0.5070, 0.5073],
       device='cuda:0') torch.Size([16])
percent tensor([0.4962, 0.4903, 0.4920, 0.4943, 0.4905, 0.4995, 0.4893, 0.4901, 0.4944,
        0.4900, 0.4939, 0.4910, 0.4958, 0.4936, 0.4936, 0.4956],
       device='cuda:0') torch.Size([16])
percent tensor([0.5019, 0.4883, 0.5096, 0.5224, 0.5177, 0.5418, 0.4973, 0.5114, 0.4896,
        0.4844, 0.4775, 0.4930, 0.4751, 0.4923, 0.5171, 0.5069],
       device='cuda:0') torch.Size([16])
percent tensor([0.5706, 0.5621, 0.5681, 0.5695, 0.5743, 0.5744, 0.5675, 0.5737, 0.5631,
        0.5614, 0.5612, 0.5644, 0.5645, 0.5608, 0.5691, 0.5725],
       device='cuda:0') torch.Size([16])
percent tensor([0.5275, 0.5114, 0.5230, 0.5417, 0.5322, 0.5719, 0.5160, 0.5312, 0.5151,
        0.5228, 0.5138, 0.5272, 0.5148, 0.5345, 0.5213, 0.5497],
       device='cuda:0') torch.Size([16])
percent tensor([0.5527, 0.5448, 0.5514, 0.5700, 0.5549, 0.5813, 0.5450, 0.5536, 0.5516,
        0.5540, 0.5528, 0.5428, 0.5460, 0.5709, 0.5351, 0.5587],
       device='cuda:0') torch.Size([16])
percent tensor([0.5158, 0.5139, 0.5203, 0.5213, 0.5188, 0.5084, 0.5191, 0.5239, 0.5160,
        0.5184, 0.5169, 0.5200, 0.5148, 0.5143, 0.5115, 0.5144],
       device='cuda:0') torch.Size([16])
percent tensor([0.9935, 0.9734, 0.9653, 0.9647, 0.9574, 0.9765, 0.9873, 0.9873, 0.9645,
        0.9785, 0.9857, 0.9799, 0.9864, 0.9769, 0.9678, 0.9850],
       device='cuda:0') torch.Size([16])
Epoch: 28 | Batch_idx: 0 |  Loss: (0.5550) |  Loss2: (0.0000) | Acc: (79.00%) (102/128)
Epoch: 28 | Batch_idx: 10 |  Loss: (0.5746) |  Loss2: (0.0000) | Acc: (80.00%) (1138/1408)
Epoch: 28 | Batch_idx: 20 |  Loss: (0.5837) |  Loss2: (0.0000) | Acc: (79.00%) (2148/2688)
Epoch: 28 | Batch_idx: 30 |  Loss: (0.5844) |  Loss2: (0.0000) | Acc: (79.00%) (3163/3968)
Epoch: 28 | Batch_idx: 40 |  Loss: (0.5709) |  Loss2: (0.0000) | Acc: (80.00%) (4199/5248)
Epoch: 28 | Batch_idx: 50 |  Loss: (0.5688) |  Loss2: (0.0000) | Acc: (80.00%) (5232/6528)
Epoch: 28 | Batch_idx: 60 |  Loss: (0.5698) |  Loss2: (0.0000) | Acc: (80.00%) (6258/7808)
Epoch: 28 | Batch_idx: 70 |  Loss: (0.5688) |  Loss2: (0.0000) | Acc: (80.00%) (7279/9088)
Epoch: 28 | Batch_idx: 80 |  Loss: (0.5690) |  Loss2: (0.0000) | Acc: (80.00%) (8310/10368)
Epoch: 28 | Batch_idx: 90 |  Loss: (0.5692) |  Loss2: (0.0000) | Acc: (80.00%) (9336/11648)
Epoch: 28 | Batch_idx: 100 |  Loss: (0.5749) |  Loss2: (0.0000) | Acc: (79.00%) (10335/12928)
Epoch: 28 | Batch_idx: 110 |  Loss: (0.5739) |  Loss2: (0.0000) | Acc: (79.00%) (11347/14208)
Epoch: 28 | Batch_idx: 120 |  Loss: (0.5757) |  Loss2: (0.0000) | Acc: (79.00%) (12359/15488)
Epoch: 28 | Batch_idx: 130 |  Loss: (0.5754) |  Loss2: (0.0000) | Acc: (79.00%) (13390/16768)
Epoch: 28 | Batch_idx: 140 |  Loss: (0.5771) |  Loss2: (0.0000) | Acc: (79.00%) (14414/18048)
Epoch: 28 | Batch_idx: 150 |  Loss: (0.5743) |  Loss2: (0.0000) | Acc: (79.00%) (15443/19328)
Epoch: 28 | Batch_idx: 160 |  Loss: (0.5759) |  Loss2: (0.0000) | Acc: (79.00%) (16454/20608)
Epoch: 28 | Batch_idx: 170 |  Loss: (0.5766) |  Loss2: (0.0000) | Acc: (79.00%) (17480/21888)
Epoch: 28 | Batch_idx: 180 |  Loss: (0.5776) |  Loss2: (0.0000) | Acc: (79.00%) (18493/23168)
Epoch: 28 | Batch_idx: 190 |  Loss: (0.5786) |  Loss2: (0.0000) | Acc: (79.00%) (19514/24448)
Epoch: 28 | Batch_idx: 200 |  Loss: (0.5783) |  Loss2: (0.0000) | Acc: (79.00%) (20541/25728)
Epoch: 28 | Batch_idx: 210 |  Loss: (0.5772) |  Loss2: (0.0000) | Acc: (79.00%) (21568/27008)
Epoch: 28 | Batch_idx: 220 |  Loss: (0.5807) |  Loss2: (0.0000) | Acc: (79.00%) (22574/28288)
Epoch: 28 | Batch_idx: 230 |  Loss: (0.5811) |  Loss2: (0.0000) | Acc: (79.00%) (23588/29568)
Epoch: 28 | Batch_idx: 240 |  Loss: (0.5828) |  Loss2: (0.0000) | Acc: (79.00%) (24579/30848)
Epoch: 28 | Batch_idx: 250 |  Loss: (0.5810) |  Loss2: (0.0000) | Acc: (79.00%) (25609/32128)
Epoch: 28 | Batch_idx: 260 |  Loss: (0.5805) |  Loss2: (0.0000) | Acc: (79.00%) (26613/33408)
Epoch: 28 | Batch_idx: 270 |  Loss: (0.5809) |  Loss2: (0.0000) | Acc: (79.00%) (27627/34688)
Epoch: 28 | Batch_idx: 280 |  Loss: (0.5800) |  Loss2: (0.0000) | Acc: (79.00%) (28655/35968)
Epoch: 28 | Batch_idx: 290 |  Loss: (0.5790) |  Loss2: (0.0000) | Acc: (79.00%) (29684/37248)
Epoch: 28 | Batch_idx: 300 |  Loss: (0.5771) |  Loss2: (0.0000) | Acc: (79.00%) (30723/38528)
Epoch: 28 | Batch_idx: 310 |  Loss: (0.5766) |  Loss2: (0.0000) | Acc: (79.00%) (31736/39808)
Epoch: 28 | Batch_idx: 320 |  Loss: (0.5747) |  Loss2: (0.0000) | Acc: (79.00%) (32801/41088)
Epoch: 28 | Batch_idx: 330 |  Loss: (0.5740) |  Loss2: (0.0000) | Acc: (79.00%) (33839/42368)
Epoch: 28 | Batch_idx: 340 |  Loss: (0.5742) |  Loss2: (0.0000) | Acc: (79.00%) (34855/43648)
Epoch: 28 | Batch_idx: 350 |  Loss: (0.5737) |  Loss2: (0.0000) | Acc: (79.00%) (35883/44928)
Epoch: 28 | Batch_idx: 360 |  Loss: (0.5740) |  Loss2: (0.0000) | Acc: (79.00%) (36906/46208)
Epoch: 28 | Batch_idx: 370 |  Loss: (0.5734) |  Loss2: (0.0000) | Acc: (79.00%) (37940/47488)
Epoch: 28 | Batch_idx: 380 |  Loss: (0.5729) |  Loss2: (0.0000) | Acc: (79.00%) (38967/48768)
Epoch: 28 | Batch_idx: 390 |  Loss: (0.5731) |  Loss2: (0.0000) | Acc: (79.00%) (39958/50000)
# TEST : Loss: (0.6560) | Acc: (77.00%) (7751/10000)
percent tensor([0.5068, 0.5060, 0.5060, 0.5070, 0.5064, 0.5088, 0.5066, 0.5073, 0.5063,
        0.5065, 0.5064, 0.5068, 0.5072, 0.5057, 0.5071, 0.5073],
       device='cuda:0') torch.Size([16])
percent tensor([0.4965, 0.4906, 0.4922, 0.4955, 0.4908, 0.4993, 0.4895, 0.4904, 0.4934,
        0.4904, 0.4941, 0.4913, 0.4958, 0.4935, 0.4939, 0.4958],
       device='cuda:0') torch.Size([16])
percent tensor([0.5004, 0.4852, 0.5083, 0.5213, 0.5175, 0.5374, 0.4938, 0.5114, 0.4872,
        0.4818, 0.4753, 0.4900, 0.4727, 0.4894, 0.5125, 0.5064],
       device='cuda:0') torch.Size([16])
percent tensor([0.5714, 0.5656, 0.5674, 0.5686, 0.5748, 0.5737, 0.5710, 0.5755, 0.5652,
        0.5626, 0.5638, 0.5670, 0.5668, 0.5668, 0.5712, 0.5762],
       device='cuda:0') torch.Size([16])
percent tensor([0.5224, 0.5128, 0.5205, 0.5433, 0.5317, 0.5610, 0.5159, 0.5291, 0.5146,
        0.5213, 0.5114, 0.5290, 0.5128, 0.5331, 0.5197, 0.5507],
       device='cuda:0') torch.Size([16])
percent tensor([0.5477, 0.5399, 0.5465, 0.5695, 0.5550, 0.5757, 0.5415, 0.5509, 0.5484,
        0.5454, 0.5465, 0.5355, 0.5386, 0.5667, 0.5304, 0.5577],
       device='cuda:0') torch.Size([16])
percent tensor([0.5175, 0.5156, 0.5227, 0.5231, 0.5231, 0.5099, 0.5202, 0.5260, 0.5166,
        0.5203, 0.5169, 0.5227, 0.5155, 0.5137, 0.5114, 0.5168],
       device='cuda:0') torch.Size([16])
percent tensor([0.9905, 0.9640, 0.9753, 0.9697, 0.9682, 0.9722, 0.9828, 0.9919, 0.9698,
        0.9756, 0.9758, 0.9772, 0.9790, 0.9780, 0.9682, 0.9881],
       device='cuda:0') torch.Size([16])
Epoch: 29 | Batch_idx: 0 |  Loss: (0.4585) |  Loss2: (0.0000) | Acc: (82.00%) (105/128)
Epoch: 29 | Batch_idx: 10 |  Loss: (0.5295) |  Loss2: (0.0000) | Acc: (80.00%) (1133/1408)
Epoch: 29 | Batch_idx: 20 |  Loss: (0.5257) |  Loss2: (0.0000) | Acc: (81.00%) (2185/2688)
Epoch: 29 | Batch_idx: 30 |  Loss: (0.5265) |  Loss2: (0.0000) | Acc: (81.00%) (3223/3968)
Epoch: 29 | Batch_idx: 40 |  Loss: (0.5247) |  Loss2: (0.0000) | Acc: (81.00%) (4276/5248)
Epoch: 29 | Batch_idx: 50 |  Loss: (0.5390) |  Loss2: (0.0000) | Acc: (81.00%) (5300/6528)
Epoch: 29 | Batch_idx: 60 |  Loss: (0.5454) |  Loss2: (0.0000) | Acc: (81.00%) (6332/7808)
Epoch: 29 | Batch_idx: 70 |  Loss: (0.5431) |  Loss2: (0.0000) | Acc: (81.00%) (7383/9088)
Epoch: 29 | Batch_idx: 80 |  Loss: (0.5449) |  Loss2: (0.0000) | Acc: (81.00%) (8425/10368)
Epoch: 29 | Batch_idx: 90 |  Loss: (0.5509) |  Loss2: (0.0000) | Acc: (81.00%) (9441/11648)
Epoch: 29 | Batch_idx: 100 |  Loss: (0.5517) |  Loss2: (0.0000) | Acc: (81.00%) (10482/12928)
Epoch: 29 | Batch_idx: 110 |  Loss: (0.5515) |  Loss2: (0.0000) | Acc: (81.00%) (11521/14208)
Epoch: 29 | Batch_idx: 120 |  Loss: (0.5490) |  Loss2: (0.0000) | Acc: (81.00%) (12563/15488)
Epoch: 29 | Batch_idx: 130 |  Loss: (0.5495) |  Loss2: (0.0000) | Acc: (81.00%) (13608/16768)
Epoch: 29 | Batch_idx: 140 |  Loss: (0.5483) |  Loss2: (0.0000) | Acc: (81.00%) (14655/18048)
Epoch: 29 | Batch_idx: 150 |  Loss: (0.5492) |  Loss2: (0.0000) | Acc: (81.00%) (15683/19328)
Epoch: 29 | Batch_idx: 160 |  Loss: (0.5508) |  Loss2: (0.0000) | Acc: (80.00%) (16691/20608)
Epoch: 29 | Batch_idx: 170 |  Loss: (0.5494) |  Loss2: (0.0000) | Acc: (81.00%) (17751/21888)
Epoch: 29 | Batch_idx: 180 |  Loss: (0.5504) |  Loss2: (0.0000) | Acc: (81.00%) (18775/23168)
Epoch: 29 | Batch_idx: 190 |  Loss: (0.5515) |  Loss2: (0.0000) | Acc: (80.00%) (19792/24448)
Epoch: 29 | Batch_idx: 200 |  Loss: (0.5495) |  Loss2: (0.0000) | Acc: (81.00%) (20843/25728)
Epoch: 29 | Batch_idx: 210 |  Loss: (0.5504) |  Loss2: (0.0000) | Acc: (81.00%) (21879/27008)
Epoch: 29 | Batch_idx: 220 |  Loss: (0.5505) |  Loss2: (0.0000) | Acc: (80.00%) (22910/28288)
Epoch: 29 | Batch_idx: 230 |  Loss: (0.5493) |  Loss2: (0.0000) | Acc: (81.00%) (23963/29568)
Epoch: 29 | Batch_idx: 240 |  Loss: (0.5510) |  Loss2: (0.0000) | Acc: (80.00%) (24981/30848)
Epoch: 29 | Batch_idx: 250 |  Loss: (0.5509) |  Loss2: (0.0000) | Acc: (80.00%) (26012/32128)
Epoch: 29 | Batch_idx: 260 |  Loss: (0.5496) |  Loss2: (0.0000) | Acc: (81.00%) (27070/33408)
Epoch: 29 | Batch_idx: 270 |  Loss: (0.5508) |  Loss2: (0.0000) | Acc: (80.00%) (28092/34688)
Epoch: 29 | Batch_idx: 280 |  Loss: (0.5491) |  Loss2: (0.0000) | Acc: (81.00%) (29145/35968)
Epoch: 29 | Batch_idx: 290 |  Loss: (0.5491) |  Loss2: (0.0000) | Acc: (81.00%) (30178/37248)
Epoch: 29 | Batch_idx: 300 |  Loss: (0.5486) |  Loss2: (0.0000) | Acc: (81.00%) (31214/38528)
Epoch: 29 | Batch_idx: 310 |  Loss: (0.5481) |  Loss2: (0.0000) | Acc: (81.00%) (32257/39808)
Epoch: 29 | Batch_idx: 320 |  Loss: (0.5472) |  Loss2: (0.0000) | Acc: (81.00%) (33309/41088)
Epoch: 29 | Batch_idx: 330 |  Loss: (0.5484) |  Loss2: (0.0000) | Acc: (81.00%) (34340/42368)
Epoch: 29 | Batch_idx: 340 |  Loss: (0.5483) |  Loss2: (0.0000) | Acc: (81.00%) (35397/43648)
Epoch: 29 | Batch_idx: 350 |  Loss: (0.5471) |  Loss2: (0.0000) | Acc: (81.00%) (36447/44928)
Epoch: 29 | Batch_idx: 360 |  Loss: (0.5469) |  Loss2: (0.0000) | Acc: (81.00%) (37490/46208)
Epoch: 29 | Batch_idx: 370 |  Loss: (0.5458) |  Loss2: (0.0000) | Acc: (81.00%) (38540/47488)
Epoch: 29 | Batch_idx: 380 |  Loss: (0.5462) |  Loss2: (0.0000) | Acc: (81.00%) (39567/48768)
Epoch: 29 | Batch_idx: 390 |  Loss: (0.5467) |  Loss2: (0.0000) | Acc: (81.00%) (40550/50000)
# TEST : Loss: (0.6867) | Acc: (76.00%) (7608/10000)
percent tensor([0.5074, 0.5062, 0.5061, 0.5072, 0.5066, 0.5093, 0.5068, 0.5076, 0.5066,
        0.5066, 0.5068, 0.5067, 0.5077, 0.5059, 0.5074, 0.5077],
       device='cuda:0') torch.Size([16])
percent tensor([0.4965, 0.4900, 0.4911, 0.4944, 0.4903, 0.5000, 0.4890, 0.4894, 0.4940,
        0.4898, 0.4947, 0.4905, 0.4960, 0.4935, 0.4941, 0.4959],
       device='cuda:0') torch.Size([16])
percent tensor([0.5009, 0.4848, 0.5086, 0.5177, 0.5168, 0.5383, 0.4953, 0.5099, 0.4910,
        0.4829, 0.4752, 0.4919, 0.4746, 0.4888, 0.5116, 0.5052],
       device='cuda:0') torch.Size([16])
percent tensor([0.5690, 0.5625, 0.5649, 0.5639, 0.5712, 0.5699, 0.5683, 0.5726, 0.5643,
        0.5612, 0.5626, 0.5643, 0.5638, 0.5647, 0.5680, 0.5725],
       device='cuda:0') torch.Size([16])
percent tensor([0.5190, 0.5085, 0.5271, 0.5359, 0.5343, 0.5596, 0.5126, 0.5312, 0.5147,
        0.5176, 0.5082, 0.5323, 0.5115, 0.5271, 0.5164, 0.5447],
       device='cuda:0') torch.Size([16])
percent tensor([0.5437, 0.5345, 0.5551, 0.5657, 0.5576, 0.5704, 0.5343, 0.5503, 0.5483,
        0.5452, 0.5453, 0.5426, 0.5384, 0.5612, 0.5251, 0.5499],
       device='cuda:0') torch.Size([16])
percent tensor([0.5162, 0.5164, 0.5217, 0.5220, 0.5206, 0.5083, 0.5187, 0.5243, 0.5174,
        0.5203, 0.5182, 0.5228, 0.5169, 0.5153, 0.5126, 0.5138],
       device='cuda:0') torch.Size([16])
percent tensor([0.9896, 0.9712, 0.9620, 0.9697, 0.9629, 0.9745, 0.9758, 0.9863, 0.9692,
        0.9747, 0.9812, 0.9759, 0.9760, 0.9786, 0.9728, 0.9843],
       device='cuda:0') torch.Size([16])
False Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=128, out_features=16, bias=False)
True Linear(in_features=16, out_features=2, bias=False)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=128, out_features=16, bias=False)
True Linear(in_features=16, out_features=2, bias=False)
False Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=256, out_features=32, bias=False)
True Linear(in_features=32, out_features=2, bias=False)
False Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=256, out_features=32, bias=False)
True Linear(in_features=32, out_features=2, bias=False)
False Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=512, out_features=64, bias=False)
True Linear(in_features=64, out_features=2, bias=False)
False Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=512, out_features=64, bias=False)
True Linear(in_features=64, out_features=2, bias=False)
False Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1024, out_features=128, bias=False)
True Linear(in_features=128, out_features=2, bias=False)
False Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1024, out_features=128, bias=False)
True Linear(in_features=128, out_features=2, bias=False)
False Linear(in_features=512, out_features=10, bias=True)
Epoch: 30 | Batch_idx: 0 |  Loss: (0.4504) |  Loss2: (0.0000) | Acc: (86.00%) (111/128)
Epoch: 30 | Batch_idx: 10 |  Loss: (0.5724) |  Loss2: (0.0000) | Acc: (80.00%) (1134/1408)
Epoch: 30 | Batch_idx: 20 |  Loss: (0.6030) |  Loss2: (0.0000) | Acc: (79.00%) (2136/2688)
Epoch: 30 | Batch_idx: 30 |  Loss: (0.6157) |  Loss2: (0.0000) | Acc: (78.00%) (3128/3968)
Epoch: 30 | Batch_idx: 40 |  Loss: (0.6265) |  Loss2: (0.0000) | Acc: (78.00%) (4123/5248)
Epoch: 30 | Batch_idx: 50 |  Loss: (0.6262) |  Loss2: (0.0000) | Acc: (78.00%) (5120/6528)
Epoch: 30 | Batch_idx: 60 |  Loss: (0.6277) |  Loss2: (0.0000) | Acc: (78.00%) (6119/7808)
Epoch: 30 | Batch_idx: 70 |  Loss: (0.6269) |  Loss2: (0.0000) | Acc: (78.00%) (7121/9088)
Epoch: 30 | Batch_idx: 80 |  Loss: (0.6288) |  Loss2: (0.0000) | Acc: (78.00%) (8125/10368)
Epoch: 30 | Batch_idx: 90 |  Loss: (0.6253) |  Loss2: (0.0000) | Acc: (78.00%) (9141/11648)
Epoch: 30 | Batch_idx: 100 |  Loss: (0.6265) |  Loss2: (0.0000) | Acc: (78.00%) (10135/12928)
Epoch: 30 | Batch_idx: 110 |  Loss: (0.6245) |  Loss2: (0.0000) | Acc: (78.00%) (11149/14208)
Epoch: 30 | Batch_idx: 120 |  Loss: (0.6242) |  Loss2: (0.0000) | Acc: (78.00%) (12139/15488)
Epoch: 30 | Batch_idx: 130 |  Loss: (0.6234) |  Loss2: (0.0000) | Acc: (78.00%) (13148/16768)
Epoch: 30 | Batch_idx: 140 |  Loss: (0.6247) |  Loss2: (0.0000) | Acc: (78.00%) (14129/18048)
Epoch: 30 | Batch_idx: 150 |  Loss: (0.6222) |  Loss2: (0.0000) | Acc: (78.00%) (15151/19328)
Epoch: 30 | Batch_idx: 160 |  Loss: (0.6182) |  Loss2: (0.0000) | Acc: (78.00%) (16183/20608)
Epoch: 30 | Batch_idx: 170 |  Loss: (0.6147) |  Loss2: (0.0000) | Acc: (78.00%) (17219/21888)
Epoch: 30 | Batch_idx: 180 |  Loss: (0.6137) |  Loss2: (0.0000) | Acc: (78.00%) (18220/23168)
Epoch: 30 | Batch_idx: 190 |  Loss: (0.6140) |  Loss2: (0.0000) | Acc: (78.00%) (19229/24448)
Epoch: 30 | Batch_idx: 200 |  Loss: (0.6122) |  Loss2: (0.0000) | Acc: (78.00%) (20246/25728)
Epoch: 30 | Batch_idx: 210 |  Loss: (0.6075) |  Loss2: (0.0000) | Acc: (78.00%) (21291/27008)
Epoch: 30 | Batch_idx: 220 |  Loss: (0.6060) |  Loss2: (0.0000) | Acc: (78.00%) (22318/28288)
Epoch: 30 | Batch_idx: 230 |  Loss: (0.6054) |  Loss2: (0.0000) | Acc: (78.00%) (23336/29568)
Epoch: 30 | Batch_idx: 240 |  Loss: (0.6046) |  Loss2: (0.0000) | Acc: (78.00%) (24354/30848)
Epoch: 30 | Batch_idx: 250 |  Loss: (0.6027) |  Loss2: (0.0000) | Acc: (78.00%) (25373/32128)
Epoch: 30 | Batch_idx: 260 |  Loss: (0.6019) |  Loss2: (0.0000) | Acc: (79.00%) (26395/33408)
Epoch: 30 | Batch_idx: 270 |  Loss: (0.6000) |  Loss2: (0.0000) | Acc: (79.00%) (27428/34688)
Epoch: 30 | Batch_idx: 280 |  Loss: (0.5995) |  Loss2: (0.0000) | Acc: (79.00%) (28454/35968)
Epoch: 30 | Batch_idx: 290 |  Loss: (0.5998) |  Loss2: (0.0000) | Acc: (79.00%) (29483/37248)
Epoch: 30 | Batch_idx: 300 |  Loss: (0.5967) |  Loss2: (0.0000) | Acc: (79.00%) (30531/38528)
Epoch: 30 | Batch_idx: 310 |  Loss: (0.5948) |  Loss2: (0.0000) | Acc: (79.00%) (31566/39808)
Epoch: 30 | Batch_idx: 320 |  Loss: (0.5935) |  Loss2: (0.0000) | Acc: (79.00%) (32602/41088)
Epoch: 30 | Batch_idx: 330 |  Loss: (0.5920) |  Loss2: (0.0000) | Acc: (79.00%) (33635/42368)
Epoch: 30 | Batch_idx: 340 |  Loss: (0.5903) |  Loss2: (0.0000) | Acc: (79.00%) (34679/43648)
Epoch: 30 | Batch_idx: 350 |  Loss: (0.5913) |  Loss2: (0.0000) | Acc: (79.00%) (35671/44928)
Epoch: 30 | Batch_idx: 360 |  Loss: (0.5899) |  Loss2: (0.0000) | Acc: (79.00%) (36716/46208)
Epoch: 30 | Batch_idx: 370 |  Loss: (0.5889) |  Loss2: (0.0000) | Acc: (79.00%) (37763/47488)
Epoch: 30 | Batch_idx: 380 |  Loss: (0.5889) |  Loss2: (0.0000) | Acc: (79.00%) (38793/48768)
Epoch: 30 | Batch_idx: 390 |  Loss: (0.5884) |  Loss2: (0.0000) | Acc: (79.00%) (39765/50000)
=> saving checkpoint 'drive/app/torch/save_Schedule/checkpoint_030.pth.tar'
# TEST : Loss: (0.6010) | Acc: (79.00%) (7938/10000)
percent tensor([0.5096, 0.5098, 0.5089, 0.5091, 0.5093, 0.5100, 0.5103, 0.5110, 0.5093,
        0.5102, 0.5095, 0.5099, 0.5104, 0.5092, 0.5095, 0.5100],
       device='cuda:0') torch.Size([16])
percent tensor([0.4952, 0.4864, 0.4892, 0.4926, 0.4879, 0.4987, 0.4856, 0.4868, 0.4915,
        0.4864, 0.4923, 0.4881, 0.4941, 0.4904, 0.4920, 0.4939],
       device='cuda:0') torch.Size([16])
percent tensor([0.4874, 0.4882, 0.5067, 0.5135, 0.5173, 0.5113, 0.5043, 0.5116, 0.4915,
        0.4879, 0.4754, 0.4893, 0.4619, 0.4974, 0.4991, 0.4922],
       device='cuda:0') torch.Size([16])
percent tensor([0.6241, 0.6194, 0.6159, 0.6158, 0.6255, 0.6225, 0.6262, 0.6293, 0.6170,
        0.6193, 0.6215, 0.6221, 0.6201, 0.6191, 0.6254, 0.6304],
       device='cuda:0') torch.Size([16])
percent tensor([0.5592, 0.5311, 0.5675, 0.5918, 0.5727, 0.6115, 0.5435, 0.5766, 0.5490,
        0.5523, 0.5440, 0.5713, 0.5421, 0.5691, 0.5487, 0.5888],
       device='cuda:0') torch.Size([16])
percent tensor([0.5281, 0.5207, 0.5339, 0.5528, 0.5356, 0.5602, 0.5192, 0.5283, 0.5345,
        0.5316, 0.5314, 0.5236, 0.5262, 0.5497, 0.5081, 0.5371],
       device='cuda:0') torch.Size([16])
percent tensor([0.5186, 0.5193, 0.5203, 0.5205, 0.5183, 0.5173, 0.5189, 0.5190, 0.5211,
        0.5222, 0.5237, 0.5230, 0.5243, 0.5219, 0.5120, 0.5179],
       device='cuda:0') torch.Size([16])
percent tensor([0.9929, 0.9800, 0.9767, 0.9765, 0.9759, 0.9808, 0.9834, 0.9917, 0.9757,
        0.9813, 0.9868, 0.9842, 0.9832, 0.9842, 0.9760, 0.9914],
       device='cuda:0') torch.Size([16])
Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 3, 3, 3]) tensor(169.9039, device='cuda:0')
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(794.2169, device='cuda:0')
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(784.8654, device='cuda:0')
Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([128, 64, 3, 3]) tensor(1528.2311, device='cuda:0')
Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([128, 64, 1, 1]) tensor(506.4667, device='cuda:0')
Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([128, 128, 3, 3]) tensor(2189.4900, device='cuda:0')
Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([256, 128, 3, 3]) tensor(4308.3125, device='cuda:0')
Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([256, 128, 1, 1]) tensor(1431.3247, device='cuda:0')
Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([256, 256, 3, 3]) tensor(6105.6460, device='cuda:0')
Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([512, 256, 3, 3]) tensor(12127.5391, device='cuda:0')
Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([512, 256, 1, 1]) tensor(4041.3186, device='cuda:0')
Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([512, 512, 3, 3]) tensor(17125.4824, device='cuda:0')
Epoch: 31 | Batch_idx: 0 |  Loss: (0.6467) |  Loss2: (0.0000) | Acc: (75.00%) (97/128)
Epoch: 31 | Batch_idx: 10 |  Loss: (0.5848) |  Loss2: (0.0000) | Acc: (79.00%) (1118/1408)
Epoch: 31 | Batch_idx: 20 |  Loss: (0.5642) |  Loss2: (0.0000) | Acc: (80.00%) (2161/2688)
Epoch: 31 | Batch_idx: 30 |  Loss: (0.5669) |  Loss2: (0.0000) | Acc: (80.00%) (3190/3968)
Epoch: 31 | Batch_idx: 40 |  Loss: (0.5671) |  Loss2: (0.0000) | Acc: (80.00%) (4212/5248)
Epoch: 31 | Batch_idx: 50 |  Loss: (0.5669) |  Loss2: (0.0000) | Acc: (80.00%) (5238/6528)
Epoch: 31 | Batch_idx: 60 |  Loss: (0.5639) |  Loss2: (0.0000) | Acc: (80.00%) (6256/7808)
Epoch: 31 | Batch_idx: 70 |  Loss: (0.5701) |  Loss2: (0.0000) | Acc: (79.00%) (7256/9088)
Epoch: 31 | Batch_idx: 80 |  Loss: (0.5694) |  Loss2: (0.0000) | Acc: (79.00%) (8286/10368)
Epoch: 31 | Batch_idx: 90 |  Loss: (0.5659) |  Loss2: (0.0000) | Acc: (80.00%) (9331/11648)
Epoch: 31 | Batch_idx: 100 |  Loss: (0.5639) |  Loss2: (0.0000) | Acc: (80.00%) (10367/12928)
Epoch: 31 | Batch_idx: 110 |  Loss: (0.5620) |  Loss2: (0.0000) | Acc: (80.00%) (11394/14208)
Epoch: 31 | Batch_idx: 120 |  Loss: (0.5635) |  Loss2: (0.0000) | Acc: (80.00%) (12397/15488)
Epoch: 31 | Batch_idx: 130 |  Loss: (0.5599) |  Loss2: (0.0000) | Acc: (80.00%) (13446/16768)
Epoch: 31 | Batch_idx: 140 |  Loss: (0.5583) |  Loss2: (0.0000) | Acc: (80.00%) (14478/18048)
Epoch: 31 | Batch_idx: 150 |  Loss: (0.5576) |  Loss2: (0.0000) | Acc: (80.00%) (15513/19328)
Epoch: 31 | Batch_idx: 160 |  Loss: (0.5570) |  Loss2: (0.0000) | Acc: (80.00%) (16538/20608)
Epoch: 31 | Batch_idx: 170 |  Loss: (0.5559) |  Loss2: (0.0000) | Acc: (80.00%) (17568/21888)
Epoch: 31 | Batch_idx: 180 |  Loss: (0.5549) |  Loss2: (0.0000) | Acc: (80.00%) (18612/23168)
Epoch: 31 | Batch_idx: 190 |  Loss: (0.5540) |  Loss2: (0.0000) | Acc: (80.00%) (19660/24448)
Epoch: 31 | Batch_idx: 200 |  Loss: (0.5536) |  Loss2: (0.0000) | Acc: (80.00%) (20699/25728)
Epoch: 31 | Batch_idx: 210 |  Loss: (0.5520) |  Loss2: (0.0000) | Acc: (80.00%) (21751/27008)
Epoch: 31 | Batch_idx: 220 |  Loss: (0.5517) |  Loss2: (0.0000) | Acc: (80.00%) (22791/28288)
Epoch: 31 | Batch_idx: 230 |  Loss: (0.5515) |  Loss2: (0.0000) | Acc: (80.00%) (23830/29568)
Epoch: 31 | Batch_idx: 240 |  Loss: (0.5516) |  Loss2: (0.0000) | Acc: (80.00%) (24871/30848)
Epoch: 31 | Batch_idx: 250 |  Loss: (0.5508) |  Loss2: (0.0000) | Acc: (80.00%) (25925/32128)
Epoch: 31 | Batch_idx: 260 |  Loss: (0.5500) |  Loss2: (0.0000) | Acc: (80.00%) (26971/33408)
Epoch: 31 | Batch_idx: 270 |  Loss: (0.5504) |  Loss2: (0.0000) | Acc: (80.00%) (28000/34688)
Epoch: 31 | Batch_idx: 280 |  Loss: (0.5503) |  Loss2: (0.0000) | Acc: (80.00%) (29030/35968)
Epoch: 31 | Batch_idx: 290 |  Loss: (0.5495) |  Loss2: (0.0000) | Acc: (80.00%) (30070/37248)
Epoch: 31 | Batch_idx: 300 |  Loss: (0.5499) |  Loss2: (0.0000) | Acc: (80.00%) (31102/38528)
Epoch: 31 | Batch_idx: 310 |  Loss: (0.5493) |  Loss2: (0.0000) | Acc: (80.00%) (32143/39808)
Epoch: 31 | Batch_idx: 320 |  Loss: (0.5483) |  Loss2: (0.0000) | Acc: (80.00%) (33187/41088)
Epoch: 31 | Batch_idx: 330 |  Loss: (0.5483) |  Loss2: (0.0000) | Acc: (80.00%) (34226/42368)
Epoch: 31 | Batch_idx: 340 |  Loss: (0.5488) |  Loss2: (0.0000) | Acc: (80.00%) (35265/43648)
Epoch: 31 | Batch_idx: 350 |  Loss: (0.5481) |  Loss2: (0.0000) | Acc: (80.00%) (36310/44928)
Epoch: 31 | Batch_idx: 360 |  Loss: (0.5475) |  Loss2: (0.0000) | Acc: (80.00%) (37355/46208)
Epoch: 31 | Batch_idx: 370 |  Loss: (0.5468) |  Loss2: (0.0000) | Acc: (80.00%) (38407/47488)
Epoch: 31 | Batch_idx: 380 |  Loss: (0.5465) |  Loss2: (0.0000) | Acc: (80.00%) (39448/48768)
Epoch: 31 | Batch_idx: 390 |  Loss: (0.5457) |  Loss2: (0.0000) | Acc: (80.00%) (40466/50000)
# TEST : Loss: (0.5775) | Acc: (80.00%) (8037/10000)
percent tensor([0.5113, 0.5122, 0.5107, 0.5106, 0.5111, 0.5105, 0.5127, 0.5132, 0.5115,
        0.5126, 0.5116, 0.5119, 0.5124, 0.5116, 0.5108, 0.5117],
       device='cuda:0') torch.Size([16])
percent tensor([0.4947, 0.4855, 0.4879, 0.4918, 0.4866, 0.4984, 0.4846, 0.4855, 0.4908,
        0.4854, 0.4918, 0.4871, 0.4936, 0.4901, 0.4912, 0.4934],
       device='cuda:0') torch.Size([16])
percent tensor([0.4842, 0.4898, 0.5079, 0.5142, 0.5200, 0.5015, 0.5094, 0.5143, 0.4958,
        0.4920, 0.4794, 0.4905, 0.4585, 0.5057, 0.4944, 0.4885],
       device='cuda:0') torch.Size([16])
percent tensor([0.6256, 0.6231, 0.6172, 0.6170, 0.6268, 0.6199, 0.6297, 0.6312, 0.6205,
        0.6235, 0.6264, 0.6252, 0.6237, 0.6238, 0.6269, 0.6313],
       device='cuda:0') torch.Size([16])
percent tensor([0.5721, 0.5435, 0.5794, 0.6044, 0.5811, 0.6137, 0.5540, 0.5858, 0.5661,
        0.5679, 0.5636, 0.5842, 0.5592, 0.5890, 0.5565, 0.5959],
       device='cuda:0') torch.Size([16])
percent tensor([0.5361, 0.5302, 0.5417, 0.5623, 0.5432, 0.5726, 0.5268, 0.5347, 0.5439,
        0.5414, 0.5416, 0.5343, 0.5366, 0.5621, 0.5171, 0.5454],
       device='cuda:0') torch.Size([16])
percent tensor([0.5246, 0.5248, 0.5260, 0.5275, 0.5238, 0.5297, 0.5242, 0.5246, 0.5267,
        0.5290, 0.5312, 0.5298, 0.5334, 0.5319, 0.5168, 0.5250],
       device='cuda:0') torch.Size([16])
percent tensor([0.9952, 0.9856, 0.9829, 0.9830, 0.9829, 0.9845, 0.9887, 0.9945, 0.9822,
        0.9872, 0.9910, 0.9892, 0.9885, 0.9903, 0.9823, 0.9937],
       device='cuda:0') torch.Size([16])
Epoch: 32 | Batch_idx: 0 |  Loss: (0.5141) |  Loss2: (0.0000) | Acc: (80.00%) (103/128)
Epoch: 32 | Batch_idx: 10 |  Loss: (0.5207) |  Loss2: (0.0000) | Acc: (81.00%) (1147/1408)
Epoch: 32 | Batch_idx: 20 |  Loss: (0.5352) |  Loss2: (0.0000) | Acc: (81.00%) (2182/2688)
Epoch: 32 | Batch_idx: 30 |  Loss: (0.5375) |  Loss2: (0.0000) | Acc: (80.00%) (3214/3968)
Epoch: 32 | Batch_idx: 40 |  Loss: (0.5381) |  Loss2: (0.0000) | Acc: (81.00%) (4258/5248)
Epoch: 32 | Batch_idx: 50 |  Loss: (0.5361) |  Loss2: (0.0000) | Acc: (81.00%) (5303/6528)
Epoch: 32 | Batch_idx: 60 |  Loss: (0.5374) |  Loss2: (0.0000) | Acc: (81.00%) (6331/7808)
Epoch: 32 | Batch_idx: 70 |  Loss: (0.5385) |  Loss2: (0.0000) | Acc: (81.00%) (7389/9088)
Epoch: 32 | Batch_idx: 80 |  Loss: (0.5376) |  Loss2: (0.0000) | Acc: (81.00%) (8446/10368)
Epoch: 32 | Batch_idx: 90 |  Loss: (0.5410) |  Loss2: (0.0000) | Acc: (81.00%) (9476/11648)
Epoch: 32 | Batch_idx: 100 |  Loss: (0.5377) |  Loss2: (0.0000) | Acc: (81.00%) (10527/12928)
Epoch: 32 | Batch_idx: 110 |  Loss: (0.5395) |  Loss2: (0.0000) | Acc: (81.00%) (11552/14208)
Epoch: 32 | Batch_idx: 120 |  Loss: (0.5373) |  Loss2: (0.0000) | Acc: (81.00%) (12599/15488)
Epoch: 32 | Batch_idx: 130 |  Loss: (0.5365) |  Loss2: (0.0000) | Acc: (81.00%) (13640/16768)
Epoch: 32 | Batch_idx: 140 |  Loss: (0.5346) |  Loss2: (0.0000) | Acc: (81.00%) (14701/18048)
Epoch: 32 | Batch_idx: 150 |  Loss: (0.5339) |  Loss2: (0.0000) | Acc: (81.00%) (15735/19328)
Epoch: 32 | Batch_idx: 160 |  Loss: (0.5356) |  Loss2: (0.0000) | Acc: (81.00%) (16772/20608)
Epoch: 32 | Batch_idx: 170 |  Loss: (0.5360) |  Loss2: (0.0000) | Acc: (81.00%) (17815/21888)
Epoch: 32 | Batch_idx: 180 |  Loss: (0.5350) |  Loss2: (0.0000) | Acc: (81.00%) (18861/23168)
Epoch: 32 | Batch_idx: 190 |  Loss: (0.5359) |  Loss2: (0.0000) | Acc: (81.00%) (19889/24448)
Epoch: 32 | Batch_idx: 200 |  Loss: (0.5349) |  Loss2: (0.0000) | Acc: (81.00%) (20953/25728)
Epoch: 32 | Batch_idx: 210 |  Loss: (0.5346) |  Loss2: (0.0000) | Acc: (81.00%) (22008/27008)
Epoch: 32 | Batch_idx: 220 |  Loss: (0.5335) |  Loss2: (0.0000) | Acc: (81.00%) (23065/28288)
Epoch: 32 | Batch_idx: 230 |  Loss: (0.5330) |  Loss2: (0.0000) | Acc: (81.00%) (24114/29568)
Epoch: 32 | Batch_idx: 240 |  Loss: (0.5348) |  Loss2: (0.0000) | Acc: (81.00%) (25154/30848)
Epoch: 32 | Batch_idx: 250 |  Loss: (0.5345) |  Loss2: (0.0000) | Acc: (81.00%) (26186/32128)
Epoch: 32 | Batch_idx: 260 |  Loss: (0.5347) |  Loss2: (0.0000) | Acc: (81.00%) (27231/33408)
Epoch: 32 | Batch_idx: 270 |  Loss: (0.5357) |  Loss2: (0.0000) | Acc: (81.00%) (28249/34688)
Epoch: 32 | Batch_idx: 280 |  Loss: (0.5350) |  Loss2: (0.0000) | Acc: (81.00%) (29288/35968)
Epoch: 32 | Batch_idx: 290 |  Loss: (0.5352) |  Loss2: (0.0000) | Acc: (81.00%) (30325/37248)
Epoch: 32 | Batch_idx: 300 |  Loss: (0.5361) |  Loss2: (0.0000) | Acc: (81.00%) (31347/38528)
Epoch: 32 | Batch_idx: 310 |  Loss: (0.5357) |  Loss2: (0.0000) | Acc: (81.00%) (32390/39808)
Epoch: 32 | Batch_idx: 320 |  Loss: (0.5359) |  Loss2: (0.0000) | Acc: (81.00%) (33435/41088)
Epoch: 32 | Batch_idx: 330 |  Loss: (0.5350) |  Loss2: (0.0000) | Acc: (81.00%) (34503/42368)
Epoch: 32 | Batch_idx: 340 |  Loss: (0.5341) |  Loss2: (0.0000) | Acc: (81.00%) (35560/43648)
Epoch: 32 | Batch_idx: 350 |  Loss: (0.5342) |  Loss2: (0.0000) | Acc: (81.00%) (36602/44928)
Epoch: 32 | Batch_idx: 360 |  Loss: (0.5350) |  Loss2: (0.0000) | Acc: (81.00%) (37634/46208)
Epoch: 32 | Batch_idx: 370 |  Loss: (0.5344) |  Loss2: (0.0000) | Acc: (81.00%) (38702/47488)
Epoch: 32 | Batch_idx: 380 |  Loss: (0.5340) |  Loss2: (0.0000) | Acc: (81.00%) (39761/48768)
Epoch: 32 | Batch_idx: 390 |  Loss: (0.5339) |  Loss2: (0.0000) | Acc: (81.00%) (40761/50000)
# TEST : Loss: (0.5703) | Acc: (80.00%) (8069/10000)
percent tensor([0.5131, 0.5146, 0.5125, 0.5123, 0.5130, 0.5114, 0.5150, 0.5155, 0.5136,
        0.5149, 0.5137, 0.5140, 0.5145, 0.5140, 0.5126, 0.5136],
       device='cuda:0') torch.Size([16])
percent tensor([0.4947, 0.4854, 0.4878, 0.4918, 0.4864, 0.4984, 0.4844, 0.4851, 0.4908,
        0.4854, 0.4918, 0.4872, 0.4937, 0.4903, 0.4912, 0.4933],
       device='cuda:0') torch.Size([16])
percent tensor([0.4853, 0.4925, 0.5093, 0.5165, 0.5222, 0.4999, 0.5129, 0.5168, 0.5003,
        0.4955, 0.4840, 0.4918, 0.4597, 0.5131, 0.4941, 0.4892],
       device='cuda:0') torch.Size([16])
percent tensor([0.6261, 0.6245, 0.6178, 0.6175, 0.6267, 0.6184, 0.6310, 0.6315, 0.6222,
        0.6255, 0.6288, 0.6269, 0.6255, 0.6261, 0.6272, 0.6315],
       device='cuda:0') torch.Size([16])
percent tensor([0.5722, 0.5431, 0.5778, 0.6039, 0.5767, 0.6082, 0.5514, 0.5808, 0.5695,
        0.5689, 0.5680, 0.5834, 0.5626, 0.5933, 0.5521, 0.5914],
       device='cuda:0') torch.Size([16])
percent tensor([0.5443, 0.5387, 0.5476, 0.5700, 0.5492, 0.5854, 0.5329, 0.5394, 0.5529,
        0.5503, 0.5511, 0.5427, 0.5476, 0.5732, 0.5243, 0.5538],
       device='cuda:0') torch.Size([16])
percent tensor([0.5302, 0.5296, 0.5307, 0.5333, 0.5281, 0.5415, 0.5283, 0.5291, 0.5320,
        0.5351, 0.5381, 0.5347, 0.5420, 0.5408, 0.5204, 0.5312],
       device='cuda:0') torch.Size([16])
percent tensor([0.9970, 0.9896, 0.9869, 0.9871, 0.9871, 0.9886, 0.9922, 0.9963, 0.9868,
        0.9910, 0.9940, 0.9918, 0.9922, 0.9938, 0.9872, 0.9955],
       device='cuda:0') torch.Size([16])
Epoch: 33 | Batch_idx: 0 |  Loss: (0.6353) |  Loss2: (0.0000) | Acc: (75.00%) (97/128)
Epoch: 33 | Batch_idx: 10 |  Loss: (0.5197) |  Loss2: (0.0000) | Acc: (81.00%) (1147/1408)
Epoch: 33 | Batch_idx: 20 |  Loss: (0.5263) |  Loss2: (0.0000) | Acc: (81.00%) (2192/2688)
Epoch: 33 | Batch_idx: 30 |  Loss: (0.5188) |  Loss2: (0.0000) | Acc: (82.00%) (3267/3968)
Epoch: 33 | Batch_idx: 40 |  Loss: (0.5217) |  Loss2: (0.0000) | Acc: (81.00%) (4303/5248)
Epoch: 33 | Batch_idx: 50 |  Loss: (0.5237) |  Loss2: (0.0000) | Acc: (82.00%) (5357/6528)
Epoch: 33 | Batch_idx: 60 |  Loss: (0.5194) |  Loss2: (0.0000) | Acc: (82.00%) (6419/7808)
Epoch: 33 | Batch_idx: 70 |  Loss: (0.5225) |  Loss2: (0.0000) | Acc: (82.00%) (7461/9088)
Epoch: 33 | Batch_idx: 80 |  Loss: (0.5250) |  Loss2: (0.0000) | Acc: (82.00%) (8504/10368)
Epoch: 33 | Batch_idx: 90 |  Loss: (0.5259) |  Loss2: (0.0000) | Acc: (82.00%) (9554/11648)
Epoch: 33 | Batch_idx: 100 |  Loss: (0.5259) |  Loss2: (0.0000) | Acc: (81.00%) (10590/12928)
Epoch: 33 | Batch_idx: 110 |  Loss: (0.5247) |  Loss2: (0.0000) | Acc: (81.00%) (11643/14208)
Epoch: 33 | Batch_idx: 120 |  Loss: (0.5255) |  Loss2: (0.0000) | Acc: (82.00%) (12701/15488)
Epoch: 33 | Batch_idx: 130 |  Loss: (0.5280) |  Loss2: (0.0000) | Acc: (81.00%) (13728/16768)
Epoch: 33 | Batch_idx: 140 |  Loss: (0.5288) |  Loss2: (0.0000) | Acc: (81.00%) (14763/18048)
Epoch: 33 | Batch_idx: 150 |  Loss: (0.5264) |  Loss2: (0.0000) | Acc: (81.00%) (15831/19328)
Epoch: 33 | Batch_idx: 160 |  Loss: (0.5278) |  Loss2: (0.0000) | Acc: (81.00%) (16853/20608)
Epoch: 33 | Batch_idx: 170 |  Loss: (0.5256) |  Loss2: (0.0000) | Acc: (81.00%) (17912/21888)
Epoch: 33 | Batch_idx: 180 |  Loss: (0.5269) |  Loss2: (0.0000) | Acc: (81.00%) (18955/23168)
Epoch: 33 | Batch_idx: 190 |  Loss: (0.5274) |  Loss2: (0.0000) | Acc: (81.00%) (20004/24448)
Epoch: 33 | Batch_idx: 200 |  Loss: (0.5260) |  Loss2: (0.0000) | Acc: (81.00%) (21069/25728)
Epoch: 33 | Batch_idx: 210 |  Loss: (0.5261) |  Loss2: (0.0000) | Acc: (81.00%) (22102/27008)
Epoch: 33 | Batch_idx: 220 |  Loss: (0.5260) |  Loss2: (0.0000) | Acc: (81.00%) (23149/28288)
Epoch: 33 | Batch_idx: 230 |  Loss: (0.5244) |  Loss2: (0.0000) | Acc: (81.00%) (24199/29568)
Epoch: 33 | Batch_idx: 240 |  Loss: (0.5259) |  Loss2: (0.0000) | Acc: (81.00%) (25229/30848)
Epoch: 33 | Batch_idx: 250 |  Loss: (0.5253) |  Loss2: (0.0000) | Acc: (81.00%) (26286/32128)
Epoch: 33 | Batch_idx: 260 |  Loss: (0.5254) |  Loss2: (0.0000) | Acc: (81.00%) (27327/33408)
Epoch: 33 | Batch_idx: 270 |  Loss: (0.5247) |  Loss2: (0.0000) | Acc: (81.00%) (28383/34688)
Epoch: 33 | Batch_idx: 280 |  Loss: (0.5255) |  Loss2: (0.0000) | Acc: (81.00%) (29428/35968)
Epoch: 33 | Batch_idx: 290 |  Loss: (0.5280) |  Loss2: (0.0000) | Acc: (81.00%) (30436/37248)
Epoch: 33 | Batch_idx: 300 |  Loss: (0.5286) |  Loss2: (0.0000) | Acc: (81.00%) (31477/38528)
Epoch: 33 | Batch_idx: 310 |  Loss: (0.5282) |  Loss2: (0.0000) | Acc: (81.00%) (32523/39808)
Epoch: 33 | Batch_idx: 320 |  Loss: (0.5282) |  Loss2: (0.0000) | Acc: (81.00%) (33568/41088)
Epoch: 33 | Batch_idx: 330 |  Loss: (0.5276) |  Loss2: (0.0000) | Acc: (81.00%) (34619/42368)
Epoch: 33 | Batch_idx: 340 |  Loss: (0.5262) |  Loss2: (0.0000) | Acc: (81.00%) (35678/43648)
Epoch: 33 | Batch_idx: 350 |  Loss: (0.5266) |  Loss2: (0.0000) | Acc: (81.00%) (36712/44928)
Epoch: 33 | Batch_idx: 360 |  Loss: (0.5279) |  Loss2: (0.0000) | Acc: (81.00%) (37744/46208)
Epoch: 33 | Batch_idx: 370 |  Loss: (0.5282) |  Loss2: (0.0000) | Acc: (81.00%) (38777/47488)
Epoch: 33 | Batch_idx: 380 |  Loss: (0.5269) |  Loss2: (0.0000) | Acc: (81.00%) (39856/48768)
Epoch: 33 | Batch_idx: 390 |  Loss: (0.5272) |  Loss2: (0.0000) | Acc: (81.00%) (40873/50000)
# TEST : Loss: (0.5638) | Acc: (80.00%) (8089/10000)
percent tensor([0.5146, 0.5165, 0.5141, 0.5135, 0.5145, 0.5119, 0.5170, 0.5173, 0.5153,
        0.5168, 0.5154, 0.5158, 0.5163, 0.5160, 0.5139, 0.5150],
       device='cuda:0') torch.Size([16])
percent tensor([0.4949, 0.4853, 0.4878, 0.4921, 0.4862, 0.4986, 0.4842, 0.4848, 0.4910,
        0.4853, 0.4920, 0.4873, 0.4940, 0.4906, 0.4911, 0.4936],
       device='cuda:0') torch.Size([16])
percent tensor([0.4851, 0.4909, 0.5084, 0.5164, 0.5215, 0.4977, 0.5119, 0.5168, 0.5014,
        0.4949, 0.4854, 0.4897, 0.4588, 0.5168, 0.4909, 0.4880],
       device='cuda:0') torch.Size([16])
percent tensor([0.6275, 0.6264, 0.6191, 0.6185, 0.6278, 0.6176, 0.6328, 0.6325, 0.6243,
        0.6281, 0.6317, 0.6291, 0.6278, 0.6287, 0.6282, 0.6326],
       device='cuda:0') torch.Size([16])
percent tensor([0.5763, 0.5471, 0.5800, 0.6057, 0.5773, 0.6061, 0.5539, 0.5809, 0.5750,
        0.5737, 0.5755, 0.5869, 0.5693, 0.5997, 0.5532, 0.5921],
       device='cuda:0') torch.Size([16])
percent tensor([0.5465, 0.5426, 0.5489, 0.5724, 0.5506, 0.5911, 0.5345, 0.5394, 0.5566,
        0.5540, 0.5557, 0.5458, 0.5522, 0.5788, 0.5266, 0.5563],
       device='cuda:0') torch.Size([16])
percent tensor([0.5344, 0.5338, 0.5355, 0.5391, 0.5331, 0.5514, 0.5317, 0.5332, 0.5371,
        0.5405, 0.5440, 0.5401, 0.5496, 0.5486, 0.5233, 0.5354],
       device='cuda:0') torch.Size([16])
percent tensor([0.9977, 0.9920, 0.9892, 0.9893, 0.9896, 0.9905, 0.9939, 0.9970, 0.9900,
        0.9932, 0.9956, 0.9934, 0.9943, 0.9957, 0.9892, 0.9964],
       device='cuda:0') torch.Size([16])
Epoch: 34 | Batch_idx: 0 |  Loss: (0.4845) |  Loss2: (0.0000) | Acc: (82.00%) (106/128)
Epoch: 34 | Batch_idx: 10 |  Loss: (0.5237) |  Loss2: (0.0000) | Acc: (80.00%) (1135/1408)
Epoch: 34 | Batch_idx: 20 |  Loss: (0.5167) |  Loss2: (0.0000) | Acc: (81.00%) (2192/2688)
Epoch: 34 | Batch_idx: 30 |  Loss: (0.5133) |  Loss2: (0.0000) | Acc: (81.00%) (3251/3968)
Epoch: 34 | Batch_idx: 40 |  Loss: (0.5136) |  Loss2: (0.0000) | Acc: (82.00%) (4304/5248)
Epoch: 34 | Batch_idx: 50 |  Loss: (0.5066) |  Loss2: (0.0000) | Acc: (82.00%) (5366/6528)
Epoch: 34 | Batch_idx: 60 |  Loss: (0.5147) |  Loss2: (0.0000) | Acc: (82.00%) (6412/7808)
Epoch: 34 | Batch_idx: 70 |  Loss: (0.5153) |  Loss2: (0.0000) | Acc: (82.00%) (7468/9088)
Epoch: 34 | Batch_idx: 80 |  Loss: (0.5191) |  Loss2: (0.0000) | Acc: (82.00%) (8519/10368)
Epoch: 34 | Batch_idx: 90 |  Loss: (0.5184) |  Loss2: (0.0000) | Acc: (82.00%) (9561/11648)
Epoch: 34 | Batch_idx: 100 |  Loss: (0.5178) |  Loss2: (0.0000) | Acc: (82.00%) (10617/12928)
Epoch: 34 | Batch_idx: 110 |  Loss: (0.5197) |  Loss2: (0.0000) | Acc: (82.00%) (11651/14208)
Epoch: 34 | Batch_idx: 120 |  Loss: (0.5207) |  Loss2: (0.0000) | Acc: (82.00%) (12706/15488)
Epoch: 34 | Batch_idx: 130 |  Loss: (0.5225) |  Loss2: (0.0000) | Acc: (81.00%) (13735/16768)
Epoch: 34 | Batch_idx: 140 |  Loss: (0.5250) |  Loss2: (0.0000) | Acc: (81.00%) (14759/18048)
Epoch: 34 | Batch_idx: 150 |  Loss: (0.5215) |  Loss2: (0.0000) | Acc: (81.00%) (15827/19328)
Epoch: 34 | Batch_idx: 160 |  Loss: (0.5227) |  Loss2: (0.0000) | Acc: (81.00%) (16873/20608)
Epoch: 34 | Batch_idx: 170 |  Loss: (0.5212) |  Loss2: (0.0000) | Acc: (81.00%) (17941/21888)
Epoch: 34 | Batch_idx: 180 |  Loss: (0.5209) |  Loss2: (0.0000) | Acc: (82.00%) (18999/23168)
Epoch: 34 | Batch_idx: 190 |  Loss: (0.5208) |  Loss2: (0.0000) | Acc: (82.00%) (20058/24448)
Epoch: 34 | Batch_idx: 200 |  Loss: (0.5202) |  Loss2: (0.0000) | Acc: (82.00%) (21109/25728)
Epoch: 34 | Batch_idx: 210 |  Loss: (0.5223) |  Loss2: (0.0000) | Acc: (81.00%) (22136/27008)
Epoch: 34 | Batch_idx: 220 |  Loss: (0.5214) |  Loss2: (0.0000) | Acc: (81.00%) (23190/28288)
Epoch: 34 | Batch_idx: 230 |  Loss: (0.5207) |  Loss2: (0.0000) | Acc: (81.00%) (24239/29568)
Epoch: 34 | Batch_idx: 240 |  Loss: (0.5215) |  Loss2: (0.0000) | Acc: (81.00%) (25290/30848)
Epoch: 34 | Batch_idx: 250 |  Loss: (0.5210) |  Loss2: (0.0000) | Acc: (82.00%) (26366/32128)
Epoch: 34 | Batch_idx: 260 |  Loss: (0.5194) |  Loss2: (0.0000) | Acc: (82.00%) (27427/33408)
Epoch: 34 | Batch_idx: 270 |  Loss: (0.5207) |  Loss2: (0.0000) | Acc: (82.00%) (28462/34688)
Epoch: 34 | Batch_idx: 280 |  Loss: (0.5214) |  Loss2: (0.0000) | Acc: (82.00%) (29502/35968)
Epoch: 34 | Batch_idx: 290 |  Loss: (0.5215) |  Loss2: (0.0000) | Acc: (81.00%) (30537/37248)
Epoch: 34 | Batch_idx: 300 |  Loss: (0.5223) |  Loss2: (0.0000) | Acc: (81.00%) (31573/38528)
Epoch: 34 | Batch_idx: 310 |  Loss: (0.5219) |  Loss2: (0.0000) | Acc: (81.00%) (32632/39808)
Epoch: 34 | Batch_idx: 320 |  Loss: (0.5221) |  Loss2: (0.0000) | Acc: (81.00%) (33676/41088)
Epoch: 34 | Batch_idx: 330 |  Loss: (0.5222) |  Loss2: (0.0000) | Acc: (81.00%) (34729/42368)
Epoch: 34 | Batch_idx: 340 |  Loss: (0.5223) |  Loss2: (0.0000) | Acc: (81.00%) (35766/43648)
Epoch: 34 | Batch_idx: 350 |  Loss: (0.5223) |  Loss2: (0.0000) | Acc: (81.00%) (36815/44928)
Epoch: 34 | Batch_idx: 360 |  Loss: (0.5226) |  Loss2: (0.0000) | Acc: (81.00%) (37871/46208)
Epoch: 34 | Batch_idx: 370 |  Loss: (0.5219) |  Loss2: (0.0000) | Acc: (81.00%) (38927/47488)
Epoch: 34 | Batch_idx: 380 |  Loss: (0.5211) |  Loss2: (0.0000) | Acc: (81.00%) (39987/48768)
Epoch: 34 | Batch_idx: 390 |  Loss: (0.5213) |  Loss2: (0.0000) | Acc: (81.00%) (40974/50000)
# TEST : Loss: (0.5616) | Acc: (80.00%) (8088/10000)
percent tensor([0.5162, 0.5186, 0.5159, 0.5149, 0.5163, 0.5126, 0.5191, 0.5193, 0.5173,
        0.5189, 0.5173, 0.5178, 0.5181, 0.5180, 0.5154, 0.5167],
       device='cuda:0') torch.Size([16])
percent tensor([0.4962, 0.4878, 0.4897, 0.4940, 0.4882, 0.5000, 0.4864, 0.4865, 0.4929,
        0.4877, 0.4939, 0.4895, 0.4956, 0.4928, 0.4929, 0.4952],
       device='cuda:0') torch.Size([16])
percent tensor([0.4882, 0.4926, 0.5089, 0.5179, 0.5219, 0.5019, 0.5125, 0.5173, 0.5038,
        0.4969, 0.4883, 0.4913, 0.4624, 0.5200, 0.4932, 0.4911],
       device='cuda:0') torch.Size([16])
percent tensor([0.6257, 0.6250, 0.6172, 0.6161, 0.6254, 0.6145, 0.6310, 0.6300, 0.6230,
        0.6269, 0.6311, 0.6278, 0.6270, 0.6270, 0.6260, 0.6305],
       device='cuda:0') torch.Size([16])
percent tensor([0.5780, 0.5478, 0.5806, 0.6046, 0.5768, 0.6038, 0.5537, 0.5789, 0.5780,
        0.5755, 0.5797, 0.5877, 0.5730, 0.6025, 0.5524, 0.5910],
       device='cuda:0') torch.Size([16])
percent tensor([0.5489, 0.5466, 0.5508, 0.5746, 0.5523, 0.5970, 0.5359, 0.5391, 0.5610,
        0.5582, 0.5603, 0.5489, 0.5571, 0.5842, 0.5289, 0.5583],
       device='cuda:0') torch.Size([16])
percent tensor([0.5362, 0.5356, 0.5390, 0.5435, 0.5366, 0.5589, 0.5326, 0.5357, 0.5398,
        0.5428, 0.5467, 0.5429, 0.5536, 0.5532, 0.5244, 0.5378],
       device='cuda:0') torch.Size([16])
percent tensor([0.9981, 0.9934, 0.9911, 0.9913, 0.9916, 0.9918, 0.9949, 0.9976, 0.9916,
        0.9943, 0.9964, 0.9946, 0.9953, 0.9966, 0.9911, 0.9969],
       device='cuda:0') torch.Size([16])
Epoch: 35 | Batch_idx: 0 |  Loss: (0.5421) |  Loss2: (0.0000) | Acc: (78.00%) (100/128)
Epoch: 35 | Batch_idx: 10 |  Loss: (0.4896) |  Loss2: (0.0000) | Acc: (82.00%) (1166/1408)
Epoch: 35 | Batch_idx: 20 |  Loss: (0.5019) |  Loss2: (0.0000) | Acc: (82.00%) (2211/2688)
Epoch: 35 | Batch_idx: 30 |  Loss: (0.5014) |  Loss2: (0.0000) | Acc: (82.00%) (3254/3968)
Epoch: 35 | Batch_idx: 40 |  Loss: (0.4992) |  Loss2: (0.0000) | Acc: (82.00%) (4317/5248)
Epoch: 35 | Batch_idx: 50 |  Loss: (0.5059) |  Loss2: (0.0000) | Acc: (82.00%) (5365/6528)
Epoch: 35 | Batch_idx: 60 |  Loss: (0.5089) |  Loss2: (0.0000) | Acc: (81.00%) (6397/7808)
Epoch: 35 | Batch_idx: 70 |  Loss: (0.5129) |  Loss2: (0.0000) | Acc: (81.00%) (7446/9088)
Epoch: 35 | Batch_idx: 80 |  Loss: (0.5147) |  Loss2: (0.0000) | Acc: (81.00%) (8493/10368)
Epoch: 35 | Batch_idx: 90 |  Loss: (0.5137) |  Loss2: (0.0000) | Acc: (82.00%) (9553/11648)
Epoch: 35 | Batch_idx: 100 |  Loss: (0.5153) |  Loss2: (0.0000) | Acc: (82.00%) (10605/12928)
Epoch: 35 | Batch_idx: 110 |  Loss: (0.5118) |  Loss2: (0.0000) | Acc: (82.00%) (11669/14208)
Epoch: 35 | Batch_idx: 120 |  Loss: (0.5122) |  Loss2: (0.0000) | Acc: (82.00%) (12728/15488)
Epoch: 35 | Batch_idx: 130 |  Loss: (0.5169) |  Loss2: (0.0000) | Acc: (82.00%) (13756/16768)
Epoch: 35 | Batch_idx: 140 |  Loss: (0.5174) |  Loss2: (0.0000) | Acc: (81.00%) (14798/18048)
Epoch: 35 | Batch_idx: 150 |  Loss: (0.5160) |  Loss2: (0.0000) | Acc: (82.00%) (15868/19328)
Epoch: 35 | Batch_idx: 160 |  Loss: (0.5169) |  Loss2: (0.0000) | Acc: (82.00%) (16910/20608)
Epoch: 35 | Batch_idx: 170 |  Loss: (0.5152) |  Loss2: (0.0000) | Acc: (82.00%) (17967/21888)
Epoch: 35 | Batch_idx: 180 |  Loss: (0.5164) |  Loss2: (0.0000) | Acc: (82.00%) (19008/23168)
Epoch: 35 | Batch_idx: 190 |  Loss: (0.5167) |  Loss2: (0.0000) | Acc: (82.00%) (20052/24448)
Epoch: 35 | Batch_idx: 200 |  Loss: (0.5163) |  Loss2: (0.0000) | Acc: (82.00%) (21104/25728)
Epoch: 35 | Batch_idx: 210 |  Loss: (0.5137) |  Loss2: (0.0000) | Acc: (82.00%) (22174/27008)
Epoch: 35 | Batch_idx: 220 |  Loss: (0.5145) |  Loss2: (0.0000) | Acc: (82.00%) (23215/28288)
Epoch: 35 | Batch_idx: 230 |  Loss: (0.5156) |  Loss2: (0.0000) | Acc: (82.00%) (24266/29568)
Epoch: 35 | Batch_idx: 240 |  Loss: (0.5166) |  Loss2: (0.0000) | Acc: (82.00%) (25305/30848)
Epoch: 35 | Batch_idx: 250 |  Loss: (0.5167) |  Loss2: (0.0000) | Acc: (82.00%) (26353/32128)
Epoch: 35 | Batch_idx: 260 |  Loss: (0.5168) |  Loss2: (0.0000) | Acc: (82.00%) (27402/33408)
Epoch: 35 | Batch_idx: 270 |  Loss: (0.5167) |  Loss2: (0.0000) | Acc: (81.00%) (28440/34688)
Epoch: 35 | Batch_idx: 280 |  Loss: (0.5180) |  Loss2: (0.0000) | Acc: (81.00%) (29479/35968)
Epoch: 35 | Batch_idx: 290 |  Loss: (0.5194) |  Loss2: (0.0000) | Acc: (81.00%) (30505/37248)
Epoch: 35 | Batch_idx: 300 |  Loss: (0.5194) |  Loss2: (0.0000) | Acc: (81.00%) (31553/38528)
Epoch: 35 | Batch_idx: 310 |  Loss: (0.5213) |  Loss2: (0.0000) | Acc: (81.00%) (32581/39808)
Epoch: 35 | Batch_idx: 320 |  Loss: (0.5216) |  Loss2: (0.0000) | Acc: (81.00%) (33622/41088)
Epoch: 35 | Batch_idx: 330 |  Loss: (0.5211) |  Loss2: (0.0000) | Acc: (81.00%) (34682/42368)
Epoch: 35 | Batch_idx: 340 |  Loss: (0.5206) |  Loss2: (0.0000) | Acc: (81.00%) (35728/43648)
Epoch: 35 | Batch_idx: 350 |  Loss: (0.5217) |  Loss2: (0.0000) | Acc: (81.00%) (36766/44928)
Epoch: 35 | Batch_idx: 360 |  Loss: (0.5213) |  Loss2: (0.0000) | Acc: (81.00%) (37821/46208)
Epoch: 35 | Batch_idx: 370 |  Loss: (0.5211) |  Loss2: (0.0000) | Acc: (81.00%) (38878/47488)
Epoch: 35 | Batch_idx: 380 |  Loss: (0.5212) |  Loss2: (0.0000) | Acc: (81.00%) (39922/48768)
Epoch: 35 | Batch_idx: 390 |  Loss: (0.5219) |  Loss2: (0.0000) | Acc: (81.00%) (40919/50000)
=> saving checkpoint 'drive/app/torch/save_Schedule/checkpoint_035.pth.tar'
# TEST : Loss: (0.5564) | Acc: (81.00%) (8106/10000)
percent tensor([0.5165, 0.5191, 0.5164, 0.5151, 0.5166, 0.5120, 0.5196, 0.5198, 0.5177,
        0.5195, 0.5176, 0.5184, 0.5186, 0.5186, 0.5154, 0.5169],
       device='cuda:0') torch.Size([16])
percent tensor([0.4967, 0.4882, 0.4903, 0.4947, 0.4886, 0.5007, 0.4868, 0.4868, 0.4934,
        0.4882, 0.4943, 0.4901, 0.4963, 0.4933, 0.4934, 0.4959],
       device='cuda:0') torch.Size([16])
percent tensor([0.4928, 0.4971, 0.5116, 0.5217, 0.5248, 0.5062, 0.5167, 0.5198, 0.5088,
        0.5017, 0.4942, 0.4951, 0.4676, 0.5262, 0.4969, 0.4962],
       device='cuda:0') torch.Size([16])
percent tensor([0.6204, 0.6200, 0.6120, 0.6106, 0.6197, 0.6075, 0.6258, 0.6239, 0.6182,
        0.6222, 0.6267, 0.6228, 0.6223, 0.6222, 0.6202, 0.6245],
       device='cuda:0') torch.Size([16])
percent tensor([0.5779, 0.5479, 0.5797, 0.6043, 0.5753, 0.6021, 0.5529, 0.5769, 0.5790,
        0.5757, 0.5812, 0.5875, 0.5744, 0.6046, 0.5512, 0.5901],
       device='cuda:0') torch.Size([16])
percent tensor([0.5534, 0.5527, 0.5541, 0.5788, 0.5551, 0.6037, 0.5397, 0.5413, 0.5667,
        0.5642, 0.5672, 0.5544, 0.5639, 0.5914, 0.5335, 0.5623],
       device='cuda:0') torch.Size([16])
percent tensor([0.5378, 0.5373, 0.5421, 0.5464, 0.5393, 0.5642, 0.5340, 0.5388, 0.5422,
        0.5449, 0.5493, 0.5453, 0.5566, 0.5560, 0.5261, 0.5401],
       device='cuda:0') torch.Size([16])
percent tensor([0.9985, 0.9945, 0.9923, 0.9924, 0.9927, 0.9928, 0.9958, 0.9981, 0.9931,
        0.9954, 0.9973, 0.9955, 0.9961, 0.9973, 0.9926, 0.9974],
       device='cuda:0') torch.Size([16])
True Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=128, out_features=16, bias=False)
False Linear(in_features=16, out_features=2, bias=False)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=128, out_features=16, bias=False)
False Linear(in_features=16, out_features=2, bias=False)
True Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=256, out_features=32, bias=False)
False Linear(in_features=32, out_features=2, bias=False)
True Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=256, out_features=32, bias=False)
False Linear(in_features=32, out_features=2, bias=False)
True Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=512, out_features=64, bias=False)
False Linear(in_features=64, out_features=2, bias=False)
True Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=512, out_features=64, bias=False)
False Linear(in_features=64, out_features=2, bias=False)
True Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1024, out_features=128, bias=False)
False Linear(in_features=128, out_features=2, bias=False)
True Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1024, out_features=128, bias=False)
False Linear(in_features=128, out_features=2, bias=False)
True Linear(in_features=512, out_features=10, bias=True)
Epoch: 36 | Batch_idx: 0 |  Loss: (0.5331) |  Loss2: (0.0000) | Acc: (81.00%) (104/128)
Epoch: 36 | Batch_idx: 10 |  Loss: (0.5128) |  Loss2: (0.0000) | Acc: (82.00%) (1164/1408)
Epoch: 36 | Batch_idx: 20 |  Loss: (0.5004) |  Loss2: (0.0000) | Acc: (82.00%) (2210/2688)
Epoch: 36 | Batch_idx: 30 |  Loss: (0.5098) |  Loss2: (0.0000) | Acc: (81.00%) (3248/3968)
Epoch: 36 | Batch_idx: 40 |  Loss: (0.5165) |  Loss2: (0.0000) | Acc: (81.00%) (4303/5248)
Epoch: 36 | Batch_idx: 50 |  Loss: (0.5226) |  Loss2: (0.0000) | Acc: (81.00%) (5330/6528)
Epoch: 36 | Batch_idx: 60 |  Loss: (0.5190) |  Loss2: (0.0000) | Acc: (81.00%) (6389/7808)
Epoch: 36 | Batch_idx: 70 |  Loss: (0.5232) |  Loss2: (0.0000) | Acc: (81.00%) (7420/9088)
Epoch: 36 | Batch_idx: 80 |  Loss: (0.5247) |  Loss2: (0.0000) | Acc: (81.00%) (8470/10368)
Epoch: 36 | Batch_idx: 90 |  Loss: (0.5278) |  Loss2: (0.0000) | Acc: (81.00%) (9513/11648)
Epoch: 36 | Batch_idx: 100 |  Loss: (0.5286) |  Loss2: (0.0000) | Acc: (81.00%) (10554/12928)
Epoch: 36 | Batch_idx: 110 |  Loss: (0.5278) |  Loss2: (0.0000) | Acc: (81.00%) (11604/14208)
Epoch: 36 | Batch_idx: 120 |  Loss: (0.5291) |  Loss2: (0.0000) | Acc: (81.00%) (12646/15488)
Epoch: 36 | Batch_idx: 130 |  Loss: (0.5348) |  Loss2: (0.0000) | Acc: (81.00%) (13655/16768)
Epoch: 36 | Batch_idx: 140 |  Loss: (0.5372) |  Loss2: (0.0000) | Acc: (81.00%) (14679/18048)
Epoch: 36 | Batch_idx: 150 |  Loss: (0.5366) |  Loss2: (0.0000) | Acc: (81.00%) (15724/19328)
Epoch: 36 | Batch_idx: 160 |  Loss: (0.5358) |  Loss2: (0.0000) | Acc: (81.00%) (16772/20608)
Epoch: 36 | Batch_idx: 170 |  Loss: (0.5352) |  Loss2: (0.0000) | Acc: (81.00%) (17815/21888)
Epoch: 36 | Batch_idx: 180 |  Loss: (0.5345) |  Loss2: (0.0000) | Acc: (81.00%) (18855/23168)
Epoch: 36 | Batch_idx: 190 |  Loss: (0.5339) |  Loss2: (0.0000) | Acc: (81.00%) (19922/24448)
Epoch: 36 | Batch_idx: 200 |  Loss: (0.5333) |  Loss2: (0.0000) | Acc: (81.00%) (20974/25728)
Epoch: 36 | Batch_idx: 210 |  Loss: (0.5327) |  Loss2: (0.0000) | Acc: (81.00%) (22025/27008)
Epoch: 36 | Batch_idx: 220 |  Loss: (0.5333) |  Loss2: (0.0000) | Acc: (81.00%) (23078/28288)
Epoch: 36 | Batch_idx: 230 |  Loss: (0.5323) |  Loss2: (0.0000) | Acc: (81.00%) (24130/29568)
Epoch: 36 | Batch_idx: 240 |  Loss: (0.5314) |  Loss2: (0.0000) | Acc: (81.00%) (25180/30848)
Epoch: 36 | Batch_idx: 250 |  Loss: (0.5300) |  Loss2: (0.0000) | Acc: (81.00%) (26247/32128)
Epoch: 36 | Batch_idx: 260 |  Loss: (0.5283) |  Loss2: (0.0000) | Acc: (81.00%) (27319/33408)
Epoch: 36 | Batch_idx: 270 |  Loss: (0.5297) |  Loss2: (0.0000) | Acc: (81.00%) (28362/34688)
Epoch: 36 | Batch_idx: 280 |  Loss: (0.5281) |  Loss2: (0.0000) | Acc: (81.00%) (29428/35968)
Epoch: 36 | Batch_idx: 290 |  Loss: (0.5278) |  Loss2: (0.0000) | Acc: (81.00%) (30481/37248)
Epoch: 36 | Batch_idx: 300 |  Loss: (0.5292) |  Loss2: (0.0000) | Acc: (81.00%) (31503/38528)
Epoch: 36 | Batch_idx: 310 |  Loss: (0.5284) |  Loss2: (0.0000) | Acc: (81.00%) (32570/39808)
Epoch: 36 | Batch_idx: 320 |  Loss: (0.5295) |  Loss2: (0.0000) | Acc: (81.00%) (33599/41088)
Epoch: 36 | Batch_idx: 330 |  Loss: (0.5286) |  Loss2: (0.0000) | Acc: (81.00%) (34653/42368)
Epoch: 36 | Batch_idx: 340 |  Loss: (0.5291) |  Loss2: (0.0000) | Acc: (81.00%) (35702/43648)
Epoch: 36 | Batch_idx: 350 |  Loss: (0.5281) |  Loss2: (0.0000) | Acc: (81.00%) (36765/44928)
Epoch: 36 | Batch_idx: 360 |  Loss: (0.5283) |  Loss2: (0.0000) | Acc: (81.00%) (37800/46208)
Epoch: 36 | Batch_idx: 370 |  Loss: (0.5282) |  Loss2: (0.0000) | Acc: (81.00%) (38852/47488)
Epoch: 36 | Batch_idx: 380 |  Loss: (0.5290) |  Loss2: (0.0000) | Acc: (81.00%) (39876/48768)
Epoch: 36 | Batch_idx: 390 |  Loss: (0.5289) |  Loss2: (0.0000) | Acc: (81.00%) (40886/50000)
# TEST : Loss: (0.6120) | Acc: (79.00%) (7924/10000)
percent tensor([0.5155, 0.5193, 0.5159, 0.5148, 0.5161, 0.5113, 0.5198, 0.5196, 0.5170,
        0.5196, 0.5169, 0.5184, 0.5177, 0.5194, 0.5148, 0.5161],
       device='cuda:0') torch.Size([16])
percent tensor([0.4955, 0.4885, 0.4900, 0.4932, 0.4876, 0.4987, 0.4866, 0.4871, 0.4929,
        0.4882, 0.4935, 0.4902, 0.4955, 0.4927, 0.4924, 0.4953],
       device='cuda:0') torch.Size([16])
percent tensor([0.4978, 0.4959, 0.5163, 0.5243, 0.5295, 0.5189, 0.5203, 0.5204, 0.5100,
        0.4998, 0.4955, 0.4990, 0.4686, 0.5261, 0.5062, 0.5002],
       device='cuda:0') torch.Size([16])
percent tensor([0.6200, 0.6200, 0.6133, 0.6108, 0.6203, 0.6099, 0.6259, 0.6225, 0.6162,
        0.6218, 0.6246, 0.6228, 0.6196, 0.6237, 0.6201, 0.6228],
       device='cuda:0') torch.Size([16])
percent tensor([0.5741, 0.5510, 0.5660, 0.6017, 0.5761, 0.6053, 0.5553, 0.5668, 0.5750,
        0.5725, 0.5771, 0.5763, 0.5672, 0.6101, 0.5531, 0.5883],
       device='cuda:0') torch.Size([16])
percent tensor([0.5503, 0.5520, 0.5482, 0.5818, 0.5561, 0.6044, 0.5385, 0.5364, 0.5655,
        0.5599, 0.5661, 0.5460, 0.5565, 0.5923, 0.5352, 0.5598],
       device='cuda:0') torch.Size([16])
percent tensor([0.5402, 0.5389, 0.5403, 0.5532, 0.5417, 0.5664, 0.5380, 0.5393, 0.5414,
        0.5443, 0.5476, 0.5420, 0.5540, 0.5543, 0.5236, 0.5394],
       device='cuda:0') torch.Size([16])
percent tensor([0.9991, 0.9942, 0.9947, 0.9945, 0.9925, 0.9948, 0.9982, 0.9981, 0.9936,
        0.9949, 0.9973, 0.9967, 0.9968, 0.9966, 0.9915, 0.9978],
       device='cuda:0') torch.Size([16])
Epoch: 37 | Batch_idx: 0 |  Loss: (0.3815) |  Loss2: (0.0000) | Acc: (89.00%) (114/128)
Epoch: 37 | Batch_idx: 10 |  Loss: (0.5344) |  Loss2: (0.0000) | Acc: (81.00%) (1145/1408)
Epoch: 37 | Batch_idx: 20 |  Loss: (0.5250) |  Loss2: (0.0000) | Acc: (81.00%) (2183/2688)
Epoch: 37 | Batch_idx: 30 |  Loss: (0.5115) |  Loss2: (0.0000) | Acc: (82.00%) (3255/3968)
Epoch: 37 | Batch_idx: 40 |  Loss: (0.5035) |  Loss2: (0.0000) | Acc: (82.00%) (4319/5248)
Epoch: 37 | Batch_idx: 50 |  Loss: (0.5130) |  Loss2: (0.0000) | Acc: (82.00%) (5356/6528)
Epoch: 37 | Batch_idx: 60 |  Loss: (0.5186) |  Loss2: (0.0000) | Acc: (81.00%) (6382/7808)
Epoch: 37 | Batch_idx: 70 |  Loss: (0.5146) |  Loss2: (0.0000) | Acc: (81.00%) (7441/9088)
Epoch: 37 | Batch_idx: 80 |  Loss: (0.5131) |  Loss2: (0.0000) | Acc: (82.00%) (8503/10368)
Epoch: 37 | Batch_idx: 90 |  Loss: (0.5145) |  Loss2: (0.0000) | Acc: (82.00%) (9559/11648)
Epoch: 37 | Batch_idx: 100 |  Loss: (0.5116) |  Loss2: (0.0000) | Acc: (82.00%) (10637/12928)
Epoch: 37 | Batch_idx: 110 |  Loss: (0.5125) |  Loss2: (0.0000) | Acc: (82.00%) (11694/14208)
Epoch: 37 | Batch_idx: 120 |  Loss: (0.5110) |  Loss2: (0.0000) | Acc: (82.00%) (12751/15488)
Epoch: 37 | Batch_idx: 130 |  Loss: (0.5075) |  Loss2: (0.0000) | Acc: (82.00%) (13832/16768)
Epoch: 37 | Batch_idx: 140 |  Loss: (0.5072) |  Loss2: (0.0000) | Acc: (82.00%) (14894/18048)
Epoch: 37 | Batch_idx: 150 |  Loss: (0.5075) |  Loss2: (0.0000) | Acc: (82.00%) (15925/19328)
Epoch: 37 | Batch_idx: 160 |  Loss: (0.5052) |  Loss2: (0.0000) | Acc: (82.00%) (17014/20608)
Epoch: 37 | Batch_idx: 170 |  Loss: (0.5053) |  Loss2: (0.0000) | Acc: (82.00%) (18078/21888)
Epoch: 37 | Batch_idx: 180 |  Loss: (0.5056) |  Loss2: (0.0000) | Acc: (82.00%) (19136/23168)
Epoch: 37 | Batch_idx: 190 |  Loss: (0.5068) |  Loss2: (0.0000) | Acc: (82.00%) (20199/24448)
Epoch: 37 | Batch_idx: 200 |  Loss: (0.5050) |  Loss2: (0.0000) | Acc: (82.00%) (21273/25728)
Epoch: 37 | Batch_idx: 210 |  Loss: (0.5040) |  Loss2: (0.0000) | Acc: (82.00%) (22331/27008)
Epoch: 37 | Batch_idx: 220 |  Loss: (0.5054) |  Loss2: (0.0000) | Acc: (82.00%) (23377/28288)
Epoch: 37 | Batch_idx: 230 |  Loss: (0.5057) |  Loss2: (0.0000) | Acc: (82.00%) (24415/29568)
Epoch: 37 | Batch_idx: 240 |  Loss: (0.5067) |  Loss2: (0.0000) | Acc: (82.00%) (25464/30848)
Epoch: 37 | Batch_idx: 250 |  Loss: (0.5080) |  Loss2: (0.0000) | Acc: (82.00%) (26507/32128)
Epoch: 37 | Batch_idx: 260 |  Loss: (0.5077) |  Loss2: (0.0000) | Acc: (82.00%) (27562/33408)
Epoch: 37 | Batch_idx: 270 |  Loss: (0.5074) |  Loss2: (0.0000) | Acc: (82.00%) (28628/34688)
Epoch: 37 | Batch_idx: 280 |  Loss: (0.5073) |  Loss2: (0.0000) | Acc: (82.00%) (29671/35968)
Epoch: 37 | Batch_idx: 290 |  Loss: (0.5074) |  Loss2: (0.0000) | Acc: (82.00%) (30719/37248)
Epoch: 37 | Batch_idx: 300 |  Loss: (0.5077) |  Loss2: (0.0000) | Acc: (82.00%) (31771/38528)
Epoch: 37 | Batch_idx: 310 |  Loss: (0.5069) |  Loss2: (0.0000) | Acc: (82.00%) (32845/39808)
Epoch: 37 | Batch_idx: 320 |  Loss: (0.5067) |  Loss2: (0.0000) | Acc: (82.00%) (33892/41088)
Epoch: 37 | Batch_idx: 330 |  Loss: (0.5070) |  Loss2: (0.0000) | Acc: (82.00%) (34925/42368)
Epoch: 37 | Batch_idx: 340 |  Loss: (0.5075) |  Loss2: (0.0000) | Acc: (82.00%) (35976/43648)
Epoch: 37 | Batch_idx: 350 |  Loss: (0.5073) |  Loss2: (0.0000) | Acc: (82.00%) (37029/44928)
Epoch: 37 | Batch_idx: 360 |  Loss: (0.5070) |  Loss2: (0.0000) | Acc: (82.00%) (38100/46208)
Epoch: 37 | Batch_idx: 370 |  Loss: (0.5072) |  Loss2: (0.0000) | Acc: (82.00%) (39158/47488)
Epoch: 37 | Batch_idx: 380 |  Loss: (0.5064) |  Loss2: (0.0000) | Acc: (82.00%) (40245/48768)
Epoch: 37 | Batch_idx: 390 |  Loss: (0.5072) |  Loss2: (0.0000) | Acc: (82.00%) (41246/50000)
# TEST : Loss: (0.5845) | Acc: (79.00%) (7977/10000)
percent tensor([0.5160, 0.5188, 0.5163, 0.5148, 0.5163, 0.5113, 0.5193, 0.5196, 0.5172,
        0.5193, 0.5171, 0.5185, 0.5180, 0.5184, 0.5150, 0.5164],
       device='cuda:0') torch.Size([16])
percent tensor([0.4961, 0.4884, 0.4903, 0.4948, 0.4884, 0.4993, 0.4867, 0.4878, 0.4933,
        0.4885, 0.4937, 0.4910, 0.4959, 0.4929, 0.4928, 0.4953],
       device='cuda:0') torch.Size([16])
percent tensor([0.4991, 0.5005, 0.5179, 0.5255, 0.5286, 0.5195, 0.5216, 0.5227, 0.5115,
        0.5028, 0.4992, 0.5015, 0.4706, 0.5284, 0.5082, 0.5037],
       device='cuda:0') torch.Size([16])
percent tensor([0.6190, 0.6173, 0.6118, 0.6113, 0.6192, 0.6075, 0.6241, 0.6226, 0.6177,
        0.6197, 0.6245, 0.6216, 0.6200, 0.6209, 0.6187, 0.6234],
       device='cuda:0') torch.Size([16])
percent tensor([0.5694, 0.5475, 0.5792, 0.5968, 0.5816, 0.5895, 0.5531, 0.5712, 0.5807,
        0.5753, 0.5757, 0.5867, 0.5683, 0.6038, 0.5455, 0.5849],
       device='cuda:0') torch.Size([16])
percent tensor([0.5478, 0.5488, 0.5576, 0.5695, 0.5574, 0.5936, 0.5421, 0.5354, 0.5649,
        0.5630, 0.5656, 0.5569, 0.5580, 0.5884, 0.5276, 0.5565],
       device='cuda:0') torch.Size([16])
percent tensor([0.5387, 0.5307, 0.5420, 0.5484, 0.5432, 0.5618, 0.5347, 0.5349, 0.5408,
        0.5395, 0.5441, 0.5389, 0.5509, 0.5504, 0.5203, 0.5392],
       device='cuda:0') torch.Size([16])
percent tensor([0.9986, 0.9937, 0.9922, 0.9944, 0.9933, 0.9945, 0.9973, 0.9980, 0.9943,
        0.9951, 0.9966, 0.9955, 0.9963, 0.9972, 0.9952, 0.9980],
       device='cuda:0') torch.Size([16])
Epoch: 38 | Batch_idx: 0 |  Loss: (0.4276) |  Loss2: (0.0000) | Acc: (84.00%) (108/128)
Epoch: 38 | Batch_idx: 10 |  Loss: (0.4468) |  Loss2: (0.0000) | Acc: (84.00%) (1192/1408)
Epoch: 38 | Batch_idx: 20 |  Loss: (0.4712) |  Loss2: (0.0000) | Acc: (84.00%) (2258/2688)
Epoch: 38 | Batch_idx: 30 |  Loss: (0.4752) |  Loss2: (0.0000) | Acc: (83.00%) (3326/3968)
Epoch: 38 | Batch_idx: 40 |  Loss: (0.4756) |  Loss2: (0.0000) | Acc: (83.00%) (4386/5248)
Epoch: 38 | Batch_idx: 50 |  Loss: (0.4795) |  Loss2: (0.0000) | Acc: (83.00%) (5435/6528)
Epoch: 38 | Batch_idx: 60 |  Loss: (0.4835) |  Loss2: (0.0000) | Acc: (83.00%) (6495/7808)
Epoch: 38 | Batch_idx: 70 |  Loss: (0.4862) |  Loss2: (0.0000) | Acc: (83.00%) (7552/9088)
Epoch: 38 | Batch_idx: 80 |  Loss: (0.4891) |  Loss2: (0.0000) | Acc: (82.00%) (8601/10368)
Epoch: 38 | Batch_idx: 90 |  Loss: (0.4881) |  Loss2: (0.0000) | Acc: (83.00%) (9678/11648)
Epoch: 38 | Batch_idx: 100 |  Loss: (0.4869) |  Loss2: (0.0000) | Acc: (83.00%) (10753/12928)
Epoch: 38 | Batch_idx: 110 |  Loss: (0.4835) |  Loss2: (0.0000) | Acc: (83.00%) (11849/14208)
Epoch: 38 | Batch_idx: 120 |  Loss: (0.4857) |  Loss2: (0.0000) | Acc: (83.00%) (12913/15488)
Epoch: 38 | Batch_idx: 130 |  Loss: (0.4863) |  Loss2: (0.0000) | Acc: (83.00%) (13973/16768)
Epoch: 38 | Batch_idx: 140 |  Loss: (0.4874) |  Loss2: (0.0000) | Acc: (83.00%) (15044/18048)
Epoch: 38 | Batch_idx: 150 |  Loss: (0.4901) |  Loss2: (0.0000) | Acc: (83.00%) (16092/19328)
Epoch: 38 | Batch_idx: 160 |  Loss: (0.4930) |  Loss2: (0.0000) | Acc: (83.00%) (17120/20608)
Epoch: 38 | Batch_idx: 170 |  Loss: (0.4920) |  Loss2: (0.0000) | Acc: (83.00%) (18189/21888)
Epoch: 38 | Batch_idx: 180 |  Loss: (0.4928) |  Loss2: (0.0000) | Acc: (83.00%) (19246/23168)
Epoch: 38 | Batch_idx: 190 |  Loss: (0.4901) |  Loss2: (0.0000) | Acc: (83.00%) (20323/24448)
Epoch: 38 | Batch_idx: 200 |  Loss: (0.4898) |  Loss2: (0.0000) | Acc: (83.00%) (21393/25728)
Epoch: 38 | Batch_idx: 210 |  Loss: (0.4889) |  Loss2: (0.0000) | Acc: (83.00%) (22452/27008)
Epoch: 38 | Batch_idx: 220 |  Loss: (0.4880) |  Loss2: (0.0000) | Acc: (83.00%) (23514/28288)
Epoch: 38 | Batch_idx: 230 |  Loss: (0.4887) |  Loss2: (0.0000) | Acc: (83.00%) (24574/29568)
Epoch: 38 | Batch_idx: 240 |  Loss: (0.4892) |  Loss2: (0.0000) | Acc: (83.00%) (25635/30848)
Epoch: 38 | Batch_idx: 250 |  Loss: (0.4880) |  Loss2: (0.0000) | Acc: (83.00%) (26715/32128)
Epoch: 38 | Batch_idx: 260 |  Loss: (0.4903) |  Loss2: (0.0000) | Acc: (83.00%) (27760/33408)
Epoch: 38 | Batch_idx: 270 |  Loss: (0.4910) |  Loss2: (0.0000) | Acc: (83.00%) (28820/34688)
Epoch: 38 | Batch_idx: 280 |  Loss: (0.4910) |  Loss2: (0.0000) | Acc: (83.00%) (29869/35968)
Epoch: 38 | Batch_idx: 290 |  Loss: (0.4910) |  Loss2: (0.0000) | Acc: (83.00%) (30929/37248)
Epoch: 38 | Batch_idx: 300 |  Loss: (0.4912) |  Loss2: (0.0000) | Acc: (82.00%) (31978/38528)
Epoch: 38 | Batch_idx: 310 |  Loss: (0.4913) |  Loss2: (0.0000) | Acc: (82.00%) (33039/39808)
Epoch: 38 | Batch_idx: 320 |  Loss: (0.4916) |  Loss2: (0.0000) | Acc: (82.00%) (34098/41088)
Epoch: 38 | Batch_idx: 330 |  Loss: (0.4919) |  Loss2: (0.0000) | Acc: (82.00%) (35155/42368)
Epoch: 38 | Batch_idx: 340 |  Loss: (0.4924) |  Loss2: (0.0000) | Acc: (82.00%) (36209/43648)
Epoch: 38 | Batch_idx: 350 |  Loss: (0.4914) |  Loss2: (0.0000) | Acc: (82.00%) (37274/44928)
Epoch: 38 | Batch_idx: 360 |  Loss: (0.4918) |  Loss2: (0.0000) | Acc: (82.00%) (38341/46208)
Epoch: 38 | Batch_idx: 370 |  Loss: (0.4922) |  Loss2: (0.0000) | Acc: (82.00%) (39392/47488)
Epoch: 38 | Batch_idx: 380 |  Loss: (0.4918) |  Loss2: (0.0000) | Acc: (82.00%) (40455/48768)
Epoch: 38 | Batch_idx: 390 |  Loss: (0.4916) |  Loss2: (0.0000) | Acc: (82.00%) (41477/50000)
# TEST : Loss: (0.6044) | Acc: (79.00%) (7923/10000)
percent tensor([0.5160, 0.5186, 0.5167, 0.5148, 0.5169, 0.5116, 0.5197, 0.5196, 0.5173,
        0.5194, 0.5172, 0.5189, 0.5179, 0.5184, 0.5151, 0.5163],
       device='cuda:0') torch.Size([16])
percent tensor([0.4957, 0.4874, 0.4907, 0.4944, 0.4883, 0.4991, 0.4861, 0.4866, 0.4932,
        0.4882, 0.4932, 0.4907, 0.4955, 0.4921, 0.4923, 0.4948],
       device='cuda:0') torch.Size([16])
percent tensor([0.5067, 0.5026, 0.5210, 0.5284, 0.5311, 0.5170, 0.5274, 0.5242, 0.5188,
        0.5076, 0.5044, 0.5079, 0.4769, 0.5341, 0.5096, 0.5085],
       device='cuda:0') torch.Size([16])
percent tensor([0.6200, 0.6200, 0.6142, 0.6112, 0.6201, 0.6091, 0.6247, 0.6234, 0.6183,
        0.6226, 0.6263, 0.6205, 0.6212, 0.6196, 0.6196, 0.6240],
       device='cuda:0') torch.Size([16])
percent tensor([0.5713, 0.5475, 0.5812, 0.5916, 0.5797, 0.5907, 0.5564, 0.5669, 0.5772,
        0.5725, 0.5744, 0.5874, 0.5671, 0.5960, 0.5494, 0.5830],
       device='cuda:0') torch.Size([16])
percent tensor([0.5496, 0.5463, 0.5570, 0.5686, 0.5573, 0.5917, 0.5430, 0.5373, 0.5676,
        0.5571, 0.5624, 0.5576, 0.5573, 0.5841, 0.5318, 0.5523],
       device='cuda:0') torch.Size([16])
percent tensor([0.5358, 0.5343, 0.5416, 0.5476, 0.5413, 0.5578, 0.5347, 0.5371, 0.5399,
        0.5378, 0.5410, 0.5406, 0.5468, 0.5466, 0.5240, 0.5326],
       device='cuda:0') torch.Size([16])
percent tensor([0.9988, 0.9949, 0.9936, 0.9934, 0.9920, 0.9946, 0.9977, 0.9983, 0.9932,
        0.9965, 0.9967, 0.9968, 0.9956, 0.9965, 0.9953, 0.9980],
       device='cuda:0') torch.Size([16])
Epoch: 39 | Batch_idx: 0 |  Loss: (0.3961) |  Loss2: (0.0000) | Acc: (87.00%) (112/128)
Epoch: 39 | Batch_idx: 10 |  Loss: (0.4485) |  Loss2: (0.0000) | Acc: (85.00%) (1203/1408)
Epoch: 39 | Batch_idx: 20 |  Loss: (0.4521) |  Loss2: (0.0000) | Acc: (85.00%) (2287/2688)
Epoch: 39 | Batch_idx: 30 |  Loss: (0.4519) |  Loss2: (0.0000) | Acc: (84.00%) (3364/3968)
Epoch: 39 | Batch_idx: 40 |  Loss: (0.4519) |  Loss2: (0.0000) | Acc: (84.00%) (4431/5248)
Epoch: 39 | Batch_idx: 50 |  Loss: (0.4575) |  Loss2: (0.0000) | Acc: (84.00%) (5490/6528)
Epoch: 39 | Batch_idx: 60 |  Loss: (0.4618) |  Loss2: (0.0000) | Acc: (83.00%) (6552/7808)
Epoch: 39 | Batch_idx: 70 |  Loss: (0.4641) |  Loss2: (0.0000) | Acc: (83.00%) (7618/9088)
Epoch: 39 | Batch_idx: 80 |  Loss: (0.4689) |  Loss2: (0.0000) | Acc: (83.00%) (8683/10368)
Epoch: 39 | Batch_idx: 90 |  Loss: (0.4711) |  Loss2: (0.0000) | Acc: (83.00%) (9741/11648)
Epoch: 39 | Batch_idx: 100 |  Loss: (0.4705) |  Loss2: (0.0000) | Acc: (83.00%) (10828/12928)
Epoch: 39 | Batch_idx: 110 |  Loss: (0.4717) |  Loss2: (0.0000) | Acc: (83.00%) (11897/14208)
Epoch: 39 | Batch_idx: 120 |  Loss: (0.4722) |  Loss2: (0.0000) | Acc: (83.00%) (12962/15488)
Epoch: 39 | Batch_idx: 130 |  Loss: (0.4723) |  Loss2: (0.0000) | Acc: (83.00%) (14025/16768)
Epoch: 39 | Batch_idx: 140 |  Loss: (0.4724) |  Loss2: (0.0000) | Acc: (83.00%) (15095/18048)
Epoch: 39 | Batch_idx: 150 |  Loss: (0.4741) |  Loss2: (0.0000) | Acc: (83.00%) (16163/19328)
Epoch: 39 | Batch_idx: 160 |  Loss: (0.4762) |  Loss2: (0.0000) | Acc: (83.00%) (17217/20608)
Epoch: 39 | Batch_idx: 170 |  Loss: (0.4755) |  Loss2: (0.0000) | Acc: (83.00%) (18290/21888)
Epoch: 39 | Batch_idx: 180 |  Loss: (0.4766) |  Loss2: (0.0000) | Acc: (83.00%) (19344/23168)
Epoch: 39 | Batch_idx: 190 |  Loss: (0.4787) |  Loss2: (0.0000) | Acc: (83.00%) (20400/24448)
Epoch: 39 | Batch_idx: 200 |  Loss: (0.4791) |  Loss2: (0.0000) | Acc: (83.00%) (21447/25728)
Epoch: 39 | Batch_idx: 210 |  Loss: (0.4782) |  Loss2: (0.0000) | Acc: (83.00%) (22521/27008)
Epoch: 39 | Batch_idx: 220 |  Loss: (0.4778) |  Loss2: (0.0000) | Acc: (83.00%) (23600/28288)
Epoch: 39 | Batch_idx: 230 |  Loss: (0.4786) |  Loss2: (0.0000) | Acc: (83.00%) (24655/29568)
Epoch: 39 | Batch_idx: 240 |  Loss: (0.4781) |  Loss2: (0.0000) | Acc: (83.00%) (25737/30848)
Epoch: 39 | Batch_idx: 250 |  Loss: (0.4764) |  Loss2: (0.0000) | Acc: (83.00%) (26825/32128)
Epoch: 39 | Batch_idx: 260 |  Loss: (0.4756) |  Loss2: (0.0000) | Acc: (83.00%) (27906/33408)
Epoch: 39 | Batch_idx: 270 |  Loss: (0.4763) |  Loss2: (0.0000) | Acc: (83.00%) (28965/34688)
Epoch: 39 | Batch_idx: 280 |  Loss: (0.4773) |  Loss2: (0.0000) | Acc: (83.00%) (30015/35968)
Epoch: 39 | Batch_idx: 290 |  Loss: (0.4776) |  Loss2: (0.0000) | Acc: (83.00%) (31089/37248)
Epoch: 39 | Batch_idx: 300 |  Loss: (0.4769) |  Loss2: (0.0000) | Acc: (83.00%) (32169/38528)
Epoch: 39 | Batch_idx: 310 |  Loss: (0.4770) |  Loss2: (0.0000) | Acc: (83.00%) (33237/39808)
Epoch: 39 | Batch_idx: 320 |  Loss: (0.4762) |  Loss2: (0.0000) | Acc: (83.00%) (34308/41088)
Epoch: 39 | Batch_idx: 330 |  Loss: (0.4761) |  Loss2: (0.0000) | Acc: (83.00%) (35393/42368)
Epoch: 39 | Batch_idx: 340 |  Loss: (0.4763) |  Loss2: (0.0000) | Acc: (83.00%) (36459/43648)
Epoch: 39 | Batch_idx: 350 |  Loss: (0.4766) |  Loss2: (0.0000) | Acc: (83.00%) (37517/44928)
Epoch: 39 | Batch_idx: 360 |  Loss: (0.4779) |  Loss2: (0.0000) | Acc: (83.00%) (38556/46208)
Epoch: 39 | Batch_idx: 370 |  Loss: (0.4773) |  Loss2: (0.0000) | Acc: (83.00%) (39627/47488)
Epoch: 39 | Batch_idx: 380 |  Loss: (0.4771) |  Loss2: (0.0000) | Acc: (83.00%) (40709/48768)
Epoch: 39 | Batch_idx: 390 |  Loss: (0.4763) |  Loss2: (0.0000) | Acc: (83.00%) (41747/50000)
# TEST : Loss: (0.6294) | Acc: (79.00%) (7960/10000)
percent tensor([0.5162, 0.5186, 0.5165, 0.5149, 0.5167, 0.5122, 0.5194, 0.5196, 0.5174,
        0.5193, 0.5172, 0.5188, 0.5181, 0.5186, 0.5152, 0.5166],
       device='cuda:0') torch.Size([16])
percent tensor([0.4959, 0.4892, 0.4911, 0.4946, 0.4888, 0.4989, 0.4876, 0.4878, 0.4944,
        0.4892, 0.4944, 0.4908, 0.4961, 0.4941, 0.4930, 0.4955],
       device='cuda:0') torch.Size([16])
percent tensor([0.4995, 0.4912, 0.5189, 0.5255, 0.5309, 0.5187, 0.5187, 0.5210, 0.5123,
        0.4978, 0.4972, 0.5051, 0.4683, 0.5272, 0.5035, 0.5008],
       device='cuda:0') torch.Size([16])
percent tensor([0.6222, 0.6218, 0.6146, 0.6099, 0.6197, 0.6087, 0.6243, 0.6217, 0.6221,
        0.6250, 0.6319, 0.6234, 0.6260, 0.6232, 0.6213, 0.6250],
       device='cuda:0') torch.Size([16])
percent tensor([0.5710, 0.5491, 0.5704, 0.5990, 0.5680, 0.5900, 0.5503, 0.5654, 0.5805,
        0.5756, 0.5839, 0.5813, 0.5732, 0.6008, 0.5434, 0.5867],
       device='cuda:0') torch.Size([16])
percent tensor([0.5485, 0.5477, 0.5501, 0.5711, 0.5515, 0.5941, 0.5431, 0.5354, 0.5643,
        0.5560, 0.5666, 0.5514, 0.5598, 0.5832, 0.5295, 0.5572],
       device='cuda:0') torch.Size([16])
percent tensor([0.5368, 0.5336, 0.5391, 0.5472, 0.5401, 0.5602, 0.5337, 0.5348, 0.5394,
        0.5388, 0.5436, 0.5376, 0.5490, 0.5476, 0.5214, 0.5335],
       device='cuda:0') torch.Size([16])
percent tensor([0.9990, 0.9947, 0.9946, 0.9951, 0.9951, 0.9950, 0.9977, 0.9981, 0.9951,
        0.9966, 0.9970, 0.9956, 0.9968, 0.9971, 0.9932, 0.9974],
       device='cuda:0') torch.Size([16])
Epoch: 40 | Batch_idx: 0 |  Loss: (0.4756) |  Loss2: (0.0000) | Acc: (84.00%) (108/128)
Epoch: 40 | Batch_idx: 10 |  Loss: (0.4566) |  Loss2: (0.0000) | Acc: (83.00%) (1172/1408)
Epoch: 40 | Batch_idx: 20 |  Loss: (0.4620) |  Loss2: (0.0000) | Acc: (84.00%) (2258/2688)
Epoch: 40 | Batch_idx: 30 |  Loss: (0.4627) |  Loss2: (0.0000) | Acc: (83.00%) (3321/3968)
Epoch: 40 | Batch_idx: 40 |  Loss: (0.4579) |  Loss2: (0.0000) | Acc: (84.00%) (4413/5248)
Epoch: 40 | Batch_idx: 50 |  Loss: (0.4553) |  Loss2: (0.0000) | Acc: (84.00%) (5507/6528)
Epoch: 40 | Batch_idx: 60 |  Loss: (0.4585) |  Loss2: (0.0000) | Acc: (84.00%) (6573/7808)
Epoch: 40 | Batch_idx: 70 |  Loss: (0.4566) |  Loss2: (0.0000) | Acc: (84.00%) (7654/9088)
Epoch: 40 | Batch_idx: 80 |  Loss: (0.4562) |  Loss2: (0.0000) | Acc: (84.00%) (8741/10368)
Epoch: 40 | Batch_idx: 90 |  Loss: (0.4569) |  Loss2: (0.0000) | Acc: (84.00%) (9822/11648)
Epoch: 40 | Batch_idx: 100 |  Loss: (0.4538) |  Loss2: (0.0000) | Acc: (84.00%) (10910/12928)
Epoch: 40 | Batch_idx: 110 |  Loss: (0.4527) |  Loss2: (0.0000) | Acc: (84.00%) (11983/14208)
Epoch: 40 | Batch_idx: 120 |  Loss: (0.4553) |  Loss2: (0.0000) | Acc: (84.00%) (13044/15488)
Epoch: 40 | Batch_idx: 130 |  Loss: (0.4562) |  Loss2: (0.0000) | Acc: (84.00%) (14126/16768)
Epoch: 40 | Batch_idx: 140 |  Loss: (0.4582) |  Loss2: (0.0000) | Acc: (84.00%) (15203/18048)
Epoch: 40 | Batch_idx: 150 |  Loss: (0.4574) |  Loss2: (0.0000) | Acc: (84.00%) (16292/19328)
Epoch: 40 | Batch_idx: 160 |  Loss: (0.4571) |  Loss2: (0.0000) | Acc: (84.00%) (17366/20608)
Epoch: 40 | Batch_idx: 170 |  Loss: (0.4570) |  Loss2: (0.0000) | Acc: (84.00%) (18445/21888)
Epoch: 40 | Batch_idx: 180 |  Loss: (0.4577) |  Loss2: (0.0000) | Acc: (84.00%) (19517/23168)
Epoch: 40 | Batch_idx: 190 |  Loss: (0.4584) |  Loss2: (0.0000) | Acc: (84.00%) (20589/24448)
Epoch: 40 | Batch_idx: 200 |  Loss: (0.4589) |  Loss2: (0.0000) | Acc: (84.00%) (21670/25728)
Epoch: 40 | Batch_idx: 210 |  Loss: (0.4593) |  Loss2: (0.0000) | Acc: (84.00%) (22748/27008)
Epoch: 40 | Batch_idx: 220 |  Loss: (0.4611) |  Loss2: (0.0000) | Acc: (84.00%) (23808/28288)
Epoch: 40 | Batch_idx: 230 |  Loss: (0.4616) |  Loss2: (0.0000) | Acc: (84.00%) (24884/29568)
Epoch: 40 | Batch_idx: 240 |  Loss: (0.4615) |  Loss2: (0.0000) | Acc: (84.00%) (25947/30848)
Epoch: 40 | Batch_idx: 250 |  Loss: (0.4617) |  Loss2: (0.0000) | Acc: (84.00%) (27021/32128)
Epoch: 40 | Batch_idx: 260 |  Loss: (0.4605) |  Loss2: (0.0000) | Acc: (84.00%) (28109/33408)
Epoch: 40 | Batch_idx: 270 |  Loss: (0.4610) |  Loss2: (0.0000) | Acc: (84.00%) (29182/34688)
Epoch: 40 | Batch_idx: 280 |  Loss: (0.4616) |  Loss2: (0.0000) | Acc: (84.00%) (30246/35968)
Epoch: 40 | Batch_idx: 290 |  Loss: (0.4613) |  Loss2: (0.0000) | Acc: (84.00%) (31325/37248)
Epoch: 40 | Batch_idx: 300 |  Loss: (0.4617) |  Loss2: (0.0000) | Acc: (84.00%) (32401/38528)
Epoch: 40 | Batch_idx: 310 |  Loss: (0.4626) |  Loss2: (0.0000) | Acc: (84.00%) (33461/39808)
Epoch: 40 | Batch_idx: 320 |  Loss: (0.4610) |  Loss2: (0.0000) | Acc: (84.00%) (34560/41088)
Epoch: 40 | Batch_idx: 330 |  Loss: (0.4612) |  Loss2: (0.0000) | Acc: (84.00%) (35628/42368)
Epoch: 40 | Batch_idx: 340 |  Loss: (0.4613) |  Loss2: (0.0000) | Acc: (84.00%) (36710/43648)
Epoch: 40 | Batch_idx: 350 |  Loss: (0.4616) |  Loss2: (0.0000) | Acc: (84.00%) (37770/44928)
Epoch: 40 | Batch_idx: 360 |  Loss: (0.4614) |  Loss2: (0.0000) | Acc: (84.00%) (38848/46208)
Epoch: 40 | Batch_idx: 370 |  Loss: (0.4623) |  Loss2: (0.0000) | Acc: (84.00%) (39913/47488)
Epoch: 40 | Batch_idx: 380 |  Loss: (0.4626) |  Loss2: (0.0000) | Acc: (84.00%) (40983/48768)
Epoch: 40 | Batch_idx: 390 |  Loss: (0.4620) |  Loss2: (0.0000) | Acc: (84.00%) (42034/50000)
=> saving checkpoint 'drive/app/torch/save_Schedule/checkpoint_040.pth.tar'
# TEST : Loss: (0.5462) | Acc: (81.00%) (8148/10000)
percent tensor([0.5161, 0.5180, 0.5172, 0.5149, 0.5168, 0.5114, 0.5191, 0.5196, 0.5173,
        0.5192, 0.5168, 0.5190, 0.5180, 0.5174, 0.5142, 0.5160],
       device='cuda:0') torch.Size([16])
percent tensor([0.4956, 0.4900, 0.4908, 0.4941, 0.4888, 0.4994, 0.4885, 0.4880, 0.4948,
        0.4893, 0.4948, 0.4912, 0.4959, 0.4948, 0.4935, 0.4955],
       device='cuda:0') torch.Size([16])
percent tensor([0.5057, 0.4944, 0.5200, 0.5286, 0.5308, 0.5269, 0.5209, 0.5219, 0.5156,
        0.5013, 0.4993, 0.5063, 0.4722, 0.5285, 0.5104, 0.5077],
       device='cuda:0') torch.Size([16])
percent tensor([0.6221, 0.6176, 0.6116, 0.6117, 0.6191, 0.6116, 0.6225, 0.6212, 0.6199,
        0.6230, 0.6283, 0.6221, 0.6224, 0.6190, 0.6207, 0.6252],
       device='cuda:0') torch.Size([16])
percent tensor([0.5731, 0.5558, 0.5788, 0.6044, 0.5846, 0.6044, 0.5609, 0.5703, 0.5841,
        0.5791, 0.5870, 0.5844, 0.5669, 0.6113, 0.5560, 0.5949],
       device='cuda:0') torch.Size([16])
percent tensor([0.5475, 0.5580, 0.5534, 0.5725, 0.5577, 0.5921, 0.5535, 0.5389, 0.5701,
        0.5643, 0.5733, 0.5563, 0.5618, 0.5964, 0.5388, 0.5640],
       device='cuda:0') torch.Size([16])
percent tensor([0.5392, 0.5398, 0.5434, 0.5486, 0.5440, 0.5556, 0.5380, 0.5387, 0.5451,
        0.5450, 0.5499, 0.5448, 0.5557, 0.5558, 0.5244, 0.5397],
       device='cuda:0') torch.Size([16])
percent tensor([0.9991, 0.9939, 0.9946, 0.9934, 0.9935, 0.9951, 0.9976, 0.9979, 0.9948,
        0.9967, 0.9976, 0.9966, 0.9974, 0.9975, 0.9935, 0.9980],
       device='cuda:0') torch.Size([16])
Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 3, 3, 3]) tensor(171.3724, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(799.3268, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(790.1176, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([128, 64, 3, 3]) tensor(1526.9883, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([128, 64, 1, 1]) tensor(504.9762, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([128, 128, 3, 3]) tensor(2199.3291, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([256, 128, 3, 3]) tensor(4302.6426, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([256, 128, 1, 1]) tensor(1425.9680, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([256, 256, 3, 3]) tensor(6108.8711, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([512, 256, 3, 3]) tensor(12085.4854, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([512, 256, 1, 1]) tensor(4025.6658, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([512, 512, 3, 3]) tensor(17054.6504, device='cuda:0', grad_fn=<NormBackward0>)
Epoch: 41 | Batch_idx: 0 |  Loss: (0.3565) |  Loss2: (0.0000) | Acc: (86.00%) (111/128)
Epoch: 41 | Batch_idx: 10 |  Loss: (0.4346) |  Loss2: (0.0000) | Acc: (85.00%) (1197/1408)
Epoch: 41 | Batch_idx: 20 |  Loss: (0.4257) |  Loss2: (0.0000) | Acc: (85.00%) (2295/2688)
Epoch: 41 | Batch_idx: 30 |  Loss: (0.4342) |  Loss2: (0.0000) | Acc: (85.00%) (3383/3968)
Epoch: 41 | Batch_idx: 40 |  Loss: (0.4378) |  Loss2: (0.0000) | Acc: (85.00%) (4472/5248)
Epoch: 41 | Batch_idx: 50 |  Loss: (0.4431) |  Loss2: (0.0000) | Acc: (84.00%) (5542/6528)
Epoch: 41 | Batch_idx: 60 |  Loss: (0.4458) |  Loss2: (0.0000) | Acc: (84.00%) (6620/7808)
Epoch: 41 | Batch_idx: 70 |  Loss: (0.4410) |  Loss2: (0.0000) | Acc: (84.00%) (7722/9088)
Epoch: 41 | Batch_idx: 80 |  Loss: (0.4389) |  Loss2: (0.0000) | Acc: (84.00%) (8810/10368)
Epoch: 41 | Batch_idx: 90 |  Loss: (0.4422) |  Loss2: (0.0000) | Acc: (84.00%) (9898/11648)
Epoch: 41 | Batch_idx: 100 |  Loss: (0.4415) |  Loss2: (0.0000) | Acc: (84.00%) (10974/12928)
Epoch: 41 | Batch_idx: 110 |  Loss: (0.4414) |  Loss2: (0.0000) | Acc: (84.00%) (12073/14208)
Epoch: 41 | Batch_idx: 120 |  Loss: (0.4437) |  Loss2: (0.0000) | Acc: (84.00%) (13143/15488)
Epoch: 41 | Batch_idx: 130 |  Loss: (0.4431) |  Loss2: (0.0000) | Acc: (84.00%) (14227/16768)
Epoch: 41 | Batch_idx: 140 |  Loss: (0.4425) |  Loss2: (0.0000) | Acc: (84.00%) (15325/18048)
Epoch: 41 | Batch_idx: 150 |  Loss: (0.4419) |  Loss2: (0.0000) | Acc: (84.00%) (16410/19328)
Epoch: 41 | Batch_idx: 160 |  Loss: (0.4435) |  Loss2: (0.0000) | Acc: (84.00%) (17488/20608)
Epoch: 41 | Batch_idx: 170 |  Loss: (0.4431) |  Loss2: (0.0000) | Acc: (84.00%) (18576/21888)
Epoch: 41 | Batch_idx: 180 |  Loss: (0.4453) |  Loss2: (0.0000) | Acc: (84.00%) (19642/23168)
Epoch: 41 | Batch_idx: 190 |  Loss: (0.4465) |  Loss2: (0.0000) | Acc: (84.00%) (20715/24448)
Epoch: 41 | Batch_idx: 200 |  Loss: (0.4467) |  Loss2: (0.0000) | Acc: (84.00%) (21788/25728)
Epoch: 41 | Batch_idx: 210 |  Loss: (0.4467) |  Loss2: (0.0000) | Acc: (84.00%) (22865/27008)
Epoch: 41 | Batch_idx: 220 |  Loss: (0.4486) |  Loss2: (0.0000) | Acc: (84.00%) (23927/28288)
Epoch: 41 | Batch_idx: 230 |  Loss: (0.4482) |  Loss2: (0.0000) | Acc: (84.00%) (25005/29568)
Epoch: 41 | Batch_idx: 240 |  Loss: (0.4461) |  Loss2: (0.0000) | Acc: (84.00%) (26104/30848)
Epoch: 41 | Batch_idx: 250 |  Loss: (0.4462) |  Loss2: (0.0000) | Acc: (84.00%) (27174/32128)
Epoch: 41 | Batch_idx: 260 |  Loss: (0.4471) |  Loss2: (0.0000) | Acc: (84.00%) (28257/33408)
Epoch: 41 | Batch_idx: 270 |  Loss: (0.4464) |  Loss2: (0.0000) | Acc: (84.00%) (29353/34688)
Epoch: 41 | Batch_idx: 280 |  Loss: (0.4470) |  Loss2: (0.0000) | Acc: (84.00%) (30430/35968)
Epoch: 41 | Batch_idx: 290 |  Loss: (0.4467) |  Loss2: (0.0000) | Acc: (84.00%) (31529/37248)
Epoch: 41 | Batch_idx: 300 |  Loss: (0.4454) |  Loss2: (0.0000) | Acc: (84.00%) (32629/38528)
Epoch: 41 | Batch_idx: 310 |  Loss: (0.4449) |  Loss2: (0.0000) | Acc: (84.00%) (33731/39808)
Epoch: 41 | Batch_idx: 320 |  Loss: (0.4442) |  Loss2: (0.0000) | Acc: (84.00%) (34801/41088)
Epoch: 41 | Batch_idx: 330 |  Loss: (0.4448) |  Loss2: (0.0000) | Acc: (84.00%) (35870/42368)
Epoch: 41 | Batch_idx: 340 |  Loss: (0.4456) |  Loss2: (0.0000) | Acc: (84.00%) (36945/43648)
Epoch: 41 | Batch_idx: 350 |  Loss: (0.4461) |  Loss2: (0.0000) | Acc: (84.00%) (38022/44928)
Epoch: 41 | Batch_idx: 360 |  Loss: (0.4467) |  Loss2: (0.0000) | Acc: (84.00%) (39111/46208)
Epoch: 41 | Batch_idx: 370 |  Loss: (0.4467) |  Loss2: (0.0000) | Acc: (84.00%) (40186/47488)
Epoch: 41 | Batch_idx: 380 |  Loss: (0.4475) |  Loss2: (0.0000) | Acc: (84.00%) (41267/48768)
Epoch: 41 | Batch_idx: 390 |  Loss: (0.4473) |  Loss2: (0.0000) | Acc: (84.00%) (42306/50000)
# TEST : Loss: (0.5419) | Acc: (82.00%) (8210/10000)
percent tensor([0.5164, 0.5191, 0.5165, 0.5149, 0.5163, 0.5123, 0.5198, 0.5197, 0.5177,
        0.5196, 0.5175, 0.5185, 0.5183, 0.5194, 0.5152, 0.5169],
       device='cuda:0') torch.Size([16])
percent tensor([0.4963, 0.4902, 0.4909, 0.4952, 0.4897, 0.4998, 0.4882, 0.4888, 0.4949,
        0.4895, 0.4954, 0.4915, 0.4963, 0.4957, 0.4940, 0.4957],
       device='cuda:0') torch.Size([16])
percent tensor([0.4979, 0.4913, 0.5203, 0.5272, 0.5290, 0.5163, 0.5147, 0.5217, 0.5069,
        0.4978, 0.4941, 0.5027, 0.4666, 0.5245, 0.5033, 0.5018],
       device='cuda:0') torch.Size([16])
percent tensor([0.6199, 0.6215, 0.6119, 0.6099, 0.6165, 0.6056, 0.6253, 0.6219, 0.6216,
        0.6261, 0.6296, 0.6220, 0.6239, 0.6222, 0.6188, 0.6241],
       device='cuda:0') torch.Size([16])
percent tensor([0.5675, 0.5541, 0.5707, 0.6022, 0.5746, 0.6007, 0.5545, 0.5675, 0.5745,
        0.5792, 0.5736, 0.5847, 0.5665, 0.6011, 0.5513, 0.5883],
       device='cuda:0') torch.Size([16])
percent tensor([0.5487, 0.5565, 0.5479, 0.5685, 0.5566, 0.6011, 0.5489, 0.5366, 0.5620,
        0.5599, 0.5600, 0.5577, 0.5598, 0.5870, 0.5402, 0.5624],
       device='cuda:0') torch.Size([16])
percent tensor([0.5393, 0.5407, 0.5409, 0.5481, 0.5442, 0.5666, 0.5354, 0.5341, 0.5429,
        0.5402, 0.5449, 0.5454, 0.5590, 0.5534, 0.5256, 0.5382],
       device='cuda:0') torch.Size([16])
percent tensor([0.9992, 0.9951, 0.9924, 0.9946, 0.9926, 0.9944, 0.9974, 0.9975, 0.9963,
        0.9958, 0.9976, 0.9966, 0.9983, 0.9976, 0.9930, 0.9980],
       device='cuda:0') torch.Size([16])
False Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=128, out_features=16, bias=False)
True Linear(in_features=16, out_features=2, bias=False)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=128, out_features=16, bias=False)
True Linear(in_features=16, out_features=2, bias=False)
False Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=256, out_features=32, bias=False)
True Linear(in_features=32, out_features=2, bias=False)
False Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=256, out_features=32, bias=False)
True Linear(in_features=32, out_features=2, bias=False)
False Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=512, out_features=64, bias=False)
True Linear(in_features=64, out_features=2, bias=False)
False Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=512, out_features=64, bias=False)
True Linear(in_features=64, out_features=2, bias=False)
False Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1024, out_features=128, bias=False)
True Linear(in_features=128, out_features=2, bias=False)
False Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1024, out_features=128, bias=False)
True Linear(in_features=128, out_features=2, bias=False)
False Linear(in_features=512, out_features=10, bias=True)
Epoch: 42 | Batch_idx: 0 |  Loss: (0.5947) |  Loss2: (0.0000) | Acc: (79.00%) (102/128)
Epoch: 42 | Batch_idx: 10 |  Loss: (0.4765) |  Loss2: (0.0000) | Acc: (84.00%) (1185/1408)
Epoch: 42 | Batch_idx: 20 |  Loss: (0.4608) |  Loss2: (0.0000) | Acc: (84.00%) (2271/2688)
Epoch: 42 | Batch_idx: 30 |  Loss: (0.4819) |  Loss2: (0.0000) | Acc: (83.00%) (3312/3968)
Epoch: 42 | Batch_idx: 40 |  Loss: (0.4989) |  Loss2: (0.0000) | Acc: (82.00%) (4340/5248)
Epoch: 42 | Batch_idx: 50 |  Loss: (0.4973) |  Loss2: (0.0000) | Acc: (82.00%) (5389/6528)
Epoch: 42 | Batch_idx: 60 |  Loss: (0.5039) |  Loss2: (0.0000) | Acc: (82.00%) (6418/7808)
Epoch: 42 | Batch_idx: 70 |  Loss: (0.4982) |  Loss2: (0.0000) | Acc: (82.00%) (7486/9088)
Epoch: 42 | Batch_idx: 80 |  Loss: (0.4993) |  Loss2: (0.0000) | Acc: (82.00%) (8541/10368)
Epoch: 42 | Batch_idx: 90 |  Loss: (0.5051) |  Loss2: (0.0000) | Acc: (82.00%) (9578/11648)
Epoch: 42 | Batch_idx: 100 |  Loss: (0.5028) |  Loss2: (0.0000) | Acc: (82.00%) (10651/12928)
Epoch: 42 | Batch_idx: 110 |  Loss: (0.4967) |  Loss2: (0.0000) | Acc: (82.00%) (11736/14208)
Epoch: 42 | Batch_idx: 120 |  Loss: (0.4934) |  Loss2: (0.0000) | Acc: (82.00%) (12797/15488)
Epoch: 42 | Batch_idx: 130 |  Loss: (0.4905) |  Loss2: (0.0000) | Acc: (82.00%) (13880/16768)
Epoch: 42 | Batch_idx: 140 |  Loss: (0.4900) |  Loss2: (0.0000) | Acc: (82.00%) (14946/18048)
Epoch: 42 | Batch_idx: 150 |  Loss: (0.4882) |  Loss2: (0.0000) | Acc: (82.00%) (16008/19328)
Epoch: 42 | Batch_idx: 160 |  Loss: (0.4867) |  Loss2: (0.0000) | Acc: (82.00%) (17084/20608)
Epoch: 42 | Batch_idx: 170 |  Loss: (0.4839) |  Loss2: (0.0000) | Acc: (82.00%) (18157/21888)
Epoch: 42 | Batch_idx: 180 |  Loss: (0.4825) |  Loss2: (0.0000) | Acc: (82.00%) (19222/23168)
Epoch: 42 | Batch_idx: 190 |  Loss: (0.4805) |  Loss2: (0.0000) | Acc: (83.00%) (20308/24448)
Epoch: 42 | Batch_idx: 200 |  Loss: (0.4807) |  Loss2: (0.0000) | Acc: (83.00%) (21380/25728)
Epoch: 42 | Batch_idx: 210 |  Loss: (0.4805) |  Loss2: (0.0000) | Acc: (83.00%) (22451/27008)
Epoch: 42 | Batch_idx: 220 |  Loss: (0.4801) |  Loss2: (0.0000) | Acc: (83.00%) (23516/28288)
Epoch: 42 | Batch_idx: 230 |  Loss: (0.4809) |  Loss2: (0.0000) | Acc: (83.00%) (24573/29568)
Epoch: 42 | Batch_idx: 240 |  Loss: (0.4811) |  Loss2: (0.0000) | Acc: (83.00%) (25643/30848)
Epoch: 42 | Batch_idx: 250 |  Loss: (0.4790) |  Loss2: (0.0000) | Acc: (83.00%) (26724/32128)
Epoch: 42 | Batch_idx: 260 |  Loss: (0.4799) |  Loss2: (0.0000) | Acc: (83.00%) (27779/33408)
Epoch: 42 | Batch_idx: 270 |  Loss: (0.4811) |  Loss2: (0.0000) | Acc: (83.00%) (28825/34688)
Epoch: 42 | Batch_idx: 280 |  Loss: (0.4802) |  Loss2: (0.0000) | Acc: (83.00%) (29888/35968)
Epoch: 42 | Batch_idx: 290 |  Loss: (0.4804) |  Loss2: (0.0000) | Acc: (83.00%) (30960/37248)
Epoch: 42 | Batch_idx: 300 |  Loss: (0.4797) |  Loss2: (0.0000) | Acc: (83.00%) (32043/38528)
Epoch: 42 | Batch_idx: 310 |  Loss: (0.4792) |  Loss2: (0.0000) | Acc: (83.00%) (33127/39808)
Epoch: 42 | Batch_idx: 320 |  Loss: (0.4780) |  Loss2: (0.0000) | Acc: (83.00%) (34215/41088)
Epoch: 42 | Batch_idx: 330 |  Loss: (0.4776) |  Loss2: (0.0000) | Acc: (83.00%) (35283/42368)
Epoch: 42 | Batch_idx: 340 |  Loss: (0.4763) |  Loss2: (0.0000) | Acc: (83.00%) (36367/43648)
Epoch: 42 | Batch_idx: 350 |  Loss: (0.4755) |  Loss2: (0.0000) | Acc: (83.00%) (37444/44928)
Epoch: 42 | Batch_idx: 360 |  Loss: (0.4752) |  Loss2: (0.0000) | Acc: (83.00%) (38520/46208)
Epoch: 42 | Batch_idx: 370 |  Loss: (0.4752) |  Loss2: (0.0000) | Acc: (83.00%) (39584/47488)
Epoch: 42 | Batch_idx: 380 |  Loss: (0.4738) |  Loss2: (0.0000) | Acc: (83.00%) (40680/48768)
Epoch: 42 | Batch_idx: 390 |  Loss: (0.4727) |  Loss2: (0.0000) | Acc: (83.00%) (41738/50000)
# TEST : Loss: (0.5296) | Acc: (82.00%) (8210/10000)
percent tensor([0.5209, 0.5250, 0.5202, 0.5194, 0.5207, 0.5182, 0.5252, 0.5246, 0.5223,
        0.5245, 0.5225, 0.5226, 0.5229, 0.5247, 0.5211, 0.5218],
       device='cuda:0') torch.Size([16])
percent tensor([0.4968, 0.4929, 0.4920, 0.4971, 0.4911, 0.5013, 0.4905, 0.4901, 0.4959,
        0.4918, 0.4971, 0.4930, 0.4974, 0.4973, 0.4959, 0.4974],
       device='cuda:0') torch.Size([16])
percent tensor([0.4993, 0.4856, 0.5274, 0.5403, 0.5432, 0.5281, 0.5207, 0.5334, 0.5076,
        0.4905, 0.4882, 0.4989, 0.4515, 0.5317, 0.5074, 0.5012],
       device='cuda:0') torch.Size([16])
percent tensor([0.6339, 0.6405, 0.6244, 0.6237, 0.6300, 0.6201, 0.6420, 0.6361, 0.6340,
        0.6435, 0.6467, 0.6388, 0.6423, 0.6387, 0.6375, 0.6418],
       device='cuda:0') torch.Size([16])
percent tensor([0.5628, 0.5469, 0.5574, 0.5972, 0.5686, 0.5975, 0.5515, 0.5614, 0.5664,
        0.5690, 0.5632, 0.5749, 0.5611, 0.5927, 0.5477, 0.5833],
       device='cuda:0') torch.Size([16])
percent tensor([0.5137, 0.5152, 0.5171, 0.5455, 0.5246, 0.5677, 0.5115, 0.4997, 0.5326,
        0.5216, 0.5232, 0.5225, 0.5260, 0.5469, 0.4987, 0.5206],
       device='cuda:0') torch.Size([16])
percent tensor([0.5406, 0.5380, 0.5517, 0.5610, 0.5556, 0.5624, 0.5432, 0.5550, 0.5402,
        0.5395, 0.5395, 0.5510, 0.5477, 0.5510, 0.5304, 0.5422],
       device='cuda:0') torch.Size([16])
percent tensor([0.9986, 0.9953, 0.9927, 0.9941, 0.9932, 0.9940, 0.9976, 0.9982, 0.9946,
        0.9958, 0.9972, 0.9971, 0.9974, 0.9974, 0.9928, 0.9983],
       device='cuda:0') torch.Size([16])
Epoch: 43 | Batch_idx: 0 |  Loss: (0.3687) |  Loss2: (0.0000) | Acc: (88.00%) (113/128)
Epoch: 43 | Batch_idx: 10 |  Loss: (0.4351) |  Loss2: (0.0000) | Acc: (85.00%) (1209/1408)
Epoch: 43 | Batch_idx: 20 |  Loss: (0.4362) |  Loss2: (0.0000) | Acc: (85.00%) (2292/2688)
Epoch: 43 | Batch_idx: 30 |  Loss: (0.4546) |  Loss2: (0.0000) | Acc: (84.00%) (3355/3968)
Epoch: 43 | Batch_idx: 40 |  Loss: (0.4590) |  Loss2: (0.0000) | Acc: (84.00%) (4427/5248)
Epoch: 43 | Batch_idx: 50 |  Loss: (0.4595) |  Loss2: (0.0000) | Acc: (84.00%) (5507/6528)
Epoch: 43 | Batch_idx: 60 |  Loss: (0.4584) |  Loss2: (0.0000) | Acc: (84.00%) (6581/7808)
Epoch: 43 | Batch_idx: 70 |  Loss: (0.4599) |  Loss2: (0.0000) | Acc: (84.00%) (7658/9088)
Epoch: 43 | Batch_idx: 80 |  Loss: (0.4583) |  Loss2: (0.0000) | Acc: (84.00%) (8761/10368)
Epoch: 43 | Batch_idx: 90 |  Loss: (0.4584) |  Loss2: (0.0000) | Acc: (84.00%) (9826/11648)
Epoch: 43 | Batch_idx: 100 |  Loss: (0.4568) |  Loss2: (0.0000) | Acc: (84.00%) (10904/12928)
Epoch: 43 | Batch_idx: 110 |  Loss: (0.4574) |  Loss2: (0.0000) | Acc: (84.00%) (11986/14208)
Epoch: 43 | Batch_idx: 120 |  Loss: (0.4551) |  Loss2: (0.0000) | Acc: (84.00%) (13085/15488)
Epoch: 43 | Batch_idx: 130 |  Loss: (0.4548) |  Loss2: (0.0000) | Acc: (84.00%) (14178/16768)
Epoch: 43 | Batch_idx: 140 |  Loss: (0.4502) |  Loss2: (0.0000) | Acc: (84.00%) (15280/18048)
Epoch: 43 | Batch_idx: 150 |  Loss: (0.4487) |  Loss2: (0.0000) | Acc: (84.00%) (16361/19328)
Epoch: 43 | Batch_idx: 160 |  Loss: (0.4502) |  Loss2: (0.0000) | Acc: (84.00%) (17445/20608)
Epoch: 43 | Batch_idx: 170 |  Loss: (0.4481) |  Loss2: (0.0000) | Acc: (84.00%) (18531/21888)
Epoch: 43 | Batch_idx: 180 |  Loss: (0.4507) |  Loss2: (0.0000) | Acc: (84.00%) (19594/23168)
Epoch: 43 | Batch_idx: 190 |  Loss: (0.4514) |  Loss2: (0.0000) | Acc: (84.00%) (20673/24448)
Epoch: 43 | Batch_idx: 200 |  Loss: (0.4492) |  Loss2: (0.0000) | Acc: (84.00%) (21766/25728)
Epoch: 43 | Batch_idx: 210 |  Loss: (0.4491) |  Loss2: (0.0000) | Acc: (84.00%) (22844/27008)
Epoch: 43 | Batch_idx: 220 |  Loss: (0.4493) |  Loss2: (0.0000) | Acc: (84.00%) (23924/28288)
Epoch: 43 | Batch_idx: 230 |  Loss: (0.4495) |  Loss2: (0.0000) | Acc: (84.00%) (24992/29568)
Epoch: 43 | Batch_idx: 240 |  Loss: (0.4494) |  Loss2: (0.0000) | Acc: (84.00%) (26076/30848)
Epoch: 43 | Batch_idx: 250 |  Loss: (0.4487) |  Loss2: (0.0000) | Acc: (84.00%) (27165/32128)
Epoch: 43 | Batch_idx: 260 |  Loss: (0.4484) |  Loss2: (0.0000) | Acc: (84.00%) (28246/33408)
Epoch: 43 | Batch_idx: 270 |  Loss: (0.4479) |  Loss2: (0.0000) | Acc: (84.00%) (29344/34688)
Epoch: 43 | Batch_idx: 280 |  Loss: (0.4489) |  Loss2: (0.0000) | Acc: (84.00%) (30414/35968)
Epoch: 43 | Batch_idx: 290 |  Loss: (0.4484) |  Loss2: (0.0000) | Acc: (84.00%) (31492/37248)
Epoch: 43 | Batch_idx: 300 |  Loss: (0.4477) |  Loss2: (0.0000) | Acc: (84.00%) (32589/38528)
Epoch: 43 | Batch_idx: 310 |  Loss: (0.4482) |  Loss2: (0.0000) | Acc: (84.00%) (33676/39808)
Epoch: 43 | Batch_idx: 320 |  Loss: (0.4469) |  Loss2: (0.0000) | Acc: (84.00%) (34776/41088)
Epoch: 43 | Batch_idx: 330 |  Loss: (0.4464) |  Loss2: (0.0000) | Acc: (84.00%) (35860/42368)
Epoch: 43 | Batch_idx: 340 |  Loss: (0.4471) |  Loss2: (0.0000) | Acc: (84.00%) (36934/43648)
Epoch: 43 | Batch_idx: 350 |  Loss: (0.4461) |  Loss2: (0.0000) | Acc: (84.00%) (38023/44928)
Epoch: 43 | Batch_idx: 360 |  Loss: (0.4467) |  Loss2: (0.0000) | Acc: (84.00%) (39093/46208)
Epoch: 43 | Batch_idx: 370 |  Loss: (0.4468) |  Loss2: (0.0000) | Acc: (84.00%) (40168/47488)
Epoch: 43 | Batch_idx: 380 |  Loss: (0.4470) |  Loss2: (0.0000) | Acc: (84.00%) (41250/48768)
Epoch: 43 | Batch_idx: 390 |  Loss: (0.4473) |  Loss2: (0.0000) | Acc: (84.00%) (42283/50000)
# TEST : Loss: (0.5152) | Acc: (82.00%) (8248/10000)
percent tensor([0.5235, 0.5279, 0.5222, 0.5220, 0.5234, 0.5220, 0.5281, 0.5270, 0.5248,
        0.5269, 0.5253, 0.5248, 0.5254, 0.5272, 0.5244, 0.5247],
       device='cuda:0') torch.Size([16])
percent tensor([0.4978, 0.4939, 0.4932, 0.4984, 0.4920, 0.5028, 0.4913, 0.4905, 0.4969,
        0.4927, 0.4982, 0.4939, 0.4985, 0.4980, 0.4971, 0.4986],
       device='cuda:0') torch.Size([16])
percent tensor([0.5006, 0.4812, 0.5319, 0.5469, 0.5503, 0.5348, 0.5211, 0.5399, 0.5082,
        0.4860, 0.4852, 0.4964, 0.4449, 0.5318, 0.5096, 0.5009],
       device='cuda:0') torch.Size([16])
percent tensor([0.6298, 0.6370, 0.6206, 0.6202, 0.6257, 0.6169, 0.6382, 0.6323, 0.6300,
        0.6393, 0.6420, 0.6362, 0.6393, 0.6347, 0.6346, 0.6379],
       device='cuda:0') torch.Size([16])
percent tensor([0.5716, 0.5521, 0.5655, 0.6075, 0.5765, 0.6105, 0.5571, 0.5696, 0.5726,
        0.5721, 0.5661, 0.5823, 0.5692, 0.5978, 0.5561, 0.5920],
       device='cuda:0') torch.Size([16])
percent tensor([0.5229, 0.5242, 0.5281, 0.5579, 0.5345, 0.5829, 0.5186, 0.5042, 0.5451,
        0.5311, 0.5343, 0.5351, 0.5381, 0.5593, 0.5056, 0.5295],
       device='cuda:0') torch.Size([16])
percent tensor([0.5476, 0.5427, 0.5665, 0.5741, 0.5732, 0.5702, 0.5509, 0.5733, 0.5447,
        0.5442, 0.5411, 0.5594, 0.5473, 0.5541, 0.5386, 0.5509],
       device='cuda:0') torch.Size([16])
percent tensor([0.9988, 0.9957, 0.9934, 0.9945, 0.9938, 0.9944, 0.9979, 0.9984, 0.9955,
        0.9961, 0.9973, 0.9973, 0.9977, 0.9978, 0.9940, 0.9986],
       device='cuda:0') torch.Size([16])
Epoch: 44 | Batch_idx: 0 |  Loss: (0.4680) |  Loss2: (0.0000) | Acc: (87.00%) (112/128)
Epoch: 44 | Batch_idx: 10 |  Loss: (0.4366) |  Loss2: (0.0000) | Acc: (84.00%) (1196/1408)
Epoch: 44 | Batch_idx: 20 |  Loss: (0.4502) |  Loss2: (0.0000) | Acc: (84.00%) (2264/2688)
Epoch: 44 | Batch_idx: 30 |  Loss: (0.4443) |  Loss2: (0.0000) | Acc: (84.00%) (3356/3968)
Epoch: 44 | Batch_idx: 40 |  Loss: (0.4403) |  Loss2: (0.0000) | Acc: (84.00%) (4441/5248)
Epoch: 44 | Batch_idx: 50 |  Loss: (0.4394) |  Loss2: (0.0000) | Acc: (84.00%) (5526/6528)
Epoch: 44 | Batch_idx: 60 |  Loss: (0.4375) |  Loss2: (0.0000) | Acc: (84.00%) (6607/7808)
Epoch: 44 | Batch_idx: 70 |  Loss: (0.4341) |  Loss2: (0.0000) | Acc: (84.00%) (7706/9088)
Epoch: 44 | Batch_idx: 80 |  Loss: (0.4380) |  Loss2: (0.0000) | Acc: (84.00%) (8781/10368)
Epoch: 44 | Batch_idx: 90 |  Loss: (0.4438) |  Loss2: (0.0000) | Acc: (84.00%) (9838/11648)
Epoch: 44 | Batch_idx: 100 |  Loss: (0.4463) |  Loss2: (0.0000) | Acc: (84.00%) (10914/12928)
Epoch: 44 | Batch_idx: 110 |  Loss: (0.4431) |  Loss2: (0.0000) | Acc: (84.00%) (12012/14208)
Epoch: 44 | Batch_idx: 120 |  Loss: (0.4412) |  Loss2: (0.0000) | Acc: (84.00%) (13104/15488)
Epoch: 44 | Batch_idx: 130 |  Loss: (0.4393) |  Loss2: (0.0000) | Acc: (84.00%) (14192/16768)
Epoch: 44 | Batch_idx: 140 |  Loss: (0.4368) |  Loss2: (0.0000) | Acc: (84.00%) (15305/18048)
Epoch: 44 | Batch_idx: 150 |  Loss: (0.4350) |  Loss2: (0.0000) | Acc: (84.00%) (16410/19328)
Epoch: 44 | Batch_idx: 160 |  Loss: (0.4360) |  Loss2: (0.0000) | Acc: (84.00%) (17492/20608)
Epoch: 44 | Batch_idx: 170 |  Loss: (0.4356) |  Loss2: (0.0000) | Acc: (84.00%) (18582/21888)
Epoch: 44 | Batch_idx: 180 |  Loss: (0.4373) |  Loss2: (0.0000) | Acc: (84.00%) (19659/23168)
Epoch: 44 | Batch_idx: 190 |  Loss: (0.4384) |  Loss2: (0.0000) | Acc: (84.00%) (20725/24448)
Epoch: 44 | Batch_idx: 200 |  Loss: (0.4385) |  Loss2: (0.0000) | Acc: (84.00%) (21815/25728)
Epoch: 44 | Batch_idx: 210 |  Loss: (0.4378) |  Loss2: (0.0000) | Acc: (84.00%) (22901/27008)
Epoch: 44 | Batch_idx: 220 |  Loss: (0.4379) |  Loss2: (0.0000) | Acc: (84.00%) (23991/28288)
Epoch: 44 | Batch_idx: 230 |  Loss: (0.4382) |  Loss2: (0.0000) | Acc: (84.00%) (25079/29568)
Epoch: 44 | Batch_idx: 240 |  Loss: (0.4381) |  Loss2: (0.0000) | Acc: (84.00%) (26162/30848)
Epoch: 44 | Batch_idx: 250 |  Loss: (0.4358) |  Loss2: (0.0000) | Acc: (84.00%) (27279/32128)
Epoch: 44 | Batch_idx: 260 |  Loss: (0.4351) |  Loss2: (0.0000) | Acc: (84.00%) (28367/33408)
Epoch: 44 | Batch_idx: 270 |  Loss: (0.4349) |  Loss2: (0.0000) | Acc: (84.00%) (29460/34688)
Epoch: 44 | Batch_idx: 280 |  Loss: (0.4346) |  Loss2: (0.0000) | Acc: (84.00%) (30554/35968)
Epoch: 44 | Batch_idx: 290 |  Loss: (0.4341) |  Loss2: (0.0000) | Acc: (84.00%) (31649/37248)
Epoch: 44 | Batch_idx: 300 |  Loss: (0.4333) |  Loss2: (0.0000) | Acc: (84.00%) (32741/38528)
Epoch: 44 | Batch_idx: 310 |  Loss: (0.4331) |  Loss2: (0.0000) | Acc: (84.00%) (33836/39808)
Epoch: 44 | Batch_idx: 320 |  Loss: (0.4334) |  Loss2: (0.0000) | Acc: (84.00%) (34922/41088)
Epoch: 44 | Batch_idx: 330 |  Loss: (0.4340) |  Loss2: (0.0000) | Acc: (84.00%) (35991/42368)
Epoch: 44 | Batch_idx: 340 |  Loss: (0.4337) |  Loss2: (0.0000) | Acc: (84.00%) (37087/43648)
Epoch: 44 | Batch_idx: 350 |  Loss: (0.4341) |  Loss2: (0.0000) | Acc: (84.00%) (38160/44928)
Epoch: 44 | Batch_idx: 360 |  Loss: (0.4351) |  Loss2: (0.0000) | Acc: (84.00%) (39241/46208)
Epoch: 44 | Batch_idx: 370 |  Loss: (0.4361) |  Loss2: (0.0000) | Acc: (84.00%) (40313/47488)
Epoch: 44 | Batch_idx: 380 |  Loss: (0.4365) |  Loss2: (0.0000) | Acc: (84.00%) (41388/48768)
Epoch: 44 | Batch_idx: 390 |  Loss: (0.4363) |  Loss2: (0.0000) | Acc: (84.00%) (42437/50000)
# TEST : Loss: (0.5015) | Acc: (83.00%) (8306/10000)
percent tensor([0.5234, 0.5277, 0.5220, 0.5219, 0.5233, 0.5228, 0.5279, 0.5267, 0.5247,
        0.5266, 0.5253, 0.5245, 0.5252, 0.5271, 0.5245, 0.5247],
       device='cuda:0') torch.Size([16])
percent tensor([0.4978, 0.4937, 0.4932, 0.4984, 0.4917, 0.5034, 0.4909, 0.4898, 0.4970,
        0.4925, 0.4983, 0.4937, 0.4986, 0.4979, 0.4972, 0.4988],
       device='cuda:0') torch.Size([16])
percent tensor([0.5015, 0.4806, 0.5340, 0.5488, 0.5520, 0.5352, 0.5223, 0.5420, 0.5093,
        0.4856, 0.4851, 0.4968, 0.4432, 0.5327, 0.5098, 0.5012],
       device='cuda:0') torch.Size([16])
percent tensor([0.6262, 0.6329, 0.6179, 0.6181, 0.6226, 0.6138, 0.6347, 0.6296, 0.6270,
        0.6355, 0.6380, 0.6338, 0.6359, 0.6315, 0.6311, 0.6340],
       device='cuda:0') torch.Size([16])
percent tensor([0.5735, 0.5532, 0.5681, 0.6119, 0.5796, 0.6153, 0.5583, 0.5732, 0.5738,
        0.5709, 0.5647, 0.5842, 0.5701, 0.5996, 0.5588, 0.5938],
       device='cuda:0') torch.Size([16])
percent tensor([0.5291, 0.5308, 0.5352, 0.5667, 0.5408, 0.5953, 0.5230, 0.5049, 0.5541,
        0.5381, 0.5425, 0.5433, 0.5470, 0.5687, 0.5099, 0.5355],
       device='cuda:0') torch.Size([16])
percent tensor([0.5591, 0.5506, 0.5827, 0.5896, 0.5920, 0.5840, 0.5617, 0.5918, 0.5518,
        0.5521, 0.5459, 0.5696, 0.5520, 0.5613, 0.5470, 0.5651],
       device='cuda:0') torch.Size([16])
percent tensor([0.9991, 0.9959, 0.9945, 0.9954, 0.9944, 0.9952, 0.9983, 0.9987, 0.9957,
        0.9966, 0.9975, 0.9978, 0.9979, 0.9982, 0.9945, 0.9989],
       device='cuda:0') torch.Size([16])
Epoch: 45 | Batch_idx: 0 |  Loss: (0.5318) |  Loss2: (0.0000) | Acc: (83.00%) (107/128)
Epoch: 45 | Batch_idx: 10 |  Loss: (0.4204) |  Loss2: (0.0000) | Acc: (85.00%) (1198/1408)
Epoch: 45 | Batch_idx: 20 |  Loss: (0.4215) |  Loss2: (0.0000) | Acc: (85.00%) (2288/2688)
Epoch: 45 | Batch_idx: 30 |  Loss: (0.4259) |  Loss2: (0.0000) | Acc: (85.00%) (3381/3968)
Epoch: 45 | Batch_idx: 40 |  Loss: (0.4375) |  Loss2: (0.0000) | Acc: (84.00%) (4444/5248)
Epoch: 45 | Batch_idx: 50 |  Loss: (0.4287) |  Loss2: (0.0000) | Acc: (85.00%) (5553/6528)
Epoch: 45 | Batch_idx: 60 |  Loss: (0.4382) |  Loss2: (0.0000) | Acc: (84.00%) (6626/7808)
Epoch: 45 | Batch_idx: 70 |  Loss: (0.4334) |  Loss2: (0.0000) | Acc: (84.00%) (7720/9088)
Epoch: 45 | Batch_idx: 80 |  Loss: (0.4322) |  Loss2: (0.0000) | Acc: (84.00%) (8812/10368)
Epoch: 45 | Batch_idx: 90 |  Loss: (0.4330) |  Loss2: (0.0000) | Acc: (84.00%) (9897/11648)
Epoch: 45 | Batch_idx: 100 |  Loss: (0.4322) |  Loss2: (0.0000) | Acc: (85.00%) (10991/12928)
Epoch: 45 | Batch_idx: 110 |  Loss: (0.4327) |  Loss2: (0.0000) | Acc: (85.00%) (12077/14208)
Epoch: 45 | Batch_idx: 120 |  Loss: (0.4343) |  Loss2: (0.0000) | Acc: (84.00%) (13160/15488)
Epoch: 45 | Batch_idx: 130 |  Loss: (0.4333) |  Loss2: (0.0000) | Acc: (85.00%) (14266/16768)
Epoch: 45 | Batch_idx: 140 |  Loss: (0.4360) |  Loss2: (0.0000) | Acc: (85.00%) (15356/18048)
Epoch: 45 | Batch_idx: 150 |  Loss: (0.4332) |  Loss2: (0.0000) | Acc: (85.00%) (16469/19328)
Epoch: 45 | Batch_idx: 160 |  Loss: (0.4334) |  Loss2: (0.0000) | Acc: (85.00%) (17571/20608)
Epoch: 45 | Batch_idx: 170 |  Loss: (0.4336) |  Loss2: (0.0000) | Acc: (85.00%) (18672/21888)
Epoch: 45 | Batch_idx: 180 |  Loss: (0.4350) |  Loss2: (0.0000) | Acc: (85.00%) (19754/23168)
Epoch: 45 | Batch_idx: 190 |  Loss: (0.4348) |  Loss2: (0.0000) | Acc: (85.00%) (20841/24448)
Epoch: 45 | Batch_idx: 200 |  Loss: (0.4336) |  Loss2: (0.0000) | Acc: (85.00%) (21945/25728)
Epoch: 45 | Batch_idx: 210 |  Loss: (0.4335) |  Loss2: (0.0000) | Acc: (85.00%) (23043/27008)
Epoch: 45 | Batch_idx: 220 |  Loss: (0.4338) |  Loss2: (0.0000) | Acc: (85.00%) (24115/28288)
Epoch: 45 | Batch_idx: 230 |  Loss: (0.4325) |  Loss2: (0.0000) | Acc: (85.00%) (25222/29568)
Epoch: 45 | Batch_idx: 240 |  Loss: (0.4325) |  Loss2: (0.0000) | Acc: (85.00%) (26315/30848)
Epoch: 45 | Batch_idx: 250 |  Loss: (0.4322) |  Loss2: (0.0000) | Acc: (85.00%) (27415/32128)
Epoch: 45 | Batch_idx: 260 |  Loss: (0.4332) |  Loss2: (0.0000) | Acc: (85.00%) (28500/33408)
Epoch: 45 | Batch_idx: 270 |  Loss: (0.4339) |  Loss2: (0.0000) | Acc: (85.00%) (29578/34688)
Epoch: 45 | Batch_idx: 280 |  Loss: (0.4334) |  Loss2: (0.0000) | Acc: (85.00%) (30687/35968)
Epoch: 45 | Batch_idx: 290 |  Loss: (0.4326) |  Loss2: (0.0000) | Acc: (85.00%) (31783/37248)
Epoch: 45 | Batch_idx: 300 |  Loss: (0.4320) |  Loss2: (0.0000) | Acc: (85.00%) (32884/38528)
Epoch: 45 | Batch_idx: 310 |  Loss: (0.4316) |  Loss2: (0.0000) | Acc: (85.00%) (33990/39808)
Epoch: 45 | Batch_idx: 320 |  Loss: (0.4332) |  Loss2: (0.0000) | Acc: (85.00%) (35058/41088)
Epoch: 45 | Batch_idx: 330 |  Loss: (0.4335) |  Loss2: (0.0000) | Acc: (85.00%) (36147/42368)
Epoch: 45 | Batch_idx: 340 |  Loss: (0.4326) |  Loss2: (0.0000) | Acc: (85.00%) (37250/43648)
Epoch: 45 | Batch_idx: 350 |  Loss: (0.4321) |  Loss2: (0.0000) | Acc: (85.00%) (38344/44928)
Epoch: 45 | Batch_idx: 360 |  Loss: (0.4318) |  Loss2: (0.0000) | Acc: (85.00%) (39440/46208)
Epoch: 45 | Batch_idx: 370 |  Loss: (0.4318) |  Loss2: (0.0000) | Acc: (85.00%) (40521/47488)
Epoch: 45 | Batch_idx: 380 |  Loss: (0.4318) |  Loss2: (0.0000) | Acc: (85.00%) (41616/48768)
Epoch: 45 | Batch_idx: 390 |  Loss: (0.4315) |  Loss2: (0.0000) | Acc: (85.00%) (42679/50000)
=> saving checkpoint 'drive/app/torch/save_Schedule/checkpoint_045.pth.tar'
# TEST : Loss: (0.4962) | Acc: (83.00%) (8323/10000)
percent tensor([0.5252, 0.5297, 0.5236, 0.5238, 0.5254, 0.5253, 0.5300, 0.5285, 0.5265,
        0.5283, 0.5272, 0.5262, 0.5269, 0.5288, 0.5268, 0.5266],
       device='cuda:0') torch.Size([16])
percent tensor([0.4986, 0.4956, 0.4945, 0.4999, 0.4932, 0.5046, 0.4925, 0.4910, 0.4982,
        0.4942, 0.5000, 0.4954, 0.4999, 0.4994, 0.4987, 0.5001],
       device='cuda:0') torch.Size([16])
percent tensor([0.5036, 0.4783, 0.5342, 0.5499, 0.5519, 0.5391, 0.5204, 0.5421, 0.5099,
        0.4842, 0.4849, 0.4962, 0.4431, 0.5311, 0.5104, 0.5026],
       device='cuda:0') torch.Size([16])
percent tensor([0.6220, 0.6283, 0.6150, 0.6153, 0.6190, 0.6103, 0.6308, 0.6261, 0.6234,
        0.6307, 0.6329, 0.6306, 0.6317, 0.6277, 0.6270, 0.6294],
       device='cuda:0') torch.Size([16])
percent tensor([0.5716, 0.5508, 0.5679, 0.6137, 0.5794, 0.6179, 0.5553, 0.5729, 0.5727,
        0.5671, 0.5601, 0.5830, 0.5688, 0.5981, 0.5569, 0.5926],
       device='cuda:0') torch.Size([16])
percent tensor([0.5352, 0.5368, 0.5426, 0.5753, 0.5466, 0.6060, 0.5271, 0.5069, 0.5623,
        0.5448, 0.5496, 0.5519, 0.5552, 0.5774, 0.5139, 0.5419],
       device='cuda:0') torch.Size([16])
percent tensor([0.5653, 0.5547, 0.5937, 0.5993, 0.6058, 0.5928, 0.5673, 0.6051, 0.5553,
        0.5563, 0.5478, 0.5752, 0.5533, 0.5630, 0.5530, 0.5724],
       device='cuda:0') torch.Size([16])
percent tensor([0.9992, 0.9963, 0.9952, 0.9958, 0.9952, 0.9957, 0.9984, 0.9988, 0.9964,
        0.9968, 0.9978, 0.9981, 0.9982, 0.9984, 0.9949, 0.9989],
       device='cuda:0') torch.Size([16])
Epoch: 46 | Batch_idx: 0 |  Loss: (0.4538) |  Loss2: (0.0000) | Acc: (85.00%) (110/128)
Epoch: 46 | Batch_idx: 10 |  Loss: (0.4306) |  Loss2: (0.0000) | Acc: (85.00%) (1205/1408)
Epoch: 46 | Batch_idx: 20 |  Loss: (0.4288) |  Loss2: (0.0000) | Acc: (84.00%) (2282/2688)
Epoch: 46 | Batch_idx: 30 |  Loss: (0.4160) |  Loss2: (0.0000) | Acc: (85.00%) (3401/3968)
Epoch: 46 | Batch_idx: 40 |  Loss: (0.4172) |  Loss2: (0.0000) | Acc: (85.00%) (4502/5248)
Epoch: 46 | Batch_idx: 50 |  Loss: (0.4132) |  Loss2: (0.0000) | Acc: (85.00%) (5609/6528)
Epoch: 46 | Batch_idx: 60 |  Loss: (0.4082) |  Loss2: (0.0000) | Acc: (86.00%) (6728/7808)
Epoch: 46 | Batch_idx: 70 |  Loss: (0.4131) |  Loss2: (0.0000) | Acc: (85.00%) (7812/9088)
Epoch: 46 | Batch_idx: 80 |  Loss: (0.4152) |  Loss2: (0.0000) | Acc: (85.00%) (8902/10368)
Epoch: 46 | Batch_idx: 90 |  Loss: (0.4178) |  Loss2: (0.0000) | Acc: (85.00%) (9986/11648)
Epoch: 46 | Batch_idx: 100 |  Loss: (0.4156) |  Loss2: (0.0000) | Acc: (85.00%) (11102/12928)
Epoch: 46 | Batch_idx: 110 |  Loss: (0.4183) |  Loss2: (0.0000) | Acc: (85.00%) (12202/14208)
Epoch: 46 | Batch_idx: 120 |  Loss: (0.4189) |  Loss2: (0.0000) | Acc: (85.00%) (13296/15488)
Epoch: 46 | Batch_idx: 130 |  Loss: (0.4216) |  Loss2: (0.0000) | Acc: (85.00%) (14360/16768)
Epoch: 46 | Batch_idx: 140 |  Loss: (0.4220) |  Loss2: (0.0000) | Acc: (85.00%) (15453/18048)
Epoch: 46 | Batch_idx: 150 |  Loss: (0.4229) |  Loss2: (0.0000) | Acc: (85.00%) (16550/19328)
Epoch: 46 | Batch_idx: 160 |  Loss: (0.4237) |  Loss2: (0.0000) | Acc: (85.00%) (17639/20608)
Epoch: 46 | Batch_idx: 170 |  Loss: (0.4213) |  Loss2: (0.0000) | Acc: (85.00%) (18753/21888)
Epoch: 46 | Batch_idx: 180 |  Loss: (0.4211) |  Loss2: (0.0000) | Acc: (85.00%) (19851/23168)
Epoch: 46 | Batch_idx: 190 |  Loss: (0.4223) |  Loss2: (0.0000) | Acc: (85.00%) (20949/24448)
Epoch: 46 | Batch_idx: 200 |  Loss: (0.4254) |  Loss2: (0.0000) | Acc: (85.00%) (22024/25728)
Epoch: 46 | Batch_idx: 210 |  Loss: (0.4258) |  Loss2: (0.0000) | Acc: (85.00%) (23113/27008)
Epoch: 46 | Batch_idx: 220 |  Loss: (0.4252) |  Loss2: (0.0000) | Acc: (85.00%) (24215/28288)
Epoch: 46 | Batch_idx: 230 |  Loss: (0.4246) |  Loss2: (0.0000) | Acc: (85.00%) (25321/29568)
Epoch: 46 | Batch_idx: 240 |  Loss: (0.4240) |  Loss2: (0.0000) | Acc: (85.00%) (26424/30848)
Epoch: 46 | Batch_idx: 250 |  Loss: (0.4243) |  Loss2: (0.0000) | Acc: (85.00%) (27505/32128)
Epoch: 46 | Batch_idx: 260 |  Loss: (0.4240) |  Loss2: (0.0000) | Acc: (85.00%) (28599/33408)
Epoch: 46 | Batch_idx: 270 |  Loss: (0.4236) |  Loss2: (0.0000) | Acc: (85.00%) (29694/34688)
Epoch: 46 | Batch_idx: 280 |  Loss: (0.4239) |  Loss2: (0.0000) | Acc: (85.00%) (30786/35968)
Epoch: 46 | Batch_idx: 290 |  Loss: (0.4227) |  Loss2: (0.0000) | Acc: (85.00%) (31899/37248)
Epoch: 46 | Batch_idx: 300 |  Loss: (0.4222) |  Loss2: (0.0000) | Acc: (85.00%) (33000/38528)
Epoch: 46 | Batch_idx: 310 |  Loss: (0.4223) |  Loss2: (0.0000) | Acc: (85.00%) (34093/39808)
Epoch: 46 | Batch_idx: 320 |  Loss: (0.4230) |  Loss2: (0.0000) | Acc: (85.00%) (35186/41088)
Epoch: 46 | Batch_idx: 330 |  Loss: (0.4237) |  Loss2: (0.0000) | Acc: (85.00%) (36271/42368)
Epoch: 46 | Batch_idx: 340 |  Loss: (0.4235) |  Loss2: (0.0000) | Acc: (85.00%) (37360/43648)
Epoch: 46 | Batch_idx: 350 |  Loss: (0.4230) |  Loss2: (0.0000) | Acc: (85.00%) (38462/44928)
Epoch: 46 | Batch_idx: 360 |  Loss: (0.4227) |  Loss2: (0.0000) | Acc: (85.00%) (39564/46208)
Epoch: 46 | Batch_idx: 370 |  Loss: (0.4224) |  Loss2: (0.0000) | Acc: (85.00%) (40667/47488)
Epoch: 46 | Batch_idx: 380 |  Loss: (0.4227) |  Loss2: (0.0000) | Acc: (85.00%) (41766/48768)
Epoch: 46 | Batch_idx: 390 |  Loss: (0.4237) |  Loss2: (0.0000) | Acc: (85.00%) (42797/50000)
# TEST : Loss: (0.4954) | Acc: (83.00%) (8332/10000)
percent tensor([0.5253, 0.5295, 0.5236, 0.5240, 0.5255, 0.5262, 0.5299, 0.5283, 0.5263,
        0.5280, 0.5272, 0.5260, 0.5268, 0.5285, 0.5270, 0.5267],
       device='cuda:0') torch.Size([16])
percent tensor([0.4983, 0.4948, 0.4938, 0.4992, 0.4922, 0.5046, 0.4915, 0.4897, 0.4978,
        0.4934, 0.4995, 0.4946, 0.4996, 0.4986, 0.4981, 0.4999],
       device='cuda:0') torch.Size([16])
percent tensor([0.5018, 0.4785, 0.5334, 0.5488, 0.5511, 0.5368, 0.5201, 0.5414, 0.5090,
        0.4841, 0.4848, 0.4959, 0.4418, 0.5290, 0.5100, 0.5011],
       device='cuda:0') torch.Size([16])
percent tensor([0.6210, 0.6278, 0.6148, 0.6152, 0.6186, 0.6092, 0.6303, 0.6260, 0.6232,
        0.6301, 0.6323, 0.6308, 0.6312, 0.6272, 0.6264, 0.6285],
       device='cuda:0') torch.Size([16])
percent tensor([0.5674, 0.5461, 0.5654, 0.6119, 0.5774, 0.6164, 0.5506, 0.5705, 0.5693,
        0.5614, 0.5540, 0.5800, 0.5650, 0.5924, 0.5534, 0.5885],
       device='cuda:0') torch.Size([16])
percent tensor([0.5434, 0.5453, 0.5519, 0.5840, 0.5543, 0.6180, 0.5331, 0.5110, 0.5735,
        0.5535, 0.5597, 0.5630, 0.5681, 0.5865, 0.5210, 0.5496],
       device='cuda:0') torch.Size([16])
percent tensor([0.5700, 0.5592, 0.6007, 0.6044, 0.6139, 0.6015, 0.5694, 0.6107, 0.5597,
        0.5604, 0.5506, 0.5773, 0.5586, 0.5635, 0.5565, 0.5778],
       device='cuda:0') torch.Size([16])
percent tensor([0.9993, 0.9968, 0.9958, 0.9964, 0.9957, 0.9960, 0.9986, 0.9990, 0.9968,
        0.9972, 0.9980, 0.9983, 0.9984, 0.9985, 0.9958, 0.9991],
       device='cuda:0') torch.Size([16])
Epoch: 47 | Batch_idx: 0 |  Loss: (0.3151) |  Loss2: (0.0000) | Acc: (90.00%) (116/128)
Epoch: 47 | Batch_idx: 10 |  Loss: (0.4388) |  Loss2: (0.0000) | Acc: (85.00%) (1201/1408)
Epoch: 47 | Batch_idx: 20 |  Loss: (0.4633) |  Loss2: (0.0000) | Acc: (85.00%) (2285/2688)
Epoch: 47 | Batch_idx: 30 |  Loss: (0.4475) |  Loss2: (0.0000) | Acc: (85.00%) (3379/3968)
Epoch: 47 | Batch_idx: 40 |  Loss: (0.4463) |  Loss2: (0.0000) | Acc: (85.00%) (4466/5248)
Epoch: 47 | Batch_idx: 50 |  Loss: (0.4420) |  Loss2: (0.0000) | Acc: (85.00%) (5561/6528)
Epoch: 47 | Batch_idx: 60 |  Loss: (0.4387) |  Loss2: (0.0000) | Acc: (85.00%) (6652/7808)
Epoch: 47 | Batch_idx: 70 |  Loss: (0.4373) |  Loss2: (0.0000) | Acc: (85.00%) (7742/9088)
Epoch: 47 | Batch_idx: 80 |  Loss: (0.4311) |  Loss2: (0.0000) | Acc: (85.00%) (8857/10368)
Epoch: 47 | Batch_idx: 90 |  Loss: (0.4291) |  Loss2: (0.0000) | Acc: (85.00%) (9948/11648)
Epoch: 47 | Batch_idx: 100 |  Loss: (0.4280) |  Loss2: (0.0000) | Acc: (85.00%) (11034/12928)
Epoch: 47 | Batch_idx: 110 |  Loss: (0.4266) |  Loss2: (0.0000) | Acc: (85.00%) (12125/14208)
Epoch: 47 | Batch_idx: 120 |  Loss: (0.4301) |  Loss2: (0.0000) | Acc: (85.00%) (13201/15488)
Epoch: 47 | Batch_idx: 130 |  Loss: (0.4285) |  Loss2: (0.0000) | Acc: (85.00%) (14280/16768)
Epoch: 47 | Batch_idx: 140 |  Loss: (0.4306) |  Loss2: (0.0000) | Acc: (85.00%) (15351/18048)
Epoch: 47 | Batch_idx: 150 |  Loss: (0.4287) |  Loss2: (0.0000) | Acc: (85.00%) (16456/19328)
Epoch: 47 | Batch_idx: 160 |  Loss: (0.4269) |  Loss2: (0.0000) | Acc: (85.00%) (17553/20608)
Epoch: 47 | Batch_idx: 170 |  Loss: (0.4256) |  Loss2: (0.0000) | Acc: (85.00%) (18655/21888)
Epoch: 47 | Batch_idx: 180 |  Loss: (0.4250) |  Loss2: (0.0000) | Acc: (85.00%) (19749/23168)
Epoch: 47 | Batch_idx: 190 |  Loss: (0.4243) |  Loss2: (0.0000) | Acc: (85.00%) (20845/24448)
Epoch: 47 | Batch_idx: 200 |  Loss: (0.4226) |  Loss2: (0.0000) | Acc: (85.00%) (21957/25728)
Epoch: 47 | Batch_idx: 210 |  Loss: (0.4225) |  Loss2: (0.0000) | Acc: (85.00%) (23038/27008)
Epoch: 47 | Batch_idx: 220 |  Loss: (0.4233) |  Loss2: (0.0000) | Acc: (85.00%) (24132/28288)
Epoch: 47 | Batch_idx: 230 |  Loss: (0.4220) |  Loss2: (0.0000) | Acc: (85.00%) (25237/29568)
Epoch: 47 | Batch_idx: 240 |  Loss: (0.4214) |  Loss2: (0.0000) | Acc: (85.00%) (26335/30848)
Epoch: 47 | Batch_idx: 250 |  Loss: (0.4206) |  Loss2: (0.0000) | Acc: (85.00%) (27439/32128)
Epoch: 47 | Batch_idx: 260 |  Loss: (0.4215) |  Loss2: (0.0000) | Acc: (85.00%) (28529/33408)
Epoch: 47 | Batch_idx: 270 |  Loss: (0.4213) |  Loss2: (0.0000) | Acc: (85.00%) (29617/34688)
Epoch: 47 | Batch_idx: 280 |  Loss: (0.4216) |  Loss2: (0.0000) | Acc: (85.00%) (30717/35968)
Epoch: 47 | Batch_idx: 290 |  Loss: (0.4207) |  Loss2: (0.0000) | Acc: (85.00%) (31822/37248)
Epoch: 47 | Batch_idx: 300 |  Loss: (0.4217) |  Loss2: (0.0000) | Acc: (85.00%) (32906/38528)
Epoch: 47 | Batch_idx: 310 |  Loss: (0.4224) |  Loss2: (0.0000) | Acc: (85.00%) (33988/39808)
Epoch: 47 | Batch_idx: 320 |  Loss: (0.4214) |  Loss2: (0.0000) | Acc: (85.00%) (35098/41088)
Epoch: 47 | Batch_idx: 330 |  Loss: (0.4204) |  Loss2: (0.0000) | Acc: (85.00%) (36188/42368)
Epoch: 47 | Batch_idx: 340 |  Loss: (0.4214) |  Loss2: (0.0000) | Acc: (85.00%) (37266/43648)
Epoch: 47 | Batch_idx: 350 |  Loss: (0.4212) |  Loss2: (0.0000) | Acc: (85.00%) (38364/44928)
Epoch: 47 | Batch_idx: 360 |  Loss: (0.4216) |  Loss2: (0.0000) | Acc: (85.00%) (39459/46208)
Epoch: 47 | Batch_idx: 370 |  Loss: (0.4217) |  Loss2: (0.0000) | Acc: (85.00%) (40559/47488)
Epoch: 47 | Batch_idx: 380 |  Loss: (0.4204) |  Loss2: (0.0000) | Acc: (85.00%) (41680/48768)
Epoch: 47 | Batch_idx: 390 |  Loss: (0.4213) |  Loss2: (0.0000) | Acc: (85.00%) (42724/50000)
# TEST : Loss: (0.4892) | Acc: (83.00%) (8364/10000)
percent tensor([0.5250, 0.5288, 0.5234, 0.5238, 0.5253, 0.5265, 0.5294, 0.5277, 0.5259,
        0.5274, 0.5267, 0.5256, 0.5262, 0.5279, 0.5269, 0.5264],
       device='cuda:0') torch.Size([16])
percent tensor([0.4979, 0.4940, 0.4929, 0.4985, 0.4912, 0.5045, 0.4905, 0.4886, 0.4972,
        0.4925, 0.4989, 0.4936, 0.4991, 0.4978, 0.4974, 0.4994],
       device='cuda:0') torch.Size([16])
percent tensor([0.5050, 0.4803, 0.5368, 0.5509, 0.5523, 0.5383, 0.5226, 0.5431, 0.5127,
        0.4874, 0.4879, 0.5008, 0.4444, 0.5319, 0.5116, 0.5045],
       device='cuda:0') torch.Size([16])
percent tensor([0.6203, 0.6260, 0.6147, 0.6160, 0.6180, 0.6092, 0.6292, 0.6258, 0.6226,
        0.6287, 0.6307, 0.6307, 0.6301, 0.6265, 0.6255, 0.6278],
       device='cuda:0') torch.Size([16])
percent tensor([0.5689, 0.5445, 0.5704, 0.6190, 0.5830, 0.6210, 0.5515, 0.5762, 0.5716,
        0.5606, 0.5523, 0.5826, 0.5635, 0.5948, 0.5542, 0.5904],
       device='cuda:0') torch.Size([16])
percent tensor([0.5474, 0.5505, 0.5571, 0.5884, 0.5585, 0.6235, 0.5368, 0.5121, 0.5796,
        0.5596, 0.5661, 0.5684, 0.5737, 0.5926, 0.5242, 0.5532],
       device='cuda:0') torch.Size([16])
percent tensor([0.5654, 0.5547, 0.6015, 0.6045, 0.6169, 0.6010, 0.5650, 0.6104, 0.5559,
        0.5563, 0.5452, 0.5737, 0.5523, 0.5564, 0.5516, 0.5749],
       device='cuda:0') torch.Size([16])
percent tensor([0.9993, 0.9971, 0.9963, 0.9968, 0.9962, 0.9963, 0.9988, 0.9991, 0.9971,
        0.9975, 0.9983, 0.9986, 0.9985, 0.9987, 0.9959, 0.9992],
       device='cuda:0') torch.Size([16])
True Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=128, out_features=16, bias=False)
False Linear(in_features=16, out_features=2, bias=False)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=128, out_features=16, bias=False)
False Linear(in_features=16, out_features=2, bias=False)
True Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=256, out_features=32, bias=False)
False Linear(in_features=32, out_features=2, bias=False)
True Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=256, out_features=32, bias=False)
False Linear(in_features=32, out_features=2, bias=False)
True Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=512, out_features=64, bias=False)
False Linear(in_features=64, out_features=2, bias=False)
True Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=512, out_features=64, bias=False)
False Linear(in_features=64, out_features=2, bias=False)
True Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1024, out_features=128, bias=False)
False Linear(in_features=128, out_features=2, bias=False)
True Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1024, out_features=128, bias=False)
False Linear(in_features=128, out_features=2, bias=False)
True Linear(in_features=512, out_features=10, bias=True)
Epoch: 48 | Batch_idx: 0 |  Loss: (0.4842) |  Loss2: (0.0000) | Acc: (84.00%) (108/128)
Epoch: 48 | Batch_idx: 10 |  Loss: (0.4419) |  Loss2: (0.0000) | Acc: (85.00%) (1197/1408)
Epoch: 48 | Batch_idx: 20 |  Loss: (0.4236) |  Loss2: (0.0000) | Acc: (85.00%) (2304/2688)
Epoch: 48 | Batch_idx: 30 |  Loss: (0.4330) |  Loss2: (0.0000) | Acc: (85.00%) (3379/3968)
Epoch: 48 | Batch_idx: 40 |  Loss: (0.4365) |  Loss2: (0.0000) | Acc: (85.00%) (4467/5248)
Epoch: 48 | Batch_idx: 50 |  Loss: (0.4373) |  Loss2: (0.0000) | Acc: (85.00%) (5555/6528)
Epoch: 48 | Batch_idx: 60 |  Loss: (0.4382) |  Loss2: (0.0000) | Acc: (84.00%) (6634/7808)
Epoch: 48 | Batch_idx: 70 |  Loss: (0.4405) |  Loss2: (0.0000) | Acc: (84.00%) (7707/9088)
Epoch: 48 | Batch_idx: 80 |  Loss: (0.4356) |  Loss2: (0.0000) | Acc: (85.00%) (8815/10368)
Epoch: 48 | Batch_idx: 90 |  Loss: (0.4331) |  Loss2: (0.0000) | Acc: (85.00%) (9911/11648)
Epoch: 48 | Batch_idx: 100 |  Loss: (0.4318) |  Loss2: (0.0000) | Acc: (85.00%) (11009/12928)
Epoch: 48 | Batch_idx: 110 |  Loss: (0.4277) |  Loss2: (0.0000) | Acc: (85.00%) (12120/14208)
Epoch: 48 | Batch_idx: 120 |  Loss: (0.4364) |  Loss2: (0.0000) | Acc: (84.00%) (13164/15488)
Epoch: 48 | Batch_idx: 130 |  Loss: (0.4334) |  Loss2: (0.0000) | Acc: (85.00%) (14281/16768)
Epoch: 48 | Batch_idx: 140 |  Loss: (0.4324) |  Loss2: (0.0000) | Acc: (85.00%) (15375/18048)
Epoch: 48 | Batch_idx: 150 |  Loss: (0.4333) |  Loss2: (0.0000) | Acc: (85.00%) (16450/19328)
Epoch: 48 | Batch_idx: 160 |  Loss: (0.4344) |  Loss2: (0.0000) | Acc: (85.00%) (17527/20608)
Epoch: 48 | Batch_idx: 170 |  Loss: (0.4323) |  Loss2: (0.0000) | Acc: (85.00%) (18629/21888)
Epoch: 48 | Batch_idx: 180 |  Loss: (0.4308) |  Loss2: (0.0000) | Acc: (85.00%) (19727/23168)
Epoch: 48 | Batch_idx: 190 |  Loss: (0.4315) |  Loss2: (0.0000) | Acc: (85.00%) (20811/24448)
Epoch: 48 | Batch_idx: 200 |  Loss: (0.4313) |  Loss2: (0.0000) | Acc: (85.00%) (21905/25728)
Epoch: 48 | Batch_idx: 210 |  Loss: (0.4339) |  Loss2: (0.0000) | Acc: (85.00%) (22979/27008)
Epoch: 48 | Batch_idx: 220 |  Loss: (0.4340) |  Loss2: (0.0000) | Acc: (85.00%) (24066/28288)
Epoch: 48 | Batch_idx: 230 |  Loss: (0.4338) |  Loss2: (0.0000) | Acc: (85.00%) (25162/29568)
Epoch: 48 | Batch_idx: 240 |  Loss: (0.4353) |  Loss2: (0.0000) | Acc: (85.00%) (26235/30848)
Epoch: 48 | Batch_idx: 250 |  Loss: (0.4351) |  Loss2: (0.0000) | Acc: (85.00%) (27324/32128)
Epoch: 48 | Batch_idx: 260 |  Loss: (0.4345) |  Loss2: (0.0000) | Acc: (85.00%) (28423/33408)
Epoch: 48 | Batch_idx: 270 |  Loss: (0.4334) |  Loss2: (0.0000) | Acc: (85.00%) (29512/34688)
Epoch: 48 | Batch_idx: 280 |  Loss: (0.4333) |  Loss2: (0.0000) | Acc: (85.00%) (30603/35968)
Epoch: 48 | Batch_idx: 290 |  Loss: (0.4330) |  Loss2: (0.0000) | Acc: (85.00%) (31705/37248)
Epoch: 48 | Batch_idx: 300 |  Loss: (0.4333) |  Loss2: (0.0000) | Acc: (85.00%) (32793/38528)
Epoch: 48 | Batch_idx: 310 |  Loss: (0.4325) |  Loss2: (0.0000) | Acc: (85.00%) (33888/39808)
Epoch: 48 | Batch_idx: 320 |  Loss: (0.4333) |  Loss2: (0.0000) | Acc: (85.00%) (34956/41088)
Epoch: 48 | Batch_idx: 330 |  Loss: (0.4332) |  Loss2: (0.0000) | Acc: (85.00%) (36045/42368)
Epoch: 48 | Batch_idx: 340 |  Loss: (0.4332) |  Loss2: (0.0000) | Acc: (85.00%) (37131/43648)
Epoch: 48 | Batch_idx: 350 |  Loss: (0.4327) |  Loss2: (0.0000) | Acc: (85.00%) (38244/44928)
Epoch: 48 | Batch_idx: 360 |  Loss: (0.4333) |  Loss2: (0.0000) | Acc: (85.00%) (39320/46208)
Epoch: 48 | Batch_idx: 370 |  Loss: (0.4332) |  Loss2: (0.0000) | Acc: (85.00%) (40401/47488)
Epoch: 48 | Batch_idx: 380 |  Loss: (0.4336) |  Loss2: (0.0000) | Acc: (85.00%) (41488/48768)
Epoch: 48 | Batch_idx: 390 |  Loss: (0.4338) |  Loss2: (0.0000) | Acc: (85.00%) (42533/50000)
# TEST : Loss: (0.5891) | Acc: (80.00%) (8013/10000)
percent tensor([0.5248, 0.5295, 0.5224, 0.5239, 0.5246, 0.5250, 0.5293, 0.5275, 0.5257,
        0.5275, 0.5267, 0.5251, 0.5261, 0.5292, 0.5267, 0.5264],
       device='cuda:0') torch.Size([16])
percent tensor([0.4989, 0.4927, 0.4955, 0.4987, 0.4928, 0.5049, 0.4907, 0.4896, 0.4981,
        0.4930, 0.4993, 0.4949, 0.5004, 0.4957, 0.4975, 0.4996],
       device='cuda:0') torch.Size([16])
percent tensor([0.5038, 0.4872, 0.5349, 0.5517, 0.5531, 0.5311, 0.5254, 0.5434, 0.5114,
        0.4938, 0.4922, 0.5035, 0.4460, 0.5303, 0.5158, 0.5056],
       device='cuda:0') torch.Size([16])
percent tensor([0.6243, 0.6261, 0.6142, 0.6175, 0.6196, 0.6178, 0.6297, 0.6231, 0.6256,
        0.6292, 0.6352, 0.6300, 0.6310, 0.6291, 0.6267, 0.6298],
       device='cuda:0') torch.Size([16])
percent tensor([0.5717, 0.5512, 0.5837, 0.6172, 0.5920, 0.6262, 0.5530, 0.5780, 0.5787,
        0.5665, 0.5653, 0.5872, 0.5675, 0.5968, 0.5551, 0.5933],
       device='cuda:0') torch.Size([16])
percent tensor([0.5482, 0.5635, 0.5692, 0.5821, 0.5674, 0.6198, 0.5462, 0.5255, 0.5828,
        0.5721, 0.5800, 0.5728, 0.5765, 0.6019, 0.5304, 0.5554],
       device='cuda:0') torch.Size([16])
percent tensor([0.5549, 0.5491, 0.5903, 0.5893, 0.6067, 0.6013, 0.5541, 0.5948, 0.5476,
        0.5538, 0.5415, 0.5613, 0.5434, 0.5535, 0.5377, 0.5665],
       device='cuda:0') torch.Size([16])
percent tensor([0.9995, 0.9985, 0.9962, 0.9971, 0.9962, 0.9971, 0.9982, 0.9979, 0.9979,
        0.9983, 0.9989, 0.9976, 0.9989, 0.9987, 0.9966, 0.9991],
       device='cuda:0') torch.Size([16])
Epoch: 49 | Batch_idx: 0 |  Loss: (0.3921) |  Loss2: (0.0000) | Acc: (85.00%) (109/128)
Epoch: 49 | Batch_idx: 10 |  Loss: (0.4048) |  Loss2: (0.0000) | Acc: (85.00%) (1208/1408)
Epoch: 49 | Batch_idx: 20 |  Loss: (0.4043) |  Loss2: (0.0000) | Acc: (85.00%) (2307/2688)
Epoch: 49 | Batch_idx: 30 |  Loss: (0.4077) |  Loss2: (0.0000) | Acc: (85.00%) (3400/3968)
Epoch: 49 | Batch_idx: 40 |  Loss: (0.4121) |  Loss2: (0.0000) | Acc: (85.00%) (4479/5248)
Epoch: 49 | Batch_idx: 50 |  Loss: (0.4199) |  Loss2: (0.0000) | Acc: (85.00%) (5568/6528)
Epoch: 49 | Batch_idx: 60 |  Loss: (0.4163) |  Loss2: (0.0000) | Acc: (85.00%) (6670/7808)
Epoch: 49 | Batch_idx: 70 |  Loss: (0.4159) |  Loss2: (0.0000) | Acc: (85.00%) (7769/9088)
Epoch: 49 | Batch_idx: 80 |  Loss: (0.4133) |  Loss2: (0.0000) | Acc: (85.00%) (8861/10368)
Epoch: 49 | Batch_idx: 90 |  Loss: (0.4143) |  Loss2: (0.0000) | Acc: (85.00%) (9949/11648)
Epoch: 49 | Batch_idx: 100 |  Loss: (0.4181) |  Loss2: (0.0000) | Acc: (85.00%) (11031/12928)
Epoch: 49 | Batch_idx: 110 |  Loss: (0.4175) |  Loss2: (0.0000) | Acc: (85.00%) (12138/14208)
Epoch: 49 | Batch_idx: 120 |  Loss: (0.4181) |  Loss2: (0.0000) | Acc: (85.00%) (13223/15488)
Epoch: 49 | Batch_idx: 130 |  Loss: (0.4196) |  Loss2: (0.0000) | Acc: (85.00%) (14308/16768)
Epoch: 49 | Batch_idx: 140 |  Loss: (0.4208) |  Loss2: (0.0000) | Acc: (85.00%) (15404/18048)
Epoch: 49 | Batch_idx: 150 |  Loss: (0.4185) |  Loss2: (0.0000) | Acc: (85.00%) (16523/19328)
Epoch: 49 | Batch_idx: 160 |  Loss: (0.4193) |  Loss2: (0.0000) | Acc: (85.00%) (17611/20608)
Epoch: 49 | Batch_idx: 170 |  Loss: (0.4199) |  Loss2: (0.0000) | Acc: (85.00%) (18702/21888)
Epoch: 49 | Batch_idx: 180 |  Loss: (0.4169) |  Loss2: (0.0000) | Acc: (85.00%) (19823/23168)
Epoch: 49 | Batch_idx: 190 |  Loss: (0.4169) |  Loss2: (0.0000) | Acc: (85.00%) (20917/24448)
Epoch: 49 | Batch_idx: 200 |  Loss: (0.4178) |  Loss2: (0.0000) | Acc: (85.00%) (22008/25728)
Epoch: 49 | Batch_idx: 210 |  Loss: (0.4164) |  Loss2: (0.0000) | Acc: (85.00%) (23122/27008)
Epoch: 49 | Batch_idx: 220 |  Loss: (0.4151) |  Loss2: (0.0000) | Acc: (85.00%) (24225/28288)
Epoch: 49 | Batch_idx: 230 |  Loss: (0.4157) |  Loss2: (0.0000) | Acc: (85.00%) (25325/29568)
Epoch: 49 | Batch_idx: 240 |  Loss: (0.4158) |  Loss2: (0.0000) | Acc: (85.00%) (26425/30848)
Epoch: 49 | Batch_idx: 250 |  Loss: (0.4160) |  Loss2: (0.0000) | Acc: (85.00%) (27510/32128)
Epoch: 49 | Batch_idx: 260 |  Loss: (0.4164) |  Loss2: (0.0000) | Acc: (85.00%) (28605/33408)
Epoch: 49 | Batch_idx: 270 |  Loss: (0.4165) |  Loss2: (0.0000) | Acc: (85.00%) (29701/34688)
Epoch: 49 | Batch_idx: 280 |  Loss: (0.4148) |  Loss2: (0.0000) | Acc: (85.00%) (30822/35968)
Epoch: 49 | Batch_idx: 290 |  Loss: (0.4148) |  Loss2: (0.0000) | Acc: (85.00%) (31927/37248)
Epoch: 49 | Batch_idx: 300 |  Loss: (0.4158) |  Loss2: (0.0000) | Acc: (85.00%) (33021/38528)
Epoch: 49 | Batch_idx: 310 |  Loss: (0.4156) |  Loss2: (0.0000) | Acc: (85.00%) (34114/39808)
Epoch: 49 | Batch_idx: 320 |  Loss: (0.4174) |  Loss2: (0.0000) | Acc: (85.00%) (35196/41088)
Epoch: 49 | Batch_idx: 330 |  Loss: (0.4157) |  Loss2: (0.0000) | Acc: (85.00%) (36309/42368)
Epoch: 49 | Batch_idx: 340 |  Loss: (0.4159) |  Loss2: (0.0000) | Acc: (85.00%) (37399/43648)
Epoch: 49 | Batch_idx: 350 |  Loss: (0.4169) |  Loss2: (0.0000) | Acc: (85.00%) (38498/44928)
Epoch: 49 | Batch_idx: 360 |  Loss: (0.4178) |  Loss2: (0.0000) | Acc: (85.00%) (39584/46208)
Epoch: 49 | Batch_idx: 370 |  Loss: (0.4178) |  Loss2: (0.0000) | Acc: (85.00%) (40676/47488)
Epoch: 49 | Batch_idx: 380 |  Loss: (0.4175) |  Loss2: (0.0000) | Acc: (85.00%) (41784/48768)
Epoch: 49 | Batch_idx: 390 |  Loss: (0.4180) |  Loss2: (0.0000) | Acc: (85.00%) (42829/50000)
# TEST : Loss: (0.5690) | Acc: (80.00%) (8098/10000)
percent tensor([0.5255, 0.5288, 0.5249, 0.5245, 0.5263, 0.5251, 0.5296, 0.5288, 0.5262,
        0.5280, 0.5267, 0.5272, 0.5268, 0.5279, 0.5262, 0.5266],
       device='cuda:0') torch.Size([16])
percent tensor([0.4981, 0.4933, 0.4935, 0.4986, 0.4921, 0.5035, 0.4910, 0.4885, 0.4971,
        0.4924, 0.4987, 0.4937, 0.4992, 0.4974, 0.4975, 0.4995],
       device='cuda:0') torch.Size([16])
percent tensor([0.5050, 0.4875, 0.5356, 0.5500, 0.5520, 0.5253, 0.5285, 0.5446, 0.5198,
        0.4932, 0.4935, 0.5061, 0.4462, 0.5427, 0.5099, 0.5027],
       device='cuda:0') torch.Size([16])
percent tensor([0.6239, 0.6241, 0.6141, 0.6184, 0.6209, 0.6135, 0.6266, 0.6250, 0.6239,
        0.6273, 0.6330, 0.6309, 0.6304, 0.6284, 0.6257, 0.6299],
       device='cuda:0') torch.Size([16])
percent tensor([0.5612, 0.5480, 0.5855, 0.6169, 0.5897, 0.5986, 0.5602, 0.5759, 0.5733,
        0.5621, 0.5568, 0.5904, 0.5597, 0.6069, 0.5472, 0.5856],
       device='cuda:0') torch.Size([16])
percent tensor([0.5411, 0.5581, 0.5686, 0.5832, 0.5639, 0.6093, 0.5523, 0.5138, 0.5813,
        0.5600, 0.5709, 0.5650, 0.5684, 0.6024, 0.5239, 0.5520],
       device='cuda:0') torch.Size([16])
percent tensor([0.5640, 0.5555, 0.6065, 0.6020, 0.6206, 0.6043, 0.5693, 0.5967, 0.5601,
        0.5561, 0.5501, 0.5755, 0.5503, 0.5595, 0.5451, 0.5760],
       device='cuda:0') torch.Size([16])
percent tensor([0.9996, 0.9963, 0.9980, 0.9976, 0.9967, 0.9977, 0.9992, 0.9991, 0.9977,
        0.9980, 0.9990, 0.9989, 0.9988, 0.9990, 0.9971, 0.9994],
       device='cuda:0') torch.Size([16])
Epoch: 50 | Batch_idx: 0 |  Loss: (0.2895) |  Loss2: (0.0000) | Acc: (89.00%) (114/128)
Epoch: 50 | Batch_idx: 10 |  Loss: (0.3942) |  Loss2: (0.0000) | Acc: (86.00%) (1218/1408)
Epoch: 50 | Batch_idx: 20 |  Loss: (0.3935) |  Loss2: (0.0000) | Acc: (86.00%) (2312/2688)
Epoch: 50 | Batch_idx: 30 |  Loss: (0.3943) |  Loss2: (0.0000) | Acc: (86.00%) (3431/3968)
Epoch: 50 | Batch_idx: 40 |  Loss: (0.3879) |  Loss2: (0.0000) | Acc: (86.00%) (4550/5248)
Epoch: 50 | Batch_idx: 50 |  Loss: (0.3910) |  Loss2: (0.0000) | Acc: (86.00%) (5655/6528)
Epoch: 50 | Batch_idx: 60 |  Loss: (0.3886) |  Loss2: (0.0000) | Acc: (86.00%) (6768/7808)
Epoch: 50 | Batch_idx: 70 |  Loss: (0.3965) |  Loss2: (0.0000) | Acc: (86.00%) (7840/9088)
Epoch: 50 | Batch_idx: 80 |  Loss: (0.4001) |  Loss2: (0.0000) | Acc: (86.00%) (8922/10368)
Epoch: 50 | Batch_idx: 90 |  Loss: (0.4032) |  Loss2: (0.0000) | Acc: (85.00%) (10013/11648)
Epoch: 50 | Batch_idx: 100 |  Loss: (0.4036) |  Loss2: (0.0000) | Acc: (85.00%) (11114/12928)
Epoch: 50 | Batch_idx: 110 |  Loss: (0.4007) |  Loss2: (0.0000) | Acc: (86.00%) (12227/14208)
Epoch: 50 | Batch_idx: 120 |  Loss: (0.4010) |  Loss2: (0.0000) | Acc: (86.00%) (13327/15488)
Epoch: 50 | Batch_idx: 130 |  Loss: (0.4000) |  Loss2: (0.0000) | Acc: (86.00%) (14442/16768)
Epoch: 50 | Batch_idx: 140 |  Loss: (0.3998) |  Loss2: (0.0000) | Acc: (86.00%) (15549/18048)
Epoch: 50 | Batch_idx: 150 |  Loss: (0.4014) |  Loss2: (0.0000) | Acc: (86.00%) (16645/19328)
Epoch: 50 | Batch_idx: 160 |  Loss: (0.4023) |  Loss2: (0.0000) | Acc: (86.00%) (17746/20608)
Epoch: 50 | Batch_idx: 170 |  Loss: (0.4019) |  Loss2: (0.0000) | Acc: (86.00%) (18847/21888)
Epoch: 50 | Batch_idx: 180 |  Loss: (0.4049) |  Loss2: (0.0000) | Acc: (85.00%) (19921/23168)
Epoch: 50 | Batch_idx: 190 |  Loss: (0.4075) |  Loss2: (0.0000) | Acc: (85.00%) (20998/24448)
Epoch: 50 | Batch_idx: 200 |  Loss: (0.4085) |  Loss2: (0.0000) | Acc: (85.00%) (22084/25728)
Epoch: 50 | Batch_idx: 210 |  Loss: (0.4093) |  Loss2: (0.0000) | Acc: (85.00%) (23181/27008)
Epoch: 50 | Batch_idx: 220 |  Loss: (0.4088) |  Loss2: (0.0000) | Acc: (85.00%) (24287/28288)
Epoch: 50 | Batch_idx: 230 |  Loss: (0.4082) |  Loss2: (0.0000) | Acc: (85.00%) (25393/29568)
Epoch: 50 | Batch_idx: 240 |  Loss: (0.4075) |  Loss2: (0.0000) | Acc: (85.00%) (26479/30848)
Epoch: 50 | Batch_idx: 250 |  Loss: (0.4072) |  Loss2: (0.0000) | Acc: (85.00%) (27578/32128)
Epoch: 50 | Batch_idx: 260 |  Loss: (0.4083) |  Loss2: (0.0000) | Acc: (85.00%) (28665/33408)
Epoch: 50 | Batch_idx: 270 |  Loss: (0.4086) |  Loss2: (0.0000) | Acc: (85.00%) (29760/34688)
Epoch: 50 | Batch_idx: 280 |  Loss: (0.4087) |  Loss2: (0.0000) | Acc: (85.00%) (30865/35968)
Epoch: 50 | Batch_idx: 290 |  Loss: (0.4078) |  Loss2: (0.0000) | Acc: (85.00%) (31968/37248)
Epoch: 50 | Batch_idx: 300 |  Loss: (0.4074) |  Loss2: (0.0000) | Acc: (85.00%) (33059/38528)
Epoch: 50 | Batch_idx: 310 |  Loss: (0.4072) |  Loss2: (0.0000) | Acc: (85.00%) (34162/39808)
Epoch: 50 | Batch_idx: 320 |  Loss: (0.4073) |  Loss2: (0.0000) | Acc: (85.00%) (35259/41088)
Epoch: 50 | Batch_idx: 330 |  Loss: (0.4074) |  Loss2: (0.0000) | Acc: (85.00%) (36360/42368)
Epoch: 50 | Batch_idx: 340 |  Loss: (0.4080) |  Loss2: (0.0000) | Acc: (85.00%) (37456/43648)
Epoch: 50 | Batch_idx: 350 |  Loss: (0.4084) |  Loss2: (0.0000) | Acc: (85.00%) (38543/44928)
Epoch: 50 | Batch_idx: 360 |  Loss: (0.4077) |  Loss2: (0.0000) | Acc: (85.00%) (39643/46208)
Epoch: 50 | Batch_idx: 370 |  Loss: (0.4077) |  Loss2: (0.0000) | Acc: (85.00%) (40750/47488)
Epoch: 50 | Batch_idx: 380 |  Loss: (0.4078) |  Loss2: (0.0000) | Acc: (85.00%) (41857/48768)
Epoch: 50 | Batch_idx: 390 |  Loss: (0.4083) |  Loss2: (0.0000) | Acc: (85.00%) (42905/50000)
=> saving checkpoint 'drive/app/torch/save_Schedule/checkpoint_050.pth.tar'
# TEST : Loss: (0.4985) | Acc: (83.00%) (8326/10000)
percent tensor([0.5258, 0.5281, 0.5248, 0.5239, 0.5266, 0.5260, 0.5295, 0.5280, 0.5263,
        0.5278, 0.5269, 0.5272, 0.5268, 0.5261, 0.5262, 0.5264],
       device='cuda:0') torch.Size([16])
percent tensor([0.4983, 0.4945, 0.4929, 0.4983, 0.4914, 0.5045, 0.4923, 0.4894, 0.4978,
        0.4934, 0.4991, 0.4942, 0.4999, 0.4989, 0.4976, 0.4998],
       device='cuda:0') torch.Size([16])
percent tensor([0.5055, 0.4826, 0.5379, 0.5487, 0.5524, 0.5399, 0.5222, 0.5421, 0.5187,
        0.4888, 0.4920, 0.5029, 0.4478, 0.5325, 0.5133, 0.5041],
       device='cuda:0') torch.Size([16])
percent tensor([0.6263, 0.6246, 0.6160, 0.6185, 0.6199, 0.6154, 0.6274, 0.6276, 0.6264,
        0.6289, 0.6348, 0.6301, 0.6320, 0.6244, 0.6273, 0.6312],
       device='cuda:0') torch.Size([16])
percent tensor([0.5712, 0.5565, 0.5913, 0.6159, 0.5907, 0.6207, 0.5614, 0.5834, 0.5805,
        0.5715, 0.5707, 0.5973, 0.5669, 0.6005, 0.5592, 0.5956],
       device='cuda:0') torch.Size([16])
percent tensor([0.5481, 0.5689, 0.5655, 0.5784, 0.5644, 0.6226, 0.5552, 0.5184, 0.5852,
        0.5661, 0.5802, 0.5705, 0.5729, 0.6045, 0.5345, 0.5664],
       device='cuda:0') torch.Size([16])
percent tensor([0.5618, 0.5560, 0.5925, 0.5907, 0.6098, 0.5953, 0.5629, 0.5926, 0.5536,
        0.5563, 0.5484, 0.5651, 0.5478, 0.5554, 0.5417, 0.5719],
       device='cuda:0') torch.Size([16])
percent tensor([0.9994, 0.9970, 0.9971, 0.9974, 0.9959, 0.9977, 0.9988, 0.9986, 0.9977,
        0.9971, 0.9991, 0.9979, 0.9986, 0.9989, 0.9964, 0.9989],
       device='cuda:0') torch.Size([16])
Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 3, 3, 3]) tensor(172.2500, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(802.4899, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(793.1542, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([128, 64, 3, 3]) tensor(1524.8524, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([128, 64, 1, 1]) tensor(503.2146, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([128, 128, 3, 3]) tensor(2204.5725, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([256, 128, 3, 3]) tensor(4294.9551, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([256, 128, 1, 1]) tensor(1420.7488, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([256, 256, 3, 3]) tensor(6108.3604, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([512, 256, 3, 3]) tensor(12043.9814, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([512, 256, 1, 1]) tensor(4010.1375, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([512, 512, 3, 3]) tensor(16985.5000, device='cuda:0', grad_fn=<NormBackward0>)
Epoch: 51 | Batch_idx: 0 |  Loss: (0.3866) |  Loss2: (0.0000) | Acc: (86.00%) (111/128)
Epoch: 51 | Batch_idx: 10 |  Loss: (0.4040) |  Loss2: (0.0000) | Acc: (85.00%) (1205/1408)
Epoch: 51 | Batch_idx: 20 |  Loss: (0.4076) |  Loss2: (0.0000) | Acc: (85.00%) (2299/2688)
Epoch: 51 | Batch_idx: 30 |  Loss: (0.4039) |  Loss2: (0.0000) | Acc: (85.00%) (3410/3968)
Epoch: 51 | Batch_idx: 40 |  Loss: (0.4082) |  Loss2: (0.0000) | Acc: (85.00%) (4512/5248)
Epoch: 51 | Batch_idx: 50 |  Loss: (0.4079) |  Loss2: (0.0000) | Acc: (85.00%) (5613/6528)
Epoch: 51 | Batch_idx: 60 |  Loss: (0.4019) |  Loss2: (0.0000) | Acc: (86.00%) (6733/7808)
Epoch: 51 | Batch_idx: 70 |  Loss: (0.4026) |  Loss2: (0.0000) | Acc: (86.00%) (7842/9088)
Epoch: 51 | Batch_idx: 80 |  Loss: (0.4018) |  Loss2: (0.0000) | Acc: (86.00%) (8948/10368)
Epoch: 51 | Batch_idx: 90 |  Loss: (0.4027) |  Loss2: (0.0000) | Acc: (86.00%) (10040/11648)
Epoch: 51 | Batch_idx: 100 |  Loss: (0.4004) |  Loss2: (0.0000) | Acc: (86.00%) (11149/12928)
Epoch: 51 | Batch_idx: 110 |  Loss: (0.3977) |  Loss2: (0.0000) | Acc: (86.00%) (12263/14208)
Epoch: 51 | Batch_idx: 120 |  Loss: (0.3958) |  Loss2: (0.0000) | Acc: (86.00%) (13372/15488)
Epoch: 51 | Batch_idx: 130 |  Loss: (0.3953) |  Loss2: (0.0000) | Acc: (86.00%) (14464/16768)
Epoch: 51 | Batch_idx: 140 |  Loss: (0.3958) |  Loss2: (0.0000) | Acc: (86.00%) (15569/18048)
Epoch: 51 | Batch_idx: 150 |  Loss: (0.3982) |  Loss2: (0.0000) | Acc: (86.00%) (16649/19328)
Epoch: 51 | Batch_idx: 160 |  Loss: (0.3969) |  Loss2: (0.0000) | Acc: (86.00%) (17764/20608)
Epoch: 51 | Batch_idx: 170 |  Loss: (0.3961) |  Loss2: (0.0000) | Acc: (86.00%) (18867/21888)
Epoch: 51 | Batch_idx: 180 |  Loss: (0.3959) |  Loss2: (0.0000) | Acc: (86.00%) (19969/23168)
Epoch: 51 | Batch_idx: 190 |  Loss: (0.3974) |  Loss2: (0.0000) | Acc: (86.00%) (21064/24448)
Epoch: 51 | Batch_idx: 200 |  Loss: (0.3971) |  Loss2: (0.0000) | Acc: (86.00%) (22169/25728)
Epoch: 51 | Batch_idx: 210 |  Loss: (0.3984) |  Loss2: (0.0000) | Acc: (86.00%) (23263/27008)
Epoch: 51 | Batch_idx: 220 |  Loss: (0.3990) |  Loss2: (0.0000) | Acc: (86.00%) (24369/28288)
Epoch: 51 | Batch_idx: 230 |  Loss: (0.3978) |  Loss2: (0.0000) | Acc: (86.00%) (25475/29568)
Epoch: 51 | Batch_idx: 240 |  Loss: (0.3973) |  Loss2: (0.0000) | Acc: (86.00%) (26589/30848)
Epoch: 51 | Batch_idx: 250 |  Loss: (0.3967) |  Loss2: (0.0000) | Acc: (86.00%) (27700/32128)
Epoch: 51 | Batch_idx: 260 |  Loss: (0.3974) |  Loss2: (0.0000) | Acc: (86.00%) (28786/33408)
Epoch: 51 | Batch_idx: 270 |  Loss: (0.3960) |  Loss2: (0.0000) | Acc: (86.00%) (29919/34688)
Epoch: 51 | Batch_idx: 280 |  Loss: (0.3950) |  Loss2: (0.0000) | Acc: (86.00%) (31036/35968)
Epoch: 51 | Batch_idx: 290 |  Loss: (0.3947) |  Loss2: (0.0000) | Acc: (86.00%) (32134/37248)
Epoch: 51 | Batch_idx: 300 |  Loss: (0.3937) |  Loss2: (0.0000) | Acc: (86.00%) (33255/38528)
Epoch: 51 | Batch_idx: 310 |  Loss: (0.3935) |  Loss2: (0.0000) | Acc: (86.00%) (34364/39808)
Epoch: 51 | Batch_idx: 320 |  Loss: (0.3932) |  Loss2: (0.0000) | Acc: (86.00%) (35472/41088)
Epoch: 51 | Batch_idx: 330 |  Loss: (0.3938) |  Loss2: (0.0000) | Acc: (86.00%) (36575/42368)
Epoch: 51 | Batch_idx: 340 |  Loss: (0.3938) |  Loss2: (0.0000) | Acc: (86.00%) (37682/43648)
Epoch: 51 | Batch_idx: 350 |  Loss: (0.3935) |  Loss2: (0.0000) | Acc: (86.00%) (38799/44928)
Epoch: 51 | Batch_idx: 360 |  Loss: (0.3945) |  Loss2: (0.0000) | Acc: (86.00%) (39902/46208)
Epoch: 51 | Batch_idx: 370 |  Loss: (0.3941) |  Loss2: (0.0000) | Acc: (86.00%) (41026/47488)
Epoch: 51 | Batch_idx: 380 |  Loss: (0.3949) |  Loss2: (0.0000) | Acc: (86.00%) (42109/48768)
Epoch: 51 | Batch_idx: 390 |  Loss: (0.3954) |  Loss2: (0.0000) | Acc: (86.00%) (43148/50000)
# TEST : Loss: (0.5998) | Acc: (80.00%) (8028/10000)
percent tensor([0.5251, 0.5295, 0.5216, 0.5239, 0.5241, 0.5256, 0.5293, 0.5275, 0.5261,
        0.5274, 0.5271, 0.5249, 0.5266, 0.5291, 0.5270, 0.5268],
       device='cuda:0') torch.Size([16])
percent tensor([0.4987, 0.4939, 0.4950, 0.4989, 0.4924, 0.5044, 0.4919, 0.4903, 0.4976,
        0.4939, 0.4997, 0.4946, 0.4999, 0.4973, 0.4978, 0.4999],
       device='cuda:0') torch.Size([16])
percent tensor([0.5036, 0.4731, 0.5389, 0.5476, 0.5528, 0.5238, 0.5164, 0.5403, 0.5123,
        0.4843, 0.4861, 0.5041, 0.4408, 0.5191, 0.5052, 0.4976],
       device='cuda:0') torch.Size([16])
percent tensor([0.6262, 0.6261, 0.6183, 0.6178, 0.6223, 0.6136, 0.6297, 0.6286, 0.6266,
        0.6259, 0.6323, 0.6300, 0.6300, 0.6279, 0.6282, 0.6302],
       device='cuda:0') torch.Size([16])
percent tensor([0.5667, 0.5538, 0.5919, 0.6159, 0.5954, 0.6102, 0.5577, 0.5775, 0.5796,
        0.5712, 0.5672, 0.5951, 0.5696, 0.5941, 0.5536, 0.5941],
       device='cuda:0') torch.Size([16])
percent tensor([0.5412, 0.5646, 0.5614, 0.5771, 0.5607, 0.6182, 0.5408, 0.5127, 0.5798,
        0.5694, 0.5826, 0.5709, 0.5830, 0.5946, 0.5294, 0.5599],
       device='cuda:0') torch.Size([16])
percent tensor([0.5616, 0.5514, 0.5943, 0.5979, 0.6134, 0.6039, 0.5587, 0.5972, 0.5544,
        0.5576, 0.5503, 0.5745, 0.5493, 0.5490, 0.5533, 0.5759],
       device='cuda:0') torch.Size([16])
percent tensor([0.9993, 0.9972, 0.9971, 0.9986, 0.9968, 0.9968, 0.9978, 0.9992, 0.9975,
        0.9981, 0.9983, 0.9982, 0.9980, 0.9983, 0.9975, 0.9987],
       device='cuda:0') torch.Size([16])
Epoch: 52 | Batch_idx: 0 |  Loss: (0.4519) |  Loss2: (0.0000) | Acc: (84.00%) (108/128)
Epoch: 52 | Batch_idx: 10 |  Loss: (0.4355) |  Loss2: (0.0000) | Acc: (84.00%) (1185/1408)
Epoch: 52 | Batch_idx: 20 |  Loss: (0.4252) |  Loss2: (0.0000) | Acc: (84.00%) (2272/2688)
Epoch: 52 | Batch_idx: 30 |  Loss: (0.4147) |  Loss2: (0.0000) | Acc: (85.00%) (3379/3968)
Epoch: 52 | Batch_idx: 40 |  Loss: (0.3984) |  Loss2: (0.0000) | Acc: (85.00%) (4504/5248)
Epoch: 52 | Batch_idx: 50 |  Loss: (0.3941) |  Loss2: (0.0000) | Acc: (86.00%) (5624/6528)
Epoch: 52 | Batch_idx: 60 |  Loss: (0.3952) |  Loss2: (0.0000) | Acc: (86.00%) (6731/7808)
Epoch: 52 | Batch_idx: 70 |  Loss: (0.3896) |  Loss2: (0.0000) | Acc: (86.00%) (7861/9088)
Epoch: 52 | Batch_idx: 80 |  Loss: (0.3887) |  Loss2: (0.0000) | Acc: (86.00%) (8982/10368)
Epoch: 52 | Batch_idx: 90 |  Loss: (0.3851) |  Loss2: (0.0000) | Acc: (86.00%) (10105/11648)
Epoch: 52 | Batch_idx: 100 |  Loss: (0.3833) |  Loss2: (0.0000) | Acc: (86.00%) (11220/12928)
Epoch: 52 | Batch_idx: 110 |  Loss: (0.3807) |  Loss2: (0.0000) | Acc: (86.00%) (12350/14208)
Epoch: 52 | Batch_idx: 120 |  Loss: (0.3792) |  Loss2: (0.0000) | Acc: (87.00%) (13482/15488)
Epoch: 52 | Batch_idx: 130 |  Loss: (0.3798) |  Loss2: (0.0000) | Acc: (87.00%) (14591/16768)
Epoch: 52 | Batch_idx: 140 |  Loss: (0.3850) |  Loss2: (0.0000) | Acc: (86.00%) (15679/18048)
Epoch: 52 | Batch_idx: 150 |  Loss: (0.3840) |  Loss2: (0.0000) | Acc: (86.00%) (16811/19328)
Epoch: 52 | Batch_idx: 160 |  Loss: (0.3832) |  Loss2: (0.0000) | Acc: (87.00%) (17949/20608)
Epoch: 52 | Batch_idx: 170 |  Loss: (0.3834) |  Loss2: (0.0000) | Acc: (87.00%) (19056/21888)
Epoch: 52 | Batch_idx: 180 |  Loss: (0.3832) |  Loss2: (0.0000) | Acc: (87.00%) (20178/23168)
Epoch: 52 | Batch_idx: 190 |  Loss: (0.3829) |  Loss2: (0.0000) | Acc: (87.00%) (21300/24448)
Epoch: 52 | Batch_idx: 200 |  Loss: (0.3823) |  Loss2: (0.0000) | Acc: (87.00%) (22421/25728)
Epoch: 52 | Batch_idx: 210 |  Loss: (0.3813) |  Loss2: (0.0000) | Acc: (87.00%) (23544/27008)
Epoch: 52 | Batch_idx: 220 |  Loss: (0.3818) |  Loss2: (0.0000) | Acc: (87.00%) (24654/28288)
Epoch: 52 | Batch_idx: 230 |  Loss: (0.3824) |  Loss2: (0.0000) | Acc: (87.00%) (25756/29568)
Epoch: 52 | Batch_idx: 240 |  Loss: (0.3819) |  Loss2: (0.0000) | Acc: (87.00%) (26865/30848)
Epoch: 52 | Batch_idx: 250 |  Loss: (0.3812) |  Loss2: (0.0000) | Acc: (87.00%) (27987/32128)
Epoch: 52 | Batch_idx: 260 |  Loss: (0.3824) |  Loss2: (0.0000) | Acc: (87.00%) (29077/33408)
Epoch: 52 | Batch_idx: 270 |  Loss: (0.3829) |  Loss2: (0.0000) | Acc: (87.00%) (30188/34688)
Epoch: 52 | Batch_idx: 280 |  Loss: (0.3836) |  Loss2: (0.0000) | Acc: (87.00%) (31294/35968)
Epoch: 52 | Batch_idx: 290 |  Loss: (0.3826) |  Loss2: (0.0000) | Acc: (87.00%) (32418/37248)
Epoch: 52 | Batch_idx: 300 |  Loss: (0.3828) |  Loss2: (0.0000) | Acc: (87.00%) (33540/38528)
Epoch: 52 | Batch_idx: 310 |  Loss: (0.3834) |  Loss2: (0.0000) | Acc: (87.00%) (34645/39808)
Epoch: 52 | Batch_idx: 320 |  Loss: (0.3842) |  Loss2: (0.0000) | Acc: (86.00%) (35745/41088)
Epoch: 52 | Batch_idx: 330 |  Loss: (0.3841) |  Loss2: (0.0000) | Acc: (87.00%) (36861/42368)
Epoch: 52 | Batch_idx: 340 |  Loss: (0.3845) |  Loss2: (0.0000) | Acc: (87.00%) (37981/43648)
Epoch: 52 | Batch_idx: 350 |  Loss: (0.3853) |  Loss2: (0.0000) | Acc: (86.00%) (39079/44928)
Epoch: 52 | Batch_idx: 360 |  Loss: (0.3853) |  Loss2: (0.0000) | Acc: (86.00%) (40179/46208)
Epoch: 52 | Batch_idx: 370 |  Loss: (0.3855) |  Loss2: (0.0000) | Acc: (86.00%) (41282/47488)
Epoch: 52 | Batch_idx: 380 |  Loss: (0.3852) |  Loss2: (0.0000) | Acc: (86.00%) (42403/48768)
Epoch: 52 | Batch_idx: 390 |  Loss: (0.3849) |  Loss2: (0.0000) | Acc: (86.00%) (43466/50000)
# TEST : Loss: (0.4745) | Acc: (84.00%) (8421/10000)
percent tensor([0.5252, 0.5287, 0.5229, 0.5237, 0.5254, 0.5259, 0.5292, 0.5275, 0.5260,
        0.5275, 0.5268, 0.5258, 0.5265, 0.5274, 0.5268, 0.5264],
       device='cuda:0') torch.Size([16])
percent tensor([0.4981, 0.4941, 0.4944, 0.4983, 0.4921, 0.5032, 0.4918, 0.4902, 0.4970,
        0.4940, 0.4995, 0.4945, 0.4992, 0.4963, 0.4975, 0.4995],
       device='cuda:0') torch.Size([16])
percent tensor([0.5016, 0.4754, 0.5390, 0.5499, 0.5527, 0.5339, 0.5184, 0.5417, 0.5159,
        0.4821, 0.4903, 0.5043, 0.4421, 0.5261, 0.5100, 0.4986],
       device='cuda:0') torch.Size([16])
percent tensor([0.6250, 0.6243, 0.6174, 0.6193, 0.6228, 0.6126, 0.6272, 0.6284, 0.6261,
        0.6277, 0.6315, 0.6320, 0.6296, 0.6251, 0.6271, 0.6303],
       device='cuda:0') torch.Size([16])
percent tensor([0.5595, 0.5494, 0.5882, 0.6100, 0.5939, 0.6037, 0.5566, 0.5830, 0.5769,
        0.5632, 0.5584, 0.5924, 0.5621, 0.5965, 0.5490, 0.5864],
       device='cuda:0') torch.Size([16])
percent tensor([0.5371, 0.5599, 0.5638, 0.5694, 0.5590, 0.6160, 0.5433, 0.5135, 0.5809,
        0.5549, 0.5736, 0.5615, 0.5737, 0.5981, 0.5189, 0.5546],
       device='cuda:0') torch.Size([16])
percent tensor([0.5626, 0.5609, 0.5972, 0.5918, 0.6163, 0.6007, 0.5643, 0.5962, 0.5586,
        0.5596, 0.5533, 0.5671, 0.5529, 0.5686, 0.5496, 0.5717],
       device='cuda:0') torch.Size([16])
percent tensor([0.9992, 0.9969, 0.9965, 0.9981, 0.9969, 0.9965, 0.9984, 0.9983, 0.9969,
        0.9976, 0.9981, 0.9978, 0.9980, 0.9988, 0.9963, 0.9985],
       device='cuda:0') torch.Size([16])
Epoch: 53 | Batch_idx: 0 |  Loss: (0.3638) |  Loss2: (0.0000) | Acc: (88.00%) (113/128)
Epoch: 53 | Batch_idx: 10 |  Loss: (0.3744) |  Loss2: (0.0000) | Acc: (87.00%) (1234/1408)
Epoch: 53 | Batch_idx: 20 |  Loss: (0.3601) |  Loss2: (0.0000) | Acc: (87.00%) (2365/2688)
Epoch: 53 | Batch_idx: 30 |  Loss: (0.3600) |  Loss2: (0.0000) | Acc: (87.00%) (3489/3968)
Epoch: 53 | Batch_idx: 40 |  Loss: (0.3623) |  Loss2: (0.0000) | Acc: (87.00%) (4600/5248)
Epoch: 53 | Batch_idx: 50 |  Loss: (0.3597) |  Loss2: (0.0000) | Acc: (87.00%) (5730/6528)
Epoch: 53 | Batch_idx: 60 |  Loss: (0.3656) |  Loss2: (0.0000) | Acc: (87.00%) (6829/7808)
Epoch: 53 | Batch_idx: 70 |  Loss: (0.3634) |  Loss2: (0.0000) | Acc: (87.00%) (7939/9088)
Epoch: 53 | Batch_idx: 80 |  Loss: (0.3634) |  Loss2: (0.0000) | Acc: (87.00%) (9064/10368)
Epoch: 53 | Batch_idx: 90 |  Loss: (0.3601) |  Loss2: (0.0000) | Acc: (87.00%) (10197/11648)
Epoch: 53 | Batch_idx: 100 |  Loss: (0.3654) |  Loss2: (0.0000) | Acc: (87.00%) (11277/12928)
Epoch: 53 | Batch_idx: 110 |  Loss: (0.3635) |  Loss2: (0.0000) | Acc: (87.00%) (12412/14208)
Epoch: 53 | Batch_idx: 120 |  Loss: (0.3666) |  Loss2: (0.0000) | Acc: (87.00%) (13524/15488)
Epoch: 53 | Batch_idx: 130 |  Loss: (0.3649) |  Loss2: (0.0000) | Acc: (87.00%) (14644/16768)
Epoch: 53 | Batch_idx: 140 |  Loss: (0.3631) |  Loss2: (0.0000) | Acc: (87.00%) (15769/18048)
Epoch: 53 | Batch_idx: 150 |  Loss: (0.3621) |  Loss2: (0.0000) | Acc: (87.00%) (16904/19328)
Epoch: 53 | Batch_idx: 160 |  Loss: (0.3610) |  Loss2: (0.0000) | Acc: (87.00%) (18031/20608)
Epoch: 53 | Batch_idx: 170 |  Loss: (0.3630) |  Loss2: (0.0000) | Acc: (87.00%) (19130/21888)
Epoch: 53 | Batch_idx: 180 |  Loss: (0.3634) |  Loss2: (0.0000) | Acc: (87.00%) (20241/23168)
Epoch: 53 | Batch_idx: 190 |  Loss: (0.3649) |  Loss2: (0.0000) | Acc: (87.00%) (21354/24448)
Epoch: 53 | Batch_idx: 200 |  Loss: (0.3646) |  Loss2: (0.0000) | Acc: (87.00%) (22466/25728)
Epoch: 53 | Batch_idx: 210 |  Loss: (0.3653) |  Loss2: (0.0000) | Acc: (87.00%) (23591/27008)
Epoch: 53 | Batch_idx: 220 |  Loss: (0.3653) |  Loss2: (0.0000) | Acc: (87.00%) (24706/28288)
Epoch: 53 | Batch_idx: 230 |  Loss: (0.3652) |  Loss2: (0.0000) | Acc: (87.00%) (25834/29568)
Epoch: 53 | Batch_idx: 240 |  Loss: (0.3683) |  Loss2: (0.0000) | Acc: (87.00%) (26908/30848)
Epoch: 53 | Batch_idx: 250 |  Loss: (0.3681) |  Loss2: (0.0000) | Acc: (87.00%) (28034/32128)
Epoch: 53 | Batch_idx: 260 |  Loss: (0.3692) |  Loss2: (0.0000) | Acc: (87.00%) (29139/33408)
Epoch: 53 | Batch_idx: 270 |  Loss: (0.3694) |  Loss2: (0.0000) | Acc: (87.00%) (30257/34688)
Epoch: 53 | Batch_idx: 280 |  Loss: (0.3703) |  Loss2: (0.0000) | Acc: (87.00%) (31368/35968)
Epoch: 53 | Batch_idx: 290 |  Loss: (0.3714) |  Loss2: (0.0000) | Acc: (87.00%) (32467/37248)
Epoch: 53 | Batch_idx: 300 |  Loss: (0.3717) |  Loss2: (0.0000) | Acc: (87.00%) (33579/38528)
Epoch: 53 | Batch_idx: 310 |  Loss: (0.3728) |  Loss2: (0.0000) | Acc: (87.00%) (34677/39808)
Epoch: 53 | Batch_idx: 320 |  Loss: (0.3728) |  Loss2: (0.0000) | Acc: (87.00%) (35802/41088)
Epoch: 53 | Batch_idx: 330 |  Loss: (0.3723) |  Loss2: (0.0000) | Acc: (87.00%) (36927/42368)
Epoch: 53 | Batch_idx: 340 |  Loss: (0.3728) |  Loss2: (0.0000) | Acc: (87.00%) (38026/43648)
Epoch: 53 | Batch_idx: 350 |  Loss: (0.3731) |  Loss2: (0.0000) | Acc: (87.00%) (39132/44928)
Epoch: 53 | Batch_idx: 360 |  Loss: (0.3725) |  Loss2: (0.0000) | Acc: (87.00%) (40263/46208)
Epoch: 53 | Batch_idx: 370 |  Loss: (0.3730) |  Loss2: (0.0000) | Acc: (87.00%) (41372/47488)
Epoch: 53 | Batch_idx: 380 |  Loss: (0.3738) |  Loss2: (0.0000) | Acc: (87.00%) (42471/48768)
Epoch: 53 | Batch_idx: 390 |  Loss: (0.3744) |  Loss2: (0.0000) | Acc: (87.00%) (43535/50000)
# TEST : Loss: (0.5073) | Acc: (83.00%) (8344/10000)
percent tensor([0.5253, 0.5280, 0.5240, 0.5240, 0.5260, 0.5259, 0.5290, 0.5276, 0.5253,
        0.5275, 0.5262, 0.5264, 0.5262, 0.5266, 0.5265, 0.5262],
       device='cuda:0') torch.Size([16])
percent tensor([0.4975, 0.4936, 0.4943, 0.4987, 0.4913, 0.5049, 0.4906, 0.4902, 0.4976,
        0.4931, 0.4994, 0.4940, 0.4990, 0.4976, 0.4976, 0.4995],
       device='cuda:0') torch.Size([16])
percent tensor([0.5087, 0.4825, 0.5414, 0.5498, 0.5547, 0.5299, 0.5263, 0.5460, 0.5255,
        0.4902, 0.4954, 0.5085, 0.4521, 0.5348, 0.5125, 0.5043],
       device='cuda:0') torch.Size([16])
percent tensor([0.6237, 0.6232, 0.6165, 0.6187, 0.6207, 0.6155, 0.6274, 0.6281, 0.6250,
        0.6266, 0.6309, 0.6295, 0.6269, 0.6276, 0.6269, 0.6291],
       device='cuda:0') torch.Size([16])
percent tensor([0.5618, 0.5460, 0.5850, 0.6166, 0.5947, 0.6149, 0.5553, 0.5784, 0.5726,
        0.5653, 0.5546, 0.5884, 0.5585, 0.5887, 0.5539, 0.5885],
       device='cuda:0') torch.Size([16])
percent tensor([0.5318, 0.5625, 0.5539, 0.5744, 0.5553, 0.6202, 0.5398, 0.5071, 0.5722,
        0.5615, 0.5665, 0.5600, 0.5693, 0.5926, 0.5247, 0.5553],
       device='cuda:0') torch.Size([16])
percent tensor([0.5686, 0.5564, 0.5991, 0.5978, 0.6210, 0.6049, 0.5680, 0.5948, 0.5504,
        0.5583, 0.5481, 0.5652, 0.5529, 0.5551, 0.5484, 0.5839],
       device='cuda:0') torch.Size([16])
percent tensor([0.9994, 0.9955, 0.9978, 0.9975, 0.9978, 0.9966, 0.9984, 0.9993, 0.9968,
        0.9965, 0.9974, 0.9982, 0.9976, 0.9979, 0.9952, 0.9989],
       device='cuda:0') torch.Size([16])
False Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=128, out_features=16, bias=False)
True Linear(in_features=16, out_features=2, bias=False)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=128, out_features=16, bias=False)
True Linear(in_features=16, out_features=2, bias=False)
False Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=256, out_features=32, bias=False)
True Linear(in_features=32, out_features=2, bias=False)
False Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=256, out_features=32, bias=False)
True Linear(in_features=32, out_features=2, bias=False)
False Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=512, out_features=64, bias=False)
True Linear(in_features=64, out_features=2, bias=False)
False Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=512, out_features=64, bias=False)
True Linear(in_features=64, out_features=2, bias=False)
False Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1024, out_features=128, bias=False)
True Linear(in_features=128, out_features=2, bias=False)
False Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1024, out_features=128, bias=False)
True Linear(in_features=128, out_features=2, bias=False)
False Linear(in_features=512, out_features=10, bias=True)
Epoch: 54 | Batch_idx: 0 |  Loss: (0.2665) |  Loss2: (0.0000) | Acc: (92.00%) (118/128)
Epoch: 54 | Batch_idx: 10 |  Loss: (0.3217) |  Loss2: (0.0000) | Acc: (88.00%) (1248/1408)
Epoch: 54 | Batch_idx: 20 |  Loss: (0.3544) |  Loss2: (0.0000) | Acc: (87.00%) (2359/2688)
Epoch: 54 | Batch_idx: 30 |  Loss: (0.3726) |  Loss2: (0.0000) | Acc: (87.00%) (3465/3968)
Epoch: 54 | Batch_idx: 40 |  Loss: (0.3925) |  Loss2: (0.0000) | Acc: (86.00%) (4540/5248)
Epoch: 54 | Batch_idx: 50 |  Loss: (0.4019) |  Loss2: (0.0000) | Acc: (86.00%) (5622/6528)
Epoch: 54 | Batch_idx: 60 |  Loss: (0.4077) |  Loss2: (0.0000) | Acc: (85.00%) (6710/7808)
Epoch: 54 | Batch_idx: 70 |  Loss: (0.4135) |  Loss2: (0.0000) | Acc: (85.00%) (7793/9088)
Epoch: 54 | Batch_idx: 80 |  Loss: (0.4138) |  Loss2: (0.0000) | Acc: (85.00%) (8881/10368)
Epoch: 54 | Batch_idx: 90 |  Loss: (0.4166) |  Loss2: (0.0000) | Acc: (85.00%) (9970/11648)
Epoch: 54 | Batch_idx: 100 |  Loss: (0.4139) |  Loss2: (0.0000) | Acc: (85.00%) (11083/12928)
Epoch: 54 | Batch_idx: 110 |  Loss: (0.4140) |  Loss2: (0.0000) | Acc: (85.00%) (12180/14208)
Epoch: 54 | Batch_idx: 120 |  Loss: (0.4162) |  Loss2: (0.0000) | Acc: (85.00%) (13268/15488)
Epoch: 54 | Batch_idx: 130 |  Loss: (0.4198) |  Loss2: (0.0000) | Acc: (85.00%) (14341/16768)
Epoch: 54 | Batch_idx: 140 |  Loss: (0.4223) |  Loss2: (0.0000) | Acc: (85.00%) (15416/18048)
Epoch: 54 | Batch_idx: 150 |  Loss: (0.4194) |  Loss2: (0.0000) | Acc: (85.00%) (16515/19328)
Epoch: 54 | Batch_idx: 160 |  Loss: (0.4194) |  Loss2: (0.0000) | Acc: (85.00%) (17618/20608)
Epoch: 54 | Batch_idx: 170 |  Loss: (0.4218) |  Loss2: (0.0000) | Acc: (85.00%) (18686/21888)
Epoch: 54 | Batch_idx: 180 |  Loss: (0.4218) |  Loss2: (0.0000) | Acc: (85.00%) (19784/23168)
Epoch: 54 | Batch_idx: 190 |  Loss: (0.4217) |  Loss2: (0.0000) | Acc: (85.00%) (20879/24448)
Epoch: 54 | Batch_idx: 200 |  Loss: (0.4221) |  Loss2: (0.0000) | Acc: (85.00%) (21970/25728)
Epoch: 54 | Batch_idx: 210 |  Loss: (0.4217) |  Loss2: (0.0000) | Acc: (85.00%) (23055/27008)
Epoch: 54 | Batch_idx: 220 |  Loss: (0.4216) |  Loss2: (0.0000) | Acc: (85.00%) (24158/28288)
Epoch: 54 | Batch_idx: 230 |  Loss: (0.4212) |  Loss2: (0.0000) | Acc: (85.00%) (25247/29568)
Epoch: 54 | Batch_idx: 240 |  Loss: (0.4214) |  Loss2: (0.0000) | Acc: (85.00%) (26341/30848)
Epoch: 54 | Batch_idx: 250 |  Loss: (0.4203) |  Loss2: (0.0000) | Acc: (85.00%) (27445/32128)
Epoch: 54 | Batch_idx: 260 |  Loss: (0.4220) |  Loss2: (0.0000) | Acc: (85.00%) (28505/33408)
Epoch: 54 | Batch_idx: 270 |  Loss: (0.4212) |  Loss2: (0.0000) | Acc: (85.00%) (29603/34688)
Epoch: 54 | Batch_idx: 280 |  Loss: (0.4210) |  Loss2: (0.0000) | Acc: (85.00%) (30694/35968)
Epoch: 54 | Batch_idx: 290 |  Loss: (0.4198) |  Loss2: (0.0000) | Acc: (85.00%) (31792/37248)
Epoch: 54 | Batch_idx: 300 |  Loss: (0.4193) |  Loss2: (0.0000) | Acc: (85.00%) (32899/38528)
Epoch: 54 | Batch_idx: 310 |  Loss: (0.4198) |  Loss2: (0.0000) | Acc: (85.00%) (33979/39808)
Epoch: 54 | Batch_idx: 320 |  Loss: (0.4188) |  Loss2: (0.0000) | Acc: (85.00%) (35083/41088)
Epoch: 54 | Batch_idx: 330 |  Loss: (0.4177) |  Loss2: (0.0000) | Acc: (85.00%) (36193/42368)
Epoch: 54 | Batch_idx: 340 |  Loss: (0.4169) |  Loss2: (0.0000) | Acc: (85.00%) (37298/43648)
Epoch: 54 | Batch_idx: 350 |  Loss: (0.4155) |  Loss2: (0.0000) | Acc: (85.00%) (38406/44928)
Epoch: 54 | Batch_idx: 360 |  Loss: (0.4144) |  Loss2: (0.0000) | Acc: (85.00%) (39525/46208)
Epoch: 54 | Batch_idx: 370 |  Loss: (0.4150) |  Loss2: (0.0000) | Acc: (85.00%) (40606/47488)
Epoch: 54 | Batch_idx: 380 |  Loss: (0.4148) |  Loss2: (0.0000) | Acc: (85.00%) (41703/48768)
Epoch: 54 | Batch_idx: 390 |  Loss: (0.4140) |  Loss2: (0.0000) | Acc: (85.00%) (42761/50000)
# TEST : Loss: (0.4821) | Acc: (83.00%) (8379/10000)
percent tensor([0.5236, 0.5271, 0.5225, 0.5230, 0.5245, 0.5240, 0.5277, 0.5267, 0.5241,
        0.5265, 0.5249, 0.5249, 0.5249, 0.5263, 0.5249, 0.5250],
       device='cuda:0') torch.Size([16])
percent tensor([0.4953, 0.4887, 0.4923, 0.4964, 0.4878, 0.5035, 0.4856, 0.4875, 0.4945,
        0.4889, 0.4954, 0.4913, 0.4962, 0.4939, 0.4935, 0.4967],
       device='cuda:0') torch.Size([16])
percent tensor([0.4918, 0.4937, 0.5419, 0.5513, 0.5555, 0.5167, 0.5315, 0.5416, 0.5297,
        0.5047, 0.5131, 0.5145, 0.4498, 0.5431, 0.5075, 0.4962],
       device='cuda:0') torch.Size([16])
percent tensor([0.5839, 0.5864, 0.5853, 0.5843, 0.5859, 0.5735, 0.5911, 0.5912, 0.5918,
        0.5901, 0.5933, 0.5943, 0.5889, 0.5930, 0.5858, 0.5870],
       device='cuda:0') torch.Size([16])
percent tensor([0.5816, 0.5735, 0.6148, 0.6430, 0.6219, 0.6423, 0.5792, 0.5982, 0.6011,
        0.6011, 0.5922, 0.6193, 0.5851, 0.6189, 0.5763, 0.6118],
       device='cuda:0') torch.Size([16])
percent tensor([0.5854, 0.6009, 0.6004, 0.6129, 0.6023, 0.6627, 0.5822, 0.5646, 0.6067,
        0.5973, 0.6052, 0.6004, 0.6076, 0.6206, 0.5749, 0.6044],
       device='cuda:0') torch.Size([16])
percent tensor([0.5646, 0.5474, 0.5861, 0.5876, 0.6155, 0.5937, 0.5612, 0.6031, 0.5389,
        0.5470, 0.5372, 0.5553, 0.5383, 0.5381, 0.5490, 0.5847],
       device='cuda:0') torch.Size([16])
percent tensor([0.9992, 0.9964, 0.9969, 0.9973, 0.9974, 0.9952, 0.9977, 0.9993, 0.9978,
        0.9976, 0.9984, 0.9980, 0.9985, 0.9984, 0.9953, 0.9990],
       device='cuda:0') torch.Size([16])
Epoch: 55 | Batch_idx: 0 |  Loss: (0.2965) |  Loss2: (0.0000) | Acc: (89.00%) (114/128)
Epoch: 55 | Batch_idx: 10 |  Loss: (0.3795) |  Loss2: (0.0000) | Acc: (86.00%) (1216/1408)
Epoch: 55 | Batch_idx: 20 |  Loss: (0.3905) |  Loss2: (0.0000) | Acc: (86.00%) (2314/2688)
Epoch: 55 | Batch_idx: 30 |  Loss: (0.3860) |  Loss2: (0.0000) | Acc: (86.00%) (3434/3968)
Epoch: 55 | Batch_idx: 40 |  Loss: (0.3940) |  Loss2: (0.0000) | Acc: (86.00%) (4529/5248)
Epoch: 55 | Batch_idx: 50 |  Loss: (0.3963) |  Loss2: (0.0000) | Acc: (86.00%) (5625/6528)
Epoch: 55 | Batch_idx: 60 |  Loss: (0.3947) |  Loss2: (0.0000) | Acc: (86.00%) (6737/7808)
Epoch: 55 | Batch_idx: 70 |  Loss: (0.3944) |  Loss2: (0.0000) | Acc: (86.00%) (7838/9088)
Epoch: 55 | Batch_idx: 80 |  Loss: (0.3962) |  Loss2: (0.0000) | Acc: (86.00%) (8941/10368)
Epoch: 55 | Batch_idx: 90 |  Loss: (0.3911) |  Loss2: (0.0000) | Acc: (86.00%) (10076/11648)
Epoch: 55 | Batch_idx: 100 |  Loss: (0.3888) |  Loss2: (0.0000) | Acc: (86.00%) (11205/12928)
Epoch: 55 | Batch_idx: 110 |  Loss: (0.3909) |  Loss2: (0.0000) | Acc: (86.00%) (12302/14208)
Epoch: 55 | Batch_idx: 120 |  Loss: (0.3901) |  Loss2: (0.0000) | Acc: (86.00%) (13422/15488)
Epoch: 55 | Batch_idx: 130 |  Loss: (0.3913) |  Loss2: (0.0000) | Acc: (86.00%) (14519/16768)
Epoch: 55 | Batch_idx: 140 |  Loss: (0.3910) |  Loss2: (0.0000) | Acc: (86.00%) (15630/18048)
Epoch: 55 | Batch_idx: 150 |  Loss: (0.3898) |  Loss2: (0.0000) | Acc: (86.00%) (16752/19328)
Epoch: 55 | Batch_idx: 160 |  Loss: (0.3910) |  Loss2: (0.0000) | Acc: (86.00%) (17852/20608)
Epoch: 55 | Batch_idx: 170 |  Loss: (0.3902) |  Loss2: (0.0000) | Acc: (86.00%) (18979/21888)
Epoch: 55 | Batch_idx: 180 |  Loss: (0.3878) |  Loss2: (0.0000) | Acc: (86.00%) (20100/23168)
Epoch: 55 | Batch_idx: 190 |  Loss: (0.3880) |  Loss2: (0.0000) | Acc: (86.00%) (21203/24448)
Epoch: 55 | Batch_idx: 200 |  Loss: (0.3884) |  Loss2: (0.0000) | Acc: (86.00%) (22301/25728)
Epoch: 55 | Batch_idx: 210 |  Loss: (0.3889) |  Loss2: (0.0000) | Acc: (86.00%) (23393/27008)
Epoch: 55 | Batch_idx: 220 |  Loss: (0.3888) |  Loss2: (0.0000) | Acc: (86.00%) (24501/28288)
Epoch: 55 | Batch_idx: 230 |  Loss: (0.3887) |  Loss2: (0.0000) | Acc: (86.00%) (25611/29568)
Epoch: 55 | Batch_idx: 240 |  Loss: (0.3871) |  Loss2: (0.0000) | Acc: (86.00%) (26748/30848)
Epoch: 55 | Batch_idx: 250 |  Loss: (0.3864) |  Loss2: (0.0000) | Acc: (86.00%) (27866/32128)
Epoch: 55 | Batch_idx: 260 |  Loss: (0.3871) |  Loss2: (0.0000) | Acc: (86.00%) (28963/33408)
Epoch: 55 | Batch_idx: 270 |  Loss: (0.3869) |  Loss2: (0.0000) | Acc: (86.00%) (30064/34688)
Epoch: 55 | Batch_idx: 280 |  Loss: (0.3859) |  Loss2: (0.0000) | Acc: (86.00%) (31172/35968)
Epoch: 55 | Batch_idx: 290 |  Loss: (0.3869) |  Loss2: (0.0000) | Acc: (86.00%) (32274/37248)
Epoch: 55 | Batch_idx: 300 |  Loss: (0.3868) |  Loss2: (0.0000) | Acc: (86.00%) (33382/38528)
Epoch: 55 | Batch_idx: 310 |  Loss: (0.3865) |  Loss2: (0.0000) | Acc: (86.00%) (34490/39808)
Epoch: 55 | Batch_idx: 320 |  Loss: (0.3861) |  Loss2: (0.0000) | Acc: (86.00%) (35595/41088)
Epoch: 55 | Batch_idx: 330 |  Loss: (0.3855) |  Loss2: (0.0000) | Acc: (86.00%) (36718/42368)
Epoch: 55 | Batch_idx: 340 |  Loss: (0.3852) |  Loss2: (0.0000) | Acc: (86.00%) (37838/43648)
Epoch: 55 | Batch_idx: 350 |  Loss: (0.3858) |  Loss2: (0.0000) | Acc: (86.00%) (38938/44928)
Epoch: 55 | Batch_idx: 360 |  Loss: (0.3857) |  Loss2: (0.0000) | Acc: (86.00%) (40044/46208)
Epoch: 55 | Batch_idx: 370 |  Loss: (0.3859) |  Loss2: (0.0000) | Acc: (86.00%) (41162/47488)
Epoch: 55 | Batch_idx: 380 |  Loss: (0.3851) |  Loss2: (0.0000) | Acc: (86.00%) (42287/48768)
Epoch: 55 | Batch_idx: 390 |  Loss: (0.3847) |  Loss2: (0.0000) | Acc: (86.00%) (43354/50000)
=> saving checkpoint 'drive/app/torch/save_Schedule/checkpoint_055.pth.tar'
# TEST : Loss: (0.4610) | Acc: (84.00%) (8459/10000)
percent tensor([0.5253, 0.5290, 0.5249, 0.5254, 0.5268, 0.5258, 0.5297, 0.5289, 0.5256,
        0.5285, 0.5265, 0.5272, 0.5265, 0.5278, 0.5268, 0.5268],
       device='cuda:0') torch.Size([16])
percent tensor([0.4957, 0.4893, 0.4936, 0.4983, 0.4888, 0.5050, 0.4859, 0.4883, 0.4953,
        0.4895, 0.4957, 0.4924, 0.4968, 0.4949, 0.4943, 0.4975],
       device='cuda:0') torch.Size([16])
percent tensor([0.4802, 0.4978, 0.5396, 0.5518, 0.5539, 0.5031, 0.5315, 0.5379, 0.5303,
        0.5097, 0.5194, 0.5140, 0.4445, 0.5527, 0.5015, 0.4894],
       device='cuda:0') torch.Size([16])
percent tensor([0.5793, 0.5851, 0.5844, 0.5825, 0.5845, 0.5667, 0.5896, 0.5899, 0.5903,
        0.5881, 0.5916, 0.5934, 0.5852, 0.5915, 0.5830, 0.5817],
       device='cuda:0') torch.Size([16])
percent tensor([0.5683, 0.5702, 0.6041, 0.6305, 0.6090, 0.6285, 0.5698, 0.5840, 0.5960,
        0.5990, 0.5904, 0.6122, 0.5803, 0.6165, 0.5633, 0.5983],
       device='cuda:0') torch.Size([16])
percent tensor([0.5968, 0.6040, 0.6098, 0.6220, 0.6142, 0.6742, 0.5902, 0.5815, 0.6105,
        0.5982, 0.6059, 0.6038, 0.6116, 0.6225, 0.5846, 0.6158],
       device='cuda:0') torch.Size([16])
percent tensor([0.5781, 0.5513, 0.5943, 0.5930, 0.6268, 0.5982, 0.5720, 0.6223, 0.5419,
        0.5525, 0.5386, 0.5574, 0.5384, 0.5411, 0.5578, 0.5999],
       device='cuda:0') torch.Size([16])
percent tensor([0.9992, 0.9966, 0.9971, 0.9977, 0.9974, 0.9956, 0.9979, 0.9993, 0.9979,
        0.9976, 0.9984, 0.9980, 0.9985, 0.9984, 0.9954, 0.9989],
       device='cuda:0') torch.Size([16])
Epoch: 56 | Batch_idx: 0 |  Loss: (0.2768) |  Loss2: (0.0000) | Acc: (90.00%) (116/128)
Epoch: 56 | Batch_idx: 10 |  Loss: (0.4058) |  Loss2: (0.0000) | Acc: (87.00%) (1227/1408)
Epoch: 56 | Batch_idx: 20 |  Loss: (0.4132) |  Loss2: (0.0000) | Acc: (86.00%) (2325/2688)
Epoch: 56 | Batch_idx: 30 |  Loss: (0.3964) |  Loss2: (0.0000) | Acc: (86.00%) (3452/3968)
Epoch: 56 | Batch_idx: 40 |  Loss: (0.3935) |  Loss2: (0.0000) | Acc: (86.00%) (4559/5248)
Epoch: 56 | Batch_idx: 50 |  Loss: (0.3934) |  Loss2: (0.0000) | Acc: (86.00%) (5672/6528)
Epoch: 56 | Batch_idx: 60 |  Loss: (0.3894) |  Loss2: (0.0000) | Acc: (86.00%) (6786/7808)
Epoch: 56 | Batch_idx: 70 |  Loss: (0.3871) |  Loss2: (0.0000) | Acc: (86.00%) (7903/9088)
Epoch: 56 | Batch_idx: 80 |  Loss: (0.3831) |  Loss2: (0.0000) | Acc: (87.00%) (9027/10368)
Epoch: 56 | Batch_idx: 90 |  Loss: (0.3825) |  Loss2: (0.0000) | Acc: (87.00%) (10141/11648)
Epoch: 56 | Batch_idx: 100 |  Loss: (0.3871) |  Loss2: (0.0000) | Acc: (86.00%) (11231/12928)
Epoch: 56 | Batch_idx: 110 |  Loss: (0.3884) |  Loss2: (0.0000) | Acc: (86.00%) (12339/14208)
Epoch: 56 | Batch_idx: 120 |  Loss: (0.3913) |  Loss2: (0.0000) | Acc: (86.00%) (13422/15488)
Epoch: 56 | Batch_idx: 130 |  Loss: (0.3917) |  Loss2: (0.0000) | Acc: (86.00%) (14506/16768)
Epoch: 56 | Batch_idx: 140 |  Loss: (0.3889) |  Loss2: (0.0000) | Acc: (86.00%) (15629/18048)
Epoch: 56 | Batch_idx: 150 |  Loss: (0.3871) |  Loss2: (0.0000) | Acc: (86.00%) (16737/19328)
Epoch: 56 | Batch_idx: 160 |  Loss: (0.3863) |  Loss2: (0.0000) | Acc: (86.00%) (17858/20608)
Epoch: 56 | Batch_idx: 170 |  Loss: (0.3859) |  Loss2: (0.0000) | Acc: (86.00%) (18962/21888)
Epoch: 56 | Batch_idx: 180 |  Loss: (0.3849) |  Loss2: (0.0000) | Acc: (86.00%) (20073/23168)
Epoch: 56 | Batch_idx: 190 |  Loss: (0.3844) |  Loss2: (0.0000) | Acc: (86.00%) (21182/24448)
Epoch: 56 | Batch_idx: 200 |  Loss: (0.3829) |  Loss2: (0.0000) | Acc: (86.00%) (22303/25728)
Epoch: 56 | Batch_idx: 210 |  Loss: (0.3813) |  Loss2: (0.0000) | Acc: (86.00%) (23428/27008)
Epoch: 56 | Batch_idx: 220 |  Loss: (0.3801) |  Loss2: (0.0000) | Acc: (86.00%) (24554/28288)
Epoch: 56 | Batch_idx: 230 |  Loss: (0.3788) |  Loss2: (0.0000) | Acc: (86.00%) (25686/29568)
Epoch: 56 | Batch_idx: 240 |  Loss: (0.3789) |  Loss2: (0.0000) | Acc: (86.00%) (26789/30848)
Epoch: 56 | Batch_idx: 250 |  Loss: (0.3789) |  Loss2: (0.0000) | Acc: (86.00%) (27911/32128)
Epoch: 56 | Batch_idx: 260 |  Loss: (0.3781) |  Loss2: (0.0000) | Acc: (86.00%) (29029/33408)
Epoch: 56 | Batch_idx: 270 |  Loss: (0.3783) |  Loss2: (0.0000) | Acc: (86.00%) (30141/34688)
Epoch: 56 | Batch_idx: 280 |  Loss: (0.3763) |  Loss2: (0.0000) | Acc: (87.00%) (31293/35968)
Epoch: 56 | Batch_idx: 290 |  Loss: (0.3753) |  Loss2: (0.0000) | Acc: (87.00%) (32429/37248)
Epoch: 56 | Batch_idx: 300 |  Loss: (0.3750) |  Loss2: (0.0000) | Acc: (87.00%) (33541/38528)
Epoch: 56 | Batch_idx: 310 |  Loss: (0.3742) |  Loss2: (0.0000) | Acc: (87.00%) (34667/39808)
Epoch: 56 | Batch_idx: 320 |  Loss: (0.3750) |  Loss2: (0.0000) | Acc: (87.00%) (35781/41088)
Epoch: 56 | Batch_idx: 330 |  Loss: (0.3746) |  Loss2: (0.0000) | Acc: (87.00%) (36904/42368)
Epoch: 56 | Batch_idx: 340 |  Loss: (0.3735) |  Loss2: (0.0000) | Acc: (87.00%) (38034/43648)
Epoch: 56 | Batch_idx: 350 |  Loss: (0.3733) |  Loss2: (0.0000) | Acc: (87.00%) (39150/44928)
Epoch: 56 | Batch_idx: 360 |  Loss: (0.3728) |  Loss2: (0.0000) | Acc: (87.00%) (40275/46208)
Epoch: 56 | Batch_idx: 370 |  Loss: (0.3724) |  Loss2: (0.0000) | Acc: (87.00%) (41393/47488)
Epoch: 56 | Batch_idx: 380 |  Loss: (0.3709) |  Loss2: (0.0000) | Acc: (87.00%) (42514/48768)
Epoch: 56 | Batch_idx: 390 |  Loss: (0.3714) |  Loss2: (0.0000) | Acc: (87.00%) (43570/50000)
# TEST : Loss: (0.4504) | Acc: (84.00%) (8475/10000)
percent tensor([0.5266, 0.5304, 0.5266, 0.5269, 0.5285, 0.5273, 0.5312, 0.5305, 0.5270,
        0.5301, 0.5277, 0.5288, 0.5278, 0.5291, 0.5282, 0.5281],
       device='cuda:0') torch.Size([16])
percent tensor([0.4979, 0.4924, 0.4968, 0.5012, 0.4918, 0.5075, 0.4886, 0.4912, 0.4982,
        0.4925, 0.4984, 0.4953, 0.4995, 0.4979, 0.4974, 0.5002],
       device='cuda:0') torch.Size([16])
percent tensor([0.4814, 0.5054, 0.5445, 0.5573, 0.5558, 0.5031, 0.5363, 0.5397, 0.5374,
        0.5204, 0.5298, 0.5217, 0.4491, 0.5653, 0.5038, 0.4929],
       device='cuda:0') torch.Size([16])
percent tensor([0.5806, 0.5873, 0.5883, 0.5861, 0.5884, 0.5674, 0.5926, 0.5936, 0.5934,
        0.5906, 0.5942, 0.5967, 0.5861, 0.5943, 0.5854, 0.5825],
       device='cuda:0') torch.Size([16])
percent tensor([0.5646, 0.5718, 0.6052, 0.6323, 0.6083, 0.6336, 0.5659, 0.5791, 0.5960,
        0.6010, 0.5914, 0.6133, 0.5803, 0.6190, 0.5600, 0.5981],
       device='cuda:0') torch.Size([16])
percent tensor([0.5993, 0.6025, 0.6118, 0.6236, 0.6181, 0.6792, 0.5913, 0.5866, 0.6096,
        0.5951, 0.6029, 0.6011, 0.6092, 0.6209, 0.5859, 0.6191],
       device='cuda:0') torch.Size([16])
percent tensor([0.5946, 0.5620, 0.6079, 0.6074, 0.6421, 0.6146, 0.5880, 0.6427, 0.5527,
        0.5632, 0.5484, 0.5666, 0.5474, 0.5570, 0.5699, 0.6208],
       device='cuda:0') torch.Size([16])
percent tensor([0.9992, 0.9967, 0.9974, 0.9979, 0.9977, 0.9958, 0.9980, 0.9993, 0.9980,
        0.9977, 0.9985, 0.9982, 0.9985, 0.9985, 0.9956, 0.9989],
       device='cuda:0') torch.Size([16])
Epoch: 57 | Batch_idx: 0 |  Loss: (0.3021) |  Loss2: (0.0000) | Acc: (89.00%) (115/128)
Epoch: 57 | Batch_idx: 10 |  Loss: (0.3177) |  Loss2: (0.0000) | Acc: (89.00%) (1255/1408)
Epoch: 57 | Batch_idx: 20 |  Loss: (0.3340) |  Loss2: (0.0000) | Acc: (88.00%) (2384/2688)
Epoch: 57 | Batch_idx: 30 |  Loss: (0.3348) |  Loss2: (0.0000) | Acc: (88.00%) (3509/3968)
Epoch: 57 | Batch_idx: 40 |  Loss: (0.3419) |  Loss2: (0.0000) | Acc: (88.00%) (4631/5248)
Epoch: 57 | Batch_idx: 50 |  Loss: (0.3544) |  Loss2: (0.0000) | Acc: (87.00%) (5734/6528)
Epoch: 57 | Batch_idx: 60 |  Loss: (0.3555) |  Loss2: (0.0000) | Acc: (87.00%) (6853/7808)
Epoch: 57 | Batch_idx: 70 |  Loss: (0.3534) |  Loss2: (0.0000) | Acc: (87.00%) (7979/9088)
Epoch: 57 | Batch_idx: 80 |  Loss: (0.3552) |  Loss2: (0.0000) | Acc: (87.00%) (9096/10368)
Epoch: 57 | Batch_idx: 90 |  Loss: (0.3546) |  Loss2: (0.0000) | Acc: (87.00%) (10225/11648)
Epoch: 57 | Batch_idx: 100 |  Loss: (0.3583) |  Loss2: (0.0000) | Acc: (87.00%) (11340/12928)
Epoch: 57 | Batch_idx: 110 |  Loss: (0.3591) |  Loss2: (0.0000) | Acc: (87.00%) (12453/14208)
Epoch: 57 | Batch_idx: 120 |  Loss: (0.3573) |  Loss2: (0.0000) | Acc: (87.00%) (13576/15488)
Epoch: 57 | Batch_idx: 130 |  Loss: (0.3583) |  Loss2: (0.0000) | Acc: (87.00%) (14676/16768)
Epoch: 57 | Batch_idx: 140 |  Loss: (0.3592) |  Loss2: (0.0000) | Acc: (87.00%) (15788/18048)
Epoch: 57 | Batch_idx: 150 |  Loss: (0.3596) |  Loss2: (0.0000) | Acc: (87.00%) (16902/19328)
Epoch: 57 | Batch_idx: 160 |  Loss: (0.3608) |  Loss2: (0.0000) | Acc: (87.00%) (18014/20608)
Epoch: 57 | Batch_idx: 170 |  Loss: (0.3600) |  Loss2: (0.0000) | Acc: (87.00%) (19130/21888)
Epoch: 57 | Batch_idx: 180 |  Loss: (0.3598) |  Loss2: (0.0000) | Acc: (87.00%) (20258/23168)
Epoch: 57 | Batch_idx: 190 |  Loss: (0.3611) |  Loss2: (0.0000) | Acc: (87.00%) (21380/24448)
Epoch: 57 | Batch_idx: 200 |  Loss: (0.3609) |  Loss2: (0.0000) | Acc: (87.00%) (22503/25728)
Epoch: 57 | Batch_idx: 210 |  Loss: (0.3614) |  Loss2: (0.0000) | Acc: (87.00%) (23608/27008)
Epoch: 57 | Batch_idx: 220 |  Loss: (0.3610) |  Loss2: (0.0000) | Acc: (87.00%) (24732/28288)
Epoch: 57 | Batch_idx: 230 |  Loss: (0.3628) |  Loss2: (0.0000) | Acc: (87.00%) (25834/29568)
Epoch: 57 | Batch_idx: 240 |  Loss: (0.3624) |  Loss2: (0.0000) | Acc: (87.00%) (26956/30848)
Epoch: 57 | Batch_idx: 250 |  Loss: (0.3620) |  Loss2: (0.0000) | Acc: (87.00%) (28079/32128)
Epoch: 57 | Batch_idx: 260 |  Loss: (0.3630) |  Loss2: (0.0000) | Acc: (87.00%) (29198/33408)
Epoch: 57 | Batch_idx: 270 |  Loss: (0.3627) |  Loss2: (0.0000) | Acc: (87.00%) (30330/34688)
Epoch: 57 | Batch_idx: 280 |  Loss: (0.3634) |  Loss2: (0.0000) | Acc: (87.00%) (31436/35968)
Epoch: 57 | Batch_idx: 290 |  Loss: (0.3627) |  Loss2: (0.0000) | Acc: (87.00%) (32565/37248)
Epoch: 57 | Batch_idx: 300 |  Loss: (0.3622) |  Loss2: (0.0000) | Acc: (87.00%) (33697/38528)
Epoch: 57 | Batch_idx: 310 |  Loss: (0.3611) |  Loss2: (0.0000) | Acc: (87.00%) (34832/39808)
Epoch: 57 | Batch_idx: 320 |  Loss: (0.3609) |  Loss2: (0.0000) | Acc: (87.00%) (35964/41088)
Epoch: 57 | Batch_idx: 330 |  Loss: (0.3603) |  Loss2: (0.0000) | Acc: (87.00%) (37099/42368)
Epoch: 57 | Batch_idx: 340 |  Loss: (0.3608) |  Loss2: (0.0000) | Acc: (87.00%) (38204/43648)
Epoch: 57 | Batch_idx: 350 |  Loss: (0.3610) |  Loss2: (0.0000) | Acc: (87.00%) (39316/44928)
Epoch: 57 | Batch_idx: 360 |  Loss: (0.3602) |  Loss2: (0.0000) | Acc: (87.00%) (40435/46208)
Epoch: 57 | Batch_idx: 370 |  Loss: (0.3609) |  Loss2: (0.0000) | Acc: (87.00%) (41545/47488)
Epoch: 57 | Batch_idx: 380 |  Loss: (0.3607) |  Loss2: (0.0000) | Acc: (87.00%) (42662/48768)
Epoch: 57 | Batch_idx: 390 |  Loss: (0.3607) |  Loss2: (0.0000) | Acc: (87.00%) (43738/50000)
# TEST : Loss: (0.4393) | Acc: (85.00%) (8523/10000)
percent tensor([0.5262, 0.5299, 0.5266, 0.5269, 0.5284, 0.5272, 0.5307, 0.5302, 0.5265,
        0.5297, 0.5272, 0.5286, 0.5273, 0.5285, 0.5278, 0.5278],
       device='cuda:0') torch.Size([16])
percent tensor([0.4994, 0.4947, 0.4989, 0.5034, 0.4943, 0.5093, 0.4906, 0.4934, 0.5003,
        0.4948, 0.5004, 0.4976, 0.5015, 0.5003, 0.4997, 0.5023],
       device='cuda:0') torch.Size([16])
percent tensor([0.4760, 0.5029, 0.5436, 0.5563, 0.5532, 0.4952, 0.5328, 0.5361, 0.5346,
        0.5203, 0.5285, 0.5210, 0.4453, 0.5636, 0.4976, 0.4893],
       device='cuda:0') torch.Size([16])
percent tensor([0.5820, 0.5897, 0.5920, 0.5896, 0.5923, 0.5680, 0.5957, 0.5973, 0.5964,
        0.5929, 0.5967, 0.6000, 0.5871, 0.5971, 0.5878, 0.5838],
       device='cuda:0') torch.Size([16])
percent tensor([0.5600, 0.5720, 0.6030, 0.6290, 0.6049, 0.6302, 0.5619, 0.5732, 0.5941,
        0.6020, 0.5923, 0.6116, 0.5792, 0.6170, 0.5543, 0.5958],
       device='cuda:0') torch.Size([16])
percent tensor([0.6011, 0.6008, 0.6140, 0.6268, 0.6215, 0.6837, 0.5917, 0.5905, 0.6097,
        0.5929, 0.6018, 0.5994, 0.6083, 0.6197, 0.5862, 0.6219],
       device='cuda:0') torch.Size([16])
percent tensor([0.6029, 0.5657, 0.6158, 0.6152, 0.6514, 0.6199, 0.5969, 0.6568, 0.5571,
        0.5671, 0.5506, 0.5704, 0.5492, 0.5624, 0.5756, 0.6316],
       device='cuda:0') torch.Size([16])
percent tensor([0.9993, 0.9970, 0.9977, 0.9981, 0.9980, 0.9963, 0.9983, 0.9993, 0.9980,
        0.9979, 0.9986, 0.9984, 0.9986, 0.9987, 0.9958, 0.9991],
       device='cuda:0') torch.Size([16])
Epoch: 58 | Batch_idx: 0 |  Loss: (0.3219) |  Loss2: (0.0000) | Acc: (89.00%) (115/128)
Epoch: 58 | Batch_idx: 10 |  Loss: (0.3627) |  Loss2: (0.0000) | Acc: (87.00%) (1229/1408)
Epoch: 58 | Batch_idx: 20 |  Loss: (0.3659) |  Loss2: (0.0000) | Acc: (87.00%) (2347/2688)
Epoch: 58 | Batch_idx: 30 |  Loss: (0.3645) |  Loss2: (0.0000) | Acc: (87.00%) (3460/3968)
Epoch: 58 | Batch_idx: 40 |  Loss: (0.3567) |  Loss2: (0.0000) | Acc: (87.00%) (4592/5248)
Epoch: 58 | Batch_idx: 50 |  Loss: (0.3522) |  Loss2: (0.0000) | Acc: (87.00%) (5728/6528)
Epoch: 58 | Batch_idx: 60 |  Loss: (0.3542) |  Loss2: (0.0000) | Acc: (87.00%) (6851/7808)
Epoch: 58 | Batch_idx: 70 |  Loss: (0.3529) |  Loss2: (0.0000) | Acc: (87.00%) (7973/9088)
Epoch: 58 | Batch_idx: 80 |  Loss: (0.3559) |  Loss2: (0.0000) | Acc: (87.00%) (9085/10368)
Epoch: 58 | Batch_idx: 90 |  Loss: (0.3562) |  Loss2: (0.0000) | Acc: (87.00%) (10209/11648)
Epoch: 58 | Batch_idx: 100 |  Loss: (0.3514) |  Loss2: (0.0000) | Acc: (87.00%) (11354/12928)
Epoch: 58 | Batch_idx: 110 |  Loss: (0.3512) |  Loss2: (0.0000) | Acc: (87.00%) (12470/14208)
Epoch: 58 | Batch_idx: 120 |  Loss: (0.3514) |  Loss2: (0.0000) | Acc: (87.00%) (13592/15488)
Epoch: 58 | Batch_idx: 130 |  Loss: (0.3519) |  Loss2: (0.0000) | Acc: (87.00%) (14713/16768)
Epoch: 58 | Batch_idx: 140 |  Loss: (0.3539) |  Loss2: (0.0000) | Acc: (87.00%) (15844/18048)
Epoch: 58 | Batch_idx: 150 |  Loss: (0.3519) |  Loss2: (0.0000) | Acc: (87.00%) (16976/19328)
Epoch: 58 | Batch_idx: 160 |  Loss: (0.3508) |  Loss2: (0.0000) | Acc: (87.00%) (18102/20608)
Epoch: 58 | Batch_idx: 170 |  Loss: (0.3504) |  Loss2: (0.0000) | Acc: (87.00%) (19239/21888)
Epoch: 58 | Batch_idx: 180 |  Loss: (0.3499) |  Loss2: (0.0000) | Acc: (87.00%) (20366/23168)
Epoch: 58 | Batch_idx: 190 |  Loss: (0.3508) |  Loss2: (0.0000) | Acc: (87.00%) (21480/24448)
Epoch: 58 | Batch_idx: 200 |  Loss: (0.3508) |  Loss2: (0.0000) | Acc: (87.00%) (22598/25728)
Epoch: 58 | Batch_idx: 210 |  Loss: (0.3526) |  Loss2: (0.0000) | Acc: (87.00%) (23710/27008)
Epoch: 58 | Batch_idx: 220 |  Loss: (0.3521) |  Loss2: (0.0000) | Acc: (87.00%) (24839/28288)
Epoch: 58 | Batch_idx: 230 |  Loss: (0.3518) |  Loss2: (0.0000) | Acc: (87.00%) (25968/29568)
Epoch: 58 | Batch_idx: 240 |  Loss: (0.3533) |  Loss2: (0.0000) | Acc: (87.00%) (27079/30848)
Epoch: 58 | Batch_idx: 250 |  Loss: (0.3547) |  Loss2: (0.0000) | Acc: (87.00%) (28191/32128)
Epoch: 58 | Batch_idx: 260 |  Loss: (0.3552) |  Loss2: (0.0000) | Acc: (87.00%) (29307/33408)
Epoch: 58 | Batch_idx: 270 |  Loss: (0.3557) |  Loss2: (0.0000) | Acc: (87.00%) (30423/34688)
Epoch: 58 | Batch_idx: 280 |  Loss: (0.3567) |  Loss2: (0.0000) | Acc: (87.00%) (31522/35968)
Epoch: 58 | Batch_idx: 290 |  Loss: (0.3568) |  Loss2: (0.0000) | Acc: (87.00%) (32634/37248)
Epoch: 58 | Batch_idx: 300 |  Loss: (0.3566) |  Loss2: (0.0000) | Acc: (87.00%) (33760/38528)
Epoch: 58 | Batch_idx: 310 |  Loss: (0.3575) |  Loss2: (0.0000) | Acc: (87.00%) (34869/39808)
Epoch: 58 | Batch_idx: 320 |  Loss: (0.3565) |  Loss2: (0.0000) | Acc: (87.00%) (36003/41088)
Epoch: 58 | Batch_idx: 330 |  Loss: (0.3574) |  Loss2: (0.0000) | Acc: (87.00%) (37121/42368)
Epoch: 58 | Batch_idx: 340 |  Loss: (0.3574) |  Loss2: (0.0000) | Acc: (87.00%) (38244/43648)
Epoch: 58 | Batch_idx: 350 |  Loss: (0.3575) |  Loss2: (0.0000) | Acc: (87.00%) (39372/44928)
Epoch: 58 | Batch_idx: 360 |  Loss: (0.3572) |  Loss2: (0.0000) | Acc: (87.00%) (40518/46208)
Epoch: 58 | Batch_idx: 370 |  Loss: (0.3571) |  Loss2: (0.0000) | Acc: (87.00%) (41652/47488)
Epoch: 58 | Batch_idx: 380 |  Loss: (0.3571) |  Loss2: (0.0000) | Acc: (87.00%) (42775/48768)
Epoch: 58 | Batch_idx: 390 |  Loss: (0.3567) |  Loss2: (0.0000) | Acc: (87.00%) (43871/50000)
# TEST : Loss: (0.4379) | Acc: (85.00%) (8520/10000)
percent tensor([0.5269, 0.5304, 0.5274, 0.5279, 0.5292, 0.5285, 0.5313, 0.5309, 0.5270,
        0.5303, 0.5278, 0.5293, 0.5278, 0.5290, 0.5287, 0.5286],
       device='cuda:0') torch.Size([16])
percent tensor([0.5017, 0.4984, 0.5023, 0.5066, 0.4983, 0.5119, 0.4943, 0.4972, 0.5037,
        0.4984, 0.5035, 0.5013, 0.5042, 0.5035, 0.5034, 0.5053],
       device='cuda:0') torch.Size([16])
percent tensor([0.4704, 0.4975, 0.5404, 0.5524, 0.5489, 0.4882, 0.5269, 0.5318, 0.5295,
        0.5156, 0.5226, 0.5149, 0.4392, 0.5597, 0.4911, 0.4829],
       device='cuda:0') torch.Size([16])
percent tensor([0.5858, 0.5945, 0.5970, 0.5940, 0.5971, 0.5708, 0.6007, 0.6027, 0.6014,
        0.5972, 0.6010, 0.6050, 0.5911, 0.6017, 0.5926, 0.5872],
       device='cuda:0') torch.Size([16])
percent tensor([0.5589, 0.5725, 0.6029, 0.6288, 0.6044, 0.6332, 0.5602, 0.5716, 0.5922,
        0.6016, 0.5910, 0.6119, 0.5792, 0.6155, 0.5550, 0.5958],
       device='cuda:0') torch.Size([16])
percent tensor([0.6013, 0.5986, 0.6151, 0.6278, 0.6234, 0.6891, 0.5898, 0.5909, 0.6075,
        0.5899, 0.5983, 0.5962, 0.6063, 0.6169, 0.5853, 0.6233],
       device='cuda:0') torch.Size([16])
percent tensor([0.6066, 0.5658, 0.6177, 0.6161, 0.6541, 0.6250, 0.5984, 0.6606, 0.5567,
        0.5672, 0.5494, 0.5677, 0.5473, 0.5618, 0.5762, 0.6371],
       device='cuda:0') torch.Size([16])
percent tensor([0.9993, 0.9973, 0.9978, 0.9983, 0.9982, 0.9967, 0.9984, 0.9993, 0.9983,
        0.9981, 0.9987, 0.9984, 0.9987, 0.9988, 0.9961, 0.9991],
       device='cuda:0') torch.Size([16])
Epoch: 59 | Batch_idx: 0 |  Loss: (0.4262) |  Loss2: (0.0000) | Acc: (84.00%) (108/128)
Epoch: 59 | Batch_idx: 10 |  Loss: (0.3592) |  Loss2: (0.0000) | Acc: (88.00%) (1251/1408)
Epoch: 59 | Batch_idx: 20 |  Loss: (0.3738) |  Loss2: (0.0000) | Acc: (87.00%) (2358/2688)
Epoch: 59 | Batch_idx: 30 |  Loss: (0.3723) |  Loss2: (0.0000) | Acc: (87.00%) (3477/3968)
Epoch: 59 | Batch_idx: 40 |  Loss: (0.3601) |  Loss2: (0.0000) | Acc: (88.00%) (4619/5248)
Epoch: 59 | Batch_idx: 50 |  Loss: (0.3569) |  Loss2: (0.0000) | Acc: (87.00%) (5743/6528)
Epoch: 59 | Batch_idx: 60 |  Loss: (0.3623) |  Loss2: (0.0000) | Acc: (87.00%) (6856/7808)
Epoch: 59 | Batch_idx: 70 |  Loss: (0.3624) |  Loss2: (0.0000) | Acc: (87.00%) (7972/9088)
Epoch: 59 | Batch_idx: 80 |  Loss: (0.3628) |  Loss2: (0.0000) | Acc: (87.00%) (9082/10368)
Epoch: 59 | Batch_idx: 90 |  Loss: (0.3616) |  Loss2: (0.0000) | Acc: (87.00%) (10195/11648)
Epoch: 59 | Batch_idx: 100 |  Loss: (0.3580) |  Loss2: (0.0000) | Acc: (87.00%) (11326/12928)
Epoch: 59 | Batch_idx: 110 |  Loss: (0.3552) |  Loss2: (0.0000) | Acc: (87.00%) (12461/14208)
Epoch: 59 | Batch_idx: 120 |  Loss: (0.3567) |  Loss2: (0.0000) | Acc: (87.00%) (13585/15488)
Epoch: 59 | Batch_idx: 130 |  Loss: (0.3562) |  Loss2: (0.0000) | Acc: (87.00%) (14705/16768)
Epoch: 59 | Batch_idx: 140 |  Loss: (0.3564) |  Loss2: (0.0000) | Acc: (87.00%) (15835/18048)
Epoch: 59 | Batch_idx: 150 |  Loss: (0.3566) |  Loss2: (0.0000) | Acc: (87.00%) (16956/19328)
Epoch: 59 | Batch_idx: 160 |  Loss: (0.3572) |  Loss2: (0.0000) | Acc: (87.00%) (18072/20608)
Epoch: 59 | Batch_idx: 170 |  Loss: (0.3574) |  Loss2: (0.0000) | Acc: (87.00%) (19187/21888)
Epoch: 59 | Batch_idx: 180 |  Loss: (0.3581) |  Loss2: (0.0000) | Acc: (87.00%) (20308/23168)
Epoch: 59 | Batch_idx: 190 |  Loss: (0.3571) |  Loss2: (0.0000) | Acc: (87.00%) (21436/24448)
Epoch: 59 | Batch_idx: 200 |  Loss: (0.3565) |  Loss2: (0.0000) | Acc: (87.00%) (22564/25728)
Epoch: 59 | Batch_idx: 210 |  Loss: (0.3563) |  Loss2: (0.0000) | Acc: (87.00%) (23699/27008)
Epoch: 59 | Batch_idx: 220 |  Loss: (0.3555) |  Loss2: (0.0000) | Acc: (87.00%) (24829/28288)
Epoch: 59 | Batch_idx: 230 |  Loss: (0.3538) |  Loss2: (0.0000) | Acc: (87.00%) (25978/29568)
Epoch: 59 | Batch_idx: 240 |  Loss: (0.3538) |  Loss2: (0.0000) | Acc: (87.00%) (27103/30848)
Epoch: 59 | Batch_idx: 250 |  Loss: (0.3539) |  Loss2: (0.0000) | Acc: (87.00%) (28226/32128)
Epoch: 59 | Batch_idx: 260 |  Loss: (0.3531) |  Loss2: (0.0000) | Acc: (87.00%) (29356/33408)
Epoch: 59 | Batch_idx: 270 |  Loss: (0.3525) |  Loss2: (0.0000) | Acc: (87.00%) (30489/34688)
Epoch: 59 | Batch_idx: 280 |  Loss: (0.3516) |  Loss2: (0.0000) | Acc: (87.00%) (31627/35968)
Epoch: 59 | Batch_idx: 290 |  Loss: (0.3522) |  Loss2: (0.0000) | Acc: (87.00%) (32739/37248)
Epoch: 59 | Batch_idx: 300 |  Loss: (0.3531) |  Loss2: (0.0000) | Acc: (87.00%) (33858/38528)
Epoch: 59 | Batch_idx: 310 |  Loss: (0.3532) |  Loss2: (0.0000) | Acc: (87.00%) (34980/39808)
Epoch: 59 | Batch_idx: 320 |  Loss: (0.3524) |  Loss2: (0.0000) | Acc: (87.00%) (36106/41088)
Epoch: 59 | Batch_idx: 330 |  Loss: (0.3526) |  Loss2: (0.0000) | Acc: (87.00%) (37233/42368)
Epoch: 59 | Batch_idx: 340 |  Loss: (0.3523) |  Loss2: (0.0000) | Acc: (87.00%) (38374/43648)
Epoch: 59 | Batch_idx: 350 |  Loss: (0.3526) |  Loss2: (0.0000) | Acc: (87.00%) (39492/44928)
Epoch: 59 | Batch_idx: 360 |  Loss: (0.3521) |  Loss2: (0.0000) | Acc: (87.00%) (40621/46208)
Epoch: 59 | Batch_idx: 370 |  Loss: (0.3531) |  Loss2: (0.0000) | Acc: (87.00%) (41738/47488)
Epoch: 59 | Batch_idx: 380 |  Loss: (0.3531) |  Loss2: (0.0000) | Acc: (87.00%) (42860/48768)
Epoch: 59 | Batch_idx: 390 |  Loss: (0.3524) |  Loss2: (0.0000) | Acc: (87.00%) (43957/50000)
# TEST : Loss: (0.4307) | Acc: (85.00%) (8535/10000)
percent tensor([0.5281, 0.5317, 0.5288, 0.5293, 0.5306, 0.5301, 0.5326, 0.5323, 0.5281,
        0.5316, 0.5289, 0.5306, 0.5290, 0.5301, 0.5301, 0.5298],
       device='cuda:0') torch.Size([16])
percent tensor([0.5030, 0.4999, 0.5040, 0.5084, 0.4999, 0.5135, 0.4955, 0.4986, 0.5051,
        0.4999, 0.5047, 0.5027, 0.5058, 0.5048, 0.5048, 0.5070],
       device='cuda:0') torch.Size([16])
percent tensor([0.4798, 0.5044, 0.5475, 0.5584, 0.5540, 0.4944, 0.5346, 0.5411, 0.5385,
        0.5244, 0.5306, 0.5240, 0.4471, 0.5690, 0.4983, 0.4908],
       device='cuda:0') torch.Size([16])
percent tensor([0.5893, 0.5984, 0.6011, 0.5974, 0.6011, 0.5735, 0.6048, 0.6072, 0.6057,
        0.6011, 0.6048, 0.6093, 0.5946, 0.6054, 0.5966, 0.5901],
       device='cuda:0') torch.Size([16])
percent tensor([0.5556, 0.5712, 0.6011, 0.6274, 0.6033, 0.6340, 0.5574, 0.5682, 0.5893,
        0.5994, 0.5877, 0.6091, 0.5772, 0.6138, 0.5522, 0.5952],
       device='cuda:0') torch.Size([16])
percent tensor([0.5994, 0.5958, 0.6130, 0.6271, 0.6217, 0.6911, 0.5876, 0.5880, 0.6043,
        0.5862, 0.5950, 0.5924, 0.6035, 0.6144, 0.5833, 0.6232],
       device='cuda:0') torch.Size([16])
percent tensor([0.6128, 0.5691, 0.6197, 0.6187, 0.6554, 0.6317, 0.6038, 0.6641, 0.5592,
        0.5704, 0.5522, 0.5679, 0.5500, 0.5671, 0.5792, 0.6448],
       device='cuda:0') torch.Size([16])
percent tensor([0.9995, 0.9974, 0.9980, 0.9985, 0.9982, 0.9971, 0.9985, 0.9993, 0.9984,
        0.9982, 0.9988, 0.9985, 0.9988, 0.9989, 0.9963, 0.9993],
       device='cuda:0') torch.Size([16])
True Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=128, out_features=16, bias=False)
False Linear(in_features=16, out_features=2, bias=False)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=128, out_features=16, bias=False)
False Linear(in_features=16, out_features=2, bias=False)
True Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=256, out_features=32, bias=False)
False Linear(in_features=32, out_features=2, bias=False)
True Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=256, out_features=32, bias=False)
False Linear(in_features=32, out_features=2, bias=False)
True Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=512, out_features=64, bias=False)
False Linear(in_features=64, out_features=2, bias=False)
True Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=512, out_features=64, bias=False)
False Linear(in_features=64, out_features=2, bias=False)
True Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1024, out_features=128, bias=False)
False Linear(in_features=128, out_features=2, bias=False)
True Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1024, out_features=128, bias=False)
False Linear(in_features=128, out_features=2, bias=False)
True Linear(in_features=512, out_features=10, bias=True)
Epoch: 60 | Batch_idx: 0 |  Loss: (0.2563) |  Loss2: (0.0000) | Acc: (90.00%) (116/128)
Epoch: 60 | Batch_idx: 10 |  Loss: (0.3382) |  Loss2: (0.0000) | Acc: (88.00%) (1252/1408)
Epoch: 60 | Batch_idx: 20 |  Loss: (0.3535) |  Loss2: (0.0000) | Acc: (88.00%) (2376/2688)
Epoch: 60 | Batch_idx: 30 |  Loss: (0.3507) |  Loss2: (0.0000) | Acc: (87.00%) (3487/3968)
Epoch: 60 | Batch_idx: 40 |  Loss: (0.3574) |  Loss2: (0.0000) | Acc: (87.00%) (4600/5248)
Epoch: 60 | Batch_idx: 50 |  Loss: (0.3588) |  Loss2: (0.0000) | Acc: (87.00%) (5710/6528)
Epoch: 60 | Batch_idx: 60 |  Loss: (0.3567) |  Loss2: (0.0000) | Acc: (87.00%) (6826/7808)
Epoch: 60 | Batch_idx: 70 |  Loss: (0.3552) |  Loss2: (0.0000) | Acc: (87.00%) (7954/9088)
Epoch: 60 | Batch_idx: 80 |  Loss: (0.3519) |  Loss2: (0.0000) | Acc: (87.00%) (9097/10368)
Epoch: 60 | Batch_idx: 90 |  Loss: (0.3546) |  Loss2: (0.0000) | Acc: (87.00%) (10212/11648)
Epoch: 60 | Batch_idx: 100 |  Loss: (0.3567) |  Loss2: (0.0000) | Acc: (87.00%) (11331/12928)
Epoch: 60 | Batch_idx: 110 |  Loss: (0.3572) |  Loss2: (0.0000) | Acc: (87.00%) (12459/14208)
Epoch: 60 | Batch_idx: 120 |  Loss: (0.3597) |  Loss2: (0.0000) | Acc: (87.00%) (13568/15488)
Epoch: 60 | Batch_idx: 130 |  Loss: (0.3629) |  Loss2: (0.0000) | Acc: (87.00%) (14686/16768)
Epoch: 60 | Batch_idx: 140 |  Loss: (0.3649) |  Loss2: (0.0000) | Acc: (87.00%) (15797/18048)
Epoch: 60 | Batch_idx: 150 |  Loss: (0.3649) |  Loss2: (0.0000) | Acc: (87.00%) (16913/19328)
Epoch: 60 | Batch_idx: 160 |  Loss: (0.3642) |  Loss2: (0.0000) | Acc: (87.00%) (18042/20608)
Epoch: 60 | Batch_idx: 170 |  Loss: (0.3644) |  Loss2: (0.0000) | Acc: (87.00%) (19153/21888)
Epoch: 60 | Batch_idx: 180 |  Loss: (0.3635) |  Loss2: (0.0000) | Acc: (87.00%) (20272/23168)
Epoch: 60 | Batch_idx: 190 |  Loss: (0.3642) |  Loss2: (0.0000) | Acc: (87.00%) (21392/24448)
Epoch: 60 | Batch_idx: 200 |  Loss: (0.3642) |  Loss2: (0.0000) | Acc: (87.00%) (22510/25728)
Epoch: 60 | Batch_idx: 210 |  Loss: (0.3639) |  Loss2: (0.0000) | Acc: (87.00%) (23631/27008)
Epoch: 60 | Batch_idx: 220 |  Loss: (0.3648) |  Loss2: (0.0000) | Acc: (87.00%) (24738/28288)
Epoch: 60 | Batch_idx: 230 |  Loss: (0.3666) |  Loss2: (0.0000) | Acc: (87.00%) (25839/29568)
Epoch: 60 | Batch_idx: 240 |  Loss: (0.3662) |  Loss2: (0.0000) | Acc: (87.00%) (26969/30848)
Epoch: 60 | Batch_idx: 250 |  Loss: (0.3661) |  Loss2: (0.0000) | Acc: (87.00%) (28100/32128)
Epoch: 60 | Batch_idx: 260 |  Loss: (0.3664) |  Loss2: (0.0000) | Acc: (87.00%) (29214/33408)
Epoch: 60 | Batch_idx: 270 |  Loss: (0.3674) |  Loss2: (0.0000) | Acc: (87.00%) (30317/34688)
Epoch: 60 | Batch_idx: 280 |  Loss: (0.3678) |  Loss2: (0.0000) | Acc: (87.00%) (31429/35968)
Epoch: 60 | Batch_idx: 290 |  Loss: (0.3678) |  Loss2: (0.0000) | Acc: (87.00%) (32541/37248)
Epoch: 60 | Batch_idx: 300 |  Loss: (0.3671) |  Loss2: (0.0000) | Acc: (87.00%) (33673/38528)
Epoch: 60 | Batch_idx: 310 |  Loss: (0.3661) |  Loss2: (0.0000) | Acc: (87.00%) (34805/39808)
Epoch: 60 | Batch_idx: 320 |  Loss: (0.3661) |  Loss2: (0.0000) | Acc: (87.00%) (35930/41088)
Epoch: 60 | Batch_idx: 330 |  Loss: (0.3675) |  Loss2: (0.0000) | Acc: (87.00%) (37014/42368)
Epoch: 60 | Batch_idx: 340 |  Loss: (0.3676) |  Loss2: (0.0000) | Acc: (87.00%) (38132/43648)
Epoch: 60 | Batch_idx: 350 |  Loss: (0.3678) |  Loss2: (0.0000) | Acc: (87.00%) (39253/44928)
Epoch: 60 | Batch_idx: 360 |  Loss: (0.3681) |  Loss2: (0.0000) | Acc: (87.00%) (40360/46208)
Epoch: 60 | Batch_idx: 370 |  Loss: (0.3681) |  Loss2: (0.0000) | Acc: (87.00%) (41484/47488)
Epoch: 60 | Batch_idx: 380 |  Loss: (0.3681) |  Loss2: (0.0000) | Acc: (87.00%) (42595/48768)
Epoch: 60 | Batch_idx: 390 |  Loss: (0.3689) |  Loss2: (0.0000) | Acc: (87.00%) (43660/50000)
=> saving checkpoint 'drive/app/torch/save_Schedule/checkpoint_060.pth.tar'
# TEST : Loss: (0.4576) | Acc: (84.00%) (8477/10000)
percent tensor([0.5286, 0.5328, 0.5289, 0.5296, 0.5304, 0.5300, 0.5335, 0.5326, 0.5289,
        0.5321, 0.5295, 0.5307, 0.5293, 0.5320, 0.5304, 0.5305],
       device='cuda:0') torch.Size([16])
percent tensor([0.5035, 0.4991, 0.5053, 0.5094, 0.5020, 0.5134, 0.4961, 0.4986, 0.5037,
        0.4998, 0.5039, 0.5035, 0.5054, 0.5037, 0.5050, 0.5069],
       device='cuda:0') torch.Size([16])
percent tensor([0.4861, 0.5180, 0.5416, 0.5611, 0.5501, 0.5053, 0.5375, 0.5432, 0.5293,
        0.5347, 0.5413, 0.5210, 0.4478, 0.5811, 0.5173, 0.5026],
       device='cuda:0') torch.Size([16])
percent tensor([0.5921, 0.6014, 0.5976, 0.5990, 0.6029, 0.5784, 0.6077, 0.6067, 0.6057,
        0.6016, 0.6071, 0.6101, 0.5961, 0.6040, 0.6030, 0.5917],
       device='cuda:0') torch.Size([16])
percent tensor([0.5586, 0.5752, 0.6005, 0.6337, 0.6092, 0.6335, 0.5598, 0.5791, 0.6005,
        0.5959, 0.5894, 0.6111, 0.5743, 0.6295, 0.5606, 0.6055],
       device='cuda:0') torch.Size([16])
percent tensor([0.5981, 0.5905, 0.6174, 0.6265, 0.6236, 0.6818, 0.5912, 0.5954, 0.6150,
        0.5853, 0.6017, 0.5951, 0.6014, 0.6245, 0.5808, 0.6252],
       device='cuda:0') torch.Size([16])
percent tensor([0.6225, 0.5803, 0.6247, 0.6159, 0.6493, 0.6511, 0.6046, 0.6612, 0.5673,
        0.5774, 0.5617, 0.5717, 0.5617, 0.5738, 0.5788, 0.6517],
       device='cuda:0') torch.Size([16])
percent tensor([0.9996, 0.9980, 0.9975, 0.9980, 0.9974, 0.9979, 0.9990, 0.9992, 0.9978,
        0.9986, 0.9992, 0.9982, 0.9987, 0.9993, 0.9964, 0.9994],
       device='cuda:0') torch.Size([16])
Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 3, 3, 3]) tensor(173.0232, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(805.4194, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(795.6913, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([128, 64, 3, 3]) tensor(1522.7551, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([128, 64, 1, 1]) tensor(501.4746, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([128, 128, 3, 3]) tensor(2209.5015, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([256, 128, 3, 3]) tensor(4287.8931, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([256, 128, 1, 1]) tensor(1415.4730, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([256, 256, 3, 3]) tensor(6109.3735, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([512, 256, 3, 3]) tensor(12003.0332, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([512, 256, 1, 1]) tensor(3994.6882, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([512, 512, 3, 3]) tensor(16917.2461, device='cuda:0', grad_fn=<NormBackward0>)
Epoch: 61 | Batch_idx: 0 |  Loss: (0.4223) |  Loss2: (0.0000) | Acc: (84.00%) (108/128)
Epoch: 61 | Batch_idx: 10 |  Loss: (0.3637) |  Loss2: (0.0000) | Acc: (86.00%) (1222/1408)
Epoch: 61 | Batch_idx: 20 |  Loss: (0.3563) |  Loss2: (0.0000) | Acc: (87.00%) (2354/2688)
Epoch: 61 | Batch_idx: 30 |  Loss: (0.3549) |  Loss2: (0.0000) | Acc: (87.00%) (3481/3968)
Epoch: 61 | Batch_idx: 40 |  Loss: (0.3603) |  Loss2: (0.0000) | Acc: (87.00%) (4600/5248)
Epoch: 61 | Batch_idx: 50 |  Loss: (0.3578) |  Loss2: (0.0000) | Acc: (87.00%) (5724/6528)
Epoch: 61 | Batch_idx: 60 |  Loss: (0.3570) |  Loss2: (0.0000) | Acc: (87.00%) (6854/7808)
Epoch: 61 | Batch_idx: 70 |  Loss: (0.3543) |  Loss2: (0.0000) | Acc: (87.00%) (7973/9088)
Epoch: 61 | Batch_idx: 80 |  Loss: (0.3548) |  Loss2: (0.0000) | Acc: (87.00%) (9090/10368)
Epoch: 61 | Batch_idx: 90 |  Loss: (0.3524) |  Loss2: (0.0000) | Acc: (87.00%) (10218/11648)
Epoch: 61 | Batch_idx: 100 |  Loss: (0.3541) |  Loss2: (0.0000) | Acc: (87.00%) (11337/12928)
Epoch: 61 | Batch_idx: 110 |  Loss: (0.3554) |  Loss2: (0.0000) | Acc: (87.00%) (12449/14208)
Epoch: 61 | Batch_idx: 120 |  Loss: (0.3560) |  Loss2: (0.0000) | Acc: (87.00%) (13567/15488)
Epoch: 61 | Batch_idx: 130 |  Loss: (0.3548) |  Loss2: (0.0000) | Acc: (87.00%) (14705/16768)
Epoch: 61 | Batch_idx: 140 |  Loss: (0.3534) |  Loss2: (0.0000) | Acc: (87.00%) (15835/18048)
Epoch: 61 | Batch_idx: 150 |  Loss: (0.3533) |  Loss2: (0.0000) | Acc: (87.00%) (16965/19328)
Epoch: 61 | Batch_idx: 160 |  Loss: (0.3538) |  Loss2: (0.0000) | Acc: (87.00%) (18088/20608)
Epoch: 61 | Batch_idx: 170 |  Loss: (0.3541) |  Loss2: (0.0000) | Acc: (87.00%) (19207/21888)
Epoch: 61 | Batch_idx: 180 |  Loss: (0.3544) |  Loss2: (0.0000) | Acc: (87.00%) (20327/23168)
Epoch: 61 | Batch_idx: 190 |  Loss: (0.3529) |  Loss2: (0.0000) | Acc: (87.00%) (21465/24448)
Epoch: 61 | Batch_idx: 200 |  Loss: (0.3536) |  Loss2: (0.0000) | Acc: (87.00%) (22574/25728)
Epoch: 61 | Batch_idx: 210 |  Loss: (0.3549) |  Loss2: (0.0000) | Acc: (87.00%) (23681/27008)
Epoch: 61 | Batch_idx: 220 |  Loss: (0.3547) |  Loss2: (0.0000) | Acc: (87.00%) (24806/28288)
Epoch: 61 | Batch_idx: 230 |  Loss: (0.3544) |  Loss2: (0.0000) | Acc: (87.00%) (25924/29568)
Epoch: 61 | Batch_idx: 240 |  Loss: (0.3555) |  Loss2: (0.0000) | Acc: (87.00%) (27026/30848)
Epoch: 61 | Batch_idx: 250 |  Loss: (0.3554) |  Loss2: (0.0000) | Acc: (87.00%) (28155/32128)
Epoch: 61 | Batch_idx: 260 |  Loss: (0.3544) |  Loss2: (0.0000) | Acc: (87.00%) (29290/33408)
Epoch: 61 | Batch_idx: 270 |  Loss: (0.3561) |  Loss2: (0.0000) | Acc: (87.00%) (30405/34688)
Epoch: 61 | Batch_idx: 280 |  Loss: (0.3568) |  Loss2: (0.0000) | Acc: (87.00%) (31521/35968)
Epoch: 61 | Batch_idx: 290 |  Loss: (0.3578) |  Loss2: (0.0000) | Acc: (87.00%) (32629/37248)
Epoch: 61 | Batch_idx: 300 |  Loss: (0.3563) |  Loss2: (0.0000) | Acc: (87.00%) (33775/38528)
Epoch: 61 | Batch_idx: 310 |  Loss: (0.3565) |  Loss2: (0.0000) | Acc: (87.00%) (34881/39808)
Epoch: 61 | Batch_idx: 320 |  Loss: (0.3558) |  Loss2: (0.0000) | Acc: (87.00%) (36009/41088)
Epoch: 61 | Batch_idx: 330 |  Loss: (0.3570) |  Loss2: (0.0000) | Acc: (87.00%) (37108/42368)
Epoch: 61 | Batch_idx: 340 |  Loss: (0.3584) |  Loss2: (0.0000) | Acc: (87.00%) (38209/43648)
Epoch: 61 | Batch_idx: 350 |  Loss: (0.3585) |  Loss2: (0.0000) | Acc: (87.00%) (39327/44928)
Epoch: 61 | Batch_idx: 360 |  Loss: (0.3584) |  Loss2: (0.0000) | Acc: (87.00%) (40458/46208)
Epoch: 61 | Batch_idx: 370 |  Loss: (0.3574) |  Loss2: (0.0000) | Acc: (87.00%) (41598/47488)
Epoch: 61 | Batch_idx: 380 |  Loss: (0.3576) |  Loss2: (0.0000) | Acc: (87.00%) (42716/48768)
Epoch: 61 | Batch_idx: 390 |  Loss: (0.3574) |  Loss2: (0.0000) | Acc: (87.00%) (43795/50000)
# TEST : Loss: (0.5151) | Acc: (82.00%) (8297/10000)
percent tensor([0.5285, 0.5316, 0.5286, 0.5289, 0.5301, 0.5292, 0.5326, 0.5320, 0.5287,
        0.5314, 0.5293, 0.5307, 0.5290, 0.5303, 0.5296, 0.5296],
       device='cuda:0') torch.Size([16])
percent tensor([0.5046, 0.4996, 0.5058, 0.5104, 0.5029, 0.5131, 0.4973, 0.4992, 0.5052,
        0.4994, 0.5044, 0.5039, 0.5063, 0.5043, 0.5060, 0.5088],
       device='cuda:0') torch.Size([16])
percent tensor([0.4972, 0.5137, 0.5497, 0.5642, 0.5564, 0.4836, 0.5430, 0.5471, 0.5465,
        0.5408, 0.5437, 0.5334, 0.4568, 0.5808, 0.5068, 0.5063],
       device='cuda:0') torch.Size([16])
percent tensor([0.5947, 0.5995, 0.6029, 0.5995, 0.6052, 0.5769, 0.6061, 0.6078, 0.6070,
        0.6020, 0.6068, 0.6133, 0.5991, 0.6038, 0.6007, 0.5929],
       device='cuda:0') torch.Size([16])
percent tensor([0.5625, 0.5720, 0.5996, 0.6355, 0.6119, 0.6351, 0.5595, 0.5758, 0.6011,
        0.5904, 0.5895, 0.6169, 0.5782, 0.6322, 0.5563, 0.6082],
       device='cuda:0') torch.Size([16])
percent tensor([0.5905, 0.5893, 0.6080, 0.6254, 0.6215, 0.6800, 0.5883, 0.5894, 0.6125,
        0.5761, 0.6011, 0.5930, 0.6014, 0.6245, 0.5767, 0.6230],
       device='cuda:0') torch.Size([16])
percent tensor([0.6065, 0.5750, 0.6190, 0.6160, 0.6530, 0.6333, 0.6028, 0.6550, 0.5654,
        0.5775, 0.5590, 0.5765, 0.5531, 0.5682, 0.5694, 0.6364],
       device='cuda:0') torch.Size([16])
percent tensor([0.9995, 0.9982, 0.9977, 0.9991, 0.9986, 0.9979, 0.9988, 0.9990, 0.9987,
        0.9985, 0.9987, 0.9987, 0.9987, 0.9992, 0.9960, 0.9994],
       device='cuda:0') torch.Size([16])
Epoch: 62 | Batch_idx: 0 |  Loss: (0.3880) |  Loss2: (0.0000) | Acc: (85.00%) (109/128)
Epoch: 62 | Batch_idx: 10 |  Loss: (0.3510) |  Loss2: (0.0000) | Acc: (87.00%) (1233/1408)
Epoch: 62 | Batch_idx: 20 |  Loss: (0.3658) |  Loss2: (0.0000) | Acc: (87.00%) (2350/2688)
Epoch: 62 | Batch_idx: 30 |  Loss: (0.3571) |  Loss2: (0.0000) | Acc: (87.00%) (3466/3968)
Epoch: 62 | Batch_idx: 40 |  Loss: (0.3465) |  Loss2: (0.0000) | Acc: (87.00%) (4599/5248)
Epoch: 62 | Batch_idx: 50 |  Loss: (0.3409) |  Loss2: (0.0000) | Acc: (87.00%) (5737/6528)
Epoch: 62 | Batch_idx: 60 |  Loss: (0.3366) |  Loss2: (0.0000) | Acc: (88.00%) (6876/7808)
Epoch: 62 | Batch_idx: 70 |  Loss: (0.3369) |  Loss2: (0.0000) | Acc: (88.00%) (8017/9088)
Epoch: 62 | Batch_idx: 80 |  Loss: (0.3383) |  Loss2: (0.0000) | Acc: (88.00%) (9151/10368)
Epoch: 62 | Batch_idx: 90 |  Loss: (0.3399) |  Loss2: (0.0000) | Acc: (88.00%) (10276/11648)
Epoch: 62 | Batch_idx: 100 |  Loss: (0.3451) |  Loss2: (0.0000) | Acc: (87.00%) (11376/12928)
Epoch: 62 | Batch_idx: 110 |  Loss: (0.3448) |  Loss2: (0.0000) | Acc: (88.00%) (12512/14208)
Epoch: 62 | Batch_idx: 120 |  Loss: (0.3441) |  Loss2: (0.0000) | Acc: (88.00%) (13650/15488)
Epoch: 62 | Batch_idx: 130 |  Loss: (0.3453) |  Loss2: (0.0000) | Acc: (88.00%) (14769/16768)
Epoch: 62 | Batch_idx: 140 |  Loss: (0.3476) |  Loss2: (0.0000) | Acc: (87.00%) (15880/18048)
Epoch: 62 | Batch_idx: 150 |  Loss: (0.3471) |  Loss2: (0.0000) | Acc: (87.00%) (16995/19328)
Epoch: 62 | Batch_idx: 160 |  Loss: (0.3450) |  Loss2: (0.0000) | Acc: (87.00%) (18128/20608)
Epoch: 62 | Batch_idx: 170 |  Loss: (0.3435) |  Loss2: (0.0000) | Acc: (88.00%) (19276/21888)
Epoch: 62 | Batch_idx: 180 |  Loss: (0.3438) |  Loss2: (0.0000) | Acc: (88.00%) (20397/23168)
Epoch: 62 | Batch_idx: 190 |  Loss: (0.3433) |  Loss2: (0.0000) | Acc: (88.00%) (21541/24448)
Epoch: 62 | Batch_idx: 200 |  Loss: (0.3437) |  Loss2: (0.0000) | Acc: (88.00%) (22655/25728)
Epoch: 62 | Batch_idx: 210 |  Loss: (0.3449) |  Loss2: (0.0000) | Acc: (88.00%) (23780/27008)
Epoch: 62 | Batch_idx: 220 |  Loss: (0.3464) |  Loss2: (0.0000) | Acc: (88.00%) (24895/28288)
Epoch: 62 | Batch_idx: 230 |  Loss: (0.3444) |  Loss2: (0.0000) | Acc: (88.00%) (26038/29568)
Epoch: 62 | Batch_idx: 240 |  Loss: (0.3443) |  Loss2: (0.0000) | Acc: (88.00%) (27175/30848)
Epoch: 62 | Batch_idx: 250 |  Loss: (0.3446) |  Loss2: (0.0000) | Acc: (88.00%) (28292/32128)
Epoch: 62 | Batch_idx: 260 |  Loss: (0.3437) |  Loss2: (0.0000) | Acc: (88.00%) (29435/33408)
Epoch: 62 | Batch_idx: 270 |  Loss: (0.3439) |  Loss2: (0.0000) | Acc: (88.00%) (30563/34688)
Epoch: 62 | Batch_idx: 280 |  Loss: (0.3454) |  Loss2: (0.0000) | Acc: (88.00%) (31679/35968)
Epoch: 62 | Batch_idx: 290 |  Loss: (0.3443) |  Loss2: (0.0000) | Acc: (88.00%) (32816/37248)
Epoch: 62 | Batch_idx: 300 |  Loss: (0.3458) |  Loss2: (0.0000) | Acc: (88.00%) (33925/38528)
Epoch: 62 | Batch_idx: 310 |  Loss: (0.3464) |  Loss2: (0.0000) | Acc: (88.00%) (35050/39808)
Epoch: 62 | Batch_idx: 320 |  Loss: (0.3470) |  Loss2: (0.0000) | Acc: (88.00%) (36163/41088)
Epoch: 62 | Batch_idx: 330 |  Loss: (0.3464) |  Loss2: (0.0000) | Acc: (88.00%) (37295/42368)
Epoch: 62 | Batch_idx: 340 |  Loss: (0.3469) |  Loss2: (0.0000) | Acc: (87.00%) (38407/43648)
Epoch: 62 | Batch_idx: 350 |  Loss: (0.3473) |  Loss2: (0.0000) | Acc: (87.00%) (39534/44928)
Epoch: 62 | Batch_idx: 360 |  Loss: (0.3466) |  Loss2: (0.0000) | Acc: (88.00%) (40669/46208)
Epoch: 62 | Batch_idx: 370 |  Loss: (0.3467) |  Loss2: (0.0000) | Acc: (88.00%) (41795/47488)
Epoch: 62 | Batch_idx: 380 |  Loss: (0.3469) |  Loss2: (0.0000) | Acc: (88.00%) (42919/48768)
Epoch: 62 | Batch_idx: 390 |  Loss: (0.3476) |  Loss2: (0.0000) | Acc: (87.00%) (43995/50000)
# TEST : Loss: (0.4955) | Acc: (83.00%) (8352/10000)
percent tensor([0.5275, 0.5321, 0.5285, 0.5289, 0.5298, 0.5284, 0.5327, 0.5325, 0.5282,
        0.5316, 0.5288, 0.5302, 0.5286, 0.5306, 0.5293, 0.5292],
       device='cuda:0') torch.Size([16])
percent tensor([0.5034, 0.4977, 0.5053, 0.5094, 0.5018, 0.5136, 0.4953, 0.4976, 0.5029,
        0.4994, 0.5028, 0.5035, 0.5051, 0.5008, 0.5052, 0.5074],
       device='cuda:0') torch.Size([16])
percent tensor([0.4880, 0.5190, 0.5358, 0.5532, 0.5373, 0.4903, 0.5359, 0.5435, 0.5288,
        0.5328, 0.5382, 0.5130, 0.4487, 0.5826, 0.5063, 0.5054],
       device='cuda:0') torch.Size([16])
percent tensor([0.5888, 0.6007, 0.5953, 0.5957, 0.5972, 0.5714, 0.6036, 0.6042, 0.6011,
        0.6008, 0.6061, 0.6050, 0.5953, 0.6029, 0.5975, 0.5909],
       device='cuda:0') torch.Size([16])
percent tensor([0.5646, 0.5680, 0.6080, 0.6421, 0.6080, 0.6376, 0.5612, 0.5717, 0.5910,
        0.5939, 0.5778, 0.6190, 0.5796, 0.6157, 0.5557, 0.6020],
       device='cuda:0') torch.Size([16])
percent tensor([0.5961, 0.5868, 0.6257, 0.6379, 0.6303, 0.6857, 0.5972, 0.5926, 0.6090,
        0.5858, 0.5942, 0.6073, 0.6029, 0.6159, 0.5818, 0.6163],
       device='cuda:0') torch.Size([16])
percent tensor([0.6121, 0.5676, 0.6331, 0.6337, 0.6576, 0.6501, 0.6020, 0.6609, 0.5593,
        0.5725, 0.5561, 0.5779, 0.5453, 0.5659, 0.5720, 0.6371],
       device='cuda:0') torch.Size([16])
percent tensor([0.9995, 0.9980, 0.9980, 0.9988, 0.9979, 0.9990, 0.9984, 0.9993, 0.9979,
        0.9985, 0.9985, 0.9989, 0.9989, 0.9986, 0.9969, 0.9992],
       device='cuda:0') torch.Size([16])
Epoch: 63 | Batch_idx: 0 |  Loss: (0.2998) |  Loss2: (0.0000) | Acc: (89.00%) (115/128)
Epoch: 63 | Batch_idx: 10 |  Loss: (0.3209) |  Loss2: (0.0000) | Acc: (89.00%) (1255/1408)
Epoch: 63 | Batch_idx: 20 |  Loss: (0.3268) |  Loss2: (0.0000) | Acc: (88.00%) (2390/2688)
Epoch: 63 | Batch_idx: 30 |  Loss: (0.3257) |  Loss2: (0.0000) | Acc: (88.00%) (3527/3968)
Epoch: 63 | Batch_idx: 40 |  Loss: (0.3328) |  Loss2: (0.0000) | Acc: (88.00%) (4641/5248)
Epoch: 63 | Batch_idx: 50 |  Loss: (0.3382) |  Loss2: (0.0000) | Acc: (88.00%) (5751/6528)
Epoch: 63 | Batch_idx: 60 |  Loss: (0.3439) |  Loss2: (0.0000) | Acc: (87.00%) (6871/7808)
Epoch: 63 | Batch_idx: 70 |  Loss: (0.3432) |  Loss2: (0.0000) | Acc: (88.00%) (7998/9088)
Epoch: 63 | Batch_idx: 80 |  Loss: (0.3459) |  Loss2: (0.0000) | Acc: (87.00%) (9123/10368)
Epoch: 63 | Batch_idx: 90 |  Loss: (0.3428) |  Loss2: (0.0000) | Acc: (88.00%) (10271/11648)
Epoch: 63 | Batch_idx: 100 |  Loss: (0.3406) |  Loss2: (0.0000) | Acc: (88.00%) (11409/12928)
Epoch: 63 | Batch_idx: 110 |  Loss: (0.3383) |  Loss2: (0.0000) | Acc: (88.00%) (12545/14208)
Epoch: 63 | Batch_idx: 120 |  Loss: (0.3381) |  Loss2: (0.0000) | Acc: (88.00%) (13686/15488)
Epoch: 63 | Batch_idx: 130 |  Loss: (0.3395) |  Loss2: (0.0000) | Acc: (88.00%) (14811/16768)
Epoch: 63 | Batch_idx: 140 |  Loss: (0.3378) |  Loss2: (0.0000) | Acc: (88.00%) (15944/18048)
Epoch: 63 | Batch_idx: 150 |  Loss: (0.3370) |  Loss2: (0.0000) | Acc: (88.00%) (17077/19328)
Epoch: 63 | Batch_idx: 160 |  Loss: (0.3361) |  Loss2: (0.0000) | Acc: (88.00%) (18203/20608)
Epoch: 63 | Batch_idx: 170 |  Loss: (0.3379) |  Loss2: (0.0000) | Acc: (88.00%) (19318/21888)
Epoch: 63 | Batch_idx: 180 |  Loss: (0.3370) |  Loss2: (0.0000) | Acc: (88.00%) (20458/23168)
Epoch: 63 | Batch_idx: 190 |  Loss: (0.3376) |  Loss2: (0.0000) | Acc: (88.00%) (21587/24448)
Epoch: 63 | Batch_idx: 200 |  Loss: (0.3370) |  Loss2: (0.0000) | Acc: (88.00%) (22713/25728)
Epoch: 63 | Batch_idx: 210 |  Loss: (0.3370) |  Loss2: (0.0000) | Acc: (88.00%) (23852/27008)
Epoch: 63 | Batch_idx: 220 |  Loss: (0.3371) |  Loss2: (0.0000) | Acc: (88.00%) (24975/28288)
Epoch: 63 | Batch_idx: 230 |  Loss: (0.3376) |  Loss2: (0.0000) | Acc: (88.00%) (26103/29568)
Epoch: 63 | Batch_idx: 240 |  Loss: (0.3378) |  Loss2: (0.0000) | Acc: (88.00%) (27234/30848)
Epoch: 63 | Batch_idx: 250 |  Loss: (0.3394) |  Loss2: (0.0000) | Acc: (88.00%) (28341/32128)
Epoch: 63 | Batch_idx: 260 |  Loss: (0.3392) |  Loss2: (0.0000) | Acc: (88.00%) (29464/33408)
Epoch: 63 | Batch_idx: 270 |  Loss: (0.3392) |  Loss2: (0.0000) | Acc: (88.00%) (30600/34688)
Epoch: 63 | Batch_idx: 280 |  Loss: (0.3391) |  Loss2: (0.0000) | Acc: (88.00%) (31737/35968)
Epoch: 63 | Batch_idx: 290 |  Loss: (0.3396) |  Loss2: (0.0000) | Acc: (88.00%) (32867/37248)
Epoch: 63 | Batch_idx: 300 |  Loss: (0.3402) |  Loss2: (0.0000) | Acc: (88.00%) (33992/38528)
Epoch: 63 | Batch_idx: 310 |  Loss: (0.3398) |  Loss2: (0.0000) | Acc: (88.00%) (35132/39808)
Epoch: 63 | Batch_idx: 320 |  Loss: (0.3404) |  Loss2: (0.0000) | Acc: (88.00%) (36256/41088)
Epoch: 63 | Batch_idx: 330 |  Loss: (0.3401) |  Loss2: (0.0000) | Acc: (88.00%) (37387/42368)
Epoch: 63 | Batch_idx: 340 |  Loss: (0.3401) |  Loss2: (0.0000) | Acc: (88.00%) (38521/43648)
Epoch: 63 | Batch_idx: 350 |  Loss: (0.3412) |  Loss2: (0.0000) | Acc: (88.00%) (39623/44928)
Epoch: 63 | Batch_idx: 360 |  Loss: (0.3417) |  Loss2: (0.0000) | Acc: (88.00%) (40747/46208)
Epoch: 63 | Batch_idx: 370 |  Loss: (0.3416) |  Loss2: (0.0000) | Acc: (88.00%) (41883/47488)
Epoch: 63 | Batch_idx: 380 |  Loss: (0.3419) |  Loss2: (0.0000) | Acc: (88.00%) (42996/48768)
Epoch: 63 | Batch_idx: 390 |  Loss: (0.3419) |  Loss2: (0.0000) | Acc: (88.00%) (44078/50000)
# TEST : Loss: (0.4998) | Acc: (83.00%) (8317/10000)
percent tensor([0.5280, 0.5315, 0.5292, 0.5294, 0.5309, 0.5306, 0.5325, 0.5324, 0.5282,
        0.5313, 0.5289, 0.5307, 0.5287, 0.5295, 0.5302, 0.5295],
       device='cuda:0') torch.Size([16])
percent tensor([0.5039, 0.4979, 0.5068, 0.5093, 0.5028, 0.5130, 0.4955, 0.4983, 0.5029,
        0.4996, 0.5028, 0.5040, 0.5046, 0.5006, 0.5052, 0.5070],
       device='cuda:0') torch.Size([16])
percent tensor([0.4828, 0.5033, 0.5303, 0.5524, 0.5400, 0.5013, 0.5273, 0.5321, 0.5235,
        0.5185, 0.5325, 0.5106, 0.4434, 0.5702, 0.5017, 0.4966],
       device='cuda:0') torch.Size([16])
percent tensor([0.5923, 0.5988, 0.5985, 0.5984, 0.6002, 0.5757, 0.6045, 0.6040, 0.6040,
        0.5999, 0.6053, 0.6086, 0.5970, 0.6031, 0.5986, 0.5925],
       device='cuda:0') torch.Size([16])
percent tensor([0.5556, 0.5643, 0.5977, 0.6269, 0.6054, 0.6307, 0.5521, 0.5669, 0.5886,
        0.5831, 0.5794, 0.6069, 0.5692, 0.6141, 0.5539, 0.5982],
       device='cuda:0') torch.Size([16])
percent tensor([0.5982, 0.5888, 0.6234, 0.6305, 0.6291, 0.6801, 0.5915, 0.5943, 0.6111,
        0.5840, 0.6004, 0.5906, 0.5972, 0.6137, 0.5781, 0.6202],
       device='cuda:0') torch.Size([16])
percent tensor([0.6181, 0.5764, 0.6401, 0.6314, 0.6684, 0.6347, 0.6100, 0.6667, 0.5725,
        0.5801, 0.5711, 0.5726, 0.5623, 0.5720, 0.5799, 0.6405],
       device='cuda:0') torch.Size([16])
percent tensor([0.9996, 0.9988, 0.9982, 0.9988, 0.9990, 0.9984, 0.9993, 0.9995, 0.9979,
        0.9989, 0.9991, 0.9980, 0.9988, 0.9995, 0.9963, 0.9995],
       device='cuda:0') torch.Size([16])
Epoch: 64 | Batch_idx: 0 |  Loss: (0.3195) |  Loss2: (0.0000) | Acc: (89.00%) (114/128)
Epoch: 64 | Batch_idx: 10 |  Loss: (0.3420) |  Loss2: (0.0000) | Acc: (88.00%) (1247/1408)
Epoch: 64 | Batch_idx: 20 |  Loss: (0.3474) |  Loss2: (0.0000) | Acc: (88.00%) (2372/2688)
Epoch: 64 | Batch_idx: 30 |  Loss: (0.3394) |  Loss2: (0.0000) | Acc: (88.00%) (3511/3968)
Epoch: 64 | Batch_idx: 40 |  Loss: (0.3446) |  Loss2: (0.0000) | Acc: (88.00%) (4624/5248)
Epoch: 64 | Batch_idx: 50 |  Loss: (0.3431) |  Loss2: (0.0000) | Acc: (88.00%) (5762/6528)
Epoch: 64 | Batch_idx: 60 |  Loss: (0.3454) |  Loss2: (0.0000) | Acc: (88.00%) (6886/7808)
Epoch: 64 | Batch_idx: 70 |  Loss: (0.3431) |  Loss2: (0.0000) | Acc: (88.00%) (8028/9088)
Epoch: 64 | Batch_idx: 80 |  Loss: (0.3428) |  Loss2: (0.0000) | Acc: (88.00%) (9158/10368)
Epoch: 64 | Batch_idx: 90 |  Loss: (0.3377) |  Loss2: (0.0000) | Acc: (88.00%) (10312/11648)
Epoch: 64 | Batch_idx: 100 |  Loss: (0.3351) |  Loss2: (0.0000) | Acc: (88.00%) (11443/12928)
Epoch: 64 | Batch_idx: 110 |  Loss: (0.3339) |  Loss2: (0.0000) | Acc: (88.00%) (12585/14208)
Epoch: 64 | Batch_idx: 120 |  Loss: (0.3326) |  Loss2: (0.0000) | Acc: (88.00%) (13722/15488)
Epoch: 64 | Batch_idx: 130 |  Loss: (0.3321) |  Loss2: (0.0000) | Acc: (88.00%) (14854/16768)
Epoch: 64 | Batch_idx: 140 |  Loss: (0.3318) |  Loss2: (0.0000) | Acc: (88.00%) (15989/18048)
Epoch: 64 | Batch_idx: 150 |  Loss: (0.3314) |  Loss2: (0.0000) | Acc: (88.00%) (17138/19328)
Epoch: 64 | Batch_idx: 160 |  Loss: (0.3306) |  Loss2: (0.0000) | Acc: (88.00%) (18287/20608)
Epoch: 64 | Batch_idx: 170 |  Loss: (0.3313) |  Loss2: (0.0000) | Acc: (88.00%) (19419/21888)
Epoch: 64 | Batch_idx: 180 |  Loss: (0.3310) |  Loss2: (0.0000) | Acc: (88.00%) (20540/23168)
Epoch: 64 | Batch_idx: 190 |  Loss: (0.3317) |  Loss2: (0.0000) | Acc: (88.00%) (21664/24448)
Epoch: 64 | Batch_idx: 200 |  Loss: (0.3322) |  Loss2: (0.0000) | Acc: (88.00%) (22785/25728)
Epoch: 64 | Batch_idx: 210 |  Loss: (0.3315) |  Loss2: (0.0000) | Acc: (88.00%) (23939/27008)
Epoch: 64 | Batch_idx: 220 |  Loss: (0.3308) |  Loss2: (0.0000) | Acc: (88.00%) (25070/28288)
Epoch: 64 | Batch_idx: 230 |  Loss: (0.3316) |  Loss2: (0.0000) | Acc: (88.00%) (26192/29568)
Epoch: 64 | Batch_idx: 240 |  Loss: (0.3305) |  Loss2: (0.0000) | Acc: (88.00%) (27336/30848)
Epoch: 64 | Batch_idx: 250 |  Loss: (0.3316) |  Loss2: (0.0000) | Acc: (88.00%) (28448/32128)
Epoch: 64 | Batch_idx: 260 |  Loss: (0.3309) |  Loss2: (0.0000) | Acc: (88.00%) (29596/33408)
Epoch: 64 | Batch_idx: 270 |  Loss: (0.3315) |  Loss2: (0.0000) | Acc: (88.00%) (30721/34688)
Epoch: 64 | Batch_idx: 280 |  Loss: (0.3313) |  Loss2: (0.0000) | Acc: (88.00%) (31850/35968)
Epoch: 64 | Batch_idx: 290 |  Loss: (0.3307) |  Loss2: (0.0000) | Acc: (88.00%) (32997/37248)
Epoch: 64 | Batch_idx: 300 |  Loss: (0.3317) |  Loss2: (0.0000) | Acc: (88.00%) (34125/38528)
Epoch: 64 | Batch_idx: 310 |  Loss: (0.3313) |  Loss2: (0.0000) | Acc: (88.00%) (35264/39808)
Epoch: 64 | Batch_idx: 320 |  Loss: (0.3332) |  Loss2: (0.0000) | Acc: (88.00%) (36365/41088)
Epoch: 64 | Batch_idx: 330 |  Loss: (0.3332) |  Loss2: (0.0000) | Acc: (88.00%) (37510/42368)
Epoch: 64 | Batch_idx: 340 |  Loss: (0.3347) |  Loss2: (0.0000) | Acc: (88.00%) (38627/43648)
Epoch: 64 | Batch_idx: 350 |  Loss: (0.3366) |  Loss2: (0.0000) | Acc: (88.00%) (39737/44928)
Epoch: 64 | Batch_idx: 360 |  Loss: (0.3355) |  Loss2: (0.0000) | Acc: (88.00%) (40887/46208)
Epoch: 64 | Batch_idx: 370 |  Loss: (0.3358) |  Loss2: (0.0000) | Acc: (88.00%) (42017/47488)
Epoch: 64 | Batch_idx: 380 |  Loss: (0.3358) |  Loss2: (0.0000) | Acc: (88.00%) (43149/48768)
Epoch: 64 | Batch_idx: 390 |  Loss: (0.3362) |  Loss2: (0.0000) | Acc: (88.00%) (44236/50000)
# TEST : Loss: (0.5266) | Acc: (82.00%) (8247/10000)
percent tensor([0.5284, 0.5323, 0.5292, 0.5296, 0.5306, 0.5298, 0.5330, 0.5330, 0.5287,
        0.5319, 0.5295, 0.5311, 0.5292, 0.5309, 0.5300, 0.5298],
       device='cuda:0') torch.Size([16])
percent tensor([0.5033, 0.4985, 0.5055, 0.5083, 0.5019, 0.5132, 0.4962, 0.4980, 0.5025,
        0.4995, 0.5035, 0.5038, 0.5039, 0.5020, 0.5047, 0.5066],
       device='cuda:0') torch.Size([16])
percent tensor([0.4931, 0.5045, 0.5483, 0.5613, 0.5511, 0.5007, 0.5299, 0.5463, 0.5325,
        0.5265, 0.5310, 0.5259, 0.4507, 0.5777, 0.5009, 0.5034],
       device='cuda:0') torch.Size([16])
percent tensor([0.5945, 0.6008, 0.6009, 0.5999, 0.6007, 0.5756, 0.6045, 0.6074, 0.6066,
        0.6015, 0.6071, 0.6119, 0.5990, 0.6026, 0.6005, 0.5939],
       device='cuda:0') torch.Size([16])
percent tensor([0.5541, 0.5637, 0.6020, 0.6253, 0.6046, 0.6405, 0.5491, 0.5702, 0.5918,
        0.5883, 0.5803, 0.6109, 0.5702, 0.6208, 0.5571, 0.6012],
       device='cuda:0') torch.Size([16])
percent tensor([0.5944, 0.5857, 0.6112, 0.6250, 0.6189, 0.6838, 0.5861, 0.5879, 0.6095,
        0.5792, 0.5988, 0.5952, 0.5955, 0.6200, 0.5834, 0.6178],
       device='cuda:0') torch.Size([16])
percent tensor([0.6173, 0.5736, 0.6236, 0.6129, 0.6537, 0.6425, 0.6050, 0.6553, 0.5699,
        0.5819, 0.5681, 0.5744, 0.5600, 0.5776, 0.5688, 0.6384],
       device='cuda:0') torch.Size([16])
percent tensor([0.9994, 0.9986, 0.9980, 0.9990, 0.9982, 0.9988, 0.9987, 0.9994, 0.9985,
        0.9984, 0.9988, 0.9987, 0.9987, 0.9989, 0.9960, 0.9993],
       device='cuda:0') torch.Size([16])
Epoch: 65 | Batch_idx: 0 |  Loss: (0.3076) |  Loss2: (0.0000) | Acc: (86.00%) (111/128)
Epoch: 65 | Batch_idx: 10 |  Loss: (0.3229) |  Loss2: (0.0000) | Acc: (88.00%) (1242/1408)
Epoch: 65 | Batch_idx: 20 |  Loss: (0.3128) |  Loss2: (0.0000) | Acc: (88.00%) (2390/2688)
Epoch: 65 | Batch_idx: 30 |  Loss: (0.3050) |  Loss2: (0.0000) | Acc: (89.00%) (3543/3968)
Epoch: 65 | Batch_idx: 40 |  Loss: (0.3060) |  Loss2: (0.0000) | Acc: (89.00%) (4677/5248)
Epoch: 65 | Batch_idx: 50 |  Loss: (0.3041) |  Loss2: (0.0000) | Acc: (89.00%) (5830/6528)
Epoch: 65 | Batch_idx: 60 |  Loss: (0.3028) |  Loss2: (0.0000) | Acc: (89.00%) (6984/7808)
Epoch: 65 | Batch_idx: 70 |  Loss: (0.3111) |  Loss2: (0.0000) | Acc: (89.00%) (8100/9088)
Epoch: 65 | Batch_idx: 80 |  Loss: (0.3078) |  Loss2: (0.0000) | Acc: (89.00%) (9260/10368)
Epoch: 65 | Batch_idx: 90 |  Loss: (0.3113) |  Loss2: (0.0000) | Acc: (89.00%) (10393/11648)
Epoch: 65 | Batch_idx: 100 |  Loss: (0.3132) |  Loss2: (0.0000) | Acc: (89.00%) (11524/12928)
Epoch: 65 | Batch_idx: 110 |  Loss: (0.3153) |  Loss2: (0.0000) | Acc: (89.00%) (12647/14208)
Epoch: 65 | Batch_idx: 120 |  Loss: (0.3143) |  Loss2: (0.0000) | Acc: (89.00%) (13788/15488)
Epoch: 65 | Batch_idx: 130 |  Loss: (0.3153) |  Loss2: (0.0000) | Acc: (89.00%) (14924/16768)
Epoch: 65 | Batch_idx: 140 |  Loss: (0.3159) |  Loss2: (0.0000) | Acc: (88.00%) (16061/18048)
Epoch: 65 | Batch_idx: 150 |  Loss: (0.3162) |  Loss2: (0.0000) | Acc: (89.00%) (17204/19328)
Epoch: 65 | Batch_idx: 160 |  Loss: (0.3146) |  Loss2: (0.0000) | Acc: (89.00%) (18354/20608)
Epoch: 65 | Batch_idx: 170 |  Loss: (0.3154) |  Loss2: (0.0000) | Acc: (89.00%) (19501/21888)
Epoch: 65 | Batch_idx: 180 |  Loss: (0.3155) |  Loss2: (0.0000) | Acc: (89.00%) (20638/23168)
Epoch: 65 | Batch_idx: 190 |  Loss: (0.3155) |  Loss2: (0.0000) | Acc: (89.00%) (21776/24448)
Epoch: 65 | Batch_idx: 200 |  Loss: (0.3162) |  Loss2: (0.0000) | Acc: (89.00%) (22908/25728)
Epoch: 65 | Batch_idx: 210 |  Loss: (0.3176) |  Loss2: (0.0000) | Acc: (88.00%) (24029/27008)
Epoch: 65 | Batch_idx: 220 |  Loss: (0.3188) |  Loss2: (0.0000) | Acc: (88.00%) (25157/28288)
Epoch: 65 | Batch_idx: 230 |  Loss: (0.3187) |  Loss2: (0.0000) | Acc: (88.00%) (26299/29568)
Epoch: 65 | Batch_idx: 240 |  Loss: (0.3194) |  Loss2: (0.0000) | Acc: (88.00%) (27431/30848)
Epoch: 65 | Batch_idx: 250 |  Loss: (0.3187) |  Loss2: (0.0000) | Acc: (88.00%) (28580/32128)
Epoch: 65 | Batch_idx: 260 |  Loss: (0.3190) |  Loss2: (0.0000) | Acc: (88.00%) (29713/33408)
Epoch: 65 | Batch_idx: 270 |  Loss: (0.3198) |  Loss2: (0.0000) | Acc: (88.00%) (30850/34688)
Epoch: 65 | Batch_idx: 280 |  Loss: (0.3200) |  Loss2: (0.0000) | Acc: (88.00%) (31990/35968)
Epoch: 65 | Batch_idx: 290 |  Loss: (0.3196) |  Loss2: (0.0000) | Acc: (88.00%) (33139/37248)
Epoch: 65 | Batch_idx: 300 |  Loss: (0.3195) |  Loss2: (0.0000) | Acc: (88.00%) (34284/38528)
Epoch: 65 | Batch_idx: 310 |  Loss: (0.3187) |  Loss2: (0.0000) | Acc: (89.00%) (35442/39808)
Epoch: 65 | Batch_idx: 320 |  Loss: (0.3182) |  Loss2: (0.0000) | Acc: (89.00%) (36600/41088)
Epoch: 65 | Batch_idx: 330 |  Loss: (0.3185) |  Loss2: (0.0000) | Acc: (89.00%) (37735/42368)
Epoch: 65 | Batch_idx: 340 |  Loss: (0.3174) |  Loss2: (0.0000) | Acc: (89.00%) (38894/43648)
Epoch: 65 | Batch_idx: 350 |  Loss: (0.3191) |  Loss2: (0.0000) | Acc: (89.00%) (40008/44928)
Epoch: 65 | Batch_idx: 360 |  Loss: (0.3203) |  Loss2: (0.0000) | Acc: (89.00%) (41132/46208)
Epoch: 65 | Batch_idx: 370 |  Loss: (0.3203) |  Loss2: (0.0000) | Acc: (89.00%) (42268/47488)
Epoch: 65 | Batch_idx: 380 |  Loss: (0.3207) |  Loss2: (0.0000) | Acc: (89.00%) (43406/48768)
Epoch: 65 | Batch_idx: 390 |  Loss: (0.3205) |  Loss2: (0.0000) | Acc: (88.00%) (44497/50000)
=> saving checkpoint 'drive/app/torch/save_Schedule/checkpoint_065.pth.tar'
# TEST : Loss: (0.4928) | Acc: (83.00%) (8392/10000)
percent tensor([0.5277, 0.5313, 0.5312, 0.5298, 0.5319, 0.5291, 0.5329, 0.5334, 0.5282,
        0.5321, 0.5280, 0.5327, 0.5287, 0.5287, 0.5294, 0.5292],
       device='cuda:0') torch.Size([16])
percent tensor([0.5053, 0.5000, 0.5049, 0.5095, 0.5016, 0.5132, 0.4965, 0.4986, 0.5034,
        0.5005, 0.5042, 0.5034, 0.5060, 0.5031, 0.5062, 0.5080],
       device='cuda:0') torch.Size([16])
percent tensor([0.4936, 0.5058, 0.5499, 0.5546, 0.5535, 0.4936, 0.5326, 0.5466, 0.5420,
        0.5278, 0.5358, 0.5345, 0.4555, 0.5696, 0.5001, 0.5010],
       device='cuda:0') torch.Size([16])
percent tensor([0.5950, 0.6012, 0.5994, 0.5992, 0.6009, 0.5770, 0.6053, 0.6072, 0.6054,
        0.6043, 0.6073, 0.6104, 0.5988, 0.6050, 0.6005, 0.5952],
       device='cuda:0') torch.Size([16])
percent tensor([0.5667, 0.5731, 0.5948, 0.6223, 0.6059, 0.6357, 0.5562, 0.5740, 0.6024,
        0.5897, 0.5947, 0.6085, 0.5859, 0.6221, 0.5568, 0.6047],
       device='cuda:0') torch.Size([16])
percent tensor([0.5965, 0.5837, 0.6066, 0.6242, 0.6242, 0.6817, 0.5867, 0.5894, 0.6146,
        0.5723, 0.6015, 0.5883, 0.6030, 0.6180, 0.5749, 0.6169],
       device='cuda:0') torch.Size([16])
percent tensor([0.6063, 0.5621, 0.6152, 0.6092, 0.6493, 0.6358, 0.6001, 0.6425, 0.5662,
        0.5665, 0.5693, 0.5640, 0.5542, 0.5734, 0.5679, 0.6160],
       device='cuda:0') torch.Size([16])
percent tensor([0.9996, 0.9989, 0.9983, 0.9986, 0.9982, 0.9977, 0.9992, 0.9993, 0.9985,
        0.9991, 0.9994, 0.9982, 0.9990, 0.9994, 0.9974, 0.9994],
       device='cuda:0') torch.Size([16])
False Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=128, out_features=16, bias=False)
True Linear(in_features=16, out_features=2, bias=False)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=128, out_features=16, bias=False)
True Linear(in_features=16, out_features=2, bias=False)
False Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=256, out_features=32, bias=False)
True Linear(in_features=32, out_features=2, bias=False)
False Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=256, out_features=32, bias=False)
True Linear(in_features=32, out_features=2, bias=False)
False Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=512, out_features=64, bias=False)
True Linear(in_features=64, out_features=2, bias=False)
False Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=512, out_features=64, bias=False)
True Linear(in_features=64, out_features=2, bias=False)
False Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1024, out_features=128, bias=False)
True Linear(in_features=128, out_features=2, bias=False)
False Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1024, out_features=128, bias=False)
True Linear(in_features=128, out_features=2, bias=False)
False Linear(in_features=512, out_features=10, bias=True)
Epoch: 66 | Batch_idx: 0 |  Loss: (0.3175) |  Loss2: (0.0000) | Acc: (89.00%) (115/128)
Epoch: 66 | Batch_idx: 10 |  Loss: (0.3256) |  Loss2: (0.0000) | Acc: (88.00%) (1250/1408)
Epoch: 66 | Batch_idx: 20 |  Loss: (0.3317) |  Loss2: (0.0000) | Acc: (88.00%) (2382/2688)
Epoch: 66 | Batch_idx: 30 |  Loss: (0.3422) |  Loss2: (0.0000) | Acc: (88.00%) (3502/3968)
Epoch: 66 | Batch_idx: 40 |  Loss: (0.3568) |  Loss2: (0.0000) | Acc: (87.00%) (4614/5248)
Epoch: 66 | Batch_idx: 50 |  Loss: (0.3698) |  Loss2: (0.0000) | Acc: (87.00%) (5698/6528)
Epoch: 66 | Batch_idx: 60 |  Loss: (0.3772) |  Loss2: (0.0000) | Acc: (86.00%) (6789/7808)
Epoch: 66 | Batch_idx: 70 |  Loss: (0.3732) |  Loss2: (0.0000) | Acc: (87.00%) (7909/9088)
Epoch: 66 | Batch_idx: 80 |  Loss: (0.3728) |  Loss2: (0.0000) | Acc: (87.00%) (9027/10368)
Epoch: 66 | Batch_idx: 90 |  Loss: (0.3719) |  Loss2: (0.0000) | Acc: (87.00%) (10141/11648)
Epoch: 66 | Batch_idx: 100 |  Loss: (0.3707) |  Loss2: (0.0000) | Acc: (87.00%) (11258/12928)
Epoch: 66 | Batch_idx: 110 |  Loss: (0.3748) |  Loss2: (0.0000) | Acc: (86.00%) (12353/14208)
Epoch: 66 | Batch_idx: 120 |  Loss: (0.3780) |  Loss2: (0.0000) | Acc: (86.00%) (13450/15488)
Epoch: 66 | Batch_idx: 130 |  Loss: (0.3806) |  Loss2: (0.0000) | Acc: (86.00%) (14540/16768)
Epoch: 66 | Batch_idx: 140 |  Loss: (0.3785) |  Loss2: (0.0000) | Acc: (86.00%) (15674/18048)
Epoch: 66 | Batch_idx: 150 |  Loss: (0.3790) |  Loss2: (0.0000) | Acc: (86.00%) (16785/19328)
Epoch: 66 | Batch_idx: 160 |  Loss: (0.3778) |  Loss2: (0.0000) | Acc: (86.00%) (17909/20608)
Epoch: 66 | Batch_idx: 170 |  Loss: (0.3792) |  Loss2: (0.0000) | Acc: (86.00%) (19019/21888)
Epoch: 66 | Batch_idx: 180 |  Loss: (0.3767) |  Loss2: (0.0000) | Acc: (86.00%) (20154/23168)
Epoch: 66 | Batch_idx: 190 |  Loss: (0.3775) |  Loss2: (0.0000) | Acc: (87.00%) (21270/24448)
Epoch: 66 | Batch_idx: 200 |  Loss: (0.3778) |  Loss2: (0.0000) | Acc: (86.00%) (22378/25728)
Epoch: 66 | Batch_idx: 210 |  Loss: (0.3778) |  Loss2: (0.0000) | Acc: (86.00%) (23483/27008)
Epoch: 66 | Batch_idx: 220 |  Loss: (0.3798) |  Loss2: (0.0000) | Acc: (86.00%) (24574/28288)
Epoch: 66 | Batch_idx: 230 |  Loss: (0.3793) |  Loss2: (0.0000) | Acc: (86.00%) (25695/29568)
Epoch: 66 | Batch_idx: 240 |  Loss: (0.3789) |  Loss2: (0.0000) | Acc: (86.00%) (26822/30848)
Epoch: 66 | Batch_idx: 250 |  Loss: (0.3776) |  Loss2: (0.0000) | Acc: (86.00%) (27946/32128)
Epoch: 66 | Batch_idx: 260 |  Loss: (0.3770) |  Loss2: (0.0000) | Acc: (87.00%) (29078/33408)
Epoch: 66 | Batch_idx: 270 |  Loss: (0.3763) |  Loss2: (0.0000) | Acc: (87.00%) (30195/34688)
Epoch: 66 | Batch_idx: 280 |  Loss: (0.3765) |  Loss2: (0.0000) | Acc: (87.00%) (31298/35968)
Epoch: 66 | Batch_idx: 290 |  Loss: (0.3768) |  Loss2: (0.0000) | Acc: (87.00%) (32409/37248)
Epoch: 66 | Batch_idx: 300 |  Loss: (0.3755) |  Loss2: (0.0000) | Acc: (87.00%) (33533/38528)
Epoch: 66 | Batch_idx: 310 |  Loss: (0.3752) |  Loss2: (0.0000) | Acc: (87.00%) (34659/39808)
Epoch: 66 | Batch_idx: 320 |  Loss: (0.3745) |  Loss2: (0.0000) | Acc: (87.00%) (35785/41088)
Epoch: 66 | Batch_idx: 330 |  Loss: (0.3743) |  Loss2: (0.0000) | Acc: (87.00%) (36913/42368)
Epoch: 66 | Batch_idx: 340 |  Loss: (0.3735) |  Loss2: (0.0000) | Acc: (87.00%) (38039/43648)
Epoch: 66 | Batch_idx: 350 |  Loss: (0.3738) |  Loss2: (0.0000) | Acc: (87.00%) (39146/44928)
Epoch: 66 | Batch_idx: 360 |  Loss: (0.3720) |  Loss2: (0.0000) | Acc: (87.00%) (40285/46208)
Epoch: 66 | Batch_idx: 370 |  Loss: (0.3714) |  Loss2: (0.0000) | Acc: (87.00%) (41402/47488)
Epoch: 66 | Batch_idx: 380 |  Loss: (0.3706) |  Loss2: (0.0000) | Acc: (87.00%) (42533/48768)
Epoch: 66 | Batch_idx: 390 |  Loss: (0.3705) |  Loss2: (0.0000) | Acc: (87.00%) (43609/50000)
# TEST : Loss: (0.4785) | Acc: (83.00%) (8389/10000)
percent tensor([0.5188, 0.5208, 0.5230, 0.5213, 0.5229, 0.5206, 0.5227, 0.5239, 0.5193,
        0.5222, 0.5185, 0.5233, 0.5192, 0.5196, 0.5198, 0.5200],
       device='cuda:0') torch.Size([16])
percent tensor([0.5066, 0.5030, 0.5054, 0.5110, 0.5032, 0.5147, 0.4988, 0.5011, 0.5041,
        0.5032, 0.5049, 0.5040, 0.5074, 0.5041, 0.5088, 0.5096],
       device='cuda:0') torch.Size([16])
percent tensor([0.5150, 0.4977, 0.5755, 0.5794, 0.5829, 0.5334, 0.5475, 0.5677, 0.5616,
        0.5289, 0.5453, 0.5534, 0.4567, 0.5871, 0.5139, 0.5143],
       device='cuda:0') torch.Size([16])
percent tensor([0.5963, 0.6039, 0.5982, 0.5957, 0.6004, 0.5788, 0.6084, 0.6093, 0.6043,
        0.6046, 0.6055, 0.6083, 0.5997, 0.6022, 0.6052, 0.5951],
       device='cuda:0') torch.Size([16])
percent tensor([0.5866, 0.6016, 0.6027, 0.6338, 0.6195, 0.6532, 0.5824, 0.5955, 0.6135,
        0.6152, 0.6122, 0.6216, 0.6112, 0.6364, 0.5894, 0.6319],
       device='cuda:0') torch.Size([16])
percent tensor([0.6213, 0.6165, 0.6267, 0.6536, 0.6429, 0.7117, 0.6132, 0.6056, 0.6406,
        0.6042, 0.6358, 0.6219, 0.6405, 0.6528, 0.6019, 0.6479],
       device='cuda:0') torch.Size([16])
percent tensor([0.6172, 0.5732, 0.6235, 0.6333, 0.6478, 0.6583, 0.6024, 0.6377, 0.5835,
        0.5784, 0.5851, 0.5842, 0.5757, 0.5937, 0.5695, 0.6358],
       device='cuda:0') torch.Size([16])
percent tensor([0.9995, 0.9988, 0.9986, 0.9991, 0.9983, 0.9984, 0.9988, 0.9992, 0.9979,
        0.9986, 0.9992, 0.9985, 0.9990, 0.9992, 0.9969, 0.9994],
       device='cuda:0') torch.Size([16])
Epoch: 67 | Batch_idx: 0 |  Loss: (0.3201) |  Loss2: (0.0000) | Acc: (85.00%) (110/128)
Epoch: 67 | Batch_idx: 10 |  Loss: (0.3663) |  Loss2: (0.0000) | Acc: (87.00%) (1231/1408)
Epoch: 67 | Batch_idx: 20 |  Loss: (0.3591) |  Loss2: (0.0000) | Acc: (87.00%) (2346/2688)
Epoch: 67 | Batch_idx: 30 |  Loss: (0.3549) |  Loss2: (0.0000) | Acc: (87.00%) (3469/3968)
Epoch: 67 | Batch_idx: 40 |  Loss: (0.3577) |  Loss2: (0.0000) | Acc: (87.00%) (4589/5248)
Epoch: 67 | Batch_idx: 50 |  Loss: (0.3594) |  Loss2: (0.0000) | Acc: (87.00%) (5713/6528)
Epoch: 67 | Batch_idx: 60 |  Loss: (0.3633) |  Loss2: (0.0000) | Acc: (87.00%) (6825/7808)
Epoch: 67 | Batch_idx: 70 |  Loss: (0.3585) |  Loss2: (0.0000) | Acc: (87.00%) (7955/9088)
Epoch: 67 | Batch_idx: 80 |  Loss: (0.3561) |  Loss2: (0.0000) | Acc: (87.00%) (9090/10368)
Epoch: 67 | Batch_idx: 90 |  Loss: (0.3561) |  Loss2: (0.0000) | Acc: (87.00%) (10223/11648)
Epoch: 67 | Batch_idx: 100 |  Loss: (0.3545) |  Loss2: (0.0000) | Acc: (87.00%) (11357/12928)
Epoch: 67 | Batch_idx: 110 |  Loss: (0.3486) |  Loss2: (0.0000) | Acc: (88.00%) (12508/14208)
Epoch: 67 | Batch_idx: 120 |  Loss: (0.3478) |  Loss2: (0.0000) | Acc: (88.00%) (13657/15488)
Epoch: 67 | Batch_idx: 130 |  Loss: (0.3482) |  Loss2: (0.0000) | Acc: (88.00%) (14778/16768)
Epoch: 67 | Batch_idx: 140 |  Loss: (0.3472) |  Loss2: (0.0000) | Acc: (88.00%) (15919/18048)
Epoch: 67 | Batch_idx: 150 |  Loss: (0.3471) |  Loss2: (0.0000) | Acc: (88.00%) (17042/19328)
Epoch: 67 | Batch_idx: 160 |  Loss: (0.3476) |  Loss2: (0.0000) | Acc: (88.00%) (18171/20608)
Epoch: 67 | Batch_idx: 170 |  Loss: (0.3469) |  Loss2: (0.0000) | Acc: (88.00%) (19290/21888)
Epoch: 67 | Batch_idx: 180 |  Loss: (0.3454) |  Loss2: (0.0000) | Acc: (88.00%) (20424/23168)
Epoch: 67 | Batch_idx: 190 |  Loss: (0.3456) |  Loss2: (0.0000) | Acc: (88.00%) (21551/24448)
Epoch: 67 | Batch_idx: 200 |  Loss: (0.3442) |  Loss2: (0.0000) | Acc: (88.00%) (22700/25728)
Epoch: 67 | Batch_idx: 210 |  Loss: (0.3446) |  Loss2: (0.0000) | Acc: (88.00%) (23822/27008)
Epoch: 67 | Batch_idx: 220 |  Loss: (0.3450) |  Loss2: (0.0000) | Acc: (88.00%) (24936/28288)
Epoch: 67 | Batch_idx: 230 |  Loss: (0.3448) |  Loss2: (0.0000) | Acc: (88.00%) (26059/29568)
Epoch: 67 | Batch_idx: 240 |  Loss: (0.3444) |  Loss2: (0.0000) | Acc: (88.00%) (27187/30848)
Epoch: 67 | Batch_idx: 250 |  Loss: (0.3431) |  Loss2: (0.0000) | Acc: (88.00%) (28329/32128)
Epoch: 67 | Batch_idx: 260 |  Loss: (0.3426) |  Loss2: (0.0000) | Acc: (88.00%) (29471/33408)
Epoch: 67 | Batch_idx: 270 |  Loss: (0.3422) |  Loss2: (0.0000) | Acc: (88.00%) (30591/34688)
Epoch: 67 | Batch_idx: 280 |  Loss: (0.3421) |  Loss2: (0.0000) | Acc: (88.00%) (31719/35968)
Epoch: 67 | Batch_idx: 290 |  Loss: (0.3422) |  Loss2: (0.0000) | Acc: (88.00%) (32834/37248)
Epoch: 67 | Batch_idx: 300 |  Loss: (0.3422) |  Loss2: (0.0000) | Acc: (88.00%) (33963/38528)
Epoch: 67 | Batch_idx: 310 |  Loss: (0.3416) |  Loss2: (0.0000) | Acc: (88.00%) (35102/39808)
Epoch: 67 | Batch_idx: 320 |  Loss: (0.3406) |  Loss2: (0.0000) | Acc: (88.00%) (36248/41088)
Epoch: 67 | Batch_idx: 330 |  Loss: (0.3405) |  Loss2: (0.0000) | Acc: (88.00%) (37379/42368)
Epoch: 67 | Batch_idx: 340 |  Loss: (0.3394) |  Loss2: (0.0000) | Acc: (88.00%) (38534/43648)
Epoch: 67 | Batch_idx: 350 |  Loss: (0.3399) |  Loss2: (0.0000) | Acc: (88.00%) (39651/44928)
Epoch: 67 | Batch_idx: 360 |  Loss: (0.3392) |  Loss2: (0.0000) | Acc: (88.00%) (40801/46208)
Epoch: 67 | Batch_idx: 370 |  Loss: (0.3387) |  Loss2: (0.0000) | Acc: (88.00%) (41942/47488)
Epoch: 67 | Batch_idx: 380 |  Loss: (0.3385) |  Loss2: (0.0000) | Acc: (88.00%) (43071/48768)
Epoch: 67 | Batch_idx: 390 |  Loss: (0.3381) |  Loss2: (0.0000) | Acc: (88.00%) (44166/50000)
# TEST : Loss: (0.4502) | Acc: (84.00%) (8469/10000)
percent tensor([0.5165, 0.5180, 0.5208, 0.5192, 0.5205, 0.5185, 0.5199, 0.5213, 0.5167,
        0.5195, 0.5159, 0.5208, 0.5167, 0.5170, 0.5174, 0.5176],
       device='cuda:0') torch.Size([16])
percent tensor([0.5080, 0.5054, 0.5079, 0.5135, 0.5060, 0.5158, 0.5013, 0.5040, 0.5058,
        0.5054, 0.5062, 0.5064, 0.5093, 0.5054, 0.5109, 0.5112],
       device='cuda:0') torch.Size([16])
percent tensor([0.5103, 0.4798, 0.5787, 0.5853, 0.5877, 0.5363, 0.5375, 0.5713, 0.5561,
        0.5110, 0.5287, 0.5435, 0.4413, 0.5790, 0.5068, 0.5067],
       device='cuda:0') torch.Size([16])
percent tensor([0.5986, 0.6058, 0.5998, 0.5968, 0.6032, 0.5796, 0.6109, 0.6127, 0.6050,
        0.6042, 0.6045, 0.6084, 0.6010, 0.6014, 0.6080, 0.5960],
       device='cuda:0') torch.Size([16])
percent tensor([0.5911, 0.6100, 0.6033, 0.6344, 0.6189, 0.6561, 0.5879, 0.5976, 0.6140,
        0.6202, 0.6142, 0.6248, 0.6204, 0.6369, 0.5951, 0.6386],
       device='cuda:0') torch.Size([16])
percent tensor([0.6284, 0.6295, 0.6363, 0.6644, 0.6492, 0.7238, 0.6213, 0.6052, 0.6536,
        0.6194, 0.6527, 0.6394, 0.6595, 0.6696, 0.6087, 0.6571],
       device='cuda:0') torch.Size([16])
percent tensor([0.6127, 0.5771, 0.6162, 0.6259, 0.6386, 0.6593, 0.5980, 0.6222, 0.5878,
        0.5826, 0.5927, 0.5833, 0.5856, 0.6005, 0.5620, 0.6289],
       device='cuda:0') torch.Size([16])
percent tensor([0.9995, 0.9987, 0.9985, 0.9990, 0.9982, 0.9984, 0.9987, 0.9992, 0.9982,
        0.9986, 0.9992, 0.9984, 0.9990, 0.9992, 0.9969, 0.9993],
       device='cuda:0') torch.Size([16])
Epoch: 68 | Batch_idx: 0 |  Loss: (0.2283) |  Loss2: (0.0000) | Acc: (92.00%) (118/128)
Epoch: 68 | Batch_idx: 10 |  Loss: (0.3189) |  Loss2: (0.0000) | Acc: (89.00%) (1255/1408)
Epoch: 68 | Batch_idx: 20 |  Loss: (0.3292) |  Loss2: (0.0000) | Acc: (88.00%) (2390/2688)
Epoch: 68 | Batch_idx: 30 |  Loss: (0.3328) |  Loss2: (0.0000) | Acc: (88.00%) (3526/3968)
Epoch: 68 | Batch_idx: 40 |  Loss: (0.3291) |  Loss2: (0.0000) | Acc: (88.00%) (4666/5248)
Epoch: 68 | Batch_idx: 50 |  Loss: (0.3326) |  Loss2: (0.0000) | Acc: (88.00%) (5795/6528)
Epoch: 68 | Batch_idx: 60 |  Loss: (0.3434) |  Loss2: (0.0000) | Acc: (88.00%) (6896/7808)
Epoch: 68 | Batch_idx: 70 |  Loss: (0.3401) |  Loss2: (0.0000) | Acc: (88.00%) (8038/9088)
Epoch: 68 | Batch_idx: 80 |  Loss: (0.3338) |  Loss2: (0.0000) | Acc: (88.00%) (9187/10368)
Epoch: 68 | Batch_idx: 90 |  Loss: (0.3319) |  Loss2: (0.0000) | Acc: (88.00%) (10316/11648)
Epoch: 68 | Batch_idx: 100 |  Loss: (0.3300) |  Loss2: (0.0000) | Acc: (88.00%) (11457/12928)
Epoch: 68 | Batch_idx: 110 |  Loss: (0.3321) |  Loss2: (0.0000) | Acc: (88.00%) (12580/14208)
Epoch: 68 | Batch_idx: 120 |  Loss: (0.3289) |  Loss2: (0.0000) | Acc: (88.00%) (13733/15488)
Epoch: 68 | Batch_idx: 130 |  Loss: (0.3282) |  Loss2: (0.0000) | Acc: (88.00%) (14871/16768)
Epoch: 68 | Batch_idx: 140 |  Loss: (0.3248) |  Loss2: (0.0000) | Acc: (88.00%) (16024/18048)
Epoch: 68 | Batch_idx: 150 |  Loss: (0.3233) |  Loss2: (0.0000) | Acc: (88.00%) (17173/19328)
Epoch: 68 | Batch_idx: 160 |  Loss: (0.3228) |  Loss2: (0.0000) | Acc: (88.00%) (18315/20608)
Epoch: 68 | Batch_idx: 170 |  Loss: (0.3249) |  Loss2: (0.0000) | Acc: (88.00%) (19427/21888)
Epoch: 68 | Batch_idx: 180 |  Loss: (0.3245) |  Loss2: (0.0000) | Acc: (88.00%) (20569/23168)
Epoch: 68 | Batch_idx: 190 |  Loss: (0.3246) |  Loss2: (0.0000) | Acc: (88.00%) (21704/24448)
Epoch: 68 | Batch_idx: 200 |  Loss: (0.3244) |  Loss2: (0.0000) | Acc: (88.00%) (22856/25728)
Epoch: 68 | Batch_idx: 210 |  Loss: (0.3237) |  Loss2: (0.0000) | Acc: (88.00%) (24001/27008)
Epoch: 68 | Batch_idx: 220 |  Loss: (0.3219) |  Loss2: (0.0000) | Acc: (88.00%) (25155/28288)
Epoch: 68 | Batch_idx: 230 |  Loss: (0.3217) |  Loss2: (0.0000) | Acc: (88.00%) (26295/29568)
Epoch: 68 | Batch_idx: 240 |  Loss: (0.3208) |  Loss2: (0.0000) | Acc: (88.00%) (27441/30848)
Epoch: 68 | Batch_idx: 250 |  Loss: (0.3216) |  Loss2: (0.0000) | Acc: (88.00%) (28565/32128)
Epoch: 68 | Batch_idx: 260 |  Loss: (0.3206) |  Loss2: (0.0000) | Acc: (88.00%) (29719/33408)
Epoch: 68 | Batch_idx: 270 |  Loss: (0.3217) |  Loss2: (0.0000) | Acc: (88.00%) (30849/34688)
Epoch: 68 | Batch_idx: 280 |  Loss: (0.3234) |  Loss2: (0.0000) | Acc: (88.00%) (31958/35968)
Epoch: 68 | Batch_idx: 290 |  Loss: (0.3229) |  Loss2: (0.0000) | Acc: (88.00%) (33106/37248)
Epoch: 68 | Batch_idx: 300 |  Loss: (0.3227) |  Loss2: (0.0000) | Acc: (88.00%) (34243/38528)
Epoch: 68 | Batch_idx: 310 |  Loss: (0.3224) |  Loss2: (0.0000) | Acc: (88.00%) (35397/39808)
Epoch: 68 | Batch_idx: 320 |  Loss: (0.3224) |  Loss2: (0.0000) | Acc: (88.00%) (36531/41088)
Epoch: 68 | Batch_idx: 330 |  Loss: (0.3214) |  Loss2: (0.0000) | Acc: (88.00%) (37681/42368)
Epoch: 68 | Batch_idx: 340 |  Loss: (0.3233) |  Loss2: (0.0000) | Acc: (88.00%) (38799/43648)
Epoch: 68 | Batch_idx: 350 |  Loss: (0.3236) |  Loss2: (0.0000) | Acc: (88.00%) (39940/44928)
Epoch: 68 | Batch_idx: 360 |  Loss: (0.3233) |  Loss2: (0.0000) | Acc: (88.00%) (41076/46208)
Epoch: 68 | Batch_idx: 370 |  Loss: (0.3229) |  Loss2: (0.0000) | Acc: (88.00%) (42213/47488)
Epoch: 68 | Batch_idx: 380 |  Loss: (0.3235) |  Loss2: (0.0000) | Acc: (88.00%) (43333/48768)
Epoch: 68 | Batch_idx: 390 |  Loss: (0.3235) |  Loss2: (0.0000) | Acc: (88.00%) (44432/50000)
# TEST : Loss: (0.4430) | Acc: (84.00%) (8491/10000)
percent tensor([0.5161, 0.5176, 0.5208, 0.5193, 0.5205, 0.5184, 0.5196, 0.5213, 0.5164,
        0.5192, 0.5154, 0.5207, 0.5163, 0.5166, 0.5173, 0.5173],
       device='cuda:0') torch.Size([16])
percent tensor([0.5074, 0.5040, 0.5074, 0.5129, 0.5053, 0.5157, 0.5001, 0.5034, 0.5044,
        0.5040, 0.5044, 0.5054, 0.5080, 0.5037, 0.5099, 0.5104],
       device='cuda:0') torch.Size([16])
percent tensor([0.5058, 0.4709, 0.5730, 0.5803, 0.5835, 0.5352, 0.5312, 0.5694, 0.5506,
        0.4989, 0.5161, 0.5342, 0.4337, 0.5727, 0.5022, 0.5000],
       device='cuda:0') torch.Size([16])
percent tensor([0.5971, 0.6043, 0.5981, 0.5946, 0.6023, 0.5773, 0.6098, 0.6124, 0.6032,
        0.6012, 0.6009, 0.6057, 0.5993, 0.5984, 0.6068, 0.5935],
       device='cuda:0') torch.Size([16])
percent tensor([0.5804, 0.5988, 0.5953, 0.6260, 0.6097, 0.6467, 0.5771, 0.5881, 0.6020,
        0.6079, 0.6001, 0.6134, 0.6096, 0.6239, 0.5839, 0.6274],
       device='cuda:0') torch.Size([16])
percent tensor([0.6200, 0.6253, 0.6332, 0.6637, 0.6431, 0.7223, 0.6131, 0.5910, 0.6515,
        0.6163, 0.6517, 0.6393, 0.6597, 0.6681, 0.5990, 0.6496],
       device='cuda:0') torch.Size([16])
percent tensor([0.6215, 0.5893, 0.6232, 0.6340, 0.6433, 0.6659, 0.6063, 0.6225, 0.6020,
        0.5977, 0.6091, 0.5949, 0.6019, 0.6172, 0.5671, 0.6355],
       device='cuda:0') torch.Size([16])
percent tensor([0.9995, 0.9987, 0.9985, 0.9990, 0.9984, 0.9985, 0.9988, 0.9992, 0.9983,
        0.9986, 0.9992, 0.9985, 0.9991, 0.9993, 0.9969, 0.9994],
       device='cuda:0') torch.Size([16])
Epoch: 69 | Batch_idx: 0 |  Loss: (0.1814) |  Loss2: (0.0000) | Acc: (94.00%) (121/128)
Epoch: 69 | Batch_idx: 10 |  Loss: (0.3200) |  Loss2: (0.0000) | Acc: (88.00%) (1250/1408)
Epoch: 69 | Batch_idx: 20 |  Loss: (0.3111) |  Loss2: (0.0000) | Acc: (89.00%) (2402/2688)
Epoch: 69 | Batch_idx: 30 |  Loss: (0.3200) |  Loss2: (0.0000) | Acc: (89.00%) (3534/3968)
Epoch: 69 | Batch_idx: 40 |  Loss: (0.3251) |  Loss2: (0.0000) | Acc: (88.00%) (4652/5248)
Epoch: 69 | Batch_idx: 50 |  Loss: (0.3197) |  Loss2: (0.0000) | Acc: (88.00%) (5802/6528)
Epoch: 69 | Batch_idx: 60 |  Loss: (0.3200) |  Loss2: (0.0000) | Acc: (88.00%) (6938/7808)
Epoch: 69 | Batch_idx: 70 |  Loss: (0.3197) |  Loss2: (0.0000) | Acc: (88.00%) (8076/9088)
Epoch: 69 | Batch_idx: 80 |  Loss: (0.3164) |  Loss2: (0.0000) | Acc: (88.00%) (9225/10368)
Epoch: 69 | Batch_idx: 90 |  Loss: (0.3185) |  Loss2: (0.0000) | Acc: (88.00%) (10360/11648)
Epoch: 69 | Batch_idx: 100 |  Loss: (0.3218) |  Loss2: (0.0000) | Acc: (88.00%) (11482/12928)
Epoch: 69 | Batch_idx: 110 |  Loss: (0.3193) |  Loss2: (0.0000) | Acc: (88.00%) (12626/14208)
Epoch: 69 | Batch_idx: 120 |  Loss: (0.3203) |  Loss2: (0.0000) | Acc: (88.00%) (13763/15488)
Epoch: 69 | Batch_idx: 130 |  Loss: (0.3243) |  Loss2: (0.0000) | Acc: (88.00%) (14877/16768)
Epoch: 69 | Batch_idx: 140 |  Loss: (0.3222) |  Loss2: (0.0000) | Acc: (88.00%) (16024/18048)
Epoch: 69 | Batch_idx: 150 |  Loss: (0.3208) |  Loss2: (0.0000) | Acc: (88.00%) (17168/19328)
Epoch: 69 | Batch_idx: 160 |  Loss: (0.3193) |  Loss2: (0.0000) | Acc: (88.00%) (18310/20608)
Epoch: 69 | Batch_idx: 170 |  Loss: (0.3196) |  Loss2: (0.0000) | Acc: (88.00%) (19446/21888)
Epoch: 69 | Batch_idx: 180 |  Loss: (0.3179) |  Loss2: (0.0000) | Acc: (88.00%) (20603/23168)
Epoch: 69 | Batch_idx: 190 |  Loss: (0.3159) |  Loss2: (0.0000) | Acc: (88.00%) (21753/24448)
Epoch: 69 | Batch_idx: 200 |  Loss: (0.3152) |  Loss2: (0.0000) | Acc: (89.00%) (22903/25728)
Epoch: 69 | Batch_idx: 210 |  Loss: (0.3163) |  Loss2: (0.0000) | Acc: (88.00%) (24035/27008)
Epoch: 69 | Batch_idx: 220 |  Loss: (0.3149) |  Loss2: (0.0000) | Acc: (89.00%) (25186/28288)
Epoch: 69 | Batch_idx: 230 |  Loss: (0.3151) |  Loss2: (0.0000) | Acc: (88.00%) (26306/29568)
Epoch: 69 | Batch_idx: 240 |  Loss: (0.3154) |  Loss2: (0.0000) | Acc: (88.00%) (27443/30848)
Epoch: 69 | Batch_idx: 250 |  Loss: (0.3160) |  Loss2: (0.0000) | Acc: (88.00%) (28574/32128)
Epoch: 69 | Batch_idx: 260 |  Loss: (0.3143) |  Loss2: (0.0000) | Acc: (88.00%) (29733/33408)
Epoch: 69 | Batch_idx: 270 |  Loss: (0.3152) |  Loss2: (0.0000) | Acc: (88.00%) (30859/34688)
Epoch: 69 | Batch_idx: 280 |  Loss: (0.3151) |  Loss2: (0.0000) | Acc: (88.00%) (31989/35968)
Epoch: 69 | Batch_idx: 290 |  Loss: (0.3144) |  Loss2: (0.0000) | Acc: (88.00%) (33128/37248)
Epoch: 69 | Batch_idx: 300 |  Loss: (0.3142) |  Loss2: (0.0000) | Acc: (88.00%) (34278/38528)
Epoch: 69 | Batch_idx: 310 |  Loss: (0.3131) |  Loss2: (0.0000) | Acc: (89.00%) (35435/39808)
Epoch: 69 | Batch_idx: 320 |  Loss: (0.3147) |  Loss2: (0.0000) | Acc: (88.00%) (36548/41088)
Epoch: 69 | Batch_idx: 330 |  Loss: (0.3147) |  Loss2: (0.0000) | Acc: (88.00%) (37689/42368)
Epoch: 69 | Batch_idx: 340 |  Loss: (0.3148) |  Loss2: (0.0000) | Acc: (88.00%) (38823/43648)
Epoch: 69 | Batch_idx: 350 |  Loss: (0.3142) |  Loss2: (0.0000) | Acc: (88.00%) (39975/44928)
Epoch: 69 | Batch_idx: 360 |  Loss: (0.3140) |  Loss2: (0.0000) | Acc: (88.00%) (41118/46208)
Epoch: 69 | Batch_idx: 370 |  Loss: (0.3152) |  Loss2: (0.0000) | Acc: (88.00%) (42245/47488)
Epoch: 69 | Batch_idx: 380 |  Loss: (0.3147) |  Loss2: (0.0000) | Acc: (88.00%) (43391/48768)
Epoch: 69 | Batch_idx: 390 |  Loss: (0.3140) |  Loss2: (0.0000) | Acc: (88.00%) (44497/50000)
# TEST : Loss: (0.4324) | Acc: (85.00%) (8510/10000)
percent tensor([0.5160, 0.5175, 0.5209, 0.5194, 0.5206, 0.5186, 0.5195, 0.5213, 0.5162,
        0.5190, 0.5152, 0.5206, 0.5160, 0.5165, 0.5174, 0.5172],
       device='cuda:0') torch.Size([16])
percent tensor([0.5075, 0.5045, 0.5079, 0.5136, 0.5059, 0.5162, 0.5004, 0.5042, 0.5045,
        0.5042, 0.5041, 0.5058, 0.5082, 0.5036, 0.5104, 0.5106],
       device='cuda:0') torch.Size([16])
percent tensor([0.5147, 0.4781, 0.5747, 0.5824, 0.5854, 0.5442, 0.5384, 0.5716, 0.5570,
        0.5040, 0.5203, 0.5399, 0.4421, 0.5775, 0.5118, 0.5071],
       device='cuda:0') torch.Size([16])
percent tensor([0.5955, 0.6016, 0.5961, 0.5921, 0.6008, 0.5761, 0.6078, 0.6113, 0.6007,
        0.5977, 0.5968, 0.6028, 0.5967, 0.5952, 0.6052, 0.5915],
       device='cuda:0') torch.Size([16])
percent tensor([0.5849, 0.6007, 0.6011, 0.6318, 0.6156, 0.6537, 0.5795, 0.5936, 0.6039,
        0.6094, 0.5991, 0.6155, 0.6123, 0.6249, 0.5864, 0.6337],
       device='cuda:0') torch.Size([16])
percent tensor([0.6220, 0.6294, 0.6382, 0.6707, 0.6462, 0.7268, 0.6148, 0.5879, 0.6585,
        0.6224, 0.6613, 0.6469, 0.6673, 0.6752, 0.5985, 0.6527],
       device='cuda:0') torch.Size([16])
percent tensor([0.6229, 0.5948, 0.6211, 0.6323, 0.6408, 0.6659, 0.6072, 0.6162, 0.6088,
        0.6048, 0.6176, 0.5948, 0.6099, 0.6242, 0.5650, 0.6358],
       device='cuda:0') torch.Size([16])
percent tensor([0.9996, 0.9988, 0.9986, 0.9991, 0.9984, 0.9985, 0.9989, 0.9993, 0.9984,
        0.9987, 0.9993, 0.9987, 0.9991, 0.9994, 0.9970, 0.9994],
       device='cuda:0') torch.Size([16])
Epoch: 70 | Batch_idx: 0 |  Loss: (0.3297) |  Loss2: (0.0000) | Acc: (85.00%) (110/128)
Epoch: 70 | Batch_idx: 10 |  Loss: (0.2829) |  Loss2: (0.0000) | Acc: (89.00%) (1257/1408)
Epoch: 70 | Batch_idx: 20 |  Loss: (0.3020) |  Loss2: (0.0000) | Acc: (88.00%) (2390/2688)
Epoch: 70 | Batch_idx: 30 |  Loss: (0.3097) |  Loss2: (0.0000) | Acc: (88.00%) (3520/3968)
Epoch: 70 | Batch_idx: 40 |  Loss: (0.3207) |  Loss2: (0.0000) | Acc: (88.00%) (4657/5248)
Epoch: 70 | Batch_idx: 50 |  Loss: (0.3126) |  Loss2: (0.0000) | Acc: (89.00%) (5812/6528)
Epoch: 70 | Batch_idx: 60 |  Loss: (0.3093) |  Loss2: (0.0000) | Acc: (89.00%) (6959/7808)
Epoch: 70 | Batch_idx: 70 |  Loss: (0.3120) |  Loss2: (0.0000) | Acc: (89.00%) (8096/9088)
Epoch: 70 | Batch_idx: 80 |  Loss: (0.3153) |  Loss2: (0.0000) | Acc: (88.00%) (9221/10368)
Epoch: 70 | Batch_idx: 90 |  Loss: (0.3143) |  Loss2: (0.0000) | Acc: (89.00%) (10371/11648)
Epoch: 70 | Batch_idx: 100 |  Loss: (0.3135) |  Loss2: (0.0000) | Acc: (89.00%) (11515/12928)
Epoch: 70 | Batch_idx: 110 |  Loss: (0.3112) |  Loss2: (0.0000) | Acc: (89.00%) (12666/14208)
Epoch: 70 | Batch_idx: 120 |  Loss: (0.3125) |  Loss2: (0.0000) | Acc: (89.00%) (13803/15488)
Epoch: 70 | Batch_idx: 130 |  Loss: (0.3142) |  Loss2: (0.0000) | Acc: (89.00%) (14930/16768)
Epoch: 70 | Batch_idx: 140 |  Loss: (0.3131) |  Loss2: (0.0000) | Acc: (89.00%) (16071/18048)
Epoch: 70 | Batch_idx: 150 |  Loss: (0.3159) |  Loss2: (0.0000) | Acc: (88.00%) (17196/19328)
Epoch: 70 | Batch_idx: 160 |  Loss: (0.3172) |  Loss2: (0.0000) | Acc: (88.00%) (18316/20608)
Epoch: 70 | Batch_idx: 170 |  Loss: (0.3169) |  Loss2: (0.0000) | Acc: (88.00%) (19454/21888)
Epoch: 70 | Batch_idx: 180 |  Loss: (0.3153) |  Loss2: (0.0000) | Acc: (88.00%) (20599/23168)
Epoch: 70 | Batch_idx: 190 |  Loss: (0.3158) |  Loss2: (0.0000) | Acc: (88.00%) (21748/24448)
Epoch: 70 | Batch_idx: 200 |  Loss: (0.3169) |  Loss2: (0.0000) | Acc: (88.00%) (22885/25728)
Epoch: 70 | Batch_idx: 210 |  Loss: (0.3159) |  Loss2: (0.0000) | Acc: (89.00%) (24040/27008)
Epoch: 70 | Batch_idx: 220 |  Loss: (0.3151) |  Loss2: (0.0000) | Acc: (89.00%) (25193/28288)
Epoch: 70 | Batch_idx: 230 |  Loss: (0.3150) |  Loss2: (0.0000) | Acc: (89.00%) (26342/29568)
Epoch: 70 | Batch_idx: 240 |  Loss: (0.3145) |  Loss2: (0.0000) | Acc: (89.00%) (27492/30848)
Epoch: 70 | Batch_idx: 250 |  Loss: (0.3149) |  Loss2: (0.0000) | Acc: (89.00%) (28624/32128)
Epoch: 70 | Batch_idx: 260 |  Loss: (0.3145) |  Loss2: (0.0000) | Acc: (89.00%) (29764/33408)
Epoch: 70 | Batch_idx: 270 |  Loss: (0.3142) |  Loss2: (0.0000) | Acc: (89.00%) (30907/34688)
Epoch: 70 | Batch_idx: 280 |  Loss: (0.3155) |  Loss2: (0.0000) | Acc: (89.00%) (32022/35968)
Epoch: 70 | Batch_idx: 290 |  Loss: (0.3160) |  Loss2: (0.0000) | Acc: (89.00%) (33166/37248)
Epoch: 70 | Batch_idx: 300 |  Loss: (0.3157) |  Loss2: (0.0000) | Acc: (89.00%) (34306/38528)
Epoch: 70 | Batch_idx: 310 |  Loss: (0.3154) |  Loss2: (0.0000) | Acc: (89.00%) (35448/39808)
Epoch: 70 | Batch_idx: 320 |  Loss: (0.3155) |  Loss2: (0.0000) | Acc: (89.00%) (36605/41088)
Epoch: 70 | Batch_idx: 330 |  Loss: (0.3147) |  Loss2: (0.0000) | Acc: (89.00%) (37754/42368)
Epoch: 70 | Batch_idx: 340 |  Loss: (0.3148) |  Loss2: (0.0000) | Acc: (89.00%) (38899/43648)
Epoch: 70 | Batch_idx: 350 |  Loss: (0.3142) |  Loss2: (0.0000) | Acc: (89.00%) (40055/44928)
Epoch: 70 | Batch_idx: 360 |  Loss: (0.3140) |  Loss2: (0.0000) | Acc: (89.00%) (41194/46208)
Epoch: 70 | Batch_idx: 370 |  Loss: (0.3136) |  Loss2: (0.0000) | Acc: (89.00%) (42342/47488)
Epoch: 70 | Batch_idx: 380 |  Loss: (0.3153) |  Loss2: (0.0000) | Acc: (89.00%) (43453/48768)
Epoch: 70 | Batch_idx: 390 |  Loss: (0.3143) |  Loss2: (0.0000) | Acc: (89.00%) (44582/50000)
=> saving checkpoint 'drive/app/torch/save_Schedule/checkpoint_070.pth.tar'
# TEST : Loss: (0.4262) | Acc: (85.00%) (8528/10000)
percent tensor([0.5168, 0.5184, 0.5220, 0.5205, 0.5217, 0.5194, 0.5205, 0.5225, 0.5171,
        0.5199, 0.5159, 0.5217, 0.5169, 0.5174, 0.5183, 0.5181],
       device='cuda:0') torch.Size([16])
percent tensor([0.5071, 0.5038, 0.5077, 0.5132, 0.5056, 0.5161, 0.4997, 0.5040, 0.5038,
        0.5035, 0.5031, 0.5054, 0.5077, 0.5027, 0.5097, 0.5098],
       device='cuda:0') torch.Size([16])
percent tensor([0.5162, 0.4787, 0.5730, 0.5809, 0.5838, 0.5434, 0.5384, 0.5709, 0.5573,
        0.5041, 0.5191, 0.5392, 0.4453, 0.5768, 0.5121, 0.5073],
       device='cuda:0') torch.Size([16])
percent tensor([0.5922, 0.5978, 0.5930, 0.5885, 0.5978, 0.5724, 0.6042, 0.6081, 0.5972,
        0.5932, 0.5919, 0.5988, 0.5933, 0.5906, 0.6015, 0.5875],
       device='cuda:0') torch.Size([16])
percent tensor([0.5807, 0.5960, 0.5990, 0.6291, 0.6132, 0.6522, 0.5749, 0.5904, 0.5995,
        0.6044, 0.5928, 0.6104, 0.6078, 0.6199, 0.5807, 0.6298],
       device='cuda:0') torch.Size([16])
percent tensor([0.6186, 0.6291, 0.6380, 0.6705, 0.6449, 0.7270, 0.6126, 0.5824, 0.6590,
        0.6223, 0.6631, 0.6478, 0.6673, 0.6762, 0.5947, 0.6496],
       device='cuda:0') torch.Size([16])
percent tensor([0.6249, 0.6019, 0.6216, 0.6328, 0.6421, 0.6684, 0.6114, 0.6152, 0.6151,
        0.6121, 0.6258, 0.5973, 0.6164, 0.6318, 0.5664, 0.6371],
       device='cuda:0') torch.Size([16])
percent tensor([0.9996, 0.9989, 0.9985, 0.9991, 0.9985, 0.9986, 0.9990, 0.9993, 0.9985,
        0.9987, 0.9994, 0.9988, 0.9992, 0.9994, 0.9971, 0.9995],
       device='cuda:0') torch.Size([16])
Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 3, 3, 3]) tensor(174.0812, device='cuda:0')
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(809.1226, device='cuda:0')
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(799.4044, device='cuda:0')
Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([128, 64, 3, 3]) tensor(1521.6780, device='cuda:0')
Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([128, 64, 1, 1]) tensor(499.8441, device='cuda:0')
Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([128, 128, 3, 3]) tensor(2217.1240, device='cuda:0')
Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([256, 128, 3, 3]) tensor(4284.0659, device='cuda:0')
Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([256, 128, 1, 1]) tensor(1410.3120, device='cuda:0')
Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([256, 256, 3, 3]) tensor(6118.9175, device='cuda:0')
Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([512, 256, 3, 3]) tensor(11965.4863, device='cuda:0')
Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([512, 256, 1, 1]) tensor(3979.3711, device='cuda:0')
Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([512, 512, 3, 3]) tensor(16849.2988, device='cuda:0')
Epoch: 71 | Batch_idx: 0 |  Loss: (0.3358) |  Loss2: (0.0000) | Acc: (90.00%) (116/128)
Epoch: 71 | Batch_idx: 10 |  Loss: (0.3140) |  Loss2: (0.0000) | Acc: (89.00%) (1267/1408)
Epoch: 71 | Batch_idx: 20 |  Loss: (0.3085) |  Loss2: (0.0000) | Acc: (90.00%) (2421/2688)
Epoch: 71 | Batch_idx: 30 |  Loss: (0.3045) |  Loss2: (0.0000) | Acc: (89.00%) (3564/3968)
Epoch: 71 | Batch_idx: 40 |  Loss: (0.2991) |  Loss2: (0.0000) | Acc: (89.00%) (4721/5248)
Epoch: 71 | Batch_idx: 50 |  Loss: (0.3003) |  Loss2: (0.0000) | Acc: (89.00%) (5860/6528)
Epoch: 71 | Batch_idx: 60 |  Loss: (0.3097) |  Loss2: (0.0000) | Acc: (89.00%) (6980/7808)
Epoch: 71 | Batch_idx: 70 |  Loss: (0.3076) |  Loss2: (0.0000) | Acc: (89.00%) (8128/9088)
Epoch: 71 | Batch_idx: 80 |  Loss: (0.3026) |  Loss2: (0.0000) | Acc: (89.00%) (9278/10368)
Epoch: 71 | Batch_idx: 90 |  Loss: (0.3047) |  Loss2: (0.0000) | Acc: (89.00%) (10423/11648)
Epoch: 71 | Batch_idx: 100 |  Loss: (0.3093) |  Loss2: (0.0000) | Acc: (89.00%) (11550/12928)
Epoch: 71 | Batch_idx: 110 |  Loss: (0.3071) |  Loss2: (0.0000) | Acc: (89.00%) (12716/14208)
Epoch: 71 | Batch_idx: 120 |  Loss: (0.3076) |  Loss2: (0.0000) | Acc: (89.00%) (13853/15488)
Epoch: 71 | Batch_idx: 130 |  Loss: (0.3077) |  Loss2: (0.0000) | Acc: (89.00%) (15002/16768)
Epoch: 71 | Batch_idx: 140 |  Loss: (0.3087) |  Loss2: (0.0000) | Acc: (89.00%) (16129/18048)
Epoch: 71 | Batch_idx: 150 |  Loss: (0.3105) |  Loss2: (0.0000) | Acc: (89.00%) (17269/19328)
Epoch: 71 | Batch_idx: 160 |  Loss: (0.3115) |  Loss2: (0.0000) | Acc: (89.00%) (18398/20608)
Epoch: 71 | Batch_idx: 170 |  Loss: (0.3118) |  Loss2: (0.0000) | Acc: (89.00%) (19530/21888)
Epoch: 71 | Batch_idx: 180 |  Loss: (0.3102) |  Loss2: (0.0000) | Acc: (89.00%) (20683/23168)
Epoch: 71 | Batch_idx: 190 |  Loss: (0.3081) |  Loss2: (0.0000) | Acc: (89.00%) (21844/24448)
Epoch: 71 | Batch_idx: 200 |  Loss: (0.3063) |  Loss2: (0.0000) | Acc: (89.00%) (23014/25728)
Epoch: 71 | Batch_idx: 210 |  Loss: (0.3072) |  Loss2: (0.0000) | Acc: (89.00%) (24161/27008)
Epoch: 71 | Batch_idx: 220 |  Loss: (0.3060) |  Loss2: (0.0000) | Acc: (89.00%) (25311/28288)
Epoch: 71 | Batch_idx: 230 |  Loss: (0.3062) |  Loss2: (0.0000) | Acc: (89.00%) (26457/29568)
Epoch: 71 | Batch_idx: 240 |  Loss: (0.3067) |  Loss2: (0.0000) | Acc: (89.00%) (27587/30848)
Epoch: 71 | Batch_idx: 250 |  Loss: (0.3068) |  Loss2: (0.0000) | Acc: (89.00%) (28741/32128)
Epoch: 71 | Batch_idx: 260 |  Loss: (0.3068) |  Loss2: (0.0000) | Acc: (89.00%) (29898/33408)
Epoch: 71 | Batch_idx: 270 |  Loss: (0.3080) |  Loss2: (0.0000) | Acc: (89.00%) (31018/34688)
Epoch: 71 | Batch_idx: 280 |  Loss: (0.3086) |  Loss2: (0.0000) | Acc: (89.00%) (32155/35968)
Epoch: 71 | Batch_idx: 290 |  Loss: (0.3080) |  Loss2: (0.0000) | Acc: (89.00%) (33312/37248)
Epoch: 71 | Batch_idx: 300 |  Loss: (0.3070) |  Loss2: (0.0000) | Acc: (89.00%) (34473/38528)
Epoch: 71 | Batch_idx: 310 |  Loss: (0.3055) |  Loss2: (0.0000) | Acc: (89.00%) (35656/39808)
Epoch: 71 | Batch_idx: 320 |  Loss: (0.3054) |  Loss2: (0.0000) | Acc: (89.00%) (36798/41088)
Epoch: 71 | Batch_idx: 330 |  Loss: (0.3053) |  Loss2: (0.0000) | Acc: (89.00%) (37951/42368)
Epoch: 71 | Batch_idx: 340 |  Loss: (0.3048) |  Loss2: (0.0000) | Acc: (89.00%) (39112/43648)
Epoch: 71 | Batch_idx: 350 |  Loss: (0.3055) |  Loss2: (0.0000) | Acc: (89.00%) (40249/44928)
Epoch: 71 | Batch_idx: 360 |  Loss: (0.3057) |  Loss2: (0.0000) | Acc: (89.00%) (41388/46208)
Epoch: 71 | Batch_idx: 370 |  Loss: (0.3062) |  Loss2: (0.0000) | Acc: (89.00%) (42528/47488)
Epoch: 71 | Batch_idx: 380 |  Loss: (0.3052) |  Loss2: (0.0000) | Acc: (89.00%) (43675/48768)
Epoch: 71 | Batch_idx: 390 |  Loss: (0.3055) |  Loss2: (0.0000) | Acc: (89.00%) (44771/50000)
# TEST : Loss: (0.4244) | Acc: (85.00%) (8544/10000)
percent tensor([0.5173, 0.5190, 0.5227, 0.5213, 0.5224, 0.5202, 0.5211, 0.5233, 0.5175,
        0.5205, 0.5163, 0.5223, 0.5173, 0.5179, 0.5190, 0.5186],
       device='cuda:0') torch.Size([16])
percent tensor([0.5066, 0.5034, 0.5077, 0.5131, 0.5056, 0.5159, 0.4994, 0.5042, 0.5035,
        0.5030, 0.5025, 0.5053, 0.5074, 0.5022, 0.5093, 0.5093],
       device='cuda:0') torch.Size([16])
percent tensor([0.5195, 0.4810, 0.5723, 0.5816, 0.5834, 0.5487, 0.5392, 0.5708, 0.5594,
        0.5047, 0.5207, 0.5391, 0.4489, 0.5784, 0.5158, 0.5105],
       device='cuda:0') torch.Size([16])
percent tensor([0.5955, 0.6006, 0.5955, 0.5908, 0.6011, 0.5758, 0.6074, 0.6118, 0.6000,
        0.5954, 0.5938, 0.6010, 0.5960, 0.5930, 0.6052, 0.5903],
       device='cuda:0') torch.Size([16])
percent tensor([0.5803, 0.5946, 0.6006, 0.6303, 0.6164, 0.6542, 0.5744, 0.5929, 0.5984,
        0.6021, 0.5882, 0.6086, 0.6062, 0.6183, 0.5794, 0.6306],
       device='cuda:0') torch.Size([16])
percent tensor([0.6192, 0.6330, 0.6401, 0.6716, 0.6464, 0.7294, 0.6144, 0.5785, 0.6630,
        0.6255, 0.6684, 0.6501, 0.6730, 0.6791, 0.5944, 0.6516],
       device='cuda:0') torch.Size([16])
percent tensor([0.6256, 0.6062, 0.6272, 0.6380, 0.6498, 0.6698, 0.6149, 0.6193, 0.6199,
        0.6180, 0.6303, 0.6012, 0.6177, 0.6368, 0.5682, 0.6382],
       device='cuda:0') torch.Size([16])
percent tensor([0.9997, 0.9989, 0.9987, 0.9991, 0.9986, 0.9988, 0.9991, 0.9993, 0.9987,
        0.9988, 0.9994, 0.9988, 0.9993, 0.9995, 0.9972, 0.9996],
       device='cuda:0') torch.Size([16])
True Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=128, out_features=16, bias=False)
False Linear(in_features=16, out_features=2, bias=False)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=128, out_features=16, bias=False)
False Linear(in_features=16, out_features=2, bias=False)
True Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=256, out_features=32, bias=False)
False Linear(in_features=32, out_features=2, bias=False)
True Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=256, out_features=32, bias=False)
False Linear(in_features=32, out_features=2, bias=False)
True Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=512, out_features=64, bias=False)
False Linear(in_features=64, out_features=2, bias=False)
True Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=512, out_features=64, bias=False)
False Linear(in_features=64, out_features=2, bias=False)
True Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1024, out_features=128, bias=False)
False Linear(in_features=128, out_features=2, bias=False)
True Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1024, out_features=128, bias=False)
False Linear(in_features=128, out_features=2, bias=False)
True Linear(in_features=512, out_features=10, bias=True)
Epoch: 72 | Batch_idx: 0 |  Loss: (0.3163) |  Loss2: (0.0000) | Acc: (87.00%) (112/128)
Epoch: 72 | Batch_idx: 10 |  Loss: (0.3153) |  Loss2: (0.0000) | Acc: (89.00%) (1259/1408)
Epoch: 72 | Batch_idx: 20 |  Loss: (0.3055) |  Loss2: (0.0000) | Acc: (89.00%) (2411/2688)
Epoch: 72 | Batch_idx: 30 |  Loss: (0.3004) |  Loss2: (0.0000) | Acc: (89.00%) (3567/3968)
Epoch: 72 | Batch_idx: 40 |  Loss: (0.3035) |  Loss2: (0.0000) | Acc: (89.00%) (4709/5248)
Epoch: 72 | Batch_idx: 50 |  Loss: (0.3081) |  Loss2: (0.0000) | Acc: (89.00%) (5850/6528)
Epoch: 72 | Batch_idx: 60 |  Loss: (0.3053) |  Loss2: (0.0000) | Acc: (89.00%) (7000/7808)
Epoch: 72 | Batch_idx: 70 |  Loss: (0.3065) |  Loss2: (0.0000) | Acc: (89.00%) (8143/9088)
Epoch: 72 | Batch_idx: 80 |  Loss: (0.3058) |  Loss2: (0.0000) | Acc: (89.00%) (9296/10368)
Epoch: 72 | Batch_idx: 90 |  Loss: (0.3075) |  Loss2: (0.0000) | Acc: (89.00%) (10430/11648)
Epoch: 72 | Batch_idx: 100 |  Loss: (0.3074) |  Loss2: (0.0000) | Acc: (89.00%) (11570/12928)
Epoch: 72 | Batch_idx: 110 |  Loss: (0.3095) |  Loss2: (0.0000) | Acc: (89.00%) (12699/14208)
Epoch: 72 | Batch_idx: 120 |  Loss: (0.3098) |  Loss2: (0.0000) | Acc: (89.00%) (13844/15488)
Epoch: 72 | Batch_idx: 130 |  Loss: (0.3086) |  Loss2: (0.0000) | Acc: (89.00%) (14986/16768)
Epoch: 72 | Batch_idx: 140 |  Loss: (0.3085) |  Loss2: (0.0000) | Acc: (89.00%) (16133/18048)
Epoch: 72 | Batch_idx: 150 |  Loss: (0.3074) |  Loss2: (0.0000) | Acc: (89.00%) (17283/19328)
Epoch: 72 | Batch_idx: 160 |  Loss: (0.3057) |  Loss2: (0.0000) | Acc: (89.00%) (18435/20608)
Epoch: 72 | Batch_idx: 170 |  Loss: (0.3063) |  Loss2: (0.0000) | Acc: (89.00%) (19585/21888)
Epoch: 72 | Batch_idx: 180 |  Loss: (0.3056) |  Loss2: (0.0000) | Acc: (89.00%) (20728/23168)
Epoch: 72 | Batch_idx: 190 |  Loss: (0.3055) |  Loss2: (0.0000) | Acc: (89.00%) (21873/24448)
Epoch: 72 | Batch_idx: 200 |  Loss: (0.3073) |  Loss2: (0.0000) | Acc: (89.00%) (22995/25728)
Epoch: 72 | Batch_idx: 210 |  Loss: (0.3075) |  Loss2: (0.0000) | Acc: (89.00%) (24148/27008)
Epoch: 72 | Batch_idx: 220 |  Loss: (0.3076) |  Loss2: (0.0000) | Acc: (89.00%) (25289/28288)
Epoch: 72 | Batch_idx: 230 |  Loss: (0.3066) |  Loss2: (0.0000) | Acc: (89.00%) (26438/29568)
Epoch: 72 | Batch_idx: 240 |  Loss: (0.3079) |  Loss2: (0.0000) | Acc: (89.00%) (27574/30848)
Epoch: 72 | Batch_idx: 250 |  Loss: (0.3071) |  Loss2: (0.0000) | Acc: (89.00%) (28728/32128)
Epoch: 72 | Batch_idx: 260 |  Loss: (0.3064) |  Loss2: (0.0000) | Acc: (89.00%) (29883/33408)
Epoch: 72 | Batch_idx: 270 |  Loss: (0.3050) |  Loss2: (0.0000) | Acc: (89.00%) (31048/34688)
Epoch: 72 | Batch_idx: 280 |  Loss: (0.3061) |  Loss2: (0.0000) | Acc: (89.00%) (32174/35968)
Epoch: 72 | Batch_idx: 290 |  Loss: (0.3057) |  Loss2: (0.0000) | Acc: (89.00%) (33323/37248)
Epoch: 72 | Batch_idx: 300 |  Loss: (0.3078) |  Loss2: (0.0000) | Acc: (89.00%) (34436/38528)
Epoch: 72 | Batch_idx: 310 |  Loss: (0.3083) |  Loss2: (0.0000) | Acc: (89.00%) (35570/39808)
Epoch: 72 | Batch_idx: 320 |  Loss: (0.3090) |  Loss2: (0.0000) | Acc: (89.00%) (36708/41088)
Epoch: 72 | Batch_idx: 330 |  Loss: (0.3104) |  Loss2: (0.0000) | Acc: (89.00%) (37821/42368)
Epoch: 72 | Batch_idx: 340 |  Loss: (0.3114) |  Loss2: (0.0000) | Acc: (89.00%) (38945/43648)
Epoch: 72 | Batch_idx: 350 |  Loss: (0.3124) |  Loss2: (0.0000) | Acc: (89.00%) (40065/44928)
Epoch: 72 | Batch_idx: 360 |  Loss: (0.3130) |  Loss2: (0.0000) | Acc: (89.00%) (41199/46208)
Epoch: 72 | Batch_idx: 370 |  Loss: (0.3130) |  Loss2: (0.0000) | Acc: (89.00%) (42336/47488)
Epoch: 72 | Batch_idx: 380 |  Loss: (0.3139) |  Loss2: (0.0000) | Acc: (89.00%) (43469/48768)
Epoch: 72 | Batch_idx: 390 |  Loss: (0.3143) |  Loss2: (0.0000) | Acc: (89.00%) (44571/50000)
# TEST : Loss: (0.4838) | Acc: (83.00%) (8383/10000)
percent tensor([0.5167, 0.5194, 0.5196, 0.5205, 0.5199, 0.5198, 0.5204, 0.5223, 0.5171,
        0.5196, 0.5163, 0.5196, 0.5169, 0.5196, 0.5187, 0.5184],
       device='cuda:0') torch.Size([16])
percent tensor([0.5059, 0.5038, 0.5081, 0.5125, 0.5059, 0.5149, 0.5005, 0.5041, 0.5048,
        0.5033, 0.5033, 0.5069, 0.5079, 0.5038, 0.5084, 0.5093],
       device='cuda:0') torch.Size([16])
percent tensor([0.5208, 0.4908, 0.5703, 0.5895, 0.5817, 0.5471, 0.5389, 0.5737, 0.5566,
        0.5108, 0.5242, 0.5268, 0.4462, 0.5825, 0.5246, 0.5194],
       device='cuda:0') torch.Size([16])
percent tensor([0.5905, 0.5984, 0.5950, 0.5936, 0.6046, 0.5742, 0.6060, 0.6113, 0.5985,
        0.5927, 0.5892, 0.6027, 0.5935, 0.5921, 0.6028, 0.5868],
       device='cuda:0') torch.Size([16])
percent tensor([0.5755, 0.5840, 0.5911, 0.6305, 0.6097, 0.6457, 0.5656, 0.5872, 0.5951,
        0.5982, 0.5924, 0.6091, 0.5942, 0.6170, 0.5720, 0.6294],
       device='cuda:0') torch.Size([16])
percent tensor([0.6216, 0.6279, 0.6355, 0.6645, 0.6369, 0.7231, 0.6212, 0.5901, 0.6597,
        0.6249, 0.6817, 0.6528, 0.6688, 0.6742, 0.5958, 0.6514],
       device='cuda:0') torch.Size([16])
percent tensor([0.6221, 0.6110, 0.6128, 0.6276, 0.6453, 0.6559, 0.6126, 0.6203, 0.6072,
        0.6086, 0.6241, 0.5890, 0.6097, 0.6250, 0.5664, 0.6461],
       device='cuda:0') torch.Size([16])
percent tensor([0.9996, 0.9988, 0.9986, 0.9990, 0.9992, 0.9984, 0.9992, 0.9994, 0.9989,
        0.9990, 0.9994, 0.9993, 0.9994, 0.9991, 0.9977, 0.9993],
       device='cuda:0') torch.Size([16])
Epoch: 73 | Batch_idx: 0 |  Loss: (0.3018) |  Loss2: (0.0000) | Acc: (91.00%) (117/128)
Epoch: 73 | Batch_idx: 10 |  Loss: (0.3090) |  Loss2: (0.0000) | Acc: (89.00%) (1261/1408)
Epoch: 73 | Batch_idx: 20 |  Loss: (0.3119) |  Loss2: (0.0000) | Acc: (88.00%) (2390/2688)
Epoch: 73 | Batch_idx: 30 |  Loss: (0.3238) |  Loss2: (0.0000) | Acc: (88.00%) (3516/3968)
Epoch: 73 | Batch_idx: 40 |  Loss: (0.3190) |  Loss2: (0.0000) | Acc: (88.00%) (4656/5248)
Epoch: 73 | Batch_idx: 50 |  Loss: (0.3086) |  Loss2: (0.0000) | Acc: (89.00%) (5815/6528)
Epoch: 73 | Batch_idx: 60 |  Loss: (0.3085) |  Loss2: (0.0000) | Acc: (89.00%) (6958/7808)
Epoch: 73 | Batch_idx: 70 |  Loss: (0.3076) |  Loss2: (0.0000) | Acc: (89.00%) (8101/9088)
Epoch: 73 | Batch_idx: 80 |  Loss: (0.3090) |  Loss2: (0.0000) | Acc: (89.00%) (9241/10368)
Epoch: 73 | Batch_idx: 90 |  Loss: (0.3070) |  Loss2: (0.0000) | Acc: (89.00%) (10393/11648)
Epoch: 73 | Batch_idx: 100 |  Loss: (0.3084) |  Loss2: (0.0000) | Acc: (89.00%) (11524/12928)
Epoch: 73 | Batch_idx: 110 |  Loss: (0.3092) |  Loss2: (0.0000) | Acc: (89.00%) (12670/14208)
Epoch: 73 | Batch_idx: 120 |  Loss: (0.3080) |  Loss2: (0.0000) | Acc: (89.00%) (13809/15488)
Epoch: 73 | Batch_idx: 130 |  Loss: (0.3101) |  Loss2: (0.0000) | Acc: (89.00%) (14926/16768)
Epoch: 73 | Batch_idx: 140 |  Loss: (0.3087) |  Loss2: (0.0000) | Acc: (89.00%) (16071/18048)
Epoch: 73 | Batch_idx: 150 |  Loss: (0.3071) |  Loss2: (0.0000) | Acc: (89.00%) (17225/19328)
Epoch: 73 | Batch_idx: 160 |  Loss: (0.3040) |  Loss2: (0.0000) | Acc: (89.00%) (18385/20608)
Epoch: 73 | Batch_idx: 170 |  Loss: (0.3029) |  Loss2: (0.0000) | Acc: (89.00%) (19530/21888)
Epoch: 73 | Batch_idx: 180 |  Loss: (0.3019) |  Loss2: (0.0000) | Acc: (89.00%) (20679/23168)
Epoch: 73 | Batch_idx: 190 |  Loss: (0.3016) |  Loss2: (0.0000) | Acc: (89.00%) (21822/24448)
Epoch: 73 | Batch_idx: 200 |  Loss: (0.3024) |  Loss2: (0.0000) | Acc: (89.00%) (22967/25728)
Epoch: 73 | Batch_idx: 210 |  Loss: (0.3032) |  Loss2: (0.0000) | Acc: (89.00%) (24099/27008)
Epoch: 73 | Batch_idx: 220 |  Loss: (0.3039) |  Loss2: (0.0000) | Acc: (89.00%) (25242/28288)
Epoch: 73 | Batch_idx: 230 |  Loss: (0.3045) |  Loss2: (0.0000) | Acc: (89.00%) (26381/29568)
Epoch: 73 | Batch_idx: 240 |  Loss: (0.3058) |  Loss2: (0.0000) | Acc: (89.00%) (27513/30848)
Epoch: 73 | Batch_idx: 250 |  Loss: (0.3063) |  Loss2: (0.0000) | Acc: (89.00%) (28653/32128)
Epoch: 73 | Batch_idx: 260 |  Loss: (0.3060) |  Loss2: (0.0000) | Acc: (89.00%) (29801/33408)
Epoch: 73 | Batch_idx: 270 |  Loss: (0.3053) |  Loss2: (0.0000) | Acc: (89.00%) (30963/34688)
Epoch: 73 | Batch_idx: 280 |  Loss: (0.3054) |  Loss2: (0.0000) | Acc: (89.00%) (32094/35968)
Epoch: 73 | Batch_idx: 290 |  Loss: (0.3062) |  Loss2: (0.0000) | Acc: (89.00%) (33226/37248)
Epoch: 73 | Batch_idx: 300 |  Loss: (0.3071) |  Loss2: (0.0000) | Acc: (89.00%) (34362/38528)
Epoch: 73 | Batch_idx: 310 |  Loss: (0.3076) |  Loss2: (0.0000) | Acc: (89.00%) (35490/39808)
Epoch: 73 | Batch_idx: 320 |  Loss: (0.3067) |  Loss2: (0.0000) | Acc: (89.00%) (36641/41088)
Epoch: 73 | Batch_idx: 330 |  Loss: (0.3071) |  Loss2: (0.0000) | Acc: (89.00%) (37770/42368)
Epoch: 73 | Batch_idx: 340 |  Loss: (0.3070) |  Loss2: (0.0000) | Acc: (89.00%) (38907/43648)
Epoch: 73 | Batch_idx: 350 |  Loss: (0.3069) |  Loss2: (0.0000) | Acc: (89.00%) (40049/44928)
Epoch: 73 | Batch_idx: 360 |  Loss: (0.3072) |  Loss2: (0.0000) | Acc: (89.00%) (41196/46208)
Epoch: 73 | Batch_idx: 370 |  Loss: (0.3072) |  Loss2: (0.0000) | Acc: (89.00%) (42340/47488)
Epoch: 73 | Batch_idx: 380 |  Loss: (0.3082) |  Loss2: (0.0000) | Acc: (89.00%) (43465/48768)
Epoch: 73 | Batch_idx: 390 |  Loss: (0.3089) |  Loss2: (0.0000) | Acc: (89.00%) (44555/50000)
# TEST : Loss: (0.5059) | Acc: (83.00%) (8330/10000)
percent tensor([0.5171, 0.5197, 0.5183, 0.5200, 0.5186, 0.5201, 0.5205, 0.5217, 0.5176,
        0.5194, 0.5173, 0.5186, 0.5173, 0.5208, 0.5188, 0.5189],
       device='cuda:0') torch.Size([16])
percent tensor([0.5061, 0.5052, 0.5101, 0.5136, 0.5080, 0.5155, 0.5020, 0.5059, 0.5051,
        0.5047, 0.5039, 0.5086, 0.5080, 0.5054, 0.5094, 0.5101],
       device='cuda:0') torch.Size([16])
percent tensor([0.5216, 0.4898, 0.5680, 0.5866, 0.5801, 0.5427, 0.5393, 0.5717, 0.5509,
        0.5138, 0.5215, 0.5265, 0.4471, 0.5845, 0.5249, 0.5164],
       device='cuda:0') torch.Size([16])
percent tensor([0.5941, 0.6021, 0.5948, 0.5943, 0.6041, 0.5788, 0.6064, 0.6101, 0.6023,
        0.5936, 0.5965, 0.6035, 0.5964, 0.5939, 0.6050, 0.5909],
       device='cuda:0') torch.Size([16])
percent tensor([0.5845, 0.5954, 0.6168, 0.6384, 0.6396, 0.6502, 0.5820, 0.6019, 0.6088,
        0.6061, 0.5903, 0.6245, 0.6044, 0.6272, 0.5753, 0.6357],
       device='cuda:0') torch.Size([16])
percent tensor([0.6185, 0.6435, 0.6477, 0.6611, 0.6603, 0.7180, 0.6345, 0.5984, 0.6659,
        0.6347, 0.6755, 0.6517, 0.6705, 0.6802, 0.6009, 0.6513],
       device='cuda:0') torch.Size([16])
percent tensor([0.6317, 0.6082, 0.6293, 0.6381, 0.6640, 0.6548, 0.6300, 0.6283, 0.6232,
        0.6225, 0.6327, 0.5957, 0.6097, 0.6339, 0.5698, 0.6545],
       device='cuda:0') torch.Size([16])
percent tensor([0.9998, 0.9992, 0.9991, 0.9988, 0.9984, 0.9982, 0.9993, 0.9995, 0.9992,
        0.9991, 0.9997, 0.9988, 0.9995, 0.9992, 0.9983, 0.9997],
       device='cuda:0') torch.Size([16])
Epoch: 74 | Batch_idx: 0 |  Loss: (0.3229) |  Loss2: (0.0000) | Acc: (84.00%) (108/128)
Epoch: 74 | Batch_idx: 10 |  Loss: (0.3070) |  Loss2: (0.0000) | Acc: (88.00%) (1252/1408)
Epoch: 74 | Batch_idx: 20 |  Loss: (0.3055) |  Loss2: (0.0000) | Acc: (89.00%) (2403/2688)
Epoch: 74 | Batch_idx: 30 |  Loss: (0.3035) |  Loss2: (0.0000) | Acc: (89.00%) (3557/3968)
Epoch: 74 | Batch_idx: 40 |  Loss: (0.2981) |  Loss2: (0.0000) | Acc: (89.00%) (4715/5248)
Epoch: 74 | Batch_idx: 50 |  Loss: (0.2939) |  Loss2: (0.0000) | Acc: (90.00%) (5880/6528)
Epoch: 74 | Batch_idx: 60 |  Loss: (0.2982) |  Loss2: (0.0000) | Acc: (89.00%) (7010/7808)
Epoch: 74 | Batch_idx: 70 |  Loss: (0.3020) |  Loss2: (0.0000) | Acc: (89.00%) (8150/9088)
Epoch: 74 | Batch_idx: 80 |  Loss: (0.3046) |  Loss2: (0.0000) | Acc: (89.00%) (9281/10368)
Epoch: 74 | Batch_idx: 90 |  Loss: (0.3053) |  Loss2: (0.0000) | Acc: (89.00%) (10424/11648)
Epoch: 74 | Batch_idx: 100 |  Loss: (0.3013) |  Loss2: (0.0000) | Acc: (89.00%) (11598/12928)
Epoch: 74 | Batch_idx: 110 |  Loss: (0.3017) |  Loss2: (0.0000) | Acc: (89.00%) (12740/14208)
Epoch: 74 | Batch_idx: 120 |  Loss: (0.2992) |  Loss2: (0.0000) | Acc: (89.00%) (13909/15488)
Epoch: 74 | Batch_idx: 130 |  Loss: (0.2984) |  Loss2: (0.0000) | Acc: (89.00%) (15069/16768)
Epoch: 74 | Batch_idx: 140 |  Loss: (0.2959) |  Loss2: (0.0000) | Acc: (89.00%) (16237/18048)
Epoch: 74 | Batch_idx: 150 |  Loss: (0.2963) |  Loss2: (0.0000) | Acc: (89.00%) (17390/19328)
Epoch: 74 | Batch_idx: 160 |  Loss: (0.2963) |  Loss2: (0.0000) | Acc: (89.00%) (18547/20608)
Epoch: 74 | Batch_idx: 170 |  Loss: (0.2959) |  Loss2: (0.0000) | Acc: (90.00%) (19702/21888)
Epoch: 74 | Batch_idx: 180 |  Loss: (0.2971) |  Loss2: (0.0000) | Acc: (89.00%) (20837/23168)
Epoch: 74 | Batch_idx: 190 |  Loss: (0.2978) |  Loss2: (0.0000) | Acc: (89.00%) (21963/24448)
Epoch: 74 | Batch_idx: 200 |  Loss: (0.2974) |  Loss2: (0.0000) | Acc: (89.00%) (23110/25728)
Epoch: 74 | Batch_idx: 210 |  Loss: (0.2971) |  Loss2: (0.0000) | Acc: (89.00%) (24276/27008)
Epoch: 74 | Batch_idx: 220 |  Loss: (0.2966) |  Loss2: (0.0000) | Acc: (89.00%) (25429/28288)
Epoch: 74 | Batch_idx: 230 |  Loss: (0.2968) |  Loss2: (0.0000) | Acc: (89.00%) (26576/29568)
Epoch: 74 | Batch_idx: 240 |  Loss: (0.2969) |  Loss2: (0.0000) | Acc: (89.00%) (27728/30848)
Epoch: 74 | Batch_idx: 250 |  Loss: (0.2983) |  Loss2: (0.0000) | Acc: (89.00%) (28872/32128)
Epoch: 74 | Batch_idx: 260 |  Loss: (0.2984) |  Loss2: (0.0000) | Acc: (89.00%) (30026/33408)
Epoch: 74 | Batch_idx: 270 |  Loss: (0.2984) |  Loss2: (0.0000) | Acc: (89.00%) (31176/34688)
Epoch: 74 | Batch_idx: 280 |  Loss: (0.2988) |  Loss2: (0.0000) | Acc: (89.00%) (32316/35968)
Epoch: 74 | Batch_idx: 290 |  Loss: (0.2988) |  Loss2: (0.0000) | Acc: (89.00%) (33477/37248)
Epoch: 74 | Batch_idx: 300 |  Loss: (0.2987) |  Loss2: (0.0000) | Acc: (89.00%) (34629/38528)
Epoch: 74 | Batch_idx: 310 |  Loss: (0.2991) |  Loss2: (0.0000) | Acc: (89.00%) (35779/39808)
Epoch: 74 | Batch_idx: 320 |  Loss: (0.2991) |  Loss2: (0.0000) | Acc: (89.00%) (36927/41088)
Epoch: 74 | Batch_idx: 330 |  Loss: (0.2993) |  Loss2: (0.0000) | Acc: (89.00%) (38071/42368)
Epoch: 74 | Batch_idx: 340 |  Loss: (0.3000) |  Loss2: (0.0000) | Acc: (89.00%) (39208/43648)
Epoch: 74 | Batch_idx: 350 |  Loss: (0.3003) |  Loss2: (0.0000) | Acc: (89.00%) (40349/44928)
Epoch: 74 | Batch_idx: 360 |  Loss: (0.2996) |  Loss2: (0.0000) | Acc: (89.00%) (41513/46208)
Epoch: 74 | Batch_idx: 370 |  Loss: (0.3000) |  Loss2: (0.0000) | Acc: (89.00%) (42651/47488)
Epoch: 74 | Batch_idx: 380 |  Loss: (0.2992) |  Loss2: (0.0000) | Acc: (89.00%) (43804/48768)
Epoch: 74 | Batch_idx: 390 |  Loss: (0.3000) |  Loss2: (0.0000) | Acc: (89.00%) (44885/50000)
# TEST : Loss: (0.5129) | Acc: (83.00%) (8331/10000)
percent tensor([0.5174, 0.5187, 0.5217, 0.5208, 0.5210, 0.5205, 0.5206, 0.5225, 0.5171,
        0.5198, 0.5163, 0.5211, 0.5172, 0.5184, 0.5188, 0.5184],
       device='cuda:0') torch.Size([16])
percent tensor([0.5052, 0.5040, 0.5089, 0.5110, 0.5060, 0.5143, 0.5013, 0.5041, 0.5043,
        0.5031, 0.5037, 0.5076, 0.5071, 0.5044, 0.5076, 0.5092],
       device='cuda:0') torch.Size([16])
percent tensor([0.5024, 0.4808, 0.5601, 0.5775, 0.5727, 0.5262, 0.5300, 0.5656, 0.5361,
        0.4961, 0.5074, 0.5086, 0.4343, 0.5838, 0.5069, 0.5029],
       device='cuda:0') torch.Size([16])
percent tensor([0.5913, 0.5983, 0.5931, 0.5909, 0.5988, 0.5699, 0.6024, 0.6073, 0.5968,
        0.5915, 0.5937, 0.5973, 0.5959, 0.5897, 0.6003, 0.5880],
       device='cuda:0') torch.Size([16])
percent tensor([0.5809, 0.5865, 0.6077, 0.6220, 0.6180, 0.6470, 0.5704, 0.5873, 0.5977,
        0.6004, 0.5814, 0.6152, 0.6051, 0.6208, 0.5677, 0.6232],
       device='cuda:0') torch.Size([16])
percent tensor([0.6170, 0.6359, 0.6408, 0.6514, 0.6423, 0.7207, 0.6265, 0.5777, 0.6706,
        0.6315, 0.6694, 0.6502, 0.6804, 0.6772, 0.5899, 0.6448],
       device='cuda:0') torch.Size([16])
percent tensor([0.6256, 0.6187, 0.6401, 0.6402, 0.6649, 0.6662, 0.6283, 0.6323, 0.6274,
        0.6257, 0.6279, 0.6049, 0.6143, 0.6379, 0.5723, 0.6379],
       device='cuda:0') torch.Size([16])
percent tensor([0.9996, 0.9987, 0.9993, 0.9989, 0.9991, 0.9980, 0.9994, 0.9997, 0.9994,
        0.9992, 0.9997, 0.9993, 0.9994, 0.9992, 0.9978, 0.9989],
       device='cuda:0') torch.Size([16])
Epoch: 75 | Batch_idx: 0 |  Loss: (0.4138) |  Loss2: (0.0000) | Acc: (85.00%) (109/128)
Epoch: 75 | Batch_idx: 10 |  Loss: (0.3122) |  Loss2: (0.0000) | Acc: (88.00%) (1243/1408)
Epoch: 75 | Batch_idx: 20 |  Loss: (0.3054) |  Loss2: (0.0000) | Acc: (89.00%) (2394/2688)
Epoch: 75 | Batch_idx: 30 |  Loss: (0.2968) |  Loss2: (0.0000) | Acc: (89.00%) (3569/3968)
Epoch: 75 | Batch_idx: 40 |  Loss: (0.3011) |  Loss2: (0.0000) | Acc: (89.00%) (4711/5248)
Epoch: 75 | Batch_idx: 50 |  Loss: (0.2991) |  Loss2: (0.0000) | Acc: (89.00%) (5857/6528)
Epoch: 75 | Batch_idx: 60 |  Loss: (0.2974) |  Loss2: (0.0000) | Acc: (89.00%) (7001/7808)
Epoch: 75 | Batch_idx: 70 |  Loss: (0.2978) |  Loss2: (0.0000) | Acc: (89.00%) (8153/9088)
Epoch: 75 | Batch_idx: 80 |  Loss: (0.2997) |  Loss2: (0.0000) | Acc: (89.00%) (9286/10368)
Epoch: 75 | Batch_idx: 90 |  Loss: (0.2970) |  Loss2: (0.0000) | Acc: (89.00%) (10459/11648)
Epoch: 75 | Batch_idx: 100 |  Loss: (0.2949) |  Loss2: (0.0000) | Acc: (89.00%) (11625/12928)
Epoch: 75 | Batch_idx: 110 |  Loss: (0.2935) |  Loss2: (0.0000) | Acc: (89.00%) (12783/14208)
Epoch: 75 | Batch_idx: 120 |  Loss: (0.2936) |  Loss2: (0.0000) | Acc: (89.00%) (13934/15488)
Epoch: 75 | Batch_idx: 130 |  Loss: (0.2937) |  Loss2: (0.0000) | Acc: (89.00%) (15087/16768)
Epoch: 75 | Batch_idx: 140 |  Loss: (0.2936) |  Loss2: (0.0000) | Acc: (89.00%) (16238/18048)
Epoch: 75 | Batch_idx: 150 |  Loss: (0.2939) |  Loss2: (0.0000) | Acc: (89.00%) (17386/19328)
Epoch: 75 | Batch_idx: 160 |  Loss: (0.2953) |  Loss2: (0.0000) | Acc: (89.00%) (18527/20608)
Epoch: 75 | Batch_idx: 170 |  Loss: (0.2963) |  Loss2: (0.0000) | Acc: (89.00%) (19678/21888)
Epoch: 75 | Batch_idx: 180 |  Loss: (0.2962) |  Loss2: (0.0000) | Acc: (89.00%) (20829/23168)
Epoch: 75 | Batch_idx: 190 |  Loss: (0.2943) |  Loss2: (0.0000) | Acc: (89.00%) (22001/24448)
Epoch: 75 | Batch_idx: 200 |  Loss: (0.2932) |  Loss2: (0.0000) | Acc: (90.00%) (23162/25728)
Epoch: 75 | Batch_idx: 210 |  Loss: (0.2939) |  Loss2: (0.0000) | Acc: (90.00%) (24316/27008)
Epoch: 75 | Batch_idx: 220 |  Loss: (0.2924) |  Loss2: (0.0000) | Acc: (90.00%) (25484/28288)
Epoch: 75 | Batch_idx: 230 |  Loss: (0.2926) |  Loss2: (0.0000) | Acc: (90.00%) (26631/29568)
Epoch: 75 | Batch_idx: 240 |  Loss: (0.2913) |  Loss2: (0.0000) | Acc: (90.00%) (27798/30848)
Epoch: 75 | Batch_idx: 250 |  Loss: (0.2910) |  Loss2: (0.0000) | Acc: (90.00%) (28955/32128)
Epoch: 75 | Batch_idx: 260 |  Loss: (0.2909) |  Loss2: (0.0000) | Acc: (90.00%) (30108/33408)
Epoch: 75 | Batch_idx: 270 |  Loss: (0.2911) |  Loss2: (0.0000) | Acc: (90.00%) (31269/34688)
Epoch: 75 | Batch_idx: 280 |  Loss: (0.2918) |  Loss2: (0.0000) | Acc: (90.00%) (32418/35968)
Epoch: 75 | Batch_idx: 290 |  Loss: (0.2926) |  Loss2: (0.0000) | Acc: (90.00%) (33558/37248)
Epoch: 75 | Batch_idx: 300 |  Loss: (0.2922) |  Loss2: (0.0000) | Acc: (90.00%) (34709/38528)
Epoch: 75 | Batch_idx: 310 |  Loss: (0.2931) |  Loss2: (0.0000) | Acc: (90.00%) (35841/39808)
Epoch: 75 | Batch_idx: 320 |  Loss: (0.2925) |  Loss2: (0.0000) | Acc: (90.00%) (36998/41088)
Epoch: 75 | Batch_idx: 330 |  Loss: (0.2929) |  Loss2: (0.0000) | Acc: (90.00%) (38132/42368)
Epoch: 75 | Batch_idx: 340 |  Loss: (0.2931) |  Loss2: (0.0000) | Acc: (89.00%) (39271/43648)
Epoch: 75 | Batch_idx: 350 |  Loss: (0.2945) |  Loss2: (0.0000) | Acc: (89.00%) (40397/44928)
Epoch: 75 | Batch_idx: 360 |  Loss: (0.2946) |  Loss2: (0.0000) | Acc: (89.00%) (41541/46208)
Epoch: 75 | Batch_idx: 370 |  Loss: (0.2940) |  Loss2: (0.0000) | Acc: (89.00%) (42712/47488)
Epoch: 75 | Batch_idx: 380 |  Loss: (0.2930) |  Loss2: (0.0000) | Acc: (89.00%) (43878/48768)
Epoch: 75 | Batch_idx: 390 |  Loss: (0.2927) |  Loss2: (0.0000) | Acc: (90.00%) (45002/50000)
=> saving checkpoint 'drive/app/torch/save_Schedule/checkpoint_075.pth.tar'
# TEST : Loss: (0.4410) | Acc: (85.00%) (8537/10000)
percent tensor([0.5171, 0.5186, 0.5209, 0.5209, 0.5206, 0.5199, 0.5202, 0.5228, 0.5171,
        0.5197, 0.5162, 0.5203, 0.5171, 0.5181, 0.5188, 0.5184],
       device='cuda:0') torch.Size([16])
percent tensor([0.5062, 0.5024, 0.5103, 0.5131, 0.5076, 0.5163, 0.5005, 0.5048, 0.5046,
        0.5030, 0.5037, 0.5081, 0.5076, 0.5009, 0.5086, 0.5090],
       device='cuda:0') torch.Size([16])
percent tensor([0.5144, 0.4844, 0.5677, 0.5897, 0.5800, 0.5304, 0.5319, 0.5720, 0.5497,
        0.5031, 0.5195, 0.5207, 0.4457, 0.5782, 0.5115, 0.5137],
       device='cuda:0') torch.Size([16])
percent tensor([0.5933, 0.5980, 0.5965, 0.5938, 0.6040, 0.5749, 0.6059, 0.6094, 0.5994,
        0.5937, 0.5947, 0.6042, 0.5982, 0.5917, 0.6025, 0.5884],
       device='cuda:0') torch.Size([16])
percent tensor([0.5889, 0.5957, 0.6115, 0.6370, 0.6233, 0.6589, 0.5759, 0.5884, 0.6029,
        0.6087, 0.5960, 0.6146, 0.6002, 0.6211, 0.5759, 0.6358],
       device='cuda:0') torch.Size([16])
percent tensor([0.6156, 0.6471, 0.6349, 0.6567, 0.6413, 0.7150, 0.6251, 0.5764, 0.6653,
        0.6394, 0.6754, 0.6476, 0.6707, 0.6786, 0.5988, 0.6463],
       device='cuda:0') torch.Size([16])
percent tensor([0.6230, 0.6044, 0.6235, 0.6316, 0.6554, 0.6649, 0.6110, 0.6179, 0.6236,
        0.6096, 0.6144, 0.5893, 0.6030, 0.6153, 0.5712, 0.6421],
       device='cuda:0') torch.Size([16])
percent tensor([0.9997, 0.9989, 0.9985, 0.9988, 0.9989, 0.9984, 0.9992, 0.9994, 0.9993,
        0.9990, 0.9997, 0.9991, 0.9994, 0.9994, 0.9982, 0.9995],
       device='cuda:0') torch.Size([16])
Epoch: 76 | Batch_idx: 0 |  Loss: (0.2617) |  Loss2: (0.0000) | Acc: (92.00%) (118/128)
Epoch: 76 | Batch_idx: 10 |  Loss: (0.2763) |  Loss2: (0.0000) | Acc: (90.00%) (1272/1408)
Epoch: 76 | Batch_idx: 20 |  Loss: (0.2786) |  Loss2: (0.0000) | Acc: (90.00%) (2435/2688)
Epoch: 76 | Batch_idx: 30 |  Loss: (0.2770) |  Loss2: (0.0000) | Acc: (90.00%) (3598/3968)
Epoch: 76 | Batch_idx: 40 |  Loss: (0.2679) |  Loss2: (0.0000) | Acc: (91.00%) (4778/5248)
Epoch: 76 | Batch_idx: 50 |  Loss: (0.2708) |  Loss2: (0.0000) | Acc: (90.00%) (5928/6528)
Epoch: 76 | Batch_idx: 60 |  Loss: (0.2684) |  Loss2: (0.0000) | Acc: (90.00%) (7088/7808)
Epoch: 76 | Batch_idx: 70 |  Loss: (0.2719) |  Loss2: (0.0000) | Acc: (90.00%) (8233/9088)
Epoch: 76 | Batch_idx: 80 |  Loss: (0.2720) |  Loss2: (0.0000) | Acc: (90.00%) (9393/10368)
Epoch: 76 | Batch_idx: 90 |  Loss: (0.2712) |  Loss2: (0.0000) | Acc: (90.00%) (10544/11648)
Epoch: 76 | Batch_idx: 100 |  Loss: (0.2725) |  Loss2: (0.0000) | Acc: (90.00%) (11696/12928)
Epoch: 76 | Batch_idx: 110 |  Loss: (0.2729) |  Loss2: (0.0000) | Acc: (90.00%) (12847/14208)
Epoch: 76 | Batch_idx: 120 |  Loss: (0.2737) |  Loss2: (0.0000) | Acc: (90.00%) (14005/15488)
Epoch: 76 | Batch_idx: 130 |  Loss: (0.2720) |  Loss2: (0.0000) | Acc: (90.00%) (15181/16768)
Epoch: 76 | Batch_idx: 140 |  Loss: (0.2722) |  Loss2: (0.0000) | Acc: (90.00%) (16333/18048)
Epoch: 76 | Batch_idx: 150 |  Loss: (0.2727) |  Loss2: (0.0000) | Acc: (90.00%) (17484/19328)
Epoch: 76 | Batch_idx: 160 |  Loss: (0.2716) |  Loss2: (0.0000) | Acc: (90.00%) (18652/20608)
Epoch: 76 | Batch_idx: 170 |  Loss: (0.2727) |  Loss2: (0.0000) | Acc: (90.00%) (19795/21888)
Epoch: 76 | Batch_idx: 180 |  Loss: (0.2733) |  Loss2: (0.0000) | Acc: (90.00%) (20933/23168)
Epoch: 76 | Batch_idx: 190 |  Loss: (0.2753) |  Loss2: (0.0000) | Acc: (90.00%) (22070/24448)
Epoch: 76 | Batch_idx: 200 |  Loss: (0.2771) |  Loss2: (0.0000) | Acc: (90.00%) (23204/25728)
Epoch: 76 | Batch_idx: 210 |  Loss: (0.2778) |  Loss2: (0.0000) | Acc: (90.00%) (24358/27008)
Epoch: 76 | Batch_idx: 220 |  Loss: (0.2783) |  Loss2: (0.0000) | Acc: (90.00%) (25503/28288)
Epoch: 76 | Batch_idx: 230 |  Loss: (0.2782) |  Loss2: (0.0000) | Acc: (90.00%) (26658/29568)
Epoch: 76 | Batch_idx: 240 |  Loss: (0.2780) |  Loss2: (0.0000) | Acc: (90.00%) (27819/30848)
Epoch: 76 | Batch_idx: 250 |  Loss: (0.2775) |  Loss2: (0.0000) | Acc: (90.00%) (28981/32128)
Epoch: 76 | Batch_idx: 260 |  Loss: (0.2802) |  Loss2: (0.0000) | Acc: (90.00%) (30109/33408)
Epoch: 76 | Batch_idx: 270 |  Loss: (0.2800) |  Loss2: (0.0000) | Acc: (90.00%) (31260/34688)
Epoch: 76 | Batch_idx: 280 |  Loss: (0.2801) |  Loss2: (0.0000) | Acc: (90.00%) (32399/35968)
Epoch: 76 | Batch_idx: 290 |  Loss: (0.2809) |  Loss2: (0.0000) | Acc: (90.00%) (33548/37248)
Epoch: 76 | Batch_idx: 300 |  Loss: (0.2831) |  Loss2: (0.0000) | Acc: (89.00%) (34667/38528)
Epoch: 76 | Batch_idx: 310 |  Loss: (0.2834) |  Loss2: (0.0000) | Acc: (89.00%) (35811/39808)
Epoch: 76 | Batch_idx: 320 |  Loss: (0.2839) |  Loss2: (0.0000) | Acc: (89.00%) (36963/41088)
Epoch: 76 | Batch_idx: 330 |  Loss: (0.2839) |  Loss2: (0.0000) | Acc: (89.00%) (38120/42368)
Epoch: 76 | Batch_idx: 340 |  Loss: (0.2833) |  Loss2: (0.0000) | Acc: (89.00%) (39277/43648)
Epoch: 76 | Batch_idx: 350 |  Loss: (0.2831) |  Loss2: (0.0000) | Acc: (89.00%) (40425/44928)
Epoch: 76 | Batch_idx: 360 |  Loss: (0.2833) |  Loss2: (0.0000) | Acc: (89.00%) (41578/46208)
Epoch: 76 | Batch_idx: 370 |  Loss: (0.2841) |  Loss2: (0.0000) | Acc: (89.00%) (42714/47488)
Epoch: 76 | Batch_idx: 380 |  Loss: (0.2854) |  Loss2: (0.0000) | Acc: (89.00%) (43844/48768)
Epoch: 76 | Batch_idx: 390 |  Loss: (0.2854) |  Loss2: (0.0000) | Acc: (89.00%) (44945/50000)
# TEST : Loss: (0.4361) | Acc: (85.00%) (8575/10000)
percent tensor([0.5173, 0.5194, 0.5210, 0.5207, 0.5209, 0.5207, 0.5212, 0.5223, 0.5177,
        0.5202, 0.5167, 0.5210, 0.5173, 0.5198, 0.5191, 0.5188],
       device='cuda:0') torch.Size([16])
percent tensor([0.5057, 0.5031, 0.5081, 0.5129, 0.5069, 0.5149, 0.4998, 0.5043, 0.5045,
        0.5024, 0.5031, 0.5069, 0.5069, 0.5027, 0.5088, 0.5086],
       device='cuda:0') torch.Size([16])
percent tensor([0.5127, 0.4914, 0.5670, 0.5879, 0.5802, 0.5264, 0.5366, 0.5738, 0.5528,
        0.5111, 0.5263, 0.5231, 0.4481, 0.5876, 0.5148, 0.5135],
       device='cuda:0') torch.Size([16])
percent tensor([0.5923, 0.6004, 0.5942, 0.5921, 0.6020, 0.5725, 0.6058, 0.6094, 0.5981,
        0.5935, 0.5938, 0.6015, 0.5962, 0.5920, 0.6011, 0.5892],
       device='cuda:0') torch.Size([16])
percent tensor([0.5795, 0.5733, 0.6051, 0.6311, 0.6163, 0.6538, 0.5610, 0.5857, 0.5998,
        0.6014, 0.5858, 0.6058, 0.5955, 0.6120, 0.5720, 0.6231],
       device='cuda:0') torch.Size([16])
percent tensor([0.6166, 0.6236, 0.6337, 0.6585, 0.6333, 0.7259, 0.6123, 0.5804, 0.6719,
        0.6229, 0.6630, 0.6363, 0.6643, 0.6676, 0.5935, 0.6421],
       device='cuda:0') torch.Size([16])
percent tensor([0.6349, 0.6110, 0.6331, 0.6436, 0.6486, 0.6724, 0.6219, 0.6252, 0.6306,
        0.6140, 0.6276, 0.5944, 0.6071, 0.6192, 0.5815, 0.6340],
       device='cuda:0') torch.Size([16])
percent tensor([0.9996, 0.9987, 0.9992, 0.9993, 0.9989, 0.9983, 0.9993, 0.9995, 0.9989,
        0.9989, 0.9996, 0.9994, 0.9994, 0.9993, 0.9982, 0.9995],
       device='cuda:0') torch.Size([16])
Epoch: 77 | Batch_idx: 0 |  Loss: (0.2536) |  Loss2: (0.0000) | Acc: (89.00%) (115/128)
Epoch: 77 | Batch_idx: 10 |  Loss: (0.2985) |  Loss2: (0.0000) | Acc: (88.00%) (1251/1408)
Epoch: 77 | Batch_idx: 20 |  Loss: (0.2989) |  Loss2: (0.0000) | Acc: (89.00%) (2393/2688)
Epoch: 77 | Batch_idx: 30 |  Loss: (0.2914) |  Loss2: (0.0000) | Acc: (89.00%) (3549/3968)
Epoch: 77 | Batch_idx: 40 |  Loss: (0.2982) |  Loss2: (0.0000) | Acc: (89.00%) (4689/5248)
Epoch: 77 | Batch_idx: 50 |  Loss: (0.2930) |  Loss2: (0.0000) | Acc: (89.00%) (5837/6528)
Epoch: 77 | Batch_idx: 60 |  Loss: (0.2909) |  Loss2: (0.0000) | Acc: (89.00%) (6989/7808)
Epoch: 77 | Batch_idx: 70 |  Loss: (0.2942) |  Loss2: (0.0000) | Acc: (89.00%) (8135/9088)
Epoch: 77 | Batch_idx: 80 |  Loss: (0.2909) |  Loss2: (0.0000) | Acc: (89.00%) (9302/10368)
Epoch: 77 | Batch_idx: 90 |  Loss: (0.2880) |  Loss2: (0.0000) | Acc: (89.00%) (10472/11648)
Epoch: 77 | Batch_idx: 100 |  Loss: (0.2886) |  Loss2: (0.0000) | Acc: (89.00%) (11632/12928)
Epoch: 77 | Batch_idx: 110 |  Loss: (0.2898) |  Loss2: (0.0000) | Acc: (89.00%) (12781/14208)
Epoch: 77 | Batch_idx: 120 |  Loss: (0.2874) |  Loss2: (0.0000) | Acc: (90.00%) (13943/15488)
Epoch: 77 | Batch_idx: 130 |  Loss: (0.2869) |  Loss2: (0.0000) | Acc: (90.00%) (15096/16768)
Epoch: 77 | Batch_idx: 140 |  Loss: (0.2863) |  Loss2: (0.0000) | Acc: (90.00%) (16245/18048)
Epoch: 77 | Batch_idx: 150 |  Loss: (0.2840) |  Loss2: (0.0000) | Acc: (90.00%) (17418/19328)
Epoch: 77 | Batch_idx: 160 |  Loss: (0.2847) |  Loss2: (0.0000) | Acc: (90.00%) (18575/20608)
Epoch: 77 | Batch_idx: 170 |  Loss: (0.2835) |  Loss2: (0.0000) | Acc: (90.00%) (19731/21888)
Epoch: 77 | Batch_idx: 180 |  Loss: (0.2828) |  Loss2: (0.0000) | Acc: (90.00%) (20887/23168)
Epoch: 77 | Batch_idx: 190 |  Loss: (0.2826) |  Loss2: (0.0000) | Acc: (90.00%) (22040/24448)
Epoch: 77 | Batch_idx: 200 |  Loss: (0.2835) |  Loss2: (0.0000) | Acc: (90.00%) (23183/25728)
Epoch: 77 | Batch_idx: 210 |  Loss: (0.2828) |  Loss2: (0.0000) | Acc: (90.00%) (24342/27008)
Epoch: 77 | Batch_idx: 220 |  Loss: (0.2821) |  Loss2: (0.0000) | Acc: (90.00%) (25510/28288)
Epoch: 77 | Batch_idx: 230 |  Loss: (0.2822) |  Loss2: (0.0000) | Acc: (90.00%) (26665/29568)
Epoch: 77 | Batch_idx: 240 |  Loss: (0.2839) |  Loss2: (0.0000) | Acc: (90.00%) (27801/30848)
Epoch: 77 | Batch_idx: 250 |  Loss: (0.2827) |  Loss2: (0.0000) | Acc: (90.00%) (28972/32128)
Epoch: 77 | Batch_idx: 260 |  Loss: (0.2824) |  Loss2: (0.0000) | Acc: (90.00%) (30130/33408)
Epoch: 77 | Batch_idx: 270 |  Loss: (0.2820) |  Loss2: (0.0000) | Acc: (90.00%) (31295/34688)
Epoch: 77 | Batch_idx: 280 |  Loss: (0.2806) |  Loss2: (0.0000) | Acc: (90.00%) (32471/35968)
Epoch: 77 | Batch_idx: 290 |  Loss: (0.2801) |  Loss2: (0.0000) | Acc: (90.00%) (33637/37248)
Epoch: 77 | Batch_idx: 300 |  Loss: (0.2800) |  Loss2: (0.0000) | Acc: (90.00%) (34800/38528)
Epoch: 77 | Batch_idx: 310 |  Loss: (0.2799) |  Loss2: (0.0000) | Acc: (90.00%) (35968/39808)
Epoch: 77 | Batch_idx: 320 |  Loss: (0.2795) |  Loss2: (0.0000) | Acc: (90.00%) (37133/41088)
Epoch: 77 | Batch_idx: 330 |  Loss: (0.2793) |  Loss2: (0.0000) | Acc: (90.00%) (38284/42368)
Epoch: 77 | Batch_idx: 340 |  Loss: (0.2797) |  Loss2: (0.0000) | Acc: (90.00%) (39432/43648)
Epoch: 77 | Batch_idx: 350 |  Loss: (0.2804) |  Loss2: (0.0000) | Acc: (90.00%) (40579/44928)
Epoch: 77 | Batch_idx: 360 |  Loss: (0.2807) |  Loss2: (0.0000) | Acc: (90.00%) (41729/46208)
Epoch: 77 | Batch_idx: 370 |  Loss: (0.2811) |  Loss2: (0.0000) | Acc: (90.00%) (42886/47488)
Epoch: 77 | Batch_idx: 380 |  Loss: (0.2809) |  Loss2: (0.0000) | Acc: (90.00%) (44051/48768)
Epoch: 77 | Batch_idx: 390 |  Loss: (0.2804) |  Loss2: (0.0000) | Acc: (90.00%) (45169/50000)
# TEST : Loss: (0.4572) | Acc: (84.00%) (8499/10000)
percent tensor([0.5169, 0.5190, 0.5204, 0.5211, 0.5206, 0.5199, 0.5205, 0.5226, 0.5171,
        0.5198, 0.5162, 0.5201, 0.5170, 0.5188, 0.5188, 0.5185],
       device='cuda:0') torch.Size([16])
percent tensor([0.5054, 0.5037, 0.5096, 0.5133, 0.5070, 0.5150, 0.5005, 0.5041, 0.5046,
        0.5031, 0.5032, 0.5072, 0.5074, 0.5032, 0.5085, 0.5093],
       device='cuda:0') torch.Size([16])
percent tensor([0.5176, 0.4905, 0.5661, 0.5829, 0.5777, 0.5433, 0.5382, 0.5693, 0.5491,
        0.5049, 0.5249, 0.5262, 0.4459, 0.5861, 0.5205, 0.5160],
       device='cuda:0') torch.Size([16])
percent tensor([0.5965, 0.6023, 0.5942, 0.5883, 0.6010, 0.5802, 0.6076, 0.6074, 0.6049,
        0.5965, 0.5981, 0.6042, 0.5997, 0.5966, 0.6062, 0.5919],
       device='cuda:0') torch.Size([16])
percent tensor([0.5726, 0.5752, 0.6038, 0.6277, 0.6140, 0.6436, 0.5647, 0.5785, 0.5926,
        0.5862, 0.5705, 0.6048, 0.5879, 0.6131, 0.5636, 0.6212],
       device='cuda:0') torch.Size([16])
percent tensor([0.6093, 0.6140, 0.6361, 0.6584, 0.6253, 0.7073, 0.6120, 0.5645, 0.6504,
        0.6037, 0.6487, 0.6331, 0.6580, 0.6513, 0.5775, 0.6362],
       device='cuda:0') torch.Size([16])
percent tensor([0.6205, 0.6040, 0.6208, 0.6378, 0.6467, 0.6533, 0.6102, 0.6108, 0.6161,
        0.6073, 0.6160, 0.5883, 0.5986, 0.6138, 0.5707, 0.6329],
       device='cuda:0') torch.Size([16])
percent tensor([0.9996, 0.9989, 0.9986, 0.9990, 0.9989, 0.9980, 0.9991, 0.9990, 0.9994,
        0.9989, 0.9995, 0.9990, 0.9996, 0.9992, 0.9977, 0.9990],
       device='cuda:0') torch.Size([16])
False Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=128, out_features=16, bias=False)
True Linear(in_features=16, out_features=2, bias=False)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=128, out_features=16, bias=False)
True Linear(in_features=16, out_features=2, bias=False)
False Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=256, out_features=32, bias=False)
True Linear(in_features=32, out_features=2, bias=False)
False Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=256, out_features=32, bias=False)
True Linear(in_features=32, out_features=2, bias=False)
False Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=512, out_features=64, bias=False)
True Linear(in_features=64, out_features=2, bias=False)
False Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=512, out_features=64, bias=False)
True Linear(in_features=64, out_features=2, bias=False)
False Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1024, out_features=128, bias=False)
True Linear(in_features=128, out_features=2, bias=False)
False Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1024, out_features=128, bias=False)
True Linear(in_features=128, out_features=2, bias=False)
False Linear(in_features=512, out_features=10, bias=True)
Epoch: 78 | Batch_idx: 0 |  Loss: (0.2809) |  Loss2: (0.0000) | Acc: (89.00%) (115/128)
Epoch: 78 | Batch_idx: 10 |  Loss: (0.2636) |  Loss2: (0.0000) | Acc: (90.00%) (1278/1408)
Epoch: 78 | Batch_idx: 20 |  Loss: (0.2759) |  Loss2: (0.0000) | Acc: (90.00%) (2429/2688)
Epoch: 78 | Batch_idx: 30 |  Loss: (0.2867) |  Loss2: (0.0000) | Acc: (89.00%) (3570/3968)
Epoch: 78 | Batch_idx: 40 |  Loss: (0.2917) |  Loss2: (0.0000) | Acc: (89.00%) (4715/5248)
Epoch: 78 | Batch_idx: 50 |  Loss: (0.2981) |  Loss2: (0.0000) | Acc: (89.00%) (5840/6528)
Epoch: 78 | Batch_idx: 60 |  Loss: (0.3063) |  Loss2: (0.0000) | Acc: (89.00%) (6960/7808)
Epoch: 78 | Batch_idx: 70 |  Loss: (0.3016) |  Loss2: (0.0000) | Acc: (89.00%) (8120/9088)
Epoch: 78 | Batch_idx: 80 |  Loss: (0.3048) |  Loss2: (0.0000) | Acc: (89.00%) (9254/10368)
Epoch: 78 | Batch_idx: 90 |  Loss: (0.3023) |  Loss2: (0.0000) | Acc: (89.00%) (10400/11648)
Epoch: 78 | Batch_idx: 100 |  Loss: (0.3048) |  Loss2: (0.0000) | Acc: (89.00%) (11529/12928)
Epoch: 78 | Batch_idx: 110 |  Loss: (0.3054) |  Loss2: (0.0000) | Acc: (89.00%) (12674/14208)
Epoch: 78 | Batch_idx: 120 |  Loss: (0.3072) |  Loss2: (0.0000) | Acc: (89.00%) (13811/15488)
Epoch: 78 | Batch_idx: 130 |  Loss: (0.3061) |  Loss2: (0.0000) | Acc: (89.00%) (14961/16768)
Epoch: 78 | Batch_idx: 140 |  Loss: (0.3058) |  Loss2: (0.0000) | Acc: (89.00%) (16110/18048)
Epoch: 78 | Batch_idx: 150 |  Loss: (0.3054) |  Loss2: (0.0000) | Acc: (89.00%) (17261/19328)
Epoch: 78 | Batch_idx: 160 |  Loss: (0.3061) |  Loss2: (0.0000) | Acc: (89.00%) (18395/20608)
Epoch: 78 | Batch_idx: 170 |  Loss: (0.3083) |  Loss2: (0.0000) | Acc: (89.00%) (19519/21888)
Epoch: 78 | Batch_idx: 180 |  Loss: (0.3091) |  Loss2: (0.0000) | Acc: (89.00%) (20657/23168)
Epoch: 78 | Batch_idx: 190 |  Loss: (0.3115) |  Loss2: (0.0000) | Acc: (89.00%) (21775/24448)
Epoch: 78 | Batch_idx: 200 |  Loss: (0.3103) |  Loss2: (0.0000) | Acc: (89.00%) (22929/25728)
Epoch: 78 | Batch_idx: 210 |  Loss: (0.3110) |  Loss2: (0.0000) | Acc: (89.00%) (24053/27008)
Epoch: 78 | Batch_idx: 220 |  Loss: (0.3107) |  Loss2: (0.0000) | Acc: (89.00%) (25197/28288)
Epoch: 78 | Batch_idx: 230 |  Loss: (0.3109) |  Loss2: (0.0000) | Acc: (89.00%) (26328/29568)
Epoch: 78 | Batch_idx: 240 |  Loss: (0.3111) |  Loss2: (0.0000) | Acc: (89.00%) (27467/30848)
Epoch: 78 | Batch_idx: 250 |  Loss: (0.3120) |  Loss2: (0.0000) | Acc: (89.00%) (28599/32128)
Epoch: 78 | Batch_idx: 260 |  Loss: (0.3100) |  Loss2: (0.0000) | Acc: (89.00%) (29767/33408)
Epoch: 78 | Batch_idx: 270 |  Loss: (0.3093) |  Loss2: (0.0000) | Acc: (89.00%) (30916/34688)
Epoch: 78 | Batch_idx: 280 |  Loss: (0.3094) |  Loss2: (0.0000) | Acc: (89.00%) (32054/35968)
Epoch: 78 | Batch_idx: 290 |  Loss: (0.3100) |  Loss2: (0.0000) | Acc: (89.00%) (33181/37248)
Epoch: 78 | Batch_idx: 300 |  Loss: (0.3092) |  Loss2: (0.0000) | Acc: (89.00%) (34322/38528)
Epoch: 78 | Batch_idx: 310 |  Loss: (0.3090) |  Loss2: (0.0000) | Acc: (89.00%) (35474/39808)
Epoch: 78 | Batch_idx: 320 |  Loss: (0.3081) |  Loss2: (0.0000) | Acc: (89.00%) (36630/41088)
Epoch: 78 | Batch_idx: 330 |  Loss: (0.3078) |  Loss2: (0.0000) | Acc: (89.00%) (37775/42368)
Epoch: 78 | Batch_idx: 340 |  Loss: (0.3075) |  Loss2: (0.0000) | Acc: (89.00%) (38921/43648)
Epoch: 78 | Batch_idx: 350 |  Loss: (0.3069) |  Loss2: (0.0000) | Acc: (89.00%) (40069/44928)
Epoch: 78 | Batch_idx: 360 |  Loss: (0.3061) |  Loss2: (0.0000) | Acc: (89.00%) (41237/46208)
Epoch: 78 | Batch_idx: 370 |  Loss: (0.3060) |  Loss2: (0.0000) | Acc: (89.00%) (42375/47488)
Epoch: 78 | Batch_idx: 380 |  Loss: (0.3057) |  Loss2: (0.0000) | Acc: (89.00%) (43522/48768)
Epoch: 78 | Batch_idx: 390 |  Loss: (0.3058) |  Loss2: (0.0000) | Acc: (89.00%) (44619/50000)
# TEST : Loss: (0.4182) | Acc: (85.00%) (8588/10000)
percent tensor([0.5164, 0.5181, 0.5204, 0.5199, 0.5203, 0.5189, 0.5197, 0.5217, 0.5170,
        0.5191, 0.5156, 0.5200, 0.5166, 0.5175, 0.5178, 0.5176],
       device='cuda:0') torch.Size([16])
percent tensor([0.5114, 0.5121, 0.5146, 0.5188, 0.5127, 0.5190, 0.5081, 0.5105, 0.5110,
        0.5109, 0.5104, 0.5143, 0.5143, 0.5091, 0.5156, 0.5155],
       device='cuda:0') torch.Size([16])
percent tensor([0.5788, 0.5300, 0.6011, 0.6229, 0.6103, 0.6108, 0.5785, 0.6015, 0.6007,
        0.5525, 0.5813, 0.5760, 0.5006, 0.6202, 0.5703, 0.5724],
       device='cuda:0') torch.Size([16])
percent tensor([0.6001, 0.6054, 0.5930, 0.5888, 0.5997, 0.5838, 0.6091, 0.6072, 0.6030,
        0.5998, 0.6003, 0.6048, 0.6036, 0.5969, 0.6102, 0.5954],
       device='cuda:0') torch.Size([16])
percent tensor([0.6121, 0.6028, 0.6308, 0.6649, 0.6477, 0.6932, 0.5904, 0.6152, 0.6275,
        0.6109, 0.5994, 0.6263, 0.6152, 0.6444, 0.5909, 0.6699],
       device='cuda:0') torch.Size([16])
percent tensor([0.6136, 0.6198, 0.6378, 0.6548, 0.6175, 0.7124, 0.6109, 0.5530, 0.6621,
        0.6124, 0.6656, 0.6434, 0.6703, 0.6625, 0.5801, 0.6374],
       device='cuda:0') torch.Size([16])
percent tensor([0.6140, 0.5800, 0.6262, 0.6452, 0.6498, 0.6626, 0.6019, 0.6139, 0.6125,
        0.5854, 0.6013, 0.5845, 0.5825, 0.6064, 0.5644, 0.6304],
       device='cuda:0') torch.Size([16])
percent tensor([0.9997, 0.9989, 0.9984, 0.9992, 0.9988, 0.9987, 0.9991, 0.9991, 0.9992,
        0.9990, 0.9996, 0.9992, 0.9996, 0.9991, 0.9977, 0.9992],
       device='cuda:0') torch.Size([16])
Epoch: 79 | Batch_idx: 0 |  Loss: (0.2821) |  Loss2: (0.0000) | Acc: (92.00%) (118/128)
Epoch: 79 | Batch_idx: 10 |  Loss: (0.2875) |  Loss2: (0.0000) | Acc: (89.00%) (1263/1408)
Epoch: 79 | Batch_idx: 20 |  Loss: (0.2830) |  Loss2: (0.0000) | Acc: (90.00%) (2432/2688)
Epoch: 79 | Batch_idx: 30 |  Loss: (0.2863) |  Loss2: (0.0000) | Acc: (90.00%) (3580/3968)
Epoch: 79 | Batch_idx: 40 |  Loss: (0.2853) |  Loss2: (0.0000) | Acc: (90.00%) (4745/5248)
Epoch: 79 | Batch_idx: 50 |  Loss: (0.2886) |  Loss2: (0.0000) | Acc: (90.00%) (5878/6528)
Epoch: 79 | Batch_idx: 60 |  Loss: (0.2883) |  Loss2: (0.0000) | Acc: (90.00%) (7040/7808)
Epoch: 79 | Batch_idx: 70 |  Loss: (0.2876) |  Loss2: (0.0000) | Acc: (90.00%) (8191/9088)
Epoch: 79 | Batch_idx: 80 |  Loss: (0.2839) |  Loss2: (0.0000) | Acc: (90.00%) (9357/10368)
Epoch: 79 | Batch_idx: 90 |  Loss: (0.2842) |  Loss2: (0.0000) | Acc: (90.00%) (10502/11648)
Epoch: 79 | Batch_idx: 100 |  Loss: (0.2878) |  Loss2: (0.0000) | Acc: (90.00%) (11642/12928)
Epoch: 79 | Batch_idx: 110 |  Loss: (0.2881) |  Loss2: (0.0000) | Acc: (89.00%) (12786/14208)
Epoch: 79 | Batch_idx: 120 |  Loss: (0.2856) |  Loss2: (0.0000) | Acc: (90.00%) (13948/15488)
Epoch: 79 | Batch_idx: 130 |  Loss: (0.2865) |  Loss2: (0.0000) | Acc: (89.00%) (15091/16768)
Epoch: 79 | Batch_idx: 140 |  Loss: (0.2862) |  Loss2: (0.0000) | Acc: (90.00%) (16245/18048)
Epoch: 79 | Batch_idx: 150 |  Loss: (0.2863) |  Loss2: (0.0000) | Acc: (89.00%) (17385/19328)
Epoch: 79 | Batch_idx: 160 |  Loss: (0.2870) |  Loss2: (0.0000) | Acc: (89.00%) (18534/20608)
Epoch: 79 | Batch_idx: 170 |  Loss: (0.2868) |  Loss2: (0.0000) | Acc: (89.00%) (19677/21888)
Epoch: 79 | Batch_idx: 180 |  Loss: (0.2857) |  Loss2: (0.0000) | Acc: (89.00%) (20844/23168)
Epoch: 79 | Batch_idx: 190 |  Loss: (0.2849) |  Loss2: (0.0000) | Acc: (90.00%) (22012/24448)
Epoch: 79 | Batch_idx: 200 |  Loss: (0.2852) |  Loss2: (0.0000) | Acc: (90.00%) (23160/25728)
Epoch: 79 | Batch_idx: 210 |  Loss: (0.2854) |  Loss2: (0.0000) | Acc: (90.00%) (24308/27008)
Epoch: 79 | Batch_idx: 220 |  Loss: (0.2851) |  Loss2: (0.0000) | Acc: (90.00%) (25463/28288)
Epoch: 79 | Batch_idx: 230 |  Loss: (0.2860) |  Loss2: (0.0000) | Acc: (90.00%) (26621/29568)
Epoch: 79 | Batch_idx: 240 |  Loss: (0.2867) |  Loss2: (0.0000) | Acc: (90.00%) (27771/30848)
Epoch: 79 | Batch_idx: 250 |  Loss: (0.2864) |  Loss2: (0.0000) | Acc: (90.00%) (28925/32128)
Epoch: 79 | Batch_idx: 260 |  Loss: (0.2867) |  Loss2: (0.0000) | Acc: (89.00%) (30067/33408)
Epoch: 79 | Batch_idx: 270 |  Loss: (0.2856) |  Loss2: (0.0000) | Acc: (90.00%) (31240/34688)
Epoch: 79 | Batch_idx: 280 |  Loss: (0.2843) |  Loss2: (0.0000) | Acc: (90.00%) (32416/35968)
Epoch: 79 | Batch_idx: 290 |  Loss: (0.2843) |  Loss2: (0.0000) | Acc: (90.00%) (33569/37248)
Epoch: 79 | Batch_idx: 300 |  Loss: (0.2840) |  Loss2: (0.0000) | Acc: (90.00%) (34717/38528)
Epoch: 79 | Batch_idx: 310 |  Loss: (0.2838) |  Loss2: (0.0000) | Acc: (90.00%) (35874/39808)
Epoch: 79 | Batch_idx: 320 |  Loss: (0.2831) |  Loss2: (0.0000) | Acc: (90.00%) (37046/41088)
Epoch: 79 | Batch_idx: 330 |  Loss: (0.2827) |  Loss2: (0.0000) | Acc: (90.00%) (38207/42368)
Epoch: 79 | Batch_idx: 340 |  Loss: (0.2829) |  Loss2: (0.0000) | Acc: (90.00%) (39364/43648)
Epoch: 79 | Batch_idx: 350 |  Loss: (0.2826) |  Loss2: (0.0000) | Acc: (90.00%) (40529/44928)
Epoch: 79 | Batch_idx: 360 |  Loss: (0.2828) |  Loss2: (0.0000) | Acc: (90.00%) (41693/46208)
Epoch: 79 | Batch_idx: 370 |  Loss: (0.2824) |  Loss2: (0.0000) | Acc: (90.00%) (42853/47488)
Epoch: 79 | Batch_idx: 380 |  Loss: (0.2815) |  Loss2: (0.0000) | Acc: (90.00%) (44030/48768)
Epoch: 79 | Batch_idx: 390 |  Loss: (0.2824) |  Loss2: (0.0000) | Acc: (90.00%) (45131/50000)
# TEST : Loss: (0.4027) | Acc: (86.00%) (8642/10000)
percent tensor([0.5154, 0.5170, 0.5189, 0.5182, 0.5189, 0.5175, 0.5186, 0.5203, 0.5160,
        0.5180, 0.5147, 0.5187, 0.5157, 0.5167, 0.5165, 0.5164],
       device='cuda:0') torch.Size([16])
percent tensor([0.5129, 0.5156, 0.5165, 0.5202, 0.5150, 0.5198, 0.5113, 0.5128, 0.5133,
        0.5143, 0.5133, 0.5170, 0.5167, 0.5115, 0.5179, 0.5171],
       device='cuda:0') torch.Size([16])
percent tensor([0.5711, 0.5179, 0.5979, 0.6192, 0.6061, 0.6034, 0.5674, 0.5974, 0.5931,
        0.5427, 0.5727, 0.5672, 0.4925, 0.6144, 0.5581, 0.5646],
       device='cuda:0') torch.Size([16])
percent tensor([0.6058, 0.6122, 0.5971, 0.5929, 0.6034, 0.5874, 0.6147, 0.6108, 0.6075,
        0.6069, 0.6073, 0.6104, 0.6110, 0.6014, 0.6160, 0.6014],
       device='cuda:0') torch.Size([16])
percent tensor([0.6107, 0.5980, 0.6291, 0.6604, 0.6459, 0.6911, 0.5859, 0.6105, 0.6243,
        0.6099, 0.5952, 0.6207, 0.6136, 0.6365, 0.5837, 0.6670],
       device='cuda:0') torch.Size([16])
percent tensor([0.6041, 0.6174, 0.6303, 0.6480, 0.6088, 0.7101, 0.6043, 0.5390, 0.6603,
        0.6090, 0.6628, 0.6410, 0.6703, 0.6603, 0.5722, 0.6275],
       device='cuda:0') torch.Size([16])
percent tensor([0.6106, 0.5729, 0.6282, 0.6484, 0.6563, 0.6669, 0.6013, 0.6184, 0.6086,
        0.5786, 0.5956, 0.5818, 0.5742, 0.6001, 0.5614, 0.6295],
       device='cuda:0') torch.Size([16])
percent tensor([0.9998, 0.9989, 0.9985, 0.9993, 0.9990, 0.9987, 0.9992, 0.9992, 0.9992,
        0.9991, 0.9996, 0.9991, 0.9996, 0.9992, 0.9976, 0.9992],
       device='cuda:0') torch.Size([16])
Epoch: 80 | Batch_idx: 0 |  Loss: (0.3204) |  Loss2: (0.0000) | Acc: (86.00%) (111/128)
Epoch: 80 | Batch_idx: 10 |  Loss: (0.3150) |  Loss2: (0.0000) | Acc: (89.00%) (1257/1408)
Epoch: 80 | Batch_idx: 20 |  Loss: (0.2957) |  Loss2: (0.0000) | Acc: (90.00%) (2422/2688)
Epoch: 80 | Batch_idx: 30 |  Loss: (0.2884) |  Loss2: (0.0000) | Acc: (90.00%) (3588/3968)
Epoch: 80 | Batch_idx: 40 |  Loss: (0.2811) |  Loss2: (0.0000) | Acc: (90.00%) (4752/5248)
Epoch: 80 | Batch_idx: 50 |  Loss: (0.2777) |  Loss2: (0.0000) | Acc: (90.00%) (5920/6528)
Epoch: 80 | Batch_idx: 60 |  Loss: (0.2770) |  Loss2: (0.0000) | Acc: (90.00%) (7082/7808)
Epoch: 80 | Batch_idx: 70 |  Loss: (0.2794) |  Loss2: (0.0000) | Acc: (90.00%) (8234/9088)
Epoch: 80 | Batch_idx: 80 |  Loss: (0.2806) |  Loss2: (0.0000) | Acc: (90.00%) (9390/10368)
Epoch: 80 | Batch_idx: 90 |  Loss: (0.2798) |  Loss2: (0.0000) | Acc: (90.00%) (10543/11648)
Epoch: 80 | Batch_idx: 100 |  Loss: (0.2825) |  Loss2: (0.0000) | Acc: (90.00%) (11683/12928)
Epoch: 80 | Batch_idx: 110 |  Loss: (0.2825) |  Loss2: (0.0000) | Acc: (90.00%) (12826/14208)
Epoch: 80 | Batch_idx: 120 |  Loss: (0.2807) |  Loss2: (0.0000) | Acc: (90.00%) (13983/15488)
Epoch: 80 | Batch_idx: 130 |  Loss: (0.2787) |  Loss2: (0.0000) | Acc: (90.00%) (15151/16768)
Epoch: 80 | Batch_idx: 140 |  Loss: (0.2760) |  Loss2: (0.0000) | Acc: (90.00%) (16315/18048)
Epoch: 80 | Batch_idx: 150 |  Loss: (0.2743) |  Loss2: (0.0000) | Acc: (90.00%) (17493/19328)
Epoch: 80 | Batch_idx: 160 |  Loss: (0.2739) |  Loss2: (0.0000) | Acc: (90.00%) (18659/20608)
Epoch: 80 | Batch_idx: 170 |  Loss: (0.2746) |  Loss2: (0.0000) | Acc: (90.00%) (19813/21888)
Epoch: 80 | Batch_idx: 180 |  Loss: (0.2744) |  Loss2: (0.0000) | Acc: (90.00%) (20980/23168)
Epoch: 80 | Batch_idx: 190 |  Loss: (0.2743) |  Loss2: (0.0000) | Acc: (90.00%) (22136/24448)
Epoch: 80 | Batch_idx: 200 |  Loss: (0.2738) |  Loss2: (0.0000) | Acc: (90.00%) (23291/25728)
Epoch: 80 | Batch_idx: 210 |  Loss: (0.2727) |  Loss2: (0.0000) | Acc: (90.00%) (24463/27008)
Epoch: 80 | Batch_idx: 220 |  Loss: (0.2746) |  Loss2: (0.0000) | Acc: (90.00%) (25596/28288)
Epoch: 80 | Batch_idx: 230 |  Loss: (0.2753) |  Loss2: (0.0000) | Acc: (90.00%) (26736/29568)
Epoch: 80 | Batch_idx: 240 |  Loss: (0.2746) |  Loss2: (0.0000) | Acc: (90.00%) (27906/30848)
Epoch: 80 | Batch_idx: 250 |  Loss: (0.2740) |  Loss2: (0.0000) | Acc: (90.00%) (29064/32128)
Epoch: 80 | Batch_idx: 260 |  Loss: (0.2729) |  Loss2: (0.0000) | Acc: (90.00%) (30238/33408)
Epoch: 80 | Batch_idx: 270 |  Loss: (0.2738) |  Loss2: (0.0000) | Acc: (90.00%) (31386/34688)
Epoch: 80 | Batch_idx: 280 |  Loss: (0.2731) |  Loss2: (0.0000) | Acc: (90.00%) (32559/35968)
Epoch: 80 | Batch_idx: 290 |  Loss: (0.2735) |  Loss2: (0.0000) | Acc: (90.00%) (33705/37248)
Epoch: 80 | Batch_idx: 300 |  Loss: (0.2726) |  Loss2: (0.0000) | Acc: (90.00%) (34875/38528)
Epoch: 80 | Batch_idx: 310 |  Loss: (0.2724) |  Loss2: (0.0000) | Acc: (90.00%) (36029/39808)
Epoch: 80 | Batch_idx: 320 |  Loss: (0.2723) |  Loss2: (0.0000) | Acc: (90.00%) (37195/41088)
Epoch: 80 | Batch_idx: 330 |  Loss: (0.2723) |  Loss2: (0.0000) | Acc: (90.00%) (38348/42368)
Epoch: 80 | Batch_idx: 340 |  Loss: (0.2718) |  Loss2: (0.0000) | Acc: (90.00%) (39514/43648)
Epoch: 80 | Batch_idx: 350 |  Loss: (0.2716) |  Loss2: (0.0000) | Acc: (90.00%) (40682/44928)
Epoch: 80 | Batch_idx: 360 |  Loss: (0.2709) |  Loss2: (0.0000) | Acc: (90.00%) (41849/46208)
Epoch: 80 | Batch_idx: 370 |  Loss: (0.2703) |  Loss2: (0.0000) | Acc: (90.00%) (43016/47488)
Epoch: 80 | Batch_idx: 380 |  Loss: (0.2699) |  Loss2: (0.0000) | Acc: (90.00%) (44203/48768)
Epoch: 80 | Batch_idx: 390 |  Loss: (0.2699) |  Loss2: (0.0000) | Acc: (90.00%) (45323/50000)
=> saving checkpoint 'drive/app/torch/save_Schedule/checkpoint_080.pth.tar'
# TEST : Loss: (0.3974) | Acc: (86.00%) (8656/10000)
percent tensor([0.5164, 0.5182, 0.5195, 0.5187, 0.5196, 0.5183, 0.5196, 0.5211, 0.5171,
        0.5190, 0.5158, 0.5195, 0.5167, 0.5178, 0.5173, 0.5173],
       device='cuda:0') torch.Size([16])
percent tensor([0.5134, 0.5173, 0.5171, 0.5207, 0.5158, 0.5199, 0.5126, 0.5136, 0.5141,
        0.5158, 0.5144, 0.5182, 0.5177, 0.5123, 0.5185, 0.5176],
       device='cuda:0') torch.Size([16])
percent tensor([0.5730, 0.5200, 0.6007, 0.6212, 0.6083, 0.6031, 0.5687, 0.5998, 0.5950,
        0.5474, 0.5764, 0.5709, 0.4958, 0.6152, 0.5583, 0.5669],
       device='cuda:0') torch.Size([16])
percent tensor([0.6088, 0.6153, 0.5986, 0.5942, 0.6039, 0.5889, 0.6169, 0.6119, 0.6103,
        0.6104, 0.6105, 0.6138, 0.6158, 0.6031, 0.6183, 0.6044],
       device='cuda:0') torch.Size([16])
percent tensor([0.6101, 0.5980, 0.6268, 0.6582, 0.6441, 0.6907, 0.5838, 0.6077, 0.6230,
        0.6110, 0.5942, 0.6169, 0.6142, 0.6342, 0.5802, 0.6668],
       device='cuda:0') torch.Size([16])
percent tensor([0.5986, 0.6162, 0.6247, 0.6435, 0.6025, 0.7087, 0.6010, 0.5296, 0.6587,
        0.6060, 0.6618, 0.6366, 0.6698, 0.6604, 0.5675, 0.6235],
       device='cuda:0') torch.Size([16])
percent tensor([0.6117, 0.5705, 0.6325, 0.6552, 0.6640, 0.6728, 0.6049, 0.6274, 0.6071,
        0.5763, 0.5943, 0.5826, 0.5679, 0.5977, 0.5635, 0.6347],
       device='cuda:0') torch.Size([16])
percent tensor([0.9998, 0.9990, 0.9987, 0.9993, 0.9990, 0.9987, 0.9992, 0.9993, 0.9993,
        0.9992, 0.9996, 0.9992, 0.9996, 0.9992, 0.9977, 0.9992],
       device='cuda:0') torch.Size([16])
Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 3, 3, 3]) tensor(175.3601, device='cuda:0')
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(813.7208, device='cuda:0')
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(804.5806, device='cuda:0')
Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([128, 64, 3, 3]) tensor(1521.9000, device='cuda:0')
Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([128, 64, 1, 1]) tensor(498.4018, device='cuda:0')
Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([128, 128, 3, 3]) tensor(2227.3518, device='cuda:0')
Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([256, 128, 3, 3]) tensor(4283.7642, device='cuda:0')
Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([256, 128, 1, 1]) tensor(1405.2207, device='cuda:0')
Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([256, 256, 3, 3]) tensor(6137.3179, device='cuda:0')
Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([512, 256, 3, 3]) tensor(11930.7783, device='cuda:0')
Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([512, 256, 1, 1]) tensor(3964.0381, device='cuda:0')
Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([512, 512, 3, 3]) tensor(16781.2793, device='cuda:0')
Epoch: 81 | Batch_idx: 0 |  Loss: (0.1804) |  Loss2: (0.0000) | Acc: (93.00%) (120/128)
Epoch: 81 | Batch_idx: 10 |  Loss: (0.2434) |  Loss2: (0.0000) | Acc: (90.00%) (1281/1408)
Epoch: 81 | Batch_idx: 20 |  Loss: (0.2531) |  Loss2: (0.0000) | Acc: (90.00%) (2444/2688)
Epoch: 81 | Batch_idx: 30 |  Loss: (0.2654) |  Loss2: (0.0000) | Acc: (90.00%) (3591/3968)
Epoch: 81 | Batch_idx: 40 |  Loss: (0.2673) |  Loss2: (0.0000) | Acc: (90.00%) (4742/5248)
Epoch: 81 | Batch_idx: 50 |  Loss: (0.2681) |  Loss2: (0.0000) | Acc: (90.00%) (5879/6528)
Epoch: 81 | Batch_idx: 60 |  Loss: (0.2662) |  Loss2: (0.0000) | Acc: (90.00%) (7047/7808)
Epoch: 81 | Batch_idx: 70 |  Loss: (0.2667) |  Loss2: (0.0000) | Acc: (90.00%) (8208/9088)
Epoch: 81 | Batch_idx: 80 |  Loss: (0.2642) |  Loss2: (0.0000) | Acc: (90.00%) (9375/10368)
Epoch: 81 | Batch_idx: 90 |  Loss: (0.2628) |  Loss2: (0.0000) | Acc: (90.00%) (10553/11648)
Epoch: 81 | Batch_idx: 100 |  Loss: (0.2647) |  Loss2: (0.0000) | Acc: (90.00%) (11709/12928)
Epoch: 81 | Batch_idx: 110 |  Loss: (0.2672) |  Loss2: (0.0000) | Acc: (90.00%) (12864/14208)
Epoch: 81 | Batch_idx: 120 |  Loss: (0.2661) |  Loss2: (0.0000) | Acc: (90.00%) (14032/15488)
Epoch: 81 | Batch_idx: 130 |  Loss: (0.2638) |  Loss2: (0.0000) | Acc: (90.00%) (15209/16768)
Epoch: 81 | Batch_idx: 140 |  Loss: (0.2655) |  Loss2: (0.0000) | Acc: (90.00%) (16351/18048)
Epoch: 81 | Batch_idx: 150 |  Loss: (0.2662) |  Loss2: (0.0000) | Acc: (90.00%) (17513/19328)
Epoch: 81 | Batch_idx: 160 |  Loss: (0.2657) |  Loss2: (0.0000) | Acc: (90.00%) (18675/20608)
Epoch: 81 | Batch_idx: 170 |  Loss: (0.2658) |  Loss2: (0.0000) | Acc: (90.00%) (19844/21888)
Epoch: 81 | Batch_idx: 180 |  Loss: (0.2662) |  Loss2: (0.0000) | Acc: (90.00%) (20998/23168)
Epoch: 81 | Batch_idx: 190 |  Loss: (0.2665) |  Loss2: (0.0000) | Acc: (90.00%) (22153/24448)
Epoch: 81 | Batch_idx: 200 |  Loss: (0.2673) |  Loss2: (0.0000) | Acc: (90.00%) (23309/25728)
Epoch: 81 | Batch_idx: 210 |  Loss: (0.2676) |  Loss2: (0.0000) | Acc: (90.00%) (24463/27008)
Epoch: 81 | Batch_idx: 220 |  Loss: (0.2676) |  Loss2: (0.0000) | Acc: (90.00%) (25629/28288)
Epoch: 81 | Batch_idx: 230 |  Loss: (0.2672) |  Loss2: (0.0000) | Acc: (90.00%) (26796/29568)
Epoch: 81 | Batch_idx: 240 |  Loss: (0.2693) |  Loss2: (0.0000) | Acc: (90.00%) (27928/30848)
Epoch: 81 | Batch_idx: 250 |  Loss: (0.2686) |  Loss2: (0.0000) | Acc: (90.00%) (29100/32128)
Epoch: 81 | Batch_idx: 260 |  Loss: (0.2683) |  Loss2: (0.0000) | Acc: (90.00%) (30277/33408)
Epoch: 81 | Batch_idx: 270 |  Loss: (0.2694) |  Loss2: (0.0000) | Acc: (90.00%) (31430/34688)
Epoch: 81 | Batch_idx: 280 |  Loss: (0.2684) |  Loss2: (0.0000) | Acc: (90.00%) (32617/35968)
Epoch: 81 | Batch_idx: 290 |  Loss: (0.2673) |  Loss2: (0.0000) | Acc: (90.00%) (33788/37248)
Epoch: 81 | Batch_idx: 300 |  Loss: (0.2683) |  Loss2: (0.0000) | Acc: (90.00%) (34932/38528)
Epoch: 81 | Batch_idx: 310 |  Loss: (0.2685) |  Loss2: (0.0000) | Acc: (90.00%) (36097/39808)
Epoch: 81 | Batch_idx: 320 |  Loss: (0.2682) |  Loss2: (0.0000) | Acc: (90.00%) (37259/41088)
Epoch: 81 | Batch_idx: 330 |  Loss: (0.2678) |  Loss2: (0.0000) | Acc: (90.00%) (38434/42368)
Epoch: 81 | Batch_idx: 340 |  Loss: (0.2672) |  Loss2: (0.0000) | Acc: (90.00%) (39603/43648)
Epoch: 81 | Batch_idx: 350 |  Loss: (0.2670) |  Loss2: (0.0000) | Acc: (90.00%) (40764/44928)
Epoch: 81 | Batch_idx: 360 |  Loss: (0.2668) |  Loss2: (0.0000) | Acc: (90.00%) (41932/46208)
Epoch: 81 | Batch_idx: 370 |  Loss: (0.2663) |  Loss2: (0.0000) | Acc: (90.00%) (43101/47488)
Epoch: 81 | Batch_idx: 380 |  Loss: (0.2655) |  Loss2: (0.0000) | Acc: (90.00%) (44282/48768)
Epoch: 81 | Batch_idx: 390 |  Loss: (0.2665) |  Loss2: (0.0000) | Acc: (90.00%) (45393/50000)
# TEST : Loss: (0.3912) | Acc: (86.00%) (8691/10000)
percent tensor([0.5159, 0.5177, 0.5188, 0.5180, 0.5189, 0.5176, 0.5191, 0.5205, 0.5167,
        0.5185, 0.5154, 0.5190, 0.5164, 0.5176, 0.5167, 0.5168],
       device='cuda:0') torch.Size([16])
percent tensor([0.5132, 0.5174, 0.5168, 0.5203, 0.5156, 0.5196, 0.5127, 0.5133, 0.5139,
        0.5159, 0.5144, 0.5182, 0.5178, 0.5121, 0.5186, 0.5175],
       device='cuda:0') torch.Size([16])
percent tensor([0.5673, 0.5150, 0.5975, 0.6170, 0.6048, 0.5955, 0.5633, 0.5966, 0.5895,
        0.5431, 0.5717, 0.5650, 0.4913, 0.6102, 0.5508, 0.5611],
       device='cuda:0') torch.Size([16])
percent tensor([0.6103, 0.6173, 0.5989, 0.5943, 0.6037, 0.5884, 0.6180, 0.6119, 0.6118,
        0.6126, 0.6128, 0.6150, 0.6188, 0.6044, 0.6191, 0.6056],
       device='cuda:0') torch.Size([16])
percent tensor([0.6111, 0.5961, 0.6271, 0.6584, 0.6436, 0.6912, 0.5825, 0.6069, 0.6225,
        0.6110, 0.5929, 0.6144, 0.6138, 0.6315, 0.5786, 0.6660],
       device='cuda:0') torch.Size([16])
percent tensor([0.5996, 0.6212, 0.6266, 0.6457, 0.6048, 0.7116, 0.6046, 0.5289, 0.6628,
        0.6104, 0.6657, 0.6405, 0.6735, 0.6649, 0.5709, 0.6245],
       device='cuda:0') torch.Size([16])
percent tensor([0.6181, 0.5733, 0.6402, 0.6629, 0.6752, 0.6816, 0.6126, 0.6371, 0.6118,
        0.5787, 0.5966, 0.5858, 0.5698, 0.5991, 0.5680, 0.6431],
       device='cuda:0') torch.Size([16])
percent tensor([0.9998, 0.9990, 0.9988, 0.9994, 0.9992, 0.9987, 0.9993, 0.9993, 0.9993,
        0.9992, 0.9996, 0.9993, 0.9996, 0.9993, 0.9977, 0.9993],
       device='cuda:0') torch.Size([16])
Epoch: 82 | Batch_idx: 0 |  Loss: (0.3204) |  Loss2: (0.0000) | Acc: (87.00%) (112/128)
Epoch: 82 | Batch_idx: 10 |  Loss: (0.2637) |  Loss2: (0.0000) | Acc: (91.00%) (1285/1408)
Epoch: 82 | Batch_idx: 20 |  Loss: (0.2461) |  Loss2: (0.0000) | Acc: (92.00%) (2481/2688)
Epoch: 82 | Batch_idx: 30 |  Loss: (0.2526) |  Loss2: (0.0000) | Acc: (91.00%) (3649/3968)
Epoch: 82 | Batch_idx: 40 |  Loss: (0.2581) |  Loss2: (0.0000) | Acc: (91.00%) (4807/5248)
Epoch: 82 | Batch_idx: 50 |  Loss: (0.2599) |  Loss2: (0.0000) | Acc: (91.00%) (5974/6528)
Epoch: 82 | Batch_idx: 60 |  Loss: (0.2646) |  Loss2: (0.0000) | Acc: (91.00%) (7125/7808)
Epoch: 82 | Batch_idx: 70 |  Loss: (0.2638) |  Loss2: (0.0000) | Acc: (91.00%) (8297/9088)
Epoch: 82 | Batch_idx: 80 |  Loss: (0.2638) |  Loss2: (0.0000) | Acc: (91.00%) (9466/10368)
Epoch: 82 | Batch_idx: 90 |  Loss: (0.2649) |  Loss2: (0.0000) | Acc: (91.00%) (10637/11648)
Epoch: 82 | Batch_idx: 100 |  Loss: (0.2662) |  Loss2: (0.0000) | Acc: (91.00%) (11800/12928)
Epoch: 82 | Batch_idx: 110 |  Loss: (0.2669) |  Loss2: (0.0000) | Acc: (91.00%) (12964/14208)
Epoch: 82 | Batch_idx: 120 |  Loss: (0.2665) |  Loss2: (0.0000) | Acc: (91.00%) (14128/15488)
Epoch: 82 | Batch_idx: 130 |  Loss: (0.2658) |  Loss2: (0.0000) | Acc: (91.00%) (15300/16768)
Epoch: 82 | Batch_idx: 140 |  Loss: (0.2652) |  Loss2: (0.0000) | Acc: (91.00%) (16472/18048)
Epoch: 82 | Batch_idx: 150 |  Loss: (0.2648) |  Loss2: (0.0000) | Acc: (91.00%) (17640/19328)
Epoch: 82 | Batch_idx: 160 |  Loss: (0.2640) |  Loss2: (0.0000) | Acc: (91.00%) (18800/20608)
Epoch: 82 | Batch_idx: 170 |  Loss: (0.2631) |  Loss2: (0.0000) | Acc: (91.00%) (19964/21888)
Epoch: 82 | Batch_idx: 180 |  Loss: (0.2619) |  Loss2: (0.0000) | Acc: (91.00%) (21137/23168)
Epoch: 82 | Batch_idx: 190 |  Loss: (0.2624) |  Loss2: (0.0000) | Acc: (91.00%) (22300/24448)
Epoch: 82 | Batch_idx: 200 |  Loss: (0.2637) |  Loss2: (0.0000) | Acc: (91.00%) (23449/25728)
Epoch: 82 | Batch_idx: 210 |  Loss: (0.2632) |  Loss2: (0.0000) | Acc: (91.00%) (24617/27008)
Epoch: 82 | Batch_idx: 220 |  Loss: (0.2631) |  Loss2: (0.0000) | Acc: (91.00%) (25791/28288)
Epoch: 82 | Batch_idx: 230 |  Loss: (0.2639) |  Loss2: (0.0000) | Acc: (91.00%) (26947/29568)
Epoch: 82 | Batch_idx: 240 |  Loss: (0.2647) |  Loss2: (0.0000) | Acc: (91.00%) (28112/30848)
Epoch: 82 | Batch_idx: 250 |  Loss: (0.2642) |  Loss2: (0.0000) | Acc: (91.00%) (29271/32128)
Epoch: 82 | Batch_idx: 260 |  Loss: (0.2635) |  Loss2: (0.0000) | Acc: (91.00%) (30439/33408)
Epoch: 82 | Batch_idx: 270 |  Loss: (0.2635) |  Loss2: (0.0000) | Acc: (91.00%) (31593/34688)
Epoch: 82 | Batch_idx: 280 |  Loss: (0.2627) |  Loss2: (0.0000) | Acc: (91.00%) (32760/35968)
Epoch: 82 | Batch_idx: 290 |  Loss: (0.2619) |  Loss2: (0.0000) | Acc: (91.00%) (33928/37248)
Epoch: 82 | Batch_idx: 300 |  Loss: (0.2624) |  Loss2: (0.0000) | Acc: (91.00%) (35087/38528)
Epoch: 82 | Batch_idx: 310 |  Loss: (0.2624) |  Loss2: (0.0000) | Acc: (91.00%) (36252/39808)
Epoch: 82 | Batch_idx: 320 |  Loss: (0.2619) |  Loss2: (0.0000) | Acc: (91.00%) (37412/41088)
Epoch: 82 | Batch_idx: 330 |  Loss: (0.2625) |  Loss2: (0.0000) | Acc: (91.00%) (38575/42368)
Epoch: 82 | Batch_idx: 340 |  Loss: (0.2622) |  Loss2: (0.0000) | Acc: (91.00%) (39746/43648)
Epoch: 82 | Batch_idx: 350 |  Loss: (0.2617) |  Loss2: (0.0000) | Acc: (91.00%) (40903/44928)
Epoch: 82 | Batch_idx: 360 |  Loss: (0.2615) |  Loss2: (0.0000) | Acc: (91.00%) (42064/46208)
Epoch: 82 | Batch_idx: 370 |  Loss: (0.2616) |  Loss2: (0.0000) | Acc: (91.00%) (43229/47488)
Epoch: 82 | Batch_idx: 380 |  Loss: (0.2615) |  Loss2: (0.0000) | Acc: (91.00%) (44401/48768)
Epoch: 82 | Batch_idx: 390 |  Loss: (0.2619) |  Loss2: (0.0000) | Acc: (91.00%) (45516/50000)
# TEST : Loss: (0.3863) | Acc: (86.00%) (8691/10000)
percent tensor([0.5162, 0.5181, 0.5190, 0.5181, 0.5192, 0.5175, 0.5195, 0.5207, 0.5171,
        0.5189, 0.5158, 0.5193, 0.5168, 0.5180, 0.5168, 0.5171],
       device='cuda:0') torch.Size([16])
percent tensor([0.5126, 0.5170, 0.5158, 0.5191, 0.5148, 0.5190, 0.5122, 0.5124, 0.5131,
        0.5154, 0.5138, 0.5175, 0.5174, 0.5113, 0.5181, 0.5169],
       device='cuda:0') torch.Size([16])
percent tensor([0.5636, 0.5127, 0.5950, 0.6142, 0.6039, 0.5925, 0.5615, 0.5958, 0.5865,
        0.5397, 0.5692, 0.5599, 0.4877, 0.6085, 0.5482, 0.5570],
       device='cuda:0') torch.Size([16])
percent tensor([0.6083, 0.6162, 0.5962, 0.5915, 0.6008, 0.5856, 0.6160, 0.6089, 0.6096,
        0.6110, 0.6117, 0.6126, 0.6179, 0.6023, 0.6174, 0.6034],
       device='cuda:0') torch.Size([16])
percent tensor([0.6144, 0.5997, 0.6312, 0.6605, 0.6480, 0.6948, 0.5847, 0.6099, 0.6273,
        0.6158, 0.5968, 0.6172, 0.6177, 0.6349, 0.5797, 0.6684],
       device='cuda:0') torch.Size([16])
percent tensor([0.5934, 0.6160, 0.6213, 0.6417, 0.5997, 0.7075, 0.5993, 0.5213, 0.6600,
        0.6069, 0.6614, 0.6369, 0.6697, 0.6604, 0.5643, 0.6184],
       device='cuda:0') torch.Size([16])
percent tensor([0.6232, 0.5758, 0.6456, 0.6686, 0.6837, 0.6884, 0.6197, 0.6450, 0.6170,
        0.5822, 0.5994, 0.5915, 0.5741, 0.6009, 0.5733, 0.6499],
       device='cuda:0') torch.Size([16])
percent tensor([0.9998, 0.9991, 0.9989, 0.9994, 0.9992, 0.9987, 0.9994, 0.9994, 0.9994,
        0.9992, 0.9997, 0.9992, 0.9997, 0.9993, 0.9979, 0.9993],
       device='cuda:0') torch.Size([16])
Epoch: 83 | Batch_idx: 0 |  Loss: (0.2546) |  Loss2: (0.0000) | Acc: (92.00%) (118/128)
Epoch: 83 | Batch_idx: 10 |  Loss: (0.2501) |  Loss2: (0.0000) | Acc: (92.00%) (1306/1408)
Epoch: 83 | Batch_idx: 20 |  Loss: (0.2556) |  Loss2: (0.0000) | Acc: (92.00%) (2473/2688)
Epoch: 83 | Batch_idx: 30 |  Loss: (0.2590) |  Loss2: (0.0000) | Acc: (91.00%) (3650/3968)
Epoch: 83 | Batch_idx: 40 |  Loss: (0.2577) |  Loss2: (0.0000) | Acc: (91.00%) (4810/5248)
Epoch: 83 | Batch_idx: 50 |  Loss: (0.2620) |  Loss2: (0.0000) | Acc: (91.00%) (5967/6528)
Epoch: 83 | Batch_idx: 60 |  Loss: (0.2587) |  Loss2: (0.0000) | Acc: (91.00%) (7150/7808)
Epoch: 83 | Batch_idx: 70 |  Loss: (0.2596) |  Loss2: (0.0000) | Acc: (91.00%) (8311/9088)
Epoch: 83 | Batch_idx: 80 |  Loss: (0.2551) |  Loss2: (0.0000) | Acc: (91.00%) (9497/10368)
Epoch: 83 | Batch_idx: 90 |  Loss: (0.2519) |  Loss2: (0.0000) | Acc: (91.00%) (10683/11648)
Epoch: 83 | Batch_idx: 100 |  Loss: (0.2527) |  Loss2: (0.0000) | Acc: (91.00%) (11848/12928)
Epoch: 83 | Batch_idx: 110 |  Loss: (0.2522) |  Loss2: (0.0000) | Acc: (91.00%) (13026/14208)
Epoch: 83 | Batch_idx: 120 |  Loss: (0.2529) |  Loss2: (0.0000) | Acc: (91.00%) (14184/15488)
Epoch: 83 | Batch_idx: 130 |  Loss: (0.2533) |  Loss2: (0.0000) | Acc: (91.00%) (15353/16768)
Epoch: 83 | Batch_idx: 140 |  Loss: (0.2527) |  Loss2: (0.0000) | Acc: (91.00%) (16528/18048)
Epoch: 83 | Batch_idx: 150 |  Loss: (0.2557) |  Loss2: (0.0000) | Acc: (91.00%) (17684/19328)
Epoch: 83 | Batch_idx: 160 |  Loss: (0.2585) |  Loss2: (0.0000) | Acc: (91.00%) (18830/20608)
Epoch: 83 | Batch_idx: 170 |  Loss: (0.2598) |  Loss2: (0.0000) | Acc: (91.00%) (19991/21888)
Epoch: 83 | Batch_idx: 180 |  Loss: (0.2601) |  Loss2: (0.0000) | Acc: (91.00%) (21154/23168)
Epoch: 83 | Batch_idx: 190 |  Loss: (0.2589) |  Loss2: (0.0000) | Acc: (91.00%) (22331/24448)
Epoch: 83 | Batch_idx: 200 |  Loss: (0.2590) |  Loss2: (0.0000) | Acc: (91.00%) (23490/25728)
Epoch: 83 | Batch_idx: 210 |  Loss: (0.2582) |  Loss2: (0.0000) | Acc: (91.00%) (24666/27008)
Epoch: 83 | Batch_idx: 220 |  Loss: (0.2578) |  Loss2: (0.0000) | Acc: (91.00%) (25842/28288)
Epoch: 83 | Batch_idx: 230 |  Loss: (0.2581) |  Loss2: (0.0000) | Acc: (91.00%) (27009/29568)
Epoch: 83 | Batch_idx: 240 |  Loss: (0.2585) |  Loss2: (0.0000) | Acc: (91.00%) (28171/30848)
Epoch: 83 | Batch_idx: 250 |  Loss: (0.2580) |  Loss2: (0.0000) | Acc: (91.00%) (29346/32128)
Epoch: 83 | Batch_idx: 260 |  Loss: (0.2581) |  Loss2: (0.0000) | Acc: (91.00%) (30518/33408)
Epoch: 83 | Batch_idx: 270 |  Loss: (0.2590) |  Loss2: (0.0000) | Acc: (91.00%) (31678/34688)
Epoch: 83 | Batch_idx: 280 |  Loss: (0.2582) |  Loss2: (0.0000) | Acc: (91.00%) (32847/35968)
Epoch: 83 | Batch_idx: 290 |  Loss: (0.2580) |  Loss2: (0.0000) | Acc: (91.00%) (34018/37248)
Epoch: 83 | Batch_idx: 300 |  Loss: (0.2581) |  Loss2: (0.0000) | Acc: (91.00%) (35185/38528)
Epoch: 83 | Batch_idx: 310 |  Loss: (0.2583) |  Loss2: (0.0000) | Acc: (91.00%) (36347/39808)
Epoch: 83 | Batch_idx: 320 |  Loss: (0.2580) |  Loss2: (0.0000) | Acc: (91.00%) (37508/41088)
Epoch: 83 | Batch_idx: 330 |  Loss: (0.2565) |  Loss2: (0.0000) | Acc: (91.00%) (38695/42368)
Epoch: 83 | Batch_idx: 340 |  Loss: (0.2567) |  Loss2: (0.0000) | Acc: (91.00%) (39860/43648)
Epoch: 83 | Batch_idx: 350 |  Loss: (0.2567) |  Loss2: (0.0000) | Acc: (91.00%) (41029/44928)
Epoch: 83 | Batch_idx: 360 |  Loss: (0.2563) |  Loss2: (0.0000) | Acc: (91.00%) (42204/46208)
Epoch: 83 | Batch_idx: 370 |  Loss: (0.2559) |  Loss2: (0.0000) | Acc: (91.00%) (43372/47488)
Epoch: 83 | Batch_idx: 380 |  Loss: (0.2553) |  Loss2: (0.0000) | Acc: (91.00%) (44551/48768)
Epoch: 83 | Batch_idx: 390 |  Loss: (0.2552) |  Loss2: (0.0000) | Acc: (91.00%) (45671/50000)
# TEST : Loss: (0.3850) | Acc: (87.00%) (8701/10000)
percent tensor([0.5150, 0.5166, 0.5175, 0.5167, 0.5176, 0.5162, 0.5179, 0.5192, 0.5160,
        0.5174, 0.5146, 0.5179, 0.5156, 0.5168, 0.5154, 0.5158],
       device='cuda:0') torch.Size([16])
percent tensor([0.5131, 0.5181, 0.5164, 0.5197, 0.5156, 0.5193, 0.5133, 0.5132, 0.5140,
        0.5165, 0.5148, 0.5184, 0.5181, 0.5122, 0.5188, 0.5174],
       device='cuda:0') torch.Size([16])
percent tensor([0.5631, 0.5107, 0.5956, 0.6148, 0.6037, 0.5911, 0.5591, 0.5954, 0.5852,
        0.5391, 0.5676, 0.5602, 0.4876, 0.6048, 0.5458, 0.5567],
       device='cuda:0') torch.Size([16])
percent tensor([0.6076, 0.6154, 0.5952, 0.5903, 0.5989, 0.5837, 0.6149, 0.6075, 0.6094,
        0.6108, 0.6113, 0.6123, 0.6183, 0.6016, 0.6159, 0.6023],
       device='cuda:0') torch.Size([16])
percent tensor([0.6053, 0.5926, 0.6224, 0.6533, 0.6423, 0.6875, 0.5768, 0.6017, 0.6202,
        0.6096, 0.5906, 0.6085, 0.6090, 0.6285, 0.5711, 0.6599],
       device='cuda:0') torch.Size([16])
percent tensor([0.5962, 0.6222, 0.6229, 0.6438, 0.6022, 0.7103, 0.6035, 0.5235, 0.6623,
        0.6113, 0.6649, 0.6385, 0.6729, 0.6649, 0.5702, 0.6211],
       device='cuda:0') torch.Size([16])
percent tensor([0.6253, 0.5780, 0.6462, 0.6682, 0.6851, 0.6892, 0.6226, 0.6476, 0.6175,
        0.5839, 0.6004, 0.5913, 0.5736, 0.6004, 0.5757, 0.6512],
       device='cuda:0') torch.Size([16])
percent tensor([0.9998, 0.9991, 0.9990, 0.9994, 0.9993, 0.9988, 0.9994, 0.9994, 0.9994,
        0.9993, 0.9997, 0.9993, 0.9997, 0.9994, 0.9980, 0.9993],
       device='cuda:0') torch.Size([16])
True Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=128, out_features=16, bias=False)
False Linear(in_features=16, out_features=2, bias=False)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=128, out_features=16, bias=False)
False Linear(in_features=16, out_features=2, bias=False)
True Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=256, out_features=32, bias=False)
False Linear(in_features=32, out_features=2, bias=False)
True Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=256, out_features=32, bias=False)
False Linear(in_features=32, out_features=2, bias=False)
True Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=512, out_features=64, bias=False)
False Linear(in_features=64, out_features=2, bias=False)
True Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=512, out_features=64, bias=False)
False Linear(in_features=64, out_features=2, bias=False)
True Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1024, out_features=128, bias=False)
False Linear(in_features=128, out_features=2, bias=False)
True Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1024, out_features=128, bias=False)
False Linear(in_features=128, out_features=2, bias=False)
True Linear(in_features=512, out_features=10, bias=True)
Epoch: 84 | Batch_idx: 0 |  Loss: (0.3285) |  Loss2: (0.0000) | Acc: (87.00%) (112/128)
Epoch: 84 | Batch_idx: 10 |  Loss: (0.2285) |  Loss2: (0.0000) | Acc: (92.00%) (1303/1408)
Epoch: 84 | Batch_idx: 20 |  Loss: (0.2371) |  Loss2: (0.0000) | Acc: (92.00%) (2475/2688)
Epoch: 84 | Batch_idx: 30 |  Loss: (0.2455) |  Loss2: (0.0000) | Acc: (92.00%) (3653/3968)
Epoch: 84 | Batch_idx: 40 |  Loss: (0.2476) |  Loss2: (0.0000) | Acc: (91.00%) (4814/5248)
Epoch: 84 | Batch_idx: 50 |  Loss: (0.2451) |  Loss2: (0.0000) | Acc: (91.00%) (6001/6528)
Epoch: 84 | Batch_idx: 60 |  Loss: (0.2488) |  Loss2: (0.0000) | Acc: (91.00%) (7158/7808)
Epoch: 84 | Batch_idx: 70 |  Loss: (0.2536) |  Loss2: (0.0000) | Acc: (91.00%) (8311/9088)
Epoch: 84 | Batch_idx: 80 |  Loss: (0.2549) |  Loss2: (0.0000) | Acc: (91.00%) (9465/10368)
Epoch: 84 | Batch_idx: 90 |  Loss: (0.2587) |  Loss2: (0.0000) | Acc: (91.00%) (10617/11648)
Epoch: 84 | Batch_idx: 100 |  Loss: (0.2609) |  Loss2: (0.0000) | Acc: (91.00%) (11781/12928)
Epoch: 84 | Batch_idx: 110 |  Loss: (0.2601) |  Loss2: (0.0000) | Acc: (91.00%) (12956/14208)
Epoch: 84 | Batch_idx: 120 |  Loss: (0.2620) |  Loss2: (0.0000) | Acc: (91.00%) (14110/15488)
Epoch: 84 | Batch_idx: 130 |  Loss: (0.2621) |  Loss2: (0.0000) | Acc: (91.00%) (15267/16768)
Epoch: 84 | Batch_idx: 140 |  Loss: (0.2630) |  Loss2: (0.0000) | Acc: (91.00%) (16424/18048)
Epoch: 84 | Batch_idx: 150 |  Loss: (0.2659) |  Loss2: (0.0000) | Acc: (90.00%) (17567/19328)
Epoch: 84 | Batch_idx: 160 |  Loss: (0.2682) |  Loss2: (0.0000) | Acc: (90.00%) (18709/20608)
Epoch: 84 | Batch_idx: 170 |  Loss: (0.2726) |  Loss2: (0.0000) | Acc: (90.00%) (19839/21888)
Epoch: 84 | Batch_idx: 180 |  Loss: (0.2736) |  Loss2: (0.0000) | Acc: (90.00%) (20992/23168)
Epoch: 84 | Batch_idx: 190 |  Loss: (0.2762) |  Loss2: (0.0000) | Acc: (90.00%) (22122/24448)
Epoch: 84 | Batch_idx: 200 |  Loss: (0.2782) |  Loss2: (0.0000) | Acc: (90.00%) (23263/25728)
Epoch: 84 | Batch_idx: 210 |  Loss: (0.2795) |  Loss2: (0.0000) | Acc: (90.00%) (24409/27008)
Epoch: 84 | Batch_idx: 220 |  Loss: (0.2793) |  Loss2: (0.0000) | Acc: (90.00%) (25559/28288)
Epoch: 84 | Batch_idx: 230 |  Loss: (0.2808) |  Loss2: (0.0000) | Acc: (90.00%) (26688/29568)
Epoch: 84 | Batch_idx: 240 |  Loss: (0.2800) |  Loss2: (0.0000) | Acc: (90.00%) (27853/30848)
Epoch: 84 | Batch_idx: 250 |  Loss: (0.2799) |  Loss2: (0.0000) | Acc: (90.00%) (29010/32128)
Epoch: 84 | Batch_idx: 260 |  Loss: (0.2791) |  Loss2: (0.0000) | Acc: (90.00%) (30174/33408)
Epoch: 84 | Batch_idx: 270 |  Loss: (0.2790) |  Loss2: (0.0000) | Acc: (90.00%) (31335/34688)
Epoch: 84 | Batch_idx: 280 |  Loss: (0.2784) |  Loss2: (0.0000) | Acc: (90.00%) (32500/35968)
Epoch: 84 | Batch_idx: 290 |  Loss: (0.2779) |  Loss2: (0.0000) | Acc: (90.00%) (33664/37248)
Epoch: 84 | Batch_idx: 300 |  Loss: (0.2776) |  Loss2: (0.0000) | Acc: (90.00%) (34819/38528)
Epoch: 84 | Batch_idx: 310 |  Loss: (0.2785) |  Loss2: (0.0000) | Acc: (90.00%) (35962/39808)
Epoch: 84 | Batch_idx: 320 |  Loss: (0.2802) |  Loss2: (0.0000) | Acc: (90.00%) (37091/41088)
Epoch: 84 | Batch_idx: 330 |  Loss: (0.2805) |  Loss2: (0.0000) | Acc: (90.00%) (38231/42368)
Epoch: 84 | Batch_idx: 340 |  Loss: (0.2804) |  Loss2: (0.0000) | Acc: (90.00%) (39379/43648)
Epoch: 84 | Batch_idx: 350 |  Loss: (0.2804) |  Loss2: (0.0000) | Acc: (90.00%) (40535/44928)
Epoch: 84 | Batch_idx: 360 |  Loss: (0.2800) |  Loss2: (0.0000) | Acc: (90.00%) (41699/46208)
Epoch: 84 | Batch_idx: 370 |  Loss: (0.2786) |  Loss2: (0.0000) | Acc: (90.00%) (42868/47488)
Epoch: 84 | Batch_idx: 380 |  Loss: (0.2782) |  Loss2: (0.0000) | Acc: (90.00%) (44029/48768)
Epoch: 84 | Batch_idx: 390 |  Loss: (0.2784) |  Loss2: (0.0000) | Acc: (90.00%) (45158/50000)
# TEST : Loss: (0.4890) | Acc: (84.00%) (8423/10000)
percent tensor([0.5147, 0.5169, 0.5170, 0.5169, 0.5169, 0.5161, 0.5179, 0.5193, 0.5157,
        0.5174, 0.5145, 0.5172, 0.5153, 0.5180, 0.5154, 0.5158],
       device='cuda:0') torch.Size([16])
percent tensor([0.5127, 0.5160, 0.5177, 0.5194, 0.5165, 0.5190, 0.5122, 0.5124, 0.5133,
        0.5158, 0.5136, 0.5189, 0.5173, 0.5103, 0.5181, 0.5167],
       device='cuda:0') torch.Size([16])
percent tensor([0.5602, 0.5172, 0.5973, 0.6171, 0.6090, 0.5758, 0.5673, 0.6002, 0.5963,
        0.5510, 0.5714, 0.5660, 0.4888, 0.6168, 0.5443, 0.5594],
       device='cuda:0') torch.Size([16])
percent tensor([0.6090, 0.6140, 0.5959, 0.5921, 0.6003, 0.5858, 0.6145, 0.6053, 0.6124,
        0.6098, 0.6124, 0.6129, 0.6195, 0.6038, 0.6150, 0.6013],
       device='cuda:0') torch.Size([16])
percent tensor([0.5856, 0.5936, 0.6302, 0.6396, 0.6456, 0.6688, 0.5778, 0.5965, 0.6183,
        0.6261, 0.5968, 0.6163, 0.6018, 0.6426, 0.5654, 0.6487],
       device='cuda:0') torch.Size([16])
percent tensor([0.5929, 0.6358, 0.6259, 0.6438, 0.6271, 0.6926, 0.6095, 0.5337, 0.6522,
        0.6320, 0.6725, 0.6497, 0.6609, 0.6706, 0.5713, 0.6156],
       device='cuda:0') torch.Size([16])
percent tensor([0.6141, 0.5892, 0.6400, 0.6478, 0.6773, 0.6760, 0.6249, 0.6489, 0.6106,
        0.5845, 0.6055, 0.5938, 0.5694, 0.6114, 0.5773, 0.6425],
       device='cuda:0') torch.Size([16])
percent tensor([0.9997, 0.9991, 0.9992, 0.9994, 0.9986, 0.9988, 0.9993, 0.9995, 0.9996,
        0.9992, 0.9997, 0.9996, 0.9995, 0.9992, 0.9986, 0.9994],
       device='cuda:0') torch.Size([16])
Epoch: 85 | Batch_idx: 0 |  Loss: (0.2196) |  Loss2: (0.0000) | Acc: (90.00%) (116/128)
Epoch: 85 | Batch_idx: 10 |  Loss: (0.2436) |  Loss2: (0.0000) | Acc: (91.00%) (1291/1408)
Epoch: 85 | Batch_idx: 20 |  Loss: (0.2617) |  Loss2: (0.0000) | Acc: (91.00%) (2448/2688)
Epoch: 85 | Batch_idx: 30 |  Loss: (0.2693) |  Loss2: (0.0000) | Acc: (90.00%) (3601/3968)
Epoch: 85 | Batch_idx: 40 |  Loss: (0.2750) |  Loss2: (0.0000) | Acc: (90.00%) (4751/5248)
Epoch: 85 | Batch_idx: 50 |  Loss: (0.2739) |  Loss2: (0.0000) | Acc: (90.00%) (5905/6528)
Epoch: 85 | Batch_idx: 60 |  Loss: (0.2713) |  Loss2: (0.0000) | Acc: (90.00%) (7082/7808)
Epoch: 85 | Batch_idx: 70 |  Loss: (0.2733) |  Loss2: (0.0000) | Acc: (90.00%) (8234/9088)
Epoch: 85 | Batch_idx: 80 |  Loss: (0.2734) |  Loss2: (0.0000) | Acc: (90.00%) (9403/10368)
Epoch: 85 | Batch_idx: 90 |  Loss: (0.2746) |  Loss2: (0.0000) | Acc: (90.00%) (10550/11648)
Epoch: 85 | Batch_idx: 100 |  Loss: (0.2695) |  Loss2: (0.0000) | Acc: (90.00%) (11741/12928)
Epoch: 85 | Batch_idx: 110 |  Loss: (0.2701) |  Loss2: (0.0000) | Acc: (90.00%) (12898/14208)
Epoch: 85 | Batch_idx: 120 |  Loss: (0.2690) |  Loss2: (0.0000) | Acc: (90.00%) (14065/15488)
Epoch: 85 | Batch_idx: 130 |  Loss: (0.2695) |  Loss2: (0.0000) | Acc: (90.00%) (15224/16768)
Epoch: 85 | Batch_idx: 140 |  Loss: (0.2674) |  Loss2: (0.0000) | Acc: (90.00%) (16400/18048)
Epoch: 85 | Batch_idx: 150 |  Loss: (0.2665) |  Loss2: (0.0000) | Acc: (90.00%) (17563/19328)
Epoch: 85 | Batch_idx: 160 |  Loss: (0.2652) |  Loss2: (0.0000) | Acc: (90.00%) (18731/20608)
Epoch: 85 | Batch_idx: 170 |  Loss: (0.2651) |  Loss2: (0.0000) | Acc: (90.00%) (19892/21888)
Epoch: 85 | Batch_idx: 180 |  Loss: (0.2658) |  Loss2: (0.0000) | Acc: (90.00%) (21039/23168)
Epoch: 85 | Batch_idx: 190 |  Loss: (0.2653) |  Loss2: (0.0000) | Acc: (90.00%) (22208/24448)
Epoch: 85 | Batch_idx: 200 |  Loss: (0.2660) |  Loss2: (0.0000) | Acc: (90.00%) (23370/25728)
Epoch: 85 | Batch_idx: 210 |  Loss: (0.2680) |  Loss2: (0.0000) | Acc: (90.00%) (24535/27008)
Epoch: 85 | Batch_idx: 220 |  Loss: (0.2681) |  Loss2: (0.0000) | Acc: (90.00%) (25701/28288)
Epoch: 85 | Batch_idx: 230 |  Loss: (0.2686) |  Loss2: (0.0000) | Acc: (90.00%) (26859/29568)
Epoch: 85 | Batch_idx: 240 |  Loss: (0.2685) |  Loss2: (0.0000) | Acc: (90.00%) (28017/30848)
Epoch: 85 | Batch_idx: 250 |  Loss: (0.2702) |  Loss2: (0.0000) | Acc: (90.00%) (29164/32128)
Epoch: 85 | Batch_idx: 260 |  Loss: (0.2703) |  Loss2: (0.0000) | Acc: (90.00%) (30332/33408)
Epoch: 85 | Batch_idx: 270 |  Loss: (0.2703) |  Loss2: (0.0000) | Acc: (90.00%) (31492/34688)
Epoch: 85 | Batch_idx: 280 |  Loss: (0.2707) |  Loss2: (0.0000) | Acc: (90.00%) (32637/35968)
Epoch: 85 | Batch_idx: 290 |  Loss: (0.2699) |  Loss2: (0.0000) | Acc: (90.00%) (33819/37248)
Epoch: 85 | Batch_idx: 300 |  Loss: (0.2700) |  Loss2: (0.0000) | Acc: (90.00%) (34979/38528)
Epoch: 85 | Batch_idx: 310 |  Loss: (0.2693) |  Loss2: (0.0000) | Acc: (90.00%) (36141/39808)
Epoch: 85 | Batch_idx: 320 |  Loss: (0.2699) |  Loss2: (0.0000) | Acc: (90.00%) (37287/41088)
Epoch: 85 | Batch_idx: 330 |  Loss: (0.2701) |  Loss2: (0.0000) | Acc: (90.00%) (38445/42368)
Epoch: 85 | Batch_idx: 340 |  Loss: (0.2699) |  Loss2: (0.0000) | Acc: (90.00%) (39606/43648)
Epoch: 85 | Batch_idx: 350 |  Loss: (0.2706) |  Loss2: (0.0000) | Acc: (90.00%) (40754/44928)
Epoch: 85 | Batch_idx: 360 |  Loss: (0.2699) |  Loss2: (0.0000) | Acc: (90.00%) (41935/46208)
Epoch: 85 | Batch_idx: 370 |  Loss: (0.2697) |  Loss2: (0.0000) | Acc: (90.00%) (43089/47488)
Epoch: 85 | Batch_idx: 380 |  Loss: (0.2707) |  Loss2: (0.0000) | Acc: (90.00%) (44237/48768)
Epoch: 85 | Batch_idx: 390 |  Loss: (0.2708) |  Loss2: (0.0000) | Acc: (90.00%) (45355/50000)
=> saving checkpoint 'drive/app/torch/save_Schedule/checkpoint_085.pth.tar'
# TEST : Loss: (0.5200) | Acc: (83.00%) (8350/10000)
percent tensor([0.5149, 0.5165, 0.5180, 0.5172, 0.5177, 0.5160, 0.5180, 0.5195, 0.5154,
        0.5176, 0.5144, 0.5181, 0.5152, 0.5167, 0.5154, 0.5159],
       device='cuda:0') torch.Size([16])
percent tensor([0.5120, 0.5186, 0.5137, 0.5168, 0.5136, 0.5186, 0.5136, 0.5125, 0.5138,
        0.5160, 0.5146, 0.5161, 0.5175, 0.5144, 0.5179, 0.5165],
       device='cuda:0') torch.Size([16])
percent tensor([0.5493, 0.4945, 0.6013, 0.6144, 0.6090, 0.5729, 0.5529, 0.5946, 0.5821,
        0.5365, 0.5487, 0.5689, 0.4755, 0.5929, 0.5328, 0.5457],
       device='cuda:0') torch.Size([16])
percent tensor([0.6069, 0.6189, 0.5950, 0.5925, 0.5971, 0.5843, 0.6140, 0.6096, 0.6098,
        0.6118, 0.6156, 0.6100, 0.6182, 0.6056, 0.6150, 0.6031],
       device='cuda:0') torch.Size([16])
percent tensor([0.5895, 0.5881, 0.6162, 0.6356, 0.6405, 0.6842, 0.5748, 0.5918, 0.6131,
        0.6178, 0.5769, 0.6080, 0.6088, 0.6382, 0.5680, 0.6456],
       device='cuda:0') torch.Size([16])
percent tensor([0.5925, 0.6292, 0.6018, 0.6376, 0.6045, 0.7032, 0.5945, 0.5256, 0.6566,
        0.6062, 0.6599, 0.6250, 0.6677, 0.6691, 0.5736, 0.6206],
       device='cuda:0') torch.Size([16])
percent tensor([0.6161, 0.5841, 0.6344, 0.6512, 0.6728, 0.6861, 0.6203, 0.6386, 0.5957,
        0.5828, 0.5954, 0.5873, 0.5817, 0.6116, 0.5776, 0.6429],
       device='cuda:0') torch.Size([16])
percent tensor([0.9997, 0.9993, 0.9991, 0.9993, 0.9989, 0.9978, 0.9991, 0.9995, 0.9996,
        0.9993, 0.9996, 0.9991, 0.9995, 0.9995, 0.9984, 0.9996],
       device='cuda:0') torch.Size([16])
Epoch: 86 | Batch_idx: 0 |  Loss: (0.1594) |  Loss2: (0.0000) | Acc: (94.00%) (121/128)
Epoch: 86 | Batch_idx: 10 |  Loss: (0.2603) |  Loss2: (0.0000) | Acc: (91.00%) (1282/1408)
Epoch: 86 | Batch_idx: 20 |  Loss: (0.2430) |  Loss2: (0.0000) | Acc: (91.00%) (2462/2688)
Epoch: 86 | Batch_idx: 30 |  Loss: (0.2381) |  Loss2: (0.0000) | Acc: (91.00%) (3637/3968)
Epoch: 86 | Batch_idx: 40 |  Loss: (0.2406) |  Loss2: (0.0000) | Acc: (91.00%) (4816/5248)
Epoch: 86 | Batch_idx: 50 |  Loss: (0.2450) |  Loss2: (0.0000) | Acc: (91.00%) (5982/6528)
Epoch: 86 | Batch_idx: 60 |  Loss: (0.2518) |  Loss2: (0.0000) | Acc: (91.00%) (7130/7808)
Epoch: 86 | Batch_idx: 70 |  Loss: (0.2513) |  Loss2: (0.0000) | Acc: (91.00%) (8292/9088)
Epoch: 86 | Batch_idx: 80 |  Loss: (0.2540) |  Loss2: (0.0000) | Acc: (91.00%) (9459/10368)
Epoch: 86 | Batch_idx: 90 |  Loss: (0.2528) |  Loss2: (0.0000) | Acc: (91.00%) (10632/11648)
Epoch: 86 | Batch_idx: 100 |  Loss: (0.2496) |  Loss2: (0.0000) | Acc: (91.00%) (11808/12928)
Epoch: 86 | Batch_idx: 110 |  Loss: (0.2467) |  Loss2: (0.0000) | Acc: (91.00%) (12988/14208)
Epoch: 86 | Batch_idx: 120 |  Loss: (0.2482) |  Loss2: (0.0000) | Acc: (91.00%) (14146/15488)
Epoch: 86 | Batch_idx: 130 |  Loss: (0.2499) |  Loss2: (0.0000) | Acc: (91.00%) (15309/16768)
Epoch: 86 | Batch_idx: 140 |  Loss: (0.2532) |  Loss2: (0.0000) | Acc: (91.00%) (16454/18048)
Epoch: 86 | Batch_idx: 150 |  Loss: (0.2535) |  Loss2: (0.0000) | Acc: (91.00%) (17623/19328)
Epoch: 86 | Batch_idx: 160 |  Loss: (0.2539) |  Loss2: (0.0000) | Acc: (91.00%) (18784/20608)
Epoch: 86 | Batch_idx: 170 |  Loss: (0.2554) |  Loss2: (0.0000) | Acc: (91.00%) (19939/21888)
Epoch: 86 | Batch_idx: 180 |  Loss: (0.2559) |  Loss2: (0.0000) | Acc: (91.00%) (21103/23168)
Epoch: 86 | Batch_idx: 190 |  Loss: (0.2563) |  Loss2: (0.0000) | Acc: (91.00%) (22266/24448)
Epoch: 86 | Batch_idx: 200 |  Loss: (0.2580) |  Loss2: (0.0000) | Acc: (91.00%) (23413/25728)
Epoch: 86 | Batch_idx: 210 |  Loss: (0.2585) |  Loss2: (0.0000) | Acc: (90.00%) (24566/27008)
Epoch: 86 | Batch_idx: 220 |  Loss: (0.2592) |  Loss2: (0.0000) | Acc: (90.00%) (25728/28288)
Epoch: 86 | Batch_idx: 230 |  Loss: (0.2592) |  Loss2: (0.0000) | Acc: (90.00%) (26882/29568)
Epoch: 86 | Batch_idx: 240 |  Loss: (0.2586) |  Loss2: (0.0000) | Acc: (90.00%) (28057/30848)
Epoch: 86 | Batch_idx: 250 |  Loss: (0.2595) |  Loss2: (0.0000) | Acc: (90.00%) (29215/32128)
Epoch: 86 | Batch_idx: 260 |  Loss: (0.2592) |  Loss2: (0.0000) | Acc: (90.00%) (30385/33408)
Epoch: 86 | Batch_idx: 270 |  Loss: (0.2598) |  Loss2: (0.0000) | Acc: (90.00%) (31537/34688)
Epoch: 86 | Batch_idx: 280 |  Loss: (0.2596) |  Loss2: (0.0000) | Acc: (90.00%) (32710/35968)
Epoch: 86 | Batch_idx: 290 |  Loss: (0.2592) |  Loss2: (0.0000) | Acc: (90.00%) (33881/37248)
Epoch: 86 | Batch_idx: 300 |  Loss: (0.2594) |  Loss2: (0.0000) | Acc: (90.00%) (35038/38528)
Epoch: 86 | Batch_idx: 310 |  Loss: (0.2604) |  Loss2: (0.0000) | Acc: (90.00%) (36192/39808)
Epoch: 86 | Batch_idx: 320 |  Loss: (0.2601) |  Loss2: (0.0000) | Acc: (90.00%) (37363/41088)
Epoch: 86 | Batch_idx: 330 |  Loss: (0.2605) |  Loss2: (0.0000) | Acc: (90.00%) (38516/42368)
Epoch: 86 | Batch_idx: 340 |  Loss: (0.2609) |  Loss2: (0.0000) | Acc: (90.00%) (39673/43648)
Epoch: 86 | Batch_idx: 350 |  Loss: (0.2615) |  Loss2: (0.0000) | Acc: (90.00%) (40827/44928)
Epoch: 86 | Batch_idx: 360 |  Loss: (0.2612) |  Loss2: (0.0000) | Acc: (90.00%) (41998/46208)
Epoch: 86 | Batch_idx: 370 |  Loss: (0.2614) |  Loss2: (0.0000) | Acc: (90.00%) (43161/47488)
Epoch: 86 | Batch_idx: 380 |  Loss: (0.2618) |  Loss2: (0.0000) | Acc: (90.00%) (44319/48768)
Epoch: 86 | Batch_idx: 390 |  Loss: (0.2612) |  Loss2: (0.0000) | Acc: (90.00%) (45440/50000)
# TEST : Loss: (0.4421) | Acc: (85.00%) (8556/10000)
percent tensor([0.5151, 0.5177, 0.5163, 0.5172, 0.5167, 0.5166, 0.5184, 0.5194, 0.5162,
        0.5177, 0.5153, 0.5169, 0.5159, 0.5189, 0.5160, 0.5166],
       device='cuda:0') torch.Size([16])
percent tensor([0.5132, 0.5182, 0.5162, 0.5194, 0.5159, 0.5198, 0.5138, 0.5137, 0.5149,
        0.5171, 0.5161, 0.5180, 0.5185, 0.5142, 0.5188, 0.5172],
       device='cuda:0') torch.Size([16])
percent tensor([0.5499, 0.5107, 0.5923, 0.6151, 0.6037, 0.5911, 0.5548, 0.5923, 0.5765,
        0.5393, 0.5582, 0.5530, 0.4729, 0.6023, 0.5519, 0.5544],
       device='cuda:0') torch.Size([16])
percent tensor([0.6094, 0.6200, 0.5978, 0.5945, 0.6005, 0.5856, 0.6166, 0.6132, 0.6128,
        0.6112, 0.6156, 0.6131, 0.6199, 0.6073, 0.6158, 0.6039],
       device='cuda:0') torch.Size([16])
percent tensor([0.6033, 0.6008, 0.6456, 0.6611, 0.6631, 0.6880, 0.5870, 0.6137, 0.6298,
        0.6305, 0.6050, 0.6255, 0.6251, 0.6529, 0.5794, 0.6565],
       device='cuda:0') torch.Size([16])
percent tensor([0.6008, 0.6365, 0.6210, 0.6447, 0.6132, 0.7127, 0.6055, 0.5357, 0.6586,
        0.6305, 0.6717, 0.6322, 0.6849, 0.6765, 0.5770, 0.6322],
       device='cuda:0') torch.Size([16])
percent tensor([0.6130, 0.5952, 0.6517, 0.6583, 0.6791, 0.6764, 0.6217, 0.6449, 0.6044,
        0.5877, 0.6076, 0.5881, 0.5786, 0.6083, 0.5775, 0.6475],
       device='cuda:0') torch.Size([16])
percent tensor([0.9997, 0.9992, 0.9992, 0.9994, 0.9995, 0.9988, 0.9991, 0.9996, 0.9995,
        0.9992, 0.9997, 0.9993, 0.9996, 0.9995, 0.9986, 0.9992],
       device='cuda:0') torch.Size([16])
Epoch: 87 | Batch_idx: 0 |  Loss: (0.1544) |  Loss2: (0.0000) | Acc: (94.00%) (121/128)
Epoch: 87 | Batch_idx: 10 |  Loss: (0.2373) |  Loss2: (0.0000) | Acc: (92.00%) (1298/1408)
Epoch: 87 | Batch_idx: 20 |  Loss: (0.2398) |  Loss2: (0.0000) | Acc: (91.00%) (2467/2688)
Epoch: 87 | Batch_idx: 30 |  Loss: (0.2413) |  Loss2: (0.0000) | Acc: (91.00%) (3644/3968)
Epoch: 87 | Batch_idx: 40 |  Loss: (0.2432) |  Loss2: (0.0000) | Acc: (91.00%) (4808/5248)
Epoch: 87 | Batch_idx: 50 |  Loss: (0.2470) |  Loss2: (0.0000) | Acc: (91.00%) (5970/6528)
Epoch: 87 | Batch_idx: 60 |  Loss: (0.2460) |  Loss2: (0.0000) | Acc: (91.00%) (7150/7808)
Epoch: 87 | Batch_idx: 70 |  Loss: (0.2488) |  Loss2: (0.0000) | Acc: (91.00%) (8307/9088)
Epoch: 87 | Batch_idx: 80 |  Loss: (0.2470) |  Loss2: (0.0000) | Acc: (91.00%) (9479/10368)
Epoch: 87 | Batch_idx: 90 |  Loss: (0.2475) |  Loss2: (0.0000) | Acc: (91.00%) (10641/11648)
Epoch: 87 | Batch_idx: 100 |  Loss: (0.2514) |  Loss2: (0.0000) | Acc: (91.00%) (11794/12928)
Epoch: 87 | Batch_idx: 110 |  Loss: (0.2510) |  Loss2: (0.0000) | Acc: (91.00%) (12961/14208)
Epoch: 87 | Batch_idx: 120 |  Loss: (0.2503) |  Loss2: (0.0000) | Acc: (91.00%) (14141/15488)
Epoch: 87 | Batch_idx: 130 |  Loss: (0.2514) |  Loss2: (0.0000) | Acc: (91.00%) (15301/16768)
Epoch: 87 | Batch_idx: 140 |  Loss: (0.2521) |  Loss2: (0.0000) | Acc: (91.00%) (16462/18048)
Epoch: 87 | Batch_idx: 150 |  Loss: (0.2521) |  Loss2: (0.0000) | Acc: (91.00%) (17633/19328)
Epoch: 87 | Batch_idx: 160 |  Loss: (0.2511) |  Loss2: (0.0000) | Acc: (91.00%) (18808/20608)
Epoch: 87 | Batch_idx: 170 |  Loss: (0.2521) |  Loss2: (0.0000) | Acc: (91.00%) (19976/21888)
Epoch: 87 | Batch_idx: 180 |  Loss: (0.2528) |  Loss2: (0.0000) | Acc: (91.00%) (21148/23168)
Epoch: 87 | Batch_idx: 190 |  Loss: (0.2522) |  Loss2: (0.0000) | Acc: (91.00%) (22326/24448)
Epoch: 87 | Batch_idx: 200 |  Loss: (0.2534) |  Loss2: (0.0000) | Acc: (91.00%) (23476/25728)
Epoch: 87 | Batch_idx: 210 |  Loss: (0.2538) |  Loss2: (0.0000) | Acc: (91.00%) (24642/27008)
Epoch: 87 | Batch_idx: 220 |  Loss: (0.2531) |  Loss2: (0.0000) | Acc: (91.00%) (25825/28288)
Epoch: 87 | Batch_idx: 230 |  Loss: (0.2536) |  Loss2: (0.0000) | Acc: (91.00%) (26993/29568)
Epoch: 87 | Batch_idx: 240 |  Loss: (0.2538) |  Loss2: (0.0000) | Acc: (91.00%) (28153/30848)
Epoch: 87 | Batch_idx: 250 |  Loss: (0.2537) |  Loss2: (0.0000) | Acc: (91.00%) (29324/32128)
Epoch: 87 | Batch_idx: 260 |  Loss: (0.2547) |  Loss2: (0.0000) | Acc: (91.00%) (30482/33408)
Epoch: 87 | Batch_idx: 270 |  Loss: (0.2548) |  Loss2: (0.0000) | Acc: (91.00%) (31652/34688)
Epoch: 87 | Batch_idx: 280 |  Loss: (0.2551) |  Loss2: (0.0000) | Acc: (91.00%) (32818/35968)
Epoch: 87 | Batch_idx: 290 |  Loss: (0.2556) |  Loss2: (0.0000) | Acc: (91.00%) (33966/37248)
Epoch: 87 | Batch_idx: 300 |  Loss: (0.2543) |  Loss2: (0.0000) | Acc: (91.00%) (35156/38528)
Epoch: 87 | Batch_idx: 310 |  Loss: (0.2554) |  Loss2: (0.0000) | Acc: (91.00%) (36301/39808)
Epoch: 87 | Batch_idx: 320 |  Loss: (0.2556) |  Loss2: (0.0000) | Acc: (91.00%) (37474/41088)
Epoch: 87 | Batch_idx: 330 |  Loss: (0.2552) |  Loss2: (0.0000) | Acc: (91.00%) (38633/42368)
Epoch: 87 | Batch_idx: 340 |  Loss: (0.2549) |  Loss2: (0.0000) | Acc: (91.00%) (39797/43648)
Epoch: 87 | Batch_idx: 350 |  Loss: (0.2546) |  Loss2: (0.0000) | Acc: (91.00%) (40963/44928)
Epoch: 87 | Batch_idx: 360 |  Loss: (0.2545) |  Loss2: (0.0000) | Acc: (91.00%) (42130/46208)
Epoch: 87 | Batch_idx: 370 |  Loss: (0.2541) |  Loss2: (0.0000) | Acc: (91.00%) (43296/47488)
Epoch: 87 | Batch_idx: 380 |  Loss: (0.2547) |  Loss2: (0.0000) | Acc: (91.00%) (44451/48768)
Epoch: 87 | Batch_idx: 390 |  Loss: (0.2548) |  Loss2: (0.0000) | Acc: (91.00%) (45573/50000)
# TEST : Loss: (0.4421) | Acc: (85.00%) (8523/10000)
percent tensor([0.5148, 0.5168, 0.5160, 0.5166, 0.5161, 0.5162, 0.5176, 0.5187, 0.5153,
        0.5171, 0.5148, 0.5164, 0.5153, 0.5174, 0.5157, 0.5159],
       device='cuda:0') torch.Size([16])
percent tensor([0.5127, 0.5182, 0.5173, 0.5195, 0.5161, 0.5189, 0.5135, 0.5138, 0.5143,
        0.5166, 0.5145, 0.5184, 0.5182, 0.5132, 0.5179, 0.5169],
       device='cuda:0') torch.Size([16])
percent tensor([0.5601, 0.5110, 0.5973, 0.6180, 0.6085, 0.5900, 0.5568, 0.5952, 0.5826,
        0.5438, 0.5589, 0.5616, 0.4854, 0.6047, 0.5473, 0.5605],
       device='cuda:0') torch.Size([16])
percent tensor([0.6074, 0.6158, 0.5933, 0.5917, 0.5964, 0.5834, 0.6129, 0.6094, 0.6076,
        0.6096, 0.6137, 0.6086, 0.6173, 0.6018, 0.6154, 0.6017],
       device='cuda:0') torch.Size([16])
percent tensor([0.5906, 0.5844, 0.6424, 0.6577, 0.6636, 0.6766, 0.5769, 0.6051, 0.6168,
        0.6247, 0.5894, 0.6206, 0.6085, 0.6324, 0.5663, 0.6495],
       device='cuda:0') torch.Size([16])
percent tensor([0.5880, 0.6245, 0.6189, 0.6470, 0.6234, 0.6968, 0.6025, 0.5258, 0.6584,
        0.6143, 0.6743, 0.6337, 0.6647, 0.6737, 0.5592, 0.6211],
       device='cuda:0') torch.Size([16])
percent tensor([0.6205, 0.5849, 0.6497, 0.6656, 0.6877, 0.6717, 0.6274, 0.6496, 0.6007,
        0.5897, 0.6033, 0.6116, 0.5857, 0.5997, 0.5824, 0.6461],
       device='cuda:0') torch.Size([16])
percent tensor([0.9997, 0.9988, 0.9993, 0.9994, 0.9995, 0.9979, 0.9992, 0.9998, 0.9993,
        0.9989, 0.9997, 0.9995, 0.9994, 0.9993, 0.9986, 0.9995],
       device='cuda:0') torch.Size([16])
Epoch: 88 | Batch_idx: 0 |  Loss: (0.2985) |  Loss2: (0.0000) | Acc: (89.00%) (114/128)
Epoch: 88 | Batch_idx: 10 |  Loss: (0.2358) |  Loss2: (0.0000) | Acc: (91.00%) (1294/1408)
Epoch: 88 | Batch_idx: 20 |  Loss: (0.2334) |  Loss2: (0.0000) | Acc: (91.00%) (2465/2688)
Epoch: 88 | Batch_idx: 30 |  Loss: (0.2358) |  Loss2: (0.0000) | Acc: (91.00%) (3641/3968)
Epoch: 88 | Batch_idx: 40 |  Loss: (0.2468) |  Loss2: (0.0000) | Acc: (91.00%) (4797/5248)
Epoch: 88 | Batch_idx: 50 |  Loss: (0.2482) |  Loss2: (0.0000) | Acc: (91.00%) (5962/6528)
Epoch: 88 | Batch_idx: 60 |  Loss: (0.2447) |  Loss2: (0.0000) | Acc: (91.00%) (7151/7808)
Epoch: 88 | Batch_idx: 70 |  Loss: (0.2409) |  Loss2: (0.0000) | Acc: (91.00%) (8338/9088)
Epoch: 88 | Batch_idx: 80 |  Loss: (0.2410) |  Loss2: (0.0000) | Acc: (91.00%) (9516/10368)
Epoch: 88 | Batch_idx: 90 |  Loss: (0.2433) |  Loss2: (0.0000) | Acc: (91.00%) (10689/11648)
Epoch: 88 | Batch_idx: 100 |  Loss: (0.2425) |  Loss2: (0.0000) | Acc: (91.00%) (11857/12928)
Epoch: 88 | Batch_idx: 110 |  Loss: (0.2429) |  Loss2: (0.0000) | Acc: (91.00%) (13020/14208)
Epoch: 88 | Batch_idx: 120 |  Loss: (0.2436) |  Loss2: (0.0000) | Acc: (91.00%) (14194/15488)
Epoch: 88 | Batch_idx: 130 |  Loss: (0.2435) |  Loss2: (0.0000) | Acc: (91.00%) (15360/16768)
Epoch: 88 | Batch_idx: 140 |  Loss: (0.2426) |  Loss2: (0.0000) | Acc: (91.00%) (16537/18048)
Epoch: 88 | Batch_idx: 150 |  Loss: (0.2420) |  Loss2: (0.0000) | Acc: (91.00%) (17718/19328)
Epoch: 88 | Batch_idx: 160 |  Loss: (0.2436) |  Loss2: (0.0000) | Acc: (91.00%) (18878/20608)
Epoch: 88 | Batch_idx: 170 |  Loss: (0.2442) |  Loss2: (0.0000) | Acc: (91.00%) (20034/21888)
Epoch: 88 | Batch_idx: 180 |  Loss: (0.2448) |  Loss2: (0.0000) | Acc: (91.00%) (21200/23168)
Epoch: 88 | Batch_idx: 190 |  Loss: (0.2469) |  Loss2: (0.0000) | Acc: (91.00%) (22369/24448)
Epoch: 88 | Batch_idx: 200 |  Loss: (0.2463) |  Loss2: (0.0000) | Acc: (91.00%) (23552/25728)
Epoch: 88 | Batch_idx: 210 |  Loss: (0.2457) |  Loss2: (0.0000) | Acc: (91.00%) (24721/27008)
Epoch: 88 | Batch_idx: 220 |  Loss: (0.2464) |  Loss2: (0.0000) | Acc: (91.00%) (25895/28288)
Epoch: 88 | Batch_idx: 230 |  Loss: (0.2449) |  Loss2: (0.0000) | Acc: (91.00%) (27079/29568)
Epoch: 88 | Batch_idx: 240 |  Loss: (0.2465) |  Loss2: (0.0000) | Acc: (91.00%) (28234/30848)
Epoch: 88 | Batch_idx: 250 |  Loss: (0.2471) |  Loss2: (0.0000) | Acc: (91.00%) (29398/32128)
Epoch: 88 | Batch_idx: 260 |  Loss: (0.2470) |  Loss2: (0.0000) | Acc: (91.00%) (30575/33408)
Epoch: 88 | Batch_idx: 270 |  Loss: (0.2460) |  Loss2: (0.0000) | Acc: (91.00%) (31757/34688)
Epoch: 88 | Batch_idx: 280 |  Loss: (0.2461) |  Loss2: (0.0000) | Acc: (91.00%) (32929/35968)
Epoch: 88 | Batch_idx: 290 |  Loss: (0.2455) |  Loss2: (0.0000) | Acc: (91.00%) (34112/37248)
Epoch: 88 | Batch_idx: 300 |  Loss: (0.2462) |  Loss2: (0.0000) | Acc: (91.00%) (35266/38528)
Epoch: 88 | Batch_idx: 310 |  Loss: (0.2470) |  Loss2: (0.0000) | Acc: (91.00%) (36432/39808)
Epoch: 88 | Batch_idx: 320 |  Loss: (0.2483) |  Loss2: (0.0000) | Acc: (91.00%) (37586/41088)
Epoch: 88 | Batch_idx: 330 |  Loss: (0.2483) |  Loss2: (0.0000) | Acc: (91.00%) (38757/42368)
Epoch: 88 | Batch_idx: 340 |  Loss: (0.2488) |  Loss2: (0.0000) | Acc: (91.00%) (39919/43648)
Epoch: 88 | Batch_idx: 350 |  Loss: (0.2490) |  Loss2: (0.0000) | Acc: (91.00%) (41084/44928)
Epoch: 88 | Batch_idx: 360 |  Loss: (0.2492) |  Loss2: (0.0000) | Acc: (91.00%) (42247/46208)
Epoch: 88 | Batch_idx: 370 |  Loss: (0.2486) |  Loss2: (0.0000) | Acc: (91.00%) (43428/47488)
Epoch: 88 | Batch_idx: 380 |  Loss: (0.2482) |  Loss2: (0.0000) | Acc: (91.00%) (44605/48768)
Epoch: 88 | Batch_idx: 390 |  Loss: (0.2487) |  Loss2: (0.0000) | Acc: (91.00%) (45730/50000)
# TEST : Loss: (0.4268) | Acc: (86.00%) (8614/10000)
percent tensor([0.5149, 0.5167, 0.5170, 0.5163, 0.5174, 0.5164, 0.5178, 0.5189, 0.5158,
        0.5173, 0.5148, 0.5174, 0.5154, 0.5165, 0.5158, 0.5156],
       device='cuda:0') torch.Size([16])
percent tensor([0.5122, 0.5185, 0.5179, 0.5200, 0.5164, 0.5190, 0.5139, 0.5140, 0.5145,
        0.5166, 0.5144, 0.5191, 0.5179, 0.5131, 0.5183, 0.5175],
       device='cuda:0') torch.Size([16])
percent tensor([0.5515, 0.4975, 0.5924, 0.6110, 0.6035, 0.5852, 0.5464, 0.5880, 0.5837,
        0.5308, 0.5629, 0.5514, 0.4757, 0.5973, 0.5379, 0.5495],
       device='cuda:0') torch.Size([16])
percent tensor([0.6061, 0.6169, 0.5995, 0.5948, 0.6010, 0.5832, 0.6141, 0.6108, 0.6067,
        0.6109, 0.6105, 0.6147, 0.6164, 0.6026, 0.6165, 0.6014],
       device='cuda:0') torch.Size([16])
percent tensor([0.6029, 0.5988, 0.6321, 0.6588, 0.6523, 0.6883, 0.5823, 0.5988, 0.6218,
        0.6244, 0.6020, 0.6187, 0.6185, 0.6457, 0.5789, 0.6542],
       device='cuda:0') torch.Size([16])
percent tensor([0.5874, 0.6363, 0.6211, 0.6435, 0.6224, 0.6988, 0.6149, 0.5339, 0.6550,
        0.6241, 0.6795, 0.6355, 0.6720, 0.6704, 0.5751, 0.6238],
       device='cuda:0') torch.Size([16])
percent tensor([0.6172, 0.5972, 0.6394, 0.6600, 0.6862, 0.6689, 0.6410, 0.6421, 0.6214,
        0.6089, 0.6224, 0.5999, 0.5947, 0.6124, 0.5771, 0.6474],
       device='cuda:0') torch.Size([16])
percent tensor([0.9997, 0.9988, 0.9991, 0.9996, 0.9995, 0.9986, 0.9991, 0.9997, 0.9994,
        0.9992, 0.9996, 0.9993, 0.9996, 0.9994, 0.9980, 0.9993],
       device='cuda:0') torch.Size([16])
Epoch: 89 | Batch_idx: 0 |  Loss: (0.2094) |  Loss2: (0.0000) | Acc: (93.00%) (120/128)
Epoch: 89 | Batch_idx: 10 |  Loss: (0.2472) |  Loss2: (0.0000) | Acc: (92.00%) (1299/1408)
Epoch: 89 | Batch_idx: 20 |  Loss: (0.2604) |  Loss2: (0.0000) | Acc: (91.00%) (2455/2688)
Epoch: 89 | Batch_idx: 30 |  Loss: (0.2532) |  Loss2: (0.0000) | Acc: (91.00%) (3630/3968)
Epoch: 89 | Batch_idx: 40 |  Loss: (0.2442) |  Loss2: (0.0000) | Acc: (91.00%) (4808/5248)
Epoch: 89 | Batch_idx: 50 |  Loss: (0.2420) |  Loss2: (0.0000) | Acc: (91.00%) (5983/6528)
Epoch: 89 | Batch_idx: 60 |  Loss: (0.2327) |  Loss2: (0.0000) | Acc: (91.00%) (7175/7808)
Epoch: 89 | Batch_idx: 70 |  Loss: (0.2355) |  Loss2: (0.0000) | Acc: (91.00%) (8344/9088)
Epoch: 89 | Batch_idx: 80 |  Loss: (0.2370) |  Loss2: (0.0000) | Acc: (91.00%) (9514/10368)
Epoch: 89 | Batch_idx: 90 |  Loss: (0.2381) |  Loss2: (0.0000) | Acc: (91.00%) (10681/11648)
Epoch: 89 | Batch_idx: 100 |  Loss: (0.2405) |  Loss2: (0.0000) | Acc: (91.00%) (11837/12928)
Epoch: 89 | Batch_idx: 110 |  Loss: (0.2420) |  Loss2: (0.0000) | Acc: (91.00%) (13006/14208)
Epoch: 89 | Batch_idx: 120 |  Loss: (0.2413) |  Loss2: (0.0000) | Acc: (91.00%) (14201/15488)
Epoch: 89 | Batch_idx: 130 |  Loss: (0.2427) |  Loss2: (0.0000) | Acc: (91.00%) (15369/16768)
Epoch: 89 | Batch_idx: 140 |  Loss: (0.2405) |  Loss2: (0.0000) | Acc: (91.00%) (16550/18048)
Epoch: 89 | Batch_idx: 150 |  Loss: (0.2408) |  Loss2: (0.0000) | Acc: (91.00%) (17721/19328)
Epoch: 89 | Batch_idx: 160 |  Loss: (0.2398) |  Loss2: (0.0000) | Acc: (91.00%) (18896/20608)
Epoch: 89 | Batch_idx: 170 |  Loss: (0.2402) |  Loss2: (0.0000) | Acc: (91.00%) (20060/21888)
Epoch: 89 | Batch_idx: 180 |  Loss: (0.2416) |  Loss2: (0.0000) | Acc: (91.00%) (21223/23168)
Epoch: 89 | Batch_idx: 190 |  Loss: (0.2426) |  Loss2: (0.0000) | Acc: (91.00%) (22391/24448)
Epoch: 89 | Batch_idx: 200 |  Loss: (0.2416) |  Loss2: (0.0000) | Acc: (91.00%) (23575/25728)
Epoch: 89 | Batch_idx: 210 |  Loss: (0.2435) |  Loss2: (0.0000) | Acc: (91.00%) (24729/27008)
Epoch: 89 | Batch_idx: 220 |  Loss: (0.2447) |  Loss2: (0.0000) | Acc: (91.00%) (25893/28288)
Epoch: 89 | Batch_idx: 230 |  Loss: (0.2450) |  Loss2: (0.0000) | Acc: (91.00%) (27055/29568)
Epoch: 89 | Batch_idx: 240 |  Loss: (0.2452) |  Loss2: (0.0000) | Acc: (91.00%) (28214/30848)
Epoch: 89 | Batch_idx: 250 |  Loss: (0.2448) |  Loss2: (0.0000) | Acc: (91.00%) (29397/32128)
Epoch: 89 | Batch_idx: 260 |  Loss: (0.2451) |  Loss2: (0.0000) | Acc: (91.00%) (30563/33408)
Epoch: 89 | Batch_idx: 270 |  Loss: (0.2452) |  Loss2: (0.0000) | Acc: (91.00%) (31728/34688)
Epoch: 89 | Batch_idx: 280 |  Loss: (0.2457) |  Loss2: (0.0000) | Acc: (91.00%) (32899/35968)
Epoch: 89 | Batch_idx: 290 |  Loss: (0.2458) |  Loss2: (0.0000) | Acc: (91.00%) (34069/37248)
Epoch: 89 | Batch_idx: 300 |  Loss: (0.2457) |  Loss2: (0.0000) | Acc: (91.00%) (35234/38528)
Epoch: 89 | Batch_idx: 310 |  Loss: (0.2462) |  Loss2: (0.0000) | Acc: (91.00%) (36398/39808)
Epoch: 89 | Batch_idx: 320 |  Loss: (0.2459) |  Loss2: (0.0000) | Acc: (91.00%) (37574/41088)
Epoch: 89 | Batch_idx: 330 |  Loss: (0.2454) |  Loss2: (0.0000) | Acc: (91.00%) (38755/42368)
Epoch: 89 | Batch_idx: 340 |  Loss: (0.2459) |  Loss2: (0.0000) | Acc: (91.00%) (39910/43648)
Epoch: 89 | Batch_idx: 350 |  Loss: (0.2456) |  Loss2: (0.0000) | Acc: (91.00%) (41087/44928)
Epoch: 89 | Batch_idx: 360 |  Loss: (0.2453) |  Loss2: (0.0000) | Acc: (91.00%) (42269/46208)
Epoch: 89 | Batch_idx: 370 |  Loss: (0.2447) |  Loss2: (0.0000) | Acc: (91.00%) (43447/47488)
Epoch: 89 | Batch_idx: 380 |  Loss: (0.2445) |  Loss2: (0.0000) | Acc: (91.00%) (44622/48768)
Epoch: 89 | Batch_idx: 390 |  Loss: (0.2442) |  Loss2: (0.0000) | Acc: (91.00%) (45760/50000)
# TEST : Loss: (0.4178) | Acc: (86.00%) (8613/10000)
percent tensor([0.5150, 0.5166, 0.5171, 0.5168, 0.5176, 0.5168, 0.5177, 0.5188, 0.5157,
        0.5172, 0.5147, 0.5174, 0.5154, 0.5166, 0.5159, 0.5158],
       device='cuda:0') torch.Size([16])
percent tensor([0.5120, 0.5179, 0.5161, 0.5190, 0.5150, 0.5178, 0.5130, 0.5138, 0.5140,
        0.5162, 0.5140, 0.5171, 0.5177, 0.5134, 0.5175, 0.5172],
       device='cuda:0') torch.Size([16])
percent tensor([0.5570, 0.5104, 0.6043, 0.6199, 0.6145, 0.5836, 0.5635, 0.5981, 0.5843,
        0.5462, 0.5595, 0.5744, 0.4809, 0.5946, 0.5502, 0.5555],
       device='cuda:0') torch.Size([16])
percent tensor([0.6057, 0.6160, 0.5945, 0.5913, 0.5975, 0.5822, 0.6142, 0.6074, 0.6115,
        0.6104, 0.6137, 0.6091, 0.6177, 0.6044, 0.6137, 0.6014],
       device='cuda:0') torch.Size([16])
percent tensor([0.5929, 0.5930, 0.6352, 0.6586, 0.6605, 0.6802, 0.5793, 0.5958, 0.6141,
        0.6183, 0.5884, 0.6198, 0.6121, 0.6312, 0.5658, 0.6479],
       device='cuda:0') torch.Size([16])
percent tensor([0.5913, 0.6239, 0.6213, 0.6533, 0.6270, 0.6960, 0.6135, 0.5388, 0.6483,
        0.6172, 0.6686, 0.6432, 0.6661, 0.6678, 0.5705, 0.6253],
       device='cuda:0') torch.Size([16])
percent tensor([0.6165, 0.5947, 0.6299, 0.6473, 0.6762, 0.6725, 0.6249, 0.6399, 0.5994,
        0.5993, 0.6149, 0.5958, 0.5885, 0.6043, 0.5731, 0.6448],
       device='cuda:0') torch.Size([16])
percent tensor([0.9998, 0.9988, 0.9990, 0.9993, 0.9990, 0.9985, 0.9993, 0.9995, 0.9995,
        0.9994, 0.9998, 0.9993, 0.9996, 0.9994, 0.9977, 0.9995],
       device='cuda:0') torch.Size([16])
False Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=128, out_features=16, bias=False)
True Linear(in_features=16, out_features=2, bias=False)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=128, out_features=16, bias=False)
True Linear(in_features=16, out_features=2, bias=False)
False Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=256, out_features=32, bias=False)
True Linear(in_features=32, out_features=2, bias=False)
False Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=256, out_features=32, bias=False)
True Linear(in_features=32, out_features=2, bias=False)
False Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=512, out_features=64, bias=False)
True Linear(in_features=64, out_features=2, bias=False)
False Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=512, out_features=64, bias=False)
True Linear(in_features=64, out_features=2, bias=False)
False Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1024, out_features=128, bias=False)
True Linear(in_features=128, out_features=2, bias=False)
False Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1024, out_features=128, bias=False)
True Linear(in_features=128, out_features=2, bias=False)
False Linear(in_features=512, out_features=10, bias=True)
Epoch: 90 | Batch_idx: 0 |  Loss: (0.2156) |  Loss2: (0.0000) | Acc: (93.00%) (120/128)
Epoch: 90 | Batch_idx: 10 |  Loss: (0.2265) |  Loss2: (0.0000) | Acc: (92.00%) (1308/1408)
Epoch: 90 | Batch_idx: 20 |  Loss: (0.2600) |  Loss2: (0.0000) | Acc: (91.00%) (2456/2688)
Epoch: 90 | Batch_idx: 30 |  Loss: (0.2748) |  Loss2: (0.0000) | Acc: (90.00%) (3606/3968)
Epoch: 90 | Batch_idx: 40 |  Loss: (0.2737) |  Loss2: (0.0000) | Acc: (90.00%) (4759/5248)
Epoch: 90 | Batch_idx: 50 |  Loss: (0.2804) |  Loss2: (0.0000) | Acc: (90.00%) (5893/6528)
Epoch: 90 | Batch_idx: 60 |  Loss: (0.2812) |  Loss2: (0.0000) | Acc: (90.00%) (7051/7808)
Epoch: 90 | Batch_idx: 70 |  Loss: (0.2792) |  Loss2: (0.0000) | Acc: (90.00%) (8219/9088)
Epoch: 90 | Batch_idx: 80 |  Loss: (0.2846) |  Loss2: (0.0000) | Acc: (90.00%) (9353/10368)
Epoch: 90 | Batch_idx: 90 |  Loss: (0.2907) |  Loss2: (0.0000) | Acc: (89.00%) (10474/11648)
Epoch: 90 | Batch_idx: 100 |  Loss: (0.2906) |  Loss2: (0.0000) | Acc: (89.00%) (11633/12928)
Epoch: 90 | Batch_idx: 110 |  Loss: (0.2942) |  Loss2: (0.0000) | Acc: (89.00%) (12768/14208)
Epoch: 90 | Batch_idx: 120 |  Loss: (0.2911) |  Loss2: (0.0000) | Acc: (89.00%) (13931/15488)
Epoch: 90 | Batch_idx: 130 |  Loss: (0.2913) |  Loss2: (0.0000) | Acc: (90.00%) (15092/16768)
Epoch: 90 | Batch_idx: 140 |  Loss: (0.2908) |  Loss2: (0.0000) | Acc: (90.00%) (16251/18048)
Epoch: 90 | Batch_idx: 150 |  Loss: (0.2898) |  Loss2: (0.0000) | Acc: (90.00%) (17410/19328)
Epoch: 90 | Batch_idx: 160 |  Loss: (0.2900) |  Loss2: (0.0000) | Acc: (90.00%) (18560/20608)
Epoch: 90 | Batch_idx: 170 |  Loss: (0.2900) |  Loss2: (0.0000) | Acc: (90.00%) (19710/21888)
Epoch: 90 | Batch_idx: 180 |  Loss: (0.2879) |  Loss2: (0.0000) | Acc: (90.00%) (20882/23168)
Epoch: 90 | Batch_idx: 190 |  Loss: (0.2873) |  Loss2: (0.0000) | Acc: (90.00%) (22040/24448)
Epoch: 90 | Batch_idx: 200 |  Loss: (0.2866) |  Loss2: (0.0000) | Acc: (90.00%) (23194/25728)
Epoch: 90 | Batch_idx: 210 |  Loss: (0.2870) |  Loss2: (0.0000) | Acc: (90.00%) (24342/27008)
Epoch: 90 | Batch_idx: 220 |  Loss: (0.2865) |  Loss2: (0.0000) | Acc: (90.00%) (25499/28288)
Epoch: 90 | Batch_idx: 230 |  Loss: (0.2865) |  Loss2: (0.0000) | Acc: (90.00%) (26647/29568)
Epoch: 90 | Batch_idx: 240 |  Loss: (0.2849) |  Loss2: (0.0000) | Acc: (90.00%) (27813/30848)
Epoch: 90 | Batch_idx: 250 |  Loss: (0.2835) |  Loss2: (0.0000) | Acc: (90.00%) (28984/32128)
Epoch: 90 | Batch_idx: 260 |  Loss: (0.2833) |  Loss2: (0.0000) | Acc: (90.00%) (30139/33408)
Epoch: 90 | Batch_idx: 270 |  Loss: (0.2829) |  Loss2: (0.0000) | Acc: (90.00%) (31306/34688)
Epoch: 90 | Batch_idx: 280 |  Loss: (0.2825) |  Loss2: (0.0000) | Acc: (90.00%) (32467/35968)
Epoch: 90 | Batch_idx: 290 |  Loss: (0.2822) |  Loss2: (0.0000) | Acc: (90.00%) (33609/37248)
Epoch: 90 | Batch_idx: 300 |  Loss: (0.2820) |  Loss2: (0.0000) | Acc: (90.00%) (34761/38528)
Epoch: 90 | Batch_idx: 310 |  Loss: (0.2815) |  Loss2: (0.0000) | Acc: (90.00%) (35923/39808)
Epoch: 90 | Batch_idx: 320 |  Loss: (0.2814) |  Loss2: (0.0000) | Acc: (90.00%) (37093/41088)
Epoch: 90 | Batch_idx: 330 |  Loss: (0.2811) |  Loss2: (0.0000) | Acc: (90.00%) (38241/42368)
Epoch: 90 | Batch_idx: 340 |  Loss: (0.2809) |  Loss2: (0.0000) | Acc: (90.00%) (39389/43648)
Epoch: 90 | Batch_idx: 350 |  Loss: (0.2796) |  Loss2: (0.0000) | Acc: (90.00%) (40565/44928)
Epoch: 90 | Batch_idx: 360 |  Loss: (0.2797) |  Loss2: (0.0000) | Acc: (90.00%) (41712/46208)
Epoch: 90 | Batch_idx: 370 |  Loss: (0.2790) |  Loss2: (0.0000) | Acc: (90.00%) (42875/47488)
Epoch: 90 | Batch_idx: 380 |  Loss: (0.2792) |  Loss2: (0.0000) | Acc: (90.00%) (44022/48768)
Epoch: 90 | Batch_idx: 390 |  Loss: (0.2796) |  Loss2: (0.0000) | Acc: (90.00%) (45125/50000)
=> saving checkpoint 'drive/app/torch/save_Schedule/checkpoint_090.pth.tar'
# TEST : Loss: (0.4144) | Acc: (86.00%) (8631/10000)
percent tensor([0.5171, 0.5184, 0.5186, 0.5189, 0.5194, 0.5204, 0.5194, 0.5203, 0.5173,
        0.5187, 0.5166, 0.5187, 0.5172, 0.5183, 0.5185, 0.5180],
       device='cuda:0') torch.Size([16])
percent tensor([0.5100, 0.5123, 0.5120, 0.5144, 0.5102, 0.5163, 0.5080, 0.5093, 0.5097,
        0.5113, 0.5100, 0.5130, 0.5142, 0.5078, 0.5139, 0.5141],
       device='cuda:0') torch.Size([16])
percent tensor([0.5807, 0.5275, 0.6180, 0.6383, 0.6271, 0.6099, 0.5799, 0.6114, 0.6027,
        0.5658, 0.5838, 0.5898, 0.5030, 0.6189, 0.5678, 0.5795],
       device='cuda:0') torch.Size([16])
percent tensor([0.6001, 0.6074, 0.5933, 0.5899, 0.5958, 0.5777, 0.6076, 0.6035, 0.6060,
        0.6048, 0.6077, 0.6061, 0.6083, 0.5986, 0.6074, 0.5947],
       device='cuda:0') torch.Size([16])
percent tensor([0.5906, 0.5833, 0.6265, 0.6452, 0.6505, 0.6653, 0.5793, 0.5944, 0.6111,
        0.6117, 0.5809, 0.6035, 0.5969, 0.6190, 0.5614, 0.6390],
       device='cuda:0') torch.Size([16])
percent tensor([0.5808, 0.6133, 0.6112, 0.6403, 0.6139, 0.6906, 0.5990, 0.5193, 0.6375,
        0.6061, 0.6568, 0.6263, 0.6532, 0.6589, 0.5569, 0.6131],
       device='cuda:0') torch.Size([16])
percent tensor([0.6131, 0.5934, 0.6212, 0.6379, 0.6623, 0.6669, 0.6198, 0.6271, 0.5978,
        0.5957, 0.6037, 0.5788, 0.5911, 0.5951, 0.5664, 0.6394],
       device='cuda:0') torch.Size([16])
percent tensor([0.9998, 0.9989, 0.9990, 0.9995, 0.9990, 0.9977, 0.9991, 0.9995, 0.9994,
        0.9995, 0.9997, 0.9993, 0.9996, 0.9995, 0.9977, 0.9994],
       device='cuda:0') torch.Size([16])
Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 3, 3, 3]) tensor(176.6487, device='cuda:0')
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(817.4567, device='cuda:0')
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(809.4928, device='cuda:0')
Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([128, 64, 3, 3]) tensor(1522.3231, device='cuda:0')
Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([128, 64, 1, 1]) tensor(496.8130, device='cuda:0')
Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([128, 128, 3, 3]) tensor(2237.5151, device='cuda:0')
Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([256, 128, 3, 3]) tensor(4284.5815, device='cuda:0')
Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([256, 128, 1, 1]) tensor(1400.1307, device='cuda:0')
Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([256, 256, 3, 3]) tensor(6155.6436, device='cuda:0')
Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([512, 256, 3, 3]) tensor(11897.1660, device='cuda:0')
Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([512, 256, 1, 1]) tensor(3948.8044, device='cuda:0')
Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([512, 512, 3, 3]) tensor(16713.9922, device='cuda:0')
Epoch: 91 | Batch_idx: 0 |  Loss: (0.2413) |  Loss2: (0.0000) | Acc: (91.00%) (117/128)
Epoch: 91 | Batch_idx: 10 |  Loss: (0.2561) |  Loss2: (0.0000) | Acc: (91.00%) (1285/1408)
Epoch: 91 | Batch_idx: 20 |  Loss: (0.2501) |  Loss2: (0.0000) | Acc: (91.00%) (2457/2688)
Epoch: 91 | Batch_idx: 30 |  Loss: (0.2521) |  Loss2: (0.0000) | Acc: (91.00%) (3611/3968)
Epoch: 91 | Batch_idx: 40 |  Loss: (0.2517) |  Loss2: (0.0000) | Acc: (91.00%) (4784/5248)
Epoch: 91 | Batch_idx: 50 |  Loss: (0.2538) |  Loss2: (0.0000) | Acc: (90.00%) (5938/6528)
Epoch: 91 | Batch_idx: 60 |  Loss: (0.2611) |  Loss2: (0.0000) | Acc: (90.00%) (7083/7808)
Epoch: 91 | Batch_idx: 70 |  Loss: (0.2657) |  Loss2: (0.0000) | Acc: (90.00%) (8228/9088)
Epoch: 91 | Batch_idx: 80 |  Loss: (0.2628) |  Loss2: (0.0000) | Acc: (90.00%) (9409/10368)
Epoch: 91 | Batch_idx: 90 |  Loss: (0.2611) |  Loss2: (0.0000) | Acc: (90.00%) (10587/11648)
Epoch: 91 | Batch_idx: 100 |  Loss: (0.2612) |  Loss2: (0.0000) | Acc: (90.00%) (11753/12928)
Epoch: 91 | Batch_idx: 110 |  Loss: (0.2636) |  Loss2: (0.0000) | Acc: (90.00%) (12902/14208)
Epoch: 91 | Batch_idx: 120 |  Loss: (0.2628) |  Loss2: (0.0000) | Acc: (90.00%) (14085/15488)
Epoch: 91 | Batch_idx: 130 |  Loss: (0.2630) |  Loss2: (0.0000) | Acc: (90.00%) (15256/16768)
Epoch: 91 | Batch_idx: 140 |  Loss: (0.2613) |  Loss2: (0.0000) | Acc: (91.00%) (16432/18048)
Epoch: 91 | Batch_idx: 150 |  Loss: (0.2621) |  Loss2: (0.0000) | Acc: (90.00%) (17585/19328)
Epoch: 91 | Batch_idx: 160 |  Loss: (0.2606) |  Loss2: (0.0000) | Acc: (91.00%) (18766/20608)
Epoch: 91 | Batch_idx: 170 |  Loss: (0.2603) |  Loss2: (0.0000) | Acc: (91.00%) (19937/21888)
Epoch: 91 | Batch_idx: 180 |  Loss: (0.2598) |  Loss2: (0.0000) | Acc: (91.00%) (21117/23168)
Epoch: 91 | Batch_idx: 190 |  Loss: (0.2594) |  Loss2: (0.0000) | Acc: (91.00%) (22287/24448)
Epoch: 91 | Batch_idx: 200 |  Loss: (0.2592) |  Loss2: (0.0000) | Acc: (91.00%) (23456/25728)
Epoch: 91 | Batch_idx: 210 |  Loss: (0.2595) |  Loss2: (0.0000) | Acc: (91.00%) (24616/27008)
Epoch: 91 | Batch_idx: 220 |  Loss: (0.2593) |  Loss2: (0.0000) | Acc: (91.00%) (25790/28288)
Epoch: 91 | Batch_idx: 230 |  Loss: (0.2570) |  Loss2: (0.0000) | Acc: (91.00%) (26986/29568)
Epoch: 91 | Batch_idx: 240 |  Loss: (0.2562) |  Loss2: (0.0000) | Acc: (91.00%) (28159/30848)
Epoch: 91 | Batch_idx: 250 |  Loss: (0.2555) |  Loss2: (0.0000) | Acc: (91.00%) (29328/32128)
Epoch: 91 | Batch_idx: 260 |  Loss: (0.2558) |  Loss2: (0.0000) | Acc: (91.00%) (30492/33408)
Epoch: 91 | Batch_idx: 270 |  Loss: (0.2558) |  Loss2: (0.0000) | Acc: (91.00%) (31649/34688)
Epoch: 91 | Batch_idx: 280 |  Loss: (0.2543) |  Loss2: (0.0000) | Acc: (91.00%) (32842/35968)
Epoch: 91 | Batch_idx: 290 |  Loss: (0.2539) |  Loss2: (0.0000) | Acc: (91.00%) (34017/37248)
Epoch: 91 | Batch_idx: 300 |  Loss: (0.2538) |  Loss2: (0.0000) | Acc: (91.00%) (35190/38528)
Epoch: 91 | Batch_idx: 310 |  Loss: (0.2533) |  Loss2: (0.0000) | Acc: (91.00%) (36358/39808)
Epoch: 91 | Batch_idx: 320 |  Loss: (0.2533) |  Loss2: (0.0000) | Acc: (91.00%) (37535/41088)
Epoch: 91 | Batch_idx: 330 |  Loss: (0.2531) |  Loss2: (0.0000) | Acc: (91.00%) (38705/42368)
Epoch: 91 | Batch_idx: 340 |  Loss: (0.2525) |  Loss2: (0.0000) | Acc: (91.00%) (39890/43648)
Epoch: 91 | Batch_idx: 350 |  Loss: (0.2529) |  Loss2: (0.0000) | Acc: (91.00%) (41054/44928)
Epoch: 91 | Batch_idx: 360 |  Loss: (0.2525) |  Loss2: (0.0000) | Acc: (91.00%) (42228/46208)
Epoch: 91 | Batch_idx: 370 |  Loss: (0.2519) |  Loss2: (0.0000) | Acc: (91.00%) (43406/47488)
Epoch: 91 | Batch_idx: 380 |  Loss: (0.2517) |  Loss2: (0.0000) | Acc: (91.00%) (44586/48768)
Epoch: 91 | Batch_idx: 390 |  Loss: (0.2522) |  Loss2: (0.0000) | Acc: (91.00%) (45702/50000)
# TEST : Loss: (0.3970) | Acc: (86.00%) (8692/10000)
percent tensor([0.5164, 0.5172, 0.5175, 0.5183, 0.5185, 0.5212, 0.5182, 0.5190, 0.5164,
        0.5172, 0.5161, 0.5174, 0.5163, 0.5173, 0.5182, 0.5175],
       device='cuda:0') torch.Size([16])
percent tensor([0.5095, 0.5104, 0.5104, 0.5130, 0.5085, 0.5159, 0.5062, 0.5076, 0.5085,
        0.5095, 0.5089, 0.5115, 0.5131, 0.5065, 0.5127, 0.5132],
       device='cuda:0') torch.Size([16])
percent tensor([0.5800, 0.5264, 0.6205, 0.6411, 0.6293, 0.6106, 0.5776, 0.6128, 0.6036,
        0.5649, 0.5858, 0.5887, 0.5019, 0.6226, 0.5647, 0.5801],
       device='cuda:0') torch.Size([16])
percent tensor([0.6069, 0.6126, 0.6018, 0.5991, 0.6051, 0.5852, 0.6147, 0.6122, 0.6137,
        0.6118, 0.6151, 0.6144, 0.6131, 0.6063, 0.6147, 0.6013],
       device='cuda:0') torch.Size([16])
percent tensor([0.5855, 0.5781, 0.6195, 0.6349, 0.6447, 0.6563, 0.5776, 0.5907, 0.6043,
        0.6059, 0.5752, 0.5961, 0.5895, 0.6121, 0.5602, 0.6316],
       device='cuda:0') torch.Size([16])
percent tensor([0.5935, 0.6269, 0.6202, 0.6486, 0.6233, 0.6989, 0.6126, 0.5318, 0.6490,
        0.6201, 0.6698, 0.6361, 0.6635, 0.6713, 0.5693, 0.6262],
       device='cuda:0') torch.Size([16])
percent tensor([0.6233, 0.6029, 0.6231, 0.6393, 0.6630, 0.6767, 0.6286, 0.6322, 0.6052,
        0.6034, 0.6104, 0.5801, 0.6016, 0.6018, 0.5729, 0.6504],
       device='cuda:0') torch.Size([16])
percent tensor([0.9998, 0.9990, 0.9991, 0.9995, 0.9991, 0.9978, 0.9992, 0.9996, 0.9995,
        0.9996, 0.9997, 0.9993, 0.9997, 0.9996, 0.9977, 0.9994],
       device='cuda:0') torch.Size([16])
Epoch: 92 | Batch_idx: 0 |  Loss: (0.2484) |  Loss2: (0.0000) | Acc: (92.00%) (118/128)
Epoch: 92 | Batch_idx: 10 |  Loss: (0.2272) |  Loss2: (0.0000) | Acc: (93.00%) (1314/1408)
Epoch: 92 | Batch_idx: 20 |  Loss: (0.2239) |  Loss2: (0.0000) | Acc: (92.00%) (2493/2688)
Epoch: 92 | Batch_idx: 30 |  Loss: (0.2201) |  Loss2: (0.0000) | Acc: (92.00%) (3685/3968)
Epoch: 92 | Batch_idx: 40 |  Loss: (0.2260) |  Loss2: (0.0000) | Acc: (92.00%) (4853/5248)
Epoch: 92 | Batch_idx: 50 |  Loss: (0.2258) |  Loss2: (0.0000) | Acc: (92.00%) (6027/6528)
Epoch: 92 | Batch_idx: 60 |  Loss: (0.2295) |  Loss2: (0.0000) | Acc: (92.00%) (7195/7808)
Epoch: 92 | Batch_idx: 70 |  Loss: (0.2319) |  Loss2: (0.0000) | Acc: (92.00%) (8370/9088)
Epoch: 92 | Batch_idx: 80 |  Loss: (0.2322) |  Loss2: (0.0000) | Acc: (92.00%) (9551/10368)
Epoch: 92 | Batch_idx: 90 |  Loss: (0.2365) |  Loss2: (0.0000) | Acc: (91.00%) (10710/11648)
Epoch: 92 | Batch_idx: 100 |  Loss: (0.2376) |  Loss2: (0.0000) | Acc: (91.00%) (11881/12928)
Epoch: 92 | Batch_idx: 110 |  Loss: (0.2416) |  Loss2: (0.0000) | Acc: (91.00%) (13038/14208)
Epoch: 92 | Batch_idx: 120 |  Loss: (0.2415) |  Loss2: (0.0000) | Acc: (91.00%) (14224/15488)
Epoch: 92 | Batch_idx: 130 |  Loss: (0.2420) |  Loss2: (0.0000) | Acc: (91.00%) (15391/16768)
Epoch: 92 | Batch_idx: 140 |  Loss: (0.2405) |  Loss2: (0.0000) | Acc: (91.00%) (16569/18048)
Epoch: 92 | Batch_idx: 150 |  Loss: (0.2399) |  Loss2: (0.0000) | Acc: (91.00%) (17746/19328)
Epoch: 92 | Batch_idx: 160 |  Loss: (0.2403) |  Loss2: (0.0000) | Acc: (91.00%) (18916/20608)
Epoch: 92 | Batch_idx: 170 |  Loss: (0.2411) |  Loss2: (0.0000) | Acc: (91.00%) (20091/21888)
Epoch: 92 | Batch_idx: 180 |  Loss: (0.2402) |  Loss2: (0.0000) | Acc: (91.00%) (21266/23168)
Epoch: 92 | Batch_idx: 190 |  Loss: (0.2407) |  Loss2: (0.0000) | Acc: (91.00%) (22434/24448)
Epoch: 92 | Batch_idx: 200 |  Loss: (0.2420) |  Loss2: (0.0000) | Acc: (91.00%) (23598/25728)
Epoch: 92 | Batch_idx: 210 |  Loss: (0.2422) |  Loss2: (0.0000) | Acc: (91.00%) (24768/27008)
Epoch: 92 | Batch_idx: 220 |  Loss: (0.2415) |  Loss2: (0.0000) | Acc: (91.00%) (25951/28288)
Epoch: 92 | Batch_idx: 230 |  Loss: (0.2423) |  Loss2: (0.0000) | Acc: (91.00%) (27117/29568)
Epoch: 92 | Batch_idx: 240 |  Loss: (0.2424) |  Loss2: (0.0000) | Acc: (91.00%) (28294/30848)
Epoch: 92 | Batch_idx: 250 |  Loss: (0.2422) |  Loss2: (0.0000) | Acc: (91.00%) (29467/32128)
Epoch: 92 | Batch_idx: 260 |  Loss: (0.2415) |  Loss2: (0.0000) | Acc: (91.00%) (30645/33408)
Epoch: 92 | Batch_idx: 270 |  Loss: (0.2398) |  Loss2: (0.0000) | Acc: (91.00%) (31842/34688)
Epoch: 92 | Batch_idx: 280 |  Loss: (0.2399) |  Loss2: (0.0000) | Acc: (91.00%) (33015/35968)
Epoch: 92 | Batch_idx: 290 |  Loss: (0.2397) |  Loss2: (0.0000) | Acc: (91.00%) (34190/37248)
Epoch: 92 | Batch_idx: 300 |  Loss: (0.2398) |  Loss2: (0.0000) | Acc: (91.00%) (35360/38528)
Epoch: 92 | Batch_idx: 310 |  Loss: (0.2398) |  Loss2: (0.0000) | Acc: (91.00%) (36534/39808)
Epoch: 92 | Batch_idx: 320 |  Loss: (0.2400) |  Loss2: (0.0000) | Acc: (91.00%) (37704/41088)
Epoch: 92 | Batch_idx: 330 |  Loss: (0.2405) |  Loss2: (0.0000) | Acc: (91.00%) (38862/42368)
Epoch: 92 | Batch_idx: 340 |  Loss: (0.2413) |  Loss2: (0.0000) | Acc: (91.00%) (40019/43648)
Epoch: 92 | Batch_idx: 350 |  Loss: (0.2412) |  Loss2: (0.0000) | Acc: (91.00%) (41190/44928)
Epoch: 92 | Batch_idx: 360 |  Loss: (0.2410) |  Loss2: (0.0000) | Acc: (91.00%) (42367/46208)
Epoch: 92 | Batch_idx: 370 |  Loss: (0.2403) |  Loss2: (0.0000) | Acc: (91.00%) (43553/47488)
Epoch: 92 | Batch_idx: 380 |  Loss: (0.2405) |  Loss2: (0.0000) | Acc: (91.00%) (44721/48768)
Epoch: 92 | Batch_idx: 390 |  Loss: (0.2401) |  Loss2: (0.0000) | Acc: (91.00%) (45874/50000)
# TEST : Loss: (0.3856) | Acc: (87.00%) (8737/10000)
percent tensor([0.5160, 0.5164, 0.5168, 0.5179, 0.5178, 0.5213, 0.5173, 0.5181, 0.5158,
        0.5162, 0.5157, 0.5165, 0.5157, 0.5166, 0.5178, 0.5171],
       device='cuda:0') torch.Size([16])
percent tensor([0.5093, 0.5091, 0.5096, 0.5122, 0.5076, 0.5156, 0.5051, 0.5065, 0.5079,
        0.5085, 0.5082, 0.5107, 0.5127, 0.5057, 0.5118, 0.5127],
       device='cuda:0') torch.Size([16])
percent tensor([0.5778, 0.5278, 0.6188, 0.6390, 0.6274, 0.6076, 0.5769, 0.6103, 0.6040,
        0.5657, 0.5888, 0.5872, 0.5023, 0.6249, 0.5623, 0.5788],
       device='cuda:0') torch.Size([16])
percent tensor([0.6073, 0.6119, 0.6037, 0.6012, 0.6065, 0.5865, 0.6147, 0.6133, 0.6150,
        0.6124, 0.6165, 0.6163, 0.6127, 0.6078, 0.6147, 0.6014],
       device='cuda:0') torch.Size([16])
percent tensor([0.5854, 0.5729, 0.6253, 0.6392, 0.6507, 0.6610, 0.5784, 0.5961, 0.6039,
        0.6033, 0.5691, 0.5964, 0.5847, 0.6080, 0.5595, 0.6319],
       device='cuda:0') torch.Size([16])
percent tensor([0.5917, 0.6263, 0.6147, 0.6423, 0.6172, 0.6947, 0.6099, 0.5238, 0.6468,
        0.6192, 0.6688, 0.6319, 0.6638, 0.6699, 0.5649, 0.6233],
       device='cuda:0') torch.Size([16])
percent tensor([0.6388, 0.6187, 0.6310, 0.6451, 0.6691, 0.6905, 0.6430, 0.6374, 0.6193,
        0.6174, 0.6234, 0.5877, 0.6203, 0.6155, 0.5837, 0.6653],
       device='cuda:0') torch.Size([16])
percent tensor([0.9998, 0.9990, 0.9991, 0.9995, 0.9992, 0.9979, 0.9992, 0.9996, 0.9995,
        0.9995, 0.9997, 0.9993, 0.9997, 0.9996, 0.9977, 0.9995],
       device='cuda:0') torch.Size([16])
Epoch: 93 | Batch_idx: 0 |  Loss: (0.3245) |  Loss2: (0.0000) | Acc: (89.00%) (115/128)
Epoch: 93 | Batch_idx: 10 |  Loss: (0.2349) |  Loss2: (0.0000) | Acc: (91.00%) (1294/1408)
Epoch: 93 | Batch_idx: 20 |  Loss: (0.2238) |  Loss2: (0.0000) | Acc: (92.00%) (2486/2688)
Epoch: 93 | Batch_idx: 30 |  Loss: (0.2311) |  Loss2: (0.0000) | Acc: (92.00%) (3654/3968)
Epoch: 93 | Batch_idx: 40 |  Loss: (0.2412) |  Loss2: (0.0000) | Acc: (91.00%) (4804/5248)
Epoch: 93 | Batch_idx: 50 |  Loss: (0.2383) |  Loss2: (0.0000) | Acc: (91.00%) (5977/6528)
Epoch: 93 | Batch_idx: 60 |  Loss: (0.2379) |  Loss2: (0.0000) | Acc: (91.00%) (7160/7808)
Epoch: 93 | Batch_idx: 70 |  Loss: (0.2371) |  Loss2: (0.0000) | Acc: (91.00%) (8335/9088)
Epoch: 93 | Batch_idx: 80 |  Loss: (0.2367) |  Loss2: (0.0000) | Acc: (91.00%) (9511/10368)
Epoch: 93 | Batch_idx: 90 |  Loss: (0.2404) |  Loss2: (0.0000) | Acc: (91.00%) (10678/11648)
Epoch: 93 | Batch_idx: 100 |  Loss: (0.2417) |  Loss2: (0.0000) | Acc: (91.00%) (11851/12928)
Epoch: 93 | Batch_idx: 110 |  Loss: (0.2404) |  Loss2: (0.0000) | Acc: (91.00%) (13029/14208)
Epoch: 93 | Batch_idx: 120 |  Loss: (0.2409) |  Loss2: (0.0000) | Acc: (91.00%) (14193/15488)
Epoch: 93 | Batch_idx: 130 |  Loss: (0.2402) |  Loss2: (0.0000) | Acc: (91.00%) (15377/16768)
Epoch: 93 | Batch_idx: 140 |  Loss: (0.2427) |  Loss2: (0.0000) | Acc: (91.00%) (16526/18048)
Epoch: 93 | Batch_idx: 150 |  Loss: (0.2404) |  Loss2: (0.0000) | Acc: (91.00%) (17720/19328)
Epoch: 93 | Batch_idx: 160 |  Loss: (0.2407) |  Loss2: (0.0000) | Acc: (91.00%) (18898/20608)
Epoch: 93 | Batch_idx: 170 |  Loss: (0.2390) |  Loss2: (0.0000) | Acc: (91.00%) (20094/21888)
Epoch: 93 | Batch_idx: 180 |  Loss: (0.2371) |  Loss2: (0.0000) | Acc: (91.00%) (21292/23168)
Epoch: 93 | Batch_idx: 190 |  Loss: (0.2366) |  Loss2: (0.0000) | Acc: (91.00%) (22478/24448)
Epoch: 93 | Batch_idx: 200 |  Loss: (0.2376) |  Loss2: (0.0000) | Acc: (91.00%) (23649/25728)
Epoch: 93 | Batch_idx: 210 |  Loss: (0.2369) |  Loss2: (0.0000) | Acc: (91.00%) (24831/27008)
Epoch: 93 | Batch_idx: 220 |  Loss: (0.2372) |  Loss2: (0.0000) | Acc: (91.00%) (26003/28288)
Epoch: 93 | Batch_idx: 230 |  Loss: (0.2373) |  Loss2: (0.0000) | Acc: (91.00%) (27173/29568)
Epoch: 93 | Batch_idx: 240 |  Loss: (0.2380) |  Loss2: (0.0000) | Acc: (91.00%) (28346/30848)
Epoch: 93 | Batch_idx: 250 |  Loss: (0.2374) |  Loss2: (0.0000) | Acc: (91.00%) (29531/32128)
Epoch: 93 | Batch_idx: 260 |  Loss: (0.2369) |  Loss2: (0.0000) | Acc: (91.00%) (30711/33408)
Epoch: 93 | Batch_idx: 270 |  Loss: (0.2366) |  Loss2: (0.0000) | Acc: (91.00%) (31879/34688)
Epoch: 93 | Batch_idx: 280 |  Loss: (0.2379) |  Loss2: (0.0000) | Acc: (91.00%) (33051/35968)
Epoch: 93 | Batch_idx: 290 |  Loss: (0.2378) |  Loss2: (0.0000) | Acc: (91.00%) (34237/37248)
Epoch: 93 | Batch_idx: 300 |  Loss: (0.2371) |  Loss2: (0.0000) | Acc: (91.00%) (35420/38528)
Epoch: 93 | Batch_idx: 310 |  Loss: (0.2366) |  Loss2: (0.0000) | Acc: (91.00%) (36603/39808)
Epoch: 93 | Batch_idx: 320 |  Loss: (0.2364) |  Loss2: (0.0000) | Acc: (91.00%) (37785/41088)
Epoch: 93 | Batch_idx: 330 |  Loss: (0.2361) |  Loss2: (0.0000) | Acc: (91.00%) (38973/42368)
Epoch: 93 | Batch_idx: 340 |  Loss: (0.2362) |  Loss2: (0.0000) | Acc: (91.00%) (40153/43648)
Epoch: 93 | Batch_idx: 350 |  Loss: (0.2354) |  Loss2: (0.0000) | Acc: (92.00%) (41342/44928)
Epoch: 93 | Batch_idx: 360 |  Loss: (0.2354) |  Loss2: (0.0000) | Acc: (92.00%) (42523/46208)
Epoch: 93 | Batch_idx: 370 |  Loss: (0.2347) |  Loss2: (0.0000) | Acc: (92.00%) (43709/47488)
Epoch: 93 | Batch_idx: 380 |  Loss: (0.2350) |  Loss2: (0.0000) | Acc: (92.00%) (44893/48768)
Epoch: 93 | Batch_idx: 390 |  Loss: (0.2348) |  Loss2: (0.0000) | Acc: (92.00%) (46031/50000)
# TEST : Loss: (0.3810) | Acc: (87.00%) (8740/10000)
percent tensor([0.5166, 0.5171, 0.5172, 0.5186, 0.5184, 0.5228, 0.5179, 0.5186, 0.5163,
        0.5165, 0.5164, 0.5168, 0.5162, 0.5172, 0.5189, 0.5179],
       device='cuda:0') torch.Size([16])
percent tensor([0.5097, 0.5091, 0.5098, 0.5124, 0.5077, 0.5158, 0.5051, 0.5067, 0.5083,
        0.5085, 0.5085, 0.5109, 0.5130, 0.5058, 0.5119, 0.5131],
       device='cuda:0') torch.Size([16])
percent tensor([0.5746, 0.5236, 0.6177, 0.6370, 0.6260, 0.6058, 0.5721, 0.6096, 0.6013,
        0.5602, 0.5852, 0.5825, 0.4975, 0.6227, 0.5582, 0.5746],
       device='cuda:0') torch.Size([16])
percent tensor([0.6137, 0.6172, 0.6106, 0.6086, 0.6133, 0.5933, 0.6211, 0.6206, 0.6222,
        0.6189, 0.6233, 0.6239, 0.6181, 0.6151, 0.6214, 0.6075],
       device='cuda:0') torch.Size([16])
percent tensor([0.5844, 0.5702, 0.6246, 0.6372, 0.6499, 0.6611, 0.5773, 0.5951, 0.6003,
        0.6001, 0.5646, 0.5941, 0.5827, 0.6024, 0.5585, 0.6310],
       device='cuda:0') torch.Size([16])
percent tensor([0.5868, 0.6261, 0.6058, 0.6337, 0.6090, 0.6900, 0.6060, 0.5134, 0.6412,
        0.6176, 0.6670, 0.6234, 0.6618, 0.6673, 0.5578, 0.6207],
       device='cuda:0') torch.Size([16])
percent tensor([0.6429, 0.6242, 0.6298, 0.6427, 0.6673, 0.6949, 0.6463, 0.6330, 0.6231,
        0.6211, 0.6283, 0.5874, 0.6296, 0.6179, 0.5855, 0.6686],
       device='cuda:0') torch.Size([16])
percent tensor([0.9998, 0.9991, 0.9992, 0.9996, 0.9993, 0.9980, 0.9992, 0.9996, 0.9996,
        0.9996, 0.9998, 0.9993, 0.9997, 0.9996, 0.9978, 0.9995],
       device='cuda:0') torch.Size([16])
Epoch: 94 | Batch_idx: 0 |  Loss: (0.2491) |  Loss2: (0.0000) | Acc: (89.00%) (115/128)
Epoch: 94 | Batch_idx: 10 |  Loss: (0.2408) |  Loss2: (0.0000) | Acc: (91.00%) (1290/1408)
Epoch: 94 | Batch_idx: 20 |  Loss: (0.2381) |  Loss2: (0.0000) | Acc: (92.00%) (2476/2688)
Epoch: 94 | Batch_idx: 30 |  Loss: (0.2296) |  Loss2: (0.0000) | Acc: (92.00%) (3666/3968)
Epoch: 94 | Batch_idx: 40 |  Loss: (0.2267) |  Loss2: (0.0000) | Acc: (92.00%) (4851/5248)
Epoch: 94 | Batch_idx: 50 |  Loss: (0.2249) |  Loss2: (0.0000) | Acc: (92.00%) (6033/6528)
Epoch: 94 | Batch_idx: 60 |  Loss: (0.2258) |  Loss2: (0.0000) | Acc: (92.00%) (7208/7808)
Epoch: 94 | Batch_idx: 70 |  Loss: (0.2297) |  Loss2: (0.0000) | Acc: (92.00%) (8373/9088)
Epoch: 94 | Batch_idx: 80 |  Loss: (0.2315) |  Loss2: (0.0000) | Acc: (91.00%) (9538/10368)
Epoch: 94 | Batch_idx: 90 |  Loss: (0.2304) |  Loss2: (0.0000) | Acc: (92.00%) (10724/11648)
Epoch: 94 | Batch_idx: 100 |  Loss: (0.2305) |  Loss2: (0.0000) | Acc: (92.00%) (11902/12928)
Epoch: 94 | Batch_idx: 110 |  Loss: (0.2308) |  Loss2: (0.0000) | Acc: (92.00%) (13078/14208)
Epoch: 94 | Batch_idx: 120 |  Loss: (0.2327) |  Loss2: (0.0000) | Acc: (92.00%) (14251/15488)
Epoch: 94 | Batch_idx: 130 |  Loss: (0.2333) |  Loss2: (0.0000) | Acc: (91.00%) (15419/16768)
Epoch: 94 | Batch_idx: 140 |  Loss: (0.2303) |  Loss2: (0.0000) | Acc: (92.00%) (16620/18048)
Epoch: 94 | Batch_idx: 150 |  Loss: (0.2286) |  Loss2: (0.0000) | Acc: (92.00%) (17814/19328)
Epoch: 94 | Batch_idx: 160 |  Loss: (0.2285) |  Loss2: (0.0000) | Acc: (92.00%) (19003/20608)
Epoch: 94 | Batch_idx: 170 |  Loss: (0.2284) |  Loss2: (0.0000) | Acc: (92.00%) (20187/21888)
Epoch: 94 | Batch_idx: 180 |  Loss: (0.2286) |  Loss2: (0.0000) | Acc: (92.00%) (21373/23168)
Epoch: 94 | Batch_idx: 190 |  Loss: (0.2283) |  Loss2: (0.0000) | Acc: (92.00%) (22559/24448)
Epoch: 94 | Batch_idx: 200 |  Loss: (0.2294) |  Loss2: (0.0000) | Acc: (92.00%) (23734/25728)
Epoch: 94 | Batch_idx: 210 |  Loss: (0.2302) |  Loss2: (0.0000) | Acc: (92.00%) (24901/27008)
Epoch: 94 | Batch_idx: 220 |  Loss: (0.2290) |  Loss2: (0.0000) | Acc: (92.00%) (26098/28288)
Epoch: 94 | Batch_idx: 230 |  Loss: (0.2286) |  Loss2: (0.0000) | Acc: (92.00%) (27283/29568)
Epoch: 94 | Batch_idx: 240 |  Loss: (0.2279) |  Loss2: (0.0000) | Acc: (92.00%) (28481/30848)
Epoch: 94 | Batch_idx: 250 |  Loss: (0.2270) |  Loss2: (0.0000) | Acc: (92.00%) (29675/32128)
Epoch: 94 | Batch_idx: 260 |  Loss: (0.2273) |  Loss2: (0.0000) | Acc: (92.00%) (30851/33408)
Epoch: 94 | Batch_idx: 270 |  Loss: (0.2271) |  Loss2: (0.0000) | Acc: (92.00%) (32039/34688)
Epoch: 94 | Batch_idx: 280 |  Loss: (0.2278) |  Loss2: (0.0000) | Acc: (92.00%) (33211/35968)
Epoch: 94 | Batch_idx: 290 |  Loss: (0.2274) |  Loss2: (0.0000) | Acc: (92.00%) (34395/37248)
Epoch: 94 | Batch_idx: 300 |  Loss: (0.2278) |  Loss2: (0.0000) | Acc: (92.00%) (35572/38528)
Epoch: 94 | Batch_idx: 310 |  Loss: (0.2282) |  Loss2: (0.0000) | Acc: (92.00%) (36751/39808)
Epoch: 94 | Batch_idx: 320 |  Loss: (0.2268) |  Loss2: (0.0000) | Acc: (92.00%) (37963/41088)
Epoch: 94 | Batch_idx: 330 |  Loss: (0.2270) |  Loss2: (0.0000) | Acc: (92.00%) (39135/42368)
Epoch: 94 | Batch_idx: 340 |  Loss: (0.2269) |  Loss2: (0.0000) | Acc: (92.00%) (40314/43648)
Epoch: 94 | Batch_idx: 350 |  Loss: (0.2266) |  Loss2: (0.0000) | Acc: (92.00%) (41500/44928)
Epoch: 94 | Batch_idx: 360 |  Loss: (0.2268) |  Loss2: (0.0000) | Acc: (92.00%) (42673/46208)
Epoch: 94 | Batch_idx: 370 |  Loss: (0.2271) |  Loss2: (0.0000) | Acc: (92.00%) (43848/47488)
Epoch: 94 | Batch_idx: 380 |  Loss: (0.2275) |  Loss2: (0.0000) | Acc: (92.00%) (45029/48768)
Epoch: 94 | Batch_idx: 390 |  Loss: (0.2273) |  Loss2: (0.0000) | Acc: (92.00%) (46175/50000)
# TEST : Loss: (0.3775) | Acc: (87.00%) (8755/10000)
percent tensor([0.5167, 0.5170, 0.5170, 0.5186, 0.5183, 0.5235, 0.5177, 0.5183, 0.5163,
        0.5162, 0.5165, 0.5165, 0.5161, 0.5171, 0.5191, 0.5181],
       device='cuda:0') torch.Size([16])
percent tensor([0.5088, 0.5076, 0.5085, 0.5111, 0.5064, 0.5153, 0.5037, 0.5053, 0.5070,
        0.5071, 0.5073, 0.5096, 0.5119, 0.5045, 0.5108, 0.5120],
       device='cuda:0') torch.Size([16])
percent tensor([0.5689, 0.5206, 0.6122, 0.6302, 0.6210, 0.6012, 0.5688, 0.6048, 0.5965,
        0.5546, 0.5799, 0.5751, 0.4925, 0.6187, 0.5546, 0.5687],
       device='cuda:0') torch.Size([16])
percent tensor([0.6138, 0.6176, 0.6115, 0.6099, 0.6141, 0.5945, 0.6215, 0.6209, 0.6231,
        0.6200, 0.6249, 0.6250, 0.6182, 0.6167, 0.6222, 0.6082],
       device='cuda:0') torch.Size([16])
percent tensor([0.5863, 0.5718, 0.6272, 0.6386, 0.6525, 0.6632, 0.5796, 0.5969, 0.6024,
        0.6037, 0.5654, 0.5984, 0.5836, 0.6041, 0.5613, 0.6335],
       device='cuda:0') torch.Size([16])
percent tensor([0.5997, 0.6386, 0.6120, 0.6399, 0.6173, 0.6989, 0.6168, 0.5202, 0.6536,
        0.6331, 0.6806, 0.6324, 0.6752, 0.6812, 0.5670, 0.6320],
       device='cuda:0') torch.Size([16])
percent tensor([0.6467, 0.6278, 0.6267, 0.6408, 0.6660, 0.6990, 0.6478, 0.6314, 0.6261,
        0.6247, 0.6324, 0.5876, 0.6359, 0.6200, 0.5857, 0.6721],
       device='cuda:0') torch.Size([16])
percent tensor([0.9998, 0.9991, 0.9992, 0.9996, 0.9993, 0.9980, 0.9992, 0.9996, 0.9995,
        0.9996, 0.9998, 0.9993, 0.9997, 0.9996, 0.9978, 0.9995],
       device='cuda:0') torch.Size([16])
Epoch: 95 | Batch_idx: 0 |  Loss: (0.2998) |  Loss2: (0.0000) | Acc: (87.00%) (112/128)
Epoch: 95 | Batch_idx: 10 |  Loss: (0.2328) |  Loss2: (0.0000) | Acc: (91.00%) (1288/1408)
Epoch: 95 | Batch_idx: 20 |  Loss: (0.2248) |  Loss2: (0.0000) | Acc: (92.00%) (2483/2688)
Epoch: 95 | Batch_idx: 30 |  Loss: (0.2216) |  Loss2: (0.0000) | Acc: (92.00%) (3666/3968)
Epoch: 95 | Batch_idx: 40 |  Loss: (0.2251) |  Loss2: (0.0000) | Acc: (92.00%) (4838/5248)
Epoch: 95 | Batch_idx: 50 |  Loss: (0.2265) |  Loss2: (0.0000) | Acc: (92.00%) (6008/6528)
Epoch: 95 | Batch_idx: 60 |  Loss: (0.2236) |  Loss2: (0.0000) | Acc: (92.00%) (7203/7808)
Epoch: 95 | Batch_idx: 70 |  Loss: (0.2238) |  Loss2: (0.0000) | Acc: (92.00%) (8387/9088)
Epoch: 95 | Batch_idx: 80 |  Loss: (0.2205) |  Loss2: (0.0000) | Acc: (92.00%) (9589/10368)
Epoch: 95 | Batch_idx: 90 |  Loss: (0.2194) |  Loss2: (0.0000) | Acc: (92.00%) (10776/11648)
Epoch: 95 | Batch_idx: 100 |  Loss: (0.2194) |  Loss2: (0.0000) | Acc: (92.00%) (11968/12928)
Epoch: 95 | Batch_idx: 110 |  Loss: (0.2202) |  Loss2: (0.0000) | Acc: (92.00%) (13152/14208)
Epoch: 95 | Batch_idx: 120 |  Loss: (0.2211) |  Loss2: (0.0000) | Acc: (92.00%) (14338/15488)
Epoch: 95 | Batch_idx: 130 |  Loss: (0.2229) |  Loss2: (0.0000) | Acc: (92.00%) (15512/16768)
Epoch: 95 | Batch_idx: 140 |  Loss: (0.2236) |  Loss2: (0.0000) | Acc: (92.00%) (16689/18048)
Epoch: 95 | Batch_idx: 150 |  Loss: (0.2243) |  Loss2: (0.0000) | Acc: (92.00%) (17870/19328)
Epoch: 95 | Batch_idx: 160 |  Loss: (0.2258) |  Loss2: (0.0000) | Acc: (92.00%) (19046/20608)
Epoch: 95 | Batch_idx: 170 |  Loss: (0.2276) |  Loss2: (0.0000) | Acc: (92.00%) (20204/21888)
Epoch: 95 | Batch_idx: 180 |  Loss: (0.2269) |  Loss2: (0.0000) | Acc: (92.00%) (21394/23168)
Epoch: 95 | Batch_idx: 190 |  Loss: (0.2280) |  Loss2: (0.0000) | Acc: (92.00%) (22572/24448)
Epoch: 95 | Batch_idx: 200 |  Loss: (0.2278) |  Loss2: (0.0000) | Acc: (92.00%) (23753/25728)
Epoch: 95 | Batch_idx: 210 |  Loss: (0.2261) |  Loss2: (0.0000) | Acc: (92.00%) (24950/27008)
Epoch: 95 | Batch_idx: 220 |  Loss: (0.2257) |  Loss2: (0.0000) | Acc: (92.00%) (26140/28288)
Epoch: 95 | Batch_idx: 230 |  Loss: (0.2250) |  Loss2: (0.0000) | Acc: (92.00%) (27335/29568)
Epoch: 95 | Batch_idx: 240 |  Loss: (0.2258) |  Loss2: (0.0000) | Acc: (92.00%) (28509/30848)
Epoch: 95 | Batch_idx: 250 |  Loss: (0.2252) |  Loss2: (0.0000) | Acc: (92.00%) (29707/32128)
Epoch: 95 | Batch_idx: 260 |  Loss: (0.2250) |  Loss2: (0.0000) | Acc: (92.00%) (30894/33408)
Epoch: 95 | Batch_idx: 270 |  Loss: (0.2262) |  Loss2: (0.0000) | Acc: (92.00%) (32072/34688)
Epoch: 95 | Batch_idx: 280 |  Loss: (0.2264) |  Loss2: (0.0000) | Acc: (92.00%) (33257/35968)
Epoch: 95 | Batch_idx: 290 |  Loss: (0.2267) |  Loss2: (0.0000) | Acc: (92.00%) (34421/37248)
Epoch: 95 | Batch_idx: 300 |  Loss: (0.2270) |  Loss2: (0.0000) | Acc: (92.00%) (35602/38528)
Epoch: 95 | Batch_idx: 310 |  Loss: (0.2267) |  Loss2: (0.0000) | Acc: (92.00%) (36780/39808)
Epoch: 95 | Batch_idx: 320 |  Loss: (0.2259) |  Loss2: (0.0000) | Acc: (92.00%) (37974/41088)
Epoch: 95 | Batch_idx: 330 |  Loss: (0.2263) |  Loss2: (0.0000) | Acc: (92.00%) (39151/42368)
Epoch: 95 | Batch_idx: 340 |  Loss: (0.2268) |  Loss2: (0.0000) | Acc: (92.00%) (40328/43648)
Epoch: 95 | Batch_idx: 350 |  Loss: (0.2271) |  Loss2: (0.0000) | Acc: (92.00%) (41498/44928)
Epoch: 95 | Batch_idx: 360 |  Loss: (0.2276) |  Loss2: (0.0000) | Acc: (92.00%) (42673/46208)
Epoch: 95 | Batch_idx: 370 |  Loss: (0.2272) |  Loss2: (0.0000) | Acc: (92.00%) (43867/47488)
Epoch: 95 | Batch_idx: 380 |  Loss: (0.2263) |  Loss2: (0.0000) | Acc: (92.00%) (45065/48768)
Epoch: 95 | Batch_idx: 390 |  Loss: (0.2262) |  Loss2: (0.0000) | Acc: (92.00%) (46209/50000)
=> saving checkpoint 'drive/app/torch/save_Schedule/checkpoint_095.pth.tar'
# TEST : Loss: (0.3722) | Acc: (87.00%) (8764/10000)
percent tensor([0.5163, 0.5164, 0.5164, 0.5181, 0.5177, 0.5235, 0.5171, 0.5176, 0.5158,
        0.5154, 0.5161, 0.5157, 0.5156, 0.5166, 0.5187, 0.5177],
       device='cuda:0') torch.Size([16])
percent tensor([0.5084, 0.5066, 0.5078, 0.5104, 0.5055, 0.5148, 0.5027, 0.5045, 0.5065,
        0.5062, 0.5066, 0.5089, 0.5114, 0.5038, 0.5099, 0.5115],
       device='cuda:0') torch.Size([16])
percent tensor([0.5712, 0.5227, 0.6145, 0.6323, 0.6230, 0.6041, 0.5700, 0.6067, 0.5986,
        0.5563, 0.5830, 0.5763, 0.4949, 0.6208, 0.5568, 0.5705],
       device='cuda:0') torch.Size([16])
percent tensor([0.6168, 0.6204, 0.6146, 0.6128, 0.6168, 0.5969, 0.6247, 0.6236, 0.6268,
        0.6235, 0.6286, 0.6288, 0.6212, 0.6203, 0.6249, 0.6111],
       device='cuda:0') torch.Size([16])
percent tensor([0.5894, 0.5758, 0.6332, 0.6436, 0.6597, 0.6683, 0.5839, 0.6024, 0.6069,
        0.6081, 0.5676, 0.6044, 0.5872, 0.6069, 0.5667, 0.6387],
       device='cuda:0') torch.Size([16])
percent tensor([0.5972, 0.6381, 0.6090, 0.6366, 0.6140, 0.6972, 0.6154, 0.5166, 0.6513,
        0.6308, 0.6797, 0.6271, 0.6741, 0.6802, 0.5621, 0.6311],
       device='cuda:0') torch.Size([16])
percent tensor([0.6500, 0.6321, 0.6282, 0.6411, 0.6647, 0.7005, 0.6516, 0.6308, 0.6299,
        0.6267, 0.6382, 0.5890, 0.6410, 0.6262, 0.5872, 0.6748],
       device='cuda:0') torch.Size([16])
percent tensor([0.9998, 0.9991, 0.9992, 0.9996, 0.9993, 0.9980, 0.9992, 0.9996, 0.9996,
        0.9996, 0.9998, 0.9993, 0.9997, 0.9996, 0.9979, 0.9995],
       device='cuda:0') torch.Size([16])
True Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=128, out_features=16, bias=False)
False Linear(in_features=16, out_features=2, bias=False)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=128, out_features=16, bias=False)
False Linear(in_features=16, out_features=2, bias=False)
True Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=256, out_features=32, bias=False)
False Linear(in_features=32, out_features=2, bias=False)
True Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=256, out_features=32, bias=False)
False Linear(in_features=32, out_features=2, bias=False)
True Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=512, out_features=64, bias=False)
False Linear(in_features=64, out_features=2, bias=False)
True Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=512, out_features=64, bias=False)
False Linear(in_features=64, out_features=2, bias=False)
True Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1024, out_features=128, bias=False)
False Linear(in_features=128, out_features=2, bias=False)
True Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1024, out_features=128, bias=False)
False Linear(in_features=128, out_features=2, bias=False)
True Linear(in_features=512, out_features=10, bias=True)
Epoch: 96 | Batch_idx: 0 |  Loss: (0.2725) |  Loss2: (0.0000) | Acc: (90.00%) (116/128)
Epoch: 96 | Batch_idx: 10 |  Loss: (0.2134) |  Loss2: (0.0000) | Acc: (92.00%) (1307/1408)
Epoch: 96 | Batch_idx: 20 |  Loss: (0.2064) |  Loss2: (0.0000) | Acc: (93.00%) (2503/2688)
Epoch: 96 | Batch_idx: 30 |  Loss: (0.2196) |  Loss2: (0.0000) | Acc: (92.00%) (3670/3968)
Epoch: 96 | Batch_idx: 40 |  Loss: (0.2184) |  Loss2: (0.0000) | Acc: (92.00%) (4858/5248)
Epoch: 96 | Batch_idx: 50 |  Loss: (0.2179) |  Loss2: (0.0000) | Acc: (92.00%) (6045/6528)
Epoch: 96 | Batch_idx: 60 |  Loss: (0.2209) |  Loss2: (0.0000) | Acc: (92.00%) (7219/7808)
Epoch: 96 | Batch_idx: 70 |  Loss: (0.2231) |  Loss2: (0.0000) | Acc: (92.00%) (8406/9088)
Epoch: 96 | Batch_idx: 80 |  Loss: (0.2274) |  Loss2: (0.0000) | Acc: (92.00%) (9569/10368)
Epoch: 96 | Batch_idx: 90 |  Loss: (0.2284) |  Loss2: (0.0000) | Acc: (92.00%) (10740/11648)
Epoch: 96 | Batch_idx: 100 |  Loss: (0.2308) |  Loss2: (0.0000) | Acc: (92.00%) (11919/12928)
Epoch: 96 | Batch_idx: 110 |  Loss: (0.2310) |  Loss2: (0.0000) | Acc: (92.00%) (13091/14208)
Epoch: 96 | Batch_idx: 120 |  Loss: (0.2315) |  Loss2: (0.0000) | Acc: (92.00%) (14265/15488)
Epoch: 96 | Batch_idx: 130 |  Loss: (0.2321) |  Loss2: (0.0000) | Acc: (92.00%) (15446/16768)
Epoch: 96 | Batch_idx: 140 |  Loss: (0.2334) |  Loss2: (0.0000) | Acc: (92.00%) (16615/18048)
Epoch: 96 | Batch_idx: 150 |  Loss: (0.2354) |  Loss2: (0.0000) | Acc: (91.00%) (17775/19328)
Epoch: 96 | Batch_idx: 160 |  Loss: (0.2367) |  Loss2: (0.0000) | Acc: (91.00%) (18940/20608)
Epoch: 96 | Batch_idx: 170 |  Loss: (0.2358) |  Loss2: (0.0000) | Acc: (91.00%) (20119/21888)
Epoch: 96 | Batch_idx: 180 |  Loss: (0.2353) |  Loss2: (0.0000) | Acc: (91.00%) (21300/23168)
Epoch: 96 | Batch_idx: 190 |  Loss: (0.2373) |  Loss2: (0.0000) | Acc: (91.00%) (22459/24448)
Epoch: 96 | Batch_idx: 200 |  Loss: (0.2369) |  Loss2: (0.0000) | Acc: (91.00%) (23635/25728)
Epoch: 96 | Batch_idx: 210 |  Loss: (0.2374) |  Loss2: (0.0000) | Acc: (91.00%) (24805/27008)
Epoch: 96 | Batch_idx: 220 |  Loss: (0.2372) |  Loss2: (0.0000) | Acc: (91.00%) (25989/28288)
Epoch: 96 | Batch_idx: 230 |  Loss: (0.2383) |  Loss2: (0.0000) | Acc: (91.00%) (27147/29568)
Epoch: 96 | Batch_idx: 240 |  Loss: (0.2386) |  Loss2: (0.0000) | Acc: (91.00%) (28328/30848)
Epoch: 96 | Batch_idx: 250 |  Loss: (0.2381) |  Loss2: (0.0000) | Acc: (91.00%) (29511/32128)
Epoch: 96 | Batch_idx: 260 |  Loss: (0.2377) |  Loss2: (0.0000) | Acc: (91.00%) (30696/33408)
Epoch: 96 | Batch_idx: 270 |  Loss: (0.2388) |  Loss2: (0.0000) | Acc: (91.00%) (31853/34688)
Epoch: 96 | Batch_idx: 280 |  Loss: (0.2395) |  Loss2: (0.0000) | Acc: (91.00%) (33006/35968)
Epoch: 96 | Batch_idx: 290 |  Loss: (0.2394) |  Loss2: (0.0000) | Acc: (91.00%) (34185/37248)
Epoch: 96 | Batch_idx: 300 |  Loss: (0.2399) |  Loss2: (0.0000) | Acc: (91.00%) (35352/38528)
Epoch: 96 | Batch_idx: 310 |  Loss: (0.2403) |  Loss2: (0.0000) | Acc: (91.00%) (36513/39808)
Epoch: 96 | Batch_idx: 320 |  Loss: (0.2415) |  Loss2: (0.0000) | Acc: (91.00%) (37671/41088)
Epoch: 96 | Batch_idx: 330 |  Loss: (0.2415) |  Loss2: (0.0000) | Acc: (91.00%) (38838/42368)
Epoch: 96 | Batch_idx: 340 |  Loss: (0.2419) |  Loss2: (0.0000) | Acc: (91.00%) (40000/43648)
Epoch: 96 | Batch_idx: 350 |  Loss: (0.2427) |  Loss2: (0.0000) | Acc: (91.00%) (41163/44928)
Epoch: 96 | Batch_idx: 360 |  Loss: (0.2422) |  Loss2: (0.0000) | Acc: (91.00%) (42353/46208)
Epoch: 96 | Batch_idx: 370 |  Loss: (0.2421) |  Loss2: (0.0000) | Acc: (91.00%) (43524/47488)
Epoch: 96 | Batch_idx: 380 |  Loss: (0.2417) |  Loss2: (0.0000) | Acc: (91.00%) (44703/48768)
Epoch: 96 | Batch_idx: 390 |  Loss: (0.2421) |  Loss2: (0.0000) | Acc: (91.00%) (45822/50000)
# TEST : Loss: (0.4188) | Acc: (86.00%) (8623/10000)
percent tensor([0.5165, 0.5160, 0.5172, 0.5183, 0.5183, 0.5231, 0.5170, 0.5178, 0.5160,
        0.5157, 0.5161, 0.5167, 0.5160, 0.5161, 0.5183, 0.5178],
       device='cuda:0') torch.Size([16])
percent tensor([0.5080, 0.5070, 0.5076, 0.5102, 0.5053, 0.5152, 0.5027, 0.5041, 0.5069,
        0.5066, 0.5069, 0.5096, 0.5117, 0.5047, 0.5096, 0.5115],
       device='cuda:0') torch.Size([16])
percent tensor([0.5680, 0.5206, 0.6140, 0.6357, 0.6222, 0.6078, 0.5614, 0.6087, 0.5924,
        0.5534, 0.5800, 0.5718, 0.4911, 0.6153, 0.5593, 0.5720],
       device='cuda:0') torch.Size([16])
percent tensor([0.6197, 0.6234, 0.6120, 0.6106, 0.6155, 0.5989, 0.6262, 0.6246, 0.6265,
        0.6241, 0.6326, 0.6285, 0.6238, 0.6209, 0.6289, 0.6133],
       device='cuda:0') torch.Size([16])
percent tensor([0.5819, 0.5700, 0.6190, 0.6406, 0.6458, 0.6598, 0.5746, 0.5980, 0.6029,
        0.6008, 0.5629, 0.5995, 0.5805, 0.6031, 0.5610, 0.6281],
       device='cuda:0') torch.Size([16])
percent tensor([0.5958, 0.6462, 0.6136, 0.6433, 0.6038, 0.6914, 0.6133, 0.5309, 0.6651,
        0.6202, 0.6797, 0.6284, 0.6631, 0.6812, 0.5552, 0.6216],
       device='cuda:0') torch.Size([16])
percent tensor([0.6486, 0.6150, 0.6513, 0.6572, 0.6647, 0.6907, 0.6449, 0.6350, 0.6243,
        0.6118, 0.6242, 0.5971, 0.6251, 0.6171, 0.5813, 0.6641],
       device='cuda:0') torch.Size([16])
percent tensor([0.9998, 0.9991, 0.9995, 0.9995, 0.9995, 0.9986, 0.9993, 0.9995, 0.9997,
        0.9992, 0.9998, 0.9996, 0.9996, 0.9995, 0.9982, 0.9995],
       device='cuda:0') torch.Size([16])
Epoch: 97 | Batch_idx: 0 |  Loss: (0.1633) |  Loss2: (0.0000) | Acc: (95.00%) (122/128)
Epoch: 97 | Batch_idx: 10 |  Loss: (0.2237) |  Loss2: (0.0000) | Acc: (92.00%) (1301/1408)
Epoch: 97 | Batch_idx: 20 |  Loss: (0.2233) |  Loss2: (0.0000) | Acc: (91.00%) (2472/2688)
Epoch: 97 | Batch_idx: 30 |  Loss: (0.2257) |  Loss2: (0.0000) | Acc: (91.00%) (3646/3968)
Epoch: 97 | Batch_idx: 40 |  Loss: (0.2254) |  Loss2: (0.0000) | Acc: (92.00%) (4835/5248)
Epoch: 97 | Batch_idx: 50 |  Loss: (0.2248) |  Loss2: (0.0000) | Acc: (92.00%) (6017/6528)
Epoch: 97 | Batch_idx: 60 |  Loss: (0.2242) |  Loss2: (0.0000) | Acc: (92.00%) (7196/7808)
Epoch: 97 | Batch_idx: 70 |  Loss: (0.2226) |  Loss2: (0.0000) | Acc: (92.00%) (8393/9088)
Epoch: 97 | Batch_idx: 80 |  Loss: (0.2222) |  Loss2: (0.0000) | Acc: (92.00%) (9569/10368)
Epoch: 97 | Batch_idx: 90 |  Loss: (0.2249) |  Loss2: (0.0000) | Acc: (92.00%) (10740/11648)
Epoch: 97 | Batch_idx: 100 |  Loss: (0.2257) |  Loss2: (0.0000) | Acc: (92.00%) (11914/12928)
Epoch: 97 | Batch_idx: 110 |  Loss: (0.2279) |  Loss2: (0.0000) | Acc: (91.00%) (13069/14208)
Epoch: 97 | Batch_idx: 120 |  Loss: (0.2312) |  Loss2: (0.0000) | Acc: (91.00%) (14235/15488)
Epoch: 97 | Batch_idx: 130 |  Loss: (0.2300) |  Loss2: (0.0000) | Acc: (91.00%) (15418/16768)
Epoch: 97 | Batch_idx: 140 |  Loss: (0.2315) |  Loss2: (0.0000) | Acc: (91.00%) (16585/18048)
Epoch: 97 | Batch_idx: 150 |  Loss: (0.2323) |  Loss2: (0.0000) | Acc: (91.00%) (17764/19328)
Epoch: 97 | Batch_idx: 160 |  Loss: (0.2322) |  Loss2: (0.0000) | Acc: (91.00%) (18956/20608)
Epoch: 97 | Batch_idx: 170 |  Loss: (0.2312) |  Loss2: (0.0000) | Acc: (92.00%) (20139/21888)
Epoch: 97 | Batch_idx: 180 |  Loss: (0.2306) |  Loss2: (0.0000) | Acc: (92.00%) (21319/23168)
Epoch: 97 | Batch_idx: 190 |  Loss: (0.2310) |  Loss2: (0.0000) | Acc: (91.00%) (22492/24448)
Epoch: 97 | Batch_idx: 200 |  Loss: (0.2313) |  Loss2: (0.0000) | Acc: (91.00%) (23658/25728)
Epoch: 97 | Batch_idx: 210 |  Loss: (0.2316) |  Loss2: (0.0000) | Acc: (91.00%) (24836/27008)
Epoch: 97 | Batch_idx: 220 |  Loss: (0.2317) |  Loss2: (0.0000) | Acc: (91.00%) (26007/28288)
Epoch: 97 | Batch_idx: 230 |  Loss: (0.2310) |  Loss2: (0.0000) | Acc: (91.00%) (27192/29568)
Epoch: 97 | Batch_idx: 240 |  Loss: (0.2318) |  Loss2: (0.0000) | Acc: (91.00%) (28362/30848)
Epoch: 97 | Batch_idx: 250 |  Loss: (0.2323) |  Loss2: (0.0000) | Acc: (91.00%) (29534/32128)
Epoch: 97 | Batch_idx: 260 |  Loss: (0.2335) |  Loss2: (0.0000) | Acc: (91.00%) (30689/33408)
Epoch: 97 | Batch_idx: 270 |  Loss: (0.2322) |  Loss2: (0.0000) | Acc: (91.00%) (31885/34688)
Epoch: 97 | Batch_idx: 280 |  Loss: (0.2328) |  Loss2: (0.0000) | Acc: (91.00%) (33046/35968)
Epoch: 97 | Batch_idx: 290 |  Loss: (0.2325) |  Loss2: (0.0000) | Acc: (91.00%) (34227/37248)
Epoch: 97 | Batch_idx: 300 |  Loss: (0.2334) |  Loss2: (0.0000) | Acc: (91.00%) (35384/38528)
Epoch: 97 | Batch_idx: 310 |  Loss: (0.2334) |  Loss2: (0.0000) | Acc: (91.00%) (36559/39808)
Epoch: 97 | Batch_idx: 320 |  Loss: (0.2346) |  Loss2: (0.0000) | Acc: (91.00%) (37719/41088)
Epoch: 97 | Batch_idx: 330 |  Loss: (0.2347) |  Loss2: (0.0000) | Acc: (91.00%) (38885/42368)
Epoch: 97 | Batch_idx: 340 |  Loss: (0.2358) |  Loss2: (0.0000) | Acc: (91.00%) (40049/43648)
Epoch: 97 | Batch_idx: 350 |  Loss: (0.2363) |  Loss2: (0.0000) | Acc: (91.00%) (41214/44928)
Epoch: 97 | Batch_idx: 360 |  Loss: (0.2368) |  Loss2: (0.0000) | Acc: (91.00%) (42384/46208)
Epoch: 97 | Batch_idx: 370 |  Loss: (0.2366) |  Loss2: (0.0000) | Acc: (91.00%) (43561/47488)
Epoch: 97 | Batch_idx: 380 |  Loss: (0.2372) |  Loss2: (0.0000) | Acc: (91.00%) (44723/48768)
Epoch: 97 | Batch_idx: 390 |  Loss: (0.2378) |  Loss2: (0.0000) | Acc: (91.00%) (45840/50000)
# TEST : Loss: (0.4385) | Acc: (85.00%) (8599/10000)
percent tensor([0.5162, 0.5172, 0.5155, 0.5185, 0.5167, 0.5229, 0.5175, 0.5177, 0.5162,
        0.5157, 0.5165, 0.5154, 0.5158, 0.5184, 0.5188, 0.5180],
       device='cuda:0') torch.Size([16])
percent tensor([0.5086, 0.5083, 0.5081, 0.5105, 0.5068, 0.5153, 0.5046, 0.5046, 0.5077,
        0.5071, 0.5079, 0.5108, 0.5125, 0.5056, 0.5107, 0.5119],
       device='cuda:0') torch.Size([16])
percent tensor([0.5622, 0.5217, 0.6109, 0.6323, 0.6206, 0.5924, 0.5628, 0.6061, 0.5955,
        0.5509, 0.5816, 0.5649, 0.4894, 0.6283, 0.5518, 0.5668],
       device='cuda:0') torch.Size([16])
percent tensor([0.6153, 0.6229, 0.6127, 0.6098, 0.6147, 0.5957, 0.6241, 0.6230, 0.6256,
        0.6222, 0.6295, 0.6305, 0.6205, 0.6223, 0.6257, 0.6101],
       device='cuda:0') torch.Size([16])
percent tensor([0.5782, 0.5714, 0.6262, 0.6444, 0.6569, 0.6528, 0.5771, 0.6056, 0.6036,
        0.5999, 0.5610, 0.6014, 0.5834, 0.6085, 0.5585, 0.6242],
       device='cuda:0') torch.Size([16])
percent tensor([0.5938, 0.6281, 0.6153, 0.6418, 0.6156, 0.7036, 0.6168, 0.5195, 0.6613,
        0.6188, 0.6779, 0.6130, 0.6675, 0.6694, 0.5497, 0.6291],
       device='cuda:0') torch.Size([16])
percent tensor([0.6452, 0.6145, 0.6407, 0.6479, 0.6643, 0.6896, 0.6617, 0.6351, 0.6182,
        0.6152, 0.6375, 0.5835, 0.6316, 0.6212, 0.5822, 0.6602],
       device='cuda:0') torch.Size([16])
percent tensor([0.9998, 0.9991, 0.9994, 0.9995, 0.9992, 0.9987, 0.9994, 0.9996, 0.9995,
        0.9994, 0.9997, 0.9996, 0.9997, 0.9995, 0.9987, 0.9995],
       device='cuda:0') torch.Size([16])
Epoch: 98 | Batch_idx: 0 |  Loss: (0.2223) |  Loss2: (0.0000) | Acc: (92.00%) (119/128)
Epoch: 98 | Batch_idx: 10 |  Loss: (0.2410) |  Loss2: (0.0000) | Acc: (91.00%) (1292/1408)
Epoch: 98 | Batch_idx: 20 |  Loss: (0.2384) |  Loss2: (0.0000) | Acc: (92.00%) (2473/2688)
Epoch: 98 | Batch_idx: 30 |  Loss: (0.2354) |  Loss2: (0.0000) | Acc: (92.00%) (3655/3968)
Epoch: 98 | Batch_idx: 40 |  Loss: (0.2288) |  Loss2: (0.0000) | Acc: (92.00%) (4847/5248)
Epoch: 98 | Batch_idx: 50 |  Loss: (0.2189) |  Loss2: (0.0000) | Acc: (92.00%) (6052/6528)
Epoch: 98 | Batch_idx: 60 |  Loss: (0.2231) |  Loss2: (0.0000) | Acc: (92.00%) (7229/7808)
Epoch: 98 | Batch_idx: 70 |  Loss: (0.2244) |  Loss2: (0.0000) | Acc: (92.00%) (8401/9088)
Epoch: 98 | Batch_idx: 80 |  Loss: (0.2207) |  Loss2: (0.0000) | Acc: (92.00%) (9600/10368)
Epoch: 98 | Batch_idx: 90 |  Loss: (0.2194) |  Loss2: (0.0000) | Acc: (92.00%) (10792/11648)
Epoch: 98 | Batch_idx: 100 |  Loss: (0.2188) |  Loss2: (0.0000) | Acc: (92.00%) (11972/12928)
Epoch: 98 | Batch_idx: 110 |  Loss: (0.2198) |  Loss2: (0.0000) | Acc: (92.00%) (13158/14208)
Epoch: 98 | Batch_idx: 120 |  Loss: (0.2193) |  Loss2: (0.0000) | Acc: (92.00%) (14347/15488)
Epoch: 98 | Batch_idx: 130 |  Loss: (0.2215) |  Loss2: (0.0000) | Acc: (92.00%) (15520/16768)
Epoch: 98 | Batch_idx: 140 |  Loss: (0.2218) |  Loss2: (0.0000) | Acc: (92.00%) (16702/18048)
Epoch: 98 | Batch_idx: 150 |  Loss: (0.2225) |  Loss2: (0.0000) | Acc: (92.00%) (17878/19328)
Epoch: 98 | Batch_idx: 160 |  Loss: (0.2224) |  Loss2: (0.0000) | Acc: (92.00%) (19072/20608)
Epoch: 98 | Batch_idx: 170 |  Loss: (0.2232) |  Loss2: (0.0000) | Acc: (92.00%) (20248/21888)
Epoch: 98 | Batch_idx: 180 |  Loss: (0.2245) |  Loss2: (0.0000) | Acc: (92.00%) (21415/23168)
Epoch: 98 | Batch_idx: 190 |  Loss: (0.2241) |  Loss2: (0.0000) | Acc: (92.00%) (22599/24448)
Epoch: 98 | Batch_idx: 200 |  Loss: (0.2254) |  Loss2: (0.0000) | Acc: (92.00%) (23770/25728)
Epoch: 98 | Batch_idx: 210 |  Loss: (0.2261) |  Loss2: (0.0000) | Acc: (92.00%) (24935/27008)
Epoch: 98 | Batch_idx: 220 |  Loss: (0.2259) |  Loss2: (0.0000) | Acc: (92.00%) (26124/28288)
Epoch: 98 | Batch_idx: 230 |  Loss: (0.2260) |  Loss2: (0.0000) | Acc: (92.00%) (27305/29568)
Epoch: 98 | Batch_idx: 240 |  Loss: (0.2263) |  Loss2: (0.0000) | Acc: (92.00%) (28476/30848)
Epoch: 98 | Batch_idx: 250 |  Loss: (0.2274) |  Loss2: (0.0000) | Acc: (92.00%) (29641/32128)
Epoch: 98 | Batch_idx: 260 |  Loss: (0.2279) |  Loss2: (0.0000) | Acc: (92.00%) (30820/33408)
Epoch: 98 | Batch_idx: 270 |  Loss: (0.2275) |  Loss2: (0.0000) | Acc: (92.00%) (32012/34688)
Epoch: 98 | Batch_idx: 280 |  Loss: (0.2276) |  Loss2: (0.0000) | Acc: (92.00%) (33188/35968)
Epoch: 98 | Batch_idx: 290 |  Loss: (0.2288) |  Loss2: (0.0000) | Acc: (92.00%) (34349/37248)
Epoch: 98 | Batch_idx: 300 |  Loss: (0.2288) |  Loss2: (0.0000) | Acc: (92.00%) (35521/38528)
Epoch: 98 | Batch_idx: 310 |  Loss: (0.2294) |  Loss2: (0.0000) | Acc: (92.00%) (36688/39808)
Epoch: 98 | Batch_idx: 320 |  Loss: (0.2289) |  Loss2: (0.0000) | Acc: (92.00%) (37875/41088)
Epoch: 98 | Batch_idx: 330 |  Loss: (0.2294) |  Loss2: (0.0000) | Acc: (92.00%) (39037/42368)
Epoch: 98 | Batch_idx: 340 |  Loss: (0.2287) |  Loss2: (0.0000) | Acc: (92.00%) (40214/43648)
Epoch: 98 | Batch_idx: 350 |  Loss: (0.2290) |  Loss2: (0.0000) | Acc: (92.00%) (41392/44928)
Epoch: 98 | Batch_idx: 360 |  Loss: (0.2290) |  Loss2: (0.0000) | Acc: (92.00%) (42562/46208)
Epoch: 98 | Batch_idx: 370 |  Loss: (0.2292) |  Loss2: (0.0000) | Acc: (92.00%) (43735/47488)
Epoch: 98 | Batch_idx: 380 |  Loss: (0.2297) |  Loss2: (0.0000) | Acc: (92.00%) (44906/48768)
Epoch: 98 | Batch_idx: 390 |  Loss: (0.2305) |  Loss2: (0.0000) | Acc: (92.00%) (46035/50000)
# TEST : Loss: (0.4214) | Acc: (86.00%) (8659/10000)
percent tensor([0.5168, 0.5172, 0.5167, 0.5188, 0.5178, 0.5231, 0.5177, 0.5183, 0.5164,
        0.5163, 0.5167, 0.5163, 0.5164, 0.5178, 0.5188, 0.5185],
       device='cuda:0') torch.Size([16])
percent tensor([0.5088, 0.5071, 0.5095, 0.5108, 0.5078, 0.5148, 0.5036, 0.5054, 0.5074,
        0.5069, 0.5070, 0.5115, 0.5126, 0.5029, 0.5103, 0.5122],
       device='cuda:0') torch.Size([16])
percent tensor([0.5568, 0.5225, 0.5954, 0.6323, 0.6114, 0.5939, 0.5603, 0.6046, 0.5860,
        0.5464, 0.5737, 0.5484, 0.4815, 0.6290, 0.5554, 0.5665],
       device='cuda:0') torch.Size([16])
percent tensor([0.6179, 0.6212, 0.6116, 0.6126, 0.6158, 0.5981, 0.6243, 0.6267, 0.6266,
        0.6215, 0.6293, 0.6292, 0.6227, 0.6191, 0.6249, 0.6117],
       device='cuda:0') torch.Size([16])
percent tensor([0.5960, 0.5881, 0.6499, 0.6555, 0.6694, 0.6700, 0.5924, 0.6163, 0.6188,
        0.6213, 0.5758, 0.6211, 0.6026, 0.6201, 0.5760, 0.6420],
       device='cuda:0') torch.Size([16])
percent tensor([0.5778, 0.6447, 0.5866, 0.6354, 0.6046, 0.6892, 0.6245, 0.5070, 0.6552,
        0.6265, 0.6835, 0.5944, 0.6651, 0.6888, 0.5541, 0.6284],
       device='cuda:0') torch.Size([16])
percent tensor([0.6458, 0.6308, 0.6487, 0.6583, 0.6728, 0.6808, 0.6706, 0.6360, 0.6417,
        0.6239, 0.6402, 0.5932, 0.6449, 0.6323, 0.5891, 0.6749],
       device='cuda:0') torch.Size([16])
percent tensor([0.9998, 0.9989, 0.9996, 0.9998, 0.9995, 0.9983, 0.9994, 0.9997, 0.9997,
        0.9991, 0.9998, 0.9996, 0.9997, 0.9994, 0.9988, 0.9996],
       device='cuda:0') torch.Size([16])
Epoch: 99 | Batch_idx: 0 |  Loss: (0.1780) |  Loss2: (0.0000) | Acc: (93.00%) (120/128)
Epoch: 99 | Batch_idx: 10 |  Loss: (0.2090) |  Loss2: (0.0000) | Acc: (93.00%) (1319/1408)
Epoch: 99 | Batch_idx: 20 |  Loss: (0.2203) |  Loss2: (0.0000) | Acc: (93.00%) (2500/2688)
Epoch: 99 | Batch_idx: 30 |  Loss: (0.2127) |  Loss2: (0.0000) | Acc: (93.00%) (3695/3968)
Epoch: 99 | Batch_idx: 40 |  Loss: (0.2151) |  Loss2: (0.0000) | Acc: (92.00%) (4874/5248)
Epoch: 99 | Batch_idx: 50 |  Loss: (0.2165) |  Loss2: (0.0000) | Acc: (92.00%) (6056/6528)
Epoch: 99 | Batch_idx: 60 |  Loss: (0.2163) |  Loss2: (0.0000) | Acc: (92.00%) (7235/7808)
Epoch: 99 | Batch_idx: 70 |  Loss: (0.2181) |  Loss2: (0.0000) | Acc: (92.00%) (8412/9088)
Epoch: 99 | Batch_idx: 80 |  Loss: (0.2186) |  Loss2: (0.0000) | Acc: (92.00%) (9590/10368)
Epoch: 99 | Batch_idx: 90 |  Loss: (0.2193) |  Loss2: (0.0000) | Acc: (92.00%) (10765/11648)
Epoch: 99 | Batch_idx: 100 |  Loss: (0.2173) |  Loss2: (0.0000) | Acc: (92.00%) (11947/12928)
Epoch: 99 | Batch_idx: 110 |  Loss: (0.2168) |  Loss2: (0.0000) | Acc: (92.00%) (13125/14208)
Epoch: 99 | Batch_idx: 120 |  Loss: (0.2176) |  Loss2: (0.0000) | Acc: (92.00%) (14300/15488)
Epoch: 99 | Batch_idx: 130 |  Loss: (0.2183) |  Loss2: (0.0000) | Acc: (92.00%) (15483/16768)
Epoch: 99 | Batch_idx: 140 |  Loss: (0.2183) |  Loss2: (0.0000) | Acc: (92.00%) (16666/18048)
Epoch: 99 | Batch_idx: 150 |  Loss: (0.2178) |  Loss2: (0.0000) | Acc: (92.00%) (17852/19328)
Epoch: 99 | Batch_idx: 160 |  Loss: (0.2171) |  Loss2: (0.0000) | Acc: (92.00%) (19042/20608)
Epoch: 99 | Batch_idx: 170 |  Loss: (0.2184) |  Loss2: (0.0000) | Acc: (92.00%) (20219/21888)
Epoch: 99 | Batch_idx: 180 |  Loss: (0.2191) |  Loss2: (0.0000) | Acc: (92.00%) (21392/23168)
Epoch: 99 | Batch_idx: 190 |  Loss: (0.2196) |  Loss2: (0.0000) | Acc: (92.00%) (22569/24448)
Epoch: 99 | Batch_idx: 200 |  Loss: (0.2192) |  Loss2: (0.0000) | Acc: (92.00%) (23755/25728)
Epoch: 99 | Batch_idx: 210 |  Loss: (0.2193) |  Loss2: (0.0000) | Acc: (92.00%) (24929/27008)
Epoch: 99 | Batch_idx: 220 |  Loss: (0.2199) |  Loss2: (0.0000) | Acc: (92.00%) (26101/28288)
Epoch: 99 | Batch_idx: 230 |  Loss: (0.2204) |  Loss2: (0.0000) | Acc: (92.00%) (27270/29568)
Epoch: 99 | Batch_idx: 240 |  Loss: (0.2197) |  Loss2: (0.0000) | Acc: (92.00%) (28467/30848)
Epoch: 99 | Batch_idx: 250 |  Loss: (0.2203) |  Loss2: (0.0000) | Acc: (92.00%) (29646/32128)
Epoch: 99 | Batch_idx: 260 |  Loss: (0.2199) |  Loss2: (0.0000) | Acc: (92.00%) (30835/33408)
Epoch: 99 | Batch_idx: 270 |  Loss: (0.2202) |  Loss2: (0.0000) | Acc: (92.00%) (32013/34688)
Epoch: 99 | Batch_idx: 280 |  Loss: (0.2192) |  Loss2: (0.0000) | Acc: (92.00%) (33214/35968)
Epoch: 99 | Batch_idx: 290 |  Loss: (0.2185) |  Loss2: (0.0000) | Acc: (92.00%) (34404/37248)
Epoch: 99 | Batch_idx: 300 |  Loss: (0.2192) |  Loss2: (0.0000) | Acc: (92.00%) (35577/38528)
Epoch: 99 | Batch_idx: 310 |  Loss: (0.2192) |  Loss2: (0.0000) | Acc: (92.00%) (36759/39808)
Epoch: 99 | Batch_idx: 320 |  Loss: (0.2193) |  Loss2: (0.0000) | Acc: (92.00%) (37942/41088)
Epoch: 99 | Batch_idx: 330 |  Loss: (0.2190) |  Loss2: (0.0000) | Acc: (92.00%) (39135/42368)
Epoch: 99 | Batch_idx: 340 |  Loss: (0.2196) |  Loss2: (0.0000) | Acc: (92.00%) (40305/43648)
Epoch: 99 | Batch_idx: 350 |  Loss: (0.2211) |  Loss2: (0.0000) | Acc: (92.00%) (41464/44928)
Epoch: 99 | Batch_idx: 360 |  Loss: (0.2219) |  Loss2: (0.0000) | Acc: (92.00%) (42631/46208)
Epoch: 99 | Batch_idx: 370 |  Loss: (0.2224) |  Loss2: (0.0000) | Acc: (92.00%) (43808/47488)
Epoch: 99 | Batch_idx: 380 |  Loss: (0.2227) |  Loss2: (0.0000) | Acc: (92.00%) (44982/48768)
Epoch: 99 | Batch_idx: 390 |  Loss: (0.2230) |  Loss2: (0.0000) | Acc: (92.00%) (46108/50000)
# TEST : Loss: (0.3908) | Acc: (87.00%) (8709/10000)
percent tensor([0.5160, 0.5174, 0.5144, 0.5182, 0.5163, 0.5229, 0.5173, 0.5173, 0.5156,
        0.5154, 0.5163, 0.5145, 0.5155, 0.5186, 0.5187, 0.5183],
       device='cuda:0') torch.Size([16])
percent tensor([0.5075, 0.5063, 0.5070, 0.5096, 0.5064, 0.5146, 0.5027, 0.5040, 0.5062,
        0.5057, 0.5062, 0.5095, 0.5114, 0.5033, 0.5097, 0.5111],
       device='cuda:0') torch.Size([16])
percent tensor([0.5651, 0.5277, 0.6068, 0.6320, 0.6177, 0.6135, 0.5656, 0.6060, 0.5993,
        0.5487, 0.5864, 0.5600, 0.4901, 0.6303, 0.5633, 0.5725],
       device='cuda:0') torch.Size([16])
percent tensor([0.6112, 0.6196, 0.6076, 0.6094, 0.6140, 0.5954, 0.6230, 0.6219, 0.6242,
        0.6206, 0.6244, 0.6255, 0.6196, 0.6213, 0.6231, 0.6081],
       device='cuda:0') torch.Size([16])
percent tensor([0.5925, 0.5904, 0.6206, 0.6402, 0.6573, 0.6783, 0.5891, 0.6109, 0.6070,
        0.6134, 0.5826, 0.6046, 0.5980, 0.6155, 0.5790, 0.6458],
       device='cuda:0') torch.Size([16])
percent tensor([0.5974, 0.6350, 0.5998, 0.6355, 0.6108, 0.7014, 0.6170, 0.5211, 0.6498,
        0.6221, 0.6883, 0.6145, 0.6670, 0.6671, 0.5627, 0.6310],
       device='cuda:0') torch.Size([16])
percent tensor([0.6429, 0.6213, 0.6358, 0.6527, 0.6733, 0.6784, 0.6576, 0.6333, 0.6300,
        0.6264, 0.6406, 0.5915, 0.6373, 0.6277, 0.5863, 0.6739],
       device='cuda:0') torch.Size([16])
percent tensor([0.9997, 0.9991, 0.9992, 0.9994, 0.9994, 0.9985, 0.9990, 0.9996, 0.9998,
        0.9992, 0.9997, 0.9991, 0.9997, 0.9995, 0.9986, 0.9994],
       device='cuda:0') torch.Size([16])
Epoch: 100 | Batch_idx: 0 |  Loss: (0.1308) |  Loss2: (0.0000) | Acc: (95.00%) (122/128)
Epoch: 100 | Batch_idx: 10 |  Loss: (0.2070) |  Loss2: (0.0000) | Acc: (92.00%) (1303/1408)
Epoch: 100 | Batch_idx: 20 |  Loss: (0.2196) |  Loss2: (0.0000) | Acc: (92.00%) (2476/2688)
Epoch: 100 | Batch_idx: 30 |  Loss: (0.2177) |  Loss2: (0.0000) | Acc: (92.00%) (3654/3968)
Epoch: 100 | Batch_idx: 40 |  Loss: (0.2192) |  Loss2: (0.0000) | Acc: (92.00%) (4835/5248)
Epoch: 100 | Batch_idx: 50 |  Loss: (0.2193) |  Loss2: (0.0000) | Acc: (92.00%) (6017/6528)
Epoch: 100 | Batch_idx: 60 |  Loss: (0.2179) |  Loss2: (0.0000) | Acc: (92.00%) (7203/7808)
Epoch: 100 | Batch_idx: 70 |  Loss: (0.2203) |  Loss2: (0.0000) | Acc: (92.00%) (8374/9088)
Epoch: 100 | Batch_idx: 80 |  Loss: (0.2198) |  Loss2: (0.0000) | Acc: (92.00%) (9569/10368)
Epoch: 100 | Batch_idx: 90 |  Loss: (0.2219) |  Loss2: (0.0000) | Acc: (92.00%) (10744/11648)
Epoch: 100 | Batch_idx: 100 |  Loss: (0.2222) |  Loss2: (0.0000) | Acc: (92.00%) (11930/12928)
Epoch: 100 | Batch_idx: 110 |  Loss: (0.2221) |  Loss2: (0.0000) | Acc: (92.00%) (13112/14208)
Epoch: 100 | Batch_idx: 120 |  Loss: (0.2204) |  Loss2: (0.0000) | Acc: (92.00%) (14301/15488)
Epoch: 100 | Batch_idx: 130 |  Loss: (0.2214) |  Loss2: (0.0000) | Acc: (92.00%) (15474/16768)
Epoch: 100 | Batch_idx: 140 |  Loss: (0.2215) |  Loss2: (0.0000) | Acc: (92.00%) (16650/18048)
Epoch: 100 | Batch_idx: 150 |  Loss: (0.2204) |  Loss2: (0.0000) | Acc: (92.00%) (17838/19328)
Epoch: 100 | Batch_idx: 160 |  Loss: (0.2193) |  Loss2: (0.0000) | Acc: (92.00%) (19029/20608)
Epoch: 100 | Batch_idx: 170 |  Loss: (0.2199) |  Loss2: (0.0000) | Acc: (92.00%) (20209/21888)
Epoch: 100 | Batch_idx: 180 |  Loss: (0.2201) |  Loss2: (0.0000) | Acc: (92.00%) (21398/23168)
Epoch: 100 | Batch_idx: 190 |  Loss: (0.2214) |  Loss2: (0.0000) | Acc: (92.00%) (22556/24448)
Epoch: 100 | Batch_idx: 200 |  Loss: (0.2214) |  Loss2: (0.0000) | Acc: (92.00%) (23736/25728)
Epoch: 100 | Batch_idx: 210 |  Loss: (0.2221) |  Loss2: (0.0000) | Acc: (92.00%) (24915/27008)
Epoch: 100 | Batch_idx: 220 |  Loss: (0.2211) |  Loss2: (0.0000) | Acc: (92.00%) (26099/28288)
Epoch: 100 | Batch_idx: 230 |  Loss: (0.2213) |  Loss2: (0.0000) | Acc: (92.00%) (27275/29568)
Epoch: 100 | Batch_idx: 240 |  Loss: (0.2211) |  Loss2: (0.0000) | Acc: (92.00%) (28463/30848)
Epoch: 100 | Batch_idx: 250 |  Loss: (0.2219) |  Loss2: (0.0000) | Acc: (92.00%) (29626/32128)
Epoch: 100 | Batch_idx: 260 |  Loss: (0.2214) |  Loss2: (0.0000) | Acc: (92.00%) (30817/33408)
Epoch: 100 | Batch_idx: 270 |  Loss: (0.2212) |  Loss2: (0.0000) | Acc: (92.00%) (32003/34688)
Epoch: 100 | Batch_idx: 280 |  Loss: (0.2207) |  Loss2: (0.0000) | Acc: (92.00%) (33201/35968)
Epoch: 100 | Batch_idx: 290 |  Loss: (0.2202) |  Loss2: (0.0000) | Acc: (92.00%) (34394/37248)
Epoch: 100 | Batch_idx: 300 |  Loss: (0.2206) |  Loss2: (0.0000) | Acc: (92.00%) (35576/38528)
Epoch: 100 | Batch_idx: 310 |  Loss: (0.2200) |  Loss2: (0.0000) | Acc: (92.00%) (36771/39808)
Epoch: 100 | Batch_idx: 320 |  Loss: (0.2202) |  Loss2: (0.0000) | Acc: (92.00%) (37955/41088)
Epoch: 100 | Batch_idx: 330 |  Loss: (0.2204) |  Loss2: (0.0000) | Acc: (92.00%) (39125/42368)
Epoch: 100 | Batch_idx: 340 |  Loss: (0.2206) |  Loss2: (0.0000) | Acc: (92.00%) (40298/43648)
Epoch: 100 | Batch_idx: 350 |  Loss: (0.2214) |  Loss2: (0.0000) | Acc: (92.00%) (41469/44928)
Epoch: 100 | Batch_idx: 360 |  Loss: (0.2214) |  Loss2: (0.0000) | Acc: (92.00%) (42661/46208)
Epoch: 100 | Batch_idx: 370 |  Loss: (0.2211) |  Loss2: (0.0000) | Acc: (92.00%) (43841/47488)
Epoch: 100 | Batch_idx: 380 |  Loss: (0.2208) |  Loss2: (0.0000) | Acc: (92.00%) (45025/48768)
Epoch: 100 | Batch_idx: 390 |  Loss: (0.2204) |  Loss2: (0.0000) | Acc: (92.00%) (46176/50000)
=> saving checkpoint 'drive/app/torch/save_Schedule/checkpoint_100.pth.tar'
# TEST : Loss: (0.4318) | Acc: (85.00%) (8592/10000)
percent tensor([0.5166, 0.5168, 0.5146, 0.5182, 0.5167, 0.5234, 0.5172, 0.5171, 0.5162,
        0.5152, 0.5166, 0.5144, 0.5159, 0.5179, 0.5188, 0.5184],
       device='cuda:0') torch.Size([16])
percent tensor([0.5070, 0.5058, 0.5093, 0.5110, 0.5066, 0.5139, 0.5022, 0.5046, 0.5047,
        0.5060, 0.5048, 0.5109, 0.5102, 0.5018, 0.5089, 0.5100],
       device='cuda:0') torch.Size([16])
percent tensor([0.5617, 0.5163, 0.6107, 0.6316, 0.6245, 0.5982, 0.5611, 0.6091, 0.5883,
        0.5474, 0.5678, 0.5648, 0.4847, 0.6043, 0.5590, 0.5602],
       device='cuda:0') torch.Size([16])
percent tensor([0.6150, 0.6236, 0.6122, 0.6111, 0.6173, 0.5974, 0.6261, 0.6234, 0.6254,
        0.6234, 0.6275, 0.6281, 0.6197, 0.6210, 0.6253, 0.6102],
       device='cuda:0') torch.Size([16])
percent tensor([0.5889, 0.5607, 0.6531, 0.6446, 0.6601, 0.6683, 0.5649, 0.6044, 0.5959,
        0.6015, 0.5569, 0.6107, 0.5905, 0.5865, 0.5666, 0.6251],
       device='cuda:0') torch.Size([16])
percent tensor([0.5854, 0.6182, 0.6141, 0.6352, 0.6000, 0.6957, 0.5996, 0.5097, 0.6464,
        0.6021, 0.6724, 0.6232, 0.6572, 0.6481, 0.5453, 0.6161],
       device='cuda:0') torch.Size([16])
percent tensor([0.6452, 0.6183, 0.6401, 0.6674, 0.6611, 0.6852, 0.6394, 0.6223, 0.6213,
        0.6144, 0.6348, 0.5910, 0.6383, 0.6153, 0.5788, 0.6600],
       device='cuda:0') torch.Size([16])
percent tensor([0.9997, 0.9996, 0.9994, 0.9995, 0.9994, 0.9976, 0.9993, 0.9994, 0.9997,
        0.9996, 0.9998, 0.9996, 0.9998, 0.9994, 0.9983, 0.9994],
       device='cuda:0') torch.Size([16])
Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 3, 3, 3]) tensor(177.3132, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(819.7925, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(812.6871, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([128, 64, 3, 3]) tensor(1521.8553, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([128, 64, 1, 1]) tensor(495.0552, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([128, 128, 3, 3]) tensor(2245.1929, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([256, 128, 3, 3]) tensor(4281.7451, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([256, 128, 1, 1]) tensor(1395.1289, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([256, 256, 3, 3]) tensor(6168.3062, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([512, 256, 3, 3]) tensor(11862.2109, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([512, 256, 1, 1]) tensor(3933.4478, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([512, 512, 3, 3]) tensor(16647.1934, device='cuda:0', grad_fn=<NormBackward0>)
Epoch: 101 | Batch_idx: 0 |  Loss: (0.1827) |  Loss2: (0.0000) | Acc: (95.00%) (122/128)
Epoch: 101 | Batch_idx: 10 |  Loss: (0.2016) |  Loss2: (0.0000) | Acc: (92.00%) (1304/1408)
Epoch: 101 | Batch_idx: 20 |  Loss: (0.1877) |  Loss2: (0.0000) | Acc: (93.00%) (2512/2688)
Epoch: 101 | Batch_idx: 30 |  Loss: (0.1921) |  Loss2: (0.0000) | Acc: (93.00%) (3708/3968)
Epoch: 101 | Batch_idx: 40 |  Loss: (0.1967) |  Loss2: (0.0000) | Acc: (93.00%) (4902/5248)
Epoch: 101 | Batch_idx: 50 |  Loss: (0.2003) |  Loss2: (0.0000) | Acc: (93.00%) (6088/6528)
Epoch: 101 | Batch_idx: 60 |  Loss: (0.1980) |  Loss2: (0.0000) | Acc: (93.00%) (7282/7808)
Epoch: 101 | Batch_idx: 70 |  Loss: (0.2046) |  Loss2: (0.0000) | Acc: (93.00%) (8466/9088)
Epoch: 101 | Batch_idx: 80 |  Loss: (0.2065) |  Loss2: (0.0000) | Acc: (93.00%) (9644/10368)
Epoch: 101 | Batch_idx: 90 |  Loss: (0.2056) |  Loss2: (0.0000) | Acc: (93.00%) (10840/11648)
Epoch: 101 | Batch_idx: 100 |  Loss: (0.2069) |  Loss2: (0.0000) | Acc: (92.00%) (12011/12928)
Epoch: 101 | Batch_idx: 110 |  Loss: (0.2071) |  Loss2: (0.0000) | Acc: (92.00%) (13199/14208)
Epoch: 101 | Batch_idx: 120 |  Loss: (0.2064) |  Loss2: (0.0000) | Acc: (92.00%) (14391/15488)
Epoch: 101 | Batch_idx: 130 |  Loss: (0.2078) |  Loss2: (0.0000) | Acc: (92.00%) (15574/16768)
Epoch: 101 | Batch_idx: 140 |  Loss: (0.2058) |  Loss2: (0.0000) | Acc: (92.00%) (16776/18048)
Epoch: 101 | Batch_idx: 150 |  Loss: (0.2062) |  Loss2: (0.0000) | Acc: (92.00%) (17958/19328)
Epoch: 101 | Batch_idx: 160 |  Loss: (0.2065) |  Loss2: (0.0000) | Acc: (92.00%) (19149/20608)
Epoch: 101 | Batch_idx: 170 |  Loss: (0.2059) |  Loss2: (0.0000) | Acc: (92.00%) (20332/21888)
Epoch: 101 | Batch_idx: 180 |  Loss: (0.2059) |  Loss2: (0.0000) | Acc: (92.00%) (21520/23168)
Epoch: 101 | Batch_idx: 190 |  Loss: (0.2054) |  Loss2: (0.0000) | Acc: (92.00%) (22715/24448)
Epoch: 101 | Batch_idx: 200 |  Loss: (0.2053) |  Loss2: (0.0000) | Acc: (92.00%) (23910/25728)
Epoch: 101 | Batch_idx: 210 |  Loss: (0.2065) |  Loss2: (0.0000) | Acc: (92.00%) (25089/27008)
Epoch: 101 | Batch_idx: 220 |  Loss: (0.2058) |  Loss2: (0.0000) | Acc: (92.00%) (26285/28288)
Epoch: 101 | Batch_idx: 230 |  Loss: (0.2053) |  Loss2: (0.0000) | Acc: (92.00%) (27477/29568)
Epoch: 101 | Batch_idx: 240 |  Loss: (0.2057) |  Loss2: (0.0000) | Acc: (92.00%) (28660/30848)
Epoch: 101 | Batch_idx: 250 |  Loss: (0.2067) |  Loss2: (0.0000) | Acc: (92.00%) (29844/32128)
Epoch: 101 | Batch_idx: 260 |  Loss: (0.2076) |  Loss2: (0.0000) | Acc: (92.00%) (31026/33408)
Epoch: 101 | Batch_idx: 270 |  Loss: (0.2086) |  Loss2: (0.0000) | Acc: (92.00%) (32198/34688)
Epoch: 101 | Batch_idx: 280 |  Loss: (0.2098) |  Loss2: (0.0000) | Acc: (92.00%) (33368/35968)
Epoch: 101 | Batch_idx: 290 |  Loss: (0.2099) |  Loss2: (0.0000) | Acc: (92.00%) (34560/37248)
Epoch: 101 | Batch_idx: 300 |  Loss: (0.2097) |  Loss2: (0.0000) | Acc: (92.00%) (35755/38528)
Epoch: 101 | Batch_idx: 310 |  Loss: (0.2099) |  Loss2: (0.0000) | Acc: (92.00%) (36947/39808)
Epoch: 101 | Batch_idx: 320 |  Loss: (0.2102) |  Loss2: (0.0000) | Acc: (92.00%) (38127/41088)
Epoch: 101 | Batch_idx: 330 |  Loss: (0.2103) |  Loss2: (0.0000) | Acc: (92.00%) (39308/42368)
Epoch: 101 | Batch_idx: 340 |  Loss: (0.2108) |  Loss2: (0.0000) | Acc: (92.00%) (40481/43648)
Epoch: 101 | Batch_idx: 350 |  Loss: (0.2114) |  Loss2: (0.0000) | Acc: (92.00%) (41650/44928)
Epoch: 101 | Batch_idx: 360 |  Loss: (0.2114) |  Loss2: (0.0000) | Acc: (92.00%) (42835/46208)
Epoch: 101 | Batch_idx: 370 |  Loss: (0.2121) |  Loss2: (0.0000) | Acc: (92.00%) (44007/47488)
Epoch: 101 | Batch_idx: 380 |  Loss: (0.2121) |  Loss2: (0.0000) | Acc: (92.00%) (45197/48768)
Epoch: 101 | Batch_idx: 390 |  Loss: (0.2118) |  Loss2: (0.0000) | Acc: (92.00%) (46337/50000)
# TEST : Loss: (0.4208) | Acc: (86.00%) (8668/10000)
percent tensor([0.5163, 0.5166, 0.5160, 0.5187, 0.5176, 0.5230, 0.5171, 0.5178, 0.5160,
        0.5154, 0.5162, 0.5157, 0.5156, 0.5171, 0.5187, 0.5180],
       device='cuda:0') torch.Size([16])
percent tensor([0.5087, 0.5068, 0.5067, 0.5102, 0.5060, 0.5159, 0.5035, 0.5039, 0.5068,
        0.5058, 0.5068, 0.5094, 0.5122, 0.5042, 0.5099, 0.5114],
       device='cuda:0') torch.Size([16])
percent tensor([0.5649, 0.5321, 0.6087, 0.6338, 0.6229, 0.6016, 0.5754, 0.6092, 0.5998,
        0.5598, 0.5894, 0.5731, 0.4922, 0.6298, 0.5676, 0.5732],
       device='cuda:0') torch.Size([16])
percent tensor([0.6126, 0.6170, 0.6067, 0.6094, 0.6129, 0.5931, 0.6219, 0.6208, 0.6237,
        0.6177, 0.6254, 0.6252, 0.6173, 0.6198, 0.6215, 0.6068],
       device='cuda:0') torch.Size([16])
percent tensor([0.5950, 0.5829, 0.6439, 0.6425, 0.6586, 0.6901, 0.5904, 0.6144, 0.6119,
        0.6120, 0.5828, 0.6140, 0.5972, 0.6217, 0.5751, 0.6426],
       device='cuda:0') torch.Size([16])
percent tensor([0.5873, 0.6382, 0.6111, 0.6330, 0.5980, 0.6964, 0.6165, 0.5238, 0.6481,
        0.6216, 0.6846, 0.6218, 0.6669, 0.6571, 0.5608, 0.6264],
       device='cuda:0') torch.Size([16])
percent tensor([0.6473, 0.6273, 0.6385, 0.6564, 0.6640, 0.6899, 0.6582, 0.6435, 0.6224,
        0.6195, 0.6356, 0.5910, 0.6381, 0.6212, 0.5911, 0.6769],
       device='cuda:0') torch.Size([16])
percent tensor([0.9998, 0.9993, 0.9993, 0.9994, 0.9995, 0.9973, 0.9989, 0.9997, 0.9996,
        0.9992, 0.9995, 0.9989, 0.9997, 0.9993, 0.9982, 0.9996],
       device='cuda:0') torch.Size([16])
False Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=128, out_features=16, bias=False)
True Linear(in_features=16, out_features=2, bias=False)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=128, out_features=16, bias=False)
True Linear(in_features=16, out_features=2, bias=False)
False Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=256, out_features=32, bias=False)
True Linear(in_features=32, out_features=2, bias=False)
False Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=256, out_features=32, bias=False)
True Linear(in_features=32, out_features=2, bias=False)
False Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=512, out_features=64, bias=False)
True Linear(in_features=64, out_features=2, bias=False)
False Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=512, out_features=64, bias=False)
True Linear(in_features=64, out_features=2, bias=False)
False Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1024, out_features=128, bias=False)
True Linear(in_features=128, out_features=2, bias=False)
False Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1024, out_features=128, bias=False)
True Linear(in_features=128, out_features=2, bias=False)
False Linear(in_features=512, out_features=10, bias=True)
Epoch: 102 | Batch_idx: 0 |  Loss: (0.2261) |  Loss2: (0.0000) | Acc: (94.00%) (121/128)
Epoch: 102 | Batch_idx: 10 |  Loss: (0.2272) |  Loss2: (0.0000) | Acc: (92.00%) (1297/1408)
Epoch: 102 | Batch_idx: 20 |  Loss: (0.2427) |  Loss2: (0.0000) | Acc: (91.00%) (2463/2688)
Epoch: 102 | Batch_idx: 30 |  Loss: (0.2439) |  Loss2: (0.0000) | Acc: (91.00%) (3631/3968)
Epoch: 102 | Batch_idx: 40 |  Loss: (0.2473) |  Loss2: (0.0000) | Acc: (91.00%) (4794/5248)
Epoch: 102 | Batch_idx: 50 |  Loss: (0.2526) |  Loss2: (0.0000) | Acc: (91.00%) (5952/6528)
Epoch: 102 | Batch_idx: 60 |  Loss: (0.2502) |  Loss2: (0.0000) | Acc: (91.00%) (7129/7808)
Epoch: 102 | Batch_idx: 70 |  Loss: (0.2557) |  Loss2: (0.0000) | Acc: (91.00%) (8282/9088)
Epoch: 102 | Batch_idx: 80 |  Loss: (0.2582) |  Loss2: (0.0000) | Acc: (90.00%) (9432/10368)
Epoch: 102 | Batch_idx: 90 |  Loss: (0.2590) |  Loss2: (0.0000) | Acc: (90.00%) (10585/11648)
Epoch: 102 | Batch_idx: 100 |  Loss: (0.2594) |  Loss2: (0.0000) | Acc: (90.00%) (11756/12928)
Epoch: 102 | Batch_idx: 110 |  Loss: (0.2591) |  Loss2: (0.0000) | Acc: (91.00%) (12932/14208)
Epoch: 102 | Batch_idx: 120 |  Loss: (0.2560) |  Loss2: (0.0000) | Acc: (91.00%) (14109/15488)
Epoch: 102 | Batch_idx: 130 |  Loss: (0.2565) |  Loss2: (0.0000) | Acc: (91.00%) (15268/16768)
Epoch: 102 | Batch_idx: 140 |  Loss: (0.2576) |  Loss2: (0.0000) | Acc: (90.00%) (16422/18048)
Epoch: 102 | Batch_idx: 150 |  Loss: (0.2561) |  Loss2: (0.0000) | Acc: (91.00%) (17598/19328)
Epoch: 102 | Batch_idx: 160 |  Loss: (0.2548) |  Loss2: (0.0000) | Acc: (91.00%) (18772/20608)
Epoch: 102 | Batch_idx: 170 |  Loss: (0.2528) |  Loss2: (0.0000) | Acc: (91.00%) (19943/21888)
Epoch: 102 | Batch_idx: 180 |  Loss: (0.2534) |  Loss2: (0.0000) | Acc: (91.00%) (21103/23168)
Epoch: 102 | Batch_idx: 190 |  Loss: (0.2537) |  Loss2: (0.0000) | Acc: (91.00%) (22266/24448)
Epoch: 102 | Batch_idx: 200 |  Loss: (0.2535) |  Loss2: (0.0000) | Acc: (91.00%) (23422/25728)
Epoch: 102 | Batch_idx: 210 |  Loss: (0.2544) |  Loss2: (0.0000) | Acc: (91.00%) (24578/27008)
Epoch: 102 | Batch_idx: 220 |  Loss: (0.2534) |  Loss2: (0.0000) | Acc: (91.00%) (25755/28288)
Epoch: 102 | Batch_idx: 230 |  Loss: (0.2528) |  Loss2: (0.0000) | Acc: (91.00%) (26932/29568)
Epoch: 102 | Batch_idx: 240 |  Loss: (0.2523) |  Loss2: (0.0000) | Acc: (91.00%) (28101/30848)
Epoch: 102 | Batch_idx: 250 |  Loss: (0.2515) |  Loss2: (0.0000) | Acc: (91.00%) (29274/32128)
Epoch: 102 | Batch_idx: 260 |  Loss: (0.2511) |  Loss2: (0.0000) | Acc: (91.00%) (30444/33408)
Epoch: 102 | Batch_idx: 270 |  Loss: (0.2499) |  Loss2: (0.0000) | Acc: (91.00%) (31628/34688)
Epoch: 102 | Batch_idx: 280 |  Loss: (0.2502) |  Loss2: (0.0000) | Acc: (91.00%) (32804/35968)
Epoch: 102 | Batch_idx: 290 |  Loss: (0.2500) |  Loss2: (0.0000) | Acc: (91.00%) (33967/37248)
Epoch: 102 | Batch_idx: 300 |  Loss: (0.2499) |  Loss2: (0.0000) | Acc: (91.00%) (35141/38528)
Epoch: 102 | Batch_idx: 310 |  Loss: (0.2484) |  Loss2: (0.0000) | Acc: (91.00%) (36325/39808)
Epoch: 102 | Batch_idx: 320 |  Loss: (0.2480) |  Loss2: (0.0000) | Acc: (91.00%) (37490/41088)
Epoch: 102 | Batch_idx: 330 |  Loss: (0.2472) |  Loss2: (0.0000) | Acc: (91.00%) (38669/42368)
Epoch: 102 | Batch_idx: 340 |  Loss: (0.2470) |  Loss2: (0.0000) | Acc: (91.00%) (39833/43648)
Epoch: 102 | Batch_idx: 350 |  Loss: (0.2466) |  Loss2: (0.0000) | Acc: (91.00%) (41003/44928)
Epoch: 102 | Batch_idx: 360 |  Loss: (0.2467) |  Loss2: (0.0000) | Acc: (91.00%) (42170/46208)
Epoch: 102 | Batch_idx: 370 |  Loss: (0.2451) |  Loss2: (0.0000) | Acc: (91.00%) (43364/47488)
Epoch: 102 | Batch_idx: 380 |  Loss: (0.2446) |  Loss2: (0.0000) | Acc: (91.00%) (44544/48768)
Epoch: 102 | Batch_idx: 390 |  Loss: (0.2437) |  Loss2: (0.0000) | Acc: (91.00%) (45685/50000)
# TEST : Loss: (0.4071) | Acc: (86.00%) (8676/10000)
percent tensor([0.5196, 0.5192, 0.5202, 0.5220, 0.5217, 0.5264, 0.5199, 0.5214, 0.5189,
        0.5183, 0.5188, 0.5193, 0.5186, 0.5186, 0.5216, 0.5208],
       device='cuda:0') torch.Size([16])
percent tensor([0.5097, 0.5079, 0.5076, 0.5116, 0.5066, 0.5163, 0.5042, 0.5038, 0.5076,
        0.5071, 0.5084, 0.5097, 0.5141, 0.5053, 0.5112, 0.5129],
       device='cuda:0') torch.Size([16])
percent tensor([0.5577, 0.5249, 0.6049, 0.6375, 0.6215, 0.5975, 0.5689, 0.6089, 0.5901,
        0.5500, 0.5796, 0.5653, 0.4808, 0.6265, 0.5633, 0.5717],
       device='cuda:0') torch.Size([16])
percent tensor([0.6180, 0.6207, 0.6105, 0.6137, 0.6149, 0.6006, 0.6244, 0.6220, 0.6261,
        0.6219, 0.6306, 0.6267, 0.6219, 0.6210, 0.6242, 0.6132],
       device='cuda:0') torch.Size([16])
percent tensor([0.5727, 0.5752, 0.5947, 0.5944, 0.6063, 0.6688, 0.5645, 0.5584, 0.5820,
        0.5990, 0.5746, 0.5761, 0.5877, 0.5993, 0.5574, 0.6163],
       device='cuda:0') torch.Size([16])
percent tensor([0.6226, 0.6636, 0.6491, 0.6769, 0.6382, 0.7221, 0.6518, 0.5803, 0.6758,
        0.6483, 0.7072, 0.6527, 0.6868, 0.6887, 0.6014, 0.6654],
       device='cuda:0') torch.Size([16])
percent tensor([0.6382, 0.6176, 0.6554, 0.6705, 0.6796, 0.7004, 0.6568, 0.6700, 0.6121,
        0.6032, 0.6192, 0.5975, 0.6165, 0.6252, 0.5901, 0.6735],
       device='cuda:0') torch.Size([16])
percent tensor([0.9998, 0.9994, 0.9995, 0.9995, 0.9994, 0.9988, 0.9991, 0.9997, 0.9997,
        0.9993, 0.9997, 0.9991, 0.9997, 0.9992, 0.9985, 0.9996],
       device='cuda:0') torch.Size([16])
Epoch: 103 | Batch_idx: 0 |  Loss: (0.1553) |  Loss2: (0.0000) | Acc: (95.00%) (122/128)
Epoch: 103 | Batch_idx: 10 |  Loss: (0.2477) |  Loss2: (0.0000) | Acc: (90.00%) (1278/1408)
Epoch: 103 | Batch_idx: 20 |  Loss: (0.2357) |  Loss2: (0.0000) | Acc: (91.00%) (2461/2688)
Epoch: 103 | Batch_idx: 30 |  Loss: (0.2355) |  Loss2: (0.0000) | Acc: (91.00%) (3637/3968)
Epoch: 103 | Batch_idx: 40 |  Loss: (0.2298) |  Loss2: (0.0000) | Acc: (91.00%) (4825/5248)
Epoch: 103 | Batch_idx: 50 |  Loss: (0.2263) |  Loss2: (0.0000) | Acc: (92.00%) (6012/6528)
Epoch: 103 | Batch_idx: 60 |  Loss: (0.2266) |  Loss2: (0.0000) | Acc: (92.00%) (7188/7808)
Epoch: 103 | Batch_idx: 70 |  Loss: (0.2250) |  Loss2: (0.0000) | Acc: (92.00%) (8373/9088)
Epoch: 103 | Batch_idx: 80 |  Loss: (0.2285) |  Loss2: (0.0000) | Acc: (91.00%) (9538/10368)
Epoch: 103 | Batch_idx: 90 |  Loss: (0.2289) |  Loss2: (0.0000) | Acc: (92.00%) (10720/11648)
Epoch: 103 | Batch_idx: 100 |  Loss: (0.2289) |  Loss2: (0.0000) | Acc: (91.00%) (11890/12928)
Epoch: 103 | Batch_idx: 110 |  Loss: (0.2278) |  Loss2: (0.0000) | Acc: (92.00%) (13078/14208)
Epoch: 103 | Batch_idx: 120 |  Loss: (0.2257) |  Loss2: (0.0000) | Acc: (92.00%) (14261/15488)
Epoch: 103 | Batch_idx: 130 |  Loss: (0.2262) |  Loss2: (0.0000) | Acc: (92.00%) (15433/16768)
Epoch: 103 | Batch_idx: 140 |  Loss: (0.2264) |  Loss2: (0.0000) | Acc: (92.00%) (16605/18048)
Epoch: 103 | Batch_idx: 150 |  Loss: (0.2251) |  Loss2: (0.0000) | Acc: (92.00%) (17793/19328)
Epoch: 103 | Batch_idx: 160 |  Loss: (0.2256) |  Loss2: (0.0000) | Acc: (92.00%) (18974/20608)
Epoch: 103 | Batch_idx: 170 |  Loss: (0.2253) |  Loss2: (0.0000) | Acc: (92.00%) (20156/21888)
Epoch: 103 | Batch_idx: 180 |  Loss: (0.2260) |  Loss2: (0.0000) | Acc: (92.00%) (21325/23168)
Epoch: 103 | Batch_idx: 190 |  Loss: (0.2268) |  Loss2: (0.0000) | Acc: (92.00%) (22499/24448)
Epoch: 103 | Batch_idx: 200 |  Loss: (0.2269) |  Loss2: (0.0000) | Acc: (92.00%) (23686/25728)
Epoch: 103 | Batch_idx: 210 |  Loss: (0.2256) |  Loss2: (0.0000) | Acc: (92.00%) (24874/27008)
Epoch: 103 | Batch_idx: 220 |  Loss: (0.2254) |  Loss2: (0.0000) | Acc: (92.00%) (26062/28288)
Epoch: 103 | Batch_idx: 230 |  Loss: (0.2254) |  Loss2: (0.0000) | Acc: (92.00%) (27246/29568)
Epoch: 103 | Batch_idx: 240 |  Loss: (0.2247) |  Loss2: (0.0000) | Acc: (92.00%) (28430/30848)
Epoch: 103 | Batch_idx: 250 |  Loss: (0.2248) |  Loss2: (0.0000) | Acc: (92.00%) (29604/32128)
Epoch: 103 | Batch_idx: 260 |  Loss: (0.2241) |  Loss2: (0.0000) | Acc: (92.00%) (30791/33408)
Epoch: 103 | Batch_idx: 270 |  Loss: (0.2228) |  Loss2: (0.0000) | Acc: (92.00%) (31984/34688)
Epoch: 103 | Batch_idx: 280 |  Loss: (0.2229) |  Loss2: (0.0000) | Acc: (92.00%) (33158/35968)
Epoch: 103 | Batch_idx: 290 |  Loss: (0.2229) |  Loss2: (0.0000) | Acc: (92.00%) (34336/37248)
Epoch: 103 | Batch_idx: 300 |  Loss: (0.2232) |  Loss2: (0.0000) | Acc: (92.00%) (35511/38528)
Epoch: 103 | Batch_idx: 310 |  Loss: (0.2237) |  Loss2: (0.0000) | Acc: (92.00%) (36675/39808)
Epoch: 103 | Batch_idx: 320 |  Loss: (0.2234) |  Loss2: (0.0000) | Acc: (92.00%) (37865/41088)
Epoch: 103 | Batch_idx: 330 |  Loss: (0.2230) |  Loss2: (0.0000) | Acc: (92.00%) (39044/42368)
Epoch: 103 | Batch_idx: 340 |  Loss: (0.2225) |  Loss2: (0.0000) | Acc: (92.00%) (40235/43648)
Epoch: 103 | Batch_idx: 350 |  Loss: (0.2213) |  Loss2: (0.0000) | Acc: (92.00%) (41432/44928)
Epoch: 103 | Batch_idx: 360 |  Loss: (0.2215) |  Loss2: (0.0000) | Acc: (92.00%) (42620/46208)
Epoch: 103 | Batch_idx: 370 |  Loss: (0.2220) |  Loss2: (0.0000) | Acc: (92.00%) (43790/47488)
Epoch: 103 | Batch_idx: 380 |  Loss: (0.2218) |  Loss2: (0.0000) | Acc: (92.00%) (44982/48768)
Epoch: 103 | Batch_idx: 390 |  Loss: (0.2211) |  Loss2: (0.0000) | Acc: (92.00%) (46129/50000)
# TEST : Loss: (0.3850) | Acc: (87.00%) (8736/10000)
percent tensor([0.5206, 0.5207, 0.5211, 0.5230, 0.5228, 0.5277, 0.5213, 0.5226, 0.5201,
        0.5194, 0.5201, 0.5203, 0.5197, 0.5202, 0.5230, 0.5220],
       device='cuda:0') torch.Size([16])
percent tensor([0.5105, 0.5100, 0.5079, 0.5125, 0.5070, 0.5166, 0.5057, 0.5042, 0.5090,
        0.5088, 0.5104, 0.5105, 0.5155, 0.5072, 0.5128, 0.5142],
       device='cuda:0') torch.Size([16])
percent tensor([0.5618, 0.5233, 0.6078, 0.6406, 0.6245, 0.6001, 0.5693, 0.6104, 0.5922,
        0.5517, 0.5806, 0.5683, 0.4828, 0.6243, 0.5634, 0.5753],
       device='cuda:0') torch.Size([16])
percent tensor([0.6174, 0.6202, 0.6088, 0.6122, 0.6131, 0.6031, 0.6229, 0.6193, 0.6245,
        0.6220, 0.6304, 0.6250, 0.6210, 0.6200, 0.6234, 0.6146],
       device='cuda:0') torch.Size([16])
percent tensor([0.5824, 0.5902, 0.5896, 0.5921, 0.6025, 0.6755, 0.5725, 0.5547, 0.5905,
        0.6118, 0.5924, 0.5786, 0.6001, 0.6099, 0.5700, 0.6273],
       device='cuda:0') torch.Size([16])
percent tensor([0.6197, 0.6565, 0.6541, 0.6815, 0.6428, 0.7181, 0.6496, 0.5857, 0.6741,
        0.6427, 0.7036, 0.6508, 0.6817, 0.6869, 0.5946, 0.6610],
       device='cuda:0') torch.Size([16])
percent tensor([0.6351, 0.6146, 0.6632, 0.6794, 0.6862, 0.6984, 0.6562, 0.6814, 0.6106,
        0.5995, 0.6138, 0.6003, 0.6134, 0.6225, 0.5886, 0.6722],
       device='cuda:0') torch.Size([16])
percent tensor([0.9998, 0.9994, 0.9994, 0.9995, 0.9994, 0.9987, 0.9992, 0.9997, 0.9997,
        0.9994, 0.9997, 0.9991, 0.9997, 0.9993, 0.9986, 0.9997],
       device='cuda:0') torch.Size([16])
Epoch: 104 | Batch_idx: 0 |  Loss: (0.1539) |  Loss2: (0.0000) | Acc: (95.00%) (122/128)
Epoch: 104 | Batch_idx: 10 |  Loss: (0.2057) |  Loss2: (0.0000) | Acc: (93.00%) (1314/1408)
Epoch: 104 | Batch_idx: 20 |  Loss: (0.2255) |  Loss2: (0.0000) | Acc: (92.00%) (2481/2688)
Epoch: 104 | Batch_idx: 30 |  Loss: (0.2225) |  Loss2: (0.0000) | Acc: (92.00%) (3663/3968)
Epoch: 104 | Batch_idx: 40 |  Loss: (0.2172) |  Loss2: (0.0000) | Acc: (92.00%) (4840/5248)
Epoch: 104 | Batch_idx: 50 |  Loss: (0.2173) |  Loss2: (0.0000) | Acc: (92.00%) (6017/6528)
Epoch: 104 | Batch_idx: 60 |  Loss: (0.2176) |  Loss2: (0.0000) | Acc: (92.00%) (7200/7808)
Epoch: 104 | Batch_idx: 70 |  Loss: (0.2159) |  Loss2: (0.0000) | Acc: (92.00%) (8385/9088)
Epoch: 104 | Batch_idx: 80 |  Loss: (0.2159) |  Loss2: (0.0000) | Acc: (92.00%) (9574/10368)
Epoch: 104 | Batch_idx: 90 |  Loss: (0.2146) |  Loss2: (0.0000) | Acc: (92.00%) (10754/11648)
Epoch: 104 | Batch_idx: 100 |  Loss: (0.2117) |  Loss2: (0.0000) | Acc: (92.00%) (11957/12928)
Epoch: 104 | Batch_idx: 110 |  Loss: (0.2105) |  Loss2: (0.0000) | Acc: (92.00%) (13151/14208)
Epoch: 104 | Batch_idx: 120 |  Loss: (0.2124) |  Loss2: (0.0000) | Acc: (92.00%) (14328/15488)
Epoch: 104 | Batch_idx: 130 |  Loss: (0.2108) |  Loss2: (0.0000) | Acc: (92.00%) (15533/16768)
Epoch: 104 | Batch_idx: 140 |  Loss: (0.2105) |  Loss2: (0.0000) | Acc: (92.00%) (16723/18048)
Epoch: 104 | Batch_idx: 150 |  Loss: (0.2090) |  Loss2: (0.0000) | Acc: (92.00%) (17920/19328)
Epoch: 104 | Batch_idx: 160 |  Loss: (0.2097) |  Loss2: (0.0000) | Acc: (92.00%) (19109/20608)
Epoch: 104 | Batch_idx: 170 |  Loss: (0.2095) |  Loss2: (0.0000) | Acc: (92.00%) (20300/21888)
Epoch: 104 | Batch_idx: 180 |  Loss: (0.2103) |  Loss2: (0.0000) | Acc: (92.00%) (21472/23168)
Epoch: 104 | Batch_idx: 190 |  Loss: (0.2102) |  Loss2: (0.0000) | Acc: (92.00%) (22648/24448)
Epoch: 104 | Batch_idx: 200 |  Loss: (0.2117) |  Loss2: (0.0000) | Acc: (92.00%) (23821/25728)
Epoch: 104 | Batch_idx: 210 |  Loss: (0.2104) |  Loss2: (0.0000) | Acc: (92.00%) (25012/27008)
Epoch: 104 | Batch_idx: 220 |  Loss: (0.2110) |  Loss2: (0.0000) | Acc: (92.00%) (26194/28288)
Epoch: 104 | Batch_idx: 230 |  Loss: (0.2100) |  Loss2: (0.0000) | Acc: (92.00%) (27397/29568)
Epoch: 104 | Batch_idx: 240 |  Loss: (0.2092) |  Loss2: (0.0000) | Acc: (92.00%) (28592/30848)
Epoch: 104 | Batch_idx: 250 |  Loss: (0.2095) |  Loss2: (0.0000) | Acc: (92.00%) (29772/32128)
Epoch: 104 | Batch_idx: 260 |  Loss: (0.2096) |  Loss2: (0.0000) | Acc: (92.00%) (30960/33408)
Epoch: 104 | Batch_idx: 270 |  Loss: (0.2090) |  Loss2: (0.0000) | Acc: (92.00%) (32157/34688)
Epoch: 104 | Batch_idx: 280 |  Loss: (0.2093) |  Loss2: (0.0000) | Acc: (92.00%) (33347/35968)
Epoch: 104 | Batch_idx: 290 |  Loss: (0.2098) |  Loss2: (0.0000) | Acc: (92.00%) (34527/37248)
Epoch: 104 | Batch_idx: 300 |  Loss: (0.2102) |  Loss2: (0.0000) | Acc: (92.00%) (35715/38528)
Epoch: 104 | Batch_idx: 310 |  Loss: (0.2100) |  Loss2: (0.0000) | Acc: (92.00%) (36903/39808)
Epoch: 104 | Batch_idx: 320 |  Loss: (0.2099) |  Loss2: (0.0000) | Acc: (92.00%) (38087/41088)
Epoch: 104 | Batch_idx: 330 |  Loss: (0.2108) |  Loss2: (0.0000) | Acc: (92.00%) (39256/42368)
Epoch: 104 | Batch_idx: 340 |  Loss: (0.2104) |  Loss2: (0.0000) | Acc: (92.00%) (40443/43648)
Epoch: 104 | Batch_idx: 350 |  Loss: (0.2096) |  Loss2: (0.0000) | Acc: (92.00%) (41636/44928)
Epoch: 104 | Batch_idx: 360 |  Loss: (0.2099) |  Loss2: (0.0000) | Acc: (92.00%) (42819/46208)
Epoch: 104 | Batch_idx: 370 |  Loss: (0.2098) |  Loss2: (0.0000) | Acc: (92.00%) (44009/47488)
Epoch: 104 | Batch_idx: 380 |  Loss: (0.2102) |  Loss2: (0.0000) | Acc: (92.00%) (45193/48768)
Epoch: 104 | Batch_idx: 390 |  Loss: (0.2103) |  Loss2: (0.0000) | Acc: (92.00%) (46337/50000)
# TEST : Loss: (0.3775) | Acc: (87.00%) (8738/10000)
percent tensor([0.5222, 0.5227, 0.5225, 0.5245, 0.5244, 0.5295, 0.5232, 0.5243, 0.5217,
        0.5211, 0.5219, 0.5217, 0.5214, 0.5220, 0.5249, 0.5237],
       device='cuda:0') torch.Size([16])
percent tensor([0.5113, 0.5116, 0.5083, 0.5133, 0.5075, 0.5171, 0.5070, 0.5048, 0.5102,
        0.5101, 0.5118, 0.5113, 0.5163, 0.5088, 0.5140, 0.5149],
       device='cuda:0') torch.Size([16])
percent tensor([0.5648, 0.5245, 0.6092, 0.6407, 0.6263, 0.6006, 0.5724, 0.6114, 0.5947,
        0.5545, 0.5823, 0.5706, 0.4855, 0.6231, 0.5642, 0.5769],
       device='cuda:0') torch.Size([16])
percent tensor([0.6165, 0.6184, 0.6074, 0.6108, 0.6115, 0.6043, 0.6209, 0.6167, 0.6225,
        0.6206, 0.6288, 0.6227, 0.6196, 0.6180, 0.6217, 0.6149],
       device='cuda:0') torch.Size([16])
percent tensor([0.5753, 0.5818, 0.5850, 0.5929, 0.5980, 0.6779, 0.5650, 0.5483, 0.5836,
        0.6031, 0.5836, 0.5741, 0.5934, 0.6041, 0.5642, 0.6241],
       device='cuda:0') torch.Size([16])
percent tensor([0.6222, 0.6567, 0.6593, 0.6876, 0.6463, 0.7196, 0.6513, 0.5902, 0.6773,
        0.6437, 0.7052, 0.6554, 0.6847, 0.6903, 0.5954, 0.6609],
       device='cuda:0') torch.Size([16])
percent tensor([0.6289, 0.6123, 0.6620, 0.6779, 0.6821, 0.6934, 0.6510, 0.6781, 0.6097,
        0.5962, 0.6099, 0.5988, 0.6133, 0.6183, 0.5845, 0.6640],
       device='cuda:0') torch.Size([16])
percent tensor([0.9998, 0.9994, 0.9994, 0.9995, 0.9994, 0.9987, 0.9992, 0.9997, 0.9997,
        0.9994, 0.9997, 0.9991, 0.9997, 0.9993, 0.9987, 0.9997],
       device='cuda:0') torch.Size([16])
Epoch: 105 | Batch_idx: 0 |  Loss: (0.1146) |  Loss2: (0.0000) | Acc: (96.00%) (124/128)
Epoch: 105 | Batch_idx: 10 |  Loss: (0.1936) |  Loss2: (0.0000) | Acc: (93.00%) (1311/1408)
Epoch: 105 | Batch_idx: 20 |  Loss: (0.1998) |  Loss2: (0.0000) | Acc: (92.00%) (2498/2688)
Epoch: 105 | Batch_idx: 30 |  Loss: (0.2003) |  Loss2: (0.0000) | Acc: (92.00%) (3685/3968)
Epoch: 105 | Batch_idx: 40 |  Loss: (0.2059) |  Loss2: (0.0000) | Acc: (92.00%) (4875/5248)
Epoch: 105 | Batch_idx: 50 |  Loss: (0.2114) |  Loss2: (0.0000) | Acc: (92.00%) (6040/6528)
Epoch: 105 | Batch_idx: 60 |  Loss: (0.2092) |  Loss2: (0.0000) | Acc: (92.00%) (7233/7808)
Epoch: 105 | Batch_idx: 70 |  Loss: (0.2095) |  Loss2: (0.0000) | Acc: (92.00%) (8418/9088)
Epoch: 105 | Batch_idx: 80 |  Loss: (0.2096) |  Loss2: (0.0000) | Acc: (92.00%) (9595/10368)
Epoch: 105 | Batch_idx: 90 |  Loss: (0.2069) |  Loss2: (0.0000) | Acc: (92.00%) (10801/11648)
Epoch: 105 | Batch_idx: 100 |  Loss: (0.2051) |  Loss2: (0.0000) | Acc: (92.00%) (12002/12928)
Epoch: 105 | Batch_idx: 110 |  Loss: (0.2083) |  Loss2: (0.0000) | Acc: (92.00%) (13170/14208)
Epoch: 105 | Batch_idx: 120 |  Loss: (0.2068) |  Loss2: (0.0000) | Acc: (92.00%) (14373/15488)
Epoch: 105 | Batch_idx: 130 |  Loss: (0.2047) |  Loss2: (0.0000) | Acc: (92.00%) (15573/16768)
Epoch: 105 | Batch_idx: 140 |  Loss: (0.2058) |  Loss2: (0.0000) | Acc: (92.00%) (16748/18048)
Epoch: 105 | Batch_idx: 150 |  Loss: (0.2070) |  Loss2: (0.0000) | Acc: (92.00%) (17930/19328)
Epoch: 105 | Batch_idx: 160 |  Loss: (0.2097) |  Loss2: (0.0000) | Acc: (92.00%) (19099/20608)
Epoch: 105 | Batch_idx: 170 |  Loss: (0.2108) |  Loss2: (0.0000) | Acc: (92.00%) (20273/21888)
Epoch: 105 | Batch_idx: 180 |  Loss: (0.2107) |  Loss2: (0.0000) | Acc: (92.00%) (21463/23168)
Epoch: 105 | Batch_idx: 190 |  Loss: (0.2097) |  Loss2: (0.0000) | Acc: (92.00%) (22653/24448)
Epoch: 105 | Batch_idx: 200 |  Loss: (0.2094) |  Loss2: (0.0000) | Acc: (92.00%) (23837/25728)
Epoch: 105 | Batch_idx: 210 |  Loss: (0.2087) |  Loss2: (0.0000) | Acc: (92.00%) (25030/27008)
Epoch: 105 | Batch_idx: 220 |  Loss: (0.2087) |  Loss2: (0.0000) | Acc: (92.00%) (26221/28288)
Epoch: 105 | Batch_idx: 230 |  Loss: (0.2082) |  Loss2: (0.0000) | Acc: (92.00%) (27410/29568)
Epoch: 105 | Batch_idx: 240 |  Loss: (0.2071) |  Loss2: (0.0000) | Acc: (92.00%) (28614/30848)
Epoch: 105 | Batch_idx: 250 |  Loss: (0.2069) |  Loss2: (0.0000) | Acc: (92.00%) (29805/32128)
Epoch: 105 | Batch_idx: 260 |  Loss: (0.2064) |  Loss2: (0.0000) | Acc: (92.00%) (30997/33408)
Epoch: 105 | Batch_idx: 270 |  Loss: (0.2062) |  Loss2: (0.0000) | Acc: (92.00%) (32197/34688)
Epoch: 105 | Batch_idx: 280 |  Loss: (0.2057) |  Loss2: (0.0000) | Acc: (92.00%) (33400/35968)
Epoch: 105 | Batch_idx: 290 |  Loss: (0.2050) |  Loss2: (0.0000) | Acc: (92.00%) (34608/37248)
Epoch: 105 | Batch_idx: 300 |  Loss: (0.2044) |  Loss2: (0.0000) | Acc: (92.00%) (35801/38528)
Epoch: 105 | Batch_idx: 310 |  Loss: (0.2039) |  Loss2: (0.0000) | Acc: (92.00%) (36999/39808)
Epoch: 105 | Batch_idx: 320 |  Loss: (0.2039) |  Loss2: (0.0000) | Acc: (92.00%) (38192/41088)
Epoch: 105 | Batch_idx: 330 |  Loss: (0.2037) |  Loss2: (0.0000) | Acc: (92.00%) (39398/42368)
Epoch: 105 | Batch_idx: 340 |  Loss: (0.2037) |  Loss2: (0.0000) | Acc: (92.00%) (40590/43648)
Epoch: 105 | Batch_idx: 350 |  Loss: (0.2035) |  Loss2: (0.0000) | Acc: (92.00%) (41782/44928)
Epoch: 105 | Batch_idx: 360 |  Loss: (0.2033) |  Loss2: (0.0000) | Acc: (93.00%) (42975/46208)
Epoch: 105 | Batch_idx: 370 |  Loss: (0.2033) |  Loss2: (0.0000) | Acc: (92.00%) (44160/47488)
Epoch: 105 | Batch_idx: 380 |  Loss: (0.2030) |  Loss2: (0.0000) | Acc: (92.00%) (45351/48768)
Epoch: 105 | Batch_idx: 390 |  Loss: (0.2036) |  Loss2: (0.0000) | Acc: (92.00%) (46488/50000)
=> saving checkpoint 'drive/app/torch/save_Schedule/checkpoint_105.pth.tar'
# TEST : Loss: (0.3725) | Acc: (87.00%) (8768/10000)
percent tensor([0.5222, 0.5229, 0.5223, 0.5245, 0.5244, 0.5297, 0.5233, 0.5243, 0.5219,
        0.5210, 0.5221, 0.5216, 0.5214, 0.5223, 0.5251, 0.5239],
       device='cuda:0') torch.Size([16])
percent tensor([0.5111, 0.5119, 0.5077, 0.5130, 0.5069, 0.5169, 0.5070, 0.5043, 0.5102,
        0.5102, 0.5119, 0.5108, 0.5161, 0.5092, 0.5139, 0.5146],
       device='cuda:0') torch.Size([16])
percent tensor([0.5611, 0.5190, 0.6087, 0.6401, 0.6261, 0.5950, 0.5685, 0.6103, 0.5921,
        0.5517, 0.5794, 0.5682, 0.4814, 0.6189, 0.5581, 0.5732],
       device='cuda:0') torch.Size([16])
percent tensor([0.6227, 0.6244, 0.6131, 0.6168, 0.6172, 0.6117, 0.6269, 0.6217, 0.6286,
        0.6272, 0.6353, 0.6284, 0.6256, 0.6241, 0.6277, 0.6224],
       device='cuda:0') torch.Size([16])
percent tensor([0.5840, 0.5886, 0.5931, 0.6044, 0.6057, 0.6907, 0.5713, 0.5558, 0.5912,
        0.6096, 0.5911, 0.5830, 0.6000, 0.6131, 0.5734, 0.6345],
       device='cuda:0') torch.Size([16])
percent tensor([0.6207, 0.6551, 0.6579, 0.6860, 0.6429, 0.7170, 0.6495, 0.5884, 0.6750,
        0.6422, 0.7036, 0.6523, 0.6837, 0.6885, 0.5917, 0.6599],
       device='cuda:0') torch.Size([16])
percent tensor([0.6277, 0.6164, 0.6629, 0.6778, 0.6798, 0.6936, 0.6492, 0.6758, 0.6118,
        0.5986, 0.6110, 0.5999, 0.6173, 0.6169, 0.5853, 0.6633],
       device='cuda:0') torch.Size([16])
percent tensor([0.9998, 0.9994, 0.9994, 0.9995, 0.9995, 0.9987, 0.9992, 0.9997, 0.9997,
        0.9994, 0.9997, 0.9992, 0.9998, 0.9994, 0.9987, 0.9997],
       device='cuda:0') torch.Size([16])
Epoch: 106 | Batch_idx: 0 |  Loss: (0.3142) |  Loss2: (0.0000) | Acc: (85.00%) (110/128)
Epoch: 106 | Batch_idx: 10 |  Loss: (0.2257) |  Loss2: (0.0000) | Acc: (92.00%) (1304/1408)
Epoch: 106 | Batch_idx: 20 |  Loss: (0.2043) |  Loss2: (0.0000) | Acc: (93.00%) (2506/2688)
Epoch: 106 | Batch_idx: 30 |  Loss: (0.2051) |  Loss2: (0.0000) | Acc: (93.00%) (3701/3968)
Epoch: 106 | Batch_idx: 40 |  Loss: (0.2089) |  Loss2: (0.0000) | Acc: (92.00%) (4876/5248)
Epoch: 106 | Batch_idx: 50 |  Loss: (0.2023) |  Loss2: (0.0000) | Acc: (93.00%) (6081/6528)
Epoch: 106 | Batch_idx: 60 |  Loss: (0.2035) |  Loss2: (0.0000) | Acc: (93.00%) (7274/7808)
Epoch: 106 | Batch_idx: 70 |  Loss: (0.2045) |  Loss2: (0.0000) | Acc: (93.00%) (8454/9088)
Epoch: 106 | Batch_idx: 80 |  Loss: (0.2062) |  Loss2: (0.0000) | Acc: (92.00%) (9636/10368)
Epoch: 106 | Batch_idx: 90 |  Loss: (0.2025) |  Loss2: (0.0000) | Acc: (93.00%) (10844/11648)
Epoch: 106 | Batch_idx: 100 |  Loss: (0.1986) |  Loss2: (0.0000) | Acc: (93.00%) (12053/12928)
Epoch: 106 | Batch_idx: 110 |  Loss: (0.1997) |  Loss2: (0.0000) | Acc: (93.00%) (13240/14208)
Epoch: 106 | Batch_idx: 120 |  Loss: (0.2025) |  Loss2: (0.0000) | Acc: (93.00%) (14421/15488)
Epoch: 106 | Batch_idx: 130 |  Loss: (0.2007) |  Loss2: (0.0000) | Acc: (93.00%) (15621/16768)
Epoch: 106 | Batch_idx: 140 |  Loss: (0.1991) |  Loss2: (0.0000) | Acc: (93.00%) (16817/18048)
Epoch: 106 | Batch_idx: 150 |  Loss: (0.1993) |  Loss2: (0.0000) | Acc: (93.00%) (18007/19328)
Epoch: 106 | Batch_idx: 160 |  Loss: (0.2011) |  Loss2: (0.0000) | Acc: (93.00%) (19185/20608)
Epoch: 106 | Batch_idx: 170 |  Loss: (0.2016) |  Loss2: (0.0000) | Acc: (93.00%) (20373/21888)
Epoch: 106 | Batch_idx: 180 |  Loss: (0.2015) |  Loss2: (0.0000) | Acc: (93.00%) (21562/23168)
Epoch: 106 | Batch_idx: 190 |  Loss: (0.2017) |  Loss2: (0.0000) | Acc: (93.00%) (22754/24448)
Epoch: 106 | Batch_idx: 200 |  Loss: (0.2014) |  Loss2: (0.0000) | Acc: (93.00%) (23944/25728)
Epoch: 106 | Batch_idx: 210 |  Loss: (0.2011) |  Loss2: (0.0000) | Acc: (93.00%) (25133/27008)
Epoch: 106 | Batch_idx: 220 |  Loss: (0.2004) |  Loss2: (0.0000) | Acc: (93.00%) (26323/28288)
Epoch: 106 | Batch_idx: 230 |  Loss: (0.1997) |  Loss2: (0.0000) | Acc: (93.00%) (27516/29568)
Epoch: 106 | Batch_idx: 240 |  Loss: (0.1991) |  Loss2: (0.0000) | Acc: (93.00%) (28710/30848)
Epoch: 106 | Batch_idx: 250 |  Loss: (0.1993) |  Loss2: (0.0000) | Acc: (93.00%) (29902/32128)
Epoch: 106 | Batch_idx: 260 |  Loss: (0.1990) |  Loss2: (0.0000) | Acc: (93.00%) (31105/33408)
Epoch: 106 | Batch_idx: 270 |  Loss: (0.1986) |  Loss2: (0.0000) | Acc: (93.00%) (32301/34688)
Epoch: 106 | Batch_idx: 280 |  Loss: (0.1984) |  Loss2: (0.0000) | Acc: (93.00%) (33501/35968)
Epoch: 106 | Batch_idx: 290 |  Loss: (0.1990) |  Loss2: (0.0000) | Acc: (93.00%) (34691/37248)
Epoch: 106 | Batch_idx: 300 |  Loss: (0.1991) |  Loss2: (0.0000) | Acc: (93.00%) (35891/38528)
Epoch: 106 | Batch_idx: 310 |  Loss: (0.1993) |  Loss2: (0.0000) | Acc: (93.00%) (37085/39808)
Epoch: 106 | Batch_idx: 320 |  Loss: (0.1990) |  Loss2: (0.0000) | Acc: (93.00%) (38282/41088)
Epoch: 106 | Batch_idx: 330 |  Loss: (0.1991) |  Loss2: (0.0000) | Acc: (93.00%) (39485/42368)
Epoch: 106 | Batch_idx: 340 |  Loss: (0.1989) |  Loss2: (0.0000) | Acc: (93.00%) (40676/43648)
Epoch: 106 | Batch_idx: 350 |  Loss: (0.1991) |  Loss2: (0.0000) | Acc: (93.00%) (41863/44928)
Epoch: 106 | Batch_idx: 360 |  Loss: (0.1995) |  Loss2: (0.0000) | Acc: (93.00%) (43035/46208)
Epoch: 106 | Batch_idx: 370 |  Loss: (0.1998) |  Loss2: (0.0000) | Acc: (93.00%) (44222/47488)
Epoch: 106 | Batch_idx: 380 |  Loss: (0.1996) |  Loss2: (0.0000) | Acc: (93.00%) (45422/48768)
Epoch: 106 | Batch_idx: 390 |  Loss: (0.1996) |  Loss2: (0.0000) | Acc: (93.00%) (46578/50000)
# TEST : Loss: (0.3714) | Acc: (87.00%) (8758/10000)
percent tensor([0.5218, 0.5227, 0.5218, 0.5240, 0.5239, 0.5295, 0.5230, 0.5239, 0.5216,
        0.5207, 0.5219, 0.5211, 0.5211, 0.5222, 0.5248, 0.5236],
       device='cuda:0') torch.Size([16])
percent tensor([0.5113, 0.5126, 0.5078, 0.5132, 0.5070, 0.5170, 0.5075, 0.5044, 0.5107,
        0.5108, 0.5125, 0.5111, 0.5164, 0.5097, 0.5142, 0.5149],
       device='cuda:0') torch.Size([16])
percent tensor([0.5685, 0.5294, 0.6112, 0.6412, 0.6290, 0.5989, 0.5779, 0.6127, 0.6011,
        0.5619, 0.5903, 0.5756, 0.4925, 0.6264, 0.5650, 0.5792],
       device='cuda:0') torch.Size([16])
percent tensor([0.6246, 0.6260, 0.6140, 0.6180, 0.6181, 0.6143, 0.6283, 0.6222, 0.6300,
        0.6292, 0.6374, 0.6295, 0.6279, 0.6255, 0.6291, 0.6250],
       device='cuda:0') torch.Size([16])
percent tensor([0.5878, 0.5914, 0.5933, 0.6076, 0.6071, 0.6940, 0.5747, 0.5570, 0.5946,
        0.6133, 0.5967, 0.5854, 0.6018, 0.6170, 0.5784, 0.6384],
       device='cuda:0') torch.Size([16])
percent tensor([0.6182, 0.6514, 0.6577, 0.6857, 0.6409, 0.7160, 0.6463, 0.5852, 0.6741,
        0.6385, 0.7025, 0.6499, 0.6815, 0.6877, 0.5853, 0.6563],
       device='cuda:0') torch.Size([16])
percent tensor([0.6315, 0.6233, 0.6679, 0.6821, 0.6817, 0.6960, 0.6527, 0.6804, 0.6192,
        0.6049, 0.6171, 0.6045, 0.6231, 0.6243, 0.5896, 0.6647],
       device='cuda:0') torch.Size([16])
percent tensor([0.9998, 0.9994, 0.9994, 0.9995, 0.9995, 0.9986, 0.9992, 0.9998, 0.9997,
        0.9994, 0.9997, 0.9992, 0.9997, 0.9994, 0.9988, 0.9997],
       device='cuda:0') torch.Size([16])
Epoch: 107 | Batch_idx: 0 |  Loss: (0.1651) |  Loss2: (0.0000) | Acc: (96.00%) (123/128)
Epoch: 107 | Batch_idx: 10 |  Loss: (0.2120) |  Loss2: (0.0000) | Acc: (93.00%) (1311/1408)
Epoch: 107 | Batch_idx: 20 |  Loss: (0.2054) |  Loss2: (0.0000) | Acc: (93.00%) (2508/2688)
Epoch: 107 | Batch_idx: 30 |  Loss: (0.2009) |  Loss2: (0.0000) | Acc: (93.00%) (3700/3968)
Epoch: 107 | Batch_idx: 40 |  Loss: (0.1972) |  Loss2: (0.0000) | Acc: (93.00%) (4901/5248)
Epoch: 107 | Batch_idx: 50 |  Loss: (0.1934) |  Loss2: (0.0000) | Acc: (93.00%) (6098/6528)
Epoch: 107 | Batch_idx: 60 |  Loss: (0.1943) |  Loss2: (0.0000) | Acc: (93.00%) (7300/7808)
Epoch: 107 | Batch_idx: 70 |  Loss: (0.1936) |  Loss2: (0.0000) | Acc: (93.00%) (8497/9088)
Epoch: 107 | Batch_idx: 80 |  Loss: (0.1963) |  Loss2: (0.0000) | Acc: (93.00%) (9687/10368)
Epoch: 107 | Batch_idx: 90 |  Loss: (0.1949) |  Loss2: (0.0000) | Acc: (93.00%) (10891/11648)
Epoch: 107 | Batch_idx: 100 |  Loss: (0.1962) |  Loss2: (0.0000) | Acc: (93.00%) (12073/12928)
Epoch: 107 | Batch_idx: 110 |  Loss: (0.1963) |  Loss2: (0.0000) | Acc: (93.00%) (13258/14208)
Epoch: 107 | Batch_idx: 120 |  Loss: (0.1982) |  Loss2: (0.0000) | Acc: (93.00%) (14440/15488)
Epoch: 107 | Batch_idx: 130 |  Loss: (0.1975) |  Loss2: (0.0000) | Acc: (93.00%) (15645/16768)
Epoch: 107 | Batch_idx: 140 |  Loss: (0.1964) |  Loss2: (0.0000) | Acc: (93.00%) (16844/18048)
Epoch: 107 | Batch_idx: 150 |  Loss: (0.1964) |  Loss2: (0.0000) | Acc: (93.00%) (18040/19328)
Epoch: 107 | Batch_idx: 160 |  Loss: (0.1972) |  Loss2: (0.0000) | Acc: (93.00%) (19222/20608)
Epoch: 107 | Batch_idx: 170 |  Loss: (0.1992) |  Loss2: (0.0000) | Acc: (93.00%) (20396/21888)
Epoch: 107 | Batch_idx: 180 |  Loss: (0.1981) |  Loss2: (0.0000) | Acc: (93.00%) (21599/23168)
Epoch: 107 | Batch_idx: 190 |  Loss: (0.1984) |  Loss2: (0.0000) | Acc: (93.00%) (22795/24448)
Epoch: 107 | Batch_idx: 200 |  Loss: (0.1987) |  Loss2: (0.0000) | Acc: (93.00%) (23974/25728)
Epoch: 107 | Batch_idx: 210 |  Loss: (0.1985) |  Loss2: (0.0000) | Acc: (93.00%) (25169/27008)
Epoch: 107 | Batch_idx: 220 |  Loss: (0.1971) |  Loss2: (0.0000) | Acc: (93.00%) (26380/28288)
Epoch: 107 | Batch_idx: 230 |  Loss: (0.1969) |  Loss2: (0.0000) | Acc: (93.00%) (27581/29568)
Epoch: 107 | Batch_idx: 240 |  Loss: (0.1963) |  Loss2: (0.0000) | Acc: (93.00%) (28784/30848)
Epoch: 107 | Batch_idx: 250 |  Loss: (0.1963) |  Loss2: (0.0000) | Acc: (93.00%) (29982/32128)
Epoch: 107 | Batch_idx: 260 |  Loss: (0.1967) |  Loss2: (0.0000) | Acc: (93.00%) (31178/33408)
Epoch: 107 | Batch_idx: 270 |  Loss: (0.1969) |  Loss2: (0.0000) | Acc: (93.00%) (32357/34688)
Epoch: 107 | Batch_idx: 280 |  Loss: (0.1966) |  Loss2: (0.0000) | Acc: (93.00%) (33549/35968)
Epoch: 107 | Batch_idx: 290 |  Loss: (0.1980) |  Loss2: (0.0000) | Acc: (93.00%) (34728/37248)
Epoch: 107 | Batch_idx: 300 |  Loss: (0.1986) |  Loss2: (0.0000) | Acc: (93.00%) (35917/38528)
Epoch: 107 | Batch_idx: 310 |  Loss: (0.1984) |  Loss2: (0.0000) | Acc: (93.00%) (37115/39808)
Epoch: 107 | Batch_idx: 320 |  Loss: (0.1994) |  Loss2: (0.0000) | Acc: (93.00%) (38287/41088)
Epoch: 107 | Batch_idx: 330 |  Loss: (0.1998) |  Loss2: (0.0000) | Acc: (93.00%) (39465/42368)
Epoch: 107 | Batch_idx: 340 |  Loss: (0.1999) |  Loss2: (0.0000) | Acc: (93.00%) (40662/43648)
Epoch: 107 | Batch_idx: 350 |  Loss: (0.1998) |  Loss2: (0.0000) | Acc: (93.00%) (41860/44928)
Epoch: 107 | Batch_idx: 360 |  Loss: (0.1997) |  Loss2: (0.0000) | Acc: (93.00%) (43052/46208)
Epoch: 107 | Batch_idx: 370 |  Loss: (0.1992) |  Loss2: (0.0000) | Acc: (93.00%) (44262/47488)
Epoch: 107 | Batch_idx: 380 |  Loss: (0.1988) |  Loss2: (0.0000) | Acc: (93.00%) (45462/48768)
Epoch: 107 | Batch_idx: 390 |  Loss: (0.1984) |  Loss2: (0.0000) | Acc: (93.00%) (46615/50000)
# TEST : Loss: (0.3689) | Acc: (87.00%) (8776/10000)
percent tensor([0.5203, 0.5211, 0.5201, 0.5225, 0.5221, 0.5280, 0.5213, 0.5222, 0.5201,
        0.5190, 0.5203, 0.5194, 0.5195, 0.5209, 0.5233, 0.5221],
       device='cuda:0') torch.Size([16])
percent tensor([0.5118, 0.5138, 0.5083, 0.5138, 0.5076, 0.5175, 0.5086, 0.5051, 0.5117,
        0.5119, 0.5137, 0.5118, 0.5171, 0.5109, 0.5150, 0.5155],
       device='cuda:0') torch.Size([16])
percent tensor([0.5723, 0.5285, 0.6144, 0.6450, 0.6312, 0.6028, 0.5787, 0.6145, 0.6034,
        0.5643, 0.5930, 0.5789, 0.4948, 0.6266, 0.5660, 0.5834],
       device='cuda:0') torch.Size([16])
percent tensor([0.6274, 0.6280, 0.6158, 0.6196, 0.6199, 0.6178, 0.6300, 0.6236, 0.6319,
        0.6313, 0.6396, 0.6308, 0.6305, 0.6270, 0.6310, 0.6283],
       device='cuda:0') torch.Size([16])
percent tensor([0.5905, 0.5920, 0.5987, 0.6131, 0.6132, 0.6998, 0.5769, 0.5627, 0.5977,
        0.6140, 0.5962, 0.5873, 0.6031, 0.6205, 0.5800, 0.6426],
       device='cuda:0') torch.Size([16])
percent tensor([0.6127, 0.6476, 0.6528, 0.6808, 0.6356, 0.7116, 0.6416, 0.5784, 0.6701,
        0.6330, 0.6984, 0.6435, 0.6781, 0.6847, 0.5774, 0.6507],
       device='cuda:0') torch.Size([16])
percent tensor([0.6313, 0.6277, 0.6708, 0.6846, 0.6815, 0.6994, 0.6538, 0.6794, 0.6227,
        0.6077, 0.6204, 0.6055, 0.6275, 0.6286, 0.5897, 0.6644],
       device='cuda:0') torch.Size([16])
percent tensor([0.9998, 0.9994, 0.9994, 0.9995, 0.9995, 0.9987, 0.9992, 0.9998, 0.9997,
        0.9994, 0.9997, 0.9992, 0.9998, 0.9994, 0.9988, 0.9997],
       device='cuda:0') torch.Size([16])
True Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=128, out_features=16, bias=False)
False Linear(in_features=16, out_features=2, bias=False)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=128, out_features=16, bias=False)
False Linear(in_features=16, out_features=2, bias=False)
True Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=256, out_features=32, bias=False)
False Linear(in_features=32, out_features=2, bias=False)
True Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=256, out_features=32, bias=False)
False Linear(in_features=32, out_features=2, bias=False)
True Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=512, out_features=64, bias=False)
False Linear(in_features=64, out_features=2, bias=False)
True Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=512, out_features=64, bias=False)
False Linear(in_features=64, out_features=2, bias=False)
True Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1024, out_features=128, bias=False)
False Linear(in_features=128, out_features=2, bias=False)
True Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1024, out_features=128, bias=False)
False Linear(in_features=128, out_features=2, bias=False)
True Linear(in_features=512, out_features=10, bias=True)
Epoch: 108 | Batch_idx: 0 |  Loss: (0.1571) |  Loss2: (0.0000) | Acc: (94.00%) (121/128)
Epoch: 108 | Batch_idx: 10 |  Loss: (0.1899) |  Loss2: (0.0000) | Acc: (93.00%) (1314/1408)
Epoch: 108 | Batch_idx: 20 |  Loss: (0.2063) |  Loss2: (0.0000) | Acc: (92.00%) (2486/2688)
Epoch: 108 | Batch_idx: 30 |  Loss: (0.2103) |  Loss2: (0.0000) | Acc: (92.00%) (3667/3968)
Epoch: 108 | Batch_idx: 40 |  Loss: (0.2070) |  Loss2: (0.0000) | Acc: (92.00%) (4864/5248)
Epoch: 108 | Batch_idx: 50 |  Loss: (0.2047) |  Loss2: (0.0000) | Acc: (92.00%) (6049/6528)
Epoch: 108 | Batch_idx: 60 |  Loss: (0.2052) |  Loss2: (0.0000) | Acc: (92.00%) (7239/7808)
Epoch: 108 | Batch_idx: 70 |  Loss: (0.2024) |  Loss2: (0.0000) | Acc: (92.00%) (8423/9088)
Epoch: 108 | Batch_idx: 80 |  Loss: (0.2039) |  Loss2: (0.0000) | Acc: (92.00%) (9605/10368)
Epoch: 108 | Batch_idx: 90 |  Loss: (0.2054) |  Loss2: (0.0000) | Acc: (92.00%) (10787/11648)
Epoch: 108 | Batch_idx: 100 |  Loss: (0.2043) |  Loss2: (0.0000) | Acc: (92.00%) (11991/12928)
Epoch: 108 | Batch_idx: 110 |  Loss: (0.2061) |  Loss2: (0.0000) | Acc: (92.00%) (13175/14208)
Epoch: 108 | Batch_idx: 120 |  Loss: (0.2056) |  Loss2: (0.0000) | Acc: (92.00%) (14353/15488)
Epoch: 108 | Batch_idx: 130 |  Loss: (0.2064) |  Loss2: (0.0000) | Acc: (92.00%) (15538/16768)
Epoch: 108 | Batch_idx: 140 |  Loss: (0.2056) |  Loss2: (0.0000) | Acc: (92.00%) (16733/18048)
Epoch: 108 | Batch_idx: 150 |  Loss: (0.2051) |  Loss2: (0.0000) | Acc: (92.00%) (17915/19328)
Epoch: 108 | Batch_idx: 160 |  Loss: (0.2054) |  Loss2: (0.0000) | Acc: (92.00%) (19110/20608)
Epoch: 108 | Batch_idx: 170 |  Loss: (0.2072) |  Loss2: (0.0000) | Acc: (92.00%) (20280/21888)
Epoch: 108 | Batch_idx: 180 |  Loss: (0.2068) |  Loss2: (0.0000) | Acc: (92.00%) (21466/23168)
Epoch: 108 | Batch_idx: 190 |  Loss: (0.2067) |  Loss2: (0.0000) | Acc: (92.00%) (22656/24448)
Epoch: 108 | Batch_idx: 200 |  Loss: (0.2077) |  Loss2: (0.0000) | Acc: (92.00%) (23831/25728)
Epoch: 108 | Batch_idx: 210 |  Loss: (0.2073) |  Loss2: (0.0000) | Acc: (92.00%) (25023/27008)
Epoch: 108 | Batch_idx: 220 |  Loss: (0.2071) |  Loss2: (0.0000) | Acc: (92.00%) (26221/28288)
Epoch: 108 | Batch_idx: 230 |  Loss: (0.2081) |  Loss2: (0.0000) | Acc: (92.00%) (27395/29568)
Epoch: 108 | Batch_idx: 240 |  Loss: (0.2084) |  Loss2: (0.0000) | Acc: (92.00%) (28585/30848)
Epoch: 108 | Batch_idx: 250 |  Loss: (0.2088) |  Loss2: (0.0000) | Acc: (92.00%) (29780/32128)
Epoch: 108 | Batch_idx: 260 |  Loss: (0.2088) |  Loss2: (0.0000) | Acc: (92.00%) (30964/33408)
Epoch: 108 | Batch_idx: 270 |  Loss: (0.2092) |  Loss2: (0.0000) | Acc: (92.00%) (32145/34688)
Epoch: 108 | Batch_idx: 280 |  Loss: (0.2083) |  Loss2: (0.0000) | Acc: (92.00%) (33336/35968)
Epoch: 108 | Batch_idx: 290 |  Loss: (0.2088) |  Loss2: (0.0000) | Acc: (92.00%) (34519/37248)
Epoch: 108 | Batch_idx: 300 |  Loss: (0.2104) |  Loss2: (0.0000) | Acc: (92.00%) (35673/38528)
Epoch: 108 | Batch_idx: 310 |  Loss: (0.2101) |  Loss2: (0.0000) | Acc: (92.00%) (36862/39808)
Epoch: 108 | Batch_idx: 320 |  Loss: (0.2096) |  Loss2: (0.0000) | Acc: (92.00%) (38057/41088)
Epoch: 108 | Batch_idx: 330 |  Loss: (0.2104) |  Loss2: (0.0000) | Acc: (92.00%) (39227/42368)
Epoch: 108 | Batch_idx: 340 |  Loss: (0.2107) |  Loss2: (0.0000) | Acc: (92.00%) (40400/43648)
Epoch: 108 | Batch_idx: 350 |  Loss: (0.2112) |  Loss2: (0.0000) | Acc: (92.00%) (41578/44928)
Epoch: 108 | Batch_idx: 360 |  Loss: (0.2112) |  Loss2: (0.0000) | Acc: (92.00%) (42766/46208)
Epoch: 108 | Batch_idx: 370 |  Loss: (0.2114) |  Loss2: (0.0000) | Acc: (92.00%) (43953/47488)
Epoch: 108 | Batch_idx: 380 |  Loss: (0.2119) |  Loss2: (0.0000) | Acc: (92.00%) (45134/48768)
Epoch: 108 | Batch_idx: 390 |  Loss: (0.2115) |  Loss2: (0.0000) | Acc: (92.00%) (46285/50000)
# TEST : Loss: (0.3979) | Acc: (87.00%) (8741/10000)
percent tensor([0.5196, 0.5222, 0.5167, 0.5212, 0.5194, 0.5272, 0.5217, 0.5212, 0.5196,
        0.5189, 0.5208, 0.5169, 0.5195, 0.5235, 0.5234, 0.5222],
       device='cuda:0') torch.Size([16])
percent tensor([0.5114, 0.5133, 0.5084, 0.5123, 0.5072, 0.5165, 0.5082, 0.5058, 0.5118,
        0.5118, 0.5129, 0.5121, 0.5171, 0.5093, 0.5145, 0.5149],
       device='cuda:0') torch.Size([16])
percent tensor([0.5725, 0.5304, 0.6166, 0.6390, 0.6331, 0.6099, 0.5789, 0.6096, 0.6061,
        0.5650, 0.5937, 0.5799, 0.4972, 0.6286, 0.5657, 0.5791],
       device='cuda:0') torch.Size([16])
percent tensor([0.6270, 0.6278, 0.6191, 0.6204, 0.6211, 0.6202, 0.6277, 0.6237, 0.6330,
        0.6306, 0.6356, 0.6342, 0.6313, 0.6286, 0.6317, 0.6286],
       device='cuda:0') torch.Size([16])
percent tensor([0.5905, 0.5944, 0.6056, 0.6089, 0.6191, 0.6807, 0.5757, 0.5724, 0.6109,
        0.6122, 0.5957, 0.5963, 0.6008, 0.6296, 0.5769, 0.6346],
       device='cuda:0') torch.Size([16])
percent tensor([0.6231, 0.6528, 0.6461, 0.6657, 0.6536, 0.7252, 0.6488, 0.5795, 0.6700,
        0.6402, 0.7025, 0.6413, 0.6805, 0.6918, 0.5867, 0.6547],
       device='cuda:0') torch.Size([16])
percent tensor([0.6425, 0.6399, 0.6764, 0.6869, 0.7035, 0.7052, 0.6594, 0.6727, 0.6356,
        0.6301, 0.6434, 0.6227, 0.6374, 0.6398, 0.5971, 0.6614],
       device='cuda:0') torch.Size([16])
percent tensor([0.9997, 0.9995, 0.9996, 0.9996, 0.9996, 0.9984, 0.9994, 0.9996, 0.9997,
        0.9995, 0.9999, 0.9996, 0.9997, 0.9994, 0.9988, 0.9996],
       device='cuda:0') torch.Size([16])
Epoch: 109 | Batch_idx: 0 |  Loss: (0.1033) |  Loss2: (0.0000) | Acc: (96.00%) (123/128)
Epoch: 109 | Batch_idx: 10 |  Loss: (0.1845) |  Loss2: (0.0000) | Acc: (93.00%) (1318/1408)
Epoch: 109 | Batch_idx: 20 |  Loss: (0.1923) |  Loss2: (0.0000) | Acc: (93.00%) (2509/2688)
Epoch: 109 | Batch_idx: 30 |  Loss: (0.1983) |  Loss2: (0.0000) | Acc: (93.00%) (3692/3968)
Epoch: 109 | Batch_idx: 40 |  Loss: (0.1924) |  Loss2: (0.0000) | Acc: (93.00%) (4904/5248)
Epoch: 109 | Batch_idx: 50 |  Loss: (0.1894) |  Loss2: (0.0000) | Acc: (93.00%) (6095/6528)
Epoch: 109 | Batch_idx: 60 |  Loss: (0.1876) |  Loss2: (0.0000) | Acc: (93.00%) (7295/7808)
Epoch: 109 | Batch_idx: 70 |  Loss: (0.1912) |  Loss2: (0.0000) | Acc: (93.00%) (8493/9088)
Epoch: 109 | Batch_idx: 80 |  Loss: (0.1942) |  Loss2: (0.0000) | Acc: (93.00%) (9660/10368)
Epoch: 109 | Batch_idx: 90 |  Loss: (0.1940) |  Loss2: (0.0000) | Acc: (93.00%) (10851/11648)
Epoch: 109 | Batch_idx: 100 |  Loss: (0.1953) |  Loss2: (0.0000) | Acc: (93.00%) (12044/12928)
Epoch: 109 | Batch_idx: 110 |  Loss: (0.1982) |  Loss2: (0.0000) | Acc: (93.00%) (13229/14208)
Epoch: 109 | Batch_idx: 120 |  Loss: (0.1997) |  Loss2: (0.0000) | Acc: (93.00%) (14418/15488)
Epoch: 109 | Batch_idx: 130 |  Loss: (0.2026) |  Loss2: (0.0000) | Acc: (92.00%) (15592/16768)
Epoch: 109 | Batch_idx: 140 |  Loss: (0.2037) |  Loss2: (0.0000) | Acc: (92.00%) (16780/18048)
Epoch: 109 | Batch_idx: 150 |  Loss: (0.2036) |  Loss2: (0.0000) | Acc: (92.00%) (17970/19328)
Epoch: 109 | Batch_idx: 160 |  Loss: (0.2027) |  Loss2: (0.0000) | Acc: (92.00%) (19164/20608)
Epoch: 109 | Batch_idx: 170 |  Loss: (0.2036) |  Loss2: (0.0000) | Acc: (92.00%) (20350/21888)
Epoch: 109 | Batch_idx: 180 |  Loss: (0.2031) |  Loss2: (0.0000) | Acc: (93.00%) (21553/23168)
Epoch: 109 | Batch_idx: 190 |  Loss: (0.2039) |  Loss2: (0.0000) | Acc: (93.00%) (22742/24448)
Epoch: 109 | Batch_idx: 200 |  Loss: (0.2044) |  Loss2: (0.0000) | Acc: (93.00%) (23930/25728)
Epoch: 109 | Batch_idx: 210 |  Loss: (0.2052) |  Loss2: (0.0000) | Acc: (92.00%) (25114/27008)
Epoch: 109 | Batch_idx: 220 |  Loss: (0.2053) |  Loss2: (0.0000) | Acc: (92.00%) (26305/28288)
Epoch: 109 | Batch_idx: 230 |  Loss: (0.2043) |  Loss2: (0.0000) | Acc: (93.00%) (27509/29568)
Epoch: 109 | Batch_idx: 240 |  Loss: (0.2033) |  Loss2: (0.0000) | Acc: (93.00%) (28704/30848)
Epoch: 109 | Batch_idx: 250 |  Loss: (0.2030) |  Loss2: (0.0000) | Acc: (93.00%) (29898/32128)
Epoch: 109 | Batch_idx: 260 |  Loss: (0.2040) |  Loss2: (0.0000) | Acc: (93.00%) (31088/33408)
Epoch: 109 | Batch_idx: 270 |  Loss: (0.2047) |  Loss2: (0.0000) | Acc: (93.00%) (32267/34688)
Epoch: 109 | Batch_idx: 280 |  Loss: (0.2054) |  Loss2: (0.0000) | Acc: (92.00%) (33443/35968)
Epoch: 109 | Batch_idx: 290 |  Loss: (0.2047) |  Loss2: (0.0000) | Acc: (92.00%) (34639/37248)
Epoch: 109 | Batch_idx: 300 |  Loss: (0.2042) |  Loss2: (0.0000) | Acc: (93.00%) (35833/38528)
Epoch: 109 | Batch_idx: 310 |  Loss: (0.2049) |  Loss2: (0.0000) | Acc: (92.00%) (37010/39808)
Epoch: 109 | Batch_idx: 320 |  Loss: (0.2060) |  Loss2: (0.0000) | Acc: (92.00%) (38190/41088)
Epoch: 109 | Batch_idx: 330 |  Loss: (0.2065) |  Loss2: (0.0000) | Acc: (92.00%) (39370/42368)
Epoch: 109 | Batch_idx: 340 |  Loss: (0.2061) |  Loss2: (0.0000) | Acc: (92.00%) (40557/43648)
Epoch: 109 | Batch_idx: 350 |  Loss: (0.2067) |  Loss2: (0.0000) | Acc: (92.00%) (41739/44928)
Epoch: 109 | Batch_idx: 360 |  Loss: (0.2067) |  Loss2: (0.0000) | Acc: (92.00%) (42925/46208)
Epoch: 109 | Batch_idx: 370 |  Loss: (0.2069) |  Loss2: (0.0000) | Acc: (92.00%) (44111/47488)
Epoch: 109 | Batch_idx: 380 |  Loss: (0.2066) |  Loss2: (0.0000) | Acc: (92.00%) (45309/48768)
Epoch: 109 | Batch_idx: 390 |  Loss: (0.2063) |  Loss2: (0.0000) | Acc: (92.00%) (46462/50000)
# TEST : Loss: (0.4104) | Acc: (86.00%) (8678/10000)
percent tensor([0.5197, 0.5223, 0.5182, 0.5223, 0.5204, 0.5276, 0.5222, 0.5219, 0.5194,
        0.5192, 0.5204, 0.5182, 0.5192, 0.5231, 0.5236, 0.5224],
       device='cuda:0') torch.Size([16])
percent tensor([0.5117, 0.5147, 0.5103, 0.5150, 0.5098, 0.5173, 0.5095, 0.5075, 0.5130,
        0.5126, 0.5137, 0.5135, 0.5171, 0.5117, 0.5155, 0.5161],
       device='cuda:0') torch.Size([16])
percent tensor([0.5661, 0.5256, 0.6139, 0.6415, 0.6315, 0.6066, 0.5709, 0.6078, 0.6009,
        0.5581, 0.5827, 0.5720, 0.4912, 0.6265, 0.5616, 0.5766],
       device='cuda:0') torch.Size([16])
percent tensor([0.6259, 0.6276, 0.6205, 0.6175, 0.6227, 0.6179, 0.6283, 0.6231, 0.6331,
        0.6332, 0.6357, 0.6367, 0.6319, 0.6261, 0.6296, 0.6280],
       device='cuda:0') torch.Size([16])
percent tensor([0.5904, 0.5915, 0.6052, 0.6284, 0.6385, 0.7003, 0.5810, 0.5798, 0.6061,
        0.6092, 0.5823, 0.5881, 0.5939, 0.6175, 0.5913, 0.6453],
       device='cuda:0') torch.Size([16])
percent tensor([0.6165, 0.6602, 0.6325, 0.6757, 0.6532, 0.7234, 0.6486, 0.5753, 0.6769,
        0.6301, 0.6942, 0.6294, 0.6841, 0.6885, 0.5877, 0.6471],
       device='cuda:0') torch.Size([16])
percent tensor([0.6423, 0.6327, 0.6699, 0.6964, 0.7093, 0.7130, 0.6597, 0.6678, 0.6255,
        0.6200, 0.6339, 0.6070, 0.6382, 0.6251, 0.5897, 0.6631],
       device='cuda:0') torch.Size([16])
percent tensor([0.9998, 0.9996, 0.9995, 0.9996, 0.9994, 0.9980, 0.9992, 0.9996, 0.9998,
        0.9995, 0.9998, 0.9992, 0.9997, 0.9995, 0.9986, 0.9996],
       device='cuda:0') torch.Size([16])
Epoch: 110 | Batch_idx: 0 |  Loss: (0.0868) |  Loss2: (0.0000) | Acc: (98.00%) (126/128)
Epoch: 110 | Batch_idx: 10 |  Loss: (0.1659) |  Loss2: (0.0000) | Acc: (94.00%) (1333/1408)
Epoch: 110 | Batch_idx: 20 |  Loss: (0.1772) |  Loss2: (0.0000) | Acc: (93.00%) (2526/2688)
Epoch: 110 | Batch_idx: 30 |  Loss: (0.1809) |  Loss2: (0.0000) | Acc: (94.00%) (3731/3968)
Epoch: 110 | Batch_idx: 40 |  Loss: (0.1844) |  Loss2: (0.0000) | Acc: (93.00%) (4923/5248)
Epoch: 110 | Batch_idx: 50 |  Loss: (0.1886) |  Loss2: (0.0000) | Acc: (93.00%) (6123/6528)
Epoch: 110 | Batch_idx: 60 |  Loss: (0.1895) |  Loss2: (0.0000) | Acc: (93.00%) (7315/7808)
Epoch: 110 | Batch_idx: 70 |  Loss: (0.1919) |  Loss2: (0.0000) | Acc: (93.00%) (8505/9088)
Epoch: 110 | Batch_idx: 80 |  Loss: (0.1932) |  Loss2: (0.0000) | Acc: (93.00%) (9694/10368)
Epoch: 110 | Batch_idx: 90 |  Loss: (0.1922) |  Loss2: (0.0000) | Acc: (93.00%) (10886/11648)
Epoch: 110 | Batch_idx: 100 |  Loss: (0.1961) |  Loss2: (0.0000) | Acc: (93.00%) (12054/12928)
Epoch: 110 | Batch_idx: 110 |  Loss: (0.1965) |  Loss2: (0.0000) | Acc: (93.00%) (13247/14208)
Epoch: 110 | Batch_idx: 120 |  Loss: (0.1962) |  Loss2: (0.0000) | Acc: (93.00%) (14446/15488)
Epoch: 110 | Batch_idx: 130 |  Loss: (0.1969) |  Loss2: (0.0000) | Acc: (93.00%) (15630/16768)
Epoch: 110 | Batch_idx: 140 |  Loss: (0.1961) |  Loss2: (0.0000) | Acc: (93.00%) (16831/18048)
Epoch: 110 | Batch_idx: 150 |  Loss: (0.1950) |  Loss2: (0.0000) | Acc: (93.00%) (18042/19328)
Epoch: 110 | Batch_idx: 160 |  Loss: (0.1957) |  Loss2: (0.0000) | Acc: (93.00%) (19232/20608)
Epoch: 110 | Batch_idx: 170 |  Loss: (0.1964) |  Loss2: (0.0000) | Acc: (93.00%) (20427/21888)
Epoch: 110 | Batch_idx: 180 |  Loss: (0.1967) |  Loss2: (0.0000) | Acc: (93.00%) (21615/23168)
Epoch: 110 | Batch_idx: 190 |  Loss: (0.1960) |  Loss2: (0.0000) | Acc: (93.00%) (22809/24448)
Epoch: 110 | Batch_idx: 200 |  Loss: (0.1969) |  Loss2: (0.0000) | Acc: (93.00%) (23997/25728)
Epoch: 110 | Batch_idx: 210 |  Loss: (0.1972) |  Loss2: (0.0000) | Acc: (93.00%) (25187/27008)
Epoch: 110 | Batch_idx: 220 |  Loss: (0.1977) |  Loss2: (0.0000) | Acc: (93.00%) (26375/28288)
Epoch: 110 | Batch_idx: 230 |  Loss: (0.1970) |  Loss2: (0.0000) | Acc: (93.00%) (27575/29568)
Epoch: 110 | Batch_idx: 240 |  Loss: (0.1982) |  Loss2: (0.0000) | Acc: (93.00%) (28747/30848)
Epoch: 110 | Batch_idx: 250 |  Loss: (0.1981) |  Loss2: (0.0000) | Acc: (93.00%) (29944/32128)
Epoch: 110 | Batch_idx: 260 |  Loss: (0.1977) |  Loss2: (0.0000) | Acc: (93.00%) (31141/33408)
Epoch: 110 | Batch_idx: 270 |  Loss: (0.1969) |  Loss2: (0.0000) | Acc: (93.00%) (32341/34688)
Epoch: 110 | Batch_idx: 280 |  Loss: (0.1979) |  Loss2: (0.0000) | Acc: (93.00%) (33522/35968)
Epoch: 110 | Batch_idx: 290 |  Loss: (0.1974) |  Loss2: (0.0000) | Acc: (93.00%) (34716/37248)
Epoch: 110 | Batch_idx: 300 |  Loss: (0.1979) |  Loss2: (0.0000) | Acc: (93.00%) (35908/38528)
Epoch: 110 | Batch_idx: 310 |  Loss: (0.1971) |  Loss2: (0.0000) | Acc: (93.00%) (37106/39808)
Epoch: 110 | Batch_idx: 320 |  Loss: (0.1973) |  Loss2: (0.0000) | Acc: (93.00%) (38296/41088)
Epoch: 110 | Batch_idx: 330 |  Loss: (0.1978) |  Loss2: (0.0000) | Acc: (93.00%) (39483/42368)
Epoch: 110 | Batch_idx: 340 |  Loss: (0.1981) |  Loss2: (0.0000) | Acc: (93.00%) (40673/43648)
Epoch: 110 | Batch_idx: 350 |  Loss: (0.1978) |  Loss2: (0.0000) | Acc: (93.00%) (41869/44928)
Epoch: 110 | Batch_idx: 360 |  Loss: (0.1987) |  Loss2: (0.0000) | Acc: (93.00%) (43049/46208)
Epoch: 110 | Batch_idx: 370 |  Loss: (0.1995) |  Loss2: (0.0000) | Acc: (93.00%) (44228/47488)
Epoch: 110 | Batch_idx: 380 |  Loss: (0.2000) |  Loss2: (0.0000) | Acc: (93.00%) (45411/48768)
Epoch: 110 | Batch_idx: 390 |  Loss: (0.2002) |  Loss2: (0.0000) | Acc: (93.00%) (46548/50000)
=> saving checkpoint 'drive/app/torch/save_Schedule/checkpoint_110.pth.tar'
# TEST : Loss: (0.4419) | Acc: (86.00%) (8618/10000)
percent tensor([0.5202, 0.5213, 0.5193, 0.5216, 0.5214, 0.5273, 0.5218, 0.5219, 0.5199,
        0.5194, 0.5205, 0.5191, 0.5199, 0.5215, 0.5230, 0.5218],
       device='cuda:0') torch.Size([16])
percent tensor([0.5119, 0.5140, 0.5102, 0.5142, 0.5086, 0.5166, 0.5090, 0.5061, 0.5123,
        0.5131, 0.5137, 0.5130, 0.5167, 0.5108, 0.5142, 0.5153],
       device='cuda:0') torch.Size([16])
percent tensor([0.5809, 0.5298, 0.6213, 0.6466, 0.6347, 0.6169, 0.5791, 0.6173, 0.6060,
        0.5682, 0.5883, 0.5849, 0.5014, 0.6278, 0.5712, 0.5856],
       device='cuda:0') torch.Size([16])
percent tensor([0.6285, 0.6315, 0.6150, 0.6180, 0.6208, 0.6204, 0.6310, 0.6246, 0.6342,
        0.6348, 0.6391, 0.6332, 0.6344, 0.6323, 0.6334, 0.6311],
       device='cuda:0') torch.Size([16])
percent tensor([0.6020, 0.5786, 0.6153, 0.6322, 0.6390, 0.6726, 0.5777, 0.5717, 0.6125,
        0.6183, 0.5793, 0.6011, 0.6030, 0.6217, 0.5696, 0.6433],
       device='cuda:0') torch.Size([16])
percent tensor([0.6173, 0.6437, 0.6407, 0.6741, 0.6426, 0.7079, 0.6381, 0.5603, 0.6680,
        0.6414, 0.6844, 0.6439, 0.6815, 0.6916, 0.5713, 0.6406],
       device='cuda:0') torch.Size([16])
percent tensor([0.6375, 0.6362, 0.6762, 0.7056, 0.7083, 0.6961, 0.6668, 0.6694, 0.6343,
        0.6374, 0.6366, 0.6213, 0.6451, 0.6185, 0.5956, 0.6645],
       device='cuda:0') torch.Size([16])
percent tensor([0.9998, 0.9993, 0.9996, 0.9999, 0.9997, 0.9986, 0.9994, 0.9997, 0.9995,
        0.9995, 0.9997, 0.9997, 0.9997, 0.9994, 0.9988, 0.9997],
       device='cuda:0') torch.Size([16])
Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 3, 3, 3]) tensor(177.7451, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(820.9283, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(814.2371, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([128, 64, 3, 3]) tensor(1520.3575, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([128, 64, 1, 1]) tensor(493.2757, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([128, 128, 3, 3]) tensor(2249.1909, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([256, 128, 3, 3]) tensor(4276.3877, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([256, 128, 1, 1]) tensor(1389.9867, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([256, 256, 3, 3]) tensor(6173.7388, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([512, 256, 3, 3]) tensor(11825.4414, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([512, 256, 1, 1]) tensor(3918.1523, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([512, 512, 3, 3]) tensor(16580.8965, device='cuda:0', grad_fn=<NormBackward0>)
Epoch: 111 | Batch_idx: 0 |  Loss: (0.1969) |  Loss2: (0.0000) | Acc: (91.00%) (117/128)
Epoch: 111 | Batch_idx: 10 |  Loss: (0.1988) |  Loss2: (0.0000) | Acc: (92.00%) (1308/1408)
Epoch: 111 | Batch_idx: 20 |  Loss: (0.1895) |  Loss2: (0.0000) | Acc: (93.00%) (2510/2688)
Epoch: 111 | Batch_idx: 30 |  Loss: (0.1879) |  Loss2: (0.0000) | Acc: (93.00%) (3708/3968)
Epoch: 111 | Batch_idx: 40 |  Loss: (0.1934) |  Loss2: (0.0000) | Acc: (93.00%) (4895/5248)
Epoch: 111 | Batch_idx: 50 |  Loss: (0.1954) |  Loss2: (0.0000) | Acc: (93.00%) (6088/6528)
Epoch: 111 | Batch_idx: 60 |  Loss: (0.1970) |  Loss2: (0.0000) | Acc: (93.00%) (7277/7808)
Epoch: 111 | Batch_idx: 70 |  Loss: (0.1951) |  Loss2: (0.0000) | Acc: (93.00%) (8475/9088)
Epoch: 111 | Batch_idx: 80 |  Loss: (0.1941) |  Loss2: (0.0000) | Acc: (93.00%) (9676/10368)
Epoch: 111 | Batch_idx: 90 |  Loss: (0.1938) |  Loss2: (0.0000) | Acc: (93.00%) (10870/11648)
Epoch: 111 | Batch_idx: 100 |  Loss: (0.1928) |  Loss2: (0.0000) | Acc: (93.00%) (12069/12928)
Epoch: 111 | Batch_idx: 110 |  Loss: (0.1917) |  Loss2: (0.0000) | Acc: (93.00%) (13272/14208)
Epoch: 111 | Batch_idx: 120 |  Loss: (0.1909) |  Loss2: (0.0000) | Acc: (93.00%) (14475/15488)
Epoch: 111 | Batch_idx: 130 |  Loss: (0.1904) |  Loss2: (0.0000) | Acc: (93.00%) (15671/16768)
Epoch: 111 | Batch_idx: 140 |  Loss: (0.1918) |  Loss2: (0.0000) | Acc: (93.00%) (16858/18048)
Epoch: 111 | Batch_idx: 150 |  Loss: (0.1895) |  Loss2: (0.0000) | Acc: (93.00%) (18070/19328)
Epoch: 111 | Batch_idx: 160 |  Loss: (0.1912) |  Loss2: (0.0000) | Acc: (93.00%) (19253/20608)
Epoch: 111 | Batch_idx: 170 |  Loss: (0.1932) |  Loss2: (0.0000) | Acc: (93.00%) (20433/21888)
Epoch: 111 | Batch_idx: 180 |  Loss: (0.1921) |  Loss2: (0.0000) | Acc: (93.00%) (21636/23168)
Epoch: 111 | Batch_idx: 190 |  Loss: (0.1923) |  Loss2: (0.0000) | Acc: (93.00%) (22829/24448)
Epoch: 111 | Batch_idx: 200 |  Loss: (0.1921) |  Loss2: (0.0000) | Acc: (93.00%) (24024/25728)
Epoch: 111 | Batch_idx: 210 |  Loss: (0.1919) |  Loss2: (0.0000) | Acc: (93.00%) (25219/27008)
Epoch: 111 | Batch_idx: 220 |  Loss: (0.1920) |  Loss2: (0.0000) | Acc: (93.00%) (26418/28288)
Epoch: 111 | Batch_idx: 230 |  Loss: (0.1920) |  Loss2: (0.0000) | Acc: (93.00%) (27614/29568)
Epoch: 111 | Batch_idx: 240 |  Loss: (0.1925) |  Loss2: (0.0000) | Acc: (93.00%) (28799/30848)
Epoch: 111 | Batch_idx: 250 |  Loss: (0.1935) |  Loss2: (0.0000) | Acc: (93.00%) (29985/32128)
Epoch: 111 | Batch_idx: 260 |  Loss: (0.1948) |  Loss2: (0.0000) | Acc: (93.00%) (31153/33408)
Epoch: 111 | Batch_idx: 270 |  Loss: (0.1949) |  Loss2: (0.0000) | Acc: (93.00%) (32352/34688)
Epoch: 111 | Batch_idx: 280 |  Loss: (0.1954) |  Loss2: (0.0000) | Acc: (93.00%) (33532/35968)
Epoch: 111 | Batch_idx: 290 |  Loss: (0.1948) |  Loss2: (0.0000) | Acc: (93.00%) (34731/37248)
Epoch: 111 | Batch_idx: 300 |  Loss: (0.1951) |  Loss2: (0.0000) | Acc: (93.00%) (35922/38528)
Epoch: 111 | Batch_idx: 310 |  Loss: (0.1950) |  Loss2: (0.0000) | Acc: (93.00%) (37118/39808)
Epoch: 111 | Batch_idx: 320 |  Loss: (0.1964) |  Loss2: (0.0000) | Acc: (93.00%) (38301/41088)
Epoch: 111 | Batch_idx: 330 |  Loss: (0.1966) |  Loss2: (0.0000) | Acc: (93.00%) (39489/42368)
Epoch: 111 | Batch_idx: 340 |  Loss: (0.1969) |  Loss2: (0.0000) | Acc: (93.00%) (40684/43648)
Epoch: 111 | Batch_idx: 350 |  Loss: (0.1970) |  Loss2: (0.0000) | Acc: (93.00%) (41885/44928)
Epoch: 111 | Batch_idx: 360 |  Loss: (0.1966) |  Loss2: (0.0000) | Acc: (93.00%) (43078/46208)
Epoch: 111 | Batch_idx: 370 |  Loss: (0.1976) |  Loss2: (0.0000) | Acc: (93.00%) (44247/47488)
Epoch: 111 | Batch_idx: 380 |  Loss: (0.1977) |  Loss2: (0.0000) | Acc: (93.00%) (45444/48768)
Epoch: 111 | Batch_idx: 390 |  Loss: (0.1980) |  Loss2: (0.0000) | Acc: (93.00%) (46587/50000)
# TEST : Loss: (0.4197) | Acc: (87.00%) (8713/10000)
percent tensor([0.5198, 0.5222, 0.5173, 0.5222, 0.5199, 0.5278, 0.5219, 0.5216, 0.5195,
        0.5190, 0.5207, 0.5176, 0.5197, 0.5237, 0.5235, 0.5225],
       device='cuda:0') torch.Size([16])
percent tensor([0.5121, 0.5147, 0.5095, 0.5134, 0.5090, 0.5172, 0.5096, 0.5066, 0.5137,
        0.5127, 0.5147, 0.5128, 0.5176, 0.5115, 0.5149, 0.5161],
       device='cuda:0') torch.Size([16])
percent tensor([0.5709, 0.5277, 0.6213, 0.6446, 0.6376, 0.6095, 0.5726, 0.6128, 0.6048,
        0.5613, 0.5837, 0.5778, 0.4931, 0.6234, 0.5636, 0.5811],
       device='cuda:0') torch.Size([16])
percent tensor([0.6260, 0.6285, 0.6164, 0.6198, 0.6220, 0.6160, 0.6290, 0.6234, 0.6331,
        0.6317, 0.6361, 0.6356, 0.6316, 0.6290, 0.6303, 0.6283],
       device='cuda:0') torch.Size([16])
percent tensor([0.5906, 0.5840, 0.6003, 0.6110, 0.6304, 0.6617, 0.5755, 0.5767, 0.6085,
        0.6146, 0.5865, 0.5906, 0.5995, 0.6182, 0.5701, 0.6399],
       device='cuda:0') torch.Size([16])
percent tensor([0.6198, 0.6463, 0.6428, 0.6710, 0.6458, 0.7123, 0.6351, 0.5667, 0.6725,
        0.6290, 0.6869, 0.6414, 0.6813, 0.6782, 0.5873, 0.6486],
       device='cuda:0') torch.Size([16])
percent tensor([0.6410, 0.6402, 0.6710, 0.6990, 0.7098, 0.7023, 0.6683, 0.6732, 0.6243,
        0.6344, 0.6379, 0.6139, 0.6459, 0.6148, 0.6028, 0.6746],
       device='cuda:0') torch.Size([16])
percent tensor([0.9998, 0.9992, 0.9994, 0.9998, 0.9995, 0.9981, 0.9991, 0.9997, 0.9998,
        0.9996, 0.9997, 0.9996, 0.9998, 0.9992, 0.9988, 0.9996],
       device='cuda:0') torch.Size([16])
Epoch: 112 | Batch_idx: 0 |  Loss: (0.2020) |  Loss2: (0.0000) | Acc: (92.00%) (119/128)
Epoch: 112 | Batch_idx: 10 |  Loss: (0.1733) |  Loss2: (0.0000) | Acc: (93.00%) (1319/1408)
Epoch: 112 | Batch_idx: 20 |  Loss: (0.1956) |  Loss2: (0.0000) | Acc: (92.00%) (2494/2688)
Epoch: 112 | Batch_idx: 30 |  Loss: (0.1905) |  Loss2: (0.0000) | Acc: (93.00%) (3696/3968)
Epoch: 112 | Batch_idx: 40 |  Loss: (0.1864) |  Loss2: (0.0000) | Acc: (93.00%) (4907/5248)
Epoch: 112 | Batch_idx: 50 |  Loss: (0.1849) |  Loss2: (0.0000) | Acc: (93.00%) (6109/6528)
Epoch: 112 | Batch_idx: 60 |  Loss: (0.1825) |  Loss2: (0.0000) | Acc: (93.00%) (7316/7808)
Epoch: 112 | Batch_idx: 70 |  Loss: (0.1844) |  Loss2: (0.0000) | Acc: (93.00%) (8508/9088)
Epoch: 112 | Batch_idx: 80 |  Loss: (0.1839) |  Loss2: (0.0000) | Acc: (93.00%) (9701/10368)
Epoch: 112 | Batch_idx: 90 |  Loss: (0.1838) |  Loss2: (0.0000) | Acc: (93.00%) (10897/11648)
Epoch: 112 | Batch_idx: 100 |  Loss: (0.1860) |  Loss2: (0.0000) | Acc: (93.00%) (12096/12928)
Epoch: 112 | Batch_idx: 110 |  Loss: (0.1870) |  Loss2: (0.0000) | Acc: (93.00%) (13282/14208)
Epoch: 112 | Batch_idx: 120 |  Loss: (0.1887) |  Loss2: (0.0000) | Acc: (93.00%) (14468/15488)
Epoch: 112 | Batch_idx: 130 |  Loss: (0.1875) |  Loss2: (0.0000) | Acc: (93.00%) (15668/16768)
Epoch: 112 | Batch_idx: 140 |  Loss: (0.1854) |  Loss2: (0.0000) | Acc: (93.00%) (16870/18048)
Epoch: 112 | Batch_idx: 150 |  Loss: (0.1847) |  Loss2: (0.0000) | Acc: (93.00%) (18076/19328)
Epoch: 112 | Batch_idx: 160 |  Loss: (0.1850) |  Loss2: (0.0000) | Acc: (93.00%) (19279/20608)
Epoch: 112 | Batch_idx: 170 |  Loss: (0.1846) |  Loss2: (0.0000) | Acc: (93.00%) (20487/21888)
Epoch: 112 | Batch_idx: 180 |  Loss: (0.1848) |  Loss2: (0.0000) | Acc: (93.00%) (21689/23168)
Epoch: 112 | Batch_idx: 190 |  Loss: (0.1847) |  Loss2: (0.0000) | Acc: (93.00%) (22888/24448)
Epoch: 112 | Batch_idx: 200 |  Loss: (0.1856) |  Loss2: (0.0000) | Acc: (93.00%) (24075/25728)
Epoch: 112 | Batch_idx: 210 |  Loss: (0.1859) |  Loss2: (0.0000) | Acc: (93.00%) (25268/27008)
Epoch: 112 | Batch_idx: 220 |  Loss: (0.1848) |  Loss2: (0.0000) | Acc: (93.00%) (26480/28288)
Epoch: 112 | Batch_idx: 230 |  Loss: (0.1856) |  Loss2: (0.0000) | Acc: (93.00%) (27674/29568)
Epoch: 112 | Batch_idx: 240 |  Loss: (0.1860) |  Loss2: (0.0000) | Acc: (93.00%) (28873/30848)
Epoch: 112 | Batch_idx: 250 |  Loss: (0.1863) |  Loss2: (0.0000) | Acc: (93.00%) (30067/32128)
Epoch: 112 | Batch_idx: 260 |  Loss: (0.1872) |  Loss2: (0.0000) | Acc: (93.00%) (31253/33408)
Epoch: 112 | Batch_idx: 270 |  Loss: (0.1871) |  Loss2: (0.0000) | Acc: (93.00%) (32453/34688)
Epoch: 112 | Batch_idx: 280 |  Loss: (0.1862) |  Loss2: (0.0000) | Acc: (93.00%) (33662/35968)
Epoch: 112 | Batch_idx: 290 |  Loss: (0.1867) |  Loss2: (0.0000) | Acc: (93.00%) (34851/37248)
Epoch: 112 | Batch_idx: 300 |  Loss: (0.1861) |  Loss2: (0.0000) | Acc: (93.00%) (36054/38528)
Epoch: 112 | Batch_idx: 310 |  Loss: (0.1866) |  Loss2: (0.0000) | Acc: (93.00%) (37251/39808)
Epoch: 112 | Batch_idx: 320 |  Loss: (0.1879) |  Loss2: (0.0000) | Acc: (93.00%) (38432/41088)
Epoch: 112 | Batch_idx: 330 |  Loss: (0.1884) |  Loss2: (0.0000) | Acc: (93.00%) (39615/42368)
Epoch: 112 | Batch_idx: 340 |  Loss: (0.1889) |  Loss2: (0.0000) | Acc: (93.00%) (40792/43648)
Epoch: 112 | Batch_idx: 350 |  Loss: (0.1890) |  Loss2: (0.0000) | Acc: (93.00%) (41989/44928)
Epoch: 112 | Batch_idx: 360 |  Loss: (0.1891) |  Loss2: (0.0000) | Acc: (93.00%) (43179/46208)
Epoch: 112 | Batch_idx: 370 |  Loss: (0.1892) |  Loss2: (0.0000) | Acc: (93.00%) (44382/47488)
Epoch: 112 | Batch_idx: 380 |  Loss: (0.1891) |  Loss2: (0.0000) | Acc: (93.00%) (45573/48768)
Epoch: 112 | Batch_idx: 390 |  Loss: (0.1897) |  Loss2: (0.0000) | Acc: (93.00%) (46721/50000)
# TEST : Loss: (0.3869) | Acc: (87.00%) (8743/10000)
percent tensor([0.5201, 0.5216, 0.5191, 0.5220, 0.5209, 0.5267, 0.5220, 0.5223, 0.5197,
        0.5194, 0.5203, 0.5192, 0.5198, 0.5223, 0.5228, 0.5220],
       device='cuda:0') torch.Size([16])
percent tensor([0.5120, 0.5157, 0.5084, 0.5143, 0.5081, 0.5168, 0.5105, 0.5061, 0.5133,
        0.5131, 0.5148, 0.5118, 0.5174, 0.5147, 0.5150, 0.5161],
       device='cuda:0') torch.Size([16])
percent tensor([0.5799, 0.5301, 0.6178, 0.6356, 0.6333, 0.6164, 0.5776, 0.6111, 0.6063,
        0.5716, 0.5996, 0.5830, 0.5005, 0.6271, 0.5688, 0.5870],
       device='cuda:0') torch.Size([16])
percent tensor([0.6249, 0.6296, 0.6169, 0.6171, 0.6211, 0.6234, 0.6312, 0.6224, 0.6342,
        0.6316, 0.6371, 0.6324, 0.6304, 0.6314, 0.6323, 0.6318],
       device='cuda:0') torch.Size([16])
percent tensor([0.5916, 0.5925, 0.6036, 0.6178, 0.6209, 0.6704, 0.5847, 0.5790, 0.6148,
        0.6208, 0.5965, 0.5876, 0.6049, 0.6240, 0.5750, 0.6371],
       device='cuda:0') torch.Size([16])
percent tensor([0.6198, 0.6541, 0.6421, 0.6720, 0.6437, 0.7040, 0.6493, 0.5758, 0.6694,
        0.6385, 0.6996, 0.6403, 0.6800, 0.6963, 0.5810, 0.6495],
       device='cuda:0') torch.Size([16])
percent tensor([0.6451, 0.6289, 0.6708, 0.7068, 0.6956, 0.6992, 0.6662, 0.6748, 0.6316,
        0.6203, 0.6340, 0.6115, 0.6357, 0.6148, 0.5995, 0.6685],
       device='cuda:0') torch.Size([16])
percent tensor([0.9998, 0.9992, 0.9995, 0.9996, 0.9994, 0.9988, 0.9995, 0.9997, 0.9997,
        0.9994, 0.9998, 0.9994, 0.9998, 0.9996, 0.9991, 0.9996],
       device='cuda:0') torch.Size([16])
Epoch: 113 | Batch_idx: 0 |  Loss: (0.1269) |  Loss2: (0.0000) | Acc: (96.00%) (123/128)
Epoch: 113 | Batch_idx: 10 |  Loss: (0.1689) |  Loss2: (0.0000) | Acc: (93.00%) (1321/1408)
Epoch: 113 | Batch_idx: 20 |  Loss: (0.1728) |  Loss2: (0.0000) | Acc: (93.00%) (2522/2688)
Epoch: 113 | Batch_idx: 30 |  Loss: (0.1718) |  Loss2: (0.0000) | Acc: (94.00%) (3733/3968)
Epoch: 113 | Batch_idx: 40 |  Loss: (0.1735) |  Loss2: (0.0000) | Acc: (94.00%) (4941/5248)
Epoch: 113 | Batch_idx: 50 |  Loss: (0.1793) |  Loss2: (0.0000) | Acc: (93.00%) (6124/6528)
Epoch: 113 | Batch_idx: 60 |  Loss: (0.1785) |  Loss2: (0.0000) | Acc: (93.00%) (7330/7808)
Epoch: 113 | Batch_idx: 70 |  Loss: (0.1816) |  Loss2: (0.0000) | Acc: (93.00%) (8520/9088)
Epoch: 113 | Batch_idx: 80 |  Loss: (0.1818) |  Loss2: (0.0000) | Acc: (93.00%) (9728/10368)
Epoch: 113 | Batch_idx: 90 |  Loss: (0.1814) |  Loss2: (0.0000) | Acc: (93.00%) (10930/11648)
Epoch: 113 | Batch_idx: 100 |  Loss: (0.1800) |  Loss2: (0.0000) | Acc: (93.00%) (12134/12928)
Epoch: 113 | Batch_idx: 110 |  Loss: (0.1811) |  Loss2: (0.0000) | Acc: (93.00%) (13329/14208)
Epoch: 113 | Batch_idx: 120 |  Loss: (0.1812) |  Loss2: (0.0000) | Acc: (93.00%) (14526/15488)
Epoch: 113 | Batch_idx: 130 |  Loss: (0.1812) |  Loss2: (0.0000) | Acc: (93.00%) (15733/16768)
Epoch: 113 | Batch_idx: 140 |  Loss: (0.1818) |  Loss2: (0.0000) | Acc: (93.00%) (16928/18048)
Epoch: 113 | Batch_idx: 150 |  Loss: (0.1830) |  Loss2: (0.0000) | Acc: (93.00%) (18123/19328)
Epoch: 113 | Batch_idx: 160 |  Loss: (0.1826) |  Loss2: (0.0000) | Acc: (93.00%) (19311/20608)
Epoch: 113 | Batch_idx: 170 |  Loss: (0.1829) |  Loss2: (0.0000) | Acc: (93.00%) (20514/21888)
Epoch: 113 | Batch_idx: 180 |  Loss: (0.1830) |  Loss2: (0.0000) | Acc: (93.00%) (21710/23168)
Epoch: 113 | Batch_idx: 190 |  Loss: (0.1841) |  Loss2: (0.0000) | Acc: (93.00%) (22899/24448)
Epoch: 113 | Batch_idx: 200 |  Loss: (0.1849) |  Loss2: (0.0000) | Acc: (93.00%) (24089/25728)
Epoch: 113 | Batch_idx: 210 |  Loss: (0.1855) |  Loss2: (0.0000) | Acc: (93.00%) (25289/27008)
Epoch: 113 | Batch_idx: 220 |  Loss: (0.1857) |  Loss2: (0.0000) | Acc: (93.00%) (26482/28288)
Epoch: 113 | Batch_idx: 230 |  Loss: (0.1850) |  Loss2: (0.0000) | Acc: (93.00%) (27686/29568)
Epoch: 113 | Batch_idx: 240 |  Loss: (0.1867) |  Loss2: (0.0000) | Acc: (93.00%) (28858/30848)
Epoch: 113 | Batch_idx: 250 |  Loss: (0.1866) |  Loss2: (0.0000) | Acc: (93.00%) (30050/32128)
Epoch: 113 | Batch_idx: 260 |  Loss: (0.1864) |  Loss2: (0.0000) | Acc: (93.00%) (31246/33408)
Epoch: 113 | Batch_idx: 270 |  Loss: (0.1863) |  Loss2: (0.0000) | Acc: (93.00%) (32440/34688)
Epoch: 113 | Batch_idx: 280 |  Loss: (0.1867) |  Loss2: (0.0000) | Acc: (93.00%) (33641/35968)
Epoch: 113 | Batch_idx: 290 |  Loss: (0.1874) |  Loss2: (0.0000) | Acc: (93.00%) (34832/37248)
Epoch: 113 | Batch_idx: 300 |  Loss: (0.1868) |  Loss2: (0.0000) | Acc: (93.00%) (36029/38528)
Epoch: 113 | Batch_idx: 310 |  Loss: (0.1862) |  Loss2: (0.0000) | Acc: (93.00%) (37233/39808)
Epoch: 113 | Batch_idx: 320 |  Loss: (0.1869) |  Loss2: (0.0000) | Acc: (93.00%) (38417/41088)
Epoch: 113 | Batch_idx: 330 |  Loss: (0.1873) |  Loss2: (0.0000) | Acc: (93.00%) (39600/42368)
Epoch: 113 | Batch_idx: 340 |  Loss: (0.1879) |  Loss2: (0.0000) | Acc: (93.00%) (40792/43648)
Epoch: 113 | Batch_idx: 350 |  Loss: (0.1887) |  Loss2: (0.0000) | Acc: (93.00%) (41975/44928)
Epoch: 113 | Batch_idx: 360 |  Loss: (0.1883) |  Loss2: (0.0000) | Acc: (93.00%) (43178/46208)
Epoch: 113 | Batch_idx: 370 |  Loss: (0.1883) |  Loss2: (0.0000) | Acc: (93.00%) (44376/47488)
Epoch: 113 | Batch_idx: 380 |  Loss: (0.1889) |  Loss2: (0.0000) | Acc: (93.00%) (45568/48768)
Epoch: 113 | Batch_idx: 390 |  Loss: (0.1885) |  Loss2: (0.0000) | Acc: (93.00%) (46730/50000)
# TEST : Loss: (0.4258) | Acc: (86.00%) (8689/10000)
percent tensor([0.5197, 0.5219, 0.5177, 0.5226, 0.5202, 0.5269, 0.5217, 0.5222, 0.5195,
        0.5193, 0.5203, 0.5181, 0.5197, 0.5233, 0.5231, 0.5223],
       device='cuda:0') torch.Size([16])
percent tensor([0.5123, 0.5147, 0.5106, 0.5145, 0.5101, 0.5175, 0.5103, 0.5070, 0.5126,
        0.5131, 0.5146, 0.5136, 0.5171, 0.5116, 0.5157, 0.5163],
       device='cuda:0') torch.Size([16])
percent tensor([0.5792, 0.5389, 0.6196, 0.6443, 0.6372, 0.6184, 0.5831, 0.6150, 0.6158,
        0.5746, 0.6001, 0.5818, 0.5054, 0.6416, 0.5768, 0.5872],
       device='cuda:0') torch.Size([16])
percent tensor([0.6260, 0.6254, 0.6201, 0.6193, 0.6227, 0.6235, 0.6276, 0.6222, 0.6319,
        0.6314, 0.6362, 0.6345, 0.6289, 0.6280, 0.6310, 0.6307],
       device='cuda:0') torch.Size([16])
percent tensor([0.5987, 0.5900, 0.6075, 0.6280, 0.6349, 0.6899, 0.5794, 0.5815, 0.6264,
        0.6154, 0.5971, 0.5901, 0.5974, 0.6328, 0.5849, 0.6406],
       device='cuda:0') torch.Size([16])
percent tensor([0.6266, 0.6522, 0.6391, 0.6751, 0.6523, 0.7237, 0.6442, 0.5685, 0.6782,
        0.6359, 0.6981, 0.6385, 0.6798, 0.6947, 0.5944, 0.6564],
       device='cuda:0') torch.Size([16])
percent tensor([0.6419, 0.6340, 0.6628, 0.6818, 0.6877, 0.7027, 0.6693, 0.6570, 0.6366,
        0.6250, 0.6324, 0.6089, 0.6439, 0.6235, 0.5966, 0.6605],
       device='cuda:0') torch.Size([16])
percent tensor([0.9998, 0.9991, 0.9994, 0.9994, 0.9993, 0.9983, 0.9995, 0.9994, 0.9996,
        0.9995, 0.9997, 0.9996, 0.9998, 0.9993, 0.9989, 0.9995],
       device='cuda:0') torch.Size([16])
False Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=128, out_features=16, bias=False)
True Linear(in_features=16, out_features=2, bias=False)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=128, out_features=16, bias=False)
True Linear(in_features=16, out_features=2, bias=False)
False Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=256, out_features=32, bias=False)
True Linear(in_features=32, out_features=2, bias=False)
False Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=256, out_features=32, bias=False)
True Linear(in_features=32, out_features=2, bias=False)
False Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=512, out_features=64, bias=False)
True Linear(in_features=64, out_features=2, bias=False)
False Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=512, out_features=64, bias=False)
True Linear(in_features=64, out_features=2, bias=False)
False Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1024, out_features=128, bias=False)
True Linear(in_features=128, out_features=2, bias=False)
False Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1024, out_features=128, bias=False)
True Linear(in_features=128, out_features=2, bias=False)
False Linear(in_features=512, out_features=10, bias=True)
Epoch: 114 | Batch_idx: 0 |  Loss: (0.1015) |  Loss2: (0.0000) | Acc: (97.00%) (125/128)
Epoch: 114 | Batch_idx: 10 |  Loss: (0.1710) |  Loss2: (0.0000) | Acc: (94.00%) (1331/1408)
Epoch: 114 | Batch_idx: 20 |  Loss: (0.1841) |  Loss2: (0.0000) | Acc: (93.00%) (2515/2688)
Epoch: 114 | Batch_idx: 30 |  Loss: (0.1951) |  Loss2: (0.0000) | Acc: (93.00%) (3702/3968)
Epoch: 114 | Batch_idx: 40 |  Loss: (0.2052) |  Loss2: (0.0000) | Acc: (92.00%) (4876/5248)
Epoch: 114 | Batch_idx: 50 |  Loss: (0.2108) |  Loss2: (0.0000) | Acc: (92.00%) (6056/6528)
Epoch: 114 | Batch_idx: 60 |  Loss: (0.2167) |  Loss2: (0.0000) | Acc: (92.00%) (7225/7808)
Epoch: 114 | Batch_idx: 70 |  Loss: (0.2134) |  Loss2: (0.0000) | Acc: (92.00%) (8425/9088)
Epoch: 114 | Batch_idx: 80 |  Loss: (0.2151) |  Loss2: (0.0000) | Acc: (92.00%) (9605/10368)
Epoch: 114 | Batch_idx: 90 |  Loss: (0.2162) |  Loss2: (0.0000) | Acc: (92.00%) (10777/11648)
Epoch: 114 | Batch_idx: 100 |  Loss: (0.2152) |  Loss2: (0.0000) | Acc: (92.00%) (11977/12928)
Epoch: 114 | Batch_idx: 110 |  Loss: (0.2166) |  Loss2: (0.0000) | Acc: (92.00%) (13157/14208)
Epoch: 114 | Batch_idx: 120 |  Loss: (0.2165) |  Loss2: (0.0000) | Acc: (92.00%) (14344/15488)
Epoch: 114 | Batch_idx: 130 |  Loss: (0.2179) |  Loss2: (0.0000) | Acc: (92.00%) (15517/16768)
Epoch: 114 | Batch_idx: 140 |  Loss: (0.2170) |  Loss2: (0.0000) | Acc: (92.00%) (16713/18048)
Epoch: 114 | Batch_idx: 150 |  Loss: (0.2165) |  Loss2: (0.0000) | Acc: (92.00%) (17897/19328)
Epoch: 114 | Batch_idx: 160 |  Loss: (0.2157) |  Loss2: (0.0000) | Acc: (92.00%) (19086/20608)
Epoch: 114 | Batch_idx: 170 |  Loss: (0.2146) |  Loss2: (0.0000) | Acc: (92.00%) (20272/21888)
Epoch: 114 | Batch_idx: 180 |  Loss: (0.2152) |  Loss2: (0.0000) | Acc: (92.00%) (21456/23168)
Epoch: 114 | Batch_idx: 190 |  Loss: (0.2153) |  Loss2: (0.0000) | Acc: (92.00%) (22643/24448)
Epoch: 114 | Batch_idx: 200 |  Loss: (0.2141) |  Loss2: (0.0000) | Acc: (92.00%) (23837/25728)
Epoch: 114 | Batch_idx: 210 |  Loss: (0.2139) |  Loss2: (0.0000) | Acc: (92.00%) (25019/27008)
Epoch: 114 | Batch_idx: 220 |  Loss: (0.2131) |  Loss2: (0.0000) | Acc: (92.00%) (26219/28288)
Epoch: 114 | Batch_idx: 230 |  Loss: (0.2130) |  Loss2: (0.0000) | Acc: (92.00%) (27403/29568)
Epoch: 114 | Batch_idx: 240 |  Loss: (0.2124) |  Loss2: (0.0000) | Acc: (92.00%) (28597/30848)
Epoch: 114 | Batch_idx: 250 |  Loss: (0.2123) |  Loss2: (0.0000) | Acc: (92.00%) (29787/32128)
Epoch: 114 | Batch_idx: 260 |  Loss: (0.2122) |  Loss2: (0.0000) | Acc: (92.00%) (30972/33408)
Epoch: 114 | Batch_idx: 270 |  Loss: (0.2119) |  Loss2: (0.0000) | Acc: (92.00%) (32163/34688)
Epoch: 114 | Batch_idx: 280 |  Loss: (0.2117) |  Loss2: (0.0000) | Acc: (92.00%) (33360/35968)
Epoch: 114 | Batch_idx: 290 |  Loss: (0.2107) |  Loss2: (0.0000) | Acc: (92.00%) (34558/37248)
Epoch: 114 | Batch_idx: 300 |  Loss: (0.2100) |  Loss2: (0.0000) | Acc: (92.00%) (35755/38528)
Epoch: 114 | Batch_idx: 310 |  Loss: (0.2083) |  Loss2: (0.0000) | Acc: (92.00%) (36964/39808)
Epoch: 114 | Batch_idx: 320 |  Loss: (0.2077) |  Loss2: (0.0000) | Acc: (92.00%) (38160/41088)
Epoch: 114 | Batch_idx: 330 |  Loss: (0.2073) |  Loss2: (0.0000) | Acc: (92.00%) (39361/42368)
Epoch: 114 | Batch_idx: 340 |  Loss: (0.2068) |  Loss2: (0.0000) | Acc: (92.00%) (40556/43648)
Epoch: 114 | Batch_idx: 350 |  Loss: (0.2067) |  Loss2: (0.0000) | Acc: (92.00%) (41743/44928)
Epoch: 114 | Batch_idx: 360 |  Loss: (0.2058) |  Loss2: (0.0000) | Acc: (92.00%) (42942/46208)
Epoch: 114 | Batch_idx: 370 |  Loss: (0.2052) |  Loss2: (0.0000) | Acc: (92.00%) (44141/47488)
Epoch: 114 | Batch_idx: 380 |  Loss: (0.2047) |  Loss2: (0.0000) | Acc: (92.00%) (45336/48768)
Epoch: 114 | Batch_idx: 390 |  Loss: (0.2049) |  Loss2: (0.0000) | Acc: (92.00%) (46483/50000)
# TEST : Loss: (0.4016) | Acc: (87.00%) (8737/10000)
percent tensor([0.5151, 0.5170, 0.5121, 0.5179, 0.5145, 0.5224, 0.5163, 0.5168, 0.5149,
        0.5145, 0.5159, 0.5124, 0.5150, 0.5193, 0.5181, 0.5179],
       device='cuda:0') torch.Size([16])
percent tensor([0.5165, 0.5213, 0.5119, 0.5167, 0.5122, 0.5220, 0.5150, 0.5091, 0.5174,
        0.5186, 0.5209, 0.5167, 0.5231, 0.5171, 0.5215, 0.5221],
       device='cuda:0') torch.Size([16])
percent tensor([0.5899, 0.5556, 0.6197, 0.6416, 0.6342, 0.6253, 0.5910, 0.6142, 0.6214,
        0.5885, 0.6145, 0.5891, 0.5253, 0.6408, 0.5872, 0.5998],
       device='cuda:0') torch.Size([16])
percent tensor([0.6236, 0.6225, 0.6179, 0.6189, 0.6209, 0.6245, 0.6242, 0.6192, 0.6297,
        0.6276, 0.6330, 0.6312, 0.6256, 0.6255, 0.6284, 0.6293],
       device='cuda:0') torch.Size([16])
percent tensor([0.5932, 0.5914, 0.5917, 0.6042, 0.6141, 0.6860, 0.5722, 0.5619, 0.6175,
        0.6152, 0.5983, 0.5795, 0.5954, 0.6254, 0.5832, 0.6383],
       device='cuda:0') torch.Size([16])
percent tensor([0.6537, 0.6654, 0.6689, 0.7023, 0.6881, 0.7440, 0.6674, 0.6158, 0.6981,
        0.6529, 0.7142, 0.6635, 0.6919, 0.7093, 0.6164, 0.6826],
       device='cuda:0') torch.Size([16])
percent tensor([0.6528, 0.6372, 0.6768, 0.7120, 0.7198, 0.6891, 0.6842, 0.7119, 0.6262,
        0.6365, 0.6384, 0.6288, 0.6164, 0.6365, 0.6161, 0.6788],
       device='cuda:0') torch.Size([16])
percent tensor([0.9998, 0.9993, 0.9994, 0.9995, 0.9993, 0.9984, 0.9994, 0.9995, 0.9995,
        0.9997, 0.9997, 0.9996, 0.9998, 0.9994, 0.9989, 0.9995],
       device='cuda:0') torch.Size([16])
Epoch: 115 | Batch_idx: 0 |  Loss: (0.1129) |  Loss2: (0.0000) | Acc: (97.00%) (125/128)
Epoch: 115 | Batch_idx: 10 |  Loss: (0.1711) |  Loss2: (0.0000) | Acc: (93.00%) (1323/1408)
Epoch: 115 | Batch_idx: 20 |  Loss: (0.1795) |  Loss2: (0.0000) | Acc: (93.00%) (2520/2688)
Epoch: 115 | Batch_idx: 30 |  Loss: (0.1779) |  Loss2: (0.0000) | Acc: (93.00%) (3729/3968)
Epoch: 115 | Batch_idx: 40 |  Loss: (0.1818) |  Loss2: (0.0000) | Acc: (93.00%) (4925/5248)
Epoch: 115 | Batch_idx: 50 |  Loss: (0.1909) |  Loss2: (0.0000) | Acc: (93.00%) (6105/6528)
Epoch: 115 | Batch_idx: 60 |  Loss: (0.1912) |  Loss2: (0.0000) | Acc: (93.00%) (7304/7808)
Epoch: 115 | Batch_idx: 70 |  Loss: (0.1889) |  Loss2: (0.0000) | Acc: (93.00%) (8510/9088)
Epoch: 115 | Batch_idx: 80 |  Loss: (0.1880) |  Loss2: (0.0000) | Acc: (93.00%) (9714/10368)
Epoch: 115 | Batch_idx: 90 |  Loss: (0.1865) |  Loss2: (0.0000) | Acc: (93.00%) (10921/11648)
Epoch: 115 | Batch_idx: 100 |  Loss: (0.1875) |  Loss2: (0.0000) | Acc: (93.00%) (12118/12928)
Epoch: 115 | Batch_idx: 110 |  Loss: (0.1906) |  Loss2: (0.0000) | Acc: (93.00%) (13298/14208)
Epoch: 115 | Batch_idx: 120 |  Loss: (0.1900) |  Loss2: (0.0000) | Acc: (93.00%) (14502/15488)
Epoch: 115 | Batch_idx: 130 |  Loss: (0.1889) |  Loss2: (0.0000) | Acc: (93.00%) (15705/16768)
Epoch: 115 | Batch_idx: 140 |  Loss: (0.1877) |  Loss2: (0.0000) | Acc: (93.00%) (16904/18048)
Epoch: 115 | Batch_idx: 150 |  Loss: (0.1874) |  Loss2: (0.0000) | Acc: (93.00%) (18099/19328)
Epoch: 115 | Batch_idx: 160 |  Loss: (0.1877) |  Loss2: (0.0000) | Acc: (93.00%) (19300/20608)
Epoch: 115 | Batch_idx: 170 |  Loss: (0.1868) |  Loss2: (0.0000) | Acc: (93.00%) (20505/21888)
Epoch: 115 | Batch_idx: 180 |  Loss: (0.1863) |  Loss2: (0.0000) | Acc: (93.00%) (21705/23168)
Epoch: 115 | Batch_idx: 190 |  Loss: (0.1859) |  Loss2: (0.0000) | Acc: (93.00%) (22908/24448)
Epoch: 115 | Batch_idx: 200 |  Loss: (0.1859) |  Loss2: (0.0000) | Acc: (93.00%) (24111/25728)
Epoch: 115 | Batch_idx: 210 |  Loss: (0.1868) |  Loss2: (0.0000) | Acc: (93.00%) (25299/27008)
Epoch: 115 | Batch_idx: 220 |  Loss: (0.1874) |  Loss2: (0.0000) | Acc: (93.00%) (26481/28288)
Epoch: 115 | Batch_idx: 230 |  Loss: (0.1877) |  Loss2: (0.0000) | Acc: (93.00%) (27675/29568)
Epoch: 115 | Batch_idx: 240 |  Loss: (0.1877) |  Loss2: (0.0000) | Acc: (93.00%) (28866/30848)
Epoch: 115 | Batch_idx: 250 |  Loss: (0.1864) |  Loss2: (0.0000) | Acc: (93.00%) (30079/32128)
Epoch: 115 | Batch_idx: 260 |  Loss: (0.1856) |  Loss2: (0.0000) | Acc: (93.00%) (31283/33408)
Epoch: 115 | Batch_idx: 270 |  Loss: (0.1854) |  Loss2: (0.0000) | Acc: (93.00%) (32485/34688)
Epoch: 115 | Batch_idx: 280 |  Loss: (0.1852) |  Loss2: (0.0000) | Acc: (93.00%) (33670/35968)
Epoch: 115 | Batch_idx: 290 |  Loss: (0.1864) |  Loss2: (0.0000) | Acc: (93.00%) (34850/37248)
Epoch: 115 | Batch_idx: 300 |  Loss: (0.1862) |  Loss2: (0.0000) | Acc: (93.00%) (36051/38528)
Epoch: 115 | Batch_idx: 310 |  Loss: (0.1863) |  Loss2: (0.0000) | Acc: (93.00%) (37251/39808)
Epoch: 115 | Batch_idx: 320 |  Loss: (0.1856) |  Loss2: (0.0000) | Acc: (93.00%) (38463/41088)
Epoch: 115 | Batch_idx: 330 |  Loss: (0.1857) |  Loss2: (0.0000) | Acc: (93.00%) (39661/42368)
Epoch: 115 | Batch_idx: 340 |  Loss: (0.1854) |  Loss2: (0.0000) | Acc: (93.00%) (40858/43648)
Epoch: 115 | Batch_idx: 350 |  Loss: (0.1844) |  Loss2: (0.0000) | Acc: (93.00%) (42071/44928)
Epoch: 115 | Batch_idx: 360 |  Loss: (0.1844) |  Loss2: (0.0000) | Acc: (93.00%) (43272/46208)
Epoch: 115 | Batch_idx: 370 |  Loss: (0.1838) |  Loss2: (0.0000) | Acc: (93.00%) (44477/47488)
Epoch: 115 | Batch_idx: 380 |  Loss: (0.1837) |  Loss2: (0.0000) | Acc: (93.00%) (45684/48768)
Epoch: 115 | Batch_idx: 390 |  Loss: (0.1835) |  Loss2: (0.0000) | Acc: (93.00%) (46843/50000)
=> saving checkpoint 'drive/app/torch/save_Schedule/checkpoint_115.pth.tar'
# TEST : Loss: (0.3833) | Acc: (87.00%) (8783/10000)
percent tensor([0.5169, 0.5191, 0.5136, 0.5197, 0.5163, 0.5245, 0.5182, 0.5187, 0.5166,
        0.5164, 0.5177, 0.5141, 0.5168, 0.5213, 0.5202, 0.5199],
       device='cuda:0') torch.Size([16])
percent tensor([0.5183, 0.5234, 0.5131, 0.5179, 0.5131, 0.5240, 0.5167, 0.5101, 0.5188,
        0.5205, 0.5229, 0.5184, 0.5256, 0.5188, 0.5234, 0.5245],
       device='cuda:0') torch.Size([16])
percent tensor([0.5893, 0.5471, 0.6241, 0.6450, 0.6373, 0.6244, 0.5866, 0.6185, 0.6202,
        0.5834, 0.6088, 0.5874, 0.5203, 0.6377, 0.5818, 0.5985],
       device='cuda:0') torch.Size([16])
percent tensor([0.6248, 0.6218, 0.6202, 0.6217, 0.6243, 0.6286, 0.6254, 0.6224, 0.6310,
        0.6267, 0.6320, 0.6312, 0.6242, 0.6264, 0.6294, 0.6308],
       device='cuda:0') torch.Size([16])
percent tensor([0.5952, 0.5891, 0.5964, 0.6146, 0.6204, 0.7022, 0.5689, 0.5614, 0.6199,
        0.6138, 0.5960, 0.5830, 0.5962, 0.6253, 0.5865, 0.6455],
       device='cuda:0') torch.Size([16])
percent tensor([0.6506, 0.6629, 0.6719, 0.7053, 0.6930, 0.7440, 0.6659, 0.6194, 0.6956,
        0.6511, 0.7106, 0.6617, 0.6907, 0.7039, 0.6115, 0.6824],
       device='cuda:0') torch.Size([16])
percent tensor([0.6587, 0.6454, 0.6812, 0.7241, 0.7289, 0.6809, 0.6935, 0.7280, 0.6285,
        0.6458, 0.6481, 0.6386, 0.6142, 0.6427, 0.6275, 0.6886],
       device='cuda:0') torch.Size([16])
percent tensor([0.9998, 0.9993, 0.9995, 0.9995, 0.9994, 0.9984, 0.9994, 0.9995, 0.9996,
        0.9996, 0.9997, 0.9996, 0.9998, 0.9994, 0.9989, 0.9995],
       device='cuda:0') torch.Size([16])
Epoch: 116 | Batch_idx: 0 |  Loss: (0.1824) |  Loss2: (0.0000) | Acc: (90.00%) (116/128)
Epoch: 116 | Batch_idx: 10 |  Loss: (0.1765) |  Loss2: (0.0000) | Acc: (93.00%) (1318/1408)
Epoch: 116 | Batch_idx: 20 |  Loss: (0.1821) |  Loss2: (0.0000) | Acc: (93.00%) (2518/2688)
Epoch: 116 | Batch_idx: 30 |  Loss: (0.1781) |  Loss2: (0.0000) | Acc: (94.00%) (3734/3968)
Epoch: 116 | Batch_idx: 40 |  Loss: (0.1729) |  Loss2: (0.0000) | Acc: (94.00%) (4944/5248)
Epoch: 116 | Batch_idx: 50 |  Loss: (0.1777) |  Loss2: (0.0000) | Acc: (93.00%) (6133/6528)
Epoch: 116 | Batch_idx: 60 |  Loss: (0.1809) |  Loss2: (0.0000) | Acc: (93.00%) (7326/7808)
Epoch: 116 | Batch_idx: 70 |  Loss: (0.1801) |  Loss2: (0.0000) | Acc: (93.00%) (8527/9088)
Epoch: 116 | Batch_idx: 80 |  Loss: (0.1782) |  Loss2: (0.0000) | Acc: (93.00%) (9736/10368)
Epoch: 116 | Batch_idx: 90 |  Loss: (0.1770) |  Loss2: (0.0000) | Acc: (93.00%) (10947/11648)
Epoch: 116 | Batch_idx: 100 |  Loss: (0.1767) |  Loss2: (0.0000) | Acc: (93.00%) (12151/12928)
Epoch: 116 | Batch_idx: 110 |  Loss: (0.1778) |  Loss2: (0.0000) | Acc: (93.00%) (13353/14208)
Epoch: 116 | Batch_idx: 120 |  Loss: (0.1765) |  Loss2: (0.0000) | Acc: (94.00%) (14566/15488)
Epoch: 116 | Batch_idx: 130 |  Loss: (0.1764) |  Loss2: (0.0000) | Acc: (94.00%) (15776/16768)
Epoch: 116 | Batch_idx: 140 |  Loss: (0.1773) |  Loss2: (0.0000) | Acc: (94.00%) (16966/18048)
Epoch: 116 | Batch_idx: 150 |  Loss: (0.1786) |  Loss2: (0.0000) | Acc: (93.00%) (18160/19328)
Epoch: 116 | Batch_idx: 160 |  Loss: (0.1799) |  Loss2: (0.0000) | Acc: (93.00%) (19352/20608)
Epoch: 116 | Batch_idx: 170 |  Loss: (0.1798) |  Loss2: (0.0000) | Acc: (93.00%) (20559/21888)
Epoch: 116 | Batch_idx: 180 |  Loss: (0.1802) |  Loss2: (0.0000) | Acc: (93.00%) (21759/23168)
Epoch: 116 | Batch_idx: 190 |  Loss: (0.1797) |  Loss2: (0.0000) | Acc: (93.00%) (22959/24448)
Epoch: 116 | Batch_idx: 200 |  Loss: (0.1787) |  Loss2: (0.0000) | Acc: (93.00%) (24176/25728)
Epoch: 116 | Batch_idx: 210 |  Loss: (0.1782) |  Loss2: (0.0000) | Acc: (93.00%) (25383/27008)
Epoch: 116 | Batch_idx: 220 |  Loss: (0.1782) |  Loss2: (0.0000) | Acc: (94.00%) (26592/28288)
Epoch: 116 | Batch_idx: 230 |  Loss: (0.1785) |  Loss2: (0.0000) | Acc: (93.00%) (27790/29568)
Epoch: 116 | Batch_idx: 240 |  Loss: (0.1778) |  Loss2: (0.0000) | Acc: (93.00%) (28995/30848)
Epoch: 116 | Batch_idx: 250 |  Loss: (0.1773) |  Loss2: (0.0000) | Acc: (94.00%) (30202/32128)
Epoch: 116 | Batch_idx: 260 |  Loss: (0.1778) |  Loss2: (0.0000) | Acc: (93.00%) (31399/33408)
Epoch: 116 | Batch_idx: 270 |  Loss: (0.1774) |  Loss2: (0.0000) | Acc: (93.00%) (32606/34688)
Epoch: 116 | Batch_idx: 280 |  Loss: (0.1778) |  Loss2: (0.0000) | Acc: (93.00%) (33799/35968)
Epoch: 116 | Batch_idx: 290 |  Loss: (0.1774) |  Loss2: (0.0000) | Acc: (93.00%) (35011/37248)
Epoch: 116 | Batch_idx: 300 |  Loss: (0.1779) |  Loss2: (0.0000) | Acc: (93.00%) (36200/38528)
Epoch: 116 | Batch_idx: 310 |  Loss: (0.1774) |  Loss2: (0.0000) | Acc: (93.00%) (37409/39808)
Epoch: 116 | Batch_idx: 320 |  Loss: (0.1772) |  Loss2: (0.0000) | Acc: (93.00%) (38607/41088)
Epoch: 116 | Batch_idx: 330 |  Loss: (0.1774) |  Loss2: (0.0000) | Acc: (93.00%) (39799/42368)
Epoch: 116 | Batch_idx: 340 |  Loss: (0.1775) |  Loss2: (0.0000) | Acc: (93.00%) (40991/43648)
Epoch: 116 | Batch_idx: 350 |  Loss: (0.1778) |  Loss2: (0.0000) | Acc: (93.00%) (42187/44928)
Epoch: 116 | Batch_idx: 360 |  Loss: (0.1779) |  Loss2: (0.0000) | Acc: (93.00%) (43379/46208)
Epoch: 116 | Batch_idx: 370 |  Loss: (0.1783) |  Loss2: (0.0000) | Acc: (93.00%) (44580/47488)
Epoch: 116 | Batch_idx: 380 |  Loss: (0.1778) |  Loss2: (0.0000) | Acc: (93.00%) (45791/48768)
Epoch: 116 | Batch_idx: 390 |  Loss: (0.1776) |  Loss2: (0.0000) | Acc: (93.00%) (46948/50000)
# TEST : Loss: (0.3750) | Acc: (88.00%) (8812/10000)
percent tensor([0.5167, 0.5187, 0.5136, 0.5198, 0.5161, 0.5246, 0.5179, 0.5185, 0.5164,
        0.5161, 0.5175, 0.5140, 0.5166, 0.5212, 0.5201, 0.5198],
       device='cuda:0') torch.Size([16])
percent tensor([0.5195, 0.5253, 0.5142, 0.5188, 0.5141, 0.5255, 0.5182, 0.5111, 0.5200,
        0.5223, 0.5246, 0.5199, 0.5271, 0.5203, 0.5250, 0.5263],
       device='cuda:0') torch.Size([16])
percent tensor([0.5842, 0.5427, 0.6248, 0.6439, 0.6362, 0.6185, 0.5829, 0.6178, 0.6175,
        0.5807, 0.6029, 0.5867, 0.5161, 0.6337, 0.5752, 0.5944],
       device='cuda:0') torch.Size([16])
percent tensor([0.6312, 0.6273, 0.6263, 0.6287, 0.6318, 0.6374, 0.6319, 0.6296, 0.6375,
        0.6327, 0.6376, 0.6370, 0.6293, 0.6333, 0.6362, 0.6383],
       device='cuda:0') torch.Size([16])
percent tensor([0.6024, 0.5950, 0.5982, 0.6203, 0.6234, 0.7148, 0.5712, 0.5616, 0.6221,
        0.6179, 0.6008, 0.5875, 0.6004, 0.6304, 0.5939, 0.6562],
       device='cuda:0') torch.Size([16])
percent tensor([0.6548, 0.6637, 0.6770, 0.7125, 0.7005, 0.7496, 0.6690, 0.6247, 0.6972,
        0.6535, 0.7123, 0.6641, 0.6931, 0.7049, 0.6145, 0.6888],
       device='cuda:0') torch.Size([16])
percent tensor([0.6585, 0.6457, 0.6837, 0.7340, 0.7338, 0.6786, 0.6957, 0.7354, 0.6258,
        0.6479, 0.6492, 0.6438, 0.6069, 0.6427, 0.6327, 0.6908],
       device='cuda:0') torch.Size([16])
percent tensor([0.9998, 0.9993, 0.9995, 0.9995, 0.9994, 0.9984, 0.9993, 0.9995, 0.9996,
        0.9996, 0.9997, 0.9996, 0.9998, 0.9994, 0.9989, 0.9995],
       device='cuda:0') torch.Size([16])
Epoch: 117 | Batch_idx: 0 |  Loss: (0.1182) |  Loss2: (0.0000) | Acc: (96.00%) (123/128)
Epoch: 117 | Batch_idx: 10 |  Loss: (0.1578) |  Loss2: (0.0000) | Acc: (94.00%) (1329/1408)
Epoch: 117 | Batch_idx: 20 |  Loss: (0.1832) |  Loss2: (0.0000) | Acc: (93.00%) (2503/2688)
Epoch: 117 | Batch_idx: 30 |  Loss: (0.1778) |  Loss2: (0.0000) | Acc: (93.00%) (3704/3968)
Epoch: 117 | Batch_idx: 40 |  Loss: (0.1773) |  Loss2: (0.0000) | Acc: (93.00%) (4903/5248)
Epoch: 117 | Batch_idx: 50 |  Loss: (0.1824) |  Loss2: (0.0000) | Acc: (93.00%) (6094/6528)
Epoch: 117 | Batch_idx: 60 |  Loss: (0.1778) |  Loss2: (0.0000) | Acc: (93.00%) (7312/7808)
Epoch: 117 | Batch_idx: 70 |  Loss: (0.1783) |  Loss2: (0.0000) | Acc: (93.00%) (8510/9088)
Epoch: 117 | Batch_idx: 80 |  Loss: (0.1762) |  Loss2: (0.0000) | Acc: (93.00%) (9724/10368)
Epoch: 117 | Batch_idx: 90 |  Loss: (0.1731) |  Loss2: (0.0000) | Acc: (93.00%) (10940/11648)
Epoch: 117 | Batch_idx: 100 |  Loss: (0.1703) |  Loss2: (0.0000) | Acc: (94.00%) (12157/12928)
Epoch: 117 | Batch_idx: 110 |  Loss: (0.1723) |  Loss2: (0.0000) | Acc: (93.00%) (13350/14208)
Epoch: 117 | Batch_idx: 120 |  Loss: (0.1732) |  Loss2: (0.0000) | Acc: (93.00%) (14553/15488)
Epoch: 117 | Batch_idx: 130 |  Loss: (0.1742) |  Loss2: (0.0000) | Acc: (93.00%) (15744/16768)
Epoch: 117 | Batch_idx: 140 |  Loss: (0.1731) |  Loss2: (0.0000) | Acc: (93.00%) (16952/18048)
Epoch: 117 | Batch_idx: 150 |  Loss: (0.1735) |  Loss2: (0.0000) | Acc: (93.00%) (18153/19328)
Epoch: 117 | Batch_idx: 160 |  Loss: (0.1732) |  Loss2: (0.0000) | Acc: (93.00%) (19365/20608)
Epoch: 117 | Batch_idx: 170 |  Loss: (0.1748) |  Loss2: (0.0000) | Acc: (93.00%) (20558/21888)
Epoch: 117 | Batch_idx: 180 |  Loss: (0.1759) |  Loss2: (0.0000) | Acc: (93.00%) (21757/23168)
Epoch: 117 | Batch_idx: 190 |  Loss: (0.1755) |  Loss2: (0.0000) | Acc: (93.00%) (22959/24448)
Epoch: 117 | Batch_idx: 200 |  Loss: (0.1739) |  Loss2: (0.0000) | Acc: (93.00%) (24172/25728)
Epoch: 117 | Batch_idx: 210 |  Loss: (0.1742) |  Loss2: (0.0000) | Acc: (93.00%) (25377/27008)
Epoch: 117 | Batch_idx: 220 |  Loss: (0.1729) |  Loss2: (0.0000) | Acc: (94.00%) (26603/28288)
Epoch: 117 | Batch_idx: 230 |  Loss: (0.1718) |  Loss2: (0.0000) | Acc: (94.00%) (27818/29568)
Epoch: 117 | Batch_idx: 240 |  Loss: (0.1709) |  Loss2: (0.0000) | Acc: (94.00%) (29026/30848)
Epoch: 117 | Batch_idx: 250 |  Loss: (0.1701) |  Loss2: (0.0000) | Acc: (94.00%) (30250/32128)
Epoch: 117 | Batch_idx: 260 |  Loss: (0.1698) |  Loss2: (0.0000) | Acc: (94.00%) (31453/33408)
Epoch: 117 | Batch_idx: 270 |  Loss: (0.1700) |  Loss2: (0.0000) | Acc: (94.00%) (32659/34688)
Epoch: 117 | Batch_idx: 280 |  Loss: (0.1698) |  Loss2: (0.0000) | Acc: (94.00%) (33868/35968)
Epoch: 117 | Batch_idx: 290 |  Loss: (0.1695) |  Loss2: (0.0000) | Acc: (94.00%) (35075/37248)
Epoch: 117 | Batch_idx: 300 |  Loss: (0.1695) |  Loss2: (0.0000) | Acc: (94.00%) (36286/38528)
Epoch: 117 | Batch_idx: 310 |  Loss: (0.1696) |  Loss2: (0.0000) | Acc: (94.00%) (37490/39808)
Epoch: 117 | Batch_idx: 320 |  Loss: (0.1698) |  Loss2: (0.0000) | Acc: (94.00%) (38691/41088)
Epoch: 117 | Batch_idx: 330 |  Loss: (0.1709) |  Loss2: (0.0000) | Acc: (94.00%) (39892/42368)
Epoch: 117 | Batch_idx: 340 |  Loss: (0.1708) |  Loss2: (0.0000) | Acc: (94.00%) (41101/43648)
Epoch: 117 | Batch_idx: 350 |  Loss: (0.1702) |  Loss2: (0.0000) | Acc: (94.00%) (42323/44928)
Epoch: 117 | Batch_idx: 360 |  Loss: (0.1699) |  Loss2: (0.0000) | Acc: (94.00%) (43531/46208)
Epoch: 117 | Batch_idx: 370 |  Loss: (0.1703) |  Loss2: (0.0000) | Acc: (94.00%) (44732/47488)
Epoch: 117 | Batch_idx: 380 |  Loss: (0.1707) |  Loss2: (0.0000) | Acc: (94.00%) (45927/48768)
Epoch: 117 | Batch_idx: 390 |  Loss: (0.1712) |  Loss2: (0.0000) | Acc: (94.00%) (47071/50000)
# TEST : Loss: (0.3712) | Acc: (88.00%) (8821/10000)
percent tensor([0.5176, 0.5197, 0.5144, 0.5208, 0.5170, 0.5260, 0.5188, 0.5194, 0.5172,
        0.5170, 0.5184, 0.5148, 0.5175, 0.5221, 0.5213, 0.5208],
       device='cuda:0') torch.Size([16])
percent tensor([0.5212, 0.5276, 0.5160, 0.5208, 0.5158, 0.5272, 0.5203, 0.5128, 0.5218,
        0.5244, 0.5265, 0.5219, 0.5293, 0.5222, 0.5270, 0.5283],
       device='cuda:0') torch.Size([16])
percent tensor([0.5854, 0.5443, 0.6268, 0.6448, 0.6386, 0.6147, 0.5863, 0.6211, 0.6197,
        0.5829, 0.6043, 0.5888, 0.5184, 0.6353, 0.5752, 0.5943],
       device='cuda:0') torch.Size([16])
percent tensor([0.6349, 0.6305, 0.6302, 0.6332, 0.6362, 0.6427, 0.6354, 0.6337, 0.6411,
        0.6358, 0.6404, 0.6407, 0.6324, 0.6366, 0.6401, 0.6428],
       device='cuda:0') torch.Size([16])
percent tensor([0.5971, 0.5883, 0.5951, 0.6224, 0.6244, 0.7179, 0.5655, 0.5570, 0.6177,
        0.6110, 0.5951, 0.5821, 0.5933, 0.6265, 0.5905, 0.6544],
       device='cuda:0') torch.Size([16])
percent tensor([0.6510, 0.6599, 0.6759, 0.7125, 0.6996, 0.7512, 0.6659, 0.6238, 0.6940,
        0.6489, 0.7088, 0.6592, 0.6902, 0.7014, 0.6085, 0.6876],
       device='cuda:0') torch.Size([16])
percent tensor([0.6605, 0.6513, 0.6828, 0.7347, 0.7323, 0.6766, 0.6990, 0.7344, 0.6262,
        0.6521, 0.6555, 0.6454, 0.6086, 0.6459, 0.6357, 0.6920],
       device='cuda:0') torch.Size([16])
percent tensor([0.9998, 0.9993, 0.9995, 0.9996, 0.9995, 0.9985, 0.9994, 0.9995, 0.9996,
        0.9997, 0.9997, 0.9997, 0.9998, 0.9994, 0.9990, 0.9996],
       device='cuda:0') torch.Size([16])
Epoch: 118 | Batch_idx: 0 |  Loss: (0.1749) |  Loss2: (0.0000) | Acc: (95.00%) (122/128)
Epoch: 118 | Batch_idx: 10 |  Loss: (0.1588) |  Loss2: (0.0000) | Acc: (94.00%) (1336/1408)
Epoch: 118 | Batch_idx: 20 |  Loss: (0.1777) |  Loss2: (0.0000) | Acc: (94.00%) (2538/2688)
Epoch: 118 | Batch_idx: 30 |  Loss: (0.1805) |  Loss2: (0.0000) | Acc: (94.00%) (3732/3968)
Epoch: 118 | Batch_idx: 40 |  Loss: (0.1825) |  Loss2: (0.0000) | Acc: (93.00%) (4926/5248)
Epoch: 118 | Batch_idx: 50 |  Loss: (0.1813) |  Loss2: (0.0000) | Acc: (93.00%) (6132/6528)
Epoch: 118 | Batch_idx: 60 |  Loss: (0.1775) |  Loss2: (0.0000) | Acc: (94.00%) (7347/7808)
Epoch: 118 | Batch_idx: 70 |  Loss: (0.1745) |  Loss2: (0.0000) | Acc: (94.00%) (8562/9088)
Epoch: 118 | Batch_idx: 80 |  Loss: (0.1733) |  Loss2: (0.0000) | Acc: (94.00%) (9765/10368)
Epoch: 118 | Batch_idx: 90 |  Loss: (0.1731) |  Loss2: (0.0000) | Acc: (94.00%) (10968/11648)
Epoch: 118 | Batch_idx: 100 |  Loss: (0.1716) |  Loss2: (0.0000) | Acc: (94.00%) (12175/12928)
Epoch: 118 | Batch_idx: 110 |  Loss: (0.1709) |  Loss2: (0.0000) | Acc: (94.00%) (13381/14208)
Epoch: 118 | Batch_idx: 120 |  Loss: (0.1701) |  Loss2: (0.0000) | Acc: (94.00%) (14592/15488)
Epoch: 118 | Batch_idx: 130 |  Loss: (0.1712) |  Loss2: (0.0000) | Acc: (94.00%) (15785/16768)
Epoch: 118 | Batch_idx: 140 |  Loss: (0.1706) |  Loss2: (0.0000) | Acc: (94.00%) (16992/18048)
Epoch: 118 | Batch_idx: 150 |  Loss: (0.1694) |  Loss2: (0.0000) | Acc: (94.00%) (18215/19328)
Epoch: 118 | Batch_idx: 160 |  Loss: (0.1694) |  Loss2: (0.0000) | Acc: (94.00%) (19421/20608)
Epoch: 118 | Batch_idx: 170 |  Loss: (0.1688) |  Loss2: (0.0000) | Acc: (94.00%) (20631/21888)
Epoch: 118 | Batch_idx: 180 |  Loss: (0.1681) |  Loss2: (0.0000) | Acc: (94.00%) (21838/23168)
Epoch: 118 | Batch_idx: 190 |  Loss: (0.1679) |  Loss2: (0.0000) | Acc: (94.00%) (23047/24448)
Epoch: 118 | Batch_idx: 200 |  Loss: (0.1666) |  Loss2: (0.0000) | Acc: (94.00%) (24272/25728)
Epoch: 118 | Batch_idx: 210 |  Loss: (0.1673) |  Loss2: (0.0000) | Acc: (94.00%) (25472/27008)
Epoch: 118 | Batch_idx: 220 |  Loss: (0.1675) |  Loss2: (0.0000) | Acc: (94.00%) (26681/28288)
Epoch: 118 | Batch_idx: 230 |  Loss: (0.1675) |  Loss2: (0.0000) | Acc: (94.00%) (27896/29568)
Epoch: 118 | Batch_idx: 240 |  Loss: (0.1679) |  Loss2: (0.0000) | Acc: (94.00%) (29099/30848)
Epoch: 118 | Batch_idx: 250 |  Loss: (0.1682) |  Loss2: (0.0000) | Acc: (94.00%) (30305/32128)
Epoch: 118 | Batch_idx: 260 |  Loss: (0.1681) |  Loss2: (0.0000) | Acc: (94.00%) (31516/33408)
Epoch: 118 | Batch_idx: 270 |  Loss: (0.1677) |  Loss2: (0.0000) | Acc: (94.00%) (32736/34688)
Epoch: 118 | Batch_idx: 280 |  Loss: (0.1688) |  Loss2: (0.0000) | Acc: (94.00%) (33925/35968)
Epoch: 118 | Batch_idx: 290 |  Loss: (0.1685) |  Loss2: (0.0000) | Acc: (94.00%) (35134/37248)
Epoch: 118 | Batch_idx: 300 |  Loss: (0.1678) |  Loss2: (0.0000) | Acc: (94.00%) (36346/38528)
Epoch: 118 | Batch_idx: 310 |  Loss: (0.1675) |  Loss2: (0.0000) | Acc: (94.00%) (37554/39808)
Epoch: 118 | Batch_idx: 320 |  Loss: (0.1669) |  Loss2: (0.0000) | Acc: (94.00%) (38773/41088)
Epoch: 118 | Batch_idx: 330 |  Loss: (0.1671) |  Loss2: (0.0000) | Acc: (94.00%) (39976/42368)
Epoch: 118 | Batch_idx: 340 |  Loss: (0.1672) |  Loss2: (0.0000) | Acc: (94.00%) (41182/43648)
Epoch: 118 | Batch_idx: 350 |  Loss: (0.1666) |  Loss2: (0.0000) | Acc: (94.00%) (42401/44928)
Epoch: 118 | Batch_idx: 360 |  Loss: (0.1667) |  Loss2: (0.0000) | Acc: (94.00%) (43601/46208)
Epoch: 118 | Batch_idx: 370 |  Loss: (0.1671) |  Loss2: (0.0000) | Acc: (94.00%) (44796/47488)
Epoch: 118 | Batch_idx: 380 |  Loss: (0.1669) |  Loss2: (0.0000) | Acc: (94.00%) (46009/48768)
Epoch: 118 | Batch_idx: 390 |  Loss: (0.1669) |  Loss2: (0.0000) | Acc: (94.00%) (47172/50000)
# TEST : Loss: (0.3673) | Acc: (88.00%) (8831/10000)
percent tensor([0.5187, 0.5209, 0.5155, 0.5221, 0.5183, 0.5274, 0.5201, 0.5207, 0.5183,
        0.5181, 0.5195, 0.5159, 0.5187, 0.5233, 0.5226, 0.5221],
       device='cuda:0') torch.Size([16])
percent tensor([0.5214, 0.5274, 0.5162, 0.5207, 0.5157, 0.5273, 0.5201, 0.5127, 0.5216,
        0.5243, 0.5262, 0.5218, 0.5294, 0.5219, 0.5268, 0.5284],
       device='cuda:0') torch.Size([16])
percent tensor([0.5885, 0.5414, 0.6325, 0.6500, 0.6438, 0.6184, 0.5869, 0.6267, 0.6211,
        0.5825, 0.6014, 0.5922, 0.5185, 0.6341, 0.5763, 0.5968],
       device='cuda:0') torch.Size([16])
percent tensor([0.6396, 0.6336, 0.6350, 0.6381, 0.6414, 0.6490, 0.6394, 0.6387, 0.6454,
        0.6392, 0.6436, 0.6447, 0.6356, 0.6404, 0.6447, 0.6476],
       device='cuda:0') torch.Size([16])
percent tensor([0.5947, 0.5849, 0.5940, 0.6224, 0.6239, 0.7180, 0.5627, 0.5553, 0.6153,
        0.6082, 0.5928, 0.5813, 0.5898, 0.6239, 0.5892, 0.6527],
       device='cuda:0') torch.Size([16])
percent tensor([0.6456, 0.6558, 0.6738, 0.7117, 0.6975, 0.7487, 0.6618, 0.6203, 0.6905,
        0.6443, 0.7052, 0.6555, 0.6860, 0.6966, 0.6020, 0.6834],
       device='cuda:0') torch.Size([16])
percent tensor([0.6535, 0.6477, 0.6741, 0.7297, 0.7232, 0.6686, 0.6935, 0.7266, 0.6200,
        0.6484, 0.6544, 0.6369, 0.6025, 0.6398, 0.6282, 0.6837],
       device='cuda:0') torch.Size([16])
percent tensor([0.9998, 0.9994, 0.9995, 0.9996, 0.9994, 0.9987, 0.9994, 0.9995, 0.9997,
        0.9997, 0.9997, 0.9997, 0.9998, 0.9994, 0.9990, 0.9996],
       device='cuda:0') torch.Size([16])
Epoch: 119 | Batch_idx: 0 |  Loss: (0.1938) |  Loss2: (0.0000) | Acc: (90.00%) (116/128)
Epoch: 119 | Batch_idx: 10 |  Loss: (0.1556) |  Loss2: (0.0000) | Acc: (95.00%) (1338/1408)
Epoch: 119 | Batch_idx: 20 |  Loss: (0.1615) |  Loss2: (0.0000) | Acc: (94.00%) (2540/2688)
Epoch: 119 | Batch_idx: 30 |  Loss: (0.1709) |  Loss2: (0.0000) | Acc: (94.00%) (3735/3968)
Epoch: 119 | Batch_idx: 40 |  Loss: (0.1726) |  Loss2: (0.0000) | Acc: (93.00%) (4924/5248)
Epoch: 119 | Batch_idx: 50 |  Loss: (0.1692) |  Loss2: (0.0000) | Acc: (94.00%) (6142/6528)
Epoch: 119 | Batch_idx: 60 |  Loss: (0.1649) |  Loss2: (0.0000) | Acc: (94.00%) (7357/7808)
Epoch: 119 | Batch_idx: 70 |  Loss: (0.1654) |  Loss2: (0.0000) | Acc: (94.00%) (8570/9088)
Epoch: 119 | Batch_idx: 80 |  Loss: (0.1643) |  Loss2: (0.0000) | Acc: (94.00%) (9778/10368)
Epoch: 119 | Batch_idx: 90 |  Loss: (0.1650) |  Loss2: (0.0000) | Acc: (94.00%) (10982/11648)
Epoch: 119 | Batch_idx: 100 |  Loss: (0.1633) |  Loss2: (0.0000) | Acc: (94.00%) (12191/12928)
Epoch: 119 | Batch_idx: 110 |  Loss: (0.1646) |  Loss2: (0.0000) | Acc: (94.00%) (13397/14208)
Epoch: 119 | Batch_idx: 120 |  Loss: (0.1647) |  Loss2: (0.0000) | Acc: (94.00%) (14601/15488)
Epoch: 119 | Batch_idx: 130 |  Loss: (0.1643) |  Loss2: (0.0000) | Acc: (94.00%) (15808/16768)
Epoch: 119 | Batch_idx: 140 |  Loss: (0.1645) |  Loss2: (0.0000) | Acc: (94.00%) (17019/18048)
Epoch: 119 | Batch_idx: 150 |  Loss: (0.1649) |  Loss2: (0.0000) | Acc: (94.00%) (18229/19328)
Epoch: 119 | Batch_idx: 160 |  Loss: (0.1647) |  Loss2: (0.0000) | Acc: (94.00%) (19436/20608)
Epoch: 119 | Batch_idx: 170 |  Loss: (0.1638) |  Loss2: (0.0000) | Acc: (94.00%) (20656/21888)
Epoch: 119 | Batch_idx: 180 |  Loss: (0.1636) |  Loss2: (0.0000) | Acc: (94.00%) (21861/23168)
Epoch: 119 | Batch_idx: 190 |  Loss: (0.1646) |  Loss2: (0.0000) | Acc: (94.00%) (23062/24448)
Epoch: 119 | Batch_idx: 200 |  Loss: (0.1647) |  Loss2: (0.0000) | Acc: (94.00%) (24267/25728)
Epoch: 119 | Batch_idx: 210 |  Loss: (0.1646) |  Loss2: (0.0000) | Acc: (94.00%) (25470/27008)
Epoch: 119 | Batch_idx: 220 |  Loss: (0.1638) |  Loss2: (0.0000) | Acc: (94.00%) (26688/28288)
Epoch: 119 | Batch_idx: 230 |  Loss: (0.1640) |  Loss2: (0.0000) | Acc: (94.00%) (27899/29568)
Epoch: 119 | Batch_idx: 240 |  Loss: (0.1639) |  Loss2: (0.0000) | Acc: (94.00%) (29099/30848)
Epoch: 119 | Batch_idx: 250 |  Loss: (0.1647) |  Loss2: (0.0000) | Acc: (94.00%) (30291/32128)
Epoch: 119 | Batch_idx: 260 |  Loss: (0.1645) |  Loss2: (0.0000) | Acc: (94.00%) (31499/33408)
Epoch: 119 | Batch_idx: 270 |  Loss: (0.1648) |  Loss2: (0.0000) | Acc: (94.00%) (32706/34688)
Epoch: 119 | Batch_idx: 280 |  Loss: (0.1650) |  Loss2: (0.0000) | Acc: (94.00%) (33904/35968)
Epoch: 119 | Batch_idx: 290 |  Loss: (0.1659) |  Loss2: (0.0000) | Acc: (94.00%) (35101/37248)
Epoch: 119 | Batch_idx: 300 |  Loss: (0.1661) |  Loss2: (0.0000) | Acc: (94.00%) (36301/38528)
Epoch: 119 | Batch_idx: 310 |  Loss: (0.1657) |  Loss2: (0.0000) | Acc: (94.00%) (37522/39808)
Epoch: 119 | Batch_idx: 320 |  Loss: (0.1663) |  Loss2: (0.0000) | Acc: (94.00%) (38713/41088)
Epoch: 119 | Batch_idx: 330 |  Loss: (0.1663) |  Loss2: (0.0000) | Acc: (94.00%) (39920/42368)
Epoch: 119 | Batch_idx: 340 |  Loss: (0.1663) |  Loss2: (0.0000) | Acc: (94.00%) (41129/43648)
Epoch: 119 | Batch_idx: 350 |  Loss: (0.1665) |  Loss2: (0.0000) | Acc: (94.00%) (42337/44928)
Epoch: 119 | Batch_idx: 360 |  Loss: (0.1665) |  Loss2: (0.0000) | Acc: (94.00%) (43553/46208)
Epoch: 119 | Batch_idx: 370 |  Loss: (0.1668) |  Loss2: (0.0000) | Acc: (94.00%) (44759/47488)
Epoch: 119 | Batch_idx: 380 |  Loss: (0.1665) |  Loss2: (0.0000) | Acc: (94.00%) (45965/48768)
Epoch: 119 | Batch_idx: 390 |  Loss: (0.1664) |  Loss2: (0.0000) | Acc: (94.00%) (47121/50000)
# TEST : Loss: (0.3641) | Acc: (88.00%) (8840/10000)
percent tensor([0.5197, 0.5219, 0.5165, 0.5232, 0.5193, 0.5285, 0.5211, 0.5218, 0.5192,
        0.5191, 0.5204, 0.5168, 0.5196, 0.5243, 0.5236, 0.5231],
       device='cuda:0') torch.Size([16])
percent tensor([0.5215, 0.5276, 0.5162, 0.5206, 0.5156, 0.5275, 0.5202, 0.5125, 0.5214,
        0.5244, 0.5262, 0.5218, 0.5294, 0.5220, 0.5269, 0.5286],
       device='cuda:0') torch.Size([16])
percent tensor([0.5931, 0.5455, 0.6370, 0.6545, 0.6477, 0.6232, 0.5911, 0.6307, 0.6261,
        0.5883, 0.6069, 0.5979, 0.5234, 0.6398, 0.5803, 0.6022],
       device='cuda:0') torch.Size([16])
percent tensor([0.6424, 0.6357, 0.6375, 0.6409, 0.6447, 0.6530, 0.6420, 0.6421, 0.6481,
        0.6413, 0.6457, 0.6468, 0.6376, 0.6431, 0.6475, 0.6508],
       device='cuda:0') torch.Size([16])
percent tensor([0.6038, 0.5938, 0.6012, 0.6287, 0.6317, 0.7260, 0.5705, 0.5616, 0.6234,
        0.6177, 0.6024, 0.5897, 0.5978, 0.6318, 0.5989, 0.6621],
       device='cuda:0') torch.Size([16])
percent tensor([0.6461, 0.6545, 0.6763, 0.7145, 0.6998, 0.7512, 0.6620, 0.6210, 0.6919,
        0.6434, 0.7064, 0.6543, 0.6868, 0.6962, 0.5991, 0.6854],
       device='cuda:0') torch.Size([16])
percent tensor([0.6557, 0.6527, 0.6773, 0.7345, 0.7242, 0.6729, 0.6953, 0.7247, 0.6238,
        0.6509, 0.6595, 0.6379, 0.6086, 0.6419, 0.6276, 0.6854],
       device='cuda:0') torch.Size([16])
percent tensor([0.9998, 0.9994, 0.9995, 0.9996, 0.9995, 0.9986, 0.9994, 0.9995, 0.9997,
        0.9996, 0.9998, 0.9997, 0.9998, 0.9995, 0.9990, 0.9996],
       device='cuda:0') torch.Size([16])
True Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=128, out_features=16, bias=False)
False Linear(in_features=16, out_features=2, bias=False)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=128, out_features=16, bias=False)
False Linear(in_features=16, out_features=2, bias=False)
True Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=256, out_features=32, bias=False)
False Linear(in_features=32, out_features=2, bias=False)
True Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=256, out_features=32, bias=False)
False Linear(in_features=32, out_features=2, bias=False)
True Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=512, out_features=64, bias=False)
False Linear(in_features=64, out_features=2, bias=False)
True Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=512, out_features=64, bias=False)
False Linear(in_features=64, out_features=2, bias=False)
True Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1024, out_features=128, bias=False)
False Linear(in_features=128, out_features=2, bias=False)
True Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1024, out_features=128, bias=False)
False Linear(in_features=128, out_features=2, bias=False)
True Linear(in_features=512, out_features=10, bias=True)
Epoch: 120 | Batch_idx: 0 |  Loss: (0.1441) |  Loss2: (0.0000) | Acc: (96.00%) (124/128)
Epoch: 120 | Batch_idx: 10 |  Loss: (0.1752) |  Loss2: (0.0000) | Acc: (94.00%) (1335/1408)
Epoch: 120 | Batch_idx: 20 |  Loss: (0.1660) |  Loss2: (0.0000) | Acc: (94.00%) (2548/2688)
Epoch: 120 | Batch_idx: 30 |  Loss: (0.1709) |  Loss2: (0.0000) | Acc: (94.00%) (3740/3968)
Epoch: 120 | Batch_idx: 40 |  Loss: (0.1746) |  Loss2: (0.0000) | Acc: (94.00%) (4947/5248)
Epoch: 120 | Batch_idx: 50 |  Loss: (0.1807) |  Loss2: (0.0000) | Acc: (93.00%) (6131/6528)
Epoch: 120 | Batch_idx: 60 |  Loss: (0.1812) |  Loss2: (0.0000) | Acc: (93.00%) (7333/7808)
Epoch: 120 | Batch_idx: 70 |  Loss: (0.1799) |  Loss2: (0.0000) | Acc: (93.00%) (8538/9088)
Epoch: 120 | Batch_idx: 80 |  Loss: (0.1809) |  Loss2: (0.0000) | Acc: (93.00%) (9739/10368)
Epoch: 120 | Batch_idx: 90 |  Loss: (0.1797) |  Loss2: (0.0000) | Acc: (93.00%) (10939/11648)
Epoch: 120 | Batch_idx: 100 |  Loss: (0.1781) |  Loss2: (0.0000) | Acc: (93.00%) (12145/12928)
Epoch: 120 | Batch_idx: 110 |  Loss: (0.1808) |  Loss2: (0.0000) | Acc: (93.00%) (13327/14208)
Epoch: 120 | Batch_idx: 120 |  Loss: (0.1819) |  Loss2: (0.0000) | Acc: (93.00%) (14516/15488)
Epoch: 120 | Batch_idx: 130 |  Loss: (0.1834) |  Loss2: (0.0000) | Acc: (93.00%) (15705/16768)
Epoch: 120 | Batch_idx: 140 |  Loss: (0.1847) |  Loss2: (0.0000) | Acc: (93.00%) (16898/18048)
Epoch: 120 | Batch_idx: 150 |  Loss: (0.1838) |  Loss2: (0.0000) | Acc: (93.00%) (18112/19328)
Epoch: 120 | Batch_idx: 160 |  Loss: (0.1843) |  Loss2: (0.0000) | Acc: (93.00%) (19307/20608)
Epoch: 120 | Batch_idx: 170 |  Loss: (0.1852) |  Loss2: (0.0000) | Acc: (93.00%) (20501/21888)
Epoch: 120 | Batch_idx: 180 |  Loss: (0.1855) |  Loss2: (0.0000) | Acc: (93.00%) (21698/23168)
Epoch: 120 | Batch_idx: 190 |  Loss: (0.1852) |  Loss2: (0.0000) | Acc: (93.00%) (22898/24448)
Epoch: 120 | Batch_idx: 200 |  Loss: (0.1844) |  Loss2: (0.0000) | Acc: (93.00%) (24105/25728)
Epoch: 120 | Batch_idx: 210 |  Loss: (0.1844) |  Loss2: (0.0000) | Acc: (93.00%) (25300/27008)
Epoch: 120 | Batch_idx: 220 |  Loss: (0.1836) |  Loss2: (0.0000) | Acc: (93.00%) (26507/28288)
Epoch: 120 | Batch_idx: 230 |  Loss: (0.1840) |  Loss2: (0.0000) | Acc: (93.00%) (27692/29568)
Epoch: 120 | Batch_idx: 240 |  Loss: (0.1840) |  Loss2: (0.0000) | Acc: (93.00%) (28890/30848)
Epoch: 120 | Batch_idx: 250 |  Loss: (0.1836) |  Loss2: (0.0000) | Acc: (93.00%) (30084/32128)
Epoch: 120 | Batch_idx: 260 |  Loss: (0.1834) |  Loss2: (0.0000) | Acc: (93.00%) (31284/33408)
Epoch: 120 | Batch_idx: 270 |  Loss: (0.1841) |  Loss2: (0.0000) | Acc: (93.00%) (32478/34688)
Epoch: 120 | Batch_idx: 280 |  Loss: (0.1840) |  Loss2: (0.0000) | Acc: (93.00%) (33681/35968)
Epoch: 120 | Batch_idx: 290 |  Loss: (0.1837) |  Loss2: (0.0000) | Acc: (93.00%) (34883/37248)
Epoch: 120 | Batch_idx: 300 |  Loss: (0.1842) |  Loss2: (0.0000) | Acc: (93.00%) (36072/38528)
Epoch: 120 | Batch_idx: 310 |  Loss: (0.1846) |  Loss2: (0.0000) | Acc: (93.00%) (37261/39808)
Epoch: 120 | Batch_idx: 320 |  Loss: (0.1846) |  Loss2: (0.0000) | Acc: (93.00%) (38453/41088)
Epoch: 120 | Batch_idx: 330 |  Loss: (0.1852) |  Loss2: (0.0000) | Acc: (93.00%) (39636/42368)
Epoch: 120 | Batch_idx: 340 |  Loss: (0.1849) |  Loss2: (0.0000) | Acc: (93.00%) (40831/43648)
Epoch: 120 | Batch_idx: 350 |  Loss: (0.1848) |  Loss2: (0.0000) | Acc: (93.00%) (42035/44928)
Epoch: 120 | Batch_idx: 360 |  Loss: (0.1846) |  Loss2: (0.0000) | Acc: (93.00%) (43239/46208)
Epoch: 120 | Batch_idx: 370 |  Loss: (0.1849) |  Loss2: (0.0000) | Acc: (93.00%) (44421/47488)
Epoch: 120 | Batch_idx: 380 |  Loss: (0.1858) |  Loss2: (0.0000) | Acc: (93.00%) (45600/48768)
Epoch: 120 | Batch_idx: 390 |  Loss: (0.1859) |  Loss2: (0.0000) | Acc: (93.00%) (46750/50000)
=> saving checkpoint 'drive/app/torch/save_Schedule/checkpoint_120.pth.tar'
# TEST : Loss: (0.5290) | Acc: (84.00%) (8445/10000)
percent tensor([0.5201, 0.5211, 0.5186, 0.5234, 0.5208, 0.5295, 0.5211, 0.5221, 0.5192,
        0.5188, 0.5201, 0.5178, 0.5194, 0.5225, 0.5238, 0.5229],
       device='cuda:0') torch.Size([16])
percent tensor([0.5219, 0.5260, 0.5191, 0.5217, 0.5162, 0.5281, 0.5194, 0.5137, 0.5207,
        0.5247, 0.5248, 0.5247, 0.5289, 0.5196, 0.5261, 0.5277],
       device='cuda:0') torch.Size([16])
percent tensor([0.5884, 0.5423, 0.6381, 0.6550, 0.6447, 0.6160, 0.5919, 0.6328, 0.6200,
        0.5843, 0.5997, 0.6001, 0.5182, 0.6419, 0.5751, 0.5979],
       device='cuda:0') torch.Size([16])
percent tensor([0.6412, 0.6365, 0.6389, 0.6407, 0.6434, 0.6426, 0.6420, 0.6444, 0.6466,
        0.6421, 0.6437, 0.6505, 0.6406, 0.6445, 0.6448, 0.6488],
       device='cuda:0') torch.Size([16])
percent tensor([0.6016, 0.5874, 0.6165, 0.6439, 0.6387, 0.7139, 0.5689, 0.5634, 0.6227,
        0.6151, 0.5985, 0.6066, 0.5956, 0.6330, 0.5873, 0.6634],
       device='cuda:0') torch.Size([16])
percent tensor([0.6499, 0.6700, 0.6786, 0.7075, 0.6879, 0.7523, 0.6770, 0.6094, 0.7022,
        0.6602, 0.7269, 0.6583, 0.6980, 0.7134, 0.6129, 0.6912],
       device='cuda:0') torch.Size([16])
percent tensor([0.6694, 0.6666, 0.6921, 0.7394, 0.7197, 0.6909, 0.7154, 0.7205, 0.6421,
        0.6747, 0.6921, 0.6483, 0.6229, 0.6787, 0.6454, 0.6914],
       device='cuda:0') torch.Size([16])
percent tensor([0.9999, 0.9993, 0.9996, 0.9999, 0.9995, 0.9988, 0.9997, 0.9998, 0.9998,
        0.9996, 0.9999, 0.9997, 0.9998, 0.9996, 0.9992, 0.9998],
       device='cuda:0') torch.Size([16])
Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 3, 3, 3]) tensor(178.0621, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(822.0561, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(815.7875, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([128, 64, 3, 3]) tensor(1518.7505, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([128, 64, 1, 1]) tensor(491.5865, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([128, 128, 3, 3]) tensor(2252.6929, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([256, 128, 3, 3]) tensor(4271.1973, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([256, 128, 1, 1]) tensor(1384.9017, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([256, 256, 3, 3]) tensor(6179.0508, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([512, 256, 3, 3]) tensor(11788.8320, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([512, 256, 1, 1]) tensor(3902.9832, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([512, 512, 3, 3]) tensor(16515.0703, device='cuda:0', grad_fn=<NormBackward0>)
Epoch: 121 | Batch_idx: 0 |  Loss: (0.1266) |  Loss2: (0.0000) | Acc: (95.00%) (122/128)
Epoch: 121 | Batch_idx: 10 |  Loss: (0.1703) |  Loss2: (0.0000) | Acc: (93.00%) (1321/1408)
Epoch: 121 | Batch_idx: 20 |  Loss: (0.1708) |  Loss2: (0.0000) | Acc: (93.00%) (2524/2688)
Epoch: 121 | Batch_idx: 30 |  Loss: (0.1770) |  Loss2: (0.0000) | Acc: (93.00%) (3714/3968)
Epoch: 121 | Batch_idx: 40 |  Loss: (0.1746) |  Loss2: (0.0000) | Acc: (93.00%) (4924/5248)
Epoch: 121 | Batch_idx: 50 |  Loss: (0.1762) |  Loss2: (0.0000) | Acc: (93.00%) (6129/6528)
Epoch: 121 | Batch_idx: 60 |  Loss: (0.1765) |  Loss2: (0.0000) | Acc: (93.00%) (7328/7808)
Epoch: 121 | Batch_idx: 70 |  Loss: (0.1760) |  Loss2: (0.0000) | Acc: (93.00%) (8527/9088)
Epoch: 121 | Batch_idx: 80 |  Loss: (0.1747) |  Loss2: (0.0000) | Acc: (93.00%) (9725/10368)
Epoch: 121 | Batch_idx: 90 |  Loss: (0.1743) |  Loss2: (0.0000) | Acc: (93.00%) (10925/11648)
Epoch: 121 | Batch_idx: 100 |  Loss: (0.1719) |  Loss2: (0.0000) | Acc: (93.00%) (12147/12928)
Epoch: 121 | Batch_idx: 110 |  Loss: (0.1722) |  Loss2: (0.0000) | Acc: (93.00%) (13341/14208)
Epoch: 121 | Batch_idx: 120 |  Loss: (0.1722) |  Loss2: (0.0000) | Acc: (93.00%) (14550/15488)
Epoch: 121 | Batch_idx: 130 |  Loss: (0.1710) |  Loss2: (0.0000) | Acc: (93.00%) (15757/16768)
Epoch: 121 | Batch_idx: 140 |  Loss: (0.1708) |  Loss2: (0.0000) | Acc: (93.00%) (16961/18048)
Epoch: 121 | Batch_idx: 150 |  Loss: (0.1716) |  Loss2: (0.0000) | Acc: (93.00%) (18157/19328)
Epoch: 121 | Batch_idx: 160 |  Loss: (0.1715) |  Loss2: (0.0000) | Acc: (93.00%) (19369/20608)
Epoch: 121 | Batch_idx: 170 |  Loss: (0.1723) |  Loss2: (0.0000) | Acc: (93.00%) (20564/21888)
Epoch: 121 | Batch_idx: 180 |  Loss: (0.1734) |  Loss2: (0.0000) | Acc: (93.00%) (21760/23168)
Epoch: 121 | Batch_idx: 190 |  Loss: (0.1755) |  Loss2: (0.0000) | Acc: (93.00%) (22947/24448)
Epoch: 121 | Batch_idx: 200 |  Loss: (0.1767) |  Loss2: (0.0000) | Acc: (93.00%) (24139/25728)
Epoch: 121 | Batch_idx: 210 |  Loss: (0.1761) |  Loss2: (0.0000) | Acc: (93.00%) (25355/27008)
Epoch: 121 | Batch_idx: 220 |  Loss: (0.1765) |  Loss2: (0.0000) | Acc: (93.00%) (26557/28288)
Epoch: 121 | Batch_idx: 230 |  Loss: (0.1761) |  Loss2: (0.0000) | Acc: (93.00%) (27757/29568)
Epoch: 121 | Batch_idx: 240 |  Loss: (0.1769) |  Loss2: (0.0000) | Acc: (93.00%) (28959/30848)
Epoch: 121 | Batch_idx: 250 |  Loss: (0.1776) |  Loss2: (0.0000) | Acc: (93.00%) (30136/32128)
Epoch: 121 | Batch_idx: 260 |  Loss: (0.1783) |  Loss2: (0.0000) | Acc: (93.00%) (31326/33408)
Epoch: 121 | Batch_idx: 270 |  Loss: (0.1782) |  Loss2: (0.0000) | Acc: (93.00%) (32525/34688)
Epoch: 121 | Batch_idx: 280 |  Loss: (0.1796) |  Loss2: (0.0000) | Acc: (93.00%) (33708/35968)
Epoch: 121 | Batch_idx: 290 |  Loss: (0.1796) |  Loss2: (0.0000) | Acc: (93.00%) (34902/37248)
Epoch: 121 | Batch_idx: 300 |  Loss: (0.1798) |  Loss2: (0.0000) | Acc: (93.00%) (36098/38528)
Epoch: 121 | Batch_idx: 310 |  Loss: (0.1801) |  Loss2: (0.0000) | Acc: (93.00%) (37297/39808)
Epoch: 121 | Batch_idx: 320 |  Loss: (0.1808) |  Loss2: (0.0000) | Acc: (93.00%) (38481/41088)
Epoch: 121 | Batch_idx: 330 |  Loss: (0.1813) |  Loss2: (0.0000) | Acc: (93.00%) (39680/42368)
Epoch: 121 | Batch_idx: 340 |  Loss: (0.1810) |  Loss2: (0.0000) | Acc: (93.00%) (40880/43648)
Epoch: 121 | Batch_idx: 350 |  Loss: (0.1818) |  Loss2: (0.0000) | Acc: (93.00%) (42067/44928)
Epoch: 121 | Batch_idx: 360 |  Loss: (0.1815) |  Loss2: (0.0000) | Acc: (93.00%) (43278/46208)
Epoch: 121 | Batch_idx: 370 |  Loss: (0.1819) |  Loss2: (0.0000) | Acc: (93.00%) (44465/47488)
Epoch: 121 | Batch_idx: 380 |  Loss: (0.1811) |  Loss2: (0.0000) | Acc: (93.00%) (45678/48768)
Epoch: 121 | Batch_idx: 390 |  Loss: (0.1807) |  Loss2: (0.0000) | Acc: (93.00%) (46841/50000)
# TEST : Loss: (0.4439) | Acc: (86.00%) (8649/10000)
percent tensor([0.5199, 0.5211, 0.5187, 0.5232, 0.5207, 0.5296, 0.5215, 0.5221, 0.5192,
        0.5187, 0.5200, 0.5182, 0.5192, 0.5228, 0.5237, 0.5228],
       device='cuda:0') torch.Size([16])
percent tensor([0.5218, 0.5272, 0.5178, 0.5199, 0.5146, 0.5282, 0.5197, 0.5139, 0.5210,
        0.5245, 0.5255, 0.5225, 0.5291, 0.5216, 0.5265, 0.5275],
       device='cuda:0') torch.Size([16])
percent tensor([0.5941, 0.5478, 0.6376, 0.6589, 0.6473, 0.6242, 0.5956, 0.6312, 0.6242,
        0.5905, 0.6074, 0.6026, 0.5255, 0.6471, 0.5790, 0.6024],
       device='cuda:0') torch.Size([16])
percent tensor([0.6425, 0.6363, 0.6352, 0.6377, 0.6439, 0.6465, 0.6429, 0.6442, 0.6493,
        0.6412, 0.6449, 0.6474, 0.6398, 0.6415, 0.6472, 0.6487],
       device='cuda:0') torch.Size([16])
percent tensor([0.6008, 0.5861, 0.6037, 0.6359, 0.6418, 0.7186, 0.5771, 0.5681, 0.6143,
        0.6122, 0.5956, 0.5921, 0.5912, 0.6314, 0.5895, 0.6624],
       device='cuda:0') torch.Size([16])
percent tensor([0.6339, 0.6514, 0.6752, 0.7027, 0.6825, 0.7429, 0.6654, 0.6068, 0.6798,
        0.6382, 0.7066, 0.6505, 0.6792, 0.6958, 0.5842, 0.6712],
       device='cuda:0') torch.Size([16])
percent tensor([0.6570, 0.6688, 0.6917, 0.7258, 0.7122, 0.6893, 0.6969, 0.7028, 0.6321,
        0.6673, 0.6650, 0.6439, 0.6286, 0.6411, 0.6144, 0.6808],
       device='cuda:0') torch.Size([16])
percent tensor([0.9998, 0.9992, 0.9995, 0.9999, 0.9997, 0.9985, 0.9995, 0.9996, 0.9998,
        0.9997, 0.9997, 0.9996, 0.9998, 0.9995, 0.9992, 0.9997],
       device='cuda:0') torch.Size([16])
Epoch: 122 | Batch_idx: 0 |  Loss: (0.2114) |  Loss2: (0.0000) | Acc: (90.00%) (116/128)
Epoch: 122 | Batch_idx: 10 |  Loss: (0.1588) |  Loss2: (0.0000) | Acc: (94.00%) (1328/1408)
Epoch: 122 | Batch_idx: 20 |  Loss: (0.1585) |  Loss2: (0.0000) | Acc: (94.00%) (2545/2688)
Epoch: 122 | Batch_idx: 30 |  Loss: (0.1555) |  Loss2: (0.0000) | Acc: (94.00%) (3756/3968)
Epoch: 122 | Batch_idx: 40 |  Loss: (0.1607) |  Loss2: (0.0000) | Acc: (94.00%) (4958/5248)
Epoch: 122 | Batch_idx: 50 |  Loss: (0.1639) |  Loss2: (0.0000) | Acc: (94.00%) (6164/6528)
Epoch: 122 | Batch_idx: 60 |  Loss: (0.1628) |  Loss2: (0.0000) | Acc: (94.00%) (7372/7808)
Epoch: 122 | Batch_idx: 70 |  Loss: (0.1656) |  Loss2: (0.0000) | Acc: (94.00%) (8572/9088)
Epoch: 122 | Batch_idx: 80 |  Loss: (0.1644) |  Loss2: (0.0000) | Acc: (94.00%) (9789/10368)
Epoch: 122 | Batch_idx: 90 |  Loss: (0.1658) |  Loss2: (0.0000) | Acc: (94.00%) (10992/11648)
Epoch: 122 | Batch_idx: 100 |  Loss: (0.1660) |  Loss2: (0.0000) | Acc: (94.00%) (12200/12928)
Epoch: 122 | Batch_idx: 110 |  Loss: (0.1671) |  Loss2: (0.0000) | Acc: (94.00%) (13400/14208)
Epoch: 122 | Batch_idx: 120 |  Loss: (0.1686) |  Loss2: (0.0000) | Acc: (94.00%) (14595/15488)
Epoch: 122 | Batch_idx: 130 |  Loss: (0.1686) |  Loss2: (0.0000) | Acc: (94.00%) (15792/16768)
Epoch: 122 | Batch_idx: 140 |  Loss: (0.1687) |  Loss2: (0.0000) | Acc: (94.00%) (16993/18048)
Epoch: 122 | Batch_idx: 150 |  Loss: (0.1692) |  Loss2: (0.0000) | Acc: (94.00%) (18194/19328)
Epoch: 122 | Batch_idx: 160 |  Loss: (0.1706) |  Loss2: (0.0000) | Acc: (94.00%) (19394/20608)
Epoch: 122 | Batch_idx: 170 |  Loss: (0.1703) |  Loss2: (0.0000) | Acc: (94.00%) (20603/21888)
Epoch: 122 | Batch_idx: 180 |  Loss: (0.1700) |  Loss2: (0.0000) | Acc: (94.00%) (21809/23168)
Epoch: 122 | Batch_idx: 190 |  Loss: (0.1701) |  Loss2: (0.0000) | Acc: (94.00%) (23015/24448)
Epoch: 122 | Batch_idx: 200 |  Loss: (0.1711) |  Loss2: (0.0000) | Acc: (94.00%) (24208/25728)
Epoch: 122 | Batch_idx: 210 |  Loss: (0.1711) |  Loss2: (0.0000) | Acc: (94.00%) (25408/27008)
Epoch: 122 | Batch_idx: 220 |  Loss: (0.1714) |  Loss2: (0.0000) | Acc: (94.00%) (26606/28288)
Epoch: 122 | Batch_idx: 230 |  Loss: (0.1715) |  Loss2: (0.0000) | Acc: (94.00%) (27813/29568)
Epoch: 122 | Batch_idx: 240 |  Loss: (0.1723) |  Loss2: (0.0000) | Acc: (94.00%) (29011/30848)
Epoch: 122 | Batch_idx: 250 |  Loss: (0.1724) |  Loss2: (0.0000) | Acc: (94.00%) (30213/32128)
Epoch: 122 | Batch_idx: 260 |  Loss: (0.1724) |  Loss2: (0.0000) | Acc: (94.00%) (31419/33408)
Epoch: 122 | Batch_idx: 270 |  Loss: (0.1728) |  Loss2: (0.0000) | Acc: (94.00%) (32624/34688)
Epoch: 122 | Batch_idx: 280 |  Loss: (0.1731) |  Loss2: (0.0000) | Acc: (94.00%) (33829/35968)
Epoch: 122 | Batch_idx: 290 |  Loss: (0.1729) |  Loss2: (0.0000) | Acc: (94.00%) (35029/37248)
Epoch: 122 | Batch_idx: 300 |  Loss: (0.1720) |  Loss2: (0.0000) | Acc: (94.00%) (36243/38528)
Epoch: 122 | Batch_idx: 310 |  Loss: (0.1718) |  Loss2: (0.0000) | Acc: (94.00%) (37447/39808)
Epoch: 122 | Batch_idx: 320 |  Loss: (0.1725) |  Loss2: (0.0000) | Acc: (94.00%) (38650/41088)
Epoch: 122 | Batch_idx: 330 |  Loss: (0.1730) |  Loss2: (0.0000) | Acc: (94.00%) (39842/42368)
Epoch: 122 | Batch_idx: 340 |  Loss: (0.1727) |  Loss2: (0.0000) | Acc: (94.00%) (41051/43648)
Epoch: 122 | Batch_idx: 350 |  Loss: (0.1727) |  Loss2: (0.0000) | Acc: (94.00%) (42249/44928)
Epoch: 122 | Batch_idx: 360 |  Loss: (0.1728) |  Loss2: (0.0000) | Acc: (94.00%) (43463/46208)
Epoch: 122 | Batch_idx: 370 |  Loss: (0.1728) |  Loss2: (0.0000) | Acc: (94.00%) (44660/47488)
Epoch: 122 | Batch_idx: 380 |  Loss: (0.1743) |  Loss2: (0.0000) | Acc: (94.00%) (45845/48768)
Epoch: 122 | Batch_idx: 390 |  Loss: (0.1747) |  Loss2: (0.0000) | Acc: (93.00%) (46998/50000)
# TEST : Loss: (0.4431) | Acc: (86.00%) (8633/10000)
percent tensor([0.5202, 0.5212, 0.5207, 0.5232, 0.5221, 0.5290, 0.5219, 0.5225, 0.5198,
        0.5193, 0.5199, 0.5197, 0.5196, 0.5226, 0.5236, 0.5223],
       device='cuda:0') torch.Size([16])
percent tensor([0.5224, 0.5274, 0.5188, 0.5216, 0.5163, 0.5284, 0.5205, 0.5140, 0.5219,
        0.5248, 0.5253, 0.5243, 0.5293, 0.5224, 0.5270, 0.5282],
       device='cuda:0') torch.Size([16])
percent tensor([0.5889, 0.5371, 0.6366, 0.6534, 0.6479, 0.6129, 0.5917, 0.6305, 0.6244,
        0.5893, 0.6052, 0.6022, 0.5223, 0.6380, 0.5688, 0.5961],
       device='cuda:0') torch.Size([16])
percent tensor([0.6414, 0.6370, 0.6347, 0.6380, 0.6428, 0.6440, 0.6424, 0.6417, 0.6473,
        0.6415, 0.6448, 0.6470, 0.6407, 0.6419, 0.6448, 0.6479],
       device='cuda:0') torch.Size([16])
percent tensor([0.6032, 0.5931, 0.6155, 0.6364, 0.6421, 0.7180, 0.5755, 0.5661, 0.6158,
        0.6206, 0.6009, 0.6069, 0.6103, 0.6326, 0.5883, 0.6642],
       device='cuda:0') torch.Size([16])
percent tensor([0.6447, 0.6702, 0.6841, 0.6996, 0.6885, 0.7504, 0.6774, 0.6019, 0.6987,
        0.6575, 0.7186, 0.6631, 0.7000, 0.7162, 0.5990, 0.6806],
       device='cuda:0') torch.Size([16])
percent tensor([0.6486, 0.6655, 0.6857, 0.7099, 0.7175, 0.6850, 0.6907, 0.6825, 0.6368,
        0.6643, 0.6637, 0.6417, 0.6252, 0.6488, 0.6097, 0.6617],
       device='cuda:0') torch.Size([16])
percent tensor([0.9999, 0.9995, 0.9996, 0.9997, 0.9995, 0.9990, 0.9997, 0.9995, 0.9998,
        0.9997, 0.9999, 0.9995, 0.9999, 0.9997, 0.9992, 0.9996],
       device='cuda:0') torch.Size([16])
Epoch: 123 | Batch_idx: 0 |  Loss: (0.1268) |  Loss2: (0.0000) | Acc: (95.00%) (122/128)
Epoch: 123 | Batch_idx: 10 |  Loss: (0.1520) |  Loss2: (0.0000) | Acc: (94.00%) (1332/1408)
Epoch: 123 | Batch_idx: 20 |  Loss: (0.1644) |  Loss2: (0.0000) | Acc: (94.00%) (2528/2688)
Epoch: 123 | Batch_idx: 30 |  Loss: (0.1661) |  Loss2: (0.0000) | Acc: (94.00%) (3734/3968)
Epoch: 123 | Batch_idx: 40 |  Loss: (0.1667) |  Loss2: (0.0000) | Acc: (94.00%) (4941/5248)
Epoch: 123 | Batch_idx: 50 |  Loss: (0.1654) |  Loss2: (0.0000) | Acc: (94.00%) (6152/6528)
Epoch: 123 | Batch_idx: 60 |  Loss: (0.1705) |  Loss2: (0.0000) | Acc: (94.00%) (7349/7808)
Epoch: 123 | Batch_idx: 70 |  Loss: (0.1685) |  Loss2: (0.0000) | Acc: (94.00%) (8558/9088)
Epoch: 123 | Batch_idx: 80 |  Loss: (0.1678) |  Loss2: (0.0000) | Acc: (94.00%) (9772/10368)
Epoch: 123 | Batch_idx: 90 |  Loss: (0.1662) |  Loss2: (0.0000) | Acc: (94.00%) (10982/11648)
Epoch: 123 | Batch_idx: 100 |  Loss: (0.1662) |  Loss2: (0.0000) | Acc: (94.00%) (12178/12928)
Epoch: 123 | Batch_idx: 110 |  Loss: (0.1663) |  Loss2: (0.0000) | Acc: (94.00%) (13390/14208)
Epoch: 123 | Batch_idx: 120 |  Loss: (0.1672) |  Loss2: (0.0000) | Acc: (94.00%) (14601/15488)
Epoch: 123 | Batch_idx: 130 |  Loss: (0.1674) |  Loss2: (0.0000) | Acc: (94.00%) (15805/16768)
Epoch: 123 | Batch_idx: 140 |  Loss: (0.1669) |  Loss2: (0.0000) | Acc: (94.00%) (17017/18048)
Epoch: 123 | Batch_idx: 150 |  Loss: (0.1671) |  Loss2: (0.0000) | Acc: (94.00%) (18217/19328)
Epoch: 123 | Batch_idx: 160 |  Loss: (0.1690) |  Loss2: (0.0000) | Acc: (94.00%) (19409/20608)
Epoch: 123 | Batch_idx: 170 |  Loss: (0.1707) |  Loss2: (0.0000) | Acc: (94.00%) (20604/21888)
Epoch: 123 | Batch_idx: 180 |  Loss: (0.1708) |  Loss2: (0.0000) | Acc: (94.00%) (21821/23168)
Epoch: 123 | Batch_idx: 190 |  Loss: (0.1711) |  Loss2: (0.0000) | Acc: (94.00%) (23014/24448)
Epoch: 123 | Batch_idx: 200 |  Loss: (0.1730) |  Loss2: (0.0000) | Acc: (94.00%) (24204/25728)
Epoch: 123 | Batch_idx: 210 |  Loss: (0.1729) |  Loss2: (0.0000) | Acc: (94.00%) (25403/27008)
Epoch: 123 | Batch_idx: 220 |  Loss: (0.1731) |  Loss2: (0.0000) | Acc: (94.00%) (26615/28288)
Epoch: 123 | Batch_idx: 230 |  Loss: (0.1716) |  Loss2: (0.0000) | Acc: (94.00%) (27831/29568)
Epoch: 123 | Batch_idx: 240 |  Loss: (0.1724) |  Loss2: (0.0000) | Acc: (94.00%) (29026/30848)
Epoch: 123 | Batch_idx: 250 |  Loss: (0.1731) |  Loss2: (0.0000) | Acc: (94.00%) (30227/32128)
Epoch: 123 | Batch_idx: 260 |  Loss: (0.1732) |  Loss2: (0.0000) | Acc: (94.00%) (31425/33408)
Epoch: 123 | Batch_idx: 270 |  Loss: (0.1743) |  Loss2: (0.0000) | Acc: (94.00%) (32615/34688)
Epoch: 123 | Batch_idx: 280 |  Loss: (0.1737) |  Loss2: (0.0000) | Acc: (94.00%) (33830/35968)
Epoch: 123 | Batch_idx: 290 |  Loss: (0.1735) |  Loss2: (0.0000) | Acc: (94.00%) (35039/37248)
Epoch: 123 | Batch_idx: 300 |  Loss: (0.1731) |  Loss2: (0.0000) | Acc: (94.00%) (36255/38528)
Epoch: 123 | Batch_idx: 310 |  Loss: (0.1729) |  Loss2: (0.0000) | Acc: (94.00%) (37457/39808)
Epoch: 123 | Batch_idx: 320 |  Loss: (0.1721) |  Loss2: (0.0000) | Acc: (94.00%) (38674/41088)
Epoch: 123 | Batch_idx: 330 |  Loss: (0.1722) |  Loss2: (0.0000) | Acc: (94.00%) (39879/42368)
Epoch: 123 | Batch_idx: 340 |  Loss: (0.1721) |  Loss2: (0.0000) | Acc: (94.00%) (41086/43648)
Epoch: 123 | Batch_idx: 350 |  Loss: (0.1719) |  Loss2: (0.0000) | Acc: (94.00%) (42289/44928)
Epoch: 123 | Batch_idx: 360 |  Loss: (0.1727) |  Loss2: (0.0000) | Acc: (94.00%) (43488/46208)
Epoch: 123 | Batch_idx: 370 |  Loss: (0.1730) |  Loss2: (0.0000) | Acc: (94.00%) (44675/47488)
Epoch: 123 | Batch_idx: 380 |  Loss: (0.1727) |  Loss2: (0.0000) | Acc: (94.00%) (45885/48768)
Epoch: 123 | Batch_idx: 390 |  Loss: (0.1725) |  Loss2: (0.0000) | Acc: (94.00%) (47043/50000)
# TEST : Loss: (0.4057) | Acc: (87.00%) (8745/10000)
percent tensor([0.5200, 0.5212, 0.5183, 0.5223, 0.5203, 0.5292, 0.5215, 0.5215, 0.5197,
        0.5188, 0.5202, 0.5177, 0.5193, 0.5228, 0.5236, 0.5226],
       device='cuda:0') torch.Size([16])
percent tensor([0.5222, 0.5263, 0.5170, 0.5224, 0.5154, 0.5285, 0.5195, 0.5136, 0.5222,
        0.5242, 0.5262, 0.5226, 0.5300, 0.5217, 0.5263, 0.5289],
       device='cuda:0') torch.Size([16])
percent tensor([0.5882, 0.5426, 0.6374, 0.6539, 0.6470, 0.6235, 0.5892, 0.6303, 0.6251,
        0.5862, 0.6050, 0.5970, 0.5185, 0.6441, 0.5793, 0.5975],
       device='cuda:0') torch.Size([16])
percent tensor([0.6426, 0.6380, 0.6344, 0.6397, 0.6433, 0.6490, 0.6431, 0.6417, 0.6483,
        0.6395, 0.6472, 0.6464, 0.6404, 0.6413, 0.6476, 0.6495],
       device='cuda:0') torch.Size([16])
percent tensor([0.6104, 0.5863, 0.6068, 0.6399, 0.6328, 0.7139, 0.5745, 0.5704, 0.6172,
        0.6106, 0.6025, 0.5990, 0.6006, 0.6208, 0.5894, 0.6599],
       device='cuda:0') torch.Size([16])
percent tensor([0.6487, 0.6727, 0.6751, 0.7104, 0.6827, 0.7502, 0.6731, 0.6069, 0.6908,
        0.6522, 0.7121, 0.6658, 0.6859, 0.7117, 0.6109, 0.6795],
       device='cuda:0') torch.Size([16])
percent tensor([0.6514, 0.6675, 0.6902, 0.7142, 0.7032, 0.6836, 0.6928, 0.6967, 0.6194,
        0.6398, 0.6498, 0.6337, 0.6198, 0.6443, 0.6226, 0.6763],
       device='cuda:0') torch.Size([16])
percent tensor([0.9999, 0.9995, 0.9996, 0.9995, 0.9994, 0.9986, 0.9996, 0.9996, 0.9998,
        0.9996, 0.9998, 0.9995, 0.9998, 0.9996, 0.9990, 0.9996],
       device='cuda:0') torch.Size([16])
Epoch: 124 | Batch_idx: 0 |  Loss: (0.1623) |  Loss2: (0.0000) | Acc: (92.00%) (119/128)
Epoch: 124 | Batch_idx: 10 |  Loss: (0.1542) |  Loss2: (0.0000) | Acc: (94.00%) (1337/1408)
Epoch: 124 | Batch_idx: 20 |  Loss: (0.1525) |  Loss2: (0.0000) | Acc: (95.00%) (2555/2688)
Epoch: 124 | Batch_idx: 30 |  Loss: (0.1573) |  Loss2: (0.0000) | Acc: (94.00%) (3759/3968)
Epoch: 124 | Batch_idx: 40 |  Loss: (0.1578) |  Loss2: (0.0000) | Acc: (94.00%) (4966/5248)
Epoch: 124 | Batch_idx: 50 |  Loss: (0.1579) |  Loss2: (0.0000) | Acc: (94.00%) (6167/6528)
Epoch: 124 | Batch_idx: 60 |  Loss: (0.1567) |  Loss2: (0.0000) | Acc: (94.00%) (7377/7808)
Epoch: 124 | Batch_idx: 70 |  Loss: (0.1584) |  Loss2: (0.0000) | Acc: (94.00%) (8580/9088)
Epoch: 124 | Batch_idx: 80 |  Loss: (0.1574) |  Loss2: (0.0000) | Acc: (94.00%) (9796/10368)
Epoch: 124 | Batch_idx: 90 |  Loss: (0.1576) |  Loss2: (0.0000) | Acc: (94.00%) (11008/11648)
Epoch: 124 | Batch_idx: 100 |  Loss: (0.1593) |  Loss2: (0.0000) | Acc: (94.00%) (12221/12928)
Epoch: 124 | Batch_idx: 110 |  Loss: (0.1597) |  Loss2: (0.0000) | Acc: (94.00%) (13429/14208)
Epoch: 124 | Batch_idx: 120 |  Loss: (0.1602) |  Loss2: (0.0000) | Acc: (94.00%) (14637/15488)
Epoch: 124 | Batch_idx: 130 |  Loss: (0.1614) |  Loss2: (0.0000) | Acc: (94.00%) (15834/16768)
Epoch: 124 | Batch_idx: 140 |  Loss: (0.1617) |  Loss2: (0.0000) | Acc: (94.00%) (17043/18048)
Epoch: 124 | Batch_idx: 150 |  Loss: (0.1626) |  Loss2: (0.0000) | Acc: (94.00%) (18243/19328)
Epoch: 124 | Batch_idx: 160 |  Loss: (0.1616) |  Loss2: (0.0000) | Acc: (94.00%) (19458/20608)
Epoch: 124 | Batch_idx: 170 |  Loss: (0.1619) |  Loss2: (0.0000) | Acc: (94.00%) (20663/21888)
Epoch: 124 | Batch_idx: 180 |  Loss: (0.1629) |  Loss2: (0.0000) | Acc: (94.00%) (21865/23168)
Epoch: 124 | Batch_idx: 190 |  Loss: (0.1638) |  Loss2: (0.0000) | Acc: (94.00%) (23069/24448)
Epoch: 124 | Batch_idx: 200 |  Loss: (0.1636) |  Loss2: (0.0000) | Acc: (94.00%) (24273/25728)
Epoch: 124 | Batch_idx: 210 |  Loss: (0.1645) |  Loss2: (0.0000) | Acc: (94.00%) (25469/27008)
Epoch: 124 | Batch_idx: 220 |  Loss: (0.1646) |  Loss2: (0.0000) | Acc: (94.00%) (26675/28288)
Epoch: 124 | Batch_idx: 230 |  Loss: (0.1647) |  Loss2: (0.0000) | Acc: (94.00%) (27881/29568)
Epoch: 124 | Batch_idx: 240 |  Loss: (0.1653) |  Loss2: (0.0000) | Acc: (94.00%) (29083/30848)
Epoch: 124 | Batch_idx: 250 |  Loss: (0.1648) |  Loss2: (0.0000) | Acc: (94.00%) (30296/32128)
Epoch: 124 | Batch_idx: 260 |  Loss: (0.1657) |  Loss2: (0.0000) | Acc: (94.00%) (31497/33408)
Epoch: 124 | Batch_idx: 270 |  Loss: (0.1657) |  Loss2: (0.0000) | Acc: (94.00%) (32696/34688)
Epoch: 124 | Batch_idx: 280 |  Loss: (0.1661) |  Loss2: (0.0000) | Acc: (94.00%) (33894/35968)
Epoch: 124 | Batch_idx: 290 |  Loss: (0.1660) |  Loss2: (0.0000) | Acc: (94.00%) (35100/37248)
Epoch: 124 | Batch_idx: 300 |  Loss: (0.1664) |  Loss2: (0.0000) | Acc: (94.00%) (36303/38528)
Epoch: 124 | Batch_idx: 310 |  Loss: (0.1667) |  Loss2: (0.0000) | Acc: (94.00%) (37506/39808)
Epoch: 124 | Batch_idx: 320 |  Loss: (0.1674) |  Loss2: (0.0000) | Acc: (94.00%) (38704/41088)
Epoch: 124 | Batch_idx: 330 |  Loss: (0.1674) |  Loss2: (0.0000) | Acc: (94.00%) (39906/42368)
Epoch: 124 | Batch_idx: 340 |  Loss: (0.1672) |  Loss2: (0.0000) | Acc: (94.00%) (41111/43648)
Epoch: 124 | Batch_idx: 350 |  Loss: (0.1676) |  Loss2: (0.0000) | Acc: (94.00%) (42307/44928)
Epoch: 124 | Batch_idx: 360 |  Loss: (0.1678) |  Loss2: (0.0000) | Acc: (94.00%) (43509/46208)
Epoch: 124 | Batch_idx: 370 |  Loss: (0.1686) |  Loss2: (0.0000) | Acc: (94.00%) (44706/47488)
Epoch: 124 | Batch_idx: 380 |  Loss: (0.1695) |  Loss2: (0.0000) | Acc: (94.00%) (45896/48768)
Epoch: 124 | Batch_idx: 390 |  Loss: (0.1702) |  Loss2: (0.0000) | Acc: (94.00%) (47042/50000)
# TEST : Loss: (0.4287) | Acc: (87.00%) (8710/10000)
percent tensor([0.5201, 0.5210, 0.5180, 0.5226, 0.5207, 0.5300, 0.5214, 0.5213, 0.5195,
        0.5188, 0.5204, 0.5177, 0.5195, 0.5226, 0.5239, 0.5230],
       device='cuda:0') torch.Size([16])
percent tensor([0.5227, 0.5266, 0.5190, 0.5211, 0.5164, 0.5285, 0.5209, 0.5143, 0.5235,
        0.5248, 0.5254, 0.5245, 0.5298, 0.5217, 0.5257, 0.5282],
       device='cuda:0') torch.Size([16])
percent tensor([0.5884, 0.5470, 0.6335, 0.6569, 0.6405, 0.6227, 0.5900, 0.6309, 0.6211,
        0.5830, 0.6020, 0.5922, 0.5202, 0.6456, 0.5824, 0.5966],
       device='cuda:0') torch.Size([16])
percent tensor([0.6406, 0.6344, 0.6328, 0.6394, 0.6403, 0.6439, 0.6408, 0.6409, 0.6475,
        0.6374, 0.6422, 0.6433, 0.6379, 0.6418, 0.6448, 0.6462],
       device='cuda:0') torch.Size([16])
percent tensor([0.6126, 0.5928, 0.6189, 0.6455, 0.6387, 0.7218, 0.5784, 0.5689, 0.6253,
        0.6206, 0.5966, 0.6031, 0.6070, 0.6274, 0.5963, 0.6655],
       device='cuda:0') torch.Size([16])
percent tensor([0.6494, 0.6704, 0.6799, 0.7136, 0.6914, 0.7566, 0.6715, 0.6163, 0.7000,
        0.6579, 0.7031, 0.6642, 0.6879, 0.7019, 0.6040, 0.6868],
       device='cuda:0') torch.Size([16])
percent tensor([0.6613, 0.6674, 0.6874, 0.7332, 0.7156, 0.6936, 0.6985, 0.7030, 0.6364,
        0.6645, 0.6647, 0.6377, 0.6383, 0.6396, 0.6210, 0.6868],
       device='cuda:0') torch.Size([16])
percent tensor([0.9999, 0.9996, 0.9996, 0.9998, 0.9993, 0.9986, 0.9996, 0.9997, 0.9998,
        0.9996, 0.9998, 0.9994, 0.9999, 0.9995, 0.9990, 0.9997],
       device='cuda:0') torch.Size([16])
Epoch: 125 | Batch_idx: 0 |  Loss: (0.1296) |  Loss2: (0.0000) | Acc: (97.00%) (125/128)
Epoch: 125 | Batch_idx: 10 |  Loss: (0.1606) |  Loss2: (0.0000) | Acc: (94.00%) (1326/1408)
Epoch: 125 | Batch_idx: 20 |  Loss: (0.1595) |  Loss2: (0.0000) | Acc: (94.00%) (2545/2688)
Epoch: 125 | Batch_idx: 30 |  Loss: (0.1606) |  Loss2: (0.0000) | Acc: (94.00%) (3750/3968)
Epoch: 125 | Batch_idx: 40 |  Loss: (0.1509) |  Loss2: (0.0000) | Acc: (94.00%) (4980/5248)
Epoch: 125 | Batch_idx: 50 |  Loss: (0.1524) |  Loss2: (0.0000) | Acc: (94.00%) (6193/6528)
Epoch: 125 | Batch_idx: 60 |  Loss: (0.1544) |  Loss2: (0.0000) | Acc: (94.00%) (7403/7808)
Epoch: 125 | Batch_idx: 70 |  Loss: (0.1529) |  Loss2: (0.0000) | Acc: (94.00%) (8620/9088)
Epoch: 125 | Batch_idx: 80 |  Loss: (0.1546) |  Loss2: (0.0000) | Acc: (94.00%) (9831/10368)
Epoch: 125 | Batch_idx: 90 |  Loss: (0.1578) |  Loss2: (0.0000) | Acc: (94.00%) (11021/11648)
Epoch: 125 | Batch_idx: 100 |  Loss: (0.1564) |  Loss2: (0.0000) | Acc: (94.00%) (12237/12928)
Epoch: 125 | Batch_idx: 110 |  Loss: (0.1547) |  Loss2: (0.0000) | Acc: (94.00%) (13462/14208)
Epoch: 125 | Batch_idx: 120 |  Loss: (0.1569) |  Loss2: (0.0000) | Acc: (94.00%) (14661/15488)
Epoch: 125 | Batch_idx: 130 |  Loss: (0.1569) |  Loss2: (0.0000) | Acc: (94.00%) (15866/16768)
Epoch: 125 | Batch_idx: 140 |  Loss: (0.1563) |  Loss2: (0.0000) | Acc: (94.00%) (17081/18048)
Epoch: 125 | Batch_idx: 150 |  Loss: (0.1567) |  Loss2: (0.0000) | Acc: (94.00%) (18288/19328)
Epoch: 125 | Batch_idx: 160 |  Loss: (0.1572) |  Loss2: (0.0000) | Acc: (94.00%) (19499/20608)
Epoch: 125 | Batch_idx: 170 |  Loss: (0.1571) |  Loss2: (0.0000) | Acc: (94.00%) (20712/21888)
Epoch: 125 | Batch_idx: 180 |  Loss: (0.1565) |  Loss2: (0.0000) | Acc: (94.00%) (21930/23168)
Epoch: 125 | Batch_idx: 190 |  Loss: (0.1560) |  Loss2: (0.0000) | Acc: (94.00%) (23149/24448)
Epoch: 125 | Batch_idx: 200 |  Loss: (0.1564) |  Loss2: (0.0000) | Acc: (94.00%) (24356/25728)
Epoch: 125 | Batch_idx: 210 |  Loss: (0.1565) |  Loss2: (0.0000) | Acc: (94.00%) (25572/27008)
Epoch: 125 | Batch_idx: 220 |  Loss: (0.1560) |  Loss2: (0.0000) | Acc: (94.00%) (26802/28288)
Epoch: 125 | Batch_idx: 230 |  Loss: (0.1563) |  Loss2: (0.0000) | Acc: (94.00%) (28004/29568)
Epoch: 125 | Batch_idx: 240 |  Loss: (0.1561) |  Loss2: (0.0000) | Acc: (94.00%) (29217/30848)
Epoch: 125 | Batch_idx: 250 |  Loss: (0.1568) |  Loss2: (0.0000) | Acc: (94.00%) (30424/32128)
Epoch: 125 | Batch_idx: 260 |  Loss: (0.1589) |  Loss2: (0.0000) | Acc: (94.00%) (31608/33408)
Epoch: 125 | Batch_idx: 270 |  Loss: (0.1593) |  Loss2: (0.0000) | Acc: (94.00%) (32815/34688)
Epoch: 125 | Batch_idx: 280 |  Loss: (0.1600) |  Loss2: (0.0000) | Acc: (94.00%) (34018/35968)
Epoch: 125 | Batch_idx: 290 |  Loss: (0.1601) |  Loss2: (0.0000) | Acc: (94.00%) (35222/37248)
Epoch: 125 | Batch_idx: 300 |  Loss: (0.1603) |  Loss2: (0.0000) | Acc: (94.00%) (36426/38528)
Epoch: 125 | Batch_idx: 310 |  Loss: (0.1601) |  Loss2: (0.0000) | Acc: (94.00%) (37642/39808)
Epoch: 125 | Batch_idx: 320 |  Loss: (0.1605) |  Loss2: (0.0000) | Acc: (94.00%) (38842/41088)
Epoch: 125 | Batch_idx: 330 |  Loss: (0.1607) |  Loss2: (0.0000) | Acc: (94.00%) (40056/42368)
Epoch: 125 | Batch_idx: 340 |  Loss: (0.1606) |  Loss2: (0.0000) | Acc: (94.00%) (41268/43648)
Epoch: 125 | Batch_idx: 350 |  Loss: (0.1615) |  Loss2: (0.0000) | Acc: (94.00%) (42462/44928)
Epoch: 125 | Batch_idx: 360 |  Loss: (0.1620) |  Loss2: (0.0000) | Acc: (94.00%) (43667/46208)
Epoch: 125 | Batch_idx: 370 |  Loss: (0.1622) |  Loss2: (0.0000) | Acc: (94.00%) (44861/47488)
Epoch: 125 | Batch_idx: 380 |  Loss: (0.1626) |  Loss2: (0.0000) | Acc: (94.00%) (46049/48768)
Epoch: 125 | Batch_idx: 390 |  Loss: (0.1628) |  Loss2: (0.0000) | Acc: (94.00%) (47201/50000)
=> saving checkpoint 'drive/app/torch/save_Schedule/checkpoint_125.pth.tar'
# TEST : Loss: (0.5050) | Acc: (85.00%) (8502/10000)
percent tensor([0.5194, 0.5202, 0.5177, 0.5225, 0.5201, 0.5284, 0.5205, 0.5214, 0.5186,
        0.5184, 0.5193, 0.5173, 0.5189, 0.5218, 0.5229, 0.5220],
       device='cuda:0') torch.Size([16])
percent tensor([0.5225, 0.5270, 0.5213, 0.5221, 0.5176, 0.5276, 0.5206, 0.5152, 0.5230,
        0.5259, 0.5256, 0.5254, 0.5305, 0.5218, 0.5255, 0.5282],
       device='cuda:0') torch.Size([16])
percent tensor([0.5941, 0.5473, 0.6433, 0.6560, 0.6494, 0.6239, 0.5947, 0.6334, 0.6264,
        0.5899, 0.6098, 0.6048, 0.5254, 0.6382, 0.5785, 0.6018],
       device='cuda:0') torch.Size([16])
percent tensor([0.6435, 0.6372, 0.6382, 0.6415, 0.6427, 0.6445, 0.6436, 0.6426, 0.6487,
        0.6420, 0.6468, 0.6480, 0.6396, 0.6409, 0.6476, 0.6480],
       device='cuda:0') torch.Size([16])
percent tensor([0.6033, 0.5863, 0.6038, 0.6274, 0.6350, 0.7066, 0.5713, 0.5501, 0.6144,
        0.6169, 0.6044, 0.6033, 0.6121, 0.6186, 0.5865, 0.6646],
       device='cuda:0') torch.Size([16])
percent tensor([0.6386, 0.6706, 0.6662, 0.6938, 0.6757, 0.7464, 0.6691, 0.5911, 0.6904,
        0.6527, 0.7150, 0.6645, 0.7009, 0.7001, 0.5919, 0.6779],
       device='cuda:0') torch.Size([16])
percent tensor([0.6404, 0.6498, 0.6791, 0.7125, 0.6968, 0.6786, 0.6818, 0.6653, 0.6309,
        0.6453, 0.6575, 0.6286, 0.6353, 0.6299, 0.6055, 0.6654],
       device='cuda:0') torch.Size([16])
percent tensor([0.9998, 0.9996, 0.9995, 0.9997, 0.9994, 0.9991, 0.9994, 0.9991, 0.9998,
        0.9996, 0.9998, 0.9995, 0.9999, 0.9996, 0.9992, 0.9996],
       device='cuda:0') torch.Size([16])
False Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=128, out_features=16, bias=False)
True Linear(in_features=16, out_features=2, bias=False)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=128, out_features=16, bias=False)
True Linear(in_features=16, out_features=2, bias=False)
False Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=256, out_features=32, bias=False)
True Linear(in_features=32, out_features=2, bias=False)
False Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=256, out_features=32, bias=False)
True Linear(in_features=32, out_features=2, bias=False)
False Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=512, out_features=64, bias=False)
True Linear(in_features=64, out_features=2, bias=False)
False Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=512, out_features=64, bias=False)
True Linear(in_features=64, out_features=2, bias=False)
False Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1024, out_features=128, bias=False)
True Linear(in_features=128, out_features=2, bias=False)
False Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1024, out_features=128, bias=False)
True Linear(in_features=128, out_features=2, bias=False)
False Linear(in_features=512, out_features=10, bias=True)
Epoch: 126 | Batch_idx: 0 |  Loss: (0.1682) |  Loss2: (0.0000) | Acc: (96.00%) (123/128)
Epoch: 126 | Batch_idx: 10 |  Loss: (0.1808) |  Loss2: (0.0000) | Acc: (94.00%) (1324/1408)
Epoch: 126 | Batch_idx: 20 |  Loss: (0.1910) |  Loss2: (0.0000) | Acc: (93.00%) (2509/2688)
Epoch: 126 | Batch_idx: 30 |  Loss: (0.2001) |  Loss2: (0.0000) | Acc: (92.00%) (3677/3968)
Epoch: 126 | Batch_idx: 40 |  Loss: (0.2038) |  Loss2: (0.0000) | Acc: (92.00%) (4860/5248)
Epoch: 126 | Batch_idx: 50 |  Loss: (0.2094) |  Loss2: (0.0000) | Acc: (92.00%) (6039/6528)
Epoch: 126 | Batch_idx: 60 |  Loss: (0.2158) |  Loss2: (0.0000) | Acc: (92.00%) (7209/7808)
Epoch: 126 | Batch_idx: 70 |  Loss: (0.2179) |  Loss2: (0.0000) | Acc: (92.00%) (8390/9088)
Epoch: 126 | Batch_idx: 80 |  Loss: (0.2164) |  Loss2: (0.0000) | Acc: (92.00%) (9577/10368)
Epoch: 126 | Batch_idx: 90 |  Loss: (0.2148) |  Loss2: (0.0000) | Acc: (92.00%) (10765/11648)
Epoch: 126 | Batch_idx: 100 |  Loss: (0.2130) |  Loss2: (0.0000) | Acc: (92.00%) (11947/12928)
Epoch: 126 | Batch_idx: 110 |  Loss: (0.2124) |  Loss2: (0.0000) | Acc: (92.00%) (13133/14208)
Epoch: 126 | Batch_idx: 120 |  Loss: (0.2123) |  Loss2: (0.0000) | Acc: (92.00%) (14321/15488)
Epoch: 126 | Batch_idx: 130 |  Loss: (0.2097) |  Loss2: (0.0000) | Acc: (92.00%) (15522/16768)
Epoch: 126 | Batch_idx: 140 |  Loss: (0.2086) |  Loss2: (0.0000) | Acc: (92.00%) (16714/18048)
Epoch: 126 | Batch_idx: 150 |  Loss: (0.2085) |  Loss2: (0.0000) | Acc: (92.00%) (17904/19328)
Epoch: 126 | Batch_idx: 160 |  Loss: (0.2069) |  Loss2: (0.0000) | Acc: (92.00%) (19094/20608)
Epoch: 126 | Batch_idx: 170 |  Loss: (0.2070) |  Loss2: (0.0000) | Acc: (92.00%) (20283/21888)
Epoch: 126 | Batch_idx: 180 |  Loss: (0.2076) |  Loss2: (0.0000) | Acc: (92.00%) (21460/23168)
Epoch: 126 | Batch_idx: 190 |  Loss: (0.2079) |  Loss2: (0.0000) | Acc: (92.00%) (22647/24448)
Epoch: 126 | Batch_idx: 200 |  Loss: (0.2078) |  Loss2: (0.0000) | Acc: (92.00%) (23833/25728)
Epoch: 126 | Batch_idx: 210 |  Loss: (0.2067) |  Loss2: (0.0000) | Acc: (92.00%) (25024/27008)
Epoch: 126 | Batch_idx: 220 |  Loss: (0.2051) |  Loss2: (0.0000) | Acc: (92.00%) (26231/28288)
Epoch: 126 | Batch_idx: 230 |  Loss: (0.2046) |  Loss2: (0.0000) | Acc: (92.00%) (27426/29568)
Epoch: 126 | Batch_idx: 240 |  Loss: (0.2050) |  Loss2: (0.0000) | Acc: (92.00%) (28611/30848)
Epoch: 126 | Batch_idx: 250 |  Loss: (0.2047) |  Loss2: (0.0000) | Acc: (92.00%) (29788/32128)
Epoch: 126 | Batch_idx: 260 |  Loss: (0.2042) |  Loss2: (0.0000) | Acc: (92.00%) (30976/33408)
Epoch: 126 | Batch_idx: 270 |  Loss: (0.2034) |  Loss2: (0.0000) | Acc: (92.00%) (32172/34688)
Epoch: 126 | Batch_idx: 280 |  Loss: (0.2043) |  Loss2: (0.0000) | Acc: (92.00%) (33345/35968)
Epoch: 126 | Batch_idx: 290 |  Loss: (0.2030) |  Loss2: (0.0000) | Acc: (92.00%) (34541/37248)
Epoch: 126 | Batch_idx: 300 |  Loss: (0.2024) |  Loss2: (0.0000) | Acc: (92.00%) (35747/38528)
Epoch: 126 | Batch_idx: 310 |  Loss: (0.2012) |  Loss2: (0.0000) | Acc: (92.00%) (36958/39808)
Epoch: 126 | Batch_idx: 320 |  Loss: (0.2010) |  Loss2: (0.0000) | Acc: (92.00%) (38141/41088)
Epoch: 126 | Batch_idx: 330 |  Loss: (0.2002) |  Loss2: (0.0000) | Acc: (92.00%) (39346/42368)
Epoch: 126 | Batch_idx: 340 |  Loss: (0.1988) |  Loss2: (0.0000) | Acc: (92.00%) (40561/43648)
Epoch: 126 | Batch_idx: 350 |  Loss: (0.1976) |  Loss2: (0.0000) | Acc: (92.00%) (41769/44928)
Epoch: 126 | Batch_idx: 360 |  Loss: (0.1973) |  Loss2: (0.0000) | Acc: (92.00%) (42967/46208)
Epoch: 126 | Batch_idx: 370 |  Loss: (0.1961) |  Loss2: (0.0000) | Acc: (93.00%) (44180/47488)
Epoch: 126 | Batch_idx: 380 |  Loss: (0.1950) |  Loss2: (0.0000) | Acc: (93.00%) (45389/48768)
Epoch: 126 | Batch_idx: 390 |  Loss: (0.1940) |  Loss2: (0.0000) | Acc: (93.00%) (46553/50000)
# TEST : Loss: (0.3992) | Acc: (87.00%) (8743/10000)
percent tensor([0.5135, 0.5135, 0.5123, 0.5169, 0.5138, 0.5219, 0.5138, 0.5152, 0.5127,
        0.5123, 0.5132, 0.5117, 0.5128, 0.5156, 0.5162, 0.5161],
       device='cuda:0') torch.Size([16])
percent tensor([0.5132, 0.5145, 0.5107, 0.5103, 0.5066, 0.5202, 0.5091, 0.5047, 0.5106,
        0.5135, 0.5126, 0.5138, 0.5195, 0.5080, 0.5144, 0.5165],
       device='cuda:0') torch.Size([16])
percent tensor([0.6095, 0.5546, 0.6652, 0.6860, 0.6710, 0.6596, 0.6034, 0.6535, 0.6410,
        0.6025, 0.6253, 0.6190, 0.5284, 0.6563, 0.5986, 0.6198],
       device='cuda:0') torch.Size([16])
percent tensor([0.6339, 0.6270, 0.6255, 0.6300, 0.6308, 0.6364, 0.6330, 0.6305, 0.6374,
        0.6310, 0.6358, 0.6367, 0.6302, 0.6313, 0.6371, 0.6387],
       device='cuda:0') torch.Size([16])
percent tensor([0.6198, 0.5976, 0.6229, 0.6402, 0.6561, 0.7045, 0.5902, 0.5822, 0.6256,
        0.6258, 0.6071, 0.6070, 0.6186, 0.6228, 0.6045, 0.6747],
       device='cuda:0') torch.Size([16])
percent tensor([0.6245, 0.6676, 0.6665, 0.6893, 0.6694, 0.7358, 0.6643, 0.5799, 0.6850,
        0.6451, 0.7071, 0.6630, 0.6974, 0.6858, 0.5763, 0.6692],
       device='cuda:0') torch.Size([16])
percent tensor([0.6089, 0.6202, 0.6889, 0.7270, 0.7205, 0.6561, 0.6731, 0.6897, 0.5992,
        0.6174, 0.6247, 0.6256, 0.5834, 0.5991, 0.5969, 0.6604],
       device='cuda:0') torch.Size([16])
percent tensor([0.9999, 0.9995, 0.9996, 0.9998, 0.9995, 0.9990, 0.9994, 0.9993, 0.9998,
        0.9996, 0.9998, 0.9996, 0.9998, 0.9996, 0.9990, 0.9996],
       device='cuda:0') torch.Size([16])
Epoch: 127 | Batch_idx: 0 |  Loss: (0.1795) |  Loss2: (0.0000) | Acc: (92.00%) (118/128)
Epoch: 127 | Batch_idx: 10 |  Loss: (0.2033) |  Loss2: (0.0000) | Acc: (93.00%) (1312/1408)
Epoch: 127 | Batch_idx: 20 |  Loss: (0.1870) |  Loss2: (0.0000) | Acc: (93.00%) (2515/2688)
Epoch: 127 | Batch_idx: 30 |  Loss: (0.1833) |  Loss2: (0.0000) | Acc: (93.00%) (3715/3968)
Epoch: 127 | Batch_idx: 40 |  Loss: (0.1884) |  Loss2: (0.0000) | Acc: (93.00%) (4910/5248)
Epoch: 127 | Batch_idx: 50 |  Loss: (0.1935) |  Loss2: (0.0000) | Acc: (93.00%) (6097/6528)
Epoch: 127 | Batch_idx: 60 |  Loss: (0.1884) |  Loss2: (0.0000) | Acc: (93.00%) (7307/7808)
Epoch: 127 | Batch_idx: 70 |  Loss: (0.1833) |  Loss2: (0.0000) | Acc: (93.00%) (8514/9088)
Epoch: 127 | Batch_idx: 80 |  Loss: (0.1801) |  Loss2: (0.0000) | Acc: (93.00%) (9728/10368)
Epoch: 127 | Batch_idx: 90 |  Loss: (0.1798) |  Loss2: (0.0000) | Acc: (93.00%) (10920/11648)
Epoch: 127 | Batch_idx: 100 |  Loss: (0.1764) |  Loss2: (0.0000) | Acc: (93.00%) (12140/12928)
Epoch: 127 | Batch_idx: 110 |  Loss: (0.1781) |  Loss2: (0.0000) | Acc: (93.00%) (13330/14208)
Epoch: 127 | Batch_idx: 120 |  Loss: (0.1790) |  Loss2: (0.0000) | Acc: (93.00%) (14526/15488)
Epoch: 127 | Batch_idx: 130 |  Loss: (0.1767) |  Loss2: (0.0000) | Acc: (93.00%) (15738/16768)
Epoch: 127 | Batch_idx: 140 |  Loss: (0.1777) |  Loss2: (0.0000) | Acc: (93.00%) (16926/18048)
Epoch: 127 | Batch_idx: 150 |  Loss: (0.1761) |  Loss2: (0.0000) | Acc: (93.00%) (18142/19328)
Epoch: 127 | Batch_idx: 160 |  Loss: (0.1758) |  Loss2: (0.0000) | Acc: (93.00%) (19340/20608)
Epoch: 127 | Batch_idx: 170 |  Loss: (0.1748) |  Loss2: (0.0000) | Acc: (93.00%) (20556/21888)
Epoch: 127 | Batch_idx: 180 |  Loss: (0.1725) |  Loss2: (0.0000) | Acc: (93.00%) (21777/23168)
Epoch: 127 | Batch_idx: 190 |  Loss: (0.1717) |  Loss2: (0.0000) | Acc: (94.00%) (22989/24448)
Epoch: 127 | Batch_idx: 200 |  Loss: (0.1717) |  Loss2: (0.0000) | Acc: (94.00%) (24199/25728)
Epoch: 127 | Batch_idx: 210 |  Loss: (0.1718) |  Loss2: (0.0000) | Acc: (94.00%) (25395/27008)
Epoch: 127 | Batch_idx: 220 |  Loss: (0.1716) |  Loss2: (0.0000) | Acc: (94.00%) (26598/28288)
Epoch: 127 | Batch_idx: 230 |  Loss: (0.1712) |  Loss2: (0.0000) | Acc: (94.00%) (27810/29568)
Epoch: 127 | Batch_idx: 240 |  Loss: (0.1711) |  Loss2: (0.0000) | Acc: (94.00%) (29002/30848)
Epoch: 127 | Batch_idx: 250 |  Loss: (0.1707) |  Loss2: (0.0000) | Acc: (94.00%) (30209/32128)
Epoch: 127 | Batch_idx: 260 |  Loss: (0.1703) |  Loss2: (0.0000) | Acc: (94.00%) (31423/33408)
Epoch: 127 | Batch_idx: 270 |  Loss: (0.1715) |  Loss2: (0.0000) | Acc: (94.00%) (32610/34688)
Epoch: 127 | Batch_idx: 280 |  Loss: (0.1707) |  Loss2: (0.0000) | Acc: (94.00%) (33825/35968)
Epoch: 127 | Batch_idx: 290 |  Loss: (0.1712) |  Loss2: (0.0000) | Acc: (94.00%) (35021/37248)
Epoch: 127 | Batch_idx: 300 |  Loss: (0.1707) |  Loss2: (0.0000) | Acc: (94.00%) (36229/38528)
Epoch: 127 | Batch_idx: 310 |  Loss: (0.1697) |  Loss2: (0.0000) | Acc: (94.00%) (37451/39808)
Epoch: 127 | Batch_idx: 320 |  Loss: (0.1692) |  Loss2: (0.0000) | Acc: (94.00%) (38662/41088)
Epoch: 127 | Batch_idx: 330 |  Loss: (0.1693) |  Loss2: (0.0000) | Acc: (94.00%) (39862/42368)
Epoch: 127 | Batch_idx: 340 |  Loss: (0.1693) |  Loss2: (0.0000) | Acc: (94.00%) (41067/43648)
Epoch: 127 | Batch_idx: 350 |  Loss: (0.1689) |  Loss2: (0.0000) | Acc: (94.00%) (42266/44928)
Epoch: 127 | Batch_idx: 360 |  Loss: (0.1689) |  Loss2: (0.0000) | Acc: (94.00%) (43480/46208)
Epoch: 127 | Batch_idx: 370 |  Loss: (0.1687) |  Loss2: (0.0000) | Acc: (94.00%) (44694/47488)
Epoch: 127 | Batch_idx: 380 |  Loss: (0.1687) |  Loss2: (0.0000) | Acc: (94.00%) (45897/48768)
Epoch: 127 | Batch_idx: 390 |  Loss: (0.1687) |  Loss2: (0.0000) | Acc: (94.00%) (47048/50000)
# TEST : Loss: (0.3875) | Acc: (87.00%) (8776/10000)
percent tensor([0.5122, 0.5120, 0.5112, 0.5157, 0.5125, 0.5205, 0.5124, 0.5138, 0.5114,
        0.5109, 0.5117, 0.5104, 0.5114, 0.5141, 0.5148, 0.5148],
       device='cuda:0') torch.Size([16])
percent tensor([0.5092, 0.5102, 0.5067, 0.5057, 0.5026, 0.5170, 0.5051, 0.5008, 0.5060,
        0.5089, 0.5075, 0.5095, 0.5155, 0.5031, 0.5105, 0.5122],
       device='cuda:0') torch.Size([16])
percent tensor([0.5970, 0.5524, 0.6589, 0.6805, 0.6644, 0.6518, 0.5959, 0.6456, 0.6316,
        0.5983, 0.6183, 0.6138, 0.5187, 0.6516, 0.5920, 0.6103],
       device='cuda:0') torch.Size([16])
percent tensor([0.6387, 0.6331, 0.6305, 0.6352, 0.6357, 0.6403, 0.6383, 0.6359, 0.6427,
        0.6371, 0.6415, 0.6426, 0.6356, 0.6364, 0.6423, 0.6437],
       device='cuda:0') torch.Size([16])
percent tensor([0.6143, 0.5866, 0.6252, 0.6407, 0.6603, 0.7067, 0.5854, 0.5860, 0.6175,
        0.6179, 0.5928, 0.5990, 0.6062, 0.6145, 0.5977, 0.6701],
       device='cuda:0') torch.Size([16])
percent tensor([0.6251, 0.6708, 0.6630, 0.6872, 0.6638, 0.7367, 0.6673, 0.5715, 0.6874,
        0.6462, 0.7111, 0.6666, 0.7054, 0.6912, 0.5764, 0.6672],
       device='cuda:0') torch.Size([16])
percent tensor([0.6208, 0.6289, 0.7009, 0.7419, 0.7374, 0.6656, 0.6896, 0.7078, 0.6039,
        0.6276, 0.6362, 0.6418, 0.5885, 0.6078, 0.6132, 0.6763],
       device='cuda:0') torch.Size([16])
percent tensor([0.9999, 0.9995, 0.9997, 0.9998, 0.9995, 0.9990, 0.9994, 0.9994, 0.9998,
        0.9996, 0.9998, 0.9997, 0.9998, 0.9996, 0.9990, 0.9996],
       device='cuda:0') torch.Size([16])
Epoch: 128 | Batch_idx: 0 |  Loss: (0.1526) |  Loss2: (0.0000) | Acc: (95.00%) (122/128)
Epoch: 128 | Batch_idx: 10 |  Loss: (0.1544) |  Loss2: (0.0000) | Acc: (94.00%) (1332/1408)
Epoch: 128 | Batch_idx: 20 |  Loss: (0.1638) |  Loss2: (0.0000) | Acc: (94.00%) (2536/2688)
Epoch: 128 | Batch_idx: 30 |  Loss: (0.1694) |  Loss2: (0.0000) | Acc: (94.00%) (3738/3968)
Epoch: 128 | Batch_idx: 40 |  Loss: (0.1673) |  Loss2: (0.0000) | Acc: (94.00%) (4934/5248)
Epoch: 128 | Batch_idx: 50 |  Loss: (0.1699) |  Loss2: (0.0000) | Acc: (93.00%) (6126/6528)
Epoch: 128 | Batch_idx: 60 |  Loss: (0.1707) |  Loss2: (0.0000) | Acc: (93.00%) (7329/7808)
Epoch: 128 | Batch_idx: 70 |  Loss: (0.1676) |  Loss2: (0.0000) | Acc: (93.00%) (8542/9088)
Epoch: 128 | Batch_idx: 80 |  Loss: (0.1666) |  Loss2: (0.0000) | Acc: (94.00%) (9759/10368)
Epoch: 128 | Batch_idx: 90 |  Loss: (0.1611) |  Loss2: (0.0000) | Acc: (94.00%) (10992/11648)
Epoch: 128 | Batch_idx: 100 |  Loss: (0.1605) |  Loss2: (0.0000) | Acc: (94.00%) (12197/12928)
Epoch: 128 | Batch_idx: 110 |  Loss: (0.1590) |  Loss2: (0.0000) | Acc: (94.00%) (13414/14208)
Epoch: 128 | Batch_idx: 120 |  Loss: (0.1593) |  Loss2: (0.0000) | Acc: (94.00%) (14629/15488)
Epoch: 128 | Batch_idx: 130 |  Loss: (0.1596) |  Loss2: (0.0000) | Acc: (94.00%) (15838/16768)
Epoch: 128 | Batch_idx: 140 |  Loss: (0.1590) |  Loss2: (0.0000) | Acc: (94.00%) (17051/18048)
Epoch: 128 | Batch_idx: 150 |  Loss: (0.1585) |  Loss2: (0.0000) | Acc: (94.00%) (18254/19328)
Epoch: 128 | Batch_idx: 160 |  Loss: (0.1591) |  Loss2: (0.0000) | Acc: (94.00%) (19464/20608)
Epoch: 128 | Batch_idx: 170 |  Loss: (0.1584) |  Loss2: (0.0000) | Acc: (94.00%) (20683/21888)
Epoch: 128 | Batch_idx: 180 |  Loss: (0.1578) |  Loss2: (0.0000) | Acc: (94.00%) (21891/23168)
Epoch: 128 | Batch_idx: 190 |  Loss: (0.1570) |  Loss2: (0.0000) | Acc: (94.00%) (23107/24448)
Epoch: 128 | Batch_idx: 200 |  Loss: (0.1581) |  Loss2: (0.0000) | Acc: (94.00%) (24302/25728)
Epoch: 128 | Batch_idx: 210 |  Loss: (0.1587) |  Loss2: (0.0000) | Acc: (94.00%) (25505/27008)
Epoch: 128 | Batch_idx: 220 |  Loss: (0.1588) |  Loss2: (0.0000) | Acc: (94.00%) (26715/28288)
Epoch: 128 | Batch_idx: 230 |  Loss: (0.1593) |  Loss2: (0.0000) | Acc: (94.00%) (27919/29568)
Epoch: 128 | Batch_idx: 240 |  Loss: (0.1592) |  Loss2: (0.0000) | Acc: (94.00%) (29122/30848)
Epoch: 128 | Batch_idx: 250 |  Loss: (0.1595) |  Loss2: (0.0000) | Acc: (94.00%) (30327/32128)
Epoch: 128 | Batch_idx: 260 |  Loss: (0.1588) |  Loss2: (0.0000) | Acc: (94.00%) (31543/33408)
Epoch: 128 | Batch_idx: 270 |  Loss: (0.1584) |  Loss2: (0.0000) | Acc: (94.00%) (32761/34688)
Epoch: 128 | Batch_idx: 280 |  Loss: (0.1584) |  Loss2: (0.0000) | Acc: (94.00%) (33972/35968)
Epoch: 128 | Batch_idx: 290 |  Loss: (0.1584) |  Loss2: (0.0000) | Acc: (94.00%) (35181/37248)
Epoch: 128 | Batch_idx: 300 |  Loss: (0.1582) |  Loss2: (0.0000) | Acc: (94.00%) (36406/38528)
Epoch: 128 | Batch_idx: 310 |  Loss: (0.1576) |  Loss2: (0.0000) | Acc: (94.00%) (37624/39808)
Epoch: 128 | Batch_idx: 320 |  Loss: (0.1574) |  Loss2: (0.0000) | Acc: (94.00%) (38838/41088)
Epoch: 128 | Batch_idx: 330 |  Loss: (0.1581) |  Loss2: (0.0000) | Acc: (94.00%) (40041/42368)
Epoch: 128 | Batch_idx: 340 |  Loss: (0.1581) |  Loss2: (0.0000) | Acc: (94.00%) (41246/43648)
Epoch: 128 | Batch_idx: 350 |  Loss: (0.1593) |  Loss2: (0.0000) | Acc: (94.00%) (42439/44928)
Epoch: 128 | Batch_idx: 360 |  Loss: (0.1592) |  Loss2: (0.0000) | Acc: (94.00%) (43651/46208)
Epoch: 128 | Batch_idx: 370 |  Loss: (0.1592) |  Loss2: (0.0000) | Acc: (94.00%) (44870/47488)
Epoch: 128 | Batch_idx: 380 |  Loss: (0.1592) |  Loss2: (0.0000) | Acc: (94.00%) (46078/48768)
Epoch: 128 | Batch_idx: 390 |  Loss: (0.1593) |  Loss2: (0.0000) | Acc: (94.00%) (47250/50000)
# TEST : Loss: (0.3745) | Acc: (88.00%) (8809/10000)
percent tensor([0.5120, 0.5117, 0.5111, 0.5155, 0.5124, 0.5201, 0.5121, 0.5137, 0.5111,
        0.5107, 0.5114, 0.5103, 0.5112, 0.5138, 0.5145, 0.5144],
       device='cuda:0') torch.Size([16])
percent tensor([0.5088, 0.5100, 0.5067, 0.5052, 0.5025, 0.5162, 0.5051, 0.5008, 0.5054,
        0.5086, 0.5067, 0.5093, 0.5153, 0.5024, 0.5102, 0.5116],
       device='cuda:0') torch.Size([16])
percent tensor([0.5976, 0.5630, 0.6573, 0.6793, 0.6624, 0.6505, 0.6006, 0.6427, 0.6340,
        0.6056, 0.6253, 0.6192, 0.5261, 0.6565, 0.5956, 0.6121],
       device='cuda:0') torch.Size([16])
percent tensor([0.6373, 0.6334, 0.6293, 0.6341, 0.6342, 0.6382, 0.6378, 0.6348, 0.6416,
        0.6374, 0.6414, 0.6423, 0.6356, 0.6361, 0.6413, 0.6429],
       device='cuda:0') torch.Size([16])
percent tensor([0.6151, 0.5860, 0.6299, 0.6432, 0.6683, 0.7101, 0.5882, 0.5916, 0.6188,
        0.6204, 0.5917, 0.5970, 0.6036, 0.6161, 0.5970, 0.6717],
       device='cuda:0') torch.Size([16])
percent tensor([0.6297, 0.6748, 0.6678, 0.6934, 0.6687, 0.7429, 0.6735, 0.5724, 0.6945,
        0.6505, 0.7171, 0.6748, 0.7129, 0.6971, 0.5789, 0.6714],
       device='cuda:0') torch.Size([16])
percent tensor([0.6268, 0.6315, 0.7092, 0.7525, 0.7498, 0.6700, 0.6974, 0.7186, 0.6044,
        0.6305, 0.6406, 0.6517, 0.5877, 0.6109, 0.6222, 0.6830],
       device='cuda:0') torch.Size([16])
percent tensor([0.9998, 0.9995, 0.9996, 0.9998, 0.9995, 0.9990, 0.9994, 0.9993, 0.9998,
        0.9996, 0.9998, 0.9997, 0.9998, 0.9996, 0.9990, 0.9996],
       device='cuda:0') torch.Size([16])
Epoch: 129 | Batch_idx: 0 |  Loss: (0.1091) |  Loss2: (0.0000) | Acc: (96.00%) (123/128)
Epoch: 129 | Batch_idx: 10 |  Loss: (0.1482) |  Loss2: (0.0000) | Acc: (94.00%) (1334/1408)
Epoch: 129 | Batch_idx: 20 |  Loss: (0.1705) |  Loss2: (0.0000) | Acc: (94.00%) (2531/2688)
Epoch: 129 | Batch_idx: 30 |  Loss: (0.1629) |  Loss2: (0.0000) | Acc: (94.00%) (3749/3968)
Epoch: 129 | Batch_idx: 40 |  Loss: (0.1596) |  Loss2: (0.0000) | Acc: (94.00%) (4967/5248)
Epoch: 129 | Batch_idx: 50 |  Loss: (0.1609) |  Loss2: (0.0000) | Acc: (94.00%) (6175/6528)
Epoch: 129 | Batch_idx: 60 |  Loss: (0.1585) |  Loss2: (0.0000) | Acc: (94.00%) (7391/7808)
Epoch: 129 | Batch_idx: 70 |  Loss: (0.1599) |  Loss2: (0.0000) | Acc: (94.00%) (8595/9088)
Epoch: 129 | Batch_idx: 80 |  Loss: (0.1593) |  Loss2: (0.0000) | Acc: (94.00%) (9806/10368)
Epoch: 129 | Batch_idx: 90 |  Loss: (0.1596) |  Loss2: (0.0000) | Acc: (94.00%) (11019/11648)
Epoch: 129 | Batch_idx: 100 |  Loss: (0.1586) |  Loss2: (0.0000) | Acc: (94.00%) (12232/12928)
Epoch: 129 | Batch_idx: 110 |  Loss: (0.1571) |  Loss2: (0.0000) | Acc: (94.00%) (13458/14208)
Epoch: 129 | Batch_idx: 120 |  Loss: (0.1554) |  Loss2: (0.0000) | Acc: (94.00%) (14672/15488)
Epoch: 129 | Batch_idx: 130 |  Loss: (0.1558) |  Loss2: (0.0000) | Acc: (94.00%) (15877/16768)
Epoch: 129 | Batch_idx: 140 |  Loss: (0.1559) |  Loss2: (0.0000) | Acc: (94.00%) (17076/18048)
Epoch: 129 | Batch_idx: 150 |  Loss: (0.1550) |  Loss2: (0.0000) | Acc: (94.00%) (18291/19328)
Epoch: 129 | Batch_idx: 160 |  Loss: (0.1551) |  Loss2: (0.0000) | Acc: (94.00%) (19502/20608)
Epoch: 129 | Batch_idx: 170 |  Loss: (0.1554) |  Loss2: (0.0000) | Acc: (94.00%) (20703/21888)
Epoch: 129 | Batch_idx: 180 |  Loss: (0.1561) |  Loss2: (0.0000) | Acc: (94.00%) (21906/23168)
Epoch: 129 | Batch_idx: 190 |  Loss: (0.1572) |  Loss2: (0.0000) | Acc: (94.00%) (23113/24448)
Epoch: 129 | Batch_idx: 200 |  Loss: (0.1568) |  Loss2: (0.0000) | Acc: (94.00%) (24325/25728)
Epoch: 129 | Batch_idx: 210 |  Loss: (0.1569) |  Loss2: (0.0000) | Acc: (94.00%) (25534/27008)
Epoch: 129 | Batch_idx: 220 |  Loss: (0.1558) |  Loss2: (0.0000) | Acc: (94.00%) (26760/28288)
Epoch: 129 | Batch_idx: 230 |  Loss: (0.1564) |  Loss2: (0.0000) | Acc: (94.00%) (27967/29568)
Epoch: 129 | Batch_idx: 240 |  Loss: (0.1564) |  Loss2: (0.0000) | Acc: (94.00%) (29178/30848)
Epoch: 129 | Batch_idx: 250 |  Loss: (0.1570) |  Loss2: (0.0000) | Acc: (94.00%) (30387/32128)
Epoch: 129 | Batch_idx: 260 |  Loss: (0.1573) |  Loss2: (0.0000) | Acc: (94.00%) (31590/33408)
Epoch: 129 | Batch_idx: 270 |  Loss: (0.1570) |  Loss2: (0.0000) | Acc: (94.00%) (32792/34688)
Epoch: 129 | Batch_idx: 280 |  Loss: (0.1568) |  Loss2: (0.0000) | Acc: (94.00%) (34009/35968)
Epoch: 129 | Batch_idx: 290 |  Loss: (0.1562) |  Loss2: (0.0000) | Acc: (94.00%) (35233/37248)
Epoch: 129 | Batch_idx: 300 |  Loss: (0.1555) |  Loss2: (0.0000) | Acc: (94.00%) (36452/38528)
Epoch: 129 | Batch_idx: 310 |  Loss: (0.1561) |  Loss2: (0.0000) | Acc: (94.00%) (37648/39808)
Epoch: 129 | Batch_idx: 320 |  Loss: (0.1553) |  Loss2: (0.0000) | Acc: (94.00%) (38875/41088)
Epoch: 129 | Batch_idx: 330 |  Loss: (0.1556) |  Loss2: (0.0000) | Acc: (94.00%) (40086/42368)
Epoch: 129 | Batch_idx: 340 |  Loss: (0.1554) |  Loss2: (0.0000) | Acc: (94.00%) (41304/43648)
Epoch: 129 | Batch_idx: 350 |  Loss: (0.1557) |  Loss2: (0.0000) | Acc: (94.00%) (42510/44928)
Epoch: 129 | Batch_idx: 360 |  Loss: (0.1554) |  Loss2: (0.0000) | Acc: (94.00%) (43719/46208)
Epoch: 129 | Batch_idx: 370 |  Loss: (0.1555) |  Loss2: (0.0000) | Acc: (94.00%) (44923/47488)
Epoch: 129 | Batch_idx: 380 |  Loss: (0.1555) |  Loss2: (0.0000) | Acc: (94.00%) (46142/48768)
Epoch: 129 | Batch_idx: 390 |  Loss: (0.1556) |  Loss2: (0.0000) | Acc: (94.00%) (47307/50000)
# TEST : Loss: (0.3659) | Acc: (88.00%) (8840/10000)
percent tensor([0.5117, 0.5114, 0.5109, 0.5153, 0.5121, 0.5198, 0.5118, 0.5135, 0.5109,
        0.5104, 0.5110, 0.5101, 0.5108, 0.5134, 0.5142, 0.5141],
       device='cuda:0') torch.Size([16])
percent tensor([0.5073, 0.5084, 0.5057, 0.5039, 0.5015, 0.5144, 0.5037, 0.4999, 0.5036,
        0.5069, 0.5044, 0.5080, 0.5137, 0.5004, 0.5087, 0.5099],
       device='cuda:0') torch.Size([16])
percent tensor([0.5929, 0.5637, 0.6526, 0.6745, 0.6577, 0.6442, 0.5987, 0.6377, 0.6309,
        0.6032, 0.6231, 0.6168, 0.5251, 0.6545, 0.5927, 0.6069],
       device='cuda:0') torch.Size([16])
percent tensor([0.6377, 0.6347, 0.6305, 0.6354, 0.6350, 0.6384, 0.6386, 0.6362, 0.6422,
        0.6386, 0.6419, 0.6435, 0.6366, 0.6368, 0.6421, 0.6436],
       device='cuda:0') torch.Size([16])
percent tensor([0.6136, 0.5814, 0.6310, 0.6436, 0.6714, 0.7115, 0.5862, 0.5932, 0.6152,
        0.6178, 0.5846, 0.5916, 0.5988, 0.6125, 0.5933, 0.6706],
       device='cuda:0') torch.Size([16])
percent tensor([0.6248, 0.6719, 0.6628, 0.6896, 0.6628, 0.7391, 0.6716, 0.5637, 0.6935,
        0.6476, 0.7165, 0.6734, 0.7127, 0.6963, 0.5728, 0.6644],
       device='cuda:0') torch.Size([16])
percent tensor([0.6350, 0.6437, 0.7056, 0.7486, 0.7441, 0.6802, 0.7044, 0.7087, 0.6172,
        0.6390, 0.6538, 0.6539, 0.6089, 0.6219, 0.6250, 0.6855],
       device='cuda:0') torch.Size([16])
percent tensor([0.9998, 0.9995, 0.9996, 0.9998, 0.9995, 0.9990, 0.9995, 0.9994, 0.9998,
        0.9996, 0.9998, 0.9997, 0.9998, 0.9996, 0.9990, 0.9996],
       device='cuda:0') torch.Size([16])
Epoch: 130 | Batch_idx: 0 |  Loss: (0.2695) |  Loss2: (0.0000) | Acc: (92.00%) (118/128)
Epoch: 130 | Batch_idx: 10 |  Loss: (0.1345) |  Loss2: (0.0000) | Acc: (95.00%) (1349/1408)
Epoch: 130 | Batch_idx: 20 |  Loss: (0.1321) |  Loss2: (0.0000) | Acc: (95.00%) (2573/2688)
Epoch: 130 | Batch_idx: 30 |  Loss: (0.1383) |  Loss2: (0.0000) | Acc: (95.00%) (3780/3968)
Epoch: 130 | Batch_idx: 40 |  Loss: (0.1461) |  Loss2: (0.0000) | Acc: (94.00%) (4979/5248)
Epoch: 130 | Batch_idx: 50 |  Loss: (0.1454) |  Loss2: (0.0000) | Acc: (94.00%) (6201/6528)
Epoch: 130 | Batch_idx: 60 |  Loss: (0.1439) |  Loss2: (0.0000) | Acc: (95.00%) (7420/7808)
Epoch: 130 | Batch_idx: 70 |  Loss: (0.1467) |  Loss2: (0.0000) | Acc: (94.00%) (8623/9088)
Epoch: 130 | Batch_idx: 80 |  Loss: (0.1450) |  Loss2: (0.0000) | Acc: (94.00%) (9842/10368)
Epoch: 130 | Batch_idx: 90 |  Loss: (0.1433) |  Loss2: (0.0000) | Acc: (94.00%) (11065/11648)
Epoch: 130 | Batch_idx: 100 |  Loss: (0.1446) |  Loss2: (0.0000) | Acc: (94.00%) (12268/12928)
Epoch: 130 | Batch_idx: 110 |  Loss: (0.1457) |  Loss2: (0.0000) | Acc: (94.00%) (13479/14208)
Epoch: 130 | Batch_idx: 120 |  Loss: (0.1471) |  Loss2: (0.0000) | Acc: (94.00%) (14695/15488)
Epoch: 130 | Batch_idx: 130 |  Loss: (0.1472) |  Loss2: (0.0000) | Acc: (94.00%) (15910/16768)
Epoch: 130 | Batch_idx: 140 |  Loss: (0.1472) |  Loss2: (0.0000) | Acc: (94.00%) (17121/18048)
Epoch: 130 | Batch_idx: 150 |  Loss: (0.1458) |  Loss2: (0.0000) | Acc: (94.00%) (18356/19328)
Epoch: 130 | Batch_idx: 160 |  Loss: (0.1454) |  Loss2: (0.0000) | Acc: (95.00%) (19585/20608)
Epoch: 130 | Batch_idx: 170 |  Loss: (0.1463) |  Loss2: (0.0000) | Acc: (95.00%) (20802/21888)
Epoch: 130 | Batch_idx: 180 |  Loss: (0.1464) |  Loss2: (0.0000) | Acc: (94.00%) (22009/23168)
Epoch: 130 | Batch_idx: 190 |  Loss: (0.1490) |  Loss2: (0.0000) | Acc: (94.00%) (23202/24448)
Epoch: 130 | Batch_idx: 200 |  Loss: (0.1497) |  Loss2: (0.0000) | Acc: (94.00%) (24412/25728)
Epoch: 130 | Batch_idx: 210 |  Loss: (0.1486) |  Loss2: (0.0000) | Acc: (94.00%) (25635/27008)
Epoch: 130 | Batch_idx: 220 |  Loss: (0.1478) |  Loss2: (0.0000) | Acc: (94.00%) (26857/28288)
Epoch: 130 | Batch_idx: 230 |  Loss: (0.1484) |  Loss2: (0.0000) | Acc: (94.00%) (28069/29568)
Epoch: 130 | Batch_idx: 240 |  Loss: (0.1479) |  Loss2: (0.0000) | Acc: (94.00%) (29297/30848)
Epoch: 130 | Batch_idx: 250 |  Loss: (0.1479) |  Loss2: (0.0000) | Acc: (94.00%) (30506/32128)
Epoch: 130 | Batch_idx: 260 |  Loss: (0.1476) |  Loss2: (0.0000) | Acc: (94.00%) (31719/33408)
Epoch: 130 | Batch_idx: 270 |  Loss: (0.1474) |  Loss2: (0.0000) | Acc: (94.00%) (32932/34688)
Epoch: 130 | Batch_idx: 280 |  Loss: (0.1471) |  Loss2: (0.0000) | Acc: (94.00%) (34146/35968)
Epoch: 130 | Batch_idx: 290 |  Loss: (0.1467) |  Loss2: (0.0000) | Acc: (94.00%) (35366/37248)
Epoch: 130 | Batch_idx: 300 |  Loss: (0.1463) |  Loss2: (0.0000) | Acc: (94.00%) (36588/38528)
Epoch: 130 | Batch_idx: 310 |  Loss: (0.1467) |  Loss2: (0.0000) | Acc: (94.00%) (37809/39808)
Epoch: 130 | Batch_idx: 320 |  Loss: (0.1469) |  Loss2: (0.0000) | Acc: (94.00%) (39025/41088)
Epoch: 130 | Batch_idx: 330 |  Loss: (0.1477) |  Loss2: (0.0000) | Acc: (94.00%) (40227/42368)
Epoch: 130 | Batch_idx: 340 |  Loss: (0.1478) |  Loss2: (0.0000) | Acc: (94.00%) (41440/43648)
Epoch: 130 | Batch_idx: 350 |  Loss: (0.1483) |  Loss2: (0.0000) | Acc: (94.00%) (42646/44928)
Epoch: 130 | Batch_idx: 360 |  Loss: (0.1483) |  Loss2: (0.0000) | Acc: (94.00%) (43862/46208)
Epoch: 130 | Batch_idx: 370 |  Loss: (0.1484) |  Loss2: (0.0000) | Acc: (94.00%) (45081/47488)
Epoch: 130 | Batch_idx: 380 |  Loss: (0.1483) |  Loss2: (0.0000) | Acc: (94.00%) (46304/48768)
Epoch: 130 | Batch_idx: 390 |  Loss: (0.1487) |  Loss2: (0.0000) | Acc: (94.00%) (47462/50000)
=> saving checkpoint 'drive/app/torch/save_Schedule/checkpoint_130.pth.tar'
# TEST : Loss: (0.3639) | Acc: (88.00%) (8827/10000)
percent tensor([0.5120, 0.5117, 0.5113, 0.5156, 0.5125, 0.5201, 0.5123, 0.5139, 0.5111,
        0.5108, 0.5113, 0.5105, 0.5112, 0.5136, 0.5145, 0.5144],
       device='cuda:0') torch.Size([16])
percent tensor([0.5075, 0.5084, 0.5059, 0.5039, 0.5018, 0.5147, 0.5039, 0.5001, 0.5035,
        0.5068, 0.5041, 0.5080, 0.5138, 0.5002, 0.5090, 0.5100],
       device='cuda:0') torch.Size([16])
percent tensor([0.5867, 0.5609, 0.6505, 0.6728, 0.6562, 0.6390, 0.5955, 0.6344, 0.6247,
        0.5993, 0.6174, 0.6128, 0.5188, 0.6496, 0.5894, 0.6015],
       device='cuda:0') torch.Size([16])
percent tensor([0.6384, 0.6370, 0.6317, 0.6363, 0.6353, 0.6385, 0.6400, 0.6371, 0.6430,
        0.6407, 0.6437, 0.6453, 0.6384, 0.6384, 0.6434, 0.6449],
       device='cuda:0') torch.Size([16])
percent tensor([0.6097, 0.5785, 0.6295, 0.6419, 0.6683, 0.7131, 0.5812, 0.5901, 0.6115,
        0.6151, 0.5794, 0.5893, 0.5964, 0.6098, 0.5888, 0.6687],
       device='cuda:0') torch.Size([16])
percent tensor([0.6301, 0.6775, 0.6676, 0.6951, 0.6678, 0.7451, 0.6786, 0.5662, 0.7005,
        0.6531, 0.7234, 0.6800, 0.7212, 0.7021, 0.5765, 0.6702],
       device='cuda:0') torch.Size([16])
percent tensor([0.6335, 0.6428, 0.7043, 0.7482, 0.7427, 0.6855, 0.7039, 0.7049, 0.6159,
        0.6379, 0.6547, 0.6518, 0.6130, 0.6169, 0.6224, 0.6835],
       device='cuda:0') torch.Size([16])
percent tensor([0.9998, 0.9995, 0.9996, 0.9998, 0.9995, 0.9990, 0.9995, 0.9994, 0.9998,
        0.9996, 0.9998, 0.9997, 0.9998, 0.9996, 0.9990, 0.9996],
       device='cuda:0') torch.Size([16])
Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 3, 3, 3]) tensor(178.5874, device='cuda:0')
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(823.7971, device='cuda:0')
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(818.8249, device='cuda:0')
Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([128, 64, 3, 3]) tensor(1517.9983, device='cuda:0')
Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([128, 64, 1, 1]) tensor(489.7989, device='cuda:0')
Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([128, 128, 3, 3]) tensor(2258.8582, device='cuda:0')
Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([256, 128, 3, 3]) tensor(4268.5288, device='cuda:0')
Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([256, 128, 1, 1]) tensor(1380.0337, device='cuda:0')
Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([256, 256, 3, 3]) tensor(6192.7192, device='cuda:0')
Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([512, 256, 3, 3]) tensor(11755.2148, device='cuda:0')
Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([512, 256, 1, 1]) tensor(3887.8733, device='cuda:0')
Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([512, 512, 3, 3]) tensor(16449.0254, device='cuda:0')
Epoch: 131 | Batch_idx: 0 |  Loss: (0.1312) |  Loss2: (0.0000) | Acc: (95.00%) (122/128)
Epoch: 131 | Batch_idx: 10 |  Loss: (0.1531) |  Loss2: (0.0000) | Acc: (94.00%) (1329/1408)
Epoch: 131 | Batch_idx: 20 |  Loss: (0.1476) |  Loss2: (0.0000) | Acc: (94.00%) (2540/2688)
Epoch: 131 | Batch_idx: 30 |  Loss: (0.1482) |  Loss2: (0.0000) | Acc: (94.00%) (3753/3968)
Epoch: 131 | Batch_idx: 40 |  Loss: (0.1489) |  Loss2: (0.0000) | Acc: (94.00%) (4966/5248)
Epoch: 131 | Batch_idx: 50 |  Loss: (0.1481) |  Loss2: (0.0000) | Acc: (94.00%) (6199/6528)
Epoch: 131 | Batch_idx: 60 |  Loss: (0.1523) |  Loss2: (0.0000) | Acc: (94.00%) (7405/7808)
Epoch: 131 | Batch_idx: 70 |  Loss: (0.1508) |  Loss2: (0.0000) | Acc: (94.00%) (8621/9088)
Epoch: 131 | Batch_idx: 80 |  Loss: (0.1493) |  Loss2: (0.0000) | Acc: (94.00%) (9835/10368)
Epoch: 131 | Batch_idx: 90 |  Loss: (0.1502) |  Loss2: (0.0000) | Acc: (94.00%) (11043/11648)
Epoch: 131 | Batch_idx: 100 |  Loss: (0.1491) |  Loss2: (0.0000) | Acc: (94.00%) (12260/12928)
Epoch: 131 | Batch_idx: 110 |  Loss: (0.1468) |  Loss2: (0.0000) | Acc: (94.00%) (13492/14208)
Epoch: 131 | Batch_idx: 120 |  Loss: (0.1460) |  Loss2: (0.0000) | Acc: (94.00%) (14711/15488)
Epoch: 131 | Batch_idx: 130 |  Loss: (0.1456) |  Loss2: (0.0000) | Acc: (94.00%) (15928/16768)
Epoch: 131 | Batch_idx: 140 |  Loss: (0.1460) |  Loss2: (0.0000) | Acc: (94.00%) (17140/18048)
Epoch: 131 | Batch_idx: 150 |  Loss: (0.1462) |  Loss2: (0.0000) | Acc: (94.00%) (18355/19328)
Epoch: 131 | Batch_idx: 160 |  Loss: (0.1456) |  Loss2: (0.0000) | Acc: (95.00%) (19583/20608)
Epoch: 131 | Batch_idx: 170 |  Loss: (0.1453) |  Loss2: (0.0000) | Acc: (95.00%) (20797/21888)
Epoch: 131 | Batch_idx: 180 |  Loss: (0.1456) |  Loss2: (0.0000) | Acc: (95.00%) (22010/23168)
Epoch: 131 | Batch_idx: 190 |  Loss: (0.1460) |  Loss2: (0.0000) | Acc: (94.00%) (23221/24448)
Epoch: 131 | Batch_idx: 200 |  Loss: (0.1456) |  Loss2: (0.0000) | Acc: (95.00%) (24443/25728)
Epoch: 131 | Batch_idx: 210 |  Loss: (0.1466) |  Loss2: (0.0000) | Acc: (94.00%) (25652/27008)
Epoch: 131 | Batch_idx: 220 |  Loss: (0.1462) |  Loss2: (0.0000) | Acc: (94.00%) (26870/28288)
Epoch: 131 | Batch_idx: 230 |  Loss: (0.1455) |  Loss2: (0.0000) | Acc: (95.00%) (28102/29568)
Epoch: 131 | Batch_idx: 240 |  Loss: (0.1457) |  Loss2: (0.0000) | Acc: (95.00%) (29320/30848)
Epoch: 131 | Batch_idx: 250 |  Loss: (0.1455) |  Loss2: (0.0000) | Acc: (95.00%) (30547/32128)
Epoch: 131 | Batch_idx: 260 |  Loss: (0.1451) |  Loss2: (0.0000) | Acc: (95.00%) (31766/33408)
Epoch: 131 | Batch_idx: 270 |  Loss: (0.1443) |  Loss2: (0.0000) | Acc: (95.00%) (32986/34688)
Epoch: 131 | Batch_idx: 280 |  Loss: (0.1436) |  Loss2: (0.0000) | Acc: (95.00%) (34217/35968)
Epoch: 131 | Batch_idx: 290 |  Loss: (0.1433) |  Loss2: (0.0000) | Acc: (95.00%) (35442/37248)
Epoch: 131 | Batch_idx: 300 |  Loss: (0.1437) |  Loss2: (0.0000) | Acc: (95.00%) (36661/38528)
Epoch: 131 | Batch_idx: 310 |  Loss: (0.1438) |  Loss2: (0.0000) | Acc: (95.00%) (37880/39808)
Epoch: 131 | Batch_idx: 320 |  Loss: (0.1440) |  Loss2: (0.0000) | Acc: (95.00%) (39098/41088)
Epoch: 131 | Batch_idx: 330 |  Loss: (0.1443) |  Loss2: (0.0000) | Acc: (95.00%) (40306/42368)
Epoch: 131 | Batch_idx: 340 |  Loss: (0.1438) |  Loss2: (0.0000) | Acc: (95.00%) (41527/43648)
Epoch: 131 | Batch_idx: 350 |  Loss: (0.1434) |  Loss2: (0.0000) | Acc: (95.00%) (42754/44928)
Epoch: 131 | Batch_idx: 360 |  Loss: (0.1437) |  Loss2: (0.0000) | Acc: (95.00%) (43969/46208)
Epoch: 131 | Batch_idx: 370 |  Loss: (0.1436) |  Loss2: (0.0000) | Acc: (95.00%) (45190/47488)
Epoch: 131 | Batch_idx: 380 |  Loss: (0.1436) |  Loss2: (0.0000) | Acc: (95.00%) (46408/48768)
Epoch: 131 | Batch_idx: 390 |  Loss: (0.1436) |  Loss2: (0.0000) | Acc: (95.00%) (47579/50000)
# TEST : Loss: (0.3639) | Acc: (88.00%) (8839/10000)
percent tensor([0.5131, 0.5129, 0.5124, 0.5167, 0.5137, 0.5212, 0.5135, 0.5151, 0.5122,
        0.5119, 0.5123, 0.5116, 0.5123, 0.5147, 0.5157, 0.5155],
       device='cuda:0') torch.Size([16])
percent tensor([0.5071, 0.5082, 0.5057, 0.5035, 0.5016, 0.5140, 0.5038, 0.4999, 0.5030,
        0.5064, 0.5034, 0.5078, 0.5136, 0.4996, 0.5086, 0.5096],
       device='cuda:0') torch.Size([16])
percent tensor([0.5816, 0.5607, 0.6452, 0.6663, 0.6512, 0.6310, 0.5937, 0.6309, 0.6207,
        0.5961, 0.6131, 0.6088, 0.5167, 0.6461, 0.5863, 0.5950],
       device='cuda:0') torch.Size([16])
percent tensor([0.6368, 0.6358, 0.6302, 0.6346, 0.6335, 0.6362, 0.6385, 0.6355, 0.6414,
        0.6395, 0.6421, 0.6440, 0.6372, 0.6369, 0.6416, 0.6433],
       device='cuda:0') torch.Size([16])
percent tensor([0.6114, 0.5810, 0.6304, 0.6420, 0.6691, 0.7176, 0.5827, 0.5886, 0.6145,
        0.6192, 0.5829, 0.5900, 0.5983, 0.6148, 0.5891, 0.6710],
       device='cuda:0') torch.Size([16])
percent tensor([0.6234, 0.6746, 0.6616, 0.6898, 0.6611, 0.7416, 0.6742, 0.5559, 0.6969,
        0.6490, 0.7210, 0.6750, 0.7187, 0.7011, 0.5693, 0.6628],
       device='cuda:0') torch.Size([16])
percent tensor([0.6349, 0.6469, 0.7022, 0.7456, 0.7421, 0.6886, 0.7075, 0.6993, 0.6212,
        0.6402, 0.6602, 0.6525, 0.6183, 0.6231, 0.6226, 0.6837],
       device='cuda:0') torch.Size([16])
percent tensor([0.9998, 0.9996, 0.9996, 0.9998, 0.9995, 0.9990, 0.9995, 0.9994, 0.9998,
        0.9996, 0.9998, 0.9997, 0.9999, 0.9996, 0.9990, 0.9996],
       device='cuda:0') torch.Size([16])
True Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=128, out_features=16, bias=False)
False Linear(in_features=16, out_features=2, bias=False)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=128, out_features=16, bias=False)
False Linear(in_features=16, out_features=2, bias=False)
True Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=256, out_features=32, bias=False)
False Linear(in_features=32, out_features=2, bias=False)
True Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=256, out_features=32, bias=False)
False Linear(in_features=32, out_features=2, bias=False)
True Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=512, out_features=64, bias=False)
False Linear(in_features=64, out_features=2, bias=False)
True Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=512, out_features=64, bias=False)
False Linear(in_features=64, out_features=2, bias=False)
True Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1024, out_features=128, bias=False)
False Linear(in_features=128, out_features=2, bias=False)
True Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1024, out_features=128, bias=False)
False Linear(in_features=128, out_features=2, bias=False)
True Linear(in_features=512, out_features=10, bias=True)
Epoch: 132 | Batch_idx: 0 |  Loss: (0.0795) |  Loss2: (0.0000) | Acc: (99.00%) (127/128)
Epoch: 132 | Batch_idx: 10 |  Loss: (0.1368) |  Loss2: (0.0000) | Acc: (95.00%) (1344/1408)
Epoch: 132 | Batch_idx: 20 |  Loss: (0.1542) |  Loss2: (0.0000) | Acc: (94.00%) (2549/2688)
Epoch: 132 | Batch_idx: 30 |  Loss: (0.1525) |  Loss2: (0.0000) | Acc: (94.00%) (3767/3968)
Epoch: 132 | Batch_idx: 40 |  Loss: (0.1511) |  Loss2: (0.0000) | Acc: (94.00%) (4978/5248)
Epoch: 132 | Batch_idx: 50 |  Loss: (0.1511) |  Loss2: (0.0000) | Acc: (94.00%) (6191/6528)
Epoch: 132 | Batch_idx: 60 |  Loss: (0.1539) |  Loss2: (0.0000) | Acc: (94.00%) (7401/7808)
Epoch: 132 | Batch_idx: 70 |  Loss: (0.1571) |  Loss2: (0.0000) | Acc: (94.00%) (8600/9088)
Epoch: 132 | Batch_idx: 80 |  Loss: (0.1581) |  Loss2: (0.0000) | Acc: (94.00%) (9801/10368)
Epoch: 132 | Batch_idx: 90 |  Loss: (0.1590) |  Loss2: (0.0000) | Acc: (94.00%) (11008/11648)
Epoch: 132 | Batch_idx: 100 |  Loss: (0.1588) |  Loss2: (0.0000) | Acc: (94.00%) (12228/12928)
Epoch: 132 | Batch_idx: 110 |  Loss: (0.1577) |  Loss2: (0.0000) | Acc: (94.00%) (13441/14208)
Epoch: 132 | Batch_idx: 120 |  Loss: (0.1575) |  Loss2: (0.0000) | Acc: (94.00%) (14648/15488)
Epoch: 132 | Batch_idx: 130 |  Loss: (0.1593) |  Loss2: (0.0000) | Acc: (94.00%) (15843/16768)
Epoch: 132 | Batch_idx: 140 |  Loss: (0.1605) |  Loss2: (0.0000) | Acc: (94.00%) (17048/18048)
Epoch: 132 | Batch_idx: 150 |  Loss: (0.1606) |  Loss2: (0.0000) | Acc: (94.00%) (18257/19328)
Epoch: 132 | Batch_idx: 160 |  Loss: (0.1606) |  Loss2: (0.0000) | Acc: (94.00%) (19465/20608)
Epoch: 132 | Batch_idx: 170 |  Loss: (0.1605) |  Loss2: (0.0000) | Acc: (94.00%) (20668/21888)
Epoch: 132 | Batch_idx: 180 |  Loss: (0.1614) |  Loss2: (0.0000) | Acc: (94.00%) (21873/23168)
Epoch: 132 | Batch_idx: 190 |  Loss: (0.1627) |  Loss2: (0.0000) | Acc: (94.00%) (23066/24448)
Epoch: 132 | Batch_idx: 200 |  Loss: (0.1617) |  Loss2: (0.0000) | Acc: (94.00%) (24282/25728)
Epoch: 132 | Batch_idx: 210 |  Loss: (0.1620) |  Loss2: (0.0000) | Acc: (94.00%) (25486/27008)
Epoch: 132 | Batch_idx: 220 |  Loss: (0.1616) |  Loss2: (0.0000) | Acc: (94.00%) (26705/28288)
Epoch: 132 | Batch_idx: 230 |  Loss: (0.1617) |  Loss2: (0.0000) | Acc: (94.00%) (27913/29568)
Epoch: 132 | Batch_idx: 240 |  Loss: (0.1617) |  Loss2: (0.0000) | Acc: (94.00%) (29121/30848)
Epoch: 132 | Batch_idx: 250 |  Loss: (0.1617) |  Loss2: (0.0000) | Acc: (94.00%) (30326/32128)
Epoch: 132 | Batch_idx: 260 |  Loss: (0.1621) |  Loss2: (0.0000) | Acc: (94.00%) (31526/33408)
Epoch: 132 | Batch_idx: 270 |  Loss: (0.1624) |  Loss2: (0.0000) | Acc: (94.00%) (32732/34688)
Epoch: 132 | Batch_idx: 280 |  Loss: (0.1627) |  Loss2: (0.0000) | Acc: (94.00%) (33937/35968)
Epoch: 132 | Batch_idx: 290 |  Loss: (0.1634) |  Loss2: (0.0000) | Acc: (94.00%) (35133/37248)
Epoch: 132 | Batch_idx: 300 |  Loss: (0.1635) |  Loss2: (0.0000) | Acc: (94.00%) (36329/38528)
Epoch: 132 | Batch_idx: 310 |  Loss: (0.1633) |  Loss2: (0.0000) | Acc: (94.00%) (37541/39808)
Epoch: 132 | Batch_idx: 320 |  Loss: (0.1628) |  Loss2: (0.0000) | Acc: (94.00%) (38765/41088)
Epoch: 132 | Batch_idx: 330 |  Loss: (0.1628) |  Loss2: (0.0000) | Acc: (94.00%) (39974/42368)
Epoch: 132 | Batch_idx: 340 |  Loss: (0.1626) |  Loss2: (0.0000) | Acc: (94.00%) (41186/43648)
Epoch: 132 | Batch_idx: 350 |  Loss: (0.1625) |  Loss2: (0.0000) | Acc: (94.00%) (42398/44928)
Epoch: 132 | Batch_idx: 360 |  Loss: (0.1634) |  Loss2: (0.0000) | Acc: (94.00%) (43588/46208)
Epoch: 132 | Batch_idx: 370 |  Loss: (0.1636) |  Loss2: (0.0000) | Acc: (94.00%) (44796/47488)
Epoch: 132 | Batch_idx: 380 |  Loss: (0.1637) |  Loss2: (0.0000) | Acc: (94.00%) (46000/48768)
Epoch: 132 | Batch_idx: 390 |  Loss: (0.1636) |  Loss2: (0.0000) | Acc: (94.00%) (47164/50000)
# TEST : Loss: (0.4699) | Acc: (85.00%) (8583/10000)
percent tensor([0.5128, 0.5132, 0.5121, 0.5158, 0.5131, 0.5215, 0.5138, 0.5145, 0.5124,
        0.5117, 0.5127, 0.5113, 0.5121, 0.5159, 0.5156, 0.5152],
       device='cuda:0') torch.Size([16])
percent tensor([0.5063, 0.5104, 0.5008, 0.5028, 0.5000, 0.5158, 0.5048, 0.4992, 0.5037,
        0.5059, 0.5049, 0.5053, 0.5147, 0.5037, 0.5099, 0.5106],
       device='cuda:0') torch.Size([16])
percent tensor([0.5756, 0.5466, 0.6456, 0.6658, 0.6524, 0.6145, 0.5855, 0.6252, 0.6241,
        0.5873, 0.6048, 0.6022, 0.5084, 0.6479, 0.5727, 0.5899],
       device='cuda:0') torch.Size([16])
percent tensor([0.6357, 0.6360, 0.6290, 0.6346, 0.6312, 0.6366, 0.6372, 0.6343, 0.6409,
        0.6373, 0.6424, 0.6421, 0.6364, 0.6349, 0.6406, 0.6430],
       device='cuda:0') torch.Size([16])
percent tensor([0.5984, 0.5696, 0.6290, 0.6356, 0.6603, 0.7134, 0.5796, 0.5861, 0.6253,
        0.6128, 0.5803, 0.5946, 0.5912, 0.6197, 0.5789, 0.6552],
       device='cuda:0') torch.Size([16])
percent tensor([0.6087, 0.6432, 0.6367, 0.6748, 0.6462, 0.7334, 0.6501, 0.5357, 0.6938,
        0.6339, 0.7075, 0.6582, 0.6968, 0.6972, 0.5553, 0.6347],
       device='cuda:0') torch.Size([16])
percent tensor([0.6264, 0.6355, 0.6942, 0.7310, 0.7246, 0.6897, 0.6896, 0.6886, 0.6222,
        0.6427, 0.6418, 0.6495, 0.6087, 0.6180, 0.6150, 0.6592],
       device='cuda:0') torch.Size([16])
percent tensor([0.9998, 0.9991, 0.9996, 0.9998, 0.9996, 0.9985, 0.9995, 0.9995, 0.9997,
        0.9995, 0.9997, 0.9995, 0.9998, 0.9995, 0.9989, 0.9994],
       device='cuda:0') torch.Size([16])
Epoch: 133 | Batch_idx: 0 |  Loss: (0.1187) |  Loss2: (0.0000) | Acc: (95.00%) (122/128)
Epoch: 133 | Batch_idx: 10 |  Loss: (0.1430) |  Loss2: (0.0000) | Acc: (95.00%) (1340/1408)
Epoch: 133 | Batch_idx: 20 |  Loss: (0.1490) |  Loss2: (0.0000) | Acc: (95.00%) (2554/2688)
Epoch: 133 | Batch_idx: 30 |  Loss: (0.1481) |  Loss2: (0.0000) | Acc: (95.00%) (3772/3968)
Epoch: 133 | Batch_idx: 40 |  Loss: (0.1472) |  Loss2: (0.0000) | Acc: (94.00%) (4982/5248)
Epoch: 133 | Batch_idx: 50 |  Loss: (0.1440) |  Loss2: (0.0000) | Acc: (95.00%) (6216/6528)
Epoch: 133 | Batch_idx: 60 |  Loss: (0.1491) |  Loss2: (0.0000) | Acc: (94.00%) (7415/7808)
Epoch: 133 | Batch_idx: 70 |  Loss: (0.1515) |  Loss2: (0.0000) | Acc: (94.00%) (8619/9088)
Epoch: 133 | Batch_idx: 80 |  Loss: (0.1497) |  Loss2: (0.0000) | Acc: (94.00%) (9841/10368)
Epoch: 133 | Batch_idx: 90 |  Loss: (0.1516) |  Loss2: (0.0000) | Acc: (94.00%) (11048/11648)
Epoch: 133 | Batch_idx: 100 |  Loss: (0.1535) |  Loss2: (0.0000) | Acc: (94.00%) (12248/12928)
Epoch: 133 | Batch_idx: 110 |  Loss: (0.1542) |  Loss2: (0.0000) | Acc: (94.00%) (13463/14208)
Epoch: 133 | Batch_idx: 120 |  Loss: (0.1547) |  Loss2: (0.0000) | Acc: (94.00%) (14670/15488)
Epoch: 133 | Batch_idx: 130 |  Loss: (0.1550) |  Loss2: (0.0000) | Acc: (94.00%) (15876/16768)
Epoch: 133 | Batch_idx: 140 |  Loss: (0.1534) |  Loss2: (0.0000) | Acc: (94.00%) (17103/18048)
Epoch: 133 | Batch_idx: 150 |  Loss: (0.1542) |  Loss2: (0.0000) | Acc: (94.00%) (18308/19328)
Epoch: 133 | Batch_idx: 160 |  Loss: (0.1537) |  Loss2: (0.0000) | Acc: (94.00%) (19520/20608)
Epoch: 133 | Batch_idx: 170 |  Loss: (0.1545) |  Loss2: (0.0000) | Acc: (94.00%) (20725/21888)
Epoch: 133 | Batch_idx: 180 |  Loss: (0.1547) |  Loss2: (0.0000) | Acc: (94.00%) (21939/23168)
Epoch: 133 | Batch_idx: 190 |  Loss: (0.1550) |  Loss2: (0.0000) | Acc: (94.00%) (23157/24448)
Epoch: 133 | Batch_idx: 200 |  Loss: (0.1562) |  Loss2: (0.0000) | Acc: (94.00%) (24360/25728)
Epoch: 133 | Batch_idx: 210 |  Loss: (0.1562) |  Loss2: (0.0000) | Acc: (94.00%) (25574/27008)
Epoch: 133 | Batch_idx: 220 |  Loss: (0.1574) |  Loss2: (0.0000) | Acc: (94.00%) (26778/28288)
Epoch: 133 | Batch_idx: 230 |  Loss: (0.1580) |  Loss2: (0.0000) | Acc: (94.00%) (27989/29568)
Epoch: 133 | Batch_idx: 240 |  Loss: (0.1591) |  Loss2: (0.0000) | Acc: (94.00%) (29194/30848)
Epoch: 133 | Batch_idx: 250 |  Loss: (0.1596) |  Loss2: (0.0000) | Acc: (94.00%) (30399/32128)
Epoch: 133 | Batch_idx: 260 |  Loss: (0.1602) |  Loss2: (0.0000) | Acc: (94.00%) (31592/33408)
Epoch: 133 | Batch_idx: 270 |  Loss: (0.1600) |  Loss2: (0.0000) | Acc: (94.00%) (32802/34688)
Epoch: 133 | Batch_idx: 280 |  Loss: (0.1606) |  Loss2: (0.0000) | Acc: (94.00%) (34004/35968)
Epoch: 133 | Batch_idx: 290 |  Loss: (0.1611) |  Loss2: (0.0000) | Acc: (94.00%) (35203/37248)
Epoch: 133 | Batch_idx: 300 |  Loss: (0.1619) |  Loss2: (0.0000) | Acc: (94.00%) (36399/38528)
Epoch: 133 | Batch_idx: 310 |  Loss: (0.1618) |  Loss2: (0.0000) | Acc: (94.00%) (37607/39808)
Epoch: 133 | Batch_idx: 320 |  Loss: (0.1620) |  Loss2: (0.0000) | Acc: (94.00%) (38805/41088)
Epoch: 133 | Batch_idx: 330 |  Loss: (0.1621) |  Loss2: (0.0000) | Acc: (94.00%) (39997/42368)
Epoch: 133 | Batch_idx: 340 |  Loss: (0.1618) |  Loss2: (0.0000) | Acc: (94.00%) (41206/43648)
Epoch: 133 | Batch_idx: 350 |  Loss: (0.1615) |  Loss2: (0.0000) | Acc: (94.00%) (42421/44928)
Epoch: 133 | Batch_idx: 360 |  Loss: (0.1616) |  Loss2: (0.0000) | Acc: (94.00%) (43632/46208)
Epoch: 133 | Batch_idx: 370 |  Loss: (0.1619) |  Loss2: (0.0000) | Acc: (94.00%) (44836/47488)
Epoch: 133 | Batch_idx: 380 |  Loss: (0.1620) |  Loss2: (0.0000) | Acc: (94.00%) (46034/48768)
Epoch: 133 | Batch_idx: 390 |  Loss: (0.1621) |  Loss2: (0.0000) | Acc: (94.00%) (47190/50000)
# TEST : Loss: (0.3907) | Acc: (87.00%) (8768/10000)
percent tensor([0.5136, 0.5130, 0.5154, 0.5164, 0.5159, 0.5216, 0.5142, 0.5160, 0.5134,
        0.5127, 0.5129, 0.5141, 0.5127, 0.5142, 0.5158, 0.5152],
       device='cuda:0') torch.Size([16])
percent tensor([0.5062, 0.5096, 0.5041, 0.5031, 0.5005, 0.5136, 0.5043, 0.4998, 0.5023,
        0.5065, 0.5043, 0.5077, 0.5136, 0.5002, 0.5087, 0.5099],
       device='cuda:0') torch.Size([16])
percent tensor([0.5851, 0.5519, 0.6424, 0.6697, 0.6535, 0.6186, 0.5943, 0.6336, 0.6308,
        0.5912, 0.6091, 0.6137, 0.5174, 0.6624, 0.5793, 0.5945],
       device='cuda:0') torch.Size([16])
percent tensor([0.6370, 0.6353, 0.6328, 0.6373, 0.6351, 0.6381, 0.6402, 0.6387, 0.6399,
        0.6398, 0.6397, 0.6440, 0.6357, 0.6371, 0.6402, 0.6450],
       device='cuda:0') torch.Size([16])
percent tensor([0.6155, 0.5775, 0.6514, 0.6547, 0.6758, 0.7253, 0.5989, 0.6004, 0.6184,
        0.6308, 0.5734, 0.6054, 0.6021, 0.6292, 0.5872, 0.6701],
       device='cuda:0') torch.Size([16])
percent tensor([0.6240, 0.6648, 0.6584, 0.6963, 0.6770, 0.7398, 0.6708, 0.5648, 0.7009,
        0.6456, 0.7188, 0.6674, 0.7241, 0.6984, 0.5741, 0.6684],
       device='cuda:0') torch.Size([16])
percent tensor([0.6531, 0.6578, 0.6926, 0.7465, 0.7390, 0.6984, 0.7081, 0.7143, 0.6371,
        0.6662, 0.6532, 0.6684, 0.6348, 0.6263, 0.6278, 0.6945],
       device='cuda:0') torch.Size([16])
percent tensor([0.9998, 0.9993, 0.9996, 0.9998, 0.9996, 0.9985, 0.9995, 0.9998, 0.9998,
        0.9997, 0.9998, 0.9996, 0.9999, 0.9994, 0.9988, 0.9994],
       device='cuda:0') torch.Size([16])
Epoch: 134 | Batch_idx: 0 |  Loss: (0.1340) |  Loss2: (0.0000) | Acc: (95.00%) (122/128)
Epoch: 134 | Batch_idx: 10 |  Loss: (0.1355) |  Loss2: (0.0000) | Acc: (95.00%) (1346/1408)
Epoch: 134 | Batch_idx: 20 |  Loss: (0.1385) |  Loss2: (0.0000) | Acc: (95.00%) (2566/2688)
Epoch: 134 | Batch_idx: 30 |  Loss: (0.1433) |  Loss2: (0.0000) | Acc: (95.00%) (3778/3968)
Epoch: 134 | Batch_idx: 40 |  Loss: (0.1447) |  Loss2: (0.0000) | Acc: (95.00%) (4991/5248)
Epoch: 134 | Batch_idx: 50 |  Loss: (0.1434) |  Loss2: (0.0000) | Acc: (95.00%) (6214/6528)
Epoch: 134 | Batch_idx: 60 |  Loss: (0.1458) |  Loss2: (0.0000) | Acc: (95.00%) (7431/7808)
Epoch: 134 | Batch_idx: 70 |  Loss: (0.1468) |  Loss2: (0.0000) | Acc: (95.00%) (8653/9088)
Epoch: 134 | Batch_idx: 80 |  Loss: (0.1469) |  Loss2: (0.0000) | Acc: (95.00%) (9876/10368)
Epoch: 134 | Batch_idx: 90 |  Loss: (0.1478) |  Loss2: (0.0000) | Acc: (95.00%) (11090/11648)
Epoch: 134 | Batch_idx: 100 |  Loss: (0.1505) |  Loss2: (0.0000) | Acc: (95.00%) (12285/12928)
Epoch: 134 | Batch_idx: 110 |  Loss: (0.1514) |  Loss2: (0.0000) | Acc: (94.00%) (13489/14208)
Epoch: 134 | Batch_idx: 120 |  Loss: (0.1535) |  Loss2: (0.0000) | Acc: (94.00%) (14679/15488)
Epoch: 134 | Batch_idx: 130 |  Loss: (0.1558) |  Loss2: (0.0000) | Acc: (94.00%) (15880/16768)
Epoch: 134 | Batch_idx: 140 |  Loss: (0.1565) |  Loss2: (0.0000) | Acc: (94.00%) (17088/18048)
Epoch: 134 | Batch_idx: 150 |  Loss: (0.1563) |  Loss2: (0.0000) | Acc: (94.00%) (18296/19328)
Epoch: 134 | Batch_idx: 160 |  Loss: (0.1553) |  Loss2: (0.0000) | Acc: (94.00%) (19510/20608)
Epoch: 134 | Batch_idx: 170 |  Loss: (0.1573) |  Loss2: (0.0000) | Acc: (94.00%) (20704/21888)
Epoch: 134 | Batch_idx: 180 |  Loss: (0.1581) |  Loss2: (0.0000) | Acc: (94.00%) (21905/23168)
Epoch: 134 | Batch_idx: 190 |  Loss: (0.1581) |  Loss2: (0.0000) | Acc: (94.00%) (23116/24448)
Epoch: 134 | Batch_idx: 200 |  Loss: (0.1587) |  Loss2: (0.0000) | Acc: (94.00%) (24316/25728)
Epoch: 134 | Batch_idx: 210 |  Loss: (0.1593) |  Loss2: (0.0000) | Acc: (94.00%) (25522/27008)
Epoch: 134 | Batch_idx: 220 |  Loss: (0.1588) |  Loss2: (0.0000) | Acc: (94.00%) (26742/28288)
Epoch: 134 | Batch_idx: 230 |  Loss: (0.1583) |  Loss2: (0.0000) | Acc: (94.00%) (27951/29568)
Epoch: 134 | Batch_idx: 240 |  Loss: (0.1586) |  Loss2: (0.0000) | Acc: (94.00%) (29156/30848)
Epoch: 134 | Batch_idx: 250 |  Loss: (0.1583) |  Loss2: (0.0000) | Acc: (94.00%) (30369/32128)
Epoch: 134 | Batch_idx: 260 |  Loss: (0.1581) |  Loss2: (0.0000) | Acc: (94.00%) (31578/33408)
Epoch: 134 | Batch_idx: 270 |  Loss: (0.1576) |  Loss2: (0.0000) | Acc: (94.00%) (32797/34688)
Epoch: 134 | Batch_idx: 280 |  Loss: (0.1570) |  Loss2: (0.0000) | Acc: (94.00%) (34011/35968)
Epoch: 134 | Batch_idx: 290 |  Loss: (0.1565) |  Loss2: (0.0000) | Acc: (94.00%) (35226/37248)
Epoch: 134 | Batch_idx: 300 |  Loss: (0.1569) |  Loss2: (0.0000) | Acc: (94.00%) (36430/38528)
Epoch: 134 | Batch_idx: 310 |  Loss: (0.1563) |  Loss2: (0.0000) | Acc: (94.00%) (37646/39808)
Epoch: 134 | Batch_idx: 320 |  Loss: (0.1563) |  Loss2: (0.0000) | Acc: (94.00%) (38866/41088)
Epoch: 134 | Batch_idx: 330 |  Loss: (0.1558) |  Loss2: (0.0000) | Acc: (94.00%) (40084/42368)
Epoch: 134 | Batch_idx: 340 |  Loss: (0.1561) |  Loss2: (0.0000) | Acc: (94.00%) (41291/43648)
Epoch: 134 | Batch_idx: 350 |  Loss: (0.1564) |  Loss2: (0.0000) | Acc: (94.00%) (42498/44928)
Epoch: 134 | Batch_idx: 360 |  Loss: (0.1571) |  Loss2: (0.0000) | Acc: (94.00%) (43696/46208)
Epoch: 134 | Batch_idx: 370 |  Loss: (0.1567) |  Loss2: (0.0000) | Acc: (94.00%) (44906/47488)
Epoch: 134 | Batch_idx: 380 |  Loss: (0.1565) |  Loss2: (0.0000) | Acc: (94.00%) (46119/48768)
Epoch: 134 | Batch_idx: 390 |  Loss: (0.1568) |  Loss2: (0.0000) | Acc: (94.00%) (47281/50000)
# TEST : Loss: (0.3990) | Acc: (87.00%) (8725/10000)
percent tensor([0.5131, 0.5133, 0.5132, 0.5166, 0.5143, 0.5225, 0.5138, 0.5152, 0.5125,
        0.5119, 0.5127, 0.5121, 0.5121, 0.5152, 0.5164, 0.5153],
       device='cuda:0') torch.Size([16])
percent tensor([0.5064, 0.5106, 0.5030, 0.5024, 0.4995, 0.5139, 0.5049, 0.4995, 0.5029,
        0.5072, 0.5048, 0.5062, 0.5141, 0.5023, 0.5091, 0.5102],
       device='cuda:0') torch.Size([16])
percent tensor([0.5852, 0.5568, 0.6483, 0.6683, 0.6593, 0.6244, 0.5962, 0.6352, 0.6258,
        0.5941, 0.6116, 0.6153, 0.5186, 0.6549, 0.5828, 0.5954],
       device='cuda:0') torch.Size([16])
percent tensor([0.6366, 0.6364, 0.6334, 0.6343, 0.6358, 0.6349, 0.6402, 0.6364, 0.6425,
        0.6394, 0.6409, 0.6459, 0.6372, 0.6381, 0.6399, 0.6424],
       device='cuda:0') torch.Size([16])
percent tensor([0.6148, 0.5835, 0.6493, 0.6572, 0.6733, 0.7267, 0.5962, 0.5978, 0.6187,
        0.6336, 0.5921, 0.6014, 0.6036, 0.6253, 0.5909, 0.6688],
       device='cuda:0') torch.Size([16])
percent tensor([0.6262, 0.6720, 0.6712, 0.7028, 0.6652, 0.7436, 0.6781, 0.5734, 0.6990,
        0.6618, 0.7268, 0.6765, 0.7229, 0.7126, 0.5938, 0.6805],
       device='cuda:0') torch.Size([16])
percent tensor([0.6466, 0.6513, 0.6930, 0.7391, 0.7248, 0.6831, 0.6937, 0.7152, 0.6238,
        0.6696, 0.6652, 0.6610, 0.6350, 0.6338, 0.6332, 0.6819],
       device='cuda:0') torch.Size([16])
percent tensor([0.9999, 0.9996, 0.9994, 0.9997, 0.9995, 0.9992, 0.9993, 0.9996, 0.9998,
        0.9997, 0.9999, 0.9997, 0.9999, 0.9995, 0.9987, 0.9994],
       device='cuda:0') torch.Size([16])
Epoch: 135 | Batch_idx: 0 |  Loss: (0.1062) |  Loss2: (0.0000) | Acc: (95.00%) (122/128)
Epoch: 135 | Batch_idx: 10 |  Loss: (0.1443) |  Loss2: (0.0000) | Acc: (95.00%) (1338/1408)
Epoch: 135 | Batch_idx: 20 |  Loss: (0.1435) |  Loss2: (0.0000) | Acc: (95.00%) (2555/2688)
Epoch: 135 | Batch_idx: 30 |  Loss: (0.1405) |  Loss2: (0.0000) | Acc: (95.00%) (3778/3968)
Epoch: 135 | Batch_idx: 40 |  Loss: (0.1433) |  Loss2: (0.0000) | Acc: (95.00%) (4990/5248)
Epoch: 135 | Batch_idx: 50 |  Loss: (0.1449) |  Loss2: (0.0000) | Acc: (95.00%) (6204/6528)
Epoch: 135 | Batch_idx: 60 |  Loss: (0.1457) |  Loss2: (0.0000) | Acc: (94.00%) (7417/7808)
Epoch: 135 | Batch_idx: 70 |  Loss: (0.1474) |  Loss2: (0.0000) | Acc: (94.00%) (8633/9088)
Epoch: 135 | Batch_idx: 80 |  Loss: (0.1471) |  Loss2: (0.0000) | Acc: (94.00%) (9848/10368)
Epoch: 135 | Batch_idx: 90 |  Loss: (0.1440) |  Loss2: (0.0000) | Acc: (95.00%) (11079/11648)
Epoch: 135 | Batch_idx: 100 |  Loss: (0.1434) |  Loss2: (0.0000) | Acc: (95.00%) (12291/12928)
Epoch: 135 | Batch_idx: 110 |  Loss: (0.1434) |  Loss2: (0.0000) | Acc: (95.00%) (13511/14208)
Epoch: 135 | Batch_idx: 120 |  Loss: (0.1421) |  Loss2: (0.0000) | Acc: (95.00%) (14736/15488)
Epoch: 135 | Batch_idx: 130 |  Loss: (0.1427) |  Loss2: (0.0000) | Acc: (95.00%) (15947/16768)
Epoch: 135 | Batch_idx: 140 |  Loss: (0.1420) |  Loss2: (0.0000) | Acc: (95.00%) (17172/18048)
Epoch: 135 | Batch_idx: 150 |  Loss: (0.1414) |  Loss2: (0.0000) | Acc: (95.00%) (18391/19328)
Epoch: 135 | Batch_idx: 160 |  Loss: (0.1423) |  Loss2: (0.0000) | Acc: (95.00%) (19602/20608)
Epoch: 135 | Batch_idx: 170 |  Loss: (0.1434) |  Loss2: (0.0000) | Acc: (95.00%) (20805/21888)
Epoch: 135 | Batch_idx: 180 |  Loss: (0.1443) |  Loss2: (0.0000) | Acc: (95.00%) (22019/23168)
Epoch: 135 | Batch_idx: 190 |  Loss: (0.1455) |  Loss2: (0.0000) | Acc: (94.00%) (23225/24448)
Epoch: 135 | Batch_idx: 200 |  Loss: (0.1451) |  Loss2: (0.0000) | Acc: (95.00%) (24442/25728)
Epoch: 135 | Batch_idx: 210 |  Loss: (0.1451) |  Loss2: (0.0000) | Acc: (95.00%) (25658/27008)
Epoch: 135 | Batch_idx: 220 |  Loss: (0.1451) |  Loss2: (0.0000) | Acc: (95.00%) (26877/28288)
Epoch: 135 | Batch_idx: 230 |  Loss: (0.1461) |  Loss2: (0.0000) | Acc: (94.00%) (28080/29568)
Epoch: 135 | Batch_idx: 240 |  Loss: (0.1463) |  Loss2: (0.0000) | Acc: (94.00%) (29297/30848)
Epoch: 135 | Batch_idx: 250 |  Loss: (0.1473) |  Loss2: (0.0000) | Acc: (94.00%) (30502/32128)
Epoch: 135 | Batch_idx: 260 |  Loss: (0.1471) |  Loss2: (0.0000) | Acc: (94.00%) (31725/33408)
Epoch: 135 | Batch_idx: 270 |  Loss: (0.1469) |  Loss2: (0.0000) | Acc: (94.00%) (32945/34688)
Epoch: 135 | Batch_idx: 280 |  Loss: (0.1472) |  Loss2: (0.0000) | Acc: (94.00%) (34155/35968)
Epoch: 135 | Batch_idx: 290 |  Loss: (0.1480) |  Loss2: (0.0000) | Acc: (94.00%) (35361/37248)
Epoch: 135 | Batch_idx: 300 |  Loss: (0.1483) |  Loss2: (0.0000) | Acc: (94.00%) (36565/38528)
Epoch: 135 | Batch_idx: 310 |  Loss: (0.1485) |  Loss2: (0.0000) | Acc: (94.00%) (37779/39808)
Epoch: 135 | Batch_idx: 320 |  Loss: (0.1488) |  Loss2: (0.0000) | Acc: (94.00%) (38981/41088)
Epoch: 135 | Batch_idx: 330 |  Loss: (0.1490) |  Loss2: (0.0000) | Acc: (94.00%) (40192/42368)
Epoch: 135 | Batch_idx: 340 |  Loss: (0.1485) |  Loss2: (0.0000) | Acc: (94.00%) (41409/43648)
Epoch: 135 | Batch_idx: 350 |  Loss: (0.1484) |  Loss2: (0.0000) | Acc: (94.00%) (42627/44928)
Epoch: 135 | Batch_idx: 360 |  Loss: (0.1490) |  Loss2: (0.0000) | Acc: (94.00%) (43829/46208)
Epoch: 135 | Batch_idx: 370 |  Loss: (0.1490) |  Loss2: (0.0000) | Acc: (94.00%) (45037/47488)
Epoch: 135 | Batch_idx: 380 |  Loss: (0.1489) |  Loss2: (0.0000) | Acc: (94.00%) (46256/48768)
Epoch: 135 | Batch_idx: 390 |  Loss: (0.1495) |  Loss2: (0.0000) | Acc: (94.00%) (47419/50000)
=> saving checkpoint 'drive/app/torch/save_Schedule/checkpoint_135.pth.tar'
# TEST : Loss: (0.3842) | Acc: (88.00%) (8844/10000)
percent tensor([0.5135, 0.5133, 0.5147, 0.5170, 0.5154, 0.5219, 0.5141, 0.5155, 0.5129,
        0.5123, 0.5126, 0.5134, 0.5125, 0.5146, 0.5163, 0.5154],
       device='cuda:0') torch.Size([16])
percent tensor([0.5071, 0.5100, 0.5037, 0.5032, 0.5006, 0.5148, 0.5051, 0.4992, 0.5033,
        0.5068, 0.5057, 0.5069, 0.5142, 0.5019, 0.5093, 0.5108],
       device='cuda:0') torch.Size([16])
percent tensor([0.5741, 0.5468, 0.6250, 0.6586, 0.6396, 0.6194, 0.5884, 0.6246, 0.6200,
        0.5821, 0.6060, 0.5926, 0.5074, 0.6530, 0.5778, 0.5908],
       device='cuda:0') torch.Size([16])
percent tensor([0.6319, 0.6357, 0.6266, 0.6326, 0.6304, 0.6370, 0.6366, 0.6363, 0.6391,
        0.6371, 0.6390, 0.6411, 0.6362, 0.6356, 0.6396, 0.6417],
       device='cuda:0') torch.Size([16])
percent tensor([0.6160, 0.5841, 0.6365, 0.6606, 0.6631, 0.7360, 0.5928, 0.6039, 0.6157,
        0.6276, 0.5873, 0.6023, 0.5958, 0.6269, 0.5960, 0.6781],
       device='cuda:0') torch.Size([16])
percent tensor([0.6266, 0.6748, 0.6651, 0.6875, 0.6595, 0.7342, 0.6784, 0.5558, 0.6998,
        0.6623, 0.7279, 0.6717, 0.7093, 0.7185, 0.5785, 0.6636],
       device='cuda:0') torch.Size([16])
percent tensor([0.6510, 0.6591, 0.7080, 0.7414, 0.7371, 0.6935, 0.7035, 0.7111, 0.6247,
        0.6537, 0.6698, 0.6631, 0.6146, 0.6311, 0.6226, 0.6726],
       device='cuda:0') torch.Size([16])
percent tensor([0.9998, 0.9996, 0.9995, 0.9997, 0.9992, 0.9984, 0.9995, 0.9998, 0.9998,
        0.9997, 0.9999, 0.9997, 0.9998, 0.9994, 0.9984, 0.9994],
       device='cuda:0') torch.Size([16])
Epoch: 136 | Batch_idx: 0 |  Loss: (0.1106) |  Loss2: (0.0000) | Acc: (96.00%) (124/128)
Epoch: 136 | Batch_idx: 10 |  Loss: (0.1458) |  Loss2: (0.0000) | Acc: (94.00%) (1334/1408)
Epoch: 136 | Batch_idx: 20 |  Loss: (0.1464) |  Loss2: (0.0000) | Acc: (95.00%) (2554/2688)
Epoch: 136 | Batch_idx: 30 |  Loss: (0.1392) |  Loss2: (0.0000) | Acc: (95.00%) (3778/3968)
Epoch: 136 | Batch_idx: 40 |  Loss: (0.1376) |  Loss2: (0.0000) | Acc: (95.00%) (4999/5248)
Epoch: 136 | Batch_idx: 50 |  Loss: (0.1398) |  Loss2: (0.0000) | Acc: (95.00%) (6217/6528)
Epoch: 136 | Batch_idx: 60 |  Loss: (0.1385) |  Loss2: (0.0000) | Acc: (95.00%) (7436/7808)
Epoch: 136 | Batch_idx: 70 |  Loss: (0.1378) |  Loss2: (0.0000) | Acc: (95.00%) (8645/9088)
Epoch: 136 | Batch_idx: 80 |  Loss: (0.1419) |  Loss2: (0.0000) | Acc: (95.00%) (9855/10368)
Epoch: 136 | Batch_idx: 90 |  Loss: (0.1389) |  Loss2: (0.0000) | Acc: (95.00%) (11089/11648)
Epoch: 136 | Batch_idx: 100 |  Loss: (0.1390) |  Loss2: (0.0000) | Acc: (95.00%) (12304/12928)
Epoch: 136 | Batch_idx: 110 |  Loss: (0.1396) |  Loss2: (0.0000) | Acc: (95.00%) (13518/14208)
Epoch: 136 | Batch_idx: 120 |  Loss: (0.1389) |  Loss2: (0.0000) | Acc: (95.00%) (14740/15488)
Epoch: 136 | Batch_idx: 130 |  Loss: (0.1387) |  Loss2: (0.0000) | Acc: (95.00%) (15955/16768)
Epoch: 136 | Batch_idx: 140 |  Loss: (0.1395) |  Loss2: (0.0000) | Acc: (95.00%) (17172/18048)
Epoch: 136 | Batch_idx: 150 |  Loss: (0.1408) |  Loss2: (0.0000) | Acc: (95.00%) (18388/19328)
Epoch: 136 | Batch_idx: 160 |  Loss: (0.1408) |  Loss2: (0.0000) | Acc: (95.00%) (19603/20608)
Epoch: 136 | Batch_idx: 170 |  Loss: (0.1414) |  Loss2: (0.0000) | Acc: (95.00%) (20809/21888)
Epoch: 136 | Batch_idx: 180 |  Loss: (0.1419) |  Loss2: (0.0000) | Acc: (95.00%) (22016/23168)
Epoch: 136 | Batch_idx: 190 |  Loss: (0.1420) |  Loss2: (0.0000) | Acc: (95.00%) (23232/24448)
Epoch: 136 | Batch_idx: 200 |  Loss: (0.1433) |  Loss2: (0.0000) | Acc: (94.00%) (24435/25728)
Epoch: 136 | Batch_idx: 210 |  Loss: (0.1440) |  Loss2: (0.0000) | Acc: (94.00%) (25656/27008)
Epoch: 136 | Batch_idx: 220 |  Loss: (0.1446) |  Loss2: (0.0000) | Acc: (94.00%) (26862/28288)
Epoch: 136 | Batch_idx: 230 |  Loss: (0.1459) |  Loss2: (0.0000) | Acc: (94.00%) (28066/29568)
Epoch: 136 | Batch_idx: 240 |  Loss: (0.1464) |  Loss2: (0.0000) | Acc: (94.00%) (29269/30848)
Epoch: 136 | Batch_idx: 250 |  Loss: (0.1466) |  Loss2: (0.0000) | Acc: (94.00%) (30475/32128)
Epoch: 136 | Batch_idx: 260 |  Loss: (0.1473) |  Loss2: (0.0000) | Acc: (94.00%) (31674/33408)
Epoch: 136 | Batch_idx: 270 |  Loss: (0.1469) |  Loss2: (0.0000) | Acc: (94.00%) (32892/34688)
Epoch: 136 | Batch_idx: 280 |  Loss: (0.1471) |  Loss2: (0.0000) | Acc: (94.00%) (34101/35968)
Epoch: 136 | Batch_idx: 290 |  Loss: (0.1469) |  Loss2: (0.0000) | Acc: (94.00%) (35319/37248)
Epoch: 136 | Batch_idx: 300 |  Loss: (0.1466) |  Loss2: (0.0000) | Acc: (94.00%) (36539/38528)
Epoch: 136 | Batch_idx: 310 |  Loss: (0.1470) |  Loss2: (0.0000) | Acc: (94.00%) (37756/39808)
Epoch: 136 | Batch_idx: 320 |  Loss: (0.1471) |  Loss2: (0.0000) | Acc: (94.00%) (38974/41088)
Epoch: 136 | Batch_idx: 330 |  Loss: (0.1475) |  Loss2: (0.0000) | Acc: (94.00%) (40184/42368)
Epoch: 136 | Batch_idx: 340 |  Loss: (0.1480) |  Loss2: (0.0000) | Acc: (94.00%) (41397/43648)
Epoch: 136 | Batch_idx: 350 |  Loss: (0.1479) |  Loss2: (0.0000) | Acc: (94.00%) (42617/44928)
Epoch: 136 | Batch_idx: 360 |  Loss: (0.1479) |  Loss2: (0.0000) | Acc: (94.00%) (43833/46208)
Epoch: 136 | Batch_idx: 370 |  Loss: (0.1482) |  Loss2: (0.0000) | Acc: (94.00%) (45044/47488)
Epoch: 136 | Batch_idx: 380 |  Loss: (0.1482) |  Loss2: (0.0000) | Acc: (94.00%) (46256/48768)
Epoch: 136 | Batch_idx: 390 |  Loss: (0.1480) |  Loss2: (0.0000) | Acc: (94.00%) (47435/50000)
# TEST : Loss: (0.3975) | Acc: (87.00%) (8773/10000)
percent tensor([0.5134, 0.5137, 0.5136, 0.5169, 0.5150, 0.5216, 0.5143, 0.5156, 0.5132,
        0.5123, 0.5132, 0.5126, 0.5128, 0.5157, 0.5161, 0.5157],
       device='cuda:0') torch.Size([16])
percent tensor([0.5071, 0.5098, 0.5025, 0.5024, 0.5001, 0.5160, 0.5036, 0.4989, 0.5029,
        0.5061, 0.5057, 0.5052, 0.5134, 0.5012, 0.5099, 0.5104],
       device='cuda:0') torch.Size([16])
percent tensor([0.5754, 0.5433, 0.6444, 0.6606, 0.6519, 0.5998, 0.5912, 0.6345, 0.6285,
        0.5899, 0.6011, 0.6114, 0.5097, 0.6523, 0.5666, 0.5856],
       device='cuda:0') torch.Size([16])
percent tensor([0.6363, 0.6343, 0.6282, 0.6340, 0.6304, 0.6403, 0.6360, 0.6363, 0.6426,
        0.6392, 0.6388, 0.6444, 0.6373, 0.6372, 0.6386, 0.6429],
       device='cuda:0') torch.Size([16])
percent tensor([0.6117, 0.5843, 0.6171, 0.6541, 0.6505, 0.7268, 0.5837, 0.6004, 0.6125,
        0.6194, 0.5715, 0.5894, 0.5927, 0.6341, 0.5869, 0.6672],
       device='cuda:0') torch.Size([16])
percent tensor([0.6221, 0.6713, 0.6700, 0.6956, 0.6697, 0.7380, 0.6739, 0.5633, 0.6884,
        0.6369, 0.7095, 0.6557, 0.7014, 0.7023, 0.5812, 0.6632],
       device='cuda:0') torch.Size([16])
percent tensor([0.6361, 0.6628, 0.6894, 0.7323, 0.7224, 0.6838, 0.7051, 0.7056, 0.6256,
        0.6525, 0.6746, 0.6464, 0.6208, 0.6318, 0.6265, 0.6734],
       device='cuda:0') torch.Size([16])
percent tensor([0.9999, 0.9995, 0.9995, 0.9997, 0.9994, 0.9987, 0.9996, 0.9997, 0.9998,
        0.9996, 0.9997, 0.9996, 0.9998, 0.9995, 0.9988, 0.9996],
       device='cuda:0') torch.Size([16])
Epoch: 137 | Batch_idx: 0 |  Loss: (0.0969) |  Loss2: (0.0000) | Acc: (96.00%) (123/128)
Epoch: 137 | Batch_idx: 10 |  Loss: (0.1245) |  Loss2: (0.0000) | Acc: (96.00%) (1353/1408)
Epoch: 137 | Batch_idx: 20 |  Loss: (0.1321) |  Loss2: (0.0000) | Acc: (95.00%) (2568/2688)
Epoch: 137 | Batch_idx: 30 |  Loss: (0.1340) |  Loss2: (0.0000) | Acc: (95.00%) (3792/3968)
Epoch: 137 | Batch_idx: 40 |  Loss: (0.1339) |  Loss2: (0.0000) | Acc: (95.00%) (5015/5248)
Epoch: 137 | Batch_idx: 50 |  Loss: (0.1332) |  Loss2: (0.0000) | Acc: (95.00%) (6238/6528)
Epoch: 137 | Batch_idx: 60 |  Loss: (0.1305) |  Loss2: (0.0000) | Acc: (95.00%) (7468/7808)
Epoch: 137 | Batch_idx: 70 |  Loss: (0.1323) |  Loss2: (0.0000) | Acc: (95.00%) (8691/9088)
Epoch: 137 | Batch_idx: 80 |  Loss: (0.1343) |  Loss2: (0.0000) | Acc: (95.00%) (9911/10368)
Epoch: 137 | Batch_idx: 90 |  Loss: (0.1323) |  Loss2: (0.0000) | Acc: (95.00%) (11143/11648)
Epoch: 137 | Batch_idx: 100 |  Loss: (0.1325) |  Loss2: (0.0000) | Acc: (95.00%) (12374/12928)
Epoch: 137 | Batch_idx: 110 |  Loss: (0.1328) |  Loss2: (0.0000) | Acc: (95.00%) (13599/14208)
Epoch: 137 | Batch_idx: 120 |  Loss: (0.1348) |  Loss2: (0.0000) | Acc: (95.00%) (14800/15488)
Epoch: 137 | Batch_idx: 130 |  Loss: (0.1358) |  Loss2: (0.0000) | Acc: (95.00%) (16014/16768)
Epoch: 137 | Batch_idx: 140 |  Loss: (0.1348) |  Loss2: (0.0000) | Acc: (95.00%) (17238/18048)
Epoch: 137 | Batch_idx: 150 |  Loss: (0.1343) |  Loss2: (0.0000) | Acc: (95.00%) (18463/19328)
Epoch: 137 | Batch_idx: 160 |  Loss: (0.1339) |  Loss2: (0.0000) | Acc: (95.00%) (19686/20608)
Epoch: 137 | Batch_idx: 170 |  Loss: (0.1347) |  Loss2: (0.0000) | Acc: (95.00%) (20903/21888)
Epoch: 137 | Batch_idx: 180 |  Loss: (0.1360) |  Loss2: (0.0000) | Acc: (95.00%) (22118/23168)
Epoch: 137 | Batch_idx: 190 |  Loss: (0.1370) |  Loss2: (0.0000) | Acc: (95.00%) (23328/24448)
Epoch: 137 | Batch_idx: 200 |  Loss: (0.1365) |  Loss2: (0.0000) | Acc: (95.00%) (24549/25728)
Epoch: 137 | Batch_idx: 210 |  Loss: (0.1360) |  Loss2: (0.0000) | Acc: (95.00%) (25775/27008)
Epoch: 137 | Batch_idx: 220 |  Loss: (0.1362) |  Loss2: (0.0000) | Acc: (95.00%) (26989/28288)
Epoch: 137 | Batch_idx: 230 |  Loss: (0.1361) |  Loss2: (0.0000) | Acc: (95.00%) (28214/29568)
Epoch: 137 | Batch_idx: 240 |  Loss: (0.1369) |  Loss2: (0.0000) | Acc: (95.00%) (29430/30848)
Epoch: 137 | Batch_idx: 250 |  Loss: (0.1368) |  Loss2: (0.0000) | Acc: (95.00%) (30649/32128)
Epoch: 137 | Batch_idx: 260 |  Loss: (0.1374) |  Loss2: (0.0000) | Acc: (95.00%) (31862/33408)
Epoch: 137 | Batch_idx: 270 |  Loss: (0.1371) |  Loss2: (0.0000) | Acc: (95.00%) (33088/34688)
Epoch: 137 | Batch_idx: 280 |  Loss: (0.1377) |  Loss2: (0.0000) | Acc: (95.00%) (34296/35968)
Epoch: 137 | Batch_idx: 290 |  Loss: (0.1372) |  Loss2: (0.0000) | Acc: (95.00%) (35521/37248)
Epoch: 137 | Batch_idx: 300 |  Loss: (0.1374) |  Loss2: (0.0000) | Acc: (95.00%) (36734/38528)
Epoch: 137 | Batch_idx: 310 |  Loss: (0.1377) |  Loss2: (0.0000) | Acc: (95.00%) (37955/39808)
Epoch: 137 | Batch_idx: 320 |  Loss: (0.1385) |  Loss2: (0.0000) | Acc: (95.00%) (39166/41088)
Epoch: 137 | Batch_idx: 330 |  Loss: (0.1383) |  Loss2: (0.0000) | Acc: (95.00%) (40390/42368)
Epoch: 137 | Batch_idx: 340 |  Loss: (0.1385) |  Loss2: (0.0000) | Acc: (95.00%) (41614/43648)
Epoch: 137 | Batch_idx: 350 |  Loss: (0.1389) |  Loss2: (0.0000) | Acc: (95.00%) (42817/44928)
Epoch: 137 | Batch_idx: 360 |  Loss: (0.1393) |  Loss2: (0.0000) | Acc: (95.00%) (44025/46208)
Epoch: 137 | Batch_idx: 370 |  Loss: (0.1392) |  Loss2: (0.0000) | Acc: (95.00%) (45242/47488)
Epoch: 137 | Batch_idx: 380 |  Loss: (0.1394) |  Loss2: (0.0000) | Acc: (95.00%) (46455/48768)
Epoch: 137 | Batch_idx: 390 |  Loss: (0.1400) |  Loss2: (0.0000) | Acc: (95.00%) (47620/50000)
# TEST : Loss: (0.4035) | Acc: (87.00%) (8747/10000)
percent tensor([0.5128, 0.5131, 0.5128, 0.5164, 0.5142, 0.5208, 0.5137, 0.5153, 0.5127,
        0.5119, 0.5128, 0.5121, 0.5121, 0.5151, 0.5156, 0.5150],
       device='cuda:0') torch.Size([16])
percent tensor([0.5066, 0.5095, 0.5038, 0.5019, 0.5008, 0.5131, 0.5043, 0.4993, 0.5031,
        0.5065, 0.5048, 0.5072, 0.5136, 0.5010, 0.5087, 0.5094],
       device='cuda:0') torch.Size([16])
percent tensor([0.5909, 0.5603, 0.6443, 0.6687, 0.6541, 0.6424, 0.5987, 0.6333, 0.6350,
        0.5930, 0.6140, 0.6176, 0.5176, 0.6511, 0.5969, 0.6068],
       device='cuda:0') torch.Size([16])
percent tensor([0.6350, 0.6367, 0.6266, 0.6337, 0.6297, 0.6373, 0.6369, 0.6340, 0.6402,
        0.6386, 0.6402, 0.6439, 0.6368, 0.6374, 0.6420, 0.6422],
       device='cuda:0') torch.Size([16])
percent tensor([0.6123, 0.5940, 0.6228, 0.6560, 0.6637, 0.7227, 0.5892, 0.5946, 0.6157,
        0.6380, 0.5905, 0.5988, 0.6061, 0.6290, 0.5993, 0.6791],
       device='cuda:0') torch.Size([16])
percent tensor([0.6136, 0.6646, 0.6765, 0.7026, 0.6827, 0.7288, 0.6782, 0.5598, 0.6883,
        0.6530, 0.7152, 0.6692, 0.7064, 0.6986, 0.5630, 0.6566],
       device='cuda:0') torch.Size([16])
percent tensor([0.6397, 0.6516, 0.6784, 0.7290, 0.7277, 0.6826, 0.6987, 0.6903, 0.6134,
        0.6686, 0.6777, 0.6650, 0.6419, 0.6240, 0.6220, 0.6805],
       device='cuda:0') torch.Size([16])
percent tensor([0.9998, 0.9995, 0.9994, 0.9995, 0.9991, 0.9985, 0.9994, 0.9994, 0.9998,
        0.9997, 0.9998, 0.9997, 0.9999, 0.9996, 0.9987, 0.9995],
       device='cuda:0') torch.Size([16])
False Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=128, out_features=16, bias=False)
True Linear(in_features=16, out_features=2, bias=False)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=128, out_features=16, bias=False)
True Linear(in_features=16, out_features=2, bias=False)
False Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=256, out_features=32, bias=False)
True Linear(in_features=32, out_features=2, bias=False)
False Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=256, out_features=32, bias=False)
True Linear(in_features=32, out_features=2, bias=False)
False Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=512, out_features=64, bias=False)
True Linear(in_features=64, out_features=2, bias=False)
False Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=512, out_features=64, bias=False)
True Linear(in_features=64, out_features=2, bias=False)
False Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1024, out_features=128, bias=False)
True Linear(in_features=128, out_features=2, bias=False)
False Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1024, out_features=128, bias=False)
True Linear(in_features=128, out_features=2, bias=False)
False Linear(in_features=512, out_features=10, bias=True)
Epoch: 138 | Batch_idx: 0 |  Loss: (0.1741) |  Loss2: (0.0000) | Acc: (93.00%) (120/128)
Epoch: 138 | Batch_idx: 10 |  Loss: (0.1495) |  Loss2: (0.0000) | Acc: (94.00%) (1330/1408)
Epoch: 138 | Batch_idx: 20 |  Loss: (0.1629) |  Loss2: (0.0000) | Acc: (93.00%) (2518/2688)
Epoch: 138 | Batch_idx: 30 |  Loss: (0.1817) |  Loss2: (0.0000) | Acc: (93.00%) (3701/3968)
Epoch: 138 | Batch_idx: 40 |  Loss: (0.2004) |  Loss2: (0.0000) | Acc: (92.00%) (4855/5248)
Epoch: 138 | Batch_idx: 50 |  Loss: (0.2077) |  Loss2: (0.0000) | Acc: (92.00%) (6026/6528)
Epoch: 138 | Batch_idx: 60 |  Loss: (0.2063) |  Loss2: (0.0000) | Acc: (92.00%) (7214/7808)
Epoch: 138 | Batch_idx: 70 |  Loss: (0.2076) |  Loss2: (0.0000) | Acc: (92.00%) (8390/9088)
Epoch: 138 | Batch_idx: 80 |  Loss: (0.2064) |  Loss2: (0.0000) | Acc: (92.00%) (9584/10368)
Epoch: 138 | Batch_idx: 90 |  Loss: (0.2052) |  Loss2: (0.0000) | Acc: (92.00%) (10775/11648)
Epoch: 138 | Batch_idx: 100 |  Loss: (0.2048) |  Loss2: (0.0000) | Acc: (92.00%) (11950/12928)
Epoch: 138 | Batch_idx: 110 |  Loss: (0.2022) |  Loss2: (0.0000) | Acc: (92.00%) (13151/14208)
Epoch: 138 | Batch_idx: 120 |  Loss: (0.2031) |  Loss2: (0.0000) | Acc: (92.00%) (14334/15488)
Epoch: 138 | Batch_idx: 130 |  Loss: (0.2010) |  Loss2: (0.0000) | Acc: (92.00%) (15535/16768)
Epoch: 138 | Batch_idx: 140 |  Loss: (0.1995) |  Loss2: (0.0000) | Acc: (92.00%) (16744/18048)
Epoch: 138 | Batch_idx: 150 |  Loss: (0.1994) |  Loss2: (0.0000) | Acc: (92.00%) (17934/19328)
Epoch: 138 | Batch_idx: 160 |  Loss: (0.2007) |  Loss2: (0.0000) | Acc: (92.00%) (19111/20608)
Epoch: 138 | Batch_idx: 170 |  Loss: (0.1995) |  Loss2: (0.0000) | Acc: (92.00%) (20312/21888)
Epoch: 138 | Batch_idx: 180 |  Loss: (0.2002) |  Loss2: (0.0000) | Acc: (92.00%) (21503/23168)
Epoch: 138 | Batch_idx: 190 |  Loss: (0.1999) |  Loss2: (0.0000) | Acc: (92.00%) (22696/24448)
Epoch: 138 | Batch_idx: 200 |  Loss: (0.2010) |  Loss2: (0.0000) | Acc: (92.00%) (23884/25728)
Epoch: 138 | Batch_idx: 210 |  Loss: (0.1996) |  Loss2: (0.0000) | Acc: (92.00%) (25078/27008)
Epoch: 138 | Batch_idx: 220 |  Loss: (0.1990) |  Loss2: (0.0000) | Acc: (92.00%) (26270/28288)
Epoch: 138 | Batch_idx: 230 |  Loss: (0.1979) |  Loss2: (0.0000) | Acc: (92.00%) (27473/29568)
Epoch: 138 | Batch_idx: 240 |  Loss: (0.1982) |  Loss2: (0.0000) | Acc: (92.00%) (28659/30848)
Epoch: 138 | Batch_idx: 250 |  Loss: (0.1974) |  Loss2: (0.0000) | Acc: (92.00%) (29857/32128)
Epoch: 138 | Batch_idx: 260 |  Loss: (0.1969) |  Loss2: (0.0000) | Acc: (92.00%) (31051/33408)
Epoch: 138 | Batch_idx: 270 |  Loss: (0.1956) |  Loss2: (0.0000) | Acc: (92.00%) (32255/34688)
Epoch: 138 | Batch_idx: 280 |  Loss: (0.1943) |  Loss2: (0.0000) | Acc: (93.00%) (33464/35968)
Epoch: 138 | Batch_idx: 290 |  Loss: (0.1945) |  Loss2: (0.0000) | Acc: (93.00%) (34657/37248)
Epoch: 138 | Batch_idx: 300 |  Loss: (0.1940) |  Loss2: (0.0000) | Acc: (93.00%) (35863/38528)
Epoch: 138 | Batch_idx: 310 |  Loss: (0.1944) |  Loss2: (0.0000) | Acc: (93.00%) (37051/39808)
Epoch: 138 | Batch_idx: 320 |  Loss: (0.1931) |  Loss2: (0.0000) | Acc: (93.00%) (38270/41088)
Epoch: 138 | Batch_idx: 330 |  Loss: (0.1935) |  Loss2: (0.0000) | Acc: (93.00%) (39452/42368)
Epoch: 138 | Batch_idx: 340 |  Loss: (0.1928) |  Loss2: (0.0000) | Acc: (93.00%) (40658/43648)
Epoch: 138 | Batch_idx: 350 |  Loss: (0.1921) |  Loss2: (0.0000) | Acc: (93.00%) (41858/44928)
Epoch: 138 | Batch_idx: 360 |  Loss: (0.1913) |  Loss2: (0.0000) | Acc: (93.00%) (43066/46208)
Epoch: 138 | Batch_idx: 370 |  Loss: (0.1913) |  Loss2: (0.0000) | Acc: (93.00%) (44255/47488)
Epoch: 138 | Batch_idx: 380 |  Loss: (0.1905) |  Loss2: (0.0000) | Acc: (93.00%) (45466/48768)
Epoch: 138 | Batch_idx: 390 |  Loss: (0.1899) |  Loss2: (0.0000) | Acc: (93.00%) (46624/50000)
# TEST : Loss: (0.4075) | Acc: (87.00%) (8744/10000)
percent tensor([0.5110, 0.5107, 0.5119, 0.5145, 0.5127, 0.5188, 0.5116, 0.5139, 0.5109,
        0.5101, 0.5108, 0.5107, 0.5103, 0.5125, 0.5135, 0.5130],
       device='cuda:0') torch.Size([16])
percent tensor([0.5029, 0.5044, 0.5007, 0.4994, 0.4974, 0.5101, 0.4998, 0.4944, 0.4991,
        0.5014, 0.5001, 0.5023, 0.5086, 0.4977, 0.5046, 0.5052],
       device='cuda:0') torch.Size([16])
percent tensor([0.5649, 0.5262, 0.6352, 0.6608, 0.6462, 0.6156, 0.5738, 0.6240, 0.6176,
        0.5629, 0.5909, 0.5893, 0.4745, 0.6374, 0.5645, 0.5816],
       device='cuda:0') torch.Size([16])
percent tensor([0.6276, 0.6272, 0.6168, 0.6241, 0.6208, 0.6269, 0.6285, 0.6254, 0.6302,
        0.6300, 0.6310, 0.6312, 0.6262, 0.6279, 0.6320, 0.6353],
       device='cuda:0') torch.Size([16])
percent tensor([0.6368, 0.6178, 0.6374, 0.6734, 0.6724, 0.7524, 0.6103, 0.6165, 0.6337,
        0.6558, 0.6142, 0.6158, 0.6274, 0.6540, 0.6242, 0.7033],
       device='cuda:0') torch.Size([16])
percent tensor([0.6366, 0.6953, 0.7076, 0.7325, 0.7004, 0.7566, 0.7041, 0.5815, 0.7156,
        0.6784, 0.7397, 0.7009, 0.7411, 0.7100, 0.5893, 0.6883],
       device='cuda:0') torch.Size([16])
percent tensor([0.5715, 0.5997, 0.6365, 0.6719, 0.6652, 0.6382, 0.6277, 0.6217, 0.5673,
        0.6140, 0.6283, 0.6121, 0.6031, 0.5632, 0.5630, 0.6085],
       device='cuda:0') torch.Size([16])
percent tensor([0.9999, 0.9995, 0.9996, 0.9998, 0.9992, 0.9983, 0.9994, 0.9996, 0.9999,
        0.9998, 0.9999, 0.9997, 0.9999, 0.9995, 0.9988, 0.9994],
       device='cuda:0') torch.Size([16])
Epoch: 139 | Batch_idx: 0 |  Loss: (0.2063) |  Loss2: (0.0000) | Acc: (92.00%) (118/128)
Epoch: 139 | Batch_idx: 10 |  Loss: (0.1756) |  Loss2: (0.0000) | Acc: (93.00%) (1322/1408)
Epoch: 139 | Batch_idx: 20 |  Loss: (0.1719) |  Loss2: (0.0000) | Acc: (94.00%) (2530/2688)
Epoch: 139 | Batch_idx: 30 |  Loss: (0.1675) |  Loss2: (0.0000) | Acc: (94.00%) (3739/3968)
Epoch: 139 | Batch_idx: 40 |  Loss: (0.1632) |  Loss2: (0.0000) | Acc: (94.00%) (4951/5248)
Epoch: 139 | Batch_idx: 50 |  Loss: (0.1687) |  Loss2: (0.0000) | Acc: (94.00%) (6141/6528)
Epoch: 139 | Batch_idx: 60 |  Loss: (0.1705) |  Loss2: (0.0000) | Acc: (94.00%) (7340/7808)
Epoch: 139 | Batch_idx: 70 |  Loss: (0.1697) |  Loss2: (0.0000) | Acc: (94.00%) (8548/9088)
Epoch: 139 | Batch_idx: 80 |  Loss: (0.1696) |  Loss2: (0.0000) | Acc: (94.00%) (9750/10368)
Epoch: 139 | Batch_idx: 90 |  Loss: (0.1689) |  Loss2: (0.0000) | Acc: (94.00%) (10956/11648)
Epoch: 139 | Batch_idx: 100 |  Loss: (0.1700) |  Loss2: (0.0000) | Acc: (94.00%) (12157/12928)
Epoch: 139 | Batch_idx: 110 |  Loss: (0.1691) |  Loss2: (0.0000) | Acc: (94.00%) (13370/14208)
Epoch: 139 | Batch_idx: 120 |  Loss: (0.1691) |  Loss2: (0.0000) | Acc: (94.00%) (14576/15488)
Epoch: 139 | Batch_idx: 130 |  Loss: (0.1694) |  Loss2: (0.0000) | Acc: (94.00%) (15784/16768)
Epoch: 139 | Batch_idx: 140 |  Loss: (0.1691) |  Loss2: (0.0000) | Acc: (94.00%) (16995/18048)
Epoch: 139 | Batch_idx: 150 |  Loss: (0.1695) |  Loss2: (0.0000) | Acc: (94.00%) (18202/19328)
Epoch: 139 | Batch_idx: 160 |  Loss: (0.1696) |  Loss2: (0.0000) | Acc: (94.00%) (19406/20608)
Epoch: 139 | Batch_idx: 170 |  Loss: (0.1705) |  Loss2: (0.0000) | Acc: (94.00%) (20607/21888)
Epoch: 139 | Batch_idx: 180 |  Loss: (0.1693) |  Loss2: (0.0000) | Acc: (94.00%) (21824/23168)
Epoch: 139 | Batch_idx: 190 |  Loss: (0.1694) |  Loss2: (0.0000) | Acc: (94.00%) (23030/24448)
Epoch: 139 | Batch_idx: 200 |  Loss: (0.1693) |  Loss2: (0.0000) | Acc: (94.00%) (24233/25728)
Epoch: 139 | Batch_idx: 210 |  Loss: (0.1692) |  Loss2: (0.0000) | Acc: (94.00%) (25439/27008)
Epoch: 139 | Batch_idx: 220 |  Loss: (0.1679) |  Loss2: (0.0000) | Acc: (94.00%) (26663/28288)
Epoch: 139 | Batch_idx: 230 |  Loss: (0.1673) |  Loss2: (0.0000) | Acc: (94.00%) (27877/29568)
Epoch: 139 | Batch_idx: 240 |  Loss: (0.1671) |  Loss2: (0.0000) | Acc: (94.00%) (29078/30848)
Epoch: 139 | Batch_idx: 250 |  Loss: (0.1680) |  Loss2: (0.0000) | Acc: (94.00%) (30271/32128)
Epoch: 139 | Batch_idx: 260 |  Loss: (0.1682) |  Loss2: (0.0000) | Acc: (94.00%) (31471/33408)
Epoch: 139 | Batch_idx: 270 |  Loss: (0.1679) |  Loss2: (0.0000) | Acc: (94.00%) (32682/34688)
Epoch: 139 | Batch_idx: 280 |  Loss: (0.1671) |  Loss2: (0.0000) | Acc: (94.00%) (33895/35968)
Epoch: 139 | Batch_idx: 290 |  Loss: (0.1674) |  Loss2: (0.0000) | Acc: (94.00%) (35095/37248)
Epoch: 139 | Batch_idx: 300 |  Loss: (0.1667) |  Loss2: (0.0000) | Acc: (94.00%) (36316/38528)
Epoch: 139 | Batch_idx: 310 |  Loss: (0.1666) |  Loss2: (0.0000) | Acc: (94.00%) (37524/39808)
Epoch: 139 | Batch_idx: 320 |  Loss: (0.1657) |  Loss2: (0.0000) | Acc: (94.00%) (38747/41088)
Epoch: 139 | Batch_idx: 330 |  Loss: (0.1661) |  Loss2: (0.0000) | Acc: (94.00%) (39953/42368)
Epoch: 139 | Batch_idx: 340 |  Loss: (0.1650) |  Loss2: (0.0000) | Acc: (94.00%) (41182/43648)
Epoch: 139 | Batch_idx: 350 |  Loss: (0.1648) |  Loss2: (0.0000) | Acc: (94.00%) (42395/44928)
Epoch: 139 | Batch_idx: 360 |  Loss: (0.1644) |  Loss2: (0.0000) | Acc: (94.00%) (43602/46208)
Epoch: 139 | Batch_idx: 370 |  Loss: (0.1649) |  Loss2: (0.0000) | Acc: (94.00%) (44804/47488)
Epoch: 139 | Batch_idx: 380 |  Loss: (0.1648) |  Loss2: (0.0000) | Acc: (94.00%) (46004/48768)
Epoch: 139 | Batch_idx: 390 |  Loss: (0.1648) |  Loss2: (0.0000) | Acc: (94.00%) (47160/50000)
# TEST : Loss: (0.3913) | Acc: (87.00%) (8791/10000)
percent tensor([0.5107, 0.5106, 0.5118, 0.5144, 0.5126, 0.5188, 0.5115, 0.5140, 0.5108,
        0.5100, 0.5106, 0.5105, 0.5100, 0.5126, 0.5135, 0.5129],
       device='cuda:0') torch.Size([16])
percent tensor([0.5048, 0.5072, 0.5024, 0.5017, 0.4995, 0.5123, 0.5025, 0.4967, 0.5014,
        0.5038, 0.5028, 0.5042, 0.5106, 0.5003, 0.5073, 0.5072],
       device='cuda:0') torch.Size([16])
percent tensor([0.5746, 0.5268, 0.6407, 0.6649, 0.6504, 0.6171, 0.5787, 0.6312, 0.6276,
        0.5699, 0.6002, 0.5932, 0.4775, 0.6461, 0.5657, 0.5892],
       device='cuda:0') torch.Size([16])
percent tensor([0.6275, 0.6254, 0.6148, 0.6217, 0.6199, 0.6248, 0.6278, 0.6249, 0.6282,
        0.6289, 0.6296, 0.6277, 0.6243, 0.6252, 0.6302, 0.6354],
       device='cuda:0') torch.Size([16])
percent tensor([0.6279, 0.6098, 0.6218, 0.6561, 0.6614, 0.7459, 0.6031, 0.6081, 0.6219,
        0.6429, 0.6058, 0.5980, 0.6158, 0.6438, 0.6144, 0.6926],
       device='cuda:0') torch.Size([16])
percent tensor([0.6177, 0.6840, 0.7021, 0.7283, 0.6891, 0.7506, 0.6906, 0.5647, 0.7087,
        0.6652, 0.7284, 0.6965, 0.7347, 0.7043, 0.5711, 0.6698],
       device='cuda:0') torch.Size([16])
percent tensor([0.5763, 0.6091, 0.6521, 0.6807, 0.6714, 0.6449, 0.6334, 0.6249, 0.5837,
        0.6290, 0.6423, 0.6259, 0.6191, 0.5824, 0.5702, 0.6037],
       device='cuda:0') torch.Size([16])
percent tensor([0.9999, 0.9995, 0.9996, 0.9998, 0.9991, 0.9984, 0.9994, 0.9996, 0.9999,
        0.9998, 0.9999, 0.9997, 0.9999, 0.9995, 0.9987, 0.9995],
       device='cuda:0') torch.Size([16])
Epoch: 140 | Batch_idx: 0 |  Loss: (0.0993) |  Loss2: (0.0000) | Acc: (96.00%) (123/128)
Epoch: 140 | Batch_idx: 10 |  Loss: (0.1444) |  Loss2: (0.0000) | Acc: (95.00%) (1339/1408)
Epoch: 140 | Batch_idx: 20 |  Loss: (0.1532) |  Loss2: (0.0000) | Acc: (94.00%) (2542/2688)
Epoch: 140 | Batch_idx: 30 |  Loss: (0.1501) |  Loss2: (0.0000) | Acc: (94.00%) (3754/3968)
Epoch: 140 | Batch_idx: 40 |  Loss: (0.1549) |  Loss2: (0.0000) | Acc: (94.00%) (4953/5248)
Epoch: 140 | Batch_idx: 50 |  Loss: (0.1629) |  Loss2: (0.0000) | Acc: (94.00%) (6148/6528)
Epoch: 140 | Batch_idx: 60 |  Loss: (0.1599) |  Loss2: (0.0000) | Acc: (94.00%) (7367/7808)
Epoch: 140 | Batch_idx: 70 |  Loss: (0.1573) |  Loss2: (0.0000) | Acc: (94.00%) (8585/9088)
Epoch: 140 | Batch_idx: 80 |  Loss: (0.1556) |  Loss2: (0.0000) | Acc: (94.00%) (9795/10368)
Epoch: 140 | Batch_idx: 90 |  Loss: (0.1582) |  Loss2: (0.0000) | Acc: (94.00%) (11001/11648)
Epoch: 140 | Batch_idx: 100 |  Loss: (0.1577) |  Loss2: (0.0000) | Acc: (94.00%) (12220/12928)
Epoch: 140 | Batch_idx: 110 |  Loss: (0.1569) |  Loss2: (0.0000) | Acc: (94.00%) (13430/14208)
Epoch: 140 | Batch_idx: 120 |  Loss: (0.1566) |  Loss2: (0.0000) | Acc: (94.00%) (14637/15488)
Epoch: 140 | Batch_idx: 130 |  Loss: (0.1546) |  Loss2: (0.0000) | Acc: (94.00%) (15868/16768)
Epoch: 140 | Batch_idx: 140 |  Loss: (0.1554) |  Loss2: (0.0000) | Acc: (94.00%) (17077/18048)
Epoch: 140 | Batch_idx: 150 |  Loss: (0.1549) |  Loss2: (0.0000) | Acc: (94.00%) (18290/19328)
Epoch: 140 | Batch_idx: 160 |  Loss: (0.1537) |  Loss2: (0.0000) | Acc: (94.00%) (19509/20608)
Epoch: 140 | Batch_idx: 170 |  Loss: (0.1533) |  Loss2: (0.0000) | Acc: (94.00%) (20724/21888)
Epoch: 140 | Batch_idx: 180 |  Loss: (0.1552) |  Loss2: (0.0000) | Acc: (94.00%) (21929/23168)
Epoch: 140 | Batch_idx: 190 |  Loss: (0.1542) |  Loss2: (0.0000) | Acc: (94.00%) (23147/24448)
Epoch: 140 | Batch_idx: 200 |  Loss: (0.1542) |  Loss2: (0.0000) | Acc: (94.00%) (24360/25728)
Epoch: 140 | Batch_idx: 210 |  Loss: (0.1531) |  Loss2: (0.0000) | Acc: (94.00%) (25583/27008)
Epoch: 140 | Batch_idx: 220 |  Loss: (0.1532) |  Loss2: (0.0000) | Acc: (94.00%) (26787/28288)
Epoch: 140 | Batch_idx: 230 |  Loss: (0.1540) |  Loss2: (0.0000) | Acc: (94.00%) (27995/29568)
Epoch: 140 | Batch_idx: 240 |  Loss: (0.1530) |  Loss2: (0.0000) | Acc: (94.00%) (29220/30848)
Epoch: 140 | Batch_idx: 250 |  Loss: (0.1540) |  Loss2: (0.0000) | Acc: (94.00%) (30419/32128)
Epoch: 140 | Batch_idx: 260 |  Loss: (0.1539) |  Loss2: (0.0000) | Acc: (94.00%) (31638/33408)
Epoch: 140 | Batch_idx: 270 |  Loss: (0.1531) |  Loss2: (0.0000) | Acc: (94.00%) (32861/34688)
Epoch: 140 | Batch_idx: 280 |  Loss: (0.1527) |  Loss2: (0.0000) | Acc: (94.00%) (34075/35968)
Epoch: 140 | Batch_idx: 290 |  Loss: (0.1525) |  Loss2: (0.0000) | Acc: (94.00%) (35294/37248)
Epoch: 140 | Batch_idx: 300 |  Loss: (0.1522) |  Loss2: (0.0000) | Acc: (94.00%) (36510/38528)
Epoch: 140 | Batch_idx: 310 |  Loss: (0.1524) |  Loss2: (0.0000) | Acc: (94.00%) (37723/39808)
Epoch: 140 | Batch_idx: 320 |  Loss: (0.1522) |  Loss2: (0.0000) | Acc: (94.00%) (38938/41088)
Epoch: 140 | Batch_idx: 330 |  Loss: (0.1521) |  Loss2: (0.0000) | Acc: (94.00%) (40153/42368)
Epoch: 140 | Batch_idx: 340 |  Loss: (0.1521) |  Loss2: (0.0000) | Acc: (94.00%) (41367/43648)
Epoch: 140 | Batch_idx: 350 |  Loss: (0.1526) |  Loss2: (0.0000) | Acc: (94.00%) (42575/44928)
Epoch: 140 | Batch_idx: 360 |  Loss: (0.1531) |  Loss2: (0.0000) | Acc: (94.00%) (43785/46208)
Epoch: 140 | Batch_idx: 370 |  Loss: (0.1527) |  Loss2: (0.0000) | Acc: (94.00%) (45001/47488)
Epoch: 140 | Batch_idx: 380 |  Loss: (0.1525) |  Loss2: (0.0000) | Acc: (94.00%) (46210/48768)
Epoch: 140 | Batch_idx: 390 |  Loss: (0.1526) |  Loss2: (0.0000) | Acc: (94.00%) (47379/50000)
=> saving checkpoint 'drive/app/torch/save_Schedule/checkpoint_140.pth.tar'
# TEST : Loss: (0.3825) | Acc: (88.00%) (8804/10000)
percent tensor([0.5111, 0.5111, 0.5122, 0.5148, 0.5130, 0.5194, 0.5120, 0.5145, 0.5112,
        0.5105, 0.5110, 0.5109, 0.5104, 0.5131, 0.5140, 0.5132],
       device='cuda:0') torch.Size([16])
percent tensor([0.5045, 0.5070, 0.5019, 0.5016, 0.4990, 0.5125, 0.5023, 0.4962, 0.5011,
        0.5034, 0.5028, 0.5036, 0.5102, 0.5001, 0.5073, 0.5070],
       device='cuda:0') torch.Size([16])
percent tensor([0.5750, 0.5277, 0.6404, 0.6628, 0.6511, 0.6088, 0.5824, 0.6339, 0.6306,
        0.5713, 0.6028, 0.5909, 0.4774, 0.6488, 0.5645, 0.5870],
       device='cuda:0') torch.Size([16])
percent tensor([0.6270, 0.6238, 0.6139, 0.6201, 0.6194, 0.6228, 0.6271, 0.6243, 0.6265,
        0.6281, 0.6282, 0.6254, 0.6229, 0.6228, 0.6286, 0.6350],
       device='cuda:0') torch.Size([16])
percent tensor([0.6366, 0.6111, 0.6324, 0.6717, 0.6733, 0.7612, 0.6104, 0.6210, 0.6293,
        0.6450, 0.6096, 0.6077, 0.6187, 0.6488, 0.6226, 0.7021],
       device='cuda:0') torch.Size([16])
percent tensor([0.6092, 0.6820, 0.6982, 0.7275, 0.6828, 0.7511, 0.6847, 0.5514, 0.7097,
        0.6599, 0.7273, 0.6956, 0.7344, 0.7070, 0.5611, 0.6604],
       device='cuda:0') torch.Size([16])
percent tensor([0.5812, 0.6202, 0.6542, 0.6779, 0.6694, 0.6480, 0.6350, 0.6155, 0.5980,
        0.6385, 0.6539, 0.6283, 0.6307, 0.5969, 0.5722, 0.5965],
       device='cuda:0') torch.Size([16])
percent tensor([0.9999, 0.9996, 0.9996, 0.9998, 0.9991, 0.9984, 0.9994, 0.9997, 0.9999,
        0.9998, 0.9999, 0.9997, 0.9999, 0.9996, 0.9988, 0.9995],
       device='cuda:0') torch.Size([16])
Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 3, 3, 3]) tensor(179.4678, device='cuda:0')
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(826.3123, device='cuda:0')
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(822.0396, device='cuda:0')
Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([128, 64, 3, 3]) tensor(1518.1370, device='cuda:0')
Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([128, 64, 1, 1]) tensor(488.1631, device='cuda:0')
Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([128, 128, 3, 3]) tensor(2267.6748, device='cuda:0')
Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([256, 128, 3, 3]) tensor(4268.9609, device='cuda:0')
Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([256, 128, 1, 1]) tensor(1375.1897, device='cuda:0')
Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([256, 256, 3, 3]) tensor(6212.9966, device='cuda:0')
Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([512, 256, 3, 3]) tensor(11723.9238, device='cuda:0')
Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([512, 256, 1, 1]) tensor(3872.9253, device='cuda:0')
Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([512, 512, 3, 3]) tensor(16382.9619, device='cuda:0')
Epoch: 141 | Batch_idx: 0 |  Loss: (0.1789) |  Loss2: (0.0000) | Acc: (93.00%) (120/128)
Epoch: 141 | Batch_idx: 10 |  Loss: (0.1538) |  Loss2: (0.0000) | Acc: (94.00%) (1337/1408)
Epoch: 141 | Batch_idx: 20 |  Loss: (0.1497) |  Loss2: (0.0000) | Acc: (94.00%) (2547/2688)
Epoch: 141 | Batch_idx: 30 |  Loss: (0.1547) |  Loss2: (0.0000) | Acc: (94.00%) (3756/3968)
Epoch: 141 | Batch_idx: 40 |  Loss: (0.1489) |  Loss2: (0.0000) | Acc: (94.00%) (4978/5248)
Epoch: 141 | Batch_idx: 50 |  Loss: (0.1457) |  Loss2: (0.0000) | Acc: (94.00%) (6199/6528)
Epoch: 141 | Batch_idx: 60 |  Loss: (0.1491) |  Loss2: (0.0000) | Acc: (94.00%) (7407/7808)
Epoch: 141 | Batch_idx: 70 |  Loss: (0.1475) |  Loss2: (0.0000) | Acc: (94.00%) (8622/9088)
Epoch: 141 | Batch_idx: 80 |  Loss: (0.1475) |  Loss2: (0.0000) | Acc: (94.00%) (9840/10368)
Epoch: 141 | Batch_idx: 90 |  Loss: (0.1471) |  Loss2: (0.0000) | Acc: (94.00%) (11061/11648)
Epoch: 141 | Batch_idx: 100 |  Loss: (0.1471) |  Loss2: (0.0000) | Acc: (94.00%) (12271/12928)
Epoch: 141 | Batch_idx: 110 |  Loss: (0.1471) |  Loss2: (0.0000) | Acc: (94.00%) (13494/14208)
Epoch: 141 | Batch_idx: 120 |  Loss: (0.1479) |  Loss2: (0.0000) | Acc: (94.00%) (14705/15488)
Epoch: 141 | Batch_idx: 130 |  Loss: (0.1477) |  Loss2: (0.0000) | Acc: (94.00%) (15924/16768)
Epoch: 141 | Batch_idx: 140 |  Loss: (0.1480) |  Loss2: (0.0000) | Acc: (94.00%) (17135/18048)
Epoch: 141 | Batch_idx: 150 |  Loss: (0.1486) |  Loss2: (0.0000) | Acc: (94.00%) (18355/19328)
Epoch: 141 | Batch_idx: 160 |  Loss: (0.1500) |  Loss2: (0.0000) | Acc: (94.00%) (19566/20608)
Epoch: 141 | Batch_idx: 170 |  Loss: (0.1512) |  Loss2: (0.0000) | Acc: (94.00%) (20766/21888)
Epoch: 141 | Batch_idx: 180 |  Loss: (0.1510) |  Loss2: (0.0000) | Acc: (94.00%) (21982/23168)
Epoch: 141 | Batch_idx: 190 |  Loss: (0.1498) |  Loss2: (0.0000) | Acc: (94.00%) (23204/24448)
Epoch: 141 | Batch_idx: 200 |  Loss: (0.1495) |  Loss2: (0.0000) | Acc: (94.00%) (24424/25728)
Epoch: 141 | Batch_idx: 210 |  Loss: (0.1487) |  Loss2: (0.0000) | Acc: (94.00%) (25646/27008)
Epoch: 141 | Batch_idx: 220 |  Loss: (0.1484) |  Loss2: (0.0000) | Acc: (94.00%) (26862/28288)
Epoch: 141 | Batch_idx: 230 |  Loss: (0.1499) |  Loss2: (0.0000) | Acc: (94.00%) (28059/29568)
Epoch: 141 | Batch_idx: 240 |  Loss: (0.1485) |  Loss2: (0.0000) | Acc: (94.00%) (29296/30848)
Epoch: 141 | Batch_idx: 250 |  Loss: (0.1483) |  Loss2: (0.0000) | Acc: (94.00%) (30515/32128)
Epoch: 141 | Batch_idx: 260 |  Loss: (0.1487) |  Loss2: (0.0000) | Acc: (94.00%) (31718/33408)
Epoch: 141 | Batch_idx: 270 |  Loss: (0.1483) |  Loss2: (0.0000) | Acc: (94.00%) (32930/34688)
Epoch: 141 | Batch_idx: 280 |  Loss: (0.1482) |  Loss2: (0.0000) | Acc: (94.00%) (34147/35968)
Epoch: 141 | Batch_idx: 290 |  Loss: (0.1487) |  Loss2: (0.0000) | Acc: (94.00%) (35358/37248)
Epoch: 141 | Batch_idx: 300 |  Loss: (0.1480) |  Loss2: (0.0000) | Acc: (94.00%) (36575/38528)
Epoch: 141 | Batch_idx: 310 |  Loss: (0.1475) |  Loss2: (0.0000) | Acc: (94.00%) (37796/39808)
Epoch: 141 | Batch_idx: 320 |  Loss: (0.1470) |  Loss2: (0.0000) | Acc: (94.00%) (39016/41088)
Epoch: 141 | Batch_idx: 330 |  Loss: (0.1469) |  Loss2: (0.0000) | Acc: (94.00%) (40238/42368)
Epoch: 141 | Batch_idx: 340 |  Loss: (0.1474) |  Loss2: (0.0000) | Acc: (94.00%) (41452/43648)
Epoch: 141 | Batch_idx: 350 |  Loss: (0.1473) |  Loss2: (0.0000) | Acc: (94.00%) (42672/44928)
Epoch: 141 | Batch_idx: 360 |  Loss: (0.1476) |  Loss2: (0.0000) | Acc: (94.00%) (43875/46208)
Epoch: 141 | Batch_idx: 370 |  Loss: (0.1472) |  Loss2: (0.0000) | Acc: (94.00%) (45102/47488)
Epoch: 141 | Batch_idx: 380 |  Loss: (0.1473) |  Loss2: (0.0000) | Acc: (94.00%) (46317/48768)
Epoch: 141 | Batch_idx: 390 |  Loss: (0.1472) |  Loss2: (0.0000) | Acc: (94.00%) (47487/50000)
# TEST : Loss: (0.3769) | Acc: (88.00%) (8815/10000)
percent tensor([0.5120, 0.5123, 0.5133, 0.5159, 0.5142, 0.5204, 0.5133, 0.5157, 0.5123,
        0.5116, 0.5121, 0.5119, 0.5114, 0.5143, 0.5151, 0.5142],
       device='cuda:0') torch.Size([16])
percent tensor([0.5047, 0.5076, 0.5018, 0.5018, 0.4993, 0.5128, 0.5027, 0.4964, 0.5014,
        0.5037, 0.5032, 0.5037, 0.5104, 0.5006, 0.5077, 0.5072],
       device='cuda:0') torch.Size([16])
percent tensor([0.5801, 0.5290, 0.6425, 0.6638, 0.6528, 0.6092, 0.5867, 0.6373, 0.6331,
        0.5748, 0.6058, 0.5928, 0.4815, 0.6495, 0.5677, 0.5905],
       device='cuda:0') torch.Size([16])
percent tensor([0.6259, 0.6218, 0.6120, 0.6176, 0.6177, 0.6207, 0.6259, 0.6227, 0.6245,
        0.6267, 0.6266, 0.6227, 0.6211, 0.6208, 0.6265, 0.6338],
       device='cuda:0') torch.Size([16])
percent tensor([0.6372, 0.6069, 0.6350, 0.6702, 0.6752, 0.7615, 0.6115, 0.6257, 0.6302,
        0.6416, 0.6066, 0.6057, 0.6171, 0.6472, 0.6198, 0.7005],
       device='cuda:0') torch.Size([16])
percent tensor([0.6057, 0.6822, 0.6981, 0.7290, 0.6797, 0.7498, 0.6814, 0.5458, 0.7125,
        0.6588, 0.7288, 0.6983, 0.7353, 0.7087, 0.5572, 0.6547],
       device='cuda:0') torch.Size([16])
percent tensor([0.5956, 0.6390, 0.6699, 0.6910, 0.6821, 0.6545, 0.6467, 0.6272, 0.6199,
        0.6594, 0.6736, 0.6477, 0.6466, 0.6178, 0.5860, 0.6033],
       device='cuda:0') torch.Size([16])
percent tensor([0.9999, 0.9996, 0.9996, 0.9997, 0.9991, 0.9984, 0.9994, 0.9997, 0.9999,
        0.9998, 0.9999, 0.9997, 0.9999, 0.9996, 0.9988, 0.9995],
       device='cuda:0') torch.Size([16])
Epoch: 142 | Batch_idx: 0 |  Loss: (0.1609) |  Loss2: (0.0000) | Acc: (93.00%) (120/128)
Epoch: 142 | Batch_idx: 10 |  Loss: (0.1403) |  Loss2: (0.0000) | Acc: (94.00%) (1335/1408)
Epoch: 142 | Batch_idx: 20 |  Loss: (0.1406) |  Loss2: (0.0000) | Acc: (94.00%) (2552/2688)
Epoch: 142 | Batch_idx: 30 |  Loss: (0.1405) |  Loss2: (0.0000) | Acc: (95.00%) (3774/3968)
Epoch: 142 | Batch_idx: 40 |  Loss: (0.1367) |  Loss2: (0.0000) | Acc: (95.00%) (5003/5248)
Epoch: 142 | Batch_idx: 50 |  Loss: (0.1358) |  Loss2: (0.0000) | Acc: (95.00%) (6226/6528)
Epoch: 142 | Batch_idx: 60 |  Loss: (0.1345) |  Loss2: (0.0000) | Acc: (95.00%) (7447/7808)
Epoch: 142 | Batch_idx: 70 |  Loss: (0.1383) |  Loss2: (0.0000) | Acc: (95.00%) (8656/9088)
Epoch: 142 | Batch_idx: 80 |  Loss: (0.1408) |  Loss2: (0.0000) | Acc: (95.00%) (9868/10368)
Epoch: 142 | Batch_idx: 90 |  Loss: (0.1409) |  Loss2: (0.0000) | Acc: (95.00%) (11085/11648)
Epoch: 142 | Batch_idx: 100 |  Loss: (0.1416) |  Loss2: (0.0000) | Acc: (95.00%) (12298/12928)
Epoch: 142 | Batch_idx: 110 |  Loss: (0.1428) |  Loss2: (0.0000) | Acc: (95.00%) (13508/14208)
Epoch: 142 | Batch_idx: 120 |  Loss: (0.1416) |  Loss2: (0.0000) | Acc: (95.00%) (14734/15488)
Epoch: 142 | Batch_idx: 130 |  Loss: (0.1421) |  Loss2: (0.0000) | Acc: (95.00%) (15946/16768)
Epoch: 142 | Batch_idx: 140 |  Loss: (0.1436) |  Loss2: (0.0000) | Acc: (95.00%) (17155/18048)
Epoch: 142 | Batch_idx: 150 |  Loss: (0.1432) |  Loss2: (0.0000) | Acc: (95.00%) (18374/19328)
Epoch: 142 | Batch_idx: 160 |  Loss: (0.1417) |  Loss2: (0.0000) | Acc: (95.00%) (19602/20608)
Epoch: 142 | Batch_idx: 170 |  Loss: (0.1422) |  Loss2: (0.0000) | Acc: (95.00%) (20819/21888)
Epoch: 142 | Batch_idx: 180 |  Loss: (0.1418) |  Loss2: (0.0000) | Acc: (95.00%) (22049/23168)
Epoch: 142 | Batch_idx: 190 |  Loss: (0.1427) |  Loss2: (0.0000) | Acc: (95.00%) (23254/24448)
Epoch: 142 | Batch_idx: 200 |  Loss: (0.1433) |  Loss2: (0.0000) | Acc: (95.00%) (24464/25728)
Epoch: 142 | Batch_idx: 210 |  Loss: (0.1443) |  Loss2: (0.0000) | Acc: (95.00%) (25676/27008)
Epoch: 142 | Batch_idx: 220 |  Loss: (0.1439) |  Loss2: (0.0000) | Acc: (95.00%) (26893/28288)
Epoch: 142 | Batch_idx: 230 |  Loss: (0.1436) |  Loss2: (0.0000) | Acc: (95.00%) (28116/29568)
Epoch: 142 | Batch_idx: 240 |  Loss: (0.1433) |  Loss2: (0.0000) | Acc: (95.00%) (29335/30848)
Epoch: 142 | Batch_idx: 250 |  Loss: (0.1437) |  Loss2: (0.0000) | Acc: (95.00%) (30549/32128)
Epoch: 142 | Batch_idx: 260 |  Loss: (0.1437) |  Loss2: (0.0000) | Acc: (95.00%) (31768/33408)
Epoch: 142 | Batch_idx: 270 |  Loss: (0.1429) |  Loss2: (0.0000) | Acc: (95.00%) (32996/34688)
Epoch: 142 | Batch_idx: 280 |  Loss: (0.1434) |  Loss2: (0.0000) | Acc: (95.00%) (34208/35968)
Epoch: 142 | Batch_idx: 290 |  Loss: (0.1432) |  Loss2: (0.0000) | Acc: (95.00%) (35424/37248)
Epoch: 142 | Batch_idx: 300 |  Loss: (0.1427) |  Loss2: (0.0000) | Acc: (95.00%) (36642/38528)
Epoch: 142 | Batch_idx: 310 |  Loss: (0.1421) |  Loss2: (0.0000) | Acc: (95.00%) (37878/39808)
Epoch: 142 | Batch_idx: 320 |  Loss: (0.1416) |  Loss2: (0.0000) | Acc: (95.00%) (39107/41088)
Epoch: 142 | Batch_idx: 330 |  Loss: (0.1413) |  Loss2: (0.0000) | Acc: (95.00%) (40323/42368)
Epoch: 142 | Batch_idx: 340 |  Loss: (0.1408) |  Loss2: (0.0000) | Acc: (95.00%) (41552/43648)
Epoch: 142 | Batch_idx: 350 |  Loss: (0.1411) |  Loss2: (0.0000) | Acc: (95.00%) (42768/44928)
Epoch: 142 | Batch_idx: 360 |  Loss: (0.1414) |  Loss2: (0.0000) | Acc: (95.00%) (43982/46208)
Epoch: 142 | Batch_idx: 370 |  Loss: (0.1410) |  Loss2: (0.0000) | Acc: (95.00%) (45211/47488)
Epoch: 142 | Batch_idx: 380 |  Loss: (0.1406) |  Loss2: (0.0000) | Acc: (95.00%) (46440/48768)
Epoch: 142 | Batch_idx: 390 |  Loss: (0.1406) |  Loss2: (0.0000) | Acc: (95.00%) (47618/50000)
# TEST : Loss: (0.3772) | Acc: (88.00%) (8806/10000)
percent tensor([0.5122, 0.5126, 0.5137, 0.5161, 0.5145, 0.5204, 0.5136, 0.5161, 0.5126,
        0.5120, 0.5123, 0.5123, 0.5116, 0.5146, 0.5153, 0.5144],
       device='cuda:0') torch.Size([16])
percent tensor([0.5072, 0.5108, 0.5046, 0.5049, 0.5022, 0.5149, 0.5059, 0.4994, 0.5044,
        0.5068, 0.5062, 0.5067, 0.5132, 0.5036, 0.5106, 0.5099],
       device='cuda:0') torch.Size([16])
percent tensor([0.5757, 0.5235, 0.6398, 0.6604, 0.6483, 0.6037, 0.5800, 0.6323, 0.6282,
        0.5710, 0.6023, 0.5871, 0.4761, 0.6464, 0.5604, 0.5865],
       device='cuda:0') torch.Size([16])
percent tensor([0.6250, 0.6212, 0.6114, 0.6163, 0.6170, 0.6183, 0.6253, 0.6216, 0.6236,
        0.6266, 0.6261, 0.6215, 0.6203, 0.6197, 0.6249, 0.6330],
       device='cuda:0') torch.Size([16])
percent tensor([0.6311, 0.6011, 0.6324, 0.6688, 0.6723, 0.7565, 0.6068, 0.6247, 0.6252,
        0.6341, 0.5992, 0.6025, 0.6111, 0.6421, 0.6142, 0.6935],
       device='cuda:0') torch.Size([16])
percent tensor([0.6174, 0.6975, 0.7064, 0.7367, 0.6876, 0.7605, 0.6941, 0.5516, 0.7238,
        0.6706, 0.7405, 0.7100, 0.7485, 0.7227, 0.5706, 0.6661],
       device='cuda:0') torch.Size([16])
percent tensor([0.6026, 0.6461, 0.6727, 0.6897, 0.6823, 0.6603, 0.6511, 0.6285, 0.6256,
        0.6661, 0.6799, 0.6488, 0.6522, 0.6243, 0.5908, 0.6059],
       device='cuda:0') torch.Size([16])
percent tensor([0.9999, 0.9996, 0.9996, 0.9997, 0.9991, 0.9985, 0.9994, 0.9997, 0.9999,
        0.9998, 0.9999, 0.9997, 0.9999, 0.9996, 0.9988, 0.9995],
       device='cuda:0') torch.Size([16])
Epoch: 143 | Batch_idx: 0 |  Loss: (0.0791) |  Loss2: (0.0000) | Acc: (97.00%) (125/128)
Epoch: 143 | Batch_idx: 10 |  Loss: (0.1236) |  Loss2: (0.0000) | Acc: (96.00%) (1353/1408)
Epoch: 143 | Batch_idx: 20 |  Loss: (0.1335) |  Loss2: (0.0000) | Acc: (95.00%) (2559/2688)
Epoch: 143 | Batch_idx: 30 |  Loss: (0.1282) |  Loss2: (0.0000) | Acc: (95.00%) (3787/3968)
Epoch: 143 | Batch_idx: 40 |  Loss: (0.1246) |  Loss2: (0.0000) | Acc: (95.00%) (5017/5248)
Epoch: 143 | Batch_idx: 50 |  Loss: (0.1282) |  Loss2: (0.0000) | Acc: (95.00%) (6239/6528)
Epoch: 143 | Batch_idx: 60 |  Loss: (0.1273) |  Loss2: (0.0000) | Acc: (95.00%) (7461/7808)
Epoch: 143 | Batch_idx: 70 |  Loss: (0.1273) |  Loss2: (0.0000) | Acc: (95.00%) (8692/9088)
Epoch: 143 | Batch_idx: 80 |  Loss: (0.1274) |  Loss2: (0.0000) | Acc: (95.00%) (9917/10368)
Epoch: 143 | Batch_idx: 90 |  Loss: (0.1303) |  Loss2: (0.0000) | Acc: (95.00%) (11129/11648)
Epoch: 143 | Batch_idx: 100 |  Loss: (0.1315) |  Loss2: (0.0000) | Acc: (95.00%) (12340/12928)
Epoch: 143 | Batch_idx: 110 |  Loss: (0.1308) |  Loss2: (0.0000) | Acc: (95.00%) (13572/14208)
Epoch: 143 | Batch_idx: 120 |  Loss: (0.1328) |  Loss2: (0.0000) | Acc: (95.00%) (14783/15488)
Epoch: 143 | Batch_idx: 130 |  Loss: (0.1350) |  Loss2: (0.0000) | Acc: (95.00%) (15988/16768)
Epoch: 143 | Batch_idx: 140 |  Loss: (0.1351) |  Loss2: (0.0000) | Acc: (95.00%) (17206/18048)
Epoch: 143 | Batch_idx: 150 |  Loss: (0.1351) |  Loss2: (0.0000) | Acc: (95.00%) (18429/19328)
Epoch: 143 | Batch_idx: 160 |  Loss: (0.1356) |  Loss2: (0.0000) | Acc: (95.00%) (19638/20608)
Epoch: 143 | Batch_idx: 170 |  Loss: (0.1353) |  Loss2: (0.0000) | Acc: (95.00%) (20857/21888)
Epoch: 143 | Batch_idx: 180 |  Loss: (0.1347) |  Loss2: (0.0000) | Acc: (95.00%) (22079/23168)
Epoch: 143 | Batch_idx: 190 |  Loss: (0.1354) |  Loss2: (0.0000) | Acc: (95.00%) (23291/24448)
Epoch: 143 | Batch_idx: 200 |  Loss: (0.1363) |  Loss2: (0.0000) | Acc: (95.00%) (24505/25728)
Epoch: 143 | Batch_idx: 210 |  Loss: (0.1351) |  Loss2: (0.0000) | Acc: (95.00%) (25738/27008)
Epoch: 143 | Batch_idx: 220 |  Loss: (0.1357) |  Loss2: (0.0000) | Acc: (95.00%) (26951/28288)
Epoch: 143 | Batch_idx: 230 |  Loss: (0.1352) |  Loss2: (0.0000) | Acc: (95.00%) (28183/29568)
Epoch: 143 | Batch_idx: 240 |  Loss: (0.1348) |  Loss2: (0.0000) | Acc: (95.00%) (29412/30848)
Epoch: 143 | Batch_idx: 250 |  Loss: (0.1361) |  Loss2: (0.0000) | Acc: (95.00%) (30616/32128)
Epoch: 143 | Batch_idx: 260 |  Loss: (0.1364) |  Loss2: (0.0000) | Acc: (95.00%) (31836/33408)
Epoch: 143 | Batch_idx: 270 |  Loss: (0.1364) |  Loss2: (0.0000) | Acc: (95.00%) (33059/34688)
Epoch: 143 | Batch_idx: 280 |  Loss: (0.1363) |  Loss2: (0.0000) | Acc: (95.00%) (34275/35968)
Epoch: 143 | Batch_idx: 290 |  Loss: (0.1365) |  Loss2: (0.0000) | Acc: (95.00%) (35493/37248)
Epoch: 143 | Batch_idx: 300 |  Loss: (0.1364) |  Loss2: (0.0000) | Acc: (95.00%) (36716/38528)
Epoch: 143 | Batch_idx: 310 |  Loss: (0.1368) |  Loss2: (0.0000) | Acc: (95.00%) (37928/39808)
Epoch: 143 | Batch_idx: 320 |  Loss: (0.1372) |  Loss2: (0.0000) | Acc: (95.00%) (39144/41088)
Epoch: 143 | Batch_idx: 330 |  Loss: (0.1373) |  Loss2: (0.0000) | Acc: (95.00%) (40354/42368)
Epoch: 143 | Batch_idx: 340 |  Loss: (0.1376) |  Loss2: (0.0000) | Acc: (95.00%) (41573/43648)
Epoch: 143 | Batch_idx: 350 |  Loss: (0.1380) |  Loss2: (0.0000) | Acc: (95.00%) (42792/44928)
Epoch: 143 | Batch_idx: 360 |  Loss: (0.1376) |  Loss2: (0.0000) | Acc: (95.00%) (44020/46208)
Epoch: 143 | Batch_idx: 370 |  Loss: (0.1371) |  Loss2: (0.0000) | Acc: (95.00%) (45244/47488)
Epoch: 143 | Batch_idx: 380 |  Loss: (0.1376) |  Loss2: (0.0000) | Acc: (95.00%) (46450/48768)
Epoch: 143 | Batch_idx: 390 |  Loss: (0.1375) |  Loss2: (0.0000) | Acc: (95.00%) (47624/50000)
# TEST : Loss: (0.3741) | Acc: (88.00%) (8834/10000)
percent tensor([0.5116, 0.5119, 0.5133, 0.5155, 0.5139, 0.5194, 0.5130, 0.5157, 0.5121,
        0.5114, 0.5116, 0.5119, 0.5110, 0.5140, 0.5144, 0.5137],
       device='cuda:0') torch.Size([16])
percent tensor([0.5072, 0.5111, 0.5042, 0.5048, 0.5019, 0.5152, 0.5060, 0.4991, 0.5044,
        0.5069, 0.5066, 0.5065, 0.5132, 0.5040, 0.5109, 0.5101],
       device='cuda:0') torch.Size([16])
percent tensor([0.5903, 0.5388, 0.6463, 0.6658, 0.6538, 0.6142, 0.5947, 0.6388, 0.6410,
        0.5874, 0.6170, 0.6016, 0.4940, 0.6583, 0.5746, 0.6008],
       device='cuda:0') torch.Size([16])
percent tensor([0.6274, 0.6229, 0.6117, 0.6168, 0.6182, 0.6197, 0.6275, 0.6229, 0.6251,
        0.6290, 0.6287, 0.6226, 0.6223, 0.6217, 0.6266, 0.6356],
       device='cuda:0') torch.Size([16])
percent tensor([0.6377, 0.6063, 0.6352, 0.6705, 0.6753, 0.7562, 0.6134, 0.6300, 0.6349,
        0.6402, 0.6085, 0.6063, 0.6165, 0.6497, 0.6183, 0.6982],
       device='cuda:0') torch.Size([16])
percent tensor([0.6023, 0.6825, 0.7003, 0.7308, 0.6816, 0.7532, 0.6814, 0.5420, 0.7154,
        0.6564, 0.7313, 0.6998, 0.7344, 0.7123, 0.5550, 0.6513],
       device='cuda:0') torch.Size([16])
percent tensor([0.6024, 0.6429, 0.6787, 0.6926, 0.6892, 0.6593, 0.6508, 0.6360, 0.6264,
        0.6665, 0.6780, 0.6479, 0.6442, 0.6229, 0.5917, 0.6037],
       device='cuda:0') torch.Size([16])
percent tensor([0.9999, 0.9996, 0.9996, 0.9997, 0.9991, 0.9985, 0.9994, 0.9997, 0.9999,
        0.9998, 0.9999, 0.9997, 0.9999, 0.9996, 0.9989, 0.9995],
       device='cuda:0') torch.Size([16])
True Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=128, out_features=16, bias=False)
False Linear(in_features=16, out_features=2, bias=False)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=128, out_features=16, bias=False)
False Linear(in_features=16, out_features=2, bias=False)
True Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=256, out_features=32, bias=False)
False Linear(in_features=32, out_features=2, bias=False)
True Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=256, out_features=32, bias=False)
False Linear(in_features=32, out_features=2, bias=False)
True Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=512, out_features=64, bias=False)
False Linear(in_features=64, out_features=2, bias=False)
True Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=512, out_features=64, bias=False)
False Linear(in_features=64, out_features=2, bias=False)
True Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1024, out_features=128, bias=False)
False Linear(in_features=128, out_features=2, bias=False)
True Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1024, out_features=128, bias=False)
False Linear(in_features=128, out_features=2, bias=False)
True Linear(in_features=512, out_features=10, bias=True)
Epoch: 144 | Batch_idx: 0 |  Loss: (0.1656) |  Loss2: (0.0000) | Acc: (95.00%) (122/128)
Epoch: 144 | Batch_idx: 10 |  Loss: (0.1340) |  Loss2: (0.0000) | Acc: (95.00%) (1347/1408)
Epoch: 144 | Batch_idx: 20 |  Loss: (0.1329) |  Loss2: (0.0000) | Acc: (95.00%) (2563/2688)
Epoch: 144 | Batch_idx: 30 |  Loss: (0.1348) |  Loss2: (0.0000) | Acc: (95.00%) (3782/3968)
Epoch: 144 | Batch_idx: 40 |  Loss: (0.1421) |  Loss2: (0.0000) | Acc: (95.00%) (4991/5248)
Epoch: 144 | Batch_idx: 50 |  Loss: (0.1396) |  Loss2: (0.0000) | Acc: (95.00%) (6204/6528)
Epoch: 144 | Batch_idx: 60 |  Loss: (0.1374) |  Loss2: (0.0000) | Acc: (95.00%) (7427/7808)
Epoch: 144 | Batch_idx: 70 |  Loss: (0.1377) |  Loss2: (0.0000) | Acc: (95.00%) (8642/9088)
Epoch: 144 | Batch_idx: 80 |  Loss: (0.1362) |  Loss2: (0.0000) | Acc: (95.00%) (9867/10368)
Epoch: 144 | Batch_idx: 90 |  Loss: (0.1379) |  Loss2: (0.0000) | Acc: (95.00%) (11078/11648)
Epoch: 144 | Batch_idx: 100 |  Loss: (0.1388) |  Loss2: (0.0000) | Acc: (95.00%) (12297/12928)
Epoch: 144 | Batch_idx: 110 |  Loss: (0.1403) |  Loss2: (0.0000) | Acc: (95.00%) (13513/14208)
Epoch: 144 | Batch_idx: 120 |  Loss: (0.1414) |  Loss2: (0.0000) | Acc: (95.00%) (14720/15488)
Epoch: 144 | Batch_idx: 130 |  Loss: (0.1425) |  Loss2: (0.0000) | Acc: (95.00%) (15930/16768)
Epoch: 144 | Batch_idx: 140 |  Loss: (0.1434) |  Loss2: (0.0000) | Acc: (94.00%) (17144/18048)
Epoch: 144 | Batch_idx: 150 |  Loss: (0.1440) |  Loss2: (0.0000) | Acc: (95.00%) (18362/19328)
Epoch: 144 | Batch_idx: 160 |  Loss: (0.1445) |  Loss2: (0.0000) | Acc: (94.00%) (19573/20608)
Epoch: 144 | Batch_idx: 170 |  Loss: (0.1447) |  Loss2: (0.0000) | Acc: (95.00%) (20796/21888)
Epoch: 144 | Batch_idx: 180 |  Loss: (0.1441) |  Loss2: (0.0000) | Acc: (95.00%) (22018/23168)
Epoch: 144 | Batch_idx: 190 |  Loss: (0.1449) |  Loss2: (0.0000) | Acc: (94.00%) (23225/24448)
Epoch: 144 | Batch_idx: 200 |  Loss: (0.1445) |  Loss2: (0.0000) | Acc: (95.00%) (24443/25728)
Epoch: 144 | Batch_idx: 210 |  Loss: (0.1447) |  Loss2: (0.0000) | Acc: (95.00%) (25662/27008)
Epoch: 144 | Batch_idx: 220 |  Loss: (0.1448) |  Loss2: (0.0000) | Acc: (95.00%) (26876/28288)
Epoch: 144 | Batch_idx: 230 |  Loss: (0.1448) |  Loss2: (0.0000) | Acc: (95.00%) (28090/29568)
Epoch: 144 | Batch_idx: 240 |  Loss: (0.1444) |  Loss2: (0.0000) | Acc: (95.00%) (29314/30848)
Epoch: 144 | Batch_idx: 250 |  Loss: (0.1447) |  Loss2: (0.0000) | Acc: (95.00%) (30530/32128)
Epoch: 144 | Batch_idx: 260 |  Loss: (0.1448) |  Loss2: (0.0000) | Acc: (95.00%) (31748/33408)
Epoch: 144 | Batch_idx: 270 |  Loss: (0.1451) |  Loss2: (0.0000) | Acc: (94.00%) (32953/34688)
Epoch: 144 | Batch_idx: 280 |  Loss: (0.1458) |  Loss2: (0.0000) | Acc: (94.00%) (34166/35968)
Epoch: 144 | Batch_idx: 290 |  Loss: (0.1459) |  Loss2: (0.0000) | Acc: (94.00%) (35384/37248)
Epoch: 144 | Batch_idx: 300 |  Loss: (0.1466) |  Loss2: (0.0000) | Acc: (94.00%) (36579/38528)
Epoch: 144 | Batch_idx: 310 |  Loss: (0.1469) |  Loss2: (0.0000) | Acc: (94.00%) (37787/39808)
Epoch: 144 | Batch_idx: 320 |  Loss: (0.1467) |  Loss2: (0.0000) | Acc: (94.00%) (38999/41088)
Epoch: 144 | Batch_idx: 330 |  Loss: (0.1474) |  Loss2: (0.0000) | Acc: (94.00%) (40204/42368)
Epoch: 144 | Batch_idx: 340 |  Loss: (0.1474) |  Loss2: (0.0000) | Acc: (94.00%) (41428/43648)
Epoch: 144 | Batch_idx: 350 |  Loss: (0.1474) |  Loss2: (0.0000) | Acc: (94.00%) (42635/44928)
Epoch: 144 | Batch_idx: 360 |  Loss: (0.1468) |  Loss2: (0.0000) | Acc: (94.00%) (43858/46208)
Epoch: 144 | Batch_idx: 370 |  Loss: (0.1472) |  Loss2: (0.0000) | Acc: (94.00%) (45067/47488)
Epoch: 144 | Batch_idx: 380 |  Loss: (0.1469) |  Loss2: (0.0000) | Acc: (94.00%) (46281/48768)
Epoch: 144 | Batch_idx: 390 |  Loss: (0.1469) |  Loss2: (0.0000) | Acc: (94.00%) (47451/50000)
# TEST : Loss: (0.3902) | Acc: (88.00%) (8801/10000)
percent tensor([0.5115, 0.5122, 0.5125, 0.5151, 0.5130, 0.5192, 0.5131, 0.5148, 0.5115,
        0.5112, 0.5113, 0.5112, 0.5107, 0.5147, 0.5144, 0.5137],
       device='cuda:0') torch.Size([16])
percent tensor([0.5077, 0.5128, 0.5025, 0.5046, 0.5013, 0.5157, 0.5067, 0.5006, 0.5047,
        0.5083, 0.5068, 0.5074, 0.5145, 0.5060, 0.5115, 0.5113],
       device='cuda:0') torch.Size([16])
percent tensor([0.5858, 0.5273, 0.6489, 0.6662, 0.6561, 0.6120, 0.5931, 0.6373, 0.6299,
        0.5769, 0.6071, 0.5901, 0.4877, 0.6644, 0.5654, 0.5948],
       device='cuda:0') torch.Size([16])
percent tensor([0.6258, 0.6203, 0.6176, 0.6189, 0.6220, 0.6241, 0.6253, 0.6234, 0.6263,
        0.6268, 0.6260, 0.6222, 0.6212, 0.6224, 0.6259, 0.6354],
       device='cuda:0') torch.Size([16])
percent tensor([0.6431, 0.6000, 0.6502, 0.6738, 0.6975, 0.7557, 0.6132, 0.6333, 0.6470,
        0.6362, 0.6119, 0.6131, 0.6300, 0.6478, 0.6169, 0.6949],
       device='cuda:0') torch.Size([16])
percent tensor([0.6335, 0.6988, 0.6951, 0.7223, 0.6805, 0.7357, 0.7054, 0.5562, 0.7351,
        0.6725, 0.7503, 0.7000, 0.7538, 0.7274, 0.5770, 0.6482],
       device='cuda:0') torch.Size([16])
percent tensor([0.6106, 0.6445, 0.6617, 0.6759, 0.6818, 0.6484, 0.6628, 0.6172, 0.6251,
        0.6612, 0.6751, 0.6417, 0.6398, 0.6145, 0.5922, 0.6061],
       device='cuda:0') torch.Size([16])
percent tensor([0.9999, 0.9996, 0.9996, 0.9997, 0.9995, 0.9987, 0.9998, 0.9993, 0.9998,
        0.9998, 0.9998, 0.9997, 0.9998, 0.9997, 0.9988, 0.9996],
       device='cuda:0') torch.Size([16])
Epoch: 145 | Batch_idx: 0 |  Loss: (0.1235) |  Loss2: (0.0000) | Acc: (95.00%) (122/128)
Epoch: 145 | Batch_idx: 10 |  Loss: (0.1477) |  Loss2: (0.0000) | Acc: (94.00%) (1334/1408)
Epoch: 145 | Batch_idx: 20 |  Loss: (0.1447) |  Loss2: (0.0000) | Acc: (94.00%) (2549/2688)
Epoch: 145 | Batch_idx: 30 |  Loss: (0.1403) |  Loss2: (0.0000) | Acc: (95.00%) (3772/3968)
Epoch: 145 | Batch_idx: 40 |  Loss: (0.1343) |  Loss2: (0.0000) | Acc: (95.00%) (5013/5248)
Epoch: 145 | Batch_idx: 50 |  Loss: (0.1396) |  Loss2: (0.0000) | Acc: (95.00%) (6227/6528)
Epoch: 145 | Batch_idx: 60 |  Loss: (0.1372) |  Loss2: (0.0000) | Acc: (95.00%) (7453/7808)
Epoch: 145 | Batch_idx: 70 |  Loss: (0.1355) |  Loss2: (0.0000) | Acc: (95.00%) (8678/9088)
Epoch: 145 | Batch_idx: 80 |  Loss: (0.1371) |  Loss2: (0.0000) | Acc: (95.00%) (9894/10368)
Epoch: 145 | Batch_idx: 90 |  Loss: (0.1416) |  Loss2: (0.0000) | Acc: (95.00%) (11088/11648)
Epoch: 145 | Batch_idx: 100 |  Loss: (0.1401) |  Loss2: (0.0000) | Acc: (95.00%) (12312/12928)
Epoch: 145 | Batch_idx: 110 |  Loss: (0.1408) |  Loss2: (0.0000) | Acc: (95.00%) (13533/14208)
Epoch: 145 | Batch_idx: 120 |  Loss: (0.1400) |  Loss2: (0.0000) | Acc: (95.00%) (14762/15488)
Epoch: 145 | Batch_idx: 130 |  Loss: (0.1393) |  Loss2: (0.0000) | Acc: (95.00%) (15982/16768)
Epoch: 145 | Batch_idx: 140 |  Loss: (0.1395) |  Loss2: (0.0000) | Acc: (95.00%) (17199/18048)
Epoch: 145 | Batch_idx: 150 |  Loss: (0.1395) |  Loss2: (0.0000) | Acc: (95.00%) (18413/19328)
Epoch: 145 | Batch_idx: 160 |  Loss: (0.1398) |  Loss2: (0.0000) | Acc: (95.00%) (19629/20608)
Epoch: 145 | Batch_idx: 170 |  Loss: (0.1402) |  Loss2: (0.0000) | Acc: (95.00%) (20837/21888)
Epoch: 145 | Batch_idx: 180 |  Loss: (0.1399) |  Loss2: (0.0000) | Acc: (95.00%) (22054/23168)
Epoch: 145 | Batch_idx: 190 |  Loss: (0.1399) |  Loss2: (0.0000) | Acc: (95.00%) (23270/24448)
Epoch: 145 | Batch_idx: 200 |  Loss: (0.1416) |  Loss2: (0.0000) | Acc: (95.00%) (24475/25728)
Epoch: 145 | Batch_idx: 210 |  Loss: (0.1426) |  Loss2: (0.0000) | Acc: (95.00%) (25676/27008)
Epoch: 145 | Batch_idx: 220 |  Loss: (0.1428) |  Loss2: (0.0000) | Acc: (95.00%) (26898/28288)
Epoch: 145 | Batch_idx: 230 |  Loss: (0.1427) |  Loss2: (0.0000) | Acc: (95.00%) (28116/29568)
Epoch: 145 | Batch_idx: 240 |  Loss: (0.1418) |  Loss2: (0.0000) | Acc: (95.00%) (29341/30848)
Epoch: 145 | Batch_idx: 250 |  Loss: (0.1420) |  Loss2: (0.0000) | Acc: (95.00%) (30552/32128)
Epoch: 145 | Batch_idx: 260 |  Loss: (0.1421) |  Loss2: (0.0000) | Acc: (95.00%) (31769/33408)
Epoch: 145 | Batch_idx: 270 |  Loss: (0.1422) |  Loss2: (0.0000) | Acc: (95.00%) (32981/34688)
Epoch: 145 | Batch_idx: 280 |  Loss: (0.1433) |  Loss2: (0.0000) | Acc: (95.00%) (34177/35968)
Epoch: 145 | Batch_idx: 290 |  Loss: (0.1435) |  Loss2: (0.0000) | Acc: (95.00%) (35391/37248)
Epoch: 145 | Batch_idx: 300 |  Loss: (0.1438) |  Loss2: (0.0000) | Acc: (94.00%) (36601/38528)
Epoch: 145 | Batch_idx: 310 |  Loss: (0.1436) |  Loss2: (0.0000) | Acc: (94.00%) (37815/39808)
Epoch: 145 | Batch_idx: 320 |  Loss: (0.1434) |  Loss2: (0.0000) | Acc: (95.00%) (39038/41088)
Epoch: 145 | Batch_idx: 330 |  Loss: (0.1427) |  Loss2: (0.0000) | Acc: (95.00%) (40263/42368)
Epoch: 145 | Batch_idx: 340 |  Loss: (0.1423) |  Loss2: (0.0000) | Acc: (95.00%) (41485/43648)
Epoch: 145 | Batch_idx: 350 |  Loss: (0.1424) |  Loss2: (0.0000) | Acc: (95.00%) (42693/44928)
Epoch: 145 | Batch_idx: 360 |  Loss: (0.1429) |  Loss2: (0.0000) | Acc: (95.00%) (43905/46208)
Epoch: 145 | Batch_idx: 370 |  Loss: (0.1427) |  Loss2: (0.0000) | Acc: (95.00%) (45115/47488)
Epoch: 145 | Batch_idx: 380 |  Loss: (0.1425) |  Loss2: (0.0000) | Acc: (95.00%) (46339/48768)
Epoch: 145 | Batch_idx: 390 |  Loss: (0.1420) |  Loss2: (0.0000) | Acc: (95.00%) (47529/50000)
=> saving checkpoint 'drive/app/torch/save_Schedule/checkpoint_145.pth.tar'
# TEST : Loss: (0.3998) | Acc: (87.00%) (8792/10000)
percent tensor([0.5119, 0.5128, 0.5123, 0.5157, 0.5128, 0.5189, 0.5134, 0.5151, 0.5123,
        0.5118, 0.5117, 0.5113, 0.5112, 0.5161, 0.5142, 0.5142],
       device='cuda:0') torch.Size([16])
percent tensor([0.5073, 0.5114, 0.5034, 0.5049, 0.5009, 0.5146, 0.5061, 0.5010, 0.5052,
        0.5075, 0.5070, 0.5071, 0.5148, 0.5052, 0.5102, 0.5105],
       device='cuda:0') torch.Size([16])
percent tensor([0.5948, 0.5371, 0.6445, 0.6694, 0.6552, 0.6251, 0.5942, 0.6409, 0.6306,
        0.5883, 0.6119, 0.5912, 0.4909, 0.6625, 0.5826, 0.6076],
       device='cuda:0') torch.Size([16])
percent tensor([0.6239, 0.6191, 0.6150, 0.6187, 0.6206, 0.6242, 0.6268, 0.6228, 0.6222,
        0.6242, 0.6239, 0.6206, 0.6188, 0.6212, 0.6253, 0.6338],
       device='cuda:0') torch.Size([16])
percent tensor([0.6247, 0.6005, 0.6409, 0.6793, 0.6720, 0.7352, 0.6029, 0.6186, 0.6386,
        0.6417, 0.6019, 0.6182, 0.6113, 0.6498, 0.6081, 0.6826],
       device='cuda:0') torch.Size([16])
percent tensor([0.6221, 0.6753, 0.6809, 0.7186, 0.6654, 0.7676, 0.6767, 0.5343, 0.7020,
        0.6430, 0.7326, 0.6875, 0.7275, 0.7191, 0.5762, 0.6570],
       device='cuda:0') torch.Size([16])
percent tensor([0.6111, 0.6381, 0.6566, 0.6834, 0.6801, 0.6747, 0.6518, 0.6224, 0.6095,
        0.6553, 0.6648, 0.6199, 0.6201, 0.6174, 0.5908, 0.6044],
       device='cuda:0') torch.Size([16])
percent tensor([0.9999, 0.9996, 0.9996, 0.9997, 0.9993, 0.9990, 0.9994, 0.9995, 0.9997,
        0.9997, 0.9998, 0.9998, 0.9998, 0.9995, 0.9991, 0.9994],
       device='cuda:0') torch.Size([16])
Epoch: 146 | Batch_idx: 0 |  Loss: (0.0847) |  Loss2: (0.0000) | Acc: (96.00%) (123/128)
Epoch: 146 | Batch_idx: 10 |  Loss: (0.1370) |  Loss2: (0.0000) | Acc: (94.00%) (1336/1408)
Epoch: 146 | Batch_idx: 20 |  Loss: (0.1457) |  Loss2: (0.0000) | Acc: (94.00%) (2552/2688)
Epoch: 146 | Batch_idx: 30 |  Loss: (0.1403) |  Loss2: (0.0000) | Acc: (95.00%) (3773/3968)
Epoch: 146 | Batch_idx: 40 |  Loss: (0.1385) |  Loss2: (0.0000) | Acc: (95.00%) (4989/5248)
Epoch: 146 | Batch_idx: 50 |  Loss: (0.1354) |  Loss2: (0.0000) | Acc: (95.00%) (6218/6528)
Epoch: 146 | Batch_idx: 60 |  Loss: (0.1402) |  Loss2: (0.0000) | Acc: (95.00%) (7435/7808)
Epoch: 146 | Batch_idx: 70 |  Loss: (0.1375) |  Loss2: (0.0000) | Acc: (95.00%) (8666/9088)
Epoch: 146 | Batch_idx: 80 |  Loss: (0.1344) |  Loss2: (0.0000) | Acc: (95.00%) (9897/10368)
Epoch: 146 | Batch_idx: 90 |  Loss: (0.1326) |  Loss2: (0.0000) | Acc: (95.00%) (11127/11648)
Epoch: 146 | Batch_idx: 100 |  Loss: (0.1321) |  Loss2: (0.0000) | Acc: (95.00%) (12353/12928)
Epoch: 146 | Batch_idx: 110 |  Loss: (0.1322) |  Loss2: (0.0000) | Acc: (95.00%) (13572/14208)
Epoch: 146 | Batch_idx: 120 |  Loss: (0.1332) |  Loss2: (0.0000) | Acc: (95.00%) (14789/15488)
Epoch: 146 | Batch_idx: 130 |  Loss: (0.1331) |  Loss2: (0.0000) | Acc: (95.00%) (16012/16768)
Epoch: 146 | Batch_idx: 140 |  Loss: (0.1339) |  Loss2: (0.0000) | Acc: (95.00%) (17230/18048)
Epoch: 146 | Batch_idx: 150 |  Loss: (0.1333) |  Loss2: (0.0000) | Acc: (95.00%) (18455/19328)
Epoch: 146 | Batch_idx: 160 |  Loss: (0.1324) |  Loss2: (0.0000) | Acc: (95.00%) (19675/20608)
Epoch: 146 | Batch_idx: 170 |  Loss: (0.1334) |  Loss2: (0.0000) | Acc: (95.00%) (20888/21888)
Epoch: 146 | Batch_idx: 180 |  Loss: (0.1330) |  Loss2: (0.0000) | Acc: (95.00%) (22113/23168)
Epoch: 146 | Batch_idx: 190 |  Loss: (0.1337) |  Loss2: (0.0000) | Acc: (95.00%) (23321/24448)
Epoch: 146 | Batch_idx: 200 |  Loss: (0.1345) |  Loss2: (0.0000) | Acc: (95.00%) (24538/25728)
Epoch: 146 | Batch_idx: 210 |  Loss: (0.1347) |  Loss2: (0.0000) | Acc: (95.00%) (25751/27008)
Epoch: 146 | Batch_idx: 220 |  Loss: (0.1344) |  Loss2: (0.0000) | Acc: (95.00%) (26967/28288)
Epoch: 146 | Batch_idx: 230 |  Loss: (0.1346) |  Loss2: (0.0000) | Acc: (95.00%) (28185/29568)
Epoch: 146 | Batch_idx: 240 |  Loss: (0.1347) |  Loss2: (0.0000) | Acc: (95.00%) (29399/30848)
Epoch: 146 | Batch_idx: 250 |  Loss: (0.1352) |  Loss2: (0.0000) | Acc: (95.00%) (30613/32128)
Epoch: 146 | Batch_idx: 260 |  Loss: (0.1349) |  Loss2: (0.0000) | Acc: (95.00%) (31833/33408)
Epoch: 146 | Batch_idx: 270 |  Loss: (0.1350) |  Loss2: (0.0000) | Acc: (95.00%) (33054/34688)
Epoch: 146 | Batch_idx: 280 |  Loss: (0.1352) |  Loss2: (0.0000) | Acc: (95.00%) (34267/35968)
Epoch: 146 | Batch_idx: 290 |  Loss: (0.1360) |  Loss2: (0.0000) | Acc: (95.00%) (35479/37248)
Epoch: 146 | Batch_idx: 300 |  Loss: (0.1368) |  Loss2: (0.0000) | Acc: (95.00%) (36685/38528)
Epoch: 146 | Batch_idx: 310 |  Loss: (0.1378) |  Loss2: (0.0000) | Acc: (95.00%) (37879/39808)
Epoch: 146 | Batch_idx: 320 |  Loss: (0.1383) |  Loss2: (0.0000) | Acc: (95.00%) (39093/41088)
Epoch: 146 | Batch_idx: 330 |  Loss: (0.1380) |  Loss2: (0.0000) | Acc: (95.00%) (40322/42368)
Epoch: 146 | Batch_idx: 340 |  Loss: (0.1377) |  Loss2: (0.0000) | Acc: (95.00%) (41552/43648)
Epoch: 146 | Batch_idx: 350 |  Loss: (0.1375) |  Loss2: (0.0000) | Acc: (95.00%) (42778/44928)
Epoch: 146 | Batch_idx: 360 |  Loss: (0.1375) |  Loss2: (0.0000) | Acc: (95.00%) (44001/46208)
Epoch: 146 | Batch_idx: 370 |  Loss: (0.1379) |  Loss2: (0.0000) | Acc: (95.00%) (45214/47488)
Epoch: 146 | Batch_idx: 380 |  Loss: (0.1378) |  Loss2: (0.0000) | Acc: (95.00%) (46431/48768)
Epoch: 146 | Batch_idx: 390 |  Loss: (0.1379) |  Loss2: (0.0000) | Acc: (95.00%) (47604/50000)
# TEST : Loss: (0.4493) | Acc: (86.00%) (8653/10000)
percent tensor([0.5123, 0.5115, 0.5139, 0.5162, 0.5145, 0.5202, 0.5129, 0.5155, 0.5125,
        0.5112, 0.5113, 0.5121, 0.5114, 0.5136, 0.5146, 0.5140],
       device='cuda:0') torch.Size([16])
percent tensor([0.5083, 0.5095, 0.5066, 0.5052, 0.5030, 0.5134, 0.5051, 0.5012, 0.5054,
        0.5078, 0.5063, 0.5083, 0.5148, 0.5015, 0.5089, 0.5105],
       device='cuda:0') torch.Size([16])
percent tensor([0.5938, 0.5415, 0.6443, 0.6653, 0.6513, 0.6244, 0.5992, 0.6400, 0.6262,
        0.5854, 0.6145, 0.6024, 0.4961, 0.6584, 0.5852, 0.6029],
       device='cuda:0') torch.Size([16])
percent tensor([0.6258, 0.6204, 0.6162, 0.6175, 0.6213, 0.6198, 0.6268, 0.6240, 0.6239,
        0.6271, 0.6262, 0.6229, 0.6219, 0.6222, 0.6234, 0.6331],
       device='cuda:0') torch.Size([16])
percent tensor([0.6427, 0.6025, 0.6479, 0.6742, 0.6814, 0.7441, 0.6119, 0.6330, 0.6324,
        0.6394, 0.6075, 0.6166, 0.6248, 0.6487, 0.6053, 0.7015],
       device='cuda:0') torch.Size([16])
percent tensor([0.6204, 0.6877, 0.6809, 0.7216, 0.6610, 0.7589, 0.6881, 0.5514, 0.6980,
        0.6682, 0.7513, 0.6872, 0.7286, 0.7220, 0.5848, 0.6433],
       device='cuda:0') torch.Size([16])
percent tensor([0.6166, 0.6350, 0.6701, 0.6877, 0.6917, 0.6546, 0.6646, 0.6418, 0.6220,
        0.6687, 0.6673, 0.6218, 0.6314, 0.6168, 0.6100, 0.6118],
       device='cuda:0') torch.Size([16])
percent tensor([0.9998, 0.9997, 0.9996, 0.9997, 0.9995, 0.9990, 0.9996, 0.9997, 0.9998,
        0.9997, 0.9998, 0.9997, 0.9999, 0.9995, 0.9992, 0.9990],
       device='cuda:0') torch.Size([16])
Epoch: 147 | Batch_idx: 0 |  Loss: (0.1210) |  Loss2: (0.0000) | Acc: (96.00%) (123/128)
Epoch: 147 | Batch_idx: 10 |  Loss: (0.1314) |  Loss2: (0.0000) | Acc: (96.00%) (1352/1408)
Epoch: 147 | Batch_idx: 20 |  Loss: (0.1159) |  Loss2: (0.0000) | Acc: (96.00%) (2586/2688)
Epoch: 147 | Batch_idx: 30 |  Loss: (0.1179) |  Loss2: (0.0000) | Acc: (96.00%) (3815/3968)
Epoch: 147 | Batch_idx: 40 |  Loss: (0.1174) |  Loss2: (0.0000) | Acc: (96.00%) (5050/5248)
Epoch: 147 | Batch_idx: 50 |  Loss: (0.1210) |  Loss2: (0.0000) | Acc: (96.00%) (6278/6528)
Epoch: 147 | Batch_idx: 60 |  Loss: (0.1210) |  Loss2: (0.0000) | Acc: (96.00%) (7502/7808)
Epoch: 147 | Batch_idx: 70 |  Loss: (0.1192) |  Loss2: (0.0000) | Acc: (96.00%) (8737/9088)
Epoch: 147 | Batch_idx: 80 |  Loss: (0.1194) |  Loss2: (0.0000) | Acc: (96.00%) (9967/10368)
Epoch: 147 | Batch_idx: 90 |  Loss: (0.1225) |  Loss2: (0.0000) | Acc: (95.00%) (11179/11648)
Epoch: 147 | Batch_idx: 100 |  Loss: (0.1244) |  Loss2: (0.0000) | Acc: (95.00%) (12400/12928)
Epoch: 147 | Batch_idx: 110 |  Loss: (0.1255) |  Loss2: (0.0000) | Acc: (95.00%) (13622/14208)
Epoch: 147 | Batch_idx: 120 |  Loss: (0.1280) |  Loss2: (0.0000) | Acc: (95.00%) (14836/15488)
Epoch: 147 | Batch_idx: 130 |  Loss: (0.1280) |  Loss2: (0.0000) | Acc: (95.00%) (16060/16768)
Epoch: 147 | Batch_idx: 140 |  Loss: (0.1279) |  Loss2: (0.0000) | Acc: (95.00%) (17282/18048)
Epoch: 147 | Batch_idx: 150 |  Loss: (0.1280) |  Loss2: (0.0000) | Acc: (95.00%) (18507/19328)
Epoch: 147 | Batch_idx: 160 |  Loss: (0.1280) |  Loss2: (0.0000) | Acc: (95.00%) (19735/20608)
Epoch: 147 | Batch_idx: 170 |  Loss: (0.1294) |  Loss2: (0.0000) | Acc: (95.00%) (20938/21888)
Epoch: 147 | Batch_idx: 180 |  Loss: (0.1281) |  Loss2: (0.0000) | Acc: (95.00%) (22175/23168)
Epoch: 147 | Batch_idx: 190 |  Loss: (0.1289) |  Loss2: (0.0000) | Acc: (95.00%) (23393/24448)
Epoch: 147 | Batch_idx: 200 |  Loss: (0.1287) |  Loss2: (0.0000) | Acc: (95.00%) (24613/25728)
Epoch: 147 | Batch_idx: 210 |  Loss: (0.1286) |  Loss2: (0.0000) | Acc: (95.00%) (25843/27008)
Epoch: 147 | Batch_idx: 220 |  Loss: (0.1291) |  Loss2: (0.0000) | Acc: (95.00%) (27064/28288)
Epoch: 147 | Batch_idx: 230 |  Loss: (0.1294) |  Loss2: (0.0000) | Acc: (95.00%) (28285/29568)
Epoch: 147 | Batch_idx: 240 |  Loss: (0.1299) |  Loss2: (0.0000) | Acc: (95.00%) (29504/30848)
Epoch: 147 | Batch_idx: 250 |  Loss: (0.1304) |  Loss2: (0.0000) | Acc: (95.00%) (30720/32128)
Epoch: 147 | Batch_idx: 260 |  Loss: (0.1308) |  Loss2: (0.0000) | Acc: (95.00%) (31933/33408)
Epoch: 147 | Batch_idx: 270 |  Loss: (0.1316) |  Loss2: (0.0000) | Acc: (95.00%) (33136/34688)
Epoch: 147 | Batch_idx: 280 |  Loss: (0.1317) |  Loss2: (0.0000) | Acc: (95.00%) (34349/35968)
Epoch: 147 | Batch_idx: 290 |  Loss: (0.1322) |  Loss2: (0.0000) | Acc: (95.00%) (35572/37248)
Epoch: 147 | Batch_idx: 300 |  Loss: (0.1321) |  Loss2: (0.0000) | Acc: (95.00%) (36793/38528)
Epoch: 147 | Batch_idx: 310 |  Loss: (0.1326) |  Loss2: (0.0000) | Acc: (95.00%) (38004/39808)
Epoch: 147 | Batch_idx: 320 |  Loss: (0.1322) |  Loss2: (0.0000) | Acc: (95.00%) (39231/41088)
Epoch: 147 | Batch_idx: 330 |  Loss: (0.1325) |  Loss2: (0.0000) | Acc: (95.00%) (40450/42368)
Epoch: 147 | Batch_idx: 340 |  Loss: (0.1327) |  Loss2: (0.0000) | Acc: (95.00%) (41665/43648)
Epoch: 147 | Batch_idx: 350 |  Loss: (0.1331) |  Loss2: (0.0000) | Acc: (95.00%) (42877/44928)
Epoch: 147 | Batch_idx: 360 |  Loss: (0.1329) |  Loss2: (0.0000) | Acc: (95.00%) (44113/46208)
Epoch: 147 | Batch_idx: 370 |  Loss: (0.1331) |  Loss2: (0.0000) | Acc: (95.00%) (45333/47488)
Epoch: 147 | Batch_idx: 380 |  Loss: (0.1338) |  Loss2: (0.0000) | Acc: (95.00%) (46541/48768)
Epoch: 147 | Batch_idx: 390 |  Loss: (0.1348) |  Loss2: (0.0000) | Acc: (95.00%) (47711/50000)
# TEST : Loss: (0.4326) | Acc: (87.00%) (8710/10000)
percent tensor([0.5121, 0.5124, 0.5130, 0.5161, 0.5138, 0.5193, 0.5134, 0.5154, 0.5122,
        0.5117, 0.5114, 0.5116, 0.5110, 0.5151, 0.5145, 0.5141],
       device='cuda:0') torch.Size([16])
percent tensor([0.5069, 0.5119, 0.5028, 0.5038, 0.5005, 0.5145, 0.5057, 0.5008, 0.5056,
        0.5073, 0.5074, 0.5061, 0.5148, 0.5055, 0.5103, 0.5108],
       device='cuda:0') torch.Size([16])
percent tensor([0.5980, 0.5530, 0.6539, 0.6661, 0.6608, 0.6210, 0.6105, 0.6448, 0.6335,
        0.6012, 0.6176, 0.6151, 0.5025, 0.6681, 0.5902, 0.6093],
       device='cuda:0') torch.Size([16])
percent tensor([0.6257, 0.6194, 0.6176, 0.6197, 0.6223, 0.6235, 0.6270, 0.6249, 0.6243,
        0.6269, 0.6262, 0.6237, 0.6194, 0.6220, 0.6241, 0.6335],
       device='cuda:0') torch.Size([16])
percent tensor([0.6510, 0.6152, 0.6646, 0.6830, 0.6929, 0.7551, 0.6281, 0.6409, 0.6544,
        0.6555, 0.6177, 0.6287, 0.6345, 0.6630, 0.6215, 0.7068],
       device='cuda:0') torch.Size([16])
percent tensor([0.6254, 0.6785, 0.6822, 0.7160, 0.6675, 0.7567, 0.6778, 0.5371, 0.7124,
        0.6705, 0.7471, 0.6886, 0.7491, 0.7111, 0.5774, 0.6503],
       device='cuda:0') torch.Size([16])
percent tensor([0.6222, 0.6427, 0.6602, 0.6897, 0.6792, 0.6711, 0.6609, 0.6458, 0.6230,
        0.6697, 0.6774, 0.6114, 0.6277, 0.6221, 0.5968, 0.6130],
       device='cuda:0') torch.Size([16])
percent tensor([0.9999, 0.9997, 0.9996, 0.9996, 0.9995, 0.9986, 0.9994, 0.9997, 0.9999,
        0.9997, 0.9999, 0.9996, 0.9999, 0.9996, 0.9990, 0.9995],
       device='cuda:0') torch.Size([16])
Epoch: 148 | Batch_idx: 0 |  Loss: (0.1414) |  Loss2: (0.0000) | Acc: (93.00%) (120/128)
Epoch: 148 | Batch_idx: 10 |  Loss: (0.1351) |  Loss2: (0.0000) | Acc: (95.00%) (1344/1408)
Epoch: 148 | Batch_idx: 20 |  Loss: (0.1358) |  Loss2: (0.0000) | Acc: (95.00%) (2565/2688)
Epoch: 148 | Batch_idx: 30 |  Loss: (0.1384) |  Loss2: (0.0000) | Acc: (95.00%) (3779/3968)
Epoch: 148 | Batch_idx: 40 |  Loss: (0.1307) |  Loss2: (0.0000) | Acc: (95.00%) (5010/5248)
Epoch: 148 | Batch_idx: 50 |  Loss: (0.1370) |  Loss2: (0.0000) | Acc: (95.00%) (6207/6528)
Epoch: 148 | Batch_idx: 60 |  Loss: (0.1345) |  Loss2: (0.0000) | Acc: (95.00%) (7437/7808)
Epoch: 148 | Batch_idx: 70 |  Loss: (0.1378) |  Loss2: (0.0000) | Acc: (95.00%) (8651/9088)
Epoch: 148 | Batch_idx: 80 |  Loss: (0.1358) |  Loss2: (0.0000) | Acc: (95.00%) (9872/10368)
Epoch: 148 | Batch_idx: 90 |  Loss: (0.1337) |  Loss2: (0.0000) | Acc: (95.00%) (11107/11648)
Epoch: 148 | Batch_idx: 100 |  Loss: (0.1348) |  Loss2: (0.0000) | Acc: (95.00%) (12321/12928)
Epoch: 148 | Batch_idx: 110 |  Loss: (0.1345) |  Loss2: (0.0000) | Acc: (95.00%) (13550/14208)
Epoch: 148 | Batch_idx: 120 |  Loss: (0.1325) |  Loss2: (0.0000) | Acc: (95.00%) (14777/15488)
Epoch: 148 | Batch_idx: 130 |  Loss: (0.1328) |  Loss2: (0.0000) | Acc: (95.00%) (15992/16768)
Epoch: 148 | Batch_idx: 140 |  Loss: (0.1318) |  Loss2: (0.0000) | Acc: (95.00%) (17233/18048)
Epoch: 148 | Batch_idx: 150 |  Loss: (0.1314) |  Loss2: (0.0000) | Acc: (95.00%) (18463/19328)
Epoch: 148 | Batch_idx: 160 |  Loss: (0.1319) |  Loss2: (0.0000) | Acc: (95.00%) (19676/20608)
Epoch: 148 | Batch_idx: 170 |  Loss: (0.1309) |  Loss2: (0.0000) | Acc: (95.00%) (20903/21888)
Epoch: 148 | Batch_idx: 180 |  Loss: (0.1304) |  Loss2: (0.0000) | Acc: (95.00%) (22130/23168)
Epoch: 148 | Batch_idx: 190 |  Loss: (0.1298) |  Loss2: (0.0000) | Acc: (95.00%) (23353/24448)
Epoch: 148 | Batch_idx: 200 |  Loss: (0.1304) |  Loss2: (0.0000) | Acc: (95.00%) (24577/25728)
Epoch: 148 | Batch_idx: 210 |  Loss: (0.1300) |  Loss2: (0.0000) | Acc: (95.00%) (25802/27008)
Epoch: 148 | Batch_idx: 220 |  Loss: (0.1302) |  Loss2: (0.0000) | Acc: (95.00%) (27024/28288)
Epoch: 148 | Batch_idx: 230 |  Loss: (0.1303) |  Loss2: (0.0000) | Acc: (95.00%) (28242/29568)
Epoch: 148 | Batch_idx: 240 |  Loss: (0.1294) |  Loss2: (0.0000) | Acc: (95.00%) (29477/30848)
Epoch: 148 | Batch_idx: 250 |  Loss: (0.1301) |  Loss2: (0.0000) | Acc: (95.00%) (30690/32128)
Epoch: 148 | Batch_idx: 260 |  Loss: (0.1309) |  Loss2: (0.0000) | Acc: (95.00%) (31907/33408)
Epoch: 148 | Batch_idx: 270 |  Loss: (0.1314) |  Loss2: (0.0000) | Acc: (95.00%) (33127/34688)
Epoch: 148 | Batch_idx: 280 |  Loss: (0.1310) |  Loss2: (0.0000) | Acc: (95.00%) (34359/35968)
Epoch: 148 | Batch_idx: 290 |  Loss: (0.1313) |  Loss2: (0.0000) | Acc: (95.00%) (35577/37248)
Epoch: 148 | Batch_idx: 300 |  Loss: (0.1310) |  Loss2: (0.0000) | Acc: (95.00%) (36808/38528)
Epoch: 148 | Batch_idx: 310 |  Loss: (0.1312) |  Loss2: (0.0000) | Acc: (95.00%) (38031/39808)
Epoch: 148 | Batch_idx: 320 |  Loss: (0.1314) |  Loss2: (0.0000) | Acc: (95.00%) (39243/41088)
Epoch: 148 | Batch_idx: 330 |  Loss: (0.1310) |  Loss2: (0.0000) | Acc: (95.00%) (40472/42368)
Epoch: 148 | Batch_idx: 340 |  Loss: (0.1303) |  Loss2: (0.0000) | Acc: (95.00%) (41703/43648)
Epoch: 148 | Batch_idx: 350 |  Loss: (0.1300) |  Loss2: (0.0000) | Acc: (95.00%) (42938/44928)
Epoch: 148 | Batch_idx: 360 |  Loss: (0.1300) |  Loss2: (0.0000) | Acc: (95.00%) (44161/46208)
Epoch: 148 | Batch_idx: 370 |  Loss: (0.1295) |  Loss2: (0.0000) | Acc: (95.00%) (45381/47488)
Epoch: 148 | Batch_idx: 380 |  Loss: (0.1297) |  Loss2: (0.0000) | Acc: (95.00%) (46601/48768)
Epoch: 148 | Batch_idx: 390 |  Loss: (0.1296) |  Loss2: (0.0000) | Acc: (95.00%) (47782/50000)
# TEST : Loss: (0.4026) | Acc: (88.00%) (8820/10000)
percent tensor([0.5123, 0.5121, 0.5143, 0.5165, 0.5149, 0.5201, 0.5132, 0.5156, 0.5121,
        0.5116, 0.5112, 0.5125, 0.5111, 0.5140, 0.5146, 0.5141],
       device='cuda:0') torch.Size([16])
percent tensor([0.5080, 0.5125, 0.5047, 0.5052, 0.5023, 0.5165, 0.5070, 0.5008, 0.5056,
        0.5088, 0.5083, 0.5075, 0.5152, 0.5050, 0.5115, 0.5113],
       device='cuda:0') torch.Size([16])
percent tensor([0.5895, 0.5165, 0.6441, 0.6578, 0.6505, 0.6116, 0.5821, 0.6367, 0.6366,
        0.5728, 0.6061, 0.6006, 0.4892, 0.6485, 0.5661, 0.5899],
       device='cuda:0') torch.Size([16])
percent tensor([0.6274, 0.6225, 0.6186, 0.6175, 0.6222, 0.6218, 0.6292, 0.6226, 0.6239,
        0.6302, 0.6290, 0.6275, 0.6230, 0.6235, 0.6249, 0.6344],
       device='cuda:0') torch.Size([16])
percent tensor([0.6330, 0.5862, 0.6357, 0.6496, 0.6763, 0.7438, 0.6043, 0.6102, 0.6353,
        0.6359, 0.5988, 0.6049, 0.6151, 0.6399, 0.5988, 0.6823],
       device='cuda:0') torch.Size([16])
percent tensor([0.6145, 0.6806, 0.6716, 0.7137, 0.6724, 0.7608, 0.6790, 0.5467, 0.7174,
        0.6403, 0.7342, 0.6643, 0.7316, 0.7146, 0.5728, 0.6460],
       device='cuda:0') torch.Size([16])
percent tensor([0.6095, 0.6306, 0.6668, 0.6738, 0.6906, 0.6704, 0.6576, 0.6348, 0.6224,
        0.6496, 0.6646, 0.6048, 0.6251, 0.6002, 0.6060, 0.6000],
       device='cuda:0') torch.Size([16])
percent tensor([0.9999, 0.9997, 0.9998, 0.9998, 0.9995, 0.9988, 0.9997, 0.9997, 0.9998,
        0.9997, 0.9999, 0.9997, 0.9999, 0.9995, 0.9992, 0.9996],
       device='cuda:0') torch.Size([16])
Epoch: 149 | Batch_idx: 0 |  Loss: (0.1401) |  Loss2: (0.0000) | Acc: (96.00%) (123/128)
Epoch: 149 | Batch_idx: 10 |  Loss: (0.1019) |  Loss2: (0.0000) | Acc: (97.00%) (1368/1408)
Epoch: 149 | Batch_idx: 20 |  Loss: (0.1027) |  Loss2: (0.0000) | Acc: (97.00%) (2608/2688)
Epoch: 149 | Batch_idx: 30 |  Loss: (0.1131) |  Loss2: (0.0000) | Acc: (96.00%) (3821/3968)
Epoch: 149 | Batch_idx: 40 |  Loss: (0.1112) |  Loss2: (0.0000) | Acc: (96.00%) (5064/5248)
Epoch: 149 | Batch_idx: 50 |  Loss: (0.1166) |  Loss2: (0.0000) | Acc: (96.00%) (6284/6528)
Epoch: 149 | Batch_idx: 60 |  Loss: (0.1207) |  Loss2: (0.0000) | Acc: (96.00%) (7496/7808)
Epoch: 149 | Batch_idx: 70 |  Loss: (0.1234) |  Loss2: (0.0000) | Acc: (95.00%) (8715/9088)
Epoch: 149 | Batch_idx: 80 |  Loss: (0.1269) |  Loss2: (0.0000) | Acc: (95.00%) (9932/10368)
Epoch: 149 | Batch_idx: 90 |  Loss: (0.1292) |  Loss2: (0.0000) | Acc: (95.00%) (11151/11648)
Epoch: 149 | Batch_idx: 100 |  Loss: (0.1275) |  Loss2: (0.0000) | Acc: (95.00%) (12384/12928)
Epoch: 149 | Batch_idx: 110 |  Loss: (0.1260) |  Loss2: (0.0000) | Acc: (95.00%) (13614/14208)
Epoch: 149 | Batch_idx: 120 |  Loss: (0.1252) |  Loss2: (0.0000) | Acc: (95.00%) (14844/15488)
Epoch: 149 | Batch_idx: 130 |  Loss: (0.1246) |  Loss2: (0.0000) | Acc: (95.00%) (16072/16768)
Epoch: 149 | Batch_idx: 140 |  Loss: (0.1232) |  Loss2: (0.0000) | Acc: (95.00%) (17304/18048)
Epoch: 149 | Batch_idx: 150 |  Loss: (0.1215) |  Loss2: (0.0000) | Acc: (95.00%) (18541/19328)
Epoch: 149 | Batch_idx: 160 |  Loss: (0.1203) |  Loss2: (0.0000) | Acc: (96.00%) (19784/20608)
Epoch: 149 | Batch_idx: 170 |  Loss: (0.1207) |  Loss2: (0.0000) | Acc: (95.00%) (21004/21888)
Epoch: 149 | Batch_idx: 180 |  Loss: (0.1202) |  Loss2: (0.0000) | Acc: (95.00%) (22231/23168)
Epoch: 149 | Batch_idx: 190 |  Loss: (0.1214) |  Loss2: (0.0000) | Acc: (95.00%) (23449/24448)
Epoch: 149 | Batch_idx: 200 |  Loss: (0.1229) |  Loss2: (0.0000) | Acc: (95.00%) (24659/25728)
Epoch: 149 | Batch_idx: 210 |  Loss: (0.1232) |  Loss2: (0.0000) | Acc: (95.00%) (25888/27008)
Epoch: 149 | Batch_idx: 220 |  Loss: (0.1246) |  Loss2: (0.0000) | Acc: (95.00%) (27099/28288)
Epoch: 149 | Batch_idx: 230 |  Loss: (0.1251) |  Loss2: (0.0000) | Acc: (95.00%) (28319/29568)
Epoch: 149 | Batch_idx: 240 |  Loss: (0.1256) |  Loss2: (0.0000) | Acc: (95.00%) (29533/30848)
Epoch: 149 | Batch_idx: 250 |  Loss: (0.1257) |  Loss2: (0.0000) | Acc: (95.00%) (30755/32128)
Epoch: 149 | Batch_idx: 260 |  Loss: (0.1265) |  Loss2: (0.0000) | Acc: (95.00%) (31958/33408)
Epoch: 149 | Batch_idx: 270 |  Loss: (0.1268) |  Loss2: (0.0000) | Acc: (95.00%) (33178/34688)
Epoch: 149 | Batch_idx: 280 |  Loss: (0.1264) |  Loss2: (0.0000) | Acc: (95.00%) (34402/35968)
Epoch: 149 | Batch_idx: 290 |  Loss: (0.1266) |  Loss2: (0.0000) | Acc: (95.00%) (35623/37248)
Epoch: 149 | Batch_idx: 300 |  Loss: (0.1269) |  Loss2: (0.0000) | Acc: (95.00%) (36840/38528)
Epoch: 149 | Batch_idx: 310 |  Loss: (0.1270) |  Loss2: (0.0000) | Acc: (95.00%) (38056/39808)
Epoch: 149 | Batch_idx: 320 |  Loss: (0.1269) |  Loss2: (0.0000) | Acc: (95.00%) (39286/41088)
Epoch: 149 | Batch_idx: 330 |  Loss: (0.1272) |  Loss2: (0.0000) | Acc: (95.00%) (40510/42368)
Epoch: 149 | Batch_idx: 340 |  Loss: (0.1280) |  Loss2: (0.0000) | Acc: (95.00%) (41722/43648)
Epoch: 149 | Batch_idx: 350 |  Loss: (0.1288) |  Loss2: (0.0000) | Acc: (95.00%) (42936/44928)
Epoch: 149 | Batch_idx: 360 |  Loss: (0.1284) |  Loss2: (0.0000) | Acc: (95.00%) (44165/46208)
Epoch: 149 | Batch_idx: 370 |  Loss: (0.1287) |  Loss2: (0.0000) | Acc: (95.00%) (45381/47488)
Epoch: 149 | Batch_idx: 380 |  Loss: (0.1282) |  Loss2: (0.0000) | Acc: (95.00%) (46618/48768)
Epoch: 149 | Batch_idx: 390 |  Loss: (0.1286) |  Loss2: (0.0000) | Acc: (95.00%) (47791/50000)
# TEST : Loss: (0.4295) | Acc: (87.00%) (8743/10000)
percent tensor([0.5122, 0.5128, 0.5128, 0.5165, 0.5138, 0.5200, 0.5137, 0.5150, 0.5123,
        0.5116, 0.5117, 0.5117, 0.5111, 0.5156, 0.5150, 0.5144],
       device='cuda:0') torch.Size([16])
percent tensor([0.5089, 0.5113, 0.5056, 0.5071, 0.5043, 0.5172, 0.5063, 0.5020, 0.5059,
        0.5081, 0.5069, 0.5093, 0.5156, 0.5036, 0.5118, 0.5121],
       device='cuda:0') torch.Size([16])
percent tensor([0.5887, 0.5344, 0.6393, 0.6611, 0.6503, 0.6115, 0.5943, 0.6367, 0.6321,
        0.5848, 0.6126, 0.5912, 0.4894, 0.6642, 0.5767, 0.5961],
       device='cuda:0') torch.Size([16])
percent tensor([0.6251, 0.6212, 0.6157, 0.6172, 0.6219, 0.6210, 0.6274, 0.6233, 0.6223,
        0.6284, 0.6281, 0.6238, 0.6207, 0.6213, 0.6249, 0.6331],
       device='cuda:0') torch.Size([16])
percent tensor([0.6521, 0.6060, 0.6633, 0.6887, 0.7075, 0.7617, 0.6204, 0.6351, 0.6506,
        0.6529, 0.6149, 0.6287, 0.6308, 0.6513, 0.6287, 0.7095],
       device='cuda:0') torch.Size([16])
percent tensor([0.6243, 0.6903, 0.6623, 0.7118, 0.6644, 0.7625, 0.6882, 0.5467, 0.7299,
        0.6582, 0.7501, 0.6631, 0.7388, 0.7363, 0.5779, 0.6746],
       device='cuda:0') torch.Size([16])
percent tensor([0.6163, 0.6372, 0.6303, 0.6664, 0.6782, 0.6627, 0.6655, 0.6322, 0.6348,
        0.6456, 0.6698, 0.5978, 0.6223, 0.6246, 0.5959, 0.6224],
       device='cuda:0') torch.Size([16])
percent tensor([0.9999, 0.9996, 0.9996, 0.9998, 0.9996, 0.9994, 0.9997, 0.9994, 0.9998,
        0.9997, 0.9999, 0.9996, 0.9999, 0.9995, 0.9990, 0.9997],
       device='cuda:0') torch.Size([16])
False Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=128, out_features=16, bias=False)
True Linear(in_features=16, out_features=2, bias=False)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=128, out_features=16, bias=False)
True Linear(in_features=16, out_features=2, bias=False)
False Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=256, out_features=32, bias=False)
True Linear(in_features=32, out_features=2, bias=False)
False Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=256, out_features=32, bias=False)
True Linear(in_features=32, out_features=2, bias=False)
False Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=512, out_features=64, bias=False)
True Linear(in_features=64, out_features=2, bias=False)
False Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=512, out_features=64, bias=False)
True Linear(in_features=64, out_features=2, bias=False)
False Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1024, out_features=128, bias=False)
True Linear(in_features=128, out_features=2, bias=False)
False Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1024, out_features=128, bias=False)
True Linear(in_features=128, out_features=2, bias=False)
False Linear(in_features=512, out_features=10, bias=True)
Epoch: 150 | Batch_idx: 0 |  Loss: (0.0735) |  Loss2: (0.0000) | Acc: (98.00%) (126/128)
Epoch: 150 | Batch_idx: 10 |  Loss: (0.0988) |  Loss2: (0.0000) | Acc: (96.00%) (1364/1408)
Epoch: 150 | Batch_idx: 20 |  Loss: (0.1303) |  Loss2: (0.0000) | Acc: (95.00%) (2565/2688)
Epoch: 150 | Batch_idx: 30 |  Loss: (0.1340) |  Loss2: (0.0000) | Acc: (95.00%) (3788/3968)
Epoch: 150 | Batch_idx: 40 |  Loss: (0.1514) |  Loss2: (0.0000) | Acc: (95.00%) (4986/5248)
Epoch: 150 | Batch_idx: 50 |  Loss: (0.1508) |  Loss2: (0.0000) | Acc: (94.00%) (6193/6528)
Epoch: 150 | Batch_idx: 60 |  Loss: (0.1508) |  Loss2: (0.0000) | Acc: (94.00%) (7393/7808)
Epoch: 150 | Batch_idx: 70 |  Loss: (0.1519) |  Loss2: (0.0000) | Acc: (94.00%) (8600/9088)
Epoch: 150 | Batch_idx: 80 |  Loss: (0.1541) |  Loss2: (0.0000) | Acc: (94.00%) (9792/10368)
Epoch: 150 | Batch_idx: 90 |  Loss: (0.1542) |  Loss2: (0.0000) | Acc: (94.00%) (11000/11648)
Epoch: 150 | Batch_idx: 100 |  Loss: (0.1543) |  Loss2: (0.0000) | Acc: (94.00%) (12206/12928)
Epoch: 150 | Batch_idx: 110 |  Loss: (0.1569) |  Loss2: (0.0000) | Acc: (94.00%) (13403/14208)
Epoch: 150 | Batch_idx: 120 |  Loss: (0.1582) |  Loss2: (0.0000) | Acc: (94.00%) (14608/15488)
Epoch: 150 | Batch_idx: 130 |  Loss: (0.1594) |  Loss2: (0.0000) | Acc: (94.00%) (15810/16768)
Epoch: 150 | Batch_idx: 140 |  Loss: (0.1584) |  Loss2: (0.0000) | Acc: (94.00%) (17022/18048)
Epoch: 150 | Batch_idx: 150 |  Loss: (0.1584) |  Loss2: (0.0000) | Acc: (94.00%) (18224/19328)
Epoch: 150 | Batch_idx: 160 |  Loss: (0.1576) |  Loss2: (0.0000) | Acc: (94.00%) (19430/20608)
Epoch: 150 | Batch_idx: 170 |  Loss: (0.1577) |  Loss2: (0.0000) | Acc: (94.00%) (20633/21888)
Epoch: 150 | Batch_idx: 180 |  Loss: (0.1582) |  Loss2: (0.0000) | Acc: (94.00%) (21837/23168)
Epoch: 150 | Batch_idx: 190 |  Loss: (0.1582) |  Loss2: (0.0000) | Acc: (94.00%) (23042/24448)
Epoch: 150 | Batch_idx: 200 |  Loss: (0.1584) |  Loss2: (0.0000) | Acc: (94.00%) (24249/25728)
Epoch: 150 | Batch_idx: 210 |  Loss: (0.1578) |  Loss2: (0.0000) | Acc: (94.00%) (25460/27008)
Epoch: 150 | Batch_idx: 220 |  Loss: (0.1581) |  Loss2: (0.0000) | Acc: (94.00%) (26663/28288)
Epoch: 150 | Batch_idx: 230 |  Loss: (0.1586) |  Loss2: (0.0000) | Acc: (94.00%) (27861/29568)
Epoch: 150 | Batch_idx: 240 |  Loss: (0.1584) |  Loss2: (0.0000) | Acc: (94.00%) (29071/30848)
Epoch: 150 | Batch_idx: 250 |  Loss: (0.1582) |  Loss2: (0.0000) | Acc: (94.00%) (30283/32128)
Epoch: 150 | Batch_idx: 260 |  Loss: (0.1575) |  Loss2: (0.0000) | Acc: (94.00%) (31487/33408)
Epoch: 150 | Batch_idx: 270 |  Loss: (0.1569) |  Loss2: (0.0000) | Acc: (94.00%) (32700/34688)
Epoch: 150 | Batch_idx: 280 |  Loss: (0.1569) |  Loss2: (0.0000) | Acc: (94.00%) (33911/35968)
Epoch: 150 | Batch_idx: 290 |  Loss: (0.1566) |  Loss2: (0.0000) | Acc: (94.00%) (35126/37248)
Epoch: 150 | Batch_idx: 300 |  Loss: (0.1565) |  Loss2: (0.0000) | Acc: (94.00%) (36336/38528)
Epoch: 150 | Batch_idx: 310 |  Loss: (0.1564) |  Loss2: (0.0000) | Acc: (94.00%) (37540/39808)
Epoch: 150 | Batch_idx: 320 |  Loss: (0.1561) |  Loss2: (0.0000) | Acc: (94.00%) (38755/41088)
Epoch: 150 | Batch_idx: 330 |  Loss: (0.1555) |  Loss2: (0.0000) | Acc: (94.00%) (39970/42368)
Epoch: 150 | Batch_idx: 340 |  Loss: (0.1551) |  Loss2: (0.0000) | Acc: (94.00%) (41194/43648)
Epoch: 150 | Batch_idx: 350 |  Loss: (0.1546) |  Loss2: (0.0000) | Acc: (94.00%) (42408/44928)
Epoch: 150 | Batch_idx: 360 |  Loss: (0.1545) |  Loss2: (0.0000) | Acc: (94.00%) (43614/46208)
Epoch: 150 | Batch_idx: 370 |  Loss: (0.1550) |  Loss2: (0.0000) | Acc: (94.00%) (44813/47488)
Epoch: 150 | Batch_idx: 380 |  Loss: (0.1551) |  Loss2: (0.0000) | Acc: (94.00%) (46012/48768)
Epoch: 150 | Batch_idx: 390 |  Loss: (0.1551) |  Loss2: (0.0000) | Acc: (94.00%) (47178/50000)
=> saving checkpoint 'drive/app/torch/save_Schedule/checkpoint_150.pth.tar'
# TEST : Loss: (0.4090) | Acc: (87.00%) (8782/10000)
percent tensor([0.5137, 0.5150, 0.5152, 0.5181, 0.5161, 0.5206, 0.5162, 0.5175, 0.5138,
        0.5141, 0.5133, 0.5143, 0.5131, 0.5171, 0.5164, 0.5160],
       device='cuda:0') torch.Size([16])
percent tensor([0.5102, 0.5137, 0.5069, 0.5076, 0.5058, 0.5185, 0.5081, 0.5027, 0.5067,
        0.5106, 0.5085, 0.5109, 0.5176, 0.5037, 0.5143, 0.5134],
       device='cuda:0') torch.Size([16])
percent tensor([0.5916, 0.5374, 0.6487, 0.6713, 0.6596, 0.6086, 0.5987, 0.6456, 0.6404,
        0.5894, 0.6179, 0.5948, 0.4931, 0.6682, 0.5771, 0.5983],
       device='cuda:0') torch.Size([16])
percent tensor([0.6284, 0.6241, 0.6197, 0.6216, 0.6256, 0.6268, 0.6293, 0.6258, 0.6266,
        0.6330, 0.6330, 0.6286, 0.6251, 0.6239, 0.6288, 0.6374],
       device='cuda:0') torch.Size([16])
percent tensor([0.6474, 0.6328, 0.6364, 0.6629, 0.6820, 0.7618, 0.6251, 0.6159, 0.6502,
        0.6731, 0.6344, 0.6207, 0.6431, 0.6517, 0.6424, 0.7125],
       device='cuda:0') torch.Size([16])
percent tensor([0.6227, 0.6909, 0.6528, 0.7076, 0.6639, 0.7607, 0.6851, 0.5567, 0.7231,
        0.6490, 0.7474, 0.6447, 0.7269, 0.7342, 0.5698, 0.6804],
       device='cuda:0') torch.Size([16])
percent tensor([0.5923, 0.6161, 0.6230, 0.6662, 0.6783, 0.6426, 0.6609, 0.6382, 0.6120,
        0.6265, 0.6382, 0.5782, 0.5904, 0.6144, 0.5831, 0.6061],
       device='cuda:0') torch.Size([16])
percent tensor([0.9999, 0.9996, 0.9997, 0.9998, 0.9996, 0.9995, 0.9997, 0.9995, 0.9998,
        0.9997, 0.9999, 0.9997, 0.9999, 0.9995, 0.9991, 0.9997],
       device='cuda:0') torch.Size([16])
Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 3, 3, 3]) tensor(180.1815, device='cuda:0')
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(828.7075, device='cuda:0')
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(825.5151, device='cuda:0')
Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([128, 64, 3, 3]) tensor(1518.1389, device='cuda:0')
Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([128, 64, 1, 1]) tensor(486.4873, device='cuda:0')
Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([128, 128, 3, 3]) tensor(2275.9060, device='cuda:0')
Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([256, 128, 3, 3]) tensor(4269.5547, device='cuda:0')
Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([256, 128, 1, 1]) tensor(1370.1315, device='cuda:0')
Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([256, 256, 3, 3]) tensor(6234.3735, device='cuda:0')
Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([512, 256, 3, 3]) tensor(11692.5586, device='cuda:0')
Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([512, 256, 1, 1]) tensor(3858.0374, device='cuda:0')
Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([512, 512, 3, 3]) tensor(16317.6318, device='cuda:0')
Epoch: 151 | Batch_idx: 0 |  Loss: (0.1102) |  Loss2: (0.0000) | Acc: (97.00%) (125/128)
Epoch: 151 | Batch_idx: 10 |  Loss: (0.1297) |  Loss2: (0.0000) | Acc: (95.00%) (1344/1408)
Epoch: 151 | Batch_idx: 20 |  Loss: (0.1278) |  Loss2: (0.0000) | Acc: (95.00%) (2570/2688)
Epoch: 151 | Batch_idx: 30 |  Loss: (0.1335) |  Loss2: (0.0000) | Acc: (95.00%) (3779/3968)
Epoch: 151 | Batch_idx: 40 |  Loss: (0.1370) |  Loss2: (0.0000) | Acc: (95.00%) (4995/5248)
Epoch: 151 | Batch_idx: 50 |  Loss: (0.1371) |  Loss2: (0.0000) | Acc: (95.00%) (6210/6528)
Epoch: 151 | Batch_idx: 60 |  Loss: (0.1386) |  Loss2: (0.0000) | Acc: (95.00%) (7420/7808)
Epoch: 151 | Batch_idx: 70 |  Loss: (0.1397) |  Loss2: (0.0000) | Acc: (95.00%) (8637/9088)
Epoch: 151 | Batch_idx: 80 |  Loss: (0.1420) |  Loss2: (0.0000) | Acc: (94.00%) (9845/10368)
Epoch: 151 | Batch_idx: 90 |  Loss: (0.1423) |  Loss2: (0.0000) | Acc: (94.00%) (11059/11648)
Epoch: 151 | Batch_idx: 100 |  Loss: (0.1397) |  Loss2: (0.0000) | Acc: (95.00%) (12286/12928)
Epoch: 151 | Batch_idx: 110 |  Loss: (0.1381) |  Loss2: (0.0000) | Acc: (95.00%) (13520/14208)
Epoch: 151 | Batch_idx: 120 |  Loss: (0.1365) |  Loss2: (0.0000) | Acc: (95.00%) (14747/15488)
Epoch: 151 | Batch_idx: 130 |  Loss: (0.1357) |  Loss2: (0.0000) | Acc: (95.00%) (15975/16768)
Epoch: 151 | Batch_idx: 140 |  Loss: (0.1381) |  Loss2: (0.0000) | Acc: (95.00%) (17183/18048)
Epoch: 151 | Batch_idx: 150 |  Loss: (0.1380) |  Loss2: (0.0000) | Acc: (95.00%) (18404/19328)
Epoch: 151 | Batch_idx: 160 |  Loss: (0.1385) |  Loss2: (0.0000) | Acc: (95.00%) (19616/20608)
Epoch: 151 | Batch_idx: 170 |  Loss: (0.1390) |  Loss2: (0.0000) | Acc: (95.00%) (20833/21888)
Epoch: 151 | Batch_idx: 180 |  Loss: (0.1388) |  Loss2: (0.0000) | Acc: (95.00%) (22048/23168)
Epoch: 151 | Batch_idx: 190 |  Loss: (0.1394) |  Loss2: (0.0000) | Acc: (95.00%) (23257/24448)
Epoch: 151 | Batch_idx: 200 |  Loss: (0.1392) |  Loss2: (0.0000) | Acc: (95.00%) (24483/25728)
Epoch: 151 | Batch_idx: 210 |  Loss: (0.1392) |  Loss2: (0.0000) | Acc: (95.00%) (25694/27008)
Epoch: 151 | Batch_idx: 220 |  Loss: (0.1383) |  Loss2: (0.0000) | Acc: (95.00%) (26913/28288)
Epoch: 151 | Batch_idx: 230 |  Loss: (0.1387) |  Loss2: (0.0000) | Acc: (95.00%) (28127/29568)
Epoch: 151 | Batch_idx: 240 |  Loss: (0.1393) |  Loss2: (0.0000) | Acc: (95.00%) (29340/30848)
Epoch: 151 | Batch_idx: 250 |  Loss: (0.1397) |  Loss2: (0.0000) | Acc: (95.00%) (30553/32128)
Epoch: 151 | Batch_idx: 260 |  Loss: (0.1389) |  Loss2: (0.0000) | Acc: (95.00%) (31785/33408)
Epoch: 151 | Batch_idx: 270 |  Loss: (0.1399) |  Loss2: (0.0000) | Acc: (95.00%) (32987/34688)
Epoch: 151 | Batch_idx: 280 |  Loss: (0.1396) |  Loss2: (0.0000) | Acc: (95.00%) (34204/35968)
Epoch: 151 | Batch_idx: 290 |  Loss: (0.1396) |  Loss2: (0.0000) | Acc: (95.00%) (35424/37248)
Epoch: 151 | Batch_idx: 300 |  Loss: (0.1393) |  Loss2: (0.0000) | Acc: (95.00%) (36651/38528)
Epoch: 151 | Batch_idx: 310 |  Loss: (0.1384) |  Loss2: (0.0000) | Acc: (95.00%) (37877/39808)
Epoch: 151 | Batch_idx: 320 |  Loss: (0.1380) |  Loss2: (0.0000) | Acc: (95.00%) (39098/41088)
Epoch: 151 | Batch_idx: 330 |  Loss: (0.1376) |  Loss2: (0.0000) | Acc: (95.00%) (40323/42368)
Epoch: 151 | Batch_idx: 340 |  Loss: (0.1380) |  Loss2: (0.0000) | Acc: (95.00%) (41531/43648)
Epoch: 151 | Batch_idx: 350 |  Loss: (0.1380) |  Loss2: (0.0000) | Acc: (95.00%) (42750/44928)
Epoch: 151 | Batch_idx: 360 |  Loss: (0.1376) |  Loss2: (0.0000) | Acc: (95.00%) (43968/46208)
Epoch: 151 | Batch_idx: 370 |  Loss: (0.1376) |  Loss2: (0.0000) | Acc: (95.00%) (45183/47488)
Epoch: 151 | Batch_idx: 380 |  Loss: (0.1375) |  Loss2: (0.0000) | Acc: (95.00%) (46408/48768)
Epoch: 151 | Batch_idx: 390 |  Loss: (0.1380) |  Loss2: (0.0000) | Acc: (95.00%) (47577/50000)
# TEST : Loss: (0.3949) | Acc: (88.00%) (8814/10000)
percent tensor([0.5144, 0.5162, 0.5167, 0.5191, 0.5175, 0.5204, 0.5176, 0.5190, 0.5148,
        0.5156, 0.5141, 0.5159, 0.5140, 0.5180, 0.5169, 0.5166],
       device='cuda:0') torch.Size([16])
percent tensor([0.5138, 0.5193, 0.5107, 0.5109, 0.5093, 0.5207, 0.5129, 0.5061, 0.5106,
        0.5159, 0.5132, 0.5155, 0.5222, 0.5080, 0.5185, 0.5175],
       device='cuda:0') torch.Size([16])
percent tensor([0.5953, 0.5400, 0.6543, 0.6756, 0.6639, 0.6101, 0.6009, 0.6473, 0.6429,
        0.5929, 0.6202, 0.6010, 0.4981, 0.6685, 0.5796, 0.5999],
       device='cuda:0') torch.Size([16])
percent tensor([0.6300, 0.6259, 0.6207, 0.6229, 0.6264, 0.6298, 0.6299, 0.6261, 0.6275,
        0.6349, 0.6352, 0.6299, 0.6267, 0.6251, 0.6304, 0.6398],
       device='cuda:0') torch.Size([16])
percent tensor([0.6468, 0.6352, 0.6247, 0.6548, 0.6728, 0.7627, 0.6211, 0.6041, 0.6496,
        0.6787, 0.6400, 0.6176, 0.6447, 0.6502, 0.6407, 0.7166],
       device='cuda:0') torch.Size([16])
percent tensor([0.6125, 0.6751, 0.6488, 0.7021, 0.6585, 0.7541, 0.6732, 0.5506, 0.7166,
        0.6358, 0.7376, 0.6331, 0.7165, 0.7222, 0.5547, 0.6686],
       device='cuda:0') torch.Size([16])
percent tensor([0.5878, 0.6153, 0.6253, 0.6700, 0.6815, 0.6384, 0.6605, 0.6434, 0.6125,
        0.6238, 0.6386, 0.5829, 0.5886, 0.6169, 0.5858, 0.6005],
       device='cuda:0') torch.Size([16])
percent tensor([0.9999, 0.9996, 0.9996, 0.9998, 0.9996, 0.9995, 0.9997, 0.9995, 0.9998,
        0.9997, 0.9999, 0.9997, 0.9999, 0.9995, 0.9991, 0.9997],
       device='cuda:0') torch.Size([16])
Epoch: 152 | Batch_idx: 0 |  Loss: (0.1623) |  Loss2: (0.0000) | Acc: (96.00%) (123/128)
Epoch: 152 | Batch_idx: 10 |  Loss: (0.1217) |  Loss2: (0.0000) | Acc: (95.00%) (1343/1408)
Epoch: 152 | Batch_idx: 20 |  Loss: (0.1173) |  Loss2: (0.0000) | Acc: (95.00%) (2571/2688)
Epoch: 152 | Batch_idx: 30 |  Loss: (0.1197) |  Loss2: (0.0000) | Acc: (95.00%) (3795/3968)
Epoch: 152 | Batch_idx: 40 |  Loss: (0.1241) |  Loss2: (0.0000) | Acc: (95.00%) (5010/5248)
Epoch: 152 | Batch_idx: 50 |  Loss: (0.1292) |  Loss2: (0.0000) | Acc: (95.00%) (6226/6528)
Epoch: 152 | Batch_idx: 60 |  Loss: (0.1275) |  Loss2: (0.0000) | Acc: (95.00%) (7455/7808)
Epoch: 152 | Batch_idx: 70 |  Loss: (0.1308) |  Loss2: (0.0000) | Acc: (95.00%) (8670/9088)
Epoch: 152 | Batch_idx: 80 |  Loss: (0.1305) |  Loss2: (0.0000) | Acc: (95.00%) (9891/10368)
Epoch: 152 | Batch_idx: 90 |  Loss: (0.1317) |  Loss2: (0.0000) | Acc: (95.00%) (11110/11648)
Epoch: 152 | Batch_idx: 100 |  Loss: (0.1309) |  Loss2: (0.0000) | Acc: (95.00%) (12333/12928)
Epoch: 152 | Batch_idx: 110 |  Loss: (0.1303) |  Loss2: (0.0000) | Acc: (95.00%) (13553/14208)
Epoch: 152 | Batch_idx: 120 |  Loss: (0.1305) |  Loss2: (0.0000) | Acc: (95.00%) (14771/15488)
Epoch: 152 | Batch_idx: 130 |  Loss: (0.1319) |  Loss2: (0.0000) | Acc: (95.00%) (15995/16768)
Epoch: 152 | Batch_idx: 140 |  Loss: (0.1328) |  Loss2: (0.0000) | Acc: (95.00%) (17214/18048)
Epoch: 152 | Batch_idx: 150 |  Loss: (0.1316) |  Loss2: (0.0000) | Acc: (95.00%) (18451/19328)
Epoch: 152 | Batch_idx: 160 |  Loss: (0.1321) |  Loss2: (0.0000) | Acc: (95.00%) (19663/20608)
Epoch: 152 | Batch_idx: 170 |  Loss: (0.1312) |  Loss2: (0.0000) | Acc: (95.00%) (20893/21888)
Epoch: 152 | Batch_idx: 180 |  Loss: (0.1306) |  Loss2: (0.0000) | Acc: (95.00%) (22122/23168)
Epoch: 152 | Batch_idx: 190 |  Loss: (0.1302) |  Loss2: (0.0000) | Acc: (95.00%) (23345/24448)
Epoch: 152 | Batch_idx: 200 |  Loss: (0.1309) |  Loss2: (0.0000) | Acc: (95.00%) (24557/25728)
Epoch: 152 | Batch_idx: 210 |  Loss: (0.1300) |  Loss2: (0.0000) | Acc: (95.00%) (25790/27008)
Epoch: 152 | Batch_idx: 220 |  Loss: (0.1297) |  Loss2: (0.0000) | Acc: (95.00%) (27011/28288)
Epoch: 152 | Batch_idx: 230 |  Loss: (0.1302) |  Loss2: (0.0000) | Acc: (95.00%) (28228/29568)
Epoch: 152 | Batch_idx: 240 |  Loss: (0.1295) |  Loss2: (0.0000) | Acc: (95.00%) (29459/30848)
Epoch: 152 | Batch_idx: 250 |  Loss: (0.1301) |  Loss2: (0.0000) | Acc: (95.00%) (30669/32128)
Epoch: 152 | Batch_idx: 260 |  Loss: (0.1309) |  Loss2: (0.0000) | Acc: (95.00%) (31870/33408)
Epoch: 152 | Batch_idx: 270 |  Loss: (0.1303) |  Loss2: (0.0000) | Acc: (95.00%) (33101/34688)
Epoch: 152 | Batch_idx: 280 |  Loss: (0.1305) |  Loss2: (0.0000) | Acc: (95.00%) (34315/35968)
Epoch: 152 | Batch_idx: 290 |  Loss: (0.1308) |  Loss2: (0.0000) | Acc: (95.00%) (35530/37248)
Epoch: 152 | Batch_idx: 300 |  Loss: (0.1307) |  Loss2: (0.0000) | Acc: (95.00%) (36759/38528)
Epoch: 152 | Batch_idx: 310 |  Loss: (0.1310) |  Loss2: (0.0000) | Acc: (95.00%) (37983/39808)
Epoch: 152 | Batch_idx: 320 |  Loss: (0.1311) |  Loss2: (0.0000) | Acc: (95.00%) (39198/41088)
Epoch: 152 | Batch_idx: 330 |  Loss: (0.1305) |  Loss2: (0.0000) | Acc: (95.00%) (40423/42368)
Epoch: 152 | Batch_idx: 340 |  Loss: (0.1303) |  Loss2: (0.0000) | Acc: (95.00%) (41647/43648)
Epoch: 152 | Batch_idx: 350 |  Loss: (0.1297) |  Loss2: (0.0000) | Acc: (95.00%) (42879/44928)
Epoch: 152 | Batch_idx: 360 |  Loss: (0.1299) |  Loss2: (0.0000) | Acc: (95.00%) (44092/46208)
Epoch: 152 | Batch_idx: 370 |  Loss: (0.1297) |  Loss2: (0.0000) | Acc: (95.00%) (45310/47488)
Epoch: 152 | Batch_idx: 380 |  Loss: (0.1295) |  Loss2: (0.0000) | Acc: (95.00%) (46537/48768)
Epoch: 152 | Batch_idx: 390 |  Loss: (0.1295) |  Loss2: (0.0000) | Acc: (95.00%) (47715/50000)
# TEST : Loss: (0.3840) | Acc: (88.00%) (8829/10000)
percent tensor([0.5150, 0.5171, 0.5178, 0.5197, 0.5185, 0.5204, 0.5186, 0.5202, 0.5154,
        0.5165, 0.5146, 0.5169, 0.5147, 0.5185, 0.5175, 0.5171],
       device='cuda:0') torch.Size([16])
percent tensor([0.5143, 0.5205, 0.5111, 0.5108, 0.5093, 0.5210, 0.5137, 0.5060, 0.5112,
        0.5170, 0.5141, 0.5163, 0.5234, 0.5085, 0.5191, 0.5181],
       device='cuda:0') torch.Size([16])
percent tensor([0.5951, 0.5399, 0.6549, 0.6749, 0.6640, 0.6056, 0.6013, 0.6476, 0.6417,
        0.5922, 0.6190, 0.6017, 0.4980, 0.6669, 0.5783, 0.5975],
       device='cuda:0') torch.Size([16])
percent tensor([0.6340, 0.6295, 0.6244, 0.6265, 0.6296, 0.6341, 0.6330, 0.6289, 0.6310,
        0.6389, 0.6391, 0.6337, 0.6305, 0.6287, 0.6340, 0.6443],
       device='cuda:0') torch.Size([16])
percent tensor([0.6465, 0.6357, 0.6209, 0.6510, 0.6695, 0.7648, 0.6179, 0.5958, 0.6476,
        0.6797, 0.6429, 0.6129, 0.6436, 0.6477, 0.6386, 0.7188],
       device='cuda:0') torch.Size([16])
percent tensor([0.6177, 0.6795, 0.6548, 0.7063, 0.6641, 0.7602, 0.6788, 0.5547, 0.7212,
        0.6401, 0.7433, 0.6360, 0.7224, 0.7279, 0.5559, 0.6754],
       device='cuda:0') torch.Size([16])
percent tensor([0.5810, 0.6156, 0.6219, 0.6708, 0.6799, 0.6418, 0.6558, 0.6390, 0.6100,
        0.6176, 0.6405, 0.5790, 0.5906, 0.6194, 0.5820, 0.5963],
       device='cuda:0') torch.Size([16])
percent tensor([0.9999, 0.9996, 0.9996, 0.9998, 0.9996, 0.9995, 0.9997, 0.9994, 0.9998,
        0.9998, 0.9998, 0.9997, 0.9999, 0.9995, 0.9991, 0.9997],
       device='cuda:0') torch.Size([16])
Epoch: 153 | Batch_idx: 0 |  Loss: (0.1807) |  Loss2: (0.0000) | Acc: (89.00%) (115/128)
Epoch: 153 | Batch_idx: 10 |  Loss: (0.1315) |  Loss2: (0.0000) | Acc: (95.00%) (1340/1408)
Epoch: 153 | Batch_idx: 20 |  Loss: (0.1253) |  Loss2: (0.0000) | Acc: (95.00%) (2565/2688)
Epoch: 153 | Batch_idx: 30 |  Loss: (0.1254) |  Loss2: (0.0000) | Acc: (95.00%) (3794/3968)
Epoch: 153 | Batch_idx: 40 |  Loss: (0.1237) |  Loss2: (0.0000) | Acc: (95.00%) (5018/5248)
Epoch: 153 | Batch_idx: 50 |  Loss: (0.1207) |  Loss2: (0.0000) | Acc: (95.00%) (6252/6528)
Epoch: 153 | Batch_idx: 60 |  Loss: (0.1209) |  Loss2: (0.0000) | Acc: (95.00%) (7475/7808)
Epoch: 153 | Batch_idx: 70 |  Loss: (0.1263) |  Loss2: (0.0000) | Acc: (95.00%) (8682/9088)
Epoch: 153 | Batch_idx: 80 |  Loss: (0.1270) |  Loss2: (0.0000) | Acc: (95.00%) (9907/10368)
Epoch: 153 | Batch_idx: 90 |  Loss: (0.1273) |  Loss2: (0.0000) | Acc: (95.00%) (11119/11648)
Epoch: 153 | Batch_idx: 100 |  Loss: (0.1265) |  Loss2: (0.0000) | Acc: (95.00%) (12343/12928)
Epoch: 153 | Batch_idx: 110 |  Loss: (0.1287) |  Loss2: (0.0000) | Acc: (95.00%) (13555/14208)
Epoch: 153 | Batch_idx: 120 |  Loss: (0.1297) |  Loss2: (0.0000) | Acc: (95.00%) (14774/15488)
Epoch: 153 | Batch_idx: 130 |  Loss: (0.1294) |  Loss2: (0.0000) | Acc: (95.00%) (16003/16768)
Epoch: 153 | Batch_idx: 140 |  Loss: (0.1311) |  Loss2: (0.0000) | Acc: (95.00%) (17212/18048)
Epoch: 153 | Batch_idx: 150 |  Loss: (0.1298) |  Loss2: (0.0000) | Acc: (95.00%) (18442/19328)
Epoch: 153 | Batch_idx: 160 |  Loss: (0.1303) |  Loss2: (0.0000) | Acc: (95.00%) (19665/20608)
Epoch: 153 | Batch_idx: 170 |  Loss: (0.1304) |  Loss2: (0.0000) | Acc: (95.00%) (20880/21888)
Epoch: 153 | Batch_idx: 180 |  Loss: (0.1299) |  Loss2: (0.0000) | Acc: (95.00%) (22116/23168)
Epoch: 153 | Batch_idx: 190 |  Loss: (0.1291) |  Loss2: (0.0000) | Acc: (95.00%) (23349/24448)
Epoch: 153 | Batch_idx: 200 |  Loss: (0.1282) |  Loss2: (0.0000) | Acc: (95.00%) (24580/25728)
Epoch: 153 | Batch_idx: 210 |  Loss: (0.1287) |  Loss2: (0.0000) | Acc: (95.00%) (25800/27008)
Epoch: 153 | Batch_idx: 220 |  Loss: (0.1287) |  Loss2: (0.0000) | Acc: (95.00%) (27025/28288)
Epoch: 153 | Batch_idx: 230 |  Loss: (0.1285) |  Loss2: (0.0000) | Acc: (95.00%) (28252/29568)
Epoch: 153 | Batch_idx: 240 |  Loss: (0.1275) |  Loss2: (0.0000) | Acc: (95.00%) (29482/30848)
Epoch: 153 | Batch_idx: 250 |  Loss: (0.1271) |  Loss2: (0.0000) | Acc: (95.00%) (30710/32128)
Epoch: 153 | Batch_idx: 260 |  Loss: (0.1269) |  Loss2: (0.0000) | Acc: (95.00%) (31940/33408)
Epoch: 153 | Batch_idx: 270 |  Loss: (0.1264) |  Loss2: (0.0000) | Acc: (95.00%) (33172/34688)
Epoch: 153 | Batch_idx: 280 |  Loss: (0.1258) |  Loss2: (0.0000) | Acc: (95.00%) (34397/35968)
Epoch: 153 | Batch_idx: 290 |  Loss: (0.1254) |  Loss2: (0.0000) | Acc: (95.00%) (35631/37248)
Epoch: 153 | Batch_idx: 300 |  Loss: (0.1255) |  Loss2: (0.0000) | Acc: (95.00%) (36856/38528)
Epoch: 153 | Batch_idx: 310 |  Loss: (0.1253) |  Loss2: (0.0000) | Acc: (95.00%) (38084/39808)
Epoch: 153 | Batch_idx: 320 |  Loss: (0.1248) |  Loss2: (0.0000) | Acc: (95.00%) (39322/41088)
Epoch: 153 | Batch_idx: 330 |  Loss: (0.1252) |  Loss2: (0.0000) | Acc: (95.00%) (40546/42368)
Epoch: 153 | Batch_idx: 340 |  Loss: (0.1253) |  Loss2: (0.0000) | Acc: (95.00%) (41765/43648)
Epoch: 153 | Batch_idx: 350 |  Loss: (0.1256) |  Loss2: (0.0000) | Acc: (95.00%) (42980/44928)
Epoch: 153 | Batch_idx: 360 |  Loss: (0.1257) |  Loss2: (0.0000) | Acc: (95.00%) (44195/46208)
Epoch: 153 | Batch_idx: 370 |  Loss: (0.1248) |  Loss2: (0.0000) | Acc: (95.00%) (45441/47488)
Epoch: 153 | Batch_idx: 380 |  Loss: (0.1248) |  Loss2: (0.0000) | Acc: (95.00%) (46670/48768)
Epoch: 153 | Batch_idx: 390 |  Loss: (0.1252) |  Loss2: (0.0000) | Acc: (95.00%) (47838/50000)
# TEST : Loss: (0.3760) | Acc: (88.00%) (8858/10000)
percent tensor([0.5146, 0.5168, 0.5178, 0.5195, 0.5184, 0.5195, 0.5184, 0.5201, 0.5151,
        0.5164, 0.5142, 0.5169, 0.5144, 0.5181, 0.5170, 0.5166],
       device='cuda:0') torch.Size([16])
percent tensor([0.5135, 0.5202, 0.5102, 0.5095, 0.5080, 0.5208, 0.5130, 0.5046, 0.5104,
        0.5168, 0.5137, 0.5156, 0.5229, 0.5079, 0.5184, 0.5176],
       device='cuda:0') torch.Size([16])
percent tensor([0.6020, 0.5435, 0.6590, 0.6780, 0.6678, 0.6125, 0.6066, 0.6540, 0.6468,
        0.5946, 0.6214, 0.6074, 0.5044, 0.6710, 0.5847, 0.6017],
       device='cuda:0') torch.Size([16])
percent tensor([0.6341, 0.6287, 0.6237, 0.6262, 0.6286, 0.6356, 0.6318, 0.6282, 0.6303,
        0.6382, 0.6385, 0.6331, 0.6307, 0.6279, 0.6336, 0.6446],
       device='cuda:0') torch.Size([16])
percent tensor([0.6456, 0.6338, 0.6187, 0.6474, 0.6687, 0.7651, 0.6156, 0.5942, 0.6465,
        0.6792, 0.6426, 0.6110, 0.6403, 0.6454, 0.6368, 0.7203],
       device='cuda:0') torch.Size([16])
percent tensor([0.6189, 0.6797, 0.6563, 0.7076, 0.6647, 0.7591, 0.6791, 0.5542, 0.7214,
        0.6450, 0.7450, 0.6360, 0.7220, 0.7294, 0.5546, 0.6755],
       device='cuda:0') torch.Size([16])
percent tensor([0.6014, 0.6378, 0.6396, 0.6870, 0.6944, 0.6580, 0.6750, 0.6514, 0.6327,
        0.6424, 0.6649, 0.5999, 0.6139, 0.6431, 0.5979, 0.6138],
       device='cuda:0') torch.Size([16])
percent tensor([0.9999, 0.9996, 0.9996, 0.9998, 0.9996, 0.9995, 0.9997, 0.9995, 0.9998,
        0.9998, 0.9999, 0.9997, 0.9999, 0.9996, 0.9990, 0.9997],
       device='cuda:0') torch.Size([16])
Epoch: 154 | Batch_idx: 0 |  Loss: (0.1409) |  Loss2: (0.0000) | Acc: (94.00%) (121/128)
Epoch: 154 | Batch_idx: 10 |  Loss: (0.1266) |  Loss2: (0.0000) | Acc: (95.00%) (1347/1408)
Epoch: 154 | Batch_idx: 20 |  Loss: (0.1319) |  Loss2: (0.0000) | Acc: (95.00%) (2569/2688)
Epoch: 154 | Batch_idx: 30 |  Loss: (0.1308) |  Loss2: (0.0000) | Acc: (95.00%) (3786/3968)
Epoch: 154 | Batch_idx: 40 |  Loss: (0.1319) |  Loss2: (0.0000) | Acc: (95.00%) (5013/5248)
Epoch: 154 | Batch_idx: 50 |  Loss: (0.1296) |  Loss2: (0.0000) | Acc: (95.00%) (6236/6528)
Epoch: 154 | Batch_idx: 60 |  Loss: (0.1276) |  Loss2: (0.0000) | Acc: (95.00%) (7463/7808)
Epoch: 154 | Batch_idx: 70 |  Loss: (0.1245) |  Loss2: (0.0000) | Acc: (95.00%) (8697/9088)
Epoch: 154 | Batch_idx: 80 |  Loss: (0.1244) |  Loss2: (0.0000) | Acc: (95.00%) (9922/10368)
Epoch: 154 | Batch_idx: 90 |  Loss: (0.1239) |  Loss2: (0.0000) | Acc: (95.00%) (11143/11648)
Epoch: 154 | Batch_idx: 100 |  Loss: (0.1257) |  Loss2: (0.0000) | Acc: (95.00%) (12361/12928)
Epoch: 154 | Batch_idx: 110 |  Loss: (0.1275) |  Loss2: (0.0000) | Acc: (95.00%) (13574/14208)
Epoch: 154 | Batch_idx: 120 |  Loss: (0.1265) |  Loss2: (0.0000) | Acc: (95.00%) (14804/15488)
Epoch: 154 | Batch_idx: 130 |  Loss: (0.1260) |  Loss2: (0.0000) | Acc: (95.00%) (16035/16768)
Epoch: 154 | Batch_idx: 140 |  Loss: (0.1251) |  Loss2: (0.0000) | Acc: (95.00%) (17260/18048)
Epoch: 154 | Batch_idx: 150 |  Loss: (0.1248) |  Loss2: (0.0000) | Acc: (95.00%) (18481/19328)
Epoch: 154 | Batch_idx: 160 |  Loss: (0.1254) |  Loss2: (0.0000) | Acc: (95.00%) (19701/20608)
Epoch: 154 | Batch_idx: 170 |  Loss: (0.1246) |  Loss2: (0.0000) | Acc: (95.00%) (20935/21888)
Epoch: 154 | Batch_idx: 180 |  Loss: (0.1234) |  Loss2: (0.0000) | Acc: (95.00%) (22174/23168)
Epoch: 154 | Batch_idx: 190 |  Loss: (0.1230) |  Loss2: (0.0000) | Acc: (95.00%) (23407/24448)
Epoch: 154 | Batch_idx: 200 |  Loss: (0.1218) |  Loss2: (0.0000) | Acc: (95.00%) (24645/25728)
Epoch: 154 | Batch_idx: 210 |  Loss: (0.1213) |  Loss2: (0.0000) | Acc: (95.00%) (25877/27008)
Epoch: 154 | Batch_idx: 220 |  Loss: (0.1211) |  Loss2: (0.0000) | Acc: (95.00%) (27109/28288)
Epoch: 154 | Batch_idx: 230 |  Loss: (0.1210) |  Loss2: (0.0000) | Acc: (95.00%) (28334/29568)
Epoch: 154 | Batch_idx: 240 |  Loss: (0.1212) |  Loss2: (0.0000) | Acc: (95.00%) (29560/30848)
Epoch: 154 | Batch_idx: 250 |  Loss: (0.1213) |  Loss2: (0.0000) | Acc: (95.00%) (30790/32128)
Epoch: 154 | Batch_idx: 260 |  Loss: (0.1212) |  Loss2: (0.0000) | Acc: (95.00%) (32012/33408)
Epoch: 154 | Batch_idx: 270 |  Loss: (0.1208) |  Loss2: (0.0000) | Acc: (95.00%) (33240/34688)
Epoch: 154 | Batch_idx: 280 |  Loss: (0.1204) |  Loss2: (0.0000) | Acc: (95.00%) (34476/35968)
Epoch: 154 | Batch_idx: 290 |  Loss: (0.1207) |  Loss2: (0.0000) | Acc: (95.00%) (35700/37248)
Epoch: 154 | Batch_idx: 300 |  Loss: (0.1211) |  Loss2: (0.0000) | Acc: (95.00%) (36922/38528)
Epoch: 154 | Batch_idx: 310 |  Loss: (0.1214) |  Loss2: (0.0000) | Acc: (95.00%) (38143/39808)
Epoch: 154 | Batch_idx: 320 |  Loss: (0.1215) |  Loss2: (0.0000) | Acc: (95.00%) (39365/41088)
Epoch: 154 | Batch_idx: 330 |  Loss: (0.1212) |  Loss2: (0.0000) | Acc: (95.00%) (40597/42368)
Epoch: 154 | Batch_idx: 340 |  Loss: (0.1219) |  Loss2: (0.0000) | Acc: (95.00%) (41807/43648)
Epoch: 154 | Batch_idx: 350 |  Loss: (0.1214) |  Loss2: (0.0000) | Acc: (95.00%) (43039/44928)
Epoch: 154 | Batch_idx: 360 |  Loss: (0.1210) |  Loss2: (0.0000) | Acc: (95.00%) (44277/46208)
Epoch: 154 | Batch_idx: 370 |  Loss: (0.1209) |  Loss2: (0.0000) | Acc: (95.00%) (45500/47488)
Epoch: 154 | Batch_idx: 380 |  Loss: (0.1213) |  Loss2: (0.0000) | Acc: (95.00%) (46727/48768)
Epoch: 154 | Batch_idx: 390 |  Loss: (0.1210) |  Loss2: (0.0000) | Acc: (95.00%) (47922/50000)
# TEST : Loss: (0.3743) | Acc: (88.00%) (8864/10000)
percent tensor([0.5139, 0.5160, 0.5172, 0.5186, 0.5177, 0.5184, 0.5176, 0.5194, 0.5144,
        0.5158, 0.5133, 0.5163, 0.5136, 0.5172, 0.5161, 0.5157],
       device='cuda:0') torch.Size([16])
percent tensor([0.5136, 0.5204, 0.5106, 0.5094, 0.5078, 0.5209, 0.5130, 0.5043, 0.5104,
        0.5171, 0.5139, 0.5159, 0.5231, 0.5078, 0.5185, 0.5177],
       device='cuda:0') torch.Size([16])
percent tensor([0.5989, 0.5391, 0.6592, 0.6771, 0.6669, 0.6085, 0.6032, 0.6531, 0.6441,
        0.5901, 0.6161, 0.6060, 0.5023, 0.6667, 0.5802, 0.5979],
       device='cuda:0') torch.Size([16])
percent tensor([0.6350, 0.6298, 0.6248, 0.6273, 0.6296, 0.6362, 0.6323, 0.6289, 0.6310,
        0.6393, 0.6392, 0.6341, 0.6317, 0.6288, 0.6341, 0.6458],
       device='cuda:0') torch.Size([16])
percent tensor([0.6455, 0.6295, 0.6188, 0.6498, 0.6706, 0.7700, 0.6126, 0.5927, 0.6460,
        0.6775, 0.6411, 0.6081, 0.6376, 0.6441, 0.6346, 0.7218],
       device='cuda:0') torch.Size([16])
percent tensor([0.6150, 0.6755, 0.6533, 0.7067, 0.6626, 0.7591, 0.6766, 0.5508, 0.7205,
        0.6397, 0.7451, 0.6321, 0.7202, 0.7273, 0.5484, 0.6701],
       device='cuda:0') torch.Size([16])
percent tensor([0.5990, 0.6392, 0.6370, 0.6884, 0.6937, 0.6555, 0.6766, 0.6494, 0.6332,
        0.6386, 0.6662, 0.6004, 0.6162, 0.6425, 0.5998, 0.6109],
       device='cuda:0') torch.Size([16])
percent tensor([0.9999, 0.9996, 0.9996, 0.9998, 0.9996, 0.9995, 0.9997, 0.9995, 0.9998,
        0.9998, 0.9998, 0.9997, 0.9999, 0.9996, 0.9991, 0.9997],
       device='cuda:0') torch.Size([16])
Epoch: 155 | Batch_idx: 0 |  Loss: (0.0985) |  Loss2: (0.0000) | Acc: (96.00%) (124/128)
Epoch: 155 | Batch_idx: 10 |  Loss: (0.1159) |  Loss2: (0.0000) | Acc: (96.00%) (1360/1408)
Epoch: 155 | Batch_idx: 20 |  Loss: (0.1113) |  Loss2: (0.0000) | Acc: (96.00%) (2597/2688)
Epoch: 155 | Batch_idx: 30 |  Loss: (0.1166) |  Loss2: (0.0000) | Acc: (96.00%) (3823/3968)
Epoch: 155 | Batch_idx: 40 |  Loss: (0.1187) |  Loss2: (0.0000) | Acc: (96.00%) (5045/5248)
Epoch: 155 | Batch_idx: 50 |  Loss: (0.1205) |  Loss2: (0.0000) | Acc: (96.00%) (6275/6528)
Epoch: 155 | Batch_idx: 60 |  Loss: (0.1209) |  Loss2: (0.0000) | Acc: (96.00%) (7502/7808)
Epoch: 155 | Batch_idx: 70 |  Loss: (0.1196) |  Loss2: (0.0000) | Acc: (96.00%) (8728/9088)
Epoch: 155 | Batch_idx: 80 |  Loss: (0.1190) |  Loss2: (0.0000) | Acc: (96.00%) (9960/10368)
Epoch: 155 | Batch_idx: 90 |  Loss: (0.1195) |  Loss2: (0.0000) | Acc: (96.00%) (11186/11648)
Epoch: 155 | Batch_idx: 100 |  Loss: (0.1193) |  Loss2: (0.0000) | Acc: (96.00%) (12418/12928)
Epoch: 155 | Batch_idx: 110 |  Loss: (0.1198) |  Loss2: (0.0000) | Acc: (96.00%) (13640/14208)
Epoch: 155 | Batch_idx: 120 |  Loss: (0.1189) |  Loss2: (0.0000) | Acc: (96.00%) (14872/15488)
Epoch: 155 | Batch_idx: 130 |  Loss: (0.1190) |  Loss2: (0.0000) | Acc: (95.00%) (16097/16768)
Epoch: 155 | Batch_idx: 140 |  Loss: (0.1182) |  Loss2: (0.0000) | Acc: (96.00%) (17334/18048)
Epoch: 155 | Batch_idx: 150 |  Loss: (0.1183) |  Loss2: (0.0000) | Acc: (96.00%) (18562/19328)
Epoch: 155 | Batch_idx: 160 |  Loss: (0.1182) |  Loss2: (0.0000) | Acc: (96.00%) (19795/20608)
Epoch: 155 | Batch_idx: 170 |  Loss: (0.1190) |  Loss2: (0.0000) | Acc: (96.00%) (21013/21888)
Epoch: 155 | Batch_idx: 180 |  Loss: (0.1204) |  Loss2: (0.0000) | Acc: (95.00%) (22226/23168)
Epoch: 155 | Batch_idx: 190 |  Loss: (0.1206) |  Loss2: (0.0000) | Acc: (95.00%) (23445/24448)
Epoch: 155 | Batch_idx: 200 |  Loss: (0.1215) |  Loss2: (0.0000) | Acc: (95.00%) (24662/25728)
Epoch: 155 | Batch_idx: 210 |  Loss: (0.1217) |  Loss2: (0.0000) | Acc: (95.00%) (25880/27008)
Epoch: 155 | Batch_idx: 220 |  Loss: (0.1210) |  Loss2: (0.0000) | Acc: (95.00%) (27117/28288)
Epoch: 155 | Batch_idx: 230 |  Loss: (0.1208) |  Loss2: (0.0000) | Acc: (95.00%) (28345/29568)
Epoch: 155 | Batch_idx: 240 |  Loss: (0.1211) |  Loss2: (0.0000) | Acc: (95.00%) (29570/30848)
Epoch: 155 | Batch_idx: 250 |  Loss: (0.1211) |  Loss2: (0.0000) | Acc: (95.00%) (30791/32128)
Epoch: 155 | Batch_idx: 260 |  Loss: (0.1211) |  Loss2: (0.0000) | Acc: (95.00%) (32006/33408)
Epoch: 155 | Batch_idx: 270 |  Loss: (0.1209) |  Loss2: (0.0000) | Acc: (95.00%) (33240/34688)
Epoch: 155 | Batch_idx: 280 |  Loss: (0.1211) |  Loss2: (0.0000) | Acc: (95.00%) (34457/35968)
Epoch: 155 | Batch_idx: 290 |  Loss: (0.1216) |  Loss2: (0.0000) | Acc: (95.00%) (35676/37248)
Epoch: 155 | Batch_idx: 300 |  Loss: (0.1218) |  Loss2: (0.0000) | Acc: (95.00%) (36902/38528)
Epoch: 155 | Batch_idx: 310 |  Loss: (0.1214) |  Loss2: (0.0000) | Acc: (95.00%) (38134/39808)
Epoch: 155 | Batch_idx: 320 |  Loss: (0.1215) |  Loss2: (0.0000) | Acc: (95.00%) (39361/41088)
Epoch: 155 | Batch_idx: 330 |  Loss: (0.1216) |  Loss2: (0.0000) | Acc: (95.00%) (40580/42368)
Epoch: 155 | Batch_idx: 340 |  Loss: (0.1210) |  Loss2: (0.0000) | Acc: (95.00%) (41822/43648)
Epoch: 155 | Batch_idx: 350 |  Loss: (0.1208) |  Loss2: (0.0000) | Acc: (95.00%) (43055/44928)
Epoch: 155 | Batch_idx: 360 |  Loss: (0.1209) |  Loss2: (0.0000) | Acc: (95.00%) (44281/46208)
Epoch: 155 | Batch_idx: 370 |  Loss: (0.1209) |  Loss2: (0.0000) | Acc: (95.00%) (45511/47488)
Epoch: 155 | Batch_idx: 380 |  Loss: (0.1205) |  Loss2: (0.0000) | Acc: (95.00%) (46746/48768)
Epoch: 155 | Batch_idx: 390 |  Loss: (0.1203) |  Loss2: (0.0000) | Acc: (95.00%) (47934/50000)
=> saving checkpoint 'drive/app/torch/save_Schedule/checkpoint_155.pth.tar'
# TEST : Loss: (0.3703) | Acc: (88.00%) (8876/10000)
percent tensor([0.5129, 0.5149, 0.5165, 0.5177, 0.5168, 0.5172, 0.5166, 0.5185, 0.5134,
        0.5148, 0.5123, 0.5155, 0.5126, 0.5161, 0.5150, 0.5147],
       device='cuda:0') torch.Size([16])
percent tensor([0.5129, 0.5197, 0.5099, 0.5085, 0.5068, 0.5206, 0.5120, 0.5030, 0.5095,
        0.5165, 0.5132, 0.5151, 0.5226, 0.5069, 0.5178, 0.5172],
       device='cuda:0') torch.Size([16])
percent tensor([0.5975, 0.5392, 0.6579, 0.6749, 0.6657, 0.6034, 0.6030, 0.6517, 0.6426,
        0.5897, 0.6151, 0.6057, 0.5021, 0.6644, 0.5789, 0.5956],
       device='cuda:0') torch.Size([16])
percent tensor([0.6359, 0.6306, 0.6258, 0.6280, 0.6298, 0.6373, 0.6326, 0.6290, 0.6315,
        0.6400, 0.6398, 0.6350, 0.6325, 0.6293, 0.6346, 0.6469],
       device='cuda:0') torch.Size([16])
percent tensor([0.6468, 0.6302, 0.6206, 0.6519, 0.6707, 0.7732, 0.6119, 0.5925, 0.6464,
        0.6783, 0.6414, 0.6089, 0.6381, 0.6454, 0.6354, 0.7237],
       device='cuda:0') torch.Size([16])
percent tensor([0.6170, 0.6769, 0.6537, 0.7061, 0.6608, 0.7599, 0.6778, 0.5496, 0.7218,
        0.6413, 0.7473, 0.6329, 0.7238, 0.7286, 0.5480, 0.6717],
       device='cuda:0') torch.Size([16])
percent tensor([0.5926, 0.6360, 0.6330, 0.6866, 0.6900, 0.6572, 0.6723, 0.6439, 0.6305,
        0.6333, 0.6656, 0.5959, 0.6160, 0.6383, 0.5954, 0.6056],
       device='cuda:0') torch.Size([16])
percent tensor([0.9999, 0.9996, 0.9996, 0.9998, 0.9997, 0.9995, 0.9997, 0.9995, 0.9998,
        0.9998, 0.9999, 0.9997, 0.9999, 0.9996, 0.9990, 0.9997],
       device='cuda:0') torch.Size([16])
True Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=128, out_features=16, bias=False)
False Linear(in_features=16, out_features=2, bias=False)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=128, out_features=16, bias=False)
False Linear(in_features=16, out_features=2, bias=False)
True Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=256, out_features=32, bias=False)
False Linear(in_features=32, out_features=2, bias=False)
True Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=256, out_features=32, bias=False)
False Linear(in_features=32, out_features=2, bias=False)
True Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=512, out_features=64, bias=False)
False Linear(in_features=64, out_features=2, bias=False)
True Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=512, out_features=64, bias=False)
False Linear(in_features=64, out_features=2, bias=False)
True Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1024, out_features=128, bias=False)
False Linear(in_features=128, out_features=2, bias=False)
True Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1024, out_features=128, bias=False)
False Linear(in_features=128, out_features=2, bias=False)
True Linear(in_features=512, out_features=10, bias=True)
Epoch: 156 | Batch_idx: 0 |  Loss: (0.1417) |  Loss2: (0.0000) | Acc: (97.00%) (125/128)
Epoch: 156 | Batch_idx: 10 |  Loss: (0.1125) |  Loss2: (0.0000) | Acc: (96.00%) (1360/1408)
Epoch: 156 | Batch_idx: 20 |  Loss: (0.1133) |  Loss2: (0.0000) | Acc: (96.00%) (2592/2688)
Epoch: 156 | Batch_idx: 30 |  Loss: (0.1139) |  Loss2: (0.0000) | Acc: (96.00%) (3822/3968)
Epoch: 156 | Batch_idx: 40 |  Loss: (0.1201) |  Loss2: (0.0000) | Acc: (95.00%) (5035/5248)
Epoch: 156 | Batch_idx: 50 |  Loss: (0.1221) |  Loss2: (0.0000) | Acc: (95.00%) (6263/6528)
Epoch: 156 | Batch_idx: 60 |  Loss: (0.1223) |  Loss2: (0.0000) | Acc: (95.00%) (7486/7808)
Epoch: 156 | Batch_idx: 70 |  Loss: (0.1245) |  Loss2: (0.0000) | Acc: (95.00%) (8700/9088)
Epoch: 156 | Batch_idx: 80 |  Loss: (0.1216) |  Loss2: (0.0000) | Acc: (95.00%) (9936/10368)
Epoch: 156 | Batch_idx: 90 |  Loss: (0.1201) |  Loss2: (0.0000) | Acc: (95.00%) (11175/11648)
Epoch: 156 | Batch_idx: 100 |  Loss: (0.1205) |  Loss2: (0.0000) | Acc: (95.00%) (12396/12928)
Epoch: 156 | Batch_idx: 110 |  Loss: (0.1229) |  Loss2: (0.0000) | Acc: (95.00%) (13614/14208)
Epoch: 156 | Batch_idx: 120 |  Loss: (0.1231) |  Loss2: (0.0000) | Acc: (95.00%) (14838/15488)
Epoch: 156 | Batch_idx: 130 |  Loss: (0.1230) |  Loss2: (0.0000) | Acc: (95.00%) (16061/16768)
Epoch: 156 | Batch_idx: 140 |  Loss: (0.1242) |  Loss2: (0.0000) | Acc: (95.00%) (17287/18048)
Epoch: 156 | Batch_idx: 150 |  Loss: (0.1231) |  Loss2: (0.0000) | Acc: (95.00%) (18520/19328)
Epoch: 156 | Batch_idx: 160 |  Loss: (0.1242) |  Loss2: (0.0000) | Acc: (95.00%) (19741/20608)
Epoch: 156 | Batch_idx: 170 |  Loss: (0.1242) |  Loss2: (0.0000) | Acc: (95.00%) (20964/21888)
Epoch: 156 | Batch_idx: 180 |  Loss: (0.1237) |  Loss2: (0.0000) | Acc: (95.00%) (22193/23168)
Epoch: 156 | Batch_idx: 190 |  Loss: (0.1243) |  Loss2: (0.0000) | Acc: (95.00%) (23415/24448)
Epoch: 156 | Batch_idx: 200 |  Loss: (0.1250) |  Loss2: (0.0000) | Acc: (95.00%) (24631/25728)
Epoch: 156 | Batch_idx: 210 |  Loss: (0.1248) |  Loss2: (0.0000) | Acc: (95.00%) (25857/27008)
Epoch: 156 | Batch_idx: 220 |  Loss: (0.1241) |  Loss2: (0.0000) | Acc: (95.00%) (27086/28288)
Epoch: 156 | Batch_idx: 230 |  Loss: (0.1244) |  Loss2: (0.0000) | Acc: (95.00%) (28305/29568)
Epoch: 156 | Batch_idx: 240 |  Loss: (0.1247) |  Loss2: (0.0000) | Acc: (95.00%) (29527/30848)
Epoch: 156 | Batch_idx: 250 |  Loss: (0.1253) |  Loss2: (0.0000) | Acc: (95.00%) (30743/32128)
Epoch: 156 | Batch_idx: 260 |  Loss: (0.1258) |  Loss2: (0.0000) | Acc: (95.00%) (31959/33408)
Epoch: 156 | Batch_idx: 270 |  Loss: (0.1266) |  Loss2: (0.0000) | Acc: (95.00%) (33166/34688)
Epoch: 156 | Batch_idx: 280 |  Loss: (0.1267) |  Loss2: (0.0000) | Acc: (95.00%) (34390/35968)
Epoch: 156 | Batch_idx: 290 |  Loss: (0.1266) |  Loss2: (0.0000) | Acc: (95.00%) (35609/37248)
Epoch: 156 | Batch_idx: 300 |  Loss: (0.1265) |  Loss2: (0.0000) | Acc: (95.00%) (36831/38528)
Epoch: 156 | Batch_idx: 310 |  Loss: (0.1271) |  Loss2: (0.0000) | Acc: (95.00%) (38043/39808)
Epoch: 156 | Batch_idx: 320 |  Loss: (0.1274) |  Loss2: (0.0000) | Acc: (95.00%) (39259/41088)
Epoch: 156 | Batch_idx: 330 |  Loss: (0.1273) |  Loss2: (0.0000) | Acc: (95.00%) (40477/42368)
Epoch: 156 | Batch_idx: 340 |  Loss: (0.1279) |  Loss2: (0.0000) | Acc: (95.00%) (41694/43648)
Epoch: 156 | Batch_idx: 350 |  Loss: (0.1282) |  Loss2: (0.0000) | Acc: (95.00%) (42906/44928)
Epoch: 156 | Batch_idx: 360 |  Loss: (0.1284) |  Loss2: (0.0000) | Acc: (95.00%) (44130/46208)
Epoch: 156 | Batch_idx: 370 |  Loss: (0.1287) |  Loss2: (0.0000) | Acc: (95.00%) (45352/47488)
Epoch: 156 | Batch_idx: 380 |  Loss: (0.1284) |  Loss2: (0.0000) | Acc: (95.00%) (46576/48768)
Epoch: 156 | Batch_idx: 390 |  Loss: (0.1286) |  Loss2: (0.0000) | Acc: (95.00%) (47749/50000)
# TEST : Loss: (0.4799) | Acc: (86.00%) (8603/10000)
percent tensor([0.5130, 0.5150, 0.5163, 0.5171, 0.5163, 0.5177, 0.5163, 0.5186, 0.5136,
        0.5146, 0.5124, 0.5152, 0.5126, 0.5162, 0.5152, 0.5145],
       device='cuda:0') torch.Size([16])
percent tensor([0.5115, 0.5205, 0.5111, 0.5067, 0.5065, 0.5216, 0.5129, 0.5020, 0.5077,
        0.5160, 0.5125, 0.5152, 0.5203, 0.5066, 0.5178, 0.5159],
       device='cuda:0') torch.Size([16])
percent tensor([0.5940, 0.5385, 0.6470, 0.6782, 0.6583, 0.6113, 0.6015, 0.6492, 0.6419,
        0.5855, 0.6155, 0.5999, 0.5048, 0.6724, 0.5808, 0.5976],
       device='cuda:0') torch.Size([16])
percent tensor([0.6358, 0.6303, 0.6273, 0.6304, 0.6300, 0.6359, 0.6337, 0.6289, 0.6343,
        0.6398, 0.6376, 0.6369, 0.6300, 0.6300, 0.6358, 0.6482],
       device='cuda:0') torch.Size([16])
percent tensor([0.6468, 0.6246, 0.6320, 0.6468, 0.6635, 0.7672, 0.6123, 0.5903, 0.6400,
        0.6678, 0.6283, 0.6134, 0.6115, 0.6508, 0.6261, 0.7122],
       device='cuda:0') torch.Size([16])
percent tensor([0.6189, 0.6806, 0.6757, 0.7142, 0.6538, 0.7670, 0.6834, 0.5559, 0.7231,
        0.6630, 0.7504, 0.6940, 0.7290, 0.7336, 0.5584, 0.6506],
       device='cuda:0') torch.Size([16])
percent tensor([0.5941, 0.6309, 0.6623, 0.6963, 0.6742, 0.6630, 0.6718, 0.6517, 0.6268,
        0.6677, 0.6830, 0.6492, 0.6328, 0.6172, 0.5988, 0.6007],
       device='cuda:0') torch.Size([16])
percent tensor([0.9999, 0.9997, 0.9998, 0.9998, 0.9996, 0.9994, 0.9996, 0.9996, 0.9999,
        0.9999, 0.9999, 0.9999, 0.9999, 0.9996, 0.9990, 0.9996],
       device='cuda:0') torch.Size([16])
Epoch: 157 | Batch_idx: 0 |  Loss: (0.1330) |  Loss2: (0.0000) | Acc: (95.00%) (122/128)
Epoch: 157 | Batch_idx: 10 |  Loss: (0.1138) |  Loss2: (0.0000) | Acc: (96.00%) (1355/1408)
Epoch: 157 | Batch_idx: 20 |  Loss: (0.1148) |  Loss2: (0.0000) | Acc: (96.00%) (2587/2688)
Epoch: 157 | Batch_idx: 30 |  Loss: (0.1182) |  Loss2: (0.0000) | Acc: (95.00%) (3806/3968)
Epoch: 157 | Batch_idx: 40 |  Loss: (0.1198) |  Loss2: (0.0000) | Acc: (95.00%) (5030/5248)
Epoch: 157 | Batch_idx: 50 |  Loss: (0.1198) |  Loss2: (0.0000) | Acc: (95.00%) (6250/6528)
Epoch: 157 | Batch_idx: 60 |  Loss: (0.1155) |  Loss2: (0.0000) | Acc: (95.00%) (7491/7808)
Epoch: 157 | Batch_idx: 70 |  Loss: (0.1155) |  Loss2: (0.0000) | Acc: (95.00%) (8723/9088)
Epoch: 157 | Batch_idx: 80 |  Loss: (0.1164) |  Loss2: (0.0000) | Acc: (95.00%) (9949/10368)
Epoch: 157 | Batch_idx: 90 |  Loss: (0.1178) |  Loss2: (0.0000) | Acc: (95.00%) (11175/11648)
Epoch: 157 | Batch_idx: 100 |  Loss: (0.1168) |  Loss2: (0.0000) | Acc: (96.00%) (12414/12928)
Epoch: 157 | Batch_idx: 110 |  Loss: (0.1164) |  Loss2: (0.0000) | Acc: (96.00%) (13645/14208)
Epoch: 157 | Batch_idx: 120 |  Loss: (0.1161) |  Loss2: (0.0000) | Acc: (96.00%) (14880/15488)
Epoch: 157 | Batch_idx: 130 |  Loss: (0.1157) |  Loss2: (0.0000) | Acc: (96.00%) (16111/16768)
Epoch: 157 | Batch_idx: 140 |  Loss: (0.1141) |  Loss2: (0.0000) | Acc: (96.00%) (17350/18048)
Epoch: 157 | Batch_idx: 150 |  Loss: (0.1146) |  Loss2: (0.0000) | Acc: (96.00%) (18580/19328)
Epoch: 157 | Batch_idx: 160 |  Loss: (0.1148) |  Loss2: (0.0000) | Acc: (96.00%) (19813/20608)
Epoch: 157 | Batch_idx: 170 |  Loss: (0.1148) |  Loss2: (0.0000) | Acc: (96.00%) (21048/21888)
Epoch: 157 | Batch_idx: 180 |  Loss: (0.1140) |  Loss2: (0.0000) | Acc: (96.00%) (22283/23168)
Epoch: 157 | Batch_idx: 190 |  Loss: (0.1147) |  Loss2: (0.0000) | Acc: (96.00%) (23510/24448)
Epoch: 157 | Batch_idx: 200 |  Loss: (0.1162) |  Loss2: (0.0000) | Acc: (96.00%) (24724/25728)
Epoch: 157 | Batch_idx: 210 |  Loss: (0.1168) |  Loss2: (0.0000) | Acc: (96.00%) (25953/27008)
Epoch: 157 | Batch_idx: 220 |  Loss: (0.1175) |  Loss2: (0.0000) | Acc: (96.00%) (27177/28288)
Epoch: 157 | Batch_idx: 230 |  Loss: (0.1173) |  Loss2: (0.0000) | Acc: (96.00%) (28412/29568)
Epoch: 157 | Batch_idx: 240 |  Loss: (0.1166) |  Loss2: (0.0000) | Acc: (96.00%) (29649/30848)
Epoch: 157 | Batch_idx: 250 |  Loss: (0.1167) |  Loss2: (0.0000) | Acc: (96.00%) (30876/32128)
Epoch: 157 | Batch_idx: 260 |  Loss: (0.1170) |  Loss2: (0.0000) | Acc: (96.00%) (32102/33408)
Epoch: 157 | Batch_idx: 270 |  Loss: (0.1166) |  Loss2: (0.0000) | Acc: (96.00%) (33336/34688)
Epoch: 157 | Batch_idx: 280 |  Loss: (0.1166) |  Loss2: (0.0000) | Acc: (96.00%) (34563/35968)
Epoch: 157 | Batch_idx: 290 |  Loss: (0.1172) |  Loss2: (0.0000) | Acc: (96.00%) (35779/37248)
Epoch: 157 | Batch_idx: 300 |  Loss: (0.1173) |  Loss2: (0.0000) | Acc: (96.00%) (37007/38528)
Epoch: 157 | Batch_idx: 310 |  Loss: (0.1182) |  Loss2: (0.0000) | Acc: (96.00%) (38224/39808)
Epoch: 157 | Batch_idx: 320 |  Loss: (0.1189) |  Loss2: (0.0000) | Acc: (95.00%) (39435/41088)
Epoch: 157 | Batch_idx: 330 |  Loss: (0.1191) |  Loss2: (0.0000) | Acc: (95.00%) (40660/42368)
Epoch: 157 | Batch_idx: 340 |  Loss: (0.1195) |  Loss2: (0.0000) | Acc: (95.00%) (41880/43648)
Epoch: 157 | Batch_idx: 350 |  Loss: (0.1194) |  Loss2: (0.0000) | Acc: (95.00%) (43108/44928)
Epoch: 157 | Batch_idx: 360 |  Loss: (0.1196) |  Loss2: (0.0000) | Acc: (95.00%) (44331/46208)
Epoch: 157 | Batch_idx: 370 |  Loss: (0.1200) |  Loss2: (0.0000) | Acc: (95.00%) (45548/47488)
Epoch: 157 | Batch_idx: 380 |  Loss: (0.1201) |  Loss2: (0.0000) | Acc: (95.00%) (46774/48768)
Epoch: 157 | Batch_idx: 390 |  Loss: (0.1209) |  Loss2: (0.0000) | Acc: (95.00%) (47941/50000)
# TEST : Loss: (0.4500) | Acc: (87.00%) (8714/10000)
percent tensor([0.5138, 0.5145, 0.5179, 0.5172, 0.5174, 0.5182, 0.5162, 0.5189, 0.5143,
        0.5148, 0.5130, 0.5161, 0.5133, 0.5152, 0.5148, 0.5148],
       device='cuda:0') torch.Size([16])
percent tensor([0.5110, 0.5210, 0.5088, 0.5054, 0.5042, 0.5181, 0.5128, 0.5030, 0.5076,
        0.5163, 0.5132, 0.5129, 0.5215, 0.5070, 0.5172, 0.5160],
       device='cuda:0') torch.Size([16])
percent tensor([0.5905, 0.5475, 0.6584, 0.6786, 0.6591, 0.6037, 0.6100, 0.6543, 0.6379,
        0.5997, 0.6181, 0.6113, 0.5011, 0.6790, 0.5786, 0.5984],
       device='cuda:0') torch.Size([16])
percent tensor([0.6341, 0.6296, 0.6258, 0.6279, 0.6277, 0.6330, 0.6337, 0.6284, 0.6329,
        0.6372, 0.6359, 0.6333, 0.6308, 0.6294, 0.6324, 0.6462],
       device='cuda:0') torch.Size([16])
percent tensor([0.6524, 0.6329, 0.6424, 0.6667, 0.6669, 0.7546, 0.6265, 0.6068, 0.6715,
        0.6811, 0.6522, 0.6196, 0.6433, 0.6900, 0.6184, 0.7173],
       device='cuda:0') torch.Size([16])
percent tensor([0.5997, 0.6805, 0.6486, 0.6961, 0.6439, 0.7374, 0.6776, 0.5335, 0.7185,
        0.6582, 0.7489, 0.6647, 0.7377, 0.7311, 0.5407, 0.6368],
       device='cuda:0') torch.Size([16])
percent tensor([0.5899, 0.6548, 0.6382, 0.6779, 0.6795, 0.6680, 0.6681, 0.6463, 0.6388,
        0.6632, 0.6802, 0.6169, 0.6425, 0.6322, 0.6013, 0.5950],
       device='cuda:0') torch.Size([16])
percent tensor([0.9999, 0.9996, 0.9998, 0.9998, 0.9997, 0.9986, 0.9997, 0.9997, 0.9999,
        0.9998, 0.9999, 0.9998, 0.9999, 0.9996, 0.9989, 0.9994],
       device='cuda:0') torch.Size([16])
Epoch: 158 | Batch_idx: 0 |  Loss: (0.1453) |  Loss2: (0.0000) | Acc: (96.00%) (123/128)
Epoch: 158 | Batch_idx: 10 |  Loss: (0.1102) |  Loss2: (0.0000) | Acc: (95.00%) (1348/1408)
Epoch: 158 | Batch_idx: 20 |  Loss: (0.1197) |  Loss2: (0.0000) | Acc: (95.00%) (2570/2688)
Epoch: 158 | Batch_idx: 30 |  Loss: (0.1200) |  Loss2: (0.0000) | Acc: (95.00%) (3792/3968)
Epoch: 158 | Batch_idx: 40 |  Loss: (0.1238) |  Loss2: (0.0000) | Acc: (95.00%) (5015/5248)
Epoch: 158 | Batch_idx: 50 |  Loss: (0.1224) |  Loss2: (0.0000) | Acc: (95.00%) (6250/6528)
Epoch: 158 | Batch_idx: 60 |  Loss: (0.1243) |  Loss2: (0.0000) | Acc: (95.00%) (7470/7808)
Epoch: 158 | Batch_idx: 70 |  Loss: (0.1223) |  Loss2: (0.0000) | Acc: (95.00%) (8706/9088)
Epoch: 158 | Batch_idx: 80 |  Loss: (0.1212) |  Loss2: (0.0000) | Acc: (95.00%) (9935/10368)
Epoch: 158 | Batch_idx: 90 |  Loss: (0.1208) |  Loss2: (0.0000) | Acc: (95.00%) (11164/11648)
Epoch: 158 | Batch_idx: 100 |  Loss: (0.1197) |  Loss2: (0.0000) | Acc: (95.00%) (12394/12928)
Epoch: 158 | Batch_idx: 110 |  Loss: (0.1212) |  Loss2: (0.0000) | Acc: (95.00%) (13613/14208)
Epoch: 158 | Batch_idx: 120 |  Loss: (0.1206) |  Loss2: (0.0000) | Acc: (95.00%) (14840/15488)
Epoch: 158 | Batch_idx: 130 |  Loss: (0.1201) |  Loss2: (0.0000) | Acc: (95.00%) (16069/16768)
Epoch: 158 | Batch_idx: 140 |  Loss: (0.1207) |  Loss2: (0.0000) | Acc: (95.00%) (17293/18048)
Epoch: 158 | Batch_idx: 150 |  Loss: (0.1212) |  Loss2: (0.0000) | Acc: (95.00%) (18515/19328)
Epoch: 158 | Batch_idx: 160 |  Loss: (0.1215) |  Loss2: (0.0000) | Acc: (95.00%) (19735/20608)
Epoch: 158 | Batch_idx: 170 |  Loss: (0.1211) |  Loss2: (0.0000) | Acc: (95.00%) (20967/21888)
Epoch: 158 | Batch_idx: 180 |  Loss: (0.1208) |  Loss2: (0.0000) | Acc: (95.00%) (22191/23168)
Epoch: 158 | Batch_idx: 190 |  Loss: (0.1225) |  Loss2: (0.0000) | Acc: (95.00%) (23394/24448)
Epoch: 158 | Batch_idx: 200 |  Loss: (0.1227) |  Loss2: (0.0000) | Acc: (95.00%) (24620/25728)
Epoch: 158 | Batch_idx: 210 |  Loss: (0.1227) |  Loss2: (0.0000) | Acc: (95.00%) (25843/27008)
Epoch: 158 | Batch_idx: 220 |  Loss: (0.1228) |  Loss2: (0.0000) | Acc: (95.00%) (27072/28288)
Epoch: 158 | Batch_idx: 230 |  Loss: (0.1237) |  Loss2: (0.0000) | Acc: (95.00%) (28293/29568)
Epoch: 158 | Batch_idx: 240 |  Loss: (0.1233) |  Loss2: (0.0000) | Acc: (95.00%) (29527/30848)
Epoch: 158 | Batch_idx: 250 |  Loss: (0.1229) |  Loss2: (0.0000) | Acc: (95.00%) (30753/32128)
Epoch: 158 | Batch_idx: 260 |  Loss: (0.1224) |  Loss2: (0.0000) | Acc: (95.00%) (31979/33408)
Epoch: 158 | Batch_idx: 270 |  Loss: (0.1234) |  Loss2: (0.0000) | Acc: (95.00%) (33198/34688)
Epoch: 158 | Batch_idx: 280 |  Loss: (0.1241) |  Loss2: (0.0000) | Acc: (95.00%) (34414/35968)
Epoch: 158 | Batch_idx: 290 |  Loss: (0.1244) |  Loss2: (0.0000) | Acc: (95.00%) (35635/37248)
Epoch: 158 | Batch_idx: 300 |  Loss: (0.1250) |  Loss2: (0.0000) | Acc: (95.00%) (36854/38528)
Epoch: 158 | Batch_idx: 310 |  Loss: (0.1243) |  Loss2: (0.0000) | Acc: (95.00%) (38089/39808)
Epoch: 158 | Batch_idx: 320 |  Loss: (0.1243) |  Loss2: (0.0000) | Acc: (95.00%) (39314/41088)
Epoch: 158 | Batch_idx: 330 |  Loss: (0.1241) |  Loss2: (0.0000) | Acc: (95.00%) (40549/42368)
Epoch: 158 | Batch_idx: 340 |  Loss: (0.1241) |  Loss2: (0.0000) | Acc: (95.00%) (41773/43648)
Epoch: 158 | Batch_idx: 350 |  Loss: (0.1243) |  Loss2: (0.0000) | Acc: (95.00%) (42993/44928)
Epoch: 158 | Batch_idx: 360 |  Loss: (0.1242) |  Loss2: (0.0000) | Acc: (95.00%) (44218/46208)
Epoch: 158 | Batch_idx: 370 |  Loss: (0.1235) |  Loss2: (0.0000) | Acc: (95.00%) (45454/47488)
Epoch: 158 | Batch_idx: 380 |  Loss: (0.1236) |  Loss2: (0.0000) | Acc: (95.00%) (46677/48768)
Epoch: 158 | Batch_idx: 390 |  Loss: (0.1236) |  Loss2: (0.0000) | Acc: (95.00%) (47859/50000)
# TEST : Loss: (0.4296) | Acc: (87.00%) (8715/10000)
percent tensor([0.5136, 0.5150, 0.5177, 0.5174, 0.5173, 0.5175, 0.5167, 0.5189, 0.5144,
        0.5151, 0.5129, 0.5163, 0.5133, 0.5160, 0.5148, 0.5147],
       device='cuda:0') torch.Size([16])
percent tensor([0.5112, 0.5211, 0.5097, 0.5089, 0.5055, 0.5189, 0.5123, 0.5043, 0.5076,
        0.5158, 0.5129, 0.5136, 0.5214, 0.5068, 0.5174, 0.5172],
       device='cuda:0') torch.Size([16])
percent tensor([0.5947, 0.5350, 0.6487, 0.6655, 0.6561, 0.6091, 0.6017, 0.6438, 0.6400,
        0.5871, 0.6157, 0.6009, 0.5028, 0.6713, 0.5744, 0.5909],
       device='cuda:0') torch.Size([16])
percent tensor([0.6356, 0.6316, 0.6245, 0.6285, 0.6281, 0.6331, 0.6342, 0.6284, 0.6350,
        0.6372, 0.6373, 0.6322, 0.6319, 0.6325, 0.6319, 0.6467],
       device='cuda:0') torch.Size([16])
percent tensor([0.6562, 0.6211, 0.6715, 0.6797, 0.6967, 0.7542, 0.6136, 0.6124, 0.6608,
        0.6716, 0.6409, 0.6317, 0.6420, 0.6563, 0.6209, 0.7139],
       device='cuda:0') torch.Size([16])
percent tensor([0.5950, 0.6654, 0.6678, 0.6993, 0.6559, 0.7492, 0.6604, 0.5467, 0.7156,
        0.6561, 0.7317, 0.6564, 0.7291, 0.7169, 0.5408, 0.6340],
       device='cuda:0') torch.Size([16])
percent tensor([0.5882, 0.6473, 0.6527, 0.6811, 0.6802, 0.6779, 0.6513, 0.6463, 0.6253,
        0.6600, 0.6557, 0.6064, 0.6266, 0.6203, 0.6053, 0.5947],
       device='cuda:0') torch.Size([16])
percent tensor([0.9998, 0.9996, 0.9998, 0.9998, 0.9995, 0.9979, 0.9997, 0.9997, 0.9999,
        0.9998, 0.9999, 0.9997, 0.9999, 0.9994, 0.9991, 0.9993],
       device='cuda:0') torch.Size([16])
Epoch: 159 | Batch_idx: 0 |  Loss: (0.1402) |  Loss2: (0.0000) | Acc: (94.00%) (121/128)
Epoch: 159 | Batch_idx: 10 |  Loss: (0.1305) |  Loss2: (0.0000) | Acc: (95.00%) (1349/1408)
Epoch: 159 | Batch_idx: 20 |  Loss: (0.1198) |  Loss2: (0.0000) | Acc: (95.00%) (2579/2688)
Epoch: 159 | Batch_idx: 30 |  Loss: (0.1194) |  Loss2: (0.0000) | Acc: (95.00%) (3805/3968)
Epoch: 159 | Batch_idx: 40 |  Loss: (0.1196) |  Loss2: (0.0000) | Acc: (95.00%) (5032/5248)
Epoch: 159 | Batch_idx: 50 |  Loss: (0.1170) |  Loss2: (0.0000) | Acc: (95.00%) (6265/6528)
Epoch: 159 | Batch_idx: 60 |  Loss: (0.1168) |  Loss2: (0.0000) | Acc: (96.00%) (7496/7808)
Epoch: 159 | Batch_idx: 70 |  Loss: (0.1158) |  Loss2: (0.0000) | Acc: (96.00%) (8730/9088)
Epoch: 159 | Batch_idx: 80 |  Loss: (0.1164) |  Loss2: (0.0000) | Acc: (96.00%) (9958/10368)
Epoch: 159 | Batch_idx: 90 |  Loss: (0.1159) |  Loss2: (0.0000) | Acc: (96.00%) (11190/11648)
Epoch: 159 | Batch_idx: 100 |  Loss: (0.1172) |  Loss2: (0.0000) | Acc: (95.00%) (12408/12928)
Epoch: 159 | Batch_idx: 110 |  Loss: (0.1168) |  Loss2: (0.0000) | Acc: (95.00%) (13638/14208)
Epoch: 159 | Batch_idx: 120 |  Loss: (0.1191) |  Loss2: (0.0000) | Acc: (95.00%) (14856/15488)
Epoch: 159 | Batch_idx: 130 |  Loss: (0.1189) |  Loss2: (0.0000) | Acc: (95.00%) (16079/16768)
Epoch: 159 | Batch_idx: 140 |  Loss: (0.1179) |  Loss2: (0.0000) | Acc: (95.00%) (17309/18048)
Epoch: 159 | Batch_idx: 150 |  Loss: (0.1173) |  Loss2: (0.0000) | Acc: (95.00%) (18542/19328)
Epoch: 159 | Batch_idx: 160 |  Loss: (0.1179) |  Loss2: (0.0000) | Acc: (95.00%) (19768/20608)
Epoch: 159 | Batch_idx: 170 |  Loss: (0.1178) |  Loss2: (0.0000) | Acc: (95.00%) (21001/21888)
Epoch: 159 | Batch_idx: 180 |  Loss: (0.1177) |  Loss2: (0.0000) | Acc: (95.00%) (22232/23168)
Epoch: 159 | Batch_idx: 190 |  Loss: (0.1171) |  Loss2: (0.0000) | Acc: (95.00%) (23464/24448)
Epoch: 159 | Batch_idx: 200 |  Loss: (0.1171) |  Loss2: (0.0000) | Acc: (96.00%) (24699/25728)
Epoch: 159 | Batch_idx: 210 |  Loss: (0.1179) |  Loss2: (0.0000) | Acc: (95.00%) (25918/27008)
Epoch: 159 | Batch_idx: 220 |  Loss: (0.1177) |  Loss2: (0.0000) | Acc: (95.00%) (27147/28288)
Epoch: 159 | Batch_idx: 230 |  Loss: (0.1179) |  Loss2: (0.0000) | Acc: (95.00%) (28378/29568)
Epoch: 159 | Batch_idx: 240 |  Loss: (0.1181) |  Loss2: (0.0000) | Acc: (95.00%) (29602/30848)
Epoch: 159 | Batch_idx: 250 |  Loss: (0.1184) |  Loss2: (0.0000) | Acc: (95.00%) (30822/32128)
Epoch: 159 | Batch_idx: 260 |  Loss: (0.1190) |  Loss2: (0.0000) | Acc: (95.00%) (32040/33408)
Epoch: 159 | Batch_idx: 270 |  Loss: (0.1196) |  Loss2: (0.0000) | Acc: (95.00%) (33254/34688)
Epoch: 159 | Batch_idx: 280 |  Loss: (0.1200) |  Loss2: (0.0000) | Acc: (95.00%) (34472/35968)
Epoch: 159 | Batch_idx: 290 |  Loss: (0.1193) |  Loss2: (0.0000) | Acc: (95.00%) (35706/37248)
Epoch: 159 | Batch_idx: 300 |  Loss: (0.1195) |  Loss2: (0.0000) | Acc: (95.00%) (36930/38528)
Epoch: 159 | Batch_idx: 310 |  Loss: (0.1199) |  Loss2: (0.0000) | Acc: (95.00%) (38154/39808)
Epoch: 159 | Batch_idx: 320 |  Loss: (0.1200) |  Loss2: (0.0000) | Acc: (95.00%) (39378/41088)
Epoch: 159 | Batch_idx: 330 |  Loss: (0.1196) |  Loss2: (0.0000) | Acc: (95.00%) (40606/42368)
Epoch: 159 | Batch_idx: 340 |  Loss: (0.1201) |  Loss2: (0.0000) | Acc: (95.00%) (41825/43648)
Epoch: 159 | Batch_idx: 350 |  Loss: (0.1205) |  Loss2: (0.0000) | Acc: (95.00%) (43046/44928)
Epoch: 159 | Batch_idx: 360 |  Loss: (0.1204) |  Loss2: (0.0000) | Acc: (95.00%) (44284/46208)
Epoch: 159 | Batch_idx: 370 |  Loss: (0.1202) |  Loss2: (0.0000) | Acc: (95.00%) (45513/47488)
Epoch: 159 | Batch_idx: 380 |  Loss: (0.1204) |  Loss2: (0.0000) | Acc: (95.00%) (46730/48768)
Epoch: 159 | Batch_idx: 390 |  Loss: (0.1205) |  Loss2: (0.0000) | Acc: (95.00%) (47915/50000)
# TEST : Loss: (0.4007) | Acc: (88.00%) (8820/10000)
percent tensor([0.5137, 0.5149, 0.5175, 0.5175, 0.5174, 0.5182, 0.5164, 0.5191, 0.5140,
        0.5150, 0.5128, 0.5160, 0.5132, 0.5157, 0.5152, 0.5150],
       device='cuda:0') torch.Size([16])
percent tensor([0.5116, 0.5211, 0.5094, 0.5077, 0.5052, 0.5200, 0.5124, 0.5030, 0.5079,
        0.5157, 0.5129, 0.5118, 0.5213, 0.5100, 0.5174, 0.5175],
       device='cuda:0') torch.Size([16])
percent tensor([0.5961, 0.5335, 0.6629, 0.6780, 0.6681, 0.6188, 0.6040, 0.6500, 0.6462,
        0.5917, 0.6203, 0.6175, 0.5053, 0.6694, 0.5789, 0.5977],
       device='cuda:0') torch.Size([16])
percent tensor([0.6369, 0.6295, 0.6272, 0.6290, 0.6288, 0.6370, 0.6322, 0.6304, 0.6343,
        0.6375, 0.6360, 0.6350, 0.6327, 0.6296, 0.6331, 0.6475],
       device='cuda:0') torch.Size([16])
percent tensor([0.6371, 0.6233, 0.6449, 0.6670, 0.6688, 0.7787, 0.6066, 0.5986, 0.6375,
        0.6654, 0.6244, 0.6188, 0.6260, 0.6607, 0.6229, 0.7063],
       device='cuda:0') torch.Size([16])
percent tensor([0.6046, 0.6744, 0.6670, 0.6939, 0.6481, 0.7577, 0.6740, 0.5512, 0.7167,
        0.6548, 0.7390, 0.6544, 0.7296, 0.7229, 0.5515, 0.6427],
       device='cuda:0') torch.Size([16])
percent tensor([0.5855, 0.6355, 0.6473, 0.6689, 0.6682, 0.6784, 0.6537, 0.6304, 0.6038,
        0.6522, 0.6609, 0.6027, 0.6179, 0.5970, 0.5893, 0.5934],
       device='cuda:0') torch.Size([16])
percent tensor([0.9998, 0.9997, 0.9997, 0.9998, 0.9995, 0.9991, 0.9996, 0.9996, 0.9998,
        0.9998, 0.9999, 0.9997, 0.9999, 0.9996, 0.9993, 0.9995],
       device='cuda:0') torch.Size([16])
Epoch: 160 | Batch_idx: 0 |  Loss: (0.0811) |  Loss2: (0.0000) | Acc: (96.00%) (124/128)
Epoch: 160 | Batch_idx: 10 |  Loss: (0.0953) |  Loss2: (0.0000) | Acc: (96.00%) (1365/1408)
Epoch: 160 | Batch_idx: 20 |  Loss: (0.0971) |  Loss2: (0.0000) | Acc: (96.00%) (2601/2688)
Epoch: 160 | Batch_idx: 30 |  Loss: (0.1021) |  Loss2: (0.0000) | Acc: (96.00%) (3835/3968)
Epoch: 160 | Batch_idx: 40 |  Loss: (0.1032) |  Loss2: (0.0000) | Acc: (96.00%) (5068/5248)
Epoch: 160 | Batch_idx: 50 |  Loss: (0.1061) |  Loss2: (0.0000) | Acc: (96.00%) (6293/6528)
Epoch: 160 | Batch_idx: 60 |  Loss: (0.1048) |  Loss2: (0.0000) | Acc: (96.00%) (7532/7808)
Epoch: 160 | Batch_idx: 70 |  Loss: (0.1042) |  Loss2: (0.0000) | Acc: (96.00%) (8772/9088)
Epoch: 160 | Batch_idx: 80 |  Loss: (0.1036) |  Loss2: (0.0000) | Acc: (96.00%) (10006/10368)
Epoch: 160 | Batch_idx: 90 |  Loss: (0.1046) |  Loss2: (0.0000) | Acc: (96.00%) (11230/11648)
Epoch: 160 | Batch_idx: 100 |  Loss: (0.1050) |  Loss2: (0.0000) | Acc: (96.00%) (12460/12928)
Epoch: 160 | Batch_idx: 110 |  Loss: (0.1047) |  Loss2: (0.0000) | Acc: (96.00%) (13701/14208)
Epoch: 160 | Batch_idx: 120 |  Loss: (0.1052) |  Loss2: (0.0000) | Acc: (96.00%) (14940/15488)
Epoch: 160 | Batch_idx: 130 |  Loss: (0.1067) |  Loss2: (0.0000) | Acc: (96.00%) (16160/16768)
Epoch: 160 | Batch_idx: 140 |  Loss: (0.1075) |  Loss2: (0.0000) | Acc: (96.00%) (17396/18048)
Epoch: 160 | Batch_idx: 150 |  Loss: (0.1071) |  Loss2: (0.0000) | Acc: (96.00%) (18633/19328)
Epoch: 160 | Batch_idx: 160 |  Loss: (0.1072) |  Loss2: (0.0000) | Acc: (96.00%) (19864/20608)
Epoch: 160 | Batch_idx: 170 |  Loss: (0.1076) |  Loss2: (0.0000) | Acc: (96.00%) (21097/21888)
Epoch: 160 | Batch_idx: 180 |  Loss: (0.1065) |  Loss2: (0.0000) | Acc: (96.00%) (22341/23168)
Epoch: 160 | Batch_idx: 190 |  Loss: (0.1083) |  Loss2: (0.0000) | Acc: (96.00%) (23560/24448)
Epoch: 160 | Batch_idx: 200 |  Loss: (0.1080) |  Loss2: (0.0000) | Acc: (96.00%) (24797/25728)
Epoch: 160 | Batch_idx: 210 |  Loss: (0.1085) |  Loss2: (0.0000) | Acc: (96.00%) (26023/27008)
Epoch: 160 | Batch_idx: 220 |  Loss: (0.1089) |  Loss2: (0.0000) | Acc: (96.00%) (27258/28288)
Epoch: 160 | Batch_idx: 230 |  Loss: (0.1088) |  Loss2: (0.0000) | Acc: (96.00%) (28501/29568)
Epoch: 160 | Batch_idx: 240 |  Loss: (0.1095) |  Loss2: (0.0000) | Acc: (96.00%) (29727/30848)
Epoch: 160 | Batch_idx: 250 |  Loss: (0.1107) |  Loss2: (0.0000) | Acc: (96.00%) (30943/32128)
Epoch: 160 | Batch_idx: 260 |  Loss: (0.1110) |  Loss2: (0.0000) | Acc: (96.00%) (32172/33408)
Epoch: 160 | Batch_idx: 270 |  Loss: (0.1106) |  Loss2: (0.0000) | Acc: (96.00%) (33409/34688)
Epoch: 160 | Batch_idx: 280 |  Loss: (0.1111) |  Loss2: (0.0000) | Acc: (96.00%) (34623/35968)
Epoch: 160 | Batch_idx: 290 |  Loss: (0.1113) |  Loss2: (0.0000) | Acc: (96.00%) (35854/37248)
Epoch: 160 | Batch_idx: 300 |  Loss: (0.1121) |  Loss2: (0.0000) | Acc: (96.00%) (37071/38528)
Epoch: 160 | Batch_idx: 310 |  Loss: (0.1122) |  Loss2: (0.0000) | Acc: (96.00%) (38304/39808)
Epoch: 160 | Batch_idx: 320 |  Loss: (0.1124) |  Loss2: (0.0000) | Acc: (96.00%) (39529/41088)
Epoch: 160 | Batch_idx: 330 |  Loss: (0.1121) |  Loss2: (0.0000) | Acc: (96.00%) (40764/42368)
Epoch: 160 | Batch_idx: 340 |  Loss: (0.1124) |  Loss2: (0.0000) | Acc: (96.00%) (41992/43648)
Epoch: 160 | Batch_idx: 350 |  Loss: (0.1122) |  Loss2: (0.0000) | Acc: (96.00%) (43230/44928)
Epoch: 160 | Batch_idx: 360 |  Loss: (0.1123) |  Loss2: (0.0000) | Acc: (96.00%) (44463/46208)
Epoch: 160 | Batch_idx: 370 |  Loss: (0.1125) |  Loss2: (0.0000) | Acc: (96.00%) (45687/47488)
Epoch: 160 | Batch_idx: 380 |  Loss: (0.1128) |  Loss2: (0.0000) | Acc: (96.00%) (46913/48768)
Epoch: 160 | Batch_idx: 390 |  Loss: (0.1130) |  Loss2: (0.0000) | Acc: (96.00%) (48093/50000)
=> saving checkpoint 'drive/app/torch/save_Schedule/checkpoint_160.pth.tar'
# TEST : Loss: (0.3934) | Acc: (88.00%) (8831/10000)
percent tensor([0.5135, 0.5148, 0.5173, 0.5174, 0.5173, 0.5177, 0.5165, 0.5187, 0.5141,
        0.5150, 0.5124, 0.5160, 0.5132, 0.5161, 0.5149, 0.5147],
       device='cuda:0') torch.Size([16])
percent tensor([0.5135, 0.5204, 0.5139, 0.5081, 0.5075, 0.5201, 0.5126, 0.5040, 0.5093,
        0.5167, 0.5143, 0.5169, 0.5227, 0.5052, 0.5177, 0.5176],
       device='cuda:0') torch.Size([16])
percent tensor([0.5853, 0.5338, 0.6500, 0.6762, 0.6595, 0.6093, 0.5978, 0.6449, 0.6265,
        0.5839, 0.6014, 0.5952, 0.4938, 0.6598, 0.5725, 0.5902],
       device='cuda:0') torch.Size([16])
percent tensor([0.6345, 0.6277, 0.6288, 0.6287, 0.6308, 0.6335, 0.6330, 0.6283, 0.6347,
        0.6374, 0.6355, 0.6353, 0.6308, 0.6294, 0.6308, 0.6446],
       device='cuda:0') torch.Size([16])
percent tensor([0.6522, 0.6271, 0.6760, 0.6829, 0.6987, 0.7622, 0.6142, 0.6177, 0.6469,
        0.6785, 0.6273, 0.6404, 0.6384, 0.6570, 0.6290, 0.7149],
       device='cuda:0') torch.Size([16])
percent tensor([0.6100, 0.6854, 0.6770, 0.6947, 0.6772, 0.7512, 0.6803, 0.5517, 0.7151,
        0.6746, 0.7470, 0.6710, 0.7292, 0.7307, 0.5578, 0.6550],
       device='cuda:0') torch.Size([16])
percent tensor([0.5928, 0.6578, 0.6546, 0.6890, 0.7020, 0.6813, 0.6696, 0.6375, 0.6218,
        0.6718, 0.6826, 0.6042, 0.6144, 0.6037, 0.5925, 0.6057],
       device='cuda:0') torch.Size([16])
percent tensor([0.9998, 0.9998, 0.9997, 0.9997, 0.9995, 0.9988, 0.9997, 0.9993, 0.9999,
        0.9998, 0.9999, 0.9997, 0.9999, 0.9996, 0.9991, 0.9995],
       device='cuda:0') torch.Size([16])
Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 3, 3, 3]) tensor(180.6034, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(829.8607, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(827.4239, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([128, 64, 3, 3]) tensor(1517.3242, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([128, 64, 1, 1]) tensor(484.8062, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([128, 128, 3, 3]) tensor(2281.1687, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([256, 128, 3, 3]) tensor(4266.8643, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([256, 128, 1, 1]) tensor(1365.1278, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([256, 256, 3, 3]) tensor(6246.5171, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([512, 256, 3, 3]) tensor(11658.1025, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([512, 256, 1, 1]) tensor(3843.1431, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([512, 512, 3, 3]) tensor(16252.7070, device='cuda:0', grad_fn=<NormBackward0>)
Epoch: 161 | Batch_idx: 0 |  Loss: (0.0884) |  Loss2: (0.0000) | Acc: (96.00%) (124/128)
Epoch: 161 | Batch_idx: 10 |  Loss: (0.1087) |  Loss2: (0.0000) | Acc: (96.00%) (1353/1408)
Epoch: 161 | Batch_idx: 20 |  Loss: (0.1032) |  Loss2: (0.0000) | Acc: (96.00%) (2589/2688)
Epoch: 161 | Batch_idx: 30 |  Loss: (0.0998) |  Loss2: (0.0000) | Acc: (96.00%) (3828/3968)
Epoch: 161 | Batch_idx: 40 |  Loss: (0.1003) |  Loss2: (0.0000) | Acc: (96.00%) (5068/5248)
Epoch: 161 | Batch_idx: 50 |  Loss: (0.1031) |  Loss2: (0.0000) | Acc: (96.00%) (6293/6528)
Epoch: 161 | Batch_idx: 60 |  Loss: (0.1018) |  Loss2: (0.0000) | Acc: (96.00%) (7532/7808)
Epoch: 161 | Batch_idx: 70 |  Loss: (0.1057) |  Loss2: (0.0000) | Acc: (96.00%) (8755/9088)
Epoch: 161 | Batch_idx: 80 |  Loss: (0.1050) |  Loss2: (0.0000) | Acc: (96.00%) (10003/10368)
Epoch: 161 | Batch_idx: 90 |  Loss: (0.1069) |  Loss2: (0.0000) | Acc: (96.00%) (11232/11648)
Epoch: 161 | Batch_idx: 100 |  Loss: (0.1059) |  Loss2: (0.0000) | Acc: (96.00%) (12466/12928)
Epoch: 161 | Batch_idx: 110 |  Loss: (0.1073) |  Loss2: (0.0000) | Acc: (96.00%) (13699/14208)
Epoch: 161 | Batch_idx: 120 |  Loss: (0.1075) |  Loss2: (0.0000) | Acc: (96.00%) (14929/15488)
Epoch: 161 | Batch_idx: 130 |  Loss: (0.1081) |  Loss2: (0.0000) | Acc: (96.00%) (16160/16768)
Epoch: 161 | Batch_idx: 140 |  Loss: (0.1086) |  Loss2: (0.0000) | Acc: (96.00%) (17388/18048)
Epoch: 161 | Batch_idx: 150 |  Loss: (0.1090) |  Loss2: (0.0000) | Acc: (96.00%) (18616/19328)
Epoch: 161 | Batch_idx: 160 |  Loss: (0.1081) |  Loss2: (0.0000) | Acc: (96.00%) (19856/20608)
Epoch: 161 | Batch_idx: 170 |  Loss: (0.1086) |  Loss2: (0.0000) | Acc: (96.00%) (21080/21888)
Epoch: 161 | Batch_idx: 180 |  Loss: (0.1078) |  Loss2: (0.0000) | Acc: (96.00%) (22328/23168)
Epoch: 161 | Batch_idx: 190 |  Loss: (0.1077) |  Loss2: (0.0000) | Acc: (96.00%) (23563/24448)
Epoch: 161 | Batch_idx: 200 |  Loss: (0.1079) |  Loss2: (0.0000) | Acc: (96.00%) (24793/25728)
Epoch: 161 | Batch_idx: 210 |  Loss: (0.1074) |  Loss2: (0.0000) | Acc: (96.00%) (26032/27008)
Epoch: 161 | Batch_idx: 220 |  Loss: (0.1074) |  Loss2: (0.0000) | Acc: (96.00%) (27270/28288)
Epoch: 161 | Batch_idx: 230 |  Loss: (0.1067) |  Loss2: (0.0000) | Acc: (96.00%) (28508/29568)
Epoch: 161 | Batch_idx: 240 |  Loss: (0.1061) |  Loss2: (0.0000) | Acc: (96.00%) (29753/30848)
Epoch: 161 | Batch_idx: 250 |  Loss: (0.1073) |  Loss2: (0.0000) | Acc: (96.00%) (30967/32128)
Epoch: 161 | Batch_idx: 260 |  Loss: (0.1070) |  Loss2: (0.0000) | Acc: (96.00%) (32195/33408)
Epoch: 161 | Batch_idx: 270 |  Loss: (0.1070) |  Loss2: (0.0000) | Acc: (96.00%) (33430/34688)
Epoch: 161 | Batch_idx: 280 |  Loss: (0.1069) |  Loss2: (0.0000) | Acc: (96.00%) (34667/35968)
Epoch: 161 | Batch_idx: 290 |  Loss: (0.1065) |  Loss2: (0.0000) | Acc: (96.00%) (35909/37248)
Epoch: 161 | Batch_idx: 300 |  Loss: (0.1061) |  Loss2: (0.0000) | Acc: (96.00%) (37145/38528)
Epoch: 161 | Batch_idx: 310 |  Loss: (0.1057) |  Loss2: (0.0000) | Acc: (96.00%) (38390/39808)
Epoch: 161 | Batch_idx: 320 |  Loss: (0.1059) |  Loss2: (0.0000) | Acc: (96.00%) (39617/41088)
Epoch: 161 | Batch_idx: 330 |  Loss: (0.1064) |  Loss2: (0.0000) | Acc: (96.00%) (40839/42368)
Epoch: 161 | Batch_idx: 340 |  Loss: (0.1064) |  Loss2: (0.0000) | Acc: (96.00%) (42067/43648)
Epoch: 161 | Batch_idx: 350 |  Loss: (0.1066) |  Loss2: (0.0000) | Acc: (96.00%) (43300/44928)
Epoch: 161 | Batch_idx: 360 |  Loss: (0.1068) |  Loss2: (0.0000) | Acc: (96.00%) (44536/46208)
Epoch: 161 | Batch_idx: 370 |  Loss: (0.1075) |  Loss2: (0.0000) | Acc: (96.00%) (45752/47488)
Epoch: 161 | Batch_idx: 380 |  Loss: (0.1084) |  Loss2: (0.0000) | Acc: (96.00%) (46968/48768)
Epoch: 161 | Batch_idx: 390 |  Loss: (0.1084) |  Loss2: (0.0000) | Acc: (96.00%) (48155/50000)
# TEST : Loss: (0.4300) | Acc: (87.00%) (8724/10000)
percent tensor([0.5133, 0.5149, 0.5157, 0.5169, 0.5159, 0.5175, 0.5161, 0.5182, 0.5140,
        0.5147, 0.5129, 0.5148, 0.5131, 0.5163, 0.5148, 0.5148],
       device='cuda:0') torch.Size([16])
percent tensor([0.5113, 0.5183, 0.5105, 0.5057, 0.5047, 0.5196, 0.5110, 0.5022, 0.5080,
        0.5139, 0.5122, 0.5126, 0.5203, 0.5053, 0.5160, 0.5159],
       device='cuda:0') torch.Size([16])
percent tensor([0.5961, 0.5501, 0.6550, 0.6733, 0.6661, 0.6142, 0.6123, 0.6518, 0.6393,
        0.5974, 0.6179, 0.6090, 0.5102, 0.6661, 0.5865, 0.6004],
       device='cuda:0') torch.Size([16])
percent tensor([0.6358, 0.6289, 0.6257, 0.6295, 0.6279, 0.6324, 0.6347, 0.6273, 0.6390,
        0.6383, 0.6402, 0.6326, 0.6344, 0.6336, 0.6329, 0.6464],
       device='cuda:0') torch.Size([16])
percent tensor([0.6454, 0.6268, 0.6768, 0.6802, 0.6819, 0.7562, 0.6155, 0.6229, 0.6489,
        0.6834, 0.6296, 0.6373, 0.6383, 0.6632, 0.6301, 0.7104],
       device='cuda:0') torch.Size([16])
percent tensor([0.6222, 0.6878, 0.6703, 0.6938, 0.6788, 0.7549, 0.6862, 0.5659, 0.6999,
        0.6667, 0.7320, 0.6644, 0.7149, 0.7359, 0.5591, 0.6698],
       device='cuda:0') torch.Size([16])
percent tensor([0.5900, 0.6617, 0.6525, 0.6796, 0.7074, 0.6658, 0.6595, 0.6498, 0.6016,
        0.6549, 0.6480, 0.5994, 0.6049, 0.5919, 0.5916, 0.6043],
       device='cuda:0') torch.Size([16])
percent tensor([0.9998, 0.9997, 0.9998, 0.9999, 0.9997, 0.9992, 0.9997, 0.9997, 0.9999,
        0.9998, 0.9999, 0.9997, 0.9999, 0.9995, 0.9993, 0.9995],
       device='cuda:0') torch.Size([16])
False Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=128, out_features=16, bias=False)
True Linear(in_features=16, out_features=2, bias=False)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=128, out_features=16, bias=False)
True Linear(in_features=16, out_features=2, bias=False)
False Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=256, out_features=32, bias=False)
True Linear(in_features=32, out_features=2, bias=False)
False Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=256, out_features=32, bias=False)
True Linear(in_features=32, out_features=2, bias=False)
False Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=512, out_features=64, bias=False)
True Linear(in_features=64, out_features=2, bias=False)
False Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=512, out_features=64, bias=False)
True Linear(in_features=64, out_features=2, bias=False)
False Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1024, out_features=128, bias=False)
True Linear(in_features=128, out_features=2, bias=False)
False Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1024, out_features=128, bias=False)
True Linear(in_features=128, out_features=2, bias=False)
False Linear(in_features=512, out_features=10, bias=True)
Epoch: 162 | Batch_idx: 0 |  Loss: (0.0768) |  Loss2: (0.0000) | Acc: (96.00%) (124/128)
Epoch: 162 | Batch_idx: 10 |  Loss: (0.0994) |  Loss2: (0.0000) | Acc: (96.00%) (1365/1408)
Epoch: 162 | Batch_idx: 20 |  Loss: (0.1154) |  Loss2: (0.0000) | Acc: (96.00%) (2587/2688)
Epoch: 162 | Batch_idx: 30 |  Loss: (0.1251) |  Loss2: (0.0000) | Acc: (95.00%) (3798/3968)
Epoch: 162 | Batch_idx: 40 |  Loss: (0.1283) |  Loss2: (0.0000) | Acc: (95.00%) (5014/5248)
Epoch: 162 | Batch_idx: 50 |  Loss: (0.1303) |  Loss2: (0.0000) | Acc: (95.00%) (6233/6528)
Epoch: 162 | Batch_idx: 60 |  Loss: (0.1353) |  Loss2: (0.0000) | Acc: (95.00%) (7434/7808)
Epoch: 162 | Batch_idx: 70 |  Loss: (0.1361) |  Loss2: (0.0000) | Acc: (95.00%) (8649/9088)
Epoch: 162 | Batch_idx: 80 |  Loss: (0.1397) |  Loss2: (0.0000) | Acc: (95.00%) (9860/10368)
Epoch: 162 | Batch_idx: 90 |  Loss: (0.1395) |  Loss2: (0.0000) | Acc: (95.00%) (11077/11648)
Epoch: 162 | Batch_idx: 100 |  Loss: (0.1399) |  Loss2: (0.0000) | Acc: (95.00%) (12292/12928)
Epoch: 162 | Batch_idx: 110 |  Loss: (0.1390) |  Loss2: (0.0000) | Acc: (95.00%) (13513/14208)
Epoch: 162 | Batch_idx: 120 |  Loss: (0.1373) |  Loss2: (0.0000) | Acc: (95.00%) (14746/15488)
Epoch: 162 | Batch_idx: 130 |  Loss: (0.1386) |  Loss2: (0.0000) | Acc: (95.00%) (15953/16768)
Epoch: 162 | Batch_idx: 140 |  Loss: (0.1383) |  Loss2: (0.0000) | Acc: (95.00%) (17170/18048)
Epoch: 162 | Batch_idx: 150 |  Loss: (0.1377) |  Loss2: (0.0000) | Acc: (95.00%) (18395/19328)
Epoch: 162 | Batch_idx: 160 |  Loss: (0.1377) |  Loss2: (0.0000) | Acc: (95.00%) (19610/20608)
Epoch: 162 | Batch_idx: 170 |  Loss: (0.1371) |  Loss2: (0.0000) | Acc: (95.00%) (20830/21888)
Epoch: 162 | Batch_idx: 180 |  Loss: (0.1371) |  Loss2: (0.0000) | Acc: (95.00%) (22046/23168)
Epoch: 162 | Batch_idx: 190 |  Loss: (0.1370) |  Loss2: (0.0000) | Acc: (95.00%) (23254/24448)
Epoch: 162 | Batch_idx: 200 |  Loss: (0.1361) |  Loss2: (0.0000) | Acc: (95.00%) (24479/25728)
Epoch: 162 | Batch_idx: 210 |  Loss: (0.1358) |  Loss2: (0.0000) | Acc: (95.00%) (25698/27008)
Epoch: 162 | Batch_idx: 220 |  Loss: (0.1352) |  Loss2: (0.0000) | Acc: (95.00%) (26925/28288)
Epoch: 162 | Batch_idx: 230 |  Loss: (0.1349) |  Loss2: (0.0000) | Acc: (95.00%) (28149/29568)
Epoch: 162 | Batch_idx: 240 |  Loss: (0.1341) |  Loss2: (0.0000) | Acc: (95.00%) (29377/30848)
Epoch: 162 | Batch_idx: 250 |  Loss: (0.1338) |  Loss2: (0.0000) | Acc: (95.00%) (30596/32128)
Epoch: 162 | Batch_idx: 260 |  Loss: (0.1337) |  Loss2: (0.0000) | Acc: (95.00%) (31819/33408)
Epoch: 162 | Batch_idx: 270 |  Loss: (0.1338) |  Loss2: (0.0000) | Acc: (95.00%) (33033/34688)
Epoch: 162 | Batch_idx: 280 |  Loss: (0.1334) |  Loss2: (0.0000) | Acc: (95.00%) (34258/35968)
Epoch: 162 | Batch_idx: 290 |  Loss: (0.1330) |  Loss2: (0.0000) | Acc: (95.00%) (35483/37248)
Epoch: 162 | Batch_idx: 300 |  Loss: (0.1336) |  Loss2: (0.0000) | Acc: (95.00%) (36694/38528)
Epoch: 162 | Batch_idx: 310 |  Loss: (0.1335) |  Loss2: (0.0000) | Acc: (95.00%) (37916/39808)
Epoch: 162 | Batch_idx: 320 |  Loss: (0.1336) |  Loss2: (0.0000) | Acc: (95.00%) (39138/41088)
Epoch: 162 | Batch_idx: 330 |  Loss: (0.1329) |  Loss2: (0.0000) | Acc: (95.00%) (40368/42368)
Epoch: 162 | Batch_idx: 340 |  Loss: (0.1327) |  Loss2: (0.0000) | Acc: (95.00%) (41588/43648)
Epoch: 162 | Batch_idx: 350 |  Loss: (0.1314) |  Loss2: (0.0000) | Acc: (95.00%) (42825/44928)
Epoch: 162 | Batch_idx: 360 |  Loss: (0.1314) |  Loss2: (0.0000) | Acc: (95.00%) (44048/46208)
Epoch: 162 | Batch_idx: 370 |  Loss: (0.1312) |  Loss2: (0.0000) | Acc: (95.00%) (45271/47488)
Epoch: 162 | Batch_idx: 380 |  Loss: (0.1311) |  Loss2: (0.0000) | Acc: (95.00%) (46491/48768)
Epoch: 162 | Batch_idx: 390 |  Loss: (0.1316) |  Loss2: (0.0000) | Acc: (95.00%) (47650/50000)
# TEST : Loss: (0.4090) | Acc: (87.00%) (8767/10000)
percent tensor([0.5121, 0.5134, 0.5137, 0.5156, 0.5139, 0.5167, 0.5145, 0.5163, 0.5125,
        0.5130, 0.5116, 0.5129, 0.5117, 0.5153, 0.5137, 0.5137],
       device='cuda:0') torch.Size([16])
percent tensor([0.5161, 0.5210, 0.5178, 0.5115, 0.5106, 0.5215, 0.5148, 0.5078, 0.5120,
        0.5181, 0.5150, 0.5183, 0.5239, 0.5069, 0.5193, 0.5195],
       device='cuda:0') torch.Size([16])
percent tensor([0.5749, 0.5322, 0.6293, 0.6556, 0.6472, 0.6048, 0.5923, 0.6308, 0.6196,
        0.5718, 0.5990, 0.5879, 0.4898, 0.6476, 0.5697, 0.5803],
       device='cuda:0') torch.Size([16])
percent tensor([0.6354, 0.6291, 0.6277, 0.6297, 0.6290, 0.6294, 0.6353, 0.6283, 0.6378,
        0.6371, 0.6379, 0.6332, 0.6319, 0.6337, 0.6332, 0.6440],
       device='cuda:0') torch.Size([16])
percent tensor([0.6315, 0.6038, 0.6620, 0.6574, 0.6668, 0.7308, 0.5991, 0.6050, 0.6292,
        0.6607, 0.6111, 0.6173, 0.6232, 0.6413, 0.6041, 0.6921],
       device='cuda:0') torch.Size([16])
percent tensor([0.6167, 0.6862, 0.6604, 0.6922, 0.6768, 0.7514, 0.6913, 0.5621, 0.7027,
        0.6708, 0.7319, 0.6584, 0.7182, 0.7319, 0.5514, 0.6618],
       device='cuda:0') torch.Size([16])
percent tensor([0.5596, 0.6446, 0.6385, 0.6726, 0.7043, 0.6353, 0.6422, 0.6366, 0.5908,
        0.6458, 0.6389, 0.5849, 0.5938, 0.5721, 0.5710, 0.5691],
       device='cuda:0') torch.Size([16])
percent tensor([0.9998, 0.9997, 0.9998, 0.9999, 0.9997, 0.9993, 0.9997, 0.9996, 0.9998,
        0.9998, 0.9999, 0.9997, 0.9999, 0.9995, 0.9993, 0.9994],
       device='cuda:0') torch.Size([16])
Epoch: 163 | Batch_idx: 0 |  Loss: (0.0959) |  Loss2: (0.0000) | Acc: (95.00%) (122/128)
Epoch: 163 | Batch_idx: 10 |  Loss: (0.1137) |  Loss2: (0.0000) | Acc: (95.00%) (1346/1408)
Epoch: 163 | Batch_idx: 20 |  Loss: (0.1167) |  Loss2: (0.0000) | Acc: (95.00%) (2572/2688)
Epoch: 163 | Batch_idx: 30 |  Loss: (0.1218) |  Loss2: (0.0000) | Acc: (95.00%) (3790/3968)
Epoch: 163 | Batch_idx: 40 |  Loss: (0.1212) |  Loss2: (0.0000) | Acc: (95.00%) (5023/5248)
Epoch: 163 | Batch_idx: 50 |  Loss: (0.1171) |  Loss2: (0.0000) | Acc: (95.00%) (6258/6528)
Epoch: 163 | Batch_idx: 60 |  Loss: (0.1197) |  Loss2: (0.0000) | Acc: (95.00%) (7482/7808)
Epoch: 163 | Batch_idx: 70 |  Loss: (0.1195) |  Loss2: (0.0000) | Acc: (95.00%) (8712/9088)
Epoch: 163 | Batch_idx: 80 |  Loss: (0.1187) |  Loss2: (0.0000) | Acc: (95.00%) (9945/10368)
Epoch: 163 | Batch_idx: 90 |  Loss: (0.1209) |  Loss2: (0.0000) | Acc: (95.00%) (11168/11648)
Epoch: 163 | Batch_idx: 100 |  Loss: (0.1207) |  Loss2: (0.0000) | Acc: (95.00%) (12396/12928)
Epoch: 163 | Batch_idx: 110 |  Loss: (0.1202) |  Loss2: (0.0000) | Acc: (95.00%) (13629/14208)
Epoch: 163 | Batch_idx: 120 |  Loss: (0.1205) |  Loss2: (0.0000) | Acc: (95.00%) (14844/15488)
Epoch: 163 | Batch_idx: 130 |  Loss: (0.1204) |  Loss2: (0.0000) | Acc: (95.00%) (16073/16768)
Epoch: 163 | Batch_idx: 140 |  Loss: (0.1201) |  Loss2: (0.0000) | Acc: (95.00%) (17302/18048)
Epoch: 163 | Batch_idx: 150 |  Loss: (0.1191) |  Loss2: (0.0000) | Acc: (95.00%) (18539/19328)
Epoch: 163 | Batch_idx: 160 |  Loss: (0.1192) |  Loss2: (0.0000) | Acc: (95.00%) (19769/20608)
Epoch: 163 | Batch_idx: 170 |  Loss: (0.1211) |  Loss2: (0.0000) | Acc: (95.00%) (20986/21888)
Epoch: 163 | Batch_idx: 180 |  Loss: (0.1202) |  Loss2: (0.0000) | Acc: (95.00%) (22227/23168)
Epoch: 163 | Batch_idx: 190 |  Loss: (0.1209) |  Loss2: (0.0000) | Acc: (95.00%) (23450/24448)
Epoch: 163 | Batch_idx: 200 |  Loss: (0.1209) |  Loss2: (0.0000) | Acc: (95.00%) (24680/25728)
Epoch: 163 | Batch_idx: 210 |  Loss: (0.1217) |  Loss2: (0.0000) | Acc: (95.00%) (25898/27008)
Epoch: 163 | Batch_idx: 220 |  Loss: (0.1221) |  Loss2: (0.0000) | Acc: (95.00%) (27127/28288)
Epoch: 163 | Batch_idx: 230 |  Loss: (0.1221) |  Loss2: (0.0000) | Acc: (95.00%) (28351/29568)
Epoch: 163 | Batch_idx: 240 |  Loss: (0.1219) |  Loss2: (0.0000) | Acc: (95.00%) (29580/30848)
Epoch: 163 | Batch_idx: 250 |  Loss: (0.1212) |  Loss2: (0.0000) | Acc: (95.00%) (30813/32128)
Epoch: 163 | Batch_idx: 260 |  Loss: (0.1215) |  Loss2: (0.0000) | Acc: (95.00%) (32040/33408)
Epoch: 163 | Batch_idx: 270 |  Loss: (0.1212) |  Loss2: (0.0000) | Acc: (95.00%) (33267/34688)
Epoch: 163 | Batch_idx: 280 |  Loss: (0.1209) |  Loss2: (0.0000) | Acc: (95.00%) (34499/35968)
Epoch: 163 | Batch_idx: 290 |  Loss: (0.1204) |  Loss2: (0.0000) | Acc: (95.00%) (35737/37248)
Epoch: 163 | Batch_idx: 300 |  Loss: (0.1205) |  Loss2: (0.0000) | Acc: (95.00%) (36959/38528)
Epoch: 163 | Batch_idx: 310 |  Loss: (0.1205) |  Loss2: (0.0000) | Acc: (95.00%) (38190/39808)
Epoch: 163 | Batch_idx: 320 |  Loss: (0.1198) |  Loss2: (0.0000) | Acc: (95.00%) (39424/41088)
Epoch: 163 | Batch_idx: 330 |  Loss: (0.1200) |  Loss2: (0.0000) | Acc: (95.00%) (40641/42368)
Epoch: 163 | Batch_idx: 340 |  Loss: (0.1197) |  Loss2: (0.0000) | Acc: (95.00%) (41875/43648)
Epoch: 163 | Batch_idx: 350 |  Loss: (0.1191) |  Loss2: (0.0000) | Acc: (95.00%) (43109/44928)
Epoch: 163 | Batch_idx: 360 |  Loss: (0.1189) |  Loss2: (0.0000) | Acc: (95.00%) (44339/46208)
Epoch: 163 | Batch_idx: 370 |  Loss: (0.1192) |  Loss2: (0.0000) | Acc: (95.00%) (45565/47488)
Epoch: 163 | Batch_idx: 380 |  Loss: (0.1195) |  Loss2: (0.0000) | Acc: (95.00%) (46779/48768)
Epoch: 163 | Batch_idx: 390 |  Loss: (0.1189) |  Loss2: (0.0000) | Acc: (95.00%) (47977/50000)
# TEST : Loss: (0.3943) | Acc: (88.00%) (8810/10000)
percent tensor([0.5115, 0.5126, 0.5131, 0.5150, 0.5133, 0.5159, 0.5138, 0.5157, 0.5118,
        0.5124, 0.5109, 0.5122, 0.5110, 0.5147, 0.5129, 0.5131],
       device='cuda:0') torch.Size([16])
percent tensor([0.5197, 0.5252, 0.5221, 0.5157, 0.5149, 0.5238, 0.5192, 0.5123, 0.5158,
        0.5224, 0.5189, 0.5225, 0.5273, 0.5110, 0.5233, 0.5233],
       device='cuda:0') torch.Size([16])
percent tensor([0.5748, 0.5347, 0.6301, 0.6551, 0.6483, 0.6067, 0.5929, 0.6307, 0.6221,
        0.5716, 0.6007, 0.5907, 0.4919, 0.6484, 0.5710, 0.5793],
       device='cuda:0') torch.Size([16])
percent tensor([0.6391, 0.6326, 0.6314, 0.6338, 0.6337, 0.6327, 0.6396, 0.6338, 0.6412,
        0.6405, 0.6409, 0.6371, 0.6344, 0.6372, 0.6376, 0.6470],
       device='cuda:0') torch.Size([16])
percent tensor([0.6426, 0.6109, 0.6627, 0.6614, 0.6706, 0.7364, 0.6088, 0.6117, 0.6352,
        0.6660, 0.6207, 0.6163, 0.6303, 0.6510, 0.6131, 0.6992],
       device='cuda:0') torch.Size([16])
percent tensor([0.6237, 0.6914, 0.6710, 0.7012, 0.6871, 0.7561, 0.6982, 0.5700, 0.7087,
        0.6788, 0.7382, 0.6678, 0.7220, 0.7383, 0.5583, 0.6687],
       device='cuda:0') torch.Size([16])
percent tensor([0.5590, 0.6497, 0.6507, 0.6782, 0.7106, 0.6350, 0.6429, 0.6420, 0.5951,
        0.6513, 0.6416, 0.5943, 0.5953, 0.5742, 0.5723, 0.5638],
       device='cuda:0') torch.Size([16])
percent tensor([0.9998, 0.9997, 0.9998, 0.9999, 0.9996, 0.9992, 0.9997, 0.9995, 0.9998,
        0.9998, 0.9999, 0.9997, 0.9999, 0.9995, 0.9993, 0.9994],
       device='cuda:0') torch.Size([16])
Epoch: 164 | Batch_idx: 0 |  Loss: (0.0953) |  Loss2: (0.0000) | Acc: (97.00%) (125/128)
Epoch: 164 | Batch_idx: 10 |  Loss: (0.1187) |  Loss2: (0.0000) | Acc: (96.00%) (1353/1408)
Epoch: 164 | Batch_idx: 20 |  Loss: (0.1214) |  Loss2: (0.0000) | Acc: (96.00%) (2581/2688)
Epoch: 164 | Batch_idx: 30 |  Loss: (0.1197) |  Loss2: (0.0000) | Acc: (95.00%) (3809/3968)
Epoch: 164 | Batch_idx: 40 |  Loss: (0.1190) |  Loss2: (0.0000) | Acc: (95.00%) (5034/5248)
Epoch: 164 | Batch_idx: 50 |  Loss: (0.1235) |  Loss2: (0.0000) | Acc: (95.00%) (6257/6528)
Epoch: 164 | Batch_idx: 60 |  Loss: (0.1211) |  Loss2: (0.0000) | Acc: (95.00%) (7495/7808)
Epoch: 164 | Batch_idx: 70 |  Loss: (0.1203) |  Loss2: (0.0000) | Acc: (95.00%) (8723/9088)
Epoch: 164 | Batch_idx: 80 |  Loss: (0.1195) |  Loss2: (0.0000) | Acc: (95.00%) (9950/10368)
Epoch: 164 | Batch_idx: 90 |  Loss: (0.1192) |  Loss2: (0.0000) | Acc: (95.00%) (11178/11648)
Epoch: 164 | Batch_idx: 100 |  Loss: (0.1188) |  Loss2: (0.0000) | Acc: (95.00%) (12405/12928)
Epoch: 164 | Batch_idx: 110 |  Loss: (0.1186) |  Loss2: (0.0000) | Acc: (95.00%) (13639/14208)
Epoch: 164 | Batch_idx: 120 |  Loss: (0.1185) |  Loss2: (0.0000) | Acc: (95.00%) (14868/15488)
Epoch: 164 | Batch_idx: 130 |  Loss: (0.1181) |  Loss2: (0.0000) | Acc: (95.00%) (16092/16768)
Epoch: 164 | Batch_idx: 140 |  Loss: (0.1176) |  Loss2: (0.0000) | Acc: (95.00%) (17326/18048)
Epoch: 164 | Batch_idx: 150 |  Loss: (0.1170) |  Loss2: (0.0000) | Acc: (95.00%) (18553/19328)
Epoch: 164 | Batch_idx: 160 |  Loss: (0.1167) |  Loss2: (0.0000) | Acc: (96.00%) (19786/20608)
Epoch: 164 | Batch_idx: 170 |  Loss: (0.1168) |  Loss2: (0.0000) | Acc: (96.00%) (21014/21888)
Epoch: 164 | Batch_idx: 180 |  Loss: (0.1169) |  Loss2: (0.0000) | Acc: (96.00%) (22243/23168)
Epoch: 164 | Batch_idx: 190 |  Loss: (0.1159) |  Loss2: (0.0000) | Acc: (96.00%) (23485/24448)
Epoch: 164 | Batch_idx: 200 |  Loss: (0.1155) |  Loss2: (0.0000) | Acc: (96.00%) (24719/25728)
Epoch: 164 | Batch_idx: 210 |  Loss: (0.1154) |  Loss2: (0.0000) | Acc: (96.00%) (25948/27008)
Epoch: 164 | Batch_idx: 220 |  Loss: (0.1154) |  Loss2: (0.0000) | Acc: (96.00%) (27175/28288)
Epoch: 164 | Batch_idx: 230 |  Loss: (0.1159) |  Loss2: (0.0000) | Acc: (96.00%) (28388/29568)
Epoch: 164 | Batch_idx: 240 |  Loss: (0.1160) |  Loss2: (0.0000) | Acc: (96.00%) (29618/30848)
Epoch: 164 | Batch_idx: 250 |  Loss: (0.1156) |  Loss2: (0.0000) | Acc: (96.00%) (30848/32128)
Epoch: 164 | Batch_idx: 260 |  Loss: (0.1152) |  Loss2: (0.0000) | Acc: (96.00%) (32081/33408)
Epoch: 164 | Batch_idx: 270 |  Loss: (0.1146) |  Loss2: (0.0000) | Acc: (96.00%) (33321/34688)
Epoch: 164 | Batch_idx: 280 |  Loss: (0.1149) |  Loss2: (0.0000) | Acc: (96.00%) (34557/35968)
Epoch: 164 | Batch_idx: 290 |  Loss: (0.1142) |  Loss2: (0.0000) | Acc: (96.00%) (35803/37248)
Epoch: 164 | Batch_idx: 300 |  Loss: (0.1144) |  Loss2: (0.0000) | Acc: (96.00%) (37028/38528)
Epoch: 164 | Batch_idx: 310 |  Loss: (0.1139) |  Loss2: (0.0000) | Acc: (96.00%) (38270/39808)
Epoch: 164 | Batch_idx: 320 |  Loss: (0.1134) |  Loss2: (0.0000) | Acc: (96.00%) (39509/41088)
Epoch: 164 | Batch_idx: 330 |  Loss: (0.1141) |  Loss2: (0.0000) | Acc: (96.00%) (40740/42368)
Epoch: 164 | Batch_idx: 340 |  Loss: (0.1140) |  Loss2: (0.0000) | Acc: (96.00%) (41967/43648)
Epoch: 164 | Batch_idx: 350 |  Loss: (0.1134) |  Loss2: (0.0000) | Acc: (96.00%) (43209/44928)
Epoch: 164 | Batch_idx: 360 |  Loss: (0.1129) |  Loss2: (0.0000) | Acc: (96.00%) (44446/46208)
Epoch: 164 | Batch_idx: 370 |  Loss: (0.1122) |  Loss2: (0.0000) | Acc: (96.00%) (45687/47488)
Epoch: 164 | Batch_idx: 380 |  Loss: (0.1120) |  Loss2: (0.0000) | Acc: (96.00%) (46927/48768)
Epoch: 164 | Batch_idx: 390 |  Loss: (0.1123) |  Loss2: (0.0000) | Acc: (96.00%) (48111/50000)
# TEST : Loss: (0.3870) | Acc: (88.00%) (8817/10000)
percent tensor([0.5109, 0.5116, 0.5125, 0.5145, 0.5126, 0.5154, 0.5128, 0.5151, 0.5111,
        0.5115, 0.5101, 0.5114, 0.5103, 0.5139, 0.5122, 0.5125],
       device='cuda:0') torch.Size([16])
percent tensor([0.5181, 0.5227, 0.5203, 0.5141, 0.5132, 0.5228, 0.5170, 0.5108, 0.5137,
        0.5200, 0.5166, 0.5204, 0.5251, 0.5090, 0.5213, 0.5216],
       device='cuda:0') torch.Size([16])
percent tensor([0.5776, 0.5350, 0.6321, 0.6592, 0.6502, 0.6138, 0.5926, 0.6318, 0.6257,
        0.5715, 0.6040, 0.5935, 0.4948, 0.6505, 0.5728, 0.5824],
       device='cuda:0') torch.Size([16])
percent tensor([0.6380, 0.6306, 0.6311, 0.6336, 0.6337, 0.6316, 0.6386, 0.6342, 0.6400,
        0.6384, 0.6383, 0.6363, 0.6322, 0.6354, 0.6364, 0.6450],
       device='cuda:0') torch.Size([16])
percent tensor([0.6402, 0.6102, 0.6604, 0.6634, 0.6715, 0.7360, 0.6107, 0.6141, 0.6339,
        0.6625, 0.6174, 0.6126, 0.6260, 0.6555, 0.6132, 0.6970],
       device='cuda:0') torch.Size([16])
percent tensor([0.6021, 0.6769, 0.6578, 0.6882, 0.6724, 0.7423, 0.6815, 0.5440, 0.6939,
        0.6589, 0.7237, 0.6505, 0.7089, 0.7208, 0.5331, 0.6468],
       device='cuda:0') torch.Size([16])
percent tensor([0.5560, 0.6521, 0.6566, 0.6795, 0.7125, 0.6312, 0.6442, 0.6388, 0.5972,
        0.6522, 0.6450, 0.5957, 0.6000, 0.5736, 0.5709, 0.5550],
       device='cuda:0') torch.Size([16])
percent tensor([0.9999, 0.9997, 0.9998, 0.9999, 0.9997, 0.9993, 0.9997, 0.9996, 0.9998,
        0.9998, 0.9999, 0.9997, 0.9999, 0.9995, 0.9994, 0.9995],
       device='cuda:0') torch.Size([16])
Epoch: 165 | Batch_idx: 0 |  Loss: (0.1107) |  Loss2: (0.0000) | Acc: (96.00%) (124/128)
Epoch: 165 | Batch_idx: 10 |  Loss: (0.0903) |  Loss2: (0.0000) | Acc: (96.00%) (1364/1408)
Epoch: 165 | Batch_idx: 20 |  Loss: (0.0994) |  Loss2: (0.0000) | Acc: (96.00%) (2595/2688)
Epoch: 165 | Batch_idx: 30 |  Loss: (0.1063) |  Loss2: (0.0000) | Acc: (96.00%) (3820/3968)
Epoch: 165 | Batch_idx: 40 |  Loss: (0.1112) |  Loss2: (0.0000) | Acc: (96.00%) (5049/5248)
Epoch: 165 | Batch_idx: 50 |  Loss: (0.1076) |  Loss2: (0.0000) | Acc: (96.00%) (6293/6528)
Epoch: 165 | Batch_idx: 60 |  Loss: (0.1103) |  Loss2: (0.0000) | Acc: (96.00%) (7517/7808)
Epoch: 165 | Batch_idx: 70 |  Loss: (0.1090) |  Loss2: (0.0000) | Acc: (96.00%) (8752/9088)
Epoch: 165 | Batch_idx: 80 |  Loss: (0.1114) |  Loss2: (0.0000) | Acc: (96.00%) (9980/10368)
Epoch: 165 | Batch_idx: 90 |  Loss: (0.1092) |  Loss2: (0.0000) | Acc: (96.00%) (11222/11648)
Epoch: 165 | Batch_idx: 100 |  Loss: (0.1072) |  Loss2: (0.0000) | Acc: (96.00%) (12465/12928)
Epoch: 165 | Batch_idx: 110 |  Loss: (0.1080) |  Loss2: (0.0000) | Acc: (96.00%) (13698/14208)
Epoch: 165 | Batch_idx: 120 |  Loss: (0.1074) |  Loss2: (0.0000) | Acc: (96.00%) (14931/15488)
Epoch: 165 | Batch_idx: 130 |  Loss: (0.1083) |  Loss2: (0.0000) | Acc: (96.00%) (16164/16768)
Epoch: 165 | Batch_idx: 140 |  Loss: (0.1075) |  Loss2: (0.0000) | Acc: (96.00%) (17406/18048)
Epoch: 165 | Batch_idx: 150 |  Loss: (0.1074) |  Loss2: (0.0000) | Acc: (96.00%) (18648/19328)
Epoch: 165 | Batch_idx: 160 |  Loss: (0.1079) |  Loss2: (0.0000) | Acc: (96.00%) (19872/20608)
Epoch: 165 | Batch_idx: 170 |  Loss: (0.1082) |  Loss2: (0.0000) | Acc: (96.00%) (21104/21888)
Epoch: 165 | Batch_idx: 180 |  Loss: (0.1079) |  Loss2: (0.0000) | Acc: (96.00%) (22341/23168)
Epoch: 165 | Batch_idx: 190 |  Loss: (0.1080) |  Loss2: (0.0000) | Acc: (96.00%) (23570/24448)
Epoch: 165 | Batch_idx: 200 |  Loss: (0.1085) |  Loss2: (0.0000) | Acc: (96.00%) (24799/25728)
Epoch: 165 | Batch_idx: 210 |  Loss: (0.1084) |  Loss2: (0.0000) | Acc: (96.00%) (26039/27008)
Epoch: 165 | Batch_idx: 220 |  Loss: (0.1080) |  Loss2: (0.0000) | Acc: (96.00%) (27275/28288)
Epoch: 165 | Batch_idx: 230 |  Loss: (0.1079) |  Loss2: (0.0000) | Acc: (96.00%) (28507/29568)
Epoch: 165 | Batch_idx: 240 |  Loss: (0.1080) |  Loss2: (0.0000) | Acc: (96.00%) (29741/30848)
Epoch: 165 | Batch_idx: 250 |  Loss: (0.1079) |  Loss2: (0.0000) | Acc: (96.00%) (30976/32128)
Epoch: 165 | Batch_idx: 260 |  Loss: (0.1076) |  Loss2: (0.0000) | Acc: (96.00%) (32210/33408)
Epoch: 165 | Batch_idx: 270 |  Loss: (0.1070) |  Loss2: (0.0000) | Acc: (96.00%) (33448/34688)
Epoch: 165 | Batch_idx: 280 |  Loss: (0.1069) |  Loss2: (0.0000) | Acc: (96.00%) (34689/35968)
Epoch: 165 | Batch_idx: 290 |  Loss: (0.1071) |  Loss2: (0.0000) | Acc: (96.00%) (35926/37248)
Epoch: 165 | Batch_idx: 300 |  Loss: (0.1067) |  Loss2: (0.0000) | Acc: (96.00%) (37167/38528)
Epoch: 165 | Batch_idx: 310 |  Loss: (0.1063) |  Loss2: (0.0000) | Acc: (96.00%) (38404/39808)
Epoch: 165 | Batch_idx: 320 |  Loss: (0.1069) |  Loss2: (0.0000) | Acc: (96.00%) (39628/41088)
Epoch: 165 | Batch_idx: 330 |  Loss: (0.1072) |  Loss2: (0.0000) | Acc: (96.00%) (40859/42368)
Epoch: 165 | Batch_idx: 340 |  Loss: (0.1067) |  Loss2: (0.0000) | Acc: (96.00%) (42099/43648)
Epoch: 165 | Batch_idx: 350 |  Loss: (0.1069) |  Loss2: (0.0000) | Acc: (96.00%) (43328/44928)
Epoch: 165 | Batch_idx: 360 |  Loss: (0.1070) |  Loss2: (0.0000) | Acc: (96.00%) (44556/46208)
Epoch: 165 | Batch_idx: 370 |  Loss: (0.1072) |  Loss2: (0.0000) | Acc: (96.00%) (45789/47488)
Epoch: 165 | Batch_idx: 380 |  Loss: (0.1076) |  Loss2: (0.0000) | Acc: (96.00%) (47017/48768)
Epoch: 165 | Batch_idx: 390 |  Loss: (0.1074) |  Loss2: (0.0000) | Acc: (96.00%) (48211/50000)
=> saving checkpoint 'drive/app/torch/save_Schedule/checkpoint_165.pth.tar'
# TEST : Loss: (0.3834) | Acc: (88.00%) (8834/10000)
percent tensor([0.5109, 0.5115, 0.5126, 0.5145, 0.5127, 0.5152, 0.5128, 0.5151, 0.5112,
        0.5115, 0.5100, 0.5115, 0.5102, 0.5139, 0.5120, 0.5124],
       device='cuda:0') torch.Size([16])
percent tensor([0.5206, 0.5254, 0.5229, 0.5167, 0.5160, 0.5246, 0.5198, 0.5135, 0.5162,
        0.5227, 0.5193, 0.5230, 0.5275, 0.5118, 0.5240, 0.5243],
       device='cuda:0') torch.Size([16])
percent tensor([0.5774, 0.5365, 0.6341, 0.6593, 0.6527, 0.6113, 0.5946, 0.6338, 0.6283,
        0.5735, 0.6050, 0.5972, 0.4959, 0.6505, 0.5725, 0.5807],
       device='cuda:0') torch.Size([16])
percent tensor([0.6424, 0.6346, 0.6354, 0.6383, 0.6388, 0.6358, 0.6435, 0.6399, 0.6444,
        0.6425, 0.6424, 0.6407, 0.6357, 0.6396, 0.6414, 0.6490],
       device='cuda:0') torch.Size([16])
percent tensor([0.6393, 0.6068, 0.6576, 0.6626, 0.6692, 0.7385, 0.6079, 0.6137, 0.6314,
        0.6593, 0.6130, 0.6069, 0.6243, 0.6551, 0.6100, 0.6972],
       device='cuda:0') torch.Size([16])
percent tensor([0.6081, 0.6817, 0.6651, 0.6936, 0.6783, 0.7453, 0.6861, 0.5481, 0.6974,
        0.6641, 0.7272, 0.6571, 0.7126, 0.7256, 0.5394, 0.6517],
       device='cuda:0') torch.Size([16])
percent tensor([0.5705, 0.6704, 0.6746, 0.6933, 0.7248, 0.6424, 0.6553, 0.6490, 0.6181,
        0.6702, 0.6636, 0.6120, 0.6200, 0.5899, 0.5805, 0.5640],
       device='cuda:0') torch.Size([16])
percent tensor([0.9998, 0.9997, 0.9998, 0.9998, 0.9997, 0.9993, 0.9997, 0.9995, 0.9998,
        0.9998, 0.9999, 0.9997, 0.9999, 0.9994, 0.9993, 0.9995],
       device='cuda:0') torch.Size([16])
Epoch: 166 | Batch_idx: 0 |  Loss: (0.0526) |  Loss2: (0.0000) | Acc: (98.00%) (126/128)
Epoch: 166 | Batch_idx: 10 |  Loss: (0.0938) |  Loss2: (0.0000) | Acc: (96.00%) (1364/1408)
Epoch: 166 | Batch_idx: 20 |  Loss: (0.0965) |  Loss2: (0.0000) | Acc: (96.00%) (2607/2688)
Epoch: 166 | Batch_idx: 30 |  Loss: (0.0989) |  Loss2: (0.0000) | Acc: (96.00%) (3841/3968)
Epoch: 166 | Batch_idx: 40 |  Loss: (0.0969) |  Loss2: (0.0000) | Acc: (96.00%) (5078/5248)
Epoch: 166 | Batch_idx: 50 |  Loss: (0.0972) |  Loss2: (0.0000) | Acc: (96.00%) (6308/6528)
Epoch: 166 | Batch_idx: 60 |  Loss: (0.0970) |  Loss2: (0.0000) | Acc: (96.00%) (7544/7808)
Epoch: 166 | Batch_idx: 70 |  Loss: (0.0982) |  Loss2: (0.0000) | Acc: (96.00%) (8779/9088)
Epoch: 166 | Batch_idx: 80 |  Loss: (0.0980) |  Loss2: (0.0000) | Acc: (96.00%) (10012/10368)
Epoch: 166 | Batch_idx: 90 |  Loss: (0.0977) |  Loss2: (0.0000) | Acc: (96.00%) (11253/11648)
Epoch: 166 | Batch_idx: 100 |  Loss: (0.0985) |  Loss2: (0.0000) | Acc: (96.00%) (12478/12928)
Epoch: 166 | Batch_idx: 110 |  Loss: (0.0997) |  Loss2: (0.0000) | Acc: (96.00%) (13712/14208)
Epoch: 166 | Batch_idx: 120 |  Loss: (0.1006) |  Loss2: (0.0000) | Acc: (96.00%) (14938/15488)
Epoch: 166 | Batch_idx: 130 |  Loss: (0.1011) |  Loss2: (0.0000) | Acc: (96.00%) (16173/16768)
Epoch: 166 | Batch_idx: 140 |  Loss: (0.1026) |  Loss2: (0.0000) | Acc: (96.00%) (17397/18048)
Epoch: 166 | Batch_idx: 150 |  Loss: (0.1030) |  Loss2: (0.0000) | Acc: (96.00%) (18627/19328)
Epoch: 166 | Batch_idx: 160 |  Loss: (0.1032) |  Loss2: (0.0000) | Acc: (96.00%) (19859/20608)
Epoch: 166 | Batch_idx: 170 |  Loss: (0.1041) |  Loss2: (0.0000) | Acc: (96.00%) (21088/21888)
Epoch: 166 | Batch_idx: 180 |  Loss: (0.1034) |  Loss2: (0.0000) | Acc: (96.00%) (22333/23168)
Epoch: 166 | Batch_idx: 190 |  Loss: (0.1037) |  Loss2: (0.0000) | Acc: (96.00%) (23568/24448)
Epoch: 166 | Batch_idx: 200 |  Loss: (0.1032) |  Loss2: (0.0000) | Acc: (96.00%) (24807/25728)
Epoch: 166 | Batch_idx: 210 |  Loss: (0.1034) |  Loss2: (0.0000) | Acc: (96.00%) (26042/27008)
Epoch: 166 | Batch_idx: 220 |  Loss: (0.1035) |  Loss2: (0.0000) | Acc: (96.00%) (27275/28288)
Epoch: 166 | Batch_idx: 230 |  Loss: (0.1038) |  Loss2: (0.0000) | Acc: (96.00%) (28509/29568)
Epoch: 166 | Batch_idx: 240 |  Loss: (0.1043) |  Loss2: (0.0000) | Acc: (96.00%) (29742/30848)
Epoch: 166 | Batch_idx: 250 |  Loss: (0.1043) |  Loss2: (0.0000) | Acc: (96.00%) (30969/32128)
Epoch: 166 | Batch_idx: 260 |  Loss: (0.1045) |  Loss2: (0.0000) | Acc: (96.00%) (32192/33408)
Epoch: 166 | Batch_idx: 270 |  Loss: (0.1051) |  Loss2: (0.0000) | Acc: (96.00%) (33418/34688)
Epoch: 166 | Batch_idx: 280 |  Loss: (0.1051) |  Loss2: (0.0000) | Acc: (96.00%) (34656/35968)
Epoch: 166 | Batch_idx: 290 |  Loss: (0.1053) |  Loss2: (0.0000) | Acc: (96.00%) (35886/37248)
Epoch: 166 | Batch_idx: 300 |  Loss: (0.1052) |  Loss2: (0.0000) | Acc: (96.00%) (37126/38528)
Epoch: 166 | Batch_idx: 310 |  Loss: (0.1050) |  Loss2: (0.0000) | Acc: (96.00%) (38363/39808)
Epoch: 166 | Batch_idx: 320 |  Loss: (0.1053) |  Loss2: (0.0000) | Acc: (96.00%) (39591/41088)
Epoch: 166 | Batch_idx: 330 |  Loss: (0.1052) |  Loss2: (0.0000) | Acc: (96.00%) (40828/42368)
Epoch: 166 | Batch_idx: 340 |  Loss: (0.1052) |  Loss2: (0.0000) | Acc: (96.00%) (42064/43648)
Epoch: 166 | Batch_idx: 350 |  Loss: (0.1053) |  Loss2: (0.0000) | Acc: (96.00%) (43292/44928)
Epoch: 166 | Batch_idx: 360 |  Loss: (0.1049) |  Loss2: (0.0000) | Acc: (96.00%) (44535/46208)
Epoch: 166 | Batch_idx: 370 |  Loss: (0.1047) |  Loss2: (0.0000) | Acc: (96.00%) (45780/47488)
Epoch: 166 | Batch_idx: 380 |  Loss: (0.1045) |  Loss2: (0.0000) | Acc: (96.00%) (47016/48768)
Epoch: 166 | Batch_idx: 390 |  Loss: (0.1044) |  Loss2: (0.0000) | Acc: (96.00%) (48207/50000)
# TEST : Loss: (0.3815) | Acc: (88.00%) (8838/10000)
percent tensor([0.5106, 0.5109, 0.5122, 0.5141, 0.5122, 0.5148, 0.5122, 0.5147, 0.5109,
        0.5110, 0.5095, 0.5111, 0.5098, 0.5136, 0.5114, 0.5120],
       device='cuda:0') torch.Size([16])
percent tensor([0.5200, 0.5241, 0.5222, 0.5161, 0.5151, 0.5239, 0.5187, 0.5131, 0.5155,
        0.5217, 0.5182, 0.5221, 0.5265, 0.5110, 0.5229, 0.5235],
       device='cuda:0') torch.Size([16])
percent tensor([0.5762, 0.5340, 0.6321, 0.6563, 0.6526, 0.6124, 0.5930, 0.6331, 0.6271,
        0.5690, 0.6014, 0.5948, 0.4944, 0.6472, 0.5719, 0.5775],
       device='cuda:0') torch.Size([16])
percent tensor([0.6391, 0.6310, 0.6327, 0.6354, 0.6360, 0.6313, 0.6406, 0.6380, 0.6414,
        0.6389, 0.6384, 0.6378, 0.6320, 0.6365, 0.6378, 0.6449],
       device='cuda:0') torch.Size([16])
percent tensor([0.6461, 0.6141, 0.6576, 0.6657, 0.6706, 0.7399, 0.6146, 0.6170, 0.6370,
        0.6639, 0.6211, 0.6084, 0.6306, 0.6632, 0.6172, 0.7033],
       device='cuda:0') torch.Size([16])
percent tensor([0.6115, 0.6851, 0.6680, 0.6961, 0.6807, 0.7472, 0.6878, 0.5484, 0.6991,
        0.6697, 0.7310, 0.6586, 0.7141, 0.7278, 0.5390, 0.6563],
       device='cuda:0') torch.Size([16])
percent tensor([0.5632, 0.6657, 0.6731, 0.6902, 0.7215, 0.6387, 0.6475, 0.6420, 0.6141,
        0.6696, 0.6616, 0.6065, 0.6142, 0.5835, 0.5736, 0.5534],
       device='cuda:0') torch.Size([16])
percent tensor([0.9999, 0.9997, 0.9998, 0.9999, 0.9997, 0.9993, 0.9997, 0.9996, 0.9998,
        0.9998, 0.9999, 0.9997, 0.9999, 0.9995, 0.9994, 0.9995],
       device='cuda:0') torch.Size([16])
Epoch: 167 | Batch_idx: 0 |  Loss: (0.0714) |  Loss2: (0.0000) | Acc: (97.00%) (125/128)
Epoch: 167 | Batch_idx: 10 |  Loss: (0.1060) |  Loss2: (0.0000) | Acc: (96.00%) (1355/1408)
Epoch: 167 | Batch_idx: 20 |  Loss: (0.1055) |  Loss2: (0.0000) | Acc: (96.00%) (2590/2688)
Epoch: 167 | Batch_idx: 30 |  Loss: (0.0998) |  Loss2: (0.0000) | Acc: (96.00%) (3824/3968)
Epoch: 167 | Batch_idx: 40 |  Loss: (0.1026) |  Loss2: (0.0000) | Acc: (96.00%) (5054/5248)
Epoch: 167 | Batch_idx: 50 |  Loss: (0.1037) |  Loss2: (0.0000) | Acc: (96.00%) (6287/6528)
Epoch: 167 | Batch_idx: 60 |  Loss: (0.1022) |  Loss2: (0.0000) | Acc: (96.00%) (7531/7808)
Epoch: 167 | Batch_idx: 70 |  Loss: (0.1022) |  Loss2: (0.0000) | Acc: (96.00%) (8768/9088)
Epoch: 167 | Batch_idx: 80 |  Loss: (0.1023) |  Loss2: (0.0000) | Acc: (96.00%) (10009/10368)
Epoch: 167 | Batch_idx: 90 |  Loss: (0.1042) |  Loss2: (0.0000) | Acc: (96.00%) (11237/11648)
Epoch: 167 | Batch_idx: 100 |  Loss: (0.1053) |  Loss2: (0.0000) | Acc: (96.00%) (12466/12928)
Epoch: 167 | Batch_idx: 110 |  Loss: (0.1034) |  Loss2: (0.0000) | Acc: (96.00%) (13716/14208)
Epoch: 167 | Batch_idx: 120 |  Loss: (0.1018) |  Loss2: (0.0000) | Acc: (96.00%) (14961/15488)
Epoch: 167 | Batch_idx: 130 |  Loss: (0.1020) |  Loss2: (0.0000) | Acc: (96.00%) (16189/16768)
Epoch: 167 | Batch_idx: 140 |  Loss: (0.1023) |  Loss2: (0.0000) | Acc: (96.00%) (17414/18048)
Epoch: 167 | Batch_idx: 150 |  Loss: (0.1022) |  Loss2: (0.0000) | Acc: (96.00%) (18652/19328)
Epoch: 167 | Batch_idx: 160 |  Loss: (0.1027) |  Loss2: (0.0000) | Acc: (96.00%) (19881/20608)
Epoch: 167 | Batch_idx: 170 |  Loss: (0.1024) |  Loss2: (0.0000) | Acc: (96.00%) (21117/21888)
Epoch: 167 | Batch_idx: 180 |  Loss: (0.1036) |  Loss2: (0.0000) | Acc: (96.00%) (22346/23168)
Epoch: 167 | Batch_idx: 190 |  Loss: (0.1028) |  Loss2: (0.0000) | Acc: (96.00%) (23596/24448)
Epoch: 167 | Batch_idx: 200 |  Loss: (0.1029) |  Loss2: (0.0000) | Acc: (96.00%) (24826/25728)
Epoch: 167 | Batch_idx: 210 |  Loss: (0.1028) |  Loss2: (0.0000) | Acc: (96.00%) (26066/27008)
Epoch: 167 | Batch_idx: 220 |  Loss: (0.1038) |  Loss2: (0.0000) | Acc: (96.00%) (27292/28288)
Epoch: 167 | Batch_idx: 230 |  Loss: (0.1035) |  Loss2: (0.0000) | Acc: (96.00%) (28537/29568)
Epoch: 167 | Batch_idx: 240 |  Loss: (0.1040) |  Loss2: (0.0000) | Acc: (96.00%) (29767/30848)
Epoch: 167 | Batch_idx: 250 |  Loss: (0.1036) |  Loss2: (0.0000) | Acc: (96.00%) (31009/32128)
Epoch: 167 | Batch_idx: 260 |  Loss: (0.1034) |  Loss2: (0.0000) | Acc: (96.00%) (32239/33408)
Epoch: 167 | Batch_idx: 270 |  Loss: (0.1032) |  Loss2: (0.0000) | Acc: (96.00%) (33480/34688)
Epoch: 167 | Batch_idx: 280 |  Loss: (0.1035) |  Loss2: (0.0000) | Acc: (96.00%) (34716/35968)
Epoch: 167 | Batch_idx: 290 |  Loss: (0.1040) |  Loss2: (0.0000) | Acc: (96.00%) (35941/37248)
Epoch: 167 | Batch_idx: 300 |  Loss: (0.1041) |  Loss2: (0.0000) | Acc: (96.00%) (37178/38528)
Epoch: 167 | Batch_idx: 310 |  Loss: (0.1041) |  Loss2: (0.0000) | Acc: (96.00%) (38417/39808)
Epoch: 167 | Batch_idx: 320 |  Loss: (0.1042) |  Loss2: (0.0000) | Acc: (96.00%) (39652/41088)
Epoch: 167 | Batch_idx: 330 |  Loss: (0.1040) |  Loss2: (0.0000) | Acc: (96.00%) (40894/42368)
Epoch: 167 | Batch_idx: 340 |  Loss: (0.1042) |  Loss2: (0.0000) | Acc: (96.00%) (42125/43648)
Epoch: 167 | Batch_idx: 350 |  Loss: (0.1047) |  Loss2: (0.0000) | Acc: (96.00%) (43352/44928)
Epoch: 167 | Batch_idx: 360 |  Loss: (0.1048) |  Loss2: (0.0000) | Acc: (96.00%) (44584/46208)
Epoch: 167 | Batch_idx: 370 |  Loss: (0.1046) |  Loss2: (0.0000) | Acc: (96.00%) (45825/47488)
Epoch: 167 | Batch_idx: 380 |  Loss: (0.1048) |  Loss2: (0.0000) | Acc: (96.00%) (47055/48768)
Epoch: 167 | Batch_idx: 390 |  Loss: (0.1042) |  Loss2: (0.0000) | Acc: (96.00%) (48258/50000)
# TEST : Loss: (0.3784) | Acc: (88.00%) (8846/10000)
percent tensor([0.5108, 0.5111, 0.5126, 0.5143, 0.5125, 0.5147, 0.5125, 0.5151, 0.5112,
        0.5114, 0.5098, 0.5114, 0.5101, 0.5139, 0.5115, 0.5122],
       device='cuda:0') torch.Size([16])
percent tensor([0.5201, 0.5239, 0.5225, 0.5165, 0.5154, 0.5237, 0.5188, 0.5134, 0.5156,
        0.5217, 0.5181, 0.5222, 0.5264, 0.5112, 0.5227, 0.5236],
       device='cuda:0') torch.Size([16])
percent tensor([0.5783, 0.5345, 0.6333, 0.6570, 0.6528, 0.6155, 0.5936, 0.6338, 0.6280,
        0.5687, 0.6019, 0.5955, 0.4957, 0.6482, 0.5735, 0.5788],
       device='cuda:0') torch.Size([16])
percent tensor([0.6428, 0.6338, 0.6363, 0.6389, 0.6399, 0.6352, 0.6443, 0.6424, 0.6447,
        0.6416, 0.6408, 0.6409, 0.6345, 0.6397, 0.6416, 0.6479],
       device='cuda:0') torch.Size([16])
percent tensor([0.6437, 0.6127, 0.6557, 0.6644, 0.6677, 0.7401, 0.6122, 0.6140, 0.6350,
        0.6610, 0.6161, 0.6055, 0.6308, 0.6624, 0.6138, 0.7024],
       device='cuda:0') torch.Size([16])
percent tensor([0.6210, 0.6941, 0.6790, 0.7060, 0.6918, 0.7532, 0.6983, 0.5601, 0.7083,
        0.6796, 0.7401, 0.6713, 0.7219, 0.7343, 0.5496, 0.6643],
       device='cuda:0') torch.Size([16])
percent tensor([0.5588, 0.6640, 0.6766, 0.6921, 0.7232, 0.6394, 0.6449, 0.6419, 0.6117,
        0.6656, 0.6608, 0.6059, 0.6113, 0.5825, 0.5687, 0.5498],
       device='cuda:0') torch.Size([16])
percent tensor([0.9998, 0.9997, 0.9998, 0.9999, 0.9997, 0.9992, 0.9997, 0.9996, 0.9998,
        0.9998, 0.9999, 0.9997, 0.9999, 0.9995, 0.9994, 0.9995],
       device='cuda:0') torch.Size([16])
True Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=128, out_features=16, bias=False)
False Linear(in_features=16, out_features=2, bias=False)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=128, out_features=16, bias=False)
False Linear(in_features=16, out_features=2, bias=False)
True Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=256, out_features=32, bias=False)
False Linear(in_features=32, out_features=2, bias=False)
True Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=256, out_features=32, bias=False)
False Linear(in_features=32, out_features=2, bias=False)
True Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=512, out_features=64, bias=False)
False Linear(in_features=64, out_features=2, bias=False)
True Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=512, out_features=64, bias=False)
False Linear(in_features=64, out_features=2, bias=False)
True Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1024, out_features=128, bias=False)
False Linear(in_features=128, out_features=2, bias=False)
True Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1024, out_features=128, bias=False)
False Linear(in_features=128, out_features=2, bias=False)
True Linear(in_features=512, out_features=10, bias=True)
Epoch: 168 | Batch_idx: 0 |  Loss: (0.1261) |  Loss2: (0.0000) | Acc: (96.00%) (123/128)
Epoch: 168 | Batch_idx: 10 |  Loss: (0.1157) |  Loss2: (0.0000) | Acc: (95.00%) (1351/1408)
Epoch: 168 | Batch_idx: 20 |  Loss: (0.1081) |  Loss2: (0.0000) | Acc: (96.00%) (2587/2688)
Epoch: 168 | Batch_idx: 30 |  Loss: (0.1056) |  Loss2: (0.0000) | Acc: (96.00%) (3825/3968)
Epoch: 168 | Batch_idx: 40 |  Loss: (0.1036) |  Loss2: (0.0000) | Acc: (96.00%) (5072/5248)
Epoch: 168 | Batch_idx: 50 |  Loss: (0.1055) |  Loss2: (0.0000) | Acc: (96.00%) (6306/6528)
Epoch: 168 | Batch_idx: 60 |  Loss: (0.1034) |  Loss2: (0.0000) | Acc: (96.00%) (7545/7808)
Epoch: 168 | Batch_idx: 70 |  Loss: (0.1060) |  Loss2: (0.0000) | Acc: (96.00%) (8776/9088)
Epoch: 168 | Batch_idx: 80 |  Loss: (0.1048) |  Loss2: (0.0000) | Acc: (96.00%) (10022/10368)
Epoch: 168 | Batch_idx: 90 |  Loss: (0.1060) |  Loss2: (0.0000) | Acc: (96.00%) (11246/11648)
Epoch: 168 | Batch_idx: 100 |  Loss: (0.1058) |  Loss2: (0.0000) | Acc: (96.00%) (12483/12928)
Epoch: 168 | Batch_idx: 110 |  Loss: (0.1051) |  Loss2: (0.0000) | Acc: (96.00%) (13719/14208)
Epoch: 168 | Batch_idx: 120 |  Loss: (0.1051) |  Loss2: (0.0000) | Acc: (96.00%) (14956/15488)
Epoch: 168 | Batch_idx: 130 |  Loss: (0.1036) |  Loss2: (0.0000) | Acc: (96.00%) (16199/16768)
Epoch: 168 | Batch_idx: 140 |  Loss: (0.1044) |  Loss2: (0.0000) | Acc: (96.00%) (17427/18048)
Epoch: 168 | Batch_idx: 150 |  Loss: (0.1046) |  Loss2: (0.0000) | Acc: (96.00%) (18660/19328)
Epoch: 168 | Batch_idx: 160 |  Loss: (0.1045) |  Loss2: (0.0000) | Acc: (96.00%) (19887/20608)
Epoch: 168 | Batch_idx: 170 |  Loss: (0.1057) |  Loss2: (0.0000) | Acc: (96.00%) (21105/21888)
Epoch: 168 | Batch_idx: 180 |  Loss: (0.1047) |  Loss2: (0.0000) | Acc: (96.00%) (22343/23168)
Epoch: 168 | Batch_idx: 190 |  Loss: (0.1044) |  Loss2: (0.0000) | Acc: (96.00%) (23578/24448)
Epoch: 168 | Batch_idx: 200 |  Loss: (0.1044) |  Loss2: (0.0000) | Acc: (96.00%) (24807/25728)
Epoch: 168 | Batch_idx: 210 |  Loss: (0.1042) |  Loss2: (0.0000) | Acc: (96.00%) (26047/27008)
Epoch: 168 | Batch_idx: 220 |  Loss: (0.1052) |  Loss2: (0.0000) | Acc: (96.00%) (27272/28288)
Epoch: 168 | Batch_idx: 230 |  Loss: (0.1053) |  Loss2: (0.0000) | Acc: (96.00%) (28509/29568)
Epoch: 168 | Batch_idx: 240 |  Loss: (0.1047) |  Loss2: (0.0000) | Acc: (96.00%) (29751/30848)
Epoch: 168 | Batch_idx: 250 |  Loss: (0.1051) |  Loss2: (0.0000) | Acc: (96.00%) (30978/32128)
Epoch: 168 | Batch_idx: 260 |  Loss: (0.1053) |  Loss2: (0.0000) | Acc: (96.00%) (32207/33408)
Epoch: 168 | Batch_idx: 270 |  Loss: (0.1055) |  Loss2: (0.0000) | Acc: (96.00%) (33439/34688)
Epoch: 168 | Batch_idx: 280 |  Loss: (0.1055) |  Loss2: (0.0000) | Acc: (96.00%) (34670/35968)
Epoch: 168 | Batch_idx: 290 |  Loss: (0.1059) |  Loss2: (0.0000) | Acc: (96.00%) (35895/37248)
Epoch: 168 | Batch_idx: 300 |  Loss: (0.1059) |  Loss2: (0.0000) | Acc: (96.00%) (37125/38528)
Epoch: 168 | Batch_idx: 310 |  Loss: (0.1062) |  Loss2: (0.0000) | Acc: (96.00%) (38351/39808)
Epoch: 168 | Batch_idx: 320 |  Loss: (0.1064) |  Loss2: (0.0000) | Acc: (96.00%) (39583/41088)
Epoch: 168 | Batch_idx: 330 |  Loss: (0.1068) |  Loss2: (0.0000) | Acc: (96.00%) (40819/42368)
Epoch: 168 | Batch_idx: 340 |  Loss: (0.1068) |  Loss2: (0.0000) | Acc: (96.00%) (42055/43648)
Epoch: 168 | Batch_idx: 350 |  Loss: (0.1069) |  Loss2: (0.0000) | Acc: (96.00%) (43281/44928)
Epoch: 168 | Batch_idx: 360 |  Loss: (0.1068) |  Loss2: (0.0000) | Acc: (96.00%) (44516/46208)
Epoch: 168 | Batch_idx: 370 |  Loss: (0.1067) |  Loss2: (0.0000) | Acc: (96.00%) (45748/47488)
Epoch: 168 | Batch_idx: 380 |  Loss: (0.1075) |  Loss2: (0.0000) | Acc: (96.00%) (46960/48768)
Epoch: 168 | Batch_idx: 390 |  Loss: (0.1077) |  Loss2: (0.0000) | Acc: (96.00%) (48145/50000)
# TEST : Loss: (0.4351) | Acc: (87.00%) (8733/10000)
percent tensor([0.5107, 0.5101, 0.5146, 0.5144, 0.5142, 0.5146, 0.5122, 0.5157, 0.5109,
        0.5113, 0.5091, 0.5126, 0.5097, 0.5124, 0.5110, 0.5117],
       device='cuda:0') torch.Size([16])
percent tensor([0.5185, 0.5239, 0.5179, 0.5139, 0.5132, 0.5246, 0.5172, 0.5113, 0.5134,
        0.5202, 0.5181, 0.5173, 0.5256, 0.5099, 0.5222, 0.5231],
       device='cuda:0') torch.Size([16])
percent tensor([0.5906, 0.5305, 0.6336, 0.6638, 0.6467, 0.6271, 0.5884, 0.6275, 0.6278,
        0.5683, 0.6043, 0.5927, 0.5010, 0.6497, 0.5775, 0.5841],
       device='cuda:0') torch.Size([16])
percent tensor([0.6401, 0.6326, 0.6356, 0.6390, 0.6375, 0.6402, 0.6419, 0.6421, 0.6377,
        0.6379, 0.6367, 0.6370, 0.6311, 0.6353, 0.6415, 0.6469],
       device='cuda:0') torch.Size([16])
percent tensor([0.6342, 0.5942, 0.6361, 0.6518, 0.6691, 0.7499, 0.6063, 0.5954, 0.6280,
        0.6475, 0.6179, 0.5986, 0.6239, 0.6506, 0.5998, 0.6994],
       device='cuda:0') torch.Size([16])
percent tensor([0.6102, 0.6820, 0.6750, 0.7135, 0.6493, 0.7423, 0.6715, 0.5368, 0.7284,
        0.6746, 0.7480, 0.6734, 0.7387, 0.7317, 0.5416, 0.6522],
       device='cuda:0') torch.Size([16])
percent tensor([0.5671, 0.6537, 0.6736, 0.6841, 0.6836, 0.6432, 0.6328, 0.6298, 0.6421,
        0.6659, 0.6747, 0.5962, 0.6300, 0.5767, 0.5714, 0.5519],
       device='cuda:0') torch.Size([16])
percent tensor([0.9999, 0.9997, 0.9998, 0.9998, 0.9995, 0.9991, 0.9996, 0.9996, 0.9999,
        0.9999, 1.0000, 0.9996, 0.9999, 0.9994, 0.9993, 0.9996],
       device='cuda:0') torch.Size([16])
Epoch: 169 | Batch_idx: 0 |  Loss: (0.1077) |  Loss2: (0.0000) | Acc: (97.00%) (125/128)
Epoch: 169 | Batch_idx: 10 |  Loss: (0.0971) |  Loss2: (0.0000) | Acc: (96.00%) (1365/1408)
Epoch: 169 | Batch_idx: 20 |  Loss: (0.1143) |  Loss2: (0.0000) | Acc: (96.00%) (2586/2688)
Epoch: 169 | Batch_idx: 30 |  Loss: (0.1091) |  Loss2: (0.0000) | Acc: (96.00%) (3830/3968)
Epoch: 169 | Batch_idx: 40 |  Loss: (0.1109) |  Loss2: (0.0000) | Acc: (96.00%) (5065/5248)
Epoch: 169 | Batch_idx: 50 |  Loss: (0.1074) |  Loss2: (0.0000) | Acc: (96.00%) (6305/6528)
Epoch: 169 | Batch_idx: 60 |  Loss: (0.1057) |  Loss2: (0.0000) | Acc: (96.00%) (7541/7808)
Epoch: 169 | Batch_idx: 70 |  Loss: (0.1101) |  Loss2: (0.0000) | Acc: (96.00%) (8761/9088)
Epoch: 169 | Batch_idx: 80 |  Loss: (0.1117) |  Loss2: (0.0000) | Acc: (96.00%) (9986/10368)
Epoch: 169 | Batch_idx: 90 |  Loss: (0.1119) |  Loss2: (0.0000) | Acc: (96.00%) (11216/11648)
Epoch: 169 | Batch_idx: 100 |  Loss: (0.1104) |  Loss2: (0.0000) | Acc: (96.00%) (12453/12928)
Epoch: 169 | Batch_idx: 110 |  Loss: (0.1094) |  Loss2: (0.0000) | Acc: (96.00%) (13694/14208)
Epoch: 169 | Batch_idx: 120 |  Loss: (0.1088) |  Loss2: (0.0000) | Acc: (96.00%) (14930/15488)
Epoch: 169 | Batch_idx: 130 |  Loss: (0.1073) |  Loss2: (0.0000) | Acc: (96.00%) (16173/16768)
Epoch: 169 | Batch_idx: 140 |  Loss: (0.1071) |  Loss2: (0.0000) | Acc: (96.00%) (17413/18048)
Epoch: 169 | Batch_idx: 150 |  Loss: (0.1076) |  Loss2: (0.0000) | Acc: (96.00%) (18642/19328)
Epoch: 169 | Batch_idx: 160 |  Loss: (0.1079) |  Loss2: (0.0000) | Acc: (96.00%) (19876/20608)
Epoch: 169 | Batch_idx: 170 |  Loss: (0.1083) |  Loss2: (0.0000) | Acc: (96.00%) (21110/21888)
Epoch: 169 | Batch_idx: 180 |  Loss: (0.1081) |  Loss2: (0.0000) | Acc: (96.00%) (22345/23168)
Epoch: 169 | Batch_idx: 190 |  Loss: (0.1071) |  Loss2: (0.0000) | Acc: (96.00%) (23587/24448)
Epoch: 169 | Batch_idx: 200 |  Loss: (0.1075) |  Loss2: (0.0000) | Acc: (96.00%) (24811/25728)
Epoch: 169 | Batch_idx: 210 |  Loss: (0.1085) |  Loss2: (0.0000) | Acc: (96.00%) (26033/27008)
Epoch: 169 | Batch_idx: 220 |  Loss: (0.1087) |  Loss2: (0.0000) | Acc: (96.00%) (27261/28288)
Epoch: 169 | Batch_idx: 230 |  Loss: (0.1099) |  Loss2: (0.0000) | Acc: (96.00%) (28482/29568)
Epoch: 169 | Batch_idx: 240 |  Loss: (0.1103) |  Loss2: (0.0000) | Acc: (96.00%) (29712/30848)
Epoch: 169 | Batch_idx: 250 |  Loss: (0.1099) |  Loss2: (0.0000) | Acc: (96.00%) (30950/32128)
Epoch: 169 | Batch_idx: 260 |  Loss: (0.1096) |  Loss2: (0.0000) | Acc: (96.00%) (32179/33408)
Epoch: 169 | Batch_idx: 270 |  Loss: (0.1095) |  Loss2: (0.0000) | Acc: (96.00%) (33421/34688)
Epoch: 169 | Batch_idx: 280 |  Loss: (0.1093) |  Loss2: (0.0000) | Acc: (96.00%) (34659/35968)
Epoch: 169 | Batch_idx: 290 |  Loss: (0.1093) |  Loss2: (0.0000) | Acc: (96.00%) (35894/37248)
Epoch: 169 | Batch_idx: 300 |  Loss: (0.1096) |  Loss2: (0.0000) | Acc: (96.00%) (37126/38528)
Epoch: 169 | Batch_idx: 310 |  Loss: (0.1094) |  Loss2: (0.0000) | Acc: (96.00%) (38365/39808)
Epoch: 169 | Batch_idx: 320 |  Loss: (0.1094) |  Loss2: (0.0000) | Acc: (96.00%) (39594/41088)
Epoch: 169 | Batch_idx: 330 |  Loss: (0.1089) |  Loss2: (0.0000) | Acc: (96.00%) (40829/42368)
Epoch: 169 | Batch_idx: 340 |  Loss: (0.1091) |  Loss2: (0.0000) | Acc: (96.00%) (42057/43648)
Epoch: 169 | Batch_idx: 350 |  Loss: (0.1087) |  Loss2: (0.0000) | Acc: (96.00%) (43297/44928)
Epoch: 169 | Batch_idx: 360 |  Loss: (0.1084) |  Loss2: (0.0000) | Acc: (96.00%) (44534/46208)
Epoch: 169 | Batch_idx: 370 |  Loss: (0.1085) |  Loss2: (0.0000) | Acc: (96.00%) (45773/47488)
Epoch: 169 | Batch_idx: 380 |  Loss: (0.1084) |  Loss2: (0.0000) | Acc: (96.00%) (47008/48768)
Epoch: 169 | Batch_idx: 390 |  Loss: (0.1084) |  Loss2: (0.0000) | Acc: (96.00%) (48197/50000)
# TEST : Loss: (0.3847) | Acc: (88.00%) (8864/10000)
percent tensor([0.5113, 0.5104, 0.5145, 0.5149, 0.5144, 0.5157, 0.5127, 0.5158, 0.5115,
        0.5114, 0.5096, 0.5125, 0.5101, 0.5125, 0.5117, 0.5123],
       device='cuda:0') torch.Size([16])
percent tensor([0.5188, 0.5259, 0.5156, 0.5151, 0.5133, 0.5256, 0.5194, 0.5106, 0.5141,
        0.5215, 0.5196, 0.5192, 0.5261, 0.5138, 0.5242, 0.5244],
       device='cuda:0') torch.Size([16])
percent tensor([0.5854, 0.5302, 0.6512, 0.6616, 0.6557, 0.6061, 0.5863, 0.6431, 0.6367,
        0.5721, 0.6019, 0.5999, 0.4998, 0.6551, 0.5671, 0.5832],
       device='cuda:0') torch.Size([16])
percent tensor([0.6428, 0.6320, 0.6342, 0.6390, 0.6414, 0.6392, 0.6424, 0.6436, 0.6413,
        0.6411, 0.6381, 0.6399, 0.6344, 0.6365, 0.6419, 0.6500],
       device='cuda:0') torch.Size([16])
percent tensor([0.6533, 0.6266, 0.6457, 0.6609, 0.6875, 0.7599, 0.6250, 0.6149, 0.6561,
        0.6698, 0.6348, 0.6239, 0.6423, 0.6740, 0.6279, 0.7178],
       device='cuda:0') torch.Size([16])
percent tensor([0.6127, 0.7053, 0.6857, 0.7122, 0.6860, 0.7526, 0.6888, 0.5709, 0.7137,
        0.6733, 0.7442, 0.6644, 0.7298, 0.7203, 0.5572, 0.6501],
       device='cuda:0') torch.Size([16])
percent tensor([0.5601, 0.6643, 0.6778, 0.6710, 0.6943, 0.6325, 0.6581, 0.6542, 0.6098,
        0.6550, 0.6730, 0.5889, 0.5964, 0.5875, 0.5646, 0.5340],
       device='cuda:0') torch.Size([16])
percent tensor([0.9999, 0.9997, 0.9997, 0.9998, 0.9995, 0.9991, 0.9996, 0.9997, 0.9999,
        0.9998, 0.9999, 0.9995, 0.9999, 0.9996, 0.9992, 0.9996],
       device='cuda:0') torch.Size([16])
Epoch: 170 | Batch_idx: 0 |  Loss: (0.0627) |  Loss2: (0.0000) | Acc: (99.00%) (127/128)
Epoch: 170 | Batch_idx: 10 |  Loss: (0.0867) |  Loss2: (0.0000) | Acc: (97.00%) (1368/1408)
Epoch: 170 | Batch_idx: 20 |  Loss: (0.0846) |  Loss2: (0.0000) | Acc: (97.00%) (2609/2688)
Epoch: 170 | Batch_idx: 30 |  Loss: (0.0896) |  Loss2: (0.0000) | Acc: (96.00%) (3846/3968)
Epoch: 170 | Batch_idx: 40 |  Loss: (0.0909) |  Loss2: (0.0000) | Acc: (96.00%) (5086/5248)
Epoch: 170 | Batch_idx: 50 |  Loss: (0.0951) |  Loss2: (0.0000) | Acc: (96.00%) (6313/6528)
Epoch: 170 | Batch_idx: 60 |  Loss: (0.0974) |  Loss2: (0.0000) | Acc: (96.00%) (7555/7808)
Epoch: 170 | Batch_idx: 70 |  Loss: (0.1021) |  Loss2: (0.0000) | Acc: (96.00%) (8770/9088)
Epoch: 170 | Batch_idx: 80 |  Loss: (0.1010) |  Loss2: (0.0000) | Acc: (96.00%) (10007/10368)
Epoch: 170 | Batch_idx: 90 |  Loss: (0.1010) |  Loss2: (0.0000) | Acc: (96.00%) (11249/11648)
Epoch: 170 | Batch_idx: 100 |  Loss: (0.1013) |  Loss2: (0.0000) | Acc: (96.00%) (12484/12928)
Epoch: 170 | Batch_idx: 110 |  Loss: (0.1028) |  Loss2: (0.0000) | Acc: (96.00%) (13713/14208)
Epoch: 170 | Batch_idx: 120 |  Loss: (0.1034) |  Loss2: (0.0000) | Acc: (96.00%) (14940/15488)
Epoch: 170 | Batch_idx: 130 |  Loss: (0.1044) |  Loss2: (0.0000) | Acc: (96.00%) (16168/16768)
Epoch: 170 | Batch_idx: 140 |  Loss: (0.1034) |  Loss2: (0.0000) | Acc: (96.00%) (17402/18048)
Epoch: 170 | Batch_idx: 150 |  Loss: (0.1034) |  Loss2: (0.0000) | Acc: (96.00%) (18630/19328)
Epoch: 170 | Batch_idx: 160 |  Loss: (0.1040) |  Loss2: (0.0000) | Acc: (96.00%) (19858/20608)
Epoch: 170 | Batch_idx: 170 |  Loss: (0.1055) |  Loss2: (0.0000) | Acc: (96.00%) (21082/21888)
Epoch: 170 | Batch_idx: 180 |  Loss: (0.1052) |  Loss2: (0.0000) | Acc: (96.00%) (22322/23168)
Epoch: 170 | Batch_idx: 190 |  Loss: (0.1050) |  Loss2: (0.0000) | Acc: (96.00%) (23551/24448)
Epoch: 170 | Batch_idx: 200 |  Loss: (0.1061) |  Loss2: (0.0000) | Acc: (96.00%) (24772/25728)
Epoch: 170 | Batch_idx: 210 |  Loss: (0.1064) |  Loss2: (0.0000) | Acc: (96.00%) (26007/27008)
Epoch: 170 | Batch_idx: 220 |  Loss: (0.1071) |  Loss2: (0.0000) | Acc: (96.00%) (27233/28288)
Epoch: 170 | Batch_idx: 230 |  Loss: (0.1067) |  Loss2: (0.0000) | Acc: (96.00%) (28462/29568)
Epoch: 170 | Batch_idx: 240 |  Loss: (0.1064) |  Loss2: (0.0000) | Acc: (96.00%) (29698/30848)
Epoch: 170 | Batch_idx: 250 |  Loss: (0.1062) |  Loss2: (0.0000) | Acc: (96.00%) (30931/32128)
Epoch: 170 | Batch_idx: 260 |  Loss: (0.1053) |  Loss2: (0.0000) | Acc: (96.00%) (32179/33408)
Epoch: 170 | Batch_idx: 270 |  Loss: (0.1053) |  Loss2: (0.0000) | Acc: (96.00%) (33419/34688)
Epoch: 170 | Batch_idx: 280 |  Loss: (0.1055) |  Loss2: (0.0000) | Acc: (96.00%) (34644/35968)
Epoch: 170 | Batch_idx: 290 |  Loss: (0.1058) |  Loss2: (0.0000) | Acc: (96.00%) (35866/37248)
Epoch: 170 | Batch_idx: 300 |  Loss: (0.1054) |  Loss2: (0.0000) | Acc: (96.00%) (37108/38528)
Epoch: 170 | Batch_idx: 310 |  Loss: (0.1056) |  Loss2: (0.0000) | Acc: (96.00%) (38340/39808)
Epoch: 170 | Batch_idx: 320 |  Loss: (0.1069) |  Loss2: (0.0000) | Acc: (96.00%) (39549/41088)
Epoch: 170 | Batch_idx: 330 |  Loss: (0.1069) |  Loss2: (0.0000) | Acc: (96.00%) (40783/42368)
Epoch: 170 | Batch_idx: 340 |  Loss: (0.1074) |  Loss2: (0.0000) | Acc: (96.00%) (42004/43648)
Epoch: 170 | Batch_idx: 350 |  Loss: (0.1071) |  Loss2: (0.0000) | Acc: (96.00%) (43245/44928)
Epoch: 170 | Batch_idx: 360 |  Loss: (0.1068) |  Loss2: (0.0000) | Acc: (96.00%) (44487/46208)
Epoch: 170 | Batch_idx: 370 |  Loss: (0.1073) |  Loss2: (0.0000) | Acc: (96.00%) (45707/47488)
Epoch: 170 | Batch_idx: 380 |  Loss: (0.1072) |  Loss2: (0.0000) | Acc: (96.00%) (46947/48768)
Epoch: 170 | Batch_idx: 390 |  Loss: (0.1076) |  Loss2: (0.0000) | Acc: (96.00%) (48125/50000)
=> saving checkpoint 'drive/app/torch/save_Schedule/checkpoint_170.pth.tar'
# TEST : Loss: (0.4179) | Acc: (87.00%) (8760/10000)
percent tensor([0.5114, 0.5110, 0.5147, 0.5152, 0.5142, 0.5154, 0.5131, 0.5162, 0.5119,
        0.5117, 0.5100, 0.5130, 0.5104, 0.5135, 0.5119, 0.5125],
       device='cuda:0') torch.Size([16])
percent tensor([0.5188, 0.5249, 0.5183, 0.5149, 0.5131, 0.5239, 0.5188, 0.5114, 0.5142,
        0.5215, 0.5185, 0.5203, 0.5264, 0.5120, 0.5225, 0.5229],
       device='cuda:0') torch.Size([16])
percent tensor([0.5839, 0.5282, 0.6329, 0.6602, 0.6500, 0.6227, 0.5878, 0.6345, 0.6378,
        0.5692, 0.6073, 0.5905, 0.4998, 0.6515, 0.5735, 0.5861],
       device='cuda:0') torch.Size([16])
percent tensor([0.6408, 0.6306, 0.6359, 0.6372, 0.6403, 0.6376, 0.6419, 0.6391, 0.6424,
        0.6395, 0.6358, 0.6405, 0.6334, 0.6360, 0.6393, 0.6478],
       device='cuda:0') torch.Size([16])
percent tensor([0.6447, 0.6073, 0.6512, 0.6656, 0.6703, 0.7283, 0.6079, 0.5953, 0.6516,
        0.6527, 0.6150, 0.6182, 0.6354, 0.6541, 0.6067, 0.6966],
       device='cuda:0') torch.Size([16])
percent tensor([0.6161, 0.6887, 0.6828, 0.7100, 0.6740, 0.7436, 0.6782, 0.5466, 0.7076,
        0.6651, 0.7435, 0.6813, 0.7266, 0.7133, 0.5564, 0.6435],
       device='cuda:0') torch.Size([16])
percent tensor([0.5682, 0.6459, 0.6736, 0.6670, 0.6866, 0.6352, 0.6515, 0.6372, 0.6142,
        0.6468, 0.6743, 0.5901, 0.6146, 0.5697, 0.5693, 0.5407],
       device='cuda:0') torch.Size([16])
percent tensor([0.9998, 0.9998, 0.9999, 0.9998, 0.9997, 0.9987, 0.9995, 0.9997, 0.9998,
        0.9998, 0.9999, 0.9998, 0.9999, 0.9995, 0.9993, 0.9995],
       device='cuda:0') torch.Size([16])
Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 3, 3, 3]) tensor(180.5876, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(829.7548, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(828.2969, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([128, 64, 3, 3]) tensor(1515.0387, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([128, 64, 1, 1]) tensor(483.1423, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([128, 128, 3, 3]) tensor(2282.5742, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([256, 128, 3, 3]) tensor(4261.0620, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([256, 128, 1, 1]) tensor(1360.1012, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([256, 256, 3, 3]) tensor(6250.4170, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([512, 256, 3, 3]) tensor(11621.9053, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([512, 256, 1, 1]) tensor(3828.2625, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([512, 512, 3, 3]) tensor(16188.0332, device='cuda:0', grad_fn=<NormBackward0>)
Epoch: 171 | Batch_idx: 0 |  Loss: (0.1005) |  Loss2: (0.0000) | Acc: (96.00%) (124/128)
Epoch: 171 | Batch_idx: 10 |  Loss: (0.0784) |  Loss2: (0.0000) | Acc: (97.00%) (1375/1408)
Epoch: 171 | Batch_idx: 20 |  Loss: (0.0881) |  Loss2: (0.0000) | Acc: (97.00%) (2611/2688)
Epoch: 171 | Batch_idx: 30 |  Loss: (0.0893) |  Loss2: (0.0000) | Acc: (97.00%) (3860/3968)
Epoch: 171 | Batch_idx: 40 |  Loss: (0.0964) |  Loss2: (0.0000) | Acc: (96.00%) (5089/5248)
Epoch: 171 | Batch_idx: 50 |  Loss: (0.0999) |  Loss2: (0.0000) | Acc: (96.00%) (6323/6528)
Epoch: 171 | Batch_idx: 60 |  Loss: (0.1017) |  Loss2: (0.0000) | Acc: (96.00%) (7552/7808)
Epoch: 171 | Batch_idx: 70 |  Loss: (0.1026) |  Loss2: (0.0000) | Acc: (96.00%) (8784/9088)
Epoch: 171 | Batch_idx: 80 |  Loss: (0.1004) |  Loss2: (0.0000) | Acc: (96.00%) (10027/10368)
Epoch: 171 | Batch_idx: 90 |  Loss: (0.0993) |  Loss2: (0.0000) | Acc: (96.00%) (11272/11648)
Epoch: 171 | Batch_idx: 100 |  Loss: (0.0978) |  Loss2: (0.0000) | Acc: (96.00%) (12515/12928)
Epoch: 171 | Batch_idx: 110 |  Loss: (0.0976) |  Loss2: (0.0000) | Acc: (96.00%) (13750/14208)
Epoch: 171 | Batch_idx: 120 |  Loss: (0.1002) |  Loss2: (0.0000) | Acc: (96.00%) (14971/15488)
Epoch: 171 | Batch_idx: 130 |  Loss: (0.0998) |  Loss2: (0.0000) | Acc: (96.00%) (16210/16768)
Epoch: 171 | Batch_idx: 140 |  Loss: (0.0986) |  Loss2: (0.0000) | Acc: (96.00%) (17456/18048)
Epoch: 171 | Batch_idx: 150 |  Loss: (0.0988) |  Loss2: (0.0000) | Acc: (96.00%) (18693/19328)
Epoch: 171 | Batch_idx: 160 |  Loss: (0.0981) |  Loss2: (0.0000) | Acc: (96.00%) (19936/20608)
Epoch: 171 | Batch_idx: 170 |  Loss: (0.0978) |  Loss2: (0.0000) | Acc: (96.00%) (21178/21888)
Epoch: 171 | Batch_idx: 180 |  Loss: (0.0990) |  Loss2: (0.0000) | Acc: (96.00%) (22405/23168)
Epoch: 171 | Batch_idx: 190 |  Loss: (0.0984) |  Loss2: (0.0000) | Acc: (96.00%) (23649/24448)
Epoch: 171 | Batch_idx: 200 |  Loss: (0.0993) |  Loss2: (0.0000) | Acc: (96.00%) (24875/25728)
Epoch: 171 | Batch_idx: 210 |  Loss: (0.0994) |  Loss2: (0.0000) | Acc: (96.00%) (26107/27008)
Epoch: 171 | Batch_idx: 220 |  Loss: (0.0998) |  Loss2: (0.0000) | Acc: (96.00%) (27341/28288)
Epoch: 171 | Batch_idx: 230 |  Loss: (0.1003) |  Loss2: (0.0000) | Acc: (96.00%) (28572/29568)
Epoch: 171 | Batch_idx: 240 |  Loss: (0.1011) |  Loss2: (0.0000) | Acc: (96.00%) (29798/30848)
Epoch: 171 | Batch_idx: 250 |  Loss: (0.1018) |  Loss2: (0.0000) | Acc: (96.00%) (31019/32128)
Epoch: 171 | Batch_idx: 260 |  Loss: (0.1017) |  Loss2: (0.0000) | Acc: (96.00%) (32250/33408)
Epoch: 171 | Batch_idx: 270 |  Loss: (0.1020) |  Loss2: (0.0000) | Acc: (96.00%) (33484/34688)
Epoch: 171 | Batch_idx: 280 |  Loss: (0.1021) |  Loss2: (0.0000) | Acc: (96.00%) (34721/35968)
Epoch: 171 | Batch_idx: 290 |  Loss: (0.1027) |  Loss2: (0.0000) | Acc: (96.00%) (35948/37248)
Epoch: 171 | Batch_idx: 300 |  Loss: (0.1034) |  Loss2: (0.0000) | Acc: (96.00%) (37173/38528)
Epoch: 171 | Batch_idx: 310 |  Loss: (0.1039) |  Loss2: (0.0000) | Acc: (96.00%) (38394/39808)
Epoch: 171 | Batch_idx: 320 |  Loss: (0.1042) |  Loss2: (0.0000) | Acc: (96.00%) (39618/41088)
Epoch: 171 | Batch_idx: 330 |  Loss: (0.1044) |  Loss2: (0.0000) | Acc: (96.00%) (40844/42368)
Epoch: 171 | Batch_idx: 340 |  Loss: (0.1041) |  Loss2: (0.0000) | Acc: (96.00%) (42085/43648)
Epoch: 171 | Batch_idx: 350 |  Loss: (0.1045) |  Loss2: (0.0000) | Acc: (96.00%) (43319/44928)
Epoch: 171 | Batch_idx: 360 |  Loss: (0.1048) |  Loss2: (0.0000) | Acc: (96.00%) (44548/46208)
Epoch: 171 | Batch_idx: 370 |  Loss: (0.1049) |  Loss2: (0.0000) | Acc: (96.00%) (45782/47488)
Epoch: 171 | Batch_idx: 380 |  Loss: (0.1051) |  Loss2: (0.0000) | Acc: (96.00%) (47015/48768)
Epoch: 171 | Batch_idx: 390 |  Loss: (0.1052) |  Loss2: (0.0000) | Acc: (96.00%) (48196/50000)
# TEST : Loss: (0.3892) | Acc: (88.00%) (8838/10000)
percent tensor([0.5113, 0.5107, 0.5153, 0.5148, 0.5145, 0.5149, 0.5129, 0.5162, 0.5118,
        0.5116, 0.5097, 0.5133, 0.5103, 0.5131, 0.5115, 0.5122],
       device='cuda:0') torch.Size([16])
percent tensor([0.5183, 0.5261, 0.5181, 0.5157, 0.5142, 0.5261, 0.5191, 0.5122, 0.5144,
        0.5214, 0.5195, 0.5205, 0.5261, 0.5134, 0.5246, 0.5238],
       device='cuda:0') torch.Size([16])
percent tensor([0.5894, 0.5230, 0.6457, 0.6682, 0.6556, 0.6234, 0.5852, 0.6369, 0.6383,
        0.5666, 0.6035, 0.6012, 0.5002, 0.6527, 0.5693, 0.5864],
       device='cuda:0') torch.Size([16])
percent tensor([0.6404, 0.6324, 0.6357, 0.6381, 0.6397, 0.6412, 0.6407, 0.6421, 0.6395,
        0.6403, 0.6372, 0.6422, 0.6347, 0.6340, 0.6433, 0.6485],
       device='cuda:0') torch.Size([16])
percent tensor([0.6394, 0.5968, 0.6594, 0.6709, 0.6823, 0.7378, 0.6049, 0.6073, 0.6520,
        0.6491, 0.6031, 0.6193, 0.6347, 0.6458, 0.6082, 0.6983],
       device='cuda:0') torch.Size([16])
percent tensor([0.6174, 0.6920, 0.6687, 0.6960, 0.6605, 0.7490, 0.6690, 0.5267, 0.7174,
        0.6619, 0.7476, 0.6709, 0.7347, 0.7212, 0.5387, 0.6471],
       device='cuda:0') torch.Size([16])
percent tensor([0.5808, 0.6574, 0.6660, 0.6783, 0.6858, 0.6589, 0.6671, 0.6210, 0.6343,
        0.6693, 0.6819, 0.6033, 0.6268, 0.6068, 0.5769, 0.5619],
       device='cuda:0') torch.Size([16])
percent tensor([0.9999, 0.9998, 0.9996, 0.9999, 0.9995, 0.9986, 0.9996, 0.9996, 0.9998,
        0.9998, 0.9999, 0.9997, 0.9999, 0.9996, 0.9990, 0.9995],
       device='cuda:0') torch.Size([16])
Epoch: 172 | Batch_idx: 0 |  Loss: (0.0935) |  Loss2: (0.0000) | Acc: (97.00%) (125/128)
Epoch: 172 | Batch_idx: 10 |  Loss: (0.0822) |  Loss2: (0.0000) | Acc: (97.00%) (1375/1408)
Epoch: 172 | Batch_idx: 20 |  Loss: (0.0913) |  Loss2: (0.0000) | Acc: (97.00%) (2610/2688)
Epoch: 172 | Batch_idx: 30 |  Loss: (0.0975) |  Loss2: (0.0000) | Acc: (96.00%) (3847/3968)
Epoch: 172 | Batch_idx: 40 |  Loss: (0.0990) |  Loss2: (0.0000) | Acc: (96.00%) (5086/5248)
Epoch: 172 | Batch_idx: 50 |  Loss: (0.0956) |  Loss2: (0.0000) | Acc: (96.00%) (6329/6528)
Epoch: 172 | Batch_idx: 60 |  Loss: (0.0911) |  Loss2: (0.0000) | Acc: (97.00%) (7581/7808)
Epoch: 172 | Batch_idx: 70 |  Loss: (0.0947) |  Loss2: (0.0000) | Acc: (96.00%) (8813/9088)
Epoch: 172 | Batch_idx: 80 |  Loss: (0.0965) |  Loss2: (0.0000) | Acc: (96.00%) (10038/10368)
Epoch: 172 | Batch_idx: 90 |  Loss: (0.0972) |  Loss2: (0.0000) | Acc: (96.00%) (11272/11648)
Epoch: 172 | Batch_idx: 100 |  Loss: (0.0980) |  Loss2: (0.0000) | Acc: (96.00%) (12499/12928)
Epoch: 172 | Batch_idx: 110 |  Loss: (0.0973) |  Loss2: (0.0000) | Acc: (96.00%) (13738/14208)
Epoch: 172 | Batch_idx: 120 |  Loss: (0.0972) |  Loss2: (0.0000) | Acc: (96.00%) (14968/15488)
Epoch: 172 | Batch_idx: 130 |  Loss: (0.0964) |  Loss2: (0.0000) | Acc: (96.00%) (16209/16768)
Epoch: 172 | Batch_idx: 140 |  Loss: (0.0968) |  Loss2: (0.0000) | Acc: (96.00%) (17455/18048)
Epoch: 172 | Batch_idx: 150 |  Loss: (0.0969) |  Loss2: (0.0000) | Acc: (96.00%) (18689/19328)
Epoch: 172 | Batch_idx: 160 |  Loss: (0.0959) |  Loss2: (0.0000) | Acc: (96.00%) (19939/20608)
Epoch: 172 | Batch_idx: 170 |  Loss: (0.0964) |  Loss2: (0.0000) | Acc: (96.00%) (21163/21888)
Epoch: 172 | Batch_idx: 180 |  Loss: (0.0958) |  Loss2: (0.0000) | Acc: (96.00%) (22404/23168)
Epoch: 172 | Batch_idx: 190 |  Loss: (0.0968) |  Loss2: (0.0000) | Acc: (96.00%) (23628/24448)
Epoch: 172 | Batch_idx: 200 |  Loss: (0.0988) |  Loss2: (0.0000) | Acc: (96.00%) (24844/25728)
Epoch: 172 | Batch_idx: 210 |  Loss: (0.0989) |  Loss2: (0.0000) | Acc: (96.00%) (26082/27008)
Epoch: 172 | Batch_idx: 220 |  Loss: (0.0989) |  Loss2: (0.0000) | Acc: (96.00%) (27316/28288)
Epoch: 172 | Batch_idx: 230 |  Loss: (0.0992) |  Loss2: (0.0000) | Acc: (96.00%) (28551/29568)
Epoch: 172 | Batch_idx: 240 |  Loss: (0.0995) |  Loss2: (0.0000) | Acc: (96.00%) (29785/30848)
Epoch: 172 | Batch_idx: 250 |  Loss: (0.0990) |  Loss2: (0.0000) | Acc: (96.00%) (31033/32128)
Epoch: 172 | Batch_idx: 260 |  Loss: (0.0994) |  Loss2: (0.0000) | Acc: (96.00%) (32268/33408)
Epoch: 172 | Batch_idx: 270 |  Loss: (0.0995) |  Loss2: (0.0000) | Acc: (96.00%) (33497/34688)
Epoch: 172 | Batch_idx: 280 |  Loss: (0.0998) |  Loss2: (0.0000) | Acc: (96.00%) (34735/35968)
Epoch: 172 | Batch_idx: 290 |  Loss: (0.1000) |  Loss2: (0.0000) | Acc: (96.00%) (35973/37248)
Epoch: 172 | Batch_idx: 300 |  Loss: (0.0999) |  Loss2: (0.0000) | Acc: (96.00%) (37208/38528)
Epoch: 172 | Batch_idx: 310 |  Loss: (0.1005) |  Loss2: (0.0000) | Acc: (96.00%) (38435/39808)
Epoch: 172 | Batch_idx: 320 |  Loss: (0.1006) |  Loss2: (0.0000) | Acc: (96.00%) (39668/41088)
Epoch: 172 | Batch_idx: 330 |  Loss: (0.1004) |  Loss2: (0.0000) | Acc: (96.00%) (40908/42368)
Epoch: 172 | Batch_idx: 340 |  Loss: (0.1007) |  Loss2: (0.0000) | Acc: (96.00%) (42142/43648)
Epoch: 172 | Batch_idx: 350 |  Loss: (0.1002) |  Loss2: (0.0000) | Acc: (96.00%) (43388/44928)
Epoch: 172 | Batch_idx: 360 |  Loss: (0.1006) |  Loss2: (0.0000) | Acc: (96.00%) (44621/46208)
Epoch: 172 | Batch_idx: 370 |  Loss: (0.1010) |  Loss2: (0.0000) | Acc: (96.00%) (45850/47488)
Epoch: 172 | Batch_idx: 380 |  Loss: (0.1016) |  Loss2: (0.0000) | Acc: (96.00%) (47068/48768)
Epoch: 172 | Batch_idx: 390 |  Loss: (0.1018) |  Loss2: (0.0000) | Acc: (96.00%) (48256/50000)
# TEST : Loss: (0.4485) | Acc: (87.00%) (8756/10000)
percent tensor([0.5114, 0.5112, 0.5146, 0.5152, 0.5143, 0.5150, 0.5131, 0.5165, 0.5122,
        0.5119, 0.5100, 0.5128, 0.5106, 0.5138, 0.5117, 0.5126],
       device='cuda:0') torch.Size([16])
percent tensor([0.5187, 0.5242, 0.5185, 0.5153, 0.5140, 0.5252, 0.5184, 0.5102, 0.5138,
        0.5208, 0.5189, 0.5209, 0.5255, 0.5105, 0.5233, 0.5234],
       device='cuda:0') torch.Size([16])
percent tensor([0.5836, 0.5334, 0.6432, 0.6626, 0.6550, 0.6186, 0.5875, 0.6410, 0.6381,
        0.5739, 0.6031, 0.5982, 0.5000, 0.6566, 0.5711, 0.5844],
       device='cuda:0') torch.Size([16])
percent tensor([0.6413, 0.6323, 0.6348, 0.6372, 0.6395, 0.6382, 0.6409, 0.6376, 0.6405,
        0.6400, 0.6371, 0.6400, 0.6344, 0.6368, 0.6395, 0.6487],
       device='cuda:0') torch.Size([16])
percent tensor([0.6323, 0.6006, 0.6415, 0.6600, 0.6573, 0.7311, 0.6120, 0.5944, 0.6508,
        0.6480, 0.6016, 0.6163, 0.6228, 0.6617, 0.6008, 0.6953],
       device='cuda:0') torch.Size([16])
percent tensor([0.6065, 0.6683, 0.6887, 0.7070, 0.6629, 0.7507, 0.6647, 0.5681, 0.7139,
        0.6524, 0.7319, 0.6865, 0.7289, 0.7102, 0.5459, 0.6418],
       device='cuda:0') torch.Size([16])
percent tensor([0.5813, 0.6574, 0.6748, 0.6669, 0.6811, 0.6449, 0.6634, 0.6483, 0.6323,
        0.6641, 0.6764, 0.5895, 0.6292, 0.5807, 0.5814, 0.5504],
       device='cuda:0') torch.Size([16])
percent tensor([0.9999, 0.9998, 0.9998, 0.9999, 0.9995, 0.9992, 0.9996, 0.9998, 0.9999,
        0.9998, 0.9998, 0.9997, 0.9999, 0.9996, 0.9990, 0.9997],
       device='cuda:0') torch.Size([16])
Epoch: 173 | Batch_idx: 0 |  Loss: (0.0914) |  Loss2: (0.0000) | Acc: (96.00%) (124/128)
Epoch: 173 | Batch_idx: 10 |  Loss: (0.0963) |  Loss2: (0.0000) | Acc: (96.00%) (1364/1408)
Epoch: 173 | Batch_idx: 20 |  Loss: (0.0968) |  Loss2: (0.0000) | Acc: (96.00%) (2597/2688)
Epoch: 173 | Batch_idx: 30 |  Loss: (0.1047) |  Loss2: (0.0000) | Acc: (96.00%) (3822/3968)
Epoch: 173 | Batch_idx: 40 |  Loss: (0.1088) |  Loss2: (0.0000) | Acc: (96.00%) (5044/5248)
Epoch: 173 | Batch_idx: 50 |  Loss: (0.1078) |  Loss2: (0.0000) | Acc: (96.00%) (6279/6528)
Epoch: 173 | Batch_idx: 60 |  Loss: (0.1044) |  Loss2: (0.0000) | Acc: (96.00%) (7525/7808)
Epoch: 173 | Batch_idx: 70 |  Loss: (0.1047) |  Loss2: (0.0000) | Acc: (96.00%) (8754/9088)
Epoch: 173 | Batch_idx: 80 |  Loss: (0.1014) |  Loss2: (0.0000) | Acc: (96.00%) (10000/10368)
Epoch: 173 | Batch_idx: 90 |  Loss: (0.0997) |  Loss2: (0.0000) | Acc: (96.00%) (11240/11648)
Epoch: 173 | Batch_idx: 100 |  Loss: (0.1008) |  Loss2: (0.0000) | Acc: (96.00%) (12477/12928)
Epoch: 173 | Batch_idx: 110 |  Loss: (0.1007) |  Loss2: (0.0000) | Acc: (96.00%) (13709/14208)
Epoch: 173 | Batch_idx: 120 |  Loss: (0.1010) |  Loss2: (0.0000) | Acc: (96.00%) (14937/15488)
Epoch: 173 | Batch_idx: 130 |  Loss: (0.1003) |  Loss2: (0.0000) | Acc: (96.00%) (16179/16768)
Epoch: 173 | Batch_idx: 140 |  Loss: (0.1000) |  Loss2: (0.0000) | Acc: (96.00%) (17415/18048)
Epoch: 173 | Batch_idx: 150 |  Loss: (0.0996) |  Loss2: (0.0000) | Acc: (96.00%) (18649/19328)
Epoch: 173 | Batch_idx: 160 |  Loss: (0.0994) |  Loss2: (0.0000) | Acc: (96.00%) (19885/20608)
Epoch: 173 | Batch_idx: 170 |  Loss: (0.0989) |  Loss2: (0.0000) | Acc: (96.00%) (21124/21888)
Epoch: 173 | Batch_idx: 180 |  Loss: (0.0994) |  Loss2: (0.0000) | Acc: (96.00%) (22362/23168)
Epoch: 173 | Batch_idx: 190 |  Loss: (0.0984) |  Loss2: (0.0000) | Acc: (96.00%) (23613/24448)
Epoch: 173 | Batch_idx: 200 |  Loss: (0.0976) |  Loss2: (0.0000) | Acc: (96.00%) (24861/25728)
Epoch: 173 | Batch_idx: 210 |  Loss: (0.0980) |  Loss2: (0.0000) | Acc: (96.00%) (26100/27008)
Epoch: 173 | Batch_idx: 220 |  Loss: (0.0991) |  Loss2: (0.0000) | Acc: (96.00%) (27318/28288)
Epoch: 173 | Batch_idx: 230 |  Loss: (0.1002) |  Loss2: (0.0000) | Acc: (96.00%) (28540/29568)
Epoch: 173 | Batch_idx: 240 |  Loss: (0.1000) |  Loss2: (0.0000) | Acc: (96.00%) (29779/30848)
Epoch: 173 | Batch_idx: 250 |  Loss: (0.1001) |  Loss2: (0.0000) | Acc: (96.00%) (31017/32128)
Epoch: 173 | Batch_idx: 260 |  Loss: (0.1005) |  Loss2: (0.0000) | Acc: (96.00%) (32251/33408)
Epoch: 173 | Batch_idx: 270 |  Loss: (0.1003) |  Loss2: (0.0000) | Acc: (96.00%) (33490/34688)
Epoch: 173 | Batch_idx: 280 |  Loss: (0.1004) |  Loss2: (0.0000) | Acc: (96.00%) (34722/35968)
Epoch: 173 | Batch_idx: 290 |  Loss: (0.1004) |  Loss2: (0.0000) | Acc: (96.00%) (35959/37248)
Epoch: 173 | Batch_idx: 300 |  Loss: (0.1007) |  Loss2: (0.0000) | Acc: (96.00%) (37188/38528)
Epoch: 173 | Batch_idx: 310 |  Loss: (0.1004) |  Loss2: (0.0000) | Acc: (96.00%) (38431/39808)
Epoch: 173 | Batch_idx: 320 |  Loss: (0.1003) |  Loss2: (0.0000) | Acc: (96.00%) (39657/41088)
Epoch: 173 | Batch_idx: 330 |  Loss: (0.1000) |  Loss2: (0.0000) | Acc: (96.00%) (40897/42368)
Epoch: 173 | Batch_idx: 340 |  Loss: (0.0994) |  Loss2: (0.0000) | Acc: (96.00%) (42142/43648)
Epoch: 173 | Batch_idx: 350 |  Loss: (0.0997) |  Loss2: (0.0000) | Acc: (96.00%) (43374/44928)
Epoch: 173 | Batch_idx: 360 |  Loss: (0.1003) |  Loss2: (0.0000) | Acc: (96.00%) (44603/46208)
Epoch: 173 | Batch_idx: 370 |  Loss: (0.1000) |  Loss2: (0.0000) | Acc: (96.00%) (45846/47488)
Epoch: 173 | Batch_idx: 380 |  Loss: (0.1004) |  Loss2: (0.0000) | Acc: (96.00%) (47077/48768)
Epoch: 173 | Batch_idx: 390 |  Loss: (0.1002) |  Loss2: (0.0000) | Acc: (96.00%) (48265/50000)
# TEST : Loss: (0.3963) | Acc: (88.00%) (8814/10000)
percent tensor([0.5113, 0.5110, 0.5154, 0.5151, 0.5145, 0.5153, 0.5133, 0.5162, 0.5121,
        0.5119, 0.5099, 0.5133, 0.5103, 0.5137, 0.5118, 0.5125],
       device='cuda:0') torch.Size([16])
percent tensor([0.5193, 0.5242, 0.5179, 0.5161, 0.5151, 0.5277, 0.5186, 0.5112, 0.5138,
        0.5209, 0.5184, 0.5205, 0.5263, 0.5117, 0.5241, 0.5241],
       device='cuda:0') torch.Size([16])
percent tensor([0.5811, 0.5275, 0.6424, 0.6599, 0.6515, 0.6030, 0.5823, 0.6385, 0.6370,
        0.5659, 0.6019, 0.5931, 0.4922, 0.6599, 0.5661, 0.5806],
       device='cuda:0') torch.Size([16])
percent tensor([0.6424, 0.6341, 0.6353, 0.6385, 0.6404, 0.6431, 0.6441, 0.6424, 0.6413,
        0.6413, 0.6384, 0.6406, 0.6334, 0.6385, 0.6430, 0.6496],
       device='cuda:0') torch.Size([16])
percent tensor([0.6449, 0.5941, 0.6435, 0.6520, 0.6698, 0.7538, 0.6131, 0.6041, 0.6460,
        0.6399, 0.5998, 0.6114, 0.6227, 0.6483, 0.6097, 0.6997],
       device='cuda:0') torch.Size([16])
percent tensor([0.6161, 0.6721, 0.6801, 0.7187, 0.6758, 0.7678, 0.6843, 0.5510, 0.7080,
        0.6495, 0.7512, 0.6740, 0.7282, 0.7184, 0.5689, 0.6608],
       device='cuda:0') torch.Size([16])
percent tensor([0.5811, 0.6405, 0.6853, 0.6866, 0.6857, 0.6620, 0.6523, 0.6370, 0.6310,
        0.6434, 0.6799, 0.5978, 0.6230, 0.5726, 0.5757, 0.5611],
       device='cuda:0') torch.Size([16])
percent tensor([0.9999, 0.9998, 0.9998, 0.9999, 0.9994, 0.9989, 0.9998, 0.9995, 0.9998,
        0.9998, 0.9999, 0.9998, 0.9999, 0.9996, 0.9991, 0.9998],
       device='cuda:0') torch.Size([16])
False Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=128, out_features=16, bias=False)
True Linear(in_features=16, out_features=2, bias=False)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=128, out_features=16, bias=False)
True Linear(in_features=16, out_features=2, bias=False)
False Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=256, out_features=32, bias=False)
True Linear(in_features=32, out_features=2, bias=False)
False Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=256, out_features=32, bias=False)
True Linear(in_features=32, out_features=2, bias=False)
False Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=512, out_features=64, bias=False)
True Linear(in_features=64, out_features=2, bias=False)
False Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=512, out_features=64, bias=False)
True Linear(in_features=64, out_features=2, bias=False)
False Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1024, out_features=128, bias=False)
True Linear(in_features=128, out_features=2, bias=False)
False Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1024, out_features=128, bias=False)
True Linear(in_features=128, out_features=2, bias=False)
False Linear(in_features=512, out_features=10, bias=True)
Epoch: 174 | Batch_idx: 0 |  Loss: (0.1105) |  Loss2: (0.0000) | Acc: (95.00%) (122/128)
Epoch: 174 | Batch_idx: 10 |  Loss: (0.0925) |  Loss2: (0.0000) | Acc: (96.00%) (1361/1408)
Epoch: 174 | Batch_idx: 20 |  Loss: (0.1048) |  Loss2: (0.0000) | Acc: (96.00%) (2591/2688)
Epoch: 174 | Batch_idx: 30 |  Loss: (0.1052) |  Loss2: (0.0000) | Acc: (96.00%) (3821/3968)
Epoch: 174 | Batch_idx: 40 |  Loss: (0.1076) |  Loss2: (0.0000) | Acc: (96.00%) (5050/5248)
Epoch: 174 | Batch_idx: 50 |  Loss: (0.1135) |  Loss2: (0.0000) | Acc: (95.00%) (6262/6528)
Epoch: 174 | Batch_idx: 60 |  Loss: (0.1112) |  Loss2: (0.0000) | Acc: (95.00%) (7487/7808)
Epoch: 174 | Batch_idx: 70 |  Loss: (0.1128) |  Loss2: (0.0000) | Acc: (95.00%) (8705/9088)
Epoch: 174 | Batch_idx: 80 |  Loss: (0.1101) |  Loss2: (0.0000) | Acc: (95.00%) (9945/10368)
Epoch: 174 | Batch_idx: 90 |  Loss: (0.1116) |  Loss2: (0.0000) | Acc: (95.00%) (11169/11648)
Epoch: 174 | Batch_idx: 100 |  Loss: (0.1111) |  Loss2: (0.0000) | Acc: (95.00%) (12398/12928)
Epoch: 174 | Batch_idx: 110 |  Loss: (0.1122) |  Loss2: (0.0000) | Acc: (95.00%) (13619/14208)
Epoch: 174 | Batch_idx: 120 |  Loss: (0.1121) |  Loss2: (0.0000) | Acc: (95.00%) (14846/15488)
Epoch: 174 | Batch_idx: 130 |  Loss: (0.1128) |  Loss2: (0.0000) | Acc: (95.00%) (16068/16768)
Epoch: 174 | Batch_idx: 140 |  Loss: (0.1122) |  Loss2: (0.0000) | Acc: (95.00%) (17298/18048)
Epoch: 174 | Batch_idx: 150 |  Loss: (0.1124) |  Loss2: (0.0000) | Acc: (95.00%) (18526/19328)
Epoch: 174 | Batch_idx: 160 |  Loss: (0.1119) |  Loss2: (0.0000) | Acc: (95.00%) (19763/20608)
Epoch: 174 | Batch_idx: 170 |  Loss: (0.1118) |  Loss2: (0.0000) | Acc: (95.00%) (20988/21888)
Epoch: 174 | Batch_idx: 180 |  Loss: (0.1129) |  Loss2: (0.0000) | Acc: (95.00%) (22208/23168)
Epoch: 174 | Batch_idx: 190 |  Loss: (0.1124) |  Loss2: (0.0000) | Acc: (95.00%) (23443/24448)
Epoch: 174 | Batch_idx: 200 |  Loss: (0.1114) |  Loss2: (0.0000) | Acc: (95.00%) (24673/25728)
Epoch: 174 | Batch_idx: 210 |  Loss: (0.1110) |  Loss2: (0.0000) | Acc: (95.00%) (25909/27008)
Epoch: 174 | Batch_idx: 220 |  Loss: (0.1108) |  Loss2: (0.0000) | Acc: (95.00%) (27144/28288)
Epoch: 174 | Batch_idx: 230 |  Loss: (0.1114) |  Loss2: (0.0000) | Acc: (95.00%) (28366/29568)
Epoch: 174 | Batch_idx: 240 |  Loss: (0.1105) |  Loss2: (0.0000) | Acc: (95.00%) (29598/30848)
Epoch: 174 | Batch_idx: 250 |  Loss: (0.1096) |  Loss2: (0.0000) | Acc: (96.00%) (30845/32128)
Epoch: 174 | Batch_idx: 260 |  Loss: (0.1095) |  Loss2: (0.0000) | Acc: (96.00%) (32072/33408)
Epoch: 174 | Batch_idx: 270 |  Loss: (0.1089) |  Loss2: (0.0000) | Acc: (96.00%) (33310/34688)
Epoch: 174 | Batch_idx: 280 |  Loss: (0.1083) |  Loss2: (0.0000) | Acc: (96.00%) (34549/35968)
Epoch: 174 | Batch_idx: 290 |  Loss: (0.1085) |  Loss2: (0.0000) | Acc: (96.00%) (35773/37248)
Epoch: 174 | Batch_idx: 300 |  Loss: (0.1083) |  Loss2: (0.0000) | Acc: (96.00%) (37012/38528)
Epoch: 174 | Batch_idx: 310 |  Loss: (0.1078) |  Loss2: (0.0000) | Acc: (96.00%) (38259/39808)
Epoch: 174 | Batch_idx: 320 |  Loss: (0.1082) |  Loss2: (0.0000) | Acc: (96.00%) (39487/41088)
Epoch: 174 | Batch_idx: 330 |  Loss: (0.1080) |  Loss2: (0.0000) | Acc: (96.00%) (40720/42368)
Epoch: 174 | Batch_idx: 340 |  Loss: (0.1079) |  Loss2: (0.0000) | Acc: (96.00%) (41950/43648)
Epoch: 174 | Batch_idx: 350 |  Loss: (0.1077) |  Loss2: (0.0000) | Acc: (96.00%) (43188/44928)
Epoch: 174 | Batch_idx: 360 |  Loss: (0.1076) |  Loss2: (0.0000) | Acc: (96.00%) (44415/46208)
Epoch: 174 | Batch_idx: 370 |  Loss: (0.1072) |  Loss2: (0.0000) | Acc: (96.00%) (45655/47488)
Epoch: 174 | Batch_idx: 380 |  Loss: (0.1073) |  Loss2: (0.0000) | Acc: (96.00%) (46890/48768)
Epoch: 174 | Batch_idx: 390 |  Loss: (0.1073) |  Loss2: (0.0000) | Acc: (96.00%) (48083/50000)
# TEST : Loss: (0.3994) | Acc: (88.00%) (8828/10000)
percent tensor([0.5114, 0.5110, 0.5154, 0.5151, 0.5146, 0.5157, 0.5133, 0.5164, 0.5122,
        0.5120, 0.5100, 0.5133, 0.5103, 0.5136, 0.5119, 0.5126],
       device='cuda:0') torch.Size([16])
percent tensor([0.5192, 0.5245, 0.5156, 0.5149, 0.5144, 0.5297, 0.5186, 0.5092, 0.5137,
        0.5201, 0.5192, 0.5188, 0.5262, 0.5123, 0.5251, 0.5246],
       device='cuda:0') torch.Size([16])
percent tensor([0.5974, 0.5431, 0.6558, 0.6731, 0.6621, 0.6099, 0.5959, 0.6493, 0.6542,
        0.5824, 0.6203, 0.6074, 0.5121, 0.6755, 0.5783, 0.5966],
       device='cuda:0') torch.Size([16])
percent tensor([0.6688, 0.6585, 0.6575, 0.6601, 0.6636, 0.6695, 0.6697, 0.6654, 0.6629,
        0.6655, 0.6628, 0.6632, 0.6567, 0.6611, 0.6689, 0.6760],
       device='cuda:0') torch.Size([16])
percent tensor([0.6586, 0.6061, 0.6414, 0.6573, 0.6677, 0.7740, 0.6198, 0.6093, 0.6544,
        0.6498, 0.6072, 0.6118, 0.6328, 0.6541, 0.6192, 0.7228],
       device='cuda:0') torch.Size([16])
percent tensor([0.6164, 0.6730, 0.6772, 0.7243, 0.6801, 0.7760, 0.6782, 0.5532, 0.7214,
        0.6509, 0.7546, 0.6647, 0.7351, 0.7170, 0.5726, 0.6575],
       device='cuda:0') torch.Size([16])
percent tensor([0.5772, 0.6287, 0.6672, 0.6731, 0.6825, 0.6461, 0.6412, 0.6397, 0.6296,
        0.6365, 0.6728, 0.5853, 0.6145, 0.5640, 0.5744, 0.5533],
       device='cuda:0') torch.Size([16])
percent tensor([0.9999, 0.9998, 0.9997, 0.9999, 0.9993, 0.9990, 0.9997, 0.9993, 0.9998,
        0.9998, 0.9998, 0.9997, 0.9999, 0.9995, 0.9993, 0.9998],
       device='cuda:0') torch.Size([16])
Epoch: 175 | Batch_idx: 0 |  Loss: (0.1245) |  Loss2: (0.0000) | Acc: (96.00%) (123/128)
Epoch: 175 | Batch_idx: 10 |  Loss: (0.1102) |  Loss2: (0.0000) | Acc: (96.00%) (1360/1408)
Epoch: 175 | Batch_idx: 20 |  Loss: (0.1064) |  Loss2: (0.0000) | Acc: (96.00%) (2601/2688)
Epoch: 175 | Batch_idx: 30 |  Loss: (0.1089) |  Loss2: (0.0000) | Acc: (96.00%) (3836/3968)
Epoch: 175 | Batch_idx: 40 |  Loss: (0.1047) |  Loss2: (0.0000) | Acc: (96.00%) (5074/5248)
Epoch: 175 | Batch_idx: 50 |  Loss: (0.1063) |  Loss2: (0.0000) | Acc: (96.00%) (6300/6528)
Epoch: 175 | Batch_idx: 60 |  Loss: (0.1063) |  Loss2: (0.0000) | Acc: (96.00%) (7526/7808)
Epoch: 175 | Batch_idx: 70 |  Loss: (0.1060) |  Loss2: (0.0000) | Acc: (96.00%) (8762/9088)
Epoch: 175 | Batch_idx: 80 |  Loss: (0.1060) |  Loss2: (0.0000) | Acc: (96.00%) (9993/10368)
Epoch: 175 | Batch_idx: 90 |  Loss: (0.1069) |  Loss2: (0.0000) | Acc: (96.00%) (11224/11648)
Epoch: 175 | Batch_idx: 100 |  Loss: (0.1069) |  Loss2: (0.0000) | Acc: (96.00%) (12461/12928)
Epoch: 175 | Batch_idx: 110 |  Loss: (0.1053) |  Loss2: (0.0000) | Acc: (96.00%) (13701/14208)
Epoch: 175 | Batch_idx: 120 |  Loss: (0.1044) |  Loss2: (0.0000) | Acc: (96.00%) (14940/15488)
Epoch: 175 | Batch_idx: 130 |  Loss: (0.1050) |  Loss2: (0.0000) | Acc: (96.00%) (16171/16768)
Epoch: 175 | Batch_idx: 140 |  Loss: (0.1044) |  Loss2: (0.0000) | Acc: (96.00%) (17408/18048)
Epoch: 175 | Batch_idx: 150 |  Loss: (0.1046) |  Loss2: (0.0000) | Acc: (96.00%) (18642/19328)
Epoch: 175 | Batch_idx: 160 |  Loss: (0.1039) |  Loss2: (0.0000) | Acc: (96.00%) (19881/20608)
Epoch: 175 | Batch_idx: 170 |  Loss: (0.1045) |  Loss2: (0.0000) | Acc: (96.00%) (21116/21888)
Epoch: 175 | Batch_idx: 180 |  Loss: (0.1043) |  Loss2: (0.0000) | Acc: (96.00%) (22351/23168)
Epoch: 175 | Batch_idx: 190 |  Loss: (0.1044) |  Loss2: (0.0000) | Acc: (96.00%) (23586/24448)
Epoch: 175 | Batch_idx: 200 |  Loss: (0.1039) |  Loss2: (0.0000) | Acc: (96.00%) (24826/25728)
Epoch: 175 | Batch_idx: 210 |  Loss: (0.1032) |  Loss2: (0.0000) | Acc: (96.00%) (26063/27008)
Epoch: 175 | Batch_idx: 220 |  Loss: (0.1025) |  Loss2: (0.0000) | Acc: (96.00%) (27305/28288)
Epoch: 175 | Batch_idx: 230 |  Loss: (0.1027) |  Loss2: (0.0000) | Acc: (96.00%) (28536/29568)
Epoch: 175 | Batch_idx: 240 |  Loss: (0.1028) |  Loss2: (0.0000) | Acc: (96.00%) (29766/30848)
Epoch: 175 | Batch_idx: 250 |  Loss: (0.1022) |  Loss2: (0.0000) | Acc: (96.00%) (31003/32128)
Epoch: 175 | Batch_idx: 260 |  Loss: (0.1024) |  Loss2: (0.0000) | Acc: (96.00%) (32239/33408)
Epoch: 175 | Batch_idx: 270 |  Loss: (0.1026) |  Loss2: (0.0000) | Acc: (96.00%) (33476/34688)
Epoch: 175 | Batch_idx: 280 |  Loss: (0.1023) |  Loss2: (0.0000) | Acc: (96.00%) (34721/35968)
Epoch: 175 | Batch_idx: 290 |  Loss: (0.1019) |  Loss2: (0.0000) | Acc: (96.00%) (35961/37248)
Epoch: 175 | Batch_idx: 300 |  Loss: (0.1017) |  Loss2: (0.0000) | Acc: (96.00%) (37194/38528)
Epoch: 175 | Batch_idx: 310 |  Loss: (0.1016) |  Loss2: (0.0000) | Acc: (96.00%) (38434/39808)
Epoch: 175 | Batch_idx: 320 |  Loss: (0.1017) |  Loss2: (0.0000) | Acc: (96.00%) (39675/41088)
Epoch: 175 | Batch_idx: 330 |  Loss: (0.1012) |  Loss2: (0.0000) | Acc: (96.00%) (40917/42368)
Epoch: 175 | Batch_idx: 340 |  Loss: (0.1009) |  Loss2: (0.0000) | Acc: (96.00%) (42159/43648)
Epoch: 175 | Batch_idx: 350 |  Loss: (0.1013) |  Loss2: (0.0000) | Acc: (96.00%) (43395/44928)
Epoch: 175 | Batch_idx: 360 |  Loss: (0.1008) |  Loss2: (0.0000) | Acc: (96.00%) (44635/46208)
Epoch: 175 | Batch_idx: 370 |  Loss: (0.1006) |  Loss2: (0.0000) | Acc: (96.00%) (45872/47488)
Epoch: 175 | Batch_idx: 380 |  Loss: (0.1007) |  Loss2: (0.0000) | Acc: (96.00%) (47104/48768)
Epoch: 175 | Batch_idx: 390 |  Loss: (0.1007) |  Loss2: (0.0000) | Acc: (96.00%) (48296/50000)
=> saving checkpoint 'drive/app/torch/save_Schedule/checkpoint_175.pth.tar'
# TEST : Loss: (0.3895) | Acc: (88.00%) (8853/10000)
percent tensor([0.5118, 0.5114, 0.5156, 0.5154, 0.5149, 0.5160, 0.5136, 0.5167, 0.5125,
        0.5123, 0.5104, 0.5136, 0.5107, 0.5138, 0.5122, 0.5129],
       device='cuda:0') torch.Size([16])
percent tensor([0.5206, 0.5258, 0.5162, 0.5156, 0.5152, 0.5306, 0.5200, 0.5101, 0.5154,
        0.5213, 0.5208, 0.5195, 0.5276, 0.5142, 0.5263, 0.5257],
       device='cuda:0') torch.Size([16])
percent tensor([0.6049, 0.5504, 0.6560, 0.6746, 0.6638, 0.6220, 0.6020, 0.6492, 0.6586,
        0.5874, 0.6285, 0.6101, 0.5196, 0.6805, 0.5875, 0.6042],
       device='cuda:0') torch.Size([16])
percent tensor([0.6691, 0.6575, 0.6573, 0.6592, 0.6631, 0.6705, 0.6695, 0.6646, 0.6624,
        0.6646, 0.6618, 0.6621, 0.6568, 0.6600, 0.6688, 0.6764],
       device='cuda:0') torch.Size([16])
percent tensor([0.6499, 0.6006, 0.6379, 0.6507, 0.6642, 0.7706, 0.6146, 0.6023, 0.6464,
        0.6437, 0.5961, 0.6044, 0.6279, 0.6447, 0.6087, 0.7199],
       device='cuda:0') torch.Size([16])
percent tensor([0.6218, 0.6748, 0.6826, 0.7299, 0.6835, 0.7756, 0.6797, 0.5631, 0.7235,
        0.6562, 0.7575, 0.6705, 0.7364, 0.7199, 0.5742, 0.6549],
       device='cuda:0') torch.Size([16])
percent tensor([0.5789, 0.6256, 0.6676, 0.6764, 0.6864, 0.6399, 0.6402, 0.6498, 0.6203,
        0.6379, 0.6677, 0.5913, 0.6028, 0.5637, 0.5789, 0.5561],
       device='cuda:0') torch.Size([16])
percent tensor([0.9999, 0.9998, 0.9997, 0.9999, 0.9993, 0.9990, 0.9997, 0.9993, 0.9998,
        0.9998, 0.9998, 0.9997, 0.9999, 0.9995, 0.9993, 0.9997],
       device='cuda:0') torch.Size([16])
Epoch: 176 | Batch_idx: 0 |  Loss: (0.0813) |  Loss2: (0.0000) | Acc: (97.00%) (125/128)
Epoch: 176 | Batch_idx: 10 |  Loss: (0.0838) |  Loss2: (0.0000) | Acc: (96.00%) (1364/1408)
Epoch: 176 | Batch_idx: 20 |  Loss: (0.0892) |  Loss2: (0.0000) | Acc: (97.00%) (2611/2688)
Epoch: 176 | Batch_idx: 30 |  Loss: (0.0912) |  Loss2: (0.0000) | Acc: (96.00%) (3844/3968)
Epoch: 176 | Batch_idx: 40 |  Loss: (0.0969) |  Loss2: (0.0000) | Acc: (96.00%) (5069/5248)
Epoch: 176 | Batch_idx: 50 |  Loss: (0.0999) |  Loss2: (0.0000) | Acc: (96.00%) (6299/6528)
Epoch: 176 | Batch_idx: 60 |  Loss: (0.1000) |  Loss2: (0.0000) | Acc: (96.00%) (7534/7808)
Epoch: 176 | Batch_idx: 70 |  Loss: (0.0978) |  Loss2: (0.0000) | Acc: (96.00%) (8778/9088)
Epoch: 176 | Batch_idx: 80 |  Loss: (0.0964) |  Loss2: (0.0000) | Acc: (96.00%) (10018/10368)
Epoch: 176 | Batch_idx: 90 |  Loss: (0.0966) |  Loss2: (0.0000) | Acc: (96.00%) (11256/11648)
Epoch: 176 | Batch_idx: 100 |  Loss: (0.0957) |  Loss2: (0.0000) | Acc: (96.00%) (12495/12928)
Epoch: 176 | Batch_idx: 110 |  Loss: (0.0952) |  Loss2: (0.0000) | Acc: (96.00%) (13735/14208)
Epoch: 176 | Batch_idx: 120 |  Loss: (0.0941) |  Loss2: (0.0000) | Acc: (96.00%) (14979/15488)
Epoch: 176 | Batch_idx: 130 |  Loss: (0.0941) |  Loss2: (0.0000) | Acc: (96.00%) (16219/16768)
Epoch: 176 | Batch_idx: 140 |  Loss: (0.0946) |  Loss2: (0.0000) | Acc: (96.00%) (17457/18048)
Epoch: 176 | Batch_idx: 150 |  Loss: (0.0946) |  Loss2: (0.0000) | Acc: (96.00%) (18693/19328)
Epoch: 176 | Batch_idx: 160 |  Loss: (0.0949) |  Loss2: (0.0000) | Acc: (96.00%) (19929/20608)
Epoch: 176 | Batch_idx: 170 |  Loss: (0.0951) |  Loss2: (0.0000) | Acc: (96.00%) (21159/21888)
Epoch: 176 | Batch_idx: 180 |  Loss: (0.0953) |  Loss2: (0.0000) | Acc: (96.00%) (22395/23168)
Epoch: 176 | Batch_idx: 190 |  Loss: (0.0949) |  Loss2: (0.0000) | Acc: (96.00%) (23638/24448)
Epoch: 176 | Batch_idx: 200 |  Loss: (0.0941) |  Loss2: (0.0000) | Acc: (96.00%) (24888/25728)
Epoch: 176 | Batch_idx: 210 |  Loss: (0.0954) |  Loss2: (0.0000) | Acc: (96.00%) (26116/27008)
Epoch: 176 | Batch_idx: 220 |  Loss: (0.0957) |  Loss2: (0.0000) | Acc: (96.00%) (27349/28288)
Epoch: 176 | Batch_idx: 230 |  Loss: (0.0956) |  Loss2: (0.0000) | Acc: (96.00%) (28584/29568)
Epoch: 176 | Batch_idx: 240 |  Loss: (0.0954) |  Loss2: (0.0000) | Acc: (96.00%) (29829/30848)
Epoch: 176 | Batch_idx: 250 |  Loss: (0.0950) |  Loss2: (0.0000) | Acc: (96.00%) (31077/32128)
Epoch: 176 | Batch_idx: 260 |  Loss: (0.0950) |  Loss2: (0.0000) | Acc: (96.00%) (32323/33408)
Epoch: 176 | Batch_idx: 270 |  Loss: (0.0952) |  Loss2: (0.0000) | Acc: (96.00%) (33558/34688)
Epoch: 176 | Batch_idx: 280 |  Loss: (0.0952) |  Loss2: (0.0000) | Acc: (96.00%) (34792/35968)
Epoch: 176 | Batch_idx: 290 |  Loss: (0.0946) |  Loss2: (0.0000) | Acc: (96.00%) (36037/37248)
Epoch: 176 | Batch_idx: 300 |  Loss: (0.0947) |  Loss2: (0.0000) | Acc: (96.00%) (37278/38528)
Epoch: 176 | Batch_idx: 310 |  Loss: (0.0947) |  Loss2: (0.0000) | Acc: (96.00%) (38523/39808)
Epoch: 176 | Batch_idx: 320 |  Loss: (0.0943) |  Loss2: (0.0000) | Acc: (96.00%) (39774/41088)
Epoch: 176 | Batch_idx: 330 |  Loss: (0.0937) |  Loss2: (0.0000) | Acc: (96.00%) (41019/42368)
Epoch: 176 | Batch_idx: 340 |  Loss: (0.0939) |  Loss2: (0.0000) | Acc: (96.00%) (42254/43648)
Epoch: 176 | Batch_idx: 350 |  Loss: (0.0938) |  Loss2: (0.0000) | Acc: (96.00%) (43494/44928)
Epoch: 176 | Batch_idx: 360 |  Loss: (0.0937) |  Loss2: (0.0000) | Acc: (96.00%) (44734/46208)
Epoch: 176 | Batch_idx: 370 |  Loss: (0.0936) |  Loss2: (0.0000) | Acc: (96.00%) (45972/47488)
Epoch: 176 | Batch_idx: 380 |  Loss: (0.0937) |  Loss2: (0.0000) | Acc: (96.00%) (47208/48768)
Epoch: 176 | Batch_idx: 390 |  Loss: (0.0943) |  Loss2: (0.0000) | Acc: (96.00%) (48390/50000)
# TEST : Loss: (0.3823) | Acc: (88.00%) (8868/10000)
percent tensor([0.5110, 0.5104, 0.5149, 0.5148, 0.5141, 0.5154, 0.5127, 0.5158, 0.5116,
        0.5114, 0.5095, 0.5128, 0.5098, 0.5129, 0.5114, 0.5121],
       device='cuda:0') torch.Size([16])
percent tensor([0.5222, 0.5273, 0.5172, 0.5168, 0.5164, 0.5319, 0.5215, 0.5113, 0.5172,
        0.5228, 0.5226, 0.5206, 0.5291, 0.5159, 0.5279, 0.5273],
       device='cuda:0') torch.Size([16])
percent tensor([0.6015, 0.5514, 0.6539, 0.6726, 0.6621, 0.6187, 0.6022, 0.6477, 0.6559,
        0.5875, 0.6282, 0.6096, 0.5170, 0.6786, 0.5876, 0.6017],
       device='cuda:0') torch.Size([16])
percent tensor([0.6664, 0.6541, 0.6544, 0.6560, 0.6595, 0.6673, 0.6662, 0.6613, 0.6596,
        0.6615, 0.6582, 0.6583, 0.6538, 0.6566, 0.6651, 0.6737],
       device='cuda:0') torch.Size([16])
percent tensor([0.6576, 0.6076, 0.6456, 0.6589, 0.6718, 0.7784, 0.6201, 0.6093, 0.6499,
        0.6486, 0.5973, 0.6096, 0.6338, 0.6502, 0.6155, 0.7300],
       device='cuda:0') torch.Size([16])
percent tensor([0.6140, 0.6697, 0.6770, 0.7230, 0.6785, 0.7702, 0.6747, 0.5538, 0.7173,
        0.6492, 0.7545, 0.6632, 0.7334, 0.7155, 0.5646, 0.6456],
       device='cuda:0') torch.Size([16])
percent tensor([0.5841, 0.6302, 0.6714, 0.6817, 0.6944, 0.6433, 0.6472, 0.6588, 0.6159,
        0.6419, 0.6716, 0.5940, 0.6024, 0.5706, 0.5864, 0.5644],
       device='cuda:0') torch.Size([16])
percent tensor([0.9999, 0.9998, 0.9997, 0.9999, 0.9993, 0.9990, 0.9997, 0.9993, 0.9998,
        0.9998, 0.9998, 0.9998, 0.9999, 0.9995, 0.9993, 0.9997],
       device='cuda:0') torch.Size([16])
Epoch: 177 | Batch_idx: 0 |  Loss: (0.1173) |  Loss2: (0.0000) | Acc: (96.00%) (124/128)
Epoch: 177 | Batch_idx: 10 |  Loss: (0.0881) |  Loss2: (0.0000) | Acc: (97.00%) (1366/1408)
Epoch: 177 | Batch_idx: 20 |  Loss: (0.1032) |  Loss2: (0.0000) | Acc: (96.00%) (2596/2688)
Epoch: 177 | Batch_idx: 30 |  Loss: (0.0985) |  Loss2: (0.0000) | Acc: (96.00%) (3836/3968)
Epoch: 177 | Batch_idx: 40 |  Loss: (0.0948) |  Loss2: (0.0000) | Acc: (96.00%) (5079/5248)
Epoch: 177 | Batch_idx: 50 |  Loss: (0.0936) |  Loss2: (0.0000) | Acc: (96.00%) (6325/6528)
Epoch: 177 | Batch_idx: 60 |  Loss: (0.0919) |  Loss2: (0.0000) | Acc: (96.00%) (7572/7808)
Epoch: 177 | Batch_idx: 70 |  Loss: (0.0929) |  Loss2: (0.0000) | Acc: (96.00%) (8813/9088)
Epoch: 177 | Batch_idx: 80 |  Loss: (0.0932) |  Loss2: (0.0000) | Acc: (96.00%) (10051/10368)
Epoch: 177 | Batch_idx: 90 |  Loss: (0.0914) |  Loss2: (0.0000) | Acc: (96.00%) (11297/11648)
Epoch: 177 | Batch_idx: 100 |  Loss: (0.0898) |  Loss2: (0.0000) | Acc: (97.00%) (12546/12928)
Epoch: 177 | Batch_idx: 110 |  Loss: (0.0903) |  Loss2: (0.0000) | Acc: (97.00%) (13782/14208)
Epoch: 177 | Batch_idx: 120 |  Loss: (0.0898) |  Loss2: (0.0000) | Acc: (96.00%) (15021/15488)
Epoch: 177 | Batch_idx: 130 |  Loss: (0.0902) |  Loss2: (0.0000) | Acc: (96.00%) (16259/16768)
Epoch: 177 | Batch_idx: 140 |  Loss: (0.0908) |  Loss2: (0.0000) | Acc: (96.00%) (17496/18048)
Epoch: 177 | Batch_idx: 150 |  Loss: (0.0899) |  Loss2: (0.0000) | Acc: (97.00%) (18752/19328)
Epoch: 177 | Batch_idx: 160 |  Loss: (0.0900) |  Loss2: (0.0000) | Acc: (97.00%) (19998/20608)
Epoch: 177 | Batch_idx: 170 |  Loss: (0.0899) |  Loss2: (0.0000) | Acc: (97.00%) (21243/21888)
Epoch: 177 | Batch_idx: 180 |  Loss: (0.0892) |  Loss2: (0.0000) | Acc: (97.00%) (22494/23168)
Epoch: 177 | Batch_idx: 190 |  Loss: (0.0899) |  Loss2: (0.0000) | Acc: (97.00%) (23725/24448)
Epoch: 177 | Batch_idx: 200 |  Loss: (0.0902) |  Loss2: (0.0000) | Acc: (97.00%) (24965/25728)
Epoch: 177 | Batch_idx: 210 |  Loss: (0.0901) |  Loss2: (0.0000) | Acc: (97.00%) (26213/27008)
Epoch: 177 | Batch_idx: 220 |  Loss: (0.0901) |  Loss2: (0.0000) | Acc: (97.00%) (27451/28288)
Epoch: 177 | Batch_idx: 230 |  Loss: (0.0904) |  Loss2: (0.0000) | Acc: (97.00%) (28690/29568)
Epoch: 177 | Batch_idx: 240 |  Loss: (0.0904) |  Loss2: (0.0000) | Acc: (97.00%) (29932/30848)
Epoch: 177 | Batch_idx: 250 |  Loss: (0.0897) |  Loss2: (0.0000) | Acc: (97.00%) (31184/32128)
Epoch: 177 | Batch_idx: 260 |  Loss: (0.0896) |  Loss2: (0.0000) | Acc: (97.00%) (32422/33408)
Epoch: 177 | Batch_idx: 270 |  Loss: (0.0905) |  Loss2: (0.0000) | Acc: (97.00%) (33651/34688)
Epoch: 177 | Batch_idx: 280 |  Loss: (0.0907) |  Loss2: (0.0000) | Acc: (96.00%) (34885/35968)
Epoch: 177 | Batch_idx: 290 |  Loss: (0.0913) |  Loss2: (0.0000) | Acc: (96.00%) (36121/37248)
Epoch: 177 | Batch_idx: 300 |  Loss: (0.0904) |  Loss2: (0.0000) | Acc: (96.00%) (37369/38528)
Epoch: 177 | Batch_idx: 310 |  Loss: (0.0912) |  Loss2: (0.0000) | Acc: (96.00%) (38605/39808)
Epoch: 177 | Batch_idx: 320 |  Loss: (0.0908) |  Loss2: (0.0000) | Acc: (97.00%) (39862/41088)
Epoch: 177 | Batch_idx: 330 |  Loss: (0.0906) |  Loss2: (0.0000) | Acc: (97.00%) (41107/42368)
Epoch: 177 | Batch_idx: 340 |  Loss: (0.0906) |  Loss2: (0.0000) | Acc: (97.00%) (42353/43648)
Epoch: 177 | Batch_idx: 350 |  Loss: (0.0906) |  Loss2: (0.0000) | Acc: (97.00%) (43595/44928)
Epoch: 177 | Batch_idx: 360 |  Loss: (0.0906) |  Loss2: (0.0000) | Acc: (97.00%) (44836/46208)
Epoch: 177 | Batch_idx: 370 |  Loss: (0.0904) |  Loss2: (0.0000) | Acc: (97.00%) (46082/47488)
Epoch: 177 | Batch_idx: 380 |  Loss: (0.0906) |  Loss2: (0.0000) | Acc: (97.00%) (47319/48768)
Epoch: 177 | Batch_idx: 390 |  Loss: (0.0906) |  Loss2: (0.0000) | Acc: (97.00%) (48518/50000)
# TEST : Loss: (0.3776) | Acc: (88.00%) (8861/10000)
percent tensor([0.5117, 0.5111, 0.5155, 0.5153, 0.5149, 0.5160, 0.5134, 0.5165, 0.5123,
        0.5121, 0.5102, 0.5134, 0.5105, 0.5135, 0.5120, 0.5128],
       device='cuda:0') torch.Size([16])
percent tensor([0.5236, 0.5287, 0.5188, 0.5183, 0.5180, 0.5330, 0.5230, 0.5128, 0.5189,
        0.5241, 0.5241, 0.5219, 0.5307, 0.5176, 0.5293, 0.5288],
       device='cuda:0') torch.Size([16])
percent tensor([0.5944, 0.5433, 0.6482, 0.6678, 0.6573, 0.6145, 0.5953, 0.6385, 0.6495,
        0.5794, 0.6226, 0.6007, 0.5085, 0.6738, 0.5806, 0.5946],
       device='cuda:0') torch.Size([16])
percent tensor([0.6674, 0.6553, 0.6567, 0.6570, 0.6608, 0.6685, 0.6679, 0.6623, 0.6610,
        0.6626, 0.6593, 0.6591, 0.6552, 0.6578, 0.6662, 0.6749],
       device='cuda:0') torch.Size([16])
percent tensor([0.6635, 0.6106, 0.6612, 0.6702, 0.6843, 0.7876, 0.6259, 0.6205, 0.6553,
        0.6533, 0.5976, 0.6186, 0.6395, 0.6521, 0.6207, 0.7364],
       device='cuda:0') torch.Size([16])
percent tensor([0.6181, 0.6755, 0.6762, 0.7221, 0.6766, 0.7721, 0.6771, 0.5546, 0.7197,
        0.6559, 0.7592, 0.6651, 0.7398, 0.7162, 0.5653, 0.6474],
       device='cuda:0') torch.Size([16])
percent tensor([0.5788, 0.6251, 0.6645, 0.6784, 0.6925, 0.6360, 0.6417, 0.6573, 0.6052,
        0.6359, 0.6668, 0.5890, 0.5919, 0.5647, 0.5835, 0.5620],
       device='cuda:0') torch.Size([16])
percent tensor([0.9999, 0.9998, 0.9997, 0.9999, 0.9993, 0.9990, 0.9997, 0.9993, 0.9998,
        0.9998, 0.9998, 0.9997, 0.9999, 0.9995, 0.9993, 0.9997],
       device='cuda:0') torch.Size([16])
Epoch: 178 | Batch_idx: 0 |  Loss: (0.0539) |  Loss2: (0.0000) | Acc: (99.00%) (127/128)
Epoch: 178 | Batch_idx: 10 |  Loss: (0.0873) |  Loss2: (0.0000) | Acc: (97.00%) (1371/1408)
Epoch: 178 | Batch_idx: 20 |  Loss: (0.0836) |  Loss2: (0.0000) | Acc: (97.00%) (2613/2688)
Epoch: 178 | Batch_idx: 30 |  Loss: (0.0889) |  Loss2: (0.0000) | Acc: (97.00%) (3857/3968)
Epoch: 178 | Batch_idx: 40 |  Loss: (0.0895) |  Loss2: (0.0000) | Acc: (97.00%) (5095/5248)
Epoch: 178 | Batch_idx: 50 |  Loss: (0.0891) |  Loss2: (0.0000) | Acc: (96.00%) (6331/6528)
Epoch: 178 | Batch_idx: 60 |  Loss: (0.0897) |  Loss2: (0.0000) | Acc: (97.00%) (7577/7808)
Epoch: 178 | Batch_idx: 70 |  Loss: (0.0891) |  Loss2: (0.0000) | Acc: (97.00%) (8822/9088)
Epoch: 178 | Batch_idx: 80 |  Loss: (0.0871) |  Loss2: (0.0000) | Acc: (97.00%) (10074/10368)
Epoch: 178 | Batch_idx: 90 |  Loss: (0.0877) |  Loss2: (0.0000) | Acc: (97.00%) (11325/11648)
Epoch: 178 | Batch_idx: 100 |  Loss: (0.0889) |  Loss2: (0.0000) | Acc: (97.00%) (12564/12928)
Epoch: 178 | Batch_idx: 110 |  Loss: (0.0902) |  Loss2: (0.0000) | Acc: (97.00%) (13797/14208)
Epoch: 178 | Batch_idx: 120 |  Loss: (0.0897) |  Loss2: (0.0000) | Acc: (97.00%) (15031/15488)
Epoch: 178 | Batch_idx: 130 |  Loss: (0.0901) |  Loss2: (0.0000) | Acc: (97.00%) (16269/16768)
Epoch: 178 | Batch_idx: 140 |  Loss: (0.0915) |  Loss2: (0.0000) | Acc: (96.00%) (17496/18048)
Epoch: 178 | Batch_idx: 150 |  Loss: (0.0920) |  Loss2: (0.0000) | Acc: (96.00%) (18728/19328)
Epoch: 178 | Batch_idx: 160 |  Loss: (0.0918) |  Loss2: (0.0000) | Acc: (96.00%) (19972/20608)
Epoch: 178 | Batch_idx: 170 |  Loss: (0.0922) |  Loss2: (0.0000) | Acc: (96.00%) (21209/21888)
Epoch: 178 | Batch_idx: 180 |  Loss: (0.0926) |  Loss2: (0.0000) | Acc: (96.00%) (22445/23168)
Epoch: 178 | Batch_idx: 190 |  Loss: (0.0923) |  Loss2: (0.0000) | Acc: (96.00%) (23683/24448)
Epoch: 178 | Batch_idx: 200 |  Loss: (0.0925) |  Loss2: (0.0000) | Acc: (96.00%) (24921/25728)
Epoch: 178 | Batch_idx: 210 |  Loss: (0.0918) |  Loss2: (0.0000) | Acc: (96.00%) (26167/27008)
Epoch: 178 | Batch_idx: 220 |  Loss: (0.0917) |  Loss2: (0.0000) | Acc: (96.00%) (27414/28288)
Epoch: 178 | Batch_idx: 230 |  Loss: (0.0917) |  Loss2: (0.0000) | Acc: (96.00%) (28662/29568)
Epoch: 178 | Batch_idx: 240 |  Loss: (0.0916) |  Loss2: (0.0000) | Acc: (96.00%) (29903/30848)
Epoch: 178 | Batch_idx: 250 |  Loss: (0.0908) |  Loss2: (0.0000) | Acc: (96.00%) (31155/32128)
Epoch: 178 | Batch_idx: 260 |  Loss: (0.0905) |  Loss2: (0.0000) | Acc: (96.00%) (32402/33408)
Epoch: 178 | Batch_idx: 270 |  Loss: (0.0906) |  Loss2: (0.0000) | Acc: (96.00%) (33645/34688)
Epoch: 178 | Batch_idx: 280 |  Loss: (0.0904) |  Loss2: (0.0000) | Acc: (97.00%) (34895/35968)
Epoch: 178 | Batch_idx: 290 |  Loss: (0.0904) |  Loss2: (0.0000) | Acc: (97.00%) (36131/37248)
Epoch: 178 | Batch_idx: 300 |  Loss: (0.0900) |  Loss2: (0.0000) | Acc: (97.00%) (37374/38528)
Epoch: 178 | Batch_idx: 310 |  Loss: (0.0905) |  Loss2: (0.0000) | Acc: (96.00%) (38608/39808)
Epoch: 178 | Batch_idx: 320 |  Loss: (0.0905) |  Loss2: (0.0000) | Acc: (96.00%) (39848/41088)
Epoch: 178 | Batch_idx: 330 |  Loss: (0.0904) |  Loss2: (0.0000) | Acc: (96.00%) (41094/42368)
Epoch: 178 | Batch_idx: 340 |  Loss: (0.0900) |  Loss2: (0.0000) | Acc: (97.00%) (42342/43648)
Epoch: 178 | Batch_idx: 350 |  Loss: (0.0898) |  Loss2: (0.0000) | Acc: (97.00%) (43589/44928)
Epoch: 178 | Batch_idx: 360 |  Loss: (0.0896) |  Loss2: (0.0000) | Acc: (97.00%) (44846/46208)
Epoch: 178 | Batch_idx: 370 |  Loss: (0.0892) |  Loss2: (0.0000) | Acc: (97.00%) (46089/47488)
Epoch: 178 | Batch_idx: 380 |  Loss: (0.0892) |  Loss2: (0.0000) | Acc: (97.00%) (47333/48768)
Epoch: 178 | Batch_idx: 390 |  Loss: (0.0891) |  Loss2: (0.0000) | Acc: (97.00%) (48528/50000)
# TEST : Loss: (0.3749) | Acc: (88.00%) (8880/10000)
percent tensor([0.5114, 0.5107, 0.5152, 0.5150, 0.5146, 0.5159, 0.5130, 0.5162, 0.5120,
        0.5117, 0.5098, 0.5131, 0.5101, 0.5131, 0.5118, 0.5125],
       device='cuda:0') torch.Size([16])
percent tensor([0.5229, 0.5276, 0.5177, 0.5174, 0.5167, 0.5324, 0.5219, 0.5117, 0.5181,
        0.5231, 0.5232, 0.5208, 0.5298, 0.5168, 0.5282, 0.5280],
       device='cuda:0') torch.Size([16])
percent tensor([0.5986, 0.5438, 0.6522, 0.6714, 0.6605, 0.6218, 0.5973, 0.6414, 0.6518,
        0.5809, 0.6246, 0.6037, 0.5103, 0.6748, 0.5843, 0.5991],
       device='cuda:0') torch.Size([16])
percent tensor([0.6663, 0.6526, 0.6558, 0.6557, 0.6590, 0.6679, 0.6657, 0.6608, 0.6593,
        0.6601, 0.6561, 0.6570, 0.6534, 0.6554, 0.6640, 0.6738],
       device='cuda:0') torch.Size([16])
percent tensor([0.6551, 0.6035, 0.6485, 0.6593, 0.6752, 0.7795, 0.6193, 0.6112, 0.6449,
        0.6430, 0.5855, 0.6040, 0.6299, 0.6444, 0.6110, 0.7307],
       device='cuda:0') torch.Size([16])
percent tensor([0.6164, 0.6777, 0.6793, 0.7240, 0.6786, 0.7684, 0.6775, 0.5606, 0.7185,
        0.6558, 0.7598, 0.6677, 0.7387, 0.7168, 0.5641, 0.6416],
       device='cuda:0') torch.Size([16])
percent tensor([0.5805, 0.6328, 0.6689, 0.6837, 0.6947, 0.6379, 0.6466, 0.6605, 0.6061,
        0.6417, 0.6745, 0.5953, 0.5966, 0.5725, 0.5880, 0.5656],
       device='cuda:0') torch.Size([16])
percent tensor([0.9999, 0.9998, 0.9998, 0.9999, 0.9994, 0.9990, 0.9997, 0.9993, 0.9998,
        0.9998, 0.9998, 0.9998, 0.9999, 0.9995, 0.9993, 0.9997],
       device='cuda:0') torch.Size([16])
Epoch: 179 | Batch_idx: 0 |  Loss: (0.1549) |  Loss2: (0.0000) | Acc: (96.00%) (123/128)
Epoch: 179 | Batch_idx: 10 |  Loss: (0.0920) |  Loss2: (0.0000) | Acc: (97.00%) (1369/1408)
Epoch: 179 | Batch_idx: 20 |  Loss: (0.0945) |  Loss2: (0.0000) | Acc: (96.00%) (2606/2688)
Epoch: 179 | Batch_idx: 30 |  Loss: (0.0945) |  Loss2: (0.0000) | Acc: (97.00%) (3849/3968)
Epoch: 179 | Batch_idx: 40 |  Loss: (0.0906) |  Loss2: (0.0000) | Acc: (97.00%) (5102/5248)
Epoch: 179 | Batch_idx: 50 |  Loss: (0.0890) |  Loss2: (0.0000) | Acc: (97.00%) (6349/6528)
Epoch: 179 | Batch_idx: 60 |  Loss: (0.0892) |  Loss2: (0.0000) | Acc: (97.00%) (7585/7808)
Epoch: 179 | Batch_idx: 70 |  Loss: (0.0901) |  Loss2: (0.0000) | Acc: (97.00%) (8816/9088)
Epoch: 179 | Batch_idx: 80 |  Loss: (0.0888) |  Loss2: (0.0000) | Acc: (97.00%) (10064/10368)
Epoch: 179 | Batch_idx: 90 |  Loss: (0.0897) |  Loss2: (0.0000) | Acc: (97.00%) (11300/11648)
Epoch: 179 | Batch_idx: 100 |  Loss: (0.0911) |  Loss2: (0.0000) | Acc: (96.00%) (12533/12928)
Epoch: 179 | Batch_idx: 110 |  Loss: (0.0910) |  Loss2: (0.0000) | Acc: (96.00%) (13780/14208)
Epoch: 179 | Batch_idx: 120 |  Loss: (0.0925) |  Loss2: (0.0000) | Acc: (96.00%) (15012/15488)
Epoch: 179 | Batch_idx: 130 |  Loss: (0.0919) |  Loss2: (0.0000) | Acc: (96.00%) (16264/16768)
Epoch: 179 | Batch_idx: 140 |  Loss: (0.0897) |  Loss2: (0.0000) | Acc: (97.00%) (17523/18048)
Epoch: 179 | Batch_idx: 150 |  Loss: (0.0897) |  Loss2: (0.0000) | Acc: (97.00%) (18768/19328)
Epoch: 179 | Batch_idx: 160 |  Loss: (0.0911) |  Loss2: (0.0000) | Acc: (97.00%) (19995/20608)
Epoch: 179 | Batch_idx: 170 |  Loss: (0.0905) |  Loss2: (0.0000) | Acc: (97.00%) (21239/21888)
Epoch: 179 | Batch_idx: 180 |  Loss: (0.0904) |  Loss2: (0.0000) | Acc: (97.00%) (22480/23168)
Epoch: 179 | Batch_idx: 190 |  Loss: (0.0899) |  Loss2: (0.0000) | Acc: (97.00%) (23724/24448)
Epoch: 179 | Batch_idx: 200 |  Loss: (0.0904) |  Loss2: (0.0000) | Acc: (97.00%) (24960/25728)
Epoch: 179 | Batch_idx: 210 |  Loss: (0.0907) |  Loss2: (0.0000) | Acc: (97.00%) (26199/27008)
Epoch: 179 | Batch_idx: 220 |  Loss: (0.0902) |  Loss2: (0.0000) | Acc: (97.00%) (27447/28288)
Epoch: 179 | Batch_idx: 230 |  Loss: (0.0901) |  Loss2: (0.0000) | Acc: (97.00%) (28688/29568)
Epoch: 179 | Batch_idx: 240 |  Loss: (0.0902) |  Loss2: (0.0000) | Acc: (97.00%) (29926/30848)
Epoch: 179 | Batch_idx: 250 |  Loss: (0.0902) |  Loss2: (0.0000) | Acc: (97.00%) (31172/32128)
Epoch: 179 | Batch_idx: 260 |  Loss: (0.0903) |  Loss2: (0.0000) | Acc: (97.00%) (32417/33408)
Epoch: 179 | Batch_idx: 270 |  Loss: (0.0896) |  Loss2: (0.0000) | Acc: (97.00%) (33671/34688)
Epoch: 179 | Batch_idx: 280 |  Loss: (0.0895) |  Loss2: (0.0000) | Acc: (97.00%) (34915/35968)
Epoch: 179 | Batch_idx: 290 |  Loss: (0.0890) |  Loss2: (0.0000) | Acc: (97.00%) (36162/37248)
Epoch: 179 | Batch_idx: 300 |  Loss: (0.0889) |  Loss2: (0.0000) | Acc: (97.00%) (37397/38528)
Epoch: 179 | Batch_idx: 310 |  Loss: (0.0885) |  Loss2: (0.0000) | Acc: (97.00%) (38645/39808)
Epoch: 179 | Batch_idx: 320 |  Loss: (0.0885) |  Loss2: (0.0000) | Acc: (97.00%) (39889/41088)
Epoch: 179 | Batch_idx: 330 |  Loss: (0.0885) |  Loss2: (0.0000) | Acc: (97.00%) (41132/42368)
Epoch: 179 | Batch_idx: 340 |  Loss: (0.0883) |  Loss2: (0.0000) | Acc: (97.00%) (42376/43648)
Epoch: 179 | Batch_idx: 350 |  Loss: (0.0883) |  Loss2: (0.0000) | Acc: (97.00%) (43622/44928)
Epoch: 179 | Batch_idx: 360 |  Loss: (0.0880) |  Loss2: (0.0000) | Acc: (97.00%) (44867/46208)
Epoch: 179 | Batch_idx: 370 |  Loss: (0.0882) |  Loss2: (0.0000) | Acc: (97.00%) (46105/47488)
Epoch: 179 | Batch_idx: 380 |  Loss: (0.0881) |  Loss2: (0.0000) | Acc: (97.00%) (47348/48768)
Epoch: 179 | Batch_idx: 390 |  Loss: (0.0883) |  Loss2: (0.0000) | Acc: (97.00%) (48538/50000)
# TEST : Loss: (0.3730) | Acc: (88.00%) (8886/10000)
percent tensor([0.5120, 0.5113, 0.5158, 0.5157, 0.5153, 0.5167, 0.5136, 0.5168, 0.5125,
        0.5122, 0.5104, 0.5137, 0.5107, 0.5136, 0.5124, 0.5131],
       device='cuda:0') torch.Size([16])
percent tensor([0.5224, 0.5266, 0.5169, 0.5165, 0.5159, 0.5320, 0.5209, 0.5108, 0.5173,
        0.5221, 0.5223, 0.5199, 0.5290, 0.5161, 0.5274, 0.5273],
       device='cuda:0') torch.Size([16])
percent tensor([0.6025, 0.5479, 0.6527, 0.6714, 0.6614, 0.6267, 0.6011, 0.6426, 0.6541,
        0.5841, 0.6282, 0.6063, 0.5158, 0.6757, 0.5895, 0.6026],
       device='cuda:0') torch.Size([16])
percent tensor([0.6650, 0.6503, 0.6548, 0.6542, 0.6574, 0.6670, 0.6638, 0.6593, 0.6576,
        0.6579, 0.6538, 0.6550, 0.6518, 0.6530, 0.6621, 0.6722],
       device='cuda:0') torch.Size([16])
percent tensor([0.6554, 0.6036, 0.6534, 0.6624, 0.6803, 0.7798, 0.6200, 0.6149, 0.6464,
        0.6448, 0.5863, 0.6074, 0.6300, 0.6443, 0.6120, 0.7317],
       device='cuda:0') torch.Size([16])
percent tensor([0.6130, 0.6764, 0.6786, 0.7225, 0.6774, 0.7652, 0.6761, 0.5581, 0.7183,
        0.6527, 0.7582, 0.6651, 0.7368, 0.7161, 0.5584, 0.6346],
       device='cuda:0') torch.Size([16])
percent tensor([0.5750, 0.6305, 0.6639, 0.6790, 0.6926, 0.6381, 0.6446, 0.6553, 0.6019,
        0.6380, 0.6722, 0.5908, 0.5949, 0.5717, 0.5839, 0.5649],
       device='cuda:0') torch.Size([16])
percent tensor([0.9999, 0.9998, 0.9998, 0.9999, 0.9994, 0.9989, 0.9997, 0.9993, 0.9998,
        0.9998, 0.9998, 0.9998, 0.9999, 0.9995, 0.9993, 0.9997],
       device='cuda:0') torch.Size([16])
True Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=128, out_features=16, bias=False)
False Linear(in_features=16, out_features=2, bias=False)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=128, out_features=16, bias=False)
False Linear(in_features=16, out_features=2, bias=False)
True Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=256, out_features=32, bias=False)
False Linear(in_features=32, out_features=2, bias=False)
True Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=256, out_features=32, bias=False)
False Linear(in_features=32, out_features=2, bias=False)
True Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=512, out_features=64, bias=False)
False Linear(in_features=64, out_features=2, bias=False)
True Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=512, out_features=64, bias=False)
False Linear(in_features=64, out_features=2, bias=False)
True Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1024, out_features=128, bias=False)
False Linear(in_features=128, out_features=2, bias=False)
True Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1024, out_features=128, bias=False)
False Linear(in_features=128, out_features=2, bias=False)
True Linear(in_features=512, out_features=10, bias=True)
Epoch: 180 | Batch_idx: 0 |  Loss: (0.0607) |  Loss2: (0.0000) | Acc: (97.00%) (125/128)
Epoch: 180 | Batch_idx: 10 |  Loss: (0.1099) |  Loss2: (0.0000) | Acc: (96.00%) (1352/1408)
Epoch: 180 | Batch_idx: 20 |  Loss: (0.1024) |  Loss2: (0.0000) | Acc: (96.00%) (2595/2688)
Epoch: 180 | Batch_idx: 30 |  Loss: (0.0946) |  Loss2: (0.0000) | Acc: (96.00%) (3842/3968)
Epoch: 180 | Batch_idx: 40 |  Loss: (0.0921) |  Loss2: (0.0000) | Acc: (96.00%) (5090/5248)
Epoch: 180 | Batch_idx: 50 |  Loss: (0.0901) |  Loss2: (0.0000) | Acc: (97.00%) (6338/6528)
Epoch: 180 | Batch_idx: 60 |  Loss: (0.0898) |  Loss2: (0.0000) | Acc: (97.00%) (7577/7808)
Epoch: 180 | Batch_idx: 70 |  Loss: (0.0912) |  Loss2: (0.0000) | Acc: (97.00%) (8817/9088)
Epoch: 180 | Batch_idx: 80 |  Loss: (0.0915) |  Loss2: (0.0000) | Acc: (97.00%) (10059/10368)
Epoch: 180 | Batch_idx: 90 |  Loss: (0.0917) |  Loss2: (0.0000) | Acc: (96.00%) (11294/11648)
Epoch: 180 | Batch_idx: 100 |  Loss: (0.0905) |  Loss2: (0.0000) | Acc: (96.00%) (12536/12928)
Epoch: 180 | Batch_idx: 110 |  Loss: (0.0922) |  Loss2: (0.0000) | Acc: (96.00%) (13772/14208)
Epoch: 180 | Batch_idx: 120 |  Loss: (0.0926) |  Loss2: (0.0000) | Acc: (96.00%) (15016/15488)
Epoch: 180 | Batch_idx: 130 |  Loss: (0.0929) |  Loss2: (0.0000) | Acc: (96.00%) (16249/16768)
Epoch: 180 | Batch_idx: 140 |  Loss: (0.0934) |  Loss2: (0.0000) | Acc: (96.00%) (17488/18048)
Epoch: 180 | Batch_idx: 150 |  Loss: (0.0942) |  Loss2: (0.0000) | Acc: (96.00%) (18716/19328)
Epoch: 180 | Batch_idx: 160 |  Loss: (0.0951) |  Loss2: (0.0000) | Acc: (96.00%) (19948/20608)
Epoch: 180 | Batch_idx: 170 |  Loss: (0.0955) |  Loss2: (0.0000) | Acc: (96.00%) (21187/21888)
Epoch: 180 | Batch_idx: 180 |  Loss: (0.0954) |  Loss2: (0.0000) | Acc: (96.00%) (22425/23168)
Epoch: 180 | Batch_idx: 190 |  Loss: (0.0953) |  Loss2: (0.0000) | Acc: (96.00%) (23667/24448)
Epoch: 180 | Batch_idx: 200 |  Loss: (0.0957) |  Loss2: (0.0000) | Acc: (96.00%) (24906/25728)
Epoch: 180 | Batch_idx: 210 |  Loss: (0.0961) |  Loss2: (0.0000) | Acc: (96.00%) (26136/27008)
Epoch: 180 | Batch_idx: 220 |  Loss: (0.0966) |  Loss2: (0.0000) | Acc: (96.00%) (27371/28288)
Epoch: 180 | Batch_idx: 230 |  Loss: (0.0964) |  Loss2: (0.0000) | Acc: (96.00%) (28609/29568)
Epoch: 180 | Batch_idx: 240 |  Loss: (0.0957) |  Loss2: (0.0000) | Acc: (96.00%) (29851/30848)
Epoch: 180 | Batch_idx: 250 |  Loss: (0.0963) |  Loss2: (0.0000) | Acc: (96.00%) (31082/32128)
Epoch: 180 | Batch_idx: 260 |  Loss: (0.0973) |  Loss2: (0.0000) | Acc: (96.00%) (32309/33408)
Epoch: 180 | Batch_idx: 270 |  Loss: (0.0969) |  Loss2: (0.0000) | Acc: (96.00%) (33549/34688)
Epoch: 180 | Batch_idx: 280 |  Loss: (0.0971) |  Loss2: (0.0000) | Acc: (96.00%) (34786/35968)
Epoch: 180 | Batch_idx: 290 |  Loss: (0.0975) |  Loss2: (0.0000) | Acc: (96.00%) (36014/37248)
Epoch: 180 | Batch_idx: 300 |  Loss: (0.0976) |  Loss2: (0.0000) | Acc: (96.00%) (37255/38528)
Epoch: 180 | Batch_idx: 310 |  Loss: (0.0982) |  Loss2: (0.0000) | Acc: (96.00%) (38483/39808)
Epoch: 180 | Batch_idx: 320 |  Loss: (0.0984) |  Loss2: (0.0000) | Acc: (96.00%) (39709/41088)
Epoch: 180 | Batch_idx: 330 |  Loss: (0.0980) |  Loss2: (0.0000) | Acc: (96.00%) (40950/42368)
Epoch: 180 | Batch_idx: 340 |  Loss: (0.0977) |  Loss2: (0.0000) | Acc: (96.00%) (42190/43648)
Epoch: 180 | Batch_idx: 350 |  Loss: (0.0980) |  Loss2: (0.0000) | Acc: (96.00%) (43422/44928)
Epoch: 180 | Batch_idx: 360 |  Loss: (0.0980) |  Loss2: (0.0000) | Acc: (96.00%) (44659/46208)
Epoch: 180 | Batch_idx: 370 |  Loss: (0.0982) |  Loss2: (0.0000) | Acc: (96.00%) (45902/47488)
Epoch: 180 | Batch_idx: 380 |  Loss: (0.0985) |  Loss2: (0.0000) | Acc: (96.00%) (47128/48768)
Epoch: 180 | Batch_idx: 390 |  Loss: (0.0987) |  Loss2: (0.0000) | Acc: (96.00%) (48318/50000)
=> saving checkpoint 'drive/app/torch/save_Schedule/checkpoint_180.pth.tar'
# TEST : Loss: (0.4058) | Acc: (88.00%) (8819/10000)
percent tensor([0.5122, 0.5114, 0.5148, 0.5157, 0.5150, 0.5170, 0.5134, 0.5160, 0.5126,
        0.5117, 0.5105, 0.5126, 0.5108, 0.5138, 0.5128, 0.5131],
       device='cuda:0') torch.Size([16])
percent tensor([0.5212, 0.5274, 0.5150, 0.5144, 0.5132, 0.5285, 0.5205, 0.5100, 0.5166,
        0.5228, 0.5221, 0.5191, 0.5289, 0.5171, 0.5261, 0.5262],
       device='cuda:0') torch.Size([16])
percent tensor([0.6082, 0.5544, 0.6573, 0.6727, 0.6632, 0.6357, 0.6093, 0.6511, 0.6613,
        0.5964, 0.6388, 0.6192, 0.5218, 0.6801, 0.5933, 0.6098],
       device='cuda:0') torch.Size([16])
percent tensor([0.6651, 0.6501, 0.6509, 0.6532, 0.6538, 0.6657, 0.6617, 0.6590, 0.6597,
        0.6599, 0.6561, 0.6544, 0.6550, 0.6544, 0.6612, 0.6738],
       device='cuda:0') torch.Size([16])
percent tensor([0.6361, 0.6129, 0.6556, 0.6739, 0.6901, 0.7502, 0.6211, 0.6185, 0.6369,
        0.6558, 0.5927, 0.6225, 0.6180, 0.6513, 0.6077, 0.7171],
       device='cuda:0') torch.Size([16])
percent tensor([0.6337, 0.6894, 0.6758, 0.7161, 0.6857, 0.7398, 0.6834, 0.5420, 0.6962,
        0.6557, 0.7631, 0.6562, 0.7400, 0.7343, 0.5522, 0.6590],
       device='cuda:0') torch.Size([16])
percent tensor([0.5764, 0.6450, 0.6639, 0.6745, 0.7047, 0.6409, 0.6575, 0.6386, 0.5803,
        0.6448, 0.6708, 0.6081, 0.6030, 0.5956, 0.5801, 0.5812],
       device='cuda:0') torch.Size([16])
percent tensor([0.9999, 0.9997, 0.9997, 0.9999, 0.9995, 0.9991, 0.9998, 0.9996, 0.9998,
        0.9999, 0.9999, 0.9998, 0.9999, 0.9997, 0.9994, 0.9997],
       device='cuda:0') torch.Size([16])
Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 3, 3, 3]) tensor(180.7660, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(829.8864, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(828.9757, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([128, 64, 3, 3]) tensor(1512.9530, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([128, 64, 1, 1]) tensor(481.4407, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([128, 128, 3, 3]) tensor(2284.7585, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([256, 128, 3, 3]) tensor(4255.2646, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([256, 128, 1, 1]) tensor(1355.0785, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([256, 256, 3, 3]) tensor(6255.1587, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([512, 256, 3, 3]) tensor(11585.3750, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([512, 256, 1, 1]) tensor(3813.4597, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([512, 512, 3, 3]) tensor(16123.8281, device='cuda:0', grad_fn=<NormBackward0>)
Epoch: 181 | Batch_idx: 0 |  Loss: (0.0872) |  Loss2: (0.0000) | Acc: (96.00%) (124/128)
Epoch: 181 | Batch_idx: 10 |  Loss: (0.0808) |  Loss2: (0.0000) | Acc: (97.00%) (1375/1408)
Epoch: 181 | Batch_idx: 20 |  Loss: (0.0853) |  Loss2: (0.0000) | Acc: (97.00%) (2620/2688)
Epoch: 181 | Batch_idx: 30 |  Loss: (0.0825) |  Loss2: (0.0000) | Acc: (97.00%) (3870/3968)
Epoch: 181 | Batch_idx: 40 |  Loss: (0.0810) |  Loss2: (0.0000) | Acc: (97.00%) (5122/5248)
Epoch: 181 | Batch_idx: 50 |  Loss: (0.0825) |  Loss2: (0.0000) | Acc: (97.00%) (6367/6528)
Epoch: 181 | Batch_idx: 60 |  Loss: (0.0839) |  Loss2: (0.0000) | Acc: (97.00%) (7601/7808)
Epoch: 181 | Batch_idx: 70 |  Loss: (0.0859) |  Loss2: (0.0000) | Acc: (97.00%) (8842/9088)
Epoch: 181 | Batch_idx: 80 |  Loss: (0.0883) |  Loss2: (0.0000) | Acc: (97.00%) (10073/10368)
Epoch: 181 | Batch_idx: 90 |  Loss: (0.0885) |  Loss2: (0.0000) | Acc: (97.00%) (11312/11648)
Epoch: 181 | Batch_idx: 100 |  Loss: (0.0890) |  Loss2: (0.0000) | Acc: (97.00%) (12557/12928)
Epoch: 181 | Batch_idx: 110 |  Loss: (0.0902) |  Loss2: (0.0000) | Acc: (97.00%) (13798/14208)
Epoch: 181 | Batch_idx: 120 |  Loss: (0.0886) |  Loss2: (0.0000) | Acc: (97.00%) (15049/15488)
Epoch: 181 | Batch_idx: 130 |  Loss: (0.0894) |  Loss2: (0.0000) | Acc: (97.00%) (16291/16768)
Epoch: 181 | Batch_idx: 140 |  Loss: (0.0900) |  Loss2: (0.0000) | Acc: (97.00%) (17526/18048)
Epoch: 181 | Batch_idx: 150 |  Loss: (0.0899) |  Loss2: (0.0000) | Acc: (97.00%) (18769/19328)
Epoch: 181 | Batch_idx: 160 |  Loss: (0.0896) |  Loss2: (0.0000) | Acc: (97.00%) (20008/20608)
Epoch: 181 | Batch_idx: 170 |  Loss: (0.0908) |  Loss2: (0.0000) | Acc: (97.00%) (21235/21888)
Epoch: 181 | Batch_idx: 180 |  Loss: (0.0908) |  Loss2: (0.0000) | Acc: (97.00%) (22477/23168)
Epoch: 181 | Batch_idx: 190 |  Loss: (0.0914) |  Loss2: (0.0000) | Acc: (96.00%) (23714/24448)
Epoch: 181 | Batch_idx: 200 |  Loss: (0.0905) |  Loss2: (0.0000) | Acc: (97.00%) (24964/25728)
Epoch: 181 | Batch_idx: 210 |  Loss: (0.0906) |  Loss2: (0.0000) | Acc: (97.00%) (26203/27008)
Epoch: 181 | Batch_idx: 220 |  Loss: (0.0908) |  Loss2: (0.0000) | Acc: (97.00%) (27449/28288)
Epoch: 181 | Batch_idx: 230 |  Loss: (0.0909) |  Loss2: (0.0000) | Acc: (97.00%) (28681/29568)
Epoch: 181 | Batch_idx: 240 |  Loss: (0.0914) |  Loss2: (0.0000) | Acc: (96.00%) (29915/30848)
Epoch: 181 | Batch_idx: 250 |  Loss: (0.0915) |  Loss2: (0.0000) | Acc: (96.00%) (31154/32128)
Epoch: 181 | Batch_idx: 260 |  Loss: (0.0917) |  Loss2: (0.0000) | Acc: (96.00%) (32390/33408)
Epoch: 181 | Batch_idx: 270 |  Loss: (0.0918) |  Loss2: (0.0000) | Acc: (96.00%) (33624/34688)
Epoch: 181 | Batch_idx: 280 |  Loss: (0.0920) |  Loss2: (0.0000) | Acc: (96.00%) (34865/35968)
Epoch: 181 | Batch_idx: 290 |  Loss: (0.0924) |  Loss2: (0.0000) | Acc: (96.00%) (36096/37248)
Epoch: 181 | Batch_idx: 300 |  Loss: (0.0923) |  Loss2: (0.0000) | Acc: (96.00%) (37333/38528)
Epoch: 181 | Batch_idx: 310 |  Loss: (0.0922) |  Loss2: (0.0000) | Acc: (96.00%) (38577/39808)
Epoch: 181 | Batch_idx: 320 |  Loss: (0.0920) |  Loss2: (0.0000) | Acc: (96.00%) (39815/41088)
Epoch: 181 | Batch_idx: 330 |  Loss: (0.0926) |  Loss2: (0.0000) | Acc: (96.00%) (41048/42368)
Epoch: 181 | Batch_idx: 340 |  Loss: (0.0924) |  Loss2: (0.0000) | Acc: (96.00%) (42290/43648)
Epoch: 181 | Batch_idx: 350 |  Loss: (0.0927) |  Loss2: (0.0000) | Acc: (96.00%) (43522/44928)
Epoch: 181 | Batch_idx: 360 |  Loss: (0.0932) |  Loss2: (0.0000) | Acc: (96.00%) (44754/46208)
Epoch: 181 | Batch_idx: 370 |  Loss: (0.0935) |  Loss2: (0.0000) | Acc: (96.00%) (45983/47488)
Epoch: 181 | Batch_idx: 380 |  Loss: (0.0938) |  Loss2: (0.0000) | Acc: (96.00%) (47220/48768)
Epoch: 181 | Batch_idx: 390 |  Loss: (0.0944) |  Loss2: (0.0000) | Acc: (96.00%) (48397/50000)
# TEST : Loss: (0.4307) | Acc: (88.00%) (8806/10000)
percent tensor([0.5123, 0.5109, 0.5163, 0.5161, 0.5159, 0.5172, 0.5134, 0.5168, 0.5125,
        0.5120, 0.5102, 0.5139, 0.5109, 0.5131, 0.5126, 0.5132],
       device='cuda:0') torch.Size([16])
percent tensor([0.5205, 0.5266, 0.5154, 0.5148, 0.5117, 0.5271, 0.5189, 0.5108, 0.5163,
        0.5218, 0.5214, 0.5176, 0.5282, 0.5164, 0.5252, 0.5258],
       device='cuda:0') torch.Size([16])
percent tensor([0.6096, 0.5488, 0.6564, 0.6752, 0.6687, 0.6463, 0.6062, 0.6462, 0.6556,
        0.5921, 0.6348, 0.6193, 0.5251, 0.6749, 0.5951, 0.6112],
       device='cuda:0') torch.Size([16])
percent tensor([0.6646, 0.6471, 0.6577, 0.6551, 0.6580, 0.6648, 0.6613, 0.6574, 0.6597,
        0.6593, 0.6528, 0.6560, 0.6539, 0.6479, 0.6589, 0.6703],
       device='cuda:0') torch.Size([16])
percent tensor([0.6532, 0.6107, 0.6700, 0.6821, 0.6916, 0.7511, 0.6279, 0.6151, 0.6390,
        0.6684, 0.5934, 0.6268, 0.6306, 0.6604, 0.6124, 0.7214],
       device='cuda:0') torch.Size([16])
percent tensor([0.6176, 0.6905, 0.6643, 0.7195, 0.6812, 0.7472, 0.6725, 0.5511, 0.6952,
        0.6594, 0.7590, 0.6549, 0.7357, 0.7256, 0.5575, 0.6440],
       device='cuda:0') torch.Size([16])
percent tensor([0.5700, 0.6523, 0.6510, 0.6741, 0.6909, 0.6392, 0.6632, 0.6321, 0.5901,
        0.6537, 0.6665, 0.6002, 0.6012, 0.5927, 0.5905, 0.5658],
       device='cuda:0') torch.Size([16])
percent tensor([0.9999, 0.9997, 0.9998, 0.9999, 0.9996, 0.9995, 0.9998, 0.9994, 0.9998,
        0.9998, 0.9999, 0.9997, 0.9999, 0.9995, 0.9994, 0.9998],
       device='cuda:0') torch.Size([16])
Epoch: 182 | Batch_idx: 0 |  Loss: (0.0677) |  Loss2: (0.0000) | Acc: (98.00%) (126/128)
Epoch: 182 | Batch_idx: 10 |  Loss: (0.0957) |  Loss2: (0.0000) | Acc: (96.00%) (1363/1408)
Epoch: 182 | Batch_idx: 20 |  Loss: (0.0941) |  Loss2: (0.0000) | Acc: (96.00%) (2603/2688)
Epoch: 182 | Batch_idx: 30 |  Loss: (0.0956) |  Loss2: (0.0000) | Acc: (96.00%) (3838/3968)
Epoch: 182 | Batch_idx: 40 |  Loss: (0.0916) |  Loss2: (0.0000) | Acc: (96.00%) (5086/5248)
Epoch: 182 | Batch_idx: 50 |  Loss: (0.0912) |  Loss2: (0.0000) | Acc: (96.00%) (6324/6528)
Epoch: 182 | Batch_idx: 60 |  Loss: (0.0910) |  Loss2: (0.0000) | Acc: (96.00%) (7565/7808)
Epoch: 182 | Batch_idx: 70 |  Loss: (0.0913) |  Loss2: (0.0000) | Acc: (96.00%) (8804/9088)
Epoch: 182 | Batch_idx: 80 |  Loss: (0.0896) |  Loss2: (0.0000) | Acc: (96.00%) (10055/10368)
Epoch: 182 | Batch_idx: 90 |  Loss: (0.0871) |  Loss2: (0.0000) | Acc: (97.00%) (11310/11648)
Epoch: 182 | Batch_idx: 100 |  Loss: (0.0843) |  Loss2: (0.0000) | Acc: (97.00%) (12563/12928)
Epoch: 182 | Batch_idx: 110 |  Loss: (0.0840) |  Loss2: (0.0000) | Acc: (97.00%) (13807/14208)
Epoch: 182 | Batch_idx: 120 |  Loss: (0.0840) |  Loss2: (0.0000) | Acc: (97.00%) (15059/15488)
Epoch: 182 | Batch_idx: 130 |  Loss: (0.0839) |  Loss2: (0.0000) | Acc: (97.00%) (16306/16768)
Epoch: 182 | Batch_idx: 140 |  Loss: (0.0842) |  Loss2: (0.0000) | Acc: (97.00%) (17545/18048)
Epoch: 182 | Batch_idx: 150 |  Loss: (0.0845) |  Loss2: (0.0000) | Acc: (97.00%) (18781/19328)
Epoch: 182 | Batch_idx: 160 |  Loss: (0.0855) |  Loss2: (0.0000) | Acc: (97.00%) (20014/20608)
Epoch: 182 | Batch_idx: 170 |  Loss: (0.0859) |  Loss2: (0.0000) | Acc: (97.00%) (21247/21888)
Epoch: 182 | Batch_idx: 180 |  Loss: (0.0879) |  Loss2: (0.0000) | Acc: (96.00%) (22467/23168)
Epoch: 182 | Batch_idx: 190 |  Loss: (0.0877) |  Loss2: (0.0000) | Acc: (97.00%) (23722/24448)
Epoch: 182 | Batch_idx: 200 |  Loss: (0.0888) |  Loss2: (0.0000) | Acc: (96.00%) (24953/25728)
Epoch: 182 | Batch_idx: 210 |  Loss: (0.0895) |  Loss2: (0.0000) | Acc: (96.00%) (26195/27008)
Epoch: 182 | Batch_idx: 220 |  Loss: (0.0887) |  Loss2: (0.0000) | Acc: (97.00%) (27442/28288)
Epoch: 182 | Batch_idx: 230 |  Loss: (0.0896) |  Loss2: (0.0000) | Acc: (96.00%) (28675/29568)
Epoch: 182 | Batch_idx: 240 |  Loss: (0.0896) |  Loss2: (0.0000) | Acc: (96.00%) (29914/30848)
Epoch: 182 | Batch_idx: 250 |  Loss: (0.0897) |  Loss2: (0.0000) | Acc: (96.00%) (31154/32128)
Epoch: 182 | Batch_idx: 260 |  Loss: (0.0895) |  Loss2: (0.0000) | Acc: (96.00%) (32405/33408)
Epoch: 182 | Batch_idx: 270 |  Loss: (0.0897) |  Loss2: (0.0000) | Acc: (96.00%) (33640/34688)
Epoch: 182 | Batch_idx: 280 |  Loss: (0.0891) |  Loss2: (0.0000) | Acc: (97.00%) (34891/35968)
Epoch: 182 | Batch_idx: 290 |  Loss: (0.0883) |  Loss2: (0.0000) | Acc: (97.00%) (36143/37248)
Epoch: 182 | Batch_idx: 300 |  Loss: (0.0881) |  Loss2: (0.0000) | Acc: (97.00%) (37390/38528)
Epoch: 182 | Batch_idx: 310 |  Loss: (0.0890) |  Loss2: (0.0000) | Acc: (97.00%) (38623/39808)
Epoch: 182 | Batch_idx: 320 |  Loss: (0.0892) |  Loss2: (0.0000) | Acc: (97.00%) (39869/41088)
Epoch: 182 | Batch_idx: 330 |  Loss: (0.0897) |  Loss2: (0.0000) | Acc: (97.00%) (41103/42368)
Epoch: 182 | Batch_idx: 340 |  Loss: (0.0897) |  Loss2: (0.0000) | Acc: (97.00%) (42342/43648)
Epoch: 182 | Batch_idx: 350 |  Loss: (0.0899) |  Loss2: (0.0000) | Acc: (97.00%) (43582/44928)
Epoch: 182 | Batch_idx: 360 |  Loss: (0.0902) |  Loss2: (0.0000) | Acc: (96.00%) (44816/46208)
Epoch: 182 | Batch_idx: 370 |  Loss: (0.0906) |  Loss2: (0.0000) | Acc: (96.00%) (46043/47488)
Epoch: 182 | Batch_idx: 380 |  Loss: (0.0910) |  Loss2: (0.0000) | Acc: (96.00%) (47283/48768)
Epoch: 182 | Batch_idx: 390 |  Loss: (0.0907) |  Loss2: (0.0000) | Acc: (96.00%) (48479/50000)
# TEST : Loss: (0.3997) | Acc: (88.00%) (8840/10000)
percent tensor([0.5123, 0.5118, 0.5152, 0.5154, 0.5149, 0.5173, 0.5138, 0.5164, 0.5132,
        0.5122, 0.5110, 0.5134, 0.5111, 0.5144, 0.5130, 0.5132],
       device='cuda:0') torch.Size([16])
percent tensor([0.5213, 0.5264, 0.5169, 0.5159, 0.5132, 0.5275, 0.5200, 0.5116, 0.5162,
        0.5224, 0.5212, 0.5198, 0.5281, 0.5161, 0.5244, 0.5265],
       device='cuda:0') torch.Size([16])
percent tensor([0.6011, 0.5370, 0.6500, 0.6694, 0.6600, 0.6413, 0.6004, 0.6426, 0.6465,
        0.5803, 0.6234, 0.6071, 0.5128, 0.6642, 0.5892, 0.6023],
       device='cuda:0') torch.Size([16])
percent tensor([0.6663, 0.6496, 0.6553, 0.6543, 0.6571, 0.6678, 0.6626, 0.6592, 0.6599,
        0.6564, 0.6553, 0.6563, 0.6560, 0.6525, 0.6630, 0.6731],
       device='cuda:0') torch.Size([16])
percent tensor([0.6487, 0.6059, 0.6453, 0.6625, 0.6534, 0.7635, 0.6102, 0.5955, 0.6411,
        0.6454, 0.5961, 0.6140, 0.6273, 0.6529, 0.6028, 0.7230],
       device='cuda:0') torch.Size([16])
percent tensor([0.6196, 0.6937, 0.6752, 0.7134, 0.6725, 0.7381, 0.6909, 0.5424, 0.7002,
        0.6763, 0.7434, 0.6821, 0.7395, 0.7241, 0.5544, 0.6350],
       device='cuda:0') torch.Size([16])
percent tensor([0.5648, 0.6537, 0.6637, 0.6648, 0.6840, 0.6281, 0.6512, 0.6356, 0.6021,
        0.6672, 0.6687, 0.6120, 0.6016, 0.5825, 0.5768, 0.5646],
       device='cuda:0') torch.Size([16])
percent tensor([0.9999, 0.9997, 0.9998, 0.9999, 0.9996, 0.9993, 0.9996, 0.9997, 0.9998,
        0.9998, 0.9998, 0.9998, 0.9999, 0.9994, 0.9994, 0.9998],
       device='cuda:0') torch.Size([16])
Epoch: 183 | Batch_idx: 0 |  Loss: (0.0694) |  Loss2: (0.0000) | Acc: (98.00%) (126/128)
Epoch: 183 | Batch_idx: 10 |  Loss: (0.0843) |  Loss2: (0.0000) | Acc: (97.00%) (1368/1408)
Epoch: 183 | Batch_idx: 20 |  Loss: (0.0810) |  Loss2: (0.0000) | Acc: (97.00%) (2613/2688)
Epoch: 183 | Batch_idx: 30 |  Loss: (0.0817) |  Loss2: (0.0000) | Acc: (97.00%) (3863/3968)
Epoch: 183 | Batch_idx: 40 |  Loss: (0.0854) |  Loss2: (0.0000) | Acc: (97.00%) (5105/5248)
Epoch: 183 | Batch_idx: 50 |  Loss: (0.0844) |  Loss2: (0.0000) | Acc: (97.00%) (6346/6528)
Epoch: 183 | Batch_idx: 60 |  Loss: (0.0849) |  Loss2: (0.0000) | Acc: (97.00%) (7588/7808)
Epoch: 183 | Batch_idx: 70 |  Loss: (0.0863) |  Loss2: (0.0000) | Acc: (97.00%) (8824/9088)
Epoch: 183 | Batch_idx: 80 |  Loss: (0.0854) |  Loss2: (0.0000) | Acc: (97.00%) (10070/10368)
Epoch: 183 | Batch_idx: 90 |  Loss: (0.0849) |  Loss2: (0.0000) | Acc: (97.00%) (11311/11648)
Epoch: 183 | Batch_idx: 100 |  Loss: (0.0842) |  Loss2: (0.0000) | Acc: (97.00%) (12559/12928)
Epoch: 183 | Batch_idx: 110 |  Loss: (0.0832) |  Loss2: (0.0000) | Acc: (97.00%) (13806/14208)
Epoch: 183 | Batch_idx: 120 |  Loss: (0.0829) |  Loss2: (0.0000) | Acc: (97.00%) (15048/15488)
Epoch: 183 | Batch_idx: 130 |  Loss: (0.0826) |  Loss2: (0.0000) | Acc: (97.00%) (16296/16768)
Epoch: 183 | Batch_idx: 140 |  Loss: (0.0828) |  Loss2: (0.0000) | Acc: (97.00%) (17539/18048)
Epoch: 183 | Batch_idx: 150 |  Loss: (0.0834) |  Loss2: (0.0000) | Acc: (97.00%) (18779/19328)
Epoch: 183 | Batch_idx: 160 |  Loss: (0.0841) |  Loss2: (0.0000) | Acc: (97.00%) (20018/20608)
Epoch: 183 | Batch_idx: 170 |  Loss: (0.0850) |  Loss2: (0.0000) | Acc: (97.00%) (21255/21888)
Epoch: 183 | Batch_idx: 180 |  Loss: (0.0851) |  Loss2: (0.0000) | Acc: (97.00%) (22497/23168)
Epoch: 183 | Batch_idx: 190 |  Loss: (0.0847) |  Loss2: (0.0000) | Acc: (97.00%) (23745/24448)
Epoch: 183 | Batch_idx: 200 |  Loss: (0.0843) |  Loss2: (0.0000) | Acc: (97.00%) (24997/25728)
Epoch: 183 | Batch_idx: 210 |  Loss: (0.0850) |  Loss2: (0.0000) | Acc: (97.00%) (26235/27008)
Epoch: 183 | Batch_idx: 220 |  Loss: (0.0850) |  Loss2: (0.0000) | Acc: (97.00%) (27475/28288)
Epoch: 183 | Batch_idx: 230 |  Loss: (0.0852) |  Loss2: (0.0000) | Acc: (97.00%) (28706/29568)
Epoch: 183 | Batch_idx: 240 |  Loss: (0.0855) |  Loss2: (0.0000) | Acc: (97.00%) (29952/30848)
Epoch: 183 | Batch_idx: 250 |  Loss: (0.0857) |  Loss2: (0.0000) | Acc: (97.00%) (31192/32128)
Epoch: 183 | Batch_idx: 260 |  Loss: (0.0852) |  Loss2: (0.0000) | Acc: (97.00%) (32440/33408)
Epoch: 183 | Batch_idx: 270 |  Loss: (0.0858) |  Loss2: (0.0000) | Acc: (97.00%) (33668/34688)
Epoch: 183 | Batch_idx: 280 |  Loss: (0.0860) |  Loss2: (0.0000) | Acc: (97.00%) (34907/35968)
Epoch: 183 | Batch_idx: 290 |  Loss: (0.0864) |  Loss2: (0.0000) | Acc: (97.00%) (36140/37248)
Epoch: 183 | Batch_idx: 300 |  Loss: (0.0863) |  Loss2: (0.0000) | Acc: (97.00%) (37380/38528)
Epoch: 183 | Batch_idx: 310 |  Loss: (0.0868) |  Loss2: (0.0000) | Acc: (97.00%) (38614/39808)
Epoch: 183 | Batch_idx: 320 |  Loss: (0.0868) |  Loss2: (0.0000) | Acc: (97.00%) (39859/41088)
Epoch: 183 | Batch_idx: 330 |  Loss: (0.0875) |  Loss2: (0.0000) | Acc: (96.00%) (41094/42368)
Epoch: 183 | Batch_idx: 340 |  Loss: (0.0877) |  Loss2: (0.0000) | Acc: (96.00%) (42337/43648)
Epoch: 183 | Batch_idx: 350 |  Loss: (0.0874) |  Loss2: (0.0000) | Acc: (97.00%) (43585/44928)
Epoch: 183 | Batch_idx: 360 |  Loss: (0.0880) |  Loss2: (0.0000) | Acc: (96.00%) (44818/46208)
Epoch: 183 | Batch_idx: 370 |  Loss: (0.0880) |  Loss2: (0.0000) | Acc: (96.00%) (46061/47488)
Epoch: 183 | Batch_idx: 380 |  Loss: (0.0878) |  Loss2: (0.0000) | Acc: (97.00%) (47311/48768)
Epoch: 183 | Batch_idx: 390 |  Loss: (0.0886) |  Loss2: (0.0000) | Acc: (96.00%) (48493/50000)
# TEST : Loss: (0.4235) | Acc: (88.00%) (8805/10000)
percent tensor([0.5121, 0.5116, 0.5147, 0.5155, 0.5145, 0.5162, 0.5135, 0.5164, 0.5129,
        0.5122, 0.5108, 0.5129, 0.5110, 0.5142, 0.5126, 0.5130],
       device='cuda:0') torch.Size([16])
percent tensor([0.5217, 0.5261, 0.5193, 0.5166, 0.5144, 0.5280, 0.5198, 0.5132, 0.5164,
        0.5231, 0.5214, 0.5204, 0.5286, 0.5142, 0.5252, 0.5265],
       device='cuda:0') torch.Size([16])
percent tensor([0.6030, 0.5494, 0.6536, 0.6715, 0.6648, 0.6512, 0.6093, 0.6456, 0.6541,
        0.5909, 0.6297, 0.6137, 0.5162, 0.6794, 0.5962, 0.6119],
       device='cuda:0') torch.Size([16])
percent tensor([0.6633, 0.6477, 0.6533, 0.6526, 0.6565, 0.6619, 0.6627, 0.6577, 0.6565,
        0.6560, 0.6528, 0.6551, 0.6537, 0.6495, 0.6587, 0.6712],
       device='cuda:0') torch.Size([16])
percent tensor([0.6358, 0.6054, 0.6438, 0.6612, 0.6477, 0.7533, 0.6120, 0.6025, 0.6305,
        0.6443, 0.5927, 0.6040, 0.6179, 0.6512, 0.6024, 0.7187],
       device='cuda:0') torch.Size([16])
percent tensor([0.6204, 0.7059, 0.6702, 0.7111, 0.6826, 0.7457, 0.6918, 0.5318, 0.7105,
        0.6736, 0.7613, 0.6764, 0.7331, 0.7393, 0.5643, 0.6500],
       device='cuda:0') torch.Size([16])
percent tensor([0.5533, 0.6543, 0.6398, 0.6550, 0.6817, 0.6378, 0.6467, 0.6170, 0.6055,
        0.6503, 0.6747, 0.5806, 0.6040, 0.5953, 0.5745, 0.5630],
       device='cuda:0') torch.Size([16])
percent tensor([0.9999, 0.9998, 0.9997, 0.9999, 0.9994, 0.9993, 0.9998, 0.9996, 0.9999,
        0.9999, 0.9999, 0.9998, 0.9999, 0.9996, 0.9995, 0.9996],
       device='cuda:0') torch.Size([16])
Epoch: 184 | Batch_idx: 0 |  Loss: (0.0875) |  Loss2: (0.0000) | Acc: (96.00%) (124/128)
Epoch: 184 | Batch_idx: 10 |  Loss: (0.0764) |  Loss2: (0.0000) | Acc: (97.00%) (1367/1408)
Epoch: 184 | Batch_idx: 20 |  Loss: (0.0836) |  Loss2: (0.0000) | Acc: (97.00%) (2610/2688)
Epoch: 184 | Batch_idx: 30 |  Loss: (0.0807) |  Loss2: (0.0000) | Acc: (97.00%) (3861/3968)
Epoch: 184 | Batch_idx: 40 |  Loss: (0.0801) |  Loss2: (0.0000) | Acc: (97.00%) (5116/5248)
Epoch: 184 | Batch_idx: 50 |  Loss: (0.0836) |  Loss2: (0.0000) | Acc: (97.00%) (6351/6528)
Epoch: 184 | Batch_idx: 60 |  Loss: (0.0862) |  Loss2: (0.0000) | Acc: (97.00%) (7589/7808)
Epoch: 184 | Batch_idx: 70 |  Loss: (0.0864) |  Loss2: (0.0000) | Acc: (97.00%) (8831/9088)
Epoch: 184 | Batch_idx: 80 |  Loss: (0.0869) |  Loss2: (0.0000) | Acc: (97.00%) (10065/10368)
Epoch: 184 | Batch_idx: 90 |  Loss: (0.0865) |  Loss2: (0.0000) | Acc: (97.00%) (11307/11648)
Epoch: 184 | Batch_idx: 100 |  Loss: (0.0859) |  Loss2: (0.0000) | Acc: (97.00%) (12559/12928)
Epoch: 184 | Batch_idx: 110 |  Loss: (0.0857) |  Loss2: (0.0000) | Acc: (97.00%) (13803/14208)
Epoch: 184 | Batch_idx: 120 |  Loss: (0.0862) |  Loss2: (0.0000) | Acc: (97.00%) (15044/15488)
Epoch: 184 | Batch_idx: 130 |  Loss: (0.0867) |  Loss2: (0.0000) | Acc: (97.00%) (16278/16768)
Epoch: 184 | Batch_idx: 140 |  Loss: (0.0863) |  Loss2: (0.0000) | Acc: (97.00%) (17520/18048)
Epoch: 184 | Batch_idx: 150 |  Loss: (0.0857) |  Loss2: (0.0000) | Acc: (97.00%) (18772/19328)
Epoch: 184 | Batch_idx: 160 |  Loss: (0.0853) |  Loss2: (0.0000) | Acc: (97.00%) (20016/20608)
Epoch: 184 | Batch_idx: 170 |  Loss: (0.0846) |  Loss2: (0.0000) | Acc: (97.00%) (21263/21888)
Epoch: 184 | Batch_idx: 180 |  Loss: (0.0843) |  Loss2: (0.0000) | Acc: (97.00%) (22507/23168)
Epoch: 184 | Batch_idx: 190 |  Loss: (0.0838) |  Loss2: (0.0000) | Acc: (97.00%) (23754/24448)
Epoch: 184 | Batch_idx: 200 |  Loss: (0.0840) |  Loss2: (0.0000) | Acc: (97.00%) (24998/25728)
Epoch: 184 | Batch_idx: 210 |  Loss: (0.0838) |  Loss2: (0.0000) | Acc: (97.00%) (26245/27008)
Epoch: 184 | Batch_idx: 220 |  Loss: (0.0838) |  Loss2: (0.0000) | Acc: (97.00%) (27487/28288)
Epoch: 184 | Batch_idx: 230 |  Loss: (0.0841) |  Loss2: (0.0000) | Acc: (97.00%) (28729/29568)
Epoch: 184 | Batch_idx: 240 |  Loss: (0.0843) |  Loss2: (0.0000) | Acc: (97.00%) (29975/30848)
Epoch: 184 | Batch_idx: 250 |  Loss: (0.0852) |  Loss2: (0.0000) | Acc: (97.00%) (31206/32128)
Epoch: 184 | Batch_idx: 260 |  Loss: (0.0850) |  Loss2: (0.0000) | Acc: (97.00%) (32447/33408)
Epoch: 184 | Batch_idx: 270 |  Loss: (0.0852) |  Loss2: (0.0000) | Acc: (97.00%) (33683/34688)
Epoch: 184 | Batch_idx: 280 |  Loss: (0.0860) |  Loss2: (0.0000) | Acc: (97.00%) (34910/35968)
Epoch: 184 | Batch_idx: 290 |  Loss: (0.0860) |  Loss2: (0.0000) | Acc: (97.00%) (36157/37248)
Epoch: 184 | Batch_idx: 300 |  Loss: (0.0869) |  Loss2: (0.0000) | Acc: (97.00%) (37381/38528)
Epoch: 184 | Batch_idx: 310 |  Loss: (0.0876) |  Loss2: (0.0000) | Acc: (96.00%) (38611/39808)
Epoch: 184 | Batch_idx: 320 |  Loss: (0.0876) |  Loss2: (0.0000) | Acc: (96.00%) (39846/41088)
Epoch: 184 | Batch_idx: 330 |  Loss: (0.0876) |  Loss2: (0.0000) | Acc: (96.00%) (41084/42368)
Epoch: 184 | Batch_idx: 340 |  Loss: (0.0880) |  Loss2: (0.0000) | Acc: (96.00%) (42320/43648)
Epoch: 184 | Batch_idx: 350 |  Loss: (0.0879) |  Loss2: (0.0000) | Acc: (96.00%) (43566/44928)
Epoch: 184 | Batch_idx: 360 |  Loss: (0.0879) |  Loss2: (0.0000) | Acc: (96.00%) (44807/46208)
Epoch: 184 | Batch_idx: 370 |  Loss: (0.0880) |  Loss2: (0.0000) | Acc: (96.00%) (46051/47488)
Epoch: 184 | Batch_idx: 380 |  Loss: (0.0883) |  Loss2: (0.0000) | Acc: (96.00%) (47282/48768)
Epoch: 184 | Batch_idx: 390 |  Loss: (0.0885) |  Loss2: (0.0000) | Acc: (96.00%) (48467/50000)
# TEST : Loss: (0.4567) | Acc: (87.00%) (8785/10000)
percent tensor([0.5123, 0.5118, 0.5147, 0.5154, 0.5144, 0.5161, 0.5134, 0.5165, 0.5131,
        0.5121, 0.5108, 0.5128, 0.5111, 0.5144, 0.5125, 0.5132],
       device='cuda:0') torch.Size([16])
percent tensor([0.5211, 0.5268, 0.5165, 0.5162, 0.5131, 0.5287, 0.5195, 0.5115, 0.5163,
        0.5224, 0.5220, 0.5187, 0.5289, 0.5157, 0.5256, 0.5263],
       device='cuda:0') torch.Size([16])
percent tensor([0.6074, 0.5507, 0.6565, 0.6758, 0.6670, 0.6498, 0.6129, 0.6501, 0.6530,
        0.5927, 0.6290, 0.6154, 0.5174, 0.6763, 0.5983, 0.6117],
       device='cuda:0') torch.Size([16])
percent tensor([0.6635, 0.6497, 0.6493, 0.6520, 0.6556, 0.6623, 0.6625, 0.6564, 0.6559,
        0.6588, 0.6548, 0.6536, 0.6549, 0.6543, 0.6592, 0.6716],
       device='cuda:0') torch.Size([16])
percent tensor([0.6475, 0.6165, 0.6435, 0.6679, 0.6597, 0.7775, 0.6163, 0.5908, 0.6511,
        0.6660, 0.6159, 0.6053, 0.6282, 0.6711, 0.6184, 0.7338],
       device='cuda:0') torch.Size([16])
percent tensor([0.6242, 0.6921, 0.6986, 0.7072, 0.6845, 0.7421, 0.6849, 0.5537, 0.7137,
        0.6609, 0.7592, 0.6715, 0.7371, 0.7236, 0.5481, 0.6460],
       device='cuda:0') torch.Size([16])
percent tensor([0.5563, 0.6489, 0.6691, 0.6571, 0.6859, 0.6365, 0.6594, 0.6345, 0.5991,
        0.6411, 0.6649, 0.5953, 0.6042, 0.5864, 0.5725, 0.5565],
       device='cuda:0') torch.Size([16])
percent tensor([0.9999, 0.9998, 0.9998, 0.9998, 0.9995, 0.9993, 0.9996, 0.9997, 0.9998,
        0.9998, 1.0000, 0.9998, 0.9999, 0.9993, 0.9994, 0.9997],
       device='cuda:0') torch.Size([16])
Epoch: 185 | Batch_idx: 0 |  Loss: (0.0899) |  Loss2: (0.0000) | Acc: (96.00%) (124/128)
Epoch: 185 | Batch_idx: 10 |  Loss: (0.0974) |  Loss2: (0.0000) | Acc: (96.00%) (1363/1408)
Epoch: 185 | Batch_idx: 20 |  Loss: (0.0864) |  Loss2: (0.0000) | Acc: (97.00%) (2618/2688)
Epoch: 185 | Batch_idx: 30 |  Loss: (0.0867) |  Loss2: (0.0000) | Acc: (97.00%) (3861/3968)
Epoch: 185 | Batch_idx: 40 |  Loss: (0.0850) |  Loss2: (0.0000) | Acc: (97.00%) (5107/5248)
Epoch: 185 | Batch_idx: 50 |  Loss: (0.0826) |  Loss2: (0.0000) | Acc: (97.00%) (6361/6528)
Epoch: 185 | Batch_idx: 60 |  Loss: (0.0808) |  Loss2: (0.0000) | Acc: (97.00%) (7611/7808)
Epoch: 185 | Batch_idx: 70 |  Loss: (0.0814) |  Loss2: (0.0000) | Acc: (97.00%) (8850/9088)
Epoch: 185 | Batch_idx: 80 |  Loss: (0.0807) |  Loss2: (0.0000) | Acc: (97.00%) (10097/10368)
Epoch: 185 | Batch_idx: 90 |  Loss: (0.0814) |  Loss2: (0.0000) | Acc: (97.00%) (11335/11648)
Epoch: 185 | Batch_idx: 100 |  Loss: (0.0824) |  Loss2: (0.0000) | Acc: (97.00%) (12585/12928)
Epoch: 185 | Batch_idx: 110 |  Loss: (0.0834) |  Loss2: (0.0000) | Acc: (97.00%) (13823/14208)
Epoch: 185 | Batch_idx: 120 |  Loss: (0.0844) |  Loss2: (0.0000) | Acc: (97.00%) (15063/15488)
Epoch: 185 | Batch_idx: 130 |  Loss: (0.0849) |  Loss2: (0.0000) | Acc: (97.00%) (16302/16768)
Epoch: 185 | Batch_idx: 140 |  Loss: (0.0843) |  Loss2: (0.0000) | Acc: (97.00%) (17553/18048)
Epoch: 185 | Batch_idx: 150 |  Loss: (0.0849) |  Loss2: (0.0000) | Acc: (97.00%) (18792/19328)
Epoch: 185 | Batch_idx: 160 |  Loss: (0.0854) |  Loss2: (0.0000) | Acc: (97.00%) (20030/20608)
Epoch: 185 | Batch_idx: 170 |  Loss: (0.0860) |  Loss2: (0.0000) | Acc: (97.00%) (21270/21888)
Epoch: 185 | Batch_idx: 180 |  Loss: (0.0861) |  Loss2: (0.0000) | Acc: (97.00%) (22506/23168)
Epoch: 185 | Batch_idx: 190 |  Loss: (0.0863) |  Loss2: (0.0000) | Acc: (97.00%) (23747/24448)
Epoch: 185 | Batch_idx: 200 |  Loss: (0.0861) |  Loss2: (0.0000) | Acc: (97.00%) (24989/25728)
Epoch: 185 | Batch_idx: 210 |  Loss: (0.0859) |  Loss2: (0.0000) | Acc: (97.00%) (26229/27008)
Epoch: 185 | Batch_idx: 220 |  Loss: (0.0850) |  Loss2: (0.0000) | Acc: (97.00%) (27475/28288)
Epoch: 185 | Batch_idx: 230 |  Loss: (0.0841) |  Loss2: (0.0000) | Acc: (97.00%) (28730/29568)
Epoch: 185 | Batch_idx: 240 |  Loss: (0.0834) |  Loss2: (0.0000) | Acc: (97.00%) (29985/30848)
Epoch: 185 | Batch_idx: 250 |  Loss: (0.0830) |  Loss2: (0.0000) | Acc: (97.00%) (31235/32128)
Epoch: 185 | Batch_idx: 260 |  Loss: (0.0823) |  Loss2: (0.0000) | Acc: (97.00%) (32490/33408)
Epoch: 185 | Batch_idx: 270 |  Loss: (0.0822) |  Loss2: (0.0000) | Acc: (97.00%) (33738/34688)
Epoch: 185 | Batch_idx: 280 |  Loss: (0.0821) |  Loss2: (0.0000) | Acc: (97.00%) (34981/35968)
Epoch: 185 | Batch_idx: 290 |  Loss: (0.0828) |  Loss2: (0.0000) | Acc: (97.00%) (36208/37248)
Epoch: 185 | Batch_idx: 300 |  Loss: (0.0829) |  Loss2: (0.0000) | Acc: (97.00%) (37452/38528)
Epoch: 185 | Batch_idx: 310 |  Loss: (0.0834) |  Loss2: (0.0000) | Acc: (97.00%) (38685/39808)
Epoch: 185 | Batch_idx: 320 |  Loss: (0.0834) |  Loss2: (0.0000) | Acc: (97.00%) (39928/41088)
Epoch: 185 | Batch_idx: 330 |  Loss: (0.0835) |  Loss2: (0.0000) | Acc: (97.00%) (41169/42368)
Epoch: 185 | Batch_idx: 340 |  Loss: (0.0838) |  Loss2: (0.0000) | Acc: (97.00%) (42404/43648)
Epoch: 185 | Batch_idx: 350 |  Loss: (0.0849) |  Loss2: (0.0000) | Acc: (97.00%) (43623/44928)
Epoch: 185 | Batch_idx: 360 |  Loss: (0.0851) |  Loss2: (0.0000) | Acc: (97.00%) (44865/46208)
Epoch: 185 | Batch_idx: 370 |  Loss: (0.0856) |  Loss2: (0.0000) | Acc: (97.00%) (46097/47488)
Epoch: 185 | Batch_idx: 380 |  Loss: (0.0866) |  Loss2: (0.0000) | Acc: (97.00%) (47321/48768)
Epoch: 185 | Batch_idx: 390 |  Loss: (0.0865) |  Loss2: (0.0000) | Acc: (97.00%) (48517/50000)
=> saving checkpoint 'drive/app/torch/save_Schedule/checkpoint_185.pth.tar'
# TEST : Loss: (0.4015) | Acc: (88.00%) (8856/10000)
percent tensor([0.5120, 0.5121, 0.5153, 0.5164, 0.5149, 0.5169, 0.5139, 0.5167, 0.5124,
        0.5124, 0.5108, 0.5132, 0.5108, 0.5146, 0.5130, 0.5135],
       device='cuda:0') torch.Size([16])
percent tensor([0.5216, 0.5275, 0.5172, 0.5151, 0.5143, 0.5297, 0.5204, 0.5107, 0.5165,
        0.5227, 0.5217, 0.5196, 0.5288, 0.5176, 0.5266, 0.5271],
       device='cuda:0') torch.Size([16])
percent tensor([0.5990, 0.5466, 0.6498, 0.6746, 0.6562, 0.6256, 0.6046, 0.6534, 0.6478,
        0.5862, 0.6222, 0.5995, 0.5099, 0.6702, 0.5880, 0.6050],
       device='cuda:0') torch.Size([16])
percent tensor([0.6633, 0.6495, 0.6541, 0.6497, 0.6570, 0.6629, 0.6623, 0.6583, 0.6546,
        0.6581, 0.6525, 0.6551, 0.6546, 0.6524, 0.6577, 0.6708],
       device='cuda:0') torch.Size([16])
percent tensor([0.6650, 0.6274, 0.6741, 0.6881, 0.6802, 0.7915, 0.6303, 0.6217, 0.6562,
        0.6759, 0.5990, 0.6310, 0.6473, 0.6559, 0.6335, 0.7415],
       device='cuda:0') torch.Size([16])
percent tensor([0.6359, 0.7176, 0.6893, 0.7162, 0.6808, 0.7508, 0.7021, 0.5340, 0.7369,
        0.6914, 0.7684, 0.6932, 0.7475, 0.7555, 0.5811, 0.6608],
       device='cuda:0') torch.Size([16])
percent tensor([0.5570, 0.6455, 0.6698, 0.6650, 0.6796, 0.6447, 0.6453, 0.6230, 0.6226,
        0.6669, 0.6732, 0.6016, 0.6192, 0.6027, 0.5889, 0.5657],
       device='cuda:0') torch.Size([16])
percent tensor([0.9999, 0.9998, 0.9998, 0.9999, 0.9996, 0.9992, 0.9998, 0.9997, 0.9999,
        0.9999, 0.9999, 0.9998, 0.9999, 0.9996, 0.9993, 0.9996],
       device='cuda:0') torch.Size([16])
False Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=128, out_features=16, bias=False)
True Linear(in_features=16, out_features=2, bias=False)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=128, out_features=16, bias=False)
True Linear(in_features=16, out_features=2, bias=False)
False Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=256, out_features=32, bias=False)
True Linear(in_features=32, out_features=2, bias=False)
False Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=256, out_features=32, bias=False)
True Linear(in_features=32, out_features=2, bias=False)
False Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=512, out_features=64, bias=False)
True Linear(in_features=64, out_features=2, bias=False)
False Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=512, out_features=64, bias=False)
True Linear(in_features=64, out_features=2, bias=False)
False Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1024, out_features=128, bias=False)
True Linear(in_features=128, out_features=2, bias=False)
False Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1024, out_features=128, bias=False)
True Linear(in_features=128, out_features=2, bias=False)
False Linear(in_features=512, out_features=10, bias=True)
Epoch: 186 | Batch_idx: 0 |  Loss: (0.0966) |  Loss2: (0.0000) | Acc: (96.00%) (124/128)
Epoch: 186 | Batch_idx: 10 |  Loss: (0.0782) |  Loss2: (0.0000) | Acc: (97.00%) (1369/1408)
Epoch: 186 | Batch_idx: 20 |  Loss: (0.0965) |  Loss2: (0.0000) | Acc: (96.00%) (2594/2688)
Epoch: 186 | Batch_idx: 30 |  Loss: (0.1042) |  Loss2: (0.0000) | Acc: (96.00%) (3815/3968)
Epoch: 186 | Batch_idx: 40 |  Loss: (0.1051) |  Loss2: (0.0000) | Acc: (96.00%) (5042/5248)
Epoch: 186 | Batch_idx: 50 |  Loss: (0.1088) |  Loss2: (0.0000) | Acc: (95.00%) (6255/6528)
Epoch: 186 | Batch_idx: 60 |  Loss: (0.1116) |  Loss2: (0.0000) | Acc: (95.00%) (7481/7808)
Epoch: 186 | Batch_idx: 70 |  Loss: (0.1105) |  Loss2: (0.0000) | Acc: (95.00%) (8719/9088)
Epoch: 186 | Batch_idx: 80 |  Loss: (0.1115) |  Loss2: (0.0000) | Acc: (95.00%) (9948/10368)
Epoch: 186 | Batch_idx: 90 |  Loss: (0.1136) |  Loss2: (0.0000) | Acc: (95.00%) (11166/11648)
Epoch: 186 | Batch_idx: 100 |  Loss: (0.1146) |  Loss2: (0.0000) | Acc: (95.00%) (12391/12928)
Epoch: 186 | Batch_idx: 110 |  Loss: (0.1133) |  Loss2: (0.0000) | Acc: (95.00%) (13622/14208)
Epoch: 186 | Batch_idx: 120 |  Loss: (0.1133) |  Loss2: (0.0000) | Acc: (95.00%) (14850/15488)
Epoch: 186 | Batch_idx: 130 |  Loss: (0.1129) |  Loss2: (0.0000) | Acc: (95.00%) (16079/16768)
Epoch: 186 | Batch_idx: 140 |  Loss: (0.1126) |  Loss2: (0.0000) | Acc: (95.00%) (17311/18048)
Epoch: 186 | Batch_idx: 150 |  Loss: (0.1109) |  Loss2: (0.0000) | Acc: (95.00%) (18554/19328)
Epoch: 186 | Batch_idx: 160 |  Loss: (0.1109) |  Loss2: (0.0000) | Acc: (95.00%) (19783/20608)
Epoch: 186 | Batch_idx: 170 |  Loss: (0.1098) |  Loss2: (0.0000) | Acc: (96.00%) (21022/21888)
Epoch: 186 | Batch_idx: 180 |  Loss: (0.1098) |  Loss2: (0.0000) | Acc: (96.00%) (22253/23168)
Epoch: 186 | Batch_idx: 190 |  Loss: (0.1095) |  Loss2: (0.0000) | Acc: (96.00%) (23494/24448)
Epoch: 186 | Batch_idx: 200 |  Loss: (0.1100) |  Loss2: (0.0000) | Acc: (96.00%) (24723/25728)
Epoch: 186 | Batch_idx: 210 |  Loss: (0.1101) |  Loss2: (0.0000) | Acc: (96.00%) (25956/27008)
Epoch: 186 | Batch_idx: 220 |  Loss: (0.1099) |  Loss2: (0.0000) | Acc: (96.00%) (27191/28288)
Epoch: 186 | Batch_idx: 230 |  Loss: (0.1108) |  Loss2: (0.0000) | Acc: (96.00%) (28413/29568)
Epoch: 186 | Batch_idx: 240 |  Loss: (0.1110) |  Loss2: (0.0000) | Acc: (96.00%) (29640/30848)
Epoch: 186 | Batch_idx: 250 |  Loss: (0.1107) |  Loss2: (0.0000) | Acc: (96.00%) (30869/32128)
Epoch: 186 | Batch_idx: 260 |  Loss: (0.1101) |  Loss2: (0.0000) | Acc: (96.00%) (32107/33408)
Epoch: 186 | Batch_idx: 270 |  Loss: (0.1095) |  Loss2: (0.0000) | Acc: (96.00%) (33340/34688)
Epoch: 186 | Batch_idx: 280 |  Loss: (0.1087) |  Loss2: (0.0000) | Acc: (96.00%) (34582/35968)
Epoch: 186 | Batch_idx: 290 |  Loss: (0.1081) |  Loss2: (0.0000) | Acc: (96.00%) (35822/37248)
Epoch: 186 | Batch_idx: 300 |  Loss: (0.1080) |  Loss2: (0.0000) | Acc: (96.00%) (37055/38528)
Epoch: 186 | Batch_idx: 310 |  Loss: (0.1078) |  Loss2: (0.0000) | Acc: (96.00%) (38290/39808)
Epoch: 186 | Batch_idx: 320 |  Loss: (0.1078) |  Loss2: (0.0000) | Acc: (96.00%) (39516/41088)
Epoch: 186 | Batch_idx: 330 |  Loss: (0.1080) |  Loss2: (0.0000) | Acc: (96.00%) (40748/42368)
Epoch: 186 | Batch_idx: 340 |  Loss: (0.1085) |  Loss2: (0.0000) | Acc: (96.00%) (41971/43648)
Epoch: 186 | Batch_idx: 350 |  Loss: (0.1081) |  Loss2: (0.0000) | Acc: (96.00%) (43205/44928)
Epoch: 186 | Batch_idx: 360 |  Loss: (0.1086) |  Loss2: (0.0000) | Acc: (96.00%) (44431/46208)
Epoch: 186 | Batch_idx: 370 |  Loss: (0.1084) |  Loss2: (0.0000) | Acc: (96.00%) (45667/47488)
Epoch: 186 | Batch_idx: 380 |  Loss: (0.1083) |  Loss2: (0.0000) | Acc: (96.00%) (46899/48768)
Epoch: 186 | Batch_idx: 390 |  Loss: (0.1079) |  Loss2: (0.0000) | Acc: (96.00%) (48092/50000)
# TEST : Loss: (0.4018) | Acc: (88.00%) (8858/10000)
percent tensor([0.5121, 0.5128, 0.5146, 0.5168, 0.5146, 0.5178, 0.5143, 0.5170, 0.5126,
        0.5126, 0.5112, 0.5129, 0.5110, 0.5156, 0.5138, 0.5140],
       device='cuda:0') torch.Size([16])
percent tensor([0.5266, 0.5338, 0.5230, 0.5195, 0.5201, 0.5351, 0.5267, 0.5150, 0.5225,
        0.5290, 0.5285, 0.5260, 0.5347, 0.5231, 0.5324, 0.5334],
       device='cuda:0') torch.Size([16])
percent tensor([0.5974, 0.5625, 0.6429, 0.6781, 0.6544, 0.6183, 0.6122, 0.6511, 0.6503,
        0.5995, 0.6375, 0.6014, 0.5119, 0.6831, 0.5938, 0.6109],
       device='cuda:0') torch.Size([16])
percent tensor([0.6653, 0.6554, 0.6547, 0.6521, 0.6584, 0.6642, 0.6656, 0.6582, 0.6574,
        0.6641, 0.6589, 0.6602, 0.6584, 0.6569, 0.6613, 0.6731],
       device='cuda:0') torch.Size([16])
percent tensor([0.6532, 0.6113, 0.6628, 0.6767, 0.6693, 0.7939, 0.6178, 0.6192, 0.6423,
        0.6639, 0.5757, 0.6124, 0.6292, 0.6392, 0.6250, 0.7353],
       device='cuda:0') torch.Size([16])
percent tensor([0.5827, 0.6756, 0.6277, 0.6659, 0.6241, 0.7026, 0.6521, 0.4646, 0.6952,
        0.6348, 0.7335, 0.6322, 0.7055, 0.7173, 0.5240, 0.5969],
       device='cuda:0') torch.Size([16])
percent tensor([0.5549, 0.6289, 0.6900, 0.6769, 0.7154, 0.6326, 0.6510, 0.6720, 0.6026,
        0.6434, 0.6351, 0.5909, 0.5771, 0.5792, 0.6126, 0.5648],
       device='cuda:0') torch.Size([16])
percent tensor([0.9999, 0.9998, 0.9998, 0.9999, 0.9995, 0.9991, 0.9996, 0.9996, 0.9998,
        0.9998, 0.9999, 0.9997, 0.9999, 0.9995, 0.9992, 0.9996],
       device='cuda:0') torch.Size([16])
Epoch: 187 | Batch_idx: 0 |  Loss: (0.1552) |  Loss2: (0.0000) | Acc: (96.00%) (123/128)
Epoch: 187 | Batch_idx: 10 |  Loss: (0.1096) |  Loss2: (0.0000) | Acc: (96.00%) (1357/1408)
Epoch: 187 | Batch_idx: 20 |  Loss: (0.1076) |  Loss2: (0.0000) | Acc: (96.00%) (2592/2688)
Epoch: 187 | Batch_idx: 30 |  Loss: (0.1046) |  Loss2: (0.0000) | Acc: (96.00%) (3830/3968)
Epoch: 187 | Batch_idx: 40 |  Loss: (0.1083) |  Loss2: (0.0000) | Acc: (96.00%) (5055/5248)
Epoch: 187 | Batch_idx: 50 |  Loss: (0.1049) |  Loss2: (0.0000) | Acc: (96.00%) (6292/6528)
Epoch: 187 | Batch_idx: 60 |  Loss: (0.1034) |  Loss2: (0.0000) | Acc: (96.00%) (7526/7808)
Epoch: 187 | Batch_idx: 70 |  Loss: (0.1030) |  Loss2: (0.0000) | Acc: (96.00%) (8766/9088)
Epoch: 187 | Batch_idx: 80 |  Loss: (0.1027) |  Loss2: (0.0000) | Acc: (96.00%) (9997/10368)
Epoch: 187 | Batch_idx: 90 |  Loss: (0.1035) |  Loss2: (0.0000) | Acc: (96.00%) (11233/11648)
Epoch: 187 | Batch_idx: 100 |  Loss: (0.1038) |  Loss2: (0.0000) | Acc: (96.00%) (12471/12928)
Epoch: 187 | Batch_idx: 110 |  Loss: (0.1032) |  Loss2: (0.0000) | Acc: (96.00%) (13709/14208)
Epoch: 187 | Batch_idx: 120 |  Loss: (0.1026) |  Loss2: (0.0000) | Acc: (96.00%) (14946/15488)
Epoch: 187 | Batch_idx: 130 |  Loss: (0.1026) |  Loss2: (0.0000) | Acc: (96.00%) (16175/16768)
Epoch: 187 | Batch_idx: 140 |  Loss: (0.1023) |  Loss2: (0.0000) | Acc: (96.00%) (17414/18048)
Epoch: 187 | Batch_idx: 150 |  Loss: (0.1019) |  Loss2: (0.0000) | Acc: (96.00%) (18643/19328)
Epoch: 187 | Batch_idx: 160 |  Loss: (0.1027) |  Loss2: (0.0000) | Acc: (96.00%) (19876/20608)
Epoch: 187 | Batch_idx: 170 |  Loss: (0.1022) |  Loss2: (0.0000) | Acc: (96.00%) (21118/21888)
Epoch: 187 | Batch_idx: 180 |  Loss: (0.1017) |  Loss2: (0.0000) | Acc: (96.00%) (22356/23168)
Epoch: 187 | Batch_idx: 190 |  Loss: (0.1014) |  Loss2: (0.0000) | Acc: (96.00%) (23593/24448)
Epoch: 187 | Batch_idx: 200 |  Loss: (0.1001) |  Loss2: (0.0000) | Acc: (96.00%) (24837/25728)
Epoch: 187 | Batch_idx: 210 |  Loss: (0.0995) |  Loss2: (0.0000) | Acc: (96.00%) (26077/27008)
Epoch: 187 | Batch_idx: 220 |  Loss: (0.0989) |  Loss2: (0.0000) | Acc: (96.00%) (27318/28288)
Epoch: 187 | Batch_idx: 230 |  Loss: (0.0984) |  Loss2: (0.0000) | Acc: (96.00%) (28555/29568)
Epoch: 187 | Batch_idx: 240 |  Loss: (0.0974) |  Loss2: (0.0000) | Acc: (96.00%) (29806/30848)
Epoch: 187 | Batch_idx: 250 |  Loss: (0.0969) |  Loss2: (0.0000) | Acc: (96.00%) (31039/32128)
Epoch: 187 | Batch_idx: 260 |  Loss: (0.0966) |  Loss2: (0.0000) | Acc: (96.00%) (32284/33408)
Epoch: 187 | Batch_idx: 270 |  Loss: (0.0963) |  Loss2: (0.0000) | Acc: (96.00%) (33527/34688)
Epoch: 187 | Batch_idx: 280 |  Loss: (0.0959) |  Loss2: (0.0000) | Acc: (96.00%) (34770/35968)
Epoch: 187 | Batch_idx: 290 |  Loss: (0.0956) |  Loss2: (0.0000) | Acc: (96.00%) (36007/37248)
Epoch: 187 | Batch_idx: 300 |  Loss: (0.0952) |  Loss2: (0.0000) | Acc: (96.00%) (37250/38528)
Epoch: 187 | Batch_idx: 310 |  Loss: (0.0952) |  Loss2: (0.0000) | Acc: (96.00%) (38495/39808)
Epoch: 187 | Batch_idx: 320 |  Loss: (0.0948) |  Loss2: (0.0000) | Acc: (96.00%) (39745/41088)
Epoch: 187 | Batch_idx: 330 |  Loss: (0.0947) |  Loss2: (0.0000) | Acc: (96.00%) (40990/42368)
Epoch: 187 | Batch_idx: 340 |  Loss: (0.0945) |  Loss2: (0.0000) | Acc: (96.00%) (42229/43648)
Epoch: 187 | Batch_idx: 350 |  Loss: (0.0949) |  Loss2: (0.0000) | Acc: (96.00%) (43464/44928)
Epoch: 187 | Batch_idx: 360 |  Loss: (0.0948) |  Loss2: (0.0000) | Acc: (96.00%) (44710/46208)
Epoch: 187 | Batch_idx: 370 |  Loss: (0.0947) |  Loss2: (0.0000) | Acc: (96.00%) (45952/47488)
Epoch: 187 | Batch_idx: 380 |  Loss: (0.0955) |  Loss2: (0.0000) | Acc: (96.00%) (47185/48768)
Epoch: 187 | Batch_idx: 390 |  Loss: (0.0954) |  Loss2: (0.0000) | Acc: (96.00%) (48381/50000)
# TEST : Loss: (0.3826) | Acc: (88.00%) (8885/10000)
percent tensor([0.5127, 0.5133, 0.5151, 0.5172, 0.5151, 0.5186, 0.5149, 0.5174, 0.5131,
        0.5131, 0.5118, 0.5133, 0.5115, 0.5160, 0.5145, 0.5145],
       device='cuda:0') torch.Size([16])
percent tensor([0.5266, 0.5340, 0.5224, 0.5188, 0.5196, 0.5365, 0.5267, 0.5137, 0.5222,
        0.5288, 0.5287, 0.5256, 0.5346, 0.5231, 0.5325, 0.5334],
       device='cuda:0') torch.Size([16])
percent tensor([0.6019, 0.5737, 0.6446, 0.6792, 0.6555, 0.6207, 0.6188, 0.6498, 0.6585,
        0.6105, 0.6506, 0.6094, 0.5217, 0.6927, 0.5974, 0.6163],
       device='cuda:0') torch.Size([16])
percent tensor([0.6662, 0.6587, 0.6546, 0.6521, 0.6579, 0.6639, 0.6677, 0.6575, 0.6586,
        0.6672, 0.6627, 0.6623, 0.6609, 0.6592, 0.6633, 0.6746],
       device='cuda:0') torch.Size([16])
percent tensor([0.6540, 0.6098, 0.6612, 0.6676, 0.6659, 0.7939, 0.6174, 0.6169, 0.6389,
        0.6609, 0.5683, 0.6030, 0.6281, 0.6366, 0.6219, 0.7361],
       device='cuda:0') torch.Size([16])
percent tensor([0.6014, 0.6890, 0.6440, 0.6799, 0.6369, 0.7172, 0.6653, 0.4781, 0.7131,
        0.6485, 0.7479, 0.6519, 0.7212, 0.7314, 0.5395, 0.6103],
       device='cuda:0') torch.Size([16])
percent tensor([0.5598, 0.6260, 0.7131, 0.6972, 0.7389, 0.6373, 0.6599, 0.7057, 0.6015,
        0.6444, 0.6262, 0.6061, 0.5652, 0.5692, 0.6307, 0.5689],
       device='cuda:0') torch.Size([16])
percent tensor([0.9998, 0.9998, 0.9998, 0.9999, 0.9995, 0.9991, 0.9996, 0.9996, 0.9998,
        0.9998, 0.9999, 0.9997, 0.9999, 0.9994, 0.9992, 0.9995],
       device='cuda:0') torch.Size([16])
Epoch: 188 | Batch_idx: 0 |  Loss: (0.0446) |  Loss2: (0.0000) | Acc: (99.00%) (127/128)
Epoch: 188 | Batch_idx: 10 |  Loss: (0.0786) |  Loss2: (0.0000) | Acc: (97.00%) (1374/1408)
Epoch: 188 | Batch_idx: 20 |  Loss: (0.0877) |  Loss2: (0.0000) | Acc: (97.00%) (2610/2688)
Epoch: 188 | Batch_idx: 30 |  Loss: (0.0946) |  Loss2: (0.0000) | Acc: (96.00%) (3840/3968)
Epoch: 188 | Batch_idx: 40 |  Loss: (0.0933) |  Loss2: (0.0000) | Acc: (96.00%) (5076/5248)
Epoch: 188 | Batch_idx: 50 |  Loss: (0.0897) |  Loss2: (0.0000) | Acc: (96.00%) (6326/6528)
Epoch: 188 | Batch_idx: 60 |  Loss: (0.0882) |  Loss2: (0.0000) | Acc: (97.00%) (7575/7808)
Epoch: 188 | Batch_idx: 70 |  Loss: (0.0885) |  Loss2: (0.0000) | Acc: (97.00%) (8817/9088)
Epoch: 188 | Batch_idx: 80 |  Loss: (0.0883) |  Loss2: (0.0000) | Acc: (97.00%) (10057/10368)
Epoch: 188 | Batch_idx: 90 |  Loss: (0.0885) |  Loss2: (0.0000) | Acc: (96.00%) (11298/11648)
Epoch: 188 | Batch_idx: 100 |  Loss: (0.0901) |  Loss2: (0.0000) | Acc: (96.00%) (12534/12928)
Epoch: 188 | Batch_idx: 110 |  Loss: (0.0897) |  Loss2: (0.0000) | Acc: (96.00%) (13777/14208)
Epoch: 188 | Batch_idx: 120 |  Loss: (0.0881) |  Loss2: (0.0000) | Acc: (97.00%) (15029/15488)
Epoch: 188 | Batch_idx: 130 |  Loss: (0.0879) |  Loss2: (0.0000) | Acc: (97.00%) (16272/16768)
Epoch: 188 | Batch_idx: 140 |  Loss: (0.0880) |  Loss2: (0.0000) | Acc: (97.00%) (17514/18048)
Epoch: 188 | Batch_idx: 150 |  Loss: (0.0879) |  Loss2: (0.0000) | Acc: (97.00%) (18753/19328)
Epoch: 188 | Batch_idx: 160 |  Loss: (0.0874) |  Loss2: (0.0000) | Acc: (97.00%) (19992/20608)
Epoch: 188 | Batch_idx: 170 |  Loss: (0.0880) |  Loss2: (0.0000) | Acc: (96.00%) (21227/21888)
Epoch: 188 | Batch_idx: 180 |  Loss: (0.0879) |  Loss2: (0.0000) | Acc: (96.00%) (22468/23168)
Epoch: 188 | Batch_idx: 190 |  Loss: (0.0880) |  Loss2: (0.0000) | Acc: (96.00%) (23710/24448)
Epoch: 188 | Batch_idx: 200 |  Loss: (0.0883) |  Loss2: (0.0000) | Acc: (96.00%) (24951/25728)
Epoch: 188 | Batch_idx: 210 |  Loss: (0.0879) |  Loss2: (0.0000) | Acc: (96.00%) (26197/27008)
Epoch: 188 | Batch_idx: 220 |  Loss: (0.0880) |  Loss2: (0.0000) | Acc: (96.00%) (27439/28288)
Epoch: 188 | Batch_idx: 230 |  Loss: (0.0878) |  Loss2: (0.0000) | Acc: (96.00%) (28679/29568)
Epoch: 188 | Batch_idx: 240 |  Loss: (0.0881) |  Loss2: (0.0000) | Acc: (96.00%) (29919/30848)
Epoch: 188 | Batch_idx: 250 |  Loss: (0.0871) |  Loss2: (0.0000) | Acc: (97.00%) (31171/32128)
Epoch: 188 | Batch_idx: 260 |  Loss: (0.0873) |  Loss2: (0.0000) | Acc: (97.00%) (32418/33408)
Epoch: 188 | Batch_idx: 270 |  Loss: (0.0876) |  Loss2: (0.0000) | Acc: (97.00%) (33663/34688)
Epoch: 188 | Batch_idx: 280 |  Loss: (0.0872) |  Loss2: (0.0000) | Acc: (97.00%) (34913/35968)
Epoch: 188 | Batch_idx: 290 |  Loss: (0.0869) |  Loss2: (0.0000) | Acc: (97.00%) (36163/37248)
Epoch: 188 | Batch_idx: 300 |  Loss: (0.0867) |  Loss2: (0.0000) | Acc: (97.00%) (37404/38528)
Epoch: 188 | Batch_idx: 310 |  Loss: (0.0866) |  Loss2: (0.0000) | Acc: (97.00%) (38652/39808)
Epoch: 188 | Batch_idx: 320 |  Loss: (0.0870) |  Loss2: (0.0000) | Acc: (97.00%) (39888/41088)
Epoch: 188 | Batch_idx: 330 |  Loss: (0.0872) |  Loss2: (0.0000) | Acc: (97.00%) (41134/42368)
Epoch: 188 | Batch_idx: 340 |  Loss: (0.0872) |  Loss2: (0.0000) | Acc: (97.00%) (42377/43648)
Epoch: 188 | Batch_idx: 350 |  Loss: (0.0870) |  Loss2: (0.0000) | Acc: (97.00%) (43623/44928)
Epoch: 188 | Batch_idx: 360 |  Loss: (0.0872) |  Loss2: (0.0000) | Acc: (97.00%) (44858/46208)
Epoch: 188 | Batch_idx: 370 |  Loss: (0.0872) |  Loss2: (0.0000) | Acc: (97.00%) (46094/47488)
Epoch: 188 | Batch_idx: 380 |  Loss: (0.0875) |  Loss2: (0.0000) | Acc: (97.00%) (47330/48768)
Epoch: 188 | Batch_idx: 390 |  Loss: (0.0874) |  Loss2: (0.0000) | Acc: (97.00%) (48524/50000)
# TEST : Loss: (0.3763) | Acc: (89.00%) (8902/10000)
percent tensor([0.5126, 0.5132, 0.5150, 0.5171, 0.5150, 0.5185, 0.5147, 0.5173, 0.5130,
        0.5130, 0.5117, 0.5133, 0.5114, 0.5158, 0.5144, 0.5144],
       device='cuda:0') torch.Size([16])
percent tensor([0.5260, 0.5342, 0.5214, 0.5175, 0.5183, 0.5369, 0.5264, 0.5121, 0.5219,
        0.5288, 0.5290, 0.5252, 0.5345, 0.5234, 0.5320, 0.5334],
       device='cuda:0') torch.Size([16])
percent tensor([0.5966, 0.5699, 0.6410, 0.6736, 0.6523, 0.6126, 0.6151, 0.6458, 0.6559,
        0.6078, 0.6476, 0.6063, 0.5166, 0.6887, 0.5913, 0.6108],
       device='cuda:0') torch.Size([16])
percent tensor([0.6647, 0.6587, 0.6529, 0.6506, 0.6560, 0.6612, 0.6671, 0.6557, 0.6580,
        0.6673, 0.6632, 0.6615, 0.6602, 0.6592, 0.6625, 0.6736],
       device='cuda:0') torch.Size([16])
percent tensor([0.6625, 0.6208, 0.6635, 0.6693, 0.6697, 0.7975, 0.6264, 0.6219, 0.6428,
        0.6684, 0.5735, 0.6048, 0.6347, 0.6464, 0.6305, 0.7452],
       device='cuda:0') torch.Size([16])
percent tensor([0.6062, 0.6936, 0.6453, 0.6802, 0.6385, 0.7194, 0.6680, 0.4769, 0.7172,
        0.6526, 0.7540, 0.6553, 0.7287, 0.7382, 0.5423, 0.6127],
       device='cuda:0') torch.Size([16])
percent tensor([0.5728, 0.6349, 0.7283, 0.7073, 0.7514, 0.6510, 0.6734, 0.7227, 0.6079,
        0.6555, 0.6282, 0.6201, 0.5755, 0.5696, 0.6463, 0.5803],
       device='cuda:0') torch.Size([16])
percent tensor([0.9998, 0.9998, 0.9998, 0.9999, 0.9995, 0.9990, 0.9996, 0.9996, 0.9998,
        0.9998, 0.9999, 0.9998, 0.9999, 0.9994, 0.9993, 0.9995],
       device='cuda:0') torch.Size([16])
Epoch: 189 | Batch_idx: 0 |  Loss: (0.1001) |  Loss2: (0.0000) | Acc: (96.00%) (123/128)
Epoch: 189 | Batch_idx: 10 |  Loss: (0.0932) |  Loss2: (0.0000) | Acc: (97.00%) (1368/1408)
Epoch: 189 | Batch_idx: 20 |  Loss: (0.0890) |  Loss2: (0.0000) | Acc: (97.00%) (2615/2688)
Epoch: 189 | Batch_idx: 30 |  Loss: (0.0800) |  Loss2: (0.0000) | Acc: (97.00%) (3871/3968)
Epoch: 189 | Batch_idx: 40 |  Loss: (0.0766) |  Loss2: (0.0000) | Acc: (97.00%) (5128/5248)
Epoch: 189 | Batch_idx: 50 |  Loss: (0.0766) |  Loss2: (0.0000) | Acc: (97.00%) (6379/6528)
Epoch: 189 | Batch_idx: 60 |  Loss: (0.0766) |  Loss2: (0.0000) | Acc: (97.00%) (7628/7808)
Epoch: 189 | Batch_idx: 70 |  Loss: (0.0788) |  Loss2: (0.0000) | Acc: (97.00%) (8867/9088)
Epoch: 189 | Batch_idx: 80 |  Loss: (0.0786) |  Loss2: (0.0000) | Acc: (97.00%) (10110/10368)
Epoch: 189 | Batch_idx: 90 |  Loss: (0.0796) |  Loss2: (0.0000) | Acc: (97.00%) (11348/11648)
Epoch: 189 | Batch_idx: 100 |  Loss: (0.0801) |  Loss2: (0.0000) | Acc: (97.00%) (12593/12928)
Epoch: 189 | Batch_idx: 110 |  Loss: (0.0806) |  Loss2: (0.0000) | Acc: (97.00%) (13831/14208)
Epoch: 189 | Batch_idx: 120 |  Loss: (0.0810) |  Loss2: (0.0000) | Acc: (97.00%) (15071/15488)
Epoch: 189 | Batch_idx: 130 |  Loss: (0.0820) |  Loss2: (0.0000) | Acc: (97.00%) (16309/16768)
Epoch: 189 | Batch_idx: 140 |  Loss: (0.0819) |  Loss2: (0.0000) | Acc: (97.00%) (17552/18048)
Epoch: 189 | Batch_idx: 150 |  Loss: (0.0820) |  Loss2: (0.0000) | Acc: (97.00%) (18794/19328)
Epoch: 189 | Batch_idx: 160 |  Loss: (0.0827) |  Loss2: (0.0000) | Acc: (97.00%) (20027/20608)
Epoch: 189 | Batch_idx: 170 |  Loss: (0.0834) |  Loss2: (0.0000) | Acc: (97.00%) (21267/21888)
Epoch: 189 | Batch_idx: 180 |  Loss: (0.0840) |  Loss2: (0.0000) | Acc: (97.00%) (22508/23168)
Epoch: 189 | Batch_idx: 190 |  Loss: (0.0847) |  Loss2: (0.0000) | Acc: (97.00%) (23748/24448)
Epoch: 189 | Batch_idx: 200 |  Loss: (0.0850) |  Loss2: (0.0000) | Acc: (97.00%) (24992/25728)
Epoch: 189 | Batch_idx: 210 |  Loss: (0.0847) |  Loss2: (0.0000) | Acc: (97.00%) (26242/27008)
Epoch: 189 | Batch_idx: 220 |  Loss: (0.0848) |  Loss2: (0.0000) | Acc: (97.00%) (27489/28288)
Epoch: 189 | Batch_idx: 230 |  Loss: (0.0843) |  Loss2: (0.0000) | Acc: (97.00%) (28737/29568)
Epoch: 189 | Batch_idx: 240 |  Loss: (0.0842) |  Loss2: (0.0000) | Acc: (97.00%) (29986/30848)
Epoch: 189 | Batch_idx: 250 |  Loss: (0.0837) |  Loss2: (0.0000) | Acc: (97.00%) (31235/32128)
Epoch: 189 | Batch_idx: 260 |  Loss: (0.0837) |  Loss2: (0.0000) | Acc: (97.00%) (32478/33408)
Epoch: 189 | Batch_idx: 270 |  Loss: (0.0835) |  Loss2: (0.0000) | Acc: (97.00%) (33723/34688)
Epoch: 189 | Batch_idx: 280 |  Loss: (0.0834) |  Loss2: (0.0000) | Acc: (97.00%) (34964/35968)
Epoch: 189 | Batch_idx: 290 |  Loss: (0.0834) |  Loss2: (0.0000) | Acc: (97.00%) (36205/37248)
Epoch: 189 | Batch_idx: 300 |  Loss: (0.0835) |  Loss2: (0.0000) | Acc: (97.00%) (37445/38528)
Epoch: 189 | Batch_idx: 310 |  Loss: (0.0835) |  Loss2: (0.0000) | Acc: (97.00%) (38689/39808)
Epoch: 189 | Batch_idx: 320 |  Loss: (0.0834) |  Loss2: (0.0000) | Acc: (97.00%) (39941/41088)
Epoch: 189 | Batch_idx: 330 |  Loss: (0.0835) |  Loss2: (0.0000) | Acc: (97.00%) (41183/42368)
Epoch: 189 | Batch_idx: 340 |  Loss: (0.0832) |  Loss2: (0.0000) | Acc: (97.00%) (42425/43648)
Epoch: 189 | Batch_idx: 350 |  Loss: (0.0835) |  Loss2: (0.0000) | Acc: (97.00%) (43662/44928)
Epoch: 189 | Batch_idx: 360 |  Loss: (0.0832) |  Loss2: (0.0000) | Acc: (97.00%) (44907/46208)
Epoch: 189 | Batch_idx: 370 |  Loss: (0.0831) |  Loss2: (0.0000) | Acc: (97.00%) (46157/47488)
Epoch: 189 | Batch_idx: 380 |  Loss: (0.0831) |  Loss2: (0.0000) | Acc: (97.00%) (47403/48768)
Epoch: 189 | Batch_idx: 390 |  Loss: (0.0828) |  Loss2: (0.0000) | Acc: (97.00%) (48603/50000)
# TEST : Loss: (0.3734) | Acc: (89.00%) (8913/10000)
percent tensor([0.5119, 0.5122, 0.5141, 0.5164, 0.5142, 0.5181, 0.5138, 0.5164, 0.5122,
        0.5121, 0.5109, 0.5123, 0.5106, 0.5150, 0.5137, 0.5136],
       device='cuda:0') torch.Size([16])
percent tensor([0.5246, 0.5327, 0.5205, 0.5165, 0.5170, 0.5363, 0.5249, 0.5105, 0.5207,
        0.5273, 0.5276, 0.5240, 0.5331, 0.5222, 0.5305, 0.5321],
       device='cuda:0') torch.Size([16])
percent tensor([0.5966, 0.5710, 0.6400, 0.6741, 0.6513, 0.6119, 0.6154, 0.6446, 0.6577,
        0.6092, 0.6502, 0.6074, 0.5181, 0.6913, 0.5899, 0.6103],
       device='cuda:0') torch.Size([16])
percent tensor([0.6651, 0.6604, 0.6537, 0.6509, 0.6563, 0.6602, 0.6682, 0.6554, 0.6591,
        0.6688, 0.6652, 0.6625, 0.6616, 0.6606, 0.6630, 0.6741],
       device='cuda:0') torch.Size([16])
percent tensor([0.6564, 0.6148, 0.6629, 0.6703, 0.6689, 0.7981, 0.6213, 0.6181, 0.6398,
        0.6619, 0.5674, 0.5979, 0.6265, 0.6429, 0.6244, 0.7422],
       device='cuda:0') torch.Size([16])
percent tensor([0.5989, 0.6909, 0.6390, 0.6706, 0.6265, 0.7146, 0.6624, 0.4679, 0.7132,
        0.6466, 0.7506, 0.6505, 0.7276, 0.7318, 0.5347, 0.6047],
       device='cuda:0') torch.Size([16])
percent tensor([0.5732, 0.6368, 0.7306, 0.7069, 0.7518, 0.6500, 0.6752, 0.7248, 0.6074,
        0.6541, 0.6244, 0.6191, 0.5785, 0.5625, 0.6488, 0.5729],
       device='cuda:0') torch.Size([16])
percent tensor([0.9998, 0.9998, 0.9998, 0.9999, 0.9995, 0.9990, 0.9996, 0.9995, 0.9998,
        0.9998, 0.9999, 0.9997, 0.9999, 0.9994, 0.9993, 0.9995],
       device='cuda:0') torch.Size([16])
Epoch: 190 | Batch_idx: 0 |  Loss: (0.0945) |  Loss2: (0.0000) | Acc: (96.00%) (124/128)
Epoch: 190 | Batch_idx: 10 |  Loss: (0.0858) |  Loss2: (0.0000) | Acc: (96.00%) (1365/1408)
Epoch: 190 | Batch_idx: 20 |  Loss: (0.0837) |  Loss2: (0.0000) | Acc: (97.00%) (2610/2688)
Epoch: 190 | Batch_idx: 30 |  Loss: (0.0806) |  Loss2: (0.0000) | Acc: (97.00%) (3860/3968)
Epoch: 190 | Batch_idx: 40 |  Loss: (0.0775) |  Loss2: (0.0000) | Acc: (97.00%) (5105/5248)
Epoch: 190 | Batch_idx: 50 |  Loss: (0.0801) |  Loss2: (0.0000) | Acc: (97.00%) (6347/6528)
Epoch: 190 | Batch_idx: 60 |  Loss: (0.0802) |  Loss2: (0.0000) | Acc: (97.00%) (7586/7808)
Epoch: 190 | Batch_idx: 70 |  Loss: (0.0811) |  Loss2: (0.0000) | Acc: (97.00%) (8833/9088)
Epoch: 190 | Batch_idx: 80 |  Loss: (0.0802) |  Loss2: (0.0000) | Acc: (97.00%) (10083/10368)
Epoch: 190 | Batch_idx: 90 |  Loss: (0.0829) |  Loss2: (0.0000) | Acc: (97.00%) (11315/11648)
Epoch: 190 | Batch_idx: 100 |  Loss: (0.0825) |  Loss2: (0.0000) | Acc: (97.00%) (12560/12928)
Epoch: 190 | Batch_idx: 110 |  Loss: (0.0827) |  Loss2: (0.0000) | Acc: (97.00%) (13811/14208)
Epoch: 190 | Batch_idx: 120 |  Loss: (0.0810) |  Loss2: (0.0000) | Acc: (97.00%) (15067/15488)
Epoch: 190 | Batch_idx: 130 |  Loss: (0.0810) |  Loss2: (0.0000) | Acc: (97.00%) (16316/16768)
Epoch: 190 | Batch_idx: 140 |  Loss: (0.0820) |  Loss2: (0.0000) | Acc: (97.00%) (17556/18048)
Epoch: 190 | Batch_idx: 150 |  Loss: (0.0833) |  Loss2: (0.0000) | Acc: (97.00%) (18787/19328)
Epoch: 190 | Batch_idx: 160 |  Loss: (0.0825) |  Loss2: (0.0000) | Acc: (97.00%) (20033/20608)
Epoch: 190 | Batch_idx: 170 |  Loss: (0.0821) |  Loss2: (0.0000) | Acc: (97.00%) (21284/21888)
Epoch: 190 | Batch_idx: 180 |  Loss: (0.0822) |  Loss2: (0.0000) | Acc: (97.00%) (22529/23168)
Epoch: 190 | Batch_idx: 190 |  Loss: (0.0827) |  Loss2: (0.0000) | Acc: (97.00%) (23768/24448)
Epoch: 190 | Batch_idx: 200 |  Loss: (0.0826) |  Loss2: (0.0000) | Acc: (97.00%) (25014/25728)
Epoch: 190 | Batch_idx: 210 |  Loss: (0.0830) |  Loss2: (0.0000) | Acc: (97.00%) (26251/27008)
Epoch: 190 | Batch_idx: 220 |  Loss: (0.0826) |  Loss2: (0.0000) | Acc: (97.00%) (27497/28288)
Epoch: 190 | Batch_idx: 230 |  Loss: (0.0829) |  Loss2: (0.0000) | Acc: (97.00%) (28734/29568)
Epoch: 190 | Batch_idx: 240 |  Loss: (0.0827) |  Loss2: (0.0000) | Acc: (97.00%) (29986/30848)
Epoch: 190 | Batch_idx: 250 |  Loss: (0.0832) |  Loss2: (0.0000) | Acc: (97.00%) (31231/32128)
Epoch: 190 | Batch_idx: 260 |  Loss: (0.0830) |  Loss2: (0.0000) | Acc: (97.00%) (32482/33408)
Epoch: 190 | Batch_idx: 270 |  Loss: (0.0829) |  Loss2: (0.0000) | Acc: (97.00%) (33727/34688)
Epoch: 190 | Batch_idx: 280 |  Loss: (0.0832) |  Loss2: (0.0000) | Acc: (97.00%) (34972/35968)
Epoch: 190 | Batch_idx: 290 |  Loss: (0.0829) |  Loss2: (0.0000) | Acc: (97.00%) (36214/37248)
Epoch: 190 | Batch_idx: 300 |  Loss: (0.0825) |  Loss2: (0.0000) | Acc: (97.00%) (37474/38528)
Epoch: 190 | Batch_idx: 310 |  Loss: (0.0824) |  Loss2: (0.0000) | Acc: (97.00%) (38726/39808)
Epoch: 190 | Batch_idx: 320 |  Loss: (0.0823) |  Loss2: (0.0000) | Acc: (97.00%) (39966/41088)
Epoch: 190 | Batch_idx: 330 |  Loss: (0.0820) |  Loss2: (0.0000) | Acc: (97.00%) (41222/42368)
Epoch: 190 | Batch_idx: 340 |  Loss: (0.0817) |  Loss2: (0.0000) | Acc: (97.00%) (42472/43648)
Epoch: 190 | Batch_idx: 350 |  Loss: (0.0816) |  Loss2: (0.0000) | Acc: (97.00%) (43717/44928)
Epoch: 190 | Batch_idx: 360 |  Loss: (0.0816) |  Loss2: (0.0000) | Acc: (97.00%) (44964/46208)
Epoch: 190 | Batch_idx: 370 |  Loss: (0.0820) |  Loss2: (0.0000) | Acc: (97.00%) (46202/47488)
Epoch: 190 | Batch_idx: 380 |  Loss: (0.0821) |  Loss2: (0.0000) | Acc: (97.00%) (47445/48768)
Epoch: 190 | Batch_idx: 390 |  Loss: (0.0820) |  Loss2: (0.0000) | Acc: (97.00%) (48649/50000)
=> saving checkpoint 'drive/app/torch/save_Schedule/checkpoint_190.pth.tar'
# TEST : Loss: (0.3692) | Acc: (89.00%) (8928/10000)
percent tensor([0.5117, 0.5120, 0.5139, 0.5162, 0.5140, 0.5183, 0.5135, 0.5161, 0.5120,
        0.5118, 0.5107, 0.5121, 0.5103, 0.5147, 0.5137, 0.5134],
       device='cuda:0') torch.Size([16])
percent tensor([0.5254, 0.5336, 0.5210, 0.5172, 0.5177, 0.5370, 0.5259, 0.5113, 0.5217,
        0.5283, 0.5288, 0.5248, 0.5339, 0.5233, 0.5312, 0.5330],
       device='cuda:0') torch.Size([16])
percent tensor([0.5886, 0.5646, 0.6332, 0.6674, 0.6425, 0.6040, 0.6076, 0.6359, 0.6510,
        0.6037, 0.6439, 0.6021, 0.5134, 0.6845, 0.5807, 0.6036],
       device='cuda:0') torch.Size([16])
percent tensor([0.6630, 0.6594, 0.6523, 0.6491, 0.6541, 0.6572, 0.6665, 0.6535, 0.6575,
        0.6677, 0.6640, 0.6610, 0.6602, 0.6591, 0.6609, 0.6718],
       device='cuda:0') torch.Size([16])
percent tensor([0.6676, 0.6221, 0.6741, 0.6810, 0.6803, 0.8027, 0.6319, 0.6328, 0.6493,
        0.6684, 0.5749, 0.6076, 0.6322, 0.6500, 0.6360, 0.7483],
       device='cuda:0') torch.Size([16])
percent tensor([0.6121, 0.7049, 0.6461, 0.6789, 0.6353, 0.7250, 0.6738, 0.4705, 0.7273,
        0.6599, 0.7632, 0.6607, 0.7427, 0.7461, 0.5459, 0.6193],
       device='cuda:0') torch.Size([16])
percent tensor([0.5803, 0.6442, 0.7330, 0.7100, 0.7539, 0.6590, 0.6823, 0.7249, 0.6160,
        0.6607, 0.6299, 0.6247, 0.5912, 0.5673, 0.6543, 0.5799],
       device='cuda:0') torch.Size([16])
percent tensor([0.9998, 0.9998, 0.9998, 0.9999, 0.9995, 0.9990, 0.9996, 0.9996, 0.9998,
        0.9998, 0.9999, 0.9997, 0.9999, 0.9994, 0.9993, 0.9996],
       device='cuda:0') torch.Size([16])
Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 3, 3, 3]) tensor(180.9035, device='cuda:0')
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(830.2584, device='cuda:0')
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(830.2834, device='cuda:0')
Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([128, 64, 3, 3]) tensor(1511.4017, device='cuda:0')
Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([128, 64, 1, 1]) tensor(479.6805, device='cuda:0')
Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([128, 128, 3, 3]) tensor(2287.9197, device='cuda:0')
Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([256, 128, 3, 3]) tensor(4251.0283, device='cuda:0')
Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([256, 128, 1, 1]) tensor(1350.0254, device='cuda:0')
Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([256, 256, 3, 3]) tensor(6264.0293, device='cuda:0')
Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([512, 256, 3, 3]) tensor(11550.5391, device='cuda:0')
Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([512, 256, 1, 1]) tensor(3798.7908, device='cuda:0')
Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([512, 512, 3, 3]) tensor(16059.3223, device='cuda:0')
Epoch: 191 | Batch_idx: 0 |  Loss: (0.0678) |  Loss2: (0.0000) | Acc: (98.00%) (126/128)
Epoch: 191 | Batch_idx: 10 |  Loss: (0.0800) |  Loss2: (0.0000) | Acc: (97.00%) (1373/1408)
Epoch: 191 | Batch_idx: 20 |  Loss: (0.0785) |  Loss2: (0.0000) | Acc: (97.00%) (2617/2688)
Epoch: 191 | Batch_idx: 30 |  Loss: (0.0790) |  Loss2: (0.0000) | Acc: (97.00%) (3867/3968)
Epoch: 191 | Batch_idx: 40 |  Loss: (0.0787) |  Loss2: (0.0000) | Acc: (97.00%) (5115/5248)
Epoch: 191 | Batch_idx: 50 |  Loss: (0.0800) |  Loss2: (0.0000) | Acc: (97.00%) (6358/6528)
Epoch: 191 | Batch_idx: 60 |  Loss: (0.0808) |  Loss2: (0.0000) | Acc: (97.00%) (7602/7808)
Epoch: 191 | Batch_idx: 70 |  Loss: (0.0803) |  Loss2: (0.0000) | Acc: (97.00%) (8846/9088)
Epoch: 191 | Batch_idx: 80 |  Loss: (0.0785) |  Loss2: (0.0000) | Acc: (97.00%) (10099/10368)
Epoch: 191 | Batch_idx: 90 |  Loss: (0.0781) |  Loss2: (0.0000) | Acc: (97.00%) (11347/11648)
Epoch: 191 | Batch_idx: 100 |  Loss: (0.0770) |  Loss2: (0.0000) | Acc: (97.00%) (12599/12928)
Epoch: 191 | Batch_idx: 110 |  Loss: (0.0772) |  Loss2: (0.0000) | Acc: (97.00%) (13847/14208)
Epoch: 191 | Batch_idx: 120 |  Loss: (0.0774) |  Loss2: (0.0000) | Acc: (97.00%) (15090/15488)
Epoch: 191 | Batch_idx: 130 |  Loss: (0.0772) |  Loss2: (0.0000) | Acc: (97.00%) (16337/16768)
Epoch: 191 | Batch_idx: 140 |  Loss: (0.0774) |  Loss2: (0.0000) | Acc: (97.00%) (17583/18048)
Epoch: 191 | Batch_idx: 150 |  Loss: (0.0772) |  Loss2: (0.0000) | Acc: (97.00%) (18829/19328)
Epoch: 191 | Batch_idx: 160 |  Loss: (0.0769) |  Loss2: (0.0000) | Acc: (97.00%) (20081/20608)
Epoch: 191 | Batch_idx: 170 |  Loss: (0.0765) |  Loss2: (0.0000) | Acc: (97.00%) (21340/21888)
Epoch: 191 | Batch_idx: 180 |  Loss: (0.0772) |  Loss2: (0.0000) | Acc: (97.00%) (22582/23168)
Epoch: 191 | Batch_idx: 190 |  Loss: (0.0776) |  Loss2: (0.0000) | Acc: (97.00%) (23829/24448)
Epoch: 191 | Batch_idx: 200 |  Loss: (0.0782) |  Loss2: (0.0000) | Acc: (97.00%) (25064/25728)
Epoch: 191 | Batch_idx: 210 |  Loss: (0.0782) |  Loss2: (0.0000) | Acc: (97.00%) (26309/27008)
Epoch: 191 | Batch_idx: 220 |  Loss: (0.0786) |  Loss2: (0.0000) | Acc: (97.00%) (27553/28288)
Epoch: 191 | Batch_idx: 230 |  Loss: (0.0785) |  Loss2: (0.0000) | Acc: (97.00%) (28801/29568)
Epoch: 191 | Batch_idx: 240 |  Loss: (0.0790) |  Loss2: (0.0000) | Acc: (97.00%) (30040/30848)
Epoch: 191 | Batch_idx: 250 |  Loss: (0.0790) |  Loss2: (0.0000) | Acc: (97.00%) (31290/32128)
Epoch: 191 | Batch_idx: 260 |  Loss: (0.0785) |  Loss2: (0.0000) | Acc: (97.00%) (32540/33408)
Epoch: 191 | Batch_idx: 270 |  Loss: (0.0788) |  Loss2: (0.0000) | Acc: (97.00%) (33787/34688)
Epoch: 191 | Batch_idx: 280 |  Loss: (0.0788) |  Loss2: (0.0000) | Acc: (97.00%) (35028/35968)
Epoch: 191 | Batch_idx: 290 |  Loss: (0.0786) |  Loss2: (0.0000) | Acc: (97.00%) (36281/37248)
Epoch: 191 | Batch_idx: 300 |  Loss: (0.0790) |  Loss2: (0.0000) | Acc: (97.00%) (37519/38528)
Epoch: 191 | Batch_idx: 310 |  Loss: (0.0792) |  Loss2: (0.0000) | Acc: (97.00%) (38765/39808)
Epoch: 191 | Batch_idx: 320 |  Loss: (0.0790) |  Loss2: (0.0000) | Acc: (97.00%) (40014/41088)
Epoch: 191 | Batch_idx: 330 |  Loss: (0.0792) |  Loss2: (0.0000) | Acc: (97.00%) (41257/42368)
Epoch: 191 | Batch_idx: 340 |  Loss: (0.0791) |  Loss2: (0.0000) | Acc: (97.00%) (42502/43648)
Epoch: 191 | Batch_idx: 350 |  Loss: (0.0786) |  Loss2: (0.0000) | Acc: (97.00%) (43756/44928)
Epoch: 191 | Batch_idx: 360 |  Loss: (0.0789) |  Loss2: (0.0000) | Acc: (97.00%) (44995/46208)
Epoch: 191 | Batch_idx: 370 |  Loss: (0.0792) |  Loss2: (0.0000) | Acc: (97.00%) (46242/47488)
Epoch: 191 | Batch_idx: 380 |  Loss: (0.0789) |  Loss2: (0.0000) | Acc: (97.00%) (47494/48768)
Epoch: 191 | Batch_idx: 390 |  Loss: (0.0791) |  Loss2: (0.0000) | Acc: (97.00%) (48681/50000)
# TEST : Loss: (0.3653) | Acc: (89.00%) (8939/10000)
percent tensor([0.5126, 0.5130, 0.5147, 0.5169, 0.5149, 0.5190, 0.5146, 0.5170, 0.5130,
        0.5127, 0.5116, 0.5130, 0.5113, 0.5157, 0.5145, 0.5143],
       device='cuda:0') torch.Size([16])
percent tensor([0.5251, 0.5336, 0.5203, 0.5161, 0.5168, 0.5376, 0.5255, 0.5103, 0.5215,
        0.5281, 0.5290, 0.5244, 0.5339, 0.5235, 0.5310, 0.5328],
       device='cuda:0') torch.Size([16])
percent tensor([0.6024, 0.5745, 0.6468, 0.6765, 0.6556, 0.6188, 0.6180, 0.6489, 0.6610,
        0.6144, 0.6524, 0.6146, 0.5250, 0.6929, 0.5939, 0.6164],
       device='cuda:0') torch.Size([16])
percent tensor([0.6632, 0.6594, 0.6511, 0.6474, 0.6530, 0.6573, 0.6664, 0.6527, 0.6571,
        0.6678, 0.6645, 0.6610, 0.6605, 0.6588, 0.6610, 0.6715],
       device='cuda:0') torch.Size([16])
percent tensor([0.6627, 0.6213, 0.6653, 0.6742, 0.6742, 0.7986, 0.6293, 0.6291, 0.6496,
        0.6704, 0.5763, 0.6036, 0.6285, 0.6548, 0.6296, 0.7472],
       device='cuda:0') torch.Size([16])
percent tensor([0.6057, 0.6986, 0.6415, 0.6729, 0.6282, 0.7187, 0.6672, 0.4611, 0.7216,
        0.6547, 0.7608, 0.6547, 0.7364, 0.7406, 0.5377, 0.6096],
       device='cuda:0') torch.Size([16])
percent tensor([0.5729, 0.6368, 0.7305, 0.7034, 0.7462, 0.6596, 0.6741, 0.7166, 0.6092,
        0.6555, 0.6198, 0.6195, 0.5876, 0.5537, 0.6478, 0.5699],
       device='cuda:0') torch.Size([16])
percent tensor([0.9998, 0.9998, 0.9998, 0.9999, 0.9995, 0.9990, 0.9996, 0.9996, 0.9998,
        0.9998, 0.9999, 0.9997, 0.9999, 0.9994, 0.9993, 0.9995],
       device='cuda:0') torch.Size([16])
True Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=128, out_features=16, bias=False)
False Linear(in_features=16, out_features=2, bias=False)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=128, out_features=16, bias=False)
False Linear(in_features=16, out_features=2, bias=False)
True Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=256, out_features=32, bias=False)
False Linear(in_features=32, out_features=2, bias=False)
True Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=256, out_features=32, bias=False)
False Linear(in_features=32, out_features=2, bias=False)
True Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=512, out_features=64, bias=False)
False Linear(in_features=64, out_features=2, bias=False)
True Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=512, out_features=64, bias=False)
False Linear(in_features=64, out_features=2, bias=False)
True Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1024, out_features=128, bias=False)
False Linear(in_features=128, out_features=2, bias=False)
True Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1024, out_features=128, bias=False)
False Linear(in_features=128, out_features=2, bias=False)
True Linear(in_features=512, out_features=10, bias=True)
Epoch: 192 | Batch_idx: 0 |  Loss: (0.0493) |  Loss2: (0.0000) | Acc: (99.00%) (127/128)
Epoch: 192 | Batch_idx: 10 |  Loss: (0.0711) |  Loss2: (0.0000) | Acc: (97.00%) (1377/1408)
Epoch: 192 | Batch_idx: 20 |  Loss: (0.0812) |  Loss2: (0.0000) | Acc: (97.00%) (2620/2688)
Epoch: 192 | Batch_idx: 30 |  Loss: (0.0803) |  Loss2: (0.0000) | Acc: (97.00%) (3867/3968)
Epoch: 192 | Batch_idx: 40 |  Loss: (0.0795) |  Loss2: (0.0000) | Acc: (97.00%) (5115/5248)
Epoch: 192 | Batch_idx: 50 |  Loss: (0.0799) |  Loss2: (0.0000) | Acc: (97.00%) (6357/6528)
Epoch: 192 | Batch_idx: 60 |  Loss: (0.0760) |  Loss2: (0.0000) | Acc: (97.00%) (7619/7808)
Epoch: 192 | Batch_idx: 70 |  Loss: (0.0759) |  Loss2: (0.0000) | Acc: (97.00%) (8866/9088)
Epoch: 192 | Batch_idx: 80 |  Loss: (0.0755) |  Loss2: (0.0000) | Acc: (97.00%) (10119/10368)
Epoch: 192 | Batch_idx: 90 |  Loss: (0.0764) |  Loss2: (0.0000) | Acc: (97.00%) (11367/11648)
Epoch: 192 | Batch_idx: 100 |  Loss: (0.0777) |  Loss2: (0.0000) | Acc: (97.00%) (12615/12928)
Epoch: 192 | Batch_idx: 110 |  Loss: (0.0780) |  Loss2: (0.0000) | Acc: (97.00%) (13857/14208)
Epoch: 192 | Batch_idx: 120 |  Loss: (0.0800) |  Loss2: (0.0000) | Acc: (97.00%) (15090/15488)
Epoch: 192 | Batch_idx: 130 |  Loss: (0.0805) |  Loss2: (0.0000) | Acc: (97.00%) (16331/16768)
Epoch: 192 | Batch_idx: 140 |  Loss: (0.0823) |  Loss2: (0.0000) | Acc: (97.00%) (17568/18048)
Epoch: 192 | Batch_idx: 150 |  Loss: (0.0823) |  Loss2: (0.0000) | Acc: (97.00%) (18815/19328)
Epoch: 192 | Batch_idx: 160 |  Loss: (0.0821) |  Loss2: (0.0000) | Acc: (97.00%) (20061/20608)
Epoch: 192 | Batch_idx: 170 |  Loss: (0.0831) |  Loss2: (0.0000) | Acc: (97.00%) (21300/21888)
Epoch: 192 | Batch_idx: 180 |  Loss: (0.0827) |  Loss2: (0.0000) | Acc: (97.00%) (22548/23168)
Epoch: 192 | Batch_idx: 190 |  Loss: (0.0840) |  Loss2: (0.0000) | Acc: (97.00%) (23782/24448)
Epoch: 192 | Batch_idx: 200 |  Loss: (0.0836) |  Loss2: (0.0000) | Acc: (97.00%) (25033/25728)
Epoch: 192 | Batch_idx: 210 |  Loss: (0.0840) |  Loss2: (0.0000) | Acc: (97.00%) (26273/27008)
Epoch: 192 | Batch_idx: 220 |  Loss: (0.0838) |  Loss2: (0.0000) | Acc: (97.00%) (27521/28288)
Epoch: 192 | Batch_idx: 230 |  Loss: (0.0843) |  Loss2: (0.0000) | Acc: (97.00%) (28756/29568)
Epoch: 192 | Batch_idx: 240 |  Loss: (0.0844) |  Loss2: (0.0000) | Acc: (97.00%) (29996/30848)
Epoch: 192 | Batch_idx: 250 |  Loss: (0.0853) |  Loss2: (0.0000) | Acc: (97.00%) (31223/32128)
Epoch: 192 | Batch_idx: 260 |  Loss: (0.0854) |  Loss2: (0.0000) | Acc: (97.00%) (32464/33408)
Epoch: 192 | Batch_idx: 270 |  Loss: (0.0864) |  Loss2: (0.0000) | Acc: (97.00%) (33689/34688)
Epoch: 192 | Batch_idx: 280 |  Loss: (0.0868) |  Loss2: (0.0000) | Acc: (97.00%) (34927/35968)
Epoch: 192 | Batch_idx: 290 |  Loss: (0.0871) |  Loss2: (0.0000) | Acc: (97.00%) (36166/37248)
Epoch: 192 | Batch_idx: 300 |  Loss: (0.0873) |  Loss2: (0.0000) | Acc: (97.00%) (37405/38528)
Epoch: 192 | Batch_idx: 310 |  Loss: (0.0875) |  Loss2: (0.0000) | Acc: (97.00%) (38643/39808)
Epoch: 192 | Batch_idx: 320 |  Loss: (0.0874) |  Loss2: (0.0000) | Acc: (97.00%) (39888/41088)
Epoch: 192 | Batch_idx: 330 |  Loss: (0.0876) |  Loss2: (0.0000) | Acc: (97.00%) (41129/42368)
Epoch: 192 | Batch_idx: 340 |  Loss: (0.0881) |  Loss2: (0.0000) | Acc: (97.00%) (42357/43648)
Epoch: 192 | Batch_idx: 350 |  Loss: (0.0876) |  Loss2: (0.0000) | Acc: (97.00%) (43609/44928)
Epoch: 192 | Batch_idx: 360 |  Loss: (0.0878) |  Loss2: (0.0000) | Acc: (97.00%) (44846/46208)
Epoch: 192 | Batch_idx: 370 |  Loss: (0.0877) |  Loss2: (0.0000) | Acc: (97.00%) (46086/47488)
Epoch: 192 | Batch_idx: 380 |  Loss: (0.0878) |  Loss2: (0.0000) | Acc: (97.00%) (47329/48768)
Epoch: 192 | Batch_idx: 390 |  Loss: (0.0876) |  Loss2: (0.0000) | Acc: (97.00%) (48529/50000)
# TEST : Loss: (0.4060) | Acc: (88.00%) (8856/10000)
percent tensor([0.5131, 0.5119, 0.5154, 0.5165, 0.5158, 0.5200, 0.5139, 0.5161, 0.5135,
        0.5121, 0.5117, 0.5132, 0.5116, 0.5141, 0.5144, 0.5140],
       device='cuda:0') torch.Size([16])
percent tensor([0.5246, 0.5340, 0.5183, 0.5156, 0.5139, 0.5341, 0.5250, 0.5106, 0.5228,
        0.5277, 0.5297, 0.5222, 0.5349, 0.5251, 0.5296, 0.5321],
       device='cuda:0') torch.Size([16])
percent tensor([0.6092, 0.5595, 0.6636, 0.6780, 0.6710, 0.6396, 0.6190, 0.6516, 0.6610,
        0.6160, 0.6453, 0.6403, 0.5262, 0.6786, 0.5946, 0.6148],
       device='cuda:0') torch.Size([16])
percent tensor([0.6604, 0.6584, 0.6488, 0.6453, 0.6482, 0.6550, 0.6622, 0.6510, 0.6575,
        0.6661, 0.6626, 0.6585, 0.6601, 0.6557, 0.6589, 0.6709],
       device='cuda:0') torch.Size([16])
percent tensor([0.6602, 0.6114, 0.6532, 0.6707, 0.6813, 0.7766, 0.6105, 0.6240, 0.6420,
        0.6501, 0.5704, 0.5939, 0.6268, 0.6476, 0.6115, 0.7444],
       device='cuda:0') torch.Size([16])
percent tensor([0.5924, 0.6939, 0.6277, 0.6683, 0.6345, 0.7131, 0.6508, 0.4785, 0.6959,
        0.6520, 0.7492, 0.6512, 0.7351, 0.7233, 0.5179, 0.6187],
       device='cuda:0') torch.Size([16])
percent tensor([0.5721, 0.6361, 0.7120, 0.7209, 0.7516, 0.6839, 0.6743, 0.7018, 0.6074,
        0.6749, 0.6260, 0.6672, 0.5766, 0.5824, 0.6337, 0.5708],
       device='cuda:0') torch.Size([16])
percent tensor([0.9998, 0.9999, 0.9997, 0.9999, 0.9992, 0.9989, 0.9997, 0.9996, 0.9997,
        0.9999, 0.9998, 0.9999, 0.9999, 0.9996, 0.9993, 0.9994],
       device='cuda:0') torch.Size([16])
Epoch: 193 | Batch_idx: 0 |  Loss: (0.0827) |  Loss2: (0.0000) | Acc: (97.00%) (125/128)
Epoch: 193 | Batch_idx: 10 |  Loss: (0.0768) |  Loss2: (0.0000) | Acc: (97.00%) (1372/1408)
Epoch: 193 | Batch_idx: 20 |  Loss: (0.0832) |  Loss2: (0.0000) | Acc: (97.00%) (2611/2688)
Epoch: 193 | Batch_idx: 30 |  Loss: (0.0786) |  Loss2: (0.0000) | Acc: (97.00%) (3863/3968)
Epoch: 193 | Batch_idx: 40 |  Loss: (0.0788) |  Loss2: (0.0000) | Acc: (97.00%) (5113/5248)
Epoch: 193 | Batch_idx: 50 |  Loss: (0.0794) |  Loss2: (0.0000) | Acc: (97.00%) (6359/6528)
Epoch: 193 | Batch_idx: 60 |  Loss: (0.0814) |  Loss2: (0.0000) | Acc: (97.00%) (7600/7808)
Epoch: 193 | Batch_idx: 70 |  Loss: (0.0814) |  Loss2: (0.0000) | Acc: (97.00%) (8845/9088)
Epoch: 193 | Batch_idx: 80 |  Loss: (0.0802) |  Loss2: (0.0000) | Acc: (97.00%) (10100/10368)
Epoch: 193 | Batch_idx: 90 |  Loss: (0.0806) |  Loss2: (0.0000) | Acc: (97.00%) (11348/11648)
Epoch: 193 | Batch_idx: 100 |  Loss: (0.0807) |  Loss2: (0.0000) | Acc: (97.00%) (12587/12928)
Epoch: 193 | Batch_idx: 110 |  Loss: (0.0821) |  Loss2: (0.0000) | Acc: (97.00%) (13826/14208)
Epoch: 193 | Batch_idx: 120 |  Loss: (0.0811) |  Loss2: (0.0000) | Acc: (97.00%) (15074/15488)
Epoch: 193 | Batch_idx: 130 |  Loss: (0.0811) |  Loss2: (0.0000) | Acc: (97.00%) (16326/16768)
Epoch: 193 | Batch_idx: 140 |  Loss: (0.0822) |  Loss2: (0.0000) | Acc: (97.00%) (17563/18048)
Epoch: 193 | Batch_idx: 150 |  Loss: (0.0826) |  Loss2: (0.0000) | Acc: (97.00%) (18807/19328)
Epoch: 193 | Batch_idx: 160 |  Loss: (0.0831) |  Loss2: (0.0000) | Acc: (97.00%) (20048/20608)
Epoch: 193 | Batch_idx: 170 |  Loss: (0.0833) |  Loss2: (0.0000) | Acc: (97.00%) (21286/21888)
Epoch: 193 | Batch_idx: 180 |  Loss: (0.0834) |  Loss2: (0.0000) | Acc: (97.00%) (22528/23168)
Epoch: 193 | Batch_idx: 190 |  Loss: (0.0836) |  Loss2: (0.0000) | Acc: (97.00%) (23766/24448)
Epoch: 193 | Batch_idx: 200 |  Loss: (0.0838) |  Loss2: (0.0000) | Acc: (97.00%) (25004/25728)
Epoch: 193 | Batch_idx: 210 |  Loss: (0.0842) |  Loss2: (0.0000) | Acc: (97.00%) (26243/27008)
Epoch: 193 | Batch_idx: 220 |  Loss: (0.0839) |  Loss2: (0.0000) | Acc: (97.00%) (27494/28288)
Epoch: 193 | Batch_idx: 230 |  Loss: (0.0835) |  Loss2: (0.0000) | Acc: (97.00%) (28745/29568)
Epoch: 193 | Batch_idx: 240 |  Loss: (0.0836) |  Loss2: (0.0000) | Acc: (97.00%) (29986/30848)
Epoch: 193 | Batch_idx: 250 |  Loss: (0.0835) |  Loss2: (0.0000) | Acc: (97.00%) (31237/32128)
Epoch: 193 | Batch_idx: 260 |  Loss: (0.0833) |  Loss2: (0.0000) | Acc: (97.00%) (32491/33408)
Epoch: 193 | Batch_idx: 270 |  Loss: (0.0834) |  Loss2: (0.0000) | Acc: (97.00%) (33727/34688)
Epoch: 193 | Batch_idx: 280 |  Loss: (0.0832) |  Loss2: (0.0000) | Acc: (97.00%) (34976/35968)
Epoch: 193 | Batch_idx: 290 |  Loss: (0.0827) |  Loss2: (0.0000) | Acc: (97.00%) (36230/37248)
Epoch: 193 | Batch_idx: 300 |  Loss: (0.0828) |  Loss2: (0.0000) | Acc: (97.00%) (37466/38528)
Epoch: 193 | Batch_idx: 310 |  Loss: (0.0826) |  Loss2: (0.0000) | Acc: (97.00%) (38713/39808)
Epoch: 193 | Batch_idx: 320 |  Loss: (0.0829) |  Loss2: (0.0000) | Acc: (97.00%) (39956/41088)
Epoch: 193 | Batch_idx: 330 |  Loss: (0.0828) |  Loss2: (0.0000) | Acc: (97.00%) (41201/42368)
Epoch: 193 | Batch_idx: 340 |  Loss: (0.0830) |  Loss2: (0.0000) | Acc: (97.00%) (42444/43648)
Epoch: 193 | Batch_idx: 350 |  Loss: (0.0832) |  Loss2: (0.0000) | Acc: (97.00%) (43682/44928)
Epoch: 193 | Batch_idx: 360 |  Loss: (0.0835) |  Loss2: (0.0000) | Acc: (97.00%) (44923/46208)
Epoch: 193 | Batch_idx: 370 |  Loss: (0.0837) |  Loss2: (0.0000) | Acc: (97.00%) (46168/47488)
Epoch: 193 | Batch_idx: 380 |  Loss: (0.0844) |  Loss2: (0.0000) | Acc: (97.00%) (47401/48768)
Epoch: 193 | Batch_idx: 390 |  Loss: (0.0844) |  Loss2: (0.0000) | Acc: (97.00%) (48597/50000)
# TEST : Loss: (0.4167) | Acc: (88.00%) (8834/10000)
percent tensor([0.5134, 0.5128, 0.5148, 0.5166, 0.5154, 0.5200, 0.5145, 0.5166, 0.5142,
        0.5123, 0.5123, 0.5127, 0.5119, 0.5155, 0.5148, 0.5146],
       device='cuda:0') torch.Size([16])
percent tensor([0.5248, 0.5328, 0.5199, 0.5163, 0.5149, 0.5345, 0.5240, 0.5118, 0.5222,
        0.5274, 0.5289, 0.5235, 0.5346, 0.5208, 0.5286, 0.5315],
       device='cuda:0') torch.Size([16])
percent tensor([0.5945, 0.5691, 0.6517, 0.6703, 0.6556, 0.6259, 0.6204, 0.6498, 0.6588,
        0.6121, 0.6483, 0.6297, 0.5248, 0.6977, 0.5914, 0.6090],
       device='cuda:0') torch.Size([16])
percent tensor([0.6611, 0.6575, 0.6495, 0.6467, 0.6499, 0.6543, 0.6634, 0.6508, 0.6596,
        0.6679, 0.6636, 0.6577, 0.6609, 0.6570, 0.6577, 0.6699],
       device='cuda:0') torch.Size([16])
percent tensor([0.6570, 0.6021, 0.6647, 0.6706, 0.6875, 0.7908, 0.6141, 0.6102, 0.6478,
        0.6448, 0.5850, 0.5932, 0.6195, 0.6553, 0.6033, 0.7379],
       device='cuda:0') torch.Size([16])
percent tensor([0.5936, 0.6768, 0.6183, 0.6615, 0.6141, 0.7182, 0.6510, 0.4512, 0.6923,
        0.6555, 0.7519, 0.6585, 0.7427, 0.7285, 0.5226, 0.6110],
       device='cuda:0') torch.Size([16])
percent tensor([0.5706, 0.6274, 0.7036, 0.7060, 0.7256, 0.6680, 0.6763, 0.7027, 0.6076,
        0.6607, 0.6278, 0.6475, 0.5717, 0.5586, 0.6219, 0.5552],
       device='cuda:0') torch.Size([16])
percent tensor([0.9999, 0.9999, 0.9998, 0.9999, 0.9995, 0.9987, 0.9998, 0.9995, 0.9998,
        0.9999, 0.9999, 0.9998, 0.9999, 0.9997, 0.9992, 0.9997],
       device='cuda:0') torch.Size([16])
Epoch: 194 | Batch_idx: 0 |  Loss: (0.0976) |  Loss2: (0.0000) | Acc: (96.00%) (124/128)
Epoch: 194 | Batch_idx: 10 |  Loss: (0.0895) |  Loss2: (0.0000) | Acc: (96.00%) (1362/1408)
Epoch: 194 | Batch_idx: 20 |  Loss: (0.0833) |  Loss2: (0.0000) | Acc: (96.00%) (2607/2688)
Epoch: 194 | Batch_idx: 30 |  Loss: (0.0792) |  Loss2: (0.0000) | Acc: (97.00%) (3856/3968)
Epoch: 194 | Batch_idx: 40 |  Loss: (0.0839) |  Loss2: (0.0000) | Acc: (97.00%) (5095/5248)
Epoch: 194 | Batch_idx: 50 |  Loss: (0.0848) |  Loss2: (0.0000) | Acc: (97.00%) (6344/6528)
Epoch: 194 | Batch_idx: 60 |  Loss: (0.0841) |  Loss2: (0.0000) | Acc: (97.00%) (7590/7808)
Epoch: 194 | Batch_idx: 70 |  Loss: (0.0839) |  Loss2: (0.0000) | Acc: (97.00%) (8833/9088)
Epoch: 194 | Batch_idx: 80 |  Loss: (0.0840) |  Loss2: (0.0000) | Acc: (97.00%) (10075/10368)
Epoch: 194 | Batch_idx: 90 |  Loss: (0.0836) |  Loss2: (0.0000) | Acc: (97.00%) (11318/11648)
Epoch: 194 | Batch_idx: 100 |  Loss: (0.0846) |  Loss2: (0.0000) | Acc: (97.00%) (12562/12928)
Epoch: 194 | Batch_idx: 110 |  Loss: (0.0843) |  Loss2: (0.0000) | Acc: (97.00%) (13808/14208)
Epoch: 194 | Batch_idx: 120 |  Loss: (0.0842) |  Loss2: (0.0000) | Acc: (97.00%) (15051/15488)
Epoch: 194 | Batch_idx: 130 |  Loss: (0.0837) |  Loss2: (0.0000) | Acc: (97.00%) (16295/16768)
Epoch: 194 | Batch_idx: 140 |  Loss: (0.0829) |  Loss2: (0.0000) | Acc: (97.00%) (17547/18048)
Epoch: 194 | Batch_idx: 150 |  Loss: (0.0825) |  Loss2: (0.0000) | Acc: (97.00%) (18796/19328)
Epoch: 194 | Batch_idx: 160 |  Loss: (0.0816) |  Loss2: (0.0000) | Acc: (97.00%) (20042/20608)
Epoch: 194 | Batch_idx: 170 |  Loss: (0.0820) |  Loss2: (0.0000) | Acc: (97.00%) (21281/21888)
Epoch: 194 | Batch_idx: 180 |  Loss: (0.0817) |  Loss2: (0.0000) | Acc: (97.00%) (22522/23168)
Epoch: 194 | Batch_idx: 190 |  Loss: (0.0819) |  Loss2: (0.0000) | Acc: (97.00%) (23764/24448)
Epoch: 194 | Batch_idx: 200 |  Loss: (0.0816) |  Loss2: (0.0000) | Acc: (97.00%) (25007/25728)
Epoch: 194 | Batch_idx: 210 |  Loss: (0.0814) |  Loss2: (0.0000) | Acc: (97.00%) (26251/27008)
Epoch: 194 | Batch_idx: 220 |  Loss: (0.0820) |  Loss2: (0.0000) | Acc: (97.00%) (27491/28288)
Epoch: 194 | Batch_idx: 230 |  Loss: (0.0832) |  Loss2: (0.0000) | Acc: (97.00%) (28716/29568)
Epoch: 194 | Batch_idx: 240 |  Loss: (0.0834) |  Loss2: (0.0000) | Acc: (97.00%) (29958/30848)
Epoch: 194 | Batch_idx: 250 |  Loss: (0.0836) |  Loss2: (0.0000) | Acc: (97.00%) (31202/32128)
Epoch: 194 | Batch_idx: 260 |  Loss: (0.0838) |  Loss2: (0.0000) | Acc: (97.00%) (32445/33408)
Epoch: 194 | Batch_idx: 270 |  Loss: (0.0834) |  Loss2: (0.0000) | Acc: (97.00%) (33689/34688)
Epoch: 194 | Batch_idx: 280 |  Loss: (0.0839) |  Loss2: (0.0000) | Acc: (97.00%) (34934/35968)
Epoch: 194 | Batch_idx: 290 |  Loss: (0.0840) |  Loss2: (0.0000) | Acc: (97.00%) (36173/37248)
Epoch: 194 | Batch_idx: 300 |  Loss: (0.0840) |  Loss2: (0.0000) | Acc: (97.00%) (37416/38528)
Epoch: 194 | Batch_idx: 310 |  Loss: (0.0842) |  Loss2: (0.0000) | Acc: (97.00%) (38656/39808)
Epoch: 194 | Batch_idx: 320 |  Loss: (0.0843) |  Loss2: (0.0000) | Acc: (97.00%) (39895/41088)
Epoch: 194 | Batch_idx: 330 |  Loss: (0.0844) |  Loss2: (0.0000) | Acc: (97.00%) (41136/42368)
Epoch: 194 | Batch_idx: 340 |  Loss: (0.0841) |  Loss2: (0.0000) | Acc: (97.00%) (42386/43648)
Epoch: 194 | Batch_idx: 350 |  Loss: (0.0842) |  Loss2: (0.0000) | Acc: (97.00%) (43629/44928)
Epoch: 194 | Batch_idx: 360 |  Loss: (0.0839) |  Loss2: (0.0000) | Acc: (97.00%) (44879/46208)
Epoch: 194 | Batch_idx: 370 |  Loss: (0.0847) |  Loss2: (0.0000) | Acc: (97.00%) (46107/47488)
Epoch: 194 | Batch_idx: 380 |  Loss: (0.0849) |  Loss2: (0.0000) | Acc: (97.00%) (47347/48768)
Epoch: 194 | Batch_idx: 390 |  Loss: (0.0849) |  Loss2: (0.0000) | Acc: (97.00%) (48544/50000)
# TEST : Loss: (0.4218) | Acc: (88.00%) (8814/10000)
percent tensor([0.5134, 0.5125, 0.5148, 0.5161, 0.5153, 0.5194, 0.5143, 0.5164, 0.5141,
        0.5122, 0.5119, 0.5130, 0.5120, 0.5155, 0.5143, 0.5144],
       device='cuda:0') torch.Size([16])
percent tensor([0.5245, 0.5326, 0.5161, 0.5174, 0.5133, 0.5338, 0.5227, 0.5106, 0.5207,
        0.5266, 0.5287, 0.5212, 0.5341, 0.5223, 0.5288, 0.5316],
       device='cuda:0') torch.Size([16])
percent tensor([0.6027, 0.5706, 0.6589, 0.6737, 0.6639, 0.6407, 0.6281, 0.6508, 0.6669,
        0.6112, 0.6490, 0.6365, 0.5261, 0.7017, 0.6005, 0.6130],
       device='cuda:0') torch.Size([16])
percent tensor([0.6602, 0.6569, 0.6484, 0.6479, 0.6489, 0.6528, 0.6615, 0.6523, 0.6584,
        0.6650, 0.6623, 0.6578, 0.6606, 0.6551, 0.6594, 0.6702],
       device='cuda:0') torch.Size([16])
percent tensor([0.6687, 0.6252, 0.6610, 0.6756, 0.6939, 0.7590, 0.6312, 0.6232, 0.6597,
        0.6595, 0.5892, 0.6122, 0.6449, 0.6696, 0.6129, 0.7336],
       device='cuda:0') torch.Size([16])
percent tensor([0.6083, 0.6979, 0.6430, 0.6632, 0.6352, 0.7083, 0.6732, 0.4966, 0.7125,
        0.6704, 0.7582, 0.6562, 0.7557, 0.7390, 0.5281, 0.6245],
       device='cuda:0') torch.Size([16])
percent tensor([0.5689, 0.6453, 0.7008, 0.7111, 0.7320, 0.6665, 0.6735, 0.7090, 0.6045,
        0.6800, 0.6364, 0.6333, 0.5855, 0.5798, 0.6299, 0.5670],
       device='cuda:0') torch.Size([16])
percent tensor([0.9999, 0.9997, 0.9997, 0.9999, 0.9994, 0.9991, 0.9997, 0.9997, 0.9998,
        0.9999, 0.9999, 0.9997, 0.9999, 0.9996, 0.9993, 0.9997],
       device='cuda:0') torch.Size([16])
Epoch: 195 | Batch_idx: 0 |  Loss: (0.0821) |  Loss2: (0.0000) | Acc: (96.00%) (124/128)
Epoch: 195 | Batch_idx: 10 |  Loss: (0.0795) |  Loss2: (0.0000) | Acc: (97.00%) (1374/1408)
Epoch: 195 | Batch_idx: 20 |  Loss: (0.0888) |  Loss2: (0.0000) | Acc: (97.00%) (2615/2688)
Epoch: 195 | Batch_idx: 30 |  Loss: (0.0859) |  Loss2: (0.0000) | Acc: (97.00%) (3858/3968)
Epoch: 195 | Batch_idx: 40 |  Loss: (0.0819) |  Loss2: (0.0000) | Acc: (97.00%) (5111/5248)
Epoch: 195 | Batch_idx: 50 |  Loss: (0.0805) |  Loss2: (0.0000) | Acc: (97.00%) (6356/6528)
Epoch: 195 | Batch_idx: 60 |  Loss: (0.0807) |  Loss2: (0.0000) | Acc: (97.00%) (7601/7808)
Epoch: 195 | Batch_idx: 70 |  Loss: (0.0815) |  Loss2: (0.0000) | Acc: (97.00%) (8843/9088)
Epoch: 195 | Batch_idx: 80 |  Loss: (0.0804) |  Loss2: (0.0000) | Acc: (97.00%) (10091/10368)
Epoch: 195 | Batch_idx: 90 |  Loss: (0.0788) |  Loss2: (0.0000) | Acc: (97.00%) (11342/11648)
Epoch: 195 | Batch_idx: 100 |  Loss: (0.0775) |  Loss2: (0.0000) | Acc: (97.00%) (12593/12928)
Epoch: 195 | Batch_idx: 110 |  Loss: (0.0772) |  Loss2: (0.0000) | Acc: (97.00%) (13841/14208)
Epoch: 195 | Batch_idx: 120 |  Loss: (0.0782) |  Loss2: (0.0000) | Acc: (97.00%) (15080/15488)
Epoch: 195 | Batch_idx: 130 |  Loss: (0.0776) |  Loss2: (0.0000) | Acc: (97.00%) (16336/16768)
Epoch: 195 | Batch_idx: 140 |  Loss: (0.0795) |  Loss2: (0.0000) | Acc: (97.00%) (17573/18048)
Epoch: 195 | Batch_idx: 150 |  Loss: (0.0801) |  Loss2: (0.0000) | Acc: (97.00%) (18811/19328)
Epoch: 195 | Batch_idx: 160 |  Loss: (0.0801) |  Loss2: (0.0000) | Acc: (97.00%) (20062/20608)
Epoch: 195 | Batch_idx: 170 |  Loss: (0.0804) |  Loss2: (0.0000) | Acc: (97.00%) (21309/21888)
Epoch: 195 | Batch_idx: 180 |  Loss: (0.0808) |  Loss2: (0.0000) | Acc: (97.00%) (22550/23168)
Epoch: 195 | Batch_idx: 190 |  Loss: (0.0809) |  Loss2: (0.0000) | Acc: (97.00%) (23799/24448)
Epoch: 195 | Batch_idx: 200 |  Loss: (0.0808) |  Loss2: (0.0000) | Acc: (97.00%) (25045/25728)
Epoch: 195 | Batch_idx: 210 |  Loss: (0.0808) |  Loss2: (0.0000) | Acc: (97.00%) (26291/27008)
Epoch: 195 | Batch_idx: 220 |  Loss: (0.0803) |  Loss2: (0.0000) | Acc: (97.00%) (27538/28288)
Epoch: 195 | Batch_idx: 230 |  Loss: (0.0805) |  Loss2: (0.0000) | Acc: (97.00%) (28781/29568)
Epoch: 195 | Batch_idx: 240 |  Loss: (0.0809) |  Loss2: (0.0000) | Acc: (97.00%) (30022/30848)
Epoch: 195 | Batch_idx: 250 |  Loss: (0.0811) |  Loss2: (0.0000) | Acc: (97.00%) (31265/32128)
Epoch: 195 | Batch_idx: 260 |  Loss: (0.0808) |  Loss2: (0.0000) | Acc: (97.00%) (32514/33408)
Epoch: 195 | Batch_idx: 270 |  Loss: (0.0814) |  Loss2: (0.0000) | Acc: (97.00%) (33751/34688)
Epoch: 195 | Batch_idx: 280 |  Loss: (0.0815) |  Loss2: (0.0000) | Acc: (97.00%) (34992/35968)
Epoch: 195 | Batch_idx: 290 |  Loss: (0.0820) |  Loss2: (0.0000) | Acc: (97.00%) (36231/37248)
Epoch: 195 | Batch_idx: 300 |  Loss: (0.0820) |  Loss2: (0.0000) | Acc: (97.00%) (37477/38528)
Epoch: 195 | Batch_idx: 310 |  Loss: (0.0819) |  Loss2: (0.0000) | Acc: (97.00%) (38726/39808)
Epoch: 195 | Batch_idx: 320 |  Loss: (0.0819) |  Loss2: (0.0000) | Acc: (97.00%) (39973/41088)
Epoch: 195 | Batch_idx: 330 |  Loss: (0.0818) |  Loss2: (0.0000) | Acc: (97.00%) (41222/42368)
Epoch: 195 | Batch_idx: 340 |  Loss: (0.0818) |  Loss2: (0.0000) | Acc: (97.00%) (42457/43648)
Epoch: 195 | Batch_idx: 350 |  Loss: (0.0817) |  Loss2: (0.0000) | Acc: (97.00%) (43703/44928)
Epoch: 195 | Batch_idx: 360 |  Loss: (0.0818) |  Loss2: (0.0000) | Acc: (97.00%) (44951/46208)
Epoch: 195 | Batch_idx: 370 |  Loss: (0.0827) |  Loss2: (0.0000) | Acc: (97.00%) (46174/47488)
Epoch: 195 | Batch_idx: 380 |  Loss: (0.0829) |  Loss2: (0.0000) | Acc: (97.00%) (47415/48768)
Epoch: 195 | Batch_idx: 390 |  Loss: (0.0830) |  Loss2: (0.0000) | Acc: (97.00%) (48606/50000)
=> saving checkpoint 'drive/app/torch/save_Schedule/checkpoint_195.pth.tar'
# TEST : Loss: (0.4163) | Acc: (87.00%) (8796/10000)
percent tensor([0.5130, 0.5126, 0.5145, 0.5168, 0.5150, 0.5193, 0.5142, 0.5170, 0.5137,
        0.5124, 0.5120, 0.5128, 0.5119, 0.5154, 0.5145, 0.5144],
       device='cuda:0') torch.Size([16])
percent tensor([0.5243, 0.5335, 0.5200, 0.5174, 0.5152, 0.5345, 0.5251, 0.5120, 0.5208,
        0.5288, 0.5277, 0.5244, 0.5340, 0.5227, 0.5287, 0.5315],
       device='cuda:0') torch.Size([16])
percent tensor([0.6053, 0.5569, 0.6525, 0.6731, 0.6590, 0.6558, 0.6094, 0.6451, 0.6563,
        0.6007, 0.6431, 0.6184, 0.5179, 0.6772, 0.5983, 0.6118],
       device='cuda:0') torch.Size([16])
percent tensor([0.6596, 0.6566, 0.6479, 0.6455, 0.6488, 0.6516, 0.6630, 0.6515, 0.6549,
        0.6668, 0.6619, 0.6569, 0.6583, 0.6539, 0.6587, 0.6711],
       device='cuda:0') torch.Size([16])
percent tensor([0.6663, 0.6240, 0.6782, 0.6813, 0.7091, 0.7779, 0.6255, 0.6235, 0.6510,
        0.6641, 0.5939, 0.6101, 0.6365, 0.6636, 0.6192, 0.7526],
       device='cuda:0') torch.Size([16])
percent tensor([0.5721, 0.6834, 0.6588, 0.6840, 0.6373, 0.7314, 0.6518, 0.4874, 0.6776,
        0.6437, 0.7356, 0.6464, 0.7309, 0.6967, 0.5082, 0.5783],
       device='cuda:0') torch.Size([16])
percent tensor([0.5519, 0.6398, 0.7017, 0.6945, 0.7186, 0.6481, 0.6699, 0.6905, 0.6072,
        0.6556, 0.6362, 0.6180, 0.5727, 0.5589, 0.6175, 0.5538],
       device='cuda:0') torch.Size([16])
percent tensor([0.9999, 0.9998, 0.9998, 0.9998, 0.9996, 0.9989, 0.9997, 0.9995, 0.9999,
        0.9999, 1.0000, 0.9999, 0.9999, 0.9995, 0.9994, 0.9994],
       device='cuda:0') torch.Size([16])
Epoch: 196 | Batch_idx: 0 |  Loss: (0.0804) |  Loss2: (0.0000) | Acc: (96.00%) (123/128)
Epoch: 196 | Batch_idx: 10 |  Loss: (0.0797) |  Loss2: (0.0000) | Acc: (97.00%) (1369/1408)
Epoch: 196 | Batch_idx: 20 |  Loss: (0.0794) |  Loss2: (0.0000) | Acc: (97.00%) (2618/2688)
Epoch: 196 | Batch_idx: 30 |  Loss: (0.0815) |  Loss2: (0.0000) | Acc: (97.00%) (3863/3968)
Epoch: 196 | Batch_idx: 40 |  Loss: (0.0790) |  Loss2: (0.0000) | Acc: (97.00%) (5113/5248)
Epoch: 196 | Batch_idx: 50 |  Loss: (0.0752) |  Loss2: (0.0000) | Acc: (97.00%) (6367/6528)
Epoch: 196 | Batch_idx: 60 |  Loss: (0.0776) |  Loss2: (0.0000) | Acc: (97.00%) (7601/7808)
Epoch: 196 | Batch_idx: 70 |  Loss: (0.0764) |  Loss2: (0.0000) | Acc: (97.00%) (8854/9088)
Epoch: 196 | Batch_idx: 80 |  Loss: (0.0748) |  Loss2: (0.0000) | Acc: (97.00%) (10111/10368)
Epoch: 196 | Batch_idx: 90 |  Loss: (0.0736) |  Loss2: (0.0000) | Acc: (97.00%) (11363/11648)
Epoch: 196 | Batch_idx: 100 |  Loss: (0.0748) |  Loss2: (0.0000) | Acc: (97.00%) (12605/12928)
Epoch: 196 | Batch_idx: 110 |  Loss: (0.0761) |  Loss2: (0.0000) | Acc: (97.00%) (13843/14208)
Epoch: 196 | Batch_idx: 120 |  Loss: (0.0759) |  Loss2: (0.0000) | Acc: (97.00%) (15089/15488)
Epoch: 196 | Batch_idx: 130 |  Loss: (0.0761) |  Loss2: (0.0000) | Acc: (97.00%) (16331/16768)
Epoch: 196 | Batch_idx: 140 |  Loss: (0.0759) |  Loss2: (0.0000) | Acc: (97.00%) (17583/18048)
Epoch: 196 | Batch_idx: 150 |  Loss: (0.0755) |  Loss2: (0.0000) | Acc: (97.00%) (18833/19328)
Epoch: 196 | Batch_idx: 160 |  Loss: (0.0753) |  Loss2: (0.0000) | Acc: (97.00%) (20082/20608)
Epoch: 196 | Batch_idx: 170 |  Loss: (0.0753) |  Loss2: (0.0000) | Acc: (97.00%) (21325/21888)
Epoch: 196 | Batch_idx: 180 |  Loss: (0.0752) |  Loss2: (0.0000) | Acc: (97.00%) (22574/23168)
Epoch: 196 | Batch_idx: 190 |  Loss: (0.0744) |  Loss2: (0.0000) | Acc: (97.00%) (23832/24448)
Epoch: 196 | Batch_idx: 200 |  Loss: (0.0746) |  Loss2: (0.0000) | Acc: (97.00%) (25078/25728)
Epoch: 196 | Batch_idx: 210 |  Loss: (0.0739) |  Loss2: (0.0000) | Acc: (97.00%) (26336/27008)
Epoch: 196 | Batch_idx: 220 |  Loss: (0.0747) |  Loss2: (0.0000) | Acc: (97.00%) (27579/28288)
Epoch: 196 | Batch_idx: 230 |  Loss: (0.0746) |  Loss2: (0.0000) | Acc: (97.00%) (28826/29568)
Epoch: 196 | Batch_idx: 240 |  Loss: (0.0745) |  Loss2: (0.0000) | Acc: (97.00%) (30075/30848)
Epoch: 196 | Batch_idx: 250 |  Loss: (0.0747) |  Loss2: (0.0000) | Acc: (97.00%) (31322/32128)
Epoch: 196 | Batch_idx: 260 |  Loss: (0.0753) |  Loss2: (0.0000) | Acc: (97.00%) (32558/33408)
Epoch: 196 | Batch_idx: 270 |  Loss: (0.0757) |  Loss2: (0.0000) | Acc: (97.00%) (33806/34688)
Epoch: 196 | Batch_idx: 280 |  Loss: (0.0762) |  Loss2: (0.0000) | Acc: (97.00%) (35049/35968)
Epoch: 196 | Batch_idx: 290 |  Loss: (0.0765) |  Loss2: (0.0000) | Acc: (97.00%) (36287/37248)
Epoch: 196 | Batch_idx: 300 |  Loss: (0.0773) |  Loss2: (0.0000) | Acc: (97.00%) (37522/38528)
Epoch: 196 | Batch_idx: 310 |  Loss: (0.0776) |  Loss2: (0.0000) | Acc: (97.00%) (38766/39808)
Epoch: 196 | Batch_idx: 320 |  Loss: (0.0779) |  Loss2: (0.0000) | Acc: (97.00%) (40009/41088)
Epoch: 196 | Batch_idx: 330 |  Loss: (0.0782) |  Loss2: (0.0000) | Acc: (97.00%) (41247/42368)
Epoch: 196 | Batch_idx: 340 |  Loss: (0.0784) |  Loss2: (0.0000) | Acc: (97.00%) (42486/43648)
Epoch: 196 | Batch_idx: 350 |  Loss: (0.0783) |  Loss2: (0.0000) | Acc: (97.00%) (43728/44928)
Epoch: 196 | Batch_idx: 360 |  Loss: (0.0786) |  Loss2: (0.0000) | Acc: (97.00%) (44964/46208)
Epoch: 196 | Batch_idx: 370 |  Loss: (0.0789) |  Loss2: (0.0000) | Acc: (97.00%) (46205/47488)
Epoch: 196 | Batch_idx: 380 |  Loss: (0.0795) |  Loss2: (0.0000) | Acc: (97.00%) (47434/48768)
Epoch: 196 | Batch_idx: 390 |  Loss: (0.0800) |  Loss2: (0.0000) | Acc: (97.00%) (48622/50000)
# TEST : Loss: (0.4302) | Acc: (88.00%) (8815/10000)
percent tensor([0.5134, 0.5127, 0.5157, 0.5168, 0.5161, 0.5199, 0.5145, 0.5170, 0.5141,
        0.5127, 0.5121, 0.5138, 0.5122, 0.5151, 0.5147, 0.5144],
       device='cuda:0') torch.Size([16])
percent tensor([0.5253, 0.5344, 0.5202, 0.5178, 0.5161, 0.5355, 0.5253, 0.5101, 0.5217,
        0.5282, 0.5296, 0.5235, 0.5342, 0.5226, 0.5303, 0.5323],
       device='cuda:0') torch.Size([16])
percent tensor([0.6030, 0.5672, 0.6638, 0.6826, 0.6649, 0.6237, 0.6214, 0.6576, 0.6683,
        0.6170, 0.6470, 0.6387, 0.5322, 0.6871, 0.5939, 0.6125],
       device='cuda:0') torch.Size([16])
percent tensor([0.6603, 0.6575, 0.6479, 0.6448, 0.6497, 0.6529, 0.6634, 0.6531, 0.6541,
        0.6659, 0.6606, 0.6577, 0.6585, 0.6524, 0.6574, 0.6706],
       device='cuda:0') torch.Size([16])
percent tensor([0.6910, 0.6498, 0.7033, 0.7048, 0.7241, 0.7805, 0.6539, 0.6533, 0.6812,
        0.6982, 0.6267, 0.6398, 0.6661, 0.6786, 0.6233, 0.7695],
       device='cuda:0') torch.Size([16])
percent tensor([0.6104, 0.6851, 0.6388, 0.6727, 0.6403, 0.7484, 0.6593, 0.4966, 0.6973,
        0.6597, 0.7574, 0.6493, 0.7419, 0.7516, 0.5667, 0.6291],
       device='cuda:0') torch.Size([16])
percent tensor([0.5642, 0.6445, 0.7011, 0.7286, 0.7327, 0.6582, 0.6790, 0.6998, 0.6324,
        0.6852, 0.6340, 0.6439, 0.5974, 0.5954, 0.6302, 0.5719],
       device='cuda:0') torch.Size([16])
percent tensor([0.9999, 0.9998, 0.9997, 0.9999, 0.9995, 0.9993, 0.9998, 0.9997, 0.9998,
        0.9999, 0.9999, 0.9999, 0.9999, 0.9995, 0.9994, 0.9996],
       device='cuda:0') torch.Size([16])
Epoch: 197 | Batch_idx: 0 |  Loss: (0.0612) |  Loss2: (0.0000) | Acc: (97.00%) (125/128)
Epoch: 197 | Batch_idx: 10 |  Loss: (0.0752) |  Loss2: (0.0000) | Acc: (97.00%) (1372/1408)
Epoch: 197 | Batch_idx: 20 |  Loss: (0.0730) |  Loss2: (0.0000) | Acc: (97.00%) (2620/2688)
Epoch: 197 | Batch_idx: 30 |  Loss: (0.0728) |  Loss2: (0.0000) | Acc: (97.00%) (3874/3968)
Epoch: 197 | Batch_idx: 40 |  Loss: (0.0746) |  Loss2: (0.0000) | Acc: (97.00%) (5118/5248)
Epoch: 197 | Batch_idx: 50 |  Loss: (0.0771) |  Loss2: (0.0000) | Acc: (97.00%) (6359/6528)
Epoch: 197 | Batch_idx: 60 |  Loss: (0.0769) |  Loss2: (0.0000) | Acc: (97.00%) (7607/7808)
Epoch: 197 | Batch_idx: 70 |  Loss: (0.0757) |  Loss2: (0.0000) | Acc: (97.00%) (8856/9088)
Epoch: 197 | Batch_idx: 80 |  Loss: (0.0761) |  Loss2: (0.0000) | Acc: (97.00%) (10097/10368)
Epoch: 197 | Batch_idx: 90 |  Loss: (0.0776) |  Loss2: (0.0000) | Acc: (97.00%) (11340/11648)
Epoch: 197 | Batch_idx: 100 |  Loss: (0.0779) |  Loss2: (0.0000) | Acc: (97.00%) (12579/12928)
Epoch: 197 | Batch_idx: 110 |  Loss: (0.0783) |  Loss2: (0.0000) | Acc: (97.00%) (13825/14208)
Epoch: 197 | Batch_idx: 120 |  Loss: (0.0771) |  Loss2: (0.0000) | Acc: (97.00%) (15078/15488)
Epoch: 197 | Batch_idx: 130 |  Loss: (0.0768) |  Loss2: (0.0000) | Acc: (97.00%) (16332/16768)
Epoch: 197 | Batch_idx: 140 |  Loss: (0.0760) |  Loss2: (0.0000) | Acc: (97.00%) (17588/18048)
Epoch: 197 | Batch_idx: 150 |  Loss: (0.0763) |  Loss2: (0.0000) | Acc: (97.00%) (18832/19328)
Epoch: 197 | Batch_idx: 160 |  Loss: (0.0749) |  Loss2: (0.0000) | Acc: (97.00%) (20092/20608)
Epoch: 197 | Batch_idx: 170 |  Loss: (0.0748) |  Loss2: (0.0000) | Acc: (97.00%) (21344/21888)
Epoch: 197 | Batch_idx: 180 |  Loss: (0.0745) |  Loss2: (0.0000) | Acc: (97.00%) (22594/23168)
Epoch: 197 | Batch_idx: 190 |  Loss: (0.0746) |  Loss2: (0.0000) | Acc: (97.00%) (23843/24448)
Epoch: 197 | Batch_idx: 200 |  Loss: (0.0745) |  Loss2: (0.0000) | Acc: (97.00%) (25094/25728)
Epoch: 197 | Batch_idx: 210 |  Loss: (0.0744) |  Loss2: (0.0000) | Acc: (97.00%) (26345/27008)
Epoch: 197 | Batch_idx: 220 |  Loss: (0.0747) |  Loss2: (0.0000) | Acc: (97.00%) (27591/28288)
Epoch: 197 | Batch_idx: 230 |  Loss: (0.0748) |  Loss2: (0.0000) | Acc: (97.00%) (28837/29568)
Epoch: 197 | Batch_idx: 240 |  Loss: (0.0743) |  Loss2: (0.0000) | Acc: (97.00%) (30094/30848)
Epoch: 197 | Batch_idx: 250 |  Loss: (0.0749) |  Loss2: (0.0000) | Acc: (97.00%) (31329/32128)
Epoch: 197 | Batch_idx: 260 |  Loss: (0.0752) |  Loss2: (0.0000) | Acc: (97.00%) (32573/33408)
Epoch: 197 | Batch_idx: 270 |  Loss: (0.0751) |  Loss2: (0.0000) | Acc: (97.00%) (33822/34688)
Epoch: 197 | Batch_idx: 280 |  Loss: (0.0756) |  Loss2: (0.0000) | Acc: (97.00%) (35062/35968)
Epoch: 197 | Batch_idx: 290 |  Loss: (0.0757) |  Loss2: (0.0000) | Acc: (97.00%) (36307/37248)
Epoch: 197 | Batch_idx: 300 |  Loss: (0.0759) |  Loss2: (0.0000) | Acc: (97.00%) (37553/38528)
Epoch: 197 | Batch_idx: 310 |  Loss: (0.0765) |  Loss2: (0.0000) | Acc: (97.00%) (38791/39808)
Epoch: 197 | Batch_idx: 320 |  Loss: (0.0767) |  Loss2: (0.0000) | Acc: (97.00%) (40035/41088)
Epoch: 197 | Batch_idx: 330 |  Loss: (0.0770) |  Loss2: (0.0000) | Acc: (97.00%) (41282/42368)
Epoch: 197 | Batch_idx: 340 |  Loss: (0.0770) |  Loss2: (0.0000) | Acc: (97.00%) (42529/43648)
Epoch: 197 | Batch_idx: 350 |  Loss: (0.0772) |  Loss2: (0.0000) | Acc: (97.00%) (43772/44928)
Epoch: 197 | Batch_idx: 360 |  Loss: (0.0771) |  Loss2: (0.0000) | Acc: (97.00%) (45018/46208)
Epoch: 197 | Batch_idx: 370 |  Loss: (0.0769) |  Loss2: (0.0000) | Acc: (97.00%) (46264/47488)
Epoch: 197 | Batch_idx: 380 |  Loss: (0.0770) |  Loss2: (0.0000) | Acc: (97.00%) (47516/48768)
Epoch: 197 | Batch_idx: 390 |  Loss: (0.0769) |  Loss2: (0.0000) | Acc: (97.00%) (48715/50000)
# TEST : Loss: (0.4345) | Acc: (87.00%) (8781/10000)
percent tensor([0.5130, 0.5125, 0.5166, 0.5167, 0.5167, 0.5192, 0.5146, 0.5174, 0.5136,
        0.5130, 0.5113, 0.5144, 0.5118, 0.5147, 0.5143, 0.5139],
       device='cuda:0') torch.Size([16])
percent tensor([0.5226, 0.5351, 0.5200, 0.5161, 0.5150, 0.5337, 0.5252, 0.5116, 0.5204,
        0.5287, 0.5286, 0.5236, 0.5328, 0.5250, 0.5291, 0.5316],
       device='cuda:0') torch.Size([16])
percent tensor([0.6001, 0.5530, 0.6492, 0.6760, 0.6640, 0.6516, 0.6096, 0.6447, 0.6537,
        0.5956, 0.6380, 0.6214, 0.5157, 0.6717, 0.6010, 0.6119],
       device='cuda:0') torch.Size([16])
percent tensor([0.6598, 0.6594, 0.6482, 0.6447, 0.6476, 0.6568, 0.6644, 0.6511, 0.6598,
        0.6686, 0.6638, 0.6563, 0.6594, 0.6571, 0.6595, 0.6722],
       device='cuda:0') torch.Size([16])
percent tensor([0.6372, 0.6082, 0.6707, 0.6595, 0.6889, 0.7481, 0.6087, 0.6253, 0.6341,
        0.6597, 0.5757, 0.6080, 0.6223, 0.6433, 0.5934, 0.7166],
       device='cuda:0') torch.Size([16])
percent tensor([0.6160, 0.6986, 0.6522, 0.6899, 0.6322, 0.7229, 0.6700, 0.4862, 0.7151,
        0.6686, 0.7495, 0.6686, 0.7550, 0.7376, 0.5452, 0.6216],
       device='cuda:0') torch.Size([16])
percent tensor([0.5714, 0.6321, 0.6868, 0.7039, 0.7149, 0.6592, 0.6642, 0.6918, 0.5978,
        0.6339, 0.6415, 0.6161, 0.5809, 0.5716, 0.6142, 0.5679],
       device='cuda:0') torch.Size([16])
percent tensor([0.9999, 0.9999, 0.9997, 0.9999, 0.9995, 0.9991, 0.9997, 0.9996, 0.9999,
        0.9999, 0.9999, 0.9999, 0.9999, 0.9997, 0.9993, 0.9994],
       device='cuda:0') torch.Size([16])
False Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=128, out_features=16, bias=False)
True Linear(in_features=16, out_features=2, bias=False)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=128, out_features=16, bias=False)
True Linear(in_features=16, out_features=2, bias=False)
False Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=256, out_features=32, bias=False)
True Linear(in_features=32, out_features=2, bias=False)
False Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=256, out_features=32, bias=False)
True Linear(in_features=32, out_features=2, bias=False)
False Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=512, out_features=64, bias=False)
True Linear(in_features=64, out_features=2, bias=False)
False Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=512, out_features=64, bias=False)
True Linear(in_features=64, out_features=2, bias=False)
False Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1024, out_features=128, bias=False)
True Linear(in_features=128, out_features=2, bias=False)
False Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1024, out_features=128, bias=False)
True Linear(in_features=128, out_features=2, bias=False)
False Linear(in_features=512, out_features=10, bias=True)
Epoch: 198 | Batch_idx: 0 |  Loss: (0.0814) |  Loss2: (0.0000) | Acc: (97.00%) (125/128)
Epoch: 198 | Batch_idx: 10 |  Loss: (0.0943) |  Loss2: (0.0000) | Acc: (96.00%) (1360/1408)
Epoch: 198 | Batch_idx: 20 |  Loss: (0.0924) |  Loss2: (0.0000) | Acc: (96.00%) (2604/2688)
Epoch: 198 | Batch_idx: 30 |  Loss: (0.0978) |  Loss2: (0.0000) | Acc: (96.00%) (3831/3968)
Epoch: 198 | Batch_idx: 40 |  Loss: (0.1062) |  Loss2: (0.0000) | Acc: (96.00%) (5055/5248)
Epoch: 198 | Batch_idx: 50 |  Loss: (0.1080) |  Loss2: (0.0000) | Acc: (96.00%) (6288/6528)
Epoch: 198 | Batch_idx: 60 |  Loss: (0.1084) |  Loss2: (0.0000) | Acc: (96.00%) (7520/7808)
Epoch: 198 | Batch_idx: 70 |  Loss: (0.1058) |  Loss2: (0.0000) | Acc: (96.00%) (8754/9088)
Epoch: 198 | Batch_idx: 80 |  Loss: (0.1036) |  Loss2: (0.0000) | Acc: (96.00%) (9994/10368)
Epoch: 198 | Batch_idx: 90 |  Loss: (0.1029) |  Loss2: (0.0000) | Acc: (96.00%) (11229/11648)
Epoch: 198 | Batch_idx: 100 |  Loss: (0.1038) |  Loss2: (0.0000) | Acc: (96.00%) (12453/12928)
Epoch: 198 | Batch_idx: 110 |  Loss: (0.1066) |  Loss2: (0.0000) | Acc: (96.00%) (13673/14208)
Epoch: 198 | Batch_idx: 120 |  Loss: (0.1064) |  Loss2: (0.0000) | Acc: (96.00%) (14898/15488)
Epoch: 198 | Batch_idx: 130 |  Loss: (0.1058) |  Loss2: (0.0000) | Acc: (96.00%) (16129/16768)
Epoch: 198 | Batch_idx: 140 |  Loss: (0.1060) |  Loss2: (0.0000) | Acc: (96.00%) (17356/18048)
Epoch: 198 | Batch_idx: 150 |  Loss: (0.1081) |  Loss2: (0.0000) | Acc: (96.00%) (18573/19328)
Epoch: 198 | Batch_idx: 160 |  Loss: (0.1081) |  Loss2: (0.0000) | Acc: (96.00%) (19805/20608)
Epoch: 198 | Batch_idx: 170 |  Loss: (0.1086) |  Loss2: (0.0000) | Acc: (96.00%) (21031/21888)
Epoch: 198 | Batch_idx: 180 |  Loss: (0.1070) |  Loss2: (0.0000) | Acc: (96.00%) (22277/23168)
Epoch: 198 | Batch_idx: 190 |  Loss: (0.1059) |  Loss2: (0.0000) | Acc: (96.00%) (23520/24448)
Epoch: 198 | Batch_idx: 200 |  Loss: (0.1067) |  Loss2: (0.0000) | Acc: (96.00%) (24748/25728)
Epoch: 198 | Batch_idx: 210 |  Loss: (0.1063) |  Loss2: (0.0000) | Acc: (96.00%) (25984/27008)
Epoch: 198 | Batch_idx: 220 |  Loss: (0.1061) |  Loss2: (0.0000) | Acc: (96.00%) (27219/28288)
Epoch: 198 | Batch_idx: 230 |  Loss: (0.1052) |  Loss2: (0.0000) | Acc: (96.00%) (28464/29568)
Epoch: 198 | Batch_idx: 240 |  Loss: (0.1044) |  Loss2: (0.0000) | Acc: (96.00%) (29704/30848)
Epoch: 198 | Batch_idx: 250 |  Loss: (0.1045) |  Loss2: (0.0000) | Acc: (96.00%) (30935/32128)
Epoch: 198 | Batch_idx: 260 |  Loss: (0.1040) |  Loss2: (0.0000) | Acc: (96.00%) (32174/33408)
Epoch: 198 | Batch_idx: 270 |  Loss: (0.1035) |  Loss2: (0.0000) | Acc: (96.00%) (33414/34688)
Epoch: 198 | Batch_idx: 280 |  Loss: (0.1025) |  Loss2: (0.0000) | Acc: (96.00%) (34657/35968)
Epoch: 198 | Batch_idx: 290 |  Loss: (0.1018) |  Loss2: (0.0000) | Acc: (96.00%) (35898/37248)
Epoch: 198 | Batch_idx: 300 |  Loss: (0.1012) |  Loss2: (0.0000) | Acc: (96.00%) (37142/38528)
Epoch: 198 | Batch_idx: 310 |  Loss: (0.1006) |  Loss2: (0.0000) | Acc: (96.00%) (38382/39808)
Epoch: 198 | Batch_idx: 320 |  Loss: (0.1005) |  Loss2: (0.0000) | Acc: (96.00%) (39615/41088)
Epoch: 198 | Batch_idx: 330 |  Loss: (0.1004) |  Loss2: (0.0000) | Acc: (96.00%) (40853/42368)
Epoch: 198 | Batch_idx: 340 |  Loss: (0.1005) |  Loss2: (0.0000) | Acc: (96.00%) (42091/43648)
Epoch: 198 | Batch_idx: 350 |  Loss: (0.1001) |  Loss2: (0.0000) | Acc: (96.00%) (43340/44928)
Epoch: 198 | Batch_idx: 360 |  Loss: (0.0999) |  Loss2: (0.0000) | Acc: (96.00%) (44579/46208)
Epoch: 198 | Batch_idx: 370 |  Loss: (0.1004) |  Loss2: (0.0000) | Acc: (96.00%) (45807/47488)
Epoch: 198 | Batch_idx: 380 |  Loss: (0.0999) |  Loss2: (0.0000) | Acc: (96.00%) (47047/48768)
Epoch: 198 | Batch_idx: 390 |  Loss: (0.0996) |  Loss2: (0.0000) | Acc: (96.00%) (48240/50000)
# TEST : Loss: (0.4041) | Acc: (88.00%) (8870/10000)
percent tensor([0.5135, 0.5131, 0.5169, 0.5169, 0.5167, 0.5195, 0.5152, 0.5178, 0.5141,
        0.5136, 0.5119, 0.5150, 0.5123, 0.5152, 0.5148, 0.5142],
       device='cuda:0') torch.Size([16])
percent tensor([0.5230, 0.5344, 0.5217, 0.5168, 0.5159, 0.5336, 0.5256, 0.5124, 0.5198,
        0.5291, 0.5274, 0.5256, 0.5329, 0.5227, 0.5282, 0.5317],
       device='cuda:0') torch.Size([16])
percent tensor([0.5979, 0.5725, 0.6417, 0.6784, 0.6625, 0.6501, 0.6184, 0.6434, 0.6592,
        0.6094, 0.6558, 0.6241, 0.5279, 0.6875, 0.6088, 0.6181],
       device='cuda:0') torch.Size([16])
percent tensor([0.6782, 0.6773, 0.6632, 0.6603, 0.6657, 0.6729, 0.6839, 0.6690, 0.6761,
        0.6873, 0.6824, 0.6760, 0.6770, 0.6755, 0.6797, 0.6900],
       device='cuda:0') torch.Size([16])
percent tensor([0.6637, 0.6222, 0.6930, 0.6956, 0.6905, 0.7740, 0.6188, 0.6332, 0.6635,
        0.6817, 0.6055, 0.6415, 0.6485, 0.6748, 0.6069, 0.7527],
       device='cuda:0') torch.Size([16])
percent tensor([0.6358, 0.7137, 0.6713, 0.7070, 0.6656, 0.7395, 0.6973, 0.5244, 0.7346,
        0.6748, 0.7652, 0.6716, 0.7618, 0.7531, 0.5790, 0.6323],
       device='cuda:0') torch.Size([16])
percent tensor([0.5283, 0.5970, 0.6593, 0.6691, 0.6887, 0.6282, 0.6326, 0.6384, 0.5862,
        0.5951, 0.6188, 0.5713, 0.5725, 0.5406, 0.5679, 0.5189],
       device='cuda:0') torch.Size([16])
percent tensor([0.9999, 0.9999, 0.9997, 0.9999, 0.9994, 0.9991, 0.9997, 0.9997, 0.9998,
        0.9998, 0.9999, 0.9998, 0.9999, 0.9996, 0.9994, 0.9996],
       device='cuda:0') torch.Size([16])
Epoch: 199 | Batch_idx: 0 |  Loss: (0.0718) |  Loss2: (0.0000) | Acc: (97.00%) (125/128)
Epoch: 199 | Batch_idx: 10 |  Loss: (0.1028) |  Loss2: (0.0000) | Acc: (96.00%) (1362/1408)
Epoch: 199 | Batch_idx: 20 |  Loss: (0.0958) |  Loss2: (0.0000) | Acc: (96.00%) (2606/2688)
Epoch: 199 | Batch_idx: 30 |  Loss: (0.0904) |  Loss2: (0.0000) | Acc: (97.00%) (3852/3968)
Epoch: 199 | Batch_idx: 40 |  Loss: (0.0892) |  Loss2: (0.0000) | Acc: (96.00%) (5090/5248)
Epoch: 199 | Batch_idx: 50 |  Loss: (0.0894) |  Loss2: (0.0000) | Acc: (96.00%) (6330/6528)
Epoch: 199 | Batch_idx: 60 |  Loss: (0.0882) |  Loss2: (0.0000) | Acc: (97.00%) (7580/7808)
Epoch: 199 | Batch_idx: 70 |  Loss: (0.0868) |  Loss2: (0.0000) | Acc: (97.00%) (8827/9088)
Epoch: 199 | Batch_idx: 80 |  Loss: (0.0870) |  Loss2: (0.0000) | Acc: (97.00%) (10065/10368)
Epoch: 199 | Batch_idx: 90 |  Loss: (0.0868) |  Loss2: (0.0000) | Acc: (97.00%) (11304/11648)
Epoch: 199 | Batch_idx: 100 |  Loss: (0.0870) |  Loss2: (0.0000) | Acc: (97.00%) (12545/12928)
Epoch: 199 | Batch_idx: 110 |  Loss: (0.0866) |  Loss2: (0.0000) | Acc: (97.00%) (13789/14208)
Epoch: 199 | Batch_idx: 120 |  Loss: (0.0872) |  Loss2: (0.0000) | Acc: (97.00%) (15028/15488)
Epoch: 199 | Batch_idx: 130 |  Loss: (0.0873) |  Loss2: (0.0000) | Acc: (97.00%) (16273/16768)
Epoch: 199 | Batch_idx: 140 |  Loss: (0.0872) |  Loss2: (0.0000) | Acc: (97.00%) (17509/18048)
Epoch: 199 | Batch_idx: 150 |  Loss: (0.0881) |  Loss2: (0.0000) | Acc: (96.00%) (18744/19328)
Epoch: 199 | Batch_idx: 160 |  Loss: (0.0871) |  Loss2: (0.0000) | Acc: (97.00%) (19996/20608)
Epoch: 199 | Batch_idx: 170 |  Loss: (0.0876) |  Loss2: (0.0000) | Acc: (96.00%) (21230/21888)
Epoch: 199 | Batch_idx: 180 |  Loss: (0.0876) |  Loss2: (0.0000) | Acc: (97.00%) (22474/23168)
Epoch: 199 | Batch_idx: 190 |  Loss: (0.0881) |  Loss2: (0.0000) | Acc: (96.00%) (23703/24448)
Epoch: 199 | Batch_idx: 200 |  Loss: (0.0885) |  Loss2: (0.0000) | Acc: (96.00%) (24945/25728)
Epoch: 199 | Batch_idx: 210 |  Loss: (0.0880) |  Loss2: (0.0000) | Acc: (96.00%) (26190/27008)
Epoch: 199 | Batch_idx: 220 |  Loss: (0.0881) |  Loss2: (0.0000) | Acc: (96.00%) (27434/28288)
Epoch: 199 | Batch_idx: 230 |  Loss: (0.0880) |  Loss2: (0.0000) | Acc: (97.00%) (28683/29568)
Epoch: 199 | Batch_idx: 240 |  Loss: (0.0875) |  Loss2: (0.0000) | Acc: (97.00%) (29926/30848)
Epoch: 199 | Batch_idx: 250 |  Loss: (0.0875) |  Loss2: (0.0000) | Acc: (97.00%) (31168/32128)
Epoch: 199 | Batch_idx: 260 |  Loss: (0.0868) |  Loss2: (0.0000) | Acc: (97.00%) (32420/33408)
Epoch: 199 | Batch_idx: 270 |  Loss: (0.0861) |  Loss2: (0.0000) | Acc: (97.00%) (33674/34688)
Epoch: 199 | Batch_idx: 280 |  Loss: (0.0862) |  Loss2: (0.0000) | Acc: (97.00%) (34918/35968)
Epoch: 199 | Batch_idx: 290 |  Loss: (0.0863) |  Loss2: (0.0000) | Acc: (97.00%) (36165/37248)
Epoch: 199 | Batch_idx: 300 |  Loss: (0.0862) |  Loss2: (0.0000) | Acc: (97.00%) (37408/38528)
Epoch: 199 | Batch_idx: 310 |  Loss: (0.0863) |  Loss2: (0.0000) | Acc: (97.00%) (38653/39808)
Epoch: 199 | Batch_idx: 320 |  Loss: (0.0858) |  Loss2: (0.0000) | Acc: (97.00%) (39911/41088)
Epoch: 199 | Batch_idx: 330 |  Loss: (0.0856) |  Loss2: (0.0000) | Acc: (97.00%) (41159/42368)
Epoch: 199 | Batch_idx: 340 |  Loss: (0.0848) |  Loss2: (0.0000) | Acc: (97.00%) (42415/43648)
Epoch: 199 | Batch_idx: 350 |  Loss: (0.0851) |  Loss2: (0.0000) | Acc: (97.00%) (43655/44928)
Epoch: 199 | Batch_idx: 360 |  Loss: (0.0854) |  Loss2: (0.0000) | Acc: (97.00%) (44891/46208)
Epoch: 199 | Batch_idx: 370 |  Loss: (0.0852) |  Loss2: (0.0000) | Acc: (97.00%) (46134/47488)
Epoch: 199 | Batch_idx: 380 |  Loss: (0.0848) |  Loss2: (0.0000) | Acc: (97.00%) (47385/48768)
Epoch: 199 | Batch_idx: 390 |  Loss: (0.0847) |  Loss2: (0.0000) | Acc: (97.00%) (48584/50000)
# TEST : Loss: (0.3923) | Acc: (88.00%) (8879/10000)
percent tensor([0.5140, 0.5137, 0.5173, 0.5172, 0.5172, 0.5198, 0.5158, 0.5184, 0.5147,
        0.5142, 0.5125, 0.5155, 0.5129, 0.5158, 0.5153, 0.5146],
       device='cuda:0') torch.Size([16])
percent tensor([0.5270, 0.5401, 0.5263, 0.5209, 0.5209, 0.5354, 0.5311, 0.5176, 0.5243,
        0.5348, 0.5321, 0.5306, 0.5375, 0.5274, 0.5325, 0.5357],
       device='cuda:0') torch.Size([16])
percent tensor([0.5990, 0.5751, 0.6469, 0.6822, 0.6671, 0.6502, 0.6209, 0.6474, 0.6610,
        0.6145, 0.6596, 0.6304, 0.5288, 0.6902, 0.6105, 0.6220],
       device='cuda:0') torch.Size([16])
percent tensor([0.6790, 0.6785, 0.6636, 0.6611, 0.6677, 0.6732, 0.6855, 0.6721, 0.6755,
        0.6876, 0.6818, 0.6768, 0.6773, 0.6749, 0.6816, 0.6903],
       device='cuda:0') torch.Size([16])
percent tensor([0.6657, 0.6310, 0.6919, 0.6912, 0.6883, 0.7729, 0.6238, 0.6357, 0.6696,
        0.6919, 0.6147, 0.6497, 0.6601, 0.6856, 0.6055, 0.7558],
       device='cuda:0') torch.Size([16])
percent tensor([0.6227, 0.6995, 0.6608, 0.6970, 0.6558, 0.7306, 0.6812, 0.5085, 0.7228,
        0.6578, 0.7518, 0.6544, 0.7513, 0.7368, 0.5664, 0.6161],
       device='cuda:0') torch.Size([16])
percent tensor([0.5379, 0.6173, 0.6736, 0.6826, 0.6973, 0.6334, 0.6497, 0.6437, 0.6119,
        0.6176, 0.6447, 0.5908, 0.5959, 0.5600, 0.5818, 0.5204],
       device='cuda:0') torch.Size([16])
percent tensor([0.9999, 0.9999, 0.9997, 0.9999, 0.9994, 0.9990, 0.9997, 0.9997, 0.9998,
        0.9998, 0.9999, 0.9998, 0.9999, 0.9997, 0.9993, 0.9995],
       device='cuda:0') torch.Size([16])
Epoch: 200 | Batch_idx: 0 |  Loss: (0.0539) |  Loss2: (0.0000) | Acc: (96.00%) (124/128)
Epoch: 200 | Batch_idx: 10 |  Loss: (0.0623) |  Loss2: (0.0000) | Acc: (98.00%) (1385/1408)
Epoch: 200 | Batch_idx: 20 |  Loss: (0.0684) |  Loss2: (0.0000) | Acc: (97.00%) (2633/2688)
Epoch: 200 | Batch_idx: 30 |  Loss: (0.0719) |  Loss2: (0.0000) | Acc: (97.00%) (3873/3968)
Epoch: 200 | Batch_idx: 40 |  Loss: (0.0686) |  Loss2: (0.0000) | Acc: (97.00%) (5131/5248)
Epoch: 200 | Batch_idx: 50 |  Loss: (0.0718) |  Loss2: (0.0000) | Acc: (97.00%) (6376/6528)
Epoch: 200 | Batch_idx: 60 |  Loss: (0.0732) |  Loss2: (0.0000) | Acc: (97.00%) (7624/7808)
Epoch: 200 | Batch_idx: 70 |  Loss: (0.0741) |  Loss2: (0.0000) | Acc: (97.00%) (8873/9088)
Epoch: 200 | Batch_idx: 80 |  Loss: (0.0750) |  Loss2: (0.0000) | Acc: (97.00%) (10116/10368)
Epoch: 200 | Batch_idx: 90 |  Loss: (0.0750) |  Loss2: (0.0000) | Acc: (97.00%) (11365/11648)
Epoch: 200 | Batch_idx: 100 |  Loss: (0.0746) |  Loss2: (0.0000) | Acc: (97.00%) (12615/12928)
Epoch: 200 | Batch_idx: 110 |  Loss: (0.0748) |  Loss2: (0.0000) | Acc: (97.00%) (13867/14208)
Epoch: 200 | Batch_idx: 120 |  Loss: (0.0741) |  Loss2: (0.0000) | Acc: (97.00%) (15116/15488)
Epoch: 200 | Batch_idx: 130 |  Loss: (0.0740) |  Loss2: (0.0000) | Acc: (97.00%) (16363/16768)
Epoch: 200 | Batch_idx: 140 |  Loss: (0.0743) |  Loss2: (0.0000) | Acc: (97.00%) (17610/18048)
Epoch: 200 | Batch_idx: 150 |  Loss: (0.0739) |  Loss2: (0.0000) | Acc: (97.00%) (18861/19328)
Epoch: 200 | Batch_idx: 160 |  Loss: (0.0735) |  Loss2: (0.0000) | Acc: (97.00%) (20113/20608)
Epoch: 200 | Batch_idx: 170 |  Loss: (0.0741) |  Loss2: (0.0000) | Acc: (97.00%) (21355/21888)
Epoch: 200 | Batch_idx: 180 |  Loss: (0.0741) |  Loss2: (0.0000) | Acc: (97.00%) (22605/23168)
Epoch: 200 | Batch_idx: 190 |  Loss: (0.0738) |  Loss2: (0.0000) | Acc: (97.00%) (23862/24448)
Epoch: 200 | Batch_idx: 200 |  Loss: (0.0737) |  Loss2: (0.0000) | Acc: (97.00%) (25109/25728)
Epoch: 200 | Batch_idx: 210 |  Loss: (0.0740) |  Loss2: (0.0000) | Acc: (97.00%) (26354/27008)
Epoch: 200 | Batch_idx: 220 |  Loss: (0.0741) |  Loss2: (0.0000) | Acc: (97.00%) (27600/28288)
Epoch: 200 | Batch_idx: 230 |  Loss: (0.0753) |  Loss2: (0.0000) | Acc: (97.00%) (28843/29568)
Epoch: 200 | Batch_idx: 240 |  Loss: (0.0751) |  Loss2: (0.0000) | Acc: (97.00%) (30096/30848)
Epoch: 200 | Batch_idx: 250 |  Loss: (0.0754) |  Loss2: (0.0000) | Acc: (97.00%) (31339/32128)
Epoch: 200 | Batch_idx: 260 |  Loss: (0.0753) |  Loss2: (0.0000) | Acc: (97.00%) (32588/33408)
Epoch: 200 | Batch_idx: 270 |  Loss: (0.0749) |  Loss2: (0.0000) | Acc: (97.00%) (33841/34688)
Epoch: 200 | Batch_idx: 280 |  Loss: (0.0750) |  Loss2: (0.0000) | Acc: (97.00%) (35089/35968)
Epoch: 200 | Batch_idx: 290 |  Loss: (0.0750) |  Loss2: (0.0000) | Acc: (97.00%) (36336/37248)
Epoch: 200 | Batch_idx: 300 |  Loss: (0.0748) |  Loss2: (0.0000) | Acc: (97.00%) (37590/38528)
Epoch: 200 | Batch_idx: 310 |  Loss: (0.0754) |  Loss2: (0.0000) | Acc: (97.00%) (38835/39808)
Epoch: 200 | Batch_idx: 320 |  Loss: (0.0762) |  Loss2: (0.0000) | Acc: (97.00%) (40061/41088)
Epoch: 200 | Batch_idx: 330 |  Loss: (0.0761) |  Loss2: (0.0000) | Acc: (97.00%) (41308/42368)
Epoch: 200 | Batch_idx: 340 |  Loss: (0.0761) |  Loss2: (0.0000) | Acc: (97.00%) (42560/43648)
Epoch: 200 | Batch_idx: 350 |  Loss: (0.0763) |  Loss2: (0.0000) | Acc: (97.00%) (43799/44928)
Epoch: 200 | Batch_idx: 360 |  Loss: (0.0766) |  Loss2: (0.0000) | Acc: (97.00%) (45037/46208)
Epoch: 200 | Batch_idx: 370 |  Loss: (0.0768) |  Loss2: (0.0000) | Acc: (97.00%) (46281/47488)
Epoch: 200 | Batch_idx: 380 |  Loss: (0.0774) |  Loss2: (0.0000) | Acc: (97.00%) (47514/48768)
Epoch: 200 | Batch_idx: 390 |  Loss: (0.0775) |  Loss2: (0.0000) | Acc: (97.00%) (48715/50000)
=> saving checkpoint 'drive/app/torch/save_Schedule/checkpoint_200.pth.tar'
# TEST : Loss: (0.4078) | Acc: (89.00%) (8906/10000)
percent tensor([0.5157, 0.5158, 0.5174, 0.5187, 0.5182, 0.5210, 0.5174, 0.5198, 0.5166,
        0.5157, 0.5147, 0.5161, 0.5149, 0.5183, 0.5167, 0.5167],
       device='cuda:0') torch.Size([16])
percent tensor([0.5264, 0.5391, 0.5218, 0.5218, 0.5188, 0.5351, 0.5296, 0.5178, 0.5259,
        0.5330, 0.5326, 0.5258, 0.5384, 0.5291, 0.5325, 0.5358],
       device='cuda:0') torch.Size([16])
percent tensor([0.6008, 0.5653, 0.6626, 0.6756, 0.6676, 0.6288, 0.6186, 0.6488, 0.6640,
        0.6179, 0.6543, 0.6434, 0.5272, 0.6865, 0.5952, 0.6123],
       device='cuda:0') torch.Size([16])
percent tensor([0.6778, 0.6713, 0.6591, 0.6601, 0.6659, 0.6718, 0.6808, 0.6687, 0.6696,
        0.6783, 0.6750, 0.6683, 0.6733, 0.6668, 0.6759, 0.6869],
       device='cuda:0') torch.Size([16])
percent tensor([0.6753, 0.6178, 0.6727, 0.6787, 0.6727, 0.7774, 0.6362, 0.6336, 0.6768,
        0.6843, 0.6091, 0.6279, 0.6555, 0.6814, 0.5916, 0.7564],
       device='cuda:0') torch.Size([16])
percent tensor([0.6308, 0.7127, 0.6607, 0.7056, 0.6629, 0.7611, 0.6827, 0.5168, 0.7176,
        0.6696, 0.7593, 0.6843, 0.7695, 0.7467, 0.5941, 0.6675],
       device='cuda:0') torch.Size([16])
percent tensor([0.5485, 0.6452, 0.6834, 0.6868, 0.7054, 0.6421, 0.6701, 0.6687, 0.6273,
        0.6741, 0.6785, 0.6364, 0.6023, 0.5824, 0.6227, 0.5615],
       device='cuda:0') torch.Size([16])
percent tensor([0.9999, 0.9999, 0.9997, 0.9998, 0.9996, 0.9994, 0.9997, 0.9996, 0.9997,
        0.9999, 0.9999, 0.9998, 0.9999, 0.9997, 0.9993, 0.9996],
       device='cuda:0') torch.Size([16])
Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 3, 3, 3]) tensor(181.4578, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(832.5029, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(833.4352, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([128, 64, 3, 3]) tensor(1511.6018, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([128, 64, 1, 1]) tensor(478.0447, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([128, 128, 3, 3]) tensor(2296.2781, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([256, 128, 3, 3]) tensor(4252.2339, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([256, 128, 1, 1]) tensor(1345.1639, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([256, 256, 3, 3]) tensor(6285.6992, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([512, 256, 3, 3]) tensor(11520.8701, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([512, 256, 1, 1]) tensor(3784.1267, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([512, 512, 3, 3]) tensor(15994.9365, device='cuda:0', grad_fn=<NormBackward0>)
Epoch: 201 | Batch_idx: 0 |  Loss: (0.0798) |  Loss2: (0.0000) | Acc: (97.00%) (125/128)
Epoch: 201 | Batch_idx: 10 |  Loss: (0.0834) |  Loss2: (0.0000) | Acc: (97.00%) (1372/1408)
Epoch: 201 | Batch_idx: 20 |  Loss: (0.0812) |  Loss2: (0.0000) | Acc: (97.00%) (2614/2688)
Epoch: 201 | Batch_idx: 30 |  Loss: (0.0835) |  Loss2: (0.0000) | Acc: (97.00%) (3856/3968)
Epoch: 201 | Batch_idx: 40 |  Loss: (0.0833) |  Loss2: (0.0000) | Acc: (97.00%) (5099/5248)
Epoch: 201 | Batch_idx: 50 |  Loss: (0.0783) |  Loss2: (0.0000) | Acc: (97.00%) (6358/6528)
Epoch: 201 | Batch_idx: 60 |  Loss: (0.0759) |  Loss2: (0.0000) | Acc: (97.00%) (7610/7808)
Epoch: 201 | Batch_idx: 70 |  Loss: (0.0762) |  Loss2: (0.0000) | Acc: (97.00%) (8862/9088)
Epoch: 201 | Batch_idx: 80 |  Loss: (0.0747) |  Loss2: (0.0000) | Acc: (97.00%) (10119/10368)
Epoch: 201 | Batch_idx: 90 |  Loss: (0.0748) |  Loss2: (0.0000) | Acc: (97.00%) (11363/11648)
Epoch: 201 | Batch_idx: 100 |  Loss: (0.0747) |  Loss2: (0.0000) | Acc: (97.00%) (12610/12928)
Epoch: 201 | Batch_idx: 110 |  Loss: (0.0750) |  Loss2: (0.0000) | Acc: (97.00%) (13851/14208)
Epoch: 201 | Batch_idx: 120 |  Loss: (0.0743) |  Loss2: (0.0000) | Acc: (97.00%) (15102/15488)
Epoch: 201 | Batch_idx: 130 |  Loss: (0.0747) |  Loss2: (0.0000) | Acc: (97.00%) (16346/16768)
Epoch: 201 | Batch_idx: 140 |  Loss: (0.0740) |  Loss2: (0.0000) | Acc: (97.00%) (17601/18048)
Epoch: 201 | Batch_idx: 150 |  Loss: (0.0736) |  Loss2: (0.0000) | Acc: (97.00%) (18863/19328)
Epoch: 201 | Batch_idx: 160 |  Loss: (0.0728) |  Loss2: (0.0000) | Acc: (97.00%) (20119/20608)
Epoch: 201 | Batch_idx: 170 |  Loss: (0.0726) |  Loss2: (0.0000) | Acc: (97.00%) (21375/21888)
Epoch: 201 | Batch_idx: 180 |  Loss: (0.0735) |  Loss2: (0.0000) | Acc: (97.00%) (22620/23168)
Epoch: 201 | Batch_idx: 190 |  Loss: (0.0738) |  Loss2: (0.0000) | Acc: (97.00%) (23862/24448)
Epoch: 201 | Batch_idx: 200 |  Loss: (0.0737) |  Loss2: (0.0000) | Acc: (97.00%) (25110/25728)
Epoch: 201 | Batch_idx: 210 |  Loss: (0.0735) |  Loss2: (0.0000) | Acc: (97.00%) (26359/27008)
Epoch: 201 | Batch_idx: 220 |  Loss: (0.0732) |  Loss2: (0.0000) | Acc: (97.00%) (27608/28288)
Epoch: 201 | Batch_idx: 230 |  Loss: (0.0729) |  Loss2: (0.0000) | Acc: (97.00%) (28857/29568)
Epoch: 201 | Batch_idx: 240 |  Loss: (0.0725) |  Loss2: (0.0000) | Acc: (97.00%) (30116/30848)
Epoch: 201 | Batch_idx: 250 |  Loss: (0.0724) |  Loss2: (0.0000) | Acc: (97.00%) (31367/32128)
Epoch: 201 | Batch_idx: 260 |  Loss: (0.0724) |  Loss2: (0.0000) | Acc: (97.00%) (32621/33408)
Epoch: 201 | Batch_idx: 270 |  Loss: (0.0729) |  Loss2: (0.0000) | Acc: (97.00%) (33858/34688)
Epoch: 201 | Batch_idx: 280 |  Loss: (0.0733) |  Loss2: (0.0000) | Acc: (97.00%) (35103/35968)
Epoch: 201 | Batch_idx: 290 |  Loss: (0.0729) |  Loss2: (0.0000) | Acc: (97.00%) (36364/37248)
Epoch: 201 | Batch_idx: 300 |  Loss: (0.0729) |  Loss2: (0.0000) | Acc: (97.00%) (37610/38528)
Epoch: 201 | Batch_idx: 310 |  Loss: (0.0734) |  Loss2: (0.0000) | Acc: (97.00%) (38854/39808)
Epoch: 201 | Batch_idx: 320 |  Loss: (0.0735) |  Loss2: (0.0000) | Acc: (97.00%) (40098/41088)
Epoch: 201 | Batch_idx: 330 |  Loss: (0.0738) |  Loss2: (0.0000) | Acc: (97.00%) (41343/42368)
Epoch: 201 | Batch_idx: 340 |  Loss: (0.0750) |  Loss2: (0.0000) | Acc: (97.00%) (42568/43648)
Epoch: 201 | Batch_idx: 350 |  Loss: (0.0750) |  Loss2: (0.0000) | Acc: (97.00%) (43808/44928)
Epoch: 201 | Batch_idx: 360 |  Loss: (0.0751) |  Loss2: (0.0000) | Acc: (97.00%) (45055/46208)
Epoch: 201 | Batch_idx: 370 |  Loss: (0.0755) |  Loss2: (0.0000) | Acc: (97.00%) (46293/47488)
Epoch: 201 | Batch_idx: 380 |  Loss: (0.0753) |  Loss2: (0.0000) | Acc: (97.00%) (47543/48768)
Epoch: 201 | Batch_idx: 390 |  Loss: (0.0754) |  Loss2: (0.0000) | Acc: (97.00%) (48744/50000)
# TEST : Loss: (0.4267) | Acc: (88.00%) (8818/10000)
percent tensor([0.5165, 0.5167, 0.5187, 0.5198, 0.5192, 0.5217, 0.5185, 0.5212, 0.5172,
        0.5166, 0.5153, 0.5173, 0.5157, 0.5189, 0.5178, 0.5175],
       device='cuda:0') torch.Size([16])
percent tensor([0.5272, 0.5390, 0.5268, 0.5225, 0.5219, 0.5360, 0.5306, 0.5173, 0.5268,
        0.5341, 0.5324, 0.5310, 0.5382, 0.5275, 0.5328, 0.5353],
       device='cuda:0') torch.Size([16])
percent tensor([0.6124, 0.5713, 0.6600, 0.6899, 0.6739, 0.6572, 0.6180, 0.6586, 0.6632,
        0.6136, 0.6556, 0.6329, 0.5334, 0.6879, 0.6106, 0.6279],
       device='cuda:0') torch.Size([16])
percent tensor([0.6762, 0.6686, 0.6601, 0.6591, 0.6638, 0.6712, 0.6774, 0.6674, 0.6713,
        0.6773, 0.6753, 0.6699, 0.6725, 0.6675, 0.6751, 0.6841],
       device='cuda:0') torch.Size([16])
percent tensor([0.6724, 0.6373, 0.7017, 0.6913, 0.6923, 0.7917, 0.6309, 0.6339, 0.6763,
        0.6842, 0.6141, 0.6520, 0.6639, 0.6862, 0.6241, 0.7583],
       device='cuda:0') torch.Size([16])
percent tensor([0.6382, 0.7226, 0.6749, 0.7196, 0.6742, 0.7618, 0.7020, 0.5419, 0.7316,
        0.6818, 0.7704, 0.6783, 0.7786, 0.7481, 0.5931, 0.6587],
       device='cuda:0') torch.Size([16])
percent tensor([0.5651, 0.6494, 0.6716, 0.6893, 0.7037, 0.6636, 0.6892, 0.6661, 0.6138,
        0.6780, 0.6726, 0.6104, 0.6150, 0.5884, 0.6140, 0.5661],
       device='cuda:0') torch.Size([16])
percent tensor([0.9999, 0.9998, 0.9997, 0.9998, 0.9995, 0.9994, 0.9997, 0.9994, 0.9998,
        0.9999, 0.9999, 0.9998, 0.9999, 0.9996, 0.9995, 0.9997],
       device='cuda:0') torch.Size([16])
Epoch: 202 | Batch_idx: 0 |  Loss: (0.0484) |  Loss2: (0.0000) | Acc: (98.00%) (126/128)
Epoch: 202 | Batch_idx: 10 |  Loss: (0.0568) |  Loss2: (0.0000) | Acc: (98.00%) (1384/1408)
Epoch: 202 | Batch_idx: 20 |  Loss: (0.0611) |  Loss2: (0.0000) | Acc: (98.00%) (2637/2688)
Epoch: 202 | Batch_idx: 30 |  Loss: (0.0644) |  Loss2: (0.0000) | Acc: (97.00%) (3883/3968)
Epoch: 202 | Batch_idx: 40 |  Loss: (0.0673) |  Loss2: (0.0000) | Acc: (97.00%) (5129/5248)
Epoch: 202 | Batch_idx: 50 |  Loss: (0.0704) |  Loss2: (0.0000) | Acc: (97.00%) (6368/6528)
Epoch: 202 | Batch_idx: 60 |  Loss: (0.0704) |  Loss2: (0.0000) | Acc: (97.00%) (7619/7808)
Epoch: 202 | Batch_idx: 70 |  Loss: (0.0701) |  Loss2: (0.0000) | Acc: (97.00%) (8867/9088)
Epoch: 202 | Batch_idx: 80 |  Loss: (0.0704) |  Loss2: (0.0000) | Acc: (97.00%) (10116/10368)
Epoch: 202 | Batch_idx: 90 |  Loss: (0.0717) |  Loss2: (0.0000) | Acc: (97.00%) (11360/11648)
Epoch: 202 | Batch_idx: 100 |  Loss: (0.0713) |  Loss2: (0.0000) | Acc: (97.00%) (12610/12928)
Epoch: 202 | Batch_idx: 110 |  Loss: (0.0709) |  Loss2: (0.0000) | Acc: (97.00%) (13858/14208)
Epoch: 202 | Batch_idx: 120 |  Loss: (0.0706) |  Loss2: (0.0000) | Acc: (97.00%) (15109/15488)
Epoch: 202 | Batch_idx: 130 |  Loss: (0.0711) |  Loss2: (0.0000) | Acc: (97.00%) (16357/16768)
Epoch: 202 | Batch_idx: 140 |  Loss: (0.0722) |  Loss2: (0.0000) | Acc: (97.00%) (17597/18048)
Epoch: 202 | Batch_idx: 150 |  Loss: (0.0714) |  Loss2: (0.0000) | Acc: (97.00%) (18847/19328)
Epoch: 202 | Batch_idx: 160 |  Loss: (0.0727) |  Loss2: (0.0000) | Acc: (97.00%) (20083/20608)
Epoch: 202 | Batch_idx: 170 |  Loss: (0.0736) |  Loss2: (0.0000) | Acc: (97.00%) (21322/21888)
Epoch: 202 | Batch_idx: 180 |  Loss: (0.0733) |  Loss2: (0.0000) | Acc: (97.00%) (22578/23168)
Epoch: 202 | Batch_idx: 190 |  Loss: (0.0736) |  Loss2: (0.0000) | Acc: (97.00%) (23825/24448)
Epoch: 202 | Batch_idx: 200 |  Loss: (0.0731) |  Loss2: (0.0000) | Acc: (97.00%) (25082/25728)
Epoch: 202 | Batch_idx: 210 |  Loss: (0.0726) |  Loss2: (0.0000) | Acc: (97.00%) (26333/27008)
Epoch: 202 | Batch_idx: 220 |  Loss: (0.0726) |  Loss2: (0.0000) | Acc: (97.00%) (27583/28288)
Epoch: 202 | Batch_idx: 230 |  Loss: (0.0723) |  Loss2: (0.0000) | Acc: (97.00%) (28832/29568)
Epoch: 202 | Batch_idx: 240 |  Loss: (0.0724) |  Loss2: (0.0000) | Acc: (97.00%) (30082/30848)
Epoch: 202 | Batch_idx: 250 |  Loss: (0.0725) |  Loss2: (0.0000) | Acc: (97.00%) (31332/32128)
Epoch: 202 | Batch_idx: 260 |  Loss: (0.0723) |  Loss2: (0.0000) | Acc: (97.00%) (32583/33408)
Epoch: 202 | Batch_idx: 270 |  Loss: (0.0725) |  Loss2: (0.0000) | Acc: (97.00%) (33830/34688)
Epoch: 202 | Batch_idx: 280 |  Loss: (0.0720) |  Loss2: (0.0000) | Acc: (97.00%) (35085/35968)
Epoch: 202 | Batch_idx: 290 |  Loss: (0.0722) |  Loss2: (0.0000) | Acc: (97.00%) (36329/37248)
Epoch: 202 | Batch_idx: 300 |  Loss: (0.0722) |  Loss2: (0.0000) | Acc: (97.00%) (37575/38528)
Epoch: 202 | Batch_idx: 310 |  Loss: (0.0718) |  Loss2: (0.0000) | Acc: (97.00%) (38832/39808)
Epoch: 202 | Batch_idx: 320 |  Loss: (0.0724) |  Loss2: (0.0000) | Acc: (97.00%) (40069/41088)
Epoch: 202 | Batch_idx: 330 |  Loss: (0.0721) |  Loss2: (0.0000) | Acc: (97.00%) (41324/42368)
Epoch: 202 | Batch_idx: 340 |  Loss: (0.0724) |  Loss2: (0.0000) | Acc: (97.00%) (42565/43648)
Epoch: 202 | Batch_idx: 350 |  Loss: (0.0722) |  Loss2: (0.0000) | Acc: (97.00%) (43818/44928)
Epoch: 202 | Batch_idx: 360 |  Loss: (0.0723) |  Loss2: (0.0000) | Acc: (97.00%) (45068/46208)
Epoch: 202 | Batch_idx: 370 |  Loss: (0.0721) |  Loss2: (0.0000) | Acc: (97.00%) (46316/47488)
Epoch: 202 | Batch_idx: 380 |  Loss: (0.0726) |  Loss2: (0.0000) | Acc: (97.00%) (47555/48768)
Epoch: 202 | Batch_idx: 390 |  Loss: (0.0726) |  Loss2: (0.0000) | Acc: (97.00%) (48756/50000)
# TEST : Loss: (0.4466) | Acc: (88.00%) (8825/10000)
percent tensor([0.5182, 0.5192, 0.5202, 0.5211, 0.5214, 0.5241, 0.5210, 0.5223, 0.5187,
        0.5185, 0.5169, 0.5191, 0.5173, 0.5215, 0.5199, 0.5192],
       device='cuda:0') torch.Size([16])
percent tensor([0.5262, 0.5405, 0.5228, 0.5221, 0.5186, 0.5368, 0.5302, 0.5166, 0.5243,
        0.5332, 0.5316, 0.5277, 0.5364, 0.5298, 0.5336, 0.5352],
       device='cuda:0') torch.Size([16])
percent tensor([0.6094, 0.5642, 0.6659, 0.6801, 0.6791, 0.6514, 0.6203, 0.6558, 0.6659,
        0.6190, 0.6542, 0.6456, 0.5324, 0.6815, 0.6033, 0.6235],
       device='cuda:0') torch.Size([16])
percent tensor([0.6750, 0.6710, 0.6630, 0.6608, 0.6624, 0.6688, 0.6764, 0.6665, 0.6685,
        0.6770, 0.6737, 0.6685, 0.6699, 0.6646, 0.6764, 0.6832],
       device='cuda:0') torch.Size([16])
percent tensor([0.6744, 0.6278, 0.6844, 0.6882, 0.6935, 0.7979, 0.6304, 0.6406, 0.6664,
        0.6819, 0.5987, 0.6460, 0.6517, 0.6793, 0.6235, 0.7570],
       device='cuda:0') torch.Size([16])
percent tensor([0.6350, 0.7266, 0.6874, 0.7019, 0.6579, 0.7550, 0.6889, 0.5244, 0.7401,
        0.6836, 0.7826, 0.6982, 0.7805, 0.7538, 0.5600, 0.6601],
       device='cuda:0') torch.Size([16])
percent tensor([0.5836, 0.6651, 0.6840, 0.6884, 0.6997, 0.6594, 0.6870, 0.6672, 0.6090,
        0.6771, 0.6755, 0.6284, 0.6389, 0.5841, 0.6178, 0.5763],
       device='cuda:0') torch.Size([16])
percent tensor([0.9999, 0.9998, 0.9998, 0.9999, 0.9995, 0.9992, 0.9996, 0.9997, 0.9997,
        0.9999, 0.9999, 0.9998, 0.9999, 0.9996, 0.9995, 0.9997],
       device='cuda:0') torch.Size([16])
Epoch: 203 | Batch_idx: 0 |  Loss: (0.0691) |  Loss2: (0.0000) | Acc: (96.00%) (124/128)
Epoch: 203 | Batch_idx: 10 |  Loss: (0.0620) |  Loss2: (0.0000) | Acc: (98.00%) (1383/1408)
Epoch: 203 | Batch_idx: 20 |  Loss: (0.0578) |  Loss2: (0.0000) | Acc: (98.00%) (2641/2688)
Epoch: 203 | Batch_idx: 30 |  Loss: (0.0595) |  Loss2: (0.0000) | Acc: (98.00%) (3895/3968)
Epoch: 203 | Batch_idx: 40 |  Loss: (0.0596) |  Loss2: (0.0000) | Acc: (98.00%) (5149/5248)
Epoch: 203 | Batch_idx: 50 |  Loss: (0.0589) |  Loss2: (0.0000) | Acc: (98.00%) (6411/6528)
Epoch: 203 | Batch_idx: 60 |  Loss: (0.0599) |  Loss2: (0.0000) | Acc: (98.00%) (7664/7808)
Epoch: 203 | Batch_idx: 70 |  Loss: (0.0628) |  Loss2: (0.0000) | Acc: (97.00%) (8905/9088)
Epoch: 203 | Batch_idx: 80 |  Loss: (0.0638) |  Loss2: (0.0000) | Acc: (97.00%) (10151/10368)
Epoch: 203 | Batch_idx: 90 |  Loss: (0.0635) |  Loss2: (0.0000) | Acc: (97.00%) (11406/11648)
Epoch: 203 | Batch_idx: 100 |  Loss: (0.0634) |  Loss2: (0.0000) | Acc: (97.00%) (12658/12928)
Epoch: 203 | Batch_idx: 110 |  Loss: (0.0630) |  Loss2: (0.0000) | Acc: (97.00%) (13912/14208)
Epoch: 203 | Batch_idx: 120 |  Loss: (0.0631) |  Loss2: (0.0000) | Acc: (97.00%) (15163/15488)
Epoch: 203 | Batch_idx: 130 |  Loss: (0.0637) |  Loss2: (0.0000) | Acc: (97.00%) (16408/16768)
Epoch: 203 | Batch_idx: 140 |  Loss: (0.0636) |  Loss2: (0.0000) | Acc: (97.00%) (17660/18048)
Epoch: 203 | Batch_idx: 150 |  Loss: (0.0647) |  Loss2: (0.0000) | Acc: (97.00%) (18909/19328)
Epoch: 203 | Batch_idx: 160 |  Loss: (0.0656) |  Loss2: (0.0000) | Acc: (97.00%) (20156/20608)
Epoch: 203 | Batch_idx: 170 |  Loss: (0.0660) |  Loss2: (0.0000) | Acc: (97.00%) (21399/21888)
Epoch: 203 | Batch_idx: 180 |  Loss: (0.0670) |  Loss2: (0.0000) | Acc: (97.00%) (22648/23168)
Epoch: 203 | Batch_idx: 190 |  Loss: (0.0680) |  Loss2: (0.0000) | Acc: (97.00%) (23888/24448)
Epoch: 203 | Batch_idx: 200 |  Loss: (0.0682) |  Loss2: (0.0000) | Acc: (97.00%) (25134/25728)
Epoch: 203 | Batch_idx: 210 |  Loss: (0.0679) |  Loss2: (0.0000) | Acc: (97.00%) (26392/27008)
Epoch: 203 | Batch_idx: 220 |  Loss: (0.0678) |  Loss2: (0.0000) | Acc: (97.00%) (27651/28288)
Epoch: 203 | Batch_idx: 230 |  Loss: (0.0682) |  Loss2: (0.0000) | Acc: (97.00%) (28899/29568)
Epoch: 203 | Batch_idx: 240 |  Loss: (0.0683) |  Loss2: (0.0000) | Acc: (97.00%) (30145/30848)
Epoch: 203 | Batch_idx: 250 |  Loss: (0.0684) |  Loss2: (0.0000) | Acc: (97.00%) (31392/32128)
Epoch: 203 | Batch_idx: 260 |  Loss: (0.0686) |  Loss2: (0.0000) | Acc: (97.00%) (32642/33408)
Epoch: 203 | Batch_idx: 270 |  Loss: (0.0686) |  Loss2: (0.0000) | Acc: (97.00%) (33892/34688)
Epoch: 203 | Batch_idx: 280 |  Loss: (0.0686) |  Loss2: (0.0000) | Acc: (97.00%) (35149/35968)
Epoch: 203 | Batch_idx: 290 |  Loss: (0.0687) |  Loss2: (0.0000) | Acc: (97.00%) (36398/37248)
Epoch: 203 | Batch_idx: 300 |  Loss: (0.0692) |  Loss2: (0.0000) | Acc: (97.00%) (37647/38528)
Epoch: 203 | Batch_idx: 310 |  Loss: (0.0691) |  Loss2: (0.0000) | Acc: (97.00%) (38894/39808)
Epoch: 203 | Batch_idx: 320 |  Loss: (0.0691) |  Loss2: (0.0000) | Acc: (97.00%) (40142/41088)
Epoch: 203 | Batch_idx: 330 |  Loss: (0.0701) |  Loss2: (0.0000) | Acc: (97.00%) (41369/42368)
Epoch: 203 | Batch_idx: 340 |  Loss: (0.0699) |  Loss2: (0.0000) | Acc: (97.00%) (42617/43648)
Epoch: 203 | Batch_idx: 350 |  Loss: (0.0699) |  Loss2: (0.0000) | Acc: (97.00%) (43874/44928)
Epoch: 203 | Batch_idx: 360 |  Loss: (0.0699) |  Loss2: (0.0000) | Acc: (97.00%) (45127/46208)
Epoch: 203 | Batch_idx: 370 |  Loss: (0.0700) |  Loss2: (0.0000) | Acc: (97.00%) (46373/47488)
Epoch: 203 | Batch_idx: 380 |  Loss: (0.0702) |  Loss2: (0.0000) | Acc: (97.00%) (47619/48768)
Epoch: 203 | Batch_idx: 390 |  Loss: (0.0707) |  Loss2: (0.0000) | Acc: (97.00%) (48812/50000)
# TEST : Loss: (0.4424) | Acc: (87.00%) (8789/10000)
percent tensor([0.5184, 0.5186, 0.5218, 0.5216, 0.5226, 0.5244, 0.5210, 0.5232, 0.5190,
        0.5189, 0.5170, 0.5203, 0.5177, 0.5202, 0.5201, 0.5193],
       device='cuda:0') torch.Size([16])
percent tensor([0.5266, 0.5396, 0.5242, 0.5217, 0.5195, 0.5350, 0.5307, 0.5188, 0.5252,
        0.5345, 0.5315, 0.5304, 0.5380, 0.5271, 0.5326, 0.5353],
       device='cuda:0') torch.Size([16])
percent tensor([0.6104, 0.5691, 0.6640, 0.6869, 0.6766, 0.6500, 0.6227, 0.6586, 0.6610,
        0.6118, 0.6501, 0.6365, 0.5270, 0.6912, 0.6090, 0.6247],
       device='cuda:0') torch.Size([16])
percent tensor([0.6770, 0.6703, 0.6612, 0.6611, 0.6654, 0.6687, 0.6795, 0.6692, 0.6679,
        0.6792, 0.6737, 0.6686, 0.6717, 0.6681, 0.6775, 0.6859],
       device='cuda:0') torch.Size([16])
percent tensor([0.6509, 0.6201, 0.6866, 0.6701, 0.6765, 0.7591, 0.6137, 0.6392, 0.6580,
        0.6672, 0.5928, 0.6382, 0.6457, 0.6690, 0.6043, 0.7396],
       device='cuda:0') torch.Size([16])
percent tensor([0.6499, 0.7334, 0.6825, 0.7058, 0.6829, 0.7768, 0.7169, 0.5297, 0.7511,
        0.7016, 0.7837, 0.6982, 0.7757, 0.7559, 0.5813, 0.6598],
       device='cuda:0') torch.Size([16])
percent tensor([0.5917, 0.6616, 0.6885, 0.6934, 0.7160, 0.6735, 0.6993, 0.6674, 0.6457,
        0.6888, 0.6770, 0.6440, 0.6383, 0.5782, 0.6053, 0.5813],
       device='cuda:0') torch.Size([16])
percent tensor([0.9999, 0.9998, 0.9998, 0.9999, 0.9996, 0.9989, 0.9998, 0.9996, 0.9998,
        0.9999, 0.9999, 0.9998, 0.9999, 0.9997, 0.9994, 0.9997],
       device='cuda:0') torch.Size([16])
Epoch: 204 | Batch_idx: 0 |  Loss: (0.0600) |  Loss2: (0.0000) | Acc: (96.00%) (124/128)
Epoch: 204 | Batch_idx: 10 |  Loss: (0.0831) |  Loss2: (0.0000) | Acc: (97.00%) (1370/1408)
Epoch: 204 | Batch_idx: 20 |  Loss: (0.0703) |  Loss2: (0.0000) | Acc: (97.00%) (2627/2688)
Epoch: 204 | Batch_idx: 30 |  Loss: (0.0683) |  Loss2: (0.0000) | Acc: (97.00%) (3878/3968)
Epoch: 204 | Batch_idx: 40 |  Loss: (0.0644) |  Loss2: (0.0000) | Acc: (97.00%) (5134/5248)
Epoch: 204 | Batch_idx: 50 |  Loss: (0.0626) |  Loss2: (0.0000) | Acc: (97.00%) (6390/6528)
Epoch: 204 | Batch_idx: 60 |  Loss: (0.0647) |  Loss2: (0.0000) | Acc: (97.00%) (7637/7808)
Epoch: 204 | Batch_idx: 70 |  Loss: (0.0643) |  Loss2: (0.0000) | Acc: (97.00%) (8888/9088)
Epoch: 204 | Batch_idx: 80 |  Loss: (0.0638) |  Loss2: (0.0000) | Acc: (97.00%) (10138/10368)
Epoch: 204 | Batch_idx: 90 |  Loss: (0.0641) |  Loss2: (0.0000) | Acc: (97.00%) (11386/11648)
Epoch: 204 | Batch_idx: 100 |  Loss: (0.0653) |  Loss2: (0.0000) | Acc: (97.00%) (12629/12928)
Epoch: 204 | Batch_idx: 110 |  Loss: (0.0663) |  Loss2: (0.0000) | Acc: (97.00%) (13879/14208)
Epoch: 204 | Batch_idx: 120 |  Loss: (0.0664) |  Loss2: (0.0000) | Acc: (97.00%) (15132/15488)
Epoch: 204 | Batch_idx: 130 |  Loss: (0.0656) |  Loss2: (0.0000) | Acc: (97.00%) (16394/16768)
Epoch: 204 | Batch_idx: 140 |  Loss: (0.0657) |  Loss2: (0.0000) | Acc: (97.00%) (17644/18048)
Epoch: 204 | Batch_idx: 150 |  Loss: (0.0667) |  Loss2: (0.0000) | Acc: (97.00%) (18887/19328)
Epoch: 204 | Batch_idx: 160 |  Loss: (0.0667) |  Loss2: (0.0000) | Acc: (97.00%) (20140/20608)
Epoch: 204 | Batch_idx: 170 |  Loss: (0.0659) |  Loss2: (0.0000) | Acc: (97.00%) (21401/21888)
Epoch: 204 | Batch_idx: 180 |  Loss: (0.0655) |  Loss2: (0.0000) | Acc: (97.00%) (22659/23168)
Epoch: 204 | Batch_idx: 190 |  Loss: (0.0653) |  Loss2: (0.0000) | Acc: (97.00%) (23912/24448)
Epoch: 204 | Batch_idx: 200 |  Loss: (0.0658) |  Loss2: (0.0000) | Acc: (97.00%) (25159/25728)
Epoch: 204 | Batch_idx: 210 |  Loss: (0.0655) |  Loss2: (0.0000) | Acc: (97.00%) (26409/27008)
Epoch: 204 | Batch_idx: 220 |  Loss: (0.0660) |  Loss2: (0.0000) | Acc: (97.00%) (27653/28288)
Epoch: 204 | Batch_idx: 230 |  Loss: (0.0669) |  Loss2: (0.0000) | Acc: (97.00%) (28894/29568)
Epoch: 204 | Batch_idx: 240 |  Loss: (0.0676) |  Loss2: (0.0000) | Acc: (97.00%) (30138/30848)
Epoch: 204 | Batch_idx: 250 |  Loss: (0.0674) |  Loss2: (0.0000) | Acc: (97.00%) (31395/32128)
Epoch: 204 | Batch_idx: 260 |  Loss: (0.0675) |  Loss2: (0.0000) | Acc: (97.00%) (32651/33408)
Epoch: 204 | Batch_idx: 270 |  Loss: (0.0667) |  Loss2: (0.0000) | Acc: (97.00%) (33917/34688)
Epoch: 204 | Batch_idx: 280 |  Loss: (0.0676) |  Loss2: (0.0000) | Acc: (97.00%) (35160/35968)
Epoch: 204 | Batch_idx: 290 |  Loss: (0.0676) |  Loss2: (0.0000) | Acc: (97.00%) (36408/37248)
Epoch: 204 | Batch_idx: 300 |  Loss: (0.0678) |  Loss2: (0.0000) | Acc: (97.00%) (37657/38528)
Epoch: 204 | Batch_idx: 310 |  Loss: (0.0679) |  Loss2: (0.0000) | Acc: (97.00%) (38906/39808)
Epoch: 204 | Batch_idx: 320 |  Loss: (0.0687) |  Loss2: (0.0000) | Acc: (97.00%) (40146/41088)
Epoch: 204 | Batch_idx: 330 |  Loss: (0.0684) |  Loss2: (0.0000) | Acc: (97.00%) (41403/42368)
Epoch: 204 | Batch_idx: 340 |  Loss: (0.0684) |  Loss2: (0.0000) | Acc: (97.00%) (42652/43648)
Epoch: 204 | Batch_idx: 350 |  Loss: (0.0686) |  Loss2: (0.0000) | Acc: (97.00%) (43895/44928)
Epoch: 204 | Batch_idx: 360 |  Loss: (0.0689) |  Loss2: (0.0000) | Acc: (97.00%) (45135/46208)
Epoch: 204 | Batch_idx: 370 |  Loss: (0.0688) |  Loss2: (0.0000) | Acc: (97.00%) (46388/47488)
Epoch: 204 | Batch_idx: 380 |  Loss: (0.0687) |  Loss2: (0.0000) | Acc: (97.00%) (47638/48768)
Epoch: 204 | Batch_idx: 390 |  Loss: (0.0689) |  Loss2: (0.0000) | Acc: (97.00%) (48841/50000)
# TEST : Loss: (0.4316) | Acc: (88.00%) (8842/10000)
percent tensor([0.5192, 0.5196, 0.5207, 0.5217, 0.5222, 0.5253, 0.5215, 0.5231, 0.5201,
        0.5191, 0.5182, 0.5200, 0.5185, 0.5211, 0.5209, 0.5199],
       device='cuda:0') torch.Size([16])
percent tensor([0.5275, 0.5381, 0.5260, 0.5218, 0.5211, 0.5370, 0.5302, 0.5173, 0.5268,
        0.5339, 0.5325, 0.5306, 0.5382, 0.5255, 0.5326, 0.5349],
       device='cuda:0') torch.Size([16])
percent tensor([0.6078, 0.5655, 0.6650, 0.6820, 0.6725, 0.6527, 0.6189, 0.6594, 0.6601,
        0.6136, 0.6469, 0.6337, 0.5293, 0.6821, 0.6061, 0.6174],
       device='cuda:0') torch.Size([16])
percent tensor([0.6731, 0.6707, 0.6554, 0.6571, 0.6618, 0.6665, 0.6786, 0.6661, 0.6671,
        0.6765, 0.6732, 0.6652, 0.6721, 0.6680, 0.6742, 0.6832],
       device='cuda:0') torch.Size([16])
percent tensor([0.6732, 0.6144, 0.6857, 0.6783, 0.7002, 0.7905, 0.6171, 0.6378, 0.6638,
        0.6784, 0.5907, 0.6464, 0.6650, 0.6399, 0.6157, 0.7528],
       device='cuda:0') torch.Size([16])
percent tensor([0.6295, 0.7236, 0.6787, 0.7089, 0.6652, 0.7522, 0.6830, 0.5196, 0.7269,
        0.7005, 0.7658, 0.7047, 0.7671, 0.7573, 0.5731, 0.6400],
       device='cuda:0') torch.Size([16])
percent tensor([0.5652, 0.6700, 0.6765, 0.6740, 0.7081, 0.6601, 0.6833, 0.6748, 0.6005,
        0.6704, 0.6773, 0.6211, 0.6083, 0.5738, 0.6135, 0.5770],
       device='cuda:0') torch.Size([16])
percent tensor([0.9999, 0.9998, 0.9998, 0.9999, 0.9997, 0.9986, 0.9999, 0.9998, 0.9998,
        0.9999, 0.9998, 0.9996, 0.9999, 0.9997, 0.9994, 0.9996],
       device='cuda:0') torch.Size([16])
Epoch: 205 | Batch_idx: 0 |  Loss: (0.0714) |  Loss2: (0.0000) | Acc: (98.00%) (126/128)
Epoch: 205 | Batch_idx: 10 |  Loss: (0.0595) |  Loss2: (0.0000) | Acc: (98.00%) (1384/1408)
Epoch: 205 | Batch_idx: 20 |  Loss: (0.0621) |  Loss2: (0.0000) | Acc: (97.00%) (2634/2688)
Epoch: 205 | Batch_idx: 30 |  Loss: (0.0635) |  Loss2: (0.0000) | Acc: (97.00%) (3880/3968)
Epoch: 205 | Batch_idx: 40 |  Loss: (0.0633) |  Loss2: (0.0000) | Acc: (97.00%) (5135/5248)
Epoch: 205 | Batch_idx: 50 |  Loss: (0.0639) |  Loss2: (0.0000) | Acc: (97.00%) (6386/6528)
Epoch: 205 | Batch_idx: 60 |  Loss: (0.0616) |  Loss2: (0.0000) | Acc: (97.00%) (7649/7808)
Epoch: 205 | Batch_idx: 70 |  Loss: (0.0622) |  Loss2: (0.0000) | Acc: (97.00%) (8899/9088)
Epoch: 205 | Batch_idx: 80 |  Loss: (0.0621) |  Loss2: (0.0000) | Acc: (97.00%) (10155/10368)
Epoch: 205 | Batch_idx: 90 |  Loss: (0.0625) |  Loss2: (0.0000) | Acc: (97.00%) (11411/11648)
Epoch: 205 | Batch_idx: 100 |  Loss: (0.0628) |  Loss2: (0.0000) | Acc: (97.00%) (12663/12928)
Epoch: 205 | Batch_idx: 110 |  Loss: (0.0630) |  Loss2: (0.0000) | Acc: (97.00%) (13918/14208)
Epoch: 205 | Batch_idx: 120 |  Loss: (0.0650) |  Loss2: (0.0000) | Acc: (97.00%) (15163/15488)
Epoch: 205 | Batch_idx: 130 |  Loss: (0.0652) |  Loss2: (0.0000) | Acc: (97.00%) (16414/16768)
Epoch: 205 | Batch_idx: 140 |  Loss: (0.0647) |  Loss2: (0.0000) | Acc: (97.00%) (17674/18048)
Epoch: 205 | Batch_idx: 150 |  Loss: (0.0648) |  Loss2: (0.0000) | Acc: (97.00%) (18928/19328)
Epoch: 205 | Batch_idx: 160 |  Loss: (0.0637) |  Loss2: (0.0000) | Acc: (97.00%) (20190/20608)
Epoch: 205 | Batch_idx: 170 |  Loss: (0.0641) |  Loss2: (0.0000) | Acc: (97.00%) (21446/21888)
Epoch: 205 | Batch_idx: 180 |  Loss: (0.0641) |  Loss2: (0.0000) | Acc: (97.00%) (22696/23168)
Epoch: 205 | Batch_idx: 190 |  Loss: (0.0636) |  Loss2: (0.0000) | Acc: (97.00%) (23954/24448)
Epoch: 205 | Batch_idx: 200 |  Loss: (0.0634) |  Loss2: (0.0000) | Acc: (97.00%) (25212/25728)
Epoch: 205 | Batch_idx: 210 |  Loss: (0.0629) |  Loss2: (0.0000) | Acc: (98.00%) (26469/27008)
Epoch: 205 | Batch_idx: 220 |  Loss: (0.0630) |  Loss2: (0.0000) | Acc: (98.00%) (27724/28288)
Epoch: 205 | Batch_idx: 230 |  Loss: (0.0632) |  Loss2: (0.0000) | Acc: (98.00%) (28978/29568)
Epoch: 205 | Batch_idx: 240 |  Loss: (0.0636) |  Loss2: (0.0000) | Acc: (97.00%) (30231/30848)
Epoch: 205 | Batch_idx: 250 |  Loss: (0.0634) |  Loss2: (0.0000) | Acc: (97.00%) (31483/32128)
Epoch: 205 | Batch_idx: 260 |  Loss: (0.0633) |  Loss2: (0.0000) | Acc: (97.00%) (32737/33408)
Epoch: 205 | Batch_idx: 270 |  Loss: (0.0634) |  Loss2: (0.0000) | Acc: (97.00%) (33991/34688)
Epoch: 205 | Batch_idx: 280 |  Loss: (0.0630) |  Loss2: (0.0000) | Acc: (98.00%) (35255/35968)
Epoch: 205 | Batch_idx: 290 |  Loss: (0.0632) |  Loss2: (0.0000) | Acc: (98.00%) (36504/37248)
Epoch: 205 | Batch_idx: 300 |  Loss: (0.0635) |  Loss2: (0.0000) | Acc: (97.00%) (37748/38528)
Epoch: 205 | Batch_idx: 310 |  Loss: (0.0633) |  Loss2: (0.0000) | Acc: (97.00%) (39005/39808)
Epoch: 205 | Batch_idx: 320 |  Loss: (0.0635) |  Loss2: (0.0000) | Acc: (97.00%) (40257/41088)
Epoch: 205 | Batch_idx: 330 |  Loss: (0.0635) |  Loss2: (0.0000) | Acc: (97.00%) (41514/42368)
Epoch: 205 | Batch_idx: 340 |  Loss: (0.0633) |  Loss2: (0.0000) | Acc: (97.00%) (42766/43648)
Epoch: 205 | Batch_idx: 350 |  Loss: (0.0637) |  Loss2: (0.0000) | Acc: (97.00%) (44014/44928)
Epoch: 205 | Batch_idx: 360 |  Loss: (0.0642) |  Loss2: (0.0000) | Acc: (97.00%) (45264/46208)
Epoch: 205 | Batch_idx: 370 |  Loss: (0.0644) |  Loss2: (0.0000) | Acc: (97.00%) (46516/47488)
Epoch: 205 | Batch_idx: 380 |  Loss: (0.0645) |  Loss2: (0.0000) | Acc: (97.00%) (47765/48768)
Epoch: 205 | Batch_idx: 390 |  Loss: (0.0646) |  Loss2: (0.0000) | Acc: (97.00%) (48973/50000)
=> saving checkpoint 'drive/app/torch/save_Schedule/checkpoint_205.pth.tar'
# TEST : Loss: (0.3952) | Acc: (89.00%) (8922/10000)
percent tensor([0.5193, 0.5196, 0.5216, 0.5226, 0.5227, 0.5264, 0.5217, 0.5239, 0.5201,
        0.5193, 0.5184, 0.5204, 0.5186, 0.5212, 0.5213, 0.5204],
       device='cuda:0') torch.Size([16])
percent tensor([0.5265, 0.5368, 0.5262, 0.5217, 0.5213, 0.5359, 0.5294, 0.5168, 0.5254,
        0.5326, 0.5311, 0.5303, 0.5368, 0.5244, 0.5322, 0.5344],
       device='cuda:0') torch.Size([16])
percent tensor([0.6066, 0.5668, 0.6660, 0.6880, 0.6728, 0.6487, 0.6149, 0.6596, 0.6621,
        0.6135, 0.6466, 0.6323, 0.5282, 0.6815, 0.6040, 0.6230],
       device='cuda:0') torch.Size([16])
percent tensor([0.6795, 0.6738, 0.6664, 0.6637, 0.6680, 0.6701, 0.6838, 0.6709, 0.6738,
        0.6834, 0.6771, 0.6748, 0.6768, 0.6709, 0.6766, 0.6884],
       device='cuda:0') torch.Size([16])
percent tensor([0.6776, 0.6218, 0.7083, 0.7123, 0.7076, 0.7976, 0.6312, 0.6483, 0.6778,
        0.6784, 0.6067, 0.6493, 0.6591, 0.6696, 0.6287, 0.7649],
       device='cuda:0') torch.Size([16])
percent tensor([0.6239, 0.7224, 0.6789, 0.7152, 0.6700, 0.7639, 0.6953, 0.5453, 0.7338,
        0.7007, 0.7724, 0.6970, 0.7696, 0.7598, 0.5853, 0.6480],
       device='cuda:0') torch.Size([16])
percent tensor([0.5655, 0.6776, 0.6775, 0.6610, 0.7083, 0.6432, 0.6970, 0.6587, 0.6510,
        0.6901, 0.6904, 0.6278, 0.6418, 0.6185, 0.6098, 0.5634],
       device='cuda:0') torch.Size([16])
percent tensor([0.9999, 0.9998, 0.9998, 0.9999, 0.9996, 0.9991, 0.9998, 0.9996, 0.9998,
        0.9999, 0.9999, 0.9998, 0.9999, 0.9996, 0.9994, 0.9996],
       device='cuda:0') torch.Size([16])
Epoch: 206 | Batch_idx: 0 |  Loss: (0.0319) |  Loss2: (0.0000) | Acc: (99.00%) (127/128)
Epoch: 206 | Batch_idx: 10 |  Loss: (0.0590) |  Loss2: (0.0000) | Acc: (97.00%) (1375/1408)
Epoch: 206 | Batch_idx: 20 |  Loss: (0.0633) |  Loss2: (0.0000) | Acc: (97.00%) (2627/2688)
Epoch: 206 | Batch_idx: 30 |  Loss: (0.0623) |  Loss2: (0.0000) | Acc: (97.00%) (3877/3968)
Epoch: 206 | Batch_idx: 40 |  Loss: (0.0616) |  Loss2: (0.0000) | Acc: (97.00%) (5132/5248)
Epoch: 206 | Batch_idx: 50 |  Loss: (0.0586) |  Loss2: (0.0000) | Acc: (97.00%) (6390/6528)
Epoch: 206 | Batch_idx: 60 |  Loss: (0.0567) |  Loss2: (0.0000) | Acc: (98.00%) (7652/7808)
Epoch: 206 | Batch_idx: 70 |  Loss: (0.0585) |  Loss2: (0.0000) | Acc: (97.00%) (8899/9088)
Epoch: 206 | Batch_idx: 80 |  Loss: (0.0590) |  Loss2: (0.0000) | Acc: (97.00%) (10150/10368)
Epoch: 206 | Batch_idx: 90 |  Loss: (0.0597) |  Loss2: (0.0000) | Acc: (97.00%) (11400/11648)
Epoch: 206 | Batch_idx: 100 |  Loss: (0.0610) |  Loss2: (0.0000) | Acc: (97.00%) (12651/12928)
Epoch: 206 | Batch_idx: 110 |  Loss: (0.0625) |  Loss2: (0.0000) | Acc: (97.00%) (13894/14208)
Epoch: 206 | Batch_idx: 120 |  Loss: (0.0637) |  Loss2: (0.0000) | Acc: (97.00%) (15132/15488)
Epoch: 206 | Batch_idx: 130 |  Loss: (0.0630) |  Loss2: (0.0000) | Acc: (97.00%) (16392/16768)
Epoch: 206 | Batch_idx: 140 |  Loss: (0.0631) |  Loss2: (0.0000) | Acc: (97.00%) (17645/18048)
Epoch: 206 | Batch_idx: 150 |  Loss: (0.0638) |  Loss2: (0.0000) | Acc: (97.00%) (18892/19328)
Epoch: 206 | Batch_idx: 160 |  Loss: (0.0650) |  Loss2: (0.0000) | Acc: (97.00%) (20134/20608)
Epoch: 206 | Batch_idx: 170 |  Loss: (0.0649) |  Loss2: (0.0000) | Acc: (97.00%) (21382/21888)
Epoch: 206 | Batch_idx: 180 |  Loss: (0.0646) |  Loss2: (0.0000) | Acc: (97.00%) (22637/23168)
Epoch: 206 | Batch_idx: 190 |  Loss: (0.0637) |  Loss2: (0.0000) | Acc: (97.00%) (23896/24448)
Epoch: 206 | Batch_idx: 200 |  Loss: (0.0637) |  Loss2: (0.0000) | Acc: (97.00%) (25151/25728)
Epoch: 206 | Batch_idx: 210 |  Loss: (0.0634) |  Loss2: (0.0000) | Acc: (97.00%) (26403/27008)
Epoch: 206 | Batch_idx: 220 |  Loss: (0.0637) |  Loss2: (0.0000) | Acc: (97.00%) (27652/28288)
Epoch: 206 | Batch_idx: 230 |  Loss: (0.0635) |  Loss2: (0.0000) | Acc: (97.00%) (28908/29568)
Epoch: 206 | Batch_idx: 240 |  Loss: (0.0637) |  Loss2: (0.0000) | Acc: (97.00%) (30157/30848)
Epoch: 206 | Batch_idx: 250 |  Loss: (0.0641) |  Loss2: (0.0000) | Acc: (97.00%) (31403/32128)
Epoch: 206 | Batch_idx: 260 |  Loss: (0.0645) |  Loss2: (0.0000) | Acc: (97.00%) (32646/33408)
Epoch: 206 | Batch_idx: 270 |  Loss: (0.0641) |  Loss2: (0.0000) | Acc: (97.00%) (33905/34688)
Epoch: 206 | Batch_idx: 280 |  Loss: (0.0641) |  Loss2: (0.0000) | Acc: (97.00%) (35153/35968)
Epoch: 206 | Batch_idx: 290 |  Loss: (0.0640) |  Loss2: (0.0000) | Acc: (97.00%) (36402/37248)
Epoch: 206 | Batch_idx: 300 |  Loss: (0.0638) |  Loss2: (0.0000) | Acc: (97.00%) (37655/38528)
Epoch: 206 | Batch_idx: 310 |  Loss: (0.0641) |  Loss2: (0.0000) | Acc: (97.00%) (38904/39808)
Epoch: 206 | Batch_idx: 320 |  Loss: (0.0639) |  Loss2: (0.0000) | Acc: (97.00%) (40160/41088)
Epoch: 206 | Batch_idx: 330 |  Loss: (0.0640) |  Loss2: (0.0000) | Acc: (97.00%) (41412/42368)
Epoch: 206 | Batch_idx: 340 |  Loss: (0.0638) |  Loss2: (0.0000) | Acc: (97.00%) (42671/43648)
Epoch: 206 | Batch_idx: 350 |  Loss: (0.0642) |  Loss2: (0.0000) | Acc: (97.00%) (43915/44928)
Epoch: 206 | Batch_idx: 360 |  Loss: (0.0645) |  Loss2: (0.0000) | Acc: (97.00%) (45157/46208)
Epoch: 206 | Batch_idx: 370 |  Loss: (0.0643) |  Loss2: (0.0000) | Acc: (97.00%) (46417/47488)
Epoch: 206 | Batch_idx: 380 |  Loss: (0.0644) |  Loss2: (0.0000) | Acc: (97.00%) (47676/48768)
Epoch: 206 | Batch_idx: 390 |  Loss: (0.0646) |  Loss2: (0.0000) | Acc: (97.00%) (48870/50000)
# TEST : Loss: (0.3987) | Acc: (89.00%) (8921/10000)
percent tensor([0.5201, 0.5207, 0.5218, 0.5236, 0.5233, 0.5268, 0.5225, 0.5247, 0.5212,
        0.5202, 0.5194, 0.5206, 0.5196, 0.5226, 0.5221, 0.5215],
       device='cuda:0') torch.Size([16])
percent tensor([0.5275, 0.5378, 0.5258, 0.5227, 0.5207, 0.5355, 0.5296, 0.5179, 0.5267,
        0.5337, 0.5311, 0.5308, 0.5386, 0.5251, 0.5325, 0.5350],
       device='cuda:0') torch.Size([16])
percent tensor([0.6044, 0.5577, 0.6639, 0.6827, 0.6710, 0.6242, 0.6162, 0.6618, 0.6603,
        0.6106, 0.6392, 0.6315, 0.5192, 0.6859, 0.5901, 0.6180],
       device='cuda:0') torch.Size([16])
percent tensor([0.6825, 0.6768, 0.6664, 0.6657, 0.6696, 0.6707, 0.6864, 0.6710, 0.6759,
        0.6852, 0.6796, 0.6775, 0.6787, 0.6736, 0.6790, 0.6909],
       device='cuda:0') torch.Size([16])
percent tensor([0.6703, 0.6257, 0.6758, 0.6917, 0.6908, 0.7913, 0.6318, 0.6312, 0.6751,
        0.6642, 0.5931, 0.6329, 0.6567, 0.6620, 0.6162, 0.7607],
       device='cuda:0') torch.Size([16])
percent tensor([0.6428, 0.7313, 0.6981, 0.7194, 0.6732, 0.7575, 0.7146, 0.5557, 0.7341,
        0.7005, 0.7822, 0.6973, 0.7711, 0.7592, 0.6110, 0.6512],
       device='cuda:0') torch.Size([16])
percent tensor([0.5806, 0.6506, 0.6839, 0.6925, 0.7102, 0.6658, 0.6871, 0.6732, 0.6300,
        0.6603, 0.6775, 0.6132, 0.6314, 0.5751, 0.6120, 0.5697],
       device='cuda:0') torch.Size([16])
percent tensor([0.9999, 0.9997, 0.9997, 0.9999, 0.9995, 0.9992, 0.9997, 0.9996, 0.9997,
        0.9999, 0.9999, 0.9998, 0.9999, 0.9994, 0.9994, 0.9997],
       device='cuda:0') torch.Size([16])
Epoch: 207 | Batch_idx: 0 |  Loss: (0.0510) |  Loss2: (0.0000) | Acc: (96.00%) (123/128)
Epoch: 207 | Batch_idx: 10 |  Loss: (0.0571) |  Loss2: (0.0000) | Acc: (97.00%) (1377/1408)
Epoch: 207 | Batch_idx: 20 |  Loss: (0.0611) |  Loss2: (0.0000) | Acc: (97.00%) (2629/2688)
Epoch: 207 | Batch_idx: 30 |  Loss: (0.0587) |  Loss2: (0.0000) | Acc: (97.00%) (3884/3968)
Epoch: 207 | Batch_idx: 40 |  Loss: (0.0582) |  Loss2: (0.0000) | Acc: (97.00%) (5139/5248)
Epoch: 207 | Batch_idx: 50 |  Loss: (0.0587) |  Loss2: (0.0000) | Acc: (97.00%) (6393/6528)
Epoch: 207 | Batch_idx: 60 |  Loss: (0.0604) |  Loss2: (0.0000) | Acc: (97.00%) (7645/7808)
Epoch: 207 | Batch_idx: 70 |  Loss: (0.0599) |  Loss2: (0.0000) | Acc: (97.00%) (8899/9088)
Epoch: 207 | Batch_idx: 80 |  Loss: (0.0609) |  Loss2: (0.0000) | Acc: (97.00%) (10146/10368)
Epoch: 207 | Batch_idx: 90 |  Loss: (0.0625) |  Loss2: (0.0000) | Acc: (97.00%) (11392/11648)
Epoch: 207 | Batch_idx: 100 |  Loss: (0.0620) |  Loss2: (0.0000) | Acc: (97.00%) (12646/12928)
Epoch: 207 | Batch_idx: 110 |  Loss: (0.0615) |  Loss2: (0.0000) | Acc: (97.00%) (13899/14208)
Epoch: 207 | Batch_idx: 120 |  Loss: (0.0619) |  Loss2: (0.0000) | Acc: (97.00%) (15152/15488)
Epoch: 207 | Batch_idx: 130 |  Loss: (0.0621) |  Loss2: (0.0000) | Acc: (97.00%) (16401/16768)
Epoch: 207 | Batch_idx: 140 |  Loss: (0.0616) |  Loss2: (0.0000) | Acc: (97.00%) (17657/18048)
Epoch: 207 | Batch_idx: 150 |  Loss: (0.0617) |  Loss2: (0.0000) | Acc: (97.00%) (18908/19328)
Epoch: 207 | Batch_idx: 160 |  Loss: (0.0619) |  Loss2: (0.0000) | Acc: (97.00%) (20155/20608)
Epoch: 207 | Batch_idx: 170 |  Loss: (0.0626) |  Loss2: (0.0000) | Acc: (97.00%) (21400/21888)
Epoch: 207 | Batch_idx: 180 |  Loss: (0.0623) |  Loss2: (0.0000) | Acc: (97.00%) (22654/23168)
Epoch: 207 | Batch_idx: 190 |  Loss: (0.0625) |  Loss2: (0.0000) | Acc: (97.00%) (23909/24448)
Epoch: 207 | Batch_idx: 200 |  Loss: (0.0626) |  Loss2: (0.0000) | Acc: (97.00%) (25163/25728)
Epoch: 207 | Batch_idx: 210 |  Loss: (0.0619) |  Loss2: (0.0000) | Acc: (97.00%) (26425/27008)
Epoch: 207 | Batch_idx: 220 |  Loss: (0.0619) |  Loss2: (0.0000) | Acc: (97.00%) (27678/28288)
Epoch: 207 | Batch_idx: 230 |  Loss: (0.0623) |  Loss2: (0.0000) | Acc: (97.00%) (28922/29568)
Epoch: 207 | Batch_idx: 240 |  Loss: (0.0626) |  Loss2: (0.0000) | Acc: (97.00%) (30168/30848)
Epoch: 207 | Batch_idx: 250 |  Loss: (0.0630) |  Loss2: (0.0000) | Acc: (97.00%) (31420/32128)
Epoch: 207 | Batch_idx: 260 |  Loss: (0.0634) |  Loss2: (0.0000) | Acc: (97.00%) (32669/33408)
Epoch: 207 | Batch_idx: 270 |  Loss: (0.0631) |  Loss2: (0.0000) | Acc: (97.00%) (33929/34688)
Epoch: 207 | Batch_idx: 280 |  Loss: (0.0632) |  Loss2: (0.0000) | Acc: (97.00%) (35179/35968)
Epoch: 207 | Batch_idx: 290 |  Loss: (0.0636) |  Loss2: (0.0000) | Acc: (97.00%) (36424/37248)
Epoch: 207 | Batch_idx: 300 |  Loss: (0.0632) |  Loss2: (0.0000) | Acc: (97.00%) (37687/38528)
Epoch: 207 | Batch_idx: 310 |  Loss: (0.0630) |  Loss2: (0.0000) | Acc: (97.00%) (38947/39808)
Epoch: 207 | Batch_idx: 320 |  Loss: (0.0633) |  Loss2: (0.0000) | Acc: (97.00%) (40190/41088)
Epoch: 207 | Batch_idx: 330 |  Loss: (0.0636) |  Loss2: (0.0000) | Acc: (97.00%) (41436/42368)
Epoch: 207 | Batch_idx: 340 |  Loss: (0.0637) |  Loss2: (0.0000) | Acc: (97.00%) (42685/43648)
Epoch: 207 | Batch_idx: 350 |  Loss: (0.0639) |  Loss2: (0.0000) | Acc: (97.00%) (43931/44928)
Epoch: 207 | Batch_idx: 360 |  Loss: (0.0638) |  Loss2: (0.0000) | Acc: (97.00%) (45186/46208)
Epoch: 207 | Batch_idx: 370 |  Loss: (0.0634) |  Loss2: (0.0000) | Acc: (97.00%) (46444/47488)
Epoch: 207 | Batch_idx: 380 |  Loss: (0.0641) |  Loss2: (0.0000) | Acc: (97.00%) (47690/48768)
Epoch: 207 | Batch_idx: 390 |  Loss: (0.0640) |  Loss2: (0.0000) | Acc: (97.00%) (48894/50000)
# TEST : Loss: (0.4447) | Acc: (87.00%) (8792/10000)
percent tensor([0.5211, 0.5209, 0.5237, 0.5237, 0.5249, 0.5275, 0.5234, 0.5253, 0.5220,
        0.5208, 0.5200, 0.5223, 0.5204, 0.5223, 0.5225, 0.5216],
       device='cuda:0') torch.Size([16])
percent tensor([0.5283, 0.5380, 0.5268, 0.5220, 0.5209, 0.5360, 0.5299, 0.5173, 0.5271,
        0.5333, 0.5315, 0.5311, 0.5384, 0.5256, 0.5325, 0.5355],
       device='cuda:0') torch.Size([16])
percent tensor([0.5992, 0.5554, 0.6617, 0.6830, 0.6679, 0.6218, 0.6133, 0.6607, 0.6550,
        0.6049, 0.6379, 0.6280, 0.5171, 0.6848, 0.5887, 0.6095],
       device='cuda:0') torch.Size([16])
percent tensor([0.6830, 0.6771, 0.6676, 0.6663, 0.6734, 0.6772, 0.6862, 0.6725, 0.6752,
        0.6838, 0.6801, 0.6782, 0.6791, 0.6714, 0.6803, 0.6910],
       device='cuda:0') torch.Size([16])
percent tensor([0.6833, 0.6260, 0.6940, 0.6806, 0.7012, 0.8050, 0.6366, 0.6390, 0.6812,
        0.6727, 0.6013, 0.6395, 0.6670, 0.6566, 0.6161, 0.7544],
       device='cuda:0') torch.Size([16])
percent tensor([0.6627, 0.7429, 0.6905, 0.7299, 0.6850, 0.7845, 0.7093, 0.5337, 0.7560,
        0.7236, 0.7994, 0.7120, 0.7960, 0.7641, 0.6461, 0.6777],
       device='cuda:0') torch.Size([16])
percent tensor([0.5659, 0.6687, 0.6810, 0.6852, 0.7160, 0.6570, 0.6898, 0.6643, 0.6496,
        0.6854, 0.6970, 0.6238, 0.6285, 0.5897, 0.6176, 0.5511],
       device='cuda:0') torch.Size([16])
percent tensor([0.9999, 0.9998, 0.9997, 0.9999, 0.9997, 0.9992, 0.9997, 0.9995, 0.9999,
        0.9999, 0.9999, 0.9997, 0.9999, 0.9996, 0.9994, 0.9997],
       device='cuda:0') torch.Size([16])
Epoch: 208 | Batch_idx: 0 |  Loss: (0.0720) |  Loss2: (0.0000) | Acc: (98.00%) (126/128)
Epoch: 208 | Batch_idx: 10 |  Loss: (0.0612) |  Loss2: (0.0000) | Acc: (98.00%) (1381/1408)
Epoch: 208 | Batch_idx: 20 |  Loss: (0.0566) |  Loss2: (0.0000) | Acc: (98.00%) (2646/2688)
Epoch: 208 | Batch_idx: 30 |  Loss: (0.0578) |  Loss2: (0.0000) | Acc: (98.00%) (3903/3968)
Epoch: 208 | Batch_idx: 40 |  Loss: (0.0585) |  Loss2: (0.0000) | Acc: (98.00%) (5155/5248)
Epoch: 208 | Batch_idx: 50 |  Loss: (0.0596) |  Loss2: (0.0000) | Acc: (98.00%) (6406/6528)
Epoch: 208 | Batch_idx: 60 |  Loss: (0.0596) |  Loss2: (0.0000) | Acc: (98.00%) (7664/7808)
Epoch: 208 | Batch_idx: 70 |  Loss: (0.0601) |  Loss2: (0.0000) | Acc: (98.00%) (8919/9088)
Epoch: 208 | Batch_idx: 80 |  Loss: (0.0598) |  Loss2: (0.0000) | Acc: (98.00%) (10177/10368)
Epoch: 208 | Batch_idx: 90 |  Loss: (0.0607) |  Loss2: (0.0000) | Acc: (98.00%) (11428/11648)
Epoch: 208 | Batch_idx: 100 |  Loss: (0.0613) |  Loss2: (0.0000) | Acc: (98.00%) (12680/12928)
Epoch: 208 | Batch_idx: 110 |  Loss: (0.0610) |  Loss2: (0.0000) | Acc: (98.00%) (13939/14208)
Epoch: 208 | Batch_idx: 120 |  Loss: (0.0610) |  Loss2: (0.0000) | Acc: (98.00%) (15196/15488)
Epoch: 208 | Batch_idx: 130 |  Loss: (0.0606) |  Loss2: (0.0000) | Acc: (98.00%) (16453/16768)
Epoch: 208 | Batch_idx: 140 |  Loss: (0.0606) |  Loss2: (0.0000) | Acc: (98.00%) (17711/18048)
Epoch: 208 | Batch_idx: 150 |  Loss: (0.0609) |  Loss2: (0.0000) | Acc: (98.00%) (18965/19328)
Epoch: 208 | Batch_idx: 160 |  Loss: (0.0609) |  Loss2: (0.0000) | Acc: (98.00%) (20223/20608)
Epoch: 208 | Batch_idx: 170 |  Loss: (0.0608) |  Loss2: (0.0000) | Acc: (98.00%) (21473/21888)
Epoch: 208 | Batch_idx: 180 |  Loss: (0.0611) |  Loss2: (0.0000) | Acc: (98.00%) (22725/23168)
Epoch: 208 | Batch_idx: 190 |  Loss: (0.0614) |  Loss2: (0.0000) | Acc: (98.00%) (23975/24448)
Epoch: 208 | Batch_idx: 200 |  Loss: (0.0615) |  Loss2: (0.0000) | Acc: (98.00%) (25223/25728)
Epoch: 208 | Batch_idx: 210 |  Loss: (0.0618) |  Loss2: (0.0000) | Acc: (98.00%) (26472/27008)
Epoch: 208 | Batch_idx: 220 |  Loss: (0.0619) |  Loss2: (0.0000) | Acc: (98.00%) (27724/28288)
Epoch: 208 | Batch_idx: 230 |  Loss: (0.0626) |  Loss2: (0.0000) | Acc: (97.00%) (28966/29568)
Epoch: 208 | Batch_idx: 240 |  Loss: (0.0621) |  Loss2: (0.0000) | Acc: (97.00%) (30227/30848)
Epoch: 208 | Batch_idx: 250 |  Loss: (0.0625) |  Loss2: (0.0000) | Acc: (97.00%) (31475/32128)
Epoch: 208 | Batch_idx: 260 |  Loss: (0.0626) |  Loss2: (0.0000) | Acc: (97.00%) (32730/33408)
Epoch: 208 | Batch_idx: 270 |  Loss: (0.0627) |  Loss2: (0.0000) | Acc: (97.00%) (33981/34688)
Epoch: 208 | Batch_idx: 280 |  Loss: (0.0627) |  Loss2: (0.0000) | Acc: (97.00%) (35232/35968)
Epoch: 208 | Batch_idx: 290 |  Loss: (0.0630) |  Loss2: (0.0000) | Acc: (97.00%) (36483/37248)
Epoch: 208 | Batch_idx: 300 |  Loss: (0.0632) |  Loss2: (0.0000) | Acc: (97.00%) (37734/38528)
Epoch: 208 | Batch_idx: 310 |  Loss: (0.0632) |  Loss2: (0.0000) | Acc: (97.00%) (38984/39808)
Epoch: 208 | Batch_idx: 320 |  Loss: (0.0635) |  Loss2: (0.0000) | Acc: (97.00%) (40235/41088)
Epoch: 208 | Batch_idx: 330 |  Loss: (0.0637) |  Loss2: (0.0000) | Acc: (97.00%) (41489/42368)
Epoch: 208 | Batch_idx: 340 |  Loss: (0.0642) |  Loss2: (0.0000) | Acc: (97.00%) (42732/43648)
Epoch: 208 | Batch_idx: 350 |  Loss: (0.0646) |  Loss2: (0.0000) | Acc: (97.00%) (43979/44928)
Epoch: 208 | Batch_idx: 360 |  Loss: (0.0646) |  Loss2: (0.0000) | Acc: (97.00%) (45230/46208)
Epoch: 208 | Batch_idx: 370 |  Loss: (0.0645) |  Loss2: (0.0000) | Acc: (97.00%) (46482/47488)
Epoch: 208 | Batch_idx: 380 |  Loss: (0.0648) |  Loss2: (0.0000) | Acc: (97.00%) (47728/48768)
Epoch: 208 | Batch_idx: 390 |  Loss: (0.0650) |  Loss2: (0.0000) | Acc: (97.00%) (48931/50000)
# TEST : Loss: (0.4196) | Acc: (88.00%) (8851/10000)
percent tensor([0.5220, 0.5225, 0.5243, 0.5247, 0.5255, 0.5279, 0.5248, 0.5267, 0.5231,
        0.5218, 0.5209, 0.5230, 0.5213, 0.5246, 0.5234, 0.5228],
       device='cuda:0') torch.Size([16])
percent tensor([0.5254, 0.5381, 0.5205, 0.5206, 0.5155, 0.5342, 0.5281, 0.5164, 0.5240,
        0.5311, 0.5302, 0.5255, 0.5361, 0.5265, 0.5320, 0.5339],
       device='cuda:0') torch.Size([16])
percent tensor([0.6111, 0.5608, 0.6731, 0.6907, 0.6796, 0.6471, 0.6196, 0.6603, 0.6614,
        0.6131, 0.6425, 0.6445, 0.5263, 0.6893, 0.6005, 0.6262],
       device='cuda:0') torch.Size([16])
percent tensor([0.6789, 0.6750, 0.6640, 0.6636, 0.6669, 0.6752, 0.6837, 0.6722, 0.6773,
        0.6814, 0.6779, 0.6763, 0.6774, 0.6721, 0.6790, 0.6883],
       device='cuda:0') torch.Size([16])
percent tensor([0.6417, 0.6053, 0.6514, 0.6710, 0.6651, 0.7762, 0.5991, 0.6150, 0.6516,
        0.6380, 0.5744, 0.6151, 0.6404, 0.6503, 0.5912, 0.7296],
       device='cuda:0') torch.Size([16])
percent tensor([0.6397, 0.7290, 0.6837, 0.7249, 0.6722, 0.7623, 0.7038, 0.5393, 0.7322,
        0.7049, 0.7872, 0.6955, 0.7815, 0.7431, 0.6065, 0.6552],
       device='cuda:0') torch.Size([16])
percent tensor([0.5703, 0.6598, 0.6736, 0.6766, 0.7037, 0.6681, 0.6837, 0.6481, 0.6093,
        0.6847, 0.6801, 0.6157, 0.6339, 0.5621, 0.6067, 0.5641],
       device='cuda:0') torch.Size([16])
percent tensor([0.9999, 0.9998, 0.9998, 0.9999, 0.9994, 0.9989, 0.9997, 0.9996, 0.9998,
        0.9999, 0.9999, 0.9995, 0.9998, 0.9996, 0.9995, 0.9997],
       device='cuda:0') torch.Size([16])
Epoch: 209 | Batch_idx: 0 |  Loss: (0.0301) |  Loss2: (0.0000) | Acc: (98.00%) (126/128)
Epoch: 209 | Batch_idx: 10 |  Loss: (0.0507) |  Loss2: (0.0000) | Acc: (98.00%) (1387/1408)
Epoch: 209 | Batch_idx: 20 |  Loss: (0.0584) |  Loss2: (0.0000) | Acc: (97.00%) (2634/2688)
Epoch: 209 | Batch_idx: 30 |  Loss: (0.0594) |  Loss2: (0.0000) | Acc: (98.00%) (3891/3968)
Epoch: 209 | Batch_idx: 40 |  Loss: (0.0611) |  Loss2: (0.0000) | Acc: (98.00%) (5144/5248)
Epoch: 209 | Batch_idx: 50 |  Loss: (0.0615) |  Loss2: (0.0000) | Acc: (98.00%) (6404/6528)
Epoch: 209 | Batch_idx: 60 |  Loss: (0.0587) |  Loss2: (0.0000) | Acc: (98.00%) (7668/7808)
Epoch: 209 | Batch_idx: 70 |  Loss: (0.0587) |  Loss2: (0.0000) | Acc: (98.00%) (8926/9088)
Epoch: 209 | Batch_idx: 80 |  Loss: (0.0579) |  Loss2: (0.0000) | Acc: (98.00%) (10184/10368)
Epoch: 209 | Batch_idx: 90 |  Loss: (0.0580) |  Loss2: (0.0000) | Acc: (98.00%) (11442/11648)
Epoch: 209 | Batch_idx: 100 |  Loss: (0.0583) |  Loss2: (0.0000) | Acc: (98.00%) (12702/12928)
Epoch: 209 | Batch_idx: 110 |  Loss: (0.0580) |  Loss2: (0.0000) | Acc: (98.00%) (13958/14208)
Epoch: 209 | Batch_idx: 120 |  Loss: (0.0582) |  Loss2: (0.0000) | Acc: (98.00%) (15214/15488)
Epoch: 209 | Batch_idx: 130 |  Loss: (0.0584) |  Loss2: (0.0000) | Acc: (98.00%) (16469/16768)
Epoch: 209 | Batch_idx: 140 |  Loss: (0.0591) |  Loss2: (0.0000) | Acc: (98.00%) (17718/18048)
Epoch: 209 | Batch_idx: 150 |  Loss: (0.0592) |  Loss2: (0.0000) | Acc: (98.00%) (18974/19328)
Epoch: 209 | Batch_idx: 160 |  Loss: (0.0591) |  Loss2: (0.0000) | Acc: (98.00%) (20229/20608)
Epoch: 209 | Batch_idx: 170 |  Loss: (0.0599) |  Loss2: (0.0000) | Acc: (98.00%) (21476/21888)
Epoch: 209 | Batch_idx: 180 |  Loss: (0.0596) |  Loss2: (0.0000) | Acc: (98.00%) (22730/23168)
Epoch: 209 | Batch_idx: 190 |  Loss: (0.0596) |  Loss2: (0.0000) | Acc: (98.00%) (23982/24448)
Epoch: 209 | Batch_idx: 200 |  Loss: (0.0606) |  Loss2: (0.0000) | Acc: (98.00%) (25229/25728)
Epoch: 209 | Batch_idx: 210 |  Loss: (0.0604) |  Loss2: (0.0000) | Acc: (98.00%) (26485/27008)
Epoch: 209 | Batch_idx: 220 |  Loss: (0.0608) |  Loss2: (0.0000) | Acc: (98.00%) (27738/28288)
Epoch: 209 | Batch_idx: 230 |  Loss: (0.0609) |  Loss2: (0.0000) | Acc: (98.00%) (28991/29568)
Epoch: 209 | Batch_idx: 240 |  Loss: (0.0609) |  Loss2: (0.0000) | Acc: (98.00%) (30246/30848)
Epoch: 209 | Batch_idx: 250 |  Loss: (0.0610) |  Loss2: (0.0000) | Acc: (98.00%) (31503/32128)
Epoch: 209 | Batch_idx: 260 |  Loss: (0.0609) |  Loss2: (0.0000) | Acc: (98.00%) (32753/33408)
Epoch: 209 | Batch_idx: 270 |  Loss: (0.0609) |  Loss2: (0.0000) | Acc: (98.00%) (34004/34688)
Epoch: 209 | Batch_idx: 280 |  Loss: (0.0605) |  Loss2: (0.0000) | Acc: (98.00%) (35261/35968)
Epoch: 209 | Batch_idx: 290 |  Loss: (0.0601) |  Loss2: (0.0000) | Acc: (98.00%) (36521/37248)
Epoch: 209 | Batch_idx: 300 |  Loss: (0.0602) |  Loss2: (0.0000) | Acc: (98.00%) (37775/38528)
Epoch: 209 | Batch_idx: 310 |  Loss: (0.0597) |  Loss2: (0.0000) | Acc: (98.00%) (39040/39808)
Epoch: 209 | Batch_idx: 320 |  Loss: (0.0598) |  Loss2: (0.0000) | Acc: (98.00%) (40294/41088)
Epoch: 209 | Batch_idx: 330 |  Loss: (0.0595) |  Loss2: (0.0000) | Acc: (98.00%) (41558/42368)
Epoch: 209 | Batch_idx: 340 |  Loss: (0.0598) |  Loss2: (0.0000) | Acc: (98.00%) (42811/43648)
Epoch: 209 | Batch_idx: 350 |  Loss: (0.0601) |  Loss2: (0.0000) | Acc: (98.00%) (44054/44928)
Epoch: 209 | Batch_idx: 360 |  Loss: (0.0602) |  Loss2: (0.0000) | Acc: (98.00%) (45310/46208)
Epoch: 209 | Batch_idx: 370 |  Loss: (0.0603) |  Loss2: (0.0000) | Acc: (98.00%) (46564/47488)
Epoch: 209 | Batch_idx: 380 |  Loss: (0.0605) |  Loss2: (0.0000) | Acc: (98.00%) (47806/48768)
Epoch: 209 | Batch_idx: 390 |  Loss: (0.0607) |  Loss2: (0.0000) | Acc: (98.00%) (49007/50000)
# TEST : Loss: (0.4481) | Acc: (87.00%) (8798/10000)
percent tensor([0.5233, 0.5240, 0.5266, 0.5265, 0.5272, 0.5293, 0.5264, 0.5285, 0.5242,
        0.5234, 0.5219, 0.5250, 0.5226, 0.5255, 0.5247, 0.5241],
       device='cuda:0') torch.Size([16])
percent tensor([0.5278, 0.5408, 0.5247, 0.5211, 0.5190, 0.5348, 0.5315, 0.5172, 0.5263,
        0.5339, 0.5330, 0.5299, 0.5384, 0.5278, 0.5340, 0.5352],
       device='cuda:0') torch.Size([16])
percent tensor([0.6041, 0.5567, 0.6630, 0.6852, 0.6707, 0.6431, 0.6130, 0.6588, 0.6545,
        0.6065, 0.6376, 0.6276, 0.5184, 0.6888, 0.5970, 0.6197],
       device='cuda:0') torch.Size([16])
percent tensor([0.6812, 0.6768, 0.6698, 0.6675, 0.6714, 0.6720, 0.6868, 0.6757, 0.6779,
        0.6837, 0.6781, 0.6782, 0.6783, 0.6740, 0.6799, 0.6893],
       device='cuda:0') torch.Size([16])
percent tensor([0.6545, 0.6160, 0.6772, 0.6817, 0.6827, 0.7798, 0.6155, 0.6209, 0.6603,
        0.6686, 0.5799, 0.6397, 0.6567, 0.6548, 0.6045, 0.7301],
       device='cuda:0') torch.Size([16])
percent tensor([0.6581, 0.7479, 0.6803, 0.7176, 0.6591, 0.7685, 0.7205, 0.5262, 0.7412,
        0.7241, 0.7993, 0.6971, 0.7904, 0.7898, 0.6062, 0.6643],
       device='cuda:0') torch.Size([16])
percent tensor([0.5663, 0.6627, 0.6530, 0.6881, 0.6886, 0.6643, 0.6726, 0.6367, 0.6149,
        0.6987, 0.6898, 0.6077, 0.6291, 0.5906, 0.6002, 0.5754],
       device='cuda:0') torch.Size([16])
percent tensor([0.9999, 0.9998, 0.9998, 0.9999, 0.9996, 0.9993, 0.9998, 0.9994, 0.9998,
        0.9999, 0.9999, 0.9998, 0.9999, 0.9996, 0.9995, 0.9998],
       device='cuda:0') torch.Size([16])
Epoch: 210 | Batch_idx: 0 |  Loss: (0.0567) |  Loss2: (0.0000) | Acc: (99.00%) (127/128)
Epoch: 210 | Batch_idx: 10 |  Loss: (0.0560) |  Loss2: (0.0000) | Acc: (98.00%) (1384/1408)
Epoch: 210 | Batch_idx: 20 |  Loss: (0.0541) |  Loss2: (0.0000) | Acc: (98.00%) (2644/2688)
Epoch: 210 | Batch_idx: 30 |  Loss: (0.0578) |  Loss2: (0.0000) | Acc: (98.00%) (3893/3968)
Epoch: 210 | Batch_idx: 40 |  Loss: (0.0597) |  Loss2: (0.0000) | Acc: (98.00%) (5147/5248)
Epoch: 210 | Batch_idx: 50 |  Loss: (0.0593) |  Loss2: (0.0000) | Acc: (98.00%) (6404/6528)
Epoch: 210 | Batch_idx: 60 |  Loss: (0.0579) |  Loss2: (0.0000) | Acc: (98.00%) (7665/7808)
Epoch: 210 | Batch_idx: 70 |  Loss: (0.0580) |  Loss2: (0.0000) | Acc: (98.00%) (8914/9088)
Epoch: 210 | Batch_idx: 80 |  Loss: (0.0580) |  Loss2: (0.0000) | Acc: (98.00%) (10169/10368)
Epoch: 210 | Batch_idx: 90 |  Loss: (0.0583) |  Loss2: (0.0000) | Acc: (98.00%) (11425/11648)
Epoch: 210 | Batch_idx: 100 |  Loss: (0.0583) |  Loss2: (0.0000) | Acc: (98.00%) (12683/12928)
Epoch: 210 | Batch_idx: 110 |  Loss: (0.0580) |  Loss2: (0.0000) | Acc: (98.00%) (13940/14208)
Epoch: 210 | Batch_idx: 120 |  Loss: (0.0575) |  Loss2: (0.0000) | Acc: (98.00%) (15195/15488)
Epoch: 210 | Batch_idx: 130 |  Loss: (0.0572) |  Loss2: (0.0000) | Acc: (98.00%) (16451/16768)
Epoch: 210 | Batch_idx: 140 |  Loss: (0.0570) |  Loss2: (0.0000) | Acc: (98.00%) (17710/18048)
Epoch: 210 | Batch_idx: 150 |  Loss: (0.0562) |  Loss2: (0.0000) | Acc: (98.00%) (18973/19328)
Epoch: 210 | Batch_idx: 160 |  Loss: (0.0566) |  Loss2: (0.0000) | Acc: (98.00%) (20228/20608)
Epoch: 210 | Batch_idx: 170 |  Loss: (0.0567) |  Loss2: (0.0000) | Acc: (98.00%) (21478/21888)
Epoch: 210 | Batch_idx: 180 |  Loss: (0.0568) |  Loss2: (0.0000) | Acc: (98.00%) (22736/23168)
Epoch: 210 | Batch_idx: 190 |  Loss: (0.0577) |  Loss2: (0.0000) | Acc: (98.00%) (23986/24448)
Epoch: 210 | Batch_idx: 200 |  Loss: (0.0580) |  Loss2: (0.0000) | Acc: (98.00%) (25237/25728)
Epoch: 210 | Batch_idx: 210 |  Loss: (0.0571) |  Loss2: (0.0000) | Acc: (98.00%) (26506/27008)
Epoch: 210 | Batch_idx: 220 |  Loss: (0.0569) |  Loss2: (0.0000) | Acc: (98.00%) (27766/28288)
Epoch: 210 | Batch_idx: 230 |  Loss: (0.0563) |  Loss2: (0.0000) | Acc: (98.00%) (29028/29568)
Epoch: 210 | Batch_idx: 240 |  Loss: (0.0560) |  Loss2: (0.0000) | Acc: (98.00%) (30288/30848)
Epoch: 210 | Batch_idx: 250 |  Loss: (0.0560) |  Loss2: (0.0000) | Acc: (98.00%) (31544/32128)
Epoch: 210 | Batch_idx: 260 |  Loss: (0.0562) |  Loss2: (0.0000) | Acc: (98.00%) (32799/33408)
Epoch: 210 | Batch_idx: 270 |  Loss: (0.0565) |  Loss2: (0.0000) | Acc: (98.00%) (34050/34688)
Epoch: 210 | Batch_idx: 280 |  Loss: (0.0570) |  Loss2: (0.0000) | Acc: (98.00%) (35302/35968)
Epoch: 210 | Batch_idx: 290 |  Loss: (0.0571) |  Loss2: (0.0000) | Acc: (98.00%) (36556/37248)
Epoch: 210 | Batch_idx: 300 |  Loss: (0.0575) |  Loss2: (0.0000) | Acc: (98.00%) (37806/38528)
Epoch: 210 | Batch_idx: 310 |  Loss: (0.0582) |  Loss2: (0.0000) | Acc: (98.00%) (39055/39808)
Epoch: 210 | Batch_idx: 320 |  Loss: (0.0583) |  Loss2: (0.0000) | Acc: (98.00%) (40308/41088)
Epoch: 210 | Batch_idx: 330 |  Loss: (0.0586) |  Loss2: (0.0000) | Acc: (98.00%) (41559/42368)
Epoch: 210 | Batch_idx: 340 |  Loss: (0.0591) |  Loss2: (0.0000) | Acc: (98.00%) (42801/43648)
Epoch: 210 | Batch_idx: 350 |  Loss: (0.0591) |  Loss2: (0.0000) | Acc: (98.00%) (44059/44928)
Epoch: 210 | Batch_idx: 360 |  Loss: (0.0591) |  Loss2: (0.0000) | Acc: (98.00%) (45317/46208)
Epoch: 210 | Batch_idx: 370 |  Loss: (0.0592) |  Loss2: (0.0000) | Acc: (98.00%) (46574/47488)
Epoch: 210 | Batch_idx: 380 |  Loss: (0.0597) |  Loss2: (0.0000) | Acc: (98.00%) (47819/48768)
Epoch: 210 | Batch_idx: 390 |  Loss: (0.0602) |  Loss2: (0.0000) | Acc: (98.00%) (49012/50000)
=> saving checkpoint 'drive/app/torch/save_Schedule/checkpoint_210.pth.tar'
# TEST : Loss: (0.4305) | Acc: (88.00%) (8897/10000)
percent tensor([0.5234, 0.5243, 0.5253, 0.5262, 0.5270, 0.5299, 0.5262, 0.5280, 0.5245,
        0.5230, 0.5225, 0.5239, 0.5228, 0.5256, 0.5254, 0.5243],
       device='cuda:0') torch.Size([16])
percent tensor([0.5265, 0.5378, 0.5241, 0.5207, 0.5189, 0.5367, 0.5289, 0.5169, 0.5244,
        0.5320, 0.5308, 0.5278, 0.5370, 0.5247, 0.5327, 0.5342],
       device='cuda:0') torch.Size([16])
percent tensor([0.6075, 0.5605, 0.6641, 0.6840, 0.6739, 0.6377, 0.6191, 0.6617, 0.6588,
        0.6059, 0.6445, 0.6348, 0.5226, 0.6845, 0.6002, 0.6208],
       device='cuda:0') torch.Size([16])
percent tensor([0.6766, 0.6727, 0.6638, 0.6594, 0.6658, 0.6676, 0.6830, 0.6698, 0.6743,
        0.6808, 0.6744, 0.6728, 0.6750, 0.6704, 0.6748, 0.6848],
       device='cuda:0') torch.Size([16])
percent tensor([0.6699, 0.6349, 0.6851, 0.6993, 0.7056, 0.8053, 0.6358, 0.6401, 0.6729,
        0.6659, 0.6078, 0.6374, 0.6611, 0.6619, 0.6325, 0.7545],
       device='cuda:0') torch.Size([16])
percent tensor([0.6827, 0.7390, 0.7117, 0.7439, 0.7080, 0.7965, 0.7346, 0.5558, 0.7454,
        0.7198, 0.8017, 0.7136, 0.7874, 0.7752, 0.6227, 0.6881],
       device='cuda:0') torch.Size([16])
percent tensor([0.5880, 0.6863, 0.6834, 0.7025, 0.6961, 0.6768, 0.6945, 0.6650, 0.6459,
        0.7111, 0.7316, 0.6247, 0.6512, 0.5993, 0.6094, 0.5658],
       device='cuda:0') torch.Size([16])
percent tensor([0.9999, 0.9999, 0.9998, 0.9999, 0.9995, 0.9989, 0.9998, 0.9997, 0.9999,
        1.0000, 1.0000, 0.9997, 0.9999, 0.9997, 0.9993, 0.9998],
       device='cuda:0') torch.Size([16])
Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 3, 3, 3]) tensor(182.4122, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(835.9041, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(837.7997, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([128, 64, 3, 3]) tensor(1513.2710, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([128, 64, 1, 1]) tensor(476.4162, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([128, 128, 3, 3]) tensor(2309.4709, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([256, 128, 3, 3]) tensor(4258.2900, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([256, 128, 1, 1]) tensor(1340.5361, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([256, 256, 3, 3]) tensor(6321.1621, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([512, 256, 3, 3]) tensor(11495.8154, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([512, 256, 1, 1]) tensor(3769.6086, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([512, 512, 3, 3]) tensor(15930.1475, device='cuda:0', grad_fn=<NormBackward0>)
Epoch: 211 | Batch_idx: 0 |  Loss: (0.0847) |  Loss2: (0.0000) | Acc: (96.00%) (124/128)
Epoch: 211 | Batch_idx: 10 |  Loss: (0.0524) |  Loss2: (0.0000) | Acc: (98.00%) (1383/1408)
Epoch: 211 | Batch_idx: 20 |  Loss: (0.0469) |  Loss2: (0.0000) | Acc: (98.00%) (2649/2688)
Epoch: 211 | Batch_idx: 30 |  Loss: (0.0474) |  Loss2: (0.0000) | Acc: (98.00%) (3911/3968)
Epoch: 211 | Batch_idx: 40 |  Loss: (0.0487) |  Loss2: (0.0000) | Acc: (98.00%) (5171/5248)
Epoch: 211 | Batch_idx: 50 |  Loss: (0.0477) |  Loss2: (0.0000) | Acc: (98.00%) (6431/6528)
Epoch: 211 | Batch_idx: 60 |  Loss: (0.0479) |  Loss2: (0.0000) | Acc: (98.00%) (7693/7808)
Epoch: 211 | Batch_idx: 70 |  Loss: (0.0485) |  Loss2: (0.0000) | Acc: (98.00%) (8953/9088)
Epoch: 211 | Batch_idx: 80 |  Loss: (0.0491) |  Loss2: (0.0000) | Acc: (98.00%) (10212/10368)
Epoch: 211 | Batch_idx: 90 |  Loss: (0.0502) |  Loss2: (0.0000) | Acc: (98.00%) (11466/11648)
Epoch: 211 | Batch_idx: 100 |  Loss: (0.0499) |  Loss2: (0.0000) | Acc: (98.00%) (12729/12928)
Epoch: 211 | Batch_idx: 110 |  Loss: (0.0518) |  Loss2: (0.0000) | Acc: (98.00%) (13981/14208)
Epoch: 211 | Batch_idx: 120 |  Loss: (0.0521) |  Loss2: (0.0000) | Acc: (98.00%) (15235/15488)
Epoch: 211 | Batch_idx: 130 |  Loss: (0.0523) |  Loss2: (0.0000) | Acc: (98.00%) (16495/16768)
Epoch: 211 | Batch_idx: 140 |  Loss: (0.0530) |  Loss2: (0.0000) | Acc: (98.00%) (17749/18048)
Epoch: 211 | Batch_idx: 150 |  Loss: (0.0530) |  Loss2: (0.0000) | Acc: (98.00%) (19005/19328)
Epoch: 211 | Batch_idx: 160 |  Loss: (0.0537) |  Loss2: (0.0000) | Acc: (98.00%) (20257/20608)
Epoch: 211 | Batch_idx: 170 |  Loss: (0.0539) |  Loss2: (0.0000) | Acc: (98.00%) (21518/21888)
Epoch: 211 | Batch_idx: 180 |  Loss: (0.0543) |  Loss2: (0.0000) | Acc: (98.00%) (22769/23168)
Epoch: 211 | Batch_idx: 190 |  Loss: (0.0543) |  Loss2: (0.0000) | Acc: (98.00%) (24030/24448)
Epoch: 211 | Batch_idx: 200 |  Loss: (0.0545) |  Loss2: (0.0000) | Acc: (98.00%) (25287/25728)
Epoch: 211 | Batch_idx: 210 |  Loss: (0.0543) |  Loss2: (0.0000) | Acc: (98.00%) (26548/27008)
Epoch: 211 | Batch_idx: 220 |  Loss: (0.0546) |  Loss2: (0.0000) | Acc: (98.00%) (27801/28288)
Epoch: 211 | Batch_idx: 230 |  Loss: (0.0549) |  Loss2: (0.0000) | Acc: (98.00%) (29060/29568)
Epoch: 211 | Batch_idx: 240 |  Loss: (0.0548) |  Loss2: (0.0000) | Acc: (98.00%) (30317/30848)
Epoch: 211 | Batch_idx: 250 |  Loss: (0.0551) |  Loss2: (0.0000) | Acc: (98.00%) (31569/32128)
Epoch: 211 | Batch_idx: 260 |  Loss: (0.0557) |  Loss2: (0.0000) | Acc: (98.00%) (32824/33408)
Epoch: 211 | Batch_idx: 270 |  Loss: (0.0566) |  Loss2: (0.0000) | Acc: (98.00%) (34063/34688)
Epoch: 211 | Batch_idx: 280 |  Loss: (0.0570) |  Loss2: (0.0000) | Acc: (98.00%) (35314/35968)
Epoch: 211 | Batch_idx: 290 |  Loss: (0.0571) |  Loss2: (0.0000) | Acc: (98.00%) (36568/37248)
Epoch: 211 | Batch_idx: 300 |  Loss: (0.0575) |  Loss2: (0.0000) | Acc: (98.00%) (37822/38528)
Epoch: 211 | Batch_idx: 310 |  Loss: (0.0575) |  Loss2: (0.0000) | Acc: (98.00%) (39076/39808)
Epoch: 211 | Batch_idx: 320 |  Loss: (0.0585) |  Loss2: (0.0000) | Acc: (98.00%) (40314/41088)
Epoch: 211 | Batch_idx: 330 |  Loss: (0.0586) |  Loss2: (0.0000) | Acc: (98.00%) (41570/42368)
Epoch: 211 | Batch_idx: 340 |  Loss: (0.0593) |  Loss2: (0.0000) | Acc: (98.00%) (42811/43648)
Epoch: 211 | Batch_idx: 350 |  Loss: (0.0592) |  Loss2: (0.0000) | Acc: (98.00%) (44067/44928)
Epoch: 211 | Batch_idx: 360 |  Loss: (0.0598) |  Loss2: (0.0000) | Acc: (98.00%) (45308/46208)
Epoch: 211 | Batch_idx: 370 |  Loss: (0.0604) |  Loss2: (0.0000) | Acc: (98.00%) (46549/47488)
Epoch: 211 | Batch_idx: 380 |  Loss: (0.0605) |  Loss2: (0.0000) | Acc: (98.00%) (47797/48768)
Epoch: 211 | Batch_idx: 390 |  Loss: (0.0602) |  Loss2: (0.0000) | Acc: (98.00%) (49014/50000)
# TEST : Loss: (0.4028) | Acc: (88.00%) (8898/10000)
percent tensor([0.5239, 0.5241, 0.5261, 0.5268, 0.5277, 0.5291, 0.5262, 0.5286, 0.5248,
        0.5234, 0.5228, 0.5245, 0.5234, 0.5252, 0.5252, 0.5246],
       device='cuda:0') torch.Size([16])
percent tensor([0.5281, 0.5377, 0.5268, 0.5227, 0.5205, 0.5353, 0.5285, 0.5177, 0.5255,
        0.5326, 0.5308, 0.5290, 0.5382, 0.5233, 0.5324, 0.5350],
       device='cuda:0') torch.Size([16])
percent tensor([0.6078, 0.5559, 0.6641, 0.6816, 0.6754, 0.6481, 0.6187, 0.6593, 0.6626,
        0.6027, 0.6416, 0.6339, 0.5248, 0.6831, 0.5998, 0.6169],
       device='cuda:0') torch.Size([16])
percent tensor([0.6803, 0.6733, 0.6667, 0.6636, 0.6689, 0.6780, 0.6851, 0.6707, 0.6755,
        0.6810, 0.6762, 0.6719, 0.6754, 0.6716, 0.6786, 0.6886],
       device='cuda:0') torch.Size([16])
percent tensor([0.6789, 0.6364, 0.6997, 0.6898, 0.6992, 0.7803, 0.6522, 0.6521, 0.6794,
        0.6700, 0.6104, 0.6355, 0.6751, 0.6711, 0.6255, 0.7521],
       device='cuda:0') torch.Size([16])
percent tensor([0.6616, 0.7477, 0.7065, 0.7257, 0.6878, 0.7875, 0.7113, 0.5451, 0.7457,
        0.7162, 0.8060, 0.7061, 0.7940, 0.7661, 0.6116, 0.6653],
       device='cuda:0') torch.Size([16])
percent tensor([0.5583, 0.6789, 0.6742, 0.6815, 0.6899, 0.6665, 0.6603, 0.6433, 0.6265,
        0.7070, 0.7092, 0.6008, 0.6219, 0.5614, 0.5910, 0.5473],
       device='cuda:0') torch.Size([16])
percent tensor([0.9999, 0.9998, 0.9999, 0.9999, 0.9995, 0.9995, 0.9997, 0.9997, 0.9998,
        0.9999, 0.9999, 0.9996, 0.9999, 0.9998, 0.9994, 0.9995],
       device='cuda:0') torch.Size([16])
Epoch: 212 | Batch_idx: 0 |  Loss: (0.0212) |  Loss2: (0.0000) | Acc: (100.00%) (128/128)
Epoch: 212 | Batch_idx: 10 |  Loss: (0.0546) |  Loss2: (0.0000) | Acc: (97.00%) (1378/1408)
Epoch: 212 | Batch_idx: 20 |  Loss: (0.0557) |  Loss2: (0.0000) | Acc: (98.00%) (2637/2688)
Epoch: 212 | Batch_idx: 30 |  Loss: (0.0583) |  Loss2: (0.0000) | Acc: (97.00%) (3888/3968)
Epoch: 212 | Batch_idx: 40 |  Loss: (0.0576) |  Loss2: (0.0000) | Acc: (98.00%) (5145/5248)
Epoch: 212 | Batch_idx: 50 |  Loss: (0.0566) |  Loss2: (0.0000) | Acc: (98.00%) (6404/6528)
Epoch: 212 | Batch_idx: 60 |  Loss: (0.0561) |  Loss2: (0.0000) | Acc: (98.00%) (7664/7808)
Epoch: 212 | Batch_idx: 70 |  Loss: (0.0553) |  Loss2: (0.0000) | Acc: (98.00%) (8922/9088)
Epoch: 212 | Batch_idx: 80 |  Loss: (0.0564) |  Loss2: (0.0000) | Acc: (98.00%) (10173/10368)
Epoch: 212 | Batch_idx: 90 |  Loss: (0.0565) |  Loss2: (0.0000) | Acc: (98.00%) (11433/11648)
Epoch: 212 | Batch_idx: 100 |  Loss: (0.0566) |  Loss2: (0.0000) | Acc: (98.00%) (12693/12928)
Epoch: 212 | Batch_idx: 110 |  Loss: (0.0571) |  Loss2: (0.0000) | Acc: (98.00%) (13945/14208)
Epoch: 212 | Batch_idx: 120 |  Loss: (0.0573) |  Loss2: (0.0000) | Acc: (98.00%) (15192/15488)
Epoch: 212 | Batch_idx: 130 |  Loss: (0.0570) |  Loss2: (0.0000) | Acc: (98.00%) (16454/16768)
Epoch: 212 | Batch_idx: 140 |  Loss: (0.0576) |  Loss2: (0.0000) | Acc: (98.00%) (17708/18048)
Epoch: 212 | Batch_idx: 150 |  Loss: (0.0572) |  Loss2: (0.0000) | Acc: (98.00%) (18967/19328)
Epoch: 212 | Batch_idx: 160 |  Loss: (0.0571) |  Loss2: (0.0000) | Acc: (98.00%) (20224/20608)
Epoch: 212 | Batch_idx: 170 |  Loss: (0.0566) |  Loss2: (0.0000) | Acc: (98.00%) (21483/21888)
Epoch: 212 | Batch_idx: 180 |  Loss: (0.0569) |  Loss2: (0.0000) | Acc: (98.00%) (22739/23168)
Epoch: 212 | Batch_idx: 190 |  Loss: (0.0566) |  Loss2: (0.0000) | Acc: (98.00%) (23994/24448)
Epoch: 212 | Batch_idx: 200 |  Loss: (0.0565) |  Loss2: (0.0000) | Acc: (98.00%) (25249/25728)
Epoch: 212 | Batch_idx: 210 |  Loss: (0.0568) |  Loss2: (0.0000) | Acc: (98.00%) (26498/27008)
Epoch: 212 | Batch_idx: 220 |  Loss: (0.0569) |  Loss2: (0.0000) | Acc: (98.00%) (27752/28288)
Epoch: 212 | Batch_idx: 230 |  Loss: (0.0571) |  Loss2: (0.0000) | Acc: (98.00%) (29005/29568)
Epoch: 212 | Batch_idx: 240 |  Loss: (0.0576) |  Loss2: (0.0000) | Acc: (98.00%) (30259/30848)
Epoch: 212 | Batch_idx: 250 |  Loss: (0.0578) |  Loss2: (0.0000) | Acc: (98.00%) (31509/32128)
Epoch: 212 | Batch_idx: 260 |  Loss: (0.0579) |  Loss2: (0.0000) | Acc: (98.00%) (32762/33408)
Epoch: 212 | Batch_idx: 270 |  Loss: (0.0580) |  Loss2: (0.0000) | Acc: (98.00%) (34015/34688)
Epoch: 212 | Batch_idx: 280 |  Loss: (0.0580) |  Loss2: (0.0000) | Acc: (98.00%) (35274/35968)
Epoch: 212 | Batch_idx: 290 |  Loss: (0.0581) |  Loss2: (0.0000) | Acc: (98.00%) (36535/37248)
Epoch: 212 | Batch_idx: 300 |  Loss: (0.0587) |  Loss2: (0.0000) | Acc: (98.00%) (37782/38528)
Epoch: 212 | Batch_idx: 310 |  Loss: (0.0589) |  Loss2: (0.0000) | Acc: (98.00%) (39034/39808)
Epoch: 212 | Batch_idx: 320 |  Loss: (0.0589) |  Loss2: (0.0000) | Acc: (98.00%) (40287/41088)
Epoch: 212 | Batch_idx: 330 |  Loss: (0.0588) |  Loss2: (0.0000) | Acc: (98.00%) (41542/42368)
Epoch: 212 | Batch_idx: 340 |  Loss: (0.0588) |  Loss2: (0.0000) | Acc: (98.00%) (42795/43648)
Epoch: 212 | Batch_idx: 350 |  Loss: (0.0590) |  Loss2: (0.0000) | Acc: (98.00%) (44049/44928)
Epoch: 212 | Batch_idx: 360 |  Loss: (0.0590) |  Loss2: (0.0000) | Acc: (98.00%) (45310/46208)
Epoch: 212 | Batch_idx: 370 |  Loss: (0.0590) |  Loss2: (0.0000) | Acc: (98.00%) (46563/47488)
Epoch: 212 | Batch_idx: 380 |  Loss: (0.0594) |  Loss2: (0.0000) | Acc: (98.00%) (47808/48768)
Epoch: 212 | Batch_idx: 390 |  Loss: (0.0592) |  Loss2: (0.0000) | Acc: (98.00%) (49019/50000)
# TEST : Loss: (0.4255) | Acc: (88.00%) (8862/10000)
percent tensor([0.5245, 0.5256, 0.5265, 0.5276, 0.5278, 0.5299, 0.5273, 0.5296, 0.5258,
        0.5245, 0.5238, 0.5249, 0.5242, 0.5270, 0.5260, 0.5255],
       device='cuda:0') torch.Size([16])
percent tensor([0.5284, 0.5391, 0.5266, 0.5251, 0.5215, 0.5360, 0.5303, 0.5187, 0.5253,
        0.5344, 0.5320, 0.5308, 0.5381, 0.5247, 0.5336, 0.5357],
       device='cuda:0') torch.Size([16])
percent tensor([0.6198, 0.5617, 0.6669, 0.6880, 0.6817, 0.6665, 0.6229, 0.6618, 0.6677,
        0.6092, 0.6486, 0.6393, 0.5282, 0.6903, 0.6120, 0.6278],
       device='cuda:0') torch.Size([16])
percent tensor([0.6787, 0.6742, 0.6660, 0.6626, 0.6665, 0.6699, 0.6857, 0.6714, 0.6788,
        0.6834, 0.6782, 0.6760, 0.6748, 0.6788, 0.6783, 0.6856],
       device='cuda:0') torch.Size([16])
percent tensor([0.6620, 0.6204, 0.7001, 0.6994, 0.6999, 0.7758, 0.6379, 0.6320, 0.6825,
        0.6709, 0.6092, 0.6544, 0.6585, 0.6797, 0.6107, 0.7430],
       device='cuda:0') torch.Size([16])
percent tensor([0.6692, 0.7261, 0.7047, 0.7107, 0.6813, 0.7733, 0.7132, 0.5502, 0.7354,
        0.7068, 0.8059, 0.6973, 0.7878, 0.7505, 0.5941, 0.6826],
       device='cuda:0') torch.Size([16])
percent tensor([0.5657, 0.6420, 0.6543, 0.6809, 0.6691, 0.6522, 0.6697, 0.6392, 0.6111,
        0.6666, 0.6932, 0.5901, 0.6303, 0.5322, 0.5910, 0.5725],
       device='cuda:0') torch.Size([16])
percent tensor([0.9999, 0.9998, 0.9998, 0.9999, 0.9997, 0.9985, 0.9997, 0.9996, 0.9999,
        0.9999, 1.0000, 0.9998, 0.9999, 0.9997, 0.9993, 0.9996],
       device='cuda:0') torch.Size([16])
Epoch: 213 | Batch_idx: 0 |  Loss: (0.0496) |  Loss2: (0.0000) | Acc: (99.00%) (127/128)
Epoch: 213 | Batch_idx: 10 |  Loss: (0.0523) |  Loss2: (0.0000) | Acc: (98.00%) (1385/1408)
Epoch: 213 | Batch_idx: 20 |  Loss: (0.0505) |  Loss2: (0.0000) | Acc: (98.00%) (2641/2688)
Epoch: 213 | Batch_idx: 30 |  Loss: (0.0493) |  Loss2: (0.0000) | Acc: (98.00%) (3906/3968)
Epoch: 213 | Batch_idx: 40 |  Loss: (0.0484) |  Loss2: (0.0000) | Acc: (98.00%) (5168/5248)
Epoch: 213 | Batch_idx: 50 |  Loss: (0.0497) |  Loss2: (0.0000) | Acc: (98.00%) (6426/6528)
Epoch: 213 | Batch_idx: 60 |  Loss: (0.0520) |  Loss2: (0.0000) | Acc: (98.00%) (7674/7808)
Epoch: 213 | Batch_idx: 70 |  Loss: (0.0509) |  Loss2: (0.0000) | Acc: (98.00%) (8940/9088)
Epoch: 213 | Batch_idx: 80 |  Loss: (0.0511) |  Loss2: (0.0000) | Acc: (98.00%) (10197/10368)
Epoch: 213 | Batch_idx: 90 |  Loss: (0.0517) |  Loss2: (0.0000) | Acc: (98.00%) (11454/11648)
Epoch: 213 | Batch_idx: 100 |  Loss: (0.0525) |  Loss2: (0.0000) | Acc: (98.00%) (12707/12928)
Epoch: 213 | Batch_idx: 110 |  Loss: (0.0535) |  Loss2: (0.0000) | Acc: (98.00%) (13960/14208)
Epoch: 213 | Batch_idx: 120 |  Loss: (0.0543) |  Loss2: (0.0000) | Acc: (98.00%) (15212/15488)
Epoch: 213 | Batch_idx: 130 |  Loss: (0.0543) |  Loss2: (0.0000) | Acc: (98.00%) (16473/16768)
Epoch: 213 | Batch_idx: 140 |  Loss: (0.0555) |  Loss2: (0.0000) | Acc: (98.00%) (17726/18048)
Epoch: 213 | Batch_idx: 150 |  Loss: (0.0550) |  Loss2: (0.0000) | Acc: (98.00%) (18987/19328)
Epoch: 213 | Batch_idx: 160 |  Loss: (0.0557) |  Loss2: (0.0000) | Acc: (98.00%) (20243/20608)
Epoch: 213 | Batch_idx: 170 |  Loss: (0.0562) |  Loss2: (0.0000) | Acc: (98.00%) (21492/21888)
Epoch: 213 | Batch_idx: 180 |  Loss: (0.0561) |  Loss2: (0.0000) | Acc: (98.00%) (22749/23168)
Epoch: 213 | Batch_idx: 190 |  Loss: (0.0565) |  Loss2: (0.0000) | Acc: (98.00%) (24003/24448)
Epoch: 213 | Batch_idx: 200 |  Loss: (0.0566) |  Loss2: (0.0000) | Acc: (98.00%) (25266/25728)
Epoch: 213 | Batch_idx: 210 |  Loss: (0.0571) |  Loss2: (0.0000) | Acc: (98.00%) (26512/27008)
Epoch: 213 | Batch_idx: 220 |  Loss: (0.0571) |  Loss2: (0.0000) | Acc: (98.00%) (27771/28288)
Epoch: 213 | Batch_idx: 230 |  Loss: (0.0570) |  Loss2: (0.0000) | Acc: (98.00%) (29030/29568)
Epoch: 213 | Batch_idx: 240 |  Loss: (0.0570) |  Loss2: (0.0000) | Acc: (98.00%) (30285/30848)
Epoch: 213 | Batch_idx: 250 |  Loss: (0.0566) |  Loss2: (0.0000) | Acc: (98.00%) (31548/32128)
Epoch: 213 | Batch_idx: 260 |  Loss: (0.0568) |  Loss2: (0.0000) | Acc: (98.00%) (32797/33408)
Epoch: 213 | Batch_idx: 270 |  Loss: (0.0572) |  Loss2: (0.0000) | Acc: (98.00%) (34047/34688)
Epoch: 213 | Batch_idx: 280 |  Loss: (0.0573) |  Loss2: (0.0000) | Acc: (98.00%) (35303/35968)
Epoch: 213 | Batch_idx: 290 |  Loss: (0.0572) |  Loss2: (0.0000) | Acc: (98.00%) (36560/37248)
Epoch: 213 | Batch_idx: 300 |  Loss: (0.0569) |  Loss2: (0.0000) | Acc: (98.00%) (37824/38528)
Epoch: 213 | Batch_idx: 310 |  Loss: (0.0571) |  Loss2: (0.0000) | Acc: (98.00%) (39073/39808)
Epoch: 213 | Batch_idx: 320 |  Loss: (0.0573) |  Loss2: (0.0000) | Acc: (98.00%) (40327/41088)
Epoch: 213 | Batch_idx: 330 |  Loss: (0.0573) |  Loss2: (0.0000) | Acc: (98.00%) (41585/42368)
Epoch: 213 | Batch_idx: 340 |  Loss: (0.0574) |  Loss2: (0.0000) | Acc: (98.00%) (42840/43648)
Epoch: 213 | Batch_idx: 350 |  Loss: (0.0575) |  Loss2: (0.0000) | Acc: (98.00%) (44094/44928)
Epoch: 213 | Batch_idx: 360 |  Loss: (0.0577) |  Loss2: (0.0000) | Acc: (98.00%) (45352/46208)
Epoch: 213 | Batch_idx: 370 |  Loss: (0.0577) |  Loss2: (0.0000) | Acc: (98.00%) (46607/47488)
Epoch: 213 | Batch_idx: 380 |  Loss: (0.0578) |  Loss2: (0.0000) | Acc: (98.00%) (47865/48768)
Epoch: 213 | Batch_idx: 390 |  Loss: (0.0579) |  Loss2: (0.0000) | Acc: (98.00%) (49071/50000)
# TEST : Loss: (0.4177) | Acc: (89.00%) (8909/10000)
percent tensor([0.5247, 0.5261, 0.5265, 0.5279, 0.5285, 0.5312, 0.5281, 0.5294, 0.5256,
        0.5249, 0.5240, 0.5256, 0.5243, 0.5272, 0.5270, 0.5259],
       device='cuda:0') torch.Size([16])
percent tensor([0.5283, 0.5410, 0.5259, 0.5228, 0.5215, 0.5369, 0.5316, 0.5191, 0.5271,
        0.5351, 0.5343, 0.5315, 0.5394, 0.5278, 0.5347, 0.5363],
       device='cuda:0') torch.Size([16])
percent tensor([0.6111, 0.5604, 0.6669, 0.6877, 0.6779, 0.6472, 0.6199, 0.6646, 0.6596,
        0.6104, 0.6397, 0.6295, 0.5242, 0.6771, 0.6067, 0.6232],
       device='cuda:0') torch.Size([16])
percent tensor([0.6763, 0.6737, 0.6635, 0.6596, 0.6654, 0.6698, 0.6835, 0.6693, 0.6730,
        0.6818, 0.6770, 0.6729, 0.6737, 0.6726, 0.6760, 0.6865],
       device='cuda:0') torch.Size([16])
percent tensor([0.6683, 0.6200, 0.6939, 0.7001, 0.6947, 0.7805, 0.6242, 0.6391, 0.6746,
        0.6786, 0.6046, 0.6395, 0.6504, 0.6488, 0.6153, 0.7446],
       device='cuda:0') torch.Size([16])
percent tensor([0.6670, 0.7376, 0.6918, 0.7184, 0.6947, 0.7838, 0.7097, 0.5302, 0.7555,
        0.6941, 0.8027, 0.6949, 0.7891, 0.7676, 0.6032, 0.6661],
       device='cuda:0') torch.Size([16])
percent tensor([0.5580, 0.6594, 0.6631, 0.6900, 0.7042, 0.6550, 0.6649, 0.6188, 0.6340,
        0.6609, 0.6922, 0.6046, 0.6609, 0.5633, 0.6026, 0.5512],
       device='cuda:0') torch.Size([16])
percent tensor([0.9999, 0.9999, 0.9998, 0.9999, 0.9994, 0.9991, 0.9998, 0.9996, 0.9998,
        0.9998, 0.9999, 0.9997, 0.9999, 0.9997, 0.9995, 0.9996],
       device='cuda:0') torch.Size([16])
Epoch: 214 | Batch_idx: 0 |  Loss: (0.0431) |  Loss2: (0.0000) | Acc: (99.00%) (127/128)
Epoch: 214 | Batch_idx: 10 |  Loss: (0.0510) |  Loss2: (0.0000) | Acc: (98.00%) (1382/1408)
Epoch: 214 | Batch_idx: 20 |  Loss: (0.0508) |  Loss2: (0.0000) | Acc: (98.00%) (2643/2688)
Epoch: 214 | Batch_idx: 30 |  Loss: (0.0547) |  Loss2: (0.0000) | Acc: (98.00%) (3891/3968)
Epoch: 214 | Batch_idx: 40 |  Loss: (0.0554) |  Loss2: (0.0000) | Acc: (98.00%) (5149/5248)
Epoch: 214 | Batch_idx: 50 |  Loss: (0.0564) |  Loss2: (0.0000) | Acc: (98.00%) (6401/6528)
Epoch: 214 | Batch_idx: 60 |  Loss: (0.0568) |  Loss2: (0.0000) | Acc: (98.00%) (7655/7808)
Epoch: 214 | Batch_idx: 70 |  Loss: (0.0565) |  Loss2: (0.0000) | Acc: (98.00%) (8915/9088)
Epoch: 214 | Batch_idx: 80 |  Loss: (0.0562) |  Loss2: (0.0000) | Acc: (98.00%) (10170/10368)
Epoch: 214 | Batch_idx: 90 |  Loss: (0.0581) |  Loss2: (0.0000) | Acc: (98.00%) (11418/11648)
Epoch: 214 | Batch_idx: 100 |  Loss: (0.0587) |  Loss2: (0.0000) | Acc: (97.00%) (12668/12928)
Epoch: 214 | Batch_idx: 110 |  Loss: (0.0573) |  Loss2: (0.0000) | Acc: (98.00%) (13931/14208)
Epoch: 214 | Batch_idx: 120 |  Loss: (0.0567) |  Loss2: (0.0000) | Acc: (98.00%) (15193/15488)
Epoch: 214 | Batch_idx: 130 |  Loss: (0.0560) |  Loss2: (0.0000) | Acc: (98.00%) (16455/16768)
Epoch: 214 | Batch_idx: 140 |  Loss: (0.0556) |  Loss2: (0.0000) | Acc: (98.00%) (17716/18048)
Epoch: 214 | Batch_idx: 150 |  Loss: (0.0560) |  Loss2: (0.0000) | Acc: (98.00%) (18968/19328)
Epoch: 214 | Batch_idx: 160 |  Loss: (0.0555) |  Loss2: (0.0000) | Acc: (98.00%) (20226/20608)
Epoch: 214 | Batch_idx: 170 |  Loss: (0.0553) |  Loss2: (0.0000) | Acc: (98.00%) (21480/21888)
Epoch: 214 | Batch_idx: 180 |  Loss: (0.0555) |  Loss2: (0.0000) | Acc: (98.00%) (22737/23168)
Epoch: 214 | Batch_idx: 190 |  Loss: (0.0551) |  Loss2: (0.0000) | Acc: (98.00%) (24000/24448)
Epoch: 214 | Batch_idx: 200 |  Loss: (0.0549) |  Loss2: (0.0000) | Acc: (98.00%) (25258/25728)
Epoch: 214 | Batch_idx: 210 |  Loss: (0.0551) |  Loss2: (0.0000) | Acc: (98.00%) (26512/27008)
Epoch: 214 | Batch_idx: 220 |  Loss: (0.0553) |  Loss2: (0.0000) | Acc: (98.00%) (27769/28288)
Epoch: 214 | Batch_idx: 230 |  Loss: (0.0552) |  Loss2: (0.0000) | Acc: (98.00%) (29030/29568)
Epoch: 214 | Batch_idx: 240 |  Loss: (0.0555) |  Loss2: (0.0000) | Acc: (98.00%) (30283/30848)
Epoch: 214 | Batch_idx: 250 |  Loss: (0.0551) |  Loss2: (0.0000) | Acc: (98.00%) (31541/32128)
Epoch: 214 | Batch_idx: 260 |  Loss: (0.0548) |  Loss2: (0.0000) | Acc: (98.00%) (32802/33408)
Epoch: 214 | Batch_idx: 270 |  Loss: (0.0544) |  Loss2: (0.0000) | Acc: (98.00%) (34065/34688)
Epoch: 214 | Batch_idx: 280 |  Loss: (0.0547) |  Loss2: (0.0000) | Acc: (98.00%) (35321/35968)
Epoch: 214 | Batch_idx: 290 |  Loss: (0.0547) |  Loss2: (0.0000) | Acc: (98.00%) (36571/37248)
Epoch: 214 | Batch_idx: 300 |  Loss: (0.0545) |  Loss2: (0.0000) | Acc: (98.00%) (37832/38528)
Epoch: 214 | Batch_idx: 310 |  Loss: (0.0547) |  Loss2: (0.0000) | Acc: (98.00%) (39086/39808)
Epoch: 214 | Batch_idx: 320 |  Loss: (0.0547) |  Loss2: (0.0000) | Acc: (98.00%) (40339/41088)
Epoch: 214 | Batch_idx: 330 |  Loss: (0.0550) |  Loss2: (0.0000) | Acc: (98.00%) (41588/42368)
Epoch: 214 | Batch_idx: 340 |  Loss: (0.0554) |  Loss2: (0.0000) | Acc: (98.00%) (42831/43648)
Epoch: 214 | Batch_idx: 350 |  Loss: (0.0558) |  Loss2: (0.0000) | Acc: (98.00%) (44085/44928)
Epoch: 214 | Batch_idx: 360 |  Loss: (0.0560) |  Loss2: (0.0000) | Acc: (98.00%) (45341/46208)
Epoch: 214 | Batch_idx: 370 |  Loss: (0.0560) |  Loss2: (0.0000) | Acc: (98.00%) (46596/47488)
Epoch: 214 | Batch_idx: 380 |  Loss: (0.0562) |  Loss2: (0.0000) | Acc: (98.00%) (47853/48768)
Epoch: 214 | Batch_idx: 390 |  Loss: (0.0560) |  Loss2: (0.0000) | Acc: (98.00%) (49065/50000)
# TEST : Loss: (0.4338) | Acc: (88.00%) (8880/10000)
percent tensor([0.5253, 0.5260, 0.5274, 0.5277, 0.5294, 0.5309, 0.5282, 0.5297, 0.5262,
        0.5251, 0.5244, 0.5263, 0.5247, 0.5267, 0.5268, 0.5261],
       device='cuda:0') torch.Size([16])
percent tensor([0.5277, 0.5419, 0.5256, 0.5237, 0.5213, 0.5374, 0.5321, 0.5196, 0.5261,
        0.5349, 0.5334, 0.5298, 0.5381, 0.5284, 0.5355, 0.5364],
       device='cuda:0') torch.Size([16])
percent tensor([0.6040, 0.5514, 0.6573, 0.6826, 0.6713, 0.6380, 0.6149, 0.6567, 0.6613,
        0.6031, 0.6368, 0.6281, 0.5164, 0.6918, 0.5952, 0.6144],
       device='cuda:0') torch.Size([16])
percent tensor([0.6797, 0.6777, 0.6675, 0.6646, 0.6690, 0.6757, 0.6863, 0.6734, 0.6767,
        0.6841, 0.6797, 0.6737, 0.6764, 0.6753, 0.6789, 0.6886],
       device='cuda:0') torch.Size([16])
percent tensor([0.6805, 0.6161, 0.7085, 0.6991, 0.7078, 0.7980, 0.6463, 0.6482, 0.6802,
        0.6827, 0.6085, 0.6557, 0.6572, 0.6842, 0.6191, 0.7513],
       device='cuda:0') torch.Size([16])
percent tensor([0.6413, 0.7327, 0.6787, 0.7196, 0.6818, 0.7727, 0.7042, 0.5188, 0.7385,
        0.6898, 0.7929, 0.7053, 0.7794, 0.7653, 0.5992, 0.6632],
       device='cuda:0') torch.Size([16])
percent tensor([0.5553, 0.6607, 0.6579, 0.6862, 0.7164, 0.6676, 0.6541, 0.6251, 0.6055,
        0.6686, 0.6786, 0.6079, 0.6206, 0.5418, 0.5920, 0.5509],
       device='cuda:0') torch.Size([16])
percent tensor([0.9999, 0.9998, 0.9998, 0.9999, 0.9995, 0.9986, 0.9999, 0.9997, 0.9999,
        0.9998, 1.0000, 0.9998, 1.0000, 0.9997, 0.9994, 0.9996],
       device='cuda:0') torch.Size([16])
Epoch: 215 | Batch_idx: 0 |  Loss: (0.0700) |  Loss2: (0.0000) | Acc: (97.00%) (125/128)
Epoch: 215 | Batch_idx: 10 |  Loss: (0.0659) |  Loss2: (0.0000) | Acc: (97.00%) (1374/1408)
Epoch: 215 | Batch_idx: 20 |  Loss: (0.0601) |  Loss2: (0.0000) | Acc: (97.00%) (2628/2688)
Epoch: 215 | Batch_idx: 30 |  Loss: (0.0559) |  Loss2: (0.0000) | Acc: (98.00%) (3889/3968)
Epoch: 215 | Batch_idx: 40 |  Loss: (0.0586) |  Loss2: (0.0000) | Acc: (97.00%) (5140/5248)
Epoch: 215 | Batch_idx: 50 |  Loss: (0.0574) |  Loss2: (0.0000) | Acc: (97.00%) (6396/6528)
Epoch: 215 | Batch_idx: 60 |  Loss: (0.0570) |  Loss2: (0.0000) | Acc: (97.00%) (7651/7808)
Epoch: 215 | Batch_idx: 70 |  Loss: (0.0564) |  Loss2: (0.0000) | Acc: (98.00%) (8910/9088)
Epoch: 215 | Batch_idx: 80 |  Loss: (0.0551) |  Loss2: (0.0000) | Acc: (98.00%) (10175/10368)
Epoch: 215 | Batch_idx: 90 |  Loss: (0.0546) |  Loss2: (0.0000) | Acc: (98.00%) (11439/11648)
Epoch: 215 | Batch_idx: 100 |  Loss: (0.0545) |  Loss2: (0.0000) | Acc: (98.00%) (12696/12928)
Epoch: 215 | Batch_idx: 110 |  Loss: (0.0546) |  Loss2: (0.0000) | Acc: (98.00%) (13951/14208)
Epoch: 215 | Batch_idx: 120 |  Loss: (0.0555) |  Loss2: (0.0000) | Acc: (98.00%) (15205/15488)
Epoch: 215 | Batch_idx: 130 |  Loss: (0.0562) |  Loss2: (0.0000) | Acc: (98.00%) (16451/16768)
Epoch: 215 | Batch_idx: 140 |  Loss: (0.0560) |  Loss2: (0.0000) | Acc: (98.00%) (17708/18048)
Epoch: 215 | Batch_idx: 150 |  Loss: (0.0554) |  Loss2: (0.0000) | Acc: (98.00%) (18967/19328)
Epoch: 215 | Batch_idx: 160 |  Loss: (0.0549) |  Loss2: (0.0000) | Acc: (98.00%) (20230/20608)
Epoch: 215 | Batch_idx: 170 |  Loss: (0.0548) |  Loss2: (0.0000) | Acc: (98.00%) (21485/21888)
Epoch: 215 | Batch_idx: 180 |  Loss: (0.0544) |  Loss2: (0.0000) | Acc: (98.00%) (22747/23168)
Epoch: 215 | Batch_idx: 190 |  Loss: (0.0545) |  Loss2: (0.0000) | Acc: (98.00%) (24003/24448)
Epoch: 215 | Batch_idx: 200 |  Loss: (0.0546) |  Loss2: (0.0000) | Acc: (98.00%) (25262/25728)
Epoch: 215 | Batch_idx: 210 |  Loss: (0.0548) |  Loss2: (0.0000) | Acc: (98.00%) (26518/27008)
Epoch: 215 | Batch_idx: 220 |  Loss: (0.0549) |  Loss2: (0.0000) | Acc: (98.00%) (27775/28288)
Epoch: 215 | Batch_idx: 230 |  Loss: (0.0543) |  Loss2: (0.0000) | Acc: (98.00%) (29040/29568)
Epoch: 215 | Batch_idx: 240 |  Loss: (0.0540) |  Loss2: (0.0000) | Acc: (98.00%) (30303/30848)
Epoch: 215 | Batch_idx: 250 |  Loss: (0.0543) |  Loss2: (0.0000) | Acc: (98.00%) (31559/32128)
Epoch: 215 | Batch_idx: 260 |  Loss: (0.0541) |  Loss2: (0.0000) | Acc: (98.00%) (32824/33408)
Epoch: 215 | Batch_idx: 270 |  Loss: (0.0536) |  Loss2: (0.0000) | Acc: (98.00%) (34087/34688)
Epoch: 215 | Batch_idx: 280 |  Loss: (0.0534) |  Loss2: (0.0000) | Acc: (98.00%) (35351/35968)
Epoch: 215 | Batch_idx: 290 |  Loss: (0.0531) |  Loss2: (0.0000) | Acc: (98.00%) (36611/37248)
Epoch: 215 | Batch_idx: 300 |  Loss: (0.0531) |  Loss2: (0.0000) | Acc: (98.00%) (37868/38528)
Epoch: 215 | Batch_idx: 310 |  Loss: (0.0531) |  Loss2: (0.0000) | Acc: (98.00%) (39126/39808)
Epoch: 215 | Batch_idx: 320 |  Loss: (0.0532) |  Loss2: (0.0000) | Acc: (98.00%) (40379/41088)
Epoch: 215 | Batch_idx: 330 |  Loss: (0.0532) |  Loss2: (0.0000) | Acc: (98.00%) (41637/42368)
Epoch: 215 | Batch_idx: 340 |  Loss: (0.0537) |  Loss2: (0.0000) | Acc: (98.00%) (42887/43648)
Epoch: 215 | Batch_idx: 350 |  Loss: (0.0538) |  Loss2: (0.0000) | Acc: (98.00%) (44146/44928)
Epoch: 215 | Batch_idx: 360 |  Loss: (0.0537) |  Loss2: (0.0000) | Acc: (98.00%) (45400/46208)
Epoch: 215 | Batch_idx: 370 |  Loss: (0.0538) |  Loss2: (0.0000) | Acc: (98.00%) (46656/47488)
Epoch: 215 | Batch_idx: 380 |  Loss: (0.0538) |  Loss2: (0.0000) | Acc: (98.00%) (47914/48768)
Epoch: 215 | Batch_idx: 390 |  Loss: (0.0538) |  Loss2: (0.0000) | Acc: (98.00%) (49120/50000)
=> saving checkpoint 'drive/app/torch/save_Schedule/checkpoint_215.pth.tar'
# TEST : Loss: (0.4201) | Acc: (88.00%) (8892/10000)
percent tensor([0.5261, 0.5279, 0.5273, 0.5288, 0.5292, 0.5321, 0.5296, 0.5306, 0.5272,
        0.5261, 0.5257, 0.5262, 0.5258, 0.5293, 0.5281, 0.5273],
       device='cuda:0') torch.Size([16])
percent tensor([0.5288, 0.5424, 0.5267, 0.5241, 0.5222, 0.5375, 0.5333, 0.5212, 0.5274,
        0.5357, 0.5344, 0.5320, 0.5390, 0.5314, 0.5359, 0.5372],
       device='cuda:0') torch.Size([16])
percent tensor([0.6084, 0.5566, 0.6610, 0.6856, 0.6739, 0.6409, 0.6174, 0.6588, 0.6617,
        0.5995, 0.6414, 0.6221, 0.5222, 0.6828, 0.6005, 0.6181],
       device='cuda:0') torch.Size([16])
percent tensor([0.6852, 0.6815, 0.6718, 0.6682, 0.6743, 0.6833, 0.6919, 0.6793, 0.6818,
        0.6884, 0.6835, 0.6804, 0.6814, 0.6812, 0.6850, 0.6941],
       device='cuda:0') torch.Size([16])
percent tensor([0.6708, 0.6305, 0.7012, 0.7101, 0.7021, 0.7943, 0.6391, 0.6454, 0.6801,
        0.6809, 0.6188, 0.6554, 0.6634, 0.6689, 0.6218, 0.7591],
       device='cuda:0') torch.Size([16])
percent tensor([0.6612, 0.7636, 0.6940, 0.7290, 0.6993, 0.7817, 0.7220, 0.5311, 0.7557,
        0.7403, 0.8021, 0.7165, 0.8081, 0.7858, 0.6236, 0.6677],
       device='cuda:0') torch.Size([16])
percent tensor([0.5721, 0.6679, 0.6860, 0.7081, 0.7206, 0.6701, 0.6565, 0.6222, 0.6285,
        0.6970, 0.6933, 0.6189, 0.6441, 0.5672, 0.5953, 0.5378],
       device='cuda:0') torch.Size([16])
percent tensor([0.9999, 0.9998, 0.9998, 0.9999, 0.9997, 0.9993, 0.9998, 0.9996, 0.9998,
        0.9998, 0.9999, 0.9998, 0.9999, 0.9996, 0.9994, 0.9997],
       device='cuda:0') torch.Size([16])
Epoch: 216 | Batch_idx: 0 |  Loss: (0.0642) |  Loss2: (0.0000) | Acc: (97.00%) (125/128)
Epoch: 216 | Batch_idx: 10 |  Loss: (0.0534) |  Loss2: (0.0000) | Acc: (98.00%) (1382/1408)
Epoch: 216 | Batch_idx: 20 |  Loss: (0.0471) |  Loss2: (0.0000) | Acc: (98.00%) (2645/2688)
Epoch: 216 | Batch_idx: 30 |  Loss: (0.0479) |  Loss2: (0.0000) | Acc: (98.00%) (3902/3968)
Epoch: 216 | Batch_idx: 40 |  Loss: (0.0508) |  Loss2: (0.0000) | Acc: (98.00%) (5156/5248)
Epoch: 216 | Batch_idx: 50 |  Loss: (0.0546) |  Loss2: (0.0000) | Acc: (98.00%) (6405/6528)
Epoch: 216 | Batch_idx: 60 |  Loss: (0.0549) |  Loss2: (0.0000) | Acc: (98.00%) (7664/7808)
Epoch: 216 | Batch_idx: 70 |  Loss: (0.0533) |  Loss2: (0.0000) | Acc: (98.00%) (8931/9088)
Epoch: 216 | Batch_idx: 80 |  Loss: (0.0525) |  Loss2: (0.0000) | Acc: (98.00%) (10196/10368)
Epoch: 216 | Batch_idx: 90 |  Loss: (0.0527) |  Loss2: (0.0000) | Acc: (98.00%) (11452/11648)
Epoch: 216 | Batch_idx: 100 |  Loss: (0.0533) |  Loss2: (0.0000) | Acc: (98.00%) (12708/12928)
Epoch: 216 | Batch_idx: 110 |  Loss: (0.0532) |  Loss2: (0.0000) | Acc: (98.00%) (13969/14208)
Epoch: 216 | Batch_idx: 120 |  Loss: (0.0530) |  Loss2: (0.0000) | Acc: (98.00%) (15225/15488)
Epoch: 216 | Batch_idx: 130 |  Loss: (0.0520) |  Loss2: (0.0000) | Acc: (98.00%) (16493/16768)
Epoch: 216 | Batch_idx: 140 |  Loss: (0.0526) |  Loss2: (0.0000) | Acc: (98.00%) (17749/18048)
Epoch: 216 | Batch_idx: 150 |  Loss: (0.0522) |  Loss2: (0.0000) | Acc: (98.00%) (19011/19328)
Epoch: 216 | Batch_idx: 160 |  Loss: (0.0519) |  Loss2: (0.0000) | Acc: (98.00%) (20271/20608)
Epoch: 216 | Batch_idx: 170 |  Loss: (0.0518) |  Loss2: (0.0000) | Acc: (98.00%) (21530/21888)
Epoch: 216 | Batch_idx: 180 |  Loss: (0.0527) |  Loss2: (0.0000) | Acc: (98.00%) (22775/23168)
Epoch: 216 | Batch_idx: 190 |  Loss: (0.0515) |  Loss2: (0.0000) | Acc: (98.00%) (24051/24448)
Epoch: 216 | Batch_idx: 200 |  Loss: (0.0515) |  Loss2: (0.0000) | Acc: (98.00%) (25312/25728)
Epoch: 216 | Batch_idx: 210 |  Loss: (0.0521) |  Loss2: (0.0000) | Acc: (98.00%) (26565/27008)
Epoch: 216 | Batch_idx: 220 |  Loss: (0.0518) |  Loss2: (0.0000) | Acc: (98.00%) (27830/28288)
Epoch: 216 | Batch_idx: 230 |  Loss: (0.0520) |  Loss2: (0.0000) | Acc: (98.00%) (29087/29568)
Epoch: 216 | Batch_idx: 240 |  Loss: (0.0522) |  Loss2: (0.0000) | Acc: (98.00%) (30341/30848)
Epoch: 216 | Batch_idx: 250 |  Loss: (0.0523) |  Loss2: (0.0000) | Acc: (98.00%) (31602/32128)
Epoch: 216 | Batch_idx: 260 |  Loss: (0.0526) |  Loss2: (0.0000) | Acc: (98.00%) (32853/33408)
Epoch: 216 | Batch_idx: 270 |  Loss: (0.0523) |  Loss2: (0.0000) | Acc: (98.00%) (34117/34688)
Epoch: 216 | Batch_idx: 280 |  Loss: (0.0523) |  Loss2: (0.0000) | Acc: (98.00%) (35379/35968)
Epoch: 216 | Batch_idx: 290 |  Loss: (0.0525) |  Loss2: (0.0000) | Acc: (98.00%) (36639/37248)
Epoch: 216 | Batch_idx: 300 |  Loss: (0.0528) |  Loss2: (0.0000) | Acc: (98.00%) (37890/38528)
Epoch: 216 | Batch_idx: 310 |  Loss: (0.0529) |  Loss2: (0.0000) | Acc: (98.00%) (39148/39808)
Epoch: 216 | Batch_idx: 320 |  Loss: (0.0531) |  Loss2: (0.0000) | Acc: (98.00%) (40405/41088)
Epoch: 216 | Batch_idx: 330 |  Loss: (0.0534) |  Loss2: (0.0000) | Acc: (98.00%) (41660/42368)
Epoch: 216 | Batch_idx: 340 |  Loss: (0.0536) |  Loss2: (0.0000) | Acc: (98.00%) (42917/43648)
Epoch: 216 | Batch_idx: 350 |  Loss: (0.0533) |  Loss2: (0.0000) | Acc: (98.00%) (44181/44928)
Epoch: 216 | Batch_idx: 360 |  Loss: (0.0532) |  Loss2: (0.0000) | Acc: (98.00%) (45440/46208)
Epoch: 216 | Batch_idx: 370 |  Loss: (0.0529) |  Loss2: (0.0000) | Acc: (98.00%) (46703/47488)
Epoch: 216 | Batch_idx: 380 |  Loss: (0.0529) |  Loss2: (0.0000) | Acc: (98.00%) (47962/48768)
Epoch: 216 | Batch_idx: 390 |  Loss: (0.0528) |  Loss2: (0.0000) | Acc: (98.00%) (49175/50000)
# TEST : Loss: (0.4247) | Acc: (89.00%) (8902/10000)
percent tensor([0.5262, 0.5279, 0.5272, 0.5287, 0.5294, 0.5326, 0.5297, 0.5309, 0.5276,
        0.5263, 0.5262, 0.5263, 0.5260, 0.5293, 0.5285, 0.5275],
       device='cuda:0') torch.Size([16])
percent tensor([0.5305, 0.5408, 0.5274, 0.5248, 0.5233, 0.5379, 0.5320, 0.5207, 0.5284,
        0.5359, 0.5347, 0.5323, 0.5404, 0.5285, 0.5360, 0.5379],
       device='cuda:0') torch.Size([16])
percent tensor([0.6099, 0.5628, 0.6580, 0.6810, 0.6716, 0.6405, 0.6209, 0.6605, 0.6668,
        0.6045, 0.6464, 0.6193, 0.5210, 0.6883, 0.6053, 0.6150],
       device='cuda:0') torch.Size([16])
percent tensor([0.6858, 0.6785, 0.6717, 0.6699, 0.6739, 0.6787, 0.6899, 0.6802, 0.6778,
        0.6873, 0.6829, 0.6807, 0.6795, 0.6763, 0.6857, 0.6922],
       device='cuda:0') torch.Size([16])
percent tensor([0.6824, 0.6334, 0.6943, 0.7039, 0.7036, 0.8027, 0.6400, 0.6511, 0.6909,
        0.6818, 0.6378, 0.6523, 0.6712, 0.6792, 0.6280, 0.7602],
       device='cuda:0') torch.Size([16])
percent tensor([0.6723, 0.7458, 0.7110, 0.7432, 0.6841, 0.7837, 0.7214, 0.5474, 0.7674,
        0.7331, 0.8035, 0.7239, 0.8030, 0.7899, 0.6119, 0.6757],
       device='cuda:0') torch.Size([16])
percent tensor([0.5680, 0.6622, 0.6785, 0.6841, 0.6872, 0.6678, 0.6598, 0.6179, 0.6435,
        0.7071, 0.7003, 0.6096, 0.6679, 0.5807, 0.5842, 0.5412],
       device='cuda:0') torch.Size([16])
percent tensor([0.9999, 0.9998, 0.9998, 0.9999, 0.9996, 0.9991, 0.9997, 0.9995, 0.9999,
        0.9999, 1.0000, 0.9998, 0.9999, 0.9996, 0.9994, 0.9996],
       device='cuda:0') torch.Size([16])
Epoch: 217 | Batch_idx: 0 |  Loss: (0.0339) |  Loss2: (0.0000) | Acc: (99.00%) (127/128)
Epoch: 217 | Batch_idx: 10 |  Loss: (0.0421) |  Loss2: (0.0000) | Acc: (98.00%) (1390/1408)
Epoch: 217 | Batch_idx: 20 |  Loss: (0.0412) |  Loss2: (0.0000) | Acc: (98.00%) (2653/2688)
Epoch: 217 | Batch_idx: 30 |  Loss: (0.0459) |  Loss2: (0.0000) | Acc: (98.00%) (3909/3968)
Epoch: 217 | Batch_idx: 40 |  Loss: (0.0446) |  Loss2: (0.0000) | Acc: (98.00%) (5176/5248)
Epoch: 217 | Batch_idx: 50 |  Loss: (0.0451) |  Loss2: (0.0000) | Acc: (98.00%) (6438/6528)
Epoch: 217 | Batch_idx: 60 |  Loss: (0.0449) |  Loss2: (0.0000) | Acc: (98.00%) (7705/7808)
Epoch: 217 | Batch_idx: 70 |  Loss: (0.0436) |  Loss2: (0.0000) | Acc: (98.00%) (8970/9088)
Epoch: 217 | Batch_idx: 80 |  Loss: (0.0433) |  Loss2: (0.0000) | Acc: (98.00%) (10230/10368)
Epoch: 217 | Batch_idx: 90 |  Loss: (0.0436) |  Loss2: (0.0000) | Acc: (98.00%) (11497/11648)
Epoch: 217 | Batch_idx: 100 |  Loss: (0.0445) |  Loss2: (0.0000) | Acc: (98.00%) (12758/12928)
Epoch: 217 | Batch_idx: 110 |  Loss: (0.0445) |  Loss2: (0.0000) | Acc: (98.00%) (14020/14208)
Epoch: 217 | Batch_idx: 120 |  Loss: (0.0443) |  Loss2: (0.0000) | Acc: (98.00%) (15282/15488)
Epoch: 217 | Batch_idx: 130 |  Loss: (0.0451) |  Loss2: (0.0000) | Acc: (98.00%) (16536/16768)
Epoch: 217 | Batch_idx: 140 |  Loss: (0.0462) |  Loss2: (0.0000) | Acc: (98.00%) (17787/18048)
Epoch: 217 | Batch_idx: 150 |  Loss: (0.0462) |  Loss2: (0.0000) | Acc: (98.00%) (19043/19328)
Epoch: 217 | Batch_idx: 160 |  Loss: (0.0461) |  Loss2: (0.0000) | Acc: (98.00%) (20308/20608)
Epoch: 217 | Batch_idx: 170 |  Loss: (0.0465) |  Loss2: (0.0000) | Acc: (98.00%) (21565/21888)
Epoch: 217 | Batch_idx: 180 |  Loss: (0.0468) |  Loss2: (0.0000) | Acc: (98.00%) (22826/23168)
Epoch: 217 | Batch_idx: 190 |  Loss: (0.0468) |  Loss2: (0.0000) | Acc: (98.00%) (24086/24448)
Epoch: 217 | Batch_idx: 200 |  Loss: (0.0470) |  Loss2: (0.0000) | Acc: (98.00%) (25341/25728)
Epoch: 217 | Batch_idx: 210 |  Loss: (0.0468) |  Loss2: (0.0000) | Acc: (98.00%) (26604/27008)
Epoch: 217 | Batch_idx: 220 |  Loss: (0.0465) |  Loss2: (0.0000) | Acc: (98.00%) (27869/28288)
Epoch: 217 | Batch_idx: 230 |  Loss: (0.0463) |  Loss2: (0.0000) | Acc: (98.00%) (29134/29568)
Epoch: 217 | Batch_idx: 240 |  Loss: (0.0461) |  Loss2: (0.0000) | Acc: (98.00%) (30398/30848)
Epoch: 217 | Batch_idx: 250 |  Loss: (0.0464) |  Loss2: (0.0000) | Acc: (98.00%) (31653/32128)
Epoch: 217 | Batch_idx: 260 |  Loss: (0.0463) |  Loss2: (0.0000) | Acc: (98.00%) (32917/33408)
Epoch: 217 | Batch_idx: 270 |  Loss: (0.0464) |  Loss2: (0.0000) | Acc: (98.00%) (34178/34688)
Epoch: 217 | Batch_idx: 280 |  Loss: (0.0468) |  Loss2: (0.0000) | Acc: (98.00%) (35433/35968)
Epoch: 217 | Batch_idx: 290 |  Loss: (0.0470) |  Loss2: (0.0000) | Acc: (98.00%) (36691/37248)
Epoch: 217 | Batch_idx: 300 |  Loss: (0.0471) |  Loss2: (0.0000) | Acc: (98.00%) (37951/38528)
Epoch: 217 | Batch_idx: 310 |  Loss: (0.0472) |  Loss2: (0.0000) | Acc: (98.00%) (39208/39808)
Epoch: 217 | Batch_idx: 320 |  Loss: (0.0472) |  Loss2: (0.0000) | Acc: (98.00%) (40472/41088)
Epoch: 217 | Batch_idx: 330 |  Loss: (0.0473) |  Loss2: (0.0000) | Acc: (98.00%) (41732/42368)
Epoch: 217 | Batch_idx: 340 |  Loss: (0.0472) |  Loss2: (0.0000) | Acc: (98.00%) (42993/43648)
Epoch: 217 | Batch_idx: 350 |  Loss: (0.0471) |  Loss2: (0.0000) | Acc: (98.00%) (44256/44928)
Epoch: 217 | Batch_idx: 360 |  Loss: (0.0476) |  Loss2: (0.0000) | Acc: (98.00%) (45506/46208)
Epoch: 217 | Batch_idx: 370 |  Loss: (0.0476) |  Loss2: (0.0000) | Acc: (98.00%) (46769/47488)
Epoch: 217 | Batch_idx: 380 |  Loss: (0.0479) |  Loss2: (0.0000) | Acc: (98.00%) (48029/48768)
Epoch: 217 | Batch_idx: 390 |  Loss: (0.0480) |  Loss2: (0.0000) | Acc: (98.00%) (49239/50000)
# TEST : Loss: (0.4355) | Acc: (88.00%) (8870/10000)
percent tensor([0.5263, 0.5272, 0.5291, 0.5294, 0.5309, 0.5334, 0.5296, 0.5316, 0.5275,
        0.5264, 0.5257, 0.5276, 0.5259, 0.5281, 0.5287, 0.5272],
       device='cuda:0') torch.Size([16])
percent tensor([0.5285, 0.5396, 0.5267, 0.5219, 0.5208, 0.5364, 0.5308, 0.5199, 0.5269,
        0.5350, 0.5335, 0.5308, 0.5386, 0.5263, 0.5335, 0.5358],
       device='cuda:0') torch.Size([16])
percent tensor([0.6132, 0.5582, 0.6646, 0.6895, 0.6831, 0.6621, 0.6226, 0.6635, 0.6643,
        0.6021, 0.6460, 0.6298, 0.5229, 0.6846, 0.6095, 0.6262],
       device='cuda:0') torch.Size([16])
percent tensor([0.6867, 0.6768, 0.6732, 0.6711, 0.6749, 0.6741, 0.6893, 0.6794, 0.6829,
        0.6879, 0.6818, 0.6806, 0.6825, 0.6775, 0.6814, 0.6906],
       device='cuda:0') torch.Size([16])
percent tensor([0.6872, 0.6367, 0.6986, 0.7170, 0.7059, 0.7967, 0.6348, 0.6422, 0.6778,
        0.6831, 0.6172, 0.6488, 0.6723, 0.6825, 0.6294, 0.7606],
       device='cuda:0') torch.Size([16])
percent tensor([0.6833, 0.7598, 0.7127, 0.7445, 0.7037, 0.8005, 0.7341, 0.5507, 0.7675,
        0.7473, 0.8233, 0.7360, 0.8125, 0.7846, 0.6183, 0.6931],
       device='cuda:0') torch.Size([16])
percent tensor([0.5869, 0.6874, 0.6801, 0.6965, 0.7128, 0.6683, 0.6784, 0.6277, 0.6390,
        0.7203, 0.6962, 0.6421, 0.6644, 0.5639, 0.5989, 0.5658],
       device='cuda:0') torch.Size([16])
percent tensor([0.9999, 0.9997, 0.9998, 0.9999, 0.9996, 0.9991, 0.9998, 0.9994, 0.9999,
        0.9999, 1.0000, 0.9999, 0.9999, 0.9996, 0.9995, 0.9995],
       device='cuda:0') torch.Size([16])
Epoch: 218 | Batch_idx: 0 |  Loss: (0.0186) |  Loss2: (0.0000) | Acc: (99.00%) (127/128)
Epoch: 218 | Batch_idx: 10 |  Loss: (0.0348) |  Loss2: (0.0000) | Acc: (99.00%) (1394/1408)
Epoch: 218 | Batch_idx: 20 |  Loss: (0.0355) |  Loss2: (0.0000) | Acc: (98.00%) (2659/2688)
Epoch: 218 | Batch_idx: 30 |  Loss: (0.0418) |  Loss2: (0.0000) | Acc: (98.00%) (3910/3968)
Epoch: 218 | Batch_idx: 40 |  Loss: (0.0453) |  Loss2: (0.0000) | Acc: (98.00%) (5169/5248)
Epoch: 218 | Batch_idx: 50 |  Loss: (0.0466) |  Loss2: (0.0000) | Acc: (98.00%) (6424/6528)
Epoch: 218 | Batch_idx: 60 |  Loss: (0.0484) |  Loss2: (0.0000) | Acc: (98.00%) (7681/7808)
Epoch: 218 | Batch_idx: 70 |  Loss: (0.0484) |  Loss2: (0.0000) | Acc: (98.00%) (8939/9088)
Epoch: 218 | Batch_idx: 80 |  Loss: (0.0482) |  Loss2: (0.0000) | Acc: (98.00%) (10198/10368)
Epoch: 218 | Batch_idx: 90 |  Loss: (0.0484) |  Loss2: (0.0000) | Acc: (98.00%) (11459/11648)
Epoch: 218 | Batch_idx: 100 |  Loss: (0.0497) |  Loss2: (0.0000) | Acc: (98.00%) (12708/12928)
Epoch: 218 | Batch_idx: 110 |  Loss: (0.0501) |  Loss2: (0.0000) | Acc: (98.00%) (13967/14208)
Epoch: 218 | Batch_idx: 120 |  Loss: (0.0500) |  Loss2: (0.0000) | Acc: (98.00%) (15231/15488)
Epoch: 218 | Batch_idx: 130 |  Loss: (0.0497) |  Loss2: (0.0000) | Acc: (98.00%) (16491/16768)
Epoch: 218 | Batch_idx: 140 |  Loss: (0.0506) |  Loss2: (0.0000) | Acc: (98.00%) (17744/18048)
Epoch: 218 | Batch_idx: 150 |  Loss: (0.0512) |  Loss2: (0.0000) | Acc: (98.00%) (19001/19328)
Epoch: 218 | Batch_idx: 160 |  Loss: (0.0517) |  Loss2: (0.0000) | Acc: (98.00%) (20258/20608)
Epoch: 218 | Batch_idx: 170 |  Loss: (0.0515) |  Loss2: (0.0000) | Acc: (98.00%) (21518/21888)
Epoch: 218 | Batch_idx: 180 |  Loss: (0.0525) |  Loss2: (0.0000) | Acc: (98.00%) (22766/23168)
Epoch: 218 | Batch_idx: 190 |  Loss: (0.0529) |  Loss2: (0.0000) | Acc: (98.00%) (24018/24448)
Epoch: 218 | Batch_idx: 200 |  Loss: (0.0536) |  Loss2: (0.0000) | Acc: (98.00%) (25268/25728)
Epoch: 218 | Batch_idx: 210 |  Loss: (0.0534) |  Loss2: (0.0000) | Acc: (98.00%) (26523/27008)
Epoch: 218 | Batch_idx: 220 |  Loss: (0.0529) |  Loss2: (0.0000) | Acc: (98.00%) (27786/28288)
Epoch: 218 | Batch_idx: 230 |  Loss: (0.0528) |  Loss2: (0.0000) | Acc: (98.00%) (29048/29568)
Epoch: 218 | Batch_idx: 240 |  Loss: (0.0526) |  Loss2: (0.0000) | Acc: (98.00%) (30309/30848)
Epoch: 218 | Batch_idx: 250 |  Loss: (0.0521) |  Loss2: (0.0000) | Acc: (98.00%) (31573/32128)
Epoch: 218 | Batch_idx: 260 |  Loss: (0.0521) |  Loss2: (0.0000) | Acc: (98.00%) (32836/33408)
Epoch: 218 | Batch_idx: 270 |  Loss: (0.0526) |  Loss2: (0.0000) | Acc: (98.00%) (34087/34688)
Epoch: 218 | Batch_idx: 280 |  Loss: (0.0529) |  Loss2: (0.0000) | Acc: (98.00%) (35340/35968)
Epoch: 218 | Batch_idx: 290 |  Loss: (0.0533) |  Loss2: (0.0000) | Acc: (98.00%) (36593/37248)
Epoch: 218 | Batch_idx: 300 |  Loss: (0.0532) |  Loss2: (0.0000) | Acc: (98.00%) (37858/38528)
Epoch: 218 | Batch_idx: 310 |  Loss: (0.0533) |  Loss2: (0.0000) | Acc: (98.00%) (39115/39808)
Epoch: 218 | Batch_idx: 320 |  Loss: (0.0534) |  Loss2: (0.0000) | Acc: (98.00%) (40372/41088)
Epoch: 218 | Batch_idx: 330 |  Loss: (0.0531) |  Loss2: (0.0000) | Acc: (98.00%) (41629/42368)
Epoch: 218 | Batch_idx: 340 |  Loss: (0.0531) |  Loss2: (0.0000) | Acc: (98.00%) (42884/43648)
Epoch: 218 | Batch_idx: 350 |  Loss: (0.0531) |  Loss2: (0.0000) | Acc: (98.00%) (44137/44928)
Epoch: 218 | Batch_idx: 360 |  Loss: (0.0529) |  Loss2: (0.0000) | Acc: (98.00%) (45398/46208)
Epoch: 218 | Batch_idx: 370 |  Loss: (0.0530) |  Loss2: (0.0000) | Acc: (98.00%) (46651/47488)
Epoch: 218 | Batch_idx: 380 |  Loss: (0.0529) |  Loss2: (0.0000) | Acc: (98.00%) (47911/48768)
Epoch: 218 | Batch_idx: 390 |  Loss: (0.0529) |  Loss2: (0.0000) | Acc: (98.00%) (49120/50000)
# TEST : Loss: (0.4333) | Acc: (88.00%) (8882/10000)
percent tensor([0.5266, 0.5282, 0.5280, 0.5295, 0.5300, 0.5334, 0.5301, 0.5316, 0.5277,
        0.5267, 0.5262, 0.5269, 0.5261, 0.5297, 0.5290, 0.5281],
       device='cuda:0') torch.Size([16])
percent tensor([0.5293, 0.5410, 0.5261, 0.5235, 0.5214, 0.5377, 0.5315, 0.5207, 0.5269,
        0.5353, 0.5344, 0.5306, 0.5396, 0.5283, 0.5354, 0.5367],
       device='cuda:0') torch.Size([16])
percent tensor([0.6129, 0.5571, 0.6674, 0.6892, 0.6789, 0.6572, 0.6215, 0.6647, 0.6610,
        0.6032, 0.6383, 0.6300, 0.5180, 0.6944, 0.6050, 0.6202],
       device='cuda:0') torch.Size([16])
percent tensor([0.6888, 0.6795, 0.6772, 0.6742, 0.6761, 0.6776, 0.6914, 0.6844, 0.6863,
        0.6904, 0.6849, 0.6823, 0.6853, 0.6811, 0.6857, 0.6939],
       device='cuda:0') torch.Size([16])
percent tensor([0.6718, 0.6329, 0.6908, 0.6983, 0.6944, 0.7848, 0.6553, 0.6443, 0.6844,
        0.6840, 0.6157, 0.6476, 0.6667, 0.6973, 0.6233, 0.7430],
       device='cuda:0') torch.Size([16])
percent tensor([0.6594, 0.7603, 0.7106, 0.7357, 0.6971, 0.7901, 0.7333, 0.5343, 0.7423,
        0.7258, 0.8082, 0.7190, 0.8003, 0.7789, 0.5982, 0.6534],
       device='cuda:0') torch.Size([16])
percent tensor([0.5672, 0.6754, 0.6758, 0.6890, 0.6989, 0.6616, 0.6695, 0.6086, 0.6222,
        0.7098, 0.6928, 0.6210, 0.6432, 0.5389, 0.5812, 0.5507],
       device='cuda:0') torch.Size([16])
percent tensor([0.9999, 0.9996, 0.9998, 1.0000, 0.9996, 0.9993, 0.9998, 0.9994, 0.9999,
        0.9999, 1.0000, 0.9998, 0.9999, 0.9996, 0.9995, 0.9996],
       device='cuda:0') torch.Size([16])
Epoch: 219 | Batch_idx: 0 |  Loss: (0.0435) |  Loss2: (0.0000) | Acc: (97.00%) (125/128)
Epoch: 219 | Batch_idx: 10 |  Loss: (0.0499) |  Loss2: (0.0000) | Acc: (98.00%) (1387/1408)
Epoch: 219 | Batch_idx: 20 |  Loss: (0.0526) |  Loss2: (0.0000) | Acc: (98.00%) (2642/2688)
Epoch: 219 | Batch_idx: 30 |  Loss: (0.0502) |  Loss2: (0.0000) | Acc: (98.00%) (3902/3968)
Epoch: 219 | Batch_idx: 40 |  Loss: (0.0496) |  Loss2: (0.0000) | Acc: (98.00%) (5161/5248)
Epoch: 219 | Batch_idx: 50 |  Loss: (0.0512) |  Loss2: (0.0000) | Acc: (98.00%) (6418/6528)
Epoch: 219 | Batch_idx: 60 |  Loss: (0.0508) |  Loss2: (0.0000) | Acc: (98.00%) (7679/7808)
Epoch: 219 | Batch_idx: 70 |  Loss: (0.0506) |  Loss2: (0.0000) | Acc: (98.00%) (8942/9088)
Epoch: 219 | Batch_idx: 80 |  Loss: (0.0514) |  Loss2: (0.0000) | Acc: (98.00%) (10198/10368)
Epoch: 219 | Batch_idx: 90 |  Loss: (0.0507) |  Loss2: (0.0000) | Acc: (98.00%) (11460/11648)
Epoch: 219 | Batch_idx: 100 |  Loss: (0.0504) |  Loss2: (0.0000) | Acc: (98.00%) (12719/12928)
Epoch: 219 | Batch_idx: 110 |  Loss: (0.0495) |  Loss2: (0.0000) | Acc: (98.00%) (13980/14208)
Epoch: 219 | Batch_idx: 120 |  Loss: (0.0497) |  Loss2: (0.0000) | Acc: (98.00%) (15235/15488)
Epoch: 219 | Batch_idx: 130 |  Loss: (0.0503) |  Loss2: (0.0000) | Acc: (98.00%) (16490/16768)
Epoch: 219 | Batch_idx: 140 |  Loss: (0.0508) |  Loss2: (0.0000) | Acc: (98.00%) (17744/18048)
Epoch: 219 | Batch_idx: 150 |  Loss: (0.0509) |  Loss2: (0.0000) | Acc: (98.00%) (19002/19328)
Epoch: 219 | Batch_idx: 160 |  Loss: (0.0503) |  Loss2: (0.0000) | Acc: (98.00%) (20266/20608)
Epoch: 219 | Batch_idx: 170 |  Loss: (0.0503) |  Loss2: (0.0000) | Acc: (98.00%) (21526/21888)
Epoch: 219 | Batch_idx: 180 |  Loss: (0.0505) |  Loss2: (0.0000) | Acc: (98.00%) (22782/23168)
Epoch: 219 | Batch_idx: 190 |  Loss: (0.0500) |  Loss2: (0.0000) | Acc: (98.00%) (24044/24448)
Epoch: 219 | Batch_idx: 200 |  Loss: (0.0499) |  Loss2: (0.0000) | Acc: (98.00%) (25307/25728)
Epoch: 219 | Batch_idx: 210 |  Loss: (0.0501) |  Loss2: (0.0000) | Acc: (98.00%) (26564/27008)
Epoch: 219 | Batch_idx: 220 |  Loss: (0.0501) |  Loss2: (0.0000) | Acc: (98.00%) (27824/28288)
Epoch: 219 | Batch_idx: 230 |  Loss: (0.0499) |  Loss2: (0.0000) | Acc: (98.00%) (29084/29568)
Epoch: 219 | Batch_idx: 240 |  Loss: (0.0497) |  Loss2: (0.0000) | Acc: (98.00%) (30344/30848)
Epoch: 219 | Batch_idx: 250 |  Loss: (0.0496) |  Loss2: (0.0000) | Acc: (98.00%) (31605/32128)
Epoch: 219 | Batch_idx: 260 |  Loss: (0.0498) |  Loss2: (0.0000) | Acc: (98.00%) (32863/33408)
Epoch: 219 | Batch_idx: 270 |  Loss: (0.0505) |  Loss2: (0.0000) | Acc: (98.00%) (34110/34688)
Epoch: 219 | Batch_idx: 280 |  Loss: (0.0508) |  Loss2: (0.0000) | Acc: (98.00%) (35364/35968)
Epoch: 219 | Batch_idx: 290 |  Loss: (0.0509) |  Loss2: (0.0000) | Acc: (98.00%) (36620/37248)
Epoch: 219 | Batch_idx: 300 |  Loss: (0.0512) |  Loss2: (0.0000) | Acc: (98.00%) (37876/38528)
Epoch: 219 | Batch_idx: 310 |  Loss: (0.0514) |  Loss2: (0.0000) | Acc: (98.00%) (39137/39808)
Epoch: 219 | Batch_idx: 320 |  Loss: (0.0516) |  Loss2: (0.0000) | Acc: (98.00%) (40391/41088)
Epoch: 219 | Batch_idx: 330 |  Loss: (0.0519) |  Loss2: (0.0000) | Acc: (98.00%) (41639/42368)
Epoch: 219 | Batch_idx: 340 |  Loss: (0.0521) |  Loss2: (0.0000) | Acc: (98.00%) (42896/43648)
Epoch: 219 | Batch_idx: 350 |  Loss: (0.0520) |  Loss2: (0.0000) | Acc: (98.00%) (44154/44928)
Epoch: 219 | Batch_idx: 360 |  Loss: (0.0521) |  Loss2: (0.0000) | Acc: (98.00%) (45408/46208)
Epoch: 219 | Batch_idx: 370 |  Loss: (0.0520) |  Loss2: (0.0000) | Acc: (98.00%) (46669/47488)
Epoch: 219 | Batch_idx: 380 |  Loss: (0.0521) |  Loss2: (0.0000) | Acc: (98.00%) (47926/48768)
Epoch: 219 | Batch_idx: 390 |  Loss: (0.0522) |  Loss2: (0.0000) | Acc: (98.00%) (49131/50000)
# TEST : Loss: (0.4050) | Acc: (89.00%) (8915/10000)
percent tensor([0.5263, 0.5271, 0.5297, 0.5292, 0.5310, 0.5324, 0.5297, 0.5315, 0.5274,
        0.5262, 0.5251, 0.5280, 0.5255, 0.5279, 0.5282, 0.5271],
       device='cuda:0') torch.Size([16])
percent tensor([0.5292, 0.5408, 0.5271, 0.5235, 0.5220, 0.5370, 0.5317, 0.5212, 0.5272,
        0.5351, 0.5340, 0.5316, 0.5394, 0.5291, 0.5343, 0.5366],
       device='cuda:0') torch.Size([16])
percent tensor([0.6086, 0.5668, 0.6665, 0.6876, 0.6789, 0.6507, 0.6259, 0.6659, 0.6681,
        0.6118, 0.6460, 0.6385, 0.5260, 0.6929, 0.6053, 0.6200],
       device='cuda:0') torch.Size([16])
percent tensor([0.6880, 0.6796, 0.6736, 0.6715, 0.6737, 0.6798, 0.6909, 0.6810, 0.6830,
        0.6910, 0.6852, 0.6822, 0.6843, 0.6812, 0.6856, 0.6943],
       device='cuda:0') torch.Size([16])
percent tensor([0.6779, 0.6241, 0.7185, 0.7076, 0.7251, 0.7914, 0.6502, 0.6620, 0.6690,
        0.6824, 0.6026, 0.6668, 0.6536, 0.6764, 0.6258, 0.7550],
       device='cuda:0') torch.Size([16])
percent tensor([0.6694, 0.7516, 0.7234, 0.7488, 0.7189, 0.7999, 0.7239, 0.5339, 0.7576,
        0.7290, 0.8048, 0.7288, 0.7911, 0.7711, 0.6278, 0.6711],
       device='cuda:0') torch.Size([16])
percent tensor([0.5703, 0.6800, 0.6927, 0.7078, 0.7250, 0.6597, 0.6726, 0.6340, 0.6285,
        0.7202, 0.6929, 0.6325, 0.6458, 0.5441, 0.6058, 0.5538],
       device='cuda:0') torch.Size([16])
percent tensor([0.9999, 0.9997, 0.9998, 0.9999, 0.9997, 0.9994, 0.9997, 0.9996, 0.9999,
        0.9999, 0.9999, 0.9998, 0.9999, 0.9996, 0.9994, 0.9996],
       device='cuda:0') torch.Size([16])
Epoch: 220 | Batch_idx: 0 |  Loss: (0.0408) |  Loss2: (0.0000) | Acc: (99.00%) (127/128)
Epoch: 220 | Batch_idx: 10 |  Loss: (0.0485) |  Loss2: (0.0000) | Acc: (98.00%) (1383/1408)
Epoch: 220 | Batch_idx: 20 |  Loss: (0.0508) |  Loss2: (0.0000) | Acc: (98.00%) (2643/2688)
Epoch: 220 | Batch_idx: 30 |  Loss: (0.0465) |  Loss2: (0.0000) | Acc: (98.00%) (3908/3968)
Epoch: 220 | Batch_idx: 40 |  Loss: (0.0454) |  Loss2: (0.0000) | Acc: (98.00%) (5172/5248)
Epoch: 220 | Batch_idx: 50 |  Loss: (0.0456) |  Loss2: (0.0000) | Acc: (98.00%) (6433/6528)
Epoch: 220 | Batch_idx: 60 |  Loss: (0.0454) |  Loss2: (0.0000) | Acc: (98.00%) (7691/7808)
Epoch: 220 | Batch_idx: 70 |  Loss: (0.0449) |  Loss2: (0.0000) | Acc: (98.00%) (8953/9088)
Epoch: 220 | Batch_idx: 80 |  Loss: (0.0461) |  Loss2: (0.0000) | Acc: (98.00%) (10208/10368)
Epoch: 220 | Batch_idx: 90 |  Loss: (0.0458) |  Loss2: (0.0000) | Acc: (98.00%) (11469/11648)
Epoch: 220 | Batch_idx: 100 |  Loss: (0.0457) |  Loss2: (0.0000) | Acc: (98.00%) (12732/12928)
Epoch: 220 | Batch_idx: 110 |  Loss: (0.0459) |  Loss2: (0.0000) | Acc: (98.00%) (13992/14208)
Epoch: 220 | Batch_idx: 120 |  Loss: (0.0471) |  Loss2: (0.0000) | Acc: (98.00%) (15245/15488)
Epoch: 220 | Batch_idx: 130 |  Loss: (0.0469) |  Loss2: (0.0000) | Acc: (98.00%) (16507/16768)
Epoch: 220 | Batch_idx: 140 |  Loss: (0.0473) |  Loss2: (0.0000) | Acc: (98.00%) (17762/18048)
Epoch: 220 | Batch_idx: 150 |  Loss: (0.0472) |  Loss2: (0.0000) | Acc: (98.00%) (19023/19328)
Epoch: 220 | Batch_idx: 160 |  Loss: (0.0469) |  Loss2: (0.0000) | Acc: (98.00%) (20289/20608)
Epoch: 220 | Batch_idx: 170 |  Loss: (0.0470) |  Loss2: (0.0000) | Acc: (98.00%) (21551/21888)
Epoch: 220 | Batch_idx: 180 |  Loss: (0.0467) |  Loss2: (0.0000) | Acc: (98.00%) (22811/23168)
Epoch: 220 | Batch_idx: 190 |  Loss: (0.0472) |  Loss2: (0.0000) | Acc: (98.00%) (24070/24448)
Epoch: 220 | Batch_idx: 200 |  Loss: (0.0474) |  Loss2: (0.0000) | Acc: (98.00%) (25327/25728)
Epoch: 220 | Batch_idx: 210 |  Loss: (0.0477) |  Loss2: (0.0000) | Acc: (98.00%) (26587/27008)
Epoch: 220 | Batch_idx: 220 |  Loss: (0.0478) |  Loss2: (0.0000) | Acc: (98.00%) (27846/28288)
Epoch: 220 | Batch_idx: 230 |  Loss: (0.0477) |  Loss2: (0.0000) | Acc: (98.00%) (29104/29568)
Epoch: 220 | Batch_idx: 240 |  Loss: (0.0478) |  Loss2: (0.0000) | Acc: (98.00%) (30362/30848)
Epoch: 220 | Batch_idx: 250 |  Loss: (0.0478) |  Loss2: (0.0000) | Acc: (98.00%) (31618/32128)
Epoch: 220 | Batch_idx: 260 |  Loss: (0.0477) |  Loss2: (0.0000) | Acc: (98.00%) (32879/33408)
Epoch: 220 | Batch_idx: 270 |  Loss: (0.0478) |  Loss2: (0.0000) | Acc: (98.00%) (34142/34688)
Epoch: 220 | Batch_idx: 280 |  Loss: (0.0477) |  Loss2: (0.0000) | Acc: (98.00%) (35400/35968)
Epoch: 220 | Batch_idx: 290 |  Loss: (0.0481) |  Loss2: (0.0000) | Acc: (98.00%) (36656/37248)
Epoch: 220 | Batch_idx: 300 |  Loss: (0.0481) |  Loss2: (0.0000) | Acc: (98.00%) (37916/38528)
Epoch: 220 | Batch_idx: 310 |  Loss: (0.0483) |  Loss2: (0.0000) | Acc: (98.00%) (39172/39808)
Epoch: 220 | Batch_idx: 320 |  Loss: (0.0484) |  Loss2: (0.0000) | Acc: (98.00%) (40429/41088)
Epoch: 220 | Batch_idx: 330 |  Loss: (0.0482) |  Loss2: (0.0000) | Acc: (98.00%) (41696/42368)
Epoch: 220 | Batch_idx: 340 |  Loss: (0.0487) |  Loss2: (0.0000) | Acc: (98.00%) (42950/43648)
Epoch: 220 | Batch_idx: 350 |  Loss: (0.0485) |  Loss2: (0.0000) | Acc: (98.00%) (44216/44928)
Epoch: 220 | Batch_idx: 360 |  Loss: (0.0489) |  Loss2: (0.0000) | Acc: (98.00%) (45466/46208)
Epoch: 220 | Batch_idx: 370 |  Loss: (0.0490) |  Loss2: (0.0000) | Acc: (98.00%) (46720/47488)
Epoch: 220 | Batch_idx: 380 |  Loss: (0.0488) |  Loss2: (0.0000) | Acc: (98.00%) (47983/48768)
Epoch: 220 | Batch_idx: 390 |  Loss: (0.0489) |  Loss2: (0.0000) | Acc: (98.00%) (49191/50000)
=> saving checkpoint 'drive/app/torch/save_Schedule/checkpoint_220.pth.tar'
# TEST : Loss: (0.4319) | Acc: (88.00%) (8879/10000)
percent tensor([0.5283, 0.5296, 0.5297, 0.5304, 0.5319, 0.5345, 0.5320, 0.5328, 0.5294,
        0.5282, 0.5281, 0.5288, 0.5279, 0.5303, 0.5304, 0.5291],
       device='cuda:0') torch.Size([16])
percent tensor([0.5322, 0.5433, 0.5283, 0.5273, 0.5248, 0.5400, 0.5352, 0.5214, 0.5295,
        0.5374, 0.5366, 0.5340, 0.5414, 0.5321, 0.5386, 0.5407],
       device='cuda:0') torch.Size([16])
percent tensor([0.6155, 0.5577, 0.6740, 0.6938, 0.6823, 0.6632, 0.6138, 0.6718, 0.6629,
        0.6054, 0.6376, 0.6319, 0.5201, 0.6832, 0.6106, 0.6202],
       device='cuda:0') torch.Size([16])
percent tensor([0.6861, 0.6789, 0.6735, 0.6742, 0.6765, 0.6781, 0.6901, 0.6826, 0.6846,
        0.6890, 0.6849, 0.6803, 0.6824, 0.6796, 0.6861, 0.6924],
       device='cuda:0') torch.Size([16])
percent tensor([0.6948, 0.6432, 0.7010, 0.7133, 0.7085, 0.8099, 0.6470, 0.6653, 0.6854,
        0.6819, 0.6207, 0.6618, 0.6769, 0.6816, 0.6469, 0.7704],
       device='cuda:0') torch.Size([16])
percent tensor([0.6857, 0.7575, 0.7210, 0.7245, 0.7135, 0.8035, 0.7350, 0.5477, 0.7531,
        0.7354, 0.8119, 0.7128, 0.7947, 0.7904, 0.6055, 0.6765],
       device='cuda:0') torch.Size([16])
percent tensor([0.5691, 0.6807, 0.6883, 0.6750, 0.7101, 0.6686, 0.6785, 0.6215, 0.6198,
        0.7142, 0.7120, 0.6244, 0.6535, 0.5665, 0.5797, 0.5435],
       device='cuda:0') torch.Size([16])
percent tensor([0.9999, 0.9998, 0.9998, 0.9999, 0.9994, 0.9988, 0.9997, 0.9996, 0.9998,
        0.9999, 0.9999, 0.9998, 0.9999, 0.9996, 0.9995, 0.9995],
       device='cuda:0') torch.Size([16])
Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 3, 3, 3]) tensor(183.0218, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(838.8586, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(841.4991, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([128, 64, 3, 3]) tensor(1514.1650, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([128, 64, 1, 1]) tensor(474.8218, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([128, 128, 3, 3]) tensor(2319.9126, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([256, 128, 3, 3]) tensor(4262.3765, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([256, 128, 1, 1]) tensor(1335.7396, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([256, 256, 3, 3]) tensor(6350.6880, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([512, 256, 3, 3]) tensor(11469.6699, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([512, 256, 1, 1]) tensor(3755.1277, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([512, 512, 3, 3]) tensor(15865.8115, device='cuda:0', grad_fn=<NormBackward0>)
Epoch: 221 | Batch_idx: 0 |  Loss: (0.0099) |  Loss2: (0.0000) | Acc: (100.00%) (128/128)
Epoch: 221 | Batch_idx: 10 |  Loss: (0.0426) |  Loss2: (0.0000) | Acc: (98.00%) (1389/1408)
Epoch: 221 | Batch_idx: 20 |  Loss: (0.0395) |  Loss2: (0.0000) | Acc: (98.00%) (2654/2688)
Epoch: 221 | Batch_idx: 30 |  Loss: (0.0405) |  Loss2: (0.0000) | Acc: (98.00%) (3914/3968)
Epoch: 221 | Batch_idx: 40 |  Loss: (0.0413) |  Loss2: (0.0000) | Acc: (98.00%) (5177/5248)
Epoch: 221 | Batch_idx: 50 |  Loss: (0.0434) |  Loss2: (0.0000) | Acc: (98.00%) (6432/6528)
Epoch: 221 | Batch_idx: 60 |  Loss: (0.0446) |  Loss2: (0.0000) | Acc: (98.00%) (7693/7808)
Epoch: 221 | Batch_idx: 70 |  Loss: (0.0458) |  Loss2: (0.0000) | Acc: (98.00%) (8950/9088)
Epoch: 221 | Batch_idx: 80 |  Loss: (0.0469) |  Loss2: (0.0000) | Acc: (98.00%) (10208/10368)
Epoch: 221 | Batch_idx: 90 |  Loss: (0.0477) |  Loss2: (0.0000) | Acc: (98.00%) (11463/11648)
Epoch: 221 | Batch_idx: 100 |  Loss: (0.0480) |  Loss2: (0.0000) | Acc: (98.00%) (12723/12928)
Epoch: 221 | Batch_idx: 110 |  Loss: (0.0471) |  Loss2: (0.0000) | Acc: (98.00%) (13988/14208)
Epoch: 221 | Batch_idx: 120 |  Loss: (0.0476) |  Loss2: (0.0000) | Acc: (98.00%) (15246/15488)
Epoch: 221 | Batch_idx: 130 |  Loss: (0.0474) |  Loss2: (0.0000) | Acc: (98.00%) (16511/16768)
Epoch: 221 | Batch_idx: 140 |  Loss: (0.0474) |  Loss2: (0.0000) | Acc: (98.00%) (17770/18048)
Epoch: 221 | Batch_idx: 150 |  Loss: (0.0474) |  Loss2: (0.0000) | Acc: (98.00%) (19033/19328)
Epoch: 221 | Batch_idx: 160 |  Loss: (0.0476) |  Loss2: (0.0000) | Acc: (98.00%) (20292/20608)
Epoch: 221 | Batch_idx: 170 |  Loss: (0.0477) |  Loss2: (0.0000) | Acc: (98.00%) (21550/21888)
Epoch: 221 | Batch_idx: 180 |  Loss: (0.0476) |  Loss2: (0.0000) | Acc: (98.00%) (22816/23168)
Epoch: 221 | Batch_idx: 190 |  Loss: (0.0479) |  Loss2: (0.0000) | Acc: (98.00%) (24073/24448)
Epoch: 221 | Batch_idx: 200 |  Loss: (0.0479) |  Loss2: (0.0000) | Acc: (98.00%) (25331/25728)
Epoch: 221 | Batch_idx: 210 |  Loss: (0.0476) |  Loss2: (0.0000) | Acc: (98.00%) (26594/27008)
Epoch: 221 | Batch_idx: 220 |  Loss: (0.0475) |  Loss2: (0.0000) | Acc: (98.00%) (27856/28288)
Epoch: 221 | Batch_idx: 230 |  Loss: (0.0474) |  Loss2: (0.0000) | Acc: (98.00%) (29118/29568)
Epoch: 221 | Batch_idx: 240 |  Loss: (0.0471) |  Loss2: (0.0000) | Acc: (98.00%) (30387/30848)
Epoch: 221 | Batch_idx: 250 |  Loss: (0.0468) |  Loss2: (0.0000) | Acc: (98.00%) (31651/32128)
Epoch: 221 | Batch_idx: 260 |  Loss: (0.0464) |  Loss2: (0.0000) | Acc: (98.00%) (32917/33408)
Epoch: 221 | Batch_idx: 270 |  Loss: (0.0460) |  Loss2: (0.0000) | Acc: (98.00%) (34184/34688)
Epoch: 221 | Batch_idx: 280 |  Loss: (0.0457) |  Loss2: (0.0000) | Acc: (98.00%) (35450/35968)
Epoch: 221 | Batch_idx: 290 |  Loss: (0.0453) |  Loss2: (0.0000) | Acc: (98.00%) (36714/37248)
Epoch: 221 | Batch_idx: 300 |  Loss: (0.0450) |  Loss2: (0.0000) | Acc: (98.00%) (37981/38528)
Epoch: 221 | Batch_idx: 310 |  Loss: (0.0449) |  Loss2: (0.0000) | Acc: (98.00%) (39238/39808)
Epoch: 221 | Batch_idx: 320 |  Loss: (0.0451) |  Loss2: (0.0000) | Acc: (98.00%) (40498/41088)
Epoch: 221 | Batch_idx: 330 |  Loss: (0.0450) |  Loss2: (0.0000) | Acc: (98.00%) (41758/42368)
Epoch: 221 | Batch_idx: 340 |  Loss: (0.0449) |  Loss2: (0.0000) | Acc: (98.00%) (43018/43648)
Epoch: 221 | Batch_idx: 350 |  Loss: (0.0449) |  Loss2: (0.0000) | Acc: (98.00%) (44284/44928)
Epoch: 221 | Batch_idx: 360 |  Loss: (0.0453) |  Loss2: (0.0000) | Acc: (98.00%) (45537/46208)
Epoch: 221 | Batch_idx: 370 |  Loss: (0.0451) |  Loss2: (0.0000) | Acc: (98.00%) (46803/47488)
Epoch: 221 | Batch_idx: 380 |  Loss: (0.0449) |  Loss2: (0.0000) | Acc: (98.00%) (48071/48768)
Epoch: 221 | Batch_idx: 390 |  Loss: (0.0448) |  Loss2: (0.0000) | Acc: (98.00%) (49284/50000)
# TEST : Loss: (0.4080) | Acc: (89.00%) (8975/10000)
percent tensor([0.5283, 0.5297, 0.5312, 0.5312, 0.5330, 0.5348, 0.5320, 0.5336, 0.5291,
        0.5286, 0.5275, 0.5299, 0.5276, 0.5301, 0.5307, 0.5293],
       device='cuda:0') torch.Size([16])
percent tensor([0.5305, 0.5416, 0.5287, 0.5273, 0.5235, 0.5395, 0.5326, 0.5221, 0.5272,
        0.5361, 0.5349, 0.5320, 0.5393, 0.5286, 0.5365, 0.5393],
       device='cuda:0') torch.Size([16])
percent tensor([0.6261, 0.5701, 0.6760, 0.6951, 0.6908, 0.6711, 0.6312, 0.6717, 0.6727,
        0.6139, 0.6496, 0.6461, 0.5334, 0.6939, 0.6211, 0.6315],
       device='cuda:0') torch.Size([16])
percent tensor([0.6857, 0.6777, 0.6731, 0.6709, 0.6727, 0.6794, 0.6877, 0.6789, 0.6828,
        0.6888, 0.6834, 0.6799, 0.6822, 0.6803, 0.6841, 0.6931],
       device='cuda:0') torch.Size([16])
percent tensor([0.6803, 0.6252, 0.6944, 0.7097, 0.6892, 0.7844, 0.6311, 0.6425, 0.6788,
        0.6803, 0.6133, 0.6494, 0.6684, 0.6749, 0.6300, 0.7544],
       device='cuda:0') torch.Size([16])
percent tensor([0.6646, 0.7623, 0.7134, 0.7271, 0.6934, 0.7800, 0.7267, 0.5315, 0.7577,
        0.7212, 0.7967, 0.7191, 0.8000, 0.7726, 0.5991, 0.6505],
       device='cuda:0') torch.Size([16])
percent tensor([0.5756, 0.6798, 0.6820, 0.6877, 0.7045, 0.6534, 0.6778, 0.6249, 0.6339,
        0.7010, 0.6969, 0.6308, 0.6658, 0.5437, 0.5880, 0.5461],
       device='cuda:0') torch.Size([16])
percent tensor([0.9999, 0.9998, 0.9999, 1.0000, 0.9992, 0.9985, 0.9998, 0.9996, 0.9999,
        0.9999, 0.9999, 0.9998, 1.0000, 0.9995, 0.9995, 0.9996],
       device='cuda:0') torch.Size([16])
Epoch: 222 | Batch_idx: 0 |  Loss: (0.0175) |  Loss2: (0.0000) | Acc: (100.00%) (128/128)
Epoch: 222 | Batch_idx: 10 |  Loss: (0.0310) |  Loss2: (0.0000) | Acc: (99.00%) (1399/1408)
Epoch: 222 | Batch_idx: 20 |  Loss: (0.0349) |  Loss2: (0.0000) | Acc: (99.00%) (2667/2688)
Epoch: 222 | Batch_idx: 30 |  Loss: (0.0404) |  Loss2: (0.0000) | Acc: (98.00%) (3922/3968)
Epoch: 222 | Batch_idx: 40 |  Loss: (0.0445) |  Loss2: (0.0000) | Acc: (98.00%) (5178/5248)
Epoch: 222 | Batch_idx: 50 |  Loss: (0.0462) |  Loss2: (0.0000) | Acc: (98.00%) (6434/6528)
Epoch: 222 | Batch_idx: 60 |  Loss: (0.0463) |  Loss2: (0.0000) | Acc: (98.00%) (7700/7808)
Epoch: 222 | Batch_idx: 70 |  Loss: (0.0471) |  Loss2: (0.0000) | Acc: (98.00%) (8951/9088)
Epoch: 222 | Batch_idx: 80 |  Loss: (0.0466) |  Loss2: (0.0000) | Acc: (98.00%) (10213/10368)
Epoch: 222 | Batch_idx: 90 |  Loss: (0.0463) |  Loss2: (0.0000) | Acc: (98.00%) (11474/11648)
Epoch: 222 | Batch_idx: 100 |  Loss: (0.0451) |  Loss2: (0.0000) | Acc: (98.00%) (12738/12928)
Epoch: 222 | Batch_idx: 110 |  Loss: (0.0449) |  Loss2: (0.0000) | Acc: (98.00%) (14003/14208)
Epoch: 222 | Batch_idx: 120 |  Loss: (0.0452) |  Loss2: (0.0000) | Acc: (98.00%) (15260/15488)
Epoch: 222 | Batch_idx: 130 |  Loss: (0.0451) |  Loss2: (0.0000) | Acc: (98.00%) (16517/16768)
Epoch: 222 | Batch_idx: 140 |  Loss: (0.0457) |  Loss2: (0.0000) | Acc: (98.00%) (17777/18048)
Epoch: 222 | Batch_idx: 150 |  Loss: (0.0459) |  Loss2: (0.0000) | Acc: (98.00%) (19035/19328)
Epoch: 222 | Batch_idx: 160 |  Loss: (0.0451) |  Loss2: (0.0000) | Acc: (98.00%) (20304/20608)
Epoch: 222 | Batch_idx: 170 |  Loss: (0.0450) |  Loss2: (0.0000) | Acc: (98.00%) (21564/21888)
Epoch: 222 | Batch_idx: 180 |  Loss: (0.0445) |  Loss2: (0.0000) | Acc: (98.00%) (22834/23168)
Epoch: 222 | Batch_idx: 190 |  Loss: (0.0446) |  Loss2: (0.0000) | Acc: (98.00%) (24097/24448)
Epoch: 222 | Batch_idx: 200 |  Loss: (0.0448) |  Loss2: (0.0000) | Acc: (98.00%) (25355/25728)
Epoch: 222 | Batch_idx: 210 |  Loss: (0.0452) |  Loss2: (0.0000) | Acc: (98.00%) (26613/27008)
Epoch: 222 | Batch_idx: 220 |  Loss: (0.0449) |  Loss2: (0.0000) | Acc: (98.00%) (27879/28288)
Epoch: 222 | Batch_idx: 230 |  Loss: (0.0453) |  Loss2: (0.0000) | Acc: (98.00%) (29139/29568)
Epoch: 222 | Batch_idx: 240 |  Loss: (0.0453) |  Loss2: (0.0000) | Acc: (98.00%) (30401/30848)
Epoch: 222 | Batch_idx: 250 |  Loss: (0.0456) |  Loss2: (0.0000) | Acc: (98.00%) (31663/32128)
Epoch: 222 | Batch_idx: 260 |  Loss: (0.0454) |  Loss2: (0.0000) | Acc: (98.00%) (32927/33408)
Epoch: 222 | Batch_idx: 270 |  Loss: (0.0461) |  Loss2: (0.0000) | Acc: (98.00%) (34180/34688)
Epoch: 222 | Batch_idx: 280 |  Loss: (0.0462) |  Loss2: (0.0000) | Acc: (98.00%) (35436/35968)
Epoch: 222 | Batch_idx: 290 |  Loss: (0.0459) |  Loss2: (0.0000) | Acc: (98.00%) (36701/37248)
Epoch: 222 | Batch_idx: 300 |  Loss: (0.0463) |  Loss2: (0.0000) | Acc: (98.00%) (37959/38528)
Epoch: 222 | Batch_idx: 310 |  Loss: (0.0464) |  Loss2: (0.0000) | Acc: (98.00%) (39224/39808)
Epoch: 222 | Batch_idx: 320 |  Loss: (0.0461) |  Loss2: (0.0000) | Acc: (98.00%) (40489/41088)
Epoch: 222 | Batch_idx: 330 |  Loss: (0.0461) |  Loss2: (0.0000) | Acc: (98.00%) (41752/42368)
Epoch: 222 | Batch_idx: 340 |  Loss: (0.0463) |  Loss2: (0.0000) | Acc: (98.00%) (43010/43648)
Epoch: 222 | Batch_idx: 350 |  Loss: (0.0465) |  Loss2: (0.0000) | Acc: (98.00%) (44266/44928)
Epoch: 222 | Batch_idx: 360 |  Loss: (0.0469) |  Loss2: (0.0000) | Acc: (98.00%) (45521/46208)
Epoch: 222 | Batch_idx: 370 |  Loss: (0.0470) |  Loss2: (0.0000) | Acc: (98.00%) (46780/47488)
Epoch: 222 | Batch_idx: 380 |  Loss: (0.0473) |  Loss2: (0.0000) | Acc: (98.00%) (48034/48768)
Epoch: 222 | Batch_idx: 390 |  Loss: (0.0473) |  Loss2: (0.0000) | Acc: (98.00%) (49245/50000)
# TEST : Loss: (0.4126) | Acc: (89.00%) (8937/10000)
percent tensor([0.5277, 0.5305, 0.5284, 0.5310, 0.5311, 0.5346, 0.5317, 0.5331, 0.5288,
        0.5281, 0.5276, 0.5276, 0.5273, 0.5321, 0.5308, 0.5295],
       device='cuda:0') torch.Size([16])
percent tensor([0.5331, 0.5438, 0.5285, 0.5273, 0.5248, 0.5405, 0.5348, 0.5230, 0.5307,
        0.5386, 0.5372, 0.5331, 0.5423, 0.5320, 0.5388, 0.5405],
       device='cuda:0') torch.Size([16])
percent tensor([0.6135, 0.5683, 0.6708, 0.6940, 0.6819, 0.6614, 0.6261, 0.6634, 0.6656,
        0.6066, 0.6453, 0.6322, 0.5223, 0.6985, 0.6120, 0.6265],
       device='cuda:0') torch.Size([16])
percent tensor([0.6820, 0.6756, 0.6692, 0.6666, 0.6692, 0.6720, 0.6856, 0.6798, 0.6812,
        0.6850, 0.6813, 0.6751, 0.6794, 0.6800, 0.6809, 0.6901],
       device='cuda:0') torch.Size([16])
percent tensor([0.6892, 0.6533, 0.7054, 0.7147, 0.7071, 0.8006, 0.6601, 0.6561, 0.6798,
        0.7041, 0.6243, 0.6720, 0.6813, 0.6922, 0.6475, 0.7684],
       device='cuda:0') torch.Size([16])
percent tensor([0.6796, 0.7715, 0.7134, 0.7306, 0.6877, 0.7992, 0.7352, 0.5522, 0.7429,
        0.7307, 0.8074, 0.7225, 0.8101, 0.7489, 0.6242, 0.6810],
       device='cuda:0') torch.Size([16])
percent tensor([0.5530, 0.6877, 0.6676, 0.6468, 0.6835, 0.6514, 0.6686, 0.6330, 0.6262,
        0.7227, 0.7037, 0.6272, 0.6785, 0.5578, 0.5736, 0.5402],
       device='cuda:0') torch.Size([16])
percent tensor([0.9999, 0.9998, 0.9998, 0.9999, 0.9995, 0.9992, 0.9998, 0.9997, 0.9999,
        0.9999, 1.0000, 0.9998, 0.9999, 0.9996, 0.9996, 0.9995],
       device='cuda:0') torch.Size([16])
Epoch: 223 | Batch_idx: 0 |  Loss: (0.0280) |  Loss2: (0.0000) | Acc: (99.00%) (127/128)
Epoch: 223 | Batch_idx: 10 |  Loss: (0.0520) |  Loss2: (0.0000) | Acc: (97.00%) (1378/1408)
Epoch: 223 | Batch_idx: 20 |  Loss: (0.0515) |  Loss2: (0.0000) | Acc: (98.00%) (2639/2688)
Epoch: 223 | Batch_idx: 30 |  Loss: (0.0481) |  Loss2: (0.0000) | Acc: (98.00%) (3902/3968)
Epoch: 223 | Batch_idx: 40 |  Loss: (0.0527) |  Loss2: (0.0000) | Acc: (98.00%) (5152/5248)
Epoch: 223 | Batch_idx: 50 |  Loss: (0.0506) |  Loss2: (0.0000) | Acc: (98.00%) (6416/6528)
Epoch: 223 | Batch_idx: 60 |  Loss: (0.0492) |  Loss2: (0.0000) | Acc: (98.00%) (7675/7808)
Epoch: 223 | Batch_idx: 70 |  Loss: (0.0473) |  Loss2: (0.0000) | Acc: (98.00%) (8942/9088)
Epoch: 223 | Batch_idx: 80 |  Loss: (0.0458) |  Loss2: (0.0000) | Acc: (98.00%) (10210/10368)
Epoch: 223 | Batch_idx: 90 |  Loss: (0.0452) |  Loss2: (0.0000) | Acc: (98.00%) (11471/11648)
Epoch: 223 | Batch_idx: 100 |  Loss: (0.0462) |  Loss2: (0.0000) | Acc: (98.00%) (12726/12928)
Epoch: 223 | Batch_idx: 110 |  Loss: (0.0464) |  Loss2: (0.0000) | Acc: (98.00%) (13984/14208)
Epoch: 223 | Batch_idx: 120 |  Loss: (0.0467) |  Loss2: (0.0000) | Acc: (98.00%) (15243/15488)
Epoch: 223 | Batch_idx: 130 |  Loss: (0.0463) |  Loss2: (0.0000) | Acc: (98.00%) (16502/16768)
Epoch: 223 | Batch_idx: 140 |  Loss: (0.0468) |  Loss2: (0.0000) | Acc: (98.00%) (17761/18048)
Epoch: 223 | Batch_idx: 150 |  Loss: (0.0474) |  Loss2: (0.0000) | Acc: (98.00%) (19017/19328)
Epoch: 223 | Batch_idx: 160 |  Loss: (0.0475) |  Loss2: (0.0000) | Acc: (98.00%) (20276/20608)
Epoch: 223 | Batch_idx: 170 |  Loss: (0.0481) |  Loss2: (0.0000) | Acc: (98.00%) (21532/21888)
Epoch: 223 | Batch_idx: 180 |  Loss: (0.0479) |  Loss2: (0.0000) | Acc: (98.00%) (22792/23168)
Epoch: 223 | Batch_idx: 190 |  Loss: (0.0469) |  Loss2: (0.0000) | Acc: (98.00%) (24067/24448)
Epoch: 223 | Batch_idx: 200 |  Loss: (0.0475) |  Loss2: (0.0000) | Acc: (98.00%) (25321/25728)
Epoch: 223 | Batch_idx: 210 |  Loss: (0.0476) |  Loss2: (0.0000) | Acc: (98.00%) (26581/27008)
Epoch: 223 | Batch_idx: 220 |  Loss: (0.0473) |  Loss2: (0.0000) | Acc: (98.00%) (27839/28288)
Epoch: 223 | Batch_idx: 230 |  Loss: (0.0479) |  Loss2: (0.0000) | Acc: (98.00%) (29092/29568)
Epoch: 223 | Batch_idx: 240 |  Loss: (0.0478) |  Loss2: (0.0000) | Acc: (98.00%) (30351/30848)
Epoch: 223 | Batch_idx: 250 |  Loss: (0.0474) |  Loss2: (0.0000) | Acc: (98.00%) (31612/32128)
Epoch: 223 | Batch_idx: 260 |  Loss: (0.0475) |  Loss2: (0.0000) | Acc: (98.00%) (32868/33408)
Epoch: 223 | Batch_idx: 270 |  Loss: (0.0472) |  Loss2: (0.0000) | Acc: (98.00%) (34132/34688)
Epoch: 223 | Batch_idx: 280 |  Loss: (0.0474) |  Loss2: (0.0000) | Acc: (98.00%) (35386/35968)
Epoch: 223 | Batch_idx: 290 |  Loss: (0.0475) |  Loss2: (0.0000) | Acc: (98.00%) (36643/37248)
Epoch: 223 | Batch_idx: 300 |  Loss: (0.0476) |  Loss2: (0.0000) | Acc: (98.00%) (37901/38528)
Epoch: 223 | Batch_idx: 310 |  Loss: (0.0476) |  Loss2: (0.0000) | Acc: (98.00%) (39157/39808)
Epoch: 223 | Batch_idx: 320 |  Loss: (0.0479) |  Loss2: (0.0000) | Acc: (98.00%) (40412/41088)
Epoch: 223 | Batch_idx: 330 |  Loss: (0.0482) |  Loss2: (0.0000) | Acc: (98.00%) (41665/42368)
Epoch: 223 | Batch_idx: 340 |  Loss: (0.0483) |  Loss2: (0.0000) | Acc: (98.00%) (42927/43648)
Epoch: 223 | Batch_idx: 350 |  Loss: (0.0490) |  Loss2: (0.0000) | Acc: (98.00%) (44170/44928)
Epoch: 223 | Batch_idx: 360 |  Loss: (0.0489) |  Loss2: (0.0000) | Acc: (98.00%) (45429/46208)
Epoch: 223 | Batch_idx: 370 |  Loss: (0.0489) |  Loss2: (0.0000) | Acc: (98.00%) (46688/47488)
Epoch: 223 | Batch_idx: 380 |  Loss: (0.0487) |  Loss2: (0.0000) | Acc: (98.00%) (47951/48768)
Epoch: 223 | Batch_idx: 390 |  Loss: (0.0489) |  Loss2: (0.0000) | Acc: (98.00%) (49160/50000)
# TEST : Loss: (0.4303) | Acc: (88.00%) (8872/10000)
percent tensor([0.5286, 0.5304, 0.5301, 0.5318, 0.5324, 0.5354, 0.5322, 0.5336, 0.5296,
        0.5286, 0.5283, 0.5289, 0.5281, 0.5313, 0.5312, 0.5302],
       device='cuda:0') torch.Size([16])
percent tensor([0.5312, 0.5417, 0.5299, 0.5249, 0.5236, 0.5390, 0.5338, 0.5235, 0.5296,
        0.5375, 0.5360, 0.5346, 0.5408, 0.5282, 0.5365, 0.5381],
       device='cuda:0') torch.Size([16])
percent tensor([0.6183, 0.5702, 0.6684, 0.6876, 0.6769, 0.6457, 0.6295, 0.6654, 0.6721,
        0.6148, 0.6556, 0.6342, 0.5358, 0.6899, 0.6087, 0.6282],
       device='cuda:0') torch.Size([16])
percent tensor([0.6851, 0.6770, 0.6736, 0.6733, 0.6752, 0.6792, 0.6888, 0.6802, 0.6830,
        0.6887, 0.6841, 0.6812, 0.6839, 0.6791, 0.6843, 0.6940],
       device='cuda:0') torch.Size([16])
percent tensor([0.6759, 0.6237, 0.6964, 0.7049, 0.6927, 0.8064, 0.6309, 0.6361, 0.6727,
        0.6706, 0.6116, 0.6453, 0.6448, 0.6753, 0.6180, 0.7578],
       device='cuda:0') torch.Size([16])
percent tensor([0.6822, 0.7760, 0.7208, 0.7469, 0.6998, 0.8017, 0.7367, 0.5436, 0.7634,
        0.7323, 0.8141, 0.7371, 0.8087, 0.7901, 0.6294, 0.6828],
       device='cuda:0') torch.Size([16])
percent tensor([0.5601, 0.6873, 0.6784, 0.6692, 0.6910, 0.6465, 0.6679, 0.6215, 0.6345,
        0.7053, 0.6949, 0.6053, 0.6674, 0.5941, 0.5667, 0.5412],
       device='cuda:0') torch.Size([16])
percent tensor([0.9999, 0.9999, 0.9997, 0.9999, 0.9997, 0.9993, 0.9998, 0.9995, 0.9999,
        0.9999, 0.9999, 0.9998, 0.9999, 0.9997, 0.9995, 0.9996],
       device='cuda:0') torch.Size([16])
Epoch: 224 | Batch_idx: 0 |  Loss: (0.0407) |  Loss2: (0.0000) | Acc: (99.00%) (127/128)
Epoch: 224 | Batch_idx: 10 |  Loss: (0.0565) |  Loss2: (0.0000) | Acc: (98.00%) (1385/1408)
Epoch: 224 | Batch_idx: 20 |  Loss: (0.0508) |  Loss2: (0.0000) | Acc: (98.00%) (2647/2688)
Epoch: 224 | Batch_idx: 30 |  Loss: (0.0500) |  Loss2: (0.0000) | Acc: (98.00%) (3905/3968)
Epoch: 224 | Batch_idx: 40 |  Loss: (0.0516) |  Loss2: (0.0000) | Acc: (98.00%) (5158/5248)
Epoch: 224 | Batch_idx: 50 |  Loss: (0.0518) |  Loss2: (0.0000) | Acc: (98.00%) (6419/6528)
Epoch: 224 | Batch_idx: 60 |  Loss: (0.0499) |  Loss2: (0.0000) | Acc: (98.00%) (7684/7808)
Epoch: 224 | Batch_idx: 70 |  Loss: (0.0489) |  Loss2: (0.0000) | Acc: (98.00%) (8949/9088)
Epoch: 224 | Batch_idx: 80 |  Loss: (0.0475) |  Loss2: (0.0000) | Acc: (98.00%) (10215/10368)
Epoch: 224 | Batch_idx: 90 |  Loss: (0.0472) |  Loss2: (0.0000) | Acc: (98.00%) (11479/11648)
Epoch: 224 | Batch_idx: 100 |  Loss: (0.0466) |  Loss2: (0.0000) | Acc: (98.00%) (12744/12928)
Epoch: 224 | Batch_idx: 110 |  Loss: (0.0471) |  Loss2: (0.0000) | Acc: (98.00%) (14005/14208)
Epoch: 224 | Batch_idx: 120 |  Loss: (0.0464) |  Loss2: (0.0000) | Acc: (98.00%) (15267/15488)
Epoch: 224 | Batch_idx: 130 |  Loss: (0.0459) |  Loss2: (0.0000) | Acc: (98.00%) (16532/16768)
Epoch: 224 | Batch_idx: 140 |  Loss: (0.0461) |  Loss2: (0.0000) | Acc: (98.00%) (17791/18048)
Epoch: 224 | Batch_idx: 150 |  Loss: (0.0468) |  Loss2: (0.0000) | Acc: (98.00%) (19047/19328)
Epoch: 224 | Batch_idx: 160 |  Loss: (0.0468) |  Loss2: (0.0000) | Acc: (98.00%) (20306/20608)
Epoch: 224 | Batch_idx: 170 |  Loss: (0.0473) |  Loss2: (0.0000) | Acc: (98.00%) (21563/21888)
Epoch: 224 | Batch_idx: 180 |  Loss: (0.0472) |  Loss2: (0.0000) | Acc: (98.00%) (22828/23168)
Epoch: 224 | Batch_idx: 190 |  Loss: (0.0474) |  Loss2: (0.0000) | Acc: (98.00%) (24090/24448)
Epoch: 224 | Batch_idx: 200 |  Loss: (0.0471) |  Loss2: (0.0000) | Acc: (98.00%) (25351/25728)
Epoch: 224 | Batch_idx: 210 |  Loss: (0.0475) |  Loss2: (0.0000) | Acc: (98.00%) (26609/27008)
Epoch: 224 | Batch_idx: 220 |  Loss: (0.0474) |  Loss2: (0.0000) | Acc: (98.00%) (27873/28288)
Epoch: 224 | Batch_idx: 230 |  Loss: (0.0474) |  Loss2: (0.0000) | Acc: (98.00%) (29130/29568)
Epoch: 224 | Batch_idx: 240 |  Loss: (0.0477) |  Loss2: (0.0000) | Acc: (98.00%) (30386/30848)
Epoch: 224 | Batch_idx: 250 |  Loss: (0.0476) |  Loss2: (0.0000) | Acc: (98.00%) (31646/32128)
Epoch: 224 | Batch_idx: 260 |  Loss: (0.0474) |  Loss2: (0.0000) | Acc: (98.00%) (32907/33408)
Epoch: 224 | Batch_idx: 270 |  Loss: (0.0476) |  Loss2: (0.0000) | Acc: (98.00%) (34166/34688)
Epoch: 224 | Batch_idx: 280 |  Loss: (0.0475) |  Loss2: (0.0000) | Acc: (98.00%) (35425/35968)
Epoch: 224 | Batch_idx: 290 |  Loss: (0.0473) |  Loss2: (0.0000) | Acc: (98.00%) (36687/37248)
Epoch: 224 | Batch_idx: 300 |  Loss: (0.0475) |  Loss2: (0.0000) | Acc: (98.00%) (37942/38528)
Epoch: 224 | Batch_idx: 310 |  Loss: (0.0473) |  Loss2: (0.0000) | Acc: (98.00%) (39207/39808)
Epoch: 224 | Batch_idx: 320 |  Loss: (0.0473) |  Loss2: (0.0000) | Acc: (98.00%) (40468/41088)
Epoch: 224 | Batch_idx: 330 |  Loss: (0.0474) |  Loss2: (0.0000) | Acc: (98.00%) (41721/42368)
Epoch: 224 | Batch_idx: 340 |  Loss: (0.0475) |  Loss2: (0.0000) | Acc: (98.00%) (42979/43648)
Epoch: 224 | Batch_idx: 350 |  Loss: (0.0474) |  Loss2: (0.0000) | Acc: (98.00%) (44241/44928)
Epoch: 224 | Batch_idx: 360 |  Loss: (0.0473) |  Loss2: (0.0000) | Acc: (98.00%) (45505/46208)
Epoch: 224 | Batch_idx: 370 |  Loss: (0.0472) |  Loss2: (0.0000) | Acc: (98.00%) (46766/47488)
Epoch: 224 | Batch_idx: 380 |  Loss: (0.0474) |  Loss2: (0.0000) | Acc: (98.00%) (48026/48768)
Epoch: 224 | Batch_idx: 390 |  Loss: (0.0480) |  Loss2: (0.0000) | Acc: (98.00%) (49227/50000)
# TEST : Loss: (0.4325) | Acc: (88.00%) (8899/10000)
percent tensor([0.5280, 0.5293, 0.5312, 0.5316, 0.5328, 0.5340, 0.5318, 0.5340, 0.5291,
        0.5284, 0.5274, 0.5298, 0.5276, 0.5303, 0.5302, 0.5294],
       device='cuda:0') torch.Size([16])
percent tensor([0.5305, 0.5413, 0.5292, 0.5259, 0.5232, 0.5379, 0.5328, 0.5225, 0.5291,
        0.5362, 0.5352, 0.5332, 0.5400, 0.5295, 0.5357, 0.5383],
       device='cuda:0') torch.Size([16])
percent tensor([0.6127, 0.5701, 0.6646, 0.6892, 0.6769, 0.6519, 0.6249, 0.6638, 0.6632,
        0.6138, 0.6465, 0.6268, 0.5287, 0.6968, 0.6083, 0.6218],
       device='cuda:0') torch.Size([16])
percent tensor([0.6880, 0.6825, 0.6729, 0.6716, 0.6740, 0.6837, 0.6924, 0.6803, 0.6841,
        0.6884, 0.6870, 0.6804, 0.6835, 0.6834, 0.6878, 0.6951],
       device='cuda:0') torch.Size([16])
percent tensor([0.6797, 0.6302, 0.7109, 0.7001, 0.6895, 0.8008, 0.6348, 0.6334, 0.6776,
        0.6842, 0.6218, 0.6596, 0.6683, 0.6836, 0.6244, 0.7571],
       device='cuda:0') torch.Size([16])
percent tensor([0.6646, 0.7561, 0.7342, 0.7438, 0.7153, 0.7807, 0.7344, 0.5554, 0.7591,
        0.7389, 0.8063, 0.7563, 0.8040, 0.7752, 0.6243, 0.6748],
       device='cuda:0') torch.Size([16])
percent tensor([0.5651, 0.6834, 0.6912, 0.6749, 0.6938, 0.6341, 0.6635, 0.6380, 0.6479,
        0.7237, 0.7069, 0.6458, 0.6807, 0.5843, 0.5706, 0.5452],
       device='cuda:0') torch.Size([16])
percent tensor([0.9999, 0.9998, 0.9999, 0.9999, 0.9995, 0.9992, 0.9998, 0.9997, 0.9999,
        0.9999, 0.9999, 0.9998, 0.9999, 0.9994, 0.9994, 0.9997],
       device='cuda:0') torch.Size([16])
Epoch: 225 | Batch_idx: 0 |  Loss: (0.0370) |  Loss2: (0.0000) | Acc: (98.00%) (126/128)
Epoch: 225 | Batch_idx: 10 |  Loss: (0.0517) |  Loss2: (0.0000) | Acc: (97.00%) (1378/1408)
Epoch: 225 | Batch_idx: 20 |  Loss: (0.0536) |  Loss2: (0.0000) | Acc: (97.00%) (2634/2688)
Epoch: 225 | Batch_idx: 30 |  Loss: (0.0510) |  Loss2: (0.0000) | Acc: (98.00%) (3893/3968)
Epoch: 225 | Batch_idx: 40 |  Loss: (0.0499) |  Loss2: (0.0000) | Acc: (98.00%) (5149/5248)
Epoch: 225 | Batch_idx: 50 |  Loss: (0.0501) |  Loss2: (0.0000) | Acc: (98.00%) (6410/6528)
Epoch: 225 | Batch_idx: 60 |  Loss: (0.0501) |  Loss2: (0.0000) | Acc: (98.00%) (7669/7808)
Epoch: 225 | Batch_idx: 70 |  Loss: (0.0498) |  Loss2: (0.0000) | Acc: (98.00%) (8929/9088)
Epoch: 225 | Batch_idx: 80 |  Loss: (0.0486) |  Loss2: (0.0000) | Acc: (98.00%) (10190/10368)
Epoch: 225 | Batch_idx: 90 |  Loss: (0.0490) |  Loss2: (0.0000) | Acc: (98.00%) (11444/11648)
Epoch: 225 | Batch_idx: 100 |  Loss: (0.0486) |  Loss2: (0.0000) | Acc: (98.00%) (12703/12928)
Epoch: 225 | Batch_idx: 110 |  Loss: (0.0485) |  Loss2: (0.0000) | Acc: (98.00%) (13958/14208)
Epoch: 225 | Batch_idx: 120 |  Loss: (0.0483) |  Loss2: (0.0000) | Acc: (98.00%) (15220/15488)
Epoch: 225 | Batch_idx: 130 |  Loss: (0.0484) |  Loss2: (0.0000) | Acc: (98.00%) (16481/16768)
Epoch: 225 | Batch_idx: 140 |  Loss: (0.0486) |  Loss2: (0.0000) | Acc: (98.00%) (17738/18048)
Epoch: 225 | Batch_idx: 150 |  Loss: (0.0481) |  Loss2: (0.0000) | Acc: (98.00%) (18998/19328)
Epoch: 225 | Batch_idx: 160 |  Loss: (0.0480) |  Loss2: (0.0000) | Acc: (98.00%) (20260/20608)
Epoch: 225 | Batch_idx: 170 |  Loss: (0.0480) |  Loss2: (0.0000) | Acc: (98.00%) (21517/21888)
Epoch: 225 | Batch_idx: 180 |  Loss: (0.0476) |  Loss2: (0.0000) | Acc: (98.00%) (22779/23168)
Epoch: 225 | Batch_idx: 190 |  Loss: (0.0477) |  Loss2: (0.0000) | Acc: (98.00%) (24039/24448)
Epoch: 225 | Batch_idx: 200 |  Loss: (0.0477) |  Loss2: (0.0000) | Acc: (98.00%) (25297/25728)
Epoch: 225 | Batch_idx: 210 |  Loss: (0.0474) |  Loss2: (0.0000) | Acc: (98.00%) (26558/27008)
Epoch: 225 | Batch_idx: 220 |  Loss: (0.0471) |  Loss2: (0.0000) | Acc: (98.00%) (27825/28288)
Epoch: 225 | Batch_idx: 230 |  Loss: (0.0466) |  Loss2: (0.0000) | Acc: (98.00%) (29091/29568)
Epoch: 225 | Batch_idx: 240 |  Loss: (0.0466) |  Loss2: (0.0000) | Acc: (98.00%) (30353/30848)
Epoch: 225 | Batch_idx: 250 |  Loss: (0.0468) |  Loss2: (0.0000) | Acc: (98.00%) (31611/32128)
Epoch: 225 | Batch_idx: 260 |  Loss: (0.0468) |  Loss2: (0.0000) | Acc: (98.00%) (32876/33408)
Epoch: 225 | Batch_idx: 270 |  Loss: (0.0469) |  Loss2: (0.0000) | Acc: (98.00%) (34133/34688)
Epoch: 225 | Batch_idx: 280 |  Loss: (0.0467) |  Loss2: (0.0000) | Acc: (98.00%) (35396/35968)
Epoch: 225 | Batch_idx: 290 |  Loss: (0.0468) |  Loss2: (0.0000) | Acc: (98.00%) (36657/37248)
Epoch: 225 | Batch_idx: 300 |  Loss: (0.0470) |  Loss2: (0.0000) | Acc: (98.00%) (37911/38528)
Epoch: 225 | Batch_idx: 310 |  Loss: (0.0467) |  Loss2: (0.0000) | Acc: (98.00%) (39177/39808)
Epoch: 225 | Batch_idx: 320 |  Loss: (0.0469) |  Loss2: (0.0000) | Acc: (98.00%) (40433/41088)
Epoch: 225 | Batch_idx: 330 |  Loss: (0.0471) |  Loss2: (0.0000) | Acc: (98.00%) (41692/42368)
Epoch: 225 | Batch_idx: 340 |  Loss: (0.0469) |  Loss2: (0.0000) | Acc: (98.00%) (42950/43648)
Epoch: 225 | Batch_idx: 350 |  Loss: (0.0469) |  Loss2: (0.0000) | Acc: (98.00%) (44211/44928)
Epoch: 225 | Batch_idx: 360 |  Loss: (0.0470) |  Loss2: (0.0000) | Acc: (98.00%) (45469/46208)
Epoch: 225 | Batch_idx: 370 |  Loss: (0.0471) |  Loss2: (0.0000) | Acc: (98.00%) (46724/47488)
Epoch: 225 | Batch_idx: 380 |  Loss: (0.0471) |  Loss2: (0.0000) | Acc: (98.00%) (47986/48768)
Epoch: 225 | Batch_idx: 390 |  Loss: (0.0476) |  Loss2: (0.0000) | Acc: (98.00%) (49191/50000)
=> saving checkpoint 'drive/app/torch/save_Schedule/checkpoint_225.pth.tar'
# TEST : Loss: (0.4483) | Acc: (89.00%) (8906/10000)
percent tensor([0.5280, 0.5297, 0.5316, 0.5316, 0.5336, 0.5351, 0.5322, 0.5339, 0.5288,
        0.5285, 0.5275, 0.5297, 0.5272, 0.5300, 0.5310, 0.5293],
       device='cuda:0') torch.Size([16])
percent tensor([0.5327, 0.5431, 0.5301, 0.5257, 0.5249, 0.5406, 0.5344, 0.5241, 0.5307,
        0.5379, 0.5369, 0.5340, 0.5426, 0.5294, 0.5382, 0.5401],
       device='cuda:0') torch.Size([16])
percent tensor([0.6083, 0.5548, 0.6549, 0.6879, 0.6760, 0.6478, 0.6154, 0.6599, 0.6580,
        0.5958, 0.6340, 0.6161, 0.5159, 0.6896, 0.6009, 0.6166],
       device='cuda:0') torch.Size([16])
percent tensor([0.6930, 0.6840, 0.6787, 0.6777, 0.6806, 0.6884, 0.6942, 0.6848, 0.6859,
        0.6926, 0.6891, 0.6843, 0.6883, 0.6811, 0.6932, 0.7005],
       device='cuda:0') torch.Size([16])
percent tensor([0.6789, 0.6272, 0.7118, 0.6927, 0.7022, 0.8072, 0.6314, 0.6362, 0.6642,
        0.6731, 0.6013, 0.6468, 0.6669, 0.6519, 0.6213, 0.7534],
       device='cuda:0') torch.Size([16])
percent tensor([0.6493, 0.7572, 0.7066, 0.7215, 0.7012, 0.7809, 0.7323, 0.5374, 0.7518,
        0.7180, 0.7956, 0.7312, 0.8001, 0.7834, 0.5826, 0.6584],
       device='cuda:0') torch.Size([16])
percent tensor([0.5575, 0.6708, 0.6752, 0.6803, 0.6985, 0.6534, 0.6735, 0.6328, 0.6194,
        0.7105, 0.6810, 0.6338, 0.6524, 0.5624, 0.5636, 0.5462],
       device='cuda:0') torch.Size([16])
percent tensor([0.9999, 0.9998, 0.9998, 1.0000, 0.9996, 0.9994, 0.9999, 0.9996, 0.9999,
        0.9999, 0.9999, 0.9999, 0.9999, 0.9996, 0.9995, 0.9997],
       device='cuda:0') torch.Size([16])
Epoch: 226 | Batch_idx: 0 |  Loss: (0.0263) |  Loss2: (0.0000) | Acc: (100.00%) (128/128)
Epoch: 226 | Batch_idx: 10 |  Loss: (0.0340) |  Loss2: (0.0000) | Acc: (99.00%) (1398/1408)
Epoch: 226 | Batch_idx: 20 |  Loss: (0.0345) |  Loss2: (0.0000) | Acc: (99.00%) (2663/2688)
Epoch: 226 | Batch_idx: 30 |  Loss: (0.0382) |  Loss2: (0.0000) | Acc: (98.00%) (3927/3968)
Epoch: 226 | Batch_idx: 40 |  Loss: (0.0381) |  Loss2: (0.0000) | Acc: (98.00%) (5192/5248)
Epoch: 226 | Batch_idx: 50 |  Loss: (0.0382) |  Loss2: (0.0000) | Acc: (98.00%) (6458/6528)
Epoch: 226 | Batch_idx: 60 |  Loss: (0.0400) |  Loss2: (0.0000) | Acc: (98.00%) (7721/7808)
Epoch: 226 | Batch_idx: 70 |  Loss: (0.0407) |  Loss2: (0.0000) | Acc: (98.00%) (8982/9088)
Epoch: 226 | Batch_idx: 80 |  Loss: (0.0408) |  Loss2: (0.0000) | Acc: (98.00%) (10246/10368)
Epoch: 226 | Batch_idx: 90 |  Loss: (0.0404) |  Loss2: (0.0000) | Acc: (98.00%) (11510/11648)
Epoch: 226 | Batch_idx: 100 |  Loss: (0.0429) |  Loss2: (0.0000) | Acc: (98.00%) (12762/12928)
Epoch: 226 | Batch_idx: 110 |  Loss: (0.0426) |  Loss2: (0.0000) | Acc: (98.00%) (14028/14208)
Epoch: 226 | Batch_idx: 120 |  Loss: (0.0431) |  Loss2: (0.0000) | Acc: (98.00%) (15289/15488)
Epoch: 226 | Batch_idx: 130 |  Loss: (0.0434) |  Loss2: (0.0000) | Acc: (98.00%) (16552/16768)
Epoch: 226 | Batch_idx: 140 |  Loss: (0.0447) |  Loss2: (0.0000) | Acc: (98.00%) (17804/18048)
Epoch: 226 | Batch_idx: 150 |  Loss: (0.0455) |  Loss2: (0.0000) | Acc: (98.00%) (19059/19328)
Epoch: 226 | Batch_idx: 160 |  Loss: (0.0452) |  Loss2: (0.0000) | Acc: (98.00%) (20319/20608)
Epoch: 226 | Batch_idx: 170 |  Loss: (0.0451) |  Loss2: (0.0000) | Acc: (98.00%) (21577/21888)
Epoch: 226 | Batch_idx: 180 |  Loss: (0.0457) |  Loss2: (0.0000) | Acc: (98.00%) (22833/23168)
Epoch: 226 | Batch_idx: 190 |  Loss: (0.0460) |  Loss2: (0.0000) | Acc: (98.00%) (24094/24448)
Epoch: 226 | Batch_idx: 200 |  Loss: (0.0461) |  Loss2: (0.0000) | Acc: (98.00%) (25355/25728)
Epoch: 226 | Batch_idx: 210 |  Loss: (0.0460) |  Loss2: (0.0000) | Acc: (98.00%) (26617/27008)
Epoch: 226 | Batch_idx: 220 |  Loss: (0.0459) |  Loss2: (0.0000) | Acc: (98.00%) (27879/28288)
Epoch: 226 | Batch_idx: 230 |  Loss: (0.0456) |  Loss2: (0.0000) | Acc: (98.00%) (29139/29568)
Epoch: 226 | Batch_idx: 240 |  Loss: (0.0455) |  Loss2: (0.0000) | Acc: (98.00%) (30403/30848)
Epoch: 226 | Batch_idx: 250 |  Loss: (0.0455) |  Loss2: (0.0000) | Acc: (98.00%) (31662/32128)
Epoch: 226 | Batch_idx: 260 |  Loss: (0.0453) |  Loss2: (0.0000) | Acc: (98.00%) (32925/33408)
Epoch: 226 | Batch_idx: 270 |  Loss: (0.0450) |  Loss2: (0.0000) | Acc: (98.00%) (34191/34688)
Epoch: 226 | Batch_idx: 280 |  Loss: (0.0448) |  Loss2: (0.0000) | Acc: (98.00%) (35460/35968)
Epoch: 226 | Batch_idx: 290 |  Loss: (0.0445) |  Loss2: (0.0000) | Acc: (98.00%) (36725/37248)
Epoch: 226 | Batch_idx: 300 |  Loss: (0.0446) |  Loss2: (0.0000) | Acc: (98.00%) (37984/38528)
Epoch: 226 | Batch_idx: 310 |  Loss: (0.0449) |  Loss2: (0.0000) | Acc: (98.00%) (39242/39808)
Epoch: 226 | Batch_idx: 320 |  Loss: (0.0448) |  Loss2: (0.0000) | Acc: (98.00%) (40506/41088)
Epoch: 226 | Batch_idx: 330 |  Loss: (0.0451) |  Loss2: (0.0000) | Acc: (98.00%) (41761/42368)
Epoch: 226 | Batch_idx: 340 |  Loss: (0.0453) |  Loss2: (0.0000) | Acc: (98.00%) (43022/43648)
Epoch: 226 | Batch_idx: 350 |  Loss: (0.0454) |  Loss2: (0.0000) | Acc: (98.00%) (44280/44928)
Epoch: 226 | Batch_idx: 360 |  Loss: (0.0455) |  Loss2: (0.0000) | Acc: (98.00%) (45544/46208)
Epoch: 226 | Batch_idx: 370 |  Loss: (0.0454) |  Loss2: (0.0000) | Acc: (98.00%) (46809/47488)
Epoch: 226 | Batch_idx: 380 |  Loss: (0.0451) |  Loss2: (0.0000) | Acc: (98.00%) (48077/48768)
Epoch: 226 | Batch_idx: 390 |  Loss: (0.0449) |  Loss2: (0.0000) | Acc: (98.00%) (49292/50000)
# TEST : Loss: (0.4231) | Acc: (89.00%) (8935/10000)
percent tensor([0.5278, 0.5299, 0.5294, 0.5313, 0.5318, 0.5352, 0.5318, 0.5331, 0.5289,
        0.5278, 0.5275, 0.5279, 0.5271, 0.5313, 0.5309, 0.5295],
       device='cuda:0') torch.Size([16])
percent tensor([0.5307, 0.5409, 0.5275, 0.5238, 0.5224, 0.5390, 0.5322, 0.5207, 0.5287,
        0.5352, 0.5338, 0.5326, 0.5398, 0.5295, 0.5345, 0.5370],
       device='cuda:0') torch.Size([16])
percent tensor([0.6206, 0.5703, 0.6694, 0.6947, 0.6834, 0.6527, 0.6291, 0.6734, 0.6701,
        0.6140, 0.6541, 0.6294, 0.5337, 0.6988, 0.6131, 0.6319],
       device='cuda:0') torch.Size([16])
percent tensor([0.6920, 0.6831, 0.6769, 0.6747, 0.6787, 0.6835, 0.6936, 0.6845, 0.6846,
        0.6925, 0.6876, 0.6853, 0.6869, 0.6829, 0.6900, 0.6977],
       device='cuda:0') torch.Size([16])
percent tensor([0.6842, 0.6435, 0.6857, 0.7049, 0.6947, 0.8195, 0.6349, 0.6443, 0.6760,
        0.6745, 0.6147, 0.6504, 0.6691, 0.6727, 0.6320, 0.7678],
       device='cuda:0') torch.Size([16])
percent tensor([0.6650, 0.7735, 0.7129, 0.7375, 0.6911, 0.8049, 0.7402, 0.5396, 0.7715,
        0.7309, 0.8156, 0.7301, 0.7997, 0.8011, 0.6245, 0.6732],
       device='cuda:0') torch.Size([16])
percent tensor([0.5562, 0.6866, 0.6781, 0.6809, 0.6901, 0.6708, 0.6783, 0.6191, 0.6502,
        0.7078, 0.6908, 0.6234, 0.6724, 0.5750, 0.5620, 0.5433],
       device='cuda:0') torch.Size([16])
percent tensor([0.9999, 0.9998, 0.9998, 1.0000, 0.9996, 0.9995, 0.9998, 0.9996, 0.9999,
        0.9999, 0.9999, 0.9998, 0.9999, 0.9995, 0.9995, 0.9997],
       device='cuda:0') torch.Size([16])
Epoch: 227 | Batch_idx: 0 |  Loss: (0.0389) |  Loss2: (0.0000) | Acc: (99.00%) (127/128)
Epoch: 227 | Batch_idx: 10 |  Loss: (0.0391) |  Loss2: (0.0000) | Acc: (98.00%) (1389/1408)
Epoch: 227 | Batch_idx: 20 |  Loss: (0.0414) |  Loss2: (0.0000) | Acc: (98.00%) (2646/2688)
Epoch: 227 | Batch_idx: 30 |  Loss: (0.0406) |  Loss2: (0.0000) | Acc: (98.00%) (3912/3968)
Epoch: 227 | Batch_idx: 40 |  Loss: (0.0391) |  Loss2: (0.0000) | Acc: (98.00%) (5178/5248)
Epoch: 227 | Batch_idx: 50 |  Loss: (0.0380) |  Loss2: (0.0000) | Acc: (98.00%) (6447/6528)
Epoch: 227 | Batch_idx: 60 |  Loss: (0.0364) |  Loss2: (0.0000) | Acc: (98.00%) (7717/7808)
Epoch: 227 | Batch_idx: 70 |  Loss: (0.0359) |  Loss2: (0.0000) | Acc: (98.00%) (8987/9088)
Epoch: 227 | Batch_idx: 80 |  Loss: (0.0361) |  Loss2: (0.0000) | Acc: (98.00%) (10253/10368)
Epoch: 227 | Batch_idx: 90 |  Loss: (0.0361) |  Loss2: (0.0000) | Acc: (98.00%) (11517/11648)
Epoch: 227 | Batch_idx: 100 |  Loss: (0.0370) |  Loss2: (0.0000) | Acc: (98.00%) (12777/12928)
Epoch: 227 | Batch_idx: 110 |  Loss: (0.0372) |  Loss2: (0.0000) | Acc: (98.00%) (14046/14208)
Epoch: 227 | Batch_idx: 120 |  Loss: (0.0378) |  Loss2: (0.0000) | Acc: (98.00%) (15307/15488)
Epoch: 227 | Batch_idx: 130 |  Loss: (0.0380) |  Loss2: (0.0000) | Acc: (98.00%) (16569/16768)
Epoch: 227 | Batch_idx: 140 |  Loss: (0.0388) |  Loss2: (0.0000) | Acc: (98.00%) (17830/18048)
Epoch: 227 | Batch_idx: 150 |  Loss: (0.0398) |  Loss2: (0.0000) | Acc: (98.00%) (19088/19328)
Epoch: 227 | Batch_idx: 160 |  Loss: (0.0402) |  Loss2: (0.0000) | Acc: (98.00%) (20347/20608)
Epoch: 227 | Batch_idx: 170 |  Loss: (0.0404) |  Loss2: (0.0000) | Acc: (98.00%) (21611/21888)
Epoch: 227 | Batch_idx: 180 |  Loss: (0.0403) |  Loss2: (0.0000) | Acc: (98.00%) (22878/23168)
Epoch: 227 | Batch_idx: 190 |  Loss: (0.0397) |  Loss2: (0.0000) | Acc: (98.00%) (24151/24448)
Epoch: 227 | Batch_idx: 200 |  Loss: (0.0403) |  Loss2: (0.0000) | Acc: (98.00%) (25409/25728)
Epoch: 227 | Batch_idx: 210 |  Loss: (0.0408) |  Loss2: (0.0000) | Acc: (98.00%) (26672/27008)
Epoch: 227 | Batch_idx: 220 |  Loss: (0.0408) |  Loss2: (0.0000) | Acc: (98.00%) (27934/28288)
Epoch: 227 | Batch_idx: 230 |  Loss: (0.0409) |  Loss2: (0.0000) | Acc: (98.00%) (29198/29568)
Epoch: 227 | Batch_idx: 240 |  Loss: (0.0407) |  Loss2: (0.0000) | Acc: (98.00%) (30463/30848)
Epoch: 227 | Batch_idx: 250 |  Loss: (0.0411) |  Loss2: (0.0000) | Acc: (98.00%) (31719/32128)
Epoch: 227 | Batch_idx: 260 |  Loss: (0.0412) |  Loss2: (0.0000) | Acc: (98.00%) (32981/33408)
Epoch: 227 | Batch_idx: 270 |  Loss: (0.0415) |  Loss2: (0.0000) | Acc: (98.00%) (34239/34688)
Epoch: 227 | Batch_idx: 280 |  Loss: (0.0420) |  Loss2: (0.0000) | Acc: (98.00%) (35494/35968)
Epoch: 227 | Batch_idx: 290 |  Loss: (0.0424) |  Loss2: (0.0000) | Acc: (98.00%) (36751/37248)
Epoch: 227 | Batch_idx: 300 |  Loss: (0.0425) |  Loss2: (0.0000) | Acc: (98.00%) (38002/38528)
Epoch: 227 | Batch_idx: 310 |  Loss: (0.0424) |  Loss2: (0.0000) | Acc: (98.00%) (39271/39808)
Epoch: 227 | Batch_idx: 320 |  Loss: (0.0424) |  Loss2: (0.0000) | Acc: (98.00%) (40536/41088)
Epoch: 227 | Batch_idx: 330 |  Loss: (0.0429) |  Loss2: (0.0000) | Acc: (98.00%) (41792/42368)
Epoch: 227 | Batch_idx: 340 |  Loss: (0.0426) |  Loss2: (0.0000) | Acc: (98.00%) (43058/43648)
Epoch: 227 | Batch_idx: 350 |  Loss: (0.0428) |  Loss2: (0.0000) | Acc: (98.00%) (44320/44928)
Epoch: 227 | Batch_idx: 360 |  Loss: (0.0425) |  Loss2: (0.0000) | Acc: (98.00%) (45588/46208)
Epoch: 227 | Batch_idx: 370 |  Loss: (0.0425) |  Loss2: (0.0000) | Acc: (98.00%) (46854/47488)
Epoch: 227 | Batch_idx: 380 |  Loss: (0.0427) |  Loss2: (0.0000) | Acc: (98.00%) (48116/48768)
Epoch: 227 | Batch_idx: 390 |  Loss: (0.0427) |  Loss2: (0.0000) | Acc: (98.00%) (49335/50000)
# TEST : Loss: (0.4226) | Acc: (89.00%) (8922/10000)
percent tensor([0.5279, 0.5307, 0.5297, 0.5321, 0.5325, 0.5356, 0.5326, 0.5333, 0.5288,
        0.5284, 0.5279, 0.5285, 0.5274, 0.5322, 0.5317, 0.5299],
       device='cuda:0') torch.Size([16])
percent tensor([0.5316, 0.5431, 0.5294, 0.5257, 0.5232, 0.5397, 0.5340, 0.5228, 0.5290,
        0.5375, 0.5353, 0.5335, 0.5410, 0.5311, 0.5361, 0.5393],
       device='cuda:0') torch.Size([16])
percent tensor([0.6231, 0.5668, 0.6774, 0.6971, 0.6907, 0.6636, 0.6316, 0.6709, 0.6692,
        0.6127, 0.6504, 0.6382, 0.5304, 0.6995, 0.6128, 0.6335],
       device='cuda:0') torch.Size([16])
percent tensor([0.6942, 0.6845, 0.6797, 0.6760, 0.6788, 0.6861, 0.6951, 0.6871, 0.6889,
        0.6915, 0.6890, 0.6865, 0.6881, 0.6848, 0.6920, 0.6987],
       device='cuda:0') torch.Size([16])
percent tensor([0.6796, 0.6361, 0.7008, 0.7278, 0.7068, 0.8179, 0.6412, 0.6613, 0.6627,
        0.6684, 0.6042, 0.6605, 0.6690, 0.6832, 0.6372, 0.7717],
       device='cuda:0') torch.Size([16])
percent tensor([0.6550, 0.7685, 0.7197, 0.7231, 0.7142, 0.7912, 0.7405, 0.5340, 0.7587,
        0.7191, 0.8083, 0.7229, 0.8058, 0.7669, 0.6156, 0.6557],
       device='cuda:0') torch.Size([16])
percent tensor([0.5503, 0.6865, 0.6861, 0.6741, 0.7109, 0.6203, 0.6785, 0.6318, 0.6453,
        0.7039, 0.6897, 0.6393, 0.6659, 0.5532, 0.5698, 0.5464],
       device='cuda:0') torch.Size([16])
percent tensor([0.9999, 0.9998, 0.9998, 0.9999, 0.9995, 0.9993, 0.9998, 0.9997, 0.9999,
        0.9999, 0.9999, 0.9999, 0.9999, 0.9995, 0.9995, 0.9996],
       device='cuda:0') torch.Size([16])
Epoch: 228 | Batch_idx: 0 |  Loss: (0.0334) |  Loss2: (0.0000) | Acc: (99.00%) (127/128)
Epoch: 228 | Batch_idx: 10 |  Loss: (0.0330) |  Loss2: (0.0000) | Acc: (99.00%) (1398/1408)
Epoch: 228 | Batch_idx: 20 |  Loss: (0.0353) |  Loss2: (0.0000) | Acc: (99.00%) (2663/2688)
Epoch: 228 | Batch_idx: 30 |  Loss: (0.0350) |  Loss2: (0.0000) | Acc: (99.00%) (3930/3968)
Epoch: 228 | Batch_idx: 40 |  Loss: (0.0350) |  Loss2: (0.0000) | Acc: (99.00%) (5197/5248)
Epoch: 228 | Batch_idx: 50 |  Loss: (0.0359) |  Loss2: (0.0000) | Acc: (98.00%) (6457/6528)
Epoch: 228 | Batch_idx: 60 |  Loss: (0.0369) |  Loss2: (0.0000) | Acc: (98.00%) (7719/7808)
Epoch: 228 | Batch_idx: 70 |  Loss: (0.0394) |  Loss2: (0.0000) | Acc: (98.00%) (8973/9088)
Epoch: 228 | Batch_idx: 80 |  Loss: (0.0396) |  Loss2: (0.0000) | Acc: (98.00%) (10236/10368)
Epoch: 228 | Batch_idx: 90 |  Loss: (0.0393) |  Loss2: (0.0000) | Acc: (98.00%) (11498/11648)
Epoch: 228 | Batch_idx: 100 |  Loss: (0.0384) |  Loss2: (0.0000) | Acc: (98.00%) (12767/12928)
Epoch: 228 | Batch_idx: 110 |  Loss: (0.0385) |  Loss2: (0.0000) | Acc: (98.00%) (14030/14208)
Epoch: 228 | Batch_idx: 120 |  Loss: (0.0380) |  Loss2: (0.0000) | Acc: (98.00%) (15296/15488)
Epoch: 228 | Batch_idx: 130 |  Loss: (0.0373) |  Loss2: (0.0000) | Acc: (98.00%) (16569/16768)
Epoch: 228 | Batch_idx: 140 |  Loss: (0.0371) |  Loss2: (0.0000) | Acc: (98.00%) (17835/18048)
Epoch: 228 | Batch_idx: 150 |  Loss: (0.0371) |  Loss2: (0.0000) | Acc: (98.00%) (19102/19328)
Epoch: 228 | Batch_idx: 160 |  Loss: (0.0371) |  Loss2: (0.0000) | Acc: (98.00%) (20366/20608)
Epoch: 228 | Batch_idx: 170 |  Loss: (0.0367) |  Loss2: (0.0000) | Acc: (98.00%) (21638/21888)
Epoch: 228 | Batch_idx: 180 |  Loss: (0.0370) |  Loss2: (0.0000) | Acc: (98.00%) (22900/23168)
Epoch: 228 | Batch_idx: 190 |  Loss: (0.0374) |  Loss2: (0.0000) | Acc: (98.00%) (24159/24448)
Epoch: 228 | Batch_idx: 200 |  Loss: (0.0377) |  Loss2: (0.0000) | Acc: (98.00%) (25417/25728)
Epoch: 228 | Batch_idx: 210 |  Loss: (0.0384) |  Loss2: (0.0000) | Acc: (98.00%) (26676/27008)
Epoch: 228 | Batch_idx: 220 |  Loss: (0.0386) |  Loss2: (0.0000) | Acc: (98.00%) (27944/28288)
Epoch: 228 | Batch_idx: 230 |  Loss: (0.0390) |  Loss2: (0.0000) | Acc: (98.00%) (29202/29568)
Epoch: 228 | Batch_idx: 240 |  Loss: (0.0385) |  Loss2: (0.0000) | Acc: (98.00%) (30473/30848)
Epoch: 228 | Batch_idx: 250 |  Loss: (0.0391) |  Loss2: (0.0000) | Acc: (98.00%) (31731/32128)
Epoch: 228 | Batch_idx: 260 |  Loss: (0.0394) |  Loss2: (0.0000) | Acc: (98.00%) (32991/33408)
Epoch: 228 | Batch_idx: 270 |  Loss: (0.0396) |  Loss2: (0.0000) | Acc: (98.00%) (34256/34688)
Epoch: 228 | Batch_idx: 280 |  Loss: (0.0397) |  Loss2: (0.0000) | Acc: (98.00%) (35522/35968)
Epoch: 228 | Batch_idx: 290 |  Loss: (0.0397) |  Loss2: (0.0000) | Acc: (98.00%) (36790/37248)
Epoch: 228 | Batch_idx: 300 |  Loss: (0.0397) |  Loss2: (0.0000) | Acc: (98.00%) (38057/38528)
Epoch: 228 | Batch_idx: 310 |  Loss: (0.0398) |  Loss2: (0.0000) | Acc: (98.00%) (39321/39808)
Epoch: 228 | Batch_idx: 320 |  Loss: (0.0398) |  Loss2: (0.0000) | Acc: (98.00%) (40588/41088)
Epoch: 228 | Batch_idx: 330 |  Loss: (0.0398) |  Loss2: (0.0000) | Acc: (98.00%) (41854/42368)
Epoch: 228 | Batch_idx: 340 |  Loss: (0.0398) |  Loss2: (0.0000) | Acc: (98.00%) (43122/43648)
Epoch: 228 | Batch_idx: 350 |  Loss: (0.0400) |  Loss2: (0.0000) | Acc: (98.00%) (44385/44928)
Epoch: 228 | Batch_idx: 360 |  Loss: (0.0401) |  Loss2: (0.0000) | Acc: (98.00%) (45648/46208)
Epoch: 228 | Batch_idx: 370 |  Loss: (0.0402) |  Loss2: (0.0000) | Acc: (98.00%) (46913/47488)
Epoch: 228 | Batch_idx: 380 |  Loss: (0.0401) |  Loss2: (0.0000) | Acc: (98.00%) (48179/48768)
Epoch: 228 | Batch_idx: 390 |  Loss: (0.0403) |  Loss2: (0.0000) | Acc: (98.00%) (49388/50000)
# TEST : Loss: (0.4159) | Acc: (89.00%) (8944/10000)
percent tensor([0.5279, 0.5293, 0.5302, 0.5315, 0.5322, 0.5345, 0.5316, 0.5334, 0.5288,
        0.5277, 0.5276, 0.5285, 0.5272, 0.5306, 0.5304, 0.5293],
       device='cuda:0') torch.Size([16])
percent tensor([0.5309, 0.5437, 0.5269, 0.5251, 0.5227, 0.5401, 0.5346, 0.5223, 0.5296,
        0.5376, 0.5359, 0.5319, 0.5414, 0.5334, 0.5363, 0.5398],
       device='cuda:0') torch.Size([16])
percent tensor([0.6153, 0.5678, 0.6744, 0.6964, 0.6850, 0.6608, 0.6274, 0.6695, 0.6653,
        0.6101, 0.6473, 0.6323, 0.5207, 0.6985, 0.6137, 0.6275],
       device='cuda:0') torch.Size([16])
percent tensor([0.6925, 0.6846, 0.6761, 0.6775, 0.6776, 0.6858, 0.6953, 0.6865, 0.6908,
        0.6929, 0.6908, 0.6858, 0.6891, 0.6871, 0.6914, 0.6993],
       device='cuda:0') torch.Size([16])
percent tensor([0.6774, 0.6246, 0.7015, 0.7127, 0.7051, 0.8149, 0.6370, 0.6506, 0.6611,
        0.6604, 0.5917, 0.6487, 0.6646, 0.6648, 0.6293, 0.7625],
       device='cuda:0') torch.Size([16])
percent tensor([0.6695, 0.7619, 0.7116, 0.7311, 0.7076, 0.7918, 0.7273, 0.5442, 0.7406,
        0.7214, 0.8033, 0.7324, 0.8106, 0.7570, 0.6022, 0.6737],
       device='cuda:0') torch.Size([16])
percent tensor([0.5668, 0.6879, 0.6792, 0.6781, 0.6987, 0.6675, 0.6608, 0.6371, 0.6225,
        0.7076, 0.6935, 0.6228, 0.6683, 0.5357, 0.5792, 0.5693],
       device='cuda:0') torch.Size([16])
percent tensor([0.9999, 0.9998, 0.9998, 1.0000, 0.9995, 0.9992, 0.9998, 0.9997, 0.9999,
        0.9999, 0.9999, 0.9997, 0.9999, 0.9994, 0.9995, 0.9997],
       device='cuda:0') torch.Size([16])
Epoch: 229 | Batch_idx: 0 |  Loss: (0.0671) |  Loss2: (0.0000) | Acc: (97.00%) (125/128)
Epoch: 229 | Batch_idx: 10 |  Loss: (0.0360) |  Loss2: (0.0000) | Acc: (99.00%) (1396/1408)
Epoch: 229 | Batch_idx: 20 |  Loss: (0.0357) |  Loss2: (0.0000) | Acc: (98.00%) (2660/2688)
Epoch: 229 | Batch_idx: 30 |  Loss: (0.0360) |  Loss2: (0.0000) | Acc: (98.00%) (3922/3968)
Epoch: 229 | Batch_idx: 40 |  Loss: (0.0360) |  Loss2: (0.0000) | Acc: (98.00%) (5185/5248)
Epoch: 229 | Batch_idx: 50 |  Loss: (0.0362) |  Loss2: (0.0000) | Acc: (98.00%) (6453/6528)
Epoch: 229 | Batch_idx: 60 |  Loss: (0.0365) |  Loss2: (0.0000) | Acc: (98.00%) (7718/7808)
Epoch: 229 | Batch_idx: 70 |  Loss: (0.0356) |  Loss2: (0.0000) | Acc: (98.00%) (8987/9088)
Epoch: 229 | Batch_idx: 80 |  Loss: (0.0364) |  Loss2: (0.0000) | Acc: (98.00%) (10250/10368)
Epoch: 229 | Batch_idx: 90 |  Loss: (0.0372) |  Loss2: (0.0000) | Acc: (98.00%) (11511/11648)
Epoch: 229 | Batch_idx: 100 |  Loss: (0.0377) |  Loss2: (0.0000) | Acc: (98.00%) (12772/12928)
Epoch: 229 | Batch_idx: 110 |  Loss: (0.0377) |  Loss2: (0.0000) | Acc: (98.00%) (14034/14208)
Epoch: 229 | Batch_idx: 120 |  Loss: (0.0382) |  Loss2: (0.0000) | Acc: (98.00%) (15299/15488)
Epoch: 229 | Batch_idx: 130 |  Loss: (0.0385) |  Loss2: (0.0000) | Acc: (98.00%) (16563/16768)
Epoch: 229 | Batch_idx: 140 |  Loss: (0.0385) |  Loss2: (0.0000) | Acc: (98.00%) (17833/18048)
Epoch: 229 | Batch_idx: 150 |  Loss: (0.0382) |  Loss2: (0.0000) | Acc: (98.00%) (19100/19328)
Epoch: 229 | Batch_idx: 160 |  Loss: (0.0384) |  Loss2: (0.0000) | Acc: (98.00%) (20361/20608)
Epoch: 229 | Batch_idx: 170 |  Loss: (0.0383) |  Loss2: (0.0000) | Acc: (98.00%) (21628/21888)
Epoch: 229 | Batch_idx: 180 |  Loss: (0.0383) |  Loss2: (0.0000) | Acc: (98.00%) (22893/23168)
Epoch: 229 | Batch_idx: 190 |  Loss: (0.0384) |  Loss2: (0.0000) | Acc: (98.00%) (24158/24448)
Epoch: 229 | Batch_idx: 200 |  Loss: (0.0387) |  Loss2: (0.0000) | Acc: (98.00%) (25416/25728)
Epoch: 229 | Batch_idx: 210 |  Loss: (0.0386) |  Loss2: (0.0000) | Acc: (98.00%) (26679/27008)
Epoch: 229 | Batch_idx: 220 |  Loss: (0.0390) |  Loss2: (0.0000) | Acc: (98.00%) (27935/28288)
Epoch: 229 | Batch_idx: 230 |  Loss: (0.0387) |  Loss2: (0.0000) | Acc: (98.00%) (29204/29568)
Epoch: 229 | Batch_idx: 240 |  Loss: (0.0386) |  Loss2: (0.0000) | Acc: (98.00%) (30472/30848)
Epoch: 229 | Batch_idx: 250 |  Loss: (0.0387) |  Loss2: (0.0000) | Acc: (98.00%) (31732/32128)
Epoch: 229 | Batch_idx: 260 |  Loss: (0.0385) |  Loss2: (0.0000) | Acc: (98.00%) (32996/33408)
Epoch: 229 | Batch_idx: 270 |  Loss: (0.0384) |  Loss2: (0.0000) | Acc: (98.00%) (34261/34688)
Epoch: 229 | Batch_idx: 280 |  Loss: (0.0386) |  Loss2: (0.0000) | Acc: (98.00%) (35527/35968)
Epoch: 229 | Batch_idx: 290 |  Loss: (0.0388) |  Loss2: (0.0000) | Acc: (98.00%) (36790/37248)
Epoch: 229 | Batch_idx: 300 |  Loss: (0.0388) |  Loss2: (0.0000) | Acc: (98.00%) (38053/38528)
Epoch: 229 | Batch_idx: 310 |  Loss: (0.0390) |  Loss2: (0.0000) | Acc: (98.00%) (39313/39808)
Epoch: 229 | Batch_idx: 320 |  Loss: (0.0392) |  Loss2: (0.0000) | Acc: (98.00%) (40573/41088)
Epoch: 229 | Batch_idx: 330 |  Loss: (0.0393) |  Loss2: (0.0000) | Acc: (98.00%) (41836/42368)
Epoch: 229 | Batch_idx: 340 |  Loss: (0.0393) |  Loss2: (0.0000) | Acc: (98.00%) (43100/43648)
Epoch: 229 | Batch_idx: 350 |  Loss: (0.0395) |  Loss2: (0.0000) | Acc: (98.00%) (44362/44928)
Epoch: 229 | Batch_idx: 360 |  Loss: (0.0395) |  Loss2: (0.0000) | Acc: (98.00%) (45625/46208)
Epoch: 229 | Batch_idx: 370 |  Loss: (0.0396) |  Loss2: (0.0000) | Acc: (98.00%) (46887/47488)
Epoch: 229 | Batch_idx: 380 |  Loss: (0.0398) |  Loss2: (0.0000) | Acc: (98.00%) (48146/48768)
Epoch: 229 | Batch_idx: 390 |  Loss: (0.0402) |  Loss2: (0.0000) | Acc: (98.00%) (49359/50000)
# TEST : Loss: (0.4236) | Acc: (89.00%) (8947/10000)
percent tensor([0.5283, 0.5298, 0.5304, 0.5321, 0.5328, 0.5355, 0.5319, 0.5336, 0.5288,
        0.5283, 0.5278, 0.5287, 0.5276, 0.5302, 0.5312, 0.5299],
       device='cuda:0') torch.Size([16])
percent tensor([0.5318, 0.5424, 0.5273, 0.5245, 0.5220, 0.5409, 0.5342, 0.5215, 0.5305,
        0.5368, 0.5360, 0.5322, 0.5415, 0.5314, 0.5366, 0.5387],
       device='cuda:0') torch.Size([16])
percent tensor([0.6241, 0.5779, 0.6788, 0.6994, 0.6895, 0.6639, 0.6360, 0.6778, 0.6708,
        0.6183, 0.6607, 0.6414, 0.5342, 0.7038, 0.6195, 0.6385],
       device='cuda:0') torch.Size([16])
percent tensor([0.6912, 0.6830, 0.6771, 0.6754, 0.6772, 0.6876, 0.6932, 0.6844, 0.6875,
        0.6923, 0.6872, 0.6859, 0.6865, 0.6821, 0.6910, 0.6976],
       device='cuda:0') torch.Size([16])
percent tensor([0.6874, 0.6310, 0.7066, 0.7196, 0.7152, 0.8004, 0.6492, 0.6672, 0.6967,
        0.6806, 0.6305, 0.6545, 0.6684, 0.6896, 0.6297, 0.7656],
       device='cuda:0') torch.Size([16])
percent tensor([0.6657, 0.7793, 0.7216, 0.7291, 0.7268, 0.8036, 0.7521, 0.5465, 0.7612,
        0.7275, 0.8108, 0.7291, 0.8189, 0.7809, 0.6266, 0.6689],
       device='cuda:0') torch.Size([16])
percent tensor([0.5498, 0.6695, 0.6898, 0.6692, 0.7018, 0.6673, 0.6726, 0.6285, 0.6180,
        0.6968, 0.7006, 0.6253, 0.6587, 0.5429, 0.5759, 0.5377],
       device='cuda:0') torch.Size([16])
percent tensor([0.9999, 0.9999, 0.9998, 0.9999, 0.9996, 0.9992, 0.9998, 0.9996, 0.9999,
        0.9999, 0.9999, 0.9999, 1.0000, 0.9995, 0.9995, 0.9997],
       device='cuda:0') torch.Size([16])
Epoch: 230 | Batch_idx: 0 |  Loss: (0.0194) |  Loss2: (0.0000) | Acc: (100.00%) (128/128)
Epoch: 230 | Batch_idx: 10 |  Loss: (0.0354) |  Loss2: (0.0000) | Acc: (98.00%) (1391/1408)
Epoch: 230 | Batch_idx: 20 |  Loss: (0.0448) |  Loss2: (0.0000) | Acc: (98.00%) (2648/2688)
Epoch: 230 | Batch_idx: 30 |  Loss: (0.0476) |  Loss2: (0.0000) | Acc: (98.00%) (3906/3968)
Epoch: 230 | Batch_idx: 40 |  Loss: (0.0474) |  Loss2: (0.0000) | Acc: (98.00%) (5165/5248)
Epoch: 230 | Batch_idx: 50 |  Loss: (0.0471) |  Loss2: (0.0000) | Acc: (98.00%) (6430/6528)
Epoch: 230 | Batch_idx: 60 |  Loss: (0.0484) |  Loss2: (0.0000) | Acc: (98.00%) (7689/7808)
Epoch: 230 | Batch_idx: 70 |  Loss: (0.0488) |  Loss2: (0.0000) | Acc: (98.00%) (8945/9088)
Epoch: 230 | Batch_idx: 80 |  Loss: (0.0488) |  Loss2: (0.0000) | Acc: (98.00%) (10206/10368)
Epoch: 230 | Batch_idx: 90 |  Loss: (0.0480) |  Loss2: (0.0000) | Acc: (98.00%) (11471/11648)
Epoch: 230 | Batch_idx: 100 |  Loss: (0.0478) |  Loss2: (0.0000) | Acc: (98.00%) (12733/12928)
Epoch: 230 | Batch_idx: 110 |  Loss: (0.0471) |  Loss2: (0.0000) | Acc: (98.00%) (13998/14208)
Epoch: 230 | Batch_idx: 120 |  Loss: (0.0468) |  Loss2: (0.0000) | Acc: (98.00%) (15264/15488)
Epoch: 230 | Batch_idx: 130 |  Loss: (0.0466) |  Loss2: (0.0000) | Acc: (98.00%) (16523/16768)
Epoch: 230 | Batch_idx: 140 |  Loss: (0.0461) |  Loss2: (0.0000) | Acc: (98.00%) (17791/18048)
Epoch: 230 | Batch_idx: 150 |  Loss: (0.0456) |  Loss2: (0.0000) | Acc: (98.00%) (19055/19328)
Epoch: 230 | Batch_idx: 160 |  Loss: (0.0455) |  Loss2: (0.0000) | Acc: (98.00%) (20317/20608)
Epoch: 230 | Batch_idx: 170 |  Loss: (0.0449) |  Loss2: (0.0000) | Acc: (98.00%) (21582/21888)
Epoch: 230 | Batch_idx: 180 |  Loss: (0.0444) |  Loss2: (0.0000) | Acc: (98.00%) (22847/23168)
Epoch: 230 | Batch_idx: 190 |  Loss: (0.0441) |  Loss2: (0.0000) | Acc: (98.00%) (24114/24448)
Epoch: 230 | Batch_idx: 200 |  Loss: (0.0435) |  Loss2: (0.0000) | Acc: (98.00%) (25383/25728)
Epoch: 230 | Batch_idx: 210 |  Loss: (0.0431) |  Loss2: (0.0000) | Acc: (98.00%) (26649/27008)
Epoch: 230 | Batch_idx: 220 |  Loss: (0.0427) |  Loss2: (0.0000) | Acc: (98.00%) (27917/28288)
Epoch: 230 | Batch_idx: 230 |  Loss: (0.0426) |  Loss2: (0.0000) | Acc: (98.00%) (29181/29568)
Epoch: 230 | Batch_idx: 240 |  Loss: (0.0425) |  Loss2: (0.0000) | Acc: (98.00%) (30443/30848)
Epoch: 230 | Batch_idx: 250 |  Loss: (0.0423) |  Loss2: (0.0000) | Acc: (98.00%) (31712/32128)
Epoch: 230 | Batch_idx: 260 |  Loss: (0.0421) |  Loss2: (0.0000) | Acc: (98.00%) (32978/33408)
Epoch: 230 | Batch_idx: 270 |  Loss: (0.0418) |  Loss2: (0.0000) | Acc: (98.00%) (34250/34688)
Epoch: 230 | Batch_idx: 280 |  Loss: (0.0417) |  Loss2: (0.0000) | Acc: (98.00%) (35516/35968)
Epoch: 230 | Batch_idx: 290 |  Loss: (0.0413) |  Loss2: (0.0000) | Acc: (98.00%) (36787/37248)
Epoch: 230 | Batch_idx: 300 |  Loss: (0.0412) |  Loss2: (0.0000) | Acc: (98.00%) (38052/38528)
Epoch: 230 | Batch_idx: 310 |  Loss: (0.0414) |  Loss2: (0.0000) | Acc: (98.00%) (39309/39808)
Epoch: 230 | Batch_idx: 320 |  Loss: (0.0415) |  Loss2: (0.0000) | Acc: (98.00%) (40566/41088)
Epoch: 230 | Batch_idx: 330 |  Loss: (0.0414) |  Loss2: (0.0000) | Acc: (98.00%) (41832/42368)
Epoch: 230 | Batch_idx: 340 |  Loss: (0.0414) |  Loss2: (0.0000) | Acc: (98.00%) (43096/43648)
Epoch: 230 | Batch_idx: 350 |  Loss: (0.0414) |  Loss2: (0.0000) | Acc: (98.00%) (44361/44928)
Epoch: 230 | Batch_idx: 360 |  Loss: (0.0415) |  Loss2: (0.0000) | Acc: (98.00%) (45622/46208)
Epoch: 230 | Batch_idx: 370 |  Loss: (0.0415) |  Loss2: (0.0000) | Acc: (98.00%) (46881/47488)
Epoch: 230 | Batch_idx: 380 |  Loss: (0.0413) |  Loss2: (0.0000) | Acc: (98.00%) (48146/48768)
Epoch: 230 | Batch_idx: 390 |  Loss: (0.0412) |  Loss2: (0.0000) | Acc: (98.00%) (49367/50000)
=> saving checkpoint 'drive/app/torch/save_Schedule/checkpoint_230.pth.tar'
# TEST : Loss: (0.4197) | Acc: (89.00%) (8944/10000)
percent tensor([0.5269, 0.5284, 0.5282, 0.5304, 0.5306, 0.5334, 0.5303, 0.5320, 0.5281,
        0.5267, 0.5266, 0.5267, 0.5263, 0.5303, 0.5292, 0.5284],
       device='cuda:0') torch.Size([16])
percent tensor([0.5322, 0.5431, 0.5275, 0.5254, 0.5229, 0.5415, 0.5342, 0.5224, 0.5311,
        0.5374, 0.5374, 0.5332, 0.5420, 0.5312, 0.5378, 0.5398],
       device='cuda:0') torch.Size([16])
percent tensor([0.6233, 0.5670, 0.6775, 0.7033, 0.6886, 0.6630, 0.6285, 0.6700, 0.6662,
        0.6123, 0.6462, 0.6399, 0.5306, 0.6934, 0.6161, 0.6334],
       device='cuda:0') torch.Size([16])
percent tensor([0.6912, 0.6832, 0.6751, 0.6740, 0.6772, 0.6882, 0.6931, 0.6828, 0.6871,
        0.6921, 0.6895, 0.6845, 0.6867, 0.6822, 0.6920, 0.6991],
       device='cuda:0') torch.Size([16])
percent tensor([0.6727, 0.6308, 0.6878, 0.7070, 0.6975, 0.8028, 0.6342, 0.6409, 0.6731,
        0.6824, 0.6142, 0.6512, 0.6543, 0.6746, 0.6273, 0.7580],
       device='cuda:0') torch.Size([16])
percent tensor([0.6705, 0.7691, 0.7170, 0.7291, 0.6994, 0.7870, 0.7389, 0.5563, 0.7476,
        0.7290, 0.8042, 0.7195, 0.8009, 0.7796, 0.6107, 0.6532],
       device='cuda:0') torch.Size([16])
percent tensor([0.5511, 0.6739, 0.6885, 0.6633, 0.6917, 0.6620, 0.6803, 0.6399, 0.6171,
        0.6926, 0.6844, 0.6109, 0.6539, 0.5584, 0.5566, 0.5383],
       device='cuda:0') torch.Size([16])
percent tensor([0.9999, 0.9998, 0.9999, 0.9999, 0.9995, 0.9992, 0.9998, 0.9998, 0.9999,
        0.9999, 0.9999, 0.9999, 0.9999, 0.9996, 0.9996, 0.9996],
       device='cuda:0') torch.Size([16])
Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 3, 3, 3]) tensor(183.5159, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(840.8844, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(844.7751, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([128, 64, 3, 3]) tensor(1514.2656, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([128, 64, 1, 1]) tensor(473.1788, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([128, 128, 3, 3]) tensor(2327.9614, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([256, 128, 3, 3]) tensor(4264.9448, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([256, 128, 1, 1]) tensor(1330.9652, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([256, 256, 3, 3]) tensor(6374.6699, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([512, 256, 3, 3]) tensor(11441.1689, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([512, 256, 1, 1]) tensor(3740.6904, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([512, 512, 3, 3]) tensor(15802.1758, device='cuda:0', grad_fn=<NormBackward0>)
Epoch: 231 | Batch_idx: 0 |  Loss: (0.0214) |  Loss2: (0.0000) | Acc: (99.00%) (127/128)
Epoch: 231 | Batch_idx: 10 |  Loss: (0.0407) |  Loss2: (0.0000) | Acc: (98.00%) (1392/1408)
Epoch: 231 | Batch_idx: 20 |  Loss: (0.0397) |  Loss2: (0.0000) | Acc: (99.00%) (2662/2688)
Epoch: 231 | Batch_idx: 30 |  Loss: (0.0406) |  Loss2: (0.0000) | Acc: (98.00%) (3927/3968)
Epoch: 231 | Batch_idx: 40 |  Loss: (0.0393) |  Loss2: (0.0000) | Acc: (98.00%) (5193/5248)
Epoch: 231 | Batch_idx: 50 |  Loss: (0.0397) |  Loss2: (0.0000) | Acc: (98.00%) (6455/6528)
Epoch: 231 | Batch_idx: 60 |  Loss: (0.0403) |  Loss2: (0.0000) | Acc: (98.00%) (7723/7808)
Epoch: 231 | Batch_idx: 70 |  Loss: (0.0394) |  Loss2: (0.0000) | Acc: (98.00%) (8990/9088)
Epoch: 231 | Batch_idx: 80 |  Loss: (0.0397) |  Loss2: (0.0000) | Acc: (98.00%) (10256/10368)
Epoch: 231 | Batch_idx: 90 |  Loss: (0.0397) |  Loss2: (0.0000) | Acc: (98.00%) (11520/11648)
Epoch: 231 | Batch_idx: 100 |  Loss: (0.0398) |  Loss2: (0.0000) | Acc: (98.00%) (12779/12928)
Epoch: 231 | Batch_idx: 110 |  Loss: (0.0396) |  Loss2: (0.0000) | Acc: (98.00%) (14047/14208)
Epoch: 231 | Batch_idx: 120 |  Loss: (0.0388) |  Loss2: (0.0000) | Acc: (98.00%) (15319/15488)
Epoch: 231 | Batch_idx: 130 |  Loss: (0.0388) |  Loss2: (0.0000) | Acc: (98.00%) (16580/16768)
Epoch: 231 | Batch_idx: 140 |  Loss: (0.0384) |  Loss2: (0.0000) | Acc: (98.00%) (17845/18048)
Epoch: 231 | Batch_idx: 150 |  Loss: (0.0382) |  Loss2: (0.0000) | Acc: (98.00%) (19108/19328)
Epoch: 231 | Batch_idx: 160 |  Loss: (0.0384) |  Loss2: (0.0000) | Acc: (98.00%) (20373/20608)
Epoch: 231 | Batch_idx: 170 |  Loss: (0.0381) |  Loss2: (0.0000) | Acc: (98.00%) (21644/21888)
Epoch: 231 | Batch_idx: 180 |  Loss: (0.0380) |  Loss2: (0.0000) | Acc: (98.00%) (22909/23168)
Epoch: 231 | Batch_idx: 190 |  Loss: (0.0378) |  Loss2: (0.0000) | Acc: (98.00%) (24175/24448)
Epoch: 231 | Batch_idx: 200 |  Loss: (0.0374) |  Loss2: (0.0000) | Acc: (98.00%) (25441/25728)
Epoch: 231 | Batch_idx: 210 |  Loss: (0.0371) |  Loss2: (0.0000) | Acc: (98.00%) (26713/27008)
Epoch: 231 | Batch_idx: 220 |  Loss: (0.0372) |  Loss2: (0.0000) | Acc: (98.00%) (27975/28288)
Epoch: 231 | Batch_idx: 230 |  Loss: (0.0375) |  Loss2: (0.0000) | Acc: (98.00%) (29235/29568)
Epoch: 231 | Batch_idx: 240 |  Loss: (0.0376) |  Loss2: (0.0000) | Acc: (98.00%) (30496/30848)
Epoch: 231 | Batch_idx: 250 |  Loss: (0.0381) |  Loss2: (0.0000) | Acc: (98.00%) (31754/32128)
Epoch: 231 | Batch_idx: 260 |  Loss: (0.0380) |  Loss2: (0.0000) | Acc: (98.00%) (33018/33408)
Epoch: 231 | Batch_idx: 270 |  Loss: (0.0381) |  Loss2: (0.0000) | Acc: (98.00%) (34283/34688)
Epoch: 231 | Batch_idx: 280 |  Loss: (0.0383) |  Loss2: (0.0000) | Acc: (98.00%) (35541/35968)
Epoch: 231 | Batch_idx: 290 |  Loss: (0.0382) |  Loss2: (0.0000) | Acc: (98.00%) (36806/37248)
Epoch: 231 | Batch_idx: 300 |  Loss: (0.0382) |  Loss2: (0.0000) | Acc: (98.00%) (38070/38528)
Epoch: 231 | Batch_idx: 310 |  Loss: (0.0382) |  Loss2: (0.0000) | Acc: (98.00%) (39335/39808)
Epoch: 231 | Batch_idx: 320 |  Loss: (0.0380) |  Loss2: (0.0000) | Acc: (98.00%) (40605/41088)
Epoch: 231 | Batch_idx: 330 |  Loss: (0.0380) |  Loss2: (0.0000) | Acc: (98.00%) (41868/42368)
Epoch: 231 | Batch_idx: 340 |  Loss: (0.0383) |  Loss2: (0.0000) | Acc: (98.00%) (43135/43648)
Epoch: 231 | Batch_idx: 350 |  Loss: (0.0381) |  Loss2: (0.0000) | Acc: (98.00%) (44400/44928)
Epoch: 231 | Batch_idx: 360 |  Loss: (0.0380) |  Loss2: (0.0000) | Acc: (98.00%) (45668/46208)
Epoch: 231 | Batch_idx: 370 |  Loss: (0.0378) |  Loss2: (0.0000) | Acc: (98.00%) (46935/47488)
Epoch: 231 | Batch_idx: 380 |  Loss: (0.0377) |  Loss2: (0.0000) | Acc: (98.00%) (48201/48768)
Epoch: 231 | Batch_idx: 390 |  Loss: (0.0379) |  Loss2: (0.0000) | Acc: (98.00%) (49417/50000)
# TEST : Loss: (0.4170) | Acc: (89.00%) (8940/10000)
percent tensor([0.5284, 0.5292, 0.5321, 0.5317, 0.5336, 0.5348, 0.5319, 0.5341, 0.5296,
        0.5285, 0.5277, 0.5302, 0.5279, 0.5298, 0.5304, 0.5292],
       device='cuda:0') torch.Size([16])
percent tensor([0.5291, 0.5430, 0.5226, 0.5222, 0.5189, 0.5385, 0.5330, 0.5186, 0.5270,
        0.5355, 0.5352, 0.5295, 0.5392, 0.5319, 0.5356, 0.5376],
       device='cuda:0') torch.Size([16])
percent tensor([0.6275, 0.5751, 0.6840, 0.7084, 0.6919, 0.6704, 0.6292, 0.6784, 0.6696,
        0.6197, 0.6562, 0.6496, 0.5361, 0.6956, 0.6239, 0.6395],
       device='cuda:0') torch.Size([16])
percent tensor([0.6926, 0.6846, 0.6782, 0.6766, 0.6795, 0.6876, 0.6957, 0.6884, 0.6871,
        0.6942, 0.6893, 0.6856, 0.6881, 0.6847, 0.6933, 0.6997],
       device='cuda:0') torch.Size([16])
percent tensor([0.6804, 0.6314, 0.6964, 0.7132, 0.7130, 0.7958, 0.6368, 0.6611, 0.6726,
        0.6738, 0.6077, 0.6537, 0.6561, 0.6712, 0.6286, 0.7580],
       device='cuda:0') torch.Size([16])
percent tensor([0.6850, 0.7696, 0.7226, 0.7412, 0.7157, 0.7948, 0.7417, 0.5552, 0.7512,
        0.7218, 0.8079, 0.7317, 0.8008, 0.7746, 0.6298, 0.6693],
       device='cuda:0') torch.Size([16])
percent tensor([0.5719, 0.6744, 0.6772, 0.6793, 0.6816, 0.6600, 0.6604, 0.6279, 0.6102,
        0.6878, 0.6893, 0.6284, 0.6732, 0.5499, 0.5703, 0.5431],
       device='cuda:0') torch.Size([16])
percent tensor([0.9999, 0.9999, 0.9998, 0.9999, 0.9995, 0.9994, 0.9998, 0.9996, 0.9999,
        0.9999, 0.9999, 0.9999, 0.9999, 0.9997, 0.9994, 0.9997],
       device='cuda:0') torch.Size([16])
Epoch: 232 | Batch_idx: 0 |  Loss: (0.0188) |  Loss2: (0.0000) | Acc: (99.00%) (127/128)
Epoch: 232 | Batch_idx: 10 |  Loss: (0.0382) |  Loss2: (0.0000) | Acc: (98.00%) (1392/1408)
Epoch: 232 | Batch_idx: 20 |  Loss: (0.0388) |  Loss2: (0.0000) | Acc: (98.00%) (2653/2688)
Epoch: 232 | Batch_idx: 30 |  Loss: (0.0382) |  Loss2: (0.0000) | Acc: (98.00%) (3920/3968)
Epoch: 232 | Batch_idx: 40 |  Loss: (0.0392) |  Loss2: (0.0000) | Acc: (98.00%) (5181/5248)
Epoch: 232 | Batch_idx: 50 |  Loss: (0.0409) |  Loss2: (0.0000) | Acc: (98.00%) (6440/6528)
Epoch: 232 | Batch_idx: 60 |  Loss: (0.0401) |  Loss2: (0.0000) | Acc: (98.00%) (7707/7808)
Epoch: 232 | Batch_idx: 70 |  Loss: (0.0392) |  Loss2: (0.0000) | Acc: (98.00%) (8973/9088)
Epoch: 232 | Batch_idx: 80 |  Loss: (0.0403) |  Loss2: (0.0000) | Acc: (98.00%) (10230/10368)
Epoch: 232 | Batch_idx: 90 |  Loss: (0.0399) |  Loss2: (0.0000) | Acc: (98.00%) (11498/11648)
Epoch: 232 | Batch_idx: 100 |  Loss: (0.0390) |  Loss2: (0.0000) | Acc: (98.00%) (12769/12928)
Epoch: 232 | Batch_idx: 110 |  Loss: (0.0385) |  Loss2: (0.0000) | Acc: (98.00%) (14032/14208)
Epoch: 232 | Batch_idx: 120 |  Loss: (0.0387) |  Loss2: (0.0000) | Acc: (98.00%) (15294/15488)
Epoch: 232 | Batch_idx: 130 |  Loss: (0.0389) |  Loss2: (0.0000) | Acc: (98.00%) (16556/16768)
Epoch: 232 | Batch_idx: 140 |  Loss: (0.0390) |  Loss2: (0.0000) | Acc: (98.00%) (17817/18048)
Epoch: 232 | Batch_idx: 150 |  Loss: (0.0393) |  Loss2: (0.0000) | Acc: (98.00%) (19080/19328)
Epoch: 232 | Batch_idx: 160 |  Loss: (0.0398) |  Loss2: (0.0000) | Acc: (98.00%) (20339/20608)
Epoch: 232 | Batch_idx: 170 |  Loss: (0.0397) |  Loss2: (0.0000) | Acc: (98.00%) (21604/21888)
Epoch: 232 | Batch_idx: 180 |  Loss: (0.0399) |  Loss2: (0.0000) | Acc: (98.00%) (22868/23168)
Epoch: 232 | Batch_idx: 190 |  Loss: (0.0395) |  Loss2: (0.0000) | Acc: (98.00%) (24138/24448)
Epoch: 232 | Batch_idx: 200 |  Loss: (0.0398) |  Loss2: (0.0000) | Acc: (98.00%) (25401/25728)
Epoch: 232 | Batch_idx: 210 |  Loss: (0.0399) |  Loss2: (0.0000) | Acc: (98.00%) (26660/27008)
Epoch: 232 | Batch_idx: 220 |  Loss: (0.0400) |  Loss2: (0.0000) | Acc: (98.00%) (27926/28288)
Epoch: 232 | Batch_idx: 230 |  Loss: (0.0402) |  Loss2: (0.0000) | Acc: (98.00%) (29190/29568)
Epoch: 232 | Batch_idx: 240 |  Loss: (0.0398) |  Loss2: (0.0000) | Acc: (98.00%) (30461/30848)
Epoch: 232 | Batch_idx: 250 |  Loss: (0.0402) |  Loss2: (0.0000) | Acc: (98.00%) (31714/32128)
Epoch: 232 | Batch_idx: 260 |  Loss: (0.0402) |  Loss2: (0.0000) | Acc: (98.00%) (32981/33408)
Epoch: 232 | Batch_idx: 270 |  Loss: (0.0401) |  Loss2: (0.0000) | Acc: (98.00%) (34246/34688)
Epoch: 232 | Batch_idx: 280 |  Loss: (0.0399) |  Loss2: (0.0000) | Acc: (98.00%) (35515/35968)
Epoch: 232 | Batch_idx: 290 |  Loss: (0.0398) |  Loss2: (0.0000) | Acc: (98.00%) (36781/37248)
Epoch: 232 | Batch_idx: 300 |  Loss: (0.0399) |  Loss2: (0.0000) | Acc: (98.00%) (38037/38528)
Epoch: 232 | Batch_idx: 310 |  Loss: (0.0400) |  Loss2: (0.0000) | Acc: (98.00%) (39296/39808)
Epoch: 232 | Batch_idx: 320 |  Loss: (0.0399) |  Loss2: (0.0000) | Acc: (98.00%) (40561/41088)
Epoch: 232 | Batch_idx: 330 |  Loss: (0.0401) |  Loss2: (0.0000) | Acc: (98.00%) (41818/42368)
Epoch: 232 | Batch_idx: 340 |  Loss: (0.0402) |  Loss2: (0.0000) | Acc: (98.00%) (43075/43648)
Epoch: 232 | Batch_idx: 350 |  Loss: (0.0402) |  Loss2: (0.0000) | Acc: (98.00%) (44337/44928)
Epoch: 232 | Batch_idx: 360 |  Loss: (0.0402) |  Loss2: (0.0000) | Acc: (98.00%) (45600/46208)
Epoch: 232 | Batch_idx: 370 |  Loss: (0.0400) |  Loss2: (0.0000) | Acc: (98.00%) (46865/47488)
Epoch: 232 | Batch_idx: 380 |  Loss: (0.0400) |  Loss2: (0.0000) | Acc: (98.00%) (48128/48768)
Epoch: 232 | Batch_idx: 390 |  Loss: (0.0401) |  Loss2: (0.0000) | Acc: (98.00%) (49339/50000)
# TEST : Loss: (0.4143) | Acc: (89.00%) (8946/10000)
percent tensor([0.5294, 0.5318, 0.5322, 0.5332, 0.5341, 0.5362, 0.5338, 0.5358, 0.5309,
        0.5300, 0.5292, 0.5305, 0.5289, 0.5331, 0.5322, 0.5311],
       device='cuda:0') torch.Size([16])
percent tensor([0.5311, 0.5430, 0.5280, 0.5261, 0.5227, 0.5400, 0.5341, 0.5227, 0.5297,
        0.5368, 0.5366, 0.5335, 0.5409, 0.5307, 0.5372, 0.5390],
       device='cuda:0') torch.Size([16])
percent tensor([0.6155, 0.5682, 0.6762, 0.6988, 0.6863, 0.6557, 0.6251, 0.6707, 0.6636,
        0.6133, 0.6424, 0.6393, 0.5287, 0.6878, 0.6129, 0.6272],
       device='cuda:0') torch.Size([16])
percent tensor([0.6943, 0.6866, 0.6804, 0.6762, 0.6798, 0.6809, 0.6972, 0.6896, 0.6882,
        0.6964, 0.6919, 0.6904, 0.6907, 0.6843, 0.6929, 0.6994],
       device='cuda:0') torch.Size([16])
percent tensor([0.6762, 0.6343, 0.6966, 0.7095, 0.7076, 0.7986, 0.6333, 0.6479, 0.6889,
        0.6804, 0.6294, 0.6636, 0.6665, 0.6798, 0.6254, 0.7557],
       device='cuda:0') torch.Size([16])
percent tensor([0.6627, 0.7535, 0.7109, 0.7257, 0.7107, 0.7944, 0.7320, 0.5429, 0.7504,
        0.7136, 0.7959, 0.7029, 0.8061, 0.7836, 0.6051, 0.6559],
       device='cuda:0') torch.Size([16])
percent tensor([0.5561, 0.6693, 0.6692, 0.6731, 0.6803, 0.6161, 0.6699, 0.6380, 0.6229,
        0.6995, 0.6894, 0.6057, 0.6556, 0.5580, 0.5500, 0.5468],
       device='cuda:0') torch.Size([16])
percent tensor([0.9999, 0.9998, 0.9998, 0.9999, 0.9996, 0.9991, 0.9998, 0.9997, 0.9999,
        0.9999, 0.9999, 0.9999, 0.9999, 0.9996, 0.9995, 0.9996],
       device='cuda:0') torch.Size([16])
Epoch: 233 | Batch_idx: 0 |  Loss: (0.0717) |  Loss2: (0.0000) | Acc: (97.00%) (125/128)
Epoch: 233 | Batch_idx: 10 |  Loss: (0.0376) |  Loss2: (0.0000) | Acc: (98.00%) (1393/1408)
Epoch: 233 | Batch_idx: 20 |  Loss: (0.0368) |  Loss2: (0.0000) | Acc: (98.00%) (2658/2688)
Epoch: 233 | Batch_idx: 30 |  Loss: (0.0403) |  Loss2: (0.0000) | Acc: (98.00%) (3918/3968)
Epoch: 233 | Batch_idx: 40 |  Loss: (0.0383) |  Loss2: (0.0000) | Acc: (98.00%) (5189/5248)
Epoch: 233 | Batch_idx: 50 |  Loss: (0.0389) |  Loss2: (0.0000) | Acc: (98.00%) (6450/6528)
Epoch: 233 | Batch_idx: 60 |  Loss: (0.0387) |  Loss2: (0.0000) | Acc: (98.00%) (7713/7808)
Epoch: 233 | Batch_idx: 70 |  Loss: (0.0381) |  Loss2: (0.0000) | Acc: (98.00%) (8981/9088)
Epoch: 233 | Batch_idx: 80 |  Loss: (0.0389) |  Loss2: (0.0000) | Acc: (98.00%) (10242/10368)
Epoch: 233 | Batch_idx: 90 |  Loss: (0.0397) |  Loss2: (0.0000) | Acc: (98.00%) (11506/11648)
Epoch: 233 | Batch_idx: 100 |  Loss: (0.0390) |  Loss2: (0.0000) | Acc: (98.00%) (12776/12928)
Epoch: 233 | Batch_idx: 110 |  Loss: (0.0386) |  Loss2: (0.0000) | Acc: (98.00%) (14045/14208)
Epoch: 233 | Batch_idx: 120 |  Loss: (0.0380) |  Loss2: (0.0000) | Acc: (98.00%) (15313/15488)
Epoch: 233 | Batch_idx: 130 |  Loss: (0.0384) |  Loss2: (0.0000) | Acc: (98.00%) (16573/16768)
Epoch: 233 | Batch_idx: 140 |  Loss: (0.0386) |  Loss2: (0.0000) | Acc: (98.00%) (17836/18048)
Epoch: 233 | Batch_idx: 150 |  Loss: (0.0390) |  Loss2: (0.0000) | Acc: (98.00%) (19099/19328)
Epoch: 233 | Batch_idx: 160 |  Loss: (0.0390) |  Loss2: (0.0000) | Acc: (98.00%) (20363/20608)
Epoch: 233 | Batch_idx: 170 |  Loss: (0.0390) |  Loss2: (0.0000) | Acc: (98.00%) (21631/21888)
Epoch: 233 | Batch_idx: 180 |  Loss: (0.0391) |  Loss2: (0.0000) | Acc: (98.00%) (22892/23168)
Epoch: 233 | Batch_idx: 190 |  Loss: (0.0393) |  Loss2: (0.0000) | Acc: (98.00%) (24150/24448)
Epoch: 233 | Batch_idx: 200 |  Loss: (0.0395) |  Loss2: (0.0000) | Acc: (98.00%) (25412/25728)
Epoch: 233 | Batch_idx: 210 |  Loss: (0.0397) |  Loss2: (0.0000) | Acc: (98.00%) (26675/27008)
Epoch: 233 | Batch_idx: 220 |  Loss: (0.0398) |  Loss2: (0.0000) | Acc: (98.00%) (27938/28288)
Epoch: 233 | Batch_idx: 230 |  Loss: (0.0401) |  Loss2: (0.0000) | Acc: (98.00%) (29197/29568)
Epoch: 233 | Batch_idx: 240 |  Loss: (0.0401) |  Loss2: (0.0000) | Acc: (98.00%) (30461/30848)
Epoch: 233 | Batch_idx: 250 |  Loss: (0.0399) |  Loss2: (0.0000) | Acc: (98.00%) (31726/32128)
Epoch: 233 | Batch_idx: 260 |  Loss: (0.0397) |  Loss2: (0.0000) | Acc: (98.00%) (32991/33408)
Epoch: 233 | Batch_idx: 270 |  Loss: (0.0397) |  Loss2: (0.0000) | Acc: (98.00%) (34257/34688)
Epoch: 233 | Batch_idx: 280 |  Loss: (0.0398) |  Loss2: (0.0000) | Acc: (98.00%) (35521/35968)
Epoch: 233 | Batch_idx: 290 |  Loss: (0.0399) |  Loss2: (0.0000) | Acc: (98.00%) (36781/37248)
Epoch: 233 | Batch_idx: 300 |  Loss: (0.0397) |  Loss2: (0.0000) | Acc: (98.00%) (38049/38528)
Epoch: 233 | Batch_idx: 310 |  Loss: (0.0396) |  Loss2: (0.0000) | Acc: (98.00%) (39314/39808)
Epoch: 233 | Batch_idx: 320 |  Loss: (0.0402) |  Loss2: (0.0000) | Acc: (98.00%) (40568/41088)
Epoch: 233 | Batch_idx: 330 |  Loss: (0.0401) |  Loss2: (0.0000) | Acc: (98.00%) (41834/42368)
Epoch: 233 | Batch_idx: 340 |  Loss: (0.0401) |  Loss2: (0.0000) | Acc: (98.00%) (43097/43648)
Epoch: 233 | Batch_idx: 350 |  Loss: (0.0400) |  Loss2: (0.0000) | Acc: (98.00%) (44366/44928)
Epoch: 233 | Batch_idx: 360 |  Loss: (0.0397) |  Loss2: (0.0000) | Acc: (98.00%) (45634/46208)
Epoch: 233 | Batch_idx: 370 |  Loss: (0.0398) |  Loss2: (0.0000) | Acc: (98.00%) (46896/47488)
Epoch: 233 | Batch_idx: 380 |  Loss: (0.0399) |  Loss2: (0.0000) | Acc: (98.00%) (48161/48768)
Epoch: 233 | Batch_idx: 390 |  Loss: (0.0400) |  Loss2: (0.0000) | Acc: (98.00%) (49371/50000)
# TEST : Loss: (0.4208) | Acc: (89.00%) (8955/10000)
percent tensor([0.5295, 0.5314, 0.5314, 0.5329, 0.5337, 0.5356, 0.5333, 0.5354, 0.5310,
        0.5297, 0.5292, 0.5300, 0.5291, 0.5326, 0.5319, 0.5309],
       device='cuda:0') torch.Size([16])
percent tensor([0.5320, 0.5421, 0.5298, 0.5260, 0.5241, 0.5402, 0.5338, 0.5219, 0.5299,
        0.5370, 0.5363, 0.5344, 0.5411, 0.5288, 0.5371, 0.5389],
       device='cuda:0') torch.Size([16])
percent tensor([0.6198, 0.5695, 0.6791, 0.6991, 0.6885, 0.6590, 0.6318, 0.6744, 0.6666,
        0.6137, 0.6436, 0.6407, 0.5297, 0.6952, 0.6145, 0.6273],
       device='cuda:0') torch.Size([16])
percent tensor([0.6915, 0.6846, 0.6771, 0.6740, 0.6799, 0.6838, 0.6958, 0.6855, 0.6872,
        0.6940, 0.6886, 0.6879, 0.6876, 0.6829, 0.6910, 0.6988],
       device='cuda:0') torch.Size([16])
percent tensor([0.6882, 0.6298, 0.7002, 0.7158, 0.7208, 0.8104, 0.6513, 0.6463, 0.6833,
        0.6857, 0.6261, 0.6621, 0.6678, 0.6776, 0.6385, 0.7586],
       device='cuda:0') torch.Size([16])
percent tensor([0.6640, 0.7574, 0.7254, 0.7397, 0.7146, 0.7976, 0.7295, 0.5364, 0.7512,
        0.7308, 0.8045, 0.7334, 0.8028, 0.7772, 0.6138, 0.6531],
       device='cuda:0') torch.Size([16])
percent tensor([0.5757, 0.6931, 0.6773, 0.6883, 0.7041, 0.6400, 0.6932, 0.6461, 0.6321,
        0.7322, 0.7052, 0.6417, 0.6779, 0.5691, 0.5798, 0.5437],
       device='cuda:0') torch.Size([16])
percent tensor([0.9999, 0.9998, 0.9997, 0.9999, 0.9994, 0.9994, 0.9998, 0.9996, 0.9999,
        0.9999, 0.9999, 0.9998, 0.9999, 0.9996, 0.9995, 0.9996],
       device='cuda:0') torch.Size([16])
Epoch: 234 | Batch_idx: 0 |  Loss: (0.0208) |  Loss2: (0.0000) | Acc: (100.00%) (128/128)
Epoch: 234 | Batch_idx: 10 |  Loss: (0.0392) |  Loss2: (0.0000) | Acc: (98.00%) (1393/1408)
Epoch: 234 | Batch_idx: 20 |  Loss: (0.0341) |  Loss2: (0.0000) | Acc: (99.00%) (2662/2688)
Epoch: 234 | Batch_idx: 30 |  Loss: (0.0375) |  Loss2: (0.0000) | Acc: (98.00%) (3924/3968)
Epoch: 234 | Batch_idx: 40 |  Loss: (0.0367) |  Loss2: (0.0000) | Acc: (98.00%) (5189/5248)
Epoch: 234 | Batch_idx: 50 |  Loss: (0.0386) |  Loss2: (0.0000) | Acc: (98.00%) (6449/6528)
Epoch: 234 | Batch_idx: 60 |  Loss: (0.0389) |  Loss2: (0.0000) | Acc: (98.00%) (7716/7808)
Epoch: 234 | Batch_idx: 70 |  Loss: (0.0382) |  Loss2: (0.0000) | Acc: (98.00%) (8978/9088)
Epoch: 234 | Batch_idx: 80 |  Loss: (0.0387) |  Loss2: (0.0000) | Acc: (98.00%) (10241/10368)
Epoch: 234 | Batch_idx: 90 |  Loss: (0.0388) |  Loss2: (0.0000) | Acc: (98.00%) (11505/11648)
Epoch: 234 | Batch_idx: 100 |  Loss: (0.0398) |  Loss2: (0.0000) | Acc: (98.00%) (12765/12928)
Epoch: 234 | Batch_idx: 110 |  Loss: (0.0410) |  Loss2: (0.0000) | Acc: (98.00%) (14024/14208)
Epoch: 234 | Batch_idx: 120 |  Loss: (0.0406) |  Loss2: (0.0000) | Acc: (98.00%) (15291/15488)
Epoch: 234 | Batch_idx: 130 |  Loss: (0.0409) |  Loss2: (0.0000) | Acc: (98.00%) (16549/16768)
Epoch: 234 | Batch_idx: 140 |  Loss: (0.0409) |  Loss2: (0.0000) | Acc: (98.00%) (17815/18048)
Epoch: 234 | Batch_idx: 150 |  Loss: (0.0407) |  Loss2: (0.0000) | Acc: (98.00%) (19081/19328)
Epoch: 234 | Batch_idx: 160 |  Loss: (0.0410) |  Loss2: (0.0000) | Acc: (98.00%) (20337/20608)
Epoch: 234 | Batch_idx: 170 |  Loss: (0.0406) |  Loss2: (0.0000) | Acc: (98.00%) (21601/21888)
Epoch: 234 | Batch_idx: 180 |  Loss: (0.0408) |  Loss2: (0.0000) | Acc: (98.00%) (22859/23168)
Epoch: 234 | Batch_idx: 190 |  Loss: (0.0404) |  Loss2: (0.0000) | Acc: (98.00%) (24126/24448)
Epoch: 234 | Batch_idx: 200 |  Loss: (0.0402) |  Loss2: (0.0000) | Acc: (98.00%) (25392/25728)
Epoch: 234 | Batch_idx: 210 |  Loss: (0.0405) |  Loss2: (0.0000) | Acc: (98.00%) (26652/27008)
Epoch: 234 | Batch_idx: 220 |  Loss: (0.0411) |  Loss2: (0.0000) | Acc: (98.00%) (27912/28288)
Epoch: 234 | Batch_idx: 230 |  Loss: (0.0409) |  Loss2: (0.0000) | Acc: (98.00%) (29178/29568)
Epoch: 234 | Batch_idx: 240 |  Loss: (0.0408) |  Loss2: (0.0000) | Acc: (98.00%) (30439/30848)
Epoch: 234 | Batch_idx: 250 |  Loss: (0.0408) |  Loss2: (0.0000) | Acc: (98.00%) (31705/32128)
Epoch: 234 | Batch_idx: 260 |  Loss: (0.0406) |  Loss2: (0.0000) | Acc: (98.00%) (32966/33408)
Epoch: 234 | Batch_idx: 270 |  Loss: (0.0407) |  Loss2: (0.0000) | Acc: (98.00%) (34225/34688)
Epoch: 234 | Batch_idx: 280 |  Loss: (0.0405) |  Loss2: (0.0000) | Acc: (98.00%) (35492/35968)
Epoch: 234 | Batch_idx: 290 |  Loss: (0.0409) |  Loss2: (0.0000) | Acc: (98.00%) (36748/37248)
Epoch: 234 | Batch_idx: 300 |  Loss: (0.0408) |  Loss2: (0.0000) | Acc: (98.00%) (38012/38528)
Epoch: 234 | Batch_idx: 310 |  Loss: (0.0407) |  Loss2: (0.0000) | Acc: (98.00%) (39276/39808)
Epoch: 234 | Batch_idx: 320 |  Loss: (0.0403) |  Loss2: (0.0000) | Acc: (98.00%) (40546/41088)
Epoch: 234 | Batch_idx: 330 |  Loss: (0.0398) |  Loss2: (0.0000) | Acc: (98.00%) (41820/42368)
Epoch: 234 | Batch_idx: 340 |  Loss: (0.0397) |  Loss2: (0.0000) | Acc: (98.00%) (43090/43648)
Epoch: 234 | Batch_idx: 350 |  Loss: (0.0394) |  Loss2: (0.0000) | Acc: (98.00%) (44359/44928)
Epoch: 234 | Batch_idx: 360 |  Loss: (0.0392) |  Loss2: (0.0000) | Acc: (98.00%) (45627/46208)
Epoch: 234 | Batch_idx: 370 |  Loss: (0.0391) |  Loss2: (0.0000) | Acc: (98.00%) (46892/47488)
Epoch: 234 | Batch_idx: 380 |  Loss: (0.0391) |  Loss2: (0.0000) | Acc: (98.00%) (48152/48768)
Epoch: 234 | Batch_idx: 390 |  Loss: (0.0391) |  Loss2: (0.0000) | Acc: (98.00%) (49371/50000)
# TEST : Loss: (0.4132) | Acc: (89.00%) (8968/10000)
percent tensor([0.5301, 0.5309, 0.5334, 0.5340, 0.5349, 0.5361, 0.5334, 0.5363, 0.5309,
        0.5300, 0.5290, 0.5313, 0.5295, 0.5313, 0.5320, 0.5310],
       device='cuda:0') torch.Size([16])
percent tensor([0.5335, 0.5461, 0.5308, 0.5284, 0.5257, 0.5404, 0.5371, 0.5249, 0.5315,
        0.5409, 0.5380, 0.5369, 0.5434, 0.5340, 0.5396, 0.5416],
       device='cuda:0') torch.Size([16])
percent tensor([0.6181, 0.5716, 0.6679, 0.6960, 0.6820, 0.6605, 0.6247, 0.6686, 0.6647,
        0.6125, 0.6465, 0.6304, 0.5289, 0.6915, 0.6162, 0.6333],
       device='cuda:0') torch.Size([16])
percent tensor([0.6932, 0.6849, 0.6788, 0.6777, 0.6776, 0.6884, 0.6955, 0.6881, 0.6893,
        0.6961, 0.6899, 0.6887, 0.6897, 0.6845, 0.6950, 0.7013],
       device='cuda:0') torch.Size([16])
percent tensor([0.6933, 0.6504, 0.7150, 0.7219, 0.7231, 0.8110, 0.6535, 0.6552, 0.6921,
        0.7005, 0.6281, 0.6777, 0.6703, 0.6915, 0.6463, 0.7670],
       device='cuda:0') torch.Size([16])
percent tensor([0.6714, 0.7700, 0.7363, 0.7497, 0.7252, 0.8036, 0.7420, 0.5631, 0.7756,
        0.7378, 0.8150, 0.7415, 0.8068, 0.7899, 0.6219, 0.6511],
       device='cuda:0') torch.Size([16])
percent tensor([0.5628, 0.6851, 0.6747, 0.6648, 0.7014, 0.6538, 0.6824, 0.6392, 0.6346,
        0.7277, 0.7064, 0.6309, 0.6871, 0.5737, 0.5822, 0.5503],
       device='cuda:0') torch.Size([16])
percent tensor([0.9999, 0.9998, 0.9999, 0.9999, 0.9995, 0.9992, 0.9998, 0.9997, 0.9999,
        0.9999, 0.9999, 0.9999, 0.9999, 0.9996, 0.9995, 0.9996],
       device='cuda:0') torch.Size([16])
Epoch: 235 | Batch_idx: 0 |  Loss: (0.0278) |  Loss2: (0.0000) | Acc: (99.00%) (127/128)
Epoch: 235 | Batch_idx: 10 |  Loss: (0.0338) |  Loss2: (0.0000) | Acc: (99.00%) (1396/1408)
Epoch: 235 | Batch_idx: 20 |  Loss: (0.0319) |  Loss2: (0.0000) | Acc: (99.00%) (2665/2688)
Epoch: 235 | Batch_idx: 30 |  Loss: (0.0342) |  Loss2: (0.0000) | Acc: (98.00%) (3928/3968)
Epoch: 235 | Batch_idx: 40 |  Loss: (0.0349) |  Loss2: (0.0000) | Acc: (98.00%) (5189/5248)
Epoch: 235 | Batch_idx: 50 |  Loss: (0.0351) |  Loss2: (0.0000) | Acc: (98.00%) (6457/6528)
Epoch: 235 | Batch_idx: 60 |  Loss: (0.0355) |  Loss2: (0.0000) | Acc: (98.00%) (7721/7808)
Epoch: 235 | Batch_idx: 70 |  Loss: (0.0353) |  Loss2: (0.0000) | Acc: (98.00%) (8985/9088)
Epoch: 235 | Batch_idx: 80 |  Loss: (0.0356) |  Loss2: (0.0000) | Acc: (98.00%) (10246/10368)
Epoch: 235 | Batch_idx: 90 |  Loss: (0.0350) |  Loss2: (0.0000) | Acc: (98.00%) (11517/11648)
Epoch: 235 | Batch_idx: 100 |  Loss: (0.0354) |  Loss2: (0.0000) | Acc: (98.00%) (12782/12928)
Epoch: 235 | Batch_idx: 110 |  Loss: (0.0354) |  Loss2: (0.0000) | Acc: (98.00%) (14047/14208)
Epoch: 235 | Batch_idx: 120 |  Loss: (0.0357) |  Loss2: (0.0000) | Acc: (98.00%) (15313/15488)
Epoch: 235 | Batch_idx: 130 |  Loss: (0.0363) |  Loss2: (0.0000) | Acc: (98.00%) (16574/16768)
Epoch: 235 | Batch_idx: 140 |  Loss: (0.0376) |  Loss2: (0.0000) | Acc: (98.00%) (17832/18048)
Epoch: 235 | Batch_idx: 150 |  Loss: (0.0379) |  Loss2: (0.0000) | Acc: (98.00%) (19095/19328)
Epoch: 235 | Batch_idx: 160 |  Loss: (0.0379) |  Loss2: (0.0000) | Acc: (98.00%) (20357/20608)
Epoch: 235 | Batch_idx: 170 |  Loss: (0.0377) |  Loss2: (0.0000) | Acc: (98.00%) (21625/21888)
Epoch: 235 | Batch_idx: 180 |  Loss: (0.0373) |  Loss2: (0.0000) | Acc: (98.00%) (22894/23168)
Epoch: 235 | Batch_idx: 190 |  Loss: (0.0373) |  Loss2: (0.0000) | Acc: (98.00%) (24162/24448)
Epoch: 235 | Batch_idx: 200 |  Loss: (0.0370) |  Loss2: (0.0000) | Acc: (98.00%) (25429/25728)
Epoch: 235 | Batch_idx: 210 |  Loss: (0.0370) |  Loss2: (0.0000) | Acc: (98.00%) (26692/27008)
Epoch: 235 | Batch_idx: 220 |  Loss: (0.0370) |  Loss2: (0.0000) | Acc: (98.00%) (27959/28288)
Epoch: 235 | Batch_idx: 230 |  Loss: (0.0372) |  Loss2: (0.0000) | Acc: (98.00%) (29223/29568)
Epoch: 235 | Batch_idx: 240 |  Loss: (0.0368) |  Loss2: (0.0000) | Acc: (98.00%) (30493/30848)
Epoch: 235 | Batch_idx: 250 |  Loss: (0.0367) |  Loss2: (0.0000) | Acc: (98.00%) (31758/32128)
Epoch: 235 | Batch_idx: 260 |  Loss: (0.0367) |  Loss2: (0.0000) | Acc: (98.00%) (33028/33408)
Epoch: 235 | Batch_idx: 270 |  Loss: (0.0366) |  Loss2: (0.0000) | Acc: (98.00%) (34295/34688)
Epoch: 235 | Batch_idx: 280 |  Loss: (0.0366) |  Loss2: (0.0000) | Acc: (98.00%) (35558/35968)
Epoch: 235 | Batch_idx: 290 |  Loss: (0.0366) |  Loss2: (0.0000) | Acc: (98.00%) (36824/37248)
Epoch: 235 | Batch_idx: 300 |  Loss: (0.0368) |  Loss2: (0.0000) | Acc: (98.00%) (38088/38528)
Epoch: 235 | Batch_idx: 310 |  Loss: (0.0369) |  Loss2: (0.0000) | Acc: (98.00%) (39355/39808)
Epoch: 235 | Batch_idx: 320 |  Loss: (0.0370) |  Loss2: (0.0000) | Acc: (98.00%) (40621/41088)
Epoch: 235 | Batch_idx: 330 |  Loss: (0.0374) |  Loss2: (0.0000) | Acc: (98.00%) (41879/42368)
Epoch: 235 | Batch_idx: 340 |  Loss: (0.0375) |  Loss2: (0.0000) | Acc: (98.00%) (43143/43648)
Epoch: 235 | Batch_idx: 350 |  Loss: (0.0378) |  Loss2: (0.0000) | Acc: (98.00%) (44398/44928)
Epoch: 235 | Batch_idx: 360 |  Loss: (0.0379) |  Loss2: (0.0000) | Acc: (98.00%) (45660/46208)
Epoch: 235 | Batch_idx: 370 |  Loss: (0.0378) |  Loss2: (0.0000) | Acc: (98.00%) (46926/47488)
Epoch: 235 | Batch_idx: 380 |  Loss: (0.0377) |  Loss2: (0.0000) | Acc: (98.00%) (48198/48768)
Epoch: 235 | Batch_idx: 390 |  Loss: (0.0379) |  Loss2: (0.0000) | Acc: (98.00%) (49415/50000)
=> saving checkpoint 'drive/app/torch/save_Schedule/checkpoint_235.pth.tar'
# TEST : Loss: (0.4178) | Acc: (89.00%) (8948/10000)
percent tensor([0.5297, 0.5315, 0.5326, 0.5338, 0.5345, 0.5363, 0.5337, 0.5363, 0.5311,
        0.5301, 0.5294, 0.5308, 0.5293, 0.5326, 0.5323, 0.5312],
       device='cuda:0') torch.Size([16])
percent tensor([0.5323, 0.5428, 0.5275, 0.5266, 0.5237, 0.5413, 0.5348, 0.5218, 0.5304,
        0.5374, 0.5369, 0.5343, 0.5415, 0.5329, 0.5380, 0.5410],
       device='cuda:0') torch.Size([16])
percent tensor([0.6085, 0.5562, 0.6743, 0.6977, 0.6856, 0.6459, 0.6151, 0.6671, 0.6596,
        0.6000, 0.6358, 0.6326, 0.5128, 0.6773, 0.6065, 0.6168],
       device='cuda:0') torch.Size([16])
percent tensor([0.6938, 0.6848, 0.6790, 0.6766, 0.6812, 0.6884, 0.6969, 0.6880, 0.6900,
        0.6956, 0.6902, 0.6895, 0.6895, 0.6831, 0.6935, 0.7009],
       device='cuda:0') torch.Size([16])
percent tensor([0.6918, 0.6333, 0.7213, 0.7288, 0.7269, 0.8216, 0.6373, 0.6535, 0.6706,
        0.6873, 0.6102, 0.6742, 0.6757, 0.6649, 0.6497, 0.7715],
       device='cuda:0') torch.Size([16])
percent tensor([0.6721, 0.7581, 0.7008, 0.7216, 0.7100, 0.8000, 0.7330, 0.5342, 0.7693,
        0.7198, 0.8043, 0.7219, 0.8177, 0.7790, 0.6119, 0.6732],
       device='cuda:0') torch.Size([16])
percent tensor([0.5527, 0.6735, 0.6405, 0.6679, 0.6797, 0.6378, 0.6853, 0.6307, 0.6217,
        0.6984, 0.7082, 0.6249, 0.6731, 0.5631, 0.5821, 0.5471],
       device='cuda:0') torch.Size([16])
percent tensor([0.9999, 0.9999, 0.9998, 1.0000, 0.9996, 0.9992, 0.9998, 0.9996, 0.9999,
        0.9999, 0.9999, 0.9999, 0.9999, 0.9997, 0.9995, 0.9997],
       device='cuda:0') torch.Size([16])
Epoch: 236 | Batch_idx: 0 |  Loss: (0.0312) |  Loss2: (0.0000) | Acc: (99.00%) (127/128)
Epoch: 236 | Batch_idx: 10 |  Loss: (0.0307) |  Loss2: (0.0000) | Acc: (98.00%) (1393/1408)
Epoch: 236 | Batch_idx: 20 |  Loss: (0.0340) |  Loss2: (0.0000) | Acc: (98.00%) (2658/2688)
Epoch: 236 | Batch_idx: 30 |  Loss: (0.0332) |  Loss2: (0.0000) | Acc: (98.00%) (3925/3968)
Epoch: 236 | Batch_idx: 40 |  Loss: (0.0329) |  Loss2: (0.0000) | Acc: (98.00%) (5191/5248)
Epoch: 236 | Batch_idx: 50 |  Loss: (0.0331) |  Loss2: (0.0000) | Acc: (98.00%) (6461/6528)
Epoch: 236 | Batch_idx: 60 |  Loss: (0.0353) |  Loss2: (0.0000) | Acc: (98.00%) (7723/7808)
Epoch: 236 | Batch_idx: 70 |  Loss: (0.0344) |  Loss2: (0.0000) | Acc: (98.00%) (8994/9088)
Epoch: 236 | Batch_idx: 80 |  Loss: (0.0346) |  Loss2: (0.0000) | Acc: (98.00%) (10257/10368)
Epoch: 236 | Batch_idx: 90 |  Loss: (0.0345) |  Loss2: (0.0000) | Acc: (98.00%) (11526/11648)
Epoch: 236 | Batch_idx: 100 |  Loss: (0.0342) |  Loss2: (0.0000) | Acc: (98.00%) (12792/12928)
Epoch: 236 | Batch_idx: 110 |  Loss: (0.0341) |  Loss2: (0.0000) | Acc: (98.00%) (14057/14208)
Epoch: 236 | Batch_idx: 120 |  Loss: (0.0332) |  Loss2: (0.0000) | Acc: (98.00%) (15332/15488)
Epoch: 236 | Batch_idx: 130 |  Loss: (0.0338) |  Loss2: (0.0000) | Acc: (98.00%) (16594/16768)
Epoch: 236 | Batch_idx: 140 |  Loss: (0.0331) |  Loss2: (0.0000) | Acc: (99.00%) (17868/18048)
Epoch: 236 | Batch_idx: 150 |  Loss: (0.0333) |  Loss2: (0.0000) | Acc: (98.00%) (19132/19328)
Epoch: 236 | Batch_idx: 160 |  Loss: (0.0329) |  Loss2: (0.0000) | Acc: (99.00%) (20405/20608)
Epoch: 236 | Batch_idx: 170 |  Loss: (0.0333) |  Loss2: (0.0000) | Acc: (99.00%) (21670/21888)
Epoch: 236 | Batch_idx: 180 |  Loss: (0.0334) |  Loss2: (0.0000) | Acc: (98.00%) (22934/23168)
Epoch: 236 | Batch_idx: 190 |  Loss: (0.0332) |  Loss2: (0.0000) | Acc: (99.00%) (24206/24448)
Epoch: 236 | Batch_idx: 200 |  Loss: (0.0332) |  Loss2: (0.0000) | Acc: (99.00%) (25475/25728)
Epoch: 236 | Batch_idx: 210 |  Loss: (0.0335) |  Loss2: (0.0000) | Acc: (99.00%) (26738/27008)
Epoch: 236 | Batch_idx: 220 |  Loss: (0.0333) |  Loss2: (0.0000) | Acc: (99.00%) (28007/28288)
Epoch: 236 | Batch_idx: 230 |  Loss: (0.0332) |  Loss2: (0.0000) | Acc: (99.00%) (29274/29568)
Epoch: 236 | Batch_idx: 240 |  Loss: (0.0331) |  Loss2: (0.0000) | Acc: (98.00%) (30539/30848)
Epoch: 236 | Batch_idx: 250 |  Loss: (0.0336) |  Loss2: (0.0000) | Acc: (98.00%) (31797/32128)
Epoch: 236 | Batch_idx: 260 |  Loss: (0.0337) |  Loss2: (0.0000) | Acc: (98.00%) (33063/33408)
Epoch: 236 | Batch_idx: 270 |  Loss: (0.0339) |  Loss2: (0.0000) | Acc: (98.00%) (34328/34688)
Epoch: 236 | Batch_idx: 280 |  Loss: (0.0340) |  Loss2: (0.0000) | Acc: (98.00%) (35597/35968)
Epoch: 236 | Batch_idx: 290 |  Loss: (0.0339) |  Loss2: (0.0000) | Acc: (98.00%) (36862/37248)
Epoch: 236 | Batch_idx: 300 |  Loss: (0.0340) |  Loss2: (0.0000) | Acc: (98.00%) (38126/38528)
Epoch: 236 | Batch_idx: 310 |  Loss: (0.0341) |  Loss2: (0.0000) | Acc: (98.00%) (39393/39808)
Epoch: 236 | Batch_idx: 320 |  Loss: (0.0344) |  Loss2: (0.0000) | Acc: (98.00%) (40655/41088)
Epoch: 236 | Batch_idx: 330 |  Loss: (0.0342) |  Loss2: (0.0000) | Acc: (98.00%) (41928/42368)
Epoch: 236 | Batch_idx: 340 |  Loss: (0.0343) |  Loss2: (0.0000) | Acc: (98.00%) (43196/43648)
Epoch: 236 | Batch_idx: 350 |  Loss: (0.0344) |  Loss2: (0.0000) | Acc: (98.00%) (44456/44928)
Epoch: 236 | Batch_idx: 360 |  Loss: (0.0346) |  Loss2: (0.0000) | Acc: (98.00%) (45720/46208)
Epoch: 236 | Batch_idx: 370 |  Loss: (0.0349) |  Loss2: (0.0000) | Acc: (98.00%) (46977/47488)
Epoch: 236 | Batch_idx: 380 |  Loss: (0.0349) |  Loss2: (0.0000) | Acc: (98.00%) (48246/48768)
Epoch: 236 | Batch_idx: 390 |  Loss: (0.0350) |  Loss2: (0.0000) | Acc: (98.00%) (49459/50000)
# TEST : Loss: (0.4268) | Acc: (89.00%) (8905/10000)
percent tensor([0.5307, 0.5315, 0.5343, 0.5349, 0.5361, 0.5376, 0.5339, 0.5370, 0.5313,
        0.5307, 0.5294, 0.5325, 0.5301, 0.5317, 0.5330, 0.5317],
       device='cuda:0') torch.Size([16])
percent tensor([0.5338, 0.5432, 0.5300, 0.5277, 0.5252, 0.5402, 0.5356, 0.5238, 0.5318,
        0.5385, 0.5376, 0.5352, 0.5430, 0.5325, 0.5383, 0.5413],
       device='cuda:0') torch.Size([16])
percent tensor([0.6058, 0.5575, 0.6708, 0.6960, 0.6837, 0.6460, 0.6194, 0.6709, 0.6591,
        0.5992, 0.6364, 0.6278, 0.5110, 0.6836, 0.6053, 0.6152],
       device='cuda:0') torch.Size([16])
percent tensor([0.6918, 0.6854, 0.6763, 0.6759, 0.6794, 0.6851, 0.6987, 0.6881, 0.6907,
        0.6959, 0.6911, 0.6885, 0.6890, 0.6874, 0.6920, 0.6980],
       device='cuda:0') torch.Size([16])
percent tensor([0.6905, 0.6367, 0.7091, 0.7070, 0.7180, 0.8182, 0.6416, 0.6410, 0.6788,
        0.6789, 0.6234, 0.6600, 0.6741, 0.6770, 0.6333, 0.7612],
       device='cuda:0') torch.Size([16])
percent tensor([0.6466, 0.7642, 0.7082, 0.7308, 0.7166, 0.7824, 0.7282, 0.5203, 0.7645,
        0.7021, 0.8077, 0.7067, 0.8022, 0.7777, 0.6007, 0.6556],
       device='cuda:0') torch.Size([16])
percent tensor([0.5533, 0.7011, 0.6636, 0.6788, 0.6931, 0.6244, 0.6698, 0.6406, 0.6316,
        0.7044, 0.7190, 0.6269, 0.6616, 0.5631, 0.5875, 0.5407],
       device='cuda:0') torch.Size([16])
percent tensor([0.9999, 0.9998, 0.9997, 0.9999, 0.9994, 0.9993, 0.9997, 0.9994, 0.9998,
        0.9999, 0.9999, 0.9998, 0.9999, 0.9997, 0.9996, 0.9996],
       device='cuda:0') torch.Size([16])
Epoch: 237 | Batch_idx: 0 |  Loss: (0.0334) |  Loss2: (0.0000) | Acc: (98.00%) (126/128)
Epoch: 237 | Batch_idx: 10 |  Loss: (0.0287) |  Loss2: (0.0000) | Acc: (99.00%) (1399/1408)
Epoch: 237 | Batch_idx: 20 |  Loss: (0.0325) |  Loss2: (0.0000) | Acc: (99.00%) (2664/2688)
Epoch: 237 | Batch_idx: 30 |  Loss: (0.0318) |  Loss2: (0.0000) | Acc: (99.00%) (3932/3968)
Epoch: 237 | Batch_idx: 40 |  Loss: (0.0320) |  Loss2: (0.0000) | Acc: (99.00%) (5200/5248)
Epoch: 237 | Batch_idx: 50 |  Loss: (0.0322) |  Loss2: (0.0000) | Acc: (99.00%) (6465/6528)
Epoch: 237 | Batch_idx: 60 |  Loss: (0.0326) |  Loss2: (0.0000) | Acc: (98.00%) (7727/7808)
Epoch: 237 | Batch_idx: 70 |  Loss: (0.0315) |  Loss2: (0.0000) | Acc: (99.00%) (8999/9088)
Epoch: 237 | Batch_idx: 80 |  Loss: (0.0310) |  Loss2: (0.0000) | Acc: (99.00%) (10270/10368)
Epoch: 237 | Batch_idx: 90 |  Loss: (0.0308) |  Loss2: (0.0000) | Acc: (99.00%) (11541/11648)
Epoch: 237 | Batch_idx: 100 |  Loss: (0.0308) |  Loss2: (0.0000) | Acc: (99.00%) (12810/12928)
Epoch: 237 | Batch_idx: 110 |  Loss: (0.0313) |  Loss2: (0.0000) | Acc: (99.00%) (14072/14208)
Epoch: 237 | Batch_idx: 120 |  Loss: (0.0328) |  Loss2: (0.0000) | Acc: (98.00%) (15330/15488)
Epoch: 237 | Batch_idx: 130 |  Loss: (0.0329) |  Loss2: (0.0000) | Acc: (98.00%) (16595/16768)
Epoch: 237 | Batch_idx: 140 |  Loss: (0.0331) |  Loss2: (0.0000) | Acc: (98.00%) (17862/18048)
Epoch: 237 | Batch_idx: 150 |  Loss: (0.0331) |  Loss2: (0.0000) | Acc: (98.00%) (19125/19328)
Epoch: 237 | Batch_idx: 160 |  Loss: (0.0339) |  Loss2: (0.0000) | Acc: (98.00%) (20385/20608)
Epoch: 237 | Batch_idx: 170 |  Loss: (0.0338) |  Loss2: (0.0000) | Acc: (98.00%) (21654/21888)
Epoch: 237 | Batch_idx: 180 |  Loss: (0.0339) |  Loss2: (0.0000) | Acc: (98.00%) (22922/23168)
Epoch: 237 | Batch_idx: 190 |  Loss: (0.0343) |  Loss2: (0.0000) | Acc: (98.00%) (24185/24448)
Epoch: 237 | Batch_idx: 200 |  Loss: (0.0341) |  Loss2: (0.0000) | Acc: (98.00%) (25451/25728)
Epoch: 237 | Batch_idx: 210 |  Loss: (0.0341) |  Loss2: (0.0000) | Acc: (98.00%) (26717/27008)
Epoch: 237 | Batch_idx: 220 |  Loss: (0.0340) |  Loss2: (0.0000) | Acc: (98.00%) (27985/28288)
Epoch: 237 | Batch_idx: 230 |  Loss: (0.0345) |  Loss2: (0.0000) | Acc: (98.00%) (29246/29568)
Epoch: 237 | Batch_idx: 240 |  Loss: (0.0344) |  Loss2: (0.0000) | Acc: (98.00%) (30516/30848)
Epoch: 237 | Batch_idx: 250 |  Loss: (0.0344) |  Loss2: (0.0000) | Acc: (98.00%) (31782/32128)
Epoch: 237 | Batch_idx: 260 |  Loss: (0.0340) |  Loss2: (0.0000) | Acc: (98.00%) (33053/33408)
Epoch: 237 | Batch_idx: 270 |  Loss: (0.0341) |  Loss2: (0.0000) | Acc: (98.00%) (34319/34688)
Epoch: 237 | Batch_idx: 280 |  Loss: (0.0342) |  Loss2: (0.0000) | Acc: (98.00%) (35582/35968)
Epoch: 237 | Batch_idx: 290 |  Loss: (0.0347) |  Loss2: (0.0000) | Acc: (98.00%) (36840/37248)
Epoch: 237 | Batch_idx: 300 |  Loss: (0.0348) |  Loss2: (0.0000) | Acc: (98.00%) (38105/38528)
Epoch: 237 | Batch_idx: 310 |  Loss: (0.0350) |  Loss2: (0.0000) | Acc: (98.00%) (39366/39808)
Epoch: 237 | Batch_idx: 320 |  Loss: (0.0353) |  Loss2: (0.0000) | Acc: (98.00%) (40622/41088)
Epoch: 237 | Batch_idx: 330 |  Loss: (0.0355) |  Loss2: (0.0000) | Acc: (98.00%) (41884/42368)
Epoch: 237 | Batch_idx: 340 |  Loss: (0.0353) |  Loss2: (0.0000) | Acc: (98.00%) (43150/43648)
Epoch: 237 | Batch_idx: 350 |  Loss: (0.0356) |  Loss2: (0.0000) | Acc: (98.00%) (44413/44928)
Epoch: 237 | Batch_idx: 360 |  Loss: (0.0355) |  Loss2: (0.0000) | Acc: (98.00%) (45681/46208)
Epoch: 237 | Batch_idx: 370 |  Loss: (0.0357) |  Loss2: (0.0000) | Acc: (98.00%) (46941/47488)
Epoch: 237 | Batch_idx: 380 |  Loss: (0.0357) |  Loss2: (0.0000) | Acc: (98.00%) (48205/48768)
Epoch: 237 | Batch_idx: 390 |  Loss: (0.0360) |  Loss2: (0.0000) | Acc: (98.00%) (49411/50000)
# TEST : Loss: (0.4220) | Acc: (89.00%) (8941/10000)
percent tensor([0.5306, 0.5321, 0.5337, 0.5343, 0.5358, 0.5383, 0.5346, 0.5365, 0.5313,
        0.5305, 0.5298, 0.5318, 0.5296, 0.5330, 0.5335, 0.5318],
       device='cuda:0') torch.Size([16])
percent tensor([0.5334, 0.5442, 0.5285, 0.5259, 0.5245, 0.5403, 0.5358, 0.5229, 0.5313,
        0.5387, 0.5375, 0.5350, 0.5427, 0.5332, 0.5382, 0.5407],
       device='cuda:0') torch.Size([16])
percent tensor([0.6170, 0.5724, 0.6686, 0.7028, 0.6843, 0.6558, 0.6271, 0.6667, 0.6667,
        0.6115, 0.6509, 0.6285, 0.5223, 0.6990, 0.6128, 0.6300],
       device='cuda:0') torch.Size([16])
percent tensor([0.6900, 0.6818, 0.6765, 0.6746, 0.6780, 0.6812, 0.6940, 0.6838, 0.6882,
        0.6934, 0.6892, 0.6844, 0.6876, 0.6825, 0.6887, 0.6973],
       device='cuda:0') torch.Size([16])
percent tensor([0.6838, 0.6422, 0.7153, 0.7076, 0.7223, 0.8030, 0.6433, 0.6418, 0.6811,
        0.6941, 0.6240, 0.6666, 0.6718, 0.6803, 0.6348, 0.7529],
       device='cuda:0') torch.Size([16])
percent tensor([0.6682, 0.7568, 0.7253, 0.7455, 0.7163, 0.7867, 0.7281, 0.5478, 0.7522,
        0.7214, 0.8048, 0.7293, 0.8122, 0.7874, 0.6004, 0.6532],
       device='cuda:0') torch.Size([16])
percent tensor([0.5690, 0.6691, 0.6839, 0.6793, 0.7105, 0.6646, 0.6764, 0.6579, 0.5994,
        0.7055, 0.6795, 0.6342, 0.6508, 0.5528, 0.5788, 0.5475],
       device='cuda:0') torch.Size([16])
percent tensor([0.9999, 0.9999, 0.9999, 0.9999, 0.9992, 0.9990, 0.9997, 0.9997, 0.9999,
        0.9999, 1.0000, 0.9999, 0.9999, 0.9995, 0.9996, 0.9997],
       device='cuda:0') torch.Size([16])
Epoch: 238 | Batch_idx: 0 |  Loss: (0.0360) |  Loss2: (0.0000) | Acc: (99.00%) (127/128)
Epoch: 238 | Batch_idx: 10 |  Loss: (0.0342) |  Loss2: (0.0000) | Acc: (99.00%) (1396/1408)
Epoch: 238 | Batch_idx: 20 |  Loss: (0.0356) |  Loss2: (0.0000) | Acc: (99.00%) (2663/2688)
Epoch: 238 | Batch_idx: 30 |  Loss: (0.0364) |  Loss2: (0.0000) | Acc: (98.00%) (3927/3968)
Epoch: 238 | Batch_idx: 40 |  Loss: (0.0351) |  Loss2: (0.0000) | Acc: (99.00%) (5197/5248)
Epoch: 238 | Batch_idx: 50 |  Loss: (0.0340) |  Loss2: (0.0000) | Acc: (99.00%) (6465/6528)
Epoch: 238 | Batch_idx: 60 |  Loss: (0.0329) |  Loss2: (0.0000) | Acc: (99.00%) (7736/7808)
Epoch: 238 | Batch_idx: 70 |  Loss: (0.0327) |  Loss2: (0.0000) | Acc: (99.00%) (9001/9088)
Epoch: 238 | Batch_idx: 80 |  Loss: (0.0339) |  Loss2: (0.0000) | Acc: (98.00%) (10264/10368)
Epoch: 238 | Batch_idx: 90 |  Loss: (0.0342) |  Loss2: (0.0000) | Acc: (98.00%) (11528/11648)
Epoch: 238 | Batch_idx: 100 |  Loss: (0.0349) |  Loss2: (0.0000) | Acc: (98.00%) (12792/12928)
Epoch: 238 | Batch_idx: 110 |  Loss: (0.0338) |  Loss2: (0.0000) | Acc: (98.00%) (14063/14208)
Epoch: 238 | Batch_idx: 120 |  Loss: (0.0340) |  Loss2: (0.0000) | Acc: (98.00%) (15325/15488)
Epoch: 238 | Batch_idx: 130 |  Loss: (0.0345) |  Loss2: (0.0000) | Acc: (98.00%) (16587/16768)
Epoch: 238 | Batch_idx: 140 |  Loss: (0.0340) |  Loss2: (0.0000) | Acc: (98.00%) (17860/18048)
Epoch: 238 | Batch_idx: 150 |  Loss: (0.0344) |  Loss2: (0.0000) | Acc: (98.00%) (19125/19328)
Epoch: 238 | Batch_idx: 160 |  Loss: (0.0343) |  Loss2: (0.0000) | Acc: (98.00%) (20392/20608)
Epoch: 238 | Batch_idx: 170 |  Loss: (0.0343) |  Loss2: (0.0000) | Acc: (98.00%) (21658/21888)
Epoch: 238 | Batch_idx: 180 |  Loss: (0.0345) |  Loss2: (0.0000) | Acc: (98.00%) (22927/23168)
Epoch: 238 | Batch_idx: 190 |  Loss: (0.0352) |  Loss2: (0.0000) | Acc: (98.00%) (24187/24448)
Epoch: 238 | Batch_idx: 200 |  Loss: (0.0352) |  Loss2: (0.0000) | Acc: (98.00%) (25452/25728)
Epoch: 238 | Batch_idx: 210 |  Loss: (0.0361) |  Loss2: (0.0000) | Acc: (98.00%) (26710/27008)
Epoch: 238 | Batch_idx: 220 |  Loss: (0.0367) |  Loss2: (0.0000) | Acc: (98.00%) (27967/28288)
Epoch: 238 | Batch_idx: 230 |  Loss: (0.0367) |  Loss2: (0.0000) | Acc: (98.00%) (29233/29568)
Epoch: 238 | Batch_idx: 240 |  Loss: (0.0367) |  Loss2: (0.0000) | Acc: (98.00%) (30499/30848)
Epoch: 238 | Batch_idx: 250 |  Loss: (0.0371) |  Loss2: (0.0000) | Acc: (98.00%) (31758/32128)
Epoch: 238 | Batch_idx: 260 |  Loss: (0.0368) |  Loss2: (0.0000) | Acc: (98.00%) (33028/33408)
Epoch: 238 | Batch_idx: 270 |  Loss: (0.0367) |  Loss2: (0.0000) | Acc: (98.00%) (34295/34688)
Epoch: 238 | Batch_idx: 280 |  Loss: (0.0370) |  Loss2: (0.0000) | Acc: (98.00%) (35557/35968)
Epoch: 238 | Batch_idx: 290 |  Loss: (0.0372) |  Loss2: (0.0000) | Acc: (98.00%) (36820/37248)
Epoch: 238 | Batch_idx: 300 |  Loss: (0.0371) |  Loss2: (0.0000) | Acc: (98.00%) (38081/38528)
Epoch: 238 | Batch_idx: 310 |  Loss: (0.0371) |  Loss2: (0.0000) | Acc: (98.00%) (39347/39808)
Epoch: 238 | Batch_idx: 320 |  Loss: (0.0371) |  Loss2: (0.0000) | Acc: (98.00%) (40610/41088)
Epoch: 238 | Batch_idx: 330 |  Loss: (0.0371) |  Loss2: (0.0000) | Acc: (98.00%) (41870/42368)
Epoch: 238 | Batch_idx: 340 |  Loss: (0.0367) |  Loss2: (0.0000) | Acc: (98.00%) (43144/43648)
Epoch: 238 | Batch_idx: 350 |  Loss: (0.0365) |  Loss2: (0.0000) | Acc: (98.00%) (44413/44928)
Epoch: 238 | Batch_idx: 360 |  Loss: (0.0365) |  Loss2: (0.0000) | Acc: (98.00%) (45675/46208)
Epoch: 238 | Batch_idx: 370 |  Loss: (0.0366) |  Loss2: (0.0000) | Acc: (98.00%) (46940/47488)
Epoch: 238 | Batch_idx: 380 |  Loss: (0.0364) |  Loss2: (0.0000) | Acc: (98.00%) (48206/48768)
Epoch: 238 | Batch_idx: 390 |  Loss: (0.0365) |  Loss2: (0.0000) | Acc: (98.00%) (49424/50000)
# TEST : Loss: (0.4320) | Acc: (89.00%) (8920/10000)
percent tensor([0.5301, 0.5321, 0.5335, 0.5342, 0.5354, 0.5366, 0.5343, 0.5364, 0.5311,
        0.5307, 0.5291, 0.5317, 0.5293, 0.5328, 0.5327, 0.5315],
       device='cuda:0') torch.Size([16])
percent tensor([0.5323, 0.5442, 0.5281, 0.5265, 0.5237, 0.5386, 0.5349, 0.5232, 0.5304,
        0.5388, 0.5368, 0.5338, 0.5423, 0.5322, 0.5373, 0.5401],
       device='cuda:0') torch.Size([16])
percent tensor([0.6215, 0.5654, 0.6814, 0.7021, 0.6922, 0.6637, 0.6316, 0.6802, 0.6713,
        0.6141, 0.6522, 0.6415, 0.5292, 0.6961, 0.6165, 0.6316],
       device='cuda:0') torch.Size([16])
percent tensor([0.6918, 0.6835, 0.6785, 0.6763, 0.6796, 0.6871, 0.6955, 0.6863, 0.6882,
        0.6931, 0.6879, 0.6850, 0.6867, 0.6838, 0.6915, 0.6981],
       device='cuda:0') torch.Size([16])
percent tensor([0.6799, 0.6388, 0.6891, 0.7059, 0.7092, 0.7993, 0.6441, 0.6334, 0.6741,
        0.6886, 0.6373, 0.6536, 0.6688, 0.6771, 0.6368, 0.7543],
       device='cuda:0') torch.Size([16])
percent tensor([0.6850, 0.7734, 0.7475, 0.7548, 0.7328, 0.7963, 0.7554, 0.5555, 0.7801,
        0.7404, 0.8246, 0.7509, 0.8210, 0.7969, 0.6137, 0.6713],
       device='cuda:0') torch.Size([16])
percent tensor([0.5621, 0.6898, 0.6896, 0.6856, 0.7047, 0.6604, 0.6691, 0.6463, 0.6436,
        0.7234, 0.7103, 0.6447, 0.6610, 0.5609, 0.5685, 0.5425],
       device='cuda:0') torch.Size([16])
percent tensor([0.9999, 0.9999, 0.9998, 0.9999, 0.9994, 0.9989, 0.9998, 0.9996, 0.9998,
        0.9999, 0.9999, 0.9998, 0.9999, 0.9997, 0.9996, 0.9996],
       device='cuda:0') torch.Size([16])
Epoch: 239 | Batch_idx: 0 |  Loss: (0.0174) |  Loss2: (0.0000) | Acc: (99.00%) (127/128)
Epoch: 239 | Batch_idx: 10 |  Loss: (0.0374) |  Loss2: (0.0000) | Acc: (98.00%) (1387/1408)
Epoch: 239 | Batch_idx: 20 |  Loss: (0.0416) |  Loss2: (0.0000) | Acc: (98.00%) (2648/2688)
Epoch: 239 | Batch_idx: 30 |  Loss: (0.0411) |  Loss2: (0.0000) | Acc: (98.00%) (3910/3968)
Epoch: 239 | Batch_idx: 40 |  Loss: (0.0415) |  Loss2: (0.0000) | Acc: (98.00%) (5172/5248)
Epoch: 239 | Batch_idx: 50 |  Loss: (0.0420) |  Loss2: (0.0000) | Acc: (98.00%) (6434/6528)
Epoch: 239 | Batch_idx: 60 |  Loss: (0.0411) |  Loss2: (0.0000) | Acc: (98.00%) (7696/7808)
Epoch: 239 | Batch_idx: 70 |  Loss: (0.0408) |  Loss2: (0.0000) | Acc: (98.00%) (8961/9088)
Epoch: 239 | Batch_idx: 80 |  Loss: (0.0406) |  Loss2: (0.0000) | Acc: (98.00%) (10225/10368)
Epoch: 239 | Batch_idx: 90 |  Loss: (0.0396) |  Loss2: (0.0000) | Acc: (98.00%) (11491/11648)
Epoch: 239 | Batch_idx: 100 |  Loss: (0.0402) |  Loss2: (0.0000) | Acc: (98.00%) (12752/12928)
Epoch: 239 | Batch_idx: 110 |  Loss: (0.0403) |  Loss2: (0.0000) | Acc: (98.00%) (14016/14208)
Epoch: 239 | Batch_idx: 120 |  Loss: (0.0410) |  Loss2: (0.0000) | Acc: (98.00%) (15278/15488)
Epoch: 239 | Batch_idx: 130 |  Loss: (0.0411) |  Loss2: (0.0000) | Acc: (98.00%) (16538/16768)
Epoch: 239 | Batch_idx: 140 |  Loss: (0.0413) |  Loss2: (0.0000) | Acc: (98.00%) (17796/18048)
Epoch: 239 | Batch_idx: 150 |  Loss: (0.0412) |  Loss2: (0.0000) | Acc: (98.00%) (19060/19328)
Epoch: 239 | Batch_idx: 160 |  Loss: (0.0411) |  Loss2: (0.0000) | Acc: (98.00%) (20322/20608)
Epoch: 239 | Batch_idx: 170 |  Loss: (0.0403) |  Loss2: (0.0000) | Acc: (98.00%) (21590/21888)
Epoch: 239 | Batch_idx: 180 |  Loss: (0.0399) |  Loss2: (0.0000) | Acc: (98.00%) (22858/23168)
Epoch: 239 | Batch_idx: 190 |  Loss: (0.0394) |  Loss2: (0.0000) | Acc: (98.00%) (24129/24448)
Epoch: 239 | Batch_idx: 200 |  Loss: (0.0391) |  Loss2: (0.0000) | Acc: (98.00%) (25396/25728)
Epoch: 239 | Batch_idx: 210 |  Loss: (0.0385) |  Loss2: (0.0000) | Acc: (98.00%) (26668/27008)
Epoch: 239 | Batch_idx: 220 |  Loss: (0.0386) |  Loss2: (0.0000) | Acc: (98.00%) (27934/28288)
Epoch: 239 | Batch_idx: 230 |  Loss: (0.0387) |  Loss2: (0.0000) | Acc: (98.00%) (29199/29568)
Epoch: 239 | Batch_idx: 240 |  Loss: (0.0386) |  Loss2: (0.0000) | Acc: (98.00%) (30464/30848)
Epoch: 239 | Batch_idx: 250 |  Loss: (0.0386) |  Loss2: (0.0000) | Acc: (98.00%) (31724/32128)
Epoch: 239 | Batch_idx: 260 |  Loss: (0.0384) |  Loss2: (0.0000) | Acc: (98.00%) (32992/33408)
Epoch: 239 | Batch_idx: 270 |  Loss: (0.0384) |  Loss2: (0.0000) | Acc: (98.00%) (34253/34688)
Epoch: 239 | Batch_idx: 280 |  Loss: (0.0379) |  Loss2: (0.0000) | Acc: (98.00%) (35526/35968)
Epoch: 239 | Batch_idx: 290 |  Loss: (0.0378) |  Loss2: (0.0000) | Acc: (98.00%) (36790/37248)
Epoch: 239 | Batch_idx: 300 |  Loss: (0.0376) |  Loss2: (0.0000) | Acc: (98.00%) (38062/38528)
Epoch: 239 | Batch_idx: 310 |  Loss: (0.0377) |  Loss2: (0.0000) | Acc: (98.00%) (39330/39808)
Epoch: 239 | Batch_idx: 320 |  Loss: (0.0377) |  Loss2: (0.0000) | Acc: (98.00%) (40594/41088)
Epoch: 239 | Batch_idx: 330 |  Loss: (0.0377) |  Loss2: (0.0000) | Acc: (98.00%) (41858/42368)
Epoch: 239 | Batch_idx: 340 |  Loss: (0.0377) |  Loss2: (0.0000) | Acc: (98.00%) (43126/43648)
Epoch: 239 | Batch_idx: 350 |  Loss: (0.0375) |  Loss2: (0.0000) | Acc: (98.00%) (44392/44928)
Epoch: 239 | Batch_idx: 360 |  Loss: (0.0375) |  Loss2: (0.0000) | Acc: (98.00%) (45658/46208)
Epoch: 239 | Batch_idx: 370 |  Loss: (0.0376) |  Loss2: (0.0000) | Acc: (98.00%) (46923/47488)
Epoch: 239 | Batch_idx: 380 |  Loss: (0.0375) |  Loss2: (0.0000) | Acc: (98.00%) (48189/48768)
Epoch: 239 | Batch_idx: 390 |  Loss: (0.0375) |  Loss2: (0.0000) | Acc: (98.00%) (49407/50000)
# TEST : Loss: (0.4233) | Acc: (89.00%) (8953/10000)
percent tensor([0.5309, 0.5323, 0.5345, 0.5349, 0.5364, 0.5376, 0.5350, 0.5371, 0.5320,
        0.5312, 0.5298, 0.5327, 0.5302, 0.5329, 0.5334, 0.5319],
       device='cuda:0') torch.Size([16])
percent tensor([0.5343, 0.5446, 0.5314, 0.5280, 0.5266, 0.5411, 0.5369, 0.5241, 0.5317,
        0.5399, 0.5377, 0.5369, 0.5439, 0.5331, 0.5389, 0.5412],
       device='cuda:0') torch.Size([16])
percent tensor([0.6107, 0.5616, 0.6780, 0.7027, 0.6876, 0.6494, 0.6218, 0.6746, 0.6520,
        0.6060, 0.6346, 0.6373, 0.5217, 0.6808, 0.6082, 0.6262],
       device='cuda:0') torch.Size([16])
percent tensor([0.6921, 0.6833, 0.6814, 0.6770, 0.6800, 0.6849, 0.6956, 0.6869, 0.6912,
        0.6938, 0.6904, 0.6857, 0.6871, 0.6847, 0.6911, 0.6986],
       device='cuda:0') torch.Size([16])
percent tensor([0.7010, 0.6376, 0.7167, 0.7290, 0.7253, 0.8193, 0.6475, 0.6537, 0.6921,
        0.6857, 0.6339, 0.6690, 0.6837, 0.6918, 0.6396, 0.7643],
       device='cuda:0') torch.Size([16])
percent tensor([0.6645, 0.7538, 0.7088, 0.7280, 0.6932, 0.7925, 0.7238, 0.5271, 0.7580,
        0.7219, 0.8111, 0.7421, 0.8252, 0.7825, 0.5964, 0.6616],
       device='cuda:0') torch.Size([16])
percent tensor([0.5534, 0.6927, 0.6622, 0.6555, 0.6718, 0.6360, 0.6705, 0.6393, 0.6324,
        0.7149, 0.7057, 0.6287, 0.6676, 0.5692, 0.5729, 0.5410],
       device='cuda:0') torch.Size([16])
percent tensor([0.9999, 0.9999, 0.9998, 0.9999, 0.9996, 0.9990, 0.9998, 0.9996, 0.9999,
        0.9999, 0.9999, 0.9999, 0.9999, 0.9997, 0.9996, 0.9997],
       device='cuda:0') torch.Size([16])
Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 3, 3, 3]) tensor(183.7680, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(842.3106, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(846.4792, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([128, 64, 3, 3]) tensor(1514.2133, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([128, 64, 1, 1]) tensor(471.7847, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([128, 128, 3, 3]) tensor(2334.1694, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([256, 128, 3, 3]) tensor(4265.7280, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([256, 128, 1, 1]) tensor(1326.6039, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([256, 256, 3, 3]) tensor(6392.6650, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([512, 256, 3, 3]) tensor(11414.0420, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([512, 256, 1, 1]) tensor(3727.7002, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([512, 512, 3, 3]) tensor(15745.4004, device='cuda:0', grad_fn=<NormBackward0>)
6 hours 12 mins 40 secs for training