Files already downloaded and verified
USE 1 GPUs!
Epoch: 0 | Batch_idx: 0 |  Loss: (2.3238) |  Loss2: (0.0000) | Acc: (7.00%) (10/128)
Epoch: 0 | Batch_idx: 10 |  Loss: (2.3102) |  Loss2: (0.0000) | Acc: (8.00%) (113/1408)
Epoch: 0 | Batch_idx: 20 |  Loss: (2.3037) |  Loss2: (0.0000) | Acc: (8.00%) (237/2688)
Epoch: 0 | Batch_idx: 30 |  Loss: (2.2981) |  Loss2: (0.0000) | Acc: (10.00%) (412/3968)
Epoch: 0 | Batch_idx: 40 |  Loss: (2.2917) |  Loss2: (0.0000) | Acc: (12.00%) (634/5248)
Epoch: 0 | Batch_idx: 50 |  Loss: (2.2855) |  Loss2: (0.0000) | Acc: (13.00%) (861/6528)
Epoch: 0 | Batch_idx: 60 |  Loss: (2.2797) |  Loss2: (0.0000) | Acc: (13.00%) (1090/7808)
Epoch: 0 | Batch_idx: 70 |  Loss: (2.2724) |  Loss2: (0.0000) | Acc: (14.00%) (1356/9088)
Epoch: 0 | Batch_idx: 80 |  Loss: (2.2653) |  Loss2: (0.0000) | Acc: (15.00%) (1623/10368)
Epoch: 0 | Batch_idx: 90 |  Loss: (2.2568) |  Loss2: (0.0000) | Acc: (16.00%) (1909/11648)
Epoch: 0 | Batch_idx: 100 |  Loss: (2.2479) |  Loss2: (0.0000) | Acc: (17.00%) (2200/12928)
Epoch: 0 | Batch_idx: 110 |  Loss: (2.2396) |  Loss2: (0.0000) | Acc: (17.00%) (2511/14208)
Epoch: 0 | Batch_idx: 120 |  Loss: (2.2327) |  Loss2: (0.0000) | Acc: (18.00%) (2824/15488)
Epoch: 0 | Batch_idx: 130 |  Loss: (2.2246) |  Loss2: (0.0000) | Acc: (18.00%) (3111/16768)
Epoch: 0 | Batch_idx: 140 |  Loss: (2.2168) |  Loss2: (0.0000) | Acc: (18.00%) (3415/18048)
Epoch: 0 | Batch_idx: 150 |  Loss: (2.2093) |  Loss2: (0.0000) | Acc: (19.00%) (3733/19328)
Epoch: 0 | Batch_idx: 160 |  Loss: (2.2011) |  Loss2: (0.0000) | Acc: (19.00%) (4060/20608)
Epoch: 0 | Batch_idx: 170 |  Loss: (2.1940) |  Loss2: (0.0000) | Acc: (19.00%) (4354/21888)
Epoch: 0 | Batch_idx: 180 |  Loss: (2.1856) |  Loss2: (0.0000) | Acc: (20.00%) (4685/23168)
Epoch: 0 | Batch_idx: 190 |  Loss: (2.1784) |  Loss2: (0.0000) | Acc: (20.00%) (5027/24448)
Epoch: 0 | Batch_idx: 200 |  Loss: (2.1693) |  Loss2: (0.0000) | Acc: (20.00%) (5390/25728)
Epoch: 0 | Batch_idx: 210 |  Loss: (2.1609) |  Loss2: (0.0000) | Acc: (21.00%) (5745/27008)
Epoch: 0 | Batch_idx: 220 |  Loss: (2.1531) |  Loss2: (0.0000) | Acc: (21.00%) (6109/28288)
Epoch: 0 | Batch_idx: 230 |  Loss: (2.1465) |  Loss2: (0.0000) | Acc: (21.00%) (6466/29568)
Epoch: 0 | Batch_idx: 240 |  Loss: (2.1396) |  Loss2: (0.0000) | Acc: (22.00%) (6835/30848)
Epoch: 0 | Batch_idx: 250 |  Loss: (2.1324) |  Loss2: (0.0000) | Acc: (22.00%) (7186/32128)
Epoch: 0 | Batch_idx: 260 |  Loss: (2.1251) |  Loss2: (0.0000) | Acc: (22.00%) (7585/33408)
Epoch: 0 | Batch_idx: 270 |  Loss: (2.1171) |  Loss2: (0.0000) | Acc: (22.00%) (7963/34688)
Epoch: 0 | Batch_idx: 280 |  Loss: (2.1103) |  Loss2: (0.0000) | Acc: (23.00%) (8343/35968)
Epoch: 0 | Batch_idx: 290 |  Loss: (2.1030) |  Loss2: (0.0000) | Acc: (23.00%) (8731/37248)
Epoch: 0 | Batch_idx: 300 |  Loss: (2.0965) |  Loss2: (0.0000) | Acc: (23.00%) (9103/38528)
Epoch: 0 | Batch_idx: 310 |  Loss: (2.0898) |  Loss2: (0.0000) | Acc: (23.00%) (9488/39808)
Epoch: 0 | Batch_idx: 320 |  Loss: (2.0833) |  Loss2: (0.0000) | Acc: (24.00%) (9882/41088)
Epoch: 0 | Batch_idx: 330 |  Loss: (2.0767) |  Loss2: (0.0000) | Acc: (24.00%) (10280/42368)
Epoch: 0 | Batch_idx: 340 |  Loss: (2.0708) |  Loss2: (0.0000) | Acc: (24.00%) (10661/43648)
Epoch: 0 | Batch_idx: 350 |  Loss: (2.0645) |  Loss2: (0.0000) | Acc: (24.00%) (11051/44928)
Epoch: 0 | Batch_idx: 360 |  Loss: (2.0586) |  Loss2: (0.0000) | Acc: (24.00%) (11443/46208)
Epoch: 0 | Batch_idx: 370 |  Loss: (2.0527) |  Loss2: (0.0000) | Acc: (24.00%) (11867/47488)
Epoch: 0 | Batch_idx: 380 |  Loss: (2.0467) |  Loss2: (0.0000) | Acc: (25.00%) (12286/48768)
Epoch: 0 | Batch_idx: 390 |  Loss: (2.0409) |  Loss2: (0.0000) | Acc: (25.00%) (12673/50000)
/usr/local/lib/python3.6/dist-packages/torch/serialization.py:241: UserWarning: Couldn't retrieve source code for container of type ResNet. It won't be checked for correctness upon loading.
  "type " + obj.__name__ + ". It won't be checked "
/usr/local/lib/python3.6/dist-packages/torch/serialization.py:241: UserWarning: Couldn't retrieve source code for container of type BasicBlock. It won't be checked for correctness upon loading.
  "type " + obj.__name__ + ". It won't be checked "
/usr/local/lib/python3.6/dist-packages/torch/serialization.py:241: UserWarning: Couldn't retrieve source code for container of type _Gate. It won't be checked for correctness upon loading.
  "type " + obj.__name__ + ". It won't be checked "
=> saving checkpoint 'drive/app/torch/save_Schedule/checkpoint_000.pth.tar'
# TEST : Loss: (1.7851) | Acc: (32.00%) (3250/10000)
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 3, 3, 3]) tensor(165.2711, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(770.4498, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(769.2204, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([128, 64, 3, 3]) tensor(1533.9653, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([128, 64, 1, 1]) tensor(515.5213, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([128, 128, 3, 3]) tensor(2169.5112, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([256, 128, 3, 3]) tensor(4346.4717, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([256, 128, 1, 1]) tensor(1456.3274, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([256, 256, 3, 3]) tensor(6135.7021, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([512, 256, 3, 3]) tensor(12287.5840, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([512, 256, 1, 1]) tensor(4100.4746, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([512, 512, 3, 3]) tensor(17365.4238, device='cuda:0', grad_fn=<NormBackward0>)
Epoch: 1 | Batch_idx: 0 |  Loss: (1.8518) |  Loss2: (0.0000) | Acc: (24.00%) (31/128)
Epoch: 1 | Batch_idx: 10 |  Loss: (1.8338) |  Loss2: (0.0000) | Acc: (34.00%) (484/1408)
Epoch: 1 | Batch_idx: 20 |  Loss: (1.8161) |  Loss2: (0.0000) | Acc: (34.00%) (916/2688)
Epoch: 1 | Batch_idx: 30 |  Loss: (1.8031) |  Loss2: (0.0000) | Acc: (34.00%) (1367/3968)
Epoch: 1 | Batch_idx: 40 |  Loss: (1.8030) |  Loss2: (0.0000) | Acc: (34.00%) (1799/5248)
Epoch: 1 | Batch_idx: 50 |  Loss: (1.8022) |  Loss2: (0.0000) | Acc: (34.00%) (2221/6528)
Epoch: 1 | Batch_idx: 60 |  Loss: (1.7973) |  Loss2: (0.0000) | Acc: (33.00%) (2654/7808)
Epoch: 1 | Batch_idx: 70 |  Loss: (1.7970) |  Loss2: (0.0000) | Acc: (33.00%) (3068/9088)
Epoch: 1 | Batch_idx: 80 |  Loss: (1.7923) |  Loss2: (0.0000) | Acc: (33.00%) (3489/10368)
Epoch: 1 | Batch_idx: 90 |  Loss: (1.7875) |  Loss2: (0.0000) | Acc: (33.00%) (3952/11648)
Epoch: 1 | Batch_idx: 100 |  Loss: (1.7830) |  Loss2: (0.0000) | Acc: (34.00%) (4431/12928)
Epoch: 1 | Batch_idx: 110 |  Loss: (1.7789) |  Loss2: (0.0000) | Acc: (34.00%) (4911/14208)
Epoch: 1 | Batch_idx: 120 |  Loss: (1.7743) |  Loss2: (0.0000) | Acc: (34.00%) (5388/15488)
Epoch: 1 | Batch_idx: 130 |  Loss: (1.7723) |  Loss2: (0.0000) | Acc: (34.00%) (5841/16768)
Epoch: 1 | Batch_idx: 140 |  Loss: (1.7699) |  Loss2: (0.0000) | Acc: (34.00%) (6298/18048)
Epoch: 1 | Batch_idx: 150 |  Loss: (1.7663) |  Loss2: (0.0000) | Acc: (35.00%) (6771/19328)
Epoch: 1 | Batch_idx: 160 |  Loss: (1.7614) |  Loss2: (0.0000) | Acc: (35.00%) (7258/20608)
Epoch: 1 | Batch_idx: 170 |  Loss: (1.7599) |  Loss2: (0.0000) | Acc: (35.00%) (7687/21888)
Epoch: 1 | Batch_idx: 180 |  Loss: (1.7559) |  Loss2: (0.0000) | Acc: (35.00%) (8161/23168)
Epoch: 1 | Batch_idx: 190 |  Loss: (1.7513) |  Loss2: (0.0000) | Acc: (35.00%) (8668/24448)
Epoch: 1 | Batch_idx: 200 |  Loss: (1.7482) |  Loss2: (0.0000) | Acc: (35.00%) (9157/25728)
Epoch: 1 | Batch_idx: 210 |  Loss: (1.7448) |  Loss2: (0.0000) | Acc: (35.00%) (9628/27008)
Epoch: 1 | Batch_idx: 220 |  Loss: (1.7418) |  Loss2: (0.0000) | Acc: (35.00%) (10107/28288)
Epoch: 1 | Batch_idx: 230 |  Loss: (1.7381) |  Loss2: (0.0000) | Acc: (35.00%) (10630/29568)
Epoch: 1 | Batch_idx: 240 |  Loss: (1.7344) |  Loss2: (0.0000) | Acc: (36.00%) (11156/30848)
Epoch: 1 | Batch_idx: 250 |  Loss: (1.7325) |  Loss2: (0.0000) | Acc: (36.00%) (11630/32128)
Epoch: 1 | Batch_idx: 260 |  Loss: (1.7292) |  Loss2: (0.0000) | Acc: (36.00%) (12125/33408)
Epoch: 1 | Batch_idx: 270 |  Loss: (1.7271) |  Loss2: (0.0000) | Acc: (36.00%) (12614/34688)
Epoch: 1 | Batch_idx: 280 |  Loss: (1.7235) |  Loss2: (0.0000) | Acc: (36.00%) (13121/35968)
Epoch: 1 | Batch_idx: 290 |  Loss: (1.7209) |  Loss2: (0.0000) | Acc: (36.00%) (13624/37248)
Epoch: 1 | Batch_idx: 300 |  Loss: (1.7171) |  Loss2: (0.0000) | Acc: (36.00%) (14158/38528)
Epoch: 1 | Batch_idx: 310 |  Loss: (1.7143) |  Loss2: (0.0000) | Acc: (36.00%) (14673/39808)
Epoch: 1 | Batch_idx: 320 |  Loss: (1.7120) |  Loss2: (0.0000) | Acc: (36.00%) (15187/41088)
Epoch: 1 | Batch_idx: 330 |  Loss: (1.7090) |  Loss2: (0.0000) | Acc: (37.00%) (15725/42368)
Epoch: 1 | Batch_idx: 340 |  Loss: (1.7059) |  Loss2: (0.0000) | Acc: (37.00%) (16253/43648)
Epoch: 1 | Batch_idx: 350 |  Loss: (1.7025) |  Loss2: (0.0000) | Acc: (37.00%) (16791/44928)
Epoch: 1 | Batch_idx: 360 |  Loss: (1.6995) |  Loss2: (0.0000) | Acc: (37.00%) (17294/46208)
Epoch: 1 | Batch_idx: 370 |  Loss: (1.6963) |  Loss2: (0.0000) | Acc: (37.00%) (17816/47488)
Epoch: 1 | Batch_idx: 380 |  Loss: (1.6931) |  Loss2: (0.0000) | Acc: (37.00%) (18349/48768)
Epoch: 1 | Batch_idx: 390 |  Loss: (1.6898) |  Loss2: (0.0000) | Acc: (37.00%) (18868/50000)
# TEST : Loss: (1.5566) | Acc: (42.00%) (4211/10000)
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
Epoch: 2 | Batch_idx: 0 |  Loss: (1.5360) |  Loss2: (0.0000) | Acc: (42.00%) (55/128)
Epoch: 2 | Batch_idx: 10 |  Loss: (1.5834) |  Loss2: (0.0000) | Acc: (41.00%) (587/1408)
Epoch: 2 | Batch_idx: 20 |  Loss: (1.5589) |  Loss2: (0.0000) | Acc: (43.00%) (1163/2688)
Epoch: 2 | Batch_idx: 30 |  Loss: (1.5612) |  Loss2: (0.0000) | Acc: (42.00%) (1702/3968)
Epoch: 2 | Batch_idx: 40 |  Loss: (1.5563) |  Loss2: (0.0000) | Acc: (42.00%) (2240/5248)
Epoch: 2 | Batch_idx: 50 |  Loss: (1.5540) |  Loss2: (0.0000) | Acc: (42.00%) (2775/6528)
Epoch: 2 | Batch_idx: 60 |  Loss: (1.5577) |  Loss2: (0.0000) | Acc: (42.00%) (3314/7808)
Epoch: 2 | Batch_idx: 70 |  Loss: (1.5524) |  Loss2: (0.0000) | Acc: (42.00%) (3880/9088)
Epoch: 2 | Batch_idx: 80 |  Loss: (1.5494) |  Loss2: (0.0000) | Acc: (43.00%) (4461/10368)
Epoch: 2 | Batch_idx: 90 |  Loss: (1.5486) |  Loss2: (0.0000) | Acc: (42.00%) (4995/11648)
Epoch: 2 | Batch_idx: 100 |  Loss: (1.5472) |  Loss2: (0.0000) | Acc: (42.00%) (5551/12928)
Epoch: 2 | Batch_idx: 110 |  Loss: (1.5437) |  Loss2: (0.0000) | Acc: (43.00%) (6111/14208)
Epoch: 2 | Batch_idx: 120 |  Loss: (1.5432) |  Loss2: (0.0000) | Acc: (43.00%) (6667/15488)
Epoch: 2 | Batch_idx: 130 |  Loss: (1.5405) |  Loss2: (0.0000) | Acc: (43.00%) (7245/16768)
Epoch: 2 | Batch_idx: 140 |  Loss: (1.5405) |  Loss2: (0.0000) | Acc: (43.00%) (7798/18048)
Epoch: 2 | Batch_idx: 150 |  Loss: (1.5387) |  Loss2: (0.0000) | Acc: (43.00%) (8377/19328)
Epoch: 2 | Batch_idx: 160 |  Loss: (1.5364) |  Loss2: (0.0000) | Acc: (43.00%) (8968/20608)
Epoch: 2 | Batch_idx: 170 |  Loss: (1.5335) |  Loss2: (0.0000) | Acc: (43.00%) (9544/21888)
Epoch: 2 | Batch_idx: 180 |  Loss: (1.5312) |  Loss2: (0.0000) | Acc: (43.00%) (10129/23168)
Epoch: 2 | Batch_idx: 190 |  Loss: (1.5302) |  Loss2: (0.0000) | Acc: (43.00%) (10707/24448)
Epoch: 2 | Batch_idx: 200 |  Loss: (1.5279) |  Loss2: (0.0000) | Acc: (43.00%) (11273/25728)
Epoch: 2 | Batch_idx: 210 |  Loss: (1.5261) |  Loss2: (0.0000) | Acc: (43.00%) (11850/27008)
Epoch: 2 | Batch_idx: 220 |  Loss: (1.5250) |  Loss2: (0.0000) | Acc: (43.00%) (12436/28288)
Epoch: 2 | Batch_idx: 230 |  Loss: (1.5220) |  Loss2: (0.0000) | Acc: (44.00%) (13031/29568)
Epoch: 2 | Batch_idx: 240 |  Loss: (1.5178) |  Loss2: (0.0000) | Acc: (44.00%) (13630/30848)
Epoch: 2 | Batch_idx: 250 |  Loss: (1.5160) |  Loss2: (0.0000) | Acc: (44.00%) (14213/32128)
Epoch: 2 | Batch_idx: 260 |  Loss: (1.5146) |  Loss2: (0.0000) | Acc: (44.00%) (14790/33408)
Epoch: 2 | Batch_idx: 270 |  Loss: (1.5130) |  Loss2: (0.0000) | Acc: (44.00%) (15372/34688)
Epoch: 2 | Batch_idx: 280 |  Loss: (1.5107) |  Loss2: (0.0000) | Acc: (44.00%) (15967/35968)
Epoch: 2 | Batch_idx: 290 |  Loss: (1.5078) |  Loss2: (0.0000) | Acc: (44.00%) (16576/37248)
Epoch: 2 | Batch_idx: 300 |  Loss: (1.5055) |  Loss2: (0.0000) | Acc: (44.00%) (17159/38528)
Epoch: 2 | Batch_idx: 310 |  Loss: (1.5045) |  Loss2: (0.0000) | Acc: (44.00%) (17764/39808)
Epoch: 2 | Batch_idx: 320 |  Loss: (1.5024) |  Loss2: (0.0000) | Acc: (44.00%) (18366/41088)
Epoch: 2 | Batch_idx: 330 |  Loss: (1.5009) |  Loss2: (0.0000) | Acc: (44.00%) (18973/42368)
Epoch: 2 | Batch_idx: 340 |  Loss: (1.4994) |  Loss2: (0.0000) | Acc: (44.00%) (19579/43648)
Epoch: 2 | Batch_idx: 350 |  Loss: (1.4983) |  Loss2: (0.0000) | Acc: (44.00%) (20174/44928)
Epoch: 2 | Batch_idx: 360 |  Loss: (1.4960) |  Loss2: (0.0000) | Acc: (44.00%) (20782/46208)
Epoch: 2 | Batch_idx: 370 |  Loss: (1.4951) |  Loss2: (0.0000) | Acc: (45.00%) (21391/47488)
Epoch: 2 | Batch_idx: 380 |  Loss: (1.4924) |  Loss2: (0.0000) | Acc: (45.00%) (22042/48768)
Epoch: 2 | Batch_idx: 390 |  Loss: (1.4903) |  Loss2: (0.0000) | Acc: (45.00%) (22653/50000)
# TEST : Loss: (1.4759) | Acc: (45.00%) (4578/10000)
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
False Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=128, out_features=16, bias=False)
True Linear(in_features=16, out_features=2, bias=False)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=128, out_features=16, bias=False)
True Linear(in_features=16, out_features=2, bias=False)
False Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=256, out_features=32, bias=False)
True Linear(in_features=32, out_features=2, bias=False)
False Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=256, out_features=32, bias=False)
True Linear(in_features=32, out_features=2, bias=False)
False Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=512, out_features=64, bias=False)
True Linear(in_features=64, out_features=2, bias=False)
False Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=512, out_features=64, bias=False)
True Linear(in_features=64, out_features=2, bias=False)
False Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1024, out_features=128, bias=False)
True Linear(in_features=128, out_features=2, bias=False)
False Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1024, out_features=128, bias=False)
True Linear(in_features=128, out_features=2, bias=False)
False Linear(in_features=512, out_features=10, bias=True)
Epoch: 3 | Batch_idx: 0 |  Loss: (1.3824) |  Loss2: (0.0000) | Acc: (51.00%) (66/128)
Epoch: 3 | Batch_idx: 10 |  Loss: (1.4317) |  Loss2: (0.0000) | Acc: (48.00%) (689/1408)
Epoch: 3 | Batch_idx: 20 |  Loss: (1.5110) |  Loss2: (0.0000) | Acc: (44.00%) (1196/2688)
Epoch: 3 | Batch_idx: 30 |  Loss: (1.5376) |  Loss2: (0.0000) | Acc: (42.00%) (1702/3968)
Epoch: 3 | Batch_idx: 40 |  Loss: (1.5387) |  Loss2: (0.0000) | Acc: (42.00%) (2252/5248)
Epoch: 3 | Batch_idx: 50 |  Loss: (1.5357) |  Loss2: (0.0000) | Acc: (43.00%) (2813/6528)
Epoch: 3 | Batch_idx: 60 |  Loss: (1.5337) |  Loss2: (0.0000) | Acc: (43.00%) (3370/7808)
Epoch: 3 | Batch_idx: 70 |  Loss: (1.5314) |  Loss2: (0.0000) | Acc: (43.00%) (3930/9088)
Epoch: 3 | Batch_idx: 80 |  Loss: (1.5327) |  Loss2: (0.0000) | Acc: (43.00%) (4480/10368)
Epoch: 3 | Batch_idx: 90 |  Loss: (1.5289) |  Loss2: (0.0000) | Acc: (43.00%) (5047/11648)
Epoch: 3 | Batch_idx: 100 |  Loss: (1.5233) |  Loss2: (0.0000) | Acc: (43.00%) (5628/12928)
Epoch: 3 | Batch_idx: 110 |  Loss: (1.5211) |  Loss2: (0.0000) | Acc: (43.00%) (6194/14208)
Epoch: 3 | Batch_idx: 120 |  Loss: (1.5229) |  Loss2: (0.0000) | Acc: (43.00%) (6738/15488)
Epoch: 3 | Batch_idx: 130 |  Loss: (1.5223) |  Loss2: (0.0000) | Acc: (43.00%) (7303/16768)
Epoch: 3 | Batch_idx: 140 |  Loss: (1.5212) |  Loss2: (0.0000) | Acc: (43.00%) (7843/18048)
Epoch: 3 | Batch_idx: 150 |  Loss: (1.5219) |  Loss2: (0.0000) | Acc: (43.00%) (8401/19328)
Epoch: 3 | Batch_idx: 160 |  Loss: (1.5204) |  Loss2: (0.0000) | Acc: (43.00%) (8988/20608)
Epoch: 3 | Batch_idx: 170 |  Loss: (1.5189) |  Loss2: (0.0000) | Acc: (43.00%) (9563/21888)
Epoch: 3 | Batch_idx: 180 |  Loss: (1.5164) |  Loss2: (0.0000) | Acc: (43.00%) (10163/23168)
Epoch: 3 | Batch_idx: 190 |  Loss: (1.5126) |  Loss2: (0.0000) | Acc: (43.00%) (10750/24448)
Epoch: 3 | Batch_idx: 200 |  Loss: (1.5102) |  Loss2: (0.0000) | Acc: (44.00%) (11322/25728)
Epoch: 3 | Batch_idx: 210 |  Loss: (1.5058) |  Loss2: (0.0000) | Acc: (44.00%) (11922/27008)
Epoch: 3 | Batch_idx: 220 |  Loss: (1.5030) |  Loss2: (0.0000) | Acc: (44.00%) (12526/28288)
Epoch: 3 | Batch_idx: 230 |  Loss: (1.5008) |  Loss2: (0.0000) | Acc: (44.00%) (13113/29568)
Epoch: 3 | Batch_idx: 240 |  Loss: (1.5000) |  Loss2: (0.0000) | Acc: (44.00%) (13691/30848)
Epoch: 3 | Batch_idx: 250 |  Loss: (1.4992) |  Loss2: (0.0000) | Acc: (44.00%) (14283/32128)
Epoch: 3 | Batch_idx: 260 |  Loss: (1.4982) |  Loss2: (0.0000) | Acc: (44.00%) (14842/33408)
Epoch: 3 | Batch_idx: 270 |  Loss: (1.4967) |  Loss2: (0.0000) | Acc: (44.00%) (15440/34688)
Epoch: 3 | Batch_idx: 280 |  Loss: (1.4958) |  Loss2: (0.0000) | Acc: (44.00%) (16038/35968)
Epoch: 3 | Batch_idx: 290 |  Loss: (1.4950) |  Loss2: (0.0000) | Acc: (44.00%) (16631/37248)
Epoch: 3 | Batch_idx: 300 |  Loss: (1.4930) |  Loss2: (0.0000) | Acc: (44.00%) (17244/38528)
Epoch: 3 | Batch_idx: 310 |  Loss: (1.4932) |  Loss2: (0.0000) | Acc: (44.00%) (17808/39808)
Epoch: 3 | Batch_idx: 320 |  Loss: (1.4910) |  Loss2: (0.0000) | Acc: (44.00%) (18388/41088)
Epoch: 3 | Batch_idx: 330 |  Loss: (1.4895) |  Loss2: (0.0000) | Acc: (44.00%) (19006/42368)
Epoch: 3 | Batch_idx: 340 |  Loss: (1.4882) |  Loss2: (0.0000) | Acc: (44.00%) (19603/43648)
Epoch: 3 | Batch_idx: 350 |  Loss: (1.4871) |  Loss2: (0.0000) | Acc: (44.00%) (20207/44928)
Epoch: 3 | Batch_idx: 360 |  Loss: (1.4849) |  Loss2: (0.0000) | Acc: (45.00%) (20820/46208)
Epoch: 3 | Batch_idx: 370 |  Loss: (1.4828) |  Loss2: (0.0000) | Acc: (45.00%) (21419/47488)
Epoch: 3 | Batch_idx: 380 |  Loss: (1.4816) |  Loss2: (0.0000) | Acc: (45.00%) (22023/48768)
Epoch: 3 | Batch_idx: 390 |  Loss: (1.4804) |  Loss2: (0.0000) | Acc: (45.00%) (22588/50000)
# TEST : Loss: (1.4069) | Acc: (47.00%) (4748/10000)
percent tensor([0.4738, 0.4615, 0.4668, 0.4755, 0.4630, 0.4788, 0.4587, 0.4637, 0.4632,
        0.4635, 0.4669, 0.4632, 0.4683, 0.4633, 0.4681, 0.4714],
       device='cuda:0') torch.Size([16])
percent tensor([0.5022, 0.5042, 0.5026, 0.5027, 0.5033, 0.5033, 0.5037, 0.5032, 0.5029,
        0.5031, 0.5028, 0.5031, 0.5021, 0.5044, 0.5038, 0.5025],
       device='cuda:0') torch.Size([16])
percent tensor([0.5008, 0.4972, 0.5118, 0.5043, 0.5111, 0.5041, 0.5022, 0.5083, 0.5010,
        0.5014, 0.4979, 0.5095, 0.4995, 0.4963, 0.5012, 0.5011],
       device='cuda:0') torch.Size([16])
percent tensor([0.5025, 0.5000, 0.5059, 0.5063, 0.5061, 0.5051, 0.5021, 0.5064, 0.5014,
        0.5018, 0.4997, 0.5045, 0.5004, 0.5001, 0.5036, 0.5037],
       device='cuda:0') torch.Size([16])
percent tensor([0.5013, 0.4986, 0.5118, 0.5111, 0.5106, 0.5034, 0.5029, 0.5110, 0.5018,
        0.5025, 0.4994, 0.5092, 0.5005, 0.4994, 0.5015, 0.5024],
       device='cuda:0') torch.Size([16])
percent tensor([0.4964, 0.4919, 0.5035, 0.5037, 0.5009, 0.5013, 0.4959, 0.5005, 0.4948,
        0.4932, 0.4924, 0.5015, 0.4932, 0.4920, 0.4973, 0.4953],
       device='cuda:0') torch.Size([16])
percent tensor([0.5050, 0.5050, 0.5196, 0.5212, 0.5186, 0.5131, 0.5058, 0.5201, 0.5051,
        0.5072, 0.5047, 0.5124, 0.5046, 0.5058, 0.5071, 0.5063],
       device='cuda:0') torch.Size([16])
percent tensor([0.5351, 0.5615, 0.5814, 0.5811, 0.5792, 0.5555, 0.5455, 0.6058, 0.5455,
        0.5606, 0.5497, 0.5473, 0.5504, 0.5584, 0.5487, 0.5698],
       device='cuda:0') torch.Size([16])
Epoch: 4 | Batch_idx: 0 |  Loss: (1.4699) |  Loss2: (0.0000) | Acc: (42.00%) (54/128)
Epoch: 4 | Batch_idx: 10 |  Loss: (1.4232) |  Loss2: (0.0000) | Acc: (47.00%) (662/1408)
Epoch: 4 | Batch_idx: 20 |  Loss: (1.4266) |  Loss2: (0.0000) | Acc: (46.00%) (1245/2688)
Epoch: 4 | Batch_idx: 30 |  Loss: (1.4307) |  Loss2: (0.0000) | Acc: (46.00%) (1852/3968)
Epoch: 4 | Batch_idx: 40 |  Loss: (1.4229) |  Loss2: (0.0000) | Acc: (47.00%) (2480/5248)
Epoch: 4 | Batch_idx: 50 |  Loss: (1.4168) |  Loss2: (0.0000) | Acc: (47.00%) (3095/6528)
Epoch: 4 | Batch_idx: 60 |  Loss: (1.4164) |  Loss2: (0.0000) | Acc: (47.00%) (3704/7808)
Epoch: 4 | Batch_idx: 70 |  Loss: (1.4197) |  Loss2: (0.0000) | Acc: (47.00%) (4321/9088)
Epoch: 4 | Batch_idx: 80 |  Loss: (1.4232) |  Loss2: (0.0000) | Acc: (47.00%) (4915/10368)
Epoch: 4 | Batch_idx: 90 |  Loss: (1.4258) |  Loss2: (0.0000) | Acc: (47.00%) (5520/11648)
Epoch: 4 | Batch_idx: 100 |  Loss: (1.4247) |  Loss2: (0.0000) | Acc: (47.00%) (6134/12928)
Epoch: 4 | Batch_idx: 110 |  Loss: (1.4228) |  Loss2: (0.0000) | Acc: (47.00%) (6745/14208)
Epoch: 4 | Batch_idx: 120 |  Loss: (1.4215) |  Loss2: (0.0000) | Acc: (47.00%) (7358/15488)
Epoch: 4 | Batch_idx: 130 |  Loss: (1.4231) |  Loss2: (0.0000) | Acc: (47.00%) (7986/16768)
Epoch: 4 | Batch_idx: 140 |  Loss: (1.4239) |  Loss2: (0.0000) | Acc: (47.00%) (8609/18048)
Epoch: 4 | Batch_idx: 150 |  Loss: (1.4212) |  Loss2: (0.0000) | Acc: (47.00%) (9215/19328)
Epoch: 4 | Batch_idx: 160 |  Loss: (1.4184) |  Loss2: (0.0000) | Acc: (47.00%) (9843/20608)
Epoch: 4 | Batch_idx: 170 |  Loss: (1.4188) |  Loss2: (0.0000) | Acc: (47.00%) (10436/21888)
Epoch: 4 | Batch_idx: 180 |  Loss: (1.4182) |  Loss2: (0.0000) | Acc: (47.00%) (11050/23168)
Epoch: 4 | Batch_idx: 190 |  Loss: (1.4178) |  Loss2: (0.0000) | Acc: (47.00%) (11662/24448)
Epoch: 4 | Batch_idx: 200 |  Loss: (1.4154) |  Loss2: (0.0000) | Acc: (47.00%) (12285/25728)
Epoch: 4 | Batch_idx: 210 |  Loss: (1.4144) |  Loss2: (0.0000) | Acc: (47.00%) (12922/27008)
Epoch: 4 | Batch_idx: 220 |  Loss: (1.4131) |  Loss2: (0.0000) | Acc: (47.00%) (13533/28288)
Epoch: 4 | Batch_idx: 230 |  Loss: (1.4135) |  Loss2: (0.0000) | Acc: (47.00%) (14123/29568)
Epoch: 4 | Batch_idx: 240 |  Loss: (1.4125) |  Loss2: (0.0000) | Acc: (47.00%) (14740/30848)
Epoch: 4 | Batch_idx: 250 |  Loss: (1.4133) |  Loss2: (0.0000) | Acc: (47.00%) (15344/32128)
Epoch: 4 | Batch_idx: 260 |  Loss: (1.4131) |  Loss2: (0.0000) | Acc: (47.00%) (15962/33408)
Epoch: 4 | Batch_idx: 270 |  Loss: (1.4132) |  Loss2: (0.0000) | Acc: (47.00%) (16578/34688)
Epoch: 4 | Batch_idx: 280 |  Loss: (1.4127) |  Loss2: (0.0000) | Acc: (47.00%) (17195/35968)
Epoch: 4 | Batch_idx: 290 |  Loss: (1.4117) |  Loss2: (0.0000) | Acc: (47.00%) (17843/37248)
Epoch: 4 | Batch_idx: 300 |  Loss: (1.4118) |  Loss2: (0.0000) | Acc: (47.00%) (18466/38528)
Epoch: 4 | Batch_idx: 310 |  Loss: (1.4120) |  Loss2: (0.0000) | Acc: (47.00%) (19087/39808)
Epoch: 4 | Batch_idx: 320 |  Loss: (1.4133) |  Loss2: (0.0000) | Acc: (47.00%) (19676/41088)
Epoch: 4 | Batch_idx: 330 |  Loss: (1.4131) |  Loss2: (0.0000) | Acc: (47.00%) (20291/42368)
Epoch: 4 | Batch_idx: 340 |  Loss: (1.4125) |  Loss2: (0.0000) | Acc: (47.00%) (20893/43648)
Epoch: 4 | Batch_idx: 350 |  Loss: (1.4122) |  Loss2: (0.0000) | Acc: (47.00%) (21496/44928)
Epoch: 4 | Batch_idx: 360 |  Loss: (1.4108) |  Loss2: (0.0000) | Acc: (47.00%) (22132/46208)
Epoch: 4 | Batch_idx: 370 |  Loss: (1.4106) |  Loss2: (0.0000) | Acc: (47.00%) (22726/47488)
Epoch: 4 | Batch_idx: 380 |  Loss: (1.4105) |  Loss2: (0.0000) | Acc: (47.00%) (23337/48768)
Epoch: 4 | Batch_idx: 390 |  Loss: (1.4101) |  Loss2: (0.0000) | Acc: (47.00%) (23946/50000)
# TEST : Loss: (1.3782) | Acc: (48.00%) (4862/10000)
percent tensor([0.4715, 0.4585, 0.4631, 0.4737, 0.4592, 0.4775, 0.4548, 0.4609, 0.4597,
        0.4601, 0.4637, 0.4588, 0.4653, 0.4612, 0.4656, 0.4697],
       device='cuda:0') torch.Size([16])
percent tensor([0.5044, 0.5076, 0.5053, 0.5053, 0.5063, 0.5061, 0.5070, 0.5064, 0.5055,
        0.5058, 0.5053, 0.5058, 0.5041, 0.5081, 0.5070, 0.5049],
       device='cuda:0') torch.Size([16])
percent tensor([0.5014, 0.4946, 0.5191, 0.5074, 0.5179, 0.5075, 0.5033, 0.5140, 0.5014,
        0.5021, 0.4961, 0.5154, 0.4990, 0.4928, 0.5023, 0.5023],
       device='cuda:0') torch.Size([16])
percent tensor([0.5058, 0.5022, 0.5105, 0.5110, 0.5110, 0.5093, 0.5057, 0.5116, 0.5045,
        0.5046, 0.5017, 0.5085, 0.5026, 0.5027, 0.5074, 0.5080],
       device='cuda:0') torch.Size([16])
percent tensor([0.5020, 0.4969, 0.5175, 0.5162, 0.5162, 0.5066, 0.5041, 0.5161, 0.5028,
        0.5020, 0.4990, 0.5139, 0.5008, 0.4984, 0.5027, 0.5040],
       device='cuda:0') torch.Size([16])
percent tensor([0.4943, 0.4865, 0.5060, 0.5067, 0.5016, 0.5035, 0.4935, 0.5011, 0.4915,
        0.4878, 0.4870, 0.5028, 0.4887, 0.4868, 0.4961, 0.4930],
       device='cuda:0') torch.Size([16])
percent tensor([0.5087, 0.5068, 0.5320, 0.5357, 0.5288, 0.5242, 0.5089, 0.5325, 0.5097,
        0.5111, 0.5078, 0.5209, 0.5086, 0.5096, 0.5115, 0.5105],
       device='cuda:0') torch.Size([16])
percent tensor([0.6561, 0.7100, 0.7779, 0.7866, 0.7668, 0.7189, 0.6744, 0.8382, 0.6904,
        0.7293, 0.6959, 0.6833, 0.6967, 0.7156, 0.6881, 0.7568],
       device='cuda:0') torch.Size([16])
Epoch: 5 | Batch_idx: 0 |  Loss: (1.3742) |  Loss2: (0.0000) | Acc: (50.00%) (64/128)
Epoch: 5 | Batch_idx: 10 |  Loss: (1.3951) |  Loss2: (0.0000) | Acc: (47.00%) (671/1408)
Epoch: 5 | Batch_idx: 20 |  Loss: (1.4009) |  Loss2: (0.0000) | Acc: (47.00%) (1272/2688)
Epoch: 5 | Batch_idx: 30 |  Loss: (1.3895) |  Loss2: (0.0000) | Acc: (48.00%) (1917/3968)
Epoch: 5 | Batch_idx: 40 |  Loss: (1.3954) |  Loss2: (0.0000) | Acc: (47.00%) (2519/5248)
Epoch: 5 | Batch_idx: 50 |  Loss: (1.3900) |  Loss2: (0.0000) | Acc: (48.00%) (3145/6528)
Epoch: 5 | Batch_idx: 60 |  Loss: (1.3826) |  Loss2: (0.0000) | Acc: (48.00%) (3780/7808)
Epoch: 5 | Batch_idx: 70 |  Loss: (1.3832) |  Loss2: (0.0000) | Acc: (48.00%) (4415/9088)
Epoch: 5 | Batch_idx: 80 |  Loss: (1.3887) |  Loss2: (0.0000) | Acc: (48.00%) (5032/10368)
Epoch: 5 | Batch_idx: 90 |  Loss: (1.3891) |  Loss2: (0.0000) | Acc: (48.00%) (5643/11648)
Epoch: 5 | Batch_idx: 100 |  Loss: (1.3967) |  Loss2: (0.0000) | Acc: (48.00%) (6251/12928)
Epoch: 5 | Batch_idx: 110 |  Loss: (1.3958) |  Loss2: (0.0000) | Acc: (48.00%) (6860/14208)
Epoch: 5 | Batch_idx: 120 |  Loss: (1.3958) |  Loss2: (0.0000) | Acc: (48.00%) (7470/15488)
Epoch: 5 | Batch_idx: 130 |  Loss: (1.3972) |  Loss2: (0.0000) | Acc: (48.00%) (8071/16768)
Epoch: 5 | Batch_idx: 140 |  Loss: (1.3981) |  Loss2: (0.0000) | Acc: (48.00%) (8692/18048)
Epoch: 5 | Batch_idx: 150 |  Loss: (1.3960) |  Loss2: (0.0000) | Acc: (48.00%) (9321/19328)
Epoch: 5 | Batch_idx: 160 |  Loss: (1.3948) |  Loss2: (0.0000) | Acc: (48.00%) (9963/20608)
Epoch: 5 | Batch_idx: 170 |  Loss: (1.3959) |  Loss2: (0.0000) | Acc: (48.00%) (10567/21888)
Epoch: 5 | Batch_idx: 180 |  Loss: (1.3962) |  Loss2: (0.0000) | Acc: (48.00%) (11178/23168)
Epoch: 5 | Batch_idx: 190 |  Loss: (1.3957) |  Loss2: (0.0000) | Acc: (48.00%) (11772/24448)
Epoch: 5 | Batch_idx: 200 |  Loss: (1.3962) |  Loss2: (0.0000) | Acc: (48.00%) (12381/25728)
Epoch: 5 | Batch_idx: 210 |  Loss: (1.3945) |  Loss2: (0.0000) | Acc: (48.00%) (13018/27008)
Epoch: 5 | Batch_idx: 220 |  Loss: (1.3958) |  Loss2: (0.0000) | Acc: (48.00%) (13617/28288)
Epoch: 5 | Batch_idx: 230 |  Loss: (1.3953) |  Loss2: (0.0000) | Acc: (48.00%) (14250/29568)
Epoch: 5 | Batch_idx: 240 |  Loss: (1.3916) |  Loss2: (0.0000) | Acc: (48.00%) (14911/30848)
Epoch: 5 | Batch_idx: 250 |  Loss: (1.3912) |  Loss2: (0.0000) | Acc: (48.00%) (15535/32128)
Epoch: 5 | Batch_idx: 260 |  Loss: (1.3908) |  Loss2: (0.0000) | Acc: (48.00%) (16147/33408)
Epoch: 5 | Batch_idx: 270 |  Loss: (1.3912) |  Loss2: (0.0000) | Acc: (48.00%) (16749/34688)
Epoch: 5 | Batch_idx: 280 |  Loss: (1.3884) |  Loss2: (0.0000) | Acc: (48.00%) (17390/35968)
Epoch: 5 | Batch_idx: 290 |  Loss: (1.3875) |  Loss2: (0.0000) | Acc: (48.00%) (18035/37248)
Epoch: 5 | Batch_idx: 300 |  Loss: (1.3895) |  Loss2: (0.0000) | Acc: (48.00%) (18619/38528)
Epoch: 5 | Batch_idx: 310 |  Loss: (1.3888) |  Loss2: (0.0000) | Acc: (48.00%) (19249/39808)
Epoch: 5 | Batch_idx: 320 |  Loss: (1.3886) |  Loss2: (0.0000) | Acc: (48.00%) (19877/41088)
Epoch: 5 | Batch_idx: 330 |  Loss: (1.3882) |  Loss2: (0.0000) | Acc: (48.00%) (20474/42368)
Epoch: 5 | Batch_idx: 340 |  Loss: (1.3876) |  Loss2: (0.0000) | Acc: (48.00%) (21098/43648)
Epoch: 5 | Batch_idx: 350 |  Loss: (1.3873) |  Loss2: (0.0000) | Acc: (48.00%) (21719/44928)
Epoch: 5 | Batch_idx: 360 |  Loss: (1.3866) |  Loss2: (0.0000) | Acc: (48.00%) (22344/46208)
Epoch: 5 | Batch_idx: 370 |  Loss: (1.3879) |  Loss2: (0.0000) | Acc: (48.00%) (22932/47488)
Epoch: 5 | Batch_idx: 380 |  Loss: (1.3861) |  Loss2: (0.0000) | Acc: (48.00%) (23595/48768)
Epoch: 5 | Batch_idx: 390 |  Loss: (1.3856) |  Loss2: (0.0000) | Acc: (48.00%) (24205/50000)
=> saving checkpoint 'drive/app/torch/save_Schedule/checkpoint_005.pth.tar'
# TEST : Loss: (1.3672) | Acc: (48.00%) (4881/10000)
percent tensor([0.4760, 0.4658, 0.4686, 0.4777, 0.4655, 0.4817, 0.4620, 0.4676, 0.4657,
        0.4663, 0.4693, 0.4646, 0.4703, 0.4691, 0.4715, 0.4751],
       device='cuda:0') torch.Size([16])
percent tensor([0.5067, 0.5108, 0.5082, 0.5081, 0.5095, 0.5089, 0.5101, 0.5095, 0.5082,
        0.5084, 0.5078, 0.5088, 0.5063, 0.5113, 0.5100, 0.5073],
       device='cuda:0') torch.Size([16])
percent tensor([0.5028, 0.4910, 0.5247, 0.5103, 0.5225, 0.5115, 0.5029, 0.5185, 0.5010,
        0.5016, 0.4940, 0.5195, 0.4985, 0.4886, 0.5031, 0.5039],
       device='cuda:0') torch.Size([16])
percent tensor([0.5089, 0.5049, 0.5145, 0.5147, 0.5154, 0.5127, 0.5094, 0.5160, 0.5076,
        0.5073, 0.5039, 0.5122, 0.5049, 0.5058, 0.5109, 0.5116],
       device='cuda:0') torch.Size([16])
percent tensor([0.5025, 0.4950, 0.5219, 0.5198, 0.5206, 0.5096, 0.5048, 0.5197, 0.5032,
        0.5008, 0.4981, 0.5176, 0.5008, 0.4972, 0.5035, 0.5049],
       device='cuda:0') torch.Size([16])
percent tensor([0.4905, 0.4801, 0.5064, 0.5074, 0.5003, 0.5036, 0.4899, 0.4991, 0.4872,
        0.4810, 0.4803, 0.5027, 0.4829, 0.4812, 0.4931, 0.4876],
       device='cuda:0') torch.Size([16])
percent tensor([0.5101, 0.5062, 0.5411, 0.5454, 0.5359, 0.5319, 0.5101, 0.5405, 0.5118,
        0.5122, 0.5081, 0.5280, 0.5098, 0.5108, 0.5129, 0.5111],
       device='cuda:0') torch.Size([16])
percent tensor([0.7431, 0.7960, 0.8807, 0.8902, 0.8719, 0.8307, 0.7628, 0.9335, 0.7818,
        0.8271, 0.7851, 0.7801, 0.7865, 0.8017, 0.7813, 0.8619],
       device='cuda:0') torch.Size([16])
True Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=128, out_features=16, bias=False)
False Linear(in_features=16, out_features=2, bias=False)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=128, out_features=16, bias=False)
False Linear(in_features=16, out_features=2, bias=False)
True Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=256, out_features=32, bias=False)
False Linear(in_features=32, out_features=2, bias=False)
True Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=256, out_features=32, bias=False)
False Linear(in_features=32, out_features=2, bias=False)
True Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=512, out_features=64, bias=False)
False Linear(in_features=64, out_features=2, bias=False)
True Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=512, out_features=64, bias=False)
False Linear(in_features=64, out_features=2, bias=False)
True Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1024, out_features=128, bias=False)
False Linear(in_features=128, out_features=2, bias=False)
True Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1024, out_features=128, bias=False)
False Linear(in_features=128, out_features=2, bias=False)
True Linear(in_features=512, out_features=10, bias=True)
Epoch: 6 | Batch_idx: 0 |  Loss: (1.3787) |  Loss2: (0.0000) | Acc: (48.00%) (62/128)
Epoch: 6 | Batch_idx: 10 |  Loss: (1.3708) |  Loss2: (0.0000) | Acc: (48.00%) (689/1408)
Epoch: 6 | Batch_idx: 20 |  Loss: (1.3944) |  Loss2: (0.0000) | Acc: (48.00%) (1307/2688)
Epoch: 6 | Batch_idx: 30 |  Loss: (1.3920) |  Loss2: (0.0000) | Acc: (48.00%) (1930/3968)
Epoch: 6 | Batch_idx: 40 |  Loss: (1.3767) |  Loss2: (0.0000) | Acc: (49.00%) (2599/5248)
Epoch: 6 | Batch_idx: 50 |  Loss: (1.3737) |  Loss2: (0.0000) | Acc: (49.00%) (3236/6528)
Epoch: 6 | Batch_idx: 60 |  Loss: (1.3690) |  Loss2: (0.0000) | Acc: (49.00%) (3872/7808)
Epoch: 6 | Batch_idx: 70 |  Loss: (1.3665) |  Loss2: (0.0000) | Acc: (49.00%) (4494/9088)
Epoch: 6 | Batch_idx: 80 |  Loss: (1.3719) |  Loss2: (0.0000) | Acc: (49.00%) (5099/10368)
Epoch: 6 | Batch_idx: 90 |  Loss: (1.3681) |  Loss2: (0.0000) | Acc: (49.00%) (5767/11648)
Epoch: 6 | Batch_idx: 100 |  Loss: (1.3667) |  Loss2: (0.0000) | Acc: (49.00%) (6418/12928)
Epoch: 6 | Batch_idx: 110 |  Loss: (1.3661) |  Loss2: (0.0000) | Acc: (49.00%) (7078/14208)
Epoch: 6 | Batch_idx: 120 |  Loss: (1.3634) |  Loss2: (0.0000) | Acc: (49.00%) (7719/15488)
Epoch: 6 | Batch_idx: 130 |  Loss: (1.3621) |  Loss2: (0.0000) | Acc: (49.00%) (8355/16768)
Epoch: 6 | Batch_idx: 140 |  Loss: (1.3570) |  Loss2: (0.0000) | Acc: (50.00%) (9032/18048)
Epoch: 6 | Batch_idx: 150 |  Loss: (1.3555) |  Loss2: (0.0000) | Acc: (50.00%) (9701/19328)
Epoch: 6 | Batch_idx: 160 |  Loss: (1.3555) |  Loss2: (0.0000) | Acc: (50.00%) (10348/20608)
Epoch: 6 | Batch_idx: 170 |  Loss: (1.3512) |  Loss2: (0.0000) | Acc: (50.00%) (11018/21888)
Epoch: 6 | Batch_idx: 180 |  Loss: (1.3465) |  Loss2: (0.0000) | Acc: (50.00%) (11725/23168)
Epoch: 6 | Batch_idx: 190 |  Loss: (1.3443) |  Loss2: (0.0000) | Acc: (50.00%) (12396/24448)
Epoch: 6 | Batch_idx: 200 |  Loss: (1.3424) |  Loss2: (0.0000) | Acc: (50.00%) (13066/25728)
Epoch: 6 | Batch_idx: 210 |  Loss: (1.3392) |  Loss2: (0.0000) | Acc: (50.00%) (13764/27008)
Epoch: 6 | Batch_idx: 220 |  Loss: (1.3387) |  Loss2: (0.0000) | Acc: (50.00%) (14416/28288)
Epoch: 6 | Batch_idx: 230 |  Loss: (1.3379) |  Loss2: (0.0000) | Acc: (51.00%) (15093/29568)
Epoch: 6 | Batch_idx: 240 |  Loss: (1.3370) |  Loss2: (0.0000) | Acc: (51.00%) (15778/30848)
Epoch: 6 | Batch_idx: 250 |  Loss: (1.3351) |  Loss2: (0.0000) | Acc: (51.00%) (16452/32128)
Epoch: 6 | Batch_idx: 260 |  Loss: (1.3331) |  Loss2: (0.0000) | Acc: (51.00%) (17130/33408)
Epoch: 6 | Batch_idx: 270 |  Loss: (1.3293) |  Loss2: (0.0000) | Acc: (51.00%) (17838/34688)
Epoch: 6 | Batch_idx: 280 |  Loss: (1.3276) |  Loss2: (0.0000) | Acc: (51.00%) (18518/35968)
Epoch: 6 | Batch_idx: 290 |  Loss: (1.3254) |  Loss2: (0.0000) | Acc: (51.00%) (19204/37248)
Epoch: 6 | Batch_idx: 300 |  Loss: (1.3220) |  Loss2: (0.0000) | Acc: (51.00%) (19925/38528)
Epoch: 6 | Batch_idx: 310 |  Loss: (1.3195) |  Loss2: (0.0000) | Acc: (51.00%) (20622/39808)
Epoch: 6 | Batch_idx: 320 |  Loss: (1.3168) |  Loss2: (0.0000) | Acc: (51.00%) (21334/41088)
Epoch: 6 | Batch_idx: 330 |  Loss: (1.3141) |  Loss2: (0.0000) | Acc: (52.00%) (22060/42368)
Epoch: 6 | Batch_idx: 340 |  Loss: (1.3121) |  Loss2: (0.0000) | Acc: (52.00%) (22760/43648)
Epoch: 6 | Batch_idx: 350 |  Loss: (1.3091) |  Loss2: (0.0000) | Acc: (52.00%) (23488/44928)
Epoch: 6 | Batch_idx: 360 |  Loss: (1.3074) |  Loss2: (0.0000) | Acc: (52.00%) (24177/46208)
Epoch: 6 | Batch_idx: 370 |  Loss: (1.3069) |  Loss2: (0.0000) | Acc: (52.00%) (24867/47488)
Epoch: 6 | Batch_idx: 380 |  Loss: (1.3044) |  Loss2: (0.0000) | Acc: (52.00%) (25583/48768)
Epoch: 6 | Batch_idx: 390 |  Loss: (1.3021) |  Loss2: (0.0000) | Acc: (52.00%) (26267/50000)
# TEST : Loss: (1.2424) | Acc: (54.00%) (5472/10000)
percent tensor([0.4766, 0.4649, 0.4695, 0.4785, 0.4673, 0.4826, 0.4624, 0.4679, 0.4662,
        0.4665, 0.4686, 0.4653, 0.4698, 0.4687, 0.4704, 0.4752],
       device='cuda:0') torch.Size([16])
percent tensor([0.5079, 0.5102, 0.5093, 0.5080, 0.5102, 0.5088, 0.5102, 0.5091, 0.5081,
        0.5083, 0.5075, 0.5093, 0.5066, 0.5111, 0.5096, 0.5077],
       device='cuda:0') torch.Size([16])
percent tensor([0.5026, 0.4906, 0.5207, 0.5106, 0.5197, 0.5090, 0.5024, 0.5154, 0.5003,
        0.4995, 0.4930, 0.5164, 0.4966, 0.4902, 0.5017, 0.5043],
       device='cuda:0') torch.Size([16])
percent tensor([0.5095, 0.5056, 0.5139, 0.5148, 0.5150, 0.5111, 0.5093, 0.5149, 0.5086,
        0.5066, 0.5042, 0.5115, 0.5052, 0.5078, 0.5097, 0.5110],
       device='cuda:0') torch.Size([16])
percent tensor([0.5035, 0.4964, 0.5156, 0.5181, 0.5153, 0.5091, 0.5042, 0.5155, 0.5027,
        0.4999, 0.4987, 0.5133, 0.5010, 0.4997, 0.5037, 0.5056],
       device='cuda:0') torch.Size([16])
percent tensor([0.4902, 0.4831, 0.5007, 0.5028, 0.4959, 0.5000, 0.4889, 0.4935, 0.4881,
        0.4837, 0.4825, 0.4983, 0.4838, 0.4851, 0.4900, 0.4864],
       device='cuda:0') torch.Size([16])
percent tensor([0.5113, 0.5079, 0.5371, 0.5359, 0.5347, 0.5247, 0.5119, 0.5381, 0.5135,
        0.5147, 0.5105, 0.5286, 0.5113, 0.5098, 0.5133, 0.5146],
       device='cuda:0') torch.Size([16])
percent tensor([0.7756, 0.7797, 0.8816, 0.8494, 0.8843, 0.8377, 0.8295, 0.9478, 0.7873,
        0.8146, 0.7871, 0.8255, 0.7831, 0.7629, 0.8180, 0.9350],
       device='cuda:0') torch.Size([16])
Epoch: 7 | Batch_idx: 0 |  Loss: (1.3293) |  Loss2: (0.0000) | Acc: (49.00%) (63/128)
Epoch: 7 | Batch_idx: 10 |  Loss: (1.2220) |  Loss2: (0.0000) | Acc: (56.00%) (791/1408)
Epoch: 7 | Batch_idx: 20 |  Loss: (1.2361) |  Loss2: (0.0000) | Acc: (54.00%) (1476/2688)
Epoch: 7 | Batch_idx: 30 |  Loss: (1.2284) |  Loss2: (0.0000) | Acc: (55.00%) (2215/3968)
Epoch: 7 | Batch_idx: 40 |  Loss: (1.2146) |  Loss2: (0.0000) | Acc: (56.00%) (2948/5248)
Epoch: 7 | Batch_idx: 50 |  Loss: (1.2044) |  Loss2: (0.0000) | Acc: (56.00%) (3697/6528)
Epoch: 7 | Batch_idx: 60 |  Loss: (1.1977) |  Loss2: (0.0000) | Acc: (56.00%) (4438/7808)
Epoch: 7 | Batch_idx: 70 |  Loss: (1.1946) |  Loss2: (0.0000) | Acc: (57.00%) (5181/9088)
Epoch: 7 | Batch_idx: 80 |  Loss: (1.1952) |  Loss2: (0.0000) | Acc: (57.00%) (5914/10368)
Epoch: 7 | Batch_idx: 90 |  Loss: (1.1912) |  Loss2: (0.0000) | Acc: (57.00%) (6654/11648)
Epoch: 7 | Batch_idx: 100 |  Loss: (1.1862) |  Loss2: (0.0000) | Acc: (57.00%) (7423/12928)
Epoch: 7 | Batch_idx: 110 |  Loss: (1.1855) |  Loss2: (0.0000) | Acc: (57.00%) (8156/14208)
Epoch: 7 | Batch_idx: 120 |  Loss: (1.1841) |  Loss2: (0.0000) | Acc: (57.00%) (8896/15488)
Epoch: 7 | Batch_idx: 130 |  Loss: (1.1851) |  Loss2: (0.0000) | Acc: (57.00%) (9632/16768)
Epoch: 7 | Batch_idx: 140 |  Loss: (1.1854) |  Loss2: (0.0000) | Acc: (57.00%) (10358/18048)
Epoch: 7 | Batch_idx: 150 |  Loss: (1.1824) |  Loss2: (0.0000) | Acc: (57.00%) (11120/19328)
Epoch: 7 | Batch_idx: 160 |  Loss: (1.1797) |  Loss2: (0.0000) | Acc: (57.00%) (11886/20608)
Epoch: 7 | Batch_idx: 170 |  Loss: (1.1793) |  Loss2: (0.0000) | Acc: (57.00%) (12621/21888)
Epoch: 7 | Batch_idx: 180 |  Loss: (1.1804) |  Loss2: (0.0000) | Acc: (57.00%) (13364/23168)
Epoch: 7 | Batch_idx: 190 |  Loss: (1.1803) |  Loss2: (0.0000) | Acc: (57.00%) (14111/24448)
Epoch: 7 | Batch_idx: 200 |  Loss: (1.1800) |  Loss2: (0.0000) | Acc: (57.00%) (14869/25728)
Epoch: 7 | Batch_idx: 210 |  Loss: (1.1769) |  Loss2: (0.0000) | Acc: (57.00%) (15651/27008)
Epoch: 7 | Batch_idx: 220 |  Loss: (1.1760) |  Loss2: (0.0000) | Acc: (58.00%) (16408/28288)
Epoch: 7 | Batch_idx: 230 |  Loss: (1.1754) |  Loss2: (0.0000) | Acc: (58.00%) (17161/29568)
Epoch: 7 | Batch_idx: 240 |  Loss: (1.1733) |  Loss2: (0.0000) | Acc: (58.00%) (17928/30848)
Epoch: 7 | Batch_idx: 250 |  Loss: (1.1717) |  Loss2: (0.0000) | Acc: (58.00%) (18678/32128)
Epoch: 7 | Batch_idx: 260 |  Loss: (1.1694) |  Loss2: (0.0000) | Acc: (58.00%) (19481/33408)
Epoch: 7 | Batch_idx: 270 |  Loss: (1.1690) |  Loss2: (0.0000) | Acc: (58.00%) (20245/34688)
Epoch: 7 | Batch_idx: 280 |  Loss: (1.1665) |  Loss2: (0.0000) | Acc: (58.00%) (21037/35968)
Epoch: 7 | Batch_idx: 290 |  Loss: (1.1636) |  Loss2: (0.0000) | Acc: (58.00%) (21845/37248)
Epoch: 7 | Batch_idx: 300 |  Loss: (1.1615) |  Loss2: (0.0000) | Acc: (58.00%) (22609/38528)
Epoch: 7 | Batch_idx: 310 |  Loss: (1.1604) |  Loss2: (0.0000) | Acc: (58.00%) (23361/39808)
Epoch: 7 | Batch_idx: 320 |  Loss: (1.1591) |  Loss2: (0.0000) | Acc: (58.00%) (24124/41088)
Epoch: 7 | Batch_idx: 330 |  Loss: (1.1575) |  Loss2: (0.0000) | Acc: (58.00%) (24883/42368)
Epoch: 7 | Batch_idx: 340 |  Loss: (1.1568) |  Loss2: (0.0000) | Acc: (58.00%) (25642/43648)
Epoch: 7 | Batch_idx: 350 |  Loss: (1.1562) |  Loss2: (0.0000) | Acc: (58.00%) (26394/44928)
Epoch: 7 | Batch_idx: 360 |  Loss: (1.1541) |  Loss2: (0.0000) | Acc: (58.00%) (27157/46208)
Epoch: 7 | Batch_idx: 370 |  Loss: (1.1525) |  Loss2: (0.0000) | Acc: (58.00%) (27952/47488)
Epoch: 7 | Batch_idx: 380 |  Loss: (1.1501) |  Loss2: (0.0000) | Acc: (58.00%) (28769/48768)
Epoch: 7 | Batch_idx: 390 |  Loss: (1.1489) |  Loss2: (0.0000) | Acc: (59.00%) (29524/50000)
# TEST : Loss: (1.0961) | Acc: (60.00%) (6044/10000)
percent tensor([0.4758, 0.4636, 0.4721, 0.4786, 0.4696, 0.4814, 0.4627, 0.4695, 0.4677,
        0.4666, 0.4678, 0.4676, 0.4693, 0.4669, 0.4688, 0.4743],
       device='cuda:0') torch.Size([16])
percent tensor([0.5075, 0.5099, 0.5084, 0.5067, 0.5102, 0.5088, 0.5099, 0.5087, 0.5076,
        0.5083, 0.5074, 0.5085, 0.5064, 0.5098, 0.5096, 0.5070],
       device='cuda:0') torch.Size([16])
percent tensor([0.5020, 0.4895, 0.5204, 0.5118, 0.5195, 0.5093, 0.5009, 0.5160, 0.5006,
        0.4986, 0.4923, 0.5156, 0.4960, 0.4892, 0.5020, 0.5027],
       device='cuda:0') torch.Size([16])
percent tensor([0.5101, 0.5050, 0.5140, 0.5154, 0.5141, 0.5123, 0.5086, 0.5145, 0.5086,
        0.5060, 0.5037, 0.5114, 0.5049, 0.5073, 0.5104, 0.5108],
       device='cuda:0') torch.Size([16])
percent tensor([0.5045, 0.4957, 0.5173, 0.5197, 0.5149, 0.5100, 0.5036, 0.5144, 0.5029,
        0.4997, 0.4979, 0.5134, 0.4998, 0.5005, 0.5039, 0.5050],
       device='cuda:0') torch.Size([16])
percent tensor([0.4913, 0.4871, 0.5010, 0.5025, 0.4990, 0.4984, 0.4899, 0.4948, 0.4890,
        0.4866, 0.4845, 0.4991, 0.4845, 0.4874, 0.4917, 0.4880],
       device='cuda:0') torch.Size([16])
percent tensor([0.5126, 0.5098, 0.5359, 0.5393, 0.5352, 0.5228, 0.5117, 0.5341, 0.5124,
        0.5172, 0.5126, 0.5298, 0.5116, 0.5106, 0.5162, 0.5135],
       device='cuda:0') torch.Size([16])
percent tensor([0.7883, 0.7412, 0.8449, 0.8669, 0.8506, 0.8311, 0.8077, 0.9144, 0.7757,
        0.8137, 0.7977, 0.8142, 0.7746, 0.7507, 0.8119, 0.9089],
       device='cuda:0') torch.Size([16])
Epoch: 8 | Batch_idx: 0 |  Loss: (1.1344) |  Loss2: (0.0000) | Acc: (57.00%) (73/128)
Epoch: 8 | Batch_idx: 10 |  Loss: (1.0774) |  Loss2: (0.0000) | Acc: (60.00%) (851/1408)
Epoch: 8 | Batch_idx: 20 |  Loss: (1.0656) |  Loss2: (0.0000) | Acc: (61.00%) (1662/2688)
Epoch: 8 | Batch_idx: 30 |  Loss: (1.0532) |  Loss2: (0.0000) | Acc: (63.00%) (2500/3968)
Epoch: 8 | Batch_idx: 40 |  Loss: (1.0478) |  Loss2: (0.0000) | Acc: (63.00%) (3310/5248)
Epoch: 8 | Batch_idx: 50 |  Loss: (1.0516) |  Loss2: (0.0000) | Acc: (62.00%) (4103/6528)
Epoch: 8 | Batch_idx: 60 |  Loss: (1.0633) |  Loss2: (0.0000) | Acc: (62.00%) (4867/7808)
Epoch: 8 | Batch_idx: 70 |  Loss: (1.0654) |  Loss2: (0.0000) | Acc: (62.00%) (5665/9088)
Epoch: 8 | Batch_idx: 80 |  Loss: (1.0642) |  Loss2: (0.0000) | Acc: (62.00%) (6460/10368)
Epoch: 8 | Batch_idx: 90 |  Loss: (1.0610) |  Loss2: (0.0000) | Acc: (62.00%) (7287/11648)
Epoch: 8 | Batch_idx: 100 |  Loss: (1.0597) |  Loss2: (0.0000) | Acc: (62.00%) (8087/12928)
Epoch: 8 | Batch_idx: 110 |  Loss: (1.0643) |  Loss2: (0.0000) | Acc: (62.00%) (8864/14208)
Epoch: 8 | Batch_idx: 120 |  Loss: (1.0615) |  Loss2: (0.0000) | Acc: (62.00%) (9655/15488)
Epoch: 8 | Batch_idx: 130 |  Loss: (1.0604) |  Loss2: (0.0000) | Acc: (62.00%) (10462/16768)
Epoch: 8 | Batch_idx: 140 |  Loss: (1.0618) |  Loss2: (0.0000) | Acc: (62.00%) (11247/18048)
Epoch: 8 | Batch_idx: 150 |  Loss: (1.0628) |  Loss2: (0.0000) | Acc: (62.00%) (12023/19328)
Epoch: 8 | Batch_idx: 160 |  Loss: (1.0610) |  Loss2: (0.0000) | Acc: (62.00%) (12815/20608)
Epoch: 8 | Batch_idx: 170 |  Loss: (1.0589) |  Loss2: (0.0000) | Acc: (62.00%) (13647/21888)
Epoch: 8 | Batch_idx: 180 |  Loss: (1.0587) |  Loss2: (0.0000) | Acc: (62.00%) (14447/23168)
Epoch: 8 | Batch_idx: 190 |  Loss: (1.0579) |  Loss2: (0.0000) | Acc: (62.00%) (15267/24448)
Epoch: 8 | Batch_idx: 200 |  Loss: (1.0596) |  Loss2: (0.0000) | Acc: (62.00%) (16051/25728)
Epoch: 8 | Batch_idx: 210 |  Loss: (1.0587) |  Loss2: (0.0000) | Acc: (62.00%) (16855/27008)
Epoch: 8 | Batch_idx: 220 |  Loss: (1.0564) |  Loss2: (0.0000) | Acc: (62.00%) (17668/28288)
Epoch: 8 | Batch_idx: 230 |  Loss: (1.0563) |  Loss2: (0.0000) | Acc: (62.00%) (18454/29568)
Epoch: 8 | Batch_idx: 240 |  Loss: (1.0552) |  Loss2: (0.0000) | Acc: (62.00%) (19250/30848)
Epoch: 8 | Batch_idx: 250 |  Loss: (1.0549) |  Loss2: (0.0000) | Acc: (62.00%) (20060/32128)
Epoch: 8 | Batch_idx: 260 |  Loss: (1.0540) |  Loss2: (0.0000) | Acc: (62.00%) (20873/33408)
Epoch: 8 | Batch_idx: 270 |  Loss: (1.0541) |  Loss2: (0.0000) | Acc: (62.00%) (21663/34688)
Epoch: 8 | Batch_idx: 280 |  Loss: (1.0538) |  Loss2: (0.0000) | Acc: (62.00%) (22454/35968)
Epoch: 8 | Batch_idx: 290 |  Loss: (1.0521) |  Loss2: (0.0000) | Acc: (62.00%) (23284/37248)
Epoch: 8 | Batch_idx: 300 |  Loss: (1.0521) |  Loss2: (0.0000) | Acc: (62.00%) (24088/38528)
Epoch: 8 | Batch_idx: 310 |  Loss: (1.0497) |  Loss2: (0.0000) | Acc: (62.00%) (24931/39808)
Epoch: 8 | Batch_idx: 320 |  Loss: (1.0492) |  Loss2: (0.0000) | Acc: (62.00%) (25727/41088)
Epoch: 8 | Batch_idx: 330 |  Loss: (1.0497) |  Loss2: (0.0000) | Acc: (62.00%) (26534/42368)
Epoch: 8 | Batch_idx: 340 |  Loss: (1.0493) |  Loss2: (0.0000) | Acc: (62.00%) (27336/43648)
Epoch: 8 | Batch_idx: 350 |  Loss: (1.0490) |  Loss2: (0.0000) | Acc: (62.00%) (28137/44928)
Epoch: 8 | Batch_idx: 360 |  Loss: (1.0499) |  Loss2: (0.0000) | Acc: (62.00%) (28924/46208)
Epoch: 8 | Batch_idx: 370 |  Loss: (1.0496) |  Loss2: (0.0000) | Acc: (62.00%) (29738/47488)
Epoch: 8 | Batch_idx: 380 |  Loss: (1.0492) |  Loss2: (0.0000) | Acc: (62.00%) (30537/48768)
Epoch: 8 | Batch_idx: 390 |  Loss: (1.0487) |  Loss2: (0.0000) | Acc: (62.00%) (31309/50000)
# TEST : Loss: (1.0778) | Acc: (61.00%) (6133/10000)
percent tensor([0.4744, 0.4638, 0.4732, 0.4787, 0.4705, 0.4803, 0.4632, 0.4698, 0.4670,
        0.4669, 0.4664, 0.4684, 0.4679, 0.4675, 0.4687, 0.4731],
       device='cuda:0') torch.Size([16])
percent tensor([0.5074, 0.5093, 0.5083, 0.5067, 0.5101, 0.5087, 0.5093, 0.5089, 0.5072,
        0.5080, 0.5072, 0.5079, 0.5064, 0.5092, 0.5091, 0.5070],
       device='cuda:0') torch.Size([16])
percent tensor([0.5028, 0.4889, 0.5193, 0.5120, 0.5187, 0.5094, 0.4993, 0.5154, 0.5007,
        0.4970, 0.4921, 0.5138, 0.4954, 0.4892, 0.5017, 0.5034],
       device='cuda:0') torch.Size([16])
percent tensor([0.5108, 0.5048, 0.5147, 0.5155, 0.5149, 0.5130, 0.5093, 0.5147, 0.5093,
        0.5060, 0.5045, 0.5113, 0.5048, 0.5075, 0.5104, 0.5109],
       device='cuda:0') torch.Size([16])
percent tensor([0.5075, 0.4983, 0.5174, 0.5198, 0.5155, 0.5123, 0.5071, 0.5146, 0.5046,
        0.5020, 0.5009, 0.5142, 0.5021, 0.5030, 0.5064, 0.5074],
       device='cuda:0') torch.Size([16])
percent tensor([0.4913, 0.4856, 0.4977, 0.5018, 0.4985, 0.5000, 0.4889, 0.4943, 0.4883,
        0.4852, 0.4824, 0.4951, 0.4836, 0.4849, 0.4906, 0.4892],
       device='cuda:0') torch.Size([16])
percent tensor([0.5141, 0.5082, 0.5390, 0.5350, 0.5390, 0.5250, 0.5162, 0.5361, 0.5107,
        0.5156, 0.5118, 0.5304, 0.5108, 0.5091, 0.5171, 0.5150],
       device='cuda:0') torch.Size([16])
percent tensor([0.8502, 0.7825, 0.8804, 0.8470, 0.8778, 0.8471, 0.8938, 0.9223, 0.7808,
        0.8627, 0.8193, 0.8589, 0.7991, 0.8193, 0.8426, 0.9319],
       device='cuda:0') torch.Size([16])
False Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=128, out_features=16, bias=False)
True Linear(in_features=16, out_features=2, bias=False)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=128, out_features=16, bias=False)
True Linear(in_features=16, out_features=2, bias=False)
False Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=256, out_features=32, bias=False)
True Linear(in_features=32, out_features=2, bias=False)
False Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=256, out_features=32, bias=False)
True Linear(in_features=32, out_features=2, bias=False)
False Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=512, out_features=64, bias=False)
True Linear(in_features=64, out_features=2, bias=False)
False Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=512, out_features=64, bias=False)
True Linear(in_features=64, out_features=2, bias=False)
False Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1024, out_features=128, bias=False)
True Linear(in_features=128, out_features=2, bias=False)
False Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1024, out_features=128, bias=False)
True Linear(in_features=128, out_features=2, bias=False)
False Linear(in_features=512, out_features=10, bias=True)
Epoch: 9 | Batch_idx: 0 |  Loss: (1.0189) |  Loss2: (0.0000) | Acc: (62.00%) (80/128)
Epoch: 9 | Batch_idx: 10 |  Loss: (1.0589) |  Loss2: (0.0000) | Acc: (61.00%) (872/1408)
Epoch: 9 | Batch_idx: 20 |  Loss: (1.1284) |  Loss2: (0.0000) | Acc: (59.00%) (1602/2688)
Epoch: 9 | Batch_idx: 30 |  Loss: (1.1555) |  Loss2: (0.0000) | Acc: (58.00%) (2311/3968)
Epoch: 9 | Batch_idx: 40 |  Loss: (1.1736) |  Loss2: (0.0000) | Acc: (57.00%) (3035/5248)
Epoch: 9 | Batch_idx: 50 |  Loss: (1.1756) |  Loss2: (0.0000) | Acc: (57.00%) (3770/6528)
Epoch: 9 | Batch_idx: 60 |  Loss: (1.1818) |  Loss2: (0.0000) | Acc: (57.00%) (4482/7808)
Epoch: 9 | Batch_idx: 70 |  Loss: (1.1844) |  Loss2: (0.0000) | Acc: (57.00%) (5202/9088)
Epoch: 9 | Batch_idx: 80 |  Loss: (1.1866) |  Loss2: (0.0000) | Acc: (57.00%) (5937/10368)
Epoch: 9 | Batch_idx: 90 |  Loss: (1.1821) |  Loss2: (0.0000) | Acc: (57.00%) (6681/11648)
Epoch: 9 | Batch_idx: 100 |  Loss: (1.1808) |  Loss2: (0.0000) | Acc: (57.00%) (7402/12928)
Epoch: 9 | Batch_idx: 110 |  Loss: (1.1722) |  Loss2: (0.0000) | Acc: (57.00%) (8191/14208)
Epoch: 9 | Batch_idx: 120 |  Loss: (1.1706) |  Loss2: (0.0000) | Acc: (57.00%) (8968/15488)
Epoch: 9 | Batch_idx: 130 |  Loss: (1.1639) |  Loss2: (0.0000) | Acc: (58.00%) (9763/16768)
Epoch: 9 | Batch_idx: 140 |  Loss: (1.1586) |  Loss2: (0.0000) | Acc: (58.00%) (10534/18048)
Epoch: 9 | Batch_idx: 150 |  Loss: (1.1545) |  Loss2: (0.0000) | Acc: (58.00%) (11318/19328)
Epoch: 9 | Batch_idx: 160 |  Loss: (1.1500) |  Loss2: (0.0000) | Acc: (58.00%) (12088/20608)
Epoch: 9 | Batch_idx: 170 |  Loss: (1.1435) |  Loss2: (0.0000) | Acc: (59.00%) (12914/21888)
Epoch: 9 | Batch_idx: 180 |  Loss: (1.1431) |  Loss2: (0.0000) | Acc: (59.00%) (13670/23168)
Epoch: 9 | Batch_idx: 190 |  Loss: (1.1416) |  Loss2: (0.0000) | Acc: (58.00%) (14408/24448)
Epoch: 9 | Batch_idx: 200 |  Loss: (1.1379) |  Loss2: (0.0000) | Acc: (59.00%) (15205/25728)
Epoch: 9 | Batch_idx: 210 |  Loss: (1.1357) |  Loss2: (0.0000) | Acc: (59.00%) (15978/27008)
Epoch: 9 | Batch_idx: 220 |  Loss: (1.1320) |  Loss2: (0.0000) | Acc: (59.00%) (16759/28288)
Epoch: 9 | Batch_idx: 230 |  Loss: (1.1296) |  Loss2: (0.0000) | Acc: (59.00%) (17553/29568)
Epoch: 9 | Batch_idx: 240 |  Loss: (1.1265) |  Loss2: (0.0000) | Acc: (59.00%) (18346/30848)
Epoch: 9 | Batch_idx: 250 |  Loss: (1.1246) |  Loss2: (0.0000) | Acc: (59.00%) (19133/32128)
Epoch: 9 | Batch_idx: 260 |  Loss: (1.1221) |  Loss2: (0.0000) | Acc: (59.00%) (19918/33408)
Epoch: 9 | Batch_idx: 270 |  Loss: (1.1192) |  Loss2: (0.0000) | Acc: (59.00%) (20716/34688)
Epoch: 9 | Batch_idx: 280 |  Loss: (1.1163) |  Loss2: (0.0000) | Acc: (59.00%) (21528/35968)
Epoch: 9 | Batch_idx: 290 |  Loss: (1.1139) |  Loss2: (0.0000) | Acc: (59.00%) (22310/37248)
Epoch: 9 | Batch_idx: 300 |  Loss: (1.1116) |  Loss2: (0.0000) | Acc: (59.00%) (23099/38528)
Epoch: 9 | Batch_idx: 310 |  Loss: (1.1103) |  Loss2: (0.0000) | Acc: (59.00%) (23871/39808)
Epoch: 9 | Batch_idx: 320 |  Loss: (1.1095) |  Loss2: (0.0000) | Acc: (59.00%) (24652/41088)
Epoch: 9 | Batch_idx: 330 |  Loss: (1.1065) |  Loss2: (0.0000) | Acc: (60.00%) (25490/42368)
Epoch: 9 | Batch_idx: 340 |  Loss: (1.1049) |  Loss2: (0.0000) | Acc: (60.00%) (26289/43648)
Epoch: 9 | Batch_idx: 350 |  Loss: (1.1021) |  Loss2: (0.0000) | Acc: (60.00%) (27114/44928)
Epoch: 9 | Batch_idx: 360 |  Loss: (1.1007) |  Loss2: (0.0000) | Acc: (60.00%) (27905/46208)
Epoch: 9 | Batch_idx: 370 |  Loss: (1.0993) |  Loss2: (0.0000) | Acc: (60.00%) (28705/47488)
Epoch: 9 | Batch_idx: 380 |  Loss: (1.0975) |  Loss2: (0.0000) | Acc: (60.00%) (29516/48768)
Epoch: 9 | Batch_idx: 390 |  Loss: (1.0957) |  Loss2: (0.0000) | Acc: (60.00%) (30296/50000)
# TEST : Loss: (1.0355) | Acc: (62.00%) (6280/10000)
percent tensor([0.4899, 0.4841, 0.4888, 0.4920, 0.4875, 0.4935, 0.4835, 0.4872, 0.4852,
        0.4865, 0.4857, 0.4869, 0.4869, 0.4850, 0.4879, 0.4896],
       device='cuda:0') torch.Size([16])
percent tensor([0.5013, 0.5010, 0.5012, 0.5009, 0.5015, 0.5028, 0.5010, 0.5011, 0.5010,
        0.5008, 0.5010, 0.5008, 0.5007, 0.5013, 0.5016, 0.5010],
       device='cuda:0') torch.Size([16])
percent tensor([0.5013, 0.4775, 0.5170, 0.5074, 0.5153, 0.5070, 0.4920, 0.5120, 0.4981,
        0.4899, 0.4855, 0.5112, 0.4939, 0.4756, 0.4957, 0.5002],
       device='cuda:0') torch.Size([16])
percent tensor([0.5120, 0.5124, 0.5110, 0.5117, 0.5114, 0.5118, 0.5131, 0.5115, 0.5122,
        0.5121, 0.5113, 0.5115, 0.5114, 0.5128, 0.5132, 0.5125],
       device='cuda:0') torch.Size([16])
percent tensor([0.5092, 0.5049, 0.5203, 0.5206, 0.5188, 0.5143, 0.5142, 0.5185, 0.5066,
        0.5088, 0.5049, 0.5180, 0.5064, 0.5060, 0.5103, 0.5107],
       device='cuda:0') torch.Size([16])
percent tensor([0.4957, 0.4890, 0.5031, 0.5052, 0.5042, 0.5010, 0.4938, 0.4987, 0.4908,
        0.4895, 0.4859, 0.5014, 0.4879, 0.4857, 0.4928, 0.4910],
       device='cuda:0') torch.Size([16])
percent tensor([0.5095, 0.5054, 0.5560, 0.5410, 0.5554, 0.5142, 0.5203, 0.5567, 0.5039,
        0.5170, 0.5059, 0.5379, 0.4987, 0.5015, 0.5166, 0.5115],
       device='cuda:0') torch.Size([16])
percent tensor([0.8922, 0.8550, 0.9478, 0.9086, 0.9455, 0.9176, 0.9496, 0.9790, 0.8584,
        0.9170, 0.8910, 0.9219, 0.8496, 0.8726, 0.9173, 0.9689],
       device='cuda:0') torch.Size([16])
Epoch: 10 | Batch_idx: 0 |  Loss: (0.9557) |  Loss2: (0.0000) | Acc: (65.00%) (84/128)
Epoch: 10 | Batch_idx: 10 |  Loss: (1.0350) |  Loss2: (0.0000) | Acc: (62.00%) (885/1408)
Epoch: 10 | Batch_idx: 20 |  Loss: (1.0133) |  Loss2: (0.0000) | Acc: (63.00%) (1707/2688)
Epoch: 10 | Batch_idx: 30 |  Loss: (1.0099) |  Loss2: (0.0000) | Acc: (63.00%) (2536/3968)
Epoch: 10 | Batch_idx: 40 |  Loss: (1.0080) |  Loss2: (0.0000) | Acc: (64.00%) (3370/5248)
Epoch: 10 | Batch_idx: 50 |  Loss: (1.0092) |  Loss2: (0.0000) | Acc: (63.00%) (4173/6528)
Epoch: 10 | Batch_idx: 60 |  Loss: (1.0122) |  Loss2: (0.0000) | Acc: (63.00%) (4963/7808)
Epoch: 10 | Batch_idx: 70 |  Loss: (1.0192) |  Loss2: (0.0000) | Acc: (63.00%) (5766/9088)
Epoch: 10 | Batch_idx: 80 |  Loss: (1.0241) |  Loss2: (0.0000) | Acc: (63.00%) (6556/10368)
Epoch: 10 | Batch_idx: 90 |  Loss: (1.0294) |  Loss2: (0.0000) | Acc: (63.00%) (7355/11648)
Epoch: 10 | Batch_idx: 100 |  Loss: (1.0268) |  Loss2: (0.0000) | Acc: (63.00%) (8163/12928)
Epoch: 10 | Batch_idx: 110 |  Loss: (1.0256) |  Loss2: (0.0000) | Acc: (63.00%) (8971/14208)
Epoch: 10 | Batch_idx: 120 |  Loss: (1.0268) |  Loss2: (0.0000) | Acc: (63.00%) (9788/15488)
Epoch: 10 | Batch_idx: 130 |  Loss: (1.0251) |  Loss2: (0.0000) | Acc: (63.00%) (10598/16768)
Epoch: 10 | Batch_idx: 140 |  Loss: (1.0269) |  Loss2: (0.0000) | Acc: (63.00%) (11387/18048)
Epoch: 10 | Batch_idx: 150 |  Loss: (1.0270) |  Loss2: (0.0000) | Acc: (63.00%) (12196/19328)
Epoch: 10 | Batch_idx: 160 |  Loss: (1.0271) |  Loss2: (0.0000) | Acc: (63.00%) (12998/20608)
Epoch: 10 | Batch_idx: 170 |  Loss: (1.0269) |  Loss2: (0.0000) | Acc: (63.00%) (13817/21888)
Epoch: 10 | Batch_idx: 180 |  Loss: (1.0239) |  Loss2: (0.0000) | Acc: (63.00%) (14654/23168)
Epoch: 10 | Batch_idx: 190 |  Loss: (1.0239) |  Loss2: (0.0000) | Acc: (63.00%) (15470/24448)
Epoch: 10 | Batch_idx: 200 |  Loss: (1.0224) |  Loss2: (0.0000) | Acc: (63.00%) (16287/25728)
Epoch: 10 | Batch_idx: 210 |  Loss: (1.0213) |  Loss2: (0.0000) | Acc: (63.00%) (17107/27008)
Epoch: 10 | Batch_idx: 220 |  Loss: (1.0216) |  Loss2: (0.0000) | Acc: (63.00%) (17900/28288)
Epoch: 10 | Batch_idx: 230 |  Loss: (1.0225) |  Loss2: (0.0000) | Acc: (63.00%) (18695/29568)
Epoch: 10 | Batch_idx: 240 |  Loss: (1.0244) |  Loss2: (0.0000) | Acc: (63.00%) (19476/30848)
Epoch: 10 | Batch_idx: 250 |  Loss: (1.0236) |  Loss2: (0.0000) | Acc: (63.00%) (20285/32128)
Epoch: 10 | Batch_idx: 260 |  Loss: (1.0238) |  Loss2: (0.0000) | Acc: (63.00%) (21089/33408)
Epoch: 10 | Batch_idx: 270 |  Loss: (1.0234) |  Loss2: (0.0000) | Acc: (63.00%) (21898/34688)
Epoch: 10 | Batch_idx: 280 |  Loss: (1.0229) |  Loss2: (0.0000) | Acc: (63.00%) (22686/35968)
Epoch: 10 | Batch_idx: 290 |  Loss: (1.0219) |  Loss2: (0.0000) | Acc: (63.00%) (23502/37248)
Epoch: 10 | Batch_idx: 300 |  Loss: (1.0208) |  Loss2: (0.0000) | Acc: (63.00%) (24352/38528)
Epoch: 10 | Batch_idx: 310 |  Loss: (1.0191) |  Loss2: (0.0000) | Acc: (63.00%) (25179/39808)
Epoch: 10 | Batch_idx: 320 |  Loss: (1.0181) |  Loss2: (0.0000) | Acc: (63.00%) (26010/41088)
Epoch: 10 | Batch_idx: 330 |  Loss: (1.0174) |  Loss2: (0.0000) | Acc: (63.00%) (26845/42368)
Epoch: 10 | Batch_idx: 340 |  Loss: (1.0184) |  Loss2: (0.0000) | Acc: (63.00%) (27647/43648)
Epoch: 10 | Batch_idx: 350 |  Loss: (1.0182) |  Loss2: (0.0000) | Acc: (63.00%) (28461/44928)
Epoch: 10 | Batch_idx: 360 |  Loss: (1.0170) |  Loss2: (0.0000) | Acc: (63.00%) (29287/46208)
Epoch: 10 | Batch_idx: 370 |  Loss: (1.0162) |  Loss2: (0.0000) | Acc: (63.00%) (30120/47488)
Epoch: 10 | Batch_idx: 380 |  Loss: (1.0156) |  Loss2: (0.0000) | Acc: (63.00%) (30943/48768)
Epoch: 10 | Batch_idx: 390 |  Loss: (1.0150) |  Loss2: (0.0000) | Acc: (63.00%) (31730/50000)
=> saving checkpoint 'drive/app/torch/save_Schedule/checkpoint_010.pth.tar'
# TEST : Loss: (1.0056) | Acc: (63.00%) (6396/10000)
percent tensor([0.4963, 0.4932, 0.4961, 0.4983, 0.4948, 0.4991, 0.4925, 0.4950, 0.4928,
        0.4950, 0.4936, 0.4947, 0.4946, 0.4932, 0.4962, 0.4967],
       device='cuda:0') torch.Size([16])
percent tensor([0.4999, 0.4986, 0.4999, 0.4997, 0.4997, 0.5027, 0.4987, 0.4993, 0.4995,
        0.4988, 0.4995, 0.4992, 0.4991, 0.4991, 0.4998, 0.4995],
       device='cuda:0') torch.Size([16])
percent tensor([0.5014, 0.4724, 0.5174, 0.5061, 0.5166, 0.5080, 0.4895, 0.5128, 0.4982,
        0.4860, 0.4822, 0.5111, 0.4924, 0.4701, 0.4935, 0.4998],
       device='cuda:0') torch.Size([16])
percent tensor([0.5196, 0.5233, 0.5158, 0.5172, 0.5163, 0.5180, 0.5220, 0.5168, 0.5207,
        0.5217, 0.5216, 0.5182, 0.5212, 0.5229, 0.5219, 0.5205],
       device='cuda:0') torch.Size([16])
percent tensor([0.5152, 0.5121, 0.5232, 0.5244, 0.5220, 0.5208, 0.5209, 0.5224, 0.5117,
        0.5142, 0.5123, 0.5227, 0.5131, 0.5130, 0.5163, 0.5178],
       device='cuda:0') torch.Size([16])
percent tensor([0.4939, 0.4881, 0.4990, 0.5035, 0.4995, 0.4997, 0.4909, 0.4917, 0.4902,
        0.4886, 0.4854, 0.5003, 0.4867, 0.4860, 0.4897, 0.4863],
       device='cuda:0') torch.Size([16])
percent tensor([0.5082, 0.5063, 0.5628, 0.5456, 0.5643, 0.5079, 0.5256, 0.5658, 0.5036,
        0.5210, 0.5073, 0.5437, 0.4958, 0.5014, 0.5212, 0.5122],
       device='cuda:0') torch.Size([16])
percent tensor([0.9449, 0.9021, 0.9741, 0.9496, 0.9759, 0.9605, 0.9756, 0.9922, 0.9140,
        0.9569, 0.9370, 0.9587, 0.9111, 0.9207, 0.9567, 0.9895],
       device='cuda:0') torch.Size([16])
Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 3, 3, 3]) tensor(166.9304, device='cuda:0')
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(775.4091, device='cuda:0')
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(773.1780, device='cuda:0')
Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([128, 64, 3, 3]) tensor(1530.0420, device='cuda:0')
Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([128, 64, 1, 1]) tensor(513.7715, device='cuda:0')
Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([128, 128, 3, 3]) tensor(2166.5889, device='cuda:0')
Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([256, 128, 3, 3]) tensor(4329.4111, device='cuda:0')
Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([256, 128, 1, 1]) tensor(1450.6704, device='cuda:0')
Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([256, 256, 3, 3]) tensor(6107.3857, device='cuda:0')
Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([512, 256, 3, 3]) tensor(12234.0342, device='cuda:0')
Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([512, 256, 1, 1]) tensor(4083.8977, device='cuda:0')
Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([512, 512, 3, 3]) tensor(17275.8926, device='cuda:0')
Epoch: 11 | Batch_idx: 0 |  Loss: (0.9478) |  Loss2: (0.0000) | Acc: (67.00%) (87/128)
Epoch: 11 | Batch_idx: 10 |  Loss: (0.9946) |  Loss2: (0.0000) | Acc: (64.00%) (902/1408)
Epoch: 11 | Batch_idx: 20 |  Loss: (0.9935) |  Loss2: (0.0000) | Acc: (64.00%) (1726/2688)
Epoch: 11 | Batch_idx: 30 |  Loss: (0.9875) |  Loss2: (0.0000) | Acc: (64.00%) (2550/3968)
Epoch: 11 | Batch_idx: 40 |  Loss: (0.9880) |  Loss2: (0.0000) | Acc: (63.00%) (3348/5248)
Epoch: 11 | Batch_idx: 50 |  Loss: (0.9848) |  Loss2: (0.0000) | Acc: (64.00%) (4195/6528)
Epoch: 11 | Batch_idx: 60 |  Loss: (0.9867) |  Loss2: (0.0000) | Acc: (64.00%) (5013/7808)
Epoch: 11 | Batch_idx: 70 |  Loss: (0.9929) |  Loss2: (0.0000) | Acc: (64.00%) (5827/9088)
Epoch: 11 | Batch_idx: 80 |  Loss: (0.9926) |  Loss2: (0.0000) | Acc: (64.00%) (6656/10368)
Epoch: 11 | Batch_idx: 90 |  Loss: (0.9918) |  Loss2: (0.0000) | Acc: (64.00%) (7480/11648)
Epoch: 11 | Batch_idx: 100 |  Loss: (0.9972) |  Loss2: (0.0000) | Acc: (64.00%) (8302/12928)
Epoch: 11 | Batch_idx: 110 |  Loss: (0.9985) |  Loss2: (0.0000) | Acc: (64.00%) (9111/14208)
Epoch: 11 | Batch_idx: 120 |  Loss: (1.0016) |  Loss2: (0.0000) | Acc: (63.00%) (9905/15488)
Epoch: 11 | Batch_idx: 130 |  Loss: (1.0012) |  Loss2: (0.0000) | Acc: (63.00%) (10725/16768)
Epoch: 11 | Batch_idx: 140 |  Loss: (1.0017) |  Loss2: (0.0000) | Acc: (63.00%) (11527/18048)
Epoch: 11 | Batch_idx: 150 |  Loss: (1.0037) |  Loss2: (0.0000) | Acc: (63.00%) (12337/19328)
Epoch: 11 | Batch_idx: 160 |  Loss: (1.0033) |  Loss2: (0.0000) | Acc: (63.00%) (13167/20608)
Epoch: 11 | Batch_idx: 170 |  Loss: (1.0003) |  Loss2: (0.0000) | Acc: (63.00%) (14007/21888)
Epoch: 11 | Batch_idx: 180 |  Loss: (1.0018) |  Loss2: (0.0000) | Acc: (63.00%) (14790/23168)
Epoch: 11 | Batch_idx: 190 |  Loss: (0.9996) |  Loss2: (0.0000) | Acc: (63.00%) (15622/24448)
Epoch: 11 | Batch_idx: 200 |  Loss: (0.9992) |  Loss2: (0.0000) | Acc: (63.00%) (16441/25728)
Epoch: 11 | Batch_idx: 210 |  Loss: (1.0005) |  Loss2: (0.0000) | Acc: (63.00%) (17244/27008)
Epoch: 11 | Batch_idx: 220 |  Loss: (1.0010) |  Loss2: (0.0000) | Acc: (63.00%) (18069/28288)
Epoch: 11 | Batch_idx: 230 |  Loss: (1.0004) |  Loss2: (0.0000) | Acc: (63.00%) (18883/29568)
Epoch: 11 | Batch_idx: 240 |  Loss: (1.0012) |  Loss2: (0.0000) | Acc: (63.00%) (19700/30848)
Epoch: 11 | Batch_idx: 250 |  Loss: (1.0000) |  Loss2: (0.0000) | Acc: (63.00%) (20543/32128)
Epoch: 11 | Batch_idx: 260 |  Loss: (1.0001) |  Loss2: (0.0000) | Acc: (63.00%) (21345/33408)
Epoch: 11 | Batch_idx: 270 |  Loss: (1.0008) |  Loss2: (0.0000) | Acc: (63.00%) (22144/34688)
Epoch: 11 | Batch_idx: 280 |  Loss: (1.0014) |  Loss2: (0.0000) | Acc: (63.00%) (22937/35968)
Epoch: 11 | Batch_idx: 290 |  Loss: (1.0006) |  Loss2: (0.0000) | Acc: (63.00%) (23775/37248)
Epoch: 11 | Batch_idx: 300 |  Loss: (0.9983) |  Loss2: (0.0000) | Acc: (63.00%) (24635/38528)
Epoch: 11 | Batch_idx: 310 |  Loss: (0.9981) |  Loss2: (0.0000) | Acc: (63.00%) (25438/39808)
Epoch: 11 | Batch_idx: 320 |  Loss: (0.9974) |  Loss2: (0.0000) | Acc: (63.00%) (26273/41088)
Epoch: 11 | Batch_idx: 330 |  Loss: (0.9969) |  Loss2: (0.0000) | Acc: (63.00%) (27101/42368)
Epoch: 11 | Batch_idx: 340 |  Loss: (0.9982) |  Loss2: (0.0000) | Acc: (63.00%) (27887/43648)
Epoch: 11 | Batch_idx: 350 |  Loss: (0.9976) |  Loss2: (0.0000) | Acc: (63.00%) (28739/44928)
Epoch: 11 | Batch_idx: 360 |  Loss: (0.9981) |  Loss2: (0.0000) | Acc: (63.00%) (29537/46208)
Epoch: 11 | Batch_idx: 370 |  Loss: (0.9979) |  Loss2: (0.0000) | Acc: (63.00%) (30351/47488)
Epoch: 11 | Batch_idx: 380 |  Loss: (0.9975) |  Loss2: (0.0000) | Acc: (63.00%) (31158/48768)
Epoch: 11 | Batch_idx: 390 |  Loss: (0.9963) |  Loss2: (0.0000) | Acc: (63.00%) (31991/50000)
# TEST : Loss: (0.9937) | Acc: (64.00%) (6447/10000)
percent tensor([0.4995, 0.4970, 0.5000, 0.5017, 0.4985, 0.5019, 0.4964, 0.4989, 0.4961,
        0.4989, 0.4971, 0.4987, 0.4981, 0.4963, 0.5002, 0.5001],
       device='cuda:0') torch.Size([16])
percent tensor([0.4994, 0.4972, 0.4993, 0.4994, 0.4988, 0.5036, 0.4973, 0.4984, 0.4987,
        0.4976, 0.4988, 0.4983, 0.4982, 0.4979, 0.4992, 0.4990],
       device='cuda:0') torch.Size([16])
percent tensor([0.5030, 0.4691, 0.5206, 0.5073, 0.5199, 0.5111, 0.4885, 0.5158, 0.4997,
        0.4839, 0.4802, 0.5130, 0.4923, 0.4661, 0.4933, 0.5009],
       device='cuda:0') torch.Size([16])
percent tensor([0.5274, 0.5332, 0.5216, 0.5234, 0.5221, 0.5244, 0.5307, 0.5227, 0.5289,
        0.5307, 0.5311, 0.5255, 0.5306, 0.5323, 0.5303, 0.5284],
       device='cuda:0') torch.Size([16])
percent tensor([0.5222, 0.5190, 0.5270, 0.5293, 0.5259, 0.5285, 0.5275, 0.5268, 0.5173,
        0.5196, 0.5199, 0.5279, 0.5204, 0.5203, 0.5225, 0.5251],
       device='cuda:0') torch.Size([16])
percent tensor([0.4939, 0.4879, 0.4969, 0.5042, 0.4967, 0.5001, 0.4898, 0.4867, 0.4908,
        0.4889, 0.4863, 0.5015, 0.4871, 0.4873, 0.4876, 0.4831],
       device='cuda:0') torch.Size([16])
percent tensor([0.5090, 0.5089, 0.5704, 0.5511, 0.5725, 0.5048, 0.5314, 0.5741, 0.5059,
        0.5269, 0.5111, 0.5506, 0.4957, 0.5028, 0.5268, 0.5148],
       device='cuda:0') torch.Size([16])
percent tensor([0.9636, 0.9255, 0.9861, 0.9688, 0.9878, 0.9761, 0.9842, 0.9968, 0.9430,
        0.9731, 0.9585, 0.9743, 0.9391, 0.9416, 0.9738, 0.9947],
       device='cuda:0') torch.Size([16])
True Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=128, out_features=16, bias=False)
False Linear(in_features=16, out_features=2, bias=False)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=128, out_features=16, bias=False)
False Linear(in_features=16, out_features=2, bias=False)
True Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=256, out_features=32, bias=False)
False Linear(in_features=32, out_features=2, bias=False)
True Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=256, out_features=32, bias=False)
False Linear(in_features=32, out_features=2, bias=False)
True Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=512, out_features=64, bias=False)
False Linear(in_features=64, out_features=2, bias=False)
True Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=512, out_features=64, bias=False)
False Linear(in_features=64, out_features=2, bias=False)
True Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1024, out_features=128, bias=False)
False Linear(in_features=128, out_features=2, bias=False)
True Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1024, out_features=128, bias=False)
False Linear(in_features=128, out_features=2, bias=False)
True Linear(in_features=512, out_features=10, bias=True)
Epoch: 12 | Batch_idx: 0 |  Loss: (1.0638) |  Loss2: (0.0000) | Acc: (60.00%) (77/128)
Epoch: 12 | Batch_idx: 10 |  Loss: (0.9850) |  Loss2: (0.0000) | Acc: (63.00%) (897/1408)
Epoch: 12 | Batch_idx: 20 |  Loss: (0.9676) |  Loss2: (0.0000) | Acc: (64.00%) (1744/2688)
Epoch: 12 | Batch_idx: 30 |  Loss: (0.9698) |  Loss2: (0.0000) | Acc: (64.00%) (2572/3968)
Epoch: 12 | Batch_idx: 40 |  Loss: (0.9790) |  Loss2: (0.0000) | Acc: (64.00%) (3396/5248)
Epoch: 12 | Batch_idx: 50 |  Loss: (0.9727) |  Loss2: (0.0000) | Acc: (64.00%) (4234/6528)
Epoch: 12 | Batch_idx: 60 |  Loss: (0.9763) |  Loss2: (0.0000) | Acc: (64.00%) (5042/7808)
Epoch: 12 | Batch_idx: 70 |  Loss: (0.9772) |  Loss2: (0.0000) | Acc: (64.00%) (5860/9088)
Epoch: 12 | Batch_idx: 80 |  Loss: (0.9747) |  Loss2: (0.0000) | Acc: (64.00%) (6704/10368)
Epoch: 12 | Batch_idx: 90 |  Loss: (0.9760) |  Loss2: (0.0000) | Acc: (64.00%) (7541/11648)
Epoch: 12 | Batch_idx: 100 |  Loss: (0.9781) |  Loss2: (0.0000) | Acc: (64.00%) (8352/12928)
Epoch: 12 | Batch_idx: 110 |  Loss: (0.9761) |  Loss2: (0.0000) | Acc: (64.00%) (9183/14208)
Epoch: 12 | Batch_idx: 120 |  Loss: (0.9745) |  Loss2: (0.0000) | Acc: (64.00%) (10030/15488)
Epoch: 12 | Batch_idx: 130 |  Loss: (0.9757) |  Loss2: (0.0000) | Acc: (64.00%) (10861/16768)
Epoch: 12 | Batch_idx: 140 |  Loss: (0.9745) |  Loss2: (0.0000) | Acc: (64.00%) (11685/18048)
Epoch: 12 | Batch_idx: 150 |  Loss: (0.9758) |  Loss2: (0.0000) | Acc: (64.00%) (12513/19328)
Epoch: 12 | Batch_idx: 160 |  Loss: (0.9738) |  Loss2: (0.0000) | Acc: (64.00%) (13352/20608)
Epoch: 12 | Batch_idx: 170 |  Loss: (0.9710) |  Loss2: (0.0000) | Acc: (64.00%) (14207/21888)
Epoch: 12 | Batch_idx: 180 |  Loss: (0.9694) |  Loss2: (0.0000) | Acc: (64.00%) (15045/23168)
Epoch: 12 | Batch_idx: 190 |  Loss: (0.9700) |  Loss2: (0.0000) | Acc: (64.00%) (15873/24448)
Epoch: 12 | Batch_idx: 200 |  Loss: (0.9708) |  Loss2: (0.0000) | Acc: (64.00%) (16704/25728)
Epoch: 12 | Batch_idx: 210 |  Loss: (0.9690) |  Loss2: (0.0000) | Acc: (65.00%) (17566/27008)
Epoch: 12 | Batch_idx: 220 |  Loss: (0.9689) |  Loss2: (0.0000) | Acc: (65.00%) (18416/28288)
Epoch: 12 | Batch_idx: 230 |  Loss: (0.9687) |  Loss2: (0.0000) | Acc: (65.00%) (19269/29568)
Epoch: 12 | Batch_idx: 240 |  Loss: (0.9677) |  Loss2: (0.0000) | Acc: (65.00%) (20103/30848)
Epoch: 12 | Batch_idx: 250 |  Loss: (0.9676) |  Loss2: (0.0000) | Acc: (65.00%) (20945/32128)
Epoch: 12 | Batch_idx: 260 |  Loss: (0.9695) |  Loss2: (0.0000) | Acc: (65.00%) (21762/33408)
Epoch: 12 | Batch_idx: 270 |  Loss: (0.9676) |  Loss2: (0.0000) | Acc: (65.00%) (22625/34688)
Epoch: 12 | Batch_idx: 280 |  Loss: (0.9661) |  Loss2: (0.0000) | Acc: (65.00%) (23475/35968)
Epoch: 12 | Batch_idx: 290 |  Loss: (0.9663) |  Loss2: (0.0000) | Acc: (65.00%) (24310/37248)
Epoch: 12 | Batch_idx: 300 |  Loss: (0.9668) |  Loss2: (0.0000) | Acc: (65.00%) (25151/38528)
Epoch: 12 | Batch_idx: 310 |  Loss: (0.9668) |  Loss2: (0.0000) | Acc: (65.00%) (25983/39808)
Epoch: 12 | Batch_idx: 320 |  Loss: (0.9660) |  Loss2: (0.0000) | Acc: (65.00%) (26817/41088)
Epoch: 12 | Batch_idx: 330 |  Loss: (0.9676) |  Loss2: (0.0000) | Acc: (65.00%) (27647/42368)
Epoch: 12 | Batch_idx: 340 |  Loss: (0.9669) |  Loss2: (0.0000) | Acc: (65.00%) (28489/43648)
Epoch: 12 | Batch_idx: 350 |  Loss: (0.9670) |  Loss2: (0.0000) | Acc: (65.00%) (29321/44928)
Epoch: 12 | Batch_idx: 360 |  Loss: (0.9664) |  Loss2: (0.0000) | Acc: (65.00%) (30161/46208)
Epoch: 12 | Batch_idx: 370 |  Loss: (0.9653) |  Loss2: (0.0000) | Acc: (65.00%) (31009/47488)
Epoch: 12 | Batch_idx: 380 |  Loss: (0.9648) |  Loss2: (0.0000) | Acc: (65.00%) (31853/48768)
Epoch: 12 | Batch_idx: 390 |  Loss: (0.9640) |  Loss2: (0.0000) | Acc: (65.00%) (32680/50000)
# TEST : Loss: (0.9651) | Acc: (65.00%) (6534/10000)
percent tensor([0.4994, 0.4977, 0.5001, 0.5019, 0.4987, 0.5019, 0.4970, 0.4990, 0.4969,
        0.4989, 0.4974, 0.4984, 0.4979, 0.4986, 0.5001, 0.5003],
       device='cuda:0') torch.Size([16])
percent tensor([0.4994, 0.4970, 0.4993, 0.4992, 0.4988, 0.5035, 0.4973, 0.4983, 0.4988,
        0.4975, 0.4988, 0.4984, 0.4981, 0.4984, 0.4991, 0.4989],
       device='cuda:0') torch.Size([16])
percent tensor([0.5018, 0.4710, 0.5197, 0.5049, 0.5199, 0.5136, 0.4921, 0.5155, 0.5012,
        0.4818, 0.4777, 0.5117, 0.4847, 0.4732, 0.4927, 0.5006],
       device='cuda:0') torch.Size([16])
percent tensor([0.5284, 0.5333, 0.5206, 0.5241, 0.5219, 0.5263, 0.5293, 0.5236, 0.5290,
        0.5307, 0.5318, 0.5259, 0.5319, 0.5307, 0.5327, 0.5293],
       device='cuda:0') torch.Size([16])
percent tensor([0.5225, 0.5199, 0.5252, 0.5289, 0.5257, 0.5299, 0.5272, 0.5279, 0.5197,
        0.5183, 0.5213, 0.5278, 0.5204, 0.5226, 0.5258, 0.5255],
       device='cuda:0') torch.Size([16])
percent tensor([0.4930, 0.4933, 0.5012, 0.5077, 0.4991, 0.5026, 0.4953, 0.4875, 0.4966,
        0.4957, 0.4915, 0.5033, 0.4893, 0.4978, 0.4882, 0.4856],
       device='cuda:0') torch.Size([16])
percent tensor([0.5127, 0.5116, 0.5635, 0.5562, 0.5735, 0.5138, 0.5380, 0.5720, 0.5115,
        0.5284, 0.5141, 0.5524, 0.5001, 0.5055, 0.5329, 0.5157],
       device='cuda:0') torch.Size([16])
percent tensor([0.9664, 0.9174, 0.9773, 0.9796, 0.9881, 0.9848, 0.9692, 0.9958, 0.9257,
        0.9632, 0.9515, 0.9760, 0.9241, 0.9304, 0.9833, 0.9905],
       device='cuda:0') torch.Size([16])
Epoch: 13 | Batch_idx: 0 |  Loss: (1.1447) |  Loss2: (0.0000) | Acc: (60.00%) (77/128)
Epoch: 13 | Batch_idx: 10 |  Loss: (0.9450) |  Loss2: (0.0000) | Acc: (67.00%) (946/1408)
Epoch: 13 | Batch_idx: 20 |  Loss: (0.9158) |  Loss2: (0.0000) | Acc: (67.00%) (1820/2688)
Epoch: 13 | Batch_idx: 30 |  Loss: (0.9126) |  Loss2: (0.0000) | Acc: (68.00%) (2708/3968)
Epoch: 13 | Batch_idx: 40 |  Loss: (0.9212) |  Loss2: (0.0000) | Acc: (67.00%) (3538/5248)
Epoch: 13 | Batch_idx: 50 |  Loss: (0.9218) |  Loss2: (0.0000) | Acc: (67.00%) (4378/6528)
Epoch: 13 | Batch_idx: 60 |  Loss: (0.9172) |  Loss2: (0.0000) | Acc: (67.00%) (5242/7808)
Epoch: 13 | Batch_idx: 70 |  Loss: (0.9137) |  Loss2: (0.0000) | Acc: (67.00%) (6117/9088)
Epoch: 13 | Batch_idx: 80 |  Loss: (0.9118) |  Loss2: (0.0000) | Acc: (67.00%) (7002/10368)
Epoch: 13 | Batch_idx: 90 |  Loss: (0.9105) |  Loss2: (0.0000) | Acc: (67.00%) (7874/11648)
Epoch: 13 | Batch_idx: 100 |  Loss: (0.9164) |  Loss2: (0.0000) | Acc: (67.00%) (8707/12928)
Epoch: 13 | Batch_idx: 110 |  Loss: (0.9191) |  Loss2: (0.0000) | Acc: (67.00%) (9562/14208)
Epoch: 13 | Batch_idx: 120 |  Loss: (0.9175) |  Loss2: (0.0000) | Acc: (67.00%) (10444/15488)
Epoch: 13 | Batch_idx: 130 |  Loss: (0.9175) |  Loss2: (0.0000) | Acc: (67.00%) (11293/16768)
Epoch: 13 | Batch_idx: 140 |  Loss: (0.9140) |  Loss2: (0.0000) | Acc: (67.00%) (12174/18048)
Epoch: 13 | Batch_idx: 150 |  Loss: (0.9128) |  Loss2: (0.0000) | Acc: (67.00%) (13055/19328)
Epoch: 13 | Batch_idx: 160 |  Loss: (0.9132) |  Loss2: (0.0000) | Acc: (67.00%) (13920/20608)
Epoch: 13 | Batch_idx: 170 |  Loss: (0.9098) |  Loss2: (0.0000) | Acc: (67.00%) (14811/21888)
Epoch: 13 | Batch_idx: 180 |  Loss: (0.9069) |  Loss2: (0.0000) | Acc: (67.00%) (15690/23168)
Epoch: 13 | Batch_idx: 190 |  Loss: (0.9063) |  Loss2: (0.0000) | Acc: (67.00%) (16573/24448)
Epoch: 13 | Batch_idx: 200 |  Loss: (0.9064) |  Loss2: (0.0000) | Acc: (67.00%) (17462/25728)
Epoch: 13 | Batch_idx: 210 |  Loss: (0.9033) |  Loss2: (0.0000) | Acc: (67.00%) (18354/27008)
Epoch: 13 | Batch_idx: 220 |  Loss: (0.9022) |  Loss2: (0.0000) | Acc: (68.00%) (19242/28288)
Epoch: 13 | Batch_idx: 230 |  Loss: (0.9027) |  Loss2: (0.0000) | Acc: (68.00%) (20112/29568)
Epoch: 13 | Batch_idx: 240 |  Loss: (0.9035) |  Loss2: (0.0000) | Acc: (67.00%) (20964/30848)
Epoch: 13 | Batch_idx: 250 |  Loss: (0.9035) |  Loss2: (0.0000) | Acc: (67.00%) (21835/32128)
Epoch: 13 | Batch_idx: 260 |  Loss: (0.9032) |  Loss2: (0.0000) | Acc: (67.00%) (22713/33408)
Epoch: 13 | Batch_idx: 270 |  Loss: (0.9016) |  Loss2: (0.0000) | Acc: (68.00%) (23592/34688)
Epoch: 13 | Batch_idx: 280 |  Loss: (0.9014) |  Loss2: (0.0000) | Acc: (68.00%) (24473/35968)
Epoch: 13 | Batch_idx: 290 |  Loss: (0.9007) |  Loss2: (0.0000) | Acc: (68.00%) (25369/37248)
Epoch: 13 | Batch_idx: 300 |  Loss: (0.8986) |  Loss2: (0.0000) | Acc: (68.00%) (26273/38528)
Epoch: 13 | Batch_idx: 310 |  Loss: (0.8984) |  Loss2: (0.0000) | Acc: (68.00%) (27124/39808)
Epoch: 13 | Batch_idx: 320 |  Loss: (0.8986) |  Loss2: (0.0000) | Acc: (68.00%) (27997/41088)
Epoch: 13 | Batch_idx: 330 |  Loss: (0.8972) |  Loss2: (0.0000) | Acc: (68.00%) (28880/42368)
Epoch: 13 | Batch_idx: 340 |  Loss: (0.8954) |  Loss2: (0.0000) | Acc: (68.00%) (29770/43648)
Epoch: 13 | Batch_idx: 350 |  Loss: (0.8944) |  Loss2: (0.0000) | Acc: (68.00%) (30678/44928)
Epoch: 13 | Batch_idx: 360 |  Loss: (0.8950) |  Loss2: (0.0000) | Acc: (68.00%) (31534/46208)
Epoch: 13 | Batch_idx: 370 |  Loss: (0.8940) |  Loss2: (0.0000) | Acc: (68.00%) (32426/47488)
Epoch: 13 | Batch_idx: 380 |  Loss: (0.8921) |  Loss2: (0.0000) | Acc: (68.00%) (33331/48768)
Epoch: 13 | Batch_idx: 390 |  Loss: (0.8933) |  Loss2: (0.0000) | Acc: (68.00%) (34174/50000)
# TEST : Loss: (0.9693) | Acc: (65.00%) (6561/10000)
percent tensor([0.4989, 0.4973, 0.4999, 0.5018, 0.4987, 0.5018, 0.4968, 0.4989, 0.4962,
        0.4986, 0.4965, 0.4983, 0.4974, 0.4981, 0.4994, 0.5001],
       device='cuda:0') torch.Size([16])
percent tensor([0.4992, 0.4972, 0.4994, 0.4991, 0.4987, 0.5028, 0.4972, 0.4983, 0.4990,
        0.4974, 0.4988, 0.4980, 0.4981, 0.4977, 0.4988, 0.4986],
       device='cuda:0') torch.Size([16])
percent tensor([0.4983, 0.4697, 0.5200, 0.5067, 0.5194, 0.5102, 0.4890, 0.5157, 0.4967,
        0.4810, 0.4741, 0.5088, 0.4826, 0.4716, 0.4894, 0.4969],
       device='cuda:0') torch.Size([16])
percent tensor([0.5283, 0.5343, 0.5204, 0.5233, 0.5217, 0.5243, 0.5307, 0.5237, 0.5310,
        0.5318, 0.5330, 0.5266, 0.5324, 0.5329, 0.5324, 0.5286],
       device='cuda:0') torch.Size([16])
percent tensor([0.5215, 0.5204, 0.5241, 0.5298, 0.5239, 0.5267, 0.5255, 0.5272, 0.5194,
        0.5165, 0.5212, 0.5253, 0.5206, 0.5223, 0.5255, 0.5246],
       device='cuda:0') torch.Size([16])
percent tensor([0.4878, 0.4896, 0.5045, 0.5067, 0.4983, 0.5003, 0.4908, 0.4882, 0.4935,
        0.4919, 0.4870, 0.5010, 0.4869, 0.4906, 0.4854, 0.4857],
       device='cuda:0') torch.Size([16])
percent tensor([0.5113, 0.5142, 0.5605, 0.5612, 0.5726, 0.5122, 0.5375, 0.5685, 0.5075,
        0.5249, 0.5176, 0.5455, 0.4989, 0.5045, 0.5351, 0.5113],
       device='cuda:0') torch.Size([16])
percent tensor([0.9700, 0.9385, 0.9800, 0.9860, 0.9898, 0.9740, 0.9816, 0.9952, 0.9215,
        0.9635, 0.9685, 0.9717, 0.9426, 0.9400, 0.9826, 0.9834],
       device='cuda:0') torch.Size([16])
Epoch: 14 | Batch_idx: 0 |  Loss: (0.7815) |  Loss2: (0.0000) | Acc: (72.00%) (93/128)
Epoch: 14 | Batch_idx: 10 |  Loss: (0.8699) |  Loss2: (0.0000) | Acc: (70.00%) (990/1408)
Epoch: 14 | Batch_idx: 20 |  Loss: (0.8772) |  Loss2: (0.0000) | Acc: (69.00%) (1878/2688)
Epoch: 14 | Batch_idx: 30 |  Loss: (0.8649) |  Loss2: (0.0000) | Acc: (70.00%) (2778/3968)
Epoch: 14 | Batch_idx: 40 |  Loss: (0.8675) |  Loss2: (0.0000) | Acc: (69.00%) (3655/5248)
Epoch: 14 | Batch_idx: 50 |  Loss: (0.8638) |  Loss2: (0.0000) | Acc: (69.00%) (4549/6528)
Epoch: 14 | Batch_idx: 60 |  Loss: (0.8646) |  Loss2: (0.0000) | Acc: (69.00%) (5430/7808)
Epoch: 14 | Batch_idx: 70 |  Loss: (0.8643) |  Loss2: (0.0000) | Acc: (69.00%) (6311/9088)
Epoch: 14 | Batch_idx: 80 |  Loss: (0.8645) |  Loss2: (0.0000) | Acc: (69.00%) (7187/10368)
Epoch: 14 | Batch_idx: 90 |  Loss: (0.8628) |  Loss2: (0.0000) | Acc: (69.00%) (8071/11648)
Epoch: 14 | Batch_idx: 100 |  Loss: (0.8566) |  Loss2: (0.0000) | Acc: (69.00%) (8992/12928)
Epoch: 14 | Batch_idx: 110 |  Loss: (0.8573) |  Loss2: (0.0000) | Acc: (69.00%) (9887/14208)
Epoch: 14 | Batch_idx: 120 |  Loss: (0.8573) |  Loss2: (0.0000) | Acc: (69.00%) (10804/15488)
Epoch: 14 | Batch_idx: 130 |  Loss: (0.8559) |  Loss2: (0.0000) | Acc: (69.00%) (11679/16768)
Epoch: 14 | Batch_idx: 140 |  Loss: (0.8577) |  Loss2: (0.0000) | Acc: (69.00%) (12556/18048)
Epoch: 14 | Batch_idx: 150 |  Loss: (0.8578) |  Loss2: (0.0000) | Acc: (69.00%) (13458/19328)
Epoch: 14 | Batch_idx: 160 |  Loss: (0.8578) |  Loss2: (0.0000) | Acc: (69.00%) (14359/20608)
Epoch: 14 | Batch_idx: 170 |  Loss: (0.8561) |  Loss2: (0.0000) | Acc: (69.00%) (15274/21888)
Epoch: 14 | Batch_idx: 180 |  Loss: (0.8563) |  Loss2: (0.0000) | Acc: (69.00%) (16179/23168)
Epoch: 14 | Batch_idx: 190 |  Loss: (0.8567) |  Loss2: (0.0000) | Acc: (69.00%) (17066/24448)
Epoch: 14 | Batch_idx: 200 |  Loss: (0.8544) |  Loss2: (0.0000) | Acc: (69.00%) (17975/25728)
Epoch: 14 | Batch_idx: 210 |  Loss: (0.8518) |  Loss2: (0.0000) | Acc: (69.00%) (18881/27008)
Epoch: 14 | Batch_idx: 220 |  Loss: (0.8491) |  Loss2: (0.0000) | Acc: (70.00%) (19816/28288)
Epoch: 14 | Batch_idx: 230 |  Loss: (0.8467) |  Loss2: (0.0000) | Acc: (70.00%) (20759/29568)
Epoch: 14 | Batch_idx: 240 |  Loss: (0.8458) |  Loss2: (0.0000) | Acc: (70.00%) (21663/30848)
Epoch: 14 | Batch_idx: 250 |  Loss: (0.8449) |  Loss2: (0.0000) | Acc: (70.00%) (22567/32128)
Epoch: 14 | Batch_idx: 260 |  Loss: (0.8417) |  Loss2: (0.0000) | Acc: (70.00%) (23493/33408)
Epoch: 14 | Batch_idx: 270 |  Loss: (0.8421) |  Loss2: (0.0000) | Acc: (70.00%) (24393/34688)
Epoch: 14 | Batch_idx: 280 |  Loss: (0.8425) |  Loss2: (0.0000) | Acc: (70.00%) (25292/35968)
Epoch: 14 | Batch_idx: 290 |  Loss: (0.8422) |  Loss2: (0.0000) | Acc: (70.00%) (26200/37248)
Epoch: 14 | Batch_idx: 300 |  Loss: (0.8421) |  Loss2: (0.0000) | Acc: (70.00%) (27100/38528)
Epoch: 14 | Batch_idx: 310 |  Loss: (0.8419) |  Loss2: (0.0000) | Acc: (70.00%) (28004/39808)
Epoch: 14 | Batch_idx: 320 |  Loss: (0.8410) |  Loss2: (0.0000) | Acc: (70.00%) (28912/41088)
Epoch: 14 | Batch_idx: 330 |  Loss: (0.8402) |  Loss2: (0.0000) | Acc: (70.00%) (29821/42368)
Epoch: 14 | Batch_idx: 340 |  Loss: (0.8392) |  Loss2: (0.0000) | Acc: (70.00%) (30729/43648)
Epoch: 14 | Batch_idx: 350 |  Loss: (0.8393) |  Loss2: (0.0000) | Acc: (70.00%) (31607/44928)
Epoch: 14 | Batch_idx: 360 |  Loss: (0.8396) |  Loss2: (0.0000) | Acc: (70.00%) (32510/46208)
Epoch: 14 | Batch_idx: 370 |  Loss: (0.8393) |  Loss2: (0.0000) | Acc: (70.00%) (33407/47488)
Epoch: 14 | Batch_idx: 380 |  Loss: (0.8395) |  Loss2: (0.0000) | Acc: (70.00%) (34288/48768)
Epoch: 14 | Batch_idx: 390 |  Loss: (0.8380) |  Loss2: (0.0000) | Acc: (70.00%) (35174/50000)
# TEST : Loss: (0.9080) | Acc: (68.00%) (6821/10000)
percent tensor([0.4991, 0.4972, 0.5002, 0.5017, 0.4989, 0.5017, 0.4969, 0.4990, 0.4969,
        0.4988, 0.4970, 0.4985, 0.4978, 0.4976, 0.4993, 0.5001],
       device='cuda:0') torch.Size([16])
percent tensor([0.4994, 0.4970, 0.4996, 0.4996, 0.4991, 0.5030, 0.4972, 0.4986, 0.4988,
        0.4973, 0.4987, 0.4979, 0.4981, 0.4976, 0.4991, 0.4989],
       device='cuda:0') torch.Size([16])
percent tensor([0.4976, 0.4720, 0.5188, 0.5062, 0.5191, 0.5104, 0.4907, 0.5159, 0.4982,
        0.4818, 0.4762, 0.5067, 0.4833, 0.4730, 0.4917, 0.4982],
       device='cuda:0') torch.Size([16])
percent tensor([0.5279, 0.5327, 0.5203, 0.5242, 0.5222, 0.5260, 0.5300, 0.5246, 0.5295,
        0.5306, 0.5315, 0.5265, 0.5310, 0.5315, 0.5325, 0.5285],
       device='cuda:0') torch.Size([16])
percent tensor([0.5221, 0.5201, 0.5254, 0.5306, 0.5247, 0.5284, 0.5280, 0.5278, 0.5193,
        0.5175, 0.5194, 0.5286, 0.5196, 0.5226, 0.5268, 0.5269],
       device='cuda:0') torch.Size([16])
percent tensor([0.4855, 0.4883, 0.4961, 0.5021, 0.4965, 0.5012, 0.4894, 0.4833, 0.4942,
        0.4879, 0.4874, 0.4993, 0.4843, 0.4942, 0.4854, 0.4829],
       device='cuda:0') torch.Size([16])
percent tensor([0.5138, 0.5102, 0.5654, 0.5622, 0.5675, 0.5169, 0.5428, 0.5774, 0.5123,
        0.5240, 0.5169, 0.5516, 0.4995, 0.5081, 0.5337, 0.5186],
       device='cuda:0') torch.Size([16])
percent tensor([0.9869, 0.9381, 0.9872, 0.9851, 0.9887, 0.9689, 0.9907, 0.9964, 0.9375,
        0.9649, 0.9575, 0.9829, 0.9655, 0.9523, 0.9840, 0.9940],
       device='cuda:0') torch.Size([16])
False Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=128, out_features=16, bias=False)
True Linear(in_features=16, out_features=2, bias=False)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=128, out_features=16, bias=False)
True Linear(in_features=16, out_features=2, bias=False)
False Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=256, out_features=32, bias=False)
True Linear(in_features=32, out_features=2, bias=False)
False Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=256, out_features=32, bias=False)
True Linear(in_features=32, out_features=2, bias=False)
False Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=512, out_features=64, bias=False)
True Linear(in_features=64, out_features=2, bias=False)
False Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=512, out_features=64, bias=False)
True Linear(in_features=64, out_features=2, bias=False)
False Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1024, out_features=128, bias=False)
True Linear(in_features=128, out_features=2, bias=False)
False Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1024, out_features=128, bias=False)
True Linear(in_features=128, out_features=2, bias=False)
False Linear(in_features=512, out_features=10, bias=True)
Epoch: 15 | Batch_idx: 0 |  Loss: (0.8464) |  Loss2: (0.0000) | Acc: (67.00%) (87/128)
Epoch: 15 | Batch_idx: 10 |  Loss: (0.8326) |  Loss2: (0.0000) | Acc: (69.00%) (978/1408)
Epoch: 15 | Batch_idx: 20 |  Loss: (0.8570) |  Loss2: (0.0000) | Acc: (69.00%) (1856/2688)
Epoch: 15 | Batch_idx: 30 |  Loss: (0.8840) |  Loss2: (0.0000) | Acc: (68.00%) (2701/3968)
Epoch: 15 | Batch_idx: 40 |  Loss: (0.8903) |  Loss2: (0.0000) | Acc: (67.00%) (3560/5248)
Epoch: 15 | Batch_idx: 50 |  Loss: (0.9040) |  Loss2: (0.0000) | Acc: (67.00%) (4418/6528)
Epoch: 15 | Batch_idx: 60 |  Loss: (0.9044) |  Loss2: (0.0000) | Acc: (67.00%) (5286/7808)
Epoch: 15 | Batch_idx: 70 |  Loss: (0.9131) |  Loss2: (0.0000) | Acc: (67.00%) (6128/9088)
Epoch: 15 | Batch_idx: 80 |  Loss: (0.9144) |  Loss2: (0.0000) | Acc: (67.00%) (6974/10368)
Epoch: 15 | Batch_idx: 90 |  Loss: (0.9148) |  Loss2: (0.0000) | Acc: (67.00%) (7823/11648)
Epoch: 15 | Batch_idx: 100 |  Loss: (0.9131) |  Loss2: (0.0000) | Acc: (67.00%) (8707/12928)
Epoch: 15 | Batch_idx: 110 |  Loss: (0.9080) |  Loss2: (0.0000) | Acc: (67.00%) (9574/14208)
Epoch: 15 | Batch_idx: 120 |  Loss: (0.9070) |  Loss2: (0.0000) | Acc: (67.00%) (10451/15488)
Epoch: 15 | Batch_idx: 130 |  Loss: (0.9060) |  Loss2: (0.0000) | Acc: (67.00%) (11317/16768)
Epoch: 15 | Batch_idx: 140 |  Loss: (0.9020) |  Loss2: (0.0000) | Acc: (67.00%) (12197/18048)
Epoch: 15 | Batch_idx: 150 |  Loss: (0.9041) |  Loss2: (0.0000) | Acc: (67.00%) (13055/19328)
Epoch: 15 | Batch_idx: 160 |  Loss: (0.9033) |  Loss2: (0.0000) | Acc: (67.00%) (13924/20608)
Epoch: 15 | Batch_idx: 170 |  Loss: (0.9033) |  Loss2: (0.0000) | Acc: (67.00%) (14799/21888)
Epoch: 15 | Batch_idx: 180 |  Loss: (0.9003) |  Loss2: (0.0000) | Acc: (67.00%) (15698/23168)
Epoch: 15 | Batch_idx: 190 |  Loss: (0.9021) |  Loss2: (0.0000) | Acc: (67.00%) (16569/24448)
Epoch: 15 | Batch_idx: 200 |  Loss: (0.8989) |  Loss2: (0.0000) | Acc: (67.00%) (17472/25728)
Epoch: 15 | Batch_idx: 210 |  Loss: (0.8966) |  Loss2: (0.0000) | Acc: (68.00%) (18375/27008)
Epoch: 15 | Batch_idx: 220 |  Loss: (0.8954) |  Loss2: (0.0000) | Acc: (68.00%) (19257/28288)
Epoch: 15 | Batch_idx: 230 |  Loss: (0.8951) |  Loss2: (0.0000) | Acc: (68.00%) (20117/29568)
Epoch: 15 | Batch_idx: 240 |  Loss: (0.8929) |  Loss2: (0.0000) | Acc: (68.00%) (21016/30848)
Epoch: 15 | Batch_idx: 250 |  Loss: (0.8908) |  Loss2: (0.0000) | Acc: (68.00%) (21917/32128)
Epoch: 15 | Batch_idx: 260 |  Loss: (0.8907) |  Loss2: (0.0000) | Acc: (68.00%) (22780/33408)
Epoch: 15 | Batch_idx: 270 |  Loss: (0.8916) |  Loss2: (0.0000) | Acc: (68.00%) (23636/34688)
Epoch: 15 | Batch_idx: 280 |  Loss: (0.8896) |  Loss2: (0.0000) | Acc: (68.00%) (24525/35968)
Epoch: 15 | Batch_idx: 290 |  Loss: (0.8884) |  Loss2: (0.0000) | Acc: (68.00%) (25416/37248)
Epoch: 15 | Batch_idx: 300 |  Loss: (0.8871) |  Loss2: (0.0000) | Acc: (68.00%) (26308/38528)
Epoch: 15 | Batch_idx: 310 |  Loss: (0.8847) |  Loss2: (0.0000) | Acc: (68.00%) (27226/39808)
Epoch: 15 | Batch_idx: 320 |  Loss: (0.8848) |  Loss2: (0.0000) | Acc: (68.00%) (28098/41088)
Epoch: 15 | Batch_idx: 330 |  Loss: (0.8833) |  Loss2: (0.0000) | Acc: (68.00%) (28997/42368)
Epoch: 15 | Batch_idx: 340 |  Loss: (0.8814) |  Loss2: (0.0000) | Acc: (68.00%) (29913/43648)
Epoch: 15 | Batch_idx: 350 |  Loss: (0.8817) |  Loss2: (0.0000) | Acc: (68.00%) (30786/44928)
Epoch: 15 | Batch_idx: 360 |  Loss: (0.8811) |  Loss2: (0.0000) | Acc: (68.00%) (31654/46208)
Epoch: 15 | Batch_idx: 370 |  Loss: (0.8801) |  Loss2: (0.0000) | Acc: (68.00%) (32547/47488)
Epoch: 15 | Batch_idx: 380 |  Loss: (0.8788) |  Loss2: (0.0000) | Acc: (68.00%) (33462/48768)
Epoch: 15 | Batch_idx: 390 |  Loss: (0.8785) |  Loss2: (0.0000) | Acc: (68.00%) (34315/50000)
=> saving checkpoint 'drive/app/torch/save_Schedule/checkpoint_015.pth.tar'
# TEST : Loss: (0.8666) | Acc: (69.00%) (6920/10000)
percent tensor([0.5065, 0.5058, 0.5086, 0.5091, 0.5072, 0.5079, 0.5064, 0.5075, 0.5039,
        0.5078, 0.5048, 0.5079, 0.5061, 0.5051, 0.5078, 0.5079],
       device='cuda:0') torch.Size([16])
percent tensor([0.4981, 0.4938, 0.4972, 0.4988, 0.4961, 0.5029, 0.4935, 0.4959, 0.4970,
        0.4944, 0.4969, 0.4949, 0.4959, 0.4948, 0.4969, 0.4975],
       device='cuda:0') torch.Size([16])
percent tensor([0.4869, 0.4279, 0.5243, 0.5145, 0.5235, 0.5138, 0.4668, 0.5186, 0.4814,
        0.4480, 0.4394, 0.4944, 0.4459, 0.4455, 0.4699, 0.4884],
       device='cuda:0') torch.Size([16])
percent tensor([0.5545, 0.5621, 0.5403, 0.5472, 0.5441, 0.5516, 0.5560, 0.5472, 0.5558,
        0.5583, 0.5603, 0.5508, 0.5600, 0.5591, 0.5610, 0.5559],
       device='cuda:0') torch.Size([16])
percent tensor([0.5283, 0.5121, 0.5380, 0.5494, 0.5391, 0.5466, 0.5280, 0.5386, 0.5232,
        0.5104, 0.5145, 0.5308, 0.5135, 0.5256, 0.5255, 0.5353],
       device='cuda:0') torch.Size([16])
percent tensor([0.4667, 0.4671, 0.4831, 0.4979, 0.4858, 0.4979, 0.4702, 0.4620, 0.4802,
        0.4625, 0.4650, 0.4751, 0.4628, 0.4804, 0.4602, 0.4692],
       device='cuda:0') torch.Size([16])
percent tensor([0.5061, 0.5087, 0.5635, 0.5568, 0.5630, 0.5036, 0.5436, 0.5857, 0.5085,
        0.5231, 0.5134, 0.5581, 0.4906, 0.5051, 0.5304, 0.5137],
       device='cuda:0') torch.Size([16])
percent tensor([0.9880, 0.9563, 0.9904, 0.9895, 0.9894, 0.9790, 0.9883, 0.9973, 0.9470,
        0.9761, 0.9686, 0.9924, 0.9681, 0.9611, 0.9817, 0.9926],
       device='cuda:0') torch.Size([16])
Epoch: 16 | Batch_idx: 0 |  Loss: (0.7887) |  Loss2: (0.0000) | Acc: (70.00%) (90/128)
Epoch: 16 | Batch_idx: 10 |  Loss: (0.8200) |  Loss2: (0.0000) | Acc: (70.00%) (998/1408)
Epoch: 16 | Batch_idx: 20 |  Loss: (0.8338) |  Loss2: (0.0000) | Acc: (70.00%) (1887/2688)
Epoch: 16 | Batch_idx: 30 |  Loss: (0.8416) |  Loss2: (0.0000) | Acc: (69.00%) (2775/3968)
Epoch: 16 | Batch_idx: 40 |  Loss: (0.8336) |  Loss2: (0.0000) | Acc: (70.00%) (3691/5248)
Epoch: 16 | Batch_idx: 50 |  Loss: (0.8364) |  Loss2: (0.0000) | Acc: (70.00%) (4596/6528)
Epoch: 16 | Batch_idx: 60 |  Loss: (0.8415) |  Loss2: (0.0000) | Acc: (70.00%) (5484/7808)
Epoch: 16 | Batch_idx: 70 |  Loss: (0.8435) |  Loss2: (0.0000) | Acc: (70.00%) (6369/9088)
Epoch: 16 | Batch_idx: 80 |  Loss: (0.8411) |  Loss2: (0.0000) | Acc: (70.00%) (7278/10368)
Epoch: 16 | Batch_idx: 90 |  Loss: (0.8396) |  Loss2: (0.0000) | Acc: (70.00%) (8188/11648)
Epoch: 16 | Batch_idx: 100 |  Loss: (0.8355) |  Loss2: (0.0000) | Acc: (70.00%) (9114/12928)
Epoch: 16 | Batch_idx: 110 |  Loss: (0.8336) |  Loss2: (0.0000) | Acc: (70.00%) (10024/14208)
Epoch: 16 | Batch_idx: 120 |  Loss: (0.8354) |  Loss2: (0.0000) | Acc: (70.00%) (10915/15488)
Epoch: 16 | Batch_idx: 130 |  Loss: (0.8346) |  Loss2: (0.0000) | Acc: (70.00%) (11826/16768)
Epoch: 16 | Batch_idx: 140 |  Loss: (0.8348) |  Loss2: (0.0000) | Acc: (70.00%) (12725/18048)
Epoch: 16 | Batch_idx: 150 |  Loss: (0.8345) |  Loss2: (0.0000) | Acc: (70.00%) (13629/19328)
Epoch: 16 | Batch_idx: 160 |  Loss: (0.8332) |  Loss2: (0.0000) | Acc: (70.00%) (14542/20608)
Epoch: 16 | Batch_idx: 170 |  Loss: (0.8347) |  Loss2: (0.0000) | Acc: (70.00%) (15446/21888)
Epoch: 16 | Batch_idx: 180 |  Loss: (0.8377) |  Loss2: (0.0000) | Acc: (70.00%) (16335/23168)
Epoch: 16 | Batch_idx: 190 |  Loss: (0.8378) |  Loss2: (0.0000) | Acc: (70.00%) (17247/24448)
Epoch: 16 | Batch_idx: 200 |  Loss: (0.8348) |  Loss2: (0.0000) | Acc: (70.00%) (18170/25728)
Epoch: 16 | Batch_idx: 210 |  Loss: (0.8350) |  Loss2: (0.0000) | Acc: (70.00%) (19074/27008)
Epoch: 16 | Batch_idx: 220 |  Loss: (0.8326) |  Loss2: (0.0000) | Acc: (70.00%) (19995/28288)
Epoch: 16 | Batch_idx: 230 |  Loss: (0.8318) |  Loss2: (0.0000) | Acc: (70.00%) (20907/29568)
Epoch: 16 | Batch_idx: 240 |  Loss: (0.8297) |  Loss2: (0.0000) | Acc: (70.00%) (21852/30848)
Epoch: 16 | Batch_idx: 250 |  Loss: (0.8290) |  Loss2: (0.0000) | Acc: (70.00%) (22757/32128)
Epoch: 16 | Batch_idx: 260 |  Loss: (0.8285) |  Loss2: (0.0000) | Acc: (70.00%) (23665/33408)
Epoch: 16 | Batch_idx: 270 |  Loss: (0.8279) |  Loss2: (0.0000) | Acc: (70.00%) (24580/34688)
Epoch: 16 | Batch_idx: 280 |  Loss: (0.8274) |  Loss2: (0.0000) | Acc: (70.00%) (25490/35968)
Epoch: 16 | Batch_idx: 290 |  Loss: (0.8275) |  Loss2: (0.0000) | Acc: (70.00%) (26397/37248)
Epoch: 16 | Batch_idx: 300 |  Loss: (0.8259) |  Loss2: (0.0000) | Acc: (70.00%) (27315/38528)
Epoch: 16 | Batch_idx: 310 |  Loss: (0.8264) |  Loss2: (0.0000) | Acc: (70.00%) (28220/39808)
Epoch: 16 | Batch_idx: 320 |  Loss: (0.8271) |  Loss2: (0.0000) | Acc: (70.00%) (29129/41088)
Epoch: 16 | Batch_idx: 330 |  Loss: (0.8276) |  Loss2: (0.0000) | Acc: (70.00%) (30033/42368)
Epoch: 16 | Batch_idx: 340 |  Loss: (0.8274) |  Loss2: (0.0000) | Acc: (70.00%) (30957/43648)
Epoch: 16 | Batch_idx: 350 |  Loss: (0.8267) |  Loss2: (0.0000) | Acc: (70.00%) (31886/44928)
Epoch: 16 | Batch_idx: 360 |  Loss: (0.8262) |  Loss2: (0.0000) | Acc: (70.00%) (32799/46208)
Epoch: 16 | Batch_idx: 370 |  Loss: (0.8256) |  Loss2: (0.0000) | Acc: (71.00%) (33717/47488)
Epoch: 16 | Batch_idx: 380 |  Loss: (0.8264) |  Loss2: (0.0000) | Acc: (70.00%) (34598/48768)
Epoch: 16 | Batch_idx: 390 |  Loss: (0.8262) |  Loss2: (0.0000) | Acc: (70.00%) (35466/50000)
# TEST : Loss: (0.8291) | Acc: (70.00%) (7076/10000)
percent tensor([0.5070, 0.5066, 0.5090, 0.5098, 0.5076, 0.5084, 0.5070, 0.5084, 0.5043,
        0.5083, 0.5052, 0.5084, 0.5065, 0.5062, 0.5083, 0.5088],
       device='cuda:0') torch.Size([16])
percent tensor([0.4968, 0.4908, 0.4948, 0.4982, 0.4933, 0.5031, 0.4901, 0.4930, 0.4951,
        0.4917, 0.4951, 0.4921, 0.4939, 0.4921, 0.4952, 0.4962],
       device='cuda:0') torch.Size([16])
percent tensor([0.4934, 0.4205, 0.5337, 0.5258, 0.5322, 0.5208, 0.4683, 0.5280, 0.4869,
        0.4454, 0.4350, 0.5008, 0.4408, 0.4474, 0.4724, 0.4957],
       device='cuda:0') torch.Size([16])
percent tensor([0.5754, 0.5855, 0.5547, 0.5638, 0.5596, 0.5697, 0.5764, 0.5642, 0.5766,
        0.5807, 0.5836, 0.5693, 0.5841, 0.5813, 0.5827, 0.5771],
       device='cuda:0') torch.Size([16])
percent tensor([0.5398, 0.5151, 0.5466, 0.5616, 0.5491, 0.5621, 0.5339, 0.5477, 0.5321,
        0.5133, 0.5207, 0.5348, 0.5187, 0.5344, 0.5317, 0.5483],
       device='cuda:0') torch.Size([16])
percent tensor([0.4702, 0.4686, 0.4876, 0.5064, 0.4932, 0.5068, 0.4717, 0.4641, 0.4827,
        0.4625, 0.4663, 0.4736, 0.4656, 0.4851, 0.4589, 0.4746],
       device='cuda:0') torch.Size([16])
percent tensor([0.5111, 0.5135, 0.5765, 0.5727, 0.5787, 0.5086, 0.5551, 0.6077, 0.5142,
        0.5298, 0.5198, 0.5700, 0.4929, 0.5090, 0.5422, 0.5226],
       device='cuda:0') torch.Size([16])
percent tensor([0.9937, 0.9659, 0.9931, 0.9933, 0.9933, 0.9870, 0.9927, 0.9985, 0.9613,
        0.9826, 0.9772, 0.9945, 0.9783, 0.9728, 0.9879, 0.9962],
       device='cuda:0') torch.Size([16])
Epoch: 17 | Batch_idx: 0 |  Loss: (0.7445) |  Loss2: (0.0000) | Acc: (73.00%) (94/128)
Epoch: 17 | Batch_idx: 10 |  Loss: (0.7784) |  Loss2: (0.0000) | Acc: (73.00%) (1028/1408)
Epoch: 17 | Batch_idx: 20 |  Loss: (0.7822) |  Loss2: (0.0000) | Acc: (73.00%) (1971/2688)
Epoch: 17 | Batch_idx: 30 |  Loss: (0.8039) |  Loss2: (0.0000) | Acc: (72.00%) (2863/3968)
Epoch: 17 | Batch_idx: 40 |  Loss: (0.7967) |  Loss2: (0.0000) | Acc: (72.00%) (3795/5248)
Epoch: 17 | Batch_idx: 50 |  Loss: (0.8059) |  Loss2: (0.0000) | Acc: (71.00%) (4695/6528)
Epoch: 17 | Batch_idx: 60 |  Loss: (0.8088) |  Loss2: (0.0000) | Acc: (71.00%) (5617/7808)
Epoch: 17 | Batch_idx: 70 |  Loss: (0.8098) |  Loss2: (0.0000) | Acc: (71.00%) (6530/9088)
Epoch: 17 | Batch_idx: 80 |  Loss: (0.8099) |  Loss2: (0.0000) | Acc: (71.00%) (7436/10368)
Epoch: 17 | Batch_idx: 90 |  Loss: (0.8093) |  Loss2: (0.0000) | Acc: (71.00%) (8355/11648)
Epoch: 17 | Batch_idx: 100 |  Loss: (0.8100) |  Loss2: (0.0000) | Acc: (71.00%) (9261/12928)
Epoch: 17 | Batch_idx: 110 |  Loss: (0.8049) |  Loss2: (0.0000) | Acc: (71.00%) (10176/14208)
Epoch: 17 | Batch_idx: 120 |  Loss: (0.8055) |  Loss2: (0.0000) | Acc: (71.00%) (11089/15488)
Epoch: 17 | Batch_idx: 130 |  Loss: (0.8046) |  Loss2: (0.0000) | Acc: (71.00%) (12017/16768)
Epoch: 17 | Batch_idx: 140 |  Loss: (0.8036) |  Loss2: (0.0000) | Acc: (71.00%) (12938/18048)
Epoch: 17 | Batch_idx: 150 |  Loss: (0.8038) |  Loss2: (0.0000) | Acc: (71.00%) (13859/19328)
Epoch: 17 | Batch_idx: 160 |  Loss: (0.8038) |  Loss2: (0.0000) | Acc: (71.00%) (14766/20608)
Epoch: 17 | Batch_idx: 170 |  Loss: (0.8035) |  Loss2: (0.0000) | Acc: (71.00%) (15676/21888)
Epoch: 17 | Batch_idx: 180 |  Loss: (0.8045) |  Loss2: (0.0000) | Acc: (71.00%) (16570/23168)
Epoch: 17 | Batch_idx: 190 |  Loss: (0.8058) |  Loss2: (0.0000) | Acc: (71.00%) (17474/24448)
Epoch: 17 | Batch_idx: 200 |  Loss: (0.8045) |  Loss2: (0.0000) | Acc: (71.00%) (18401/25728)
Epoch: 17 | Batch_idx: 210 |  Loss: (0.8065) |  Loss2: (0.0000) | Acc: (71.00%) (19307/27008)
Epoch: 17 | Batch_idx: 220 |  Loss: (0.8057) |  Loss2: (0.0000) | Acc: (71.00%) (20220/28288)
Epoch: 17 | Batch_idx: 230 |  Loss: (0.8061) |  Loss2: (0.0000) | Acc: (71.00%) (21123/29568)
Epoch: 17 | Batch_idx: 240 |  Loss: (0.8065) |  Loss2: (0.0000) | Acc: (71.00%) (22038/30848)
Epoch: 17 | Batch_idx: 250 |  Loss: (0.8065) |  Loss2: (0.0000) | Acc: (71.00%) (22931/32128)
Epoch: 17 | Batch_idx: 260 |  Loss: (0.8048) |  Loss2: (0.0000) | Acc: (71.00%) (23885/33408)
Epoch: 17 | Batch_idx: 270 |  Loss: (0.8052) |  Loss2: (0.0000) | Acc: (71.00%) (24784/34688)
Epoch: 17 | Batch_idx: 280 |  Loss: (0.8044) |  Loss2: (0.0000) | Acc: (71.00%) (25728/35968)
Epoch: 17 | Batch_idx: 290 |  Loss: (0.8059) |  Loss2: (0.0000) | Acc: (71.00%) (26625/37248)
Epoch: 17 | Batch_idx: 300 |  Loss: (0.8050) |  Loss2: (0.0000) | Acc: (71.00%) (27553/38528)
Epoch: 17 | Batch_idx: 310 |  Loss: (0.8061) |  Loss2: (0.0000) | Acc: (71.00%) (28465/39808)
Epoch: 17 | Batch_idx: 320 |  Loss: (0.8053) |  Loss2: (0.0000) | Acc: (71.00%) (29398/41088)
Epoch: 17 | Batch_idx: 330 |  Loss: (0.8060) |  Loss2: (0.0000) | Acc: (71.00%) (30310/42368)
Epoch: 17 | Batch_idx: 340 |  Loss: (0.8044) |  Loss2: (0.0000) | Acc: (71.00%) (31272/43648)
Epoch: 17 | Batch_idx: 350 |  Loss: (0.8050) |  Loss2: (0.0000) | Acc: (71.00%) (32166/44928)
Epoch: 17 | Batch_idx: 360 |  Loss: (0.8044) |  Loss2: (0.0000) | Acc: (71.00%) (33085/46208)
Epoch: 17 | Batch_idx: 370 |  Loss: (0.8049) |  Loss2: (0.0000) | Acc: (71.00%) (33993/47488)
Epoch: 17 | Batch_idx: 380 |  Loss: (0.8043) |  Loss2: (0.0000) | Acc: (71.00%) (34928/48768)
Epoch: 17 | Batch_idx: 390 |  Loss: (0.8054) |  Loss2: (0.0000) | Acc: (71.00%) (35786/50000)
# TEST : Loss: (0.8124) | Acc: (71.00%) (7119/10000)
percent tensor([0.5058, 0.5053, 0.5076, 0.5090, 0.5064, 0.5075, 0.5055, 0.5074, 0.5031,
        0.5070, 0.5037, 0.5068, 0.5050, 0.5056, 0.5070, 0.5080],
       device='cuda:0') torch.Size([16])
percent tensor([0.4959, 0.4886, 0.4928, 0.4976, 0.4911, 0.5037, 0.4875, 0.4907, 0.4935,
        0.4895, 0.4938, 0.4898, 0.4923, 0.4902, 0.4941, 0.4953],
       device='cuda:0') torch.Size([16])
percent tensor([0.5024, 0.4262, 0.5418, 0.5342, 0.5390, 0.5256, 0.4768, 0.5359, 0.4953,
        0.4532, 0.4400, 0.5101, 0.4474, 0.4562, 0.4804, 0.5049],
       device='cuda:0') torch.Size([16])
percent tensor([0.5851, 0.5957, 0.5604, 0.5710, 0.5657, 0.5771, 0.5849, 0.5712, 0.5864,
        0.5906, 0.5944, 0.5767, 0.5954, 0.5914, 0.5918, 0.5868],
       device='cuda:0') torch.Size([16])
percent tensor([0.5528, 0.5236, 0.5513, 0.5685, 0.5551, 0.5758, 0.5414, 0.5531, 0.5415,
        0.5208, 0.5316, 0.5383, 0.5293, 0.5451, 0.5399, 0.5622],
       device='cuda:0') torch.Size([16])
percent tensor([0.4766, 0.4743, 0.4944, 0.5164, 0.5028, 0.5170, 0.4775, 0.4698, 0.4884,
        0.4665, 0.4711, 0.4756, 0.4713, 0.4932, 0.4616, 0.4830],
       device='cuda:0') torch.Size([16])
percent tensor([0.5197, 0.5222, 0.5973, 0.5937, 0.6004, 0.5171, 0.5713, 0.6354, 0.5240,
        0.5409, 0.5306, 0.5892, 0.4987, 0.5166, 0.5578, 0.5339],
       device='cuda:0') torch.Size([16])
percent tensor([0.9959, 0.9733, 0.9951, 0.9954, 0.9956, 0.9911, 0.9947, 0.9991, 0.9712,
        0.9872, 0.9835, 0.9960, 0.9851, 0.9803, 0.9915, 0.9976],
       device='cuda:0') torch.Size([16])
True Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=128, out_features=16, bias=False)
False Linear(in_features=16, out_features=2, bias=False)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=128, out_features=16, bias=False)
False Linear(in_features=16, out_features=2, bias=False)
True Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=256, out_features=32, bias=False)
False Linear(in_features=32, out_features=2, bias=False)
True Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=256, out_features=32, bias=False)
False Linear(in_features=32, out_features=2, bias=False)
True Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=512, out_features=64, bias=False)
False Linear(in_features=64, out_features=2, bias=False)
True Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=512, out_features=64, bias=False)
False Linear(in_features=64, out_features=2, bias=False)
True Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1024, out_features=128, bias=False)
False Linear(in_features=128, out_features=2, bias=False)
True Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1024, out_features=128, bias=False)
False Linear(in_features=128, out_features=2, bias=False)
True Linear(in_features=512, out_features=10, bias=True)
Epoch: 18 | Batch_idx: 0 |  Loss: (0.7747) |  Loss2: (0.0000) | Acc: (75.00%) (97/128)
Epoch: 18 | Batch_idx: 10 |  Loss: (0.7720) |  Loss2: (0.0000) | Acc: (73.00%) (1033/1408)
Epoch: 18 | Batch_idx: 20 |  Loss: (0.7883) |  Loss2: (0.0000) | Acc: (71.00%) (1933/2688)
Epoch: 18 | Batch_idx: 30 |  Loss: (0.7888) |  Loss2: (0.0000) | Acc: (72.00%) (2863/3968)
Epoch: 18 | Batch_idx: 40 |  Loss: (0.7860) |  Loss2: (0.0000) | Acc: (72.00%) (3790/5248)
Epoch: 18 | Batch_idx: 50 |  Loss: (0.7818) |  Loss2: (0.0000) | Acc: (72.00%) (4728/6528)
Epoch: 18 | Batch_idx: 60 |  Loss: (0.7766) |  Loss2: (0.0000) | Acc: (72.00%) (5665/7808)
Epoch: 18 | Batch_idx: 70 |  Loss: (0.7766) |  Loss2: (0.0000) | Acc: (72.00%) (6597/9088)
Epoch: 18 | Batch_idx: 80 |  Loss: (0.7796) |  Loss2: (0.0000) | Acc: (72.00%) (7520/10368)
Epoch: 18 | Batch_idx: 90 |  Loss: (0.7775) |  Loss2: (0.0000) | Acc: (72.00%) (8474/11648)
Epoch: 18 | Batch_idx: 100 |  Loss: (0.7807) |  Loss2: (0.0000) | Acc: (72.00%) (9392/12928)
Epoch: 18 | Batch_idx: 110 |  Loss: (0.7773) |  Loss2: (0.0000) | Acc: (72.00%) (10333/14208)
Epoch: 18 | Batch_idx: 120 |  Loss: (0.7773) |  Loss2: (0.0000) | Acc: (72.00%) (11251/15488)
Epoch: 18 | Batch_idx: 130 |  Loss: (0.7809) |  Loss2: (0.0000) | Acc: (72.00%) (12144/16768)
Epoch: 18 | Batch_idx: 140 |  Loss: (0.7817) |  Loss2: (0.0000) | Acc: (72.00%) (13082/18048)
Epoch: 18 | Batch_idx: 150 |  Loss: (0.7829) |  Loss2: (0.0000) | Acc: (72.00%) (14009/19328)
Epoch: 18 | Batch_idx: 160 |  Loss: (0.7855) |  Loss2: (0.0000) | Acc: (72.00%) (14901/20608)
Epoch: 18 | Batch_idx: 170 |  Loss: (0.7852) |  Loss2: (0.0000) | Acc: (72.00%) (15835/21888)
Epoch: 18 | Batch_idx: 180 |  Loss: (0.7846) |  Loss2: (0.0000) | Acc: (72.00%) (16772/23168)
Epoch: 18 | Batch_idx: 190 |  Loss: (0.7843) |  Loss2: (0.0000) | Acc: (72.00%) (17691/24448)
Epoch: 18 | Batch_idx: 200 |  Loss: (0.7862) |  Loss2: (0.0000) | Acc: (72.00%) (18604/25728)
Epoch: 18 | Batch_idx: 210 |  Loss: (0.7880) |  Loss2: (0.0000) | Acc: (72.00%) (19488/27008)
Epoch: 18 | Batch_idx: 220 |  Loss: (0.7899) |  Loss2: (0.0000) | Acc: (72.00%) (20404/28288)
Epoch: 18 | Batch_idx: 230 |  Loss: (0.7895) |  Loss2: (0.0000) | Acc: (72.00%) (21328/29568)
Epoch: 18 | Batch_idx: 240 |  Loss: (0.7891) |  Loss2: (0.0000) | Acc: (72.00%) (22263/30848)
Epoch: 18 | Batch_idx: 250 |  Loss: (0.7899) |  Loss2: (0.0000) | Acc: (72.00%) (23169/32128)
Epoch: 18 | Batch_idx: 260 |  Loss: (0.7892) |  Loss2: (0.0000) | Acc: (72.00%) (24098/33408)
Epoch: 18 | Batch_idx: 270 |  Loss: (0.7879) |  Loss2: (0.0000) | Acc: (72.00%) (25046/34688)
Epoch: 18 | Batch_idx: 280 |  Loss: (0.7873) |  Loss2: (0.0000) | Acc: (72.00%) (25985/35968)
Epoch: 18 | Batch_idx: 290 |  Loss: (0.7872) |  Loss2: (0.0000) | Acc: (72.00%) (26898/37248)
Epoch: 18 | Batch_idx: 300 |  Loss: (0.7876) |  Loss2: (0.0000) | Acc: (72.00%) (27797/38528)
Epoch: 18 | Batch_idx: 310 |  Loss: (0.7884) |  Loss2: (0.0000) | Acc: (72.00%) (28714/39808)
Epoch: 18 | Batch_idx: 320 |  Loss: (0.7877) |  Loss2: (0.0000) | Acc: (72.00%) (29643/41088)
Epoch: 18 | Batch_idx: 330 |  Loss: (0.7872) |  Loss2: (0.0000) | Acc: (72.00%) (30580/42368)
Epoch: 18 | Batch_idx: 340 |  Loss: (0.7868) |  Loss2: (0.0000) | Acc: (72.00%) (31510/43648)
Epoch: 18 | Batch_idx: 350 |  Loss: (0.7874) |  Loss2: (0.0000) | Acc: (72.00%) (32423/44928)
Epoch: 18 | Batch_idx: 360 |  Loss: (0.7869) |  Loss2: (0.0000) | Acc: (72.00%) (33331/46208)
Epoch: 18 | Batch_idx: 370 |  Loss: (0.7869) |  Loss2: (0.0000) | Acc: (72.00%) (34257/47488)
Epoch: 18 | Batch_idx: 380 |  Loss: (0.7849) |  Loss2: (0.0000) | Acc: (72.00%) (35220/48768)
Epoch: 18 | Batch_idx: 390 |  Loss: (0.7855) |  Loss2: (0.0000) | Acc: (72.00%) (36104/50000)
# TEST : Loss: (0.9110) | Acc: (68.00%) (6853/10000)
percent tensor([0.5059, 0.5057, 0.5083, 0.5094, 0.5068, 0.5073, 0.5056, 0.5073, 0.5036,
        0.5069, 0.5040, 0.5071, 0.5049, 0.5062, 0.5071, 0.5081],
       device='cuda:0') torch.Size([16])
percent tensor([0.4959, 0.4889, 0.4934, 0.4976, 0.4917, 0.5040, 0.4879, 0.4913, 0.4935,
        0.4901, 0.4939, 0.4907, 0.4920, 0.4904, 0.4943, 0.4953],
       device='cuda:0') torch.Size([16])
percent tensor([0.5061, 0.4323, 0.5431, 0.5331, 0.5383, 0.5210, 0.4821, 0.5409, 0.5101,
        0.4576, 0.4464, 0.5106, 0.4539, 0.4710, 0.4775, 0.5069],
       device='cuda:0') torch.Size([16])
percent tensor([0.5845, 0.5955, 0.5583, 0.5693, 0.5624, 0.5762, 0.5843, 0.5692, 0.5834,
        0.5903, 0.5934, 0.5768, 0.5943, 0.5903, 0.5923, 0.5866],
       device='cuda:0') torch.Size([16])
percent tensor([0.5550, 0.5290, 0.5472, 0.5635, 0.5501, 0.5768, 0.5425, 0.5507, 0.5448,
        0.5275, 0.5329, 0.5393, 0.5355, 0.5491, 0.5437, 0.5654],
       device='cuda:0') torch.Size([16])
percent tensor([0.4769, 0.4760, 0.4939, 0.5111, 0.5003, 0.5177, 0.4764, 0.4688, 0.4946,
        0.4754, 0.4718, 0.4783, 0.4747, 0.5015, 0.4620, 0.4822],
       device='cuda:0') torch.Size([16])
percent tensor([0.5272, 0.5191, 0.5901, 0.5980, 0.5956, 0.5259, 0.5662, 0.6120, 0.5323,
        0.5422, 0.5305, 0.5713, 0.5002, 0.5165, 0.5523, 0.5432],
       device='cuda:0') torch.Size([16])
percent tensor([0.9970, 0.9795, 0.9927, 0.9943, 0.9943, 0.9953, 0.9966, 0.9989, 0.9693,
        0.9890, 0.9818, 0.9936, 0.9815, 0.9842, 0.9934, 0.9992],
       device='cuda:0') torch.Size([16])
Epoch: 19 | Batch_idx: 0 |  Loss: (0.7436) |  Loss2: (0.0000) | Acc: (75.00%) (96/128)
Epoch: 19 | Batch_idx: 10 |  Loss: (0.7226) |  Loss2: (0.0000) | Acc: (73.00%) (1038/1408)
Epoch: 19 | Batch_idx: 20 |  Loss: (0.7437) |  Loss2: (0.0000) | Acc: (73.00%) (1975/2688)
Epoch: 19 | Batch_idx: 30 |  Loss: (0.7457) |  Loss2: (0.0000) | Acc: (73.00%) (2911/3968)
Epoch: 19 | Batch_idx: 40 |  Loss: (0.7459) |  Loss2: (0.0000) | Acc: (73.00%) (3860/5248)
Epoch: 19 | Batch_idx: 50 |  Loss: (0.7367) |  Loss2: (0.0000) | Acc: (73.00%) (4827/6528)
Epoch: 19 | Batch_idx: 60 |  Loss: (0.7426) |  Loss2: (0.0000) | Acc: (73.00%) (5752/7808)
Epoch: 19 | Batch_idx: 70 |  Loss: (0.7444) |  Loss2: (0.0000) | Acc: (73.00%) (6707/9088)
Epoch: 19 | Batch_idx: 80 |  Loss: (0.7460) |  Loss2: (0.0000) | Acc: (73.00%) (7667/10368)
Epoch: 19 | Batch_idx: 90 |  Loss: (0.7468) |  Loss2: (0.0000) | Acc: (73.00%) (8597/11648)
Epoch: 19 | Batch_idx: 100 |  Loss: (0.7485) |  Loss2: (0.0000) | Acc: (73.00%) (9535/12928)
Epoch: 19 | Batch_idx: 110 |  Loss: (0.7427) |  Loss2: (0.0000) | Acc: (74.00%) (10519/14208)
Epoch: 19 | Batch_idx: 120 |  Loss: (0.7423) |  Loss2: (0.0000) | Acc: (74.00%) (11483/15488)
Epoch: 19 | Batch_idx: 130 |  Loss: (0.7413) |  Loss2: (0.0000) | Acc: (74.00%) (12433/16768)
Epoch: 19 | Batch_idx: 140 |  Loss: (0.7417) |  Loss2: (0.0000) | Acc: (74.00%) (13383/18048)
Epoch: 19 | Batch_idx: 150 |  Loss: (0.7432) |  Loss2: (0.0000) | Acc: (74.00%) (14312/19328)
Epoch: 19 | Batch_idx: 160 |  Loss: (0.7456) |  Loss2: (0.0000) | Acc: (73.00%) (15240/20608)
Epoch: 19 | Batch_idx: 170 |  Loss: (0.7458) |  Loss2: (0.0000) | Acc: (73.00%) (16188/21888)
Epoch: 19 | Batch_idx: 180 |  Loss: (0.7446) |  Loss2: (0.0000) | Acc: (73.00%) (17128/23168)
Epoch: 19 | Batch_idx: 190 |  Loss: (0.7444) |  Loss2: (0.0000) | Acc: (73.00%) (18079/24448)
Epoch: 19 | Batch_idx: 200 |  Loss: (0.7455) |  Loss2: (0.0000) | Acc: (73.00%) (19008/25728)
Epoch: 19 | Batch_idx: 210 |  Loss: (0.7433) |  Loss2: (0.0000) | Acc: (73.00%) (19967/27008)
Epoch: 19 | Batch_idx: 220 |  Loss: (0.7401) |  Loss2: (0.0000) | Acc: (74.00%) (20963/28288)
Epoch: 19 | Batch_idx: 230 |  Loss: (0.7399) |  Loss2: (0.0000) | Acc: (74.00%) (21912/29568)
Epoch: 19 | Batch_idx: 240 |  Loss: (0.7397) |  Loss2: (0.0000) | Acc: (74.00%) (22858/30848)
Epoch: 19 | Batch_idx: 250 |  Loss: (0.7398) |  Loss2: (0.0000) | Acc: (74.00%) (23800/32128)
Epoch: 19 | Batch_idx: 260 |  Loss: (0.7380) |  Loss2: (0.0000) | Acc: (74.00%) (24777/33408)
Epoch: 19 | Batch_idx: 270 |  Loss: (0.7392) |  Loss2: (0.0000) | Acc: (74.00%) (25707/34688)
Epoch: 19 | Batch_idx: 280 |  Loss: (0.7394) |  Loss2: (0.0000) | Acc: (74.00%) (26650/35968)
Epoch: 19 | Batch_idx: 290 |  Loss: (0.7403) |  Loss2: (0.0000) | Acc: (74.00%) (27570/37248)
Epoch: 19 | Batch_idx: 300 |  Loss: (0.7417) |  Loss2: (0.0000) | Acc: (73.00%) (28495/38528)
Epoch: 19 | Batch_idx: 310 |  Loss: (0.7419) |  Loss2: (0.0000) | Acc: (73.00%) (29444/39808)
Epoch: 19 | Batch_idx: 320 |  Loss: (0.7414) |  Loss2: (0.0000) | Acc: (73.00%) (30389/41088)
Epoch: 19 | Batch_idx: 330 |  Loss: (0.7406) |  Loss2: (0.0000) | Acc: (73.00%) (31348/42368)
Epoch: 19 | Batch_idx: 340 |  Loss: (0.7406) |  Loss2: (0.0000) | Acc: (73.00%) (32292/43648)
Epoch: 19 | Batch_idx: 350 |  Loss: (0.7390) |  Loss2: (0.0000) | Acc: (74.00%) (33273/44928)
Epoch: 19 | Batch_idx: 360 |  Loss: (0.7378) |  Loss2: (0.0000) | Acc: (74.00%) (34237/46208)
Epoch: 19 | Batch_idx: 370 |  Loss: (0.7383) |  Loss2: (0.0000) | Acc: (74.00%) (35170/47488)
Epoch: 19 | Batch_idx: 380 |  Loss: (0.7391) |  Loss2: (0.0000) | Acc: (73.00%) (36086/48768)
Epoch: 19 | Batch_idx: 390 |  Loss: (0.7386) |  Loss2: (0.0000) | Acc: (74.00%) (37008/50000)
# TEST : Loss: (0.8176) | Acc: (72.00%) (7215/10000)
percent tensor([0.5052, 0.5052, 0.5074, 0.5090, 0.5059, 0.5062, 0.5051, 0.5072, 0.5028,
        0.5064, 0.5034, 0.5063, 0.5042, 0.5060, 0.5066, 0.5078],
       device='cuda:0') torch.Size([16])
percent tensor([0.4954, 0.4890, 0.4939, 0.4977, 0.4913, 0.5029, 0.4882, 0.4913, 0.4936,
        0.4898, 0.4936, 0.4910, 0.4918, 0.4913, 0.4938, 0.4950],
       device='cuda:0') torch.Size([16])
percent tensor([0.4997, 0.4257, 0.5486, 0.5327, 0.5421, 0.5166, 0.4791, 0.5398, 0.4991,
        0.4575, 0.4388, 0.5159, 0.4470, 0.4578, 0.4738, 0.5014],
       device='cuda:0') torch.Size([16])
percent tensor([0.5837, 0.5957, 0.5593, 0.5694, 0.5631, 0.5750, 0.5841, 0.5691, 0.5853,
        0.5902, 0.5954, 0.5784, 0.5943, 0.5930, 0.5923, 0.5839],
       device='cuda:0') torch.Size([16])
percent tensor([0.5522, 0.5236, 0.5480, 0.5631, 0.5513, 0.5712, 0.5410, 0.5483, 0.5425,
        0.5255, 0.5291, 0.5419, 0.5312, 0.5480, 0.5401, 0.5604],
       device='cuda:0') torch.Size([16])
percent tensor([0.4710, 0.4707, 0.4975, 0.5120, 0.5025, 0.5170, 0.4740, 0.4679, 0.4840,
        0.4698, 0.4629, 0.4789, 0.4661, 0.4962, 0.4583, 0.4816],
       device='cuda:0') torch.Size([16])
percent tensor([0.5296, 0.5254, 0.5975, 0.5965, 0.6011, 0.5279, 0.5722, 0.6311, 0.5275,
        0.5541, 0.5319, 0.5818, 0.5053, 0.5201, 0.5612, 0.5418],
       device='cuda:0') torch.Size([16])
percent tensor([0.9939, 0.9845, 0.9953, 0.9945, 0.9966, 0.9876, 0.9950, 0.9993, 0.9769,
        0.9929, 0.9883, 0.9949, 0.9835, 0.9836, 0.9952, 0.9968],
       device='cuda:0') torch.Size([16])
Epoch: 20 | Batch_idx: 0 |  Loss: (0.6200) |  Loss2: (0.0000) | Acc: (78.00%) (100/128)
Epoch: 20 | Batch_idx: 10 |  Loss: (0.7026) |  Loss2: (0.0000) | Acc: (75.00%) (1057/1408)
Epoch: 20 | Batch_idx: 20 |  Loss: (0.7144) |  Loss2: (0.0000) | Acc: (74.00%) (2004/2688)
Epoch: 20 | Batch_idx: 30 |  Loss: (0.7243) |  Loss2: (0.0000) | Acc: (74.00%) (2937/3968)
Epoch: 20 | Batch_idx: 40 |  Loss: (0.7174) |  Loss2: (0.0000) | Acc: (74.00%) (3902/5248)
Epoch: 20 | Batch_idx: 50 |  Loss: (0.7174) |  Loss2: (0.0000) | Acc: (74.00%) (4849/6528)
Epoch: 20 | Batch_idx: 60 |  Loss: (0.7203) |  Loss2: (0.0000) | Acc: (74.00%) (5783/7808)
Epoch: 20 | Batch_idx: 70 |  Loss: (0.7155) |  Loss2: (0.0000) | Acc: (74.00%) (6760/9088)
Epoch: 20 | Batch_idx: 80 |  Loss: (0.7106) |  Loss2: (0.0000) | Acc: (74.00%) (7738/10368)
Epoch: 20 | Batch_idx: 90 |  Loss: (0.7075) |  Loss2: (0.0000) | Acc: (74.00%) (8716/11648)
Epoch: 20 | Batch_idx: 100 |  Loss: (0.7090) |  Loss2: (0.0000) | Acc: (74.00%) (9656/12928)
Epoch: 20 | Batch_idx: 110 |  Loss: (0.7095) |  Loss2: (0.0000) | Acc: (74.00%) (10617/14208)
Epoch: 20 | Batch_idx: 120 |  Loss: (0.7096) |  Loss2: (0.0000) | Acc: (74.00%) (11585/15488)
Epoch: 20 | Batch_idx: 130 |  Loss: (0.7108) |  Loss2: (0.0000) | Acc: (74.00%) (12545/16768)
Epoch: 20 | Batch_idx: 140 |  Loss: (0.7075) |  Loss2: (0.0000) | Acc: (74.00%) (13529/18048)
Epoch: 20 | Batch_idx: 150 |  Loss: (0.7041) |  Loss2: (0.0000) | Acc: (75.00%) (14513/19328)
Epoch: 20 | Batch_idx: 160 |  Loss: (0.7018) |  Loss2: (0.0000) | Acc: (75.00%) (15499/20608)
Epoch: 20 | Batch_idx: 170 |  Loss: (0.7005) |  Loss2: (0.0000) | Acc: (75.00%) (16480/21888)
Epoch: 20 | Batch_idx: 180 |  Loss: (0.7007) |  Loss2: (0.0000) | Acc: (75.00%) (17439/23168)
Epoch: 20 | Batch_idx: 190 |  Loss: (0.6988) |  Loss2: (0.0000) | Acc: (75.00%) (18430/24448)
Epoch: 20 | Batch_idx: 200 |  Loss: (0.6991) |  Loss2: (0.0000) | Acc: (75.00%) (19399/25728)
Epoch: 20 | Batch_idx: 210 |  Loss: (0.6991) |  Loss2: (0.0000) | Acc: (75.00%) (20362/27008)
Epoch: 20 | Batch_idx: 220 |  Loss: (0.7004) |  Loss2: (0.0000) | Acc: (75.00%) (21322/28288)
Epoch: 20 | Batch_idx: 230 |  Loss: (0.6973) |  Loss2: (0.0000) | Acc: (75.00%) (22317/29568)
Epoch: 20 | Batch_idx: 240 |  Loss: (0.6977) |  Loss2: (0.0000) | Acc: (75.00%) (23287/30848)
Epoch: 20 | Batch_idx: 250 |  Loss: (0.6956) |  Loss2: (0.0000) | Acc: (75.00%) (24262/32128)
Epoch: 20 | Batch_idx: 260 |  Loss: (0.6961) |  Loss2: (0.0000) | Acc: (75.00%) (25222/33408)
Epoch: 20 | Batch_idx: 270 |  Loss: (0.6968) |  Loss2: (0.0000) | Acc: (75.00%) (26179/34688)
Epoch: 20 | Batch_idx: 280 |  Loss: (0.6943) |  Loss2: (0.0000) | Acc: (75.00%) (27186/35968)
Epoch: 20 | Batch_idx: 290 |  Loss: (0.6943) |  Loss2: (0.0000) | Acc: (75.00%) (28150/37248)
Epoch: 20 | Batch_idx: 300 |  Loss: (0.6942) |  Loss2: (0.0000) | Acc: (75.00%) (29120/38528)
Epoch: 20 | Batch_idx: 310 |  Loss: (0.6944) |  Loss2: (0.0000) | Acc: (75.00%) (30091/39808)
Epoch: 20 | Batch_idx: 320 |  Loss: (0.6938) |  Loss2: (0.0000) | Acc: (75.00%) (31059/41088)
Epoch: 20 | Batch_idx: 330 |  Loss: (0.6938) |  Loss2: (0.0000) | Acc: (75.00%) (32028/42368)
Epoch: 20 | Batch_idx: 340 |  Loss: (0.6945) |  Loss2: (0.0000) | Acc: (75.00%) (32991/43648)
Epoch: 20 | Batch_idx: 350 |  Loss: (0.6941) |  Loss2: (0.0000) | Acc: (75.00%) (33971/44928)
Epoch: 20 | Batch_idx: 360 |  Loss: (0.6931) |  Loss2: (0.0000) | Acc: (75.00%) (34954/46208)
Epoch: 20 | Batch_idx: 370 |  Loss: (0.6939) |  Loss2: (0.0000) | Acc: (75.00%) (35919/47488)
Epoch: 20 | Batch_idx: 380 |  Loss: (0.6935) |  Loss2: (0.0000) | Acc: (75.00%) (36890/48768)
Epoch: 20 | Batch_idx: 390 |  Loss: (0.6928) |  Loss2: (0.0000) | Acc: (75.00%) (37823/50000)
=> saving checkpoint 'drive/app/torch/save_Schedule/checkpoint_020.pth.tar'
# TEST : Loss: (0.7422) | Acc: (73.00%) (7390/10000)
percent tensor([0.5054, 0.5050, 0.5067, 0.5089, 0.5057, 0.5070, 0.5050, 0.5066, 0.5032,
        0.5063, 0.5033, 0.5060, 0.5047, 0.5055, 0.5066, 0.5078],
       device='cuda:0') torch.Size([16])
percent tensor([0.4952, 0.4895, 0.4941, 0.4978, 0.4913, 0.5027, 0.4884, 0.4918, 0.4935,
        0.4900, 0.4933, 0.4913, 0.4915, 0.4919, 0.4938, 0.4951],
       device='cuda:0') torch.Size([16])
percent tensor([0.4962, 0.4255, 0.5440, 0.5288, 0.5373, 0.5168, 0.4760, 0.5372, 0.4931,
        0.4580, 0.4376, 0.5104, 0.4457, 0.4520, 0.4748, 0.5011],
       device='cuda:0') torch.Size([16])
percent tensor([0.5861, 0.5949, 0.5612, 0.5723, 0.5650, 0.5791, 0.5851, 0.5707, 0.5890,
        0.5902, 0.5958, 0.5807, 0.5978, 0.5941, 0.5926, 0.5863],
       device='cuda:0') torch.Size([16])
percent tensor([0.5515, 0.5269, 0.5434, 0.5614, 0.5495, 0.5685, 0.5380, 0.5494, 0.5383,
        0.5265, 0.5293, 0.5402, 0.5322, 0.5429, 0.5439, 0.5611],
       device='cuda:0') torch.Size([16])
percent tensor([0.4703, 0.4709, 0.4887, 0.5046, 0.4950, 0.5161, 0.4675, 0.4728, 0.4779,
        0.4685, 0.4622, 0.4756, 0.4667, 0.4875, 0.4646, 0.4786],
       device='cuda:0') torch.Size([16])
percent tensor([0.5261, 0.5236, 0.5939, 0.5936, 0.6032, 0.5244, 0.5732, 0.6285, 0.5279,
        0.5465, 0.5299, 0.5739, 0.5018, 0.5244, 0.5588, 0.5403],
       device='cuda:0') torch.Size([16])
percent tensor([0.9972, 0.9856, 0.9916, 0.9935, 0.9942, 0.9907, 0.9972, 0.9985, 0.9856,
        0.9917, 0.9864, 0.9958, 0.9849, 0.9895, 0.9937, 0.9976],
       device='cuda:0') torch.Size([16])
False Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=128, out_features=16, bias=False)
True Linear(in_features=16, out_features=2, bias=False)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=128, out_features=16, bias=False)
True Linear(in_features=16, out_features=2, bias=False)
False Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=256, out_features=32, bias=False)
True Linear(in_features=32, out_features=2, bias=False)
False Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=256, out_features=32, bias=False)
True Linear(in_features=32, out_features=2, bias=False)
False Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=512, out_features=64, bias=False)
True Linear(in_features=64, out_features=2, bias=False)
False Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=512, out_features=64, bias=False)
True Linear(in_features=64, out_features=2, bias=False)
False Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1024, out_features=128, bias=False)
True Linear(in_features=128, out_features=2, bias=False)
False Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1024, out_features=128, bias=False)
True Linear(in_features=128, out_features=2, bias=False)
False Linear(in_features=512, out_features=10, bias=True)
Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 3, 3, 3]) tensor(169.8040, device='cuda:0')
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(783.7806, device='cuda:0')
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(781.8341, device='cuda:0')
Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([128, 64, 3, 3]) tensor(1529.3580, device='cuda:0')
Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([128, 64, 1, 1]) tensor(512.2964, device='cuda:0')
Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([128, 128, 3, 3]) tensor(2177.3716, device='cuda:0')
Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([256, 128, 3, 3]) tensor(4318.5791, device='cuda:0')
Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([256, 128, 1, 1]) tensor(1445.2389, device='cuda:0')
Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([256, 256, 3, 3]) tensor(6095.6055, device='cuda:0')
Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([512, 256, 3, 3]) tensor(12185.8584, device='cuda:0')
Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([512, 256, 1, 1]) tensor(4067.8979, device='cuda:0')
Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([512, 512, 3, 3]) tensor(17193.0078, device='cuda:0')
Epoch: 21 | Batch_idx: 0 |  Loss: (0.7338) |  Loss2: (0.0000) | Acc: (75.00%) (96/128)
Epoch: 21 | Batch_idx: 10 |  Loss: (0.7403) |  Loss2: (0.0000) | Acc: (73.00%) (1040/1408)
Epoch: 21 | Batch_idx: 20 |  Loss: (0.7729) |  Loss2: (0.0000) | Acc: (72.00%) (1953/2688)
Epoch: 21 | Batch_idx: 30 |  Loss: (0.8006) |  Loss2: (0.0000) | Acc: (71.00%) (2832/3968)
Epoch: 21 | Batch_idx: 40 |  Loss: (0.8105) |  Loss2: (0.0000) | Acc: (70.00%) (3718/5248)
Epoch: 21 | Batch_idx: 50 |  Loss: (0.8221) |  Loss2: (0.0000) | Acc: (70.00%) (4610/6528)
Epoch: 21 | Batch_idx: 60 |  Loss: (0.8331) |  Loss2: (0.0000) | Acc: (70.00%) (5482/7808)
Epoch: 21 | Batch_idx: 70 |  Loss: (0.8344) |  Loss2: (0.0000) | Acc: (70.00%) (6367/9088)
Epoch: 21 | Batch_idx: 80 |  Loss: (0.8300) |  Loss2: (0.0000) | Acc: (70.00%) (7309/10368)
Epoch: 21 | Batch_idx: 90 |  Loss: (0.8293) |  Loss2: (0.0000) | Acc: (70.00%) (8219/11648)
Epoch: 21 | Batch_idx: 100 |  Loss: (0.8299) |  Loss2: (0.0000) | Acc: (70.00%) (9114/12928)
Epoch: 21 | Batch_idx: 110 |  Loss: (0.8260) |  Loss2: (0.0000) | Acc: (70.00%) (10033/14208)
Epoch: 21 | Batch_idx: 120 |  Loss: (0.8212) |  Loss2: (0.0000) | Acc: (70.00%) (10954/15488)
Epoch: 21 | Batch_idx: 130 |  Loss: (0.8186) |  Loss2: (0.0000) | Acc: (70.00%) (11884/16768)
Epoch: 21 | Batch_idx: 140 |  Loss: (0.8163) |  Loss2: (0.0000) | Acc: (70.00%) (12801/18048)
Epoch: 21 | Batch_idx: 150 |  Loss: (0.8116) |  Loss2: (0.0000) | Acc: (71.00%) (13748/19328)
Epoch: 21 | Batch_idx: 160 |  Loss: (0.8094) |  Loss2: (0.0000) | Acc: (71.00%) (14676/20608)
Epoch: 21 | Batch_idx: 170 |  Loss: (0.8069) |  Loss2: (0.0000) | Acc: (71.00%) (15598/21888)
Epoch: 21 | Batch_idx: 180 |  Loss: (0.8014) |  Loss2: (0.0000) | Acc: (71.00%) (16563/23168)
Epoch: 21 | Batch_idx: 190 |  Loss: (0.7983) |  Loss2: (0.0000) | Acc: (71.00%) (17521/24448)
Epoch: 21 | Batch_idx: 200 |  Loss: (0.7960) |  Loss2: (0.0000) | Acc: (71.00%) (18476/25728)
Epoch: 21 | Batch_idx: 210 |  Loss: (0.7925) |  Loss2: (0.0000) | Acc: (71.00%) (19434/27008)
Epoch: 21 | Batch_idx: 220 |  Loss: (0.7907) |  Loss2: (0.0000) | Acc: (72.00%) (20376/28288)
Epoch: 21 | Batch_idx: 230 |  Loss: (0.7880) |  Loss2: (0.0000) | Acc: (72.00%) (21318/29568)
Epoch: 21 | Batch_idx: 240 |  Loss: (0.7851) |  Loss2: (0.0000) | Acc: (72.00%) (22270/30848)
Epoch: 21 | Batch_idx: 250 |  Loss: (0.7837) |  Loss2: (0.0000) | Acc: (72.00%) (23229/32128)
Epoch: 21 | Batch_idx: 260 |  Loss: (0.7819) |  Loss2: (0.0000) | Acc: (72.00%) (24178/33408)
Epoch: 21 | Batch_idx: 270 |  Loss: (0.7796) |  Loss2: (0.0000) | Acc: (72.00%) (25132/34688)
Epoch: 21 | Batch_idx: 280 |  Loss: (0.7790) |  Loss2: (0.0000) | Acc: (72.00%) (26065/35968)
Epoch: 21 | Batch_idx: 290 |  Loss: (0.7776) |  Loss2: (0.0000) | Acc: (72.00%) (27007/37248)
Epoch: 21 | Batch_idx: 300 |  Loss: (0.7764) |  Loss2: (0.0000) | Acc: (72.00%) (27943/38528)
Epoch: 21 | Batch_idx: 310 |  Loss: (0.7756) |  Loss2: (0.0000) | Acc: (72.00%) (28879/39808)
Epoch: 21 | Batch_idx: 320 |  Loss: (0.7745) |  Loss2: (0.0000) | Acc: (72.00%) (29828/41088)
Epoch: 21 | Batch_idx: 330 |  Loss: (0.7731) |  Loss2: (0.0000) | Acc: (72.00%) (30768/42368)
Epoch: 21 | Batch_idx: 340 |  Loss: (0.7727) |  Loss2: (0.0000) | Acc: (72.00%) (31693/43648)
Epoch: 21 | Batch_idx: 350 |  Loss: (0.7706) |  Loss2: (0.0000) | Acc: (72.00%) (32649/44928)
Epoch: 21 | Batch_idx: 360 |  Loss: (0.7696) |  Loss2: (0.0000) | Acc: (72.00%) (33592/46208)
Epoch: 21 | Batch_idx: 370 |  Loss: (0.7687) |  Loss2: (0.0000) | Acc: (72.00%) (34528/47488)
Epoch: 21 | Batch_idx: 380 |  Loss: (0.7659) |  Loss2: (0.0000) | Acc: (72.00%) (35522/48768)
Epoch: 21 | Batch_idx: 390 |  Loss: (0.7657) |  Loss2: (0.0000) | Acc: (72.00%) (36435/50000)
# TEST : Loss: (0.7327) | Acc: (74.00%) (7404/10000)
percent tensor([0.5021, 0.4990, 0.5044, 0.5062, 0.5029, 0.5036, 0.4992, 0.5031, 0.4977,
        0.5013, 0.4977, 0.5021, 0.4999, 0.4991, 0.5015, 0.5036],
       device='cuda:0') torch.Size([16])
percent tensor([0.4944, 0.4892, 0.4919, 0.4973, 0.4888, 0.5011, 0.4870, 0.4898, 0.4922,
        0.4894, 0.4928, 0.4901, 0.4913, 0.4913, 0.4928, 0.4949],
       device='cuda:0') torch.Size([16])
percent tensor([0.5029, 0.4120, 0.5648, 0.5398, 0.5564, 0.5216, 0.4779, 0.5576, 0.4873,
        0.4536, 0.4221, 0.5237, 0.4434, 0.4202, 0.4739, 0.5069],
       device='cuda:0') torch.Size([16])
percent tensor([0.5998, 0.6126, 0.5728, 0.5875, 0.5772, 0.5962, 0.6004, 0.5844, 0.6042,
        0.6050, 0.6115, 0.5956, 0.6124, 0.6146, 0.6091, 0.6028],
       device='cuda:0') torch.Size([16])
percent tensor([0.5703, 0.5236, 0.5842, 0.6048, 0.5855, 0.5961, 0.5534, 0.5910, 0.5552,
        0.5275, 0.5271, 0.5721, 0.5340, 0.5516, 0.5628, 0.5816],
       device='cuda:0') torch.Size([16])
percent tensor([0.4516, 0.4464, 0.4796, 0.4940, 0.4829, 0.5124, 0.4425, 0.4626, 0.4611,
        0.4373, 0.4331, 0.4477, 0.4426, 0.4656, 0.4431, 0.4665],
       device='cuda:0') torch.Size([16])
percent tensor([0.5558, 0.5439, 0.5858, 0.5922, 0.5952, 0.5548, 0.5773, 0.6287, 0.5454,
        0.5597, 0.5531, 0.5681, 0.5331, 0.5412, 0.5664, 0.5635],
       device='cuda:0') torch.Size([16])
percent tensor([0.9973, 0.9846, 0.9928, 0.9941, 0.9938, 0.9902, 0.9970, 0.9988, 0.9814,
        0.9914, 0.9858, 0.9966, 0.9847, 0.9869, 0.9929, 0.9973],
       device='cuda:0') torch.Size([16])
Epoch: 22 | Batch_idx: 0 |  Loss: (0.8162) |  Loss2: (0.0000) | Acc: (71.00%) (92/128)
Epoch: 22 | Batch_idx: 10 |  Loss: (0.7231) |  Loss2: (0.0000) | Acc: (75.00%) (1061/1408)
Epoch: 22 | Batch_idx: 20 |  Loss: (0.7392) |  Loss2: (0.0000) | Acc: (74.00%) (1991/2688)
Epoch: 22 | Batch_idx: 30 |  Loss: (0.7256) |  Loss2: (0.0000) | Acc: (74.00%) (2952/3968)
Epoch: 22 | Batch_idx: 40 |  Loss: (0.7287) |  Loss2: (0.0000) | Acc: (74.00%) (3885/5248)
Epoch: 22 | Batch_idx: 50 |  Loss: (0.7303) |  Loss2: (0.0000) | Acc: (73.00%) (4821/6528)
Epoch: 22 | Batch_idx: 60 |  Loss: (0.7234) |  Loss2: (0.0000) | Acc: (74.00%) (5810/7808)
Epoch: 22 | Batch_idx: 70 |  Loss: (0.7208) |  Loss2: (0.0000) | Acc: (74.00%) (6770/9088)
Epoch: 22 | Batch_idx: 80 |  Loss: (0.7202) |  Loss2: (0.0000) | Acc: (74.00%) (7733/10368)
Epoch: 22 | Batch_idx: 90 |  Loss: (0.7184) |  Loss2: (0.0000) | Acc: (74.00%) (8689/11648)
Epoch: 22 | Batch_idx: 100 |  Loss: (0.7158) |  Loss2: (0.0000) | Acc: (74.00%) (9677/12928)
Epoch: 22 | Batch_idx: 110 |  Loss: (0.7171) |  Loss2: (0.0000) | Acc: (74.00%) (10619/14208)
Epoch: 22 | Batch_idx: 120 |  Loss: (0.7189) |  Loss2: (0.0000) | Acc: (74.00%) (11559/15488)
Epoch: 22 | Batch_idx: 130 |  Loss: (0.7192) |  Loss2: (0.0000) | Acc: (74.00%) (12514/16768)
Epoch: 22 | Batch_idx: 140 |  Loss: (0.7194) |  Loss2: (0.0000) | Acc: (74.00%) (13463/18048)
Epoch: 22 | Batch_idx: 150 |  Loss: (0.7159) |  Loss2: (0.0000) | Acc: (74.00%) (14453/19328)
Epoch: 22 | Batch_idx: 160 |  Loss: (0.7155) |  Loss2: (0.0000) | Acc: (74.00%) (15411/20608)
Epoch: 22 | Batch_idx: 170 |  Loss: (0.7135) |  Loss2: (0.0000) | Acc: (74.00%) (16375/21888)
Epoch: 22 | Batch_idx: 180 |  Loss: (0.7116) |  Loss2: (0.0000) | Acc: (74.00%) (17335/23168)
Epoch: 22 | Batch_idx: 190 |  Loss: (0.7116) |  Loss2: (0.0000) | Acc: (74.00%) (18294/24448)
Epoch: 22 | Batch_idx: 200 |  Loss: (0.7101) |  Loss2: (0.0000) | Acc: (74.00%) (19267/25728)
Epoch: 22 | Batch_idx: 210 |  Loss: (0.7090) |  Loss2: (0.0000) | Acc: (74.00%) (20232/27008)
Epoch: 22 | Batch_idx: 220 |  Loss: (0.7090) |  Loss2: (0.0000) | Acc: (74.00%) (21192/28288)
Epoch: 22 | Batch_idx: 230 |  Loss: (0.7078) |  Loss2: (0.0000) | Acc: (74.00%) (22169/29568)
Epoch: 22 | Batch_idx: 240 |  Loss: (0.7078) |  Loss2: (0.0000) | Acc: (74.00%) (23118/30848)
Epoch: 22 | Batch_idx: 250 |  Loss: (0.7070) |  Loss2: (0.0000) | Acc: (74.00%) (24084/32128)
Epoch: 22 | Batch_idx: 260 |  Loss: (0.7070) |  Loss2: (0.0000) | Acc: (75.00%) (25066/33408)
Epoch: 22 | Batch_idx: 270 |  Loss: (0.7058) |  Loss2: (0.0000) | Acc: (75.00%) (26050/34688)
Epoch: 22 | Batch_idx: 280 |  Loss: (0.7052) |  Loss2: (0.0000) | Acc: (75.00%) (27045/35968)
Epoch: 22 | Batch_idx: 290 |  Loss: (0.7040) |  Loss2: (0.0000) | Acc: (75.00%) (28041/37248)
Epoch: 22 | Batch_idx: 300 |  Loss: (0.7038) |  Loss2: (0.0000) | Acc: (75.00%) (28996/38528)
Epoch: 22 | Batch_idx: 310 |  Loss: (0.7025) |  Loss2: (0.0000) | Acc: (75.00%) (29978/39808)
Epoch: 22 | Batch_idx: 320 |  Loss: (0.7017) |  Loss2: (0.0000) | Acc: (75.00%) (30970/41088)
Epoch: 22 | Batch_idx: 330 |  Loss: (0.7032) |  Loss2: (0.0000) | Acc: (75.00%) (31924/42368)
Epoch: 22 | Batch_idx: 340 |  Loss: (0.7028) |  Loss2: (0.0000) | Acc: (75.00%) (32895/43648)
Epoch: 22 | Batch_idx: 350 |  Loss: (0.7037) |  Loss2: (0.0000) | Acc: (75.00%) (33846/44928)
Epoch: 22 | Batch_idx: 360 |  Loss: (0.7033) |  Loss2: (0.0000) | Acc: (75.00%) (34821/46208)
Epoch: 22 | Batch_idx: 370 |  Loss: (0.7036) |  Loss2: (0.0000) | Acc: (75.00%) (35779/47488)
Epoch: 22 | Batch_idx: 380 |  Loss: (0.7026) |  Loss2: (0.0000) | Acc: (75.00%) (36738/48768)
Epoch: 22 | Batch_idx: 390 |  Loss: (0.7027) |  Loss2: (0.0000) | Acc: (75.00%) (37676/50000)
# TEST : Loss: (0.7020) | Acc: (75.00%) (7505/10000)
percent tensor([0.5055, 0.5033, 0.5082, 0.5093, 0.5066, 0.5062, 0.5039, 0.5071, 0.5015,
        0.5058, 0.5016, 0.5067, 0.5040, 0.5030, 0.5055, 0.5072],
       device='cuda:0') torch.Size([16])
percent tensor([0.4942, 0.4892, 0.4911, 0.4969, 0.4879, 0.5007, 0.4867, 0.4887, 0.4919,
        0.4895, 0.4929, 0.4900, 0.4915, 0.4915, 0.4923, 0.4948],
       device='cuda:0') torch.Size([16])
percent tensor([0.5119, 0.4162, 0.5833, 0.5531, 0.5726, 0.5300, 0.4881, 0.5735, 0.4989,
        0.4634, 0.4254, 0.5427, 0.4531, 0.4215, 0.4797, 0.5183],
       device='cuda:0') torch.Size([16])
percent tensor([0.6021, 0.6169, 0.5738, 0.5874, 0.5772, 0.5959, 0.6023, 0.5853, 0.6077,
        0.6078, 0.6151, 0.5973, 0.6162, 0.6200, 0.6105, 0.6046],
       device='cuda:0') torch.Size([16])
percent tensor([0.5875, 0.5360, 0.6073, 0.6279, 0.6054, 0.6123, 0.5719, 0.6120, 0.5729,
        0.5390, 0.5374, 0.5970, 0.5475, 0.5730, 0.5813, 0.5974],
       device='cuda:0') torch.Size([16])
percent tensor([0.4542, 0.4493, 0.4901, 0.5026, 0.4958, 0.5199, 0.4474, 0.4711, 0.4646,
        0.4385, 0.4322, 0.4544, 0.4427, 0.4708, 0.4471, 0.4728],
       device='cuda:0') torch.Size([16])
percent tensor([0.5879, 0.5709, 0.6021, 0.6045, 0.6079, 0.5817, 0.5987, 0.6377, 0.5703,
        0.5858, 0.5841, 0.5867, 0.5677, 0.5697, 0.5875, 0.5908],
       device='cuda:0') torch.Size([16])
percent tensor([0.9977, 0.9869, 0.9950, 0.9954, 0.9954, 0.9919, 0.9977, 0.9992, 0.9837,
        0.9933, 0.9888, 0.9974, 0.9881, 0.9888, 0.9943, 0.9978],
       device='cuda:0') torch.Size([16])
Epoch: 23 | Batch_idx: 0 |  Loss: (0.6434) |  Loss2: (0.0000) | Acc: (74.00%) (95/128)
Epoch: 23 | Batch_idx: 10 |  Loss: (0.6593) |  Loss2: (0.0000) | Acc: (75.00%) (1062/1408)
Epoch: 23 | Batch_idx: 20 |  Loss: (0.6760) |  Loss2: (0.0000) | Acc: (75.00%) (2040/2688)
Epoch: 23 | Batch_idx: 30 |  Loss: (0.6692) |  Loss2: (0.0000) | Acc: (76.00%) (3032/3968)
Epoch: 23 | Batch_idx: 40 |  Loss: (0.6684) |  Loss2: (0.0000) | Acc: (76.00%) (4007/5248)
Epoch: 23 | Batch_idx: 50 |  Loss: (0.6699) |  Loss2: (0.0000) | Acc: (76.00%) (4981/6528)
Epoch: 23 | Batch_idx: 60 |  Loss: (0.6733) |  Loss2: (0.0000) | Acc: (76.00%) (5969/7808)
Epoch: 23 | Batch_idx: 70 |  Loss: (0.6731) |  Loss2: (0.0000) | Acc: (76.00%) (6941/9088)
Epoch: 23 | Batch_idx: 80 |  Loss: (0.6755) |  Loss2: (0.0000) | Acc: (76.00%) (7904/10368)
Epoch: 23 | Batch_idx: 90 |  Loss: (0.6751) |  Loss2: (0.0000) | Acc: (76.00%) (8883/11648)
Epoch: 23 | Batch_idx: 100 |  Loss: (0.6753) |  Loss2: (0.0000) | Acc: (76.00%) (9855/12928)
Epoch: 23 | Batch_idx: 110 |  Loss: (0.6749) |  Loss2: (0.0000) | Acc: (76.00%) (10834/14208)
Epoch: 23 | Batch_idx: 120 |  Loss: (0.6745) |  Loss2: (0.0000) | Acc: (76.00%) (11813/15488)
Epoch: 23 | Batch_idx: 130 |  Loss: (0.6732) |  Loss2: (0.0000) | Acc: (76.00%) (12800/16768)
Epoch: 23 | Batch_idx: 140 |  Loss: (0.6759) |  Loss2: (0.0000) | Acc: (76.00%) (13761/18048)
Epoch: 23 | Batch_idx: 150 |  Loss: (0.6756) |  Loss2: (0.0000) | Acc: (76.00%) (14742/19328)
Epoch: 23 | Batch_idx: 160 |  Loss: (0.6764) |  Loss2: (0.0000) | Acc: (76.00%) (15716/20608)
Epoch: 23 | Batch_idx: 170 |  Loss: (0.6758) |  Loss2: (0.0000) | Acc: (76.00%) (16689/21888)
Epoch: 23 | Batch_idx: 180 |  Loss: (0.6789) |  Loss2: (0.0000) | Acc: (76.00%) (17634/23168)
Epoch: 23 | Batch_idx: 190 |  Loss: (0.6774) |  Loss2: (0.0000) | Acc: (76.00%) (18626/24448)
Epoch: 23 | Batch_idx: 200 |  Loss: (0.6790) |  Loss2: (0.0000) | Acc: (76.00%) (19586/25728)
Epoch: 23 | Batch_idx: 210 |  Loss: (0.6790) |  Loss2: (0.0000) | Acc: (76.00%) (20581/27008)
Epoch: 23 | Batch_idx: 220 |  Loss: (0.6793) |  Loss2: (0.0000) | Acc: (76.00%) (21560/28288)
Epoch: 23 | Batch_idx: 230 |  Loss: (0.6813) |  Loss2: (0.0000) | Acc: (76.00%) (22514/29568)
Epoch: 23 | Batch_idx: 240 |  Loss: (0.6812) |  Loss2: (0.0000) | Acc: (76.00%) (23482/30848)
Epoch: 23 | Batch_idx: 250 |  Loss: (0.6811) |  Loss2: (0.0000) | Acc: (76.00%) (24453/32128)
Epoch: 23 | Batch_idx: 260 |  Loss: (0.6816) |  Loss2: (0.0000) | Acc: (76.00%) (25423/33408)
Epoch: 23 | Batch_idx: 270 |  Loss: (0.6802) |  Loss2: (0.0000) | Acc: (76.00%) (26416/34688)
Epoch: 23 | Batch_idx: 280 |  Loss: (0.6815) |  Loss2: (0.0000) | Acc: (76.00%) (27371/35968)
Epoch: 23 | Batch_idx: 290 |  Loss: (0.6819) |  Loss2: (0.0000) | Acc: (76.00%) (28343/37248)
Epoch: 23 | Batch_idx: 300 |  Loss: (0.6817) |  Loss2: (0.0000) | Acc: (76.00%) (29312/38528)
Epoch: 23 | Batch_idx: 310 |  Loss: (0.6823) |  Loss2: (0.0000) | Acc: (76.00%) (30282/39808)
Epoch: 23 | Batch_idx: 320 |  Loss: (0.6827) |  Loss2: (0.0000) | Acc: (76.00%) (31247/41088)
Epoch: 23 | Batch_idx: 330 |  Loss: (0.6831) |  Loss2: (0.0000) | Acc: (76.00%) (32235/42368)
Epoch: 23 | Batch_idx: 340 |  Loss: (0.6833) |  Loss2: (0.0000) | Acc: (76.00%) (33195/43648)
Epoch: 23 | Batch_idx: 350 |  Loss: (0.6827) |  Loss2: (0.0000) | Acc: (76.00%) (34178/44928)
Epoch: 23 | Batch_idx: 360 |  Loss: (0.6827) |  Loss2: (0.0000) | Acc: (76.00%) (35139/46208)
Epoch: 23 | Batch_idx: 370 |  Loss: (0.6827) |  Loss2: (0.0000) | Acc: (76.00%) (36106/47488)
Epoch: 23 | Batch_idx: 380 |  Loss: (0.6831) |  Loss2: (0.0000) | Acc: (76.00%) (37071/48768)
Epoch: 23 | Batch_idx: 390 |  Loss: (0.6834) |  Loss2: (0.0000) | Acc: (75.00%) (37995/50000)
# TEST : Loss: (0.6885) | Acc: (75.00%) (7538/10000)
percent tensor([0.5079, 0.5065, 0.5110, 0.5115, 0.5093, 0.5081, 0.5072, 0.5101, 0.5043,
        0.5090, 0.5045, 0.5099, 0.5068, 0.5060, 0.5084, 0.5098],
       device='cuda:0') torch.Size([16])
percent tensor([0.4937, 0.4887, 0.4900, 0.4964, 0.4866, 0.5005, 0.4857, 0.4874, 0.4911,
        0.4888, 0.4925, 0.4892, 0.4911, 0.4911, 0.4918, 0.4946],
       device='cuda:0') torch.Size([16])
percent tensor([0.5150, 0.4186, 0.5954, 0.5609, 0.5821, 0.5300, 0.4926, 0.5835, 0.5072,
        0.4691, 0.4266, 0.5555, 0.4593, 0.4237, 0.4793, 0.5232],
       device='cuda:0') torch.Size([16])
percent tensor([0.6026, 0.6183, 0.5737, 0.5865, 0.5760, 0.5944, 0.6023, 0.5849, 0.6091,
        0.6085, 0.6163, 0.5972, 0.6176, 0.6221, 0.6102, 0.6044],
       device='cuda:0') torch.Size([16])
percent tensor([0.5909, 0.5424, 0.6082, 0.6286, 0.6038, 0.6103, 0.5767, 0.6105, 0.5793,
        0.5438, 0.5431, 0.6022, 0.5540, 0.5846, 0.5857, 0.5987],
       device='cuda:0') torch.Size([16])
percent tensor([0.4612, 0.4573, 0.4997, 0.5126, 0.5081, 0.5301, 0.4563, 0.4808, 0.4711,
        0.4441, 0.4369, 0.4608, 0.4476, 0.4807, 0.4544, 0.4821],
       device='cuda:0') torch.Size([16])
percent tensor([0.6087, 0.5887, 0.6032, 0.6035, 0.6077, 0.5970, 0.6086, 0.6293, 0.5864,
        0.6015, 0.6044, 0.5908, 0.5929, 0.5881, 0.5962, 0.6080],
       device='cuda:0') torch.Size([16])
percent tensor([0.9984, 0.9891, 0.9960, 0.9962, 0.9964, 0.9939, 0.9984, 0.9994, 0.9862,
        0.9948, 0.9911, 0.9978, 0.9910, 0.9912, 0.9955, 0.9986],
       device='cuda:0') torch.Size([16])
True Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=128, out_features=16, bias=False)
False Linear(in_features=16, out_features=2, bias=False)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=128, out_features=16, bias=False)
False Linear(in_features=16, out_features=2, bias=False)
True Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=256, out_features=32, bias=False)
False Linear(in_features=32, out_features=2, bias=False)
True Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=256, out_features=32, bias=False)
False Linear(in_features=32, out_features=2, bias=False)
True Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=512, out_features=64, bias=False)
False Linear(in_features=64, out_features=2, bias=False)
True Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=512, out_features=64, bias=False)
False Linear(in_features=64, out_features=2, bias=False)
True Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1024, out_features=128, bias=False)
False Linear(in_features=128, out_features=2, bias=False)
True Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1024, out_features=128, bias=False)
False Linear(in_features=128, out_features=2, bias=False)
True Linear(in_features=512, out_features=10, bias=True)
Epoch: 24 | Batch_idx: 0 |  Loss: (0.7642) |  Loss2: (0.0000) | Acc: (72.00%) (93/128)
Epoch: 24 | Batch_idx: 10 |  Loss: (0.6786) |  Loss2: (0.0000) | Acc: (76.00%) (1076/1408)
Epoch: 24 | Batch_idx: 20 |  Loss: (0.6563) |  Loss2: (0.0000) | Acc: (77.00%) (2091/2688)
Epoch: 24 | Batch_idx: 30 |  Loss: (0.6578) |  Loss2: (0.0000) | Acc: (77.00%) (3079/3968)
Epoch: 24 | Batch_idx: 40 |  Loss: (0.6605) |  Loss2: (0.0000) | Acc: (77.00%) (4061/5248)
Epoch: 24 | Batch_idx: 50 |  Loss: (0.6590) |  Loss2: (0.0000) | Acc: (77.00%) (5054/6528)
Epoch: 24 | Batch_idx: 60 |  Loss: (0.6570) |  Loss2: (0.0000) | Acc: (77.00%) (6037/7808)
Epoch: 24 | Batch_idx: 70 |  Loss: (0.6560) |  Loss2: (0.0000) | Acc: (77.00%) (7032/9088)
Epoch: 24 | Batch_idx: 80 |  Loss: (0.6576) |  Loss2: (0.0000) | Acc: (77.00%) (8008/10368)
Epoch: 24 | Batch_idx: 90 |  Loss: (0.6597) |  Loss2: (0.0000) | Acc: (77.00%) (8991/11648)
Epoch: 24 | Batch_idx: 100 |  Loss: (0.6612) |  Loss2: (0.0000) | Acc: (77.00%) (9977/12928)
Epoch: 24 | Batch_idx: 110 |  Loss: (0.6596) |  Loss2: (0.0000) | Acc: (77.00%) (10987/14208)
Epoch: 24 | Batch_idx: 120 |  Loss: (0.6586) |  Loss2: (0.0000) | Acc: (77.00%) (11977/15488)
Epoch: 24 | Batch_idx: 130 |  Loss: (0.6588) |  Loss2: (0.0000) | Acc: (77.00%) (12961/16768)
Epoch: 24 | Batch_idx: 140 |  Loss: (0.6593) |  Loss2: (0.0000) | Acc: (77.00%) (13927/18048)
Epoch: 24 | Batch_idx: 150 |  Loss: (0.6622) |  Loss2: (0.0000) | Acc: (77.00%) (14906/19328)
Epoch: 24 | Batch_idx: 160 |  Loss: (0.6622) |  Loss2: (0.0000) | Acc: (77.00%) (15896/20608)
Epoch: 24 | Batch_idx: 170 |  Loss: (0.6609) |  Loss2: (0.0000) | Acc: (77.00%) (16887/21888)
Epoch: 24 | Batch_idx: 180 |  Loss: (0.6615) |  Loss2: (0.0000) | Acc: (77.00%) (17867/23168)
Epoch: 24 | Batch_idx: 190 |  Loss: (0.6646) |  Loss2: (0.0000) | Acc: (76.00%) (18816/24448)
Epoch: 24 | Batch_idx: 200 |  Loss: (0.6645) |  Loss2: (0.0000) | Acc: (76.00%) (19810/25728)
Epoch: 24 | Batch_idx: 210 |  Loss: (0.6631) |  Loss2: (0.0000) | Acc: (76.00%) (20796/27008)
Epoch: 24 | Batch_idx: 220 |  Loss: (0.6642) |  Loss2: (0.0000) | Acc: (76.00%) (21758/28288)
Epoch: 24 | Batch_idx: 230 |  Loss: (0.6640) |  Loss2: (0.0000) | Acc: (76.00%) (22737/29568)
Epoch: 24 | Batch_idx: 240 |  Loss: (0.6653) |  Loss2: (0.0000) | Acc: (76.00%) (23699/30848)
Epoch: 24 | Batch_idx: 250 |  Loss: (0.6669) |  Loss2: (0.0000) | Acc: (76.00%) (24653/32128)
Epoch: 24 | Batch_idx: 260 |  Loss: (0.6654) |  Loss2: (0.0000) | Acc: (76.00%) (25657/33408)
Epoch: 24 | Batch_idx: 270 |  Loss: (0.6662) |  Loss2: (0.0000) | Acc: (76.00%) (26637/34688)
Epoch: 24 | Batch_idx: 280 |  Loss: (0.6649) |  Loss2: (0.0000) | Acc: (76.00%) (27638/35968)
Epoch: 24 | Batch_idx: 290 |  Loss: (0.6646) |  Loss2: (0.0000) | Acc: (76.00%) (28619/37248)
Epoch: 24 | Batch_idx: 300 |  Loss: (0.6648) |  Loss2: (0.0000) | Acc: (76.00%) (29584/38528)
Epoch: 24 | Batch_idx: 310 |  Loss: (0.6648) |  Loss2: (0.0000) | Acc: (76.00%) (30581/39808)
Epoch: 24 | Batch_idx: 320 |  Loss: (0.6635) |  Loss2: (0.0000) | Acc: (76.00%) (31567/41088)
Epoch: 24 | Batch_idx: 330 |  Loss: (0.6627) |  Loss2: (0.0000) | Acc: (76.00%) (32569/42368)
Epoch: 24 | Batch_idx: 340 |  Loss: (0.6625) |  Loss2: (0.0000) | Acc: (76.00%) (33561/43648)
Epoch: 24 | Batch_idx: 350 |  Loss: (0.6626) |  Loss2: (0.0000) | Acc: (76.00%) (34531/44928)
Epoch: 24 | Batch_idx: 360 |  Loss: (0.6628) |  Loss2: (0.0000) | Acc: (76.00%) (35489/46208)
Epoch: 24 | Batch_idx: 370 |  Loss: (0.6618) |  Loss2: (0.0000) | Acc: (76.00%) (36498/47488)
Epoch: 24 | Batch_idx: 380 |  Loss: (0.6600) |  Loss2: (0.0000) | Acc: (76.00%) (37501/48768)
Epoch: 24 | Batch_idx: 390 |  Loss: (0.6599) |  Loss2: (0.0000) | Acc: (76.00%) (38441/50000)
# TEST : Loss: (0.7040) | Acc: (75.00%) (7544/10000)
percent tensor([0.5079, 0.5063, 0.5121, 0.5115, 0.5104, 0.5084, 0.5079, 0.5095, 0.5054,
        0.5090, 0.5050, 0.5105, 0.5068, 0.5063, 0.5082, 0.5097],
       device='cuda:0') torch.Size([16])
percent tensor([0.4938, 0.4879, 0.4892, 0.4960, 0.4863, 0.5003, 0.4845, 0.4868, 0.4898,
        0.4887, 0.4920, 0.4880, 0.4909, 0.4893, 0.4919, 0.4940],
       device='cuda:0') torch.Size([16])
percent tensor([0.5064, 0.4169, 0.5855, 0.5523, 0.5723, 0.5237, 0.4913, 0.5727, 0.5178,
        0.4706, 0.4331, 0.5552, 0.4560, 0.4378, 0.4728, 0.5107],
       device='cuda:0') torch.Size([16])
percent tensor([0.6057, 0.6191, 0.5751, 0.5885, 0.5775, 0.5977, 0.6020, 0.5859, 0.6060,
        0.6090, 0.6156, 0.5955, 0.6185, 0.6158, 0.6147, 0.6086],
       device='cuda:0') torch.Size([16])
percent tensor([0.5884, 0.5330, 0.6053, 0.6275, 0.6028, 0.6117, 0.5711, 0.6014, 0.5827,
        0.5383, 0.5453, 0.5990, 0.5520, 0.5807, 0.5842, 0.5999],
       device='cuda:0') torch.Size([16])
percent tensor([0.4608, 0.4515, 0.5037, 0.5267, 0.5169, 0.5310, 0.4588, 0.4722, 0.4870,
        0.4449, 0.4495, 0.4664, 0.4575, 0.4822, 0.4486, 0.4849],
       device='cuda:0') torch.Size([16])
percent tensor([0.6107, 0.5937, 0.6105, 0.6078, 0.6136, 0.5920, 0.6027, 0.6191, 0.5842,
        0.6066, 0.6075, 0.5955, 0.5938, 0.5902, 0.6001, 0.6058],
       device='cuda:0') torch.Size([16])
percent tensor([0.9982, 0.9925, 0.9981, 0.9980, 0.9982, 0.9940, 0.9976, 0.9993, 0.9862,
        0.9950, 0.9933, 0.9978, 0.9932, 0.9910, 0.9975, 0.9983],
       device='cuda:0') torch.Size([16])
Epoch: 25 | Batch_idx: 0 |  Loss: (0.6553) |  Loss2: (0.0000) | Acc: (81.00%) (104/128)
Epoch: 25 | Batch_idx: 10 |  Loss: (0.6302) |  Loss2: (0.0000) | Acc: (78.00%) (1108/1408)
Epoch: 25 | Batch_idx: 20 |  Loss: (0.6470) |  Loss2: (0.0000) | Acc: (77.00%) (2091/2688)
Epoch: 25 | Batch_idx: 30 |  Loss: (0.6411) |  Loss2: (0.0000) | Acc: (78.00%) (3100/3968)
Epoch: 25 | Batch_idx: 40 |  Loss: (0.6361) |  Loss2: (0.0000) | Acc: (77.00%) (4093/5248)
Epoch: 25 | Batch_idx: 50 |  Loss: (0.6276) |  Loss2: (0.0000) | Acc: (78.00%) (5117/6528)
Epoch: 25 | Batch_idx: 60 |  Loss: (0.6255) |  Loss2: (0.0000) | Acc: (78.00%) (6122/7808)
Epoch: 25 | Batch_idx: 70 |  Loss: (0.6271) |  Loss2: (0.0000) | Acc: (78.00%) (7126/9088)
Epoch: 25 | Batch_idx: 80 |  Loss: (0.6307) |  Loss2: (0.0000) | Acc: (78.00%) (8117/10368)
Epoch: 25 | Batch_idx: 90 |  Loss: (0.6312) |  Loss2: (0.0000) | Acc: (78.00%) (9112/11648)
Epoch: 25 | Batch_idx: 100 |  Loss: (0.6310) |  Loss2: (0.0000) | Acc: (78.00%) (10111/12928)
Epoch: 25 | Batch_idx: 110 |  Loss: (0.6301) |  Loss2: (0.0000) | Acc: (78.00%) (11125/14208)
Epoch: 25 | Batch_idx: 120 |  Loss: (0.6335) |  Loss2: (0.0000) | Acc: (78.00%) (12114/15488)
Epoch: 25 | Batch_idx: 130 |  Loss: (0.6337) |  Loss2: (0.0000) | Acc: (78.00%) (13111/16768)
Epoch: 25 | Batch_idx: 140 |  Loss: (0.6330) |  Loss2: (0.0000) | Acc: (78.00%) (14125/18048)
Epoch: 25 | Batch_idx: 150 |  Loss: (0.6354) |  Loss2: (0.0000) | Acc: (78.00%) (15094/19328)
Epoch: 25 | Batch_idx: 160 |  Loss: (0.6333) |  Loss2: (0.0000) | Acc: (78.00%) (16095/20608)
Epoch: 25 | Batch_idx: 170 |  Loss: (0.6346) |  Loss2: (0.0000) | Acc: (78.00%) (17095/21888)
Epoch: 25 | Batch_idx: 180 |  Loss: (0.6327) |  Loss2: (0.0000) | Acc: (78.00%) (18131/23168)
Epoch: 25 | Batch_idx: 190 |  Loss: (0.6319) |  Loss2: (0.0000) | Acc: (78.00%) (19137/24448)
Epoch: 25 | Batch_idx: 200 |  Loss: (0.6324) |  Loss2: (0.0000) | Acc: (78.00%) (20113/25728)
Epoch: 25 | Batch_idx: 210 |  Loss: (0.6317) |  Loss2: (0.0000) | Acc: (78.00%) (21107/27008)
Epoch: 25 | Batch_idx: 220 |  Loss: (0.6309) |  Loss2: (0.0000) | Acc: (78.00%) (22116/28288)
Epoch: 25 | Batch_idx: 230 |  Loss: (0.6281) |  Loss2: (0.0000) | Acc: (78.00%) (23135/29568)
Epoch: 25 | Batch_idx: 240 |  Loss: (0.6271) |  Loss2: (0.0000) | Acc: (78.00%) (24140/30848)
Epoch: 25 | Batch_idx: 250 |  Loss: (0.6278) |  Loss2: (0.0000) | Acc: (78.00%) (25143/32128)
Epoch: 25 | Batch_idx: 260 |  Loss: (0.6281) |  Loss2: (0.0000) | Acc: (78.00%) (26147/33408)
Epoch: 25 | Batch_idx: 270 |  Loss: (0.6288) |  Loss2: (0.0000) | Acc: (78.00%) (27123/34688)
Epoch: 25 | Batch_idx: 280 |  Loss: (0.6288) |  Loss2: (0.0000) | Acc: (78.00%) (28139/35968)
Epoch: 25 | Batch_idx: 290 |  Loss: (0.6285) |  Loss2: (0.0000) | Acc: (78.00%) (29155/37248)
Epoch: 25 | Batch_idx: 300 |  Loss: (0.6279) |  Loss2: (0.0000) | Acc: (78.00%) (30144/38528)
Epoch: 25 | Batch_idx: 310 |  Loss: (0.6271) |  Loss2: (0.0000) | Acc: (78.00%) (31164/39808)
Epoch: 25 | Batch_idx: 320 |  Loss: (0.6272) |  Loss2: (0.0000) | Acc: (78.00%) (32158/41088)
Epoch: 25 | Batch_idx: 330 |  Loss: (0.6270) |  Loss2: (0.0000) | Acc: (78.00%) (33157/42368)
Epoch: 25 | Batch_idx: 340 |  Loss: (0.6269) |  Loss2: (0.0000) | Acc: (78.00%) (34168/43648)
Epoch: 25 | Batch_idx: 350 |  Loss: (0.6276) |  Loss2: (0.0000) | Acc: (78.00%) (35172/44928)
Epoch: 25 | Batch_idx: 360 |  Loss: (0.6268) |  Loss2: (0.0000) | Acc: (78.00%) (36184/46208)
Epoch: 25 | Batch_idx: 370 |  Loss: (0.6262) |  Loss2: (0.0000) | Acc: (78.00%) (37193/47488)
Epoch: 25 | Batch_idx: 380 |  Loss: (0.6254) |  Loss2: (0.0000) | Acc: (78.00%) (38199/48768)
Epoch: 25 | Batch_idx: 390 |  Loss: (0.6254) |  Loss2: (0.0000) | Acc: (78.00%) (39162/50000)
=> saving checkpoint 'drive/app/torch/save_Schedule/checkpoint_025.pth.tar'
# TEST : Loss: (0.7746) | Acc: (73.00%) (7341/10000)
percent tensor([0.5073, 0.5065, 0.5107, 0.5105, 0.5095, 0.5070, 0.5078, 0.5089, 0.5052,
        0.5085, 0.5050, 0.5096, 0.5064, 0.5077, 0.5077, 0.5092],
       device='cuda:0') torch.Size([16])
percent tensor([0.4935, 0.4888, 0.4910, 0.4957, 0.4872, 0.4995, 0.4861, 0.4875, 0.4911,
        0.4897, 0.4925, 0.4900, 0.4909, 0.4901, 0.4919, 0.4935],
       device='cuda:0') torch.Size([16])
percent tensor([0.5039, 0.4256, 0.5953, 0.5594, 0.5797, 0.5236, 0.5018, 0.5754, 0.5201,
        0.4741, 0.4309, 0.5648, 0.4517, 0.4515, 0.4784, 0.5127],
       device='cuda:0') torch.Size([16])
percent tensor([0.6046, 0.6169, 0.5752, 0.5838, 0.5755, 0.5927, 0.6005, 0.5868, 0.6092,
        0.6102, 0.6178, 0.5993, 0.6218, 0.6143, 0.6135, 0.6049],
       device='cuda:0') torch.Size([16])
percent tensor([0.5928, 0.5546, 0.6072, 0.6204, 0.6036, 0.6131, 0.5875, 0.6018, 0.5875,
        0.5505, 0.5549, 0.6040, 0.5583, 0.5997, 0.5953, 0.6019],
       device='cuda:0') torch.Size([16])
percent tensor([0.4522, 0.4633, 0.5028, 0.5158, 0.5140, 0.5260, 0.4657, 0.4646, 0.4720,
        0.4549, 0.4445, 0.4710, 0.4441, 0.4963, 0.4494, 0.4754],
       device='cuda:0') torch.Size([16])
percent tensor([0.6028, 0.5870, 0.6062, 0.6049, 0.6118, 0.5886, 0.5911, 0.6190, 0.5783,
        0.5965, 0.5979, 0.5932, 0.5858, 0.5857, 0.5990, 0.6022],
       device='cuda:0') torch.Size([16])
percent tensor([0.9976, 0.9903, 0.9959, 0.9969, 0.9973, 0.9902, 0.9975, 0.9992, 0.9875,
        0.9949, 0.9943, 0.9984, 0.9926, 0.9912, 0.9980, 0.9979],
       device='cuda:0') torch.Size([16])
Epoch: 26 | Batch_idx: 0 |  Loss: (0.6205) |  Loss2: (0.0000) | Acc: (80.00%) (103/128)
Epoch: 26 | Batch_idx: 10 |  Loss: (0.6035) |  Loss2: (0.0000) | Acc: (80.00%) (1129/1408)
Epoch: 26 | Batch_idx: 20 |  Loss: (0.6140) |  Loss2: (0.0000) | Acc: (78.00%) (2120/2688)
Epoch: 26 | Batch_idx: 30 |  Loss: (0.6131) |  Loss2: (0.0000) | Acc: (78.00%) (3126/3968)
Epoch: 26 | Batch_idx: 40 |  Loss: (0.6054) |  Loss2: (0.0000) | Acc: (79.00%) (4152/5248)
Epoch: 26 | Batch_idx: 50 |  Loss: (0.5990) |  Loss2: (0.0000) | Acc: (79.00%) (5179/6528)
Epoch: 26 | Batch_idx: 60 |  Loss: (0.5931) |  Loss2: (0.0000) | Acc: (79.00%) (6211/7808)
Epoch: 26 | Batch_idx: 70 |  Loss: (0.5850) |  Loss2: (0.0000) | Acc: (79.00%) (7263/9088)
Epoch: 26 | Batch_idx: 80 |  Loss: (0.5836) |  Loss2: (0.0000) | Acc: (79.00%) (8285/10368)
Epoch: 26 | Batch_idx: 90 |  Loss: (0.5840) |  Loss2: (0.0000) | Acc: (79.00%) (9304/11648)
Epoch: 26 | Batch_idx: 100 |  Loss: (0.5843) |  Loss2: (0.0000) | Acc: (79.00%) (10317/12928)
Epoch: 26 | Batch_idx: 110 |  Loss: (0.5882) |  Loss2: (0.0000) | Acc: (79.00%) (11315/14208)
Epoch: 26 | Batch_idx: 120 |  Loss: (0.5898) |  Loss2: (0.0000) | Acc: (79.00%) (12331/15488)
Epoch: 26 | Batch_idx: 130 |  Loss: (0.5915) |  Loss2: (0.0000) | Acc: (79.00%) (13350/16768)
Epoch: 26 | Batch_idx: 140 |  Loss: (0.5899) |  Loss2: (0.0000) | Acc: (79.00%) (14377/18048)
Epoch: 26 | Batch_idx: 150 |  Loss: (0.5912) |  Loss2: (0.0000) | Acc: (79.00%) (15378/19328)
Epoch: 26 | Batch_idx: 160 |  Loss: (0.5901) |  Loss2: (0.0000) | Acc: (79.00%) (16409/20608)
Epoch: 26 | Batch_idx: 170 |  Loss: (0.5913) |  Loss2: (0.0000) | Acc: (79.00%) (17418/21888)
Epoch: 26 | Batch_idx: 180 |  Loss: (0.5925) |  Loss2: (0.0000) | Acc: (79.00%) (18426/23168)
Epoch: 26 | Batch_idx: 190 |  Loss: (0.5944) |  Loss2: (0.0000) | Acc: (79.00%) (19422/24448)
Epoch: 26 | Batch_idx: 200 |  Loss: (0.5964) |  Loss2: (0.0000) | Acc: (79.00%) (20428/25728)
Epoch: 26 | Batch_idx: 210 |  Loss: (0.5961) |  Loss2: (0.0000) | Acc: (79.00%) (21450/27008)
Epoch: 26 | Batch_idx: 220 |  Loss: (0.5945) |  Loss2: (0.0000) | Acc: (79.00%) (22498/28288)
Epoch: 26 | Batch_idx: 230 |  Loss: (0.5941) |  Loss2: (0.0000) | Acc: (79.00%) (23524/29568)
Epoch: 26 | Batch_idx: 240 |  Loss: (0.5943) |  Loss2: (0.0000) | Acc: (79.00%) (24538/30848)
Epoch: 26 | Batch_idx: 250 |  Loss: (0.5925) |  Loss2: (0.0000) | Acc: (79.00%) (25558/32128)
Epoch: 26 | Batch_idx: 260 |  Loss: (0.5928) |  Loss2: (0.0000) | Acc: (79.00%) (26568/33408)
Epoch: 26 | Batch_idx: 270 |  Loss: (0.5915) |  Loss2: (0.0000) | Acc: (79.00%) (27599/34688)
Epoch: 26 | Batch_idx: 280 |  Loss: (0.5916) |  Loss2: (0.0000) | Acc: (79.00%) (28618/35968)
Epoch: 26 | Batch_idx: 290 |  Loss: (0.5912) |  Loss2: (0.0000) | Acc: (79.00%) (29647/37248)
Epoch: 26 | Batch_idx: 300 |  Loss: (0.5904) |  Loss2: (0.0000) | Acc: (79.00%) (30680/38528)
Epoch: 26 | Batch_idx: 310 |  Loss: (0.5908) |  Loss2: (0.0000) | Acc: (79.00%) (31682/39808)
Epoch: 26 | Batch_idx: 320 |  Loss: (0.5907) |  Loss2: (0.0000) | Acc: (79.00%) (32712/41088)
Epoch: 26 | Batch_idx: 330 |  Loss: (0.5896) |  Loss2: (0.0000) | Acc: (79.00%) (33740/42368)
Epoch: 26 | Batch_idx: 340 |  Loss: (0.5913) |  Loss2: (0.0000) | Acc: (79.00%) (34725/43648)
Epoch: 26 | Batch_idx: 350 |  Loss: (0.5912) |  Loss2: (0.0000) | Acc: (79.00%) (35743/44928)
Epoch: 26 | Batch_idx: 360 |  Loss: (0.5924) |  Loss2: (0.0000) | Acc: (79.00%) (36726/46208)
Epoch: 26 | Batch_idx: 370 |  Loss: (0.5928) |  Loss2: (0.0000) | Acc: (79.00%) (37737/47488)
Epoch: 26 | Batch_idx: 380 |  Loss: (0.5929) |  Loss2: (0.0000) | Acc: (79.00%) (38754/48768)
Epoch: 26 | Batch_idx: 390 |  Loss: (0.5929) |  Loss2: (0.0000) | Acc: (79.00%) (39727/50000)
# TEST : Loss: (0.7114) | Acc: (75.00%) (7536/10000)
percent tensor([0.5075, 0.5067, 0.5107, 0.5105, 0.5096, 0.5074, 0.5079, 0.5087, 0.5053,
        0.5089, 0.5049, 0.5097, 0.5064, 0.5073, 0.5080, 0.5092],
       device='cuda:0') torch.Size([16])
percent tensor([0.4932, 0.4892, 0.4906, 0.4956, 0.4871, 0.4988, 0.4861, 0.4879, 0.4911,
        0.4900, 0.4930, 0.4896, 0.4911, 0.4906, 0.4921, 0.4937],
       device='cuda:0') torch.Size([16])
percent tensor([0.5138, 0.4288, 0.5888, 0.5615, 0.5741, 0.5260, 0.4990, 0.5780, 0.5254,
        0.4793, 0.4356, 0.5579, 0.4611, 0.4583, 0.4813, 0.5210],
       device='cuda:0') torch.Size([16])
percent tensor([0.6048, 0.6156, 0.5763, 0.5839, 0.5760, 0.5951, 0.6014, 0.5846, 0.6082,
        0.6105, 0.6180, 0.6009, 0.6202, 0.6168, 0.6136, 0.6071],
       device='cuda:0') torch.Size([16])
percent tensor([0.5917, 0.5542, 0.6067, 0.6221, 0.6038, 0.6102, 0.5811, 0.6015, 0.5909,
        0.5529, 0.5568, 0.6002, 0.5596, 0.6048, 0.5902, 0.6108],
       device='cuda:0') torch.Size([16])
percent tensor([0.4587, 0.4706, 0.5099, 0.5169, 0.5233, 0.5265, 0.4741, 0.4845, 0.4787,
        0.4602, 0.4511, 0.4691, 0.4514, 0.4984, 0.4548, 0.4848],
       device='cuda:0') torch.Size([16])
percent tensor([0.6043, 0.5854, 0.6035, 0.6049, 0.6101, 0.5944, 0.5865, 0.6123, 0.5811,
        0.5946, 0.5980, 0.5912, 0.5873, 0.5899, 0.5959, 0.6024],
       device='cuda:0') torch.Size([16])
percent tensor([0.9975, 0.9904, 0.9958, 0.9965, 0.9970, 0.9932, 0.9947, 0.9985, 0.9840,
        0.9930, 0.9916, 0.9969, 0.9933, 0.9923, 0.9980, 0.9982],
       device='cuda:0') torch.Size([16])
False Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=128, out_features=16, bias=False)
True Linear(in_features=16, out_features=2, bias=False)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=128, out_features=16, bias=False)
True Linear(in_features=16, out_features=2, bias=False)
False Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=256, out_features=32, bias=False)
True Linear(in_features=32, out_features=2, bias=False)
False Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=256, out_features=32, bias=False)
True Linear(in_features=32, out_features=2, bias=False)
False Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=512, out_features=64, bias=False)
True Linear(in_features=64, out_features=2, bias=False)
False Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=512, out_features=64, bias=False)
True Linear(in_features=64, out_features=2, bias=False)
False Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1024, out_features=128, bias=False)
True Linear(in_features=128, out_features=2, bias=False)
False Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1024, out_features=128, bias=False)
True Linear(in_features=128, out_features=2, bias=False)
False Linear(in_features=512, out_features=10, bias=True)
Epoch: 27 | Batch_idx: 0 |  Loss: (0.6382) |  Loss2: (0.0000) | Acc: (79.00%) (102/128)
Epoch: 27 | Batch_idx: 10 |  Loss: (0.6137) |  Loss2: (0.0000) | Acc: (79.00%) (1114/1408)
Epoch: 27 | Batch_idx: 20 |  Loss: (0.6405) |  Loss2: (0.0000) | Acc: (78.00%) (2099/2688)
Epoch: 27 | Batch_idx: 30 |  Loss: (0.6506) |  Loss2: (0.0000) | Acc: (77.00%) (3087/3968)
Epoch: 27 | Batch_idx: 40 |  Loss: (0.6668) |  Loss2: (0.0000) | Acc: (77.00%) (4057/5248)
Epoch: 27 | Batch_idx: 50 |  Loss: (0.6782) |  Loss2: (0.0000) | Acc: (76.00%) (5019/6528)
Epoch: 27 | Batch_idx: 60 |  Loss: (0.6818) |  Loss2: (0.0000) | Acc: (76.00%) (5971/7808)
Epoch: 27 | Batch_idx: 70 |  Loss: (0.6744) |  Loss2: (0.0000) | Acc: (76.00%) (6980/9088)
Epoch: 27 | Batch_idx: 80 |  Loss: (0.6728) |  Loss2: (0.0000) | Acc: (76.00%) (7974/10368)
Epoch: 27 | Batch_idx: 90 |  Loss: (0.6650) |  Loss2: (0.0000) | Acc: (77.00%) (8994/11648)
Epoch: 27 | Batch_idx: 100 |  Loss: (0.6663) |  Loss2: (0.0000) | Acc: (77.00%) (9964/12928)
Epoch: 27 | Batch_idx: 110 |  Loss: (0.6617) |  Loss2: (0.0000) | Acc: (77.00%) (10978/14208)
Epoch: 27 | Batch_idx: 120 |  Loss: (0.6599) |  Loss2: (0.0000) | Acc: (77.00%) (11983/15488)
Epoch: 27 | Batch_idx: 130 |  Loss: (0.6615) |  Loss2: (0.0000) | Acc: (77.00%) (12963/16768)
Epoch: 27 | Batch_idx: 140 |  Loss: (0.6624) |  Loss2: (0.0000) | Acc: (77.00%) (13950/18048)
Epoch: 27 | Batch_idx: 150 |  Loss: (0.6625) |  Loss2: (0.0000) | Acc: (77.00%) (14927/19328)
Epoch: 27 | Batch_idx: 160 |  Loss: (0.6608) |  Loss2: (0.0000) | Acc: (77.00%) (15904/20608)
Epoch: 27 | Batch_idx: 170 |  Loss: (0.6598) |  Loss2: (0.0000) | Acc: (77.00%) (16883/21888)
Epoch: 27 | Batch_idx: 180 |  Loss: (0.6596) |  Loss2: (0.0000) | Acc: (77.00%) (17875/23168)
Epoch: 27 | Batch_idx: 190 |  Loss: (0.6582) |  Loss2: (0.0000) | Acc: (77.00%) (18877/24448)
Epoch: 27 | Batch_idx: 200 |  Loss: (0.6562) |  Loss2: (0.0000) | Acc: (77.00%) (19884/25728)
Epoch: 27 | Batch_idx: 210 |  Loss: (0.6541) |  Loss2: (0.0000) | Acc: (77.00%) (20887/27008)
Epoch: 27 | Batch_idx: 220 |  Loss: (0.6527) |  Loss2: (0.0000) | Acc: (77.00%) (21864/28288)
Epoch: 27 | Batch_idx: 230 |  Loss: (0.6510) |  Loss2: (0.0000) | Acc: (77.00%) (22869/29568)
Epoch: 27 | Batch_idx: 240 |  Loss: (0.6508) |  Loss2: (0.0000) | Acc: (77.00%) (23852/30848)
Epoch: 27 | Batch_idx: 250 |  Loss: (0.6497) |  Loss2: (0.0000) | Acc: (77.00%) (24839/32128)
Epoch: 27 | Batch_idx: 260 |  Loss: (0.6477) |  Loss2: (0.0000) | Acc: (77.00%) (25861/33408)
Epoch: 27 | Batch_idx: 270 |  Loss: (0.6455) |  Loss2: (0.0000) | Acc: (77.00%) (26873/34688)
Epoch: 27 | Batch_idx: 280 |  Loss: (0.6438) |  Loss2: (0.0000) | Acc: (77.00%) (27886/35968)
Epoch: 27 | Batch_idx: 290 |  Loss: (0.6441) |  Loss2: (0.0000) | Acc: (77.00%) (28867/37248)
Epoch: 27 | Batch_idx: 300 |  Loss: (0.6416) |  Loss2: (0.0000) | Acc: (77.00%) (29903/38528)
Epoch: 27 | Batch_idx: 310 |  Loss: (0.6395) |  Loss2: (0.0000) | Acc: (77.00%) (30927/39808)
Epoch: 27 | Batch_idx: 320 |  Loss: (0.6394) |  Loss2: (0.0000) | Acc: (77.00%) (31921/41088)
Epoch: 27 | Batch_idx: 330 |  Loss: (0.6373) |  Loss2: (0.0000) | Acc: (77.00%) (32948/42368)
Epoch: 27 | Batch_idx: 340 |  Loss: (0.6364) |  Loss2: (0.0000) | Acc: (77.00%) (33962/43648)
Epoch: 27 | Batch_idx: 350 |  Loss: (0.6353) |  Loss2: (0.0000) | Acc: (77.00%) (34979/44928)
Epoch: 27 | Batch_idx: 360 |  Loss: (0.6345) |  Loss2: (0.0000) | Acc: (77.00%) (35984/46208)
Epoch: 27 | Batch_idx: 370 |  Loss: (0.6342) |  Loss2: (0.0000) | Acc: (77.00%) (36991/47488)
Epoch: 27 | Batch_idx: 380 |  Loss: (0.6337) |  Loss2: (0.0000) | Acc: (77.00%) (37992/48768)
Epoch: 27 | Batch_idx: 390 |  Loss: (0.6335) |  Loss2: (0.0000) | Acc: (77.00%) (38941/50000)
# TEST : Loss: (0.6151) | Acc: (78.00%) (7827/10000)
percent tensor([0.5177, 0.5155, 0.5232, 0.5193, 0.5211, 0.5171, 0.5190, 0.5186, 0.5141,
        0.5190, 0.5149, 0.5226, 0.5172, 0.5124, 0.5186, 0.5183],
       device='cuda:0') torch.Size([16])
percent tensor([0.4984, 0.4952, 0.4947, 0.5003, 0.4930, 0.5041, 0.4924, 0.4930, 0.4964,
        0.4956, 0.4983, 0.4945, 0.4963, 0.4957, 0.4985, 0.4987],
       device='cuda:0') torch.Size([16])
percent tensor([0.4964, 0.4115, 0.5847, 0.5627, 0.5788, 0.5255, 0.4894, 0.5891, 0.5015,
        0.4569, 0.4045, 0.5285, 0.4334, 0.4370, 0.4723, 0.5074],
       device='cuda:0') torch.Size([16])
percent tensor([0.6124, 0.6234, 0.5861, 0.5921, 0.5866, 0.6001, 0.6112, 0.5959, 0.6173,
        0.6190, 0.6258, 0.6104, 0.6266, 0.6247, 0.6208, 0.6144],
       device='cuda:0') torch.Size([16])
percent tensor([0.5895, 0.5480, 0.6101, 0.6216, 0.6144, 0.6119, 0.5831, 0.6159, 0.5855,
        0.5511, 0.5452, 0.5900, 0.5530, 0.5893, 0.5872, 0.6130],
       device='cuda:0') torch.Size([16])
percent tensor([0.4645, 0.4762, 0.5100, 0.5252, 0.5279, 0.5310, 0.4768, 0.4853, 0.4886,
        0.4693, 0.4583, 0.4800, 0.4693, 0.5083, 0.4587, 0.4870],
       device='cuda:0') torch.Size([16])
percent tensor([0.5961, 0.5902, 0.6088, 0.6142, 0.6100, 0.5934, 0.5796, 0.6036, 0.5874,
        0.6020, 0.6000, 0.5901, 0.5842, 0.6015, 0.5784, 0.5832],
       device='cuda:0') torch.Size([16])
percent tensor([0.9981, 0.9922, 0.9973, 0.9968, 0.9971, 0.9940, 0.9970, 0.9989, 0.9876,
        0.9945, 0.9939, 0.9981, 0.9936, 0.9928, 0.9981, 0.9987],
       device='cuda:0') torch.Size([16])
Epoch: 28 | Batch_idx: 0 |  Loss: (0.5791) |  Loss2: (0.0000) | Acc: (79.00%) (102/128)
Epoch: 28 | Batch_idx: 10 |  Loss: (0.5697) |  Loss2: (0.0000) | Acc: (80.00%) (1129/1408)
Epoch: 28 | Batch_idx: 20 |  Loss: (0.5939) |  Loss2: (0.0000) | Acc: (79.00%) (2147/2688)
Epoch: 28 | Batch_idx: 30 |  Loss: (0.5817) |  Loss2: (0.0000) | Acc: (80.00%) (3188/3968)
Epoch: 28 | Batch_idx: 40 |  Loss: (0.5808) |  Loss2: (0.0000) | Acc: (79.00%) (4196/5248)
Epoch: 28 | Batch_idx: 50 |  Loss: (0.5766) |  Loss2: (0.0000) | Acc: (80.00%) (5232/6528)
Epoch: 28 | Batch_idx: 60 |  Loss: (0.5829) |  Loss2: (0.0000) | Acc: (79.00%) (6244/7808)
Epoch: 28 | Batch_idx: 70 |  Loss: (0.5868) |  Loss2: (0.0000) | Acc: (79.00%) (7254/9088)
Epoch: 28 | Batch_idx: 80 |  Loss: (0.5824) |  Loss2: (0.0000) | Acc: (79.00%) (8279/10368)
Epoch: 28 | Batch_idx: 90 |  Loss: (0.5797) |  Loss2: (0.0000) | Acc: (79.00%) (9314/11648)
Epoch: 28 | Batch_idx: 100 |  Loss: (0.5839) |  Loss2: (0.0000) | Acc: (79.00%) (10329/12928)
Epoch: 28 | Batch_idx: 110 |  Loss: (0.5840) |  Loss2: (0.0000) | Acc: (79.00%) (11345/14208)
Epoch: 28 | Batch_idx: 120 |  Loss: (0.5807) |  Loss2: (0.0000) | Acc: (79.00%) (12375/15488)
Epoch: 28 | Batch_idx: 130 |  Loss: (0.5830) |  Loss2: (0.0000) | Acc: (79.00%) (13376/16768)
Epoch: 28 | Batch_idx: 140 |  Loss: (0.5822) |  Loss2: (0.0000) | Acc: (79.00%) (14410/18048)
Epoch: 28 | Batch_idx: 150 |  Loss: (0.5823) |  Loss2: (0.0000) | Acc: (79.00%) (15427/19328)
Epoch: 28 | Batch_idx: 160 |  Loss: (0.5833) |  Loss2: (0.0000) | Acc: (79.00%) (16441/20608)
Epoch: 28 | Batch_idx: 170 |  Loss: (0.5842) |  Loss2: (0.0000) | Acc: (79.00%) (17455/21888)
Epoch: 28 | Batch_idx: 180 |  Loss: (0.5850) |  Loss2: (0.0000) | Acc: (79.00%) (18483/23168)
Epoch: 28 | Batch_idx: 190 |  Loss: (0.5844) |  Loss2: (0.0000) | Acc: (79.00%) (19503/24448)
Epoch: 28 | Batch_idx: 200 |  Loss: (0.5841) |  Loss2: (0.0000) | Acc: (79.00%) (20533/25728)
Epoch: 28 | Batch_idx: 210 |  Loss: (0.5846) |  Loss2: (0.0000) | Acc: (79.00%) (21540/27008)
Epoch: 28 | Batch_idx: 220 |  Loss: (0.5846) |  Loss2: (0.0000) | Acc: (79.00%) (22559/28288)
Epoch: 28 | Batch_idx: 230 |  Loss: (0.5827) |  Loss2: (0.0000) | Acc: (79.00%) (23613/29568)
Epoch: 28 | Batch_idx: 240 |  Loss: (0.5829) |  Loss2: (0.0000) | Acc: (79.00%) (24630/30848)
Epoch: 28 | Batch_idx: 250 |  Loss: (0.5831) |  Loss2: (0.0000) | Acc: (79.00%) (25647/32128)
Epoch: 28 | Batch_idx: 260 |  Loss: (0.5830) |  Loss2: (0.0000) | Acc: (79.00%) (26669/33408)
Epoch: 28 | Batch_idx: 270 |  Loss: (0.5827) |  Loss2: (0.0000) | Acc: (79.00%) (27702/34688)
Epoch: 28 | Batch_idx: 280 |  Loss: (0.5812) |  Loss2: (0.0000) | Acc: (79.00%) (28744/35968)
Epoch: 28 | Batch_idx: 290 |  Loss: (0.5802) |  Loss2: (0.0000) | Acc: (79.00%) (29786/37248)
Epoch: 28 | Batch_idx: 300 |  Loss: (0.5813) |  Loss2: (0.0000) | Acc: (79.00%) (30798/38528)
Epoch: 28 | Batch_idx: 310 |  Loss: (0.5810) |  Loss2: (0.0000) | Acc: (79.00%) (31820/39808)
Epoch: 28 | Batch_idx: 320 |  Loss: (0.5796) |  Loss2: (0.0000) | Acc: (80.00%) (32876/41088)
Epoch: 28 | Batch_idx: 330 |  Loss: (0.5802) |  Loss2: (0.0000) | Acc: (79.00%) (33887/42368)
Epoch: 28 | Batch_idx: 340 |  Loss: (0.5798) |  Loss2: (0.0000) | Acc: (79.00%) (34912/43648)
Epoch: 28 | Batch_idx: 350 |  Loss: (0.5804) |  Loss2: (0.0000) | Acc: (79.00%) (35928/44928)
Epoch: 28 | Batch_idx: 360 |  Loss: (0.5818) |  Loss2: (0.0000) | Acc: (79.00%) (36922/46208)
Epoch: 28 | Batch_idx: 370 |  Loss: (0.5809) |  Loss2: (0.0000) | Acc: (79.00%) (37952/47488)
Epoch: 28 | Batch_idx: 380 |  Loss: (0.5821) |  Loss2: (0.0000) | Acc: (79.00%) (38937/48768)
Epoch: 28 | Batch_idx: 390 |  Loss: (0.5834) |  Loss2: (0.0000) | Acc: (79.00%) (39895/50000)
# TEST : Loss: (0.5926) | Acc: (79.00%) (7902/10000)
percent tensor([0.5174, 0.5144, 0.5226, 0.5187, 0.5204, 0.5169, 0.5181, 0.5179, 0.5135,
        0.5180, 0.5144, 0.5219, 0.5168, 0.5113, 0.5178, 0.5175],
       device='cuda:0') torch.Size([16])
percent tensor([0.4994, 0.4956, 0.4948, 0.5012, 0.4931, 0.5053, 0.4924, 0.4930, 0.4967,
        0.4960, 0.4990, 0.4947, 0.4970, 0.4960, 0.4994, 0.4997],
       device='cuda:0') torch.Size([16])
percent tensor([0.4933, 0.4042, 0.5810, 0.5582, 0.5766, 0.5314, 0.4827, 0.5822, 0.4951,
        0.4482, 0.3997, 0.5204, 0.4264, 0.4290, 0.4683, 0.5039],
       device='cuda:0') torch.Size([16])
percent tensor([0.6172, 0.6284, 0.5890, 0.5968, 0.5900, 0.6032, 0.6143, 0.6000, 0.6221,
        0.6241, 0.6306, 0.6127, 0.6316, 0.6302, 0.6244, 0.6194],
       device='cuda:0') torch.Size([16])
percent tensor([0.5999, 0.5519, 0.6168, 0.6261, 0.6250, 0.6275, 0.5887, 0.6243, 0.5886,
        0.5549, 0.5478, 0.5866, 0.5582, 0.5921, 0.5919, 0.6266],
       device='cuda:0') torch.Size([16])
percent tensor([0.4713, 0.4843, 0.5191, 0.5360, 0.5380, 0.5452, 0.4815, 0.4855, 0.4990,
        0.4771, 0.4687, 0.4908, 0.4822, 0.5216, 0.4642, 0.4961],
       device='cuda:0') torch.Size([16])
percent tensor([0.5966, 0.5973, 0.6181, 0.6262, 0.6174, 0.5986, 0.5797, 0.6009, 0.5970,
        0.6128, 0.6092, 0.5983, 0.5904, 0.6148, 0.5751, 0.5755],
       device='cuda:0') torch.Size([16])
percent tensor([0.9987, 0.9936, 0.9975, 0.9970, 0.9974, 0.9956, 0.9975, 0.9991, 0.9897,
        0.9956, 0.9951, 0.9983, 0.9951, 0.9943, 0.9985, 0.9990],
       device='cuda:0') torch.Size([16])
Epoch: 29 | Batch_idx: 0 |  Loss: (0.6102) |  Loss2: (0.0000) | Acc: (77.00%) (99/128)
Epoch: 29 | Batch_idx: 10 |  Loss: (0.5569) |  Loss2: (0.0000) | Acc: (80.00%) (1136/1408)
Epoch: 29 | Batch_idx: 20 |  Loss: (0.5572) |  Loss2: (0.0000) | Acc: (81.00%) (2191/2688)
Epoch: 29 | Batch_idx: 30 |  Loss: (0.5606) |  Loss2: (0.0000) | Acc: (81.00%) (3224/3968)
Epoch: 29 | Batch_idx: 40 |  Loss: (0.5634) |  Loss2: (0.0000) | Acc: (80.00%) (4246/5248)
Epoch: 29 | Batch_idx: 50 |  Loss: (0.5662) |  Loss2: (0.0000) | Acc: (80.00%) (5274/6528)
Epoch: 29 | Batch_idx: 60 |  Loss: (0.5613) |  Loss2: (0.0000) | Acc: (80.00%) (6321/7808)
Epoch: 29 | Batch_idx: 70 |  Loss: (0.5669) |  Loss2: (0.0000) | Acc: (80.00%) (7335/9088)
Epoch: 29 | Batch_idx: 80 |  Loss: (0.5648) |  Loss2: (0.0000) | Acc: (80.00%) (8378/10368)
Epoch: 29 | Batch_idx: 90 |  Loss: (0.5662) |  Loss2: (0.0000) | Acc: (80.00%) (9408/11648)
Epoch: 29 | Batch_idx: 100 |  Loss: (0.5730) |  Loss2: (0.0000) | Acc: (80.00%) (10394/12928)
Epoch: 29 | Batch_idx: 110 |  Loss: (0.5726) |  Loss2: (0.0000) | Acc: (80.00%) (11426/14208)
Epoch: 29 | Batch_idx: 120 |  Loss: (0.5720) |  Loss2: (0.0000) | Acc: (80.00%) (12454/15488)
Epoch: 29 | Batch_idx: 130 |  Loss: (0.5735) |  Loss2: (0.0000) | Acc: (80.00%) (13487/16768)
Epoch: 29 | Batch_idx: 140 |  Loss: (0.5726) |  Loss2: (0.0000) | Acc: (80.00%) (14520/18048)
Epoch: 29 | Batch_idx: 150 |  Loss: (0.5725) |  Loss2: (0.0000) | Acc: (80.00%) (15545/19328)
Epoch: 29 | Batch_idx: 160 |  Loss: (0.5719) |  Loss2: (0.0000) | Acc: (80.00%) (16568/20608)
Epoch: 29 | Batch_idx: 170 |  Loss: (0.5715) |  Loss2: (0.0000) | Acc: (80.00%) (17612/21888)
Epoch: 29 | Batch_idx: 180 |  Loss: (0.5712) |  Loss2: (0.0000) | Acc: (80.00%) (18637/23168)
Epoch: 29 | Batch_idx: 190 |  Loss: (0.5712) |  Loss2: (0.0000) | Acc: (80.00%) (19666/24448)
Epoch: 29 | Batch_idx: 200 |  Loss: (0.5703) |  Loss2: (0.0000) | Acc: (80.00%) (20704/25728)
Epoch: 29 | Batch_idx: 210 |  Loss: (0.5696) |  Loss2: (0.0000) | Acc: (80.00%) (21740/27008)
Epoch: 29 | Batch_idx: 220 |  Loss: (0.5712) |  Loss2: (0.0000) | Acc: (80.00%) (22751/28288)
Epoch: 29 | Batch_idx: 230 |  Loss: (0.5701) |  Loss2: (0.0000) | Acc: (80.00%) (23778/29568)
Epoch: 29 | Batch_idx: 240 |  Loss: (0.5699) |  Loss2: (0.0000) | Acc: (80.00%) (24811/30848)
Epoch: 29 | Batch_idx: 250 |  Loss: (0.5704) |  Loss2: (0.0000) | Acc: (80.00%) (25827/32128)
Epoch: 29 | Batch_idx: 260 |  Loss: (0.5694) |  Loss2: (0.0000) | Acc: (80.00%) (26867/33408)
Epoch: 29 | Batch_idx: 270 |  Loss: (0.5701) |  Loss2: (0.0000) | Acc: (80.00%) (27887/34688)
Epoch: 29 | Batch_idx: 280 |  Loss: (0.5701) |  Loss2: (0.0000) | Acc: (80.00%) (28920/35968)
Epoch: 29 | Batch_idx: 290 |  Loss: (0.5695) |  Loss2: (0.0000) | Acc: (80.00%) (29956/37248)
Epoch: 29 | Batch_idx: 300 |  Loss: (0.5707) |  Loss2: (0.0000) | Acc: (80.00%) (30960/38528)
Epoch: 29 | Batch_idx: 310 |  Loss: (0.5710) |  Loss2: (0.0000) | Acc: (80.00%) (31986/39808)
Epoch: 29 | Batch_idx: 320 |  Loss: (0.5709) |  Loss2: (0.0000) | Acc: (80.00%) (33025/41088)
Epoch: 29 | Batch_idx: 330 |  Loss: (0.5722) |  Loss2: (0.0000) | Acc: (80.00%) (34030/42368)
Epoch: 29 | Batch_idx: 340 |  Loss: (0.5707) |  Loss2: (0.0000) | Acc: (80.00%) (35087/43648)
Epoch: 29 | Batch_idx: 350 |  Loss: (0.5705) |  Loss2: (0.0000) | Acc: (80.00%) (36125/44928)
Epoch: 29 | Batch_idx: 360 |  Loss: (0.5706) |  Loss2: (0.0000) | Acc: (80.00%) (37146/46208)
Epoch: 29 | Batch_idx: 370 |  Loss: (0.5703) |  Loss2: (0.0000) | Acc: (80.00%) (38181/47488)
Epoch: 29 | Batch_idx: 380 |  Loss: (0.5708) |  Loss2: (0.0000) | Acc: (80.00%) (39207/48768)
Epoch: 29 | Batch_idx: 390 |  Loss: (0.5704) |  Loss2: (0.0000) | Acc: (80.00%) (40203/50000)
# TEST : Loss: (0.5844) | Acc: (79.00%) (7919/10000)
percent tensor([0.5150, 0.5112, 0.5195, 0.5161, 0.5173, 0.5146, 0.5146, 0.5149, 0.5109,
        0.5147, 0.5116, 0.5185, 0.5139, 0.5087, 0.5148, 0.5147],
       device='cuda:0') torch.Size([16])
percent tensor([0.4998, 0.4954, 0.4945, 0.5016, 0.4926, 0.5061, 0.4920, 0.4927, 0.4967,
        0.4959, 0.4994, 0.4945, 0.4971, 0.4958, 0.4998, 0.5002],
       device='cuda:0') torch.Size([16])
percent tensor([0.4967, 0.4030, 0.5838, 0.5607, 0.5794, 0.5390, 0.4844, 0.5830, 0.4974,
        0.4479, 0.3995, 0.5223, 0.4256, 0.4300, 0.4703, 0.5072],
       device='cuda:0') torch.Size([16])
percent tensor([0.6238, 0.6357, 0.5936, 0.6025, 0.5947, 0.6077, 0.6199, 0.6055, 0.6284,
        0.6313, 0.6379, 0.6177, 0.6388, 0.6373, 0.6302, 0.6261],
       device='cuda:0') torch.Size([16])
percent tensor([0.6017, 0.5475, 0.6177, 0.6257, 0.6300, 0.6354, 0.5872, 0.6272, 0.5851,
        0.5507, 0.5419, 0.5763, 0.5541, 0.5875, 0.5885, 0.6322],
       device='cuda:0') torch.Size([16])
percent tensor([0.4672, 0.4814, 0.5193, 0.5384, 0.5391, 0.5511, 0.4774, 0.4786, 0.5003,
        0.4728, 0.4664, 0.4895, 0.4822, 0.5230, 0.4592, 0.4939],
       device='cuda:0') torch.Size([16])
percent tensor([0.6023, 0.6092, 0.6313, 0.6424, 0.6279, 0.6068, 0.5843, 0.6042, 0.6110,
        0.6291, 0.6245, 0.6106, 0.6013, 0.6316, 0.5766, 0.5731],
       device='cuda:0') torch.Size([16])
percent tensor([0.9989, 0.9945, 0.9982, 0.9976, 0.9981, 0.9968, 0.9979, 0.9992, 0.9910,
        0.9964, 0.9960, 0.9988, 0.9960, 0.9951, 0.9987, 0.9991],
       device='cuda:0') torch.Size([16])
True Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=128, out_features=16, bias=False)
False Linear(in_features=16, out_features=2, bias=False)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=128, out_features=16, bias=False)
False Linear(in_features=16, out_features=2, bias=False)
True Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=256, out_features=32, bias=False)
False Linear(in_features=32, out_features=2, bias=False)
True Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=256, out_features=32, bias=False)
False Linear(in_features=32, out_features=2, bias=False)
True Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=512, out_features=64, bias=False)
False Linear(in_features=64, out_features=2, bias=False)
True Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=512, out_features=64, bias=False)
False Linear(in_features=64, out_features=2, bias=False)
True Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1024, out_features=128, bias=False)
False Linear(in_features=128, out_features=2, bias=False)
True Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1024, out_features=128, bias=False)
False Linear(in_features=128, out_features=2, bias=False)
True Linear(in_features=512, out_features=10, bias=True)
Epoch: 30 | Batch_idx: 0 |  Loss: (0.6472) |  Loss2: (0.0000) | Acc: (80.00%) (103/128)
Epoch: 30 | Batch_idx: 10 |  Loss: (0.5821) |  Loss2: (0.0000) | Acc: (80.00%) (1136/1408)
Epoch: 30 | Batch_idx: 20 |  Loss: (0.5641) |  Loss2: (0.0000) | Acc: (79.00%) (2149/2688)
Epoch: 30 | Batch_idx: 30 |  Loss: (0.5712) |  Loss2: (0.0000) | Acc: (80.00%) (3182/3968)
Epoch: 30 | Batch_idx: 40 |  Loss: (0.5778) |  Loss2: (0.0000) | Acc: (80.00%) (4203/5248)
Epoch: 30 | Batch_idx: 50 |  Loss: (0.5736) |  Loss2: (0.0000) | Acc: (80.00%) (5246/6528)
Epoch: 30 | Batch_idx: 60 |  Loss: (0.5720) |  Loss2: (0.0000) | Acc: (80.00%) (6290/7808)
Epoch: 30 | Batch_idx: 70 |  Loss: (0.5653) |  Loss2: (0.0000) | Acc: (80.00%) (7340/9088)
Epoch: 30 | Batch_idx: 80 |  Loss: (0.5691) |  Loss2: (0.0000) | Acc: (80.00%) (8355/10368)
Epoch: 30 | Batch_idx: 90 |  Loss: (0.5722) |  Loss2: (0.0000) | Acc: (80.00%) (9380/11648)
Epoch: 30 | Batch_idx: 100 |  Loss: (0.5703) |  Loss2: (0.0000) | Acc: (80.00%) (10416/12928)
Epoch: 30 | Batch_idx: 110 |  Loss: (0.5696) |  Loss2: (0.0000) | Acc: (80.00%) (11434/14208)
Epoch: 30 | Batch_idx: 120 |  Loss: (0.5696) |  Loss2: (0.0000) | Acc: (80.00%) (12463/15488)
Epoch: 30 | Batch_idx: 130 |  Loss: (0.5717) |  Loss2: (0.0000) | Acc: (80.00%) (13489/16768)
Epoch: 30 | Batch_idx: 140 |  Loss: (0.5734) |  Loss2: (0.0000) | Acc: (80.00%) (14494/18048)
Epoch: 30 | Batch_idx: 150 |  Loss: (0.5715) |  Loss2: (0.0000) | Acc: (80.00%) (15543/19328)
Epoch: 30 | Batch_idx: 160 |  Loss: (0.5729) |  Loss2: (0.0000) | Acc: (80.00%) (16556/20608)
Epoch: 30 | Batch_idx: 170 |  Loss: (0.5722) |  Loss2: (0.0000) | Acc: (80.00%) (17595/21888)
Epoch: 30 | Batch_idx: 180 |  Loss: (0.5742) |  Loss2: (0.0000) | Acc: (80.00%) (18605/23168)
Epoch: 30 | Batch_idx: 190 |  Loss: (0.5750) |  Loss2: (0.0000) | Acc: (80.00%) (19631/24448)
Epoch: 30 | Batch_idx: 200 |  Loss: (0.5720) |  Loss2: (0.0000) | Acc: (80.00%) (20684/25728)
Epoch: 30 | Batch_idx: 210 |  Loss: (0.5708) |  Loss2: (0.0000) | Acc: (80.00%) (21717/27008)
Epoch: 30 | Batch_idx: 220 |  Loss: (0.5705) |  Loss2: (0.0000) | Acc: (80.00%) (22741/28288)
Epoch: 30 | Batch_idx: 230 |  Loss: (0.5687) |  Loss2: (0.0000) | Acc: (80.00%) (23774/29568)
Epoch: 30 | Batch_idx: 240 |  Loss: (0.5682) |  Loss2: (0.0000) | Acc: (80.00%) (24818/30848)
Epoch: 30 | Batch_idx: 250 |  Loss: (0.5683) |  Loss2: (0.0000) | Acc: (80.00%) (25841/32128)
Epoch: 30 | Batch_idx: 260 |  Loss: (0.5688) |  Loss2: (0.0000) | Acc: (80.00%) (26864/33408)
Epoch: 30 | Batch_idx: 270 |  Loss: (0.5675) |  Loss2: (0.0000) | Acc: (80.00%) (27905/34688)
Epoch: 30 | Batch_idx: 280 |  Loss: (0.5675) |  Loss2: (0.0000) | Acc: (80.00%) (28933/35968)
Epoch: 30 | Batch_idx: 290 |  Loss: (0.5671) |  Loss2: (0.0000) | Acc: (80.00%) (29972/37248)
Epoch: 30 | Batch_idx: 300 |  Loss: (0.5671) |  Loss2: (0.0000) | Acc: (80.00%) (31001/38528)
Epoch: 30 | Batch_idx: 310 |  Loss: (0.5671) |  Loss2: (0.0000) | Acc: (80.00%) (32024/39808)
Epoch: 30 | Batch_idx: 320 |  Loss: (0.5672) |  Loss2: (0.0000) | Acc: (80.00%) (33055/41088)
Epoch: 30 | Batch_idx: 330 |  Loss: (0.5678) |  Loss2: (0.0000) | Acc: (80.00%) (34069/42368)
Epoch: 30 | Batch_idx: 340 |  Loss: (0.5685) |  Loss2: (0.0000) | Acc: (80.00%) (35090/43648)
Epoch: 30 | Batch_idx: 350 |  Loss: (0.5691) |  Loss2: (0.0000) | Acc: (80.00%) (36090/44928)
Epoch: 30 | Batch_idx: 360 |  Loss: (0.5693) |  Loss2: (0.0000) | Acc: (80.00%) (37105/46208)
Epoch: 30 | Batch_idx: 370 |  Loss: (0.5683) |  Loss2: (0.0000) | Acc: (80.00%) (38158/47488)
Epoch: 30 | Batch_idx: 380 |  Loss: (0.5681) |  Loss2: (0.0000) | Acc: (80.00%) (39200/48768)
Epoch: 30 | Batch_idx: 390 |  Loss: (0.5685) |  Loss2: (0.0000) | Acc: (80.00%) (40191/50000)
=> saving checkpoint 'drive/app/torch/save_Schedule/checkpoint_030.pth.tar'
# TEST : Loss: (0.6063) | Acc: (78.00%) (7875/10000)
percent tensor([0.5144, 0.5119, 0.5162, 0.5154, 0.5154, 0.5139, 0.5146, 0.5139, 0.5109,
        0.5142, 0.5115, 0.5164, 0.5138, 0.5092, 0.5147, 0.5143],
       device='cuda:0') torch.Size([16])
percent tensor([0.4998, 0.4951, 0.4955, 0.5009, 0.4926, 0.5062, 0.4920, 0.4927, 0.4964,
        0.4951, 0.4990, 0.4941, 0.4963, 0.4958, 0.4990, 0.5002],
       device='cuda:0') torch.Size([16])
percent tensor([0.4971, 0.3996, 0.5916, 0.5545, 0.5803, 0.5382, 0.4845, 0.5724, 0.5029,
        0.4488, 0.4021, 0.5394, 0.4280, 0.4246, 0.4658, 0.5030],
       device='cuda:0') torch.Size([16])
percent tensor([0.6238, 0.6378, 0.5890, 0.6042, 0.5940, 0.6067, 0.6236, 0.6066, 0.6293,
        0.6309, 0.6393, 0.6177, 0.6380, 0.6419, 0.6335, 0.6250],
       device='cuda:0') torch.Size([16])
percent tensor([0.5999, 0.5459, 0.6126, 0.6182, 0.6228, 0.6308, 0.5902, 0.6205, 0.5925,
        0.5485, 0.5442, 0.5855, 0.5513, 0.5966, 0.5844, 0.6250],
       device='cuda:0') torch.Size([16])
percent tensor([0.4647, 0.4792, 0.5101, 0.5392, 0.5344, 0.5541, 0.4744, 0.4665, 0.5021,
        0.4646, 0.4703, 0.4985, 0.4753, 0.5269, 0.4509, 0.4930],
       device='cuda:0') torch.Size([16])
percent tensor([0.6068, 0.6162, 0.6283, 0.6405, 0.6291, 0.6093, 0.6100, 0.6064, 0.6212,
        0.6329, 0.6333, 0.6211, 0.6166, 0.6382, 0.5866, 0.5847],
       device='cuda:0') torch.Size([16])
percent tensor([0.9989, 0.9948, 0.9976, 0.9977, 0.9981, 0.9967, 0.9991, 0.9993, 0.9937,
        0.9966, 0.9960, 0.9980, 0.9965, 0.9962, 0.9986, 0.9993],
       device='cuda:0') torch.Size([16])
Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 3, 3, 3]) tensor(171.2725, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(787.0032, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(785.6332, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([128, 64, 3, 3]) tensor(1526.5468, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([128, 64, 1, 1]) tensor(510.6811, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([128, 128, 3, 3]) tensor(2182.1182, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([256, 128, 3, 3]) tensor(4309.0527, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([256, 128, 1, 1]) tensor(1439.7360, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([256, 256, 3, 3]) tensor(6086.7871, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([512, 256, 3, 3]) tensor(12141.2314, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([512, 256, 1, 1]) tensor(4052.0103, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([512, 512, 3, 3]) tensor(17118.6348, device='cuda:0', grad_fn=<NormBackward0>)
Epoch: 31 | Batch_idx: 0 |  Loss: (0.6206) |  Loss2: (0.0000) | Acc: (76.00%) (98/128)
Epoch: 31 | Batch_idx: 10 |  Loss: (0.5729) |  Loss2: (0.0000) | Acc: (78.00%) (1109/1408)
Epoch: 31 | Batch_idx: 20 |  Loss: (0.5600) |  Loss2: (0.0000) | Acc: (79.00%) (2143/2688)
Epoch: 31 | Batch_idx: 30 |  Loss: (0.5550) |  Loss2: (0.0000) | Acc: (80.00%) (3186/3968)
Epoch: 31 | Batch_idx: 40 |  Loss: (0.5494) |  Loss2: (0.0000) | Acc: (80.00%) (4234/5248)
Epoch: 31 | Batch_idx: 50 |  Loss: (0.5449) |  Loss2: (0.0000) | Acc: (80.00%) (5268/6528)
Epoch: 31 | Batch_idx: 60 |  Loss: (0.5513) |  Loss2: (0.0000) | Acc: (80.00%) (6290/7808)
Epoch: 31 | Batch_idx: 70 |  Loss: (0.5477) |  Loss2: (0.0000) | Acc: (80.00%) (7338/9088)
Epoch: 31 | Batch_idx: 80 |  Loss: (0.5499) |  Loss2: (0.0000) | Acc: (80.00%) (8387/10368)
Epoch: 31 | Batch_idx: 90 |  Loss: (0.5516) |  Loss2: (0.0000) | Acc: (80.00%) (9419/11648)
Epoch: 31 | Batch_idx: 100 |  Loss: (0.5522) |  Loss2: (0.0000) | Acc: (80.00%) (10455/12928)
Epoch: 31 | Batch_idx: 110 |  Loss: (0.5518) |  Loss2: (0.0000) | Acc: (80.00%) (11488/14208)
Epoch: 31 | Batch_idx: 120 |  Loss: (0.5535) |  Loss2: (0.0000) | Acc: (80.00%) (12499/15488)
Epoch: 31 | Batch_idx: 130 |  Loss: (0.5491) |  Loss2: (0.0000) | Acc: (80.00%) (13562/16768)
Epoch: 31 | Batch_idx: 140 |  Loss: (0.5496) |  Loss2: (0.0000) | Acc: (80.00%) (14580/18048)
Epoch: 31 | Batch_idx: 150 |  Loss: (0.5492) |  Loss2: (0.0000) | Acc: (80.00%) (15611/19328)
Epoch: 31 | Batch_idx: 160 |  Loss: (0.5492) |  Loss2: (0.0000) | Acc: (80.00%) (16652/20608)
Epoch: 31 | Batch_idx: 170 |  Loss: (0.5471) |  Loss2: (0.0000) | Acc: (80.00%) (17698/21888)
Epoch: 31 | Batch_idx: 180 |  Loss: (0.5467) |  Loss2: (0.0000) | Acc: (80.00%) (18738/23168)
Epoch: 31 | Batch_idx: 190 |  Loss: (0.5469) |  Loss2: (0.0000) | Acc: (80.00%) (19787/24448)
Epoch: 31 | Batch_idx: 200 |  Loss: (0.5470) |  Loss2: (0.0000) | Acc: (80.00%) (20831/25728)
Epoch: 31 | Batch_idx: 210 |  Loss: (0.5495) |  Loss2: (0.0000) | Acc: (80.00%) (21854/27008)
Epoch: 31 | Batch_idx: 220 |  Loss: (0.5488) |  Loss2: (0.0000) | Acc: (80.00%) (22892/28288)
Epoch: 31 | Batch_idx: 230 |  Loss: (0.5488) |  Loss2: (0.0000) | Acc: (80.00%) (23930/29568)
Epoch: 31 | Batch_idx: 240 |  Loss: (0.5493) |  Loss2: (0.0000) | Acc: (80.00%) (24959/30848)
Epoch: 31 | Batch_idx: 250 |  Loss: (0.5492) |  Loss2: (0.0000) | Acc: (80.00%) (26008/32128)
Epoch: 31 | Batch_idx: 260 |  Loss: (0.5478) |  Loss2: (0.0000) | Acc: (80.00%) (27057/33408)
Epoch: 31 | Batch_idx: 270 |  Loss: (0.5456) |  Loss2: (0.0000) | Acc: (81.00%) (28109/34688)
Epoch: 31 | Batch_idx: 280 |  Loss: (0.5457) |  Loss2: (0.0000) | Acc: (81.00%) (29146/35968)
Epoch: 31 | Batch_idx: 290 |  Loss: (0.5433) |  Loss2: (0.0000) | Acc: (81.00%) (30206/37248)
Epoch: 31 | Batch_idx: 300 |  Loss: (0.5425) |  Loss2: (0.0000) | Acc: (81.00%) (31255/38528)
Epoch: 31 | Batch_idx: 310 |  Loss: (0.5428) |  Loss2: (0.0000) | Acc: (81.00%) (32298/39808)
Epoch: 31 | Batch_idx: 320 |  Loss: (0.5424) |  Loss2: (0.0000) | Acc: (81.00%) (33333/41088)
Epoch: 31 | Batch_idx: 330 |  Loss: (0.5422) |  Loss2: (0.0000) | Acc: (81.00%) (34362/42368)
Epoch: 31 | Batch_idx: 340 |  Loss: (0.5418) |  Loss2: (0.0000) | Acc: (81.00%) (35409/43648)
Epoch: 31 | Batch_idx: 350 |  Loss: (0.5423) |  Loss2: (0.0000) | Acc: (81.00%) (36434/44928)
Epoch: 31 | Batch_idx: 360 |  Loss: (0.5428) |  Loss2: (0.0000) | Acc: (81.00%) (37468/46208)
Epoch: 31 | Batch_idx: 370 |  Loss: (0.5416) |  Loss2: (0.0000) | Acc: (81.00%) (38513/47488)
Epoch: 31 | Batch_idx: 380 |  Loss: (0.5422) |  Loss2: (0.0000) | Acc: (81.00%) (39531/48768)
Epoch: 31 | Batch_idx: 390 |  Loss: (0.5427) |  Loss2: (0.0000) | Acc: (81.00%) (40533/50000)
# TEST : Loss: (0.5968) | Acc: (79.00%) (7939/10000)
percent tensor([0.5147, 0.5124, 0.5157, 0.5157, 0.5153, 0.5146, 0.5145, 0.5139, 0.5112,
        0.5141, 0.5119, 0.5161, 0.5141, 0.5103, 0.5152, 0.5152],
       device='cuda:0') torch.Size([16])
percent tensor([0.4998, 0.4951, 0.4976, 0.5014, 0.4944, 0.5058, 0.4928, 0.4936, 0.4958,
        0.4959, 0.4989, 0.4961, 0.4964, 0.4949, 0.4992, 0.4994],
       device='cuda:0') torch.Size([16])
percent tensor([0.4952, 0.4054, 0.5927, 0.5658, 0.5867, 0.5420, 0.4912, 0.5770, 0.5186,
        0.4495, 0.4049, 0.5439, 0.4284, 0.4508, 0.4618, 0.5091],
       device='cuda:0') torch.Size([16])
percent tensor([0.6282, 0.6415, 0.5976, 0.6082, 0.5994, 0.6128, 0.6241, 0.6111, 0.6296,
        0.6369, 0.6408, 0.6228, 0.6434, 0.6369, 0.6380, 0.6301],
       device='cuda:0') torch.Size([16])
percent tensor([0.5949, 0.5418, 0.6266, 0.6294, 0.6347, 0.6311, 0.5985, 0.6271, 0.5917,
        0.5442, 0.5337, 0.5918, 0.5419, 0.5902, 0.5820, 0.6242],
       device='cuda:0') torch.Size([16])
percent tensor([0.4740, 0.4883, 0.5305, 0.5509, 0.5548, 0.5603, 0.4973, 0.4852, 0.5173,
        0.4842, 0.4852, 0.5115, 0.4970, 0.5299, 0.4513, 0.5042],
       device='cuda:0') torch.Size([16])
percent tensor([0.6041, 0.6084, 0.6240, 0.6305, 0.6271, 0.6118, 0.5957, 0.5928, 0.6170,
        0.6328, 0.6330, 0.6206, 0.6061, 0.6265, 0.5916, 0.5785],
       device='cuda:0') torch.Size([16])
percent tensor([0.9986, 0.9935, 0.9984, 0.9978, 0.9969, 0.9959, 0.9984, 0.9992, 0.9908,
        0.9948, 0.9957, 0.9984, 0.9943, 0.9933, 0.9989, 0.9988],
       device='cuda:0') torch.Size([16])
Epoch: 32 | Batch_idx: 0 |  Loss: (0.5405) |  Loss2: (0.0000) | Acc: (80.00%) (103/128)
Epoch: 32 | Batch_idx: 10 |  Loss: (0.5301) |  Loss2: (0.0000) | Acc: (81.00%) (1142/1408)
Epoch: 32 | Batch_idx: 20 |  Loss: (0.5041) |  Loss2: (0.0000) | Acc: (82.00%) (2215/2688)
Epoch: 32 | Batch_idx: 30 |  Loss: (0.5177) |  Loss2: (0.0000) | Acc: (81.00%) (3245/3968)
Epoch: 32 | Batch_idx: 40 |  Loss: (0.5207) |  Loss2: (0.0000) | Acc: (81.00%) (4292/5248)
Epoch: 32 | Batch_idx: 50 |  Loss: (0.5200) |  Loss2: (0.0000) | Acc: (81.00%) (5349/6528)
Epoch: 32 | Batch_idx: 60 |  Loss: (0.5237) |  Loss2: (0.0000) | Acc: (82.00%) (6404/7808)
Epoch: 32 | Batch_idx: 70 |  Loss: (0.5245) |  Loss2: (0.0000) | Acc: (82.00%) (7455/9088)
Epoch: 32 | Batch_idx: 80 |  Loss: (0.5276) |  Loss2: (0.0000) | Acc: (81.00%) (8497/10368)
Epoch: 32 | Batch_idx: 90 |  Loss: (0.5232) |  Loss2: (0.0000) | Acc: (82.00%) (9563/11648)
Epoch: 32 | Batch_idx: 100 |  Loss: (0.5232) |  Loss2: (0.0000) | Acc: (82.00%) (10625/12928)
Epoch: 32 | Batch_idx: 110 |  Loss: (0.5261) |  Loss2: (0.0000) | Acc: (82.00%) (11669/14208)
Epoch: 32 | Batch_idx: 120 |  Loss: (0.5271) |  Loss2: (0.0000) | Acc: (81.00%) (12699/15488)
Epoch: 32 | Batch_idx: 130 |  Loss: (0.5308) |  Loss2: (0.0000) | Acc: (81.00%) (13730/16768)
Epoch: 32 | Batch_idx: 140 |  Loss: (0.5311) |  Loss2: (0.0000) | Acc: (81.00%) (14774/18048)
Epoch: 32 | Batch_idx: 150 |  Loss: (0.5280) |  Loss2: (0.0000) | Acc: (81.00%) (15835/19328)
Epoch: 32 | Batch_idx: 160 |  Loss: (0.5274) |  Loss2: (0.0000) | Acc: (81.00%) (16893/20608)
Epoch: 32 | Batch_idx: 170 |  Loss: (0.5264) |  Loss2: (0.0000) | Acc: (82.00%) (17960/21888)
Epoch: 32 | Batch_idx: 180 |  Loss: (0.5270) |  Loss2: (0.0000) | Acc: (81.00%) (18992/23168)
Epoch: 32 | Batch_idx: 190 |  Loss: (0.5256) |  Loss2: (0.0000) | Acc: (82.00%) (20054/24448)
Epoch: 32 | Batch_idx: 200 |  Loss: (0.5261) |  Loss2: (0.0000) | Acc: (82.00%) (21103/25728)
Epoch: 32 | Batch_idx: 210 |  Loss: (0.5282) |  Loss2: (0.0000) | Acc: (81.00%) (22119/27008)
Epoch: 32 | Batch_idx: 220 |  Loss: (0.5254) |  Loss2: (0.0000) | Acc: (82.00%) (23207/28288)
Epoch: 32 | Batch_idx: 230 |  Loss: (0.5244) |  Loss2: (0.0000) | Acc: (82.00%) (24270/29568)
Epoch: 32 | Batch_idx: 240 |  Loss: (0.5241) |  Loss2: (0.0000) | Acc: (82.00%) (25330/30848)
Epoch: 32 | Batch_idx: 250 |  Loss: (0.5228) |  Loss2: (0.0000) | Acc: (82.00%) (26397/32128)
Epoch: 32 | Batch_idx: 260 |  Loss: (0.5225) |  Loss2: (0.0000) | Acc: (82.00%) (27442/33408)
Epoch: 32 | Batch_idx: 270 |  Loss: (0.5224) |  Loss2: (0.0000) | Acc: (82.00%) (28506/34688)
Epoch: 32 | Batch_idx: 280 |  Loss: (0.5221) |  Loss2: (0.0000) | Acc: (82.00%) (29556/35968)
Epoch: 32 | Batch_idx: 290 |  Loss: (0.5226) |  Loss2: (0.0000) | Acc: (82.00%) (30599/37248)
Epoch: 32 | Batch_idx: 300 |  Loss: (0.5213) |  Loss2: (0.0000) | Acc: (82.00%) (31666/38528)
Epoch: 32 | Batch_idx: 310 |  Loss: (0.5211) |  Loss2: (0.0000) | Acc: (82.00%) (32707/39808)
Epoch: 32 | Batch_idx: 320 |  Loss: (0.5222) |  Loss2: (0.0000) | Acc: (82.00%) (33737/41088)
Epoch: 32 | Batch_idx: 330 |  Loss: (0.5228) |  Loss2: (0.0000) | Acc: (82.00%) (34782/42368)
Epoch: 32 | Batch_idx: 340 |  Loss: (0.5235) |  Loss2: (0.0000) | Acc: (82.00%) (35828/43648)
Epoch: 32 | Batch_idx: 350 |  Loss: (0.5232) |  Loss2: (0.0000) | Acc: (82.00%) (36880/44928)
Epoch: 32 | Batch_idx: 360 |  Loss: (0.5238) |  Loss2: (0.0000) | Acc: (82.00%) (37923/46208)
Epoch: 32 | Batch_idx: 370 |  Loss: (0.5242) |  Loss2: (0.0000) | Acc: (82.00%) (38967/47488)
Epoch: 32 | Batch_idx: 380 |  Loss: (0.5242) |  Loss2: (0.0000) | Acc: (82.00%) (40008/48768)
Epoch: 32 | Batch_idx: 390 |  Loss: (0.5232) |  Loss2: (0.0000) | Acc: (82.00%) (41055/50000)
# TEST : Loss: (0.6523) | Acc: (77.00%) (7722/10000)
percent tensor([0.5149, 0.5121, 0.5170, 0.5158, 0.5161, 0.5154, 0.5149, 0.5143, 0.5109,
        0.5146, 0.5121, 0.5171, 0.5141, 0.5095, 0.5153, 0.5150],
       device='cuda:0') torch.Size([16])
percent tensor([0.4997, 0.4949, 0.4967, 0.5017, 0.4935, 0.5060, 0.4920, 0.4935, 0.4960,
        0.4954, 0.4984, 0.4945, 0.4962, 0.4954, 0.4990, 0.4998],
       device='cuda:0') torch.Size([16])
percent tensor([0.4896, 0.4025, 0.5773, 0.5520, 0.5724, 0.5215, 0.4796, 0.5678, 0.4990,
        0.4440, 0.4060, 0.5293, 0.4224, 0.4420, 0.4597, 0.4965],
       device='cuda:0') torch.Size([16])
percent tensor([0.6276, 0.6381, 0.5952, 0.6083, 0.5981, 0.6094, 0.6253, 0.6093, 0.6267,
        0.6314, 0.6421, 0.6217, 0.6404, 0.6368, 0.6362, 0.6301],
       device='cuda:0') torch.Size([16])
percent tensor([0.5968, 0.5482, 0.6084, 0.6163, 0.6208, 0.6280, 0.5869, 0.6244, 0.5889,
        0.5448, 0.5437, 0.5812, 0.5476, 0.5956, 0.5864, 0.6239],
       device='cuda:0') torch.Size([16])
percent tensor([0.4772, 0.4919, 0.5094, 0.5276, 0.5273, 0.5566, 0.4891, 0.4698, 0.5181,
        0.4727, 0.4920, 0.5006, 0.4951, 0.5367, 0.4615, 0.4990],
       device='cuda:0') torch.Size([16])
percent tensor([0.6009, 0.6112, 0.6191, 0.6266, 0.6196, 0.6013, 0.5952, 0.5900, 0.6179,
        0.6302, 0.6335, 0.6180, 0.6103, 0.6352, 0.5792, 0.5742],
       device='cuda:0') torch.Size([16])
percent tensor([0.9992, 0.9947, 0.9985, 0.9987, 0.9990, 0.9966, 0.9974, 0.9994, 0.9932,
        0.9962, 0.9966, 0.9990, 0.9954, 0.9955, 0.9982, 0.9990],
       device='cuda:0') torch.Size([16])
False Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=128, out_features=16, bias=False)
True Linear(in_features=16, out_features=2, bias=False)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=128, out_features=16, bias=False)
True Linear(in_features=16, out_features=2, bias=False)
False Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=256, out_features=32, bias=False)
True Linear(in_features=32, out_features=2, bias=False)
False Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=256, out_features=32, bias=False)
True Linear(in_features=32, out_features=2, bias=False)
False Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=512, out_features=64, bias=False)
True Linear(in_features=64, out_features=2, bias=False)
False Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=512, out_features=64, bias=False)
True Linear(in_features=64, out_features=2, bias=False)
False Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1024, out_features=128, bias=False)
True Linear(in_features=128, out_features=2, bias=False)
False Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1024, out_features=128, bias=False)
True Linear(in_features=128, out_features=2, bias=False)
False Linear(in_features=512, out_features=10, bias=True)
Epoch: 33 | Batch_idx: 0 |  Loss: (0.4744) |  Loss2: (0.0000) | Acc: (82.00%) (105/128)
Epoch: 33 | Batch_idx: 10 |  Loss: (0.5426) |  Loss2: (0.0000) | Acc: (80.00%) (1135/1408)
Epoch: 33 | Batch_idx: 20 |  Loss: (0.5442) |  Loss2: (0.0000) | Acc: (80.00%) (2177/2688)
Epoch: 33 | Batch_idx: 30 |  Loss: (0.5528) |  Loss2: (0.0000) | Acc: (80.00%) (3213/3968)
Epoch: 33 | Batch_idx: 40 |  Loss: (0.5598) |  Loss2: (0.0000) | Acc: (80.00%) (4242/5248)
Epoch: 33 | Batch_idx: 50 |  Loss: (0.5651) |  Loss2: (0.0000) | Acc: (80.00%) (5264/6528)
Epoch: 33 | Batch_idx: 60 |  Loss: (0.5703) |  Loss2: (0.0000) | Acc: (80.00%) (6272/7808)
Epoch: 33 | Batch_idx: 70 |  Loss: (0.5709) |  Loss2: (0.0000) | Acc: (80.00%) (7299/9088)
Epoch: 33 | Batch_idx: 80 |  Loss: (0.5718) |  Loss2: (0.0000) | Acc: (80.00%) (8332/10368)
Epoch: 33 | Batch_idx: 90 |  Loss: (0.5710) |  Loss2: (0.0000) | Acc: (80.00%) (9375/11648)
Epoch: 33 | Batch_idx: 100 |  Loss: (0.5700) |  Loss2: (0.0000) | Acc: (80.00%) (10402/12928)
Epoch: 33 | Batch_idx: 110 |  Loss: (0.5702) |  Loss2: (0.0000) | Acc: (80.00%) (11427/14208)
Epoch: 33 | Batch_idx: 120 |  Loss: (0.5674) |  Loss2: (0.0000) | Acc: (80.00%) (12466/15488)
Epoch: 33 | Batch_idx: 130 |  Loss: (0.5639) |  Loss2: (0.0000) | Acc: (80.00%) (13510/16768)
Epoch: 33 | Batch_idx: 140 |  Loss: (0.5624) |  Loss2: (0.0000) | Acc: (80.00%) (14564/18048)
Epoch: 33 | Batch_idx: 150 |  Loss: (0.5601) |  Loss2: (0.0000) | Acc: (80.00%) (15618/19328)
Epoch: 33 | Batch_idx: 160 |  Loss: (0.5594) |  Loss2: (0.0000) | Acc: (80.00%) (16669/20608)
Epoch: 33 | Batch_idx: 170 |  Loss: (0.5585) |  Loss2: (0.0000) | Acc: (80.00%) (17708/21888)
Epoch: 33 | Batch_idx: 180 |  Loss: (0.5583) |  Loss2: (0.0000) | Acc: (80.00%) (18751/23168)
Epoch: 33 | Batch_idx: 190 |  Loss: (0.5553) |  Loss2: (0.0000) | Acc: (81.00%) (19809/24448)
Epoch: 33 | Batch_idx: 200 |  Loss: (0.5524) |  Loss2: (0.0000) | Acc: (81.00%) (20874/25728)
Epoch: 33 | Batch_idx: 210 |  Loss: (0.5506) |  Loss2: (0.0000) | Acc: (81.00%) (21925/27008)
Epoch: 33 | Batch_idx: 220 |  Loss: (0.5494) |  Loss2: (0.0000) | Acc: (81.00%) (22969/28288)
Epoch: 33 | Batch_idx: 230 |  Loss: (0.5483) |  Loss2: (0.0000) | Acc: (81.00%) (24024/29568)
Epoch: 33 | Batch_idx: 240 |  Loss: (0.5472) |  Loss2: (0.0000) | Acc: (81.00%) (25073/30848)
Epoch: 33 | Batch_idx: 250 |  Loss: (0.5457) |  Loss2: (0.0000) | Acc: (81.00%) (26134/32128)
Epoch: 33 | Batch_idx: 260 |  Loss: (0.5455) |  Loss2: (0.0000) | Acc: (81.00%) (27169/33408)
Epoch: 33 | Batch_idx: 270 |  Loss: (0.5457) |  Loss2: (0.0000) | Acc: (81.00%) (28207/34688)
Epoch: 33 | Batch_idx: 280 |  Loss: (0.5447) |  Loss2: (0.0000) | Acc: (81.00%) (29255/35968)
Epoch: 33 | Batch_idx: 290 |  Loss: (0.5452) |  Loss2: (0.0000) | Acc: (81.00%) (30293/37248)
Epoch: 33 | Batch_idx: 300 |  Loss: (0.5440) |  Loss2: (0.0000) | Acc: (81.00%) (31353/38528)
Epoch: 33 | Batch_idx: 310 |  Loss: (0.5431) |  Loss2: (0.0000) | Acc: (81.00%) (32426/39808)
Epoch: 33 | Batch_idx: 320 |  Loss: (0.5415) |  Loss2: (0.0000) | Acc: (81.00%) (33500/41088)
Epoch: 33 | Batch_idx: 330 |  Loss: (0.5410) |  Loss2: (0.0000) | Acc: (81.00%) (34555/42368)
Epoch: 33 | Batch_idx: 340 |  Loss: (0.5404) |  Loss2: (0.0000) | Acc: (81.00%) (35596/43648)
Epoch: 33 | Batch_idx: 350 |  Loss: (0.5398) |  Loss2: (0.0000) | Acc: (81.00%) (36649/44928)
Epoch: 33 | Batch_idx: 360 |  Loss: (0.5385) |  Loss2: (0.0000) | Acc: (81.00%) (37714/46208)
Epoch: 33 | Batch_idx: 370 |  Loss: (0.5388) |  Loss2: (0.0000) | Acc: (81.00%) (38751/47488)
Epoch: 33 | Batch_idx: 380 |  Loss: (0.5383) |  Loss2: (0.0000) | Acc: (81.00%) (39781/48768)
Epoch: 33 | Batch_idx: 390 |  Loss: (0.5387) |  Loss2: (0.0000) | Acc: (81.00%) (40774/50000)
# TEST : Loss: (0.5506) | Acc: (81.00%) (8118/10000)
percent tensor([0.5174, 0.5178, 0.5196, 0.5174, 0.5191, 0.5173, 0.5199, 0.5176, 0.5153,
        0.5186, 0.5169, 0.5203, 0.5178, 0.5145, 0.5194, 0.5179],
       device='cuda:0') torch.Size([16])
percent tensor([0.5017, 0.4986, 0.4981, 0.5027, 0.4962, 0.5071, 0.4956, 0.4961, 0.4988,
        0.4986, 0.5015, 0.4968, 0.4990, 0.4981, 0.5022, 0.5016],
       device='cuda:0') torch.Size([16])
percent tensor([0.4931, 0.4125, 0.5754, 0.5494, 0.5710, 0.5086, 0.4956, 0.5676, 0.5055,
        0.4562, 0.4180, 0.5428, 0.4306, 0.4496, 0.4627, 0.4943],
       device='cuda:0') torch.Size([16])
percent tensor([0.6395, 0.6583, 0.5977, 0.6088, 0.5979, 0.6153, 0.6366, 0.6119, 0.6357,
        0.6489, 0.6608, 0.6336, 0.6604, 0.6476, 0.6500, 0.6421],
       device='cuda:0') torch.Size([16])
percent tensor([0.6094, 0.5768, 0.6150, 0.6202, 0.6214, 0.6156, 0.6103, 0.6310, 0.6006,
        0.5729, 0.5710, 0.5991, 0.5751, 0.6157, 0.6026, 0.6315],
       device='cuda:0') torch.Size([16])
percent tensor([0.4556, 0.4711, 0.5035, 0.5294, 0.5318, 0.5467, 0.4750, 0.4579, 0.5055,
        0.4601, 0.4765, 0.4921, 0.4826, 0.5218, 0.4420, 0.4800],
       device='cuda:0') torch.Size([16])
percent tensor([0.5712, 0.5707, 0.5954, 0.6079, 0.6035, 0.5911, 0.5670, 0.5720, 0.5849,
        0.5890, 0.5937, 0.5896, 0.5711, 0.6000, 0.5555, 0.5595],
       device='cuda:0') torch.Size([16])
percent tensor([0.9991, 0.9956, 0.9982, 0.9989, 0.9981, 0.9974, 0.9979, 0.9995, 0.9940,
        0.9967, 0.9967, 0.9988, 0.9962, 0.9963, 0.9983, 0.9993],
       device='cuda:0') torch.Size([16])
Epoch: 34 | Batch_idx: 0 |  Loss: (0.7155) |  Loss2: (0.0000) | Acc: (75.00%) (96/128)
Epoch: 34 | Batch_idx: 10 |  Loss: (0.5351) |  Loss2: (0.0000) | Acc: (80.00%) (1140/1408)
Epoch: 34 | Batch_idx: 20 |  Loss: (0.5394) |  Loss2: (0.0000) | Acc: (81.00%) (2185/2688)
Epoch: 34 | Batch_idx: 30 |  Loss: (0.5296) |  Loss2: (0.0000) | Acc: (81.00%) (3230/3968)
Epoch: 34 | Batch_idx: 40 |  Loss: (0.5271) |  Loss2: (0.0000) | Acc: (81.00%) (4284/5248)
Epoch: 34 | Batch_idx: 50 |  Loss: (0.5219) |  Loss2: (0.0000) | Acc: (81.00%) (5339/6528)
Epoch: 34 | Batch_idx: 60 |  Loss: (0.5257) |  Loss2: (0.0000) | Acc: (81.00%) (6379/7808)
Epoch: 34 | Batch_idx: 70 |  Loss: (0.5264) |  Loss2: (0.0000) | Acc: (81.00%) (7435/9088)
Epoch: 34 | Batch_idx: 80 |  Loss: (0.5225) |  Loss2: (0.0000) | Acc: (82.00%) (8504/10368)
Epoch: 34 | Batch_idx: 90 |  Loss: (0.5193) |  Loss2: (0.0000) | Acc: (82.00%) (9573/11648)
Epoch: 34 | Batch_idx: 100 |  Loss: (0.5192) |  Loss2: (0.0000) | Acc: (82.00%) (10625/12928)
Epoch: 34 | Batch_idx: 110 |  Loss: (0.5190) |  Loss2: (0.0000) | Acc: (82.00%) (11687/14208)
Epoch: 34 | Batch_idx: 120 |  Loss: (0.5181) |  Loss2: (0.0000) | Acc: (82.00%) (12741/15488)
Epoch: 34 | Batch_idx: 130 |  Loss: (0.5167) |  Loss2: (0.0000) | Acc: (82.00%) (13801/16768)
Epoch: 34 | Batch_idx: 140 |  Loss: (0.5159) |  Loss2: (0.0000) | Acc: (82.00%) (14861/18048)
Epoch: 34 | Batch_idx: 150 |  Loss: (0.5141) |  Loss2: (0.0000) | Acc: (82.00%) (15901/19328)
Epoch: 34 | Batch_idx: 160 |  Loss: (0.5116) |  Loss2: (0.0000) | Acc: (82.00%) (16968/20608)
Epoch: 34 | Batch_idx: 170 |  Loss: (0.5120) |  Loss2: (0.0000) | Acc: (82.00%) (18023/21888)
Epoch: 34 | Batch_idx: 180 |  Loss: (0.5123) |  Loss2: (0.0000) | Acc: (82.00%) (19079/23168)
Epoch: 34 | Batch_idx: 190 |  Loss: (0.5133) |  Loss2: (0.0000) | Acc: (82.00%) (20129/24448)
Epoch: 34 | Batch_idx: 200 |  Loss: (0.5119) |  Loss2: (0.0000) | Acc: (82.00%) (21190/25728)
Epoch: 34 | Batch_idx: 210 |  Loss: (0.5112) |  Loss2: (0.0000) | Acc: (82.00%) (22247/27008)
Epoch: 34 | Batch_idx: 220 |  Loss: (0.5107) |  Loss2: (0.0000) | Acc: (82.00%) (23306/28288)
Epoch: 34 | Batch_idx: 230 |  Loss: (0.5104) |  Loss2: (0.0000) | Acc: (82.00%) (24370/29568)
Epoch: 34 | Batch_idx: 240 |  Loss: (0.5102) |  Loss2: (0.0000) | Acc: (82.00%) (25434/30848)
Epoch: 34 | Batch_idx: 250 |  Loss: (0.5087) |  Loss2: (0.0000) | Acc: (82.00%) (26508/32128)
Epoch: 34 | Batch_idx: 260 |  Loss: (0.5082) |  Loss2: (0.0000) | Acc: (82.00%) (27571/33408)
Epoch: 34 | Batch_idx: 270 |  Loss: (0.5081) |  Loss2: (0.0000) | Acc: (82.00%) (28628/34688)
Epoch: 34 | Batch_idx: 280 |  Loss: (0.5084) |  Loss2: (0.0000) | Acc: (82.00%) (29692/35968)
Epoch: 34 | Batch_idx: 290 |  Loss: (0.5074) |  Loss2: (0.0000) | Acc: (82.00%) (30765/37248)
Epoch: 34 | Batch_idx: 300 |  Loss: (0.5068) |  Loss2: (0.0000) | Acc: (82.00%) (31833/38528)
Epoch: 34 | Batch_idx: 310 |  Loss: (0.5063) |  Loss2: (0.0000) | Acc: (82.00%) (32919/39808)
Epoch: 34 | Batch_idx: 320 |  Loss: (0.5059) |  Loss2: (0.0000) | Acc: (82.00%) (33982/41088)
Epoch: 34 | Batch_idx: 330 |  Loss: (0.5053) |  Loss2: (0.0000) | Acc: (82.00%) (35064/42368)
Epoch: 34 | Batch_idx: 340 |  Loss: (0.5051) |  Loss2: (0.0000) | Acc: (82.00%) (36133/43648)
Epoch: 34 | Batch_idx: 350 |  Loss: (0.5055) |  Loss2: (0.0000) | Acc: (82.00%) (37177/44928)
Epoch: 34 | Batch_idx: 360 |  Loss: (0.5054) |  Loss2: (0.0000) | Acc: (82.00%) (38241/46208)
Epoch: 34 | Batch_idx: 370 |  Loss: (0.5053) |  Loss2: (0.0000) | Acc: (82.00%) (39300/47488)
Epoch: 34 | Batch_idx: 380 |  Loss: (0.5053) |  Loss2: (0.0000) | Acc: (82.00%) (40357/48768)
Epoch: 34 | Batch_idx: 390 |  Loss: (0.5056) |  Loss2: (0.0000) | Acc: (82.00%) (41370/50000)
# TEST : Loss: (0.5347) | Acc: (81.00%) (8150/10000)
percent tensor([0.5158, 0.5167, 0.5177, 0.5159, 0.5173, 0.5156, 0.5185, 0.5161, 0.5141,
        0.5172, 0.5156, 0.5184, 0.5164, 0.5138, 0.5179, 0.5165],
       device='cuda:0') torch.Size([16])
percent tensor([0.5023, 0.4997, 0.4988, 0.5032, 0.4970, 0.5072, 0.4968, 0.4969, 0.4996,
        0.4997, 0.5024, 0.4979, 0.4999, 0.4990, 0.5030, 0.5021],
       device='cuda:0') torch.Size([16])
percent tensor([0.4927, 0.4133, 0.5791, 0.5529, 0.5747, 0.5025, 0.5012, 0.5726, 0.5104,
        0.4585, 0.4213, 0.5466, 0.4300, 0.4534, 0.4624, 0.4926],
       device='cuda:0') torch.Size([16])
percent tensor([0.6487, 0.6721, 0.5993, 0.6102, 0.5992, 0.6214, 0.6455, 0.6137, 0.6421,
        0.6616, 0.6742, 0.6415, 0.6739, 0.6575, 0.6599, 0.6520],
       device='cuda:0') torch.Size([16])
percent tensor([0.6182, 0.5865, 0.6191, 0.6245, 0.6250, 0.6139, 0.6200, 0.6382, 0.6099,
        0.5847, 0.5857, 0.6072, 0.5838, 0.6240, 0.6131, 0.6377],
       device='cuda:0') torch.Size([16])
percent tensor([0.4566, 0.4716, 0.5089, 0.5363, 0.5398, 0.5503, 0.4788, 0.4649, 0.5104,
        0.4630, 0.4802, 0.4944, 0.4833, 0.5255, 0.4429, 0.4826],
       device='cuda:0') torch.Size([16])
percent tensor([0.5797, 0.5782, 0.6077, 0.6200, 0.6162, 0.6070, 0.5772, 0.5853, 0.5947,
        0.5952, 0.5994, 0.6029, 0.5774, 0.6090, 0.5705, 0.5702],
       device='cuda:0') torch.Size([16])
percent tensor([0.9992, 0.9963, 0.9984, 0.9991, 0.9985, 0.9975, 0.9983, 0.9996, 0.9951,
        0.9974, 0.9974, 0.9992, 0.9970, 0.9971, 0.9988, 0.9993],
       device='cuda:0') torch.Size([16])
Epoch: 35 | Batch_idx: 0 |  Loss: (0.4366) |  Loss2: (0.0000) | Acc: (84.00%) (108/128)
Epoch: 35 | Batch_idx: 10 |  Loss: (0.5298) |  Loss2: (0.0000) | Acc: (80.00%) (1128/1408)
Epoch: 35 | Batch_idx: 20 |  Loss: (0.5181) |  Loss2: (0.0000) | Acc: (81.00%) (2184/2688)
Epoch: 35 | Batch_idx: 30 |  Loss: (0.5131) |  Loss2: (0.0000) | Acc: (81.00%) (3235/3968)
Epoch: 35 | Batch_idx: 40 |  Loss: (0.5065) |  Loss2: (0.0000) | Acc: (81.00%) (4294/5248)
Epoch: 35 | Batch_idx: 50 |  Loss: (0.5008) |  Loss2: (0.0000) | Acc: (82.00%) (5359/6528)
Epoch: 35 | Batch_idx: 60 |  Loss: (0.4995) |  Loss2: (0.0000) | Acc: (82.00%) (6426/7808)
Epoch: 35 | Batch_idx: 70 |  Loss: (0.5012) |  Loss2: (0.0000) | Acc: (82.00%) (7486/9088)
Epoch: 35 | Batch_idx: 80 |  Loss: (0.4998) |  Loss2: (0.0000) | Acc: (82.00%) (8565/10368)
Epoch: 35 | Batch_idx: 90 |  Loss: (0.4966) |  Loss2: (0.0000) | Acc: (82.00%) (9631/11648)
Epoch: 35 | Batch_idx: 100 |  Loss: (0.4944) |  Loss2: (0.0000) | Acc: (82.00%) (10707/12928)
Epoch: 35 | Batch_idx: 110 |  Loss: (0.4944) |  Loss2: (0.0000) | Acc: (82.00%) (11780/14208)
Epoch: 35 | Batch_idx: 120 |  Loss: (0.4920) |  Loss2: (0.0000) | Acc: (83.00%) (12867/15488)
Epoch: 35 | Batch_idx: 130 |  Loss: (0.4936) |  Loss2: (0.0000) | Acc: (83.00%) (13929/16768)
Epoch: 35 | Batch_idx: 140 |  Loss: (0.4928) |  Loss2: (0.0000) | Acc: (83.00%) (14991/18048)
Epoch: 35 | Batch_idx: 150 |  Loss: (0.4939) |  Loss2: (0.0000) | Acc: (83.00%) (16053/19328)
Epoch: 35 | Batch_idx: 160 |  Loss: (0.4964) |  Loss2: (0.0000) | Acc: (82.00%) (17097/20608)
Epoch: 35 | Batch_idx: 170 |  Loss: (0.4960) |  Loss2: (0.0000) | Acc: (82.00%) (18155/21888)
Epoch: 35 | Batch_idx: 180 |  Loss: (0.4951) |  Loss2: (0.0000) | Acc: (82.00%) (19216/23168)
Epoch: 35 | Batch_idx: 190 |  Loss: (0.4945) |  Loss2: (0.0000) | Acc: (82.00%) (20276/24448)
Epoch: 35 | Batch_idx: 200 |  Loss: (0.4942) |  Loss2: (0.0000) | Acc: (82.00%) (21345/25728)
Epoch: 35 | Batch_idx: 210 |  Loss: (0.4943) |  Loss2: (0.0000) | Acc: (82.00%) (22404/27008)
Epoch: 35 | Batch_idx: 220 |  Loss: (0.4963) |  Loss2: (0.0000) | Acc: (82.00%) (23458/28288)
Epoch: 35 | Batch_idx: 230 |  Loss: (0.4947) |  Loss2: (0.0000) | Acc: (82.00%) (24537/29568)
Epoch: 35 | Batch_idx: 240 |  Loss: (0.4942) |  Loss2: (0.0000) | Acc: (82.00%) (25598/30848)
Epoch: 35 | Batch_idx: 250 |  Loss: (0.4942) |  Loss2: (0.0000) | Acc: (82.00%) (26665/32128)
Epoch: 35 | Batch_idx: 260 |  Loss: (0.4938) |  Loss2: (0.0000) | Acc: (83.00%) (27741/33408)
Epoch: 35 | Batch_idx: 270 |  Loss: (0.4931) |  Loss2: (0.0000) | Acc: (83.00%) (28830/34688)
Epoch: 35 | Batch_idx: 280 |  Loss: (0.4931) |  Loss2: (0.0000) | Acc: (83.00%) (29899/35968)
Epoch: 35 | Batch_idx: 290 |  Loss: (0.4938) |  Loss2: (0.0000) | Acc: (83.00%) (30943/37248)
Epoch: 35 | Batch_idx: 300 |  Loss: (0.4931) |  Loss2: (0.0000) | Acc: (83.00%) (32010/38528)
Epoch: 35 | Batch_idx: 310 |  Loss: (0.4940) |  Loss2: (0.0000) | Acc: (83.00%) (33053/39808)
Epoch: 35 | Batch_idx: 320 |  Loss: (0.4934) |  Loss2: (0.0000) | Acc: (83.00%) (34131/41088)
Epoch: 35 | Batch_idx: 330 |  Loss: (0.4933) |  Loss2: (0.0000) | Acc: (83.00%) (35207/42368)
Epoch: 35 | Batch_idx: 340 |  Loss: (0.4933) |  Loss2: (0.0000) | Acc: (83.00%) (36272/43648)
Epoch: 35 | Batch_idx: 350 |  Loss: (0.4928) |  Loss2: (0.0000) | Acc: (83.00%) (37336/44928)
Epoch: 35 | Batch_idx: 360 |  Loss: (0.4929) |  Loss2: (0.0000) | Acc: (83.00%) (38395/46208)
Epoch: 35 | Batch_idx: 370 |  Loss: (0.4927) |  Loss2: (0.0000) | Acc: (83.00%) (39472/47488)
Epoch: 35 | Batch_idx: 380 |  Loss: (0.4917) |  Loss2: (0.0000) | Acc: (83.00%) (40555/48768)
Epoch: 35 | Batch_idx: 390 |  Loss: (0.4922) |  Loss2: (0.0000) | Acc: (83.00%) (41565/50000)
=> saving checkpoint 'drive/app/torch/save_Schedule/checkpoint_035.pth.tar'
# TEST : Loss: (0.5273) | Acc: (81.00%) (8169/10000)
percent tensor([0.5149, 0.5159, 0.5166, 0.5151, 0.5162, 0.5147, 0.5175, 0.5152, 0.5134,
        0.5163, 0.5148, 0.5173, 0.5156, 0.5134, 0.5169, 0.5155],
       device='cuda:0') torch.Size([16])
percent tensor([0.5029, 0.5006, 0.4994, 0.5038, 0.4977, 0.5077, 0.4977, 0.4976, 0.5002,
        0.5004, 0.5032, 0.4987, 0.5005, 0.4997, 0.5038, 0.5028],
       device='cuda:0') torch.Size([16])
percent tensor([0.4951, 0.4114, 0.5854, 0.5581, 0.5796, 0.5031, 0.5046, 0.5776, 0.5149,
        0.4595, 0.4239, 0.5517, 0.4293, 0.4521, 0.4629, 0.4935],
       device='cuda:0') torch.Size([16])
percent tensor([0.6582, 0.6845, 0.6041, 0.6154, 0.6037, 0.6282, 0.6553, 0.6193, 0.6508,
        0.6735, 0.6863, 0.6508, 0.6856, 0.6694, 0.6702, 0.6624],
       device='cuda:0') torch.Size([16])
percent tensor([0.6195, 0.5865, 0.6170, 0.6237, 0.6226, 0.6090, 0.6209, 0.6373, 0.6109,
        0.5859, 0.5900, 0.6063, 0.5828, 0.6251, 0.6141, 0.6368],
       device='cuda:0') torch.Size([16])
percent tensor([0.4590, 0.4746, 0.5174, 0.5465, 0.5496, 0.5553, 0.4840, 0.4738, 0.5161,
        0.4667, 0.4845, 0.5003, 0.4857, 0.5304, 0.4469, 0.4865],
       device='cuda:0') torch.Size([16])
percent tensor([0.5857, 0.5835, 0.6172, 0.6297, 0.6255, 0.6165, 0.5855, 0.5975, 0.6010,
        0.5992, 0.6020, 0.6138, 0.5810, 0.6126, 0.5829, 0.5793],
       device='cuda:0') torch.Size([16])
percent tensor([0.9994, 0.9966, 0.9985, 0.9992, 0.9985, 0.9979, 0.9986, 0.9996, 0.9954,
        0.9977, 0.9975, 0.9993, 0.9974, 0.9974, 0.9990, 0.9994],
       device='cuda:0') torch.Size([16])
True Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=128, out_features=16, bias=False)
False Linear(in_features=16, out_features=2, bias=False)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=128, out_features=16, bias=False)
False Linear(in_features=16, out_features=2, bias=False)
True Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=256, out_features=32, bias=False)
False Linear(in_features=32, out_features=2, bias=False)
True Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=256, out_features=32, bias=False)
False Linear(in_features=32, out_features=2, bias=False)
True Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=512, out_features=64, bias=False)
False Linear(in_features=64, out_features=2, bias=False)
True Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=512, out_features=64, bias=False)
False Linear(in_features=64, out_features=2, bias=False)
True Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1024, out_features=128, bias=False)
False Linear(in_features=128, out_features=2, bias=False)
True Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1024, out_features=128, bias=False)
False Linear(in_features=128, out_features=2, bias=False)
True Linear(in_features=512, out_features=10, bias=True)
Epoch: 36 | Batch_idx: 0 |  Loss: (0.5929) |  Loss2: (0.0000) | Acc: (77.00%) (99/128)
Epoch: 36 | Batch_idx: 10 |  Loss: (0.4912) |  Loss2: (0.0000) | Acc: (81.00%) (1153/1408)
Epoch: 36 | Batch_idx: 20 |  Loss: (0.5036) |  Loss2: (0.0000) | Acc: (82.00%) (2207/2688)
Epoch: 36 | Batch_idx: 30 |  Loss: (0.5026) |  Loss2: (0.0000) | Acc: (82.00%) (3267/3968)
Epoch: 36 | Batch_idx: 40 |  Loss: (0.4992) |  Loss2: (0.0000) | Acc: (82.00%) (4339/5248)
Epoch: 36 | Batch_idx: 50 |  Loss: (0.4981) |  Loss2: (0.0000) | Acc: (82.00%) (5396/6528)
Epoch: 36 | Batch_idx: 60 |  Loss: (0.4956) |  Loss2: (0.0000) | Acc: (82.00%) (6474/7808)
Epoch: 36 | Batch_idx: 70 |  Loss: (0.4970) |  Loss2: (0.0000) | Acc: (82.00%) (7531/9088)
Epoch: 36 | Batch_idx: 80 |  Loss: (0.4958) |  Loss2: (0.0000) | Acc: (82.00%) (8604/10368)
Epoch: 36 | Batch_idx: 90 |  Loss: (0.4965) |  Loss2: (0.0000) | Acc: (82.00%) (9657/11648)
Epoch: 36 | Batch_idx: 100 |  Loss: (0.4986) |  Loss2: (0.0000) | Acc: (82.00%) (10710/12928)
Epoch: 36 | Batch_idx: 110 |  Loss: (0.4992) |  Loss2: (0.0000) | Acc: (82.00%) (11784/14208)
Epoch: 36 | Batch_idx: 120 |  Loss: (0.4989) |  Loss2: (0.0000) | Acc: (82.00%) (12850/15488)
Epoch: 36 | Batch_idx: 130 |  Loss: (0.4971) |  Loss2: (0.0000) | Acc: (83.00%) (13930/16768)
Epoch: 36 | Batch_idx: 140 |  Loss: (0.4986) |  Loss2: (0.0000) | Acc: (83.00%) (14985/18048)
Epoch: 36 | Batch_idx: 150 |  Loss: (0.4977) |  Loss2: (0.0000) | Acc: (83.00%) (16056/19328)
Epoch: 36 | Batch_idx: 160 |  Loss: (0.4993) |  Loss2: (0.0000) | Acc: (82.00%) (17100/20608)
Epoch: 36 | Batch_idx: 170 |  Loss: (0.5007) |  Loss2: (0.0000) | Acc: (82.00%) (18156/21888)
Epoch: 36 | Batch_idx: 180 |  Loss: (0.5006) |  Loss2: (0.0000) | Acc: (82.00%) (19213/23168)
Epoch: 36 | Batch_idx: 190 |  Loss: (0.5008) |  Loss2: (0.0000) | Acc: (82.00%) (20270/24448)
Epoch: 36 | Batch_idx: 200 |  Loss: (0.5014) |  Loss2: (0.0000) | Acc: (82.00%) (21324/25728)
Epoch: 36 | Batch_idx: 210 |  Loss: (0.5016) |  Loss2: (0.0000) | Acc: (82.00%) (22369/27008)
Epoch: 36 | Batch_idx: 220 |  Loss: (0.5021) |  Loss2: (0.0000) | Acc: (82.00%) (23421/28288)
Epoch: 36 | Batch_idx: 230 |  Loss: (0.5034) |  Loss2: (0.0000) | Acc: (82.00%) (24469/29568)
Epoch: 36 | Batch_idx: 240 |  Loss: (0.5031) |  Loss2: (0.0000) | Acc: (82.00%) (25532/30848)
Epoch: 36 | Batch_idx: 250 |  Loss: (0.5025) |  Loss2: (0.0000) | Acc: (82.00%) (26598/32128)
Epoch: 36 | Batch_idx: 260 |  Loss: (0.5028) |  Loss2: (0.0000) | Acc: (82.00%) (27653/33408)
Epoch: 36 | Batch_idx: 270 |  Loss: (0.5031) |  Loss2: (0.0000) | Acc: (82.00%) (28710/34688)
Epoch: 36 | Batch_idx: 280 |  Loss: (0.5038) |  Loss2: (0.0000) | Acc: (82.00%) (29753/35968)
Epoch: 36 | Batch_idx: 290 |  Loss: (0.5037) |  Loss2: (0.0000) | Acc: (82.00%) (30812/37248)
Epoch: 36 | Batch_idx: 300 |  Loss: (0.5030) |  Loss2: (0.0000) | Acc: (82.00%) (31886/38528)
Epoch: 36 | Batch_idx: 310 |  Loss: (0.5041) |  Loss2: (0.0000) | Acc: (82.00%) (32933/39808)
Epoch: 36 | Batch_idx: 320 |  Loss: (0.5033) |  Loss2: (0.0000) | Acc: (82.00%) (33994/41088)
Epoch: 36 | Batch_idx: 330 |  Loss: (0.5031) |  Loss2: (0.0000) | Acc: (82.00%) (35064/42368)
Epoch: 36 | Batch_idx: 340 |  Loss: (0.5030) |  Loss2: (0.0000) | Acc: (82.00%) (36129/43648)
Epoch: 36 | Batch_idx: 350 |  Loss: (0.5026) |  Loss2: (0.0000) | Acc: (82.00%) (37195/44928)
Epoch: 36 | Batch_idx: 360 |  Loss: (0.5024) |  Loss2: (0.0000) | Acc: (82.00%) (38255/46208)
Epoch: 36 | Batch_idx: 370 |  Loss: (0.5028) |  Loss2: (0.0000) | Acc: (82.00%) (39310/47488)
Epoch: 36 | Batch_idx: 380 |  Loss: (0.5034) |  Loss2: (0.0000) | Acc: (82.00%) (40355/48768)
Epoch: 36 | Batch_idx: 390 |  Loss: (0.5019) |  Loss2: (0.0000) | Acc: (82.00%) (41392/50000)
# TEST : Loss: (0.6955) | Acc: (76.00%) (7662/10000)
percent tensor([0.5147, 0.5154, 0.5164, 0.5148, 0.5163, 0.5149, 0.5176, 0.5144, 0.5133,
        0.5159, 0.5146, 0.5172, 0.5154, 0.5129, 0.5167, 0.5153],
       device='cuda:0') torch.Size([16])
percent tensor([0.5027, 0.5009, 0.4983, 0.5036, 0.4964, 0.5070, 0.4978, 0.4975, 0.5001,
        0.5004, 0.5034, 0.4982, 0.5005, 0.5001, 0.5037, 0.5026],
       device='cuda:0') torch.Size([16])
percent tensor([0.4967, 0.4045, 0.5890, 0.5604, 0.5838, 0.5189, 0.4957, 0.5793, 0.5139,
        0.4577, 0.4209, 0.5427, 0.4287, 0.4345, 0.4666, 0.4985],
       device='cuda:0') torch.Size([16])
percent tensor([0.6577, 0.6890, 0.6011, 0.6178, 0.6036, 0.6308, 0.6602, 0.6199, 0.6589,
        0.6766, 0.6887, 0.6493, 0.6862, 0.6824, 0.6723, 0.6633],
       device='cuda:0') torch.Size([16])
percent tensor([0.6137, 0.5703, 0.6210, 0.6226, 0.6263, 0.6137, 0.6083, 0.6318, 0.6070,
        0.5784, 0.5836, 0.6048, 0.5702, 0.6144, 0.6084, 0.6282],
       device='cuda:0') torch.Size([16])
percent tensor([0.4574, 0.4744, 0.5165, 0.5466, 0.5375, 0.5616, 0.4646, 0.4762, 0.5131,
        0.4727, 0.4795, 0.4959, 0.4765, 0.5242, 0.4403, 0.4994],
       device='cuda:0') torch.Size([16])
percent tensor([0.5935, 0.5942, 0.6182, 0.6354, 0.6191, 0.6217, 0.5893, 0.6067, 0.6033,
        0.6124, 0.6126, 0.6095, 0.5874, 0.6193, 0.5975, 0.5850],
       device='cuda:0') torch.Size([16])
percent tensor([0.9993, 0.9966, 0.9979, 0.9985, 0.9985, 0.9979, 0.9985, 0.9991, 0.9961,
        0.9983, 0.9980, 0.9993, 0.9974, 0.9979, 0.9991, 0.9985],
       device='cuda:0') torch.Size([16])
Epoch: 37 | Batch_idx: 0 |  Loss: (0.3662) |  Loss2: (0.0000) | Acc: (87.00%) (112/128)
Epoch: 37 | Batch_idx: 10 |  Loss: (0.4330) |  Loss2: (0.0000) | Acc: (85.00%) (1198/1408)
Epoch: 37 | Batch_idx: 20 |  Loss: (0.4556) |  Loss2: (0.0000) | Acc: (84.00%) (2271/2688)
Epoch: 37 | Batch_idx: 30 |  Loss: (0.4611) |  Loss2: (0.0000) | Acc: (84.00%) (3334/3968)
Epoch: 37 | Batch_idx: 40 |  Loss: (0.4672) |  Loss2: (0.0000) | Acc: (83.00%) (4397/5248)
Epoch: 37 | Batch_idx: 50 |  Loss: (0.4695) |  Loss2: (0.0000) | Acc: (83.00%) (5464/6528)
Epoch: 37 | Batch_idx: 60 |  Loss: (0.4707) |  Loss2: (0.0000) | Acc: (83.00%) (6529/7808)
Epoch: 37 | Batch_idx: 70 |  Loss: (0.4689) |  Loss2: (0.0000) | Acc: (83.00%) (7624/9088)
Epoch: 37 | Batch_idx: 80 |  Loss: (0.4704) |  Loss2: (0.0000) | Acc: (83.00%) (8699/10368)
Epoch: 37 | Batch_idx: 90 |  Loss: (0.4717) |  Loss2: (0.0000) | Acc: (83.00%) (9763/11648)
Epoch: 37 | Batch_idx: 100 |  Loss: (0.4740) |  Loss2: (0.0000) | Acc: (83.00%) (10815/12928)
Epoch: 37 | Batch_idx: 110 |  Loss: (0.4745) |  Loss2: (0.0000) | Acc: (83.00%) (11901/14208)
Epoch: 37 | Batch_idx: 120 |  Loss: (0.4757) |  Loss2: (0.0000) | Acc: (83.00%) (12973/15488)
Epoch: 37 | Batch_idx: 130 |  Loss: (0.4747) |  Loss2: (0.0000) | Acc: (83.00%) (14055/16768)
Epoch: 37 | Batch_idx: 140 |  Loss: (0.4760) |  Loss2: (0.0000) | Acc: (83.00%) (15101/18048)
Epoch: 37 | Batch_idx: 150 |  Loss: (0.4768) |  Loss2: (0.0000) | Acc: (83.00%) (16164/19328)
Epoch: 37 | Batch_idx: 160 |  Loss: (0.4762) |  Loss2: (0.0000) | Acc: (83.00%) (17241/20608)
Epoch: 37 | Batch_idx: 170 |  Loss: (0.4753) |  Loss2: (0.0000) | Acc: (83.00%) (18317/21888)
Epoch: 37 | Batch_idx: 180 |  Loss: (0.4749) |  Loss2: (0.0000) | Acc: (83.00%) (19380/23168)
Epoch: 37 | Batch_idx: 190 |  Loss: (0.4771) |  Loss2: (0.0000) | Acc: (83.00%) (20423/24448)
Epoch: 37 | Batch_idx: 200 |  Loss: (0.4783) |  Loss2: (0.0000) | Acc: (83.00%) (21485/25728)
Epoch: 37 | Batch_idx: 210 |  Loss: (0.4789) |  Loss2: (0.0000) | Acc: (83.00%) (22552/27008)
Epoch: 37 | Batch_idx: 220 |  Loss: (0.4790) |  Loss2: (0.0000) | Acc: (83.00%) (23627/28288)
Epoch: 37 | Batch_idx: 230 |  Loss: (0.4792) |  Loss2: (0.0000) | Acc: (83.00%) (24693/29568)
Epoch: 37 | Batch_idx: 240 |  Loss: (0.4804) |  Loss2: (0.0000) | Acc: (83.00%) (25752/30848)
Epoch: 37 | Batch_idx: 250 |  Loss: (0.4819) |  Loss2: (0.0000) | Acc: (83.00%) (26794/32128)
Epoch: 37 | Batch_idx: 260 |  Loss: (0.4825) |  Loss2: (0.0000) | Acc: (83.00%) (27860/33408)
Epoch: 37 | Batch_idx: 270 |  Loss: (0.4827) |  Loss2: (0.0000) | Acc: (83.00%) (28918/34688)
Epoch: 37 | Batch_idx: 280 |  Loss: (0.4832) |  Loss2: (0.0000) | Acc: (83.00%) (29977/35968)
Epoch: 37 | Batch_idx: 290 |  Loss: (0.4828) |  Loss2: (0.0000) | Acc: (83.00%) (31045/37248)
Epoch: 37 | Batch_idx: 300 |  Loss: (0.4835) |  Loss2: (0.0000) | Acc: (83.00%) (32099/38528)
Epoch: 37 | Batch_idx: 310 |  Loss: (0.4824) |  Loss2: (0.0000) | Acc: (83.00%) (33191/39808)
Epoch: 37 | Batch_idx: 320 |  Loss: (0.4830) |  Loss2: (0.0000) | Acc: (83.00%) (34255/41088)
Epoch: 37 | Batch_idx: 330 |  Loss: (0.4824) |  Loss2: (0.0000) | Acc: (83.00%) (35327/42368)
Epoch: 37 | Batch_idx: 340 |  Loss: (0.4821) |  Loss2: (0.0000) | Acc: (83.00%) (36394/43648)
Epoch: 37 | Batch_idx: 350 |  Loss: (0.4815) |  Loss2: (0.0000) | Acc: (83.00%) (37475/44928)
Epoch: 37 | Batch_idx: 360 |  Loss: (0.4823) |  Loss2: (0.0000) | Acc: (83.00%) (38528/46208)
Epoch: 37 | Batch_idx: 370 |  Loss: (0.4816) |  Loss2: (0.0000) | Acc: (83.00%) (39592/47488)
Epoch: 37 | Batch_idx: 380 |  Loss: (0.4826) |  Loss2: (0.0000) | Acc: (83.00%) (40651/48768)
Epoch: 37 | Batch_idx: 390 |  Loss: (0.4823) |  Loss2: (0.0000) | Acc: (83.00%) (41685/50000)
# TEST : Loss: (0.5780) | Acc: (80.00%) (8034/10000)
percent tensor([0.5144, 0.5152, 0.5164, 0.5149, 0.5160, 0.5143, 0.5172, 0.5149, 0.5131,
        0.5160, 0.5142, 0.5173, 0.5153, 0.5128, 0.5162, 0.5151],
       device='cuda:0') torch.Size([16])
percent tensor([0.5035, 0.5008, 0.4988, 0.5035, 0.4966, 0.5073, 0.4975, 0.4972, 0.5000,
        0.5008, 0.5036, 0.4994, 0.5010, 0.4994, 0.5038, 0.5030],
       device='cuda:0') torch.Size([16])
percent tensor([0.5024, 0.4131, 0.5941, 0.5592, 0.5900, 0.5222, 0.5160, 0.5811, 0.5319,
        0.4639, 0.4273, 0.5543, 0.4369, 0.4521, 0.4716, 0.5049],
       device='cuda:0') torch.Size([16])
percent tensor([0.6555, 0.6822, 0.5965, 0.6149, 0.5977, 0.6224, 0.6496, 0.6149, 0.6520,
        0.6718, 0.6838, 0.6437, 0.6825, 0.6764, 0.6682, 0.6578],
       device='cuda:0') torch.Size([16])
percent tensor([0.6220, 0.5832, 0.6244, 0.6311, 0.6354, 0.6198, 0.6269, 0.6361, 0.6189,
        0.5886, 0.5895, 0.6066, 0.5820, 0.6300, 0.6178, 0.6421],
       device='cuda:0') torch.Size([16])
percent tensor([0.4618, 0.4614, 0.5232, 0.5343, 0.5452, 0.5552, 0.4812, 0.4788, 0.5186,
        0.4564, 0.4724, 0.4970, 0.4764, 0.5198, 0.4423, 0.4862],
       device='cuda:0') torch.Size([16])
percent tensor([0.5858, 0.5850, 0.6223, 0.6294, 0.6304, 0.6158, 0.5884, 0.6022, 0.6027,
        0.5959, 0.6109, 0.6103, 0.5819, 0.6111, 0.5905, 0.5799],
       device='cuda:0') torch.Size([16])
percent tensor([0.9993, 0.9967, 0.9985, 0.9993, 0.9994, 0.9959, 0.9986, 0.9994, 0.9964,
        0.9978, 0.9979, 0.9992, 0.9983, 0.9974, 0.9990, 0.9989],
       device='cuda:0') torch.Size([16])
Epoch: 38 | Batch_idx: 0 |  Loss: (0.4306) |  Loss2: (0.0000) | Acc: (83.00%) (107/128)
Epoch: 38 | Batch_idx: 10 |  Loss: (0.4847) |  Loss2: (0.0000) | Acc: (83.00%) (1172/1408)
Epoch: 38 | Batch_idx: 20 |  Loss: (0.4825) |  Loss2: (0.0000) | Acc: (83.00%) (2246/2688)
Epoch: 38 | Batch_idx: 30 |  Loss: (0.4687) |  Loss2: (0.0000) | Acc: (83.00%) (3330/3968)
Epoch: 38 | Batch_idx: 40 |  Loss: (0.4660) |  Loss2: (0.0000) | Acc: (83.00%) (4404/5248)
Epoch: 38 | Batch_idx: 50 |  Loss: (0.4694) |  Loss2: (0.0000) | Acc: (83.00%) (5465/6528)
Epoch: 38 | Batch_idx: 60 |  Loss: (0.4689) |  Loss2: (0.0000) | Acc: (83.00%) (6528/7808)
Epoch: 38 | Batch_idx: 70 |  Loss: (0.4767) |  Loss2: (0.0000) | Acc: (83.00%) (7575/9088)
Epoch: 38 | Batch_idx: 80 |  Loss: (0.4755) |  Loss2: (0.0000) | Acc: (83.00%) (8663/10368)
Epoch: 38 | Batch_idx: 90 |  Loss: (0.4752) |  Loss2: (0.0000) | Acc: (83.00%) (9741/11648)
Epoch: 38 | Batch_idx: 100 |  Loss: (0.4759) |  Loss2: (0.0000) | Acc: (83.00%) (10806/12928)
Epoch: 38 | Batch_idx: 110 |  Loss: (0.4754) |  Loss2: (0.0000) | Acc: (83.00%) (11882/14208)
Epoch: 38 | Batch_idx: 120 |  Loss: (0.4735) |  Loss2: (0.0000) | Acc: (83.00%) (12971/15488)
Epoch: 38 | Batch_idx: 130 |  Loss: (0.4706) |  Loss2: (0.0000) | Acc: (83.00%) (14074/16768)
Epoch: 38 | Batch_idx: 140 |  Loss: (0.4709) |  Loss2: (0.0000) | Acc: (83.00%) (15146/18048)
Epoch: 38 | Batch_idx: 150 |  Loss: (0.4703) |  Loss2: (0.0000) | Acc: (83.00%) (16218/19328)
Epoch: 38 | Batch_idx: 160 |  Loss: (0.4707) |  Loss2: (0.0000) | Acc: (83.00%) (17288/20608)
Epoch: 38 | Batch_idx: 170 |  Loss: (0.4715) |  Loss2: (0.0000) | Acc: (83.00%) (18356/21888)
Epoch: 38 | Batch_idx: 180 |  Loss: (0.4685) |  Loss2: (0.0000) | Acc: (84.00%) (19463/23168)
Epoch: 38 | Batch_idx: 190 |  Loss: (0.4695) |  Loss2: (0.0000) | Acc: (83.00%) (20525/24448)
Epoch: 38 | Batch_idx: 200 |  Loss: (0.4686) |  Loss2: (0.0000) | Acc: (83.00%) (21601/25728)
Epoch: 38 | Batch_idx: 210 |  Loss: (0.4671) |  Loss2: (0.0000) | Acc: (84.00%) (22692/27008)
Epoch: 38 | Batch_idx: 220 |  Loss: (0.4668) |  Loss2: (0.0000) | Acc: (84.00%) (23771/28288)
Epoch: 38 | Batch_idx: 230 |  Loss: (0.4652) |  Loss2: (0.0000) | Acc: (84.00%) (24867/29568)
Epoch: 38 | Batch_idx: 240 |  Loss: (0.4647) |  Loss2: (0.0000) | Acc: (84.00%) (25937/30848)
Epoch: 38 | Batch_idx: 250 |  Loss: (0.4656) |  Loss2: (0.0000) | Acc: (84.00%) (27002/32128)
Epoch: 38 | Batch_idx: 260 |  Loss: (0.4642) |  Loss2: (0.0000) | Acc: (84.00%) (28101/33408)
Epoch: 38 | Batch_idx: 270 |  Loss: (0.4629) |  Loss2: (0.0000) | Acc: (84.00%) (29201/34688)
Epoch: 38 | Batch_idx: 280 |  Loss: (0.4617) |  Loss2: (0.0000) | Acc: (84.00%) (30289/35968)
Epoch: 38 | Batch_idx: 290 |  Loss: (0.4639) |  Loss2: (0.0000) | Acc: (84.00%) (31337/37248)
Epoch: 38 | Batch_idx: 300 |  Loss: (0.4632) |  Loss2: (0.0000) | Acc: (84.00%) (32423/38528)
Epoch: 38 | Batch_idx: 310 |  Loss: (0.4642) |  Loss2: (0.0000) | Acc: (84.00%) (33486/39808)
Epoch: 38 | Batch_idx: 320 |  Loss: (0.4651) |  Loss2: (0.0000) | Acc: (84.00%) (34542/41088)
Epoch: 38 | Batch_idx: 330 |  Loss: (0.4651) |  Loss2: (0.0000) | Acc: (84.00%) (35616/42368)
Epoch: 38 | Batch_idx: 340 |  Loss: (0.4654) |  Loss2: (0.0000) | Acc: (84.00%) (36671/43648)
Epoch: 38 | Batch_idx: 350 |  Loss: (0.4649) |  Loss2: (0.0000) | Acc: (84.00%) (37764/44928)
Epoch: 38 | Batch_idx: 360 |  Loss: (0.4644) |  Loss2: (0.0000) | Acc: (84.00%) (38845/46208)
Epoch: 38 | Batch_idx: 370 |  Loss: (0.4641) |  Loss2: (0.0000) | Acc: (84.00%) (39920/47488)
Epoch: 38 | Batch_idx: 380 |  Loss: (0.4639) |  Loss2: (0.0000) | Acc: (84.00%) (40990/48768)
Epoch: 38 | Batch_idx: 390 |  Loss: (0.4644) |  Loss2: (0.0000) | Acc: (84.00%) (42024/50000)
# TEST : Loss: (0.5802) | Acc: (80.00%) (8049/10000)
percent tensor([0.5146, 0.5161, 0.5154, 0.5147, 0.5156, 0.5146, 0.5173, 0.5147, 0.5136,
        0.5160, 0.5149, 0.5166, 0.5155, 0.5141, 0.5168, 0.5156],
       device='cuda:0') torch.Size([16])
percent tensor([0.5033, 0.5011, 0.4995, 0.5033, 0.4970, 0.5073, 0.4982, 0.4975, 0.4998,
        0.5011, 0.5034, 0.4999, 0.5008, 0.4996, 0.5039, 0.5026],
       device='cuda:0') torch.Size([16])
percent tensor([0.4943, 0.4104, 0.5974, 0.5631, 0.5902, 0.5174, 0.5087, 0.5826, 0.5300,
        0.4595, 0.4179, 0.5518, 0.4258, 0.4554, 0.4624, 0.4996],
       device='cuda:0') torch.Size([16])
percent tensor([0.6597, 0.6818, 0.6012, 0.6152, 0.5986, 0.6284, 0.6502, 0.6209, 0.6534,
        0.6703, 0.6889, 0.6489, 0.6876, 0.6730, 0.6695, 0.6589],
       device='cuda:0') torch.Size([16])
percent tensor([0.6215, 0.5789, 0.6272, 0.6295, 0.6342, 0.6215, 0.6231, 0.6394, 0.6183,
        0.5844, 0.5870, 0.6019, 0.5759, 0.6194, 0.6119, 0.6413],
       device='cuda:0') torch.Size([16])
percent tensor([0.4666, 0.4749, 0.5268, 0.5485, 0.5470, 0.5540, 0.4867, 0.4738, 0.5161,
        0.4675, 0.4824, 0.5006, 0.4725, 0.5250, 0.4517, 0.4967],
       device='cuda:0') torch.Size([16])
percent tensor([0.5841, 0.5862, 0.6179, 0.6265, 0.6230, 0.6057, 0.5773, 0.5905, 0.5991,
        0.6010, 0.6024, 0.6168, 0.5790, 0.6087, 0.5862, 0.5735],
       device='cuda:0') torch.Size([16])
percent tensor([0.9993, 0.9974, 0.9983, 0.9990, 0.9993, 0.9959, 0.9986, 0.9996, 0.9955,
        0.9984, 0.9972, 0.9996, 0.9973, 0.9974, 0.9992, 0.9993],
       device='cuda:0') torch.Size([16])
False Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=128, out_features=16, bias=False)
True Linear(in_features=16, out_features=2, bias=False)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=128, out_features=16, bias=False)
True Linear(in_features=16, out_features=2, bias=False)
False Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=256, out_features=32, bias=False)
True Linear(in_features=32, out_features=2, bias=False)
False Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=256, out_features=32, bias=False)
True Linear(in_features=32, out_features=2, bias=False)
False Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=512, out_features=64, bias=False)
True Linear(in_features=64, out_features=2, bias=False)
False Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=512, out_features=64, bias=False)
True Linear(in_features=64, out_features=2, bias=False)
False Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1024, out_features=128, bias=False)
True Linear(in_features=128, out_features=2, bias=False)
False Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1024, out_features=128, bias=False)
True Linear(in_features=128, out_features=2, bias=False)
False Linear(in_features=512, out_features=10, bias=True)
Epoch: 39 | Batch_idx: 0 |  Loss: (0.4317) |  Loss2: (0.0000) | Acc: (86.00%) (111/128)
Epoch: 39 | Batch_idx: 10 |  Loss: (0.4945) |  Loss2: (0.0000) | Acc: (82.00%) (1166/1408)
Epoch: 39 | Batch_idx: 20 |  Loss: (0.5138) |  Loss2: (0.0000) | Acc: (81.00%) (2195/2688)
Epoch: 39 | Batch_idx: 30 |  Loss: (0.5260) |  Loss2: (0.0000) | Acc: (81.00%) (3229/3968)
Epoch: 39 | Batch_idx: 40 |  Loss: (0.5446) |  Loss2: (0.0000) | Acc: (80.00%) (4224/5248)
Epoch: 39 | Batch_idx: 50 |  Loss: (0.5480) |  Loss2: (0.0000) | Acc: (80.00%) (5252/6528)
Epoch: 39 | Batch_idx: 60 |  Loss: (0.5519) |  Loss2: (0.0000) | Acc: (80.00%) (6262/7808)
Epoch: 39 | Batch_idx: 70 |  Loss: (0.5514) |  Loss2: (0.0000) | Acc: (80.00%) (7295/9088)
Epoch: 39 | Batch_idx: 80 |  Loss: (0.5538) |  Loss2: (0.0000) | Acc: (80.00%) (8321/10368)
Epoch: 39 | Batch_idx: 90 |  Loss: (0.5516) |  Loss2: (0.0000) | Acc: (80.00%) (9365/11648)
Epoch: 39 | Batch_idx: 100 |  Loss: (0.5567) |  Loss2: (0.0000) | Acc: (80.00%) (10372/12928)
Epoch: 39 | Batch_idx: 110 |  Loss: (0.5558) |  Loss2: (0.0000) | Acc: (80.00%) (11410/14208)
Epoch: 39 | Batch_idx: 120 |  Loss: (0.5526) |  Loss2: (0.0000) | Acc: (80.00%) (12461/15488)
Epoch: 39 | Batch_idx: 130 |  Loss: (0.5520) |  Loss2: (0.0000) | Acc: (80.00%) (13493/16768)
Epoch: 39 | Batch_idx: 140 |  Loss: (0.5504) |  Loss2: (0.0000) | Acc: (80.00%) (14541/18048)
Epoch: 39 | Batch_idx: 150 |  Loss: (0.5527) |  Loss2: (0.0000) | Acc: (80.00%) (15558/19328)
Epoch: 39 | Batch_idx: 160 |  Loss: (0.5502) |  Loss2: (0.0000) | Acc: (80.00%) (16610/20608)
Epoch: 39 | Batch_idx: 170 |  Loss: (0.5485) |  Loss2: (0.0000) | Acc: (80.00%) (17664/21888)
Epoch: 39 | Batch_idx: 180 |  Loss: (0.5472) |  Loss2: (0.0000) | Acc: (80.00%) (18721/23168)
Epoch: 39 | Batch_idx: 190 |  Loss: (0.5485) |  Loss2: (0.0000) | Acc: (80.00%) (19746/24448)
Epoch: 39 | Batch_idx: 200 |  Loss: (0.5481) |  Loss2: (0.0000) | Acc: (80.00%) (20781/25728)
Epoch: 39 | Batch_idx: 210 |  Loss: (0.5477) |  Loss2: (0.0000) | Acc: (80.00%) (21809/27008)
Epoch: 39 | Batch_idx: 220 |  Loss: (0.5451) |  Loss2: (0.0000) | Acc: (80.00%) (22864/28288)
Epoch: 39 | Batch_idx: 230 |  Loss: (0.5448) |  Loss2: (0.0000) | Acc: (80.00%) (23894/29568)
Epoch: 39 | Batch_idx: 240 |  Loss: (0.5448) |  Loss2: (0.0000) | Acc: (80.00%) (24933/30848)
Epoch: 39 | Batch_idx: 250 |  Loss: (0.5428) |  Loss2: (0.0000) | Acc: (80.00%) (25983/32128)
Epoch: 39 | Batch_idx: 260 |  Loss: (0.5431) |  Loss2: (0.0000) | Acc: (80.00%) (27016/33408)
Epoch: 39 | Batch_idx: 270 |  Loss: (0.5421) |  Loss2: (0.0000) | Acc: (80.00%) (28071/34688)
Epoch: 39 | Batch_idx: 280 |  Loss: (0.5422) |  Loss2: (0.0000) | Acc: (80.00%) (29098/35968)
Epoch: 39 | Batch_idx: 290 |  Loss: (0.5415) |  Loss2: (0.0000) | Acc: (80.00%) (30133/37248)
Epoch: 39 | Batch_idx: 300 |  Loss: (0.5416) |  Loss2: (0.0000) | Acc: (80.00%) (31173/38528)
Epoch: 39 | Batch_idx: 310 |  Loss: (0.5409) |  Loss2: (0.0000) | Acc: (80.00%) (32226/39808)
Epoch: 39 | Batch_idx: 320 |  Loss: (0.5400) |  Loss2: (0.0000) | Acc: (80.00%) (33274/41088)
Epoch: 39 | Batch_idx: 330 |  Loss: (0.5408) |  Loss2: (0.0000) | Acc: (80.00%) (34299/42368)
Epoch: 39 | Batch_idx: 340 |  Loss: (0.5394) |  Loss2: (0.0000) | Acc: (81.00%) (35365/43648)
Epoch: 39 | Batch_idx: 350 |  Loss: (0.5385) |  Loss2: (0.0000) | Acc: (81.00%) (36430/44928)
Epoch: 39 | Batch_idx: 360 |  Loss: (0.5391) |  Loss2: (0.0000) | Acc: (81.00%) (37449/46208)
Epoch: 39 | Batch_idx: 370 |  Loss: (0.5389) |  Loss2: (0.0000) | Acc: (81.00%) (38493/47488)
Epoch: 39 | Batch_idx: 380 |  Loss: (0.5382) |  Loss2: (0.0000) | Acc: (81.00%) (39559/48768)
Epoch: 39 | Batch_idx: 390 |  Loss: (0.5366) |  Loss2: (0.0000) | Acc: (81.00%) (40596/50000)
# TEST : Loss: (0.5586) | Acc: (80.00%) (8081/10000)
percent tensor([0.5215, 0.5256, 0.5212, 0.5208, 0.5224, 0.5226, 0.5262, 0.5209, 0.5202,
        0.5234, 0.5233, 0.5236, 0.5232, 0.5213, 0.5257, 0.5229],
       device='cuda:0') torch.Size([16])
percent tensor([0.5033, 0.5010, 0.4977, 0.5034, 0.4940, 0.5076, 0.4968, 0.4951, 0.4982,
        0.5011, 0.5036, 0.4996, 0.5007, 0.4985, 0.5043, 0.5029],
       device='cuda:0') torch.Size([16])
percent tensor([0.4642, 0.3683, 0.5870, 0.5509, 0.5810, 0.4848, 0.4683, 0.5670, 0.4986,
        0.4244, 0.3817, 0.5243, 0.3887, 0.3978, 0.4242, 0.4718],
       device='cuda:0') torch.Size([16])
percent tensor([0.6472, 0.6722, 0.5857, 0.6030, 0.5820, 0.6184, 0.6373, 0.6042, 0.6390,
        0.6581, 0.6763, 0.6310, 0.6734, 0.6661, 0.6564, 0.6467],
       device='cuda:0') torch.Size([16])
percent tensor([0.6068, 0.5493, 0.6207, 0.6190, 0.6338, 0.6166, 0.6075, 0.6425, 0.6009,
        0.5600, 0.5564, 0.5803, 0.5516, 0.5923, 0.5956, 0.6281],
       device='cuda:0') torch.Size([16])
percent tensor([0.4351, 0.4395, 0.5326, 0.5704, 0.5641, 0.5681, 0.4663, 0.4631, 0.5019,
        0.4334, 0.4484, 0.4830, 0.4337, 0.5019, 0.4270, 0.4811],
       device='cuda:0') torch.Size([16])
percent tensor([0.5719, 0.5802, 0.6206, 0.6335, 0.6248, 0.5897, 0.5725, 0.5737, 0.6067,
        0.6041, 0.6092, 0.6171, 0.5762, 0.6147, 0.5778, 0.5557],
       device='cuda:0') torch.Size([16])
percent tensor([0.9993, 0.9964, 0.9985, 0.9992, 0.9995, 0.9955, 0.9986, 0.9997, 0.9962,
        0.9979, 0.9963, 0.9994, 0.9969, 0.9972, 0.9989, 0.9991],
       device='cuda:0') torch.Size([16])
Epoch: 40 | Batch_idx: 0 |  Loss: (0.5327) |  Loss2: (0.0000) | Acc: (79.00%) (102/128)
Epoch: 40 | Batch_idx: 10 |  Loss: (0.4945) |  Loss2: (0.0000) | Acc: (83.00%) (1176/1408)
Epoch: 40 | Batch_idx: 20 |  Loss: (0.4945) |  Loss2: (0.0000) | Acc: (83.00%) (2241/2688)
Epoch: 40 | Batch_idx: 30 |  Loss: (0.5068) |  Loss2: (0.0000) | Acc: (82.00%) (3286/3968)
Epoch: 40 | Batch_idx: 40 |  Loss: (0.5004) |  Loss2: (0.0000) | Acc: (82.00%) (4343/5248)
Epoch: 40 | Batch_idx: 50 |  Loss: (0.4997) |  Loss2: (0.0000) | Acc: (82.00%) (5392/6528)
Epoch: 40 | Batch_idx: 60 |  Loss: (0.4992) |  Loss2: (0.0000) | Acc: (82.00%) (6455/7808)
Epoch: 40 | Batch_idx: 70 |  Loss: (0.5006) |  Loss2: (0.0000) | Acc: (82.00%) (7512/9088)
Epoch: 40 | Batch_idx: 80 |  Loss: (0.4969) |  Loss2: (0.0000) | Acc: (82.00%) (8592/10368)
Epoch: 40 | Batch_idx: 90 |  Loss: (0.5036) |  Loss2: (0.0000) | Acc: (82.00%) (9613/11648)
Epoch: 40 | Batch_idx: 100 |  Loss: (0.5030) |  Loss2: (0.0000) | Acc: (82.00%) (10681/12928)
Epoch: 40 | Batch_idx: 110 |  Loss: (0.5011) |  Loss2: (0.0000) | Acc: (82.00%) (11741/14208)
Epoch: 40 | Batch_idx: 120 |  Loss: (0.5023) |  Loss2: (0.0000) | Acc: (82.00%) (12792/15488)
Epoch: 40 | Batch_idx: 130 |  Loss: (0.5040) |  Loss2: (0.0000) | Acc: (82.00%) (13835/16768)
Epoch: 40 | Batch_idx: 140 |  Loss: (0.5058) |  Loss2: (0.0000) | Acc: (82.00%) (14869/18048)
Epoch: 40 | Batch_idx: 150 |  Loss: (0.5092) |  Loss2: (0.0000) | Acc: (82.00%) (15894/19328)
Epoch: 40 | Batch_idx: 160 |  Loss: (0.5079) |  Loss2: (0.0000) | Acc: (82.00%) (16964/20608)
Epoch: 40 | Batch_idx: 170 |  Loss: (0.5045) |  Loss2: (0.0000) | Acc: (82.00%) (18032/21888)
Epoch: 40 | Batch_idx: 180 |  Loss: (0.5028) |  Loss2: (0.0000) | Acc: (82.00%) (19111/23168)
Epoch: 40 | Batch_idx: 190 |  Loss: (0.5051) |  Loss2: (0.0000) | Acc: (82.00%) (20153/24448)
Epoch: 40 | Batch_idx: 200 |  Loss: (0.5048) |  Loss2: (0.0000) | Acc: (82.00%) (21212/25728)
Epoch: 40 | Batch_idx: 210 |  Loss: (0.5051) |  Loss2: (0.0000) | Acc: (82.00%) (22263/27008)
Epoch: 40 | Batch_idx: 220 |  Loss: (0.5062) |  Loss2: (0.0000) | Acc: (82.00%) (23307/28288)
Epoch: 40 | Batch_idx: 230 |  Loss: (0.5048) |  Loss2: (0.0000) | Acc: (82.00%) (24375/29568)
Epoch: 40 | Batch_idx: 240 |  Loss: (0.5026) |  Loss2: (0.0000) | Acc: (82.00%) (25462/30848)
Epoch: 40 | Batch_idx: 250 |  Loss: (0.5013) |  Loss2: (0.0000) | Acc: (82.00%) (26538/32128)
Epoch: 40 | Batch_idx: 260 |  Loss: (0.4992) |  Loss2: (0.0000) | Acc: (82.00%) (27626/33408)
Epoch: 40 | Batch_idx: 270 |  Loss: (0.4984) |  Loss2: (0.0000) | Acc: (82.00%) (28690/34688)
Epoch: 40 | Batch_idx: 280 |  Loss: (0.4973) |  Loss2: (0.0000) | Acc: (82.00%) (29774/35968)
Epoch: 40 | Batch_idx: 290 |  Loss: (0.4958) |  Loss2: (0.0000) | Acc: (82.00%) (30864/37248)
Epoch: 40 | Batch_idx: 300 |  Loss: (0.4956) |  Loss2: (0.0000) | Acc: (82.00%) (31920/38528)
Epoch: 40 | Batch_idx: 310 |  Loss: (0.4954) |  Loss2: (0.0000) | Acc: (82.00%) (32983/39808)
Epoch: 40 | Batch_idx: 320 |  Loss: (0.4938) |  Loss2: (0.0000) | Acc: (82.00%) (34054/41088)
Epoch: 40 | Batch_idx: 330 |  Loss: (0.4947) |  Loss2: (0.0000) | Acc: (82.00%) (35115/42368)
Epoch: 40 | Batch_idx: 340 |  Loss: (0.4949) |  Loss2: (0.0000) | Acc: (82.00%) (36170/43648)
Epoch: 40 | Batch_idx: 350 |  Loss: (0.4949) |  Loss2: (0.0000) | Acc: (82.00%) (37239/44928)
Epoch: 40 | Batch_idx: 360 |  Loss: (0.4956) |  Loss2: (0.0000) | Acc: (82.00%) (38278/46208)
Epoch: 40 | Batch_idx: 370 |  Loss: (0.4947) |  Loss2: (0.0000) | Acc: (82.00%) (39352/47488)
Epoch: 40 | Batch_idx: 380 |  Loss: (0.4936) |  Loss2: (0.0000) | Acc: (82.00%) (40428/48768)
Epoch: 40 | Batch_idx: 390 |  Loss: (0.4934) |  Loss2: (0.0000) | Acc: (82.00%) (41441/50000)
=> saving checkpoint 'drive/app/torch/save_Schedule/checkpoint_040.pth.tar'
# TEST : Loss: (0.5316) | Acc: (81.00%) (8164/10000)
percent tensor([0.5234, 0.5281, 0.5226, 0.5224, 0.5240, 0.5253, 0.5283, 0.5220, 0.5217,
        0.5250, 0.5253, 0.5250, 0.5250, 0.5233, 0.5283, 0.5249],
       device='cuda:0') torch.Size([16])
percent tensor([0.5031, 0.5008, 0.4963, 0.5029, 0.4917, 0.5083, 0.4954, 0.4931, 0.4969,
        0.5009, 0.5036, 0.4990, 0.5005, 0.4979, 0.5041, 0.5032],
       device='cuda:0') torch.Size([16])
percent tensor([0.4798, 0.3811, 0.6021, 0.5672, 0.5934, 0.5059, 0.4838, 0.5770, 0.5148,
        0.4422, 0.3976, 0.5459, 0.4017, 0.4087, 0.4410, 0.4904],
       device='cuda:0') torch.Size([16])
percent tensor([0.6593, 0.6861, 0.5915, 0.6108, 0.5890, 0.6257, 0.6509, 0.6140, 0.6507,
        0.6707, 0.6893, 0.6420, 0.6855, 0.6821, 0.6693, 0.6584],
       device='cuda:0') torch.Size([16])
percent tensor([0.6112, 0.5470, 0.6254, 0.6223, 0.6422, 0.6282, 0.6113, 0.6494, 0.6006,
        0.5565, 0.5504, 0.5767, 0.5485, 0.5918, 0.5994, 0.6343],
       device='cuda:0') torch.Size([16])
percent tensor([0.4321, 0.4364, 0.5495, 0.5896, 0.5844, 0.5835, 0.4688, 0.4737, 0.5040,
        0.4289, 0.4450, 0.4922, 0.4270, 0.5064, 0.4317, 0.4811],
       device='cuda:0') torch.Size([16])
percent tensor([0.5760, 0.5955, 0.6360, 0.6481, 0.6368, 0.5858, 0.5795, 0.5699, 0.6251,
        0.6241, 0.6330, 0.6392, 0.5914, 0.6372, 0.5872, 0.5499],
       device='cuda:0') torch.Size([16])
percent tensor([0.9992, 0.9965, 0.9986, 0.9992, 0.9996, 0.9961, 0.9987, 0.9997, 0.9965,
        0.9980, 0.9965, 0.9995, 0.9969, 0.9975, 0.9990, 0.9991],
       device='cuda:0') torch.Size([16])
Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 3, 3, 3]) tensor(173.4243, device='cuda:0')
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(790.8673, device='cuda:0')
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(790.4285, device='cuda:0')
Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([128, 64, 3, 3]) tensor(1524.9807, device='cuda:0')
Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([128, 64, 1, 1]) tensor(509.2448, device='cuda:0')
Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([128, 128, 3, 3]) tensor(2191.1072, device='cuda:0')
Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([256, 128, 3, 3]) tensor(4303.8374, device='cuda:0')
Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([256, 128, 1, 1]) tensor(1434.4274, device='cuda:0')
Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([256, 256, 3, 3]) tensor(6087.1333, device='cuda:0')
Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([512, 256, 3, 3]) tensor(12099.4258, device='cuda:0')
Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([512, 256, 1, 1]) tensor(4036.1704, device='cuda:0')
Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([512, 512, 3, 3]) tensor(17045.3145, device='cuda:0')
Epoch: 41 | Batch_idx: 0 |  Loss: (0.3968) |  Loss2: (0.0000) | Acc: (85.00%) (110/128)
Epoch: 41 | Batch_idx: 10 |  Loss: (0.4905) |  Loss2: (0.0000) | Acc: (82.00%) (1164/1408)
Epoch: 41 | Batch_idx: 20 |  Loss: (0.4865) |  Loss2: (0.0000) | Acc: (82.00%) (2226/2688)
Epoch: 41 | Batch_idx: 30 |  Loss: (0.4807) |  Loss2: (0.0000) | Acc: (83.00%) (3308/3968)
Epoch: 41 | Batch_idx: 40 |  Loss: (0.4757) |  Loss2: (0.0000) | Acc: (83.00%) (4389/5248)
Epoch: 41 | Batch_idx: 50 |  Loss: (0.4732) |  Loss2: (0.0000) | Acc: (83.00%) (5459/6528)
Epoch: 41 | Batch_idx: 60 |  Loss: (0.4788) |  Loss2: (0.0000) | Acc: (83.00%) (6523/7808)
Epoch: 41 | Batch_idx: 70 |  Loss: (0.4716) |  Loss2: (0.0000) | Acc: (83.00%) (7625/9088)
Epoch: 41 | Batch_idx: 80 |  Loss: (0.4709) |  Loss2: (0.0000) | Acc: (83.00%) (8693/10368)
Epoch: 41 | Batch_idx: 90 |  Loss: (0.4740) |  Loss2: (0.0000) | Acc: (83.00%) (9756/11648)
Epoch: 41 | Batch_idx: 100 |  Loss: (0.4722) |  Loss2: (0.0000) | Acc: (83.00%) (10838/12928)
Epoch: 41 | Batch_idx: 110 |  Loss: (0.4714) |  Loss2: (0.0000) | Acc: (83.00%) (11909/14208)
Epoch: 41 | Batch_idx: 120 |  Loss: (0.4717) |  Loss2: (0.0000) | Acc: (83.00%) (12984/15488)
Epoch: 41 | Batch_idx: 130 |  Loss: (0.4735) |  Loss2: (0.0000) | Acc: (83.00%) (14024/16768)
Epoch: 41 | Batch_idx: 140 |  Loss: (0.4736) |  Loss2: (0.0000) | Acc: (83.00%) (15088/18048)
Epoch: 41 | Batch_idx: 150 |  Loss: (0.4727) |  Loss2: (0.0000) | Acc: (83.00%) (16169/19328)
Epoch: 41 | Batch_idx: 160 |  Loss: (0.4747) |  Loss2: (0.0000) | Acc: (83.00%) (17228/20608)
Epoch: 41 | Batch_idx: 170 |  Loss: (0.4789) |  Loss2: (0.0000) | Acc: (83.00%) (18273/21888)
Epoch: 41 | Batch_idx: 180 |  Loss: (0.4765) |  Loss2: (0.0000) | Acc: (83.00%) (19362/23168)
Epoch: 41 | Batch_idx: 190 |  Loss: (0.4767) |  Loss2: (0.0000) | Acc: (83.00%) (20433/24448)
Epoch: 41 | Batch_idx: 200 |  Loss: (0.4769) |  Loss2: (0.0000) | Acc: (83.00%) (21504/25728)
Epoch: 41 | Batch_idx: 210 |  Loss: (0.4775) |  Loss2: (0.0000) | Acc: (83.00%) (22563/27008)
Epoch: 41 | Batch_idx: 220 |  Loss: (0.4782) |  Loss2: (0.0000) | Acc: (83.00%) (23631/28288)
Epoch: 41 | Batch_idx: 230 |  Loss: (0.4781) |  Loss2: (0.0000) | Acc: (83.00%) (24699/29568)
Epoch: 41 | Batch_idx: 240 |  Loss: (0.4766) |  Loss2: (0.0000) | Acc: (83.00%) (25780/30848)
Epoch: 41 | Batch_idx: 250 |  Loss: (0.4752) |  Loss2: (0.0000) | Acc: (83.00%) (26866/32128)
Epoch: 41 | Batch_idx: 260 |  Loss: (0.4736) |  Loss2: (0.0000) | Acc: (83.00%) (27955/33408)
Epoch: 41 | Batch_idx: 270 |  Loss: (0.4729) |  Loss2: (0.0000) | Acc: (83.00%) (29030/34688)
Epoch: 41 | Batch_idx: 280 |  Loss: (0.4730) |  Loss2: (0.0000) | Acc: (83.00%) (30110/35968)
Epoch: 41 | Batch_idx: 290 |  Loss: (0.4732) |  Loss2: (0.0000) | Acc: (83.00%) (31195/37248)
Epoch: 41 | Batch_idx: 300 |  Loss: (0.4741) |  Loss2: (0.0000) | Acc: (83.00%) (32258/38528)
Epoch: 41 | Batch_idx: 310 |  Loss: (0.4743) |  Loss2: (0.0000) | Acc: (83.00%) (33325/39808)
Epoch: 41 | Batch_idx: 320 |  Loss: (0.4732) |  Loss2: (0.0000) | Acc: (83.00%) (34400/41088)
Epoch: 41 | Batch_idx: 330 |  Loss: (0.4740) |  Loss2: (0.0000) | Acc: (83.00%) (35462/42368)
Epoch: 41 | Batch_idx: 340 |  Loss: (0.4728) |  Loss2: (0.0000) | Acc: (83.00%) (36549/43648)
Epoch: 41 | Batch_idx: 350 |  Loss: (0.4736) |  Loss2: (0.0000) | Acc: (83.00%) (37605/44928)
Epoch: 41 | Batch_idx: 360 |  Loss: (0.4727) |  Loss2: (0.0000) | Acc: (83.00%) (38682/46208)
Epoch: 41 | Batch_idx: 370 |  Loss: (0.4732) |  Loss2: (0.0000) | Acc: (83.00%) (39746/47488)
Epoch: 41 | Batch_idx: 380 |  Loss: (0.4729) |  Loss2: (0.0000) | Acc: (83.00%) (40832/48768)
Epoch: 41 | Batch_idx: 390 |  Loss: (0.4726) |  Loss2: (0.0000) | Acc: (83.00%) (41867/50000)
# TEST : Loss: (0.5145) | Acc: (82.00%) (8230/10000)
percent tensor([0.5240, 0.5292, 0.5229, 0.5227, 0.5243, 0.5265, 0.5291, 0.5220, 0.5221,
        0.5254, 0.5261, 0.5252, 0.5256, 0.5242, 0.5295, 0.5256],
       device='cuda:0') torch.Size([16])
percent tensor([0.5024, 0.5001, 0.4945, 0.5023, 0.4893, 0.5088, 0.4938, 0.4908, 0.4953,
        0.5003, 0.5032, 0.4979, 0.5000, 0.4970, 0.5038, 0.5031],
       device='cuda:0') torch.Size([16])
percent tensor([0.4816, 0.3816, 0.6045, 0.5714, 0.5937, 0.5093, 0.4839, 0.5767, 0.5171,
        0.4465, 0.4022, 0.5512, 0.4029, 0.4096, 0.4420, 0.4938],
       device='cuda:0') torch.Size([16])
percent tensor([0.6696, 0.6982, 0.5957, 0.6160, 0.5943, 0.6317, 0.6623, 0.6218, 0.6596,
        0.6809, 0.6996, 0.6503, 0.6957, 0.6952, 0.6800, 0.6679],
       device='cuda:0') torch.Size([16])
percent tensor([0.6127, 0.5417, 0.6252, 0.6212, 0.6451, 0.6331, 0.6117, 0.6526, 0.5983,
        0.5501, 0.5431, 0.5688, 0.5425, 0.5891, 0.5993, 0.6363],
       device='cuda:0') torch.Size([16])
percent tensor([0.4404, 0.4463, 0.5696, 0.6094, 0.6053, 0.6022, 0.4812, 0.4941, 0.5158,
        0.4367, 0.4533, 0.5089, 0.4346, 0.5198, 0.4483, 0.4912],
       device='cuda:0') torch.Size([16])
percent tensor([0.5773, 0.6082, 0.6502, 0.6621, 0.6480, 0.5818, 0.5866, 0.5720, 0.6411,
        0.6422, 0.6528, 0.6578, 0.6017, 0.6554, 0.5983, 0.5440],
       device='cuda:0') torch.Size([16])
percent tensor([0.9993, 0.9966, 0.9989, 0.9994, 0.9997, 0.9964, 0.9988, 0.9998, 0.9967,
        0.9982, 0.9967, 0.9996, 0.9971, 0.9977, 0.9992, 0.9992],
       device='cuda:0') torch.Size([16])
True Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=128, out_features=16, bias=False)
False Linear(in_features=16, out_features=2, bias=False)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=128, out_features=16, bias=False)
False Linear(in_features=16, out_features=2, bias=False)
True Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=256, out_features=32, bias=False)
False Linear(in_features=32, out_features=2, bias=False)
True Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=256, out_features=32, bias=False)
False Linear(in_features=32, out_features=2, bias=False)
True Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=512, out_features=64, bias=False)
False Linear(in_features=64, out_features=2, bias=False)
True Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=512, out_features=64, bias=False)
False Linear(in_features=64, out_features=2, bias=False)
True Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1024, out_features=128, bias=False)
False Linear(in_features=128, out_features=2, bias=False)
True Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1024, out_features=128, bias=False)
False Linear(in_features=128, out_features=2, bias=False)
True Linear(in_features=512, out_features=10, bias=True)
Epoch: 42 | Batch_idx: 0 |  Loss: (0.5628) |  Loss2: (0.0000) | Acc: (81.00%) (104/128)
Epoch: 42 | Batch_idx: 10 |  Loss: (0.4674) |  Loss2: (0.0000) | Acc: (83.00%) (1178/1408)
Epoch: 42 | Batch_idx: 20 |  Loss: (0.4525) |  Loss2: (0.0000) | Acc: (84.00%) (2271/2688)
Epoch: 42 | Batch_idx: 30 |  Loss: (0.4491) |  Loss2: (0.0000) | Acc: (84.00%) (3363/3968)
Epoch: 42 | Batch_idx: 40 |  Loss: (0.4473) |  Loss2: (0.0000) | Acc: (84.00%) (4434/5248)
Epoch: 42 | Batch_idx: 50 |  Loss: (0.4491) |  Loss2: (0.0000) | Acc: (84.00%) (5516/6528)
Epoch: 42 | Batch_idx: 60 |  Loss: (0.4469) |  Loss2: (0.0000) | Acc: (84.00%) (6604/7808)
Epoch: 42 | Batch_idx: 70 |  Loss: (0.4495) |  Loss2: (0.0000) | Acc: (84.00%) (7682/9088)
Epoch: 42 | Batch_idx: 80 |  Loss: (0.4497) |  Loss2: (0.0000) | Acc: (84.00%) (8775/10368)
Epoch: 42 | Batch_idx: 90 |  Loss: (0.4516) |  Loss2: (0.0000) | Acc: (84.00%) (9844/11648)
Epoch: 42 | Batch_idx: 100 |  Loss: (0.4481) |  Loss2: (0.0000) | Acc: (84.00%) (10958/12928)
Epoch: 42 | Batch_idx: 110 |  Loss: (0.4471) |  Loss2: (0.0000) | Acc: (84.00%) (12042/14208)
Epoch: 42 | Batch_idx: 120 |  Loss: (0.4470) |  Loss2: (0.0000) | Acc: (84.00%) (13125/15488)
Epoch: 42 | Batch_idx: 130 |  Loss: (0.4489) |  Loss2: (0.0000) | Acc: (84.00%) (14192/16768)
Epoch: 42 | Batch_idx: 140 |  Loss: (0.4496) |  Loss2: (0.0000) | Acc: (84.00%) (15251/18048)
Epoch: 42 | Batch_idx: 150 |  Loss: (0.4493) |  Loss2: (0.0000) | Acc: (84.00%) (16339/19328)
Epoch: 42 | Batch_idx: 160 |  Loss: (0.4505) |  Loss2: (0.0000) | Acc: (84.00%) (17401/20608)
Epoch: 42 | Batch_idx: 170 |  Loss: (0.4508) |  Loss2: (0.0000) | Acc: (84.00%) (18477/21888)
Epoch: 42 | Batch_idx: 180 |  Loss: (0.4526) |  Loss2: (0.0000) | Acc: (84.00%) (19547/23168)
Epoch: 42 | Batch_idx: 190 |  Loss: (0.4534) |  Loss2: (0.0000) | Acc: (84.00%) (20617/24448)
Epoch: 42 | Batch_idx: 200 |  Loss: (0.4527) |  Loss2: (0.0000) | Acc: (84.00%) (21713/25728)
Epoch: 42 | Batch_idx: 210 |  Loss: (0.4525) |  Loss2: (0.0000) | Acc: (84.00%) (22783/27008)
Epoch: 42 | Batch_idx: 220 |  Loss: (0.4524) |  Loss2: (0.0000) | Acc: (84.00%) (23872/28288)
Epoch: 42 | Batch_idx: 230 |  Loss: (0.4522) |  Loss2: (0.0000) | Acc: (84.00%) (24965/29568)
Epoch: 42 | Batch_idx: 240 |  Loss: (0.4536) |  Loss2: (0.0000) | Acc: (84.00%) (26027/30848)
Epoch: 42 | Batch_idx: 250 |  Loss: (0.4552) |  Loss2: (0.0000) | Acc: (84.00%) (27085/32128)
Epoch: 42 | Batch_idx: 260 |  Loss: (0.4554) |  Loss2: (0.0000) | Acc: (84.00%) (28163/33408)
Epoch: 42 | Batch_idx: 270 |  Loss: (0.4549) |  Loss2: (0.0000) | Acc: (84.00%) (29246/34688)
Epoch: 42 | Batch_idx: 280 |  Loss: (0.4556) |  Loss2: (0.0000) | Acc: (84.00%) (30317/35968)
Epoch: 42 | Batch_idx: 290 |  Loss: (0.4555) |  Loss2: (0.0000) | Acc: (84.00%) (31400/37248)
Epoch: 42 | Batch_idx: 300 |  Loss: (0.4563) |  Loss2: (0.0000) | Acc: (84.00%) (32465/38528)
Epoch: 42 | Batch_idx: 310 |  Loss: (0.4558) |  Loss2: (0.0000) | Acc: (84.00%) (33555/39808)
Epoch: 42 | Batch_idx: 320 |  Loss: (0.4553) |  Loss2: (0.0000) | Acc: (84.00%) (34641/41088)
Epoch: 42 | Batch_idx: 330 |  Loss: (0.4550) |  Loss2: (0.0000) | Acc: (84.00%) (35708/42368)
Epoch: 42 | Batch_idx: 340 |  Loss: (0.4546) |  Loss2: (0.0000) | Acc: (84.00%) (36780/43648)
Epoch: 42 | Batch_idx: 350 |  Loss: (0.4555) |  Loss2: (0.0000) | Acc: (84.00%) (37860/44928)
Epoch: 42 | Batch_idx: 360 |  Loss: (0.4544) |  Loss2: (0.0000) | Acc: (84.00%) (38963/46208)
Epoch: 42 | Batch_idx: 370 |  Loss: (0.4537) |  Loss2: (0.0000) | Acc: (84.00%) (40036/47488)
Epoch: 42 | Batch_idx: 380 |  Loss: (0.4535) |  Loss2: (0.0000) | Acc: (84.00%) (41117/48768)
Epoch: 42 | Batch_idx: 390 |  Loss: (0.4531) |  Loss2: (0.0000) | Acc: (84.00%) (42173/50000)
# TEST : Loss: (0.5682) | Acc: (80.00%) (8050/10000)
percent tensor([0.5249, 0.5294, 0.5255, 0.5240, 0.5263, 0.5274, 0.5299, 0.5232, 0.5230,
        0.5264, 0.5268, 0.5272, 0.5262, 0.5245, 0.5300, 0.5265],
       device='cuda:0') torch.Size([16])
percent tensor([0.5024, 0.5003, 0.4940, 0.5028, 0.4895, 0.5093, 0.4936, 0.4910, 0.4956,
        0.5001, 0.5037, 0.4977, 0.4999, 0.4983, 0.5034, 0.5035],
       device='cuda:0') torch.Size([16])
percent tensor([0.4888, 0.3997, 0.5901, 0.5658, 0.5850, 0.5265, 0.4977, 0.5695, 0.5260,
        0.4488, 0.4178, 0.5491, 0.4143, 0.4535, 0.4576, 0.4980],
       device='cuda:0') torch.Size([16])
percent tensor([0.6718, 0.6929, 0.5986, 0.6182, 0.6015, 0.6214, 0.6639, 0.6203, 0.6589,
        0.6853, 0.6973, 0.6558, 0.6950, 0.6877, 0.6771, 0.6680],
       device='cuda:0') torch.Size([16])
percent tensor([0.6171, 0.5491, 0.6295, 0.6287, 0.6458, 0.6310, 0.6119, 0.6451, 0.6027,
        0.5550, 0.5479, 0.5809, 0.5453, 0.5947, 0.6018, 0.6400],
       device='cuda:0') torch.Size([16])
percent tensor([0.4240, 0.4588, 0.5502, 0.5897, 0.5947, 0.5991, 0.4807, 0.5061, 0.5171,
        0.4433, 0.4580, 0.5130, 0.4334, 0.5100, 0.4529, 0.4880],
       device='cuda:0') torch.Size([16])
percent tensor([0.5854, 0.6225, 0.6328, 0.6590, 0.6308, 0.5900, 0.5960, 0.5769, 0.6387,
        0.6474, 0.6643, 0.6487, 0.6076, 0.6742, 0.5974, 0.5502],
       device='cuda:0') torch.Size([16])
percent tensor([0.9991, 0.9977, 0.9989, 0.9991, 0.9994, 0.9961, 0.9989, 0.9997, 0.9967,
        0.9987, 0.9970, 0.9992, 0.9977, 0.9987, 0.9993, 0.9991],
       device='cuda:0') torch.Size([16])
Epoch: 43 | Batch_idx: 0 |  Loss: (0.4439) |  Loss2: (0.0000) | Acc: (83.00%) (107/128)
Epoch: 43 | Batch_idx: 10 |  Loss: (0.4543) |  Loss2: (0.0000) | Acc: (83.00%) (1180/1408)
Epoch: 43 | Batch_idx: 20 |  Loss: (0.4369) |  Loss2: (0.0000) | Acc: (84.00%) (2266/2688)
Epoch: 43 | Batch_idx: 30 |  Loss: (0.4395) |  Loss2: (0.0000) | Acc: (84.00%) (3346/3968)
Epoch: 43 | Batch_idx: 40 |  Loss: (0.4417) |  Loss2: (0.0000) | Acc: (84.00%) (4430/5248)
Epoch: 43 | Batch_idx: 50 |  Loss: (0.4429) |  Loss2: (0.0000) | Acc: (84.00%) (5499/6528)
Epoch: 43 | Batch_idx: 60 |  Loss: (0.4374) |  Loss2: (0.0000) | Acc: (84.00%) (6599/7808)
Epoch: 43 | Batch_idx: 70 |  Loss: (0.4327) |  Loss2: (0.0000) | Acc: (84.00%) (7708/9088)
Epoch: 43 | Batch_idx: 80 |  Loss: (0.4355) |  Loss2: (0.0000) | Acc: (84.00%) (8787/10368)
Epoch: 43 | Batch_idx: 90 |  Loss: (0.4378) |  Loss2: (0.0000) | Acc: (84.00%) (9870/11648)
Epoch: 43 | Batch_idx: 100 |  Loss: (0.4400) |  Loss2: (0.0000) | Acc: (84.00%) (10950/12928)
Epoch: 43 | Batch_idx: 110 |  Loss: (0.4396) |  Loss2: (0.0000) | Acc: (84.00%) (12047/14208)
Epoch: 43 | Batch_idx: 120 |  Loss: (0.4374) |  Loss2: (0.0000) | Acc: (84.00%) (13136/15488)
Epoch: 43 | Batch_idx: 130 |  Loss: (0.4362) |  Loss2: (0.0000) | Acc: (84.00%) (14242/16768)
Epoch: 43 | Batch_idx: 140 |  Loss: (0.4390) |  Loss2: (0.0000) | Acc: (84.00%) (15295/18048)
Epoch: 43 | Batch_idx: 150 |  Loss: (0.4372) |  Loss2: (0.0000) | Acc: (84.00%) (16393/19328)
Epoch: 43 | Batch_idx: 160 |  Loss: (0.4378) |  Loss2: (0.0000) | Acc: (84.00%) (17478/20608)
Epoch: 43 | Batch_idx: 170 |  Loss: (0.4364) |  Loss2: (0.0000) | Acc: (84.00%) (18586/21888)
Epoch: 43 | Batch_idx: 180 |  Loss: (0.4363) |  Loss2: (0.0000) | Acc: (84.00%) (19668/23168)
Epoch: 43 | Batch_idx: 190 |  Loss: (0.4369) |  Loss2: (0.0000) | Acc: (84.00%) (20731/24448)
Epoch: 43 | Batch_idx: 200 |  Loss: (0.4378) |  Loss2: (0.0000) | Acc: (84.00%) (21820/25728)
Epoch: 43 | Batch_idx: 210 |  Loss: (0.4399) |  Loss2: (0.0000) | Acc: (84.00%) (22884/27008)
Epoch: 43 | Batch_idx: 220 |  Loss: (0.4386) |  Loss2: (0.0000) | Acc: (84.00%) (23976/28288)
Epoch: 43 | Batch_idx: 230 |  Loss: (0.4375) |  Loss2: (0.0000) | Acc: (84.00%) (25083/29568)
Epoch: 43 | Batch_idx: 240 |  Loss: (0.4383) |  Loss2: (0.0000) | Acc: (84.00%) (26173/30848)
Epoch: 43 | Batch_idx: 250 |  Loss: (0.4363) |  Loss2: (0.0000) | Acc: (84.00%) (27283/32128)
Epoch: 43 | Batch_idx: 260 |  Loss: (0.4376) |  Loss2: (0.0000) | Acc: (84.00%) (28357/33408)
Epoch: 43 | Batch_idx: 270 |  Loss: (0.4371) |  Loss2: (0.0000) | Acc: (84.00%) (29445/34688)
Epoch: 43 | Batch_idx: 280 |  Loss: (0.4375) |  Loss2: (0.0000) | Acc: (84.00%) (30531/35968)
Epoch: 43 | Batch_idx: 290 |  Loss: (0.4371) |  Loss2: (0.0000) | Acc: (84.00%) (31625/37248)
Epoch: 43 | Batch_idx: 300 |  Loss: (0.4374) |  Loss2: (0.0000) | Acc: (84.00%) (32703/38528)
Epoch: 43 | Batch_idx: 310 |  Loss: (0.4385) |  Loss2: (0.0000) | Acc: (84.00%) (33775/39808)
Epoch: 43 | Batch_idx: 320 |  Loss: (0.4376) |  Loss2: (0.0000) | Acc: (84.00%) (34876/41088)
Epoch: 43 | Batch_idx: 330 |  Loss: (0.4369) |  Loss2: (0.0000) | Acc: (84.00%) (35959/42368)
Epoch: 43 | Batch_idx: 340 |  Loss: (0.4354) |  Loss2: (0.0000) | Acc: (84.00%) (37066/43648)
Epoch: 43 | Batch_idx: 350 |  Loss: (0.4363) |  Loss2: (0.0000) | Acc: (84.00%) (38147/44928)
Epoch: 43 | Batch_idx: 360 |  Loss: (0.4358) |  Loss2: (0.0000) | Acc: (84.00%) (39244/46208)
Epoch: 43 | Batch_idx: 370 |  Loss: (0.4364) |  Loss2: (0.0000) | Acc: (84.00%) (40326/47488)
Epoch: 43 | Batch_idx: 380 |  Loss: (0.4367) |  Loss2: (0.0000) | Acc: (84.00%) (41413/48768)
Epoch: 43 | Batch_idx: 390 |  Loss: (0.4373) |  Loss2: (0.0000) | Acc: (84.00%) (42456/50000)
# TEST : Loss: (0.5108) | Acc: (82.00%) (8270/10000)
percent tensor([0.5248, 0.5292, 0.5256, 0.5240, 0.5268, 0.5273, 0.5304, 0.5229, 0.5229,
        0.5267, 0.5268, 0.5278, 0.5260, 0.5239, 0.5299, 0.5263],
       device='cuda:0') torch.Size([16])
percent tensor([0.5029, 0.5008, 0.4941, 0.5031, 0.4903, 0.5100, 0.4941, 0.4906, 0.4964,
        0.5004, 0.5041, 0.4974, 0.5004, 0.4986, 0.5039, 0.5042],
       device='cuda:0') torch.Size([16])
percent tensor([0.4804, 0.3891, 0.5982, 0.5681, 0.5842, 0.5193, 0.4852, 0.5763, 0.5175,
        0.4499, 0.4059, 0.5505, 0.4097, 0.4462, 0.4437, 0.4933],
       device='cuda:0') torch.Size([16])
percent tensor([0.6710, 0.6945, 0.6035, 0.6190, 0.6055, 0.6260, 0.6646, 0.6208, 0.6602,
        0.6811, 0.6967, 0.6554, 0.6903, 0.6868, 0.6780, 0.6689],
       device='cuda:0') torch.Size([16])
percent tensor([0.6154, 0.5517, 0.6225, 0.6317, 0.6397, 0.6315, 0.6115, 0.6401, 0.6002,
        0.5534, 0.5545, 0.5762, 0.5471, 0.6024, 0.6057, 0.6412],
       device='cuda:0') torch.Size([16])
percent tensor([0.4397, 0.4625, 0.5431, 0.5932, 0.5839, 0.6100, 0.4799, 0.4949, 0.5255,
        0.4506, 0.4746, 0.5148, 0.4643, 0.5306, 0.4524, 0.5021],
       device='cuda:0') torch.Size([16])
percent tensor([0.5689, 0.6062, 0.6251, 0.6523, 0.6299, 0.5988, 0.5784, 0.5732, 0.6334,
        0.6373, 0.6428, 0.6382, 0.6061, 0.6591, 0.5790, 0.5351],
       device='cuda:0') torch.Size([16])
percent tensor([0.9991, 0.9973, 0.9993, 0.9995, 0.9995, 0.9961, 0.9990, 0.9997, 0.9971,
        0.9985, 0.9973, 0.9994, 0.9978, 0.9980, 0.9996, 0.9993],
       device='cuda:0') torch.Size([16])
Epoch: 44 | Batch_idx: 0 |  Loss: (0.4578) |  Loss2: (0.0000) | Acc: (85.00%) (109/128)
Epoch: 44 | Batch_idx: 10 |  Loss: (0.3959) |  Loss2: (0.0000) | Acc: (86.00%) (1215/1408)
Epoch: 44 | Batch_idx: 20 |  Loss: (0.3923) |  Loss2: (0.0000) | Acc: (86.00%) (2322/2688)
Epoch: 44 | Batch_idx: 30 |  Loss: (0.3998) |  Loss2: (0.0000) | Acc: (86.00%) (3432/3968)
Epoch: 44 | Batch_idx: 40 |  Loss: (0.4109) |  Loss2: (0.0000) | Acc: (86.00%) (4528/5248)
Epoch: 44 | Batch_idx: 50 |  Loss: (0.4123) |  Loss2: (0.0000) | Acc: (86.00%) (5638/6528)
Epoch: 44 | Batch_idx: 60 |  Loss: (0.4091) |  Loss2: (0.0000) | Acc: (86.00%) (6742/7808)
Epoch: 44 | Batch_idx: 70 |  Loss: (0.4069) |  Loss2: (0.0000) | Acc: (86.00%) (7841/9088)
Epoch: 44 | Batch_idx: 80 |  Loss: (0.4086) |  Loss2: (0.0000) | Acc: (86.00%) (8937/10368)
Epoch: 44 | Batch_idx: 90 |  Loss: (0.4092) |  Loss2: (0.0000) | Acc: (86.00%) (10039/11648)
Epoch: 44 | Batch_idx: 100 |  Loss: (0.4119) |  Loss2: (0.0000) | Acc: (86.00%) (11132/12928)
Epoch: 44 | Batch_idx: 110 |  Loss: (0.4159) |  Loss2: (0.0000) | Acc: (85.00%) (12207/14208)
Epoch: 44 | Batch_idx: 120 |  Loss: (0.4191) |  Loss2: (0.0000) | Acc: (85.00%) (13285/15488)
Epoch: 44 | Batch_idx: 130 |  Loss: (0.4212) |  Loss2: (0.0000) | Acc: (85.00%) (14371/16768)
Epoch: 44 | Batch_idx: 140 |  Loss: (0.4189) |  Loss2: (0.0000) | Acc: (85.00%) (15487/18048)
Epoch: 44 | Batch_idx: 150 |  Loss: (0.4170) |  Loss2: (0.0000) | Acc: (85.00%) (16602/19328)
Epoch: 44 | Batch_idx: 160 |  Loss: (0.4181) |  Loss2: (0.0000) | Acc: (85.00%) (17691/20608)
Epoch: 44 | Batch_idx: 170 |  Loss: (0.4178) |  Loss2: (0.0000) | Acc: (85.00%) (18787/21888)
Epoch: 44 | Batch_idx: 180 |  Loss: (0.4191) |  Loss2: (0.0000) | Acc: (85.00%) (19879/23168)
Epoch: 44 | Batch_idx: 190 |  Loss: (0.4198) |  Loss2: (0.0000) | Acc: (85.00%) (20970/24448)
Epoch: 44 | Batch_idx: 200 |  Loss: (0.4201) |  Loss2: (0.0000) | Acc: (85.00%) (22065/25728)
Epoch: 44 | Batch_idx: 210 |  Loss: (0.4197) |  Loss2: (0.0000) | Acc: (85.00%) (23163/27008)
Epoch: 44 | Batch_idx: 220 |  Loss: (0.4198) |  Loss2: (0.0000) | Acc: (85.00%) (24264/28288)
Epoch: 44 | Batch_idx: 230 |  Loss: (0.4188) |  Loss2: (0.0000) | Acc: (85.00%) (25373/29568)
Epoch: 44 | Batch_idx: 240 |  Loss: (0.4166) |  Loss2: (0.0000) | Acc: (85.00%) (26495/30848)
Epoch: 44 | Batch_idx: 250 |  Loss: (0.4167) |  Loss2: (0.0000) | Acc: (85.00%) (27584/32128)
Epoch: 44 | Batch_idx: 260 |  Loss: (0.4179) |  Loss2: (0.0000) | Acc: (85.00%) (28668/33408)
Epoch: 44 | Batch_idx: 270 |  Loss: (0.4173) |  Loss2: (0.0000) | Acc: (85.00%) (29772/34688)
Epoch: 44 | Batch_idx: 280 |  Loss: (0.4187) |  Loss2: (0.0000) | Acc: (85.00%) (30846/35968)
Epoch: 44 | Batch_idx: 290 |  Loss: (0.4186) |  Loss2: (0.0000) | Acc: (85.00%) (31942/37248)
Epoch: 44 | Batch_idx: 300 |  Loss: (0.4187) |  Loss2: (0.0000) | Acc: (85.00%) (33030/38528)
Epoch: 44 | Batch_idx: 310 |  Loss: (0.4195) |  Loss2: (0.0000) | Acc: (85.00%) (34131/39808)
Epoch: 44 | Batch_idx: 320 |  Loss: (0.4197) |  Loss2: (0.0000) | Acc: (85.00%) (35235/41088)
Epoch: 44 | Batch_idx: 330 |  Loss: (0.4196) |  Loss2: (0.0000) | Acc: (85.00%) (36321/42368)
Epoch: 44 | Batch_idx: 340 |  Loss: (0.4194) |  Loss2: (0.0000) | Acc: (85.00%) (37421/43648)
Epoch: 44 | Batch_idx: 350 |  Loss: (0.4190) |  Loss2: (0.0000) | Acc: (85.00%) (38522/44928)
Epoch: 44 | Batch_idx: 360 |  Loss: (0.4190) |  Loss2: (0.0000) | Acc: (85.00%) (39616/46208)
Epoch: 44 | Batch_idx: 370 |  Loss: (0.4188) |  Loss2: (0.0000) | Acc: (85.00%) (40732/47488)
Epoch: 44 | Batch_idx: 380 |  Loss: (0.4195) |  Loss2: (0.0000) | Acc: (85.00%) (41814/48768)
Epoch: 44 | Batch_idx: 390 |  Loss: (0.4201) |  Loss2: (0.0000) | Acc: (85.00%) (42847/50000)
# TEST : Loss: (0.5369) | Acc: (82.00%) (8219/10000)
percent tensor([0.5248, 0.5293, 0.5244, 0.5239, 0.5254, 0.5268, 0.5295, 0.5231, 0.5224,
        0.5264, 0.5268, 0.5264, 0.5263, 0.5237, 0.5297, 0.5263],
       device='cuda:0') torch.Size([16])
percent tensor([0.5040, 0.5009, 0.4945, 0.5032, 0.4908, 0.5106, 0.4944, 0.4905, 0.4968,
        0.5011, 0.5051, 0.4988, 0.5012, 0.4974, 0.5049, 0.5043],
       device='cuda:0') torch.Size([16])
percent tensor([0.4871, 0.3869, 0.5989, 0.5721, 0.5874, 0.5262, 0.4838, 0.5762, 0.5258,
        0.4496, 0.4072, 0.5523, 0.4102, 0.4384, 0.4516, 0.5014],
       device='cuda:0') torch.Size([16])
percent tensor([0.6711, 0.6999, 0.5951, 0.6100, 0.5996, 0.6222, 0.6668, 0.6201, 0.6644,
        0.6838, 0.7015, 0.6537, 0.6970, 0.6951, 0.6793, 0.6666],
       device='cuda:0') torch.Size([16])
percent tensor([0.6165, 0.5594, 0.6278, 0.6394, 0.6403, 0.6355, 0.6186, 0.6454, 0.5991,
        0.5607, 0.5454, 0.5812, 0.5468, 0.6083, 0.6110, 0.6452],
       device='cuda:0') torch.Size([16])
percent tensor([0.4343, 0.4707, 0.5487, 0.5944, 0.5957, 0.5891, 0.4808, 0.4977, 0.5064,
        0.4527, 0.4795, 0.5196, 0.4662, 0.5216, 0.4462, 0.4931],
       device='cuda:0') torch.Size([16])
percent tensor([0.5771, 0.6035, 0.6243, 0.6392, 0.6345, 0.5913, 0.5771, 0.5625, 0.6291,
        0.6264, 0.6508, 0.6441, 0.6051, 0.6417, 0.5758, 0.5479],
       device='cuda:0') torch.Size([16])
percent tensor([0.9994, 0.9974, 0.9993, 0.9994, 0.9995, 0.9977, 0.9992, 0.9997, 0.9968,
        0.9980, 0.9973, 0.9992, 0.9967, 0.9984, 0.9995, 0.9996],
       device='cuda:0') torch.Size([16])
False Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=128, out_features=16, bias=False)
True Linear(in_features=16, out_features=2, bias=False)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=128, out_features=16, bias=False)
True Linear(in_features=16, out_features=2, bias=False)
False Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=256, out_features=32, bias=False)
True Linear(in_features=32, out_features=2, bias=False)
False Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=256, out_features=32, bias=False)
True Linear(in_features=32, out_features=2, bias=False)
False Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=512, out_features=64, bias=False)
True Linear(in_features=64, out_features=2, bias=False)
False Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=512, out_features=64, bias=False)
True Linear(in_features=64, out_features=2, bias=False)
False Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1024, out_features=128, bias=False)
True Linear(in_features=128, out_features=2, bias=False)
False Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1024, out_features=128, bias=False)
True Linear(in_features=128, out_features=2, bias=False)
False Linear(in_features=512, out_features=10, bias=True)
Epoch: 45 | Batch_idx: 0 |  Loss: (0.3931) |  Loss2: (0.0000) | Acc: (88.00%) (113/128)
Epoch: 45 | Batch_idx: 10 |  Loss: (0.3945) |  Loss2: (0.0000) | Acc: (86.00%) (1213/1408)
Epoch: 45 | Batch_idx: 20 |  Loss: (0.4471) |  Loss2: (0.0000) | Acc: (84.00%) (2263/2688)
Epoch: 45 | Batch_idx: 30 |  Loss: (0.4648) |  Loss2: (0.0000) | Acc: (83.00%) (3315/3968)
Epoch: 45 | Batch_idx: 40 |  Loss: (0.4686) |  Loss2: (0.0000) | Acc: (83.00%) (4372/5248)
Epoch: 45 | Batch_idx: 50 |  Loss: (0.4803) |  Loss2: (0.0000) | Acc: (82.00%) (5409/6528)
Epoch: 45 | Batch_idx: 60 |  Loss: (0.4856) |  Loss2: (0.0000) | Acc: (82.00%) (6463/7808)
Epoch: 45 | Batch_idx: 70 |  Loss: (0.4881) |  Loss2: (0.0000) | Acc: (82.00%) (7508/9088)
Epoch: 45 | Batch_idx: 80 |  Loss: (0.4907) |  Loss2: (0.0000) | Acc: (82.00%) (8545/10368)
Epoch: 45 | Batch_idx: 90 |  Loss: (0.4913) |  Loss2: (0.0000) | Acc: (82.00%) (9607/11648)
Epoch: 45 | Batch_idx: 100 |  Loss: (0.4933) |  Loss2: (0.0000) | Acc: (82.00%) (10663/12928)
Epoch: 45 | Batch_idx: 110 |  Loss: (0.4928) |  Loss2: (0.0000) | Acc: (82.00%) (11730/14208)
Epoch: 45 | Batch_idx: 120 |  Loss: (0.4906) |  Loss2: (0.0000) | Acc: (82.00%) (12800/15488)
Epoch: 45 | Batch_idx: 130 |  Loss: (0.4886) |  Loss2: (0.0000) | Acc: (82.00%) (13866/16768)
Epoch: 45 | Batch_idx: 140 |  Loss: (0.4881) |  Loss2: (0.0000) | Acc: (82.00%) (14951/18048)
Epoch: 45 | Batch_idx: 150 |  Loss: (0.4860) |  Loss2: (0.0000) | Acc: (82.00%) (16035/19328)
Epoch: 45 | Batch_idx: 160 |  Loss: (0.4853) |  Loss2: (0.0000) | Acc: (82.00%) (17091/20608)
Epoch: 45 | Batch_idx: 170 |  Loss: (0.4829) |  Loss2: (0.0000) | Acc: (82.00%) (18166/21888)
Epoch: 45 | Batch_idx: 180 |  Loss: (0.4812) |  Loss2: (0.0000) | Acc: (82.00%) (19225/23168)
Epoch: 45 | Batch_idx: 190 |  Loss: (0.4801) |  Loss2: (0.0000) | Acc: (83.00%) (20300/24448)
Epoch: 45 | Batch_idx: 200 |  Loss: (0.4783) |  Loss2: (0.0000) | Acc: (83.00%) (21382/25728)
Epoch: 45 | Batch_idx: 210 |  Loss: (0.4760) |  Loss2: (0.0000) | Acc: (83.00%) (22468/27008)
Epoch: 45 | Batch_idx: 220 |  Loss: (0.4759) |  Loss2: (0.0000) | Acc: (83.00%) (23547/28288)
Epoch: 45 | Batch_idx: 230 |  Loss: (0.4745) |  Loss2: (0.0000) | Acc: (83.00%) (24630/29568)
Epoch: 45 | Batch_idx: 240 |  Loss: (0.4733) |  Loss2: (0.0000) | Acc: (83.00%) (25720/30848)
Epoch: 45 | Batch_idx: 250 |  Loss: (0.4718) |  Loss2: (0.0000) | Acc: (83.00%) (26799/32128)
Epoch: 45 | Batch_idx: 260 |  Loss: (0.4709) |  Loss2: (0.0000) | Acc: (83.00%) (27875/33408)
Epoch: 45 | Batch_idx: 270 |  Loss: (0.4694) |  Loss2: (0.0000) | Acc: (83.00%) (28960/34688)
Epoch: 45 | Batch_idx: 280 |  Loss: (0.4683) |  Loss2: (0.0000) | Acc: (83.00%) (30044/35968)
Epoch: 45 | Batch_idx: 290 |  Loss: (0.4681) |  Loss2: (0.0000) | Acc: (83.00%) (31114/37248)
Epoch: 45 | Batch_idx: 300 |  Loss: (0.4683) |  Loss2: (0.0000) | Acc: (83.00%) (32202/38528)
Epoch: 45 | Batch_idx: 310 |  Loss: (0.4673) |  Loss2: (0.0000) | Acc: (83.00%) (33294/39808)
Epoch: 45 | Batch_idx: 320 |  Loss: (0.4660) |  Loss2: (0.0000) | Acc: (83.00%) (34377/41088)
Epoch: 45 | Batch_idx: 330 |  Loss: (0.4650) |  Loss2: (0.0000) | Acc: (83.00%) (35466/42368)
Epoch: 45 | Batch_idx: 340 |  Loss: (0.4644) |  Loss2: (0.0000) | Acc: (83.00%) (36544/43648)
Epoch: 45 | Batch_idx: 350 |  Loss: (0.4636) |  Loss2: (0.0000) | Acc: (83.00%) (37637/44928)
Epoch: 45 | Batch_idx: 360 |  Loss: (0.4631) |  Loss2: (0.0000) | Acc: (83.00%) (38719/46208)
Epoch: 45 | Batch_idx: 370 |  Loss: (0.4636) |  Loss2: (0.0000) | Acc: (83.00%) (39780/47488)
Epoch: 45 | Batch_idx: 380 |  Loss: (0.4639) |  Loss2: (0.0000) | Acc: (83.00%) (40844/48768)
Epoch: 45 | Batch_idx: 390 |  Loss: (0.4633) |  Loss2: (0.0000) | Acc: (83.00%) (41890/50000)
=> saving checkpoint 'drive/app/torch/save_Schedule/checkpoint_045.pth.tar'
# TEST : Loss: (0.4982) | Acc: (83.00%) (8338/10000)
percent tensor([0.5401, 0.5484, 0.5389, 0.5377, 0.5414, 0.5411, 0.5485, 0.5396, 0.5388,
        0.5438, 0.5444, 0.5433, 0.5438, 0.5402, 0.5476, 0.5423],
       device='cuda:0') torch.Size([16])
percent tensor([0.5048, 0.5020, 0.4976, 0.5038, 0.4950, 0.5093, 0.4972, 0.4943, 0.4995,
        0.5022, 0.5053, 0.5008, 0.5017, 0.4998, 0.5051, 0.5043],
       device='cuda:0') torch.Size([16])
percent tensor([0.4753, 0.3829, 0.6004, 0.5660, 0.5880, 0.4958, 0.4782, 0.5802, 0.5064,
        0.4413, 0.3951, 0.5421, 0.4040, 0.4182, 0.4364, 0.4850],
       device='cuda:0') torch.Size([16])
percent tensor([0.6372, 0.6576, 0.5770, 0.5901, 0.5832, 0.5891, 0.6368, 0.5994, 0.6364,
        0.6468, 0.6605, 0.6233, 0.6564, 0.6593, 0.6422, 0.6300],
       device='cuda:0') torch.Size([16])
percent tensor([0.6919, 0.5946, 0.7186, 0.7369, 0.7278, 0.7094, 0.6865, 0.7328, 0.6657,
        0.6031, 0.5900, 0.6649, 0.5926, 0.6698, 0.6788, 0.7154],
       device='cuda:0') torch.Size([16])
percent tensor([0.4497, 0.4770, 0.5718, 0.6048, 0.6163, 0.6137, 0.4919, 0.4948, 0.5076,
        0.4757, 0.4812, 0.5416, 0.4650, 0.5363, 0.4515, 0.5069],
       device='cuda:0') torch.Size([16])
percent tensor([0.6224, 0.6535, 0.6254, 0.6398, 0.6272, 0.6139, 0.6078, 0.5636, 0.6729,
        0.6790, 0.7023, 0.6550, 0.6586, 0.6898, 0.6065, 0.5818],
       device='cuda:0') torch.Size([16])
percent tensor([0.9995, 0.9970, 0.9989, 0.9990, 0.9993, 0.9966, 0.9993, 0.9997, 0.9974,
        0.9980, 0.9971, 0.9992, 0.9966, 0.9985, 0.9995, 0.9996],
       device='cuda:0') torch.Size([16])
Epoch: 46 | Batch_idx: 0 |  Loss: (0.3760) |  Loss2: (0.0000) | Acc: (85.00%) (110/128)
Epoch: 46 | Batch_idx: 10 |  Loss: (0.4218) |  Loss2: (0.0000) | Acc: (85.00%) (1206/1408)
Epoch: 46 | Batch_idx: 20 |  Loss: (0.4172) |  Loss2: (0.0000) | Acc: (85.00%) (2295/2688)
Epoch: 46 | Batch_idx: 30 |  Loss: (0.4229) |  Loss2: (0.0000) | Acc: (85.00%) (3391/3968)
Epoch: 46 | Batch_idx: 40 |  Loss: (0.4265) |  Loss2: (0.0000) | Acc: (85.00%) (4471/5248)
Epoch: 46 | Batch_idx: 50 |  Loss: (0.4194) |  Loss2: (0.0000) | Acc: (85.00%) (5580/6528)
Epoch: 46 | Batch_idx: 60 |  Loss: (0.4173) |  Loss2: (0.0000) | Acc: (85.00%) (6674/7808)
Epoch: 46 | Batch_idx: 70 |  Loss: (0.4185) |  Loss2: (0.0000) | Acc: (85.00%) (7761/9088)
Epoch: 46 | Batch_idx: 80 |  Loss: (0.4178) |  Loss2: (0.0000) | Acc: (85.00%) (8862/10368)
Epoch: 46 | Batch_idx: 90 |  Loss: (0.4191) |  Loss2: (0.0000) | Acc: (85.00%) (9946/11648)
Epoch: 46 | Batch_idx: 100 |  Loss: (0.4189) |  Loss2: (0.0000) | Acc: (85.00%) (11042/12928)
Epoch: 46 | Batch_idx: 110 |  Loss: (0.4202) |  Loss2: (0.0000) | Acc: (85.00%) (12137/14208)
Epoch: 46 | Batch_idx: 120 |  Loss: (0.4231) |  Loss2: (0.0000) | Acc: (85.00%) (13198/15488)
Epoch: 46 | Batch_idx: 130 |  Loss: (0.4270) |  Loss2: (0.0000) | Acc: (85.00%) (14280/16768)
Epoch: 46 | Batch_idx: 140 |  Loss: (0.4290) |  Loss2: (0.0000) | Acc: (85.00%) (15371/18048)
Epoch: 46 | Batch_idx: 150 |  Loss: (0.4308) |  Loss2: (0.0000) | Acc: (85.00%) (16447/19328)
Epoch: 46 | Batch_idx: 160 |  Loss: (0.4294) |  Loss2: (0.0000) | Acc: (85.00%) (17547/20608)
Epoch: 46 | Batch_idx: 170 |  Loss: (0.4286) |  Loss2: (0.0000) | Acc: (85.00%) (18641/21888)
Epoch: 46 | Batch_idx: 180 |  Loss: (0.4291) |  Loss2: (0.0000) | Acc: (85.00%) (19722/23168)
Epoch: 46 | Batch_idx: 190 |  Loss: (0.4283) |  Loss2: (0.0000) | Acc: (85.00%) (20814/24448)
Epoch: 46 | Batch_idx: 200 |  Loss: (0.4279) |  Loss2: (0.0000) | Acc: (85.00%) (21910/25728)
Epoch: 46 | Batch_idx: 210 |  Loss: (0.4278) |  Loss2: (0.0000) | Acc: (85.00%) (23006/27008)
Epoch: 46 | Batch_idx: 220 |  Loss: (0.4295) |  Loss2: (0.0000) | Acc: (85.00%) (24079/28288)
Epoch: 46 | Batch_idx: 230 |  Loss: (0.4274) |  Loss2: (0.0000) | Acc: (85.00%) (25187/29568)
Epoch: 46 | Batch_idx: 240 |  Loss: (0.4286) |  Loss2: (0.0000) | Acc: (85.00%) (26268/30848)
Epoch: 46 | Batch_idx: 250 |  Loss: (0.4265) |  Loss2: (0.0000) | Acc: (85.00%) (27384/32128)
Epoch: 46 | Batch_idx: 260 |  Loss: (0.4255) |  Loss2: (0.0000) | Acc: (85.00%) (28489/33408)
Epoch: 46 | Batch_idx: 270 |  Loss: (0.4247) |  Loss2: (0.0000) | Acc: (85.00%) (29600/34688)
Epoch: 46 | Batch_idx: 280 |  Loss: (0.4239) |  Loss2: (0.0000) | Acc: (85.00%) (30712/35968)
Epoch: 46 | Batch_idx: 290 |  Loss: (0.4232) |  Loss2: (0.0000) | Acc: (85.00%) (31816/37248)
Epoch: 46 | Batch_idx: 300 |  Loss: (0.4237) |  Loss2: (0.0000) | Acc: (85.00%) (32901/38528)
Epoch: 46 | Batch_idx: 310 |  Loss: (0.4228) |  Loss2: (0.0000) | Acc: (85.00%) (34002/39808)
Epoch: 46 | Batch_idx: 320 |  Loss: (0.4223) |  Loss2: (0.0000) | Acc: (85.00%) (35092/41088)
Epoch: 46 | Batch_idx: 330 |  Loss: (0.4217) |  Loss2: (0.0000) | Acc: (85.00%) (36192/42368)
Epoch: 46 | Batch_idx: 340 |  Loss: (0.4208) |  Loss2: (0.0000) | Acc: (85.00%) (37297/43648)
Epoch: 46 | Batch_idx: 350 |  Loss: (0.4223) |  Loss2: (0.0000) | Acc: (85.00%) (38352/44928)
Epoch: 46 | Batch_idx: 360 |  Loss: (0.4214) |  Loss2: (0.0000) | Acc: (85.00%) (39457/46208)
Epoch: 46 | Batch_idx: 370 |  Loss: (0.4215) |  Loss2: (0.0000) | Acc: (85.00%) (40549/47488)
Epoch: 46 | Batch_idx: 380 |  Loss: (0.4218) |  Loss2: (0.0000) | Acc: (85.00%) (41633/48768)
Epoch: 46 | Batch_idx: 390 |  Loss: (0.4212) |  Loss2: (0.0000) | Acc: (85.00%) (42685/50000)
# TEST : Loss: (0.4713) | Acc: (84.00%) (8411/10000)
percent tensor([0.5461, 0.5556, 0.5454, 0.5433, 0.5484, 0.5466, 0.5560, 0.5469, 0.5453,
        0.5509, 0.5511, 0.5504, 0.5505, 0.5464, 0.5543, 0.5485],
       device='cuda:0') torch.Size([16])
percent tensor([0.5049, 0.5027, 0.4986, 0.5039, 0.4965, 0.5090, 0.4984, 0.4957, 0.5003,
        0.5027, 0.5053, 0.5015, 0.5021, 0.5011, 0.5053, 0.5045],
       device='cuda:0') torch.Size([16])
percent tensor([0.4691, 0.3785, 0.5977, 0.5597, 0.5848, 0.4807, 0.4738, 0.5787, 0.5011,
        0.4352, 0.3890, 0.5352, 0.4008, 0.4129, 0.4260, 0.4768],
       device='cuda:0') torch.Size([16])
percent tensor([0.6436, 0.6644, 0.5844, 0.5967, 0.5920, 0.5906, 0.6459, 0.6090, 0.6428,
        0.6541, 0.6670, 0.6297, 0.6612, 0.6651, 0.6496, 0.6340],
       device='cuda:0') torch.Size([16])
percent tensor([0.6865, 0.5895, 0.7157, 0.7333, 0.7240, 0.7018, 0.6823, 0.7271, 0.6600,
        0.5917, 0.5802, 0.6611, 0.5878, 0.6692, 0.6705, 0.7069],
       device='cuda:0') torch.Size([16])
percent tensor([0.4439, 0.4736, 0.5702, 0.6060, 0.6190, 0.6288, 0.4850, 0.4888, 0.5032,
        0.4684, 0.4706, 0.5304, 0.4580, 0.5348, 0.4419, 0.5126],
       device='cuda:0') torch.Size([16])
percent tensor([0.6267, 0.6647, 0.6203, 0.6345, 0.6193, 0.6179, 0.6081, 0.5586, 0.6802,
        0.6914, 0.7131, 0.6548, 0.6687, 0.6950, 0.6075, 0.5828],
       device='cuda:0') torch.Size([16])
percent tensor([0.9995, 0.9971, 0.9990, 0.9992, 0.9994, 0.9965, 0.9992, 0.9997, 0.9976,
        0.9981, 0.9975, 0.9992, 0.9970, 0.9986, 0.9994, 0.9996],
       device='cuda:0') torch.Size([16])
Epoch: 47 | Batch_idx: 0 |  Loss: (0.4938) |  Loss2: (0.0000) | Acc: (82.00%) (105/128)
Epoch: 47 | Batch_idx: 10 |  Loss: (0.3915) |  Loss2: (0.0000) | Acc: (85.00%) (1206/1408)
Epoch: 47 | Batch_idx: 20 |  Loss: (0.4062) |  Loss2: (0.0000) | Acc: (85.00%) (2303/2688)
Epoch: 47 | Batch_idx: 30 |  Loss: (0.4090) |  Loss2: (0.0000) | Acc: (85.00%) (3394/3968)
Epoch: 47 | Batch_idx: 40 |  Loss: (0.4117) |  Loss2: (0.0000) | Acc: (85.00%) (4476/5248)
Epoch: 47 | Batch_idx: 50 |  Loss: (0.4172) |  Loss2: (0.0000) | Acc: (85.00%) (5550/6528)
Epoch: 47 | Batch_idx: 60 |  Loss: (0.4151) |  Loss2: (0.0000) | Acc: (85.00%) (6661/7808)
Epoch: 47 | Batch_idx: 70 |  Loss: (0.4162) |  Loss2: (0.0000) | Acc: (85.00%) (7747/9088)
Epoch: 47 | Batch_idx: 80 |  Loss: (0.4142) |  Loss2: (0.0000) | Acc: (85.00%) (8844/10368)
Epoch: 47 | Batch_idx: 90 |  Loss: (0.4123) |  Loss2: (0.0000) | Acc: (85.00%) (9959/11648)
Epoch: 47 | Batch_idx: 100 |  Loss: (0.4106) |  Loss2: (0.0000) | Acc: (85.00%) (11074/12928)
Epoch: 47 | Batch_idx: 110 |  Loss: (0.4138) |  Loss2: (0.0000) | Acc: (85.00%) (12147/14208)
Epoch: 47 | Batch_idx: 120 |  Loss: (0.4136) |  Loss2: (0.0000) | Acc: (85.00%) (13239/15488)
Epoch: 47 | Batch_idx: 130 |  Loss: (0.4149) |  Loss2: (0.0000) | Acc: (85.00%) (14318/16768)
Epoch: 47 | Batch_idx: 140 |  Loss: (0.4112) |  Loss2: (0.0000) | Acc: (85.00%) (15445/18048)
Epoch: 47 | Batch_idx: 150 |  Loss: (0.4107) |  Loss2: (0.0000) | Acc: (85.00%) (16541/19328)
Epoch: 47 | Batch_idx: 160 |  Loss: (0.4131) |  Loss2: (0.0000) | Acc: (85.00%) (17617/20608)
Epoch: 47 | Batch_idx: 170 |  Loss: (0.4122) |  Loss2: (0.0000) | Acc: (85.00%) (18724/21888)
Epoch: 47 | Batch_idx: 180 |  Loss: (0.4112) |  Loss2: (0.0000) | Acc: (85.00%) (19829/23168)
Epoch: 47 | Batch_idx: 190 |  Loss: (0.4094) |  Loss2: (0.0000) | Acc: (85.00%) (20948/24448)
Epoch: 47 | Batch_idx: 200 |  Loss: (0.4085) |  Loss2: (0.0000) | Acc: (85.00%) (22051/25728)
Epoch: 47 | Batch_idx: 210 |  Loss: (0.4085) |  Loss2: (0.0000) | Acc: (85.00%) (23149/27008)
Epoch: 47 | Batch_idx: 220 |  Loss: (0.4070) |  Loss2: (0.0000) | Acc: (85.00%) (24266/28288)
Epoch: 47 | Batch_idx: 230 |  Loss: (0.4082) |  Loss2: (0.0000) | Acc: (85.00%) (25358/29568)
Epoch: 47 | Batch_idx: 240 |  Loss: (0.4081) |  Loss2: (0.0000) | Acc: (85.00%) (26465/30848)
Epoch: 47 | Batch_idx: 250 |  Loss: (0.4088) |  Loss2: (0.0000) | Acc: (85.00%) (27569/32128)
Epoch: 47 | Batch_idx: 260 |  Loss: (0.4072) |  Loss2: (0.0000) | Acc: (85.00%) (28688/33408)
Epoch: 47 | Batch_idx: 270 |  Loss: (0.4077) |  Loss2: (0.0000) | Acc: (85.00%) (29788/34688)
Epoch: 47 | Batch_idx: 280 |  Loss: (0.4082) |  Loss2: (0.0000) | Acc: (85.00%) (30885/35968)
Epoch: 47 | Batch_idx: 290 |  Loss: (0.4070) |  Loss2: (0.0000) | Acc: (85.00%) (32008/37248)
Epoch: 47 | Batch_idx: 300 |  Loss: (0.4074) |  Loss2: (0.0000) | Acc: (85.00%) (33110/38528)
Epoch: 47 | Batch_idx: 310 |  Loss: (0.4073) |  Loss2: (0.0000) | Acc: (85.00%) (34205/39808)
Epoch: 47 | Batch_idx: 320 |  Loss: (0.4078) |  Loss2: (0.0000) | Acc: (85.00%) (35289/41088)
Epoch: 47 | Batch_idx: 330 |  Loss: (0.4079) |  Loss2: (0.0000) | Acc: (85.00%) (36389/42368)
Epoch: 47 | Batch_idx: 340 |  Loss: (0.4081) |  Loss2: (0.0000) | Acc: (85.00%) (37489/43648)
Epoch: 47 | Batch_idx: 350 |  Loss: (0.4084) |  Loss2: (0.0000) | Acc: (85.00%) (38597/44928)
Epoch: 47 | Batch_idx: 360 |  Loss: (0.4068) |  Loss2: (0.0000) | Acc: (85.00%) (39725/46208)
Epoch: 47 | Batch_idx: 370 |  Loss: (0.4067) |  Loss2: (0.0000) | Acc: (86.00%) (40840/47488)
Epoch: 47 | Batch_idx: 380 |  Loss: (0.4066) |  Loss2: (0.0000) | Acc: (86.00%) (41948/48768)
Epoch: 47 | Batch_idx: 390 |  Loss: (0.4058) |  Loss2: (0.0000) | Acc: (86.00%) (43036/50000)
# TEST : Loss: (0.4625) | Acc: (84.00%) (8451/10000)
percent tensor([0.5466, 0.5562, 0.5465, 0.5439, 0.5494, 0.5467, 0.5567, 0.5480, 0.5460,
        0.5516, 0.5515, 0.5515, 0.5512, 0.5469, 0.5547, 0.5489],
       device='cuda:0') torch.Size([16])
percent tensor([0.5047, 0.5027, 0.4989, 0.5037, 0.4970, 0.5088, 0.4988, 0.4962, 0.5005,
        0.5027, 0.5051, 0.5015, 0.5020, 0.5011, 0.5052, 0.5044],
       device='cuda:0') torch.Size([16])
percent tensor([0.4681, 0.3772, 0.5980, 0.5577, 0.5842, 0.4743, 0.4725, 0.5773, 0.4995,
        0.4343, 0.3877, 0.5336, 0.4014, 0.4094, 0.4222, 0.4738],
       device='cuda:0') torch.Size([16])
percent tensor([0.6521, 0.6748, 0.5908, 0.6023, 0.5993, 0.5941, 0.6565, 0.6175, 0.6504,
        0.6634, 0.6763, 0.6377, 0.6695, 0.6745, 0.6588, 0.6410],
       device='cuda:0') torch.Size([16])
percent tensor([0.6770, 0.5832, 0.7055, 0.7209, 0.7140, 0.6915, 0.6731, 0.7149, 0.6502,
        0.5809, 0.5711, 0.6501, 0.5806, 0.6611, 0.6606, 0.6954],
       device='cuda:0') torch.Size([16])
percent tensor([0.4381, 0.4657, 0.5679, 0.6062, 0.6204, 0.6390, 0.4758, 0.4817, 0.5000,
        0.4593, 0.4639, 0.5225, 0.4511, 0.5320, 0.4349, 0.5111],
       device='cuda:0') torch.Size([16])
percent tensor([0.6361, 0.6781, 0.6270, 0.6417, 0.6245, 0.6255, 0.6168, 0.5666, 0.6919,
        0.7056, 0.7265, 0.6650, 0.6809, 0.7059, 0.6175, 0.5893],
       device='cuda:0') torch.Size([16])
percent tensor([0.9995, 0.9972, 0.9990, 0.9993, 0.9994, 0.9966, 0.9993, 0.9997, 0.9979,
        0.9983, 0.9978, 0.9993, 0.9973, 0.9987, 0.9994, 0.9997],
       device='cuda:0') torch.Size([16])
True Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=128, out_features=16, bias=False)
False Linear(in_features=16, out_features=2, bias=False)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=128, out_features=16, bias=False)
False Linear(in_features=16, out_features=2, bias=False)
True Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=256, out_features=32, bias=False)
False Linear(in_features=32, out_features=2, bias=False)
True Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=256, out_features=32, bias=False)
False Linear(in_features=32, out_features=2, bias=False)
True Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=512, out_features=64, bias=False)
False Linear(in_features=64, out_features=2, bias=False)
True Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=512, out_features=64, bias=False)
False Linear(in_features=64, out_features=2, bias=False)
True Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1024, out_features=128, bias=False)
False Linear(in_features=128, out_features=2, bias=False)
True Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1024, out_features=128, bias=False)
False Linear(in_features=128, out_features=2, bias=False)
True Linear(in_features=512, out_features=10, bias=True)
Epoch: 48 | Batch_idx: 0 |  Loss: (0.4840) |  Loss2: (0.0000) | Acc: (82.00%) (105/128)
Epoch: 48 | Batch_idx: 10 |  Loss: (0.4065) |  Loss2: (0.0000) | Acc: (85.00%) (1205/1408)
Epoch: 48 | Batch_idx: 20 |  Loss: (0.3908) |  Loss2: (0.0000) | Acc: (86.00%) (2318/2688)
Epoch: 48 | Batch_idx: 30 |  Loss: (0.4008) |  Loss2: (0.0000) | Acc: (86.00%) (3427/3968)
Epoch: 48 | Batch_idx: 40 |  Loss: (0.4065) |  Loss2: (0.0000) | Acc: (85.00%) (4511/5248)
Epoch: 48 | Batch_idx: 50 |  Loss: (0.4121) |  Loss2: (0.0000) | Acc: (85.00%) (5606/6528)
Epoch: 48 | Batch_idx: 60 |  Loss: (0.4113) |  Loss2: (0.0000) | Acc: (85.00%) (6712/7808)
Epoch: 48 | Batch_idx: 70 |  Loss: (0.4129) |  Loss2: (0.0000) | Acc: (85.00%) (7809/9088)
Epoch: 48 | Batch_idx: 80 |  Loss: (0.4102) |  Loss2: (0.0000) | Acc: (85.00%) (8915/10368)
Epoch: 48 | Batch_idx: 90 |  Loss: (0.4145) |  Loss2: (0.0000) | Acc: (85.00%) (9987/11648)
Epoch: 48 | Batch_idx: 100 |  Loss: (0.4112) |  Loss2: (0.0000) | Acc: (85.00%) (11093/12928)
Epoch: 48 | Batch_idx: 110 |  Loss: (0.4118) |  Loss2: (0.0000) | Acc: (85.00%) (12178/14208)
Epoch: 48 | Batch_idx: 120 |  Loss: (0.4133) |  Loss2: (0.0000) | Acc: (85.00%) (13264/15488)
Epoch: 48 | Batch_idx: 130 |  Loss: (0.4116) |  Loss2: (0.0000) | Acc: (85.00%) (14375/16768)
Epoch: 48 | Batch_idx: 140 |  Loss: (0.4101) |  Loss2: (0.0000) | Acc: (85.00%) (15491/18048)
Epoch: 48 | Batch_idx: 150 |  Loss: (0.4100) |  Loss2: (0.0000) | Acc: (85.00%) (16579/19328)
Epoch: 48 | Batch_idx: 160 |  Loss: (0.4082) |  Loss2: (0.0000) | Acc: (85.00%) (17698/20608)
Epoch: 48 | Batch_idx: 170 |  Loss: (0.4088) |  Loss2: (0.0000) | Acc: (85.00%) (18798/21888)
Epoch: 48 | Batch_idx: 180 |  Loss: (0.4079) |  Loss2: (0.0000) | Acc: (85.00%) (19903/23168)
Epoch: 48 | Batch_idx: 190 |  Loss: (0.4075) |  Loss2: (0.0000) | Acc: (85.00%) (21009/24448)
Epoch: 48 | Batch_idx: 200 |  Loss: (0.4072) |  Loss2: (0.0000) | Acc: (85.00%) (22103/25728)
Epoch: 48 | Batch_idx: 210 |  Loss: (0.4067) |  Loss2: (0.0000) | Acc: (85.00%) (23195/27008)
Epoch: 48 | Batch_idx: 220 |  Loss: (0.4082) |  Loss2: (0.0000) | Acc: (85.00%) (24280/28288)
Epoch: 48 | Batch_idx: 230 |  Loss: (0.4083) |  Loss2: (0.0000) | Acc: (85.00%) (25373/29568)
Epoch: 48 | Batch_idx: 240 |  Loss: (0.4073) |  Loss2: (0.0000) | Acc: (85.00%) (26489/30848)
Epoch: 48 | Batch_idx: 250 |  Loss: (0.4060) |  Loss2: (0.0000) | Acc: (85.00%) (27606/32128)
Epoch: 48 | Batch_idx: 260 |  Loss: (0.4059) |  Loss2: (0.0000) | Acc: (85.00%) (28715/33408)
Epoch: 48 | Batch_idx: 270 |  Loss: (0.4056) |  Loss2: (0.0000) | Acc: (85.00%) (29809/34688)
Epoch: 48 | Batch_idx: 280 |  Loss: (0.4048) |  Loss2: (0.0000) | Acc: (86.00%) (30936/35968)
Epoch: 48 | Batch_idx: 290 |  Loss: (0.4057) |  Loss2: (0.0000) | Acc: (85.00%) (32029/37248)
Epoch: 48 | Batch_idx: 300 |  Loss: (0.4049) |  Loss2: (0.0000) | Acc: (86.00%) (33152/38528)
Epoch: 48 | Batch_idx: 310 |  Loss: (0.4066) |  Loss2: (0.0000) | Acc: (85.00%) (34230/39808)
Epoch: 48 | Batch_idx: 320 |  Loss: (0.4056) |  Loss2: (0.0000) | Acc: (86.00%) (35356/41088)
Epoch: 48 | Batch_idx: 330 |  Loss: (0.4064) |  Loss2: (0.0000) | Acc: (86.00%) (36448/42368)
Epoch: 48 | Batch_idx: 340 |  Loss: (0.4068) |  Loss2: (0.0000) | Acc: (86.00%) (37549/43648)
Epoch: 48 | Batch_idx: 350 |  Loss: (0.4066) |  Loss2: (0.0000) | Acc: (86.00%) (38642/44928)
Epoch: 48 | Batch_idx: 360 |  Loss: (0.4064) |  Loss2: (0.0000) | Acc: (86.00%) (39739/46208)
Epoch: 48 | Batch_idx: 370 |  Loss: (0.4076) |  Loss2: (0.0000) | Acc: (85.00%) (40833/47488)
Epoch: 48 | Batch_idx: 380 |  Loss: (0.4085) |  Loss2: (0.0000) | Acc: (85.00%) (41920/48768)
Epoch: 48 | Batch_idx: 390 |  Loss: (0.4088) |  Loss2: (0.0000) | Acc: (85.00%) (42980/50000)
# TEST : Loss: (0.5321) | Acc: (82.00%) (8238/10000)
percent tensor([0.5466, 0.5552, 0.5516, 0.5446, 0.5528, 0.5478, 0.5576, 0.5484, 0.5455,
        0.5522, 0.5504, 0.5549, 0.5498, 0.5463, 0.5545, 0.5486],
       device='cuda:0') torch.Size([16])
percent tensor([0.5037, 0.5026, 0.4975, 0.5038, 0.4955, 0.5086, 0.4977, 0.4968, 0.4995,
        0.5019, 0.5045, 0.4995, 0.5014, 0.5013, 0.5046, 0.5044],
       device='cuda:0') torch.Size([16])
percent tensor([0.4847, 0.3945, 0.5934, 0.5577, 0.5857, 0.5144, 0.4873, 0.5731, 0.5087,
        0.4431, 0.4042, 0.5395, 0.4182, 0.4280, 0.4468, 0.4957],
       device='cuda:0') torch.Size([16])
percent tensor([0.6519, 0.6731, 0.5933, 0.6050, 0.5991, 0.5856, 0.6520, 0.6178, 0.6482,
        0.6646, 0.6781, 0.6383, 0.6675, 0.6714, 0.6564, 0.6402],
       device='cuda:0') torch.Size([16])
percent tensor([0.6780, 0.5914, 0.6931, 0.7094, 0.7099, 0.6821, 0.6789, 0.7167, 0.6641,
        0.5778, 0.5787, 0.6402, 0.5856, 0.6849, 0.6577, 0.7007],
       device='cuda:0') torch.Size([16])
percent tensor([0.4535, 0.5055, 0.5641, 0.6167, 0.6091, 0.6246, 0.5108, 0.5003, 0.5340,
        0.4757, 0.4747, 0.5279, 0.4727, 0.5661, 0.4493, 0.5288],
       device='cuda:0') torch.Size([16])
percent tensor([0.6301, 0.6709, 0.6254, 0.6477, 0.6149, 0.6287, 0.6157, 0.5627, 0.6779,
        0.6932, 0.7264, 0.6743, 0.6724, 0.7086, 0.6174, 0.5708],
       device='cuda:0') torch.Size([16])
percent tensor([0.9995, 0.9974, 0.9997, 0.9995, 0.9998, 0.9974, 0.9991, 0.9999, 0.9977,
        0.9991, 0.9978, 0.9997, 0.9969, 0.9985, 0.9995, 0.9998],
       device='cuda:0') torch.Size([16])
Epoch: 49 | Batch_idx: 0 |  Loss: (0.3712) |  Loss2: (0.0000) | Acc: (89.00%) (115/128)
Epoch: 49 | Batch_idx: 10 |  Loss: (0.3923) |  Loss2: (0.0000) | Acc: (87.00%) (1230/1408)
Epoch: 49 | Batch_idx: 20 |  Loss: (0.3882) |  Loss2: (0.0000) | Acc: (87.00%) (2342/2688)
Epoch: 49 | Batch_idx: 30 |  Loss: (0.3870) |  Loss2: (0.0000) | Acc: (86.00%) (3449/3968)
Epoch: 49 | Batch_idx: 40 |  Loss: (0.3871) |  Loss2: (0.0000) | Acc: (86.00%) (4552/5248)
Epoch: 49 | Batch_idx: 50 |  Loss: (0.3954) |  Loss2: (0.0000) | Acc: (86.00%) (5633/6528)
Epoch: 49 | Batch_idx: 60 |  Loss: (0.3959) |  Loss2: (0.0000) | Acc: (86.00%) (6737/7808)
Epoch: 49 | Batch_idx: 70 |  Loss: (0.3950) |  Loss2: (0.0000) | Acc: (86.00%) (7851/9088)
Epoch: 49 | Batch_idx: 80 |  Loss: (0.3920) |  Loss2: (0.0000) | Acc: (86.00%) (8971/10368)
Epoch: 49 | Batch_idx: 90 |  Loss: (0.3943) |  Loss2: (0.0000) | Acc: (86.00%) (10077/11648)
Epoch: 49 | Batch_idx: 100 |  Loss: (0.3968) |  Loss2: (0.0000) | Acc: (86.00%) (11168/12928)
Epoch: 49 | Batch_idx: 110 |  Loss: (0.3951) |  Loss2: (0.0000) | Acc: (86.00%) (12285/14208)
Epoch: 49 | Batch_idx: 120 |  Loss: (0.3947) |  Loss2: (0.0000) | Acc: (86.00%) (13387/15488)
Epoch: 49 | Batch_idx: 130 |  Loss: (0.3953) |  Loss2: (0.0000) | Acc: (86.00%) (14492/16768)
Epoch: 49 | Batch_idx: 140 |  Loss: (0.3951) |  Loss2: (0.0000) | Acc: (86.00%) (15591/18048)
Epoch: 49 | Batch_idx: 150 |  Loss: (0.3947) |  Loss2: (0.0000) | Acc: (86.00%) (16693/19328)
Epoch: 49 | Batch_idx: 160 |  Loss: (0.3948) |  Loss2: (0.0000) | Acc: (86.00%) (17801/20608)
Epoch: 49 | Batch_idx: 170 |  Loss: (0.3943) |  Loss2: (0.0000) | Acc: (86.00%) (18910/21888)
Epoch: 49 | Batch_idx: 180 |  Loss: (0.3930) |  Loss2: (0.0000) | Acc: (86.00%) (20037/23168)
Epoch: 49 | Batch_idx: 190 |  Loss: (0.3928) |  Loss2: (0.0000) | Acc: (86.00%) (21141/24448)
Epoch: 49 | Batch_idx: 200 |  Loss: (0.3930) |  Loss2: (0.0000) | Acc: (86.00%) (22235/25728)
Epoch: 49 | Batch_idx: 210 |  Loss: (0.3934) |  Loss2: (0.0000) | Acc: (86.00%) (23331/27008)
Epoch: 49 | Batch_idx: 220 |  Loss: (0.3939) |  Loss2: (0.0000) | Acc: (86.00%) (24442/28288)
Epoch: 49 | Batch_idx: 230 |  Loss: (0.3933) |  Loss2: (0.0000) | Acc: (86.00%) (25550/29568)
Epoch: 49 | Batch_idx: 240 |  Loss: (0.3950) |  Loss2: (0.0000) | Acc: (86.00%) (26645/30848)
Epoch: 49 | Batch_idx: 250 |  Loss: (0.3979) |  Loss2: (0.0000) | Acc: (86.00%) (27731/32128)
Epoch: 49 | Batch_idx: 260 |  Loss: (0.3988) |  Loss2: (0.0000) | Acc: (86.00%) (28811/33408)
Epoch: 49 | Batch_idx: 270 |  Loss: (0.3982) |  Loss2: (0.0000) | Acc: (86.00%) (29928/34688)
Epoch: 49 | Batch_idx: 280 |  Loss: (0.3991) |  Loss2: (0.0000) | Acc: (86.00%) (31029/35968)
Epoch: 49 | Batch_idx: 290 |  Loss: (0.3984) |  Loss2: (0.0000) | Acc: (86.00%) (32146/37248)
Epoch: 49 | Batch_idx: 300 |  Loss: (0.3975) |  Loss2: (0.0000) | Acc: (86.00%) (33263/38528)
Epoch: 49 | Batch_idx: 310 |  Loss: (0.3971) |  Loss2: (0.0000) | Acc: (86.00%) (34372/39808)
Epoch: 49 | Batch_idx: 320 |  Loss: (0.3979) |  Loss2: (0.0000) | Acc: (86.00%) (35456/41088)
Epoch: 49 | Batch_idx: 330 |  Loss: (0.3968) |  Loss2: (0.0000) | Acc: (86.00%) (36577/42368)
Epoch: 49 | Batch_idx: 340 |  Loss: (0.3965) |  Loss2: (0.0000) | Acc: (86.00%) (37675/43648)
Epoch: 49 | Batch_idx: 350 |  Loss: (0.3965) |  Loss2: (0.0000) | Acc: (86.00%) (38792/44928)
Epoch: 49 | Batch_idx: 360 |  Loss: (0.3967) |  Loss2: (0.0000) | Acc: (86.00%) (39901/46208)
Epoch: 49 | Batch_idx: 370 |  Loss: (0.3964) |  Loss2: (0.0000) | Acc: (86.00%) (41007/47488)
Epoch: 49 | Batch_idx: 380 |  Loss: (0.3964) |  Loss2: (0.0000) | Acc: (86.00%) (42110/48768)
Epoch: 49 | Batch_idx: 390 |  Loss: (0.3970) |  Loss2: (0.0000) | Acc: (86.00%) (43170/50000)
# TEST : Loss: (0.5555) | Acc: (81.00%) (8106/10000)
percent tensor([0.5466, 0.5558, 0.5481, 0.5449, 0.5499, 0.5476, 0.5564, 0.5477, 0.5457,
        0.5517, 0.5508, 0.5518, 0.5503, 0.5469, 0.5547, 0.5491],
       device='cuda:0') torch.Size([16])
percent tensor([0.5044, 0.5027, 0.4993, 0.5040, 0.4969, 0.5086, 0.4985, 0.4967, 0.4989,
        0.5027, 0.5048, 0.5017, 0.5019, 0.5003, 0.5055, 0.5041],
       device='cuda:0') torch.Size([16])
percent tensor([0.4635, 0.3756, 0.5859, 0.5433, 0.5749, 0.4682, 0.4670, 0.5668, 0.5091,
        0.4315, 0.3900, 0.5218, 0.4052, 0.4235, 0.4113, 0.4712],
       device='cuda:0') torch.Size([16])
percent tensor([0.6608, 0.6794, 0.6041, 0.6123, 0.6082, 0.6068, 0.6606, 0.6239, 0.6483,
        0.6679, 0.6812, 0.6431, 0.6732, 0.6727, 0.6676, 0.6487],
       device='cuda:0') torch.Size([16])
percent tensor([0.6707, 0.5750, 0.7006, 0.7068, 0.7106, 0.6911, 0.6625, 0.7131, 0.6599,
        0.5786, 0.5756, 0.6406, 0.5805, 0.6597, 0.6525, 0.6932],
       device='cuda:0') torch.Size([16])
percent tensor([0.4099, 0.4387, 0.5248, 0.5694, 0.5797, 0.6030, 0.4633, 0.4727, 0.5120,
        0.4211, 0.4487, 0.4882, 0.4324, 0.5099, 0.4170, 0.4787],
       device='cuda:0') torch.Size([16])
percent tensor([0.6322, 0.6829, 0.6264, 0.6473, 0.6288, 0.6222, 0.6264, 0.5834, 0.6816,
        0.6992, 0.7223, 0.6696, 0.6820, 0.7075, 0.6360, 0.5701],
       device='cuda:0') torch.Size([16])
percent tensor([0.9994, 0.9980, 0.9983, 0.9990, 0.9997, 0.9981, 0.9987, 0.9995, 0.9976,
        0.9988, 0.9978, 0.9992, 0.9978, 0.9983, 0.9992, 0.9995],
       device='cuda:0') torch.Size([16])
Epoch: 50 | Batch_idx: 0 |  Loss: (0.3655) |  Loss2: (0.0000) | Acc: (86.00%) (111/128)
Epoch: 50 | Batch_idx: 10 |  Loss: (0.3892) |  Loss2: (0.0000) | Acc: (86.00%) (1220/1408)
Epoch: 50 | Batch_idx: 20 |  Loss: (0.3740) |  Loss2: (0.0000) | Acc: (86.00%) (2332/2688)
Epoch: 50 | Batch_idx: 30 |  Loss: (0.3861) |  Loss2: (0.0000) | Acc: (86.00%) (3444/3968)
Epoch: 50 | Batch_idx: 40 |  Loss: (0.3791) |  Loss2: (0.0000) | Acc: (86.00%) (4564/5248)
Epoch: 50 | Batch_idx: 50 |  Loss: (0.3794) |  Loss2: (0.0000) | Acc: (86.00%) (5671/6528)
Epoch: 50 | Batch_idx: 60 |  Loss: (0.3774) |  Loss2: (0.0000) | Acc: (86.00%) (6791/7808)
Epoch: 50 | Batch_idx: 70 |  Loss: (0.3762) |  Loss2: (0.0000) | Acc: (87.00%) (7913/9088)
Epoch: 50 | Batch_idx: 80 |  Loss: (0.3718) |  Loss2: (0.0000) | Acc: (87.00%) (9042/10368)
Epoch: 50 | Batch_idx: 90 |  Loss: (0.3742) |  Loss2: (0.0000) | Acc: (87.00%) (10143/11648)
Epoch: 50 | Batch_idx: 100 |  Loss: (0.3738) |  Loss2: (0.0000) | Acc: (87.00%) (11261/12928)
Epoch: 50 | Batch_idx: 110 |  Loss: (0.3745) |  Loss2: (0.0000) | Acc: (87.00%) (12372/14208)
Epoch: 50 | Batch_idx: 120 |  Loss: (0.3760) |  Loss2: (0.0000) | Acc: (86.00%) (13467/15488)
Epoch: 50 | Batch_idx: 130 |  Loss: (0.3766) |  Loss2: (0.0000) | Acc: (86.00%) (14586/16768)
Epoch: 50 | Batch_idx: 140 |  Loss: (0.3761) |  Loss2: (0.0000) | Acc: (87.00%) (15702/18048)
Epoch: 50 | Batch_idx: 150 |  Loss: (0.3767) |  Loss2: (0.0000) | Acc: (86.00%) (16811/19328)
Epoch: 50 | Batch_idx: 160 |  Loss: (0.3771) |  Loss2: (0.0000) | Acc: (86.00%) (17915/20608)
Epoch: 50 | Batch_idx: 170 |  Loss: (0.3802) |  Loss2: (0.0000) | Acc: (86.00%) (19024/21888)
Epoch: 50 | Batch_idx: 180 |  Loss: (0.3804) |  Loss2: (0.0000) | Acc: (86.00%) (20138/23168)
Epoch: 50 | Batch_idx: 190 |  Loss: (0.3816) |  Loss2: (0.0000) | Acc: (86.00%) (21228/24448)
Epoch: 50 | Batch_idx: 200 |  Loss: (0.3822) |  Loss2: (0.0000) | Acc: (86.00%) (22338/25728)
Epoch: 50 | Batch_idx: 210 |  Loss: (0.3816) |  Loss2: (0.0000) | Acc: (86.00%) (23458/27008)
Epoch: 50 | Batch_idx: 220 |  Loss: (0.3818) |  Loss2: (0.0000) | Acc: (86.00%) (24575/28288)
Epoch: 50 | Batch_idx: 230 |  Loss: (0.3832) |  Loss2: (0.0000) | Acc: (86.00%) (25684/29568)
Epoch: 50 | Batch_idx: 240 |  Loss: (0.3833) |  Loss2: (0.0000) | Acc: (86.00%) (26800/30848)
Epoch: 50 | Batch_idx: 250 |  Loss: (0.3835) |  Loss2: (0.0000) | Acc: (86.00%) (27905/32128)
Epoch: 50 | Batch_idx: 260 |  Loss: (0.3825) |  Loss2: (0.0000) | Acc: (86.00%) (29015/33408)
Epoch: 50 | Batch_idx: 270 |  Loss: (0.3830) |  Loss2: (0.0000) | Acc: (86.00%) (30121/34688)
Epoch: 50 | Batch_idx: 280 |  Loss: (0.3834) |  Loss2: (0.0000) | Acc: (86.00%) (31227/35968)
Epoch: 50 | Batch_idx: 290 |  Loss: (0.3825) |  Loss2: (0.0000) | Acc: (86.00%) (32352/37248)
Epoch: 50 | Batch_idx: 300 |  Loss: (0.3834) |  Loss2: (0.0000) | Acc: (86.00%) (33441/38528)
Epoch: 50 | Batch_idx: 310 |  Loss: (0.3837) |  Loss2: (0.0000) | Acc: (86.00%) (34546/39808)
Epoch: 50 | Batch_idx: 320 |  Loss: (0.3830) |  Loss2: (0.0000) | Acc: (86.00%) (35676/41088)
Epoch: 50 | Batch_idx: 330 |  Loss: (0.3828) |  Loss2: (0.0000) | Acc: (86.00%) (36791/42368)
Epoch: 50 | Batch_idx: 340 |  Loss: (0.3837) |  Loss2: (0.0000) | Acc: (86.00%) (37886/43648)
Epoch: 50 | Batch_idx: 350 |  Loss: (0.3853) |  Loss2: (0.0000) | Acc: (86.00%) (38969/44928)
Epoch: 50 | Batch_idx: 360 |  Loss: (0.3853) |  Loss2: (0.0000) | Acc: (86.00%) (40081/46208)
Epoch: 50 | Batch_idx: 370 |  Loss: (0.3859) |  Loss2: (0.0000) | Acc: (86.00%) (41188/47488)
Epoch: 50 | Batch_idx: 380 |  Loss: (0.3863) |  Loss2: (0.0000) | Acc: (86.00%) (42298/48768)
Epoch: 50 | Batch_idx: 390 |  Loss: (0.3869) |  Loss2: (0.0000) | Acc: (86.00%) (43353/50000)
=> saving checkpoint 'drive/app/torch/save_Schedule/checkpoint_050.pth.tar'
# TEST : Loss: (0.5147) | Acc: (82.00%) (8253/10000)
percent tensor([0.5467, 0.5552, 0.5489, 0.5454, 0.5518, 0.5490, 0.5574, 0.5476, 0.5466,
        0.5515, 0.5509, 0.5527, 0.5504, 0.5465, 0.5549, 0.5494],
       device='cuda:0') torch.Size([16])
percent tensor([0.5037, 0.5021, 0.4984, 0.5031, 0.4957, 0.5080, 0.4975, 0.4966, 0.4986,
        0.5020, 0.5043, 0.5006, 0.5012, 0.5000, 0.5045, 0.5036],
       device='cuda:0') torch.Size([16])
percent tensor([0.4813, 0.3958, 0.5881, 0.5587, 0.5802, 0.4990, 0.4830, 0.5675, 0.5144,
        0.4415, 0.4082, 0.5270, 0.4193, 0.4364, 0.4341, 0.4910],
       device='cuda:0') torch.Size([16])
percent tensor([0.6517, 0.6724, 0.5909, 0.6059, 0.6024, 0.5899, 0.6498, 0.6153, 0.6422,
        0.6616, 0.6762, 0.6334, 0.6674, 0.6649, 0.6589, 0.6385],
       device='cuda:0') torch.Size([16])
percent tensor([0.6719, 0.5965, 0.6971, 0.7163, 0.7055, 0.6852, 0.6689, 0.7070, 0.6635,
        0.5907, 0.5793, 0.6467, 0.5897, 0.6758, 0.6637, 0.6950],
       device='cuda:0') torch.Size([16])
percent tensor([0.4383, 0.5037, 0.5624, 0.5949, 0.6045, 0.6259, 0.5107, 0.5033, 0.5385,
        0.4734, 0.4794, 0.5366, 0.4709, 0.5576, 0.4543, 0.5095],
       device='cuda:0') torch.Size([16])
percent tensor([0.6203, 0.6590, 0.6452, 0.6463, 0.6484, 0.6355, 0.6248, 0.5827, 0.6803,
        0.6878, 0.7163, 0.6638, 0.6627, 0.6845, 0.6088, 0.5700],
       device='cuda:0') torch.Size([16])
percent tensor([0.9994, 0.9984, 0.9989, 0.9992, 0.9996, 0.9976, 0.9987, 0.9997, 0.9979,
        0.9987, 0.9987, 0.9996, 0.9988, 0.9982, 0.9993, 0.9994],
       device='cuda:0') torch.Size([16])
False Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=128, out_features=16, bias=False)
True Linear(in_features=16, out_features=2, bias=False)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=128, out_features=16, bias=False)
True Linear(in_features=16, out_features=2, bias=False)
False Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=256, out_features=32, bias=False)
True Linear(in_features=32, out_features=2, bias=False)
False Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=256, out_features=32, bias=False)
True Linear(in_features=32, out_features=2, bias=False)
False Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=512, out_features=64, bias=False)
True Linear(in_features=64, out_features=2, bias=False)
False Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=512, out_features=64, bias=False)
True Linear(in_features=64, out_features=2, bias=False)
False Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1024, out_features=128, bias=False)
True Linear(in_features=128, out_features=2, bias=False)
False Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1024, out_features=128, bias=False)
True Linear(in_features=128, out_features=2, bias=False)
False Linear(in_features=512, out_features=10, bias=True)
Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 3, 3, 3]) tensor(175.4984, device='cuda:0')
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(796.1670, device='cuda:0')
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(796.2121, device='cuda:0')
Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([128, 64, 3, 3]) tensor(1524.5840, device='cuda:0')
Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([128, 64, 1, 1]) tensor(507.7042, device='cuda:0')
Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([128, 128, 3, 3]) tensor(2202.4375, device='cuda:0')
Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([256, 128, 3, 3]) tensor(4303.2944, device='cuda:0')
Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([256, 128, 1, 1]) tensor(1429.2278, device='cuda:0')
Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([256, 256, 3, 3]) tensor(6098.0225, device='cuda:0')
Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([512, 256, 3, 3]) tensor(12061.4053, device='cuda:0')
Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([512, 256, 1, 1]) tensor(4020.5222, device='cuda:0')
Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([512, 512, 3, 3]) tensor(16973.7012, device='cuda:0')
Epoch: 51 | Batch_idx: 0 |  Loss: (0.3058) |  Loss2: (0.0000) | Acc: (89.00%) (115/128)
Epoch: 51 | Batch_idx: 10 |  Loss: (0.4017) |  Loss2: (0.0000) | Acc: (85.00%) (1204/1408)
Epoch: 51 | Batch_idx: 20 |  Loss: (0.4104) |  Loss2: (0.0000) | Acc: (85.00%) (2295/2688)
Epoch: 51 | Batch_idx: 30 |  Loss: (0.4388) |  Loss2: (0.0000) | Acc: (84.00%) (3363/3968)
Epoch: 51 | Batch_idx: 40 |  Loss: (0.4543) |  Loss2: (0.0000) | Acc: (84.00%) (4422/5248)
Epoch: 51 | Batch_idx: 50 |  Loss: (0.4551) |  Loss2: (0.0000) | Acc: (84.00%) (5506/6528)
Epoch: 51 | Batch_idx: 60 |  Loss: (0.4547) |  Loss2: (0.0000) | Acc: (84.00%) (6575/7808)
Epoch: 51 | Batch_idx: 70 |  Loss: (0.4524) |  Loss2: (0.0000) | Acc: (84.00%) (7660/9088)
Epoch: 51 | Batch_idx: 80 |  Loss: (0.4495) |  Loss2: (0.0000) | Acc: (84.00%) (8750/10368)
Epoch: 51 | Batch_idx: 90 |  Loss: (0.4486) |  Loss2: (0.0000) | Acc: (84.00%) (9822/11648)
Epoch: 51 | Batch_idx: 100 |  Loss: (0.4505) |  Loss2: (0.0000) | Acc: (84.00%) (10897/12928)
Epoch: 51 | Batch_idx: 110 |  Loss: (0.4512) |  Loss2: (0.0000) | Acc: (84.00%) (11972/14208)
Epoch: 51 | Batch_idx: 120 |  Loss: (0.4501) |  Loss2: (0.0000) | Acc: (84.00%) (13061/15488)
Epoch: 51 | Batch_idx: 130 |  Loss: (0.4463) |  Loss2: (0.0000) | Acc: (84.00%) (14163/16768)
Epoch: 51 | Batch_idx: 140 |  Loss: (0.4441) |  Loss2: (0.0000) | Acc: (84.00%) (15269/18048)
Epoch: 51 | Batch_idx: 150 |  Loss: (0.4421) |  Loss2: (0.0000) | Acc: (84.00%) (16358/19328)
Epoch: 51 | Batch_idx: 160 |  Loss: (0.4418) |  Loss2: (0.0000) | Acc: (84.00%) (17432/20608)
Epoch: 51 | Batch_idx: 170 |  Loss: (0.4421) |  Loss2: (0.0000) | Acc: (84.00%) (18531/21888)
Epoch: 51 | Batch_idx: 180 |  Loss: (0.4411) |  Loss2: (0.0000) | Acc: (84.00%) (19626/23168)
Epoch: 51 | Batch_idx: 190 |  Loss: (0.4400) |  Loss2: (0.0000) | Acc: (84.00%) (20726/24448)
Epoch: 51 | Batch_idx: 200 |  Loss: (0.4378) |  Loss2: (0.0000) | Acc: (84.00%) (21830/25728)
Epoch: 51 | Batch_idx: 210 |  Loss: (0.4365) |  Loss2: (0.0000) | Acc: (84.00%) (22922/27008)
Epoch: 51 | Batch_idx: 220 |  Loss: (0.4350) |  Loss2: (0.0000) | Acc: (84.00%) (24016/28288)
Epoch: 51 | Batch_idx: 230 |  Loss: (0.4335) |  Loss2: (0.0000) | Acc: (84.00%) (25115/29568)
Epoch: 51 | Batch_idx: 240 |  Loss: (0.4328) |  Loss2: (0.0000) | Acc: (84.00%) (26210/30848)
Epoch: 51 | Batch_idx: 250 |  Loss: (0.4302) |  Loss2: (0.0000) | Acc: (85.00%) (27335/32128)
Epoch: 51 | Batch_idx: 260 |  Loss: (0.4290) |  Loss2: (0.0000) | Acc: (85.00%) (28437/33408)
Epoch: 51 | Batch_idx: 270 |  Loss: (0.4298) |  Loss2: (0.0000) | Acc: (85.00%) (29519/34688)
Epoch: 51 | Batch_idx: 280 |  Loss: (0.4289) |  Loss2: (0.0000) | Acc: (85.00%) (30620/35968)
Epoch: 51 | Batch_idx: 290 |  Loss: (0.4289) |  Loss2: (0.0000) | Acc: (85.00%) (31724/37248)
Epoch: 51 | Batch_idx: 300 |  Loss: (0.4276) |  Loss2: (0.0000) | Acc: (85.00%) (32837/38528)
Epoch: 51 | Batch_idx: 310 |  Loss: (0.4264) |  Loss2: (0.0000) | Acc: (85.00%) (33949/39808)
Epoch: 51 | Batch_idx: 320 |  Loss: (0.4260) |  Loss2: (0.0000) | Acc: (85.00%) (35051/41088)
Epoch: 51 | Batch_idx: 330 |  Loss: (0.4256) |  Loss2: (0.0000) | Acc: (85.00%) (36148/42368)
Epoch: 51 | Batch_idx: 340 |  Loss: (0.4245) |  Loss2: (0.0000) | Acc: (85.00%) (37256/43648)
Epoch: 51 | Batch_idx: 350 |  Loss: (0.4233) |  Loss2: (0.0000) | Acc: (85.00%) (38367/44928)
Epoch: 51 | Batch_idx: 360 |  Loss: (0.4234) |  Loss2: (0.0000) | Acc: (85.00%) (39464/46208)
Epoch: 51 | Batch_idx: 370 |  Loss: (0.4225) |  Loss2: (0.0000) | Acc: (85.00%) (40550/47488)
Epoch: 51 | Batch_idx: 380 |  Loss: (0.4222) |  Loss2: (0.0000) | Acc: (85.00%) (41654/48768)
Epoch: 51 | Batch_idx: 390 |  Loss: (0.4222) |  Loss2: (0.0000) | Acc: (85.00%) (42695/50000)
# TEST : Loss: (0.4715) | Acc: (83.00%) (8379/10000)
percent tensor([0.5399, 0.5482, 0.5417, 0.5395, 0.5441, 0.5424, 0.5497, 0.5407, 0.5398,
        0.5444, 0.5436, 0.5456, 0.5433, 0.5412, 0.5477, 0.5426],
       device='cuda:0') torch.Size([16])
percent tensor([0.5045, 0.5036, 0.4997, 0.5041, 0.4979, 0.5083, 0.5002, 0.4984, 0.5000,
        0.5029, 0.5054, 0.5015, 0.5021, 0.5014, 0.5060, 0.5040],
       device='cuda:0') torch.Size([16])
percent tensor([0.4979, 0.4165, 0.6231, 0.5869, 0.6172, 0.5043, 0.5125, 0.6061, 0.5425,
        0.4727, 0.4340, 0.5672, 0.4354, 0.4385, 0.4551, 0.5071],
       device='cuda:0') torch.Size([16])
percent tensor([0.6530, 0.6800, 0.5878, 0.6026, 0.5992, 0.5815, 0.6547, 0.6040, 0.6401,
        0.6704, 0.6815, 0.6411, 0.6756, 0.6681, 0.6597, 0.6394],
       device='cuda:0') torch.Size([16])
percent tensor([0.6393, 0.5863, 0.6639, 0.6785, 0.6733, 0.6366, 0.6451, 0.6714, 0.6343,
        0.5870, 0.5736, 0.6216, 0.5740, 0.6467, 0.6396, 0.6562],
       device='cuda:0') torch.Size([16])
percent tensor([0.4478, 0.5018, 0.5604, 0.5938, 0.6039, 0.6369, 0.5014, 0.5127, 0.5332,
        0.4717, 0.4797, 0.5221, 0.4707, 0.5591, 0.4642, 0.5217],
       device='cuda:0') torch.Size([16])
percent tensor([0.5879, 0.6086, 0.6078, 0.6285, 0.6178, 0.6461, 0.5834, 0.5556, 0.6409,
        0.6204, 0.6493, 0.6004, 0.6060, 0.6376, 0.5598, 0.5573],
       device='cuda:0') torch.Size([16])
percent tensor([0.9995, 0.9979, 0.9991, 0.9994, 0.9998, 0.9982, 0.9987, 0.9997, 0.9977,
        0.9986, 0.9980, 0.9996, 0.9976, 0.9977, 0.9989, 0.9996],
       device='cuda:0') torch.Size([16])
Epoch: 52 | Batch_idx: 0 |  Loss: (0.3548) |  Loss2: (0.0000) | Acc: (88.00%) (113/128)
Epoch: 52 | Batch_idx: 10 |  Loss: (0.4201) |  Loss2: (0.0000) | Acc: (85.00%) (1198/1408)
Epoch: 52 | Batch_idx: 20 |  Loss: (0.4241) |  Loss2: (0.0000) | Acc: (85.00%) (2288/2688)
Epoch: 52 | Batch_idx: 30 |  Loss: (0.4080) |  Loss2: (0.0000) | Acc: (85.00%) (3406/3968)
Epoch: 52 | Batch_idx: 40 |  Loss: (0.3976) |  Loss2: (0.0000) | Acc: (86.00%) (4520/5248)
Epoch: 52 | Batch_idx: 50 |  Loss: (0.3955) |  Loss2: (0.0000) | Acc: (86.00%) (5623/6528)
Epoch: 52 | Batch_idx: 60 |  Loss: (0.3980) |  Loss2: (0.0000) | Acc: (86.00%) (6725/7808)
Epoch: 52 | Batch_idx: 70 |  Loss: (0.3928) |  Loss2: (0.0000) | Acc: (86.00%) (7850/9088)
Epoch: 52 | Batch_idx: 80 |  Loss: (0.3955) |  Loss2: (0.0000) | Acc: (86.00%) (8941/10368)
Epoch: 52 | Batch_idx: 90 |  Loss: (0.3940) |  Loss2: (0.0000) | Acc: (86.00%) (10065/11648)
Epoch: 52 | Batch_idx: 100 |  Loss: (0.3936) |  Loss2: (0.0000) | Acc: (86.00%) (11178/12928)
Epoch: 52 | Batch_idx: 110 |  Loss: (0.3909) |  Loss2: (0.0000) | Acc: (86.00%) (12297/14208)
Epoch: 52 | Batch_idx: 120 |  Loss: (0.3903) |  Loss2: (0.0000) | Acc: (86.00%) (13408/15488)
Epoch: 52 | Batch_idx: 130 |  Loss: (0.3938) |  Loss2: (0.0000) | Acc: (86.00%) (14489/16768)
Epoch: 52 | Batch_idx: 140 |  Loss: (0.3942) |  Loss2: (0.0000) | Acc: (86.00%) (15589/18048)
Epoch: 52 | Batch_idx: 150 |  Loss: (0.3919) |  Loss2: (0.0000) | Acc: (86.00%) (16708/19328)
Epoch: 52 | Batch_idx: 160 |  Loss: (0.3896) |  Loss2: (0.0000) | Acc: (86.00%) (17840/20608)
Epoch: 52 | Batch_idx: 170 |  Loss: (0.3900) |  Loss2: (0.0000) | Acc: (86.00%) (18944/21888)
Epoch: 52 | Batch_idx: 180 |  Loss: (0.3888) |  Loss2: (0.0000) | Acc: (86.00%) (20066/23168)
Epoch: 52 | Batch_idx: 190 |  Loss: (0.3887) |  Loss2: (0.0000) | Acc: (86.00%) (21174/24448)
Epoch: 52 | Batch_idx: 200 |  Loss: (0.3883) |  Loss2: (0.0000) | Acc: (86.00%) (22273/25728)
Epoch: 52 | Batch_idx: 210 |  Loss: (0.3898) |  Loss2: (0.0000) | Acc: (86.00%) (23367/27008)
Epoch: 52 | Batch_idx: 220 |  Loss: (0.3886) |  Loss2: (0.0000) | Acc: (86.00%) (24489/28288)
Epoch: 52 | Batch_idx: 230 |  Loss: (0.3885) |  Loss2: (0.0000) | Acc: (86.00%) (25598/29568)
Epoch: 52 | Batch_idx: 240 |  Loss: (0.3887) |  Loss2: (0.0000) | Acc: (86.00%) (26703/30848)
Epoch: 52 | Batch_idx: 250 |  Loss: (0.3890) |  Loss2: (0.0000) | Acc: (86.00%) (27808/32128)
Epoch: 52 | Batch_idx: 260 |  Loss: (0.3897) |  Loss2: (0.0000) | Acc: (86.00%) (28909/33408)
Epoch: 52 | Batch_idx: 270 |  Loss: (0.3897) |  Loss2: (0.0000) | Acc: (86.00%) (30023/34688)
Epoch: 52 | Batch_idx: 280 |  Loss: (0.3910) |  Loss2: (0.0000) | Acc: (86.00%) (31103/35968)
Epoch: 52 | Batch_idx: 290 |  Loss: (0.3915) |  Loss2: (0.0000) | Acc: (86.00%) (32199/37248)
Epoch: 52 | Batch_idx: 300 |  Loss: (0.3906) |  Loss2: (0.0000) | Acc: (86.00%) (33312/38528)
Epoch: 52 | Batch_idx: 310 |  Loss: (0.3907) |  Loss2: (0.0000) | Acc: (86.00%) (34412/39808)
Epoch: 52 | Batch_idx: 320 |  Loss: (0.3917) |  Loss2: (0.0000) | Acc: (86.00%) (35486/41088)
Epoch: 52 | Batch_idx: 330 |  Loss: (0.3915) |  Loss2: (0.0000) | Acc: (86.00%) (36602/42368)
Epoch: 52 | Batch_idx: 340 |  Loss: (0.3910) |  Loss2: (0.0000) | Acc: (86.00%) (37721/43648)
Epoch: 52 | Batch_idx: 350 |  Loss: (0.3914) |  Loss2: (0.0000) | Acc: (86.00%) (38829/44928)
Epoch: 52 | Batch_idx: 360 |  Loss: (0.3918) |  Loss2: (0.0000) | Acc: (86.00%) (39933/46208)
Epoch: 52 | Batch_idx: 370 |  Loss: (0.3916) |  Loss2: (0.0000) | Acc: (86.00%) (41043/47488)
Epoch: 52 | Batch_idx: 380 |  Loss: (0.3923) |  Loss2: (0.0000) | Acc: (86.00%) (42141/48768)
Epoch: 52 | Batch_idx: 390 |  Loss: (0.3922) |  Loss2: (0.0000) | Acc: (86.00%) (43204/50000)
# TEST : Loss: (0.4556) | Acc: (84.00%) (8435/10000)
percent tensor([0.5394, 0.5477, 0.5415, 0.5394, 0.5438, 0.5418, 0.5493, 0.5405, 0.5393,
        0.5441, 0.5429, 0.5455, 0.5427, 0.5408, 0.5471, 0.5421],
       device='cuda:0') torch.Size([16])
percent tensor([0.5042, 0.5037, 0.4995, 0.5039, 0.4979, 0.5079, 0.5004, 0.4983, 0.4999,
        0.5029, 0.5054, 0.5015, 0.5021, 0.5018, 0.5059, 0.5039],
       device='cuda:0') torch.Size([16])
percent tensor([0.4951, 0.4125, 0.6358, 0.5956, 0.6282, 0.5095, 0.5152, 0.6131, 0.5426,
        0.4761, 0.4328, 0.5805, 0.4307, 0.4300, 0.4559, 0.5071],
       device='cuda:0') torch.Size([16])
percent tensor([0.6547, 0.6844, 0.5840, 0.6007, 0.5959, 0.5789, 0.6578, 0.6013, 0.6404,
        0.6732, 0.6852, 0.6412, 0.6780, 0.6729, 0.6619, 0.6398],
       device='cuda:0') torch.Size([16])
percent tensor([0.6553, 0.6018, 0.6765, 0.6900, 0.6859, 0.6444, 0.6612, 0.6836, 0.6446,
        0.6047, 0.5878, 0.6382, 0.5899, 0.6577, 0.6572, 0.6710],
       device='cuda:0') torch.Size([16])
percent tensor([0.4520, 0.5003, 0.5650, 0.5980, 0.6082, 0.6391, 0.5031, 0.5127, 0.5305,
        0.4715, 0.4778, 0.5200, 0.4705, 0.5585, 0.4621, 0.5249],
       device='cuda:0') torch.Size([16])
percent tensor([0.5990, 0.6135, 0.6236, 0.6488, 0.6389, 0.6747, 0.5924, 0.5717, 0.6511,
        0.6165, 0.6461, 0.5994, 0.6048, 0.6435, 0.5636, 0.5747],
       device='cuda:0') torch.Size([16])
percent tensor([0.9996, 0.9979, 0.9992, 0.9994, 0.9998, 0.9984, 0.9989, 0.9997, 0.9979,
        0.9987, 0.9979, 0.9996, 0.9976, 0.9978, 0.9990, 0.9997],
       device='cuda:0') torch.Size([16])
Epoch: 53 | Batch_idx: 0 |  Loss: (0.4330) |  Loss2: (0.0000) | Acc: (85.00%) (110/128)
Epoch: 53 | Batch_idx: 10 |  Loss: (0.3622) |  Loss2: (0.0000) | Acc: (87.00%) (1237/1408)
Epoch: 53 | Batch_idx: 20 |  Loss: (0.3670) |  Loss2: (0.0000) | Acc: (86.00%) (2332/2688)
Epoch: 53 | Batch_idx: 30 |  Loss: (0.3682) |  Loss2: (0.0000) | Acc: (86.00%) (3448/3968)
Epoch: 53 | Batch_idx: 40 |  Loss: (0.3663) |  Loss2: (0.0000) | Acc: (86.00%) (4564/5248)
Epoch: 53 | Batch_idx: 50 |  Loss: (0.3651) |  Loss2: (0.0000) | Acc: (87.00%) (5689/6528)
Epoch: 53 | Batch_idx: 60 |  Loss: (0.3655) |  Loss2: (0.0000) | Acc: (87.00%) (6802/7808)
Epoch: 53 | Batch_idx: 70 |  Loss: (0.3666) |  Loss2: (0.0000) | Acc: (87.00%) (7913/9088)
Epoch: 53 | Batch_idx: 80 |  Loss: (0.3634) |  Loss2: (0.0000) | Acc: (87.00%) (9039/10368)
Epoch: 53 | Batch_idx: 90 |  Loss: (0.3661) |  Loss2: (0.0000) | Acc: (87.00%) (10161/11648)
Epoch: 53 | Batch_idx: 100 |  Loss: (0.3704) |  Loss2: (0.0000) | Acc: (87.00%) (11252/12928)
Epoch: 53 | Batch_idx: 110 |  Loss: (0.3719) |  Loss2: (0.0000) | Acc: (87.00%) (12368/14208)
Epoch: 53 | Batch_idx: 120 |  Loss: (0.3746) |  Loss2: (0.0000) | Acc: (87.00%) (13483/15488)
Epoch: 53 | Batch_idx: 130 |  Loss: (0.3760) |  Loss2: (0.0000) | Acc: (87.00%) (14594/16768)
Epoch: 53 | Batch_idx: 140 |  Loss: (0.3741) |  Loss2: (0.0000) | Acc: (87.00%) (15718/18048)
Epoch: 53 | Batch_idx: 150 |  Loss: (0.3729) |  Loss2: (0.0000) | Acc: (87.00%) (16850/19328)
Epoch: 53 | Batch_idx: 160 |  Loss: (0.3736) |  Loss2: (0.0000) | Acc: (87.00%) (17956/20608)
Epoch: 53 | Batch_idx: 170 |  Loss: (0.3733) |  Loss2: (0.0000) | Acc: (87.00%) (19081/21888)
Epoch: 53 | Batch_idx: 180 |  Loss: (0.3725) |  Loss2: (0.0000) | Acc: (87.00%) (20201/23168)
Epoch: 53 | Batch_idx: 190 |  Loss: (0.3725) |  Loss2: (0.0000) | Acc: (87.00%) (21316/24448)
Epoch: 53 | Batch_idx: 200 |  Loss: (0.3725) |  Loss2: (0.0000) | Acc: (87.00%) (22434/25728)
Epoch: 53 | Batch_idx: 210 |  Loss: (0.3719) |  Loss2: (0.0000) | Acc: (87.00%) (23555/27008)
Epoch: 53 | Batch_idx: 220 |  Loss: (0.3723) |  Loss2: (0.0000) | Acc: (87.00%) (24645/28288)
Epoch: 53 | Batch_idx: 230 |  Loss: (0.3718) |  Loss2: (0.0000) | Acc: (87.00%) (25772/29568)
Epoch: 53 | Batch_idx: 240 |  Loss: (0.3710) |  Loss2: (0.0000) | Acc: (87.00%) (26903/30848)
Epoch: 53 | Batch_idx: 250 |  Loss: (0.3714) |  Loss2: (0.0000) | Acc: (87.00%) (28033/32128)
Epoch: 53 | Batch_idx: 260 |  Loss: (0.3726) |  Loss2: (0.0000) | Acc: (87.00%) (29136/33408)
Epoch: 53 | Batch_idx: 270 |  Loss: (0.3729) |  Loss2: (0.0000) | Acc: (87.00%) (30242/34688)
Epoch: 53 | Batch_idx: 280 |  Loss: (0.3729) |  Loss2: (0.0000) | Acc: (87.00%) (31354/35968)
Epoch: 53 | Batch_idx: 290 |  Loss: (0.3728) |  Loss2: (0.0000) | Acc: (87.00%) (32469/37248)
Epoch: 53 | Batch_idx: 300 |  Loss: (0.3736) |  Loss2: (0.0000) | Acc: (87.00%) (33577/38528)
Epoch: 53 | Batch_idx: 310 |  Loss: (0.3736) |  Loss2: (0.0000) | Acc: (87.00%) (34694/39808)
Epoch: 53 | Batch_idx: 320 |  Loss: (0.3738) |  Loss2: (0.0000) | Acc: (87.00%) (35801/41088)
Epoch: 53 | Batch_idx: 330 |  Loss: (0.3742) |  Loss2: (0.0000) | Acc: (87.00%) (36919/42368)
Epoch: 53 | Batch_idx: 340 |  Loss: (0.3739) |  Loss2: (0.0000) | Acc: (87.00%) (38039/43648)
Epoch: 53 | Batch_idx: 350 |  Loss: (0.3752) |  Loss2: (0.0000) | Acc: (87.00%) (39145/44928)
Epoch: 53 | Batch_idx: 360 |  Loss: (0.3758) |  Loss2: (0.0000) | Acc: (87.00%) (40247/46208)
Epoch: 53 | Batch_idx: 370 |  Loss: (0.3763) |  Loss2: (0.0000) | Acc: (87.00%) (41355/47488)
Epoch: 53 | Batch_idx: 380 |  Loss: (0.3762) |  Loss2: (0.0000) | Acc: (87.00%) (42485/48768)
Epoch: 53 | Batch_idx: 390 |  Loss: (0.3768) |  Loss2: (0.0000) | Acc: (87.00%) (43551/50000)
# TEST : Loss: (0.4467) | Acc: (84.00%) (8467/10000)
percent tensor([0.5421, 0.5512, 0.5445, 0.5422, 0.5470, 0.5443, 0.5528, 0.5438, 0.5424,
        0.5475, 0.5460, 0.5491, 0.5458, 0.5441, 0.5502, 0.5451],
       device='cuda:0') torch.Size([16])
percent tensor([0.5037, 0.5035, 0.4991, 0.5036, 0.4975, 0.5073, 0.5002, 0.4980, 0.4997,
        0.5026, 0.5050, 0.5013, 0.5019, 0.5018, 0.5054, 0.5033],
       device='cuda:0') torch.Size([16])
percent tensor([0.4934, 0.4067, 0.6381, 0.5978, 0.6290, 0.5145, 0.5124, 0.6120, 0.5374,
        0.4742, 0.4292, 0.5824, 0.4260, 0.4254, 0.4538, 0.5083],
       device='cuda:0') torch.Size([16])
percent tensor([0.6608, 0.6922, 0.5872, 0.6046, 0.5999, 0.5830, 0.6651, 0.6056, 0.6453,
        0.6796, 0.6920, 0.6463, 0.6838, 0.6812, 0.6691, 0.6454],
       device='cuda:0') torch.Size([16])
percent tensor([0.6570, 0.5991, 0.6794, 0.6942, 0.6895, 0.6473, 0.6633, 0.6879, 0.6422,
        0.6028, 0.5837, 0.6387, 0.5859, 0.6568, 0.6588, 0.6728],
       device='cuda:0') torch.Size([16])
percent tensor([0.4573, 0.4978, 0.5691, 0.6019, 0.6115, 0.6438, 0.5052, 0.5138, 0.5309,
        0.4724, 0.4787, 0.5213, 0.4727, 0.5588, 0.4623, 0.5279],
       device='cuda:0') torch.Size([16])
percent tensor([0.6127, 0.6220, 0.6364, 0.6630, 0.6549, 0.6943, 0.6032, 0.5825, 0.6626,
        0.6199, 0.6516, 0.6016, 0.6096, 0.6530, 0.5712, 0.5898],
       device='cuda:0') torch.Size([16])
percent tensor([0.9996, 0.9981, 0.9993, 0.9995, 0.9998, 0.9985, 0.9991, 0.9997, 0.9981,
        0.9988, 0.9981, 0.9997, 0.9978, 0.9980, 0.9992, 0.9997],
       device='cuda:0') torch.Size([16])
True Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=128, out_features=16, bias=False)
False Linear(in_features=16, out_features=2, bias=False)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=128, out_features=16, bias=False)
False Linear(in_features=16, out_features=2, bias=False)
True Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=256, out_features=32, bias=False)
False Linear(in_features=32, out_features=2, bias=False)
True Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=256, out_features=32, bias=False)
False Linear(in_features=32, out_features=2, bias=False)
True Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=512, out_features=64, bias=False)
False Linear(in_features=64, out_features=2, bias=False)
True Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=512, out_features=64, bias=False)
False Linear(in_features=64, out_features=2, bias=False)
True Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1024, out_features=128, bias=False)
False Linear(in_features=128, out_features=2, bias=False)
True Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1024, out_features=128, bias=False)
False Linear(in_features=128, out_features=2, bias=False)
True Linear(in_features=512, out_features=10, bias=True)
Epoch: 54 | Batch_idx: 0 |  Loss: (0.4312) |  Loss2: (0.0000) | Acc: (85.00%) (110/128)
Epoch: 54 | Batch_idx: 10 |  Loss: (0.3598) |  Loss2: (0.0000) | Acc: (88.00%) (1241/1408)
Epoch: 54 | Batch_idx: 20 |  Loss: (0.3612) |  Loss2: (0.0000) | Acc: (87.00%) (2361/2688)
Epoch: 54 | Batch_idx: 30 |  Loss: (0.3754) |  Loss2: (0.0000) | Acc: (87.00%) (3461/3968)
Epoch: 54 | Batch_idx: 40 |  Loss: (0.3799) |  Loss2: (0.0000) | Acc: (87.00%) (4578/5248)
Epoch: 54 | Batch_idx: 50 |  Loss: (0.3793) |  Loss2: (0.0000) | Acc: (87.00%) (5684/6528)
Epoch: 54 | Batch_idx: 60 |  Loss: (0.3814) |  Loss2: (0.0000) | Acc: (86.00%) (6788/7808)
Epoch: 54 | Batch_idx: 70 |  Loss: (0.3833) |  Loss2: (0.0000) | Acc: (86.00%) (7889/9088)
Epoch: 54 | Batch_idx: 80 |  Loss: (0.3837) |  Loss2: (0.0000) | Acc: (86.00%) (8989/10368)
Epoch: 54 | Batch_idx: 90 |  Loss: (0.3819) |  Loss2: (0.0000) | Acc: (86.00%) (10106/11648)
Epoch: 54 | Batch_idx: 100 |  Loss: (0.3836) |  Loss2: (0.0000) | Acc: (86.00%) (11210/12928)
Epoch: 54 | Batch_idx: 110 |  Loss: (0.3829) |  Loss2: (0.0000) | Acc: (86.00%) (12320/14208)
Epoch: 54 | Batch_idx: 120 |  Loss: (0.3819) |  Loss2: (0.0000) | Acc: (86.00%) (13445/15488)
Epoch: 54 | Batch_idx: 130 |  Loss: (0.3815) |  Loss2: (0.0000) | Acc: (86.00%) (14557/16768)
Epoch: 54 | Batch_idx: 140 |  Loss: (0.3814) |  Loss2: (0.0000) | Acc: (86.00%) (15686/18048)
Epoch: 54 | Batch_idx: 150 |  Loss: (0.3821) |  Loss2: (0.0000) | Acc: (86.00%) (16800/19328)
Epoch: 54 | Batch_idx: 160 |  Loss: (0.3829) |  Loss2: (0.0000) | Acc: (86.00%) (17914/20608)
Epoch: 54 | Batch_idx: 170 |  Loss: (0.3844) |  Loss2: (0.0000) | Acc: (86.00%) (19022/21888)
Epoch: 54 | Batch_idx: 180 |  Loss: (0.3834) |  Loss2: (0.0000) | Acc: (86.00%) (20137/23168)
Epoch: 54 | Batch_idx: 190 |  Loss: (0.3820) |  Loss2: (0.0000) | Acc: (86.00%) (21246/24448)
Epoch: 54 | Batch_idx: 200 |  Loss: (0.3815) |  Loss2: (0.0000) | Acc: (86.00%) (22361/25728)
Epoch: 54 | Batch_idx: 210 |  Loss: (0.3822) |  Loss2: (0.0000) | Acc: (86.00%) (23449/27008)
Epoch: 54 | Batch_idx: 220 |  Loss: (0.3824) |  Loss2: (0.0000) | Acc: (86.00%) (24564/28288)
Epoch: 54 | Batch_idx: 230 |  Loss: (0.3812) |  Loss2: (0.0000) | Acc: (86.00%) (25696/29568)
Epoch: 54 | Batch_idx: 240 |  Loss: (0.3801) |  Loss2: (0.0000) | Acc: (86.00%) (26826/30848)
Epoch: 54 | Batch_idx: 250 |  Loss: (0.3805) |  Loss2: (0.0000) | Acc: (86.00%) (27946/32128)
Epoch: 54 | Batch_idx: 260 |  Loss: (0.3808) |  Loss2: (0.0000) | Acc: (86.00%) (29054/33408)
Epoch: 54 | Batch_idx: 270 |  Loss: (0.3796) |  Loss2: (0.0000) | Acc: (86.00%) (30177/34688)
Epoch: 54 | Batch_idx: 280 |  Loss: (0.3791) |  Loss2: (0.0000) | Acc: (87.00%) (31301/35968)
Epoch: 54 | Batch_idx: 290 |  Loss: (0.3784) |  Loss2: (0.0000) | Acc: (87.00%) (32422/37248)
Epoch: 54 | Batch_idx: 300 |  Loss: (0.3790) |  Loss2: (0.0000) | Acc: (87.00%) (33540/38528)
Epoch: 54 | Batch_idx: 310 |  Loss: (0.3768) |  Loss2: (0.0000) | Acc: (87.00%) (34684/39808)
Epoch: 54 | Batch_idx: 320 |  Loss: (0.3776) |  Loss2: (0.0000) | Acc: (87.00%) (35782/41088)
Epoch: 54 | Batch_idx: 330 |  Loss: (0.3774) |  Loss2: (0.0000) | Acc: (87.00%) (36893/42368)
Epoch: 54 | Batch_idx: 340 |  Loss: (0.3772) |  Loss2: (0.0000) | Acc: (87.00%) (38010/43648)
Epoch: 54 | Batch_idx: 350 |  Loss: (0.3784) |  Loss2: (0.0000) | Acc: (87.00%) (39108/44928)
Epoch: 54 | Batch_idx: 360 |  Loss: (0.3781) |  Loss2: (0.0000) | Acc: (87.00%) (40221/46208)
Epoch: 54 | Batch_idx: 370 |  Loss: (0.3780) |  Loss2: (0.0000) | Acc: (87.00%) (41331/47488)
Epoch: 54 | Batch_idx: 380 |  Loss: (0.3782) |  Loss2: (0.0000) | Acc: (87.00%) (42429/48768)
Epoch: 54 | Batch_idx: 390 |  Loss: (0.3787) |  Loss2: (0.0000) | Acc: (86.00%) (43499/50000)
# TEST : Loss: (0.4694) | Acc: (84.00%) (8455/10000)
percent tensor([0.5432, 0.5514, 0.5470, 0.5414, 0.5484, 0.5441, 0.5531, 0.5449, 0.5432,
        0.5488, 0.5470, 0.5510, 0.5469, 0.5431, 0.5504, 0.5449],
       device='cuda:0') torch.Size([16])
percent tensor([0.5039, 0.5040, 0.4988, 0.5030, 0.4974, 0.5071, 0.5007, 0.4981, 0.5000,
        0.5031, 0.5054, 0.5012, 0.5019, 0.5025, 0.5053, 0.5036],
       device='cuda:0') torch.Size([16])
percent tensor([0.4884, 0.3971, 0.6384, 0.5976, 0.6231, 0.5154, 0.5126, 0.6099, 0.5296,
        0.4726, 0.4196, 0.5915, 0.4210, 0.4312, 0.4572, 0.4992],
       device='cuda:0') torch.Size([16])
percent tensor([0.6683, 0.6991, 0.5916, 0.5980, 0.6002, 0.5894, 0.6735, 0.6170, 0.6560,
        0.6828, 0.6992, 0.6494, 0.6853, 0.6940, 0.6729, 0.6558],
       device='cuda:0') torch.Size([16])
percent tensor([0.6616, 0.5859, 0.6818, 0.6813, 0.6854, 0.6491, 0.6639, 0.6956, 0.6400,
        0.5905, 0.5798, 0.6335, 0.5851, 0.6494, 0.6515, 0.6751],
       device='cuda:0') torch.Size([16])
percent tensor([0.4600, 0.4810, 0.5856, 0.6249, 0.6320, 0.6527, 0.5087, 0.5010, 0.5313,
        0.4528, 0.4870, 0.5196, 0.4674, 0.5463, 0.4486, 0.5235],
       device='cuda:0') torch.Size([16])
percent tensor([0.6046, 0.6411, 0.6420, 0.6707, 0.6697, 0.6858, 0.6014, 0.5693, 0.6505,
        0.6420, 0.6613, 0.6325, 0.6047, 0.6753, 0.5769, 0.5788],
       device='cuda:0') torch.Size([16])
percent tensor([0.9996, 0.9981, 0.9992, 0.9994, 0.9996, 0.9989, 0.9993, 0.9997, 0.9982,
        0.9991, 0.9984, 0.9996, 0.9978, 0.9986, 0.9995, 0.9998],
       device='cuda:0') torch.Size([16])
Epoch: 55 | Batch_idx: 0 |  Loss: (0.3835) |  Loss2: (0.0000) | Acc: (88.00%) (113/128)
Epoch: 55 | Batch_idx: 10 |  Loss: (0.3407) |  Loss2: (0.0000) | Acc: (88.00%) (1252/1408)
Epoch: 55 | Batch_idx: 20 |  Loss: (0.3389) |  Loss2: (0.0000) | Acc: (89.00%) (2400/2688)
Epoch: 55 | Batch_idx: 30 |  Loss: (0.3400) |  Loss2: (0.0000) | Acc: (88.00%) (3527/3968)
Epoch: 55 | Batch_idx: 40 |  Loss: (0.3457) |  Loss2: (0.0000) | Acc: (88.00%) (4647/5248)
Epoch: 55 | Batch_idx: 50 |  Loss: (0.3455) |  Loss2: (0.0000) | Acc: (88.00%) (5769/6528)
Epoch: 55 | Batch_idx: 60 |  Loss: (0.3513) |  Loss2: (0.0000) | Acc: (88.00%) (6880/7808)
Epoch: 55 | Batch_idx: 70 |  Loss: (0.3521) |  Loss2: (0.0000) | Acc: (88.00%) (8000/9088)
Epoch: 55 | Batch_idx: 80 |  Loss: (0.3564) |  Loss2: (0.0000) | Acc: (87.00%) (9116/10368)
Epoch: 55 | Batch_idx: 90 |  Loss: (0.3590) |  Loss2: (0.0000) | Acc: (87.00%) (10235/11648)
Epoch: 55 | Batch_idx: 100 |  Loss: (0.3635) |  Loss2: (0.0000) | Acc: (87.00%) (11346/12928)
Epoch: 55 | Batch_idx: 110 |  Loss: (0.3646) |  Loss2: (0.0000) | Acc: (87.00%) (12451/14208)
Epoch: 55 | Batch_idx: 120 |  Loss: (0.3618) |  Loss2: (0.0000) | Acc: (87.00%) (13590/15488)
Epoch: 55 | Batch_idx: 130 |  Loss: (0.3606) |  Loss2: (0.0000) | Acc: (87.00%) (14717/16768)
Epoch: 55 | Batch_idx: 140 |  Loss: (0.3583) |  Loss2: (0.0000) | Acc: (87.00%) (15853/18048)
Epoch: 55 | Batch_idx: 150 |  Loss: (0.3579) |  Loss2: (0.0000) | Acc: (87.00%) (16984/19328)
Epoch: 55 | Batch_idx: 160 |  Loss: (0.3581) |  Loss2: (0.0000) | Acc: (87.00%) (18112/20608)
Epoch: 55 | Batch_idx: 170 |  Loss: (0.3587) |  Loss2: (0.0000) | Acc: (87.00%) (19220/21888)
Epoch: 55 | Batch_idx: 180 |  Loss: (0.3599) |  Loss2: (0.0000) | Acc: (87.00%) (20325/23168)
Epoch: 55 | Batch_idx: 190 |  Loss: (0.3609) |  Loss2: (0.0000) | Acc: (87.00%) (21438/24448)
Epoch: 55 | Batch_idx: 200 |  Loss: (0.3617) |  Loss2: (0.0000) | Acc: (87.00%) (22551/25728)
Epoch: 55 | Batch_idx: 210 |  Loss: (0.3615) |  Loss2: (0.0000) | Acc: (87.00%) (23674/27008)
Epoch: 55 | Batch_idx: 220 |  Loss: (0.3608) |  Loss2: (0.0000) | Acc: (87.00%) (24792/28288)
Epoch: 55 | Batch_idx: 230 |  Loss: (0.3615) |  Loss2: (0.0000) | Acc: (87.00%) (25901/29568)
Epoch: 55 | Batch_idx: 240 |  Loss: (0.3633) |  Loss2: (0.0000) | Acc: (87.00%) (27000/30848)
Epoch: 55 | Batch_idx: 250 |  Loss: (0.3615) |  Loss2: (0.0000) | Acc: (87.00%) (28134/32128)
Epoch: 55 | Batch_idx: 260 |  Loss: (0.3612) |  Loss2: (0.0000) | Acc: (87.00%) (29257/33408)
Epoch: 55 | Batch_idx: 270 |  Loss: (0.3624) |  Loss2: (0.0000) | Acc: (87.00%) (30366/34688)
Epoch: 55 | Batch_idx: 280 |  Loss: (0.3621) |  Loss2: (0.0000) | Acc: (87.00%) (31491/35968)
Epoch: 55 | Batch_idx: 290 |  Loss: (0.3618) |  Loss2: (0.0000) | Acc: (87.00%) (32620/37248)
Epoch: 55 | Batch_idx: 300 |  Loss: (0.3631) |  Loss2: (0.0000) | Acc: (87.00%) (33728/38528)
Epoch: 55 | Batch_idx: 310 |  Loss: (0.3627) |  Loss2: (0.0000) | Acc: (87.00%) (34849/39808)
Epoch: 55 | Batch_idx: 320 |  Loss: (0.3624) |  Loss2: (0.0000) | Acc: (87.00%) (35967/41088)
Epoch: 55 | Batch_idx: 330 |  Loss: (0.3626) |  Loss2: (0.0000) | Acc: (87.00%) (37097/42368)
Epoch: 55 | Batch_idx: 340 |  Loss: (0.3626) |  Loss2: (0.0000) | Acc: (87.00%) (38218/43648)
Epoch: 55 | Batch_idx: 350 |  Loss: (0.3630) |  Loss2: (0.0000) | Acc: (87.00%) (39330/44928)
Epoch: 55 | Batch_idx: 360 |  Loss: (0.3632) |  Loss2: (0.0000) | Acc: (87.00%) (40447/46208)
Epoch: 55 | Batch_idx: 370 |  Loss: (0.3632) |  Loss2: (0.0000) | Acc: (87.00%) (41559/47488)
Epoch: 55 | Batch_idx: 380 |  Loss: (0.3632) |  Loss2: (0.0000) | Acc: (87.00%) (42690/48768)
Epoch: 55 | Batch_idx: 390 |  Loss: (0.3631) |  Loss2: (0.0000) | Acc: (87.00%) (43767/50000)
=> saving checkpoint 'drive/app/torch/save_Schedule/checkpoint_055.pth.tar'
# TEST : Loss: (0.4588) | Acc: (84.00%) (8482/10000)
percent tensor([0.5426, 0.5518, 0.5435, 0.5415, 0.5465, 0.5432, 0.5528, 0.5440, 0.5430,
        0.5480, 0.5471, 0.5487, 0.5467, 0.5445, 0.5504, 0.5452],
       device='cuda:0') torch.Size([16])
percent tensor([0.5037, 0.5031, 0.4991, 0.5027, 0.4980, 0.5076, 0.5002, 0.4978, 0.5001,
        0.5025, 0.5052, 0.5018, 0.5018, 0.5008, 0.5050, 0.5031],
       device='cuda:0') torch.Size([16])
percent tensor([0.4831, 0.3978, 0.6233, 0.6094, 0.6143, 0.5172, 0.4959, 0.5985, 0.5189,
        0.4614, 0.4126, 0.5596, 0.4061, 0.4340, 0.4579, 0.5034],
       device='cuda:0') torch.Size([16])
percent tensor([0.6619, 0.6897, 0.5835, 0.5997, 0.5960, 0.5871, 0.6677, 0.6100, 0.6527,
        0.6782, 0.6960, 0.6456, 0.6846, 0.6873, 0.6687, 0.6519],
       device='cuda:0') torch.Size([16])
percent tensor([0.6656, 0.5951, 0.6769, 0.6870, 0.6838, 0.6550, 0.6567, 0.6867, 0.6454,
        0.5968, 0.5939, 0.6317, 0.5906, 0.6397, 0.6556, 0.6783],
       device='cuda:0') torch.Size([16])
percent tensor([0.4715, 0.4988, 0.5872, 0.6205, 0.6375, 0.6531, 0.5130, 0.5296, 0.5495,
        0.4703, 0.4934, 0.5312, 0.4641, 0.5515, 0.4571, 0.5244],
       device='cuda:0') torch.Size([16])
percent tensor([0.6074, 0.6404, 0.6538, 0.6779, 0.6731, 0.6880, 0.6298, 0.5851, 0.6521,
        0.6506, 0.6591, 0.6424, 0.6177, 0.6764, 0.5838, 0.5875],
       device='cuda:0') torch.Size([16])
percent tensor([0.9997, 0.9982, 0.9985, 0.9991, 0.9994, 0.9970, 0.9993, 0.9996, 0.9981,
        0.9987, 0.9977, 0.9994, 0.9982, 0.9987, 0.9996, 0.9997],
       device='cuda:0') torch.Size([16])
Epoch: 56 | Batch_idx: 0 |  Loss: (0.4324) |  Loss2: (0.0000) | Acc: (82.00%) (105/128)
Epoch: 56 | Batch_idx: 10 |  Loss: (0.3400) |  Loss2: (0.0000) | Acc: (87.00%) (1235/1408)
Epoch: 56 | Batch_idx: 20 |  Loss: (0.3443) |  Loss2: (0.0000) | Acc: (88.00%) (2367/2688)
Epoch: 56 | Batch_idx: 30 |  Loss: (0.3410) |  Loss2: (0.0000) | Acc: (88.00%) (3500/3968)
Epoch: 56 | Batch_idx: 40 |  Loss: (0.3487) |  Loss2: (0.0000) | Acc: (87.00%) (4609/5248)
Epoch: 56 | Batch_idx: 50 |  Loss: (0.3474) |  Loss2: (0.0000) | Acc: (87.00%) (5742/6528)
Epoch: 56 | Batch_idx: 60 |  Loss: (0.3460) |  Loss2: (0.0000) | Acc: (88.00%) (6872/7808)
Epoch: 56 | Batch_idx: 70 |  Loss: (0.3505) |  Loss2: (0.0000) | Acc: (87.00%) (7980/9088)
Epoch: 56 | Batch_idx: 80 |  Loss: (0.3493) |  Loss2: (0.0000) | Acc: (87.00%) (9110/10368)
Epoch: 56 | Batch_idx: 90 |  Loss: (0.3478) |  Loss2: (0.0000) | Acc: (87.00%) (10240/11648)
Epoch: 56 | Batch_idx: 100 |  Loss: (0.3495) |  Loss2: (0.0000) | Acc: (87.00%) (11359/12928)
Epoch: 56 | Batch_idx: 110 |  Loss: (0.3491) |  Loss2: (0.0000) | Acc: (87.00%) (12483/14208)
Epoch: 56 | Batch_idx: 120 |  Loss: (0.3473) |  Loss2: (0.0000) | Acc: (88.00%) (13633/15488)
Epoch: 56 | Batch_idx: 130 |  Loss: (0.3471) |  Loss2: (0.0000) | Acc: (88.00%) (14765/16768)
Epoch: 56 | Batch_idx: 140 |  Loss: (0.3456) |  Loss2: (0.0000) | Acc: (88.00%) (15906/18048)
Epoch: 56 | Batch_idx: 150 |  Loss: (0.3443) |  Loss2: (0.0000) | Acc: (88.00%) (17037/19328)
Epoch: 56 | Batch_idx: 160 |  Loss: (0.3466) |  Loss2: (0.0000) | Acc: (88.00%) (18146/20608)
Epoch: 56 | Batch_idx: 170 |  Loss: (0.3466) |  Loss2: (0.0000) | Acc: (88.00%) (19278/21888)
Epoch: 56 | Batch_idx: 180 |  Loss: (0.3478) |  Loss2: (0.0000) | Acc: (87.00%) (20387/23168)
Epoch: 56 | Batch_idx: 190 |  Loss: (0.3490) |  Loss2: (0.0000) | Acc: (87.00%) (21502/24448)
Epoch: 56 | Batch_idx: 200 |  Loss: (0.3494) |  Loss2: (0.0000) | Acc: (87.00%) (22626/25728)
Epoch: 56 | Batch_idx: 210 |  Loss: (0.3495) |  Loss2: (0.0000) | Acc: (87.00%) (23749/27008)
Epoch: 56 | Batch_idx: 220 |  Loss: (0.3495) |  Loss2: (0.0000) | Acc: (87.00%) (24872/28288)
Epoch: 56 | Batch_idx: 230 |  Loss: (0.3508) |  Loss2: (0.0000) | Acc: (87.00%) (25983/29568)
Epoch: 56 | Batch_idx: 240 |  Loss: (0.3501) |  Loss2: (0.0000) | Acc: (87.00%) (27120/30848)
Epoch: 56 | Batch_idx: 250 |  Loss: (0.3509) |  Loss2: (0.0000) | Acc: (87.00%) (28229/32128)
Epoch: 56 | Batch_idx: 260 |  Loss: (0.3511) |  Loss2: (0.0000) | Acc: (87.00%) (29345/33408)
Epoch: 56 | Batch_idx: 270 |  Loss: (0.3508) |  Loss2: (0.0000) | Acc: (87.00%) (30477/34688)
Epoch: 56 | Batch_idx: 280 |  Loss: (0.3510) |  Loss2: (0.0000) | Acc: (87.00%) (31600/35968)
Epoch: 56 | Batch_idx: 290 |  Loss: (0.3507) |  Loss2: (0.0000) | Acc: (87.00%) (32727/37248)
Epoch: 56 | Batch_idx: 300 |  Loss: (0.3512) |  Loss2: (0.0000) | Acc: (87.00%) (33852/38528)
Epoch: 56 | Batch_idx: 310 |  Loss: (0.3522) |  Loss2: (0.0000) | Acc: (87.00%) (34964/39808)
Epoch: 56 | Batch_idx: 320 |  Loss: (0.3522) |  Loss2: (0.0000) | Acc: (87.00%) (36098/41088)
Epoch: 56 | Batch_idx: 330 |  Loss: (0.3529) |  Loss2: (0.0000) | Acc: (87.00%) (37218/42368)
Epoch: 56 | Batch_idx: 340 |  Loss: (0.3526) |  Loss2: (0.0000) | Acc: (87.00%) (38339/43648)
Epoch: 56 | Batch_idx: 350 |  Loss: (0.3533) |  Loss2: (0.0000) | Acc: (87.00%) (39450/44928)
Epoch: 56 | Batch_idx: 360 |  Loss: (0.3538) |  Loss2: (0.0000) | Acc: (87.00%) (40556/46208)
Epoch: 56 | Batch_idx: 370 |  Loss: (0.3534) |  Loss2: (0.0000) | Acc: (87.00%) (41687/47488)
Epoch: 56 | Batch_idx: 380 |  Loss: (0.3537) |  Loss2: (0.0000) | Acc: (87.00%) (42799/48768)
Epoch: 56 | Batch_idx: 390 |  Loss: (0.3552) |  Loss2: (0.0000) | Acc: (87.00%) (43855/50000)
# TEST : Loss: (0.4948) | Acc: (83.00%) (8354/10000)
percent tensor([0.5428, 0.5508, 0.5466, 0.5416, 0.5477, 0.5431, 0.5523, 0.5445, 0.5424,
        0.5482, 0.5467, 0.5500, 0.5464, 0.5422, 0.5499, 0.5446],
       device='cuda:0') torch.Size([16])
percent tensor([0.5038, 0.5035, 0.4991, 0.5031, 0.4977, 0.5076, 0.5004, 0.4979, 0.5001,
        0.5027, 0.5051, 0.5016, 0.5017, 0.5017, 0.5053, 0.5036],
       device='cuda:0') torch.Size([16])
percent tensor([0.4919, 0.4178, 0.6216, 0.5957, 0.6117, 0.5155, 0.5194, 0.6060, 0.5403,
        0.4741, 0.4284, 0.5759, 0.4270, 0.4845, 0.4594, 0.5118],
       device='cuda:0') torch.Size([16])
percent tensor([0.6664, 0.6887, 0.5880, 0.6011, 0.6009, 0.5930, 0.6650, 0.6131, 0.6510,
        0.6779, 0.6954, 0.6439, 0.6802, 0.6770, 0.6705, 0.6514],
       device='cuda:0') torch.Size([16])
percent tensor([0.6614, 0.6001, 0.6772, 0.6845, 0.6845, 0.6456, 0.6654, 0.6934, 0.6413,
        0.5961, 0.5811, 0.6392, 0.5853, 0.6613, 0.6498, 0.6762],
       device='cuda:0') torch.Size([16])
percent tensor([0.4708, 0.5052, 0.5943, 0.6258, 0.6342, 0.6445, 0.5275, 0.5078, 0.5594,
        0.4933, 0.5035, 0.5464, 0.4879, 0.5605, 0.4537, 0.5453],
       device='cuda:0') torch.Size([16])
percent tensor([0.5987, 0.6382, 0.6348, 0.6643, 0.6530, 0.6776, 0.6175, 0.5689, 0.6686,
        0.6452, 0.6738, 0.6336, 0.6182, 0.6733, 0.5735, 0.5734],
       device='cuda:0') torch.Size([16])
percent tensor([0.9996, 0.9987, 0.9995, 0.9995, 0.9994, 0.9972, 0.9994, 0.9998, 0.9983,
        0.9989, 0.9987, 0.9995, 0.9979, 0.9988, 0.9995, 0.9996],
       device='cuda:0') torch.Size([16])
False Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=128, out_features=16, bias=False)
True Linear(in_features=16, out_features=2, bias=False)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=128, out_features=16, bias=False)
True Linear(in_features=16, out_features=2, bias=False)
False Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=256, out_features=32, bias=False)
True Linear(in_features=32, out_features=2, bias=False)
False Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=256, out_features=32, bias=False)
True Linear(in_features=32, out_features=2, bias=False)
False Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=512, out_features=64, bias=False)
True Linear(in_features=64, out_features=2, bias=False)
False Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=512, out_features=64, bias=False)
True Linear(in_features=64, out_features=2, bias=False)
False Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1024, out_features=128, bias=False)
True Linear(in_features=128, out_features=2, bias=False)
False Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1024, out_features=128, bias=False)
True Linear(in_features=128, out_features=2, bias=False)
False Linear(in_features=512, out_features=10, bias=True)
Epoch: 57 | Batch_idx: 0 |  Loss: (0.2928) |  Loss2: (0.0000) | Acc: (86.00%) (111/128)
Epoch: 57 | Batch_idx: 10 |  Loss: (0.3853) |  Loss2: (0.0000) | Acc: (85.00%) (1204/1408)
Epoch: 57 | Batch_idx: 20 |  Loss: (0.3959) |  Loss2: (0.0000) | Acc: (85.00%) (2294/2688)
Epoch: 57 | Batch_idx: 30 |  Loss: (0.4098) |  Loss2: (0.0000) | Acc: (85.00%) (3375/3968)
Epoch: 57 | Batch_idx: 40 |  Loss: (0.4039) |  Loss2: (0.0000) | Acc: (85.00%) (4479/5248)
Epoch: 57 | Batch_idx: 50 |  Loss: (0.4141) |  Loss2: (0.0000) | Acc: (85.00%) (5560/6528)
Epoch: 57 | Batch_idx: 60 |  Loss: (0.4110) |  Loss2: (0.0000) | Acc: (85.00%) (6671/7808)
Epoch: 57 | Batch_idx: 70 |  Loss: (0.4138) |  Loss2: (0.0000) | Acc: (85.00%) (7772/9088)
Epoch: 57 | Batch_idx: 80 |  Loss: (0.4151) |  Loss2: (0.0000) | Acc: (85.00%) (8858/10368)
Epoch: 57 | Batch_idx: 90 |  Loss: (0.4124) |  Loss2: (0.0000) | Acc: (85.00%) (9974/11648)
Epoch: 57 | Batch_idx: 100 |  Loss: (0.4132) |  Loss2: (0.0000) | Acc: (85.00%) (11068/12928)
Epoch: 57 | Batch_idx: 110 |  Loss: (0.4151) |  Loss2: (0.0000) | Acc: (85.00%) (12151/14208)
Epoch: 57 | Batch_idx: 120 |  Loss: (0.4194) |  Loss2: (0.0000) | Acc: (85.00%) (13217/15488)
Epoch: 57 | Batch_idx: 130 |  Loss: (0.4194) |  Loss2: (0.0000) | Acc: (85.00%) (14309/16768)
Epoch: 57 | Batch_idx: 140 |  Loss: (0.4182) |  Loss2: (0.0000) | Acc: (85.00%) (15412/18048)
Epoch: 57 | Batch_idx: 150 |  Loss: (0.4161) |  Loss2: (0.0000) | Acc: (85.00%) (16531/19328)
Epoch: 57 | Batch_idx: 160 |  Loss: (0.4151) |  Loss2: (0.0000) | Acc: (85.00%) (17651/20608)
Epoch: 57 | Batch_idx: 170 |  Loss: (0.4140) |  Loss2: (0.0000) | Acc: (85.00%) (18757/21888)
Epoch: 57 | Batch_idx: 180 |  Loss: (0.4147) |  Loss2: (0.0000) | Acc: (85.00%) (19857/23168)
Epoch: 57 | Batch_idx: 190 |  Loss: (0.4129) |  Loss2: (0.0000) | Acc: (85.00%) (20956/24448)
Epoch: 57 | Batch_idx: 200 |  Loss: (0.4123) |  Loss2: (0.0000) | Acc: (85.00%) (22047/25728)
Epoch: 57 | Batch_idx: 210 |  Loss: (0.4114) |  Loss2: (0.0000) | Acc: (85.00%) (23156/27008)
Epoch: 57 | Batch_idx: 220 |  Loss: (0.4094) |  Loss2: (0.0000) | Acc: (85.00%) (24278/28288)
Epoch: 57 | Batch_idx: 230 |  Loss: (0.4083) |  Loss2: (0.0000) | Acc: (85.00%) (25389/29568)
Epoch: 57 | Batch_idx: 240 |  Loss: (0.4083) |  Loss2: (0.0000) | Acc: (85.00%) (26489/30848)
Epoch: 57 | Batch_idx: 250 |  Loss: (0.4076) |  Loss2: (0.0000) | Acc: (85.00%) (27594/32128)
Epoch: 57 | Batch_idx: 260 |  Loss: (0.4071) |  Loss2: (0.0000) | Acc: (85.00%) (28688/33408)
Epoch: 57 | Batch_idx: 270 |  Loss: (0.4073) |  Loss2: (0.0000) | Acc: (85.00%) (29794/34688)
Epoch: 57 | Batch_idx: 280 |  Loss: (0.4076) |  Loss2: (0.0000) | Acc: (85.00%) (30886/35968)
Epoch: 57 | Batch_idx: 290 |  Loss: (0.4081) |  Loss2: (0.0000) | Acc: (85.00%) (31981/37248)
Epoch: 57 | Batch_idx: 300 |  Loss: (0.4089) |  Loss2: (0.0000) | Acc: (85.00%) (33076/38528)
Epoch: 57 | Batch_idx: 310 |  Loss: (0.4083) |  Loss2: (0.0000) | Acc: (85.00%) (34189/39808)
Epoch: 57 | Batch_idx: 320 |  Loss: (0.4084) |  Loss2: (0.0000) | Acc: (85.00%) (35287/41088)
Epoch: 57 | Batch_idx: 330 |  Loss: (0.4085) |  Loss2: (0.0000) | Acc: (85.00%) (36377/42368)
Epoch: 57 | Batch_idx: 340 |  Loss: (0.4081) |  Loss2: (0.0000) | Acc: (85.00%) (37478/43648)
Epoch: 57 | Batch_idx: 350 |  Loss: (0.4076) |  Loss2: (0.0000) | Acc: (85.00%) (38591/44928)
Epoch: 57 | Batch_idx: 360 |  Loss: (0.4070) |  Loss2: (0.0000) | Acc: (85.00%) (39700/46208)
Epoch: 57 | Batch_idx: 370 |  Loss: (0.4077) |  Loss2: (0.0000) | Acc: (85.00%) (40781/47488)
Epoch: 57 | Batch_idx: 380 |  Loss: (0.4069) |  Loss2: (0.0000) | Acc: (85.00%) (41889/48768)
Epoch: 57 | Batch_idx: 390 |  Loss: (0.4063) |  Loss2: (0.0000) | Acc: (85.00%) (42967/50000)
# TEST : Loss: (0.4694) | Acc: (84.00%) (8425/10000)
percent tensor([0.5324, 0.5378, 0.5375, 0.5322, 0.5379, 0.5332, 0.5402, 0.5336, 0.5318,
        0.5370, 0.5349, 0.5400, 0.5348, 0.5309, 0.5377, 0.5339],
       device='cuda:0') torch.Size([16])
percent tensor([0.5071, 0.5065, 0.5046, 0.5057, 0.5033, 0.5105, 0.5045, 0.5024, 0.5042,
        0.5059, 0.5081, 0.5055, 0.5048, 0.5041, 0.5089, 0.5064],
       device='cuda:0') torch.Size([16])
percent tensor([0.4494, 0.3905, 0.5736, 0.5944, 0.5726, 0.4994, 0.4766, 0.5926, 0.4976,
        0.4312, 0.3869, 0.4977, 0.3886, 0.4868, 0.4270, 0.4900],
       device='cuda:0') torch.Size([16])
percent tensor([0.6422, 0.6596, 0.5844, 0.5828, 0.5958, 0.5793, 0.6433, 0.5911, 0.6371,
        0.6511, 0.6682, 0.6344, 0.6526, 0.6521, 0.6422, 0.6253],
       device='cuda:0') torch.Size([16])
percent tensor([0.6241, 0.5537, 0.6485, 0.6728, 0.6684, 0.6348, 0.6277, 0.6750, 0.6111,
        0.5552, 0.5439, 0.6003, 0.5333, 0.6278, 0.6154, 0.6456],
       device='cuda:0') torch.Size([16])
percent tensor([0.4733, 0.4962, 0.5963, 0.6426, 0.6440, 0.6530, 0.5306, 0.5304, 0.5517,
        0.4979, 0.4872, 0.5329, 0.4861, 0.5423, 0.4654, 0.5548],
       device='cuda:0') torch.Size([16])
percent tensor([0.6210, 0.6507, 0.6496, 0.6735, 0.6454, 0.6962, 0.6262, 0.5753, 0.6800,
        0.6563, 0.6790, 0.6270, 0.6399, 0.6804, 0.5917, 0.5925],
       device='cuda:0') torch.Size([16])
percent tensor([0.9994, 0.9989, 0.9997, 0.9995, 0.9995, 0.9984, 0.9990, 0.9997, 0.9985,
        0.9985, 0.9983, 0.9995, 0.9979, 0.9988, 0.9993, 0.9994],
       device='cuda:0') torch.Size([16])
Epoch: 58 | Batch_idx: 0 |  Loss: (0.2976) |  Loss2: (0.0000) | Acc: (87.00%) (112/128)
Epoch: 58 | Batch_idx: 10 |  Loss: (0.3855) |  Loss2: (0.0000) | Acc: (86.00%) (1214/1408)
Epoch: 58 | Batch_idx: 20 |  Loss: (0.3870) |  Loss2: (0.0000) | Acc: (86.00%) (2314/2688)
Epoch: 58 | Batch_idx: 30 |  Loss: (0.3952) |  Loss2: (0.0000) | Acc: (86.00%) (3415/3968)
Epoch: 58 | Batch_idx: 40 |  Loss: (0.3939) |  Loss2: (0.0000) | Acc: (86.00%) (4524/5248)
Epoch: 58 | Batch_idx: 50 |  Loss: (0.3958) |  Loss2: (0.0000) | Acc: (86.00%) (5624/6528)
Epoch: 58 | Batch_idx: 60 |  Loss: (0.3906) |  Loss2: (0.0000) | Acc: (86.00%) (6754/7808)
Epoch: 58 | Batch_idx: 70 |  Loss: (0.3867) |  Loss2: (0.0000) | Acc: (86.00%) (7880/9088)
Epoch: 58 | Batch_idx: 80 |  Loss: (0.3889) |  Loss2: (0.0000) | Acc: (86.00%) (8979/10368)
Epoch: 58 | Batch_idx: 90 |  Loss: (0.3891) |  Loss2: (0.0000) | Acc: (86.00%) (10076/11648)
Epoch: 58 | Batch_idx: 100 |  Loss: (0.3862) |  Loss2: (0.0000) | Acc: (86.00%) (11199/12928)
Epoch: 58 | Batch_idx: 110 |  Loss: (0.3823) |  Loss2: (0.0000) | Acc: (86.00%) (12326/14208)
Epoch: 58 | Batch_idx: 120 |  Loss: (0.3813) |  Loss2: (0.0000) | Acc: (86.00%) (13447/15488)
Epoch: 58 | Batch_idx: 130 |  Loss: (0.3824) |  Loss2: (0.0000) | Acc: (86.00%) (14561/16768)
Epoch: 58 | Batch_idx: 140 |  Loss: (0.3809) |  Loss2: (0.0000) | Acc: (86.00%) (15688/18048)
Epoch: 58 | Batch_idx: 150 |  Loss: (0.3807) |  Loss2: (0.0000) | Acc: (86.00%) (16791/19328)
Epoch: 58 | Batch_idx: 160 |  Loss: (0.3804) |  Loss2: (0.0000) | Acc: (86.00%) (17896/20608)
Epoch: 58 | Batch_idx: 170 |  Loss: (0.3800) |  Loss2: (0.0000) | Acc: (86.00%) (19003/21888)
Epoch: 58 | Batch_idx: 180 |  Loss: (0.3795) |  Loss2: (0.0000) | Acc: (86.00%) (20117/23168)
Epoch: 58 | Batch_idx: 190 |  Loss: (0.3771) |  Loss2: (0.0000) | Acc: (86.00%) (21262/24448)
Epoch: 58 | Batch_idx: 200 |  Loss: (0.3756) |  Loss2: (0.0000) | Acc: (87.00%) (22398/25728)
Epoch: 58 | Batch_idx: 210 |  Loss: (0.3744) |  Loss2: (0.0000) | Acc: (87.00%) (23532/27008)
Epoch: 58 | Batch_idx: 220 |  Loss: (0.3746) |  Loss2: (0.0000) | Acc: (87.00%) (24647/28288)
Epoch: 58 | Batch_idx: 230 |  Loss: (0.3745) |  Loss2: (0.0000) | Acc: (87.00%) (25763/29568)
Epoch: 58 | Batch_idx: 240 |  Loss: (0.3759) |  Loss2: (0.0000) | Acc: (87.00%) (26863/30848)
Epoch: 58 | Batch_idx: 250 |  Loss: (0.3759) |  Loss2: (0.0000) | Acc: (87.00%) (27979/32128)
Epoch: 58 | Batch_idx: 260 |  Loss: (0.3769) |  Loss2: (0.0000) | Acc: (87.00%) (29086/33408)
Epoch: 58 | Batch_idx: 270 |  Loss: (0.3780) |  Loss2: (0.0000) | Acc: (87.00%) (30180/34688)
Epoch: 58 | Batch_idx: 280 |  Loss: (0.3779) |  Loss2: (0.0000) | Acc: (86.00%) (31291/35968)
Epoch: 58 | Batch_idx: 290 |  Loss: (0.3771) |  Loss2: (0.0000) | Acc: (87.00%) (32415/37248)
Epoch: 58 | Batch_idx: 300 |  Loss: (0.3769) |  Loss2: (0.0000) | Acc: (87.00%) (33527/38528)
Epoch: 58 | Batch_idx: 310 |  Loss: (0.3756) |  Loss2: (0.0000) | Acc: (87.00%) (34655/39808)
Epoch: 58 | Batch_idx: 320 |  Loss: (0.3744) |  Loss2: (0.0000) | Acc: (87.00%) (35783/41088)
Epoch: 58 | Batch_idx: 330 |  Loss: (0.3741) |  Loss2: (0.0000) | Acc: (87.00%) (36907/42368)
Epoch: 58 | Batch_idx: 340 |  Loss: (0.3745) |  Loss2: (0.0000) | Acc: (87.00%) (38004/43648)
Epoch: 58 | Batch_idx: 350 |  Loss: (0.3741) |  Loss2: (0.0000) | Acc: (87.00%) (39134/44928)
Epoch: 58 | Batch_idx: 360 |  Loss: (0.3741) |  Loss2: (0.0000) | Acc: (87.00%) (40250/46208)
Epoch: 58 | Batch_idx: 370 |  Loss: (0.3737) |  Loss2: (0.0000) | Acc: (87.00%) (41372/47488)
Epoch: 58 | Batch_idx: 380 |  Loss: (0.3728) |  Loss2: (0.0000) | Acc: (87.00%) (42500/48768)
Epoch: 58 | Batch_idx: 390 |  Loss: (0.3732) |  Loss2: (0.0000) | Acc: (87.00%) (43576/50000)
# TEST : Loss: (0.4490) | Acc: (84.00%) (8488/10000)
percent tensor([0.5292, 0.5345, 0.5341, 0.5290, 0.5343, 0.5296, 0.5366, 0.5304, 0.5287,
        0.5338, 0.5315, 0.5364, 0.5313, 0.5285, 0.5341, 0.5306],
       device='cuda:0') torch.Size([16])
percent tensor([0.5076, 0.5075, 0.5051, 0.5065, 0.5039, 0.5112, 0.5053, 0.5032, 0.5050,
        0.5068, 0.5090, 0.5062, 0.5056, 0.5046, 0.5097, 0.5070],
       device='cuda:0') torch.Size([16])
percent tensor([0.4547, 0.3944, 0.5894, 0.6050, 0.5822, 0.5161, 0.4774, 0.6006, 0.5062,
        0.4388, 0.3902, 0.5092, 0.3974, 0.4880, 0.4316, 0.4987],
       device='cuda:0') torch.Size([16])
percent tensor([0.6503, 0.6676, 0.5916, 0.5913, 0.6039, 0.5881, 0.6509, 0.6000, 0.6461,
        0.6587, 0.6766, 0.6421, 0.6608, 0.6604, 0.6509, 0.6348],
       device='cuda:0') torch.Size([16])
percent tensor([0.6318, 0.5581, 0.6568, 0.6804, 0.6795, 0.6495, 0.6324, 0.6851, 0.6174,
        0.5578, 0.5457, 0.6040, 0.5374, 0.6309, 0.6236, 0.6562],
       device='cuda:0') torch.Size([16])
percent tensor([0.4951, 0.5149, 0.6202, 0.6632, 0.6707, 0.6681, 0.5571, 0.5609, 0.5695,
        0.5144, 0.5060, 0.5577, 0.5014, 0.5617, 0.4926, 0.5748],
       device='cuda:0') torch.Size([16])
percent tensor([0.6258, 0.6564, 0.6571, 0.6801, 0.6495, 0.7044, 0.6333, 0.5703, 0.6884,
        0.6605, 0.6897, 0.6439, 0.6555, 0.6903, 0.6000, 0.5952],
       device='cuda:0') torch.Size([16])
percent tensor([0.9995, 0.9989, 0.9997, 0.9995, 0.9996, 0.9985, 0.9991, 0.9998, 0.9986,
        0.9986, 0.9983, 0.9996, 0.9980, 0.9988, 0.9994, 0.9995],
       device='cuda:0') torch.Size([16])
Epoch: 59 | Batch_idx: 0 |  Loss: (0.3397) |  Loss2: (0.0000) | Acc: (89.00%) (115/128)
Epoch: 59 | Batch_idx: 10 |  Loss: (0.3600) |  Loss2: (0.0000) | Acc: (87.00%) (1237/1408)
Epoch: 59 | Batch_idx: 20 |  Loss: (0.3540) |  Loss2: (0.0000) | Acc: (88.00%) (2367/2688)
Epoch: 59 | Batch_idx: 30 |  Loss: (0.3415) |  Loss2: (0.0000) | Acc: (88.00%) (3509/3968)
Epoch: 59 | Batch_idx: 40 |  Loss: (0.3483) |  Loss2: (0.0000) | Acc: (88.00%) (4624/5248)
Epoch: 59 | Batch_idx: 50 |  Loss: (0.3542) |  Loss2: (0.0000) | Acc: (87.00%) (5729/6528)
Epoch: 59 | Batch_idx: 60 |  Loss: (0.3477) |  Loss2: (0.0000) | Acc: (88.00%) (6876/7808)
Epoch: 59 | Batch_idx: 70 |  Loss: (0.3521) |  Loss2: (0.0000) | Acc: (87.00%) (7989/9088)
Epoch: 59 | Batch_idx: 80 |  Loss: (0.3519) |  Loss2: (0.0000) | Acc: (87.00%) (9115/10368)
Epoch: 59 | Batch_idx: 90 |  Loss: (0.3526) |  Loss2: (0.0000) | Acc: (87.00%) (10242/11648)
Epoch: 59 | Batch_idx: 100 |  Loss: (0.3526) |  Loss2: (0.0000) | Acc: (87.00%) (11372/12928)
Epoch: 59 | Batch_idx: 110 |  Loss: (0.3520) |  Loss2: (0.0000) | Acc: (87.00%) (12486/14208)
Epoch: 59 | Batch_idx: 120 |  Loss: (0.3532) |  Loss2: (0.0000) | Acc: (87.00%) (13600/15488)
Epoch: 59 | Batch_idx: 130 |  Loss: (0.3546) |  Loss2: (0.0000) | Acc: (87.00%) (14697/16768)
Epoch: 59 | Batch_idx: 140 |  Loss: (0.3540) |  Loss2: (0.0000) | Acc: (87.00%) (15818/18048)
Epoch: 59 | Batch_idx: 150 |  Loss: (0.3535) |  Loss2: (0.0000) | Acc: (87.00%) (16957/19328)
Epoch: 59 | Batch_idx: 160 |  Loss: (0.3557) |  Loss2: (0.0000) | Acc: (87.00%) (18064/20608)
Epoch: 59 | Batch_idx: 170 |  Loss: (0.3575) |  Loss2: (0.0000) | Acc: (87.00%) (19170/21888)
Epoch: 59 | Batch_idx: 180 |  Loss: (0.3576) |  Loss2: (0.0000) | Acc: (87.00%) (20295/23168)
Epoch: 59 | Batch_idx: 190 |  Loss: (0.3574) |  Loss2: (0.0000) | Acc: (87.00%) (21421/24448)
Epoch: 59 | Batch_idx: 200 |  Loss: (0.3562) |  Loss2: (0.0000) | Acc: (87.00%) (22561/25728)
Epoch: 59 | Batch_idx: 210 |  Loss: (0.3572) |  Loss2: (0.0000) | Acc: (87.00%) (23668/27008)
Epoch: 59 | Batch_idx: 220 |  Loss: (0.3573) |  Loss2: (0.0000) | Acc: (87.00%) (24789/28288)
Epoch: 59 | Batch_idx: 230 |  Loss: (0.3573) |  Loss2: (0.0000) | Acc: (87.00%) (25909/29568)
Epoch: 59 | Batch_idx: 240 |  Loss: (0.3584) |  Loss2: (0.0000) | Acc: (87.00%) (27030/30848)
Epoch: 59 | Batch_idx: 250 |  Loss: (0.3577) |  Loss2: (0.0000) | Acc: (87.00%) (28171/32128)
Epoch: 59 | Batch_idx: 260 |  Loss: (0.3583) |  Loss2: (0.0000) | Acc: (87.00%) (29286/33408)
Epoch: 59 | Batch_idx: 270 |  Loss: (0.3577) |  Loss2: (0.0000) | Acc: (87.00%) (30416/34688)
Epoch: 59 | Batch_idx: 280 |  Loss: (0.3572) |  Loss2: (0.0000) | Acc: (87.00%) (31548/35968)
Epoch: 59 | Batch_idx: 290 |  Loss: (0.3568) |  Loss2: (0.0000) | Acc: (87.00%) (32688/37248)
Epoch: 59 | Batch_idx: 300 |  Loss: (0.3568) |  Loss2: (0.0000) | Acc: (87.00%) (33803/38528)
Epoch: 59 | Batch_idx: 310 |  Loss: (0.3577) |  Loss2: (0.0000) | Acc: (87.00%) (34897/39808)
Epoch: 59 | Batch_idx: 320 |  Loss: (0.3585) |  Loss2: (0.0000) | Acc: (87.00%) (36006/41088)
Epoch: 59 | Batch_idx: 330 |  Loss: (0.3585) |  Loss2: (0.0000) | Acc: (87.00%) (37138/42368)
Epoch: 59 | Batch_idx: 340 |  Loss: (0.3584) |  Loss2: (0.0000) | Acc: (87.00%) (38267/43648)
Epoch: 59 | Batch_idx: 350 |  Loss: (0.3591) |  Loss2: (0.0000) | Acc: (87.00%) (39371/44928)
Epoch: 59 | Batch_idx: 360 |  Loss: (0.3596) |  Loss2: (0.0000) | Acc: (87.00%) (40498/46208)
Epoch: 59 | Batch_idx: 370 |  Loss: (0.3594) |  Loss2: (0.0000) | Acc: (87.00%) (41626/47488)
Epoch: 59 | Batch_idx: 380 |  Loss: (0.3588) |  Loss2: (0.0000) | Acc: (87.00%) (42760/48768)
Epoch: 59 | Batch_idx: 390 |  Loss: (0.3591) |  Loss2: (0.0000) | Acc: (87.00%) (43830/50000)
# TEST : Loss: (0.4373) | Acc: (85.00%) (8531/10000)
percent tensor([0.5290, 0.5346, 0.5340, 0.5288, 0.5343, 0.5293, 0.5367, 0.5303, 0.5287,
        0.5338, 0.5315, 0.5365, 0.5313, 0.5284, 0.5340, 0.5305],
       device='cuda:0') torch.Size([16])
percent tensor([0.5078, 0.5081, 0.5052, 0.5069, 0.5040, 0.5114, 0.5058, 0.5034, 0.5054,
        0.5073, 0.5095, 0.5066, 0.5061, 0.5051, 0.5100, 0.5071],
       device='cuda:0') torch.Size([16])
percent tensor([0.4679, 0.4108, 0.6007, 0.6111, 0.5910, 0.5291, 0.4883, 0.6069, 0.5214,
        0.4564, 0.4048, 0.5243, 0.4186, 0.4979, 0.4432, 0.5134],
       device='cuda:0') torch.Size([16])
percent tensor([0.6543, 0.6727, 0.5954, 0.5963, 0.6086, 0.5937, 0.6558, 0.6044, 0.6505,
        0.6630, 0.6818, 0.6468, 0.6651, 0.6657, 0.6565, 0.6404],
       device='cuda:0') torch.Size([16])
percent tensor([0.6423, 0.5644, 0.6688, 0.6929, 0.6945, 0.6651, 0.6428, 0.7008, 0.6276,
        0.5622, 0.5492, 0.6127, 0.5416, 0.6387, 0.6361, 0.6696],
       device='cuda:0') torch.Size([16])
percent tensor([0.4866, 0.5045, 0.6167, 0.6585, 0.6676, 0.6659, 0.5533, 0.5565, 0.5649,
        0.5040, 0.5007, 0.5535, 0.4908, 0.5536, 0.4858, 0.5657],
       device='cuda:0') torch.Size([16])
percent tensor([0.6247, 0.6567, 0.6625, 0.6847, 0.6487, 0.7087, 0.6351, 0.5665, 0.6930,
        0.6629, 0.6973, 0.6562, 0.6640, 0.6955, 0.6024, 0.5917],
       device='cuda:0') torch.Size([16])
percent tensor([0.9995, 0.9989, 0.9997, 0.9995, 0.9997, 0.9985, 0.9991, 0.9998, 0.9987,
        0.9986, 0.9984, 0.9996, 0.9981, 0.9988, 0.9994, 0.9995],
       device='cuda:0') torch.Size([16])
True Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=128, out_features=16, bias=False)
False Linear(in_features=16, out_features=2, bias=False)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=128, out_features=16, bias=False)
False Linear(in_features=16, out_features=2, bias=False)
True Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=256, out_features=32, bias=False)
False Linear(in_features=32, out_features=2, bias=False)
True Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=256, out_features=32, bias=False)
False Linear(in_features=32, out_features=2, bias=False)
True Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=512, out_features=64, bias=False)
False Linear(in_features=64, out_features=2, bias=False)
True Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=512, out_features=64, bias=False)
False Linear(in_features=64, out_features=2, bias=False)
True Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1024, out_features=128, bias=False)
False Linear(in_features=128, out_features=2, bias=False)
True Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1024, out_features=128, bias=False)
False Linear(in_features=128, out_features=2, bias=False)
True Linear(in_features=512, out_features=10, bias=True)
Epoch: 60 | Batch_idx: 0 |  Loss: (0.3777) |  Loss2: (0.0000) | Acc: (88.00%) (113/128)
Epoch: 60 | Batch_idx: 10 |  Loss: (0.3568) |  Loss2: (0.0000) | Acc: (87.00%) (1237/1408)
Epoch: 60 | Batch_idx: 20 |  Loss: (0.3448) |  Loss2: (0.0000) | Acc: (87.00%) (2357/2688)
Epoch: 60 | Batch_idx: 30 |  Loss: (0.3341) |  Loss2: (0.0000) | Acc: (88.00%) (3505/3968)
Epoch: 60 | Batch_idx: 40 |  Loss: (0.3440) |  Loss2: (0.0000) | Acc: (88.00%) (4621/5248)
Epoch: 60 | Batch_idx: 50 |  Loss: (0.3479) |  Loss2: (0.0000) | Acc: (87.00%) (5739/6528)
Epoch: 60 | Batch_idx: 60 |  Loss: (0.3467) |  Loss2: (0.0000) | Acc: (87.00%) (6861/7808)
Epoch: 60 | Batch_idx: 70 |  Loss: (0.3454) |  Loss2: (0.0000) | Acc: (87.00%) (7986/9088)
Epoch: 60 | Batch_idx: 80 |  Loss: (0.3453) |  Loss2: (0.0000) | Acc: (87.00%) (9114/10368)
Epoch: 60 | Batch_idx: 90 |  Loss: (0.3459) |  Loss2: (0.0000) | Acc: (87.00%) (10246/11648)
Epoch: 60 | Batch_idx: 100 |  Loss: (0.3472) |  Loss2: (0.0000) | Acc: (87.00%) (11370/12928)
Epoch: 60 | Batch_idx: 110 |  Loss: (0.3471) |  Loss2: (0.0000) | Acc: (87.00%) (12492/14208)
Epoch: 60 | Batch_idx: 120 |  Loss: (0.3478) |  Loss2: (0.0000) | Acc: (87.00%) (13623/15488)
Epoch: 60 | Batch_idx: 130 |  Loss: (0.3463) |  Loss2: (0.0000) | Acc: (88.00%) (14759/16768)
Epoch: 60 | Batch_idx: 140 |  Loss: (0.3478) |  Loss2: (0.0000) | Acc: (88.00%) (15887/18048)
Epoch: 60 | Batch_idx: 150 |  Loss: (0.3490) |  Loss2: (0.0000) | Acc: (88.00%) (17012/19328)
Epoch: 60 | Batch_idx: 160 |  Loss: (0.3481) |  Loss2: (0.0000) | Acc: (88.00%) (18146/20608)
Epoch: 60 | Batch_idx: 170 |  Loss: (0.3479) |  Loss2: (0.0000) | Acc: (88.00%) (19273/21888)
Epoch: 60 | Batch_idx: 180 |  Loss: (0.3496) |  Loss2: (0.0000) | Acc: (88.00%) (20399/23168)
Epoch: 60 | Batch_idx: 190 |  Loss: (0.3493) |  Loss2: (0.0000) | Acc: (88.00%) (21538/24448)
Epoch: 60 | Batch_idx: 200 |  Loss: (0.3482) |  Loss2: (0.0000) | Acc: (88.00%) (22686/25728)
Epoch: 60 | Batch_idx: 210 |  Loss: (0.3489) |  Loss2: (0.0000) | Acc: (88.00%) (23816/27008)
Epoch: 60 | Batch_idx: 220 |  Loss: (0.3480) |  Loss2: (0.0000) | Acc: (88.00%) (24957/28288)
Epoch: 60 | Batch_idx: 230 |  Loss: (0.3485) |  Loss2: (0.0000) | Acc: (88.00%) (26067/29568)
Epoch: 60 | Batch_idx: 240 |  Loss: (0.3477) |  Loss2: (0.0000) | Acc: (88.00%) (27206/30848)
Epoch: 60 | Batch_idx: 250 |  Loss: (0.3475) |  Loss2: (0.0000) | Acc: (88.00%) (28338/32128)
Epoch: 60 | Batch_idx: 260 |  Loss: (0.3465) |  Loss2: (0.0000) | Acc: (88.00%) (29473/33408)
Epoch: 60 | Batch_idx: 270 |  Loss: (0.3463) |  Loss2: (0.0000) | Acc: (88.00%) (30606/34688)
Epoch: 60 | Batch_idx: 280 |  Loss: (0.3471) |  Loss2: (0.0000) | Acc: (88.00%) (31711/35968)
Epoch: 60 | Batch_idx: 290 |  Loss: (0.3477) |  Loss2: (0.0000) | Acc: (88.00%) (32842/37248)
Epoch: 60 | Batch_idx: 300 |  Loss: (0.3481) |  Loss2: (0.0000) | Acc: (88.00%) (33956/38528)
Epoch: 60 | Batch_idx: 310 |  Loss: (0.3476) |  Loss2: (0.0000) | Acc: (88.00%) (35085/39808)
Epoch: 60 | Batch_idx: 320 |  Loss: (0.3477) |  Loss2: (0.0000) | Acc: (88.00%) (36210/41088)
Epoch: 60 | Batch_idx: 330 |  Loss: (0.3472) |  Loss2: (0.0000) | Acc: (88.00%) (37349/42368)
Epoch: 60 | Batch_idx: 340 |  Loss: (0.3484) |  Loss2: (0.0000) | Acc: (88.00%) (38445/43648)
Epoch: 60 | Batch_idx: 350 |  Loss: (0.3474) |  Loss2: (0.0000) | Acc: (88.00%) (39584/44928)
Epoch: 60 | Batch_idx: 360 |  Loss: (0.3477) |  Loss2: (0.0000) | Acc: (88.00%) (40702/46208)
Epoch: 60 | Batch_idx: 370 |  Loss: (0.3477) |  Loss2: (0.0000) | Acc: (88.00%) (41820/47488)
Epoch: 60 | Batch_idx: 380 |  Loss: (0.3471) |  Loss2: (0.0000) | Acc: (88.00%) (42964/48768)
Epoch: 60 | Batch_idx: 390 |  Loss: (0.3471) |  Loss2: (0.0000) | Acc: (88.00%) (44045/50000)
=> saving checkpoint 'drive/app/torch/save_Schedule/checkpoint_060.pth.tar'
# TEST : Loss: (0.4754) | Acc: (83.00%) (8389/10000)
percent tensor([0.5283, 0.5342, 0.5309, 0.5282, 0.5317, 0.5283, 0.5356, 0.5293, 0.5278,
        0.5330, 0.5307, 0.5342, 0.5309, 0.5285, 0.5334, 0.5299],
       device='cuda:0') torch.Size([16])
percent tensor([0.5079, 0.5088, 0.5042, 0.5064, 0.5033, 0.5111, 0.5060, 0.5030, 0.5055,
        0.5079, 0.5096, 0.5065, 0.5065, 0.5057, 0.5097, 0.5070],
       device='cuda:0') torch.Size([16])
percent tensor([0.4718, 0.3891, 0.6257, 0.6084, 0.6127, 0.5243, 0.4793, 0.6067, 0.5319,
        0.4589, 0.4018, 0.5573, 0.4136, 0.4586, 0.4368, 0.5062],
       device='cuda:0') torch.Size([16])
percent tensor([0.6575, 0.6834, 0.5872, 0.5978, 0.5992, 0.5914, 0.6597, 0.6107, 0.6525,
        0.6703, 0.6908, 0.6404, 0.6739, 0.6779, 0.6628, 0.6469],
       device='cuda:0') torch.Size([16])
percent tensor([0.6452, 0.5646, 0.6711, 0.6834, 0.6874, 0.6719, 0.6407, 0.6934, 0.6241,
        0.5599, 0.5547, 0.6134, 0.5423, 0.6302, 0.6412, 0.6618],
       device='cuda:0') torch.Size([16])
percent tensor([0.4764, 0.4811, 0.6162, 0.6510, 0.6663, 0.6604, 0.5295, 0.5455, 0.5488,
        0.4506, 0.4804, 0.5455, 0.4617, 0.5302, 0.4589, 0.5339],
       device='cuda:0') torch.Size([16])
percent tensor([0.6163, 0.6430, 0.6608, 0.6835, 0.6691, 0.6963, 0.6281, 0.5699, 0.6833,
        0.6546, 0.6895, 0.6589, 0.6631, 0.6863, 0.5954, 0.5960],
       device='cuda:0') torch.Size([16])
percent tensor([0.9994, 0.9986, 0.9995, 0.9992, 0.9996, 0.9981, 0.9995, 0.9997, 0.9991,
        0.9994, 0.9988, 0.9999, 0.9989, 0.9991, 0.9995, 0.9995],
       device='cuda:0') torch.Size([16])
Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 3, 3, 3]) tensor(176.4281, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(798.3477, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(798.9088, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([128, 64, 3, 3]) tensor(1522.2126, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([128, 64, 1, 1]) tensor(506.0111, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([128, 128, 3, 3]) tensor(2206.9680, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([256, 128, 3, 3]) tensor(4297.4634, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([256, 128, 1, 1]) tensor(1423.8999, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([256, 256, 3, 3]) tensor(6099.8696, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([512, 256, 3, 3]) tensor(12021.3018, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([512, 256, 1, 1]) tensor(4004.9705, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([512, 512, 3, 3]) tensor(16904.7949, device='cuda:0', grad_fn=<NormBackward0>)
Epoch: 61 | Batch_idx: 0 |  Loss: (0.3470) |  Loss2: (0.0000) | Acc: (89.00%) (114/128)
Epoch: 61 | Batch_idx: 10 |  Loss: (0.3510) |  Loss2: (0.0000) | Acc: (87.00%) (1238/1408)
Epoch: 61 | Batch_idx: 20 |  Loss: (0.3424) |  Loss2: (0.0000) | Acc: (87.00%) (2361/2688)
Epoch: 61 | Batch_idx: 30 |  Loss: (0.3385) |  Loss2: (0.0000) | Acc: (88.00%) (3499/3968)
Epoch: 61 | Batch_idx: 40 |  Loss: (0.3334) |  Loss2: (0.0000) | Acc: (88.00%) (4640/5248)
Epoch: 61 | Batch_idx: 50 |  Loss: (0.3353) |  Loss2: (0.0000) | Acc: (88.00%) (5770/6528)
Epoch: 61 | Batch_idx: 60 |  Loss: (0.3418) |  Loss2: (0.0000) | Acc: (88.00%) (6896/7808)
Epoch: 61 | Batch_idx: 70 |  Loss: (0.3388) |  Loss2: (0.0000) | Acc: (88.00%) (8038/9088)
Epoch: 61 | Batch_idx: 80 |  Loss: (0.3333) |  Loss2: (0.0000) | Acc: (88.00%) (9194/10368)
Epoch: 61 | Batch_idx: 90 |  Loss: (0.3326) |  Loss2: (0.0000) | Acc: (88.00%) (10343/11648)
Epoch: 61 | Batch_idx: 100 |  Loss: (0.3328) |  Loss2: (0.0000) | Acc: (88.00%) (11480/12928)
Epoch: 61 | Batch_idx: 110 |  Loss: (0.3358) |  Loss2: (0.0000) | Acc: (88.00%) (12591/14208)
Epoch: 61 | Batch_idx: 120 |  Loss: (0.3357) |  Loss2: (0.0000) | Acc: (88.00%) (13735/15488)
Epoch: 61 | Batch_idx: 130 |  Loss: (0.3345) |  Loss2: (0.0000) | Acc: (88.00%) (14871/16768)
Epoch: 61 | Batch_idx: 140 |  Loss: (0.3380) |  Loss2: (0.0000) | Acc: (88.00%) (15980/18048)
Epoch: 61 | Batch_idx: 150 |  Loss: (0.3382) |  Loss2: (0.0000) | Acc: (88.00%) (17113/19328)
Epoch: 61 | Batch_idx: 160 |  Loss: (0.3392) |  Loss2: (0.0000) | Acc: (88.00%) (18238/20608)
Epoch: 61 | Batch_idx: 170 |  Loss: (0.3394) |  Loss2: (0.0000) | Acc: (88.00%) (19356/21888)
Epoch: 61 | Batch_idx: 180 |  Loss: (0.3405) |  Loss2: (0.0000) | Acc: (88.00%) (20475/23168)
Epoch: 61 | Batch_idx: 190 |  Loss: (0.3404) |  Loss2: (0.0000) | Acc: (88.00%) (21598/24448)
Epoch: 61 | Batch_idx: 200 |  Loss: (0.3393) |  Loss2: (0.0000) | Acc: (88.00%) (22737/25728)
Epoch: 61 | Batch_idx: 210 |  Loss: (0.3391) |  Loss2: (0.0000) | Acc: (88.00%) (23872/27008)
Epoch: 61 | Batch_idx: 220 |  Loss: (0.3391) |  Loss2: (0.0000) | Acc: (88.00%) (25010/28288)
Epoch: 61 | Batch_idx: 230 |  Loss: (0.3402) |  Loss2: (0.0000) | Acc: (88.00%) (26133/29568)
Epoch: 61 | Batch_idx: 240 |  Loss: (0.3398) |  Loss2: (0.0000) | Acc: (88.00%) (27261/30848)
Epoch: 61 | Batch_idx: 250 |  Loss: (0.3391) |  Loss2: (0.0000) | Acc: (88.00%) (28400/32128)
Epoch: 61 | Batch_idx: 260 |  Loss: (0.3385) |  Loss2: (0.0000) | Acc: (88.00%) (29540/33408)
Epoch: 61 | Batch_idx: 270 |  Loss: (0.3373) |  Loss2: (0.0000) | Acc: (88.00%) (30688/34688)
Epoch: 61 | Batch_idx: 280 |  Loss: (0.3365) |  Loss2: (0.0000) | Acc: (88.00%) (31828/35968)
Epoch: 61 | Batch_idx: 290 |  Loss: (0.3367) |  Loss2: (0.0000) | Acc: (88.00%) (32962/37248)
Epoch: 61 | Batch_idx: 300 |  Loss: (0.3363) |  Loss2: (0.0000) | Acc: (88.00%) (34094/38528)
Epoch: 61 | Batch_idx: 310 |  Loss: (0.3370) |  Loss2: (0.0000) | Acc: (88.00%) (35214/39808)
Epoch: 61 | Batch_idx: 320 |  Loss: (0.3380) |  Loss2: (0.0000) | Acc: (88.00%) (36338/41088)
Epoch: 61 | Batch_idx: 330 |  Loss: (0.3373) |  Loss2: (0.0000) | Acc: (88.00%) (37487/42368)
Epoch: 61 | Batch_idx: 340 |  Loss: (0.3372) |  Loss2: (0.0000) | Acc: (88.00%) (38612/43648)
Epoch: 61 | Batch_idx: 350 |  Loss: (0.3369) |  Loss2: (0.0000) | Acc: (88.00%) (39750/44928)
Epoch: 61 | Batch_idx: 360 |  Loss: (0.3368) |  Loss2: (0.0000) | Acc: (88.00%) (40878/46208)
Epoch: 61 | Batch_idx: 370 |  Loss: (0.3367) |  Loss2: (0.0000) | Acc: (88.00%) (42003/47488)
Epoch: 61 | Batch_idx: 380 |  Loss: (0.3369) |  Loss2: (0.0000) | Acc: (88.00%) (43129/48768)
Epoch: 61 | Batch_idx: 390 |  Loss: (0.3368) |  Loss2: (0.0000) | Acc: (88.00%) (44224/50000)
# TEST : Loss: (0.5598) | Acc: (81.00%) (8176/10000)
percent tensor([0.5283, 0.5353, 0.5312, 0.5284, 0.5318, 0.5290, 0.5360, 0.5298, 0.5279,
        0.5333, 0.5311, 0.5340, 0.5309, 0.5299, 0.5339, 0.5303],
       device='cuda:0') torch.Size([16])
percent tensor([0.5077, 0.5081, 0.5034, 0.5061, 0.5020, 0.5106, 0.5057, 0.5026, 0.5052,
        0.5077, 0.5095, 0.5059, 0.5062, 0.5058, 0.5098, 0.5067],
       device='cuda:0') torch.Size([16])
percent tensor([0.4900, 0.3945, 0.6455, 0.6125, 0.6356, 0.5612, 0.4909, 0.6118, 0.5403,
        0.4683, 0.4074, 0.5828, 0.4249, 0.4359, 0.4560, 0.5154],
       device='cuda:0') torch.Size([16])
percent tensor([0.6542, 0.6765, 0.5873, 0.5997, 0.5941, 0.5817, 0.6532, 0.6084, 0.6491,
        0.6641, 0.6868, 0.6386, 0.6698, 0.6727, 0.6548, 0.6409],
       device='cuda:0') torch.Size([16])
percent tensor([0.6542, 0.5764, 0.6736, 0.6899, 0.6877, 0.6736, 0.6479, 0.6998, 0.6375,
        0.5682, 0.5667, 0.6217, 0.5586, 0.6410, 0.6454, 0.6706],
       device='cuda:0') torch.Size([16])
percent tensor([0.5051, 0.5290, 0.6249, 0.6663, 0.6741, 0.6751, 0.5584, 0.5521, 0.5875,
        0.5078, 0.5324, 0.5619, 0.5047, 0.5868, 0.5081, 0.5720],
       device='cuda:0') torch.Size([16])
percent tensor([0.6061, 0.6588, 0.6476, 0.6763, 0.6672, 0.6989, 0.6194, 0.5495, 0.6853,
        0.6524, 0.6984, 0.6444, 0.6585, 0.6958, 0.5931, 0.5898],
       device='cuda:0') torch.Size([16])
percent tensor([0.9994, 0.9992, 0.9997, 0.9996, 0.9997, 0.9984, 0.9994, 0.9998, 0.9987,
        0.9991, 0.9988, 0.9998, 0.9981, 0.9988, 0.9995, 0.9995],
       device='cuda:0') torch.Size([16])
Epoch: 62 | Batch_idx: 0 |  Loss: (0.3774) |  Loss2: (0.0000) | Acc: (86.00%) (111/128)
Epoch: 62 | Batch_idx: 10 |  Loss: (0.3710) |  Loss2: (0.0000) | Acc: (87.00%) (1228/1408)
Epoch: 62 | Batch_idx: 20 |  Loss: (0.3546) |  Loss2: (0.0000) | Acc: (87.00%) (2356/2688)
Epoch: 62 | Batch_idx: 30 |  Loss: (0.3480) |  Loss2: (0.0000) | Acc: (88.00%) (3493/3968)
Epoch: 62 | Batch_idx: 40 |  Loss: (0.3455) |  Loss2: (0.0000) | Acc: (88.00%) (4622/5248)
Epoch: 62 | Batch_idx: 50 |  Loss: (0.3394) |  Loss2: (0.0000) | Acc: (88.00%) (5758/6528)
Epoch: 62 | Batch_idx: 60 |  Loss: (0.3336) |  Loss2: (0.0000) | Acc: (88.00%) (6902/7808)
Epoch: 62 | Batch_idx: 70 |  Loss: (0.3347) |  Loss2: (0.0000) | Acc: (88.00%) (8029/9088)
Epoch: 62 | Batch_idx: 80 |  Loss: (0.3319) |  Loss2: (0.0000) | Acc: (88.00%) (9177/10368)
Epoch: 62 | Batch_idx: 90 |  Loss: (0.3309) |  Loss2: (0.0000) | Acc: (88.00%) (10316/11648)
Epoch: 62 | Batch_idx: 100 |  Loss: (0.3281) |  Loss2: (0.0000) | Acc: (88.00%) (11471/12928)
Epoch: 62 | Batch_idx: 110 |  Loss: (0.3295) |  Loss2: (0.0000) | Acc: (88.00%) (12590/14208)
Epoch: 62 | Batch_idx: 120 |  Loss: (0.3284) |  Loss2: (0.0000) | Acc: (88.00%) (13730/15488)
Epoch: 62 | Batch_idx: 130 |  Loss: (0.3267) |  Loss2: (0.0000) | Acc: (88.00%) (14864/16768)
Epoch: 62 | Batch_idx: 140 |  Loss: (0.3259) |  Loss2: (0.0000) | Acc: (88.00%) (16019/18048)
Epoch: 62 | Batch_idx: 150 |  Loss: (0.3255) |  Loss2: (0.0000) | Acc: (88.00%) (17154/19328)
Epoch: 62 | Batch_idx: 160 |  Loss: (0.3224) |  Loss2: (0.0000) | Acc: (88.00%) (18309/20608)
Epoch: 62 | Batch_idx: 170 |  Loss: (0.3239) |  Loss2: (0.0000) | Acc: (88.00%) (19442/21888)
Epoch: 62 | Batch_idx: 180 |  Loss: (0.3251) |  Loss2: (0.0000) | Acc: (88.00%) (20576/23168)
Epoch: 62 | Batch_idx: 190 |  Loss: (0.3266) |  Loss2: (0.0000) | Acc: (88.00%) (21707/24448)
Epoch: 62 | Batch_idx: 200 |  Loss: (0.3285) |  Loss2: (0.0000) | Acc: (88.00%) (22834/25728)
Epoch: 62 | Batch_idx: 210 |  Loss: (0.3280) |  Loss2: (0.0000) | Acc: (88.00%) (23972/27008)
Epoch: 62 | Batch_idx: 220 |  Loss: (0.3281) |  Loss2: (0.0000) | Acc: (88.00%) (25108/28288)
Epoch: 62 | Batch_idx: 230 |  Loss: (0.3264) |  Loss2: (0.0000) | Acc: (88.00%) (26279/29568)
Epoch: 62 | Batch_idx: 240 |  Loss: (0.3260) |  Loss2: (0.0000) | Acc: (88.00%) (27425/30848)
Epoch: 62 | Batch_idx: 250 |  Loss: (0.3274) |  Loss2: (0.0000) | Acc: (88.00%) (28548/32128)
Epoch: 62 | Batch_idx: 260 |  Loss: (0.3282) |  Loss2: (0.0000) | Acc: (88.00%) (29676/33408)
Epoch: 62 | Batch_idx: 270 |  Loss: (0.3285) |  Loss2: (0.0000) | Acc: (88.00%) (30807/34688)
Epoch: 62 | Batch_idx: 280 |  Loss: (0.3284) |  Loss2: (0.0000) | Acc: (88.00%) (31942/35968)
Epoch: 62 | Batch_idx: 290 |  Loss: (0.3295) |  Loss2: (0.0000) | Acc: (88.00%) (33067/37248)
Epoch: 62 | Batch_idx: 300 |  Loss: (0.3285) |  Loss2: (0.0000) | Acc: (88.00%) (34207/38528)
Epoch: 62 | Batch_idx: 310 |  Loss: (0.3295) |  Loss2: (0.0000) | Acc: (88.00%) (35338/39808)
Epoch: 62 | Batch_idx: 320 |  Loss: (0.3292) |  Loss2: (0.0000) | Acc: (88.00%) (36472/41088)
Epoch: 62 | Batch_idx: 330 |  Loss: (0.3285) |  Loss2: (0.0000) | Acc: (88.00%) (37622/42368)
Epoch: 62 | Batch_idx: 340 |  Loss: (0.3281) |  Loss2: (0.0000) | Acc: (88.00%) (38755/43648)
Epoch: 62 | Batch_idx: 350 |  Loss: (0.3282) |  Loss2: (0.0000) | Acc: (88.00%) (39894/44928)
Epoch: 62 | Batch_idx: 360 |  Loss: (0.3280) |  Loss2: (0.0000) | Acc: (88.00%) (41040/46208)
Epoch: 62 | Batch_idx: 370 |  Loss: (0.3285) |  Loss2: (0.0000) | Acc: (88.00%) (42161/47488)
Epoch: 62 | Batch_idx: 380 |  Loss: (0.3287) |  Loss2: (0.0000) | Acc: (88.00%) (43304/48768)
Epoch: 62 | Batch_idx: 390 |  Loss: (0.3285) |  Loss2: (0.0000) | Acc: (88.00%) (44404/50000)
# TEST : Loss: (0.4636) | Acc: (84.00%) (8490/10000)
percent tensor([0.5278, 0.5343, 0.5303, 0.5279, 0.5312, 0.5281, 0.5353, 0.5292, 0.5275,
        0.5327, 0.5305, 0.5338, 0.5304, 0.5291, 0.5329, 0.5300],
       device='cuda:0') torch.Size([16])
percent tensor([0.5078, 0.5080, 0.5038, 0.5065, 0.5030, 0.5110, 0.5058, 0.5028, 0.5051,
        0.5072, 0.5092, 0.5061, 0.5061, 0.5054, 0.5099, 0.5067],
       device='cuda:0') torch.Size([16])
percent tensor([0.4924, 0.4047, 0.6406, 0.6127, 0.6315, 0.5502, 0.5038, 0.6094, 0.5455,
        0.4781, 0.4303, 0.5776, 0.4305, 0.4661, 0.4593, 0.5251],
       device='cuda:0') torch.Size([16])
percent tensor([0.6526, 0.6754, 0.5859, 0.6005, 0.5946, 0.5892, 0.6491, 0.6080, 0.6457,
        0.6650, 0.6826, 0.6356, 0.6653, 0.6654, 0.6573, 0.6425],
       device='cuda:0') torch.Size([16])
percent tensor([0.6456, 0.5590, 0.6792, 0.6954, 0.6941, 0.6695, 0.6366, 0.6942, 0.6271,
        0.5663, 0.5565, 0.6160, 0.5511, 0.6293, 0.6434, 0.6664],
       device='cuda:0') torch.Size([16])
percent tensor([0.4764, 0.4990, 0.6136, 0.6570, 0.6766, 0.6641, 0.5600, 0.5579, 0.5657,
        0.4461, 0.4999, 0.5388, 0.4842, 0.5569, 0.4733, 0.5259],
       device='cuda:0') torch.Size([16])
percent tensor([0.6146, 0.6536, 0.6404, 0.6629, 0.6631, 0.6874, 0.6364, 0.5562, 0.6835,
        0.6414, 0.6892, 0.6411, 0.6583, 0.6941, 0.5925, 0.5781],
       device='cuda:0') torch.Size([16])
percent tensor([0.9996, 0.9988, 0.9996, 0.9997, 0.9996, 0.9981, 0.9992, 0.9999, 0.9988,
        0.9996, 0.9984, 0.9998, 0.9985, 0.9990, 0.9996, 0.9998],
       device='cuda:0') torch.Size([16])
False Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=128, out_features=16, bias=False)
True Linear(in_features=16, out_features=2, bias=False)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=128, out_features=16, bias=False)
True Linear(in_features=16, out_features=2, bias=False)
False Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=256, out_features=32, bias=False)
True Linear(in_features=32, out_features=2, bias=False)
False Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=256, out_features=32, bias=False)
True Linear(in_features=32, out_features=2, bias=False)
False Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=512, out_features=64, bias=False)
True Linear(in_features=64, out_features=2, bias=False)
False Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=512, out_features=64, bias=False)
True Linear(in_features=64, out_features=2, bias=False)
False Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1024, out_features=128, bias=False)
True Linear(in_features=128, out_features=2, bias=False)
False Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1024, out_features=128, bias=False)
True Linear(in_features=128, out_features=2, bias=False)
False Linear(in_features=512, out_features=10, bias=True)
Epoch: 63 | Batch_idx: 0 |  Loss: (0.2729) |  Loss2: (0.0000) | Acc: (90.00%) (116/128)
Epoch: 63 | Batch_idx: 10 |  Loss: (0.3362) |  Loss2: (0.0000) | Acc: (88.00%) (1247/1408)
Epoch: 63 | Batch_idx: 20 |  Loss: (0.3384) |  Loss2: (0.0000) | Acc: (88.00%) (2370/2688)
Epoch: 63 | Batch_idx: 30 |  Loss: (0.3465) |  Loss2: (0.0000) | Acc: (87.00%) (3482/3968)
Epoch: 63 | Batch_idx: 40 |  Loss: (0.3468) |  Loss2: (0.0000) | Acc: (87.00%) (4594/5248)
Epoch: 63 | Batch_idx: 50 |  Loss: (0.3475) |  Loss2: (0.0000) | Acc: (87.00%) (5725/6528)
Epoch: 63 | Batch_idx: 60 |  Loss: (0.3545) |  Loss2: (0.0000) | Acc: (87.00%) (6828/7808)
Epoch: 63 | Batch_idx: 70 |  Loss: (0.3535) |  Loss2: (0.0000) | Acc: (87.00%) (7948/9088)
Epoch: 63 | Batch_idx: 80 |  Loss: (0.3559) |  Loss2: (0.0000) | Acc: (87.00%) (9059/10368)
Epoch: 63 | Batch_idx: 90 |  Loss: (0.3558) |  Loss2: (0.0000) | Acc: (87.00%) (10182/11648)
Epoch: 63 | Batch_idx: 100 |  Loss: (0.3552) |  Loss2: (0.0000) | Acc: (87.00%) (11298/12928)
Epoch: 63 | Batch_idx: 110 |  Loss: (0.3567) |  Loss2: (0.0000) | Acc: (87.00%) (12405/14208)
Epoch: 63 | Batch_idx: 120 |  Loss: (0.3564) |  Loss2: (0.0000) | Acc: (87.00%) (13525/15488)
Epoch: 63 | Batch_idx: 130 |  Loss: (0.3561) |  Loss2: (0.0000) | Acc: (87.00%) (14657/16768)
Epoch: 63 | Batch_idx: 140 |  Loss: (0.3556) |  Loss2: (0.0000) | Acc: (87.00%) (15786/18048)
Epoch: 63 | Batch_idx: 150 |  Loss: (0.3537) |  Loss2: (0.0000) | Acc: (87.00%) (16913/19328)
Epoch: 63 | Batch_idx: 160 |  Loss: (0.3517) |  Loss2: (0.0000) | Acc: (87.00%) (18044/20608)
Epoch: 63 | Batch_idx: 170 |  Loss: (0.3498) |  Loss2: (0.0000) | Acc: (87.00%) (19183/21888)
Epoch: 63 | Batch_idx: 180 |  Loss: (0.3508) |  Loss2: (0.0000) | Acc: (87.00%) (20295/23168)
Epoch: 63 | Batch_idx: 190 |  Loss: (0.3489) |  Loss2: (0.0000) | Acc: (87.00%) (21435/24448)
Epoch: 63 | Batch_idx: 200 |  Loss: (0.3473) |  Loss2: (0.0000) | Acc: (87.00%) (22583/25728)
Epoch: 63 | Batch_idx: 210 |  Loss: (0.3496) |  Loss2: (0.0000) | Acc: (87.00%) (23691/27008)
Epoch: 63 | Batch_idx: 220 |  Loss: (0.3486) |  Loss2: (0.0000) | Acc: (87.00%) (24826/28288)
Epoch: 63 | Batch_idx: 230 |  Loss: (0.3474) |  Loss2: (0.0000) | Acc: (87.00%) (25954/29568)
Epoch: 63 | Batch_idx: 240 |  Loss: (0.3483) |  Loss2: (0.0000) | Acc: (87.00%) (27050/30848)
Epoch: 63 | Batch_idx: 250 |  Loss: (0.3493) |  Loss2: (0.0000) | Acc: (87.00%) (28165/32128)
Epoch: 63 | Batch_idx: 260 |  Loss: (0.3499) |  Loss2: (0.0000) | Acc: (87.00%) (29300/33408)
Epoch: 63 | Batch_idx: 270 |  Loss: (0.3492) |  Loss2: (0.0000) | Acc: (87.00%) (30428/34688)
Epoch: 63 | Batch_idx: 280 |  Loss: (0.3477) |  Loss2: (0.0000) | Acc: (87.00%) (31568/35968)
Epoch: 63 | Batch_idx: 290 |  Loss: (0.3469) |  Loss2: (0.0000) | Acc: (87.00%) (32697/37248)
Epoch: 63 | Batch_idx: 300 |  Loss: (0.3464) |  Loss2: (0.0000) | Acc: (87.00%) (33833/38528)
Epoch: 63 | Batch_idx: 310 |  Loss: (0.3457) |  Loss2: (0.0000) | Acc: (87.00%) (34972/39808)
Epoch: 63 | Batch_idx: 320 |  Loss: (0.3465) |  Loss2: (0.0000) | Acc: (87.00%) (36082/41088)
Epoch: 63 | Batch_idx: 330 |  Loss: (0.3456) |  Loss2: (0.0000) | Acc: (87.00%) (37220/42368)
Epoch: 63 | Batch_idx: 340 |  Loss: (0.3440) |  Loss2: (0.0000) | Acc: (87.00%) (38373/43648)
Epoch: 63 | Batch_idx: 350 |  Loss: (0.3437) |  Loss2: (0.0000) | Acc: (87.00%) (39505/44928)
Epoch: 63 | Batch_idx: 360 |  Loss: (0.3427) |  Loss2: (0.0000) | Acc: (87.00%) (40650/46208)
Epoch: 63 | Batch_idx: 370 |  Loss: (0.3426) |  Loss2: (0.0000) | Acc: (87.00%) (41787/47488)
Epoch: 63 | Batch_idx: 380 |  Loss: (0.3413) |  Loss2: (0.0000) | Acc: (88.00%) (42939/48768)
Epoch: 63 | Batch_idx: 390 |  Loss: (0.3408) |  Loss2: (0.0000) | Acc: (88.00%) (44044/50000)
# TEST : Loss: (0.4396) | Acc: (85.00%) (8539/10000)
percent tensor([0.5272, 0.5334, 0.5291, 0.5274, 0.5300, 0.5272, 0.5343, 0.5286, 0.5268,
        0.5320, 0.5299, 0.5330, 0.5299, 0.5283, 0.5322, 0.5294],
       device='cuda:0') torch.Size([16])
percent tensor([0.5126, 0.5135, 0.5082, 0.5107, 0.5090, 0.5157, 0.5115, 0.5075, 0.5096,
        0.5124, 0.5141, 0.5105, 0.5116, 0.5102, 0.5149, 0.5123],
       device='cuda:0') torch.Size([16])
percent tensor([0.4839, 0.3786, 0.6280, 0.6048, 0.6217, 0.5438, 0.4900, 0.6106, 0.5349,
        0.4472, 0.4044, 0.5461, 0.4031, 0.4635, 0.4475, 0.5102],
       device='cuda:0') torch.Size([16])
percent tensor([0.6642, 0.6855, 0.6040, 0.6148, 0.6084, 0.5932, 0.6597, 0.6228, 0.6626,
        0.6773, 0.6964, 0.6488, 0.6771, 0.6765, 0.6636, 0.6521],
       device='cuda:0') torch.Size([16])
percent tensor([0.6567, 0.5547, 0.7033, 0.7267, 0.7191, 0.6859, 0.6485, 0.7173, 0.6437,
        0.5621, 0.5533, 0.6233, 0.5408, 0.6457, 0.6534, 0.6720],
       device='cuda:0') torch.Size([16])
percent tensor([0.4998, 0.5325, 0.6091, 0.6535, 0.6765, 0.6728, 0.5772, 0.5533, 0.5801,
        0.4844, 0.5318, 0.5519, 0.5132, 0.5811, 0.4974, 0.5436],
       device='cuda:0') torch.Size([16])
percent tensor([0.6223, 0.6561, 0.6271, 0.6516, 0.6505, 0.6802, 0.6419, 0.5455, 0.6797,
        0.6490, 0.6899, 0.6287, 0.6489, 0.6962, 0.5819, 0.5908],
       device='cuda:0') torch.Size([16])
percent tensor([0.9995, 0.9989, 0.9993, 0.9995, 0.9995, 0.9970, 0.9992, 0.9998, 0.9985,
        0.9996, 0.9986, 0.9996, 0.9984, 0.9991, 0.9996, 0.9996],
       device='cuda:0') torch.Size([16])
Epoch: 64 | Batch_idx: 0 |  Loss: (0.3212) |  Loss2: (0.0000) | Acc: (89.00%) (115/128)
Epoch: 64 | Batch_idx: 10 |  Loss: (0.3469) |  Loss2: (0.0000) | Acc: (88.00%) (1244/1408)
Epoch: 64 | Batch_idx: 20 |  Loss: (0.3479) |  Loss2: (0.0000) | Acc: (88.00%) (2378/2688)
Epoch: 64 | Batch_idx: 30 |  Loss: (0.3296) |  Loss2: (0.0000) | Acc: (89.00%) (3532/3968)
Epoch: 64 | Batch_idx: 40 |  Loss: (0.3273) |  Loss2: (0.0000) | Acc: (88.00%) (4666/5248)
Epoch: 64 | Batch_idx: 50 |  Loss: (0.3274) |  Loss2: (0.0000) | Acc: (89.00%) (5812/6528)
Epoch: 64 | Batch_idx: 60 |  Loss: (0.3266) |  Loss2: (0.0000) | Acc: (89.00%) (6958/7808)
Epoch: 64 | Batch_idx: 70 |  Loss: (0.3236) |  Loss2: (0.0000) | Acc: (89.00%) (8106/9088)
Epoch: 64 | Batch_idx: 80 |  Loss: (0.3252) |  Loss2: (0.0000) | Acc: (89.00%) (9242/10368)
Epoch: 64 | Batch_idx: 90 |  Loss: (0.3260) |  Loss2: (0.0000) | Acc: (88.00%) (10361/11648)
Epoch: 64 | Batch_idx: 100 |  Loss: (0.3204) |  Loss2: (0.0000) | Acc: (89.00%) (11537/12928)
Epoch: 64 | Batch_idx: 110 |  Loss: (0.3205) |  Loss2: (0.0000) | Acc: (89.00%) (12671/14208)
Epoch: 64 | Batch_idx: 120 |  Loss: (0.3203) |  Loss2: (0.0000) | Acc: (89.00%) (13815/15488)
Epoch: 64 | Batch_idx: 130 |  Loss: (0.3204) |  Loss2: (0.0000) | Acc: (89.00%) (14958/16768)
Epoch: 64 | Batch_idx: 140 |  Loss: (0.3186) |  Loss2: (0.0000) | Acc: (89.00%) (16095/18048)
Epoch: 64 | Batch_idx: 150 |  Loss: (0.3171) |  Loss2: (0.0000) | Acc: (89.00%) (17256/19328)
Epoch: 64 | Batch_idx: 160 |  Loss: (0.3181) |  Loss2: (0.0000) | Acc: (89.00%) (18394/20608)
Epoch: 64 | Batch_idx: 170 |  Loss: (0.3183) |  Loss2: (0.0000) | Acc: (89.00%) (19536/21888)
Epoch: 64 | Batch_idx: 180 |  Loss: (0.3188) |  Loss2: (0.0000) | Acc: (89.00%) (20677/23168)
Epoch: 64 | Batch_idx: 190 |  Loss: (0.3189) |  Loss2: (0.0000) | Acc: (89.00%) (21819/24448)
Epoch: 64 | Batch_idx: 200 |  Loss: (0.3197) |  Loss2: (0.0000) | Acc: (89.00%) (22947/25728)
Epoch: 64 | Batch_idx: 210 |  Loss: (0.3207) |  Loss2: (0.0000) | Acc: (89.00%) (24070/27008)
Epoch: 64 | Batch_idx: 220 |  Loss: (0.3216) |  Loss2: (0.0000) | Acc: (89.00%) (25210/28288)
Epoch: 64 | Batch_idx: 230 |  Loss: (0.3221) |  Loss2: (0.0000) | Acc: (89.00%) (26330/29568)
Epoch: 64 | Batch_idx: 240 |  Loss: (0.3237) |  Loss2: (0.0000) | Acc: (88.00%) (27448/30848)
Epoch: 64 | Batch_idx: 250 |  Loss: (0.3236) |  Loss2: (0.0000) | Acc: (88.00%) (28582/32128)
Epoch: 64 | Batch_idx: 260 |  Loss: (0.3237) |  Loss2: (0.0000) | Acc: (88.00%) (29708/33408)
Epoch: 64 | Batch_idx: 270 |  Loss: (0.3234) |  Loss2: (0.0000) | Acc: (88.00%) (30848/34688)
Epoch: 64 | Batch_idx: 280 |  Loss: (0.3239) |  Loss2: (0.0000) | Acc: (88.00%) (31969/35968)
Epoch: 64 | Batch_idx: 290 |  Loss: (0.3233) |  Loss2: (0.0000) | Acc: (88.00%) (33113/37248)
Epoch: 64 | Batch_idx: 300 |  Loss: (0.3234) |  Loss2: (0.0000) | Acc: (88.00%) (34251/38528)
Epoch: 64 | Batch_idx: 310 |  Loss: (0.3254) |  Loss2: (0.0000) | Acc: (88.00%) (35372/39808)
Epoch: 64 | Batch_idx: 320 |  Loss: (0.3252) |  Loss2: (0.0000) | Acc: (88.00%) (36516/41088)
Epoch: 64 | Batch_idx: 330 |  Loss: (0.3244) |  Loss2: (0.0000) | Acc: (88.00%) (37664/42368)
Epoch: 64 | Batch_idx: 340 |  Loss: (0.3235) |  Loss2: (0.0000) | Acc: (88.00%) (38824/43648)
Epoch: 64 | Batch_idx: 350 |  Loss: (0.3228) |  Loss2: (0.0000) | Acc: (88.00%) (39975/44928)
Epoch: 64 | Batch_idx: 360 |  Loss: (0.3229) |  Loss2: (0.0000) | Acc: (88.00%) (41115/46208)
Epoch: 64 | Batch_idx: 370 |  Loss: (0.3235) |  Loss2: (0.0000) | Acc: (88.00%) (42242/47488)
Epoch: 64 | Batch_idx: 380 |  Loss: (0.3235) |  Loss2: (0.0000) | Acc: (88.00%) (43384/48768)
Epoch: 64 | Batch_idx: 390 |  Loss: (0.3230) |  Loss2: (0.0000) | Acc: (88.00%) (44488/50000)
# TEST : Loss: (0.4255) | Acc: (85.00%) (8576/10000)
percent tensor([0.5273, 0.5336, 0.5291, 0.5273, 0.5301, 0.5271, 0.5345, 0.5287, 0.5271,
        0.5321, 0.5301, 0.5331, 0.5301, 0.5283, 0.5323, 0.5294],
       device='cuda:0') torch.Size([16])
percent tensor([0.5156, 0.5167, 0.5104, 0.5135, 0.5117, 0.5186, 0.5146, 0.5101, 0.5121,
        0.5154, 0.5173, 0.5131, 0.5145, 0.5133, 0.5180, 0.5153],
       device='cuda:0') torch.Size([16])
percent tensor([0.4964, 0.3782, 0.6335, 0.6097, 0.6260, 0.5545, 0.4942, 0.6193, 0.5421,
        0.4486, 0.4060, 0.5506, 0.4084, 0.4635, 0.4558, 0.5176],
       device='cuda:0') torch.Size([16])
percent tensor([0.6693, 0.6900, 0.6085, 0.6199, 0.6129, 0.5951, 0.6646, 0.6267, 0.6686,
        0.6828, 0.7028, 0.6522, 0.6806, 0.6839, 0.6666, 0.6562],
       device='cuda:0') torch.Size([16])
percent tensor([0.6661, 0.5548, 0.7164, 0.7387, 0.7295, 0.6962, 0.6557, 0.7277, 0.6542,
        0.5661, 0.5583, 0.6292, 0.5411, 0.6533, 0.6598, 0.6781],
       device='cuda:0') torch.Size([16])
percent tensor([0.4926, 0.5311, 0.6061, 0.6544, 0.6759, 0.6758, 0.5731, 0.5445, 0.5769,
        0.4830, 0.5323, 0.5519, 0.5147, 0.5790, 0.4913, 0.5427],
       device='cuda:0') torch.Size([16])
percent tensor([0.6223, 0.6562, 0.6213, 0.6569, 0.6548, 0.6816, 0.6440, 0.5409, 0.6805,
        0.6505, 0.6915, 0.6235, 0.6459, 0.7017, 0.5718, 0.5962],
       device='cuda:0') torch.Size([16])
percent tensor([0.9995, 0.9989, 0.9994, 0.9996, 0.9995, 0.9974, 0.9993, 0.9998, 0.9987,
        0.9996, 0.9987, 0.9996, 0.9985, 0.9992, 0.9996, 0.9997],
       device='cuda:0') torch.Size([16])
Epoch: 65 | Batch_idx: 0 |  Loss: (0.3443) |  Loss2: (0.0000) | Acc: (89.00%) (114/128)
Epoch: 65 | Batch_idx: 10 |  Loss: (0.3404) |  Loss2: (0.0000) | Acc: (88.00%) (1243/1408)
Epoch: 65 | Batch_idx: 20 |  Loss: (0.3211) |  Loss2: (0.0000) | Acc: (89.00%) (2395/2688)
Epoch: 65 | Batch_idx: 30 |  Loss: (0.3388) |  Loss2: (0.0000) | Acc: (88.00%) (3514/3968)
Epoch: 65 | Batch_idx: 40 |  Loss: (0.3327) |  Loss2: (0.0000) | Acc: (88.00%) (4661/5248)
Epoch: 65 | Batch_idx: 50 |  Loss: (0.3317) |  Loss2: (0.0000) | Acc: (88.00%) (5804/6528)
Epoch: 65 | Batch_idx: 60 |  Loss: (0.3304) |  Loss2: (0.0000) | Acc: (88.00%) (6944/7808)
Epoch: 65 | Batch_idx: 70 |  Loss: (0.3265) |  Loss2: (0.0000) | Acc: (88.00%) (8080/9088)
Epoch: 65 | Batch_idx: 80 |  Loss: (0.3261) |  Loss2: (0.0000) | Acc: (88.00%) (9224/10368)
Epoch: 65 | Batch_idx: 90 |  Loss: (0.3233) |  Loss2: (0.0000) | Acc: (89.00%) (10382/11648)
Epoch: 65 | Batch_idx: 100 |  Loss: (0.3209) |  Loss2: (0.0000) | Acc: (89.00%) (11527/12928)
Epoch: 65 | Batch_idx: 110 |  Loss: (0.3185) |  Loss2: (0.0000) | Acc: (89.00%) (12676/14208)
Epoch: 65 | Batch_idx: 120 |  Loss: (0.3191) |  Loss2: (0.0000) | Acc: (89.00%) (13802/15488)
Epoch: 65 | Batch_idx: 130 |  Loss: (0.3164) |  Loss2: (0.0000) | Acc: (89.00%) (14971/16768)
Epoch: 65 | Batch_idx: 140 |  Loss: (0.3158) |  Loss2: (0.0000) | Acc: (89.00%) (16110/18048)
Epoch: 65 | Batch_idx: 150 |  Loss: (0.3131) |  Loss2: (0.0000) | Acc: (89.00%) (17270/19328)
Epoch: 65 | Batch_idx: 160 |  Loss: (0.3117) |  Loss2: (0.0000) | Acc: (89.00%) (18430/20608)
Epoch: 65 | Batch_idx: 170 |  Loss: (0.3144) |  Loss2: (0.0000) | Acc: (89.00%) (19550/21888)
Epoch: 65 | Batch_idx: 180 |  Loss: (0.3144) |  Loss2: (0.0000) | Acc: (89.00%) (20700/23168)
Epoch: 65 | Batch_idx: 190 |  Loss: (0.3155) |  Loss2: (0.0000) | Acc: (89.00%) (21846/24448)
Epoch: 65 | Batch_idx: 200 |  Loss: (0.3153) |  Loss2: (0.0000) | Acc: (89.00%) (22993/25728)
Epoch: 65 | Batch_idx: 210 |  Loss: (0.3155) |  Loss2: (0.0000) | Acc: (89.00%) (24132/27008)
Epoch: 65 | Batch_idx: 220 |  Loss: (0.3159) |  Loss2: (0.0000) | Acc: (89.00%) (25265/28288)
Epoch: 65 | Batch_idx: 230 |  Loss: (0.3154) |  Loss2: (0.0000) | Acc: (89.00%) (26416/29568)
Epoch: 65 | Batch_idx: 240 |  Loss: (0.3151) |  Loss2: (0.0000) | Acc: (89.00%) (27567/30848)
Epoch: 65 | Batch_idx: 250 |  Loss: (0.3156) |  Loss2: (0.0000) | Acc: (89.00%) (28696/32128)
Epoch: 65 | Batch_idx: 260 |  Loss: (0.3142) |  Loss2: (0.0000) | Acc: (89.00%) (29852/33408)
Epoch: 65 | Batch_idx: 270 |  Loss: (0.3144) |  Loss2: (0.0000) | Acc: (89.00%) (30994/34688)
Epoch: 65 | Batch_idx: 280 |  Loss: (0.3147) |  Loss2: (0.0000) | Acc: (89.00%) (32130/35968)
Epoch: 65 | Batch_idx: 290 |  Loss: (0.3147) |  Loss2: (0.0000) | Acc: (89.00%) (33281/37248)
Epoch: 65 | Batch_idx: 300 |  Loss: (0.3149) |  Loss2: (0.0000) | Acc: (89.00%) (34422/38528)
Epoch: 65 | Batch_idx: 310 |  Loss: (0.3145) |  Loss2: (0.0000) | Acc: (89.00%) (35580/39808)
Epoch: 65 | Batch_idx: 320 |  Loss: (0.3149) |  Loss2: (0.0000) | Acc: (89.00%) (36710/41088)
Epoch: 65 | Batch_idx: 330 |  Loss: (0.3148) |  Loss2: (0.0000) | Acc: (89.00%) (37848/42368)
Epoch: 65 | Batch_idx: 340 |  Loss: (0.3151) |  Loss2: (0.0000) | Acc: (89.00%) (38981/43648)
Epoch: 65 | Batch_idx: 350 |  Loss: (0.3146) |  Loss2: (0.0000) | Acc: (89.00%) (40129/44928)
Epoch: 65 | Batch_idx: 360 |  Loss: (0.3146) |  Loss2: (0.0000) | Acc: (89.00%) (41276/46208)
Epoch: 65 | Batch_idx: 370 |  Loss: (0.3139) |  Loss2: (0.0000) | Acc: (89.00%) (42437/47488)
Epoch: 65 | Batch_idx: 380 |  Loss: (0.3136) |  Loss2: (0.0000) | Acc: (89.00%) (43577/48768)
Epoch: 65 | Batch_idx: 390 |  Loss: (0.3136) |  Loss2: (0.0000) | Acc: (89.00%) (44677/50000)
=> saving checkpoint 'drive/app/torch/save_Schedule/checkpoint_065.pth.tar'
# TEST : Loss: (0.4149) | Acc: (86.00%) (8610/10000)
percent tensor([0.5282, 0.5347, 0.5299, 0.5281, 0.5311, 0.5280, 0.5356, 0.5297, 0.5282,
        0.5332, 0.5313, 0.5342, 0.5313, 0.5292, 0.5334, 0.5304],
       device='cuda:0') torch.Size([16])
percent tensor([0.5193, 0.5205, 0.5132, 0.5166, 0.5152, 0.5221, 0.5183, 0.5133, 0.5153,
        0.5190, 0.5211, 0.5164, 0.5181, 0.5167, 0.5219, 0.5189],
       device='cuda:0') torch.Size([16])
percent tensor([0.5123, 0.3875, 0.6414, 0.6191, 0.6341, 0.5664, 0.5064, 0.6282, 0.5552,
        0.4596, 0.4162, 0.5623, 0.4209, 0.4739, 0.4691, 0.5311],
       device='cuda:0') torch.Size([16])
percent tensor([0.6722, 0.6930, 0.6099, 0.6219, 0.6152, 0.5956, 0.6672, 0.6279, 0.6719,
        0.6864, 0.7069, 0.6536, 0.6833, 0.6878, 0.6681, 0.6583],
       device='cuda:0') torch.Size([16])
percent tensor([0.6722, 0.5602, 0.7245, 0.7447, 0.7359, 0.7023, 0.6620, 0.7326, 0.6623,
        0.5720, 0.5652, 0.6335, 0.5446, 0.6604, 0.6642, 0.6817],
       device='cuda:0') torch.Size([16])
percent tensor([0.4840, 0.5281, 0.6024, 0.6535, 0.6714, 0.6755, 0.5681, 0.5337, 0.5744,
        0.4786, 0.5324, 0.5520, 0.5142, 0.5758, 0.4851, 0.5383],
       device='cuda:0') torch.Size([16])
percent tensor([0.6339, 0.6650, 0.6253, 0.6690, 0.6631, 0.6901, 0.6539, 0.5460, 0.6909,
        0.6634, 0.7040, 0.6333, 0.6565, 0.7135, 0.5759, 0.6089],
       device='cuda:0') torch.Size([16])
percent tensor([0.9995, 0.9989, 0.9994, 0.9996, 0.9995, 0.9976, 0.9993, 0.9998, 0.9986,
        0.9996, 0.9987, 0.9997, 0.9985, 0.9992, 0.9996, 0.9997],
       device='cuda:0') torch.Size([16])
True Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=128, out_features=16, bias=False)
False Linear(in_features=16, out_features=2, bias=False)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=128, out_features=16, bias=False)
False Linear(in_features=16, out_features=2, bias=False)
True Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=256, out_features=32, bias=False)
False Linear(in_features=32, out_features=2, bias=False)
True Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=256, out_features=32, bias=False)
False Linear(in_features=32, out_features=2, bias=False)
True Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=512, out_features=64, bias=False)
False Linear(in_features=64, out_features=2, bias=False)
True Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=512, out_features=64, bias=False)
False Linear(in_features=64, out_features=2, bias=False)
True Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1024, out_features=128, bias=False)
False Linear(in_features=128, out_features=2, bias=False)
True Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1024, out_features=128, bias=False)
False Linear(in_features=128, out_features=2, bias=False)
True Linear(in_features=512, out_features=10, bias=True)
Epoch: 66 | Batch_idx: 0 |  Loss: (0.2835) |  Loss2: (0.0000) | Acc: (89.00%) (115/128)
Epoch: 66 | Batch_idx: 10 |  Loss: (0.3029) |  Loss2: (0.0000) | Acc: (89.00%) (1264/1408)
Epoch: 66 | Batch_idx: 20 |  Loss: (0.3003) |  Loss2: (0.0000) | Acc: (89.00%) (2411/2688)
Epoch: 66 | Batch_idx: 30 |  Loss: (0.3019) |  Loss2: (0.0000) | Acc: (90.00%) (3582/3968)
Epoch: 66 | Batch_idx: 40 |  Loss: (0.3043) |  Loss2: (0.0000) | Acc: (89.00%) (4711/5248)
Epoch: 66 | Batch_idx: 50 |  Loss: (0.3068) |  Loss2: (0.0000) | Acc: (89.00%) (5844/6528)
Epoch: 66 | Batch_idx: 60 |  Loss: (0.3145) |  Loss2: (0.0000) | Acc: (89.00%) (6962/7808)
Epoch: 66 | Batch_idx: 70 |  Loss: (0.3137) |  Loss2: (0.0000) | Acc: (89.00%) (8103/9088)
Epoch: 66 | Batch_idx: 80 |  Loss: (0.3126) |  Loss2: (0.0000) | Acc: (89.00%) (9240/10368)
Epoch: 66 | Batch_idx: 90 |  Loss: (0.3133) |  Loss2: (0.0000) | Acc: (89.00%) (10383/11648)
Epoch: 66 | Batch_idx: 100 |  Loss: (0.3131) |  Loss2: (0.0000) | Acc: (89.00%) (11517/12928)
Epoch: 66 | Batch_idx: 110 |  Loss: (0.3110) |  Loss2: (0.0000) | Acc: (89.00%) (12670/14208)
Epoch: 66 | Batch_idx: 120 |  Loss: (0.3116) |  Loss2: (0.0000) | Acc: (89.00%) (13808/15488)
Epoch: 66 | Batch_idx: 130 |  Loss: (0.3120) |  Loss2: (0.0000) | Acc: (89.00%) (14947/16768)
Epoch: 66 | Batch_idx: 140 |  Loss: (0.3114) |  Loss2: (0.0000) | Acc: (89.00%) (16095/18048)
Epoch: 66 | Batch_idx: 150 |  Loss: (0.3115) |  Loss2: (0.0000) | Acc: (89.00%) (17235/19328)
Epoch: 66 | Batch_idx: 160 |  Loss: (0.3120) |  Loss2: (0.0000) | Acc: (89.00%) (18380/20608)
Epoch: 66 | Batch_idx: 170 |  Loss: (0.3118) |  Loss2: (0.0000) | Acc: (89.00%) (19528/21888)
Epoch: 66 | Batch_idx: 180 |  Loss: (0.3125) |  Loss2: (0.0000) | Acc: (89.00%) (20666/23168)
Epoch: 66 | Batch_idx: 190 |  Loss: (0.3124) |  Loss2: (0.0000) | Acc: (89.00%) (21805/24448)
Epoch: 66 | Batch_idx: 200 |  Loss: (0.3144) |  Loss2: (0.0000) | Acc: (89.00%) (22922/25728)
Epoch: 66 | Batch_idx: 210 |  Loss: (0.3153) |  Loss2: (0.0000) | Acc: (89.00%) (24062/27008)
Epoch: 66 | Batch_idx: 220 |  Loss: (0.3147) |  Loss2: (0.0000) | Acc: (89.00%) (25213/28288)
Epoch: 66 | Batch_idx: 230 |  Loss: (0.3150) |  Loss2: (0.0000) | Acc: (89.00%) (26359/29568)
Epoch: 66 | Batch_idx: 240 |  Loss: (0.3157) |  Loss2: (0.0000) | Acc: (89.00%) (27498/30848)
Epoch: 66 | Batch_idx: 250 |  Loss: (0.3163) |  Loss2: (0.0000) | Acc: (89.00%) (28632/32128)
Epoch: 66 | Batch_idx: 260 |  Loss: (0.3168) |  Loss2: (0.0000) | Acc: (89.00%) (29750/33408)
Epoch: 66 | Batch_idx: 270 |  Loss: (0.3174) |  Loss2: (0.0000) | Acc: (89.00%) (30877/34688)
Epoch: 66 | Batch_idx: 280 |  Loss: (0.3180) |  Loss2: (0.0000) | Acc: (88.00%) (32007/35968)
Epoch: 66 | Batch_idx: 290 |  Loss: (0.3184) |  Loss2: (0.0000) | Acc: (88.00%) (33137/37248)
Epoch: 66 | Batch_idx: 300 |  Loss: (0.3194) |  Loss2: (0.0000) | Acc: (88.00%) (34259/38528)
Epoch: 66 | Batch_idx: 310 |  Loss: (0.3183) |  Loss2: (0.0000) | Acc: (88.00%) (35404/39808)
Epoch: 66 | Batch_idx: 320 |  Loss: (0.3183) |  Loss2: (0.0000) | Acc: (88.00%) (36541/41088)
Epoch: 66 | Batch_idx: 330 |  Loss: (0.3186) |  Loss2: (0.0000) | Acc: (88.00%) (37678/42368)
Epoch: 66 | Batch_idx: 340 |  Loss: (0.3182) |  Loss2: (0.0000) | Acc: (88.00%) (38830/43648)
Epoch: 66 | Batch_idx: 350 |  Loss: (0.3178) |  Loss2: (0.0000) | Acc: (88.00%) (39982/44928)
Epoch: 66 | Batch_idx: 360 |  Loss: (0.3187) |  Loss2: (0.0000) | Acc: (88.00%) (41115/46208)
Epoch: 66 | Batch_idx: 370 |  Loss: (0.3190) |  Loss2: (0.0000) | Acc: (88.00%) (42238/47488)
Epoch: 66 | Batch_idx: 380 |  Loss: (0.3187) |  Loss2: (0.0000) | Acc: (88.00%) (43395/48768)
Epoch: 66 | Batch_idx: 390 |  Loss: (0.3190) |  Loss2: (0.0000) | Acc: (88.00%) (44498/50000)
# TEST : Loss: (0.4439) | Acc: (85.00%) (8516/10000)
percent tensor([0.5294, 0.5349, 0.5318, 0.5285, 0.5325, 0.5295, 0.5362, 0.5300, 0.5286,
        0.5335, 0.5319, 0.5351, 0.5317, 0.5284, 0.5345, 0.5308],
       device='cuda:0') torch.Size([16])
percent tensor([0.5191, 0.5210, 0.5116, 0.5165, 0.5127, 0.5219, 0.5183, 0.5135, 0.5148,
        0.5191, 0.5214, 0.5153, 0.5181, 0.5178, 0.5222, 0.5191],
       device='cuda:0') torch.Size([16])
percent tensor([0.5164, 0.3877, 0.6631, 0.6264, 0.6451, 0.5613, 0.5050, 0.6317, 0.5638,
        0.4729, 0.4128, 0.5973, 0.4294, 0.4532, 0.4616, 0.5259],
       device='cuda:0') torch.Size([16])
percent tensor([0.6711, 0.6900, 0.5950, 0.6137, 0.6095, 0.5979, 0.6673, 0.6240, 0.6653,
        0.6822, 0.7043, 0.6433, 0.6823, 0.6921, 0.6681, 0.6581],
       device='cuda:0') torch.Size([16])
percent tensor([0.6746, 0.5738, 0.7202, 0.7394, 0.7282, 0.6949, 0.6628, 0.7289, 0.6620,
        0.5783, 0.5696, 0.6401, 0.5587, 0.6671, 0.6617, 0.6842],
       device='cuda:0') torch.Size([16])
percent tensor([0.4787, 0.5299, 0.6085, 0.6600, 0.6495, 0.6901, 0.5467, 0.5179, 0.5681,
        0.4907, 0.5228, 0.5655, 0.4985, 0.5804, 0.4990, 0.5595],
       device='cuda:0') torch.Size([16])
percent tensor([0.6330, 0.6782, 0.6456, 0.6751, 0.6651, 0.6928, 0.6421, 0.5669, 0.6818,
        0.6945, 0.7057, 0.6559, 0.6611, 0.7161, 0.5903, 0.6125],
       device='cuda:0') torch.Size([16])
percent tensor([0.9996, 0.9988, 0.9996, 0.9996, 0.9997, 0.9975, 0.9994, 0.9998, 0.9989,
        0.9995, 0.9988, 0.9997, 0.9984, 0.9991, 0.9997, 0.9996],
       device='cuda:0') torch.Size([16])
Epoch: 67 | Batch_idx: 0 |  Loss: (0.3684) |  Loss2: (0.0000) | Acc: (86.00%) (111/128)
Epoch: 67 | Batch_idx: 10 |  Loss: (0.3090) |  Loss2: (0.0000) | Acc: (90.00%) (1268/1408)
Epoch: 67 | Batch_idx: 20 |  Loss: (0.2946) |  Loss2: (0.0000) | Acc: (90.00%) (2431/2688)
Epoch: 67 | Batch_idx: 30 |  Loss: (0.3036) |  Loss2: (0.0000) | Acc: (89.00%) (3564/3968)
Epoch: 67 | Batch_idx: 40 |  Loss: (0.3012) |  Loss2: (0.0000) | Acc: (89.00%) (4711/5248)
Epoch: 67 | Batch_idx: 50 |  Loss: (0.2960) |  Loss2: (0.0000) | Acc: (89.00%) (5864/6528)
Epoch: 67 | Batch_idx: 60 |  Loss: (0.2982) |  Loss2: (0.0000) | Acc: (89.00%) (7008/7808)
Epoch: 67 | Batch_idx: 70 |  Loss: (0.3020) |  Loss2: (0.0000) | Acc: (89.00%) (8156/9088)
Epoch: 67 | Batch_idx: 80 |  Loss: (0.3011) |  Loss2: (0.0000) | Acc: (89.00%) (9305/10368)
Epoch: 67 | Batch_idx: 90 |  Loss: (0.3035) |  Loss2: (0.0000) | Acc: (89.00%) (10447/11648)
Epoch: 67 | Batch_idx: 100 |  Loss: (0.3037) |  Loss2: (0.0000) | Acc: (89.00%) (11589/12928)
Epoch: 67 | Batch_idx: 110 |  Loss: (0.3048) |  Loss2: (0.0000) | Acc: (89.00%) (12735/14208)
Epoch: 67 | Batch_idx: 120 |  Loss: (0.3051) |  Loss2: (0.0000) | Acc: (89.00%) (13871/15488)
Epoch: 67 | Batch_idx: 130 |  Loss: (0.3053) |  Loss2: (0.0000) | Acc: (89.00%) (15017/16768)
Epoch: 67 | Batch_idx: 140 |  Loss: (0.3068) |  Loss2: (0.0000) | Acc: (89.00%) (16159/18048)
Epoch: 67 | Batch_idx: 150 |  Loss: (0.3087) |  Loss2: (0.0000) | Acc: (89.00%) (17288/19328)
Epoch: 67 | Batch_idx: 160 |  Loss: (0.3114) |  Loss2: (0.0000) | Acc: (89.00%) (18428/20608)
Epoch: 67 | Batch_idx: 170 |  Loss: (0.3108) |  Loss2: (0.0000) | Acc: (89.00%) (19577/21888)
Epoch: 67 | Batch_idx: 180 |  Loss: (0.3119) |  Loss2: (0.0000) | Acc: (89.00%) (20711/23168)
Epoch: 67 | Batch_idx: 190 |  Loss: (0.3099) |  Loss2: (0.0000) | Acc: (89.00%) (21876/24448)
Epoch: 67 | Batch_idx: 200 |  Loss: (0.3086) |  Loss2: (0.0000) | Acc: (89.00%) (23029/25728)
Epoch: 67 | Batch_idx: 210 |  Loss: (0.3091) |  Loss2: (0.0000) | Acc: (89.00%) (24164/27008)
Epoch: 67 | Batch_idx: 220 |  Loss: (0.3085) |  Loss2: (0.0000) | Acc: (89.00%) (25307/28288)
Epoch: 67 | Batch_idx: 230 |  Loss: (0.3091) |  Loss2: (0.0000) | Acc: (89.00%) (26446/29568)
Epoch: 67 | Batch_idx: 240 |  Loss: (0.3104) |  Loss2: (0.0000) | Acc: (89.00%) (27580/30848)
Epoch: 67 | Batch_idx: 250 |  Loss: (0.3116) |  Loss2: (0.0000) | Acc: (89.00%) (28707/32128)
Epoch: 67 | Batch_idx: 260 |  Loss: (0.3115) |  Loss2: (0.0000) | Acc: (89.00%) (29845/33408)
Epoch: 67 | Batch_idx: 270 |  Loss: (0.3112) |  Loss2: (0.0000) | Acc: (89.00%) (30991/34688)
Epoch: 67 | Batch_idx: 280 |  Loss: (0.3110) |  Loss2: (0.0000) | Acc: (89.00%) (32126/35968)
Epoch: 67 | Batch_idx: 290 |  Loss: (0.3112) |  Loss2: (0.0000) | Acc: (89.00%) (33270/37248)
Epoch: 67 | Batch_idx: 300 |  Loss: (0.3106) |  Loss2: (0.0000) | Acc: (89.00%) (34416/38528)
Epoch: 67 | Batch_idx: 310 |  Loss: (0.3084) |  Loss2: (0.0000) | Acc: (89.00%) (35587/39808)
Epoch: 67 | Batch_idx: 320 |  Loss: (0.3084) |  Loss2: (0.0000) | Acc: (89.00%) (36728/41088)
Epoch: 67 | Batch_idx: 330 |  Loss: (0.3077) |  Loss2: (0.0000) | Acc: (89.00%) (37881/42368)
Epoch: 67 | Batch_idx: 340 |  Loss: (0.3074) |  Loss2: (0.0000) | Acc: (89.00%) (39038/43648)
Epoch: 67 | Batch_idx: 350 |  Loss: (0.3077) |  Loss2: (0.0000) | Acc: (89.00%) (40184/44928)
Epoch: 67 | Batch_idx: 360 |  Loss: (0.3083) |  Loss2: (0.0000) | Acc: (89.00%) (41307/46208)
Epoch: 67 | Batch_idx: 370 |  Loss: (0.3086) |  Loss2: (0.0000) | Acc: (89.00%) (42438/47488)
Epoch: 67 | Batch_idx: 380 |  Loss: (0.3093) |  Loss2: (0.0000) | Acc: (89.00%) (43569/48768)
Epoch: 67 | Batch_idx: 390 |  Loss: (0.3097) |  Loss2: (0.0000) | Acc: (89.00%) (44656/50000)
# TEST : Loss: (0.4911) | Acc: (83.00%) (8364/10000)
percent tensor([0.5295, 0.5344, 0.5332, 0.5293, 0.5337, 0.5297, 0.5364, 0.5304, 0.5293,
        0.5334, 0.5318, 0.5364, 0.5320, 0.5281, 0.5341, 0.5308],
       device='cuda:0') torch.Size([16])
percent tensor([0.5191, 0.5211, 0.5117, 0.5167, 0.5133, 0.5228, 0.5183, 0.5130, 0.5148,
        0.5192, 0.5213, 0.5151, 0.5179, 0.5180, 0.5224, 0.5192],
       device='cuda:0') torch.Size([16])
percent tensor([0.5127, 0.3995, 0.6419, 0.6157, 0.6384, 0.5700, 0.5095, 0.6233, 0.5611,
        0.4677, 0.4225, 0.5778, 0.4334, 0.4650, 0.4710, 0.5241],
       device='cuda:0') torch.Size([16])
percent tensor([0.6718, 0.6945, 0.6045, 0.6213, 0.6162, 0.5959, 0.6718, 0.6285, 0.6664,
        0.6862, 0.7001, 0.6460, 0.6800, 0.6938, 0.6691, 0.6593],
       device='cuda:0') torch.Size([16])
percent tensor([0.6792, 0.5820, 0.7099, 0.7360, 0.7258, 0.6947, 0.6728, 0.7299, 0.6683,
        0.5835, 0.5826, 0.6422, 0.5679, 0.6687, 0.6663, 0.6873],
       device='cuda:0') torch.Size([16])
percent tensor([0.5042, 0.5280, 0.6092, 0.6705, 0.6741, 0.6932, 0.5606, 0.5493, 0.5749,
        0.4952, 0.5154, 0.5693, 0.5080, 0.5731, 0.5120, 0.5701],
       device='cuda:0') torch.Size([16])
percent tensor([0.6192, 0.6599, 0.6395, 0.6638, 0.6673, 0.7111, 0.6439, 0.5426, 0.6861,
        0.6734, 0.6952, 0.6263, 0.6462, 0.7055, 0.5744, 0.6032],
       device='cuda:0') torch.Size([16])
percent tensor([0.9994, 0.9990, 0.9995, 0.9997, 0.9998, 0.9981, 0.9992, 0.9998, 0.9989,
        0.9996, 0.9986, 0.9996, 0.9983, 0.9991, 0.9993, 0.9994],
       device='cuda:0') torch.Size([16])
Epoch: 68 | Batch_idx: 0 |  Loss: (0.2941) |  Loss2: (0.0000) | Acc: (89.00%) (114/128)
Epoch: 68 | Batch_idx: 10 |  Loss: (0.3070) |  Loss2: (0.0000) | Acc: (89.00%) (1264/1408)
Epoch: 68 | Batch_idx: 20 |  Loss: (0.2952) |  Loss2: (0.0000) | Acc: (90.00%) (2429/2688)
Epoch: 68 | Batch_idx: 30 |  Loss: (0.2905) |  Loss2: (0.0000) | Acc: (90.00%) (3597/3968)
Epoch: 68 | Batch_idx: 40 |  Loss: (0.2963) |  Loss2: (0.0000) | Acc: (90.00%) (4739/5248)
Epoch: 68 | Batch_idx: 50 |  Loss: (0.3039) |  Loss2: (0.0000) | Acc: (89.00%) (5869/6528)
Epoch: 68 | Batch_idx: 60 |  Loss: (0.3025) |  Loss2: (0.0000) | Acc: (89.00%) (7016/7808)
Epoch: 68 | Batch_idx: 70 |  Loss: (0.2997) |  Loss2: (0.0000) | Acc: (89.00%) (8173/9088)
Epoch: 68 | Batch_idx: 80 |  Loss: (0.2958) |  Loss2: (0.0000) | Acc: (90.00%) (9346/10368)
Epoch: 68 | Batch_idx: 90 |  Loss: (0.2931) |  Loss2: (0.0000) | Acc: (90.00%) (10502/11648)
Epoch: 68 | Batch_idx: 100 |  Loss: (0.2935) |  Loss2: (0.0000) | Acc: (90.00%) (11650/12928)
Epoch: 68 | Batch_idx: 110 |  Loss: (0.2944) |  Loss2: (0.0000) | Acc: (90.00%) (12798/14208)
Epoch: 68 | Batch_idx: 120 |  Loss: (0.2960) |  Loss2: (0.0000) | Acc: (89.00%) (13938/15488)
Epoch: 68 | Batch_idx: 130 |  Loss: (0.2969) |  Loss2: (0.0000) | Acc: (89.00%) (15074/16768)
Epoch: 68 | Batch_idx: 140 |  Loss: (0.2961) |  Loss2: (0.0000) | Acc: (89.00%) (16231/18048)
Epoch: 68 | Batch_idx: 150 |  Loss: (0.2962) |  Loss2: (0.0000) | Acc: (89.00%) (17381/19328)
Epoch: 68 | Batch_idx: 160 |  Loss: (0.2977) |  Loss2: (0.0000) | Acc: (89.00%) (18533/20608)
Epoch: 68 | Batch_idx: 170 |  Loss: (0.2964) |  Loss2: (0.0000) | Acc: (89.00%) (19698/21888)
Epoch: 68 | Batch_idx: 180 |  Loss: (0.2970) |  Loss2: (0.0000) | Acc: (89.00%) (20835/23168)
Epoch: 68 | Batch_idx: 190 |  Loss: (0.2989) |  Loss2: (0.0000) | Acc: (89.00%) (21967/24448)
Epoch: 68 | Batch_idx: 200 |  Loss: (0.2989) |  Loss2: (0.0000) | Acc: (89.00%) (23118/25728)
Epoch: 68 | Batch_idx: 210 |  Loss: (0.2992) |  Loss2: (0.0000) | Acc: (89.00%) (24263/27008)
Epoch: 68 | Batch_idx: 220 |  Loss: (0.2973) |  Loss2: (0.0000) | Acc: (89.00%) (25418/28288)
Epoch: 68 | Batch_idx: 230 |  Loss: (0.2984) |  Loss2: (0.0000) | Acc: (89.00%) (26548/29568)
Epoch: 68 | Batch_idx: 240 |  Loss: (0.2990) |  Loss2: (0.0000) | Acc: (89.00%) (27681/30848)
Epoch: 68 | Batch_idx: 250 |  Loss: (0.2995) |  Loss2: (0.0000) | Acc: (89.00%) (28821/32128)
Epoch: 68 | Batch_idx: 260 |  Loss: (0.3002) |  Loss2: (0.0000) | Acc: (89.00%) (29960/33408)
Epoch: 68 | Batch_idx: 270 |  Loss: (0.3010) |  Loss2: (0.0000) | Acc: (89.00%) (31092/34688)
Epoch: 68 | Batch_idx: 280 |  Loss: (0.3018) |  Loss2: (0.0000) | Acc: (89.00%) (32225/35968)
Epoch: 68 | Batch_idx: 290 |  Loss: (0.3020) |  Loss2: (0.0000) | Acc: (89.00%) (33368/37248)
Epoch: 68 | Batch_idx: 300 |  Loss: (0.3032) |  Loss2: (0.0000) | Acc: (89.00%) (34507/38528)
Epoch: 68 | Batch_idx: 310 |  Loss: (0.3032) |  Loss2: (0.0000) | Acc: (89.00%) (35651/39808)
Epoch: 68 | Batch_idx: 320 |  Loss: (0.3034) |  Loss2: (0.0000) | Acc: (89.00%) (36780/41088)
Epoch: 68 | Batch_idx: 330 |  Loss: (0.3034) |  Loss2: (0.0000) | Acc: (89.00%) (37929/42368)
Epoch: 68 | Batch_idx: 340 |  Loss: (0.3032) |  Loss2: (0.0000) | Acc: (89.00%) (39081/43648)
Epoch: 68 | Batch_idx: 350 |  Loss: (0.3032) |  Loss2: (0.0000) | Acc: (89.00%) (40229/44928)
Epoch: 68 | Batch_idx: 360 |  Loss: (0.3036) |  Loss2: (0.0000) | Acc: (89.00%) (41365/46208)
Epoch: 68 | Batch_idx: 370 |  Loss: (0.3039) |  Loss2: (0.0000) | Acc: (89.00%) (42501/47488)
Epoch: 68 | Batch_idx: 380 |  Loss: (0.3040) |  Loss2: (0.0000) | Acc: (89.00%) (43639/48768)
Epoch: 68 | Batch_idx: 390 |  Loss: (0.3047) |  Loss2: (0.0000) | Acc: (89.00%) (44732/50000)
# TEST : Loss: (0.4325) | Acc: (85.00%) (8550/10000)
percent tensor([0.5286, 0.5355, 0.5315, 0.5287, 0.5320, 0.5283, 0.5361, 0.5299, 0.5287,
        0.5333, 0.5315, 0.5346, 0.5315, 0.5300, 0.5337, 0.5305],
       device='cuda:0') torch.Size([16])
percent tensor([0.5191, 0.5212, 0.5124, 0.5168, 0.5138, 0.5220, 0.5185, 0.5137, 0.5150,
        0.5195, 0.5214, 0.5158, 0.5182, 0.5186, 0.5223, 0.5195],
       device='cuda:0') torch.Size([16])
percent tensor([0.5197, 0.3970, 0.6489, 0.6213, 0.6399, 0.5713, 0.5054, 0.6196, 0.5595,
        0.4677, 0.4192, 0.5731, 0.4293, 0.4393, 0.4674, 0.5275],
       device='cuda:0') torch.Size([16])
percent tensor([0.6723, 0.6907, 0.6053, 0.6224, 0.6123, 0.5982, 0.6681, 0.6301, 0.6669,
        0.6868, 0.7016, 0.6512, 0.6840, 0.6925, 0.6699, 0.6590],
       device='cuda:0') torch.Size([16])
percent tensor([0.6739, 0.5775, 0.7178, 0.7289, 0.7235, 0.6918, 0.6729, 0.7276, 0.6655,
        0.5718, 0.5681, 0.6353, 0.5510, 0.6880, 0.6608, 0.6800],
       device='cuda:0') torch.Size([16])
percent tensor([0.4800, 0.5237, 0.6007, 0.6603, 0.6658, 0.6701, 0.5572, 0.5342, 0.5764,
        0.4823, 0.5213, 0.5497, 0.4864, 0.5853, 0.4760, 0.5431],
       device='cuda:0') torch.Size([16])
percent tensor([0.6238, 0.6617, 0.6345, 0.6639, 0.6685, 0.6910, 0.6422, 0.5470, 0.6909,
        0.6816, 0.7130, 0.6448, 0.6581, 0.6978, 0.5776, 0.6017],
       device='cuda:0') torch.Size([16])
percent tensor([0.9996, 0.9991, 0.9996, 0.9996, 0.9998, 0.9979, 0.9996, 0.9998, 0.9990,
        0.9994, 0.9986, 0.9996, 0.9985, 0.9993, 0.9996, 0.9997],
       device='cuda:0') torch.Size([16])
False Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=128, out_features=16, bias=False)
True Linear(in_features=16, out_features=2, bias=False)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=128, out_features=16, bias=False)
True Linear(in_features=16, out_features=2, bias=False)
False Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=256, out_features=32, bias=False)
True Linear(in_features=32, out_features=2, bias=False)
False Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=256, out_features=32, bias=False)
True Linear(in_features=32, out_features=2, bias=False)
False Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=512, out_features=64, bias=False)
True Linear(in_features=64, out_features=2, bias=False)
False Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=512, out_features=64, bias=False)
True Linear(in_features=64, out_features=2, bias=False)
False Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1024, out_features=128, bias=False)
True Linear(in_features=128, out_features=2, bias=False)
False Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1024, out_features=128, bias=False)
True Linear(in_features=128, out_features=2, bias=False)
False Linear(in_features=512, out_features=10, bias=True)
Epoch: 69 | Batch_idx: 0 |  Loss: (0.3457) |  Loss2: (0.0000) | Acc: (88.00%) (113/128)
Epoch: 69 | Batch_idx: 10 |  Loss: (0.3211) |  Loss2: (0.0000) | Acc: (89.00%) (1256/1408)
Epoch: 69 | Batch_idx: 20 |  Loss: (0.3080) |  Loss2: (0.0000) | Acc: (89.00%) (2405/2688)
Epoch: 69 | Batch_idx: 30 |  Loss: (0.3351) |  Loss2: (0.0000) | Acc: (88.00%) (3515/3968)
Epoch: 69 | Batch_idx: 40 |  Loss: (0.3385) |  Loss2: (0.0000) | Acc: (88.00%) (4656/5248)
Epoch: 69 | Batch_idx: 50 |  Loss: (0.3412) |  Loss2: (0.0000) | Acc: (88.00%) (5772/6528)
Epoch: 69 | Batch_idx: 60 |  Loss: (0.3453) |  Loss2: (0.0000) | Acc: (88.00%) (6885/7808)
Epoch: 69 | Batch_idx: 70 |  Loss: (0.3452) |  Loss2: (0.0000) | Acc: (88.00%) (8010/9088)
Epoch: 69 | Batch_idx: 80 |  Loss: (0.3468) |  Loss2: (0.0000) | Acc: (88.00%) (9134/10368)
Epoch: 69 | Batch_idx: 90 |  Loss: (0.3474) |  Loss2: (0.0000) | Acc: (88.00%) (10257/11648)
Epoch: 69 | Batch_idx: 100 |  Loss: (0.3519) |  Loss2: (0.0000) | Acc: (87.00%) (11364/12928)
Epoch: 69 | Batch_idx: 110 |  Loss: (0.3505) |  Loss2: (0.0000) | Acc: (87.00%) (12492/14208)
Epoch: 69 | Batch_idx: 120 |  Loss: (0.3512) |  Loss2: (0.0000) | Acc: (87.00%) (13608/15488)
Epoch: 69 | Batch_idx: 130 |  Loss: (0.3488) |  Loss2: (0.0000) | Acc: (87.00%) (14743/16768)
Epoch: 69 | Batch_idx: 140 |  Loss: (0.3501) |  Loss2: (0.0000) | Acc: (87.00%) (15858/18048)
Epoch: 69 | Batch_idx: 150 |  Loss: (0.3505) |  Loss2: (0.0000) | Acc: (87.00%) (16973/19328)
Epoch: 69 | Batch_idx: 160 |  Loss: (0.3482) |  Loss2: (0.0000) | Acc: (87.00%) (18103/20608)
Epoch: 69 | Batch_idx: 170 |  Loss: (0.3488) |  Loss2: (0.0000) | Acc: (87.00%) (19214/21888)
Epoch: 69 | Batch_idx: 180 |  Loss: (0.3478) |  Loss2: (0.0000) | Acc: (87.00%) (20335/23168)
Epoch: 69 | Batch_idx: 190 |  Loss: (0.3465) |  Loss2: (0.0000) | Acc: (87.00%) (21467/24448)
Epoch: 69 | Batch_idx: 200 |  Loss: (0.3462) |  Loss2: (0.0000) | Acc: (87.00%) (22590/25728)
Epoch: 69 | Batch_idx: 210 |  Loss: (0.3464) |  Loss2: (0.0000) | Acc: (87.00%) (23708/27008)
Epoch: 69 | Batch_idx: 220 |  Loss: (0.3456) |  Loss2: (0.0000) | Acc: (87.00%) (24838/28288)
Epoch: 69 | Batch_idx: 230 |  Loss: (0.3461) |  Loss2: (0.0000) | Acc: (87.00%) (25966/29568)
Epoch: 69 | Batch_idx: 240 |  Loss: (0.3454) |  Loss2: (0.0000) | Acc: (87.00%) (27103/30848)
Epoch: 69 | Batch_idx: 250 |  Loss: (0.3448) |  Loss2: (0.0000) | Acc: (87.00%) (28243/32128)
Epoch: 69 | Batch_idx: 260 |  Loss: (0.3445) |  Loss2: (0.0000) | Acc: (87.00%) (29367/33408)
Epoch: 69 | Batch_idx: 270 |  Loss: (0.3439) |  Loss2: (0.0000) | Acc: (87.00%) (30504/34688)
Epoch: 69 | Batch_idx: 280 |  Loss: (0.3431) |  Loss2: (0.0000) | Acc: (87.00%) (31638/35968)
Epoch: 69 | Batch_idx: 290 |  Loss: (0.3420) |  Loss2: (0.0000) | Acc: (88.00%) (32790/37248)
Epoch: 69 | Batch_idx: 300 |  Loss: (0.3415) |  Loss2: (0.0000) | Acc: (88.00%) (33919/38528)
Epoch: 69 | Batch_idx: 310 |  Loss: (0.3414) |  Loss2: (0.0000) | Acc: (88.00%) (35039/39808)
Epoch: 69 | Batch_idx: 320 |  Loss: (0.3404) |  Loss2: (0.0000) | Acc: (88.00%) (36186/41088)
Epoch: 69 | Batch_idx: 330 |  Loss: (0.3400) |  Loss2: (0.0000) | Acc: (88.00%) (37331/42368)
Epoch: 69 | Batch_idx: 340 |  Loss: (0.3386) |  Loss2: (0.0000) | Acc: (88.00%) (38480/43648)
Epoch: 69 | Batch_idx: 350 |  Loss: (0.3381) |  Loss2: (0.0000) | Acc: (88.00%) (39624/44928)
Epoch: 69 | Batch_idx: 360 |  Loss: (0.3367) |  Loss2: (0.0000) | Acc: (88.00%) (40783/46208)
Epoch: 69 | Batch_idx: 370 |  Loss: (0.3362) |  Loss2: (0.0000) | Acc: (88.00%) (41917/47488)
Epoch: 69 | Batch_idx: 380 |  Loss: (0.3368) |  Loss2: (0.0000) | Acc: (88.00%) (43043/48768)
Epoch: 69 | Batch_idx: 390 |  Loss: (0.3367) |  Loss2: (0.0000) | Acc: (88.00%) (44142/50000)
# TEST : Loss: (0.4269) | Acc: (85.00%) (8583/10000)
percent tensor([0.5321, 0.5399, 0.5328, 0.5318, 0.5339, 0.5334, 0.5396, 0.5322, 0.5311,
        0.5365, 0.5354, 0.5364, 0.5348, 0.5332, 0.5385, 0.5346],
       device='cuda:0') torch.Size([16])
percent tensor([0.5148, 0.5169, 0.5087, 0.5129, 0.5084, 0.5175, 0.5136, 0.5094, 0.5114,
        0.5155, 0.5171, 0.5124, 0.5143, 0.5148, 0.5173, 0.5150],
       device='cuda:0') torch.Size([16])
percent tensor([0.5057, 0.3725, 0.6321, 0.6074, 0.6252, 0.5584, 0.4796, 0.5997, 0.5349,
        0.4442, 0.3956, 0.5447, 0.4075, 0.4141, 0.4578, 0.5125],
       device='cuda:0') torch.Size([16])
percent tensor([0.6892, 0.7164, 0.6167, 0.6395, 0.6256, 0.6063, 0.6894, 0.6515, 0.6892,
        0.7107, 0.7259, 0.6738, 0.7044, 0.7213, 0.6877, 0.6767],
       device='cuda:0') torch.Size([16])
percent tensor([0.6753, 0.5691, 0.7161, 0.7116, 0.7210, 0.6951, 0.6667, 0.7294, 0.6494,
        0.5632, 0.5547, 0.6229, 0.5591, 0.6573, 0.6615, 0.6764],
       device='cuda:0') torch.Size([16])
percent tensor([0.4806, 0.5219, 0.6002, 0.6619, 0.6530, 0.6609, 0.5545, 0.5051, 0.5798,
        0.4898, 0.5206, 0.5538, 0.4948, 0.5891, 0.4602, 0.5314],
       device='cuda:0') torch.Size([16])
percent tensor([0.6243, 0.6718, 0.6414, 0.6720, 0.6589, 0.6587, 0.6434, 0.5451, 0.6926,
        0.6918, 0.7207, 0.6638, 0.6565, 0.7200, 0.5860, 0.5989],
       device='cuda:0') torch.Size([16])
percent tensor([0.9995, 0.9990, 0.9997, 0.9997, 0.9998, 0.9984, 0.9995, 0.9998, 0.9989,
        0.9993, 0.9989, 0.9997, 0.9985, 0.9993, 0.9995, 0.9995],
       device='cuda:0') torch.Size([16])
Epoch: 70 | Batch_idx: 0 |  Loss: (0.3459) |  Loss2: (0.0000) | Acc: (89.00%) (115/128)
Epoch: 70 | Batch_idx: 10 |  Loss: (0.3423) |  Loss2: (0.0000) | Acc: (88.00%) (1240/1408)
Epoch: 70 | Batch_idx: 20 |  Loss: (0.3447) |  Loss2: (0.0000) | Acc: (88.00%) (2367/2688)
Epoch: 70 | Batch_idx: 30 |  Loss: (0.3280) |  Loss2: (0.0000) | Acc: (88.00%) (3517/3968)
Epoch: 70 | Batch_idx: 40 |  Loss: (0.3207) |  Loss2: (0.0000) | Acc: (88.00%) (4663/5248)
Epoch: 70 | Batch_idx: 50 |  Loss: (0.3228) |  Loss2: (0.0000) | Acc: (88.00%) (5800/6528)
Epoch: 70 | Batch_idx: 60 |  Loss: (0.3195) |  Loss2: (0.0000) | Acc: (88.00%) (6945/7808)
Epoch: 70 | Batch_idx: 70 |  Loss: (0.3226) |  Loss2: (0.0000) | Acc: (88.00%) (8075/9088)
Epoch: 70 | Batch_idx: 80 |  Loss: (0.3249) |  Loss2: (0.0000) | Acc: (88.00%) (9202/10368)
Epoch: 70 | Batch_idx: 90 |  Loss: (0.3258) |  Loss2: (0.0000) | Acc: (88.00%) (10325/11648)
Epoch: 70 | Batch_idx: 100 |  Loss: (0.3245) |  Loss2: (0.0000) | Acc: (88.00%) (11472/12928)
Epoch: 70 | Batch_idx: 110 |  Loss: (0.3255) |  Loss2: (0.0000) | Acc: (88.00%) (12604/14208)
Epoch: 70 | Batch_idx: 120 |  Loss: (0.3227) |  Loss2: (0.0000) | Acc: (88.00%) (13755/15488)
Epoch: 70 | Batch_idx: 130 |  Loss: (0.3225) |  Loss2: (0.0000) | Acc: (88.00%) (14891/16768)
Epoch: 70 | Batch_idx: 140 |  Loss: (0.3225) |  Loss2: (0.0000) | Acc: (88.00%) (16033/18048)
Epoch: 70 | Batch_idx: 150 |  Loss: (0.3213) |  Loss2: (0.0000) | Acc: (88.00%) (17185/19328)
Epoch: 70 | Batch_idx: 160 |  Loss: (0.3190) |  Loss2: (0.0000) | Acc: (88.00%) (18340/20608)
Epoch: 70 | Batch_idx: 170 |  Loss: (0.3200) |  Loss2: (0.0000) | Acc: (88.00%) (19470/21888)
Epoch: 70 | Batch_idx: 180 |  Loss: (0.3203) |  Loss2: (0.0000) | Acc: (88.00%) (20606/23168)
Epoch: 70 | Batch_idx: 190 |  Loss: (0.3209) |  Loss2: (0.0000) | Acc: (88.00%) (21740/24448)
Epoch: 70 | Batch_idx: 200 |  Loss: (0.3199) |  Loss2: (0.0000) | Acc: (88.00%) (22880/25728)
Epoch: 70 | Batch_idx: 210 |  Loss: (0.3197) |  Loss2: (0.0000) | Acc: (88.00%) (24024/27008)
Epoch: 70 | Batch_idx: 220 |  Loss: (0.3182) |  Loss2: (0.0000) | Acc: (89.00%) (25183/28288)
Epoch: 70 | Batch_idx: 230 |  Loss: (0.3169) |  Loss2: (0.0000) | Acc: (89.00%) (26345/29568)
Epoch: 70 | Batch_idx: 240 |  Loss: (0.3160) |  Loss2: (0.0000) | Acc: (89.00%) (27498/30848)
Epoch: 70 | Batch_idx: 250 |  Loss: (0.3143) |  Loss2: (0.0000) | Acc: (89.00%) (28658/32128)
Epoch: 70 | Batch_idx: 260 |  Loss: (0.3137) |  Loss2: (0.0000) | Acc: (89.00%) (29815/33408)
Epoch: 70 | Batch_idx: 270 |  Loss: (0.3142) |  Loss2: (0.0000) | Acc: (89.00%) (30952/34688)
Epoch: 70 | Batch_idx: 280 |  Loss: (0.3137) |  Loss2: (0.0000) | Acc: (89.00%) (32093/35968)
Epoch: 70 | Batch_idx: 290 |  Loss: (0.3141) |  Loss2: (0.0000) | Acc: (89.00%) (33228/37248)
Epoch: 70 | Batch_idx: 300 |  Loss: (0.3127) |  Loss2: (0.0000) | Acc: (89.00%) (34393/38528)
Epoch: 70 | Batch_idx: 310 |  Loss: (0.3116) |  Loss2: (0.0000) | Acc: (89.00%) (35547/39808)
Epoch: 70 | Batch_idx: 320 |  Loss: (0.3108) |  Loss2: (0.0000) | Acc: (89.00%) (36696/41088)
Epoch: 70 | Batch_idx: 330 |  Loss: (0.3113) |  Loss2: (0.0000) | Acc: (89.00%) (37835/42368)
Epoch: 70 | Batch_idx: 340 |  Loss: (0.3113) |  Loss2: (0.0000) | Acc: (89.00%) (38971/43648)
Epoch: 70 | Batch_idx: 350 |  Loss: (0.3107) |  Loss2: (0.0000) | Acc: (89.00%) (40118/44928)
Epoch: 70 | Batch_idx: 360 |  Loss: (0.3107) |  Loss2: (0.0000) | Acc: (89.00%) (41269/46208)
Epoch: 70 | Batch_idx: 370 |  Loss: (0.3109) |  Loss2: (0.0000) | Acc: (89.00%) (42407/47488)
Epoch: 70 | Batch_idx: 380 |  Loss: (0.3103) |  Loss2: (0.0000) | Acc: (89.00%) (43559/48768)
Epoch: 70 | Batch_idx: 390 |  Loss: (0.3101) |  Loss2: (0.0000) | Acc: (89.00%) (44663/50000)
=> saving checkpoint 'drive/app/torch/save_Schedule/checkpoint_070.pth.tar'
# TEST : Loss: (0.4114) | Acc: (86.00%) (8635/10000)
percent tensor([0.5323, 0.5400, 0.5324, 0.5319, 0.5336, 0.5349, 0.5396, 0.5316, 0.5307,
        0.5362, 0.5356, 0.5359, 0.5347, 0.5326, 0.5394, 0.5350],
       device='cuda:0') torch.Size([16])
percent tensor([0.5131, 0.5154, 0.5070, 0.5113, 0.5062, 0.5160, 0.5114, 0.5072, 0.5098,
        0.5140, 0.5154, 0.5110, 0.5126, 0.5133, 0.5155, 0.5136],
       device='cuda:0') torch.Size([16])
percent tensor([0.5127, 0.3764, 0.6286, 0.6075, 0.6232, 0.5671, 0.4833, 0.5990, 0.5388,
        0.4460, 0.3999, 0.5429, 0.4106, 0.4257, 0.4655, 0.5213],
       device='cuda:0') torch.Size([16])
percent tensor([0.6914, 0.7216, 0.6177, 0.6415, 0.6273, 0.5994, 0.6929, 0.6531, 0.6947,
        0.7170, 0.7323, 0.6780, 0.7078, 0.7283, 0.6882, 0.6773],
       device='cuda:0') torch.Size([16])
percent tensor([0.6958, 0.5832, 0.7353, 0.7282, 0.7403, 0.7213, 0.6819, 0.7466, 0.6626,
        0.5775, 0.5661, 0.6389, 0.5794, 0.6625, 0.6810, 0.7003],
       device='cuda:0') torch.Size([16])
percent tensor([0.4972, 0.5434, 0.6165, 0.6773, 0.6663, 0.6727, 0.5707, 0.5158, 0.5998,
        0.5144, 0.5444, 0.5732, 0.5160, 0.6090, 0.4761, 0.5455],
       device='cuda:0') torch.Size([16])
percent tensor([0.6296, 0.6790, 0.6528, 0.6831, 0.6687, 0.6533, 0.6555, 0.5544, 0.7038,
        0.7022, 0.7340, 0.6776, 0.6624, 0.7403, 0.5958, 0.6028],
       device='cuda:0') torch.Size([16])
percent tensor([0.9996, 0.9991, 0.9996, 0.9997, 0.9998, 0.9985, 0.9995, 0.9998, 0.9989,
        0.9994, 0.9990, 0.9997, 0.9986, 0.9994, 0.9996, 0.9996],
       device='cuda:0') torch.Size([16])
Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 3, 3, 3]) tensor(177.7593, device='cuda:0')
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(801.2780, device='cuda:0')
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(802.9647, device='cuda:0')
Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([128, 64, 3, 3]) tensor(1521.2738, device='cuda:0')
Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([128, 64, 1, 1]) tensor(504.4894, device='cuda:0')
Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([128, 128, 3, 3]) tensor(2214.0615, device='cuda:0')
Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([256, 128, 3, 3]) tensor(4294.4351, device='cuda:0')
Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([256, 128, 1, 1]) tensor(1418.7756, device='cuda:0')
Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([256, 256, 3, 3]) tensor(6109., device='cuda:0')
Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([512, 256, 3, 3]) tensor(11984.8174, device='cuda:0')
Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([512, 256, 1, 1]) tensor(3989.3730, device='cuda:0')
Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([512, 512, 3, 3]) tensor(16835.7676, device='cuda:0')
Epoch: 71 | Batch_idx: 0 |  Loss: (0.3299) |  Loss2: (0.0000) | Acc: (87.00%) (112/128)
Epoch: 71 | Batch_idx: 10 |  Loss: (0.3088) |  Loss2: (0.0000) | Acc: (89.00%) (1263/1408)
Epoch: 71 | Batch_idx: 20 |  Loss: (0.3124) |  Loss2: (0.0000) | Acc: (88.00%) (2392/2688)
Epoch: 71 | Batch_idx: 30 |  Loss: (0.3059) |  Loss2: (0.0000) | Acc: (89.00%) (3548/3968)
Epoch: 71 | Batch_idx: 40 |  Loss: (0.3002) |  Loss2: (0.0000) | Acc: (89.00%) (4710/5248)
Epoch: 71 | Batch_idx: 50 |  Loss: (0.2967) |  Loss2: (0.0000) | Acc: (89.00%) (5869/6528)
Epoch: 71 | Batch_idx: 60 |  Loss: (0.2983) |  Loss2: (0.0000) | Acc: (89.00%) (7008/7808)
Epoch: 71 | Batch_idx: 70 |  Loss: (0.2961) |  Loss2: (0.0000) | Acc: (89.00%) (8157/9088)
Epoch: 71 | Batch_idx: 80 |  Loss: (0.2963) |  Loss2: (0.0000) | Acc: (89.00%) (9311/10368)
Epoch: 71 | Batch_idx: 90 |  Loss: (0.2964) |  Loss2: (0.0000) | Acc: (89.00%) (10464/11648)
Epoch: 71 | Batch_idx: 100 |  Loss: (0.2939) |  Loss2: (0.0000) | Acc: (89.00%) (11633/12928)
Epoch: 71 | Batch_idx: 110 |  Loss: (0.2957) |  Loss2: (0.0000) | Acc: (89.00%) (12771/14208)
Epoch: 71 | Batch_idx: 120 |  Loss: (0.2970) |  Loss2: (0.0000) | Acc: (89.00%) (13910/15488)
Epoch: 71 | Batch_idx: 130 |  Loss: (0.2985) |  Loss2: (0.0000) | Acc: (89.00%) (15057/16768)
Epoch: 71 | Batch_idx: 140 |  Loss: (0.3001) |  Loss2: (0.0000) | Acc: (89.00%) (16204/18048)
Epoch: 71 | Batch_idx: 150 |  Loss: (0.2998) |  Loss2: (0.0000) | Acc: (89.00%) (17357/19328)
Epoch: 71 | Batch_idx: 160 |  Loss: (0.3007) |  Loss2: (0.0000) | Acc: (89.00%) (18496/20608)
Epoch: 71 | Batch_idx: 170 |  Loss: (0.3019) |  Loss2: (0.0000) | Acc: (89.00%) (19641/21888)
Epoch: 71 | Batch_idx: 180 |  Loss: (0.3000) |  Loss2: (0.0000) | Acc: (89.00%) (20801/23168)
Epoch: 71 | Batch_idx: 190 |  Loss: (0.3009) |  Loss2: (0.0000) | Acc: (89.00%) (21955/24448)
Epoch: 71 | Batch_idx: 200 |  Loss: (0.3013) |  Loss2: (0.0000) | Acc: (89.00%) (23093/25728)
Epoch: 71 | Batch_idx: 210 |  Loss: (0.3026) |  Loss2: (0.0000) | Acc: (89.00%) (24224/27008)
Epoch: 71 | Batch_idx: 220 |  Loss: (0.3016) |  Loss2: (0.0000) | Acc: (89.00%) (25367/28288)
Epoch: 71 | Batch_idx: 230 |  Loss: (0.3018) |  Loss2: (0.0000) | Acc: (89.00%) (26519/29568)
Epoch: 71 | Batch_idx: 240 |  Loss: (0.3012) |  Loss2: (0.0000) | Acc: (89.00%) (27676/30848)
Epoch: 71 | Batch_idx: 250 |  Loss: (0.3018) |  Loss2: (0.0000) | Acc: (89.00%) (28816/32128)
Epoch: 71 | Batch_idx: 260 |  Loss: (0.3035) |  Loss2: (0.0000) | Acc: (89.00%) (29950/33408)
Epoch: 71 | Batch_idx: 270 |  Loss: (0.3040) |  Loss2: (0.0000) | Acc: (89.00%) (31090/34688)
Epoch: 71 | Batch_idx: 280 |  Loss: (0.3028) |  Loss2: (0.0000) | Acc: (89.00%) (32247/35968)
Epoch: 71 | Batch_idx: 290 |  Loss: (0.3015) |  Loss2: (0.0000) | Acc: (89.00%) (33414/37248)
Epoch: 71 | Batch_idx: 300 |  Loss: (0.3013) |  Loss2: (0.0000) | Acc: (89.00%) (34562/38528)
Epoch: 71 | Batch_idx: 310 |  Loss: (0.3009) |  Loss2: (0.0000) | Acc: (89.00%) (35729/39808)
Epoch: 71 | Batch_idx: 320 |  Loss: (0.3000) |  Loss2: (0.0000) | Acc: (89.00%) (36898/41088)
Epoch: 71 | Batch_idx: 330 |  Loss: (0.2998) |  Loss2: (0.0000) | Acc: (89.00%) (38045/42368)
Epoch: 71 | Batch_idx: 340 |  Loss: (0.3002) |  Loss2: (0.0000) | Acc: (89.00%) (39184/43648)
Epoch: 71 | Batch_idx: 350 |  Loss: (0.3001) |  Loss2: (0.0000) | Acc: (89.00%) (40327/44928)
Epoch: 71 | Batch_idx: 360 |  Loss: (0.2997) |  Loss2: (0.0000) | Acc: (89.00%) (41491/46208)
Epoch: 71 | Batch_idx: 370 |  Loss: (0.3002) |  Loss2: (0.0000) | Acc: (89.00%) (42634/47488)
Epoch: 71 | Batch_idx: 380 |  Loss: (0.2995) |  Loss2: (0.0000) | Acc: (89.00%) (43786/48768)
Epoch: 71 | Batch_idx: 390 |  Loss: (0.2993) |  Loss2: (0.0000) | Acc: (89.00%) (44891/50000)
# TEST : Loss: (0.4008) | Acc: (86.00%) (8671/10000)
percent tensor([0.5343, 0.5421, 0.5340, 0.5338, 0.5355, 0.5378, 0.5417, 0.5330, 0.5323,
        0.5380, 0.5377, 0.5377, 0.5366, 0.5340, 0.5420, 0.5371],
       device='cuda:0') torch.Size([16])
percent tensor([0.5126, 0.5148, 0.5065, 0.5107, 0.5056, 0.5155, 0.5109, 0.5067, 0.5093,
        0.5136, 0.5148, 0.5105, 0.5123, 0.5128, 0.5149, 0.5132],
       device='cuda:0') torch.Size([16])
percent tensor([0.5138, 0.3771, 0.6261, 0.6060, 0.6228, 0.5679, 0.4847, 0.5978, 0.5400,
        0.4461, 0.4012, 0.5399, 0.4102, 0.4312, 0.4675, 0.5228],
       device='cuda:0') torch.Size([16])
percent tensor([0.6870, 0.7195, 0.6124, 0.6381, 0.6216, 0.5882, 0.6886, 0.6468, 0.6920,
        0.7152, 0.7310, 0.6743, 0.7041, 0.7269, 0.6815, 0.6717],
       device='cuda:0') torch.Size([16])
percent tensor([0.6950, 0.5820, 0.7351, 0.7260, 0.7400, 0.7258, 0.6800, 0.7442, 0.6607,
        0.5767, 0.5654, 0.6387, 0.5817, 0.6572, 0.6803, 0.7019],
       device='cuda:0') torch.Size([16])
percent tensor([0.4999, 0.5502, 0.6202, 0.6795, 0.6674, 0.6757, 0.5742, 0.5164, 0.6065,
        0.5236, 0.5526, 0.5801, 0.5240, 0.6163, 0.4791, 0.5458],
       device='cuda:0') torch.Size([16])
percent tensor([0.6368, 0.6888, 0.6625, 0.6917, 0.6767, 0.6533, 0.6645, 0.5651, 0.7153,
        0.7132, 0.7464, 0.6882, 0.6714, 0.7544, 0.6031, 0.6067],
       device='cuda:0') torch.Size([16])
percent tensor([0.9996, 0.9992, 0.9996, 0.9996, 0.9998, 0.9985, 0.9995, 0.9998, 0.9990,
        0.9994, 0.9991, 0.9997, 0.9986, 0.9995, 0.9996, 0.9996],
       device='cuda:0') torch.Size([16])
True Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=128, out_features=16, bias=False)
False Linear(in_features=16, out_features=2, bias=False)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=128, out_features=16, bias=False)
False Linear(in_features=16, out_features=2, bias=False)
True Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=256, out_features=32, bias=False)
False Linear(in_features=32, out_features=2, bias=False)
True Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=256, out_features=32, bias=False)
False Linear(in_features=32, out_features=2, bias=False)
True Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=512, out_features=64, bias=False)
False Linear(in_features=64, out_features=2, bias=False)
True Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=512, out_features=64, bias=False)
False Linear(in_features=64, out_features=2, bias=False)
True Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1024, out_features=128, bias=False)
False Linear(in_features=128, out_features=2, bias=False)
True Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1024, out_features=128, bias=False)
False Linear(in_features=128, out_features=2, bias=False)
True Linear(in_features=512, out_features=10, bias=True)
Epoch: 72 | Batch_idx: 0 |  Loss: (0.3146) |  Loss2: (0.0000) | Acc: (90.00%) (116/128)
Epoch: 72 | Batch_idx: 10 |  Loss: (0.3007) |  Loss2: (0.0000) | Acc: (89.00%) (1266/1408)
Epoch: 72 | Batch_idx: 20 |  Loss: (0.3007) |  Loss2: (0.0000) | Acc: (89.00%) (2413/2688)
Epoch: 72 | Batch_idx: 30 |  Loss: (0.2978) |  Loss2: (0.0000) | Acc: (89.00%) (3558/3968)
Epoch: 72 | Batch_idx: 40 |  Loss: (0.2971) |  Loss2: (0.0000) | Acc: (89.00%) (4704/5248)
Epoch: 72 | Batch_idx: 50 |  Loss: (0.2934) |  Loss2: (0.0000) | Acc: (89.00%) (5867/6528)
Epoch: 72 | Batch_idx: 60 |  Loss: (0.2954) |  Loss2: (0.0000) | Acc: (89.00%) (7012/7808)
Epoch: 72 | Batch_idx: 70 |  Loss: (0.2921) |  Loss2: (0.0000) | Acc: (89.00%) (8174/9088)
Epoch: 72 | Batch_idx: 80 |  Loss: (0.2864) |  Loss2: (0.0000) | Acc: (90.00%) (9351/10368)
Epoch: 72 | Batch_idx: 90 |  Loss: (0.2908) |  Loss2: (0.0000) | Acc: (90.00%) (10487/11648)
Epoch: 72 | Batch_idx: 100 |  Loss: (0.2879) |  Loss2: (0.0000) | Acc: (90.00%) (11661/12928)
Epoch: 72 | Batch_idx: 110 |  Loss: (0.2879) |  Loss2: (0.0000) | Acc: (90.00%) (12800/14208)
Epoch: 72 | Batch_idx: 120 |  Loss: (0.2873) |  Loss2: (0.0000) | Acc: (90.00%) (13958/15488)
Epoch: 72 | Batch_idx: 130 |  Loss: (0.2875) |  Loss2: (0.0000) | Acc: (90.00%) (15106/16768)
Epoch: 72 | Batch_idx: 140 |  Loss: (0.2906) |  Loss2: (0.0000) | Acc: (90.00%) (16245/18048)
Epoch: 72 | Batch_idx: 150 |  Loss: (0.2890) |  Loss2: (0.0000) | Acc: (90.00%) (17410/19328)
Epoch: 72 | Batch_idx: 160 |  Loss: (0.2901) |  Loss2: (0.0000) | Acc: (90.00%) (18559/20608)
Epoch: 72 | Batch_idx: 170 |  Loss: (0.2923) |  Loss2: (0.0000) | Acc: (89.00%) (19687/21888)
Epoch: 72 | Batch_idx: 180 |  Loss: (0.2940) |  Loss2: (0.0000) | Acc: (89.00%) (20819/23168)
Epoch: 72 | Batch_idx: 190 |  Loss: (0.2939) |  Loss2: (0.0000) | Acc: (89.00%) (21971/24448)
Epoch: 72 | Batch_idx: 200 |  Loss: (0.2933) |  Loss2: (0.0000) | Acc: (89.00%) (23122/25728)
Epoch: 72 | Batch_idx: 210 |  Loss: (0.2936) |  Loss2: (0.0000) | Acc: (89.00%) (24269/27008)
Epoch: 72 | Batch_idx: 220 |  Loss: (0.2939) |  Loss2: (0.0000) | Acc: (89.00%) (25422/28288)
Epoch: 72 | Batch_idx: 230 |  Loss: (0.2933) |  Loss2: (0.0000) | Acc: (89.00%) (26582/29568)
Epoch: 72 | Batch_idx: 240 |  Loss: (0.2939) |  Loss2: (0.0000) | Acc: (89.00%) (27730/30848)
Epoch: 72 | Batch_idx: 250 |  Loss: (0.2951) |  Loss2: (0.0000) | Acc: (89.00%) (28860/32128)
Epoch: 72 | Batch_idx: 260 |  Loss: (0.2958) |  Loss2: (0.0000) | Acc: (89.00%) (29994/33408)
Epoch: 72 | Batch_idx: 270 |  Loss: (0.2942) |  Loss2: (0.0000) | Acc: (89.00%) (31164/34688)
Epoch: 72 | Batch_idx: 280 |  Loss: (0.2955) |  Loss2: (0.0000) | Acc: (89.00%) (32295/35968)
Epoch: 72 | Batch_idx: 290 |  Loss: (0.2968) |  Loss2: (0.0000) | Acc: (89.00%) (33431/37248)
Epoch: 72 | Batch_idx: 300 |  Loss: (0.2966) |  Loss2: (0.0000) | Acc: (89.00%) (34594/38528)
Epoch: 72 | Batch_idx: 310 |  Loss: (0.2970) |  Loss2: (0.0000) | Acc: (89.00%) (35745/39808)
Epoch: 72 | Batch_idx: 320 |  Loss: (0.2979) |  Loss2: (0.0000) | Acc: (89.00%) (36880/41088)
Epoch: 72 | Batch_idx: 330 |  Loss: (0.2975) |  Loss2: (0.0000) | Acc: (89.00%) (38035/42368)
Epoch: 72 | Batch_idx: 340 |  Loss: (0.2976) |  Loss2: (0.0000) | Acc: (89.00%) (39185/43648)
Epoch: 72 | Batch_idx: 350 |  Loss: (0.2969) |  Loss2: (0.0000) | Acc: (89.00%) (40340/44928)
Epoch: 72 | Batch_idx: 360 |  Loss: (0.2968) |  Loss2: (0.0000) | Acc: (89.00%) (41489/46208)
Epoch: 72 | Batch_idx: 370 |  Loss: (0.2969) |  Loss2: (0.0000) | Acc: (89.00%) (42638/47488)
Epoch: 72 | Batch_idx: 380 |  Loss: (0.2967) |  Loss2: (0.0000) | Acc: (89.00%) (43793/48768)
Epoch: 72 | Batch_idx: 390 |  Loss: (0.2974) |  Loss2: (0.0000) | Acc: (89.00%) (44889/50000)
# TEST : Loss: (0.4349) | Acc: (85.00%) (8571/10000)
percent tensor([0.5349, 0.5399, 0.5369, 0.5344, 0.5380, 0.5373, 0.5412, 0.5337, 0.5332,
        0.5376, 0.5373, 0.5399, 0.5370, 0.5308, 0.5413, 0.5365],
       device='cuda:0') torch.Size([16])
percent tensor([0.5122, 0.5145, 0.5059, 0.5092, 0.5050, 0.5152, 0.5104, 0.5065, 0.5091,
        0.5131, 0.5150, 0.5094, 0.5121, 0.5119, 0.5145, 0.5126],
       device='cuda:0') torch.Size([16])
percent tensor([0.4989, 0.3774, 0.6179, 0.6021, 0.6160, 0.5618, 0.4859, 0.5971, 0.5372,
        0.4522, 0.3960, 0.5406, 0.4048, 0.4475, 0.4570, 0.5202],
       device='cuda:0') torch.Size([16])
percent tensor([0.6943, 0.7184, 0.6216, 0.6402, 0.6379, 0.5926, 0.6944, 0.6461, 0.7011,
        0.7162, 0.7366, 0.6773, 0.7091, 0.7271, 0.6858, 0.6771],
       device='cuda:0') torch.Size([16])
percent tensor([0.6897, 0.5858, 0.7192, 0.7346, 0.7312, 0.7325, 0.6690, 0.7354, 0.6538,
        0.5794, 0.5626, 0.6274, 0.5679, 0.6496, 0.6786, 0.7047],
       device='cuda:0') torch.Size([16])
percent tensor([0.4890, 0.5398, 0.5974, 0.6541, 0.6512, 0.6805, 0.5612, 0.5143, 0.5954,
        0.5266, 0.5532, 0.5727, 0.5215, 0.5963, 0.4911, 0.5563],
       device='cuda:0') torch.Size([16])
percent tensor([0.6261, 0.6804, 0.6557, 0.6840, 0.6840, 0.6636, 0.6529, 0.5729, 0.7133,
        0.7122, 0.7331, 0.6931, 0.6691, 0.7485, 0.5954, 0.5994],
       device='cuda:0') torch.Size([16])
percent tensor([0.9995, 0.9993, 0.9997, 0.9997, 0.9998, 0.9986, 0.9996, 0.9999, 0.9993,
        0.9996, 0.9993, 0.9997, 0.9989, 0.9996, 0.9996, 0.9996],
       device='cuda:0') torch.Size([16])
Epoch: 73 | Batch_idx: 0 |  Loss: (0.3209) |  Loss2: (0.0000) | Acc: (85.00%) (109/128)
Epoch: 73 | Batch_idx: 10 |  Loss: (0.2656) |  Loss2: (0.0000) | Acc: (90.00%) (1268/1408)
Epoch: 73 | Batch_idx: 20 |  Loss: (0.2743) |  Loss2: (0.0000) | Acc: (90.00%) (2425/2688)
Epoch: 73 | Batch_idx: 30 |  Loss: (0.2809) |  Loss2: (0.0000) | Acc: (90.00%) (3572/3968)
Epoch: 73 | Batch_idx: 40 |  Loss: (0.2806) |  Loss2: (0.0000) | Acc: (90.00%) (4735/5248)
Epoch: 73 | Batch_idx: 50 |  Loss: (0.2786) |  Loss2: (0.0000) | Acc: (90.00%) (5894/6528)
Epoch: 73 | Batch_idx: 60 |  Loss: (0.2796) |  Loss2: (0.0000) | Acc: (90.00%) (7058/7808)
Epoch: 73 | Batch_idx: 70 |  Loss: (0.2827) |  Loss2: (0.0000) | Acc: (90.00%) (8201/9088)
Epoch: 73 | Batch_idx: 80 |  Loss: (0.2804) |  Loss2: (0.0000) | Acc: (90.00%) (9360/10368)
Epoch: 73 | Batch_idx: 90 |  Loss: (0.2865) |  Loss2: (0.0000) | Acc: (90.00%) (10507/11648)
Epoch: 73 | Batch_idx: 100 |  Loss: (0.2858) |  Loss2: (0.0000) | Acc: (90.00%) (11660/12928)
Epoch: 73 | Batch_idx: 110 |  Loss: (0.2852) |  Loss2: (0.0000) | Acc: (90.00%) (12827/14208)
Epoch: 73 | Batch_idx: 120 |  Loss: (0.2843) |  Loss2: (0.0000) | Acc: (90.00%) (13993/15488)
Epoch: 73 | Batch_idx: 130 |  Loss: (0.2853) |  Loss2: (0.0000) | Acc: (90.00%) (15134/16768)
Epoch: 73 | Batch_idx: 140 |  Loss: (0.2862) |  Loss2: (0.0000) | Acc: (90.00%) (16276/18048)
Epoch: 73 | Batch_idx: 150 |  Loss: (0.2862) |  Loss2: (0.0000) | Acc: (90.00%) (17425/19328)
Epoch: 73 | Batch_idx: 160 |  Loss: (0.2875) |  Loss2: (0.0000) | Acc: (90.00%) (18566/20608)
Epoch: 73 | Batch_idx: 170 |  Loss: (0.2862) |  Loss2: (0.0000) | Acc: (90.00%) (19732/21888)
Epoch: 73 | Batch_idx: 180 |  Loss: (0.2867) |  Loss2: (0.0000) | Acc: (90.00%) (20882/23168)
Epoch: 73 | Batch_idx: 190 |  Loss: (0.2858) |  Loss2: (0.0000) | Acc: (90.00%) (22039/24448)
Epoch: 73 | Batch_idx: 200 |  Loss: (0.2866) |  Loss2: (0.0000) | Acc: (90.00%) (23183/25728)
Epoch: 73 | Batch_idx: 210 |  Loss: (0.2872) |  Loss2: (0.0000) | Acc: (90.00%) (24338/27008)
Epoch: 73 | Batch_idx: 220 |  Loss: (0.2869) |  Loss2: (0.0000) | Acc: (90.00%) (25496/28288)
Epoch: 73 | Batch_idx: 230 |  Loss: (0.2873) |  Loss2: (0.0000) | Acc: (90.00%) (26648/29568)
Epoch: 73 | Batch_idx: 240 |  Loss: (0.2883) |  Loss2: (0.0000) | Acc: (90.00%) (27797/30848)
Epoch: 73 | Batch_idx: 250 |  Loss: (0.2886) |  Loss2: (0.0000) | Acc: (90.00%) (28940/32128)
Epoch: 73 | Batch_idx: 260 |  Loss: (0.2888) |  Loss2: (0.0000) | Acc: (90.00%) (30102/33408)
Epoch: 73 | Batch_idx: 270 |  Loss: (0.2897) |  Loss2: (0.0000) | Acc: (90.00%) (31247/34688)
Epoch: 73 | Batch_idx: 280 |  Loss: (0.2897) |  Loss2: (0.0000) | Acc: (90.00%) (32398/35968)
Epoch: 73 | Batch_idx: 290 |  Loss: (0.2907) |  Loss2: (0.0000) | Acc: (90.00%) (33540/37248)
Epoch: 73 | Batch_idx: 300 |  Loss: (0.2912) |  Loss2: (0.0000) | Acc: (89.00%) (34675/38528)
Epoch: 73 | Batch_idx: 310 |  Loss: (0.2916) |  Loss2: (0.0000) | Acc: (90.00%) (35828/39808)
Epoch: 73 | Batch_idx: 320 |  Loss: (0.2910) |  Loss2: (0.0000) | Acc: (90.00%) (36988/41088)
Epoch: 73 | Batch_idx: 330 |  Loss: (0.2913) |  Loss2: (0.0000) | Acc: (90.00%) (38141/42368)
Epoch: 73 | Batch_idx: 340 |  Loss: (0.2919) |  Loss2: (0.0000) | Acc: (90.00%) (39295/43648)
Epoch: 73 | Batch_idx: 350 |  Loss: (0.2925) |  Loss2: (0.0000) | Acc: (90.00%) (40444/44928)
Epoch: 73 | Batch_idx: 360 |  Loss: (0.2923) |  Loss2: (0.0000) | Acc: (90.00%) (41593/46208)
Epoch: 73 | Batch_idx: 370 |  Loss: (0.2927) |  Loss2: (0.0000) | Acc: (89.00%) (42737/47488)
Epoch: 73 | Batch_idx: 380 |  Loss: (0.2925) |  Loss2: (0.0000) | Acc: (89.00%) (43890/48768)
Epoch: 73 | Batch_idx: 390 |  Loss: (0.2915) |  Loss2: (0.0000) | Acc: (90.00%) (45015/50000)
# TEST : Loss: (0.3922) | Acc: (87.00%) (8707/10000)
percent tensor([0.5346, 0.5412, 0.5343, 0.5345, 0.5358, 0.5372, 0.5415, 0.5337, 0.5328,
        0.5379, 0.5375, 0.5381, 0.5370, 0.5330, 0.5418, 0.5370],
       device='cuda:0') torch.Size([16])
percent tensor([0.5128, 0.5146, 0.5061, 0.5112, 0.5062, 0.5172, 0.5104, 0.5061, 0.5094,
        0.5130, 0.5152, 0.5101, 0.5120, 0.5120, 0.5154, 0.5130],
       device='cuda:0') torch.Size([16])
percent tensor([0.5063, 0.3855, 0.6253, 0.6026, 0.6215, 0.5571, 0.4926, 0.5992, 0.5316,
        0.4556, 0.3940, 0.5588, 0.4125, 0.4550, 0.4575, 0.5180],
       device='cuda:0') torch.Size([16])
percent tensor([0.6918, 0.7117, 0.6100, 0.6391, 0.6282, 0.5868, 0.6857, 0.6403, 0.6964,
        0.7154, 0.7383, 0.6700, 0.7064, 0.7188, 0.6839, 0.6721],
       device='cuda:0') torch.Size([16])
percent tensor([0.6817, 0.5783, 0.7293, 0.7208, 0.7368, 0.7177, 0.6669, 0.7362, 0.6640,
        0.5730, 0.5493, 0.6475, 0.5751, 0.6287, 0.6658, 0.6958],
       device='cuda:0') torch.Size([16])
percent tensor([0.4931, 0.5624, 0.6217, 0.6773, 0.6807, 0.6939, 0.5683, 0.5384, 0.5859,
        0.5371, 0.5563, 0.6049, 0.5305, 0.5934, 0.5033, 0.5729],
       device='cuda:0') torch.Size([16])
percent tensor([0.6270, 0.6799, 0.6548, 0.7107, 0.6872, 0.6921, 0.6456, 0.5665, 0.6976,
        0.6977, 0.7300, 0.6817, 0.6640, 0.7493, 0.6014, 0.6140],
       device='cuda:0') torch.Size([16])
percent tensor([0.9993, 0.9990, 0.9996, 0.9999, 0.9998, 0.9984, 0.9994, 0.9997, 0.9993,
        0.9991, 0.9987, 0.9998, 0.9986, 0.9994, 0.9996, 0.9996],
       device='cuda:0') torch.Size([16])
Epoch: 74 | Batch_idx: 0 |  Loss: (0.2479) |  Loss2: (0.0000) | Acc: (91.00%) (117/128)
Epoch: 74 | Batch_idx: 10 |  Loss: (0.2942) |  Loss2: (0.0000) | Acc: (90.00%) (1269/1408)
Epoch: 74 | Batch_idx: 20 |  Loss: (0.2848) |  Loss2: (0.0000) | Acc: (90.00%) (2426/2688)
Epoch: 74 | Batch_idx: 30 |  Loss: (0.2748) |  Loss2: (0.0000) | Acc: (90.00%) (3590/3968)
Epoch: 74 | Batch_idx: 40 |  Loss: (0.2771) |  Loss2: (0.0000) | Acc: (90.00%) (4750/5248)
Epoch: 74 | Batch_idx: 50 |  Loss: (0.2787) |  Loss2: (0.0000) | Acc: (90.00%) (5909/6528)
Epoch: 74 | Batch_idx: 60 |  Loss: (0.2755) |  Loss2: (0.0000) | Acc: (90.00%) (7075/7808)
Epoch: 74 | Batch_idx: 70 |  Loss: (0.2769) |  Loss2: (0.0000) | Acc: (90.00%) (8219/9088)
Epoch: 74 | Batch_idx: 80 |  Loss: (0.2755) |  Loss2: (0.0000) | Acc: (90.00%) (9379/10368)
Epoch: 74 | Batch_idx: 90 |  Loss: (0.2769) |  Loss2: (0.0000) | Acc: (90.00%) (10525/11648)
Epoch: 74 | Batch_idx: 100 |  Loss: (0.2804) |  Loss2: (0.0000) | Acc: (90.00%) (11660/12928)
Epoch: 74 | Batch_idx: 110 |  Loss: (0.2778) |  Loss2: (0.0000) | Acc: (90.00%) (12835/14208)
Epoch: 74 | Batch_idx: 120 |  Loss: (0.2805) |  Loss2: (0.0000) | Acc: (90.00%) (13975/15488)
Epoch: 74 | Batch_idx: 130 |  Loss: (0.2804) |  Loss2: (0.0000) | Acc: (90.00%) (15133/16768)
Epoch: 74 | Batch_idx: 140 |  Loss: (0.2797) |  Loss2: (0.0000) | Acc: (90.00%) (16293/18048)
Epoch: 74 | Batch_idx: 150 |  Loss: (0.2800) |  Loss2: (0.0000) | Acc: (90.00%) (17447/19328)
Epoch: 74 | Batch_idx: 160 |  Loss: (0.2814) |  Loss2: (0.0000) | Acc: (90.00%) (18604/20608)
Epoch: 74 | Batch_idx: 170 |  Loss: (0.2812) |  Loss2: (0.0000) | Acc: (90.00%) (19763/21888)
Epoch: 74 | Batch_idx: 180 |  Loss: (0.2813) |  Loss2: (0.0000) | Acc: (90.00%) (20915/23168)
Epoch: 74 | Batch_idx: 190 |  Loss: (0.2811) |  Loss2: (0.0000) | Acc: (90.00%) (22085/24448)
Epoch: 74 | Batch_idx: 200 |  Loss: (0.2818) |  Loss2: (0.0000) | Acc: (90.00%) (23235/25728)
Epoch: 74 | Batch_idx: 210 |  Loss: (0.2815) |  Loss2: (0.0000) | Acc: (90.00%) (24401/27008)
Epoch: 74 | Batch_idx: 220 |  Loss: (0.2810) |  Loss2: (0.0000) | Acc: (90.00%) (25554/28288)
Epoch: 74 | Batch_idx: 230 |  Loss: (0.2811) |  Loss2: (0.0000) | Acc: (90.00%) (26716/29568)
Epoch: 74 | Batch_idx: 240 |  Loss: (0.2816) |  Loss2: (0.0000) | Acc: (90.00%) (27874/30848)
Epoch: 74 | Batch_idx: 250 |  Loss: (0.2810) |  Loss2: (0.0000) | Acc: (90.00%) (29041/32128)
Epoch: 74 | Batch_idx: 260 |  Loss: (0.2807) |  Loss2: (0.0000) | Acc: (90.00%) (30200/33408)
Epoch: 74 | Batch_idx: 270 |  Loss: (0.2799) |  Loss2: (0.0000) | Acc: (90.00%) (31378/34688)
Epoch: 74 | Batch_idx: 280 |  Loss: (0.2795) |  Loss2: (0.0000) | Acc: (90.00%) (32542/35968)
Epoch: 74 | Batch_idx: 290 |  Loss: (0.2785) |  Loss2: (0.0000) | Acc: (90.00%) (33713/37248)
Epoch: 74 | Batch_idx: 300 |  Loss: (0.2780) |  Loss2: (0.0000) | Acc: (90.00%) (34866/38528)
Epoch: 74 | Batch_idx: 310 |  Loss: (0.2780) |  Loss2: (0.0000) | Acc: (90.00%) (36019/39808)
Epoch: 74 | Batch_idx: 320 |  Loss: (0.2787) |  Loss2: (0.0000) | Acc: (90.00%) (37158/41088)
Epoch: 74 | Batch_idx: 330 |  Loss: (0.2772) |  Loss2: (0.0000) | Acc: (90.00%) (38328/42368)
Epoch: 74 | Batch_idx: 340 |  Loss: (0.2779) |  Loss2: (0.0000) | Acc: (90.00%) (39485/43648)
Epoch: 74 | Batch_idx: 350 |  Loss: (0.2781) |  Loss2: (0.0000) | Acc: (90.00%) (40632/44928)
Epoch: 74 | Batch_idx: 360 |  Loss: (0.2774) |  Loss2: (0.0000) | Acc: (90.00%) (41798/46208)
Epoch: 74 | Batch_idx: 370 |  Loss: (0.2775) |  Loss2: (0.0000) | Acc: (90.00%) (42960/47488)
Epoch: 74 | Batch_idx: 380 |  Loss: (0.2788) |  Loss2: (0.0000) | Acc: (90.00%) (44087/48768)
Epoch: 74 | Batch_idx: 390 |  Loss: (0.2800) |  Loss2: (0.0000) | Acc: (90.00%) (45176/50000)
# TEST : Loss: (0.4323) | Acc: (85.00%) (8591/10000)
percent tensor([0.5342, 0.5407, 0.5343, 0.5336, 0.5364, 0.5379, 0.5411, 0.5330, 0.5326,
        0.5372, 0.5372, 0.5382, 0.5365, 0.5332, 0.5416, 0.5365],
       device='cuda:0') torch.Size([16])
percent tensor([0.5129, 0.5146, 0.5049, 0.5098, 0.5051, 0.5160, 0.5101, 0.5055, 0.5087,
        0.5131, 0.5151, 0.5094, 0.5121, 0.5117, 0.5150, 0.5134],
       device='cuda:0') torch.Size([16])
percent tensor([0.5101, 0.3871, 0.6328, 0.6093, 0.6283, 0.5676, 0.4985, 0.6077, 0.5497,
        0.4601, 0.4041, 0.5696, 0.4153, 0.4602, 0.4684, 0.5300],
       device='cuda:0') torch.Size([16])
percent tensor([0.6923, 0.7175, 0.6084, 0.6359, 0.6240, 0.5760, 0.6897, 0.6400, 0.6923,
        0.7133, 0.7334, 0.6685, 0.7074, 0.7207, 0.6801, 0.6670],
       device='cuda:0') torch.Size([16])
percent tensor([0.6856, 0.5788, 0.7335, 0.7304, 0.7389, 0.7373, 0.6746, 0.7415, 0.6630,
        0.5761, 0.5628, 0.6347, 0.5589, 0.6379, 0.6771, 0.7096],
       device='cuda:0') torch.Size([16])
percent tensor([0.5129, 0.5707, 0.6253, 0.6802, 0.6728, 0.6907, 0.5830, 0.5556, 0.5921,
        0.5477, 0.5693, 0.5904, 0.5377, 0.6112, 0.5033, 0.5792],
       device='cuda:0') torch.Size([16])
percent tensor([0.6549, 0.6917, 0.6459, 0.7013, 0.6836, 0.6754, 0.6623, 0.5701, 0.7079,
        0.7131, 0.7348, 0.6843, 0.6796, 0.7412, 0.6056, 0.6162],
       device='cuda:0') torch.Size([16])
percent tensor([0.9995, 0.9990, 0.9996, 0.9998, 0.9999, 0.9976, 0.9994, 0.9996, 0.9991,
        0.9994, 0.9983, 0.9997, 0.9985, 0.9989, 0.9996, 0.9995],
       device='cuda:0') torch.Size([16])
False Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=128, out_features=16, bias=False)
True Linear(in_features=16, out_features=2, bias=False)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=128, out_features=16, bias=False)
True Linear(in_features=16, out_features=2, bias=False)
False Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=256, out_features=32, bias=False)
True Linear(in_features=32, out_features=2, bias=False)
False Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=256, out_features=32, bias=False)
True Linear(in_features=32, out_features=2, bias=False)
False Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=512, out_features=64, bias=False)
True Linear(in_features=64, out_features=2, bias=False)
False Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=512, out_features=64, bias=False)
True Linear(in_features=64, out_features=2, bias=False)
False Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1024, out_features=128, bias=False)
True Linear(in_features=128, out_features=2, bias=False)
False Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1024, out_features=128, bias=False)
True Linear(in_features=128, out_features=2, bias=False)
False Linear(in_features=512, out_features=10, bias=True)
Epoch: 75 | Batch_idx: 0 |  Loss: (0.2587) |  Loss2: (0.0000) | Acc: (92.00%) (118/128)
Epoch: 75 | Batch_idx: 10 |  Loss: (0.2718) |  Loss2: (0.0000) | Acc: (90.00%) (1272/1408)
Epoch: 75 | Batch_idx: 20 |  Loss: (0.2905) |  Loss2: (0.0000) | Acc: (89.00%) (2408/2688)
Epoch: 75 | Batch_idx: 30 |  Loss: (0.2898) |  Loss2: (0.0000) | Acc: (89.00%) (3552/3968)
Epoch: 75 | Batch_idx: 40 |  Loss: (0.3038) |  Loss2: (0.0000) | Acc: (89.00%) (4677/5248)
Epoch: 75 | Batch_idx: 50 |  Loss: (0.3058) |  Loss2: (0.0000) | Acc: (89.00%) (5816/6528)
Epoch: 75 | Batch_idx: 60 |  Loss: (0.3128) |  Loss2: (0.0000) | Acc: (88.00%) (6945/7808)
Epoch: 75 | Batch_idx: 70 |  Loss: (0.3096) |  Loss2: (0.0000) | Acc: (88.00%) (8083/9088)
Epoch: 75 | Batch_idx: 80 |  Loss: (0.3121) |  Loss2: (0.0000) | Acc: (88.00%) (9206/10368)
Epoch: 75 | Batch_idx: 90 |  Loss: (0.3139) |  Loss2: (0.0000) | Acc: (88.00%) (10337/11648)
Epoch: 75 | Batch_idx: 100 |  Loss: (0.3155) |  Loss2: (0.0000) | Acc: (88.00%) (11470/12928)
Epoch: 75 | Batch_idx: 110 |  Loss: (0.3164) |  Loss2: (0.0000) | Acc: (88.00%) (12605/14208)
Epoch: 75 | Batch_idx: 120 |  Loss: (0.3171) |  Loss2: (0.0000) | Acc: (88.00%) (13735/15488)
Epoch: 75 | Batch_idx: 130 |  Loss: (0.3194) |  Loss2: (0.0000) | Acc: (88.00%) (14856/16768)
Epoch: 75 | Batch_idx: 140 |  Loss: (0.3210) |  Loss2: (0.0000) | Acc: (88.00%) (15977/18048)
Epoch: 75 | Batch_idx: 150 |  Loss: (0.3206) |  Loss2: (0.0000) | Acc: (88.00%) (17112/19328)
Epoch: 75 | Batch_idx: 160 |  Loss: (0.3227) |  Loss2: (0.0000) | Acc: (88.00%) (18227/20608)
Epoch: 75 | Batch_idx: 170 |  Loss: (0.3235) |  Loss2: (0.0000) | Acc: (88.00%) (19357/21888)
Epoch: 75 | Batch_idx: 180 |  Loss: (0.3236) |  Loss2: (0.0000) | Acc: (88.00%) (20496/23168)
Epoch: 75 | Batch_idx: 190 |  Loss: (0.3216) |  Loss2: (0.0000) | Acc: (88.00%) (21649/24448)
Epoch: 75 | Batch_idx: 200 |  Loss: (0.3194) |  Loss2: (0.0000) | Acc: (88.00%) (22806/25728)
Epoch: 75 | Batch_idx: 210 |  Loss: (0.3193) |  Loss2: (0.0000) | Acc: (88.00%) (23950/27008)
Epoch: 75 | Batch_idx: 220 |  Loss: (0.3174) |  Loss2: (0.0000) | Acc: (88.00%) (25106/28288)
Epoch: 75 | Batch_idx: 230 |  Loss: (0.3175) |  Loss2: (0.0000) | Acc: (88.00%) (26249/29568)
Epoch: 75 | Batch_idx: 240 |  Loss: (0.3175) |  Loss2: (0.0000) | Acc: (88.00%) (27398/30848)
Epoch: 75 | Batch_idx: 250 |  Loss: (0.3178) |  Loss2: (0.0000) | Acc: (88.00%) (28527/32128)
Epoch: 75 | Batch_idx: 260 |  Loss: (0.3171) |  Loss2: (0.0000) | Acc: (88.00%) (29670/33408)
Epoch: 75 | Batch_idx: 270 |  Loss: (0.3150) |  Loss2: (0.0000) | Acc: (88.00%) (30831/34688)
Epoch: 75 | Batch_idx: 280 |  Loss: (0.3140) |  Loss2: (0.0000) | Acc: (88.00%) (31971/35968)
Epoch: 75 | Batch_idx: 290 |  Loss: (0.3133) |  Loss2: (0.0000) | Acc: (88.00%) (33119/37248)
Epoch: 75 | Batch_idx: 300 |  Loss: (0.3126) |  Loss2: (0.0000) | Acc: (88.00%) (34276/38528)
Epoch: 75 | Batch_idx: 310 |  Loss: (0.3122) |  Loss2: (0.0000) | Acc: (88.00%) (35420/39808)
Epoch: 75 | Batch_idx: 320 |  Loss: (0.3122) |  Loss2: (0.0000) | Acc: (88.00%) (36563/41088)
Epoch: 75 | Batch_idx: 330 |  Loss: (0.3109) |  Loss2: (0.0000) | Acc: (89.00%) (37731/42368)
Epoch: 75 | Batch_idx: 340 |  Loss: (0.3106) |  Loss2: (0.0000) | Acc: (89.00%) (38872/43648)
Epoch: 75 | Batch_idx: 350 |  Loss: (0.3104) |  Loss2: (0.0000) | Acc: (89.00%) (40023/44928)
Epoch: 75 | Batch_idx: 360 |  Loss: (0.3095) |  Loss2: (0.0000) | Acc: (89.00%) (41165/46208)
Epoch: 75 | Batch_idx: 370 |  Loss: (0.3093) |  Loss2: (0.0000) | Acc: (89.00%) (42308/47488)
Epoch: 75 | Batch_idx: 380 |  Loss: (0.3088) |  Loss2: (0.0000) | Acc: (89.00%) (43458/48768)
Epoch: 75 | Batch_idx: 390 |  Loss: (0.3090) |  Loss2: (0.0000) | Acc: (89.00%) (44558/50000)
=> saving checkpoint 'drive/app/torch/save_Schedule/checkpoint_075.pth.tar'
# TEST : Loss: (0.4320) | Acc: (86.00%) (8634/10000)
percent tensor([0.5356, 0.5421, 0.5365, 0.5350, 0.5386, 0.5384, 0.5429, 0.5347, 0.5344,
        0.5391, 0.5388, 0.5408, 0.5380, 0.5348, 0.5428, 0.5374],
       device='cuda:0') torch.Size([16])
percent tensor([0.5117, 0.5130, 0.5057, 0.5090, 0.5059, 0.5150, 0.5096, 0.5059, 0.5078,
        0.5116, 0.5136, 0.5086, 0.5109, 0.5107, 0.5136, 0.5121],
       device='cuda:0') torch.Size([16])
percent tensor([0.5182, 0.4060, 0.6357, 0.6181, 0.6346, 0.5813, 0.5101, 0.6195, 0.5618,
        0.4749, 0.4181, 0.5731, 0.4285, 0.4815, 0.4876, 0.5456],
       device='cuda:0') torch.Size([16])
percent tensor([0.6796, 0.7034, 0.5993, 0.6189, 0.6122, 0.5582, 0.6746, 0.6249, 0.6769,
        0.6999, 0.7184, 0.6608, 0.6956, 0.6962, 0.6642, 0.6495],
       device='cuda:0') torch.Size([16])
percent tensor([0.6557, 0.5856, 0.6893, 0.6930, 0.6953, 0.7130, 0.6428, 0.6879, 0.6367,
        0.5806, 0.5662, 0.6065, 0.5655, 0.6271, 0.6507, 0.6861],
       device='cuda:0') torch.Size([16])
percent tensor([0.5328, 0.5877, 0.6411, 0.6997, 0.6847, 0.6950, 0.5941, 0.5775, 0.6227,
        0.5742, 0.6017, 0.6158, 0.5651, 0.6314, 0.5208, 0.5846],
       device='cuda:0') torch.Size([16])
percent tensor([0.5799, 0.6213, 0.5886, 0.6456, 0.6124, 0.5990, 0.6064, 0.5330, 0.6564,
        0.6477, 0.6841, 0.6500, 0.6134, 0.6884, 0.5592, 0.5348],
       device='cuda:0') torch.Size([16])
percent tensor([0.9996, 0.9989, 0.9998, 0.9999, 0.9999, 0.9975, 0.9993, 0.9997, 0.9991,
        0.9994, 0.9985, 0.9997, 0.9986, 0.9989, 0.9997, 0.9996],
       device='cuda:0') torch.Size([16])
Epoch: 76 | Batch_idx: 0 |  Loss: (0.2900) |  Loss2: (0.0000) | Acc: (89.00%) (114/128)
Epoch: 76 | Batch_idx: 10 |  Loss: (0.3034) |  Loss2: (0.0000) | Acc: (89.00%) (1258/1408)
Epoch: 76 | Batch_idx: 20 |  Loss: (0.2942) |  Loss2: (0.0000) | Acc: (89.00%) (2411/2688)
Epoch: 76 | Batch_idx: 30 |  Loss: (0.2903) |  Loss2: (0.0000) | Acc: (89.00%) (3567/3968)
Epoch: 76 | Batch_idx: 40 |  Loss: (0.2899) |  Loss2: (0.0000) | Acc: (89.00%) (4718/5248)
Epoch: 76 | Batch_idx: 50 |  Loss: (0.2863) |  Loss2: (0.0000) | Acc: (89.00%) (5873/6528)
Epoch: 76 | Batch_idx: 60 |  Loss: (0.2853) |  Loss2: (0.0000) | Acc: (89.00%) (7026/7808)
Epoch: 76 | Batch_idx: 70 |  Loss: (0.2887) |  Loss2: (0.0000) | Acc: (89.00%) (8174/9088)
Epoch: 76 | Batch_idx: 80 |  Loss: (0.2878) |  Loss2: (0.0000) | Acc: (89.00%) (9320/10368)
Epoch: 76 | Batch_idx: 90 |  Loss: (0.2898) |  Loss2: (0.0000) | Acc: (89.00%) (10465/11648)
Epoch: 76 | Batch_idx: 100 |  Loss: (0.2869) |  Loss2: (0.0000) | Acc: (89.00%) (11634/12928)
Epoch: 76 | Batch_idx: 110 |  Loss: (0.2868) |  Loss2: (0.0000) | Acc: (90.00%) (12792/14208)
Epoch: 76 | Batch_idx: 120 |  Loss: (0.2901) |  Loss2: (0.0000) | Acc: (89.00%) (13937/15488)
Epoch: 76 | Batch_idx: 130 |  Loss: (0.2878) |  Loss2: (0.0000) | Acc: (90.00%) (15102/16768)
Epoch: 76 | Batch_idx: 140 |  Loss: (0.2900) |  Loss2: (0.0000) | Acc: (89.00%) (16236/18048)
Epoch: 76 | Batch_idx: 150 |  Loss: (0.2908) |  Loss2: (0.0000) | Acc: (89.00%) (17371/19328)
Epoch: 76 | Batch_idx: 160 |  Loss: (0.2899) |  Loss2: (0.0000) | Acc: (89.00%) (18533/20608)
Epoch: 76 | Batch_idx: 170 |  Loss: (0.2904) |  Loss2: (0.0000) | Acc: (89.00%) (19690/21888)
Epoch: 76 | Batch_idx: 180 |  Loss: (0.2909) |  Loss2: (0.0000) | Acc: (89.00%) (20839/23168)
Epoch: 76 | Batch_idx: 190 |  Loss: (0.2906) |  Loss2: (0.0000) | Acc: (89.00%) (21991/24448)
Epoch: 76 | Batch_idx: 200 |  Loss: (0.2898) |  Loss2: (0.0000) | Acc: (89.00%) (23147/25728)
Epoch: 76 | Batch_idx: 210 |  Loss: (0.2901) |  Loss2: (0.0000) | Acc: (89.00%) (24295/27008)
Epoch: 76 | Batch_idx: 220 |  Loss: (0.2889) |  Loss2: (0.0000) | Acc: (89.00%) (25458/28288)
Epoch: 76 | Batch_idx: 230 |  Loss: (0.2895) |  Loss2: (0.0000) | Acc: (89.00%) (26610/29568)
Epoch: 76 | Batch_idx: 240 |  Loss: (0.2888) |  Loss2: (0.0000) | Acc: (90.00%) (27775/30848)
Epoch: 76 | Batch_idx: 250 |  Loss: (0.2874) |  Loss2: (0.0000) | Acc: (90.00%) (28935/32128)
Epoch: 76 | Batch_idx: 260 |  Loss: (0.2875) |  Loss2: (0.0000) | Acc: (90.00%) (30096/33408)
Epoch: 76 | Batch_idx: 270 |  Loss: (0.2878) |  Loss2: (0.0000) | Acc: (90.00%) (31231/34688)
Epoch: 76 | Batch_idx: 280 |  Loss: (0.2874) |  Loss2: (0.0000) | Acc: (90.00%) (32400/35968)
Epoch: 76 | Batch_idx: 290 |  Loss: (0.2882) |  Loss2: (0.0000) | Acc: (90.00%) (33533/37248)
Epoch: 76 | Batch_idx: 300 |  Loss: (0.2875) |  Loss2: (0.0000) | Acc: (90.00%) (34694/38528)
Epoch: 76 | Batch_idx: 310 |  Loss: (0.2882) |  Loss2: (0.0000) | Acc: (89.00%) (35819/39808)
Epoch: 76 | Batch_idx: 320 |  Loss: (0.2882) |  Loss2: (0.0000) | Acc: (89.00%) (36968/41088)
Epoch: 76 | Batch_idx: 330 |  Loss: (0.2875) |  Loss2: (0.0000) | Acc: (89.00%) (38128/42368)
Epoch: 76 | Batch_idx: 340 |  Loss: (0.2862) |  Loss2: (0.0000) | Acc: (90.00%) (39302/43648)
Epoch: 76 | Batch_idx: 350 |  Loss: (0.2859) |  Loss2: (0.0000) | Acc: (90.00%) (40462/44928)
Epoch: 76 | Batch_idx: 360 |  Loss: (0.2866) |  Loss2: (0.0000) | Acc: (90.00%) (41601/46208)
Epoch: 76 | Batch_idx: 370 |  Loss: (0.2865) |  Loss2: (0.0000) | Acc: (90.00%) (42743/47488)
Epoch: 76 | Batch_idx: 380 |  Loss: (0.2857) |  Loss2: (0.0000) | Acc: (90.00%) (43914/48768)
Epoch: 76 | Batch_idx: 390 |  Loss: (0.2856) |  Loss2: (0.0000) | Acc: (90.00%) (45033/50000)
# TEST : Loss: (0.4172) | Acc: (86.00%) (8658/10000)
percent tensor([0.5350, 0.5416, 0.5358, 0.5343, 0.5378, 0.5373, 0.5423, 0.5342, 0.5342,
        0.5388, 0.5384, 0.5404, 0.5375, 0.5348, 0.5419, 0.5367],
       device='cuda:0') torch.Size([16])
percent tensor([0.5108, 0.5120, 0.5053, 0.5084, 0.5059, 0.5142, 0.5092, 0.5056, 0.5071,
        0.5107, 0.5125, 0.5078, 0.5100, 0.5099, 0.5126, 0.5112],
       device='cuda:0') torch.Size([16])
percent tensor([0.5144, 0.3996, 0.6386, 0.6209, 0.6393, 0.5877, 0.5052, 0.6228, 0.5587,
        0.4672, 0.4094, 0.5667, 0.4195, 0.4747, 0.4862, 0.5419],
       device='cuda:0') torch.Size([16])
percent tensor([0.6795, 0.7044, 0.5978, 0.6176, 0.6115, 0.5558, 0.6757, 0.6261, 0.6779,
        0.7002, 0.7192, 0.6607, 0.6962, 0.6972, 0.6648, 0.6484],
       device='cuda:0') torch.Size([16])
percent tensor([0.6687, 0.6002, 0.6911, 0.7000, 0.7019, 0.7216, 0.6524, 0.6897, 0.6510,
        0.6020, 0.5883, 0.6193, 0.5845, 0.6447, 0.6617, 0.7005],
       device='cuda:0') torch.Size([16])
percent tensor([0.5292, 0.5923, 0.6371, 0.6977, 0.6793, 0.6902, 0.5910, 0.5649, 0.6217,
        0.5774, 0.6063, 0.6141, 0.5707, 0.6325, 0.5164, 0.5847],
       device='cuda:0') torch.Size([16])
percent tensor([0.5852, 0.6329, 0.6008, 0.6611, 0.6097, 0.5955, 0.6160, 0.5393, 0.6701,
        0.6576, 0.7014, 0.6703, 0.6234, 0.7053, 0.5789, 0.5335],
       device='cuda:0') torch.Size([16])
percent tensor([0.9996, 0.9989, 0.9997, 0.9999, 0.9999, 0.9975, 0.9993, 0.9997, 0.9991,
        0.9994, 0.9985, 0.9997, 0.9987, 0.9990, 0.9997, 0.9996],
       device='cuda:0') torch.Size([16])
Epoch: 77 | Batch_idx: 0 |  Loss: (0.2845) |  Loss2: (0.0000) | Acc: (85.00%) (109/128)
Epoch: 77 | Batch_idx: 10 |  Loss: (0.2725) |  Loss2: (0.0000) | Acc: (90.00%) (1271/1408)
Epoch: 77 | Batch_idx: 20 |  Loss: (0.2716) |  Loss2: (0.0000) | Acc: (90.00%) (2439/2688)
Epoch: 77 | Batch_idx: 30 |  Loss: (0.2791) |  Loss2: (0.0000) | Acc: (90.00%) (3583/3968)
Epoch: 77 | Batch_idx: 40 |  Loss: (0.2744) |  Loss2: (0.0000) | Acc: (90.00%) (4756/5248)
Epoch: 77 | Batch_idx: 50 |  Loss: (0.2781) |  Loss2: (0.0000) | Acc: (90.00%) (5903/6528)
Epoch: 77 | Batch_idx: 60 |  Loss: (0.2766) |  Loss2: (0.0000) | Acc: (90.00%) (7066/7808)
Epoch: 77 | Batch_idx: 70 |  Loss: (0.2781) |  Loss2: (0.0000) | Acc: (90.00%) (8225/9088)
Epoch: 77 | Batch_idx: 80 |  Loss: (0.2786) |  Loss2: (0.0000) | Acc: (90.00%) (9385/10368)
Epoch: 77 | Batch_idx: 90 |  Loss: (0.2803) |  Loss2: (0.0000) | Acc: (90.00%) (10536/11648)
Epoch: 77 | Batch_idx: 100 |  Loss: (0.2800) |  Loss2: (0.0000) | Acc: (90.00%) (11686/12928)
Epoch: 77 | Batch_idx: 110 |  Loss: (0.2837) |  Loss2: (0.0000) | Acc: (90.00%) (12822/14208)
Epoch: 77 | Batch_idx: 120 |  Loss: (0.2827) |  Loss2: (0.0000) | Acc: (90.00%) (13988/15488)
Epoch: 77 | Batch_idx: 130 |  Loss: (0.2804) |  Loss2: (0.0000) | Acc: (90.00%) (15158/16768)
Epoch: 77 | Batch_idx: 140 |  Loss: (0.2819) |  Loss2: (0.0000) | Acc: (90.00%) (16299/18048)
Epoch: 77 | Batch_idx: 150 |  Loss: (0.2808) |  Loss2: (0.0000) | Acc: (90.00%) (17455/19328)
Epoch: 77 | Batch_idx: 160 |  Loss: (0.2809) |  Loss2: (0.0000) | Acc: (90.00%) (18615/20608)
Epoch: 77 | Batch_idx: 170 |  Loss: (0.2795) |  Loss2: (0.0000) | Acc: (90.00%) (19781/21888)
Epoch: 77 | Batch_idx: 180 |  Loss: (0.2803) |  Loss2: (0.0000) | Acc: (90.00%) (20930/23168)
Epoch: 77 | Batch_idx: 190 |  Loss: (0.2804) |  Loss2: (0.0000) | Acc: (90.00%) (22077/24448)
Epoch: 77 | Batch_idx: 200 |  Loss: (0.2797) |  Loss2: (0.0000) | Acc: (90.00%) (23248/25728)
Epoch: 77 | Batch_idx: 210 |  Loss: (0.2792) |  Loss2: (0.0000) | Acc: (90.00%) (24405/27008)
Epoch: 77 | Batch_idx: 220 |  Loss: (0.2795) |  Loss2: (0.0000) | Acc: (90.00%) (25553/28288)
Epoch: 77 | Batch_idx: 230 |  Loss: (0.2809) |  Loss2: (0.0000) | Acc: (90.00%) (26699/29568)
Epoch: 77 | Batch_idx: 240 |  Loss: (0.2804) |  Loss2: (0.0000) | Acc: (90.00%) (27858/30848)
Epoch: 77 | Batch_idx: 250 |  Loss: (0.2812) |  Loss2: (0.0000) | Acc: (90.00%) (28988/32128)
Epoch: 77 | Batch_idx: 260 |  Loss: (0.2809) |  Loss2: (0.0000) | Acc: (90.00%) (30154/33408)
Epoch: 77 | Batch_idx: 270 |  Loss: (0.2811) |  Loss2: (0.0000) | Acc: (90.00%) (31304/34688)
Epoch: 77 | Batch_idx: 280 |  Loss: (0.2822) |  Loss2: (0.0000) | Acc: (90.00%) (32453/35968)
Epoch: 77 | Batch_idx: 290 |  Loss: (0.2818) |  Loss2: (0.0000) | Acc: (90.00%) (33612/37248)
Epoch: 77 | Batch_idx: 300 |  Loss: (0.2832) |  Loss2: (0.0000) | Acc: (90.00%) (34752/38528)
Epoch: 77 | Batch_idx: 310 |  Loss: (0.2823) |  Loss2: (0.0000) | Acc: (90.00%) (35916/39808)
Epoch: 77 | Batch_idx: 320 |  Loss: (0.2815) |  Loss2: (0.0000) | Acc: (90.00%) (37091/41088)
Epoch: 77 | Batch_idx: 330 |  Loss: (0.2809) |  Loss2: (0.0000) | Acc: (90.00%) (38250/42368)
Epoch: 77 | Batch_idx: 340 |  Loss: (0.2805) |  Loss2: (0.0000) | Acc: (90.00%) (39409/43648)
Epoch: 77 | Batch_idx: 350 |  Loss: (0.2800) |  Loss2: (0.0000) | Acc: (90.00%) (40574/44928)
Epoch: 77 | Batch_idx: 360 |  Loss: (0.2797) |  Loss2: (0.0000) | Acc: (90.00%) (41751/46208)
Epoch: 77 | Batch_idx: 370 |  Loss: (0.2800) |  Loss2: (0.0000) | Acc: (90.00%) (42904/47488)
Epoch: 77 | Batch_idx: 380 |  Loss: (0.2794) |  Loss2: (0.0000) | Acc: (90.00%) (44071/48768)
Epoch: 77 | Batch_idx: 390 |  Loss: (0.2799) |  Loss2: (0.0000) | Acc: (90.00%) (45190/50000)
# TEST : Loss: (0.4079) | Acc: (86.00%) (8675/10000)
percent tensor([0.5363, 0.5433, 0.5373, 0.5355, 0.5394, 0.5380, 0.5441, 0.5358, 0.5359,
        0.5405, 0.5401, 0.5422, 0.5391, 0.5368, 0.5432, 0.5379],
       device='cuda:0') torch.Size([16])
percent tensor([0.5098, 0.5109, 0.5047, 0.5077, 0.5057, 0.5133, 0.5084, 0.5051, 0.5063,
        0.5097, 0.5115, 0.5070, 0.5090, 0.5090, 0.5116, 0.5103],
       device='cuda:0') torch.Size([16])
percent tensor([0.5104, 0.3976, 0.6366, 0.6176, 0.6388, 0.5868, 0.5019, 0.6225, 0.5543,
        0.4624, 0.4047, 0.5610, 0.4159, 0.4689, 0.4839, 0.5357],
       device='cuda:0') torch.Size([16])
percent tensor([0.6791, 0.7050, 0.5968, 0.6168, 0.6114, 0.5541, 0.6759, 0.6272, 0.6788,
        0.7002, 0.7199, 0.6596, 0.6964, 0.6983, 0.6648, 0.6475],
       device='cuda:0') torch.Size([16])
percent tensor([0.6624, 0.5969, 0.6796, 0.6911, 0.6951, 0.7165, 0.6459, 0.6777, 0.6452,
        0.6002, 0.5854, 0.6102, 0.5820, 0.6430, 0.6531, 0.6976],
       device='cuda:0') torch.Size([16])
percent tensor([0.5289, 0.5964, 0.6391, 0.6993, 0.6798, 0.6924, 0.5918, 0.5577, 0.6238,
        0.5833, 0.6090, 0.6147, 0.5747, 0.6378, 0.5138, 0.5888],
       device='cuda:0') torch.Size([16])
percent tensor([0.5895, 0.6408, 0.6096, 0.6713, 0.6090, 0.5986, 0.6238, 0.5398, 0.6837,
        0.6675, 0.7172, 0.6853, 0.6318, 0.7219, 0.5916, 0.5327],
       device='cuda:0') torch.Size([16])
percent tensor([0.9996, 0.9990, 0.9997, 0.9999, 0.9999, 0.9977, 0.9993, 0.9997, 0.9992,
        0.9995, 0.9986, 0.9998, 0.9988, 0.9991, 0.9997, 0.9996],
       device='cuda:0') torch.Size([16])
True Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=128, out_features=16, bias=False)
False Linear(in_features=16, out_features=2, bias=False)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=128, out_features=16, bias=False)
False Linear(in_features=16, out_features=2, bias=False)
True Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=256, out_features=32, bias=False)
False Linear(in_features=32, out_features=2, bias=False)
True Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=256, out_features=32, bias=False)
False Linear(in_features=32, out_features=2, bias=False)
True Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=512, out_features=64, bias=False)
False Linear(in_features=64, out_features=2, bias=False)
True Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=512, out_features=64, bias=False)
False Linear(in_features=64, out_features=2, bias=False)
True Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1024, out_features=128, bias=False)
False Linear(in_features=128, out_features=2, bias=False)
True Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1024, out_features=128, bias=False)
False Linear(in_features=128, out_features=2, bias=False)
True Linear(in_features=512, out_features=10, bias=True)
Epoch: 78 | Batch_idx: 0 |  Loss: (0.1920) |  Loss2: (0.0000) | Acc: (92.00%) (119/128)
Epoch: 78 | Batch_idx: 10 |  Loss: (0.2829) |  Loss2: (0.0000) | Acc: (90.00%) (1272/1408)
Epoch: 78 | Batch_idx: 20 |  Loss: (0.2787) |  Loss2: (0.0000) | Acc: (90.00%) (2440/2688)
Epoch: 78 | Batch_idx: 30 |  Loss: (0.2783) |  Loss2: (0.0000) | Acc: (90.00%) (3602/3968)
Epoch: 78 | Batch_idx: 40 |  Loss: (0.2735) |  Loss2: (0.0000) | Acc: (90.00%) (4767/5248)
Epoch: 78 | Batch_idx: 50 |  Loss: (0.2746) |  Loss2: (0.0000) | Acc: (90.00%) (5926/6528)
Epoch: 78 | Batch_idx: 60 |  Loss: (0.2733) |  Loss2: (0.0000) | Acc: (90.00%) (7082/7808)
Epoch: 78 | Batch_idx: 70 |  Loss: (0.2681) |  Loss2: (0.0000) | Acc: (90.00%) (8263/9088)
Epoch: 78 | Batch_idx: 80 |  Loss: (0.2670) |  Loss2: (0.0000) | Acc: (91.00%) (9435/10368)
Epoch: 78 | Batch_idx: 90 |  Loss: (0.2697) |  Loss2: (0.0000) | Acc: (90.00%) (10594/11648)
Epoch: 78 | Batch_idx: 100 |  Loss: (0.2695) |  Loss2: (0.0000) | Acc: (90.00%) (11760/12928)
Epoch: 78 | Batch_idx: 110 |  Loss: (0.2713) |  Loss2: (0.0000) | Acc: (90.00%) (12909/14208)
Epoch: 78 | Batch_idx: 120 |  Loss: (0.2743) |  Loss2: (0.0000) | Acc: (90.00%) (14053/15488)
Epoch: 78 | Batch_idx: 130 |  Loss: (0.2744) |  Loss2: (0.0000) | Acc: (90.00%) (15207/16768)
Epoch: 78 | Batch_idx: 140 |  Loss: (0.2745) |  Loss2: (0.0000) | Acc: (90.00%) (16367/18048)
Epoch: 78 | Batch_idx: 150 |  Loss: (0.2750) |  Loss2: (0.0000) | Acc: (90.00%) (17516/19328)
Epoch: 78 | Batch_idx: 160 |  Loss: (0.2742) |  Loss2: (0.0000) | Acc: (90.00%) (18668/20608)
Epoch: 78 | Batch_idx: 170 |  Loss: (0.2753) |  Loss2: (0.0000) | Acc: (90.00%) (19816/21888)
Epoch: 78 | Batch_idx: 180 |  Loss: (0.2754) |  Loss2: (0.0000) | Acc: (90.00%) (20982/23168)
Epoch: 78 | Batch_idx: 190 |  Loss: (0.2767) |  Loss2: (0.0000) | Acc: (90.00%) (22120/24448)
Epoch: 78 | Batch_idx: 200 |  Loss: (0.2758) |  Loss2: (0.0000) | Acc: (90.00%) (23289/25728)
Epoch: 78 | Batch_idx: 210 |  Loss: (0.2762) |  Loss2: (0.0000) | Acc: (90.00%) (24453/27008)
Epoch: 78 | Batch_idx: 220 |  Loss: (0.2778) |  Loss2: (0.0000) | Acc: (90.00%) (25590/28288)
Epoch: 78 | Batch_idx: 230 |  Loss: (0.2773) |  Loss2: (0.0000) | Acc: (90.00%) (26749/29568)
Epoch: 78 | Batch_idx: 240 |  Loss: (0.2767) |  Loss2: (0.0000) | Acc: (90.00%) (27904/30848)
Epoch: 78 | Batch_idx: 250 |  Loss: (0.2774) |  Loss2: (0.0000) | Acc: (90.00%) (29055/32128)
Epoch: 78 | Batch_idx: 260 |  Loss: (0.2772) |  Loss2: (0.0000) | Acc: (90.00%) (30212/33408)
Epoch: 78 | Batch_idx: 270 |  Loss: (0.2771) |  Loss2: (0.0000) | Acc: (90.00%) (31369/34688)
Epoch: 78 | Batch_idx: 280 |  Loss: (0.2779) |  Loss2: (0.0000) | Acc: (90.00%) (32516/35968)
Epoch: 78 | Batch_idx: 290 |  Loss: (0.2781) |  Loss2: (0.0000) | Acc: (90.00%) (33660/37248)
Epoch: 78 | Batch_idx: 300 |  Loss: (0.2785) |  Loss2: (0.0000) | Acc: (90.00%) (34817/38528)
Epoch: 78 | Batch_idx: 310 |  Loss: (0.2776) |  Loss2: (0.0000) | Acc: (90.00%) (35985/39808)
Epoch: 78 | Batch_idx: 320 |  Loss: (0.2772) |  Loss2: (0.0000) | Acc: (90.00%) (37151/41088)
Epoch: 78 | Batch_idx: 330 |  Loss: (0.2774) |  Loss2: (0.0000) | Acc: (90.00%) (38308/42368)
Epoch: 78 | Batch_idx: 340 |  Loss: (0.2776) |  Loss2: (0.0000) | Acc: (90.00%) (39464/43648)
Epoch: 78 | Batch_idx: 350 |  Loss: (0.2775) |  Loss2: (0.0000) | Acc: (90.00%) (40618/44928)
Epoch: 78 | Batch_idx: 360 |  Loss: (0.2772) |  Loss2: (0.0000) | Acc: (90.00%) (41776/46208)
Epoch: 78 | Batch_idx: 370 |  Loss: (0.2775) |  Loss2: (0.0000) | Acc: (90.00%) (42923/47488)
Epoch: 78 | Batch_idx: 380 |  Loss: (0.2777) |  Loss2: (0.0000) | Acc: (90.00%) (44077/48768)
Epoch: 78 | Batch_idx: 390 |  Loss: (0.2775) |  Loss2: (0.0000) | Acc: (90.00%) (45199/50000)
# TEST : Loss: (0.4688) | Acc: (84.00%) (8448/10000)
percent tensor([0.5368, 0.5431, 0.5380, 0.5358, 0.5399, 0.5386, 0.5446, 0.5364, 0.5363,
        0.5406, 0.5403, 0.5423, 0.5396, 0.5358, 0.5431, 0.5385],
       device='cuda:0') torch.Size([16])
percent tensor([0.5092, 0.5107, 0.5042, 0.5073, 0.5049, 0.5125, 0.5079, 0.5047, 0.5064,
        0.5096, 0.5115, 0.5068, 0.5092, 0.5084, 0.5115, 0.5095],
       device='cuda:0') torch.Size([16])
percent tensor([0.5128, 0.3991, 0.6370, 0.6168, 0.6368, 0.5843, 0.5039, 0.6222, 0.5435,
        0.4712, 0.4055, 0.5533, 0.4159, 0.4636, 0.4793, 0.5417],
       device='cuda:0') torch.Size([16])
percent tensor([0.6744, 0.7054, 0.5945, 0.6199, 0.6103, 0.5652, 0.6730, 0.6212, 0.6782,
        0.6958, 0.7232, 0.6493, 0.6917, 0.7020, 0.6687, 0.6469],
       device='cuda:0') torch.Size([16])
percent tensor([0.6688, 0.5976, 0.6735, 0.6878, 0.6860, 0.7139, 0.6509, 0.6754, 0.6449,
        0.6019, 0.5838, 0.6157, 0.5930, 0.6358, 0.6542, 0.6932],
       device='cuda:0') torch.Size([16])
percent tensor([0.5425, 0.5718, 0.6569, 0.6965, 0.6977, 0.7226, 0.6013, 0.5743, 0.6253,
        0.5666, 0.5870, 0.6157, 0.5729, 0.6362, 0.5247, 0.5991],
       device='cuda:0') torch.Size([16])
percent tensor([0.5925, 0.6507, 0.6474, 0.6512, 0.6390, 0.6078, 0.6395, 0.5786, 0.6820,
        0.6580, 0.7162, 0.6765, 0.6345, 0.7400, 0.6002, 0.5336],
       device='cuda:0') torch.Size([16])
percent tensor([0.9992, 0.9994, 0.9996, 0.9998, 0.9999, 0.9988, 0.9994, 0.9997, 0.9995,
        0.9995, 0.9989, 0.9997, 0.9989, 0.9995, 0.9997, 0.9994],
       device='cuda:0') torch.Size([16])
Epoch: 79 | Batch_idx: 0 |  Loss: (0.2156) |  Loss2: (0.0000) | Acc: (92.00%) (118/128)
Epoch: 79 | Batch_idx: 10 |  Loss: (0.2768) |  Loss2: (0.0000) | Acc: (90.00%) (1269/1408)
Epoch: 79 | Batch_idx: 20 |  Loss: (0.2699) |  Loss2: (0.0000) | Acc: (89.00%) (2419/2688)
Epoch: 79 | Batch_idx: 30 |  Loss: (0.2623) |  Loss2: (0.0000) | Acc: (90.00%) (3590/3968)
Epoch: 79 | Batch_idx: 40 |  Loss: (0.2626) |  Loss2: (0.0000) | Acc: (90.00%) (4741/5248)
Epoch: 79 | Batch_idx: 50 |  Loss: (0.2640) |  Loss2: (0.0000) | Acc: (90.00%) (5901/6528)
Epoch: 79 | Batch_idx: 60 |  Loss: (0.2618) |  Loss2: (0.0000) | Acc: (90.00%) (7067/7808)
Epoch: 79 | Batch_idx: 70 |  Loss: (0.2609) |  Loss2: (0.0000) | Acc: (90.00%) (8235/9088)
Epoch: 79 | Batch_idx: 80 |  Loss: (0.2640) |  Loss2: (0.0000) | Acc: (90.00%) (9383/10368)
Epoch: 79 | Batch_idx: 90 |  Loss: (0.2669) |  Loss2: (0.0000) | Acc: (90.00%) (10534/11648)
Epoch: 79 | Batch_idx: 100 |  Loss: (0.2661) |  Loss2: (0.0000) | Acc: (90.00%) (11699/12928)
Epoch: 79 | Batch_idx: 110 |  Loss: (0.2654) |  Loss2: (0.0000) | Acc: (90.00%) (12857/14208)
Epoch: 79 | Batch_idx: 120 |  Loss: (0.2652) |  Loss2: (0.0000) | Acc: (90.00%) (14007/15488)
Epoch: 79 | Batch_idx: 130 |  Loss: (0.2639) |  Loss2: (0.0000) | Acc: (90.00%) (15172/16768)
Epoch: 79 | Batch_idx: 140 |  Loss: (0.2650) |  Loss2: (0.0000) | Acc: (90.00%) (16320/18048)
Epoch: 79 | Batch_idx: 150 |  Loss: (0.2643) |  Loss2: (0.0000) | Acc: (90.00%) (17492/19328)
Epoch: 79 | Batch_idx: 160 |  Loss: (0.2636) |  Loss2: (0.0000) | Acc: (90.00%) (18654/20608)
Epoch: 79 | Batch_idx: 170 |  Loss: (0.2623) |  Loss2: (0.0000) | Acc: (90.00%) (19834/21888)
Epoch: 79 | Batch_idx: 180 |  Loss: (0.2611) |  Loss2: (0.0000) | Acc: (90.00%) (20998/23168)
Epoch: 79 | Batch_idx: 190 |  Loss: (0.2618) |  Loss2: (0.0000) | Acc: (90.00%) (22148/24448)
Epoch: 79 | Batch_idx: 200 |  Loss: (0.2631) |  Loss2: (0.0000) | Acc: (90.00%) (23297/25728)
Epoch: 79 | Batch_idx: 210 |  Loss: (0.2639) |  Loss2: (0.0000) | Acc: (90.00%) (24455/27008)
Epoch: 79 | Batch_idx: 220 |  Loss: (0.2634) |  Loss2: (0.0000) | Acc: (90.00%) (25628/28288)
Epoch: 79 | Batch_idx: 230 |  Loss: (0.2635) |  Loss2: (0.0000) | Acc: (90.00%) (26790/29568)
Epoch: 79 | Batch_idx: 240 |  Loss: (0.2630) |  Loss2: (0.0000) | Acc: (90.00%) (27960/30848)
Epoch: 79 | Batch_idx: 250 |  Loss: (0.2634) |  Loss2: (0.0000) | Acc: (90.00%) (29116/32128)
Epoch: 79 | Batch_idx: 260 |  Loss: (0.2638) |  Loss2: (0.0000) | Acc: (90.00%) (30281/33408)
Epoch: 79 | Batch_idx: 270 |  Loss: (0.2647) |  Loss2: (0.0000) | Acc: (90.00%) (31422/34688)
Epoch: 79 | Batch_idx: 280 |  Loss: (0.2649) |  Loss2: (0.0000) | Acc: (90.00%) (32589/35968)
Epoch: 79 | Batch_idx: 290 |  Loss: (0.2655) |  Loss2: (0.0000) | Acc: (90.00%) (33752/37248)
Epoch: 79 | Batch_idx: 300 |  Loss: (0.2658) |  Loss2: (0.0000) | Acc: (90.00%) (34903/38528)
Epoch: 79 | Batch_idx: 310 |  Loss: (0.2658) |  Loss2: (0.0000) | Acc: (90.00%) (36061/39808)
Epoch: 79 | Batch_idx: 320 |  Loss: (0.2663) |  Loss2: (0.0000) | Acc: (90.00%) (37224/41088)
Epoch: 79 | Batch_idx: 330 |  Loss: (0.2668) |  Loss2: (0.0000) | Acc: (90.00%) (38366/42368)
Epoch: 79 | Batch_idx: 340 |  Loss: (0.2678) |  Loss2: (0.0000) | Acc: (90.00%) (39512/43648)
Epoch: 79 | Batch_idx: 350 |  Loss: (0.2680) |  Loss2: (0.0000) | Acc: (90.00%) (40659/44928)
Epoch: 79 | Batch_idx: 360 |  Loss: (0.2686) |  Loss2: (0.0000) | Acc: (90.00%) (41811/46208)
Epoch: 79 | Batch_idx: 370 |  Loss: (0.2691) |  Loss2: (0.0000) | Acc: (90.00%) (42966/47488)
Epoch: 79 | Batch_idx: 380 |  Loss: (0.2685) |  Loss2: (0.0000) | Acc: (90.00%) (44144/48768)
Epoch: 79 | Batch_idx: 390 |  Loss: (0.2685) |  Loss2: (0.0000) | Acc: (90.00%) (45266/50000)
# TEST : Loss: (0.4472) | Acc: (85.00%) (8523/10000)
percent tensor([0.5368, 0.5438, 0.5370, 0.5354, 0.5388, 0.5387, 0.5445, 0.5361, 0.5361,
        0.5408, 0.5407, 0.5417, 0.5399, 0.5363, 0.5438, 0.5384],
       device='cuda:0') torch.Size([16])
percent tensor([0.5093, 0.5106, 0.5045, 0.5074, 0.5055, 0.5127, 0.5083, 0.5045, 0.5062,
        0.5098, 0.5110, 0.5075, 0.5093, 0.5082, 0.5113, 0.5097],
       device='cuda:0') torch.Size([16])
percent tensor([0.5181, 0.3977, 0.6450, 0.6263, 0.6401, 0.5899, 0.5049, 0.6231, 0.5466,
        0.4628, 0.4027, 0.5659, 0.4139, 0.4707, 0.4845, 0.5409],
       device='cuda:0') torch.Size([16])
percent tensor([0.6743, 0.7092, 0.5913, 0.6228, 0.6129, 0.5598, 0.6745, 0.6222, 0.6845,
        0.7049, 0.7241, 0.6560, 0.6964, 0.7071, 0.6666, 0.6523],
       device='cuda:0') torch.Size([16])
percent tensor([0.6716, 0.5890, 0.6849, 0.7000, 0.6972, 0.7159, 0.6573, 0.6832, 0.6498,
        0.5964, 0.5812, 0.6222, 0.5859, 0.6405, 0.6580, 0.6974],
       device='cuda:0') torch.Size([16])
percent tensor([0.5501, 0.5834, 0.6739, 0.7046, 0.7005, 0.7202, 0.6080, 0.5779, 0.6172,
        0.5847, 0.6021, 0.6328, 0.5763, 0.6222, 0.5502, 0.5992],
       device='cuda:0') torch.Size([16])
percent tensor([0.5777, 0.6405, 0.6307, 0.6603, 0.6319, 0.6223, 0.6163, 0.5494, 0.6631,
        0.6602, 0.7107, 0.6713, 0.6258, 0.7239, 0.5778, 0.5329],
       device='cuda:0') torch.Size([16])
percent tensor([0.9997, 0.9994, 0.9997, 0.9998, 0.9999, 0.9982, 0.9996, 0.9997, 0.9996,
        0.9997, 0.9988, 0.9998, 0.9992, 0.9996, 0.9995, 0.9996],
       device='cuda:0') torch.Size([16])
Epoch: 80 | Batch_idx: 0 |  Loss: (0.2511) |  Loss2: (0.0000) | Acc: (94.00%) (121/128)
Epoch: 80 | Batch_idx: 10 |  Loss: (0.2492) |  Loss2: (0.0000) | Acc: (92.00%) (1302/1408)
Epoch: 80 | Batch_idx: 20 |  Loss: (0.2328) |  Loss2: (0.0000) | Acc: (92.00%) (2487/2688)
Epoch: 80 | Batch_idx: 30 |  Loss: (0.2431) |  Loss2: (0.0000) | Acc: (92.00%) (3656/3968)
Epoch: 80 | Batch_idx: 40 |  Loss: (0.2391) |  Loss2: (0.0000) | Acc: (92.00%) (4843/5248)
Epoch: 80 | Batch_idx: 50 |  Loss: (0.2454) |  Loss2: (0.0000) | Acc: (91.00%) (6001/6528)
Epoch: 80 | Batch_idx: 60 |  Loss: (0.2483) |  Loss2: (0.0000) | Acc: (91.00%) (7166/7808)
Epoch: 80 | Batch_idx: 70 |  Loss: (0.2490) |  Loss2: (0.0000) | Acc: (91.00%) (8333/9088)
Epoch: 80 | Batch_idx: 80 |  Loss: (0.2461) |  Loss2: (0.0000) | Acc: (91.00%) (9508/10368)
Epoch: 80 | Batch_idx: 90 |  Loss: (0.2481) |  Loss2: (0.0000) | Acc: (91.00%) (10665/11648)
Epoch: 80 | Batch_idx: 100 |  Loss: (0.2500) |  Loss2: (0.0000) | Acc: (91.00%) (11828/12928)
Epoch: 80 | Batch_idx: 110 |  Loss: (0.2483) |  Loss2: (0.0000) | Acc: (91.00%) (13021/14208)
Epoch: 80 | Batch_idx: 120 |  Loss: (0.2493) |  Loss2: (0.0000) | Acc: (91.00%) (14183/15488)
Epoch: 80 | Batch_idx: 130 |  Loss: (0.2507) |  Loss2: (0.0000) | Acc: (91.00%) (15347/16768)
Epoch: 80 | Batch_idx: 140 |  Loss: (0.2512) |  Loss2: (0.0000) | Acc: (91.00%) (16513/18048)
Epoch: 80 | Batch_idx: 150 |  Loss: (0.2517) |  Loss2: (0.0000) | Acc: (91.00%) (17673/19328)
Epoch: 80 | Batch_idx: 160 |  Loss: (0.2526) |  Loss2: (0.0000) | Acc: (91.00%) (18850/20608)
Epoch: 80 | Batch_idx: 170 |  Loss: (0.2559) |  Loss2: (0.0000) | Acc: (91.00%) (19990/21888)
Epoch: 80 | Batch_idx: 180 |  Loss: (0.2559) |  Loss2: (0.0000) | Acc: (91.00%) (21161/23168)
Epoch: 80 | Batch_idx: 190 |  Loss: (0.2569) |  Loss2: (0.0000) | Acc: (91.00%) (22327/24448)
Epoch: 80 | Batch_idx: 200 |  Loss: (0.2581) |  Loss2: (0.0000) | Acc: (91.00%) (23476/25728)
Epoch: 80 | Batch_idx: 210 |  Loss: (0.2591) |  Loss2: (0.0000) | Acc: (91.00%) (24627/27008)
Epoch: 80 | Batch_idx: 220 |  Loss: (0.2592) |  Loss2: (0.0000) | Acc: (91.00%) (25797/28288)
Epoch: 80 | Batch_idx: 230 |  Loss: (0.2589) |  Loss2: (0.0000) | Acc: (91.00%) (26971/29568)
Epoch: 80 | Batch_idx: 240 |  Loss: (0.2584) |  Loss2: (0.0000) | Acc: (91.00%) (28146/30848)
Epoch: 80 | Batch_idx: 250 |  Loss: (0.2585) |  Loss2: (0.0000) | Acc: (91.00%) (29308/32128)
Epoch: 80 | Batch_idx: 260 |  Loss: (0.2580) |  Loss2: (0.0000) | Acc: (91.00%) (30483/33408)
Epoch: 80 | Batch_idx: 270 |  Loss: (0.2587) |  Loss2: (0.0000) | Acc: (91.00%) (31641/34688)
Epoch: 80 | Batch_idx: 280 |  Loss: (0.2594) |  Loss2: (0.0000) | Acc: (91.00%) (32799/35968)
Epoch: 80 | Batch_idx: 290 |  Loss: (0.2603) |  Loss2: (0.0000) | Acc: (91.00%) (33956/37248)
Epoch: 80 | Batch_idx: 300 |  Loss: (0.2605) |  Loss2: (0.0000) | Acc: (91.00%) (35128/38528)
Epoch: 80 | Batch_idx: 310 |  Loss: (0.2601) |  Loss2: (0.0000) | Acc: (91.00%) (36293/39808)
Epoch: 80 | Batch_idx: 320 |  Loss: (0.2609) |  Loss2: (0.0000) | Acc: (91.00%) (37440/41088)
Epoch: 80 | Batch_idx: 330 |  Loss: (0.2622) |  Loss2: (0.0000) | Acc: (91.00%) (38590/42368)
Epoch: 80 | Batch_idx: 340 |  Loss: (0.2617) |  Loss2: (0.0000) | Acc: (91.00%) (39752/43648)
Epoch: 80 | Batch_idx: 350 |  Loss: (0.2624) |  Loss2: (0.0000) | Acc: (91.00%) (40907/44928)
Epoch: 80 | Batch_idx: 360 |  Loss: (0.2626) |  Loss2: (0.0000) | Acc: (91.00%) (42069/46208)
Epoch: 80 | Batch_idx: 370 |  Loss: (0.2631) |  Loss2: (0.0000) | Acc: (90.00%) (43213/47488)
Epoch: 80 | Batch_idx: 380 |  Loss: (0.2634) |  Loss2: (0.0000) | Acc: (90.00%) (44370/48768)
Epoch: 80 | Batch_idx: 390 |  Loss: (0.2644) |  Loss2: (0.0000) | Acc: (90.00%) (45477/50000)
=> saving checkpoint 'drive/app/torch/save_Schedule/checkpoint_080.pth.tar'
# TEST : Loss: (0.4417) | Acc: (85.00%) (8549/10000)
percent tensor([0.5364, 0.5442, 0.5380, 0.5352, 0.5395, 0.5382, 0.5449, 0.5363, 0.5363,
        0.5414, 0.5401, 0.5423, 0.5392, 0.5375, 0.5437, 0.5383],
       device='cuda:0') torch.Size([16])
percent tensor([0.5092, 0.5106, 0.5038, 0.5078, 0.5046, 0.5135, 0.5079, 0.5046, 0.5054,
        0.5093, 0.5108, 0.5066, 0.5088, 0.5087, 0.5117, 0.5100],
       device='cuda:0') torch.Size([16])
percent tensor([0.5308, 0.3866, 0.6520, 0.6215, 0.6465, 0.5897, 0.4992, 0.6247, 0.5603,
        0.4688, 0.4115, 0.5830, 0.4358, 0.4093, 0.4780, 0.5363],
       device='cuda:0') torch.Size([16])
percent tensor([0.6808, 0.7031, 0.5978, 0.6216, 0.6131, 0.5690, 0.6718, 0.6235, 0.6742,
        0.6991, 0.7238, 0.6528, 0.6964, 0.6958, 0.6714, 0.6560],
       device='cuda:0') torch.Size([16])
percent tensor([0.6724, 0.5919, 0.6712, 0.6858, 0.6842, 0.7115, 0.6581, 0.6799, 0.6483,
        0.5954, 0.5807, 0.6113, 0.5862, 0.6546, 0.6524, 0.6944],
       device='cuda:0') torch.Size([16])
percent tensor([0.5452, 0.6156, 0.6540, 0.7110, 0.6939, 0.7214, 0.5958, 0.5585, 0.6371,
        0.5755, 0.6093, 0.6385, 0.5886, 0.6594, 0.5410, 0.6003],
       device='cuda:0') torch.Size([16])
percent tensor([0.5587, 0.6587, 0.6358, 0.6780, 0.6372, 0.6309, 0.6087, 0.5508, 0.6800,
        0.6648, 0.7067, 0.6870, 0.6343, 0.7199, 0.5727, 0.5394],
       device='cuda:0') torch.Size([16])
percent tensor([0.9996, 0.9992, 0.9996, 0.9998, 0.9999, 0.9988, 0.9993, 0.9997, 0.9993,
        0.9997, 0.9988, 0.9996, 0.9991, 0.9989, 0.9995, 0.9995],
       device='cuda:0') torch.Size([16])
False Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=128, out_features=16, bias=False)
True Linear(in_features=16, out_features=2, bias=False)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=128, out_features=16, bias=False)
True Linear(in_features=16, out_features=2, bias=False)
False Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=256, out_features=32, bias=False)
True Linear(in_features=32, out_features=2, bias=False)
False Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=256, out_features=32, bias=False)
True Linear(in_features=32, out_features=2, bias=False)
False Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=512, out_features=64, bias=False)
True Linear(in_features=64, out_features=2, bias=False)
False Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=512, out_features=64, bias=False)
True Linear(in_features=64, out_features=2, bias=False)
False Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1024, out_features=128, bias=False)
True Linear(in_features=128, out_features=2, bias=False)
False Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1024, out_features=128, bias=False)
True Linear(in_features=128, out_features=2, bias=False)
False Linear(in_features=512, out_features=10, bias=True)
Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 3, 3, 3]) tensor(179.3733, device='cuda:0')
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(805.3427, device='cuda:0')
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(808.0535, device='cuda:0')
Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([128, 64, 3, 3]) tensor(1521.3613, device='cuda:0')
Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([128, 64, 1, 1]) tensor(502.8482, device='cuda:0')
Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([128, 128, 3, 3]) tensor(2224.5513, device='cuda:0')
Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([256, 128, 3, 3]) tensor(4295.5825, device='cuda:0')
Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([256, 128, 1, 1]) tensor(1413.6492, device='cuda:0')
Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([256, 256, 3, 3]) tensor(6126.6646, device='cuda:0')
Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([512, 256, 3, 3]) tensor(11950.6709, device='cuda:0')
Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([512, 256, 1, 1]) tensor(3973.8438, device='cuda:0')
Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([512, 512, 3, 3]) tensor(16766.9727, device='cuda:0')
Epoch: 81 | Batch_idx: 0 |  Loss: (0.2712) |  Loss2: (0.0000) | Acc: (88.00%) (113/128)
Epoch: 81 | Batch_idx: 10 |  Loss: (0.3295) |  Loss2: (0.0000) | Acc: (88.00%) (1243/1408)
Epoch: 81 | Batch_idx: 20 |  Loss: (0.3440) |  Loss2: (0.0000) | Acc: (87.00%) (2354/2688)
Epoch: 81 | Batch_idx: 30 |  Loss: (0.3446) |  Loss2: (0.0000) | Acc: (87.00%) (3483/3968)
Epoch: 81 | Batch_idx: 40 |  Loss: (0.3515) |  Loss2: (0.0000) | Acc: (87.00%) (4600/5248)
Epoch: 81 | Batch_idx: 50 |  Loss: (0.3531) |  Loss2: (0.0000) | Acc: (87.00%) (5725/6528)
Epoch: 81 | Batch_idx: 60 |  Loss: (0.3557) |  Loss2: (0.0000) | Acc: (87.00%) (6838/7808)
Epoch: 81 | Batch_idx: 70 |  Loss: (0.3554) |  Loss2: (0.0000) | Acc: (87.00%) (7963/9088)
Epoch: 81 | Batch_idx: 80 |  Loss: (0.3549) |  Loss2: (0.0000) | Acc: (87.00%) (9091/10368)
Epoch: 81 | Batch_idx: 90 |  Loss: (0.3556) |  Loss2: (0.0000) | Acc: (87.00%) (10196/11648)
Epoch: 81 | Batch_idx: 100 |  Loss: (0.3568) |  Loss2: (0.0000) | Acc: (87.00%) (11297/12928)
Epoch: 81 | Batch_idx: 110 |  Loss: (0.3619) |  Loss2: (0.0000) | Acc: (87.00%) (12384/14208)
Epoch: 81 | Batch_idx: 120 |  Loss: (0.3585) |  Loss2: (0.0000) | Acc: (87.00%) (13506/15488)
Epoch: 81 | Batch_idx: 130 |  Loss: (0.3563) |  Loss2: (0.0000) | Acc: (87.00%) (14641/16768)
Epoch: 81 | Batch_idx: 140 |  Loss: (0.3574) |  Loss2: (0.0000) | Acc: (87.00%) (15749/18048)
Epoch: 81 | Batch_idx: 150 |  Loss: (0.3567) |  Loss2: (0.0000) | Acc: (87.00%) (16866/19328)
Epoch: 81 | Batch_idx: 160 |  Loss: (0.3553) |  Loss2: (0.0000) | Acc: (87.00%) (17992/20608)
Epoch: 81 | Batch_idx: 170 |  Loss: (0.3558) |  Loss2: (0.0000) | Acc: (87.00%) (19116/21888)
Epoch: 81 | Batch_idx: 180 |  Loss: (0.3543) |  Loss2: (0.0000) | Acc: (87.00%) (20256/23168)
Epoch: 81 | Batch_idx: 190 |  Loss: (0.3528) |  Loss2: (0.0000) | Acc: (87.00%) (21392/24448)
Epoch: 81 | Batch_idx: 200 |  Loss: (0.3530) |  Loss2: (0.0000) | Acc: (87.00%) (22512/25728)
Epoch: 81 | Batch_idx: 210 |  Loss: (0.3496) |  Loss2: (0.0000) | Acc: (87.00%) (23667/27008)
Epoch: 81 | Batch_idx: 220 |  Loss: (0.3466) |  Loss2: (0.0000) | Acc: (87.00%) (24827/28288)
Epoch: 81 | Batch_idx: 230 |  Loss: (0.3443) |  Loss2: (0.0000) | Acc: (87.00%) (25979/29568)
Epoch: 81 | Batch_idx: 240 |  Loss: (0.3434) |  Loss2: (0.0000) | Acc: (87.00%) (27103/30848)
Epoch: 81 | Batch_idx: 250 |  Loss: (0.3447) |  Loss2: (0.0000) | Acc: (87.00%) (28209/32128)
Epoch: 81 | Batch_idx: 260 |  Loss: (0.3430) |  Loss2: (0.0000) | Acc: (87.00%) (29345/33408)
Epoch: 81 | Batch_idx: 270 |  Loss: (0.3416) |  Loss2: (0.0000) | Acc: (87.00%) (30493/34688)
Epoch: 81 | Batch_idx: 280 |  Loss: (0.3411) |  Loss2: (0.0000) | Acc: (87.00%) (31636/35968)
Epoch: 81 | Batch_idx: 290 |  Loss: (0.3412) |  Loss2: (0.0000) | Acc: (87.00%) (32763/37248)
Epoch: 81 | Batch_idx: 300 |  Loss: (0.3404) |  Loss2: (0.0000) | Acc: (87.00%) (33902/38528)
Epoch: 81 | Batch_idx: 310 |  Loss: (0.3396) |  Loss2: (0.0000) | Acc: (88.00%) (35034/39808)
Epoch: 81 | Batch_idx: 320 |  Loss: (0.3387) |  Loss2: (0.0000) | Acc: (88.00%) (36170/41088)
Epoch: 81 | Batch_idx: 330 |  Loss: (0.3371) |  Loss2: (0.0000) | Acc: (88.00%) (37317/42368)
Epoch: 81 | Batch_idx: 340 |  Loss: (0.3364) |  Loss2: (0.0000) | Acc: (88.00%) (38460/43648)
Epoch: 81 | Batch_idx: 350 |  Loss: (0.3357) |  Loss2: (0.0000) | Acc: (88.00%) (39597/44928)
Epoch: 81 | Batch_idx: 360 |  Loss: (0.3333) |  Loss2: (0.0000) | Acc: (88.00%) (40764/46208)
Epoch: 81 | Batch_idx: 370 |  Loss: (0.3322) |  Loss2: (0.0000) | Acc: (88.00%) (41917/47488)
Epoch: 81 | Batch_idx: 380 |  Loss: (0.3307) |  Loss2: (0.0000) | Acc: (88.00%) (43079/48768)
Epoch: 81 | Batch_idx: 390 |  Loss: (0.3299) |  Loss2: (0.0000) | Acc: (88.00%) (44182/50000)
# TEST : Loss: (0.4362) | Acc: (85.00%) (8572/10000)
percent tensor([0.5456, 0.5541, 0.5481, 0.5436, 0.5495, 0.5475, 0.5552, 0.5453, 0.5455,
        0.5514, 0.5495, 0.5528, 0.5486, 0.5464, 0.5533, 0.5473],
       device='cuda:0') torch.Size([16])
percent tensor([0.5059, 0.5069, 0.5021, 0.5046, 0.5020, 0.5097, 0.5045, 0.5023, 0.5028,
        0.5060, 0.5072, 0.5038, 0.5054, 0.5057, 0.5077, 0.5066],
       device='cuda:0') torch.Size([16])
percent tensor([0.5453, 0.4166, 0.6618, 0.6458, 0.6615, 0.6111, 0.5232, 0.6462, 0.5764,
        0.5000, 0.4304, 0.5969, 0.4547, 0.4610, 0.5061, 0.5730],
       device='cuda:0') torch.Size([16])
percent tensor([0.6723, 0.6955, 0.5937, 0.6054, 0.6028, 0.5548, 0.6649, 0.6109, 0.6671,
        0.6924, 0.7189, 0.6525, 0.6930, 0.6868, 0.6635, 0.6355],
       device='cuda:0') torch.Size([16])
percent tensor([0.6639, 0.5901, 0.6828, 0.7063, 0.6964, 0.7241, 0.6615, 0.7012, 0.6391,
        0.5749, 0.5580, 0.6128, 0.5637, 0.6541, 0.6575, 0.6948],
       device='cuda:0') torch.Size([16])
percent tensor([0.5156, 0.5997, 0.6274, 0.6920, 0.6773, 0.6961, 0.5745, 0.5180, 0.6294,
        0.5622, 0.5938, 0.6157, 0.5709, 0.6494, 0.5044, 0.5618],
       device='cuda:0') torch.Size([16])
percent tensor([0.5125, 0.6148, 0.6034, 0.6623, 0.6013, 0.6023, 0.5585, 0.5133, 0.6626,
        0.6188, 0.6761, 0.6465, 0.6154, 0.6917, 0.5225, 0.4910],
       device='cuda:0') torch.Size([16])
percent tensor([0.9996, 0.9993, 0.9995, 0.9997, 0.9999, 0.9981, 0.9995, 0.9997, 0.9991,
        0.9997, 0.9992, 0.9998, 0.9989, 0.9994, 0.9995, 0.9995],
       device='cuda:0') torch.Size([16])
Epoch: 82 | Batch_idx: 0 |  Loss: (0.2174) |  Loss2: (0.0000) | Acc: (93.00%) (120/128)
Epoch: 82 | Batch_idx: 10 |  Loss: (0.2779) |  Loss2: (0.0000) | Acc: (90.00%) (1271/1408)
Epoch: 82 | Batch_idx: 20 |  Loss: (0.2901) |  Loss2: (0.0000) | Acc: (89.00%) (2415/2688)
Epoch: 82 | Batch_idx: 30 |  Loss: (0.2858) |  Loss2: (0.0000) | Acc: (90.00%) (3578/3968)
Epoch: 82 | Batch_idx: 40 |  Loss: (0.2962) |  Loss2: (0.0000) | Acc: (89.00%) (4713/5248)
Epoch: 82 | Batch_idx: 50 |  Loss: (0.2988) |  Loss2: (0.0000) | Acc: (89.00%) (5846/6528)
Epoch: 82 | Batch_idx: 60 |  Loss: (0.2996) |  Loss2: (0.0000) | Acc: (89.00%) (6991/7808)
Epoch: 82 | Batch_idx: 70 |  Loss: (0.2999) |  Loss2: (0.0000) | Acc: (89.00%) (8137/9088)
Epoch: 82 | Batch_idx: 80 |  Loss: (0.2946) |  Loss2: (0.0000) | Acc: (89.00%) (9304/10368)
Epoch: 82 | Batch_idx: 90 |  Loss: (0.2940) |  Loss2: (0.0000) | Acc: (89.00%) (10466/11648)
Epoch: 82 | Batch_idx: 100 |  Loss: (0.2978) |  Loss2: (0.0000) | Acc: (89.00%) (11600/12928)
Epoch: 82 | Batch_idx: 110 |  Loss: (0.2955) |  Loss2: (0.0000) | Acc: (89.00%) (12768/14208)
Epoch: 82 | Batch_idx: 120 |  Loss: (0.2961) |  Loss2: (0.0000) | Acc: (89.00%) (13926/15488)
Epoch: 82 | Batch_idx: 130 |  Loss: (0.2952) |  Loss2: (0.0000) | Acc: (89.00%) (15066/16768)
Epoch: 82 | Batch_idx: 140 |  Loss: (0.2951) |  Loss2: (0.0000) | Acc: (89.00%) (16217/18048)
Epoch: 82 | Batch_idx: 150 |  Loss: (0.2955) |  Loss2: (0.0000) | Acc: (89.00%) (17361/19328)
Epoch: 82 | Batch_idx: 160 |  Loss: (0.2943) |  Loss2: (0.0000) | Acc: (89.00%) (18524/20608)
Epoch: 82 | Batch_idx: 170 |  Loss: (0.2948) |  Loss2: (0.0000) | Acc: (89.00%) (19675/21888)
Epoch: 82 | Batch_idx: 180 |  Loss: (0.2957) |  Loss2: (0.0000) | Acc: (89.00%) (20820/23168)
Epoch: 82 | Batch_idx: 190 |  Loss: (0.2943) |  Loss2: (0.0000) | Acc: (89.00%) (21975/24448)
Epoch: 82 | Batch_idx: 200 |  Loss: (0.2942) |  Loss2: (0.0000) | Acc: (89.00%) (23129/25728)
Epoch: 82 | Batch_idx: 210 |  Loss: (0.2930) |  Loss2: (0.0000) | Acc: (89.00%) (24304/27008)
Epoch: 82 | Batch_idx: 220 |  Loss: (0.2922) |  Loss2: (0.0000) | Acc: (89.00%) (25452/28288)
Epoch: 82 | Batch_idx: 230 |  Loss: (0.2922) |  Loss2: (0.0000) | Acc: (89.00%) (26590/29568)
Epoch: 82 | Batch_idx: 240 |  Loss: (0.2921) |  Loss2: (0.0000) | Acc: (89.00%) (27731/30848)
Epoch: 82 | Batch_idx: 250 |  Loss: (0.2919) |  Loss2: (0.0000) | Acc: (89.00%) (28876/32128)
Epoch: 82 | Batch_idx: 260 |  Loss: (0.2923) |  Loss2: (0.0000) | Acc: (89.00%) (30024/33408)
Epoch: 82 | Batch_idx: 270 |  Loss: (0.2916) |  Loss2: (0.0000) | Acc: (89.00%) (31189/34688)
Epoch: 82 | Batch_idx: 280 |  Loss: (0.2905) |  Loss2: (0.0000) | Acc: (89.00%) (32363/35968)
Epoch: 82 | Batch_idx: 290 |  Loss: (0.2901) |  Loss2: (0.0000) | Acc: (90.00%) (33525/37248)
Epoch: 82 | Batch_idx: 300 |  Loss: (0.2891) |  Loss2: (0.0000) | Acc: (90.00%) (34693/38528)
Epoch: 82 | Batch_idx: 310 |  Loss: (0.2884) |  Loss2: (0.0000) | Acc: (90.00%) (35862/39808)
Epoch: 82 | Batch_idx: 320 |  Loss: (0.2883) |  Loss2: (0.0000) | Acc: (90.00%) (37006/41088)
Epoch: 82 | Batch_idx: 330 |  Loss: (0.2875) |  Loss2: (0.0000) | Acc: (90.00%) (38171/42368)
Epoch: 82 | Batch_idx: 340 |  Loss: (0.2876) |  Loss2: (0.0000) | Acc: (90.00%) (39315/43648)
Epoch: 82 | Batch_idx: 350 |  Loss: (0.2890) |  Loss2: (0.0000) | Acc: (90.00%) (40450/44928)
Epoch: 82 | Batch_idx: 360 |  Loss: (0.2886) |  Loss2: (0.0000) | Acc: (90.00%) (41612/46208)
Epoch: 82 | Batch_idx: 370 |  Loss: (0.2878) |  Loss2: (0.0000) | Acc: (90.00%) (42767/47488)
Epoch: 82 | Batch_idx: 380 |  Loss: (0.2881) |  Loss2: (0.0000) | Acc: (90.00%) (43907/48768)
Epoch: 82 | Batch_idx: 390 |  Loss: (0.2882) |  Loss2: (0.0000) | Acc: (90.00%) (45016/50000)
# TEST : Loss: (0.4142) | Acc: (86.00%) (8653/10000)
percent tensor([0.5483, 0.5574, 0.5507, 0.5459, 0.5523, 0.5504, 0.5585, 0.5479, 0.5483,
        0.5544, 0.5525, 0.5558, 0.5515, 0.5494, 0.5565, 0.5501],
       device='cuda:0') torch.Size([16])
percent tensor([0.5057, 0.5065, 0.5022, 0.5045, 0.5024, 0.5095, 0.5043, 0.5024, 0.5026,
        0.5056, 0.5068, 0.5035, 0.5051, 0.5054, 0.5074, 0.5064],
       device='cuda:0') torch.Size([16])
percent tensor([0.5424, 0.4217, 0.6579, 0.6425, 0.6585, 0.6137, 0.5220, 0.6423, 0.5717,
        0.5005, 0.4315, 0.5920, 0.4535, 0.4629, 0.5096, 0.5751],
       device='cuda:0') torch.Size([16])
percent tensor([0.6792, 0.7045, 0.6018, 0.6116, 0.6079, 0.5554, 0.6749, 0.6192, 0.6782,
        0.7030, 0.7290, 0.6652, 0.7020, 0.7007, 0.6715, 0.6406],
       device='cuda:0') torch.Size([16])
percent tensor([0.6728, 0.5902, 0.7028, 0.7228, 0.7138, 0.7388, 0.6699, 0.7208, 0.6451,
        0.5699, 0.5509, 0.6263, 0.5644, 0.6504, 0.6698, 0.7041],
       device='cuda:0') torch.Size([16])
percent tensor([0.5230, 0.6044, 0.6295, 0.6954, 0.6781, 0.6956, 0.5781, 0.5169, 0.6352,
        0.5731, 0.6046, 0.6231, 0.5786, 0.6596, 0.5098, 0.5634],
       device='cuda:0') torch.Size([16])
percent tensor([0.5022, 0.6196, 0.6063, 0.6714, 0.6108, 0.6033, 0.5568, 0.5135, 0.6682,
        0.6187, 0.6863, 0.6528, 0.6211, 0.7014, 0.5195, 0.4791],
       device='cuda:0') torch.Size([16])
percent tensor([0.9997, 0.9994, 0.9995, 0.9997, 0.9999, 0.9981, 0.9996, 0.9997, 0.9992,
        0.9998, 0.9993, 0.9998, 0.9990, 0.9994, 0.9996, 0.9996],
       device='cuda:0') torch.Size([16])
Epoch: 83 | Batch_idx: 0 |  Loss: (0.3230) |  Loss2: (0.0000) | Acc: (88.00%) (113/128)
Epoch: 83 | Batch_idx: 10 |  Loss: (0.2818) |  Loss2: (0.0000) | Acc: (89.00%) (1266/1408)
Epoch: 83 | Batch_idx: 20 |  Loss: (0.2833) |  Loss2: (0.0000) | Acc: (90.00%) (2420/2688)
Epoch: 83 | Batch_idx: 30 |  Loss: (0.2825) |  Loss2: (0.0000) | Acc: (90.00%) (3578/3968)
Epoch: 83 | Batch_idx: 40 |  Loss: (0.2814) |  Loss2: (0.0000) | Acc: (90.00%) (4738/5248)
Epoch: 83 | Batch_idx: 50 |  Loss: (0.2788) |  Loss2: (0.0000) | Acc: (90.00%) (5899/6528)
Epoch: 83 | Batch_idx: 60 |  Loss: (0.2739) |  Loss2: (0.0000) | Acc: (90.00%) (7074/7808)
Epoch: 83 | Batch_idx: 70 |  Loss: (0.2766) |  Loss2: (0.0000) | Acc: (90.00%) (8221/9088)
Epoch: 83 | Batch_idx: 80 |  Loss: (0.2746) |  Loss2: (0.0000) | Acc: (90.00%) (9383/10368)
Epoch: 83 | Batch_idx: 90 |  Loss: (0.2733) |  Loss2: (0.0000) | Acc: (90.00%) (10550/11648)
Epoch: 83 | Batch_idx: 100 |  Loss: (0.2771) |  Loss2: (0.0000) | Acc: (90.00%) (11695/12928)
Epoch: 83 | Batch_idx: 110 |  Loss: (0.2786) |  Loss2: (0.0000) | Acc: (90.00%) (12840/14208)
Epoch: 83 | Batch_idx: 120 |  Loss: (0.2769) |  Loss2: (0.0000) | Acc: (90.00%) (14014/15488)
Epoch: 83 | Batch_idx: 130 |  Loss: (0.2770) |  Loss2: (0.0000) | Acc: (90.00%) (15176/16768)
Epoch: 83 | Batch_idx: 140 |  Loss: (0.2788) |  Loss2: (0.0000) | Acc: (90.00%) (16326/18048)
Epoch: 83 | Batch_idx: 150 |  Loss: (0.2814) |  Loss2: (0.0000) | Acc: (90.00%) (17466/19328)
Epoch: 83 | Batch_idx: 160 |  Loss: (0.2802) |  Loss2: (0.0000) | Acc: (90.00%) (18629/20608)
Epoch: 83 | Batch_idx: 170 |  Loss: (0.2787) |  Loss2: (0.0000) | Acc: (90.00%) (19789/21888)
Epoch: 83 | Batch_idx: 180 |  Loss: (0.2773) |  Loss2: (0.0000) | Acc: (90.00%) (20965/23168)
Epoch: 83 | Batch_idx: 190 |  Loss: (0.2767) |  Loss2: (0.0000) | Acc: (90.00%) (22133/24448)
Epoch: 83 | Batch_idx: 200 |  Loss: (0.2754) |  Loss2: (0.0000) | Acc: (90.00%) (23307/25728)
Epoch: 83 | Batch_idx: 210 |  Loss: (0.2741) |  Loss2: (0.0000) | Acc: (90.00%) (24476/27008)
Epoch: 83 | Batch_idx: 220 |  Loss: (0.2749) |  Loss2: (0.0000) | Acc: (90.00%) (25629/28288)
Epoch: 83 | Batch_idx: 230 |  Loss: (0.2747) |  Loss2: (0.0000) | Acc: (90.00%) (26779/29568)
Epoch: 83 | Batch_idx: 240 |  Loss: (0.2769) |  Loss2: (0.0000) | Acc: (90.00%) (27918/30848)
Epoch: 83 | Batch_idx: 250 |  Loss: (0.2764) |  Loss2: (0.0000) | Acc: (90.00%) (29082/32128)
Epoch: 83 | Batch_idx: 260 |  Loss: (0.2765) |  Loss2: (0.0000) | Acc: (90.00%) (30234/33408)
Epoch: 83 | Batch_idx: 270 |  Loss: (0.2759) |  Loss2: (0.0000) | Acc: (90.00%) (31404/34688)
Epoch: 83 | Batch_idx: 280 |  Loss: (0.2773) |  Loss2: (0.0000) | Acc: (90.00%) (32550/35968)
Epoch: 83 | Batch_idx: 290 |  Loss: (0.2779) |  Loss2: (0.0000) | Acc: (90.00%) (33695/37248)
Epoch: 83 | Batch_idx: 300 |  Loss: (0.2779) |  Loss2: (0.0000) | Acc: (90.00%) (34851/38528)
Epoch: 83 | Batch_idx: 310 |  Loss: (0.2772) |  Loss2: (0.0000) | Acc: (90.00%) (36023/39808)
Epoch: 83 | Batch_idx: 320 |  Loss: (0.2765) |  Loss2: (0.0000) | Acc: (90.00%) (37186/41088)
Epoch: 83 | Batch_idx: 330 |  Loss: (0.2758) |  Loss2: (0.0000) | Acc: (90.00%) (38356/42368)
Epoch: 83 | Batch_idx: 340 |  Loss: (0.2763) |  Loss2: (0.0000) | Acc: (90.00%) (39508/43648)
Epoch: 83 | Batch_idx: 350 |  Loss: (0.2756) |  Loss2: (0.0000) | Acc: (90.00%) (40676/44928)
Epoch: 83 | Batch_idx: 360 |  Loss: (0.2753) |  Loss2: (0.0000) | Acc: (90.00%) (41832/46208)
Epoch: 83 | Batch_idx: 370 |  Loss: (0.2750) |  Loss2: (0.0000) | Acc: (90.00%) (42991/47488)
Epoch: 83 | Batch_idx: 380 |  Loss: (0.2745) |  Loss2: (0.0000) | Acc: (90.00%) (44170/48768)
Epoch: 83 | Batch_idx: 390 |  Loss: (0.2752) |  Loss2: (0.0000) | Acc: (90.00%) (45279/50000)
# TEST : Loss: (0.4063) | Acc: (86.00%) (8692/10000)
percent tensor([0.5505, 0.5602, 0.5525, 0.5476, 0.5545, 0.5525, 0.5612, 0.5499, 0.5508,
        0.5568, 0.5551, 0.5580, 0.5540, 0.5523, 0.5590, 0.5524],
       device='cuda:0') torch.Size([16])
percent tensor([0.5059, 0.5067, 0.5025, 0.5046, 0.5027, 0.5098, 0.5046, 0.5027, 0.5029,
        0.5057, 0.5069, 0.5036, 0.5052, 0.5055, 0.5077, 0.5065],
       device='cuda:0') torch.Size([16])
percent tensor([0.5397, 0.4227, 0.6541, 0.6373, 0.6548, 0.6120, 0.5196, 0.6385, 0.5681,
        0.5008, 0.4304, 0.5889, 0.4531, 0.4608, 0.5078, 0.5738],
       device='cuda:0') torch.Size([16])
percent tensor([0.6849, 0.7125, 0.6068, 0.6183, 0.6124, 0.5585, 0.6826, 0.6245, 0.6852,
        0.7108, 0.7373, 0.6731, 0.7092, 0.7094, 0.6791, 0.6471],
       device='cuda:0') torch.Size([16])
percent tensor([0.6795, 0.5915, 0.7148, 0.7303, 0.7254, 0.7467, 0.6775, 0.7344, 0.6505,
        0.5696, 0.5467, 0.6350, 0.5671, 0.6498, 0.6783, 0.7104],
       device='cuda:0') torch.Size([16])
percent tensor([0.5443, 0.6180, 0.6462, 0.7086, 0.6927, 0.7057, 0.5952, 0.5361, 0.6519,
        0.5928, 0.6232, 0.6411, 0.5938, 0.6771, 0.5284, 0.5791],
       device='cuda:0') torch.Size([16])
percent tensor([0.4963, 0.6312, 0.6133, 0.6813, 0.6189, 0.6099, 0.5573, 0.5153, 0.6766,
        0.6247, 0.7005, 0.6617, 0.6319, 0.7141, 0.5228, 0.4717],
       device='cuda:0') torch.Size([16])
percent tensor([0.9997, 0.9994, 0.9996, 0.9997, 0.9999, 0.9981, 0.9996, 0.9997, 0.9993,
        0.9998, 0.9994, 0.9998, 0.9991, 0.9994, 0.9996, 0.9995],
       device='cuda:0') torch.Size([16])
True Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=128, out_features=16, bias=False)
False Linear(in_features=16, out_features=2, bias=False)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=128, out_features=16, bias=False)
False Linear(in_features=16, out_features=2, bias=False)
True Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=256, out_features=32, bias=False)
False Linear(in_features=32, out_features=2, bias=False)
True Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=256, out_features=32, bias=False)
False Linear(in_features=32, out_features=2, bias=False)
True Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=512, out_features=64, bias=False)
False Linear(in_features=64, out_features=2, bias=False)
True Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=512, out_features=64, bias=False)
False Linear(in_features=64, out_features=2, bias=False)
True Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1024, out_features=128, bias=False)
False Linear(in_features=128, out_features=2, bias=False)
True Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1024, out_features=128, bias=False)
False Linear(in_features=128, out_features=2, bias=False)
True Linear(in_features=512, out_features=10, bias=True)
Epoch: 84 | Batch_idx: 0 |  Loss: (0.2493) |  Loss2: (0.0000) | Acc: (91.00%) (117/128)
Epoch: 84 | Batch_idx: 10 |  Loss: (0.2385) |  Loss2: (0.0000) | Acc: (91.00%) (1285/1408)
Epoch: 84 | Batch_idx: 20 |  Loss: (0.2584) |  Loss2: (0.0000) | Acc: (90.00%) (2438/2688)
Epoch: 84 | Batch_idx: 30 |  Loss: (0.2476) |  Loss2: (0.0000) | Acc: (91.00%) (3616/3968)
Epoch: 84 | Batch_idx: 40 |  Loss: (0.2498) |  Loss2: (0.0000) | Acc: (91.00%) (4778/5248)
Epoch: 84 | Batch_idx: 50 |  Loss: (0.2533) |  Loss2: (0.0000) | Acc: (90.00%) (5935/6528)
Epoch: 84 | Batch_idx: 60 |  Loss: (0.2556) |  Loss2: (0.0000) | Acc: (90.00%) (7098/7808)
Epoch: 84 | Batch_idx: 70 |  Loss: (0.2585) |  Loss2: (0.0000) | Acc: (90.00%) (8266/9088)
Epoch: 84 | Batch_idx: 80 |  Loss: (0.2596) |  Loss2: (0.0000) | Acc: (90.00%) (9429/10368)
Epoch: 84 | Batch_idx: 90 |  Loss: (0.2588) |  Loss2: (0.0000) | Acc: (90.00%) (10598/11648)
Epoch: 84 | Batch_idx: 100 |  Loss: (0.2578) |  Loss2: (0.0000) | Acc: (91.00%) (11772/12928)
Epoch: 84 | Batch_idx: 110 |  Loss: (0.2567) |  Loss2: (0.0000) | Acc: (91.00%) (12948/14208)
Epoch: 84 | Batch_idx: 120 |  Loss: (0.2594) |  Loss2: (0.0000) | Acc: (90.00%) (14088/15488)
Epoch: 84 | Batch_idx: 130 |  Loss: (0.2599) |  Loss2: (0.0000) | Acc: (90.00%) (15249/16768)
Epoch: 84 | Batch_idx: 140 |  Loss: (0.2600) |  Loss2: (0.0000) | Acc: (90.00%) (16418/18048)
Epoch: 84 | Batch_idx: 150 |  Loss: (0.2614) |  Loss2: (0.0000) | Acc: (90.00%) (17569/19328)
Epoch: 84 | Batch_idx: 160 |  Loss: (0.2624) |  Loss2: (0.0000) | Acc: (90.00%) (18730/20608)
Epoch: 84 | Batch_idx: 170 |  Loss: (0.2632) |  Loss2: (0.0000) | Acc: (90.00%) (19887/21888)
Epoch: 84 | Batch_idx: 180 |  Loss: (0.2628) |  Loss2: (0.0000) | Acc: (90.00%) (21053/23168)
Epoch: 84 | Batch_idx: 190 |  Loss: (0.2623) |  Loss2: (0.0000) | Acc: (90.00%) (22229/24448)
Epoch: 84 | Batch_idx: 200 |  Loss: (0.2607) |  Loss2: (0.0000) | Acc: (90.00%) (23400/25728)
Epoch: 84 | Batch_idx: 210 |  Loss: (0.2604) |  Loss2: (0.0000) | Acc: (90.00%) (24559/27008)
Epoch: 84 | Batch_idx: 220 |  Loss: (0.2610) |  Loss2: (0.0000) | Acc: (90.00%) (25711/28288)
Epoch: 84 | Batch_idx: 230 |  Loss: (0.2612) |  Loss2: (0.0000) | Acc: (90.00%) (26879/29568)
Epoch: 84 | Batch_idx: 240 |  Loss: (0.2612) |  Loss2: (0.0000) | Acc: (90.00%) (28042/30848)
Epoch: 84 | Batch_idx: 250 |  Loss: (0.2615) |  Loss2: (0.0000) | Acc: (90.00%) (29217/32128)
Epoch: 84 | Batch_idx: 260 |  Loss: (0.2609) |  Loss2: (0.0000) | Acc: (90.00%) (30390/33408)
Epoch: 84 | Batch_idx: 270 |  Loss: (0.2615) |  Loss2: (0.0000) | Acc: (90.00%) (31545/34688)
Epoch: 84 | Batch_idx: 280 |  Loss: (0.2613) |  Loss2: (0.0000) | Acc: (90.00%) (32718/35968)
Epoch: 84 | Batch_idx: 290 |  Loss: (0.2602) |  Loss2: (0.0000) | Acc: (91.00%) (33902/37248)
Epoch: 84 | Batch_idx: 300 |  Loss: (0.2599) |  Loss2: (0.0000) | Acc: (91.00%) (35064/38528)
Epoch: 84 | Batch_idx: 310 |  Loss: (0.2598) |  Loss2: (0.0000) | Acc: (91.00%) (36241/39808)
Epoch: 84 | Batch_idx: 320 |  Loss: (0.2599) |  Loss2: (0.0000) | Acc: (91.00%) (37398/41088)
Epoch: 84 | Batch_idx: 330 |  Loss: (0.2598) |  Loss2: (0.0000) | Acc: (91.00%) (38564/42368)
Epoch: 84 | Batch_idx: 340 |  Loss: (0.2594) |  Loss2: (0.0000) | Acc: (91.00%) (39737/43648)
Epoch: 84 | Batch_idx: 350 |  Loss: (0.2595) |  Loss2: (0.0000) | Acc: (91.00%) (40902/44928)
Epoch: 84 | Batch_idx: 360 |  Loss: (0.2594) |  Loss2: (0.0000) | Acc: (91.00%) (42062/46208)
Epoch: 84 | Batch_idx: 370 |  Loss: (0.2603) |  Loss2: (0.0000) | Acc: (91.00%) (43218/47488)
Epoch: 84 | Batch_idx: 380 |  Loss: (0.2605) |  Loss2: (0.0000) | Acc: (90.00%) (44378/48768)
Epoch: 84 | Batch_idx: 390 |  Loss: (0.2617) |  Loss2: (0.0000) | Acc: (90.00%) (45482/50000)
# TEST : Loss: (0.4785) | Acc: (84.00%) (8457/10000)
percent tensor([0.5502, 0.5607, 0.5497, 0.5487, 0.5528, 0.5532, 0.5611, 0.5492, 0.5504,
        0.5559, 0.5557, 0.5558, 0.5544, 0.5523, 0.5597, 0.5529],
       device='cuda:0') torch.Size([16])
percent tensor([0.5062, 0.5065, 0.5022, 0.5045, 0.5032, 0.5094, 0.5044, 0.5022, 0.5031,
        0.5056, 0.5068, 0.5036, 0.5055, 0.5043, 0.5075, 0.5065],
       device='cuda:0') torch.Size([16])
percent tensor([0.5222, 0.4197, 0.6474, 0.6243, 0.6534, 0.6158, 0.5153, 0.6342, 0.5644,
        0.4748, 0.4255, 0.5625, 0.4307, 0.4858, 0.5026, 0.5577],
       device='cuda:0') torch.Size([16])
percent tensor([0.6790, 0.7153, 0.5980, 0.6228, 0.6125, 0.5483, 0.6840, 0.6271, 0.6839,
        0.7130, 0.7340, 0.6732, 0.7049, 0.7119, 0.6685, 0.6459],
       device='cuda:0') torch.Size([16])
percent tensor([0.6759, 0.5872, 0.7166, 0.7257, 0.7294, 0.7449, 0.6738, 0.7207, 0.6538,
        0.5740, 0.5492, 0.6330, 0.5733, 0.6604, 0.6798, 0.7037],
       device='cuda:0') torch.Size([16])
percent tensor([0.5181, 0.5888, 0.6525, 0.6828, 0.6819, 0.6950, 0.5887, 0.5268, 0.6309,
        0.5892, 0.6089, 0.6321, 0.5731, 0.6438, 0.5244, 0.5614],
       device='cuda:0') torch.Size([16])
percent tensor([0.4991, 0.6151, 0.6281, 0.6410, 0.6123, 0.5701, 0.5872, 0.5247, 0.6593,
        0.6221, 0.6957, 0.6483, 0.5893, 0.6786, 0.5318, 0.4700],
       device='cuda:0') torch.Size([16])
percent tensor([0.9996, 0.9995, 0.9996, 0.9997, 0.9999, 0.9985, 0.9996, 0.9995, 0.9994,
        0.9997, 0.9991, 0.9998, 0.9988, 0.9992, 0.9995, 0.9996],
       device='cuda:0') torch.Size([16])
Epoch: 85 | Batch_idx: 0 |  Loss: (0.2212) |  Loss2: (0.0000) | Acc: (93.00%) (120/128)
Epoch: 85 | Batch_idx: 10 |  Loss: (0.2359) |  Loss2: (0.0000) | Acc: (91.00%) (1293/1408)
Epoch: 85 | Batch_idx: 20 |  Loss: (0.2246) |  Loss2: (0.0000) | Acc: (92.00%) (2478/2688)
Epoch: 85 | Batch_idx: 30 |  Loss: (0.2344) |  Loss2: (0.0000) | Acc: (92.00%) (3653/3968)
Epoch: 85 | Batch_idx: 40 |  Loss: (0.2416) |  Loss2: (0.0000) | Acc: (91.00%) (4822/5248)
Epoch: 85 | Batch_idx: 50 |  Loss: (0.2496) |  Loss2: (0.0000) | Acc: (91.00%) (5971/6528)
Epoch: 85 | Batch_idx: 60 |  Loss: (0.2471) |  Loss2: (0.0000) | Acc: (91.00%) (7136/7808)
Epoch: 85 | Batch_idx: 70 |  Loss: (0.2470) |  Loss2: (0.0000) | Acc: (91.00%) (8314/9088)
Epoch: 85 | Batch_idx: 80 |  Loss: (0.2487) |  Loss2: (0.0000) | Acc: (91.00%) (9476/10368)
Epoch: 85 | Batch_idx: 90 |  Loss: (0.2461) |  Loss2: (0.0000) | Acc: (91.00%) (10651/11648)
Epoch: 85 | Batch_idx: 100 |  Loss: (0.2463) |  Loss2: (0.0000) | Acc: (91.00%) (11825/12928)
Epoch: 85 | Batch_idx: 110 |  Loss: (0.2477) |  Loss2: (0.0000) | Acc: (91.00%) (12981/14208)
Epoch: 85 | Batch_idx: 120 |  Loss: (0.2473) |  Loss2: (0.0000) | Acc: (91.00%) (14155/15488)
Epoch: 85 | Batch_idx: 130 |  Loss: (0.2494) |  Loss2: (0.0000) | Acc: (91.00%) (15312/16768)
Epoch: 85 | Batch_idx: 140 |  Loss: (0.2493) |  Loss2: (0.0000) | Acc: (91.00%) (16485/18048)
Epoch: 85 | Batch_idx: 150 |  Loss: (0.2488) |  Loss2: (0.0000) | Acc: (91.00%) (17660/19328)
Epoch: 85 | Batch_idx: 160 |  Loss: (0.2493) |  Loss2: (0.0000) | Acc: (91.00%) (18840/20608)
Epoch: 85 | Batch_idx: 170 |  Loss: (0.2492) |  Loss2: (0.0000) | Acc: (91.00%) (20021/21888)
Epoch: 85 | Batch_idx: 180 |  Loss: (0.2483) |  Loss2: (0.0000) | Acc: (91.00%) (21192/23168)
Epoch: 85 | Batch_idx: 190 |  Loss: (0.2479) |  Loss2: (0.0000) | Acc: (91.00%) (22364/24448)
Epoch: 85 | Batch_idx: 200 |  Loss: (0.2473) |  Loss2: (0.0000) | Acc: (91.00%) (23540/25728)
Epoch: 85 | Batch_idx: 210 |  Loss: (0.2475) |  Loss2: (0.0000) | Acc: (91.00%) (24713/27008)
Epoch: 85 | Batch_idx: 220 |  Loss: (0.2495) |  Loss2: (0.0000) | Acc: (91.00%) (25859/28288)
Epoch: 85 | Batch_idx: 230 |  Loss: (0.2499) |  Loss2: (0.0000) | Acc: (91.00%) (27020/29568)
Epoch: 85 | Batch_idx: 240 |  Loss: (0.2500) |  Loss2: (0.0000) | Acc: (91.00%) (28194/30848)
Epoch: 85 | Batch_idx: 250 |  Loss: (0.2515) |  Loss2: (0.0000) | Acc: (91.00%) (29350/32128)
Epoch: 85 | Batch_idx: 260 |  Loss: (0.2526) |  Loss2: (0.0000) | Acc: (91.00%) (30507/33408)
Epoch: 85 | Batch_idx: 270 |  Loss: (0.2535) |  Loss2: (0.0000) | Acc: (91.00%) (31667/34688)
Epoch: 85 | Batch_idx: 280 |  Loss: (0.2537) |  Loss2: (0.0000) | Acc: (91.00%) (32837/35968)
Epoch: 85 | Batch_idx: 290 |  Loss: (0.2533) |  Loss2: (0.0000) | Acc: (91.00%) (34012/37248)
Epoch: 85 | Batch_idx: 300 |  Loss: (0.2538) |  Loss2: (0.0000) | Acc: (91.00%) (35178/38528)
Epoch: 85 | Batch_idx: 310 |  Loss: (0.2524) |  Loss2: (0.0000) | Acc: (91.00%) (36360/39808)
Epoch: 85 | Batch_idx: 320 |  Loss: (0.2524) |  Loss2: (0.0000) | Acc: (91.00%) (37528/41088)
Epoch: 85 | Batch_idx: 330 |  Loss: (0.2533) |  Loss2: (0.0000) | Acc: (91.00%) (38688/42368)
Epoch: 85 | Batch_idx: 340 |  Loss: (0.2526) |  Loss2: (0.0000) | Acc: (91.00%) (39877/43648)
Epoch: 85 | Batch_idx: 350 |  Loss: (0.2518) |  Loss2: (0.0000) | Acc: (91.00%) (41069/44928)
Epoch: 85 | Batch_idx: 360 |  Loss: (0.2515) |  Loss2: (0.0000) | Acc: (91.00%) (42243/46208)
Epoch: 85 | Batch_idx: 370 |  Loss: (0.2517) |  Loss2: (0.0000) | Acc: (91.00%) (43403/47488)
Epoch: 85 | Batch_idx: 380 |  Loss: (0.2519) |  Loss2: (0.0000) | Acc: (91.00%) (44554/48768)
Epoch: 85 | Batch_idx: 390 |  Loss: (0.2526) |  Loss2: (0.0000) | Acc: (91.00%) (45679/50000)
=> saving checkpoint 'drive/app/torch/save_Schedule/checkpoint_085.pth.tar'
# TEST : Loss: (0.4883) | Acc: (84.00%) (8420/10000)
percent tensor([0.5501, 0.5600, 0.5497, 0.5475, 0.5527, 0.5534, 0.5605, 0.5483, 0.5494,
        0.5553, 0.5556, 0.5555, 0.5537, 0.5514, 0.5594, 0.5524],
       device='cuda:0') torch.Size([16])
percent tensor([0.5059, 0.5072, 0.5012, 0.5044, 0.5024, 0.5091, 0.5048, 0.5021, 0.5032,
        0.5059, 0.5071, 0.5032, 0.5056, 0.5055, 0.5078, 0.5064],
       device='cuda:0') torch.Size([16])
percent tensor([0.5259, 0.3997, 0.6646, 0.6276, 0.6606, 0.5911, 0.5133, 0.6359, 0.5675,
        0.4812, 0.4146, 0.5857, 0.4269, 0.4584, 0.4771, 0.5478],
       device='cuda:0') torch.Size([16])
percent tensor([0.6813, 0.7185, 0.5973, 0.6192, 0.6117, 0.5531, 0.6823, 0.6278, 0.6831,
        0.7145, 0.7376, 0.6730, 0.7082, 0.7157, 0.6751, 0.6522],
       device='cuda:0') torch.Size([16])
percent tensor([0.6800, 0.5665, 0.7216, 0.7279, 0.7302, 0.7492, 0.6618, 0.7177, 0.6479,
        0.5751, 0.5432, 0.6348, 0.5660, 0.6329, 0.6756, 0.7088],
       device='cuda:0') torch.Size([16])
percent tensor([0.5357, 0.5995, 0.6450, 0.6916, 0.6831, 0.7006, 0.5987, 0.5407, 0.6195,
        0.5835, 0.6248, 0.6086, 0.5842, 0.6402, 0.5251, 0.5725],
       device='cuda:0') torch.Size([16])
percent tensor([0.5045, 0.6423, 0.6287, 0.6471, 0.5979, 0.5975, 0.5919, 0.5252, 0.6390,
        0.6416, 0.7130, 0.6403, 0.6181, 0.7042, 0.5375, 0.4740],
       device='cuda:0') torch.Size([16])
percent tensor([0.9997, 0.9992, 0.9995, 0.9998, 0.9999, 0.9982, 0.9997, 0.9996, 0.9995,
        0.9997, 0.9985, 0.9998, 0.9990, 0.9995, 0.9996, 0.9996],
       device='cuda:0') torch.Size([16])
Epoch: 86 | Batch_idx: 0 |  Loss: (0.2141) |  Loss2: (0.0000) | Acc: (92.00%) (118/128)
Epoch: 86 | Batch_idx: 10 |  Loss: (0.2454) |  Loss2: (0.0000) | Acc: (91.00%) (1284/1408)
Epoch: 86 | Batch_idx: 20 |  Loss: (0.2433) |  Loss2: (0.0000) | Acc: (91.00%) (2459/2688)
Epoch: 86 | Batch_idx: 30 |  Loss: (0.2392) |  Loss2: (0.0000) | Acc: (91.00%) (3633/3968)
Epoch: 86 | Batch_idx: 40 |  Loss: (0.2406) |  Loss2: (0.0000) | Acc: (91.00%) (4802/5248)
Epoch: 86 | Batch_idx: 50 |  Loss: (0.2384) |  Loss2: (0.0000) | Acc: (91.00%) (5989/6528)
Epoch: 86 | Batch_idx: 60 |  Loss: (0.2408) |  Loss2: (0.0000) | Acc: (91.00%) (7156/7808)
Epoch: 86 | Batch_idx: 70 |  Loss: (0.2418) |  Loss2: (0.0000) | Acc: (91.00%) (8325/9088)
Epoch: 86 | Batch_idx: 80 |  Loss: (0.2409) |  Loss2: (0.0000) | Acc: (91.00%) (9504/10368)
Epoch: 86 | Batch_idx: 90 |  Loss: (0.2403) |  Loss2: (0.0000) | Acc: (91.00%) (10675/11648)
Epoch: 86 | Batch_idx: 100 |  Loss: (0.2411) |  Loss2: (0.0000) | Acc: (91.00%) (11840/12928)
Epoch: 86 | Batch_idx: 110 |  Loss: (0.2417) |  Loss2: (0.0000) | Acc: (91.00%) (13012/14208)
Epoch: 86 | Batch_idx: 120 |  Loss: (0.2393) |  Loss2: (0.0000) | Acc: (91.00%) (14194/15488)
Epoch: 86 | Batch_idx: 130 |  Loss: (0.2397) |  Loss2: (0.0000) | Acc: (91.00%) (15366/16768)
Epoch: 86 | Batch_idx: 140 |  Loss: (0.2407) |  Loss2: (0.0000) | Acc: (91.00%) (16535/18048)
Epoch: 86 | Batch_idx: 150 |  Loss: (0.2412) |  Loss2: (0.0000) | Acc: (91.00%) (17709/19328)
Epoch: 86 | Batch_idx: 160 |  Loss: (0.2429) |  Loss2: (0.0000) | Acc: (91.00%) (18878/20608)
Epoch: 86 | Batch_idx: 170 |  Loss: (0.2428) |  Loss2: (0.0000) | Acc: (91.00%) (20039/21888)
Epoch: 86 | Batch_idx: 180 |  Loss: (0.2425) |  Loss2: (0.0000) | Acc: (91.00%) (21208/23168)
Epoch: 86 | Batch_idx: 190 |  Loss: (0.2426) |  Loss2: (0.0000) | Acc: (91.00%) (22372/24448)
Epoch: 86 | Batch_idx: 200 |  Loss: (0.2437) |  Loss2: (0.0000) | Acc: (91.00%) (23537/25728)
Epoch: 86 | Batch_idx: 210 |  Loss: (0.2453) |  Loss2: (0.0000) | Acc: (91.00%) (24682/27008)
Epoch: 86 | Batch_idx: 220 |  Loss: (0.2442) |  Loss2: (0.0000) | Acc: (91.00%) (25873/28288)
Epoch: 86 | Batch_idx: 230 |  Loss: (0.2452) |  Loss2: (0.0000) | Acc: (91.00%) (27037/29568)
Epoch: 86 | Batch_idx: 240 |  Loss: (0.2462) |  Loss2: (0.0000) | Acc: (91.00%) (28199/30848)
Epoch: 86 | Batch_idx: 250 |  Loss: (0.2464) |  Loss2: (0.0000) | Acc: (91.00%) (29353/32128)
Epoch: 86 | Batch_idx: 260 |  Loss: (0.2464) |  Loss2: (0.0000) | Acc: (91.00%) (30532/33408)
Epoch: 86 | Batch_idx: 270 |  Loss: (0.2459) |  Loss2: (0.0000) | Acc: (91.00%) (31708/34688)
Epoch: 86 | Batch_idx: 280 |  Loss: (0.2461) |  Loss2: (0.0000) | Acc: (91.00%) (32875/35968)
Epoch: 86 | Batch_idx: 290 |  Loss: (0.2467) |  Loss2: (0.0000) | Acc: (91.00%) (34045/37248)
Epoch: 86 | Batch_idx: 300 |  Loss: (0.2452) |  Loss2: (0.0000) | Acc: (91.00%) (35243/38528)
Epoch: 86 | Batch_idx: 310 |  Loss: (0.2451) |  Loss2: (0.0000) | Acc: (91.00%) (36413/39808)
Epoch: 86 | Batch_idx: 320 |  Loss: (0.2453) |  Loss2: (0.0000) | Acc: (91.00%) (37587/41088)
Epoch: 86 | Batch_idx: 330 |  Loss: (0.2451) |  Loss2: (0.0000) | Acc: (91.00%) (38765/42368)
Epoch: 86 | Batch_idx: 340 |  Loss: (0.2449) |  Loss2: (0.0000) | Acc: (91.00%) (39942/43648)
Epoch: 86 | Batch_idx: 350 |  Loss: (0.2444) |  Loss2: (0.0000) | Acc: (91.00%) (41118/44928)
Epoch: 86 | Batch_idx: 360 |  Loss: (0.2439) |  Loss2: (0.0000) | Acc: (91.00%) (42304/46208)
Epoch: 86 | Batch_idx: 370 |  Loss: (0.2437) |  Loss2: (0.0000) | Acc: (91.00%) (43473/47488)
Epoch: 86 | Batch_idx: 380 |  Loss: (0.2441) |  Loss2: (0.0000) | Acc: (91.00%) (44630/48768)
Epoch: 86 | Batch_idx: 390 |  Loss: (0.2443) |  Loss2: (0.0000) | Acc: (91.00%) (45757/50000)
# TEST : Loss: (0.3996) | Acc: (86.00%) (8699/10000)
percent tensor([0.5497, 0.5588, 0.5503, 0.5480, 0.5532, 0.5528, 0.5596, 0.5489, 0.5491,
        0.5548, 0.5544, 0.5558, 0.5532, 0.5498, 0.5586, 0.5520],
       device='cuda:0') torch.Size([16])
percent tensor([0.5058, 0.5069, 0.5015, 0.5043, 0.5022, 0.5093, 0.5046, 0.5017, 0.5030,
        0.5058, 0.5069, 0.5034, 0.5053, 0.5056, 0.5077, 0.5064],
       device='cuda:0') torch.Size([16])
percent tensor([0.5341, 0.4204, 0.6571, 0.6272, 0.6591, 0.6064, 0.5272, 0.6320, 0.5752,
        0.4874, 0.4323, 0.5837, 0.4414, 0.4818, 0.5008, 0.5615],
       device='cuda:0') torch.Size([16])
percent tensor([0.6853, 0.7188, 0.6110, 0.6383, 0.6256, 0.5506, 0.6835, 0.6342, 0.6855,
        0.7185, 0.7342, 0.6793, 0.7061, 0.7149, 0.6764, 0.6530],
       device='cuda:0') torch.Size([16])
percent tensor([0.6793, 0.5893, 0.7251, 0.7264, 0.7319, 0.7456, 0.6696, 0.7271, 0.6619,
        0.5783, 0.5579, 0.6391, 0.5767, 0.6480, 0.6764, 0.7071],
       device='cuda:0') torch.Size([16])
percent tensor([0.5441, 0.6024, 0.6565, 0.6887, 0.6853, 0.7102, 0.6105, 0.5524, 0.6426,
        0.5903, 0.6276, 0.6131, 0.5925, 0.6696, 0.5211, 0.5886],
       device='cuda:0') torch.Size([16])
percent tensor([0.5092, 0.6265, 0.6089, 0.6318, 0.6062, 0.6097, 0.6054, 0.5174, 0.6471,
        0.6419, 0.7019, 0.6400, 0.6105, 0.6921, 0.5291, 0.4798],
       device='cuda:0') torch.Size([16])
percent tensor([0.9997, 0.9992, 0.9997, 0.9999, 0.9999, 0.9962, 0.9996, 0.9997, 0.9993,
        0.9998, 0.9987, 0.9998, 0.9987, 0.9994, 0.9997, 0.9996],
       device='cuda:0') torch.Size([16])
False Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=128, out_features=16, bias=False)
True Linear(in_features=16, out_features=2, bias=False)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=128, out_features=16, bias=False)
True Linear(in_features=16, out_features=2, bias=False)
False Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=256, out_features=32, bias=False)
True Linear(in_features=32, out_features=2, bias=False)
False Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=256, out_features=32, bias=False)
True Linear(in_features=32, out_features=2, bias=False)
False Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=512, out_features=64, bias=False)
True Linear(in_features=64, out_features=2, bias=False)
False Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=512, out_features=64, bias=False)
True Linear(in_features=64, out_features=2, bias=False)
False Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1024, out_features=128, bias=False)
True Linear(in_features=128, out_features=2, bias=False)
False Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1024, out_features=128, bias=False)
True Linear(in_features=128, out_features=2, bias=False)
False Linear(in_features=512, out_features=10, bias=True)
Epoch: 87 | Batch_idx: 0 |  Loss: (0.2065) |  Loss2: (0.0000) | Acc: (92.00%) (118/128)
Epoch: 87 | Batch_idx: 10 |  Loss: (0.2539) |  Loss2: (0.0000) | Acc: (90.00%) (1279/1408)
Epoch: 87 | Batch_idx: 20 |  Loss: (0.2599) |  Loss2: (0.0000) | Acc: (90.00%) (2436/2688)
Epoch: 87 | Batch_idx: 30 |  Loss: (0.2704) |  Loss2: (0.0000) | Acc: (90.00%) (3578/3968)
Epoch: 87 | Batch_idx: 40 |  Loss: (0.2821) |  Loss2: (0.0000) | Acc: (89.00%) (4712/5248)
Epoch: 87 | Batch_idx: 50 |  Loss: (0.2895) |  Loss2: (0.0000) | Acc: (89.00%) (5850/6528)
Epoch: 87 | Batch_idx: 60 |  Loss: (0.2947) |  Loss2: (0.0000) | Acc: (89.00%) (6977/7808)
Epoch: 87 | Batch_idx: 70 |  Loss: (0.2940) |  Loss2: (0.0000) | Acc: (89.00%) (8125/9088)
Epoch: 87 | Batch_idx: 80 |  Loss: (0.2981) |  Loss2: (0.0000) | Acc: (89.00%) (9247/10368)
Epoch: 87 | Batch_idx: 90 |  Loss: (0.3007) |  Loss2: (0.0000) | Acc: (89.00%) (10397/11648)
Epoch: 87 | Batch_idx: 100 |  Loss: (0.3041) |  Loss2: (0.0000) | Acc: (89.00%) (11528/12928)
Epoch: 87 | Batch_idx: 110 |  Loss: (0.3021) |  Loss2: (0.0000) | Acc: (89.00%) (12692/14208)
Epoch: 87 | Batch_idx: 120 |  Loss: (0.2984) |  Loss2: (0.0000) | Acc: (89.00%) (13842/15488)
Epoch: 87 | Batch_idx: 130 |  Loss: (0.2980) |  Loss2: (0.0000) | Acc: (89.00%) (14983/16768)
Epoch: 87 | Batch_idx: 140 |  Loss: (0.2958) |  Loss2: (0.0000) | Acc: (89.00%) (16147/18048)
Epoch: 87 | Batch_idx: 150 |  Loss: (0.2956) |  Loss2: (0.0000) | Acc: (89.00%) (17287/19328)
Epoch: 87 | Batch_idx: 160 |  Loss: (0.2940) |  Loss2: (0.0000) | Acc: (89.00%) (18439/20608)
Epoch: 87 | Batch_idx: 170 |  Loss: (0.2925) |  Loss2: (0.0000) | Acc: (89.00%) (19603/21888)
Epoch: 87 | Batch_idx: 180 |  Loss: (0.2920) |  Loss2: (0.0000) | Acc: (89.00%) (20763/23168)
Epoch: 87 | Batch_idx: 190 |  Loss: (0.2912) |  Loss2: (0.0000) | Acc: (89.00%) (21912/24448)
Epoch: 87 | Batch_idx: 200 |  Loss: (0.2901) |  Loss2: (0.0000) | Acc: (89.00%) (23071/25728)
Epoch: 87 | Batch_idx: 210 |  Loss: (0.2913) |  Loss2: (0.0000) | Acc: (89.00%) (24201/27008)
Epoch: 87 | Batch_idx: 220 |  Loss: (0.2894) |  Loss2: (0.0000) | Acc: (89.00%) (25369/28288)
Epoch: 87 | Batch_idx: 230 |  Loss: (0.2884) |  Loss2: (0.0000) | Acc: (89.00%) (26537/29568)
Epoch: 87 | Batch_idx: 240 |  Loss: (0.2882) |  Loss2: (0.0000) | Acc: (89.00%) (27700/30848)
Epoch: 87 | Batch_idx: 250 |  Loss: (0.2871) |  Loss2: (0.0000) | Acc: (89.00%) (28870/32128)
Epoch: 87 | Batch_idx: 260 |  Loss: (0.2854) |  Loss2: (0.0000) | Acc: (89.00%) (30040/33408)
Epoch: 87 | Batch_idx: 270 |  Loss: (0.2832) |  Loss2: (0.0000) | Acc: (90.00%) (31227/34688)
Epoch: 87 | Batch_idx: 280 |  Loss: (0.2826) |  Loss2: (0.0000) | Acc: (90.00%) (32395/35968)
Epoch: 87 | Batch_idx: 290 |  Loss: (0.2820) |  Loss2: (0.0000) | Acc: (90.00%) (33556/37248)
Epoch: 87 | Batch_idx: 300 |  Loss: (0.2812) |  Loss2: (0.0000) | Acc: (90.00%) (34731/38528)
Epoch: 87 | Batch_idx: 310 |  Loss: (0.2806) |  Loss2: (0.0000) | Acc: (90.00%) (35899/39808)
Epoch: 87 | Batch_idx: 320 |  Loss: (0.2797) |  Loss2: (0.0000) | Acc: (90.00%) (37064/41088)
Epoch: 87 | Batch_idx: 330 |  Loss: (0.2797) |  Loss2: (0.0000) | Acc: (90.00%) (38209/42368)
Epoch: 87 | Batch_idx: 340 |  Loss: (0.2798) |  Loss2: (0.0000) | Acc: (90.00%) (39362/43648)
Epoch: 87 | Batch_idx: 350 |  Loss: (0.2803) |  Loss2: (0.0000) | Acc: (90.00%) (40502/44928)
Epoch: 87 | Batch_idx: 360 |  Loss: (0.2792) |  Loss2: (0.0000) | Acc: (90.00%) (41678/46208)
Epoch: 87 | Batch_idx: 370 |  Loss: (0.2785) |  Loss2: (0.0000) | Acc: (90.00%) (42858/47488)
Epoch: 87 | Batch_idx: 380 |  Loss: (0.2784) |  Loss2: (0.0000) | Acc: (90.00%) (44006/48768)
Epoch: 87 | Batch_idx: 390 |  Loss: (0.2792) |  Loss2: (0.0000) | Acc: (90.00%) (45108/50000)
# TEST : Loss: (0.4065) | Acc: (86.00%) (8657/10000)
percent tensor([0.5588, 0.5690, 0.5600, 0.5573, 0.5633, 0.5618, 0.5697, 0.5584, 0.5587,
        0.5645, 0.5638, 0.5657, 0.5627, 0.5595, 0.5685, 0.5612],
       device='cuda:0') torch.Size([16])
percent tensor([0.5073, 0.5078, 0.5028, 0.5055, 0.5035, 0.5108, 0.5057, 0.5034, 0.5043,
        0.5066, 0.5081, 0.5043, 0.5062, 0.5071, 0.5091, 0.5077],
       device='cuda:0') torch.Size([16])
percent tensor([0.5499, 0.4204, 0.6874, 0.6589, 0.6871, 0.6339, 0.5340, 0.6607, 0.5956,
        0.5020, 0.4436, 0.6015, 0.4499, 0.4836, 0.5176, 0.5824],
       device='cuda:0') torch.Size([16])
percent tensor([0.6727, 0.7096, 0.6107, 0.6396, 0.6294, 0.5350, 0.6783, 0.6356, 0.6794,
        0.7083, 0.7266, 0.6781, 0.6933, 0.7108, 0.6692, 0.6419],
       device='cuda:0') torch.Size([16])
percent tensor([0.6824, 0.5861, 0.7283, 0.7297, 0.7400, 0.7496, 0.6739, 0.7336, 0.6655,
        0.5757, 0.5578, 0.6334, 0.5649, 0.6545, 0.6788, 0.7066],
       device='cuda:0') torch.Size([16])
percent tensor([0.5621, 0.6164, 0.6745, 0.7030, 0.6931, 0.7226, 0.6233, 0.5521, 0.6556,
        0.6076, 0.6436, 0.6334, 0.6131, 0.6748, 0.5290, 0.5924],
       device='cuda:0') torch.Size([16])
percent tensor([0.4873, 0.5893, 0.5788, 0.5930, 0.5659, 0.5639, 0.5715, 0.4935, 0.5940,
        0.5992, 0.6506, 0.6017, 0.5717, 0.6365, 0.5042, 0.4632],
       device='cuda:0') torch.Size([16])
percent tensor([0.9997, 0.9992, 0.9997, 0.9998, 0.9999, 0.9965, 0.9994, 0.9997, 0.9991,
        0.9997, 0.9992, 0.9997, 0.9988, 0.9993, 0.9997, 0.9995],
       device='cuda:0') torch.Size([16])
Epoch: 88 | Batch_idx: 0 |  Loss: (0.2814) |  Loss2: (0.0000) | Acc: (90.00%) (116/128)
Epoch: 88 | Batch_idx: 10 |  Loss: (0.2681) |  Loss2: (0.0000) | Acc: (90.00%) (1280/1408)
Epoch: 88 | Batch_idx: 20 |  Loss: (0.2683) |  Loss2: (0.0000) | Acc: (90.00%) (2423/2688)
Epoch: 88 | Batch_idx: 30 |  Loss: (0.2572) |  Loss2: (0.0000) | Acc: (90.00%) (3589/3968)
Epoch: 88 | Batch_idx: 40 |  Loss: (0.2575) |  Loss2: (0.0000) | Acc: (90.00%) (4755/5248)
Epoch: 88 | Batch_idx: 50 |  Loss: (0.2589) |  Loss2: (0.0000) | Acc: (90.00%) (5917/6528)
Epoch: 88 | Batch_idx: 60 |  Loss: (0.2526) |  Loss2: (0.0000) | Acc: (90.00%) (7098/7808)
Epoch: 88 | Batch_idx: 70 |  Loss: (0.2491) |  Loss2: (0.0000) | Acc: (91.00%) (8276/9088)
Epoch: 88 | Batch_idx: 80 |  Loss: (0.2487) |  Loss2: (0.0000) | Acc: (91.00%) (9439/10368)
Epoch: 88 | Batch_idx: 90 |  Loss: (0.2514) |  Loss2: (0.0000) | Acc: (91.00%) (10610/11648)
Epoch: 88 | Batch_idx: 100 |  Loss: (0.2511) |  Loss2: (0.0000) | Acc: (91.00%) (11779/12928)
Epoch: 88 | Batch_idx: 110 |  Loss: (0.2515) |  Loss2: (0.0000) | Acc: (91.00%) (12951/14208)
Epoch: 88 | Batch_idx: 120 |  Loss: (0.2508) |  Loss2: (0.0000) | Acc: (91.00%) (14128/15488)
Epoch: 88 | Batch_idx: 130 |  Loss: (0.2515) |  Loss2: (0.0000) | Acc: (91.00%) (15294/16768)
Epoch: 88 | Batch_idx: 140 |  Loss: (0.2527) |  Loss2: (0.0000) | Acc: (91.00%) (16460/18048)
Epoch: 88 | Batch_idx: 150 |  Loss: (0.2504) |  Loss2: (0.0000) | Acc: (91.00%) (17649/19328)
Epoch: 88 | Batch_idx: 160 |  Loss: (0.2498) |  Loss2: (0.0000) | Acc: (91.00%) (18825/20608)
Epoch: 88 | Batch_idx: 170 |  Loss: (0.2500) |  Loss2: (0.0000) | Acc: (91.00%) (19993/21888)
Epoch: 88 | Batch_idx: 180 |  Loss: (0.2501) |  Loss2: (0.0000) | Acc: (91.00%) (21146/23168)
Epoch: 88 | Batch_idx: 190 |  Loss: (0.2499) |  Loss2: (0.0000) | Acc: (91.00%) (22312/24448)
Epoch: 88 | Batch_idx: 200 |  Loss: (0.2506) |  Loss2: (0.0000) | Acc: (91.00%) (23473/25728)
Epoch: 88 | Batch_idx: 210 |  Loss: (0.2517) |  Loss2: (0.0000) | Acc: (91.00%) (24631/27008)
Epoch: 88 | Batch_idx: 220 |  Loss: (0.2524) |  Loss2: (0.0000) | Acc: (91.00%) (25790/28288)
Epoch: 88 | Batch_idx: 230 |  Loss: (0.2519) |  Loss2: (0.0000) | Acc: (91.00%) (26960/29568)
Epoch: 88 | Batch_idx: 240 |  Loss: (0.2511) |  Loss2: (0.0000) | Acc: (91.00%) (28141/30848)
Epoch: 88 | Batch_idx: 250 |  Loss: (0.2510) |  Loss2: (0.0000) | Acc: (91.00%) (29312/32128)
Epoch: 88 | Batch_idx: 260 |  Loss: (0.2499) |  Loss2: (0.0000) | Acc: (91.00%) (30494/33408)
Epoch: 88 | Batch_idx: 270 |  Loss: (0.2498) |  Loss2: (0.0000) | Acc: (91.00%) (31661/34688)
Epoch: 88 | Batch_idx: 280 |  Loss: (0.2513) |  Loss2: (0.0000) | Acc: (91.00%) (32806/35968)
Epoch: 88 | Batch_idx: 290 |  Loss: (0.2514) |  Loss2: (0.0000) | Acc: (91.00%) (33978/37248)
Epoch: 88 | Batch_idx: 300 |  Loss: (0.2511) |  Loss2: (0.0000) | Acc: (91.00%) (35163/38528)
Epoch: 88 | Batch_idx: 310 |  Loss: (0.2504) |  Loss2: (0.0000) | Acc: (91.00%) (36339/39808)
Epoch: 88 | Batch_idx: 320 |  Loss: (0.2507) |  Loss2: (0.0000) | Acc: (91.00%) (37514/41088)
Epoch: 88 | Batch_idx: 330 |  Loss: (0.2508) |  Loss2: (0.0000) | Acc: (91.00%) (38676/42368)
Epoch: 88 | Batch_idx: 340 |  Loss: (0.2508) |  Loss2: (0.0000) | Acc: (91.00%) (39847/43648)
Epoch: 88 | Batch_idx: 350 |  Loss: (0.2514) |  Loss2: (0.0000) | Acc: (91.00%) (41005/44928)
Epoch: 88 | Batch_idx: 360 |  Loss: (0.2520) |  Loss2: (0.0000) | Acc: (91.00%) (42169/46208)
Epoch: 88 | Batch_idx: 370 |  Loss: (0.2509) |  Loss2: (0.0000) | Acc: (91.00%) (43348/47488)
Epoch: 88 | Batch_idx: 380 |  Loss: (0.2504) |  Loss2: (0.0000) | Acc: (91.00%) (44527/48768)
Epoch: 88 | Batch_idx: 390 |  Loss: (0.2505) |  Loss2: (0.0000) | Acc: (91.00%) (45653/50000)
# TEST : Loss: (0.3923) | Acc: (87.00%) (8711/10000)
percent tensor([0.5586, 0.5688, 0.5595, 0.5570, 0.5629, 0.5618, 0.5695, 0.5582, 0.5588,
        0.5642, 0.5639, 0.5653, 0.5625, 0.5600, 0.5684, 0.5609],
       device='cuda:0') torch.Size([16])
percent tensor([0.5086, 0.5090, 0.5043, 0.5069, 0.5051, 0.5125, 0.5069, 0.5050, 0.5054,
        0.5075, 0.5094, 0.5053, 0.5071, 0.5082, 0.5106, 0.5090],
       device='cuda:0') torch.Size([16])
percent tensor([0.5380, 0.4121, 0.6903, 0.6593, 0.6899, 0.6311, 0.5244, 0.6604, 0.5900,
        0.4920, 0.4330, 0.5945, 0.4397, 0.4791, 0.5068, 0.5696],
       device='cuda:0') torch.Size([16])
percent tensor([0.6830, 0.7187, 0.6239, 0.6545, 0.6441, 0.5403, 0.6912, 0.6515, 0.6923,
        0.7168, 0.7376, 0.6890, 0.7018, 0.7239, 0.6800, 0.6500],
       device='cuda:0') torch.Size([16])
percent tensor([0.6844, 0.5848, 0.7289, 0.7295, 0.7477, 0.7530, 0.6780, 0.7396, 0.6644,
        0.5703, 0.5498, 0.6232, 0.5524, 0.6567, 0.6792, 0.7074],
       device='cuda:0') torch.Size([16])
percent tensor([0.5550, 0.6160, 0.6715, 0.7019, 0.6902, 0.7291, 0.6198, 0.5357, 0.6579,
        0.6040, 0.6411, 0.6311, 0.6133, 0.6766, 0.5206, 0.5883],
       device='cuda:0') torch.Size([16])
percent tensor([0.4968, 0.6027, 0.5874, 0.6011, 0.5698, 0.5768, 0.5820, 0.4966, 0.6054,
        0.6096, 0.6636, 0.6153, 0.5881, 0.6444, 0.5135, 0.4722],
       device='cuda:0') torch.Size([16])
percent tensor([0.9996, 0.9992, 0.9997, 0.9998, 0.9999, 0.9970, 0.9994, 0.9997, 0.9992,
        0.9997, 0.9992, 0.9997, 0.9988, 0.9993, 0.9996, 0.9994],
       device='cuda:0') torch.Size([16])
Epoch: 89 | Batch_idx: 0 |  Loss: (0.2285) |  Loss2: (0.0000) | Acc: (92.00%) (118/128)
Epoch: 89 | Batch_idx: 10 |  Loss: (0.2357) |  Loss2: (0.0000) | Acc: (92.00%) (1301/1408)
Epoch: 89 | Batch_idx: 20 |  Loss: (0.2216) |  Loss2: (0.0000) | Acc: (92.00%) (2497/2688)
Epoch: 89 | Batch_idx: 30 |  Loss: (0.2284) |  Loss2: (0.0000) | Acc: (92.00%) (3668/3968)
Epoch: 89 | Batch_idx: 40 |  Loss: (0.2408) |  Loss2: (0.0000) | Acc: (91.00%) (4823/5248)
Epoch: 89 | Batch_idx: 50 |  Loss: (0.2441) |  Loss2: (0.0000) | Acc: (91.00%) (5989/6528)
Epoch: 89 | Batch_idx: 60 |  Loss: (0.2455) |  Loss2: (0.0000) | Acc: (91.00%) (7154/7808)
Epoch: 89 | Batch_idx: 70 |  Loss: (0.2454) |  Loss2: (0.0000) | Acc: (91.00%) (8320/9088)
Epoch: 89 | Batch_idx: 80 |  Loss: (0.2405) |  Loss2: (0.0000) | Acc: (91.00%) (9509/10368)
Epoch: 89 | Batch_idx: 90 |  Loss: (0.2426) |  Loss2: (0.0000) | Acc: (91.00%) (10675/11648)
Epoch: 89 | Batch_idx: 100 |  Loss: (0.2428) |  Loss2: (0.0000) | Acc: (91.00%) (11854/12928)
Epoch: 89 | Batch_idx: 110 |  Loss: (0.2399) |  Loss2: (0.0000) | Acc: (91.00%) (13039/14208)
Epoch: 89 | Batch_idx: 120 |  Loss: (0.2408) |  Loss2: (0.0000) | Acc: (91.00%) (14208/15488)
Epoch: 89 | Batch_idx: 130 |  Loss: (0.2402) |  Loss2: (0.0000) | Acc: (91.00%) (15386/16768)
Epoch: 89 | Batch_idx: 140 |  Loss: (0.2410) |  Loss2: (0.0000) | Acc: (91.00%) (16557/18048)
Epoch: 89 | Batch_idx: 150 |  Loss: (0.2418) |  Loss2: (0.0000) | Acc: (91.00%) (17721/19328)
Epoch: 89 | Batch_idx: 160 |  Loss: (0.2406) |  Loss2: (0.0000) | Acc: (91.00%) (18906/20608)
Epoch: 89 | Batch_idx: 170 |  Loss: (0.2396) |  Loss2: (0.0000) | Acc: (91.00%) (20087/21888)
Epoch: 89 | Batch_idx: 180 |  Loss: (0.2373) |  Loss2: (0.0000) | Acc: (91.00%) (21277/23168)
Epoch: 89 | Batch_idx: 190 |  Loss: (0.2371) |  Loss2: (0.0000) | Acc: (91.00%) (22462/24448)
Epoch: 89 | Batch_idx: 200 |  Loss: (0.2367) |  Loss2: (0.0000) | Acc: (91.00%) (23646/25728)
Epoch: 89 | Batch_idx: 210 |  Loss: (0.2364) |  Loss2: (0.0000) | Acc: (91.00%) (24827/27008)
Epoch: 89 | Batch_idx: 220 |  Loss: (0.2356) |  Loss2: (0.0000) | Acc: (91.00%) (26000/28288)
Epoch: 89 | Batch_idx: 230 |  Loss: (0.2369) |  Loss2: (0.0000) | Acc: (91.00%) (27172/29568)
Epoch: 89 | Batch_idx: 240 |  Loss: (0.2363) |  Loss2: (0.0000) | Acc: (91.00%) (28365/30848)
Epoch: 89 | Batch_idx: 250 |  Loss: (0.2360) |  Loss2: (0.0000) | Acc: (91.00%) (29553/32128)
Epoch: 89 | Batch_idx: 260 |  Loss: (0.2360) |  Loss2: (0.0000) | Acc: (91.00%) (30724/33408)
Epoch: 89 | Batch_idx: 270 |  Loss: (0.2352) |  Loss2: (0.0000) | Acc: (92.00%) (31917/34688)
Epoch: 89 | Batch_idx: 280 |  Loss: (0.2358) |  Loss2: (0.0000) | Acc: (92.00%) (33091/35968)
Epoch: 89 | Batch_idx: 290 |  Loss: (0.2347) |  Loss2: (0.0000) | Acc: (92.00%) (34285/37248)
Epoch: 89 | Batch_idx: 300 |  Loss: (0.2348) |  Loss2: (0.0000) | Acc: (92.00%) (35464/38528)
Epoch: 89 | Batch_idx: 310 |  Loss: (0.2345) |  Loss2: (0.0000) | Acc: (92.00%) (36645/39808)
Epoch: 89 | Batch_idx: 320 |  Loss: (0.2353) |  Loss2: (0.0000) | Acc: (91.00%) (37795/41088)
Epoch: 89 | Batch_idx: 330 |  Loss: (0.2360) |  Loss2: (0.0000) | Acc: (91.00%) (38950/42368)
Epoch: 89 | Batch_idx: 340 |  Loss: (0.2365) |  Loss2: (0.0000) | Acc: (91.00%) (40117/43648)
Epoch: 89 | Batch_idx: 350 |  Loss: (0.2369) |  Loss2: (0.0000) | Acc: (91.00%) (41285/44928)
Epoch: 89 | Batch_idx: 360 |  Loss: (0.2367) |  Loss2: (0.0000) | Acc: (91.00%) (42464/46208)
Epoch: 89 | Batch_idx: 370 |  Loss: (0.2362) |  Loss2: (0.0000) | Acc: (91.00%) (43643/47488)
Epoch: 89 | Batch_idx: 380 |  Loss: (0.2361) |  Loss2: (0.0000) | Acc: (91.00%) (44820/48768)
Epoch: 89 | Batch_idx: 390 |  Loss: (0.2356) |  Loss2: (0.0000) | Acc: (91.00%) (45962/50000)
# TEST : Loss: (0.3813) | Acc: (87.00%) (8732/10000)
percent tensor([0.5546, 0.5640, 0.5552, 0.5530, 0.5584, 0.5578, 0.5646, 0.5539, 0.5548,
        0.5596, 0.5596, 0.5605, 0.5581, 0.5561, 0.5638, 0.5567],
       device='cuda:0') torch.Size([16])
percent tensor([0.5095, 0.5095, 0.5052, 0.5078, 0.5059, 0.5138, 0.5075, 0.5059, 0.5061,
        0.5079, 0.5101, 0.5058, 0.5076, 0.5089, 0.5115, 0.5098],
       device='cuda:0') torch.Size([16])
percent tensor([0.5405, 0.4196, 0.6930, 0.6610, 0.6926, 0.6334, 0.5295, 0.6637, 0.5915,
        0.4965, 0.4358, 0.5969, 0.4442, 0.4856, 0.5127, 0.5721],
       device='cuda:0') torch.Size([16])
percent tensor([0.6858, 0.7216, 0.6265, 0.6593, 0.6480, 0.5370, 0.6951, 0.6559, 0.6963,
        0.7202, 0.7422, 0.6922, 0.7045, 0.7285, 0.6830, 0.6521],
       device='cuda:0') torch.Size([16])
percent tensor([0.6877, 0.5841, 0.7327, 0.7299, 0.7552, 0.7576, 0.6814, 0.7467, 0.6654,
        0.5684, 0.5443, 0.6202, 0.5488, 0.6537, 0.6808, 0.7105],
       device='cuda:0') torch.Size([16])
percent tensor([0.5561, 0.6187, 0.6787, 0.7078, 0.6977, 0.7360, 0.6217, 0.5360, 0.6645,
        0.6064, 0.6444, 0.6357, 0.6165, 0.6783, 0.5190, 0.5900],
       device='cuda:0') torch.Size([16])
percent tensor([0.5045, 0.6102, 0.6003, 0.6132, 0.5815, 0.5857, 0.5912, 0.5042, 0.6164,
        0.6191, 0.6741, 0.6276, 0.5967, 0.6495, 0.5248, 0.4792],
       device='cuda:0') torch.Size([16])
percent tensor([0.9996, 0.9993, 0.9997, 0.9998, 0.9999, 0.9973, 0.9994, 0.9996, 0.9992,
        0.9997, 0.9991, 0.9997, 0.9988, 0.9993, 0.9996, 0.9994],
       device='cuda:0') torch.Size([16])
True Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=128, out_features=16, bias=False)
False Linear(in_features=16, out_features=2, bias=False)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=128, out_features=16, bias=False)
False Linear(in_features=16, out_features=2, bias=False)
True Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=256, out_features=32, bias=False)
False Linear(in_features=32, out_features=2, bias=False)
True Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=256, out_features=32, bias=False)
False Linear(in_features=32, out_features=2, bias=False)
True Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=512, out_features=64, bias=False)
False Linear(in_features=64, out_features=2, bias=False)
True Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=512, out_features=64, bias=False)
False Linear(in_features=64, out_features=2, bias=False)
True Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1024, out_features=128, bias=False)
False Linear(in_features=128, out_features=2, bias=False)
True Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1024, out_features=128, bias=False)
False Linear(in_features=128, out_features=2, bias=False)
True Linear(in_features=512, out_features=10, bias=True)
Epoch: 90 | Batch_idx: 0 |  Loss: (0.1737) |  Loss2: (0.0000) | Acc: (93.00%) (120/128)
Epoch: 90 | Batch_idx: 10 |  Loss: (0.2266) |  Loss2: (0.0000) | Acc: (92.00%) (1297/1408)
Epoch: 90 | Batch_idx: 20 |  Loss: (0.2471) |  Loss2: (0.0000) | Acc: (91.00%) (2457/2688)
Epoch: 90 | Batch_idx: 30 |  Loss: (0.2426) |  Loss2: (0.0000) | Acc: (91.00%) (3633/3968)
Epoch: 90 | Batch_idx: 40 |  Loss: (0.2347) |  Loss2: (0.0000) | Acc: (91.00%) (4826/5248)
Epoch: 90 | Batch_idx: 50 |  Loss: (0.2384) |  Loss2: (0.0000) | Acc: (91.00%) (5999/6528)
Epoch: 90 | Batch_idx: 60 |  Loss: (0.2370) |  Loss2: (0.0000) | Acc: (91.00%) (7178/7808)
Epoch: 90 | Batch_idx: 70 |  Loss: (0.2344) |  Loss2: (0.0000) | Acc: (91.00%) (8350/9088)
Epoch: 90 | Batch_idx: 80 |  Loss: (0.2354) |  Loss2: (0.0000) | Acc: (91.00%) (9519/10368)
Epoch: 90 | Batch_idx: 90 |  Loss: (0.2323) |  Loss2: (0.0000) | Acc: (91.00%) (10711/11648)
Epoch: 90 | Batch_idx: 100 |  Loss: (0.2310) |  Loss2: (0.0000) | Acc: (92.00%) (11901/12928)
Epoch: 90 | Batch_idx: 110 |  Loss: (0.2330) |  Loss2: (0.0000) | Acc: (92.00%) (13077/14208)
Epoch: 90 | Batch_idx: 120 |  Loss: (0.2344) |  Loss2: (0.0000) | Acc: (91.00%) (14235/15488)
Epoch: 90 | Batch_idx: 130 |  Loss: (0.2366) |  Loss2: (0.0000) | Acc: (91.00%) (15393/16768)
Epoch: 90 | Batch_idx: 140 |  Loss: (0.2359) |  Loss2: (0.0000) | Acc: (91.00%) (16578/18048)
Epoch: 90 | Batch_idx: 150 |  Loss: (0.2348) |  Loss2: (0.0000) | Acc: (91.00%) (17757/19328)
Epoch: 90 | Batch_idx: 160 |  Loss: (0.2359) |  Loss2: (0.0000) | Acc: (91.00%) (18927/20608)
Epoch: 90 | Batch_idx: 170 |  Loss: (0.2370) |  Loss2: (0.0000) | Acc: (91.00%) (20090/21888)
Epoch: 90 | Batch_idx: 180 |  Loss: (0.2374) |  Loss2: (0.0000) | Acc: (91.00%) (21267/23168)
Epoch: 90 | Batch_idx: 190 |  Loss: (0.2383) |  Loss2: (0.0000) | Acc: (91.00%) (22429/24448)
Epoch: 90 | Batch_idx: 200 |  Loss: (0.2382) |  Loss2: (0.0000) | Acc: (91.00%) (23607/25728)
Epoch: 90 | Batch_idx: 210 |  Loss: (0.2394) |  Loss2: (0.0000) | Acc: (91.00%) (24768/27008)
Epoch: 90 | Batch_idx: 220 |  Loss: (0.2401) |  Loss2: (0.0000) | Acc: (91.00%) (25932/28288)
Epoch: 90 | Batch_idx: 230 |  Loss: (0.2401) |  Loss2: (0.0000) | Acc: (91.00%) (27102/29568)
Epoch: 90 | Batch_idx: 240 |  Loss: (0.2407) |  Loss2: (0.0000) | Acc: (91.00%) (28282/30848)
Epoch: 90 | Batch_idx: 250 |  Loss: (0.2412) |  Loss2: (0.0000) | Acc: (91.00%) (29445/32128)
Epoch: 90 | Batch_idx: 260 |  Loss: (0.2415) |  Loss2: (0.0000) | Acc: (91.00%) (30616/33408)
Epoch: 90 | Batch_idx: 270 |  Loss: (0.2409) |  Loss2: (0.0000) | Acc: (91.00%) (31803/34688)
Epoch: 90 | Batch_idx: 280 |  Loss: (0.2412) |  Loss2: (0.0000) | Acc: (91.00%) (32958/35968)
Epoch: 90 | Batch_idx: 290 |  Loss: (0.2405) |  Loss2: (0.0000) | Acc: (91.00%) (34142/37248)
Epoch: 90 | Batch_idx: 300 |  Loss: (0.2398) |  Loss2: (0.0000) | Acc: (91.00%) (35331/38528)
Epoch: 90 | Batch_idx: 310 |  Loss: (0.2397) |  Loss2: (0.0000) | Acc: (91.00%) (36502/39808)
Epoch: 90 | Batch_idx: 320 |  Loss: (0.2407) |  Loss2: (0.0000) | Acc: (91.00%) (37665/41088)
Epoch: 90 | Batch_idx: 330 |  Loss: (0.2412) |  Loss2: (0.0000) | Acc: (91.00%) (38829/42368)
Epoch: 90 | Batch_idx: 340 |  Loss: (0.2422) |  Loss2: (0.0000) | Acc: (91.00%) (39993/43648)
Epoch: 90 | Batch_idx: 350 |  Loss: (0.2420) |  Loss2: (0.0000) | Acc: (91.00%) (41166/44928)
Epoch: 90 | Batch_idx: 360 |  Loss: (0.2421) |  Loss2: (0.0000) | Acc: (91.00%) (42343/46208)
Epoch: 90 | Batch_idx: 370 |  Loss: (0.2425) |  Loss2: (0.0000) | Acc: (91.00%) (43520/47488)
Epoch: 90 | Batch_idx: 380 |  Loss: (0.2423) |  Loss2: (0.0000) | Acc: (91.00%) (44693/48768)
Epoch: 90 | Batch_idx: 390 |  Loss: (0.2431) |  Loss2: (0.0000) | Acc: (91.00%) (45820/50000)
=> saving checkpoint 'drive/app/torch/save_Schedule/checkpoint_090.pth.tar'
# TEST : Loss: (0.4584) | Acc: (85.00%) (8533/10000)
percent tensor([0.5543, 0.5639, 0.5560, 0.5520, 0.5585, 0.5564, 0.5650, 0.5543, 0.5552,
        0.5599, 0.5595, 0.5614, 0.5579, 0.5554, 0.5631, 0.5562],
       device='cuda:0') torch.Size([16])
percent tensor([0.5099, 0.5090, 0.5065, 0.5084, 0.5067, 0.5145, 0.5075, 0.5065, 0.5061,
        0.5079, 0.5100, 0.5061, 0.5075, 0.5085, 0.5113, 0.5100],
       device='cuda:0') torch.Size([16])
percent tensor([0.5420, 0.4256, 0.6882, 0.6694, 0.6914, 0.6316, 0.5326, 0.6625, 0.5831,
        0.5005, 0.4414, 0.6045, 0.4453, 0.4956, 0.5193, 0.5754],
       device='cuda:0') torch.Size([16])
percent tensor([0.6900, 0.7176, 0.6154, 0.6510, 0.6310, 0.5470, 0.6940, 0.6487, 0.6952,
        0.7163, 0.7427, 0.6789, 0.6994, 0.7222, 0.6819, 0.6529],
       device='cuda:0') torch.Size([16])
percent tensor([0.6963, 0.5973, 0.7350, 0.7459, 0.7570, 0.7576, 0.6898, 0.7472, 0.6668,
        0.5837, 0.5548, 0.6403, 0.5709, 0.6520, 0.6876, 0.7248],
       device='cuda:0') torch.Size([16])
percent tensor([0.5400, 0.6181, 0.6861, 0.7264, 0.7133, 0.7317, 0.6034, 0.5427, 0.6498,
        0.6072, 0.6439, 0.6634, 0.6096, 0.6667, 0.5236, 0.5803],
       device='cuda:0') torch.Size([16])
percent tensor([0.5015, 0.6200, 0.6121, 0.6115, 0.5896, 0.5857, 0.5780, 0.5091, 0.6246,
        0.6135, 0.6810, 0.6341, 0.5813, 0.6525, 0.5292, 0.4753],
       device='cuda:0') torch.Size([16])
percent tensor([0.9997, 0.9994, 0.9995, 0.9997, 0.9998, 0.9984, 0.9996, 0.9998, 0.9994,
        0.9997, 0.9992, 0.9997, 0.9989, 0.9993, 0.9997, 0.9996],
       device='cuda:0') torch.Size([16])
Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 3, 3, 3]) tensor(179.9848, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(806.6494, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(810.2655, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([128, 64, 3, 3]) tensor(1519.5005, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([128, 64, 1, 1]) tensor(501.2053, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([128, 128, 3, 3]) tensor(2228.6294, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([256, 128, 3, 3]) tensor(4290.5205, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([256, 128, 1, 1]) tensor(1408.3384, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([256, 256, 3, 3]) tensor(6131.4746, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([512, 256, 3, 3]) tensor(11911.9648, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([512, 256, 1, 1]) tensor(3958.4590, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([512, 512, 3, 3]) tensor(16699.4180, device='cuda:0', grad_fn=<NormBackward0>)
Epoch: 91 | Batch_idx: 0 |  Loss: (0.3119) |  Loss2: (0.0000) | Acc: (87.00%) (112/128)
Epoch: 91 | Batch_idx: 10 |  Loss: (0.2343) |  Loss2: (0.0000) | Acc: (92.00%) (1299/1408)
Epoch: 91 | Batch_idx: 20 |  Loss: (0.2103) |  Loss2: (0.0000) | Acc: (92.00%) (2498/2688)
Epoch: 91 | Batch_idx: 30 |  Loss: (0.2159) |  Loss2: (0.0000) | Acc: (92.00%) (3669/3968)
Epoch: 91 | Batch_idx: 40 |  Loss: (0.2212) |  Loss2: (0.0000) | Acc: (92.00%) (4834/5248)
Epoch: 91 | Batch_idx: 50 |  Loss: (0.2249) |  Loss2: (0.0000) | Acc: (92.00%) (6018/6528)
Epoch: 91 | Batch_idx: 60 |  Loss: (0.2218) |  Loss2: (0.0000) | Acc: (92.00%) (7204/7808)
Epoch: 91 | Batch_idx: 70 |  Loss: (0.2245) |  Loss2: (0.0000) | Acc: (92.00%) (8383/9088)
Epoch: 91 | Batch_idx: 80 |  Loss: (0.2271) |  Loss2: (0.0000) | Acc: (92.00%) (9556/10368)
Epoch: 91 | Batch_idx: 90 |  Loss: (0.2301) |  Loss2: (0.0000) | Acc: (92.00%) (10724/11648)
Epoch: 91 | Batch_idx: 100 |  Loss: (0.2315) |  Loss2: (0.0000) | Acc: (91.00%) (11891/12928)
Epoch: 91 | Batch_idx: 110 |  Loss: (0.2306) |  Loss2: (0.0000) | Acc: (92.00%) (13072/14208)
Epoch: 91 | Batch_idx: 120 |  Loss: (0.2301) |  Loss2: (0.0000) | Acc: (92.00%) (14259/15488)
Epoch: 91 | Batch_idx: 130 |  Loss: (0.2308) |  Loss2: (0.0000) | Acc: (92.00%) (15436/16768)
Epoch: 91 | Batch_idx: 140 |  Loss: (0.2314) |  Loss2: (0.0000) | Acc: (92.00%) (16620/18048)
Epoch: 91 | Batch_idx: 150 |  Loss: (0.2307) |  Loss2: (0.0000) | Acc: (92.00%) (17808/19328)
Epoch: 91 | Batch_idx: 160 |  Loss: (0.2346) |  Loss2: (0.0000) | Acc: (91.00%) (18952/20608)
Epoch: 91 | Batch_idx: 170 |  Loss: (0.2369) |  Loss2: (0.0000) | Acc: (91.00%) (20106/21888)
Epoch: 91 | Batch_idx: 180 |  Loss: (0.2384) |  Loss2: (0.0000) | Acc: (91.00%) (21268/23168)
Epoch: 91 | Batch_idx: 190 |  Loss: (0.2388) |  Loss2: (0.0000) | Acc: (91.00%) (22438/24448)
Epoch: 91 | Batch_idx: 200 |  Loss: (0.2376) |  Loss2: (0.0000) | Acc: (91.00%) (23633/25728)
Epoch: 91 | Batch_idx: 210 |  Loss: (0.2373) |  Loss2: (0.0000) | Acc: (91.00%) (24812/27008)
Epoch: 91 | Batch_idx: 220 |  Loss: (0.2372) |  Loss2: (0.0000) | Acc: (91.00%) (25991/28288)
Epoch: 91 | Batch_idx: 230 |  Loss: (0.2362) |  Loss2: (0.0000) | Acc: (91.00%) (27176/29568)
Epoch: 91 | Batch_idx: 240 |  Loss: (0.2368) |  Loss2: (0.0000) | Acc: (91.00%) (28340/30848)
Epoch: 91 | Batch_idx: 250 |  Loss: (0.2363) |  Loss2: (0.0000) | Acc: (91.00%) (29514/32128)
Epoch: 91 | Batch_idx: 260 |  Loss: (0.2362) |  Loss2: (0.0000) | Acc: (91.00%) (30696/33408)
Epoch: 91 | Batch_idx: 270 |  Loss: (0.2368) |  Loss2: (0.0000) | Acc: (91.00%) (31855/34688)
Epoch: 91 | Batch_idx: 280 |  Loss: (0.2369) |  Loss2: (0.0000) | Acc: (91.00%) (33029/35968)
Epoch: 91 | Batch_idx: 290 |  Loss: (0.2362) |  Loss2: (0.0000) | Acc: (91.00%) (34211/37248)
Epoch: 91 | Batch_idx: 300 |  Loss: (0.2360) |  Loss2: (0.0000) | Acc: (91.00%) (35389/38528)
Epoch: 91 | Batch_idx: 310 |  Loss: (0.2358) |  Loss2: (0.0000) | Acc: (91.00%) (36583/39808)
Epoch: 91 | Batch_idx: 320 |  Loss: (0.2365) |  Loss2: (0.0000) | Acc: (91.00%) (37749/41088)
Epoch: 91 | Batch_idx: 330 |  Loss: (0.2367) |  Loss2: (0.0000) | Acc: (91.00%) (38919/42368)
Epoch: 91 | Batch_idx: 340 |  Loss: (0.2372) |  Loss2: (0.0000) | Acc: (91.00%) (40090/43648)
Epoch: 91 | Batch_idx: 350 |  Loss: (0.2371) |  Loss2: (0.0000) | Acc: (91.00%) (41269/44928)
Epoch: 91 | Batch_idx: 360 |  Loss: (0.2376) |  Loss2: (0.0000) | Acc: (91.00%) (42444/46208)
Epoch: 91 | Batch_idx: 370 |  Loss: (0.2376) |  Loss2: (0.0000) | Acc: (91.00%) (43618/47488)
Epoch: 91 | Batch_idx: 380 |  Loss: (0.2373) |  Loss2: (0.0000) | Acc: (91.00%) (44803/48768)
Epoch: 91 | Batch_idx: 390 |  Loss: (0.2371) |  Loss2: (0.0000) | Acc: (91.00%) (45938/50000)
# TEST : Loss: (0.4160) | Acc: (86.00%) (8662/10000)
percent tensor([0.5544, 0.5650, 0.5534, 0.5518, 0.5568, 0.5567, 0.5657, 0.5534, 0.5553,
        0.5601, 0.5602, 0.5596, 0.5584, 0.5577, 0.5635, 0.5569],
       device='cuda:0') torch.Size([16])
percent tensor([0.5099, 0.5091, 0.5058, 0.5080, 0.5065, 0.5150, 0.5071, 0.5059, 0.5058,
        0.5080, 0.5099, 0.5059, 0.5077, 0.5082, 0.5116, 0.5098],
       device='cuda:0') torch.Size([16])
percent tensor([0.5249, 0.4128, 0.6849, 0.6623, 0.6852, 0.6163, 0.5215, 0.6513, 0.5775,
        0.4859, 0.4298, 0.6019, 0.4356, 0.4846, 0.4961, 0.5569],
       device='cuda:0') torch.Size([16])
percent tensor([0.6935, 0.7195, 0.6134, 0.6464, 0.6370, 0.5481, 0.6969, 0.6492, 0.6969,
        0.7169, 0.7410, 0.6796, 0.7106, 0.7212, 0.6856, 0.6526],
       device='cuda:0') torch.Size([16])
percent tensor([0.6953, 0.5756, 0.7298, 0.7475, 0.7522, 0.7536, 0.6755, 0.7367, 0.6764,
        0.5791, 0.5653, 0.6360, 0.5697, 0.6404, 0.6824, 0.7171],
       device='cuda:0') torch.Size([16])
percent tensor([0.5312, 0.5946, 0.6805, 0.7174, 0.7135, 0.7382, 0.5964, 0.5461, 0.6377,
        0.5756, 0.6202, 0.6428, 0.5982, 0.6314, 0.5177, 0.5597],
       device='cuda:0') torch.Size([16])
percent tensor([0.4979, 0.6148, 0.6091, 0.6064, 0.5910, 0.5968, 0.5760, 0.5139, 0.6023,
        0.5975, 0.6609, 0.6201, 0.5770, 0.6579, 0.5319, 0.4791],
       device='cuda:0') torch.Size([16])
percent tensor([0.9996, 0.9995, 0.9994, 0.9998, 0.9998, 0.9984, 0.9996, 0.9997, 0.9996,
        0.9997, 0.9991, 0.9997, 0.9992, 0.9992, 0.9997, 0.9997],
       device='cuda:0') torch.Size([16])
Epoch: 92 | Batch_idx: 0 |  Loss: (0.2717) |  Loss2: (0.0000) | Acc: (91.00%) (117/128)
Epoch: 92 | Batch_idx: 10 |  Loss: (0.2634) |  Loss2: (0.0000) | Acc: (91.00%) (1289/1408)
Epoch: 92 | Batch_idx: 20 |  Loss: (0.2538) |  Loss2: (0.0000) | Acc: (91.00%) (2461/2688)
Epoch: 92 | Batch_idx: 30 |  Loss: (0.2494) |  Loss2: (0.0000) | Acc: (91.00%) (3635/3968)
Epoch: 92 | Batch_idx: 40 |  Loss: (0.2390) |  Loss2: (0.0000) | Acc: (92.00%) (4831/5248)
Epoch: 92 | Batch_idx: 50 |  Loss: (0.2454) |  Loss2: (0.0000) | Acc: (91.00%) (5981/6528)
Epoch: 92 | Batch_idx: 60 |  Loss: (0.2429) |  Loss2: (0.0000) | Acc: (91.00%) (7158/7808)
Epoch: 92 | Batch_idx: 70 |  Loss: (0.2387) |  Loss2: (0.0000) | Acc: (91.00%) (8344/9088)
Epoch: 92 | Batch_idx: 80 |  Loss: (0.2384) |  Loss2: (0.0000) | Acc: (91.00%) (9520/10368)
Epoch: 92 | Batch_idx: 90 |  Loss: (0.2357) |  Loss2: (0.0000) | Acc: (91.00%) (10708/11648)
Epoch: 92 | Batch_idx: 100 |  Loss: (0.2334) |  Loss2: (0.0000) | Acc: (91.00%) (11891/12928)
Epoch: 92 | Batch_idx: 110 |  Loss: (0.2331) |  Loss2: (0.0000) | Acc: (91.00%) (13061/14208)
Epoch: 92 | Batch_idx: 120 |  Loss: (0.2360) |  Loss2: (0.0000) | Acc: (91.00%) (14217/15488)
Epoch: 92 | Batch_idx: 130 |  Loss: (0.2358) |  Loss2: (0.0000) | Acc: (91.00%) (15391/16768)
Epoch: 92 | Batch_idx: 140 |  Loss: (0.2350) |  Loss2: (0.0000) | Acc: (91.00%) (16568/18048)
Epoch: 92 | Batch_idx: 150 |  Loss: (0.2323) |  Loss2: (0.0000) | Acc: (91.00%) (17763/19328)
Epoch: 92 | Batch_idx: 160 |  Loss: (0.2309) |  Loss2: (0.0000) | Acc: (91.00%) (18953/20608)
Epoch: 92 | Batch_idx: 170 |  Loss: (0.2321) |  Loss2: (0.0000) | Acc: (91.00%) (20122/21888)
Epoch: 92 | Batch_idx: 180 |  Loss: (0.2325) |  Loss2: (0.0000) | Acc: (91.00%) (21296/23168)
Epoch: 92 | Batch_idx: 190 |  Loss: (0.2311) |  Loss2: (0.0000) | Acc: (91.00%) (22481/24448)
Epoch: 92 | Batch_idx: 200 |  Loss: (0.2302) |  Loss2: (0.0000) | Acc: (91.00%) (23660/25728)
Epoch: 92 | Batch_idx: 210 |  Loss: (0.2311) |  Loss2: (0.0000) | Acc: (91.00%) (24828/27008)
Epoch: 92 | Batch_idx: 220 |  Loss: (0.2296) |  Loss2: (0.0000) | Acc: (91.00%) (26024/28288)
Epoch: 92 | Batch_idx: 230 |  Loss: (0.2299) |  Loss2: (0.0000) | Acc: (91.00%) (27192/29568)
Epoch: 92 | Batch_idx: 240 |  Loss: (0.2297) |  Loss2: (0.0000) | Acc: (91.00%) (28367/30848)
Epoch: 92 | Batch_idx: 250 |  Loss: (0.2295) |  Loss2: (0.0000) | Acc: (92.00%) (29562/32128)
Epoch: 92 | Batch_idx: 260 |  Loss: (0.2300) |  Loss2: (0.0000) | Acc: (92.00%) (30749/33408)
Epoch: 92 | Batch_idx: 270 |  Loss: (0.2302) |  Loss2: (0.0000) | Acc: (92.00%) (31929/34688)
Epoch: 92 | Batch_idx: 280 |  Loss: (0.2310) |  Loss2: (0.0000) | Acc: (92.00%) (33098/35968)
Epoch: 92 | Batch_idx: 290 |  Loss: (0.2315) |  Loss2: (0.0000) | Acc: (91.00%) (34260/37248)
Epoch: 92 | Batch_idx: 300 |  Loss: (0.2308) |  Loss2: (0.0000) | Acc: (92.00%) (35447/38528)
Epoch: 92 | Batch_idx: 310 |  Loss: (0.2310) |  Loss2: (0.0000) | Acc: (92.00%) (36631/39808)
Epoch: 92 | Batch_idx: 320 |  Loss: (0.2312) |  Loss2: (0.0000) | Acc: (91.00%) (37799/41088)
Epoch: 92 | Batch_idx: 330 |  Loss: (0.2304) |  Loss2: (0.0000) | Acc: (92.00%) (38990/42368)
Epoch: 92 | Batch_idx: 340 |  Loss: (0.2303) |  Loss2: (0.0000) | Acc: (92.00%) (40174/43648)
Epoch: 92 | Batch_idx: 350 |  Loss: (0.2304) |  Loss2: (0.0000) | Acc: (92.00%) (41355/44928)
Epoch: 92 | Batch_idx: 360 |  Loss: (0.2298) |  Loss2: (0.0000) | Acc: (92.00%) (42542/46208)
Epoch: 92 | Batch_idx: 370 |  Loss: (0.2301) |  Loss2: (0.0000) | Acc: (92.00%) (43711/47488)
Epoch: 92 | Batch_idx: 380 |  Loss: (0.2305) |  Loss2: (0.0000) | Acc: (92.00%) (44888/48768)
Epoch: 92 | Batch_idx: 390 |  Loss: (0.2315) |  Loss2: (0.0000) | Acc: (92.00%) (46016/50000)
# TEST : Loss: (0.4466) | Acc: (85.00%) (8599/10000)
percent tensor([0.5545, 0.5641, 0.5553, 0.5508, 0.5585, 0.5574, 0.5658, 0.5539, 0.5556,
        0.5598, 0.5602, 0.5609, 0.5584, 0.5562, 0.5633, 0.5567],
       device='cuda:0') torch.Size([16])
percent tensor([0.5098, 0.5091, 0.5048, 0.5080, 0.5060, 0.5145, 0.5073, 0.5054, 0.5058,
        0.5081, 0.5100, 0.5057, 0.5075, 0.5086, 0.5115, 0.5098],
       device='cuda:0') torch.Size([16])
percent tensor([0.5441, 0.4272, 0.6794, 0.6595, 0.6845, 0.6194, 0.5357, 0.6565, 0.5978,
        0.4978, 0.4472, 0.6030, 0.4607, 0.5032, 0.5030, 0.5677],
       device='cuda:0') torch.Size([16])
percent tensor([0.6916, 0.7188, 0.6241, 0.6512, 0.6439, 0.5649, 0.6933, 0.6506, 0.6955,
        0.7163, 0.7378, 0.6797, 0.7024, 0.7209, 0.6829, 0.6542],
       device='cuda:0') torch.Size([16])
percent tensor([0.6856, 0.5718, 0.7267, 0.7313, 0.7462, 0.7464, 0.6772, 0.7309, 0.6612,
        0.5768, 0.5567, 0.6266, 0.5620, 0.6313, 0.6744, 0.7179],
       device='cuda:0') torch.Size([16])
percent tensor([0.5430, 0.6259, 0.6677, 0.7084, 0.6963, 0.7400, 0.6198, 0.5369, 0.6573,
        0.6162, 0.6416, 0.6549, 0.6239, 0.6747, 0.5461, 0.5835],
       device='cuda:0') torch.Size([16])
percent tensor([0.4986, 0.6258, 0.5857, 0.6231, 0.5716, 0.5957, 0.5851, 0.5036, 0.6273,
        0.6143, 0.6750, 0.6267, 0.5997, 0.6658, 0.5204, 0.4750],
       device='cuda:0') torch.Size([16])
percent tensor([0.9996, 0.9995, 0.9997, 0.9998, 0.9998, 0.9983, 0.9998, 0.9997, 0.9998,
        0.9996, 0.9993, 0.9998, 0.9991, 0.9993, 0.9996, 0.9995],
       device='cuda:0') torch.Size([16])
False Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=128, out_features=16, bias=False)
True Linear(in_features=16, out_features=2, bias=False)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=128, out_features=16, bias=False)
True Linear(in_features=16, out_features=2, bias=False)
False Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=256, out_features=32, bias=False)
True Linear(in_features=32, out_features=2, bias=False)
False Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=256, out_features=32, bias=False)
True Linear(in_features=32, out_features=2, bias=False)
False Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=512, out_features=64, bias=False)
True Linear(in_features=64, out_features=2, bias=False)
False Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=512, out_features=64, bias=False)
True Linear(in_features=64, out_features=2, bias=False)
False Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1024, out_features=128, bias=False)
True Linear(in_features=128, out_features=2, bias=False)
False Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1024, out_features=128, bias=False)
True Linear(in_features=128, out_features=2, bias=False)
False Linear(in_features=512, out_features=10, bias=True)
Epoch: 93 | Batch_idx: 0 |  Loss: (0.2533) |  Loss2: (0.0000) | Acc: (92.00%) (119/128)
Epoch: 93 | Batch_idx: 10 |  Loss: (0.2355) |  Loss2: (0.0000) | Acc: (91.00%) (1292/1408)
Epoch: 93 | Batch_idx: 20 |  Loss: (0.2631) |  Loss2: (0.0000) | Acc: (90.00%) (2442/2688)
Epoch: 93 | Batch_idx: 30 |  Loss: (0.2661) |  Loss2: (0.0000) | Acc: (90.00%) (3597/3968)
Epoch: 93 | Batch_idx: 40 |  Loss: (0.2755) |  Loss2: (0.0000) | Acc: (90.00%) (4739/5248)
Epoch: 93 | Batch_idx: 50 |  Loss: (0.2837) |  Loss2: (0.0000) | Acc: (90.00%) (5882/6528)
Epoch: 93 | Batch_idx: 60 |  Loss: (0.2871) |  Loss2: (0.0000) | Acc: (89.00%) (7018/7808)
Epoch: 93 | Batch_idx: 70 |  Loss: (0.2830) |  Loss2: (0.0000) | Acc: (90.00%) (8183/9088)
Epoch: 93 | Batch_idx: 80 |  Loss: (0.2831) |  Loss2: (0.0000) | Acc: (90.00%) (9338/10368)
Epoch: 93 | Batch_idx: 90 |  Loss: (0.2849) |  Loss2: (0.0000) | Acc: (90.00%) (10486/11648)
Epoch: 93 | Batch_idx: 100 |  Loss: (0.2903) |  Loss2: (0.0000) | Acc: (89.00%) (11620/12928)
Epoch: 93 | Batch_idx: 110 |  Loss: (0.2886) |  Loss2: (0.0000) | Acc: (89.00%) (12776/14208)
Epoch: 93 | Batch_idx: 120 |  Loss: (0.2893) |  Loss2: (0.0000) | Acc: (89.00%) (13924/15488)
Epoch: 93 | Batch_idx: 130 |  Loss: (0.2894) |  Loss2: (0.0000) | Acc: (89.00%) (15087/16768)
Epoch: 93 | Batch_idx: 140 |  Loss: (0.2895) |  Loss2: (0.0000) | Acc: (89.00%) (16227/18048)
Epoch: 93 | Batch_idx: 150 |  Loss: (0.2896) |  Loss2: (0.0000) | Acc: (89.00%) (17374/19328)
Epoch: 93 | Batch_idx: 160 |  Loss: (0.2864) |  Loss2: (0.0000) | Acc: (90.00%) (18552/20608)
Epoch: 93 | Batch_idx: 170 |  Loss: (0.2842) |  Loss2: (0.0000) | Acc: (90.00%) (19727/21888)
Epoch: 93 | Batch_idx: 180 |  Loss: (0.2838) |  Loss2: (0.0000) | Acc: (90.00%) (20882/23168)
Epoch: 93 | Batch_idx: 190 |  Loss: (0.2817) |  Loss2: (0.0000) | Acc: (90.00%) (22063/24448)
Epoch: 93 | Batch_idx: 200 |  Loss: (0.2813) |  Loss2: (0.0000) | Acc: (90.00%) (23219/25728)
Epoch: 93 | Batch_idx: 210 |  Loss: (0.2787) |  Loss2: (0.0000) | Acc: (90.00%) (24402/27008)
Epoch: 93 | Batch_idx: 220 |  Loss: (0.2778) |  Loss2: (0.0000) | Acc: (90.00%) (25561/28288)
Epoch: 93 | Batch_idx: 230 |  Loss: (0.2784) |  Loss2: (0.0000) | Acc: (90.00%) (26717/29568)
Epoch: 93 | Batch_idx: 240 |  Loss: (0.2771) |  Loss2: (0.0000) | Acc: (90.00%) (27885/30848)
Epoch: 93 | Batch_idx: 250 |  Loss: (0.2775) |  Loss2: (0.0000) | Acc: (90.00%) (29029/32128)
Epoch: 93 | Batch_idx: 260 |  Loss: (0.2758) |  Loss2: (0.0000) | Acc: (90.00%) (30204/33408)
Epoch: 93 | Batch_idx: 270 |  Loss: (0.2752) |  Loss2: (0.0000) | Acc: (90.00%) (31366/34688)
Epoch: 93 | Batch_idx: 280 |  Loss: (0.2740) |  Loss2: (0.0000) | Acc: (90.00%) (32542/35968)
Epoch: 93 | Batch_idx: 290 |  Loss: (0.2732) |  Loss2: (0.0000) | Acc: (90.00%) (33704/37248)
Epoch: 93 | Batch_idx: 300 |  Loss: (0.2728) |  Loss2: (0.0000) | Acc: (90.00%) (34864/38528)
Epoch: 93 | Batch_idx: 310 |  Loss: (0.2722) |  Loss2: (0.0000) | Acc: (90.00%) (36029/39808)
Epoch: 93 | Batch_idx: 320 |  Loss: (0.2716) |  Loss2: (0.0000) | Acc: (90.00%) (37196/41088)
Epoch: 93 | Batch_idx: 330 |  Loss: (0.2718) |  Loss2: (0.0000) | Acc: (90.00%) (38346/42368)
Epoch: 93 | Batch_idx: 340 |  Loss: (0.2714) |  Loss2: (0.0000) | Acc: (90.00%) (39515/43648)
Epoch: 93 | Batch_idx: 350 |  Loss: (0.2707) |  Loss2: (0.0000) | Acc: (90.00%) (40683/44928)
Epoch: 93 | Batch_idx: 360 |  Loss: (0.2701) |  Loss2: (0.0000) | Acc: (90.00%) (41853/46208)
Epoch: 93 | Batch_idx: 370 |  Loss: (0.2697) |  Loss2: (0.0000) | Acc: (90.00%) (43025/47488)
Epoch: 93 | Batch_idx: 380 |  Loss: (0.2695) |  Loss2: (0.0000) | Acc: (90.00%) (44189/48768)
Epoch: 93 | Batch_idx: 390 |  Loss: (0.2696) |  Loss2: (0.0000) | Acc: (90.00%) (45304/50000)
# TEST : Loss: (0.4210) | Acc: (86.00%) (8638/10000)
percent tensor([0.5558, 0.5639, 0.5572, 0.5523, 0.5600, 0.5614, 0.5659, 0.5538, 0.5551,
        0.5601, 0.5609, 0.5627, 0.5591, 0.5529, 0.5658, 0.5578],
       device='cuda:0') torch.Size([16])
percent tensor([0.5098, 0.5080, 0.5049, 0.5085, 0.5061, 0.5153, 0.5056, 0.5052, 0.5056,
        0.5076, 0.5098, 0.5054, 0.5064, 0.5071, 0.5117, 0.5100],
       device='cuda:0') torch.Size([16])
percent tensor([0.5358, 0.4137, 0.6738, 0.6543, 0.6810, 0.6269, 0.5209, 0.6489, 0.5846,
        0.4839, 0.4307, 0.5898, 0.4482, 0.4826, 0.4990, 0.5655],
       device='cuda:0') torch.Size([16])
percent tensor([0.6714, 0.7063, 0.6067, 0.6282, 0.6150, 0.5415, 0.6737, 0.6253, 0.6746,
        0.7004, 0.7201, 0.6595, 0.6888, 0.7053, 0.6611, 0.6391],
       device='cuda:0') torch.Size([16])
percent tensor([0.6682, 0.5743, 0.6982, 0.6920, 0.7179, 0.7408, 0.6669, 0.7007, 0.6359,
        0.5704, 0.5469, 0.6005, 0.5674, 0.6074, 0.6634, 0.6950],
       device='cuda:0') torch.Size([16])
percent tensor([0.5099, 0.6021, 0.6692, 0.7181, 0.7107, 0.7274, 0.6143, 0.5290, 0.6449,
        0.5881, 0.6092, 0.6565, 0.5881, 0.6652, 0.5291, 0.5451],
       device='cuda:0') torch.Size([16])
percent tensor([0.5297, 0.6577, 0.6433, 0.6829, 0.6177, 0.6406, 0.6193, 0.5294, 0.6742,
        0.6402, 0.7036, 0.6782, 0.6399, 0.7068, 0.5583, 0.4877],
       device='cuda:0') torch.Size([16])
percent tensor([0.9995, 0.9996, 0.9997, 0.9998, 0.9997, 0.9987, 0.9998, 0.9998, 0.9997,
        0.9995, 0.9992, 0.9998, 0.9989, 0.9995, 0.9995, 0.9995],
       device='cuda:0') torch.Size([16])
Epoch: 94 | Batch_idx: 0 |  Loss: (0.2433) |  Loss2: (0.0000) | Acc: (90.00%) (116/128)
Epoch: 94 | Batch_idx: 10 |  Loss: (0.2633) |  Loss2: (0.0000) | Acc: (90.00%) (1275/1408)
Epoch: 94 | Batch_idx: 20 |  Loss: (0.2418) |  Loss2: (0.0000) | Acc: (91.00%) (2469/2688)
Epoch: 94 | Batch_idx: 30 |  Loss: (0.2554) |  Loss2: (0.0000) | Acc: (91.00%) (3618/3968)
Epoch: 94 | Batch_idx: 40 |  Loss: (0.2551) |  Loss2: (0.0000) | Acc: (91.00%) (4778/5248)
Epoch: 94 | Batch_idx: 50 |  Loss: (0.2527) |  Loss2: (0.0000) | Acc: (91.00%) (5948/6528)
Epoch: 94 | Batch_idx: 60 |  Loss: (0.2539) |  Loss2: (0.0000) | Acc: (91.00%) (7106/7808)
Epoch: 94 | Batch_idx: 70 |  Loss: (0.2533) |  Loss2: (0.0000) | Acc: (91.00%) (8276/9088)
Epoch: 94 | Batch_idx: 80 |  Loss: (0.2544) |  Loss2: (0.0000) | Acc: (90.00%) (9430/10368)
Epoch: 94 | Batch_idx: 90 |  Loss: (0.2524) |  Loss2: (0.0000) | Acc: (91.00%) (10612/11648)
Epoch: 94 | Batch_idx: 100 |  Loss: (0.2502) |  Loss2: (0.0000) | Acc: (91.00%) (11791/12928)
Epoch: 94 | Batch_idx: 110 |  Loss: (0.2519) |  Loss2: (0.0000) | Acc: (91.00%) (12950/14208)
Epoch: 94 | Batch_idx: 120 |  Loss: (0.2510) |  Loss2: (0.0000) | Acc: (91.00%) (14128/15488)
Epoch: 94 | Batch_idx: 130 |  Loss: (0.2498) |  Loss2: (0.0000) | Acc: (91.00%) (15300/16768)
Epoch: 94 | Batch_idx: 140 |  Loss: (0.2507) |  Loss2: (0.0000) | Acc: (91.00%) (16466/18048)
Epoch: 94 | Batch_idx: 150 |  Loss: (0.2477) |  Loss2: (0.0000) | Acc: (91.00%) (17658/19328)
Epoch: 94 | Batch_idx: 160 |  Loss: (0.2466) |  Loss2: (0.0000) | Acc: (91.00%) (18833/20608)
Epoch: 94 | Batch_idx: 170 |  Loss: (0.2468) |  Loss2: (0.0000) | Acc: (91.00%) (20009/21888)
Epoch: 94 | Batch_idx: 180 |  Loss: (0.2476) |  Loss2: (0.0000) | Acc: (91.00%) (21163/23168)
Epoch: 94 | Batch_idx: 190 |  Loss: (0.2480) |  Loss2: (0.0000) | Acc: (91.00%) (22334/24448)
Epoch: 94 | Batch_idx: 200 |  Loss: (0.2466) |  Loss2: (0.0000) | Acc: (91.00%) (23509/25728)
Epoch: 94 | Batch_idx: 210 |  Loss: (0.2464) |  Loss2: (0.0000) | Acc: (91.00%) (24691/27008)
Epoch: 94 | Batch_idx: 220 |  Loss: (0.2456) |  Loss2: (0.0000) | Acc: (91.00%) (25867/28288)
Epoch: 94 | Batch_idx: 230 |  Loss: (0.2452) |  Loss2: (0.0000) | Acc: (91.00%) (27043/29568)
Epoch: 94 | Batch_idx: 240 |  Loss: (0.2440) |  Loss2: (0.0000) | Acc: (91.00%) (28226/30848)
Epoch: 94 | Batch_idx: 250 |  Loss: (0.2434) |  Loss2: (0.0000) | Acc: (91.00%) (29407/32128)
Epoch: 94 | Batch_idx: 260 |  Loss: (0.2437) |  Loss2: (0.0000) | Acc: (91.00%) (30575/33408)
Epoch: 94 | Batch_idx: 270 |  Loss: (0.2429) |  Loss2: (0.0000) | Acc: (91.00%) (31755/34688)
Epoch: 94 | Batch_idx: 280 |  Loss: (0.2425) |  Loss2: (0.0000) | Acc: (91.00%) (32929/35968)
Epoch: 94 | Batch_idx: 290 |  Loss: (0.2419) |  Loss2: (0.0000) | Acc: (91.00%) (34110/37248)
Epoch: 94 | Batch_idx: 300 |  Loss: (0.2420) |  Loss2: (0.0000) | Acc: (91.00%) (35285/38528)
Epoch: 94 | Batch_idx: 310 |  Loss: (0.2416) |  Loss2: (0.0000) | Acc: (91.00%) (36455/39808)
Epoch: 94 | Batch_idx: 320 |  Loss: (0.2418) |  Loss2: (0.0000) | Acc: (91.00%) (37630/41088)
Epoch: 94 | Batch_idx: 330 |  Loss: (0.2416) |  Loss2: (0.0000) | Acc: (91.00%) (38806/42368)
Epoch: 94 | Batch_idx: 340 |  Loss: (0.2412) |  Loss2: (0.0000) | Acc: (91.00%) (39988/43648)
Epoch: 94 | Batch_idx: 350 |  Loss: (0.2408) |  Loss2: (0.0000) | Acc: (91.00%) (41171/44928)
Epoch: 94 | Batch_idx: 360 |  Loss: (0.2405) |  Loss2: (0.0000) | Acc: (91.00%) (42353/46208)
Epoch: 94 | Batch_idx: 370 |  Loss: (0.2405) |  Loss2: (0.0000) | Acc: (91.00%) (43534/47488)
Epoch: 94 | Batch_idx: 380 |  Loss: (0.2410) |  Loss2: (0.0000) | Acc: (91.00%) (44689/48768)
Epoch: 94 | Batch_idx: 390 |  Loss: (0.2403) |  Loss2: (0.0000) | Acc: (91.00%) (45828/50000)
# TEST : Loss: (0.3994) | Acc: (86.00%) (8695/10000)
percent tensor([0.5564, 0.5637, 0.5584, 0.5537, 0.5610, 0.5642, 0.5660, 0.5538, 0.5545,
        0.5602, 0.5611, 0.5636, 0.5593, 0.5506, 0.5675, 0.5586],
       device='cuda:0') torch.Size([16])
percent tensor([0.5106, 0.5086, 0.5053, 0.5095, 0.5065, 0.5167, 0.5061, 0.5057, 0.5062,
        0.5082, 0.5107, 0.5059, 0.5068, 0.5078, 0.5128, 0.5108],
       device='cuda:0') torch.Size([16])
percent tensor([0.5461, 0.4179, 0.6824, 0.6621, 0.6883, 0.6370, 0.5285, 0.6541, 0.5901,
        0.4925, 0.4375, 0.6008, 0.4547, 0.4862, 0.5073, 0.5783],
       device='cuda:0') torch.Size([16])
percent tensor([0.6775, 0.7157, 0.6068, 0.6313, 0.6170, 0.5429, 0.6804, 0.6272, 0.6797,
        0.7072, 0.7272, 0.6649, 0.6969, 0.7148, 0.6677, 0.6471],
       device='cuda:0') torch.Size([16])
percent tensor([0.6778, 0.5846, 0.7067, 0.6969, 0.7237, 0.7572, 0.6758, 0.7069, 0.6463,
        0.5814, 0.5587, 0.6064, 0.5774, 0.6147, 0.6736, 0.7034],
       device='cuda:0') torch.Size([16])
percent tensor([0.5198, 0.6128, 0.6809, 0.7296, 0.7204, 0.7306, 0.6296, 0.5453, 0.6605,
        0.5996, 0.6253, 0.6705, 0.5953, 0.6835, 0.5379, 0.5472],
       device='cuda:0') torch.Size([16])
percent tensor([0.5266, 0.6617, 0.6624, 0.7027, 0.6375, 0.6464, 0.6279, 0.5454, 0.6837,
        0.6428, 0.7082, 0.6944, 0.6426, 0.7112, 0.5648, 0.4860],
       device='cuda:0') torch.Size([16])
percent tensor([0.9995, 0.9996, 0.9996, 0.9998, 0.9997, 0.9985, 0.9998, 0.9998, 0.9997,
        0.9995, 0.9992, 0.9997, 0.9989, 0.9994, 0.9995, 0.9995],
       device='cuda:0') torch.Size([16])
Epoch: 95 | Batch_idx: 0 |  Loss: (0.2304) |  Loss2: (0.0000) | Acc: (92.00%) (118/128)
Epoch: 95 | Batch_idx: 10 |  Loss: (0.2563) |  Loss2: (0.0000) | Acc: (91.00%) (1286/1408)
Epoch: 95 | Batch_idx: 20 |  Loss: (0.2415) |  Loss2: (0.0000) | Acc: (92.00%) (2479/2688)
Epoch: 95 | Batch_idx: 30 |  Loss: (0.2393) |  Loss2: (0.0000) | Acc: (91.00%) (3650/3968)
Epoch: 95 | Batch_idx: 40 |  Loss: (0.2433) |  Loss2: (0.0000) | Acc: (91.00%) (4804/5248)
Epoch: 95 | Batch_idx: 50 |  Loss: (0.2389) |  Loss2: (0.0000) | Acc: (91.00%) (5988/6528)
Epoch: 95 | Batch_idx: 60 |  Loss: (0.2343) |  Loss2: (0.0000) | Acc: (91.00%) (7178/7808)
Epoch: 95 | Batch_idx: 70 |  Loss: (0.2320) |  Loss2: (0.0000) | Acc: (92.00%) (8365/9088)
Epoch: 95 | Batch_idx: 80 |  Loss: (0.2334) |  Loss2: (0.0000) | Acc: (91.00%) (9537/10368)
Epoch: 95 | Batch_idx: 90 |  Loss: (0.2332) |  Loss2: (0.0000) | Acc: (91.00%) (10716/11648)
Epoch: 95 | Batch_idx: 100 |  Loss: (0.2311) |  Loss2: (0.0000) | Acc: (92.00%) (11897/12928)
Epoch: 95 | Batch_idx: 110 |  Loss: (0.2327) |  Loss2: (0.0000) | Acc: (91.00%) (13062/14208)
Epoch: 95 | Batch_idx: 120 |  Loss: (0.2329) |  Loss2: (0.0000) | Acc: (91.00%) (14239/15488)
Epoch: 95 | Batch_idx: 130 |  Loss: (0.2349) |  Loss2: (0.0000) | Acc: (91.00%) (15402/16768)
Epoch: 95 | Batch_idx: 140 |  Loss: (0.2327) |  Loss2: (0.0000) | Acc: (91.00%) (16592/18048)
Epoch: 95 | Batch_idx: 150 |  Loss: (0.2328) |  Loss2: (0.0000) | Acc: (91.00%) (17770/19328)
Epoch: 95 | Batch_idx: 160 |  Loss: (0.2342) |  Loss2: (0.0000) | Acc: (91.00%) (18928/20608)
Epoch: 95 | Batch_idx: 170 |  Loss: (0.2334) |  Loss2: (0.0000) | Acc: (91.00%) (20100/21888)
Epoch: 95 | Batch_idx: 180 |  Loss: (0.2335) |  Loss2: (0.0000) | Acc: (91.00%) (21272/23168)
Epoch: 95 | Batch_idx: 190 |  Loss: (0.2344) |  Loss2: (0.0000) | Acc: (91.00%) (22449/24448)
Epoch: 95 | Batch_idx: 200 |  Loss: (0.2333) |  Loss2: (0.0000) | Acc: (91.00%) (23637/25728)
Epoch: 95 | Batch_idx: 210 |  Loss: (0.2334) |  Loss2: (0.0000) | Acc: (91.00%) (24822/27008)
Epoch: 95 | Batch_idx: 220 |  Loss: (0.2341) |  Loss2: (0.0000) | Acc: (91.00%) (25992/28288)
Epoch: 95 | Batch_idx: 230 |  Loss: (0.2338) |  Loss2: (0.0000) | Acc: (91.00%) (27165/29568)
Epoch: 95 | Batch_idx: 240 |  Loss: (0.2325) |  Loss2: (0.0000) | Acc: (91.00%) (28350/30848)
Epoch: 95 | Batch_idx: 250 |  Loss: (0.2326) |  Loss2: (0.0000) | Acc: (91.00%) (29528/32128)
Epoch: 95 | Batch_idx: 260 |  Loss: (0.2319) |  Loss2: (0.0000) | Acc: (91.00%) (30703/33408)
Epoch: 95 | Batch_idx: 270 |  Loss: (0.2316) |  Loss2: (0.0000) | Acc: (91.00%) (31883/34688)
Epoch: 95 | Batch_idx: 280 |  Loss: (0.2316) |  Loss2: (0.0000) | Acc: (91.00%) (33062/35968)
Epoch: 95 | Batch_idx: 290 |  Loss: (0.2320) |  Loss2: (0.0000) | Acc: (91.00%) (34234/37248)
Epoch: 95 | Batch_idx: 300 |  Loss: (0.2320) |  Loss2: (0.0000) | Acc: (91.00%) (35415/38528)
Epoch: 95 | Batch_idx: 310 |  Loss: (0.2315) |  Loss2: (0.0000) | Acc: (91.00%) (36603/39808)
Epoch: 95 | Batch_idx: 320 |  Loss: (0.2316) |  Loss2: (0.0000) | Acc: (91.00%) (37792/41088)
Epoch: 95 | Batch_idx: 330 |  Loss: (0.2322) |  Loss2: (0.0000) | Acc: (91.00%) (38957/42368)
Epoch: 95 | Batch_idx: 340 |  Loss: (0.2325) |  Loss2: (0.0000) | Acc: (91.00%) (40129/43648)
Epoch: 95 | Batch_idx: 350 |  Loss: (0.2320) |  Loss2: (0.0000) | Acc: (91.00%) (41315/44928)
Epoch: 95 | Batch_idx: 360 |  Loss: (0.2317) |  Loss2: (0.0000) | Acc: (91.00%) (42506/46208)
Epoch: 95 | Batch_idx: 370 |  Loss: (0.2319) |  Loss2: (0.0000) | Acc: (91.00%) (43679/47488)
Epoch: 95 | Batch_idx: 380 |  Loss: (0.2315) |  Loss2: (0.0000) | Acc: (91.00%) (44851/48768)
Epoch: 95 | Batch_idx: 390 |  Loss: (0.2320) |  Loss2: (0.0000) | Acc: (91.00%) (45986/50000)
=> saving checkpoint 'drive/app/torch/save_Schedule/checkpoint_095.pth.tar'
# TEST : Loss: (0.3889) | Acc: (87.00%) (8718/10000)
percent tensor([0.5544, 0.5607, 0.5566, 0.5525, 0.5589, 0.5637, 0.5630, 0.5511, 0.5514,
        0.5575, 0.5584, 0.5614, 0.5567, 0.5469, 0.5657, 0.5566],
       device='cuda:0') torch.Size([16])
percent tensor([0.5117, 0.5095, 0.5062, 0.5108, 0.5076, 0.5185, 0.5069, 0.5067, 0.5071,
        0.5089, 0.5117, 0.5065, 0.5074, 0.5087, 0.5142, 0.5120],
       device='cuda:0') torch.Size([16])
percent tensor([0.5314, 0.4108, 0.6734, 0.6514, 0.6817, 0.6255, 0.5196, 0.6450, 0.5764,
        0.4826, 0.4265, 0.5872, 0.4418, 0.4747, 0.4938, 0.5657],
       device='cuda:0') torch.Size([16])
percent tensor([0.6716, 0.7126, 0.6033, 0.6260, 0.6124, 0.5361, 0.6771, 0.6243, 0.6778,
        0.7030, 0.7221, 0.6606, 0.6917, 0.7155, 0.6601, 0.6407],
       device='cuda:0') torch.Size([16])
percent tensor([0.6919, 0.5941, 0.7196, 0.7107, 0.7354, 0.7729, 0.6850, 0.7180, 0.6591,
        0.5929, 0.5720, 0.6186, 0.5901, 0.6231, 0.6889, 0.7164],
       device='cuda:0') torch.Size([16])
percent tensor([0.5115, 0.6047, 0.6664, 0.7141, 0.7039, 0.7229, 0.6184, 0.5269, 0.6489,
        0.5881, 0.6181, 0.6561, 0.5826, 0.6803, 0.5272, 0.5348],
       device='cuda:0') torch.Size([16])
percent tensor([0.5342, 0.6729, 0.6647, 0.7040, 0.6399, 0.6598, 0.6339, 0.5492, 0.6901,
        0.6496, 0.7158, 0.7007, 0.6526, 0.7179, 0.5724, 0.4914],
       device='cuda:0') torch.Size([16])
percent tensor([0.9995, 0.9996, 0.9996, 0.9998, 0.9997, 0.9984, 0.9998, 0.9998, 0.9997,
        0.9995, 0.9992, 0.9998, 0.9989, 0.9993, 0.9996, 0.9995],
       device='cuda:0') torch.Size([16])
True Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=128, out_features=16, bias=False)
False Linear(in_features=16, out_features=2, bias=False)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=128, out_features=16, bias=False)
False Linear(in_features=16, out_features=2, bias=False)
True Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=256, out_features=32, bias=False)
False Linear(in_features=32, out_features=2, bias=False)
True Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=256, out_features=32, bias=False)
False Linear(in_features=32, out_features=2, bias=False)
True Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=512, out_features=64, bias=False)
False Linear(in_features=64, out_features=2, bias=False)
True Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=512, out_features=64, bias=False)
False Linear(in_features=64, out_features=2, bias=False)
True Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1024, out_features=128, bias=False)
False Linear(in_features=128, out_features=2, bias=False)
True Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1024, out_features=128, bias=False)
False Linear(in_features=128, out_features=2, bias=False)
True Linear(in_features=512, out_features=10, bias=True)
Epoch: 96 | Batch_idx: 0 |  Loss: (0.2079) |  Loss2: (0.0000) | Acc: (92.00%) (119/128)
Epoch: 96 | Batch_idx: 10 |  Loss: (0.1803) |  Loss2: (0.0000) | Acc: (93.00%) (1320/1408)
Epoch: 96 | Batch_idx: 20 |  Loss: (0.1910) |  Loss2: (0.0000) | Acc: (93.00%) (2510/2688)
Epoch: 96 | Batch_idx: 30 |  Loss: (0.1914) |  Loss2: (0.0000) | Acc: (93.00%) (3704/3968)
Epoch: 96 | Batch_idx: 40 |  Loss: (0.1951) |  Loss2: (0.0000) | Acc: (93.00%) (4886/5248)
Epoch: 96 | Batch_idx: 50 |  Loss: (0.2035) |  Loss2: (0.0000) | Acc: (92.00%) (6066/6528)
Epoch: 96 | Batch_idx: 60 |  Loss: (0.2109) |  Loss2: (0.0000) | Acc: (92.00%) (7236/7808)
Epoch: 96 | Batch_idx: 70 |  Loss: (0.2117) |  Loss2: (0.0000) | Acc: (92.00%) (8428/9088)
Epoch: 96 | Batch_idx: 80 |  Loss: (0.2129) |  Loss2: (0.0000) | Acc: (92.00%) (9606/10368)
Epoch: 96 | Batch_idx: 90 |  Loss: (0.2155) |  Loss2: (0.0000) | Acc: (92.00%) (10779/11648)
Epoch: 96 | Batch_idx: 100 |  Loss: (0.2190) |  Loss2: (0.0000) | Acc: (92.00%) (11947/12928)
Epoch: 96 | Batch_idx: 110 |  Loss: (0.2205) |  Loss2: (0.0000) | Acc: (92.00%) (13122/14208)
Epoch: 96 | Batch_idx: 120 |  Loss: (0.2227) |  Loss2: (0.0000) | Acc: (92.00%) (14296/15488)
Epoch: 96 | Batch_idx: 130 |  Loss: (0.2234) |  Loss2: (0.0000) | Acc: (92.00%) (15474/16768)
Epoch: 96 | Batch_idx: 140 |  Loss: (0.2233) |  Loss2: (0.0000) | Acc: (92.00%) (16656/18048)
Epoch: 96 | Batch_idx: 150 |  Loss: (0.2234) |  Loss2: (0.0000) | Acc: (92.00%) (17833/19328)
Epoch: 96 | Batch_idx: 160 |  Loss: (0.2238) |  Loss2: (0.0000) | Acc: (92.00%) (19010/20608)
Epoch: 96 | Batch_idx: 170 |  Loss: (0.2247) |  Loss2: (0.0000) | Acc: (92.00%) (20187/21888)
Epoch: 96 | Batch_idx: 180 |  Loss: (0.2241) |  Loss2: (0.0000) | Acc: (92.00%) (21377/23168)
Epoch: 96 | Batch_idx: 190 |  Loss: (0.2250) |  Loss2: (0.0000) | Acc: (92.00%) (22547/24448)
Epoch: 96 | Batch_idx: 200 |  Loss: (0.2251) |  Loss2: (0.0000) | Acc: (92.00%) (23730/25728)
Epoch: 96 | Batch_idx: 210 |  Loss: (0.2252) |  Loss2: (0.0000) | Acc: (92.00%) (24913/27008)
Epoch: 96 | Batch_idx: 220 |  Loss: (0.2250) |  Loss2: (0.0000) | Acc: (92.00%) (26099/28288)
Epoch: 96 | Batch_idx: 230 |  Loss: (0.2254) |  Loss2: (0.0000) | Acc: (92.00%) (27280/29568)
Epoch: 96 | Batch_idx: 240 |  Loss: (0.2246) |  Loss2: (0.0000) | Acc: (92.00%) (28477/30848)
Epoch: 96 | Batch_idx: 250 |  Loss: (0.2235) |  Loss2: (0.0000) | Acc: (92.00%) (29665/32128)
Epoch: 96 | Batch_idx: 260 |  Loss: (0.2236) |  Loss2: (0.0000) | Acc: (92.00%) (30839/33408)
Epoch: 96 | Batch_idx: 270 |  Loss: (0.2236) |  Loss2: (0.0000) | Acc: (92.00%) (32023/34688)
Epoch: 96 | Batch_idx: 280 |  Loss: (0.2247) |  Loss2: (0.0000) | Acc: (92.00%) (33197/35968)
Epoch: 96 | Batch_idx: 290 |  Loss: (0.2244) |  Loss2: (0.0000) | Acc: (92.00%) (34383/37248)
Epoch: 96 | Batch_idx: 300 |  Loss: (0.2244) |  Loss2: (0.0000) | Acc: (92.00%) (35561/38528)
Epoch: 96 | Batch_idx: 310 |  Loss: (0.2251) |  Loss2: (0.0000) | Acc: (92.00%) (36727/39808)
Epoch: 96 | Batch_idx: 320 |  Loss: (0.2249) |  Loss2: (0.0000) | Acc: (92.00%) (37917/41088)
Epoch: 96 | Batch_idx: 330 |  Loss: (0.2247) |  Loss2: (0.0000) | Acc: (92.00%) (39106/42368)
Epoch: 96 | Batch_idx: 340 |  Loss: (0.2250) |  Loss2: (0.0000) | Acc: (92.00%) (40277/43648)
Epoch: 96 | Batch_idx: 350 |  Loss: (0.2252) |  Loss2: (0.0000) | Acc: (92.00%) (41459/44928)
Epoch: 96 | Batch_idx: 360 |  Loss: (0.2254) |  Loss2: (0.0000) | Acc: (92.00%) (42641/46208)
Epoch: 96 | Batch_idx: 370 |  Loss: (0.2259) |  Loss2: (0.0000) | Acc: (92.00%) (43819/47488)
Epoch: 96 | Batch_idx: 380 |  Loss: (0.2258) |  Loss2: (0.0000) | Acc: (92.00%) (45001/48768)
Epoch: 96 | Batch_idx: 390 |  Loss: (0.2255) |  Loss2: (0.0000) | Acc: (92.00%) (46142/50000)
# TEST : Loss: (0.4311) | Acc: (86.00%) (8615/10000)
percent tensor([0.5529, 0.5617, 0.5539, 0.5525, 0.5568, 0.5624, 0.5624, 0.5500, 0.5499,
        0.5571, 0.5570, 0.5592, 0.5554, 0.5497, 0.5652, 0.5558],
       device='cuda:0') torch.Size([16])
percent tensor([0.5116, 0.5105, 0.5064, 0.5105, 0.5065, 0.5179, 0.5075, 0.5068, 0.5068,
        0.5090, 0.5119, 0.5064, 0.5076, 0.5099, 0.5141, 0.5121],
       device='cuda:0') torch.Size([16])
percent tensor([0.5198, 0.4076, 0.6858, 0.6506, 0.6892, 0.6222, 0.5201, 0.6564, 0.5730,
        0.4813, 0.4206, 0.5970, 0.4351, 0.4526, 0.4937, 0.5584],
       device='cuda:0') torch.Size([16])
percent tensor([0.6806, 0.7209, 0.5901, 0.6282, 0.6056, 0.5432, 0.6824, 0.6275, 0.6857,
        0.7082, 0.7362, 0.6623, 0.7017, 0.7267, 0.6725, 0.6506],
       device='cuda:0') torch.Size([16])
percent tensor([0.6896, 0.5908, 0.7096, 0.7090, 0.7230, 0.7669, 0.6718, 0.7091, 0.6513,
        0.5774, 0.5547, 0.6118, 0.5785, 0.6275, 0.6815, 0.7140],
       device='cuda:0') torch.Size([16])
percent tensor([0.5349, 0.6163, 0.6720, 0.7110, 0.7065, 0.7332, 0.6219, 0.5509, 0.6619,
        0.5817, 0.6314, 0.6493, 0.5895, 0.7006, 0.5190, 0.5513],
       device='cuda:0') torch.Size([16])
percent tensor([0.5335, 0.6716, 0.6749, 0.6873, 0.6449, 0.6555, 0.6314, 0.5737, 0.6949,
        0.6628, 0.7162, 0.6967, 0.6384, 0.7189, 0.5659, 0.4868],
       device='cuda:0') torch.Size([16])
percent tensor([0.9996, 0.9995, 0.9997, 0.9999, 0.9999, 0.9986, 0.9996, 0.9997, 0.9995,
        0.9997, 0.9994, 0.9998, 0.9992, 0.9995, 0.9996, 0.9997],
       device='cuda:0') torch.Size([16])
Epoch: 97 | Batch_idx: 0 |  Loss: (0.1908) |  Loss2: (0.0000) | Acc: (92.00%) (118/128)
Epoch: 97 | Batch_idx: 10 |  Loss: (0.2072) |  Loss2: (0.0000) | Acc: (92.00%) (1305/1408)
Epoch: 97 | Batch_idx: 20 |  Loss: (0.2026) |  Loss2: (0.0000) | Acc: (93.00%) (2500/2688)
Epoch: 97 | Batch_idx: 30 |  Loss: (0.1984) |  Loss2: (0.0000) | Acc: (93.00%) (3695/3968)
Epoch: 97 | Batch_idx: 40 |  Loss: (0.2045) |  Loss2: (0.0000) | Acc: (92.00%) (4875/5248)
Epoch: 97 | Batch_idx: 50 |  Loss: (0.2063) |  Loss2: (0.0000) | Acc: (92.00%) (6056/6528)
Epoch: 97 | Batch_idx: 60 |  Loss: (0.2079) |  Loss2: (0.0000) | Acc: (92.00%) (7240/7808)
Epoch: 97 | Batch_idx: 70 |  Loss: (0.2107) |  Loss2: (0.0000) | Acc: (92.00%) (8417/9088)
Epoch: 97 | Batch_idx: 80 |  Loss: (0.2154) |  Loss2: (0.0000) | Acc: (92.00%) (9576/10368)
Epoch: 97 | Batch_idx: 90 |  Loss: (0.2175) |  Loss2: (0.0000) | Acc: (92.00%) (10750/11648)
Epoch: 97 | Batch_idx: 100 |  Loss: (0.2188) |  Loss2: (0.0000) | Acc: (92.00%) (11933/12928)
Epoch: 97 | Batch_idx: 110 |  Loss: (0.2181) |  Loss2: (0.0000) | Acc: (92.00%) (13112/14208)
Epoch: 97 | Batch_idx: 120 |  Loss: (0.2174) |  Loss2: (0.0000) | Acc: (92.00%) (14303/15488)
Epoch: 97 | Batch_idx: 130 |  Loss: (0.2165) |  Loss2: (0.0000) | Acc: (92.00%) (15491/16768)
Epoch: 97 | Batch_idx: 140 |  Loss: (0.2168) |  Loss2: (0.0000) | Acc: (92.00%) (16662/18048)
Epoch: 97 | Batch_idx: 150 |  Loss: (0.2167) |  Loss2: (0.0000) | Acc: (92.00%) (17843/19328)
Epoch: 97 | Batch_idx: 160 |  Loss: (0.2159) |  Loss2: (0.0000) | Acc: (92.00%) (19034/20608)
Epoch: 97 | Batch_idx: 170 |  Loss: (0.2157) |  Loss2: (0.0000) | Acc: (92.00%) (20212/21888)
Epoch: 97 | Batch_idx: 180 |  Loss: (0.2155) |  Loss2: (0.0000) | Acc: (92.00%) (21406/23168)
Epoch: 97 | Batch_idx: 190 |  Loss: (0.2166) |  Loss2: (0.0000) | Acc: (92.00%) (22574/24448)
Epoch: 97 | Batch_idx: 200 |  Loss: (0.2172) |  Loss2: (0.0000) | Acc: (92.00%) (23763/25728)
Epoch: 97 | Batch_idx: 210 |  Loss: (0.2182) |  Loss2: (0.0000) | Acc: (92.00%) (24939/27008)
Epoch: 97 | Batch_idx: 220 |  Loss: (0.2177) |  Loss2: (0.0000) | Acc: (92.00%) (26125/28288)
Epoch: 97 | Batch_idx: 230 |  Loss: (0.2189) |  Loss2: (0.0000) | Acc: (92.00%) (27298/29568)
Epoch: 97 | Batch_idx: 240 |  Loss: (0.2201) |  Loss2: (0.0000) | Acc: (92.00%) (28465/30848)
Epoch: 97 | Batch_idx: 250 |  Loss: (0.2215) |  Loss2: (0.0000) | Acc: (92.00%) (29632/32128)
Epoch: 97 | Batch_idx: 260 |  Loss: (0.2209) |  Loss2: (0.0000) | Acc: (92.00%) (30816/33408)
Epoch: 97 | Batch_idx: 270 |  Loss: (0.2214) |  Loss2: (0.0000) | Acc: (92.00%) (31988/34688)
Epoch: 97 | Batch_idx: 280 |  Loss: (0.2211) |  Loss2: (0.0000) | Acc: (92.00%) (33183/35968)
Epoch: 97 | Batch_idx: 290 |  Loss: (0.2214) |  Loss2: (0.0000) | Acc: (92.00%) (34366/37248)
Epoch: 97 | Batch_idx: 300 |  Loss: (0.2220) |  Loss2: (0.0000) | Acc: (92.00%) (35543/38528)
Epoch: 97 | Batch_idx: 310 |  Loss: (0.2219) |  Loss2: (0.0000) | Acc: (92.00%) (36722/39808)
Epoch: 97 | Batch_idx: 320 |  Loss: (0.2222) |  Loss2: (0.0000) | Acc: (92.00%) (37904/41088)
Epoch: 97 | Batch_idx: 330 |  Loss: (0.2223) |  Loss2: (0.0000) | Acc: (92.00%) (39076/42368)
Epoch: 97 | Batch_idx: 340 |  Loss: (0.2222) |  Loss2: (0.0000) | Acc: (92.00%) (40262/43648)
Epoch: 97 | Batch_idx: 350 |  Loss: (0.2228) |  Loss2: (0.0000) | Acc: (92.00%) (41431/44928)
Epoch: 97 | Batch_idx: 360 |  Loss: (0.2229) |  Loss2: (0.0000) | Acc: (92.00%) (42611/46208)
Epoch: 97 | Batch_idx: 370 |  Loss: (0.2236) |  Loss2: (0.0000) | Acc: (92.00%) (43782/47488)
Epoch: 97 | Batch_idx: 380 |  Loss: (0.2225) |  Loss2: (0.0000) | Acc: (92.00%) (44985/48768)
Epoch: 97 | Batch_idx: 390 |  Loss: (0.2226) |  Loss2: (0.0000) | Acc: (92.00%) (46126/50000)
# TEST : Loss: (0.4399) | Acc: (86.00%) (8608/10000)
percent tensor([0.5530, 0.5612, 0.5551, 0.5531, 0.5572, 0.5631, 0.5624, 0.5499, 0.5493,
        0.5573, 0.5570, 0.5601, 0.5549, 0.5482, 0.5658, 0.5560],
       device='cuda:0') torch.Size([16])
percent tensor([0.5118, 0.5102, 0.5076, 0.5104, 0.5070, 0.5181, 0.5078, 0.5073, 0.5071,
        0.5088, 0.5120, 0.5073, 0.5077, 0.5105, 0.5139, 0.5121],
       device='cuda:0') torch.Size([16])
percent tensor([0.5395, 0.4231, 0.6818, 0.6612, 0.6891, 0.6378, 0.5294, 0.6529, 0.5786,
        0.4925, 0.4394, 0.6012, 0.4533, 0.4639, 0.5119, 0.5821],
       device='cuda:0') torch.Size([16])
percent tensor([0.6747, 0.7108, 0.5957, 0.6297, 0.6072, 0.5304, 0.6784, 0.6254, 0.6875,
        0.7040, 0.7305, 0.6633, 0.6970, 0.7252, 0.6624, 0.6399],
       device='cuda:0') torch.Size([16])
percent tensor([0.6956, 0.5896, 0.7197, 0.7124, 0.7324, 0.7636, 0.6673, 0.7192, 0.6492,
        0.5882, 0.5553, 0.6231, 0.5848, 0.5983, 0.6822, 0.7150],
       device='cuda:0') torch.Size([16])
percent tensor([0.5404, 0.6193, 0.6611, 0.7124, 0.7056, 0.7280, 0.6261, 0.5347, 0.6499,
        0.5995, 0.6454, 0.6423, 0.6054, 0.6790, 0.5042, 0.5615],
       device='cuda:0') torch.Size([16])
percent tensor([0.5195, 0.6577, 0.6321, 0.6924, 0.6432, 0.6552, 0.6421, 0.5398, 0.6618,
        0.6433, 0.7147, 0.6456, 0.6327, 0.7159, 0.5499, 0.4979],
       device='cuda:0') torch.Size([16])
percent tensor([0.9996, 0.9993, 0.9997, 0.9999, 0.9999, 0.9987, 0.9998, 0.9997, 0.9996,
        0.9997, 0.9991, 0.9998, 0.9992, 0.9992, 0.9998, 0.9997],
       device='cuda:0') torch.Size([16])
Epoch: 98 | Batch_idx: 0 |  Loss: (0.2807) |  Loss2: (0.0000) | Acc: (89.00%) (114/128)
Epoch: 98 | Batch_idx: 10 |  Loss: (0.2271) |  Loss2: (0.0000) | Acc: (92.00%) (1300/1408)
Epoch: 98 | Batch_idx: 20 |  Loss: (0.2182) |  Loss2: (0.0000) | Acc: (92.00%) (2483/2688)
Epoch: 98 | Batch_idx: 30 |  Loss: (0.2113) |  Loss2: (0.0000) | Acc: (92.00%) (3674/3968)
Epoch: 98 | Batch_idx: 40 |  Loss: (0.2109) |  Loss2: (0.0000) | Acc: (92.00%) (4863/5248)
Epoch: 98 | Batch_idx: 50 |  Loss: (0.2116) |  Loss2: (0.0000) | Acc: (92.00%) (6047/6528)
Epoch: 98 | Batch_idx: 60 |  Loss: (0.2104) |  Loss2: (0.0000) | Acc: (92.00%) (7232/7808)
Epoch: 98 | Batch_idx: 70 |  Loss: (0.2095) |  Loss2: (0.0000) | Acc: (92.00%) (8431/9088)
Epoch: 98 | Batch_idx: 80 |  Loss: (0.2103) |  Loss2: (0.0000) | Acc: (92.00%) (9612/10368)
Epoch: 98 | Batch_idx: 90 |  Loss: (0.2083) |  Loss2: (0.0000) | Acc: (92.00%) (10802/11648)
Epoch: 98 | Batch_idx: 100 |  Loss: (0.2093) |  Loss2: (0.0000) | Acc: (92.00%) (11993/12928)
Epoch: 98 | Batch_idx: 110 |  Loss: (0.2074) |  Loss2: (0.0000) | Acc: (92.00%) (13191/14208)
Epoch: 98 | Batch_idx: 120 |  Loss: (0.2087) |  Loss2: (0.0000) | Acc: (92.00%) (14373/15488)
Epoch: 98 | Batch_idx: 130 |  Loss: (0.2090) |  Loss2: (0.0000) | Acc: (92.00%) (15559/16768)
Epoch: 98 | Batch_idx: 140 |  Loss: (0.2094) |  Loss2: (0.0000) | Acc: (92.00%) (16741/18048)
Epoch: 98 | Batch_idx: 150 |  Loss: (0.2096) |  Loss2: (0.0000) | Acc: (92.00%) (17921/19328)
Epoch: 98 | Batch_idx: 160 |  Loss: (0.2095) |  Loss2: (0.0000) | Acc: (92.00%) (19111/20608)
Epoch: 98 | Batch_idx: 170 |  Loss: (0.2091) |  Loss2: (0.0000) | Acc: (92.00%) (20302/21888)
Epoch: 98 | Batch_idx: 180 |  Loss: (0.2090) |  Loss2: (0.0000) | Acc: (92.00%) (21496/23168)
Epoch: 98 | Batch_idx: 190 |  Loss: (0.2100) |  Loss2: (0.0000) | Acc: (92.00%) (22672/24448)
Epoch: 98 | Batch_idx: 200 |  Loss: (0.2098) |  Loss2: (0.0000) | Acc: (92.00%) (23859/25728)
Epoch: 98 | Batch_idx: 210 |  Loss: (0.2104) |  Loss2: (0.0000) | Acc: (92.00%) (25039/27008)
Epoch: 98 | Batch_idx: 220 |  Loss: (0.2106) |  Loss2: (0.0000) | Acc: (92.00%) (26219/28288)
Epoch: 98 | Batch_idx: 230 |  Loss: (0.2129) |  Loss2: (0.0000) | Acc: (92.00%) (27385/29568)
Epoch: 98 | Batch_idx: 240 |  Loss: (0.2126) |  Loss2: (0.0000) | Acc: (92.00%) (28574/30848)
Epoch: 98 | Batch_idx: 250 |  Loss: (0.2125) |  Loss2: (0.0000) | Acc: (92.00%) (29770/32128)
Epoch: 98 | Batch_idx: 260 |  Loss: (0.2125) |  Loss2: (0.0000) | Acc: (92.00%) (30954/33408)
Epoch: 98 | Batch_idx: 270 |  Loss: (0.2136) |  Loss2: (0.0000) | Acc: (92.00%) (32118/34688)
Epoch: 98 | Batch_idx: 280 |  Loss: (0.2141) |  Loss2: (0.0000) | Acc: (92.00%) (33293/35968)
Epoch: 98 | Batch_idx: 290 |  Loss: (0.2139) |  Loss2: (0.0000) | Acc: (92.00%) (34484/37248)
Epoch: 98 | Batch_idx: 300 |  Loss: (0.2131) |  Loss2: (0.0000) | Acc: (92.00%) (35679/38528)
Epoch: 98 | Batch_idx: 310 |  Loss: (0.2130) |  Loss2: (0.0000) | Acc: (92.00%) (36866/39808)
Epoch: 98 | Batch_idx: 320 |  Loss: (0.2124) |  Loss2: (0.0000) | Acc: (92.00%) (38053/41088)
Epoch: 98 | Batch_idx: 330 |  Loss: (0.2126) |  Loss2: (0.0000) | Acc: (92.00%) (39233/42368)
Epoch: 98 | Batch_idx: 340 |  Loss: (0.2129) |  Loss2: (0.0000) | Acc: (92.00%) (40423/43648)
Epoch: 98 | Batch_idx: 350 |  Loss: (0.2131) |  Loss2: (0.0000) | Acc: (92.00%) (41610/44928)
Epoch: 98 | Batch_idx: 360 |  Loss: (0.2123) |  Loss2: (0.0000) | Acc: (92.00%) (42812/46208)
Epoch: 98 | Batch_idx: 370 |  Loss: (0.2117) |  Loss2: (0.0000) | Acc: (92.00%) (44009/47488)
Epoch: 98 | Batch_idx: 380 |  Loss: (0.2127) |  Loss2: (0.0000) | Acc: (92.00%) (45181/48768)
Epoch: 98 | Batch_idx: 390 |  Loss: (0.2127) |  Loss2: (0.0000) | Acc: (92.00%) (46325/50000)
# TEST : Loss: (0.4361) | Acc: (86.00%) (8631/10000)
percent tensor([0.5537, 0.5624, 0.5537, 0.5523, 0.5569, 0.5639, 0.5630, 0.5496, 0.5505,
        0.5572, 0.5582, 0.5583, 0.5555, 0.5492, 0.5664, 0.5568],
       device='cuda:0') torch.Size([16])
percent tensor([0.5117, 0.5104, 0.5073, 0.5111, 0.5071, 0.5184, 0.5076, 0.5073, 0.5068,
        0.5089, 0.5119, 0.5070, 0.5078, 0.5098, 0.5140, 0.5121],
       device='cuda:0') torch.Size([16])
percent tensor([0.5375, 0.4145, 0.6881, 0.6635, 0.6849, 0.6286, 0.5159, 0.6543, 0.5683,
        0.4920, 0.4253, 0.6032, 0.4459, 0.4500, 0.5042, 0.5741],
       device='cuda:0') torch.Size([16])
percent tensor([0.6818, 0.7101, 0.5991, 0.6313, 0.6196, 0.5357, 0.6785, 0.6276, 0.6844,
        0.7070, 0.7305, 0.6649, 0.6986, 0.7158, 0.6651, 0.6483],
       device='cuda:0') torch.Size([16])
percent tensor([0.6857, 0.5853, 0.7166, 0.7128, 0.7333, 0.7594, 0.6665, 0.7104, 0.6594,
        0.5819, 0.5595, 0.6227, 0.5828, 0.6061, 0.6806, 0.6996],
       device='cuda:0') torch.Size([16])
percent tensor([0.5426, 0.6347, 0.6744, 0.7084, 0.7031, 0.7229, 0.6174, 0.5329, 0.6529,
        0.6030, 0.6506, 0.6509, 0.6119, 0.6745, 0.5295, 0.5534],
       device='cuda:0') torch.Size([16])
percent tensor([0.5444, 0.7109, 0.6569, 0.6795, 0.6255, 0.6515, 0.6566, 0.5535, 0.6732,
        0.6736, 0.7308, 0.6867, 0.6542, 0.7438, 0.5781, 0.5013],
       device='cuda:0') torch.Size([16])
percent tensor([0.9997, 0.9996, 0.9998, 0.9999, 0.9999, 0.9993, 0.9995, 0.9997, 0.9997,
        0.9997, 0.9993, 0.9999, 0.9992, 0.9995, 0.9997, 0.9996],
       device='cuda:0') torch.Size([16])
False Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=128, out_features=16, bias=False)
True Linear(in_features=16, out_features=2, bias=False)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=128, out_features=16, bias=False)
True Linear(in_features=16, out_features=2, bias=False)
False Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=256, out_features=32, bias=False)
True Linear(in_features=32, out_features=2, bias=False)
False Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=256, out_features=32, bias=False)
True Linear(in_features=32, out_features=2, bias=False)
False Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=512, out_features=64, bias=False)
True Linear(in_features=64, out_features=2, bias=False)
False Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=512, out_features=64, bias=False)
True Linear(in_features=64, out_features=2, bias=False)
False Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1024, out_features=128, bias=False)
True Linear(in_features=128, out_features=2, bias=False)
False Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1024, out_features=128, bias=False)
True Linear(in_features=128, out_features=2, bias=False)
False Linear(in_features=512, out_features=10, bias=True)
Epoch: 99 | Batch_idx: 0 |  Loss: (0.1704) |  Loss2: (0.0000) | Acc: (96.00%) (124/128)
Epoch: 99 | Batch_idx: 10 |  Loss: (0.2265) |  Loss2: (0.0000) | Acc: (92.00%) (1298/1408)
Epoch: 99 | Batch_idx: 20 |  Loss: (0.2328) |  Loss2: (0.0000) | Acc: (92.00%) (2475/2688)
Epoch: 99 | Batch_idx: 30 |  Loss: (0.2376) |  Loss2: (0.0000) | Acc: (91.00%) (3640/3968)
Epoch: 99 | Batch_idx: 40 |  Loss: (0.2435) |  Loss2: (0.0000) | Acc: (91.00%) (4804/5248)
Epoch: 99 | Batch_idx: 50 |  Loss: (0.2463) |  Loss2: (0.0000) | Acc: (91.00%) (5967/6528)
Epoch: 99 | Batch_idx: 60 |  Loss: (0.2500) |  Loss2: (0.0000) | Acc: (91.00%) (7120/7808)
Epoch: 99 | Batch_idx: 70 |  Loss: (0.2545) |  Loss2: (0.0000) | Acc: (90.00%) (8269/9088)
Epoch: 99 | Batch_idx: 80 |  Loss: (0.2548) |  Loss2: (0.0000) | Acc: (90.00%) (9431/10368)
Epoch: 99 | Batch_idx: 90 |  Loss: (0.2550) |  Loss2: (0.0000) | Acc: (90.00%) (10598/11648)
Epoch: 99 | Batch_idx: 100 |  Loss: (0.2561) |  Loss2: (0.0000) | Acc: (90.00%) (11759/12928)
Epoch: 99 | Batch_idx: 110 |  Loss: (0.2575) |  Loss2: (0.0000) | Acc: (90.00%) (12915/14208)
Epoch: 99 | Batch_idx: 120 |  Loss: (0.2580) |  Loss2: (0.0000) | Acc: (90.00%) (14075/15488)
Epoch: 99 | Batch_idx: 130 |  Loss: (0.2599) |  Loss2: (0.0000) | Acc: (90.00%) (15215/16768)
Epoch: 99 | Batch_idx: 140 |  Loss: (0.2581) |  Loss2: (0.0000) | Acc: (90.00%) (16398/18048)
Epoch: 99 | Batch_idx: 150 |  Loss: (0.2574) |  Loss2: (0.0000) | Acc: (90.00%) (17571/19328)
Epoch: 99 | Batch_idx: 160 |  Loss: (0.2580) |  Loss2: (0.0000) | Acc: (90.00%) (18727/20608)
Epoch: 99 | Batch_idx: 170 |  Loss: (0.2570) |  Loss2: (0.0000) | Acc: (90.00%) (19899/21888)
Epoch: 99 | Batch_idx: 180 |  Loss: (0.2570) |  Loss2: (0.0000) | Acc: (90.00%) (21067/23168)
Epoch: 99 | Batch_idx: 190 |  Loss: (0.2553) |  Loss2: (0.0000) | Acc: (91.00%) (22249/24448)
Epoch: 99 | Batch_idx: 200 |  Loss: (0.2549) |  Loss2: (0.0000) | Acc: (90.00%) (23412/25728)
Epoch: 99 | Batch_idx: 210 |  Loss: (0.2552) |  Loss2: (0.0000) | Acc: (90.00%) (24573/27008)
Epoch: 99 | Batch_idx: 220 |  Loss: (0.2550) |  Loss2: (0.0000) | Acc: (91.00%) (25743/28288)
Epoch: 99 | Batch_idx: 230 |  Loss: (0.2545) |  Loss2: (0.0000) | Acc: (91.00%) (26914/29568)
Epoch: 99 | Batch_idx: 240 |  Loss: (0.2536) |  Loss2: (0.0000) | Acc: (91.00%) (28084/30848)
Epoch: 99 | Batch_idx: 250 |  Loss: (0.2532) |  Loss2: (0.0000) | Acc: (91.00%) (29243/32128)
Epoch: 99 | Batch_idx: 260 |  Loss: (0.2533) |  Loss2: (0.0000) | Acc: (91.00%) (30408/33408)
Epoch: 99 | Batch_idx: 270 |  Loss: (0.2530) |  Loss2: (0.0000) | Acc: (91.00%) (31583/34688)
Epoch: 99 | Batch_idx: 280 |  Loss: (0.2529) |  Loss2: (0.0000) | Acc: (91.00%) (32762/35968)
Epoch: 99 | Batch_idx: 290 |  Loss: (0.2530) |  Loss2: (0.0000) | Acc: (91.00%) (33929/37248)
Epoch: 99 | Batch_idx: 300 |  Loss: (0.2529) |  Loss2: (0.0000) | Acc: (91.00%) (35104/38528)
Epoch: 99 | Batch_idx: 310 |  Loss: (0.2520) |  Loss2: (0.0000) | Acc: (91.00%) (36278/39808)
Epoch: 99 | Batch_idx: 320 |  Loss: (0.2520) |  Loss2: (0.0000) | Acc: (91.00%) (37448/41088)
Epoch: 99 | Batch_idx: 330 |  Loss: (0.2505) |  Loss2: (0.0000) | Acc: (91.00%) (38640/42368)
Epoch: 99 | Batch_idx: 340 |  Loss: (0.2495) |  Loss2: (0.0000) | Acc: (91.00%) (39836/43648)
Epoch: 99 | Batch_idx: 350 |  Loss: (0.2489) |  Loss2: (0.0000) | Acc: (91.00%) (41018/44928)
Epoch: 99 | Batch_idx: 360 |  Loss: (0.2490) |  Loss2: (0.0000) | Acc: (91.00%) (42187/46208)
Epoch: 99 | Batch_idx: 370 |  Loss: (0.2474) |  Loss2: (0.0000) | Acc: (91.00%) (43383/47488)
Epoch: 99 | Batch_idx: 380 |  Loss: (0.2469) |  Loss2: (0.0000) | Acc: (91.00%) (44561/48768)
Epoch: 99 | Batch_idx: 390 |  Loss: (0.2472) |  Loss2: (0.0000) | Acc: (91.00%) (45681/50000)
# TEST : Loss: (0.4134) | Acc: (86.00%) (8676/10000)
percent tensor([0.5559, 0.5654, 0.5555, 0.5537, 0.5588, 0.5655, 0.5659, 0.5513, 0.5532,
        0.5597, 0.5611, 0.5598, 0.5579, 0.5528, 0.5683, 0.5588],
       device='cuda:0') torch.Size([16])
percent tensor([0.5117, 0.5108, 0.5074, 0.5108, 0.5065, 0.5183, 0.5076, 0.5070, 0.5067,
        0.5089, 0.5121, 0.5072, 0.5078, 0.5096, 0.5140, 0.5121],
       device='cuda:0') torch.Size([16])
percent tensor([0.5384, 0.4292, 0.6794, 0.6567, 0.6732, 0.6286, 0.5203, 0.6501, 0.5698,
        0.5046, 0.4356, 0.6006, 0.4602, 0.4647, 0.5127, 0.5757],
       device='cuda:0') torch.Size([16])
percent tensor([0.6626, 0.6940, 0.5780, 0.6097, 0.6015, 0.5244, 0.6601, 0.6013, 0.6613,
        0.6886, 0.7148, 0.6477, 0.6781, 0.7037, 0.6447, 0.6288],
       device='cuda:0') torch.Size([16])
percent tensor([0.6983, 0.6091, 0.7114, 0.7173, 0.7221, 0.7615, 0.6809, 0.7029, 0.6798,
        0.5986, 0.5817, 0.6237, 0.6070, 0.6334, 0.6870, 0.7051],
       device='cuda:0') torch.Size([16])
percent tensor([0.5546, 0.6433, 0.7153, 0.7422, 0.7392, 0.7541, 0.6346, 0.5711, 0.6886,
        0.6214, 0.6672, 0.6649, 0.6279, 0.6847, 0.5467, 0.5839],
       device='cuda:0') torch.Size([16])
percent tensor([0.4825, 0.6477, 0.6576, 0.6674, 0.6295, 0.6077, 0.6024, 0.5468, 0.6117,
        0.6038, 0.6653, 0.6585, 0.5797, 0.6716, 0.5356, 0.4684],
       device='cuda:0') torch.Size([16])
percent tensor([0.9997, 0.9995, 0.9998, 0.9999, 0.9999, 0.9992, 0.9997, 0.9997, 0.9997,
        0.9998, 0.9993, 0.9999, 0.9990, 0.9993, 0.9997, 0.9996],
       device='cuda:0') torch.Size([16])
Epoch: 100 | Batch_idx: 0 |  Loss: (0.2995) |  Loss2: (0.0000) | Acc: (86.00%) (111/128)
Epoch: 100 | Batch_idx: 10 |  Loss: (0.2329) |  Loss2: (0.0000) | Acc: (91.00%) (1292/1408)
Epoch: 100 | Batch_idx: 20 |  Loss: (0.2204) |  Loss2: (0.0000) | Acc: (92.00%) (2476/2688)
Epoch: 100 | Batch_idx: 30 |  Loss: (0.2234) |  Loss2: (0.0000) | Acc: (92.00%) (3656/3968)
Epoch: 100 | Batch_idx: 40 |  Loss: (0.2237) |  Loss2: (0.0000) | Acc: (92.00%) (4835/5248)
Epoch: 100 | Batch_idx: 50 |  Loss: (0.2240) |  Loss2: (0.0000) | Acc: (92.00%) (6014/6528)
Epoch: 100 | Batch_idx: 60 |  Loss: (0.2228) |  Loss2: (0.0000) | Acc: (92.00%) (7205/7808)
Epoch: 100 | Batch_idx: 70 |  Loss: (0.2211) |  Loss2: (0.0000) | Acc: (92.00%) (8393/9088)
Epoch: 100 | Batch_idx: 80 |  Loss: (0.2251) |  Loss2: (0.0000) | Acc: (92.00%) (9555/10368)
Epoch: 100 | Batch_idx: 90 |  Loss: (0.2252) |  Loss2: (0.0000) | Acc: (92.00%) (10733/11648)
Epoch: 100 | Batch_idx: 100 |  Loss: (0.2258) |  Loss2: (0.0000) | Acc: (92.00%) (11912/12928)
Epoch: 100 | Batch_idx: 110 |  Loss: (0.2272) |  Loss2: (0.0000) | Acc: (92.00%) (13080/14208)
Epoch: 100 | Batch_idx: 120 |  Loss: (0.2275) |  Loss2: (0.0000) | Acc: (92.00%) (14263/15488)
Epoch: 100 | Batch_idx: 130 |  Loss: (0.2292) |  Loss2: (0.0000) | Acc: (92.00%) (15435/16768)
Epoch: 100 | Batch_idx: 140 |  Loss: (0.2278) |  Loss2: (0.0000) | Acc: (92.00%) (16623/18048)
Epoch: 100 | Batch_idx: 150 |  Loss: (0.2273) |  Loss2: (0.0000) | Acc: (92.00%) (17817/19328)
Epoch: 100 | Batch_idx: 160 |  Loss: (0.2274) |  Loss2: (0.0000) | Acc: (92.00%) (18988/20608)
Epoch: 100 | Batch_idx: 170 |  Loss: (0.2274) |  Loss2: (0.0000) | Acc: (92.00%) (20170/21888)
Epoch: 100 | Batch_idx: 180 |  Loss: (0.2270) |  Loss2: (0.0000) | Acc: (92.00%) (21337/23168)
Epoch: 100 | Batch_idx: 190 |  Loss: (0.2265) |  Loss2: (0.0000) | Acc: (92.00%) (22523/24448)
Epoch: 100 | Batch_idx: 200 |  Loss: (0.2262) |  Loss2: (0.0000) | Acc: (92.00%) (23711/25728)
Epoch: 100 | Batch_idx: 210 |  Loss: (0.2263) |  Loss2: (0.0000) | Acc: (92.00%) (24887/27008)
Epoch: 100 | Batch_idx: 220 |  Loss: (0.2265) |  Loss2: (0.0000) | Acc: (92.00%) (26063/28288)
Epoch: 100 | Batch_idx: 230 |  Loss: (0.2265) |  Loss2: (0.0000) | Acc: (92.00%) (27248/29568)
Epoch: 100 | Batch_idx: 240 |  Loss: (0.2247) |  Loss2: (0.0000) | Acc: (92.00%) (28451/30848)
Epoch: 100 | Batch_idx: 250 |  Loss: (0.2254) |  Loss2: (0.0000) | Acc: (92.00%) (29627/32128)
Epoch: 100 | Batch_idx: 260 |  Loss: (0.2242) |  Loss2: (0.0000) | Acc: (92.00%) (30814/33408)
Epoch: 100 | Batch_idx: 270 |  Loss: (0.2231) |  Loss2: (0.0000) | Acc: (92.00%) (32001/34688)
Epoch: 100 | Batch_idx: 280 |  Loss: (0.2231) |  Loss2: (0.0000) | Acc: (92.00%) (33185/35968)
Epoch: 100 | Batch_idx: 290 |  Loss: (0.2244) |  Loss2: (0.0000) | Acc: (92.00%) (34347/37248)
Epoch: 100 | Batch_idx: 300 |  Loss: (0.2249) |  Loss2: (0.0000) | Acc: (92.00%) (35525/38528)
Epoch: 100 | Batch_idx: 310 |  Loss: (0.2245) |  Loss2: (0.0000) | Acc: (92.00%) (36718/39808)
Epoch: 100 | Batch_idx: 320 |  Loss: (0.2240) |  Loss2: (0.0000) | Acc: (92.00%) (37901/41088)
Epoch: 100 | Batch_idx: 330 |  Loss: (0.2232) |  Loss2: (0.0000) | Acc: (92.00%) (39090/42368)
Epoch: 100 | Batch_idx: 340 |  Loss: (0.2228) |  Loss2: (0.0000) | Acc: (92.00%) (40280/43648)
Epoch: 100 | Batch_idx: 350 |  Loss: (0.2225) |  Loss2: (0.0000) | Acc: (92.00%) (41458/44928)
Epoch: 100 | Batch_idx: 360 |  Loss: (0.2223) |  Loss2: (0.0000) | Acc: (92.00%) (42641/46208)
Epoch: 100 | Batch_idx: 370 |  Loss: (0.2226) |  Loss2: (0.0000) | Acc: (92.00%) (43816/47488)
Epoch: 100 | Batch_idx: 380 |  Loss: (0.2224) |  Loss2: (0.0000) | Acc: (92.00%) (45001/48768)
Epoch: 100 | Batch_idx: 390 |  Loss: (0.2223) |  Loss2: (0.0000) | Acc: (92.00%) (46130/50000)
=> saving checkpoint 'drive/app/torch/save_Schedule/checkpoint_100.pth.tar'
# TEST : Loss: (0.3906) | Acc: (87.00%) (8752/10000)
percent tensor([0.5594, 0.5700, 0.5595, 0.5571, 0.5629, 0.5688, 0.5704, 0.5552, 0.5571,
        0.5640, 0.5651, 0.5641, 0.5619, 0.5571, 0.5724, 0.5625],
       device='cuda:0') torch.Size([16])
percent tensor([0.5117, 0.5112, 0.5073, 0.5108, 0.5064, 0.5183, 0.5077, 0.5069, 0.5068,
        0.5092, 0.5124, 0.5073, 0.5082, 0.5098, 0.5141, 0.5122],
       device='cuda:0') torch.Size([16])
percent tensor([0.5324, 0.4253, 0.6729, 0.6539, 0.6672, 0.6289, 0.5149, 0.6427, 0.5649,
        0.4994, 0.4343, 0.5907, 0.4526, 0.4703, 0.5078, 0.5752],
       device='cuda:0') torch.Size([16])
percent tensor([0.6680, 0.7011, 0.5810, 0.6151, 0.6024, 0.5371, 0.6640, 0.6015, 0.6655,
        0.6958, 0.7226, 0.6515, 0.6834, 0.7112, 0.6515, 0.6383],
       device='cuda:0') torch.Size([16])
percent tensor([0.7142, 0.6230, 0.7229, 0.7326, 0.7330, 0.7723, 0.6960, 0.7134, 0.6987,
        0.6118, 0.5966, 0.6358, 0.6225, 0.6570, 0.6970, 0.7189],
       device='cuda:0') torch.Size([16])
percent tensor([0.5320, 0.6208, 0.7077, 0.7378, 0.7357, 0.7484, 0.6222, 0.5634, 0.6830,
        0.6014, 0.6531, 0.6492, 0.6115, 0.6684, 0.5252, 0.5590],
       device='cuda:0') torch.Size([16])
percent tensor([0.4829, 0.6551, 0.6786, 0.6911, 0.6591, 0.6131, 0.6121, 0.5787, 0.6235,
        0.6079, 0.6688, 0.6778, 0.5760, 0.6683, 0.5596, 0.4694],
       device='cuda:0') torch.Size([16])
percent tensor([0.9997, 0.9995, 0.9998, 0.9999, 0.9999, 0.9993, 0.9997, 0.9997, 0.9997,
        0.9998, 0.9991, 0.9999, 0.9990, 0.9994, 0.9997, 0.9996],
       device='cuda:0') torch.Size([16])
Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 3, 3, 3]) tensor(180.8642, device='cuda:0')
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(808.8626, device='cuda:0')
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(813.4587, device='cuda:0')
Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([128, 64, 3, 3]) tensor(1518.7853, device='cuda:0')
Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([128, 64, 1, 1]) tensor(499.4071, device='cuda:0')
Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([128, 128, 3, 3]) tensor(2234.7705, device='cuda:0')
Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([256, 128, 3, 3]) tensor(4288.6367, device='cuda:0')
Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([256, 128, 1, 1]) tensor(1403.0950, device='cuda:0')
Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([256, 256, 3, 3]) tensor(6144.9312, device='cuda:0')
Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([512, 256, 3, 3]) tensor(11876.7207, device='cuda:0')
Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([512, 256, 1, 1]) tensor(3943.0596, device='cuda:0')
Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([512, 512, 3, 3]) tensor(16632.0488, device='cuda:0')
Epoch: 101 | Batch_idx: 0 |  Loss: (0.3291) |  Loss2: (0.0000) | Acc: (88.00%) (113/128)
Epoch: 101 | Batch_idx: 10 |  Loss: (0.2302) |  Loss2: (0.0000) | Acc: (91.00%) (1288/1408)
Epoch: 101 | Batch_idx: 20 |  Loss: (0.2412) |  Loss2: (0.0000) | Acc: (91.00%) (2466/2688)
Epoch: 101 | Batch_idx: 30 |  Loss: (0.2355) |  Loss2: (0.0000) | Acc: (91.00%) (3646/3968)
Epoch: 101 | Batch_idx: 40 |  Loss: (0.2282) |  Loss2: (0.0000) | Acc: (91.00%) (4826/5248)
Epoch: 101 | Batch_idx: 50 |  Loss: (0.2268) |  Loss2: (0.0000) | Acc: (92.00%) (6006/6528)
Epoch: 101 | Batch_idx: 60 |  Loss: (0.2260) |  Loss2: (0.0000) | Acc: (92.00%) (7198/7808)
Epoch: 101 | Batch_idx: 70 |  Loss: (0.2301) |  Loss2: (0.0000) | Acc: (92.00%) (8361/9088)
Epoch: 101 | Batch_idx: 80 |  Loss: (0.2296) |  Loss2: (0.0000) | Acc: (91.00%) (9538/10368)
Epoch: 101 | Batch_idx: 90 |  Loss: (0.2265) |  Loss2: (0.0000) | Acc: (92.00%) (10726/11648)
Epoch: 101 | Batch_idx: 100 |  Loss: (0.2240) |  Loss2: (0.0000) | Acc: (92.00%) (11916/12928)
Epoch: 101 | Batch_idx: 110 |  Loss: (0.2221) |  Loss2: (0.0000) | Acc: (92.00%) (13112/14208)
Epoch: 101 | Batch_idx: 120 |  Loss: (0.2231) |  Loss2: (0.0000) | Acc: (92.00%) (14287/15488)
Epoch: 101 | Batch_idx: 130 |  Loss: (0.2227) |  Loss2: (0.0000) | Acc: (92.00%) (15470/16768)
Epoch: 101 | Batch_idx: 140 |  Loss: (0.2222) |  Loss2: (0.0000) | Acc: (92.00%) (16667/18048)
Epoch: 101 | Batch_idx: 150 |  Loss: (0.2223) |  Loss2: (0.0000) | Acc: (92.00%) (17852/19328)
Epoch: 101 | Batch_idx: 160 |  Loss: (0.2216) |  Loss2: (0.0000) | Acc: (92.00%) (19045/20608)
Epoch: 101 | Batch_idx: 170 |  Loss: (0.2198) |  Loss2: (0.0000) | Acc: (92.00%) (20235/21888)
Epoch: 101 | Batch_idx: 180 |  Loss: (0.2191) |  Loss2: (0.0000) | Acc: (92.00%) (21415/23168)
Epoch: 101 | Batch_idx: 190 |  Loss: (0.2200) |  Loss2: (0.0000) | Acc: (92.00%) (22589/24448)
Epoch: 101 | Batch_idx: 200 |  Loss: (0.2208) |  Loss2: (0.0000) | Acc: (92.00%) (23769/25728)
Epoch: 101 | Batch_idx: 210 |  Loss: (0.2200) |  Loss2: (0.0000) | Acc: (92.00%) (24961/27008)
Epoch: 101 | Batch_idx: 220 |  Loss: (0.2209) |  Loss2: (0.0000) | Acc: (92.00%) (26128/28288)
Epoch: 101 | Batch_idx: 230 |  Loss: (0.2208) |  Loss2: (0.0000) | Acc: (92.00%) (27314/29568)
Epoch: 101 | Batch_idx: 240 |  Loss: (0.2207) |  Loss2: (0.0000) | Acc: (92.00%) (28496/30848)
Epoch: 101 | Batch_idx: 250 |  Loss: (0.2198) |  Loss2: (0.0000) | Acc: (92.00%) (29689/32128)
Epoch: 101 | Batch_idx: 260 |  Loss: (0.2202) |  Loss2: (0.0000) | Acc: (92.00%) (30865/33408)
Epoch: 101 | Batch_idx: 270 |  Loss: (0.2198) |  Loss2: (0.0000) | Acc: (92.00%) (32056/34688)
Epoch: 101 | Batch_idx: 280 |  Loss: (0.2199) |  Loss2: (0.0000) | Acc: (92.00%) (33229/35968)
Epoch: 101 | Batch_idx: 290 |  Loss: (0.2186) |  Loss2: (0.0000) | Acc: (92.00%) (34437/37248)
Epoch: 101 | Batch_idx: 300 |  Loss: (0.2180) |  Loss2: (0.0000) | Acc: (92.00%) (35607/38528)
Epoch: 101 | Batch_idx: 310 |  Loss: (0.2182) |  Loss2: (0.0000) | Acc: (92.00%) (36792/39808)
Epoch: 101 | Batch_idx: 320 |  Loss: (0.2178) |  Loss2: (0.0000) | Acc: (92.00%) (37989/41088)
Epoch: 101 | Batch_idx: 330 |  Loss: (0.2181) |  Loss2: (0.0000) | Acc: (92.00%) (39176/42368)
Epoch: 101 | Batch_idx: 340 |  Loss: (0.2178) |  Loss2: (0.0000) | Acc: (92.00%) (40359/43648)
Epoch: 101 | Batch_idx: 350 |  Loss: (0.2170) |  Loss2: (0.0000) | Acc: (92.00%) (41549/44928)
Epoch: 101 | Batch_idx: 360 |  Loss: (0.2167) |  Loss2: (0.0000) | Acc: (92.00%) (42735/46208)
Epoch: 101 | Batch_idx: 370 |  Loss: (0.2166) |  Loss2: (0.0000) | Acc: (92.00%) (43927/47488)
Epoch: 101 | Batch_idx: 380 |  Loss: (0.2167) |  Loss2: (0.0000) | Acc: (92.00%) (45116/48768)
Epoch: 101 | Batch_idx: 390 |  Loss: (0.2172) |  Loss2: (0.0000) | Acc: (92.00%) (46245/50000)
# TEST : Loss: (0.3847) | Acc: (87.00%) (8763/10000)
percent tensor([0.5586, 0.5690, 0.5588, 0.5563, 0.5619, 0.5676, 0.5694, 0.5544, 0.5563,
        0.5632, 0.5642, 0.5632, 0.5610, 0.5566, 0.5711, 0.5617],
       device='cuda:0') torch.Size([16])
percent tensor([0.5121, 0.5118, 0.5075, 0.5111, 0.5067, 0.5187, 0.5082, 0.5072, 0.5071,
        0.5097, 0.5129, 0.5076, 0.5088, 0.5103, 0.5145, 0.5127],
       device='cuda:0') torch.Size([16])
percent tensor([0.5258, 0.4214, 0.6701, 0.6507, 0.6668, 0.6278, 0.5121, 0.6427, 0.5584,
        0.4928, 0.4269, 0.5825, 0.4474, 0.4661, 0.5036, 0.5706],
       device='cuda:0') torch.Size([16])
percent tensor([0.6780, 0.7127, 0.5878, 0.6238, 0.6089, 0.5491, 0.6726, 0.6074, 0.6750,
        0.7081, 0.7347, 0.6617, 0.6947, 0.7218, 0.6625, 0.6509],
       device='cuda:0') torch.Size([16])
percent tensor([0.7149, 0.6197, 0.7236, 0.7334, 0.7337, 0.7728, 0.6964, 0.7138, 0.7002,
        0.6072, 0.5948, 0.6348, 0.6227, 0.6571, 0.6964, 0.7181],
       device='cuda:0') torch.Size([16])
percent tensor([0.5189, 0.6080, 0.7036, 0.7356, 0.7329, 0.7454, 0.6149, 0.5551, 0.6802,
        0.5899, 0.6449, 0.6401, 0.6014, 0.6612, 0.5081, 0.5469],
       device='cuda:0') torch.Size([16])
percent tensor([0.4862, 0.6656, 0.6968, 0.7106, 0.6803, 0.6206, 0.6235, 0.5986, 0.6387,
        0.6204, 0.6794, 0.6946, 0.5822, 0.6791, 0.5754, 0.4723],
       device='cuda:0') torch.Size([16])
percent tensor([0.9997, 0.9995, 0.9998, 0.9999, 0.9999, 0.9993, 0.9997, 0.9997, 0.9997,
        0.9998, 0.9991, 0.9999, 0.9990, 0.9994, 0.9997, 0.9996],
       device='cuda:0') torch.Size([16])
True Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=128, out_features=16, bias=False)
False Linear(in_features=16, out_features=2, bias=False)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=128, out_features=16, bias=False)
False Linear(in_features=16, out_features=2, bias=False)
True Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=256, out_features=32, bias=False)
False Linear(in_features=32, out_features=2, bias=False)
True Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=256, out_features=32, bias=False)
False Linear(in_features=32, out_features=2, bias=False)
True Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=512, out_features=64, bias=False)
False Linear(in_features=64, out_features=2, bias=False)
True Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=512, out_features=64, bias=False)
False Linear(in_features=64, out_features=2, bias=False)
True Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1024, out_features=128, bias=False)
False Linear(in_features=128, out_features=2, bias=False)
True Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1024, out_features=128, bias=False)
False Linear(in_features=128, out_features=2, bias=False)
True Linear(in_features=512, out_features=10, bias=True)
Epoch: 102 | Batch_idx: 0 |  Loss: (0.1554) |  Loss2: (0.0000) | Acc: (94.00%) (121/128)
Epoch: 102 | Batch_idx: 10 |  Loss: (0.2009) |  Loss2: (0.0000) | Acc: (92.00%) (1306/1408)
Epoch: 102 | Batch_idx: 20 |  Loss: (0.1894) |  Loss2: (0.0000) | Acc: (93.00%) (2500/2688)
Epoch: 102 | Batch_idx: 30 |  Loss: (0.1940) |  Loss2: (0.0000) | Acc: (93.00%) (3695/3968)
Epoch: 102 | Batch_idx: 40 |  Loss: (0.2009) |  Loss2: (0.0000) | Acc: (93.00%) (4883/5248)
Epoch: 102 | Batch_idx: 50 |  Loss: (0.2012) |  Loss2: (0.0000) | Acc: (93.00%) (6083/6528)
Epoch: 102 | Batch_idx: 60 |  Loss: (0.2001) |  Loss2: (0.0000) | Acc: (93.00%) (7270/7808)
Epoch: 102 | Batch_idx: 70 |  Loss: (0.2024) |  Loss2: (0.0000) | Acc: (92.00%) (8445/9088)
Epoch: 102 | Batch_idx: 80 |  Loss: (0.2041) |  Loss2: (0.0000) | Acc: (92.00%) (9620/10368)
Epoch: 102 | Batch_idx: 90 |  Loss: (0.2055) |  Loss2: (0.0000) | Acc: (92.00%) (10798/11648)
Epoch: 102 | Batch_idx: 100 |  Loss: (0.2084) |  Loss2: (0.0000) | Acc: (92.00%) (11969/12928)
Epoch: 102 | Batch_idx: 110 |  Loss: (0.2097) |  Loss2: (0.0000) | Acc: (92.00%) (13154/14208)
Epoch: 102 | Batch_idx: 120 |  Loss: (0.2087) |  Loss2: (0.0000) | Acc: (92.00%) (14352/15488)
Epoch: 102 | Batch_idx: 130 |  Loss: (0.2091) |  Loss2: (0.0000) | Acc: (92.00%) (15533/16768)
Epoch: 102 | Batch_idx: 140 |  Loss: (0.2074) |  Loss2: (0.0000) | Acc: (92.00%) (16732/18048)
Epoch: 102 | Batch_idx: 150 |  Loss: (0.2073) |  Loss2: (0.0000) | Acc: (92.00%) (17923/19328)
Epoch: 102 | Batch_idx: 160 |  Loss: (0.2079) |  Loss2: (0.0000) | Acc: (92.00%) (19111/20608)
Epoch: 102 | Batch_idx: 170 |  Loss: (0.2081) |  Loss2: (0.0000) | Acc: (92.00%) (20296/21888)
Epoch: 102 | Batch_idx: 180 |  Loss: (0.2092) |  Loss2: (0.0000) | Acc: (92.00%) (21486/23168)
Epoch: 102 | Batch_idx: 190 |  Loss: (0.2101) |  Loss2: (0.0000) | Acc: (92.00%) (22661/24448)
Epoch: 102 | Batch_idx: 200 |  Loss: (0.2110) |  Loss2: (0.0000) | Acc: (92.00%) (23834/25728)
Epoch: 102 | Batch_idx: 210 |  Loss: (0.2100) |  Loss2: (0.0000) | Acc: (92.00%) (25040/27008)
Epoch: 102 | Batch_idx: 220 |  Loss: (0.2106) |  Loss2: (0.0000) | Acc: (92.00%) (26219/28288)
Epoch: 102 | Batch_idx: 230 |  Loss: (0.2100) |  Loss2: (0.0000) | Acc: (92.00%) (27413/29568)
Epoch: 102 | Batch_idx: 240 |  Loss: (0.2112) |  Loss2: (0.0000) | Acc: (92.00%) (28588/30848)
Epoch: 102 | Batch_idx: 250 |  Loss: (0.2119) |  Loss2: (0.0000) | Acc: (92.00%) (29764/32128)
Epoch: 102 | Batch_idx: 260 |  Loss: (0.2133) |  Loss2: (0.0000) | Acc: (92.00%) (30930/33408)
Epoch: 102 | Batch_idx: 270 |  Loss: (0.2140) |  Loss2: (0.0000) | Acc: (92.00%) (32101/34688)
Epoch: 102 | Batch_idx: 280 |  Loss: (0.2138) |  Loss2: (0.0000) | Acc: (92.00%) (33299/35968)
Epoch: 102 | Batch_idx: 290 |  Loss: (0.2134) |  Loss2: (0.0000) | Acc: (92.00%) (34489/37248)
Epoch: 102 | Batch_idx: 300 |  Loss: (0.2147) |  Loss2: (0.0000) | Acc: (92.00%) (35661/38528)
Epoch: 102 | Batch_idx: 310 |  Loss: (0.2147) |  Loss2: (0.0000) | Acc: (92.00%) (36844/39808)
Epoch: 102 | Batch_idx: 320 |  Loss: (0.2147) |  Loss2: (0.0000) | Acc: (92.00%) (38036/41088)
Epoch: 102 | Batch_idx: 330 |  Loss: (0.2154) |  Loss2: (0.0000) | Acc: (92.00%) (39206/42368)
Epoch: 102 | Batch_idx: 340 |  Loss: (0.2154) |  Loss2: (0.0000) | Acc: (92.00%) (40396/43648)
Epoch: 102 | Batch_idx: 350 |  Loss: (0.2163) |  Loss2: (0.0000) | Acc: (92.00%) (41571/44928)
Epoch: 102 | Batch_idx: 360 |  Loss: (0.2165) |  Loss2: (0.0000) | Acc: (92.00%) (42742/46208)
Epoch: 102 | Batch_idx: 370 |  Loss: (0.2169) |  Loss2: (0.0000) | Acc: (92.00%) (43918/47488)
Epoch: 102 | Batch_idx: 380 |  Loss: (0.2165) |  Loss2: (0.0000) | Acc: (92.00%) (45111/48768)
Epoch: 102 | Batch_idx: 390 |  Loss: (0.2164) |  Loss2: (0.0000) | Acc: (92.00%) (46255/50000)
# TEST : Loss: (0.4127) | Acc: (86.00%) (8673/10000)
percent tensor([0.5573, 0.5683, 0.5584, 0.5556, 0.5611, 0.5656, 0.5688, 0.5538, 0.5549,
        0.5626, 0.5636, 0.5641, 0.5602, 0.5557, 0.5704, 0.5606],
       device='cuda:0') torch.Size([16])
percent tensor([0.5122, 0.5117, 0.5075, 0.5099, 0.5069, 0.5183, 0.5085, 0.5072, 0.5075,
        0.5098, 0.5129, 0.5074, 0.5090, 0.5103, 0.5141, 0.5124],
       device='cuda:0') torch.Size([16])
percent tensor([0.5197, 0.4198, 0.6621, 0.6513, 0.6755, 0.6219, 0.5133, 0.6353, 0.5518,
        0.4799, 0.4277, 0.5709, 0.4344, 0.4697, 0.4950, 0.5676],
       device='cuda:0') torch.Size([16])
percent tensor([0.6779, 0.7160, 0.6060, 0.6260, 0.6130, 0.5463, 0.6784, 0.6158, 0.6848,
        0.7155, 0.7404, 0.6723, 0.7029, 0.7178, 0.6612, 0.6520],
       device='cuda:0') torch.Size([16])
percent tensor([0.7086, 0.6014, 0.7168, 0.7349, 0.7325, 0.7772, 0.6886, 0.7186, 0.6805,
        0.5924, 0.5763, 0.6138, 0.5923, 0.6497, 0.6944, 0.7208],
       device='cuda:0') torch.Size([16])
percent tensor([0.5243, 0.6270, 0.6935, 0.7255, 0.7229, 0.7471, 0.6409, 0.5536, 0.6713,
        0.6170, 0.6695, 0.6483, 0.6250, 0.6824, 0.5198, 0.5484],
       device='cuda:0') torch.Size([16])
percent tensor([0.4976, 0.6826, 0.6847, 0.6954, 0.6795, 0.6305, 0.6383, 0.6014, 0.6546,
        0.6516, 0.7002, 0.6960, 0.6292, 0.6807, 0.5899, 0.4735],
       device='cuda:0') torch.Size([16])
percent tensor([0.9997, 0.9994, 0.9998, 0.9999, 1.0000, 0.9981, 0.9997, 0.9999, 0.9996,
        0.9998, 0.9995, 0.9998, 0.9991, 0.9995, 0.9997, 0.9995],
       device='cuda:0') torch.Size([16])
Epoch: 103 | Batch_idx: 0 |  Loss: (0.1831) |  Loss2: (0.0000) | Acc: (96.00%) (123/128)
Epoch: 103 | Batch_idx: 10 |  Loss: (0.1839) |  Loss2: (0.0000) | Acc: (94.00%) (1325/1408)
Epoch: 103 | Batch_idx: 20 |  Loss: (0.2000) |  Loss2: (0.0000) | Acc: (93.00%) (2506/2688)
Epoch: 103 | Batch_idx: 30 |  Loss: (0.2006) |  Loss2: (0.0000) | Acc: (93.00%) (3701/3968)
Epoch: 103 | Batch_idx: 40 |  Loss: (0.2040) |  Loss2: (0.0000) | Acc: (93.00%) (4896/5248)
Epoch: 103 | Batch_idx: 50 |  Loss: (0.1952) |  Loss2: (0.0000) | Acc: (93.00%) (6103/6528)
Epoch: 103 | Batch_idx: 60 |  Loss: (0.1959) |  Loss2: (0.0000) | Acc: (93.00%) (7303/7808)
Epoch: 103 | Batch_idx: 70 |  Loss: (0.1974) |  Loss2: (0.0000) | Acc: (93.00%) (8494/9088)
Epoch: 103 | Batch_idx: 80 |  Loss: (0.2002) |  Loss2: (0.0000) | Acc: (93.00%) (9680/10368)
Epoch: 103 | Batch_idx: 90 |  Loss: (0.1999) |  Loss2: (0.0000) | Acc: (93.00%) (10874/11648)
Epoch: 103 | Batch_idx: 100 |  Loss: (0.1999) |  Loss2: (0.0000) | Acc: (93.00%) (12074/12928)
Epoch: 103 | Batch_idx: 110 |  Loss: (0.2002) |  Loss2: (0.0000) | Acc: (93.00%) (13278/14208)
Epoch: 103 | Batch_idx: 120 |  Loss: (0.1983) |  Loss2: (0.0000) | Acc: (93.00%) (14479/15488)
Epoch: 103 | Batch_idx: 130 |  Loss: (0.2000) |  Loss2: (0.0000) | Acc: (93.00%) (15662/16768)
Epoch: 103 | Batch_idx: 140 |  Loss: (0.2001) |  Loss2: (0.0000) | Acc: (93.00%) (16845/18048)
Epoch: 103 | Batch_idx: 150 |  Loss: (0.2015) |  Loss2: (0.0000) | Acc: (93.00%) (18032/19328)
Epoch: 103 | Batch_idx: 160 |  Loss: (0.2023) |  Loss2: (0.0000) | Acc: (93.00%) (19215/20608)
Epoch: 103 | Batch_idx: 170 |  Loss: (0.2012) |  Loss2: (0.0000) | Acc: (93.00%) (20422/21888)
Epoch: 103 | Batch_idx: 180 |  Loss: (0.2008) |  Loss2: (0.0000) | Acc: (93.00%) (21618/23168)
Epoch: 103 | Batch_idx: 190 |  Loss: (0.2015) |  Loss2: (0.0000) | Acc: (93.00%) (22805/24448)
Epoch: 103 | Batch_idx: 200 |  Loss: (0.2013) |  Loss2: (0.0000) | Acc: (93.00%) (23998/25728)
Epoch: 103 | Batch_idx: 210 |  Loss: (0.2007) |  Loss2: (0.0000) | Acc: (93.00%) (25194/27008)
Epoch: 103 | Batch_idx: 220 |  Loss: (0.2011) |  Loss2: (0.0000) | Acc: (93.00%) (26384/28288)
Epoch: 103 | Batch_idx: 230 |  Loss: (0.2016) |  Loss2: (0.0000) | Acc: (93.00%) (27570/29568)
Epoch: 103 | Batch_idx: 240 |  Loss: (0.2030) |  Loss2: (0.0000) | Acc: (93.00%) (28730/30848)
Epoch: 103 | Batch_idx: 250 |  Loss: (0.2038) |  Loss2: (0.0000) | Acc: (93.00%) (29909/32128)
Epoch: 103 | Batch_idx: 260 |  Loss: (0.2039) |  Loss2: (0.0000) | Acc: (93.00%) (31099/33408)
Epoch: 103 | Batch_idx: 270 |  Loss: (0.2042) |  Loss2: (0.0000) | Acc: (93.00%) (32290/34688)
Epoch: 103 | Batch_idx: 280 |  Loss: (0.2043) |  Loss2: (0.0000) | Acc: (93.00%) (33474/35968)
Epoch: 103 | Batch_idx: 290 |  Loss: (0.2054) |  Loss2: (0.0000) | Acc: (92.00%) (34640/37248)
Epoch: 103 | Batch_idx: 300 |  Loss: (0.2068) |  Loss2: (0.0000) | Acc: (92.00%) (35809/38528)
Epoch: 103 | Batch_idx: 310 |  Loss: (0.2061) |  Loss2: (0.0000) | Acc: (92.00%) (37002/39808)
Epoch: 103 | Batch_idx: 320 |  Loss: (0.2071) |  Loss2: (0.0000) | Acc: (92.00%) (38173/41088)
Epoch: 103 | Batch_idx: 330 |  Loss: (0.2080) |  Loss2: (0.0000) | Acc: (92.00%) (39352/42368)
Epoch: 103 | Batch_idx: 340 |  Loss: (0.2084) |  Loss2: (0.0000) | Acc: (92.00%) (40540/43648)
Epoch: 103 | Batch_idx: 350 |  Loss: (0.2097) |  Loss2: (0.0000) | Acc: (92.00%) (41713/44928)
Epoch: 103 | Batch_idx: 360 |  Loss: (0.2104) |  Loss2: (0.0000) | Acc: (92.00%) (42893/46208)
Epoch: 103 | Batch_idx: 370 |  Loss: (0.2097) |  Loss2: (0.0000) | Acc: (92.00%) (44079/47488)
Epoch: 103 | Batch_idx: 380 |  Loss: (0.2099) |  Loss2: (0.0000) | Acc: (92.00%) (45259/48768)
Epoch: 103 | Batch_idx: 390 |  Loss: (0.2104) |  Loss2: (0.0000) | Acc: (92.00%) (46393/50000)
# TEST : Loss: (0.3850) | Acc: (87.00%) (8760/10000)
percent tensor([0.5585, 0.5685, 0.5592, 0.5563, 0.5625, 0.5673, 0.5696, 0.5547, 0.5563,
        0.5629, 0.5643, 0.5649, 0.5612, 0.5557, 0.5712, 0.5614],
       device='cuda:0') torch.Size([16])
percent tensor([0.5116, 0.5113, 0.5064, 0.5102, 0.5065, 0.5180, 0.5077, 0.5067, 0.5070,
        0.5095, 0.5123, 0.5069, 0.5091, 0.5094, 0.5140, 0.5117],
       device='cuda:0') torch.Size([16])
percent tensor([0.5280, 0.4085, 0.6644, 0.6534, 0.6748, 0.6391, 0.5088, 0.6331, 0.5530,
        0.4735, 0.4163, 0.5663, 0.4332, 0.4748, 0.5016, 0.5713],
       device='cuda:0') torch.Size([16])
percent tensor([0.6723, 0.7176, 0.5868, 0.6236, 0.6040, 0.5364, 0.6731, 0.6150, 0.6816,
        0.7100, 0.7359, 0.6596, 0.6987, 0.7288, 0.6546, 0.6498],
       device='cuda:0') torch.Size([16])
percent tensor([0.6976, 0.5992, 0.7185, 0.7198, 0.7308, 0.7662, 0.6874, 0.7205, 0.6815,
        0.6019, 0.5711, 0.6273, 0.5840, 0.6511, 0.6905, 0.7089],
       device='cuda:0') torch.Size([16])
percent tensor([0.5087, 0.5802, 0.6897, 0.7101, 0.7122, 0.7465, 0.6085, 0.5460, 0.6268,
        0.5325, 0.6274, 0.6240, 0.5788, 0.6324, 0.4799, 0.5215],
       device='cuda:0') torch.Size([16])
percent tensor([0.4924, 0.6569, 0.6800, 0.6935, 0.6734, 0.6197, 0.6176, 0.5956, 0.6197,
        0.6051, 0.6800, 0.6700, 0.6018, 0.6603, 0.5752, 0.4739],
       device='cuda:0') torch.Size([16])
percent tensor([0.9997, 0.9995, 0.9996, 0.9998, 0.9999, 0.9987, 0.9995, 0.9998, 0.9996,
        0.9998, 0.9993, 0.9998, 0.9990, 0.9996, 0.9996, 0.9996],
       device='cuda:0') torch.Size([16])
Epoch: 104 | Batch_idx: 0 |  Loss: (0.1616) |  Loss2: (0.0000) | Acc: (95.00%) (122/128)
Epoch: 104 | Batch_idx: 10 |  Loss: (0.1961) |  Loss2: (0.0000) | Acc: (93.00%) (1317/1408)
Epoch: 104 | Batch_idx: 20 |  Loss: (0.1915) |  Loss2: (0.0000) | Acc: (93.00%) (2510/2688)
Epoch: 104 | Batch_idx: 30 |  Loss: (0.1884) |  Loss2: (0.0000) | Acc: (93.00%) (3708/3968)
Epoch: 104 | Batch_idx: 40 |  Loss: (0.1908) |  Loss2: (0.0000) | Acc: (93.00%) (4905/5248)
Epoch: 104 | Batch_idx: 50 |  Loss: (0.1940) |  Loss2: (0.0000) | Acc: (93.00%) (6094/6528)
Epoch: 104 | Batch_idx: 60 |  Loss: (0.1937) |  Loss2: (0.0000) | Acc: (93.00%) (7288/7808)
Epoch: 104 | Batch_idx: 70 |  Loss: (0.1975) |  Loss2: (0.0000) | Acc: (93.00%) (8470/9088)
Epoch: 104 | Batch_idx: 80 |  Loss: (0.1961) |  Loss2: (0.0000) | Acc: (93.00%) (9672/10368)
Epoch: 104 | Batch_idx: 90 |  Loss: (0.1969) |  Loss2: (0.0000) | Acc: (93.00%) (10860/11648)
Epoch: 104 | Batch_idx: 100 |  Loss: (0.1962) |  Loss2: (0.0000) | Acc: (93.00%) (12058/12928)
Epoch: 104 | Batch_idx: 110 |  Loss: (0.1946) |  Loss2: (0.0000) | Acc: (93.00%) (13254/14208)
Epoch: 104 | Batch_idx: 120 |  Loss: (0.1965) |  Loss2: (0.0000) | Acc: (93.00%) (14437/15488)
Epoch: 104 | Batch_idx: 130 |  Loss: (0.1969) |  Loss2: (0.0000) | Acc: (93.00%) (15633/16768)
Epoch: 104 | Batch_idx: 140 |  Loss: (0.1976) |  Loss2: (0.0000) | Acc: (93.00%) (16826/18048)
Epoch: 104 | Batch_idx: 150 |  Loss: (0.1978) |  Loss2: (0.0000) | Acc: (93.00%) (18007/19328)
Epoch: 104 | Batch_idx: 160 |  Loss: (0.1979) |  Loss2: (0.0000) | Acc: (93.00%) (19196/20608)
Epoch: 104 | Batch_idx: 170 |  Loss: (0.1987) |  Loss2: (0.0000) | Acc: (93.00%) (20380/21888)
Epoch: 104 | Batch_idx: 180 |  Loss: (0.1984) |  Loss2: (0.0000) | Acc: (93.00%) (21571/23168)
Epoch: 104 | Batch_idx: 190 |  Loss: (0.1989) |  Loss2: (0.0000) | Acc: (93.00%) (22752/24448)
Epoch: 104 | Batch_idx: 200 |  Loss: (0.1983) |  Loss2: (0.0000) | Acc: (93.00%) (23954/25728)
Epoch: 104 | Batch_idx: 210 |  Loss: (0.1988) |  Loss2: (0.0000) | Acc: (93.00%) (25132/27008)
Epoch: 104 | Batch_idx: 220 |  Loss: (0.2005) |  Loss2: (0.0000) | Acc: (93.00%) (26315/28288)
Epoch: 104 | Batch_idx: 230 |  Loss: (0.2006) |  Loss2: (0.0000) | Acc: (93.00%) (27507/29568)
Epoch: 104 | Batch_idx: 240 |  Loss: (0.2005) |  Loss2: (0.0000) | Acc: (93.00%) (28703/30848)
Epoch: 104 | Batch_idx: 250 |  Loss: (0.2007) |  Loss2: (0.0000) | Acc: (93.00%) (29891/32128)
Epoch: 104 | Batch_idx: 260 |  Loss: (0.2011) |  Loss2: (0.0000) | Acc: (93.00%) (31071/33408)
Epoch: 104 | Batch_idx: 270 |  Loss: (0.2018) |  Loss2: (0.0000) | Acc: (92.00%) (32257/34688)
Epoch: 104 | Batch_idx: 280 |  Loss: (0.2023) |  Loss2: (0.0000) | Acc: (92.00%) (33433/35968)
Epoch: 104 | Batch_idx: 290 |  Loss: (0.2026) |  Loss2: (0.0000) | Acc: (92.00%) (34623/37248)
Epoch: 104 | Batch_idx: 300 |  Loss: (0.2034) |  Loss2: (0.0000) | Acc: (92.00%) (35799/38528)
Epoch: 104 | Batch_idx: 310 |  Loss: (0.2038) |  Loss2: (0.0000) | Acc: (92.00%) (36990/39808)
Epoch: 104 | Batch_idx: 320 |  Loss: (0.2031) |  Loss2: (0.0000) | Acc: (92.00%) (38189/41088)
Epoch: 104 | Batch_idx: 330 |  Loss: (0.2035) |  Loss2: (0.0000) | Acc: (92.00%) (39375/42368)
Epoch: 104 | Batch_idx: 340 |  Loss: (0.2037) |  Loss2: (0.0000) | Acc: (92.00%) (40562/43648)
Epoch: 104 | Batch_idx: 350 |  Loss: (0.2045) |  Loss2: (0.0000) | Acc: (92.00%) (41742/44928)
Epoch: 104 | Batch_idx: 360 |  Loss: (0.2041) |  Loss2: (0.0000) | Acc: (92.00%) (42929/46208)
Epoch: 104 | Batch_idx: 370 |  Loss: (0.2043) |  Loss2: (0.0000) | Acc: (92.00%) (44117/47488)
Epoch: 104 | Batch_idx: 380 |  Loss: (0.2039) |  Loss2: (0.0000) | Acc: (92.00%) (45307/48768)
Epoch: 104 | Batch_idx: 390 |  Loss: (0.2036) |  Loss2: (0.0000) | Acc: (92.00%) (46454/50000)
# TEST : Loss: (0.4140) | Acc: (86.00%) (8681/10000)
percent tensor([0.5574, 0.5684, 0.5567, 0.5559, 0.5606, 0.5664, 0.5686, 0.5536, 0.5552,
        0.5621, 0.5631, 0.5632, 0.5601, 0.5560, 0.5709, 0.5609],
       device='cuda:0') torch.Size([16])
percent tensor([0.5122, 0.5115, 0.5067, 0.5101, 0.5072, 0.5185, 0.5081, 0.5069, 0.5073,
        0.5096, 0.5128, 0.5073, 0.5090, 0.5098, 0.5147, 0.5122],
       device='cuda:0') torch.Size([16])
percent tensor([0.5247, 0.4134, 0.6699, 0.6550, 0.6822, 0.6218, 0.5191, 0.6404, 0.5667,
        0.4744, 0.4216, 0.5761, 0.4304, 0.4922, 0.4920, 0.5671],
       device='cuda:0') torch.Size([16])
percent tensor([0.6756, 0.7156, 0.5919, 0.6345, 0.6074, 0.5599, 0.6686, 0.6158, 0.6818,
        0.7113, 0.7312, 0.6627, 0.6992, 0.7195, 0.6637, 0.6535],
       device='cuda:0') torch.Size([16])
percent tensor([0.6978, 0.5894, 0.7256, 0.7252, 0.7314, 0.7615, 0.6906, 0.7241, 0.6845,
        0.5915, 0.5727, 0.6234, 0.5811, 0.6491, 0.6868, 0.7108],
       device='cuda:0') torch.Size([16])
percent tensor([0.5359, 0.6142, 0.6871, 0.7293, 0.7125, 0.7408, 0.6467, 0.5637, 0.6615,
        0.5876, 0.6548, 0.6576, 0.6110, 0.6565, 0.5105, 0.5436],
       device='cuda:0') torch.Size([16])
percent tensor([0.5245, 0.6933, 0.6777, 0.6878, 0.6773, 0.6427, 0.6561, 0.6158, 0.6580,
        0.6392, 0.7028, 0.6893, 0.6263, 0.6766, 0.6059, 0.4898],
       device='cuda:0') torch.Size([16])
percent tensor([0.9997, 0.9996, 0.9997, 0.9998, 0.9999, 0.9983, 0.9998, 0.9997, 0.9996,
        0.9998, 0.9994, 0.9999, 0.9989, 0.9997, 0.9998, 0.9997],
       device='cuda:0') torch.Size([16])
False Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=128, out_features=16, bias=False)
True Linear(in_features=16, out_features=2, bias=False)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=128, out_features=16, bias=False)
True Linear(in_features=16, out_features=2, bias=False)
False Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=256, out_features=32, bias=False)
True Linear(in_features=32, out_features=2, bias=False)
False Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=256, out_features=32, bias=False)
True Linear(in_features=32, out_features=2, bias=False)
False Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=512, out_features=64, bias=False)
True Linear(in_features=64, out_features=2, bias=False)
False Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=512, out_features=64, bias=False)
True Linear(in_features=64, out_features=2, bias=False)
False Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1024, out_features=128, bias=False)
True Linear(in_features=128, out_features=2, bias=False)
False Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1024, out_features=128, bias=False)
True Linear(in_features=128, out_features=2, bias=False)
False Linear(in_features=512, out_features=10, bias=True)
Epoch: 105 | Batch_idx: 0 |  Loss: (0.2819) |  Loss2: (0.0000) | Acc: (92.00%) (119/128)
Epoch: 105 | Batch_idx: 10 |  Loss: (0.1991) |  Loss2: (0.0000) | Acc: (93.00%) (1311/1408)
Epoch: 105 | Batch_idx: 20 |  Loss: (0.2193) |  Loss2: (0.0000) | Acc: (92.00%) (2482/2688)
Epoch: 105 | Batch_idx: 30 |  Loss: (0.2239) |  Loss2: (0.0000) | Acc: (92.00%) (3665/3968)
Epoch: 105 | Batch_idx: 40 |  Loss: (0.2267) |  Loss2: (0.0000) | Acc: (92.00%) (4844/5248)
Epoch: 105 | Batch_idx: 50 |  Loss: (0.2247) |  Loss2: (0.0000) | Acc: (92.00%) (6035/6528)
Epoch: 105 | Batch_idx: 60 |  Loss: (0.2239) |  Loss2: (0.0000) | Acc: (92.00%) (7214/7808)
Epoch: 105 | Batch_idx: 70 |  Loss: (0.2216) |  Loss2: (0.0000) | Acc: (92.00%) (8409/9088)
Epoch: 105 | Batch_idx: 80 |  Loss: (0.2214) |  Loss2: (0.0000) | Acc: (92.00%) (9585/10368)
Epoch: 105 | Batch_idx: 90 |  Loss: (0.2237) |  Loss2: (0.0000) | Acc: (92.00%) (10755/11648)
Epoch: 105 | Batch_idx: 100 |  Loss: (0.2235) |  Loss2: (0.0000) | Acc: (92.00%) (11929/12928)
Epoch: 105 | Batch_idx: 110 |  Loss: (0.2234) |  Loss2: (0.0000) | Acc: (92.00%) (13112/14208)
Epoch: 105 | Batch_idx: 120 |  Loss: (0.2248) |  Loss2: (0.0000) | Acc: (92.00%) (14286/15488)
Epoch: 105 | Batch_idx: 130 |  Loss: (0.2260) |  Loss2: (0.0000) | Acc: (92.00%) (15457/16768)
Epoch: 105 | Batch_idx: 140 |  Loss: (0.2246) |  Loss2: (0.0000) | Acc: (92.00%) (16641/18048)
Epoch: 105 | Batch_idx: 150 |  Loss: (0.2243) |  Loss2: (0.0000) | Acc: (92.00%) (17820/19328)
Epoch: 105 | Batch_idx: 160 |  Loss: (0.2225) |  Loss2: (0.0000) | Acc: (92.00%) (19012/20608)
Epoch: 105 | Batch_idx: 170 |  Loss: (0.2215) |  Loss2: (0.0000) | Acc: (92.00%) (20200/21888)
Epoch: 105 | Batch_idx: 180 |  Loss: (0.2214) |  Loss2: (0.0000) | Acc: (92.00%) (21390/23168)
Epoch: 105 | Batch_idx: 190 |  Loss: (0.2218) |  Loss2: (0.0000) | Acc: (92.00%) (22566/24448)
Epoch: 105 | Batch_idx: 200 |  Loss: (0.2213) |  Loss2: (0.0000) | Acc: (92.00%) (23752/25728)
Epoch: 105 | Batch_idx: 210 |  Loss: (0.2197) |  Loss2: (0.0000) | Acc: (92.00%) (24953/27008)
Epoch: 105 | Batch_idx: 220 |  Loss: (0.2181) |  Loss2: (0.0000) | Acc: (92.00%) (26158/28288)
Epoch: 105 | Batch_idx: 230 |  Loss: (0.2174) |  Loss2: (0.0000) | Acc: (92.00%) (27348/29568)
Epoch: 105 | Batch_idx: 240 |  Loss: (0.2179) |  Loss2: (0.0000) | Acc: (92.00%) (28533/30848)
Epoch: 105 | Batch_idx: 250 |  Loss: (0.2174) |  Loss2: (0.0000) | Acc: (92.00%) (29719/32128)
Epoch: 105 | Batch_idx: 260 |  Loss: (0.2174) |  Loss2: (0.0000) | Acc: (92.00%) (30905/33408)
Epoch: 105 | Batch_idx: 270 |  Loss: (0.2177) |  Loss2: (0.0000) | Acc: (92.00%) (32090/34688)
Epoch: 105 | Batch_idx: 280 |  Loss: (0.2183) |  Loss2: (0.0000) | Acc: (92.00%) (33271/35968)
Epoch: 105 | Batch_idx: 290 |  Loss: (0.2174) |  Loss2: (0.0000) | Acc: (92.00%) (34460/37248)
Epoch: 105 | Batch_idx: 300 |  Loss: (0.2162) |  Loss2: (0.0000) | Acc: (92.00%) (35658/38528)
Epoch: 105 | Batch_idx: 310 |  Loss: (0.2160) |  Loss2: (0.0000) | Acc: (92.00%) (36848/39808)
Epoch: 105 | Batch_idx: 320 |  Loss: (0.2160) |  Loss2: (0.0000) | Acc: (92.00%) (38030/41088)
Epoch: 105 | Batch_idx: 330 |  Loss: (0.2154) |  Loss2: (0.0000) | Acc: (92.00%) (39228/42368)
Epoch: 105 | Batch_idx: 340 |  Loss: (0.2150) |  Loss2: (0.0000) | Acc: (92.00%) (40408/43648)
Epoch: 105 | Batch_idx: 350 |  Loss: (0.2140) |  Loss2: (0.0000) | Acc: (92.00%) (41615/44928)
Epoch: 105 | Batch_idx: 360 |  Loss: (0.2138) |  Loss2: (0.0000) | Acc: (92.00%) (42806/46208)
Epoch: 105 | Batch_idx: 370 |  Loss: (0.2132) |  Loss2: (0.0000) | Acc: (92.00%) (44010/47488)
Epoch: 105 | Batch_idx: 380 |  Loss: (0.2132) |  Loss2: (0.0000) | Acc: (92.00%) (45204/48768)
Epoch: 105 | Batch_idx: 390 |  Loss: (0.2121) |  Loss2: (0.0000) | Acc: (92.00%) (46366/50000)
=> saving checkpoint 'drive/app/torch/save_Schedule/checkpoint_105.pth.tar'
# TEST : Loss: (0.3885) | Acc: (87.00%) (8761/10000)
percent tensor([0.5592, 0.5707, 0.5566, 0.5577, 0.5613, 0.5697, 0.5703, 0.5543, 0.5562,
        0.5634, 0.5652, 0.5637, 0.5620, 0.5563, 0.5743, 0.5634],
       device='cuda:0') torch.Size([16])
percent tensor([0.5124, 0.5116, 0.5072, 0.5107, 0.5072, 0.5192, 0.5079, 0.5069, 0.5072,
        0.5098, 0.5131, 0.5077, 0.5090, 0.5104, 0.5147, 0.5127],
       device='cuda:0') torch.Size([16])
percent tensor([0.5265, 0.3973, 0.6890, 0.6622, 0.6917, 0.6260, 0.5103, 0.6441, 0.5740,
        0.4726, 0.4225, 0.5871, 0.4254, 0.4843, 0.4821, 0.5674],
       device='cuda:0') torch.Size([16])
percent tensor([0.6888, 0.7282, 0.6041, 0.6479, 0.6174, 0.5723, 0.6815, 0.6254, 0.6936,
        0.7272, 0.7490, 0.6792, 0.7131, 0.7293, 0.6760, 0.6689],
       device='cuda:0') torch.Size([16])
percent tensor([0.6958, 0.5824, 0.7210, 0.7259, 0.7305, 0.7596, 0.6874, 0.7184, 0.6837,
        0.5911, 0.5772, 0.6154, 0.5763, 0.6512, 0.6806, 0.7117],
       device='cuda:0') torch.Size([16])
percent tensor([0.4817, 0.5816, 0.6490, 0.6951, 0.6816, 0.7224, 0.6148, 0.5048, 0.6311,
        0.5474, 0.6232, 0.6243, 0.5789, 0.6212, 0.4625, 0.4887],
       device='cuda:0') torch.Size([16])
percent tensor([0.4660, 0.6386, 0.6284, 0.6460, 0.6296, 0.5846, 0.5907, 0.5650, 0.5993,
        0.5831, 0.6582, 0.6446, 0.5655, 0.6150, 0.5477, 0.4459],
       device='cuda:0') torch.Size([16])
percent tensor([0.9997, 0.9995, 0.9997, 0.9999, 0.9999, 0.9989, 0.9997, 0.9997, 0.9996,
        0.9998, 0.9994, 0.9998, 0.9987, 0.9997, 0.9997, 0.9997],
       device='cuda:0') torch.Size([16])
Epoch: 106 | Batch_idx: 0 |  Loss: (0.2238) |  Loss2: (0.0000) | Acc: (94.00%) (121/128)
Epoch: 106 | Batch_idx: 10 |  Loss: (0.2213) |  Loss2: (0.0000) | Acc: (92.00%) (1305/1408)
Epoch: 106 | Batch_idx: 20 |  Loss: (0.2249) |  Loss2: (0.0000) | Acc: (92.00%) (2484/2688)
Epoch: 106 | Batch_idx: 30 |  Loss: (0.2178) |  Loss2: (0.0000) | Acc: (92.00%) (3677/3968)
Epoch: 106 | Batch_idx: 40 |  Loss: (0.2105) |  Loss2: (0.0000) | Acc: (92.00%) (4868/5248)
Epoch: 106 | Batch_idx: 50 |  Loss: (0.2108) |  Loss2: (0.0000) | Acc: (92.00%) (6045/6528)
Epoch: 106 | Batch_idx: 60 |  Loss: (0.2116) |  Loss2: (0.0000) | Acc: (92.00%) (7224/7808)
Epoch: 106 | Batch_idx: 70 |  Loss: (0.2139) |  Loss2: (0.0000) | Acc: (92.00%) (8403/9088)
Epoch: 106 | Batch_idx: 80 |  Loss: (0.2123) |  Loss2: (0.0000) | Acc: (92.00%) (9594/10368)
Epoch: 106 | Batch_idx: 90 |  Loss: (0.2075) |  Loss2: (0.0000) | Acc: (92.00%) (10798/11648)
Epoch: 106 | Batch_idx: 100 |  Loss: (0.2075) |  Loss2: (0.0000) | Acc: (92.00%) (11981/12928)
Epoch: 106 | Batch_idx: 110 |  Loss: (0.2060) |  Loss2: (0.0000) | Acc: (92.00%) (13170/14208)
Epoch: 106 | Batch_idx: 120 |  Loss: (0.2045) |  Loss2: (0.0000) | Acc: (92.00%) (14368/15488)
Epoch: 106 | Batch_idx: 130 |  Loss: (0.2042) |  Loss2: (0.0000) | Acc: (92.00%) (15553/16768)
Epoch: 106 | Batch_idx: 140 |  Loss: (0.2034) |  Loss2: (0.0000) | Acc: (92.00%) (16749/18048)
Epoch: 106 | Batch_idx: 150 |  Loss: (0.2049) |  Loss2: (0.0000) | Acc: (92.00%) (17936/19328)
Epoch: 106 | Batch_idx: 160 |  Loss: (0.2033) |  Loss2: (0.0000) | Acc: (92.00%) (19142/20608)
Epoch: 106 | Batch_idx: 170 |  Loss: (0.2025) |  Loss2: (0.0000) | Acc: (92.00%) (20336/21888)
Epoch: 106 | Batch_idx: 180 |  Loss: (0.2024) |  Loss2: (0.0000) | Acc: (92.00%) (21532/23168)
Epoch: 106 | Batch_idx: 190 |  Loss: (0.2021) |  Loss2: (0.0000) | Acc: (92.00%) (22728/24448)
Epoch: 106 | Batch_idx: 200 |  Loss: (0.2021) |  Loss2: (0.0000) | Acc: (92.00%) (23924/25728)
Epoch: 106 | Batch_idx: 210 |  Loss: (0.2011) |  Loss2: (0.0000) | Acc: (93.00%) (25128/27008)
Epoch: 106 | Batch_idx: 220 |  Loss: (0.2000) |  Loss2: (0.0000) | Acc: (93.00%) (26332/28288)
Epoch: 106 | Batch_idx: 230 |  Loss: (0.1990) |  Loss2: (0.0000) | Acc: (93.00%) (27538/29568)
Epoch: 106 | Batch_idx: 240 |  Loss: (0.1979) |  Loss2: (0.0000) | Acc: (93.00%) (28739/30848)
Epoch: 106 | Batch_idx: 250 |  Loss: (0.1993) |  Loss2: (0.0000) | Acc: (93.00%) (29909/32128)
Epoch: 106 | Batch_idx: 260 |  Loss: (0.1988) |  Loss2: (0.0000) | Acc: (93.00%) (31105/33408)
Epoch: 106 | Batch_idx: 270 |  Loss: (0.1985) |  Loss2: (0.0000) | Acc: (93.00%) (32299/34688)
Epoch: 106 | Batch_idx: 280 |  Loss: (0.1986) |  Loss2: (0.0000) | Acc: (93.00%) (33494/35968)
Epoch: 106 | Batch_idx: 290 |  Loss: (0.1982) |  Loss2: (0.0000) | Acc: (93.00%) (34691/37248)
Epoch: 106 | Batch_idx: 300 |  Loss: (0.1989) |  Loss2: (0.0000) | Acc: (93.00%) (35867/38528)
Epoch: 106 | Batch_idx: 310 |  Loss: (0.1988) |  Loss2: (0.0000) | Acc: (93.00%) (37062/39808)
Epoch: 106 | Batch_idx: 320 |  Loss: (0.1984) |  Loss2: (0.0000) | Acc: (93.00%) (38255/41088)
Epoch: 106 | Batch_idx: 330 |  Loss: (0.1978) |  Loss2: (0.0000) | Acc: (93.00%) (39463/42368)
Epoch: 106 | Batch_idx: 340 |  Loss: (0.1976) |  Loss2: (0.0000) | Acc: (93.00%) (40660/43648)
Epoch: 106 | Batch_idx: 350 |  Loss: (0.1986) |  Loss2: (0.0000) | Acc: (93.00%) (41837/44928)
Epoch: 106 | Batch_idx: 360 |  Loss: (0.1985) |  Loss2: (0.0000) | Acc: (93.00%) (43031/46208)
Epoch: 106 | Batch_idx: 370 |  Loss: (0.1986) |  Loss2: (0.0000) | Acc: (93.00%) (44223/47488)
Epoch: 106 | Batch_idx: 380 |  Loss: (0.1981) |  Loss2: (0.0000) | Acc: (93.00%) (45425/48768)
Epoch: 106 | Batch_idx: 390 |  Loss: (0.1981) |  Loss2: (0.0000) | Acc: (93.00%) (46578/50000)
# TEST : Loss: (0.3731) | Acc: (88.00%) (8807/10000)
percent tensor([0.5627, 0.5748, 0.5593, 0.5606, 0.5645, 0.5743, 0.5742, 0.5571, 0.5590,
        0.5667, 0.5691, 0.5667, 0.5655, 0.5586, 0.5791, 0.5672],
       device='cuda:0') torch.Size([16])
percent tensor([0.5132, 0.5124, 0.5078, 0.5113, 0.5081, 0.5200, 0.5092, 0.5076, 0.5078,
        0.5104, 0.5139, 0.5083, 0.5100, 0.5112, 0.5155, 0.5134],
       device='cuda:0') torch.Size([16])
percent tensor([0.5348, 0.4070, 0.6941, 0.6676, 0.6966, 0.6300, 0.5182, 0.6485, 0.5832,
        0.4849, 0.4348, 0.5951, 0.4387, 0.4917, 0.4894, 0.5794],
       device='cuda:0') torch.Size([16])
percent tensor([0.6932, 0.7339, 0.6034, 0.6496, 0.6169, 0.5739, 0.6852, 0.6248, 0.6981,
        0.7335, 0.7555, 0.6840, 0.7196, 0.7343, 0.6800, 0.6737],
       device='cuda:0') torch.Size([16])
percent tensor([0.7083, 0.5936, 0.7288, 0.7328, 0.7382, 0.7661, 0.6966, 0.7285, 0.6917,
        0.6037, 0.5924, 0.6235, 0.5825, 0.6587, 0.6926, 0.7217],
       device='cuda:0') torch.Size([16])
percent tensor([0.4997, 0.6064, 0.6717, 0.7132, 0.7060, 0.7409, 0.6396, 0.5273, 0.6518,
        0.5712, 0.6454, 0.6411, 0.5981, 0.6484, 0.4808, 0.5040],
       device='cuda:0') torch.Size([16])
percent tensor([0.4579, 0.6416, 0.6283, 0.6516, 0.6225, 0.5771, 0.5909, 0.5613, 0.6044,
        0.5835, 0.6644, 0.6502, 0.5705, 0.6247, 0.5431, 0.4357],
       device='cuda:0') torch.Size([16])
percent tensor([0.9997, 0.9995, 0.9997, 0.9998, 0.9999, 0.9988, 0.9997, 0.9997, 0.9996,
        0.9998, 0.9994, 0.9998, 0.9987, 0.9996, 0.9997, 0.9997],
       device='cuda:0') torch.Size([16])
Epoch: 107 | Batch_idx: 0 |  Loss: (0.1875) |  Loss2: (0.0000) | Acc: (92.00%) (119/128)
Epoch: 107 | Batch_idx: 10 |  Loss: (0.2008) |  Loss2: (0.0000) | Acc: (92.00%) (1300/1408)
Epoch: 107 | Batch_idx: 20 |  Loss: (0.1932) |  Loss2: (0.0000) | Acc: (93.00%) (2508/2688)
Epoch: 107 | Batch_idx: 30 |  Loss: (0.1914) |  Loss2: (0.0000) | Acc: (93.00%) (3706/3968)
Epoch: 107 | Batch_idx: 40 |  Loss: (0.1900) |  Loss2: (0.0000) | Acc: (93.00%) (4908/5248)
Epoch: 107 | Batch_idx: 50 |  Loss: (0.1910) |  Loss2: (0.0000) | Acc: (93.00%) (6099/6528)
Epoch: 107 | Batch_idx: 60 |  Loss: (0.1927) |  Loss2: (0.0000) | Acc: (93.00%) (7297/7808)
Epoch: 107 | Batch_idx: 70 |  Loss: (0.1896) |  Loss2: (0.0000) | Acc: (93.00%) (8511/9088)
Epoch: 107 | Batch_idx: 80 |  Loss: (0.1883) |  Loss2: (0.0000) | Acc: (93.00%) (9708/10368)
Epoch: 107 | Batch_idx: 90 |  Loss: (0.1863) |  Loss2: (0.0000) | Acc: (93.00%) (10925/11648)
Epoch: 107 | Batch_idx: 100 |  Loss: (0.1854) |  Loss2: (0.0000) | Acc: (93.00%) (12123/12928)
Epoch: 107 | Batch_idx: 110 |  Loss: (0.1860) |  Loss2: (0.0000) | Acc: (93.00%) (13315/14208)
Epoch: 107 | Batch_idx: 120 |  Loss: (0.1860) |  Loss2: (0.0000) | Acc: (93.00%) (14511/15488)
Epoch: 107 | Batch_idx: 130 |  Loss: (0.1850) |  Loss2: (0.0000) | Acc: (93.00%) (15716/16768)
Epoch: 107 | Batch_idx: 140 |  Loss: (0.1869) |  Loss2: (0.0000) | Acc: (93.00%) (16906/18048)
Epoch: 107 | Batch_idx: 150 |  Loss: (0.1878) |  Loss2: (0.0000) | Acc: (93.00%) (18093/19328)
Epoch: 107 | Batch_idx: 160 |  Loss: (0.1869) |  Loss2: (0.0000) | Acc: (93.00%) (19301/20608)
Epoch: 107 | Batch_idx: 170 |  Loss: (0.1872) |  Loss2: (0.0000) | Acc: (93.00%) (20501/21888)
Epoch: 107 | Batch_idx: 180 |  Loss: (0.1873) |  Loss2: (0.0000) | Acc: (93.00%) (21686/23168)
Epoch: 107 | Batch_idx: 190 |  Loss: (0.1868) |  Loss2: (0.0000) | Acc: (93.00%) (22894/24448)
Epoch: 107 | Batch_idx: 200 |  Loss: (0.1875) |  Loss2: (0.0000) | Acc: (93.00%) (24084/25728)
Epoch: 107 | Batch_idx: 210 |  Loss: (0.1880) |  Loss2: (0.0000) | Acc: (93.00%) (25286/27008)
Epoch: 107 | Batch_idx: 220 |  Loss: (0.1882) |  Loss2: (0.0000) | Acc: (93.00%) (26480/28288)
Epoch: 107 | Batch_idx: 230 |  Loss: (0.1884) |  Loss2: (0.0000) | Acc: (93.00%) (27681/29568)
Epoch: 107 | Batch_idx: 240 |  Loss: (0.1884) |  Loss2: (0.0000) | Acc: (93.00%) (28873/30848)
Epoch: 107 | Batch_idx: 250 |  Loss: (0.1882) |  Loss2: (0.0000) | Acc: (93.00%) (30074/32128)
Epoch: 107 | Batch_idx: 260 |  Loss: (0.1876) |  Loss2: (0.0000) | Acc: (93.00%) (31268/33408)
Epoch: 107 | Batch_idx: 270 |  Loss: (0.1869) |  Loss2: (0.0000) | Acc: (93.00%) (32479/34688)
Epoch: 107 | Batch_idx: 280 |  Loss: (0.1872) |  Loss2: (0.0000) | Acc: (93.00%) (33673/35968)
Epoch: 107 | Batch_idx: 290 |  Loss: (0.1875) |  Loss2: (0.0000) | Acc: (93.00%) (34867/37248)
Epoch: 107 | Batch_idx: 300 |  Loss: (0.1876) |  Loss2: (0.0000) | Acc: (93.00%) (36063/38528)
Epoch: 107 | Batch_idx: 310 |  Loss: (0.1885) |  Loss2: (0.0000) | Acc: (93.00%) (37250/39808)
Epoch: 107 | Batch_idx: 320 |  Loss: (0.1881) |  Loss2: (0.0000) | Acc: (93.00%) (38452/41088)
Epoch: 107 | Batch_idx: 330 |  Loss: (0.1870) |  Loss2: (0.0000) | Acc: (93.00%) (39673/42368)
Epoch: 107 | Batch_idx: 340 |  Loss: (0.1869) |  Loss2: (0.0000) | Acc: (93.00%) (40871/43648)
Epoch: 107 | Batch_idx: 350 |  Loss: (0.1863) |  Loss2: (0.0000) | Acc: (93.00%) (42083/44928)
Epoch: 107 | Batch_idx: 360 |  Loss: (0.1865) |  Loss2: (0.0000) | Acc: (93.00%) (43283/46208)
Epoch: 107 | Batch_idx: 370 |  Loss: (0.1866) |  Loss2: (0.0000) | Acc: (93.00%) (44482/47488)
Epoch: 107 | Batch_idx: 380 |  Loss: (0.1864) |  Loss2: (0.0000) | Acc: (93.00%) (45687/48768)
Epoch: 107 | Batch_idx: 390 |  Loss: (0.1865) |  Loss2: (0.0000) | Acc: (93.00%) (46840/50000)
# TEST : Loss: (0.3671) | Acc: (88.00%) (8818/10000)
percent tensor([0.5624, 0.5743, 0.5583, 0.5601, 0.5637, 0.5749, 0.5736, 0.5559, 0.5580,
        0.5659, 0.5687, 0.5656, 0.5650, 0.5573, 0.5793, 0.5670],
       device='cuda:0') torch.Size([16])
percent tensor([0.5131, 0.5124, 0.5076, 0.5112, 0.5084, 0.5201, 0.5095, 0.5075, 0.5077,
        0.5104, 0.5139, 0.5083, 0.5101, 0.5112, 0.5154, 0.5134],
       device='cuda:0') torch.Size([16])
percent tensor([0.5319, 0.4074, 0.6904, 0.6639, 0.6918, 0.6277, 0.5139, 0.6432, 0.5788,
        0.4857, 0.4343, 0.5919, 0.4401, 0.4866, 0.4875, 0.5799],
       device='cuda:0') torch.Size([16])
percent tensor([0.6928, 0.7344, 0.6000, 0.6473, 0.6116, 0.5706, 0.6838, 0.6205, 0.6981,
        0.7346, 0.7571, 0.6837, 0.7214, 0.7354, 0.6776, 0.6726],
       device='cuda:0') torch.Size([16])
percent tensor([0.7215, 0.6084, 0.7371, 0.7375, 0.7446, 0.7741, 0.7084, 0.7378, 0.6978,
        0.6175, 0.6039, 0.6307, 0.5922, 0.6647, 0.7069, 0.7329],
       device='cuda:0') torch.Size([16])
percent tensor([0.5012, 0.6156, 0.6786, 0.7189, 0.7171, 0.7484, 0.6480, 0.5333, 0.6566,
        0.5764, 0.6497, 0.6443, 0.6012, 0.6582, 0.4851, 0.5072],
       device='cuda:0') torch.Size([16])
percent tensor([0.4522, 0.6483, 0.6297, 0.6591, 0.6222, 0.5752, 0.5916, 0.5621, 0.6110,
        0.5875, 0.6706, 0.6546, 0.5742, 0.6411, 0.5411, 0.4287],
       device='cuda:0') torch.Size([16])
percent tensor([0.9997, 0.9995, 0.9996, 0.9998, 0.9999, 0.9988, 0.9997, 0.9997, 0.9996,
        0.9997, 0.9994, 0.9998, 0.9988, 0.9996, 0.9997, 0.9997],
       device='cuda:0') torch.Size([16])
True Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=128, out_features=16, bias=False)
False Linear(in_features=16, out_features=2, bias=False)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=128, out_features=16, bias=False)
False Linear(in_features=16, out_features=2, bias=False)
True Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=256, out_features=32, bias=False)
False Linear(in_features=32, out_features=2, bias=False)
True Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=256, out_features=32, bias=False)
False Linear(in_features=32, out_features=2, bias=False)
True Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=512, out_features=64, bias=False)
False Linear(in_features=64, out_features=2, bias=False)
True Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=512, out_features=64, bias=False)
False Linear(in_features=64, out_features=2, bias=False)
True Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1024, out_features=128, bias=False)
False Linear(in_features=128, out_features=2, bias=False)
True Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1024, out_features=128, bias=False)
False Linear(in_features=128, out_features=2, bias=False)
True Linear(in_features=512, out_features=10, bias=True)
Epoch: 108 | Batch_idx: 0 |  Loss: (0.1959) |  Loss2: (0.0000) | Acc: (91.00%) (117/128)
Epoch: 108 | Batch_idx: 10 |  Loss: (0.1927) |  Loss2: (0.0000) | Acc: (93.00%) (1316/1408)
Epoch: 108 | Batch_idx: 20 |  Loss: (0.1903) |  Loss2: (0.0000) | Acc: (93.00%) (2517/2688)
Epoch: 108 | Batch_idx: 30 |  Loss: (0.1960) |  Loss2: (0.0000) | Acc: (93.00%) (3705/3968)
Epoch: 108 | Batch_idx: 40 |  Loss: (0.1933) |  Loss2: (0.0000) | Acc: (93.00%) (4903/5248)
Epoch: 108 | Batch_idx: 50 |  Loss: (0.1930) |  Loss2: (0.0000) | Acc: (93.00%) (6096/6528)
Epoch: 108 | Batch_idx: 60 |  Loss: (0.1915) |  Loss2: (0.0000) | Acc: (93.00%) (7299/7808)
Epoch: 108 | Batch_idx: 70 |  Loss: (0.1907) |  Loss2: (0.0000) | Acc: (93.00%) (8497/9088)
Epoch: 108 | Batch_idx: 80 |  Loss: (0.1897) |  Loss2: (0.0000) | Acc: (93.00%) (9688/10368)
Epoch: 108 | Batch_idx: 90 |  Loss: (0.1898) |  Loss2: (0.0000) | Acc: (93.00%) (10881/11648)
Epoch: 108 | Batch_idx: 100 |  Loss: (0.1906) |  Loss2: (0.0000) | Acc: (93.00%) (12077/12928)
Epoch: 108 | Batch_idx: 110 |  Loss: (0.1895) |  Loss2: (0.0000) | Acc: (93.00%) (13284/14208)
Epoch: 108 | Batch_idx: 120 |  Loss: (0.1907) |  Loss2: (0.0000) | Acc: (93.00%) (14476/15488)
Epoch: 108 | Batch_idx: 130 |  Loss: (0.1929) |  Loss2: (0.0000) | Acc: (93.00%) (15655/16768)
Epoch: 108 | Batch_idx: 140 |  Loss: (0.1921) |  Loss2: (0.0000) | Acc: (93.00%) (16858/18048)
Epoch: 108 | Batch_idx: 150 |  Loss: (0.1939) |  Loss2: (0.0000) | Acc: (93.00%) (18052/19328)
Epoch: 108 | Batch_idx: 160 |  Loss: (0.1939) |  Loss2: (0.0000) | Acc: (93.00%) (19252/20608)
Epoch: 108 | Batch_idx: 170 |  Loss: (0.1952) |  Loss2: (0.0000) | Acc: (93.00%) (20432/21888)
Epoch: 108 | Batch_idx: 180 |  Loss: (0.1952) |  Loss2: (0.0000) | Acc: (93.00%) (21630/23168)
Epoch: 108 | Batch_idx: 190 |  Loss: (0.1954) |  Loss2: (0.0000) | Acc: (93.00%) (22832/24448)
Epoch: 108 | Batch_idx: 200 |  Loss: (0.1958) |  Loss2: (0.0000) | Acc: (93.00%) (24024/25728)
Epoch: 108 | Batch_idx: 210 |  Loss: (0.1954) |  Loss2: (0.0000) | Acc: (93.00%) (25229/27008)
Epoch: 108 | Batch_idx: 220 |  Loss: (0.1944) |  Loss2: (0.0000) | Acc: (93.00%) (26436/28288)
Epoch: 108 | Batch_idx: 230 |  Loss: (0.1939) |  Loss2: (0.0000) | Acc: (93.00%) (27633/29568)
Epoch: 108 | Batch_idx: 240 |  Loss: (0.1937) |  Loss2: (0.0000) | Acc: (93.00%) (28826/30848)
Epoch: 108 | Batch_idx: 250 |  Loss: (0.1947) |  Loss2: (0.0000) | Acc: (93.00%) (30016/32128)
Epoch: 108 | Batch_idx: 260 |  Loss: (0.1935) |  Loss2: (0.0000) | Acc: (93.00%) (31230/33408)
Epoch: 108 | Batch_idx: 270 |  Loss: (0.1938) |  Loss2: (0.0000) | Acc: (93.00%) (32416/34688)
Epoch: 108 | Batch_idx: 280 |  Loss: (0.1936) |  Loss2: (0.0000) | Acc: (93.00%) (33607/35968)
Epoch: 108 | Batch_idx: 290 |  Loss: (0.1933) |  Loss2: (0.0000) | Acc: (93.00%) (34808/37248)
Epoch: 108 | Batch_idx: 300 |  Loss: (0.1937) |  Loss2: (0.0000) | Acc: (93.00%) (36001/38528)
Epoch: 108 | Batch_idx: 310 |  Loss: (0.1943) |  Loss2: (0.0000) | Acc: (93.00%) (37182/39808)
Epoch: 108 | Batch_idx: 320 |  Loss: (0.1939) |  Loss2: (0.0000) | Acc: (93.00%) (38381/41088)
Epoch: 108 | Batch_idx: 330 |  Loss: (0.1944) |  Loss2: (0.0000) | Acc: (93.00%) (39572/42368)
Epoch: 108 | Batch_idx: 340 |  Loss: (0.1944) |  Loss2: (0.0000) | Acc: (93.00%) (40773/43648)
Epoch: 108 | Batch_idx: 350 |  Loss: (0.1943) |  Loss2: (0.0000) | Acc: (93.00%) (41974/44928)
Epoch: 108 | Batch_idx: 360 |  Loss: (0.1948) |  Loss2: (0.0000) | Acc: (93.00%) (43159/46208)
Epoch: 108 | Batch_idx: 370 |  Loss: (0.1952) |  Loss2: (0.0000) | Acc: (93.00%) (44347/47488)
Epoch: 108 | Batch_idx: 380 |  Loss: (0.1959) |  Loss2: (0.0000) | Acc: (93.00%) (45534/48768)
Epoch: 108 | Batch_idx: 390 |  Loss: (0.1961) |  Loss2: (0.0000) | Acc: (93.00%) (46681/50000)
# TEST : Loss: (0.4018) | Acc: (87.00%) (8730/10000)
percent tensor([0.5627, 0.5723, 0.5609, 0.5602, 0.5655, 0.5747, 0.5733, 0.5567, 0.5578,
        0.5660, 0.5677, 0.5673, 0.5647, 0.5565, 0.5776, 0.5667],
       device='cuda:0') torch.Size([16])
percent tensor([0.5130, 0.5128, 0.5076, 0.5110, 0.5082, 0.5199, 0.5098, 0.5070, 0.5081,
        0.5106, 0.5139, 0.5082, 0.5101, 0.5115, 0.5154, 0.5134],
       device='cuda:0') torch.Size([16])
percent tensor([0.5404, 0.4104, 0.6857, 0.6780, 0.6890, 0.6408, 0.5120, 0.6505, 0.5740,
        0.4830, 0.4455, 0.5889, 0.4442, 0.4749, 0.4939, 0.5906],
       device='cuda:0') torch.Size([16])
percent tensor([0.6882, 0.7379, 0.6004, 0.6408, 0.6097, 0.5721, 0.6874, 0.6174, 0.6971,
        0.7376, 0.7525, 0.6833, 0.7154, 0.7387, 0.6847, 0.6697],
       device='cuda:0') torch.Size([16])
percent tensor([0.7192, 0.6169, 0.7272, 0.7186, 0.7363, 0.7699, 0.7039, 0.7293, 0.6820,
        0.6089, 0.6005, 0.6218, 0.5891, 0.6551, 0.7023, 0.7279],
       device='cuda:0') torch.Size([16])
percent tensor([0.4822, 0.5877, 0.6513, 0.7266, 0.7015, 0.7355, 0.6203, 0.4803, 0.6426,
        0.5633, 0.6277, 0.6098, 0.5730, 0.6631, 0.4374, 0.4814],
       device='cuda:0') torch.Size([16])
percent tensor([0.4487, 0.6278, 0.6167, 0.6493, 0.6056, 0.5554, 0.5834, 0.5381, 0.6217,
        0.5932, 0.6677, 0.6476, 0.5765, 0.6478, 0.5226, 0.4246],
       device='cuda:0') torch.Size([16])
percent tensor([0.9998, 0.9994, 0.9997, 0.9998, 0.9999, 0.9994, 0.9995, 0.9998, 0.9996,
        0.9998, 0.9990, 0.9998, 0.9986, 0.9990, 0.9997, 0.9997],
       device='cuda:0') torch.Size([16])
Epoch: 109 | Batch_idx: 0 |  Loss: (0.2035) |  Loss2: (0.0000) | Acc: (93.00%) (120/128)
Epoch: 109 | Batch_idx: 10 |  Loss: (0.2059) |  Loss2: (0.0000) | Acc: (92.00%) (1307/1408)
Epoch: 109 | Batch_idx: 20 |  Loss: (0.1990) |  Loss2: (0.0000) | Acc: (93.00%) (2501/2688)
Epoch: 109 | Batch_idx: 30 |  Loss: (0.1895) |  Loss2: (0.0000) | Acc: (93.00%) (3707/3968)
Epoch: 109 | Batch_idx: 40 |  Loss: (0.1906) |  Loss2: (0.0000) | Acc: (93.00%) (4905/5248)
Epoch: 109 | Batch_idx: 50 |  Loss: (0.1890) |  Loss2: (0.0000) | Acc: (93.00%) (6100/6528)
Epoch: 109 | Batch_idx: 60 |  Loss: (0.1906) |  Loss2: (0.0000) | Acc: (93.00%) (7295/7808)
Epoch: 109 | Batch_idx: 70 |  Loss: (0.1913) |  Loss2: (0.0000) | Acc: (93.00%) (8494/9088)
Epoch: 109 | Batch_idx: 80 |  Loss: (0.1930) |  Loss2: (0.0000) | Acc: (93.00%) (9682/10368)
Epoch: 109 | Batch_idx: 90 |  Loss: (0.1902) |  Loss2: (0.0000) | Acc: (93.00%) (10896/11648)
Epoch: 109 | Batch_idx: 100 |  Loss: (0.1893) |  Loss2: (0.0000) | Acc: (93.00%) (12097/12928)
Epoch: 109 | Batch_idx: 110 |  Loss: (0.1899) |  Loss2: (0.0000) | Acc: (93.00%) (13292/14208)
Epoch: 109 | Batch_idx: 120 |  Loss: (0.1894) |  Loss2: (0.0000) | Acc: (93.00%) (14487/15488)
Epoch: 109 | Batch_idx: 130 |  Loss: (0.1879) |  Loss2: (0.0000) | Acc: (93.00%) (15691/16768)
Epoch: 109 | Batch_idx: 140 |  Loss: (0.1883) |  Loss2: (0.0000) | Acc: (93.00%) (16889/18048)
Epoch: 109 | Batch_idx: 150 |  Loss: (0.1873) |  Loss2: (0.0000) | Acc: (93.00%) (18095/19328)
Epoch: 109 | Batch_idx: 160 |  Loss: (0.1869) |  Loss2: (0.0000) | Acc: (93.00%) (19299/20608)
Epoch: 109 | Batch_idx: 170 |  Loss: (0.1875) |  Loss2: (0.0000) | Acc: (93.00%) (20499/21888)
Epoch: 109 | Batch_idx: 180 |  Loss: (0.1886) |  Loss2: (0.0000) | Acc: (93.00%) (21687/23168)
Epoch: 109 | Batch_idx: 190 |  Loss: (0.1884) |  Loss2: (0.0000) | Acc: (93.00%) (22885/24448)
Epoch: 109 | Batch_idx: 200 |  Loss: (0.1884) |  Loss2: (0.0000) | Acc: (93.00%) (24091/25728)
Epoch: 109 | Batch_idx: 210 |  Loss: (0.1878) |  Loss2: (0.0000) | Acc: (93.00%) (25296/27008)
Epoch: 109 | Batch_idx: 220 |  Loss: (0.1872) |  Loss2: (0.0000) | Acc: (93.00%) (26506/28288)
Epoch: 109 | Batch_idx: 230 |  Loss: (0.1876) |  Loss2: (0.0000) | Acc: (93.00%) (27710/29568)
Epoch: 109 | Batch_idx: 240 |  Loss: (0.1884) |  Loss2: (0.0000) | Acc: (93.00%) (28899/30848)
Epoch: 109 | Batch_idx: 250 |  Loss: (0.1885) |  Loss2: (0.0000) | Acc: (93.00%) (30096/32128)
Epoch: 109 | Batch_idx: 260 |  Loss: (0.1894) |  Loss2: (0.0000) | Acc: (93.00%) (31278/33408)
Epoch: 109 | Batch_idx: 270 |  Loss: (0.1886) |  Loss2: (0.0000) | Acc: (93.00%) (32488/34688)
Epoch: 109 | Batch_idx: 280 |  Loss: (0.1883) |  Loss2: (0.0000) | Acc: (93.00%) (33690/35968)
Epoch: 109 | Batch_idx: 290 |  Loss: (0.1887) |  Loss2: (0.0000) | Acc: (93.00%) (34881/37248)
Epoch: 109 | Batch_idx: 300 |  Loss: (0.1888) |  Loss2: (0.0000) | Acc: (93.00%) (36083/38528)
Epoch: 109 | Batch_idx: 310 |  Loss: (0.1889) |  Loss2: (0.0000) | Acc: (93.00%) (37282/39808)
Epoch: 109 | Batch_idx: 320 |  Loss: (0.1897) |  Loss2: (0.0000) | Acc: (93.00%) (38457/41088)
Epoch: 109 | Batch_idx: 330 |  Loss: (0.1900) |  Loss2: (0.0000) | Acc: (93.00%) (39654/42368)
Epoch: 109 | Batch_idx: 340 |  Loss: (0.1903) |  Loss2: (0.0000) | Acc: (93.00%) (40839/43648)
Epoch: 109 | Batch_idx: 350 |  Loss: (0.1906) |  Loss2: (0.0000) | Acc: (93.00%) (42024/44928)
Epoch: 109 | Batch_idx: 360 |  Loss: (0.1913) |  Loss2: (0.0000) | Acc: (93.00%) (43211/46208)
Epoch: 109 | Batch_idx: 370 |  Loss: (0.1912) |  Loss2: (0.0000) | Acc: (93.00%) (44420/47488)
Epoch: 109 | Batch_idx: 380 |  Loss: (0.1912) |  Loss2: (0.0000) | Acc: (93.00%) (45616/48768)
Epoch: 109 | Batch_idx: 390 |  Loss: (0.1915) |  Loss2: (0.0000) | Acc: (93.00%) (46763/50000)
# TEST : Loss: (0.4931) | Acc: (84.00%) (8456/10000)
percent tensor([0.5627, 0.5715, 0.5608, 0.5595, 0.5656, 0.5743, 0.5727, 0.5564, 0.5579,
        0.5658, 0.5680, 0.5674, 0.5649, 0.5551, 0.5771, 0.5661],
       device='cuda:0') torch.Size([16])
percent tensor([0.5126, 0.5124, 0.5073, 0.5111, 0.5074, 0.5192, 0.5091, 0.5070, 0.5080,
        0.5102, 0.5135, 0.5076, 0.5100, 0.5109, 0.5148, 0.5130],
       device='cuda:0') torch.Size([16])
percent tensor([0.5266, 0.4158, 0.6755, 0.6741, 0.6793, 0.6336, 0.5134, 0.6518, 0.5613,
        0.4896, 0.4383, 0.5743, 0.4358, 0.4932, 0.4959, 0.5886],
       device='cuda:0') torch.Size([16])
percent tensor([0.6983, 0.7395, 0.6003, 0.6382, 0.6192, 0.5620, 0.6905, 0.6142, 0.7086,
        0.7361, 0.7638, 0.6937, 0.7280, 0.7487, 0.6798, 0.6697],
       device='cuda:0') torch.Size([16])
percent tensor([0.7149, 0.6165, 0.7174, 0.7268, 0.7305, 0.7741, 0.7064, 0.7283, 0.6735,
        0.6088, 0.5939, 0.6089, 0.5681, 0.6615, 0.7053, 0.7266],
       device='cuda:0') torch.Size([16])
percent tensor([0.5304, 0.6281, 0.6962, 0.7300, 0.7092, 0.7609, 0.6421, 0.5252, 0.6694,
        0.6047, 0.6592, 0.6368, 0.6022, 0.6930, 0.5189, 0.5273],
       device='cuda:0') torch.Size([16])
percent tensor([0.4783, 0.6591, 0.6613, 0.6589, 0.6237, 0.6138, 0.6057, 0.5669, 0.6648,
        0.6219, 0.6783, 0.6677, 0.6053, 0.6701, 0.5519, 0.4461],
       device='cuda:0') torch.Size([16])
percent tensor([0.9997, 0.9994, 0.9996, 0.9998, 0.9999, 0.9989, 0.9998, 0.9998, 0.9997,
        0.9998, 0.9994, 0.9998, 0.9991, 0.9992, 0.9996, 0.9997],
       device='cuda:0') torch.Size([16])
Epoch: 110 | Batch_idx: 0 |  Loss: (0.1844) |  Loss2: (0.0000) | Acc: (93.00%) (120/128)
Epoch: 110 | Batch_idx: 10 |  Loss: (0.1869) |  Loss2: (0.0000) | Acc: (93.00%) (1313/1408)
Epoch: 110 | Batch_idx: 20 |  Loss: (0.1906) |  Loss2: (0.0000) | Acc: (93.00%) (2501/2688)
Epoch: 110 | Batch_idx: 30 |  Loss: (0.1870) |  Loss2: (0.0000) | Acc: (93.00%) (3692/3968)
Epoch: 110 | Batch_idx: 40 |  Loss: (0.1804) |  Loss2: (0.0000) | Acc: (93.00%) (4900/5248)
Epoch: 110 | Batch_idx: 50 |  Loss: (0.1837) |  Loss2: (0.0000) | Acc: (93.00%) (6092/6528)
Epoch: 110 | Batch_idx: 60 |  Loss: (0.1904) |  Loss2: (0.0000) | Acc: (93.00%) (7272/7808)
Epoch: 110 | Batch_idx: 70 |  Loss: (0.1879) |  Loss2: (0.0000) | Acc: (93.00%) (8470/9088)
Epoch: 110 | Batch_idx: 80 |  Loss: (0.1908) |  Loss2: (0.0000) | Acc: (93.00%) (9662/10368)
Epoch: 110 | Batch_idx: 90 |  Loss: (0.1892) |  Loss2: (0.0000) | Acc: (93.00%) (10861/11648)
Epoch: 110 | Batch_idx: 100 |  Loss: (0.1857) |  Loss2: (0.0000) | Acc: (93.00%) (12085/12928)
Epoch: 110 | Batch_idx: 110 |  Loss: (0.1857) |  Loss2: (0.0000) | Acc: (93.00%) (13288/14208)
Epoch: 110 | Batch_idx: 120 |  Loss: (0.1867) |  Loss2: (0.0000) | Acc: (93.00%) (14481/15488)
Epoch: 110 | Batch_idx: 130 |  Loss: (0.1861) |  Loss2: (0.0000) | Acc: (93.00%) (15686/16768)
Epoch: 110 | Batch_idx: 140 |  Loss: (0.1864) |  Loss2: (0.0000) | Acc: (93.00%) (16887/18048)
Epoch: 110 | Batch_idx: 150 |  Loss: (0.1876) |  Loss2: (0.0000) | Acc: (93.00%) (18080/19328)
Epoch: 110 | Batch_idx: 160 |  Loss: (0.1864) |  Loss2: (0.0000) | Acc: (93.00%) (19291/20608)
Epoch: 110 | Batch_idx: 170 |  Loss: (0.1851) |  Loss2: (0.0000) | Acc: (93.00%) (20501/21888)
Epoch: 110 | Batch_idx: 180 |  Loss: (0.1858) |  Loss2: (0.0000) | Acc: (93.00%) (21684/23168)
Epoch: 110 | Batch_idx: 190 |  Loss: (0.1854) |  Loss2: (0.0000) | Acc: (93.00%) (22890/24448)
Epoch: 110 | Batch_idx: 200 |  Loss: (0.1862) |  Loss2: (0.0000) | Acc: (93.00%) (24082/25728)
Epoch: 110 | Batch_idx: 210 |  Loss: (0.1862) |  Loss2: (0.0000) | Acc: (93.00%) (25277/27008)
Epoch: 110 | Batch_idx: 220 |  Loss: (0.1855) |  Loss2: (0.0000) | Acc: (93.00%) (26478/28288)
Epoch: 110 | Batch_idx: 230 |  Loss: (0.1874) |  Loss2: (0.0000) | Acc: (93.00%) (27653/29568)
Epoch: 110 | Batch_idx: 240 |  Loss: (0.1880) |  Loss2: (0.0000) | Acc: (93.00%) (28831/30848)
Epoch: 110 | Batch_idx: 250 |  Loss: (0.1871) |  Loss2: (0.0000) | Acc: (93.00%) (30039/32128)
Epoch: 110 | Batch_idx: 260 |  Loss: (0.1876) |  Loss2: (0.0000) | Acc: (93.00%) (31232/33408)
Epoch: 110 | Batch_idx: 270 |  Loss: (0.1876) |  Loss2: (0.0000) | Acc: (93.00%) (32430/34688)
Epoch: 110 | Batch_idx: 280 |  Loss: (0.1868) |  Loss2: (0.0000) | Acc: (93.00%) (33644/35968)
Epoch: 110 | Batch_idx: 290 |  Loss: (0.1873) |  Loss2: (0.0000) | Acc: (93.00%) (34830/37248)
Epoch: 110 | Batch_idx: 300 |  Loss: (0.1877) |  Loss2: (0.0000) | Acc: (93.00%) (36024/38528)
Epoch: 110 | Batch_idx: 310 |  Loss: (0.1882) |  Loss2: (0.0000) | Acc: (93.00%) (37217/39808)
Epoch: 110 | Batch_idx: 320 |  Loss: (0.1890) |  Loss2: (0.0000) | Acc: (93.00%) (38400/41088)
Epoch: 110 | Batch_idx: 330 |  Loss: (0.1888) |  Loss2: (0.0000) | Acc: (93.00%) (39599/42368)
Epoch: 110 | Batch_idx: 340 |  Loss: (0.1898) |  Loss2: (0.0000) | Acc: (93.00%) (40775/43648)
Epoch: 110 | Batch_idx: 350 |  Loss: (0.1900) |  Loss2: (0.0000) | Acc: (93.00%) (41973/44928)
Epoch: 110 | Batch_idx: 360 |  Loss: (0.1895) |  Loss2: (0.0000) | Acc: (93.00%) (43180/46208)
Epoch: 110 | Batch_idx: 370 |  Loss: (0.1892) |  Loss2: (0.0000) | Acc: (93.00%) (44381/47488)
Epoch: 110 | Batch_idx: 380 |  Loss: (0.1893) |  Loss2: (0.0000) | Acc: (93.00%) (45587/48768)
Epoch: 110 | Batch_idx: 390 |  Loss: (0.1894) |  Loss2: (0.0000) | Acc: (93.00%) (46733/50000)
=> saving checkpoint 'drive/app/torch/save_Schedule/checkpoint_110.pth.tar'
# TEST : Loss: (0.4610) | Acc: (85.00%) (8592/10000)
percent tensor([0.5629, 0.5717, 0.5613, 0.5592, 0.5659, 0.5748, 0.5733, 0.5563, 0.5578,
        0.5667, 0.5685, 0.5678, 0.5651, 0.5567, 0.5773, 0.5657],
       device='cuda:0') torch.Size([16])
percent tensor([0.5128, 0.5125, 0.5071, 0.5111, 0.5080, 0.5192, 0.5094, 0.5070, 0.5083,
        0.5102, 0.5137, 0.5074, 0.5101, 0.5120, 0.5151, 0.5137],
       device='cuda:0') torch.Size([16])
percent tensor([0.5378, 0.4190, 0.6777, 0.6649, 0.6880, 0.6477, 0.5277, 0.6458, 0.5786,
        0.4927, 0.4475, 0.5913, 0.4469, 0.4813, 0.5063, 0.5919],
       device='cuda:0') torch.Size([16])
percent tensor([0.6877, 0.7321, 0.5976, 0.6402, 0.5937, 0.5508, 0.6785, 0.6185, 0.6921,
        0.7307, 0.7505, 0.6783, 0.7143, 0.7353, 0.6740, 0.6603],
       device='cuda:0') torch.Size([16])
percent tensor([0.7202, 0.6331, 0.7344, 0.7334, 0.7407, 0.7649, 0.7106, 0.7362, 0.6829,
        0.6272, 0.6059, 0.6379, 0.5951, 0.6774, 0.7037, 0.7357],
       device='cuda:0') torch.Size([16])
percent tensor([0.5210, 0.6182, 0.6622, 0.7139, 0.7193, 0.7499, 0.6447, 0.5083, 0.6503,
        0.5917, 0.6405, 0.6164, 0.6094, 0.6886, 0.4745, 0.5394],
       device='cuda:0') torch.Size([16])
percent tensor([0.4811, 0.6569, 0.6383, 0.6712, 0.6318, 0.6142, 0.6055, 0.5587, 0.6678,
        0.6288, 0.6903, 0.6610, 0.6173, 0.6673, 0.5512, 0.4428],
       device='cuda:0') torch.Size([16])
percent tensor([0.9997, 0.9995, 0.9995, 0.9999, 0.9999, 0.9988, 0.9997, 0.9998, 0.9997,
        0.9998, 0.9996, 0.9997, 0.9991, 0.9993, 0.9998, 0.9996],
       device='cuda:0') torch.Size([16])
False Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=128, out_features=16, bias=False)
True Linear(in_features=16, out_features=2, bias=False)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=128, out_features=16, bias=False)
True Linear(in_features=16, out_features=2, bias=False)
False Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=256, out_features=32, bias=False)
True Linear(in_features=32, out_features=2, bias=False)
False Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=256, out_features=32, bias=False)
True Linear(in_features=32, out_features=2, bias=False)
False Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=512, out_features=64, bias=False)
True Linear(in_features=64, out_features=2, bias=False)
False Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=512, out_features=64, bias=False)
True Linear(in_features=64, out_features=2, bias=False)
False Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1024, out_features=128, bias=False)
True Linear(in_features=128, out_features=2, bias=False)
False Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1024, out_features=128, bias=False)
True Linear(in_features=128, out_features=2, bias=False)
False Linear(in_features=512, out_features=10, bias=True)
Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 3, 3, 3]) tensor(182.0239, device='cuda:0')
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(811.9009, device='cuda:0')
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(817.6279, device='cuda:0')
Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([128, 64, 3, 3]) tensor(1519.1036, device='cuda:0')
Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([128, 64, 1, 1]) tensor(497.8355, device='cuda:0')
Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([128, 128, 3, 3]) tensor(2244.5889, device='cuda:0')
Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([256, 128, 3, 3]) tensor(4290.1226, device='cuda:0')
Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([256, 128, 1, 1]) tensor(1397.9020, device='cuda:0')
Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([256, 256, 3, 3]) tensor(6164.7910, device='cuda:0')
Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([512, 256, 3, 3]) tensor(11844.4756, device='cuda:0')
Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([512, 256, 1, 1]) tensor(3927.8630, device='cuda:0')
Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([512, 512, 3, 3]) tensor(16564.6035, device='cuda:0')
Epoch: 111 | Batch_idx: 0 |  Loss: (0.1186) |  Loss2: (0.0000) | Acc: (97.00%) (125/128)
Epoch: 111 | Batch_idx: 10 |  Loss: (0.1905) |  Loss2: (0.0000) | Acc: (93.00%) (1318/1408)
Epoch: 111 | Batch_idx: 20 |  Loss: (0.2085) |  Loss2: (0.0000) | Acc: (92.00%) (2493/2688)
Epoch: 111 | Batch_idx: 30 |  Loss: (0.2157) |  Loss2: (0.0000) | Acc: (92.00%) (3664/3968)
Epoch: 111 | Batch_idx: 40 |  Loss: (0.2215) |  Loss2: (0.0000) | Acc: (92.00%) (4838/5248)
Epoch: 111 | Batch_idx: 50 |  Loss: (0.2265) |  Loss2: (0.0000) | Acc: (92.00%) (6014/6528)
Epoch: 111 | Batch_idx: 60 |  Loss: (0.2169) |  Loss2: (0.0000) | Acc: (92.00%) (7217/7808)
Epoch: 111 | Batch_idx: 70 |  Loss: (0.2189) |  Loss2: (0.0000) | Acc: (92.00%) (8393/9088)
Epoch: 111 | Batch_idx: 80 |  Loss: (0.2218) |  Loss2: (0.0000) | Acc: (92.00%) (9577/10368)
Epoch: 111 | Batch_idx: 90 |  Loss: (0.2238) |  Loss2: (0.0000) | Acc: (92.00%) (10740/11648)
Epoch: 111 | Batch_idx: 100 |  Loss: (0.2208) |  Loss2: (0.0000) | Acc: (92.00%) (11929/12928)
Epoch: 111 | Batch_idx: 110 |  Loss: (0.2222) |  Loss2: (0.0000) | Acc: (92.00%) (13106/14208)
Epoch: 111 | Batch_idx: 120 |  Loss: (0.2181) |  Loss2: (0.0000) | Acc: (92.00%) (14313/15488)
Epoch: 111 | Batch_idx: 130 |  Loss: (0.2200) |  Loss2: (0.0000) | Acc: (92.00%) (15483/16768)
Epoch: 111 | Batch_idx: 140 |  Loss: (0.2204) |  Loss2: (0.0000) | Acc: (92.00%) (16659/18048)
Epoch: 111 | Batch_idx: 150 |  Loss: (0.2192) |  Loss2: (0.0000) | Acc: (92.00%) (17838/19328)
Epoch: 111 | Batch_idx: 160 |  Loss: (0.2186) |  Loss2: (0.0000) | Acc: (92.00%) (19022/20608)
Epoch: 111 | Batch_idx: 170 |  Loss: (0.2181) |  Loss2: (0.0000) | Acc: (92.00%) (20207/21888)
Epoch: 111 | Batch_idx: 180 |  Loss: (0.2162) |  Loss2: (0.0000) | Acc: (92.00%) (21398/23168)
Epoch: 111 | Batch_idx: 190 |  Loss: (0.2162) |  Loss2: (0.0000) | Acc: (92.00%) (22576/24448)
Epoch: 111 | Batch_idx: 200 |  Loss: (0.2152) |  Loss2: (0.0000) | Acc: (92.00%) (23768/25728)
Epoch: 111 | Batch_idx: 210 |  Loss: (0.2156) |  Loss2: (0.0000) | Acc: (92.00%) (24942/27008)
Epoch: 111 | Batch_idx: 220 |  Loss: (0.2150) |  Loss2: (0.0000) | Acc: (92.00%) (26130/28288)
Epoch: 111 | Batch_idx: 230 |  Loss: (0.2148) |  Loss2: (0.0000) | Acc: (92.00%) (27321/29568)
Epoch: 111 | Batch_idx: 240 |  Loss: (0.2144) |  Loss2: (0.0000) | Acc: (92.00%) (28508/30848)
Epoch: 111 | Batch_idx: 250 |  Loss: (0.2142) |  Loss2: (0.0000) | Acc: (92.00%) (29693/32128)
Epoch: 111 | Batch_idx: 260 |  Loss: (0.2147) |  Loss2: (0.0000) | Acc: (92.00%) (30866/33408)
Epoch: 111 | Batch_idx: 270 |  Loss: (0.2147) |  Loss2: (0.0000) | Acc: (92.00%) (32052/34688)
Epoch: 111 | Batch_idx: 280 |  Loss: (0.2146) |  Loss2: (0.0000) | Acc: (92.00%) (33236/35968)
Epoch: 111 | Batch_idx: 290 |  Loss: (0.2141) |  Loss2: (0.0000) | Acc: (92.00%) (34428/37248)
Epoch: 111 | Batch_idx: 300 |  Loss: (0.2134) |  Loss2: (0.0000) | Acc: (92.00%) (35628/38528)
Epoch: 111 | Batch_idx: 310 |  Loss: (0.2126) |  Loss2: (0.0000) | Acc: (92.00%) (36823/39808)
Epoch: 111 | Batch_idx: 320 |  Loss: (0.2116) |  Loss2: (0.0000) | Acc: (92.00%) (38029/41088)
Epoch: 111 | Batch_idx: 330 |  Loss: (0.2121) |  Loss2: (0.0000) | Acc: (92.00%) (39207/42368)
Epoch: 111 | Batch_idx: 340 |  Loss: (0.2122) |  Loss2: (0.0000) | Acc: (92.00%) (40394/43648)
Epoch: 111 | Batch_idx: 350 |  Loss: (0.2117) |  Loss2: (0.0000) | Acc: (92.00%) (41576/44928)
Epoch: 111 | Batch_idx: 360 |  Loss: (0.2115) |  Loss2: (0.0000) | Acc: (92.00%) (42769/46208)
Epoch: 111 | Batch_idx: 370 |  Loss: (0.2115) |  Loss2: (0.0000) | Acc: (92.00%) (43965/47488)
Epoch: 111 | Batch_idx: 380 |  Loss: (0.2107) |  Loss2: (0.0000) | Acc: (92.00%) (45164/48768)
Epoch: 111 | Batch_idx: 390 |  Loss: (0.2101) |  Loss2: (0.0000) | Acc: (92.00%) (46308/50000)
# TEST : Loss: (0.3993) | Acc: (87.00%) (8755/10000)
percent tensor([0.5648, 0.5724, 0.5640, 0.5612, 0.5681, 0.5763, 0.5747, 0.5580, 0.5593,
        0.5682, 0.5699, 0.5700, 0.5666, 0.5563, 0.5791, 0.5673],
       device='cuda:0') torch.Size([16])
percent tensor([0.5137, 0.5130, 0.5079, 0.5121, 0.5076, 0.5214, 0.5084, 0.5069, 0.5086,
        0.5110, 0.5143, 0.5084, 0.5103, 0.5126, 0.5157, 0.5148],
       device='cuda:0') torch.Size([16])
percent tensor([0.5439, 0.4253, 0.6821, 0.6751, 0.6937, 0.6523, 0.5318, 0.6550, 0.5873,
        0.5097, 0.4561, 0.6022, 0.4571, 0.4915, 0.5104, 0.6022],
       device='cuda:0') torch.Size([16])
percent tensor([0.6899, 0.7342, 0.6076, 0.6486, 0.5970, 0.5484, 0.6829, 0.6231, 0.6986,
        0.7323, 0.7527, 0.6818, 0.7161, 0.7384, 0.6742, 0.6649],
       device='cuda:0') torch.Size([16])
percent tensor([0.6793, 0.5953, 0.7005, 0.6911, 0.7033, 0.7318, 0.6719, 0.6918, 0.6434,
        0.5978, 0.5734, 0.6053, 0.5649, 0.6311, 0.6639, 0.6942],
       device='cuda:0') torch.Size([16])
percent tensor([0.5367, 0.6217, 0.6828, 0.7343, 0.7354, 0.7673, 0.6519, 0.5269, 0.6624,
        0.6050, 0.6591, 0.6401, 0.6173, 0.7067, 0.4977, 0.5487],
       device='cuda:0') torch.Size([16])
percent tensor([0.4352, 0.5906, 0.5848, 0.6323, 0.5935, 0.5534, 0.5488, 0.5343, 0.5992,
        0.5481, 0.6275, 0.5910, 0.5243, 0.6290, 0.5110, 0.4166],
       device='cuda:0') torch.Size([16])
percent tensor([0.9998, 0.9994, 0.9998, 0.9999, 0.9999, 0.9988, 0.9997, 0.9998, 0.9996,
        0.9998, 0.9995, 0.9997, 0.9990, 0.9993, 0.9997, 0.9997],
       device='cuda:0') torch.Size([16])
Epoch: 112 | Batch_idx: 0 |  Loss: (0.1834) |  Loss2: (0.0000) | Acc: (93.00%) (120/128)
Epoch: 112 | Batch_idx: 10 |  Loss: (0.1804) |  Loss2: (0.0000) | Acc: (93.00%) (1323/1408)
Epoch: 112 | Batch_idx: 20 |  Loss: (0.1924) |  Loss2: (0.0000) | Acc: (93.00%) (2514/2688)
Epoch: 112 | Batch_idx: 30 |  Loss: (0.1911) |  Loss2: (0.0000) | Acc: (93.00%) (3713/3968)
Epoch: 112 | Batch_idx: 40 |  Loss: (0.1945) |  Loss2: (0.0000) | Acc: (93.00%) (4908/5248)
Epoch: 112 | Batch_idx: 50 |  Loss: (0.1954) |  Loss2: (0.0000) | Acc: (93.00%) (6108/6528)
Epoch: 112 | Batch_idx: 60 |  Loss: (0.1943) |  Loss2: (0.0000) | Acc: (93.00%) (7312/7808)
Epoch: 112 | Batch_idx: 70 |  Loss: (0.1939) |  Loss2: (0.0000) | Acc: (93.00%) (8512/9088)
Epoch: 112 | Batch_idx: 80 |  Loss: (0.1969) |  Loss2: (0.0000) | Acc: (93.00%) (9687/10368)
Epoch: 112 | Batch_idx: 90 |  Loss: (0.1959) |  Loss2: (0.0000) | Acc: (93.00%) (10883/11648)
Epoch: 112 | Batch_idx: 100 |  Loss: (0.1924) |  Loss2: (0.0000) | Acc: (93.00%) (12090/12928)
Epoch: 112 | Batch_idx: 110 |  Loss: (0.1910) |  Loss2: (0.0000) | Acc: (93.00%) (13289/14208)
Epoch: 112 | Batch_idx: 120 |  Loss: (0.1887) |  Loss2: (0.0000) | Acc: (93.00%) (14496/15488)
Epoch: 112 | Batch_idx: 130 |  Loss: (0.1879) |  Loss2: (0.0000) | Acc: (93.00%) (15698/16768)
Epoch: 112 | Batch_idx: 140 |  Loss: (0.1880) |  Loss2: (0.0000) | Acc: (93.00%) (16900/18048)
Epoch: 112 | Batch_idx: 150 |  Loss: (0.1885) |  Loss2: (0.0000) | Acc: (93.00%) (18100/19328)
Epoch: 112 | Batch_idx: 160 |  Loss: (0.1893) |  Loss2: (0.0000) | Acc: (93.00%) (19284/20608)
Epoch: 112 | Batch_idx: 170 |  Loss: (0.1891) |  Loss2: (0.0000) | Acc: (93.00%) (20486/21888)
Epoch: 112 | Batch_idx: 180 |  Loss: (0.1884) |  Loss2: (0.0000) | Acc: (93.00%) (21693/23168)
Epoch: 112 | Batch_idx: 190 |  Loss: (0.1891) |  Loss2: (0.0000) | Acc: (93.00%) (22882/24448)
Epoch: 112 | Batch_idx: 200 |  Loss: (0.1903) |  Loss2: (0.0000) | Acc: (93.00%) (24072/25728)
Epoch: 112 | Batch_idx: 210 |  Loss: (0.1912) |  Loss2: (0.0000) | Acc: (93.00%) (25258/27008)
Epoch: 112 | Batch_idx: 220 |  Loss: (0.1919) |  Loss2: (0.0000) | Acc: (93.00%) (26443/28288)
Epoch: 112 | Batch_idx: 230 |  Loss: (0.1916) |  Loss2: (0.0000) | Acc: (93.00%) (27642/29568)
Epoch: 112 | Batch_idx: 240 |  Loss: (0.1922) |  Loss2: (0.0000) | Acc: (93.00%) (28822/30848)
Epoch: 112 | Batch_idx: 250 |  Loss: (0.1924) |  Loss2: (0.0000) | Acc: (93.00%) (30012/32128)
Epoch: 112 | Batch_idx: 260 |  Loss: (0.1927) |  Loss2: (0.0000) | Acc: (93.00%) (31200/33408)
Epoch: 112 | Batch_idx: 270 |  Loss: (0.1925) |  Loss2: (0.0000) | Acc: (93.00%) (32398/34688)
Epoch: 112 | Batch_idx: 280 |  Loss: (0.1929) |  Loss2: (0.0000) | Acc: (93.00%) (33590/35968)
Epoch: 112 | Batch_idx: 290 |  Loss: (0.1920) |  Loss2: (0.0000) | Acc: (93.00%) (34797/37248)
Epoch: 112 | Batch_idx: 300 |  Loss: (0.1911) |  Loss2: (0.0000) | Acc: (93.00%) (36004/38528)
Epoch: 112 | Batch_idx: 310 |  Loss: (0.1909) |  Loss2: (0.0000) | Acc: (93.00%) (37206/39808)
Epoch: 112 | Batch_idx: 320 |  Loss: (0.1911) |  Loss2: (0.0000) | Acc: (93.00%) (38396/41088)
Epoch: 112 | Batch_idx: 330 |  Loss: (0.1906) |  Loss2: (0.0000) | Acc: (93.00%) (39597/42368)
Epoch: 112 | Batch_idx: 340 |  Loss: (0.1904) |  Loss2: (0.0000) | Acc: (93.00%) (40794/43648)
Epoch: 112 | Batch_idx: 350 |  Loss: (0.1900) |  Loss2: (0.0000) | Acc: (93.00%) (41995/44928)
Epoch: 112 | Batch_idx: 360 |  Loss: (0.1892) |  Loss2: (0.0000) | Acc: (93.00%) (43209/46208)
Epoch: 112 | Batch_idx: 370 |  Loss: (0.1893) |  Loss2: (0.0000) | Acc: (93.00%) (44399/47488)
Epoch: 112 | Batch_idx: 380 |  Loss: (0.1891) |  Loss2: (0.0000) | Acc: (93.00%) (45606/48768)
Epoch: 112 | Batch_idx: 390 |  Loss: (0.1891) |  Loss2: (0.0000) | Acc: (93.00%) (46763/50000)
# TEST : Loss: (0.3881) | Acc: (87.00%) (8763/10000)
percent tensor([0.5689, 0.5772, 0.5674, 0.5653, 0.5722, 0.5816, 0.5794, 0.5615, 0.5630,
        0.5724, 0.5745, 0.5738, 0.5707, 0.5590, 0.5846, 0.5718],
       device='cuda:0') torch.Size([16])
percent tensor([0.5128, 0.5116, 0.5068, 0.5114, 0.5056, 0.5212, 0.5062, 0.5049, 0.5071,
        0.5099, 0.5132, 0.5071, 0.5088, 0.5115, 0.5145, 0.5144],
       device='cuda:0') torch.Size([16])
percent tensor([0.5413, 0.4246, 0.6778, 0.6717, 0.6904, 0.6492, 0.5287, 0.6545, 0.5859,
        0.5090, 0.4538, 0.5962, 0.4567, 0.4901, 0.5057, 0.6018],
       device='cuda:0') torch.Size([16])
percent tensor([0.6863, 0.7295, 0.6060, 0.6456, 0.5947, 0.5407, 0.6791, 0.6206, 0.6972,
        0.7290, 0.7509, 0.6792, 0.7128, 0.7353, 0.6684, 0.6598],
       device='cuda:0') torch.Size([16])
percent tensor([0.6894, 0.6089, 0.7050, 0.6958, 0.7087, 0.7392, 0.6820, 0.6987, 0.6481,
        0.6092, 0.5811, 0.6131, 0.5760, 0.6395, 0.6757, 0.7043],
       device='cuda:0') torch.Size([16])
percent tensor([0.5356, 0.6242, 0.6825, 0.7380, 0.7336, 0.7686, 0.6550, 0.5204, 0.6636,
        0.6021, 0.6661, 0.6469, 0.6211, 0.7072, 0.4981, 0.5353],
       device='cuda:0') torch.Size([16])
percent tensor([0.4479, 0.6088, 0.6009, 0.6566, 0.6050, 0.5660, 0.5710, 0.5527, 0.6189,
        0.5583, 0.6460, 0.6123, 0.5376, 0.6420, 0.5344, 0.4259],
       device='cuda:0') torch.Size([16])
percent tensor([0.9998, 0.9994, 0.9998, 0.9999, 0.9999, 0.9987, 0.9997, 0.9998, 0.9996,
        0.9997, 0.9995, 0.9997, 0.9990, 0.9994, 0.9997, 0.9996],
       device='cuda:0') torch.Size([16])
Epoch: 113 | Batch_idx: 0 |  Loss: (0.2364) |  Loss2: (0.0000) | Acc: (89.00%) (115/128)
Epoch: 113 | Batch_idx: 10 |  Loss: (0.1722) |  Loss2: (0.0000) | Acc: (94.00%) (1326/1408)
Epoch: 113 | Batch_idx: 20 |  Loss: (0.1753) |  Loss2: (0.0000) | Acc: (94.00%) (2528/2688)
Epoch: 113 | Batch_idx: 30 |  Loss: (0.1814) |  Loss2: (0.0000) | Acc: (93.00%) (3725/3968)
Epoch: 113 | Batch_idx: 40 |  Loss: (0.1784) |  Loss2: (0.0000) | Acc: (94.00%) (4938/5248)
Epoch: 113 | Batch_idx: 50 |  Loss: (0.1777) |  Loss2: (0.0000) | Acc: (94.00%) (6140/6528)
Epoch: 113 | Batch_idx: 60 |  Loss: (0.1804) |  Loss2: (0.0000) | Acc: (93.00%) (7331/7808)
Epoch: 113 | Batch_idx: 70 |  Loss: (0.1816) |  Loss2: (0.0000) | Acc: (93.00%) (8533/9088)
Epoch: 113 | Batch_idx: 80 |  Loss: (0.1822) |  Loss2: (0.0000) | Acc: (93.00%) (9731/10368)
Epoch: 113 | Batch_idx: 90 |  Loss: (0.1851) |  Loss2: (0.0000) | Acc: (93.00%) (10930/11648)
Epoch: 113 | Batch_idx: 100 |  Loss: (0.1851) |  Loss2: (0.0000) | Acc: (93.00%) (12124/12928)
Epoch: 113 | Batch_idx: 110 |  Loss: (0.1839) |  Loss2: (0.0000) | Acc: (93.00%) (13334/14208)
Epoch: 113 | Batch_idx: 120 |  Loss: (0.1839) |  Loss2: (0.0000) | Acc: (93.00%) (14530/15488)
Epoch: 113 | Batch_idx: 130 |  Loss: (0.1833) |  Loss2: (0.0000) | Acc: (93.00%) (15734/16768)
Epoch: 113 | Batch_idx: 140 |  Loss: (0.1823) |  Loss2: (0.0000) | Acc: (93.00%) (16948/18048)
Epoch: 113 | Batch_idx: 150 |  Loss: (0.1825) |  Loss2: (0.0000) | Acc: (93.00%) (18141/19328)
Epoch: 113 | Batch_idx: 160 |  Loss: (0.1837) |  Loss2: (0.0000) | Acc: (93.00%) (19335/20608)
Epoch: 113 | Batch_idx: 170 |  Loss: (0.1839) |  Loss2: (0.0000) | Acc: (93.00%) (20541/21888)
Epoch: 113 | Batch_idx: 180 |  Loss: (0.1843) |  Loss2: (0.0000) | Acc: (93.00%) (21741/23168)
Epoch: 113 | Batch_idx: 190 |  Loss: (0.1833) |  Loss2: (0.0000) | Acc: (93.00%) (22945/24448)
Epoch: 113 | Batch_idx: 200 |  Loss: (0.1845) |  Loss2: (0.0000) | Acc: (93.00%) (24132/25728)
Epoch: 113 | Batch_idx: 210 |  Loss: (0.1859) |  Loss2: (0.0000) | Acc: (93.00%) (25315/27008)
Epoch: 113 | Batch_idx: 220 |  Loss: (0.1852) |  Loss2: (0.0000) | Acc: (93.00%) (26519/28288)
Epoch: 113 | Batch_idx: 230 |  Loss: (0.1850) |  Loss2: (0.0000) | Acc: (93.00%) (27713/29568)
Epoch: 113 | Batch_idx: 240 |  Loss: (0.1839) |  Loss2: (0.0000) | Acc: (93.00%) (28930/30848)
Epoch: 113 | Batch_idx: 250 |  Loss: (0.1839) |  Loss2: (0.0000) | Acc: (93.00%) (30134/32128)
Epoch: 113 | Batch_idx: 260 |  Loss: (0.1835) |  Loss2: (0.0000) | Acc: (93.00%) (31341/33408)
Epoch: 113 | Batch_idx: 270 |  Loss: (0.1834) |  Loss2: (0.0000) | Acc: (93.00%) (32547/34688)
Epoch: 113 | Batch_idx: 280 |  Loss: (0.1826) |  Loss2: (0.0000) | Acc: (93.00%) (33749/35968)
Epoch: 113 | Batch_idx: 290 |  Loss: (0.1831) |  Loss2: (0.0000) | Acc: (93.00%) (34934/37248)
Epoch: 113 | Batch_idx: 300 |  Loss: (0.1829) |  Loss2: (0.0000) | Acc: (93.00%) (36137/38528)
Epoch: 113 | Batch_idx: 310 |  Loss: (0.1819) |  Loss2: (0.0000) | Acc: (93.00%) (37348/39808)
Epoch: 113 | Batch_idx: 320 |  Loss: (0.1821) |  Loss2: (0.0000) | Acc: (93.00%) (38540/41088)
Epoch: 113 | Batch_idx: 330 |  Loss: (0.1816) |  Loss2: (0.0000) | Acc: (93.00%) (39736/42368)
Epoch: 113 | Batch_idx: 340 |  Loss: (0.1816) |  Loss2: (0.0000) | Acc: (93.00%) (40932/43648)
Epoch: 113 | Batch_idx: 350 |  Loss: (0.1814) |  Loss2: (0.0000) | Acc: (93.00%) (42124/44928)
Epoch: 113 | Batch_idx: 360 |  Loss: (0.1807) |  Loss2: (0.0000) | Acc: (93.00%) (43337/46208)
Epoch: 113 | Batch_idx: 370 |  Loss: (0.1805) |  Loss2: (0.0000) | Acc: (93.00%) (44544/47488)
Epoch: 113 | Batch_idx: 380 |  Loss: (0.1801) |  Loss2: (0.0000) | Acc: (93.00%) (45750/48768)
Epoch: 113 | Batch_idx: 390 |  Loss: (0.1803) |  Loss2: (0.0000) | Acc: (93.00%) (46902/50000)
# TEST : Loss: (0.3775) | Acc: (88.00%) (8807/10000)
percent tensor([0.5670, 0.5749, 0.5651, 0.5639, 0.5699, 0.5803, 0.5769, 0.5590, 0.5606,
        0.5699, 0.5723, 0.5713, 0.5685, 0.5569, 0.5828, 0.5699],
       device='cuda:0') torch.Size([16])
percent tensor([0.5132, 0.5116, 0.5072, 0.5122, 0.5060, 0.5225, 0.5061, 0.5050, 0.5070,
        0.5102, 0.5134, 0.5073, 0.5089, 0.5114, 0.5149, 0.5152],
       device='cuda:0') torch.Size([16])
percent tensor([0.5271, 0.4096, 0.6706, 0.6646, 0.6843, 0.6427, 0.5127, 0.6484, 0.5747,
        0.4945, 0.4357, 0.5813, 0.4412, 0.4756, 0.4890, 0.5892],
       device='cuda:0') torch.Size([16])
percent tensor([0.6805, 0.7237, 0.6029, 0.6400, 0.5911, 0.5326, 0.6744, 0.6175, 0.6936,
        0.7228, 0.7455, 0.6738, 0.7073, 0.7297, 0.6604, 0.6515],
       device='cuda:0') torch.Size([16])
percent tensor([0.6965, 0.6109, 0.7138, 0.7043, 0.7200, 0.7521, 0.6884, 0.7076, 0.6538,
        0.6140, 0.5840, 0.6179, 0.5801, 0.6442, 0.6844, 0.7142],
       device='cuda:0') torch.Size([16])
percent tensor([0.5407, 0.6382, 0.6812, 0.7418, 0.7324, 0.7714, 0.6631, 0.5165, 0.6666,
        0.6102, 0.6758, 0.6581, 0.6285, 0.7183, 0.5099, 0.5380],
       device='cuda:0') torch.Size([16])
percent tensor([0.4558, 0.6267, 0.5987, 0.6645, 0.6025, 0.5736, 0.5841, 0.5582, 0.6263,
        0.5698, 0.6591, 0.6213, 0.5478, 0.6600, 0.5474, 0.4303],
       device='cuda:0') torch.Size([16])
percent tensor([0.9998, 0.9994, 0.9997, 0.9999, 0.9999, 0.9987, 0.9997, 0.9998, 0.9996,
        0.9998, 0.9995, 0.9997, 0.9991, 0.9994, 0.9997, 0.9996],
       device='cuda:0') torch.Size([16])
True Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=128, out_features=16, bias=False)
False Linear(in_features=16, out_features=2, bias=False)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=128, out_features=16, bias=False)
False Linear(in_features=16, out_features=2, bias=False)
True Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=256, out_features=32, bias=False)
False Linear(in_features=32, out_features=2, bias=False)
True Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=256, out_features=32, bias=False)
False Linear(in_features=32, out_features=2, bias=False)
True Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=512, out_features=64, bias=False)
False Linear(in_features=64, out_features=2, bias=False)
True Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=512, out_features=64, bias=False)
False Linear(in_features=64, out_features=2, bias=False)
True Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1024, out_features=128, bias=False)
False Linear(in_features=128, out_features=2, bias=False)
True Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1024, out_features=128, bias=False)
False Linear(in_features=128, out_features=2, bias=False)
True Linear(in_features=512, out_features=10, bias=True)
Epoch: 114 | Batch_idx: 0 |  Loss: (0.2318) |  Loss2: (0.0000) | Acc: (94.00%) (121/128)
Epoch: 114 | Batch_idx: 10 |  Loss: (0.1631) |  Loss2: (0.0000) | Acc: (94.00%) (1333/1408)
Epoch: 114 | Batch_idx: 20 |  Loss: (0.1611) |  Loss2: (0.0000) | Acc: (94.00%) (2545/2688)
Epoch: 114 | Batch_idx: 30 |  Loss: (0.1599) |  Loss2: (0.0000) | Acc: (94.00%) (3751/3968)
Epoch: 114 | Batch_idx: 40 |  Loss: (0.1584) |  Loss2: (0.0000) | Acc: (94.00%) (4964/5248)
Epoch: 114 | Batch_idx: 50 |  Loss: (0.1597) |  Loss2: (0.0000) | Acc: (94.00%) (6169/6528)
Epoch: 114 | Batch_idx: 60 |  Loss: (0.1612) |  Loss2: (0.0000) | Acc: (94.00%) (7378/7808)
Epoch: 114 | Batch_idx: 70 |  Loss: (0.1635) |  Loss2: (0.0000) | Acc: (94.00%) (8576/9088)
Epoch: 114 | Batch_idx: 80 |  Loss: (0.1674) |  Loss2: (0.0000) | Acc: (94.00%) (9766/10368)
Epoch: 114 | Batch_idx: 90 |  Loss: (0.1669) |  Loss2: (0.0000) | Acc: (94.00%) (10973/11648)
Epoch: 114 | Batch_idx: 100 |  Loss: (0.1678) |  Loss2: (0.0000) | Acc: (94.00%) (12179/12928)
Epoch: 114 | Batch_idx: 110 |  Loss: (0.1694) |  Loss2: (0.0000) | Acc: (94.00%) (13385/14208)
Epoch: 114 | Batch_idx: 120 |  Loss: (0.1718) |  Loss2: (0.0000) | Acc: (94.00%) (14583/15488)
Epoch: 114 | Batch_idx: 130 |  Loss: (0.1734) |  Loss2: (0.0000) | Acc: (94.00%) (15769/16768)
Epoch: 114 | Batch_idx: 140 |  Loss: (0.1749) |  Loss2: (0.0000) | Acc: (93.00%) (16963/18048)
Epoch: 114 | Batch_idx: 150 |  Loss: (0.1762) |  Loss2: (0.0000) | Acc: (93.00%) (18158/19328)
Epoch: 114 | Batch_idx: 160 |  Loss: (0.1763) |  Loss2: (0.0000) | Acc: (93.00%) (19364/20608)
Epoch: 114 | Batch_idx: 170 |  Loss: (0.1776) |  Loss2: (0.0000) | Acc: (93.00%) (20552/21888)
Epoch: 114 | Batch_idx: 180 |  Loss: (0.1772) |  Loss2: (0.0000) | Acc: (93.00%) (21757/23168)
Epoch: 114 | Batch_idx: 190 |  Loss: (0.1781) |  Loss2: (0.0000) | Acc: (93.00%) (22952/24448)
Epoch: 114 | Batch_idx: 200 |  Loss: (0.1778) |  Loss2: (0.0000) | Acc: (93.00%) (24154/25728)
Epoch: 114 | Batch_idx: 210 |  Loss: (0.1794) |  Loss2: (0.0000) | Acc: (93.00%) (25341/27008)
Epoch: 114 | Batch_idx: 220 |  Loss: (0.1794) |  Loss2: (0.0000) | Acc: (93.00%) (26540/28288)
Epoch: 114 | Batch_idx: 230 |  Loss: (0.1804) |  Loss2: (0.0000) | Acc: (93.00%) (27733/29568)
Epoch: 114 | Batch_idx: 240 |  Loss: (0.1812) |  Loss2: (0.0000) | Acc: (93.00%) (28928/30848)
Epoch: 114 | Batch_idx: 250 |  Loss: (0.1821) |  Loss2: (0.0000) | Acc: (93.00%) (30114/32128)
Epoch: 114 | Batch_idx: 260 |  Loss: (0.1827) |  Loss2: (0.0000) | Acc: (93.00%) (31308/33408)
Epoch: 114 | Batch_idx: 270 |  Loss: (0.1826) |  Loss2: (0.0000) | Acc: (93.00%) (32509/34688)
Epoch: 114 | Batch_idx: 280 |  Loss: (0.1824) |  Loss2: (0.0000) | Acc: (93.00%) (33717/35968)
Epoch: 114 | Batch_idx: 290 |  Loss: (0.1821) |  Loss2: (0.0000) | Acc: (93.00%) (34920/37248)
Epoch: 114 | Batch_idx: 300 |  Loss: (0.1820) |  Loss2: (0.0000) | Acc: (93.00%) (36126/38528)
Epoch: 114 | Batch_idx: 310 |  Loss: (0.1820) |  Loss2: (0.0000) | Acc: (93.00%) (37318/39808)
Epoch: 114 | Batch_idx: 320 |  Loss: (0.1822) |  Loss2: (0.0000) | Acc: (93.00%) (38514/41088)
Epoch: 114 | Batch_idx: 330 |  Loss: (0.1823) |  Loss2: (0.0000) | Acc: (93.00%) (39702/42368)
Epoch: 114 | Batch_idx: 340 |  Loss: (0.1819) |  Loss2: (0.0000) | Acc: (93.00%) (40912/43648)
Epoch: 114 | Batch_idx: 350 |  Loss: (0.1823) |  Loss2: (0.0000) | Acc: (93.00%) (42109/44928)
Epoch: 114 | Batch_idx: 360 |  Loss: (0.1829) |  Loss2: (0.0000) | Acc: (93.00%) (43293/46208)
Epoch: 114 | Batch_idx: 370 |  Loss: (0.1833) |  Loss2: (0.0000) | Acc: (93.00%) (44480/47488)
Epoch: 114 | Batch_idx: 380 |  Loss: (0.1836) |  Loss2: (0.0000) | Acc: (93.00%) (45678/48768)
Epoch: 114 | Batch_idx: 390 |  Loss: (0.1834) |  Loss2: (0.0000) | Acc: (93.00%) (46833/50000)
# TEST : Loss: (0.3915) | Acc: (87.00%) (8756/10000)
percent tensor([0.5657, 0.5771, 0.5617, 0.5632, 0.5675, 0.5783, 0.5769, 0.5589, 0.5609,
        0.5694, 0.5719, 0.5689, 0.5683, 0.5591, 0.5827, 0.5702],
       device='cuda:0') torch.Size([16])
percent tensor([0.5130, 0.5116, 0.5075, 0.5134, 0.5064, 0.5221, 0.5068, 0.5054, 0.5071,
        0.5105, 0.5131, 0.5084, 0.5090, 0.5118, 0.5151, 0.5145],
       device='cuda:0') torch.Size([16])
percent tensor([0.5215, 0.4088, 0.6759, 0.6693, 0.6823, 0.6376, 0.5010, 0.6466, 0.5559,
        0.4845, 0.4207, 0.5745, 0.4322, 0.4620, 0.4846, 0.5801],
       device='cuda:0') torch.Size([16])
percent tensor([0.6808, 0.7194, 0.5830, 0.6324, 0.5941, 0.5290, 0.6746, 0.6147, 0.6946,
        0.7227, 0.7514, 0.6751, 0.7108, 0.7357, 0.6564, 0.6516],
       device='cuda:0') torch.Size([16])
percent tensor([0.6897, 0.5964, 0.7112, 0.7007, 0.7213, 0.7565, 0.6772, 0.7078, 0.6523,
        0.5953, 0.5676, 0.6090, 0.5600, 0.6295, 0.6845, 0.7033],
       device='cuda:0') torch.Size([16])
percent tensor([0.5174, 0.6621, 0.6965, 0.7403, 0.7387, 0.7624, 0.6518, 0.5330, 0.6617,
        0.6100, 0.6593, 0.6626, 0.6355, 0.6985, 0.5231, 0.5314],
       device='cuda:0') torch.Size([16])
percent tensor([0.4547, 0.6306, 0.6085, 0.6467, 0.6035, 0.5795, 0.5901, 0.5541, 0.5980,
        0.5807, 0.6472, 0.6244, 0.5735, 0.6358, 0.5431, 0.4402],
       device='cuda:0') torch.Size([16])
percent tensor([0.9998, 0.9993, 0.9995, 0.9999, 0.9999, 0.9989, 0.9998, 0.9994, 0.9995,
        0.9998, 0.9992, 0.9998, 0.9992, 0.9995, 0.9997, 0.9996],
       device='cuda:0') torch.Size([16])
Epoch: 115 | Batch_idx: 0 |  Loss: (0.1842) |  Loss2: (0.0000) | Acc: (92.00%) (118/128)
Epoch: 115 | Batch_idx: 10 |  Loss: (0.1614) |  Loss2: (0.0000) | Acc: (94.00%) (1324/1408)
Epoch: 115 | Batch_idx: 20 |  Loss: (0.1623) |  Loss2: (0.0000) | Acc: (94.00%) (2531/2688)
Epoch: 115 | Batch_idx: 30 |  Loss: (0.1682) |  Loss2: (0.0000) | Acc: (94.00%) (3739/3968)
Epoch: 115 | Batch_idx: 40 |  Loss: (0.1664) |  Loss2: (0.0000) | Acc: (94.00%) (4953/5248)
Epoch: 115 | Batch_idx: 50 |  Loss: (0.1675) |  Loss2: (0.0000) | Acc: (94.00%) (6160/6528)
Epoch: 115 | Batch_idx: 60 |  Loss: (0.1697) |  Loss2: (0.0000) | Acc: (94.00%) (7360/7808)
Epoch: 115 | Batch_idx: 70 |  Loss: (0.1704) |  Loss2: (0.0000) | Acc: (94.00%) (8554/9088)
Epoch: 115 | Batch_idx: 80 |  Loss: (0.1703) |  Loss2: (0.0000) | Acc: (94.00%) (9762/10368)
Epoch: 115 | Batch_idx: 90 |  Loss: (0.1702) |  Loss2: (0.0000) | Acc: (94.00%) (10967/11648)
Epoch: 115 | Batch_idx: 100 |  Loss: (0.1718) |  Loss2: (0.0000) | Acc: (94.00%) (12165/12928)
Epoch: 115 | Batch_idx: 110 |  Loss: (0.1717) |  Loss2: (0.0000) | Acc: (94.00%) (13368/14208)
Epoch: 115 | Batch_idx: 120 |  Loss: (0.1723) |  Loss2: (0.0000) | Acc: (94.00%) (14561/15488)
Epoch: 115 | Batch_idx: 130 |  Loss: (0.1728) |  Loss2: (0.0000) | Acc: (94.00%) (15767/16768)
Epoch: 115 | Batch_idx: 140 |  Loss: (0.1722) |  Loss2: (0.0000) | Acc: (94.00%) (16977/18048)
Epoch: 115 | Batch_idx: 150 |  Loss: (0.1721) |  Loss2: (0.0000) | Acc: (94.00%) (18195/19328)
Epoch: 115 | Batch_idx: 160 |  Loss: (0.1707) |  Loss2: (0.0000) | Acc: (94.00%) (19411/20608)
Epoch: 115 | Batch_idx: 170 |  Loss: (0.1719) |  Loss2: (0.0000) | Acc: (94.00%) (20605/21888)
Epoch: 115 | Batch_idx: 180 |  Loss: (0.1717) |  Loss2: (0.0000) | Acc: (94.00%) (21806/23168)
Epoch: 115 | Batch_idx: 190 |  Loss: (0.1726) |  Loss2: (0.0000) | Acc: (94.00%) (23010/24448)
Epoch: 115 | Batch_idx: 200 |  Loss: (0.1727) |  Loss2: (0.0000) | Acc: (94.00%) (24212/25728)
Epoch: 115 | Batch_idx: 210 |  Loss: (0.1735) |  Loss2: (0.0000) | Acc: (94.00%) (25410/27008)
Epoch: 115 | Batch_idx: 220 |  Loss: (0.1735) |  Loss2: (0.0000) | Acc: (94.00%) (26618/28288)
Epoch: 115 | Batch_idx: 230 |  Loss: (0.1737) |  Loss2: (0.0000) | Acc: (94.00%) (27819/29568)
Epoch: 115 | Batch_idx: 240 |  Loss: (0.1737) |  Loss2: (0.0000) | Acc: (94.00%) (29028/30848)
Epoch: 115 | Batch_idx: 250 |  Loss: (0.1745) |  Loss2: (0.0000) | Acc: (94.00%) (30226/32128)
Epoch: 115 | Batch_idx: 260 |  Loss: (0.1760) |  Loss2: (0.0000) | Acc: (93.00%) (31400/33408)
Epoch: 115 | Batch_idx: 270 |  Loss: (0.1766) |  Loss2: (0.0000) | Acc: (93.00%) (32601/34688)
Epoch: 115 | Batch_idx: 280 |  Loss: (0.1769) |  Loss2: (0.0000) | Acc: (93.00%) (33803/35968)
Epoch: 115 | Batch_idx: 290 |  Loss: (0.1770) |  Loss2: (0.0000) | Acc: (93.00%) (35007/37248)
Epoch: 115 | Batch_idx: 300 |  Loss: (0.1770) |  Loss2: (0.0000) | Acc: (93.00%) (36214/38528)
Epoch: 115 | Batch_idx: 310 |  Loss: (0.1781) |  Loss2: (0.0000) | Acc: (93.00%) (37412/39808)
Epoch: 115 | Batch_idx: 320 |  Loss: (0.1789) |  Loss2: (0.0000) | Acc: (93.00%) (38602/41088)
Epoch: 115 | Batch_idx: 330 |  Loss: (0.1789) |  Loss2: (0.0000) | Acc: (93.00%) (39810/42368)
Epoch: 115 | Batch_idx: 340 |  Loss: (0.1790) |  Loss2: (0.0000) | Acc: (93.00%) (41014/43648)
Epoch: 115 | Batch_idx: 350 |  Loss: (0.1799) |  Loss2: (0.0000) | Acc: (93.00%) (42206/44928)
Epoch: 115 | Batch_idx: 360 |  Loss: (0.1801) |  Loss2: (0.0000) | Acc: (93.00%) (43406/46208)
Epoch: 115 | Batch_idx: 370 |  Loss: (0.1810) |  Loss2: (0.0000) | Acc: (93.00%) (44588/47488)
Epoch: 115 | Batch_idx: 380 |  Loss: (0.1810) |  Loss2: (0.0000) | Acc: (93.00%) (45786/48768)
Epoch: 115 | Batch_idx: 390 |  Loss: (0.1811) |  Loss2: (0.0000) | Acc: (93.00%) (46931/50000)
=> saving checkpoint 'drive/app/torch/save_Schedule/checkpoint_115.pth.tar'
# TEST : Loss: (0.3916) | Acc: (87.00%) (8775/10000)
percent tensor([0.5664, 0.5756, 0.5664, 0.5652, 0.5702, 0.5807, 0.5765, 0.5593, 0.5606,
        0.5695, 0.5711, 0.5719, 0.5679, 0.5563, 0.5827, 0.5706],
       device='cuda:0') torch.Size([16])
percent tensor([0.5127, 0.5120, 0.5064, 0.5125, 0.5058, 0.5208, 0.5069, 0.5055, 0.5069,
        0.5107, 0.5135, 0.5074, 0.5092, 0.5122, 0.5148, 0.5145],
       device='cuda:0') torch.Size([16])
percent tensor([0.5309, 0.4129, 0.6746, 0.6749, 0.6849, 0.6304, 0.5027, 0.6458, 0.5506,
        0.4914, 0.4215, 0.5742, 0.4340, 0.4846, 0.4858, 0.5936],
       device='cuda:0') torch.Size([16])
percent tensor([0.6799, 0.7224, 0.5899, 0.6462, 0.6015, 0.5504, 0.6771, 0.6151, 0.6939,
        0.7220, 0.7508, 0.6709, 0.7070, 0.7317, 0.6656, 0.6580],
       device='cuda:0') torch.Size([16])
percent tensor([0.6946, 0.6008, 0.7046, 0.6869, 0.7214, 0.7492, 0.6871, 0.7124, 0.6520,
        0.6027, 0.5725, 0.6137, 0.5686, 0.6426, 0.6779, 0.7099],
       device='cuda:0') torch.Size([16])
percent tensor([0.5127, 0.6495, 0.6774, 0.7219, 0.7209, 0.7511, 0.6424, 0.5232, 0.6510,
        0.6196, 0.6781, 0.6630, 0.6366, 0.6919, 0.5125, 0.5110],
       device='cuda:0') torch.Size([16])
percent tensor([0.4518, 0.6223, 0.6017, 0.6505, 0.6058, 0.5869, 0.5861, 0.5432, 0.6139,
        0.5831, 0.6551, 0.6219, 0.5595, 0.6204, 0.5411, 0.4438],
       device='cuda:0') torch.Size([16])
percent tensor([0.9998, 0.9997, 0.9996, 0.9999, 0.9999, 0.9991, 0.9998, 0.9997, 0.9997,
        0.9998, 0.9994, 0.9999, 0.9993, 0.9996, 0.9997, 0.9997],
       device='cuda:0') torch.Size([16])
Epoch: 116 | Batch_idx: 0 |  Loss: (0.1444) |  Loss2: (0.0000) | Acc: (95.00%) (122/128)
Epoch: 116 | Batch_idx: 10 |  Loss: (0.1725) |  Loss2: (0.0000) | Acc: (94.00%) (1332/1408)
Epoch: 116 | Batch_idx: 20 |  Loss: (0.1631) |  Loss2: (0.0000) | Acc: (94.00%) (2543/2688)
Epoch: 116 | Batch_idx: 30 |  Loss: (0.1769) |  Loss2: (0.0000) | Acc: (93.00%) (3724/3968)
Epoch: 116 | Batch_idx: 40 |  Loss: (0.1812) |  Loss2: (0.0000) | Acc: (93.00%) (4923/5248)
Epoch: 116 | Batch_idx: 50 |  Loss: (0.1797) |  Loss2: (0.0000) | Acc: (93.00%) (6130/6528)
Epoch: 116 | Batch_idx: 60 |  Loss: (0.1783) |  Loss2: (0.0000) | Acc: (93.00%) (7335/7808)
Epoch: 116 | Batch_idx: 70 |  Loss: (0.1788) |  Loss2: (0.0000) | Acc: (93.00%) (8533/9088)
Epoch: 116 | Batch_idx: 80 |  Loss: (0.1764) |  Loss2: (0.0000) | Acc: (93.00%) (9741/10368)
Epoch: 116 | Batch_idx: 90 |  Loss: (0.1766) |  Loss2: (0.0000) | Acc: (94.00%) (10951/11648)
Epoch: 116 | Batch_idx: 100 |  Loss: (0.1805) |  Loss2: (0.0000) | Acc: (93.00%) (12148/12928)
Epoch: 116 | Batch_idx: 110 |  Loss: (0.1812) |  Loss2: (0.0000) | Acc: (93.00%) (13344/14208)
Epoch: 116 | Batch_idx: 120 |  Loss: (0.1798) |  Loss2: (0.0000) | Acc: (94.00%) (14566/15488)
Epoch: 116 | Batch_idx: 130 |  Loss: (0.1785) |  Loss2: (0.0000) | Acc: (94.00%) (15773/16768)
Epoch: 116 | Batch_idx: 140 |  Loss: (0.1776) |  Loss2: (0.0000) | Acc: (94.00%) (16986/18048)
Epoch: 116 | Batch_idx: 150 |  Loss: (0.1761) |  Loss2: (0.0000) | Acc: (94.00%) (18195/19328)
Epoch: 116 | Batch_idx: 160 |  Loss: (0.1757) |  Loss2: (0.0000) | Acc: (94.00%) (19405/20608)
Epoch: 116 | Batch_idx: 170 |  Loss: (0.1768) |  Loss2: (0.0000) | Acc: (94.00%) (20600/21888)
Epoch: 116 | Batch_idx: 180 |  Loss: (0.1754) |  Loss2: (0.0000) | Acc: (94.00%) (21821/23168)
Epoch: 116 | Batch_idx: 190 |  Loss: (0.1746) |  Loss2: (0.0000) | Acc: (94.00%) (23031/24448)
Epoch: 116 | Batch_idx: 200 |  Loss: (0.1754) |  Loss2: (0.0000) | Acc: (94.00%) (24221/25728)
Epoch: 116 | Batch_idx: 210 |  Loss: (0.1748) |  Loss2: (0.0000) | Acc: (94.00%) (25430/27008)
Epoch: 116 | Batch_idx: 220 |  Loss: (0.1754) |  Loss2: (0.0000) | Acc: (94.00%) (26629/28288)
Epoch: 116 | Batch_idx: 230 |  Loss: (0.1755) |  Loss2: (0.0000) | Acc: (94.00%) (27832/29568)
Epoch: 116 | Batch_idx: 240 |  Loss: (0.1756) |  Loss2: (0.0000) | Acc: (94.00%) (29026/30848)
Epoch: 116 | Batch_idx: 250 |  Loss: (0.1766) |  Loss2: (0.0000) | Acc: (94.00%) (30215/32128)
Epoch: 116 | Batch_idx: 260 |  Loss: (0.1770) |  Loss2: (0.0000) | Acc: (94.00%) (31415/33408)
Epoch: 116 | Batch_idx: 270 |  Loss: (0.1774) |  Loss2: (0.0000) | Acc: (94.00%) (32611/34688)
Epoch: 116 | Batch_idx: 280 |  Loss: (0.1774) |  Loss2: (0.0000) | Acc: (93.00%) (33803/35968)
Epoch: 116 | Batch_idx: 290 |  Loss: (0.1777) |  Loss2: (0.0000) | Acc: (93.00%) (34997/37248)
Epoch: 116 | Batch_idx: 300 |  Loss: (0.1784) |  Loss2: (0.0000) | Acc: (93.00%) (36195/38528)
Epoch: 116 | Batch_idx: 310 |  Loss: (0.1783) |  Loss2: (0.0000) | Acc: (93.00%) (37402/39808)
Epoch: 116 | Batch_idx: 320 |  Loss: (0.1795) |  Loss2: (0.0000) | Acc: (93.00%) (38583/41088)
Epoch: 116 | Batch_idx: 330 |  Loss: (0.1802) |  Loss2: (0.0000) | Acc: (93.00%) (39762/42368)
Epoch: 116 | Batch_idx: 340 |  Loss: (0.1806) |  Loss2: (0.0000) | Acc: (93.00%) (40948/43648)
Epoch: 116 | Batch_idx: 350 |  Loss: (0.1810) |  Loss2: (0.0000) | Acc: (93.00%) (42143/44928)
Epoch: 116 | Batch_idx: 360 |  Loss: (0.1812) |  Loss2: (0.0000) | Acc: (93.00%) (43330/46208)
Epoch: 116 | Batch_idx: 370 |  Loss: (0.1810) |  Loss2: (0.0000) | Acc: (93.00%) (44535/47488)
Epoch: 116 | Batch_idx: 380 |  Loss: (0.1807) |  Loss2: (0.0000) | Acc: (93.00%) (45739/48768)
Epoch: 116 | Batch_idx: 390 |  Loss: (0.1807) |  Loss2: (0.0000) | Acc: (93.00%) (46895/50000)
# TEST : Loss: (0.3985) | Acc: (87.00%) (8774/10000)
percent tensor([0.5646, 0.5768, 0.5613, 0.5619, 0.5661, 0.5788, 0.5760, 0.5576, 0.5602,
        0.5679, 0.5712, 0.5673, 0.5669, 0.5595, 0.5821, 0.5692],
       device='cuda:0') torch.Size([16])
percent tensor([0.5134, 0.5124, 0.5074, 0.5134, 0.5054, 0.5207, 0.5072, 0.5065, 0.5077,
        0.5112, 0.5142, 0.5080, 0.5100, 0.5129, 0.5152, 0.5151],
       device='cuda:0') torch.Size([16])
percent tensor([0.5381, 0.4293, 0.6771, 0.6655, 0.6888, 0.6324, 0.5204, 0.6487, 0.5805,
        0.4942, 0.4400, 0.5807, 0.4465, 0.5024, 0.4952, 0.5962],
       device='cuda:0') torch.Size([16])
percent tensor([0.6758, 0.7162, 0.5931, 0.6389, 0.6034, 0.5472, 0.6757, 0.6081, 0.6900,
        0.7231, 0.7490, 0.6748, 0.7067, 0.7264, 0.6605, 0.6511],
       device='cuda:0') torch.Size([16])
percent tensor([0.6945, 0.6227, 0.6988, 0.6953, 0.7118, 0.7593, 0.6901, 0.7143, 0.6609,
        0.6054, 0.5831, 0.5993, 0.5739, 0.6620, 0.6902, 0.7161],
       device='cuda:0') torch.Size([16])
percent tensor([0.5386, 0.6661, 0.7114, 0.7378, 0.7484, 0.7782, 0.6759, 0.5650, 0.6961,
        0.6271, 0.6711, 0.6732, 0.6368, 0.7094, 0.5432, 0.5377],
       device='cuda:0') torch.Size([16])
percent tensor([0.4726, 0.6405, 0.6275, 0.6657, 0.6218, 0.6140, 0.6047, 0.5569, 0.6509,
        0.6000, 0.6540, 0.6515, 0.5752, 0.6268, 0.5489, 0.4357],
       device='cuda:0') torch.Size([16])
percent tensor([0.9997, 0.9995, 0.9997, 0.9999, 1.0000, 0.9988, 0.9998, 0.9997, 0.9996,
        0.9998, 0.9994, 0.9997, 0.9994, 0.9995, 0.9996, 0.9994],
       device='cuda:0') torch.Size([16])
False Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=128, out_features=16, bias=False)
True Linear(in_features=16, out_features=2, bias=False)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=128, out_features=16, bias=False)
True Linear(in_features=16, out_features=2, bias=False)
False Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=256, out_features=32, bias=False)
True Linear(in_features=32, out_features=2, bias=False)
False Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=256, out_features=32, bias=False)
True Linear(in_features=32, out_features=2, bias=False)
False Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=512, out_features=64, bias=False)
True Linear(in_features=64, out_features=2, bias=False)
False Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=512, out_features=64, bias=False)
True Linear(in_features=64, out_features=2, bias=False)
False Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1024, out_features=128, bias=False)
True Linear(in_features=128, out_features=2, bias=False)
False Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1024, out_features=128, bias=False)
True Linear(in_features=128, out_features=2, bias=False)
False Linear(in_features=512, out_features=10, bias=True)
Epoch: 117 | Batch_idx: 0 |  Loss: (0.1636) |  Loss2: (0.0000) | Acc: (94.00%) (121/128)
Epoch: 117 | Batch_idx: 10 |  Loss: (0.1866) |  Loss2: (0.0000) | Acc: (92.00%) (1302/1408)
Epoch: 117 | Batch_idx: 20 |  Loss: (0.1975) |  Loss2: (0.0000) | Acc: (92.00%) (2486/2688)
Epoch: 117 | Batch_idx: 30 |  Loss: (0.2093) |  Loss2: (0.0000) | Acc: (92.00%) (3666/3968)
Epoch: 117 | Batch_idx: 40 |  Loss: (0.2170) |  Loss2: (0.0000) | Acc: (92.00%) (4838/5248)
Epoch: 117 | Batch_idx: 50 |  Loss: (0.2246) |  Loss2: (0.0000) | Acc: (91.00%) (6002/6528)
Epoch: 117 | Batch_idx: 60 |  Loss: (0.2301) |  Loss2: (0.0000) | Acc: (91.00%) (7154/7808)
Epoch: 117 | Batch_idx: 70 |  Loss: (0.2317) |  Loss2: (0.0000) | Acc: (91.00%) (8339/9088)
Epoch: 117 | Batch_idx: 80 |  Loss: (0.2329) |  Loss2: (0.0000) | Acc: (91.00%) (9518/10368)
Epoch: 117 | Batch_idx: 90 |  Loss: (0.2323) |  Loss2: (0.0000) | Acc: (91.00%) (10698/11648)
Epoch: 117 | Batch_idx: 100 |  Loss: (0.2342) |  Loss2: (0.0000) | Acc: (91.00%) (11870/12928)
Epoch: 117 | Batch_idx: 110 |  Loss: (0.2357) |  Loss2: (0.0000) | Acc: (91.00%) (13030/14208)
Epoch: 117 | Batch_idx: 120 |  Loss: (0.2350) |  Loss2: (0.0000) | Acc: (91.00%) (14208/15488)
Epoch: 117 | Batch_idx: 130 |  Loss: (0.2364) |  Loss2: (0.0000) | Acc: (91.00%) (15363/16768)
Epoch: 117 | Batch_idx: 140 |  Loss: (0.2346) |  Loss2: (0.0000) | Acc: (91.00%) (16545/18048)
Epoch: 117 | Batch_idx: 150 |  Loss: (0.2303) |  Loss2: (0.0000) | Acc: (91.00%) (17749/19328)
Epoch: 117 | Batch_idx: 160 |  Loss: (0.2279) |  Loss2: (0.0000) | Acc: (91.00%) (18942/20608)
Epoch: 117 | Batch_idx: 170 |  Loss: (0.2267) |  Loss2: (0.0000) | Acc: (91.00%) (20120/21888)
Epoch: 117 | Batch_idx: 180 |  Loss: (0.2258) |  Loss2: (0.0000) | Acc: (91.00%) (21293/23168)
Epoch: 117 | Batch_idx: 190 |  Loss: (0.2251) |  Loss2: (0.0000) | Acc: (91.00%) (22477/24448)
Epoch: 117 | Batch_idx: 200 |  Loss: (0.2237) |  Loss2: (0.0000) | Acc: (91.00%) (23665/25728)
Epoch: 117 | Batch_idx: 210 |  Loss: (0.2235) |  Loss2: (0.0000) | Acc: (91.00%) (24842/27008)
Epoch: 117 | Batch_idx: 220 |  Loss: (0.2222) |  Loss2: (0.0000) | Acc: (92.00%) (26033/28288)
Epoch: 117 | Batch_idx: 230 |  Loss: (0.2206) |  Loss2: (0.0000) | Acc: (92.00%) (27239/29568)
Epoch: 117 | Batch_idx: 240 |  Loss: (0.2199) |  Loss2: (0.0000) | Acc: (92.00%) (28439/30848)
Epoch: 117 | Batch_idx: 250 |  Loss: (0.2200) |  Loss2: (0.0000) | Acc: (92.00%) (29624/32128)
Epoch: 117 | Batch_idx: 260 |  Loss: (0.2188) |  Loss2: (0.0000) | Acc: (92.00%) (30826/33408)
Epoch: 117 | Batch_idx: 270 |  Loss: (0.2187) |  Loss2: (0.0000) | Acc: (92.00%) (32011/34688)
Epoch: 117 | Batch_idx: 280 |  Loss: (0.2195) |  Loss2: (0.0000) | Acc: (92.00%) (33185/35968)
Epoch: 117 | Batch_idx: 290 |  Loss: (0.2186) |  Loss2: (0.0000) | Acc: (92.00%) (34373/37248)
Epoch: 117 | Batch_idx: 300 |  Loss: (0.2177) |  Loss2: (0.0000) | Acc: (92.00%) (35577/38528)
Epoch: 117 | Batch_idx: 310 |  Loss: (0.2164) |  Loss2: (0.0000) | Acc: (92.00%) (36776/39808)
Epoch: 117 | Batch_idx: 320 |  Loss: (0.2154) |  Loss2: (0.0000) | Acc: (92.00%) (37977/41088)
Epoch: 117 | Batch_idx: 330 |  Loss: (0.2143) |  Loss2: (0.0000) | Acc: (92.00%) (39179/42368)
Epoch: 117 | Batch_idx: 340 |  Loss: (0.2142) |  Loss2: (0.0000) | Acc: (92.00%) (40372/43648)
Epoch: 117 | Batch_idx: 350 |  Loss: (0.2131) |  Loss2: (0.0000) | Acc: (92.00%) (41577/44928)
Epoch: 117 | Batch_idx: 360 |  Loss: (0.2118) |  Loss2: (0.0000) | Acc: (92.00%) (42781/46208)
Epoch: 117 | Batch_idx: 370 |  Loss: (0.2109) |  Loss2: (0.0000) | Acc: (92.00%) (43975/47488)
Epoch: 117 | Batch_idx: 380 |  Loss: (0.2100) |  Loss2: (0.0000) | Acc: (92.00%) (45175/48768)
Epoch: 117 | Batch_idx: 390 |  Loss: (0.2102) |  Loss2: (0.0000) | Acc: (92.00%) (46312/50000)
# TEST : Loss: (0.3957) | Acc: (87.00%) (8774/10000)
percent tensor([0.5735, 0.5877, 0.5698, 0.5703, 0.5759, 0.5900, 0.5867, 0.5666, 0.5692,
        0.5774, 0.5808, 0.5774, 0.5763, 0.5696, 0.5929, 0.5787],
       device='cuda:0') torch.Size([16])
percent tensor([0.5110, 0.5110, 0.5051, 0.5107, 0.5032, 0.5175, 0.5055, 0.5042, 0.5062,
        0.5096, 0.5122, 0.5058, 0.5081, 0.5107, 0.5131, 0.5127],
       device='cuda:0') torch.Size([16])
percent tensor([0.5274, 0.4295, 0.6526, 0.6467, 0.6693, 0.6041, 0.5081, 0.6333, 0.5593,
        0.4887, 0.4372, 0.5628, 0.4433, 0.4725, 0.4892, 0.5874],
       device='cuda:0') torch.Size([16])
percent tensor([0.6741, 0.7222, 0.5887, 0.6292, 0.5964, 0.5575, 0.6775, 0.6081, 0.6889,
        0.7249, 0.7478, 0.6710, 0.7078, 0.7292, 0.6660, 0.6517],
       device='cuda:0') torch.Size([16])
percent tensor([0.6969, 0.6048, 0.7247, 0.7121, 0.7415, 0.7690, 0.6937, 0.7446, 0.6623,
        0.5935, 0.5600, 0.6076, 0.5519, 0.6684, 0.6843, 0.7296],
       device='cuda:0') torch.Size([16])
percent tensor([0.5329, 0.6665, 0.7002, 0.7250, 0.7209, 0.7749, 0.6540, 0.5349, 0.6858,
        0.6361, 0.6765, 0.6860, 0.6395, 0.7168, 0.5336, 0.5113],
       device='cuda:0') torch.Size([16])
percent tensor([0.4567, 0.6478, 0.6218, 0.6572, 0.6057, 0.6248, 0.6009, 0.5402, 0.6735,
        0.6123, 0.6812, 0.6569, 0.5974, 0.6491, 0.5409, 0.4256],
       device='cuda:0') torch.Size([16])
percent tensor([0.9998, 0.9996, 0.9997, 0.9998, 1.0000, 0.9989, 0.9998, 0.9998, 0.9996,
        0.9998, 0.9996, 0.9998, 0.9994, 0.9995, 0.9997, 0.9994],
       device='cuda:0') torch.Size([16])
Epoch: 118 | Batch_idx: 0 |  Loss: (0.2755) |  Loss2: (0.0000) | Acc: (92.00%) (118/128)
Epoch: 118 | Batch_idx: 10 |  Loss: (0.1941) |  Loss2: (0.0000) | Acc: (93.00%) (1320/1408)
Epoch: 118 | Batch_idx: 20 |  Loss: (0.1955) |  Loss2: (0.0000) | Acc: (93.00%) (2506/2688)
Epoch: 118 | Batch_idx: 30 |  Loss: (0.1849) |  Loss2: (0.0000) | Acc: (93.00%) (3719/3968)
Epoch: 118 | Batch_idx: 40 |  Loss: (0.1856) |  Loss2: (0.0000) | Acc: (93.00%) (4917/5248)
Epoch: 118 | Batch_idx: 50 |  Loss: (0.1876) |  Loss2: (0.0000) | Acc: (93.00%) (6116/6528)
Epoch: 118 | Batch_idx: 60 |  Loss: (0.1876) |  Loss2: (0.0000) | Acc: (93.00%) (7319/7808)
Epoch: 118 | Batch_idx: 70 |  Loss: (0.1855) |  Loss2: (0.0000) | Acc: (93.00%) (8523/9088)
Epoch: 118 | Batch_idx: 80 |  Loss: (0.1870) |  Loss2: (0.0000) | Acc: (93.00%) (9720/10368)
Epoch: 118 | Batch_idx: 90 |  Loss: (0.1857) |  Loss2: (0.0000) | Acc: (93.00%) (10927/11648)
Epoch: 118 | Batch_idx: 100 |  Loss: (0.1837) |  Loss2: (0.0000) | Acc: (93.00%) (12135/12928)
Epoch: 118 | Batch_idx: 110 |  Loss: (0.1835) |  Loss2: (0.0000) | Acc: (93.00%) (13334/14208)
Epoch: 118 | Batch_idx: 120 |  Loss: (0.1869) |  Loss2: (0.0000) | Acc: (93.00%) (14507/15488)
Epoch: 118 | Batch_idx: 130 |  Loss: (0.1867) |  Loss2: (0.0000) | Acc: (93.00%) (15705/16768)
Epoch: 118 | Batch_idx: 140 |  Loss: (0.1864) |  Loss2: (0.0000) | Acc: (93.00%) (16907/18048)
Epoch: 118 | Batch_idx: 150 |  Loss: (0.1848) |  Loss2: (0.0000) | Acc: (93.00%) (18122/19328)
Epoch: 118 | Batch_idx: 160 |  Loss: (0.1843) |  Loss2: (0.0000) | Acc: (93.00%) (19322/20608)
Epoch: 118 | Batch_idx: 170 |  Loss: (0.1848) |  Loss2: (0.0000) | Acc: (93.00%) (20520/21888)
Epoch: 118 | Batch_idx: 180 |  Loss: (0.1849) |  Loss2: (0.0000) | Acc: (93.00%) (21717/23168)
Epoch: 118 | Batch_idx: 190 |  Loss: (0.1847) |  Loss2: (0.0000) | Acc: (93.00%) (22915/24448)
Epoch: 118 | Batch_idx: 200 |  Loss: (0.1854) |  Loss2: (0.0000) | Acc: (93.00%) (24111/25728)
Epoch: 118 | Batch_idx: 210 |  Loss: (0.1851) |  Loss2: (0.0000) | Acc: (93.00%) (25302/27008)
Epoch: 118 | Batch_idx: 220 |  Loss: (0.1847) |  Loss2: (0.0000) | Acc: (93.00%) (26502/28288)
Epoch: 118 | Batch_idx: 230 |  Loss: (0.1847) |  Loss2: (0.0000) | Acc: (93.00%) (27705/29568)
Epoch: 118 | Batch_idx: 240 |  Loss: (0.1853) |  Loss2: (0.0000) | Acc: (93.00%) (28901/30848)
Epoch: 118 | Batch_idx: 250 |  Loss: (0.1857) |  Loss2: (0.0000) | Acc: (93.00%) (30097/32128)
Epoch: 118 | Batch_idx: 260 |  Loss: (0.1842) |  Loss2: (0.0000) | Acc: (93.00%) (31314/33408)
Epoch: 118 | Batch_idx: 270 |  Loss: (0.1849) |  Loss2: (0.0000) | Acc: (93.00%) (32508/34688)
Epoch: 118 | Batch_idx: 280 |  Loss: (0.1850) |  Loss2: (0.0000) | Acc: (93.00%) (33704/35968)
Epoch: 118 | Batch_idx: 290 |  Loss: (0.1849) |  Loss2: (0.0000) | Acc: (93.00%) (34906/37248)
Epoch: 118 | Batch_idx: 300 |  Loss: (0.1839) |  Loss2: (0.0000) | Acc: (93.00%) (36118/38528)
Epoch: 118 | Batch_idx: 310 |  Loss: (0.1843) |  Loss2: (0.0000) | Acc: (93.00%) (37309/39808)
Epoch: 118 | Batch_idx: 320 |  Loss: (0.1840) |  Loss2: (0.0000) | Acc: (93.00%) (38510/41088)
Epoch: 118 | Batch_idx: 330 |  Loss: (0.1838) |  Loss2: (0.0000) | Acc: (93.00%) (39718/42368)
Epoch: 118 | Batch_idx: 340 |  Loss: (0.1837) |  Loss2: (0.0000) | Acc: (93.00%) (40917/43648)
Epoch: 118 | Batch_idx: 350 |  Loss: (0.1837) |  Loss2: (0.0000) | Acc: (93.00%) (42113/44928)
Epoch: 118 | Batch_idx: 360 |  Loss: (0.1838) |  Loss2: (0.0000) | Acc: (93.00%) (43302/46208)
Epoch: 118 | Batch_idx: 370 |  Loss: (0.1833) |  Loss2: (0.0000) | Acc: (93.00%) (44508/47488)
Epoch: 118 | Batch_idx: 380 |  Loss: (0.1825) |  Loss2: (0.0000) | Acc: (93.00%) (45725/48768)
Epoch: 118 | Batch_idx: 390 |  Loss: (0.1828) |  Loss2: (0.0000) | Acc: (93.00%) (46868/50000)
# TEST : Loss: (0.3786) | Acc: (88.00%) (8817/10000)
percent tensor([0.5712, 0.5851, 0.5677, 0.5684, 0.5737, 0.5886, 0.5842, 0.5645, 0.5670,
        0.5749, 0.5784, 0.5752, 0.5739, 0.5675, 0.5908, 0.5763],
       device='cuda:0') torch.Size([16])
percent tensor([0.5108, 0.5112, 0.5048, 0.5106, 0.5032, 0.5176, 0.5056, 0.5040, 0.5061,
        0.5095, 0.5124, 0.5056, 0.5079, 0.5108, 0.5134, 0.5129],
       device='cuda:0') torch.Size([16])
percent tensor([0.5305, 0.4278, 0.6538, 0.6469, 0.6711, 0.6082, 0.5091, 0.6332, 0.5577,
        0.4876, 0.4336, 0.5642, 0.4393, 0.4695, 0.4907, 0.5867],
       device='cuda:0') torch.Size([16])
percent tensor([0.6699, 0.7199, 0.5844, 0.6196, 0.5909, 0.5480, 0.6754, 0.6060, 0.6848,
        0.7223, 0.7437, 0.6670, 0.7061, 0.7257, 0.6606, 0.6460],
       device='cuda:0') torch.Size([16])
percent tensor([0.6949, 0.5943, 0.7265, 0.7092, 0.7448, 0.7722, 0.6857, 0.7420, 0.6513,
        0.5858, 0.5457, 0.5998, 0.5452, 0.6439, 0.6783, 0.7291],
       device='cuda:0') torch.Size([16])
percent tensor([0.5192, 0.6560, 0.6866, 0.7199, 0.7042, 0.7667, 0.6331, 0.5044, 0.6735,
        0.6222, 0.6702, 0.6766, 0.6327, 0.7120, 0.5153, 0.4935],
       device='cuda:0') torch.Size([16])
percent tensor([0.4424, 0.6377, 0.6116, 0.6476, 0.5956, 0.6013, 0.5876, 0.5306, 0.6684,
        0.6014, 0.6795, 0.6440, 0.5812, 0.6614, 0.5229, 0.4157],
       device='cuda:0') torch.Size([16])
percent tensor([0.9998, 0.9996, 0.9997, 0.9998, 1.0000, 0.9989, 0.9998, 0.9998, 0.9996,
        0.9998, 0.9996, 0.9998, 0.9993, 0.9995, 0.9997, 0.9995],
       device='cuda:0') torch.Size([16])
Epoch: 119 | Batch_idx: 0 |  Loss: (0.1727) |  Loss2: (0.0000) | Acc: (92.00%) (118/128)
Epoch: 119 | Batch_idx: 10 |  Loss: (0.1723) |  Loss2: (0.0000) | Acc: (93.00%) (1321/1408)
Epoch: 119 | Batch_idx: 20 |  Loss: (0.1723) |  Loss2: (0.0000) | Acc: (94.00%) (2530/2688)
Epoch: 119 | Batch_idx: 30 |  Loss: (0.1705) |  Loss2: (0.0000) | Acc: (94.00%) (3744/3968)
Epoch: 119 | Batch_idx: 40 |  Loss: (0.1737) |  Loss2: (0.0000) | Acc: (94.00%) (4941/5248)
Epoch: 119 | Batch_idx: 50 |  Loss: (0.1718) |  Loss2: (0.0000) | Acc: (94.00%) (6160/6528)
Epoch: 119 | Batch_idx: 60 |  Loss: (0.1740) |  Loss2: (0.0000) | Acc: (94.00%) (7357/7808)
Epoch: 119 | Batch_idx: 70 |  Loss: (0.1725) |  Loss2: (0.0000) | Acc: (94.00%) (8570/9088)
Epoch: 119 | Batch_idx: 80 |  Loss: (0.1716) |  Loss2: (0.0000) | Acc: (94.00%) (9776/10368)
Epoch: 119 | Batch_idx: 90 |  Loss: (0.1745) |  Loss2: (0.0000) | Acc: (94.00%) (10968/11648)
Epoch: 119 | Batch_idx: 100 |  Loss: (0.1737) |  Loss2: (0.0000) | Acc: (94.00%) (12171/12928)
Epoch: 119 | Batch_idx: 110 |  Loss: (0.1746) |  Loss2: (0.0000) | Acc: (94.00%) (13373/14208)
Epoch: 119 | Batch_idx: 120 |  Loss: (0.1760) |  Loss2: (0.0000) | Acc: (94.00%) (14582/15488)
Epoch: 119 | Batch_idx: 130 |  Loss: (0.1768) |  Loss2: (0.0000) | Acc: (94.00%) (15774/16768)
Epoch: 119 | Batch_idx: 140 |  Loss: (0.1761) |  Loss2: (0.0000) | Acc: (94.00%) (16978/18048)
Epoch: 119 | Batch_idx: 150 |  Loss: (0.1772) |  Loss2: (0.0000) | Acc: (94.00%) (18178/19328)
Epoch: 119 | Batch_idx: 160 |  Loss: (0.1789) |  Loss2: (0.0000) | Acc: (93.00%) (19361/20608)
Epoch: 119 | Batch_idx: 170 |  Loss: (0.1790) |  Loss2: (0.0000) | Acc: (93.00%) (20570/21888)
Epoch: 119 | Batch_idx: 180 |  Loss: (0.1785) |  Loss2: (0.0000) | Acc: (93.00%) (21777/23168)
Epoch: 119 | Batch_idx: 190 |  Loss: (0.1781) |  Loss2: (0.0000) | Acc: (93.00%) (22980/24448)
Epoch: 119 | Batch_idx: 200 |  Loss: (0.1776) |  Loss2: (0.0000) | Acc: (93.00%) (24184/25728)
Epoch: 119 | Batch_idx: 210 |  Loss: (0.1774) |  Loss2: (0.0000) | Acc: (94.00%) (25394/27008)
Epoch: 119 | Batch_idx: 220 |  Loss: (0.1774) |  Loss2: (0.0000) | Acc: (94.00%) (26598/28288)
Epoch: 119 | Batch_idx: 230 |  Loss: (0.1776) |  Loss2: (0.0000) | Acc: (93.00%) (27788/29568)
Epoch: 119 | Batch_idx: 240 |  Loss: (0.1776) |  Loss2: (0.0000) | Acc: (93.00%) (28988/30848)
Epoch: 119 | Batch_idx: 250 |  Loss: (0.1778) |  Loss2: (0.0000) | Acc: (93.00%) (30195/32128)
Epoch: 119 | Batch_idx: 260 |  Loss: (0.1774) |  Loss2: (0.0000) | Acc: (93.00%) (31399/33408)
Epoch: 119 | Batch_idx: 270 |  Loss: (0.1777) |  Loss2: (0.0000) | Acc: (93.00%) (32593/34688)
Epoch: 119 | Batch_idx: 280 |  Loss: (0.1772) |  Loss2: (0.0000) | Acc: (93.00%) (33794/35968)
Epoch: 119 | Batch_idx: 290 |  Loss: (0.1768) |  Loss2: (0.0000) | Acc: (93.00%) (34993/37248)
Epoch: 119 | Batch_idx: 300 |  Loss: (0.1768) |  Loss2: (0.0000) | Acc: (93.00%) (36197/38528)
Epoch: 119 | Batch_idx: 310 |  Loss: (0.1766) |  Loss2: (0.0000) | Acc: (93.00%) (37401/39808)
Epoch: 119 | Batch_idx: 320 |  Loss: (0.1762) |  Loss2: (0.0000) | Acc: (93.00%) (38618/41088)
Epoch: 119 | Batch_idx: 330 |  Loss: (0.1763) |  Loss2: (0.0000) | Acc: (93.00%) (39820/42368)
Epoch: 119 | Batch_idx: 340 |  Loss: (0.1764) |  Loss2: (0.0000) | Acc: (93.00%) (41029/43648)
Epoch: 119 | Batch_idx: 350 |  Loss: (0.1764) |  Loss2: (0.0000) | Acc: (94.00%) (42240/44928)
Epoch: 119 | Batch_idx: 360 |  Loss: (0.1763) |  Loss2: (0.0000) | Acc: (94.00%) (43448/46208)
Epoch: 119 | Batch_idx: 370 |  Loss: (0.1760) |  Loss2: (0.0000) | Acc: (94.00%) (44664/47488)
Epoch: 119 | Batch_idx: 380 |  Loss: (0.1758) |  Loss2: (0.0000) | Acc: (94.00%) (45871/48768)
Epoch: 119 | Batch_idx: 390 |  Loss: (0.1756) |  Loss2: (0.0000) | Acc: (94.00%) (47044/50000)
# TEST : Loss: (0.3733) | Acc: (88.00%) (8825/10000)
percent tensor([0.5680, 0.5814, 0.5646, 0.5658, 0.5706, 0.5851, 0.5804, 0.5617, 0.5642,
        0.5715, 0.5749, 0.5719, 0.5706, 0.5647, 0.5870, 0.5729],
       device='cuda:0') torch.Size([16])
percent tensor([0.5106, 0.5112, 0.5050, 0.5103, 0.5035, 0.5177, 0.5057, 0.5041, 0.5058,
        0.5094, 0.5121, 0.5057, 0.5078, 0.5106, 0.5135, 0.5126],
       device='cuda:0') torch.Size([16])
percent tensor([0.5319, 0.4279, 0.6541, 0.6473, 0.6719, 0.6077, 0.5112, 0.6340, 0.5600,
        0.4887, 0.4331, 0.5656, 0.4388, 0.4718, 0.4895, 0.5832],
       device='cuda:0') torch.Size([16])
percent tensor([0.6778, 0.7280, 0.5916, 0.6242, 0.5978, 0.5493, 0.6841, 0.6148, 0.6915,
        0.7307, 0.7510, 0.6754, 0.7149, 0.7322, 0.6679, 0.6529],
       device='cuda:0') torch.Size([16])
percent tensor([0.6982, 0.5966, 0.7308, 0.7144, 0.7491, 0.7774, 0.6874, 0.7433, 0.6564,
        0.5916, 0.5521, 0.6075, 0.5503, 0.6425, 0.6814, 0.7338],
       device='cuda:0') torch.Size([16])
percent tensor([0.5333, 0.6646, 0.6931, 0.7312, 0.7082, 0.7776, 0.6403, 0.5059, 0.6806,
        0.6301, 0.6803, 0.6837, 0.6399, 0.7254, 0.5255, 0.5062],
       device='cuda:0') torch.Size([16])
percent tensor([0.4570, 0.6573, 0.6278, 0.6579, 0.6078, 0.6190, 0.6046, 0.5386, 0.6815,
        0.6227, 0.6992, 0.6543, 0.6009, 0.6835, 0.5335, 0.4235],
       device='cuda:0') torch.Size([16])
percent tensor([0.9998, 0.9996, 0.9997, 0.9998, 1.0000, 0.9989, 0.9998, 0.9998, 0.9996,
        0.9998, 0.9996, 0.9998, 0.9994, 0.9995, 0.9997, 0.9995],
       device='cuda:0') torch.Size([16])
True Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=128, out_features=16, bias=False)
False Linear(in_features=16, out_features=2, bias=False)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=128, out_features=16, bias=False)
False Linear(in_features=16, out_features=2, bias=False)
True Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=256, out_features=32, bias=False)
False Linear(in_features=32, out_features=2, bias=False)
True Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=256, out_features=32, bias=False)
False Linear(in_features=32, out_features=2, bias=False)
True Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=512, out_features=64, bias=False)
False Linear(in_features=64, out_features=2, bias=False)
True Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=512, out_features=64, bias=False)
False Linear(in_features=64, out_features=2, bias=False)
True Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1024, out_features=128, bias=False)
False Linear(in_features=128, out_features=2, bias=False)
True Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1024, out_features=128, bias=False)
False Linear(in_features=128, out_features=2, bias=False)
True Linear(in_features=512, out_features=10, bias=True)
Epoch: 120 | Batch_idx: 0 |  Loss: (0.1353) |  Loss2: (0.0000) | Acc: (93.00%) (120/128)
Epoch: 120 | Batch_idx: 10 |  Loss: (0.1408) |  Loss2: (0.0000) | Acc: (95.00%) (1343/1408)
Epoch: 120 | Batch_idx: 20 |  Loss: (0.1506) |  Loss2: (0.0000) | Acc: (95.00%) (2557/2688)
Epoch: 120 | Batch_idx: 30 |  Loss: (0.1549) |  Loss2: (0.0000) | Acc: (95.00%) (3770/3968)
Epoch: 120 | Batch_idx: 40 |  Loss: (0.1540) |  Loss2: (0.0000) | Acc: (95.00%) (4989/5248)
Epoch: 120 | Batch_idx: 50 |  Loss: (0.1663) |  Loss2: (0.0000) | Acc: (94.00%) (6182/6528)
Epoch: 120 | Batch_idx: 60 |  Loss: (0.1680) |  Loss2: (0.0000) | Acc: (94.00%) (7383/7808)
Epoch: 120 | Batch_idx: 70 |  Loss: (0.1667) |  Loss2: (0.0000) | Acc: (94.00%) (8595/9088)
Epoch: 120 | Batch_idx: 80 |  Loss: (0.1692) |  Loss2: (0.0000) | Acc: (94.00%) (9796/10368)
Epoch: 120 | Batch_idx: 90 |  Loss: (0.1686) |  Loss2: (0.0000) | Acc: (94.00%) (11012/11648)
Epoch: 120 | Batch_idx: 100 |  Loss: (0.1702) |  Loss2: (0.0000) | Acc: (94.00%) (12221/12928)
Epoch: 120 | Batch_idx: 110 |  Loss: (0.1699) |  Loss2: (0.0000) | Acc: (94.00%) (13428/14208)
Epoch: 120 | Batch_idx: 120 |  Loss: (0.1705) |  Loss2: (0.0000) | Acc: (94.00%) (14627/15488)
Epoch: 120 | Batch_idx: 130 |  Loss: (0.1700) |  Loss2: (0.0000) | Acc: (94.00%) (15840/16768)
Epoch: 120 | Batch_idx: 140 |  Loss: (0.1710) |  Loss2: (0.0000) | Acc: (94.00%) (17036/18048)
Epoch: 120 | Batch_idx: 150 |  Loss: (0.1710) |  Loss2: (0.0000) | Acc: (94.00%) (18240/19328)
Epoch: 120 | Batch_idx: 160 |  Loss: (0.1716) |  Loss2: (0.0000) | Acc: (94.00%) (19438/20608)
Epoch: 120 | Batch_idx: 170 |  Loss: (0.1716) |  Loss2: (0.0000) | Acc: (94.00%) (20645/21888)
Epoch: 120 | Batch_idx: 180 |  Loss: (0.1706) |  Loss2: (0.0000) | Acc: (94.00%) (21854/23168)
Epoch: 120 | Batch_idx: 190 |  Loss: (0.1714) |  Loss2: (0.0000) | Acc: (94.00%) (23051/24448)
Epoch: 120 | Batch_idx: 200 |  Loss: (0.1710) |  Loss2: (0.0000) | Acc: (94.00%) (24253/25728)
Epoch: 120 | Batch_idx: 210 |  Loss: (0.1722) |  Loss2: (0.0000) | Acc: (94.00%) (25441/27008)
Epoch: 120 | Batch_idx: 220 |  Loss: (0.1722) |  Loss2: (0.0000) | Acc: (94.00%) (26639/28288)
Epoch: 120 | Batch_idx: 230 |  Loss: (0.1728) |  Loss2: (0.0000) | Acc: (94.00%) (27832/29568)
Epoch: 120 | Batch_idx: 240 |  Loss: (0.1728) |  Loss2: (0.0000) | Acc: (94.00%) (29030/30848)
Epoch: 120 | Batch_idx: 250 |  Loss: (0.1734) |  Loss2: (0.0000) | Acc: (94.00%) (30218/32128)
Epoch: 120 | Batch_idx: 260 |  Loss: (0.1734) |  Loss2: (0.0000) | Acc: (94.00%) (31419/33408)
Epoch: 120 | Batch_idx: 270 |  Loss: (0.1743) |  Loss2: (0.0000) | Acc: (94.00%) (32615/34688)
Epoch: 120 | Batch_idx: 280 |  Loss: (0.1738) |  Loss2: (0.0000) | Acc: (94.00%) (33830/35968)
Epoch: 120 | Batch_idx: 290 |  Loss: (0.1742) |  Loss2: (0.0000) | Acc: (94.00%) (35027/37248)
Epoch: 120 | Batch_idx: 300 |  Loss: (0.1751) |  Loss2: (0.0000) | Acc: (94.00%) (36221/38528)
Epoch: 120 | Batch_idx: 310 |  Loss: (0.1757) |  Loss2: (0.0000) | Acc: (93.00%) (37416/39808)
Epoch: 120 | Batch_idx: 320 |  Loss: (0.1759) |  Loss2: (0.0000) | Acc: (93.00%) (38605/41088)
Epoch: 120 | Batch_idx: 330 |  Loss: (0.1764) |  Loss2: (0.0000) | Acc: (93.00%) (39804/42368)
Epoch: 120 | Batch_idx: 340 |  Loss: (0.1761) |  Loss2: (0.0000) | Acc: (93.00%) (41022/43648)
Epoch: 120 | Batch_idx: 350 |  Loss: (0.1764) |  Loss2: (0.0000) | Acc: (93.00%) (42215/44928)
Epoch: 120 | Batch_idx: 360 |  Loss: (0.1767) |  Loss2: (0.0000) | Acc: (93.00%) (43412/46208)
Epoch: 120 | Batch_idx: 370 |  Loss: (0.1770) |  Loss2: (0.0000) | Acc: (93.00%) (44599/47488)
Epoch: 120 | Batch_idx: 380 |  Loss: (0.1765) |  Loss2: (0.0000) | Acc: (93.00%) (45812/48768)
Epoch: 120 | Batch_idx: 390 |  Loss: (0.1770) |  Loss2: (0.0000) | Acc: (93.00%) (46968/50000)
=> saving checkpoint 'drive/app/torch/save_Schedule/checkpoint_120.pth.tar'
# TEST : Loss: (0.4648) | Acc: (85.00%) (8574/10000)
percent tensor([0.5698, 0.5816, 0.5683, 0.5681, 0.5735, 0.5864, 0.5826, 0.5630, 0.5649,
        0.5738, 0.5760, 0.5758, 0.5722, 0.5624, 0.5886, 0.5744],
       device='cuda:0') torch.Size([16])
percent tensor([0.5101, 0.5107, 0.5038, 0.5097, 0.5032, 0.5178, 0.5048, 0.5036, 0.5045,
        0.5090, 0.5116, 0.5048, 0.5077, 0.5091, 0.5132, 0.5122],
       device='cuda:0') torch.Size([16])
percent tensor([0.5416, 0.4289, 0.6473, 0.6490, 0.6654, 0.6240, 0.5190, 0.6356, 0.5804,
        0.4850, 0.4382, 0.5640, 0.4483, 0.5047, 0.4938, 0.5870],
       device='cuda:0') torch.Size([16])
percent tensor([0.6841, 0.7284, 0.5999, 0.6259, 0.6130, 0.5366, 0.6855, 0.6168, 0.6890,
        0.7287, 0.7514, 0.6791, 0.7174, 0.7226, 0.6669, 0.6564],
       device='cuda:0') torch.Size([16])
percent tensor([0.7026, 0.5939, 0.7275, 0.7096, 0.7424, 0.7773, 0.6941, 0.7253, 0.6713,
        0.6053, 0.5683, 0.6107, 0.5724, 0.6354, 0.6836, 0.7266],
       device='cuda:0') torch.Size([16])
percent tensor([0.5382, 0.6318, 0.6958, 0.7361, 0.7267, 0.7832, 0.6703, 0.5264, 0.6918,
        0.6119, 0.6788, 0.6497, 0.6308, 0.6765, 0.5197, 0.5428],
       device='cuda:0') torch.Size([16])
percent tensor([0.4579, 0.6331, 0.6100, 0.6496, 0.6111, 0.6267, 0.5729, 0.5487, 0.6665,
        0.6138, 0.7016, 0.6001, 0.5752, 0.6508, 0.5293, 0.4294],
       device='cuda:0') torch.Size([16])
percent tensor([0.9998, 0.9997, 0.9998, 0.9999, 0.9999, 0.9993, 0.9998, 0.9997, 0.9996,
        0.9999, 0.9993, 0.9999, 0.9990, 0.9998, 0.9997, 0.9997],
       device='cuda:0') torch.Size([16])
Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 3, 3, 3]) tensor(182.5607, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(813.0330, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(819.3091, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([128, 64, 3, 3]) tensor(1517.2476, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([128, 64, 1, 1]) tensor(496.1782, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([128, 128, 3, 3]) tensor(2248.0254, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([256, 128, 3, 3]) tensor(4285.1196, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([256, 128, 1, 1]) tensor(1392.7230, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([256, 256, 3, 3]) tensor(6171.3115, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([512, 256, 3, 3]) tensor(11807.8232, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([512, 256, 1, 1]) tensor(3912.6582, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([512, 512, 3, 3]) tensor(16498.3945, device='cuda:0', grad_fn=<NormBackward0>)
Epoch: 121 | Batch_idx: 0 |  Loss: (0.1476) |  Loss2: (0.0000) | Acc: (96.00%) (124/128)
Epoch: 121 | Batch_idx: 10 |  Loss: (0.1637) |  Loss2: (0.0000) | Acc: (94.00%) (1336/1408)
Epoch: 121 | Batch_idx: 20 |  Loss: (0.1622) |  Loss2: (0.0000) | Acc: (94.00%) (2542/2688)
Epoch: 121 | Batch_idx: 30 |  Loss: (0.1626) |  Loss2: (0.0000) | Acc: (94.00%) (3752/3968)
Epoch: 121 | Batch_idx: 40 |  Loss: (0.1659) |  Loss2: (0.0000) | Acc: (94.00%) (4935/5248)
Epoch: 121 | Batch_idx: 50 |  Loss: (0.1650) |  Loss2: (0.0000) | Acc: (94.00%) (6140/6528)
Epoch: 121 | Batch_idx: 60 |  Loss: (0.1659) |  Loss2: (0.0000) | Acc: (94.00%) (7353/7808)
Epoch: 121 | Batch_idx: 70 |  Loss: (0.1646) |  Loss2: (0.0000) | Acc: (94.00%) (8571/9088)
Epoch: 121 | Batch_idx: 80 |  Loss: (0.1665) |  Loss2: (0.0000) | Acc: (94.00%) (9780/10368)
Epoch: 121 | Batch_idx: 90 |  Loss: (0.1660) |  Loss2: (0.0000) | Acc: (94.00%) (10988/11648)
Epoch: 121 | Batch_idx: 100 |  Loss: (0.1646) |  Loss2: (0.0000) | Acc: (94.00%) (12212/12928)
Epoch: 121 | Batch_idx: 110 |  Loss: (0.1665) |  Loss2: (0.0000) | Acc: (94.00%) (13405/14208)
Epoch: 121 | Batch_idx: 120 |  Loss: (0.1662) |  Loss2: (0.0000) | Acc: (94.00%) (14616/15488)
Epoch: 121 | Batch_idx: 130 |  Loss: (0.1649) |  Loss2: (0.0000) | Acc: (94.00%) (15839/16768)
Epoch: 121 | Batch_idx: 140 |  Loss: (0.1655) |  Loss2: (0.0000) | Acc: (94.00%) (17046/18048)
Epoch: 121 | Batch_idx: 150 |  Loss: (0.1652) |  Loss2: (0.0000) | Acc: (94.00%) (18252/19328)
Epoch: 121 | Batch_idx: 160 |  Loss: (0.1646) |  Loss2: (0.0000) | Acc: (94.00%) (19458/20608)
Epoch: 121 | Batch_idx: 170 |  Loss: (0.1647) |  Loss2: (0.0000) | Acc: (94.00%) (20662/21888)
Epoch: 121 | Batch_idx: 180 |  Loss: (0.1638) |  Loss2: (0.0000) | Acc: (94.00%) (21875/23168)
Epoch: 121 | Batch_idx: 190 |  Loss: (0.1661) |  Loss2: (0.0000) | Acc: (94.00%) (23064/24448)
Epoch: 121 | Batch_idx: 200 |  Loss: (0.1670) |  Loss2: (0.0000) | Acc: (94.00%) (24260/25728)
Epoch: 121 | Batch_idx: 210 |  Loss: (0.1671) |  Loss2: (0.0000) | Acc: (94.00%) (25462/27008)
Epoch: 121 | Batch_idx: 220 |  Loss: (0.1677) |  Loss2: (0.0000) | Acc: (94.00%) (26656/28288)
Epoch: 121 | Batch_idx: 230 |  Loss: (0.1671) |  Loss2: (0.0000) | Acc: (94.00%) (27863/29568)
Epoch: 121 | Batch_idx: 240 |  Loss: (0.1662) |  Loss2: (0.0000) | Acc: (94.00%) (29076/30848)
Epoch: 121 | Batch_idx: 250 |  Loss: (0.1655) |  Loss2: (0.0000) | Acc: (94.00%) (30286/32128)
Epoch: 121 | Batch_idx: 260 |  Loss: (0.1661) |  Loss2: (0.0000) | Acc: (94.00%) (31482/33408)
Epoch: 121 | Batch_idx: 270 |  Loss: (0.1662) |  Loss2: (0.0000) | Acc: (94.00%) (32679/34688)
Epoch: 121 | Batch_idx: 280 |  Loss: (0.1667) |  Loss2: (0.0000) | Acc: (94.00%) (33882/35968)
Epoch: 121 | Batch_idx: 290 |  Loss: (0.1668) |  Loss2: (0.0000) | Acc: (94.00%) (35086/37248)
Epoch: 121 | Batch_idx: 300 |  Loss: (0.1670) |  Loss2: (0.0000) | Acc: (94.00%) (36286/38528)
Epoch: 121 | Batch_idx: 310 |  Loss: (0.1670) |  Loss2: (0.0000) | Acc: (94.00%) (37492/39808)
Epoch: 121 | Batch_idx: 320 |  Loss: (0.1673) |  Loss2: (0.0000) | Acc: (94.00%) (38697/41088)
Epoch: 121 | Batch_idx: 330 |  Loss: (0.1678) |  Loss2: (0.0000) | Acc: (94.00%) (39897/42368)
Epoch: 121 | Batch_idx: 340 |  Loss: (0.1687) |  Loss2: (0.0000) | Acc: (94.00%) (41089/43648)
Epoch: 121 | Batch_idx: 350 |  Loss: (0.1689) |  Loss2: (0.0000) | Acc: (94.00%) (42291/44928)
Epoch: 121 | Batch_idx: 360 |  Loss: (0.1686) |  Loss2: (0.0000) | Acc: (94.00%) (43507/46208)
Epoch: 121 | Batch_idx: 370 |  Loss: (0.1691) |  Loss2: (0.0000) | Acc: (94.00%) (44695/47488)
Epoch: 121 | Batch_idx: 380 |  Loss: (0.1694) |  Loss2: (0.0000) | Acc: (94.00%) (45901/48768)
Epoch: 121 | Batch_idx: 390 |  Loss: (0.1695) |  Loss2: (0.0000) | Acc: (94.00%) (47064/50000)
# TEST : Loss: (0.3992) | Acc: (87.00%) (8772/10000)
percent tensor([0.5693, 0.5821, 0.5626, 0.5662, 0.5697, 0.5866, 0.5806, 0.5607, 0.5643,
        0.5719, 0.5768, 0.5706, 0.5717, 0.5644, 0.5886, 0.5740],
       device='cuda:0') torch.Size([16])
percent tensor([0.5107, 0.5110, 0.5051, 0.5102, 0.5040, 0.5193, 0.5054, 0.5037, 0.5053,
        0.5092, 0.5118, 0.5060, 0.5080, 0.5094, 0.5136, 0.5129],
       device='cuda:0') torch.Size([16])
percent tensor([0.5333, 0.4217, 0.6611, 0.6588, 0.6739, 0.6164, 0.5109, 0.6426, 0.5693,
        0.4878, 0.4307, 0.5675, 0.4359, 0.4894, 0.4875, 0.5825],
       device='cuda:0') torch.Size([16])
percent tensor([0.6823, 0.7278, 0.5981, 0.6293, 0.6091, 0.5370, 0.6857, 0.6187, 0.6926,
        0.7280, 0.7473, 0.6842, 0.7190, 0.7221, 0.6680, 0.6560],
       device='cuda:0') torch.Size([16])
percent tensor([0.7034, 0.5993, 0.7241, 0.7210, 0.7419, 0.7819, 0.6947, 0.7240, 0.6647,
        0.6070, 0.5697, 0.6073, 0.5540, 0.6539, 0.6873, 0.7303],
       device='cuda:0') torch.Size([16])
percent tensor([0.5094, 0.6419, 0.6852, 0.7390, 0.7368, 0.7727, 0.6662, 0.5332, 0.6859,
        0.5956, 0.6828, 0.6466, 0.6191, 0.6962, 0.4762, 0.4891],
       device='cuda:0') torch.Size([16])
percent tensor([0.4585, 0.6529, 0.6199, 0.6534, 0.6273, 0.6243, 0.6143, 0.5650, 0.6666,
        0.6047, 0.7083, 0.6468, 0.5852, 0.6562, 0.5293, 0.4408],
       device='cuda:0') torch.Size([16])
percent tensor([0.9997, 0.9996, 0.9997, 0.9998, 1.0000, 0.9985, 0.9998, 0.9998, 0.9995,
        0.9999, 0.9994, 0.9998, 0.9988, 0.9995, 0.9997, 0.9996],
       device='cuda:0') torch.Size([16])
Epoch: 122 | Batch_idx: 0 |  Loss: (0.1392) |  Loss2: (0.0000) | Acc: (96.00%) (123/128)
Epoch: 122 | Batch_idx: 10 |  Loss: (0.1353) |  Loss2: (0.0000) | Acc: (95.00%) (1343/1408)
Epoch: 122 | Batch_idx: 20 |  Loss: (0.1421) |  Loss2: (0.0000) | Acc: (94.00%) (2550/2688)
Epoch: 122 | Batch_idx: 30 |  Loss: (0.1487) |  Loss2: (0.0000) | Acc: (94.00%) (3760/3968)
Epoch: 122 | Batch_idx: 40 |  Loss: (0.1512) |  Loss2: (0.0000) | Acc: (94.00%) (4966/5248)
Epoch: 122 | Batch_idx: 50 |  Loss: (0.1537) |  Loss2: (0.0000) | Acc: (94.00%) (6176/6528)
Epoch: 122 | Batch_idx: 60 |  Loss: (0.1569) |  Loss2: (0.0000) | Acc: (94.00%) (7374/7808)
Epoch: 122 | Batch_idx: 70 |  Loss: (0.1592) |  Loss2: (0.0000) | Acc: (94.00%) (8582/9088)
Epoch: 122 | Batch_idx: 80 |  Loss: (0.1571) |  Loss2: (0.0000) | Acc: (94.00%) (9798/10368)
Epoch: 122 | Batch_idx: 90 |  Loss: (0.1589) |  Loss2: (0.0000) | Acc: (94.00%) (11009/11648)
Epoch: 122 | Batch_idx: 100 |  Loss: (0.1609) |  Loss2: (0.0000) | Acc: (94.00%) (12205/12928)
Epoch: 122 | Batch_idx: 110 |  Loss: (0.1643) |  Loss2: (0.0000) | Acc: (94.00%) (13405/14208)
Epoch: 122 | Batch_idx: 120 |  Loss: (0.1665) |  Loss2: (0.0000) | Acc: (94.00%) (14606/15488)
Epoch: 122 | Batch_idx: 130 |  Loss: (0.1666) |  Loss2: (0.0000) | Acc: (94.00%) (15809/16768)
Epoch: 122 | Batch_idx: 140 |  Loss: (0.1687) |  Loss2: (0.0000) | Acc: (94.00%) (16996/18048)
Epoch: 122 | Batch_idx: 150 |  Loss: (0.1685) |  Loss2: (0.0000) | Acc: (94.00%) (18207/19328)
Epoch: 122 | Batch_idx: 160 |  Loss: (0.1688) |  Loss2: (0.0000) | Acc: (94.00%) (19408/20608)
Epoch: 122 | Batch_idx: 170 |  Loss: (0.1687) |  Loss2: (0.0000) | Acc: (94.00%) (20609/21888)
Epoch: 122 | Batch_idx: 180 |  Loss: (0.1675) |  Loss2: (0.0000) | Acc: (94.00%) (21821/23168)
Epoch: 122 | Batch_idx: 190 |  Loss: (0.1671) |  Loss2: (0.0000) | Acc: (94.00%) (23029/24448)
Epoch: 122 | Batch_idx: 200 |  Loss: (0.1668) |  Loss2: (0.0000) | Acc: (94.00%) (24241/25728)
Epoch: 122 | Batch_idx: 210 |  Loss: (0.1662) |  Loss2: (0.0000) | Acc: (94.00%) (25459/27008)
Epoch: 122 | Batch_idx: 220 |  Loss: (0.1653) |  Loss2: (0.0000) | Acc: (94.00%) (26680/28288)
Epoch: 122 | Batch_idx: 230 |  Loss: (0.1648) |  Loss2: (0.0000) | Acc: (94.00%) (27896/29568)
Epoch: 122 | Batch_idx: 240 |  Loss: (0.1652) |  Loss2: (0.0000) | Acc: (94.00%) (29098/30848)
Epoch: 122 | Batch_idx: 250 |  Loss: (0.1658) |  Loss2: (0.0000) | Acc: (94.00%) (30290/32128)
Epoch: 122 | Batch_idx: 260 |  Loss: (0.1660) |  Loss2: (0.0000) | Acc: (94.00%) (31492/33408)
Epoch: 122 | Batch_idx: 270 |  Loss: (0.1665) |  Loss2: (0.0000) | Acc: (94.00%) (32687/34688)
Epoch: 122 | Batch_idx: 280 |  Loss: (0.1656) |  Loss2: (0.0000) | Acc: (94.00%) (33914/35968)
Epoch: 122 | Batch_idx: 290 |  Loss: (0.1667) |  Loss2: (0.0000) | Acc: (94.00%) (35106/37248)
Epoch: 122 | Batch_idx: 300 |  Loss: (0.1669) |  Loss2: (0.0000) | Acc: (94.00%) (36304/38528)
Epoch: 122 | Batch_idx: 310 |  Loss: (0.1666) |  Loss2: (0.0000) | Acc: (94.00%) (37519/39808)
Epoch: 122 | Batch_idx: 320 |  Loss: (0.1663) |  Loss2: (0.0000) | Acc: (94.00%) (38736/41088)
Epoch: 122 | Batch_idx: 330 |  Loss: (0.1664) |  Loss2: (0.0000) | Acc: (94.00%) (39937/42368)
Epoch: 122 | Batch_idx: 340 |  Loss: (0.1661) |  Loss2: (0.0000) | Acc: (94.00%) (41144/43648)
Epoch: 122 | Batch_idx: 350 |  Loss: (0.1659) |  Loss2: (0.0000) | Acc: (94.00%) (42347/44928)
Epoch: 122 | Batch_idx: 360 |  Loss: (0.1665) |  Loss2: (0.0000) | Acc: (94.00%) (43552/46208)
Epoch: 122 | Batch_idx: 370 |  Loss: (0.1664) |  Loss2: (0.0000) | Acc: (94.00%) (44762/47488)
Epoch: 122 | Batch_idx: 380 |  Loss: (0.1661) |  Loss2: (0.0000) | Acc: (94.00%) (45969/48768)
Epoch: 122 | Batch_idx: 390 |  Loss: (0.1664) |  Loss2: (0.0000) | Acc: (94.00%) (47124/50000)
# TEST : Loss: (0.4034) | Acc: (87.00%) (8741/10000)
percent tensor([0.5698, 0.5814, 0.5669, 0.5683, 0.5719, 0.5857, 0.5811, 0.5630, 0.5645,
        0.5727, 0.5758, 0.5734, 0.5719, 0.5620, 0.5881, 0.5740],
       device='cuda:0') torch.Size([16])
percent tensor([0.5104, 0.5111, 0.5032, 0.5096, 0.5024, 0.5197, 0.5054, 0.5024, 0.5053,
        0.5088, 0.5122, 0.5050, 0.5076, 0.5107, 0.5138, 0.5125],
       device='cuda:0') torch.Size([16])
percent tensor([0.5408, 0.4212, 0.6726, 0.6581, 0.6819, 0.6230, 0.5119, 0.6457, 0.5755,
        0.4989, 0.4416, 0.5937, 0.4477, 0.4592, 0.4927, 0.5863],
       device='cuda:0') torch.Size([16])
percent tensor([0.6899, 0.7383, 0.5958, 0.6348, 0.6055, 0.5363, 0.6900, 0.6205, 0.6980,
        0.7344, 0.7540, 0.6809, 0.7267, 0.7391, 0.6736, 0.6660],
       device='cuda:0') torch.Size([16])
percent tensor([0.6908, 0.5852, 0.7206, 0.7086, 0.7357, 0.7811, 0.6801, 0.7284, 0.6506,
        0.5845, 0.5554, 0.5946, 0.5409, 0.6369, 0.6764, 0.7177],
       device='cuda:0') torch.Size([16])
percent tensor([0.5189, 0.6671, 0.6865, 0.7334, 0.6949, 0.7621, 0.6617, 0.4946, 0.6752,
        0.6404, 0.6833, 0.6761, 0.6342, 0.7157, 0.5437, 0.5045],
       device='cuda:0') torch.Size([16])
percent tensor([0.4586, 0.6566, 0.6034, 0.6557, 0.6024, 0.5942, 0.6236, 0.5374, 0.6511,
        0.6280, 0.6974, 0.6549, 0.6008, 0.6655, 0.5309, 0.4377],
       device='cuda:0') torch.Size([16])
percent tensor([0.9997, 0.9996, 0.9997, 0.9998, 0.9999, 0.9992, 0.9998, 0.9996, 0.9996,
        0.9998, 0.9994, 0.9998, 0.9990, 0.9995, 0.9997, 0.9997],
       device='cuda:0') torch.Size([16])
False Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=128, out_features=16, bias=False)
True Linear(in_features=16, out_features=2, bias=False)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=128, out_features=16, bias=False)
True Linear(in_features=16, out_features=2, bias=False)
False Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=256, out_features=32, bias=False)
True Linear(in_features=32, out_features=2, bias=False)
False Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=256, out_features=32, bias=False)
True Linear(in_features=32, out_features=2, bias=False)
False Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=512, out_features=64, bias=False)
True Linear(in_features=64, out_features=2, bias=False)
False Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=512, out_features=64, bias=False)
True Linear(in_features=64, out_features=2, bias=False)
False Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1024, out_features=128, bias=False)
True Linear(in_features=128, out_features=2, bias=False)
False Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1024, out_features=128, bias=False)
True Linear(in_features=128, out_features=2, bias=False)
False Linear(in_features=512, out_features=10, bias=True)
Epoch: 123 | Batch_idx: 0 |  Loss: (0.1870) |  Loss2: (0.0000) | Acc: (92.00%) (119/128)
Epoch: 123 | Batch_idx: 10 |  Loss: (0.1689) |  Loss2: (0.0000) | Acc: (93.00%) (1322/1408)
Epoch: 123 | Batch_idx: 20 |  Loss: (0.1814) |  Loss2: (0.0000) | Acc: (93.00%) (2500/2688)
Epoch: 123 | Batch_idx: 30 |  Loss: (0.1978) |  Loss2: (0.0000) | Acc: (92.00%) (3677/3968)
Epoch: 123 | Batch_idx: 40 |  Loss: (0.1998) |  Loss2: (0.0000) | Acc: (92.00%) (4856/5248)
Epoch: 123 | Batch_idx: 50 |  Loss: (0.2068) |  Loss2: (0.0000) | Acc: (92.00%) (6029/6528)
Epoch: 123 | Batch_idx: 60 |  Loss: (0.2099) |  Loss2: (0.0000) | Acc: (92.00%) (7200/7808)
Epoch: 123 | Batch_idx: 70 |  Loss: (0.2131) |  Loss2: (0.0000) | Acc: (92.00%) (8370/9088)
Epoch: 123 | Batch_idx: 80 |  Loss: (0.2164) |  Loss2: (0.0000) | Acc: (91.00%) (9537/10368)
Epoch: 123 | Batch_idx: 90 |  Loss: (0.2166) |  Loss2: (0.0000) | Acc: (92.00%) (10721/11648)
Epoch: 123 | Batch_idx: 100 |  Loss: (0.2161) |  Loss2: (0.0000) | Acc: (92.00%) (11914/12928)
Epoch: 123 | Batch_idx: 110 |  Loss: (0.2145) |  Loss2: (0.0000) | Acc: (92.00%) (13102/14208)
Epoch: 123 | Batch_idx: 120 |  Loss: (0.2141) |  Loss2: (0.0000) | Acc: (92.00%) (14286/15488)
Epoch: 123 | Batch_idx: 130 |  Loss: (0.2142) |  Loss2: (0.0000) | Acc: (92.00%) (15473/16768)
Epoch: 123 | Batch_idx: 140 |  Loss: (0.2132) |  Loss2: (0.0000) | Acc: (92.00%) (16669/18048)
Epoch: 123 | Batch_idx: 150 |  Loss: (0.2122) |  Loss2: (0.0000) | Acc: (92.00%) (17854/19328)
Epoch: 123 | Batch_idx: 160 |  Loss: (0.2146) |  Loss2: (0.0000) | Acc: (92.00%) (19025/20608)
Epoch: 123 | Batch_idx: 170 |  Loss: (0.2127) |  Loss2: (0.0000) | Acc: (92.00%) (20229/21888)
Epoch: 123 | Batch_idx: 180 |  Loss: (0.2122) |  Loss2: (0.0000) | Acc: (92.00%) (21418/23168)
Epoch: 123 | Batch_idx: 190 |  Loss: (0.2114) |  Loss2: (0.0000) | Acc: (92.00%) (22609/24448)
Epoch: 123 | Batch_idx: 200 |  Loss: (0.2100) |  Loss2: (0.0000) | Acc: (92.00%) (23806/25728)
Epoch: 123 | Batch_idx: 210 |  Loss: (0.2082) |  Loss2: (0.0000) | Acc: (92.00%) (25014/27008)
Epoch: 123 | Batch_idx: 220 |  Loss: (0.2072) |  Loss2: (0.0000) | Acc: (92.00%) (26216/28288)
Epoch: 123 | Batch_idx: 230 |  Loss: (0.2071) |  Loss2: (0.0000) | Acc: (92.00%) (27405/29568)
Epoch: 123 | Batch_idx: 240 |  Loss: (0.2067) |  Loss2: (0.0000) | Acc: (92.00%) (28596/30848)
Epoch: 123 | Batch_idx: 250 |  Loss: (0.2058) |  Loss2: (0.0000) | Acc: (92.00%) (29794/32128)
Epoch: 123 | Batch_idx: 260 |  Loss: (0.2045) |  Loss2: (0.0000) | Acc: (92.00%) (31000/33408)
Epoch: 123 | Batch_idx: 270 |  Loss: (0.2031) |  Loss2: (0.0000) | Acc: (92.00%) (32203/34688)
Epoch: 123 | Batch_idx: 280 |  Loss: (0.2029) |  Loss2: (0.0000) | Acc: (92.00%) (33392/35968)
Epoch: 123 | Batch_idx: 290 |  Loss: (0.2024) |  Loss2: (0.0000) | Acc: (92.00%) (34577/37248)
Epoch: 123 | Batch_idx: 300 |  Loss: (0.2015) |  Loss2: (0.0000) | Acc: (92.00%) (35779/38528)
Epoch: 123 | Batch_idx: 310 |  Loss: (0.2012) |  Loss2: (0.0000) | Acc: (92.00%) (36973/39808)
Epoch: 123 | Batch_idx: 320 |  Loss: (0.2008) |  Loss2: (0.0000) | Acc: (92.00%) (38168/41088)
Epoch: 123 | Batch_idx: 330 |  Loss: (0.2001) |  Loss2: (0.0000) | Acc: (92.00%) (39368/42368)
Epoch: 123 | Batch_idx: 340 |  Loss: (0.1995) |  Loss2: (0.0000) | Acc: (92.00%) (40569/43648)
Epoch: 123 | Batch_idx: 350 |  Loss: (0.1989) |  Loss2: (0.0000) | Acc: (92.00%) (41770/44928)
Epoch: 123 | Batch_idx: 360 |  Loss: (0.1980) |  Loss2: (0.0000) | Acc: (93.00%) (42983/46208)
Epoch: 123 | Batch_idx: 370 |  Loss: (0.1972) |  Loss2: (0.0000) | Acc: (93.00%) (44193/47488)
Epoch: 123 | Batch_idx: 380 |  Loss: (0.1970) |  Loss2: (0.0000) | Acc: (93.00%) (45385/48768)
Epoch: 123 | Batch_idx: 390 |  Loss: (0.1970) |  Loss2: (0.0000) | Acc: (93.00%) (46527/50000)
# TEST : Loss: (0.4145) | Acc: (87.00%) (8711/10000)
percent tensor([0.5682, 0.5800, 0.5660, 0.5683, 0.5703, 0.5829, 0.5790, 0.5628, 0.5631,
        0.5717, 0.5739, 0.5721, 0.5703, 0.5617, 0.5861, 0.5730],
       device='cuda:0') torch.Size([16])
percent tensor([0.5212, 0.5223, 0.5134, 0.5196, 0.5149, 0.5302, 0.5184, 0.5141, 0.5157,
        0.5191, 0.5232, 0.5149, 0.5187, 0.5205, 0.5251, 0.5224],
       device='cuda:0') torch.Size([16])
percent tensor([0.5697, 0.4247, 0.6942, 0.6838, 0.7015, 0.6418, 0.5280, 0.6774, 0.6143,
        0.5167, 0.4631, 0.6041, 0.4636, 0.4869, 0.5069, 0.6156],
       device='cuda:0') torch.Size([16])
percent tensor([0.6973, 0.7478, 0.6125, 0.6436, 0.6222, 0.5400, 0.6999, 0.6274, 0.7047,
        0.7421, 0.7631, 0.7003, 0.7389, 0.7415, 0.6865, 0.6717],
       device='cuda:0') torch.Size([16])
percent tensor([0.7304, 0.6223, 0.7656, 0.7447, 0.7692, 0.8116, 0.7201, 0.7644, 0.6998,
        0.6289, 0.5944, 0.6396, 0.5861, 0.6739, 0.7098, 0.7591],
       device='cuda:0') torch.Size([16])
percent tensor([0.5199, 0.6553, 0.6603, 0.7194, 0.6775, 0.7673, 0.6563, 0.4704, 0.6718,
        0.6225, 0.6894, 0.6513, 0.6245, 0.7096, 0.5159, 0.5006],
       device='cuda:0') torch.Size([16])
percent tensor([0.4968, 0.6775, 0.5932, 0.6606, 0.5863, 0.6094, 0.6335, 0.5395, 0.6725,
        0.6583, 0.7177, 0.6675, 0.6399, 0.6769, 0.5630, 0.4594],
       device='cuda:0') torch.Size([16])
percent tensor([0.9997, 0.9997, 0.9996, 0.9998, 0.9999, 0.9988, 0.9998, 0.9996, 0.9995,
        0.9997, 0.9995, 0.9998, 0.9990, 0.9995, 0.9997, 0.9997],
       device='cuda:0') torch.Size([16])
Epoch: 124 | Batch_idx: 0 |  Loss: (0.1872) |  Loss2: (0.0000) | Acc: (92.00%) (119/128)
Epoch: 124 | Batch_idx: 10 |  Loss: (0.2032) |  Loss2: (0.0000) | Acc: (92.00%) (1305/1408)
Epoch: 124 | Batch_idx: 20 |  Loss: (0.1914) |  Loss2: (0.0000) | Acc: (93.00%) (2503/2688)
Epoch: 124 | Batch_idx: 30 |  Loss: (0.1889) |  Loss2: (0.0000) | Acc: (93.00%) (3701/3968)
Epoch: 124 | Batch_idx: 40 |  Loss: (0.1947) |  Loss2: (0.0000) | Acc: (93.00%) (4888/5248)
Epoch: 124 | Batch_idx: 50 |  Loss: (0.1920) |  Loss2: (0.0000) | Acc: (93.00%) (6082/6528)
Epoch: 124 | Batch_idx: 60 |  Loss: (0.1866) |  Loss2: (0.0000) | Acc: (93.00%) (7294/7808)
Epoch: 124 | Batch_idx: 70 |  Loss: (0.1861) |  Loss2: (0.0000) | Acc: (93.00%) (8488/9088)
Epoch: 124 | Batch_idx: 80 |  Loss: (0.1837) |  Loss2: (0.0000) | Acc: (93.00%) (9693/10368)
Epoch: 124 | Batch_idx: 90 |  Loss: (0.1813) |  Loss2: (0.0000) | Acc: (93.00%) (10905/11648)
Epoch: 124 | Batch_idx: 100 |  Loss: (0.1813) |  Loss2: (0.0000) | Acc: (93.00%) (12106/12928)
Epoch: 124 | Batch_idx: 110 |  Loss: (0.1807) |  Loss2: (0.0000) | Acc: (93.00%) (13308/14208)
Epoch: 124 | Batch_idx: 120 |  Loss: (0.1798) |  Loss2: (0.0000) | Acc: (93.00%) (14507/15488)
Epoch: 124 | Batch_idx: 130 |  Loss: (0.1803) |  Loss2: (0.0000) | Acc: (93.00%) (15704/16768)
Epoch: 124 | Batch_idx: 140 |  Loss: (0.1795) |  Loss2: (0.0000) | Acc: (93.00%) (16910/18048)
Epoch: 124 | Batch_idx: 150 |  Loss: (0.1788) |  Loss2: (0.0000) | Acc: (93.00%) (18114/19328)
Epoch: 124 | Batch_idx: 160 |  Loss: (0.1773) |  Loss2: (0.0000) | Acc: (93.00%) (19326/20608)
Epoch: 124 | Batch_idx: 170 |  Loss: (0.1762) |  Loss2: (0.0000) | Acc: (93.00%) (20531/21888)
Epoch: 124 | Batch_idx: 180 |  Loss: (0.1760) |  Loss2: (0.0000) | Acc: (93.00%) (21733/23168)
Epoch: 124 | Batch_idx: 190 |  Loss: (0.1751) |  Loss2: (0.0000) | Acc: (93.00%) (22950/24448)
Epoch: 124 | Batch_idx: 200 |  Loss: (0.1739) |  Loss2: (0.0000) | Acc: (93.00%) (24165/25728)
Epoch: 124 | Batch_idx: 210 |  Loss: (0.1737) |  Loss2: (0.0000) | Acc: (93.00%) (25370/27008)
Epoch: 124 | Batch_idx: 220 |  Loss: (0.1734) |  Loss2: (0.0000) | Acc: (93.00%) (26568/28288)
Epoch: 124 | Batch_idx: 230 |  Loss: (0.1734) |  Loss2: (0.0000) | Acc: (93.00%) (27763/29568)
Epoch: 124 | Batch_idx: 240 |  Loss: (0.1736) |  Loss2: (0.0000) | Acc: (93.00%) (28973/30848)
Epoch: 124 | Batch_idx: 250 |  Loss: (0.1736) |  Loss2: (0.0000) | Acc: (93.00%) (30173/32128)
Epoch: 124 | Batch_idx: 260 |  Loss: (0.1729) |  Loss2: (0.0000) | Acc: (93.00%) (31375/33408)
Epoch: 124 | Batch_idx: 270 |  Loss: (0.1740) |  Loss2: (0.0000) | Acc: (93.00%) (32568/34688)
Epoch: 124 | Batch_idx: 280 |  Loss: (0.1742) |  Loss2: (0.0000) | Acc: (93.00%) (33777/35968)
Epoch: 124 | Batch_idx: 290 |  Loss: (0.1741) |  Loss2: (0.0000) | Acc: (93.00%) (34982/37248)
Epoch: 124 | Batch_idx: 300 |  Loss: (0.1735) |  Loss2: (0.0000) | Acc: (93.00%) (36193/38528)
Epoch: 124 | Batch_idx: 310 |  Loss: (0.1730) |  Loss2: (0.0000) | Acc: (93.00%) (37395/39808)
Epoch: 124 | Batch_idx: 320 |  Loss: (0.1734) |  Loss2: (0.0000) | Acc: (93.00%) (38588/41088)
Epoch: 124 | Batch_idx: 330 |  Loss: (0.1733) |  Loss2: (0.0000) | Acc: (93.00%) (39792/42368)
Epoch: 124 | Batch_idx: 340 |  Loss: (0.1736) |  Loss2: (0.0000) | Acc: (93.00%) (40993/43648)
Epoch: 124 | Batch_idx: 350 |  Loss: (0.1735) |  Loss2: (0.0000) | Acc: (93.00%) (42207/44928)
Epoch: 124 | Batch_idx: 360 |  Loss: (0.1731) |  Loss2: (0.0000) | Acc: (93.00%) (43410/46208)
Epoch: 124 | Batch_idx: 370 |  Loss: (0.1734) |  Loss2: (0.0000) | Acc: (93.00%) (44598/47488)
Epoch: 124 | Batch_idx: 380 |  Loss: (0.1730) |  Loss2: (0.0000) | Acc: (93.00%) (45815/48768)
Epoch: 124 | Batch_idx: 390 |  Loss: (0.1732) |  Loss2: (0.0000) | Acc: (93.00%) (46970/50000)
# TEST : Loss: (0.3919) | Acc: (87.00%) (8764/10000)
percent tensor([0.5653, 0.5764, 0.5637, 0.5659, 0.5675, 0.5801, 0.5756, 0.5602, 0.5602,
        0.5687, 0.5705, 0.5693, 0.5670, 0.5593, 0.5826, 0.5701],
       device='cuda:0') torch.Size([16])
percent tensor([0.5270, 0.5281, 0.5186, 0.5247, 0.5211, 0.5355, 0.5246, 0.5202, 0.5215,
        0.5244, 0.5290, 0.5200, 0.5240, 0.5256, 0.5313, 0.5276],
       device='cuda:0') torch.Size([16])
percent tensor([0.5592, 0.4094, 0.6953, 0.6829, 0.7012, 0.6420, 0.5143, 0.6758, 0.6084,
        0.5051, 0.4502, 0.5935, 0.4495, 0.4779, 0.4927, 0.6073],
       device='cuda:0') torch.Size([16])
percent tensor([0.6854, 0.7381, 0.6003, 0.6310, 0.6074, 0.5263, 0.6886, 0.6167, 0.6940,
        0.7303, 0.7525, 0.6891, 0.7284, 0.7313, 0.6724, 0.6573],
       device='cuda:0') torch.Size([16])
percent tensor([0.7374, 0.6241, 0.7774, 0.7528, 0.7761, 0.8180, 0.7239, 0.7683, 0.7056,
        0.6332, 0.5965, 0.6544, 0.5980, 0.6653, 0.7176, 0.7638],
       device='cuda:0') torch.Size([16])
percent tensor([0.5303, 0.6685, 0.6613, 0.7249, 0.6873, 0.7685, 0.6681, 0.4807, 0.6727,
        0.6335, 0.6925, 0.6549, 0.6315, 0.7159, 0.5285, 0.5127],
       device='cuda:0') torch.Size([16])
percent tensor([0.5086, 0.6885, 0.5914, 0.6550, 0.5766, 0.6091, 0.6370, 0.5359, 0.6710,
        0.6674, 0.7206, 0.6645, 0.6491, 0.6947, 0.5662, 0.4595],
       device='cuda:0') torch.Size([16])
percent tensor([0.9997, 0.9997, 0.9996, 0.9998, 0.9999, 0.9988, 0.9997, 0.9996, 0.9995,
        0.9997, 0.9995, 0.9998, 0.9990, 0.9995, 0.9997, 0.9997],
       device='cuda:0') torch.Size([16])
Epoch: 125 | Batch_idx: 0 |  Loss: (0.1253) |  Loss2: (0.0000) | Acc: (96.00%) (123/128)
Epoch: 125 | Batch_idx: 10 |  Loss: (0.1746) |  Loss2: (0.0000) | Acc: (93.00%) (1311/1408)
Epoch: 125 | Batch_idx: 20 |  Loss: (0.1688) |  Loss2: (0.0000) | Acc: (93.00%) (2515/2688)
Epoch: 125 | Batch_idx: 30 |  Loss: (0.1683) |  Loss2: (0.0000) | Acc: (93.00%) (3727/3968)
Epoch: 125 | Batch_idx: 40 |  Loss: (0.1637) |  Loss2: (0.0000) | Acc: (94.00%) (4946/5248)
Epoch: 125 | Batch_idx: 50 |  Loss: (0.1664) |  Loss2: (0.0000) | Acc: (94.00%) (6144/6528)
Epoch: 125 | Batch_idx: 60 |  Loss: (0.1686) |  Loss2: (0.0000) | Acc: (94.00%) (7342/7808)
Epoch: 125 | Batch_idx: 70 |  Loss: (0.1681) |  Loss2: (0.0000) | Acc: (94.00%) (8546/9088)
Epoch: 125 | Batch_idx: 80 |  Loss: (0.1681) |  Loss2: (0.0000) | Acc: (94.00%) (9755/10368)
Epoch: 125 | Batch_idx: 90 |  Loss: (0.1666) |  Loss2: (0.0000) | Acc: (94.00%) (10967/11648)
Epoch: 125 | Batch_idx: 100 |  Loss: (0.1638) |  Loss2: (0.0000) | Acc: (94.00%) (12187/12928)
Epoch: 125 | Batch_idx: 110 |  Loss: (0.1630) |  Loss2: (0.0000) | Acc: (94.00%) (13402/14208)
Epoch: 125 | Batch_idx: 120 |  Loss: (0.1618) |  Loss2: (0.0000) | Acc: (94.00%) (14625/15488)
Epoch: 125 | Batch_idx: 130 |  Loss: (0.1625) |  Loss2: (0.0000) | Acc: (94.00%) (15832/16768)
Epoch: 125 | Batch_idx: 140 |  Loss: (0.1654) |  Loss2: (0.0000) | Acc: (94.00%) (17016/18048)
Epoch: 125 | Batch_idx: 150 |  Loss: (0.1654) |  Loss2: (0.0000) | Acc: (94.00%) (18217/19328)
Epoch: 125 | Batch_idx: 160 |  Loss: (0.1651) |  Loss2: (0.0000) | Acc: (94.00%) (19429/20608)
Epoch: 125 | Batch_idx: 170 |  Loss: (0.1650) |  Loss2: (0.0000) | Acc: (94.00%) (20638/21888)
Epoch: 125 | Batch_idx: 180 |  Loss: (0.1649) |  Loss2: (0.0000) | Acc: (94.00%) (21844/23168)
Epoch: 125 | Batch_idx: 190 |  Loss: (0.1644) |  Loss2: (0.0000) | Acc: (94.00%) (23054/24448)
Epoch: 125 | Batch_idx: 200 |  Loss: (0.1648) |  Loss2: (0.0000) | Acc: (94.00%) (24259/25728)
Epoch: 125 | Batch_idx: 210 |  Loss: (0.1646) |  Loss2: (0.0000) | Acc: (94.00%) (25467/27008)
Epoch: 125 | Batch_idx: 220 |  Loss: (0.1650) |  Loss2: (0.0000) | Acc: (94.00%) (26667/28288)
Epoch: 125 | Batch_idx: 230 |  Loss: (0.1647) |  Loss2: (0.0000) | Acc: (94.00%) (27876/29568)
Epoch: 125 | Batch_idx: 240 |  Loss: (0.1658) |  Loss2: (0.0000) | Acc: (94.00%) (29069/30848)
Epoch: 125 | Batch_idx: 250 |  Loss: (0.1656) |  Loss2: (0.0000) | Acc: (94.00%) (30278/32128)
Epoch: 125 | Batch_idx: 260 |  Loss: (0.1655) |  Loss2: (0.0000) | Acc: (94.00%) (31487/33408)
Epoch: 125 | Batch_idx: 270 |  Loss: (0.1657) |  Loss2: (0.0000) | Acc: (94.00%) (32695/34688)
Epoch: 125 | Batch_idx: 280 |  Loss: (0.1654) |  Loss2: (0.0000) | Acc: (94.00%) (33907/35968)
Epoch: 125 | Batch_idx: 290 |  Loss: (0.1651) |  Loss2: (0.0000) | Acc: (94.00%) (35115/37248)
Epoch: 125 | Batch_idx: 300 |  Loss: (0.1649) |  Loss2: (0.0000) | Acc: (94.00%) (36319/38528)
Epoch: 125 | Batch_idx: 310 |  Loss: (0.1649) |  Loss2: (0.0000) | Acc: (94.00%) (37532/39808)
Epoch: 125 | Batch_idx: 320 |  Loss: (0.1645) |  Loss2: (0.0000) | Acc: (94.00%) (38749/41088)
Epoch: 125 | Batch_idx: 330 |  Loss: (0.1645) |  Loss2: (0.0000) | Acc: (94.00%) (39956/42368)
Epoch: 125 | Batch_idx: 340 |  Loss: (0.1649) |  Loss2: (0.0000) | Acc: (94.00%) (41156/43648)
Epoch: 125 | Batch_idx: 350 |  Loss: (0.1648) |  Loss2: (0.0000) | Acc: (94.00%) (42367/44928)
Epoch: 125 | Batch_idx: 360 |  Loss: (0.1645) |  Loss2: (0.0000) | Acc: (94.00%) (43585/46208)
Epoch: 125 | Batch_idx: 370 |  Loss: (0.1645) |  Loss2: (0.0000) | Acc: (94.00%) (44776/47488)
Epoch: 125 | Batch_idx: 380 |  Loss: (0.1639) |  Loss2: (0.0000) | Acc: (94.00%) (45992/48768)
Epoch: 125 | Batch_idx: 390 |  Loss: (0.1639) |  Loss2: (0.0000) | Acc: (94.00%) (47155/50000)
=> saving checkpoint 'drive/app/torch/save_Schedule/checkpoint_125.pth.tar'
# TEST : Loss: (0.3824) | Acc: (87.00%) (8784/10000)
percent tensor([0.5664, 0.5772, 0.5648, 0.5673, 0.5688, 0.5812, 0.5766, 0.5614, 0.5612,
        0.5697, 0.5715, 0.5704, 0.5680, 0.5605, 0.5836, 0.5713],
       device='cuda:0') torch.Size([16])
percent tensor([0.5292, 0.5303, 0.5208, 0.5266, 0.5236, 0.5371, 0.5271, 0.5229, 0.5239,
        0.5267, 0.5313, 0.5223, 0.5263, 0.5277, 0.5333, 0.5295],
       device='cuda:0') torch.Size([16])
percent tensor([0.5530, 0.4113, 0.6950, 0.6809, 0.7016, 0.6389, 0.5141, 0.6765, 0.6093,
        0.5053, 0.4494, 0.5925, 0.4477, 0.4813, 0.4895, 0.6018],
       device='cuda:0') torch.Size([16])
percent tensor([0.6900, 0.7437, 0.6032, 0.6370, 0.6114, 0.5286, 0.6947, 0.6218, 0.6981,
        0.7341, 0.7564, 0.6942, 0.7334, 0.7364, 0.6777, 0.6610],
       device='cuda:0') torch.Size([16])
percent tensor([0.7342, 0.6191, 0.7760, 0.7478, 0.7714, 0.8120, 0.7184, 0.7612, 0.7033,
        0.6294, 0.5954, 0.6553, 0.6016, 0.6516, 0.7117, 0.7589],
       device='cuda:0') torch.Size([16])
percent tensor([0.5336, 0.6663, 0.6650, 0.7251, 0.6888, 0.7706, 0.6697, 0.4854, 0.6711,
        0.6342, 0.6929, 0.6558, 0.6292, 0.7154, 0.5348, 0.5135],
       device='cuda:0') torch.Size([16])
percent tensor([0.5070, 0.6879, 0.5888, 0.6479, 0.5682, 0.6040, 0.6327, 0.5351, 0.6638,
        0.6667, 0.7148, 0.6605, 0.6461, 0.6985, 0.5671, 0.4563],
       device='cuda:0') torch.Size([16])
percent tensor([0.9997, 0.9997, 0.9996, 0.9998, 0.9999, 0.9988, 0.9997, 0.9996, 0.9995,
        0.9997, 0.9995, 0.9998, 0.9990, 0.9995, 0.9997, 0.9997],
       device='cuda:0') torch.Size([16])
True Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=128, out_features=16, bias=False)
False Linear(in_features=16, out_features=2, bias=False)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=128, out_features=16, bias=False)
False Linear(in_features=16, out_features=2, bias=False)
True Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=256, out_features=32, bias=False)
False Linear(in_features=32, out_features=2, bias=False)
True Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=256, out_features=32, bias=False)
False Linear(in_features=32, out_features=2, bias=False)
True Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=512, out_features=64, bias=False)
False Linear(in_features=64, out_features=2, bias=False)
True Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=512, out_features=64, bias=False)
False Linear(in_features=64, out_features=2, bias=False)
True Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1024, out_features=128, bias=False)
False Linear(in_features=128, out_features=2, bias=False)
True Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1024, out_features=128, bias=False)
False Linear(in_features=128, out_features=2, bias=False)
True Linear(in_features=512, out_features=10, bias=True)
Epoch: 126 | Batch_idx: 0 |  Loss: (0.1130) |  Loss2: (0.0000) | Acc: (96.00%) (123/128)
Epoch: 126 | Batch_idx: 10 |  Loss: (0.1604) |  Loss2: (0.0000) | Acc: (94.00%) (1333/1408)
Epoch: 126 | Batch_idx: 20 |  Loss: (0.1634) |  Loss2: (0.0000) | Acc: (94.00%) (2539/2688)
Epoch: 126 | Batch_idx: 30 |  Loss: (0.1592) |  Loss2: (0.0000) | Acc: (94.00%) (3751/3968)
Epoch: 126 | Batch_idx: 40 |  Loss: (0.1584) |  Loss2: (0.0000) | Acc: (94.00%) (4960/5248)
Epoch: 126 | Batch_idx: 50 |  Loss: (0.1566) |  Loss2: (0.0000) | Acc: (94.00%) (6169/6528)
Epoch: 126 | Batch_idx: 60 |  Loss: (0.1567) |  Loss2: (0.0000) | Acc: (94.00%) (7378/7808)
Epoch: 126 | Batch_idx: 70 |  Loss: (0.1596) |  Loss2: (0.0000) | Acc: (94.00%) (8577/9088)
Epoch: 126 | Batch_idx: 80 |  Loss: (0.1577) |  Loss2: (0.0000) | Acc: (94.00%) (9796/10368)
Epoch: 126 | Batch_idx: 90 |  Loss: (0.1590) |  Loss2: (0.0000) | Acc: (94.00%) (10997/11648)
Epoch: 126 | Batch_idx: 100 |  Loss: (0.1600) |  Loss2: (0.0000) | Acc: (94.00%) (12205/12928)
Epoch: 126 | Batch_idx: 110 |  Loss: (0.1596) |  Loss2: (0.0000) | Acc: (94.00%) (13418/14208)
Epoch: 126 | Batch_idx: 120 |  Loss: (0.1587) |  Loss2: (0.0000) | Acc: (94.00%) (14634/15488)
Epoch: 126 | Batch_idx: 130 |  Loss: (0.1582) |  Loss2: (0.0000) | Acc: (94.00%) (15848/16768)
Epoch: 126 | Batch_idx: 140 |  Loss: (0.1582) |  Loss2: (0.0000) | Acc: (94.00%) (17057/18048)
Epoch: 126 | Batch_idx: 150 |  Loss: (0.1580) |  Loss2: (0.0000) | Acc: (94.00%) (18278/19328)
Epoch: 126 | Batch_idx: 160 |  Loss: (0.1589) |  Loss2: (0.0000) | Acc: (94.00%) (19493/20608)
Epoch: 126 | Batch_idx: 170 |  Loss: (0.1608) |  Loss2: (0.0000) | Acc: (94.00%) (20683/21888)
Epoch: 126 | Batch_idx: 180 |  Loss: (0.1611) |  Loss2: (0.0000) | Acc: (94.00%) (21888/23168)
Epoch: 126 | Batch_idx: 190 |  Loss: (0.1613) |  Loss2: (0.0000) | Acc: (94.00%) (23096/24448)
Epoch: 126 | Batch_idx: 200 |  Loss: (0.1624) |  Loss2: (0.0000) | Acc: (94.00%) (24288/25728)
Epoch: 126 | Batch_idx: 210 |  Loss: (0.1625) |  Loss2: (0.0000) | Acc: (94.00%) (25492/27008)
Epoch: 126 | Batch_idx: 220 |  Loss: (0.1636) |  Loss2: (0.0000) | Acc: (94.00%) (26684/28288)
Epoch: 126 | Batch_idx: 230 |  Loss: (0.1630) |  Loss2: (0.0000) | Acc: (94.00%) (27901/29568)
Epoch: 126 | Batch_idx: 240 |  Loss: (0.1633) |  Loss2: (0.0000) | Acc: (94.00%) (29099/30848)
Epoch: 126 | Batch_idx: 250 |  Loss: (0.1630) |  Loss2: (0.0000) | Acc: (94.00%) (30303/32128)
Epoch: 126 | Batch_idx: 260 |  Loss: (0.1624) |  Loss2: (0.0000) | Acc: (94.00%) (31514/33408)
Epoch: 126 | Batch_idx: 270 |  Loss: (0.1620) |  Loss2: (0.0000) | Acc: (94.00%) (32723/34688)
Epoch: 126 | Batch_idx: 280 |  Loss: (0.1616) |  Loss2: (0.0000) | Acc: (94.00%) (33940/35968)
Epoch: 126 | Batch_idx: 290 |  Loss: (0.1619) |  Loss2: (0.0000) | Acc: (94.00%) (35142/37248)
Epoch: 126 | Batch_idx: 300 |  Loss: (0.1608) |  Loss2: (0.0000) | Acc: (94.00%) (36369/38528)
Epoch: 126 | Batch_idx: 310 |  Loss: (0.1605) |  Loss2: (0.0000) | Acc: (94.00%) (37577/39808)
Epoch: 126 | Batch_idx: 320 |  Loss: (0.1607) |  Loss2: (0.0000) | Acc: (94.00%) (38782/41088)
Epoch: 126 | Batch_idx: 330 |  Loss: (0.1606) |  Loss2: (0.0000) | Acc: (94.00%) (39976/42368)
Epoch: 126 | Batch_idx: 340 |  Loss: (0.1609) |  Loss2: (0.0000) | Acc: (94.00%) (41176/43648)
Epoch: 126 | Batch_idx: 350 |  Loss: (0.1612) |  Loss2: (0.0000) | Acc: (94.00%) (42384/44928)
Epoch: 126 | Batch_idx: 360 |  Loss: (0.1618) |  Loss2: (0.0000) | Acc: (94.00%) (43581/46208)
Epoch: 126 | Batch_idx: 370 |  Loss: (0.1617) |  Loss2: (0.0000) | Acc: (94.00%) (44791/47488)
Epoch: 126 | Batch_idx: 380 |  Loss: (0.1614) |  Loss2: (0.0000) | Acc: (94.00%) (46015/48768)
Epoch: 126 | Batch_idx: 390 |  Loss: (0.1617) |  Loss2: (0.0000) | Acc: (94.00%) (47175/50000)
# TEST : Loss: (0.4199) | Acc: (87.00%) (8721/10000)
percent tensor([0.5671, 0.5781, 0.5639, 0.5672, 0.5694, 0.5837, 0.5782, 0.5616, 0.5621,
        0.5706, 0.5731, 0.5700, 0.5687, 0.5623, 0.5848, 0.5724],
       device='cuda:0') torch.Size([16])
percent tensor([0.5301, 0.5306, 0.5222, 0.5270, 0.5241, 0.5364, 0.5272, 0.5231, 0.5241,
        0.5267, 0.5316, 0.5227, 0.5267, 0.5274, 0.5332, 0.5299],
       device='cuda:0') torch.Size([16])
percent tensor([0.5465, 0.4213, 0.7022, 0.6858, 0.7123, 0.6571, 0.5305, 0.6700, 0.5919,
        0.5073, 0.4417, 0.6178, 0.4431, 0.4994, 0.5022, 0.5977],
       device='cuda:0') torch.Size([16])
percent tensor([0.6903, 0.7371, 0.5814, 0.6232, 0.5978, 0.5232, 0.6893, 0.6173, 0.6973,
        0.7326, 0.7587, 0.6857, 0.7275, 0.7322, 0.6729, 0.6528],
       device='cuda:0') torch.Size([16])
percent tensor([0.7370, 0.6294, 0.7651, 0.7463, 0.7632, 0.8071, 0.7194, 0.7543, 0.6986,
        0.6320, 0.5962, 0.6604, 0.6086, 0.6564, 0.7169, 0.7611],
       device='cuda:0') torch.Size([16])
percent tensor([0.5318, 0.6549, 0.7070, 0.7539, 0.7363, 0.7457, 0.6622, 0.5397, 0.6761,
        0.6260, 0.6521, 0.6591, 0.6343, 0.6761, 0.5104, 0.4942],
       device='cuda:0') torch.Size([16])
percent tensor([0.4976, 0.6836, 0.6392, 0.6632, 0.6055, 0.6083, 0.6343, 0.5574, 0.6735,
        0.6568, 0.7024, 0.6634, 0.6234, 0.6843, 0.5551, 0.4480],
       device='cuda:0') torch.Size([16])
percent tensor([0.9997, 0.9997, 0.9996, 0.9999, 0.9999, 0.9988, 0.9998, 0.9998, 0.9996,
        0.9999, 0.9995, 0.9999, 0.9992, 0.9992, 0.9996, 0.9996],
       device='cuda:0') torch.Size([16])
Epoch: 127 | Batch_idx: 0 |  Loss: (0.1589) |  Loss2: (0.0000) | Acc: (94.00%) (121/128)
Epoch: 127 | Batch_idx: 10 |  Loss: (0.1416) |  Loss2: (0.0000) | Acc: (95.00%) (1343/1408)
Epoch: 127 | Batch_idx: 20 |  Loss: (0.1540) |  Loss2: (0.0000) | Acc: (94.00%) (2543/2688)
Epoch: 127 | Batch_idx: 30 |  Loss: (0.1480) |  Loss2: (0.0000) | Acc: (94.00%) (3761/3968)
Epoch: 127 | Batch_idx: 40 |  Loss: (0.1515) |  Loss2: (0.0000) | Acc: (94.00%) (4968/5248)
Epoch: 127 | Batch_idx: 50 |  Loss: (0.1479) |  Loss2: (0.0000) | Acc: (94.00%) (6194/6528)
Epoch: 127 | Batch_idx: 60 |  Loss: (0.1470) |  Loss2: (0.0000) | Acc: (94.00%) (7414/7808)
Epoch: 127 | Batch_idx: 70 |  Loss: (0.1487) |  Loss2: (0.0000) | Acc: (94.00%) (8617/9088)
Epoch: 127 | Batch_idx: 80 |  Loss: (0.1482) |  Loss2: (0.0000) | Acc: (94.00%) (9844/10368)
Epoch: 127 | Batch_idx: 90 |  Loss: (0.1488) |  Loss2: (0.0000) | Acc: (94.00%) (11059/11648)
Epoch: 127 | Batch_idx: 100 |  Loss: (0.1493) |  Loss2: (0.0000) | Acc: (94.00%) (12266/12928)
Epoch: 127 | Batch_idx: 110 |  Loss: (0.1491) |  Loss2: (0.0000) | Acc: (94.00%) (13480/14208)
Epoch: 127 | Batch_idx: 120 |  Loss: (0.1501) |  Loss2: (0.0000) | Acc: (94.00%) (14691/15488)
Epoch: 127 | Batch_idx: 130 |  Loss: (0.1500) |  Loss2: (0.0000) | Acc: (94.00%) (15904/16768)
Epoch: 127 | Batch_idx: 140 |  Loss: (0.1494) |  Loss2: (0.0000) | Acc: (94.00%) (17123/18048)
Epoch: 127 | Batch_idx: 150 |  Loss: (0.1493) |  Loss2: (0.0000) | Acc: (94.00%) (18335/19328)
Epoch: 127 | Batch_idx: 160 |  Loss: (0.1491) |  Loss2: (0.0000) | Acc: (94.00%) (19552/20608)
Epoch: 127 | Batch_idx: 170 |  Loss: (0.1490) |  Loss2: (0.0000) | Acc: (94.00%) (20767/21888)
Epoch: 127 | Batch_idx: 180 |  Loss: (0.1486) |  Loss2: (0.0000) | Acc: (94.00%) (21986/23168)
Epoch: 127 | Batch_idx: 190 |  Loss: (0.1495) |  Loss2: (0.0000) | Acc: (94.00%) (23186/24448)
Epoch: 127 | Batch_idx: 200 |  Loss: (0.1490) |  Loss2: (0.0000) | Acc: (94.00%) (24405/25728)
Epoch: 127 | Batch_idx: 210 |  Loss: (0.1493) |  Loss2: (0.0000) | Acc: (94.00%) (25609/27008)
Epoch: 127 | Batch_idx: 220 |  Loss: (0.1506) |  Loss2: (0.0000) | Acc: (94.00%) (26807/28288)
Epoch: 127 | Batch_idx: 230 |  Loss: (0.1504) |  Loss2: (0.0000) | Acc: (94.00%) (28024/29568)
Epoch: 127 | Batch_idx: 240 |  Loss: (0.1495) |  Loss2: (0.0000) | Acc: (94.00%) (29246/30848)
Epoch: 127 | Batch_idx: 250 |  Loss: (0.1498) |  Loss2: (0.0000) | Acc: (94.00%) (30460/32128)
Epoch: 127 | Batch_idx: 260 |  Loss: (0.1499) |  Loss2: (0.0000) | Acc: (94.00%) (31678/33408)
Epoch: 127 | Batch_idx: 270 |  Loss: (0.1508) |  Loss2: (0.0000) | Acc: (94.00%) (32887/34688)
Epoch: 127 | Batch_idx: 280 |  Loss: (0.1520) |  Loss2: (0.0000) | Acc: (94.00%) (34089/35968)
Epoch: 127 | Batch_idx: 290 |  Loss: (0.1524) |  Loss2: (0.0000) | Acc: (94.00%) (35300/37248)
Epoch: 127 | Batch_idx: 300 |  Loss: (0.1533) |  Loss2: (0.0000) | Acc: (94.00%) (36505/38528)
Epoch: 127 | Batch_idx: 310 |  Loss: (0.1530) |  Loss2: (0.0000) | Acc: (94.00%) (37720/39808)
Epoch: 127 | Batch_idx: 320 |  Loss: (0.1535) |  Loss2: (0.0000) | Acc: (94.00%) (38930/41088)
Epoch: 127 | Batch_idx: 330 |  Loss: (0.1534) |  Loss2: (0.0000) | Acc: (94.00%) (40144/42368)
Epoch: 127 | Batch_idx: 340 |  Loss: (0.1544) |  Loss2: (0.0000) | Acc: (94.00%) (41345/43648)
Epoch: 127 | Batch_idx: 350 |  Loss: (0.1542) |  Loss2: (0.0000) | Acc: (94.00%) (42563/44928)
Epoch: 127 | Batch_idx: 360 |  Loss: (0.1546) |  Loss2: (0.0000) | Acc: (94.00%) (43769/46208)
Epoch: 127 | Batch_idx: 370 |  Loss: (0.1549) |  Loss2: (0.0000) | Acc: (94.00%) (44978/47488)
Epoch: 127 | Batch_idx: 380 |  Loss: (0.1556) |  Loss2: (0.0000) | Acc: (94.00%) (46171/48768)
Epoch: 127 | Batch_idx: 390 |  Loss: (0.1566) |  Loss2: (0.0000) | Acc: (94.00%) (47318/50000)
# TEST : Loss: (0.4519) | Acc: (85.00%) (8585/10000)
percent tensor([0.5675, 0.5762, 0.5654, 0.5674, 0.5706, 0.5854, 0.5775, 0.5603, 0.5610,
        0.5697, 0.5725, 0.5712, 0.5682, 0.5595, 0.5849, 0.5720],
       device='cuda:0') torch.Size([16])
percent tensor([0.5299, 0.5299, 0.5219, 0.5265, 0.5243, 0.5358, 0.5270, 0.5237, 0.5244,
        0.5268, 0.5314, 0.5225, 0.5264, 0.5272, 0.5324, 0.5299],
       device='cuda:0') torch.Size([16])
percent tensor([0.5584, 0.4410, 0.6796, 0.6790, 0.6979, 0.6513, 0.5344, 0.6663, 0.6063,
        0.5081, 0.4648, 0.5872, 0.4518, 0.5256, 0.5104, 0.6077],
       device='cuda:0') torch.Size([16])
percent tensor([0.6904, 0.7360, 0.6033, 0.6339, 0.6032, 0.5319, 0.6877, 0.6236, 0.6982,
        0.7349, 0.7508, 0.6943, 0.7265, 0.7379, 0.6733, 0.6455],
       device='cuda:0') torch.Size([16])
percent tensor([0.7345, 0.6380, 0.7607, 0.7510, 0.7675, 0.8113, 0.7262, 0.7511, 0.6970,
        0.6336, 0.6035, 0.6551, 0.6137, 0.6465, 0.7226, 0.7700],
       device='cuda:0') torch.Size([16])
percent tensor([0.5467, 0.6834, 0.6828, 0.7465, 0.7205, 0.7577, 0.6774, 0.5186, 0.6886,
        0.6532, 0.7064, 0.6502, 0.6550, 0.7202, 0.5031, 0.5496],
       device='cuda:0') torch.Size([16])
percent tensor([0.5303, 0.6936, 0.6366, 0.6486, 0.5911, 0.6134, 0.6388, 0.5573, 0.6890,
        0.6669, 0.7261, 0.6498, 0.6515, 0.7024, 0.5429, 0.4512],
       device='cuda:0') torch.Size([16])
percent tensor([0.9997, 0.9997, 0.9998, 0.9999, 0.9999, 0.9989, 0.9997, 0.9998, 0.9997,
        0.9998, 0.9995, 0.9999, 0.9995, 0.9996, 0.9997, 0.9997],
       device='cuda:0') torch.Size([16])
Epoch: 128 | Batch_idx: 0 |  Loss: (0.1431) |  Loss2: (0.0000) | Acc: (95.00%) (122/128)
Epoch: 128 | Batch_idx: 10 |  Loss: (0.1604) |  Loss2: (0.0000) | Acc: (94.00%) (1330/1408)
Epoch: 128 | Batch_idx: 20 |  Loss: (0.1576) |  Loss2: (0.0000) | Acc: (94.00%) (2540/2688)
Epoch: 128 | Batch_idx: 30 |  Loss: (0.1623) |  Loss2: (0.0000) | Acc: (94.00%) (3747/3968)
Epoch: 128 | Batch_idx: 40 |  Loss: (0.1606) |  Loss2: (0.0000) | Acc: (94.00%) (4958/5248)
Epoch: 128 | Batch_idx: 50 |  Loss: (0.1585) |  Loss2: (0.0000) | Acc: (94.00%) (6170/6528)
Epoch: 128 | Batch_idx: 60 |  Loss: (0.1559) |  Loss2: (0.0000) | Acc: (94.00%) (7391/7808)
Epoch: 128 | Batch_idx: 70 |  Loss: (0.1537) |  Loss2: (0.0000) | Acc: (94.00%) (8613/9088)
Epoch: 128 | Batch_idx: 80 |  Loss: (0.1545) |  Loss2: (0.0000) | Acc: (94.00%) (9818/10368)
Epoch: 128 | Batch_idx: 90 |  Loss: (0.1572) |  Loss2: (0.0000) | Acc: (94.00%) (11012/11648)
Epoch: 128 | Batch_idx: 100 |  Loss: (0.1536) |  Loss2: (0.0000) | Acc: (94.00%) (12234/12928)
Epoch: 128 | Batch_idx: 110 |  Loss: (0.1546) |  Loss2: (0.0000) | Acc: (94.00%) (13448/14208)
Epoch: 128 | Batch_idx: 120 |  Loss: (0.1541) |  Loss2: (0.0000) | Acc: (94.00%) (14666/15488)
Epoch: 128 | Batch_idx: 130 |  Loss: (0.1530) |  Loss2: (0.0000) | Acc: (94.00%) (15889/16768)
Epoch: 128 | Batch_idx: 140 |  Loss: (0.1523) |  Loss2: (0.0000) | Acc: (94.00%) (17105/18048)
Epoch: 128 | Batch_idx: 150 |  Loss: (0.1518) |  Loss2: (0.0000) | Acc: (94.00%) (18325/19328)
Epoch: 128 | Batch_idx: 160 |  Loss: (0.1518) |  Loss2: (0.0000) | Acc: (94.00%) (19551/20608)
Epoch: 128 | Batch_idx: 170 |  Loss: (0.1521) |  Loss2: (0.0000) | Acc: (94.00%) (20756/21888)
Epoch: 128 | Batch_idx: 180 |  Loss: (0.1529) |  Loss2: (0.0000) | Acc: (94.00%) (21959/23168)
Epoch: 128 | Batch_idx: 190 |  Loss: (0.1526) |  Loss2: (0.0000) | Acc: (94.00%) (23175/24448)
Epoch: 128 | Batch_idx: 200 |  Loss: (0.1526) |  Loss2: (0.0000) | Acc: (94.00%) (24395/25728)
Epoch: 128 | Batch_idx: 210 |  Loss: (0.1526) |  Loss2: (0.0000) | Acc: (94.00%) (25606/27008)
Epoch: 128 | Batch_idx: 220 |  Loss: (0.1532) |  Loss2: (0.0000) | Acc: (94.00%) (26817/28288)
Epoch: 128 | Batch_idx: 230 |  Loss: (0.1539) |  Loss2: (0.0000) | Acc: (94.00%) (28028/29568)
Epoch: 128 | Batch_idx: 240 |  Loss: (0.1545) |  Loss2: (0.0000) | Acc: (94.00%) (29233/30848)
Epoch: 128 | Batch_idx: 250 |  Loss: (0.1543) |  Loss2: (0.0000) | Acc: (94.00%) (30442/32128)
Epoch: 128 | Batch_idx: 260 |  Loss: (0.1541) |  Loss2: (0.0000) | Acc: (94.00%) (31658/33408)
Epoch: 128 | Batch_idx: 270 |  Loss: (0.1532) |  Loss2: (0.0000) | Acc: (94.00%) (32887/34688)
Epoch: 128 | Batch_idx: 280 |  Loss: (0.1520) |  Loss2: (0.0000) | Acc: (94.00%) (34112/35968)
Epoch: 128 | Batch_idx: 290 |  Loss: (0.1521) |  Loss2: (0.0000) | Acc: (94.00%) (35317/37248)
Epoch: 128 | Batch_idx: 300 |  Loss: (0.1518) |  Loss2: (0.0000) | Acc: (94.00%) (36530/38528)
Epoch: 128 | Batch_idx: 310 |  Loss: (0.1514) |  Loss2: (0.0000) | Acc: (94.00%) (37756/39808)
Epoch: 128 | Batch_idx: 320 |  Loss: (0.1515) |  Loss2: (0.0000) | Acc: (94.00%) (38969/41088)
Epoch: 128 | Batch_idx: 330 |  Loss: (0.1512) |  Loss2: (0.0000) | Acc: (94.00%) (40187/42368)
Epoch: 128 | Batch_idx: 340 |  Loss: (0.1515) |  Loss2: (0.0000) | Acc: (94.00%) (41401/43648)
Epoch: 128 | Batch_idx: 350 |  Loss: (0.1520) |  Loss2: (0.0000) | Acc: (94.00%) (42599/44928)
Epoch: 128 | Batch_idx: 360 |  Loss: (0.1524) |  Loss2: (0.0000) | Acc: (94.00%) (43806/46208)
Epoch: 128 | Batch_idx: 370 |  Loss: (0.1529) |  Loss2: (0.0000) | Acc: (94.00%) (45016/47488)
Epoch: 128 | Batch_idx: 380 |  Loss: (0.1533) |  Loss2: (0.0000) | Acc: (94.00%) (46216/48768)
Epoch: 128 | Batch_idx: 390 |  Loss: (0.1530) |  Loss2: (0.0000) | Acc: (94.00%) (47388/50000)
# TEST : Loss: (0.4328) | Acc: (87.00%) (8706/10000)
percent tensor([0.5677, 0.5781, 0.5666, 0.5680, 0.5721, 0.5853, 0.5792, 0.5618, 0.5626,
        0.5706, 0.5723, 0.5728, 0.5684, 0.5623, 0.5852, 0.5723],
       device='cuda:0') torch.Size([16])
percent tensor([0.5299, 0.5302, 0.5237, 0.5274, 0.5254, 0.5364, 0.5273, 0.5246, 0.5242,
        0.5266, 0.5311, 0.5230, 0.5264, 0.5271, 0.5330, 0.5300],
       device='cuda:0') torch.Size([16])
percent tensor([0.5624, 0.4349, 0.6791, 0.6832, 0.6995, 0.6467, 0.5330, 0.6601, 0.5983,
        0.5131, 0.4592, 0.5932, 0.4640, 0.5224, 0.5083, 0.6127],
       device='cuda:0') torch.Size([16])
percent tensor([0.6916, 0.7364, 0.6036, 0.6330, 0.6087, 0.5318, 0.6910, 0.6181, 0.6971,
        0.7412, 0.7572, 0.7003, 0.7236, 0.7360, 0.6758, 0.6560],
       device='cuda:0') torch.Size([16])
percent tensor([0.7400, 0.6438, 0.7660, 0.7385, 0.7724, 0.8131, 0.7274, 0.7554, 0.7109,
        0.6270, 0.6041, 0.6538, 0.6270, 0.6411, 0.7227, 0.7707],
       device='cuda:0') torch.Size([16])
percent tensor([0.5266, 0.6725, 0.6815, 0.7402, 0.7190, 0.7792, 0.6411, 0.5183, 0.6657,
        0.6191, 0.6591, 0.6438, 0.6342, 0.7002, 0.5006, 0.4990],
       device='cuda:0') torch.Size([16])
percent tensor([0.4909, 0.6804, 0.6129, 0.6540, 0.5990, 0.6213, 0.6090, 0.5497, 0.6596,
        0.6291, 0.6906, 0.6393, 0.6152, 0.6832, 0.5394, 0.4419],
       device='cuda:0') torch.Size([16])
percent tensor([0.9997, 0.9997, 0.9999, 0.9999, 0.9999, 0.9991, 0.9998, 0.9998, 0.9994,
        0.9998, 0.9994, 0.9999, 0.9991, 0.9993, 0.9998, 0.9998],
       device='cuda:0') torch.Size([16])
False Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=128, out_features=16, bias=False)
True Linear(in_features=16, out_features=2, bias=False)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=128, out_features=16, bias=False)
True Linear(in_features=16, out_features=2, bias=False)
False Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=256, out_features=32, bias=False)
True Linear(in_features=32, out_features=2, bias=False)
False Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=256, out_features=32, bias=False)
True Linear(in_features=32, out_features=2, bias=False)
False Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=512, out_features=64, bias=False)
True Linear(in_features=64, out_features=2, bias=False)
False Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=512, out_features=64, bias=False)
True Linear(in_features=64, out_features=2, bias=False)
False Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1024, out_features=128, bias=False)
True Linear(in_features=128, out_features=2, bias=False)
False Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1024, out_features=128, bias=False)
True Linear(in_features=128, out_features=2, bias=False)
False Linear(in_features=512, out_features=10, bias=True)
Epoch: 129 | Batch_idx: 0 |  Loss: (0.0792) |  Loss2: (0.0000) | Acc: (99.00%) (127/128)
Epoch: 129 | Batch_idx: 10 |  Loss: (0.1798) |  Loss2: (0.0000) | Acc: (94.00%) (1326/1408)
Epoch: 129 | Batch_idx: 20 |  Loss: (0.1894) |  Loss2: (0.0000) | Acc: (93.00%) (2516/2688)
Epoch: 129 | Batch_idx: 30 |  Loss: (0.1893) |  Loss2: (0.0000) | Acc: (93.00%) (3716/3968)
Epoch: 129 | Batch_idx: 40 |  Loss: (0.1947) |  Loss2: (0.0000) | Acc: (93.00%) (4899/5248)
Epoch: 129 | Batch_idx: 50 |  Loss: (0.2016) |  Loss2: (0.0000) | Acc: (92.00%) (6071/6528)
Epoch: 129 | Batch_idx: 60 |  Loss: (0.1981) |  Loss2: (0.0000) | Acc: (93.00%) (7267/7808)
Epoch: 129 | Batch_idx: 70 |  Loss: (0.2038) |  Loss2: (0.0000) | Acc: (92.00%) (8442/9088)
Epoch: 129 | Batch_idx: 80 |  Loss: (0.2020) |  Loss2: (0.0000) | Acc: (92.00%) (9640/10368)
Epoch: 129 | Batch_idx: 90 |  Loss: (0.2013) |  Loss2: (0.0000) | Acc: (93.00%) (10837/11648)
Epoch: 129 | Batch_idx: 100 |  Loss: (0.1985) |  Loss2: (0.0000) | Acc: (93.00%) (12039/12928)
Epoch: 129 | Batch_idx: 110 |  Loss: (0.1984) |  Loss2: (0.0000) | Acc: (93.00%) (13234/14208)
Epoch: 129 | Batch_idx: 120 |  Loss: (0.1995) |  Loss2: (0.0000) | Acc: (93.00%) (14418/15488)
Epoch: 129 | Batch_idx: 130 |  Loss: (0.1990) |  Loss2: (0.0000) | Acc: (93.00%) (15618/16768)
Epoch: 129 | Batch_idx: 140 |  Loss: (0.1997) |  Loss2: (0.0000) | Acc: (93.00%) (16802/18048)
Epoch: 129 | Batch_idx: 150 |  Loss: (0.1989) |  Loss2: (0.0000) | Acc: (93.00%) (17991/19328)
Epoch: 129 | Batch_idx: 160 |  Loss: (0.1980) |  Loss2: (0.0000) | Acc: (93.00%) (19182/20608)
Epoch: 129 | Batch_idx: 170 |  Loss: (0.1966) |  Loss2: (0.0000) | Acc: (93.00%) (20383/21888)
Epoch: 129 | Batch_idx: 180 |  Loss: (0.1950) |  Loss2: (0.0000) | Acc: (93.00%) (21586/23168)
Epoch: 129 | Batch_idx: 190 |  Loss: (0.1942) |  Loss2: (0.0000) | Acc: (93.00%) (22783/24448)
Epoch: 129 | Batch_idx: 200 |  Loss: (0.1925) |  Loss2: (0.0000) | Acc: (93.00%) (23997/25728)
Epoch: 129 | Batch_idx: 210 |  Loss: (0.1922) |  Loss2: (0.0000) | Acc: (93.00%) (25194/27008)
Epoch: 129 | Batch_idx: 220 |  Loss: (0.1933) |  Loss2: (0.0000) | Acc: (93.00%) (26369/28288)
Epoch: 129 | Batch_idx: 230 |  Loss: (0.1915) |  Loss2: (0.0000) | Acc: (93.00%) (27582/29568)
Epoch: 129 | Batch_idx: 240 |  Loss: (0.1908) |  Loss2: (0.0000) | Acc: (93.00%) (28785/30848)
Epoch: 129 | Batch_idx: 250 |  Loss: (0.1904) |  Loss2: (0.0000) | Acc: (93.00%) (29986/32128)
Epoch: 129 | Batch_idx: 260 |  Loss: (0.1904) |  Loss2: (0.0000) | Acc: (93.00%) (31178/33408)
Epoch: 129 | Batch_idx: 270 |  Loss: (0.1914) |  Loss2: (0.0000) | Acc: (93.00%) (32350/34688)
Epoch: 129 | Batch_idx: 280 |  Loss: (0.1905) |  Loss2: (0.0000) | Acc: (93.00%) (33567/35968)
Epoch: 129 | Batch_idx: 290 |  Loss: (0.1887) |  Loss2: (0.0000) | Acc: (93.00%) (34785/37248)
Epoch: 129 | Batch_idx: 300 |  Loss: (0.1882) |  Loss2: (0.0000) | Acc: (93.00%) (35988/38528)
Epoch: 129 | Batch_idx: 310 |  Loss: (0.1883) |  Loss2: (0.0000) | Acc: (93.00%) (37169/39808)
Epoch: 129 | Batch_idx: 320 |  Loss: (0.1877) |  Loss2: (0.0000) | Acc: (93.00%) (38378/41088)
Epoch: 129 | Batch_idx: 330 |  Loss: (0.1879) |  Loss2: (0.0000) | Acc: (93.00%) (39566/42368)
Epoch: 129 | Batch_idx: 340 |  Loss: (0.1874) |  Loss2: (0.0000) | Acc: (93.00%) (40771/43648)
Epoch: 129 | Batch_idx: 350 |  Loss: (0.1867) |  Loss2: (0.0000) | Acc: (93.00%) (41966/44928)
Epoch: 129 | Batch_idx: 360 |  Loss: (0.1864) |  Loss2: (0.0000) | Acc: (93.00%) (43168/46208)
Epoch: 129 | Batch_idx: 370 |  Loss: (0.1857) |  Loss2: (0.0000) | Acc: (93.00%) (44374/47488)
Epoch: 129 | Batch_idx: 380 |  Loss: (0.1860) |  Loss2: (0.0000) | Acc: (93.00%) (45565/48768)
Epoch: 129 | Batch_idx: 390 |  Loss: (0.1859) |  Loss2: (0.0000) | Acc: (93.00%) (46717/50000)
# TEST : Loss: (0.3941) | Acc: (87.00%) (8781/10000)
percent tensor([0.5647, 0.5738, 0.5647, 0.5661, 0.5695, 0.5837, 0.5751, 0.5585, 0.5592,
        0.5668, 0.5685, 0.5696, 0.5642, 0.5595, 0.5817, 0.5697],
       device='cuda:0') torch.Size([16])
percent tensor([0.5298, 0.5308, 0.5243, 0.5278, 0.5252, 0.5360, 0.5276, 0.5255, 0.5243,
        0.5269, 0.5312, 0.5235, 0.5263, 0.5284, 0.5330, 0.5302],
       device='cuda:0') torch.Size([16])
percent tensor([0.5504, 0.4451, 0.6707, 0.6639, 0.6871, 0.6284, 0.5316, 0.6494, 0.5841,
        0.5107, 0.4541, 0.5880, 0.4668, 0.5142, 0.5072, 0.5989],
       device='cuda:0') torch.Size([16])
percent tensor([0.6949, 0.7379, 0.6168, 0.6471, 0.6268, 0.5441, 0.6992, 0.6314, 0.7002,
        0.7403, 0.7581, 0.7052, 0.7196, 0.7375, 0.6846, 0.6598],
       device='cuda:0') torch.Size([16])
percent tensor([0.7310, 0.6398, 0.7511, 0.7369, 0.7587, 0.8093, 0.7155, 0.7406, 0.7093,
        0.6221, 0.6026, 0.6357, 0.6145, 0.6557, 0.7088, 0.7646],
       device='cuda:0') torch.Size([16])
percent tensor([0.5954, 0.7159, 0.7200, 0.7622, 0.7422, 0.8081, 0.6910, 0.5841, 0.7192,
        0.6774, 0.7076, 0.6918, 0.6873, 0.7559, 0.5554, 0.5556],
       device='cuda:0') torch.Size([16])
percent tensor([0.4853, 0.6592, 0.5912, 0.6265, 0.5859, 0.5766, 0.6107, 0.5552, 0.6545,
        0.6266, 0.6813, 0.6326, 0.5950, 0.6582, 0.5547, 0.4362],
       device='cuda:0') torch.Size([16])
percent tensor([0.9998, 0.9997, 0.9998, 0.9998, 0.9999, 0.9987, 0.9998, 0.9997, 0.9996,
        0.9998, 0.9995, 0.9999, 0.9994, 0.9994, 0.9997, 0.9997],
       device='cuda:0') torch.Size([16])
Epoch: 130 | Batch_idx: 0 |  Loss: (0.2891) |  Loss2: (0.0000) | Acc: (86.00%) (111/128)
Epoch: 130 | Batch_idx: 10 |  Loss: (0.1773) |  Loss2: (0.0000) | Acc: (92.00%) (1307/1408)
Epoch: 130 | Batch_idx: 20 |  Loss: (0.1856) |  Loss2: (0.0000) | Acc: (93.00%) (2504/2688)
Epoch: 130 | Batch_idx: 30 |  Loss: (0.1778) |  Loss2: (0.0000) | Acc: (93.00%) (3712/3968)
Epoch: 130 | Batch_idx: 40 |  Loss: (0.1832) |  Loss2: (0.0000) | Acc: (93.00%) (4904/5248)
Epoch: 130 | Batch_idx: 50 |  Loss: (0.1810) |  Loss2: (0.0000) | Acc: (93.00%) (6110/6528)
Epoch: 130 | Batch_idx: 60 |  Loss: (0.1764) |  Loss2: (0.0000) | Acc: (93.00%) (7316/7808)
Epoch: 130 | Batch_idx: 70 |  Loss: (0.1754) |  Loss2: (0.0000) | Acc: (93.00%) (8526/9088)
Epoch: 130 | Batch_idx: 80 |  Loss: (0.1737) |  Loss2: (0.0000) | Acc: (93.00%) (9733/10368)
Epoch: 130 | Batch_idx: 90 |  Loss: (0.1685) |  Loss2: (0.0000) | Acc: (94.00%) (10959/11648)
Epoch: 130 | Batch_idx: 100 |  Loss: (0.1680) |  Loss2: (0.0000) | Acc: (94.00%) (12174/12928)
Epoch: 130 | Batch_idx: 110 |  Loss: (0.1681) |  Loss2: (0.0000) | Acc: (94.00%) (13378/14208)
Epoch: 130 | Batch_idx: 120 |  Loss: (0.1681) |  Loss2: (0.0000) | Acc: (94.00%) (14582/15488)
Epoch: 130 | Batch_idx: 130 |  Loss: (0.1683) |  Loss2: (0.0000) | Acc: (94.00%) (15780/16768)
Epoch: 130 | Batch_idx: 140 |  Loss: (0.1686) |  Loss2: (0.0000) | Acc: (94.00%) (16985/18048)
Epoch: 130 | Batch_idx: 150 |  Loss: (0.1672) |  Loss2: (0.0000) | Acc: (94.00%) (18210/19328)
Epoch: 130 | Batch_idx: 160 |  Loss: (0.1670) |  Loss2: (0.0000) | Acc: (94.00%) (19416/20608)
Epoch: 130 | Batch_idx: 170 |  Loss: (0.1670) |  Loss2: (0.0000) | Acc: (94.00%) (20618/21888)
Epoch: 130 | Batch_idx: 180 |  Loss: (0.1670) |  Loss2: (0.0000) | Acc: (94.00%) (21818/23168)
Epoch: 130 | Batch_idx: 190 |  Loss: (0.1664) |  Loss2: (0.0000) | Acc: (94.00%) (23033/24448)
Epoch: 130 | Batch_idx: 200 |  Loss: (0.1673) |  Loss2: (0.0000) | Acc: (94.00%) (24229/25728)
Epoch: 130 | Batch_idx: 210 |  Loss: (0.1669) |  Loss2: (0.0000) | Acc: (94.00%) (25436/27008)
Epoch: 130 | Batch_idx: 220 |  Loss: (0.1660) |  Loss2: (0.0000) | Acc: (94.00%) (26643/28288)
Epoch: 130 | Batch_idx: 230 |  Loss: (0.1653) |  Loss2: (0.0000) | Acc: (94.00%) (27849/29568)
Epoch: 130 | Batch_idx: 240 |  Loss: (0.1653) |  Loss2: (0.0000) | Acc: (94.00%) (29052/30848)
Epoch: 130 | Batch_idx: 250 |  Loss: (0.1646) |  Loss2: (0.0000) | Acc: (94.00%) (30269/32128)
Epoch: 130 | Batch_idx: 260 |  Loss: (0.1637) |  Loss2: (0.0000) | Acc: (94.00%) (31487/33408)
Epoch: 130 | Batch_idx: 270 |  Loss: (0.1630) |  Loss2: (0.0000) | Acc: (94.00%) (32702/34688)
Epoch: 130 | Batch_idx: 280 |  Loss: (0.1636) |  Loss2: (0.0000) | Acc: (94.00%) (33893/35968)
Epoch: 130 | Batch_idx: 290 |  Loss: (0.1630) |  Loss2: (0.0000) | Acc: (94.00%) (35107/37248)
Epoch: 130 | Batch_idx: 300 |  Loss: (0.1626) |  Loss2: (0.0000) | Acc: (94.00%) (36316/38528)
Epoch: 130 | Batch_idx: 310 |  Loss: (0.1623) |  Loss2: (0.0000) | Acc: (94.00%) (37532/39808)
Epoch: 130 | Batch_idx: 320 |  Loss: (0.1622) |  Loss2: (0.0000) | Acc: (94.00%) (38744/41088)
Epoch: 130 | Batch_idx: 330 |  Loss: (0.1625) |  Loss2: (0.0000) | Acc: (94.00%) (39947/42368)
Epoch: 130 | Batch_idx: 340 |  Loss: (0.1622) |  Loss2: (0.0000) | Acc: (94.00%) (41166/43648)
Epoch: 130 | Batch_idx: 350 |  Loss: (0.1625) |  Loss2: (0.0000) | Acc: (94.00%) (42368/44928)
Epoch: 130 | Batch_idx: 360 |  Loss: (0.1619) |  Loss2: (0.0000) | Acc: (94.00%) (43592/46208)
Epoch: 130 | Batch_idx: 370 |  Loss: (0.1621) |  Loss2: (0.0000) | Acc: (94.00%) (44793/47488)
Epoch: 130 | Batch_idx: 380 |  Loss: (0.1620) |  Loss2: (0.0000) | Acc: (94.00%) (46008/48768)
Epoch: 130 | Batch_idx: 390 |  Loss: (0.1621) |  Loss2: (0.0000) | Acc: (94.00%) (47177/50000)
=> saving checkpoint 'drive/app/torch/save_Schedule/checkpoint_130.pth.tar'
# TEST : Loss: (0.3810) | Acc: (88.00%) (8835/10000)
percent tensor([0.5616, 0.5699, 0.5615, 0.5637, 0.5661, 0.5813, 0.5712, 0.5551, 0.5559,
        0.5630, 0.5650, 0.5657, 0.5605, 0.5572, 0.5781, 0.5667],
       device='cuda:0') torch.Size([16])
percent tensor([0.5300, 0.5304, 0.5251, 0.5283, 0.5259, 0.5364, 0.5275, 0.5260, 0.5246,
        0.5268, 0.5309, 0.5238, 0.5262, 0.5284, 0.5329, 0.5304],
       device='cuda:0') torch.Size([16])
percent tensor([0.5532, 0.4506, 0.6749, 0.6664, 0.6914, 0.6347, 0.5365, 0.6519, 0.5841,
        0.5132, 0.4554, 0.5898, 0.4685, 0.5186, 0.5127, 0.6002],
       device='cuda:0') torch.Size([16])
percent tensor([0.6899, 0.7336, 0.6146, 0.6417, 0.6251, 0.5367, 0.6967, 0.6327, 0.6970,
        0.7352, 0.7519, 0.7016, 0.7141, 0.7347, 0.6791, 0.6536],
       device='cuda:0') torch.Size([16])
percent tensor([0.7279, 0.6374, 0.7480, 0.7395, 0.7580, 0.8109, 0.7112, 0.7362, 0.7098,
        0.6207, 0.6086, 0.6350, 0.6140, 0.6568, 0.7072, 0.7630],
       device='cuda:0') torch.Size([16])
percent tensor([0.5798, 0.7041, 0.7053, 0.7553, 0.7242, 0.8028, 0.6713, 0.5540, 0.7110,
        0.6656, 0.7022, 0.6859, 0.6839, 0.7466, 0.5342, 0.5299],
       device='cuda:0') torch.Size([16])
percent tensor([0.4799, 0.6640, 0.5938, 0.6274, 0.5884, 0.5652, 0.6074, 0.5530, 0.6648,
        0.6308, 0.6900, 0.6452, 0.5957, 0.6659, 0.5604, 0.4282],
       device='cuda:0') torch.Size([16])
percent tensor([0.9998, 0.9997, 0.9998, 0.9998, 0.9999, 0.9988, 0.9998, 0.9997, 0.9996,
        0.9999, 0.9995, 0.9999, 0.9995, 0.9995, 0.9997, 0.9997],
       device='cuda:0') torch.Size([16])
Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 3, 3, 3]) tensor(183.1958, device='cuda:0')
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(814.9545, device='cuda:0')
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(822.3313, device='cuda:0')
Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([128, 64, 3, 3]) tensor(1516.2238, device='cuda:0')
Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([128, 64, 1, 1]) tensor(494.5177, device='cuda:0')
Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([128, 128, 3, 3]) tensor(2253.9241, device='cuda:0')
Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([256, 128, 3, 3]) tensor(4283.3887, device='cuda:0')
Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([256, 128, 1, 1]) tensor(1387.6060, device='cuda:0')
Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([256, 256, 3, 3]) tensor(6185.1519, device='cuda:0')
Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([512, 256, 3, 3]) tensor(11773.7227, device='cuda:0')
Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([512, 256, 1, 1]) tensor(3897.6174, device='cuda:0')
Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([512, 512, 3, 3]) tensor(16431.9648, device='cuda:0')
Epoch: 131 | Batch_idx: 0 |  Loss: (0.1167) |  Loss2: (0.0000) | Acc: (96.00%) (124/128)
Epoch: 131 | Batch_idx: 10 |  Loss: (0.1389) |  Loss2: (0.0000) | Acc: (94.00%) (1332/1408)
Epoch: 131 | Batch_idx: 20 |  Loss: (0.1535) |  Loss2: (0.0000) | Acc: (94.00%) (2536/2688)
Epoch: 131 | Batch_idx: 30 |  Loss: (0.1622) |  Loss2: (0.0000) | Acc: (94.00%) (3735/3968)
Epoch: 131 | Batch_idx: 40 |  Loss: (0.1649) |  Loss2: (0.0000) | Acc: (93.00%) (4930/5248)
Epoch: 131 | Batch_idx: 50 |  Loss: (0.1630) |  Loss2: (0.0000) | Acc: (94.00%) (6146/6528)
Epoch: 131 | Batch_idx: 60 |  Loss: (0.1625) |  Loss2: (0.0000) | Acc: (94.00%) (7349/7808)
Epoch: 131 | Batch_idx: 70 |  Loss: (0.1611) |  Loss2: (0.0000) | Acc: (94.00%) (8556/9088)
Epoch: 131 | Batch_idx: 80 |  Loss: (0.1568) |  Loss2: (0.0000) | Acc: (94.00%) (9783/10368)
Epoch: 131 | Batch_idx: 90 |  Loss: (0.1577) |  Loss2: (0.0000) | Acc: (94.00%) (10984/11648)
Epoch: 131 | Batch_idx: 100 |  Loss: (0.1567) |  Loss2: (0.0000) | Acc: (94.00%) (12201/12928)
Epoch: 131 | Batch_idx: 110 |  Loss: (0.1565) |  Loss2: (0.0000) | Acc: (94.00%) (13414/14208)
Epoch: 131 | Batch_idx: 120 |  Loss: (0.1549) |  Loss2: (0.0000) | Acc: (94.00%) (14627/15488)
Epoch: 131 | Batch_idx: 130 |  Loss: (0.1525) |  Loss2: (0.0000) | Acc: (94.00%) (15862/16768)
Epoch: 131 | Batch_idx: 140 |  Loss: (0.1520) |  Loss2: (0.0000) | Acc: (94.00%) (17081/18048)
Epoch: 131 | Batch_idx: 150 |  Loss: (0.1512) |  Loss2: (0.0000) | Acc: (94.00%) (18297/19328)
Epoch: 131 | Batch_idx: 160 |  Loss: (0.1531) |  Loss2: (0.0000) | Acc: (94.00%) (19502/20608)
Epoch: 131 | Batch_idx: 170 |  Loss: (0.1523) |  Loss2: (0.0000) | Acc: (94.00%) (20714/21888)
Epoch: 131 | Batch_idx: 180 |  Loss: (0.1530) |  Loss2: (0.0000) | Acc: (94.00%) (21916/23168)
Epoch: 131 | Batch_idx: 190 |  Loss: (0.1523) |  Loss2: (0.0000) | Acc: (94.00%) (23132/24448)
Epoch: 131 | Batch_idx: 200 |  Loss: (0.1534) |  Loss2: (0.0000) | Acc: (94.00%) (24334/25728)
Epoch: 131 | Batch_idx: 210 |  Loss: (0.1535) |  Loss2: (0.0000) | Acc: (94.00%) (25534/27008)
Epoch: 131 | Batch_idx: 220 |  Loss: (0.1547) |  Loss2: (0.0000) | Acc: (94.00%) (26741/28288)
Epoch: 131 | Batch_idx: 230 |  Loss: (0.1545) |  Loss2: (0.0000) | Acc: (94.00%) (27957/29568)
Epoch: 131 | Batch_idx: 240 |  Loss: (0.1544) |  Loss2: (0.0000) | Acc: (94.00%) (29174/30848)
Epoch: 131 | Batch_idx: 250 |  Loss: (0.1541) |  Loss2: (0.0000) | Acc: (94.00%) (30396/32128)
Epoch: 131 | Batch_idx: 260 |  Loss: (0.1534) |  Loss2: (0.0000) | Acc: (94.00%) (31614/33408)
Epoch: 131 | Batch_idx: 270 |  Loss: (0.1536) |  Loss2: (0.0000) | Acc: (94.00%) (32822/34688)
Epoch: 131 | Batch_idx: 280 |  Loss: (0.1528) |  Loss2: (0.0000) | Acc: (94.00%) (34045/35968)
Epoch: 131 | Batch_idx: 290 |  Loss: (0.1517) |  Loss2: (0.0000) | Acc: (94.00%) (35277/37248)
Epoch: 131 | Batch_idx: 300 |  Loss: (0.1517) |  Loss2: (0.0000) | Acc: (94.00%) (36484/38528)
Epoch: 131 | Batch_idx: 310 |  Loss: (0.1520) |  Loss2: (0.0000) | Acc: (94.00%) (37693/39808)
Epoch: 131 | Batch_idx: 320 |  Loss: (0.1516) |  Loss2: (0.0000) | Acc: (94.00%) (38903/41088)
Epoch: 131 | Batch_idx: 330 |  Loss: (0.1517) |  Loss2: (0.0000) | Acc: (94.00%) (40104/42368)
Epoch: 131 | Batch_idx: 340 |  Loss: (0.1516) |  Loss2: (0.0000) | Acc: (94.00%) (41320/43648)
Epoch: 131 | Batch_idx: 350 |  Loss: (0.1514) |  Loss2: (0.0000) | Acc: (94.00%) (42539/44928)
Epoch: 131 | Batch_idx: 360 |  Loss: (0.1515) |  Loss2: (0.0000) | Acc: (94.00%) (43748/46208)
Epoch: 131 | Batch_idx: 370 |  Loss: (0.1518) |  Loss2: (0.0000) | Acc: (94.00%) (44965/47488)
Epoch: 131 | Batch_idx: 380 |  Loss: (0.1520) |  Loss2: (0.0000) | Acc: (94.00%) (46189/48768)
Epoch: 131 | Batch_idx: 390 |  Loss: (0.1521) |  Loss2: (0.0000) | Acc: (94.00%) (47355/50000)
# TEST : Loss: (0.3754) | Acc: (88.00%) (8838/10000)
percent tensor([0.5588, 0.5663, 0.5584, 0.5612, 0.5630, 0.5790, 0.5677, 0.5518, 0.5527,
        0.5594, 0.5617, 0.5622, 0.5572, 0.5548, 0.5750, 0.5639],
       device='cuda:0') torch.Size([16])
percent tensor([0.5321, 0.5323, 0.5274, 0.5306, 0.5282, 0.5387, 0.5295, 0.5284, 0.5267,
        0.5288, 0.5329, 0.5259, 0.5281, 0.5305, 0.5350, 0.5326],
       device='cuda:0') torch.Size([16])
percent tensor([0.5418, 0.4383, 0.6726, 0.6635, 0.6896, 0.6296, 0.5258, 0.6480, 0.5746,
        0.5008, 0.4406, 0.5801, 0.4539, 0.5097, 0.5012, 0.5886],
       device='cuda:0') torch.Size([16])
percent tensor([0.6863, 0.7308, 0.6113, 0.6386, 0.6240, 0.5312, 0.6949, 0.6335, 0.6943,
        0.7304, 0.7477, 0.6969, 0.7087, 0.7320, 0.6748, 0.6495],
       device='cuda:0') torch.Size([16])
percent tensor([0.7240, 0.6308, 0.7436, 0.7348, 0.7547, 0.8086, 0.7059, 0.7307, 0.7041,
        0.6170, 0.6050, 0.6294, 0.6086, 0.6513, 0.7035, 0.7566],
       device='cuda:0') torch.Size([16])
percent tensor([0.5878, 0.7144, 0.7076, 0.7602, 0.7216, 0.8071, 0.6742, 0.5463, 0.7175,
        0.6777, 0.7140, 0.6986, 0.7019, 0.7517, 0.5393, 0.5319],
       device='cuda:0') torch.Size([16])
percent tensor([0.4860, 0.6725, 0.6073, 0.6370, 0.5999, 0.5706, 0.6178, 0.5610, 0.6795,
        0.6429, 0.6979, 0.6595, 0.6060, 0.6752, 0.5710, 0.4307],
       device='cuda:0') torch.Size([16])
percent tensor([0.9998, 0.9997, 0.9998, 0.9998, 0.9999, 0.9989, 0.9998, 0.9997, 0.9996,
        0.9999, 0.9995, 0.9999, 0.9995, 0.9995, 0.9997, 0.9997],
       device='cuda:0') torch.Size([16])
True Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=128, out_features=16, bias=False)
False Linear(in_features=16, out_features=2, bias=False)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=128, out_features=16, bias=False)
False Linear(in_features=16, out_features=2, bias=False)
True Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=256, out_features=32, bias=False)
False Linear(in_features=32, out_features=2, bias=False)
True Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=256, out_features=32, bias=False)
False Linear(in_features=32, out_features=2, bias=False)
True Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=512, out_features=64, bias=False)
False Linear(in_features=64, out_features=2, bias=False)
True Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=512, out_features=64, bias=False)
False Linear(in_features=64, out_features=2, bias=False)
True Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1024, out_features=128, bias=False)
False Linear(in_features=128, out_features=2, bias=False)
True Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1024, out_features=128, bias=False)
False Linear(in_features=128, out_features=2, bias=False)
True Linear(in_features=512, out_features=10, bias=True)
Epoch: 132 | Batch_idx: 0 |  Loss: (0.1296) |  Loss2: (0.0000) | Acc: (95.00%) (122/128)
Epoch: 132 | Batch_idx: 10 |  Loss: (0.1448) |  Loss2: (0.0000) | Acc: (95.00%) (1342/1408)
Epoch: 132 | Batch_idx: 20 |  Loss: (0.1436) |  Loss2: (0.0000) | Acc: (95.00%) (2555/2688)
Epoch: 132 | Batch_idx: 30 |  Loss: (0.1481) |  Loss2: (0.0000) | Acc: (95.00%) (3774/3968)
Epoch: 132 | Batch_idx: 40 |  Loss: (0.1490) |  Loss2: (0.0000) | Acc: (94.00%) (4983/5248)
Epoch: 132 | Batch_idx: 50 |  Loss: (0.1459) |  Loss2: (0.0000) | Acc: (94.00%) (6200/6528)
Epoch: 132 | Batch_idx: 60 |  Loss: (0.1480) |  Loss2: (0.0000) | Acc: (94.00%) (7409/7808)
Epoch: 132 | Batch_idx: 70 |  Loss: (0.1440) |  Loss2: (0.0000) | Acc: (95.00%) (8635/9088)
Epoch: 132 | Batch_idx: 80 |  Loss: (0.1452) |  Loss2: (0.0000) | Acc: (94.00%) (9847/10368)
Epoch: 132 | Batch_idx: 90 |  Loss: (0.1480) |  Loss2: (0.0000) | Acc: (94.00%) (11052/11648)
Epoch: 132 | Batch_idx: 100 |  Loss: (0.1493) |  Loss2: (0.0000) | Acc: (94.00%) (12261/12928)
Epoch: 132 | Batch_idx: 110 |  Loss: (0.1480) |  Loss2: (0.0000) | Acc: (94.00%) (13475/14208)
Epoch: 132 | Batch_idx: 120 |  Loss: (0.1494) |  Loss2: (0.0000) | Acc: (94.00%) (14682/15488)
Epoch: 132 | Batch_idx: 130 |  Loss: (0.1483) |  Loss2: (0.0000) | Acc: (94.00%) (15899/16768)
Epoch: 132 | Batch_idx: 140 |  Loss: (0.1496) |  Loss2: (0.0000) | Acc: (94.00%) (17105/18048)
Epoch: 132 | Batch_idx: 150 |  Loss: (0.1504) |  Loss2: (0.0000) | Acc: (94.00%) (18309/19328)
Epoch: 132 | Batch_idx: 160 |  Loss: (0.1510) |  Loss2: (0.0000) | Acc: (94.00%) (19515/20608)
Epoch: 132 | Batch_idx: 170 |  Loss: (0.1520) |  Loss2: (0.0000) | Acc: (94.00%) (20724/21888)
Epoch: 132 | Batch_idx: 180 |  Loss: (0.1523) |  Loss2: (0.0000) | Acc: (94.00%) (21928/23168)
Epoch: 132 | Batch_idx: 190 |  Loss: (0.1524) |  Loss2: (0.0000) | Acc: (94.00%) (23135/24448)
Epoch: 132 | Batch_idx: 200 |  Loss: (0.1519) |  Loss2: (0.0000) | Acc: (94.00%) (24353/25728)
Epoch: 132 | Batch_idx: 210 |  Loss: (0.1525) |  Loss2: (0.0000) | Acc: (94.00%) (25562/27008)
Epoch: 132 | Batch_idx: 220 |  Loss: (0.1526) |  Loss2: (0.0000) | Acc: (94.00%) (26770/28288)
Epoch: 132 | Batch_idx: 230 |  Loss: (0.1528) |  Loss2: (0.0000) | Acc: (94.00%) (27975/29568)
Epoch: 132 | Batch_idx: 240 |  Loss: (0.1533) |  Loss2: (0.0000) | Acc: (94.00%) (29181/30848)
Epoch: 132 | Batch_idx: 250 |  Loss: (0.1540) |  Loss2: (0.0000) | Acc: (94.00%) (30383/32128)
Epoch: 132 | Batch_idx: 260 |  Loss: (0.1535) |  Loss2: (0.0000) | Acc: (94.00%) (31604/33408)
Epoch: 132 | Batch_idx: 270 |  Loss: (0.1536) |  Loss2: (0.0000) | Acc: (94.00%) (32810/34688)
Epoch: 132 | Batch_idx: 280 |  Loss: (0.1542) |  Loss2: (0.0000) | Acc: (94.00%) (34021/35968)
Epoch: 132 | Batch_idx: 290 |  Loss: (0.1551) |  Loss2: (0.0000) | Acc: (94.00%) (35222/37248)
Epoch: 132 | Batch_idx: 300 |  Loss: (0.1543) |  Loss2: (0.0000) | Acc: (94.00%) (36449/38528)
Epoch: 132 | Batch_idx: 310 |  Loss: (0.1541) |  Loss2: (0.0000) | Acc: (94.00%) (37669/39808)
Epoch: 132 | Batch_idx: 320 |  Loss: (0.1539) |  Loss2: (0.0000) | Acc: (94.00%) (38887/41088)
Epoch: 132 | Batch_idx: 330 |  Loss: (0.1543) |  Loss2: (0.0000) | Acc: (94.00%) (40091/42368)
Epoch: 132 | Batch_idx: 340 |  Loss: (0.1544) |  Loss2: (0.0000) | Acc: (94.00%) (41301/43648)
Epoch: 132 | Batch_idx: 350 |  Loss: (0.1554) |  Loss2: (0.0000) | Acc: (94.00%) (42501/44928)
Epoch: 132 | Batch_idx: 360 |  Loss: (0.1563) |  Loss2: (0.0000) | Acc: (94.00%) (43701/46208)
Epoch: 132 | Batch_idx: 370 |  Loss: (0.1564) |  Loss2: (0.0000) | Acc: (94.00%) (44911/47488)
Epoch: 132 | Batch_idx: 380 |  Loss: (0.1567) |  Loss2: (0.0000) | Acc: (94.00%) (46111/48768)
Epoch: 132 | Batch_idx: 390 |  Loss: (0.1567) |  Loss2: (0.0000) | Acc: (94.00%) (47279/50000)
# TEST : Loss: (0.4656) | Acc: (86.00%) (8607/10000)
percent tensor([0.5599, 0.5671, 0.5556, 0.5612, 0.5607, 0.5803, 0.5673, 0.5507, 0.5518,
        0.5593, 0.5630, 0.5604, 0.5587, 0.5539, 0.5767, 0.5649],
       device='cuda:0') torch.Size([16])
percent tensor([0.5330, 0.5323, 0.5268, 0.5307, 0.5285, 0.5382, 0.5295, 0.5285, 0.5269,
        0.5293, 0.5336, 0.5262, 0.5289, 0.5299, 0.5349, 0.5332],
       device='cuda:0') torch.Size([16])
percent tensor([0.5461, 0.4286, 0.6972, 0.6803, 0.6987, 0.6409, 0.5256, 0.6597, 0.5809,
        0.4991, 0.4368, 0.6025, 0.4500, 0.4878, 0.5035, 0.5880],
       device='cuda:0') torch.Size([16])
percent tensor([0.6797, 0.7286, 0.5942, 0.6278, 0.6097, 0.5189, 0.6916, 0.6302, 0.6958,
        0.7251, 0.7406, 0.6829, 0.7109, 0.7357, 0.6611, 0.6429],
       device='cuda:0') torch.Size([16])
percent tensor([0.7301, 0.6288, 0.7545, 0.7360, 0.7606, 0.8091, 0.7050, 0.7349, 0.6962,
        0.6258, 0.6114, 0.6417, 0.6077, 0.6530, 0.7116, 0.7569],
       device='cuda:0') torch.Size([16])
percent tensor([0.5783, 0.7082, 0.6967, 0.7802, 0.7251, 0.7893, 0.6660, 0.5248, 0.7039,
        0.6801, 0.7253, 0.7085, 0.6848, 0.7300, 0.5491, 0.5620],
       device='cuda:0') torch.Size([16])
percent tensor([0.4771, 0.6749, 0.6137, 0.6545, 0.5888, 0.5791, 0.5985, 0.5595, 0.6517,
        0.6471, 0.6998, 0.6428, 0.5793, 0.6897, 0.5715, 0.4359],
       device='cuda:0') torch.Size([16])
percent tensor([0.9998, 0.9997, 0.9999, 0.9999, 1.0000, 0.9992, 0.9998, 0.9999, 0.9996,
        0.9999, 0.9994, 1.0000, 0.9994, 0.9994, 0.9997, 0.9997],
       device='cuda:0') torch.Size([16])
Epoch: 133 | Batch_idx: 0 |  Loss: (0.1180) |  Loss2: (0.0000) | Acc: (96.00%) (123/128)
Epoch: 133 | Batch_idx: 10 |  Loss: (0.1553) |  Loss2: (0.0000) | Acc: (94.00%) (1335/1408)
Epoch: 133 | Batch_idx: 20 |  Loss: (0.1408) |  Loss2: (0.0000) | Acc: (95.00%) (2566/2688)
Epoch: 133 | Batch_idx: 30 |  Loss: (0.1385) |  Loss2: (0.0000) | Acc: (95.00%) (3792/3968)
Epoch: 133 | Batch_idx: 40 |  Loss: (0.1396) |  Loss2: (0.0000) | Acc: (95.00%) (5005/5248)
Epoch: 133 | Batch_idx: 50 |  Loss: (0.1409) |  Loss2: (0.0000) | Acc: (95.00%) (6220/6528)
Epoch: 133 | Batch_idx: 60 |  Loss: (0.1439) |  Loss2: (0.0000) | Acc: (95.00%) (7430/7808)
Epoch: 133 | Batch_idx: 70 |  Loss: (0.1433) |  Loss2: (0.0000) | Acc: (95.00%) (8655/9088)
Epoch: 133 | Batch_idx: 80 |  Loss: (0.1437) |  Loss2: (0.0000) | Acc: (95.00%) (9876/10368)
Epoch: 133 | Batch_idx: 90 |  Loss: (0.1447) |  Loss2: (0.0000) | Acc: (95.00%) (11090/11648)
Epoch: 133 | Batch_idx: 100 |  Loss: (0.1435) |  Loss2: (0.0000) | Acc: (95.00%) (12313/12928)
Epoch: 133 | Batch_idx: 110 |  Loss: (0.1445) |  Loss2: (0.0000) | Acc: (95.00%) (13529/14208)
Epoch: 133 | Batch_idx: 120 |  Loss: (0.1426) |  Loss2: (0.0000) | Acc: (95.00%) (14751/15488)
Epoch: 133 | Batch_idx: 130 |  Loss: (0.1419) |  Loss2: (0.0000) | Acc: (95.00%) (15970/16768)
Epoch: 133 | Batch_idx: 140 |  Loss: (0.1424) |  Loss2: (0.0000) | Acc: (95.00%) (17183/18048)
Epoch: 133 | Batch_idx: 150 |  Loss: (0.1422) |  Loss2: (0.0000) | Acc: (95.00%) (18402/19328)
Epoch: 133 | Batch_idx: 160 |  Loss: (0.1415) |  Loss2: (0.0000) | Acc: (95.00%) (19612/20608)
Epoch: 133 | Batch_idx: 170 |  Loss: (0.1418) |  Loss2: (0.0000) | Acc: (95.00%) (20827/21888)
Epoch: 133 | Batch_idx: 180 |  Loss: (0.1439) |  Loss2: (0.0000) | Acc: (95.00%) (22031/23168)
Epoch: 133 | Batch_idx: 190 |  Loss: (0.1447) |  Loss2: (0.0000) | Acc: (95.00%) (23249/24448)
Epoch: 133 | Batch_idx: 200 |  Loss: (0.1438) |  Loss2: (0.0000) | Acc: (95.00%) (24477/25728)
Epoch: 133 | Batch_idx: 210 |  Loss: (0.1441) |  Loss2: (0.0000) | Acc: (95.00%) (25692/27008)
Epoch: 133 | Batch_idx: 220 |  Loss: (0.1445) |  Loss2: (0.0000) | Acc: (95.00%) (26906/28288)
Epoch: 133 | Batch_idx: 230 |  Loss: (0.1437) |  Loss2: (0.0000) | Acc: (95.00%) (28129/29568)
Epoch: 133 | Batch_idx: 240 |  Loss: (0.1452) |  Loss2: (0.0000) | Acc: (95.00%) (29319/30848)
Epoch: 133 | Batch_idx: 250 |  Loss: (0.1455) |  Loss2: (0.0000) | Acc: (95.00%) (30536/32128)
Epoch: 133 | Batch_idx: 260 |  Loss: (0.1454) |  Loss2: (0.0000) | Acc: (95.00%) (31749/33408)
Epoch: 133 | Batch_idx: 270 |  Loss: (0.1452) |  Loss2: (0.0000) | Acc: (95.00%) (32968/34688)
Epoch: 133 | Batch_idx: 280 |  Loss: (0.1455) |  Loss2: (0.0000) | Acc: (95.00%) (34184/35968)
Epoch: 133 | Batch_idx: 290 |  Loss: (0.1459) |  Loss2: (0.0000) | Acc: (95.00%) (35401/37248)
Epoch: 133 | Batch_idx: 300 |  Loss: (0.1455) |  Loss2: (0.0000) | Acc: (95.00%) (36623/38528)
Epoch: 133 | Batch_idx: 310 |  Loss: (0.1458) |  Loss2: (0.0000) | Acc: (95.00%) (37832/39808)
Epoch: 133 | Batch_idx: 320 |  Loss: (0.1460) |  Loss2: (0.0000) | Acc: (95.00%) (39047/41088)
Epoch: 133 | Batch_idx: 330 |  Loss: (0.1463) |  Loss2: (0.0000) | Acc: (95.00%) (40271/42368)
Epoch: 133 | Batch_idx: 340 |  Loss: (0.1468) |  Loss2: (0.0000) | Acc: (95.00%) (41479/43648)
Epoch: 133 | Batch_idx: 350 |  Loss: (0.1471) |  Loss2: (0.0000) | Acc: (95.00%) (42690/44928)
Epoch: 133 | Batch_idx: 360 |  Loss: (0.1473) |  Loss2: (0.0000) | Acc: (94.00%) (43892/46208)
Epoch: 133 | Batch_idx: 370 |  Loss: (0.1475) |  Loss2: (0.0000) | Acc: (94.00%) (45108/47488)
Epoch: 133 | Batch_idx: 380 |  Loss: (0.1475) |  Loss2: (0.0000) | Acc: (94.00%) (46326/48768)
Epoch: 133 | Batch_idx: 390 |  Loss: (0.1479) |  Loss2: (0.0000) | Acc: (94.00%) (47484/50000)
# TEST : Loss: (0.4404) | Acc: (86.00%) (8679/10000)
percent tensor([0.5597, 0.5677, 0.5572, 0.5618, 0.5624, 0.5795, 0.5685, 0.5520, 0.5525,
        0.5602, 0.5626, 0.5620, 0.5589, 0.5544, 0.5767, 0.5650],
       device='cuda:0') torch.Size([16])
percent tensor([0.5326, 0.5316, 0.5268, 0.5308, 0.5288, 0.5394, 0.5296, 0.5279, 0.5267,
        0.5292, 0.5331, 0.5265, 0.5286, 0.5296, 0.5351, 0.5328],
       device='cuda:0') torch.Size([16])
percent tensor([0.5431, 0.4081, 0.6896, 0.6843, 0.7030, 0.6450, 0.5091, 0.6603, 0.5746,
        0.4849, 0.4320, 0.5876, 0.4476, 0.4730, 0.4966, 0.5846],
       device='cuda:0') torch.Size([16])
percent tensor([0.6813, 0.7274, 0.5962, 0.6237, 0.6082, 0.5213, 0.6897, 0.6351, 0.6951,
        0.7197, 0.7436, 0.6845, 0.7078, 0.7356, 0.6698, 0.6426],
       device='cuda:0') torch.Size([16])
percent tensor([0.7344, 0.6156, 0.7594, 0.7374, 0.7654, 0.8108, 0.6958, 0.7291, 0.6938,
        0.6234, 0.6134, 0.6545, 0.6164, 0.6446, 0.7080, 0.7594],
       device='cuda:0') torch.Size([16])
percent tensor([0.6106, 0.6945, 0.7198, 0.7845, 0.7243, 0.7954, 0.6865, 0.5586, 0.6930,
        0.6703, 0.7143, 0.7196, 0.7024, 0.7316, 0.5566, 0.5701],
       device='cuda:0') torch.Size([16])
percent tensor([0.4914, 0.6970, 0.6192, 0.6673, 0.6018, 0.5953, 0.6334, 0.5870, 0.6653,
        0.6630, 0.6994, 0.6404, 0.6050, 0.6971, 0.5925, 0.4460],
       device='cuda:0') torch.Size([16])
percent tensor([0.9997, 0.9998, 0.9997, 0.9999, 0.9999, 0.9992, 0.9996, 0.9997, 0.9997,
        0.9999, 0.9995, 0.9999, 0.9994, 0.9995, 0.9997, 0.9996],
       device='cuda:0') torch.Size([16])
Epoch: 134 | Batch_idx: 0 |  Loss: (0.0910) |  Loss2: (0.0000) | Acc: (97.00%) (125/128)
Epoch: 134 | Batch_idx: 10 |  Loss: (0.1344) |  Loss2: (0.0000) | Acc: (95.00%) (1341/1408)
Epoch: 134 | Batch_idx: 20 |  Loss: (0.1374) |  Loss2: (0.0000) | Acc: (95.00%) (2558/2688)
Epoch: 134 | Batch_idx: 30 |  Loss: (0.1469) |  Loss2: (0.0000) | Acc: (94.00%) (3762/3968)
Epoch: 134 | Batch_idx: 40 |  Loss: (0.1428) |  Loss2: (0.0000) | Acc: (95.00%) (4996/5248)
Epoch: 134 | Batch_idx: 50 |  Loss: (0.1381) |  Loss2: (0.0000) | Acc: (95.00%) (6228/6528)
Epoch: 134 | Batch_idx: 60 |  Loss: (0.1366) |  Loss2: (0.0000) | Acc: (95.00%) (7459/7808)
Epoch: 134 | Batch_idx: 70 |  Loss: (0.1356) |  Loss2: (0.0000) | Acc: (95.00%) (8689/9088)
Epoch: 134 | Batch_idx: 80 |  Loss: (0.1396) |  Loss2: (0.0000) | Acc: (95.00%) (9890/10368)
Epoch: 134 | Batch_idx: 90 |  Loss: (0.1379) |  Loss2: (0.0000) | Acc: (95.00%) (11119/11648)
Epoch: 134 | Batch_idx: 100 |  Loss: (0.1389) |  Loss2: (0.0000) | Acc: (95.00%) (12335/12928)
Epoch: 134 | Batch_idx: 110 |  Loss: (0.1395) |  Loss2: (0.0000) | Acc: (95.00%) (13546/14208)
Epoch: 134 | Batch_idx: 120 |  Loss: (0.1380) |  Loss2: (0.0000) | Acc: (95.00%) (14770/15488)
Epoch: 134 | Batch_idx: 130 |  Loss: (0.1371) |  Loss2: (0.0000) | Acc: (95.00%) (15998/16768)
Epoch: 134 | Batch_idx: 140 |  Loss: (0.1378) |  Loss2: (0.0000) | Acc: (95.00%) (17220/18048)
Epoch: 134 | Batch_idx: 150 |  Loss: (0.1392) |  Loss2: (0.0000) | Acc: (95.00%) (18423/19328)
Epoch: 134 | Batch_idx: 160 |  Loss: (0.1394) |  Loss2: (0.0000) | Acc: (95.00%) (19641/20608)
Epoch: 134 | Batch_idx: 170 |  Loss: (0.1402) |  Loss2: (0.0000) | Acc: (95.00%) (20853/21888)
Epoch: 134 | Batch_idx: 180 |  Loss: (0.1415) |  Loss2: (0.0000) | Acc: (95.00%) (22051/23168)
Epoch: 134 | Batch_idx: 190 |  Loss: (0.1425) |  Loss2: (0.0000) | Acc: (95.00%) (23257/24448)
Epoch: 134 | Batch_idx: 200 |  Loss: (0.1428) |  Loss2: (0.0000) | Acc: (95.00%) (24473/25728)
Epoch: 134 | Batch_idx: 210 |  Loss: (0.1417) |  Loss2: (0.0000) | Acc: (95.00%) (25700/27008)
Epoch: 134 | Batch_idx: 220 |  Loss: (0.1421) |  Loss2: (0.0000) | Acc: (95.00%) (26912/28288)
Epoch: 134 | Batch_idx: 230 |  Loss: (0.1415) |  Loss2: (0.0000) | Acc: (95.00%) (28133/29568)
Epoch: 134 | Batch_idx: 240 |  Loss: (0.1416) |  Loss2: (0.0000) | Acc: (95.00%) (29347/30848)
Epoch: 134 | Batch_idx: 250 |  Loss: (0.1422) |  Loss2: (0.0000) | Acc: (95.00%) (30558/32128)
Epoch: 134 | Batch_idx: 260 |  Loss: (0.1421) |  Loss2: (0.0000) | Acc: (95.00%) (31772/33408)
Epoch: 134 | Batch_idx: 270 |  Loss: (0.1420) |  Loss2: (0.0000) | Acc: (95.00%) (32995/34688)
Epoch: 134 | Batch_idx: 280 |  Loss: (0.1426) |  Loss2: (0.0000) | Acc: (95.00%) (34201/35968)
Epoch: 134 | Batch_idx: 290 |  Loss: (0.1430) |  Loss2: (0.0000) | Acc: (95.00%) (35415/37248)
Epoch: 134 | Batch_idx: 300 |  Loss: (0.1432) |  Loss2: (0.0000) | Acc: (95.00%) (36636/38528)
Epoch: 134 | Batch_idx: 310 |  Loss: (0.1431) |  Loss2: (0.0000) | Acc: (95.00%) (37851/39808)
Epoch: 134 | Batch_idx: 320 |  Loss: (0.1432) |  Loss2: (0.0000) | Acc: (95.00%) (39068/41088)
Epoch: 134 | Batch_idx: 330 |  Loss: (0.1436) |  Loss2: (0.0000) | Acc: (95.00%) (40278/42368)
Epoch: 134 | Batch_idx: 340 |  Loss: (0.1436) |  Loss2: (0.0000) | Acc: (95.00%) (41495/43648)
Epoch: 134 | Batch_idx: 350 |  Loss: (0.1442) |  Loss2: (0.0000) | Acc: (95.00%) (42702/44928)
Epoch: 134 | Batch_idx: 360 |  Loss: (0.1451) |  Loss2: (0.0000) | Acc: (95.00%) (43910/46208)
Epoch: 134 | Batch_idx: 370 |  Loss: (0.1453) |  Loss2: (0.0000) | Acc: (95.00%) (45118/47488)
Epoch: 134 | Batch_idx: 380 |  Loss: (0.1454) |  Loss2: (0.0000) | Acc: (94.00%) (46324/48768)
Epoch: 134 | Batch_idx: 390 |  Loss: (0.1452) |  Loss2: (0.0000) | Acc: (94.00%) (47495/50000)
# TEST : Loss: (0.4427) | Acc: (86.00%) (8681/10000)
percent tensor([0.5607, 0.5664, 0.5595, 0.5604, 0.5638, 0.5798, 0.5675, 0.5518, 0.5540,
        0.5597, 0.5637, 0.5628, 0.5596, 0.5538, 0.5757, 0.5648],
       device='cuda:0') torch.Size([16])
percent tensor([0.5325, 0.5323, 0.5252, 0.5301, 0.5278, 0.5391, 0.5298, 0.5277, 0.5271,
        0.5293, 0.5339, 0.5254, 0.5287, 0.5309, 0.5353, 0.5335],
       device='cuda:0') torch.Size([16])
percent tensor([0.5448, 0.4295, 0.6842, 0.6770, 0.6996, 0.6488, 0.5249, 0.6626, 0.5759,
        0.4952, 0.4432, 0.5887, 0.4440, 0.4896, 0.5056, 0.5957],
       device='cuda:0') torch.Size([16])
percent tensor([0.6876, 0.7379, 0.6075, 0.6334, 0.6142, 0.5301, 0.6952, 0.6328, 0.7026,
        0.7300, 0.7489, 0.6871, 0.7116, 0.7420, 0.6729, 0.6493],
       device='cuda:0') torch.Size([16])
percent tensor([0.7240, 0.6167, 0.7473, 0.7348, 0.7640, 0.8109, 0.7079, 0.7294, 0.6833,
        0.6142, 0.5954, 0.6390, 0.6062, 0.6594, 0.7046, 0.7608],
       device='cuda:0') torch.Size([16])
percent tensor([0.5623, 0.6674, 0.7013, 0.7506, 0.7012, 0.7897, 0.6440, 0.5257, 0.7067,
        0.6627, 0.7091, 0.7094, 0.6706, 0.7223, 0.5101, 0.5345],
       device='cuda:0') torch.Size([16])
percent tensor([0.4727, 0.6506, 0.6040, 0.6204, 0.5819, 0.5884, 0.5977, 0.5545, 0.6641,
        0.6282, 0.6731, 0.6493, 0.6097, 0.6682, 0.5679, 0.4394],
       device='cuda:0') torch.Size([16])
percent tensor([0.9998, 0.9997, 0.9997, 0.9998, 0.9999, 0.9988, 0.9998, 0.9997, 0.9997,
        0.9999, 0.9994, 0.9999, 0.9995, 0.9997, 0.9997, 0.9996],
       device='cuda:0') torch.Size([16])
False Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=128, out_features=16, bias=False)
True Linear(in_features=16, out_features=2, bias=False)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=128, out_features=16, bias=False)
True Linear(in_features=16, out_features=2, bias=False)
False Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=256, out_features=32, bias=False)
True Linear(in_features=32, out_features=2, bias=False)
False Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=256, out_features=32, bias=False)
True Linear(in_features=32, out_features=2, bias=False)
False Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=512, out_features=64, bias=False)
True Linear(in_features=64, out_features=2, bias=False)
False Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=512, out_features=64, bias=False)
True Linear(in_features=64, out_features=2, bias=False)
False Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1024, out_features=128, bias=False)
True Linear(in_features=128, out_features=2, bias=False)
False Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1024, out_features=128, bias=False)
True Linear(in_features=128, out_features=2, bias=False)
False Linear(in_features=512, out_features=10, bias=True)
Epoch: 135 | Batch_idx: 0 |  Loss: (0.1034) |  Loss2: (0.0000) | Acc: (96.00%) (124/128)
Epoch: 135 | Batch_idx: 10 |  Loss: (0.1311) |  Loss2: (0.0000) | Acc: (95.00%) (1344/1408)
Epoch: 135 | Batch_idx: 20 |  Loss: (0.1355) |  Loss2: (0.0000) | Acc: (95.00%) (2566/2688)
Epoch: 135 | Batch_idx: 30 |  Loss: (0.1460) |  Loss2: (0.0000) | Acc: (95.00%) (3773/3968)
Epoch: 135 | Batch_idx: 40 |  Loss: (0.1537) |  Loss2: (0.0000) | Acc: (94.00%) (4966/5248)
Epoch: 135 | Batch_idx: 50 |  Loss: (0.1515) |  Loss2: (0.0000) | Acc: (94.00%) (6176/6528)
Epoch: 135 | Batch_idx: 60 |  Loss: (0.1573) |  Loss2: (0.0000) | Acc: (94.00%) (7377/7808)
Epoch: 135 | Batch_idx: 70 |  Loss: (0.1586) |  Loss2: (0.0000) | Acc: (94.00%) (8581/9088)
Epoch: 135 | Batch_idx: 80 |  Loss: (0.1613) |  Loss2: (0.0000) | Acc: (94.00%) (9776/10368)
Epoch: 135 | Batch_idx: 90 |  Loss: (0.1647) |  Loss2: (0.0000) | Acc: (94.00%) (10971/11648)
Epoch: 135 | Batch_idx: 100 |  Loss: (0.1681) |  Loss2: (0.0000) | Acc: (94.00%) (12164/12928)
Epoch: 135 | Batch_idx: 110 |  Loss: (0.1680) |  Loss2: (0.0000) | Acc: (94.00%) (13368/14208)
Epoch: 135 | Batch_idx: 120 |  Loss: (0.1661) |  Loss2: (0.0000) | Acc: (94.00%) (14577/15488)
Epoch: 135 | Batch_idx: 130 |  Loss: (0.1663) |  Loss2: (0.0000) | Acc: (94.00%) (15780/16768)
Epoch: 135 | Batch_idx: 140 |  Loss: (0.1642) |  Loss2: (0.0000) | Acc: (94.00%) (16999/18048)
Epoch: 135 | Batch_idx: 150 |  Loss: (0.1652) |  Loss2: (0.0000) | Acc: (94.00%) (18199/19328)
Epoch: 135 | Batch_idx: 160 |  Loss: (0.1663) |  Loss2: (0.0000) | Acc: (94.00%) (19394/20608)
Epoch: 135 | Batch_idx: 170 |  Loss: (0.1651) |  Loss2: (0.0000) | Acc: (94.00%) (20594/21888)
Epoch: 135 | Batch_idx: 180 |  Loss: (0.1644) |  Loss2: (0.0000) | Acc: (94.00%) (21803/23168)
Epoch: 135 | Batch_idx: 190 |  Loss: (0.1627) |  Loss2: (0.0000) | Acc: (94.00%) (23020/24448)
Epoch: 135 | Batch_idx: 200 |  Loss: (0.1617) |  Loss2: (0.0000) | Acc: (94.00%) (24240/25728)
Epoch: 135 | Batch_idx: 210 |  Loss: (0.1614) |  Loss2: (0.0000) | Acc: (94.00%) (25453/27008)
Epoch: 135 | Batch_idx: 220 |  Loss: (0.1605) |  Loss2: (0.0000) | Acc: (94.00%) (26679/28288)
Epoch: 135 | Batch_idx: 230 |  Loss: (0.1589) |  Loss2: (0.0000) | Acc: (94.00%) (27910/29568)
Epoch: 135 | Batch_idx: 240 |  Loss: (0.1588) |  Loss2: (0.0000) | Acc: (94.00%) (29125/30848)
Epoch: 135 | Batch_idx: 250 |  Loss: (0.1587) |  Loss2: (0.0000) | Acc: (94.00%) (30336/32128)
Epoch: 135 | Batch_idx: 260 |  Loss: (0.1579) |  Loss2: (0.0000) | Acc: (94.00%) (31557/33408)
Epoch: 135 | Batch_idx: 270 |  Loss: (0.1573) |  Loss2: (0.0000) | Acc: (94.00%) (32771/34688)
Epoch: 135 | Batch_idx: 280 |  Loss: (0.1569) |  Loss2: (0.0000) | Acc: (94.00%) (33989/35968)
Epoch: 135 | Batch_idx: 290 |  Loss: (0.1572) |  Loss2: (0.0000) | Acc: (94.00%) (35192/37248)
Epoch: 135 | Batch_idx: 300 |  Loss: (0.1568) |  Loss2: (0.0000) | Acc: (94.00%) (36408/38528)
Epoch: 135 | Batch_idx: 310 |  Loss: (0.1565) |  Loss2: (0.0000) | Acc: (94.00%) (37623/39808)
Epoch: 135 | Batch_idx: 320 |  Loss: (0.1565) |  Loss2: (0.0000) | Acc: (94.00%) (38821/41088)
Epoch: 135 | Batch_idx: 330 |  Loss: (0.1564) |  Loss2: (0.0000) | Acc: (94.00%) (40042/42368)
Epoch: 135 | Batch_idx: 340 |  Loss: (0.1562) |  Loss2: (0.0000) | Acc: (94.00%) (41256/43648)
Epoch: 135 | Batch_idx: 350 |  Loss: (0.1558) |  Loss2: (0.0000) | Acc: (94.00%) (42467/44928)
Epoch: 135 | Batch_idx: 360 |  Loss: (0.1556) |  Loss2: (0.0000) | Acc: (94.00%) (43682/46208)
Epoch: 135 | Batch_idx: 370 |  Loss: (0.1550) |  Loss2: (0.0000) | Acc: (94.00%) (44899/47488)
Epoch: 135 | Batch_idx: 380 |  Loss: (0.1551) |  Loss2: (0.0000) | Acc: (94.00%) (46113/48768)
Epoch: 135 | Batch_idx: 390 |  Loss: (0.1546) |  Loss2: (0.0000) | Acc: (94.00%) (47294/50000)
=> saving checkpoint 'drive/app/torch/save_Schedule/checkpoint_135.pth.tar'
# TEST : Loss: (0.3797) | Acc: (88.00%) (8826/10000)
percent tensor([0.5605, 0.5672, 0.5585, 0.5602, 0.5630, 0.5804, 0.5680, 0.5510, 0.5536,
        0.5600, 0.5641, 0.5629, 0.5595, 0.5535, 0.5764, 0.5652],
       device='cuda:0') torch.Size([16])
percent tensor([0.5260, 0.5266, 0.5199, 0.5239, 0.5202, 0.5327, 0.5229, 0.5211, 0.5207,
        0.5238, 0.5275, 0.5201, 0.5230, 0.5254, 0.5284, 0.5275],
       device='cuda:0') torch.Size([16])
percent tensor([0.5627, 0.4528, 0.6850, 0.6851, 0.6984, 0.6506, 0.5406, 0.6597, 0.5911,
        0.5188, 0.4704, 0.6065, 0.4760, 0.5133, 0.5227, 0.6125],
       device='cuda:0') torch.Size([16])
percent tensor([0.7021, 0.7422, 0.6306, 0.6511, 0.6384, 0.5459, 0.7061, 0.6483, 0.7158,
        0.7430, 0.7589, 0.7068, 0.7215, 0.7458, 0.6845, 0.6619],
       device='cuda:0') torch.Size([16])
percent tensor([0.7166, 0.6138, 0.7380, 0.7247, 0.7620, 0.8068, 0.7013, 0.7271, 0.6719,
        0.5989, 0.5816, 0.6162, 0.5919, 0.6532, 0.6918, 0.7640],
       device='cuda:0') torch.Size([16])
percent tensor([0.5896, 0.6879, 0.7087, 0.7582, 0.7005, 0.7967, 0.6699, 0.5579, 0.7228,
        0.6729, 0.7157, 0.7118, 0.6910, 0.7345, 0.5399, 0.5498],
       device='cuda:0') torch.Size([16])
percent tensor([0.4772, 0.6716, 0.6129, 0.6361, 0.5720, 0.5923, 0.6193, 0.5591, 0.6956,
        0.6621, 0.7056, 0.6766, 0.6376, 0.6969, 0.5772, 0.4229],
       device='cuda:0') torch.Size([16])
percent tensor([0.9997, 0.9996, 0.9997, 0.9998, 0.9999, 0.9990, 0.9998, 0.9997, 0.9997,
        0.9998, 0.9993, 1.0000, 0.9996, 0.9996, 0.9997, 0.9996],
       device='cuda:0') torch.Size([16])
Epoch: 136 | Batch_idx: 0 |  Loss: (0.0723) |  Loss2: (0.0000) | Acc: (97.00%) (125/128)
Epoch: 136 | Batch_idx: 10 |  Loss: (0.1521) |  Loss2: (0.0000) | Acc: (94.00%) (1328/1408)
Epoch: 136 | Batch_idx: 20 |  Loss: (0.1501) |  Loss2: (0.0000) | Acc: (94.00%) (2546/2688)
Epoch: 136 | Batch_idx: 30 |  Loss: (0.1369) |  Loss2: (0.0000) | Acc: (95.00%) (3784/3968)
Epoch: 136 | Batch_idx: 40 |  Loss: (0.1380) |  Loss2: (0.0000) | Acc: (95.00%) (5003/5248)
Epoch: 136 | Batch_idx: 50 |  Loss: (0.1405) |  Loss2: (0.0000) | Acc: (95.00%) (6220/6528)
Epoch: 136 | Batch_idx: 60 |  Loss: (0.1425) |  Loss2: (0.0000) | Acc: (95.00%) (7435/7808)
Epoch: 136 | Batch_idx: 70 |  Loss: (0.1404) |  Loss2: (0.0000) | Acc: (95.00%) (8659/9088)
Epoch: 136 | Batch_idx: 80 |  Loss: (0.1403) |  Loss2: (0.0000) | Acc: (95.00%) (9879/10368)
Epoch: 136 | Batch_idx: 90 |  Loss: (0.1425) |  Loss2: (0.0000) | Acc: (95.00%) (11085/11648)
Epoch: 136 | Batch_idx: 100 |  Loss: (0.1437) |  Loss2: (0.0000) | Acc: (95.00%) (12297/12928)
Epoch: 136 | Batch_idx: 110 |  Loss: (0.1428) |  Loss2: (0.0000) | Acc: (95.00%) (13514/14208)
Epoch: 136 | Batch_idx: 120 |  Loss: (0.1431) |  Loss2: (0.0000) | Acc: (95.00%) (14740/15488)
Epoch: 136 | Batch_idx: 130 |  Loss: (0.1422) |  Loss2: (0.0000) | Acc: (95.00%) (15964/16768)
Epoch: 136 | Batch_idx: 140 |  Loss: (0.1424) |  Loss2: (0.0000) | Acc: (95.00%) (17177/18048)
Epoch: 136 | Batch_idx: 150 |  Loss: (0.1415) |  Loss2: (0.0000) | Acc: (95.00%) (18398/19328)
Epoch: 136 | Batch_idx: 160 |  Loss: (0.1422) |  Loss2: (0.0000) | Acc: (95.00%) (19609/20608)
Epoch: 136 | Batch_idx: 170 |  Loss: (0.1418) |  Loss2: (0.0000) | Acc: (95.00%) (20828/21888)
Epoch: 136 | Batch_idx: 180 |  Loss: (0.1422) |  Loss2: (0.0000) | Acc: (95.00%) (22037/23168)
Epoch: 136 | Batch_idx: 190 |  Loss: (0.1426) |  Loss2: (0.0000) | Acc: (95.00%) (23246/24448)
Epoch: 136 | Batch_idx: 200 |  Loss: (0.1432) |  Loss2: (0.0000) | Acc: (95.00%) (24467/25728)
Epoch: 136 | Batch_idx: 210 |  Loss: (0.1429) |  Loss2: (0.0000) | Acc: (95.00%) (25680/27008)
Epoch: 136 | Batch_idx: 220 |  Loss: (0.1434) |  Loss2: (0.0000) | Acc: (95.00%) (26886/28288)
Epoch: 136 | Batch_idx: 230 |  Loss: (0.1436) |  Loss2: (0.0000) | Acc: (95.00%) (28100/29568)
Epoch: 136 | Batch_idx: 240 |  Loss: (0.1432) |  Loss2: (0.0000) | Acc: (95.00%) (29322/30848)
Epoch: 136 | Batch_idx: 250 |  Loss: (0.1433) |  Loss2: (0.0000) | Acc: (95.00%) (30542/32128)
Epoch: 136 | Batch_idx: 260 |  Loss: (0.1437) |  Loss2: (0.0000) | Acc: (95.00%) (31754/33408)
Epoch: 136 | Batch_idx: 270 |  Loss: (0.1435) |  Loss2: (0.0000) | Acc: (95.00%) (32970/34688)
Epoch: 136 | Batch_idx: 280 |  Loss: (0.1432) |  Loss2: (0.0000) | Acc: (95.00%) (34196/35968)
Epoch: 136 | Batch_idx: 290 |  Loss: (0.1428) |  Loss2: (0.0000) | Acc: (95.00%) (35426/37248)
Epoch: 136 | Batch_idx: 300 |  Loss: (0.1425) |  Loss2: (0.0000) | Acc: (95.00%) (36646/38528)
Epoch: 136 | Batch_idx: 310 |  Loss: (0.1431) |  Loss2: (0.0000) | Acc: (95.00%) (37857/39808)
Epoch: 136 | Batch_idx: 320 |  Loss: (0.1426) |  Loss2: (0.0000) | Acc: (95.00%) (39080/41088)
Epoch: 136 | Batch_idx: 330 |  Loss: (0.1426) |  Loss2: (0.0000) | Acc: (95.00%) (40296/42368)
Epoch: 136 | Batch_idx: 340 |  Loss: (0.1421) |  Loss2: (0.0000) | Acc: (95.00%) (41525/43648)
Epoch: 136 | Batch_idx: 350 |  Loss: (0.1423) |  Loss2: (0.0000) | Acc: (95.00%) (42744/44928)
Epoch: 136 | Batch_idx: 360 |  Loss: (0.1422) |  Loss2: (0.0000) | Acc: (95.00%) (43965/46208)
Epoch: 136 | Batch_idx: 370 |  Loss: (0.1421) |  Loss2: (0.0000) | Acc: (95.00%) (45184/47488)
Epoch: 136 | Batch_idx: 380 |  Loss: (0.1413) |  Loss2: (0.0000) | Acc: (95.00%) (46406/48768)
Epoch: 136 | Batch_idx: 390 |  Loss: (0.1411) |  Loss2: (0.0000) | Acc: (95.00%) (47581/50000)
# TEST : Loss: (0.3719) | Acc: (88.00%) (8857/10000)
percent tensor([0.5597, 0.5669, 0.5575, 0.5592, 0.5622, 0.5803, 0.5676, 0.5497, 0.5528,
        0.5593, 0.5637, 0.5623, 0.5587, 0.5530, 0.5762, 0.5645],
       device='cuda:0') torch.Size([16])
percent tensor([0.5242, 0.5248, 0.5181, 0.5222, 0.5176, 0.5312, 0.5206, 0.5190, 0.5189,
        0.5223, 0.5257, 0.5188, 0.5214, 0.5237, 0.5266, 0.5258],
       device='cuda:0') torch.Size([16])
percent tensor([0.5523, 0.4446, 0.6834, 0.6851, 0.6971, 0.6426, 0.5331, 0.6560, 0.5901,
        0.5149, 0.4632, 0.6063, 0.4690, 0.5094, 0.5112, 0.6050],
       device='cuda:0') torch.Size([16])
percent tensor([0.7009, 0.7394, 0.6261, 0.6523, 0.6357, 0.5453, 0.7037, 0.6469, 0.7143,
        0.7389, 0.7567, 0.7016, 0.7182, 0.7454, 0.6805, 0.6624],
       device='cuda:0') torch.Size([16])
percent tensor([0.7152, 0.6091, 0.7384, 0.7219, 0.7638, 0.8023, 0.6994, 0.7283, 0.6696,
        0.6001, 0.5756, 0.6130, 0.5901, 0.6472, 0.6876, 0.7634],
       device='cuda:0') torch.Size([16])
percent tensor([0.5799, 0.6827, 0.6976, 0.7461, 0.6922, 0.7920, 0.6604, 0.5425, 0.7100,
        0.6632, 0.7034, 0.7001, 0.6810, 0.7251, 0.5327, 0.5302],
       device='cuda:0') torch.Size([16])
percent tensor([0.4838, 0.6943, 0.6280, 0.6547, 0.5805, 0.6151, 0.6367, 0.5674, 0.7148,
        0.6778, 0.7284, 0.6978, 0.6532, 0.7236, 0.5900, 0.4249],
       device='cuda:0') torch.Size([16])
percent tensor([0.9997, 0.9997, 0.9997, 0.9998, 0.9999, 0.9990, 0.9998, 0.9997, 0.9997,
        0.9998, 0.9993, 1.0000, 0.9996, 0.9996, 0.9997, 0.9996],
       device='cuda:0') torch.Size([16])
Epoch: 137 | Batch_idx: 0 |  Loss: (0.0919) |  Loss2: (0.0000) | Acc: (99.00%) (127/128)
Epoch: 137 | Batch_idx: 10 |  Loss: (0.1349) |  Loss2: (0.0000) | Acc: (95.00%) (1345/1408)
Epoch: 137 | Batch_idx: 20 |  Loss: (0.1357) |  Loss2: (0.0000) | Acc: (95.00%) (2566/2688)
Epoch: 137 | Batch_idx: 30 |  Loss: (0.1401) |  Loss2: (0.0000) | Acc: (95.00%) (3781/3968)
Epoch: 137 | Batch_idx: 40 |  Loss: (0.1377) |  Loss2: (0.0000) | Acc: (95.00%) (5003/5248)
Epoch: 137 | Batch_idx: 50 |  Loss: (0.1361) |  Loss2: (0.0000) | Acc: (95.00%) (6227/6528)
Epoch: 137 | Batch_idx: 60 |  Loss: (0.1354) |  Loss2: (0.0000) | Acc: (95.00%) (7454/7808)
Epoch: 137 | Batch_idx: 70 |  Loss: (0.1356) |  Loss2: (0.0000) | Acc: (95.00%) (8678/9088)
Epoch: 137 | Batch_idx: 80 |  Loss: (0.1381) |  Loss2: (0.0000) | Acc: (95.00%) (9890/10368)
Epoch: 137 | Batch_idx: 90 |  Loss: (0.1377) |  Loss2: (0.0000) | Acc: (95.00%) (11107/11648)
Epoch: 137 | Batch_idx: 100 |  Loss: (0.1365) |  Loss2: (0.0000) | Acc: (95.00%) (12334/12928)
Epoch: 137 | Batch_idx: 110 |  Loss: (0.1354) |  Loss2: (0.0000) | Acc: (95.00%) (13551/14208)
Epoch: 137 | Batch_idx: 120 |  Loss: (0.1338) |  Loss2: (0.0000) | Acc: (95.00%) (14782/15488)
Epoch: 137 | Batch_idx: 130 |  Loss: (0.1334) |  Loss2: (0.0000) | Acc: (95.00%) (16008/16768)
Epoch: 137 | Batch_idx: 140 |  Loss: (0.1320) |  Loss2: (0.0000) | Acc: (95.00%) (17242/18048)
Epoch: 137 | Batch_idx: 150 |  Loss: (0.1324) |  Loss2: (0.0000) | Acc: (95.00%) (18457/19328)
Epoch: 137 | Batch_idx: 160 |  Loss: (0.1322) |  Loss2: (0.0000) | Acc: (95.00%) (19684/20608)
Epoch: 137 | Batch_idx: 170 |  Loss: (0.1322) |  Loss2: (0.0000) | Acc: (95.00%) (20900/21888)
Epoch: 137 | Batch_idx: 180 |  Loss: (0.1317) |  Loss2: (0.0000) | Acc: (95.00%) (22129/23168)
Epoch: 137 | Batch_idx: 190 |  Loss: (0.1318) |  Loss2: (0.0000) | Acc: (95.00%) (23354/24448)
Epoch: 137 | Batch_idx: 200 |  Loss: (0.1330) |  Loss2: (0.0000) | Acc: (95.00%) (24567/25728)
Epoch: 137 | Batch_idx: 210 |  Loss: (0.1324) |  Loss2: (0.0000) | Acc: (95.00%) (25804/27008)
Epoch: 137 | Batch_idx: 220 |  Loss: (0.1322) |  Loss2: (0.0000) | Acc: (95.00%) (27020/28288)
Epoch: 137 | Batch_idx: 230 |  Loss: (0.1320) |  Loss2: (0.0000) | Acc: (95.00%) (28241/29568)
Epoch: 137 | Batch_idx: 240 |  Loss: (0.1318) |  Loss2: (0.0000) | Acc: (95.00%) (29463/30848)
Epoch: 137 | Batch_idx: 250 |  Loss: (0.1320) |  Loss2: (0.0000) | Acc: (95.00%) (30687/32128)
Epoch: 137 | Batch_idx: 260 |  Loss: (0.1321) |  Loss2: (0.0000) | Acc: (95.00%) (31914/33408)
Epoch: 137 | Batch_idx: 270 |  Loss: (0.1318) |  Loss2: (0.0000) | Acc: (95.00%) (33143/34688)
Epoch: 137 | Batch_idx: 280 |  Loss: (0.1325) |  Loss2: (0.0000) | Acc: (95.00%) (34363/35968)
Epoch: 137 | Batch_idx: 290 |  Loss: (0.1321) |  Loss2: (0.0000) | Acc: (95.00%) (35601/37248)
Epoch: 137 | Batch_idx: 300 |  Loss: (0.1323) |  Loss2: (0.0000) | Acc: (95.00%) (36823/38528)
Epoch: 137 | Batch_idx: 310 |  Loss: (0.1318) |  Loss2: (0.0000) | Acc: (95.00%) (38052/39808)
Epoch: 137 | Batch_idx: 320 |  Loss: (0.1317) |  Loss2: (0.0000) | Acc: (95.00%) (39280/41088)
Epoch: 137 | Batch_idx: 330 |  Loss: (0.1322) |  Loss2: (0.0000) | Acc: (95.00%) (40487/42368)
Epoch: 137 | Batch_idx: 340 |  Loss: (0.1318) |  Loss2: (0.0000) | Acc: (95.00%) (41720/43648)
Epoch: 137 | Batch_idx: 350 |  Loss: (0.1323) |  Loss2: (0.0000) | Acc: (95.00%) (42923/44928)
Epoch: 137 | Batch_idx: 360 |  Loss: (0.1329) |  Loss2: (0.0000) | Acc: (95.00%) (44133/46208)
Epoch: 137 | Batch_idx: 370 |  Loss: (0.1326) |  Loss2: (0.0000) | Acc: (95.00%) (45354/47488)
Epoch: 137 | Batch_idx: 380 |  Loss: (0.1326) |  Loss2: (0.0000) | Acc: (95.00%) (46582/48768)
Epoch: 137 | Batch_idx: 390 |  Loss: (0.1330) |  Loss2: (0.0000) | Acc: (95.00%) (47754/50000)
# TEST : Loss: (0.3614) | Acc: (88.00%) (8876/10000)
percent tensor([0.5585, 0.5658, 0.5563, 0.5582, 0.5610, 0.5794, 0.5664, 0.5483, 0.5515,
        0.5580, 0.5625, 0.5612, 0.5573, 0.5518, 0.5751, 0.5633],
       device='cuda:0') torch.Size([16])
percent tensor([0.5230, 0.5237, 0.5171, 0.5211, 0.5162, 0.5303, 0.5192, 0.5177, 0.5177,
        0.5213, 0.5246, 0.5179, 0.5204, 0.5226, 0.5255, 0.5247],
       device='cuda:0') torch.Size([16])
percent tensor([0.5526, 0.4448, 0.6843, 0.6865, 0.7009, 0.6406, 0.5359, 0.6593, 0.5935,
        0.5144, 0.4638, 0.6077, 0.4716, 0.5088, 0.5108, 0.6041],
       device='cuda:0') torch.Size([16])
percent tensor([0.7003, 0.7375, 0.6263, 0.6529, 0.6349, 0.5445, 0.7030, 0.6481, 0.7139,
        0.7374, 0.7544, 0.7015, 0.7172, 0.7448, 0.6784, 0.6619],
       device='cuda:0') torch.Size([16])
percent tensor([0.7169, 0.6107, 0.7377, 0.7227, 0.7642, 0.8023, 0.6989, 0.7276, 0.6706,
        0.6050, 0.5797, 0.6124, 0.5924, 0.6480, 0.6891, 0.7670],
       device='cuda:0') torch.Size([16])
percent tensor([0.5839, 0.6868, 0.6996, 0.7457, 0.6957, 0.7938, 0.6621, 0.5466, 0.7070,
        0.6633, 0.7042, 0.6953, 0.6807, 0.7257, 0.5389, 0.5328],
       device='cuda:0') torch.Size([16])
percent tensor([0.4790, 0.6951, 0.6306, 0.6580, 0.5802, 0.6173, 0.6379, 0.5696, 0.7153,
        0.6740, 0.7324, 0.7002, 0.6505, 0.7289, 0.5928, 0.4198],
       device='cuda:0') torch.Size([16])
percent tensor([0.9997, 0.9996, 0.9997, 0.9998, 0.9999, 0.9989, 0.9998, 0.9996, 0.9997,
        0.9998, 0.9993, 1.0000, 0.9995, 0.9996, 0.9997, 0.9996],
       device='cuda:0') torch.Size([16])
True Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=128, out_features=16, bias=False)
False Linear(in_features=16, out_features=2, bias=False)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=128, out_features=16, bias=False)
False Linear(in_features=16, out_features=2, bias=False)
True Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=256, out_features=32, bias=False)
False Linear(in_features=32, out_features=2, bias=False)
True Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=256, out_features=32, bias=False)
False Linear(in_features=32, out_features=2, bias=False)
True Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=512, out_features=64, bias=False)
False Linear(in_features=64, out_features=2, bias=False)
True Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=512, out_features=64, bias=False)
False Linear(in_features=64, out_features=2, bias=False)
True Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1024, out_features=128, bias=False)
False Linear(in_features=128, out_features=2, bias=False)
True Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1024, out_features=128, bias=False)
False Linear(in_features=128, out_features=2, bias=False)
True Linear(in_features=512, out_features=10, bias=True)
Epoch: 138 | Batch_idx: 0 |  Loss: (0.1406) |  Loss2: (0.0000) | Acc: (95.00%) (122/128)
Epoch: 138 | Batch_idx: 10 |  Loss: (0.1119) |  Loss2: (0.0000) | Acc: (96.00%) (1355/1408)
Epoch: 138 | Batch_idx: 20 |  Loss: (0.1161) |  Loss2: (0.0000) | Acc: (96.00%) (2591/2688)
Epoch: 138 | Batch_idx: 30 |  Loss: (0.1151) |  Loss2: (0.0000) | Acc: (96.00%) (3820/3968)
Epoch: 138 | Batch_idx: 40 |  Loss: (0.1249) |  Loss2: (0.0000) | Acc: (95.00%) (5034/5248)
Epoch: 138 | Batch_idx: 50 |  Loss: (0.1262) |  Loss2: (0.0000) | Acc: (95.00%) (6259/6528)
Epoch: 138 | Batch_idx: 60 |  Loss: (0.1298) |  Loss2: (0.0000) | Acc: (95.00%) (7467/7808)
Epoch: 138 | Batch_idx: 70 |  Loss: (0.1307) |  Loss2: (0.0000) | Acc: (95.00%) (8690/9088)
Epoch: 138 | Batch_idx: 80 |  Loss: (0.1320) |  Loss2: (0.0000) | Acc: (95.00%) (9905/10368)
Epoch: 138 | Batch_idx: 90 |  Loss: (0.1324) |  Loss2: (0.0000) | Acc: (95.00%) (11120/11648)
Epoch: 138 | Batch_idx: 100 |  Loss: (0.1317) |  Loss2: (0.0000) | Acc: (95.00%) (12346/12928)
Epoch: 138 | Batch_idx: 110 |  Loss: (0.1317) |  Loss2: (0.0000) | Acc: (95.00%) (13567/14208)
Epoch: 138 | Batch_idx: 120 |  Loss: (0.1296) |  Loss2: (0.0000) | Acc: (95.00%) (14802/15488)
Epoch: 138 | Batch_idx: 130 |  Loss: (0.1304) |  Loss2: (0.0000) | Acc: (95.00%) (16026/16768)
Epoch: 138 | Batch_idx: 140 |  Loss: (0.1316) |  Loss2: (0.0000) | Acc: (95.00%) (17240/18048)
Epoch: 138 | Batch_idx: 150 |  Loss: (0.1327) |  Loss2: (0.0000) | Acc: (95.00%) (18446/19328)
Epoch: 138 | Batch_idx: 160 |  Loss: (0.1324) |  Loss2: (0.0000) | Acc: (95.00%) (19673/20608)
Epoch: 138 | Batch_idx: 170 |  Loss: (0.1349) |  Loss2: (0.0000) | Acc: (95.00%) (20876/21888)
Epoch: 138 | Batch_idx: 180 |  Loss: (0.1353) |  Loss2: (0.0000) | Acc: (95.00%) (22101/23168)
Epoch: 138 | Batch_idx: 190 |  Loss: (0.1371) |  Loss2: (0.0000) | Acc: (95.00%) (23305/24448)
Epoch: 138 | Batch_idx: 200 |  Loss: (0.1373) |  Loss2: (0.0000) | Acc: (95.00%) (24522/25728)
Epoch: 138 | Batch_idx: 210 |  Loss: (0.1382) |  Loss2: (0.0000) | Acc: (95.00%) (25731/27008)
Epoch: 138 | Batch_idx: 220 |  Loss: (0.1383) |  Loss2: (0.0000) | Acc: (95.00%) (26952/28288)
Epoch: 138 | Batch_idx: 230 |  Loss: (0.1391) |  Loss2: (0.0000) | Acc: (95.00%) (28159/29568)
Epoch: 138 | Batch_idx: 240 |  Loss: (0.1401) |  Loss2: (0.0000) | Acc: (95.00%) (29367/30848)
Epoch: 138 | Batch_idx: 250 |  Loss: (0.1396) |  Loss2: (0.0000) | Acc: (95.00%) (30591/32128)
Epoch: 138 | Batch_idx: 260 |  Loss: (0.1399) |  Loss2: (0.0000) | Acc: (95.00%) (31800/33408)
Epoch: 138 | Batch_idx: 270 |  Loss: (0.1411) |  Loss2: (0.0000) | Acc: (95.00%) (33001/34688)
Epoch: 138 | Batch_idx: 280 |  Loss: (0.1408) |  Loss2: (0.0000) | Acc: (95.00%) (34226/35968)
Epoch: 138 | Batch_idx: 290 |  Loss: (0.1420) |  Loss2: (0.0000) | Acc: (95.00%) (35437/37248)
Epoch: 138 | Batch_idx: 300 |  Loss: (0.1415) |  Loss2: (0.0000) | Acc: (95.00%) (36666/38528)
Epoch: 138 | Batch_idx: 310 |  Loss: (0.1416) |  Loss2: (0.0000) | Acc: (95.00%) (37886/39808)
Epoch: 138 | Batch_idx: 320 |  Loss: (0.1416) |  Loss2: (0.0000) | Acc: (95.00%) (39106/41088)
Epoch: 138 | Batch_idx: 330 |  Loss: (0.1420) |  Loss2: (0.0000) | Acc: (95.00%) (40309/42368)
Epoch: 138 | Batch_idx: 340 |  Loss: (0.1430) |  Loss2: (0.0000) | Acc: (95.00%) (41509/43648)
Epoch: 138 | Batch_idx: 350 |  Loss: (0.1434) |  Loss2: (0.0000) | Acc: (95.00%) (42723/44928)
Epoch: 138 | Batch_idx: 360 |  Loss: (0.1434) |  Loss2: (0.0000) | Acc: (95.00%) (43952/46208)
Epoch: 138 | Batch_idx: 370 |  Loss: (0.1432) |  Loss2: (0.0000) | Acc: (95.00%) (45175/47488)
Epoch: 138 | Batch_idx: 380 |  Loss: (0.1432) |  Loss2: (0.0000) | Acc: (95.00%) (46384/48768)
Epoch: 138 | Batch_idx: 390 |  Loss: (0.1430) |  Loss2: (0.0000) | Acc: (95.00%) (47556/50000)
# TEST : Loss: (0.4095) | Acc: (87.00%) (8746/10000)
percent tensor([0.5577, 0.5659, 0.5544, 0.5586, 0.5588, 0.5792, 0.5656, 0.5487, 0.5503,
        0.5578, 0.5619, 0.5587, 0.5569, 0.5512, 0.5751, 0.5629],
       device='cuda:0') torch.Size([16])
percent tensor([0.5235, 0.5237, 0.5172, 0.5230, 0.5182, 0.5302, 0.5191, 0.5176, 0.5179,
        0.5215, 0.5247, 0.5186, 0.5211, 0.5219, 0.5257, 0.5250],
       device='cuda:0') torch.Size([16])
percent tensor([0.5689, 0.4549, 0.7008, 0.6918, 0.7131, 0.6524, 0.5564, 0.6698, 0.6080,
        0.5253, 0.4636, 0.6302, 0.4850, 0.5272, 0.5257, 0.6165],
       device='cuda:0') torch.Size([16])
percent tensor([0.6929, 0.7296, 0.6098, 0.6385, 0.6173, 0.5211, 0.6975, 0.6458, 0.7074,
        0.7299, 0.7510, 0.6957, 0.7126, 0.7435, 0.6719, 0.6500],
       device='cuda:0') torch.Size([16])
percent tensor([0.7323, 0.6251, 0.7554, 0.7426, 0.7736, 0.8150, 0.7095, 0.7340, 0.6856,
        0.6300, 0.6096, 0.6259, 0.6127, 0.6523, 0.7050, 0.7736],
       device='cuda:0') torch.Size([16])
percent tensor([0.5819, 0.7117, 0.7037, 0.7717, 0.7268, 0.7946, 0.6663, 0.5366, 0.7060,
        0.6667, 0.7289, 0.7042, 0.6889, 0.7300, 0.5747, 0.5692],
       device='cuda:0') torch.Size([16])
percent tensor([0.4616, 0.6963, 0.6468, 0.6521, 0.5959, 0.6031, 0.6124, 0.5773, 0.7056,
        0.6489, 0.7342, 0.6924, 0.6469, 0.7146, 0.5780, 0.4156],
       device='cuda:0') torch.Size([16])
percent tensor([0.9996, 0.9997, 0.9998, 0.9999, 1.0000, 0.9990, 0.9998, 0.9998, 0.9997,
        0.9998, 0.9993, 0.9999, 0.9994, 0.9993, 0.9997, 0.9996],
       device='cuda:0') torch.Size([16])
Epoch: 139 | Batch_idx: 0 |  Loss: (0.0759) |  Loss2: (0.0000) | Acc: (97.00%) (125/128)
Epoch: 139 | Batch_idx: 10 |  Loss: (0.1282) |  Loss2: (0.0000) | Acc: (95.00%) (1347/1408)
Epoch: 139 | Batch_idx: 20 |  Loss: (0.1302) |  Loss2: (0.0000) | Acc: (95.00%) (2568/2688)
Epoch: 139 | Batch_idx: 30 |  Loss: (0.1287) |  Loss2: (0.0000) | Acc: (95.00%) (3792/3968)
Epoch: 139 | Batch_idx: 40 |  Loss: (0.1339) |  Loss2: (0.0000) | Acc: (95.00%) (5000/5248)
Epoch: 139 | Batch_idx: 50 |  Loss: (0.1359) |  Loss2: (0.0000) | Acc: (95.00%) (6212/6528)
Epoch: 139 | Batch_idx: 60 |  Loss: (0.1364) |  Loss2: (0.0000) | Acc: (95.00%) (7439/7808)
Epoch: 139 | Batch_idx: 70 |  Loss: (0.1345) |  Loss2: (0.0000) | Acc: (95.00%) (8671/9088)
Epoch: 139 | Batch_idx: 80 |  Loss: (0.1326) |  Loss2: (0.0000) | Acc: (95.00%) (9909/10368)
Epoch: 139 | Batch_idx: 90 |  Loss: (0.1319) |  Loss2: (0.0000) | Acc: (95.00%) (11139/11648)
Epoch: 139 | Batch_idx: 100 |  Loss: (0.1335) |  Loss2: (0.0000) | Acc: (95.00%) (12350/12928)
Epoch: 139 | Batch_idx: 110 |  Loss: (0.1320) |  Loss2: (0.0000) | Acc: (95.00%) (13583/14208)
Epoch: 139 | Batch_idx: 120 |  Loss: (0.1310) |  Loss2: (0.0000) | Acc: (95.00%) (14812/15488)
Epoch: 139 | Batch_idx: 130 |  Loss: (0.1321) |  Loss2: (0.0000) | Acc: (95.00%) (16020/16768)
Epoch: 139 | Batch_idx: 140 |  Loss: (0.1331) |  Loss2: (0.0000) | Acc: (95.00%) (17237/18048)
Epoch: 139 | Batch_idx: 150 |  Loss: (0.1349) |  Loss2: (0.0000) | Acc: (95.00%) (18446/19328)
Epoch: 139 | Batch_idx: 160 |  Loss: (0.1346) |  Loss2: (0.0000) | Acc: (95.00%) (19669/20608)
Epoch: 139 | Batch_idx: 170 |  Loss: (0.1357) |  Loss2: (0.0000) | Acc: (95.00%) (20873/21888)
Epoch: 139 | Batch_idx: 180 |  Loss: (0.1366) |  Loss2: (0.0000) | Acc: (95.00%) (22089/23168)
Epoch: 139 | Batch_idx: 190 |  Loss: (0.1354) |  Loss2: (0.0000) | Acc: (95.00%) (23320/24448)
Epoch: 139 | Batch_idx: 200 |  Loss: (0.1349) |  Loss2: (0.0000) | Acc: (95.00%) (24542/25728)
Epoch: 139 | Batch_idx: 210 |  Loss: (0.1340) |  Loss2: (0.0000) | Acc: (95.00%) (25772/27008)
Epoch: 139 | Batch_idx: 220 |  Loss: (0.1342) |  Loss2: (0.0000) | Acc: (95.00%) (26994/28288)
Epoch: 139 | Batch_idx: 230 |  Loss: (0.1342) |  Loss2: (0.0000) | Acc: (95.00%) (28216/29568)
Epoch: 139 | Batch_idx: 240 |  Loss: (0.1345) |  Loss2: (0.0000) | Acc: (95.00%) (29430/30848)
Epoch: 139 | Batch_idx: 250 |  Loss: (0.1356) |  Loss2: (0.0000) | Acc: (95.00%) (30641/32128)
Epoch: 139 | Batch_idx: 260 |  Loss: (0.1348) |  Loss2: (0.0000) | Acc: (95.00%) (31871/33408)
Epoch: 139 | Batch_idx: 270 |  Loss: (0.1349) |  Loss2: (0.0000) | Acc: (95.00%) (33097/34688)
Epoch: 139 | Batch_idx: 280 |  Loss: (0.1352) |  Loss2: (0.0000) | Acc: (95.00%) (34312/35968)
Epoch: 139 | Batch_idx: 290 |  Loss: (0.1355) |  Loss2: (0.0000) | Acc: (95.00%) (35535/37248)
Epoch: 139 | Batch_idx: 300 |  Loss: (0.1364) |  Loss2: (0.0000) | Acc: (95.00%) (36746/38528)
Epoch: 139 | Batch_idx: 310 |  Loss: (0.1366) |  Loss2: (0.0000) | Acc: (95.00%) (37957/39808)
Epoch: 139 | Batch_idx: 320 |  Loss: (0.1374) |  Loss2: (0.0000) | Acc: (95.00%) (39172/41088)
Epoch: 139 | Batch_idx: 330 |  Loss: (0.1378) |  Loss2: (0.0000) | Acc: (95.00%) (40388/42368)
Epoch: 139 | Batch_idx: 340 |  Loss: (0.1378) |  Loss2: (0.0000) | Acc: (95.00%) (41613/43648)
Epoch: 139 | Batch_idx: 350 |  Loss: (0.1385) |  Loss2: (0.0000) | Acc: (95.00%) (42822/44928)
Epoch: 139 | Batch_idx: 360 |  Loss: (0.1383) |  Loss2: (0.0000) | Acc: (95.00%) (44041/46208)
Epoch: 139 | Batch_idx: 370 |  Loss: (0.1387) |  Loss2: (0.0000) | Acc: (95.00%) (45254/47488)
Epoch: 139 | Batch_idx: 380 |  Loss: (0.1396) |  Loss2: (0.0000) | Acc: (95.00%) (46463/48768)
Epoch: 139 | Batch_idx: 390 |  Loss: (0.1396) |  Loss2: (0.0000) | Acc: (95.00%) (47641/50000)
# TEST : Loss: (0.4354) | Acc: (87.00%) (8706/10000)
percent tensor([0.5578, 0.5655, 0.5557, 0.5575, 0.5602, 0.5782, 0.5662, 0.5488, 0.5514,
        0.5576, 0.5618, 0.5601, 0.5572, 0.5516, 0.5741, 0.5624],
       device='cuda:0') torch.Size([16])
percent tensor([0.5241, 0.5254, 0.5160, 0.5224, 0.5175, 0.5315, 0.5201, 0.5174, 0.5182,
        0.5225, 0.5262, 0.5177, 0.5217, 0.5232, 0.5272, 0.5260],
       device='cuda:0') torch.Size([16])
percent tensor([0.5617, 0.4539, 0.6852, 0.6878, 0.7003, 0.6630, 0.5405, 0.6586, 0.5970,
        0.5170, 0.4630, 0.6116, 0.4700, 0.5173, 0.5240, 0.6132],
       device='cuda:0') torch.Size([16])
percent tensor([0.6936, 0.7329, 0.6185, 0.6413, 0.6220, 0.5209, 0.6977, 0.6518, 0.7102,
        0.7328, 0.7473, 0.6949, 0.7211, 0.7393, 0.6708, 0.6537],
       device='cuda:0') torch.Size([16])
percent tensor([0.7243, 0.5963, 0.7505, 0.7315, 0.7672, 0.8100, 0.6968, 0.7253, 0.6819,
        0.6216, 0.6012, 0.6316, 0.5887, 0.6349, 0.6950, 0.7685],
       device='cuda:0') torch.Size([16])
percent tensor([0.5775, 0.6836, 0.7008, 0.7646, 0.7264, 0.7813, 0.6894, 0.5635, 0.6792,
        0.6568, 0.6997, 0.6904, 0.6586, 0.7170, 0.5652, 0.5512],
       device='cuda:0') torch.Size([16])
percent tensor([0.4622, 0.6944, 0.6278, 0.6633, 0.6085, 0.6337, 0.6591, 0.5798, 0.6712,
        0.6274, 0.7246, 0.6661, 0.6336, 0.7069, 0.6038, 0.4341],
       device='cuda:0') torch.Size([16])
percent tensor([0.9997, 0.9997, 0.9997, 0.9999, 0.9999, 0.9986, 0.9998, 0.9995, 0.9998,
        0.9998, 0.9996, 0.9999, 0.9996, 0.9997, 0.9996, 0.9994],
       device='cuda:0') torch.Size([16])
Epoch: 140 | Batch_idx: 0 |  Loss: (0.1512) |  Loss2: (0.0000) | Acc: (94.00%) (121/128)
Epoch: 140 | Batch_idx: 10 |  Loss: (0.1297) |  Loss2: (0.0000) | Acc: (95.00%) (1343/1408)
Epoch: 140 | Batch_idx: 20 |  Loss: (0.1418) |  Loss2: (0.0000) | Acc: (94.00%) (2549/2688)
Epoch: 140 | Batch_idx: 30 |  Loss: (0.1411) |  Loss2: (0.0000) | Acc: (94.00%) (3765/3968)
Epoch: 140 | Batch_idx: 40 |  Loss: (0.1358) |  Loss2: (0.0000) | Acc: (95.00%) (4993/5248)
Epoch: 140 | Batch_idx: 50 |  Loss: (0.1339) |  Loss2: (0.0000) | Acc: (95.00%) (6215/6528)
Epoch: 140 | Batch_idx: 60 |  Loss: (0.1305) |  Loss2: (0.0000) | Acc: (95.00%) (7454/7808)
Epoch: 140 | Batch_idx: 70 |  Loss: (0.1284) |  Loss2: (0.0000) | Acc: (95.00%) (8686/9088)
Epoch: 140 | Batch_idx: 80 |  Loss: (0.1306) |  Loss2: (0.0000) | Acc: (95.00%) (9903/10368)
Epoch: 140 | Batch_idx: 90 |  Loss: (0.1323) |  Loss2: (0.0000) | Acc: (95.00%) (11118/11648)
Epoch: 140 | Batch_idx: 100 |  Loss: (0.1335) |  Loss2: (0.0000) | Acc: (95.00%) (12338/12928)
Epoch: 140 | Batch_idx: 110 |  Loss: (0.1338) |  Loss2: (0.0000) | Acc: (95.00%) (13551/14208)
Epoch: 140 | Batch_idx: 120 |  Loss: (0.1342) |  Loss2: (0.0000) | Acc: (95.00%) (14769/15488)
Epoch: 140 | Batch_idx: 130 |  Loss: (0.1335) |  Loss2: (0.0000) | Acc: (95.00%) (15993/16768)
Epoch: 140 | Batch_idx: 140 |  Loss: (0.1335) |  Loss2: (0.0000) | Acc: (95.00%) (17210/18048)
Epoch: 140 | Batch_idx: 150 |  Loss: (0.1325) |  Loss2: (0.0000) | Acc: (95.00%) (18434/19328)
Epoch: 140 | Batch_idx: 160 |  Loss: (0.1328) |  Loss2: (0.0000) | Acc: (95.00%) (19656/20608)
Epoch: 140 | Batch_idx: 170 |  Loss: (0.1309) |  Loss2: (0.0000) | Acc: (95.00%) (20897/21888)
Epoch: 140 | Batch_idx: 180 |  Loss: (0.1311) |  Loss2: (0.0000) | Acc: (95.00%) (22107/23168)
Epoch: 140 | Batch_idx: 190 |  Loss: (0.1308) |  Loss2: (0.0000) | Acc: (95.00%) (23332/24448)
Epoch: 140 | Batch_idx: 200 |  Loss: (0.1316) |  Loss2: (0.0000) | Acc: (95.00%) (24551/25728)
Epoch: 140 | Batch_idx: 210 |  Loss: (0.1320) |  Loss2: (0.0000) | Acc: (95.00%) (25769/27008)
Epoch: 140 | Batch_idx: 220 |  Loss: (0.1320) |  Loss2: (0.0000) | Acc: (95.00%) (26984/28288)
Epoch: 140 | Batch_idx: 230 |  Loss: (0.1326) |  Loss2: (0.0000) | Acc: (95.00%) (28202/29568)
Epoch: 140 | Batch_idx: 240 |  Loss: (0.1323) |  Loss2: (0.0000) | Acc: (95.00%) (29428/30848)
Epoch: 140 | Batch_idx: 250 |  Loss: (0.1326) |  Loss2: (0.0000) | Acc: (95.00%) (30650/32128)
Epoch: 140 | Batch_idx: 260 |  Loss: (0.1333) |  Loss2: (0.0000) | Acc: (95.00%) (31862/33408)
Epoch: 140 | Batch_idx: 270 |  Loss: (0.1334) |  Loss2: (0.0000) | Acc: (95.00%) (33082/34688)
Epoch: 140 | Batch_idx: 280 |  Loss: (0.1332) |  Loss2: (0.0000) | Acc: (95.00%) (34309/35968)
Epoch: 140 | Batch_idx: 290 |  Loss: (0.1334) |  Loss2: (0.0000) | Acc: (95.00%) (35526/37248)
Epoch: 140 | Batch_idx: 300 |  Loss: (0.1344) |  Loss2: (0.0000) | Acc: (95.00%) (36724/38528)
Epoch: 140 | Batch_idx: 310 |  Loss: (0.1345) |  Loss2: (0.0000) | Acc: (95.00%) (37952/39808)
Epoch: 140 | Batch_idx: 320 |  Loss: (0.1346) |  Loss2: (0.0000) | Acc: (95.00%) (39176/41088)
Epoch: 140 | Batch_idx: 330 |  Loss: (0.1349) |  Loss2: (0.0000) | Acc: (95.00%) (40394/42368)
Epoch: 140 | Batch_idx: 340 |  Loss: (0.1352) |  Loss2: (0.0000) | Acc: (95.00%) (41605/43648)
Epoch: 140 | Batch_idx: 350 |  Loss: (0.1362) |  Loss2: (0.0000) | Acc: (95.00%) (42815/44928)
Epoch: 140 | Batch_idx: 360 |  Loss: (0.1365) |  Loss2: (0.0000) | Acc: (95.00%) (44031/46208)
Epoch: 140 | Batch_idx: 370 |  Loss: (0.1368) |  Loss2: (0.0000) | Acc: (95.00%) (45254/47488)
Epoch: 140 | Batch_idx: 380 |  Loss: (0.1365) |  Loss2: (0.0000) | Acc: (95.00%) (46477/48768)
Epoch: 140 | Batch_idx: 390 |  Loss: (0.1367) |  Loss2: (0.0000) | Acc: (95.00%) (47646/50000)
=> saving checkpoint 'drive/app/torch/save_Schedule/checkpoint_140.pth.tar'
# TEST : Loss: (0.4055) | Acc: (88.00%) (8807/10000)
percent tensor([0.5574, 0.5663, 0.5531, 0.5579, 0.5587, 0.5786, 0.5660, 0.5478, 0.5503,
        0.5576, 0.5618, 0.5584, 0.5570, 0.5521, 0.5750, 0.5626],
       device='cuda:0') torch.Size([16])
percent tensor([0.5231, 0.5243, 0.5161, 0.5219, 0.5168, 0.5300, 0.5195, 0.5166, 0.5178,
        0.5216, 0.5252, 0.5174, 0.5211, 0.5229, 0.5258, 0.5249],
       device='cuda:0') torch.Size([16])
percent tensor([0.5537, 0.4476, 0.6882, 0.6865, 0.7034, 0.6561, 0.5349, 0.6640, 0.5973,
        0.5098, 0.4595, 0.6124, 0.4652, 0.5102, 0.5146, 0.6055],
       device='cuda:0') torch.Size([16])
percent tensor([0.6994, 0.7377, 0.6087, 0.6411, 0.6220, 0.5352, 0.7052, 0.6460, 0.7121,
        0.7363, 0.7568, 0.6919, 0.7260, 0.7467, 0.6801, 0.6621],
       device='cuda:0') torch.Size([16])
percent tensor([0.7168, 0.6040, 0.7455, 0.7391, 0.7584, 0.8016, 0.6962, 0.7276, 0.6874,
        0.6195, 0.5893, 0.6329, 0.5944, 0.6361, 0.6917, 0.7610],
       device='cuda:0') torch.Size([16])
percent tensor([0.5913, 0.7174, 0.7167, 0.7582, 0.7294, 0.8032, 0.6682, 0.5313, 0.6885,
        0.6773, 0.7188, 0.6880, 0.6852, 0.7389, 0.5640, 0.5507],
       device='cuda:0') torch.Size([16])
percent tensor([0.4802, 0.7116, 0.6596, 0.6715, 0.6064, 0.6561, 0.6309, 0.5646, 0.6969,
        0.6615, 0.7340, 0.6563, 0.6372, 0.7141, 0.5760, 0.4334],
       device='cuda:0') torch.Size([16])
percent tensor([0.9998, 0.9998, 0.9996, 0.9999, 0.9999, 0.9994, 0.9999, 0.9998, 0.9998,
        0.9999, 0.9995, 0.9998, 0.9995, 0.9995, 0.9997, 0.9996],
       device='cuda:0') torch.Size([16])
False Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=128, out_features=16, bias=False)
True Linear(in_features=16, out_features=2, bias=False)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=128, out_features=16, bias=False)
True Linear(in_features=16, out_features=2, bias=False)
False Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=256, out_features=32, bias=False)
True Linear(in_features=32, out_features=2, bias=False)
False Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=256, out_features=32, bias=False)
True Linear(in_features=32, out_features=2, bias=False)
False Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=512, out_features=64, bias=False)
True Linear(in_features=64, out_features=2, bias=False)
False Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=512, out_features=64, bias=False)
True Linear(in_features=64, out_features=2, bias=False)
False Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1024, out_features=128, bias=False)
True Linear(in_features=128, out_features=2, bias=False)
False Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1024, out_features=128, bias=False)
True Linear(in_features=128, out_features=2, bias=False)
False Linear(in_features=512, out_features=10, bias=True)
Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 3, 3, 3]) tensor(184.0882, device='cuda:0')
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(817.3917, device='cuda:0')
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(825.6198, device='cuda:0')
Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([128, 64, 3, 3]) tensor(1516.2699, device='cuda:0')
Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([128, 64, 1, 1]) tensor(492.8073, device='cuda:0')
Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([128, 128, 3, 3]) tensor(2262.5007, device='cuda:0')
Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([256, 128, 3, 3]) tensor(4284.4888, device='cuda:0')
Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([256, 128, 1, 1]) tensor(1382.6035, device='cuda:0')
Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([256, 256, 3, 3]) tensor(6206.8662, device='cuda:0')
Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([512, 256, 3, 3]) tensor(11742.4229, device='cuda:0')
Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([512, 256, 1, 1]) tensor(3882.5117, device='cuda:0')
Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([512, 512, 3, 3]) tensor(16365.6689, device='cuda:0')
Epoch: 141 | Batch_idx: 0 |  Loss: (0.1974) |  Loss2: (0.0000) | Acc: (90.00%) (116/128)
Epoch: 141 | Batch_idx: 10 |  Loss: (0.1526) |  Loss2: (0.0000) | Acc: (95.00%) (1339/1408)
Epoch: 141 | Batch_idx: 20 |  Loss: (0.1595) |  Loss2: (0.0000) | Acc: (94.00%) (2542/2688)
Epoch: 141 | Batch_idx: 30 |  Loss: (0.1581) |  Loss2: (0.0000) | Acc: (94.00%) (3745/3968)
Epoch: 141 | Batch_idx: 40 |  Loss: (0.1567) |  Loss2: (0.0000) | Acc: (94.00%) (4965/5248)
Epoch: 141 | Batch_idx: 50 |  Loss: (0.1577) |  Loss2: (0.0000) | Acc: (94.00%) (6177/6528)
Epoch: 141 | Batch_idx: 60 |  Loss: (0.1569) |  Loss2: (0.0000) | Acc: (94.00%) (7382/7808)
Epoch: 141 | Batch_idx: 70 |  Loss: (0.1549) |  Loss2: (0.0000) | Acc: (94.00%) (8598/9088)
Epoch: 141 | Batch_idx: 80 |  Loss: (0.1583) |  Loss2: (0.0000) | Acc: (94.00%) (9792/10368)
Epoch: 141 | Batch_idx: 90 |  Loss: (0.1590) |  Loss2: (0.0000) | Acc: (94.00%) (11000/11648)
Epoch: 141 | Batch_idx: 100 |  Loss: (0.1592) |  Loss2: (0.0000) | Acc: (94.00%) (12208/12928)
Epoch: 141 | Batch_idx: 110 |  Loss: (0.1579) |  Loss2: (0.0000) | Acc: (94.00%) (13428/14208)
Epoch: 141 | Batch_idx: 120 |  Loss: (0.1569) |  Loss2: (0.0000) | Acc: (94.00%) (14637/15488)
Epoch: 141 | Batch_idx: 130 |  Loss: (0.1576) |  Loss2: (0.0000) | Acc: (94.00%) (15844/16768)
Epoch: 141 | Batch_idx: 140 |  Loss: (0.1570) |  Loss2: (0.0000) | Acc: (94.00%) (17057/18048)
Epoch: 141 | Batch_idx: 150 |  Loss: (0.1566) |  Loss2: (0.0000) | Acc: (94.00%) (18264/19328)
Epoch: 141 | Batch_idx: 160 |  Loss: (0.1552) |  Loss2: (0.0000) | Acc: (94.00%) (19484/20608)
Epoch: 141 | Batch_idx: 170 |  Loss: (0.1535) |  Loss2: (0.0000) | Acc: (94.00%) (20707/21888)
Epoch: 141 | Batch_idx: 180 |  Loss: (0.1536) |  Loss2: (0.0000) | Acc: (94.00%) (21916/23168)
Epoch: 141 | Batch_idx: 190 |  Loss: (0.1531) |  Loss2: (0.0000) | Acc: (94.00%) (23128/24448)
Epoch: 141 | Batch_idx: 200 |  Loss: (0.1532) |  Loss2: (0.0000) | Acc: (94.00%) (24334/25728)
Epoch: 141 | Batch_idx: 210 |  Loss: (0.1526) |  Loss2: (0.0000) | Acc: (94.00%) (25544/27008)
Epoch: 141 | Batch_idx: 220 |  Loss: (0.1518) |  Loss2: (0.0000) | Acc: (94.00%) (26763/28288)
Epoch: 141 | Batch_idx: 230 |  Loss: (0.1513) |  Loss2: (0.0000) | Acc: (94.00%) (27988/29568)
Epoch: 141 | Batch_idx: 240 |  Loss: (0.1513) |  Loss2: (0.0000) | Acc: (94.00%) (29205/30848)
Epoch: 141 | Batch_idx: 250 |  Loss: (0.1516) |  Loss2: (0.0000) | Acc: (94.00%) (30412/32128)
Epoch: 141 | Batch_idx: 260 |  Loss: (0.1517) |  Loss2: (0.0000) | Acc: (94.00%) (31621/33408)
Epoch: 141 | Batch_idx: 270 |  Loss: (0.1514) |  Loss2: (0.0000) | Acc: (94.00%) (32832/34688)
Epoch: 141 | Batch_idx: 280 |  Loss: (0.1503) |  Loss2: (0.0000) | Acc: (94.00%) (34055/35968)
Epoch: 141 | Batch_idx: 290 |  Loss: (0.1500) |  Loss2: (0.0000) | Acc: (94.00%) (35277/37248)
Epoch: 141 | Batch_idx: 300 |  Loss: (0.1494) |  Loss2: (0.0000) | Acc: (94.00%) (36503/38528)
Epoch: 141 | Batch_idx: 310 |  Loss: (0.1499) |  Loss2: (0.0000) | Acc: (94.00%) (37709/39808)
Epoch: 141 | Batch_idx: 320 |  Loss: (0.1505) |  Loss2: (0.0000) | Acc: (94.00%) (38912/41088)
Epoch: 141 | Batch_idx: 330 |  Loss: (0.1499) |  Loss2: (0.0000) | Acc: (94.00%) (40130/42368)
Epoch: 141 | Batch_idx: 340 |  Loss: (0.1492) |  Loss2: (0.0000) | Acc: (94.00%) (41355/43648)
Epoch: 141 | Batch_idx: 350 |  Loss: (0.1494) |  Loss2: (0.0000) | Acc: (94.00%) (42567/44928)
Epoch: 141 | Batch_idx: 360 |  Loss: (0.1492) |  Loss2: (0.0000) | Acc: (94.00%) (43789/46208)
Epoch: 141 | Batch_idx: 370 |  Loss: (0.1484) |  Loss2: (0.0000) | Acc: (94.00%) (45014/47488)
Epoch: 141 | Batch_idx: 380 |  Loss: (0.1482) |  Loss2: (0.0000) | Acc: (94.00%) (46234/48768)
Epoch: 141 | Batch_idx: 390 |  Loss: (0.1480) |  Loss2: (0.0000) | Acc: (94.00%) (47398/50000)
# TEST : Loss: (0.4087) | Acc: (88.00%) (8833/10000)
percent tensor([0.5600, 0.5697, 0.5557, 0.5603, 0.5618, 0.5810, 0.5695, 0.5509, 0.5535,
        0.5608, 0.5648, 0.5616, 0.5601, 0.5557, 0.5780, 0.5653],
       device='cuda:0') torch.Size([16])
percent tensor([0.5179, 0.5188, 0.5108, 0.5165, 0.5090, 0.5258, 0.5128, 0.5102, 0.5122,
        0.5163, 0.5199, 0.5120, 0.5152, 0.5179, 0.5205, 0.5203],
       device='cuda:0') torch.Size([16])
percent tensor([0.5758, 0.4518, 0.6971, 0.7019, 0.7131, 0.6673, 0.5493, 0.6758, 0.6163,
        0.5255, 0.4825, 0.6302, 0.4809, 0.5249, 0.5310, 0.6239],
       device='cuda:0') torch.Size([16])
percent tensor([0.7120, 0.7424, 0.6228, 0.6520, 0.6358, 0.5458, 0.7159, 0.6591, 0.7266,
        0.7439, 0.7628, 0.7024, 0.7333, 0.7613, 0.6898, 0.6746],
       device='cuda:0') torch.Size([16])
percent tensor([0.7056, 0.5947, 0.7406, 0.7332, 0.7533, 0.7974, 0.6843, 0.7225, 0.6720,
        0.6029, 0.5774, 0.6187, 0.5779, 0.6180, 0.6826, 0.7543],
       device='cuda:0') torch.Size([16])
percent tensor([0.5624, 0.7220, 0.7070, 0.7534, 0.7232, 0.7959, 0.6639, 0.5147, 0.6702,
        0.6741, 0.7101, 0.6899, 0.6731, 0.7374, 0.5596, 0.5248],
       device='cuda:0') torch.Size([16])
percent tensor([0.4790, 0.7137, 0.6718, 0.6956, 0.6157, 0.6545, 0.6535, 0.5823, 0.6926,
        0.6623, 0.7260, 0.6798, 0.6259, 0.7206, 0.6000, 0.4294],
       device='cuda:0') torch.Size([16])
percent tensor([0.9997, 0.9997, 0.9996, 0.9999, 0.9999, 0.9995, 0.9999, 0.9998, 0.9997,
        0.9998, 0.9996, 0.9997, 0.9993, 0.9994, 0.9998, 0.9996],
       device='cuda:0') torch.Size([16])
Epoch: 142 | Batch_idx: 0 |  Loss: (0.0871) |  Loss2: (0.0000) | Acc: (97.00%) (125/128)
Epoch: 142 | Batch_idx: 10 |  Loss: (0.1522) |  Loss2: (0.0000) | Acc: (94.00%) (1330/1408)
Epoch: 142 | Batch_idx: 20 |  Loss: (0.1438) |  Loss2: (0.0000) | Acc: (95.00%) (2556/2688)
Epoch: 142 | Batch_idx: 30 |  Loss: (0.1435) |  Loss2: (0.0000) | Acc: (95.00%) (3776/3968)
Epoch: 142 | Batch_idx: 40 |  Loss: (0.1401) |  Loss2: (0.0000) | Acc: (95.00%) (4995/5248)
Epoch: 142 | Batch_idx: 50 |  Loss: (0.1410) |  Loss2: (0.0000) | Acc: (95.00%) (6205/6528)
Epoch: 142 | Batch_idx: 60 |  Loss: (0.1417) |  Loss2: (0.0000) | Acc: (95.00%) (7420/7808)
Epoch: 142 | Batch_idx: 70 |  Loss: (0.1436) |  Loss2: (0.0000) | Acc: (94.00%) (8622/9088)
Epoch: 142 | Batch_idx: 80 |  Loss: (0.1435) |  Loss2: (0.0000) | Acc: (94.00%) (9828/10368)
Epoch: 142 | Batch_idx: 90 |  Loss: (0.1418) |  Loss2: (0.0000) | Acc: (94.00%) (11055/11648)
Epoch: 142 | Batch_idx: 100 |  Loss: (0.1399) |  Loss2: (0.0000) | Acc: (94.00%) (12276/12928)
Epoch: 142 | Batch_idx: 110 |  Loss: (0.1387) |  Loss2: (0.0000) | Acc: (95.00%) (13505/14208)
Epoch: 142 | Batch_idx: 120 |  Loss: (0.1360) |  Loss2: (0.0000) | Acc: (95.00%) (14736/15488)
Epoch: 142 | Batch_idx: 130 |  Loss: (0.1349) |  Loss2: (0.0000) | Acc: (95.00%) (15967/16768)
Epoch: 142 | Batch_idx: 140 |  Loss: (0.1347) |  Loss2: (0.0000) | Acc: (95.00%) (17187/18048)
Epoch: 142 | Batch_idx: 150 |  Loss: (0.1345) |  Loss2: (0.0000) | Acc: (95.00%) (18410/19328)
Epoch: 142 | Batch_idx: 160 |  Loss: (0.1338) |  Loss2: (0.0000) | Acc: (95.00%) (19629/20608)
Epoch: 142 | Batch_idx: 170 |  Loss: (0.1342) |  Loss2: (0.0000) | Acc: (95.00%) (20841/21888)
Epoch: 142 | Batch_idx: 180 |  Loss: (0.1335) |  Loss2: (0.0000) | Acc: (95.00%) (22062/23168)
Epoch: 142 | Batch_idx: 190 |  Loss: (0.1329) |  Loss2: (0.0000) | Acc: (95.00%) (23287/24448)
Epoch: 142 | Batch_idx: 200 |  Loss: (0.1321) |  Loss2: (0.0000) | Acc: (95.00%) (24518/25728)
Epoch: 142 | Batch_idx: 210 |  Loss: (0.1327) |  Loss2: (0.0000) | Acc: (95.00%) (25737/27008)
Epoch: 142 | Batch_idx: 220 |  Loss: (0.1333) |  Loss2: (0.0000) | Acc: (95.00%) (26953/28288)
Epoch: 142 | Batch_idx: 230 |  Loss: (0.1328) |  Loss2: (0.0000) | Acc: (95.00%) (28185/29568)
Epoch: 142 | Batch_idx: 240 |  Loss: (0.1331) |  Loss2: (0.0000) | Acc: (95.00%) (29406/30848)
Epoch: 142 | Batch_idx: 250 |  Loss: (0.1336) |  Loss2: (0.0000) | Acc: (95.00%) (30616/32128)
Epoch: 142 | Batch_idx: 260 |  Loss: (0.1336) |  Loss2: (0.0000) | Acc: (95.00%) (31837/33408)
Epoch: 142 | Batch_idx: 270 |  Loss: (0.1341) |  Loss2: (0.0000) | Acc: (95.00%) (33050/34688)
Epoch: 142 | Batch_idx: 280 |  Loss: (0.1346) |  Loss2: (0.0000) | Acc: (95.00%) (34263/35968)
Epoch: 142 | Batch_idx: 290 |  Loss: (0.1340) |  Loss2: (0.0000) | Acc: (95.00%) (35491/37248)
Epoch: 142 | Batch_idx: 300 |  Loss: (0.1337) |  Loss2: (0.0000) | Acc: (95.00%) (36713/38528)
Epoch: 142 | Batch_idx: 310 |  Loss: (0.1333) |  Loss2: (0.0000) | Acc: (95.00%) (37935/39808)
Epoch: 142 | Batch_idx: 320 |  Loss: (0.1332) |  Loss2: (0.0000) | Acc: (95.00%) (39161/41088)
Epoch: 142 | Batch_idx: 330 |  Loss: (0.1328) |  Loss2: (0.0000) | Acc: (95.00%) (40385/42368)
Epoch: 142 | Batch_idx: 340 |  Loss: (0.1333) |  Loss2: (0.0000) | Acc: (95.00%) (41593/43648)
Epoch: 142 | Batch_idx: 350 |  Loss: (0.1336) |  Loss2: (0.0000) | Acc: (95.00%) (42801/44928)
Epoch: 142 | Batch_idx: 360 |  Loss: (0.1332) |  Loss2: (0.0000) | Acc: (95.00%) (44025/46208)
Epoch: 142 | Batch_idx: 370 |  Loss: (0.1329) |  Loss2: (0.0000) | Acc: (95.00%) (45254/47488)
Epoch: 142 | Batch_idx: 380 |  Loss: (0.1330) |  Loss2: (0.0000) | Acc: (95.00%) (46468/48768)
Epoch: 142 | Batch_idx: 390 |  Loss: (0.1326) |  Loss2: (0.0000) | Acc: (95.00%) (47653/50000)
# TEST : Loss: (0.3938) | Acc: (88.00%) (8871/10000)
percent tensor([0.5617, 0.5717, 0.5578, 0.5619, 0.5638, 0.5823, 0.5715, 0.5529, 0.5554,
        0.5629, 0.5667, 0.5639, 0.5621, 0.5571, 0.5798, 0.5669],
       device='cuda:0') torch.Size([16])
percent tensor([0.5163, 0.5169, 0.5090, 0.5151, 0.5064, 0.5247, 0.5104, 0.5077, 0.5101,
        0.5143, 0.5183, 0.5103, 0.5132, 0.5163, 0.5189, 0.5187],
       device='cuda:0') torch.Size([16])
percent tensor([0.5733, 0.4398, 0.6974, 0.7026, 0.7149, 0.6657, 0.5465, 0.6792, 0.6181,
        0.5165, 0.4770, 0.6259, 0.4724, 0.5224, 0.5255, 0.6179],
       device='cuda:0') torch.Size([16])
percent tensor([0.7159, 0.7425, 0.6275, 0.6559, 0.6398, 0.5519, 0.7185, 0.6627, 0.7279,
        0.7448, 0.7639, 0.7046, 0.7335, 0.7629, 0.6931, 0.6786],
       device='cuda:0') torch.Size([16])
percent tensor([0.7019, 0.5903, 0.7426, 0.7300, 0.7545, 0.7988, 0.6801, 0.7212, 0.6672,
        0.6013, 0.5712, 0.6159, 0.5742, 0.6107, 0.6791, 0.7535],
       device='cuda:0') torch.Size([16])
percent tensor([0.5839, 0.7409, 0.7190, 0.7667, 0.7356, 0.8094, 0.6809, 0.5276, 0.6876,
        0.6963, 0.7269, 0.7098, 0.6961, 0.7527, 0.5781, 0.5521],
       device='cuda:0') torch.Size([16])
percent tensor([0.4943, 0.7220, 0.6796, 0.7094, 0.6244, 0.6671, 0.6759, 0.5995, 0.7005,
        0.6690, 0.7320, 0.6925, 0.6339, 0.7288, 0.6247, 0.4363],
       device='cuda:0') torch.Size([16])
percent tensor([0.9997, 0.9997, 0.9996, 0.9999, 0.9999, 0.9995, 0.9999, 0.9998, 0.9997,
        0.9998, 0.9996, 0.9998, 0.9994, 0.9995, 0.9998, 0.9996],
       device='cuda:0') torch.Size([16])
Epoch: 143 | Batch_idx: 0 |  Loss: (0.1740) |  Loss2: (0.0000) | Acc: (95.00%) (122/128)
Epoch: 143 | Batch_idx: 10 |  Loss: (0.1354) |  Loss2: (0.0000) | Acc: (96.00%) (1352/1408)
Epoch: 143 | Batch_idx: 20 |  Loss: (0.1279) |  Loss2: (0.0000) | Acc: (96.00%) (2586/2688)
Epoch: 143 | Batch_idx: 30 |  Loss: (0.1268) |  Loss2: (0.0000) | Acc: (96.00%) (3813/3968)
Epoch: 143 | Batch_idx: 40 |  Loss: (0.1207) |  Loss2: (0.0000) | Acc: (96.00%) (5051/5248)
Epoch: 143 | Batch_idx: 50 |  Loss: (0.1241) |  Loss2: (0.0000) | Acc: (96.00%) (6267/6528)
Epoch: 143 | Batch_idx: 60 |  Loss: (0.1229) |  Loss2: (0.0000) | Acc: (96.00%) (7499/7808)
Epoch: 143 | Batch_idx: 70 |  Loss: (0.1223) |  Loss2: (0.0000) | Acc: (95.00%) (8722/9088)
Epoch: 143 | Batch_idx: 80 |  Loss: (0.1234) |  Loss2: (0.0000) | Acc: (95.00%) (9949/10368)
Epoch: 143 | Batch_idx: 90 |  Loss: (0.1238) |  Loss2: (0.0000) | Acc: (95.00%) (11171/11648)
Epoch: 143 | Batch_idx: 100 |  Loss: (0.1237) |  Loss2: (0.0000) | Acc: (95.00%) (12403/12928)
Epoch: 143 | Batch_idx: 110 |  Loss: (0.1249) |  Loss2: (0.0000) | Acc: (95.00%) (13612/14208)
Epoch: 143 | Batch_idx: 120 |  Loss: (0.1244) |  Loss2: (0.0000) | Acc: (95.00%) (14840/15488)
Epoch: 143 | Batch_idx: 130 |  Loss: (0.1254) |  Loss2: (0.0000) | Acc: (95.00%) (16056/16768)
Epoch: 143 | Batch_idx: 140 |  Loss: (0.1251) |  Loss2: (0.0000) | Acc: (95.00%) (17286/18048)
Epoch: 143 | Batch_idx: 150 |  Loss: (0.1252) |  Loss2: (0.0000) | Acc: (95.00%) (18514/19328)
Epoch: 143 | Batch_idx: 160 |  Loss: (0.1253) |  Loss2: (0.0000) | Acc: (95.00%) (19742/20608)
Epoch: 143 | Batch_idx: 170 |  Loss: (0.1246) |  Loss2: (0.0000) | Acc: (95.00%) (20972/21888)
Epoch: 143 | Batch_idx: 180 |  Loss: (0.1242) |  Loss2: (0.0000) | Acc: (95.00%) (22199/23168)
Epoch: 143 | Batch_idx: 190 |  Loss: (0.1243) |  Loss2: (0.0000) | Acc: (95.00%) (23417/24448)
Epoch: 143 | Batch_idx: 200 |  Loss: (0.1250) |  Loss2: (0.0000) | Acc: (95.00%) (24620/25728)
Epoch: 143 | Batch_idx: 210 |  Loss: (0.1252) |  Loss2: (0.0000) | Acc: (95.00%) (25836/27008)
Epoch: 143 | Batch_idx: 220 |  Loss: (0.1254) |  Loss2: (0.0000) | Acc: (95.00%) (27057/28288)
Epoch: 143 | Batch_idx: 230 |  Loss: (0.1260) |  Loss2: (0.0000) | Acc: (95.00%) (28266/29568)
Epoch: 143 | Batch_idx: 240 |  Loss: (0.1252) |  Loss2: (0.0000) | Acc: (95.00%) (29501/30848)
Epoch: 143 | Batch_idx: 250 |  Loss: (0.1248) |  Loss2: (0.0000) | Acc: (95.00%) (30728/32128)
Epoch: 143 | Batch_idx: 260 |  Loss: (0.1250) |  Loss2: (0.0000) | Acc: (95.00%) (31947/33408)
Epoch: 143 | Batch_idx: 270 |  Loss: (0.1251) |  Loss2: (0.0000) | Acc: (95.00%) (33168/34688)
Epoch: 143 | Batch_idx: 280 |  Loss: (0.1252) |  Loss2: (0.0000) | Acc: (95.00%) (34386/35968)
Epoch: 143 | Batch_idx: 290 |  Loss: (0.1255) |  Loss2: (0.0000) | Acc: (95.00%) (35613/37248)
Epoch: 143 | Batch_idx: 300 |  Loss: (0.1253) |  Loss2: (0.0000) | Acc: (95.00%) (36845/38528)
Epoch: 143 | Batch_idx: 310 |  Loss: (0.1251) |  Loss2: (0.0000) | Acc: (95.00%) (38071/39808)
Epoch: 143 | Batch_idx: 320 |  Loss: (0.1241) |  Loss2: (0.0000) | Acc: (95.00%) (39313/41088)
Epoch: 143 | Batch_idx: 330 |  Loss: (0.1245) |  Loss2: (0.0000) | Acc: (95.00%) (40528/42368)
Epoch: 143 | Batch_idx: 340 |  Loss: (0.1247) |  Loss2: (0.0000) | Acc: (95.00%) (41753/43648)
Epoch: 143 | Batch_idx: 350 |  Loss: (0.1248) |  Loss2: (0.0000) | Acc: (95.00%) (42970/44928)
Epoch: 143 | Batch_idx: 360 |  Loss: (0.1244) |  Loss2: (0.0000) | Acc: (95.00%) (44201/46208)
Epoch: 143 | Batch_idx: 370 |  Loss: (0.1241) |  Loss2: (0.0000) | Acc: (95.00%) (45435/47488)
Epoch: 143 | Batch_idx: 380 |  Loss: (0.1242) |  Loss2: (0.0000) | Acc: (95.00%) (46667/48768)
Epoch: 143 | Batch_idx: 390 |  Loss: (0.1244) |  Loss2: (0.0000) | Acc: (95.00%) (47837/50000)
# TEST : Loss: (0.3862) | Acc: (88.00%) (8881/10000)
percent tensor([0.5638, 0.5742, 0.5598, 0.5638, 0.5661, 0.5845, 0.5739, 0.5551, 0.5576,
        0.5652, 0.5691, 0.5663, 0.5644, 0.5590, 0.5823, 0.5690],
       device='cuda:0') torch.Size([16])
percent tensor([0.5151, 0.5157, 0.5075, 0.5143, 0.5045, 0.5243, 0.5089, 0.5061, 0.5086,
        0.5131, 0.5173, 0.5088, 0.5119, 0.5154, 0.5178, 0.5178],
       device='cuda:0') torch.Size([16])
percent tensor([0.5682, 0.4338, 0.6991, 0.7037, 0.7161, 0.6612, 0.5448, 0.6803, 0.6173,
        0.5131, 0.4722, 0.6273, 0.4667, 0.5198, 0.5189, 0.6125],
       device='cuda:0') torch.Size([16])
percent tensor([0.7095, 0.7339, 0.6236, 0.6528, 0.6359, 0.5482, 0.7119, 0.6575, 0.7210,
        0.7364, 0.7560, 0.6974, 0.7251, 0.7557, 0.6858, 0.6719],
       device='cuda:0') torch.Size([16])
percent tensor([0.7096, 0.6036, 0.7468, 0.7340, 0.7581, 0.8037, 0.6891, 0.7254, 0.6741,
        0.6121, 0.5813, 0.6270, 0.5858, 0.6183, 0.6910, 0.7594],
       device='cuda:0') torch.Size([16])
percent tensor([0.5722, 0.7343, 0.7012, 0.7509, 0.7184, 0.8034, 0.6680, 0.5004, 0.6770,
        0.6854, 0.7190, 0.6978, 0.6887, 0.7446, 0.5587, 0.5402],
       device='cuda:0') torch.Size([16])
percent tensor([0.4994, 0.7229, 0.6774, 0.7073, 0.6228, 0.6680, 0.6828, 0.6027, 0.6995,
        0.6618, 0.7304, 0.6949, 0.6308, 0.7315, 0.6254, 0.4456],
       device='cuda:0') torch.Size([16])
percent tensor([0.9997, 0.9997, 0.9996, 0.9999, 0.9999, 0.9996, 0.9999, 0.9998, 0.9997,
        0.9998, 0.9996, 0.9998, 0.9994, 0.9995, 0.9998, 0.9996],
       device='cuda:0') torch.Size([16])
True Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=128, out_features=16, bias=False)
False Linear(in_features=16, out_features=2, bias=False)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=128, out_features=16, bias=False)
False Linear(in_features=16, out_features=2, bias=False)
True Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=256, out_features=32, bias=False)
False Linear(in_features=32, out_features=2, bias=False)
True Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=256, out_features=32, bias=False)
False Linear(in_features=32, out_features=2, bias=False)
True Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=512, out_features=64, bias=False)
False Linear(in_features=64, out_features=2, bias=False)
True Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=512, out_features=64, bias=False)
False Linear(in_features=64, out_features=2, bias=False)
True Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1024, out_features=128, bias=False)
False Linear(in_features=128, out_features=2, bias=False)
True Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1024, out_features=128, bias=False)
False Linear(in_features=128, out_features=2, bias=False)
True Linear(in_features=512, out_features=10, bias=True)
Epoch: 144 | Batch_idx: 0 |  Loss: (0.1261) |  Loss2: (0.0000) | Acc: (95.00%) (122/128)
Epoch: 144 | Batch_idx: 10 |  Loss: (0.1195) |  Loss2: (0.0000) | Acc: (95.00%) (1351/1408)
Epoch: 144 | Batch_idx: 20 |  Loss: (0.1295) |  Loss2: (0.0000) | Acc: (95.00%) (2573/2688)
Epoch: 144 | Batch_idx: 30 |  Loss: (0.1243) |  Loss2: (0.0000) | Acc: (95.00%) (3804/3968)
Epoch: 144 | Batch_idx: 40 |  Loss: (0.1247) |  Loss2: (0.0000) | Acc: (95.00%) (5032/5248)
Epoch: 144 | Batch_idx: 50 |  Loss: (0.1287) |  Loss2: (0.0000) | Acc: (95.00%) (6245/6528)
Epoch: 144 | Batch_idx: 60 |  Loss: (0.1301) |  Loss2: (0.0000) | Acc: (95.00%) (7469/7808)
Epoch: 144 | Batch_idx: 70 |  Loss: (0.1282) |  Loss2: (0.0000) | Acc: (95.00%) (8697/9088)
Epoch: 144 | Batch_idx: 80 |  Loss: (0.1286) |  Loss2: (0.0000) | Acc: (95.00%) (9911/10368)
Epoch: 144 | Batch_idx: 90 |  Loss: (0.1287) |  Loss2: (0.0000) | Acc: (95.00%) (11133/11648)
Epoch: 144 | Batch_idx: 100 |  Loss: (0.1300) |  Loss2: (0.0000) | Acc: (95.00%) (12344/12928)
Epoch: 144 | Batch_idx: 110 |  Loss: (0.1289) |  Loss2: (0.0000) | Acc: (95.00%) (13578/14208)
Epoch: 144 | Batch_idx: 120 |  Loss: (0.1291) |  Loss2: (0.0000) | Acc: (95.00%) (14793/15488)
Epoch: 144 | Batch_idx: 130 |  Loss: (0.1292) |  Loss2: (0.0000) | Acc: (95.00%) (16017/16768)
Epoch: 144 | Batch_idx: 140 |  Loss: (0.1322) |  Loss2: (0.0000) | Acc: (95.00%) (17228/18048)
Epoch: 144 | Batch_idx: 150 |  Loss: (0.1326) |  Loss2: (0.0000) | Acc: (95.00%) (18449/19328)
Epoch: 144 | Batch_idx: 160 |  Loss: (0.1345) |  Loss2: (0.0000) | Acc: (95.00%) (19656/20608)
Epoch: 144 | Batch_idx: 170 |  Loss: (0.1339) |  Loss2: (0.0000) | Acc: (95.00%) (20879/21888)
Epoch: 144 | Batch_idx: 180 |  Loss: (0.1337) |  Loss2: (0.0000) | Acc: (95.00%) (22099/23168)
Epoch: 144 | Batch_idx: 190 |  Loss: (0.1353) |  Loss2: (0.0000) | Acc: (95.00%) (23295/24448)
Epoch: 144 | Batch_idx: 200 |  Loss: (0.1352) |  Loss2: (0.0000) | Acc: (95.00%) (24510/25728)
Epoch: 144 | Batch_idx: 210 |  Loss: (0.1352) |  Loss2: (0.0000) | Acc: (95.00%) (25737/27008)
Epoch: 144 | Batch_idx: 220 |  Loss: (0.1362) |  Loss2: (0.0000) | Acc: (95.00%) (26948/28288)
Epoch: 144 | Batch_idx: 230 |  Loss: (0.1361) |  Loss2: (0.0000) | Acc: (95.00%) (28171/29568)
Epoch: 144 | Batch_idx: 240 |  Loss: (0.1362) |  Loss2: (0.0000) | Acc: (95.00%) (29394/30848)
Epoch: 144 | Batch_idx: 250 |  Loss: (0.1365) |  Loss2: (0.0000) | Acc: (95.00%) (30608/32128)
Epoch: 144 | Batch_idx: 260 |  Loss: (0.1360) |  Loss2: (0.0000) | Acc: (95.00%) (31828/33408)
Epoch: 144 | Batch_idx: 270 |  Loss: (0.1363) |  Loss2: (0.0000) | Acc: (95.00%) (33046/34688)
Epoch: 144 | Batch_idx: 280 |  Loss: (0.1370) |  Loss2: (0.0000) | Acc: (95.00%) (34251/35968)
Epoch: 144 | Batch_idx: 290 |  Loss: (0.1362) |  Loss2: (0.0000) | Acc: (95.00%) (35474/37248)
Epoch: 144 | Batch_idx: 300 |  Loss: (0.1367) |  Loss2: (0.0000) | Acc: (95.00%) (36690/38528)
Epoch: 144 | Batch_idx: 310 |  Loss: (0.1372) |  Loss2: (0.0000) | Acc: (95.00%) (37903/39808)
Epoch: 144 | Batch_idx: 320 |  Loss: (0.1380) |  Loss2: (0.0000) | Acc: (95.00%) (39104/41088)
Epoch: 144 | Batch_idx: 330 |  Loss: (0.1380) |  Loss2: (0.0000) | Acc: (95.00%) (40319/42368)
Epoch: 144 | Batch_idx: 340 |  Loss: (0.1382) |  Loss2: (0.0000) | Acc: (95.00%) (41534/43648)
Epoch: 144 | Batch_idx: 350 |  Loss: (0.1379) |  Loss2: (0.0000) | Acc: (95.00%) (42754/44928)
Epoch: 144 | Batch_idx: 360 |  Loss: (0.1375) |  Loss2: (0.0000) | Acc: (95.00%) (43978/46208)
Epoch: 144 | Batch_idx: 370 |  Loss: (0.1369) |  Loss2: (0.0000) | Acc: (95.00%) (45214/47488)
Epoch: 144 | Batch_idx: 380 |  Loss: (0.1368) |  Loss2: (0.0000) | Acc: (95.00%) (46435/48768)
Epoch: 144 | Batch_idx: 390 |  Loss: (0.1366) |  Loss2: (0.0000) | Acc: (95.00%) (47608/50000)
# TEST : Loss: (0.4445) | Acc: (87.00%) (8741/10000)
percent tensor([0.5632, 0.5728, 0.5632, 0.5651, 0.5685, 0.5836, 0.5730, 0.5558, 0.5572,
        0.5655, 0.5680, 0.5683, 0.5638, 0.5573, 0.5815, 0.5685],
       device='cuda:0') torch.Size([16])
percent tensor([0.5167, 0.5154, 0.5078, 0.5156, 0.5062, 0.5256, 0.5095, 0.5068, 0.5095,
        0.5134, 0.5178, 0.5102, 0.5128, 0.5150, 0.5190, 0.5188],
       device='cuda:0') torch.Size([16])
percent tensor([0.5631, 0.4252, 0.6921, 0.6845, 0.7065, 0.6334, 0.5363, 0.6768, 0.6086,
        0.5035, 0.4629, 0.6095, 0.4693, 0.5095, 0.4965, 0.5939],
       device='cuda:0') torch.Size([16])
percent tensor([0.7088, 0.7336, 0.6346, 0.6621, 0.6386, 0.5573, 0.7053, 0.6651, 0.7180,
        0.7345, 0.7571, 0.7004, 0.7217, 0.7527, 0.6889, 0.6714],
       device='cuda:0') torch.Size([16])
percent tensor([0.7145, 0.6114, 0.7527, 0.7251, 0.7678, 0.7990, 0.7059, 0.7331, 0.6827,
        0.6214, 0.5834, 0.6307, 0.6016, 0.6284, 0.6922, 0.7544],
       device='cuda:0') torch.Size([16])
percent tensor([0.5788, 0.7147, 0.6963, 0.7623, 0.7097, 0.7960, 0.6781, 0.5027, 0.6911,
        0.6571, 0.7258, 0.7014, 0.6942, 0.7320, 0.5509, 0.5506],
       device='cuda:0') torch.Size([16])
percent tensor([0.5327, 0.7426, 0.6808, 0.7093, 0.6247, 0.6605, 0.6966, 0.6102, 0.6963,
        0.6540, 0.7423, 0.7044, 0.6502, 0.7465, 0.6235, 0.4603],
       device='cuda:0') torch.Size([16])
percent tensor([0.9998, 0.9998, 0.9997, 0.9999, 0.9999, 0.9996, 0.9998, 0.9998, 0.9998,
        0.9998, 0.9997, 0.9998, 0.9997, 0.9997, 0.9997, 0.9996],
       device='cuda:0') torch.Size([16])
Epoch: 145 | Batch_idx: 0 |  Loss: (0.1392) |  Loss2: (0.0000) | Acc: (94.00%) (121/128)
Epoch: 145 | Batch_idx: 10 |  Loss: (0.1245) |  Loss2: (0.0000) | Acc: (96.00%) (1352/1408)
Epoch: 145 | Batch_idx: 20 |  Loss: (0.1253) |  Loss2: (0.0000) | Acc: (95.00%) (2580/2688)
Epoch: 145 | Batch_idx: 30 |  Loss: (0.1255) |  Loss2: (0.0000) | Acc: (95.00%) (3806/3968)
Epoch: 145 | Batch_idx: 40 |  Loss: (0.1269) |  Loss2: (0.0000) | Acc: (95.00%) (5027/5248)
Epoch: 145 | Batch_idx: 50 |  Loss: (0.1265) |  Loss2: (0.0000) | Acc: (95.00%) (6254/6528)
Epoch: 145 | Batch_idx: 60 |  Loss: (0.1252) |  Loss2: (0.0000) | Acc: (95.00%) (7483/7808)
Epoch: 145 | Batch_idx: 70 |  Loss: (0.1266) |  Loss2: (0.0000) | Acc: (95.00%) (8703/9088)
Epoch: 145 | Batch_idx: 80 |  Loss: (0.1269) |  Loss2: (0.0000) | Acc: (95.00%) (9929/10368)
Epoch: 145 | Batch_idx: 90 |  Loss: (0.1271) |  Loss2: (0.0000) | Acc: (95.00%) (11149/11648)
Epoch: 145 | Batch_idx: 100 |  Loss: (0.1272) |  Loss2: (0.0000) | Acc: (95.00%) (12372/12928)
Epoch: 145 | Batch_idx: 110 |  Loss: (0.1279) |  Loss2: (0.0000) | Acc: (95.00%) (13591/14208)
Epoch: 145 | Batch_idx: 120 |  Loss: (0.1284) |  Loss2: (0.0000) | Acc: (95.00%) (14812/15488)
Epoch: 145 | Batch_idx: 130 |  Loss: (0.1253) |  Loss2: (0.0000) | Acc: (95.00%) (16059/16768)
Epoch: 145 | Batch_idx: 140 |  Loss: (0.1250) |  Loss2: (0.0000) | Acc: (95.00%) (17291/18048)
Epoch: 145 | Batch_idx: 150 |  Loss: (0.1256) |  Loss2: (0.0000) | Acc: (95.00%) (18508/19328)
Epoch: 145 | Batch_idx: 160 |  Loss: (0.1276) |  Loss2: (0.0000) | Acc: (95.00%) (19720/20608)
Epoch: 145 | Batch_idx: 170 |  Loss: (0.1266) |  Loss2: (0.0000) | Acc: (95.00%) (20956/21888)
Epoch: 145 | Batch_idx: 180 |  Loss: (0.1275) |  Loss2: (0.0000) | Acc: (95.00%) (22175/23168)
Epoch: 145 | Batch_idx: 190 |  Loss: (0.1267) |  Loss2: (0.0000) | Acc: (95.00%) (23413/24448)
Epoch: 145 | Batch_idx: 200 |  Loss: (0.1266) |  Loss2: (0.0000) | Acc: (95.00%) (24638/25728)
Epoch: 145 | Batch_idx: 210 |  Loss: (0.1270) |  Loss2: (0.0000) | Acc: (95.00%) (25851/27008)
Epoch: 145 | Batch_idx: 220 |  Loss: (0.1278) |  Loss2: (0.0000) | Acc: (95.00%) (27073/28288)
Epoch: 145 | Batch_idx: 230 |  Loss: (0.1281) |  Loss2: (0.0000) | Acc: (95.00%) (28299/29568)
Epoch: 145 | Batch_idx: 240 |  Loss: (0.1285) |  Loss2: (0.0000) | Acc: (95.00%) (29515/30848)
Epoch: 145 | Batch_idx: 250 |  Loss: (0.1290) |  Loss2: (0.0000) | Acc: (95.00%) (30743/32128)
Epoch: 145 | Batch_idx: 260 |  Loss: (0.1286) |  Loss2: (0.0000) | Acc: (95.00%) (31972/33408)
Epoch: 145 | Batch_idx: 270 |  Loss: (0.1292) |  Loss2: (0.0000) | Acc: (95.00%) (33186/34688)
Epoch: 145 | Batch_idx: 280 |  Loss: (0.1295) |  Loss2: (0.0000) | Acc: (95.00%) (34406/35968)
Epoch: 145 | Batch_idx: 290 |  Loss: (0.1293) |  Loss2: (0.0000) | Acc: (95.00%) (35628/37248)
Epoch: 145 | Batch_idx: 300 |  Loss: (0.1293) |  Loss2: (0.0000) | Acc: (95.00%) (36856/38528)
Epoch: 145 | Batch_idx: 310 |  Loss: (0.1293) |  Loss2: (0.0000) | Acc: (95.00%) (38081/39808)
Epoch: 145 | Batch_idx: 320 |  Loss: (0.1289) |  Loss2: (0.0000) | Acc: (95.00%) (39312/41088)
Epoch: 145 | Batch_idx: 330 |  Loss: (0.1289) |  Loss2: (0.0000) | Acc: (95.00%) (40533/42368)
Epoch: 145 | Batch_idx: 340 |  Loss: (0.1284) |  Loss2: (0.0000) | Acc: (95.00%) (41765/43648)
Epoch: 145 | Batch_idx: 350 |  Loss: (0.1281) |  Loss2: (0.0000) | Acc: (95.00%) (42986/44928)
Epoch: 145 | Batch_idx: 360 |  Loss: (0.1283) |  Loss2: (0.0000) | Acc: (95.00%) (44209/46208)
Epoch: 145 | Batch_idx: 370 |  Loss: (0.1283) |  Loss2: (0.0000) | Acc: (95.00%) (45431/47488)
Epoch: 145 | Batch_idx: 380 |  Loss: (0.1281) |  Loss2: (0.0000) | Acc: (95.00%) (46658/48768)
Epoch: 145 | Batch_idx: 390 |  Loss: (0.1288) |  Loss2: (0.0000) | Acc: (95.00%) (47826/50000)
=> saving checkpoint 'drive/app/torch/save_Schedule/checkpoint_145.pth.tar'
# TEST : Loss: (0.4488) | Acc: (86.00%) (8696/10000)
percent tensor([0.5636, 0.5729, 0.5631, 0.5645, 0.5675, 0.5827, 0.5733, 0.5565, 0.5581,
        0.5656, 0.5689, 0.5680, 0.5643, 0.5575, 0.5812, 0.5684],
       device='cuda:0') torch.Size([16])
percent tensor([0.5157, 0.5155, 0.5076, 0.5140, 0.5052, 0.5239, 0.5090, 0.5067, 0.5095,
        0.5130, 0.5173, 0.5092, 0.5123, 0.5148, 0.5178, 0.5173],
       device='cuda:0') torch.Size([16])
percent tensor([0.5719, 0.4297, 0.7088, 0.7054, 0.7172, 0.6464, 0.5580, 0.6852, 0.6141,
        0.5142, 0.4598, 0.6370, 0.4740, 0.5237, 0.5127, 0.6101],
       device='cuda:0') torch.Size([16])
percent tensor([0.7087, 0.7311, 0.6267, 0.6515, 0.6322, 0.5512, 0.7024, 0.6535, 0.7113,
        0.7364, 0.7546, 0.6991, 0.7181, 0.7514, 0.6824, 0.6726],
       device='cuda:0') torch.Size([16])
percent tensor([0.7122, 0.6091, 0.7463, 0.7219, 0.7589, 0.8009, 0.7028, 0.7330, 0.6720,
        0.6053, 0.5725, 0.6200, 0.5922, 0.6273, 0.6952, 0.7523],
       device='cuda:0') torch.Size([16])
percent tensor([0.5499, 0.7142, 0.6997, 0.7728, 0.7173, 0.8084, 0.6447, 0.4765, 0.6813,
        0.6624, 0.7098, 0.6932, 0.6900, 0.7245, 0.5464, 0.5316],
       device='cuda:0') torch.Size([16])
percent tensor([0.4850, 0.7062, 0.6501, 0.6828, 0.6014, 0.6520, 0.6418, 0.5731, 0.6797,
        0.6345, 0.7349, 0.6728, 0.6174, 0.7123, 0.6017, 0.4339],
       device='cuda:0') torch.Size([16])
percent tensor([0.9998, 0.9997, 0.9997, 0.9999, 0.9999, 0.9995, 0.9998, 0.9996, 0.9995,
        0.9998, 0.9994, 0.9999, 0.9993, 0.9995, 0.9997, 0.9996],
       device='cuda:0') torch.Size([16])
Epoch: 146 | Batch_idx: 0 |  Loss: (0.1619) |  Loss2: (0.0000) | Acc: (94.00%) (121/128)
Epoch: 146 | Batch_idx: 10 |  Loss: (0.1219) |  Loss2: (0.0000) | Acc: (95.00%) (1348/1408)
Epoch: 146 | Batch_idx: 20 |  Loss: (0.1215) |  Loss2: (0.0000) | Acc: (95.00%) (2570/2688)
Epoch: 146 | Batch_idx: 30 |  Loss: (0.1188) |  Loss2: (0.0000) | Acc: (95.00%) (3798/3968)
Epoch: 146 | Batch_idx: 40 |  Loss: (0.1260) |  Loss2: (0.0000) | Acc: (95.00%) (5009/5248)
Epoch: 146 | Batch_idx: 50 |  Loss: (0.1225) |  Loss2: (0.0000) | Acc: (95.00%) (6244/6528)
Epoch: 146 | Batch_idx: 60 |  Loss: (0.1229) |  Loss2: (0.0000) | Acc: (95.00%) (7465/7808)
Epoch: 146 | Batch_idx: 70 |  Loss: (0.1233) |  Loss2: (0.0000) | Acc: (95.00%) (8699/9088)
Epoch: 146 | Batch_idx: 80 |  Loss: (0.1244) |  Loss2: (0.0000) | Acc: (95.00%) (9917/10368)
Epoch: 146 | Batch_idx: 90 |  Loss: (0.1215) |  Loss2: (0.0000) | Acc: (95.00%) (11156/11648)
Epoch: 146 | Batch_idx: 100 |  Loss: (0.1216) |  Loss2: (0.0000) | Acc: (95.00%) (12385/12928)
Epoch: 146 | Batch_idx: 110 |  Loss: (0.1215) |  Loss2: (0.0000) | Acc: (95.00%) (13615/14208)
Epoch: 146 | Batch_idx: 120 |  Loss: (0.1213) |  Loss2: (0.0000) | Acc: (95.00%) (14847/15488)
Epoch: 146 | Batch_idx: 130 |  Loss: (0.1211) |  Loss2: (0.0000) | Acc: (95.00%) (16067/16768)
Epoch: 146 | Batch_idx: 140 |  Loss: (0.1206) |  Loss2: (0.0000) | Acc: (95.00%) (17291/18048)
Epoch: 146 | Batch_idx: 150 |  Loss: (0.1210) |  Loss2: (0.0000) | Acc: (95.00%) (18513/19328)
Epoch: 146 | Batch_idx: 160 |  Loss: (0.1214) |  Loss2: (0.0000) | Acc: (95.00%) (19733/20608)
Epoch: 146 | Batch_idx: 170 |  Loss: (0.1219) |  Loss2: (0.0000) | Acc: (95.00%) (20954/21888)
Epoch: 146 | Batch_idx: 180 |  Loss: (0.1228) |  Loss2: (0.0000) | Acc: (95.00%) (22178/23168)
Epoch: 146 | Batch_idx: 190 |  Loss: (0.1224) |  Loss2: (0.0000) | Acc: (95.00%) (23407/24448)
Epoch: 146 | Batch_idx: 200 |  Loss: (0.1226) |  Loss2: (0.0000) | Acc: (95.00%) (24630/25728)
Epoch: 146 | Batch_idx: 210 |  Loss: (0.1239) |  Loss2: (0.0000) | Acc: (95.00%) (25833/27008)
Epoch: 146 | Batch_idx: 220 |  Loss: (0.1247) |  Loss2: (0.0000) | Acc: (95.00%) (27052/28288)
Epoch: 146 | Batch_idx: 230 |  Loss: (0.1250) |  Loss2: (0.0000) | Acc: (95.00%) (28271/29568)
Epoch: 146 | Batch_idx: 240 |  Loss: (0.1252) |  Loss2: (0.0000) | Acc: (95.00%) (29504/30848)
Epoch: 146 | Batch_idx: 250 |  Loss: (0.1250) |  Loss2: (0.0000) | Acc: (95.00%) (30728/32128)
Epoch: 146 | Batch_idx: 260 |  Loss: (0.1253) |  Loss2: (0.0000) | Acc: (95.00%) (31949/33408)
Epoch: 146 | Batch_idx: 270 |  Loss: (0.1256) |  Loss2: (0.0000) | Acc: (95.00%) (33165/34688)
Epoch: 146 | Batch_idx: 280 |  Loss: (0.1260) |  Loss2: (0.0000) | Acc: (95.00%) (34385/35968)
Epoch: 146 | Batch_idx: 290 |  Loss: (0.1258) |  Loss2: (0.0000) | Acc: (95.00%) (35612/37248)
Epoch: 146 | Batch_idx: 300 |  Loss: (0.1261) |  Loss2: (0.0000) | Acc: (95.00%) (36831/38528)
Epoch: 146 | Batch_idx: 310 |  Loss: (0.1260) |  Loss2: (0.0000) | Acc: (95.00%) (38059/39808)
Epoch: 146 | Batch_idx: 320 |  Loss: (0.1261) |  Loss2: (0.0000) | Acc: (95.00%) (39276/41088)
Epoch: 146 | Batch_idx: 330 |  Loss: (0.1268) |  Loss2: (0.0000) | Acc: (95.00%) (40485/42368)
Epoch: 146 | Batch_idx: 340 |  Loss: (0.1272) |  Loss2: (0.0000) | Acc: (95.00%) (41702/43648)
Epoch: 146 | Batch_idx: 350 |  Loss: (0.1271) |  Loss2: (0.0000) | Acc: (95.00%) (42933/44928)
Epoch: 146 | Batch_idx: 360 |  Loss: (0.1276) |  Loss2: (0.0000) | Acc: (95.00%) (44155/46208)
Epoch: 146 | Batch_idx: 370 |  Loss: (0.1275) |  Loss2: (0.0000) | Acc: (95.00%) (45380/47488)
Epoch: 146 | Batch_idx: 380 |  Loss: (0.1272) |  Loss2: (0.0000) | Acc: (95.00%) (46604/48768)
Epoch: 146 | Batch_idx: 390 |  Loss: (0.1275) |  Loss2: (0.0000) | Acc: (95.00%) (47775/50000)
# TEST : Loss: (0.4256) | Acc: (87.00%) (8775/10000)
percent tensor([0.5643, 0.5729, 0.5623, 0.5638, 0.5665, 0.5845, 0.5727, 0.5556, 0.5586,
        0.5653, 0.5696, 0.5673, 0.5643, 0.5577, 0.5813, 0.5691],
       device='cuda:0') torch.Size([16])
percent tensor([0.5164, 0.5160, 0.5087, 0.5159, 0.5073, 0.5256, 0.5098, 0.5080, 0.5095,
        0.5137, 0.5183, 0.5102, 0.5130, 0.5141, 0.5194, 0.5190],
       device='cuda:0') torch.Size([16])
percent tensor([0.5678, 0.4196, 0.7012, 0.6950, 0.7106, 0.6501, 0.5352, 0.6822, 0.5984,
        0.5026, 0.4507, 0.6240, 0.4668, 0.4870, 0.5056, 0.6000],
       device='cuda:0') torch.Size([16])
percent tensor([0.7035, 0.7280, 0.6237, 0.6392, 0.6275, 0.5448, 0.7020, 0.6519, 0.7141,
        0.7341, 0.7527, 0.6991, 0.7147, 0.7479, 0.6753, 0.6649],
       device='cuda:0') torch.Size([16])
percent tensor([0.7197, 0.6211, 0.7482, 0.7436, 0.7614, 0.8014, 0.7067, 0.7260, 0.6756,
        0.6149, 0.5878, 0.6190, 0.5998, 0.6455, 0.7070, 0.7613],
       device='cuda:0') torch.Size([16])
percent tensor([0.5944, 0.7287, 0.7145, 0.7691, 0.7463, 0.7998, 0.6634, 0.5317, 0.6973,
        0.6795, 0.7324, 0.6992, 0.7243, 0.7456, 0.5492, 0.5661],
       device='cuda:0') torch.Size([16])
percent tensor([0.5077, 0.7285, 0.6500, 0.6826, 0.6232, 0.6367, 0.6828, 0.5904, 0.6758,
        0.6579, 0.7454, 0.6922, 0.6377, 0.7309, 0.5975, 0.4424],
       device='cuda:0') torch.Size([16])
percent tensor([0.9998, 0.9997, 0.9997, 0.9999, 0.9999, 0.9994, 0.9997, 0.9997, 0.9998,
        0.9999, 0.9996, 0.9999, 0.9996, 0.9992, 0.9998, 0.9995],
       device='cuda:0') torch.Size([16])
False Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=128, out_features=16, bias=False)
True Linear(in_features=16, out_features=2, bias=False)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=128, out_features=16, bias=False)
True Linear(in_features=16, out_features=2, bias=False)
False Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=256, out_features=32, bias=False)
True Linear(in_features=32, out_features=2, bias=False)
False Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=256, out_features=32, bias=False)
True Linear(in_features=32, out_features=2, bias=False)
False Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=512, out_features=64, bias=False)
True Linear(in_features=64, out_features=2, bias=False)
False Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=512, out_features=64, bias=False)
True Linear(in_features=64, out_features=2, bias=False)
False Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1024, out_features=128, bias=False)
True Linear(in_features=128, out_features=2, bias=False)
False Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1024, out_features=128, bias=False)
True Linear(in_features=128, out_features=2, bias=False)
False Linear(in_features=512, out_features=10, bias=True)
Epoch: 147 | Batch_idx: 0 |  Loss: (0.1844) |  Loss2: (0.0000) | Acc: (93.00%) (120/128)
Epoch: 147 | Batch_idx: 10 |  Loss: (0.1487) |  Loss2: (0.0000) | Acc: (94.00%) (1330/1408)
Epoch: 147 | Batch_idx: 20 |  Loss: (0.1477) |  Loss2: (0.0000) | Acc: (94.00%) (2541/2688)
Epoch: 147 | Batch_idx: 30 |  Loss: (0.1609) |  Loss2: (0.0000) | Acc: (93.00%) (3727/3968)
Epoch: 147 | Batch_idx: 40 |  Loss: (0.1658) |  Loss2: (0.0000) | Acc: (93.00%) (4925/5248)
Epoch: 147 | Batch_idx: 50 |  Loss: (0.1700) |  Loss2: (0.0000) | Acc: (93.00%) (6119/6528)
Epoch: 147 | Batch_idx: 60 |  Loss: (0.1739) |  Loss2: (0.0000) | Acc: (93.00%) (7306/7808)
Epoch: 147 | Batch_idx: 70 |  Loss: (0.1723) |  Loss2: (0.0000) | Acc: (93.00%) (8512/9088)
Epoch: 147 | Batch_idx: 80 |  Loss: (0.1721) |  Loss2: (0.0000) | Acc: (93.00%) (9712/10368)
Epoch: 147 | Batch_idx: 90 |  Loss: (0.1714) |  Loss2: (0.0000) | Acc: (93.00%) (10911/11648)
Epoch: 147 | Batch_idx: 100 |  Loss: (0.1760) |  Loss2: (0.0000) | Acc: (93.00%) (12100/12928)
Epoch: 147 | Batch_idx: 110 |  Loss: (0.1760) |  Loss2: (0.0000) | Acc: (93.00%) (13303/14208)
Epoch: 147 | Batch_idx: 120 |  Loss: (0.1757) |  Loss2: (0.0000) | Acc: (93.00%) (14499/15488)
Epoch: 147 | Batch_idx: 130 |  Loss: (0.1775) |  Loss2: (0.0000) | Acc: (93.00%) (15691/16768)
Epoch: 147 | Batch_idx: 140 |  Loss: (0.1778) |  Loss2: (0.0000) | Acc: (93.00%) (16880/18048)
Epoch: 147 | Batch_idx: 150 |  Loss: (0.1777) |  Loss2: (0.0000) | Acc: (93.00%) (18089/19328)
Epoch: 147 | Batch_idx: 160 |  Loss: (0.1774) |  Loss2: (0.0000) | Acc: (93.00%) (19285/20608)
Epoch: 147 | Batch_idx: 170 |  Loss: (0.1770) |  Loss2: (0.0000) | Acc: (93.00%) (20483/21888)
Epoch: 147 | Batch_idx: 180 |  Loss: (0.1759) |  Loss2: (0.0000) | Acc: (93.00%) (21688/23168)
Epoch: 147 | Batch_idx: 190 |  Loss: (0.1752) |  Loss2: (0.0000) | Acc: (93.00%) (22898/24448)
Epoch: 147 | Batch_idx: 200 |  Loss: (0.1746) |  Loss2: (0.0000) | Acc: (93.00%) (24107/25728)
Epoch: 147 | Batch_idx: 210 |  Loss: (0.1734) |  Loss2: (0.0000) | Acc: (93.00%) (25317/27008)
Epoch: 147 | Batch_idx: 220 |  Loss: (0.1730) |  Loss2: (0.0000) | Acc: (93.00%) (26525/28288)
Epoch: 147 | Batch_idx: 230 |  Loss: (0.1737) |  Loss2: (0.0000) | Acc: (93.00%) (27729/29568)
Epoch: 147 | Batch_idx: 240 |  Loss: (0.1725) |  Loss2: (0.0000) | Acc: (93.00%) (28939/30848)
Epoch: 147 | Batch_idx: 250 |  Loss: (0.1716) |  Loss2: (0.0000) | Acc: (93.00%) (30151/32128)
Epoch: 147 | Batch_idx: 260 |  Loss: (0.1713) |  Loss2: (0.0000) | Acc: (93.00%) (31351/33408)
Epoch: 147 | Batch_idx: 270 |  Loss: (0.1715) |  Loss2: (0.0000) | Acc: (93.00%) (32555/34688)
Epoch: 147 | Batch_idx: 280 |  Loss: (0.1705) |  Loss2: (0.0000) | Acc: (93.00%) (33776/35968)
Epoch: 147 | Batch_idx: 290 |  Loss: (0.1705) |  Loss2: (0.0000) | Acc: (93.00%) (34969/37248)
Epoch: 147 | Batch_idx: 300 |  Loss: (0.1697) |  Loss2: (0.0000) | Acc: (93.00%) (36190/38528)
Epoch: 147 | Batch_idx: 310 |  Loss: (0.1695) |  Loss2: (0.0000) | Acc: (93.00%) (37389/39808)
Epoch: 147 | Batch_idx: 320 |  Loss: (0.1684) |  Loss2: (0.0000) | Acc: (93.00%) (38609/41088)
Epoch: 147 | Batch_idx: 330 |  Loss: (0.1682) |  Loss2: (0.0000) | Acc: (93.00%) (39814/42368)
Epoch: 147 | Batch_idx: 340 |  Loss: (0.1672) |  Loss2: (0.0000) | Acc: (94.00%) (41035/43648)
Epoch: 147 | Batch_idx: 350 |  Loss: (0.1670) |  Loss2: (0.0000) | Acc: (94.00%) (42239/44928)
Epoch: 147 | Batch_idx: 360 |  Loss: (0.1667) |  Loss2: (0.0000) | Acc: (94.00%) (43444/46208)
Epoch: 147 | Batch_idx: 370 |  Loss: (0.1661) |  Loss2: (0.0000) | Acc: (94.00%) (44651/47488)
Epoch: 147 | Batch_idx: 380 |  Loss: (0.1663) |  Loss2: (0.0000) | Acc: (94.00%) (45853/48768)
Epoch: 147 | Batch_idx: 390 |  Loss: (0.1660) |  Loss2: (0.0000) | Acc: (94.00%) (47023/50000)
# TEST : Loss: (0.4147) | Acc: (87.00%) (8783/10000)
percent tensor([0.5794, 0.5906, 0.5773, 0.5790, 0.5821, 0.5996, 0.5903, 0.5717, 0.5745,
        0.5824, 0.5859, 0.5832, 0.5801, 0.5738, 0.5974, 0.5846],
       device='cuda:0') torch.Size([16])
percent tensor([0.5200, 0.5207, 0.5120, 0.5189, 0.5122, 0.5281, 0.5149, 0.5128, 0.5136,
        0.5177, 0.5221, 0.5138, 0.5168, 0.5188, 0.5235, 0.5220],
       device='cuda:0') torch.Size([16])
percent tensor([0.5793, 0.4233, 0.7221, 0.7267, 0.7369, 0.6759, 0.5529, 0.7045, 0.6210,
        0.5149, 0.4570, 0.6391, 0.4699, 0.5075, 0.5166, 0.6224],
       device='cuda:0') torch.Size([16])
percent tensor([0.6972, 0.7272, 0.6270, 0.6419, 0.6310, 0.5444, 0.6973, 0.6478, 0.7094,
        0.7313, 0.7470, 0.7005, 0.7099, 0.7447, 0.6759, 0.6620],
       device='cuda:0') torch.Size([16])
percent tensor([0.7003, 0.6031, 0.7201, 0.7115, 0.7382, 0.7748, 0.6908, 0.7017, 0.6640,
        0.6047, 0.5851, 0.6030, 0.5875, 0.6418, 0.6813, 0.7417],
       device='cuda:0') torch.Size([16])
percent tensor([0.6106, 0.7462, 0.7328, 0.7870, 0.7545, 0.7945, 0.6852, 0.5646, 0.7131,
        0.6846, 0.7501, 0.7164, 0.7436, 0.7457, 0.5538, 0.5423],
       device='cuda:0') torch.Size([16])
percent tensor([0.4636, 0.6712, 0.6276, 0.6541, 0.6054, 0.6200, 0.6193, 0.5708, 0.6150,
        0.5635, 0.6621, 0.6090, 0.5878, 0.6440, 0.5404, 0.4204],
       device='cuda:0') torch.Size([16])
percent tensor([0.9998, 0.9997, 0.9997, 0.9999, 0.9999, 0.9994, 0.9997, 0.9998, 0.9997,
        0.9998, 0.9995, 0.9999, 0.9995, 0.9994, 0.9998, 0.9996],
       device='cuda:0') torch.Size([16])
Epoch: 148 | Batch_idx: 0 |  Loss: (0.1126) |  Loss2: (0.0000) | Acc: (95.00%) (122/128)
Epoch: 148 | Batch_idx: 10 |  Loss: (0.1276) |  Loss2: (0.0000) | Acc: (95.00%) (1349/1408)
Epoch: 148 | Batch_idx: 20 |  Loss: (0.1245) |  Loss2: (0.0000) | Acc: (95.00%) (2575/2688)
Epoch: 148 | Batch_idx: 30 |  Loss: (0.1312) |  Loss2: (0.0000) | Acc: (95.00%) (3788/3968)
Epoch: 148 | Batch_idx: 40 |  Loss: (0.1326) |  Loss2: (0.0000) | Acc: (95.00%) (5009/5248)
Epoch: 148 | Batch_idx: 50 |  Loss: (0.1343) |  Loss2: (0.0000) | Acc: (95.00%) (6226/6528)
Epoch: 148 | Batch_idx: 60 |  Loss: (0.1395) |  Loss2: (0.0000) | Acc: (95.00%) (7429/7808)
Epoch: 148 | Batch_idx: 70 |  Loss: (0.1428) |  Loss2: (0.0000) | Acc: (95.00%) (8638/9088)
Epoch: 148 | Batch_idx: 80 |  Loss: (0.1430) |  Loss2: (0.0000) | Acc: (95.00%) (9850/10368)
Epoch: 148 | Batch_idx: 90 |  Loss: (0.1418) |  Loss2: (0.0000) | Acc: (95.00%) (11074/11648)
Epoch: 148 | Batch_idx: 100 |  Loss: (0.1418) |  Loss2: (0.0000) | Acc: (95.00%) (12283/12928)
Epoch: 148 | Batch_idx: 110 |  Loss: (0.1404) |  Loss2: (0.0000) | Acc: (95.00%) (13510/14208)
Epoch: 148 | Batch_idx: 120 |  Loss: (0.1398) |  Loss2: (0.0000) | Acc: (95.00%) (14734/15488)
Epoch: 148 | Batch_idx: 130 |  Loss: (0.1393) |  Loss2: (0.0000) | Acc: (95.00%) (15946/16768)
Epoch: 148 | Batch_idx: 140 |  Loss: (0.1403) |  Loss2: (0.0000) | Acc: (95.00%) (17153/18048)
Epoch: 148 | Batch_idx: 150 |  Loss: (0.1392) |  Loss2: (0.0000) | Acc: (95.00%) (18378/19328)
Epoch: 148 | Batch_idx: 160 |  Loss: (0.1387) |  Loss2: (0.0000) | Acc: (95.00%) (19602/20608)
Epoch: 148 | Batch_idx: 170 |  Loss: (0.1389) |  Loss2: (0.0000) | Acc: (95.00%) (20814/21888)
Epoch: 148 | Batch_idx: 180 |  Loss: (0.1389) |  Loss2: (0.0000) | Acc: (95.00%) (22023/23168)
Epoch: 148 | Batch_idx: 190 |  Loss: (0.1383) |  Loss2: (0.0000) | Acc: (95.00%) (23251/24448)
Epoch: 148 | Batch_idx: 200 |  Loss: (0.1381) |  Loss2: (0.0000) | Acc: (95.00%) (24469/25728)
Epoch: 148 | Batch_idx: 210 |  Loss: (0.1380) |  Loss2: (0.0000) | Acc: (95.00%) (25687/27008)
Epoch: 148 | Batch_idx: 220 |  Loss: (0.1377) |  Loss2: (0.0000) | Acc: (95.00%) (26905/28288)
Epoch: 148 | Batch_idx: 230 |  Loss: (0.1367) |  Loss2: (0.0000) | Acc: (95.00%) (28134/29568)
Epoch: 148 | Batch_idx: 240 |  Loss: (0.1366) |  Loss2: (0.0000) | Acc: (95.00%) (29349/30848)
Epoch: 148 | Batch_idx: 250 |  Loss: (0.1369) |  Loss2: (0.0000) | Acc: (95.00%) (30566/32128)
Epoch: 148 | Batch_idx: 260 |  Loss: (0.1367) |  Loss2: (0.0000) | Acc: (95.00%) (31784/33408)
Epoch: 148 | Batch_idx: 270 |  Loss: (0.1362) |  Loss2: (0.0000) | Acc: (95.00%) (33007/34688)
Epoch: 148 | Batch_idx: 280 |  Loss: (0.1363) |  Loss2: (0.0000) | Acc: (95.00%) (34229/35968)
Epoch: 148 | Batch_idx: 290 |  Loss: (0.1355) |  Loss2: (0.0000) | Acc: (95.00%) (35459/37248)
Epoch: 148 | Batch_idx: 300 |  Loss: (0.1359) |  Loss2: (0.0000) | Acc: (95.00%) (36680/38528)
Epoch: 148 | Batch_idx: 310 |  Loss: (0.1346) |  Loss2: (0.0000) | Acc: (95.00%) (37915/39808)
Epoch: 148 | Batch_idx: 320 |  Loss: (0.1341) |  Loss2: (0.0000) | Acc: (95.00%) (39144/41088)
Epoch: 148 | Batch_idx: 330 |  Loss: (0.1342) |  Loss2: (0.0000) | Acc: (95.00%) (40362/42368)
Epoch: 148 | Batch_idx: 340 |  Loss: (0.1345) |  Loss2: (0.0000) | Acc: (95.00%) (41575/43648)
Epoch: 148 | Batch_idx: 350 |  Loss: (0.1343) |  Loss2: (0.0000) | Acc: (95.00%) (42799/44928)
Epoch: 148 | Batch_idx: 360 |  Loss: (0.1348) |  Loss2: (0.0000) | Acc: (95.00%) (44014/46208)
Epoch: 148 | Batch_idx: 370 |  Loss: (0.1344) |  Loss2: (0.0000) | Acc: (95.00%) (45235/47488)
Epoch: 148 | Batch_idx: 380 |  Loss: (0.1345) |  Loss2: (0.0000) | Acc: (95.00%) (46456/48768)
Epoch: 148 | Batch_idx: 390 |  Loss: (0.1351) |  Loss2: (0.0000) | Acc: (95.00%) (47621/50000)
# TEST : Loss: (0.3960) | Acc: (88.00%) (8827/10000)
percent tensor([0.5749, 0.5855, 0.5731, 0.5747, 0.5776, 0.5943, 0.5853, 0.5674, 0.5701,
        0.5776, 0.5810, 0.5787, 0.5754, 0.5698, 0.5922, 0.5798],
       device='cuda:0') torch.Size([16])
percent tensor([0.5212, 0.5223, 0.5133, 0.5201, 0.5140, 0.5293, 0.5166, 0.5146, 0.5149,
        0.5191, 0.5233, 0.5150, 0.5181, 0.5203, 0.5250, 0.5232],
       device='cuda:0') torch.Size([16])
percent tensor([0.5679, 0.4274, 0.7163, 0.7229, 0.7334, 0.6692, 0.5523, 0.7002, 0.6195,
        0.5140, 0.4557, 0.6336, 0.4641, 0.5207, 0.5124, 0.6147],
       device='cuda:0') torch.Size([16])
percent tensor([0.6971, 0.7315, 0.6283, 0.6446, 0.6321, 0.5450, 0.6993, 0.6497, 0.7102,
        0.7324, 0.7488, 0.7007, 0.7115, 0.7480, 0.6779, 0.6626],
       device='cuda:0') torch.Size([16])
percent tensor([0.7099, 0.6087, 0.7230, 0.7149, 0.7428, 0.7833, 0.6979, 0.7056, 0.6700,
        0.6137, 0.5891, 0.6063, 0.5934, 0.6491, 0.6884, 0.7520],
       device='cuda:0') torch.Size([16])
percent tensor([0.6089, 0.7358, 0.7304, 0.7794, 0.7443, 0.7868, 0.6814, 0.5613, 0.7099,
        0.6789, 0.7466, 0.7105, 0.7373, 0.7366, 0.5473, 0.5325],
       device='cuda:0') torch.Size([16])
percent tensor([0.4748, 0.6768, 0.6399, 0.6539, 0.6216, 0.6429, 0.6232, 0.5847, 0.6166,
        0.5672, 0.6584, 0.6100, 0.5986, 0.6357, 0.5492, 0.4310],
       device='cuda:0') torch.Size([16])
percent tensor([0.9998, 0.9997, 0.9998, 0.9999, 0.9999, 0.9994, 0.9997, 0.9997, 0.9997,
        0.9999, 0.9995, 0.9999, 0.9995, 0.9994, 0.9998, 0.9995],
       device='cuda:0') torch.Size([16])
Epoch: 149 | Batch_idx: 0 |  Loss: (0.0802) |  Loss2: (0.0000) | Acc: (96.00%) (124/128)
Epoch: 149 | Batch_idx: 10 |  Loss: (0.1269) |  Loss2: (0.0000) | Acc: (94.00%) (1335/1408)
Epoch: 149 | Batch_idx: 20 |  Loss: (0.1262) |  Loss2: (0.0000) | Acc: (95.00%) (2566/2688)
Epoch: 149 | Batch_idx: 30 |  Loss: (0.1244) |  Loss2: (0.0000) | Acc: (95.00%) (3788/3968)
Epoch: 149 | Batch_idx: 40 |  Loss: (0.1277) |  Loss2: (0.0000) | Acc: (95.00%) (5003/5248)
Epoch: 149 | Batch_idx: 50 |  Loss: (0.1268) |  Loss2: (0.0000) | Acc: (95.00%) (6229/6528)
Epoch: 149 | Batch_idx: 60 |  Loss: (0.1314) |  Loss2: (0.0000) | Acc: (95.00%) (7433/7808)
Epoch: 149 | Batch_idx: 70 |  Loss: (0.1293) |  Loss2: (0.0000) | Acc: (95.00%) (8661/9088)
Epoch: 149 | Batch_idx: 80 |  Loss: (0.1277) |  Loss2: (0.0000) | Acc: (95.00%) (9899/10368)
Epoch: 149 | Batch_idx: 90 |  Loss: (0.1276) |  Loss2: (0.0000) | Acc: (95.00%) (11126/11648)
Epoch: 149 | Batch_idx: 100 |  Loss: (0.1281) |  Loss2: (0.0000) | Acc: (95.00%) (12350/12928)
Epoch: 149 | Batch_idx: 110 |  Loss: (0.1283) |  Loss2: (0.0000) | Acc: (95.00%) (13568/14208)
Epoch: 149 | Batch_idx: 120 |  Loss: (0.1272) |  Loss2: (0.0000) | Acc: (95.00%) (14793/15488)
Epoch: 149 | Batch_idx: 130 |  Loss: (0.1265) |  Loss2: (0.0000) | Acc: (95.00%) (16021/16768)
Epoch: 149 | Batch_idx: 140 |  Loss: (0.1249) |  Loss2: (0.0000) | Acc: (95.00%) (17258/18048)
Epoch: 149 | Batch_idx: 150 |  Loss: (0.1239) |  Loss2: (0.0000) | Acc: (95.00%) (18490/19328)
Epoch: 149 | Batch_idx: 160 |  Loss: (0.1241) |  Loss2: (0.0000) | Acc: (95.00%) (19719/20608)
Epoch: 149 | Batch_idx: 170 |  Loss: (0.1236) |  Loss2: (0.0000) | Acc: (95.00%) (20951/21888)
Epoch: 149 | Batch_idx: 180 |  Loss: (0.1231) |  Loss2: (0.0000) | Acc: (95.00%) (22187/23168)
Epoch: 149 | Batch_idx: 190 |  Loss: (0.1231) |  Loss2: (0.0000) | Acc: (95.00%) (23411/24448)
Epoch: 149 | Batch_idx: 200 |  Loss: (0.1237) |  Loss2: (0.0000) | Acc: (95.00%) (24633/25728)
Epoch: 149 | Batch_idx: 210 |  Loss: (0.1235) |  Loss2: (0.0000) | Acc: (95.00%) (25860/27008)
Epoch: 149 | Batch_idx: 220 |  Loss: (0.1229) |  Loss2: (0.0000) | Acc: (95.00%) (27084/28288)
Epoch: 149 | Batch_idx: 230 |  Loss: (0.1221) |  Loss2: (0.0000) | Acc: (95.00%) (28324/29568)
Epoch: 149 | Batch_idx: 240 |  Loss: (0.1222) |  Loss2: (0.0000) | Acc: (95.00%) (29554/30848)
Epoch: 149 | Batch_idx: 250 |  Loss: (0.1223) |  Loss2: (0.0000) | Acc: (95.00%) (30779/32128)
Epoch: 149 | Batch_idx: 260 |  Loss: (0.1223) |  Loss2: (0.0000) | Acc: (95.00%) (32009/33408)
Epoch: 149 | Batch_idx: 270 |  Loss: (0.1227) |  Loss2: (0.0000) | Acc: (95.00%) (33233/34688)
Epoch: 149 | Batch_idx: 280 |  Loss: (0.1223) |  Loss2: (0.0000) | Acc: (95.00%) (34466/35968)
Epoch: 149 | Batch_idx: 290 |  Loss: (0.1220) |  Loss2: (0.0000) | Acc: (95.00%) (35698/37248)
Epoch: 149 | Batch_idx: 300 |  Loss: (0.1215) |  Loss2: (0.0000) | Acc: (95.00%) (36932/38528)
Epoch: 149 | Batch_idx: 310 |  Loss: (0.1218) |  Loss2: (0.0000) | Acc: (95.00%) (38147/39808)
Epoch: 149 | Batch_idx: 320 |  Loss: (0.1219) |  Loss2: (0.0000) | Acc: (95.00%) (39366/41088)
Epoch: 149 | Batch_idx: 330 |  Loss: (0.1218) |  Loss2: (0.0000) | Acc: (95.00%) (40590/42368)
Epoch: 149 | Batch_idx: 340 |  Loss: (0.1211) |  Loss2: (0.0000) | Acc: (95.00%) (41830/43648)
Epoch: 149 | Batch_idx: 350 |  Loss: (0.1215) |  Loss2: (0.0000) | Acc: (95.00%) (43048/44928)
Epoch: 149 | Batch_idx: 360 |  Loss: (0.1217) |  Loss2: (0.0000) | Acc: (95.00%) (44266/46208)
Epoch: 149 | Batch_idx: 370 |  Loss: (0.1218) |  Loss2: (0.0000) | Acc: (95.00%) (45485/47488)
Epoch: 149 | Batch_idx: 380 |  Loss: (0.1219) |  Loss2: (0.0000) | Acc: (95.00%) (46713/48768)
Epoch: 149 | Batch_idx: 390 |  Loss: (0.1219) |  Loss2: (0.0000) | Acc: (95.00%) (47890/50000)
# TEST : Loss: (0.3879) | Acc: (88.00%) (8858/10000)
percent tensor([0.5724, 0.5830, 0.5707, 0.5720, 0.5753, 0.5916, 0.5828, 0.5648, 0.5678,
        0.5750, 0.5787, 0.5761, 0.5729, 0.5676, 0.5896, 0.5771],
       device='cuda:0') torch.Size([16])
percent tensor([0.5220, 0.5232, 0.5142, 0.5210, 0.5151, 0.5302, 0.5175, 0.5157, 0.5155,
        0.5198, 0.5241, 0.5158, 0.5187, 0.5210, 0.5259, 0.5238],
       device='cuda:0') torch.Size([16])
percent tensor([0.5672, 0.4345, 0.7142, 0.7215, 0.7317, 0.6694, 0.5564, 0.6985, 0.6208,
        0.5174, 0.4623, 0.6339, 0.4650, 0.5318, 0.5173, 0.6129],
       device='cuda:0') torch.Size([16])
percent tensor([0.6989, 0.7350, 0.6312, 0.6488, 0.6341, 0.5449, 0.7026, 0.6525, 0.7126,
        0.7352, 0.7508, 0.7038, 0.7142, 0.7512, 0.6804, 0.6635],
       device='cuda:0') torch.Size([16])
percent tensor([0.7074, 0.6033, 0.7191, 0.7128, 0.7403, 0.7837, 0.6940, 0.7015, 0.6639,
        0.6075, 0.5819, 0.5983, 0.5837, 0.6464, 0.6841, 0.7529],
       device='cuda:0') torch.Size([16])
percent tensor([0.6048, 0.7358, 0.7316, 0.7798, 0.7420, 0.7848, 0.6819, 0.5581, 0.7129,
        0.6783, 0.7498, 0.7103, 0.7405, 0.7351, 0.5452, 0.5274],
       device='cuda:0') torch.Size([16])
percent tensor([0.4843, 0.6923, 0.6583, 0.6649, 0.6457, 0.6611, 0.6376, 0.6015, 0.6346,
        0.5823, 0.6688, 0.6216, 0.6187, 0.6416, 0.5622, 0.4405],
       device='cuda:0') torch.Size([16])
percent tensor([0.9998, 0.9998, 0.9998, 0.9999, 0.9999, 0.9994, 0.9997, 0.9998, 0.9997,
        0.9999, 0.9995, 0.9999, 0.9996, 0.9994, 0.9998, 0.9995],
       device='cuda:0') torch.Size([16])
True Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=128, out_features=16, bias=False)
False Linear(in_features=16, out_features=2, bias=False)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=128, out_features=16, bias=False)
False Linear(in_features=16, out_features=2, bias=False)
True Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=256, out_features=32, bias=False)
False Linear(in_features=32, out_features=2, bias=False)
True Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=256, out_features=32, bias=False)
False Linear(in_features=32, out_features=2, bias=False)
True Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=512, out_features=64, bias=False)
False Linear(in_features=64, out_features=2, bias=False)
True Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=512, out_features=64, bias=False)
False Linear(in_features=64, out_features=2, bias=False)
True Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1024, out_features=128, bias=False)
False Linear(in_features=128, out_features=2, bias=False)
True Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1024, out_features=128, bias=False)
False Linear(in_features=128, out_features=2, bias=False)
True Linear(in_features=512, out_features=10, bias=True)
Epoch: 150 | Batch_idx: 0 |  Loss: (0.1250) |  Loss2: (0.0000) | Acc: (95.00%) (122/128)
Epoch: 150 | Batch_idx: 10 |  Loss: (0.1237) |  Loss2: (0.0000) | Acc: (96.00%) (1353/1408)
Epoch: 150 | Batch_idx: 20 |  Loss: (0.1298) |  Loss2: (0.0000) | Acc: (95.00%) (2577/2688)
Epoch: 150 | Batch_idx: 30 |  Loss: (0.1242) |  Loss2: (0.0000) | Acc: (95.00%) (3807/3968)
Epoch: 150 | Batch_idx: 40 |  Loss: (0.1240) |  Loss2: (0.0000) | Acc: (95.00%) (5033/5248)
Epoch: 150 | Batch_idx: 50 |  Loss: (0.1212) |  Loss2: (0.0000) | Acc: (96.00%) (6271/6528)
Epoch: 150 | Batch_idx: 60 |  Loss: (0.1242) |  Loss2: (0.0000) | Acc: (95.00%) (7495/7808)
Epoch: 150 | Batch_idx: 70 |  Loss: (0.1226) |  Loss2: (0.0000) | Acc: (96.00%) (8727/9088)
Epoch: 150 | Batch_idx: 80 |  Loss: (0.1230) |  Loss2: (0.0000) | Acc: (95.00%) (9951/10368)
Epoch: 150 | Batch_idx: 90 |  Loss: (0.1213) |  Loss2: (0.0000) | Acc: (96.00%) (11194/11648)
Epoch: 150 | Batch_idx: 100 |  Loss: (0.1205) |  Loss2: (0.0000) | Acc: (96.00%) (12425/12928)
Epoch: 150 | Batch_idx: 110 |  Loss: (0.1190) |  Loss2: (0.0000) | Acc: (96.00%) (13663/14208)
Epoch: 150 | Batch_idx: 120 |  Loss: (0.1181) |  Loss2: (0.0000) | Acc: (96.00%) (14905/15488)
Epoch: 150 | Batch_idx: 130 |  Loss: (0.1189) |  Loss2: (0.0000) | Acc: (96.00%) (16134/16768)
Epoch: 150 | Batch_idx: 140 |  Loss: (0.1200) |  Loss2: (0.0000) | Acc: (96.00%) (17360/18048)
Epoch: 150 | Batch_idx: 150 |  Loss: (0.1202) |  Loss2: (0.0000) | Acc: (96.00%) (18583/19328)
Epoch: 150 | Batch_idx: 160 |  Loss: (0.1207) |  Loss2: (0.0000) | Acc: (96.00%) (19809/20608)
Epoch: 150 | Batch_idx: 170 |  Loss: (0.1203) |  Loss2: (0.0000) | Acc: (96.00%) (21041/21888)
Epoch: 150 | Batch_idx: 180 |  Loss: (0.1205) |  Loss2: (0.0000) | Acc: (96.00%) (22270/23168)
Epoch: 150 | Batch_idx: 190 |  Loss: (0.1203) |  Loss2: (0.0000) | Acc: (96.00%) (23502/24448)
Epoch: 150 | Batch_idx: 200 |  Loss: (0.1203) |  Loss2: (0.0000) | Acc: (96.00%) (24731/25728)
Epoch: 150 | Batch_idx: 210 |  Loss: (0.1200) |  Loss2: (0.0000) | Acc: (96.00%) (25961/27008)
Epoch: 150 | Batch_idx: 220 |  Loss: (0.1198) |  Loss2: (0.0000) | Acc: (96.00%) (27185/28288)
Epoch: 150 | Batch_idx: 230 |  Loss: (0.1204) |  Loss2: (0.0000) | Acc: (96.00%) (28408/29568)
Epoch: 150 | Batch_idx: 240 |  Loss: (0.1204) |  Loss2: (0.0000) | Acc: (96.00%) (29636/30848)
Epoch: 150 | Batch_idx: 250 |  Loss: (0.1211) |  Loss2: (0.0000) | Acc: (96.00%) (30858/32128)
Epoch: 150 | Batch_idx: 260 |  Loss: (0.1219) |  Loss2: (0.0000) | Acc: (96.00%) (32082/33408)
Epoch: 150 | Batch_idx: 270 |  Loss: (0.1219) |  Loss2: (0.0000) | Acc: (96.00%) (33309/34688)
Epoch: 150 | Batch_idx: 280 |  Loss: (0.1231) |  Loss2: (0.0000) | Acc: (95.00%) (34525/35968)
Epoch: 150 | Batch_idx: 290 |  Loss: (0.1229) |  Loss2: (0.0000) | Acc: (95.00%) (35757/37248)
Epoch: 150 | Batch_idx: 300 |  Loss: (0.1223) |  Loss2: (0.0000) | Acc: (96.00%) (36990/38528)
Epoch: 150 | Batch_idx: 310 |  Loss: (0.1226) |  Loss2: (0.0000) | Acc: (96.00%) (38216/39808)
Epoch: 150 | Batch_idx: 320 |  Loss: (0.1230) |  Loss2: (0.0000) | Acc: (95.00%) (39434/41088)
Epoch: 150 | Batch_idx: 330 |  Loss: (0.1232) |  Loss2: (0.0000) | Acc: (95.00%) (40654/42368)
Epoch: 150 | Batch_idx: 340 |  Loss: (0.1230) |  Loss2: (0.0000) | Acc: (95.00%) (41889/43648)
Epoch: 150 | Batch_idx: 350 |  Loss: (0.1230) |  Loss2: (0.0000) | Acc: (95.00%) (43111/44928)
Epoch: 150 | Batch_idx: 360 |  Loss: (0.1232) |  Loss2: (0.0000) | Acc: (95.00%) (44334/46208)
Epoch: 150 | Batch_idx: 370 |  Loss: (0.1233) |  Loss2: (0.0000) | Acc: (95.00%) (45566/47488)
Epoch: 150 | Batch_idx: 380 |  Loss: (0.1227) |  Loss2: (0.0000) | Acc: (95.00%) (46803/48768)
Epoch: 150 | Batch_idx: 390 |  Loss: (0.1226) |  Loss2: (0.0000) | Acc: (95.00%) (47982/50000)
=> saving checkpoint 'drive/app/torch/save_Schedule/checkpoint_150.pth.tar'
# TEST : Loss: (0.3808) | Acc: (88.00%) (8838/10000)
percent tensor([0.5709, 0.5834, 0.5686, 0.5711, 0.5751, 0.5894, 0.5823, 0.5644, 0.5671,
        0.5736, 0.5776, 0.5748, 0.5722, 0.5677, 0.5894, 0.5763],
       device='cuda:0') torch.Size([16])
percent tensor([0.5222, 0.5238, 0.5146, 0.5218, 0.5145, 0.5303, 0.5182, 0.5151, 0.5159,
        0.5202, 0.5243, 0.5163, 0.5187, 0.5235, 0.5257, 0.5245],
       device='cuda:0') torch.Size([16])
percent tensor([0.5537, 0.4362, 0.7034, 0.7125, 0.7255, 0.6471, 0.5457, 0.6900, 0.6108,
        0.5090, 0.4617, 0.6209, 0.4565, 0.5292, 0.5083, 0.6022],
       device='cuda:0') torch.Size([16])
percent tensor([0.6984, 0.7321, 0.6200, 0.6484, 0.6287, 0.5529, 0.7033, 0.6497, 0.7135,
        0.7275, 0.7509, 0.6955, 0.7171, 0.7467, 0.6854, 0.6570],
       device='cuda:0') torch.Size([16])
percent tensor([0.7134, 0.6177, 0.7333, 0.7267, 0.7494, 0.7998, 0.7060, 0.7171, 0.6734,
        0.6190, 0.5841, 0.6178, 0.5837, 0.6530, 0.6824, 0.7701],
       device='cuda:0') torch.Size([16])
percent tensor([0.6201, 0.7355, 0.7219, 0.7776, 0.7114, 0.8049, 0.7107, 0.5311, 0.7260,
        0.7121, 0.7657, 0.7327, 0.7249, 0.7681, 0.5776, 0.5663],
       device='cuda:0') torch.Size([16])
percent tensor([0.4707, 0.6548, 0.6372, 0.6605, 0.6032, 0.6683, 0.6352, 0.5830, 0.6367,
        0.6080, 0.6904, 0.6380, 0.5934, 0.6705, 0.5662, 0.4295],
       device='cuda:0') torch.Size([16])
percent tensor([0.9998, 0.9997, 0.9995, 0.9998, 0.9999, 0.9989, 0.9998, 0.9997, 0.9998,
        0.9999, 0.9994, 0.9999, 0.9995, 0.9996, 0.9997, 0.9996],
       device='cuda:0') torch.Size([16])
Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 3, 3, 3]) tensor(184.3051, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(817.9185, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(826.6934, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([128, 64, 3, 3]) tensor(1514.0051, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([128, 64, 1, 1]) tensor(490.8956, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([128, 128, 3, 3]) tensor(2265.0942, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([256, 128, 3, 3]) tensor(4279.0322, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([256, 128, 1, 1]) tensor(1377.4304, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([256, 256, 3, 3]) tensor(6212.8462, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([512, 256, 3, 3]) tensor(11706.5225, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([512, 256, 1, 1]) tensor(3867.4636, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([512, 512, 3, 3]) tensor(16300.4170, device='cuda:0', grad_fn=<NormBackward0>)
Epoch: 151 | Batch_idx: 0 |  Loss: (0.0888) |  Loss2: (0.0000) | Acc: (96.00%) (124/128)
Epoch: 151 | Batch_idx: 10 |  Loss: (0.1094) |  Loss2: (0.0000) | Acc: (96.00%) (1363/1408)
Epoch: 151 | Batch_idx: 20 |  Loss: (0.1002) |  Loss2: (0.0000) | Acc: (97.00%) (2609/2688)
Epoch: 151 | Batch_idx: 30 |  Loss: (0.1114) |  Loss2: (0.0000) | Acc: (96.00%) (3822/3968)
Epoch: 151 | Batch_idx: 40 |  Loss: (0.1125) |  Loss2: (0.0000) | Acc: (96.00%) (5055/5248)
Epoch: 151 | Batch_idx: 50 |  Loss: (0.1122) |  Loss2: (0.0000) | Acc: (96.00%) (6289/6528)
Epoch: 151 | Batch_idx: 60 |  Loss: (0.1150) |  Loss2: (0.0000) | Acc: (96.00%) (7525/7808)
Epoch: 151 | Batch_idx: 70 |  Loss: (0.1131) |  Loss2: (0.0000) | Acc: (96.00%) (8760/9088)
Epoch: 151 | Batch_idx: 80 |  Loss: (0.1119) |  Loss2: (0.0000) | Acc: (96.00%) (10001/10368)
Epoch: 151 | Batch_idx: 90 |  Loss: (0.1107) |  Loss2: (0.0000) | Acc: (96.00%) (11238/11648)
Epoch: 151 | Batch_idx: 100 |  Loss: (0.1101) |  Loss2: (0.0000) | Acc: (96.00%) (12471/12928)
Epoch: 151 | Batch_idx: 110 |  Loss: (0.1130) |  Loss2: (0.0000) | Acc: (96.00%) (13681/14208)
Epoch: 151 | Batch_idx: 120 |  Loss: (0.1145) |  Loss2: (0.0000) | Acc: (96.00%) (14903/15488)
Epoch: 151 | Batch_idx: 130 |  Loss: (0.1143) |  Loss2: (0.0000) | Acc: (96.00%) (16138/16768)
Epoch: 151 | Batch_idx: 140 |  Loss: (0.1148) |  Loss2: (0.0000) | Acc: (96.00%) (17365/18048)
Epoch: 151 | Batch_idx: 150 |  Loss: (0.1155) |  Loss2: (0.0000) | Acc: (96.00%) (18597/19328)
Epoch: 151 | Batch_idx: 160 |  Loss: (0.1168) |  Loss2: (0.0000) | Acc: (96.00%) (19816/20608)
Epoch: 151 | Batch_idx: 170 |  Loss: (0.1164) |  Loss2: (0.0000) | Acc: (96.00%) (21047/21888)
Epoch: 151 | Batch_idx: 180 |  Loss: (0.1171) |  Loss2: (0.0000) | Acc: (96.00%) (22269/23168)
Epoch: 151 | Batch_idx: 190 |  Loss: (0.1175) |  Loss2: (0.0000) | Acc: (96.00%) (23491/24448)
Epoch: 151 | Batch_idx: 200 |  Loss: (0.1176) |  Loss2: (0.0000) | Acc: (96.00%) (24716/25728)
Epoch: 151 | Batch_idx: 210 |  Loss: (0.1185) |  Loss2: (0.0000) | Acc: (96.00%) (25937/27008)
Epoch: 151 | Batch_idx: 220 |  Loss: (0.1201) |  Loss2: (0.0000) | Acc: (95.00%) (27143/28288)
Epoch: 151 | Batch_idx: 230 |  Loss: (0.1209) |  Loss2: (0.0000) | Acc: (95.00%) (28360/29568)
Epoch: 151 | Batch_idx: 240 |  Loss: (0.1208) |  Loss2: (0.0000) | Acc: (95.00%) (29597/30848)
Epoch: 151 | Batch_idx: 250 |  Loss: (0.1210) |  Loss2: (0.0000) | Acc: (95.00%) (30814/32128)
Epoch: 151 | Batch_idx: 260 |  Loss: (0.1214) |  Loss2: (0.0000) | Acc: (95.00%) (32032/33408)
Epoch: 151 | Batch_idx: 270 |  Loss: (0.1220) |  Loss2: (0.0000) | Acc: (95.00%) (33247/34688)
Epoch: 151 | Batch_idx: 280 |  Loss: (0.1218) |  Loss2: (0.0000) | Acc: (95.00%) (34479/35968)
Epoch: 151 | Batch_idx: 290 |  Loss: (0.1216) |  Loss2: (0.0000) | Acc: (95.00%) (35706/37248)
Epoch: 151 | Batch_idx: 300 |  Loss: (0.1219) |  Loss2: (0.0000) | Acc: (95.00%) (36929/38528)
Epoch: 151 | Batch_idx: 310 |  Loss: (0.1222) |  Loss2: (0.0000) | Acc: (95.00%) (38157/39808)
Epoch: 151 | Batch_idx: 320 |  Loss: (0.1221) |  Loss2: (0.0000) | Acc: (95.00%) (39379/41088)
Epoch: 151 | Batch_idx: 330 |  Loss: (0.1221) |  Loss2: (0.0000) | Acc: (95.00%) (40610/42368)
Epoch: 151 | Batch_idx: 340 |  Loss: (0.1224) |  Loss2: (0.0000) | Acc: (95.00%) (41832/43648)
Epoch: 151 | Batch_idx: 350 |  Loss: (0.1226) |  Loss2: (0.0000) | Acc: (95.00%) (43056/44928)
Epoch: 151 | Batch_idx: 360 |  Loss: (0.1229) |  Loss2: (0.0000) | Acc: (95.00%) (44276/46208)
Epoch: 151 | Batch_idx: 370 |  Loss: (0.1227) |  Loss2: (0.0000) | Acc: (95.00%) (45503/47488)
Epoch: 151 | Batch_idx: 380 |  Loss: (0.1230) |  Loss2: (0.0000) | Acc: (95.00%) (46714/48768)
Epoch: 151 | Batch_idx: 390 |  Loss: (0.1235) |  Loss2: (0.0000) | Acc: (95.00%) (47884/50000)
# TEST : Loss: (0.3994) | Acc: (88.00%) (8866/10000)
percent tensor([0.5703, 0.5815, 0.5670, 0.5716, 0.5729, 0.5896, 0.5808, 0.5628, 0.5655,
        0.5728, 0.5772, 0.5735, 0.5711, 0.5653, 0.5890, 0.5757],
       device='cuda:0') torch.Size([16])
percent tensor([0.5227, 0.5234, 0.5168, 0.5220, 0.5169, 0.5310, 0.5183, 0.5161, 0.5166,
        0.5205, 0.5242, 0.5176, 0.5192, 0.5224, 0.5254, 0.5242],
       device='cuda:0') torch.Size([16])
percent tensor([0.5703, 0.4525, 0.7136, 0.7179, 0.7255, 0.6555, 0.5581, 0.6899, 0.6182,
        0.5209, 0.4702, 0.6235, 0.4644, 0.5585, 0.5239, 0.6104],
       device='cuda:0') torch.Size([16])
percent tensor([0.7079, 0.7408, 0.6248, 0.6493, 0.6329, 0.5471, 0.7106, 0.6540, 0.7199,
        0.7428, 0.7605, 0.7086, 0.7306, 0.7502, 0.6904, 0.6664],
       device='cuda:0') torch.Size([16])
percent tensor([0.7108, 0.6059, 0.7380, 0.7208, 0.7570, 0.7987, 0.7026, 0.7152, 0.6709,
        0.6116, 0.5784, 0.6044, 0.5708, 0.6420, 0.6759, 0.7559],
       device='cuda:0') torch.Size([16])
percent tensor([0.6292, 0.7235, 0.7369, 0.7870, 0.7395, 0.8111, 0.6998, 0.5483, 0.7325,
        0.7142, 0.7527, 0.7426, 0.7179, 0.7555, 0.6053, 0.5955],
       device='cuda:0') torch.Size([16])
percent tensor([0.4999, 0.6653, 0.6548, 0.6749, 0.6123, 0.6951, 0.6244, 0.5848, 0.6632,
        0.6298, 0.7222, 0.6550, 0.6125, 0.6533, 0.6020, 0.4509],
       device='cuda:0') torch.Size([16])
percent tensor([0.9998, 0.9997, 0.9998, 0.9999, 0.9999, 0.9997, 0.9999, 0.9998, 0.9996,
        0.9999, 0.9996, 0.9999, 0.9994, 0.9996, 0.9997, 0.9997],
       device='cuda:0') torch.Size([16])
Epoch: 152 | Batch_idx: 0 |  Loss: (0.0735) |  Loss2: (0.0000) | Acc: (97.00%) (125/128)
Epoch: 152 | Batch_idx: 10 |  Loss: (0.1145) |  Loss2: (0.0000) | Acc: (96.00%) (1357/1408)
Epoch: 152 | Batch_idx: 20 |  Loss: (0.1163) |  Loss2: (0.0000) | Acc: (96.00%) (2581/2688)
Epoch: 152 | Batch_idx: 30 |  Loss: (0.1166) |  Loss2: (0.0000) | Acc: (95.00%) (3806/3968)
Epoch: 152 | Batch_idx: 40 |  Loss: (0.1177) |  Loss2: (0.0000) | Acc: (95.00%) (5033/5248)
Epoch: 152 | Batch_idx: 50 |  Loss: (0.1137) |  Loss2: (0.0000) | Acc: (96.00%) (6267/6528)
Epoch: 152 | Batch_idx: 60 |  Loss: (0.1132) |  Loss2: (0.0000) | Acc: (96.00%) (7499/7808)
Epoch: 152 | Batch_idx: 70 |  Loss: (0.1108) |  Loss2: (0.0000) | Acc: (96.00%) (8734/9088)
Epoch: 152 | Batch_idx: 80 |  Loss: (0.1098) |  Loss2: (0.0000) | Acc: (96.00%) (9965/10368)
Epoch: 152 | Batch_idx: 90 |  Loss: (0.1104) |  Loss2: (0.0000) | Acc: (96.00%) (11195/11648)
Epoch: 152 | Batch_idx: 100 |  Loss: (0.1098) |  Loss2: (0.0000) | Acc: (96.00%) (12429/12928)
Epoch: 152 | Batch_idx: 110 |  Loss: (0.1119) |  Loss2: (0.0000) | Acc: (96.00%) (13646/14208)
Epoch: 152 | Batch_idx: 120 |  Loss: (0.1136) |  Loss2: (0.0000) | Acc: (95.00%) (14862/15488)
Epoch: 152 | Batch_idx: 130 |  Loss: (0.1133) |  Loss2: (0.0000) | Acc: (95.00%) (16096/16768)
Epoch: 152 | Batch_idx: 140 |  Loss: (0.1127) |  Loss2: (0.0000) | Acc: (96.00%) (17337/18048)
Epoch: 152 | Batch_idx: 150 |  Loss: (0.1124) |  Loss2: (0.0000) | Acc: (96.00%) (18568/19328)
Epoch: 152 | Batch_idx: 160 |  Loss: (0.1120) |  Loss2: (0.0000) | Acc: (96.00%) (19803/20608)
Epoch: 152 | Batch_idx: 170 |  Loss: (0.1126) |  Loss2: (0.0000) | Acc: (96.00%) (21031/21888)
Epoch: 152 | Batch_idx: 180 |  Loss: (0.1128) |  Loss2: (0.0000) | Acc: (96.00%) (22261/23168)
Epoch: 152 | Batch_idx: 190 |  Loss: (0.1121) |  Loss2: (0.0000) | Acc: (96.00%) (23496/24448)
Epoch: 152 | Batch_idx: 200 |  Loss: (0.1120) |  Loss2: (0.0000) | Acc: (96.00%) (24727/25728)
Epoch: 152 | Batch_idx: 210 |  Loss: (0.1115) |  Loss2: (0.0000) | Acc: (96.00%) (25968/27008)
Epoch: 152 | Batch_idx: 220 |  Loss: (0.1118) |  Loss2: (0.0000) | Acc: (96.00%) (27197/28288)
Epoch: 152 | Batch_idx: 230 |  Loss: (0.1124) |  Loss2: (0.0000) | Acc: (96.00%) (28428/29568)
Epoch: 152 | Batch_idx: 240 |  Loss: (0.1134) |  Loss2: (0.0000) | Acc: (96.00%) (29638/30848)
Epoch: 152 | Batch_idx: 250 |  Loss: (0.1139) |  Loss2: (0.0000) | Acc: (96.00%) (30857/32128)
Epoch: 152 | Batch_idx: 260 |  Loss: (0.1155) |  Loss2: (0.0000) | Acc: (95.00%) (32064/33408)
Epoch: 152 | Batch_idx: 270 |  Loss: (0.1158) |  Loss2: (0.0000) | Acc: (95.00%) (33284/34688)
Epoch: 152 | Batch_idx: 280 |  Loss: (0.1173) |  Loss2: (0.0000) | Acc: (95.00%) (34499/35968)
Epoch: 152 | Batch_idx: 290 |  Loss: (0.1176) |  Loss2: (0.0000) | Acc: (95.00%) (35725/37248)
Epoch: 152 | Batch_idx: 300 |  Loss: (0.1181) |  Loss2: (0.0000) | Acc: (95.00%) (36955/38528)
Epoch: 152 | Batch_idx: 310 |  Loss: (0.1177) |  Loss2: (0.0000) | Acc: (95.00%) (38185/39808)
Epoch: 152 | Batch_idx: 320 |  Loss: (0.1180) |  Loss2: (0.0000) | Acc: (95.00%) (39411/41088)
Epoch: 152 | Batch_idx: 330 |  Loss: (0.1181) |  Loss2: (0.0000) | Acc: (95.00%) (40639/42368)
Epoch: 152 | Batch_idx: 340 |  Loss: (0.1183) |  Loss2: (0.0000) | Acc: (95.00%) (41859/43648)
Epoch: 152 | Batch_idx: 350 |  Loss: (0.1189) |  Loss2: (0.0000) | Acc: (95.00%) (43079/44928)
Epoch: 152 | Batch_idx: 360 |  Loss: (0.1193) |  Loss2: (0.0000) | Acc: (95.00%) (44298/46208)
Epoch: 152 | Batch_idx: 370 |  Loss: (0.1192) |  Loss2: (0.0000) | Acc: (95.00%) (45528/47488)
Epoch: 152 | Batch_idx: 380 |  Loss: (0.1192) |  Loss2: (0.0000) | Acc: (95.00%) (46759/48768)
Epoch: 152 | Batch_idx: 390 |  Loss: (0.1192) |  Loss2: (0.0000) | Acc: (95.00%) (47939/50000)
# TEST : Loss: (0.4077) | Acc: (88.00%) (8840/10000)
percent tensor([0.5701, 0.5831, 0.5703, 0.5714, 0.5757, 0.5884, 0.5825, 0.5644, 0.5674,
        0.5736, 0.5767, 0.5750, 0.5716, 0.5694, 0.5885, 0.5756],
       device='cuda:0') torch.Size([16])
percent tensor([0.5230, 0.5234, 0.5148, 0.5234, 0.5153, 0.5322, 0.5178, 0.5157, 0.5164,
        0.5199, 0.5248, 0.5160, 0.5193, 0.5218, 0.5268, 0.5257],
       device='cuda:0') torch.Size([16])
percent tensor([0.5652, 0.4497, 0.7088, 0.7130, 0.7323, 0.6654, 0.5638, 0.6886, 0.6219,
        0.5244, 0.4665, 0.6233, 0.4645, 0.5376, 0.5240, 0.6109],
       device='cuda:0') torch.Size([16])
percent tensor([0.6972, 0.7316, 0.6119, 0.6337, 0.6209, 0.5365, 0.6985, 0.6410, 0.7083,
        0.7293, 0.7526, 0.6940, 0.7153, 0.7507, 0.6744, 0.6577],
       device='cuda:0') torch.Size([16])
percent tensor([0.7104, 0.6158, 0.7316, 0.7230, 0.7495, 0.8017, 0.7086, 0.7150, 0.6749,
        0.6142, 0.5753, 0.6149, 0.5878, 0.6478, 0.6899, 0.7634],
       device='cuda:0') torch.Size([16])
percent tensor([0.6169, 0.7360, 0.7598, 0.7915, 0.7612, 0.7902, 0.7127, 0.5853, 0.7478,
        0.7166, 0.7591, 0.7262, 0.7104, 0.7459, 0.5980, 0.5760],
       device='cuda:0') torch.Size([16])
percent tensor([0.4833, 0.6981, 0.6657, 0.6914, 0.6443, 0.6507, 0.6415, 0.5961, 0.6640,
        0.6265, 0.7339, 0.6540, 0.6193, 0.6633, 0.5657, 0.4434],
       device='cuda:0') torch.Size([16])
percent tensor([0.9997, 0.9998, 0.9997, 0.9999, 0.9999, 0.9996, 0.9999, 0.9998, 0.9997,
        0.9998, 0.9997, 0.9999, 0.9995, 0.9995, 0.9998, 0.9996],
       device='cuda:0') torch.Size([16])
False Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=128, out_features=16, bias=False)
True Linear(in_features=16, out_features=2, bias=False)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=128, out_features=16, bias=False)
True Linear(in_features=16, out_features=2, bias=False)
False Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=256, out_features=32, bias=False)
True Linear(in_features=32, out_features=2, bias=False)
False Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=256, out_features=32, bias=False)
True Linear(in_features=32, out_features=2, bias=False)
False Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=512, out_features=64, bias=False)
True Linear(in_features=64, out_features=2, bias=False)
False Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=512, out_features=64, bias=False)
True Linear(in_features=64, out_features=2, bias=False)
False Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1024, out_features=128, bias=False)
True Linear(in_features=128, out_features=2, bias=False)
False Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1024, out_features=128, bias=False)
True Linear(in_features=128, out_features=2, bias=False)
False Linear(in_features=512, out_features=10, bias=True)
Epoch: 153 | Batch_idx: 0 |  Loss: (0.0918) |  Loss2: (0.0000) | Acc: (96.00%) (123/128)
Epoch: 153 | Batch_idx: 10 |  Loss: (0.1208) |  Loss2: (0.0000) | Acc: (96.00%) (1353/1408)
Epoch: 153 | Batch_idx: 20 |  Loss: (0.1228) |  Loss2: (0.0000) | Acc: (95.00%) (2577/2688)
Epoch: 153 | Batch_idx: 30 |  Loss: (0.1238) |  Loss2: (0.0000) | Acc: (95.00%) (3804/3968)
Epoch: 153 | Batch_idx: 40 |  Loss: (0.1298) |  Loss2: (0.0000) | Acc: (95.00%) (5016/5248)
Epoch: 153 | Batch_idx: 50 |  Loss: (0.1321) |  Loss2: (0.0000) | Acc: (95.00%) (6223/6528)
Epoch: 153 | Batch_idx: 60 |  Loss: (0.1344) |  Loss2: (0.0000) | Acc: (95.00%) (7438/7808)
Epoch: 153 | Batch_idx: 70 |  Loss: (0.1362) |  Loss2: (0.0000) | Acc: (95.00%) (8649/9088)
Epoch: 153 | Batch_idx: 80 |  Loss: (0.1368) |  Loss2: (0.0000) | Acc: (95.00%) (9866/10368)
Epoch: 153 | Batch_idx: 90 |  Loss: (0.1364) |  Loss2: (0.0000) | Acc: (95.00%) (11085/11648)
Epoch: 153 | Batch_idx: 100 |  Loss: (0.1378) |  Loss2: (0.0000) | Acc: (95.00%) (12294/12928)
Epoch: 153 | Batch_idx: 110 |  Loss: (0.1377) |  Loss2: (0.0000) | Acc: (95.00%) (13516/14208)
Epoch: 153 | Batch_idx: 120 |  Loss: (0.1384) |  Loss2: (0.0000) | Acc: (95.00%) (14728/15488)
Epoch: 153 | Batch_idx: 130 |  Loss: (0.1364) |  Loss2: (0.0000) | Acc: (95.00%) (15958/16768)
Epoch: 153 | Batch_idx: 140 |  Loss: (0.1367) |  Loss2: (0.0000) | Acc: (95.00%) (17174/18048)
Epoch: 153 | Batch_idx: 150 |  Loss: (0.1369) |  Loss2: (0.0000) | Acc: (95.00%) (18401/19328)
Epoch: 153 | Batch_idx: 160 |  Loss: (0.1362) |  Loss2: (0.0000) | Acc: (95.00%) (19630/20608)
Epoch: 153 | Batch_idx: 170 |  Loss: (0.1373) |  Loss2: (0.0000) | Acc: (95.00%) (20837/21888)
Epoch: 153 | Batch_idx: 180 |  Loss: (0.1372) |  Loss2: (0.0000) | Acc: (95.00%) (22052/23168)
Epoch: 153 | Batch_idx: 190 |  Loss: (0.1362) |  Loss2: (0.0000) | Acc: (95.00%) (23278/24448)
Epoch: 153 | Batch_idx: 200 |  Loss: (0.1357) |  Loss2: (0.0000) | Acc: (95.00%) (24497/25728)
Epoch: 153 | Batch_idx: 210 |  Loss: (0.1349) |  Loss2: (0.0000) | Acc: (95.00%) (25725/27008)
Epoch: 153 | Batch_idx: 220 |  Loss: (0.1351) |  Loss2: (0.0000) | Acc: (95.00%) (26949/28288)
Epoch: 153 | Batch_idx: 230 |  Loss: (0.1346) |  Loss2: (0.0000) | Acc: (95.00%) (28175/29568)
Epoch: 153 | Batch_idx: 240 |  Loss: (0.1337) |  Loss2: (0.0000) | Acc: (95.00%) (29406/30848)
Epoch: 153 | Batch_idx: 250 |  Loss: (0.1337) |  Loss2: (0.0000) | Acc: (95.00%) (30619/32128)
Epoch: 153 | Batch_idx: 260 |  Loss: (0.1329) |  Loss2: (0.0000) | Acc: (95.00%) (31859/33408)
Epoch: 153 | Batch_idx: 270 |  Loss: (0.1333) |  Loss2: (0.0000) | Acc: (95.00%) (33072/34688)
Epoch: 153 | Batch_idx: 280 |  Loss: (0.1337) |  Loss2: (0.0000) | Acc: (95.00%) (34291/35968)
Epoch: 153 | Batch_idx: 290 |  Loss: (0.1333) |  Loss2: (0.0000) | Acc: (95.00%) (35512/37248)
Epoch: 153 | Batch_idx: 300 |  Loss: (0.1334) |  Loss2: (0.0000) | Acc: (95.00%) (36731/38528)
Epoch: 153 | Batch_idx: 310 |  Loss: (0.1331) |  Loss2: (0.0000) | Acc: (95.00%) (37953/39808)
Epoch: 153 | Batch_idx: 320 |  Loss: (0.1329) |  Loss2: (0.0000) | Acc: (95.00%) (39173/41088)
Epoch: 153 | Batch_idx: 330 |  Loss: (0.1332) |  Loss2: (0.0000) | Acc: (95.00%) (40389/42368)
Epoch: 153 | Batch_idx: 340 |  Loss: (0.1327) |  Loss2: (0.0000) | Acc: (95.00%) (41618/43648)
Epoch: 153 | Batch_idx: 350 |  Loss: (0.1327) |  Loss2: (0.0000) | Acc: (95.00%) (42838/44928)
Epoch: 153 | Batch_idx: 360 |  Loss: (0.1326) |  Loss2: (0.0000) | Acc: (95.00%) (44055/46208)
Epoch: 153 | Batch_idx: 370 |  Loss: (0.1328) |  Loss2: (0.0000) | Acc: (95.00%) (45271/47488)
Epoch: 153 | Batch_idx: 380 |  Loss: (0.1328) |  Loss2: (0.0000) | Acc: (95.00%) (46494/48768)
Epoch: 153 | Batch_idx: 390 |  Loss: (0.1325) |  Loss2: (0.0000) | Acc: (95.00%) (47681/50000)
# TEST : Loss: (0.4033) | Acc: (88.00%) (8831/10000)
percent tensor([0.5752, 0.5883, 0.5754, 0.5755, 0.5813, 0.5928, 0.5881, 0.5701, 0.5733,
        0.5788, 0.5819, 0.5802, 0.5773, 0.5740, 0.5932, 0.5806],
       device='cuda:0') torch.Size([16])
percent tensor([0.5199, 0.5202, 0.5126, 0.5196, 0.5122, 0.5286, 0.5146, 0.5129, 0.5136,
        0.5172, 0.5216, 0.5136, 0.5165, 0.5190, 0.5232, 0.5223],
       device='cuda:0') torch.Size([16])
percent tensor([0.5733, 0.4433, 0.7141, 0.7183, 0.7343, 0.6778, 0.5689, 0.6928, 0.6101,
        0.5208, 0.4570, 0.6240, 0.4617, 0.5257, 0.5392, 0.6189],
       device='cuda:0') torch.Size([16])
percent tensor([0.6955, 0.7314, 0.6016, 0.6250, 0.6146, 0.5476, 0.6960, 0.6347, 0.7039,
        0.7261, 0.7518, 0.6830, 0.7100, 0.7482, 0.6770, 0.6597],
       device='cuda:0') torch.Size([16])
percent tensor([0.7359, 0.6322, 0.7489, 0.7388, 0.7632, 0.8196, 0.7240, 0.7284, 0.6925,
        0.6413, 0.5907, 0.6364, 0.6138, 0.6662, 0.7071, 0.7861],
       device='cuda:0') torch.Size([16])
percent tensor([0.5970, 0.7267, 0.7434, 0.7829, 0.7334, 0.7820, 0.6867, 0.5609, 0.7334,
        0.7057, 0.7540, 0.7174, 0.7057, 0.7468, 0.5604, 0.5630],
       device='cuda:0') torch.Size([16])
percent tensor([0.4935, 0.7321, 0.6803, 0.7072, 0.6492, 0.6473, 0.6581, 0.5973, 0.6865,
        0.6582, 0.7612, 0.6790, 0.6477, 0.7037, 0.5760, 0.4357],
       device='cuda:0') torch.Size([16])
percent tensor([0.9997, 0.9998, 0.9998, 0.9999, 0.9999, 0.9997, 0.9999, 0.9997, 0.9997,
        0.9998, 0.9997, 0.9999, 0.9996, 0.9995, 0.9999, 0.9996],
       device='cuda:0') torch.Size([16])
Epoch: 154 | Batch_idx: 0 |  Loss: (0.0592) |  Loss2: (0.0000) | Acc: (98.00%) (126/128)
Epoch: 154 | Batch_idx: 10 |  Loss: (0.1084) |  Loss2: (0.0000) | Acc: (96.00%) (1355/1408)
Epoch: 154 | Batch_idx: 20 |  Loss: (0.1204) |  Loss2: (0.0000) | Acc: (95.00%) (2576/2688)
Epoch: 154 | Batch_idx: 30 |  Loss: (0.1236) |  Loss2: (0.0000) | Acc: (95.00%) (3802/3968)
Epoch: 154 | Batch_idx: 40 |  Loss: (0.1235) |  Loss2: (0.0000) | Acc: (95.00%) (5026/5248)
Epoch: 154 | Batch_idx: 50 |  Loss: (0.1220) |  Loss2: (0.0000) | Acc: (95.00%) (6253/6528)
Epoch: 154 | Batch_idx: 60 |  Loss: (0.1203) |  Loss2: (0.0000) | Acc: (95.00%) (7484/7808)
Epoch: 154 | Batch_idx: 70 |  Loss: (0.1209) |  Loss2: (0.0000) | Acc: (95.00%) (8712/9088)
Epoch: 154 | Batch_idx: 80 |  Loss: (0.1176) |  Loss2: (0.0000) | Acc: (95.00%) (9947/10368)
Epoch: 154 | Batch_idx: 90 |  Loss: (0.1167) |  Loss2: (0.0000) | Acc: (95.00%) (11181/11648)
Epoch: 154 | Batch_idx: 100 |  Loss: (0.1176) |  Loss2: (0.0000) | Acc: (95.00%) (12404/12928)
Epoch: 154 | Batch_idx: 110 |  Loss: (0.1177) |  Loss2: (0.0000) | Acc: (95.00%) (13634/14208)
Epoch: 154 | Batch_idx: 120 |  Loss: (0.1176) |  Loss2: (0.0000) | Acc: (95.00%) (14859/15488)
Epoch: 154 | Batch_idx: 130 |  Loss: (0.1171) |  Loss2: (0.0000) | Acc: (95.00%) (16086/16768)
Epoch: 154 | Batch_idx: 140 |  Loss: (0.1163) |  Loss2: (0.0000) | Acc: (95.00%) (17319/18048)
Epoch: 154 | Batch_idx: 150 |  Loss: (0.1155) |  Loss2: (0.0000) | Acc: (96.00%) (18557/19328)
Epoch: 154 | Batch_idx: 160 |  Loss: (0.1150) |  Loss2: (0.0000) | Acc: (96.00%) (19794/20608)
Epoch: 154 | Batch_idx: 170 |  Loss: (0.1161) |  Loss2: (0.0000) | Acc: (96.00%) (21016/21888)
Epoch: 154 | Batch_idx: 180 |  Loss: (0.1164) |  Loss2: (0.0000) | Acc: (96.00%) (22242/23168)
Epoch: 154 | Batch_idx: 190 |  Loss: (0.1168) |  Loss2: (0.0000) | Acc: (95.00%) (23468/24448)
Epoch: 154 | Batch_idx: 200 |  Loss: (0.1171) |  Loss2: (0.0000) | Acc: (95.00%) (24688/25728)
Epoch: 154 | Batch_idx: 210 |  Loss: (0.1175) |  Loss2: (0.0000) | Acc: (95.00%) (25916/27008)
Epoch: 154 | Batch_idx: 220 |  Loss: (0.1177) |  Loss2: (0.0000) | Acc: (95.00%) (27143/28288)
Epoch: 154 | Batch_idx: 230 |  Loss: (0.1171) |  Loss2: (0.0000) | Acc: (95.00%) (28376/29568)
Epoch: 154 | Batch_idx: 240 |  Loss: (0.1166) |  Loss2: (0.0000) | Acc: (95.00%) (29608/30848)
Epoch: 154 | Batch_idx: 250 |  Loss: (0.1158) |  Loss2: (0.0000) | Acc: (96.00%) (30849/32128)
Epoch: 154 | Batch_idx: 260 |  Loss: (0.1156) |  Loss2: (0.0000) | Acc: (96.00%) (32082/33408)
Epoch: 154 | Batch_idx: 270 |  Loss: (0.1155) |  Loss2: (0.0000) | Acc: (96.00%) (33303/34688)
Epoch: 154 | Batch_idx: 280 |  Loss: (0.1152) |  Loss2: (0.0000) | Acc: (96.00%) (34539/35968)
Epoch: 154 | Batch_idx: 290 |  Loss: (0.1155) |  Loss2: (0.0000) | Acc: (96.00%) (35766/37248)
Epoch: 154 | Batch_idx: 300 |  Loss: (0.1150) |  Loss2: (0.0000) | Acc: (96.00%) (36998/38528)
Epoch: 154 | Batch_idx: 310 |  Loss: (0.1150) |  Loss2: (0.0000) | Acc: (96.00%) (38224/39808)
Epoch: 154 | Batch_idx: 320 |  Loss: (0.1147) |  Loss2: (0.0000) | Acc: (96.00%) (39457/41088)
Epoch: 154 | Batch_idx: 330 |  Loss: (0.1150) |  Loss2: (0.0000) | Acc: (96.00%) (40687/42368)
Epoch: 154 | Batch_idx: 340 |  Loss: (0.1150) |  Loss2: (0.0000) | Acc: (96.00%) (41917/43648)
Epoch: 154 | Batch_idx: 350 |  Loss: (0.1154) |  Loss2: (0.0000) | Acc: (96.00%) (43141/44928)
Epoch: 154 | Batch_idx: 360 |  Loss: (0.1151) |  Loss2: (0.0000) | Acc: (96.00%) (44376/46208)
Epoch: 154 | Batch_idx: 370 |  Loss: (0.1150) |  Loss2: (0.0000) | Acc: (96.00%) (45610/47488)
Epoch: 154 | Batch_idx: 380 |  Loss: (0.1148) |  Loss2: (0.0000) | Acc: (96.00%) (46835/48768)
Epoch: 154 | Batch_idx: 390 |  Loss: (0.1149) |  Loss2: (0.0000) | Acc: (96.00%) (48018/50000)
# TEST : Loss: (0.3899) | Acc: (88.00%) (8879/10000)
percent tensor([0.5724, 0.5846, 0.5721, 0.5723, 0.5779, 0.5890, 0.5844, 0.5671, 0.5706,
        0.5756, 0.5789, 0.5769, 0.5745, 0.5708, 0.5894, 0.5776],
       device='cuda:0') torch.Size([16])
percent tensor([0.5197, 0.5198, 0.5130, 0.5195, 0.5122, 0.5284, 0.5143, 0.5129, 0.5133,
        0.5170, 0.5212, 0.5138, 0.5162, 0.5185, 0.5227, 0.5219],
       device='cuda:0') torch.Size([16])
percent tensor([0.5751, 0.4383, 0.7179, 0.7240, 0.7365, 0.6863, 0.5683, 0.6957, 0.6062,
        0.5151, 0.4483, 0.6211, 0.4534, 0.5269, 0.5410, 0.6235],
       device='cuda:0') torch.Size([16])
percent tensor([0.6999, 0.7350, 0.6065, 0.6313, 0.6199, 0.5564, 0.6996, 0.6400, 0.7084,
        0.7313, 0.7550, 0.6865, 0.7136, 0.7517, 0.6826, 0.6667],
       device='cuda:0') torch.Size([16])
percent tensor([0.7298, 0.6279, 0.7412, 0.7311, 0.7565, 0.8180, 0.7174, 0.7179, 0.6857,
        0.6323, 0.5832, 0.6263, 0.6081, 0.6619, 0.6982, 0.7821],
       device='cuda:0') torch.Size([16])
percent tensor([0.6173, 0.7517, 0.7562, 0.7995, 0.7534, 0.7934, 0.7103, 0.5880, 0.7568,
        0.7316, 0.7750, 0.7404, 0.7310, 0.7667, 0.5910, 0.5870],
       device='cuda:0') torch.Size([16])
percent tensor([0.4653, 0.7295, 0.6746, 0.7034, 0.6462, 0.6189, 0.6457, 0.5877, 0.6855,
        0.6571, 0.7618, 0.6650, 0.6354, 0.6988, 0.5564, 0.4110],
       device='cuda:0') torch.Size([16])
percent tensor([0.9998, 0.9998, 0.9998, 0.9999, 0.9999, 0.9996, 0.9999, 0.9997, 0.9997,
        0.9999, 0.9997, 0.9999, 0.9996, 0.9996, 0.9998, 0.9997],
       device='cuda:0') torch.Size([16])
Epoch: 155 | Batch_idx: 0 |  Loss: (0.1394) |  Loss2: (0.0000) | Acc: (93.00%) (120/128)
Epoch: 155 | Batch_idx: 10 |  Loss: (0.1210) |  Loss2: (0.0000) | Acc: (96.00%) (1353/1408)
Epoch: 155 | Batch_idx: 20 |  Loss: (0.1195) |  Loss2: (0.0000) | Acc: (96.00%) (2590/2688)
Epoch: 155 | Batch_idx: 30 |  Loss: (0.1158) |  Loss2: (0.0000) | Acc: (96.00%) (3826/3968)
Epoch: 155 | Batch_idx: 40 |  Loss: (0.1159) |  Loss2: (0.0000) | Acc: (96.00%) (5057/5248)
Epoch: 155 | Batch_idx: 50 |  Loss: (0.1139) |  Loss2: (0.0000) | Acc: (96.00%) (6296/6528)
Epoch: 155 | Batch_idx: 60 |  Loss: (0.1143) |  Loss2: (0.0000) | Acc: (96.00%) (7523/7808)
Epoch: 155 | Batch_idx: 70 |  Loss: (0.1121) |  Loss2: (0.0000) | Acc: (96.00%) (8759/9088)
Epoch: 155 | Batch_idx: 80 |  Loss: (0.1116) |  Loss2: (0.0000) | Acc: (96.00%) (9988/10368)
Epoch: 155 | Batch_idx: 90 |  Loss: (0.1106) |  Loss2: (0.0000) | Acc: (96.00%) (11228/11648)
Epoch: 155 | Batch_idx: 100 |  Loss: (0.1116) |  Loss2: (0.0000) | Acc: (96.00%) (12454/12928)
Epoch: 155 | Batch_idx: 110 |  Loss: (0.1124) |  Loss2: (0.0000) | Acc: (96.00%) (13680/14208)
Epoch: 155 | Batch_idx: 120 |  Loss: (0.1129) |  Loss2: (0.0000) | Acc: (96.00%) (14901/15488)
Epoch: 155 | Batch_idx: 130 |  Loss: (0.1124) |  Loss2: (0.0000) | Acc: (96.00%) (16137/16768)
Epoch: 155 | Batch_idx: 140 |  Loss: (0.1125) |  Loss2: (0.0000) | Acc: (96.00%) (17366/18048)
Epoch: 155 | Batch_idx: 150 |  Loss: (0.1121) |  Loss2: (0.0000) | Acc: (96.00%) (18599/19328)
Epoch: 155 | Batch_idx: 160 |  Loss: (0.1117) |  Loss2: (0.0000) | Acc: (96.00%) (19835/20608)
Epoch: 155 | Batch_idx: 170 |  Loss: (0.1120) |  Loss2: (0.0000) | Acc: (96.00%) (21066/21888)
Epoch: 155 | Batch_idx: 180 |  Loss: (0.1125) |  Loss2: (0.0000) | Acc: (96.00%) (22298/23168)
Epoch: 155 | Batch_idx: 190 |  Loss: (0.1128) |  Loss2: (0.0000) | Acc: (96.00%) (23529/24448)
Epoch: 155 | Batch_idx: 200 |  Loss: (0.1124) |  Loss2: (0.0000) | Acc: (96.00%) (24767/25728)
Epoch: 155 | Batch_idx: 210 |  Loss: (0.1111) |  Loss2: (0.0000) | Acc: (96.00%) (26016/27008)
Epoch: 155 | Batch_idx: 220 |  Loss: (0.1116) |  Loss2: (0.0000) | Acc: (96.00%) (27242/28288)
Epoch: 155 | Batch_idx: 230 |  Loss: (0.1120) |  Loss2: (0.0000) | Acc: (96.00%) (28469/29568)
Epoch: 155 | Batch_idx: 240 |  Loss: (0.1122) |  Loss2: (0.0000) | Acc: (96.00%) (29695/30848)
Epoch: 155 | Batch_idx: 250 |  Loss: (0.1122) |  Loss2: (0.0000) | Acc: (96.00%) (30926/32128)
Epoch: 155 | Batch_idx: 260 |  Loss: (0.1119) |  Loss2: (0.0000) | Acc: (96.00%) (32157/33408)
Epoch: 155 | Batch_idx: 270 |  Loss: (0.1117) |  Loss2: (0.0000) | Acc: (96.00%) (33394/34688)
Epoch: 155 | Batch_idx: 280 |  Loss: (0.1113) |  Loss2: (0.0000) | Acc: (96.00%) (34633/35968)
Epoch: 155 | Batch_idx: 290 |  Loss: (0.1119) |  Loss2: (0.0000) | Acc: (96.00%) (35862/37248)
Epoch: 155 | Batch_idx: 300 |  Loss: (0.1119) |  Loss2: (0.0000) | Acc: (96.00%) (37088/38528)
Epoch: 155 | Batch_idx: 310 |  Loss: (0.1115) |  Loss2: (0.0000) | Acc: (96.00%) (38329/39808)
Epoch: 155 | Batch_idx: 320 |  Loss: (0.1114) |  Loss2: (0.0000) | Acc: (96.00%) (39561/41088)
Epoch: 155 | Batch_idx: 330 |  Loss: (0.1111) |  Loss2: (0.0000) | Acc: (96.00%) (40796/42368)
Epoch: 155 | Batch_idx: 340 |  Loss: (0.1115) |  Loss2: (0.0000) | Acc: (96.00%) (42021/43648)
Epoch: 155 | Batch_idx: 350 |  Loss: (0.1121) |  Loss2: (0.0000) | Acc: (96.00%) (43249/44928)
Epoch: 155 | Batch_idx: 360 |  Loss: (0.1117) |  Loss2: (0.0000) | Acc: (96.00%) (44491/46208)
Epoch: 155 | Batch_idx: 370 |  Loss: (0.1111) |  Loss2: (0.0000) | Acc: (96.00%) (45736/47488)
Epoch: 155 | Batch_idx: 380 |  Loss: (0.1108) |  Loss2: (0.0000) | Acc: (96.00%) (46970/48768)
Epoch: 155 | Batch_idx: 390 |  Loss: (0.1110) |  Loss2: (0.0000) | Acc: (96.00%) (48151/50000)
=> saving checkpoint 'drive/app/torch/save_Schedule/checkpoint_155.pth.tar'
# TEST : Loss: (0.3800) | Acc: (89.00%) (8907/10000)
percent tensor([0.5735, 0.5852, 0.5727, 0.5732, 0.5787, 0.5899, 0.5851, 0.5680, 0.5716,
        0.5764, 0.5799, 0.5776, 0.5758, 0.5711, 0.5902, 0.5785],
       device='cuda:0') torch.Size([16])
percent tensor([0.5197, 0.5201, 0.5134, 0.5194, 0.5126, 0.5283, 0.5146, 0.5130, 0.5134,
        0.5173, 0.5212, 0.5141, 0.5164, 0.5185, 0.5226, 0.5221],
       device='cuda:0') torch.Size([16])
percent tensor([0.5816, 0.4475, 0.7196, 0.7266, 0.7374, 0.6905, 0.5747, 0.6967, 0.6111,
        0.5227, 0.4567, 0.6240, 0.4598, 0.5396, 0.5468, 0.6314],
       device='cuda:0') torch.Size([16])
percent tensor([0.7012, 0.7362, 0.6068, 0.6340, 0.6195, 0.5593, 0.7000, 0.6395, 0.7096,
        0.7345, 0.7567, 0.6871, 0.7157, 0.7535, 0.6833, 0.6699],
       device='cuda:0') torch.Size([16])
percent tensor([0.7363, 0.6333, 0.7500, 0.7408, 0.7664, 0.8237, 0.7258, 0.7274, 0.6925,
        0.6348, 0.5877, 0.6346, 0.6112, 0.6658, 0.7060, 0.7900],
       device='cuda:0') torch.Size([16])
percent tensor([0.5946, 0.7381, 0.7398, 0.7877, 0.7374, 0.7820, 0.6920, 0.5660, 0.7450,
        0.7131, 0.7640, 0.7254, 0.7184, 0.7489, 0.5685, 0.5606],
       device='cuda:0') torch.Size([16])
percent tensor([0.4671, 0.7404, 0.6799, 0.7130, 0.6515, 0.6218, 0.6529, 0.5867, 0.6990,
        0.6701, 0.7762, 0.6700, 0.6443, 0.7094, 0.5592, 0.4082],
       device='cuda:0') torch.Size([16])
percent tensor([0.9997, 0.9998, 0.9998, 0.9999, 0.9999, 0.9995, 0.9999, 0.9997, 0.9997,
        0.9998, 0.9997, 0.9999, 0.9996, 0.9996, 0.9998, 0.9996],
       device='cuda:0') torch.Size([16])
True Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=128, out_features=16, bias=False)
False Linear(in_features=16, out_features=2, bias=False)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=128, out_features=16, bias=False)
False Linear(in_features=16, out_features=2, bias=False)
True Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=256, out_features=32, bias=False)
False Linear(in_features=32, out_features=2, bias=False)
True Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=256, out_features=32, bias=False)
False Linear(in_features=32, out_features=2, bias=False)
True Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=512, out_features=64, bias=False)
False Linear(in_features=64, out_features=2, bias=False)
True Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=512, out_features=64, bias=False)
False Linear(in_features=64, out_features=2, bias=False)
True Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1024, out_features=128, bias=False)
False Linear(in_features=128, out_features=2, bias=False)
True Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1024, out_features=128, bias=False)
False Linear(in_features=128, out_features=2, bias=False)
True Linear(in_features=512, out_features=10, bias=True)
Epoch: 156 | Batch_idx: 0 |  Loss: (0.0659) |  Loss2: (0.0000) | Acc: (98.00%) (126/128)
Epoch: 156 | Batch_idx: 10 |  Loss: (0.0997) |  Loss2: (0.0000) | Acc: (96.00%) (1362/1408)
Epoch: 156 | Batch_idx: 20 |  Loss: (0.0941) |  Loss2: (0.0000) | Acc: (96.00%) (2607/2688)
Epoch: 156 | Batch_idx: 30 |  Loss: (0.0958) |  Loss2: (0.0000) | Acc: (96.00%) (3843/3968)
Epoch: 156 | Batch_idx: 40 |  Loss: (0.1034) |  Loss2: (0.0000) | Acc: (96.00%) (5061/5248)
Epoch: 156 | Batch_idx: 50 |  Loss: (0.1098) |  Loss2: (0.0000) | Acc: (96.00%) (6279/6528)
Epoch: 156 | Batch_idx: 60 |  Loss: (0.1097) |  Loss2: (0.0000) | Acc: (96.00%) (7502/7808)
Epoch: 156 | Batch_idx: 70 |  Loss: (0.1085) |  Loss2: (0.0000) | Acc: (96.00%) (8741/9088)
Epoch: 156 | Batch_idx: 80 |  Loss: (0.1096) |  Loss2: (0.0000) | Acc: (96.00%) (9965/10368)
Epoch: 156 | Batch_idx: 90 |  Loss: (0.1103) |  Loss2: (0.0000) | Acc: (96.00%) (11198/11648)
Epoch: 156 | Batch_idx: 100 |  Loss: (0.1115) |  Loss2: (0.0000) | Acc: (96.00%) (12430/12928)
Epoch: 156 | Batch_idx: 110 |  Loss: (0.1110) |  Loss2: (0.0000) | Acc: (96.00%) (13664/14208)
Epoch: 156 | Batch_idx: 120 |  Loss: (0.1118) |  Loss2: (0.0000) | Acc: (96.00%) (14884/15488)
Epoch: 156 | Batch_idx: 130 |  Loss: (0.1104) |  Loss2: (0.0000) | Acc: (96.00%) (16128/16768)
Epoch: 156 | Batch_idx: 140 |  Loss: (0.1118) |  Loss2: (0.0000) | Acc: (96.00%) (17345/18048)
Epoch: 156 | Batch_idx: 150 |  Loss: (0.1117) |  Loss2: (0.0000) | Acc: (96.00%) (18576/19328)
Epoch: 156 | Batch_idx: 160 |  Loss: (0.1122) |  Loss2: (0.0000) | Acc: (96.00%) (19799/20608)
Epoch: 156 | Batch_idx: 170 |  Loss: (0.1119) |  Loss2: (0.0000) | Acc: (96.00%) (21027/21888)
Epoch: 156 | Batch_idx: 180 |  Loss: (0.1124) |  Loss2: (0.0000) | Acc: (96.00%) (22249/23168)
Epoch: 156 | Batch_idx: 190 |  Loss: (0.1136) |  Loss2: (0.0000) | Acc: (96.00%) (23474/24448)
Epoch: 156 | Batch_idx: 200 |  Loss: (0.1141) |  Loss2: (0.0000) | Acc: (96.00%) (24702/25728)
Epoch: 156 | Batch_idx: 210 |  Loss: (0.1142) |  Loss2: (0.0000) | Acc: (95.00%) (25927/27008)
Epoch: 156 | Batch_idx: 220 |  Loss: (0.1147) |  Loss2: (0.0000) | Acc: (95.00%) (27150/28288)
Epoch: 156 | Batch_idx: 230 |  Loss: (0.1147) |  Loss2: (0.0000) | Acc: (95.00%) (28379/29568)
Epoch: 156 | Batch_idx: 240 |  Loss: (0.1141) |  Loss2: (0.0000) | Acc: (96.00%) (29619/30848)
Epoch: 156 | Batch_idx: 250 |  Loss: (0.1139) |  Loss2: (0.0000) | Acc: (96.00%) (30846/32128)
Epoch: 156 | Batch_idx: 260 |  Loss: (0.1138) |  Loss2: (0.0000) | Acc: (96.00%) (32074/33408)
Epoch: 156 | Batch_idx: 270 |  Loss: (0.1141) |  Loss2: (0.0000) | Acc: (96.00%) (33301/34688)
Epoch: 156 | Batch_idx: 280 |  Loss: (0.1151) |  Loss2: (0.0000) | Acc: (95.00%) (34507/35968)
Epoch: 156 | Batch_idx: 290 |  Loss: (0.1158) |  Loss2: (0.0000) | Acc: (95.00%) (35731/37248)
Epoch: 156 | Batch_idx: 300 |  Loss: (0.1162) |  Loss2: (0.0000) | Acc: (95.00%) (36961/38528)
Epoch: 156 | Batch_idx: 310 |  Loss: (0.1163) |  Loss2: (0.0000) | Acc: (95.00%) (38188/39808)
Epoch: 156 | Batch_idx: 320 |  Loss: (0.1166) |  Loss2: (0.0000) | Acc: (95.00%) (39406/41088)
Epoch: 156 | Batch_idx: 330 |  Loss: (0.1169) |  Loss2: (0.0000) | Acc: (95.00%) (40636/42368)
Epoch: 156 | Batch_idx: 340 |  Loss: (0.1169) |  Loss2: (0.0000) | Acc: (95.00%) (41862/43648)
Epoch: 156 | Batch_idx: 350 |  Loss: (0.1171) |  Loss2: (0.0000) | Acc: (95.00%) (43099/44928)
Epoch: 156 | Batch_idx: 360 |  Loss: (0.1173) |  Loss2: (0.0000) | Acc: (95.00%) (44328/46208)
Epoch: 156 | Batch_idx: 370 |  Loss: (0.1172) |  Loss2: (0.0000) | Acc: (95.00%) (45557/47488)
Epoch: 156 | Batch_idx: 380 |  Loss: (0.1171) |  Loss2: (0.0000) | Acc: (95.00%) (46784/48768)
Epoch: 156 | Batch_idx: 390 |  Loss: (0.1171) |  Loss2: (0.0000) | Acc: (95.00%) (47971/50000)
# TEST : Loss: (0.4004) | Acc: (88.00%) (8851/10000)
percent tensor([0.5740, 0.5849, 0.5729, 0.5730, 0.5789, 0.5906, 0.5853, 0.5676, 0.5702,
        0.5770, 0.5804, 0.5795, 0.5754, 0.5678, 0.5912, 0.5783],
       device='cuda:0') torch.Size([16])
percent tensor([0.5197, 0.5192, 0.5138, 0.5196, 0.5124, 0.5279, 0.5139, 0.5129, 0.5139,
        0.5165, 0.5203, 0.5137, 0.5160, 0.5184, 0.5217, 0.5213],
       device='cuda:0') torch.Size([16])
percent tensor([0.5754, 0.4489, 0.7012, 0.7207, 0.7277, 0.6846, 0.5696, 0.6809, 0.6155,
        0.5096, 0.4564, 0.6105, 0.4501, 0.5531, 0.5441, 0.6289],
       device='cuda:0') torch.Size([16])
percent tensor([0.7030, 0.7358, 0.6202, 0.6455, 0.6265, 0.5682, 0.7029, 0.6483, 0.7095,
        0.7347, 0.7564, 0.6926, 0.7153, 0.7486, 0.6889, 0.6728],
       device='cuda:0') torch.Size([16])
percent tensor([0.7377, 0.6311, 0.7502, 0.7386, 0.7655, 0.8181, 0.7261, 0.7374, 0.6929,
        0.6364, 0.5869, 0.6342, 0.6124, 0.6597, 0.7021, 0.7857],
       device='cuda:0') torch.Size([16])
percent tensor([0.5917, 0.7272, 0.7128, 0.7601, 0.7293, 0.7998, 0.6919, 0.5255, 0.7427,
        0.6949, 0.7611, 0.7102, 0.7203, 0.7527, 0.5631, 0.5412],
       device='cuda:0') torch.Size([16])
percent tensor([0.4867, 0.7167, 0.6609, 0.6643, 0.6483, 0.6613, 0.6776, 0.5722, 0.6922,
        0.6673, 0.7657, 0.6481, 0.6315, 0.7018, 0.5685, 0.4061],
       device='cuda:0') torch.Size([16])
percent tensor([0.9998, 0.9998, 0.9997, 0.9998, 1.0000, 0.9995, 0.9999, 0.9997, 0.9998,
        0.9999, 0.9998, 0.9999, 0.9996, 0.9996, 0.9998, 0.9997],
       device='cuda:0') torch.Size([16])
Epoch: 157 | Batch_idx: 0 |  Loss: (0.0952) |  Loss2: (0.0000) | Acc: (97.00%) (125/128)
Epoch: 157 | Batch_idx: 10 |  Loss: (0.1122) |  Loss2: (0.0000) | Acc: (95.00%) (1348/1408)
Epoch: 157 | Batch_idx: 20 |  Loss: (0.1090) |  Loss2: (0.0000) | Acc: (96.00%) (2584/2688)
Epoch: 157 | Batch_idx: 30 |  Loss: (0.1067) |  Loss2: (0.0000) | Acc: (96.00%) (3821/3968)
Epoch: 157 | Batch_idx: 40 |  Loss: (0.1040) |  Loss2: (0.0000) | Acc: (96.00%) (5062/5248)
Epoch: 157 | Batch_idx: 50 |  Loss: (0.1079) |  Loss2: (0.0000) | Acc: (96.00%) (6284/6528)
Epoch: 157 | Batch_idx: 60 |  Loss: (0.1071) |  Loss2: (0.0000) | Acc: (96.00%) (7522/7808)
Epoch: 157 | Batch_idx: 70 |  Loss: (0.1046) |  Loss2: (0.0000) | Acc: (96.00%) (8764/9088)
Epoch: 157 | Batch_idx: 80 |  Loss: (0.1049) |  Loss2: (0.0000) | Acc: (96.00%) (9994/10368)
Epoch: 157 | Batch_idx: 90 |  Loss: (0.1066) |  Loss2: (0.0000) | Acc: (96.00%) (11222/11648)
Epoch: 157 | Batch_idx: 100 |  Loss: (0.1058) |  Loss2: (0.0000) | Acc: (96.00%) (12458/12928)
Epoch: 157 | Batch_idx: 110 |  Loss: (0.1045) |  Loss2: (0.0000) | Acc: (96.00%) (13700/14208)
Epoch: 157 | Batch_idx: 120 |  Loss: (0.1045) |  Loss2: (0.0000) | Acc: (96.00%) (14937/15488)
Epoch: 157 | Batch_idx: 130 |  Loss: (0.1060) |  Loss2: (0.0000) | Acc: (96.00%) (16151/16768)
Epoch: 157 | Batch_idx: 140 |  Loss: (0.1052) |  Loss2: (0.0000) | Acc: (96.00%) (17397/18048)
Epoch: 157 | Batch_idx: 150 |  Loss: (0.1050) |  Loss2: (0.0000) | Acc: (96.00%) (18639/19328)
Epoch: 157 | Batch_idx: 160 |  Loss: (0.1047) |  Loss2: (0.0000) | Acc: (96.00%) (19872/20608)
Epoch: 157 | Batch_idx: 170 |  Loss: (0.1051) |  Loss2: (0.0000) | Acc: (96.00%) (21103/21888)
Epoch: 157 | Batch_idx: 180 |  Loss: (0.1053) |  Loss2: (0.0000) | Acc: (96.00%) (22331/23168)
Epoch: 157 | Batch_idx: 190 |  Loss: (0.1055) |  Loss2: (0.0000) | Acc: (96.00%) (23567/24448)
Epoch: 157 | Batch_idx: 200 |  Loss: (0.1050) |  Loss2: (0.0000) | Acc: (96.00%) (24801/25728)
Epoch: 157 | Batch_idx: 210 |  Loss: (0.1049) |  Loss2: (0.0000) | Acc: (96.00%) (26036/27008)
Epoch: 157 | Batch_idx: 220 |  Loss: (0.1058) |  Loss2: (0.0000) | Acc: (96.00%) (27264/28288)
Epoch: 157 | Batch_idx: 230 |  Loss: (0.1067) |  Loss2: (0.0000) | Acc: (96.00%) (28482/29568)
Epoch: 157 | Batch_idx: 240 |  Loss: (0.1076) |  Loss2: (0.0000) | Acc: (96.00%) (29698/30848)
Epoch: 157 | Batch_idx: 250 |  Loss: (0.1084) |  Loss2: (0.0000) | Acc: (96.00%) (30926/32128)
Epoch: 157 | Batch_idx: 260 |  Loss: (0.1090) |  Loss2: (0.0000) | Acc: (96.00%) (32142/33408)
Epoch: 157 | Batch_idx: 270 |  Loss: (0.1093) |  Loss2: (0.0000) | Acc: (96.00%) (33371/34688)
Epoch: 157 | Batch_idx: 280 |  Loss: (0.1089) |  Loss2: (0.0000) | Acc: (96.00%) (34606/35968)
Epoch: 157 | Batch_idx: 290 |  Loss: (0.1095) |  Loss2: (0.0000) | Acc: (96.00%) (35830/37248)
Epoch: 157 | Batch_idx: 300 |  Loss: (0.1098) |  Loss2: (0.0000) | Acc: (96.00%) (37064/38528)
Epoch: 157 | Batch_idx: 310 |  Loss: (0.1099) |  Loss2: (0.0000) | Acc: (96.00%) (38297/39808)
Epoch: 157 | Batch_idx: 320 |  Loss: (0.1106) |  Loss2: (0.0000) | Acc: (96.00%) (39510/41088)
Epoch: 157 | Batch_idx: 330 |  Loss: (0.1112) |  Loss2: (0.0000) | Acc: (96.00%) (40734/42368)
Epoch: 157 | Batch_idx: 340 |  Loss: (0.1118) |  Loss2: (0.0000) | Acc: (96.00%) (41958/43648)
Epoch: 157 | Batch_idx: 350 |  Loss: (0.1117) |  Loss2: (0.0000) | Acc: (96.00%) (43190/44928)
Epoch: 157 | Batch_idx: 360 |  Loss: (0.1122) |  Loss2: (0.0000) | Acc: (96.00%) (44413/46208)
Epoch: 157 | Batch_idx: 370 |  Loss: (0.1120) |  Loss2: (0.0000) | Acc: (96.00%) (45643/47488)
Epoch: 157 | Batch_idx: 380 |  Loss: (0.1125) |  Loss2: (0.0000) | Acc: (96.00%) (46860/48768)
Epoch: 157 | Batch_idx: 390 |  Loss: (0.1131) |  Loss2: (0.0000) | Acc: (96.00%) (48036/50000)
# TEST : Loss: (0.3770) | Acc: (88.00%) (8877/10000)
percent tensor([0.5734, 0.5853, 0.5696, 0.5728, 0.5768, 0.5915, 0.5848, 0.5674, 0.5703,
        0.5758, 0.5804, 0.5763, 0.5754, 0.5686, 0.5915, 0.5785],
       device='cuda:0') torch.Size([16])
percent tensor([0.5200, 0.5198, 0.5136, 0.5193, 0.5130, 0.5287, 0.5144, 0.5127, 0.5132,
        0.5169, 0.5208, 0.5141, 0.5160, 0.5186, 0.5224, 0.5214],
       device='cuda:0') torch.Size([16])
percent tensor([0.5797, 0.4538, 0.7213, 0.7261, 0.7319, 0.6738, 0.5699, 0.6858, 0.6183,
        0.5218, 0.4705, 0.6385, 0.4688, 0.5389, 0.5328, 0.6289],
       device='cuda:0') torch.Size([16])
percent tensor([0.6999, 0.7412, 0.6179, 0.6443, 0.6251, 0.5538, 0.7055, 0.6494, 0.7123,
        0.7350, 0.7573, 0.6943, 0.7155, 0.7531, 0.6821, 0.6703],
       device='cuda:0') torch.Size([16])
percent tensor([0.7366, 0.6268, 0.7575, 0.7432, 0.7705, 0.8247, 0.7238, 0.7385, 0.6988,
        0.6337, 0.5961, 0.6375, 0.6142, 0.6537, 0.7119, 0.7913],
       device='cuda:0') torch.Size([16])
percent tensor([0.5958, 0.7137, 0.7241, 0.7658, 0.7300, 0.8221, 0.6731, 0.5129, 0.7336,
        0.6962, 0.7650, 0.7231, 0.7237, 0.7476, 0.5563, 0.5408],
       device='cuda:0') torch.Size([16])
percent tensor([0.4608, 0.7120, 0.6462, 0.6677, 0.6401, 0.6985, 0.6272, 0.5693, 0.6682,
        0.6628, 0.7527, 0.6421, 0.6374, 0.6873, 0.5627, 0.4114],
       device='cuda:0') torch.Size([16])
percent tensor([0.9997, 0.9996, 0.9997, 0.9999, 0.9999, 0.9992, 0.9998, 0.9998, 0.9997,
        0.9999, 0.9996, 0.9999, 0.9994, 0.9997, 0.9997, 0.9995],
       device='cuda:0') torch.Size([16])
Epoch: 158 | Batch_idx: 0 |  Loss: (0.0613) |  Loss2: (0.0000) | Acc: (98.00%) (126/128)
Epoch: 158 | Batch_idx: 10 |  Loss: (0.0881) |  Loss2: (0.0000) | Acc: (96.00%) (1363/1408)
Epoch: 158 | Batch_idx: 20 |  Loss: (0.0984) |  Loss2: (0.0000) | Acc: (96.00%) (2594/2688)
Epoch: 158 | Batch_idx: 30 |  Loss: (0.1011) |  Loss2: (0.0000) | Acc: (96.00%) (3827/3968)
Epoch: 158 | Batch_idx: 40 |  Loss: (0.0980) |  Loss2: (0.0000) | Acc: (96.00%) (5066/5248)
Epoch: 158 | Batch_idx: 50 |  Loss: (0.0988) |  Loss2: (0.0000) | Acc: (96.00%) (6303/6528)
Epoch: 158 | Batch_idx: 60 |  Loss: (0.0949) |  Loss2: (0.0000) | Acc: (96.00%) (7554/7808)
Epoch: 158 | Batch_idx: 70 |  Loss: (0.0959) |  Loss2: (0.0000) | Acc: (96.00%) (8783/9088)
Epoch: 158 | Batch_idx: 80 |  Loss: (0.0971) |  Loss2: (0.0000) | Acc: (96.00%) (10019/10368)
Epoch: 158 | Batch_idx: 90 |  Loss: (0.0975) |  Loss2: (0.0000) | Acc: (96.00%) (11255/11648)
Epoch: 158 | Batch_idx: 100 |  Loss: (0.0984) |  Loss2: (0.0000) | Acc: (96.00%) (12494/12928)
Epoch: 158 | Batch_idx: 110 |  Loss: (0.1009) |  Loss2: (0.0000) | Acc: (96.00%) (13719/14208)
Epoch: 158 | Batch_idx: 120 |  Loss: (0.1019) |  Loss2: (0.0000) | Acc: (96.00%) (14953/15488)
Epoch: 158 | Batch_idx: 130 |  Loss: (0.1020) |  Loss2: (0.0000) | Acc: (96.00%) (16189/16768)
Epoch: 158 | Batch_idx: 140 |  Loss: (0.1033) |  Loss2: (0.0000) | Acc: (96.00%) (17411/18048)
Epoch: 158 | Batch_idx: 150 |  Loss: (0.1051) |  Loss2: (0.0000) | Acc: (96.00%) (18640/19328)
Epoch: 158 | Batch_idx: 160 |  Loss: (0.1056) |  Loss2: (0.0000) | Acc: (96.00%) (19867/20608)
Epoch: 158 | Batch_idx: 170 |  Loss: (0.1045) |  Loss2: (0.0000) | Acc: (96.00%) (21108/21888)
Epoch: 158 | Batch_idx: 180 |  Loss: (0.1041) |  Loss2: (0.0000) | Acc: (96.00%) (22351/23168)
Epoch: 158 | Batch_idx: 190 |  Loss: (0.1043) |  Loss2: (0.0000) | Acc: (96.00%) (23587/24448)
Epoch: 158 | Batch_idx: 200 |  Loss: (0.1055) |  Loss2: (0.0000) | Acc: (96.00%) (24812/25728)
Epoch: 158 | Batch_idx: 210 |  Loss: (0.1048) |  Loss2: (0.0000) | Acc: (96.00%) (26056/27008)
Epoch: 158 | Batch_idx: 220 |  Loss: (0.1043) |  Loss2: (0.0000) | Acc: (96.00%) (27298/28288)
Epoch: 158 | Batch_idx: 230 |  Loss: (0.1043) |  Loss2: (0.0000) | Acc: (96.00%) (28531/29568)
Epoch: 158 | Batch_idx: 240 |  Loss: (0.1053) |  Loss2: (0.0000) | Acc: (96.00%) (29748/30848)
Epoch: 158 | Batch_idx: 250 |  Loss: (0.1058) |  Loss2: (0.0000) | Acc: (96.00%) (30978/32128)
Epoch: 158 | Batch_idx: 260 |  Loss: (0.1057) |  Loss2: (0.0000) | Acc: (96.00%) (32207/33408)
Epoch: 158 | Batch_idx: 270 |  Loss: (0.1065) |  Loss2: (0.0000) | Acc: (96.00%) (33424/34688)
Epoch: 158 | Batch_idx: 280 |  Loss: (0.1066) |  Loss2: (0.0000) | Acc: (96.00%) (34653/35968)
Epoch: 158 | Batch_idx: 290 |  Loss: (0.1065) |  Loss2: (0.0000) | Acc: (96.00%) (35885/37248)
Epoch: 158 | Batch_idx: 300 |  Loss: (0.1067) |  Loss2: (0.0000) | Acc: (96.00%) (37117/38528)
Epoch: 158 | Batch_idx: 310 |  Loss: (0.1066) |  Loss2: (0.0000) | Acc: (96.00%) (38352/39808)
Epoch: 158 | Batch_idx: 320 |  Loss: (0.1073) |  Loss2: (0.0000) | Acc: (96.00%) (39572/41088)
Epoch: 158 | Batch_idx: 330 |  Loss: (0.1073) |  Loss2: (0.0000) | Acc: (96.00%) (40804/42368)
Epoch: 158 | Batch_idx: 340 |  Loss: (0.1074) |  Loss2: (0.0000) | Acc: (96.00%) (42036/43648)
Epoch: 158 | Batch_idx: 350 |  Loss: (0.1072) |  Loss2: (0.0000) | Acc: (96.00%) (43274/44928)
Epoch: 158 | Batch_idx: 360 |  Loss: (0.1076) |  Loss2: (0.0000) | Acc: (96.00%) (44491/46208)
Epoch: 158 | Batch_idx: 370 |  Loss: (0.1075) |  Loss2: (0.0000) | Acc: (96.00%) (45729/47488)
Epoch: 158 | Batch_idx: 380 |  Loss: (0.1081) |  Loss2: (0.0000) | Acc: (96.00%) (46950/48768)
Epoch: 158 | Batch_idx: 390 |  Loss: (0.1082) |  Loss2: (0.0000) | Acc: (96.00%) (48140/50000)
# TEST : Loss: (0.3876) | Acc: (88.00%) (8846/10000)
percent tensor([0.5729, 0.5850, 0.5695, 0.5721, 0.5765, 0.5914, 0.5843, 0.5659, 0.5691,
        0.5759, 0.5802, 0.5761, 0.5746, 0.5691, 0.5917, 0.5782],
       device='cuda:0') torch.Size([16])
percent tensor([0.5201, 0.5196, 0.5151, 0.5205, 0.5134, 0.5283, 0.5149, 0.5139, 0.5141,
        0.5176, 0.5204, 0.5154, 0.5164, 0.5191, 0.5220, 0.5217],
       device='cuda:0') torch.Size([16])
percent tensor([0.5791, 0.4554, 0.7190, 0.7206, 0.7329, 0.6736, 0.5739, 0.6874, 0.6197,
        0.5253, 0.4684, 0.6319, 0.4640, 0.5496, 0.5339, 0.6191],
       device='cuda:0') torch.Size([16])
percent tensor([0.6995, 0.7347, 0.6229, 0.6486, 0.6279, 0.5529, 0.7026, 0.6515, 0.7174,
        0.7385, 0.7568, 0.6950, 0.7164, 0.7480, 0.6774, 0.6723],
       device='cuda:0') torch.Size([16])
percent tensor([0.7338, 0.6176, 0.7522, 0.7457, 0.7670, 0.8195, 0.7124, 0.7371, 0.6792,
        0.6185, 0.5832, 0.6404, 0.6025, 0.6584, 0.7071, 0.7765],
       device='cuda:0') torch.Size([16])
percent tensor([0.6166, 0.7386, 0.7270, 0.7691, 0.7266, 0.8016, 0.7029, 0.5441, 0.7353,
        0.7153, 0.7508, 0.7361, 0.7248, 0.7566, 0.5900, 0.5520],
       device='cuda:0') torch.Size([16])
percent tensor([0.4863, 0.7297, 0.6608, 0.6651, 0.6458, 0.6833, 0.6570, 0.5860, 0.6992,
        0.6663, 0.7378, 0.6698, 0.6378, 0.6912, 0.5853, 0.4179],
       device='cuda:0') torch.Size([16])
percent tensor([0.9997, 0.9997, 0.9999, 0.9999, 1.0000, 0.9992, 0.9999, 0.9998, 0.9998,
        0.9999, 0.9995, 0.9999, 0.9994, 0.9997, 0.9997, 0.9995],
       device='cuda:0') torch.Size([16])
False Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=128, out_features=16, bias=False)
True Linear(in_features=16, out_features=2, bias=False)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=128, out_features=16, bias=False)
True Linear(in_features=16, out_features=2, bias=False)
False Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=256, out_features=32, bias=False)
True Linear(in_features=32, out_features=2, bias=False)
False Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=256, out_features=32, bias=False)
True Linear(in_features=32, out_features=2, bias=False)
False Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=512, out_features=64, bias=False)
True Linear(in_features=64, out_features=2, bias=False)
False Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=512, out_features=64, bias=False)
True Linear(in_features=64, out_features=2, bias=False)
False Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1024, out_features=128, bias=False)
True Linear(in_features=128, out_features=2, bias=False)
False Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1024, out_features=128, bias=False)
True Linear(in_features=128, out_features=2, bias=False)
False Linear(in_features=512, out_features=10, bias=True)
Epoch: 159 | Batch_idx: 0 |  Loss: (0.1062) |  Loss2: (0.0000) | Acc: (96.00%) (123/128)
Epoch: 159 | Batch_idx: 10 |  Loss: (0.1299) |  Loss2: (0.0000) | Acc: (95.00%) (1341/1408)
Epoch: 159 | Batch_idx: 20 |  Loss: (0.1350) |  Loss2: (0.0000) | Acc: (94.00%) (2544/2688)
Epoch: 159 | Batch_idx: 30 |  Loss: (0.1444) |  Loss2: (0.0000) | Acc: (94.00%) (3747/3968)
Epoch: 159 | Batch_idx: 40 |  Loss: (0.1430) |  Loss2: (0.0000) | Acc: (94.00%) (4962/5248)
Epoch: 159 | Batch_idx: 50 |  Loss: (0.1503) |  Loss2: (0.0000) | Acc: (94.00%) (6165/6528)
Epoch: 159 | Batch_idx: 60 |  Loss: (0.1536) |  Loss2: (0.0000) | Acc: (94.00%) (7371/7808)
Epoch: 159 | Batch_idx: 70 |  Loss: (0.1541) |  Loss2: (0.0000) | Acc: (94.00%) (8585/9088)
Epoch: 159 | Batch_idx: 80 |  Loss: (0.1560) |  Loss2: (0.0000) | Acc: (94.00%) (9784/10368)
Epoch: 159 | Batch_idx: 90 |  Loss: (0.1558) |  Loss2: (0.0000) | Acc: (94.00%) (10992/11648)
Epoch: 159 | Batch_idx: 100 |  Loss: (0.1526) |  Loss2: (0.0000) | Acc: (94.00%) (12215/12928)
Epoch: 159 | Batch_idx: 110 |  Loss: (0.1543) |  Loss2: (0.0000) | Acc: (94.00%) (13416/14208)
Epoch: 159 | Batch_idx: 120 |  Loss: (0.1527) |  Loss2: (0.0000) | Acc: (94.00%) (14633/15488)
Epoch: 159 | Batch_idx: 130 |  Loss: (0.1523) |  Loss2: (0.0000) | Acc: (94.00%) (15849/16768)
Epoch: 159 | Batch_idx: 140 |  Loss: (0.1523) |  Loss2: (0.0000) | Acc: (94.00%) (17062/18048)
Epoch: 159 | Batch_idx: 150 |  Loss: (0.1527) |  Loss2: (0.0000) | Acc: (94.00%) (18273/19328)
Epoch: 159 | Batch_idx: 160 |  Loss: (0.1524) |  Loss2: (0.0000) | Acc: (94.00%) (19481/20608)
Epoch: 159 | Batch_idx: 170 |  Loss: (0.1512) |  Loss2: (0.0000) | Acc: (94.00%) (20700/21888)
Epoch: 159 | Batch_idx: 180 |  Loss: (0.1498) |  Loss2: (0.0000) | Acc: (94.00%) (21915/23168)
Epoch: 159 | Batch_idx: 190 |  Loss: (0.1499) |  Loss2: (0.0000) | Acc: (94.00%) (23126/24448)
Epoch: 159 | Batch_idx: 200 |  Loss: (0.1489) |  Loss2: (0.0000) | Acc: (94.00%) (24347/25728)
Epoch: 159 | Batch_idx: 210 |  Loss: (0.1485) |  Loss2: (0.0000) | Acc: (94.00%) (25564/27008)
Epoch: 159 | Batch_idx: 220 |  Loss: (0.1476) |  Loss2: (0.0000) | Acc: (94.00%) (26780/28288)
Epoch: 159 | Batch_idx: 230 |  Loss: (0.1465) |  Loss2: (0.0000) | Acc: (94.00%) (28010/29568)
Epoch: 159 | Batch_idx: 240 |  Loss: (0.1455) |  Loss2: (0.0000) | Acc: (94.00%) (29233/30848)
Epoch: 159 | Batch_idx: 250 |  Loss: (0.1449) |  Loss2: (0.0000) | Acc: (94.00%) (30462/32128)
Epoch: 159 | Batch_idx: 260 |  Loss: (0.1446) |  Loss2: (0.0000) | Acc: (94.00%) (31680/33408)
Epoch: 159 | Batch_idx: 270 |  Loss: (0.1441) |  Loss2: (0.0000) | Acc: (94.00%) (32896/34688)
Epoch: 159 | Batch_idx: 280 |  Loss: (0.1436) |  Loss2: (0.0000) | Acc: (94.00%) (34116/35968)
Epoch: 159 | Batch_idx: 290 |  Loss: (0.1427) |  Loss2: (0.0000) | Acc: (94.00%) (35344/37248)
Epoch: 159 | Batch_idx: 300 |  Loss: (0.1430) |  Loss2: (0.0000) | Acc: (94.00%) (36553/38528)
Epoch: 159 | Batch_idx: 310 |  Loss: (0.1425) |  Loss2: (0.0000) | Acc: (94.00%) (37778/39808)
Epoch: 159 | Batch_idx: 320 |  Loss: (0.1422) |  Loss2: (0.0000) | Acc: (94.00%) (38995/41088)
Epoch: 159 | Batch_idx: 330 |  Loss: (0.1412) |  Loss2: (0.0000) | Acc: (94.00%) (40224/42368)
Epoch: 159 | Batch_idx: 340 |  Loss: (0.1408) |  Loss2: (0.0000) | Acc: (94.00%) (41442/43648)
Epoch: 159 | Batch_idx: 350 |  Loss: (0.1402) |  Loss2: (0.0000) | Acc: (94.00%) (42672/44928)
Epoch: 159 | Batch_idx: 360 |  Loss: (0.1398) |  Loss2: (0.0000) | Acc: (94.00%) (43896/46208)
Epoch: 159 | Batch_idx: 370 |  Loss: (0.1393) |  Loss2: (0.0000) | Acc: (95.00%) (45118/47488)
Epoch: 159 | Batch_idx: 380 |  Loss: (0.1386) |  Loss2: (0.0000) | Acc: (95.00%) (46352/48768)
Epoch: 159 | Batch_idx: 390 |  Loss: (0.1386) |  Loss2: (0.0000) | Acc: (95.00%) (47520/50000)
# TEST : Loss: (0.3969) | Acc: (88.00%) (8814/10000)
percent tensor([0.5841, 0.5987, 0.5818, 0.5836, 0.5893, 0.6031, 0.5979, 0.5784, 0.5812,
        0.5886, 0.5924, 0.5895, 0.5866, 0.5813, 0.6044, 0.5902],
       device='cuda:0') torch.Size([16])
percent tensor([0.5158, 0.5160, 0.5110, 0.5154, 0.5088, 0.5227, 0.5112, 0.5095, 0.5106,
        0.5142, 0.5166, 0.5114, 0.5129, 0.5152, 0.5175, 0.5172],
       device='cuda:0') torch.Size([16])
percent tensor([0.5996, 0.4749, 0.7044, 0.7203, 0.7234, 0.6897, 0.5802, 0.6833, 0.6267,
        0.5330, 0.4879, 0.6213, 0.4861, 0.5516, 0.5641, 0.6420],
       device='cuda:0') torch.Size([16])
percent tensor([0.6698, 0.7117, 0.6015, 0.6122, 0.5997, 0.5334, 0.6750, 0.6192, 0.6900,
        0.7131, 0.7295, 0.6703, 0.6934, 0.7193, 0.6513, 0.6416],
       device='cuda:0') torch.Size([16])
percent tensor([0.7496, 0.6192, 0.7692, 0.7735, 0.7915, 0.8349, 0.7273, 0.7710, 0.6882,
        0.6133, 0.5826, 0.6450, 0.5924, 0.6780, 0.7166, 0.7963],
       device='cuda:0') torch.Size([16])
percent tensor([0.5866, 0.6977, 0.6868, 0.7390, 0.6793, 0.7769, 0.6749, 0.5030, 0.7077,
        0.6793, 0.7255, 0.7044, 0.6870, 0.7310, 0.5197, 0.5135],
       device='cuda:0') torch.Size([16])
percent tensor([0.4454, 0.7243, 0.6364, 0.6412, 0.6097, 0.6332, 0.6437, 0.5579, 0.7096,
        0.6660, 0.7382, 0.6754, 0.6274, 0.6722, 0.5542, 0.3746],
       device='cuda:0') torch.Size([16])
percent tensor([0.9998, 0.9998, 0.9999, 0.9998, 1.0000, 0.9988, 0.9999, 0.9998, 0.9998,
        0.9999, 0.9996, 0.9999, 0.9995, 0.9998, 0.9997, 0.9996],
       device='cuda:0') torch.Size([16])
Epoch: 160 | Batch_idx: 0 |  Loss: (0.0604) |  Loss2: (0.0000) | Acc: (96.00%) (124/128)
Epoch: 160 | Batch_idx: 10 |  Loss: (0.1272) |  Loss2: (0.0000) | Acc: (95.00%) (1343/1408)
Epoch: 160 | Batch_idx: 20 |  Loss: (0.1258) |  Loss2: (0.0000) | Acc: (95.00%) (2567/2688)
Epoch: 160 | Batch_idx: 30 |  Loss: (0.1213) |  Loss2: (0.0000) | Acc: (95.00%) (3793/3968)
Epoch: 160 | Batch_idx: 40 |  Loss: (0.1218) |  Loss2: (0.0000) | Acc: (95.00%) (5023/5248)
Epoch: 160 | Batch_idx: 50 |  Loss: (0.1270) |  Loss2: (0.0000) | Acc: (95.00%) (6237/6528)
Epoch: 160 | Batch_idx: 60 |  Loss: (0.1285) |  Loss2: (0.0000) | Acc: (95.00%) (7461/7808)
Epoch: 160 | Batch_idx: 70 |  Loss: (0.1275) |  Loss2: (0.0000) | Acc: (95.00%) (8684/9088)
Epoch: 160 | Batch_idx: 80 |  Loss: (0.1266) |  Loss2: (0.0000) | Acc: (95.00%) (9912/10368)
Epoch: 160 | Batch_idx: 90 |  Loss: (0.1258) |  Loss2: (0.0000) | Acc: (95.00%) (11139/11648)
Epoch: 160 | Batch_idx: 100 |  Loss: (0.1254) |  Loss2: (0.0000) | Acc: (95.00%) (12365/12928)
Epoch: 160 | Batch_idx: 110 |  Loss: (0.1258) |  Loss2: (0.0000) | Acc: (95.00%) (13584/14208)
Epoch: 160 | Batch_idx: 120 |  Loss: (0.1260) |  Loss2: (0.0000) | Acc: (95.00%) (14812/15488)
Epoch: 160 | Batch_idx: 130 |  Loss: (0.1250) |  Loss2: (0.0000) | Acc: (95.00%) (16040/16768)
Epoch: 160 | Batch_idx: 140 |  Loss: (0.1254) |  Loss2: (0.0000) | Acc: (95.00%) (17257/18048)
Epoch: 160 | Batch_idx: 150 |  Loss: (0.1267) |  Loss2: (0.0000) | Acc: (95.00%) (18473/19328)
Epoch: 160 | Batch_idx: 160 |  Loss: (0.1257) |  Loss2: (0.0000) | Acc: (95.00%) (19709/20608)
Epoch: 160 | Batch_idx: 170 |  Loss: (0.1257) |  Loss2: (0.0000) | Acc: (95.00%) (20933/21888)
Epoch: 160 | Batch_idx: 180 |  Loss: (0.1249) |  Loss2: (0.0000) | Acc: (95.00%) (22161/23168)
Epoch: 160 | Batch_idx: 190 |  Loss: (0.1247) |  Loss2: (0.0000) | Acc: (95.00%) (23395/24448)
Epoch: 160 | Batch_idx: 200 |  Loss: (0.1240) |  Loss2: (0.0000) | Acc: (95.00%) (24626/25728)
Epoch: 160 | Batch_idx: 210 |  Loss: (0.1231) |  Loss2: (0.0000) | Acc: (95.00%) (25858/27008)
Epoch: 160 | Batch_idx: 220 |  Loss: (0.1229) |  Loss2: (0.0000) | Acc: (95.00%) (27089/28288)
Epoch: 160 | Batch_idx: 230 |  Loss: (0.1228) |  Loss2: (0.0000) | Acc: (95.00%) (28312/29568)
Epoch: 160 | Batch_idx: 240 |  Loss: (0.1223) |  Loss2: (0.0000) | Acc: (95.00%) (29545/30848)
Epoch: 160 | Batch_idx: 250 |  Loss: (0.1219) |  Loss2: (0.0000) | Acc: (95.00%) (30777/32128)
Epoch: 160 | Batch_idx: 260 |  Loss: (0.1225) |  Loss2: (0.0000) | Acc: (95.00%) (31994/33408)
Epoch: 160 | Batch_idx: 270 |  Loss: (0.1219) |  Loss2: (0.0000) | Acc: (95.00%) (33233/34688)
Epoch: 160 | Batch_idx: 280 |  Loss: (0.1214) |  Loss2: (0.0000) | Acc: (95.00%) (34471/35968)
Epoch: 160 | Batch_idx: 290 |  Loss: (0.1217) |  Loss2: (0.0000) | Acc: (95.00%) (35694/37248)
Epoch: 160 | Batch_idx: 300 |  Loss: (0.1214) |  Loss2: (0.0000) | Acc: (95.00%) (36919/38528)
Epoch: 160 | Batch_idx: 310 |  Loss: (0.1210) |  Loss2: (0.0000) | Acc: (95.00%) (38148/39808)
Epoch: 160 | Batch_idx: 320 |  Loss: (0.1210) |  Loss2: (0.0000) | Acc: (95.00%) (39371/41088)
Epoch: 160 | Batch_idx: 330 |  Loss: (0.1205) |  Loss2: (0.0000) | Acc: (95.00%) (40603/42368)
Epoch: 160 | Batch_idx: 340 |  Loss: (0.1204) |  Loss2: (0.0000) | Acc: (95.00%) (41833/43648)
Epoch: 160 | Batch_idx: 350 |  Loss: (0.1203) |  Loss2: (0.0000) | Acc: (95.00%) (43056/44928)
Epoch: 160 | Batch_idx: 360 |  Loss: (0.1202) |  Loss2: (0.0000) | Acc: (95.00%) (44279/46208)
Epoch: 160 | Batch_idx: 370 |  Loss: (0.1198) |  Loss2: (0.0000) | Acc: (95.00%) (45515/47488)
Epoch: 160 | Batch_idx: 380 |  Loss: (0.1203) |  Loss2: (0.0000) | Acc: (95.00%) (46737/48768)
Epoch: 160 | Batch_idx: 390 |  Loss: (0.1198) |  Loss2: (0.0000) | Acc: (95.00%) (47930/50000)
=> saving checkpoint 'drive/app/torch/save_Schedule/checkpoint_160.pth.tar'
# TEST : Loss: (0.3843) | Acc: (88.00%) (8848/10000)
percent tensor([0.5783, 0.5917, 0.5770, 0.5782, 0.5838, 0.5966, 0.5912, 0.5730, 0.5757,
        0.5825, 0.5860, 0.5841, 0.5805, 0.5757, 0.5976, 0.5840],
       device='cuda:0') torch.Size([16])
percent tensor([0.5147, 0.5155, 0.5100, 0.5141, 0.5081, 0.5211, 0.5108, 0.5088, 0.5098,
        0.5137, 0.5158, 0.5105, 0.5124, 0.5148, 0.5162, 0.5165],
       device='cuda:0') torch.Size([16])
percent tensor([0.6051, 0.4737, 0.7129, 0.7255, 0.7308, 0.6965, 0.5828, 0.6910, 0.6364,
        0.5361, 0.4911, 0.6312, 0.4907, 0.5519, 0.5672, 0.6444],
       device='cuda:0') torch.Size([16])
percent tensor([0.6737, 0.7153, 0.5968, 0.6105, 0.5976, 0.5349, 0.6771, 0.6177, 0.6913,
        0.7158, 0.7326, 0.6686, 0.6987, 0.7223, 0.6525, 0.6467],
       device='cuda:0') torch.Size([16])
percent tensor([0.7534, 0.6269, 0.7735, 0.7802, 0.7960, 0.8383, 0.7317, 0.7769, 0.6973,
        0.6178, 0.5901, 0.6515, 0.5958, 0.6855, 0.7231, 0.8002],
       device='cuda:0') torch.Size([16])
percent tensor([0.6149, 0.7192, 0.7139, 0.7606, 0.7102, 0.7917, 0.6998, 0.5349, 0.7286,
        0.7036, 0.7426, 0.7224, 0.7038, 0.7501, 0.5490, 0.5448],
       device='cuda:0') torch.Size([16])
percent tensor([0.4663, 0.7543, 0.6680, 0.6661, 0.6330, 0.6528, 0.6800, 0.5838, 0.7356,
        0.7057, 0.7652, 0.7113, 0.6610, 0.7034, 0.5843, 0.3745],
       device='cuda:0') torch.Size([16])
percent tensor([0.9998, 0.9998, 0.9999, 0.9999, 1.0000, 0.9989, 0.9999, 0.9998, 0.9998,
        0.9999, 0.9996, 0.9999, 0.9996, 0.9998, 0.9997, 0.9996],
       device='cuda:0') torch.Size([16])
Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 3, 3, 3]) tensor(184.7378, device='cuda:0')
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(819.0020, device='cuda:0')
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(828.5452, device='cuda:0')
Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([128, 64, 3, 3]) tensor(1513.2969, device='cuda:0')
Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([128, 64, 1, 1]) tensor(489.2312, device='cuda:0')
Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([128, 128, 3, 3]) tensor(2270.3269, device='cuda:0')
Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([256, 128, 3, 3]) tensor(4276.4902, device='cuda:0')
Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([256, 128, 1, 1]) tensor(1372.3601, device='cuda:0')
Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([256, 256, 3, 3]) tensor(6226.6816, device='cuda:0')
Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([512, 256, 3, 3]) tensor(11673.1035, device='cuda:0')
Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([512, 256, 1, 1]) tensor(3852.5264, device='cuda:0')
Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([512, 512, 3, 3]) tensor(16234.9766, device='cuda:0')
Epoch: 161 | Batch_idx: 0 |  Loss: (0.1389) |  Loss2: (0.0000) | Acc: (95.00%) (122/128)
Epoch: 161 | Batch_idx: 10 |  Loss: (0.1093) |  Loss2: (0.0000) | Acc: (96.00%) (1356/1408)
Epoch: 161 | Batch_idx: 20 |  Loss: (0.1135) |  Loss2: (0.0000) | Acc: (96.00%) (2589/2688)
Epoch: 161 | Batch_idx: 30 |  Loss: (0.1141) |  Loss2: (0.0000) | Acc: (96.00%) (3824/3968)
Epoch: 161 | Batch_idx: 40 |  Loss: (0.1121) |  Loss2: (0.0000) | Acc: (96.00%) (5063/5248)
Epoch: 161 | Batch_idx: 50 |  Loss: (0.1106) |  Loss2: (0.0000) | Acc: (96.00%) (6297/6528)
Epoch: 161 | Batch_idx: 60 |  Loss: (0.1127) |  Loss2: (0.0000) | Acc: (96.00%) (7523/7808)
Epoch: 161 | Batch_idx: 70 |  Loss: (0.1144) |  Loss2: (0.0000) | Acc: (96.00%) (8750/9088)
Epoch: 161 | Batch_idx: 80 |  Loss: (0.1119) |  Loss2: (0.0000) | Acc: (96.00%) (9990/10368)
Epoch: 161 | Batch_idx: 90 |  Loss: (0.1105) |  Loss2: (0.0000) | Acc: (96.00%) (11217/11648)
Epoch: 161 | Batch_idx: 100 |  Loss: (0.1103) |  Loss2: (0.0000) | Acc: (96.00%) (12444/12928)
Epoch: 161 | Batch_idx: 110 |  Loss: (0.1104) |  Loss2: (0.0000) | Acc: (96.00%) (13678/14208)
Epoch: 161 | Batch_idx: 120 |  Loss: (0.1099) |  Loss2: (0.0000) | Acc: (96.00%) (14914/15488)
Epoch: 161 | Batch_idx: 130 |  Loss: (0.1104) |  Loss2: (0.0000) | Acc: (96.00%) (16143/16768)
Epoch: 161 | Batch_idx: 140 |  Loss: (0.1098) |  Loss2: (0.0000) | Acc: (96.00%) (17380/18048)
Epoch: 161 | Batch_idx: 150 |  Loss: (0.1099) |  Loss2: (0.0000) | Acc: (96.00%) (18610/19328)
Epoch: 161 | Batch_idx: 160 |  Loss: (0.1103) |  Loss2: (0.0000) | Acc: (96.00%) (19838/20608)
Epoch: 161 | Batch_idx: 170 |  Loss: (0.1100) |  Loss2: (0.0000) | Acc: (96.00%) (21069/21888)
Epoch: 161 | Batch_idx: 180 |  Loss: (0.1105) |  Loss2: (0.0000) | Acc: (96.00%) (22295/23168)
Epoch: 161 | Batch_idx: 190 |  Loss: (0.1100) |  Loss2: (0.0000) | Acc: (96.00%) (23531/24448)
Epoch: 161 | Batch_idx: 200 |  Loss: (0.1095) |  Loss2: (0.0000) | Acc: (96.00%) (24770/25728)
Epoch: 161 | Batch_idx: 210 |  Loss: (0.1091) |  Loss2: (0.0000) | Acc: (96.00%) (26010/27008)
Epoch: 161 | Batch_idx: 220 |  Loss: (0.1088) |  Loss2: (0.0000) | Acc: (96.00%) (27250/28288)
Epoch: 161 | Batch_idx: 230 |  Loss: (0.1088) |  Loss2: (0.0000) | Acc: (96.00%) (28483/29568)
Epoch: 161 | Batch_idx: 240 |  Loss: (0.1090) |  Loss2: (0.0000) | Acc: (96.00%) (29714/30848)
Epoch: 161 | Batch_idx: 250 |  Loss: (0.1085) |  Loss2: (0.0000) | Acc: (96.00%) (30953/32128)
Epoch: 161 | Batch_idx: 260 |  Loss: (0.1082) |  Loss2: (0.0000) | Acc: (96.00%) (32192/33408)
Epoch: 161 | Batch_idx: 270 |  Loss: (0.1076) |  Loss2: (0.0000) | Acc: (96.00%) (33436/34688)
Epoch: 161 | Batch_idx: 280 |  Loss: (0.1071) |  Loss2: (0.0000) | Acc: (96.00%) (34671/35968)
Epoch: 161 | Batch_idx: 290 |  Loss: (0.1068) |  Loss2: (0.0000) | Acc: (96.00%) (35912/37248)
Epoch: 161 | Batch_idx: 300 |  Loss: (0.1066) |  Loss2: (0.0000) | Acc: (96.00%) (37150/38528)
Epoch: 161 | Batch_idx: 310 |  Loss: (0.1075) |  Loss2: (0.0000) | Acc: (96.00%) (38368/39808)
Epoch: 161 | Batch_idx: 320 |  Loss: (0.1071) |  Loss2: (0.0000) | Acc: (96.00%) (39607/41088)
Epoch: 161 | Batch_idx: 330 |  Loss: (0.1070) |  Loss2: (0.0000) | Acc: (96.00%) (40839/42368)
Epoch: 161 | Batch_idx: 340 |  Loss: (0.1072) |  Loss2: (0.0000) | Acc: (96.00%) (42067/43648)
Epoch: 161 | Batch_idx: 350 |  Loss: (0.1072) |  Loss2: (0.0000) | Acc: (96.00%) (43308/44928)
Epoch: 161 | Batch_idx: 360 |  Loss: (0.1066) |  Loss2: (0.0000) | Acc: (96.00%) (44545/46208)
Epoch: 161 | Batch_idx: 370 |  Loss: (0.1069) |  Loss2: (0.0000) | Acc: (96.00%) (45774/47488)
Epoch: 161 | Batch_idx: 380 |  Loss: (0.1067) |  Loss2: (0.0000) | Acc: (96.00%) (47005/48768)
Epoch: 161 | Batch_idx: 390 |  Loss: (0.1069) |  Loss2: (0.0000) | Acc: (96.00%) (48187/50000)
# TEST : Loss: (0.3787) | Acc: (88.00%) (8862/10000)
percent tensor([0.5796, 0.5930, 0.5791, 0.5796, 0.5857, 0.5970, 0.5928, 0.5752, 0.5775,
        0.5844, 0.5873, 0.5864, 0.5821, 0.5772, 0.5985, 0.5851],
       device='cuda:0') torch.Size([16])
percent tensor([0.5149, 0.5159, 0.5101, 0.5141, 0.5086, 0.5209, 0.5116, 0.5094, 0.5101,
        0.5141, 0.5161, 0.5107, 0.5133, 0.5155, 0.5163, 0.5167],
       device='cuda:0') torch.Size([16])
percent tensor([0.5972, 0.4673, 0.7115, 0.7217, 0.7300, 0.6907, 0.5775, 0.6887, 0.6337,
        0.5316, 0.4856, 0.6285, 0.4858, 0.5443, 0.5598, 0.6346],
       device='cuda:0') torch.Size([16])
percent tensor([0.6775, 0.7192, 0.5978, 0.6122, 0.5999, 0.5367, 0.6801, 0.6200, 0.6944,
        0.7191, 0.7364, 0.6710, 0.7031, 0.7254, 0.6555, 0.6500],
       device='cuda:0') torch.Size([16])
percent tensor([0.7570, 0.6320, 0.7769, 0.7843, 0.7973, 0.8422, 0.7352, 0.7799, 0.7003,
        0.6210, 0.5932, 0.6568, 0.6026, 0.6872, 0.7290, 0.8026],
       device='cuda:0') torch.Size([16])
percent tensor([0.6132, 0.7131, 0.7132, 0.7573, 0.7083, 0.7931, 0.6955, 0.5290, 0.7242,
        0.6992, 0.7371, 0.7171, 0.6987, 0.7454, 0.5399, 0.5441],
       device='cuda:0') torch.Size([16])
percent tensor([0.4633, 0.7510, 0.6713, 0.6698, 0.6356, 0.6562, 0.6755, 0.5832, 0.7321,
        0.7059, 0.7652, 0.7088, 0.6552, 0.7050, 0.5796, 0.3712],
       device='cuda:0') torch.Size([16])
percent tensor([0.9998, 0.9998, 0.9999, 0.9999, 1.0000, 0.9990, 0.9999, 0.9998, 0.9998,
        0.9999, 0.9996, 0.9999, 0.9996, 0.9997, 0.9997, 0.9996],
       device='cuda:0') torch.Size([16])
True Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=128, out_features=16, bias=False)
False Linear(in_features=16, out_features=2, bias=False)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=128, out_features=16, bias=False)
False Linear(in_features=16, out_features=2, bias=False)
True Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=256, out_features=32, bias=False)
False Linear(in_features=32, out_features=2, bias=False)
True Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=256, out_features=32, bias=False)
False Linear(in_features=32, out_features=2, bias=False)
True Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=512, out_features=64, bias=False)
False Linear(in_features=64, out_features=2, bias=False)
True Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=512, out_features=64, bias=False)
False Linear(in_features=64, out_features=2, bias=False)
True Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1024, out_features=128, bias=False)
False Linear(in_features=128, out_features=2, bias=False)
True Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1024, out_features=128, bias=False)
False Linear(in_features=128, out_features=2, bias=False)
True Linear(in_features=512, out_features=10, bias=True)
Epoch: 162 | Batch_idx: 0 |  Loss: (0.1172) |  Loss2: (0.0000) | Acc: (98.00%) (126/128)
Epoch: 162 | Batch_idx: 10 |  Loss: (0.0893) |  Loss2: (0.0000) | Acc: (97.00%) (1374/1408)
Epoch: 162 | Batch_idx: 20 |  Loss: (0.0946) |  Loss2: (0.0000) | Acc: (97.00%) (2612/2688)
Epoch: 162 | Batch_idx: 30 |  Loss: (0.0928) |  Loss2: (0.0000) | Acc: (97.00%) (3853/3968)
Epoch: 162 | Batch_idx: 40 |  Loss: (0.0954) |  Loss2: (0.0000) | Acc: (96.00%) (5090/5248)
Epoch: 162 | Batch_idx: 50 |  Loss: (0.0976) |  Loss2: (0.0000) | Acc: (96.00%) (6324/6528)
Epoch: 162 | Batch_idx: 60 |  Loss: (0.0987) |  Loss2: (0.0000) | Acc: (96.00%) (7566/7808)
Epoch: 162 | Batch_idx: 70 |  Loss: (0.1028) |  Loss2: (0.0000) | Acc: (96.00%) (8788/9088)
Epoch: 162 | Batch_idx: 80 |  Loss: (0.1025) |  Loss2: (0.0000) | Acc: (96.00%) (10031/10368)
Epoch: 162 | Batch_idx: 90 |  Loss: (0.1032) |  Loss2: (0.0000) | Acc: (96.00%) (11265/11648)
Epoch: 162 | Batch_idx: 100 |  Loss: (0.1028) |  Loss2: (0.0000) | Acc: (96.00%) (12504/12928)
Epoch: 162 | Batch_idx: 110 |  Loss: (0.1050) |  Loss2: (0.0000) | Acc: (96.00%) (13724/14208)
Epoch: 162 | Batch_idx: 120 |  Loss: (0.1061) |  Loss2: (0.0000) | Acc: (96.00%) (14944/15488)
Epoch: 162 | Batch_idx: 130 |  Loss: (0.1059) |  Loss2: (0.0000) | Acc: (96.00%) (16182/16768)
Epoch: 162 | Batch_idx: 140 |  Loss: (0.1066) |  Loss2: (0.0000) | Acc: (96.00%) (17411/18048)
Epoch: 162 | Batch_idx: 150 |  Loss: (0.1069) |  Loss2: (0.0000) | Acc: (96.00%) (18641/19328)
Epoch: 162 | Batch_idx: 160 |  Loss: (0.1075) |  Loss2: (0.0000) | Acc: (96.00%) (19869/20608)
Epoch: 162 | Batch_idx: 170 |  Loss: (0.1076) |  Loss2: (0.0000) | Acc: (96.00%) (21096/21888)
Epoch: 162 | Batch_idx: 180 |  Loss: (0.1079) |  Loss2: (0.0000) | Acc: (96.00%) (22318/23168)
Epoch: 162 | Batch_idx: 190 |  Loss: (0.1077) |  Loss2: (0.0000) | Acc: (96.00%) (23555/24448)
Epoch: 162 | Batch_idx: 200 |  Loss: (0.1073) |  Loss2: (0.0000) | Acc: (96.00%) (24785/25728)
Epoch: 162 | Batch_idx: 210 |  Loss: (0.1085) |  Loss2: (0.0000) | Acc: (96.00%) (26009/27008)
Epoch: 162 | Batch_idx: 220 |  Loss: (0.1090) |  Loss2: (0.0000) | Acc: (96.00%) (27235/28288)
Epoch: 162 | Batch_idx: 230 |  Loss: (0.1092) |  Loss2: (0.0000) | Acc: (96.00%) (28472/29568)
Epoch: 162 | Batch_idx: 240 |  Loss: (0.1098) |  Loss2: (0.0000) | Acc: (96.00%) (29697/30848)
Epoch: 162 | Batch_idx: 250 |  Loss: (0.1104) |  Loss2: (0.0000) | Acc: (96.00%) (30926/32128)
Epoch: 162 | Batch_idx: 260 |  Loss: (0.1105) |  Loss2: (0.0000) | Acc: (96.00%) (32157/33408)
Epoch: 162 | Batch_idx: 270 |  Loss: (0.1104) |  Loss2: (0.0000) | Acc: (96.00%) (33395/34688)
Epoch: 162 | Batch_idx: 280 |  Loss: (0.1106) |  Loss2: (0.0000) | Acc: (96.00%) (34618/35968)
Epoch: 162 | Batch_idx: 290 |  Loss: (0.1107) |  Loss2: (0.0000) | Acc: (96.00%) (35847/37248)
Epoch: 162 | Batch_idx: 300 |  Loss: (0.1108) |  Loss2: (0.0000) | Acc: (96.00%) (37081/38528)
Epoch: 162 | Batch_idx: 310 |  Loss: (0.1105) |  Loss2: (0.0000) | Acc: (96.00%) (38310/39808)
Epoch: 162 | Batch_idx: 320 |  Loss: (0.1109) |  Loss2: (0.0000) | Acc: (96.00%) (39528/41088)
Epoch: 162 | Batch_idx: 330 |  Loss: (0.1108) |  Loss2: (0.0000) | Acc: (96.00%) (40764/42368)
Epoch: 162 | Batch_idx: 340 |  Loss: (0.1108) |  Loss2: (0.0000) | Acc: (96.00%) (41989/43648)
Epoch: 162 | Batch_idx: 350 |  Loss: (0.1104) |  Loss2: (0.0000) | Acc: (96.00%) (43224/44928)
Epoch: 162 | Batch_idx: 360 |  Loss: (0.1104) |  Loss2: (0.0000) | Acc: (96.00%) (44456/46208)
Epoch: 162 | Batch_idx: 370 |  Loss: (0.1106) |  Loss2: (0.0000) | Acc: (96.00%) (45679/47488)
Epoch: 162 | Batch_idx: 380 |  Loss: (0.1107) |  Loss2: (0.0000) | Acc: (96.00%) (46915/48768)
Epoch: 162 | Batch_idx: 390 |  Loss: (0.1112) |  Loss2: (0.0000) | Acc: (96.00%) (48092/50000)
# TEST : Loss: (0.4713) | Acc: (86.00%) (8659/10000)
percent tensor([0.5801, 0.5914, 0.5797, 0.5796, 0.5874, 0.5983, 0.5931, 0.5756, 0.5784,
        0.5837, 0.5872, 0.5871, 0.5824, 0.5756, 0.5984, 0.5855],
       device='cuda:0') torch.Size([16])
percent tensor([0.5147, 0.5157, 0.5094, 0.5145, 0.5090, 0.5215, 0.5110, 0.5091, 0.5093,
        0.5135, 0.5158, 0.5101, 0.5128, 0.5150, 0.5164, 0.5166],
       device='cuda:0') torch.Size([16])
percent tensor([0.5761, 0.4592, 0.7130, 0.7230, 0.7272, 0.6654, 0.5673, 0.6957, 0.6257,
        0.5271, 0.4730, 0.6380, 0.4800, 0.5506, 0.5364, 0.6251],
       device='cuda:0') torch.Size([16])
percent tensor([0.6812, 0.7187, 0.5886, 0.6129, 0.5955, 0.5452, 0.6803, 0.6197, 0.6901,
        0.7168, 0.7388, 0.6631, 0.7027, 0.7274, 0.6578, 0.6482],
       device='cuda:0') torch.Size([16])
percent tensor([0.7527, 0.6303, 0.7941, 0.7810, 0.8057, 0.8419, 0.7407, 0.7729, 0.7060,
        0.6307, 0.5900, 0.6630, 0.6096, 0.6683, 0.7238, 0.8075],
       device='cuda:0') torch.Size([16])
percent tensor([0.5809, 0.7222, 0.7158, 0.7504, 0.7362, 0.7896, 0.6881, 0.5015, 0.7111,
        0.7043, 0.7293, 0.7164, 0.7115, 0.7484, 0.5501, 0.5370],
       device='cuda:0') torch.Size([16])
percent tensor([0.4256, 0.7506, 0.6195, 0.6455, 0.6286, 0.6353, 0.6575, 0.5487, 0.6549,
        0.7116, 0.7514, 0.6346, 0.6144, 0.7294, 0.5604, 0.3723],
       device='cuda:0') torch.Size([16])
percent tensor([0.9998, 0.9998, 0.9996, 0.9998, 0.9999, 0.9991, 0.9999, 0.9995, 0.9998,
        0.9999, 0.9996, 0.9998, 0.9996, 0.9995, 0.9996, 0.9996],
       device='cuda:0') torch.Size([16])
Epoch: 163 | Batch_idx: 0 |  Loss: (0.0963) |  Loss2: (0.0000) | Acc: (97.00%) (125/128)
Epoch: 163 | Batch_idx: 10 |  Loss: (0.0985) |  Loss2: (0.0000) | Acc: (96.00%) (1363/1408)
Epoch: 163 | Batch_idx: 20 |  Loss: (0.0952) |  Loss2: (0.0000) | Acc: (96.00%) (2604/2688)
Epoch: 163 | Batch_idx: 30 |  Loss: (0.1019) |  Loss2: (0.0000) | Acc: (96.00%) (3834/3968)
Epoch: 163 | Batch_idx: 40 |  Loss: (0.1050) |  Loss2: (0.0000) | Acc: (96.00%) (5064/5248)
Epoch: 163 | Batch_idx: 50 |  Loss: (0.1014) |  Loss2: (0.0000) | Acc: (96.00%) (6307/6528)
Epoch: 163 | Batch_idx: 60 |  Loss: (0.1018) |  Loss2: (0.0000) | Acc: (96.00%) (7540/7808)
Epoch: 163 | Batch_idx: 70 |  Loss: (0.1026) |  Loss2: (0.0000) | Acc: (96.00%) (8767/9088)
Epoch: 163 | Batch_idx: 80 |  Loss: (0.1011) |  Loss2: (0.0000) | Acc: (96.00%) (10004/10368)
Epoch: 163 | Batch_idx: 90 |  Loss: (0.1008) |  Loss2: (0.0000) | Acc: (96.00%) (11245/11648)
Epoch: 163 | Batch_idx: 100 |  Loss: (0.0999) |  Loss2: (0.0000) | Acc: (96.00%) (12493/12928)
Epoch: 163 | Batch_idx: 110 |  Loss: (0.1000) |  Loss2: (0.0000) | Acc: (96.00%) (13725/14208)
Epoch: 163 | Batch_idx: 120 |  Loss: (0.0989) |  Loss2: (0.0000) | Acc: (96.00%) (14970/15488)
Epoch: 163 | Batch_idx: 130 |  Loss: (0.0985) |  Loss2: (0.0000) | Acc: (96.00%) (16208/16768)
Epoch: 163 | Batch_idx: 140 |  Loss: (0.0982) |  Loss2: (0.0000) | Acc: (96.00%) (17443/18048)
Epoch: 163 | Batch_idx: 150 |  Loss: (0.0991) |  Loss2: (0.0000) | Acc: (96.00%) (18676/19328)
Epoch: 163 | Batch_idx: 160 |  Loss: (0.0995) |  Loss2: (0.0000) | Acc: (96.00%) (19904/20608)
Epoch: 163 | Batch_idx: 170 |  Loss: (0.1000) |  Loss2: (0.0000) | Acc: (96.00%) (21142/21888)
Epoch: 163 | Batch_idx: 180 |  Loss: (0.1012) |  Loss2: (0.0000) | Acc: (96.00%) (22363/23168)
Epoch: 163 | Batch_idx: 190 |  Loss: (0.1018) |  Loss2: (0.0000) | Acc: (96.00%) (23584/24448)
Epoch: 163 | Batch_idx: 200 |  Loss: (0.1023) |  Loss2: (0.0000) | Acc: (96.00%) (24818/25728)
Epoch: 163 | Batch_idx: 210 |  Loss: (0.1028) |  Loss2: (0.0000) | Acc: (96.00%) (26048/27008)
Epoch: 163 | Batch_idx: 220 |  Loss: (0.1029) |  Loss2: (0.0000) | Acc: (96.00%) (27281/28288)
Epoch: 163 | Batch_idx: 230 |  Loss: (0.1031) |  Loss2: (0.0000) | Acc: (96.00%) (28517/29568)
Epoch: 163 | Batch_idx: 240 |  Loss: (0.1034) |  Loss2: (0.0000) | Acc: (96.00%) (29746/30848)
Epoch: 163 | Batch_idx: 250 |  Loss: (0.1036) |  Loss2: (0.0000) | Acc: (96.00%) (30975/32128)
Epoch: 163 | Batch_idx: 260 |  Loss: (0.1038) |  Loss2: (0.0000) | Acc: (96.00%) (32210/33408)
Epoch: 163 | Batch_idx: 270 |  Loss: (0.1040) |  Loss2: (0.0000) | Acc: (96.00%) (33442/34688)
Epoch: 163 | Batch_idx: 280 |  Loss: (0.1039) |  Loss2: (0.0000) | Acc: (96.00%) (34680/35968)
Epoch: 163 | Batch_idx: 290 |  Loss: (0.1040) |  Loss2: (0.0000) | Acc: (96.00%) (35914/37248)
Epoch: 163 | Batch_idx: 300 |  Loss: (0.1046) |  Loss2: (0.0000) | Acc: (96.00%) (37139/38528)
Epoch: 163 | Batch_idx: 310 |  Loss: (0.1037) |  Loss2: (0.0000) | Acc: (96.00%) (38388/39808)
Epoch: 163 | Batch_idx: 320 |  Loss: (0.1036) |  Loss2: (0.0000) | Acc: (96.00%) (39629/41088)
Epoch: 163 | Batch_idx: 330 |  Loss: (0.1042) |  Loss2: (0.0000) | Acc: (96.00%) (40852/42368)
Epoch: 163 | Batch_idx: 340 |  Loss: (0.1043) |  Loss2: (0.0000) | Acc: (96.00%) (42080/43648)
Epoch: 163 | Batch_idx: 350 |  Loss: (0.1042) |  Loss2: (0.0000) | Acc: (96.00%) (43319/44928)
Epoch: 163 | Batch_idx: 360 |  Loss: (0.1045) |  Loss2: (0.0000) | Acc: (96.00%) (44547/46208)
Epoch: 163 | Batch_idx: 370 |  Loss: (0.1043) |  Loss2: (0.0000) | Acc: (96.00%) (45790/47488)
Epoch: 163 | Batch_idx: 380 |  Loss: (0.1045) |  Loss2: (0.0000) | Acc: (96.00%) (47020/48768)
Epoch: 163 | Batch_idx: 390 |  Loss: (0.1042) |  Loss2: (0.0000) | Acc: (96.00%) (48214/50000)
# TEST : Loss: (0.3871) | Acc: (89.00%) (8915/10000)
percent tensor([0.5808, 0.5916, 0.5820, 0.5791, 0.5882, 0.5976, 0.5931, 0.5760, 0.5786,
        0.5844, 0.5878, 0.5887, 0.5832, 0.5752, 0.5981, 0.5845],
       device='cuda:0') torch.Size([16])
percent tensor([0.5147, 0.5159, 0.5095, 0.5143, 0.5084, 0.5211, 0.5110, 0.5089, 0.5097,
        0.5139, 0.5164, 0.5102, 0.5135, 0.5145, 0.5165, 0.5169],
       device='cuda:0') torch.Size([16])
percent tensor([0.5671, 0.4485, 0.7051, 0.7173, 0.7263, 0.6716, 0.5664, 0.6907, 0.6150,
        0.5215, 0.4655, 0.6274, 0.4648, 0.5448, 0.5314, 0.6174],
       device='cuda:0') torch.Size([16])
percent tensor([0.6885, 0.7280, 0.5956, 0.6241, 0.5953, 0.5476, 0.6811, 0.6220, 0.6938,
        0.7240, 0.7437, 0.6717, 0.7084, 0.7308, 0.6636, 0.6578],
       device='cuda:0') torch.Size([16])
percent tensor([0.7375, 0.6235, 0.7725, 0.7629, 0.7930, 0.8297, 0.7453, 0.7583, 0.6960,
        0.6282, 0.5808, 0.6479, 0.6016, 0.6821, 0.7186, 0.7946],
       device='cuda:0') torch.Size([16])
percent tensor([0.5919, 0.7151, 0.7376, 0.7736, 0.7519, 0.7941, 0.7023, 0.5579, 0.7206,
        0.6869, 0.7192, 0.7189, 0.7119, 0.7282, 0.5483, 0.5731],
       device='cuda:0') torch.Size([16])
percent tensor([0.4687, 0.7413, 0.6867, 0.6591, 0.6520, 0.6414, 0.6731, 0.5981, 0.7177,
        0.6857, 0.7606, 0.6675, 0.6317, 0.7251, 0.5702, 0.3874],
       device='cuda:0') torch.Size([16])
percent tensor([0.9998, 0.9998, 0.9997, 0.9999, 1.0000, 0.9994, 0.9999, 0.9996, 0.9998,
        0.9998, 0.9996, 0.9999, 0.9995, 0.9997, 0.9998, 0.9996],
       device='cuda:0') torch.Size([16])
Epoch: 164 | Batch_idx: 0 |  Loss: (0.1059) |  Loss2: (0.0000) | Acc: (97.00%) (125/128)
Epoch: 164 | Batch_idx: 10 |  Loss: (0.0949) |  Loss2: (0.0000) | Acc: (96.00%) (1365/1408)
Epoch: 164 | Batch_idx: 20 |  Loss: (0.0978) |  Loss2: (0.0000) | Acc: (96.00%) (2604/2688)
Epoch: 164 | Batch_idx: 30 |  Loss: (0.0921) |  Loss2: (0.0000) | Acc: (97.00%) (3856/3968)
Epoch: 164 | Batch_idx: 40 |  Loss: (0.0921) |  Loss2: (0.0000) | Acc: (96.00%) (5090/5248)
Epoch: 164 | Batch_idx: 50 |  Loss: (0.0907) |  Loss2: (0.0000) | Acc: (96.00%) (6331/6528)
Epoch: 164 | Batch_idx: 60 |  Loss: (0.0905) |  Loss2: (0.0000) | Acc: (97.00%) (7575/7808)
Epoch: 164 | Batch_idx: 70 |  Loss: (0.0908) |  Loss2: (0.0000) | Acc: (97.00%) (8816/9088)
Epoch: 164 | Batch_idx: 80 |  Loss: (0.0956) |  Loss2: (0.0000) | Acc: (96.00%) (10037/10368)
Epoch: 164 | Batch_idx: 90 |  Loss: (0.0964) |  Loss2: (0.0000) | Acc: (96.00%) (11271/11648)
Epoch: 164 | Batch_idx: 100 |  Loss: (0.0969) |  Loss2: (0.0000) | Acc: (96.00%) (12503/12928)
Epoch: 164 | Batch_idx: 110 |  Loss: (0.0980) |  Loss2: (0.0000) | Acc: (96.00%) (13738/14208)
Epoch: 164 | Batch_idx: 120 |  Loss: (0.0988) |  Loss2: (0.0000) | Acc: (96.00%) (14973/15488)
Epoch: 164 | Batch_idx: 130 |  Loss: (0.1003) |  Loss2: (0.0000) | Acc: (96.00%) (16205/16768)
Epoch: 164 | Batch_idx: 140 |  Loss: (0.1002) |  Loss2: (0.0000) | Acc: (96.00%) (17445/18048)
Epoch: 164 | Batch_idx: 150 |  Loss: (0.1018) |  Loss2: (0.0000) | Acc: (96.00%) (18667/19328)
Epoch: 164 | Batch_idx: 160 |  Loss: (0.1003) |  Loss2: (0.0000) | Acc: (96.00%) (19913/20608)
Epoch: 164 | Batch_idx: 170 |  Loss: (0.1004) |  Loss2: (0.0000) | Acc: (96.00%) (21149/21888)
Epoch: 164 | Batch_idx: 180 |  Loss: (0.0997) |  Loss2: (0.0000) | Acc: (96.00%) (22393/23168)
Epoch: 164 | Batch_idx: 190 |  Loss: (0.1005) |  Loss2: (0.0000) | Acc: (96.00%) (23629/24448)
Epoch: 164 | Batch_idx: 200 |  Loss: (0.1011) |  Loss2: (0.0000) | Acc: (96.00%) (24859/25728)
Epoch: 164 | Batch_idx: 210 |  Loss: (0.1012) |  Loss2: (0.0000) | Acc: (96.00%) (26096/27008)
Epoch: 164 | Batch_idx: 220 |  Loss: (0.1020) |  Loss2: (0.0000) | Acc: (96.00%) (27322/28288)
Epoch: 164 | Batch_idx: 230 |  Loss: (0.1018) |  Loss2: (0.0000) | Acc: (96.00%) (28562/29568)
Epoch: 164 | Batch_idx: 240 |  Loss: (0.1028) |  Loss2: (0.0000) | Acc: (96.00%) (29778/30848)
Epoch: 164 | Batch_idx: 250 |  Loss: (0.1038) |  Loss2: (0.0000) | Acc: (96.00%) (30994/32128)
Epoch: 164 | Batch_idx: 260 |  Loss: (0.1037) |  Loss2: (0.0000) | Acc: (96.00%) (32226/33408)
Epoch: 164 | Batch_idx: 270 |  Loss: (0.1043) |  Loss2: (0.0000) | Acc: (96.00%) (33449/34688)
Epoch: 164 | Batch_idx: 280 |  Loss: (0.1047) |  Loss2: (0.0000) | Acc: (96.00%) (34671/35968)
Epoch: 164 | Batch_idx: 290 |  Loss: (0.1045) |  Loss2: (0.0000) | Acc: (96.00%) (35911/37248)
Epoch: 164 | Batch_idx: 300 |  Loss: (0.1044) |  Loss2: (0.0000) | Acc: (96.00%) (37143/38528)
Epoch: 164 | Batch_idx: 310 |  Loss: (0.1046) |  Loss2: (0.0000) | Acc: (96.00%) (38372/39808)
Epoch: 164 | Batch_idx: 320 |  Loss: (0.1053) |  Loss2: (0.0000) | Acc: (96.00%) (39593/41088)
Epoch: 164 | Batch_idx: 330 |  Loss: (0.1054) |  Loss2: (0.0000) | Acc: (96.00%) (40831/42368)
Epoch: 164 | Batch_idx: 340 |  Loss: (0.1053) |  Loss2: (0.0000) | Acc: (96.00%) (42066/43648)
Epoch: 164 | Batch_idx: 350 |  Loss: (0.1058) |  Loss2: (0.0000) | Acc: (96.00%) (43294/44928)
Epoch: 164 | Batch_idx: 360 |  Loss: (0.1054) |  Loss2: (0.0000) | Acc: (96.00%) (44535/46208)
Epoch: 164 | Batch_idx: 370 |  Loss: (0.1061) |  Loss2: (0.0000) | Acc: (96.00%) (45762/47488)
Epoch: 164 | Batch_idx: 380 |  Loss: (0.1063) |  Loss2: (0.0000) | Acc: (96.00%) (46986/48768)
Epoch: 164 | Batch_idx: 390 |  Loss: (0.1059) |  Loss2: (0.0000) | Acc: (96.00%) (48185/50000)
# TEST : Loss: (0.4214) | Acc: (88.00%) (8813/10000)
percent tensor([0.5811, 0.5919, 0.5831, 0.5795, 0.5881, 0.5971, 0.5930, 0.5767, 0.5789,
        0.5844, 0.5874, 0.5885, 0.5833, 0.5757, 0.5976, 0.5848],
       device='cuda:0') torch.Size([16])
percent tensor([0.5146, 0.5170, 0.5092, 0.5141, 0.5084, 0.5210, 0.5117, 0.5089, 0.5098,
        0.5145, 0.5166, 0.5108, 0.5136, 0.5158, 0.5171, 0.5168],
       device='cuda:0') torch.Size([16])
percent tensor([0.5896, 0.4530, 0.7330, 0.7230, 0.7449, 0.6846, 0.5848, 0.7029, 0.6285,
        0.5317, 0.4765, 0.6620, 0.4756, 0.5515, 0.5442, 0.6342],
       device='cuda:0') torch.Size([16])
percent tensor([0.6815, 0.7181, 0.5902, 0.6185, 0.5941, 0.5381, 0.6788, 0.6229, 0.6929,
        0.7187, 0.7390, 0.6706, 0.7023, 0.7313, 0.6566, 0.6553],
       device='cuda:0') torch.Size([16])
percent tensor([0.7451, 0.6438, 0.7733, 0.7630, 0.7856, 0.8458, 0.7422, 0.7565, 0.6960,
        0.6253, 0.5951, 0.6377, 0.6131, 0.6746, 0.7365, 0.7919],
       device='cuda:0') torch.Size([16])
percent tensor([0.5801, 0.7362, 0.7119, 0.7659, 0.7337, 0.7947, 0.6817, 0.5542, 0.7279,
        0.6958, 0.7427, 0.7170, 0.7290, 0.7305, 0.5675, 0.5408],
       device='cuda:0') torch.Size([16])
percent tensor([0.4308, 0.7343, 0.6675, 0.6606, 0.6443, 0.6175, 0.6300, 0.6087, 0.6825,
        0.6649, 0.7298, 0.6507, 0.6241, 0.6832, 0.5476, 0.3753],
       device='cuda:0') torch.Size([16])
percent tensor([0.9998, 0.9998, 0.9995, 0.9999, 0.9999, 0.9996, 0.9999, 0.9998, 0.9997,
        0.9999, 0.9996, 0.9999, 0.9995, 0.9997, 0.9998, 0.9997],
       device='cuda:0') torch.Size([16])
False Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=128, out_features=16, bias=False)
True Linear(in_features=16, out_features=2, bias=False)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=128, out_features=16, bias=False)
True Linear(in_features=16, out_features=2, bias=False)
False Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=256, out_features=32, bias=False)
True Linear(in_features=32, out_features=2, bias=False)
False Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=256, out_features=32, bias=False)
True Linear(in_features=32, out_features=2, bias=False)
False Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=512, out_features=64, bias=False)
True Linear(in_features=64, out_features=2, bias=False)
False Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=512, out_features=64, bias=False)
True Linear(in_features=64, out_features=2, bias=False)
False Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1024, out_features=128, bias=False)
True Linear(in_features=128, out_features=2, bias=False)
False Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1024, out_features=128, bias=False)
True Linear(in_features=128, out_features=2, bias=False)
False Linear(in_features=512, out_features=10, bias=True)
Epoch: 165 | Batch_idx: 0 |  Loss: (0.0802) |  Loss2: (0.0000) | Acc: (97.00%) (125/128)
Epoch: 165 | Batch_idx: 10 |  Loss: (0.0967) |  Loss2: (0.0000) | Acc: (96.00%) (1355/1408)
Epoch: 165 | Batch_idx: 20 |  Loss: (0.1171) |  Loss2: (0.0000) | Acc: (95.00%) (2577/2688)
Epoch: 165 | Batch_idx: 30 |  Loss: (0.1210) |  Loss2: (0.0000) | Acc: (95.00%) (3797/3968)
Epoch: 165 | Batch_idx: 40 |  Loss: (0.1227) |  Loss2: (0.0000) | Acc: (95.00%) (5021/5248)
Epoch: 165 | Batch_idx: 50 |  Loss: (0.1196) |  Loss2: (0.0000) | Acc: (95.00%) (6253/6528)
Epoch: 165 | Batch_idx: 60 |  Loss: (0.1184) |  Loss2: (0.0000) | Acc: (95.00%) (7489/7808)
Epoch: 165 | Batch_idx: 70 |  Loss: (0.1187) |  Loss2: (0.0000) | Acc: (95.00%) (8709/9088)
Epoch: 165 | Batch_idx: 80 |  Loss: (0.1193) |  Loss2: (0.0000) | Acc: (95.00%) (9934/10368)
Epoch: 165 | Batch_idx: 90 |  Loss: (0.1207) |  Loss2: (0.0000) | Acc: (95.00%) (11151/11648)
Epoch: 165 | Batch_idx: 100 |  Loss: (0.1200) |  Loss2: (0.0000) | Acc: (95.00%) (12379/12928)
Epoch: 165 | Batch_idx: 110 |  Loss: (0.1193) |  Loss2: (0.0000) | Acc: (95.00%) (13614/14208)
Epoch: 165 | Batch_idx: 120 |  Loss: (0.1178) |  Loss2: (0.0000) | Acc: (95.00%) (14852/15488)
Epoch: 165 | Batch_idx: 130 |  Loss: (0.1180) |  Loss2: (0.0000) | Acc: (95.00%) (16075/16768)
Epoch: 165 | Batch_idx: 140 |  Loss: (0.1171) |  Loss2: (0.0000) | Acc: (95.00%) (17310/18048)
Epoch: 165 | Batch_idx: 150 |  Loss: (0.1164) |  Loss2: (0.0000) | Acc: (95.00%) (18546/19328)
Epoch: 165 | Batch_idx: 160 |  Loss: (0.1155) |  Loss2: (0.0000) | Acc: (96.00%) (19784/20608)
Epoch: 165 | Batch_idx: 170 |  Loss: (0.1160) |  Loss2: (0.0000) | Acc: (95.00%) (21002/21888)
Epoch: 165 | Batch_idx: 180 |  Loss: (0.1168) |  Loss2: (0.0000) | Acc: (95.00%) (22227/23168)
Epoch: 165 | Batch_idx: 190 |  Loss: (0.1168) |  Loss2: (0.0000) | Acc: (95.00%) (23453/24448)
Epoch: 165 | Batch_idx: 200 |  Loss: (0.1158) |  Loss2: (0.0000) | Acc: (95.00%) (24690/25728)
Epoch: 165 | Batch_idx: 210 |  Loss: (0.1150) |  Loss2: (0.0000) | Acc: (96.00%) (25931/27008)
Epoch: 165 | Batch_idx: 220 |  Loss: (0.1149) |  Loss2: (0.0000) | Acc: (96.00%) (27161/28288)
Epoch: 165 | Batch_idx: 230 |  Loss: (0.1153) |  Loss2: (0.0000) | Acc: (96.00%) (28387/29568)
Epoch: 165 | Batch_idx: 240 |  Loss: (0.1153) |  Loss2: (0.0000) | Acc: (96.00%) (29620/30848)
Epoch: 165 | Batch_idx: 250 |  Loss: (0.1151) |  Loss2: (0.0000) | Acc: (96.00%) (30854/32128)
Epoch: 165 | Batch_idx: 260 |  Loss: (0.1143) |  Loss2: (0.0000) | Acc: (96.00%) (32094/33408)
Epoch: 165 | Batch_idx: 270 |  Loss: (0.1139) |  Loss2: (0.0000) | Acc: (96.00%) (33326/34688)
Epoch: 165 | Batch_idx: 280 |  Loss: (0.1141) |  Loss2: (0.0000) | Acc: (96.00%) (34548/35968)
Epoch: 165 | Batch_idx: 290 |  Loss: (0.1136) |  Loss2: (0.0000) | Acc: (96.00%) (35781/37248)
Epoch: 165 | Batch_idx: 300 |  Loss: (0.1130) |  Loss2: (0.0000) | Acc: (96.00%) (37019/38528)
Epoch: 165 | Batch_idx: 310 |  Loss: (0.1132) |  Loss2: (0.0000) | Acc: (96.00%) (38243/39808)
Epoch: 165 | Batch_idx: 320 |  Loss: (0.1134) |  Loss2: (0.0000) | Acc: (96.00%) (39475/41088)
Epoch: 165 | Batch_idx: 330 |  Loss: (0.1134) |  Loss2: (0.0000) | Acc: (96.00%) (40697/42368)
Epoch: 165 | Batch_idx: 340 |  Loss: (0.1135) |  Loss2: (0.0000) | Acc: (96.00%) (41925/43648)
Epoch: 165 | Batch_idx: 350 |  Loss: (0.1139) |  Loss2: (0.0000) | Acc: (96.00%) (43146/44928)
Epoch: 165 | Batch_idx: 360 |  Loss: (0.1138) |  Loss2: (0.0000) | Acc: (96.00%) (44376/46208)
Epoch: 165 | Batch_idx: 370 |  Loss: (0.1130) |  Loss2: (0.0000) | Acc: (96.00%) (45622/47488)
Epoch: 165 | Batch_idx: 380 |  Loss: (0.1129) |  Loss2: (0.0000) | Acc: (96.00%) (46858/48768)
Epoch: 165 | Batch_idx: 390 |  Loss: (0.1125) |  Loss2: (0.0000) | Acc: (96.00%) (48047/50000)
=> saving checkpoint 'drive/app/torch/save_Schedule/checkpoint_165.pth.tar'
# TEST : Loss: (0.3993) | Acc: (88.00%) (8874/10000)
percent tensor([0.5830, 0.5950, 0.5851, 0.5822, 0.5900, 0.5996, 0.5958, 0.5792, 0.5816,
        0.5867, 0.5897, 0.5906, 0.5856, 0.5795, 0.5998, 0.5874],
       device='cuda:0') torch.Size([16])
percent tensor([0.5175, 0.5209, 0.5109, 0.5164, 0.5098, 0.5236, 0.5146, 0.5115, 0.5124,
        0.5177, 0.5201, 0.5132, 0.5167, 0.5193, 0.5207, 0.5197],
       device='cuda:0') torch.Size([16])
percent tensor([0.5846, 0.4637, 0.7157, 0.7091, 0.7258, 0.6634, 0.5773, 0.6841, 0.6231,
        0.5434, 0.4901, 0.6533, 0.4864, 0.5477, 0.5409, 0.6299],
       device='cuda:0') torch.Size([16])
percent tensor([0.7163, 0.7516, 0.6234, 0.6522, 0.6305, 0.5744, 0.7128, 0.6583, 0.7231,
        0.7503, 0.7718, 0.7032, 0.7358, 0.7624, 0.6969, 0.6926],
       device='cuda:0') torch.Size([16])
percent tensor([0.7282, 0.6256, 0.7742, 0.7665, 0.7885, 0.8405, 0.7324, 0.7598, 0.6941,
        0.6097, 0.5757, 0.6400, 0.5962, 0.6658, 0.7149, 0.7827],
       device='cuda:0') torch.Size([16])
percent tensor([0.6134, 0.7570, 0.7375, 0.7767, 0.7489, 0.8241, 0.7165, 0.5852, 0.7510,
        0.7184, 0.7649, 0.7386, 0.7446, 0.7609, 0.5951, 0.5545],
       device='cuda:0') torch.Size([16])
percent tensor([0.4578, 0.7198, 0.6588, 0.6322, 0.6387, 0.6732, 0.6308, 0.5980, 0.6831,
        0.6510, 0.7186, 0.6380, 0.6324, 0.6847, 0.5646, 0.4046],
       device='cuda:0') torch.Size([16])
percent tensor([0.9998, 0.9998, 0.9996, 0.9998, 0.9999, 0.9997, 0.9999, 0.9997, 0.9998,
        0.9999, 0.9997, 0.9999, 0.9996, 0.9996, 0.9998, 0.9996],
       device='cuda:0') torch.Size([16])
Epoch: 166 | Batch_idx: 0 |  Loss: (0.1122) |  Loss2: (0.0000) | Acc: (96.00%) (124/128)
Epoch: 166 | Batch_idx: 10 |  Loss: (0.1104) |  Loss2: (0.0000) | Acc: (96.00%) (1352/1408)
Epoch: 166 | Batch_idx: 20 |  Loss: (0.1090) |  Loss2: (0.0000) | Acc: (96.00%) (2592/2688)
Epoch: 166 | Batch_idx: 30 |  Loss: (0.1074) |  Loss2: (0.0000) | Acc: (96.00%) (3827/3968)
Epoch: 166 | Batch_idx: 40 |  Loss: (0.1066) |  Loss2: (0.0000) | Acc: (96.00%) (5059/5248)
Epoch: 166 | Batch_idx: 50 |  Loss: (0.1029) |  Loss2: (0.0000) | Acc: (96.00%) (6296/6528)
Epoch: 166 | Batch_idx: 60 |  Loss: (0.1014) |  Loss2: (0.0000) | Acc: (96.00%) (7530/7808)
Epoch: 166 | Batch_idx: 70 |  Loss: (0.1026) |  Loss2: (0.0000) | Acc: (96.00%) (8766/9088)
Epoch: 166 | Batch_idx: 80 |  Loss: (0.1036) |  Loss2: (0.0000) | Acc: (96.00%) (9992/10368)
Epoch: 166 | Batch_idx: 90 |  Loss: (0.1021) |  Loss2: (0.0000) | Acc: (96.00%) (11236/11648)
Epoch: 166 | Batch_idx: 100 |  Loss: (0.1017) |  Loss2: (0.0000) | Acc: (96.00%) (12482/12928)
Epoch: 166 | Batch_idx: 110 |  Loss: (0.0999) |  Loss2: (0.0000) | Acc: (96.00%) (13732/14208)
Epoch: 166 | Batch_idx: 120 |  Loss: (0.1002) |  Loss2: (0.0000) | Acc: (96.00%) (14970/15488)
Epoch: 166 | Batch_idx: 130 |  Loss: (0.0990) |  Loss2: (0.0000) | Acc: (96.00%) (16218/16768)
Epoch: 166 | Batch_idx: 140 |  Loss: (0.0998) |  Loss2: (0.0000) | Acc: (96.00%) (17448/18048)
Epoch: 166 | Batch_idx: 150 |  Loss: (0.0997) |  Loss2: (0.0000) | Acc: (96.00%) (18683/19328)
Epoch: 166 | Batch_idx: 160 |  Loss: (0.1003) |  Loss2: (0.0000) | Acc: (96.00%) (19908/20608)
Epoch: 166 | Batch_idx: 170 |  Loss: (0.1002) |  Loss2: (0.0000) | Acc: (96.00%) (21142/21888)
Epoch: 166 | Batch_idx: 180 |  Loss: (0.1006) |  Loss2: (0.0000) | Acc: (96.00%) (22368/23168)
Epoch: 166 | Batch_idx: 190 |  Loss: (0.1001) |  Loss2: (0.0000) | Acc: (96.00%) (23604/24448)
Epoch: 166 | Batch_idx: 200 |  Loss: (0.1002) |  Loss2: (0.0000) | Acc: (96.00%) (24841/25728)
Epoch: 166 | Batch_idx: 210 |  Loss: (0.1001) |  Loss2: (0.0000) | Acc: (96.00%) (26080/27008)
Epoch: 166 | Batch_idx: 220 |  Loss: (0.1006) |  Loss2: (0.0000) | Acc: (96.00%) (27306/28288)
Epoch: 166 | Batch_idx: 230 |  Loss: (0.1010) |  Loss2: (0.0000) | Acc: (96.00%) (28536/29568)
Epoch: 166 | Batch_idx: 240 |  Loss: (0.1010) |  Loss2: (0.0000) | Acc: (96.00%) (29770/30848)
Epoch: 166 | Batch_idx: 250 |  Loss: (0.1008) |  Loss2: (0.0000) | Acc: (96.00%) (31009/32128)
Epoch: 166 | Batch_idx: 260 |  Loss: (0.0999) |  Loss2: (0.0000) | Acc: (96.00%) (32259/33408)
Epoch: 166 | Batch_idx: 270 |  Loss: (0.0998) |  Loss2: (0.0000) | Acc: (96.00%) (33503/34688)
Epoch: 166 | Batch_idx: 280 |  Loss: (0.1001) |  Loss2: (0.0000) | Acc: (96.00%) (34737/35968)
Epoch: 166 | Batch_idx: 290 |  Loss: (0.1001) |  Loss2: (0.0000) | Acc: (96.00%) (35975/37248)
Epoch: 166 | Batch_idx: 300 |  Loss: (0.0999) |  Loss2: (0.0000) | Acc: (96.00%) (37217/38528)
Epoch: 166 | Batch_idx: 310 |  Loss: (0.1002) |  Loss2: (0.0000) | Acc: (96.00%) (38451/39808)
Epoch: 166 | Batch_idx: 320 |  Loss: (0.0997) |  Loss2: (0.0000) | Acc: (96.00%) (39689/41088)
Epoch: 166 | Batch_idx: 330 |  Loss: (0.1006) |  Loss2: (0.0000) | Acc: (96.00%) (40911/42368)
Epoch: 166 | Batch_idx: 340 |  Loss: (0.1007) |  Loss2: (0.0000) | Acc: (96.00%) (42141/43648)
Epoch: 166 | Batch_idx: 350 |  Loss: (0.1008) |  Loss2: (0.0000) | Acc: (96.00%) (43374/44928)
Epoch: 166 | Batch_idx: 360 |  Loss: (0.1008) |  Loss2: (0.0000) | Acc: (96.00%) (44621/46208)
Epoch: 166 | Batch_idx: 370 |  Loss: (0.1004) |  Loss2: (0.0000) | Acc: (96.00%) (45862/47488)
Epoch: 166 | Batch_idx: 380 |  Loss: (0.1002) |  Loss2: (0.0000) | Acc: (96.00%) (47097/48768)
Epoch: 166 | Batch_idx: 390 |  Loss: (0.1003) |  Loss2: (0.0000) | Acc: (96.00%) (48284/50000)
# TEST : Loss: (0.3855) | Acc: (88.00%) (8894/10000)
percent tensor([0.5819, 0.5935, 0.5842, 0.5813, 0.5889, 0.5982, 0.5945, 0.5782, 0.5806,
        0.5856, 0.5884, 0.5895, 0.5843, 0.5783, 0.5983, 0.5862],
       device='cuda:0') torch.Size([16])
percent tensor([0.5206, 0.5244, 0.5131, 0.5190, 0.5123, 0.5267, 0.5178, 0.5141, 0.5152,
        0.5207, 0.5234, 0.5157, 0.5197, 0.5225, 0.5240, 0.5226],
       device='cuda:0') torch.Size([16])
percent tensor([0.5885, 0.4671, 0.7176, 0.7135, 0.7266, 0.6654, 0.5780, 0.6842, 0.6255,
        0.5492, 0.4958, 0.6565, 0.4912, 0.5534, 0.5432, 0.6359],
       device='cuda:0') torch.Size([16])
percent tensor([0.7152, 0.7511, 0.6225, 0.6484, 0.6298, 0.5721, 0.7117, 0.6586, 0.7216,
        0.7493, 0.7699, 0.6997, 0.7354, 0.7601, 0.6959, 0.6914],
       device='cuda:0') torch.Size([16])
percent tensor([0.7320, 0.6272, 0.7778, 0.7662, 0.7929, 0.8471, 0.7325, 0.7627, 0.6942,
        0.6107, 0.5749, 0.6414, 0.5967, 0.6587, 0.7170, 0.7887],
       device='cuda:0') torch.Size([16])
percent tensor([0.5948, 0.7436, 0.7233, 0.7676, 0.7350, 0.8142, 0.7043, 0.5659, 0.7387,
        0.7011, 0.7559, 0.7290, 0.7308, 0.7471, 0.5696, 0.5280],
       device='cuda:0') torch.Size([16])
percent tensor([0.4546, 0.6953, 0.6477, 0.6199, 0.6381, 0.6706, 0.6199, 0.5947, 0.6712,
        0.6313, 0.6998, 0.6280, 0.6093, 0.6618, 0.5572, 0.4079],
       device='cuda:0') torch.Size([16])
percent tensor([0.9998, 0.9998, 0.9997, 0.9999, 1.0000, 0.9997, 0.9999, 0.9997, 0.9998,
        0.9999, 0.9997, 0.9999, 0.9996, 0.9996, 0.9998, 0.9997],
       device='cuda:0') torch.Size([16])
Epoch: 167 | Batch_idx: 0 |  Loss: (0.0503) |  Loss2: (0.0000) | Acc: (99.00%) (127/128)
Epoch: 167 | Batch_idx: 10 |  Loss: (0.0979) |  Loss2: (0.0000) | Acc: (97.00%) (1367/1408)
Epoch: 167 | Batch_idx: 20 |  Loss: (0.0946) |  Loss2: (0.0000) | Acc: (96.00%) (2606/2688)
Epoch: 167 | Batch_idx: 30 |  Loss: (0.1004) |  Loss2: (0.0000) | Acc: (96.00%) (3831/3968)
Epoch: 167 | Batch_idx: 40 |  Loss: (0.0979) |  Loss2: (0.0000) | Acc: (96.00%) (5074/5248)
Epoch: 167 | Batch_idx: 50 |  Loss: (0.0956) |  Loss2: (0.0000) | Acc: (96.00%) (6316/6528)
Epoch: 167 | Batch_idx: 60 |  Loss: (0.0987) |  Loss2: (0.0000) | Acc: (96.00%) (7549/7808)
Epoch: 167 | Batch_idx: 70 |  Loss: (0.0995) |  Loss2: (0.0000) | Acc: (96.00%) (8781/9088)
Epoch: 167 | Batch_idx: 80 |  Loss: (0.0968) |  Loss2: (0.0000) | Acc: (96.00%) (10030/10368)
Epoch: 167 | Batch_idx: 90 |  Loss: (0.0972) |  Loss2: (0.0000) | Acc: (96.00%) (11265/11648)
Epoch: 167 | Batch_idx: 100 |  Loss: (0.0975) |  Loss2: (0.0000) | Acc: (96.00%) (12502/12928)
Epoch: 167 | Batch_idx: 110 |  Loss: (0.0970) |  Loss2: (0.0000) | Acc: (96.00%) (13746/14208)
Epoch: 167 | Batch_idx: 120 |  Loss: (0.0962) |  Loss2: (0.0000) | Acc: (96.00%) (14990/15488)
Epoch: 167 | Batch_idx: 130 |  Loss: (0.0957) |  Loss2: (0.0000) | Acc: (96.00%) (16232/16768)
Epoch: 167 | Batch_idx: 140 |  Loss: (0.0954) |  Loss2: (0.0000) | Acc: (96.00%) (17473/18048)
Epoch: 167 | Batch_idx: 150 |  Loss: (0.0955) |  Loss2: (0.0000) | Acc: (96.00%) (18714/19328)
Epoch: 167 | Batch_idx: 160 |  Loss: (0.0947) |  Loss2: (0.0000) | Acc: (96.00%) (19958/20608)
Epoch: 167 | Batch_idx: 170 |  Loss: (0.0947) |  Loss2: (0.0000) | Acc: (96.00%) (21204/21888)
Epoch: 167 | Batch_idx: 180 |  Loss: (0.0945) |  Loss2: (0.0000) | Acc: (96.00%) (22448/23168)
Epoch: 167 | Batch_idx: 190 |  Loss: (0.0943) |  Loss2: (0.0000) | Acc: (96.00%) (23691/24448)
Epoch: 167 | Batch_idx: 200 |  Loss: (0.0950) |  Loss2: (0.0000) | Acc: (96.00%) (24921/25728)
Epoch: 167 | Batch_idx: 210 |  Loss: (0.0947) |  Loss2: (0.0000) | Acc: (96.00%) (26164/27008)
Epoch: 167 | Batch_idx: 220 |  Loss: (0.0948) |  Loss2: (0.0000) | Acc: (96.00%) (27398/28288)
Epoch: 167 | Batch_idx: 230 |  Loss: (0.0949) |  Loss2: (0.0000) | Acc: (96.00%) (28636/29568)
Epoch: 167 | Batch_idx: 240 |  Loss: (0.0946) |  Loss2: (0.0000) | Acc: (96.00%) (29882/30848)
Epoch: 167 | Batch_idx: 250 |  Loss: (0.0952) |  Loss2: (0.0000) | Acc: (96.00%) (31112/32128)
Epoch: 167 | Batch_idx: 260 |  Loss: (0.0953) |  Loss2: (0.0000) | Acc: (96.00%) (32349/33408)
Epoch: 167 | Batch_idx: 270 |  Loss: (0.0948) |  Loss2: (0.0000) | Acc: (96.00%) (33596/34688)
Epoch: 167 | Batch_idx: 280 |  Loss: (0.0946) |  Loss2: (0.0000) | Acc: (96.00%) (34844/35968)
Epoch: 167 | Batch_idx: 290 |  Loss: (0.0946) |  Loss2: (0.0000) | Acc: (96.00%) (36087/37248)
Epoch: 167 | Batch_idx: 300 |  Loss: (0.0948) |  Loss2: (0.0000) | Acc: (96.00%) (37321/38528)
Epoch: 167 | Batch_idx: 310 |  Loss: (0.0945) |  Loss2: (0.0000) | Acc: (96.00%) (38562/39808)
Epoch: 167 | Batch_idx: 320 |  Loss: (0.0943) |  Loss2: (0.0000) | Acc: (96.00%) (39801/41088)
Epoch: 167 | Batch_idx: 330 |  Loss: (0.0939) |  Loss2: (0.0000) | Acc: (96.00%) (41048/42368)
Epoch: 167 | Batch_idx: 340 |  Loss: (0.0938) |  Loss2: (0.0000) | Acc: (96.00%) (42288/43648)
Epoch: 167 | Batch_idx: 350 |  Loss: (0.0940) |  Loss2: (0.0000) | Acc: (96.00%) (43527/44928)
Epoch: 167 | Batch_idx: 360 |  Loss: (0.0941) |  Loss2: (0.0000) | Acc: (96.00%) (44762/46208)
Epoch: 167 | Batch_idx: 370 |  Loss: (0.0938) |  Loss2: (0.0000) | Acc: (96.00%) (46007/47488)
Epoch: 167 | Batch_idx: 380 |  Loss: (0.0940) |  Loss2: (0.0000) | Acc: (96.00%) (47245/48768)
Epoch: 167 | Batch_idx: 390 |  Loss: (0.0939) |  Loss2: (0.0000) | Acc: (96.00%) (48434/50000)
# TEST : Loss: (0.3788) | Acc: (89.00%) (8910/10000)
percent tensor([0.5846, 0.5968, 0.5868, 0.5841, 0.5918, 0.6017, 0.5977, 0.5807, 0.5833,
        0.5884, 0.5915, 0.5924, 0.5871, 0.5810, 0.6017, 0.5892],
       device='cuda:0') torch.Size([16])
percent tensor([0.5214, 0.5255, 0.5136, 0.5198, 0.5126, 0.5277, 0.5184, 0.5148, 0.5159,
        0.5216, 0.5245, 0.5165, 0.5207, 0.5234, 0.5251, 0.5236],
       device='cuda:0') torch.Size([16])
percent tensor([0.5883, 0.4657, 0.7194, 0.7181, 0.7293, 0.6698, 0.5765, 0.6858, 0.6273,
        0.5494, 0.4967, 0.6578, 0.4891, 0.5572, 0.5447, 0.6364],
       device='cuda:0') torch.Size([16])
percent tensor([0.7188, 0.7547, 0.6262, 0.6532, 0.6340, 0.5756, 0.7153, 0.6634, 0.7256,
        0.7525, 0.7731, 0.7030, 0.7388, 0.7635, 0.6999, 0.6955],
       device='cuda:0') torch.Size([16])
percent tensor([0.7350, 0.6269, 0.7808, 0.7673, 0.7989, 0.8512, 0.7358, 0.7668, 0.6946,
        0.6084, 0.5721, 0.6403, 0.5954, 0.6560, 0.7184, 0.7938],
       device='cuda:0') torch.Size([16])
percent tensor([0.5803, 0.7331, 0.7126, 0.7575, 0.7201, 0.8047, 0.6931, 0.5453, 0.7270,
        0.6889, 0.7477, 0.7196, 0.7218, 0.7344, 0.5503, 0.5050],
       device='cuda:0') torch.Size([16])
percent tensor([0.4643, 0.6978, 0.6553, 0.6238, 0.6506, 0.6787, 0.6263, 0.6024, 0.6797,
        0.6345, 0.6988, 0.6376, 0.6134, 0.6651, 0.5679, 0.4187],
       device='cuda:0') torch.Size([16])
percent tensor([0.9998, 0.9998, 0.9996, 0.9999, 1.0000, 0.9997, 0.9999, 0.9997, 0.9997,
        0.9999, 0.9997, 0.9999, 0.9996, 0.9996, 0.9998, 0.9997],
       device='cuda:0') torch.Size([16])
True Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=128, out_features=16, bias=False)
False Linear(in_features=16, out_features=2, bias=False)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=128, out_features=16, bias=False)
False Linear(in_features=16, out_features=2, bias=False)
True Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=256, out_features=32, bias=False)
False Linear(in_features=32, out_features=2, bias=False)
True Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=256, out_features=32, bias=False)
False Linear(in_features=32, out_features=2, bias=False)
True Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=512, out_features=64, bias=False)
False Linear(in_features=64, out_features=2, bias=False)
True Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=512, out_features=64, bias=False)
False Linear(in_features=64, out_features=2, bias=False)
True Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1024, out_features=128, bias=False)
False Linear(in_features=128, out_features=2, bias=False)
True Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1024, out_features=128, bias=False)
False Linear(in_features=128, out_features=2, bias=False)
True Linear(in_features=512, out_features=10, bias=True)
Epoch: 168 | Batch_idx: 0 |  Loss: (0.0859) |  Loss2: (0.0000) | Acc: (97.00%) (125/128)
Epoch: 168 | Batch_idx: 10 |  Loss: (0.0875) |  Loss2: (0.0000) | Acc: (97.00%) (1369/1408)
Epoch: 168 | Batch_idx: 20 |  Loss: (0.0876) |  Loss2: (0.0000) | Acc: (97.00%) (2612/2688)
Epoch: 168 | Batch_idx: 30 |  Loss: (0.0942) |  Loss2: (0.0000) | Acc: (96.00%) (3847/3968)
Epoch: 168 | Batch_idx: 40 |  Loss: (0.0947) |  Loss2: (0.0000) | Acc: (96.00%) (5082/5248)
Epoch: 168 | Batch_idx: 50 |  Loss: (0.0948) |  Loss2: (0.0000) | Acc: (96.00%) (6318/6528)
Epoch: 168 | Batch_idx: 60 |  Loss: (0.0950) |  Loss2: (0.0000) | Acc: (96.00%) (7553/7808)
Epoch: 168 | Batch_idx: 70 |  Loss: (0.0979) |  Loss2: (0.0000) | Acc: (96.00%) (8780/9088)
Epoch: 168 | Batch_idx: 80 |  Loss: (0.0974) |  Loss2: (0.0000) | Acc: (96.00%) (10019/10368)
Epoch: 168 | Batch_idx: 90 |  Loss: (0.0977) |  Loss2: (0.0000) | Acc: (96.00%) (11256/11648)
Epoch: 168 | Batch_idx: 100 |  Loss: (0.0987) |  Loss2: (0.0000) | Acc: (96.00%) (12496/12928)
Epoch: 168 | Batch_idx: 110 |  Loss: (0.0993) |  Loss2: (0.0000) | Acc: (96.00%) (13729/14208)
Epoch: 168 | Batch_idx: 120 |  Loss: (0.0997) |  Loss2: (0.0000) | Acc: (96.00%) (14966/15488)
Epoch: 168 | Batch_idx: 130 |  Loss: (0.0995) |  Loss2: (0.0000) | Acc: (96.00%) (16204/16768)
Epoch: 168 | Batch_idx: 140 |  Loss: (0.0994) |  Loss2: (0.0000) | Acc: (96.00%) (17442/18048)
Epoch: 168 | Batch_idx: 150 |  Loss: (0.1000) |  Loss2: (0.0000) | Acc: (96.00%) (18681/19328)
Epoch: 168 | Batch_idx: 160 |  Loss: (0.0994) |  Loss2: (0.0000) | Acc: (96.00%) (19925/20608)
Epoch: 168 | Batch_idx: 170 |  Loss: (0.0989) |  Loss2: (0.0000) | Acc: (96.00%) (21170/21888)
Epoch: 168 | Batch_idx: 180 |  Loss: (0.0993) |  Loss2: (0.0000) | Acc: (96.00%) (22402/23168)
Epoch: 168 | Batch_idx: 190 |  Loss: (0.0996) |  Loss2: (0.0000) | Acc: (96.00%) (23641/24448)
Epoch: 168 | Batch_idx: 200 |  Loss: (0.1001) |  Loss2: (0.0000) | Acc: (96.00%) (24875/25728)
Epoch: 168 | Batch_idx: 210 |  Loss: (0.0993) |  Loss2: (0.0000) | Acc: (96.00%) (26124/27008)
Epoch: 168 | Batch_idx: 220 |  Loss: (0.0994) |  Loss2: (0.0000) | Acc: (96.00%) (27357/28288)
Epoch: 168 | Batch_idx: 230 |  Loss: (0.1000) |  Loss2: (0.0000) | Acc: (96.00%) (28588/29568)
Epoch: 168 | Batch_idx: 240 |  Loss: (0.1004) |  Loss2: (0.0000) | Acc: (96.00%) (29817/30848)
Epoch: 168 | Batch_idx: 250 |  Loss: (0.1006) |  Loss2: (0.0000) | Acc: (96.00%) (31051/32128)
Epoch: 168 | Batch_idx: 260 |  Loss: (0.1005) |  Loss2: (0.0000) | Acc: (96.00%) (32282/33408)
Epoch: 168 | Batch_idx: 270 |  Loss: (0.1007) |  Loss2: (0.0000) | Acc: (96.00%) (33516/34688)
Epoch: 168 | Batch_idx: 280 |  Loss: (0.1006) |  Loss2: (0.0000) | Acc: (96.00%) (34753/35968)
Epoch: 168 | Batch_idx: 290 |  Loss: (0.1006) |  Loss2: (0.0000) | Acc: (96.00%) (35991/37248)
Epoch: 168 | Batch_idx: 300 |  Loss: (0.1004) |  Loss2: (0.0000) | Acc: (96.00%) (37227/38528)
Epoch: 168 | Batch_idx: 310 |  Loss: (0.1007) |  Loss2: (0.0000) | Acc: (96.00%) (38458/39808)
Epoch: 168 | Batch_idx: 320 |  Loss: (0.1007) |  Loss2: (0.0000) | Acc: (96.00%) (39684/41088)
Epoch: 168 | Batch_idx: 330 |  Loss: (0.1010) |  Loss2: (0.0000) | Acc: (96.00%) (40923/42368)
Epoch: 168 | Batch_idx: 340 |  Loss: (0.1011) |  Loss2: (0.0000) | Acc: (96.00%) (42159/43648)
Epoch: 168 | Batch_idx: 350 |  Loss: (0.1012) |  Loss2: (0.0000) | Acc: (96.00%) (43389/44928)
Epoch: 168 | Batch_idx: 360 |  Loss: (0.1014) |  Loss2: (0.0000) | Acc: (96.00%) (44613/46208)
Epoch: 168 | Batch_idx: 370 |  Loss: (0.1011) |  Loss2: (0.0000) | Acc: (96.00%) (45856/47488)
Epoch: 168 | Batch_idx: 380 |  Loss: (0.1015) |  Loss2: (0.0000) | Acc: (96.00%) (47082/48768)
Epoch: 168 | Batch_idx: 390 |  Loss: (0.1016) |  Loss2: (0.0000) | Acc: (96.00%) (48270/50000)
# TEST : Loss: (0.4130) | Acc: (88.00%) (8814/10000)
percent tensor([0.5831, 0.5968, 0.5820, 0.5827, 0.5887, 0.6003, 0.5967, 0.5792, 0.5812,
        0.5873, 0.5911, 0.5889, 0.5857, 0.5816, 0.6016, 0.5888],
       device='cuda:0') torch.Size([16])
percent tensor([0.5219, 0.5245, 0.5141, 0.5206, 0.5137, 0.5296, 0.5183, 0.5143, 0.5163,
        0.5212, 0.5249, 0.5168, 0.5211, 0.5225, 0.5251, 0.5241],
       device='cuda:0') torch.Size([16])
percent tensor([0.5878, 0.4707, 0.7218, 0.7213, 0.7274, 0.6619, 0.5738, 0.6913, 0.6253,
        0.5529, 0.4883, 0.6563, 0.4927, 0.5550, 0.5449, 0.6316],
       device='cuda:0') torch.Size([16])
percent tensor([0.7181, 0.7525, 0.6211, 0.6576, 0.6315, 0.5761, 0.7120, 0.6547, 0.7224,
        0.7513, 0.7695, 0.7025, 0.7405, 0.7561, 0.6941, 0.6924],
       device='cuda:0') torch.Size([16])
percent tensor([0.7398, 0.6168, 0.7925, 0.7691, 0.8043, 0.8397, 0.7309, 0.7710, 0.6906,
        0.6196, 0.5729, 0.6589, 0.5945, 0.6609, 0.7078, 0.7942],
       device='cuda:0') torch.Size([16])
percent tensor([0.6080, 0.7166, 0.7413, 0.7764, 0.7456, 0.8086, 0.7045, 0.5337, 0.7049,
        0.6804, 0.7405, 0.7298, 0.7059, 0.7537, 0.5575, 0.5494],
       device='cuda:0') torch.Size([16])
percent tensor([0.4647, 0.6975, 0.6664, 0.6259, 0.6447, 0.6712, 0.6339, 0.5977, 0.6572,
        0.6374, 0.6916, 0.6296, 0.6219, 0.6608, 0.5726, 0.4164],
       device='cuda:0') torch.Size([16])
percent tensor([0.9997, 0.9998, 0.9997, 0.9998, 0.9999, 0.9997, 0.9998, 0.9996, 0.9997,
        0.9998, 0.9997, 0.9999, 0.9995, 0.9995, 0.9997, 0.9995],
       device='cuda:0') torch.Size([16])
Epoch: 169 | Batch_idx: 0 |  Loss: (0.0821) |  Loss2: (0.0000) | Acc: (97.00%) (125/128)
Epoch: 169 | Batch_idx: 10 |  Loss: (0.0937) |  Loss2: (0.0000) | Acc: (96.00%) (1361/1408)
Epoch: 169 | Batch_idx: 20 |  Loss: (0.0947) |  Loss2: (0.0000) | Acc: (96.00%) (2600/2688)
Epoch: 169 | Batch_idx: 30 |  Loss: (0.0928) |  Loss2: (0.0000) | Acc: (96.00%) (3841/3968)
Epoch: 169 | Batch_idx: 40 |  Loss: (0.0936) |  Loss2: (0.0000) | Acc: (96.00%) (5073/5248)
Epoch: 169 | Batch_idx: 50 |  Loss: (0.0963) |  Loss2: (0.0000) | Acc: (96.00%) (6307/6528)
Epoch: 169 | Batch_idx: 60 |  Loss: (0.0991) |  Loss2: (0.0000) | Acc: (96.00%) (7538/7808)
Epoch: 169 | Batch_idx: 70 |  Loss: (0.0996) |  Loss2: (0.0000) | Acc: (96.00%) (8767/9088)
Epoch: 169 | Batch_idx: 80 |  Loss: (0.0991) |  Loss2: (0.0000) | Acc: (96.00%) (10006/10368)
Epoch: 169 | Batch_idx: 90 |  Loss: (0.0990) |  Loss2: (0.0000) | Acc: (96.00%) (11236/11648)
Epoch: 169 | Batch_idx: 100 |  Loss: (0.0983) |  Loss2: (0.0000) | Acc: (96.00%) (12476/12928)
Epoch: 169 | Batch_idx: 110 |  Loss: (0.0983) |  Loss2: (0.0000) | Acc: (96.00%) (13713/14208)
Epoch: 169 | Batch_idx: 120 |  Loss: (0.0974) |  Loss2: (0.0000) | Acc: (96.00%) (14952/15488)
Epoch: 169 | Batch_idx: 130 |  Loss: (0.0967) |  Loss2: (0.0000) | Acc: (96.00%) (16192/16768)
Epoch: 169 | Batch_idx: 140 |  Loss: (0.0968) |  Loss2: (0.0000) | Acc: (96.00%) (17431/18048)
Epoch: 169 | Batch_idx: 150 |  Loss: (0.0965) |  Loss2: (0.0000) | Acc: (96.00%) (18668/19328)
Epoch: 169 | Batch_idx: 160 |  Loss: (0.0971) |  Loss2: (0.0000) | Acc: (96.00%) (19895/20608)
Epoch: 169 | Batch_idx: 170 |  Loss: (0.0969) |  Loss2: (0.0000) | Acc: (96.00%) (21141/21888)
Epoch: 169 | Batch_idx: 180 |  Loss: (0.0979) |  Loss2: (0.0000) | Acc: (96.00%) (22366/23168)
Epoch: 169 | Batch_idx: 190 |  Loss: (0.0981) |  Loss2: (0.0000) | Acc: (96.00%) (23602/24448)
Epoch: 169 | Batch_idx: 200 |  Loss: (0.0979) |  Loss2: (0.0000) | Acc: (96.00%) (24844/25728)
Epoch: 169 | Batch_idx: 210 |  Loss: (0.0976) |  Loss2: (0.0000) | Acc: (96.00%) (26085/27008)
Epoch: 169 | Batch_idx: 220 |  Loss: (0.0966) |  Loss2: (0.0000) | Acc: (96.00%) (27335/28288)
Epoch: 169 | Batch_idx: 230 |  Loss: (0.0975) |  Loss2: (0.0000) | Acc: (96.00%) (28568/29568)
Epoch: 169 | Batch_idx: 240 |  Loss: (0.0976) |  Loss2: (0.0000) | Acc: (96.00%) (29810/30848)
Epoch: 169 | Batch_idx: 250 |  Loss: (0.0980) |  Loss2: (0.0000) | Acc: (96.00%) (31046/32128)
Epoch: 169 | Batch_idx: 260 |  Loss: (0.0983) |  Loss2: (0.0000) | Acc: (96.00%) (32278/33408)
Epoch: 169 | Batch_idx: 270 |  Loss: (0.0977) |  Loss2: (0.0000) | Acc: (96.00%) (33527/34688)
Epoch: 169 | Batch_idx: 280 |  Loss: (0.0981) |  Loss2: (0.0000) | Acc: (96.00%) (34755/35968)
Epoch: 169 | Batch_idx: 290 |  Loss: (0.0985) |  Loss2: (0.0000) | Acc: (96.00%) (35992/37248)
Epoch: 169 | Batch_idx: 300 |  Loss: (0.0991) |  Loss2: (0.0000) | Acc: (96.00%) (37227/38528)
Epoch: 169 | Batch_idx: 310 |  Loss: (0.0989) |  Loss2: (0.0000) | Acc: (96.00%) (38464/39808)
Epoch: 169 | Batch_idx: 320 |  Loss: (0.0992) |  Loss2: (0.0000) | Acc: (96.00%) (39694/41088)
Epoch: 169 | Batch_idx: 330 |  Loss: (0.0992) |  Loss2: (0.0000) | Acc: (96.00%) (40928/42368)
Epoch: 169 | Batch_idx: 340 |  Loss: (0.0993) |  Loss2: (0.0000) | Acc: (96.00%) (42162/43648)
Epoch: 169 | Batch_idx: 350 |  Loss: (0.0996) |  Loss2: (0.0000) | Acc: (96.00%) (43386/44928)
Epoch: 169 | Batch_idx: 360 |  Loss: (0.0994) |  Loss2: (0.0000) | Acc: (96.00%) (44626/46208)
Epoch: 169 | Batch_idx: 370 |  Loss: (0.0995) |  Loss2: (0.0000) | Acc: (96.00%) (45866/47488)
Epoch: 169 | Batch_idx: 380 |  Loss: (0.0997) |  Loss2: (0.0000) | Acc: (96.00%) (47102/48768)
Epoch: 169 | Batch_idx: 390 |  Loss: (0.1001) |  Loss2: (0.0000) | Acc: (96.00%) (48286/50000)
# TEST : Loss: (0.4256) | Acc: (87.00%) (8798/10000)
percent tensor([0.5839, 0.5949, 0.5862, 0.5843, 0.5923, 0.6010, 0.5965, 0.5801, 0.5811,
        0.5876, 0.5906, 0.5934, 0.5860, 0.5766, 0.6017, 0.5885],
       device='cuda:0') torch.Size([16])
percent tensor([0.5222, 0.5244, 0.5141, 0.5210, 0.5138, 0.5298, 0.5182, 0.5146, 0.5161,
        0.5214, 0.5244, 0.5161, 0.5206, 0.5225, 0.5252, 0.5247],
       device='cuda:0') torch.Size([16])
percent tensor([0.5819, 0.4541, 0.7093, 0.7143, 0.7219, 0.6682, 0.5570, 0.6839, 0.6337,
        0.5362, 0.4984, 0.6435, 0.4918, 0.5413, 0.5353, 0.6288],
       device='cuda:0') torch.Size([16])
percent tensor([0.7128, 0.7568, 0.6290, 0.6458, 0.6289, 0.5609, 0.7181, 0.6578, 0.7226,
        0.7506, 0.7659, 0.7008, 0.7363, 0.7688, 0.6931, 0.6814],
       device='cuda:0') torch.Size([16])
percent tensor([0.7460, 0.6206, 0.7580, 0.7783, 0.7923, 0.8483, 0.7223, 0.7559, 0.6923,
        0.6141, 0.5946, 0.6236, 0.5966, 0.6416, 0.7207, 0.8081],
       device='cuda:0') torch.Size([16])
percent tensor([0.6240, 0.7404, 0.7209, 0.7781, 0.7340, 0.8041, 0.7109, 0.5429, 0.7195,
        0.7088, 0.7618, 0.7375, 0.7290, 0.7540, 0.5911, 0.5575],
       device='cuda:0') torch.Size([16])
percent tensor([0.4643, 0.7392, 0.6364, 0.6175, 0.6492, 0.6619, 0.6540, 0.6124, 0.6822,
        0.6715, 0.7162, 0.6476, 0.6403, 0.7145, 0.5603, 0.4150],
       device='cuda:0') torch.Size([16])
percent tensor([0.9998, 0.9998, 0.9997, 0.9999, 0.9999, 0.9993, 0.9999, 0.9997, 0.9998,
        0.9999, 0.9997, 0.9999, 0.9997, 0.9996, 0.9998, 0.9996],
       device='cuda:0') torch.Size([16])
Epoch: 170 | Batch_idx: 0 |  Loss: (0.1499) |  Loss2: (0.0000) | Acc: (92.00%) (119/128)
Epoch: 170 | Batch_idx: 10 |  Loss: (0.0880) |  Loss2: (0.0000) | Acc: (97.00%) (1368/1408)
Epoch: 170 | Batch_idx: 20 |  Loss: (0.0870) |  Loss2: (0.0000) | Acc: (97.00%) (2613/2688)
Epoch: 170 | Batch_idx: 30 |  Loss: (0.0864) |  Loss2: (0.0000) | Acc: (97.00%) (3857/3968)
Epoch: 170 | Batch_idx: 40 |  Loss: (0.0852) |  Loss2: (0.0000) | Acc: (97.00%) (5100/5248)
Epoch: 170 | Batch_idx: 50 |  Loss: (0.0840) |  Loss2: (0.0000) | Acc: (97.00%) (6344/6528)
Epoch: 170 | Batch_idx: 60 |  Loss: (0.0853) |  Loss2: (0.0000) | Acc: (97.00%) (7582/7808)
Epoch: 170 | Batch_idx: 70 |  Loss: (0.0862) |  Loss2: (0.0000) | Acc: (97.00%) (8818/9088)
Epoch: 170 | Batch_idx: 80 |  Loss: (0.0854) |  Loss2: (0.0000) | Acc: (97.00%) (10072/10368)
Epoch: 170 | Batch_idx: 90 |  Loss: (0.0847) |  Loss2: (0.0000) | Acc: (97.00%) (11324/11648)
Epoch: 170 | Batch_idx: 100 |  Loss: (0.0851) |  Loss2: (0.0000) | Acc: (97.00%) (12570/12928)
Epoch: 170 | Batch_idx: 110 |  Loss: (0.0859) |  Loss2: (0.0000) | Acc: (97.00%) (13800/14208)
Epoch: 170 | Batch_idx: 120 |  Loss: (0.0864) |  Loss2: (0.0000) | Acc: (97.00%) (15036/15488)
Epoch: 170 | Batch_idx: 130 |  Loss: (0.0854) |  Loss2: (0.0000) | Acc: (97.00%) (16291/16768)
Epoch: 170 | Batch_idx: 140 |  Loss: (0.0849) |  Loss2: (0.0000) | Acc: (97.00%) (17537/18048)
Epoch: 170 | Batch_idx: 150 |  Loss: (0.0862) |  Loss2: (0.0000) | Acc: (97.00%) (18768/19328)
Epoch: 170 | Batch_idx: 160 |  Loss: (0.0863) |  Loss2: (0.0000) | Acc: (97.00%) (20012/20608)
Epoch: 170 | Batch_idx: 170 |  Loss: (0.0873) |  Loss2: (0.0000) | Acc: (97.00%) (21242/21888)
Epoch: 170 | Batch_idx: 180 |  Loss: (0.0877) |  Loss2: (0.0000) | Acc: (97.00%) (22480/23168)
Epoch: 170 | Batch_idx: 190 |  Loss: (0.0882) |  Loss2: (0.0000) | Acc: (97.00%) (23719/24448)
Epoch: 170 | Batch_idx: 200 |  Loss: (0.0888) |  Loss2: (0.0000) | Acc: (96.00%) (24956/25728)
Epoch: 170 | Batch_idx: 210 |  Loss: (0.0886) |  Loss2: (0.0000) | Acc: (97.00%) (26201/27008)
Epoch: 170 | Batch_idx: 220 |  Loss: (0.0888) |  Loss2: (0.0000) | Acc: (97.00%) (27447/28288)
Epoch: 170 | Batch_idx: 230 |  Loss: (0.0884) |  Loss2: (0.0000) | Acc: (97.00%) (28689/29568)
Epoch: 170 | Batch_idx: 240 |  Loss: (0.0890) |  Loss2: (0.0000) | Acc: (97.00%) (29928/30848)
Epoch: 170 | Batch_idx: 250 |  Loss: (0.0897) |  Loss2: (0.0000) | Acc: (96.00%) (31163/32128)
Epoch: 170 | Batch_idx: 260 |  Loss: (0.0901) |  Loss2: (0.0000) | Acc: (97.00%) (32407/33408)
Epoch: 170 | Batch_idx: 270 |  Loss: (0.0904) |  Loss2: (0.0000) | Acc: (96.00%) (33641/34688)
Epoch: 170 | Batch_idx: 280 |  Loss: (0.0904) |  Loss2: (0.0000) | Acc: (96.00%) (34885/35968)
Epoch: 170 | Batch_idx: 290 |  Loss: (0.0905) |  Loss2: (0.0000) | Acc: (96.00%) (36124/37248)
Epoch: 170 | Batch_idx: 300 |  Loss: (0.0913) |  Loss2: (0.0000) | Acc: (96.00%) (37347/38528)
Epoch: 170 | Batch_idx: 310 |  Loss: (0.0912) |  Loss2: (0.0000) | Acc: (96.00%) (38590/39808)
Epoch: 170 | Batch_idx: 320 |  Loss: (0.0915) |  Loss2: (0.0000) | Acc: (96.00%) (39821/41088)
Epoch: 170 | Batch_idx: 330 |  Loss: (0.0920) |  Loss2: (0.0000) | Acc: (96.00%) (41050/42368)
Epoch: 170 | Batch_idx: 340 |  Loss: (0.0919) |  Loss2: (0.0000) | Acc: (96.00%) (42289/43648)
Epoch: 170 | Batch_idx: 350 |  Loss: (0.0919) |  Loss2: (0.0000) | Acc: (96.00%) (43532/44928)
Epoch: 170 | Batch_idx: 360 |  Loss: (0.0924) |  Loss2: (0.0000) | Acc: (96.00%) (44762/46208)
Epoch: 170 | Batch_idx: 370 |  Loss: (0.0928) |  Loss2: (0.0000) | Acc: (96.00%) (45997/47488)
Epoch: 170 | Batch_idx: 380 |  Loss: (0.0929) |  Loss2: (0.0000) | Acc: (96.00%) (47232/48768)
Epoch: 170 | Batch_idx: 390 |  Loss: (0.0930) |  Loss2: (0.0000) | Acc: (96.00%) (48423/50000)
=> saving checkpoint 'drive/app/torch/save_Schedule/checkpoint_170.pth.tar'
# TEST : Loss: (0.3807) | Acc: (89.00%) (8904/10000)
percent tensor([0.5832, 0.5961, 0.5851, 0.5848, 0.5918, 0.6001, 0.5968, 0.5801, 0.5815,
        0.5880, 0.5902, 0.5924, 0.5862, 0.5787, 0.6018, 0.5882],
       device='cuda:0') torch.Size([16])
percent tensor([0.5216, 0.5237, 0.5147, 0.5205, 0.5138, 0.5282, 0.5174, 0.5148, 0.5159,
        0.5209, 0.5240, 0.5161, 0.5203, 0.5215, 0.5244, 0.5238],
       device='cuda:0') torch.Size([16])
percent tensor([0.5762, 0.4691, 0.7137, 0.7152, 0.7256, 0.6766, 0.5761, 0.6865, 0.6366,
        0.5405, 0.4982, 0.6495, 0.4859, 0.5601, 0.5480, 0.6279],
       device='cuda:0') torch.Size([16])
percent tensor([0.7185, 0.7583, 0.6208, 0.6493, 0.6219, 0.5686, 0.7143, 0.6544, 0.7218,
        0.7537, 0.7683, 0.7018, 0.7411, 0.7612, 0.6969, 0.6900],
       device='cuda:0') torch.Size([16])
percent tensor([0.7362, 0.6170, 0.7748, 0.7555, 0.7991, 0.8411, 0.7291, 0.7605, 0.7003,
        0.6220, 0.5870, 0.6308, 0.5897, 0.6593, 0.7086, 0.7918],
       device='cuda:0') torch.Size([16])
percent tensor([0.6220, 0.7257, 0.7296, 0.7738, 0.7409, 0.7968, 0.6971, 0.5364, 0.7426,
        0.7175, 0.7603, 0.7501, 0.7259, 0.7418, 0.5545, 0.5655],
       device='cuda:0') torch.Size([16])
percent tensor([0.4604, 0.7165, 0.6438, 0.6377, 0.6445, 0.6428, 0.6361, 0.5978, 0.6579,
        0.6295, 0.7274, 0.6608, 0.6164, 0.6737, 0.5748, 0.4102],
       device='cuda:0') torch.Size([16])
percent tensor([0.9998, 0.9998, 0.9996, 0.9999, 0.9999, 0.9995, 0.9999, 0.9997, 0.9998,
        0.9999, 0.9995, 1.0000, 0.9995, 0.9997, 0.9997, 0.9996],
       device='cuda:0') torch.Size([16])
False Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=128, out_features=16, bias=False)
True Linear(in_features=16, out_features=2, bias=False)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=128, out_features=16, bias=False)
True Linear(in_features=16, out_features=2, bias=False)
False Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=256, out_features=32, bias=False)
True Linear(in_features=32, out_features=2, bias=False)
False Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=256, out_features=32, bias=False)
True Linear(in_features=32, out_features=2, bias=False)
False Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=512, out_features=64, bias=False)
True Linear(in_features=64, out_features=2, bias=False)
False Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=512, out_features=64, bias=False)
True Linear(in_features=64, out_features=2, bias=False)
False Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1024, out_features=128, bias=False)
True Linear(in_features=128, out_features=2, bias=False)
False Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1024, out_features=128, bias=False)
True Linear(in_features=128, out_features=2, bias=False)
False Linear(in_features=512, out_features=10, bias=True)
Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 3, 3, 3]) tensor(185.2346, device='cuda:0')
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(821.1503, device='cuda:0')
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(831.1644, device='cuda:0')
Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([128, 64, 3, 3]) tensor(1512.8560, device='cuda:0')
Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([128, 64, 1, 1]) tensor(487.4341, device='cuda:0')
Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([128, 128, 3, 3]) tensor(2277.4666, device='cuda:0')
Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([256, 128, 3, 3]) tensor(4276.9438, device='cuda:0')
Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([256, 128, 1, 1]) tensor(1367.2893, device='cuda:0')
Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([256, 256, 3, 3]) tensor(6244.5503, device='cuda:0')
Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([512, 256, 3, 3]) tensor(11641.2578, device='cuda:0')
Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([512, 256, 1, 1]) tensor(3837.6360, device='cuda:0')
Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([512, 512, 3, 3]) tensor(16169.5996, device='cuda:0')
Epoch: 171 | Batch_idx: 0 |  Loss: (0.0653) |  Loss2: (0.0000) | Acc: (97.00%) (125/128)
Epoch: 171 | Batch_idx: 10 |  Loss: (0.0976) |  Loss2: (0.0000) | Acc: (96.00%) (1361/1408)
Epoch: 171 | Batch_idx: 20 |  Loss: (0.0985) |  Loss2: (0.0000) | Acc: (96.00%) (2595/2688)
Epoch: 171 | Batch_idx: 30 |  Loss: (0.1123) |  Loss2: (0.0000) | Acc: (96.00%) (3813/3968)
Epoch: 171 | Batch_idx: 40 |  Loss: (0.1129) |  Loss2: (0.0000) | Acc: (96.00%) (5040/5248)
Epoch: 171 | Batch_idx: 50 |  Loss: (0.1113) |  Loss2: (0.0000) | Acc: (96.00%) (6274/6528)
Epoch: 171 | Batch_idx: 60 |  Loss: (0.1137) |  Loss2: (0.0000) | Acc: (95.00%) (7492/7808)
Epoch: 171 | Batch_idx: 70 |  Loss: (0.1141) |  Loss2: (0.0000) | Acc: (95.00%) (8718/9088)
Epoch: 171 | Batch_idx: 80 |  Loss: (0.1144) |  Loss2: (0.0000) | Acc: (95.00%) (9944/10368)
Epoch: 171 | Batch_idx: 90 |  Loss: (0.1135) |  Loss2: (0.0000) | Acc: (95.00%) (11175/11648)
Epoch: 171 | Batch_idx: 100 |  Loss: (0.1135) |  Loss2: (0.0000) | Acc: (95.00%) (12405/12928)
Epoch: 171 | Batch_idx: 110 |  Loss: (0.1140) |  Loss2: (0.0000) | Acc: (95.00%) (13631/14208)
Epoch: 171 | Batch_idx: 120 |  Loss: (0.1147) |  Loss2: (0.0000) | Acc: (95.00%) (14862/15488)
Epoch: 171 | Batch_idx: 130 |  Loss: (0.1162) |  Loss2: (0.0000) | Acc: (95.00%) (16078/16768)
Epoch: 171 | Batch_idx: 140 |  Loss: (0.1161) |  Loss2: (0.0000) | Acc: (95.00%) (17307/18048)
Epoch: 171 | Batch_idx: 150 |  Loss: (0.1151) |  Loss2: (0.0000) | Acc: (95.00%) (18542/19328)
Epoch: 171 | Batch_idx: 160 |  Loss: (0.1145) |  Loss2: (0.0000) | Acc: (95.00%) (19782/20608)
Epoch: 171 | Batch_idx: 170 |  Loss: (0.1148) |  Loss2: (0.0000) | Acc: (95.00%) (21006/21888)
Epoch: 171 | Batch_idx: 180 |  Loss: (0.1152) |  Loss2: (0.0000) | Acc: (95.00%) (22236/23168)
Epoch: 171 | Batch_idx: 190 |  Loss: (0.1135) |  Loss2: (0.0000) | Acc: (96.00%) (23484/24448)
Epoch: 171 | Batch_idx: 200 |  Loss: (0.1121) |  Loss2: (0.0000) | Acc: (96.00%) (24727/25728)
Epoch: 171 | Batch_idx: 210 |  Loss: (0.1111) |  Loss2: (0.0000) | Acc: (96.00%) (25968/27008)
Epoch: 171 | Batch_idx: 220 |  Loss: (0.1107) |  Loss2: (0.0000) | Acc: (96.00%) (27203/28288)
Epoch: 171 | Batch_idx: 230 |  Loss: (0.1106) |  Loss2: (0.0000) | Acc: (96.00%) (28432/29568)
Epoch: 171 | Batch_idx: 240 |  Loss: (0.1098) |  Loss2: (0.0000) | Acc: (96.00%) (29676/30848)
Epoch: 171 | Batch_idx: 250 |  Loss: (0.1096) |  Loss2: (0.0000) | Acc: (96.00%) (30911/32128)
Epoch: 171 | Batch_idx: 260 |  Loss: (0.1093) |  Loss2: (0.0000) | Acc: (96.00%) (32150/33408)
Epoch: 171 | Batch_idx: 270 |  Loss: (0.1086) |  Loss2: (0.0000) | Acc: (96.00%) (33389/34688)
Epoch: 171 | Batch_idx: 280 |  Loss: (0.1080) |  Loss2: (0.0000) | Acc: (96.00%) (34628/35968)
Epoch: 171 | Batch_idx: 290 |  Loss: (0.1082) |  Loss2: (0.0000) | Acc: (96.00%) (35852/37248)
Epoch: 171 | Batch_idx: 300 |  Loss: (0.1074) |  Loss2: (0.0000) | Acc: (96.00%) (37092/38528)
Epoch: 171 | Batch_idx: 310 |  Loss: (0.1071) |  Loss2: (0.0000) | Acc: (96.00%) (38337/39808)
Epoch: 171 | Batch_idx: 320 |  Loss: (0.1074) |  Loss2: (0.0000) | Acc: (96.00%) (39570/41088)
Epoch: 171 | Batch_idx: 330 |  Loss: (0.1067) |  Loss2: (0.0000) | Acc: (96.00%) (40807/42368)
Epoch: 171 | Batch_idx: 340 |  Loss: (0.1072) |  Loss2: (0.0000) | Acc: (96.00%) (42031/43648)
Epoch: 171 | Batch_idx: 350 |  Loss: (0.1072) |  Loss2: (0.0000) | Acc: (96.00%) (43267/44928)
Epoch: 171 | Batch_idx: 360 |  Loss: (0.1071) |  Loss2: (0.0000) | Acc: (96.00%) (44505/46208)
Epoch: 171 | Batch_idx: 370 |  Loss: (0.1072) |  Loss2: (0.0000) | Acc: (96.00%) (45738/47488)
Epoch: 171 | Batch_idx: 380 |  Loss: (0.1070) |  Loss2: (0.0000) | Acc: (96.00%) (46972/48768)
Epoch: 171 | Batch_idx: 390 |  Loss: (0.1066) |  Loss2: (0.0000) | Acc: (96.00%) (48164/50000)
# TEST : Loss: (0.3906) | Acc: (88.00%) (8879/10000)
percent tensor([0.5823, 0.5950, 0.5846, 0.5842, 0.5915, 0.5987, 0.5961, 0.5798, 0.5808,
        0.5875, 0.5894, 0.5917, 0.5857, 0.5782, 0.6007, 0.5874],
       device='cuda:0') torch.Size([16])
percent tensor([0.5246, 0.5265, 0.5160, 0.5225, 0.5157, 0.5318, 0.5198, 0.5156, 0.5184,
        0.5236, 0.5273, 0.5184, 0.5231, 0.5241, 0.5275, 0.5268],
       device='cuda:0') torch.Size([16])
percent tensor([0.5727, 0.4690, 0.7017, 0.7045, 0.7138, 0.6661, 0.5685, 0.6794, 0.6271,
        0.5390, 0.4978, 0.6373, 0.4838, 0.5521, 0.5385, 0.6253],
       device='cuda:0') torch.Size([16])
percent tensor([0.7003, 0.7444, 0.6056, 0.6386, 0.6009, 0.5462, 0.6992, 0.6414, 0.7071,
        0.7371, 0.7520, 0.6834, 0.7240, 0.7524, 0.6747, 0.6725],
       device='cuda:0') torch.Size([16])
percent tensor([0.7561, 0.6189, 0.7904, 0.7798, 0.8159, 0.8552, 0.7432, 0.7780, 0.7157,
        0.6359, 0.6012, 0.6526, 0.5998, 0.6693, 0.7319, 0.8069],
       device='cuda:0') torch.Size([16])
percent tensor([0.6230, 0.7199, 0.7380, 0.7695, 0.7575, 0.7957, 0.7070, 0.5383, 0.7551,
        0.7209, 0.7597, 0.7531, 0.7241, 0.7539, 0.5543, 0.5578],
       device='cuda:0') torch.Size([16])
percent tensor([0.4386, 0.7121, 0.6380, 0.6188, 0.6313, 0.6301, 0.6173, 0.5604, 0.6475,
        0.6075, 0.7192, 0.6553, 0.6281, 0.6757, 0.5314, 0.3910],
       device='cuda:0') torch.Size([16])
percent tensor([0.9998, 0.9998, 0.9995, 0.9999, 0.9999, 0.9995, 0.9998, 0.9997, 0.9998,
        0.9999, 0.9995, 1.0000, 0.9995, 0.9996, 0.9997, 0.9997],
       device='cuda:0') torch.Size([16])
Epoch: 172 | Batch_idx: 0 |  Loss: (0.0740) |  Loss2: (0.0000) | Acc: (95.00%) (122/128)
Epoch: 172 | Batch_idx: 10 |  Loss: (0.1303) |  Loss2: (0.0000) | Acc: (95.00%) (1347/1408)
Epoch: 172 | Batch_idx: 20 |  Loss: (0.1120) |  Loss2: (0.0000) | Acc: (96.00%) (2590/2688)
Epoch: 172 | Batch_idx: 30 |  Loss: (0.1078) |  Loss2: (0.0000) | Acc: (96.00%) (3825/3968)
Epoch: 172 | Batch_idx: 40 |  Loss: (0.1044) |  Loss2: (0.0000) | Acc: (96.00%) (5072/5248)
Epoch: 172 | Batch_idx: 50 |  Loss: (0.1027) |  Loss2: (0.0000) | Acc: (96.00%) (6316/6528)
Epoch: 172 | Batch_idx: 60 |  Loss: (0.1010) |  Loss2: (0.0000) | Acc: (96.00%) (7561/7808)
Epoch: 172 | Batch_idx: 70 |  Loss: (0.1033) |  Loss2: (0.0000) | Acc: (96.00%) (8793/9088)
Epoch: 172 | Batch_idx: 80 |  Loss: (0.1047) |  Loss2: (0.0000) | Acc: (96.00%) (10018/10368)
Epoch: 172 | Batch_idx: 90 |  Loss: (0.1042) |  Loss2: (0.0000) | Acc: (96.00%) (11261/11648)
Epoch: 172 | Batch_idx: 100 |  Loss: (0.1036) |  Loss2: (0.0000) | Acc: (96.00%) (12502/12928)
Epoch: 172 | Batch_idx: 110 |  Loss: (0.1025) |  Loss2: (0.0000) | Acc: (96.00%) (13741/14208)
Epoch: 172 | Batch_idx: 120 |  Loss: (0.1014) |  Loss2: (0.0000) | Acc: (96.00%) (14983/15488)
Epoch: 172 | Batch_idx: 130 |  Loss: (0.1011) |  Loss2: (0.0000) | Acc: (96.00%) (16221/16768)
Epoch: 172 | Batch_idx: 140 |  Loss: (0.1008) |  Loss2: (0.0000) | Acc: (96.00%) (17461/18048)
Epoch: 172 | Batch_idx: 150 |  Loss: (0.1003) |  Loss2: (0.0000) | Acc: (96.00%) (18698/19328)
Epoch: 172 | Batch_idx: 160 |  Loss: (0.0999) |  Loss2: (0.0000) | Acc: (96.00%) (19943/20608)
Epoch: 172 | Batch_idx: 170 |  Loss: (0.1001) |  Loss2: (0.0000) | Acc: (96.00%) (21178/21888)
Epoch: 172 | Batch_idx: 180 |  Loss: (0.0999) |  Loss2: (0.0000) | Acc: (96.00%) (22413/23168)
Epoch: 172 | Batch_idx: 190 |  Loss: (0.0994) |  Loss2: (0.0000) | Acc: (96.00%) (23657/24448)
Epoch: 172 | Batch_idx: 200 |  Loss: (0.0991) |  Loss2: (0.0000) | Acc: (96.00%) (24896/25728)
Epoch: 172 | Batch_idx: 210 |  Loss: (0.0992) |  Loss2: (0.0000) | Acc: (96.00%) (26126/27008)
Epoch: 172 | Batch_idx: 220 |  Loss: (0.0987) |  Loss2: (0.0000) | Acc: (96.00%) (27364/28288)
Epoch: 172 | Batch_idx: 230 |  Loss: (0.0988) |  Loss2: (0.0000) | Acc: (96.00%) (28603/29568)
Epoch: 172 | Batch_idx: 240 |  Loss: (0.0992) |  Loss2: (0.0000) | Acc: (96.00%) (29835/30848)
Epoch: 172 | Batch_idx: 250 |  Loss: (0.0983) |  Loss2: (0.0000) | Acc: (96.00%) (31081/32128)
Epoch: 172 | Batch_idx: 260 |  Loss: (0.0984) |  Loss2: (0.0000) | Acc: (96.00%) (32314/33408)
Epoch: 172 | Batch_idx: 270 |  Loss: (0.0982) |  Loss2: (0.0000) | Acc: (96.00%) (33561/34688)
Epoch: 172 | Batch_idx: 280 |  Loss: (0.0978) |  Loss2: (0.0000) | Acc: (96.00%) (34809/35968)
Epoch: 172 | Batch_idx: 290 |  Loss: (0.0975) |  Loss2: (0.0000) | Acc: (96.00%) (36050/37248)
Epoch: 172 | Batch_idx: 300 |  Loss: (0.0977) |  Loss2: (0.0000) | Acc: (96.00%) (37280/38528)
Epoch: 172 | Batch_idx: 310 |  Loss: (0.0978) |  Loss2: (0.0000) | Acc: (96.00%) (38519/39808)
Epoch: 172 | Batch_idx: 320 |  Loss: (0.0982) |  Loss2: (0.0000) | Acc: (96.00%) (39751/41088)
Epoch: 172 | Batch_idx: 330 |  Loss: (0.0980) |  Loss2: (0.0000) | Acc: (96.00%) (40992/42368)
Epoch: 172 | Batch_idx: 340 |  Loss: (0.0976) |  Loss2: (0.0000) | Acc: (96.00%) (42239/43648)
Epoch: 172 | Batch_idx: 350 |  Loss: (0.0972) |  Loss2: (0.0000) | Acc: (96.00%) (43482/44928)
Epoch: 172 | Batch_idx: 360 |  Loss: (0.0969) |  Loss2: (0.0000) | Acc: (96.00%) (44720/46208)
Epoch: 172 | Batch_idx: 370 |  Loss: (0.0966) |  Loss2: (0.0000) | Acc: (96.00%) (45965/47488)
Epoch: 172 | Batch_idx: 380 |  Loss: (0.0962) |  Loss2: (0.0000) | Acc: (96.00%) (47217/48768)
Epoch: 172 | Batch_idx: 390 |  Loss: (0.0959) |  Loss2: (0.0000) | Acc: (96.00%) (48415/50000)
# TEST : Loss: (0.3792) | Acc: (89.00%) (8909/10000)
percent tensor([0.5812, 0.5937, 0.5834, 0.5830, 0.5902, 0.5973, 0.5948, 0.5788, 0.5798,
        0.5864, 0.5882, 0.5904, 0.5845, 0.5775, 0.5993, 0.5862],
       device='cuda:0') torch.Size([16])
percent tensor([0.5280, 0.5299, 0.5185, 0.5255, 0.5182, 0.5357, 0.5228, 0.5180, 0.5211,
        0.5268, 0.5308, 0.5211, 0.5263, 0.5269, 0.5310, 0.5304],
       device='cuda:0') torch.Size([16])
percent tensor([0.5637, 0.4566, 0.6968, 0.7001, 0.7104, 0.6565, 0.5585, 0.6758, 0.6220,
        0.5295, 0.4871, 0.6280, 0.4709, 0.5462, 0.5225, 0.6149],
       device='cuda:0') torch.Size([16])
percent tensor([0.7067, 0.7483, 0.6127, 0.6450, 0.6096, 0.5499, 0.7055, 0.6493, 0.7152,
        0.7434, 0.7584, 0.6904, 0.7293, 0.7576, 0.6799, 0.6786],
       device='cuda:0') torch.Size([16])
percent tensor([0.7539, 0.6206, 0.7929, 0.7828, 0.8171, 0.8535, 0.7455, 0.7797, 0.7140,
        0.6324, 0.5941, 0.6579, 0.6018, 0.6682, 0.7332, 0.8024],
       device='cuda:0') torch.Size([16])
percent tensor([0.6115, 0.7131, 0.7302, 0.7611, 0.7491, 0.7957, 0.6986, 0.5213, 0.7454,
        0.7123, 0.7522, 0.7439, 0.7185, 0.7452, 0.5480, 0.5506],
       device='cuda:0') torch.Size([16])
percent tensor([0.4371, 0.7186, 0.6342, 0.6219, 0.6253, 0.6415, 0.6150, 0.5549, 0.6519,
        0.6157, 0.7263, 0.6509, 0.6322, 0.6788, 0.5233, 0.3930],
       device='cuda:0') torch.Size([16])
percent tensor([0.9998, 0.9998, 0.9996, 0.9999, 0.9999, 0.9996, 0.9998, 0.9997, 0.9998,
        0.9999, 0.9996, 1.0000, 0.9995, 0.9996, 0.9997, 0.9997],
       device='cuda:0') torch.Size([16])
Epoch: 173 | Batch_idx: 0 |  Loss: (0.0885) |  Loss2: (0.0000) | Acc: (98.00%) (126/128)
Epoch: 173 | Batch_idx: 10 |  Loss: (0.0868) |  Loss2: (0.0000) | Acc: (97.00%) (1368/1408)
Epoch: 173 | Batch_idx: 20 |  Loss: (0.0775) |  Loss2: (0.0000) | Acc: (97.00%) (2619/2688)
Epoch: 173 | Batch_idx: 30 |  Loss: (0.0846) |  Loss2: (0.0000) | Acc: (97.00%) (3856/3968)
Epoch: 173 | Batch_idx: 40 |  Loss: (0.0837) |  Loss2: (0.0000) | Acc: (97.00%) (5099/5248)
Epoch: 173 | Batch_idx: 50 |  Loss: (0.0885) |  Loss2: (0.0000) | Acc: (96.00%) (6331/6528)
Epoch: 173 | Batch_idx: 60 |  Loss: (0.0877) |  Loss2: (0.0000) | Acc: (97.00%) (7576/7808)
Epoch: 173 | Batch_idx: 70 |  Loss: (0.0872) |  Loss2: (0.0000) | Acc: (96.00%) (8814/9088)
Epoch: 173 | Batch_idx: 80 |  Loss: (0.0889) |  Loss2: (0.0000) | Acc: (96.00%) (10053/10368)
Epoch: 173 | Batch_idx: 90 |  Loss: (0.0889) |  Loss2: (0.0000) | Acc: (96.00%) (11297/11648)
Epoch: 173 | Batch_idx: 100 |  Loss: (0.0903) |  Loss2: (0.0000) | Acc: (96.00%) (12534/12928)
Epoch: 173 | Batch_idx: 110 |  Loss: (0.0897) |  Loss2: (0.0000) | Acc: (96.00%) (13778/14208)
Epoch: 173 | Batch_idx: 120 |  Loss: (0.0894) |  Loss2: (0.0000) | Acc: (96.00%) (15021/15488)
Epoch: 173 | Batch_idx: 130 |  Loss: (0.0888) |  Loss2: (0.0000) | Acc: (97.00%) (16265/16768)
Epoch: 173 | Batch_idx: 140 |  Loss: (0.0887) |  Loss2: (0.0000) | Acc: (96.00%) (17504/18048)
Epoch: 173 | Batch_idx: 150 |  Loss: (0.0882) |  Loss2: (0.0000) | Acc: (97.00%) (18750/19328)
Epoch: 173 | Batch_idx: 160 |  Loss: (0.0886) |  Loss2: (0.0000) | Acc: (96.00%) (19989/20608)
Epoch: 173 | Batch_idx: 170 |  Loss: (0.0886) |  Loss2: (0.0000) | Acc: (96.00%) (21228/21888)
Epoch: 173 | Batch_idx: 180 |  Loss: (0.0881) |  Loss2: (0.0000) | Acc: (97.00%) (22477/23168)
Epoch: 173 | Batch_idx: 190 |  Loss: (0.0890) |  Loss2: (0.0000) | Acc: (96.00%) (23708/24448)
Epoch: 173 | Batch_idx: 200 |  Loss: (0.0887) |  Loss2: (0.0000) | Acc: (96.00%) (24952/25728)
Epoch: 173 | Batch_idx: 210 |  Loss: (0.0889) |  Loss2: (0.0000) | Acc: (96.00%) (26192/27008)
Epoch: 173 | Batch_idx: 220 |  Loss: (0.0895) |  Loss2: (0.0000) | Acc: (96.00%) (27428/28288)
Epoch: 173 | Batch_idx: 230 |  Loss: (0.0892) |  Loss2: (0.0000) | Acc: (96.00%) (28672/29568)
Epoch: 173 | Batch_idx: 240 |  Loss: (0.0885) |  Loss2: (0.0000) | Acc: (96.00%) (29920/30848)
Epoch: 173 | Batch_idx: 250 |  Loss: (0.0889) |  Loss2: (0.0000) | Acc: (96.00%) (31156/32128)
Epoch: 173 | Batch_idx: 260 |  Loss: (0.0888) |  Loss2: (0.0000) | Acc: (96.00%) (32400/33408)
Epoch: 173 | Batch_idx: 270 |  Loss: (0.0888) |  Loss2: (0.0000) | Acc: (96.00%) (33642/34688)
Epoch: 173 | Batch_idx: 280 |  Loss: (0.0885) |  Loss2: (0.0000) | Acc: (97.00%) (34892/35968)
Epoch: 173 | Batch_idx: 290 |  Loss: (0.0890) |  Loss2: (0.0000) | Acc: (96.00%) (36122/37248)
Epoch: 173 | Batch_idx: 300 |  Loss: (0.0890) |  Loss2: (0.0000) | Acc: (96.00%) (37365/38528)
Epoch: 173 | Batch_idx: 310 |  Loss: (0.0890) |  Loss2: (0.0000) | Acc: (96.00%) (38604/39808)
Epoch: 173 | Batch_idx: 320 |  Loss: (0.0890) |  Loss2: (0.0000) | Acc: (96.00%) (39843/41088)
Epoch: 173 | Batch_idx: 330 |  Loss: (0.0887) |  Loss2: (0.0000) | Acc: (96.00%) (41094/42368)
Epoch: 173 | Batch_idx: 340 |  Loss: (0.0888) |  Loss2: (0.0000) | Acc: (96.00%) (42332/43648)
Epoch: 173 | Batch_idx: 350 |  Loss: (0.0891) |  Loss2: (0.0000) | Acc: (96.00%) (43572/44928)
Epoch: 173 | Batch_idx: 360 |  Loss: (0.0890) |  Loss2: (0.0000) | Acc: (96.00%) (44821/46208)
Epoch: 173 | Batch_idx: 370 |  Loss: (0.0895) |  Loss2: (0.0000) | Acc: (96.00%) (46050/47488)
Epoch: 173 | Batch_idx: 380 |  Loss: (0.0894) |  Loss2: (0.0000) | Acc: (96.00%) (47292/48768)
Epoch: 173 | Batch_idx: 390 |  Loss: (0.0892) |  Loss2: (0.0000) | Acc: (96.00%) (48493/50000)
# TEST : Loss: (0.3750) | Acc: (89.00%) (8925/10000)
percent tensor([0.5785, 0.5909, 0.5806, 0.5805, 0.5873, 0.5945, 0.5917, 0.5761, 0.5770,
        0.5836, 0.5854, 0.5876, 0.5817, 0.5750, 0.5964, 0.5836],
       device='cuda:0') torch.Size([16])
percent tensor([0.5289, 0.5307, 0.5186, 0.5263, 0.5179, 0.5372, 0.5228, 0.5176, 0.5215,
        0.5276, 0.5318, 0.5216, 0.5267, 0.5271, 0.5321, 0.5315],
       device='cuda:0') torch.Size([16])
percent tensor([0.5614, 0.4511, 0.6955, 0.6986, 0.7106, 0.6545, 0.5553, 0.6758, 0.6210,
        0.5253, 0.4825, 0.6252, 0.4662, 0.5438, 0.5173, 0.6114],
       device='cuda:0') torch.Size([16])
percent tensor([0.7041, 0.7440, 0.6101, 0.6411, 0.6068, 0.5472, 0.7023, 0.6461, 0.7119,
        0.7404, 0.7547, 0.6876, 0.7259, 0.7541, 0.6747, 0.6759],
       device='cuda:0') torch.Size([16])
percent tensor([0.7510, 0.6192, 0.7938, 0.7848, 0.8170, 0.8528, 0.7449, 0.7797, 0.7124,
        0.6282, 0.5887, 0.6583, 0.5994, 0.6680, 0.7326, 0.7987],
       device='cuda:0') torch.Size([16])
percent tensor([0.6174, 0.7162, 0.7341, 0.7650, 0.7550, 0.7994, 0.7035, 0.5308, 0.7488,
        0.7135, 0.7535, 0.7459, 0.7198, 0.7458, 0.5584, 0.5584],
       device='cuda:0') torch.Size([16])
percent tensor([0.4396, 0.7224, 0.6348, 0.6246, 0.6258, 0.6490, 0.6135, 0.5580, 0.6525,
        0.6196, 0.7279, 0.6501, 0.6350, 0.6715, 0.5221, 0.3937],
       device='cuda:0') torch.Size([16])
percent tensor([0.9998, 0.9999, 0.9996, 0.9999, 0.9999, 0.9996, 0.9999, 0.9997, 0.9998,
        0.9999, 0.9996, 1.0000, 0.9995, 0.9996, 0.9997, 0.9997],
       device='cuda:0') torch.Size([16])
True Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=128, out_features=16, bias=False)
False Linear(in_features=16, out_features=2, bias=False)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=128, out_features=16, bias=False)
False Linear(in_features=16, out_features=2, bias=False)
True Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=256, out_features=32, bias=False)
False Linear(in_features=32, out_features=2, bias=False)
True Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=256, out_features=32, bias=False)
False Linear(in_features=32, out_features=2, bias=False)
True Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=512, out_features=64, bias=False)
False Linear(in_features=64, out_features=2, bias=False)
True Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=512, out_features=64, bias=False)
False Linear(in_features=64, out_features=2, bias=False)
True Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1024, out_features=128, bias=False)
False Linear(in_features=128, out_features=2, bias=False)
True Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1024, out_features=128, bias=False)
False Linear(in_features=128, out_features=2, bias=False)
True Linear(in_features=512, out_features=10, bias=True)
Epoch: 174 | Batch_idx: 0 |  Loss: (0.0606) |  Loss2: (0.0000) | Acc: (97.00%) (125/128)
Epoch: 174 | Batch_idx: 10 |  Loss: (0.0853) |  Loss2: (0.0000) | Acc: (97.00%) (1372/1408)
Epoch: 174 | Batch_idx: 20 |  Loss: (0.0892) |  Loss2: (0.0000) | Acc: (97.00%) (2614/2688)
Epoch: 174 | Batch_idx: 30 |  Loss: (0.0829) |  Loss2: (0.0000) | Acc: (97.00%) (3868/3968)
Epoch: 174 | Batch_idx: 40 |  Loss: (0.0847) |  Loss2: (0.0000) | Acc: (97.00%) (5112/5248)
Epoch: 174 | Batch_idx: 50 |  Loss: (0.0853) |  Loss2: (0.0000) | Acc: (97.00%) (6353/6528)
Epoch: 174 | Batch_idx: 60 |  Loss: (0.0870) |  Loss2: (0.0000) | Acc: (97.00%) (7595/7808)
Epoch: 174 | Batch_idx: 70 |  Loss: (0.0868) |  Loss2: (0.0000) | Acc: (97.00%) (8835/9088)
Epoch: 174 | Batch_idx: 80 |  Loss: (0.0861) |  Loss2: (0.0000) | Acc: (97.00%) (10083/10368)
Epoch: 174 | Batch_idx: 90 |  Loss: (0.0846) |  Loss2: (0.0000) | Acc: (97.00%) (11335/11648)
Epoch: 174 | Batch_idx: 100 |  Loss: (0.0831) |  Loss2: (0.0000) | Acc: (97.00%) (12587/12928)
Epoch: 174 | Batch_idx: 110 |  Loss: (0.0830) |  Loss2: (0.0000) | Acc: (97.00%) (13832/14208)
Epoch: 174 | Batch_idx: 120 |  Loss: (0.0833) |  Loss2: (0.0000) | Acc: (97.00%) (15079/15488)
Epoch: 174 | Batch_idx: 130 |  Loss: (0.0836) |  Loss2: (0.0000) | Acc: (97.00%) (16324/16768)
Epoch: 174 | Batch_idx: 140 |  Loss: (0.0836) |  Loss2: (0.0000) | Acc: (97.00%) (17573/18048)
Epoch: 174 | Batch_idx: 150 |  Loss: (0.0834) |  Loss2: (0.0000) | Acc: (97.00%) (18820/19328)
Epoch: 174 | Batch_idx: 160 |  Loss: (0.0827) |  Loss2: (0.0000) | Acc: (97.00%) (20074/20608)
Epoch: 174 | Batch_idx: 170 |  Loss: (0.0827) |  Loss2: (0.0000) | Acc: (97.00%) (21317/21888)
Epoch: 174 | Batch_idx: 180 |  Loss: (0.0830) |  Loss2: (0.0000) | Acc: (97.00%) (22556/23168)
Epoch: 174 | Batch_idx: 190 |  Loss: (0.0839) |  Loss2: (0.0000) | Acc: (97.00%) (23791/24448)
Epoch: 174 | Batch_idx: 200 |  Loss: (0.0840) |  Loss2: (0.0000) | Acc: (97.00%) (25035/25728)
Epoch: 174 | Batch_idx: 210 |  Loss: (0.0843) |  Loss2: (0.0000) | Acc: (97.00%) (26276/27008)
Epoch: 174 | Batch_idx: 220 |  Loss: (0.0845) |  Loss2: (0.0000) | Acc: (97.00%) (27519/28288)
Epoch: 174 | Batch_idx: 230 |  Loss: (0.0854) |  Loss2: (0.0000) | Acc: (97.00%) (28747/29568)
Epoch: 174 | Batch_idx: 240 |  Loss: (0.0861) |  Loss2: (0.0000) | Acc: (97.00%) (29987/30848)
Epoch: 174 | Batch_idx: 250 |  Loss: (0.0868) |  Loss2: (0.0000) | Acc: (97.00%) (31219/32128)
Epoch: 174 | Batch_idx: 260 |  Loss: (0.0870) |  Loss2: (0.0000) | Acc: (97.00%) (32460/33408)
Epoch: 174 | Batch_idx: 270 |  Loss: (0.0874) |  Loss2: (0.0000) | Acc: (97.00%) (33694/34688)
Epoch: 174 | Batch_idx: 280 |  Loss: (0.0880) |  Loss2: (0.0000) | Acc: (97.00%) (34926/35968)
Epoch: 174 | Batch_idx: 290 |  Loss: (0.0877) |  Loss2: (0.0000) | Acc: (97.00%) (36174/37248)
Epoch: 174 | Batch_idx: 300 |  Loss: (0.0885) |  Loss2: (0.0000) | Acc: (97.00%) (37411/38528)
Epoch: 174 | Batch_idx: 310 |  Loss: (0.0891) |  Loss2: (0.0000) | Acc: (97.00%) (38650/39808)
Epoch: 174 | Batch_idx: 320 |  Loss: (0.0889) |  Loss2: (0.0000) | Acc: (97.00%) (39900/41088)
Epoch: 174 | Batch_idx: 330 |  Loss: (0.0894) |  Loss2: (0.0000) | Acc: (97.00%) (41133/42368)
Epoch: 174 | Batch_idx: 340 |  Loss: (0.0893) |  Loss2: (0.0000) | Acc: (97.00%) (42371/43648)
Epoch: 174 | Batch_idx: 350 |  Loss: (0.0897) |  Loss2: (0.0000) | Acc: (97.00%) (43600/44928)
Epoch: 174 | Batch_idx: 360 |  Loss: (0.0900) |  Loss2: (0.0000) | Acc: (97.00%) (44830/46208)
Epoch: 174 | Batch_idx: 370 |  Loss: (0.0903) |  Loss2: (0.0000) | Acc: (96.00%) (46062/47488)
Epoch: 174 | Batch_idx: 380 |  Loss: (0.0904) |  Loss2: (0.0000) | Acc: (96.00%) (47301/48768)
Epoch: 174 | Batch_idx: 390 |  Loss: (0.0903) |  Loss2: (0.0000) | Acc: (96.00%) (48495/50000)
# TEST : Loss: (0.4205) | Acc: (88.00%) (8839/10000)
percent tensor([0.5788, 0.5908, 0.5801, 0.5796, 0.5864, 0.5953, 0.5911, 0.5757, 0.5775,
        0.5829, 0.5852, 0.5863, 0.5814, 0.5750, 0.5959, 0.5837],
       device='cuda:0') torch.Size([16])
percent tensor([0.5287, 0.5314, 0.5183, 0.5257, 0.5159, 0.5360, 0.5232, 0.5181, 0.5204,
        0.5277, 0.5320, 0.5213, 0.5266, 0.5293, 0.5317, 0.5317],
       device='cuda:0') torch.Size([16])
percent tensor([0.5776, 0.4600, 0.6973, 0.7026, 0.7149, 0.6644, 0.5572, 0.6700, 0.6357,
        0.5328, 0.4961, 0.6290, 0.4845, 0.5546, 0.5223, 0.6225],
       device='cuda:0') torch.Size([16])
percent tensor([0.7100, 0.7382, 0.6168, 0.6326, 0.6183, 0.5562, 0.7029, 0.6487, 0.7102,
        0.7411, 0.7559, 0.6880, 0.7254, 0.7498, 0.6778, 0.6702],
       device='cuda:0') torch.Size([16])
percent tensor([0.7474, 0.6442, 0.7854, 0.7878, 0.8050, 0.8517, 0.7454, 0.7694, 0.7112,
        0.6341, 0.5899, 0.6573, 0.5991, 0.6730, 0.7385, 0.8095],
       device='cuda:0') torch.Size([16])
percent tensor([0.5914, 0.7367, 0.7268, 0.7633, 0.7438, 0.8081, 0.7144, 0.5405, 0.7337,
        0.7147, 0.7576, 0.7322, 0.7276, 0.7463, 0.5465, 0.5738],
       device='cuda:0') torch.Size([16])
percent tensor([0.4236, 0.7214, 0.6388, 0.6362, 0.6445, 0.6737, 0.6272, 0.5809, 0.6578,
        0.6377, 0.7287, 0.6396, 0.6047, 0.6476, 0.5196, 0.3995],
       device='cuda:0') torch.Size([16])
percent tensor([0.9997, 0.9997, 0.9998, 0.9999, 1.0000, 0.9997, 0.9999, 0.9998, 0.9998,
        0.9999, 0.9997, 1.0000, 0.9993, 0.9995, 0.9997, 0.9996],
       device='cuda:0') torch.Size([16])
Epoch: 175 | Batch_idx: 0 |  Loss: (0.0874) |  Loss2: (0.0000) | Acc: (96.00%) (123/128)
Epoch: 175 | Batch_idx: 10 |  Loss: (0.0915) |  Loss2: (0.0000) | Acc: (96.00%) (1360/1408)
Epoch: 175 | Batch_idx: 20 |  Loss: (0.0838) |  Loss2: (0.0000) | Acc: (97.00%) (2611/2688)
Epoch: 175 | Batch_idx: 30 |  Loss: (0.0852) |  Loss2: (0.0000) | Acc: (96.00%) (3848/3968)
Epoch: 175 | Batch_idx: 40 |  Loss: (0.0866) |  Loss2: (0.0000) | Acc: (96.00%) (5089/5248)
Epoch: 175 | Batch_idx: 50 |  Loss: (0.0841) |  Loss2: (0.0000) | Acc: (97.00%) (6338/6528)
Epoch: 175 | Batch_idx: 60 |  Loss: (0.0843) |  Loss2: (0.0000) | Acc: (97.00%) (7585/7808)
Epoch: 175 | Batch_idx: 70 |  Loss: (0.0828) |  Loss2: (0.0000) | Acc: (97.00%) (8833/9088)
Epoch: 175 | Batch_idx: 80 |  Loss: (0.0845) |  Loss2: (0.0000) | Acc: (97.00%) (10063/10368)
Epoch: 175 | Batch_idx: 90 |  Loss: (0.0843) |  Loss2: (0.0000) | Acc: (97.00%) (11304/11648)
Epoch: 175 | Batch_idx: 100 |  Loss: (0.0836) |  Loss2: (0.0000) | Acc: (97.00%) (12542/12928)
Epoch: 175 | Batch_idx: 110 |  Loss: (0.0842) |  Loss2: (0.0000) | Acc: (96.00%) (13781/14208)
Epoch: 175 | Batch_idx: 120 |  Loss: (0.0867) |  Loss2: (0.0000) | Acc: (96.00%) (15006/15488)
Epoch: 175 | Batch_idx: 130 |  Loss: (0.0876) |  Loss2: (0.0000) | Acc: (96.00%) (16246/16768)
Epoch: 175 | Batch_idx: 140 |  Loss: (0.0876) |  Loss2: (0.0000) | Acc: (96.00%) (17489/18048)
Epoch: 175 | Batch_idx: 150 |  Loss: (0.0881) |  Loss2: (0.0000) | Acc: (96.00%) (18725/19328)
Epoch: 175 | Batch_idx: 160 |  Loss: (0.0892) |  Loss2: (0.0000) | Acc: (96.00%) (19949/20608)
Epoch: 175 | Batch_idx: 170 |  Loss: (0.0898) |  Loss2: (0.0000) | Acc: (96.00%) (21187/21888)
Epoch: 175 | Batch_idx: 180 |  Loss: (0.0901) |  Loss2: (0.0000) | Acc: (96.00%) (22431/23168)
Epoch: 175 | Batch_idx: 190 |  Loss: (0.0896) |  Loss2: (0.0000) | Acc: (96.00%) (23679/24448)
Epoch: 175 | Batch_idx: 200 |  Loss: (0.0887) |  Loss2: (0.0000) | Acc: (96.00%) (24930/25728)
Epoch: 175 | Batch_idx: 210 |  Loss: (0.0900) |  Loss2: (0.0000) | Acc: (96.00%) (26151/27008)
Epoch: 175 | Batch_idx: 220 |  Loss: (0.0898) |  Loss2: (0.0000) | Acc: (96.00%) (27395/28288)
Epoch: 175 | Batch_idx: 230 |  Loss: (0.0902) |  Loss2: (0.0000) | Acc: (96.00%) (28632/29568)
Epoch: 175 | Batch_idx: 240 |  Loss: (0.0903) |  Loss2: (0.0000) | Acc: (96.00%) (29873/30848)
Epoch: 175 | Batch_idx: 250 |  Loss: (0.0904) |  Loss2: (0.0000) | Acc: (96.00%) (31113/32128)
Epoch: 175 | Batch_idx: 260 |  Loss: (0.0900) |  Loss2: (0.0000) | Acc: (96.00%) (32361/33408)
Epoch: 175 | Batch_idx: 270 |  Loss: (0.0900) |  Loss2: (0.0000) | Acc: (96.00%) (33600/34688)
Epoch: 175 | Batch_idx: 280 |  Loss: (0.0901) |  Loss2: (0.0000) | Acc: (96.00%) (34838/35968)
Epoch: 175 | Batch_idx: 290 |  Loss: (0.0907) |  Loss2: (0.0000) | Acc: (96.00%) (36074/37248)
Epoch: 175 | Batch_idx: 300 |  Loss: (0.0908) |  Loss2: (0.0000) | Acc: (96.00%) (37316/38528)
Epoch: 175 | Batch_idx: 310 |  Loss: (0.0908) |  Loss2: (0.0000) | Acc: (96.00%) (38557/39808)
Epoch: 175 | Batch_idx: 320 |  Loss: (0.0909) |  Loss2: (0.0000) | Acc: (96.00%) (39802/41088)
Epoch: 175 | Batch_idx: 330 |  Loss: (0.0921) |  Loss2: (0.0000) | Acc: (96.00%) (41020/42368)
Epoch: 175 | Batch_idx: 340 |  Loss: (0.0921) |  Loss2: (0.0000) | Acc: (96.00%) (42257/43648)
Epoch: 175 | Batch_idx: 350 |  Loss: (0.0927) |  Loss2: (0.0000) | Acc: (96.00%) (43482/44928)
Epoch: 175 | Batch_idx: 360 |  Loss: (0.0922) |  Loss2: (0.0000) | Acc: (96.00%) (44726/46208)
Epoch: 175 | Batch_idx: 370 |  Loss: (0.0924) |  Loss2: (0.0000) | Acc: (96.00%) (45969/47488)
Epoch: 175 | Batch_idx: 380 |  Loss: (0.0925) |  Loss2: (0.0000) | Acc: (96.00%) (47203/48768)
Epoch: 175 | Batch_idx: 390 |  Loss: (0.0928) |  Loss2: (0.0000) | Acc: (96.00%) (48388/50000)
=> saving checkpoint 'drive/app/torch/save_Schedule/checkpoint_175.pth.tar'
# TEST : Loss: (0.3901) | Acc: (89.00%) (8903/10000)
percent tensor([0.5792, 0.5908, 0.5822, 0.5812, 0.5872, 0.5956, 0.5915, 0.5763, 0.5767,
        0.5840, 0.5853, 0.5881, 0.5817, 0.5743, 0.5967, 0.5840],
       device='cuda:0') torch.Size([16])
percent tensor([0.5281, 0.5317, 0.5176, 0.5253, 0.5153, 0.5364, 0.5230, 0.5187, 0.5202,
        0.5274, 0.5316, 0.5205, 0.5261, 0.5288, 0.5315, 0.5315],
       device='cuda:0') torch.Size([16])
percent tensor([0.5704, 0.4599, 0.7049, 0.7022, 0.7204, 0.6614, 0.5651, 0.6808, 0.6339,
        0.5424, 0.4879, 0.6453, 0.4815, 0.5656, 0.5203, 0.6170],
       device='cuda:0') torch.Size([16])
percent tensor([0.7055, 0.7379, 0.6231, 0.6428, 0.6206, 0.5572, 0.7038, 0.6463, 0.7045,
        0.7384, 0.7543, 0.6863, 0.7179, 0.7487, 0.6768, 0.6756],
       device='cuda:0') torch.Size([16])
percent tensor([0.7474, 0.6323, 0.7816, 0.7741, 0.8045, 0.8491, 0.7394, 0.7681, 0.7094,
        0.6171, 0.5933, 0.6451, 0.6003, 0.6654, 0.7299, 0.7970],
       device='cuda:0') torch.Size([16])
percent tensor([0.5828, 0.7154, 0.7341, 0.7869, 0.7537, 0.8010, 0.7090, 0.5453, 0.7352,
        0.7058, 0.7316, 0.7458, 0.7264, 0.7206, 0.5489, 0.5527],
       device='cuda:0') torch.Size([16])
percent tensor([0.4361, 0.7109, 0.6483, 0.6659, 0.6327, 0.6619, 0.6443, 0.5691, 0.6722,
        0.6387, 0.7057, 0.6244, 0.6435, 0.6390, 0.5196, 0.4070],
       device='cuda:0') torch.Size([16])
percent tensor([0.9998, 0.9998, 0.9997, 0.9999, 1.0000, 0.9996, 0.9999, 0.9997, 0.9998,
        0.9999, 0.9997, 0.9999, 0.9995, 0.9998, 0.9997, 0.9995],
       device='cuda:0') torch.Size([16])
Epoch: 176 | Batch_idx: 0 |  Loss: (0.0878) |  Loss2: (0.0000) | Acc: (96.00%) (123/128)
Epoch: 176 | Batch_idx: 10 |  Loss: (0.0990) |  Loss2: (0.0000) | Acc: (96.00%) (1361/1408)
Epoch: 176 | Batch_idx: 20 |  Loss: (0.0904) |  Loss2: (0.0000) | Acc: (96.00%) (2606/2688)
Epoch: 176 | Batch_idx: 30 |  Loss: (0.0873) |  Loss2: (0.0000) | Acc: (96.00%) (3847/3968)
Epoch: 176 | Batch_idx: 40 |  Loss: (0.0883) |  Loss2: (0.0000) | Acc: (96.00%) (5089/5248)
Epoch: 176 | Batch_idx: 50 |  Loss: (0.0915) |  Loss2: (0.0000) | Acc: (96.00%) (6321/6528)
Epoch: 176 | Batch_idx: 60 |  Loss: (0.0912) |  Loss2: (0.0000) | Acc: (96.00%) (7562/7808)
Epoch: 176 | Batch_idx: 70 |  Loss: (0.0893) |  Loss2: (0.0000) | Acc: (96.00%) (8812/9088)
Epoch: 176 | Batch_idx: 80 |  Loss: (0.0874) |  Loss2: (0.0000) | Acc: (97.00%) (10063/10368)
Epoch: 176 | Batch_idx: 90 |  Loss: (0.0865) |  Loss2: (0.0000) | Acc: (97.00%) (11304/11648)
Epoch: 176 | Batch_idx: 100 |  Loss: (0.0865) |  Loss2: (0.0000) | Acc: (97.00%) (12553/12928)
Epoch: 176 | Batch_idx: 110 |  Loss: (0.0859) |  Loss2: (0.0000) | Acc: (97.00%) (13797/14208)
Epoch: 176 | Batch_idx: 120 |  Loss: (0.0848) |  Loss2: (0.0000) | Acc: (97.00%) (15044/15488)
Epoch: 176 | Batch_idx: 130 |  Loss: (0.0849) |  Loss2: (0.0000) | Acc: (97.00%) (16282/16768)
Epoch: 176 | Batch_idx: 140 |  Loss: (0.0851) |  Loss2: (0.0000) | Acc: (97.00%) (17525/18048)
Epoch: 176 | Batch_idx: 150 |  Loss: (0.0856) |  Loss2: (0.0000) | Acc: (97.00%) (18765/19328)
Epoch: 176 | Batch_idx: 160 |  Loss: (0.0868) |  Loss2: (0.0000) | Acc: (97.00%) (19997/20608)
Epoch: 176 | Batch_idx: 170 |  Loss: (0.0880) |  Loss2: (0.0000) | Acc: (96.00%) (21223/21888)
Epoch: 176 | Batch_idx: 180 |  Loss: (0.0882) |  Loss2: (0.0000) | Acc: (96.00%) (22468/23168)
Epoch: 176 | Batch_idx: 190 |  Loss: (0.0887) |  Loss2: (0.0000) | Acc: (96.00%) (23705/24448)
Epoch: 176 | Batch_idx: 200 |  Loss: (0.0894) |  Loss2: (0.0000) | Acc: (96.00%) (24944/25728)
Epoch: 176 | Batch_idx: 210 |  Loss: (0.0893) |  Loss2: (0.0000) | Acc: (96.00%) (26182/27008)
Epoch: 176 | Batch_idx: 220 |  Loss: (0.0893) |  Loss2: (0.0000) | Acc: (96.00%) (27422/28288)
Epoch: 176 | Batch_idx: 230 |  Loss: (0.0894) |  Loss2: (0.0000) | Acc: (96.00%) (28653/29568)
Epoch: 176 | Batch_idx: 240 |  Loss: (0.0887) |  Loss2: (0.0000) | Acc: (96.00%) (29897/30848)
Epoch: 176 | Batch_idx: 250 |  Loss: (0.0883) |  Loss2: (0.0000) | Acc: (96.00%) (31145/32128)
Epoch: 176 | Batch_idx: 260 |  Loss: (0.0883) |  Loss2: (0.0000) | Acc: (96.00%) (32383/33408)
Epoch: 176 | Batch_idx: 270 |  Loss: (0.0884) |  Loss2: (0.0000) | Acc: (96.00%) (33618/34688)
Epoch: 176 | Batch_idx: 280 |  Loss: (0.0887) |  Loss2: (0.0000) | Acc: (96.00%) (34856/35968)
Epoch: 176 | Batch_idx: 290 |  Loss: (0.0894) |  Loss2: (0.0000) | Acc: (96.00%) (36092/37248)
Epoch: 176 | Batch_idx: 300 |  Loss: (0.0891) |  Loss2: (0.0000) | Acc: (96.00%) (37334/38528)
Epoch: 176 | Batch_idx: 310 |  Loss: (0.0889) |  Loss2: (0.0000) | Acc: (96.00%) (38577/39808)
Epoch: 176 | Batch_idx: 320 |  Loss: (0.0894) |  Loss2: (0.0000) | Acc: (96.00%) (39810/41088)
Epoch: 176 | Batch_idx: 330 |  Loss: (0.0891) |  Loss2: (0.0000) | Acc: (96.00%) (41060/42368)
Epoch: 176 | Batch_idx: 340 |  Loss: (0.0891) |  Loss2: (0.0000) | Acc: (96.00%) (42299/43648)
Epoch: 176 | Batch_idx: 350 |  Loss: (0.0892) |  Loss2: (0.0000) | Acc: (96.00%) (43546/44928)
Epoch: 176 | Batch_idx: 360 |  Loss: (0.0900) |  Loss2: (0.0000) | Acc: (96.00%) (44772/46208)
Epoch: 176 | Batch_idx: 370 |  Loss: (0.0908) |  Loss2: (0.0000) | Acc: (96.00%) (46007/47488)
Epoch: 176 | Batch_idx: 380 |  Loss: (0.0906) |  Loss2: (0.0000) | Acc: (96.00%) (47254/48768)
Epoch: 176 | Batch_idx: 390 |  Loss: (0.0903) |  Loss2: (0.0000) | Acc: (96.00%) (48456/50000)
# TEST : Loss: (0.4445) | Acc: (88.00%) (8810/10000)
percent tensor([0.5799, 0.5892, 0.5830, 0.5801, 0.5894, 0.5968, 0.5920, 0.5766, 0.5784,
        0.5836, 0.5856, 0.5892, 0.5822, 0.5734, 0.5962, 0.5838],
       device='cuda:0') torch.Size([16])
percent tensor([0.5287, 0.5316, 0.5176, 0.5252, 0.5164, 0.5372, 0.5232, 0.5166, 0.5209,
        0.5276, 0.5322, 0.5216, 0.5269, 0.5291, 0.5323, 0.5319],
       device='cuda:0') torch.Size([16])
percent tensor([0.5823, 0.4551, 0.7063, 0.7118, 0.7185, 0.6646, 0.5597, 0.6835, 0.6235,
        0.5327, 0.4800, 0.6354, 0.4788, 0.5496, 0.5289, 0.6253],
       device='cuda:0') torch.Size([16])
percent tensor([0.7016, 0.7403, 0.6256, 0.6382, 0.6231, 0.5491, 0.7017, 0.6426, 0.7120,
        0.7400, 0.7490, 0.6937, 0.7211, 0.7501, 0.6719, 0.6660],
       device='cuda:0') torch.Size([16])
percent tensor([0.7506, 0.6365, 0.7791, 0.7692, 0.8009, 0.8472, 0.7434, 0.7738, 0.7094,
        0.6191, 0.6021, 0.6346, 0.6073, 0.6641, 0.7403, 0.8001],
       device='cuda:0') torch.Size([16])
percent tensor([0.6229, 0.7413, 0.7700, 0.7983, 0.7790, 0.8211, 0.7374, 0.6024, 0.7373,
        0.7306, 0.7644, 0.7678, 0.7484, 0.7632, 0.6048, 0.6126],
       device='cuda:0') torch.Size([16])
percent tensor([0.4612, 0.7198, 0.6673, 0.6654, 0.6423, 0.6677, 0.6389, 0.5930, 0.6515,
        0.6698, 0.7207, 0.6562, 0.6572, 0.6857, 0.5339, 0.4055],
       device='cuda:0') torch.Size([16])
percent tensor([0.9998, 0.9998, 0.9997, 0.9999, 0.9999, 0.9997, 0.9999, 0.9995, 0.9999,
        0.9999, 0.9997, 1.0000, 0.9997, 0.9996, 0.9998, 0.9996],
       device='cuda:0') torch.Size([16])
False Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=128, out_features=16, bias=False)
True Linear(in_features=16, out_features=2, bias=False)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=128, out_features=16, bias=False)
True Linear(in_features=16, out_features=2, bias=False)
False Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=256, out_features=32, bias=False)
True Linear(in_features=32, out_features=2, bias=False)
False Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=256, out_features=32, bias=False)
True Linear(in_features=32, out_features=2, bias=False)
False Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=512, out_features=64, bias=False)
True Linear(in_features=64, out_features=2, bias=False)
False Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=512, out_features=64, bias=False)
True Linear(in_features=64, out_features=2, bias=False)
False Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1024, out_features=128, bias=False)
True Linear(in_features=128, out_features=2, bias=False)
False Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1024, out_features=128, bias=False)
True Linear(in_features=128, out_features=2, bias=False)
False Linear(in_features=512, out_features=10, bias=True)
Epoch: 177 | Batch_idx: 0 |  Loss: (0.0928) |  Loss2: (0.0000) | Acc: (97.00%) (125/128)
Epoch: 177 | Batch_idx: 10 |  Loss: (0.1003) |  Loss2: (0.0000) | Acc: (96.00%) (1363/1408)
Epoch: 177 | Batch_idx: 20 |  Loss: (0.1110) |  Loss2: (0.0000) | Acc: (96.00%) (2587/2688)
Epoch: 177 | Batch_idx: 30 |  Loss: (0.1129) |  Loss2: (0.0000) | Acc: (96.00%) (3811/3968)
Epoch: 177 | Batch_idx: 40 |  Loss: (0.1192) |  Loss2: (0.0000) | Acc: (95.00%) (5029/5248)
Epoch: 177 | Batch_idx: 50 |  Loss: (0.1189) |  Loss2: (0.0000) | Acc: (95.00%) (6251/6528)
Epoch: 177 | Batch_idx: 60 |  Loss: (0.1155) |  Loss2: (0.0000) | Acc: (95.00%) (7493/7808)
Epoch: 177 | Batch_idx: 70 |  Loss: (0.1141) |  Loss2: (0.0000) | Acc: (96.00%) (8730/9088)
Epoch: 177 | Batch_idx: 80 |  Loss: (0.1131) |  Loss2: (0.0000) | Acc: (96.00%) (9961/10368)
Epoch: 177 | Batch_idx: 90 |  Loss: (0.1137) |  Loss2: (0.0000) | Acc: (96.00%) (11188/11648)
Epoch: 177 | Batch_idx: 100 |  Loss: (0.1136) |  Loss2: (0.0000) | Acc: (96.00%) (12423/12928)
Epoch: 177 | Batch_idx: 110 |  Loss: (0.1151) |  Loss2: (0.0000) | Acc: (96.00%) (13649/14208)
Epoch: 177 | Batch_idx: 120 |  Loss: (0.1145) |  Loss2: (0.0000) | Acc: (96.00%) (14886/15488)
Epoch: 177 | Batch_idx: 130 |  Loss: (0.1140) |  Loss2: (0.0000) | Acc: (96.00%) (16119/16768)
Epoch: 177 | Batch_idx: 140 |  Loss: (0.1131) |  Loss2: (0.0000) | Acc: (96.00%) (17349/18048)
Epoch: 177 | Batch_idx: 150 |  Loss: (0.1136) |  Loss2: (0.0000) | Acc: (96.00%) (18579/19328)
Epoch: 177 | Batch_idx: 160 |  Loss: (0.1122) |  Loss2: (0.0000) | Acc: (96.00%) (19815/20608)
Epoch: 177 | Batch_idx: 170 |  Loss: (0.1118) |  Loss2: (0.0000) | Acc: (96.00%) (21053/21888)
Epoch: 177 | Batch_idx: 180 |  Loss: (0.1103) |  Loss2: (0.0000) | Acc: (96.00%) (22299/23168)
Epoch: 177 | Batch_idx: 190 |  Loss: (0.1091) |  Loss2: (0.0000) | Acc: (96.00%) (23542/24448)
Epoch: 177 | Batch_idx: 200 |  Loss: (0.1092) |  Loss2: (0.0000) | Acc: (96.00%) (24771/25728)
Epoch: 177 | Batch_idx: 210 |  Loss: (0.1095) |  Loss2: (0.0000) | Acc: (96.00%) (25996/27008)
Epoch: 177 | Batch_idx: 220 |  Loss: (0.1088) |  Loss2: (0.0000) | Acc: (96.00%) (27241/28288)
Epoch: 177 | Batch_idx: 230 |  Loss: (0.1084) |  Loss2: (0.0000) | Acc: (96.00%) (28481/29568)
Epoch: 177 | Batch_idx: 240 |  Loss: (0.1083) |  Loss2: (0.0000) | Acc: (96.00%) (29709/30848)
Epoch: 177 | Batch_idx: 250 |  Loss: (0.1080) |  Loss2: (0.0000) | Acc: (96.00%) (30940/32128)
Epoch: 177 | Batch_idx: 260 |  Loss: (0.1088) |  Loss2: (0.0000) | Acc: (96.00%) (32162/33408)
Epoch: 177 | Batch_idx: 270 |  Loss: (0.1080) |  Loss2: (0.0000) | Acc: (96.00%) (33406/34688)
Epoch: 177 | Batch_idx: 280 |  Loss: (0.1077) |  Loss2: (0.0000) | Acc: (96.00%) (34639/35968)
Epoch: 177 | Batch_idx: 290 |  Loss: (0.1070) |  Loss2: (0.0000) | Acc: (96.00%) (35880/37248)
Epoch: 177 | Batch_idx: 300 |  Loss: (0.1075) |  Loss2: (0.0000) | Acc: (96.00%) (37102/38528)
Epoch: 177 | Batch_idx: 310 |  Loss: (0.1073) |  Loss2: (0.0000) | Acc: (96.00%) (38338/39808)
Epoch: 177 | Batch_idx: 320 |  Loss: (0.1070) |  Loss2: (0.0000) | Acc: (96.00%) (39570/41088)
Epoch: 177 | Batch_idx: 330 |  Loss: (0.1067) |  Loss2: (0.0000) | Acc: (96.00%) (40808/42368)
Epoch: 177 | Batch_idx: 340 |  Loss: (0.1062) |  Loss2: (0.0000) | Acc: (96.00%) (42046/43648)
Epoch: 177 | Batch_idx: 350 |  Loss: (0.1059) |  Loss2: (0.0000) | Acc: (96.00%) (43283/44928)
Epoch: 177 | Batch_idx: 360 |  Loss: (0.1057) |  Loss2: (0.0000) | Acc: (96.00%) (44518/46208)
Epoch: 177 | Batch_idx: 370 |  Loss: (0.1054) |  Loss2: (0.0000) | Acc: (96.00%) (45762/47488)
Epoch: 177 | Batch_idx: 380 |  Loss: (0.1048) |  Loss2: (0.0000) | Acc: (96.00%) (47012/48768)
Epoch: 177 | Batch_idx: 390 |  Loss: (0.1042) |  Loss2: (0.0000) | Acc: (96.00%) (48204/50000)
# TEST : Loss: (0.3977) | Acc: (88.00%) (8874/10000)
percent tensor([0.5723, 0.5811, 0.5741, 0.5730, 0.5806, 0.5885, 0.5833, 0.5691, 0.5708,
        0.5754, 0.5776, 0.5800, 0.5742, 0.5677, 0.5878, 0.5765],
       device='cuda:0') torch.Size([16])
percent tensor([0.5296, 0.5324, 0.5199, 0.5265, 0.5195, 0.5392, 0.5251, 0.5185, 0.5221,
        0.5290, 0.5328, 0.5233, 0.5278, 0.5296, 0.5335, 0.5327],
       device='cuda:0') torch.Size([16])
percent tensor([0.5795, 0.4558, 0.7039, 0.7039, 0.7140, 0.6636, 0.5585, 0.6770, 0.6161,
        0.5339, 0.4771, 0.6365, 0.4803, 0.5417, 0.5296, 0.6196],
       device='cuda:0') torch.Size([16])
percent tensor([0.6809, 0.7212, 0.6026, 0.6229, 0.6033, 0.5321, 0.6827, 0.6265, 0.6912,
        0.7212, 0.7287, 0.6712, 0.7004, 0.7316, 0.6505, 0.6508],
       device='cuda:0') torch.Size([16])
percent tensor([0.7529, 0.6364, 0.7796, 0.7730, 0.7963, 0.8490, 0.7384, 0.7634, 0.7175,
        0.6245, 0.6148, 0.6468, 0.6015, 0.6840, 0.7396, 0.7992],
       device='cuda:0') torch.Size([16])
percent tensor([0.6084, 0.7543, 0.7759, 0.8055, 0.7889, 0.8194, 0.7411, 0.6187, 0.7461,
        0.7306, 0.7732, 0.7864, 0.7626, 0.7683, 0.5965, 0.5843],
       device='cuda:0') torch.Size([16])
percent tensor([0.4018, 0.6663, 0.6338, 0.6175, 0.6060, 0.6153, 0.5840, 0.5619, 0.5907,
        0.5924, 0.6833, 0.5977, 0.6082, 0.6167, 0.4816, 0.3765],
       device='cuda:0') torch.Size([16])
percent tensor([0.9998, 0.9998, 0.9997, 0.9999, 0.9999, 0.9995, 0.9998, 0.9996, 0.9997,
        0.9999, 0.9996, 0.9999, 0.9996, 0.9996, 0.9998, 0.9996],
       device='cuda:0') torch.Size([16])
Epoch: 178 | Batch_idx: 0 |  Loss: (0.0511) |  Loss2: (0.0000) | Acc: (99.00%) (127/128)
Epoch: 178 | Batch_idx: 10 |  Loss: (0.0975) |  Loss2: (0.0000) | Acc: (96.00%) (1364/1408)
Epoch: 178 | Batch_idx: 20 |  Loss: (0.0917) |  Loss2: (0.0000) | Acc: (96.00%) (2602/2688)
Epoch: 178 | Batch_idx: 30 |  Loss: (0.0917) |  Loss2: (0.0000) | Acc: (96.00%) (3844/3968)
Epoch: 178 | Batch_idx: 40 |  Loss: (0.0937) |  Loss2: (0.0000) | Acc: (96.00%) (5078/5248)
Epoch: 178 | Batch_idx: 50 |  Loss: (0.0953) |  Loss2: (0.0000) | Acc: (96.00%) (6310/6528)
Epoch: 178 | Batch_idx: 60 |  Loss: (0.0942) |  Loss2: (0.0000) | Acc: (96.00%) (7551/7808)
Epoch: 178 | Batch_idx: 70 |  Loss: (0.0909) |  Loss2: (0.0000) | Acc: (96.00%) (8799/9088)
Epoch: 178 | Batch_idx: 80 |  Loss: (0.0888) |  Loss2: (0.0000) | Acc: (96.00%) (10049/10368)
Epoch: 178 | Batch_idx: 90 |  Loss: (0.0912) |  Loss2: (0.0000) | Acc: (96.00%) (11286/11648)
Epoch: 178 | Batch_idx: 100 |  Loss: (0.0907) |  Loss2: (0.0000) | Acc: (96.00%) (12525/12928)
Epoch: 178 | Batch_idx: 110 |  Loss: (0.0905) |  Loss2: (0.0000) | Acc: (96.00%) (13769/14208)
Epoch: 178 | Batch_idx: 120 |  Loss: (0.0917) |  Loss2: (0.0000) | Acc: (96.00%) (15004/15488)
Epoch: 178 | Batch_idx: 130 |  Loss: (0.0911) |  Loss2: (0.0000) | Acc: (96.00%) (16253/16768)
Epoch: 178 | Batch_idx: 140 |  Loss: (0.0926) |  Loss2: (0.0000) | Acc: (96.00%) (17479/18048)
Epoch: 178 | Batch_idx: 150 |  Loss: (0.0937) |  Loss2: (0.0000) | Acc: (96.00%) (18717/19328)
Epoch: 178 | Batch_idx: 160 |  Loss: (0.0942) |  Loss2: (0.0000) | Acc: (96.00%) (19946/20608)
Epoch: 178 | Batch_idx: 170 |  Loss: (0.0932) |  Loss2: (0.0000) | Acc: (96.00%) (21193/21888)
Epoch: 178 | Batch_idx: 180 |  Loss: (0.0930) |  Loss2: (0.0000) | Acc: (96.00%) (22443/23168)
Epoch: 178 | Batch_idx: 190 |  Loss: (0.0934) |  Loss2: (0.0000) | Acc: (96.00%) (23676/24448)
Epoch: 178 | Batch_idx: 200 |  Loss: (0.0941) |  Loss2: (0.0000) | Acc: (96.00%) (24903/25728)
Epoch: 178 | Batch_idx: 210 |  Loss: (0.0937) |  Loss2: (0.0000) | Acc: (96.00%) (26146/27008)
Epoch: 178 | Batch_idx: 220 |  Loss: (0.0941) |  Loss2: (0.0000) | Acc: (96.00%) (27385/28288)
Epoch: 178 | Batch_idx: 230 |  Loss: (0.0941) |  Loss2: (0.0000) | Acc: (96.00%) (28618/29568)
Epoch: 178 | Batch_idx: 240 |  Loss: (0.0935) |  Loss2: (0.0000) | Acc: (96.00%) (29859/30848)
Epoch: 178 | Batch_idx: 250 |  Loss: (0.0934) |  Loss2: (0.0000) | Acc: (96.00%) (31102/32128)
Epoch: 178 | Batch_idx: 260 |  Loss: (0.0926) |  Loss2: (0.0000) | Acc: (96.00%) (32355/33408)
Epoch: 178 | Batch_idx: 270 |  Loss: (0.0926) |  Loss2: (0.0000) | Acc: (96.00%) (33598/34688)
Epoch: 178 | Batch_idx: 280 |  Loss: (0.0928) |  Loss2: (0.0000) | Acc: (96.00%) (34841/35968)
Epoch: 178 | Batch_idx: 290 |  Loss: (0.0932) |  Loss2: (0.0000) | Acc: (96.00%) (36075/37248)
Epoch: 178 | Batch_idx: 300 |  Loss: (0.0931) |  Loss2: (0.0000) | Acc: (96.00%) (37314/38528)
Epoch: 178 | Batch_idx: 310 |  Loss: (0.0933) |  Loss2: (0.0000) | Acc: (96.00%) (38548/39808)
Epoch: 178 | Batch_idx: 320 |  Loss: (0.0934) |  Loss2: (0.0000) | Acc: (96.00%) (39786/41088)
Epoch: 178 | Batch_idx: 330 |  Loss: (0.0931) |  Loss2: (0.0000) | Acc: (96.00%) (41033/42368)
Epoch: 178 | Batch_idx: 340 |  Loss: (0.0927) |  Loss2: (0.0000) | Acc: (96.00%) (42283/43648)
Epoch: 178 | Batch_idx: 350 |  Loss: (0.0927) |  Loss2: (0.0000) | Acc: (96.00%) (43521/44928)
Epoch: 178 | Batch_idx: 360 |  Loss: (0.0932) |  Loss2: (0.0000) | Acc: (96.00%) (44750/46208)
Epoch: 178 | Batch_idx: 370 |  Loss: (0.0932) |  Loss2: (0.0000) | Acc: (96.00%) (45988/47488)
Epoch: 178 | Batch_idx: 380 |  Loss: (0.0934) |  Loss2: (0.0000) | Acc: (96.00%) (47227/48768)
Epoch: 178 | Batch_idx: 390 |  Loss: (0.0931) |  Loss2: (0.0000) | Acc: (96.00%) (48425/50000)
# TEST : Loss: (0.3915) | Acc: (88.00%) (8891/10000)
percent tensor([0.5686, 0.5767, 0.5701, 0.5693, 0.5761, 0.5841, 0.5787, 0.5653, 0.5671,
        0.5714, 0.5736, 0.5757, 0.5703, 0.5647, 0.5832, 0.5726],
       device='cuda:0') torch.Size([16])
percent tensor([0.5323, 0.5355, 0.5232, 0.5291, 0.5234, 0.5418, 0.5287, 0.5220, 0.5247,
        0.5318, 0.5356, 0.5260, 0.5310, 0.5324, 0.5364, 0.5355],
       device='cuda:0') torch.Size([16])
percent tensor([0.5743, 0.4563, 0.6987, 0.6970, 0.7125, 0.6565, 0.5604, 0.6771, 0.6144,
        0.5321, 0.4723, 0.6310, 0.4770, 0.5434, 0.5234, 0.6129],
       device='cuda:0') torch.Size([16])
percent tensor([0.6800, 0.7203, 0.6032, 0.6260, 0.6055, 0.5331, 0.6826, 0.6289, 0.6910,
        0.7196, 0.7279, 0.6697, 0.6991, 0.7306, 0.6506, 0.6500],
       device='cuda:0') torch.Size([16])
percent tensor([0.7594, 0.6426, 0.7823, 0.7782, 0.7957, 0.8538, 0.7423, 0.7631, 0.7234,
        0.6315, 0.6223, 0.6567, 0.6094, 0.6932, 0.7446, 0.8036],
       device='cuda:0') torch.Size([16])
percent tensor([0.6144, 0.7564, 0.7749, 0.8042, 0.7848, 0.8221, 0.7407, 0.6125, 0.7482,
        0.7346, 0.7785, 0.7866, 0.7662, 0.7709, 0.5990, 0.5884],
       device='cuda:0') torch.Size([16])
percent tensor([0.4032, 0.6892, 0.6531, 0.6272, 0.6186, 0.6405, 0.5989, 0.5775, 0.6103,
        0.6112, 0.7009, 0.6108, 0.6272, 0.6358, 0.5024, 0.3794],
       device='cuda:0') torch.Size([16])
percent tensor([0.9998, 0.9998, 0.9997, 0.9999, 0.9999, 0.9996, 0.9998, 0.9996, 0.9998,
        0.9999, 0.9997, 0.9999, 0.9997, 0.9996, 0.9998, 0.9996],
       device='cuda:0') torch.Size([16])
Epoch: 179 | Batch_idx: 0 |  Loss: (0.0875) |  Loss2: (0.0000) | Acc: (95.00%) (122/128)
Epoch: 179 | Batch_idx: 10 |  Loss: (0.0875) |  Loss2: (0.0000) | Acc: (97.00%) (1368/1408)
Epoch: 179 | Batch_idx: 20 |  Loss: (0.0904) |  Loss2: (0.0000) | Acc: (96.00%) (2604/2688)
Epoch: 179 | Batch_idx: 30 |  Loss: (0.0897) |  Loss2: (0.0000) | Acc: (96.00%) (3842/3968)
Epoch: 179 | Batch_idx: 40 |  Loss: (0.0912) |  Loss2: (0.0000) | Acc: (96.00%) (5073/5248)
Epoch: 179 | Batch_idx: 50 |  Loss: (0.0909) |  Loss2: (0.0000) | Acc: (96.00%) (6314/6528)
Epoch: 179 | Batch_idx: 60 |  Loss: (0.0928) |  Loss2: (0.0000) | Acc: (96.00%) (7551/7808)
Epoch: 179 | Batch_idx: 70 |  Loss: (0.0939) |  Loss2: (0.0000) | Acc: (96.00%) (8786/9088)
Epoch: 179 | Batch_idx: 80 |  Loss: (0.0927) |  Loss2: (0.0000) | Acc: (96.00%) (10026/10368)
Epoch: 179 | Batch_idx: 90 |  Loss: (0.0918) |  Loss2: (0.0000) | Acc: (96.00%) (11271/11648)
Epoch: 179 | Batch_idx: 100 |  Loss: (0.0920) |  Loss2: (0.0000) | Acc: (96.00%) (12516/12928)
Epoch: 179 | Batch_idx: 110 |  Loss: (0.0904) |  Loss2: (0.0000) | Acc: (96.00%) (13769/14208)
Epoch: 179 | Batch_idx: 120 |  Loss: (0.0906) |  Loss2: (0.0000) | Acc: (96.00%) (15006/15488)
Epoch: 179 | Batch_idx: 130 |  Loss: (0.0900) |  Loss2: (0.0000) | Acc: (96.00%) (16250/16768)
Epoch: 179 | Batch_idx: 140 |  Loss: (0.0887) |  Loss2: (0.0000) | Acc: (96.00%) (17503/18048)
Epoch: 179 | Batch_idx: 150 |  Loss: (0.0880) |  Loss2: (0.0000) | Acc: (96.00%) (18748/19328)
Epoch: 179 | Batch_idx: 160 |  Loss: (0.0874) |  Loss2: (0.0000) | Acc: (97.00%) (19999/20608)
Epoch: 179 | Batch_idx: 170 |  Loss: (0.0872) |  Loss2: (0.0000) | Acc: (97.00%) (21246/21888)
Epoch: 179 | Batch_idx: 180 |  Loss: (0.0870) |  Loss2: (0.0000) | Acc: (97.00%) (22490/23168)
Epoch: 179 | Batch_idx: 190 |  Loss: (0.0867) |  Loss2: (0.0000) | Acc: (97.00%) (23739/24448)
Epoch: 179 | Batch_idx: 200 |  Loss: (0.0868) |  Loss2: (0.0000) | Acc: (97.00%) (24983/25728)
Epoch: 179 | Batch_idx: 210 |  Loss: (0.0864) |  Loss2: (0.0000) | Acc: (97.00%) (26229/27008)
Epoch: 179 | Batch_idx: 220 |  Loss: (0.0866) |  Loss2: (0.0000) | Acc: (97.00%) (27466/28288)
Epoch: 179 | Batch_idx: 230 |  Loss: (0.0868) |  Loss2: (0.0000) | Acc: (97.00%) (28707/29568)
Epoch: 179 | Batch_idx: 240 |  Loss: (0.0863) |  Loss2: (0.0000) | Acc: (97.00%) (29957/30848)
Epoch: 179 | Batch_idx: 250 |  Loss: (0.0864) |  Loss2: (0.0000) | Acc: (97.00%) (31209/32128)
Epoch: 179 | Batch_idx: 260 |  Loss: (0.0861) |  Loss2: (0.0000) | Acc: (97.00%) (32457/33408)
Epoch: 179 | Batch_idx: 270 |  Loss: (0.0866) |  Loss2: (0.0000) | Acc: (97.00%) (33701/34688)
Epoch: 179 | Batch_idx: 280 |  Loss: (0.0873) |  Loss2: (0.0000) | Acc: (97.00%) (34932/35968)
Epoch: 179 | Batch_idx: 290 |  Loss: (0.0873) |  Loss2: (0.0000) | Acc: (97.00%) (36169/37248)
Epoch: 179 | Batch_idx: 300 |  Loss: (0.0870) |  Loss2: (0.0000) | Acc: (97.00%) (37419/38528)
Epoch: 179 | Batch_idx: 310 |  Loss: (0.0878) |  Loss2: (0.0000) | Acc: (97.00%) (38650/39808)
Epoch: 179 | Batch_idx: 320 |  Loss: (0.0875) |  Loss2: (0.0000) | Acc: (97.00%) (39892/41088)
Epoch: 179 | Batch_idx: 330 |  Loss: (0.0874) |  Loss2: (0.0000) | Acc: (97.00%) (41136/42368)
Epoch: 179 | Batch_idx: 340 |  Loss: (0.0875) |  Loss2: (0.0000) | Acc: (97.00%) (42373/43648)
Epoch: 179 | Batch_idx: 350 |  Loss: (0.0874) |  Loss2: (0.0000) | Acc: (97.00%) (43610/44928)
Epoch: 179 | Batch_idx: 360 |  Loss: (0.0878) |  Loss2: (0.0000) | Acc: (97.00%) (44851/46208)
Epoch: 179 | Batch_idx: 370 |  Loss: (0.0876) |  Loss2: (0.0000) | Acc: (97.00%) (46097/47488)
Epoch: 179 | Batch_idx: 380 |  Loss: (0.0871) |  Loss2: (0.0000) | Acc: (97.00%) (47351/48768)
Epoch: 179 | Batch_idx: 390 |  Loss: (0.0868) |  Loss2: (0.0000) | Acc: (97.00%) (48559/50000)
# TEST : Loss: (0.3838) | Acc: (89.00%) (8914/10000)
percent tensor([0.5701, 0.5786, 0.5715, 0.5708, 0.5774, 0.5857, 0.5804, 0.5670, 0.5686,
        0.5732, 0.5752, 0.5774, 0.5719, 0.5665, 0.5849, 0.5742],
       device='cuda:0') torch.Size([16])
percent tensor([0.5305, 0.5339, 0.5222, 0.5277, 0.5224, 0.5404, 0.5271, 0.5205, 0.5231,
        0.5306, 0.5338, 0.5251, 0.5292, 0.5308, 0.5348, 0.5341],
       device='cuda:0') torch.Size([16])
percent tensor([0.5685, 0.4507, 0.6933, 0.6909, 0.7065, 0.6506, 0.5537, 0.6717, 0.6094,
        0.5261, 0.4680, 0.6229, 0.4729, 0.5416, 0.5130, 0.6073],
       device='cuda:0') torch.Size([16])
percent tensor([0.6778, 0.7182, 0.6034, 0.6263, 0.6055, 0.5322, 0.6810, 0.6294, 0.6905,
        0.7183, 0.7259, 0.6702, 0.6963, 0.7287, 0.6484, 0.6483],
       device='cuda:0') torch.Size([16])
percent tensor([0.7519, 0.6343, 0.7765, 0.7780, 0.7928, 0.8504, 0.7356, 0.7579, 0.7158,
        0.6230, 0.6146, 0.6494, 0.6035, 0.6870, 0.7377, 0.7990],
       device='cuda:0') torch.Size([16])
percent tensor([0.6071, 0.7527, 0.7733, 0.8021, 0.7805, 0.8188, 0.7343, 0.6040, 0.7414,
        0.7300, 0.7768, 0.7836, 0.7632, 0.7633, 0.5964, 0.5748],
       device='cuda:0') torch.Size([16])
percent tensor([0.4054, 0.6939, 0.6559, 0.6288, 0.6190, 0.6354, 0.6014, 0.5819, 0.6130,
        0.6160, 0.7052, 0.6152, 0.6236, 0.6358, 0.5180, 0.3798],
       device='cuda:0') torch.Size([16])
percent tensor([0.9998, 0.9998, 0.9997, 0.9999, 0.9999, 0.9996, 0.9998, 0.9996, 0.9998,
        0.9999, 0.9996, 0.9999, 0.9996, 0.9996, 0.9998, 0.9996],
       device='cuda:0') torch.Size([16])
True Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=128, out_features=16, bias=False)
False Linear(in_features=16, out_features=2, bias=False)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=128, out_features=16, bias=False)
False Linear(in_features=16, out_features=2, bias=False)
True Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=256, out_features=32, bias=False)
False Linear(in_features=32, out_features=2, bias=False)
True Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=256, out_features=32, bias=False)
False Linear(in_features=32, out_features=2, bias=False)
True Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=512, out_features=64, bias=False)
False Linear(in_features=64, out_features=2, bias=False)
True Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=512, out_features=64, bias=False)
False Linear(in_features=64, out_features=2, bias=False)
True Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1024, out_features=128, bias=False)
False Linear(in_features=128, out_features=2, bias=False)
True Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1024, out_features=128, bias=False)
False Linear(in_features=128, out_features=2, bias=False)
True Linear(in_features=512, out_features=10, bias=True)
Epoch: 180 | Batch_idx: 0 |  Loss: (0.0517) |  Loss2: (0.0000) | Acc: (98.00%) (126/128)
Epoch: 180 | Batch_idx: 10 |  Loss: (0.0703) |  Loss2: (0.0000) | Acc: (97.00%) (1379/1408)
Epoch: 180 | Batch_idx: 20 |  Loss: (0.0669) |  Loss2: (0.0000) | Acc: (97.00%) (2634/2688)
Epoch: 180 | Batch_idx: 30 |  Loss: (0.0723) |  Loss2: (0.0000) | Acc: (97.00%) (3879/3968)
Epoch: 180 | Batch_idx: 40 |  Loss: (0.0749) |  Loss2: (0.0000) | Acc: (97.00%) (5118/5248)
Epoch: 180 | Batch_idx: 50 |  Loss: (0.0828) |  Loss2: (0.0000) | Acc: (97.00%) (6342/6528)
Epoch: 180 | Batch_idx: 60 |  Loss: (0.0826) |  Loss2: (0.0000) | Acc: (97.00%) (7589/7808)
Epoch: 180 | Batch_idx: 70 |  Loss: (0.0853) |  Loss2: (0.0000) | Acc: (97.00%) (8824/9088)
Epoch: 180 | Batch_idx: 80 |  Loss: (0.0863) |  Loss2: (0.0000) | Acc: (97.00%) (10064/10368)
Epoch: 180 | Batch_idx: 90 |  Loss: (0.0863) |  Loss2: (0.0000) | Acc: (97.00%) (11306/11648)
Epoch: 180 | Batch_idx: 100 |  Loss: (0.0871) |  Loss2: (0.0000) | Acc: (97.00%) (12548/12928)
Epoch: 180 | Batch_idx: 110 |  Loss: (0.0869) |  Loss2: (0.0000) | Acc: (97.00%) (13782/14208)
Epoch: 180 | Batch_idx: 120 |  Loss: (0.0876) |  Loss2: (0.0000) | Acc: (97.00%) (15027/15488)
Epoch: 180 | Batch_idx: 130 |  Loss: (0.0876) |  Loss2: (0.0000) | Acc: (97.00%) (16267/16768)
Epoch: 180 | Batch_idx: 140 |  Loss: (0.0884) |  Loss2: (0.0000) | Acc: (96.00%) (17497/18048)
Epoch: 180 | Batch_idx: 150 |  Loss: (0.0885) |  Loss2: (0.0000) | Acc: (96.00%) (18732/19328)
Epoch: 180 | Batch_idx: 160 |  Loss: (0.0874) |  Loss2: (0.0000) | Acc: (96.00%) (19987/20608)
Epoch: 180 | Batch_idx: 170 |  Loss: (0.0872) |  Loss2: (0.0000) | Acc: (96.00%) (21229/21888)
Epoch: 180 | Batch_idx: 180 |  Loss: (0.0873) |  Loss2: (0.0000) | Acc: (96.00%) (22469/23168)
Epoch: 180 | Batch_idx: 190 |  Loss: (0.0871) |  Loss2: (0.0000) | Acc: (96.00%) (23712/24448)
Epoch: 180 | Batch_idx: 200 |  Loss: (0.0873) |  Loss2: (0.0000) | Acc: (96.00%) (24956/25728)
Epoch: 180 | Batch_idx: 210 |  Loss: (0.0875) |  Loss2: (0.0000) | Acc: (96.00%) (26195/27008)
Epoch: 180 | Batch_idx: 220 |  Loss: (0.0871) |  Loss2: (0.0000) | Acc: (97.00%) (27445/28288)
Epoch: 180 | Batch_idx: 230 |  Loss: (0.0874) |  Loss2: (0.0000) | Acc: (97.00%) (28689/29568)
Epoch: 180 | Batch_idx: 240 |  Loss: (0.0882) |  Loss2: (0.0000) | Acc: (96.00%) (29920/30848)
Epoch: 180 | Batch_idx: 250 |  Loss: (0.0880) |  Loss2: (0.0000) | Acc: (97.00%) (31165/32128)
Epoch: 180 | Batch_idx: 260 |  Loss: (0.0883) |  Loss2: (0.0000) | Acc: (96.00%) (32405/33408)
Epoch: 180 | Batch_idx: 270 |  Loss: (0.0892) |  Loss2: (0.0000) | Acc: (96.00%) (33629/34688)
Epoch: 180 | Batch_idx: 280 |  Loss: (0.0896) |  Loss2: (0.0000) | Acc: (96.00%) (34853/35968)
Epoch: 180 | Batch_idx: 290 |  Loss: (0.0895) |  Loss2: (0.0000) | Acc: (96.00%) (36091/37248)
Epoch: 180 | Batch_idx: 300 |  Loss: (0.0898) |  Loss2: (0.0000) | Acc: (96.00%) (37337/38528)
Epoch: 180 | Batch_idx: 310 |  Loss: (0.0896) |  Loss2: (0.0000) | Acc: (96.00%) (38580/39808)
Epoch: 180 | Batch_idx: 320 |  Loss: (0.0894) |  Loss2: (0.0000) | Acc: (96.00%) (39826/41088)
Epoch: 180 | Batch_idx: 330 |  Loss: (0.0895) |  Loss2: (0.0000) | Acc: (96.00%) (41057/42368)
Epoch: 180 | Batch_idx: 340 |  Loss: (0.0895) |  Loss2: (0.0000) | Acc: (96.00%) (42298/43648)
Epoch: 180 | Batch_idx: 350 |  Loss: (0.0900) |  Loss2: (0.0000) | Acc: (96.00%) (43528/44928)
Epoch: 180 | Batch_idx: 360 |  Loss: (0.0899) |  Loss2: (0.0000) | Acc: (96.00%) (44770/46208)
Epoch: 180 | Batch_idx: 370 |  Loss: (0.0902) |  Loss2: (0.0000) | Acc: (96.00%) (45998/47488)
Epoch: 180 | Batch_idx: 380 |  Loss: (0.0904) |  Loss2: (0.0000) | Acc: (96.00%) (47237/48768)
Epoch: 180 | Batch_idx: 390 |  Loss: (0.0905) |  Loss2: (0.0000) | Acc: (96.00%) (48429/50000)
=> saving checkpoint 'drive/app/torch/save_Schedule/checkpoint_180.pth.tar'
# TEST : Loss: (0.4026) | Acc: (88.00%) (8871/10000)
percent tensor([0.5707, 0.5794, 0.5722, 0.5728, 0.5772, 0.5867, 0.5806, 0.5678, 0.5684,
        0.5741, 0.5761, 0.5783, 0.5725, 0.5672, 0.5858, 0.5753],
       device='cuda:0') torch.Size([16])
percent tensor([0.5308, 0.5347, 0.5202, 0.5263, 0.5201, 0.5393, 0.5269, 0.5196, 0.5231,
        0.5301, 0.5342, 0.5234, 0.5291, 0.5318, 0.5342, 0.5341],
       device='cuda:0') torch.Size([16])
percent tensor([0.5827, 0.4515, 0.7034, 0.6982, 0.7168, 0.6652, 0.5629, 0.6763, 0.6237,
        0.5331, 0.4762, 0.6402, 0.4807, 0.5573, 0.5187, 0.6207],
       device='cuda:0') torch.Size([16])
percent tensor([0.6704, 0.7078, 0.5966, 0.6259, 0.6001, 0.5233, 0.6724, 0.6234, 0.6805,
        0.7116, 0.7201, 0.6615, 0.6871, 0.7154, 0.6436, 0.6432],
       device='cuda:0') torch.Size([16])
percent tensor([0.7567, 0.6497, 0.7930, 0.7903, 0.8035, 0.8569, 0.7347, 0.7684, 0.7208,
        0.6397, 0.6256, 0.6745, 0.6273, 0.6764, 0.7442, 0.8071],
       device='cuda:0') torch.Size([16])
percent tensor([0.6342, 0.7621, 0.7553, 0.7891, 0.7570, 0.8144, 0.7363, 0.5548, 0.7515,
        0.7385, 0.7893, 0.7710, 0.7637, 0.7775, 0.6126, 0.5982],
       device='cuda:0') torch.Size([16])
percent tensor([0.4045, 0.7183, 0.6404, 0.5956, 0.6082, 0.6190, 0.6107, 0.5620, 0.6517,
        0.6389, 0.7026, 0.6089, 0.6453, 0.6533, 0.5185, 0.3822],
       device='cuda:0') torch.Size([16])
percent tensor([0.9998, 0.9998, 0.9997, 0.9999, 0.9999, 0.9996, 0.9998, 0.9996, 0.9998,
        0.9998, 0.9997, 0.9999, 0.9997, 0.9997, 0.9998, 0.9996],
       device='cuda:0') torch.Size([16])
Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 3, 3, 3]) tensor(185.2933, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(821.3358, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(831.4697, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([128, 64, 3, 3]) tensor(1510.3876, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([128, 64, 1, 1]) tensor(485.7281, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([128, 128, 3, 3]) tensor(2278.3250, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([256, 128, 3, 3]) tensor(4271.1660, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([256, 128, 1, 1]) tensor(1362.1395, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([256, 256, 3, 3]) tensor(6248.3735, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([512, 256, 3, 3]) tensor(11604.5029, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([512, 256, 1, 1]) tensor(3822.8284, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([512, 512, 3, 3]) tensor(16104.9893, device='cuda:0', grad_fn=<NormBackward0>)
Epoch: 181 | Batch_idx: 0 |  Loss: (0.0276) |  Loss2: (0.0000) | Acc: (100.00%) (128/128)
Epoch: 181 | Batch_idx: 10 |  Loss: (0.0727) |  Loss2: (0.0000) | Acc: (97.00%) (1376/1408)
Epoch: 181 | Batch_idx: 20 |  Loss: (0.0842) |  Loss2: (0.0000) | Acc: (97.00%) (2612/2688)
Epoch: 181 | Batch_idx: 30 |  Loss: (0.0821) |  Loss2: (0.0000) | Acc: (97.00%) (3857/3968)
Epoch: 181 | Batch_idx: 40 |  Loss: (0.0834) |  Loss2: (0.0000) | Acc: (97.00%) (5095/5248)
Epoch: 181 | Batch_idx: 50 |  Loss: (0.0834) |  Loss2: (0.0000) | Acc: (97.00%) (6335/6528)
Epoch: 181 | Batch_idx: 60 |  Loss: (0.0864) |  Loss2: (0.0000) | Acc: (96.00%) (7573/7808)
Epoch: 181 | Batch_idx: 70 |  Loss: (0.0838) |  Loss2: (0.0000) | Acc: (97.00%) (8827/9088)
Epoch: 181 | Batch_idx: 80 |  Loss: (0.0839) |  Loss2: (0.0000) | Acc: (97.00%) (10069/10368)
Epoch: 181 | Batch_idx: 90 |  Loss: (0.0845) |  Loss2: (0.0000) | Acc: (97.00%) (11305/11648)
Epoch: 181 | Batch_idx: 100 |  Loss: (0.0846) |  Loss2: (0.0000) | Acc: (97.00%) (12552/12928)
Epoch: 181 | Batch_idx: 110 |  Loss: (0.0847) |  Loss2: (0.0000) | Acc: (97.00%) (13791/14208)
Epoch: 181 | Batch_idx: 120 |  Loss: (0.0856) |  Loss2: (0.0000) | Acc: (97.00%) (15029/15488)
Epoch: 181 | Batch_idx: 130 |  Loss: (0.0849) |  Loss2: (0.0000) | Acc: (97.00%) (16276/16768)
Epoch: 181 | Batch_idx: 140 |  Loss: (0.0858) |  Loss2: (0.0000) | Acc: (97.00%) (17509/18048)
Epoch: 181 | Batch_idx: 150 |  Loss: (0.0856) |  Loss2: (0.0000) | Acc: (97.00%) (18757/19328)
Epoch: 181 | Batch_idx: 160 |  Loss: (0.0854) |  Loss2: (0.0000) | Acc: (97.00%) (20001/20608)
Epoch: 181 | Batch_idx: 170 |  Loss: (0.0864) |  Loss2: (0.0000) | Acc: (97.00%) (21235/21888)
Epoch: 181 | Batch_idx: 180 |  Loss: (0.0859) |  Loss2: (0.0000) | Acc: (97.00%) (22481/23168)
Epoch: 181 | Batch_idx: 190 |  Loss: (0.0850) |  Loss2: (0.0000) | Acc: (97.00%) (23735/24448)
Epoch: 181 | Batch_idx: 200 |  Loss: (0.0848) |  Loss2: (0.0000) | Acc: (97.00%) (24978/25728)
Epoch: 181 | Batch_idx: 210 |  Loss: (0.0855) |  Loss2: (0.0000) | Acc: (97.00%) (26214/27008)
Epoch: 181 | Batch_idx: 220 |  Loss: (0.0848) |  Loss2: (0.0000) | Acc: (97.00%) (27471/28288)
Epoch: 181 | Batch_idx: 230 |  Loss: (0.0847) |  Loss2: (0.0000) | Acc: (97.00%) (28716/29568)
Epoch: 181 | Batch_idx: 240 |  Loss: (0.0845) |  Loss2: (0.0000) | Acc: (97.00%) (29963/30848)
Epoch: 181 | Batch_idx: 250 |  Loss: (0.0846) |  Loss2: (0.0000) | Acc: (97.00%) (31205/32128)
Epoch: 181 | Batch_idx: 260 |  Loss: (0.0846) |  Loss2: (0.0000) | Acc: (97.00%) (32445/33408)
Epoch: 181 | Batch_idx: 270 |  Loss: (0.0844) |  Loss2: (0.0000) | Acc: (97.00%) (33693/34688)
Epoch: 181 | Batch_idx: 280 |  Loss: (0.0850) |  Loss2: (0.0000) | Acc: (97.00%) (34933/35968)
Epoch: 181 | Batch_idx: 290 |  Loss: (0.0849) |  Loss2: (0.0000) | Acc: (97.00%) (36174/37248)
Epoch: 181 | Batch_idx: 300 |  Loss: (0.0851) |  Loss2: (0.0000) | Acc: (97.00%) (37414/38528)
Epoch: 181 | Batch_idx: 310 |  Loss: (0.0855) |  Loss2: (0.0000) | Acc: (97.00%) (38650/39808)
Epoch: 181 | Batch_idx: 320 |  Loss: (0.0857) |  Loss2: (0.0000) | Acc: (97.00%) (39886/41088)
Epoch: 181 | Batch_idx: 330 |  Loss: (0.0862) |  Loss2: (0.0000) | Acc: (97.00%) (41123/42368)
Epoch: 181 | Batch_idx: 340 |  Loss: (0.0868) |  Loss2: (0.0000) | Acc: (97.00%) (42358/43648)
Epoch: 181 | Batch_idx: 350 |  Loss: (0.0868) |  Loss2: (0.0000) | Acc: (97.00%) (43602/44928)
Epoch: 181 | Batch_idx: 360 |  Loss: (0.0871) |  Loss2: (0.0000) | Acc: (97.00%) (44836/46208)
Epoch: 181 | Batch_idx: 370 |  Loss: (0.0866) |  Loss2: (0.0000) | Acc: (97.00%) (46096/47488)
Epoch: 181 | Batch_idx: 380 |  Loss: (0.0870) |  Loss2: (0.0000) | Acc: (97.00%) (47325/48768)
Epoch: 181 | Batch_idx: 390 |  Loss: (0.0870) |  Loss2: (0.0000) | Acc: (97.00%) (48528/50000)
# TEST : Loss: (0.4627) | Acc: (87.00%) (8712/10000)
percent tensor([0.5687, 0.5792, 0.5700, 0.5714, 0.5751, 0.5844, 0.5794, 0.5665, 0.5669,
        0.5729, 0.5743, 0.5762, 0.5707, 0.5676, 0.5846, 0.5738],
       device='cuda:0') torch.Size([16])
percent tensor([0.5314, 0.5344, 0.5216, 0.5275, 0.5214, 0.5398, 0.5272, 0.5205, 0.5230,
        0.5302, 0.5337, 0.5241, 0.5295, 0.5316, 0.5341, 0.5344],
       device='cuda:0') torch.Size([16])
percent tensor([0.5723, 0.4548, 0.6904, 0.6947, 0.7070, 0.6586, 0.5558, 0.6692, 0.6227,
        0.5267, 0.4777, 0.6165, 0.4689, 0.5595, 0.5108, 0.6207],
       device='cuda:0') torch.Size([16])
percent tensor([0.6847, 0.7227, 0.5972, 0.6325, 0.6011, 0.5390, 0.6833, 0.6331, 0.6871,
        0.7222, 0.7327, 0.6702, 0.7036, 0.7304, 0.6574, 0.6549],
       device='cuda:0') torch.Size([16])
percent tensor([0.7471, 0.6275, 0.7828, 0.7856, 0.8023, 0.8529, 0.7335, 0.7651, 0.7086,
        0.6292, 0.5982, 0.6540, 0.6033, 0.6488, 0.7328, 0.7987],
       device='cuda:0') torch.Size([16])
percent tensor([0.6190, 0.7368, 0.7831, 0.8051, 0.7802, 0.8189, 0.7324, 0.5574, 0.7499,
        0.7193, 0.7793, 0.7728, 0.7350, 0.7577, 0.5948, 0.5648],
       device='cuda:0') torch.Size([16])
percent tensor([0.4042, 0.6947, 0.6649, 0.6258, 0.6194, 0.6396, 0.6058, 0.5526, 0.6583,
        0.5948, 0.7216, 0.6447, 0.5956, 0.6460, 0.5307, 0.3772],
       device='cuda:0') torch.Size([16])
percent tensor([0.9998, 0.9998, 0.9998, 0.9998, 1.0000, 0.9992, 0.9999, 0.9996, 0.9998,
        0.9999, 0.9997, 1.0000, 0.9994, 0.9999, 0.9998, 0.9995],
       device='cuda:0') torch.Size([16])
Epoch: 182 | Batch_idx: 0 |  Loss: (0.0457) |  Loss2: (0.0000) | Acc: (98.00%) (126/128)
Epoch: 182 | Batch_idx: 10 |  Loss: (0.0760) |  Loss2: (0.0000) | Acc: (97.00%) (1375/1408)
Epoch: 182 | Batch_idx: 20 |  Loss: (0.0699) |  Loss2: (0.0000) | Acc: (97.00%) (2632/2688)
Epoch: 182 | Batch_idx: 30 |  Loss: (0.0705) |  Loss2: (0.0000) | Acc: (97.00%) (3882/3968)
Epoch: 182 | Batch_idx: 40 |  Loss: (0.0703) |  Loss2: (0.0000) | Acc: (97.00%) (5130/5248)
Epoch: 182 | Batch_idx: 50 |  Loss: (0.0714) |  Loss2: (0.0000) | Acc: (97.00%) (6375/6528)
Epoch: 182 | Batch_idx: 60 |  Loss: (0.0723) |  Loss2: (0.0000) | Acc: (97.00%) (7627/7808)
Epoch: 182 | Batch_idx: 70 |  Loss: (0.0721) |  Loss2: (0.0000) | Acc: (97.00%) (8867/9088)
Epoch: 182 | Batch_idx: 80 |  Loss: (0.0736) |  Loss2: (0.0000) | Acc: (97.00%) (10110/10368)
Epoch: 182 | Batch_idx: 90 |  Loss: (0.0744) |  Loss2: (0.0000) | Acc: (97.00%) (11350/11648)
Epoch: 182 | Batch_idx: 100 |  Loss: (0.0732) |  Loss2: (0.0000) | Acc: (97.00%) (12606/12928)
Epoch: 182 | Batch_idx: 110 |  Loss: (0.0747) |  Loss2: (0.0000) | Acc: (97.00%) (13850/14208)
Epoch: 182 | Batch_idx: 120 |  Loss: (0.0747) |  Loss2: (0.0000) | Acc: (97.00%) (15102/15488)
Epoch: 182 | Batch_idx: 130 |  Loss: (0.0755) |  Loss2: (0.0000) | Acc: (97.00%) (16347/16768)
Epoch: 182 | Batch_idx: 140 |  Loss: (0.0764) |  Loss2: (0.0000) | Acc: (97.00%) (17591/18048)
Epoch: 182 | Batch_idx: 150 |  Loss: (0.0785) |  Loss2: (0.0000) | Acc: (97.00%) (18818/19328)
Epoch: 182 | Batch_idx: 160 |  Loss: (0.0794) |  Loss2: (0.0000) | Acc: (97.00%) (20051/20608)
Epoch: 182 | Batch_idx: 170 |  Loss: (0.0811) |  Loss2: (0.0000) | Acc: (97.00%) (21292/21888)
Epoch: 182 | Batch_idx: 180 |  Loss: (0.0816) |  Loss2: (0.0000) | Acc: (97.00%) (22528/23168)
Epoch: 182 | Batch_idx: 190 |  Loss: (0.0823) |  Loss2: (0.0000) | Acc: (97.00%) (23769/24448)
Epoch: 182 | Batch_idx: 200 |  Loss: (0.0827) |  Loss2: (0.0000) | Acc: (97.00%) (25010/25728)
Epoch: 182 | Batch_idx: 210 |  Loss: (0.0834) |  Loss2: (0.0000) | Acc: (97.00%) (26253/27008)
Epoch: 182 | Batch_idx: 220 |  Loss: (0.0842) |  Loss2: (0.0000) | Acc: (97.00%) (27492/28288)
Epoch: 182 | Batch_idx: 230 |  Loss: (0.0835) |  Loss2: (0.0000) | Acc: (97.00%) (28745/29568)
Epoch: 182 | Batch_idx: 240 |  Loss: (0.0846) |  Loss2: (0.0000) | Acc: (97.00%) (29981/30848)
Epoch: 182 | Batch_idx: 250 |  Loss: (0.0845) |  Loss2: (0.0000) | Acc: (97.00%) (31223/32128)
Epoch: 182 | Batch_idx: 260 |  Loss: (0.0842) |  Loss2: (0.0000) | Acc: (97.00%) (32467/33408)
Epoch: 182 | Batch_idx: 270 |  Loss: (0.0841) |  Loss2: (0.0000) | Acc: (97.00%) (33704/34688)
Epoch: 182 | Batch_idx: 280 |  Loss: (0.0843) |  Loss2: (0.0000) | Acc: (97.00%) (34942/35968)
Epoch: 182 | Batch_idx: 290 |  Loss: (0.0842) |  Loss2: (0.0000) | Acc: (97.00%) (36187/37248)
Epoch: 182 | Batch_idx: 300 |  Loss: (0.0843) |  Loss2: (0.0000) | Acc: (97.00%) (37432/38528)
Epoch: 182 | Batch_idx: 310 |  Loss: (0.0847) |  Loss2: (0.0000) | Acc: (97.00%) (38663/39808)
Epoch: 182 | Batch_idx: 320 |  Loss: (0.0844) |  Loss2: (0.0000) | Acc: (97.00%) (39915/41088)
Epoch: 182 | Batch_idx: 330 |  Loss: (0.0840) |  Loss2: (0.0000) | Acc: (97.00%) (41167/42368)
Epoch: 182 | Batch_idx: 340 |  Loss: (0.0843) |  Loss2: (0.0000) | Acc: (97.00%) (42406/43648)
Epoch: 182 | Batch_idx: 350 |  Loss: (0.0845) |  Loss2: (0.0000) | Acc: (97.00%) (43641/44928)
Epoch: 182 | Batch_idx: 360 |  Loss: (0.0847) |  Loss2: (0.0000) | Acc: (97.00%) (44876/46208)
Epoch: 182 | Batch_idx: 370 |  Loss: (0.0849) |  Loss2: (0.0000) | Acc: (97.00%) (46113/47488)
Epoch: 182 | Batch_idx: 380 |  Loss: (0.0847) |  Loss2: (0.0000) | Acc: (97.00%) (47364/48768)
Epoch: 182 | Batch_idx: 390 |  Loss: (0.0846) |  Loss2: (0.0000) | Acc: (97.00%) (48560/50000)
# TEST : Loss: (0.4093) | Acc: (88.00%) (8885/10000)
percent tensor([0.5708, 0.5797, 0.5706, 0.5731, 0.5761, 0.5863, 0.5810, 0.5671, 0.5683,
        0.5744, 0.5761, 0.5778, 0.5724, 0.5673, 0.5857, 0.5757],
       device='cuda:0') torch.Size([16])
percent tensor([0.5315, 0.5349, 0.5220, 0.5270, 0.5213, 0.5405, 0.5274, 0.5215, 0.5228,
        0.5308, 0.5343, 0.5244, 0.5298, 0.5317, 0.5348, 0.5345],
       device='cuda:0') torch.Size([16])
percent tensor([0.5549, 0.4529, 0.6919, 0.7021, 0.7123, 0.6629, 0.5467, 0.6674, 0.6017,
        0.5208, 0.4597, 0.6226, 0.4572, 0.5452, 0.5201, 0.6063],
       device='cuda:0') torch.Size([16])
percent tensor([0.6862, 0.7162, 0.6110, 0.6363, 0.6142, 0.5395, 0.6866, 0.6390, 0.6945,
        0.7203, 0.7327, 0.6760, 0.7053, 0.7265, 0.6551, 0.6558],
       device='cuda:0') torch.Size([16])
percent tensor([0.7354, 0.6370, 0.7776, 0.7719, 0.7905, 0.8408, 0.7297, 0.7594, 0.7081,
        0.6208, 0.5967, 0.6488, 0.5863, 0.6621, 0.7276, 0.7839],
       device='cuda:0') torch.Size([16])
percent tensor([0.6511, 0.7661, 0.7490, 0.7896, 0.7595, 0.7972, 0.7418, 0.5836, 0.7372,
        0.7465, 0.7958, 0.7902, 0.7705, 0.7520, 0.6178, 0.6145],
       device='cuda:0') torch.Size([16])
percent tensor([0.4283, 0.6800, 0.6398, 0.6111, 0.5994, 0.5733, 0.5914, 0.5652, 0.6181,
        0.6216, 0.7158, 0.6255, 0.6060, 0.6443, 0.5213, 0.3849],
       device='cuda:0') torch.Size([16])
percent tensor([0.9998, 0.9997, 0.9997, 0.9999, 0.9999, 0.9994, 0.9999, 0.9997, 0.9998,
        0.9999, 0.9997, 0.9999, 0.9995, 0.9997, 0.9998, 0.9996],
       device='cuda:0') torch.Size([16])
False Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=128, out_features=16, bias=False)
True Linear(in_features=16, out_features=2, bias=False)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=128, out_features=16, bias=False)
True Linear(in_features=16, out_features=2, bias=False)
False Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=256, out_features=32, bias=False)
True Linear(in_features=32, out_features=2, bias=False)
False Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=256, out_features=32, bias=False)
True Linear(in_features=32, out_features=2, bias=False)
False Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=512, out_features=64, bias=False)
True Linear(in_features=64, out_features=2, bias=False)
False Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=512, out_features=64, bias=False)
True Linear(in_features=64, out_features=2, bias=False)
False Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1024, out_features=128, bias=False)
True Linear(in_features=128, out_features=2, bias=False)
False Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1024, out_features=128, bias=False)
True Linear(in_features=128, out_features=2, bias=False)
False Linear(in_features=512, out_features=10, bias=True)
Epoch: 183 | Batch_idx: 0 |  Loss: (0.0347) |  Loss2: (0.0000) | Acc: (97.00%) (125/128)
Epoch: 183 | Batch_idx: 10 |  Loss: (0.0988) |  Loss2: (0.0000) | Acc: (96.00%) (1362/1408)
Epoch: 183 | Batch_idx: 20 |  Loss: (0.0998) |  Loss2: (0.0000) | Acc: (96.00%) (2594/2688)
Epoch: 183 | Batch_idx: 30 |  Loss: (0.1029) |  Loss2: (0.0000) | Acc: (96.00%) (3815/3968)
Epoch: 183 | Batch_idx: 40 |  Loss: (0.1043) |  Loss2: (0.0000) | Acc: (96.00%) (5049/5248)
Epoch: 183 | Batch_idx: 50 |  Loss: (0.1075) |  Loss2: (0.0000) | Acc: (96.00%) (6275/6528)
Epoch: 183 | Batch_idx: 60 |  Loss: (0.1058) |  Loss2: (0.0000) | Acc: (96.00%) (7517/7808)
Epoch: 183 | Batch_idx: 70 |  Loss: (0.1073) |  Loss2: (0.0000) | Acc: (96.00%) (8742/9088)
Epoch: 183 | Batch_idx: 80 |  Loss: (0.1099) |  Loss2: (0.0000) | Acc: (96.00%) (9964/10368)
Epoch: 183 | Batch_idx: 90 |  Loss: (0.1097) |  Loss2: (0.0000) | Acc: (96.00%) (11194/11648)
Epoch: 183 | Batch_idx: 100 |  Loss: (0.1085) |  Loss2: (0.0000) | Acc: (96.00%) (12429/12928)
Epoch: 183 | Batch_idx: 110 |  Loss: (0.1073) |  Loss2: (0.0000) | Acc: (96.00%) (13669/14208)
Epoch: 183 | Batch_idx: 120 |  Loss: (0.1085) |  Loss2: (0.0000) | Acc: (96.00%) (14899/15488)
Epoch: 183 | Batch_idx: 130 |  Loss: (0.1090) |  Loss2: (0.0000) | Acc: (96.00%) (16128/16768)
Epoch: 183 | Batch_idx: 140 |  Loss: (0.1093) |  Loss2: (0.0000) | Acc: (96.00%) (17351/18048)
Epoch: 183 | Batch_idx: 150 |  Loss: (0.1089) |  Loss2: (0.0000) | Acc: (96.00%) (18582/19328)
Epoch: 183 | Batch_idx: 160 |  Loss: (0.1076) |  Loss2: (0.0000) | Acc: (96.00%) (19822/20608)
Epoch: 183 | Batch_idx: 170 |  Loss: (0.1072) |  Loss2: (0.0000) | Acc: (96.00%) (21058/21888)
Epoch: 183 | Batch_idx: 180 |  Loss: (0.1069) |  Loss2: (0.0000) | Acc: (96.00%) (22293/23168)
Epoch: 183 | Batch_idx: 190 |  Loss: (0.1068) |  Loss2: (0.0000) | Acc: (96.00%) (23531/24448)
Epoch: 183 | Batch_idx: 200 |  Loss: (0.1066) |  Loss2: (0.0000) | Acc: (96.00%) (24770/25728)
Epoch: 183 | Batch_idx: 210 |  Loss: (0.1073) |  Loss2: (0.0000) | Acc: (96.00%) (25994/27008)
Epoch: 183 | Batch_idx: 220 |  Loss: (0.1071) |  Loss2: (0.0000) | Acc: (96.00%) (27227/28288)
Epoch: 183 | Batch_idx: 230 |  Loss: (0.1068) |  Loss2: (0.0000) | Acc: (96.00%) (28465/29568)
Epoch: 183 | Batch_idx: 240 |  Loss: (0.1062) |  Loss2: (0.0000) | Acc: (96.00%) (29704/30848)
Epoch: 183 | Batch_idx: 250 |  Loss: (0.1048) |  Loss2: (0.0000) | Acc: (96.00%) (30954/32128)
Epoch: 183 | Batch_idx: 260 |  Loss: (0.1049) |  Loss2: (0.0000) | Acc: (96.00%) (32185/33408)
Epoch: 183 | Batch_idx: 270 |  Loss: (0.1043) |  Loss2: (0.0000) | Acc: (96.00%) (33425/34688)
Epoch: 183 | Batch_idx: 280 |  Loss: (0.1032) |  Loss2: (0.0000) | Acc: (96.00%) (34675/35968)
Epoch: 183 | Batch_idx: 290 |  Loss: (0.1028) |  Loss2: (0.0000) | Acc: (96.00%) (35915/37248)
Epoch: 183 | Batch_idx: 300 |  Loss: (0.1031) |  Loss2: (0.0000) | Acc: (96.00%) (37145/38528)
Epoch: 183 | Batch_idx: 310 |  Loss: (0.1031) |  Loss2: (0.0000) | Acc: (96.00%) (38380/39808)
Epoch: 183 | Batch_idx: 320 |  Loss: (0.1025) |  Loss2: (0.0000) | Acc: (96.00%) (39618/41088)
Epoch: 183 | Batch_idx: 330 |  Loss: (0.1015) |  Loss2: (0.0000) | Acc: (96.00%) (40868/42368)
Epoch: 183 | Batch_idx: 340 |  Loss: (0.1013) |  Loss2: (0.0000) | Acc: (96.00%) (42112/43648)
Epoch: 183 | Batch_idx: 350 |  Loss: (0.1011) |  Loss2: (0.0000) | Acc: (96.00%) (43351/44928)
Epoch: 183 | Batch_idx: 360 |  Loss: (0.1011) |  Loss2: (0.0000) | Acc: (96.00%) (44587/46208)
Epoch: 183 | Batch_idx: 370 |  Loss: (0.1010) |  Loss2: (0.0000) | Acc: (96.00%) (45824/47488)
Epoch: 183 | Batch_idx: 380 |  Loss: (0.1007) |  Loss2: (0.0000) | Acc: (96.00%) (47065/48768)
Epoch: 183 | Batch_idx: 390 |  Loss: (0.1006) |  Loss2: (0.0000) | Acc: (96.00%) (48250/50000)
# TEST : Loss: (0.4032) | Acc: (89.00%) (8902/10000)
percent tensor([0.5722, 0.5813, 0.5736, 0.5739, 0.5786, 0.5873, 0.5829, 0.5696, 0.5703,
        0.5764, 0.5772, 0.5805, 0.5740, 0.5682, 0.5868, 0.5767],
       device='cuda:0') torch.Size([16])
percent tensor([0.5306, 0.5348, 0.5212, 0.5262, 0.5200, 0.5375, 0.5275, 0.5208, 0.5226,
        0.5309, 0.5343, 0.5245, 0.5301, 0.5314, 0.5336, 0.5334],
       device='cuda:0') torch.Size([16])
percent tensor([0.5910, 0.4719, 0.7070, 0.7177, 0.7257, 0.6883, 0.5696, 0.6794, 0.6263,
        0.5464, 0.4924, 0.6467, 0.4937, 0.5637, 0.5488, 0.6397],
       device='cuda:0') torch.Size([16])
percent tensor([0.6819, 0.7153, 0.6104, 0.6338, 0.6148, 0.5415, 0.6857, 0.6353, 0.6882,
        0.7178, 0.7274, 0.6756, 0.6990, 0.7222, 0.6571, 0.6542],
       device='cuda:0') torch.Size([16])
percent tensor([0.7271, 0.6483, 0.7553, 0.7475, 0.7654, 0.8278, 0.7115, 0.7348, 0.7010,
        0.6190, 0.6026, 0.6402, 0.6074, 0.6547, 0.7154, 0.7757],
       device='cuda:0') torch.Size([16])
percent tensor([0.6441, 0.7756, 0.7513, 0.8063, 0.7746, 0.7963, 0.7441, 0.5924, 0.7532,
        0.7484, 0.8046, 0.7917, 0.7778, 0.7665, 0.6197, 0.5869],
       device='cuda:0') torch.Size([16])
percent tensor([0.3659, 0.6469, 0.6507, 0.6258, 0.6063, 0.5762, 0.5527, 0.5615, 0.5895,
        0.5521, 0.6908, 0.6013, 0.5618, 0.5955, 0.4752, 0.3393],
       device='cuda:0') torch.Size([16])
percent tensor([0.9998, 0.9998, 0.9998, 0.9999, 1.0000, 0.9994, 0.9999, 0.9997, 0.9998,
        0.9999, 0.9997, 0.9999, 0.9995, 0.9997, 0.9997, 0.9997],
       device='cuda:0') torch.Size([16])
Epoch: 184 | Batch_idx: 0 |  Loss: (0.0507) |  Loss2: (0.0000) | Acc: (98.00%) (126/128)
Epoch: 184 | Batch_idx: 10 |  Loss: (0.0831) |  Loss2: (0.0000) | Acc: (97.00%) (1368/1408)
Epoch: 184 | Batch_idx: 20 |  Loss: (0.0903) |  Loss2: (0.0000) | Acc: (97.00%) (2610/2688)
Epoch: 184 | Batch_idx: 30 |  Loss: (0.0939) |  Loss2: (0.0000) | Acc: (96.00%) (3847/3968)
Epoch: 184 | Batch_idx: 40 |  Loss: (0.0917) |  Loss2: (0.0000) | Acc: (97.00%) (5092/5248)
Epoch: 184 | Batch_idx: 50 |  Loss: (0.0911) |  Loss2: (0.0000) | Acc: (97.00%) (6337/6528)
Epoch: 184 | Batch_idx: 60 |  Loss: (0.0911) |  Loss2: (0.0000) | Acc: (97.00%) (7576/7808)
Epoch: 184 | Batch_idx: 70 |  Loss: (0.0909) |  Loss2: (0.0000) | Acc: (96.00%) (8814/9088)
Epoch: 184 | Batch_idx: 80 |  Loss: (0.0869) |  Loss2: (0.0000) | Acc: (97.00%) (10069/10368)
Epoch: 184 | Batch_idx: 90 |  Loss: (0.0876) |  Loss2: (0.0000) | Acc: (97.00%) (11303/11648)
Epoch: 184 | Batch_idx: 100 |  Loss: (0.0885) |  Loss2: (0.0000) | Acc: (96.00%) (12533/12928)
Epoch: 184 | Batch_idx: 110 |  Loss: (0.0878) |  Loss2: (0.0000) | Acc: (96.00%) (13776/14208)
Epoch: 184 | Batch_idx: 120 |  Loss: (0.0874) |  Loss2: (0.0000) | Acc: (96.00%) (15022/15488)
Epoch: 184 | Batch_idx: 130 |  Loss: (0.0875) |  Loss2: (0.0000) | Acc: (96.00%) (16264/16768)
Epoch: 184 | Batch_idx: 140 |  Loss: (0.0879) |  Loss2: (0.0000) | Acc: (97.00%) (17507/18048)
Epoch: 184 | Batch_idx: 150 |  Loss: (0.0886) |  Loss2: (0.0000) | Acc: (96.00%) (18744/19328)
Epoch: 184 | Batch_idx: 160 |  Loss: (0.0896) |  Loss2: (0.0000) | Acc: (96.00%) (19983/20608)
Epoch: 184 | Batch_idx: 170 |  Loss: (0.0890) |  Loss2: (0.0000) | Acc: (96.00%) (21229/21888)
Epoch: 184 | Batch_idx: 180 |  Loss: (0.0880) |  Loss2: (0.0000) | Acc: (97.00%) (22477/23168)
Epoch: 184 | Batch_idx: 190 |  Loss: (0.0887) |  Loss2: (0.0000) | Acc: (96.00%) (23711/24448)
Epoch: 184 | Batch_idx: 200 |  Loss: (0.0881) |  Loss2: (0.0000) | Acc: (97.00%) (24961/25728)
Epoch: 184 | Batch_idx: 210 |  Loss: (0.0878) |  Loss2: (0.0000) | Acc: (97.00%) (26211/27008)
Epoch: 184 | Batch_idx: 220 |  Loss: (0.0875) |  Loss2: (0.0000) | Acc: (97.00%) (27460/28288)
Epoch: 184 | Batch_idx: 230 |  Loss: (0.0874) |  Loss2: (0.0000) | Acc: (97.00%) (28699/29568)
Epoch: 184 | Batch_idx: 240 |  Loss: (0.0873) |  Loss2: (0.0000) | Acc: (97.00%) (29941/30848)
Epoch: 184 | Batch_idx: 250 |  Loss: (0.0874) |  Loss2: (0.0000) | Acc: (97.00%) (31187/32128)
Epoch: 184 | Batch_idx: 260 |  Loss: (0.0876) |  Loss2: (0.0000) | Acc: (97.00%) (32423/33408)
Epoch: 184 | Batch_idx: 270 |  Loss: (0.0875) |  Loss2: (0.0000) | Acc: (97.00%) (33661/34688)
Epoch: 184 | Batch_idx: 280 |  Loss: (0.0874) |  Loss2: (0.0000) | Acc: (97.00%) (34899/35968)
Epoch: 184 | Batch_idx: 290 |  Loss: (0.0877) |  Loss2: (0.0000) | Acc: (97.00%) (36139/37248)
Epoch: 184 | Batch_idx: 300 |  Loss: (0.0880) |  Loss2: (0.0000) | Acc: (97.00%) (37377/38528)
Epoch: 184 | Batch_idx: 310 |  Loss: (0.0875) |  Loss2: (0.0000) | Acc: (97.00%) (38631/39808)
Epoch: 184 | Batch_idx: 320 |  Loss: (0.0878) |  Loss2: (0.0000) | Acc: (97.00%) (39869/41088)
Epoch: 184 | Batch_idx: 330 |  Loss: (0.0881) |  Loss2: (0.0000) | Acc: (97.00%) (41107/42368)
Epoch: 184 | Batch_idx: 340 |  Loss: (0.0880) |  Loss2: (0.0000) | Acc: (97.00%) (42353/43648)
Epoch: 184 | Batch_idx: 350 |  Loss: (0.0883) |  Loss2: (0.0000) | Acc: (97.00%) (43587/44928)
Epoch: 184 | Batch_idx: 360 |  Loss: (0.0883) |  Loss2: (0.0000) | Acc: (97.00%) (44829/46208)
Epoch: 184 | Batch_idx: 370 |  Loss: (0.0880) |  Loss2: (0.0000) | Acc: (97.00%) (46081/47488)
Epoch: 184 | Batch_idx: 380 |  Loss: (0.0877) |  Loss2: (0.0000) | Acc: (97.00%) (47329/48768)
Epoch: 184 | Batch_idx: 390 |  Loss: (0.0875) |  Loss2: (0.0000) | Acc: (97.00%) (48524/50000)
# TEST : Loss: (0.3925) | Acc: (89.00%) (8915/10000)
percent tensor([0.5679, 0.5767, 0.5698, 0.5697, 0.5745, 0.5826, 0.5783, 0.5655, 0.5658,
        0.5722, 0.5726, 0.5765, 0.5695, 0.5641, 0.5821, 0.5722],
       device='cuda:0') torch.Size([16])
percent tensor([0.5324, 0.5368, 0.5228, 0.5281, 0.5216, 0.5386, 0.5297, 0.5225, 0.5245,
        0.5328, 0.5366, 0.5265, 0.5322, 0.5330, 0.5355, 0.5350],
       device='cuda:0') torch.Size([16])
percent tensor([0.5806, 0.4635, 0.7023, 0.7111, 0.7201, 0.6818, 0.5578, 0.6702, 0.6182,
        0.5387, 0.4841, 0.6400, 0.4871, 0.5503, 0.5383, 0.6298],
       device='cuda:0') torch.Size([16])
percent tensor([0.6807, 0.7156, 0.6082, 0.6322, 0.6137, 0.5429, 0.6862, 0.6359, 0.6870,
        0.7159, 0.7254, 0.6745, 0.6976, 0.7214, 0.6560, 0.6533],
       device='cuda:0') torch.Size([16])
percent tensor([0.7284, 0.6514, 0.7554, 0.7494, 0.7638, 0.8285, 0.7099, 0.7326, 0.7006,
        0.6216, 0.6041, 0.6438, 0.6107, 0.6572, 0.7162, 0.7763],
       device='cuda:0') torch.Size([16])
percent tensor([0.6331, 0.7669, 0.7444, 0.7997, 0.7678, 0.7921, 0.7341, 0.5795, 0.7449,
        0.7366, 0.7976, 0.7810, 0.7688, 0.7631, 0.6090, 0.5674],
       device='cuda:0') torch.Size([16])
percent tensor([0.3630, 0.6641, 0.6591, 0.6365, 0.6107, 0.5938, 0.5568, 0.5703, 0.5900,
        0.5479, 0.6991, 0.6067, 0.5708, 0.6085, 0.4883, 0.3360],
       device='cuda:0') torch.Size([16])
percent tensor([0.9998, 0.9998, 0.9997, 0.9999, 1.0000, 0.9994, 0.9999, 0.9997, 0.9998,
        0.9999, 0.9997, 0.9999, 0.9995, 0.9997, 0.9997, 0.9997],
       device='cuda:0') torch.Size([16])
Epoch: 185 | Batch_idx: 0 |  Loss: (0.0713) |  Loss2: (0.0000) | Acc: (97.00%) (125/128)
Epoch: 185 | Batch_idx: 10 |  Loss: (0.0970) |  Loss2: (0.0000) | Acc: (97.00%) (1368/1408)
Epoch: 185 | Batch_idx: 20 |  Loss: (0.0847) |  Loss2: (0.0000) | Acc: (97.00%) (2610/2688)
Epoch: 185 | Batch_idx: 30 |  Loss: (0.0823) |  Loss2: (0.0000) | Acc: (97.00%) (3855/3968)
Epoch: 185 | Batch_idx: 40 |  Loss: (0.0844) |  Loss2: (0.0000) | Acc: (97.00%) (5092/5248)
Epoch: 185 | Batch_idx: 50 |  Loss: (0.0841) |  Loss2: (0.0000) | Acc: (96.00%) (6328/6528)
Epoch: 185 | Batch_idx: 60 |  Loss: (0.0854) |  Loss2: (0.0000) | Acc: (96.00%) (7570/7808)
Epoch: 185 | Batch_idx: 70 |  Loss: (0.0857) |  Loss2: (0.0000) | Acc: (97.00%) (8819/9088)
Epoch: 185 | Batch_idx: 80 |  Loss: (0.0853) |  Loss2: (0.0000) | Acc: (97.00%) (10059/10368)
Epoch: 185 | Batch_idx: 90 |  Loss: (0.0852) |  Loss2: (0.0000) | Acc: (97.00%) (11300/11648)
Epoch: 185 | Batch_idx: 100 |  Loss: (0.0844) |  Loss2: (0.0000) | Acc: (97.00%) (12549/12928)
Epoch: 185 | Batch_idx: 110 |  Loss: (0.0835) |  Loss2: (0.0000) | Acc: (97.00%) (13795/14208)
Epoch: 185 | Batch_idx: 120 |  Loss: (0.0822) |  Loss2: (0.0000) | Acc: (97.00%) (15049/15488)
Epoch: 185 | Batch_idx: 130 |  Loss: (0.0825) |  Loss2: (0.0000) | Acc: (97.00%) (16291/16768)
Epoch: 185 | Batch_idx: 140 |  Loss: (0.0824) |  Loss2: (0.0000) | Acc: (97.00%) (17535/18048)
Epoch: 185 | Batch_idx: 150 |  Loss: (0.0826) |  Loss2: (0.0000) | Acc: (97.00%) (18781/19328)
Epoch: 185 | Batch_idx: 160 |  Loss: (0.0825) |  Loss2: (0.0000) | Acc: (97.00%) (20021/20608)
Epoch: 185 | Batch_idx: 170 |  Loss: (0.0821) |  Loss2: (0.0000) | Acc: (97.00%) (21267/21888)
Epoch: 185 | Batch_idx: 180 |  Loss: (0.0817) |  Loss2: (0.0000) | Acc: (97.00%) (22515/23168)
Epoch: 185 | Batch_idx: 190 |  Loss: (0.0820) |  Loss2: (0.0000) | Acc: (97.00%) (23762/24448)
Epoch: 185 | Batch_idx: 200 |  Loss: (0.0815) |  Loss2: (0.0000) | Acc: (97.00%) (25015/25728)
Epoch: 185 | Batch_idx: 210 |  Loss: (0.0817) |  Loss2: (0.0000) | Acc: (97.00%) (26261/27008)
Epoch: 185 | Batch_idx: 220 |  Loss: (0.0814) |  Loss2: (0.0000) | Acc: (97.00%) (27512/28288)
Epoch: 185 | Batch_idx: 230 |  Loss: (0.0819) |  Loss2: (0.0000) | Acc: (97.00%) (28757/29568)
Epoch: 185 | Batch_idx: 240 |  Loss: (0.0813) |  Loss2: (0.0000) | Acc: (97.00%) (30007/30848)
Epoch: 185 | Batch_idx: 250 |  Loss: (0.0813) |  Loss2: (0.0000) | Acc: (97.00%) (31255/32128)
Epoch: 185 | Batch_idx: 260 |  Loss: (0.0815) |  Loss2: (0.0000) | Acc: (97.00%) (32498/33408)
Epoch: 185 | Batch_idx: 270 |  Loss: (0.0824) |  Loss2: (0.0000) | Acc: (97.00%) (33738/34688)
Epoch: 185 | Batch_idx: 280 |  Loss: (0.0823) |  Loss2: (0.0000) | Acc: (97.00%) (34986/35968)
Epoch: 185 | Batch_idx: 290 |  Loss: (0.0823) |  Loss2: (0.0000) | Acc: (97.00%) (36225/37248)
Epoch: 185 | Batch_idx: 300 |  Loss: (0.0820) |  Loss2: (0.0000) | Acc: (97.00%) (37474/38528)
Epoch: 185 | Batch_idx: 310 |  Loss: (0.0815) |  Loss2: (0.0000) | Acc: (97.00%) (38724/39808)
Epoch: 185 | Batch_idx: 320 |  Loss: (0.0817) |  Loss2: (0.0000) | Acc: (97.00%) (39968/41088)
Epoch: 185 | Batch_idx: 330 |  Loss: (0.0817) |  Loss2: (0.0000) | Acc: (97.00%) (41211/42368)
Epoch: 185 | Batch_idx: 340 |  Loss: (0.0813) |  Loss2: (0.0000) | Acc: (97.00%) (42465/43648)
Epoch: 185 | Batch_idx: 350 |  Loss: (0.0814) |  Loss2: (0.0000) | Acc: (97.00%) (43706/44928)
Epoch: 185 | Batch_idx: 360 |  Loss: (0.0812) |  Loss2: (0.0000) | Acc: (97.00%) (44949/46208)
Epoch: 185 | Batch_idx: 370 |  Loss: (0.0812) |  Loss2: (0.0000) | Acc: (97.00%) (46196/47488)
Epoch: 185 | Batch_idx: 380 |  Loss: (0.0811) |  Loss2: (0.0000) | Acc: (97.00%) (47443/48768)
Epoch: 185 | Batch_idx: 390 |  Loss: (0.0811) |  Loss2: (0.0000) | Acc: (97.00%) (48641/50000)
=> saving checkpoint 'drive/app/torch/save_Schedule/checkpoint_185.pth.tar'
# TEST : Loss: (0.3885) | Acc: (89.00%) (8924/10000)
percent tensor([0.5709, 0.5801, 0.5735, 0.5729, 0.5781, 0.5856, 0.5819, 0.5691, 0.5690,
        0.5758, 0.5758, 0.5804, 0.5727, 0.5669, 0.5854, 0.5753],
       device='cuda:0') torch.Size([16])
percent tensor([0.5339, 0.5384, 0.5240, 0.5293, 0.5230, 0.5398, 0.5313, 0.5237, 0.5258,
        0.5343, 0.5382, 0.5278, 0.5337, 0.5344, 0.5370, 0.5364],
       device='cuda:0') torch.Size([16])
percent tensor([0.5821, 0.4656, 0.7040, 0.7117, 0.7228, 0.6823, 0.5595, 0.6720, 0.6200,
        0.5403, 0.4854, 0.6420, 0.4892, 0.5494, 0.5390, 0.6312],
       device='cuda:0') torch.Size([16])
percent tensor([0.6862, 0.7214, 0.6134, 0.6374, 0.6194, 0.5485, 0.6919, 0.6425, 0.6926,
        0.7214, 0.7303, 0.6814, 0.7043, 0.7258, 0.6630, 0.6586],
       device='cuda:0') torch.Size([16])
percent tensor([0.7262, 0.6537, 0.7524, 0.7485, 0.7625, 0.8287, 0.7101, 0.7301, 0.6988,
        0.6179, 0.6012, 0.6397, 0.6067, 0.6615, 0.7168, 0.7759],
       device='cuda:0') torch.Size([16])
percent tensor([0.6321, 0.7677, 0.7479, 0.7989, 0.7699, 0.7936, 0.7357, 0.5736, 0.7452,
        0.7383, 0.7986, 0.7773, 0.7663, 0.7682, 0.6042, 0.5663],
       device='cuda:0') torch.Size([16])
percent tensor([0.3782, 0.7001, 0.6878, 0.6712, 0.6303, 0.6258, 0.5930, 0.5952, 0.6282,
        0.5848, 0.7320, 0.6431, 0.6059, 0.6409, 0.5286, 0.3468],
       device='cuda:0') torch.Size([16])
percent tensor([0.9998, 0.9998, 0.9997, 0.9999, 1.0000, 0.9994, 0.9999, 0.9997, 0.9998,
        0.9999, 0.9997, 0.9999, 0.9996, 0.9997, 0.9997, 0.9996],
       device='cuda:0') torch.Size([16])
True Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=128, out_features=16, bias=False)
False Linear(in_features=16, out_features=2, bias=False)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=128, out_features=16, bias=False)
False Linear(in_features=16, out_features=2, bias=False)
True Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=256, out_features=32, bias=False)
False Linear(in_features=32, out_features=2, bias=False)
True Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=256, out_features=32, bias=False)
False Linear(in_features=32, out_features=2, bias=False)
True Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=512, out_features=64, bias=False)
False Linear(in_features=64, out_features=2, bias=False)
True Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=512, out_features=64, bias=False)
False Linear(in_features=64, out_features=2, bias=False)
True Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1024, out_features=128, bias=False)
False Linear(in_features=128, out_features=2, bias=False)
True Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1024, out_features=128, bias=False)
False Linear(in_features=128, out_features=2, bias=False)
True Linear(in_features=512, out_features=10, bias=True)
Epoch: 186 | Batch_idx: 0 |  Loss: (0.0843) |  Loss2: (0.0000) | Acc: (96.00%) (124/128)
Epoch: 186 | Batch_idx: 10 |  Loss: (0.0841) |  Loss2: (0.0000) | Acc: (97.00%) (1369/1408)
Epoch: 186 | Batch_idx: 20 |  Loss: (0.0815) |  Loss2: (0.0000) | Acc: (97.00%) (2618/2688)
Epoch: 186 | Batch_idx: 30 |  Loss: (0.0859) |  Loss2: (0.0000) | Acc: (97.00%) (3854/3968)
Epoch: 186 | Batch_idx: 40 |  Loss: (0.0852) |  Loss2: (0.0000) | Acc: (97.00%) (5096/5248)
Epoch: 186 | Batch_idx: 50 |  Loss: (0.0884) |  Loss2: (0.0000) | Acc: (97.00%) (6334/6528)
Epoch: 186 | Batch_idx: 60 |  Loss: (0.0877) |  Loss2: (0.0000) | Acc: (97.00%) (7581/7808)
Epoch: 186 | Batch_idx: 70 |  Loss: (0.0897) |  Loss2: (0.0000) | Acc: (97.00%) (8819/9088)
Epoch: 186 | Batch_idx: 80 |  Loss: (0.0900) |  Loss2: (0.0000) | Acc: (97.00%) (10060/10368)
Epoch: 186 | Batch_idx: 90 |  Loss: (0.0893) |  Loss2: (0.0000) | Acc: (97.00%) (11305/11648)
Epoch: 186 | Batch_idx: 100 |  Loss: (0.0894) |  Loss2: (0.0000) | Acc: (97.00%) (12541/12928)
Epoch: 186 | Batch_idx: 110 |  Loss: (0.0894) |  Loss2: (0.0000) | Acc: (96.00%) (13780/14208)
Epoch: 186 | Batch_idx: 120 |  Loss: (0.0905) |  Loss2: (0.0000) | Acc: (96.00%) (15016/15488)
Epoch: 186 | Batch_idx: 130 |  Loss: (0.0898) |  Loss2: (0.0000) | Acc: (96.00%) (16263/16768)
Epoch: 186 | Batch_idx: 140 |  Loss: (0.0904) |  Loss2: (0.0000) | Acc: (96.00%) (17503/18048)
Epoch: 186 | Batch_idx: 150 |  Loss: (0.0896) |  Loss2: (0.0000) | Acc: (96.00%) (18747/19328)
Epoch: 186 | Batch_idx: 160 |  Loss: (0.0893) |  Loss2: (0.0000) | Acc: (97.00%) (19990/20608)
Epoch: 186 | Batch_idx: 170 |  Loss: (0.0896) |  Loss2: (0.0000) | Acc: (96.00%) (21229/21888)
Epoch: 186 | Batch_idx: 180 |  Loss: (0.0896) |  Loss2: (0.0000) | Acc: (96.00%) (22470/23168)
Epoch: 186 | Batch_idx: 190 |  Loss: (0.0896) |  Loss2: (0.0000) | Acc: (96.00%) (23710/24448)
Epoch: 186 | Batch_idx: 200 |  Loss: (0.0885) |  Loss2: (0.0000) | Acc: (97.00%) (24963/25728)
Epoch: 186 | Batch_idx: 210 |  Loss: (0.0879) |  Loss2: (0.0000) | Acc: (97.00%) (26216/27008)
Epoch: 186 | Batch_idx: 220 |  Loss: (0.0881) |  Loss2: (0.0000) | Acc: (97.00%) (27453/28288)
Epoch: 186 | Batch_idx: 230 |  Loss: (0.0875) |  Loss2: (0.0000) | Acc: (97.00%) (28701/29568)
Epoch: 186 | Batch_idx: 240 |  Loss: (0.0868) |  Loss2: (0.0000) | Acc: (97.00%) (29954/30848)
Epoch: 186 | Batch_idx: 250 |  Loss: (0.0868) |  Loss2: (0.0000) | Acc: (97.00%) (31196/32128)
Epoch: 186 | Batch_idx: 260 |  Loss: (0.0863) |  Loss2: (0.0000) | Acc: (97.00%) (32441/33408)
Epoch: 186 | Batch_idx: 270 |  Loss: (0.0860) |  Loss2: (0.0000) | Acc: (97.00%) (33686/34688)
Epoch: 186 | Batch_idx: 280 |  Loss: (0.0854) |  Loss2: (0.0000) | Acc: (97.00%) (34938/35968)
Epoch: 186 | Batch_idx: 290 |  Loss: (0.0855) |  Loss2: (0.0000) | Acc: (97.00%) (36179/37248)
Epoch: 186 | Batch_idx: 300 |  Loss: (0.0855) |  Loss2: (0.0000) | Acc: (97.00%) (37417/38528)
Epoch: 186 | Batch_idx: 310 |  Loss: (0.0855) |  Loss2: (0.0000) | Acc: (97.00%) (38653/39808)
Epoch: 186 | Batch_idx: 320 |  Loss: (0.0855) |  Loss2: (0.0000) | Acc: (97.00%) (39899/41088)
Epoch: 186 | Batch_idx: 330 |  Loss: (0.0858) |  Loss2: (0.0000) | Acc: (97.00%) (41140/42368)
Epoch: 186 | Batch_idx: 340 |  Loss: (0.0858) |  Loss2: (0.0000) | Acc: (97.00%) (42387/43648)
Epoch: 186 | Batch_idx: 350 |  Loss: (0.0861) |  Loss2: (0.0000) | Acc: (97.00%) (43628/44928)
Epoch: 186 | Batch_idx: 360 |  Loss: (0.0858) |  Loss2: (0.0000) | Acc: (97.00%) (44872/46208)
Epoch: 186 | Batch_idx: 370 |  Loss: (0.0857) |  Loss2: (0.0000) | Acc: (97.00%) (46117/47488)
Epoch: 186 | Batch_idx: 380 |  Loss: (0.0855) |  Loss2: (0.0000) | Acc: (97.00%) (47373/48768)
Epoch: 186 | Batch_idx: 390 |  Loss: (0.0852) |  Loss2: (0.0000) | Acc: (97.00%) (48577/50000)
# TEST : Loss: (0.4145) | Acc: (88.00%) (8890/10000)
percent tensor([0.5710, 0.5804, 0.5732, 0.5716, 0.5782, 0.5854, 0.5820, 0.5684, 0.5691,
        0.5756, 0.5765, 0.5805, 0.5731, 0.5677, 0.5855, 0.5752],
       device='cuda:0') torch.Size([16])
percent tensor([0.5334, 0.5380, 0.5217, 0.5298, 0.5218, 0.5394, 0.5301, 0.5228, 0.5250,
        0.5336, 0.5375, 0.5263, 0.5332, 0.5338, 0.5367, 0.5363],
       device='cuda:0') torch.Size([16])
percent tensor([0.5782, 0.4506, 0.7045, 0.7039, 0.7185, 0.6603, 0.5566, 0.6774, 0.6355,
        0.5425, 0.4911, 0.6525, 0.4897, 0.5517, 0.5192, 0.6244],
       device='cuda:0') torch.Size([16])
percent tensor([0.6854, 0.7173, 0.6095, 0.6342, 0.6163, 0.5502, 0.6849, 0.6406, 0.6874,
        0.7153, 0.7252, 0.6703, 0.7040, 0.7207, 0.6591, 0.6579],
       device='cuda:0') torch.Size([16])
percent tensor([0.7312, 0.6429, 0.7582, 0.7563, 0.7701, 0.8289, 0.7149, 0.7256, 0.7027,
        0.6332, 0.6098, 0.6511, 0.6158, 0.6633, 0.7260, 0.7816],
       device='cuda:0') torch.Size([16])
percent tensor([0.6195, 0.7383, 0.7517, 0.7876, 0.7701, 0.7983, 0.7167, 0.5668, 0.7431,
        0.7090, 0.7878, 0.7627, 0.7478, 0.7407, 0.5819, 0.5581],
       device='cuda:0') torch.Size([16])
percent tensor([0.4149, 0.6967, 0.6660, 0.6515, 0.6127, 0.6571, 0.6011, 0.5935, 0.6478,
        0.5643, 0.7460, 0.6422, 0.6029, 0.6160, 0.5610, 0.3583],
       device='cuda:0') torch.Size([16])
percent tensor([0.9998, 0.9998, 0.9996, 1.0000, 1.0000, 0.9995, 0.9999, 0.9997, 0.9998,
        0.9999, 0.9997, 0.9999, 0.9996, 0.9996, 0.9998, 0.9996],
       device='cuda:0') torch.Size([16])
Epoch: 187 | Batch_idx: 0 |  Loss: (0.1222) |  Loss2: (0.0000) | Acc: (95.00%) (122/128)
Epoch: 187 | Batch_idx: 10 |  Loss: (0.0908) |  Loss2: (0.0000) | Acc: (96.00%) (1365/1408)
Epoch: 187 | Batch_idx: 20 |  Loss: (0.0820) |  Loss2: (0.0000) | Acc: (97.00%) (2614/2688)
Epoch: 187 | Batch_idx: 30 |  Loss: (0.0834) |  Loss2: (0.0000) | Acc: (97.00%) (3855/3968)
Epoch: 187 | Batch_idx: 40 |  Loss: (0.0830) |  Loss2: (0.0000) | Acc: (97.00%) (5098/5248)
Epoch: 187 | Batch_idx: 50 |  Loss: (0.0858) |  Loss2: (0.0000) | Acc: (96.00%) (6332/6528)
Epoch: 187 | Batch_idx: 60 |  Loss: (0.0835) |  Loss2: (0.0000) | Acc: (97.00%) (7580/7808)
Epoch: 187 | Batch_idx: 70 |  Loss: (0.0810) |  Loss2: (0.0000) | Acc: (97.00%) (8835/9088)
Epoch: 187 | Batch_idx: 80 |  Loss: (0.0803) |  Loss2: (0.0000) | Acc: (97.00%) (10080/10368)
Epoch: 187 | Batch_idx: 90 |  Loss: (0.0795) |  Loss2: (0.0000) | Acc: (97.00%) (11327/11648)
Epoch: 187 | Batch_idx: 100 |  Loss: (0.0794) |  Loss2: (0.0000) | Acc: (97.00%) (12575/12928)
Epoch: 187 | Batch_idx: 110 |  Loss: (0.0799) |  Loss2: (0.0000) | Acc: (97.00%) (13811/14208)
Epoch: 187 | Batch_idx: 120 |  Loss: (0.0792) |  Loss2: (0.0000) | Acc: (97.00%) (15062/15488)
Epoch: 187 | Batch_idx: 130 |  Loss: (0.0795) |  Loss2: (0.0000) | Acc: (97.00%) (16302/16768)
Epoch: 187 | Batch_idx: 140 |  Loss: (0.0792) |  Loss2: (0.0000) | Acc: (97.00%) (17549/18048)
Epoch: 187 | Batch_idx: 150 |  Loss: (0.0795) |  Loss2: (0.0000) | Acc: (97.00%) (18792/19328)
Epoch: 187 | Batch_idx: 160 |  Loss: (0.0789) |  Loss2: (0.0000) | Acc: (97.00%) (20044/20608)
Epoch: 187 | Batch_idx: 170 |  Loss: (0.0792) |  Loss2: (0.0000) | Acc: (97.00%) (21289/21888)
Epoch: 187 | Batch_idx: 180 |  Loss: (0.0793) |  Loss2: (0.0000) | Acc: (97.00%) (22536/23168)
Epoch: 187 | Batch_idx: 190 |  Loss: (0.0805) |  Loss2: (0.0000) | Acc: (97.00%) (23777/24448)
Epoch: 187 | Batch_idx: 200 |  Loss: (0.0819) |  Loss2: (0.0000) | Acc: (97.00%) (25012/25728)
Epoch: 187 | Batch_idx: 210 |  Loss: (0.0825) |  Loss2: (0.0000) | Acc: (97.00%) (26253/27008)
Epoch: 187 | Batch_idx: 220 |  Loss: (0.0828) |  Loss2: (0.0000) | Acc: (97.00%) (27497/28288)
Epoch: 187 | Batch_idx: 230 |  Loss: (0.0826) |  Loss2: (0.0000) | Acc: (97.00%) (28747/29568)
Epoch: 187 | Batch_idx: 240 |  Loss: (0.0833) |  Loss2: (0.0000) | Acc: (97.00%) (29982/30848)
Epoch: 187 | Batch_idx: 250 |  Loss: (0.0836) |  Loss2: (0.0000) | Acc: (97.00%) (31221/32128)
Epoch: 187 | Batch_idx: 260 |  Loss: (0.0839) |  Loss2: (0.0000) | Acc: (97.00%) (32467/33408)
Epoch: 187 | Batch_idx: 270 |  Loss: (0.0838) |  Loss2: (0.0000) | Acc: (97.00%) (33711/34688)
Epoch: 187 | Batch_idx: 280 |  Loss: (0.0839) |  Loss2: (0.0000) | Acc: (97.00%) (34956/35968)
Epoch: 187 | Batch_idx: 290 |  Loss: (0.0842) |  Loss2: (0.0000) | Acc: (97.00%) (36198/37248)
Epoch: 187 | Batch_idx: 300 |  Loss: (0.0843) |  Loss2: (0.0000) | Acc: (97.00%) (37434/38528)
Epoch: 187 | Batch_idx: 310 |  Loss: (0.0840) |  Loss2: (0.0000) | Acc: (97.00%) (38682/39808)
Epoch: 187 | Batch_idx: 320 |  Loss: (0.0838) |  Loss2: (0.0000) | Acc: (97.00%) (39931/41088)
Epoch: 187 | Batch_idx: 330 |  Loss: (0.0834) |  Loss2: (0.0000) | Acc: (97.00%) (41176/42368)
Epoch: 187 | Batch_idx: 340 |  Loss: (0.0837) |  Loss2: (0.0000) | Acc: (97.00%) (42414/43648)
Epoch: 187 | Batch_idx: 350 |  Loss: (0.0835) |  Loss2: (0.0000) | Acc: (97.00%) (43662/44928)
Epoch: 187 | Batch_idx: 360 |  Loss: (0.0838) |  Loss2: (0.0000) | Acc: (97.00%) (44903/46208)
Epoch: 187 | Batch_idx: 370 |  Loss: (0.0838) |  Loss2: (0.0000) | Acc: (97.00%) (46148/47488)
Epoch: 187 | Batch_idx: 380 |  Loss: (0.0837) |  Loss2: (0.0000) | Acc: (97.00%) (47396/48768)
Epoch: 187 | Batch_idx: 390 |  Loss: (0.0840) |  Loss2: (0.0000) | Acc: (97.00%) (48588/50000)
# TEST : Loss: (0.4060) | Acc: (88.00%) (8879/10000)
percent tensor([0.5715, 0.5803, 0.5735, 0.5719, 0.5781, 0.5857, 0.5819, 0.5684, 0.5699,
        0.5754, 0.5769, 0.5797, 0.5734, 0.5677, 0.5853, 0.5753],
       device='cuda:0') torch.Size([16])
percent tensor([0.5337, 0.5383, 0.5240, 0.5309, 0.5236, 0.5394, 0.5304, 0.5236, 0.5259,
        0.5340, 0.5378, 0.5274, 0.5337, 0.5337, 0.5373, 0.5363],
       device='cuda:0') torch.Size([16])
percent tensor([0.5910, 0.4573, 0.7036, 0.7121, 0.7222, 0.6732, 0.5641, 0.6816, 0.6369,
        0.5377, 0.4940, 0.6454, 0.4894, 0.5555, 0.5294, 0.6290],
       device='cuda:0') torch.Size([16])
percent tensor([0.6873, 0.7237, 0.6075, 0.6303, 0.6151, 0.5535, 0.6865, 0.6409, 0.6901,
        0.7215, 0.7318, 0.6769, 0.7046, 0.7290, 0.6663, 0.6593],
       device='cuda:0') torch.Size([16])
percent tensor([0.7273, 0.6279, 0.7546, 0.7474, 0.7718, 0.8305, 0.7158, 0.7276, 0.6906,
        0.6126, 0.5902, 0.6252, 0.6027, 0.6495, 0.7128, 0.7825],
       device='cuda:0') torch.Size([16])
percent tensor([0.6054, 0.7244, 0.7543, 0.7871, 0.7555, 0.8136, 0.7121, 0.5420, 0.7504,
        0.7098, 0.7845, 0.7402, 0.7456, 0.7331, 0.5409, 0.5598],
       device='cuda:0') torch.Size([16])
percent tensor([0.3917, 0.7028, 0.6617, 0.6766, 0.6152, 0.6353, 0.6167, 0.5767, 0.6742,
        0.5934, 0.7593, 0.6453, 0.6052, 0.6073, 0.5519, 0.3601],
       device='cuda:0') torch.Size([16])
percent tensor([0.9997, 0.9997, 0.9997, 0.9999, 1.0000, 0.9995, 0.9998, 0.9996, 0.9998,
        0.9999, 0.9998, 0.9999, 0.9996, 0.9998, 0.9998, 0.9995],
       device='cuda:0') torch.Size([16])
Epoch: 188 | Batch_idx: 0 |  Loss: (0.0523) |  Loss2: (0.0000) | Acc: (97.00%) (125/128)
Epoch: 188 | Batch_idx: 10 |  Loss: (0.0798) |  Loss2: (0.0000) | Acc: (97.00%) (1371/1408)
Epoch: 188 | Batch_idx: 20 |  Loss: (0.0876) |  Loss2: (0.0000) | Acc: (96.00%) (2603/2688)
Epoch: 188 | Batch_idx: 30 |  Loss: (0.0810) |  Loss2: (0.0000) | Acc: (97.00%) (3856/3968)
Epoch: 188 | Batch_idx: 40 |  Loss: (0.0846) |  Loss2: (0.0000) | Acc: (97.00%) (5095/5248)
Epoch: 188 | Batch_idx: 50 |  Loss: (0.0858) |  Loss2: (0.0000) | Acc: (96.00%) (6328/6528)
Epoch: 188 | Batch_idx: 60 |  Loss: (0.0846) |  Loss2: (0.0000) | Acc: (97.00%) (7576/7808)
Epoch: 188 | Batch_idx: 70 |  Loss: (0.0842) |  Loss2: (0.0000) | Acc: (97.00%) (8819/9088)
Epoch: 188 | Batch_idx: 80 |  Loss: (0.0840) |  Loss2: (0.0000) | Acc: (97.00%) (10061/10368)
Epoch: 188 | Batch_idx: 90 |  Loss: (0.0852) |  Loss2: (0.0000) | Acc: (96.00%) (11298/11648)
Epoch: 188 | Batch_idx: 100 |  Loss: (0.0839) |  Loss2: (0.0000) | Acc: (97.00%) (12547/12928)
Epoch: 188 | Batch_idx: 110 |  Loss: (0.0830) |  Loss2: (0.0000) | Acc: (97.00%) (13795/14208)
Epoch: 188 | Batch_idx: 120 |  Loss: (0.0817) |  Loss2: (0.0000) | Acc: (97.00%) (15047/15488)
Epoch: 188 | Batch_idx: 130 |  Loss: (0.0812) |  Loss2: (0.0000) | Acc: (97.00%) (16297/16768)
Epoch: 188 | Batch_idx: 140 |  Loss: (0.0816) |  Loss2: (0.0000) | Acc: (97.00%) (17534/18048)
Epoch: 188 | Batch_idx: 150 |  Loss: (0.0809) |  Loss2: (0.0000) | Acc: (97.00%) (18778/19328)
Epoch: 188 | Batch_idx: 160 |  Loss: (0.0804) |  Loss2: (0.0000) | Acc: (97.00%) (20027/20608)
Epoch: 188 | Batch_idx: 170 |  Loss: (0.0800) |  Loss2: (0.0000) | Acc: (97.00%) (21279/21888)
Epoch: 188 | Batch_idx: 180 |  Loss: (0.0803) |  Loss2: (0.0000) | Acc: (97.00%) (22521/23168)
Epoch: 188 | Batch_idx: 190 |  Loss: (0.0799) |  Loss2: (0.0000) | Acc: (97.00%) (23770/24448)
Epoch: 188 | Batch_idx: 200 |  Loss: (0.0799) |  Loss2: (0.0000) | Acc: (97.00%) (25016/25728)
Epoch: 188 | Batch_idx: 210 |  Loss: (0.0805) |  Loss2: (0.0000) | Acc: (97.00%) (26252/27008)
Epoch: 188 | Batch_idx: 220 |  Loss: (0.0800) |  Loss2: (0.0000) | Acc: (97.00%) (27502/28288)
Epoch: 188 | Batch_idx: 230 |  Loss: (0.0797) |  Loss2: (0.0000) | Acc: (97.00%) (28743/29568)
Epoch: 188 | Batch_idx: 240 |  Loss: (0.0801) |  Loss2: (0.0000) | Acc: (97.00%) (29983/30848)
Epoch: 188 | Batch_idx: 250 |  Loss: (0.0801) |  Loss2: (0.0000) | Acc: (97.00%) (31227/32128)
Epoch: 188 | Batch_idx: 260 |  Loss: (0.0806) |  Loss2: (0.0000) | Acc: (97.00%) (32469/33408)
Epoch: 188 | Batch_idx: 270 |  Loss: (0.0805) |  Loss2: (0.0000) | Acc: (97.00%) (33719/34688)
Epoch: 188 | Batch_idx: 280 |  Loss: (0.0807) |  Loss2: (0.0000) | Acc: (97.00%) (34955/35968)
Epoch: 188 | Batch_idx: 290 |  Loss: (0.0803) |  Loss2: (0.0000) | Acc: (97.00%) (36205/37248)
Epoch: 188 | Batch_idx: 300 |  Loss: (0.0805) |  Loss2: (0.0000) | Acc: (97.00%) (37444/38528)
Epoch: 188 | Batch_idx: 310 |  Loss: (0.0800) |  Loss2: (0.0000) | Acc: (97.00%) (38702/39808)
Epoch: 188 | Batch_idx: 320 |  Loss: (0.0796) |  Loss2: (0.0000) | Acc: (97.00%) (39951/41088)
Epoch: 188 | Batch_idx: 330 |  Loss: (0.0800) |  Loss2: (0.0000) | Acc: (97.00%) (41185/42368)
Epoch: 188 | Batch_idx: 340 |  Loss: (0.0799) |  Loss2: (0.0000) | Acc: (97.00%) (42431/43648)
Epoch: 188 | Batch_idx: 350 |  Loss: (0.0797) |  Loss2: (0.0000) | Acc: (97.00%) (43678/44928)
Epoch: 188 | Batch_idx: 360 |  Loss: (0.0796) |  Loss2: (0.0000) | Acc: (97.00%) (44927/46208)
Epoch: 188 | Batch_idx: 370 |  Loss: (0.0795) |  Loss2: (0.0000) | Acc: (97.00%) (46173/47488)
Epoch: 188 | Batch_idx: 380 |  Loss: (0.0798) |  Loss2: (0.0000) | Acc: (97.00%) (47410/48768)
Epoch: 188 | Batch_idx: 390 |  Loss: (0.0798) |  Loss2: (0.0000) | Acc: (97.00%) (48612/50000)
# TEST : Loss: (0.4397) | Acc: (88.00%) (8846/10000)
percent tensor([0.5704, 0.5801, 0.5729, 0.5718, 0.5780, 0.5853, 0.5821, 0.5682, 0.5693,
        0.5753, 0.5760, 0.5798, 0.5724, 0.5679, 0.5850, 0.5748],
       device='cuda:0') torch.Size([16])
percent tensor([0.5340, 0.5378, 0.5237, 0.5307, 0.5238, 0.5392, 0.5306, 0.5235, 0.5261,
        0.5337, 0.5375, 0.5274, 0.5335, 0.5335, 0.5371, 0.5362],
       device='cuda:0') torch.Size([16])
percent tensor([0.5817, 0.4458, 0.7095, 0.7095, 0.7231, 0.6648, 0.5566, 0.6857, 0.6254,
        0.5361, 0.4837, 0.6428, 0.4796, 0.5382, 0.5188, 0.6216],
       device='cuda:0') torch.Size([16])
percent tensor([0.6887, 0.7280, 0.6013, 0.6322, 0.6095, 0.5568, 0.6911, 0.6419, 0.6927,
        0.7241, 0.7329, 0.6727, 0.7085, 0.7298, 0.6677, 0.6657],
       device='cuda:0') torch.Size([16])
percent tensor([0.7218, 0.6154, 0.7593, 0.7480, 0.7735, 0.8290, 0.7046, 0.7193, 0.6843,
        0.6034, 0.5850, 0.6330, 0.5864, 0.6486, 0.7023, 0.7700],
       device='cuda:0') torch.Size([16])
percent tensor([0.6269, 0.7193, 0.7629, 0.7925, 0.7621, 0.8161, 0.7105, 0.5331, 0.7359,
        0.7224, 0.7632, 0.7695, 0.7445, 0.7539, 0.5425, 0.5657],
       device='cuda:0') torch.Size([16])
percent tensor([0.4224, 0.7159, 0.6673, 0.6591, 0.6227, 0.6695, 0.6255, 0.5822, 0.6399,
        0.6199, 0.7631, 0.6318, 0.6415, 0.6239, 0.5701, 0.3682],
       device='cuda:0') torch.Size([16])
percent tensor([0.9999, 0.9997, 0.9997, 0.9999, 0.9999, 0.9996, 0.9999, 0.9997, 0.9998,
        0.9999, 0.9999, 0.9999, 0.9996, 0.9995, 0.9997, 0.9997],
       device='cuda:0') torch.Size([16])
False Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=128, out_features=16, bias=False)
True Linear(in_features=16, out_features=2, bias=False)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=128, out_features=16, bias=False)
True Linear(in_features=16, out_features=2, bias=False)
False Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=256, out_features=32, bias=False)
True Linear(in_features=32, out_features=2, bias=False)
False Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=256, out_features=32, bias=False)
True Linear(in_features=32, out_features=2, bias=False)
False Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=512, out_features=64, bias=False)
True Linear(in_features=64, out_features=2, bias=False)
False Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=512, out_features=64, bias=False)
True Linear(in_features=64, out_features=2, bias=False)
False Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1024, out_features=128, bias=False)
True Linear(in_features=128, out_features=2, bias=False)
False Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1024, out_features=128, bias=False)
True Linear(in_features=128, out_features=2, bias=False)
False Linear(in_features=512, out_features=10, bias=True)
Epoch: 189 | Batch_idx: 0 |  Loss: (0.0668) |  Loss2: (0.0000) | Acc: (96.00%) (123/128)
Epoch: 189 | Batch_idx: 10 |  Loss: (0.0810) |  Loss2: (0.0000) | Acc: (96.00%) (1364/1408)
Epoch: 189 | Batch_idx: 20 |  Loss: (0.0814) |  Loss2: (0.0000) | Acc: (96.00%) (2605/2688)
Epoch: 189 | Batch_idx: 30 |  Loss: (0.0875) |  Loss2: (0.0000) | Acc: (96.00%) (3834/3968)
Epoch: 189 | Batch_idx: 40 |  Loss: (0.0874) |  Loss2: (0.0000) | Acc: (96.00%) (5072/5248)
Epoch: 189 | Batch_idx: 50 |  Loss: (0.0834) |  Loss2: (0.0000) | Acc: (96.00%) (6324/6528)
Epoch: 189 | Batch_idx: 60 |  Loss: (0.0843) |  Loss2: (0.0000) | Acc: (96.00%) (7566/7808)
Epoch: 189 | Batch_idx: 70 |  Loss: (0.0855) |  Loss2: (0.0000) | Acc: (96.00%) (8803/9088)
Epoch: 189 | Batch_idx: 80 |  Loss: (0.0858) |  Loss2: (0.0000) | Acc: (96.00%) (10042/10368)
Epoch: 189 | Batch_idx: 90 |  Loss: (0.0853) |  Loss2: (0.0000) | Acc: (96.00%) (11288/11648)
Epoch: 189 | Batch_idx: 100 |  Loss: (0.0853) |  Loss2: (0.0000) | Acc: (96.00%) (12528/12928)
Epoch: 189 | Batch_idx: 110 |  Loss: (0.0854) |  Loss2: (0.0000) | Acc: (96.00%) (13769/14208)
Epoch: 189 | Batch_idx: 120 |  Loss: (0.0850) |  Loss2: (0.0000) | Acc: (96.00%) (15013/15488)
Epoch: 189 | Batch_idx: 130 |  Loss: (0.0864) |  Loss2: (0.0000) | Acc: (96.00%) (16242/16768)
Epoch: 189 | Batch_idx: 140 |  Loss: (0.0875) |  Loss2: (0.0000) | Acc: (96.00%) (17472/18048)
Epoch: 189 | Batch_idx: 150 |  Loss: (0.0876) |  Loss2: (0.0000) | Acc: (96.00%) (18715/19328)
Epoch: 189 | Batch_idx: 160 |  Loss: (0.0882) |  Loss2: (0.0000) | Acc: (96.00%) (19951/20608)
Epoch: 189 | Batch_idx: 170 |  Loss: (0.0880) |  Loss2: (0.0000) | Acc: (96.00%) (21189/21888)
Epoch: 189 | Batch_idx: 180 |  Loss: (0.0876) |  Loss2: (0.0000) | Acc: (96.00%) (22432/23168)
Epoch: 189 | Batch_idx: 190 |  Loss: (0.0876) |  Loss2: (0.0000) | Acc: (96.00%) (23675/24448)
Epoch: 189 | Batch_idx: 200 |  Loss: (0.0882) |  Loss2: (0.0000) | Acc: (96.00%) (24904/25728)
Epoch: 189 | Batch_idx: 210 |  Loss: (0.0886) |  Loss2: (0.0000) | Acc: (96.00%) (26144/27008)
Epoch: 189 | Batch_idx: 220 |  Loss: (0.0884) |  Loss2: (0.0000) | Acc: (96.00%) (27385/28288)
Epoch: 189 | Batch_idx: 230 |  Loss: (0.0882) |  Loss2: (0.0000) | Acc: (96.00%) (28628/29568)
Epoch: 189 | Batch_idx: 240 |  Loss: (0.0880) |  Loss2: (0.0000) | Acc: (96.00%) (29863/30848)
Epoch: 189 | Batch_idx: 250 |  Loss: (0.0877) |  Loss2: (0.0000) | Acc: (96.00%) (31106/32128)
Epoch: 189 | Batch_idx: 260 |  Loss: (0.0880) |  Loss2: (0.0000) | Acc: (96.00%) (32353/33408)
Epoch: 189 | Batch_idx: 270 |  Loss: (0.0880) |  Loss2: (0.0000) | Acc: (96.00%) (33591/34688)
Epoch: 189 | Batch_idx: 280 |  Loss: (0.0875) |  Loss2: (0.0000) | Acc: (96.00%) (34837/35968)
Epoch: 189 | Batch_idx: 290 |  Loss: (0.0879) |  Loss2: (0.0000) | Acc: (96.00%) (36072/37248)
Epoch: 189 | Batch_idx: 300 |  Loss: (0.0875) |  Loss2: (0.0000) | Acc: (96.00%) (37313/38528)
Epoch: 189 | Batch_idx: 310 |  Loss: (0.0875) |  Loss2: (0.0000) | Acc: (96.00%) (38555/39808)
Epoch: 189 | Batch_idx: 320 |  Loss: (0.0870) |  Loss2: (0.0000) | Acc: (96.00%) (39800/41088)
Epoch: 189 | Batch_idx: 330 |  Loss: (0.0871) |  Loss2: (0.0000) | Acc: (96.00%) (41046/42368)
Epoch: 189 | Batch_idx: 340 |  Loss: (0.0871) |  Loss2: (0.0000) | Acc: (96.00%) (42297/43648)
Epoch: 189 | Batch_idx: 350 |  Loss: (0.0869) |  Loss2: (0.0000) | Acc: (96.00%) (43545/44928)
Epoch: 189 | Batch_idx: 360 |  Loss: (0.0875) |  Loss2: (0.0000) | Acc: (96.00%) (44777/46208)
Epoch: 189 | Batch_idx: 370 |  Loss: (0.0871) |  Loss2: (0.0000) | Acc: (96.00%) (46021/47488)
Epoch: 189 | Batch_idx: 380 |  Loss: (0.0872) |  Loss2: (0.0000) | Acc: (96.00%) (47264/48768)
Epoch: 189 | Batch_idx: 390 |  Loss: (0.0874) |  Loss2: (0.0000) | Acc: (96.00%) (48456/50000)
# TEST : Loss: (0.4148) | Acc: (88.00%) (8873/10000)
percent tensor([0.5623, 0.5706, 0.5656, 0.5641, 0.5700, 0.5762, 0.5731, 0.5598, 0.5611,
        0.5668, 0.5670, 0.5716, 0.5635, 0.5596, 0.5755, 0.5660],
       device='cuda:0') torch.Size([16])
percent tensor([0.5347, 0.5370, 0.5263, 0.5321, 0.5254, 0.5402, 0.5303, 0.5247, 0.5268,
        0.5336, 0.5377, 0.5283, 0.5334, 0.5328, 0.5372, 0.5368],
       device='cuda:0') torch.Size([16])
percent tensor([0.5925, 0.4458, 0.7228, 0.7246, 0.7325, 0.6740, 0.5604, 0.6996, 0.6299,
        0.5412, 0.4859, 0.6473, 0.4912, 0.5410, 0.5197, 0.6323],
       device='cuda:0') torch.Size([16])
percent tensor([0.6816, 0.7167, 0.6051, 0.6294, 0.6101, 0.5569, 0.6843, 0.6404, 0.6861,
        0.7142, 0.7213, 0.6672, 0.6963, 0.7245, 0.6585, 0.6562],
       device='cuda:0') torch.Size([16])
percent tensor([0.7346, 0.6480, 0.7542, 0.7484, 0.7670, 0.8281, 0.7140, 0.7126, 0.7015,
        0.6305, 0.6163, 0.6440, 0.6185, 0.6737, 0.7122, 0.7827],
       device='cuda:0') torch.Size([16])
percent tensor([0.6682, 0.7513, 0.7931, 0.8189, 0.8143, 0.8439, 0.7380, 0.5769, 0.7737,
        0.7532, 0.7883, 0.7957, 0.7737, 0.7840, 0.5944, 0.6324],
       device='cuda:0') torch.Size([16])
percent tensor([0.4071, 0.6957, 0.6801, 0.6594, 0.6489, 0.6647, 0.6296, 0.6016, 0.6212,
        0.5944, 0.7525, 0.6480, 0.5972, 0.5859, 0.5894, 0.3565],
       device='cuda:0') torch.Size([16])
percent tensor([0.9999, 0.9997, 0.9998, 0.9999, 0.9999, 0.9995, 0.9999, 0.9997, 0.9998,
        0.9999, 0.9998, 1.0000, 0.9997, 0.9996, 0.9997, 0.9997],
       device='cuda:0') torch.Size([16])
Epoch: 190 | Batch_idx: 0 |  Loss: (0.1382) |  Loss2: (0.0000) | Acc: (95.00%) (122/128)
Epoch: 190 | Batch_idx: 10 |  Loss: (0.0839) |  Loss2: (0.0000) | Acc: (96.00%) (1363/1408)
Epoch: 190 | Batch_idx: 20 |  Loss: (0.0938) |  Loss2: (0.0000) | Acc: (96.00%) (2596/2688)
Epoch: 190 | Batch_idx: 30 |  Loss: (0.0898) |  Loss2: (0.0000) | Acc: (96.00%) (3840/3968)
Epoch: 190 | Batch_idx: 40 |  Loss: (0.0881) |  Loss2: (0.0000) | Acc: (96.00%) (5086/5248)
Epoch: 190 | Batch_idx: 50 |  Loss: (0.0823) |  Loss2: (0.0000) | Acc: (97.00%) (6341/6528)
Epoch: 190 | Batch_idx: 60 |  Loss: (0.0827) |  Loss2: (0.0000) | Acc: (97.00%) (7588/7808)
Epoch: 190 | Batch_idx: 70 |  Loss: (0.0825) |  Loss2: (0.0000) | Acc: (97.00%) (8832/9088)
Epoch: 190 | Batch_idx: 80 |  Loss: (0.0825) |  Loss2: (0.0000) | Acc: (97.00%) (10076/10368)
Epoch: 190 | Batch_idx: 90 |  Loss: (0.0833) |  Loss2: (0.0000) | Acc: (97.00%) (11316/11648)
Epoch: 190 | Batch_idx: 100 |  Loss: (0.0818) |  Loss2: (0.0000) | Acc: (97.00%) (12564/12928)
Epoch: 190 | Batch_idx: 110 |  Loss: (0.0816) |  Loss2: (0.0000) | Acc: (97.00%) (13812/14208)
Epoch: 190 | Batch_idx: 120 |  Loss: (0.0809) |  Loss2: (0.0000) | Acc: (97.00%) (15059/15488)
Epoch: 190 | Batch_idx: 130 |  Loss: (0.0801) |  Loss2: (0.0000) | Acc: (97.00%) (16306/16768)
Epoch: 190 | Batch_idx: 140 |  Loss: (0.0798) |  Loss2: (0.0000) | Acc: (97.00%) (17558/18048)
Epoch: 190 | Batch_idx: 150 |  Loss: (0.0798) |  Loss2: (0.0000) | Acc: (97.00%) (18798/19328)
Epoch: 190 | Batch_idx: 160 |  Loss: (0.0802) |  Loss2: (0.0000) | Acc: (97.00%) (20045/20608)
Epoch: 190 | Batch_idx: 170 |  Loss: (0.0798) |  Loss2: (0.0000) | Acc: (97.00%) (21293/21888)
Epoch: 190 | Batch_idx: 180 |  Loss: (0.0791) |  Loss2: (0.0000) | Acc: (97.00%) (22541/23168)
Epoch: 190 | Batch_idx: 190 |  Loss: (0.0791) |  Loss2: (0.0000) | Acc: (97.00%) (23781/24448)
Epoch: 190 | Batch_idx: 200 |  Loss: (0.0795) |  Loss2: (0.0000) | Acc: (97.00%) (25026/25728)
Epoch: 190 | Batch_idx: 210 |  Loss: (0.0791) |  Loss2: (0.0000) | Acc: (97.00%) (26280/27008)
Epoch: 190 | Batch_idx: 220 |  Loss: (0.0790) |  Loss2: (0.0000) | Acc: (97.00%) (27526/28288)
Epoch: 190 | Batch_idx: 230 |  Loss: (0.0789) |  Loss2: (0.0000) | Acc: (97.00%) (28767/29568)
Epoch: 190 | Batch_idx: 240 |  Loss: (0.0785) |  Loss2: (0.0000) | Acc: (97.00%) (30023/30848)
Epoch: 190 | Batch_idx: 250 |  Loss: (0.0779) |  Loss2: (0.0000) | Acc: (97.00%) (31281/32128)
Epoch: 190 | Batch_idx: 260 |  Loss: (0.0779) |  Loss2: (0.0000) | Acc: (97.00%) (32534/33408)
Epoch: 190 | Batch_idx: 270 |  Loss: (0.0778) |  Loss2: (0.0000) | Acc: (97.00%) (33781/34688)
Epoch: 190 | Batch_idx: 280 |  Loss: (0.0776) |  Loss2: (0.0000) | Acc: (97.00%) (35028/35968)
Epoch: 190 | Batch_idx: 290 |  Loss: (0.0781) |  Loss2: (0.0000) | Acc: (97.00%) (36265/37248)
Epoch: 190 | Batch_idx: 300 |  Loss: (0.0783) |  Loss2: (0.0000) | Acc: (97.00%) (37510/38528)
Epoch: 190 | Batch_idx: 310 |  Loss: (0.0782) |  Loss2: (0.0000) | Acc: (97.00%) (38752/39808)
Epoch: 190 | Batch_idx: 320 |  Loss: (0.0784) |  Loss2: (0.0000) | Acc: (97.00%) (39998/41088)
Epoch: 190 | Batch_idx: 330 |  Loss: (0.0782) |  Loss2: (0.0000) | Acc: (97.00%) (41245/42368)
Epoch: 190 | Batch_idx: 340 |  Loss: (0.0778) |  Loss2: (0.0000) | Acc: (97.00%) (42497/43648)
Epoch: 190 | Batch_idx: 350 |  Loss: (0.0775) |  Loss2: (0.0000) | Acc: (97.00%) (43745/44928)
Epoch: 190 | Batch_idx: 360 |  Loss: (0.0773) |  Loss2: (0.0000) | Acc: (97.00%) (44996/46208)
Epoch: 190 | Batch_idx: 370 |  Loss: (0.0771) |  Loss2: (0.0000) | Acc: (97.00%) (46247/47488)
Epoch: 190 | Batch_idx: 380 |  Loss: (0.0767) |  Loss2: (0.0000) | Acc: (97.00%) (47501/48768)
Epoch: 190 | Batch_idx: 390 |  Loss: (0.0765) |  Loss2: (0.0000) | Acc: (97.00%) (48699/50000)
=> saving checkpoint 'drive/app/torch/save_Schedule/checkpoint_190.pth.tar'
# TEST : Loss: (0.4042) | Acc: (88.00%) (8887/10000)
percent tensor([0.5642, 0.5731, 0.5677, 0.5657, 0.5723, 0.5780, 0.5757, 0.5619, 0.5633,
        0.5692, 0.5693, 0.5742, 0.5656, 0.5619, 0.5776, 0.5680],
       device='cuda:0') torch.Size([16])
percent tensor([0.5332, 0.5353, 0.5249, 0.5307, 0.5236, 0.5387, 0.5284, 0.5234, 0.5254,
        0.5321, 0.5360, 0.5270, 0.5319, 0.5314, 0.5354, 0.5353],
       device='cuda:0') torch.Size([16])
percent tensor([0.5940, 0.4506, 0.7281, 0.7289, 0.7366, 0.6765, 0.5643, 0.7040, 0.6328,
        0.5459, 0.4887, 0.6527, 0.4960, 0.5454, 0.5217, 0.6353],
       device='cuda:0') torch.Size([16])
percent tensor([0.6818, 0.7130, 0.6080, 0.6336, 0.6129, 0.5616, 0.6828, 0.6422, 0.6842,
        0.7115, 0.7181, 0.6658, 0.6941, 0.7210, 0.6583, 0.6576],
       device='cuda:0') torch.Size([16])
percent tensor([0.7301, 0.6460, 0.7487, 0.7452, 0.7612, 0.8222, 0.7106, 0.7085, 0.7009,
        0.6292, 0.6174, 0.6430, 0.6132, 0.6787, 0.7089, 0.7748],
       device='cuda:0') torch.Size([16])
percent tensor([0.6617, 0.7496, 0.7872, 0.8156, 0.8109, 0.8408, 0.7360, 0.5723, 0.7739,
        0.7500, 0.7883, 0.7929, 0.7721, 0.7819, 0.5910, 0.6234],
       device='cuda:0') torch.Size([16])
percent tensor([0.4132, 0.6984, 0.6917, 0.6726, 0.6589, 0.6636, 0.6448, 0.6162, 0.6325,
        0.5950, 0.7591, 0.6647, 0.6073, 0.5885, 0.6002, 0.3564],
       device='cuda:0') torch.Size([16])
percent tensor([0.9999, 0.9997, 0.9998, 0.9999, 0.9999, 0.9995, 0.9999, 0.9996, 0.9998,
        0.9999, 0.9998, 1.0000, 0.9997, 0.9996, 0.9997, 0.9997],
       device='cuda:0') torch.Size([16])
Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 3, 3, 3]) tensor(185.6493, device='cuda:0')
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(821.7457, device='cuda:0')
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(833.2476, device='cuda:0')
Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([128, 64, 3, 3]) tensor(1508.7850, device='cuda:0')
Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([128, 64, 1, 1]) tensor(484.0294, device='cuda:0')
Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([128, 128, 3, 3]) tensor(2282.1006, device='cuda:0')
Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([256, 128, 3, 3]) tensor(4267.3691, device='cuda:0')
Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([256, 128, 1, 1]) tensor(1357.0405, device='cuda:0')
Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([256, 256, 3, 3]) tensor(6258.9561, device='cuda:0')
Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([512, 256, 3, 3]) tensor(11569.8545, device='cuda:0')
Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([512, 256, 1, 1]) tensor(3808.0027, device='cuda:0')
Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([512, 512, 3, 3]) tensor(16040.5352, device='cuda:0')
Epoch: 191 | Batch_idx: 0 |  Loss: (0.0669) |  Loss2: (0.0000) | Acc: (99.00%) (127/128)
Epoch: 191 | Batch_idx: 10 |  Loss: (0.0761) |  Loss2: (0.0000) | Acc: (97.00%) (1370/1408)
Epoch: 191 | Batch_idx: 20 |  Loss: (0.0762) |  Loss2: (0.0000) | Acc: (97.00%) (2615/2688)
Epoch: 191 | Batch_idx: 30 |  Loss: (0.0747) |  Loss2: (0.0000) | Acc: (97.00%) (3864/3968)
Epoch: 191 | Batch_idx: 40 |  Loss: (0.0762) |  Loss2: (0.0000) | Acc: (97.00%) (5106/5248)
Epoch: 191 | Batch_idx: 50 |  Loss: (0.0766) |  Loss2: (0.0000) | Acc: (97.00%) (6353/6528)
Epoch: 191 | Batch_idx: 60 |  Loss: (0.0768) |  Loss2: (0.0000) | Acc: (97.00%) (7597/7808)
Epoch: 191 | Batch_idx: 70 |  Loss: (0.0791) |  Loss2: (0.0000) | Acc: (97.00%) (8843/9088)
Epoch: 191 | Batch_idx: 80 |  Loss: (0.0799) |  Loss2: (0.0000) | Acc: (97.00%) (10086/10368)
Epoch: 191 | Batch_idx: 90 |  Loss: (0.0802) |  Loss2: (0.0000) | Acc: (97.00%) (11329/11648)
Epoch: 191 | Batch_idx: 100 |  Loss: (0.0788) |  Loss2: (0.0000) | Acc: (97.00%) (12574/12928)
Epoch: 191 | Batch_idx: 110 |  Loss: (0.0786) |  Loss2: (0.0000) | Acc: (97.00%) (13823/14208)
Epoch: 191 | Batch_idx: 120 |  Loss: (0.0788) |  Loss2: (0.0000) | Acc: (97.00%) (15071/15488)
Epoch: 191 | Batch_idx: 130 |  Loss: (0.0778) |  Loss2: (0.0000) | Acc: (97.00%) (16323/16768)
Epoch: 191 | Batch_idx: 140 |  Loss: (0.0794) |  Loss2: (0.0000) | Acc: (97.00%) (17564/18048)
Epoch: 191 | Batch_idx: 150 |  Loss: (0.0789) |  Loss2: (0.0000) | Acc: (97.00%) (18811/19328)
Epoch: 191 | Batch_idx: 160 |  Loss: (0.0787) |  Loss2: (0.0000) | Acc: (97.00%) (20059/20608)
Epoch: 191 | Batch_idx: 170 |  Loss: (0.0786) |  Loss2: (0.0000) | Acc: (97.00%) (21309/21888)
Epoch: 191 | Batch_idx: 180 |  Loss: (0.0786) |  Loss2: (0.0000) | Acc: (97.00%) (22553/23168)
Epoch: 191 | Batch_idx: 190 |  Loss: (0.0778) |  Loss2: (0.0000) | Acc: (97.00%) (23811/24448)
Epoch: 191 | Batch_idx: 200 |  Loss: (0.0774) |  Loss2: (0.0000) | Acc: (97.00%) (25060/25728)
Epoch: 191 | Batch_idx: 210 |  Loss: (0.0774) |  Loss2: (0.0000) | Acc: (97.00%) (26304/27008)
Epoch: 191 | Batch_idx: 220 |  Loss: (0.0772) |  Loss2: (0.0000) | Acc: (97.00%) (27551/28288)
Epoch: 191 | Batch_idx: 230 |  Loss: (0.0767) |  Loss2: (0.0000) | Acc: (97.00%) (28802/29568)
Epoch: 191 | Batch_idx: 240 |  Loss: (0.0765) |  Loss2: (0.0000) | Acc: (97.00%) (30053/30848)
Epoch: 191 | Batch_idx: 250 |  Loss: (0.0764) |  Loss2: (0.0000) | Acc: (97.00%) (31297/32128)
Epoch: 191 | Batch_idx: 260 |  Loss: (0.0757) |  Loss2: (0.0000) | Acc: (97.00%) (32556/33408)
Epoch: 191 | Batch_idx: 270 |  Loss: (0.0764) |  Loss2: (0.0000) | Acc: (97.00%) (33792/34688)
Epoch: 191 | Batch_idx: 280 |  Loss: (0.0763) |  Loss2: (0.0000) | Acc: (97.00%) (35039/35968)
Epoch: 191 | Batch_idx: 290 |  Loss: (0.0759) |  Loss2: (0.0000) | Acc: (97.00%) (36289/37248)
Epoch: 191 | Batch_idx: 300 |  Loss: (0.0756) |  Loss2: (0.0000) | Acc: (97.00%) (37541/38528)
Epoch: 191 | Batch_idx: 310 |  Loss: (0.0755) |  Loss2: (0.0000) | Acc: (97.00%) (38793/39808)
Epoch: 191 | Batch_idx: 320 |  Loss: (0.0753) |  Loss2: (0.0000) | Acc: (97.00%) (40043/41088)
Epoch: 191 | Batch_idx: 330 |  Loss: (0.0753) |  Loss2: (0.0000) | Acc: (97.00%) (41288/42368)
Epoch: 191 | Batch_idx: 340 |  Loss: (0.0751) |  Loss2: (0.0000) | Acc: (97.00%) (42538/43648)
Epoch: 191 | Batch_idx: 350 |  Loss: (0.0752) |  Loss2: (0.0000) | Acc: (97.00%) (43784/44928)
Epoch: 191 | Batch_idx: 360 |  Loss: (0.0750) |  Loss2: (0.0000) | Acc: (97.00%) (45033/46208)
Epoch: 191 | Batch_idx: 370 |  Loss: (0.0748) |  Loss2: (0.0000) | Acc: (97.00%) (46284/47488)
Epoch: 191 | Batch_idx: 380 |  Loss: (0.0752) |  Loss2: (0.0000) | Acc: (97.00%) (47528/48768)
Epoch: 191 | Batch_idx: 390 |  Loss: (0.0758) |  Loss2: (0.0000) | Acc: (97.00%) (48723/50000)
# TEST : Loss: (0.3967) | Acc: (89.00%) (8903/10000)
percent tensor([0.5627, 0.5717, 0.5664, 0.5643, 0.5708, 0.5762, 0.5742, 0.5605, 0.5618,
        0.5679, 0.5678, 0.5729, 0.5641, 0.5606, 0.5760, 0.5664],
       device='cuda:0') torch.Size([16])
percent tensor([0.5313, 0.5336, 0.5232, 0.5292, 0.5211, 0.5371, 0.5258, 0.5211, 0.5232,
        0.5305, 0.5340, 0.5255, 0.5303, 0.5296, 0.5333, 0.5339],
       device='cuda:0') torch.Size([16])
percent tensor([0.5878, 0.4480, 0.7238, 0.7225, 0.7327, 0.6724, 0.5604, 0.7004, 0.6266,
        0.5407, 0.4843, 0.6459, 0.4925, 0.5382, 0.5172, 0.6301],
       device='cuda:0') torch.Size([16])
percent tensor([0.6863, 0.7158, 0.6139, 0.6380, 0.6178, 0.5661, 0.6864, 0.6472, 0.6880,
        0.7154, 0.7203, 0.6709, 0.6985, 0.7230, 0.6619, 0.6616],
       device='cuda:0') torch.Size([16])
percent tensor([0.7379, 0.6512, 0.7578, 0.7570, 0.7689, 0.8283, 0.7163, 0.7178, 0.7109,
        0.6356, 0.6252, 0.6524, 0.6174, 0.6889, 0.7164, 0.7806],
       device='cuda:0') torch.Size([16])
percent tensor([0.6390, 0.7359, 0.7723, 0.8023, 0.7980, 0.8311, 0.7149, 0.5437, 0.7585,
        0.7331, 0.7786, 0.7782, 0.7603, 0.7680, 0.5646, 0.5959],
       device='cuda:0') torch.Size([16])
percent tensor([0.4032, 0.6936, 0.6820, 0.6676, 0.6513, 0.6540, 0.6369, 0.6081, 0.6203,
        0.5823, 0.7587, 0.6643, 0.6021, 0.5771, 0.5906, 0.3515],
       device='cuda:0') torch.Size([16])
percent tensor([0.9999, 0.9997, 0.9998, 1.0000, 0.9999, 0.9995, 0.9999, 0.9996, 0.9998,
        0.9999, 0.9999, 1.0000, 0.9997, 0.9996, 0.9997, 0.9997],
       device='cuda:0') torch.Size([16])
True Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=128, out_features=16, bias=False)
False Linear(in_features=16, out_features=2, bias=False)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=128, out_features=16, bias=False)
False Linear(in_features=16, out_features=2, bias=False)
True Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=256, out_features=32, bias=False)
False Linear(in_features=32, out_features=2, bias=False)
True Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=256, out_features=32, bias=False)
False Linear(in_features=32, out_features=2, bias=False)
True Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=512, out_features=64, bias=False)
False Linear(in_features=64, out_features=2, bias=False)
True Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=512, out_features=64, bias=False)
False Linear(in_features=64, out_features=2, bias=False)
True Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1024, out_features=128, bias=False)
False Linear(in_features=128, out_features=2, bias=False)
True Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1024, out_features=128, bias=False)
False Linear(in_features=128, out_features=2, bias=False)
True Linear(in_features=512, out_features=10, bias=True)
Epoch: 192 | Batch_idx: 0 |  Loss: (0.0677) |  Loss2: (0.0000) | Acc: (97.00%) (125/128)
Epoch: 192 | Batch_idx: 10 |  Loss: (0.0838) |  Loss2: (0.0000) | Acc: (96.00%) (1361/1408)
Epoch: 192 | Batch_idx: 20 |  Loss: (0.0714) |  Loss2: (0.0000) | Acc: (97.00%) (2621/2688)
Epoch: 192 | Batch_idx: 30 |  Loss: (0.0712) |  Loss2: (0.0000) | Acc: (97.00%) (3871/3968)
Epoch: 192 | Batch_idx: 40 |  Loss: (0.0733) |  Loss2: (0.0000) | Acc: (97.00%) (5115/5248)
Epoch: 192 | Batch_idx: 50 |  Loss: (0.0717) |  Loss2: (0.0000) | Acc: (97.00%) (6368/6528)
Epoch: 192 | Batch_idx: 60 |  Loss: (0.0732) |  Loss2: (0.0000) | Acc: (97.00%) (7615/7808)
Epoch: 192 | Batch_idx: 70 |  Loss: (0.0734) |  Loss2: (0.0000) | Acc: (97.00%) (8865/9088)
Epoch: 192 | Batch_idx: 80 |  Loss: (0.0741) |  Loss2: (0.0000) | Acc: (97.00%) (10105/10368)
Epoch: 192 | Batch_idx: 90 |  Loss: (0.0745) |  Loss2: (0.0000) | Acc: (97.00%) (11354/11648)
Epoch: 192 | Batch_idx: 100 |  Loss: (0.0746) |  Loss2: (0.0000) | Acc: (97.00%) (12601/12928)
Epoch: 192 | Batch_idx: 110 |  Loss: (0.0744) |  Loss2: (0.0000) | Acc: (97.00%) (13850/14208)
Epoch: 192 | Batch_idx: 120 |  Loss: (0.0750) |  Loss2: (0.0000) | Acc: (97.00%) (15093/15488)
Epoch: 192 | Batch_idx: 130 |  Loss: (0.0740) |  Loss2: (0.0000) | Acc: (97.00%) (16347/16768)
Epoch: 192 | Batch_idx: 140 |  Loss: (0.0739) |  Loss2: (0.0000) | Acc: (97.00%) (17594/18048)
Epoch: 192 | Batch_idx: 150 |  Loss: (0.0740) |  Loss2: (0.0000) | Acc: (97.00%) (18847/19328)
Epoch: 192 | Batch_idx: 160 |  Loss: (0.0736) |  Loss2: (0.0000) | Acc: (97.00%) (20096/20608)
Epoch: 192 | Batch_idx: 170 |  Loss: (0.0734) |  Loss2: (0.0000) | Acc: (97.00%) (21350/21888)
Epoch: 192 | Batch_idx: 180 |  Loss: (0.0737) |  Loss2: (0.0000) | Acc: (97.00%) (22600/23168)
Epoch: 192 | Batch_idx: 190 |  Loss: (0.0738) |  Loss2: (0.0000) | Acc: (97.00%) (23847/24448)
Epoch: 192 | Batch_idx: 200 |  Loss: (0.0735) |  Loss2: (0.0000) | Acc: (97.00%) (25100/25728)
Epoch: 192 | Batch_idx: 210 |  Loss: (0.0736) |  Loss2: (0.0000) | Acc: (97.00%) (26352/27008)
Epoch: 192 | Batch_idx: 220 |  Loss: (0.0738) |  Loss2: (0.0000) | Acc: (97.00%) (27601/28288)
Epoch: 192 | Batch_idx: 230 |  Loss: (0.0739) |  Loss2: (0.0000) | Acc: (97.00%) (28854/29568)
Epoch: 192 | Batch_idx: 240 |  Loss: (0.0738) |  Loss2: (0.0000) | Acc: (97.00%) (30107/30848)
Epoch: 192 | Batch_idx: 250 |  Loss: (0.0745) |  Loss2: (0.0000) | Acc: (97.00%) (31339/32128)
Epoch: 192 | Batch_idx: 260 |  Loss: (0.0756) |  Loss2: (0.0000) | Acc: (97.00%) (32572/33408)
Epoch: 192 | Batch_idx: 270 |  Loss: (0.0756) |  Loss2: (0.0000) | Acc: (97.00%) (33820/34688)
Epoch: 192 | Batch_idx: 280 |  Loss: (0.0760) |  Loss2: (0.0000) | Acc: (97.00%) (35063/35968)
Epoch: 192 | Batch_idx: 290 |  Loss: (0.0759) |  Loss2: (0.0000) | Acc: (97.00%) (36312/37248)
Epoch: 192 | Batch_idx: 300 |  Loss: (0.0759) |  Loss2: (0.0000) | Acc: (97.00%) (37561/38528)
Epoch: 192 | Batch_idx: 310 |  Loss: (0.0760) |  Loss2: (0.0000) | Acc: (97.00%) (38807/39808)
Epoch: 192 | Batch_idx: 320 |  Loss: (0.0763) |  Loss2: (0.0000) | Acc: (97.00%) (40047/41088)
Epoch: 192 | Batch_idx: 330 |  Loss: (0.0766) |  Loss2: (0.0000) | Acc: (97.00%) (41285/42368)
Epoch: 192 | Batch_idx: 340 |  Loss: (0.0773) |  Loss2: (0.0000) | Acc: (97.00%) (42519/43648)
Epoch: 192 | Batch_idx: 350 |  Loss: (0.0778) |  Loss2: (0.0000) | Acc: (97.00%) (43763/44928)
Epoch: 192 | Batch_idx: 360 |  Loss: (0.0787) |  Loss2: (0.0000) | Acc: (97.00%) (44990/46208)
Epoch: 192 | Batch_idx: 370 |  Loss: (0.0785) |  Loss2: (0.0000) | Acc: (97.00%) (46239/47488)
Epoch: 192 | Batch_idx: 380 |  Loss: (0.0788) |  Loss2: (0.0000) | Acc: (97.00%) (47475/48768)
Epoch: 192 | Batch_idx: 390 |  Loss: (0.0788) |  Loss2: (0.0000) | Acc: (97.00%) (48673/50000)
# TEST : Loss: (0.4413) | Acc: (88.00%) (8811/10000)
percent tensor([0.5638, 0.5734, 0.5685, 0.5659, 0.5715, 0.5769, 0.5744, 0.5619, 0.5625,
        0.5689, 0.5686, 0.5741, 0.5653, 0.5617, 0.5771, 0.5676],
       device='cuda:0') torch.Size([16])
percent tensor([0.5307, 0.5336, 0.5212, 0.5285, 0.5196, 0.5363, 0.5258, 0.5206, 0.5231,
        0.5301, 0.5336, 0.5238, 0.5300, 0.5289, 0.5327, 0.5330],
       device='cuda:0') torch.Size([16])
percent tensor([0.5824, 0.4515, 0.7213, 0.7169, 0.7346, 0.6774, 0.5581, 0.6930, 0.6293,
        0.5392, 0.4773, 0.6514, 0.4882, 0.5359, 0.5230, 0.6301],
       device='cuda:0') torch.Size([16])
percent tensor([0.6892, 0.7186, 0.6091, 0.6397, 0.6238, 0.5586, 0.6930, 0.6421, 0.6952,
        0.7180, 0.7278, 0.6732, 0.7024, 0.7296, 0.6643, 0.6678],
       device='cuda:0') torch.Size([16])
percent tensor([0.7288, 0.6372, 0.7606, 0.7564, 0.7672, 0.8302, 0.7185, 0.7287, 0.7041,
        0.6199, 0.6034, 0.6323, 0.6040, 0.6974, 0.7129, 0.7719],
       device='cuda:0') torch.Size([16])
percent tensor([0.6094, 0.7208, 0.7570, 0.8037, 0.7532, 0.8066, 0.6992, 0.5666, 0.7550,
        0.7374, 0.7851, 0.7778, 0.7483, 0.7593, 0.5860, 0.5359],
       device='cuda:0') torch.Size([16])
percent tensor([0.3726, 0.6797, 0.6564, 0.6568, 0.5938, 0.6343, 0.5807, 0.5724, 0.6245,
        0.5988, 0.7309, 0.6717, 0.5720, 0.5886, 0.5920, 0.3554],
       device='cuda:0') torch.Size([16])
percent tensor([0.9998, 0.9999, 0.9997, 0.9999, 1.0000, 0.9995, 0.9999, 0.9995, 0.9998,
        0.9999, 0.9998, 1.0000, 0.9997, 0.9996, 0.9998, 0.9995],
       device='cuda:0') torch.Size([16])
Epoch: 193 | Batch_idx: 0 |  Loss: (0.0974) |  Loss2: (0.0000) | Acc: (95.00%) (122/128)
Epoch: 193 | Batch_idx: 10 |  Loss: (0.0751) |  Loss2: (0.0000) | Acc: (97.00%) (1373/1408)
Epoch: 193 | Batch_idx: 20 |  Loss: (0.0727) |  Loss2: (0.0000) | Acc: (97.00%) (2622/2688)
Epoch: 193 | Batch_idx: 30 |  Loss: (0.0749) |  Loss2: (0.0000) | Acc: (97.00%) (3870/3968)
Epoch: 193 | Batch_idx: 40 |  Loss: (0.0738) |  Loss2: (0.0000) | Acc: (97.00%) (5121/5248)
Epoch: 193 | Batch_idx: 50 |  Loss: (0.0709) |  Loss2: (0.0000) | Acc: (97.00%) (6377/6528)
Epoch: 193 | Batch_idx: 60 |  Loss: (0.0722) |  Loss2: (0.0000) | Acc: (97.00%) (7625/7808)
Epoch: 193 | Batch_idx: 70 |  Loss: (0.0706) |  Loss2: (0.0000) | Acc: (97.00%) (8879/9088)
Epoch: 193 | Batch_idx: 80 |  Loss: (0.0707) |  Loss2: (0.0000) | Acc: (97.00%) (10131/10368)
Epoch: 193 | Batch_idx: 90 |  Loss: (0.0700) |  Loss2: (0.0000) | Acc: (97.00%) (11385/11648)
Epoch: 193 | Batch_idx: 100 |  Loss: (0.0703) |  Loss2: (0.0000) | Acc: (97.00%) (12633/12928)
Epoch: 193 | Batch_idx: 110 |  Loss: (0.0698) |  Loss2: (0.0000) | Acc: (97.00%) (13881/14208)
Epoch: 193 | Batch_idx: 120 |  Loss: (0.0700) |  Loss2: (0.0000) | Acc: (97.00%) (15128/15488)
Epoch: 193 | Batch_idx: 130 |  Loss: (0.0702) |  Loss2: (0.0000) | Acc: (97.00%) (16380/16768)
Epoch: 193 | Batch_idx: 140 |  Loss: (0.0697) |  Loss2: (0.0000) | Acc: (97.00%) (17632/18048)
Epoch: 193 | Batch_idx: 150 |  Loss: (0.0701) |  Loss2: (0.0000) | Acc: (97.00%) (18876/19328)
Epoch: 193 | Batch_idx: 160 |  Loss: (0.0712) |  Loss2: (0.0000) | Acc: (97.00%) (20122/20608)
Epoch: 193 | Batch_idx: 170 |  Loss: (0.0719) |  Loss2: (0.0000) | Acc: (97.00%) (21362/21888)
Epoch: 193 | Batch_idx: 180 |  Loss: (0.0723) |  Loss2: (0.0000) | Acc: (97.00%) (22613/23168)
Epoch: 193 | Batch_idx: 190 |  Loss: (0.0732) |  Loss2: (0.0000) | Acc: (97.00%) (23849/24448)
Epoch: 193 | Batch_idx: 200 |  Loss: (0.0730) |  Loss2: (0.0000) | Acc: (97.00%) (25097/25728)
Epoch: 193 | Batch_idx: 210 |  Loss: (0.0740) |  Loss2: (0.0000) | Acc: (97.00%) (26325/27008)
Epoch: 193 | Batch_idx: 220 |  Loss: (0.0741) |  Loss2: (0.0000) | Acc: (97.00%) (27575/28288)
Epoch: 193 | Batch_idx: 230 |  Loss: (0.0751) |  Loss2: (0.0000) | Acc: (97.00%) (28811/29568)
Epoch: 193 | Batch_idx: 240 |  Loss: (0.0749) |  Loss2: (0.0000) | Acc: (97.00%) (30063/30848)
Epoch: 193 | Batch_idx: 250 |  Loss: (0.0747) |  Loss2: (0.0000) | Acc: (97.00%) (31311/32128)
Epoch: 193 | Batch_idx: 260 |  Loss: (0.0748) |  Loss2: (0.0000) | Acc: (97.00%) (32551/33408)
Epoch: 193 | Batch_idx: 270 |  Loss: (0.0747) |  Loss2: (0.0000) | Acc: (97.00%) (33801/34688)
Epoch: 193 | Batch_idx: 280 |  Loss: (0.0744) |  Loss2: (0.0000) | Acc: (97.00%) (35056/35968)
Epoch: 193 | Batch_idx: 290 |  Loss: (0.0744) |  Loss2: (0.0000) | Acc: (97.00%) (36304/37248)
Epoch: 193 | Batch_idx: 300 |  Loss: (0.0746) |  Loss2: (0.0000) | Acc: (97.00%) (37549/38528)
Epoch: 193 | Batch_idx: 310 |  Loss: (0.0747) |  Loss2: (0.0000) | Acc: (97.00%) (38796/39808)
Epoch: 193 | Batch_idx: 320 |  Loss: (0.0748) |  Loss2: (0.0000) | Acc: (97.00%) (40040/41088)
Epoch: 193 | Batch_idx: 330 |  Loss: (0.0749) |  Loss2: (0.0000) | Acc: (97.00%) (41291/42368)
Epoch: 193 | Batch_idx: 340 |  Loss: (0.0751) |  Loss2: (0.0000) | Acc: (97.00%) (42534/43648)
Epoch: 193 | Batch_idx: 350 |  Loss: (0.0749) |  Loss2: (0.0000) | Acc: (97.00%) (43788/44928)
Epoch: 193 | Batch_idx: 360 |  Loss: (0.0751) |  Loss2: (0.0000) | Acc: (97.00%) (45033/46208)
Epoch: 193 | Batch_idx: 370 |  Loss: (0.0752) |  Loss2: (0.0000) | Acc: (97.00%) (46281/47488)
Epoch: 193 | Batch_idx: 380 |  Loss: (0.0753) |  Loss2: (0.0000) | Acc: (97.00%) (47526/48768)
Epoch: 193 | Batch_idx: 390 |  Loss: (0.0754) |  Loss2: (0.0000) | Acc: (97.00%) (48719/50000)
# TEST : Loss: (0.4392) | Acc: (88.00%) (8825/10000)
percent tensor([0.5633, 0.5732, 0.5674, 0.5642, 0.5705, 0.5762, 0.5740, 0.5616, 0.5624,
        0.5691, 0.5683, 0.5734, 0.5650, 0.5616, 0.5764, 0.5671],
       device='cuda:0') torch.Size([16])
percent tensor([0.5306, 0.5345, 0.5195, 0.5295, 0.5182, 0.5364, 0.5265, 0.5204, 0.5223,
        0.5303, 0.5339, 0.5235, 0.5304, 0.5316, 0.5333, 0.5343],
       device='cuda:0') torch.Size([16])
percent tensor([0.6015, 0.4537, 0.7360, 0.7357, 0.7483, 0.6905, 0.5693, 0.6946, 0.6417,
        0.5493, 0.4905, 0.6653, 0.4989, 0.5356, 0.5332, 0.6434],
       device='cuda:0') torch.Size([16])
percent tensor([0.6844, 0.7157, 0.6123, 0.6291, 0.6155, 0.5582, 0.6911, 0.6430, 0.6906,
        0.7131, 0.7261, 0.6731, 0.7000, 0.7254, 0.6629, 0.6609],
       device='cuda:0') torch.Size([16])
percent tensor([0.7420, 0.6588, 0.7682, 0.7529, 0.7731, 0.8271, 0.7293, 0.7327, 0.7174,
        0.6410, 0.6189, 0.6512, 0.6233, 0.6910, 0.7214, 0.7819],
       device='cuda:0') torch.Size([16])
percent tensor([0.5998, 0.7450, 0.7310, 0.7976, 0.7386, 0.8053, 0.7282, 0.5435, 0.7537,
        0.7294, 0.8013, 0.7549, 0.7439, 0.7937, 0.5628, 0.5308],
       device='cuda:0') torch.Size([16])
percent tensor([0.3618, 0.6755, 0.6210, 0.6576, 0.5945, 0.6387, 0.5711, 0.5780, 0.5932,
        0.5533, 0.7244, 0.6157, 0.5406, 0.5843, 0.5713, 0.3523],
       device='cuda:0') torch.Size([16])
percent tensor([0.9998, 0.9997, 0.9997, 0.9999, 0.9999, 0.9993, 0.9999, 0.9996, 0.9999,
        0.9999, 0.9999, 0.9998, 0.9997, 0.9997, 0.9998, 0.9996],
       device='cuda:0') torch.Size([16])
Epoch: 194 | Batch_idx: 0 |  Loss: (0.0505) |  Loss2: (0.0000) | Acc: (98.00%) (126/128)
Epoch: 194 | Batch_idx: 10 |  Loss: (0.0667) |  Loss2: (0.0000) | Acc: (97.00%) (1378/1408)
Epoch: 194 | Batch_idx: 20 |  Loss: (0.0707) |  Loss2: (0.0000) | Acc: (97.00%) (2628/2688)
Epoch: 194 | Batch_idx: 30 |  Loss: (0.0747) |  Loss2: (0.0000) | Acc: (97.00%) (3875/3968)
Epoch: 194 | Batch_idx: 40 |  Loss: (0.0739) |  Loss2: (0.0000) | Acc: (97.00%) (5124/5248)
Epoch: 194 | Batch_idx: 50 |  Loss: (0.0695) |  Loss2: (0.0000) | Acc: (97.00%) (6382/6528)
Epoch: 194 | Batch_idx: 60 |  Loss: (0.0715) |  Loss2: (0.0000) | Acc: (97.00%) (7625/7808)
Epoch: 194 | Batch_idx: 70 |  Loss: (0.0705) |  Loss2: (0.0000) | Acc: (97.00%) (8877/9088)
Epoch: 194 | Batch_idx: 80 |  Loss: (0.0702) |  Loss2: (0.0000) | Acc: (97.00%) (10130/10368)
Epoch: 194 | Batch_idx: 90 |  Loss: (0.0704) |  Loss2: (0.0000) | Acc: (97.00%) (11382/11648)
Epoch: 194 | Batch_idx: 100 |  Loss: (0.0703) |  Loss2: (0.0000) | Acc: (97.00%) (12632/12928)
Epoch: 194 | Batch_idx: 110 |  Loss: (0.0709) |  Loss2: (0.0000) | Acc: (97.00%) (13881/14208)
Epoch: 194 | Batch_idx: 120 |  Loss: (0.0714) |  Loss2: (0.0000) | Acc: (97.00%) (15126/15488)
Epoch: 194 | Batch_idx: 130 |  Loss: (0.0708) |  Loss2: (0.0000) | Acc: (97.00%) (16378/16768)
Epoch: 194 | Batch_idx: 140 |  Loss: (0.0710) |  Loss2: (0.0000) | Acc: (97.00%) (17623/18048)
Epoch: 194 | Batch_idx: 150 |  Loss: (0.0709) |  Loss2: (0.0000) | Acc: (97.00%) (18874/19328)
Epoch: 194 | Batch_idx: 160 |  Loss: (0.0708) |  Loss2: (0.0000) | Acc: (97.00%) (20121/20608)
Epoch: 194 | Batch_idx: 170 |  Loss: (0.0708) |  Loss2: (0.0000) | Acc: (97.00%) (21370/21888)
Epoch: 194 | Batch_idx: 180 |  Loss: (0.0719) |  Loss2: (0.0000) | Acc: (97.00%) (22607/23168)
Epoch: 194 | Batch_idx: 190 |  Loss: (0.0713) |  Loss2: (0.0000) | Acc: (97.00%) (23869/24448)
Epoch: 194 | Batch_idx: 200 |  Loss: (0.0716) |  Loss2: (0.0000) | Acc: (97.00%) (25119/25728)
Epoch: 194 | Batch_idx: 210 |  Loss: (0.0715) |  Loss2: (0.0000) | Acc: (97.00%) (26369/27008)
Epoch: 194 | Batch_idx: 220 |  Loss: (0.0720) |  Loss2: (0.0000) | Acc: (97.00%) (27616/28288)
Epoch: 194 | Batch_idx: 230 |  Loss: (0.0717) |  Loss2: (0.0000) | Acc: (97.00%) (28868/29568)
Epoch: 194 | Batch_idx: 240 |  Loss: (0.0712) |  Loss2: (0.0000) | Acc: (97.00%) (30124/30848)
Epoch: 194 | Batch_idx: 250 |  Loss: (0.0708) |  Loss2: (0.0000) | Acc: (97.00%) (31377/32128)
Epoch: 194 | Batch_idx: 260 |  Loss: (0.0708) |  Loss2: (0.0000) | Acc: (97.00%) (32627/33408)
Epoch: 194 | Batch_idx: 270 |  Loss: (0.0707) |  Loss2: (0.0000) | Acc: (97.00%) (33880/34688)
Epoch: 194 | Batch_idx: 280 |  Loss: (0.0714) |  Loss2: (0.0000) | Acc: (97.00%) (35128/35968)
Epoch: 194 | Batch_idx: 290 |  Loss: (0.0715) |  Loss2: (0.0000) | Acc: (97.00%) (36378/37248)
Epoch: 194 | Batch_idx: 300 |  Loss: (0.0715) |  Loss2: (0.0000) | Acc: (97.00%) (37623/38528)
Epoch: 194 | Batch_idx: 310 |  Loss: (0.0722) |  Loss2: (0.0000) | Acc: (97.00%) (38859/39808)
Epoch: 194 | Batch_idx: 320 |  Loss: (0.0721) |  Loss2: (0.0000) | Acc: (97.00%) (40110/41088)
Epoch: 194 | Batch_idx: 330 |  Loss: (0.0720) |  Loss2: (0.0000) | Acc: (97.00%) (41358/42368)
Epoch: 194 | Batch_idx: 340 |  Loss: (0.0721) |  Loss2: (0.0000) | Acc: (97.00%) (42600/43648)
Epoch: 194 | Batch_idx: 350 |  Loss: (0.0726) |  Loss2: (0.0000) | Acc: (97.00%) (43844/44928)
Epoch: 194 | Batch_idx: 360 |  Loss: (0.0725) |  Loss2: (0.0000) | Acc: (97.00%) (45101/46208)
Epoch: 194 | Batch_idx: 370 |  Loss: (0.0728) |  Loss2: (0.0000) | Acc: (97.00%) (46343/47488)
Epoch: 194 | Batch_idx: 380 |  Loss: (0.0729) |  Loss2: (0.0000) | Acc: (97.00%) (47584/48768)
Epoch: 194 | Batch_idx: 390 |  Loss: (0.0729) |  Loss2: (0.0000) | Acc: (97.00%) (48791/50000)
# TEST : Loss: (0.4432) | Acc: (88.00%) (8836/10000)
percent tensor([0.5627, 0.5733, 0.5658, 0.5644, 0.5693, 0.5759, 0.5739, 0.5613, 0.5614,
        0.5686, 0.5683, 0.5721, 0.5645, 0.5620, 0.5763, 0.5670],
       device='cuda:0') torch.Size([16])
percent tensor([0.5312, 0.5347, 0.5204, 0.5287, 0.5186, 0.5374, 0.5267, 0.5209, 0.5231,
        0.5303, 0.5343, 0.5239, 0.5308, 0.5313, 0.5336, 0.5342],
       device='cuda:0') torch.Size([16])
percent tensor([0.5897, 0.4425, 0.7235, 0.7192, 0.7409, 0.6826, 0.5543, 0.6854, 0.6385,
        0.5315, 0.4770, 0.6443, 0.4842, 0.5253, 0.5162, 0.6287],
       device='cuda:0') torch.Size([16])
percent tensor([0.6841, 0.7100, 0.6108, 0.6347, 0.6197, 0.5609, 0.6878, 0.6395, 0.6897,
        0.7106, 0.7260, 0.6708, 0.6999, 0.7250, 0.6600, 0.6572],
       device='cuda:0') torch.Size([16])
percent tensor([0.7350, 0.6585, 0.7508, 0.7514, 0.7642, 0.8216, 0.7267, 0.7224, 0.7057,
        0.6320, 0.6192, 0.6376, 0.6078, 0.6993, 0.7204, 0.7779],
       device='cuda:0') torch.Size([16])
percent tensor([0.6384, 0.7734, 0.7635, 0.8175, 0.7648, 0.8292, 0.7463, 0.5978, 0.7691,
        0.7297, 0.7899, 0.7636, 0.7695, 0.7932, 0.6143, 0.5813],
       device='cuda:0') torch.Size([16])
percent tensor([0.3898, 0.7265, 0.6807, 0.7013, 0.6077, 0.6664, 0.6378, 0.6176, 0.6610,
        0.6048, 0.7413, 0.6679, 0.6603, 0.6414, 0.6049, 0.3683],
       device='cuda:0') torch.Size([16])
percent tensor([0.9998, 0.9998, 0.9998, 0.9999, 1.0000, 0.9996, 0.9999, 0.9997, 0.9999,
        0.9999, 0.9998, 0.9999, 0.9998, 0.9996, 0.9998, 0.9996],
       device='cuda:0') torch.Size([16])
False Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=128, out_features=16, bias=False)
True Linear(in_features=16, out_features=2, bias=False)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=128, out_features=16, bias=False)
True Linear(in_features=16, out_features=2, bias=False)
False Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=256, out_features=32, bias=False)
True Linear(in_features=32, out_features=2, bias=False)
False Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=256, out_features=32, bias=False)
True Linear(in_features=32, out_features=2, bias=False)
False Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=512, out_features=64, bias=False)
True Linear(in_features=64, out_features=2, bias=False)
False Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=512, out_features=64, bias=False)
True Linear(in_features=64, out_features=2, bias=False)
False Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1024, out_features=128, bias=False)
True Linear(in_features=128, out_features=2, bias=False)
False Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1024, out_features=128, bias=False)
True Linear(in_features=128, out_features=2, bias=False)
False Linear(in_features=512, out_features=10, bias=True)
Epoch: 195 | Batch_idx: 0 |  Loss: (0.0723) |  Loss2: (0.0000) | Acc: (97.00%) (125/128)
Epoch: 195 | Batch_idx: 10 |  Loss: (0.0743) |  Loss2: (0.0000) | Acc: (97.00%) (1372/1408)
Epoch: 195 | Batch_idx: 20 |  Loss: (0.0914) |  Loss2: (0.0000) | Acc: (96.00%) (2600/2688)
Epoch: 195 | Batch_idx: 30 |  Loss: (0.0946) |  Loss2: (0.0000) | Acc: (96.00%) (3830/3968)
Epoch: 195 | Batch_idx: 40 |  Loss: (0.1002) |  Loss2: (0.0000) | Acc: (96.00%) (5056/5248)
Epoch: 195 | Batch_idx: 50 |  Loss: (0.1015) |  Loss2: (0.0000) | Acc: (96.00%) (6289/6528)
Epoch: 195 | Batch_idx: 60 |  Loss: (0.0997) |  Loss2: (0.0000) | Acc: (96.00%) (7528/7808)
Epoch: 195 | Batch_idx: 70 |  Loss: (0.0995) |  Loss2: (0.0000) | Acc: (96.00%) (8763/9088)
Epoch: 195 | Batch_idx: 80 |  Loss: (0.0979) |  Loss2: (0.0000) | Acc: (96.00%) (10005/10368)
Epoch: 195 | Batch_idx: 90 |  Loss: (0.0954) |  Loss2: (0.0000) | Acc: (96.00%) (11248/11648)
Epoch: 195 | Batch_idx: 100 |  Loss: (0.0946) |  Loss2: (0.0000) | Acc: (96.00%) (12492/12928)
Epoch: 195 | Batch_idx: 110 |  Loss: (0.0934) |  Loss2: (0.0000) | Acc: (96.00%) (13732/14208)
Epoch: 195 | Batch_idx: 120 |  Loss: (0.0933) |  Loss2: (0.0000) | Acc: (96.00%) (14969/15488)
Epoch: 195 | Batch_idx: 130 |  Loss: (0.0930) |  Loss2: (0.0000) | Acc: (96.00%) (16214/16768)
Epoch: 195 | Batch_idx: 140 |  Loss: (0.0928) |  Loss2: (0.0000) | Acc: (96.00%) (17449/18048)
Epoch: 195 | Batch_idx: 150 |  Loss: (0.0925) |  Loss2: (0.0000) | Acc: (96.00%) (18687/19328)
Epoch: 195 | Batch_idx: 160 |  Loss: (0.0928) |  Loss2: (0.0000) | Acc: (96.00%) (19917/20608)
Epoch: 195 | Batch_idx: 170 |  Loss: (0.0927) |  Loss2: (0.0000) | Acc: (96.00%) (21163/21888)
Epoch: 195 | Batch_idx: 180 |  Loss: (0.0916) |  Loss2: (0.0000) | Acc: (96.00%) (22413/23168)
Epoch: 195 | Batch_idx: 190 |  Loss: (0.0909) |  Loss2: (0.0000) | Acc: (96.00%) (23661/24448)
Epoch: 195 | Batch_idx: 200 |  Loss: (0.0917) |  Loss2: (0.0000) | Acc: (96.00%) (24897/25728)
Epoch: 195 | Batch_idx: 210 |  Loss: (0.0913) |  Loss2: (0.0000) | Acc: (96.00%) (26138/27008)
Epoch: 195 | Batch_idx: 220 |  Loss: (0.0908) |  Loss2: (0.0000) | Acc: (96.00%) (27379/28288)
Epoch: 195 | Batch_idx: 230 |  Loss: (0.0906) |  Loss2: (0.0000) | Acc: (96.00%) (28625/29568)
Epoch: 195 | Batch_idx: 240 |  Loss: (0.0910) |  Loss2: (0.0000) | Acc: (96.00%) (29861/30848)
Epoch: 195 | Batch_idx: 250 |  Loss: (0.0918) |  Loss2: (0.0000) | Acc: (96.00%) (31089/32128)
Epoch: 195 | Batch_idx: 260 |  Loss: (0.0913) |  Loss2: (0.0000) | Acc: (96.00%) (32334/33408)
Epoch: 195 | Batch_idx: 270 |  Loss: (0.0914) |  Loss2: (0.0000) | Acc: (96.00%) (33572/34688)
Epoch: 195 | Batch_idx: 280 |  Loss: (0.0914) |  Loss2: (0.0000) | Acc: (96.00%) (34808/35968)
Epoch: 195 | Batch_idx: 290 |  Loss: (0.0910) |  Loss2: (0.0000) | Acc: (96.00%) (36054/37248)
Epoch: 195 | Batch_idx: 300 |  Loss: (0.0907) |  Loss2: (0.0000) | Acc: (96.00%) (37298/38528)
Epoch: 195 | Batch_idx: 310 |  Loss: (0.0901) |  Loss2: (0.0000) | Acc: (96.00%) (38548/39808)
Epoch: 195 | Batch_idx: 320 |  Loss: (0.0898) |  Loss2: (0.0000) | Acc: (96.00%) (39791/41088)
Epoch: 195 | Batch_idx: 330 |  Loss: (0.0896) |  Loss2: (0.0000) | Acc: (96.00%) (41029/42368)
Epoch: 195 | Batch_idx: 340 |  Loss: (0.0894) |  Loss2: (0.0000) | Acc: (96.00%) (42278/43648)
Epoch: 195 | Batch_idx: 350 |  Loss: (0.0889) |  Loss2: (0.0000) | Acc: (96.00%) (43529/44928)
Epoch: 195 | Batch_idx: 360 |  Loss: (0.0887) |  Loss2: (0.0000) | Acc: (96.00%) (44778/46208)
Epoch: 195 | Batch_idx: 370 |  Loss: (0.0878) |  Loss2: (0.0000) | Acc: (96.00%) (46036/47488)
Epoch: 195 | Batch_idx: 380 |  Loss: (0.0876) |  Loss2: (0.0000) | Acc: (96.00%) (47283/48768)
Epoch: 195 | Batch_idx: 390 |  Loss: (0.0873) |  Loss2: (0.0000) | Acc: (96.00%) (48480/50000)
=> saving checkpoint 'drive/app/torch/save_Schedule/checkpoint_195.pth.tar'
# TEST : Loss: (0.4008) | Acc: (88.00%) (8874/10000)
percent tensor([0.5708, 0.5826, 0.5744, 0.5720, 0.5783, 0.5849, 0.5837, 0.5691, 0.5696,
        0.5776, 0.5773, 0.5816, 0.5730, 0.5693, 0.5857, 0.5754],
       device='cuda:0') torch.Size([16])
percent tensor([0.5328, 0.5356, 0.5234, 0.5290, 0.5229, 0.5370, 0.5303, 0.5244, 0.5257,
        0.5312, 0.5356, 0.5252, 0.5316, 0.5322, 0.5353, 0.5344],
       device='cuda:0') torch.Size([16])
percent tensor([0.5948, 0.4646, 0.7169, 0.7200, 0.7431, 0.6849, 0.5706, 0.6944, 0.6455,
        0.5462, 0.4967, 0.6438, 0.4930, 0.5436, 0.5334, 0.6407],
       device='cuda:0') torch.Size([16])
percent tensor([0.6957, 0.7209, 0.6270, 0.6497, 0.6330, 0.5770, 0.6977, 0.6487, 0.7020,
        0.7223, 0.7357, 0.6830, 0.7090, 0.7370, 0.6737, 0.6705],
       device='cuda:0') torch.Size([16])
percent tensor([0.7369, 0.6633, 0.7581, 0.7499, 0.7702, 0.8228, 0.7314, 0.7334, 0.7042,
        0.6258, 0.6143, 0.6382, 0.6073, 0.6906, 0.7225, 0.7786],
       device='cuda:0') torch.Size([16])
percent tensor([0.6331, 0.7677, 0.7577, 0.8083, 0.7490, 0.8145, 0.7442, 0.5921, 0.7641,
        0.7337, 0.7935, 0.7603, 0.7708, 0.7909, 0.6012, 0.5665],
       device='cuda:0') torch.Size([16])
percent tensor([0.3787, 0.6972, 0.6521, 0.6817, 0.5975, 0.6372, 0.6286, 0.6022, 0.6479,
        0.5925, 0.7269, 0.6305, 0.6321, 0.6300, 0.5651, 0.3651],
       device='cuda:0') torch.Size([16])
percent tensor([0.9998, 0.9998, 0.9998, 0.9999, 1.0000, 0.9994, 0.9999, 0.9996, 0.9998,
        0.9999, 0.9998, 0.9999, 0.9998, 0.9996, 0.9998, 0.9996],
       device='cuda:0') torch.Size([16])
Epoch: 196 | Batch_idx: 0 |  Loss: (0.0749) |  Loss2: (0.0000) | Acc: (98.00%) (126/128)
Epoch: 196 | Batch_idx: 10 |  Loss: (0.0767) |  Loss2: (0.0000) | Acc: (97.00%) (1370/1408)
Epoch: 196 | Batch_idx: 20 |  Loss: (0.0867) |  Loss2: (0.0000) | Acc: (96.00%) (2606/2688)
Epoch: 196 | Batch_idx: 30 |  Loss: (0.0890) |  Loss2: (0.0000) | Acc: (96.00%) (3846/3968)
Epoch: 196 | Batch_idx: 40 |  Loss: (0.0840) |  Loss2: (0.0000) | Acc: (97.00%) (5095/5248)
Epoch: 196 | Batch_idx: 50 |  Loss: (0.0841) |  Loss2: (0.0000) | Acc: (97.00%) (6335/6528)
Epoch: 196 | Batch_idx: 60 |  Loss: (0.0818) |  Loss2: (0.0000) | Acc: (97.00%) (7578/7808)
Epoch: 196 | Batch_idx: 70 |  Loss: (0.0811) |  Loss2: (0.0000) | Acc: (97.00%) (8822/9088)
Epoch: 196 | Batch_idx: 80 |  Loss: (0.0820) |  Loss2: (0.0000) | Acc: (97.00%) (10064/10368)
Epoch: 196 | Batch_idx: 90 |  Loss: (0.0794) |  Loss2: (0.0000) | Acc: (97.00%) (11322/11648)
Epoch: 196 | Batch_idx: 100 |  Loss: (0.0787) |  Loss2: (0.0000) | Acc: (97.00%) (12574/12928)
Epoch: 196 | Batch_idx: 110 |  Loss: (0.0779) |  Loss2: (0.0000) | Acc: (97.00%) (13822/14208)
Epoch: 196 | Batch_idx: 120 |  Loss: (0.0786) |  Loss2: (0.0000) | Acc: (97.00%) (15068/15488)
Epoch: 196 | Batch_idx: 130 |  Loss: (0.0772) |  Loss2: (0.0000) | Acc: (97.00%) (16326/16768)
Epoch: 196 | Batch_idx: 140 |  Loss: (0.0767) |  Loss2: (0.0000) | Acc: (97.00%) (17582/18048)
Epoch: 196 | Batch_idx: 150 |  Loss: (0.0783) |  Loss2: (0.0000) | Acc: (97.00%) (18821/19328)
Epoch: 196 | Batch_idx: 160 |  Loss: (0.0792) |  Loss2: (0.0000) | Acc: (97.00%) (20059/20608)
Epoch: 196 | Batch_idx: 170 |  Loss: (0.0785) |  Loss2: (0.0000) | Acc: (97.00%) (21309/21888)
Epoch: 196 | Batch_idx: 180 |  Loss: (0.0779) |  Loss2: (0.0000) | Acc: (97.00%) (22558/23168)
Epoch: 196 | Batch_idx: 190 |  Loss: (0.0777) |  Loss2: (0.0000) | Acc: (97.00%) (23807/24448)
Epoch: 196 | Batch_idx: 200 |  Loss: (0.0769) |  Loss2: (0.0000) | Acc: (97.00%) (25060/25728)
Epoch: 196 | Batch_idx: 210 |  Loss: (0.0770) |  Loss2: (0.0000) | Acc: (97.00%) (26311/27008)
Epoch: 196 | Batch_idx: 220 |  Loss: (0.0765) |  Loss2: (0.0000) | Acc: (97.00%) (27569/28288)
Epoch: 196 | Batch_idx: 230 |  Loss: (0.0760) |  Loss2: (0.0000) | Acc: (97.00%) (28819/29568)
Epoch: 196 | Batch_idx: 240 |  Loss: (0.0760) |  Loss2: (0.0000) | Acc: (97.00%) (30065/30848)
Epoch: 196 | Batch_idx: 250 |  Loss: (0.0761) |  Loss2: (0.0000) | Acc: (97.00%) (31309/32128)
Epoch: 196 | Batch_idx: 260 |  Loss: (0.0761) |  Loss2: (0.0000) | Acc: (97.00%) (32555/33408)
Epoch: 196 | Batch_idx: 270 |  Loss: (0.0758) |  Loss2: (0.0000) | Acc: (97.00%) (33807/34688)
Epoch: 196 | Batch_idx: 280 |  Loss: (0.0760) |  Loss2: (0.0000) | Acc: (97.00%) (35050/35968)
Epoch: 196 | Batch_idx: 290 |  Loss: (0.0759) |  Loss2: (0.0000) | Acc: (97.00%) (36299/37248)
Epoch: 196 | Batch_idx: 300 |  Loss: (0.0756) |  Loss2: (0.0000) | Acc: (97.00%) (37546/38528)
Epoch: 196 | Batch_idx: 310 |  Loss: (0.0752) |  Loss2: (0.0000) | Acc: (97.00%) (38805/39808)
Epoch: 196 | Batch_idx: 320 |  Loss: (0.0746) |  Loss2: (0.0000) | Acc: (97.00%) (40062/41088)
Epoch: 196 | Batch_idx: 330 |  Loss: (0.0745) |  Loss2: (0.0000) | Acc: (97.00%) (41306/42368)
Epoch: 196 | Batch_idx: 340 |  Loss: (0.0744) |  Loss2: (0.0000) | Acc: (97.00%) (42552/43648)
Epoch: 196 | Batch_idx: 350 |  Loss: (0.0745) |  Loss2: (0.0000) | Acc: (97.00%) (43803/44928)
Epoch: 196 | Batch_idx: 360 |  Loss: (0.0743) |  Loss2: (0.0000) | Acc: (97.00%) (45057/46208)
Epoch: 196 | Batch_idx: 370 |  Loss: (0.0744) |  Loss2: (0.0000) | Acc: (97.00%) (46305/47488)
Epoch: 196 | Batch_idx: 380 |  Loss: (0.0741) |  Loss2: (0.0000) | Acc: (97.00%) (47556/48768)
Epoch: 196 | Batch_idx: 390 |  Loss: (0.0743) |  Loss2: (0.0000) | Acc: (97.00%) (48760/50000)
# TEST : Loss: (0.3848) | Acc: (88.00%) (8892/10000)
percent tensor([0.5697, 0.5814, 0.5727, 0.5707, 0.5766, 0.5840, 0.5824, 0.5673, 0.5682,
        0.5762, 0.5761, 0.5800, 0.5717, 0.5678, 0.5846, 0.5743],
       device='cuda:0') torch.Size([16])
percent tensor([0.5329, 0.5358, 0.5240, 0.5291, 0.5242, 0.5367, 0.5310, 0.5254, 0.5264,
        0.5315, 0.5358, 0.5257, 0.5318, 0.5323, 0.5355, 0.5343],
       device='cuda:0') torch.Size([16])
percent tensor([0.5913, 0.4609, 0.7146, 0.7173, 0.7411, 0.6833, 0.5666, 0.6915, 0.6403,
        0.5419, 0.4923, 0.6401, 0.4866, 0.5372, 0.5334, 0.6350],
       device='cuda:0') torch.Size([16])
percent tensor([0.7000, 0.7248, 0.6320, 0.6555, 0.6374, 0.5836, 0.7019, 0.6537, 0.7083,
        0.7274, 0.7407, 0.6880, 0.7126, 0.7428, 0.6788, 0.6757],
       device='cuda:0') torch.Size([16])
percent tensor([0.7332, 0.6495, 0.7603, 0.7489, 0.7709, 0.8229, 0.7244, 0.7337, 0.6971,
        0.6142, 0.6040, 0.6321, 0.5972, 0.6771, 0.7172, 0.7743],
       device='cuda:0') torch.Size([16])
percent tensor([0.6204, 0.7616, 0.7480, 0.7999, 0.7360, 0.8076, 0.7315, 0.5748, 0.7512,
        0.7241, 0.7873, 0.7535, 0.7648, 0.7843, 0.5876, 0.5582],
       device='cuda:0') torch.Size([16])
percent tensor([0.3639, 0.6958, 0.6448, 0.6798, 0.5970, 0.6340, 0.6190, 0.5971, 0.6420,
        0.5927, 0.7269, 0.6199, 0.6276, 0.6383, 0.5583, 0.3623],
       device='cuda:0') torch.Size([16])
percent tensor([0.9998, 0.9998, 0.9998, 0.9999, 1.0000, 0.9994, 0.9999, 0.9996, 0.9998,
        0.9999, 0.9997, 0.9999, 0.9997, 0.9997, 0.9998, 0.9997],
       device='cuda:0') torch.Size([16])
Epoch: 197 | Batch_idx: 0 |  Loss: (0.0902) |  Loss2: (0.0000) | Acc: (96.00%) (123/128)
Epoch: 197 | Batch_idx: 10 |  Loss: (0.0742) |  Loss2: (0.0000) | Acc: (97.00%) (1371/1408)
Epoch: 197 | Batch_idx: 20 |  Loss: (0.0708) |  Loss2: (0.0000) | Acc: (97.00%) (2619/2688)
Epoch: 197 | Batch_idx: 30 |  Loss: (0.0686) |  Loss2: (0.0000) | Acc: (97.00%) (3870/3968)
Epoch: 197 | Batch_idx: 40 |  Loss: (0.0656) |  Loss2: (0.0000) | Acc: (97.00%) (5130/5248)
Epoch: 197 | Batch_idx: 50 |  Loss: (0.0647) |  Loss2: (0.0000) | Acc: (97.00%) (6390/6528)
Epoch: 197 | Batch_idx: 60 |  Loss: (0.0628) |  Loss2: (0.0000) | Acc: (98.00%) (7653/7808)
Epoch: 197 | Batch_idx: 70 |  Loss: (0.0629) |  Loss2: (0.0000) | Acc: (98.00%) (8907/9088)
Epoch: 197 | Batch_idx: 80 |  Loss: (0.0641) |  Loss2: (0.0000) | Acc: (97.00%) (10157/10368)
Epoch: 197 | Batch_idx: 90 |  Loss: (0.0663) |  Loss2: (0.0000) | Acc: (97.00%) (11408/11648)
Epoch: 197 | Batch_idx: 100 |  Loss: (0.0666) |  Loss2: (0.0000) | Acc: (97.00%) (12655/12928)
Epoch: 197 | Batch_idx: 110 |  Loss: (0.0680) |  Loss2: (0.0000) | Acc: (97.00%) (13901/14208)
Epoch: 197 | Batch_idx: 120 |  Loss: (0.0700) |  Loss2: (0.0000) | Acc: (97.00%) (15138/15488)
Epoch: 197 | Batch_idx: 130 |  Loss: (0.0701) |  Loss2: (0.0000) | Acc: (97.00%) (16387/16768)
Epoch: 197 | Batch_idx: 140 |  Loss: (0.0691) |  Loss2: (0.0000) | Acc: (97.00%) (17643/18048)
Epoch: 197 | Batch_idx: 150 |  Loss: (0.0693) |  Loss2: (0.0000) | Acc: (97.00%) (18895/19328)
Epoch: 197 | Batch_idx: 160 |  Loss: (0.0698) |  Loss2: (0.0000) | Acc: (97.00%) (20141/20608)
Epoch: 197 | Batch_idx: 170 |  Loss: (0.0702) |  Loss2: (0.0000) | Acc: (97.00%) (21396/21888)
Epoch: 197 | Batch_idx: 180 |  Loss: (0.0704) |  Loss2: (0.0000) | Acc: (97.00%) (22648/23168)
Epoch: 197 | Batch_idx: 190 |  Loss: (0.0702) |  Loss2: (0.0000) | Acc: (97.00%) (23901/24448)
Epoch: 197 | Batch_idx: 200 |  Loss: (0.0700) |  Loss2: (0.0000) | Acc: (97.00%) (25151/25728)
Epoch: 197 | Batch_idx: 210 |  Loss: (0.0702) |  Loss2: (0.0000) | Acc: (97.00%) (26401/27008)
Epoch: 197 | Batch_idx: 220 |  Loss: (0.0695) |  Loss2: (0.0000) | Acc: (97.00%) (27659/28288)
Epoch: 197 | Batch_idx: 230 |  Loss: (0.0693) |  Loss2: (0.0000) | Acc: (97.00%) (28909/29568)
Epoch: 197 | Batch_idx: 240 |  Loss: (0.0697) |  Loss2: (0.0000) | Acc: (97.00%) (30157/30848)
Epoch: 197 | Batch_idx: 250 |  Loss: (0.0700) |  Loss2: (0.0000) | Acc: (97.00%) (31402/32128)
Epoch: 197 | Batch_idx: 260 |  Loss: (0.0698) |  Loss2: (0.0000) | Acc: (97.00%) (32658/33408)
Epoch: 197 | Batch_idx: 270 |  Loss: (0.0699) |  Loss2: (0.0000) | Acc: (97.00%) (33900/34688)
Epoch: 197 | Batch_idx: 280 |  Loss: (0.0698) |  Loss2: (0.0000) | Acc: (97.00%) (35157/35968)
Epoch: 197 | Batch_idx: 290 |  Loss: (0.0699) |  Loss2: (0.0000) | Acc: (97.00%) (36407/37248)
Epoch: 197 | Batch_idx: 300 |  Loss: (0.0700) |  Loss2: (0.0000) | Acc: (97.00%) (37651/38528)
Epoch: 197 | Batch_idx: 310 |  Loss: (0.0700) |  Loss2: (0.0000) | Acc: (97.00%) (38904/39808)
Epoch: 197 | Batch_idx: 320 |  Loss: (0.0697) |  Loss2: (0.0000) | Acc: (97.00%) (40158/41088)
Epoch: 197 | Batch_idx: 330 |  Loss: (0.0699) |  Loss2: (0.0000) | Acc: (97.00%) (41407/42368)
Epoch: 197 | Batch_idx: 340 |  Loss: (0.0699) |  Loss2: (0.0000) | Acc: (97.00%) (42661/43648)
Epoch: 197 | Batch_idx: 350 |  Loss: (0.0697) |  Loss2: (0.0000) | Acc: (97.00%) (43915/44928)
Epoch: 197 | Batch_idx: 360 |  Loss: (0.0695) |  Loss2: (0.0000) | Acc: (97.00%) (45165/46208)
Epoch: 197 | Batch_idx: 370 |  Loss: (0.0693) |  Loss2: (0.0000) | Acc: (97.00%) (46414/47488)
Epoch: 197 | Batch_idx: 380 |  Loss: (0.0692) |  Loss2: (0.0000) | Acc: (97.00%) (47666/48768)
Epoch: 197 | Batch_idx: 390 |  Loss: (0.0692) |  Loss2: (0.0000) | Acc: (97.00%) (48869/50000)
# TEST : Loss: (0.3782) | Acc: (89.00%) (8904/10000)
percent tensor([0.5705, 0.5826, 0.5735, 0.5714, 0.5775, 0.5852, 0.5835, 0.5677, 0.5687,
        0.5771, 0.5769, 0.5809, 0.5724, 0.5685, 0.5858, 0.5752],
       device='cuda:0') torch.Size([16])
percent tensor([0.5303, 0.5333, 0.5222, 0.5268, 0.5221, 0.5338, 0.5287, 0.5233, 0.5242,
        0.5292, 0.5330, 0.5238, 0.5295, 0.5299, 0.5329, 0.5316],
       device='cuda:0') torch.Size([16])
percent tensor([0.5975, 0.4677, 0.7170, 0.7185, 0.7441, 0.6853, 0.5747, 0.6955, 0.6443,
        0.5483, 0.4983, 0.6461, 0.4941, 0.5412, 0.5416, 0.6388],
       device='cuda:0') torch.Size([16])
percent tensor([0.7021, 0.7275, 0.6337, 0.6579, 0.6400, 0.5855, 0.7050, 0.6560, 0.7107,
        0.7299, 0.7430, 0.6912, 0.7146, 0.7466, 0.6819, 0.6779],
       device='cuda:0') torch.Size([16])
percent tensor([0.7384, 0.6493, 0.7700, 0.7542, 0.7790, 0.8297, 0.7279, 0.7432, 0.7015,
        0.6120, 0.6040, 0.6323, 0.5967, 0.6770, 0.7199, 0.7787],
       device='cuda:0') torch.Size([16])
percent tensor([0.6151, 0.7576, 0.7482, 0.8011, 0.7334, 0.8077, 0.7226, 0.5737, 0.7472,
        0.7198, 0.7863, 0.7518, 0.7618, 0.7798, 0.5845, 0.5542],
       device='cuda:0') torch.Size([16])
percent tensor([0.3614, 0.7028, 0.6468, 0.6857, 0.5965, 0.6380, 0.6104, 0.5975, 0.6479,
        0.6021, 0.7363, 0.6215, 0.6364, 0.6383, 0.5567, 0.3602],
       device='cuda:0') torch.Size([16])
percent tensor([0.9998, 0.9998, 0.9998, 0.9999, 1.0000, 0.9994, 0.9999, 0.9996, 0.9998,
        0.9999, 0.9998, 0.9999, 0.9997, 0.9997, 0.9998, 0.9996],
       device='cuda:0') torch.Size([16])
True Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=128, out_features=16, bias=False)
False Linear(in_features=16, out_features=2, bias=False)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=128, out_features=16, bias=False)
False Linear(in_features=16, out_features=2, bias=False)
True Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=256, out_features=32, bias=False)
False Linear(in_features=32, out_features=2, bias=False)
True Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=256, out_features=32, bias=False)
False Linear(in_features=32, out_features=2, bias=False)
True Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=512, out_features=64, bias=False)
False Linear(in_features=64, out_features=2, bias=False)
True Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=512, out_features=64, bias=False)
False Linear(in_features=64, out_features=2, bias=False)
True Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1024, out_features=128, bias=False)
False Linear(in_features=128, out_features=2, bias=False)
True Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1024, out_features=128, bias=False)
False Linear(in_features=128, out_features=2, bias=False)
True Linear(in_features=512, out_features=10, bias=True)
Epoch: 198 | Batch_idx: 0 |  Loss: (0.0638) |  Loss2: (0.0000) | Acc: (97.00%) (125/128)
Epoch: 198 | Batch_idx: 10 |  Loss: (0.0763) |  Loss2: (0.0000) | Acc: (97.00%) (1370/1408)
Epoch: 198 | Batch_idx: 20 |  Loss: (0.0706) |  Loss2: (0.0000) | Acc: (97.00%) (2626/2688)
Epoch: 198 | Batch_idx: 30 |  Loss: (0.0675) |  Loss2: (0.0000) | Acc: (97.00%) (3885/3968)
Epoch: 198 | Batch_idx: 40 |  Loss: (0.0693) |  Loss2: (0.0000) | Acc: (97.00%) (5131/5248)
Epoch: 198 | Batch_idx: 50 |  Loss: (0.0689) |  Loss2: (0.0000) | Acc: (97.00%) (6387/6528)
Epoch: 198 | Batch_idx: 60 |  Loss: (0.0674) |  Loss2: (0.0000) | Acc: (97.00%) (7643/7808)
Epoch: 198 | Batch_idx: 70 |  Loss: (0.0682) |  Loss2: (0.0000) | Acc: (97.00%) (8897/9088)
Epoch: 198 | Batch_idx: 80 |  Loss: (0.0679) |  Loss2: (0.0000) | Acc: (97.00%) (10145/10368)
Epoch: 198 | Batch_idx: 90 |  Loss: (0.0682) |  Loss2: (0.0000) | Acc: (97.00%) (11394/11648)
Epoch: 198 | Batch_idx: 100 |  Loss: (0.0685) |  Loss2: (0.0000) | Acc: (97.00%) (12638/12928)
Epoch: 198 | Batch_idx: 110 |  Loss: (0.0679) |  Loss2: (0.0000) | Acc: (97.00%) (13897/14208)
Epoch: 198 | Batch_idx: 120 |  Loss: (0.0682) |  Loss2: (0.0000) | Acc: (97.00%) (15148/15488)
Epoch: 198 | Batch_idx: 130 |  Loss: (0.0683) |  Loss2: (0.0000) | Acc: (97.00%) (16398/16768)
Epoch: 198 | Batch_idx: 140 |  Loss: (0.0697) |  Loss2: (0.0000) | Acc: (97.00%) (17637/18048)
Epoch: 198 | Batch_idx: 150 |  Loss: (0.0688) |  Loss2: (0.0000) | Acc: (97.00%) (18895/19328)
Epoch: 198 | Batch_idx: 160 |  Loss: (0.0700) |  Loss2: (0.0000) | Acc: (97.00%) (20137/20608)
Epoch: 198 | Batch_idx: 170 |  Loss: (0.0706) |  Loss2: (0.0000) | Acc: (97.00%) (21384/21888)
Epoch: 198 | Batch_idx: 180 |  Loss: (0.0703) |  Loss2: (0.0000) | Acc: (97.00%) (22636/23168)
Epoch: 198 | Batch_idx: 190 |  Loss: (0.0712) |  Loss2: (0.0000) | Acc: (97.00%) (23876/24448)
Epoch: 198 | Batch_idx: 200 |  Loss: (0.0707) |  Loss2: (0.0000) | Acc: (97.00%) (25132/25728)
Epoch: 198 | Batch_idx: 210 |  Loss: (0.0707) |  Loss2: (0.0000) | Acc: (97.00%) (26380/27008)
Epoch: 198 | Batch_idx: 220 |  Loss: (0.0707) |  Loss2: (0.0000) | Acc: (97.00%) (27632/28288)
Epoch: 198 | Batch_idx: 230 |  Loss: (0.0709) |  Loss2: (0.0000) | Acc: (97.00%) (28880/29568)
Epoch: 198 | Batch_idx: 240 |  Loss: (0.0715) |  Loss2: (0.0000) | Acc: (97.00%) (30124/30848)
Epoch: 198 | Batch_idx: 250 |  Loss: (0.0716) |  Loss2: (0.0000) | Acc: (97.00%) (31371/32128)
Epoch: 198 | Batch_idx: 260 |  Loss: (0.0717) |  Loss2: (0.0000) | Acc: (97.00%) (32620/33408)
Epoch: 198 | Batch_idx: 270 |  Loss: (0.0723) |  Loss2: (0.0000) | Acc: (97.00%) (33864/34688)
Epoch: 198 | Batch_idx: 280 |  Loss: (0.0724) |  Loss2: (0.0000) | Acc: (97.00%) (35113/35968)
Epoch: 198 | Batch_idx: 290 |  Loss: (0.0727) |  Loss2: (0.0000) | Acc: (97.00%) (36356/37248)
Epoch: 198 | Batch_idx: 300 |  Loss: (0.0731) |  Loss2: (0.0000) | Acc: (97.00%) (37598/38528)
Epoch: 198 | Batch_idx: 310 |  Loss: (0.0741) |  Loss2: (0.0000) | Acc: (97.00%) (38827/39808)
Epoch: 198 | Batch_idx: 320 |  Loss: (0.0745) |  Loss2: (0.0000) | Acc: (97.00%) (40067/41088)
Epoch: 198 | Batch_idx: 330 |  Loss: (0.0749) |  Loss2: (0.0000) | Acc: (97.00%) (41311/42368)
Epoch: 198 | Batch_idx: 340 |  Loss: (0.0746) |  Loss2: (0.0000) | Acc: (97.00%) (42560/43648)
Epoch: 198 | Batch_idx: 350 |  Loss: (0.0747) |  Loss2: (0.0000) | Acc: (97.00%) (43805/44928)
Epoch: 198 | Batch_idx: 360 |  Loss: (0.0748) |  Loss2: (0.0000) | Acc: (97.00%) (45048/46208)
Epoch: 198 | Batch_idx: 370 |  Loss: (0.0751) |  Loss2: (0.0000) | Acc: (97.00%) (46286/47488)
Epoch: 198 | Batch_idx: 380 |  Loss: (0.0757) |  Loss2: (0.0000) | Acc: (97.00%) (47519/48768)
Epoch: 198 | Batch_idx: 390 |  Loss: (0.0758) |  Loss2: (0.0000) | Acc: (97.00%) (48720/50000)
# TEST : Loss: (0.3907) | Acc: (89.00%) (8921/10000)
percent tensor([0.5697, 0.5830, 0.5725, 0.5712, 0.5773, 0.5843, 0.5831, 0.5675, 0.5681,
        0.5765, 0.5762, 0.5792, 0.5714, 0.5687, 0.5859, 0.5750],
       device='cuda:0') torch.Size([16])
percent tensor([0.5305, 0.5325, 0.5225, 0.5272, 0.5230, 0.5345, 0.5285, 0.5228, 0.5244,
        0.5293, 0.5332, 0.5246, 0.5301, 0.5292, 0.5326, 0.5315],
       device='cuda:0') torch.Size([16])
percent tensor([0.5935, 0.4872, 0.7115, 0.7179, 0.7363, 0.6831, 0.5884, 0.6905, 0.6402,
        0.5552, 0.5030, 0.6460, 0.5006, 0.5729, 0.5493, 0.6387],
       device='cuda:0') torch.Size([16])
percent tensor([0.6990, 0.7267, 0.6317, 0.6571, 0.6384, 0.5740, 0.7023, 0.6534, 0.7079,
        0.7278, 0.7389, 0.6928, 0.7153, 0.7393, 0.6763, 0.6714],
       device='cuda:0') torch.Size([16])
percent tensor([0.7436, 0.6331, 0.7643, 0.7553, 0.7694, 0.8365, 0.7230, 0.7430, 0.6971,
        0.6164, 0.5982, 0.6361, 0.5966, 0.6700, 0.7176, 0.7865],
       device='cuda:0') torch.Size([16])
percent tensor([0.6430, 0.7321, 0.7610, 0.7958, 0.7438, 0.8090, 0.7153, 0.5673, 0.7523,
        0.7342, 0.8009, 0.7769, 0.7582, 0.7655, 0.6091, 0.5726],
       device='cuda:0') torch.Size([16])
percent tensor([0.3691, 0.7181, 0.6853, 0.6398, 0.6077, 0.6632, 0.6142, 0.5949, 0.6777,
        0.6726, 0.7726, 0.6522, 0.6295, 0.6076, 0.5752, 0.3677],
       device='cuda:0') torch.Size([16])
percent tensor([0.9998, 0.9998, 0.9998, 0.9999, 1.0000, 0.9995, 0.9999, 0.9996, 0.9999,
        0.9999, 0.9998, 0.9999, 0.9997, 0.9996, 0.9998, 0.9996],
       device='cuda:0') torch.Size([16])
Epoch: 199 | Batch_idx: 0 |  Loss: (0.0557) |  Loss2: (0.0000) | Acc: (98.00%) (126/128)
Epoch: 199 | Batch_idx: 10 |  Loss: (0.0534) |  Loss2: (0.0000) | Acc: (98.00%) (1386/1408)
Epoch: 199 | Batch_idx: 20 |  Loss: (0.0639) |  Loss2: (0.0000) | Acc: (97.00%) (2631/2688)
Epoch: 199 | Batch_idx: 30 |  Loss: (0.0627) |  Loss2: (0.0000) | Acc: (98.00%) (3890/3968)
Epoch: 199 | Batch_idx: 40 |  Loss: (0.0649) |  Loss2: (0.0000) | Acc: (97.00%) (5142/5248)
Epoch: 199 | Batch_idx: 50 |  Loss: (0.0649) |  Loss2: (0.0000) | Acc: (97.00%) (6395/6528)
Epoch: 199 | Batch_idx: 60 |  Loss: (0.0644) |  Loss2: (0.0000) | Acc: (97.00%) (7649/7808)
Epoch: 199 | Batch_idx: 70 |  Loss: (0.0648) |  Loss2: (0.0000) | Acc: (97.00%) (8898/9088)
Epoch: 199 | Batch_idx: 80 |  Loss: (0.0648) |  Loss2: (0.0000) | Acc: (97.00%) (10154/10368)
Epoch: 199 | Batch_idx: 90 |  Loss: (0.0653) |  Loss2: (0.0000) | Acc: (97.00%) (11406/11648)
Epoch: 199 | Batch_idx: 100 |  Loss: (0.0657) |  Loss2: (0.0000) | Acc: (97.00%) (12659/12928)
Epoch: 199 | Batch_idx: 110 |  Loss: (0.0659) |  Loss2: (0.0000) | Acc: (97.00%) (13914/14208)
Epoch: 199 | Batch_idx: 120 |  Loss: (0.0675) |  Loss2: (0.0000) | Acc: (97.00%) (15155/15488)
Epoch: 199 | Batch_idx: 130 |  Loss: (0.0690) |  Loss2: (0.0000) | Acc: (97.00%) (16397/16768)
Epoch: 199 | Batch_idx: 140 |  Loss: (0.0685) |  Loss2: (0.0000) | Acc: (97.00%) (17647/18048)
Epoch: 199 | Batch_idx: 150 |  Loss: (0.0688) |  Loss2: (0.0000) | Acc: (97.00%) (18900/19328)
Epoch: 199 | Batch_idx: 160 |  Loss: (0.0685) |  Loss2: (0.0000) | Acc: (97.00%) (20149/20608)
Epoch: 199 | Batch_idx: 170 |  Loss: (0.0694) |  Loss2: (0.0000) | Acc: (97.00%) (21390/21888)
Epoch: 199 | Batch_idx: 180 |  Loss: (0.0695) |  Loss2: (0.0000) | Acc: (97.00%) (22633/23168)
Epoch: 199 | Batch_idx: 190 |  Loss: (0.0696) |  Loss2: (0.0000) | Acc: (97.00%) (23885/24448)
Epoch: 199 | Batch_idx: 200 |  Loss: (0.0699) |  Loss2: (0.0000) | Acc: (97.00%) (25134/25728)
Epoch: 199 | Batch_idx: 210 |  Loss: (0.0705) |  Loss2: (0.0000) | Acc: (97.00%) (26374/27008)
Epoch: 199 | Batch_idx: 220 |  Loss: (0.0715) |  Loss2: (0.0000) | Acc: (97.00%) (27611/28288)
Epoch: 199 | Batch_idx: 230 |  Loss: (0.0718) |  Loss2: (0.0000) | Acc: (97.00%) (28854/29568)
Epoch: 199 | Batch_idx: 240 |  Loss: (0.0723) |  Loss2: (0.0000) | Acc: (97.00%) (30098/30848)
Epoch: 199 | Batch_idx: 250 |  Loss: (0.0720) |  Loss2: (0.0000) | Acc: (97.00%) (31355/32128)
Epoch: 199 | Batch_idx: 260 |  Loss: (0.0727) |  Loss2: (0.0000) | Acc: (97.00%) (32599/33408)
Epoch: 199 | Batch_idx: 270 |  Loss: (0.0723) |  Loss2: (0.0000) | Acc: (97.00%) (33850/34688)
Epoch: 199 | Batch_idx: 280 |  Loss: (0.0725) |  Loss2: (0.0000) | Acc: (97.00%) (35101/35968)
Epoch: 199 | Batch_idx: 290 |  Loss: (0.0723) |  Loss2: (0.0000) | Acc: (97.00%) (36352/37248)
Epoch: 199 | Batch_idx: 300 |  Loss: (0.0725) |  Loss2: (0.0000) | Acc: (97.00%) (37598/38528)
Epoch: 199 | Batch_idx: 310 |  Loss: (0.0723) |  Loss2: (0.0000) | Acc: (97.00%) (38852/39808)
Epoch: 199 | Batch_idx: 320 |  Loss: (0.0725) |  Loss2: (0.0000) | Acc: (97.00%) (40096/41088)
Epoch: 199 | Batch_idx: 330 |  Loss: (0.0724) |  Loss2: (0.0000) | Acc: (97.00%) (41349/42368)
Epoch: 199 | Batch_idx: 340 |  Loss: (0.0731) |  Loss2: (0.0000) | Acc: (97.00%) (42581/43648)
Epoch: 199 | Batch_idx: 350 |  Loss: (0.0734) |  Loss2: (0.0000) | Acc: (97.00%) (43828/44928)
Epoch: 199 | Batch_idx: 360 |  Loss: (0.0737) |  Loss2: (0.0000) | Acc: (97.00%) (45073/46208)
Epoch: 199 | Batch_idx: 370 |  Loss: (0.0738) |  Loss2: (0.0000) | Acc: (97.00%) (46321/47488)
Epoch: 199 | Batch_idx: 380 |  Loss: (0.0741) |  Loss2: (0.0000) | Acc: (97.00%) (47557/48768)
Epoch: 199 | Batch_idx: 390 |  Loss: (0.0745) |  Loss2: (0.0000) | Acc: (97.00%) (48745/50000)
# TEST : Loss: (0.4349) | Acc: (88.00%) (8849/10000)
percent tensor([0.5707, 0.5822, 0.5742, 0.5713, 0.5786, 0.5852, 0.5834, 0.5676, 0.5691,
        0.5769, 0.5768, 0.5816, 0.5728, 0.5674, 0.5861, 0.5749],
       device='cuda:0') torch.Size([16])
percent tensor([0.5307, 0.5333, 0.5222, 0.5268, 0.5225, 0.5340, 0.5289, 0.5227, 0.5242,
        0.5297, 0.5336, 0.5239, 0.5299, 0.5294, 0.5328, 0.5318],
       device='cuda:0') torch.Size([16])
percent tensor([0.5940, 0.4780, 0.7098, 0.7198, 0.7357, 0.6759, 0.5817, 0.6972, 0.6439,
        0.5521, 0.4978, 0.6473, 0.4980, 0.5646, 0.5415, 0.6416],
       device='cuda:0') torch.Size([16])
percent tensor([0.6991, 0.7362, 0.6246, 0.6500, 0.6303, 0.5681, 0.7021, 0.6512, 0.7095,
        0.7302, 0.7458, 0.6908, 0.7197, 0.7448, 0.6779, 0.6739],
       device='cuda:0') torch.Size([16])
percent tensor([0.7422, 0.6418, 0.7654, 0.7716, 0.7801, 0.8482, 0.7282, 0.7469, 0.7012,
        0.6195, 0.5965, 0.6339, 0.5922, 0.6736, 0.7324, 0.7934],
       device='cuda:0') torch.Size([16])
percent tensor([0.6311, 0.7490, 0.7427, 0.7798, 0.7497, 0.8348, 0.7266, 0.5560, 0.7455,
        0.7309, 0.7983, 0.7630, 0.7386, 0.7793, 0.6122, 0.5928],
       device='cuda:0') torch.Size([16])
percent tensor([0.3907, 0.7201, 0.6792, 0.6356, 0.6235, 0.6790, 0.6413, 0.5861, 0.6873,
        0.6533, 0.7462, 0.6278, 0.6351, 0.6241, 0.5689, 0.3784],
       device='cuda:0') torch.Size([16])
percent tensor([0.9998, 0.9998, 0.9997, 0.9999, 0.9999, 0.9995, 0.9999, 0.9996, 0.9999,
        0.9999, 0.9998, 0.9999, 0.9998, 0.9995, 0.9998, 0.9995],
       device='cuda:0') torch.Size([16])
Epoch: 200 | Batch_idx: 0 |  Loss: (0.1040) |  Loss2: (0.0000) | Acc: (96.00%) (124/128)
Epoch: 200 | Batch_idx: 10 |  Loss: (0.0778) |  Loss2: (0.0000) | Acc: (96.00%) (1363/1408)
Epoch: 200 | Batch_idx: 20 |  Loss: (0.0693) |  Loss2: (0.0000) | Acc: (97.00%) (2621/2688)
Epoch: 200 | Batch_idx: 30 |  Loss: (0.0699) |  Loss2: (0.0000) | Acc: (97.00%) (3872/3968)
Epoch: 200 | Batch_idx: 40 |  Loss: (0.0671) |  Loss2: (0.0000) | Acc: (97.00%) (5126/5248)
Epoch: 200 | Batch_idx: 50 |  Loss: (0.0687) |  Loss2: (0.0000) | Acc: (97.00%) (6369/6528)
Epoch: 200 | Batch_idx: 60 |  Loss: (0.0692) |  Loss2: (0.0000) | Acc: (97.00%) (7613/7808)
Epoch: 200 | Batch_idx: 70 |  Loss: (0.0692) |  Loss2: (0.0000) | Acc: (97.00%) (8859/9088)
Epoch: 200 | Batch_idx: 80 |  Loss: (0.0667) |  Loss2: (0.0000) | Acc: (97.00%) (10124/10368)
Epoch: 200 | Batch_idx: 90 |  Loss: (0.0659) |  Loss2: (0.0000) | Acc: (97.00%) (11380/11648)
Epoch: 200 | Batch_idx: 100 |  Loss: (0.0652) |  Loss2: (0.0000) | Acc: (97.00%) (12639/12928)
Epoch: 200 | Batch_idx: 110 |  Loss: (0.0641) |  Loss2: (0.0000) | Acc: (97.00%) (13898/14208)
Epoch: 200 | Batch_idx: 120 |  Loss: (0.0646) |  Loss2: (0.0000) | Acc: (97.00%) (15154/15488)
Epoch: 200 | Batch_idx: 130 |  Loss: (0.0649) |  Loss2: (0.0000) | Acc: (97.00%) (16404/16768)
Epoch: 200 | Batch_idx: 140 |  Loss: (0.0652) |  Loss2: (0.0000) | Acc: (97.00%) (17663/18048)
Epoch: 200 | Batch_idx: 150 |  Loss: (0.0657) |  Loss2: (0.0000) | Acc: (97.00%) (18915/19328)
Epoch: 200 | Batch_idx: 160 |  Loss: (0.0653) |  Loss2: (0.0000) | Acc: (97.00%) (20176/20608)
Epoch: 200 | Batch_idx: 170 |  Loss: (0.0663) |  Loss2: (0.0000) | Acc: (97.00%) (21417/21888)
Epoch: 200 | Batch_idx: 180 |  Loss: (0.0664) |  Loss2: (0.0000) | Acc: (97.00%) (22662/23168)
Epoch: 200 | Batch_idx: 190 |  Loss: (0.0662) |  Loss2: (0.0000) | Acc: (97.00%) (23915/24448)
Epoch: 200 | Batch_idx: 200 |  Loss: (0.0665) |  Loss2: (0.0000) | Acc: (97.00%) (25160/25728)
Epoch: 200 | Batch_idx: 210 |  Loss: (0.0667) |  Loss2: (0.0000) | Acc: (97.00%) (26402/27008)
Epoch: 200 | Batch_idx: 220 |  Loss: (0.0665) |  Loss2: (0.0000) | Acc: (97.00%) (27654/28288)
Epoch: 200 | Batch_idx: 230 |  Loss: (0.0660) |  Loss2: (0.0000) | Acc: (97.00%) (28912/29568)
Epoch: 200 | Batch_idx: 240 |  Loss: (0.0662) |  Loss2: (0.0000) | Acc: (97.00%) (30157/30848)
Epoch: 200 | Batch_idx: 250 |  Loss: (0.0662) |  Loss2: (0.0000) | Acc: (97.00%) (31414/32128)
Epoch: 200 | Batch_idx: 260 |  Loss: (0.0663) |  Loss2: (0.0000) | Acc: (97.00%) (32666/33408)
Epoch: 200 | Batch_idx: 270 |  Loss: (0.0666) |  Loss2: (0.0000) | Acc: (97.00%) (33917/34688)
Epoch: 200 | Batch_idx: 280 |  Loss: (0.0666) |  Loss2: (0.0000) | Acc: (97.00%) (35166/35968)
Epoch: 200 | Batch_idx: 290 |  Loss: (0.0668) |  Loss2: (0.0000) | Acc: (97.00%) (36421/37248)
Epoch: 200 | Batch_idx: 300 |  Loss: (0.0676) |  Loss2: (0.0000) | Acc: (97.00%) (37659/38528)
Epoch: 200 | Batch_idx: 310 |  Loss: (0.0679) |  Loss2: (0.0000) | Acc: (97.00%) (38907/39808)
Epoch: 200 | Batch_idx: 320 |  Loss: (0.0684) |  Loss2: (0.0000) | Acc: (97.00%) (40143/41088)
Epoch: 200 | Batch_idx: 330 |  Loss: (0.0683) |  Loss2: (0.0000) | Acc: (97.00%) (41392/42368)
Epoch: 200 | Batch_idx: 340 |  Loss: (0.0685) |  Loss2: (0.0000) | Acc: (97.00%) (42637/43648)
Epoch: 200 | Batch_idx: 350 |  Loss: (0.0688) |  Loss2: (0.0000) | Acc: (97.00%) (43879/44928)
Epoch: 200 | Batch_idx: 360 |  Loss: (0.0688) |  Loss2: (0.0000) | Acc: (97.00%) (45132/46208)
Epoch: 200 | Batch_idx: 370 |  Loss: (0.0684) |  Loss2: (0.0000) | Acc: (97.00%) (46392/47488)
Epoch: 200 | Batch_idx: 380 |  Loss: (0.0682) |  Loss2: (0.0000) | Acc: (97.00%) (47644/48768)
Epoch: 200 | Batch_idx: 390 |  Loss: (0.0684) |  Loss2: (0.0000) | Acc: (97.00%) (48844/50000)
=> saving checkpoint 'drive/app/torch/save_Schedule/checkpoint_200.pth.tar'
# TEST : Loss: (0.4278) | Acc: (88.00%) (8849/10000)
percent tensor([0.5733, 0.5849, 0.5769, 0.5742, 0.5813, 0.5874, 0.5861, 0.5706, 0.5713,
        0.5793, 0.5796, 0.5831, 0.5751, 0.5694, 0.5888, 0.5777],
       device='cuda:0') torch.Size([16])
percent tensor([0.5303, 0.5331, 0.5214, 0.5267, 0.5207, 0.5350, 0.5284, 0.5219, 0.5240,
        0.5291, 0.5332, 0.5234, 0.5294, 0.5297, 0.5330, 0.5317],
       device='cuda:0') torch.Size([16])
percent tensor([0.5977, 0.4688, 0.7219, 0.7169, 0.7420, 0.6746, 0.5810, 0.6950, 0.6447,
        0.5571, 0.4955, 0.6569, 0.4987, 0.5453, 0.5353, 0.6366],
       device='cuda:0') torch.Size([16])
percent tensor([0.7024, 0.7339, 0.6318, 0.6587, 0.6471, 0.5833, 0.7083, 0.6592, 0.7147,
        0.7350, 0.7459, 0.6961, 0.7181, 0.7473, 0.6849, 0.6807],
       device='cuda:0') torch.Size([16])
percent tensor([0.7455, 0.6455, 0.7781, 0.7690, 0.7789, 0.8426, 0.7251, 0.7580, 0.7015,
        0.6119, 0.6076, 0.6456, 0.5954, 0.6835, 0.7255, 0.7870],
       device='cuda:0') torch.Size([16])
percent tensor([0.6326, 0.7578, 0.7419, 0.8043, 0.7531, 0.8208, 0.7160, 0.5390, 0.7411,
        0.7297, 0.7975, 0.7667, 0.7503, 0.7787, 0.5988, 0.5961],
       device='cuda:0') torch.Size([16])
percent tensor([0.3881, 0.7380, 0.6601, 0.6537, 0.6255, 0.6355, 0.6439, 0.5659, 0.6388,
        0.6523, 0.7456, 0.6603, 0.6522, 0.6054, 0.5927, 0.3684],
       device='cuda:0') torch.Size([16])
percent tensor([0.9998, 0.9999, 0.9998, 0.9999, 1.0000, 0.9995, 0.9999, 0.9996, 0.9999,
        0.9999, 0.9999, 0.9999, 0.9996, 0.9997, 0.9998, 0.9996],
       device='cuda:0') torch.Size([16])
Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 3, 3, 3]) tensor(185.9886, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(822.9244, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(834.7869, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([128, 64, 3, 3]) tensor(1508.3307, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([128, 64, 1, 1]) tensor(482.4399, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([128, 128, 3, 3]) tensor(2286.7766, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([256, 128, 3, 3]) tensor(4265.8545, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([256, 128, 1, 1]) tensor(1352.0171, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([256, 256, 3, 3]) tensor(6273.9775, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([512, 256, 3, 3]) tensor(11536.8330, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([512, 256, 1, 1]) tensor(3793.0815, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([512, 512, 3, 3]) tensor(15976.0352, device='cuda:0', grad_fn=<NormBackward0>)
Epoch: 201 | Batch_idx: 0 |  Loss: (0.0536) |  Loss2: (0.0000) | Acc: (97.00%) (125/128)
Epoch: 201 | Batch_idx: 10 |  Loss: (0.0686) |  Loss2: (0.0000) | Acc: (97.00%) (1377/1408)
Epoch: 201 | Batch_idx: 20 |  Loss: (0.0722) |  Loss2: (0.0000) | Acc: (97.00%) (2623/2688)
Epoch: 201 | Batch_idx: 30 |  Loss: (0.0718) |  Loss2: (0.0000) | Acc: (97.00%) (3868/3968)
Epoch: 201 | Batch_idx: 40 |  Loss: (0.0721) |  Loss2: (0.0000) | Acc: (97.00%) (5119/5248)
Epoch: 201 | Batch_idx: 50 |  Loss: (0.0703) |  Loss2: (0.0000) | Acc: (97.00%) (6375/6528)
Epoch: 201 | Batch_idx: 60 |  Loss: (0.0685) |  Loss2: (0.0000) | Acc: (97.00%) (7630/7808)
Epoch: 201 | Batch_idx: 70 |  Loss: (0.0680) |  Loss2: (0.0000) | Acc: (97.00%) (8879/9088)
Epoch: 201 | Batch_idx: 80 |  Loss: (0.0686) |  Loss2: (0.0000) | Acc: (97.00%) (10132/10368)
Epoch: 201 | Batch_idx: 90 |  Loss: (0.0679) |  Loss2: (0.0000) | Acc: (97.00%) (11386/11648)
Epoch: 201 | Batch_idx: 100 |  Loss: (0.0681) |  Loss2: (0.0000) | Acc: (97.00%) (12640/12928)
Epoch: 201 | Batch_idx: 110 |  Loss: (0.0690) |  Loss2: (0.0000) | Acc: (97.00%) (13886/14208)
Epoch: 201 | Batch_idx: 120 |  Loss: (0.0690) |  Loss2: (0.0000) | Acc: (97.00%) (15133/15488)
Epoch: 201 | Batch_idx: 130 |  Loss: (0.0695) |  Loss2: (0.0000) | Acc: (97.00%) (16377/16768)
Epoch: 201 | Batch_idx: 140 |  Loss: (0.0695) |  Loss2: (0.0000) | Acc: (97.00%) (17623/18048)
Epoch: 201 | Batch_idx: 150 |  Loss: (0.0697) |  Loss2: (0.0000) | Acc: (97.00%) (18875/19328)
Epoch: 201 | Batch_idx: 160 |  Loss: (0.0693) |  Loss2: (0.0000) | Acc: (97.00%) (20129/20608)
Epoch: 201 | Batch_idx: 170 |  Loss: (0.0697) |  Loss2: (0.0000) | Acc: (97.00%) (21382/21888)
Epoch: 201 | Batch_idx: 180 |  Loss: (0.0703) |  Loss2: (0.0000) | Acc: (97.00%) (22621/23168)
Epoch: 201 | Batch_idx: 190 |  Loss: (0.0704) |  Loss2: (0.0000) | Acc: (97.00%) (23866/24448)
Epoch: 201 | Batch_idx: 200 |  Loss: (0.0706) |  Loss2: (0.0000) | Acc: (97.00%) (25111/25728)
Epoch: 201 | Batch_idx: 210 |  Loss: (0.0699) |  Loss2: (0.0000) | Acc: (97.00%) (26369/27008)
Epoch: 201 | Batch_idx: 220 |  Loss: (0.0696) |  Loss2: (0.0000) | Acc: (97.00%) (27619/28288)
Epoch: 201 | Batch_idx: 230 |  Loss: (0.0704) |  Loss2: (0.0000) | Acc: (97.00%) (28856/29568)
Epoch: 201 | Batch_idx: 240 |  Loss: (0.0703) |  Loss2: (0.0000) | Acc: (97.00%) (30108/30848)
Epoch: 201 | Batch_idx: 250 |  Loss: (0.0702) |  Loss2: (0.0000) | Acc: (97.00%) (31359/32128)
Epoch: 201 | Batch_idx: 260 |  Loss: (0.0697) |  Loss2: (0.0000) | Acc: (97.00%) (32615/33408)
Epoch: 201 | Batch_idx: 270 |  Loss: (0.0694) |  Loss2: (0.0000) | Acc: (97.00%) (33867/34688)
Epoch: 201 | Batch_idx: 280 |  Loss: (0.0697) |  Loss2: (0.0000) | Acc: (97.00%) (35115/35968)
Epoch: 201 | Batch_idx: 290 |  Loss: (0.0703) |  Loss2: (0.0000) | Acc: (97.00%) (36359/37248)
Epoch: 201 | Batch_idx: 300 |  Loss: (0.0703) |  Loss2: (0.0000) | Acc: (97.00%) (37612/38528)
Epoch: 201 | Batch_idx: 310 |  Loss: (0.0711) |  Loss2: (0.0000) | Acc: (97.00%) (38846/39808)
Epoch: 201 | Batch_idx: 320 |  Loss: (0.0707) |  Loss2: (0.0000) | Acc: (97.00%) (40096/41088)
Epoch: 201 | Batch_idx: 330 |  Loss: (0.0704) |  Loss2: (0.0000) | Acc: (97.00%) (41351/42368)
Epoch: 201 | Batch_idx: 340 |  Loss: (0.0705) |  Loss2: (0.0000) | Acc: (97.00%) (42596/43648)
Epoch: 201 | Batch_idx: 350 |  Loss: (0.0706) |  Loss2: (0.0000) | Acc: (97.00%) (43844/44928)
Epoch: 201 | Batch_idx: 360 |  Loss: (0.0706) |  Loss2: (0.0000) | Acc: (97.00%) (45091/46208)
Epoch: 201 | Batch_idx: 370 |  Loss: (0.0703) |  Loss2: (0.0000) | Acc: (97.00%) (46344/47488)
Epoch: 201 | Batch_idx: 380 |  Loss: (0.0706) |  Loss2: (0.0000) | Acc: (97.00%) (47594/48768)
Epoch: 201 | Batch_idx: 390 |  Loss: (0.0706) |  Loss2: (0.0000) | Acc: (97.00%) (48795/50000)
# TEST : Loss: (0.4525) | Acc: (88.00%) (8810/10000)
percent tensor([0.5736, 0.5855, 0.5766, 0.5736, 0.5815, 0.5875, 0.5870, 0.5711, 0.5720,
        0.5798, 0.5798, 0.5838, 0.5758, 0.5695, 0.5891, 0.5779],
       device='cuda:0') torch.Size([16])
percent tensor([0.5315, 0.5336, 0.5228, 0.5277, 0.5230, 0.5364, 0.5298, 0.5223, 0.5246,
        0.5298, 0.5343, 0.5250, 0.5301, 0.5299, 0.5341, 0.5325],
       device='cuda:0') torch.Size([16])
percent tensor([0.5968, 0.4586, 0.7251, 0.7174, 0.7363, 0.6691, 0.5625, 0.6950, 0.6395,
        0.5487, 0.4842, 0.6550, 0.5009, 0.5415, 0.5252, 0.6259],
       device='cuda:0') torch.Size([16])
percent tensor([0.7089, 0.7361, 0.6417, 0.6661, 0.6498, 0.5906, 0.7088, 0.6648, 0.7074,
        0.7367, 0.7494, 0.7020, 0.7217, 0.7448, 0.6868, 0.6877],
       device='cuda:0') torch.Size([16])
percent tensor([0.7515, 0.6425, 0.7828, 0.7664, 0.7898, 0.8456, 0.7322, 0.7506, 0.7133,
        0.6200, 0.6029, 0.6606, 0.6041, 0.6691, 0.7329, 0.7918],
       device='cuda:0') torch.Size([16])
percent tensor([0.6207, 0.7632, 0.7432, 0.8010, 0.7526, 0.8251, 0.7033, 0.5340, 0.7563,
        0.7241, 0.7878, 0.7542, 0.7728, 0.7483, 0.5779, 0.5663],
       device='cuda:0') torch.Size([16])
percent tensor([0.4042, 0.7361, 0.6731, 0.6958, 0.6083, 0.6758, 0.6801, 0.5655, 0.6803,
        0.6484, 0.8025, 0.6519, 0.6711, 0.6508, 0.5845, 0.3795],
       device='cuda:0') torch.Size([16])
percent tensor([0.9998, 0.9999, 0.9998, 0.9999, 0.9999, 0.9996, 0.9999, 0.9994, 0.9999,
        0.9999, 0.9999, 0.9999, 0.9998, 0.9997, 0.9998, 0.9996],
       device='cuda:0') torch.Size([16])
Epoch: 202 | Batch_idx: 0 |  Loss: (0.0780) |  Loss2: (0.0000) | Acc: (96.00%) (124/128)
Epoch: 202 | Batch_idx: 10 |  Loss: (0.0660) |  Loss2: (0.0000) | Acc: (97.00%) (1377/1408)
Epoch: 202 | Batch_idx: 20 |  Loss: (0.0581) |  Loss2: (0.0000) | Acc: (98.00%) (2639/2688)
Epoch: 202 | Batch_idx: 30 |  Loss: (0.0579) |  Loss2: (0.0000) | Acc: (98.00%) (3897/3968)
Epoch: 202 | Batch_idx: 40 |  Loss: (0.0630) |  Loss2: (0.0000) | Acc: (97.00%) (5142/5248)
Epoch: 202 | Batch_idx: 50 |  Loss: (0.0641) |  Loss2: (0.0000) | Acc: (97.00%) (6389/6528)
Epoch: 202 | Batch_idx: 60 |  Loss: (0.0639) |  Loss2: (0.0000) | Acc: (97.00%) (7640/7808)
Epoch: 202 | Batch_idx: 70 |  Loss: (0.0635) |  Loss2: (0.0000) | Acc: (97.00%) (8894/9088)
Epoch: 202 | Batch_idx: 80 |  Loss: (0.0643) |  Loss2: (0.0000) | Acc: (97.00%) (10142/10368)
Epoch: 202 | Batch_idx: 90 |  Loss: (0.0641) |  Loss2: (0.0000) | Acc: (97.00%) (11395/11648)
Epoch: 202 | Batch_idx: 100 |  Loss: (0.0639) |  Loss2: (0.0000) | Acc: (97.00%) (12650/12928)
Epoch: 202 | Batch_idx: 110 |  Loss: (0.0650) |  Loss2: (0.0000) | Acc: (97.00%) (13895/14208)
Epoch: 202 | Batch_idx: 120 |  Loss: (0.0649) |  Loss2: (0.0000) | Acc: (97.00%) (15148/15488)
Epoch: 202 | Batch_idx: 130 |  Loss: (0.0657) |  Loss2: (0.0000) | Acc: (97.00%) (16393/16768)
Epoch: 202 | Batch_idx: 140 |  Loss: (0.0669) |  Loss2: (0.0000) | Acc: (97.00%) (17636/18048)
Epoch: 202 | Batch_idx: 150 |  Loss: (0.0659) |  Loss2: (0.0000) | Acc: (97.00%) (18898/19328)
Epoch: 202 | Batch_idx: 160 |  Loss: (0.0663) |  Loss2: (0.0000) | Acc: (97.00%) (20150/20608)
Epoch: 202 | Batch_idx: 170 |  Loss: (0.0672) |  Loss2: (0.0000) | Acc: (97.00%) (21391/21888)
Epoch: 202 | Batch_idx: 180 |  Loss: (0.0670) |  Loss2: (0.0000) | Acc: (97.00%) (22648/23168)
Epoch: 202 | Batch_idx: 190 |  Loss: (0.0674) |  Loss2: (0.0000) | Acc: (97.00%) (23896/24448)
Epoch: 202 | Batch_idx: 200 |  Loss: (0.0676) |  Loss2: (0.0000) | Acc: (97.00%) (25139/25728)
Epoch: 202 | Batch_idx: 210 |  Loss: (0.0683) |  Loss2: (0.0000) | Acc: (97.00%) (26385/27008)
Epoch: 202 | Batch_idx: 220 |  Loss: (0.0685) |  Loss2: (0.0000) | Acc: (97.00%) (27637/28288)
Epoch: 202 | Batch_idx: 230 |  Loss: (0.0679) |  Loss2: (0.0000) | Acc: (97.00%) (28894/29568)
Epoch: 202 | Batch_idx: 240 |  Loss: (0.0679) |  Loss2: (0.0000) | Acc: (97.00%) (30143/30848)
Epoch: 202 | Batch_idx: 250 |  Loss: (0.0680) |  Loss2: (0.0000) | Acc: (97.00%) (31395/32128)
Epoch: 202 | Batch_idx: 260 |  Loss: (0.0685) |  Loss2: (0.0000) | Acc: (97.00%) (32646/33408)
Epoch: 202 | Batch_idx: 270 |  Loss: (0.0684) |  Loss2: (0.0000) | Acc: (97.00%) (33902/34688)
Epoch: 202 | Batch_idx: 280 |  Loss: (0.0686) |  Loss2: (0.0000) | Acc: (97.00%) (35146/35968)
Epoch: 202 | Batch_idx: 290 |  Loss: (0.0683) |  Loss2: (0.0000) | Acc: (97.00%) (36400/37248)
Epoch: 202 | Batch_idx: 300 |  Loss: (0.0683) |  Loss2: (0.0000) | Acc: (97.00%) (37654/38528)
Epoch: 202 | Batch_idx: 310 |  Loss: (0.0682) |  Loss2: (0.0000) | Acc: (97.00%) (38909/39808)
Epoch: 202 | Batch_idx: 320 |  Loss: (0.0684) |  Loss2: (0.0000) | Acc: (97.00%) (40165/41088)
Epoch: 202 | Batch_idx: 330 |  Loss: (0.0682) |  Loss2: (0.0000) | Acc: (97.00%) (41416/42368)
Epoch: 202 | Batch_idx: 340 |  Loss: (0.0683) |  Loss2: (0.0000) | Acc: (97.00%) (42666/43648)
Epoch: 202 | Batch_idx: 350 |  Loss: (0.0686) |  Loss2: (0.0000) | Acc: (97.00%) (43911/44928)
Epoch: 202 | Batch_idx: 360 |  Loss: (0.0689) |  Loss2: (0.0000) | Acc: (97.00%) (45152/46208)
Epoch: 202 | Batch_idx: 370 |  Loss: (0.0691) |  Loss2: (0.0000) | Acc: (97.00%) (46402/47488)
Epoch: 202 | Batch_idx: 380 |  Loss: (0.0690) |  Loss2: (0.0000) | Acc: (97.00%) (47659/48768)
Epoch: 202 | Batch_idx: 390 |  Loss: (0.0693) |  Loss2: (0.0000) | Acc: (97.00%) (48854/50000)
# TEST : Loss: (0.4483) | Acc: (88.00%) (8843/10000)
percent tensor([0.5744, 0.5867, 0.5771, 0.5744, 0.5816, 0.5891, 0.5868, 0.5715, 0.5730,
        0.5802, 0.5809, 0.5835, 0.5764, 0.5712, 0.5903, 0.5791],
       device='cuda:0') torch.Size([16])
percent tensor([0.5314, 0.5333, 0.5223, 0.5279, 0.5226, 0.5351, 0.5289, 0.5227, 0.5239,
        0.5298, 0.5339, 0.5249, 0.5301, 0.5303, 0.5336, 0.5322],
       device='cuda:0') torch.Size([16])
percent tensor([0.5815, 0.4541, 0.7218, 0.7163, 0.7288, 0.6664, 0.5519, 0.6919, 0.6272,
        0.5398, 0.4741, 0.6438, 0.4807, 0.5320, 0.5152, 0.6213],
       device='cuda:0') torch.Size([16])
percent tensor([0.7098, 0.7426, 0.6383, 0.6636, 0.6490, 0.5850, 0.7138, 0.6686, 0.7159,
        0.7428, 0.7547, 0.7036, 0.7258, 0.7521, 0.6894, 0.6884],
       device='cuda:0') torch.Size([16])
percent tensor([0.7507, 0.6454, 0.7722, 0.7666, 0.7815, 0.8438, 0.7342, 0.7512, 0.7049,
        0.6091, 0.5946, 0.6269, 0.6063, 0.6778, 0.7333, 0.7877],
       device='cuda:0') torch.Size([16])
percent tensor([0.6460, 0.7566, 0.7691, 0.8021, 0.7540, 0.8169, 0.7528, 0.5793, 0.7443,
        0.7315, 0.7919, 0.7675, 0.7514, 0.7727, 0.6028, 0.5716],
       device='cuda:0') torch.Size([16])
percent tensor([0.3792, 0.7149, 0.6566, 0.6804, 0.5859, 0.6654, 0.6345, 0.5799, 0.6334,
        0.6229, 0.7470, 0.6563, 0.6197, 0.5937, 0.5483, 0.3633],
       device='cuda:0') torch.Size([16])
percent tensor([0.9998, 0.9999, 0.9998, 0.9999, 1.0000, 0.9993, 1.0000, 0.9996, 0.9998,
        0.9999, 0.9998, 1.0000, 0.9997, 0.9997, 0.9998, 0.9996],
       device='cuda:0') torch.Size([16])
Epoch: 203 | Batch_idx: 0 |  Loss: (0.0780) |  Loss2: (0.0000) | Acc: (96.00%) (124/128)
Epoch: 203 | Batch_idx: 10 |  Loss: (0.0703) |  Loss2: (0.0000) | Acc: (97.00%) (1371/1408)
Epoch: 203 | Batch_idx: 20 |  Loss: (0.0726) |  Loss2: (0.0000) | Acc: (97.00%) (2623/2688)
Epoch: 203 | Batch_idx: 30 |  Loss: (0.0725) |  Loss2: (0.0000) | Acc: (97.00%) (3874/3968)
Epoch: 203 | Batch_idx: 40 |  Loss: (0.0740) |  Loss2: (0.0000) | Acc: (97.00%) (5117/5248)
Epoch: 203 | Batch_idx: 50 |  Loss: (0.0713) |  Loss2: (0.0000) | Acc: (97.00%) (6375/6528)
Epoch: 203 | Batch_idx: 60 |  Loss: (0.0708) |  Loss2: (0.0000) | Acc: (97.00%) (7628/7808)
Epoch: 203 | Batch_idx: 70 |  Loss: (0.0693) |  Loss2: (0.0000) | Acc: (97.00%) (8887/9088)
Epoch: 203 | Batch_idx: 80 |  Loss: (0.0682) |  Loss2: (0.0000) | Acc: (97.00%) (10146/10368)
Epoch: 203 | Batch_idx: 90 |  Loss: (0.0679) |  Loss2: (0.0000) | Acc: (97.00%) (11395/11648)
Epoch: 203 | Batch_idx: 100 |  Loss: (0.0672) |  Loss2: (0.0000) | Acc: (97.00%) (12649/12928)
Epoch: 203 | Batch_idx: 110 |  Loss: (0.0664) |  Loss2: (0.0000) | Acc: (97.00%) (13907/14208)
Epoch: 203 | Batch_idx: 120 |  Loss: (0.0660) |  Loss2: (0.0000) | Acc: (97.00%) (15157/15488)
Epoch: 203 | Batch_idx: 130 |  Loss: (0.0669) |  Loss2: (0.0000) | Acc: (97.00%) (16402/16768)
Epoch: 203 | Batch_idx: 140 |  Loss: (0.0687) |  Loss2: (0.0000) | Acc: (97.00%) (17643/18048)
Epoch: 203 | Batch_idx: 150 |  Loss: (0.0685) |  Loss2: (0.0000) | Acc: (97.00%) (18892/19328)
Epoch: 203 | Batch_idx: 160 |  Loss: (0.0686) |  Loss2: (0.0000) | Acc: (97.00%) (20140/20608)
Epoch: 203 | Batch_idx: 170 |  Loss: (0.0686) |  Loss2: (0.0000) | Acc: (97.00%) (21387/21888)
Epoch: 203 | Batch_idx: 180 |  Loss: (0.0691) |  Loss2: (0.0000) | Acc: (97.00%) (22633/23168)
Epoch: 203 | Batch_idx: 190 |  Loss: (0.0690) |  Loss2: (0.0000) | Acc: (97.00%) (23883/24448)
Epoch: 203 | Batch_idx: 200 |  Loss: (0.0692) |  Loss2: (0.0000) | Acc: (97.00%) (25131/25728)
Epoch: 203 | Batch_idx: 210 |  Loss: (0.0692) |  Loss2: (0.0000) | Acc: (97.00%) (26385/27008)
Epoch: 203 | Batch_idx: 220 |  Loss: (0.0688) |  Loss2: (0.0000) | Acc: (97.00%) (27637/28288)
Epoch: 203 | Batch_idx: 230 |  Loss: (0.0689) |  Loss2: (0.0000) | Acc: (97.00%) (28888/29568)
Epoch: 203 | Batch_idx: 240 |  Loss: (0.0687) |  Loss2: (0.0000) | Acc: (97.00%) (30134/30848)
Epoch: 203 | Batch_idx: 250 |  Loss: (0.0683) |  Loss2: (0.0000) | Acc: (97.00%) (31390/32128)
Epoch: 203 | Batch_idx: 260 |  Loss: (0.0687) |  Loss2: (0.0000) | Acc: (97.00%) (32635/33408)
Epoch: 203 | Batch_idx: 270 |  Loss: (0.0686) |  Loss2: (0.0000) | Acc: (97.00%) (33886/34688)
Epoch: 203 | Batch_idx: 280 |  Loss: (0.0685) |  Loss2: (0.0000) | Acc: (97.00%) (35133/35968)
Epoch: 203 | Batch_idx: 290 |  Loss: (0.0683) |  Loss2: (0.0000) | Acc: (97.00%) (36386/37248)
Epoch: 203 | Batch_idx: 300 |  Loss: (0.0679) |  Loss2: (0.0000) | Acc: (97.00%) (37646/38528)
Epoch: 203 | Batch_idx: 310 |  Loss: (0.0679) |  Loss2: (0.0000) | Acc: (97.00%) (38897/39808)
Epoch: 203 | Batch_idx: 320 |  Loss: (0.0682) |  Loss2: (0.0000) | Acc: (97.00%) (40140/41088)
Epoch: 203 | Batch_idx: 330 |  Loss: (0.0683) |  Loss2: (0.0000) | Acc: (97.00%) (41394/42368)
Epoch: 203 | Batch_idx: 340 |  Loss: (0.0685) |  Loss2: (0.0000) | Acc: (97.00%) (42633/43648)
Epoch: 203 | Batch_idx: 350 |  Loss: (0.0682) |  Loss2: (0.0000) | Acc: (97.00%) (43890/44928)
Epoch: 203 | Batch_idx: 360 |  Loss: (0.0678) |  Loss2: (0.0000) | Acc: (97.00%) (45150/46208)
Epoch: 203 | Batch_idx: 370 |  Loss: (0.0680) |  Loss2: (0.0000) | Acc: (97.00%) (46400/47488)
Epoch: 203 | Batch_idx: 380 |  Loss: (0.0682) |  Loss2: (0.0000) | Acc: (97.00%) (47640/48768)
Epoch: 203 | Batch_idx: 390 |  Loss: (0.0681) |  Loss2: (0.0000) | Acc: (97.00%) (48845/50000)
# TEST : Loss: (0.4402) | Acc: (88.00%) (8830/10000)
percent tensor([0.5748, 0.5879, 0.5761, 0.5751, 0.5820, 0.5898, 0.5883, 0.5717, 0.5730,
        0.5809, 0.5813, 0.5842, 0.5771, 0.5732, 0.5914, 0.5804],
       device='cuda:0') torch.Size([16])
percent tensor([0.5303, 0.5324, 0.5218, 0.5267, 0.5221, 0.5345, 0.5282, 0.5219, 0.5233,
        0.5290, 0.5327, 0.5238, 0.5290, 0.5295, 0.5328, 0.5313],
       device='cuda:0') torch.Size([16])
percent tensor([0.5932, 0.4590, 0.7144, 0.7194, 0.7330, 0.6848, 0.5655, 0.6917, 0.6442,
        0.5391, 0.4943, 0.6350, 0.4903, 0.5457, 0.5315, 0.6335],
       device='cuda:0') torch.Size([16])
percent tensor([0.7090, 0.7465, 0.6392, 0.6596, 0.6417, 0.5882, 0.7150, 0.6701, 0.7097,
        0.7423, 0.7512, 0.7027, 0.7215, 0.7536, 0.6932, 0.6903],
       device='cuda:0') torch.Size([16])
percent tensor([0.7551, 0.6533, 0.7756, 0.7809, 0.7850, 0.8466, 0.7447, 0.7501, 0.7193,
        0.6393, 0.6118, 0.6601, 0.6150, 0.7010, 0.7348, 0.7990],
       device='cuda:0') torch.Size([16])
percent tensor([0.6590, 0.7646, 0.7637, 0.8062, 0.7506, 0.8136, 0.7520, 0.5804, 0.7701,
        0.7578, 0.8130, 0.7778, 0.7821, 0.7925, 0.6079, 0.5782],
       device='cuda:0') torch.Size([16])
percent tensor([0.4206, 0.7429, 0.6618, 0.6288, 0.5870, 0.6281, 0.6641, 0.5794, 0.6779,
        0.6532, 0.7661, 0.6482, 0.6482, 0.6461, 0.5634, 0.3787],
       device='cuda:0') torch.Size([16])
percent tensor([0.9998, 0.9998, 0.9998, 0.9998, 1.0000, 0.9994, 0.9999, 0.9998, 0.9999,
        0.9998, 0.9999, 0.9999, 0.9997, 0.9995, 0.9997, 0.9997],
       device='cuda:0') torch.Size([16])
Epoch: 204 | Batch_idx: 0 |  Loss: (0.0403) |  Loss2: (0.0000) | Acc: (98.00%) (126/128)
Epoch: 204 | Batch_idx: 10 |  Loss: (0.0576) |  Loss2: (0.0000) | Acc: (98.00%) (1381/1408)
Epoch: 204 | Batch_idx: 20 |  Loss: (0.0593) |  Loss2: (0.0000) | Acc: (97.00%) (2632/2688)
Epoch: 204 | Batch_idx: 30 |  Loss: (0.0704) |  Loss2: (0.0000) | Acc: (97.00%) (3865/3968)
Epoch: 204 | Batch_idx: 40 |  Loss: (0.0678) |  Loss2: (0.0000) | Acc: (97.00%) (5126/5248)
Epoch: 204 | Batch_idx: 50 |  Loss: (0.0656) |  Loss2: (0.0000) | Acc: (97.00%) (6376/6528)
Epoch: 204 | Batch_idx: 60 |  Loss: (0.0669) |  Loss2: (0.0000) | Acc: (97.00%) (7622/7808)
Epoch: 204 | Batch_idx: 70 |  Loss: (0.0661) |  Loss2: (0.0000) | Acc: (97.00%) (8871/9088)
Epoch: 204 | Batch_idx: 80 |  Loss: (0.0655) |  Loss2: (0.0000) | Acc: (97.00%) (10127/10368)
Epoch: 204 | Batch_idx: 90 |  Loss: (0.0667) |  Loss2: (0.0000) | Acc: (97.00%) (11368/11648)
Epoch: 204 | Batch_idx: 100 |  Loss: (0.0666) |  Loss2: (0.0000) | Acc: (97.00%) (12623/12928)
Epoch: 204 | Batch_idx: 110 |  Loss: (0.0668) |  Loss2: (0.0000) | Acc: (97.00%) (13873/14208)
Epoch: 204 | Batch_idx: 120 |  Loss: (0.0675) |  Loss2: (0.0000) | Acc: (97.00%) (15120/15488)
Epoch: 204 | Batch_idx: 130 |  Loss: (0.0671) |  Loss2: (0.0000) | Acc: (97.00%) (16375/16768)
Epoch: 204 | Batch_idx: 140 |  Loss: (0.0669) |  Loss2: (0.0000) | Acc: (97.00%) (17630/18048)
Epoch: 204 | Batch_idx: 150 |  Loss: (0.0661) |  Loss2: (0.0000) | Acc: (97.00%) (18886/19328)
Epoch: 204 | Batch_idx: 160 |  Loss: (0.0657) |  Loss2: (0.0000) | Acc: (97.00%) (20140/20608)
Epoch: 204 | Batch_idx: 170 |  Loss: (0.0651) |  Loss2: (0.0000) | Acc: (97.00%) (21397/21888)
Epoch: 204 | Batch_idx: 180 |  Loss: (0.0653) |  Loss2: (0.0000) | Acc: (97.00%) (22651/23168)
Epoch: 204 | Batch_idx: 190 |  Loss: (0.0652) |  Loss2: (0.0000) | Acc: (97.00%) (23902/24448)
Epoch: 204 | Batch_idx: 200 |  Loss: (0.0645) |  Loss2: (0.0000) | Acc: (97.00%) (25160/25728)
Epoch: 204 | Batch_idx: 210 |  Loss: (0.0644) |  Loss2: (0.0000) | Acc: (97.00%) (26411/27008)
Epoch: 204 | Batch_idx: 220 |  Loss: (0.0643) |  Loss2: (0.0000) | Acc: (97.00%) (27661/28288)
Epoch: 204 | Batch_idx: 230 |  Loss: (0.0647) |  Loss2: (0.0000) | Acc: (97.00%) (28912/29568)
Epoch: 204 | Batch_idx: 240 |  Loss: (0.0648) |  Loss2: (0.0000) | Acc: (97.00%) (30163/30848)
Epoch: 204 | Batch_idx: 250 |  Loss: (0.0649) |  Loss2: (0.0000) | Acc: (97.00%) (31411/32128)
Epoch: 204 | Batch_idx: 260 |  Loss: (0.0654) |  Loss2: (0.0000) | Acc: (97.00%) (32658/33408)
Epoch: 204 | Batch_idx: 270 |  Loss: (0.0655) |  Loss2: (0.0000) | Acc: (97.00%) (33910/34688)
Epoch: 204 | Batch_idx: 280 |  Loss: (0.0659) |  Loss2: (0.0000) | Acc: (97.00%) (35159/35968)
Epoch: 204 | Batch_idx: 290 |  Loss: (0.0658) |  Loss2: (0.0000) | Acc: (97.00%) (36410/37248)
Epoch: 204 | Batch_idx: 300 |  Loss: (0.0657) |  Loss2: (0.0000) | Acc: (97.00%) (37667/38528)
Epoch: 204 | Batch_idx: 310 |  Loss: (0.0654) |  Loss2: (0.0000) | Acc: (97.00%) (38925/39808)
Epoch: 204 | Batch_idx: 320 |  Loss: (0.0656) |  Loss2: (0.0000) | Acc: (97.00%) (40183/41088)
Epoch: 204 | Batch_idx: 330 |  Loss: (0.0660) |  Loss2: (0.0000) | Acc: (97.00%) (41430/42368)
Epoch: 204 | Batch_idx: 340 |  Loss: (0.0665) |  Loss2: (0.0000) | Acc: (97.00%) (42676/43648)
Epoch: 204 | Batch_idx: 350 |  Loss: (0.0666) |  Loss2: (0.0000) | Acc: (97.00%) (43930/44928)
Epoch: 204 | Batch_idx: 360 |  Loss: (0.0670) |  Loss2: (0.0000) | Acc: (97.00%) (45173/46208)
Epoch: 204 | Batch_idx: 370 |  Loss: (0.0670) |  Loss2: (0.0000) | Acc: (97.00%) (46421/47488)
Epoch: 204 | Batch_idx: 380 |  Loss: (0.0673) |  Loss2: (0.0000) | Acc: (97.00%) (47668/48768)
Epoch: 204 | Batch_idx: 390 |  Loss: (0.0680) |  Loss2: (0.0000) | Acc: (97.00%) (48861/50000)
# TEST : Loss: (0.4429) | Acc: (88.00%) (8843/10000)
percent tensor([0.5752, 0.5878, 0.5784, 0.5756, 0.5830, 0.5905, 0.5888, 0.5728, 0.5739,
        0.5819, 0.5823, 0.5855, 0.5774, 0.5731, 0.5913, 0.5804],
       device='cuda:0') torch.Size([16])
percent tensor([0.5325, 0.5343, 0.5235, 0.5290, 0.5248, 0.5373, 0.5301, 0.5232, 0.5257,
        0.5306, 0.5350, 0.5256, 0.5311, 0.5309, 0.5351, 0.5333],
       device='cuda:0') torch.Size([16])
percent tensor([0.5882, 0.4620, 0.7220, 0.7169, 0.7321, 0.6709, 0.5752, 0.6960, 0.6359,
        0.5375, 0.4864, 0.6440, 0.4859, 0.5616, 0.5219, 0.6276],
       device='cuda:0') torch.Size([16])
percent tensor([0.7076, 0.7502, 0.6304, 0.6598, 0.6378, 0.5820, 0.7126, 0.6642, 0.7156,
        0.7448, 0.7561, 0.7024, 0.7283, 0.7545, 0.6895, 0.6828],
       device='cuda:0') torch.Size([16])
percent tensor([0.7574, 0.6537, 0.7885, 0.7812, 0.7941, 0.8541, 0.7451, 0.7613, 0.7003,
        0.6290, 0.6065, 0.6519, 0.5973, 0.6891, 0.7449, 0.7954],
       device='cuda:0') torch.Size([16])
percent tensor([0.6807, 0.7643, 0.7931, 0.8157, 0.7802, 0.8407, 0.7758, 0.6119, 0.7745,
        0.7568, 0.8084, 0.7959, 0.7877, 0.7920, 0.6524, 0.6303],
       device='cuda:0') torch.Size([16])
percent tensor([0.4138, 0.7335, 0.6565, 0.6769, 0.6059, 0.6576, 0.6666, 0.6096, 0.6998,
        0.6573, 0.7652, 0.6783, 0.6775, 0.6427, 0.5950, 0.3923],
       device='cuda:0') torch.Size([16])
percent tensor([0.9998, 0.9999, 0.9997, 0.9999, 1.0000, 0.9997, 0.9999, 0.9994, 0.9999,
        0.9999, 0.9999, 1.0000, 0.9998, 0.9994, 0.9998, 0.9995],
       device='cuda:0') torch.Size([16])
Epoch: 205 | Batch_idx: 0 |  Loss: (0.0621) |  Loss2: (0.0000) | Acc: (98.00%) (126/128)
Epoch: 205 | Batch_idx: 10 |  Loss: (0.0572) |  Loss2: (0.0000) | Acc: (98.00%) (1380/1408)
Epoch: 205 | Batch_idx: 20 |  Loss: (0.0576) |  Loss2: (0.0000) | Acc: (97.00%) (2634/2688)
Epoch: 205 | Batch_idx: 30 |  Loss: (0.0547) |  Loss2: (0.0000) | Acc: (98.00%) (3900/3968)
Epoch: 205 | Batch_idx: 40 |  Loss: (0.0545) |  Loss2: (0.0000) | Acc: (98.00%) (5159/5248)
Epoch: 205 | Batch_idx: 50 |  Loss: (0.0549) |  Loss2: (0.0000) | Acc: (98.00%) (6416/6528)
Epoch: 205 | Batch_idx: 60 |  Loss: (0.0557) |  Loss2: (0.0000) | Acc: (98.00%) (7674/7808)
Epoch: 205 | Batch_idx: 70 |  Loss: (0.0565) |  Loss2: (0.0000) | Acc: (98.00%) (8924/9088)
Epoch: 205 | Batch_idx: 80 |  Loss: (0.0568) |  Loss2: (0.0000) | Acc: (98.00%) (10181/10368)
Epoch: 205 | Batch_idx: 90 |  Loss: (0.0573) |  Loss2: (0.0000) | Acc: (98.00%) (11430/11648)
Epoch: 205 | Batch_idx: 100 |  Loss: (0.0574) |  Loss2: (0.0000) | Acc: (98.00%) (12691/12928)
Epoch: 205 | Batch_idx: 110 |  Loss: (0.0574) |  Loss2: (0.0000) | Acc: (98.00%) (13947/14208)
Epoch: 205 | Batch_idx: 120 |  Loss: (0.0575) |  Loss2: (0.0000) | Acc: (98.00%) (15205/15488)
Epoch: 205 | Batch_idx: 130 |  Loss: (0.0579) |  Loss2: (0.0000) | Acc: (98.00%) (16454/16768)
Epoch: 205 | Batch_idx: 140 |  Loss: (0.0582) |  Loss2: (0.0000) | Acc: (98.00%) (17715/18048)
Epoch: 205 | Batch_idx: 150 |  Loss: (0.0577) |  Loss2: (0.0000) | Acc: (98.00%) (18975/19328)
Epoch: 205 | Batch_idx: 160 |  Loss: (0.0575) |  Loss2: (0.0000) | Acc: (98.00%) (20229/20608)
Epoch: 205 | Batch_idx: 170 |  Loss: (0.0568) |  Loss2: (0.0000) | Acc: (98.00%) (21491/21888)
Epoch: 205 | Batch_idx: 180 |  Loss: (0.0568) |  Loss2: (0.0000) | Acc: (98.00%) (22749/23168)
Epoch: 205 | Batch_idx: 190 |  Loss: (0.0568) |  Loss2: (0.0000) | Acc: (98.00%) (23998/24448)
Epoch: 205 | Batch_idx: 200 |  Loss: (0.0569) |  Loss2: (0.0000) | Acc: (98.00%) (25254/25728)
Epoch: 205 | Batch_idx: 210 |  Loss: (0.0571) |  Loss2: (0.0000) | Acc: (98.00%) (26503/27008)
Epoch: 205 | Batch_idx: 220 |  Loss: (0.0579) |  Loss2: (0.0000) | Acc: (98.00%) (27753/28288)
Epoch: 205 | Batch_idx: 230 |  Loss: (0.0583) |  Loss2: (0.0000) | Acc: (98.00%) (29004/29568)
Epoch: 205 | Batch_idx: 240 |  Loss: (0.0589) |  Loss2: (0.0000) | Acc: (98.00%) (30245/30848)
Epoch: 205 | Batch_idx: 250 |  Loss: (0.0592) |  Loss2: (0.0000) | Acc: (98.00%) (31494/32128)
Epoch: 205 | Batch_idx: 260 |  Loss: (0.0594) |  Loss2: (0.0000) | Acc: (98.00%) (32749/33408)
Epoch: 205 | Batch_idx: 270 |  Loss: (0.0586) |  Loss2: (0.0000) | Acc: (98.00%) (34012/34688)
Epoch: 205 | Batch_idx: 280 |  Loss: (0.0583) |  Loss2: (0.0000) | Acc: (98.00%) (35275/35968)
Epoch: 205 | Batch_idx: 290 |  Loss: (0.0587) |  Loss2: (0.0000) | Acc: (98.00%) (36524/37248)
Epoch: 205 | Batch_idx: 300 |  Loss: (0.0590) |  Loss2: (0.0000) | Acc: (98.00%) (37778/38528)
Epoch: 205 | Batch_idx: 310 |  Loss: (0.0591) |  Loss2: (0.0000) | Acc: (98.00%) (39034/39808)
Epoch: 205 | Batch_idx: 320 |  Loss: (0.0593) |  Loss2: (0.0000) | Acc: (98.00%) (40282/41088)
Epoch: 205 | Batch_idx: 330 |  Loss: (0.0596) |  Loss2: (0.0000) | Acc: (98.00%) (41530/42368)
Epoch: 205 | Batch_idx: 340 |  Loss: (0.0593) |  Loss2: (0.0000) | Acc: (98.00%) (42792/43648)
Epoch: 205 | Batch_idx: 350 |  Loss: (0.0599) |  Loss2: (0.0000) | Acc: (98.00%) (44038/44928)
Epoch: 205 | Batch_idx: 360 |  Loss: (0.0600) |  Loss2: (0.0000) | Acc: (98.00%) (45291/46208)
Epoch: 205 | Batch_idx: 370 |  Loss: (0.0604) |  Loss2: (0.0000) | Acc: (97.00%) (46534/47488)
Epoch: 205 | Batch_idx: 380 |  Loss: (0.0606) |  Loss2: (0.0000) | Acc: (97.00%) (47786/48768)
Epoch: 205 | Batch_idx: 390 |  Loss: (0.0608) |  Loss2: (0.0000) | Acc: (97.00%) (48989/50000)
=> saving checkpoint 'drive/app/torch/save_Schedule/checkpoint_205.pth.tar'
# TEST : Loss: (0.4343) | Acc: (88.00%) (8856/10000)
percent tensor([0.5736, 0.5859, 0.5784, 0.5740, 0.5825, 0.5893, 0.5876, 0.5712, 0.5729,
        0.5804, 0.5800, 0.5853, 0.5756, 0.5713, 0.5897, 0.5784],
       device='cuda:0') torch.Size([16])
percent tensor([0.5329, 0.5357, 0.5240, 0.5297, 0.5238, 0.5362, 0.5306, 0.5243, 0.5257,
        0.5315, 0.5357, 0.5258, 0.5315, 0.5320, 0.5351, 0.5340],
       device='cuda:0') torch.Size([16])
percent tensor([0.5952, 0.4630, 0.7225, 0.7220, 0.7366, 0.6865, 0.5744, 0.6936, 0.6304,
        0.5382, 0.4894, 0.6494, 0.4916, 0.5522, 0.5356, 0.6322],
       device='cuda:0') torch.Size([16])
percent tensor([0.7142, 0.7483, 0.6408, 0.6727, 0.6507, 0.5909, 0.7189, 0.6685, 0.7192,
        0.7478, 0.7574, 0.7079, 0.7293, 0.7562, 0.6947, 0.6921],
       device='cuda:0') torch.Size([16])
percent tensor([0.7541, 0.6491, 0.7776, 0.7746, 0.7842, 0.8457, 0.7389, 0.7629, 0.7032,
        0.6243, 0.5984, 0.6522, 0.6121, 0.6829, 0.7331, 0.7934],
       device='cuda:0') torch.Size([16])
percent tensor([0.6767, 0.7808, 0.7777, 0.8186, 0.7761, 0.8300, 0.7475, 0.5816, 0.7725,
        0.7417, 0.7968, 0.7940, 0.7736, 0.7985, 0.6331, 0.6087],
       device='cuda:0') torch.Size([16])
percent tensor([0.4478, 0.7268, 0.6942, 0.6766, 0.6248, 0.6633, 0.6709, 0.6023, 0.6872,
        0.6647, 0.7624, 0.6715, 0.6436, 0.6409, 0.5744, 0.3999],
       device='cuda:0') torch.Size([16])
percent tensor([0.9999, 0.9998, 0.9999, 0.9999, 1.0000, 0.9995, 0.9999, 0.9997, 0.9999,
        0.9999, 0.9998, 1.0000, 0.9998, 0.9992, 0.9997, 0.9995],
       device='cuda:0') torch.Size([16])
Epoch: 206 | Batch_idx: 0 |  Loss: (0.0948) |  Loss2: (0.0000) | Acc: (96.00%) (123/128)
Epoch: 206 | Batch_idx: 10 |  Loss: (0.0714) |  Loss2: (0.0000) | Acc: (97.00%) (1376/1408)
Epoch: 206 | Batch_idx: 20 |  Loss: (0.0617) |  Loss2: (0.0000) | Acc: (97.00%) (2633/2688)
Epoch: 206 | Batch_idx: 30 |  Loss: (0.0591) |  Loss2: (0.0000) | Acc: (97.00%) (3886/3968)
Epoch: 206 | Batch_idx: 40 |  Loss: (0.0591) |  Loss2: (0.0000) | Acc: (98.00%) (5148/5248)
Epoch: 206 | Batch_idx: 50 |  Loss: (0.0590) |  Loss2: (0.0000) | Acc: (98.00%) (6398/6528)
Epoch: 206 | Batch_idx: 60 |  Loss: (0.0574) |  Loss2: (0.0000) | Acc: (98.00%) (7658/7808)
Epoch: 206 | Batch_idx: 70 |  Loss: (0.0578) |  Loss2: (0.0000) | Acc: (98.00%) (8914/9088)
Epoch: 206 | Batch_idx: 80 |  Loss: (0.0576) |  Loss2: (0.0000) | Acc: (98.00%) (10169/10368)
Epoch: 206 | Batch_idx: 90 |  Loss: (0.0566) |  Loss2: (0.0000) | Acc: (98.00%) (11433/11648)
Epoch: 206 | Batch_idx: 100 |  Loss: (0.0564) |  Loss2: (0.0000) | Acc: (98.00%) (12694/12928)
Epoch: 206 | Batch_idx: 110 |  Loss: (0.0558) |  Loss2: (0.0000) | Acc: (98.00%) (13953/14208)
Epoch: 206 | Batch_idx: 120 |  Loss: (0.0555) |  Loss2: (0.0000) | Acc: (98.00%) (15213/15488)
Epoch: 206 | Batch_idx: 130 |  Loss: (0.0560) |  Loss2: (0.0000) | Acc: (98.00%) (16465/16768)
Epoch: 206 | Batch_idx: 140 |  Loss: (0.0565) |  Loss2: (0.0000) | Acc: (98.00%) (17716/18048)
Epoch: 206 | Batch_idx: 150 |  Loss: (0.0564) |  Loss2: (0.0000) | Acc: (98.00%) (18973/19328)
Epoch: 206 | Batch_idx: 160 |  Loss: (0.0564) |  Loss2: (0.0000) | Acc: (98.00%) (20231/20608)
Epoch: 206 | Batch_idx: 170 |  Loss: (0.0566) |  Loss2: (0.0000) | Acc: (98.00%) (21483/21888)
Epoch: 206 | Batch_idx: 180 |  Loss: (0.0573) |  Loss2: (0.0000) | Acc: (98.00%) (22730/23168)
Epoch: 206 | Batch_idx: 190 |  Loss: (0.0579) |  Loss2: (0.0000) | Acc: (98.00%) (23982/24448)
Epoch: 206 | Batch_idx: 200 |  Loss: (0.0590) |  Loss2: (0.0000) | Acc: (98.00%) (25224/25728)
Epoch: 206 | Batch_idx: 210 |  Loss: (0.0596) |  Loss2: (0.0000) | Acc: (98.00%) (26475/27008)
Epoch: 206 | Batch_idx: 220 |  Loss: (0.0595) |  Loss2: (0.0000) | Acc: (98.00%) (27733/28288)
Epoch: 206 | Batch_idx: 230 |  Loss: (0.0594) |  Loss2: (0.0000) | Acc: (98.00%) (28991/29568)
Epoch: 206 | Batch_idx: 240 |  Loss: (0.0591) |  Loss2: (0.0000) | Acc: (98.00%) (30250/30848)
Epoch: 206 | Batch_idx: 250 |  Loss: (0.0591) |  Loss2: (0.0000) | Acc: (98.00%) (31504/32128)
Epoch: 206 | Batch_idx: 260 |  Loss: (0.0597) |  Loss2: (0.0000) | Acc: (98.00%) (32752/33408)
Epoch: 206 | Batch_idx: 270 |  Loss: (0.0604) |  Loss2: (0.0000) | Acc: (97.00%) (33994/34688)
Epoch: 206 | Batch_idx: 280 |  Loss: (0.0605) |  Loss2: (0.0000) | Acc: (97.00%) (35246/35968)
Epoch: 206 | Batch_idx: 290 |  Loss: (0.0603) |  Loss2: (0.0000) | Acc: (97.00%) (36499/37248)
Epoch: 206 | Batch_idx: 300 |  Loss: (0.0605) |  Loss2: (0.0000) | Acc: (97.00%) (37748/38528)
Epoch: 206 | Batch_idx: 310 |  Loss: (0.0605) |  Loss2: (0.0000) | Acc: (97.00%) (39001/39808)
Epoch: 206 | Batch_idx: 320 |  Loss: (0.0614) |  Loss2: (0.0000) | Acc: (97.00%) (40242/41088)
Epoch: 206 | Batch_idx: 330 |  Loss: (0.0617) |  Loss2: (0.0000) | Acc: (97.00%) (41490/42368)
Epoch: 206 | Batch_idx: 340 |  Loss: (0.0618) |  Loss2: (0.0000) | Acc: (97.00%) (42745/43648)
Epoch: 206 | Batch_idx: 350 |  Loss: (0.0617) |  Loss2: (0.0000) | Acc: (97.00%) (44005/44928)
Epoch: 206 | Batch_idx: 360 |  Loss: (0.0616) |  Loss2: (0.0000) | Acc: (97.00%) (45263/46208)
Epoch: 206 | Batch_idx: 370 |  Loss: (0.0618) |  Loss2: (0.0000) | Acc: (97.00%) (46515/47488)
Epoch: 206 | Batch_idx: 380 |  Loss: (0.0618) |  Loss2: (0.0000) | Acc: (97.00%) (47762/48768)
Epoch: 206 | Batch_idx: 390 |  Loss: (0.0620) |  Loss2: (0.0000) | Acc: (97.00%) (48968/50000)
# TEST : Loss: (0.4177) | Acc: (89.00%) (8904/10000)
percent tensor([0.5749, 0.5882, 0.5756, 0.5750, 0.5813, 0.5886, 0.5882, 0.5720, 0.5734,
        0.5817, 0.5820, 0.5842, 0.5777, 0.5729, 0.5913, 0.5803],
       device='cuda:0') torch.Size([16])
percent tensor([0.5316, 0.5337, 0.5235, 0.5283, 0.5241, 0.5364, 0.5296, 0.5229, 0.5245,
        0.5302, 0.5341, 0.5256, 0.5304, 0.5306, 0.5341, 0.5326],
       device='cuda:0') torch.Size([16])
percent tensor([0.5947, 0.4647, 0.7242, 0.7278, 0.7425, 0.6915, 0.5710, 0.7019, 0.6418,
        0.5389, 0.4990, 0.6442, 0.4931, 0.5576, 0.5420, 0.6354],
       device='cuda:0') torch.Size([16])
percent tensor([0.7188, 0.7466, 0.6525, 0.6769, 0.6562, 0.5951, 0.7179, 0.6702, 0.7266,
        0.7507, 0.7615, 0.7169, 0.7335, 0.7539, 0.7008, 0.6949],
       device='cuda:0') torch.Size([16])
percent tensor([0.7558, 0.6489, 0.7806, 0.7725, 0.7869, 0.8516, 0.7319, 0.7599, 0.7140,
        0.6264, 0.6131, 0.6467, 0.6118, 0.6825, 0.7341, 0.7919],
       device='cuda:0') torch.Size([16])
percent tensor([0.6728, 0.7839, 0.7590, 0.8015, 0.7521, 0.8361, 0.7601, 0.5711, 0.7701,
        0.7488, 0.8056, 0.7728, 0.7728, 0.7963, 0.5903, 0.6221],
       device='cuda:0') torch.Size([16])
percent tensor([0.4383, 0.7222, 0.6438, 0.6551, 0.5830, 0.6832, 0.6815, 0.5725, 0.6794,
        0.6635, 0.7566, 0.6415, 0.6282, 0.6245, 0.5545, 0.4016],
       device='cuda:0') torch.Size([16])
percent tensor([0.9999, 0.9997, 0.9999, 1.0000, 1.0000, 0.9997, 0.9999, 0.9996, 0.9999,
        0.9999, 0.9998, 1.0000, 0.9997, 0.9997, 0.9998, 0.9996],
       device='cuda:0') torch.Size([16])
Epoch: 207 | Batch_idx: 0 |  Loss: (0.0525) |  Loss2: (0.0000) | Acc: (98.00%) (126/128)
Epoch: 207 | Batch_idx: 10 |  Loss: (0.0503) |  Loss2: (0.0000) | Acc: (98.00%) (1387/1408)
Epoch: 207 | Batch_idx: 20 |  Loss: (0.0565) |  Loss2: (0.0000) | Acc: (98.00%) (2637/2688)
Epoch: 207 | Batch_idx: 30 |  Loss: (0.0573) |  Loss2: (0.0000) | Acc: (98.00%) (3896/3968)
Epoch: 207 | Batch_idx: 40 |  Loss: (0.0559) |  Loss2: (0.0000) | Acc: (98.00%) (5157/5248)
Epoch: 207 | Batch_idx: 50 |  Loss: (0.0554) |  Loss2: (0.0000) | Acc: (98.00%) (6414/6528)
Epoch: 207 | Batch_idx: 60 |  Loss: (0.0580) |  Loss2: (0.0000) | Acc: (98.00%) (7662/7808)
Epoch: 207 | Batch_idx: 70 |  Loss: (0.0574) |  Loss2: (0.0000) | Acc: (98.00%) (8919/9088)
Epoch: 207 | Batch_idx: 80 |  Loss: (0.0578) |  Loss2: (0.0000) | Acc: (98.00%) (10174/10368)
Epoch: 207 | Batch_idx: 90 |  Loss: (0.0579) |  Loss2: (0.0000) | Acc: (98.00%) (11428/11648)
Epoch: 207 | Batch_idx: 100 |  Loss: (0.0577) |  Loss2: (0.0000) | Acc: (98.00%) (12683/12928)
Epoch: 207 | Batch_idx: 110 |  Loss: (0.0593) |  Loss2: (0.0000) | Acc: (98.00%) (13928/14208)
Epoch: 207 | Batch_idx: 120 |  Loss: (0.0586) |  Loss2: (0.0000) | Acc: (98.00%) (15187/15488)
Epoch: 207 | Batch_idx: 130 |  Loss: (0.0590) |  Loss2: (0.0000) | Acc: (98.00%) (16438/16768)
Epoch: 207 | Batch_idx: 140 |  Loss: (0.0584) |  Loss2: (0.0000) | Acc: (98.00%) (17699/18048)
Epoch: 207 | Batch_idx: 150 |  Loss: (0.0589) |  Loss2: (0.0000) | Acc: (98.00%) (18949/19328)
Epoch: 207 | Batch_idx: 160 |  Loss: (0.0591) |  Loss2: (0.0000) | Acc: (98.00%) (20203/20608)
Epoch: 207 | Batch_idx: 170 |  Loss: (0.0592) |  Loss2: (0.0000) | Acc: (98.00%) (21457/21888)
Epoch: 207 | Batch_idx: 180 |  Loss: (0.0586) |  Loss2: (0.0000) | Acc: (98.00%) (22716/23168)
Epoch: 207 | Batch_idx: 190 |  Loss: (0.0588) |  Loss2: (0.0000) | Acc: (98.00%) (23969/24448)
Epoch: 207 | Batch_idx: 200 |  Loss: (0.0591) |  Loss2: (0.0000) | Acc: (98.00%) (25215/25728)
Epoch: 207 | Batch_idx: 210 |  Loss: (0.0590) |  Loss2: (0.0000) | Acc: (98.00%) (26472/27008)
Epoch: 207 | Batch_idx: 220 |  Loss: (0.0595) |  Loss2: (0.0000) | Acc: (97.00%) (27718/28288)
Epoch: 207 | Batch_idx: 230 |  Loss: (0.0597) |  Loss2: (0.0000) | Acc: (97.00%) (28970/29568)
Epoch: 207 | Batch_idx: 240 |  Loss: (0.0602) |  Loss2: (0.0000) | Acc: (97.00%) (30220/30848)
Epoch: 207 | Batch_idx: 250 |  Loss: (0.0598) |  Loss2: (0.0000) | Acc: (97.00%) (31479/32128)
Epoch: 207 | Batch_idx: 260 |  Loss: (0.0604) |  Loss2: (0.0000) | Acc: (97.00%) (32726/33408)
Epoch: 207 | Batch_idx: 270 |  Loss: (0.0602) |  Loss2: (0.0000) | Acc: (97.00%) (33986/34688)
Epoch: 207 | Batch_idx: 280 |  Loss: (0.0602) |  Loss2: (0.0000) | Acc: (97.00%) (35238/35968)
Epoch: 207 | Batch_idx: 290 |  Loss: (0.0601) |  Loss2: (0.0000) | Acc: (97.00%) (36494/37248)
Epoch: 207 | Batch_idx: 300 |  Loss: (0.0597) |  Loss2: (0.0000) | Acc: (97.00%) (37752/38528)
Epoch: 207 | Batch_idx: 310 |  Loss: (0.0598) |  Loss2: (0.0000) | Acc: (97.00%) (39005/39808)
Epoch: 207 | Batch_idx: 320 |  Loss: (0.0597) |  Loss2: (0.0000) | Acc: (97.00%) (40264/41088)
Epoch: 207 | Batch_idx: 330 |  Loss: (0.0597) |  Loss2: (0.0000) | Acc: (97.00%) (41516/42368)
Epoch: 207 | Batch_idx: 340 |  Loss: (0.0596) |  Loss2: (0.0000) | Acc: (97.00%) (42772/43648)
Epoch: 207 | Batch_idx: 350 |  Loss: (0.0596) |  Loss2: (0.0000) | Acc: (97.00%) (44024/44928)
Epoch: 207 | Batch_idx: 360 |  Loss: (0.0598) |  Loss2: (0.0000) | Acc: (97.00%) (45276/46208)
Epoch: 207 | Batch_idx: 370 |  Loss: (0.0601) |  Loss2: (0.0000) | Acc: (97.00%) (46522/47488)
Epoch: 207 | Batch_idx: 380 |  Loss: (0.0605) |  Loss2: (0.0000) | Acc: (97.00%) (47774/48768)
Epoch: 207 | Batch_idx: 390 |  Loss: (0.0611) |  Loss2: (0.0000) | Acc: (97.00%) (48971/50000)
# TEST : Loss: (0.4718) | Acc: (87.00%) (8794/10000)
percent tensor([0.5773, 0.5901, 0.5809, 0.5772, 0.5856, 0.5913, 0.5908, 0.5742, 0.5765,
        0.5838, 0.5843, 0.5879, 0.5800, 0.5742, 0.5933, 0.5818],
       device='cuda:0') torch.Size([16])
percent tensor([0.5321, 0.5343, 0.5222, 0.5284, 0.5233, 0.5376, 0.5293, 0.5224, 0.5243,
        0.5304, 0.5351, 0.5247, 0.5312, 0.5305, 0.5350, 0.5334],
       device='cuda:0') torch.Size([16])
percent tensor([0.6015, 0.4645, 0.7294, 0.7393, 0.7447, 0.6983, 0.5779, 0.7028, 0.6386,
        0.5406, 0.4943, 0.6495, 0.4846, 0.5699, 0.5407, 0.6424],
       device='cuda:0') torch.Size([16])
percent tensor([0.7181, 0.7513, 0.6479, 0.6726, 0.6586, 0.5998, 0.7166, 0.6739, 0.7277,
        0.7514, 0.7619, 0.7128, 0.7344, 0.7596, 0.7006, 0.6941],
       device='cuda:0') torch.Size([16])
percent tensor([0.7559, 0.6438, 0.7794, 0.7632, 0.7934, 0.8426, 0.7433, 0.7656, 0.7247,
        0.6310, 0.6164, 0.6574, 0.6179, 0.6896, 0.7300, 0.7936],
       device='cuda:0') torch.Size([16])
percent tensor([0.6684, 0.7745, 0.7675, 0.8034, 0.7729, 0.8345, 0.7494, 0.5818, 0.7595,
        0.7420, 0.8031, 0.7805, 0.7719, 0.7849, 0.6133, 0.6114],
       device='cuda:0') torch.Size([16])
percent tensor([0.4100, 0.6661, 0.6644, 0.6819, 0.5955, 0.6497, 0.6404, 0.5862, 0.6260,
        0.6394, 0.7436, 0.6351, 0.5692, 0.5858, 0.5656, 0.3856],
       device='cuda:0') torch.Size([16])
percent tensor([0.9999, 0.9999, 0.9998, 1.0000, 1.0000, 0.9996, 0.9999, 0.9998, 0.9999,
        0.9999, 0.9999, 1.0000, 0.9997, 0.9997, 0.9998, 0.9996],
       device='cuda:0') torch.Size([16])
Epoch: 208 | Batch_idx: 0 |  Loss: (0.0556) |  Loss2: (0.0000) | Acc: (96.00%) (124/128)
Epoch: 208 | Batch_idx: 10 |  Loss: (0.0659) |  Loss2: (0.0000) | Acc: (97.00%) (1376/1408)
Epoch: 208 | Batch_idx: 20 |  Loss: (0.0690) |  Loss2: (0.0000) | Acc: (97.00%) (2621/2688)
Epoch: 208 | Batch_idx: 30 |  Loss: (0.0708) |  Loss2: (0.0000) | Acc: (97.00%) (3868/3968)
Epoch: 208 | Batch_idx: 40 |  Loss: (0.0706) |  Loss2: (0.0000) | Acc: (97.00%) (5119/5248)
Epoch: 208 | Batch_idx: 50 |  Loss: (0.0687) |  Loss2: (0.0000) | Acc: (97.00%) (6375/6528)
Epoch: 208 | Batch_idx: 60 |  Loss: (0.0656) |  Loss2: (0.0000) | Acc: (97.00%) (7633/7808)
Epoch: 208 | Batch_idx: 70 |  Loss: (0.0651) |  Loss2: (0.0000) | Acc: (97.00%) (8888/9088)
Epoch: 208 | Batch_idx: 80 |  Loss: (0.0649) |  Loss2: (0.0000) | Acc: (97.00%) (10140/10368)
Epoch: 208 | Batch_idx: 90 |  Loss: (0.0637) |  Loss2: (0.0000) | Acc: (97.00%) (11398/11648)
Epoch: 208 | Batch_idx: 100 |  Loss: (0.0637) |  Loss2: (0.0000) | Acc: (97.00%) (12651/12928)
Epoch: 208 | Batch_idx: 110 |  Loss: (0.0625) |  Loss2: (0.0000) | Acc: (97.00%) (13906/14208)
Epoch: 208 | Batch_idx: 120 |  Loss: (0.0623) |  Loss2: (0.0000) | Acc: (97.00%) (15160/15488)
Epoch: 208 | Batch_idx: 130 |  Loss: (0.0614) |  Loss2: (0.0000) | Acc: (97.00%) (16417/16768)
Epoch: 208 | Batch_idx: 140 |  Loss: (0.0609) |  Loss2: (0.0000) | Acc: (97.00%) (17674/18048)
Epoch: 208 | Batch_idx: 150 |  Loss: (0.0617) |  Loss2: (0.0000) | Acc: (97.00%) (18921/19328)
Epoch: 208 | Batch_idx: 160 |  Loss: (0.0611) |  Loss2: (0.0000) | Acc: (97.00%) (20184/20608)
Epoch: 208 | Batch_idx: 170 |  Loss: (0.0605) |  Loss2: (0.0000) | Acc: (97.00%) (21443/21888)
Epoch: 208 | Batch_idx: 180 |  Loss: (0.0608) |  Loss2: (0.0000) | Acc: (97.00%) (22698/23168)
Epoch: 208 | Batch_idx: 190 |  Loss: (0.0610) |  Loss2: (0.0000) | Acc: (97.00%) (23949/24448)
Epoch: 208 | Batch_idx: 200 |  Loss: (0.0604) |  Loss2: (0.0000) | Acc: (97.00%) (25202/25728)
Epoch: 208 | Batch_idx: 210 |  Loss: (0.0603) |  Loss2: (0.0000) | Acc: (97.00%) (26458/27008)
Epoch: 208 | Batch_idx: 220 |  Loss: (0.0600) |  Loss2: (0.0000) | Acc: (97.00%) (27714/28288)
Epoch: 208 | Batch_idx: 230 |  Loss: (0.0604) |  Loss2: (0.0000) | Acc: (97.00%) (28959/29568)
Epoch: 208 | Batch_idx: 240 |  Loss: (0.0601) |  Loss2: (0.0000) | Acc: (97.00%) (30217/30848)
Epoch: 208 | Batch_idx: 250 |  Loss: (0.0606) |  Loss2: (0.0000) | Acc: (97.00%) (31460/32128)
Epoch: 208 | Batch_idx: 260 |  Loss: (0.0606) |  Loss2: (0.0000) | Acc: (97.00%) (32715/33408)
Epoch: 208 | Batch_idx: 270 |  Loss: (0.0610) |  Loss2: (0.0000) | Acc: (97.00%) (33965/34688)
Epoch: 208 | Batch_idx: 280 |  Loss: (0.0605) |  Loss2: (0.0000) | Acc: (97.00%) (35224/35968)
Epoch: 208 | Batch_idx: 290 |  Loss: (0.0605) |  Loss2: (0.0000) | Acc: (97.00%) (36479/37248)
Epoch: 208 | Batch_idx: 300 |  Loss: (0.0603) |  Loss2: (0.0000) | Acc: (97.00%) (37735/38528)
Epoch: 208 | Batch_idx: 310 |  Loss: (0.0601) |  Loss2: (0.0000) | Acc: (97.00%) (38991/39808)
Epoch: 208 | Batch_idx: 320 |  Loss: (0.0594) |  Loss2: (0.0000) | Acc: (97.00%) (40258/41088)
Epoch: 208 | Batch_idx: 330 |  Loss: (0.0594) |  Loss2: (0.0000) | Acc: (97.00%) (41512/42368)
Epoch: 208 | Batch_idx: 340 |  Loss: (0.0592) |  Loss2: (0.0000) | Acc: (97.00%) (42769/43648)
Epoch: 208 | Batch_idx: 350 |  Loss: (0.0593) |  Loss2: (0.0000) | Acc: (97.00%) (44021/44928)
Epoch: 208 | Batch_idx: 360 |  Loss: (0.0597) |  Loss2: (0.0000) | Acc: (97.00%) (45266/46208)
Epoch: 208 | Batch_idx: 370 |  Loss: (0.0598) |  Loss2: (0.0000) | Acc: (97.00%) (46523/47488)
Epoch: 208 | Batch_idx: 380 |  Loss: (0.0601) |  Loss2: (0.0000) | Acc: (97.00%) (47775/48768)
Epoch: 208 | Batch_idx: 390 |  Loss: (0.0599) |  Loss2: (0.0000) | Acc: (97.00%) (48983/50000)
# TEST : Loss: (0.4634) | Acc: (88.00%) (8819/10000)
percent tensor([0.5791, 0.5933, 0.5797, 0.5786, 0.5860, 0.5945, 0.5927, 0.5755, 0.5777,
        0.5854, 0.5866, 0.5878, 0.5819, 0.5769, 0.5966, 0.5844],
       device='cuda:0') torch.Size([16])
percent tensor([0.5313, 0.5339, 0.5219, 0.5276, 0.5223, 0.5348, 0.5293, 0.5222, 0.5240,
        0.5305, 0.5344, 0.5252, 0.5306, 0.5310, 0.5336, 0.5326],
       device='cuda:0') torch.Size([16])
percent tensor([0.6002, 0.4728, 0.7267, 0.7291, 0.7438, 0.7001, 0.5801, 0.7007, 0.6457,
        0.5475, 0.5040, 0.6543, 0.4945, 0.5613, 0.5476, 0.6418],
       device='cuda:0') torch.Size([16])
percent tensor([0.7182, 0.7541, 0.6465, 0.6764, 0.6520, 0.5906, 0.7246, 0.6773, 0.7268,
        0.7532, 0.7611, 0.7108, 0.7342, 0.7655, 0.6971, 0.6966],
       device='cuda:0') torch.Size([16])
percent tensor([0.7522, 0.6374, 0.7798, 0.7784, 0.7895, 0.8474, 0.7294, 0.7529, 0.7136,
        0.6217, 0.6159, 0.6489, 0.6022, 0.6828, 0.7330, 0.7924],
       device='cuda:0') torch.Size([16])
percent tensor([0.6428, 0.7571, 0.7587, 0.8046, 0.7628, 0.8258, 0.7378, 0.5610, 0.7649,
        0.7456, 0.7924, 0.7891, 0.7681, 0.7864, 0.5964, 0.5815],
       device='cuda:0') torch.Size([16])
percent tensor([0.4266, 0.7142, 0.6556, 0.6517, 0.5878, 0.6715, 0.6472, 0.5707, 0.6883,
        0.6598, 0.7392, 0.6524, 0.6637, 0.6242, 0.5327, 0.3902],
       device='cuda:0') torch.Size([16])
percent tensor([0.9998, 0.9998, 0.9998, 0.9999, 1.0000, 0.9995, 0.9999, 0.9997, 0.9998,
        0.9999, 0.9998, 0.9999, 0.9995, 0.9997, 0.9998, 0.9995],
       device='cuda:0') torch.Size([16])
Epoch: 209 | Batch_idx: 0 |  Loss: (0.0379) |  Loss2: (0.0000) | Acc: (98.00%) (126/128)
Epoch: 209 | Batch_idx: 10 |  Loss: (0.0580) |  Loss2: (0.0000) | Acc: (97.00%) (1378/1408)
Epoch: 209 | Batch_idx: 20 |  Loss: (0.0641) |  Loss2: (0.0000) | Acc: (97.00%) (2624/2688)
Epoch: 209 | Batch_idx: 30 |  Loss: (0.0594) |  Loss2: (0.0000) | Acc: (97.00%) (3881/3968)
Epoch: 209 | Batch_idx: 40 |  Loss: (0.0560) |  Loss2: (0.0000) | Acc: (97.00%) (5143/5248)
Epoch: 209 | Batch_idx: 50 |  Loss: (0.0565) |  Loss2: (0.0000) | Acc: (97.00%) (6396/6528)
Epoch: 209 | Batch_idx: 60 |  Loss: (0.0581) |  Loss2: (0.0000) | Acc: (97.00%) (7647/7808)
Epoch: 209 | Batch_idx: 70 |  Loss: (0.0583) |  Loss2: (0.0000) | Acc: (97.00%) (8903/9088)
Epoch: 209 | Batch_idx: 80 |  Loss: (0.0586) |  Loss2: (0.0000) | Acc: (97.00%) (10154/10368)
Epoch: 209 | Batch_idx: 90 |  Loss: (0.0588) |  Loss2: (0.0000) | Acc: (97.00%) (11412/11648)
Epoch: 209 | Batch_idx: 100 |  Loss: (0.0591) |  Loss2: (0.0000) | Acc: (97.00%) (12669/12928)
Epoch: 209 | Batch_idx: 110 |  Loss: (0.0592) |  Loss2: (0.0000) | Acc: (97.00%) (13922/14208)
Epoch: 209 | Batch_idx: 120 |  Loss: (0.0591) |  Loss2: (0.0000) | Acc: (97.00%) (15177/15488)
Epoch: 209 | Batch_idx: 130 |  Loss: (0.0590) |  Loss2: (0.0000) | Acc: (97.00%) (16431/16768)
Epoch: 209 | Batch_idx: 140 |  Loss: (0.0585) |  Loss2: (0.0000) | Acc: (97.00%) (17686/18048)
Epoch: 209 | Batch_idx: 150 |  Loss: (0.0585) |  Loss2: (0.0000) | Acc: (97.00%) (18935/19328)
Epoch: 209 | Batch_idx: 160 |  Loss: (0.0592) |  Loss2: (0.0000) | Acc: (97.00%) (20181/20608)
Epoch: 209 | Batch_idx: 170 |  Loss: (0.0592) |  Loss2: (0.0000) | Acc: (97.00%) (21436/21888)
Epoch: 209 | Batch_idx: 180 |  Loss: (0.0597) |  Loss2: (0.0000) | Acc: (97.00%) (22682/23168)
Epoch: 209 | Batch_idx: 190 |  Loss: (0.0587) |  Loss2: (0.0000) | Acc: (97.00%) (23946/24448)
Epoch: 209 | Batch_idx: 200 |  Loss: (0.0587) |  Loss2: (0.0000) | Acc: (97.00%) (25204/25728)
Epoch: 209 | Batch_idx: 210 |  Loss: (0.0583) |  Loss2: (0.0000) | Acc: (97.00%) (26466/27008)
Epoch: 209 | Batch_idx: 220 |  Loss: (0.0588) |  Loss2: (0.0000) | Acc: (97.00%) (27710/28288)
Epoch: 209 | Batch_idx: 230 |  Loss: (0.0591) |  Loss2: (0.0000) | Acc: (97.00%) (28960/29568)
Epoch: 209 | Batch_idx: 240 |  Loss: (0.0592) |  Loss2: (0.0000) | Acc: (97.00%) (30210/30848)
Epoch: 209 | Batch_idx: 250 |  Loss: (0.0594) |  Loss2: (0.0000) | Acc: (97.00%) (31462/32128)
Epoch: 209 | Batch_idx: 260 |  Loss: (0.0590) |  Loss2: (0.0000) | Acc: (97.00%) (32723/33408)
Epoch: 209 | Batch_idx: 270 |  Loss: (0.0589) |  Loss2: (0.0000) | Acc: (97.00%) (33982/34688)
Epoch: 209 | Batch_idx: 280 |  Loss: (0.0592) |  Loss2: (0.0000) | Acc: (97.00%) (35234/35968)
Epoch: 209 | Batch_idx: 290 |  Loss: (0.0595) |  Loss2: (0.0000) | Acc: (97.00%) (36483/37248)
Epoch: 209 | Batch_idx: 300 |  Loss: (0.0597) |  Loss2: (0.0000) | Acc: (97.00%) (37732/38528)
Epoch: 209 | Batch_idx: 310 |  Loss: (0.0599) |  Loss2: (0.0000) | Acc: (97.00%) (38981/39808)
Epoch: 209 | Batch_idx: 320 |  Loss: (0.0603) |  Loss2: (0.0000) | Acc: (97.00%) (40228/41088)
Epoch: 209 | Batch_idx: 330 |  Loss: (0.0601) |  Loss2: (0.0000) | Acc: (97.00%) (41480/42368)
Epoch: 209 | Batch_idx: 340 |  Loss: (0.0606) |  Loss2: (0.0000) | Acc: (97.00%) (42726/43648)
Epoch: 209 | Batch_idx: 350 |  Loss: (0.0606) |  Loss2: (0.0000) | Acc: (97.00%) (43982/44928)
Epoch: 209 | Batch_idx: 360 |  Loss: (0.0603) |  Loss2: (0.0000) | Acc: (97.00%) (45243/46208)
Epoch: 209 | Batch_idx: 370 |  Loss: (0.0603) |  Loss2: (0.0000) | Acc: (97.00%) (46494/47488)
Epoch: 209 | Batch_idx: 380 |  Loss: (0.0599) |  Loss2: (0.0000) | Acc: (97.00%) (47753/48768)
Epoch: 209 | Batch_idx: 390 |  Loss: (0.0602) |  Loss2: (0.0000) | Acc: (97.00%) (48957/50000)
# TEST : Loss: (0.5397) | Acc: (87.00%) (8722/10000)
percent tensor([0.5793, 0.5929, 0.5831, 0.5799, 0.5878, 0.5938, 0.5938, 0.5764, 0.5781,
        0.5863, 0.5864, 0.5910, 0.5821, 0.5769, 0.5958, 0.5839],
       device='cuda:0') torch.Size([16])
percent tensor([0.5322, 0.5353, 0.5225, 0.5285, 0.5233, 0.5370, 0.5301, 0.5235, 0.5250,
        0.5311, 0.5356, 0.5248, 0.5313, 0.5316, 0.5353, 0.5339],
       device='cuda:0') torch.Size([16])
percent tensor([0.5979, 0.4658, 0.7160, 0.7244, 0.7353, 0.6880, 0.5748, 0.6978, 0.6406,
        0.5417, 0.4939, 0.6424, 0.4944, 0.5622, 0.5308, 0.6375],
       device='cuda:0') torch.Size([16])
percent tensor([0.7132, 0.7491, 0.6373, 0.6638, 0.6461, 0.5883, 0.7163, 0.6691, 0.7228,
        0.7477, 0.7571, 0.7028, 0.7287, 0.7594, 0.6920, 0.6908],
       device='cuda:0') torch.Size([16])
percent tensor([0.7523, 0.6431, 0.7767, 0.7774, 0.7903, 0.8502, 0.7382, 0.7554, 0.7144,
        0.6238, 0.6025, 0.6327, 0.5968, 0.6808, 0.7364, 0.7962],
       device='cuda:0') torch.Size([16])
percent tensor([0.6597, 0.7841, 0.7795, 0.7923, 0.7714, 0.8245, 0.7445, 0.5512, 0.7731,
        0.7636, 0.8033, 0.7895, 0.7838, 0.7950, 0.5984, 0.6101],
       device='cuda:0') torch.Size([16])
percent tensor([0.4477, 0.7409, 0.6651, 0.6532, 0.6191, 0.6894, 0.6320, 0.5832, 0.6891,
        0.6827, 0.7762, 0.6578, 0.6504, 0.6807, 0.5671, 0.4072],
       device='cuda:0') torch.Size([16])
percent tensor([0.9998, 0.9999, 0.9997, 0.9999, 0.9999, 0.9996, 0.9999, 0.9996, 0.9999,
        0.9999, 0.9999, 0.9999, 0.9997, 0.9995, 0.9997, 0.9993],
       device='cuda:0') torch.Size([16])
Epoch: 210 | Batch_idx: 0 |  Loss: (0.0641) |  Loss2: (0.0000) | Acc: (98.00%) (126/128)
Epoch: 210 | Batch_idx: 10 |  Loss: (0.0609) |  Loss2: (0.0000) | Acc: (98.00%) (1383/1408)
Epoch: 210 | Batch_idx: 20 |  Loss: (0.0559) |  Loss2: (0.0000) | Acc: (98.00%) (2643/2688)
Epoch: 210 | Batch_idx: 30 |  Loss: (0.0556) |  Loss2: (0.0000) | Acc: (98.00%) (3903/3968)
Epoch: 210 | Batch_idx: 40 |  Loss: (0.0547) |  Loss2: (0.0000) | Acc: (98.00%) (5164/5248)
Epoch: 210 | Batch_idx: 50 |  Loss: (0.0533) |  Loss2: (0.0000) | Acc: (98.00%) (6428/6528)
Epoch: 210 | Batch_idx: 60 |  Loss: (0.0537) |  Loss2: (0.0000) | Acc: (98.00%) (7688/7808)
Epoch: 210 | Batch_idx: 70 |  Loss: (0.0538) |  Loss2: (0.0000) | Acc: (98.00%) (8945/9088)
Epoch: 210 | Batch_idx: 80 |  Loss: (0.0541) |  Loss2: (0.0000) | Acc: (98.00%) (10204/10368)
Epoch: 210 | Batch_idx: 90 |  Loss: (0.0543) |  Loss2: (0.0000) | Acc: (98.00%) (11461/11648)
Epoch: 210 | Batch_idx: 100 |  Loss: (0.0546) |  Loss2: (0.0000) | Acc: (98.00%) (12717/12928)
Epoch: 210 | Batch_idx: 110 |  Loss: (0.0547) |  Loss2: (0.0000) | Acc: (98.00%) (13972/14208)
Epoch: 210 | Batch_idx: 120 |  Loss: (0.0547) |  Loss2: (0.0000) | Acc: (98.00%) (15232/15488)
Epoch: 210 | Batch_idx: 130 |  Loss: (0.0553) |  Loss2: (0.0000) | Acc: (98.00%) (16480/16768)
Epoch: 210 | Batch_idx: 140 |  Loss: (0.0555) |  Loss2: (0.0000) | Acc: (98.00%) (17733/18048)
Epoch: 210 | Batch_idx: 150 |  Loss: (0.0554) |  Loss2: (0.0000) | Acc: (98.00%) (18988/19328)
Epoch: 210 | Batch_idx: 160 |  Loss: (0.0559) |  Loss2: (0.0000) | Acc: (98.00%) (20239/20608)
Epoch: 210 | Batch_idx: 170 |  Loss: (0.0555) |  Loss2: (0.0000) | Acc: (98.00%) (21498/21888)
Epoch: 210 | Batch_idx: 180 |  Loss: (0.0559) |  Loss2: (0.0000) | Acc: (98.00%) (22748/23168)
Epoch: 210 | Batch_idx: 190 |  Loss: (0.0560) |  Loss2: (0.0000) | Acc: (98.00%) (24001/24448)
Epoch: 210 | Batch_idx: 200 |  Loss: (0.0564) |  Loss2: (0.0000) | Acc: (98.00%) (25253/25728)
Epoch: 210 | Batch_idx: 210 |  Loss: (0.0561) |  Loss2: (0.0000) | Acc: (98.00%) (26512/27008)
Epoch: 210 | Batch_idx: 220 |  Loss: (0.0568) |  Loss2: (0.0000) | Acc: (98.00%) (27762/28288)
Epoch: 210 | Batch_idx: 230 |  Loss: (0.0566) |  Loss2: (0.0000) | Acc: (98.00%) (29019/29568)
Epoch: 210 | Batch_idx: 240 |  Loss: (0.0570) |  Loss2: (0.0000) | Acc: (98.00%) (30270/30848)
Epoch: 210 | Batch_idx: 250 |  Loss: (0.0566) |  Loss2: (0.0000) | Acc: (98.00%) (31529/32128)
Epoch: 210 | Batch_idx: 260 |  Loss: (0.0573) |  Loss2: (0.0000) | Acc: (98.00%) (32774/33408)
Epoch: 210 | Batch_idx: 270 |  Loss: (0.0571) |  Loss2: (0.0000) | Acc: (98.00%) (34032/34688)
Epoch: 210 | Batch_idx: 280 |  Loss: (0.0576) |  Loss2: (0.0000) | Acc: (98.00%) (35277/35968)
Epoch: 210 | Batch_idx: 290 |  Loss: (0.0577) |  Loss2: (0.0000) | Acc: (98.00%) (36526/37248)
Epoch: 210 | Batch_idx: 300 |  Loss: (0.0578) |  Loss2: (0.0000) | Acc: (98.00%) (37783/38528)
Epoch: 210 | Batch_idx: 310 |  Loss: (0.0576) |  Loss2: (0.0000) | Acc: (98.00%) (39036/39808)
Epoch: 210 | Batch_idx: 320 |  Loss: (0.0578) |  Loss2: (0.0000) | Acc: (98.00%) (40286/41088)
Epoch: 210 | Batch_idx: 330 |  Loss: (0.0578) |  Loss2: (0.0000) | Acc: (98.00%) (41538/42368)
Epoch: 210 | Batch_idx: 340 |  Loss: (0.0579) |  Loss2: (0.0000) | Acc: (98.00%) (42791/43648)
Epoch: 210 | Batch_idx: 350 |  Loss: (0.0581) |  Loss2: (0.0000) | Acc: (98.00%) (44042/44928)
Epoch: 210 | Batch_idx: 360 |  Loss: (0.0583) |  Loss2: (0.0000) | Acc: (98.00%) (45297/46208)
Epoch: 210 | Batch_idx: 370 |  Loss: (0.0581) |  Loss2: (0.0000) | Acc: (98.00%) (46555/47488)
Epoch: 210 | Batch_idx: 380 |  Loss: (0.0581) |  Loss2: (0.0000) | Acc: (98.00%) (47810/48768)
Epoch: 210 | Batch_idx: 390 |  Loss: (0.0586) |  Loss2: (0.0000) | Acc: (98.00%) (49012/50000)
=> saving checkpoint 'drive/app/torch/save_Schedule/checkpoint_210.pth.tar'
# TEST : Loss: (0.4592) | Acc: (88.00%) (8802/10000)
percent tensor([0.5791, 0.5920, 0.5830, 0.5795, 0.5882, 0.5933, 0.5929, 0.5766, 0.5782,
        0.5860, 0.5858, 0.5905, 0.5817, 0.5757, 0.5952, 0.5841],
       device='cuda:0') torch.Size([16])
percent tensor([0.5317, 0.5346, 0.5232, 0.5284, 0.5227, 0.5360, 0.5294, 0.5236, 0.5245,
        0.5311, 0.5345, 0.5254, 0.5309, 0.5314, 0.5342, 0.5331],
       device='cuda:0') torch.Size([16])
percent tensor([0.5988, 0.4580, 0.7285, 0.7243, 0.7455, 0.6884, 0.5790, 0.6965, 0.6399,
        0.5371, 0.4936, 0.6541, 0.4912, 0.5452, 0.5316, 0.6338],
       device='cuda:0') torch.Size([16])
percent tensor([0.7094, 0.7509, 0.6357, 0.6700, 0.6450, 0.5945, 0.7180, 0.6691, 0.7197,
        0.7484, 0.7558, 0.7054, 0.7286, 0.7577, 0.6970, 0.6928],
       device='cuda:0') torch.Size([16])
percent tensor([0.7570, 0.6540, 0.7824, 0.7693, 0.7901, 0.8439, 0.7436, 0.7691, 0.7192,
        0.6225, 0.6202, 0.6507, 0.6151, 0.6879, 0.7419, 0.7876],
       device='cuda:0') torch.Size([16])
percent tensor([0.7034, 0.7734, 0.7897, 0.8210, 0.7908, 0.8429, 0.7473, 0.5709, 0.7836,
        0.7813, 0.8240, 0.8082, 0.7905, 0.7986, 0.6349, 0.6489],
       device='cuda:0') torch.Size([16])
percent tensor([0.4817, 0.7486, 0.6560, 0.6760, 0.5960, 0.6728, 0.6518, 0.5797, 0.6918,
        0.6982, 0.7546, 0.7027, 0.6493, 0.6608, 0.5816, 0.4132],
       device='cuda:0') torch.Size([16])
percent tensor([0.9998, 0.9999, 0.9999, 0.9999, 1.0000, 0.9996, 0.9999, 0.9998, 0.9999,
        0.9999, 0.9998, 1.0000, 0.9996, 0.9993, 0.9998, 0.9996],
       device='cuda:0') torch.Size([16])
Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 3, 3, 3]) tensor(186.8730, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(826.2518, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(839.5800, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([128, 64, 3, 3]) tensor(1509.5546, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([128, 64, 1, 1]) tensor(480.8239, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([128, 128, 3, 3]) tensor(2299.6487, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([256, 128, 3, 3]) tensor(4273.4077, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([256, 128, 1, 1]) tensor(1347.2245, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([256, 256, 3, 3]) tensor(6310.5522, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([512, 256, 3, 3]) tensor(11512.3193, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([512, 256, 1, 1]) tensor(3778.5042, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([512, 512, 3, 3]) tensor(15911.0791, device='cuda:0', grad_fn=<NormBackward0>)
Epoch: 211 | Batch_idx: 0 |  Loss: (0.0691) |  Loss2: (0.0000) | Acc: (97.00%) (125/128)
Epoch: 211 | Batch_idx: 10 |  Loss: (0.0602) |  Loss2: (0.0000) | Acc: (98.00%) (1381/1408)
Epoch: 211 | Batch_idx: 20 |  Loss: (0.0590) |  Loss2: (0.0000) | Acc: (98.00%) (2639/2688)
Epoch: 211 | Batch_idx: 30 |  Loss: (0.0581) |  Loss2: (0.0000) | Acc: (98.00%) (3894/3968)
Epoch: 211 | Batch_idx: 40 |  Loss: (0.0565) |  Loss2: (0.0000) | Acc: (98.00%) (5149/5248)
Epoch: 211 | Batch_idx: 50 |  Loss: (0.0553) |  Loss2: (0.0000) | Acc: (98.00%) (6404/6528)
Epoch: 211 | Batch_idx: 60 |  Loss: (0.0548) |  Loss2: (0.0000) | Acc: (98.00%) (7659/7808)
Epoch: 211 | Batch_idx: 70 |  Loss: (0.0551) |  Loss2: (0.0000) | Acc: (98.00%) (8912/9088)
Epoch: 211 | Batch_idx: 80 |  Loss: (0.0550) |  Loss2: (0.0000) | Acc: (98.00%) (10166/10368)
Epoch: 211 | Batch_idx: 90 |  Loss: (0.0548) |  Loss2: (0.0000) | Acc: (98.00%) (11423/11648)
Epoch: 211 | Batch_idx: 100 |  Loss: (0.0549) |  Loss2: (0.0000) | Acc: (98.00%) (12682/12928)
Epoch: 211 | Batch_idx: 110 |  Loss: (0.0545) |  Loss2: (0.0000) | Acc: (98.00%) (13943/14208)
Epoch: 211 | Batch_idx: 120 |  Loss: (0.0544) |  Loss2: (0.0000) | Acc: (98.00%) (15195/15488)
Epoch: 211 | Batch_idx: 130 |  Loss: (0.0556) |  Loss2: (0.0000) | Acc: (98.00%) (16445/16768)
Epoch: 211 | Batch_idx: 140 |  Loss: (0.0565) |  Loss2: (0.0000) | Acc: (98.00%) (17693/18048)
Epoch: 211 | Batch_idx: 150 |  Loss: (0.0560) |  Loss2: (0.0000) | Acc: (98.00%) (18950/19328)
Epoch: 211 | Batch_idx: 160 |  Loss: (0.0565) |  Loss2: (0.0000) | Acc: (98.00%) (20202/20608)
Epoch: 211 | Batch_idx: 170 |  Loss: (0.0563) |  Loss2: (0.0000) | Acc: (98.00%) (21462/21888)
Epoch: 211 | Batch_idx: 180 |  Loss: (0.0564) |  Loss2: (0.0000) | Acc: (98.00%) (22720/23168)
Epoch: 211 | Batch_idx: 190 |  Loss: (0.0560) |  Loss2: (0.0000) | Acc: (98.00%) (23984/24448)
Epoch: 211 | Batch_idx: 200 |  Loss: (0.0560) |  Loss2: (0.0000) | Acc: (98.00%) (25239/25728)
Epoch: 211 | Batch_idx: 210 |  Loss: (0.0557) |  Loss2: (0.0000) | Acc: (98.00%) (26502/27008)
Epoch: 211 | Batch_idx: 220 |  Loss: (0.0560) |  Loss2: (0.0000) | Acc: (98.00%) (27756/28288)
Epoch: 211 | Batch_idx: 230 |  Loss: (0.0563) |  Loss2: (0.0000) | Acc: (98.00%) (29012/29568)
Epoch: 211 | Batch_idx: 240 |  Loss: (0.0564) |  Loss2: (0.0000) | Acc: (98.00%) (30262/30848)
Epoch: 211 | Batch_idx: 250 |  Loss: (0.0565) |  Loss2: (0.0000) | Acc: (98.00%) (31516/32128)
Epoch: 211 | Batch_idx: 260 |  Loss: (0.0567) |  Loss2: (0.0000) | Acc: (98.00%) (32768/33408)
Epoch: 211 | Batch_idx: 270 |  Loss: (0.0568) |  Loss2: (0.0000) | Acc: (98.00%) (34028/34688)
Epoch: 211 | Batch_idx: 280 |  Loss: (0.0569) |  Loss2: (0.0000) | Acc: (98.00%) (35287/35968)
Epoch: 211 | Batch_idx: 290 |  Loss: (0.0570) |  Loss2: (0.0000) | Acc: (98.00%) (36544/37248)
Epoch: 211 | Batch_idx: 300 |  Loss: (0.0569) |  Loss2: (0.0000) | Acc: (98.00%) (37802/38528)
Epoch: 211 | Batch_idx: 310 |  Loss: (0.0569) |  Loss2: (0.0000) | Acc: (98.00%) (39058/39808)
Epoch: 211 | Batch_idx: 320 |  Loss: (0.0569) |  Loss2: (0.0000) | Acc: (98.00%) (40315/41088)
Epoch: 211 | Batch_idx: 330 |  Loss: (0.0569) |  Loss2: (0.0000) | Acc: (98.00%) (41573/42368)
Epoch: 211 | Batch_idx: 340 |  Loss: (0.0567) |  Loss2: (0.0000) | Acc: (98.00%) (42834/43648)
Epoch: 211 | Batch_idx: 350 |  Loss: (0.0566) |  Loss2: (0.0000) | Acc: (98.00%) (44097/44928)
Epoch: 211 | Batch_idx: 360 |  Loss: (0.0564) |  Loss2: (0.0000) | Acc: (98.00%) (45354/46208)
Epoch: 211 | Batch_idx: 370 |  Loss: (0.0567) |  Loss2: (0.0000) | Acc: (98.00%) (46608/47488)
Epoch: 211 | Batch_idx: 380 |  Loss: (0.0565) |  Loss2: (0.0000) | Acc: (98.00%) (47867/48768)
Epoch: 211 | Batch_idx: 390 |  Loss: (0.0561) |  Loss2: (0.0000) | Acc: (98.00%) (49081/50000)
# TEST : Loss: (0.4116) | Acc: (89.00%) (8900/10000)
percent tensor([0.5812, 0.5958, 0.5839, 0.5810, 0.5887, 0.5949, 0.5951, 0.5786, 0.5806,
        0.5884, 0.5883, 0.5916, 0.5844, 0.5800, 0.5979, 0.5860],
       device='cuda:0') torch.Size([16])
percent tensor([0.5321, 0.5355, 0.5219, 0.5292, 0.5222, 0.5370, 0.5298, 0.5235, 0.5249,
        0.5315, 0.5356, 0.5253, 0.5312, 0.5323, 0.5352, 0.5339],
       device='cuda:0') torch.Size([16])
percent tensor([0.6180, 0.4598, 0.7356, 0.7371, 0.7488, 0.7036, 0.5744, 0.7050, 0.6501,
        0.5528, 0.5040, 0.6574, 0.5073, 0.5394, 0.5442, 0.6482],
       device='cuda:0') torch.Size([16])
percent tensor([0.7091, 0.7485, 0.6322, 0.6674, 0.6420, 0.5936, 0.7163, 0.6666, 0.7171,
        0.7465, 0.7573, 0.7079, 0.7286, 0.7606, 0.6991, 0.6964],
       device='cuda:0') torch.Size([16])
percent tensor([0.7583, 0.6507, 0.7822, 0.7718, 0.7936, 0.8416, 0.7426, 0.7631, 0.7171,
        0.6187, 0.6089, 0.6402, 0.6070, 0.6899, 0.7334, 0.7882],
       device='cuda:0') torch.Size([16])
percent tensor([0.6711, 0.7781, 0.7700, 0.8214, 0.7700, 0.8413, 0.7410, 0.5629, 0.7733,
        0.7586, 0.8036, 0.7914, 0.7774, 0.7987, 0.6030, 0.5962],
       device='cuda:0') torch.Size([16])
percent tensor([0.4218, 0.7469, 0.6271, 0.6633, 0.5819, 0.6550, 0.6274, 0.5726, 0.6958,
        0.6785, 0.7661, 0.6632, 0.6241, 0.6724, 0.5602, 0.4062],
       device='cuda:0') torch.Size([16])
percent tensor([0.9998, 0.9998, 0.9998, 0.9999, 1.0000, 0.9995, 1.0000, 0.9998, 0.9999,
        0.9999, 0.9998, 1.0000, 0.9998, 0.9997, 0.9998, 0.9993],
       device='cuda:0') torch.Size([16])
Epoch: 212 | Batch_idx: 0 |  Loss: (0.0658) |  Loss2: (0.0000) | Acc: (96.00%) (124/128)
Epoch: 212 | Batch_idx: 10 |  Loss: (0.0493) |  Loss2: (0.0000) | Acc: (98.00%) (1383/1408)
Epoch: 212 | Batch_idx: 20 |  Loss: (0.0490) |  Loss2: (0.0000) | Acc: (98.00%) (2647/2688)
Epoch: 212 | Batch_idx: 30 |  Loss: (0.0465) |  Loss2: (0.0000) | Acc: (98.00%) (3909/3968)
Epoch: 212 | Batch_idx: 40 |  Loss: (0.0497) |  Loss2: (0.0000) | Acc: (98.00%) (5163/5248)
Epoch: 212 | Batch_idx: 50 |  Loss: (0.0499) |  Loss2: (0.0000) | Acc: (98.00%) (6426/6528)
Epoch: 212 | Batch_idx: 60 |  Loss: (0.0489) |  Loss2: (0.0000) | Acc: (98.00%) (7687/7808)
Epoch: 212 | Batch_idx: 70 |  Loss: (0.0492) |  Loss2: (0.0000) | Acc: (98.00%) (8943/9088)
Epoch: 212 | Batch_idx: 80 |  Loss: (0.0482) |  Loss2: (0.0000) | Acc: (98.00%) (10210/10368)
Epoch: 212 | Batch_idx: 90 |  Loss: (0.0478) |  Loss2: (0.0000) | Acc: (98.00%) (11474/11648)
Epoch: 212 | Batch_idx: 100 |  Loss: (0.0477) |  Loss2: (0.0000) | Acc: (98.00%) (12732/12928)
Epoch: 212 | Batch_idx: 110 |  Loss: (0.0491) |  Loss2: (0.0000) | Acc: (98.00%) (13983/14208)
Epoch: 212 | Batch_idx: 120 |  Loss: (0.0497) |  Loss2: (0.0000) | Acc: (98.00%) (15235/15488)
Epoch: 212 | Batch_idx: 130 |  Loss: (0.0502) |  Loss2: (0.0000) | Acc: (98.00%) (16495/16768)
Epoch: 212 | Batch_idx: 140 |  Loss: (0.0506) |  Loss2: (0.0000) | Acc: (98.00%) (17747/18048)
Epoch: 212 | Batch_idx: 150 |  Loss: (0.0511) |  Loss2: (0.0000) | Acc: (98.00%) (19004/19328)
Epoch: 212 | Batch_idx: 160 |  Loss: (0.0525) |  Loss2: (0.0000) | Acc: (98.00%) (20256/20608)
Epoch: 212 | Batch_idx: 170 |  Loss: (0.0529) |  Loss2: (0.0000) | Acc: (98.00%) (21507/21888)
Epoch: 212 | Batch_idx: 180 |  Loss: (0.0531) |  Loss2: (0.0000) | Acc: (98.00%) (22762/23168)
Epoch: 212 | Batch_idx: 190 |  Loss: (0.0537) |  Loss2: (0.0000) | Acc: (98.00%) (24012/24448)
Epoch: 212 | Batch_idx: 200 |  Loss: (0.0537) |  Loss2: (0.0000) | Acc: (98.00%) (25268/25728)
Epoch: 212 | Batch_idx: 210 |  Loss: (0.0535) |  Loss2: (0.0000) | Acc: (98.00%) (26527/27008)
Epoch: 212 | Batch_idx: 220 |  Loss: (0.0533) |  Loss2: (0.0000) | Acc: (98.00%) (27791/28288)
Epoch: 212 | Batch_idx: 230 |  Loss: (0.0528) |  Loss2: (0.0000) | Acc: (98.00%) (29057/29568)
Epoch: 212 | Batch_idx: 240 |  Loss: (0.0528) |  Loss2: (0.0000) | Acc: (98.00%) (30315/30848)
Epoch: 212 | Batch_idx: 250 |  Loss: (0.0523) |  Loss2: (0.0000) | Acc: (98.00%) (31581/32128)
Epoch: 212 | Batch_idx: 260 |  Loss: (0.0525) |  Loss2: (0.0000) | Acc: (98.00%) (32837/33408)
Epoch: 212 | Batch_idx: 270 |  Loss: (0.0523) |  Loss2: (0.0000) | Acc: (98.00%) (34098/34688)
Epoch: 212 | Batch_idx: 280 |  Loss: (0.0522) |  Loss2: (0.0000) | Acc: (98.00%) (35355/35968)
Epoch: 212 | Batch_idx: 290 |  Loss: (0.0523) |  Loss2: (0.0000) | Acc: (98.00%) (36612/37248)
Epoch: 212 | Batch_idx: 300 |  Loss: (0.0529) |  Loss2: (0.0000) | Acc: (98.00%) (37860/38528)
Epoch: 212 | Batch_idx: 310 |  Loss: (0.0533) |  Loss2: (0.0000) | Acc: (98.00%) (39111/39808)
Epoch: 212 | Batch_idx: 320 |  Loss: (0.0531) |  Loss2: (0.0000) | Acc: (98.00%) (40370/41088)
Epoch: 212 | Batch_idx: 330 |  Loss: (0.0534) |  Loss2: (0.0000) | Acc: (98.00%) (41623/42368)
Epoch: 212 | Batch_idx: 340 |  Loss: (0.0536) |  Loss2: (0.0000) | Acc: (98.00%) (42878/43648)
Epoch: 212 | Batch_idx: 350 |  Loss: (0.0540) |  Loss2: (0.0000) | Acc: (98.00%) (44130/44928)
Epoch: 212 | Batch_idx: 360 |  Loss: (0.0540) |  Loss2: (0.0000) | Acc: (98.00%) (45390/46208)
Epoch: 212 | Batch_idx: 370 |  Loss: (0.0542) |  Loss2: (0.0000) | Acc: (98.00%) (46641/47488)
Epoch: 212 | Batch_idx: 380 |  Loss: (0.0547) |  Loss2: (0.0000) | Acc: (98.00%) (47889/48768)
Epoch: 212 | Batch_idx: 390 |  Loss: (0.0547) |  Loss2: (0.0000) | Acc: (98.00%) (49099/50000)
# TEST : Loss: (0.4446) | Acc: (88.00%) (8850/10000)
percent tensor([0.5804, 0.5943, 0.5817, 0.5805, 0.5876, 0.5951, 0.5939, 0.5774, 0.5790,
        0.5874, 0.5877, 0.5900, 0.5832, 0.5779, 0.5977, 0.5857],
       device='cuda:0') torch.Size([16])
percent tensor([0.5329, 0.5354, 0.5234, 0.5294, 0.5231, 0.5383, 0.5304, 0.5248, 0.5254,
        0.5318, 0.5361, 0.5261, 0.5316, 0.5328, 0.5357, 0.5344],
       device='cuda:0') torch.Size([16])
percent tensor([0.6021, 0.4762, 0.7202, 0.7288, 0.7369, 0.6893, 0.5746, 0.6919, 0.6495,
        0.5501, 0.5092, 0.6394, 0.4975, 0.5658, 0.5413, 0.6429],
       device='cuda:0') torch.Size([16])
percent tensor([0.7181, 0.7525, 0.6491, 0.6812, 0.6554, 0.5923, 0.7213, 0.6750, 0.7262,
        0.7558, 0.7634, 0.7137, 0.7370, 0.7655, 0.6971, 0.6978],
       device='cuda:0') torch.Size([16])
percent tensor([0.7605, 0.6575, 0.7698, 0.7663, 0.7880, 0.8499, 0.7478, 0.7583, 0.7202,
        0.6249, 0.6133, 0.6522, 0.6113, 0.6831, 0.7469, 0.8010],
       device='cuda:0') torch.Size([16])
percent tensor([0.7030, 0.7869, 0.7805, 0.7998, 0.7790, 0.8366, 0.7699, 0.5990, 0.7657,
        0.7641, 0.8120, 0.7923, 0.7895, 0.8015, 0.6161, 0.6449],
       device='cuda:0') torch.Size([16])
percent tensor([0.4487, 0.7266, 0.6567, 0.6591, 0.6271, 0.6541, 0.6624, 0.6082, 0.6981,
        0.6651, 0.7726, 0.6367, 0.6449, 0.6615, 0.5676, 0.4052],
       device='cuda:0') torch.Size([16])
percent tensor([0.9999, 0.9998, 0.9998, 0.9999, 1.0000, 0.9998, 0.9999, 0.9997, 0.9999,
        0.9999, 0.9998, 1.0000, 0.9996, 0.9996, 0.9998, 0.9994],
       device='cuda:0') torch.Size([16])
Epoch: 213 | Batch_idx: 0 |  Loss: (0.0288) |  Loss2: (0.0000) | Acc: (99.00%) (127/128)
Epoch: 213 | Batch_idx: 10 |  Loss: (0.0402) |  Loss2: (0.0000) | Acc: (98.00%) (1393/1408)
Epoch: 213 | Batch_idx: 20 |  Loss: (0.0449) |  Loss2: (0.0000) | Acc: (98.00%) (2655/2688)
Epoch: 213 | Batch_idx: 30 |  Loss: (0.0453) |  Loss2: (0.0000) | Acc: (98.00%) (3917/3968)
Epoch: 213 | Batch_idx: 40 |  Loss: (0.0446) |  Loss2: (0.0000) | Acc: (98.00%) (5182/5248)
Epoch: 213 | Batch_idx: 50 |  Loss: (0.0464) |  Loss2: (0.0000) | Acc: (98.00%) (6442/6528)
Epoch: 213 | Batch_idx: 60 |  Loss: (0.0471) |  Loss2: (0.0000) | Acc: (98.00%) (7698/7808)
Epoch: 213 | Batch_idx: 70 |  Loss: (0.0466) |  Loss2: (0.0000) | Acc: (98.00%) (8961/9088)
Epoch: 213 | Batch_idx: 80 |  Loss: (0.0463) |  Loss2: (0.0000) | Acc: (98.00%) (10223/10368)
Epoch: 213 | Batch_idx: 90 |  Loss: (0.0474) |  Loss2: (0.0000) | Acc: (98.00%) (11481/11648)
Epoch: 213 | Batch_idx: 100 |  Loss: (0.0471) |  Loss2: (0.0000) | Acc: (98.00%) (12743/12928)
Epoch: 213 | Batch_idx: 110 |  Loss: (0.0468) |  Loss2: (0.0000) | Acc: (98.00%) (14009/14208)
Epoch: 213 | Batch_idx: 120 |  Loss: (0.0473) |  Loss2: (0.0000) | Acc: (98.00%) (15268/15488)
Epoch: 213 | Batch_idx: 130 |  Loss: (0.0474) |  Loss2: (0.0000) | Acc: (98.00%) (16526/16768)
Epoch: 213 | Batch_idx: 140 |  Loss: (0.0472) |  Loss2: (0.0000) | Acc: (98.00%) (17790/18048)
Epoch: 213 | Batch_idx: 150 |  Loss: (0.0484) |  Loss2: (0.0000) | Acc: (98.00%) (19045/19328)
Epoch: 213 | Batch_idx: 160 |  Loss: (0.0483) |  Loss2: (0.0000) | Acc: (98.00%) (20305/20608)
Epoch: 213 | Batch_idx: 170 |  Loss: (0.0487) |  Loss2: (0.0000) | Acc: (98.00%) (21560/21888)
Epoch: 213 | Batch_idx: 180 |  Loss: (0.0488) |  Loss2: (0.0000) | Acc: (98.00%) (22817/23168)
Epoch: 213 | Batch_idx: 190 |  Loss: (0.0486) |  Loss2: (0.0000) | Acc: (98.00%) (24082/24448)
Epoch: 213 | Batch_idx: 200 |  Loss: (0.0485) |  Loss2: (0.0000) | Acc: (98.00%) (25344/25728)
Epoch: 213 | Batch_idx: 210 |  Loss: (0.0482) |  Loss2: (0.0000) | Acc: (98.00%) (26604/27008)
Epoch: 213 | Batch_idx: 220 |  Loss: (0.0484) |  Loss2: (0.0000) | Acc: (98.00%) (27857/28288)
Epoch: 213 | Batch_idx: 230 |  Loss: (0.0488) |  Loss2: (0.0000) | Acc: (98.00%) (29115/29568)
Epoch: 213 | Batch_idx: 240 |  Loss: (0.0484) |  Loss2: (0.0000) | Acc: (98.00%) (30386/30848)
Epoch: 213 | Batch_idx: 250 |  Loss: (0.0483) |  Loss2: (0.0000) | Acc: (98.00%) (31649/32128)
Epoch: 213 | Batch_idx: 260 |  Loss: (0.0481) |  Loss2: (0.0000) | Acc: (98.00%) (32912/33408)
Epoch: 213 | Batch_idx: 270 |  Loss: (0.0482) |  Loss2: (0.0000) | Acc: (98.00%) (34172/34688)
Epoch: 213 | Batch_idx: 280 |  Loss: (0.0480) |  Loss2: (0.0000) | Acc: (98.00%) (35437/35968)
Epoch: 213 | Batch_idx: 290 |  Loss: (0.0479) |  Loss2: (0.0000) | Acc: (98.00%) (36700/37248)
Epoch: 213 | Batch_idx: 300 |  Loss: (0.0481) |  Loss2: (0.0000) | Acc: (98.00%) (37954/38528)
Epoch: 213 | Batch_idx: 310 |  Loss: (0.0485) |  Loss2: (0.0000) | Acc: (98.00%) (39207/39808)
Epoch: 213 | Batch_idx: 320 |  Loss: (0.0487) |  Loss2: (0.0000) | Acc: (98.00%) (40462/41088)
Epoch: 213 | Batch_idx: 330 |  Loss: (0.0487) |  Loss2: (0.0000) | Acc: (98.00%) (41726/42368)
Epoch: 213 | Batch_idx: 340 |  Loss: (0.0490) |  Loss2: (0.0000) | Acc: (98.00%) (42980/43648)
Epoch: 213 | Batch_idx: 350 |  Loss: (0.0491) |  Loss2: (0.0000) | Acc: (98.00%) (44238/44928)
Epoch: 213 | Batch_idx: 360 |  Loss: (0.0493) |  Loss2: (0.0000) | Acc: (98.00%) (45494/46208)
Epoch: 213 | Batch_idx: 370 |  Loss: (0.0496) |  Loss2: (0.0000) | Acc: (98.00%) (46749/47488)
Epoch: 213 | Batch_idx: 380 |  Loss: (0.0496) |  Loss2: (0.0000) | Acc: (98.00%) (48007/48768)
Epoch: 213 | Batch_idx: 390 |  Loss: (0.0498) |  Loss2: (0.0000) | Acc: (98.00%) (49211/50000)
# TEST : Loss: (0.4199) | Acc: (89.00%) (8949/10000)
percent tensor([0.5797, 0.5935, 0.5828, 0.5798, 0.5878, 0.5935, 0.5942, 0.5776, 0.5789,
        0.5872, 0.5871, 0.5907, 0.5825, 0.5779, 0.5966, 0.5843],
       device='cuda:0') torch.Size([16])
percent tensor([0.5323, 0.5344, 0.5234, 0.5292, 0.5236, 0.5375, 0.5295, 0.5238, 0.5252,
        0.5309, 0.5353, 0.5258, 0.5314, 0.5319, 0.5342, 0.5341],
       device='cuda:0') torch.Size([16])
percent tensor([0.6038, 0.4668, 0.7229, 0.7260, 0.7400, 0.6910, 0.5762, 0.7017, 0.6496,
        0.5425, 0.5008, 0.6466, 0.4966, 0.5657, 0.5365, 0.6415],
       device='cuda:0') torch.Size([16])
percent tensor([0.7177, 0.7519, 0.6450, 0.6705, 0.6485, 0.5962, 0.7199, 0.6697, 0.7246,
        0.7497, 0.7597, 0.7114, 0.7345, 0.7599, 0.7020, 0.6945],
       device='cuda:0') torch.Size([16])
percent tensor([0.7631, 0.6683, 0.7816, 0.7814, 0.7989, 0.8559, 0.7489, 0.7646, 0.7244,
        0.6361, 0.6190, 0.6470, 0.6192, 0.7019, 0.7496, 0.8034],
       device='cuda:0') torch.Size([16])
percent tensor([0.6642, 0.7664, 0.7792, 0.8178, 0.7798, 0.8231, 0.7653, 0.5659, 0.7629,
        0.7606, 0.8078, 0.7799, 0.7677, 0.8021, 0.5767, 0.6085],
       device='cuda:0') torch.Size([16])
percent tensor([0.4183, 0.7213, 0.6547, 0.6604, 0.5958, 0.6643, 0.6700, 0.5856, 0.6886,
        0.6625, 0.7922, 0.6684, 0.6370, 0.6405, 0.5576, 0.3981],
       device='cuda:0') torch.Size([16])
percent tensor([0.9999, 0.9998, 0.9998, 0.9999, 1.0000, 0.9997, 1.0000, 0.9998, 0.9999,
        0.9999, 0.9998, 0.9999, 0.9997, 0.9996, 0.9998, 0.9996],
       device='cuda:0') torch.Size([16])
Epoch: 214 | Batch_idx: 0 |  Loss: (0.0511) |  Loss2: (0.0000) | Acc: (97.00%) (125/128)
Epoch: 214 | Batch_idx: 10 |  Loss: (0.0504) |  Loss2: (0.0000) | Acc: (98.00%) (1390/1408)
Epoch: 214 | Batch_idx: 20 |  Loss: (0.0440) |  Loss2: (0.0000) | Acc: (98.00%) (2657/2688)
Epoch: 214 | Batch_idx: 30 |  Loss: (0.0439) |  Loss2: (0.0000) | Acc: (98.00%) (3920/3968)
Epoch: 214 | Batch_idx: 40 |  Loss: (0.0463) |  Loss2: (0.0000) | Acc: (98.00%) (5176/5248)
Epoch: 214 | Batch_idx: 50 |  Loss: (0.0489) |  Loss2: (0.0000) | Acc: (98.00%) (6427/6528)
Epoch: 214 | Batch_idx: 60 |  Loss: (0.0486) |  Loss2: (0.0000) | Acc: (98.00%) (7691/7808)
Epoch: 214 | Batch_idx: 70 |  Loss: (0.0487) |  Loss2: (0.0000) | Acc: (98.00%) (8951/9088)
Epoch: 214 | Batch_idx: 80 |  Loss: (0.0482) |  Loss2: (0.0000) | Acc: (98.00%) (10212/10368)
Epoch: 214 | Batch_idx: 90 |  Loss: (0.0482) |  Loss2: (0.0000) | Acc: (98.00%) (11478/11648)
Epoch: 214 | Batch_idx: 100 |  Loss: (0.0487) |  Loss2: (0.0000) | Acc: (98.00%) (12737/12928)
Epoch: 214 | Batch_idx: 110 |  Loss: (0.0481) |  Loss2: (0.0000) | Acc: (98.00%) (13999/14208)
Epoch: 214 | Batch_idx: 120 |  Loss: (0.0478) |  Loss2: (0.0000) | Acc: (98.00%) (15257/15488)
Epoch: 214 | Batch_idx: 130 |  Loss: (0.0475) |  Loss2: (0.0000) | Acc: (98.00%) (16520/16768)
Epoch: 214 | Batch_idx: 140 |  Loss: (0.0484) |  Loss2: (0.0000) | Acc: (98.00%) (17773/18048)
Epoch: 214 | Batch_idx: 150 |  Loss: (0.0494) |  Loss2: (0.0000) | Acc: (98.00%) (19028/19328)
Epoch: 214 | Batch_idx: 160 |  Loss: (0.0496) |  Loss2: (0.0000) | Acc: (98.00%) (20288/20608)
Epoch: 214 | Batch_idx: 170 |  Loss: (0.0501) |  Loss2: (0.0000) | Acc: (98.00%) (21540/21888)
Epoch: 214 | Batch_idx: 180 |  Loss: (0.0503) |  Loss2: (0.0000) | Acc: (98.00%) (22795/23168)
Epoch: 214 | Batch_idx: 190 |  Loss: (0.0507) |  Loss2: (0.0000) | Acc: (98.00%) (24047/24448)
Epoch: 214 | Batch_idx: 200 |  Loss: (0.0509) |  Loss2: (0.0000) | Acc: (98.00%) (25300/25728)
Epoch: 214 | Batch_idx: 210 |  Loss: (0.0512) |  Loss2: (0.0000) | Acc: (98.00%) (26559/27008)
Epoch: 214 | Batch_idx: 220 |  Loss: (0.0518) |  Loss2: (0.0000) | Acc: (98.00%) (27814/28288)
Epoch: 214 | Batch_idx: 230 |  Loss: (0.0514) |  Loss2: (0.0000) | Acc: (98.00%) (29074/29568)
Epoch: 214 | Batch_idx: 240 |  Loss: (0.0517) |  Loss2: (0.0000) | Acc: (98.00%) (30327/30848)
Epoch: 214 | Batch_idx: 250 |  Loss: (0.0516) |  Loss2: (0.0000) | Acc: (98.00%) (31585/32128)
Epoch: 214 | Batch_idx: 260 |  Loss: (0.0517) |  Loss2: (0.0000) | Acc: (98.00%) (32842/33408)
Epoch: 214 | Batch_idx: 270 |  Loss: (0.0516) |  Loss2: (0.0000) | Acc: (98.00%) (34100/34688)
Epoch: 214 | Batch_idx: 280 |  Loss: (0.0515) |  Loss2: (0.0000) | Acc: (98.00%) (35361/35968)
Epoch: 214 | Batch_idx: 290 |  Loss: (0.0512) |  Loss2: (0.0000) | Acc: (98.00%) (36623/37248)
Epoch: 214 | Batch_idx: 300 |  Loss: (0.0512) |  Loss2: (0.0000) | Acc: (98.00%) (37885/38528)
Epoch: 214 | Batch_idx: 310 |  Loss: (0.0511) |  Loss2: (0.0000) | Acc: (98.00%) (39146/39808)
Epoch: 214 | Batch_idx: 320 |  Loss: (0.0515) |  Loss2: (0.0000) | Acc: (98.00%) (40397/41088)
Epoch: 214 | Batch_idx: 330 |  Loss: (0.0515) |  Loss2: (0.0000) | Acc: (98.00%) (41658/42368)
Epoch: 214 | Batch_idx: 340 |  Loss: (0.0517) |  Loss2: (0.0000) | Acc: (98.00%) (42916/43648)
Epoch: 214 | Batch_idx: 350 |  Loss: (0.0523) |  Loss2: (0.0000) | Acc: (98.00%) (44164/44928)
Epoch: 214 | Batch_idx: 360 |  Loss: (0.0525) |  Loss2: (0.0000) | Acc: (98.00%) (45418/46208)
Epoch: 214 | Batch_idx: 370 |  Loss: (0.0526) |  Loss2: (0.0000) | Acc: (98.00%) (46676/47488)
Epoch: 214 | Batch_idx: 380 |  Loss: (0.0527) |  Loss2: (0.0000) | Acc: (98.00%) (47933/48768)
Epoch: 214 | Batch_idx: 390 |  Loss: (0.0526) |  Loss2: (0.0000) | Acc: (98.00%) (49145/50000)
# TEST : Loss: (0.4412) | Acc: (88.00%) (8885/10000)
percent tensor([0.5815, 0.5956, 0.5821, 0.5808, 0.5886, 0.5957, 0.5955, 0.5787, 0.5801,
        0.5882, 0.5887, 0.5911, 0.5850, 0.5791, 0.5989, 0.5863],
       device='cuda:0') torch.Size([16])
percent tensor([0.5315, 0.5342, 0.5231, 0.5290, 0.5233, 0.5362, 0.5291, 0.5232, 0.5240,
        0.5308, 0.5347, 0.5260, 0.5305, 0.5312, 0.5338, 0.5332],
       device='cuda:0') torch.Size([16])
percent tensor([0.5829, 0.4575, 0.7233, 0.7270, 0.7377, 0.6931, 0.5636, 0.6937, 0.6343,
        0.5305, 0.4829, 0.6414, 0.4810, 0.5448, 0.5293, 0.6285],
       device='cuda:0') torch.Size([16])
percent tensor([0.7265, 0.7586, 0.6496, 0.6834, 0.6591, 0.6099, 0.7232, 0.6805, 0.7311,
        0.7575, 0.7733, 0.7170, 0.7415, 0.7647, 0.7079, 0.7065],
       device='cuda:0') torch.Size([16])
percent tensor([0.7422, 0.6262, 0.7835, 0.7762, 0.7970, 0.8422, 0.7358, 0.7572, 0.7115,
        0.6094, 0.5880, 0.6454, 0.5765, 0.6840, 0.7304, 0.7805],
       device='cuda:0') torch.Size([16])
percent tensor([0.6715, 0.7461, 0.7758, 0.7949, 0.7526, 0.8231, 0.7379, 0.5605, 0.7454,
        0.7350, 0.7775, 0.7919, 0.7660, 0.7774, 0.5736, 0.6038],
       device='cuda:0') torch.Size([16])
percent tensor([0.4362, 0.7124, 0.6194, 0.6507, 0.5687, 0.6180, 0.6337, 0.5915, 0.6386,
        0.6482, 0.7675, 0.6457, 0.6264, 0.6598, 0.5484, 0.3965],
       device='cuda:0') torch.Size([16])
percent tensor([0.9999, 0.9998, 0.9998, 1.0000, 1.0000, 0.9996, 0.9999, 0.9997, 0.9998,
        0.9999, 0.9999, 0.9999, 0.9996, 0.9995, 0.9997, 0.9996],
       device='cuda:0') torch.Size([16])
Epoch: 215 | Batch_idx: 0 |  Loss: (0.0267) |  Loss2: (0.0000) | Acc: (99.00%) (127/128)
Epoch: 215 | Batch_idx: 10 |  Loss: (0.0455) |  Loss2: (0.0000) | Acc: (98.00%) (1388/1408)
Epoch: 215 | Batch_idx: 20 |  Loss: (0.0482) |  Loss2: (0.0000) | Acc: (98.00%) (2648/2688)
Epoch: 215 | Batch_idx: 30 |  Loss: (0.0512) |  Loss2: (0.0000) | Acc: (98.00%) (3899/3968)
Epoch: 215 | Batch_idx: 40 |  Loss: (0.0485) |  Loss2: (0.0000) | Acc: (98.00%) (5165/5248)
Epoch: 215 | Batch_idx: 50 |  Loss: (0.0502) |  Loss2: (0.0000) | Acc: (98.00%) (6420/6528)
Epoch: 215 | Batch_idx: 60 |  Loss: (0.0492) |  Loss2: (0.0000) | Acc: (98.00%) (7683/7808)
Epoch: 215 | Batch_idx: 70 |  Loss: (0.0481) |  Loss2: (0.0000) | Acc: (98.00%) (8948/9088)
Epoch: 215 | Batch_idx: 80 |  Loss: (0.0478) |  Loss2: (0.0000) | Acc: (98.00%) (10211/10368)
Epoch: 215 | Batch_idx: 90 |  Loss: (0.0485) |  Loss2: (0.0000) | Acc: (98.00%) (11466/11648)
Epoch: 215 | Batch_idx: 100 |  Loss: (0.0481) |  Loss2: (0.0000) | Acc: (98.00%) (12730/12928)
Epoch: 215 | Batch_idx: 110 |  Loss: (0.0477) |  Loss2: (0.0000) | Acc: (98.00%) (13989/14208)
Epoch: 215 | Batch_idx: 120 |  Loss: (0.0479) |  Loss2: (0.0000) | Acc: (98.00%) (15246/15488)
Epoch: 215 | Batch_idx: 130 |  Loss: (0.0479) |  Loss2: (0.0000) | Acc: (98.00%) (16506/16768)
Epoch: 215 | Batch_idx: 140 |  Loss: (0.0491) |  Loss2: (0.0000) | Acc: (98.00%) (17758/18048)
Epoch: 215 | Batch_idx: 150 |  Loss: (0.0488) |  Loss2: (0.0000) | Acc: (98.00%) (19024/19328)
Epoch: 215 | Batch_idx: 160 |  Loss: (0.0495) |  Loss2: (0.0000) | Acc: (98.00%) (20279/20608)
Epoch: 215 | Batch_idx: 170 |  Loss: (0.0495) |  Loss2: (0.0000) | Acc: (98.00%) (21540/21888)
Epoch: 215 | Batch_idx: 180 |  Loss: (0.0498) |  Loss2: (0.0000) | Acc: (98.00%) (22800/23168)
Epoch: 215 | Batch_idx: 190 |  Loss: (0.0501) |  Loss2: (0.0000) | Acc: (98.00%) (24054/24448)
Epoch: 215 | Batch_idx: 200 |  Loss: (0.0508) |  Loss2: (0.0000) | Acc: (98.00%) (25310/25728)
Epoch: 215 | Batch_idx: 210 |  Loss: (0.0511) |  Loss2: (0.0000) | Acc: (98.00%) (26565/27008)
Epoch: 215 | Batch_idx: 220 |  Loss: (0.0516) |  Loss2: (0.0000) | Acc: (98.00%) (27816/28288)
Epoch: 215 | Batch_idx: 230 |  Loss: (0.0517) |  Loss2: (0.0000) | Acc: (98.00%) (29077/29568)
Epoch: 215 | Batch_idx: 240 |  Loss: (0.0520) |  Loss2: (0.0000) | Acc: (98.00%) (30330/30848)
Epoch: 215 | Batch_idx: 250 |  Loss: (0.0522) |  Loss2: (0.0000) | Acc: (98.00%) (31589/32128)
Epoch: 215 | Batch_idx: 260 |  Loss: (0.0518) |  Loss2: (0.0000) | Acc: (98.00%) (32852/33408)
Epoch: 215 | Batch_idx: 270 |  Loss: (0.0523) |  Loss2: (0.0000) | Acc: (98.00%) (34109/34688)
Epoch: 215 | Batch_idx: 280 |  Loss: (0.0521) |  Loss2: (0.0000) | Acc: (98.00%) (35372/35968)
Epoch: 215 | Batch_idx: 290 |  Loss: (0.0517) |  Loss2: (0.0000) | Acc: (98.00%) (36635/37248)
Epoch: 215 | Batch_idx: 300 |  Loss: (0.0519) |  Loss2: (0.0000) | Acc: (98.00%) (37886/38528)
Epoch: 215 | Batch_idx: 310 |  Loss: (0.0524) |  Loss2: (0.0000) | Acc: (98.00%) (39142/39808)
Epoch: 215 | Batch_idx: 320 |  Loss: (0.0522) |  Loss2: (0.0000) | Acc: (98.00%) (40403/41088)
Epoch: 215 | Batch_idx: 330 |  Loss: (0.0526) |  Loss2: (0.0000) | Acc: (98.00%) (41659/42368)
Epoch: 215 | Batch_idx: 340 |  Loss: (0.0532) |  Loss2: (0.0000) | Acc: (98.00%) (42902/43648)
Epoch: 215 | Batch_idx: 350 |  Loss: (0.0531) |  Loss2: (0.0000) | Acc: (98.00%) (44160/44928)
Epoch: 215 | Batch_idx: 360 |  Loss: (0.0536) |  Loss2: (0.0000) | Acc: (98.00%) (45405/46208)
Epoch: 215 | Batch_idx: 370 |  Loss: (0.0540) |  Loss2: (0.0000) | Acc: (98.00%) (46658/47488)
Epoch: 215 | Batch_idx: 380 |  Loss: (0.0542) |  Loss2: (0.0000) | Acc: (98.00%) (47913/48768)
Epoch: 215 | Batch_idx: 390 |  Loss: (0.0546) |  Loss2: (0.0000) | Acc: (98.00%) (49120/50000)
=> saving checkpoint 'drive/app/torch/save_Schedule/checkpoint_215.pth.tar'
# TEST : Loss: (0.4375) | Acc: (88.00%) (8882/10000)
percent tensor([0.5803, 0.5939, 0.5818, 0.5795, 0.5881, 0.5950, 0.5942, 0.5771, 0.5790,
        0.5872, 0.5874, 0.5902, 0.5833, 0.5775, 0.5976, 0.5848],
       device='cuda:0') torch.Size([16])
percent tensor([0.5319, 0.5343, 0.5228, 0.5285, 0.5229, 0.5365, 0.5296, 0.5232, 0.5252,
        0.5307, 0.5349, 0.5255, 0.5311, 0.5317, 0.5342, 0.5334],
       device='cuda:0') torch.Size([16])
percent tensor([0.6043, 0.4934, 0.7300, 0.7379, 0.7512, 0.7004, 0.5949, 0.6964, 0.6475,
        0.5620, 0.5138, 0.6539, 0.4984, 0.5824, 0.5622, 0.6512],
       device='cuda:0') torch.Size([16])
percent tensor([0.7272, 0.7576, 0.6505, 0.6831, 0.6595, 0.5963, 0.7253, 0.6828, 0.7335,
        0.7569, 0.7659, 0.7216, 0.7445, 0.7668, 0.7064, 0.7040],
       device='cuda:0') torch.Size([16])
percent tensor([0.7541, 0.6389, 0.7876, 0.7761, 0.7956, 0.8538, 0.7396, 0.7642, 0.7180,
        0.6185, 0.6079, 0.6459, 0.6013, 0.6794, 0.7391, 0.7930],
       device='cuda:0') torch.Size([16])
percent tensor([0.6751, 0.7747, 0.7732, 0.8167, 0.7678, 0.8207, 0.7395, 0.5638, 0.7599,
        0.7447, 0.8048, 0.7731, 0.7773, 0.7979, 0.5727, 0.5896],
       device='cuda:0') torch.Size([16])
percent tensor([0.4431, 0.7355, 0.6350, 0.6687, 0.5949, 0.6267, 0.6525, 0.5743, 0.6884,
        0.6770, 0.7808, 0.6465, 0.6567, 0.6705, 0.5364, 0.3975],
       device='cuda:0') torch.Size([16])
percent tensor([0.9999, 0.9998, 0.9998, 0.9999, 1.0000, 0.9996, 0.9999, 0.9997, 0.9999,
        0.9999, 0.9999, 0.9999, 0.9997, 0.9997, 0.9998, 0.9997],
       device='cuda:0') torch.Size([16])
Epoch: 216 | Batch_idx: 0 |  Loss: (0.0684) |  Loss2: (0.0000) | Acc: (96.00%) (124/128)
Epoch: 216 | Batch_idx: 10 |  Loss: (0.0519) |  Loss2: (0.0000) | Acc: (98.00%) (1381/1408)
Epoch: 216 | Batch_idx: 20 |  Loss: (0.0595) |  Loss2: (0.0000) | Acc: (97.00%) (2632/2688)
Epoch: 216 | Batch_idx: 30 |  Loss: (0.0610) |  Loss2: (0.0000) | Acc: (97.00%) (3884/3968)
Epoch: 216 | Batch_idx: 40 |  Loss: (0.0570) |  Loss2: (0.0000) | Acc: (98.00%) (5146/5248)
Epoch: 216 | Batch_idx: 50 |  Loss: (0.0553) |  Loss2: (0.0000) | Acc: (98.00%) (6404/6528)
Epoch: 216 | Batch_idx: 60 |  Loss: (0.0558) |  Loss2: (0.0000) | Acc: (98.00%) (7663/7808)
Epoch: 216 | Batch_idx: 70 |  Loss: (0.0536) |  Loss2: (0.0000) | Acc: (98.00%) (8926/9088)
Epoch: 216 | Batch_idx: 80 |  Loss: (0.0538) |  Loss2: (0.0000) | Acc: (98.00%) (10183/10368)
Epoch: 216 | Batch_idx: 90 |  Loss: (0.0536) |  Loss2: (0.0000) | Acc: (98.00%) (11437/11648)
Epoch: 216 | Batch_idx: 100 |  Loss: (0.0549) |  Loss2: (0.0000) | Acc: (98.00%) (12694/12928)
Epoch: 216 | Batch_idx: 110 |  Loss: (0.0542) |  Loss2: (0.0000) | Acc: (98.00%) (13955/14208)
Epoch: 216 | Batch_idx: 120 |  Loss: (0.0541) |  Loss2: (0.0000) | Acc: (98.00%) (15216/15488)
Epoch: 216 | Batch_idx: 130 |  Loss: (0.0550) |  Loss2: (0.0000) | Acc: (98.00%) (16465/16768)
Epoch: 216 | Batch_idx: 140 |  Loss: (0.0547) |  Loss2: (0.0000) | Acc: (98.00%) (17721/18048)
Epoch: 216 | Batch_idx: 150 |  Loss: (0.0542) |  Loss2: (0.0000) | Acc: (98.00%) (18981/19328)
Epoch: 216 | Batch_idx: 160 |  Loss: (0.0539) |  Loss2: (0.0000) | Acc: (98.00%) (20240/20608)
Epoch: 216 | Batch_idx: 170 |  Loss: (0.0535) |  Loss2: (0.0000) | Acc: (98.00%) (21499/21888)
Epoch: 216 | Batch_idx: 180 |  Loss: (0.0535) |  Loss2: (0.0000) | Acc: (98.00%) (22758/23168)
Epoch: 216 | Batch_idx: 190 |  Loss: (0.0531) |  Loss2: (0.0000) | Acc: (98.00%) (24021/24448)
Epoch: 216 | Batch_idx: 200 |  Loss: (0.0528) |  Loss2: (0.0000) | Acc: (98.00%) (25285/25728)
Epoch: 216 | Batch_idx: 210 |  Loss: (0.0523) |  Loss2: (0.0000) | Acc: (98.00%) (26547/27008)
Epoch: 216 | Batch_idx: 220 |  Loss: (0.0522) |  Loss2: (0.0000) | Acc: (98.00%) (27806/28288)
Epoch: 216 | Batch_idx: 230 |  Loss: (0.0522) |  Loss2: (0.0000) | Acc: (98.00%) (29065/29568)
Epoch: 216 | Batch_idx: 240 |  Loss: (0.0519) |  Loss2: (0.0000) | Acc: (98.00%) (30324/30848)
Epoch: 216 | Batch_idx: 250 |  Loss: (0.0520) |  Loss2: (0.0000) | Acc: (98.00%) (31580/32128)
Epoch: 216 | Batch_idx: 260 |  Loss: (0.0518) |  Loss2: (0.0000) | Acc: (98.00%) (32845/33408)
Epoch: 216 | Batch_idx: 270 |  Loss: (0.0519) |  Loss2: (0.0000) | Acc: (98.00%) (34102/34688)
Epoch: 216 | Batch_idx: 280 |  Loss: (0.0521) |  Loss2: (0.0000) | Acc: (98.00%) (35357/35968)
Epoch: 216 | Batch_idx: 290 |  Loss: (0.0515) |  Loss2: (0.0000) | Acc: (98.00%) (36627/37248)
Epoch: 216 | Batch_idx: 300 |  Loss: (0.0512) |  Loss2: (0.0000) | Acc: (98.00%) (37892/38528)
Epoch: 216 | Batch_idx: 310 |  Loss: (0.0507) |  Loss2: (0.0000) | Acc: (98.00%) (39157/39808)
Epoch: 216 | Batch_idx: 320 |  Loss: (0.0507) |  Loss2: (0.0000) | Acc: (98.00%) (40416/41088)
Epoch: 216 | Batch_idx: 330 |  Loss: (0.0502) |  Loss2: (0.0000) | Acc: (98.00%) (41683/42368)
Epoch: 216 | Batch_idx: 340 |  Loss: (0.0503) |  Loss2: (0.0000) | Acc: (98.00%) (42941/43648)
Epoch: 216 | Batch_idx: 350 |  Loss: (0.0502) |  Loss2: (0.0000) | Acc: (98.00%) (44201/44928)
Epoch: 216 | Batch_idx: 360 |  Loss: (0.0501) |  Loss2: (0.0000) | Acc: (98.00%) (45463/46208)
Epoch: 216 | Batch_idx: 370 |  Loss: (0.0501) |  Loss2: (0.0000) | Acc: (98.00%) (46726/47488)
Epoch: 216 | Batch_idx: 380 |  Loss: (0.0500) |  Loss2: (0.0000) | Acc: (98.00%) (47990/48768)
Epoch: 216 | Batch_idx: 390 |  Loss: (0.0503) |  Loss2: (0.0000) | Acc: (98.00%) (49202/50000)
# TEST : Loss: (0.4671) | Acc: (88.00%) (8847/10000)
percent tensor([0.5807, 0.5957, 0.5804, 0.5801, 0.5870, 0.5950, 0.5950, 0.5783, 0.5792,
        0.5884, 0.5886, 0.5904, 0.5842, 0.5793, 0.5986, 0.5860],
       device='cuda:0') torch.Size([16])
percent tensor([0.5330, 0.5350, 0.5238, 0.5300, 0.5241, 0.5385, 0.5302, 0.5240, 0.5258,
        0.5317, 0.5358, 0.5268, 0.5321, 0.5319, 0.5359, 0.5346],
       device='cuda:0') torch.Size([16])
percent tensor([0.5961, 0.4620, 0.7242, 0.7291, 0.7478, 0.6964, 0.5714, 0.7009, 0.6481,
        0.5365, 0.4944, 0.6316, 0.4870, 0.5468, 0.5402, 0.6405],
       device='cuda:0') torch.Size([16])
percent tensor([0.7297, 0.7647, 0.6585, 0.6828, 0.6653, 0.6079, 0.7321, 0.6848, 0.7352,
        0.7639, 0.7708, 0.7289, 0.7479, 0.7724, 0.7127, 0.7056],
       device='cuda:0') torch.Size([16])
percent tensor([0.7493, 0.6235, 0.7769, 0.7824, 0.7913, 0.8489, 0.7291, 0.7564, 0.7081,
        0.6061, 0.5952, 0.6380, 0.5849, 0.6766, 0.7247, 0.7922],
       device='cuda:0') torch.Size([16])
percent tensor([0.6693, 0.7713, 0.7699, 0.8009, 0.7554, 0.8337, 0.7615, 0.5365, 0.7730,
        0.7552, 0.8075, 0.7892, 0.7860, 0.7897, 0.5697, 0.5685],
       device='cuda:0') torch.Size([16])
percent tensor([0.4679, 0.7205, 0.6354, 0.6518, 0.5679, 0.6437, 0.6549, 0.5574, 0.7119,
        0.6712, 0.7701, 0.6474, 0.6483, 0.6549, 0.5472, 0.3926],
       device='cuda:0') torch.Size([16])
percent tensor([0.9999, 0.9999, 0.9998, 0.9999, 1.0000, 0.9997, 1.0000, 0.9994, 0.9999,
        0.9999, 0.9999, 0.9999, 0.9997, 0.9997, 0.9998, 0.9997],
       device='cuda:0') torch.Size([16])
Epoch: 217 | Batch_idx: 0 |  Loss: (0.1077) |  Loss2: (0.0000) | Acc: (96.00%) (124/128)
Epoch: 217 | Batch_idx: 10 |  Loss: (0.0591) |  Loss2: (0.0000) | Acc: (98.00%) (1383/1408)
Epoch: 217 | Batch_idx: 20 |  Loss: (0.0513) |  Loss2: (0.0000) | Acc: (98.00%) (2645/2688)
Epoch: 217 | Batch_idx: 30 |  Loss: (0.0516) |  Loss2: (0.0000) | Acc: (98.00%) (3904/3968)
Epoch: 217 | Batch_idx: 40 |  Loss: (0.0498) |  Loss2: (0.0000) | Acc: (98.00%) (5166/5248)
Epoch: 217 | Batch_idx: 50 |  Loss: (0.0506) |  Loss2: (0.0000) | Acc: (98.00%) (6424/6528)
Epoch: 217 | Batch_idx: 60 |  Loss: (0.0511) |  Loss2: (0.0000) | Acc: (98.00%) (7679/7808)
Epoch: 217 | Batch_idx: 70 |  Loss: (0.0509) |  Loss2: (0.0000) | Acc: (98.00%) (8941/9088)
Epoch: 217 | Batch_idx: 80 |  Loss: (0.0514) |  Loss2: (0.0000) | Acc: (98.00%) (10188/10368)
Epoch: 217 | Batch_idx: 90 |  Loss: (0.0528) |  Loss2: (0.0000) | Acc: (98.00%) (11442/11648)
Epoch: 217 | Batch_idx: 100 |  Loss: (0.0518) |  Loss2: (0.0000) | Acc: (98.00%) (12703/12928)
Epoch: 217 | Batch_idx: 110 |  Loss: (0.0509) |  Loss2: (0.0000) | Acc: (98.00%) (13967/14208)
Epoch: 217 | Batch_idx: 120 |  Loss: (0.0516) |  Loss2: (0.0000) | Acc: (98.00%) (15222/15488)
Epoch: 217 | Batch_idx: 130 |  Loss: (0.0511) |  Loss2: (0.0000) | Acc: (98.00%) (16482/16768)
Epoch: 217 | Batch_idx: 140 |  Loss: (0.0513) |  Loss2: (0.0000) | Acc: (98.00%) (17742/18048)
Epoch: 217 | Batch_idx: 150 |  Loss: (0.0507) |  Loss2: (0.0000) | Acc: (98.00%) (19002/19328)
Epoch: 217 | Batch_idx: 160 |  Loss: (0.0511) |  Loss2: (0.0000) | Acc: (98.00%) (20258/20608)
Epoch: 217 | Batch_idx: 170 |  Loss: (0.0517) |  Loss2: (0.0000) | Acc: (98.00%) (21511/21888)
Epoch: 217 | Batch_idx: 180 |  Loss: (0.0511) |  Loss2: (0.0000) | Acc: (98.00%) (22774/23168)
Epoch: 217 | Batch_idx: 190 |  Loss: (0.0514) |  Loss2: (0.0000) | Acc: (98.00%) (24031/24448)
Epoch: 217 | Batch_idx: 200 |  Loss: (0.0512) |  Loss2: (0.0000) | Acc: (98.00%) (25290/25728)
Epoch: 217 | Batch_idx: 210 |  Loss: (0.0513) |  Loss2: (0.0000) | Acc: (98.00%) (26546/27008)
Epoch: 217 | Batch_idx: 220 |  Loss: (0.0509) |  Loss2: (0.0000) | Acc: (98.00%) (27809/28288)
Epoch: 217 | Batch_idx: 230 |  Loss: (0.0511) |  Loss2: (0.0000) | Acc: (98.00%) (29062/29568)
Epoch: 217 | Batch_idx: 240 |  Loss: (0.0515) |  Loss2: (0.0000) | Acc: (98.00%) (30312/30848)
Epoch: 217 | Batch_idx: 250 |  Loss: (0.0513) |  Loss2: (0.0000) | Acc: (98.00%) (31573/32128)
Epoch: 217 | Batch_idx: 260 |  Loss: (0.0519) |  Loss2: (0.0000) | Acc: (98.00%) (32823/33408)
Epoch: 217 | Batch_idx: 270 |  Loss: (0.0517) |  Loss2: (0.0000) | Acc: (98.00%) (34082/34688)
Epoch: 217 | Batch_idx: 280 |  Loss: (0.0514) |  Loss2: (0.0000) | Acc: (98.00%) (35342/35968)
Epoch: 217 | Batch_idx: 290 |  Loss: (0.0516) |  Loss2: (0.0000) | Acc: (98.00%) (36594/37248)
Epoch: 217 | Batch_idx: 300 |  Loss: (0.0515) |  Loss2: (0.0000) | Acc: (98.00%) (37854/38528)
Epoch: 217 | Batch_idx: 310 |  Loss: (0.0515) |  Loss2: (0.0000) | Acc: (98.00%) (39110/39808)
Epoch: 217 | Batch_idx: 320 |  Loss: (0.0515) |  Loss2: (0.0000) | Acc: (98.00%) (40369/41088)
Epoch: 217 | Batch_idx: 330 |  Loss: (0.0518) |  Loss2: (0.0000) | Acc: (98.00%) (41620/42368)
Epoch: 217 | Batch_idx: 340 |  Loss: (0.0520) |  Loss2: (0.0000) | Acc: (98.00%) (42873/43648)
Epoch: 217 | Batch_idx: 350 |  Loss: (0.0522) |  Loss2: (0.0000) | Acc: (98.00%) (44125/44928)
Epoch: 217 | Batch_idx: 360 |  Loss: (0.0523) |  Loss2: (0.0000) | Acc: (98.00%) (45382/46208)
Epoch: 217 | Batch_idx: 370 |  Loss: (0.0525) |  Loss2: (0.0000) | Acc: (98.00%) (46637/47488)
Epoch: 217 | Batch_idx: 380 |  Loss: (0.0521) |  Loss2: (0.0000) | Acc: (98.00%) (47901/48768)
Epoch: 217 | Batch_idx: 390 |  Loss: (0.0520) |  Loss2: (0.0000) | Acc: (98.00%) (49116/50000)
# TEST : Loss: (0.4281) | Acc: (88.00%) (8889/10000)
percent tensor([0.5826, 0.5961, 0.5870, 0.5834, 0.5918, 0.5957, 0.5971, 0.5812, 0.5811,
        0.5902, 0.5892, 0.5956, 0.5858, 0.5794, 0.5993, 0.5873],
       device='cuda:0') torch.Size([16])
percent tensor([0.5331, 0.5363, 0.5236, 0.5296, 0.5236, 0.5384, 0.5310, 0.5244, 0.5261,
        0.5322, 0.5370, 0.5261, 0.5323, 0.5335, 0.5363, 0.5346],
       device='cuda:0') torch.Size([16])
percent tensor([0.6114, 0.4814, 0.7345, 0.7351, 0.7510, 0.6959, 0.5904, 0.6993, 0.6592,
        0.5619, 0.5152, 0.6596, 0.5092, 0.5776, 0.5479, 0.6424],
       device='cuda:0') torch.Size([16])
percent tensor([0.7283, 0.7604, 0.6509, 0.6776, 0.6594, 0.5957, 0.7302, 0.6830, 0.7325,
        0.7623, 0.7726, 0.7238, 0.7455, 0.7638, 0.7073, 0.7050],
       device='cuda:0') torch.Size([16])
percent tensor([0.7466, 0.6262, 0.7766, 0.7632, 0.7894, 0.8572, 0.7253, 0.7590, 0.7062,
        0.5987, 0.5950, 0.6249, 0.5854, 0.6762, 0.7346, 0.7909],
       device='cuda:0') torch.Size([16])
percent tensor([0.6699, 0.7766, 0.7709, 0.8105, 0.7901, 0.8387, 0.7483, 0.5567, 0.7716,
        0.7552, 0.8035, 0.7742, 0.7797, 0.7841, 0.5867, 0.5696],
       device='cuda:0') torch.Size([16])
percent tensor([0.4752, 0.7378, 0.6493, 0.6817, 0.5987, 0.6468, 0.6746, 0.5749, 0.6916,
        0.6833, 0.7864, 0.6631, 0.6617, 0.6360, 0.5505, 0.3903],
       device='cuda:0') torch.Size([16])
percent tensor([0.9999, 0.9998, 0.9999, 0.9999, 0.9999, 0.9997, 1.0000, 0.9996, 0.9999,
        0.9999, 0.9998, 0.9999, 0.9998, 0.9997, 0.9997, 0.9995],
       device='cuda:0') torch.Size([16])
Epoch: 218 | Batch_idx: 0 |  Loss: (0.0620) |  Loss2: (0.0000) | Acc: (97.00%) (125/128)
Epoch: 218 | Batch_idx: 10 |  Loss: (0.0606) |  Loss2: (0.0000) | Acc: (97.00%) (1375/1408)
Epoch: 218 | Batch_idx: 20 |  Loss: (0.0530) |  Loss2: (0.0000) | Acc: (97.00%) (2634/2688)
Epoch: 218 | Batch_idx: 30 |  Loss: (0.0548) |  Loss2: (0.0000) | Acc: (97.00%) (3888/3968)
Epoch: 218 | Batch_idx: 40 |  Loss: (0.0550) |  Loss2: (0.0000) | Acc: (98.00%) (5146/5248)
Epoch: 218 | Batch_idx: 50 |  Loss: (0.0546) |  Loss2: (0.0000) | Acc: (98.00%) (6409/6528)
Epoch: 218 | Batch_idx: 60 |  Loss: (0.0534) |  Loss2: (0.0000) | Acc: (98.00%) (7668/7808)
Epoch: 218 | Batch_idx: 70 |  Loss: (0.0538) |  Loss2: (0.0000) | Acc: (98.00%) (8922/9088)
Epoch: 218 | Batch_idx: 80 |  Loss: (0.0534) |  Loss2: (0.0000) | Acc: (98.00%) (10184/10368)
Epoch: 218 | Batch_idx: 90 |  Loss: (0.0518) |  Loss2: (0.0000) | Acc: (98.00%) (11449/11648)
Epoch: 218 | Batch_idx: 100 |  Loss: (0.0528) |  Loss2: (0.0000) | Acc: (98.00%) (12706/12928)
Epoch: 218 | Batch_idx: 110 |  Loss: (0.0530) |  Loss2: (0.0000) | Acc: (98.00%) (13962/14208)
Epoch: 218 | Batch_idx: 120 |  Loss: (0.0517) |  Loss2: (0.0000) | Acc: (98.00%) (15229/15488)
Epoch: 218 | Batch_idx: 130 |  Loss: (0.0524) |  Loss2: (0.0000) | Acc: (98.00%) (16486/16768)
Epoch: 218 | Batch_idx: 140 |  Loss: (0.0516) |  Loss2: (0.0000) | Acc: (98.00%) (17746/18048)
Epoch: 218 | Batch_idx: 150 |  Loss: (0.0513) |  Loss2: (0.0000) | Acc: (98.00%) (19008/19328)
Epoch: 218 | Batch_idx: 160 |  Loss: (0.0513) |  Loss2: (0.0000) | Acc: (98.00%) (20267/20608)
Epoch: 218 | Batch_idx: 170 |  Loss: (0.0506) |  Loss2: (0.0000) | Acc: (98.00%) (21532/21888)
Epoch: 218 | Batch_idx: 180 |  Loss: (0.0505) |  Loss2: (0.0000) | Acc: (98.00%) (22796/23168)
Epoch: 218 | Batch_idx: 190 |  Loss: (0.0503) |  Loss2: (0.0000) | Acc: (98.00%) (24057/24448)
Epoch: 218 | Batch_idx: 200 |  Loss: (0.0506) |  Loss2: (0.0000) | Acc: (98.00%) (25311/25728)
Epoch: 218 | Batch_idx: 210 |  Loss: (0.0505) |  Loss2: (0.0000) | Acc: (98.00%) (26574/27008)
Epoch: 218 | Batch_idx: 220 |  Loss: (0.0503) |  Loss2: (0.0000) | Acc: (98.00%) (27835/28288)
Epoch: 218 | Batch_idx: 230 |  Loss: (0.0502) |  Loss2: (0.0000) | Acc: (98.00%) (29100/29568)
Epoch: 218 | Batch_idx: 240 |  Loss: (0.0501) |  Loss2: (0.0000) | Acc: (98.00%) (30363/30848)
Epoch: 218 | Batch_idx: 250 |  Loss: (0.0502) |  Loss2: (0.0000) | Acc: (98.00%) (31624/32128)
Epoch: 218 | Batch_idx: 260 |  Loss: (0.0501) |  Loss2: (0.0000) | Acc: (98.00%) (32883/33408)
Epoch: 218 | Batch_idx: 270 |  Loss: (0.0498) |  Loss2: (0.0000) | Acc: (98.00%) (34147/34688)
Epoch: 218 | Batch_idx: 280 |  Loss: (0.0499) |  Loss2: (0.0000) | Acc: (98.00%) (35402/35968)
Epoch: 218 | Batch_idx: 290 |  Loss: (0.0498) |  Loss2: (0.0000) | Acc: (98.00%) (36659/37248)
Epoch: 218 | Batch_idx: 300 |  Loss: (0.0499) |  Loss2: (0.0000) | Acc: (98.00%) (37920/38528)
Epoch: 218 | Batch_idx: 310 |  Loss: (0.0499) |  Loss2: (0.0000) | Acc: (98.00%) (39175/39808)
Epoch: 218 | Batch_idx: 320 |  Loss: (0.0498) |  Loss2: (0.0000) | Acc: (98.00%) (40438/41088)
Epoch: 218 | Batch_idx: 330 |  Loss: (0.0497) |  Loss2: (0.0000) | Acc: (98.00%) (41695/42368)
Epoch: 218 | Batch_idx: 340 |  Loss: (0.0496) |  Loss2: (0.0000) | Acc: (98.00%) (42955/43648)
Epoch: 218 | Batch_idx: 350 |  Loss: (0.0497) |  Loss2: (0.0000) | Acc: (98.00%) (44214/44928)
Epoch: 218 | Batch_idx: 360 |  Loss: (0.0495) |  Loss2: (0.0000) | Acc: (98.00%) (45475/46208)
Epoch: 218 | Batch_idx: 370 |  Loss: (0.0495) |  Loss2: (0.0000) | Acc: (98.00%) (46731/47488)
Epoch: 218 | Batch_idx: 380 |  Loss: (0.0498) |  Loss2: (0.0000) | Acc: (98.00%) (47984/48768)
Epoch: 218 | Batch_idx: 390 |  Loss: (0.0499) |  Loss2: (0.0000) | Acc: (98.00%) (49188/50000)
# TEST : Loss: (0.4377) | Acc: (89.00%) (8917/10000)
percent tensor([0.5829, 0.5963, 0.5887, 0.5836, 0.5926, 0.5961, 0.5969, 0.5818, 0.5809,
        0.5904, 0.5894, 0.5954, 0.5858, 0.5791, 0.5995, 0.5868],
       device='cuda:0') torch.Size([16])
percent tensor([0.5331, 0.5360, 0.5229, 0.5293, 0.5224, 0.5394, 0.5305, 0.5237, 0.5259,
        0.5322, 0.5369, 0.5257, 0.5322, 0.5336, 0.5362, 0.5354],
       device='cuda:0') torch.Size([16])
percent tensor([0.5984, 0.4659, 0.7271, 0.7370, 0.7430, 0.6918, 0.5723, 0.6994, 0.6447,
        0.5458, 0.4959, 0.6517, 0.4913, 0.5526, 0.5383, 0.6451],
       device='cuda:0') torch.Size([16])
percent tensor([0.7273, 0.7646, 0.6525, 0.6774, 0.6607, 0.5985, 0.7296, 0.6830, 0.7346,
        0.7636, 0.7747, 0.7237, 0.7466, 0.7731, 0.7097, 0.7056],
       device='cuda:0') torch.Size([16])
percent tensor([0.7529, 0.6463, 0.7892, 0.7766, 0.8010, 0.8542, 0.7516, 0.7669, 0.7125,
        0.6265, 0.5957, 0.6419, 0.5920, 0.6877, 0.7473, 0.7994],
       device='cuda:0') torch.Size([16])
percent tensor([0.6771, 0.7782, 0.7767, 0.8146, 0.7819, 0.8399, 0.7629, 0.5583, 0.7655,
        0.7603, 0.8100, 0.7878, 0.7862, 0.7919, 0.6233, 0.6025],
       device='cuda:0') torch.Size([16])
percent tensor([0.4512, 0.7537, 0.6176, 0.6532, 0.5555, 0.6265, 0.6433, 0.5658, 0.6647,
        0.6750, 0.7899, 0.6505, 0.6373, 0.6514, 0.5516, 0.3753],
       device='cuda:0') torch.Size([16])
percent tensor([0.9999, 0.9999, 0.9998, 0.9999, 1.0000, 0.9995, 1.0000, 0.9998, 0.9999,
        1.0000, 0.9999, 0.9999, 0.9998, 0.9997, 0.9998, 0.9996],
       device='cuda:0') torch.Size([16])
Epoch: 219 | Batch_idx: 0 |  Loss: (0.0508) |  Loss2: (0.0000) | Acc: (98.00%) (126/128)
Epoch: 219 | Batch_idx: 10 |  Loss: (0.0406) |  Loss2: (0.0000) | Acc: (98.00%) (1390/1408)
Epoch: 219 | Batch_idx: 20 |  Loss: (0.0421) |  Loss2: (0.0000) | Acc: (98.00%) (2649/2688)
Epoch: 219 | Batch_idx: 30 |  Loss: (0.0464) |  Loss2: (0.0000) | Acc: (98.00%) (3902/3968)
Epoch: 219 | Batch_idx: 40 |  Loss: (0.0445) |  Loss2: (0.0000) | Acc: (98.00%) (5166/5248)
Epoch: 219 | Batch_idx: 50 |  Loss: (0.0462) |  Loss2: (0.0000) | Acc: (98.00%) (6425/6528)
Epoch: 219 | Batch_idx: 60 |  Loss: (0.0457) |  Loss2: (0.0000) | Acc: (98.00%) (7689/7808)
Epoch: 219 | Batch_idx: 70 |  Loss: (0.0458) |  Loss2: (0.0000) | Acc: (98.00%) (8950/9088)
Epoch: 219 | Batch_idx: 80 |  Loss: (0.0463) |  Loss2: (0.0000) | Acc: (98.00%) (10214/10368)
Epoch: 219 | Batch_idx: 90 |  Loss: (0.0463) |  Loss2: (0.0000) | Acc: (98.00%) (11474/11648)
Epoch: 219 | Batch_idx: 100 |  Loss: (0.0464) |  Loss2: (0.0000) | Acc: (98.00%) (12735/12928)
Epoch: 219 | Batch_idx: 110 |  Loss: (0.0479) |  Loss2: (0.0000) | Acc: (98.00%) (13991/14208)
Epoch: 219 | Batch_idx: 120 |  Loss: (0.0487) |  Loss2: (0.0000) | Acc: (98.00%) (15250/15488)
Epoch: 219 | Batch_idx: 130 |  Loss: (0.0495) |  Loss2: (0.0000) | Acc: (98.00%) (16507/16768)
Epoch: 219 | Batch_idx: 140 |  Loss: (0.0495) |  Loss2: (0.0000) | Acc: (98.00%) (17764/18048)
Epoch: 219 | Batch_idx: 150 |  Loss: (0.0501) |  Loss2: (0.0000) | Acc: (98.00%) (19020/19328)
Epoch: 219 | Batch_idx: 160 |  Loss: (0.0497) |  Loss2: (0.0000) | Acc: (98.00%) (20286/20608)
Epoch: 219 | Batch_idx: 170 |  Loss: (0.0495) |  Loss2: (0.0000) | Acc: (98.00%) (21546/21888)
Epoch: 219 | Batch_idx: 180 |  Loss: (0.0491) |  Loss2: (0.0000) | Acc: (98.00%) (22808/23168)
Epoch: 219 | Batch_idx: 190 |  Loss: (0.0488) |  Loss2: (0.0000) | Acc: (98.00%) (24069/24448)
Epoch: 219 | Batch_idx: 200 |  Loss: (0.0488) |  Loss2: (0.0000) | Acc: (98.00%) (25330/25728)
Epoch: 219 | Batch_idx: 210 |  Loss: (0.0493) |  Loss2: (0.0000) | Acc: (98.00%) (26585/27008)
Epoch: 219 | Batch_idx: 220 |  Loss: (0.0491) |  Loss2: (0.0000) | Acc: (98.00%) (27849/28288)
Epoch: 219 | Batch_idx: 230 |  Loss: (0.0496) |  Loss2: (0.0000) | Acc: (98.00%) (29101/29568)
Epoch: 219 | Batch_idx: 240 |  Loss: (0.0496) |  Loss2: (0.0000) | Acc: (98.00%) (30361/30848)
Epoch: 219 | Batch_idx: 250 |  Loss: (0.0498) |  Loss2: (0.0000) | Acc: (98.00%) (31614/32128)
Epoch: 219 | Batch_idx: 260 |  Loss: (0.0497) |  Loss2: (0.0000) | Acc: (98.00%) (32873/33408)
Epoch: 219 | Batch_idx: 270 |  Loss: (0.0496) |  Loss2: (0.0000) | Acc: (98.00%) (34135/34688)
Epoch: 219 | Batch_idx: 280 |  Loss: (0.0496) |  Loss2: (0.0000) | Acc: (98.00%) (35394/35968)
Epoch: 219 | Batch_idx: 290 |  Loss: (0.0495) |  Loss2: (0.0000) | Acc: (98.00%) (36652/37248)
Epoch: 219 | Batch_idx: 300 |  Loss: (0.0496) |  Loss2: (0.0000) | Acc: (98.00%) (37908/38528)
Epoch: 219 | Batch_idx: 310 |  Loss: (0.0495) |  Loss2: (0.0000) | Acc: (98.00%) (39167/39808)
Epoch: 219 | Batch_idx: 320 |  Loss: (0.0492) |  Loss2: (0.0000) | Acc: (98.00%) (40433/41088)
Epoch: 219 | Batch_idx: 330 |  Loss: (0.0493) |  Loss2: (0.0000) | Acc: (98.00%) (41690/42368)
Epoch: 219 | Batch_idx: 340 |  Loss: (0.0493) |  Loss2: (0.0000) | Acc: (98.00%) (42950/43648)
Epoch: 219 | Batch_idx: 350 |  Loss: (0.0490) |  Loss2: (0.0000) | Acc: (98.00%) (44211/44928)
Epoch: 219 | Batch_idx: 360 |  Loss: (0.0489) |  Loss2: (0.0000) | Acc: (98.00%) (45473/46208)
Epoch: 219 | Batch_idx: 370 |  Loss: (0.0490) |  Loss2: (0.0000) | Acc: (98.00%) (46730/47488)
Epoch: 219 | Batch_idx: 380 |  Loss: (0.0489) |  Loss2: (0.0000) | Acc: (98.00%) (47989/48768)
Epoch: 219 | Batch_idx: 390 |  Loss: (0.0485) |  Loss2: (0.0000) | Acc: (98.00%) (49205/50000)
# TEST : Loss: (0.4433) | Acc: (88.00%) (8845/10000)
percent tensor([0.5812, 0.5952, 0.5844, 0.5808, 0.5889, 0.5961, 0.5953, 0.5796, 0.5801,
        0.5884, 0.5886, 0.5918, 0.5841, 0.5794, 0.5984, 0.5857],
       device='cuda:0') torch.Size([16])
percent tensor([0.5325, 0.5358, 0.5219, 0.5297, 0.5225, 0.5377, 0.5299, 0.5233, 0.5251,
        0.5319, 0.5360, 0.5257, 0.5322, 0.5325, 0.5353, 0.5349],
       device='cuda:0') torch.Size([16])
percent tensor([0.5942, 0.4588, 0.7285, 0.7328, 0.7428, 0.6922, 0.5674, 0.6932, 0.6388,
        0.5411, 0.4981, 0.6432, 0.4893, 0.5579, 0.5317, 0.6376],
       device='cuda:0') torch.Size([16])
percent tensor([0.7203, 0.7596, 0.6427, 0.6698, 0.6508, 0.5922, 0.7242, 0.6750, 0.7332,
        0.7583, 0.7734, 0.7137, 0.7426, 0.7693, 0.7068, 0.6975],
       device='cuda:0') torch.Size([16])
percent tensor([0.7619, 0.6462, 0.7914, 0.7906, 0.7995, 0.8535, 0.7439, 0.7613, 0.7219,
        0.6178, 0.6045, 0.6439, 0.5978, 0.6971, 0.7387, 0.7969],
       device='cuda:0') torch.Size([16])
percent tensor([0.7005, 0.7950, 0.7832, 0.8283, 0.7914, 0.8413, 0.7714, 0.6081, 0.8038,
        0.7745, 0.8296, 0.8036, 0.7988, 0.8095, 0.6301, 0.6004],
       device='cuda:0') torch.Size([16])
percent tensor([0.4407, 0.7377, 0.6280, 0.6421, 0.5889, 0.6266, 0.6764, 0.5936, 0.6644,
        0.6710, 0.7822, 0.6511, 0.6341, 0.6576, 0.5474, 0.3967],
       device='cuda:0') torch.Size([16])
percent tensor([0.9999, 0.9998, 0.9999, 0.9999, 1.0000, 0.9996, 1.0000, 0.9998, 0.9998,
        0.9999, 0.9999, 1.0000, 0.9997, 0.9997, 0.9997, 0.9996],
       device='cuda:0') torch.Size([16])
Epoch: 220 | Batch_idx: 0 |  Loss: (0.0511) |  Loss2: (0.0000) | Acc: (99.00%) (127/128)
Epoch: 220 | Batch_idx: 10 |  Loss: (0.0543) |  Loss2: (0.0000) | Acc: (98.00%) (1384/1408)
Epoch: 220 | Batch_idx: 20 |  Loss: (0.0498) |  Loss2: (0.0000) | Acc: (98.00%) (2644/2688)
Epoch: 220 | Batch_idx: 30 |  Loss: (0.0511) |  Loss2: (0.0000) | Acc: (98.00%) (3903/3968)
Epoch: 220 | Batch_idx: 40 |  Loss: (0.0492) |  Loss2: (0.0000) | Acc: (98.00%) (5165/5248)
Epoch: 220 | Batch_idx: 50 |  Loss: (0.0465) |  Loss2: (0.0000) | Acc: (98.00%) (6431/6528)
Epoch: 220 | Batch_idx: 60 |  Loss: (0.0468) |  Loss2: (0.0000) | Acc: (98.00%) (7691/7808)
Epoch: 220 | Batch_idx: 70 |  Loss: (0.0471) |  Loss2: (0.0000) | Acc: (98.00%) (8953/9088)
Epoch: 220 | Batch_idx: 80 |  Loss: (0.0473) |  Loss2: (0.0000) | Acc: (98.00%) (10210/10368)
Epoch: 220 | Batch_idx: 90 |  Loss: (0.0473) |  Loss2: (0.0000) | Acc: (98.00%) (11468/11648)
Epoch: 220 | Batch_idx: 100 |  Loss: (0.0471) |  Loss2: (0.0000) | Acc: (98.00%) (12732/12928)
Epoch: 220 | Batch_idx: 110 |  Loss: (0.0471) |  Loss2: (0.0000) | Acc: (98.00%) (13991/14208)
Epoch: 220 | Batch_idx: 120 |  Loss: (0.0469) |  Loss2: (0.0000) | Acc: (98.00%) (15254/15488)
Epoch: 220 | Batch_idx: 130 |  Loss: (0.0465) |  Loss2: (0.0000) | Acc: (98.00%) (16519/16768)
Epoch: 220 | Batch_idx: 140 |  Loss: (0.0460) |  Loss2: (0.0000) | Acc: (98.00%) (17784/18048)
Epoch: 220 | Batch_idx: 150 |  Loss: (0.0455) |  Loss2: (0.0000) | Acc: (98.00%) (19046/19328)
Epoch: 220 | Batch_idx: 160 |  Loss: (0.0454) |  Loss2: (0.0000) | Acc: (98.00%) (20309/20608)
Epoch: 220 | Batch_idx: 170 |  Loss: (0.0449) |  Loss2: (0.0000) | Acc: (98.00%) (21574/21888)
Epoch: 220 | Batch_idx: 180 |  Loss: (0.0450) |  Loss2: (0.0000) | Acc: (98.00%) (22834/23168)
Epoch: 220 | Batch_idx: 190 |  Loss: (0.0449) |  Loss2: (0.0000) | Acc: (98.00%) (24095/24448)
Epoch: 220 | Batch_idx: 200 |  Loss: (0.0450) |  Loss2: (0.0000) | Acc: (98.00%) (25352/25728)
Epoch: 220 | Batch_idx: 210 |  Loss: (0.0448) |  Loss2: (0.0000) | Acc: (98.00%) (26616/27008)
Epoch: 220 | Batch_idx: 220 |  Loss: (0.0444) |  Loss2: (0.0000) | Acc: (98.00%) (27884/28288)
Epoch: 220 | Batch_idx: 230 |  Loss: (0.0445) |  Loss2: (0.0000) | Acc: (98.00%) (29143/29568)
Epoch: 220 | Batch_idx: 240 |  Loss: (0.0448) |  Loss2: (0.0000) | Acc: (98.00%) (30400/30848)
Epoch: 220 | Batch_idx: 250 |  Loss: (0.0450) |  Loss2: (0.0000) | Acc: (98.00%) (31662/32128)
Epoch: 220 | Batch_idx: 260 |  Loss: (0.0450) |  Loss2: (0.0000) | Acc: (98.00%) (32926/33408)
Epoch: 220 | Batch_idx: 270 |  Loss: (0.0451) |  Loss2: (0.0000) | Acc: (98.00%) (34185/34688)
Epoch: 220 | Batch_idx: 280 |  Loss: (0.0450) |  Loss2: (0.0000) | Acc: (98.00%) (35447/35968)
Epoch: 220 | Batch_idx: 290 |  Loss: (0.0449) |  Loss2: (0.0000) | Acc: (98.00%) (36708/37248)
Epoch: 220 | Batch_idx: 300 |  Loss: (0.0448) |  Loss2: (0.0000) | Acc: (98.00%) (37971/38528)
Epoch: 220 | Batch_idx: 310 |  Loss: (0.0450) |  Loss2: (0.0000) | Acc: (98.00%) (39235/39808)
Epoch: 220 | Batch_idx: 320 |  Loss: (0.0448) |  Loss2: (0.0000) | Acc: (98.00%) (40496/41088)
Epoch: 220 | Batch_idx: 330 |  Loss: (0.0450) |  Loss2: (0.0000) | Acc: (98.00%) (41758/42368)
Epoch: 220 | Batch_idx: 340 |  Loss: (0.0450) |  Loss2: (0.0000) | Acc: (98.00%) (43016/43648)
Epoch: 220 | Batch_idx: 350 |  Loss: (0.0451) |  Loss2: (0.0000) | Acc: (98.00%) (44273/44928)
Epoch: 220 | Batch_idx: 360 |  Loss: (0.0453) |  Loss2: (0.0000) | Acc: (98.00%) (45527/46208)
Epoch: 220 | Batch_idx: 370 |  Loss: (0.0454) |  Loss2: (0.0000) | Acc: (98.00%) (46787/47488)
Epoch: 220 | Batch_idx: 380 |  Loss: (0.0454) |  Loss2: (0.0000) | Acc: (98.00%) (48049/48768)
Epoch: 220 | Batch_idx: 390 |  Loss: (0.0457) |  Loss2: (0.0000) | Acc: (98.00%) (49258/50000)
=> saving checkpoint 'drive/app/torch/save_Schedule/checkpoint_220.pth.tar'
# TEST : Loss: (0.4454) | Acc: (88.00%) (8899/10000)
percent tensor([0.5828, 0.5957, 0.5867, 0.5824, 0.5914, 0.5965, 0.5970, 0.5811, 0.5821,
        0.5901, 0.5898, 0.5948, 0.5854, 0.5805, 0.5991, 0.5871],
       device='cuda:0') torch.Size([16])
percent tensor([0.5327, 0.5357, 0.5236, 0.5301, 0.5237, 0.5383, 0.5304, 0.5242, 0.5255,
        0.5319, 0.5361, 0.5264, 0.5321, 0.5331, 0.5360, 0.5348],
       device='cuda:0') torch.Size([16])
percent tensor([0.5957, 0.4796, 0.7266, 0.7281, 0.7463, 0.6900, 0.5843, 0.6943, 0.6497,
        0.5562, 0.5154, 0.6561, 0.5082, 0.5682, 0.5389, 0.6392],
       device='cuda:0') torch.Size([16])
percent tensor([0.7234, 0.7557, 0.6523, 0.6753, 0.6569, 0.5935, 0.7240, 0.6749, 0.7319,
        0.7574, 0.7665, 0.7184, 0.7389, 0.7653, 0.7038, 0.6975],
       device='cuda:0') torch.Size([16])
percent tensor([0.7616, 0.6505, 0.7876, 0.7891, 0.7986, 0.8524, 0.7382, 0.7665, 0.7143,
        0.6299, 0.6074, 0.6539, 0.6048, 0.6712, 0.7468, 0.8032],
       device='cuda:0') torch.Size([16])
percent tensor([0.7025, 0.7668, 0.7899, 0.8292, 0.7979, 0.8376, 0.7721, 0.6057, 0.7841,
        0.7483, 0.8056, 0.8139, 0.7945, 0.7953, 0.6106, 0.6023],
       device='cuda:0') torch.Size([16])
percent tensor([0.4920, 0.7372, 0.6599, 0.6899, 0.6009, 0.6787, 0.6821, 0.6050, 0.6931,
        0.6819, 0.7810, 0.6946, 0.6674, 0.6773, 0.5473, 0.3962],
       device='cuda:0') torch.Size([16])
percent tensor([0.9999, 0.9998, 0.9998, 1.0000, 0.9999, 0.9996, 0.9999, 0.9998, 0.9999,
        0.9999, 0.9999, 1.0000, 0.9998, 0.9997, 0.9998, 0.9996],
       device='cuda:0') torch.Size([16])
Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 3, 3, 3]) tensor(187.4889, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(829.0225, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(843.1323, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([128, 64, 3, 3]) tensor(1510.5167, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([128, 64, 1, 1]) tensor(479.2741, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([128, 128, 3, 3]) tensor(2310.1094, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([256, 128, 3, 3]) tensor(4278.0493, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([256, 128, 1, 1]) tensor(1342.2919, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([256, 256, 3, 3]) tensor(6341.4316, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([512, 256, 3, 3]) tensor(11485.5244, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([512, 256, 1, 1]) tensor(3763.9434, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([512, 512, 3, 3]) tensor(15846.4268, device='cuda:0', grad_fn=<NormBackward0>)
Epoch: 221 | Batch_idx: 0 |  Loss: (0.0276) |  Loss2: (0.0000) | Acc: (100.00%) (128/128)
Epoch: 221 | Batch_idx: 10 |  Loss: (0.0417) |  Loss2: (0.0000) | Acc: (98.00%) (1392/1408)
Epoch: 221 | Batch_idx: 20 |  Loss: (0.0449) |  Loss2: (0.0000) | Acc: (98.00%) (2651/2688)
Epoch: 221 | Batch_idx: 30 |  Loss: (0.0442) |  Loss2: (0.0000) | Acc: (98.00%) (3912/3968)
Epoch: 221 | Batch_idx: 40 |  Loss: (0.0426) |  Loss2: (0.0000) | Acc: (98.00%) (5178/5248)
Epoch: 221 | Batch_idx: 50 |  Loss: (0.0448) |  Loss2: (0.0000) | Acc: (98.00%) (6435/6528)
Epoch: 221 | Batch_idx: 60 |  Loss: (0.0459) |  Loss2: (0.0000) | Acc: (98.00%) (7692/7808)
Epoch: 221 | Batch_idx: 70 |  Loss: (0.0455) |  Loss2: (0.0000) | Acc: (98.00%) (8955/9088)
Epoch: 221 | Batch_idx: 80 |  Loss: (0.0443) |  Loss2: (0.0000) | Acc: (98.00%) (10219/10368)
Epoch: 221 | Batch_idx: 90 |  Loss: (0.0450) |  Loss2: (0.0000) | Acc: (98.00%) (11474/11648)
Epoch: 221 | Batch_idx: 100 |  Loss: (0.0447) |  Loss2: (0.0000) | Acc: (98.00%) (12736/12928)
Epoch: 221 | Batch_idx: 110 |  Loss: (0.0443) |  Loss2: (0.0000) | Acc: (98.00%) (14004/14208)
Epoch: 221 | Batch_idx: 120 |  Loss: (0.0437) |  Loss2: (0.0000) | Acc: (98.00%) (15273/15488)
Epoch: 221 | Batch_idx: 130 |  Loss: (0.0438) |  Loss2: (0.0000) | Acc: (98.00%) (16537/16768)
Epoch: 221 | Batch_idx: 140 |  Loss: (0.0435) |  Loss2: (0.0000) | Acc: (98.00%) (17805/18048)
Epoch: 221 | Batch_idx: 150 |  Loss: (0.0426) |  Loss2: (0.0000) | Acc: (98.00%) (19074/19328)
Epoch: 221 | Batch_idx: 160 |  Loss: (0.0427) |  Loss2: (0.0000) | Acc: (98.00%) (20337/20608)
Epoch: 221 | Batch_idx: 170 |  Loss: (0.0427) |  Loss2: (0.0000) | Acc: (98.00%) (21601/21888)
Epoch: 221 | Batch_idx: 180 |  Loss: (0.0428) |  Loss2: (0.0000) | Acc: (98.00%) (22864/23168)
Epoch: 221 | Batch_idx: 190 |  Loss: (0.0431) |  Loss2: (0.0000) | Acc: (98.00%) (24122/24448)
Epoch: 221 | Batch_idx: 200 |  Loss: (0.0428) |  Loss2: (0.0000) | Acc: (98.00%) (25385/25728)
Epoch: 221 | Batch_idx: 210 |  Loss: (0.0430) |  Loss2: (0.0000) | Acc: (98.00%) (26649/27008)
Epoch: 221 | Batch_idx: 220 |  Loss: (0.0434) |  Loss2: (0.0000) | Acc: (98.00%) (27903/28288)
Epoch: 221 | Batch_idx: 230 |  Loss: (0.0434) |  Loss2: (0.0000) | Acc: (98.00%) (29167/29568)
Epoch: 221 | Batch_idx: 240 |  Loss: (0.0436) |  Loss2: (0.0000) | Acc: (98.00%) (30430/30848)
Epoch: 221 | Batch_idx: 250 |  Loss: (0.0432) |  Loss2: (0.0000) | Acc: (98.00%) (31697/32128)
Epoch: 221 | Batch_idx: 260 |  Loss: (0.0431) |  Loss2: (0.0000) | Acc: (98.00%) (32960/33408)
Epoch: 221 | Batch_idx: 270 |  Loss: (0.0429) |  Loss2: (0.0000) | Acc: (98.00%) (34224/34688)
Epoch: 221 | Batch_idx: 280 |  Loss: (0.0426) |  Loss2: (0.0000) | Acc: (98.00%) (35490/35968)
Epoch: 221 | Batch_idx: 290 |  Loss: (0.0427) |  Loss2: (0.0000) | Acc: (98.00%) (36754/37248)
Epoch: 221 | Batch_idx: 300 |  Loss: (0.0431) |  Loss2: (0.0000) | Acc: (98.00%) (38008/38528)
Epoch: 221 | Batch_idx: 310 |  Loss: (0.0430) |  Loss2: (0.0000) | Acc: (98.00%) (39274/39808)
Epoch: 221 | Batch_idx: 320 |  Loss: (0.0436) |  Loss2: (0.0000) | Acc: (98.00%) (40528/41088)
Epoch: 221 | Batch_idx: 330 |  Loss: (0.0434) |  Loss2: (0.0000) | Acc: (98.00%) (41792/42368)
Epoch: 221 | Batch_idx: 340 |  Loss: (0.0437) |  Loss2: (0.0000) | Acc: (98.00%) (43048/43648)
Epoch: 221 | Batch_idx: 350 |  Loss: (0.0438) |  Loss2: (0.0000) | Acc: (98.00%) (44310/44928)
Epoch: 221 | Batch_idx: 360 |  Loss: (0.0438) |  Loss2: (0.0000) | Acc: (98.00%) (45575/46208)
Epoch: 221 | Batch_idx: 370 |  Loss: (0.0439) |  Loss2: (0.0000) | Acc: (98.00%) (46840/47488)
Epoch: 221 | Batch_idx: 380 |  Loss: (0.0442) |  Loss2: (0.0000) | Acc: (98.00%) (48099/48768)
Epoch: 221 | Batch_idx: 390 |  Loss: (0.0444) |  Loss2: (0.0000) | Acc: (98.00%) (49312/50000)
# TEST : Loss: (0.4275) | Acc: (89.00%) (8936/10000)
percent tensor([0.5830, 0.5967, 0.5865, 0.5833, 0.5920, 0.5964, 0.5981, 0.5820, 0.5825,
        0.5908, 0.5903, 0.5956, 0.5861, 0.5809, 0.5999, 0.5876],
       device='cuda:0') torch.Size([16])
percent tensor([0.5337, 0.5367, 0.5241, 0.5308, 0.5233, 0.5398, 0.5305, 0.5251, 0.5257,
        0.5327, 0.5365, 0.5265, 0.5327, 0.5335, 0.5365, 0.5358],
       device='cuda:0') torch.Size([16])
percent tensor([0.5900, 0.4616, 0.7240, 0.7239, 0.7432, 0.6859, 0.5709, 0.6981, 0.6464,
        0.5375, 0.5023, 0.6431, 0.4910, 0.5615, 0.5282, 0.6339],
       device='cuda:0') torch.Size([16])
percent tensor([0.7238, 0.7612, 0.6536, 0.6871, 0.6641, 0.5968, 0.7289, 0.6831, 0.7334,
        0.7634, 0.7667, 0.7221, 0.7398, 0.7661, 0.7083, 0.7011],
       device='cuda:0') torch.Size([16])
percent tensor([0.7576, 0.6494, 0.7861, 0.7765, 0.7952, 0.8586, 0.7457, 0.7565, 0.7186,
        0.6192, 0.6108, 0.6508, 0.6064, 0.6992, 0.7419, 0.8049],
       device='cuda:0') torch.Size([16])
percent tensor([0.6883, 0.7756, 0.7723, 0.8016, 0.7717, 0.8520, 0.7565, 0.5470, 0.7564,
        0.7531, 0.8010, 0.8058, 0.8004, 0.7820, 0.6084, 0.6250],
       device='cuda:0') torch.Size([16])
percent tensor([0.4517, 0.7126, 0.6289, 0.6317, 0.5667, 0.6690, 0.6530, 0.5852, 0.6361,
        0.6672, 0.7582, 0.6241, 0.6390, 0.6389, 0.5286, 0.3835],
       device='cuda:0') torch.Size([16])
percent tensor([0.9999, 0.9998, 0.9998, 1.0000, 1.0000, 0.9995, 0.9999, 0.9998, 0.9998,
        1.0000, 0.9999, 0.9999, 0.9998, 0.9997, 0.9997, 0.9995],
       device='cuda:0') torch.Size([16])
Epoch: 222 | Batch_idx: 0 |  Loss: (0.0273) |  Loss2: (0.0000) | Acc: (100.00%) (128/128)
Epoch: 222 | Batch_idx: 10 |  Loss: (0.0380) |  Loss2: (0.0000) | Acc: (98.00%) (1389/1408)
Epoch: 222 | Batch_idx: 20 |  Loss: (0.0378) |  Loss2: (0.0000) | Acc: (98.00%) (2654/2688)
Epoch: 222 | Batch_idx: 30 |  Loss: (0.0386) |  Loss2: (0.0000) | Acc: (98.00%) (3918/3968)
Epoch: 222 | Batch_idx: 40 |  Loss: (0.0401) |  Loss2: (0.0000) | Acc: (98.00%) (5177/5248)
Epoch: 222 | Batch_idx: 50 |  Loss: (0.0402) |  Loss2: (0.0000) | Acc: (98.00%) (6443/6528)
Epoch: 222 | Batch_idx: 60 |  Loss: (0.0409) |  Loss2: (0.0000) | Acc: (98.00%) (7705/7808)
Epoch: 222 | Batch_idx: 70 |  Loss: (0.0416) |  Loss2: (0.0000) | Acc: (98.00%) (8969/9088)
Epoch: 222 | Batch_idx: 80 |  Loss: (0.0422) |  Loss2: (0.0000) | Acc: (98.00%) (10230/10368)
Epoch: 222 | Batch_idx: 90 |  Loss: (0.0411) |  Loss2: (0.0000) | Acc: (98.00%) (11496/11648)
Epoch: 222 | Batch_idx: 100 |  Loss: (0.0408) |  Loss2: (0.0000) | Acc: (98.00%) (12766/12928)
Epoch: 222 | Batch_idx: 110 |  Loss: (0.0412) |  Loss2: (0.0000) | Acc: (98.00%) (14025/14208)
Epoch: 222 | Batch_idx: 120 |  Loss: (0.0416) |  Loss2: (0.0000) | Acc: (98.00%) (15286/15488)
Epoch: 222 | Batch_idx: 130 |  Loss: (0.0415) |  Loss2: (0.0000) | Acc: (98.00%) (16551/16768)
Epoch: 222 | Batch_idx: 140 |  Loss: (0.0417) |  Loss2: (0.0000) | Acc: (98.00%) (17817/18048)
Epoch: 222 | Batch_idx: 150 |  Loss: (0.0420) |  Loss2: (0.0000) | Acc: (98.00%) (19079/19328)
Epoch: 222 | Batch_idx: 160 |  Loss: (0.0420) |  Loss2: (0.0000) | Acc: (98.00%) (20343/20608)
Epoch: 222 | Batch_idx: 170 |  Loss: (0.0426) |  Loss2: (0.0000) | Acc: (98.00%) (21599/21888)
Epoch: 222 | Batch_idx: 180 |  Loss: (0.0432) |  Loss2: (0.0000) | Acc: (98.00%) (22856/23168)
Epoch: 222 | Batch_idx: 190 |  Loss: (0.0432) |  Loss2: (0.0000) | Acc: (98.00%) (24118/24448)
Epoch: 222 | Batch_idx: 200 |  Loss: (0.0433) |  Loss2: (0.0000) | Acc: (98.00%) (25380/25728)
Epoch: 222 | Batch_idx: 210 |  Loss: (0.0438) |  Loss2: (0.0000) | Acc: (98.00%) (26639/27008)
Epoch: 222 | Batch_idx: 220 |  Loss: (0.0442) |  Loss2: (0.0000) | Acc: (98.00%) (27893/28288)
Epoch: 222 | Batch_idx: 230 |  Loss: (0.0439) |  Loss2: (0.0000) | Acc: (98.00%) (29157/29568)
Epoch: 222 | Batch_idx: 240 |  Loss: (0.0438) |  Loss2: (0.0000) | Acc: (98.00%) (30425/30848)
Epoch: 222 | Batch_idx: 250 |  Loss: (0.0439) |  Loss2: (0.0000) | Acc: (98.00%) (31683/32128)
Epoch: 222 | Batch_idx: 260 |  Loss: (0.0440) |  Loss2: (0.0000) | Acc: (98.00%) (32939/33408)
Epoch: 222 | Batch_idx: 270 |  Loss: (0.0440) |  Loss2: (0.0000) | Acc: (98.00%) (34202/34688)
Epoch: 222 | Batch_idx: 280 |  Loss: (0.0444) |  Loss2: (0.0000) | Acc: (98.00%) (35454/35968)
Epoch: 222 | Batch_idx: 290 |  Loss: (0.0445) |  Loss2: (0.0000) | Acc: (98.00%) (36716/37248)
Epoch: 222 | Batch_idx: 300 |  Loss: (0.0444) |  Loss2: (0.0000) | Acc: (98.00%) (37983/38528)
Epoch: 222 | Batch_idx: 310 |  Loss: (0.0446) |  Loss2: (0.0000) | Acc: (98.00%) (39245/39808)
Epoch: 222 | Batch_idx: 320 |  Loss: (0.0448) |  Loss2: (0.0000) | Acc: (98.00%) (40503/41088)
Epoch: 222 | Batch_idx: 330 |  Loss: (0.0451) |  Loss2: (0.0000) | Acc: (98.00%) (41762/42368)
Epoch: 222 | Batch_idx: 340 |  Loss: (0.0451) |  Loss2: (0.0000) | Acc: (98.00%) (43025/43648)
Epoch: 222 | Batch_idx: 350 |  Loss: (0.0455) |  Loss2: (0.0000) | Acc: (98.00%) (44279/44928)
Epoch: 222 | Batch_idx: 360 |  Loss: (0.0457) |  Loss2: (0.0000) | Acc: (98.00%) (45538/46208)
Epoch: 222 | Batch_idx: 370 |  Loss: (0.0459) |  Loss2: (0.0000) | Acc: (98.00%) (46798/47488)
Epoch: 222 | Batch_idx: 380 |  Loss: (0.0460) |  Loss2: (0.0000) | Acc: (98.00%) (48057/48768)
Epoch: 222 | Batch_idx: 390 |  Loss: (0.0464) |  Loss2: (0.0000) | Acc: (98.00%) (49265/50000)
# TEST : Loss: (0.4310) | Acc: (89.00%) (8918/10000)
percent tensor([0.5817, 0.5957, 0.5845, 0.5818, 0.5899, 0.5950, 0.5963, 0.5796, 0.5809,
        0.5890, 0.5887, 0.5924, 0.5844, 0.5805, 0.5981, 0.5866],
       device='cuda:0') torch.Size([16])
percent tensor([0.5344, 0.5376, 0.5244, 0.5318, 0.5238, 0.5394, 0.5319, 0.5261, 0.5267,
        0.5337, 0.5378, 0.5277, 0.5335, 0.5348, 0.5375, 0.5366],
       device='cuda:0') torch.Size([16])
percent tensor([0.6042, 0.4570, 0.7426, 0.7383, 0.7578, 0.7057, 0.5791, 0.6984, 0.6515,
        0.5403, 0.4967, 0.6607, 0.4954, 0.5437, 0.5387, 0.6375],
       device='cuda:0') torch.Size([16])
percent tensor([0.7256, 0.7588, 0.6527, 0.6845, 0.6576, 0.5970, 0.7275, 0.6830, 0.7340,
        0.7619, 0.7712, 0.7184, 0.7408, 0.7693, 0.7073, 0.7025],
       device='cuda:0') torch.Size([16])
percent tensor([0.7592, 0.6562, 0.7867, 0.7752, 0.7979, 0.8534, 0.7525, 0.7665, 0.7211,
        0.6326, 0.6162, 0.6588, 0.5985, 0.7062, 0.7470, 0.8044],
       device='cuda:0') torch.Size([16])
percent tensor([0.6814, 0.7789, 0.7563, 0.8104, 0.7631, 0.8325, 0.7434, 0.5756, 0.7779,
        0.7682, 0.8206, 0.7999, 0.7945, 0.8116, 0.5990, 0.6265],
       device='cuda:0') torch.Size([16])
percent tensor([0.4429, 0.7260, 0.6392, 0.6703, 0.6044, 0.6547, 0.6607, 0.5920, 0.6367,
        0.6675, 0.7739, 0.6587, 0.6489, 0.6600, 0.5555, 0.3926],
       device='cuda:0') torch.Size([16])
percent tensor([0.9999, 0.9998, 0.9999, 1.0000, 1.0000, 0.9996, 1.0000, 0.9998, 0.9998,
        0.9999, 0.9999, 0.9999, 0.9997, 0.9995, 0.9998, 0.9996],
       device='cuda:0') torch.Size([16])
Epoch: 223 | Batch_idx: 0 |  Loss: (0.0270) |  Loss2: (0.0000) | Acc: (99.00%) (127/128)
Epoch: 223 | Batch_idx: 10 |  Loss: (0.0424) |  Loss2: (0.0000) | Acc: (98.00%) (1389/1408)
Epoch: 223 | Batch_idx: 20 |  Loss: (0.0416) |  Loss2: (0.0000) | Acc: (98.00%) (2653/2688)
Epoch: 223 | Batch_idx: 30 |  Loss: (0.0419) |  Loss2: (0.0000) | Acc: (98.00%) (3921/3968)
Epoch: 223 | Batch_idx: 40 |  Loss: (0.0408) |  Loss2: (0.0000) | Acc: (98.00%) (5185/5248)
Epoch: 223 | Batch_idx: 50 |  Loss: (0.0411) |  Loss2: (0.0000) | Acc: (98.00%) (6450/6528)
Epoch: 223 | Batch_idx: 60 |  Loss: (0.0424) |  Loss2: (0.0000) | Acc: (98.00%) (7710/7808)
Epoch: 223 | Batch_idx: 70 |  Loss: (0.0418) |  Loss2: (0.0000) | Acc: (98.00%) (8978/9088)
Epoch: 223 | Batch_idx: 80 |  Loss: (0.0416) |  Loss2: (0.0000) | Acc: (98.00%) (10244/10368)
Epoch: 223 | Batch_idx: 90 |  Loss: (0.0415) |  Loss2: (0.0000) | Acc: (98.00%) (11511/11648)
Epoch: 223 | Batch_idx: 100 |  Loss: (0.0426) |  Loss2: (0.0000) | Acc: (98.00%) (12765/12928)
Epoch: 223 | Batch_idx: 110 |  Loss: (0.0434) |  Loss2: (0.0000) | Acc: (98.00%) (14022/14208)
Epoch: 223 | Batch_idx: 120 |  Loss: (0.0438) |  Loss2: (0.0000) | Acc: (98.00%) (15280/15488)
Epoch: 223 | Batch_idx: 130 |  Loss: (0.0433) |  Loss2: (0.0000) | Acc: (98.00%) (16545/16768)
Epoch: 223 | Batch_idx: 140 |  Loss: (0.0428) |  Loss2: (0.0000) | Acc: (98.00%) (17813/18048)
Epoch: 223 | Batch_idx: 150 |  Loss: (0.0431) |  Loss2: (0.0000) | Acc: (98.00%) (19075/19328)
Epoch: 223 | Batch_idx: 160 |  Loss: (0.0438) |  Loss2: (0.0000) | Acc: (98.00%) (20326/20608)
Epoch: 223 | Batch_idx: 170 |  Loss: (0.0437) |  Loss2: (0.0000) | Acc: (98.00%) (21591/21888)
Epoch: 223 | Batch_idx: 180 |  Loss: (0.0444) |  Loss2: (0.0000) | Acc: (98.00%) (22847/23168)
Epoch: 223 | Batch_idx: 190 |  Loss: (0.0447) |  Loss2: (0.0000) | Acc: (98.00%) (24104/24448)
Epoch: 223 | Batch_idx: 200 |  Loss: (0.0453) |  Loss2: (0.0000) | Acc: (98.00%) (25357/25728)
Epoch: 223 | Batch_idx: 210 |  Loss: (0.0451) |  Loss2: (0.0000) | Acc: (98.00%) (26619/27008)
Epoch: 223 | Batch_idx: 220 |  Loss: (0.0449) |  Loss2: (0.0000) | Acc: (98.00%) (27883/28288)
Epoch: 223 | Batch_idx: 230 |  Loss: (0.0445) |  Loss2: (0.0000) | Acc: (98.00%) (29150/29568)
Epoch: 223 | Batch_idx: 240 |  Loss: (0.0447) |  Loss2: (0.0000) | Acc: (98.00%) (30409/30848)
Epoch: 223 | Batch_idx: 250 |  Loss: (0.0447) |  Loss2: (0.0000) | Acc: (98.00%) (31666/32128)
Epoch: 223 | Batch_idx: 260 |  Loss: (0.0449) |  Loss2: (0.0000) | Acc: (98.00%) (32929/33408)
Epoch: 223 | Batch_idx: 270 |  Loss: (0.0449) |  Loss2: (0.0000) | Acc: (98.00%) (34192/34688)
Epoch: 223 | Batch_idx: 280 |  Loss: (0.0453) |  Loss2: (0.0000) | Acc: (98.00%) (35450/35968)
Epoch: 223 | Batch_idx: 290 |  Loss: (0.0451) |  Loss2: (0.0000) | Acc: (98.00%) (36717/37248)
Epoch: 223 | Batch_idx: 300 |  Loss: (0.0453) |  Loss2: (0.0000) | Acc: (98.00%) (37978/38528)
Epoch: 223 | Batch_idx: 310 |  Loss: (0.0456) |  Loss2: (0.0000) | Acc: (98.00%) (39233/39808)
Epoch: 223 | Batch_idx: 320 |  Loss: (0.0458) |  Loss2: (0.0000) | Acc: (98.00%) (40491/41088)
Epoch: 223 | Batch_idx: 330 |  Loss: (0.0457) |  Loss2: (0.0000) | Acc: (98.00%) (41751/42368)
Epoch: 223 | Batch_idx: 340 |  Loss: (0.0458) |  Loss2: (0.0000) | Acc: (98.00%) (43012/43648)
Epoch: 223 | Batch_idx: 350 |  Loss: (0.0459) |  Loss2: (0.0000) | Acc: (98.00%) (44273/44928)
Epoch: 223 | Batch_idx: 360 |  Loss: (0.0460) |  Loss2: (0.0000) | Acc: (98.00%) (45532/46208)
Epoch: 223 | Batch_idx: 370 |  Loss: (0.0461) |  Loss2: (0.0000) | Acc: (98.00%) (46793/47488)
Epoch: 223 | Batch_idx: 380 |  Loss: (0.0462) |  Loss2: (0.0000) | Acc: (98.00%) (48051/48768)
Epoch: 223 | Batch_idx: 390 |  Loss: (0.0463) |  Loss2: (0.0000) | Acc: (98.00%) (49262/50000)
# TEST : Loss: (0.4268) | Acc: (89.00%) (8953/10000)
percent tensor([0.5827, 0.5951, 0.5877, 0.5835, 0.5924, 0.5967, 0.5971, 0.5814, 0.5817,
        0.5899, 0.5896, 0.5957, 0.5855, 0.5782, 0.5991, 0.5868],
       device='cuda:0') torch.Size([16])
percent tensor([0.5351, 0.5366, 0.5246, 0.5310, 0.5246, 0.5403, 0.5305, 0.5254, 0.5271,
        0.5328, 0.5382, 0.5271, 0.5332, 0.5335, 0.5371, 0.5366],
       device='cuda:0') torch.Size([16])
percent tensor([0.5999, 0.4821, 0.7349, 0.7372, 0.7493, 0.6935, 0.5890, 0.7099, 0.6552,
        0.5601, 0.5092, 0.6644, 0.5019, 0.5786, 0.5462, 0.6455],
       device='cuda:0') torch.Size([16])
percent tensor([0.7262, 0.7612, 0.6495, 0.6829, 0.6593, 0.5927, 0.7282, 0.6776, 0.7333,
        0.7624, 0.7692, 0.7211, 0.7422, 0.7685, 0.7035, 0.7025],
       device='cuda:0') torch.Size([16])
percent tensor([0.7579, 0.6642, 0.7749, 0.7723, 0.7909, 0.8551, 0.7478, 0.7670, 0.7112,
        0.6352, 0.6173, 0.6400, 0.6025, 0.7103, 0.7553, 0.8021],
       device='cuda:0') torch.Size([16])
percent tensor([0.6573, 0.7800, 0.7967, 0.8209, 0.7968, 0.8409, 0.7672, 0.5638, 0.7575,
        0.7707, 0.7988, 0.8041, 0.7756, 0.7924, 0.6255, 0.6061],
       device='cuda:0') torch.Size([16])
percent tensor([0.4328, 0.6949, 0.6493, 0.6458, 0.6040, 0.6338, 0.6493, 0.5637, 0.6660,
        0.6548, 0.7675, 0.6705, 0.6380, 0.5939, 0.5475, 0.3970],
       device='cuda:0') torch.Size([16])
percent tensor([0.9999, 0.9999, 0.9998, 0.9999, 0.9999, 0.9997, 1.0000, 0.9997, 0.9998,
        1.0000, 0.9998, 1.0000, 0.9997, 0.9998, 0.9998, 0.9996],
       device='cuda:0') torch.Size([16])
Epoch: 224 | Batch_idx: 0 |  Loss: (0.0133) |  Loss2: (0.0000) | Acc: (100.00%) (128/128)
Epoch: 224 | Batch_idx: 10 |  Loss: (0.0392) |  Loss2: (0.0000) | Acc: (98.00%) (1385/1408)
Epoch: 224 | Batch_idx: 20 |  Loss: (0.0374) |  Loss2: (0.0000) | Acc: (98.00%) (2651/2688)
Epoch: 224 | Batch_idx: 30 |  Loss: (0.0369) |  Loss2: (0.0000) | Acc: (98.00%) (3915/3968)
Epoch: 224 | Batch_idx: 40 |  Loss: (0.0417) |  Loss2: (0.0000) | Acc: (98.00%) (5173/5248)
Epoch: 224 | Batch_idx: 50 |  Loss: (0.0395) |  Loss2: (0.0000) | Acc: (98.00%) (6444/6528)
Epoch: 224 | Batch_idx: 60 |  Loss: (0.0399) |  Loss2: (0.0000) | Acc: (98.00%) (7709/7808)
Epoch: 224 | Batch_idx: 70 |  Loss: (0.0399) |  Loss2: (0.0000) | Acc: (98.00%) (8975/9088)
Epoch: 224 | Batch_idx: 80 |  Loss: (0.0405) |  Loss2: (0.0000) | Acc: (98.00%) (10237/10368)
Epoch: 224 | Batch_idx: 90 |  Loss: (0.0410) |  Loss2: (0.0000) | Acc: (98.00%) (11497/11648)
Epoch: 224 | Batch_idx: 100 |  Loss: (0.0417) |  Loss2: (0.0000) | Acc: (98.00%) (12756/12928)
Epoch: 224 | Batch_idx: 110 |  Loss: (0.0420) |  Loss2: (0.0000) | Acc: (98.00%) (14023/14208)
Epoch: 224 | Batch_idx: 120 |  Loss: (0.0421) |  Loss2: (0.0000) | Acc: (98.00%) (15287/15488)
Epoch: 224 | Batch_idx: 130 |  Loss: (0.0423) |  Loss2: (0.0000) | Acc: (98.00%) (16550/16768)
Epoch: 224 | Batch_idx: 140 |  Loss: (0.0428) |  Loss2: (0.0000) | Acc: (98.00%) (17806/18048)
Epoch: 224 | Batch_idx: 150 |  Loss: (0.0436) |  Loss2: (0.0000) | Acc: (98.00%) (19063/19328)
Epoch: 224 | Batch_idx: 160 |  Loss: (0.0436) |  Loss2: (0.0000) | Acc: (98.00%) (20327/20608)
Epoch: 224 | Batch_idx: 170 |  Loss: (0.0439) |  Loss2: (0.0000) | Acc: (98.00%) (21589/21888)
Epoch: 224 | Batch_idx: 180 |  Loss: (0.0442) |  Loss2: (0.0000) | Acc: (98.00%) (22847/23168)
Epoch: 224 | Batch_idx: 190 |  Loss: (0.0435) |  Loss2: (0.0000) | Acc: (98.00%) (24118/24448)
Epoch: 224 | Batch_idx: 200 |  Loss: (0.0432) |  Loss2: (0.0000) | Acc: (98.00%) (25388/25728)
Epoch: 224 | Batch_idx: 210 |  Loss: (0.0429) |  Loss2: (0.0000) | Acc: (98.00%) (26652/27008)
Epoch: 224 | Batch_idx: 220 |  Loss: (0.0425) |  Loss2: (0.0000) | Acc: (98.00%) (27916/28288)
Epoch: 224 | Batch_idx: 230 |  Loss: (0.0423) |  Loss2: (0.0000) | Acc: (98.00%) (29184/29568)
Epoch: 224 | Batch_idx: 240 |  Loss: (0.0422) |  Loss2: (0.0000) | Acc: (98.00%) (30446/30848)
Epoch: 224 | Batch_idx: 250 |  Loss: (0.0422) |  Loss2: (0.0000) | Acc: (98.00%) (31708/32128)
Epoch: 224 | Batch_idx: 260 |  Loss: (0.0421) |  Loss2: (0.0000) | Acc: (98.00%) (32972/33408)
Epoch: 224 | Batch_idx: 270 |  Loss: (0.0424) |  Loss2: (0.0000) | Acc: (98.00%) (34236/34688)
Epoch: 224 | Batch_idx: 280 |  Loss: (0.0423) |  Loss2: (0.0000) | Acc: (98.00%) (35505/35968)
Epoch: 224 | Batch_idx: 290 |  Loss: (0.0421) |  Loss2: (0.0000) | Acc: (98.00%) (36774/37248)
Epoch: 224 | Batch_idx: 300 |  Loss: (0.0419) |  Loss2: (0.0000) | Acc: (98.00%) (38036/38528)
Epoch: 224 | Batch_idx: 310 |  Loss: (0.0418) |  Loss2: (0.0000) | Acc: (98.00%) (39297/39808)
Epoch: 224 | Batch_idx: 320 |  Loss: (0.0416) |  Loss2: (0.0000) | Acc: (98.00%) (40561/41088)
Epoch: 224 | Batch_idx: 330 |  Loss: (0.0416) |  Loss2: (0.0000) | Acc: (98.00%) (41824/42368)
Epoch: 224 | Batch_idx: 340 |  Loss: (0.0415) |  Loss2: (0.0000) | Acc: (98.00%) (43085/43648)
Epoch: 224 | Batch_idx: 350 |  Loss: (0.0418) |  Loss2: (0.0000) | Acc: (98.00%) (44340/44928)
Epoch: 224 | Batch_idx: 360 |  Loss: (0.0418) |  Loss2: (0.0000) | Acc: (98.00%) (45603/46208)
Epoch: 224 | Batch_idx: 370 |  Loss: (0.0415) |  Loss2: (0.0000) | Acc: (98.00%) (46873/47488)
Epoch: 224 | Batch_idx: 380 |  Loss: (0.0418) |  Loss2: (0.0000) | Acc: (98.00%) (48128/48768)
Epoch: 224 | Batch_idx: 390 |  Loss: (0.0419) |  Loss2: (0.0000) | Acc: (98.00%) (49346/50000)
# TEST : Loss: (0.4362) | Acc: (89.00%) (8920/10000)
percent tensor([0.5823, 0.5953, 0.5863, 0.5819, 0.5909, 0.5963, 0.5963, 0.5800, 0.5814,
        0.5893, 0.5892, 0.5936, 0.5851, 0.5786, 0.5987, 0.5863],
       device='cuda:0') torch.Size([16])
percent tensor([0.5343, 0.5370, 0.5239, 0.5312, 0.5241, 0.5398, 0.5314, 0.5252, 0.5262,
        0.5329, 0.5374, 0.5272, 0.5329, 0.5339, 0.5374, 0.5362],
       device='cuda:0') torch.Size([16])
percent tensor([0.6038, 0.4607, 0.7472, 0.7407, 0.7575, 0.7006, 0.5806, 0.7066, 0.6511,
        0.5424, 0.4991, 0.6629, 0.4943, 0.5520, 0.5366, 0.6394],
       device='cuda:0') torch.Size([16])
percent tensor([0.7249, 0.7600, 0.6513, 0.6839, 0.6596, 0.5946, 0.7276, 0.6786, 0.7304,
        0.7601, 0.7656, 0.7223, 0.7393, 0.7715, 0.7055, 0.7029],
       device='cuda:0') torch.Size([16])
percent tensor([0.7583, 0.6437, 0.7866, 0.7784, 0.7985, 0.8558, 0.7417, 0.7661, 0.7213,
        0.6249, 0.6116, 0.6402, 0.6038, 0.6892, 0.7441, 0.8051],
       device='cuda:0') torch.Size([16])
percent tensor([0.6519, 0.7971, 0.7553, 0.8034, 0.7605, 0.8264, 0.7621, 0.5465, 0.7610,
        0.7622, 0.8024, 0.8027, 0.7833, 0.8154, 0.5996, 0.6086],
       device='cuda:0') torch.Size([16])
percent tensor([0.4215, 0.7181, 0.6258, 0.6416, 0.5854, 0.6198, 0.6578, 0.5833, 0.6567,
        0.6846, 0.7558, 0.6332, 0.6258, 0.6437, 0.5421, 0.4000],
       device='cuda:0') torch.Size([16])
percent tensor([0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9996, 1.0000, 0.9997, 0.9999,
        0.9999, 0.9999, 0.9999, 0.9997, 0.9997, 0.9998, 0.9994],
       device='cuda:0') torch.Size([16])
Epoch: 225 | Batch_idx: 0 |  Loss: (0.0420) |  Loss2: (0.0000) | Acc: (98.00%) (126/128)
Epoch: 225 | Batch_idx: 10 |  Loss: (0.0442) |  Loss2: (0.0000) | Acc: (98.00%) (1389/1408)
Epoch: 225 | Batch_idx: 20 |  Loss: (0.0382) |  Loss2: (0.0000) | Acc: (98.00%) (2658/2688)
Epoch: 225 | Batch_idx: 30 |  Loss: (0.0394) |  Loss2: (0.0000) | Acc: (98.00%) (3922/3968)
Epoch: 225 | Batch_idx: 40 |  Loss: (0.0370) |  Loss2: (0.0000) | Acc: (98.00%) (5194/5248)
Epoch: 225 | Batch_idx: 50 |  Loss: (0.0363) |  Loss2: (0.0000) | Acc: (98.00%) (6460/6528)
Epoch: 225 | Batch_idx: 60 |  Loss: (0.0380) |  Loss2: (0.0000) | Acc: (98.00%) (7719/7808)
Epoch: 225 | Batch_idx: 70 |  Loss: (0.0377) |  Loss2: (0.0000) | Acc: (98.00%) (8988/9088)
Epoch: 225 | Batch_idx: 80 |  Loss: (0.0379) |  Loss2: (0.0000) | Acc: (98.00%) (10252/10368)
Epoch: 225 | Batch_idx: 90 |  Loss: (0.0393) |  Loss2: (0.0000) | Acc: (98.00%) (11513/11648)
Epoch: 225 | Batch_idx: 100 |  Loss: (0.0390) |  Loss2: (0.0000) | Acc: (98.00%) (12779/12928)
Epoch: 225 | Batch_idx: 110 |  Loss: (0.0389) |  Loss2: (0.0000) | Acc: (98.00%) (14041/14208)
Epoch: 225 | Batch_idx: 120 |  Loss: (0.0387) |  Loss2: (0.0000) | Acc: (98.00%) (15308/15488)
Epoch: 225 | Batch_idx: 130 |  Loss: (0.0386) |  Loss2: (0.0000) | Acc: (98.00%) (16575/16768)
Epoch: 225 | Batch_idx: 140 |  Loss: (0.0384) |  Loss2: (0.0000) | Acc: (98.00%) (17839/18048)
Epoch: 225 | Batch_idx: 150 |  Loss: (0.0388) |  Loss2: (0.0000) | Acc: (98.00%) (19097/19328)
Epoch: 225 | Batch_idx: 160 |  Loss: (0.0393) |  Loss2: (0.0000) | Acc: (98.00%) (20357/20608)
Epoch: 225 | Batch_idx: 170 |  Loss: (0.0387) |  Loss2: (0.0000) | Acc: (98.00%) (21627/21888)
Epoch: 225 | Batch_idx: 180 |  Loss: (0.0388) |  Loss2: (0.0000) | Acc: (98.00%) (22891/23168)
Epoch: 225 | Batch_idx: 190 |  Loss: (0.0388) |  Loss2: (0.0000) | Acc: (98.00%) (24152/24448)
Epoch: 225 | Batch_idx: 200 |  Loss: (0.0388) |  Loss2: (0.0000) | Acc: (98.00%) (25414/25728)
Epoch: 225 | Batch_idx: 210 |  Loss: (0.0392) |  Loss2: (0.0000) | Acc: (98.00%) (26677/27008)
Epoch: 225 | Batch_idx: 220 |  Loss: (0.0394) |  Loss2: (0.0000) | Acc: (98.00%) (27941/28288)
Epoch: 225 | Batch_idx: 230 |  Loss: (0.0393) |  Loss2: (0.0000) | Acc: (98.00%) (29202/29568)
Epoch: 225 | Batch_idx: 240 |  Loss: (0.0390) |  Loss2: (0.0000) | Acc: (98.00%) (30471/30848)
Epoch: 225 | Batch_idx: 250 |  Loss: (0.0387) |  Loss2: (0.0000) | Acc: (98.00%) (31739/32128)
Epoch: 225 | Batch_idx: 260 |  Loss: (0.0387) |  Loss2: (0.0000) | Acc: (98.00%) (33003/33408)
Epoch: 225 | Batch_idx: 270 |  Loss: (0.0392) |  Loss2: (0.0000) | Acc: (98.00%) (34264/34688)
Epoch: 225 | Batch_idx: 280 |  Loss: (0.0390) |  Loss2: (0.0000) | Acc: (98.00%) (35529/35968)
Epoch: 225 | Batch_idx: 290 |  Loss: (0.0391) |  Loss2: (0.0000) | Acc: (98.00%) (36790/37248)
Epoch: 225 | Batch_idx: 300 |  Loss: (0.0389) |  Loss2: (0.0000) | Acc: (98.00%) (38060/38528)
Epoch: 225 | Batch_idx: 310 |  Loss: (0.0391) |  Loss2: (0.0000) | Acc: (98.00%) (39326/39808)
Epoch: 225 | Batch_idx: 320 |  Loss: (0.0391) |  Loss2: (0.0000) | Acc: (98.00%) (40590/41088)
Epoch: 225 | Batch_idx: 330 |  Loss: (0.0389) |  Loss2: (0.0000) | Acc: (98.00%) (41857/42368)
Epoch: 225 | Batch_idx: 340 |  Loss: (0.0391) |  Loss2: (0.0000) | Acc: (98.00%) (43120/43648)
Epoch: 225 | Batch_idx: 350 |  Loss: (0.0391) |  Loss2: (0.0000) | Acc: (98.00%) (44380/44928)
Epoch: 225 | Batch_idx: 360 |  Loss: (0.0394) |  Loss2: (0.0000) | Acc: (98.00%) (45636/46208)
Epoch: 225 | Batch_idx: 370 |  Loss: (0.0397) |  Loss2: (0.0000) | Acc: (98.00%) (46892/47488)
Epoch: 225 | Batch_idx: 380 |  Loss: (0.0402) |  Loss2: (0.0000) | Acc: (98.00%) (48143/48768)
Epoch: 225 | Batch_idx: 390 |  Loss: (0.0403) |  Loss2: (0.0000) | Acc: (98.00%) (49356/50000)
=> saving checkpoint 'drive/app/torch/save_Schedule/checkpoint_225.pth.tar'
# TEST : Loss: (0.4359) | Acc: (89.00%) (8936/10000)
percent tensor([0.5820, 0.5969, 0.5848, 0.5821, 0.5906, 0.5965, 0.5970, 0.5805, 0.5816,
        0.5896, 0.5898, 0.5934, 0.5854, 0.5808, 0.5997, 0.5864],
       device='cuda:0') torch.Size([16])
percent tensor([0.5357, 0.5375, 0.5251, 0.5326, 0.5256, 0.5400, 0.5323, 0.5261, 0.5274,
        0.5337, 0.5384, 0.5279, 0.5338, 0.5346, 0.5380, 0.5374],
       device='cuda:0') torch.Size([16])
percent tensor([0.6033, 0.4704, 0.7359, 0.7414, 0.7518, 0.6995, 0.5813, 0.7109, 0.6489,
        0.5443, 0.5038, 0.6505, 0.4956, 0.5586, 0.5471, 0.6446],
       device='cuda:0') torch.Size([16])
percent tensor([0.7261, 0.7617, 0.6507, 0.6874, 0.6628, 0.5946, 0.7300, 0.6787, 0.7358,
        0.7611, 0.7709, 0.7225, 0.7426, 0.7718, 0.7066, 0.7038],
       device='cuda:0') torch.Size([16])
percent tensor([0.7576, 0.6393, 0.7857, 0.7695, 0.7953, 0.8487, 0.7459, 0.7672, 0.7231,
        0.6255, 0.6085, 0.6469, 0.6034, 0.6948, 0.7441, 0.8006],
       device='cuda:0') torch.Size([16])
percent tensor([0.6782, 0.8030, 0.7814, 0.8003, 0.7772, 0.8526, 0.7857, 0.5706, 0.7653,
        0.7728, 0.8028, 0.8038, 0.7976, 0.7982, 0.6210, 0.6282],
       device='cuda:0') torch.Size([16])
percent tensor([0.4466, 0.7288, 0.6413, 0.6290, 0.5932, 0.6898, 0.6903, 0.5765, 0.6622,
        0.6854, 0.7663, 0.6532, 0.6507, 0.6631, 0.5418, 0.3947],
       device='cuda:0') torch.Size([16])
percent tensor([0.9999, 0.9998, 0.9998, 0.9999, 1.0000, 0.9998, 0.9999, 0.9997, 0.9999,
        0.9999, 0.9999, 0.9999, 0.9997, 0.9995, 0.9998, 0.9995],
       device='cuda:0') torch.Size([16])
Epoch: 226 | Batch_idx: 0 |  Loss: (0.0386) |  Loss2: (0.0000) | Acc: (98.00%) (126/128)
Epoch: 226 | Batch_idx: 10 |  Loss: (0.0453) |  Loss2: (0.0000) | Acc: (98.00%) (1384/1408)
Epoch: 226 | Batch_idx: 20 |  Loss: (0.0416) |  Loss2: (0.0000) | Acc: (98.00%) (2647/2688)
Epoch: 226 | Batch_idx: 30 |  Loss: (0.0402) |  Loss2: (0.0000) | Acc: (98.00%) (3913/3968)
Epoch: 226 | Batch_idx: 40 |  Loss: (0.0390) |  Loss2: (0.0000) | Acc: (98.00%) (5177/5248)
Epoch: 226 | Batch_idx: 50 |  Loss: (0.0401) |  Loss2: (0.0000) | Acc: (98.00%) (6439/6528)
Epoch: 226 | Batch_idx: 60 |  Loss: (0.0399) |  Loss2: (0.0000) | Acc: (98.00%) (7700/7808)
Epoch: 226 | Batch_idx: 70 |  Loss: (0.0416) |  Loss2: (0.0000) | Acc: (98.00%) (8955/9088)
Epoch: 226 | Batch_idx: 80 |  Loss: (0.0412) |  Loss2: (0.0000) | Acc: (98.00%) (10222/10368)
Epoch: 226 | Batch_idx: 90 |  Loss: (0.0426) |  Loss2: (0.0000) | Acc: (98.00%) (11477/11648)
Epoch: 226 | Batch_idx: 100 |  Loss: (0.0430) |  Loss2: (0.0000) | Acc: (98.00%) (12739/12928)
Epoch: 226 | Batch_idx: 110 |  Loss: (0.0421) |  Loss2: (0.0000) | Acc: (98.00%) (14011/14208)
Epoch: 226 | Batch_idx: 120 |  Loss: (0.0419) |  Loss2: (0.0000) | Acc: (98.00%) (15280/15488)
Epoch: 226 | Batch_idx: 130 |  Loss: (0.0416) |  Loss2: (0.0000) | Acc: (98.00%) (16548/16768)
Epoch: 226 | Batch_idx: 140 |  Loss: (0.0413) |  Loss2: (0.0000) | Acc: (98.00%) (17811/18048)
Epoch: 226 | Batch_idx: 150 |  Loss: (0.0410) |  Loss2: (0.0000) | Acc: (98.00%) (19077/19328)
Epoch: 226 | Batch_idx: 160 |  Loss: (0.0409) |  Loss2: (0.0000) | Acc: (98.00%) (20341/20608)
Epoch: 226 | Batch_idx: 170 |  Loss: (0.0408) |  Loss2: (0.0000) | Acc: (98.00%) (21605/21888)
Epoch: 226 | Batch_idx: 180 |  Loss: (0.0406) |  Loss2: (0.0000) | Acc: (98.00%) (22875/23168)
Epoch: 226 | Batch_idx: 190 |  Loss: (0.0409) |  Loss2: (0.0000) | Acc: (98.00%) (24131/24448)
Epoch: 226 | Batch_idx: 200 |  Loss: (0.0408) |  Loss2: (0.0000) | Acc: (98.00%) (25398/25728)
Epoch: 226 | Batch_idx: 210 |  Loss: (0.0405) |  Loss2: (0.0000) | Acc: (98.00%) (26667/27008)
Epoch: 226 | Batch_idx: 220 |  Loss: (0.0409) |  Loss2: (0.0000) | Acc: (98.00%) (27926/28288)
Epoch: 226 | Batch_idx: 230 |  Loss: (0.0415) |  Loss2: (0.0000) | Acc: (98.00%) (29183/29568)
Epoch: 226 | Batch_idx: 240 |  Loss: (0.0415) |  Loss2: (0.0000) | Acc: (98.00%) (30445/30848)
Epoch: 226 | Batch_idx: 250 |  Loss: (0.0414) |  Loss2: (0.0000) | Acc: (98.00%) (31712/32128)
Epoch: 226 | Batch_idx: 260 |  Loss: (0.0417) |  Loss2: (0.0000) | Acc: (98.00%) (32972/33408)
Epoch: 226 | Batch_idx: 270 |  Loss: (0.0417) |  Loss2: (0.0000) | Acc: (98.00%) (34235/34688)
Epoch: 226 | Batch_idx: 280 |  Loss: (0.0417) |  Loss2: (0.0000) | Acc: (98.00%) (35496/35968)
Epoch: 226 | Batch_idx: 290 |  Loss: (0.0417) |  Loss2: (0.0000) | Acc: (98.00%) (36757/37248)
Epoch: 226 | Batch_idx: 300 |  Loss: (0.0416) |  Loss2: (0.0000) | Acc: (98.00%) (38022/38528)
Epoch: 226 | Batch_idx: 310 |  Loss: (0.0414) |  Loss2: (0.0000) | Acc: (98.00%) (39287/39808)
Epoch: 226 | Batch_idx: 320 |  Loss: (0.0414) |  Loss2: (0.0000) | Acc: (98.00%) (40548/41088)
Epoch: 226 | Batch_idx: 330 |  Loss: (0.0415) |  Loss2: (0.0000) | Acc: (98.00%) (41807/42368)
Epoch: 226 | Batch_idx: 340 |  Loss: (0.0414) |  Loss2: (0.0000) | Acc: (98.00%) (43074/43648)
Epoch: 226 | Batch_idx: 350 |  Loss: (0.0413) |  Loss2: (0.0000) | Acc: (98.00%) (44338/44928)
Epoch: 226 | Batch_idx: 360 |  Loss: (0.0412) |  Loss2: (0.0000) | Acc: (98.00%) (45604/46208)
Epoch: 226 | Batch_idx: 370 |  Loss: (0.0412) |  Loss2: (0.0000) | Acc: (98.00%) (46867/47488)
Epoch: 226 | Batch_idx: 380 |  Loss: (0.0413) |  Loss2: (0.0000) | Acc: (98.00%) (48130/48768)
Epoch: 226 | Batch_idx: 390 |  Loss: (0.0411) |  Loss2: (0.0000) | Acc: (98.00%) (49353/50000)
# TEST : Loss: (0.4295) | Acc: (89.00%) (8966/10000)
percent tensor([0.5813, 0.5961, 0.5843, 0.5824, 0.5898, 0.5954, 0.5960, 0.5799, 0.5808,
        0.5886, 0.5889, 0.5919, 0.5842, 0.5799, 0.5988, 0.5861],
       device='cuda:0') torch.Size([16])
percent tensor([0.5345, 0.5369, 0.5250, 0.5311, 0.5243, 0.5398, 0.5318, 0.5259, 0.5271,
        0.5331, 0.5376, 0.5277, 0.5334, 0.5340, 0.5370, 0.5361],
       device='cuda:0') torch.Size([16])
percent tensor([0.6134, 0.4773, 0.7465, 0.7449, 0.7563, 0.7025, 0.5891, 0.7073, 0.6613,
        0.5532, 0.5202, 0.6676, 0.5128, 0.5631, 0.5485, 0.6500],
       device='cuda:0') torch.Size([16])
percent tensor([0.7287, 0.7643, 0.6556, 0.6886, 0.6672, 0.6030, 0.7349, 0.6802, 0.7396,
        0.7667, 0.7743, 0.7279, 0.7454, 0.7726, 0.7107, 0.7085],
       device='cuda:0') torch.Size([16])
percent tensor([0.7503, 0.6554, 0.7829, 0.7721, 0.7949, 0.8530, 0.7435, 0.7698, 0.7097,
        0.6180, 0.6052, 0.6509, 0.5896, 0.6969, 0.7423, 0.7991],
       device='cuda:0') torch.Size([16])
percent tensor([0.6562, 0.7859, 0.7781, 0.8047, 0.7715, 0.8294, 0.7435, 0.5763, 0.7720,
        0.7633, 0.8008, 0.8100, 0.7944, 0.7917, 0.6114, 0.5823],
       device='cuda:0') torch.Size([16])
percent tensor([0.4127, 0.6943, 0.6319, 0.6320, 0.5548, 0.5826, 0.6267, 0.5683, 0.6750,
        0.6484, 0.7435, 0.6389, 0.6526, 0.6189, 0.5238, 0.3824],
       device='cuda:0') torch.Size([16])
percent tensor([0.9998, 0.9998, 0.9998, 0.9999, 1.0000, 0.9997, 0.9999, 0.9997, 0.9999,
        0.9999, 0.9999, 0.9999, 0.9998, 0.9995, 0.9998, 0.9994],
       device='cuda:0') torch.Size([16])
Epoch: 227 | Batch_idx: 0 |  Loss: (0.0622) |  Loss2: (0.0000) | Acc: (98.00%) (126/128)
Epoch: 227 | Batch_idx: 10 |  Loss: (0.0384) |  Loss2: (0.0000) | Acc: (98.00%) (1392/1408)
Epoch: 227 | Batch_idx: 20 |  Loss: (0.0414) |  Loss2: (0.0000) | Acc: (98.00%) (2654/2688)
Epoch: 227 | Batch_idx: 30 |  Loss: (0.0429) |  Loss2: (0.0000) | Acc: (98.00%) (3915/3968)
Epoch: 227 | Batch_idx: 40 |  Loss: (0.0388) |  Loss2: (0.0000) | Acc: (98.00%) (5185/5248)
Epoch: 227 | Batch_idx: 50 |  Loss: (0.0376) |  Loss2: (0.0000) | Acc: (98.00%) (6455/6528)
Epoch: 227 | Batch_idx: 60 |  Loss: (0.0367) |  Loss2: (0.0000) | Acc: (98.00%) (7723/7808)
Epoch: 227 | Batch_idx: 70 |  Loss: (0.0375) |  Loss2: (0.0000) | Acc: (98.00%) (8985/9088)
Epoch: 227 | Batch_idx: 80 |  Loss: (0.0372) |  Loss2: (0.0000) | Acc: (98.00%) (10255/10368)
Epoch: 227 | Batch_idx: 90 |  Loss: (0.0379) |  Loss2: (0.0000) | Acc: (98.00%) (11519/11648)
Epoch: 227 | Batch_idx: 100 |  Loss: (0.0376) |  Loss2: (0.0000) | Acc: (98.00%) (12786/12928)
Epoch: 227 | Batch_idx: 110 |  Loss: (0.0376) |  Loss2: (0.0000) | Acc: (98.00%) (14053/14208)
Epoch: 227 | Batch_idx: 120 |  Loss: (0.0371) |  Loss2: (0.0000) | Acc: (98.00%) (15322/15488)
Epoch: 227 | Batch_idx: 130 |  Loss: (0.0379) |  Loss2: (0.0000) | Acc: (98.00%) (16582/16768)
Epoch: 227 | Batch_idx: 140 |  Loss: (0.0382) |  Loss2: (0.0000) | Acc: (98.00%) (17847/18048)
Epoch: 227 | Batch_idx: 150 |  Loss: (0.0383) |  Loss2: (0.0000) | Acc: (98.00%) (19112/19328)
Epoch: 227 | Batch_idx: 160 |  Loss: (0.0387) |  Loss2: (0.0000) | Acc: (98.00%) (20372/20608)
Epoch: 227 | Batch_idx: 170 |  Loss: (0.0387) |  Loss2: (0.0000) | Acc: (98.00%) (21638/21888)
Epoch: 227 | Batch_idx: 180 |  Loss: (0.0386) |  Loss2: (0.0000) | Acc: (98.00%) (22907/23168)
Epoch: 227 | Batch_idx: 190 |  Loss: (0.0387) |  Loss2: (0.0000) | Acc: (98.00%) (24170/24448)
Epoch: 227 | Batch_idx: 200 |  Loss: (0.0383) |  Loss2: (0.0000) | Acc: (98.00%) (25440/25728)
Epoch: 227 | Batch_idx: 210 |  Loss: (0.0388) |  Loss2: (0.0000) | Acc: (98.00%) (26700/27008)
Epoch: 227 | Batch_idx: 220 |  Loss: (0.0388) |  Loss2: (0.0000) | Acc: (98.00%) (27967/28288)
Epoch: 227 | Batch_idx: 230 |  Loss: (0.0393) |  Loss2: (0.0000) | Acc: (98.00%) (29227/29568)
Epoch: 227 | Batch_idx: 240 |  Loss: (0.0392) |  Loss2: (0.0000) | Acc: (98.00%) (30492/30848)
Epoch: 227 | Batch_idx: 250 |  Loss: (0.0389) |  Loss2: (0.0000) | Acc: (98.00%) (31762/32128)
Epoch: 227 | Batch_idx: 260 |  Loss: (0.0391) |  Loss2: (0.0000) | Acc: (98.00%) (33025/33408)
Epoch: 227 | Batch_idx: 270 |  Loss: (0.0392) |  Loss2: (0.0000) | Acc: (98.00%) (34289/34688)
Epoch: 227 | Batch_idx: 280 |  Loss: (0.0394) |  Loss2: (0.0000) | Acc: (98.00%) (35549/35968)
Epoch: 227 | Batch_idx: 290 |  Loss: (0.0393) |  Loss2: (0.0000) | Acc: (98.00%) (36813/37248)
Epoch: 227 | Batch_idx: 300 |  Loss: (0.0392) |  Loss2: (0.0000) | Acc: (98.00%) (38075/38528)
Epoch: 227 | Batch_idx: 310 |  Loss: (0.0396) |  Loss2: (0.0000) | Acc: (98.00%) (39328/39808)
Epoch: 227 | Batch_idx: 320 |  Loss: (0.0398) |  Loss2: (0.0000) | Acc: (98.00%) (40592/41088)
Epoch: 227 | Batch_idx: 330 |  Loss: (0.0401) |  Loss2: (0.0000) | Acc: (98.00%) (41846/42368)
Epoch: 227 | Batch_idx: 340 |  Loss: (0.0399) |  Loss2: (0.0000) | Acc: (98.00%) (43111/43648)
Epoch: 227 | Batch_idx: 350 |  Loss: (0.0408) |  Loss2: (0.0000) | Acc: (98.00%) (44356/44928)
Epoch: 227 | Batch_idx: 360 |  Loss: (0.0412) |  Loss2: (0.0000) | Acc: (98.00%) (45607/46208)
Epoch: 227 | Batch_idx: 370 |  Loss: (0.0413) |  Loss2: (0.0000) | Acc: (98.00%) (46870/47488)
Epoch: 227 | Batch_idx: 380 |  Loss: (0.0415) |  Loss2: (0.0000) | Acc: (98.00%) (48122/48768)
Epoch: 227 | Batch_idx: 390 |  Loss: (0.0414) |  Loss2: (0.0000) | Acc: (98.00%) (49343/50000)
# TEST : Loss: (0.4376) | Acc: (89.00%) (8911/10000)
percent tensor([0.5828, 0.5976, 0.5872, 0.5834, 0.5919, 0.5974, 0.5979, 0.5815, 0.5818,
        0.5907, 0.5900, 0.5945, 0.5858, 0.5814, 0.6003, 0.5875],
       device='cuda:0') torch.Size([16])
percent tensor([0.5345, 0.5375, 0.5231, 0.5317, 0.5243, 0.5398, 0.5319, 0.5255, 0.5270,
        0.5328, 0.5376, 0.5268, 0.5334, 0.5344, 0.5377, 0.5366],
       device='cuda:0') torch.Size([16])
percent tensor([0.5998, 0.4601, 0.7394, 0.7380, 0.7511, 0.6834, 0.5733, 0.7079, 0.6317,
        0.5511, 0.4899, 0.6639, 0.4944, 0.5286, 0.5325, 0.6345],
       device='cuda:0') torch.Size([16])
percent tensor([0.7265, 0.7619, 0.6566, 0.6895, 0.6662, 0.6004, 0.7337, 0.6846, 0.7397,
        0.7648, 0.7746, 0.7262, 0.7432, 0.7765, 0.7101, 0.7078],
       device='cuda:0') torch.Size([16])
percent tensor([0.7546, 0.6408, 0.7795, 0.7738, 0.7943, 0.8533, 0.7310, 0.7659, 0.7067,
        0.6078, 0.5999, 0.6391, 0.5946, 0.6775, 0.7380, 0.7952],
       device='cuda:0') torch.Size([16])
percent tensor([0.6648, 0.7680, 0.7605, 0.8077, 0.7445, 0.8357, 0.7276, 0.5303, 0.7405,
        0.7304, 0.7693, 0.7808, 0.7731, 0.7936, 0.5596, 0.5903],
       device='cuda:0') torch.Size([16])
percent tensor([0.4602, 0.7290, 0.6280, 0.6585, 0.5694, 0.6688, 0.6788, 0.5885, 0.6436,
        0.6701, 0.7432, 0.6566, 0.6750, 0.6391, 0.5382, 0.4093],
       device='cuda:0') torch.Size([16])
percent tensor([0.9998, 0.9999, 0.9999, 0.9999, 1.0000, 0.9995, 0.9999, 0.9997, 0.9999,
        0.9999, 0.9999, 1.0000, 0.9998, 0.9996, 0.9998, 0.9994],
       device='cuda:0') torch.Size([16])
Epoch: 228 | Batch_idx: 0 |  Loss: (0.0476) |  Loss2: (0.0000) | Acc: (98.00%) (126/128)
Epoch: 228 | Batch_idx: 10 |  Loss: (0.0361) |  Loss2: (0.0000) | Acc: (98.00%) (1390/1408)
Epoch: 228 | Batch_idx: 20 |  Loss: (0.0385) |  Loss2: (0.0000) | Acc: (98.00%) (2657/2688)
Epoch: 228 | Batch_idx: 30 |  Loss: (0.0386) |  Loss2: (0.0000) | Acc: (98.00%) (3918/3968)
Epoch: 228 | Batch_idx: 40 |  Loss: (0.0398) |  Loss2: (0.0000) | Acc: (98.00%) (5181/5248)
Epoch: 228 | Batch_idx: 50 |  Loss: (0.0383) |  Loss2: (0.0000) | Acc: (98.00%) (6450/6528)
Epoch: 228 | Batch_idx: 60 |  Loss: (0.0381) |  Loss2: (0.0000) | Acc: (98.00%) (7714/7808)
Epoch: 228 | Batch_idx: 70 |  Loss: (0.0394) |  Loss2: (0.0000) | Acc: (98.00%) (8972/9088)
Epoch: 228 | Batch_idx: 80 |  Loss: (0.0407) |  Loss2: (0.0000) | Acc: (98.00%) (10232/10368)
Epoch: 228 | Batch_idx: 90 |  Loss: (0.0394) |  Loss2: (0.0000) | Acc: (98.00%) (11503/11648)
Epoch: 228 | Batch_idx: 100 |  Loss: (0.0394) |  Loss2: (0.0000) | Acc: (98.00%) (12767/12928)
Epoch: 228 | Batch_idx: 110 |  Loss: (0.0406) |  Loss2: (0.0000) | Acc: (98.00%) (14026/14208)
Epoch: 228 | Batch_idx: 120 |  Loss: (0.0400) |  Loss2: (0.0000) | Acc: (98.00%) (15294/15488)
Epoch: 228 | Batch_idx: 130 |  Loss: (0.0402) |  Loss2: (0.0000) | Acc: (98.00%) (16557/16768)
Epoch: 228 | Batch_idx: 140 |  Loss: (0.0396) |  Loss2: (0.0000) | Acc: (98.00%) (17827/18048)
Epoch: 228 | Batch_idx: 150 |  Loss: (0.0398) |  Loss2: (0.0000) | Acc: (98.00%) (19089/19328)
Epoch: 228 | Batch_idx: 160 |  Loss: (0.0400) |  Loss2: (0.0000) | Acc: (98.00%) (20353/20608)
Epoch: 228 | Batch_idx: 170 |  Loss: (0.0403) |  Loss2: (0.0000) | Acc: (98.00%) (21615/21888)
Epoch: 228 | Batch_idx: 180 |  Loss: (0.0398) |  Loss2: (0.0000) | Acc: (98.00%) (22884/23168)
Epoch: 228 | Batch_idx: 190 |  Loss: (0.0405) |  Loss2: (0.0000) | Acc: (98.00%) (24142/24448)
Epoch: 228 | Batch_idx: 200 |  Loss: (0.0408) |  Loss2: (0.0000) | Acc: (98.00%) (25406/25728)
Epoch: 228 | Batch_idx: 210 |  Loss: (0.0409) |  Loss2: (0.0000) | Acc: (98.00%) (26666/27008)
Epoch: 228 | Batch_idx: 220 |  Loss: (0.0406) |  Loss2: (0.0000) | Acc: (98.00%) (27928/28288)
Epoch: 228 | Batch_idx: 230 |  Loss: (0.0407) |  Loss2: (0.0000) | Acc: (98.00%) (29191/29568)
Epoch: 228 | Batch_idx: 240 |  Loss: (0.0410) |  Loss2: (0.0000) | Acc: (98.00%) (30452/30848)
Epoch: 228 | Batch_idx: 250 |  Loss: (0.0412) |  Loss2: (0.0000) | Acc: (98.00%) (31710/32128)
Epoch: 228 | Batch_idx: 260 |  Loss: (0.0411) |  Loss2: (0.0000) | Acc: (98.00%) (32974/33408)
Epoch: 228 | Batch_idx: 270 |  Loss: (0.0410) |  Loss2: (0.0000) | Acc: (98.00%) (34241/34688)
Epoch: 228 | Batch_idx: 280 |  Loss: (0.0410) |  Loss2: (0.0000) | Acc: (98.00%) (35502/35968)
Epoch: 228 | Batch_idx: 290 |  Loss: (0.0409) |  Loss2: (0.0000) | Acc: (98.00%) (36767/37248)
Epoch: 228 | Batch_idx: 300 |  Loss: (0.0407) |  Loss2: (0.0000) | Acc: (98.00%) (38033/38528)
Epoch: 228 | Batch_idx: 310 |  Loss: (0.0410) |  Loss2: (0.0000) | Acc: (98.00%) (39294/39808)
Epoch: 228 | Batch_idx: 320 |  Loss: (0.0410) |  Loss2: (0.0000) | Acc: (98.00%) (40561/41088)
Epoch: 228 | Batch_idx: 330 |  Loss: (0.0408) |  Loss2: (0.0000) | Acc: (98.00%) (41830/42368)
Epoch: 228 | Batch_idx: 340 |  Loss: (0.0407) |  Loss2: (0.0000) | Acc: (98.00%) (43096/43648)
Epoch: 228 | Batch_idx: 350 |  Loss: (0.0404) |  Loss2: (0.0000) | Acc: (98.00%) (44364/44928)
Epoch: 228 | Batch_idx: 360 |  Loss: (0.0401) |  Loss2: (0.0000) | Acc: (98.00%) (45636/46208)
Epoch: 228 | Batch_idx: 370 |  Loss: (0.0400) |  Loss2: (0.0000) | Acc: (98.00%) (46905/47488)
Epoch: 228 | Batch_idx: 380 |  Loss: (0.0399) |  Loss2: (0.0000) | Acc: (98.00%) (48174/48768)
Epoch: 228 | Batch_idx: 390 |  Loss: (0.0401) |  Loss2: (0.0000) | Acc: (98.00%) (49391/50000)
# TEST : Loss: (0.4595) | Acc: (89.00%) (8917/10000)
percent tensor([0.5853, 0.5997, 0.5886, 0.5849, 0.5945, 0.6009, 0.6009, 0.5840, 0.5857,
        0.5929, 0.5933, 0.5968, 0.5885, 0.5841, 0.6031, 0.5898],
       device='cuda:0') torch.Size([16])
percent tensor([0.5355, 0.5375, 0.5238, 0.5318, 0.5246, 0.5401, 0.5320, 0.5257, 0.5272,
        0.5331, 0.5381, 0.5272, 0.5338, 0.5346, 0.5383, 0.5370],
       device='cuda:0') torch.Size([16])
percent tensor([0.6005, 0.4559, 0.7304, 0.7353, 0.7519, 0.6945, 0.5785, 0.7007, 0.6366,
        0.5349, 0.4968, 0.6479, 0.4826, 0.5442, 0.5326, 0.6402],
       device='cuda:0') torch.Size([16])
percent tensor([0.7293, 0.7611, 0.6516, 0.6879, 0.6631, 0.5979, 0.7322, 0.6834, 0.7405,
        0.7633, 0.7743, 0.7216, 0.7433, 0.7728, 0.7103, 0.7101],
       device='cuda:0') torch.Size([16])
percent tensor([0.7643, 0.6722, 0.7924, 0.7764, 0.8030, 0.8620, 0.7484, 0.7689, 0.7210,
        0.6377, 0.6218, 0.6627, 0.6214, 0.7082, 0.7505, 0.8074],
       device='cuda:0') torch.Size([16])
percent tensor([0.6807, 0.8063, 0.7880, 0.8088, 0.7718, 0.8432, 0.7517, 0.5745, 0.7758,
        0.7807, 0.8082, 0.8088, 0.7986, 0.8069, 0.5941, 0.5809],
       device='cuda:0') torch.Size([16])
percent tensor([0.4862, 0.7303, 0.6532, 0.6477, 0.5709, 0.6491, 0.6745, 0.5916, 0.6887,
        0.6856, 0.7743, 0.6407, 0.6804, 0.6587, 0.5349, 0.3965],
       device='cuda:0') torch.Size([16])
percent tensor([0.9998, 0.9998, 0.9999, 0.9999, 1.0000, 0.9996, 1.0000, 0.9997, 0.9999,
        0.9999, 0.9999, 1.0000, 0.9998, 0.9994, 0.9998, 0.9995],
       device='cuda:0') torch.Size([16])
Epoch: 229 | Batch_idx: 0 |  Loss: (0.0757) |  Loss2: (0.0000) | Acc: (97.00%) (125/128)
Epoch: 229 | Batch_idx: 10 |  Loss: (0.0373) |  Loss2: (0.0000) | Acc: (99.00%) (1394/1408)
Epoch: 229 | Batch_idx: 20 |  Loss: (0.0332) |  Loss2: (0.0000) | Acc: (99.00%) (2665/2688)
Epoch: 229 | Batch_idx: 30 |  Loss: (0.0341) |  Loss2: (0.0000) | Acc: (98.00%) (3928/3968)
Epoch: 229 | Batch_idx: 40 |  Loss: (0.0357) |  Loss2: (0.0000) | Acc: (98.00%) (5192/5248)
Epoch: 229 | Batch_idx: 50 |  Loss: (0.0355) |  Loss2: (0.0000) | Acc: (98.00%) (6461/6528)
Epoch: 229 | Batch_idx: 60 |  Loss: (0.0351) |  Loss2: (0.0000) | Acc: (99.00%) (7732/7808)
Epoch: 229 | Batch_idx: 70 |  Loss: (0.0346) |  Loss2: (0.0000) | Acc: (98.00%) (8996/9088)
Epoch: 229 | Batch_idx: 80 |  Loss: (0.0352) |  Loss2: (0.0000) | Acc: (98.00%) (10258/10368)
Epoch: 229 | Batch_idx: 90 |  Loss: (0.0356) |  Loss2: (0.0000) | Acc: (98.00%) (11526/11648)
Epoch: 229 | Batch_idx: 100 |  Loss: (0.0360) |  Loss2: (0.0000) | Acc: (98.00%) (12788/12928)
Epoch: 229 | Batch_idx: 110 |  Loss: (0.0366) |  Loss2: (0.0000) | Acc: (98.00%) (14050/14208)
Epoch: 229 | Batch_idx: 120 |  Loss: (0.0365) |  Loss2: (0.0000) | Acc: (98.00%) (15317/15488)
Epoch: 229 | Batch_idx: 130 |  Loss: (0.0361) |  Loss2: (0.0000) | Acc: (98.00%) (16585/16768)
Epoch: 229 | Batch_idx: 140 |  Loss: (0.0357) |  Loss2: (0.0000) | Acc: (98.00%) (17857/18048)
Epoch: 229 | Batch_idx: 150 |  Loss: (0.0356) |  Loss2: (0.0000) | Acc: (98.00%) (19124/19328)
Epoch: 229 | Batch_idx: 160 |  Loss: (0.0362) |  Loss2: (0.0000) | Acc: (98.00%) (20382/20608)
Epoch: 229 | Batch_idx: 170 |  Loss: (0.0358) |  Loss2: (0.0000) | Acc: (98.00%) (21651/21888)
Epoch: 229 | Batch_idx: 180 |  Loss: (0.0360) |  Loss2: (0.0000) | Acc: (98.00%) (22916/23168)
Epoch: 229 | Batch_idx: 190 |  Loss: (0.0357) |  Loss2: (0.0000) | Acc: (98.00%) (24185/24448)
Epoch: 229 | Batch_idx: 200 |  Loss: (0.0360) |  Loss2: (0.0000) | Acc: (98.00%) (25449/25728)
Epoch: 229 | Batch_idx: 210 |  Loss: (0.0361) |  Loss2: (0.0000) | Acc: (98.00%) (26714/27008)
Epoch: 229 | Batch_idx: 220 |  Loss: (0.0362) |  Loss2: (0.0000) | Acc: (98.00%) (27979/28288)
Epoch: 229 | Batch_idx: 230 |  Loss: (0.0364) |  Loss2: (0.0000) | Acc: (98.00%) (29243/29568)
Epoch: 229 | Batch_idx: 240 |  Loss: (0.0362) |  Loss2: (0.0000) | Acc: (98.00%) (30515/30848)
Epoch: 229 | Batch_idx: 250 |  Loss: (0.0361) |  Loss2: (0.0000) | Acc: (98.00%) (31778/32128)
Epoch: 229 | Batch_idx: 260 |  Loss: (0.0366) |  Loss2: (0.0000) | Acc: (98.00%) (33037/33408)
Epoch: 229 | Batch_idx: 270 |  Loss: (0.0368) |  Loss2: (0.0000) | Acc: (98.00%) (34301/34688)
Epoch: 229 | Batch_idx: 280 |  Loss: (0.0370) |  Loss2: (0.0000) | Acc: (98.00%) (35561/35968)
Epoch: 229 | Batch_idx: 290 |  Loss: (0.0371) |  Loss2: (0.0000) | Acc: (98.00%) (36829/37248)
Epoch: 229 | Batch_idx: 300 |  Loss: (0.0373) |  Loss2: (0.0000) | Acc: (98.00%) (38091/38528)
Epoch: 229 | Batch_idx: 310 |  Loss: (0.0372) |  Loss2: (0.0000) | Acc: (98.00%) (39359/39808)
Epoch: 229 | Batch_idx: 320 |  Loss: (0.0376) |  Loss2: (0.0000) | Acc: (98.00%) (40619/41088)
Epoch: 229 | Batch_idx: 330 |  Loss: (0.0375) |  Loss2: (0.0000) | Acc: (98.00%) (41884/42368)
Epoch: 229 | Batch_idx: 340 |  Loss: (0.0374) |  Loss2: (0.0000) | Acc: (98.00%) (43149/43648)
Epoch: 229 | Batch_idx: 350 |  Loss: (0.0373) |  Loss2: (0.0000) | Acc: (98.00%) (44415/44928)
Epoch: 229 | Batch_idx: 360 |  Loss: (0.0373) |  Loss2: (0.0000) | Acc: (98.00%) (45677/46208)
Epoch: 229 | Batch_idx: 370 |  Loss: (0.0375) |  Loss2: (0.0000) | Acc: (98.00%) (46941/47488)
Epoch: 229 | Batch_idx: 380 |  Loss: (0.0378) |  Loss2: (0.0000) | Acc: (98.00%) (48199/48768)
Epoch: 229 | Batch_idx: 390 |  Loss: (0.0378) |  Loss2: (0.0000) | Acc: (98.00%) (49415/50000)
# TEST : Loss: (0.4565) | Acc: (88.00%) (8889/10000)
percent tensor([0.5835, 0.5975, 0.5882, 0.5838, 0.5941, 0.5989, 0.5986, 0.5825, 0.5834,
        0.5913, 0.5907, 0.5963, 0.5865, 0.5818, 0.6010, 0.5879],
       device='cuda:0') torch.Size([16])
percent tensor([0.5360, 0.5377, 0.5258, 0.5324, 0.5266, 0.5405, 0.5327, 0.5263, 0.5276,
        0.5336, 0.5384, 0.5281, 0.5341, 0.5349, 0.5387, 0.5373],
       device='cuda:0') torch.Size([16])
percent tensor([0.6014, 0.4633, 0.7360, 0.7374, 0.7524, 0.6979, 0.5760, 0.7059, 0.6536,
        0.5431, 0.5047, 0.6582, 0.4953, 0.5548, 0.5366, 0.6393],
       device='cuda:0') torch.Size([16])
percent tensor([0.7274, 0.7649, 0.6532, 0.6868, 0.6607, 0.5969, 0.7335, 0.6846, 0.7345,
        0.7635, 0.7727, 0.7246, 0.7403, 0.7730, 0.7086, 0.7082],
       device='cuda:0') torch.Size([16])
percent tensor([0.7618, 0.6667, 0.7858, 0.7750, 0.8004, 0.8566, 0.7517, 0.7695, 0.7214,
        0.6358, 0.6296, 0.6530, 0.6226, 0.7065, 0.7559, 0.8071],
       device='cuda:0') torch.Size([16])
percent tensor([0.6592, 0.7737, 0.7811, 0.8095, 0.7668, 0.8463, 0.7334, 0.5453, 0.7719,
        0.7417, 0.8005, 0.8067, 0.7819, 0.7784, 0.5769, 0.5883],
       device='cuda:0') torch.Size([16])
percent tensor([0.4512, 0.7044, 0.6307, 0.6398, 0.5579, 0.6683, 0.6244, 0.5580, 0.6667,
        0.6274, 0.7568, 0.6528, 0.6552, 0.5972, 0.5195, 0.3856],
       device='cuda:0') torch.Size([16])
percent tensor([0.9999, 0.9998, 0.9998, 1.0000, 1.0000, 0.9996, 0.9999, 0.9996, 0.9999,
        1.0000, 0.9998, 1.0000, 0.9997, 0.9997, 0.9998, 0.9994],
       device='cuda:0') torch.Size([16])
Epoch: 230 | Batch_idx: 0 |  Loss: (0.0209) |  Loss2: (0.0000) | Acc: (99.00%) (127/128)
Epoch: 230 | Batch_idx: 10 |  Loss: (0.0411) |  Loss2: (0.0000) | Acc: (98.00%) (1387/1408)
Epoch: 230 | Batch_idx: 20 |  Loss: (0.0411) |  Loss2: (0.0000) | Acc: (98.00%) (2650/2688)
Epoch: 230 | Batch_idx: 30 |  Loss: (0.0411) |  Loss2: (0.0000) | Acc: (98.00%) (3911/3968)
Epoch: 230 | Batch_idx: 40 |  Loss: (0.0412) |  Loss2: (0.0000) | Acc: (98.00%) (5174/5248)
Epoch: 230 | Batch_idx: 50 |  Loss: (0.0403) |  Loss2: (0.0000) | Acc: (98.00%) (6441/6528)
Epoch: 230 | Batch_idx: 60 |  Loss: (0.0383) |  Loss2: (0.0000) | Acc: (98.00%) (7711/7808)
Epoch: 230 | Batch_idx: 70 |  Loss: (0.0382) |  Loss2: (0.0000) | Acc: (98.00%) (8978/9088)
Epoch: 230 | Batch_idx: 80 |  Loss: (0.0374) |  Loss2: (0.0000) | Acc: (98.00%) (10248/10368)
Epoch: 230 | Batch_idx: 90 |  Loss: (0.0372) |  Loss2: (0.0000) | Acc: (98.00%) (11516/11648)
Epoch: 230 | Batch_idx: 100 |  Loss: (0.0371) |  Loss2: (0.0000) | Acc: (98.00%) (12784/12928)
Epoch: 230 | Batch_idx: 110 |  Loss: (0.0370) |  Loss2: (0.0000) | Acc: (98.00%) (14046/14208)
Epoch: 230 | Batch_idx: 120 |  Loss: (0.0375) |  Loss2: (0.0000) | Acc: (98.00%) (15307/15488)
Epoch: 230 | Batch_idx: 130 |  Loss: (0.0378) |  Loss2: (0.0000) | Acc: (98.00%) (16569/16768)
Epoch: 230 | Batch_idx: 140 |  Loss: (0.0385) |  Loss2: (0.0000) | Acc: (98.00%) (17828/18048)
Epoch: 230 | Batch_idx: 150 |  Loss: (0.0383) |  Loss2: (0.0000) | Acc: (98.00%) (19097/19328)
Epoch: 230 | Batch_idx: 160 |  Loss: (0.0379) |  Loss2: (0.0000) | Acc: (98.00%) (20366/20608)
Epoch: 230 | Batch_idx: 170 |  Loss: (0.0381) |  Loss2: (0.0000) | Acc: (98.00%) (21627/21888)
Epoch: 230 | Batch_idx: 180 |  Loss: (0.0380) |  Loss2: (0.0000) | Acc: (98.00%) (22891/23168)
Epoch: 230 | Batch_idx: 190 |  Loss: (0.0380) |  Loss2: (0.0000) | Acc: (98.00%) (24150/24448)
Epoch: 230 | Batch_idx: 200 |  Loss: (0.0385) |  Loss2: (0.0000) | Acc: (98.00%) (25411/25728)
Epoch: 230 | Batch_idx: 210 |  Loss: (0.0387) |  Loss2: (0.0000) | Acc: (98.00%) (26671/27008)
Epoch: 230 | Batch_idx: 220 |  Loss: (0.0383) |  Loss2: (0.0000) | Acc: (98.00%) (27938/28288)
Epoch: 230 | Batch_idx: 230 |  Loss: (0.0382) |  Loss2: (0.0000) | Acc: (98.00%) (29207/29568)
Epoch: 230 | Batch_idx: 240 |  Loss: (0.0383) |  Loss2: (0.0000) | Acc: (98.00%) (30473/30848)
Epoch: 230 | Batch_idx: 250 |  Loss: (0.0382) |  Loss2: (0.0000) | Acc: (98.00%) (31740/32128)
Epoch: 230 | Batch_idx: 260 |  Loss: (0.0378) |  Loss2: (0.0000) | Acc: (98.00%) (33009/33408)
Epoch: 230 | Batch_idx: 270 |  Loss: (0.0379) |  Loss2: (0.0000) | Acc: (98.00%) (34273/34688)
Epoch: 230 | Batch_idx: 280 |  Loss: (0.0378) |  Loss2: (0.0000) | Acc: (98.00%) (35539/35968)
Epoch: 230 | Batch_idx: 290 |  Loss: (0.0376) |  Loss2: (0.0000) | Acc: (98.00%) (36804/37248)
Epoch: 230 | Batch_idx: 300 |  Loss: (0.0374) |  Loss2: (0.0000) | Acc: (98.00%) (38072/38528)
Epoch: 230 | Batch_idx: 310 |  Loss: (0.0375) |  Loss2: (0.0000) | Acc: (98.00%) (39334/39808)
Epoch: 230 | Batch_idx: 320 |  Loss: (0.0373) |  Loss2: (0.0000) | Acc: (98.00%) (40605/41088)
Epoch: 230 | Batch_idx: 330 |  Loss: (0.0374) |  Loss2: (0.0000) | Acc: (98.00%) (41870/42368)
Epoch: 230 | Batch_idx: 340 |  Loss: (0.0375) |  Loss2: (0.0000) | Acc: (98.00%) (43133/43648)
Epoch: 230 | Batch_idx: 350 |  Loss: (0.0378) |  Loss2: (0.0000) | Acc: (98.00%) (44394/44928)
Epoch: 230 | Batch_idx: 360 |  Loss: (0.0382) |  Loss2: (0.0000) | Acc: (98.00%) (45652/46208)
Epoch: 230 | Batch_idx: 370 |  Loss: (0.0381) |  Loss2: (0.0000) | Acc: (98.00%) (46921/47488)
Epoch: 230 | Batch_idx: 380 |  Loss: (0.0379) |  Loss2: (0.0000) | Acc: (98.00%) (48192/48768)
Epoch: 230 | Batch_idx: 390 |  Loss: (0.0381) |  Loss2: (0.0000) | Acc: (98.00%) (49410/50000)
=> saving checkpoint 'drive/app/torch/save_Schedule/checkpoint_230.pth.tar'
# TEST : Loss: (0.4453) | Acc: (89.00%) (8912/10000)
percent tensor([0.5837, 0.5988, 0.5866, 0.5831, 0.5927, 0.5986, 0.5995, 0.5828, 0.5843,
        0.5919, 0.5918, 0.5954, 0.5874, 0.5842, 0.6014, 0.5885],
       device='cuda:0') torch.Size([16])
percent tensor([0.5354, 0.5378, 0.5244, 0.5322, 0.5254, 0.5406, 0.5322, 0.5256, 0.5265,
        0.5335, 0.5378, 0.5281, 0.5340, 0.5346, 0.5388, 0.5370],
       device='cuda:0') torch.Size([16])
percent tensor([0.6033, 0.4774, 0.7311, 0.7417, 0.7514, 0.6965, 0.5844, 0.7095, 0.6527,
        0.5497, 0.5197, 0.6507, 0.5015, 0.5825, 0.5437, 0.6473],
       device='cuda:0') torch.Size([16])
percent tensor([0.7293, 0.7677, 0.6635, 0.6946, 0.6706, 0.5949, 0.7376, 0.6883, 0.7383,
        0.7652, 0.7729, 0.7313, 0.7456, 0.7771, 0.7099, 0.7078],
       device='cuda:0') torch.Size([16])
percent tensor([0.7634, 0.6547, 0.7848, 0.7756, 0.7998, 0.8622, 0.7428, 0.7692, 0.7259,
        0.6286, 0.6223, 0.6467, 0.6122, 0.7000, 0.7539, 0.8053],
       device='cuda:0') torch.Size([16])
percent tensor([0.6789, 0.7803, 0.7845, 0.8171, 0.7711, 0.8479, 0.7706, 0.5671, 0.7765,
        0.7539, 0.8083, 0.7998, 0.7835, 0.7868, 0.6066, 0.6170],
       device='cuda:0') torch.Size([16])
percent tensor([0.4473, 0.7077, 0.6439, 0.6535, 0.5790, 0.6704, 0.6456, 0.5680, 0.6718,
        0.6493, 0.7672, 0.6477, 0.6665, 0.6204, 0.5365, 0.4039],
       device='cuda:0') torch.Size([16])
percent tensor([0.9999, 0.9998, 0.9998, 0.9999, 1.0000, 0.9996, 1.0000, 0.9996, 0.9999,
        0.9999, 0.9999, 1.0000, 0.9998, 0.9997, 0.9997, 0.9995],
       device='cuda:0') torch.Size([16])
Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 3, 3, 3]) tensor(187.9955, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(830.6342, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(845.6439, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([128, 64, 3, 3]) tensor(1510.1888, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([128, 64, 1, 1]) tensor(477.7000, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([128, 128, 3, 3]) tensor(2317.5542, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([256, 128, 3, 3]) tensor(4279.6255, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([256, 128, 1, 1]) tensor(1337.3589, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([256, 256, 3, 3]) tensor(6365.5166, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([512, 256, 3, 3]) tensor(11456.2314, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([512, 256, 1, 1]) tensor(3749.3696, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([512, 512, 3, 3]) tensor(15782.3359, device='cuda:0', grad_fn=<NormBackward0>)
Epoch: 231 | Batch_idx: 0 |  Loss: (0.0406) |  Loss2: (0.0000) | Acc: (99.00%) (127/128)
Epoch: 231 | Batch_idx: 10 |  Loss: (0.0409) |  Loss2: (0.0000) | Acc: (98.00%) (1388/1408)
Epoch: 231 | Batch_idx: 20 |  Loss: (0.0391) |  Loss2: (0.0000) | Acc: (98.00%) (2649/2688)
Epoch: 231 | Batch_idx: 30 |  Loss: (0.0397) |  Loss2: (0.0000) | Acc: (98.00%) (3916/3968)
Epoch: 231 | Batch_idx: 40 |  Loss: (0.0441) |  Loss2: (0.0000) | Acc: (98.00%) (5176/5248)
Epoch: 231 | Batch_idx: 50 |  Loss: (0.0435) |  Loss2: (0.0000) | Acc: (98.00%) (6439/6528)
Epoch: 231 | Batch_idx: 60 |  Loss: (0.0442) |  Loss2: (0.0000) | Acc: (98.00%) (7697/7808)
Epoch: 231 | Batch_idx: 70 |  Loss: (0.0426) |  Loss2: (0.0000) | Acc: (98.00%) (8963/9088)
Epoch: 231 | Batch_idx: 80 |  Loss: (0.0424) |  Loss2: (0.0000) | Acc: (98.00%) (10224/10368)
Epoch: 231 | Batch_idx: 90 |  Loss: (0.0419) |  Loss2: (0.0000) | Acc: (98.00%) (11486/11648)
Epoch: 231 | Batch_idx: 100 |  Loss: (0.0426) |  Loss2: (0.0000) | Acc: (98.00%) (12745/12928)
Epoch: 231 | Batch_idx: 110 |  Loss: (0.0433) |  Loss2: (0.0000) | Acc: (98.00%) (14003/14208)
Epoch: 231 | Batch_idx: 120 |  Loss: (0.0431) |  Loss2: (0.0000) | Acc: (98.00%) (15268/15488)
Epoch: 231 | Batch_idx: 130 |  Loss: (0.0439) |  Loss2: (0.0000) | Acc: (98.00%) (16524/16768)
Epoch: 231 | Batch_idx: 140 |  Loss: (0.0442) |  Loss2: (0.0000) | Acc: (98.00%) (17783/18048)
Epoch: 231 | Batch_idx: 150 |  Loss: (0.0441) |  Loss2: (0.0000) | Acc: (98.00%) (19045/19328)
Epoch: 231 | Batch_idx: 160 |  Loss: (0.0433) |  Loss2: (0.0000) | Acc: (98.00%) (20313/20608)
Epoch: 231 | Batch_idx: 170 |  Loss: (0.0428) |  Loss2: (0.0000) | Acc: (98.00%) (21579/21888)
Epoch: 231 | Batch_idx: 180 |  Loss: (0.0424) |  Loss2: (0.0000) | Acc: (98.00%) (22843/23168)
Epoch: 231 | Batch_idx: 190 |  Loss: (0.0425) |  Loss2: (0.0000) | Acc: (98.00%) (24102/24448)
Epoch: 231 | Batch_idx: 200 |  Loss: (0.0422) |  Loss2: (0.0000) | Acc: (98.00%) (25368/25728)
Epoch: 231 | Batch_idx: 210 |  Loss: (0.0419) |  Loss2: (0.0000) | Acc: (98.00%) (26633/27008)
Epoch: 231 | Batch_idx: 220 |  Loss: (0.0423) |  Loss2: (0.0000) | Acc: (98.00%) (27893/28288)
Epoch: 231 | Batch_idx: 230 |  Loss: (0.0419) |  Loss2: (0.0000) | Acc: (98.00%) (29163/29568)
Epoch: 231 | Batch_idx: 240 |  Loss: (0.0417) |  Loss2: (0.0000) | Acc: (98.00%) (30429/30848)
Epoch: 231 | Batch_idx: 250 |  Loss: (0.0419) |  Loss2: (0.0000) | Acc: (98.00%) (31685/32128)
Epoch: 231 | Batch_idx: 260 |  Loss: (0.0415) |  Loss2: (0.0000) | Acc: (98.00%) (32950/33408)
Epoch: 231 | Batch_idx: 270 |  Loss: (0.0414) |  Loss2: (0.0000) | Acc: (98.00%) (34213/34688)
Epoch: 231 | Batch_idx: 280 |  Loss: (0.0415) |  Loss2: (0.0000) | Acc: (98.00%) (35473/35968)
Epoch: 231 | Batch_idx: 290 |  Loss: (0.0414) |  Loss2: (0.0000) | Acc: (98.00%) (36733/37248)
Epoch: 231 | Batch_idx: 300 |  Loss: (0.0413) |  Loss2: (0.0000) | Acc: (98.00%) (37995/38528)
Epoch: 231 | Batch_idx: 310 |  Loss: (0.0412) |  Loss2: (0.0000) | Acc: (98.00%) (39265/39808)
Epoch: 231 | Batch_idx: 320 |  Loss: (0.0413) |  Loss2: (0.0000) | Acc: (98.00%) (40529/41088)
Epoch: 231 | Batch_idx: 330 |  Loss: (0.0415) |  Loss2: (0.0000) | Acc: (98.00%) (41789/42368)
Epoch: 231 | Batch_idx: 340 |  Loss: (0.0416) |  Loss2: (0.0000) | Acc: (98.00%) (43050/43648)
Epoch: 231 | Batch_idx: 350 |  Loss: (0.0417) |  Loss2: (0.0000) | Acc: (98.00%) (44308/44928)
Epoch: 231 | Batch_idx: 360 |  Loss: (0.0419) |  Loss2: (0.0000) | Acc: (98.00%) (45565/46208)
Epoch: 231 | Batch_idx: 370 |  Loss: (0.0420) |  Loss2: (0.0000) | Acc: (98.00%) (46824/47488)
Epoch: 231 | Batch_idx: 380 |  Loss: (0.0419) |  Loss2: (0.0000) | Acc: (98.00%) (48089/48768)
Epoch: 231 | Batch_idx: 390 |  Loss: (0.0420) |  Loss2: (0.0000) | Acc: (98.00%) (49301/50000)
# TEST : Loss: (0.4549) | Acc: (88.00%) (8889/10000)
percent tensor([0.5846, 0.5983, 0.5897, 0.5846, 0.5949, 0.5995, 0.5997, 0.5842, 0.5840,
        0.5926, 0.5915, 0.5977, 0.5876, 0.5809, 0.6018, 0.5889],
       device='cuda:0') torch.Size([16])
percent tensor([0.5363, 0.5382, 0.5263, 0.5325, 0.5265, 0.5408, 0.5331, 0.5268, 0.5285,
        0.5343, 0.5389, 0.5287, 0.5342, 0.5358, 0.5386, 0.5378],
       device='cuda:0') torch.Size([16])
percent tensor([0.6069, 0.4854, 0.7487, 0.7514, 0.7553, 0.6986, 0.5930, 0.7167, 0.6503,
        0.5652, 0.5178, 0.6746, 0.5061, 0.5791, 0.5464, 0.6508],
       device='cuda:0') torch.Size([16])
percent tensor([0.7284, 0.7611, 0.6538, 0.6863, 0.6625, 0.5918, 0.7357, 0.6839, 0.7374,
        0.7656, 0.7726, 0.7287, 0.7442, 0.7763, 0.7067, 0.7023],
       device='cuda:0') torch.Size([16])
percent tensor([0.7575, 0.6654, 0.7797, 0.7703, 0.7945, 0.8608, 0.7453, 0.7616, 0.7192,
        0.6315, 0.6241, 0.6426, 0.6143, 0.7080, 0.7457, 0.8033],
       device='cuda:0') torch.Size([16])
percent tensor([0.6824, 0.7778, 0.7832, 0.8201, 0.7705, 0.8437, 0.7412, 0.5580, 0.7968,
        0.7593, 0.8172, 0.8090, 0.8008, 0.7955, 0.6287, 0.6278],
       device='cuda:0') torch.Size([16])
percent tensor([0.4636, 0.7071, 0.6397, 0.6598, 0.5737, 0.6608, 0.6535, 0.5579, 0.7171,
        0.6387, 0.7743, 0.6703, 0.6828, 0.6618, 0.5551, 0.4040],
       device='cuda:0') torch.Size([16])
percent tensor([0.9999, 0.9998, 0.9999, 0.9999, 1.0000, 0.9996, 0.9999, 0.9996, 0.9999,
        0.9999, 0.9999, 0.9999, 0.9998, 0.9996, 0.9998, 0.9994],
       device='cuda:0') torch.Size([16])
Epoch: 232 | Batch_idx: 0 |  Loss: (0.0182) |  Loss2: (0.0000) | Acc: (100.00%) (128/128)
Epoch: 232 | Batch_idx: 10 |  Loss: (0.0322) |  Loss2: (0.0000) | Acc: (99.00%) (1397/1408)
Epoch: 232 | Batch_idx: 20 |  Loss: (0.0327) |  Loss2: (0.0000) | Acc: (99.00%) (2668/2688)
Epoch: 232 | Batch_idx: 30 |  Loss: (0.0357) |  Loss2: (0.0000) | Acc: (98.00%) (3926/3968)
Epoch: 232 | Batch_idx: 40 |  Loss: (0.0352) |  Loss2: (0.0000) | Acc: (98.00%) (5195/5248)
Epoch: 232 | Batch_idx: 50 |  Loss: (0.0336) |  Loss2: (0.0000) | Acc: (99.00%) (6467/6528)
Epoch: 232 | Batch_idx: 60 |  Loss: (0.0353) |  Loss2: (0.0000) | Acc: (99.00%) (7732/7808)
Epoch: 232 | Batch_idx: 70 |  Loss: (0.0371) |  Loss2: (0.0000) | Acc: (98.00%) (8985/9088)
Epoch: 232 | Batch_idx: 80 |  Loss: (0.0373) |  Loss2: (0.0000) | Acc: (98.00%) (10251/10368)
Epoch: 232 | Batch_idx: 90 |  Loss: (0.0374) |  Loss2: (0.0000) | Acc: (98.00%) (11518/11648)
Epoch: 232 | Batch_idx: 100 |  Loss: (0.0366) |  Loss2: (0.0000) | Acc: (98.00%) (12786/12928)
Epoch: 232 | Batch_idx: 110 |  Loss: (0.0365) |  Loss2: (0.0000) | Acc: (98.00%) (14054/14208)
Epoch: 232 | Batch_idx: 120 |  Loss: (0.0363) |  Loss2: (0.0000) | Acc: (98.00%) (15320/15488)
Epoch: 232 | Batch_idx: 130 |  Loss: (0.0369) |  Loss2: (0.0000) | Acc: (98.00%) (16579/16768)
Epoch: 232 | Batch_idx: 140 |  Loss: (0.0363) |  Loss2: (0.0000) | Acc: (98.00%) (17850/18048)
Epoch: 232 | Batch_idx: 150 |  Loss: (0.0363) |  Loss2: (0.0000) | Acc: (98.00%) (19113/19328)
Epoch: 232 | Batch_idx: 160 |  Loss: (0.0361) |  Loss2: (0.0000) | Acc: (98.00%) (20380/20608)
Epoch: 232 | Batch_idx: 170 |  Loss: (0.0362) |  Loss2: (0.0000) | Acc: (98.00%) (21646/21888)
Epoch: 232 | Batch_idx: 180 |  Loss: (0.0362) |  Loss2: (0.0000) | Acc: (98.00%) (22917/23168)
Epoch: 232 | Batch_idx: 190 |  Loss: (0.0359) |  Loss2: (0.0000) | Acc: (98.00%) (24183/24448)
Epoch: 232 | Batch_idx: 200 |  Loss: (0.0360) |  Loss2: (0.0000) | Acc: (98.00%) (25450/25728)
Epoch: 232 | Batch_idx: 210 |  Loss: (0.0359) |  Loss2: (0.0000) | Acc: (98.00%) (26717/27008)
Epoch: 232 | Batch_idx: 220 |  Loss: (0.0360) |  Loss2: (0.0000) | Acc: (98.00%) (27979/28288)
Epoch: 232 | Batch_idx: 230 |  Loss: (0.0360) |  Loss2: (0.0000) | Acc: (98.00%) (29245/29568)
Epoch: 232 | Batch_idx: 240 |  Loss: (0.0361) |  Loss2: (0.0000) | Acc: (98.00%) (30509/30848)
Epoch: 232 | Batch_idx: 250 |  Loss: (0.0361) |  Loss2: (0.0000) | Acc: (98.00%) (31774/32128)
Epoch: 232 | Batch_idx: 260 |  Loss: (0.0358) |  Loss2: (0.0000) | Acc: (98.00%) (33044/33408)
Epoch: 232 | Batch_idx: 270 |  Loss: (0.0361) |  Loss2: (0.0000) | Acc: (98.00%) (34306/34688)
Epoch: 232 | Batch_idx: 280 |  Loss: (0.0357) |  Loss2: (0.0000) | Acc: (98.00%) (35583/35968)
Epoch: 232 | Batch_idx: 290 |  Loss: (0.0357) |  Loss2: (0.0000) | Acc: (98.00%) (36852/37248)
Epoch: 232 | Batch_idx: 300 |  Loss: (0.0355) |  Loss2: (0.0000) | Acc: (98.00%) (38123/38528)
Epoch: 232 | Batch_idx: 310 |  Loss: (0.0355) |  Loss2: (0.0000) | Acc: (98.00%) (39389/39808)
Epoch: 232 | Batch_idx: 320 |  Loss: (0.0353) |  Loss2: (0.0000) | Acc: (98.00%) (40660/41088)
Epoch: 232 | Batch_idx: 330 |  Loss: (0.0351) |  Loss2: (0.0000) | Acc: (98.00%) (41929/42368)
Epoch: 232 | Batch_idx: 340 |  Loss: (0.0354) |  Loss2: (0.0000) | Acc: (98.00%) (43186/43648)
Epoch: 232 | Batch_idx: 350 |  Loss: (0.0353) |  Loss2: (0.0000) | Acc: (98.00%) (44454/44928)
Epoch: 232 | Batch_idx: 360 |  Loss: (0.0353) |  Loss2: (0.0000) | Acc: (98.00%) (45720/46208)
Epoch: 232 | Batch_idx: 370 |  Loss: (0.0356) |  Loss2: (0.0000) | Acc: (98.00%) (46979/47488)
Epoch: 232 | Batch_idx: 380 |  Loss: (0.0360) |  Loss2: (0.0000) | Acc: (98.00%) (48233/48768)
Epoch: 232 | Batch_idx: 390 |  Loss: (0.0362) |  Loss2: (0.0000) | Acc: (98.00%) (49446/50000)
# TEST : Loss: (0.4559) | Acc: (89.00%) (8902/10000)
percent tensor([0.5859, 0.5992, 0.5903, 0.5864, 0.5951, 0.6008, 0.6000, 0.5850, 0.5841,
        0.5934, 0.5925, 0.5978, 0.5883, 0.5814, 0.6034, 0.5903],
       device='cuda:0') torch.Size([16])
percent tensor([0.5361, 0.5389, 0.5269, 0.5325, 0.5264, 0.5401, 0.5336, 0.5276, 0.5284,
        0.5347, 0.5391, 0.5293, 0.5344, 0.5363, 0.5386, 0.5374],
       device='cuda:0') torch.Size([16])
percent tensor([0.6003, 0.4892, 0.7367, 0.7389, 0.7478, 0.6940, 0.5951, 0.7138, 0.6485,
        0.5618, 0.5117, 0.6597, 0.5020, 0.5867, 0.5478, 0.6470],
       device='cuda:0') torch.Size([16])
percent tensor([0.7284, 0.7574, 0.6587, 0.6851, 0.6674, 0.5934, 0.7304, 0.6721, 0.7389,
        0.7599, 0.7684, 0.7295, 0.7420, 0.7707, 0.7019, 0.6973],
       device='cuda:0') torch.Size([16])
percent tensor([0.7578, 0.6714, 0.7876, 0.7742, 0.7914, 0.8560, 0.7631, 0.7768, 0.7217,
        0.6432, 0.6252, 0.6488, 0.6144, 0.7150, 0.7538, 0.8054],
       device='cuda:0') torch.Size([16])
percent tensor([0.6619, 0.7958, 0.7613, 0.8055, 0.7685, 0.8281, 0.7765, 0.5810, 0.7753,
        0.7697, 0.8215, 0.8034, 0.8019, 0.8018, 0.5998, 0.6343],
       device='cuda:0') torch.Size([16])
percent tensor([0.4482, 0.7246, 0.6119, 0.6439, 0.5934, 0.6836, 0.6630, 0.5432, 0.6830,
        0.6765, 0.7745, 0.6645, 0.6949, 0.6346, 0.5470, 0.4190],
       device='cuda:0') torch.Size([16])
percent tensor([0.9998, 0.9998, 0.9999, 1.0000, 1.0000, 0.9996, 0.9999, 0.9996, 0.9999,
        0.9999, 0.9999, 1.0000, 0.9997, 0.9995, 0.9998, 0.9994],
       device='cuda:0') torch.Size([16])
Epoch: 233 | Batch_idx: 0 |  Loss: (0.0545) |  Loss2: (0.0000) | Acc: (98.00%) (126/128)
Epoch: 233 | Batch_idx: 10 |  Loss: (0.0404) |  Loss2: (0.0000) | Acc: (98.00%) (1391/1408)
Epoch: 233 | Batch_idx: 20 |  Loss: (0.0381) |  Loss2: (0.0000) | Acc: (98.00%) (2658/2688)
Epoch: 233 | Batch_idx: 30 |  Loss: (0.0398) |  Loss2: (0.0000) | Acc: (98.00%) (3918/3968)
Epoch: 233 | Batch_idx: 40 |  Loss: (0.0387) |  Loss2: (0.0000) | Acc: (98.00%) (5181/5248)
Epoch: 233 | Batch_idx: 50 |  Loss: (0.0378) |  Loss2: (0.0000) | Acc: (98.00%) (6449/6528)
Epoch: 233 | Batch_idx: 60 |  Loss: (0.0362) |  Loss2: (0.0000) | Acc: (98.00%) (7719/7808)
Epoch: 233 | Batch_idx: 70 |  Loss: (0.0365) |  Loss2: (0.0000) | Acc: (98.00%) (8987/9088)
Epoch: 233 | Batch_idx: 80 |  Loss: (0.0377) |  Loss2: (0.0000) | Acc: (98.00%) (10245/10368)
Epoch: 233 | Batch_idx: 90 |  Loss: (0.0371) |  Loss2: (0.0000) | Acc: (98.00%) (11516/11648)
Epoch: 233 | Batch_idx: 100 |  Loss: (0.0365) |  Loss2: (0.0000) | Acc: (98.00%) (12783/12928)
Epoch: 233 | Batch_idx: 110 |  Loss: (0.0361) |  Loss2: (0.0000) | Acc: (98.00%) (14051/14208)
Epoch: 233 | Batch_idx: 120 |  Loss: (0.0360) |  Loss2: (0.0000) | Acc: (98.00%) (15321/15488)
Epoch: 233 | Batch_idx: 130 |  Loss: (0.0363) |  Loss2: (0.0000) | Acc: (98.00%) (16586/16768)
Epoch: 233 | Batch_idx: 140 |  Loss: (0.0368) |  Loss2: (0.0000) | Acc: (98.00%) (17848/18048)
Epoch: 233 | Batch_idx: 150 |  Loss: (0.0365) |  Loss2: (0.0000) | Acc: (98.00%) (19119/19328)
Epoch: 233 | Batch_idx: 160 |  Loss: (0.0364) |  Loss2: (0.0000) | Acc: (98.00%) (20384/20608)
Epoch: 233 | Batch_idx: 170 |  Loss: (0.0366) |  Loss2: (0.0000) | Acc: (98.00%) (21647/21888)
Epoch: 233 | Batch_idx: 180 |  Loss: (0.0363) |  Loss2: (0.0000) | Acc: (98.00%) (22914/23168)
Epoch: 233 | Batch_idx: 190 |  Loss: (0.0366) |  Loss2: (0.0000) | Acc: (98.00%) (24181/24448)
Epoch: 233 | Batch_idx: 200 |  Loss: (0.0367) |  Loss2: (0.0000) | Acc: (98.00%) (25444/25728)
Epoch: 233 | Batch_idx: 210 |  Loss: (0.0368) |  Loss2: (0.0000) | Acc: (98.00%) (26712/27008)
Epoch: 233 | Batch_idx: 220 |  Loss: (0.0368) |  Loss2: (0.0000) | Acc: (98.00%) (27976/28288)
Epoch: 233 | Batch_idx: 230 |  Loss: (0.0369) |  Loss2: (0.0000) | Acc: (98.00%) (29237/29568)
Epoch: 233 | Batch_idx: 240 |  Loss: (0.0366) |  Loss2: (0.0000) | Acc: (98.00%) (30504/30848)
Epoch: 233 | Batch_idx: 250 |  Loss: (0.0371) |  Loss2: (0.0000) | Acc: (98.00%) (31763/32128)
Epoch: 233 | Batch_idx: 260 |  Loss: (0.0369) |  Loss2: (0.0000) | Acc: (98.00%) (33029/33408)
Epoch: 233 | Batch_idx: 270 |  Loss: (0.0374) |  Loss2: (0.0000) | Acc: (98.00%) (34286/34688)
Epoch: 233 | Batch_idx: 280 |  Loss: (0.0374) |  Loss2: (0.0000) | Acc: (98.00%) (35552/35968)
Epoch: 233 | Batch_idx: 290 |  Loss: (0.0378) |  Loss2: (0.0000) | Acc: (98.00%) (36808/37248)
Epoch: 233 | Batch_idx: 300 |  Loss: (0.0379) |  Loss2: (0.0000) | Acc: (98.00%) (38073/38528)
Epoch: 233 | Batch_idx: 310 |  Loss: (0.0378) |  Loss2: (0.0000) | Acc: (98.00%) (39341/39808)
Epoch: 233 | Batch_idx: 320 |  Loss: (0.0376) |  Loss2: (0.0000) | Acc: (98.00%) (40611/41088)
Epoch: 233 | Batch_idx: 330 |  Loss: (0.0374) |  Loss2: (0.0000) | Acc: (98.00%) (41882/42368)
Epoch: 233 | Batch_idx: 340 |  Loss: (0.0373) |  Loss2: (0.0000) | Acc: (98.00%) (43150/43648)
Epoch: 233 | Batch_idx: 350 |  Loss: (0.0373) |  Loss2: (0.0000) | Acc: (98.00%) (44413/44928)
Epoch: 233 | Batch_idx: 360 |  Loss: (0.0375) |  Loss2: (0.0000) | Acc: (98.00%) (45675/46208)
Epoch: 233 | Batch_idx: 370 |  Loss: (0.0376) |  Loss2: (0.0000) | Acc: (98.00%) (46938/47488)
Epoch: 233 | Batch_idx: 380 |  Loss: (0.0381) |  Loss2: (0.0000) | Acc: (98.00%) (48195/48768)
Epoch: 233 | Batch_idx: 390 |  Loss: (0.0382) |  Loss2: (0.0000) | Acc: (98.00%) (49410/50000)
# TEST : Loss: (0.4424) | Acc: (89.00%) (8935/10000)
percent tensor([0.5851, 0.5991, 0.5894, 0.5852, 0.5950, 0.5994, 0.6006, 0.5843, 0.5848,
        0.5930, 0.5925, 0.5978, 0.5883, 0.5825, 0.6023, 0.5897],
       device='cuda:0') torch.Size([16])
percent tensor([0.5368, 0.5386, 0.5268, 0.5328, 0.5272, 0.5416, 0.5339, 0.5275, 0.5290,
        0.5350, 0.5399, 0.5296, 0.5352, 0.5357, 0.5396, 0.5381],
       device='cuda:0') torch.Size([16])
percent tensor([0.6047, 0.4790, 0.7378, 0.7411, 0.7501, 0.7050, 0.5806, 0.7140, 0.6543,
        0.5561, 0.5149, 0.6594, 0.5072, 0.5704, 0.5493, 0.6534],
       device='cuda:0') torch.Size([16])
percent tensor([0.7315, 0.7665, 0.6591, 0.6805, 0.6697, 0.5898, 0.7376, 0.6821, 0.7399,
        0.7663, 0.7749, 0.7311, 0.7522, 0.7741, 0.7094, 0.7055],
       device='cuda:0') torch.Size([16])
percent tensor([0.7531, 0.6442, 0.7893, 0.7847, 0.7991, 0.8652, 0.7444, 0.7609, 0.7158,
        0.6191, 0.6087, 0.6347, 0.5977, 0.6969, 0.7438, 0.8002],
       device='cuda:0') torch.Size([16])
percent tensor([0.6752, 0.7822, 0.7728, 0.8239, 0.7707, 0.8362, 0.7630, 0.5442, 0.7860,
        0.7619, 0.8119, 0.8013, 0.7798, 0.7887, 0.5831, 0.6194],
       device='cuda:0') torch.Size([16])
percent tensor([0.4545, 0.7054, 0.6263, 0.6693, 0.5817, 0.6768, 0.6677, 0.5805, 0.6918,
        0.6630, 0.7680, 0.6911, 0.6853, 0.6068, 0.5438, 0.4167],
       device='cuda:0') torch.Size([16])
percent tensor([0.9998, 0.9999, 0.9998, 0.9999, 1.0000, 0.9995, 0.9999, 0.9997, 0.9999,
        0.9999, 0.9999, 0.9999, 0.9998, 0.9997, 0.9998, 0.9995],
       device='cuda:0') torch.Size([16])
Epoch: 234 | Batch_idx: 0 |  Loss: (0.0357) |  Loss2: (0.0000) | Acc: (98.00%) (126/128)
Epoch: 234 | Batch_idx: 10 |  Loss: (0.0326) |  Loss2: (0.0000) | Acc: (99.00%) (1394/1408)
Epoch: 234 | Batch_idx: 20 |  Loss: (0.0340) |  Loss2: (0.0000) | Acc: (98.00%) (2658/2688)
Epoch: 234 | Batch_idx: 30 |  Loss: (0.0337) |  Loss2: (0.0000) | Acc: (98.00%) (3924/3968)
Epoch: 234 | Batch_idx: 40 |  Loss: (0.0328) |  Loss2: (0.0000) | Acc: (98.00%) (5190/5248)
Epoch: 234 | Batch_idx: 50 |  Loss: (0.0352) |  Loss2: (0.0000) | Acc: (98.00%) (6448/6528)
Epoch: 234 | Batch_idx: 60 |  Loss: (0.0338) |  Loss2: (0.0000) | Acc: (98.00%) (7722/7808)
Epoch: 234 | Batch_idx: 70 |  Loss: (0.0350) |  Loss2: (0.0000) | Acc: (98.00%) (8984/9088)
Epoch: 234 | Batch_idx: 80 |  Loss: (0.0360) |  Loss2: (0.0000) | Acc: (98.00%) (10245/10368)
Epoch: 234 | Batch_idx: 90 |  Loss: (0.0359) |  Loss2: (0.0000) | Acc: (98.00%) (11507/11648)
Epoch: 234 | Batch_idx: 100 |  Loss: (0.0355) |  Loss2: (0.0000) | Acc: (98.00%) (12776/12928)
Epoch: 234 | Batch_idx: 110 |  Loss: (0.0353) |  Loss2: (0.0000) | Acc: (98.00%) (14039/14208)
Epoch: 234 | Batch_idx: 120 |  Loss: (0.0360) |  Loss2: (0.0000) | Acc: (98.00%) (15301/15488)
Epoch: 234 | Batch_idx: 130 |  Loss: (0.0357) |  Loss2: (0.0000) | Acc: (98.00%) (16565/16768)
Epoch: 234 | Batch_idx: 140 |  Loss: (0.0365) |  Loss2: (0.0000) | Acc: (98.00%) (17823/18048)
Epoch: 234 | Batch_idx: 150 |  Loss: (0.0358) |  Loss2: (0.0000) | Acc: (98.00%) (19095/19328)
Epoch: 234 | Batch_idx: 160 |  Loss: (0.0359) |  Loss2: (0.0000) | Acc: (98.00%) (20364/20608)
Epoch: 234 | Batch_idx: 170 |  Loss: (0.0363) |  Loss2: (0.0000) | Acc: (98.00%) (21629/21888)
Epoch: 234 | Batch_idx: 180 |  Loss: (0.0363) |  Loss2: (0.0000) | Acc: (98.00%) (22890/23168)
Epoch: 234 | Batch_idx: 190 |  Loss: (0.0359) |  Loss2: (0.0000) | Acc: (98.00%) (24163/24448)
Epoch: 234 | Batch_idx: 200 |  Loss: (0.0363) |  Loss2: (0.0000) | Acc: (98.00%) (25425/25728)
Epoch: 234 | Batch_idx: 210 |  Loss: (0.0363) |  Loss2: (0.0000) | Acc: (98.00%) (26694/27008)
Epoch: 234 | Batch_idx: 220 |  Loss: (0.0360) |  Loss2: (0.0000) | Acc: (98.00%) (27964/28288)
Epoch: 234 | Batch_idx: 230 |  Loss: (0.0357) |  Loss2: (0.0000) | Acc: (98.00%) (29234/29568)
Epoch: 234 | Batch_idx: 240 |  Loss: (0.0352) |  Loss2: (0.0000) | Acc: (98.00%) (30506/30848)
Epoch: 234 | Batch_idx: 250 |  Loss: (0.0355) |  Loss2: (0.0000) | Acc: (98.00%) (31765/32128)
Epoch: 234 | Batch_idx: 260 |  Loss: (0.0355) |  Loss2: (0.0000) | Acc: (98.00%) (33029/33408)
Epoch: 234 | Batch_idx: 270 |  Loss: (0.0356) |  Loss2: (0.0000) | Acc: (98.00%) (34297/34688)
Epoch: 234 | Batch_idx: 280 |  Loss: (0.0359) |  Loss2: (0.0000) | Acc: (98.00%) (35561/35968)
Epoch: 234 | Batch_idx: 290 |  Loss: (0.0362) |  Loss2: (0.0000) | Acc: (98.00%) (36824/37248)
Epoch: 234 | Batch_idx: 300 |  Loss: (0.0362) |  Loss2: (0.0000) | Acc: (98.00%) (38091/38528)
Epoch: 234 | Batch_idx: 310 |  Loss: (0.0362) |  Loss2: (0.0000) | Acc: (98.00%) (39350/39808)
Epoch: 234 | Batch_idx: 320 |  Loss: (0.0361) |  Loss2: (0.0000) | Acc: (98.00%) (40616/41088)
Epoch: 234 | Batch_idx: 330 |  Loss: (0.0364) |  Loss2: (0.0000) | Acc: (98.00%) (41869/42368)
Epoch: 234 | Batch_idx: 340 |  Loss: (0.0367) |  Loss2: (0.0000) | Acc: (98.00%) (43132/43648)
Epoch: 234 | Batch_idx: 350 |  Loss: (0.0366) |  Loss2: (0.0000) | Acc: (98.00%) (44401/44928)
Epoch: 234 | Batch_idx: 360 |  Loss: (0.0366) |  Loss2: (0.0000) | Acc: (98.00%) (45664/46208)
Epoch: 234 | Batch_idx: 370 |  Loss: (0.0367) |  Loss2: (0.0000) | Acc: (98.00%) (46928/47488)
Epoch: 234 | Batch_idx: 380 |  Loss: (0.0364) |  Loss2: (0.0000) | Acc: (98.00%) (48196/48768)
Epoch: 234 | Batch_idx: 390 |  Loss: (0.0364) |  Loss2: (0.0000) | Acc: (98.00%) (49414/50000)
# TEST : Loss: (0.4519) | Acc: (89.00%) (8904/10000)
percent tensor([0.5850, 0.5986, 0.5890, 0.5846, 0.5949, 0.5990, 0.5994, 0.5840, 0.5842,
        0.5922, 0.5917, 0.5969, 0.5879, 0.5819, 0.6020, 0.5891],
       device='cuda:0') torch.Size([16])
percent tensor([0.5369, 0.5390, 0.5261, 0.5330, 0.5266, 0.5413, 0.5340, 0.5280, 0.5292,
        0.5348, 0.5400, 0.5289, 0.5352, 0.5362, 0.5395, 0.5382],
       device='cuda:0') torch.Size([16])
percent tensor([0.6024, 0.4792, 0.7396, 0.7443, 0.7569, 0.6998, 0.5893, 0.7164, 0.6616,
        0.5615, 0.5140, 0.6663, 0.4998, 0.5699, 0.5490, 0.6546],
       device='cuda:0') torch.Size([16])
percent tensor([0.7279, 0.7658, 0.6579, 0.6827, 0.6629, 0.5998, 0.7302, 0.6842, 0.7386,
        0.7602, 0.7729, 0.7261, 0.7467, 0.7732, 0.7116, 0.7064],
       device='cuda:0') torch.Size([16])
percent tensor([0.7600, 0.6677, 0.7774, 0.7811, 0.7938, 0.8565, 0.7641, 0.7675, 0.7205,
        0.6404, 0.6232, 0.6456, 0.6110, 0.7258, 0.7507, 0.8093],
       device='cuda:0') torch.Size([16])
percent tensor([0.6765, 0.7800, 0.7606, 0.8058, 0.7678, 0.8456, 0.7575, 0.5507, 0.7749,
        0.7633, 0.8177, 0.7935, 0.7935, 0.7991, 0.5748, 0.5897],
       device='cuda:0') torch.Size([16])
percent tensor([0.4397, 0.7190, 0.6434, 0.6531, 0.6029, 0.6728, 0.6831, 0.5915, 0.6745,
        0.6736, 0.7695, 0.6655, 0.6707, 0.6297, 0.5345, 0.4027],
       device='cuda:0') torch.Size([16])
percent tensor([0.9999, 0.9999, 0.9998, 0.9999, 1.0000, 0.9996, 0.9999, 0.9997, 0.9999,
        0.9999, 0.9999, 1.0000, 0.9998, 0.9996, 0.9998, 0.9994],
       device='cuda:0') torch.Size([16])
Epoch: 235 | Batch_idx: 0 |  Loss: (0.0161) |  Loss2: (0.0000) | Acc: (100.00%) (128/128)
Epoch: 235 | Batch_idx: 10 |  Loss: (0.0321) |  Loss2: (0.0000) | Acc: (98.00%) (1392/1408)
Epoch: 235 | Batch_idx: 20 |  Loss: (0.0340) |  Loss2: (0.0000) | Acc: (98.00%) (2661/2688)
Epoch: 235 | Batch_idx: 30 |  Loss: (0.0347) |  Loss2: (0.0000) | Acc: (98.00%) (3925/3968)
Epoch: 235 | Batch_idx: 40 |  Loss: (0.0375) |  Loss2: (0.0000) | Acc: (98.00%) (5183/5248)
Epoch: 235 | Batch_idx: 50 |  Loss: (0.0355) |  Loss2: (0.0000) | Acc: (98.00%) (6452/6528)
Epoch: 235 | Batch_idx: 60 |  Loss: (0.0344) |  Loss2: (0.0000) | Acc: (98.00%) (7718/7808)
Epoch: 235 | Batch_idx: 70 |  Loss: (0.0350) |  Loss2: (0.0000) | Acc: (98.00%) (8981/9088)
Epoch: 235 | Batch_idx: 80 |  Loss: (0.0365) |  Loss2: (0.0000) | Acc: (98.00%) (10237/10368)
Epoch: 235 | Batch_idx: 90 |  Loss: (0.0368) |  Loss2: (0.0000) | Acc: (98.00%) (11500/11648)
Epoch: 235 | Batch_idx: 100 |  Loss: (0.0358) |  Loss2: (0.0000) | Acc: (98.00%) (12768/12928)
Epoch: 235 | Batch_idx: 110 |  Loss: (0.0358) |  Loss2: (0.0000) | Acc: (98.00%) (14036/14208)
Epoch: 235 | Batch_idx: 120 |  Loss: (0.0357) |  Loss2: (0.0000) | Acc: (98.00%) (15303/15488)
Epoch: 235 | Batch_idx: 130 |  Loss: (0.0352) |  Loss2: (0.0000) | Acc: (98.00%) (16574/16768)
Epoch: 235 | Batch_idx: 140 |  Loss: (0.0348) |  Loss2: (0.0000) | Acc: (98.00%) (17845/18048)
Epoch: 235 | Batch_idx: 150 |  Loss: (0.0345) |  Loss2: (0.0000) | Acc: (98.00%) (19114/19328)
Epoch: 235 | Batch_idx: 160 |  Loss: (0.0344) |  Loss2: (0.0000) | Acc: (98.00%) (20381/20608)
Epoch: 235 | Batch_idx: 170 |  Loss: (0.0345) |  Loss2: (0.0000) | Acc: (98.00%) (21643/21888)
Epoch: 235 | Batch_idx: 180 |  Loss: (0.0346) |  Loss2: (0.0000) | Acc: (98.00%) (22913/23168)
Epoch: 235 | Batch_idx: 190 |  Loss: (0.0346) |  Loss2: (0.0000) | Acc: (98.00%) (24179/24448)
Epoch: 235 | Batch_idx: 200 |  Loss: (0.0343) |  Loss2: (0.0000) | Acc: (98.00%) (25449/25728)
Epoch: 235 | Batch_idx: 210 |  Loss: (0.0344) |  Loss2: (0.0000) | Acc: (98.00%) (26714/27008)
Epoch: 235 | Batch_idx: 220 |  Loss: (0.0346) |  Loss2: (0.0000) | Acc: (98.00%) (27981/28288)
Epoch: 235 | Batch_idx: 230 |  Loss: (0.0345) |  Loss2: (0.0000) | Acc: (98.00%) (29245/29568)
Epoch: 235 | Batch_idx: 240 |  Loss: (0.0347) |  Loss2: (0.0000) | Acc: (98.00%) (30509/30848)
Epoch: 235 | Batch_idx: 250 |  Loss: (0.0346) |  Loss2: (0.0000) | Acc: (98.00%) (31775/32128)
Epoch: 235 | Batch_idx: 260 |  Loss: (0.0345) |  Loss2: (0.0000) | Acc: (98.00%) (33040/33408)
Epoch: 235 | Batch_idx: 270 |  Loss: (0.0345) |  Loss2: (0.0000) | Acc: (98.00%) (34306/34688)
Epoch: 235 | Batch_idx: 280 |  Loss: (0.0352) |  Loss2: (0.0000) | Acc: (98.00%) (35564/35968)
Epoch: 235 | Batch_idx: 290 |  Loss: (0.0354) |  Loss2: (0.0000) | Acc: (98.00%) (36827/37248)
Epoch: 235 | Batch_idx: 300 |  Loss: (0.0353) |  Loss2: (0.0000) | Acc: (98.00%) (38094/38528)
Epoch: 235 | Batch_idx: 310 |  Loss: (0.0356) |  Loss2: (0.0000) | Acc: (98.00%) (39358/39808)
Epoch: 235 | Batch_idx: 320 |  Loss: (0.0358) |  Loss2: (0.0000) | Acc: (98.00%) (40621/41088)
Epoch: 235 | Batch_idx: 330 |  Loss: (0.0361) |  Loss2: (0.0000) | Acc: (98.00%) (41880/42368)
Epoch: 235 | Batch_idx: 340 |  Loss: (0.0361) |  Loss2: (0.0000) | Acc: (98.00%) (43142/43648)
Epoch: 235 | Batch_idx: 350 |  Loss: (0.0363) |  Loss2: (0.0000) | Acc: (98.00%) (44405/44928)
Epoch: 235 | Batch_idx: 360 |  Loss: (0.0364) |  Loss2: (0.0000) | Acc: (98.00%) (45667/46208)
Epoch: 235 | Batch_idx: 370 |  Loss: (0.0365) |  Loss2: (0.0000) | Acc: (98.00%) (46925/47488)
Epoch: 235 | Batch_idx: 380 |  Loss: (0.0367) |  Loss2: (0.0000) | Acc: (98.00%) (48182/48768)
Epoch: 235 | Batch_idx: 390 |  Loss: (0.0367) |  Loss2: (0.0000) | Acc: (98.00%) (49401/50000)
=> saving checkpoint 'drive/app/torch/save_Schedule/checkpoint_235.pth.tar'
# TEST : Loss: (0.4866) | Acc: (88.00%) (8826/10000)
percent tensor([0.5866, 0.6013, 0.5914, 0.5877, 0.5965, 0.6014, 0.6018, 0.5866, 0.5856,
        0.5947, 0.5931, 0.5993, 0.5896, 0.5843, 0.6046, 0.5911],
       device='cuda:0') torch.Size([16])
percent tensor([0.5375, 0.5394, 0.5271, 0.5334, 0.5277, 0.5411, 0.5344, 0.5283, 0.5298,
        0.5354, 0.5405, 0.5297, 0.5358, 0.5365, 0.5397, 0.5386],
       device='cuda:0') torch.Size([16])
percent tensor([0.6145, 0.4768, 0.7413, 0.7429, 0.7517, 0.7023, 0.5853, 0.7131, 0.6637,
        0.5565, 0.5140, 0.6630, 0.5064, 0.5746, 0.5426, 0.6569],
       device='cuda:0') torch.Size([16])
percent tensor([0.7288, 0.7660, 0.6561, 0.6812, 0.6662, 0.5948, 0.7351, 0.6818, 0.7342,
        0.7665, 0.7735, 0.7299, 0.7458, 0.7724, 0.7089, 0.7047],
       device='cuda:0') torch.Size([16])
percent tensor([0.7648, 0.6713, 0.7848, 0.7752, 0.8004, 0.8651, 0.7619, 0.7657, 0.7156,
        0.6343, 0.6190, 0.6540, 0.6143, 0.7041, 0.7572, 0.8099],
       device='cuda:0') torch.Size([16])
percent tensor([0.6356, 0.7879, 0.7733, 0.7972, 0.7663, 0.8330, 0.7662, 0.5493, 0.7537,
        0.7617, 0.8110, 0.7906, 0.7833, 0.7914, 0.5831, 0.5909],
       device='cuda:0') torch.Size([16])
percent tensor([0.4313, 0.6836, 0.6331, 0.6561, 0.5888, 0.6475, 0.6744, 0.5911, 0.6469,
        0.6438, 0.7496, 0.6466, 0.6451, 0.5855, 0.5233, 0.4071],
       device='cuda:0') torch.Size([16])
percent tensor([0.9999, 0.9999, 0.9998, 0.9999, 0.9999, 0.9997, 0.9999, 0.9997, 0.9998,
        0.9999, 0.9999, 0.9999, 0.9998, 0.9998, 0.9998, 0.9993],
       device='cuda:0') torch.Size([16])
Epoch: 236 | Batch_idx: 0 |  Loss: (0.0388) |  Loss2: (0.0000) | Acc: (99.00%) (127/128)
Epoch: 236 | Batch_idx: 10 |  Loss: (0.0464) |  Loss2: (0.0000) | Acc: (98.00%) (1387/1408)
Epoch: 236 | Batch_idx: 20 |  Loss: (0.0385) |  Loss2: (0.0000) | Acc: (98.00%) (2657/2688)
Epoch: 236 | Batch_idx: 30 |  Loss: (0.0362) |  Loss2: (0.0000) | Acc: (98.00%) (3926/3968)
Epoch: 236 | Batch_idx: 40 |  Loss: (0.0375) |  Loss2: (0.0000) | Acc: (98.00%) (5192/5248)
Epoch: 236 | Batch_idx: 50 |  Loss: (0.0361) |  Loss2: (0.0000) | Acc: (99.00%) (6463/6528)
Epoch: 236 | Batch_idx: 60 |  Loss: (0.0356) |  Loss2: (0.0000) | Acc: (99.00%) (7731/7808)
Epoch: 236 | Batch_idx: 70 |  Loss: (0.0353) |  Loss2: (0.0000) | Acc: (98.00%) (8996/9088)
Epoch: 236 | Batch_idx: 80 |  Loss: (0.0350) |  Loss2: (0.0000) | Acc: (98.00%) (10262/10368)
Epoch: 236 | Batch_idx: 90 |  Loss: (0.0351) |  Loss2: (0.0000) | Acc: (98.00%) (11529/11648)
Epoch: 236 | Batch_idx: 100 |  Loss: (0.0351) |  Loss2: (0.0000) | Acc: (98.00%) (12793/12928)
Epoch: 236 | Batch_idx: 110 |  Loss: (0.0347) |  Loss2: (0.0000) | Acc: (98.00%) (14060/14208)
Epoch: 236 | Batch_idx: 120 |  Loss: (0.0344) |  Loss2: (0.0000) | Acc: (98.00%) (15330/15488)
Epoch: 236 | Batch_idx: 130 |  Loss: (0.0345) |  Loss2: (0.0000) | Acc: (98.00%) (16596/16768)
Epoch: 236 | Batch_idx: 140 |  Loss: (0.0337) |  Loss2: (0.0000) | Acc: (98.00%) (17865/18048)
Epoch: 236 | Batch_idx: 150 |  Loss: (0.0336) |  Loss2: (0.0000) | Acc: (98.00%) (19130/19328)
Epoch: 236 | Batch_idx: 160 |  Loss: (0.0334) |  Loss2: (0.0000) | Acc: (98.00%) (20398/20608)
Epoch: 236 | Batch_idx: 170 |  Loss: (0.0342) |  Loss2: (0.0000) | Acc: (98.00%) (21657/21888)
Epoch: 236 | Batch_idx: 180 |  Loss: (0.0340) |  Loss2: (0.0000) | Acc: (98.00%) (22928/23168)
Epoch: 236 | Batch_idx: 190 |  Loss: (0.0340) |  Loss2: (0.0000) | Acc: (98.00%) (24194/24448)
Epoch: 236 | Batch_idx: 200 |  Loss: (0.0342) |  Loss2: (0.0000) | Acc: (98.00%) (25456/25728)
Epoch: 236 | Batch_idx: 210 |  Loss: (0.0344) |  Loss2: (0.0000) | Acc: (98.00%) (26722/27008)
Epoch: 236 | Batch_idx: 220 |  Loss: (0.0344) |  Loss2: (0.0000) | Acc: (98.00%) (27991/28288)
Epoch: 236 | Batch_idx: 230 |  Loss: (0.0341) |  Loss2: (0.0000) | Acc: (98.00%) (29262/29568)
Epoch: 236 | Batch_idx: 240 |  Loss: (0.0338) |  Loss2: (0.0000) | Acc: (98.00%) (30531/30848)
Epoch: 236 | Batch_idx: 250 |  Loss: (0.0337) |  Loss2: (0.0000) | Acc: (98.00%) (31801/32128)
Epoch: 236 | Batch_idx: 260 |  Loss: (0.0337) |  Loss2: (0.0000) | Acc: (98.00%) (33066/33408)
Epoch: 236 | Batch_idx: 270 |  Loss: (0.0337) |  Loss2: (0.0000) | Acc: (98.00%) (34332/34688)
Epoch: 236 | Batch_idx: 280 |  Loss: (0.0340) |  Loss2: (0.0000) | Acc: (98.00%) (35592/35968)
Epoch: 236 | Batch_idx: 290 |  Loss: (0.0338) |  Loss2: (0.0000) | Acc: (98.00%) (36859/37248)
Epoch: 236 | Batch_idx: 300 |  Loss: (0.0337) |  Loss2: (0.0000) | Acc: (98.00%) (38127/38528)
Epoch: 236 | Batch_idx: 310 |  Loss: (0.0333) |  Loss2: (0.0000) | Acc: (98.00%) (39397/39808)
Epoch: 236 | Batch_idx: 320 |  Loss: (0.0333) |  Loss2: (0.0000) | Acc: (98.00%) (40665/41088)
Epoch: 236 | Batch_idx: 330 |  Loss: (0.0333) |  Loss2: (0.0000) | Acc: (98.00%) (41933/42368)
Epoch: 236 | Batch_idx: 340 |  Loss: (0.0331) |  Loss2: (0.0000) | Acc: (98.00%) (43206/43648)
Epoch: 236 | Batch_idx: 350 |  Loss: (0.0333) |  Loss2: (0.0000) | Acc: (98.00%) (44468/44928)
Epoch: 236 | Batch_idx: 360 |  Loss: (0.0335) |  Loss2: (0.0000) | Acc: (98.00%) (45731/46208)
Epoch: 236 | Batch_idx: 370 |  Loss: (0.0333) |  Loss2: (0.0000) | Acc: (98.00%) (47001/47488)
Epoch: 236 | Batch_idx: 380 |  Loss: (0.0333) |  Loss2: (0.0000) | Acc: (98.00%) (48268/48768)
Epoch: 236 | Batch_idx: 390 |  Loss: (0.0333) |  Loss2: (0.0000) | Acc: (98.00%) (49486/50000)
# TEST : Loss: (0.4408) | Acc: (89.00%) (8952/10000)
percent tensor([0.5856, 0.6003, 0.5889, 0.5857, 0.5947, 0.5998, 0.6007, 0.5850, 0.5852,
        0.5930, 0.5926, 0.5978, 0.5888, 0.5838, 0.6033, 0.5898],
       device='cuda:0') torch.Size([16])
percent tensor([0.5367, 0.5383, 0.5268, 0.5330, 0.5279, 0.5403, 0.5337, 0.5269, 0.5288,
        0.5347, 0.5392, 0.5294, 0.5351, 0.5354, 0.5385, 0.5379],
       device='cuda:0') torch.Size([16])
percent tensor([0.5956, 0.4787, 0.7280, 0.7379, 0.7425, 0.6872, 0.5815, 0.7052, 0.6463,
        0.5528, 0.5095, 0.6456, 0.4919, 0.5712, 0.5382, 0.6423],
       device='cuda:0') torch.Size([16])
percent tensor([0.7363, 0.7748, 0.6637, 0.6969, 0.6721, 0.6084, 0.7397, 0.6906, 0.7419,
        0.7748, 0.7799, 0.7355, 0.7551, 0.7792, 0.7159, 0.7155],
       device='cuda:0') torch.Size([16])
percent tensor([0.7611, 0.6435, 0.7853, 0.7732, 0.7996, 0.8579, 0.7473, 0.7691, 0.7159,
        0.6246, 0.6041, 0.6493, 0.6013, 0.6994, 0.7471, 0.8014],
       device='cuda:0') torch.Size([16])
percent tensor([0.6570, 0.7734, 0.7811, 0.8048, 0.7690, 0.8359, 0.7645, 0.5487, 0.7682,
        0.7512, 0.8003, 0.7823, 0.7696, 0.7980, 0.5824, 0.5727],
       device='cuda:0') torch.Size([16])
percent tensor([0.4422, 0.7311, 0.6217, 0.6484, 0.5660, 0.6463, 0.6873, 0.5695, 0.6838,
        0.6708, 0.7757, 0.6567, 0.6459, 0.6349, 0.5571, 0.4173],
       device='cuda:0') torch.Size([16])
percent tensor([0.9999, 0.9998, 0.9999, 1.0000, 1.0000, 0.9998, 0.9999, 0.9997, 0.9999,
        0.9999, 0.9999, 1.0000, 0.9997, 0.9996, 0.9998, 0.9994],
       device='cuda:0') torch.Size([16])
Epoch: 237 | Batch_idx: 0 |  Loss: (0.0397) |  Loss2: (0.0000) | Acc: (99.00%) (127/128)
Epoch: 237 | Batch_idx: 10 |  Loss: (0.0312) |  Loss2: (0.0000) | Acc: (99.00%) (1394/1408)
Epoch: 237 | Batch_idx: 20 |  Loss: (0.0306) |  Loss2: (0.0000) | Acc: (99.00%) (2662/2688)
Epoch: 237 | Batch_idx: 30 |  Loss: (0.0304) |  Loss2: (0.0000) | Acc: (99.00%) (3933/3968)
Epoch: 237 | Batch_idx: 40 |  Loss: (0.0290) |  Loss2: (0.0000) | Acc: (99.00%) (5207/5248)
Epoch: 237 | Batch_idx: 50 |  Loss: (0.0307) |  Loss2: (0.0000) | Acc: (99.00%) (6471/6528)
Epoch: 237 | Batch_idx: 60 |  Loss: (0.0296) |  Loss2: (0.0000) | Acc: (99.00%) (7740/7808)
Epoch: 237 | Batch_idx: 70 |  Loss: (0.0308) |  Loss2: (0.0000) | Acc: (99.00%) (9006/9088)
Epoch: 237 | Batch_idx: 80 |  Loss: (0.0323) |  Loss2: (0.0000) | Acc: (99.00%) (10265/10368)
Epoch: 237 | Batch_idx: 90 |  Loss: (0.0328) |  Loss2: (0.0000) | Acc: (98.00%) (11531/11648)
Epoch: 237 | Batch_idx: 100 |  Loss: (0.0336) |  Loss2: (0.0000) | Acc: (98.00%) (12795/12928)
Epoch: 237 | Batch_idx: 110 |  Loss: (0.0339) |  Loss2: (0.0000) | Acc: (98.00%) (14062/14208)
Epoch: 237 | Batch_idx: 120 |  Loss: (0.0341) |  Loss2: (0.0000) | Acc: (98.00%) (15326/15488)
Epoch: 237 | Batch_idx: 130 |  Loss: (0.0338) |  Loss2: (0.0000) | Acc: (98.00%) (16592/16768)
Epoch: 237 | Batch_idx: 140 |  Loss: (0.0340) |  Loss2: (0.0000) | Acc: (98.00%) (17858/18048)
Epoch: 237 | Batch_idx: 150 |  Loss: (0.0336) |  Loss2: (0.0000) | Acc: (98.00%) (19127/19328)
Epoch: 237 | Batch_idx: 160 |  Loss: (0.0339) |  Loss2: (0.0000) | Acc: (98.00%) (20391/20608)
Epoch: 237 | Batch_idx: 170 |  Loss: (0.0341) |  Loss2: (0.0000) | Acc: (98.00%) (21653/21888)
Epoch: 237 | Batch_idx: 180 |  Loss: (0.0337) |  Loss2: (0.0000) | Acc: (98.00%) (22922/23168)
Epoch: 237 | Batch_idx: 190 |  Loss: (0.0337) |  Loss2: (0.0000) | Acc: (98.00%) (24192/24448)
Epoch: 237 | Batch_idx: 200 |  Loss: (0.0337) |  Loss2: (0.0000) | Acc: (98.00%) (25458/25728)
Epoch: 237 | Batch_idx: 210 |  Loss: (0.0333) |  Loss2: (0.0000) | Acc: (98.00%) (26730/27008)
Epoch: 237 | Batch_idx: 220 |  Loss: (0.0331) |  Loss2: (0.0000) | Acc: (98.00%) (28000/28288)
Epoch: 237 | Batch_idx: 230 |  Loss: (0.0329) |  Loss2: (0.0000) | Acc: (98.00%) (29271/29568)
Epoch: 237 | Batch_idx: 240 |  Loss: (0.0330) |  Loss2: (0.0000) | Acc: (98.00%) (30534/30848)
Epoch: 237 | Batch_idx: 250 |  Loss: (0.0330) |  Loss2: (0.0000) | Acc: (98.00%) (31800/32128)
Epoch: 237 | Batch_idx: 260 |  Loss: (0.0331) |  Loss2: (0.0000) | Acc: (98.00%) (33065/33408)
Epoch: 237 | Batch_idx: 270 |  Loss: (0.0331) |  Loss2: (0.0000) | Acc: (98.00%) (34328/34688)
Epoch: 237 | Batch_idx: 280 |  Loss: (0.0330) |  Loss2: (0.0000) | Acc: (98.00%) (35597/35968)
Epoch: 237 | Batch_idx: 290 |  Loss: (0.0330) |  Loss2: (0.0000) | Acc: (98.00%) (36867/37248)
Epoch: 237 | Batch_idx: 300 |  Loss: (0.0329) |  Loss2: (0.0000) | Acc: (98.00%) (38134/38528)
Epoch: 237 | Batch_idx: 310 |  Loss: (0.0332) |  Loss2: (0.0000) | Acc: (98.00%) (39402/39808)
Epoch: 237 | Batch_idx: 320 |  Loss: (0.0331) |  Loss2: (0.0000) | Acc: (98.00%) (40669/41088)
Epoch: 237 | Batch_idx: 330 |  Loss: (0.0331) |  Loss2: (0.0000) | Acc: (98.00%) (41938/42368)
Epoch: 237 | Batch_idx: 340 |  Loss: (0.0332) |  Loss2: (0.0000) | Acc: (98.00%) (43203/43648)
Epoch: 237 | Batch_idx: 350 |  Loss: (0.0330) |  Loss2: (0.0000) | Acc: (98.00%) (44474/44928)
Epoch: 237 | Batch_idx: 360 |  Loss: (0.0329) |  Loss2: (0.0000) | Acc: (98.00%) (45738/46208)
Epoch: 237 | Batch_idx: 370 |  Loss: (0.0327) |  Loss2: (0.0000) | Acc: (98.00%) (47012/47488)
Epoch: 237 | Batch_idx: 380 |  Loss: (0.0329) |  Loss2: (0.0000) | Acc: (98.00%) (48271/48768)
Epoch: 237 | Batch_idx: 390 |  Loss: (0.0330) |  Loss2: (0.0000) | Acc: (98.00%) (49489/50000)
# TEST : Loss: (0.4274) | Acc: (89.00%) (8963/10000)
percent tensor([0.5859, 0.6007, 0.5894, 0.5862, 0.5947, 0.5997, 0.6010, 0.5853, 0.5854,
        0.5937, 0.5931, 0.5979, 0.5890, 0.5843, 0.6034, 0.5902],
       device='cuda:0') torch.Size([16])
percent tensor([0.5370, 0.5388, 0.5265, 0.5331, 0.5274, 0.5406, 0.5338, 0.5276, 0.5293,
        0.5349, 0.5398, 0.5289, 0.5353, 0.5359, 0.5389, 0.5381],
       device='cuda:0') torch.Size([16])
percent tensor([0.6107, 0.4726, 0.7451, 0.7492, 0.7543, 0.7047, 0.5877, 0.7117, 0.6591,
        0.5601, 0.5183, 0.6695, 0.5100, 0.5753, 0.5472, 0.6519],
       device='cuda:0') torch.Size([16])
percent tensor([0.7348, 0.7719, 0.6673, 0.6935, 0.6712, 0.6045, 0.7364, 0.6916, 0.7414,
        0.7714, 0.7788, 0.7346, 0.7529, 0.7738, 0.7157, 0.7130],
       device='cuda:0') torch.Size([16])
percent tensor([0.7521, 0.6461, 0.7815, 0.7689, 0.7955, 0.8544, 0.7497, 0.7644, 0.7129,
        0.6221, 0.6081, 0.6473, 0.6062, 0.7013, 0.7423, 0.7985],
       device='cuda:0') torch.Size([16])
percent tensor([0.6477, 0.7781, 0.7639, 0.8126, 0.7624, 0.8356, 0.7481, 0.5260, 0.7696,
        0.7563, 0.8125, 0.7856, 0.7738, 0.7858, 0.5860, 0.5826],
       device='cuda:0') torch.Size([16])
percent tensor([0.4421, 0.7159, 0.6145, 0.6544, 0.5739, 0.6487, 0.6723, 0.5720, 0.6818,
        0.6733, 0.7833, 0.6543, 0.6120, 0.6417, 0.5541, 0.4118],
       device='cuda:0') torch.Size([16])
percent tensor([0.9999, 0.9999, 0.9999, 1.0000, 1.0000, 0.9997, 1.0000, 0.9997, 0.9999,
        0.9999, 0.9999, 1.0000, 0.9997, 0.9996, 0.9998, 0.9995],
       device='cuda:0') torch.Size([16])
Epoch: 238 | Batch_idx: 0 |  Loss: (0.0250) |  Loss2: (0.0000) | Acc: (100.00%) (128/128)
Epoch: 238 | Batch_idx: 10 |  Loss: (0.0283) |  Loss2: (0.0000) | Acc: (99.00%) (1398/1408)
Epoch: 238 | Batch_idx: 20 |  Loss: (0.0307) |  Loss2: (0.0000) | Acc: (99.00%) (2665/2688)
Epoch: 238 | Batch_idx: 30 |  Loss: (0.0296) |  Loss2: (0.0000) | Acc: (99.00%) (3935/3968)
Epoch: 238 | Batch_idx: 40 |  Loss: (0.0292) |  Loss2: (0.0000) | Acc: (99.00%) (5204/5248)
Epoch: 238 | Batch_idx: 50 |  Loss: (0.0301) |  Loss2: (0.0000) | Acc: (99.00%) (6468/6528)
Epoch: 238 | Batch_idx: 60 |  Loss: (0.0307) |  Loss2: (0.0000) | Acc: (99.00%) (7735/7808)
Epoch: 238 | Batch_idx: 70 |  Loss: (0.0300) |  Loss2: (0.0000) | Acc: (99.00%) (9005/9088)
Epoch: 238 | Batch_idx: 80 |  Loss: (0.0291) |  Loss2: (0.0000) | Acc: (99.00%) (10277/10368)
Epoch: 238 | Batch_idx: 90 |  Loss: (0.0294) |  Loss2: (0.0000) | Acc: (99.00%) (11547/11648)
Epoch: 238 | Batch_idx: 100 |  Loss: (0.0309) |  Loss2: (0.0000) | Acc: (99.00%) (12807/12928)
Epoch: 238 | Batch_idx: 110 |  Loss: (0.0310) |  Loss2: (0.0000) | Acc: (99.00%) (14074/14208)
Epoch: 238 | Batch_idx: 120 |  Loss: (0.0308) |  Loss2: (0.0000) | Acc: (99.00%) (15343/15488)
Epoch: 238 | Batch_idx: 130 |  Loss: (0.0307) |  Loss2: (0.0000) | Acc: (99.00%) (16612/16768)
Epoch: 238 | Batch_idx: 140 |  Loss: (0.0312) |  Loss2: (0.0000) | Acc: (99.00%) (17875/18048)
Epoch: 238 | Batch_idx: 150 |  Loss: (0.0308) |  Loss2: (0.0000) | Acc: (99.00%) (19147/19328)
Epoch: 238 | Batch_idx: 160 |  Loss: (0.0310) |  Loss2: (0.0000) | Acc: (99.00%) (20416/20608)
Epoch: 238 | Batch_idx: 170 |  Loss: (0.0307) |  Loss2: (0.0000) | Acc: (99.00%) (21685/21888)
Epoch: 238 | Batch_idx: 180 |  Loss: (0.0311) |  Loss2: (0.0000) | Acc: (99.00%) (22949/23168)
Epoch: 238 | Batch_idx: 190 |  Loss: (0.0310) |  Loss2: (0.0000) | Acc: (99.00%) (24222/24448)
Epoch: 238 | Batch_idx: 200 |  Loss: (0.0313) |  Loss2: (0.0000) | Acc: (99.00%) (25486/25728)
Epoch: 238 | Batch_idx: 210 |  Loss: (0.0310) |  Loss2: (0.0000) | Acc: (99.00%) (26757/27008)
Epoch: 238 | Batch_idx: 220 |  Loss: (0.0312) |  Loss2: (0.0000) | Acc: (99.00%) (28024/28288)
Epoch: 238 | Batch_idx: 230 |  Loss: (0.0307) |  Loss2: (0.0000) | Acc: (99.00%) (29298/29568)
Epoch: 238 | Batch_idx: 240 |  Loss: (0.0307) |  Loss2: (0.0000) | Acc: (99.00%) (30568/30848)
Epoch: 238 | Batch_idx: 250 |  Loss: (0.0307) |  Loss2: (0.0000) | Acc: (99.00%) (31834/32128)
Epoch: 238 | Batch_idx: 260 |  Loss: (0.0307) |  Loss2: (0.0000) | Acc: (99.00%) (33102/33408)
Epoch: 238 | Batch_idx: 270 |  Loss: (0.0308) |  Loss2: (0.0000) | Acc: (99.00%) (34369/34688)
Epoch: 238 | Batch_idx: 280 |  Loss: (0.0315) |  Loss2: (0.0000) | Acc: (99.00%) (35626/35968)
Epoch: 238 | Batch_idx: 290 |  Loss: (0.0317) |  Loss2: (0.0000) | Acc: (99.00%) (36887/37248)
Epoch: 238 | Batch_idx: 300 |  Loss: (0.0319) |  Loss2: (0.0000) | Acc: (99.00%) (38151/38528)
Epoch: 238 | Batch_idx: 310 |  Loss: (0.0319) |  Loss2: (0.0000) | Acc: (99.00%) (39420/39808)
Epoch: 238 | Batch_idx: 320 |  Loss: (0.0321) |  Loss2: (0.0000) | Acc: (99.00%) (40689/41088)
Epoch: 238 | Batch_idx: 330 |  Loss: (0.0323) |  Loss2: (0.0000) | Acc: (99.00%) (41950/42368)
Epoch: 238 | Batch_idx: 340 |  Loss: (0.0323) |  Loss2: (0.0000) | Acc: (99.00%) (43218/43648)
Epoch: 238 | Batch_idx: 350 |  Loss: (0.0323) |  Loss2: (0.0000) | Acc: (99.00%) (44488/44928)
Epoch: 238 | Batch_idx: 360 |  Loss: (0.0324) |  Loss2: (0.0000) | Acc: (99.00%) (45751/46208)
Epoch: 238 | Batch_idx: 370 |  Loss: (0.0324) |  Loss2: (0.0000) | Acc: (99.00%) (47019/47488)
Epoch: 238 | Batch_idx: 380 |  Loss: (0.0325) |  Loss2: (0.0000) | Acc: (98.00%) (48280/48768)
Epoch: 238 | Batch_idx: 390 |  Loss: (0.0329) |  Loss2: (0.0000) | Acc: (98.00%) (49494/50000)
# TEST : Loss: (0.4455) | Acc: (89.00%) (8958/10000)
percent tensor([0.5861, 0.6003, 0.5910, 0.5871, 0.5968, 0.6007, 0.6014, 0.5855, 0.5849,
        0.5938, 0.5926, 0.5992, 0.5886, 0.5825, 0.6039, 0.5902],
       device='cuda:0') torch.Size([16])
percent tensor([0.5380, 0.5394, 0.5275, 0.5340, 0.5271, 0.5418, 0.5347, 0.5284, 0.5301,
        0.5358, 0.5410, 0.5303, 0.5365, 0.5371, 0.5398, 0.5391],
       device='cuda:0') torch.Size([16])
percent tensor([0.6225, 0.4784, 0.7489, 0.7494, 0.7654, 0.7232, 0.6000, 0.7134, 0.6674,
        0.5635, 0.5286, 0.6740, 0.5180, 0.5733, 0.5643, 0.6609],
       device='cuda:0') torch.Size([16])
percent tensor([0.7290, 0.7660, 0.6639, 0.6927, 0.6665, 0.5969, 0.7342, 0.6867, 0.7394,
        0.7677, 0.7738, 0.7303, 0.7496, 0.7776, 0.7130, 0.7079],
       device='cuda:0') torch.Size([16])
percent tensor([0.7654, 0.6653, 0.7858, 0.7859, 0.7970, 0.8538, 0.7558, 0.7793, 0.7141,
        0.6278, 0.6281, 0.6701, 0.6156, 0.6981, 0.7520, 0.8082],
       device='cuda:0') torch.Size([16])
percent tensor([0.6901, 0.7988, 0.7767, 0.8455, 0.7867, 0.8508, 0.7401, 0.5595, 0.7847,
        0.7725, 0.8226, 0.7893, 0.7872, 0.7983, 0.5990, 0.6000],
       device='cuda:0') torch.Size([16])
percent tensor([0.4926, 0.7412, 0.6322, 0.6909, 0.5850, 0.6784, 0.6664, 0.5720, 0.6916,
        0.6915, 0.7993, 0.6769, 0.6655, 0.6558, 0.5576, 0.4119],
       device='cuda:0') torch.Size([16])
percent tensor([0.9999, 0.9999, 0.9998, 1.0000, 1.0000, 0.9998, 1.0000, 0.9997, 0.9998,
        0.9999, 0.9999, 0.9999, 0.9998, 0.9996, 0.9998, 0.9996],
       device='cuda:0') torch.Size([16])
Epoch: 239 | Batch_idx: 0 |  Loss: (0.0608) |  Loss2: (0.0000) | Acc: (96.00%) (124/128)
Epoch: 239 | Batch_idx: 10 |  Loss: (0.0418) |  Loss2: (0.0000) | Acc: (98.00%) (1383/1408)
Epoch: 239 | Batch_idx: 20 |  Loss: (0.0406) |  Loss2: (0.0000) | Acc: (98.00%) (2649/2688)
Epoch: 239 | Batch_idx: 30 |  Loss: (0.0392) |  Loss2: (0.0000) | Acc: (98.00%) (3917/3968)
Epoch: 239 | Batch_idx: 40 |  Loss: (0.0360) |  Loss2: (0.0000) | Acc: (98.00%) (5186/5248)
Epoch: 239 | Batch_idx: 50 |  Loss: (0.0342) |  Loss2: (0.0000) | Acc: (98.00%) (6456/6528)
Epoch: 239 | Batch_idx: 60 |  Loss: (0.0333) |  Loss2: (0.0000) | Acc: (98.00%) (7724/7808)
Epoch: 239 | Batch_idx: 70 |  Loss: (0.0337) |  Loss2: (0.0000) | Acc: (98.00%) (8986/9088)
Epoch: 239 | Batch_idx: 80 |  Loss: (0.0333) |  Loss2: (0.0000) | Acc: (98.00%) (10255/10368)
Epoch: 239 | Batch_idx: 90 |  Loss: (0.0331) |  Loss2: (0.0000) | Acc: (98.00%) (11521/11648)
Epoch: 239 | Batch_idx: 100 |  Loss: (0.0319) |  Loss2: (0.0000) | Acc: (98.00%) (12793/12928)
Epoch: 239 | Batch_idx: 110 |  Loss: (0.0324) |  Loss2: (0.0000) | Acc: (98.00%) (14057/14208)
Epoch: 239 | Batch_idx: 120 |  Loss: (0.0329) |  Loss2: (0.0000) | Acc: (98.00%) (15322/15488)
Epoch: 239 | Batch_idx: 130 |  Loss: (0.0330) |  Loss2: (0.0000) | Acc: (98.00%) (16586/16768)
Epoch: 239 | Batch_idx: 140 |  Loss: (0.0324) |  Loss2: (0.0000) | Acc: (98.00%) (17857/18048)
Epoch: 239 | Batch_idx: 150 |  Loss: (0.0322) |  Loss2: (0.0000) | Acc: (98.00%) (19128/19328)
Epoch: 239 | Batch_idx: 160 |  Loss: (0.0323) |  Loss2: (0.0000) | Acc: (98.00%) (20396/20608)
Epoch: 239 | Batch_idx: 170 |  Loss: (0.0326) |  Loss2: (0.0000) | Acc: (98.00%) (21660/21888)
Epoch: 239 | Batch_idx: 180 |  Loss: (0.0329) |  Loss2: (0.0000) | Acc: (98.00%) (22920/23168)
Epoch: 239 | Batch_idx: 190 |  Loss: (0.0330) |  Loss2: (0.0000) | Acc: (98.00%) (24188/24448)
Epoch: 239 | Batch_idx: 200 |  Loss: (0.0332) |  Loss2: (0.0000) | Acc: (98.00%) (25454/25728)
Epoch: 239 | Batch_idx: 210 |  Loss: (0.0333) |  Loss2: (0.0000) | Acc: (98.00%) (26719/27008)
Epoch: 239 | Batch_idx: 220 |  Loss: (0.0333) |  Loss2: (0.0000) | Acc: (98.00%) (27989/28288)
Epoch: 239 | Batch_idx: 230 |  Loss: (0.0330) |  Loss2: (0.0000) | Acc: (98.00%) (29257/29568)
Epoch: 239 | Batch_idx: 240 |  Loss: (0.0331) |  Loss2: (0.0000) | Acc: (98.00%) (30526/30848)
Epoch: 239 | Batch_idx: 250 |  Loss: (0.0331) |  Loss2: (0.0000) | Acc: (98.00%) (31794/32128)
Epoch: 239 | Batch_idx: 260 |  Loss: (0.0329) |  Loss2: (0.0000) | Acc: (98.00%) (33064/33408)
Epoch: 239 | Batch_idx: 270 |  Loss: (0.0330) |  Loss2: (0.0000) | Acc: (98.00%) (34330/34688)
Epoch: 239 | Batch_idx: 280 |  Loss: (0.0330) |  Loss2: (0.0000) | Acc: (98.00%) (35593/35968)
Epoch: 239 | Batch_idx: 290 |  Loss: (0.0330) |  Loss2: (0.0000) | Acc: (98.00%) (36858/37248)
Epoch: 239 | Batch_idx: 300 |  Loss: (0.0335) |  Loss2: (0.0000) | Acc: (98.00%) (38117/38528)
Epoch: 239 | Batch_idx: 310 |  Loss: (0.0337) |  Loss2: (0.0000) | Acc: (98.00%) (39378/39808)
Epoch: 239 | Batch_idx: 320 |  Loss: (0.0335) |  Loss2: (0.0000) | Acc: (98.00%) (40648/41088)
Epoch: 239 | Batch_idx: 330 |  Loss: (0.0341) |  Loss2: (0.0000) | Acc: (98.00%) (41907/42368)
Epoch: 239 | Batch_idx: 340 |  Loss: (0.0340) |  Loss2: (0.0000) | Acc: (98.00%) (43176/43648)
Epoch: 239 | Batch_idx: 350 |  Loss: (0.0340) |  Loss2: (0.0000) | Acc: (98.00%) (44442/44928)
Epoch: 239 | Batch_idx: 360 |  Loss: (0.0336) |  Loss2: (0.0000) | Acc: (98.00%) (45714/46208)
Epoch: 239 | Batch_idx: 370 |  Loss: (0.0334) |  Loss2: (0.0000) | Acc: (98.00%) (46984/47488)
Epoch: 239 | Batch_idx: 380 |  Loss: (0.0335) |  Loss2: (0.0000) | Acc: (98.00%) (48249/48768)
Epoch: 239 | Batch_idx: 390 |  Loss: (0.0337) |  Loss2: (0.0000) | Acc: (98.00%) (49464/50000)
# TEST : Loss: (0.4677) | Acc: (88.00%) (8884/10000)
percent tensor([0.5860, 0.5999, 0.5908, 0.5858, 0.5969, 0.5992, 0.6020, 0.5855, 0.5864,
        0.5939, 0.5932, 0.5999, 0.5894, 0.5835, 0.6029, 0.5900],
       device='cuda:0') torch.Size([16])
percent tensor([0.5382, 0.5389, 0.5283, 0.5345, 0.5293, 0.5435, 0.5343, 0.5289, 0.5298,
        0.5356, 0.5405, 0.5304, 0.5363, 0.5355, 0.5407, 0.5393],
       device='cuda:0') torch.Size([16])
percent tensor([0.6020, 0.4832, 0.7368, 0.7458, 0.7543, 0.6947, 0.5937, 0.7153, 0.6622,
        0.5626, 0.5246, 0.6622, 0.5101, 0.5773, 0.5451, 0.6539],
       device='cuda:0') torch.Size([16])
percent tensor([0.7323, 0.7741, 0.6594, 0.6844, 0.6653, 0.6037, 0.7366, 0.6893, 0.7406,
        0.7727, 0.7791, 0.7302, 0.7520, 0.7765, 0.7153, 0.7100],
       device='cuda:0') torch.Size([16])
percent tensor([0.7652, 0.6682, 0.7923, 0.7859, 0.8038, 0.8655, 0.7613, 0.7742, 0.7155,
        0.6353, 0.6223, 0.6529, 0.6089, 0.7257, 0.7607, 0.8078],
       device='cuda:0') torch.Size([16])
percent tensor([0.7091, 0.7916, 0.7851, 0.8239, 0.7759, 0.8580, 0.7780, 0.5713, 0.7894,
        0.7725, 0.8331, 0.8009, 0.8009, 0.8130, 0.6271, 0.6362],
       device='cuda:0') torch.Size([16])
percent tensor([0.4452, 0.6974, 0.6189, 0.6735, 0.5672, 0.6767, 0.6542, 0.5587, 0.6786,
        0.6505, 0.7871, 0.6416, 0.6540, 0.6237, 0.5371, 0.4106],
       device='cuda:0') torch.Size([16])
percent tensor([0.9999, 0.9999, 0.9998, 1.0000, 1.0000, 0.9996, 0.9999, 0.9997, 0.9998,
        0.9999, 0.9999, 1.0000, 0.9997, 0.9997, 0.9998, 0.9994],
       device='cuda:0') torch.Size([16])
Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 3, 3, 3]) tensor(188.3478, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(831.8541, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(847.7147, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([128, 64, 3, 3]) tensor(1510.0967, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([128, 64, 1, 1]) tensor(476.2476, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([128, 128, 3, 3]) tensor(2323.6436, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([256, 128, 3, 3]) tensor(4279.6626, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([256, 128, 1, 1]) tensor(1332.9606, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([256, 256, 3, 3]) tensor(6382.2651, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([512, 256, 3, 3]) tensor(11429.0312, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([512, 256, 1, 1]) tensor(3736.2510, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([512, 512, 3, 3]) tensor(15725.2246, device='cuda:0', grad_fn=<NormBackward0>)
6 hours 5 mins 33 secs for training