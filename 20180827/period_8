Files already downloaded and verified
USE 1 GPUs!
Epoch: 0 | Batch_idx: 0 |  Loss: (2.3130) |  Loss2: (0.0000) | Acc: (8.00%) (11/128)
Epoch: 0 | Batch_idx: 10 |  Loss: (2.3074) |  Loss2: (0.0000) | Acc: (10.00%) (153/1408)
Epoch: 0 | Batch_idx: 20 |  Loss: (2.3014) |  Loss2: (0.0000) | Acc: (11.00%) (316/2688)
Epoch: 0 | Batch_idx: 30 |  Loss: (2.2940) |  Loss2: (0.0000) | Acc: (12.00%) (494/3968)
Epoch: 0 | Batch_idx: 40 |  Loss: (2.2853) |  Loss2: (0.0000) | Acc: (13.00%) (691/5248)
Epoch: 0 | Batch_idx: 50 |  Loss: (2.2745) |  Loss2: (0.0000) | Acc: (14.00%) (927/6528)
Epoch: 0 | Batch_idx: 60 |  Loss: (2.2648) |  Loss2: (0.0000) | Acc: (15.00%) (1186/7808)
Epoch: 0 | Batch_idx: 70 |  Loss: (2.2560) |  Loss2: (0.0000) | Acc: (15.00%) (1433/9088)
Epoch: 0 | Batch_idx: 80 |  Loss: (2.2472) |  Loss2: (0.0000) | Acc: (16.00%) (1676/10368)
Epoch: 0 | Batch_idx: 90 |  Loss: (2.2387) |  Loss2: (0.0000) | Acc: (16.00%) (1934/11648)
Epoch: 0 | Batch_idx: 100 |  Loss: (2.2300) |  Loss2: (0.0000) | Acc: (17.00%) (2212/12928)
Epoch: 0 | Batch_idx: 110 |  Loss: (2.2205) |  Loss2: (0.0000) | Acc: (17.00%) (2512/14208)
Epoch: 0 | Batch_idx: 120 |  Loss: (2.2113) |  Loss2: (0.0000) | Acc: (18.00%) (2807/15488)
Epoch: 0 | Batch_idx: 130 |  Loss: (2.2037) |  Loss2: (0.0000) | Acc: (18.00%) (3102/16768)
Epoch: 0 | Batch_idx: 140 |  Loss: (2.1957) |  Loss2: (0.0000) | Acc: (18.00%) (3427/18048)
Epoch: 0 | Batch_idx: 150 |  Loss: (2.1869) |  Loss2: (0.0000) | Acc: (19.00%) (3777/19328)
Epoch: 0 | Batch_idx: 160 |  Loss: (2.1791) |  Loss2: (0.0000) | Acc: (19.00%) (4085/20608)
Epoch: 0 | Batch_idx: 170 |  Loss: (2.1706) |  Loss2: (0.0000) | Acc: (20.00%) (4432/21888)
Epoch: 0 | Batch_idx: 180 |  Loss: (2.1627) |  Loss2: (0.0000) | Acc: (20.00%) (4806/23168)
Epoch: 0 | Batch_idx: 190 |  Loss: (2.1549) |  Loss2: (0.0000) | Acc: (21.00%) (5147/24448)
Epoch: 0 | Batch_idx: 200 |  Loss: (2.1475) |  Loss2: (0.0000) | Acc: (21.00%) (5485/25728)
Epoch: 0 | Batch_idx: 210 |  Loss: (2.1399) |  Loss2: (0.0000) | Acc: (21.00%) (5833/27008)
Epoch: 0 | Batch_idx: 220 |  Loss: (2.1335) |  Loss2: (0.0000) | Acc: (21.00%) (6202/28288)
Epoch: 0 | Batch_idx: 230 |  Loss: (2.1266) |  Loss2: (0.0000) | Acc: (22.00%) (6581/29568)
Epoch: 0 | Batch_idx: 240 |  Loss: (2.1203) |  Loss2: (0.0000) | Acc: (22.00%) (6943/30848)
Epoch: 0 | Batch_idx: 250 |  Loss: (2.1143) |  Loss2: (0.0000) | Acc: (22.00%) (7292/32128)
Epoch: 0 | Batch_idx: 260 |  Loss: (2.1083) |  Loss2: (0.0000) | Acc: (22.00%) (7666/33408)
Epoch: 0 | Batch_idx: 270 |  Loss: (2.1022) |  Loss2: (0.0000) | Acc: (23.00%) (8066/34688)
Epoch: 0 | Batch_idx: 280 |  Loss: (2.0962) |  Loss2: (0.0000) | Acc: (23.00%) (8439/35968)
Epoch: 0 | Batch_idx: 290 |  Loss: (2.0902) |  Loss2: (0.0000) | Acc: (23.00%) (8818/37248)
Epoch: 0 | Batch_idx: 300 |  Loss: (2.0845) |  Loss2: (0.0000) | Acc: (23.00%) (9191/38528)
Epoch: 0 | Batch_idx: 310 |  Loss: (2.0786) |  Loss2: (0.0000) | Acc: (24.00%) (9556/39808)
Epoch: 0 | Batch_idx: 320 |  Loss: (2.0726) |  Loss2: (0.0000) | Acc: (24.00%) (9958/41088)
Epoch: 0 | Batch_idx: 330 |  Loss: (2.0675) |  Loss2: (0.0000) | Acc: (24.00%) (10346/42368)
Epoch: 0 | Batch_idx: 340 |  Loss: (2.0620) |  Loss2: (0.0000) | Acc: (24.00%) (10746/43648)
Epoch: 0 | Batch_idx: 350 |  Loss: (2.0563) |  Loss2: (0.0000) | Acc: (24.00%) (11139/44928)
Epoch: 0 | Batch_idx: 360 |  Loss: (2.0512) |  Loss2: (0.0000) | Acc: (24.00%) (11551/46208)
Epoch: 0 | Batch_idx: 370 |  Loss: (2.0460) |  Loss2: (0.0000) | Acc: (25.00%) (11969/47488)
Epoch: 0 | Batch_idx: 380 |  Loss: (2.0404) |  Loss2: (0.0000) | Acc: (25.00%) (12414/48768)
Epoch: 0 | Batch_idx: 390 |  Loss: (2.0350) |  Loss2: (0.0000) | Acc: (25.00%) (12843/50000)
/usr/local/lib/python3.6/dist-packages/torch/serialization.py:241: UserWarning: Couldn't retrieve source code for container of type ResNet. It won't be checked for correctness upon loading.
  "type " + obj.__name__ + ". It won't be checked "
/usr/local/lib/python3.6/dist-packages/torch/serialization.py:241: UserWarning: Couldn't retrieve source code for container of type BasicBlock. It won't be checked for correctness upon loading.
  "type " + obj.__name__ + ". It won't be checked "
/usr/local/lib/python3.6/dist-packages/torch/serialization.py:241: UserWarning: Couldn't retrieve source code for container of type _Gate. It won't be checked for correctness upon loading.
  "type " + obj.__name__ + ". It won't be checked "
=> saving checkpoint 'drive/app/torch/save_Schedule/checkpoint_000.pth.tar'
# TEST : Loss: (1.8052) | Acc: (32.00%) (3267/10000)
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 3, 3, 3]) tensor(170.9288, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(763.8708, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(768.8510, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([128, 64, 3, 3]) tensor(1537.3787, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([128, 64, 1, 1]) tensor(508.6260, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([128, 128, 3, 3]) tensor(2173.0691, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([256, 128, 3, 3]) tensor(4348.3765, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([256, 128, 1, 1]) tensor(1441.9026, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([256, 256, 3, 3]) tensor(6142.1714, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([512, 256, 3, 3]) tensor(12292.3975, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([512, 256, 1, 1]) tensor(4098.7095, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([512, 512, 3, 3]) tensor(17372.2148, device='cuda:0', grad_fn=<NormBackward0>)
Epoch: 1 | Batch_idx: 0 |  Loss: (1.8227) |  Loss2: (0.0000) | Acc: (32.00%) (42/128)
Epoch: 1 | Batch_idx: 10 |  Loss: (1.8013) |  Loss2: (0.0000) | Acc: (34.00%) (479/1408)
Epoch: 1 | Batch_idx: 20 |  Loss: (1.8126) |  Loss2: (0.0000) | Acc: (32.00%) (881/2688)
Epoch: 1 | Batch_idx: 30 |  Loss: (1.8140) |  Loss2: (0.0000) | Acc: (33.00%) (1337/3968)
Epoch: 1 | Batch_idx: 40 |  Loss: (1.8130) |  Loss2: (0.0000) | Acc: (33.00%) (1759/5248)
Epoch: 1 | Batch_idx: 50 |  Loss: (1.8144) |  Loss2: (0.0000) | Acc: (33.00%) (2195/6528)
Epoch: 1 | Batch_idx: 60 |  Loss: (1.8057) |  Loss2: (0.0000) | Acc: (34.00%) (2665/7808)
Epoch: 1 | Batch_idx: 70 |  Loss: (1.8016) |  Loss2: (0.0000) | Acc: (34.00%) (3103/9088)
Epoch: 1 | Batch_idx: 80 |  Loss: (1.7985) |  Loss2: (0.0000) | Acc: (34.00%) (3555/10368)
Epoch: 1 | Batch_idx: 90 |  Loss: (1.7904) |  Loss2: (0.0000) | Acc: (34.00%) (4055/11648)
Epoch: 1 | Batch_idx: 100 |  Loss: (1.7872) |  Loss2: (0.0000) | Acc: (34.00%) (4505/12928)
Epoch: 1 | Batch_idx: 110 |  Loss: (1.7822) |  Loss2: (0.0000) | Acc: (35.00%) (4984/14208)
Epoch: 1 | Batch_idx: 120 |  Loss: (1.7787) |  Loss2: (0.0000) | Acc: (35.00%) (5459/15488)
Epoch: 1 | Batch_idx: 130 |  Loss: (1.7766) |  Loss2: (0.0000) | Acc: (35.00%) (5940/16768)
Epoch: 1 | Batch_idx: 140 |  Loss: (1.7718) |  Loss2: (0.0000) | Acc: (35.00%) (6412/18048)
Epoch: 1 | Batch_idx: 150 |  Loss: (1.7679) |  Loss2: (0.0000) | Acc: (35.00%) (6895/19328)
Epoch: 1 | Batch_idx: 160 |  Loss: (1.7654) |  Loss2: (0.0000) | Acc: (35.00%) (7371/20608)
Epoch: 1 | Batch_idx: 170 |  Loss: (1.7619) |  Loss2: (0.0000) | Acc: (35.00%) (7865/21888)
Epoch: 1 | Batch_idx: 180 |  Loss: (1.7575) |  Loss2: (0.0000) | Acc: (36.00%) (8359/23168)
Epoch: 1 | Batch_idx: 190 |  Loss: (1.7551) |  Loss2: (0.0000) | Acc: (36.00%) (8824/24448)
Epoch: 1 | Batch_idx: 200 |  Loss: (1.7527) |  Loss2: (0.0000) | Acc: (36.00%) (9314/25728)
Epoch: 1 | Batch_idx: 210 |  Loss: (1.7490) |  Loss2: (0.0000) | Acc: (36.00%) (9809/27008)
Epoch: 1 | Batch_idx: 220 |  Loss: (1.7451) |  Loss2: (0.0000) | Acc: (36.00%) (10289/28288)
Epoch: 1 | Batch_idx: 230 |  Loss: (1.7412) |  Loss2: (0.0000) | Acc: (36.00%) (10800/29568)
Epoch: 1 | Batch_idx: 240 |  Loss: (1.7389) |  Loss2: (0.0000) | Acc: (36.00%) (11310/30848)
Epoch: 1 | Batch_idx: 250 |  Loss: (1.7357) |  Loss2: (0.0000) | Acc: (36.00%) (11792/32128)
Epoch: 1 | Batch_idx: 260 |  Loss: (1.7319) |  Loss2: (0.0000) | Acc: (36.00%) (12315/33408)
Epoch: 1 | Batch_idx: 270 |  Loss: (1.7282) |  Loss2: (0.0000) | Acc: (37.00%) (12839/34688)
Epoch: 1 | Batch_idx: 280 |  Loss: (1.7253) |  Loss2: (0.0000) | Acc: (37.00%) (13329/35968)
Epoch: 1 | Batch_idx: 290 |  Loss: (1.7215) |  Loss2: (0.0000) | Acc: (37.00%) (13843/37248)
Epoch: 1 | Batch_idx: 300 |  Loss: (1.7191) |  Loss2: (0.0000) | Acc: (37.00%) (14357/38528)
Epoch: 1 | Batch_idx: 310 |  Loss: (1.7158) |  Loss2: (0.0000) | Acc: (37.00%) (14881/39808)
Epoch: 1 | Batch_idx: 320 |  Loss: (1.7131) |  Loss2: (0.0000) | Acc: (37.00%) (15404/41088)
Epoch: 1 | Batch_idx: 330 |  Loss: (1.7099) |  Loss2: (0.0000) | Acc: (37.00%) (15954/42368)
Epoch: 1 | Batch_idx: 340 |  Loss: (1.7063) |  Loss2: (0.0000) | Acc: (37.00%) (16487/43648)
Epoch: 1 | Batch_idx: 350 |  Loss: (1.7031) |  Loss2: (0.0000) | Acc: (37.00%) (16988/44928)
Epoch: 1 | Batch_idx: 360 |  Loss: (1.7007) |  Loss2: (0.0000) | Acc: (37.00%) (17508/46208)
Epoch: 1 | Batch_idx: 370 |  Loss: (1.6975) |  Loss2: (0.0000) | Acc: (37.00%) (18033/47488)
Epoch: 1 | Batch_idx: 380 |  Loss: (1.6940) |  Loss2: (0.0000) | Acc: (38.00%) (18584/48768)
Epoch: 1 | Batch_idx: 390 |  Loss: (1.6908) |  Loss2: (0.0000) | Acc: (38.00%) (19123/50000)
# TEST : Loss: (1.5646) | Acc: (41.00%) (4161/10000)
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
Epoch: 2 | Batch_idx: 0 |  Loss: (1.5336) |  Loss2: (0.0000) | Acc: (47.00%) (61/128)
Epoch: 2 | Batch_idx: 10 |  Loss: (1.5529) |  Loss2: (0.0000) | Acc: (44.00%) (624/1408)
Epoch: 2 | Batch_idx: 20 |  Loss: (1.5560) |  Loss2: (0.0000) | Acc: (42.00%) (1132/2688)
Epoch: 2 | Batch_idx: 30 |  Loss: (1.5605) |  Loss2: (0.0000) | Acc: (41.00%) (1650/3968)
Epoch: 2 | Batch_idx: 40 |  Loss: (1.5606) |  Loss2: (0.0000) | Acc: (41.00%) (2177/5248)
Epoch: 2 | Batch_idx: 50 |  Loss: (1.5653) |  Loss2: (0.0000) | Acc: (41.00%) (2696/6528)
Epoch: 2 | Batch_idx: 60 |  Loss: (1.5650) |  Loss2: (0.0000) | Acc: (41.00%) (3239/7808)
Epoch: 2 | Batch_idx: 70 |  Loss: (1.5620) |  Loss2: (0.0000) | Acc: (41.00%) (3792/9088)
Epoch: 2 | Batch_idx: 80 |  Loss: (1.5595) |  Loss2: (0.0000) | Acc: (41.00%) (4338/10368)
Epoch: 2 | Batch_idx: 90 |  Loss: (1.5555) |  Loss2: (0.0000) | Acc: (42.00%) (4899/11648)
Epoch: 2 | Batch_idx: 100 |  Loss: (1.5537) |  Loss2: (0.0000) | Acc: (42.00%) (5460/12928)
Epoch: 2 | Batch_idx: 110 |  Loss: (1.5523) |  Loss2: (0.0000) | Acc: (42.00%) (6025/14208)
Epoch: 2 | Batch_idx: 120 |  Loss: (1.5511) |  Loss2: (0.0000) | Acc: (42.00%) (6568/15488)
Epoch: 2 | Batch_idx: 130 |  Loss: (1.5504) |  Loss2: (0.0000) | Acc: (42.00%) (7110/16768)
Epoch: 2 | Batch_idx: 140 |  Loss: (1.5458) |  Loss2: (0.0000) | Acc: (42.00%) (7694/18048)
Epoch: 2 | Batch_idx: 150 |  Loss: (1.5443) |  Loss2: (0.0000) | Acc: (42.00%) (8282/19328)
Epoch: 2 | Batch_idx: 160 |  Loss: (1.5432) |  Loss2: (0.0000) | Acc: (42.00%) (8837/20608)
Epoch: 2 | Batch_idx: 170 |  Loss: (1.5400) |  Loss2: (0.0000) | Acc: (42.00%) (9410/21888)
Epoch: 2 | Batch_idx: 180 |  Loss: (1.5367) |  Loss2: (0.0000) | Acc: (43.00%) (10013/23168)
Epoch: 2 | Batch_idx: 190 |  Loss: (1.5376) |  Loss2: (0.0000) | Acc: (43.00%) (10550/24448)
Epoch: 2 | Batch_idx: 200 |  Loss: (1.5361) |  Loss2: (0.0000) | Acc: (43.00%) (11105/25728)
Epoch: 2 | Batch_idx: 210 |  Loss: (1.5337) |  Loss2: (0.0000) | Acc: (43.00%) (11676/27008)
Epoch: 2 | Batch_idx: 220 |  Loss: (1.5316) |  Loss2: (0.0000) | Acc: (43.00%) (12260/28288)
Epoch: 2 | Batch_idx: 230 |  Loss: (1.5296) |  Loss2: (0.0000) | Acc: (43.00%) (12823/29568)
Epoch: 2 | Batch_idx: 240 |  Loss: (1.5269) |  Loss2: (0.0000) | Acc: (43.00%) (13428/30848)
Epoch: 2 | Batch_idx: 250 |  Loss: (1.5233) |  Loss2: (0.0000) | Acc: (43.00%) (14049/32128)
Epoch: 2 | Batch_idx: 260 |  Loss: (1.5206) |  Loss2: (0.0000) | Acc: (43.00%) (14642/33408)
Epoch: 2 | Batch_idx: 270 |  Loss: (1.5188) |  Loss2: (0.0000) | Acc: (43.00%) (15209/34688)
Epoch: 2 | Batch_idx: 280 |  Loss: (1.5168) |  Loss2: (0.0000) | Acc: (43.00%) (15767/35968)
Epoch: 2 | Batch_idx: 290 |  Loss: (1.5162) |  Loss2: (0.0000) | Acc: (43.00%) (16368/37248)
Epoch: 2 | Batch_idx: 300 |  Loss: (1.5140) |  Loss2: (0.0000) | Acc: (44.00%) (16966/38528)
Epoch: 2 | Batch_idx: 310 |  Loss: (1.5126) |  Loss2: (0.0000) | Acc: (44.00%) (17561/39808)
Epoch: 2 | Batch_idx: 320 |  Loss: (1.5102) |  Loss2: (0.0000) | Acc: (44.00%) (18173/41088)
Epoch: 2 | Batch_idx: 330 |  Loss: (1.5084) |  Loss2: (0.0000) | Acc: (44.00%) (18758/42368)
Epoch: 2 | Batch_idx: 340 |  Loss: (1.5074) |  Loss2: (0.0000) | Acc: (44.00%) (19348/43648)
Epoch: 2 | Batch_idx: 350 |  Loss: (1.5055) |  Loss2: (0.0000) | Acc: (44.00%) (19978/44928)
Epoch: 2 | Batch_idx: 360 |  Loss: (1.5046) |  Loss2: (0.0000) | Acc: (44.00%) (20585/46208)
Epoch: 2 | Batch_idx: 370 |  Loss: (1.5017) |  Loss2: (0.0000) | Acc: (44.00%) (21207/47488)
Epoch: 2 | Batch_idx: 380 |  Loss: (1.4998) |  Loss2: (0.0000) | Acc: (44.00%) (21825/48768)
Epoch: 2 | Batch_idx: 390 |  Loss: (1.4985) |  Loss2: (0.0000) | Acc: (44.00%) (22389/50000)
# TEST : Loss: (1.3956) | Acc: (48.00%) (4826/10000)
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
Epoch: 3 | Batch_idx: 0 |  Loss: (1.3680) |  Loss2: (0.0000) | Acc: (47.00%) (61/128)
Epoch: 3 | Batch_idx: 10 |  Loss: (1.4182) |  Loss2: (0.0000) | Acc: (48.00%) (681/1408)
Epoch: 3 | Batch_idx: 20 |  Loss: (1.4166) |  Loss2: (0.0000) | Acc: (48.00%) (1317/2688)
Epoch: 3 | Batch_idx: 30 |  Loss: (1.4189) |  Loss2: (0.0000) | Acc: (48.00%) (1912/3968)
Epoch: 3 | Batch_idx: 40 |  Loss: (1.4091) |  Loss2: (0.0000) | Acc: (48.00%) (2546/5248)
Epoch: 3 | Batch_idx: 50 |  Loss: (1.4010) |  Loss2: (0.0000) | Acc: (48.00%) (3175/6528)
Epoch: 3 | Batch_idx: 60 |  Loss: (1.4047) |  Loss2: (0.0000) | Acc: (48.00%) (3786/7808)
Epoch: 3 | Batch_idx: 70 |  Loss: (1.4003) |  Loss2: (0.0000) | Acc: (48.00%) (4428/9088)
Epoch: 3 | Batch_idx: 80 |  Loss: (1.4032) |  Loss2: (0.0000) | Acc: (48.00%) (5045/10368)
Epoch: 3 | Batch_idx: 90 |  Loss: (1.4012) |  Loss2: (0.0000) | Acc: (48.00%) (5685/11648)
Epoch: 3 | Batch_idx: 100 |  Loss: (1.3976) |  Loss2: (0.0000) | Acc: (48.00%) (6330/12928)
Epoch: 3 | Batch_idx: 110 |  Loss: (1.3943) |  Loss2: (0.0000) | Acc: (49.00%) (6988/14208)
Epoch: 3 | Batch_idx: 120 |  Loss: (1.3938) |  Loss2: (0.0000) | Acc: (49.00%) (7607/15488)
Epoch: 3 | Batch_idx: 130 |  Loss: (1.3936) |  Loss2: (0.0000) | Acc: (49.00%) (8227/16768)
Epoch: 3 | Batch_idx: 140 |  Loss: (1.3905) |  Loss2: (0.0000) | Acc: (49.00%) (8884/18048)
Epoch: 3 | Batch_idx: 150 |  Loss: (1.3877) |  Loss2: (0.0000) | Acc: (49.00%) (9536/19328)
Epoch: 3 | Batch_idx: 160 |  Loss: (1.3864) |  Loss2: (0.0000) | Acc: (49.00%) (10196/20608)
Epoch: 3 | Batch_idx: 170 |  Loss: (1.3850) |  Loss2: (0.0000) | Acc: (49.00%) (10855/21888)
Epoch: 3 | Batch_idx: 180 |  Loss: (1.3845) |  Loss2: (0.0000) | Acc: (49.00%) (11508/23168)
Epoch: 3 | Batch_idx: 190 |  Loss: (1.3836) |  Loss2: (0.0000) | Acc: (49.00%) (12151/24448)
Epoch: 3 | Batch_idx: 200 |  Loss: (1.3813) |  Loss2: (0.0000) | Acc: (49.00%) (12827/25728)
Epoch: 3 | Batch_idx: 210 |  Loss: (1.3795) |  Loss2: (0.0000) | Acc: (49.00%) (13470/27008)
Epoch: 3 | Batch_idx: 220 |  Loss: (1.3785) |  Loss2: (0.0000) | Acc: (49.00%) (14135/28288)
Epoch: 3 | Batch_idx: 230 |  Loss: (1.3771) |  Loss2: (0.0000) | Acc: (50.00%) (14789/29568)
Epoch: 3 | Batch_idx: 240 |  Loss: (1.3753) |  Loss2: (0.0000) | Acc: (50.00%) (15470/30848)
Epoch: 3 | Batch_idx: 250 |  Loss: (1.3738) |  Loss2: (0.0000) | Acc: (50.00%) (16122/32128)
Epoch: 3 | Batch_idx: 260 |  Loss: (1.3735) |  Loss2: (0.0000) | Acc: (50.00%) (16743/33408)
Epoch: 3 | Batch_idx: 270 |  Loss: (1.3720) |  Loss2: (0.0000) | Acc: (50.00%) (17413/34688)
Epoch: 3 | Batch_idx: 280 |  Loss: (1.3716) |  Loss2: (0.0000) | Acc: (50.00%) (18066/35968)
Epoch: 3 | Batch_idx: 290 |  Loss: (1.3707) |  Loss2: (0.0000) | Acc: (50.00%) (18722/37248)
Epoch: 3 | Batch_idx: 300 |  Loss: (1.3697) |  Loss2: (0.0000) | Acc: (50.00%) (19387/38528)
Epoch: 3 | Batch_idx: 310 |  Loss: (1.3691) |  Loss2: (0.0000) | Acc: (50.00%) (20039/39808)
Epoch: 3 | Batch_idx: 320 |  Loss: (1.3679) |  Loss2: (0.0000) | Acc: (50.00%) (20693/41088)
Epoch: 3 | Batch_idx: 330 |  Loss: (1.3666) |  Loss2: (0.0000) | Acc: (50.00%) (21349/42368)
Epoch: 3 | Batch_idx: 340 |  Loss: (1.3647) |  Loss2: (0.0000) | Acc: (50.00%) (22053/43648)
Epoch: 3 | Batch_idx: 350 |  Loss: (1.3628) |  Loss2: (0.0000) | Acc: (50.00%) (22714/44928)
Epoch: 3 | Batch_idx: 360 |  Loss: (1.3611) |  Loss2: (0.0000) | Acc: (50.00%) (23415/46208)
Epoch: 3 | Batch_idx: 370 |  Loss: (1.3581) |  Loss2: (0.0000) | Acc: (50.00%) (24133/47488)
Epoch: 3 | Batch_idx: 380 |  Loss: (1.3575) |  Loss2: (0.0000) | Acc: (50.00%) (24797/48768)
Epoch: 3 | Batch_idx: 390 |  Loss: (1.3556) |  Loss2: (0.0000) | Acc: (50.00%) (25436/50000)
# TEST : Loss: (1.3339) | Acc: (51.00%) (5144/10000)
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
Epoch: 4 | Batch_idx: 0 |  Loss: (1.2611) |  Loss2: (0.0000) | Acc: (54.00%) (70/128)
Epoch: 4 | Batch_idx: 10 |  Loss: (1.2702) |  Loss2: (0.0000) | Acc: (54.00%) (768/1408)
Epoch: 4 | Batch_idx: 20 |  Loss: (1.2840) |  Loss2: (0.0000) | Acc: (54.00%) (1454/2688)
Epoch: 4 | Batch_idx: 30 |  Loss: (1.2936) |  Loss2: (0.0000) | Acc: (53.00%) (2114/3968)
Epoch: 4 | Batch_idx: 40 |  Loss: (1.2893) |  Loss2: (0.0000) | Acc: (53.00%) (2823/5248)
Epoch: 4 | Batch_idx: 50 |  Loss: (1.2883) |  Loss2: (0.0000) | Acc: (54.00%) (3530/6528)
Epoch: 4 | Batch_idx: 60 |  Loss: (1.2820) |  Loss2: (0.0000) | Acc: (54.00%) (4246/7808)
Epoch: 4 | Batch_idx: 70 |  Loss: (1.2824) |  Loss2: (0.0000) | Acc: (54.00%) (4925/9088)
Epoch: 4 | Batch_idx: 80 |  Loss: (1.2812) |  Loss2: (0.0000) | Acc: (54.00%) (5607/10368)
Epoch: 4 | Batch_idx: 90 |  Loss: (1.2793) |  Loss2: (0.0000) | Acc: (54.00%) (6331/11648)
Epoch: 4 | Batch_idx: 100 |  Loss: (1.2807) |  Loss2: (0.0000) | Acc: (54.00%) (7017/12928)
Epoch: 4 | Batch_idx: 110 |  Loss: (1.2808) |  Loss2: (0.0000) | Acc: (54.00%) (7712/14208)
Epoch: 4 | Batch_idx: 120 |  Loss: (1.2779) |  Loss2: (0.0000) | Acc: (54.00%) (8414/15488)
Epoch: 4 | Batch_idx: 130 |  Loss: (1.2763) |  Loss2: (0.0000) | Acc: (54.00%) (9122/16768)
Epoch: 4 | Batch_idx: 140 |  Loss: (1.2761) |  Loss2: (0.0000) | Acc: (54.00%) (9801/18048)
Epoch: 4 | Batch_idx: 150 |  Loss: (1.2767) |  Loss2: (0.0000) | Acc: (54.00%) (10498/19328)
Epoch: 4 | Batch_idx: 160 |  Loss: (1.2754) |  Loss2: (0.0000) | Acc: (54.00%) (11204/20608)
Epoch: 4 | Batch_idx: 170 |  Loss: (1.2744) |  Loss2: (0.0000) | Acc: (54.00%) (11925/21888)
Epoch: 4 | Batch_idx: 180 |  Loss: (1.2726) |  Loss2: (0.0000) | Acc: (54.00%) (12640/23168)
Epoch: 4 | Batch_idx: 190 |  Loss: (1.2683) |  Loss2: (0.0000) | Acc: (54.00%) (13385/24448)
Epoch: 4 | Batch_idx: 200 |  Loss: (1.2668) |  Loss2: (0.0000) | Acc: (54.00%) (14089/25728)
Epoch: 4 | Batch_idx: 210 |  Loss: (1.2634) |  Loss2: (0.0000) | Acc: (54.00%) (14812/27008)
Epoch: 4 | Batch_idx: 220 |  Loss: (1.2600) |  Loss2: (0.0000) | Acc: (54.00%) (15546/28288)
Epoch: 4 | Batch_idx: 230 |  Loss: (1.2588) |  Loss2: (0.0000) | Acc: (54.00%) (16258/29568)
Epoch: 4 | Batch_idx: 240 |  Loss: (1.2571) |  Loss2: (0.0000) | Acc: (55.00%) (16978/30848)
Epoch: 4 | Batch_idx: 250 |  Loss: (1.2564) |  Loss2: (0.0000) | Acc: (55.00%) (17699/32128)
Epoch: 4 | Batch_idx: 260 |  Loss: (1.2545) |  Loss2: (0.0000) | Acc: (55.00%) (18424/33408)
Epoch: 4 | Batch_idx: 270 |  Loss: (1.2530) |  Loss2: (0.0000) | Acc: (55.00%) (19160/34688)
Epoch: 4 | Batch_idx: 280 |  Loss: (1.2512) |  Loss2: (0.0000) | Acc: (55.00%) (19897/35968)
Epoch: 4 | Batch_idx: 290 |  Loss: (1.2494) |  Loss2: (0.0000) | Acc: (55.00%) (20632/37248)
Epoch: 4 | Batch_idx: 300 |  Loss: (1.2484) |  Loss2: (0.0000) | Acc: (55.00%) (21364/38528)
Epoch: 4 | Batch_idx: 310 |  Loss: (1.2477) |  Loss2: (0.0000) | Acc: (55.00%) (22076/39808)
Epoch: 4 | Batch_idx: 320 |  Loss: (1.2456) |  Loss2: (0.0000) | Acc: (55.00%) (22818/41088)
Epoch: 4 | Batch_idx: 330 |  Loss: (1.2444) |  Loss2: (0.0000) | Acc: (55.00%) (23547/42368)
Epoch: 4 | Batch_idx: 340 |  Loss: (1.2419) |  Loss2: (0.0000) | Acc: (55.00%) (24287/43648)
Epoch: 4 | Batch_idx: 350 |  Loss: (1.2398) |  Loss2: (0.0000) | Acc: (55.00%) (25017/44928)
Epoch: 4 | Batch_idx: 360 |  Loss: (1.2391) |  Loss2: (0.0000) | Acc: (55.00%) (25722/46208)
Epoch: 4 | Batch_idx: 370 |  Loss: (1.2372) |  Loss2: (0.0000) | Acc: (55.00%) (26466/47488)
Epoch: 4 | Batch_idx: 380 |  Loss: (1.2369) |  Loss2: (0.0000) | Acc: (55.00%) (27168/48768)
Epoch: 4 | Batch_idx: 390 |  Loss: (1.2352) |  Loss2: (0.0000) | Acc: (55.00%) (27883/50000)
# TEST : Loss: (1.2330) | Acc: (55.00%) (5503/10000)
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
Epoch: 5 | Batch_idx: 0 |  Loss: (1.1370) |  Loss2: (0.0000) | Acc: (56.00%) (72/128)
Epoch: 5 | Batch_idx: 10 |  Loss: (1.1769) |  Loss2: (0.0000) | Acc: (58.00%) (819/1408)
Epoch: 5 | Batch_idx: 20 |  Loss: (1.1904) |  Loss2: (0.0000) | Acc: (56.00%) (1513/2688)
Epoch: 5 | Batch_idx: 30 |  Loss: (1.1875) |  Loss2: (0.0000) | Acc: (56.00%) (2258/3968)
Epoch: 5 | Batch_idx: 40 |  Loss: (1.1709) |  Loss2: (0.0000) | Acc: (57.00%) (3022/5248)
Epoch: 5 | Batch_idx: 50 |  Loss: (1.1662) |  Loss2: (0.0000) | Acc: (57.00%) (3766/6528)
Epoch: 5 | Batch_idx: 60 |  Loss: (1.1683) |  Loss2: (0.0000) | Acc: (57.00%) (4497/7808)
Epoch: 5 | Batch_idx: 70 |  Loss: (1.1746) |  Loss2: (0.0000) | Acc: (57.00%) (5202/9088)
Epoch: 5 | Batch_idx: 80 |  Loss: (1.1791) |  Loss2: (0.0000) | Acc: (57.00%) (5912/10368)
Epoch: 5 | Batch_idx: 90 |  Loss: (1.1782) |  Loss2: (0.0000) | Acc: (57.00%) (6656/11648)
Epoch: 5 | Batch_idx: 100 |  Loss: (1.1780) |  Loss2: (0.0000) | Acc: (57.00%) (7400/12928)
Epoch: 5 | Batch_idx: 110 |  Loss: (1.1771) |  Loss2: (0.0000) | Acc: (57.00%) (8141/14208)
Epoch: 5 | Batch_idx: 120 |  Loss: (1.1757) |  Loss2: (0.0000) | Acc: (57.00%) (8895/15488)
Epoch: 5 | Batch_idx: 130 |  Loss: (1.1728) |  Loss2: (0.0000) | Acc: (57.00%) (9660/16768)
Epoch: 5 | Batch_idx: 140 |  Loss: (1.1704) |  Loss2: (0.0000) | Acc: (57.00%) (10428/18048)
Epoch: 5 | Batch_idx: 150 |  Loss: (1.1710) |  Loss2: (0.0000) | Acc: (57.00%) (11180/19328)
Epoch: 5 | Batch_idx: 160 |  Loss: (1.1687) |  Loss2: (0.0000) | Acc: (57.00%) (11934/20608)
Epoch: 5 | Batch_idx: 170 |  Loss: (1.1689) |  Loss2: (0.0000) | Acc: (58.00%) (12702/21888)
Epoch: 5 | Batch_idx: 180 |  Loss: (1.1655) |  Loss2: (0.0000) | Acc: (58.00%) (13486/23168)
Epoch: 5 | Batch_idx: 190 |  Loss: (1.1626) |  Loss2: (0.0000) | Acc: (58.00%) (14259/24448)
Epoch: 5 | Batch_idx: 200 |  Loss: (1.1612) |  Loss2: (0.0000) | Acc: (58.00%) (15026/25728)
Epoch: 5 | Batch_idx: 210 |  Loss: (1.1607) |  Loss2: (0.0000) | Acc: (58.00%) (15788/27008)
Epoch: 5 | Batch_idx: 220 |  Loss: (1.1587) |  Loss2: (0.0000) | Acc: (58.00%) (16570/28288)
Epoch: 5 | Batch_idx: 230 |  Loss: (1.1560) |  Loss2: (0.0000) | Acc: (58.00%) (17365/29568)
Epoch: 5 | Batch_idx: 240 |  Loss: (1.1546) |  Loss2: (0.0000) | Acc: (58.00%) (18145/30848)
Epoch: 5 | Batch_idx: 250 |  Loss: (1.1529) |  Loss2: (0.0000) | Acc: (58.00%) (18937/32128)
Epoch: 5 | Batch_idx: 260 |  Loss: (1.1526) |  Loss2: (0.0000) | Acc: (58.00%) (19684/33408)
Epoch: 5 | Batch_idx: 270 |  Loss: (1.1532) |  Loss2: (0.0000) | Acc: (58.00%) (20441/34688)
Epoch: 5 | Batch_idx: 280 |  Loss: (1.1522) |  Loss2: (0.0000) | Acc: (58.00%) (21193/35968)
Epoch: 5 | Batch_idx: 290 |  Loss: (1.1520) |  Loss2: (0.0000) | Acc: (58.00%) (21951/37248)
Epoch: 5 | Batch_idx: 300 |  Loss: (1.1502) |  Loss2: (0.0000) | Acc: (59.00%) (22746/38528)
Epoch: 5 | Batch_idx: 310 |  Loss: (1.1487) |  Loss2: (0.0000) | Acc: (59.00%) (23546/39808)
Epoch: 5 | Batch_idx: 320 |  Loss: (1.1468) |  Loss2: (0.0000) | Acc: (59.00%) (24348/41088)
Epoch: 5 | Batch_idx: 330 |  Loss: (1.1463) |  Loss2: (0.0000) | Acc: (59.00%) (25135/42368)
Epoch: 5 | Batch_idx: 340 |  Loss: (1.1442) |  Loss2: (0.0000) | Acc: (59.00%) (25922/43648)
Epoch: 5 | Batch_idx: 350 |  Loss: (1.1428) |  Loss2: (0.0000) | Acc: (59.00%) (26705/44928)
Epoch: 5 | Batch_idx: 360 |  Loss: (1.1416) |  Loss2: (0.0000) | Acc: (59.00%) (27475/46208)
Epoch: 5 | Batch_idx: 370 |  Loss: (1.1405) |  Loss2: (0.0000) | Acc: (59.00%) (28280/47488)
Epoch: 5 | Batch_idx: 380 |  Loss: (1.1381) |  Loss2: (0.0000) | Acc: (59.00%) (29100/48768)
Epoch: 5 | Batch_idx: 390 |  Loss: (1.1369) |  Loss2: (0.0000) | Acc: (59.00%) (29842/50000)
=> saving checkpoint 'drive/app/torch/save_Schedule/checkpoint_005.pth.tar'
# TEST : Loss: (1.1794) | Acc: (58.00%) (5827/10000)
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
Epoch: 6 | Batch_idx: 0 |  Loss: (0.9441) |  Loss2: (0.0000) | Acc: (64.00%) (83/128)
Epoch: 6 | Batch_idx: 10 |  Loss: (1.1055) |  Loss2: (0.0000) | Acc: (61.00%) (870/1408)
Epoch: 6 | Batch_idx: 20 |  Loss: (1.0892) |  Loss2: (0.0000) | Acc: (61.00%) (1648/2688)
Epoch: 6 | Batch_idx: 30 |  Loss: (1.0881) |  Loss2: (0.0000) | Acc: (61.00%) (2430/3968)
Epoch: 6 | Batch_idx: 40 |  Loss: (1.0763) |  Loss2: (0.0000) | Acc: (61.00%) (3242/5248)
Epoch: 6 | Batch_idx: 50 |  Loss: (1.0810) |  Loss2: (0.0000) | Acc: (61.00%) (4016/6528)
Epoch: 6 | Batch_idx: 60 |  Loss: (1.0769) |  Loss2: (0.0000) | Acc: (61.00%) (4826/7808)
Epoch: 6 | Batch_idx: 70 |  Loss: (1.0772) |  Loss2: (0.0000) | Acc: (61.00%) (5624/9088)
Epoch: 6 | Batch_idx: 80 |  Loss: (1.0794) |  Loss2: (0.0000) | Acc: (61.00%) (6402/10368)
Epoch: 6 | Batch_idx: 90 |  Loss: (1.0802) |  Loss2: (0.0000) | Acc: (61.00%) (7167/11648)
Epoch: 6 | Batch_idx: 100 |  Loss: (1.0813) |  Loss2: (0.0000) | Acc: (61.00%) (7964/12928)
Epoch: 6 | Batch_idx: 110 |  Loss: (1.0759) |  Loss2: (0.0000) | Acc: (61.00%) (8801/14208)
Epoch: 6 | Batch_idx: 120 |  Loss: (1.0757) |  Loss2: (0.0000) | Acc: (61.00%) (9588/15488)
Epoch: 6 | Batch_idx: 130 |  Loss: (1.0738) |  Loss2: (0.0000) | Acc: (61.00%) (10388/16768)
Epoch: 6 | Batch_idx: 140 |  Loss: (1.0703) |  Loss2: (0.0000) | Acc: (62.00%) (11197/18048)
Epoch: 6 | Batch_idx: 150 |  Loss: (1.0712) |  Loss2: (0.0000) | Acc: (61.00%) (11962/19328)
Epoch: 6 | Batch_idx: 160 |  Loss: (1.0708) |  Loss2: (0.0000) | Acc: (61.00%) (12749/20608)
Epoch: 6 | Batch_idx: 170 |  Loss: (1.0694) |  Loss2: (0.0000) | Acc: (61.00%) (13548/21888)
Epoch: 6 | Batch_idx: 180 |  Loss: (1.0659) |  Loss2: (0.0000) | Acc: (62.00%) (14382/23168)
Epoch: 6 | Batch_idx: 190 |  Loss: (1.0648) |  Loss2: (0.0000) | Acc: (62.00%) (15202/24448)
Epoch: 6 | Batch_idx: 200 |  Loss: (1.0657) |  Loss2: (0.0000) | Acc: (62.00%) (16002/25728)
Epoch: 6 | Batch_idx: 210 |  Loss: (1.0660) |  Loss2: (0.0000) | Acc: (62.00%) (16786/27008)
Epoch: 6 | Batch_idx: 220 |  Loss: (1.0656) |  Loss2: (0.0000) | Acc: (62.00%) (17575/28288)
Epoch: 6 | Batch_idx: 230 |  Loss: (1.0658) |  Loss2: (0.0000) | Acc: (62.00%) (18370/29568)
Epoch: 6 | Batch_idx: 240 |  Loss: (1.0648) |  Loss2: (0.0000) | Acc: (62.00%) (19183/30848)
Epoch: 6 | Batch_idx: 250 |  Loss: (1.0629) |  Loss2: (0.0000) | Acc: (62.00%) (20003/32128)
Epoch: 6 | Batch_idx: 260 |  Loss: (1.0607) |  Loss2: (0.0000) | Acc: (62.00%) (20831/33408)
Epoch: 6 | Batch_idx: 270 |  Loss: (1.0595) |  Loss2: (0.0000) | Acc: (62.00%) (21634/34688)
Epoch: 6 | Batch_idx: 280 |  Loss: (1.0604) |  Loss2: (0.0000) | Acc: (62.00%) (22427/35968)
Epoch: 6 | Batch_idx: 290 |  Loss: (1.0601) |  Loss2: (0.0000) | Acc: (62.00%) (23233/37248)
Epoch: 6 | Batch_idx: 300 |  Loss: (1.0579) |  Loss2: (0.0000) | Acc: (62.00%) (24076/38528)
Epoch: 6 | Batch_idx: 310 |  Loss: (1.0560) |  Loss2: (0.0000) | Acc: (62.00%) (24918/39808)
Epoch: 6 | Batch_idx: 320 |  Loss: (1.0545) |  Loss2: (0.0000) | Acc: (62.00%) (25735/41088)
Epoch: 6 | Batch_idx: 330 |  Loss: (1.0552) |  Loss2: (0.0000) | Acc: (62.00%) (26527/42368)
Epoch: 6 | Batch_idx: 340 |  Loss: (1.0539) |  Loss2: (0.0000) | Acc: (62.00%) (27348/43648)
Epoch: 6 | Batch_idx: 350 |  Loss: (1.0540) |  Loss2: (0.0000) | Acc: (62.00%) (28167/44928)
Epoch: 6 | Batch_idx: 360 |  Loss: (1.0528) |  Loss2: (0.0000) | Acc: (62.00%) (28972/46208)
Epoch: 6 | Batch_idx: 370 |  Loss: (1.0534) |  Loss2: (0.0000) | Acc: (62.00%) (29748/47488)
Epoch: 6 | Batch_idx: 380 |  Loss: (1.0530) |  Loss2: (0.0000) | Acc: (62.00%) (30539/48768)
Epoch: 6 | Batch_idx: 390 |  Loss: (1.0513) |  Loss2: (0.0000) | Acc: (62.00%) (31330/50000)
# TEST : Loss: (1.0626) | Acc: (61.00%) (6145/10000)
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
Epoch: 7 | Batch_idx: 0 |  Loss: (0.9754) |  Loss2: (0.0000) | Acc: (63.00%) (81/128)
Epoch: 7 | Batch_idx: 10 |  Loss: (0.9886) |  Loss2: (0.0000) | Acc: (66.00%) (931/1408)
Epoch: 7 | Batch_idx: 20 |  Loss: (0.9978) |  Loss2: (0.0000) | Acc: (65.00%) (1750/2688)
Epoch: 7 | Batch_idx: 30 |  Loss: (1.0041) |  Loss2: (0.0000) | Acc: (64.00%) (2578/3968)
Epoch: 7 | Batch_idx: 40 |  Loss: (1.0034) |  Loss2: (0.0000) | Acc: (64.00%) (3411/5248)
Epoch: 7 | Batch_idx: 50 |  Loss: (0.9922) |  Loss2: (0.0000) | Acc: (65.00%) (4264/6528)
Epoch: 7 | Batch_idx: 60 |  Loss: (0.9919) |  Loss2: (0.0000) | Acc: (65.00%) (5087/7808)
Epoch: 7 | Batch_idx: 70 |  Loss: (0.9988) |  Loss2: (0.0000) | Acc: (64.00%) (5905/9088)
Epoch: 7 | Batch_idx: 80 |  Loss: (0.9904) |  Loss2: (0.0000) | Acc: (65.00%) (6763/10368)
Epoch: 7 | Batch_idx: 90 |  Loss: (0.9891) |  Loss2: (0.0000) | Acc: (65.00%) (7597/11648)
Epoch: 7 | Batch_idx: 100 |  Loss: (0.9922) |  Loss2: (0.0000) | Acc: (65.00%) (8424/12928)
Epoch: 7 | Batch_idx: 110 |  Loss: (0.9878) |  Loss2: (0.0000) | Acc: (65.00%) (9276/14208)
Epoch: 7 | Batch_idx: 120 |  Loss: (0.9884) |  Loss2: (0.0000) | Acc: (65.00%) (10108/15488)
Epoch: 7 | Batch_idx: 130 |  Loss: (0.9920) |  Loss2: (0.0000) | Acc: (65.00%) (10909/16768)
Epoch: 7 | Batch_idx: 140 |  Loss: (0.9954) |  Loss2: (0.0000) | Acc: (64.00%) (11716/18048)
Epoch: 7 | Batch_idx: 150 |  Loss: (0.9923) |  Loss2: (0.0000) | Acc: (65.00%) (12568/19328)
Epoch: 7 | Batch_idx: 160 |  Loss: (0.9930) |  Loss2: (0.0000) | Acc: (65.00%) (13401/20608)
Epoch: 7 | Batch_idx: 170 |  Loss: (0.9924) |  Loss2: (0.0000) | Acc: (65.00%) (14235/21888)
Epoch: 7 | Batch_idx: 180 |  Loss: (0.9929) |  Loss2: (0.0000) | Acc: (65.00%) (15074/23168)
Epoch: 7 | Batch_idx: 190 |  Loss: (0.9937) |  Loss2: (0.0000) | Acc: (65.00%) (15900/24448)
Epoch: 7 | Batch_idx: 200 |  Loss: (0.9942) |  Loss2: (0.0000) | Acc: (65.00%) (16735/25728)
Epoch: 7 | Batch_idx: 210 |  Loss: (0.9940) |  Loss2: (0.0000) | Acc: (65.00%) (17561/27008)
Epoch: 7 | Batch_idx: 220 |  Loss: (0.9942) |  Loss2: (0.0000) | Acc: (65.00%) (18394/28288)
Epoch: 7 | Batch_idx: 230 |  Loss: (0.9931) |  Loss2: (0.0000) | Acc: (65.00%) (19235/29568)
Epoch: 7 | Batch_idx: 240 |  Loss: (0.9913) |  Loss2: (0.0000) | Acc: (65.00%) (20094/30848)
Epoch: 7 | Batch_idx: 250 |  Loss: (0.9900) |  Loss2: (0.0000) | Acc: (65.00%) (20925/32128)
Epoch: 7 | Batch_idx: 260 |  Loss: (0.9896) |  Loss2: (0.0000) | Acc: (65.00%) (21758/33408)
Epoch: 7 | Batch_idx: 270 |  Loss: (0.9890) |  Loss2: (0.0000) | Acc: (65.00%) (22600/34688)
Epoch: 7 | Batch_idx: 280 |  Loss: (0.9872) |  Loss2: (0.0000) | Acc: (65.00%) (23445/35968)
Epoch: 7 | Batch_idx: 290 |  Loss: (0.9860) |  Loss2: (0.0000) | Acc: (65.00%) (24281/37248)
Epoch: 7 | Batch_idx: 300 |  Loss: (0.9853) |  Loss2: (0.0000) | Acc: (65.00%) (25128/38528)
Epoch: 7 | Batch_idx: 310 |  Loss: (0.9853) |  Loss2: (0.0000) | Acc: (65.00%) (25981/39808)
Epoch: 7 | Batch_idx: 320 |  Loss: (0.9844) |  Loss2: (0.0000) | Acc: (65.00%) (26819/41088)
Epoch: 7 | Batch_idx: 330 |  Loss: (0.9842) |  Loss2: (0.0000) | Acc: (65.00%) (27680/42368)
Epoch: 7 | Batch_idx: 340 |  Loss: (0.9841) |  Loss2: (0.0000) | Acc: (65.00%) (28513/43648)
Epoch: 7 | Batch_idx: 350 |  Loss: (0.9837) |  Loss2: (0.0000) | Acc: (65.00%) (29370/44928)
Epoch: 7 | Batch_idx: 360 |  Loss: (0.9828) |  Loss2: (0.0000) | Acc: (65.00%) (30217/46208)
Epoch: 7 | Batch_idx: 370 |  Loss: (0.9837) |  Loss2: (0.0000) | Acc: (65.00%) (31043/47488)
Epoch: 7 | Batch_idx: 380 |  Loss: (0.9828) |  Loss2: (0.0000) | Acc: (65.00%) (31886/48768)
Epoch: 7 | Batch_idx: 390 |  Loss: (0.9829) |  Loss2: (0.0000) | Acc: (65.00%) (32684/50000)
# TEST : Loss: (0.9935) | Acc: (64.00%) (6451/10000)
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
False Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=128, out_features=16, bias=False)
True Linear(in_features=16, out_features=2, bias=False)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=128, out_features=16, bias=False)
True Linear(in_features=16, out_features=2, bias=False)
False Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=256, out_features=32, bias=False)
True Linear(in_features=32, out_features=2, bias=False)
False Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=256, out_features=32, bias=False)
True Linear(in_features=32, out_features=2, bias=False)
False Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=512, out_features=64, bias=False)
True Linear(in_features=64, out_features=2, bias=False)
False Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=512, out_features=64, bias=False)
True Linear(in_features=64, out_features=2, bias=False)
False Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1024, out_features=128, bias=False)
True Linear(in_features=128, out_features=2, bias=False)
False Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1024, out_features=128, bias=False)
True Linear(in_features=128, out_features=2, bias=False)
False Linear(in_features=512, out_features=10, bias=True)
Epoch: 8 | Batch_idx: 0 |  Loss: (0.7902) |  Loss2: (0.0000) | Acc: (72.00%) (93/128)
Epoch: 8 | Batch_idx: 10 |  Loss: (0.9473) |  Loss2: (0.0000) | Acc: (66.00%) (942/1408)
Epoch: 8 | Batch_idx: 20 |  Loss: (1.0189) |  Loss2: (0.0000) | Acc: (63.00%) (1715/2688)
Epoch: 8 | Batch_idx: 30 |  Loss: (1.0476) |  Loss2: (0.0000) | Acc: (62.00%) (2490/3968)
Epoch: 8 | Batch_idx: 40 |  Loss: (1.0724) |  Loss2: (0.0000) | Acc: (61.00%) (3244/5248)
Epoch: 8 | Batch_idx: 50 |  Loss: (1.0784) |  Loss2: (0.0000) | Acc: (61.00%) (4020/6528)
Epoch: 8 | Batch_idx: 60 |  Loss: (1.0884) |  Loss2: (0.0000) | Acc: (60.00%) (4760/7808)
Epoch: 8 | Batch_idx: 70 |  Loss: (1.0945) |  Loss2: (0.0000) | Acc: (60.00%) (5517/9088)
Epoch: 8 | Batch_idx: 80 |  Loss: (1.0989) |  Loss2: (0.0000) | Acc: (60.00%) (6261/10368)
Epoch: 8 | Batch_idx: 90 |  Loss: (1.0976) |  Loss2: (0.0000) | Acc: (60.00%) (7038/11648)
Epoch: 8 | Batch_idx: 100 |  Loss: (1.0955) |  Loss2: (0.0000) | Acc: (60.00%) (7828/12928)
Epoch: 8 | Batch_idx: 110 |  Loss: (1.0972) |  Loss2: (0.0000) | Acc: (60.00%) (8594/14208)
Epoch: 8 | Batch_idx: 120 |  Loss: (1.0973) |  Loss2: (0.0000) | Acc: (60.00%) (9362/15488)
Epoch: 8 | Batch_idx: 130 |  Loss: (1.0958) |  Loss2: (0.0000) | Acc: (60.00%) (10133/16768)
Epoch: 8 | Batch_idx: 140 |  Loss: (1.0949) |  Loss2: (0.0000) | Acc: (60.00%) (10919/18048)
Epoch: 8 | Batch_idx: 150 |  Loss: (1.0914) |  Loss2: (0.0000) | Acc: (60.00%) (11728/19328)
Epoch: 8 | Batch_idx: 160 |  Loss: (1.0895) |  Loss2: (0.0000) | Acc: (60.00%) (12529/20608)
Epoch: 8 | Batch_idx: 170 |  Loss: (1.0869) |  Loss2: (0.0000) | Acc: (60.00%) (13339/21888)
Epoch: 8 | Batch_idx: 180 |  Loss: (1.0830) |  Loss2: (0.0000) | Acc: (61.00%) (14148/23168)
Epoch: 8 | Batch_idx: 190 |  Loss: (1.0826) |  Loss2: (0.0000) | Acc: (61.00%) (14941/24448)
Epoch: 8 | Batch_idx: 200 |  Loss: (1.0792) |  Loss2: (0.0000) | Acc: (61.00%) (15759/25728)
Epoch: 8 | Batch_idx: 210 |  Loss: (1.0783) |  Loss2: (0.0000) | Acc: (61.00%) (16556/27008)
Epoch: 8 | Batch_idx: 220 |  Loss: (1.0773) |  Loss2: (0.0000) | Acc: (61.00%) (17352/28288)
Epoch: 8 | Batch_idx: 230 |  Loss: (1.0743) |  Loss2: (0.0000) | Acc: (61.00%) (18182/29568)
Epoch: 8 | Batch_idx: 240 |  Loss: (1.0706) |  Loss2: (0.0000) | Acc: (61.00%) (19022/30848)
Epoch: 8 | Batch_idx: 250 |  Loss: (1.0688) |  Loss2: (0.0000) | Acc: (61.00%) (19848/32128)
Epoch: 8 | Batch_idx: 260 |  Loss: (1.0671) |  Loss2: (0.0000) | Acc: (61.00%) (20660/33408)
Epoch: 8 | Batch_idx: 270 |  Loss: (1.0659) |  Loss2: (0.0000) | Acc: (61.00%) (21476/34688)
Epoch: 8 | Batch_idx: 280 |  Loss: (1.0659) |  Loss2: (0.0000) | Acc: (61.00%) (22290/35968)
Epoch: 8 | Batch_idx: 290 |  Loss: (1.0655) |  Loss2: (0.0000) | Acc: (61.00%) (23084/37248)
Epoch: 8 | Batch_idx: 300 |  Loss: (1.0631) |  Loss2: (0.0000) | Acc: (62.00%) (23917/38528)
Epoch: 8 | Batch_idx: 310 |  Loss: (1.0618) |  Loss2: (0.0000) | Acc: (62.00%) (24727/39808)
Epoch: 8 | Batch_idx: 320 |  Loss: (1.0590) |  Loss2: (0.0000) | Acc: (62.00%) (25568/41088)
Epoch: 8 | Batch_idx: 330 |  Loss: (1.0561) |  Loss2: (0.0000) | Acc: (62.00%) (26417/42368)
Epoch: 8 | Batch_idx: 340 |  Loss: (1.0547) |  Loss2: (0.0000) | Acc: (62.00%) (27248/43648)
Epoch: 8 | Batch_idx: 350 |  Loss: (1.0531) |  Loss2: (0.0000) | Acc: (62.00%) (28066/44928)
Epoch: 8 | Batch_idx: 360 |  Loss: (1.0518) |  Loss2: (0.0000) | Acc: (62.00%) (28875/46208)
Epoch: 8 | Batch_idx: 370 |  Loss: (1.0507) |  Loss2: (0.0000) | Acc: (62.00%) (29688/47488)
Epoch: 8 | Batch_idx: 380 |  Loss: (1.0496) |  Loss2: (0.0000) | Acc: (62.00%) (30507/48768)
Epoch: 8 | Batch_idx: 390 |  Loss: (1.0488) |  Loss2: (0.0000) | Acc: (62.00%) (31300/50000)
# TEST : Loss: (0.9799) | Acc: (65.00%) (6527/10000)
percent tensor([0.5021, 0.5018, 0.5040, 0.5016, 0.5040, 0.5025, 0.5029, 0.5018, 0.5021,
        0.5022, 0.5022, 0.5038, 0.5021, 0.5013, 0.5023, 0.5016],
       device='cuda:0') torch.Size([16])
percent tensor([0.4918, 0.4860, 0.4929, 0.4932, 0.4904, 0.4924, 0.4868, 0.4923, 0.4894,
        0.4894, 0.4879, 0.4915, 0.4906, 0.4844, 0.4887, 0.4907],
       device='cuda:0') torch.Size([16])
percent tensor([0.5162, 0.5174, 0.5177, 0.5125, 0.5168, 0.5159, 0.5202, 0.5158, 0.5127,
        0.5163, 0.5160, 0.5182, 0.5171, 0.5123, 0.5200, 0.5146],
       device='cuda:0') torch.Size([16])
percent tensor([0.5420, 0.5434, 0.5337, 0.5335, 0.5401, 0.5391, 0.5456, 0.5405, 0.5383,
        0.5428, 0.5403, 0.5368, 0.5412, 0.5394, 0.5441, 0.5416],
       device='cuda:0') torch.Size([16])
percent tensor([0.5018, 0.5029, 0.5073, 0.5082, 0.5064, 0.4974, 0.5034, 0.5078, 0.5034,
        0.5061, 0.5039, 0.5056, 0.5030, 0.5027, 0.4977, 0.5035],
       device='cuda:0') torch.Size([16])
percent tensor([0.5124, 0.5119, 0.5159, 0.5178, 0.5170, 0.5131, 0.5134, 0.5214, 0.5096,
        0.5122, 0.5096, 0.5124, 0.5098, 0.5109, 0.5111, 0.5169],
       device='cuda:0') torch.Size([16])
percent tensor([0.5182, 0.5155, 0.5190, 0.5203, 0.5208, 0.5128, 0.5206, 0.5307, 0.5179,
        0.5222, 0.5171, 0.5209, 0.5182, 0.5142, 0.5145, 0.5203],
       device='cuda:0') torch.Size([16])
percent tensor([0.5718, 0.5520, 0.5646, 0.5566, 0.5581, 0.5605, 0.5520, 0.5762, 0.5635,
        0.5699, 0.5690, 0.5669, 0.5688, 0.5678, 0.5725, 0.5809],
       device='cuda:0') torch.Size([16])
Epoch: 9 | Batch_idx: 0 |  Loss: (0.8598) |  Loss2: (0.0000) | Acc: (69.00%) (89/128)
Epoch: 9 | Batch_idx: 10 |  Loss: (0.9679) |  Loss2: (0.0000) | Acc: (66.00%) (940/1408)
Epoch: 9 | Batch_idx: 20 |  Loss: (0.9613) |  Loss2: (0.0000) | Acc: (66.00%) (1787/2688)
Epoch: 9 | Batch_idx: 30 |  Loss: (0.9597) |  Loss2: (0.0000) | Acc: (66.00%) (2639/3968)
Epoch: 9 | Batch_idx: 40 |  Loss: (0.9606) |  Loss2: (0.0000) | Acc: (66.00%) (3490/5248)
Epoch: 9 | Batch_idx: 50 |  Loss: (0.9679) |  Loss2: (0.0000) | Acc: (66.00%) (4318/6528)
Epoch: 9 | Batch_idx: 60 |  Loss: (0.9722) |  Loss2: (0.0000) | Acc: (65.00%) (5127/7808)
Epoch: 9 | Batch_idx: 70 |  Loss: (0.9691) |  Loss2: (0.0000) | Acc: (65.00%) (5991/9088)
Epoch: 9 | Batch_idx: 80 |  Loss: (0.9724) |  Loss2: (0.0000) | Acc: (65.00%) (6828/10368)
Epoch: 9 | Batch_idx: 90 |  Loss: (0.9765) |  Loss2: (0.0000) | Acc: (65.00%) (7676/11648)
Epoch: 9 | Batch_idx: 100 |  Loss: (0.9740) |  Loss2: (0.0000) | Acc: (65.00%) (8525/12928)
Epoch: 9 | Batch_idx: 110 |  Loss: (0.9730) |  Loss2: (0.0000) | Acc: (66.00%) (9384/14208)
Epoch: 9 | Batch_idx: 120 |  Loss: (0.9744) |  Loss2: (0.0000) | Acc: (65.00%) (10201/15488)
Epoch: 9 | Batch_idx: 130 |  Loss: (0.9721) |  Loss2: (0.0000) | Acc: (65.00%) (11046/16768)
Epoch: 9 | Batch_idx: 140 |  Loss: (0.9743) |  Loss2: (0.0000) | Acc: (65.00%) (11864/18048)
Epoch: 9 | Batch_idx: 150 |  Loss: (0.9741) |  Loss2: (0.0000) | Acc: (65.00%) (12710/19328)
Epoch: 9 | Batch_idx: 160 |  Loss: (0.9733) |  Loss2: (0.0000) | Acc: (65.00%) (13546/20608)
Epoch: 9 | Batch_idx: 170 |  Loss: (0.9733) |  Loss2: (0.0000) | Acc: (65.00%) (14397/21888)
Epoch: 9 | Batch_idx: 180 |  Loss: (0.9716) |  Loss2: (0.0000) | Acc: (65.00%) (15266/23168)
Epoch: 9 | Batch_idx: 190 |  Loss: (0.9723) |  Loss2: (0.0000) | Acc: (65.00%) (16094/24448)
Epoch: 9 | Batch_idx: 200 |  Loss: (0.9716) |  Loss2: (0.0000) | Acc: (65.00%) (16944/25728)
Epoch: 9 | Batch_idx: 210 |  Loss: (0.9687) |  Loss2: (0.0000) | Acc: (65.00%) (17820/27008)
Epoch: 9 | Batch_idx: 220 |  Loss: (0.9698) |  Loss2: (0.0000) | Acc: (65.00%) (18632/28288)
Epoch: 9 | Batch_idx: 230 |  Loss: (0.9713) |  Loss2: (0.0000) | Acc: (65.00%) (19463/29568)
Epoch: 9 | Batch_idx: 240 |  Loss: (0.9716) |  Loss2: (0.0000) | Acc: (65.00%) (20271/30848)
Epoch: 9 | Batch_idx: 250 |  Loss: (0.9714) |  Loss2: (0.0000) | Acc: (65.00%) (21106/32128)
Epoch: 9 | Batch_idx: 260 |  Loss: (0.9688) |  Loss2: (0.0000) | Acc: (65.00%) (21986/33408)
Epoch: 9 | Batch_idx: 270 |  Loss: (0.9688) |  Loss2: (0.0000) | Acc: (65.00%) (22812/34688)
Epoch: 9 | Batch_idx: 280 |  Loss: (0.9675) |  Loss2: (0.0000) | Acc: (65.00%) (23669/35968)
Epoch: 9 | Batch_idx: 290 |  Loss: (0.9699) |  Loss2: (0.0000) | Acc: (65.00%) (24479/37248)
Epoch: 9 | Batch_idx: 300 |  Loss: (0.9671) |  Loss2: (0.0000) | Acc: (65.00%) (25351/38528)
Epoch: 9 | Batch_idx: 310 |  Loss: (0.9668) |  Loss2: (0.0000) | Acc: (65.00%) (26206/39808)
Epoch: 9 | Batch_idx: 320 |  Loss: (0.9666) |  Loss2: (0.0000) | Acc: (65.00%) (27042/41088)
Epoch: 9 | Batch_idx: 330 |  Loss: (0.9673) |  Loss2: (0.0000) | Acc: (65.00%) (27866/42368)
Epoch: 9 | Batch_idx: 340 |  Loss: (0.9681) |  Loss2: (0.0000) | Acc: (65.00%) (28705/43648)
Epoch: 9 | Batch_idx: 350 |  Loss: (0.9684) |  Loss2: (0.0000) | Acc: (65.00%) (29539/44928)
Epoch: 9 | Batch_idx: 360 |  Loss: (0.9688) |  Loss2: (0.0000) | Acc: (65.00%) (30383/46208)
Epoch: 9 | Batch_idx: 370 |  Loss: (0.9680) |  Loss2: (0.0000) | Acc: (65.00%) (31247/47488)
Epoch: 9 | Batch_idx: 380 |  Loss: (0.9668) |  Loss2: (0.0000) | Acc: (65.00%) (32097/48768)
Epoch: 9 | Batch_idx: 390 |  Loss: (0.9663) |  Loss2: (0.0000) | Acc: (65.00%) (32899/50000)
# TEST : Loss: (0.9528) | Acc: (66.00%) (6623/10000)
percent tensor([0.5049, 0.5047, 0.5100, 0.5044, 0.5099, 0.5056, 0.5071, 0.5052, 0.5053,
        0.5057, 0.5050, 0.5096, 0.5050, 0.5043, 0.5054, 0.5041],
       device='cuda:0') torch.Size([16])
percent tensor([0.4883, 0.4796, 0.4901, 0.4897, 0.4867, 0.4891, 0.4807, 0.4887, 0.4849,
        0.4843, 0.4827, 0.4876, 0.4863, 0.4771, 0.4837, 0.4865],
       device='cuda:0') torch.Size([16])
percent tensor([0.5237, 0.5246, 0.5256, 0.5176, 0.5244, 0.5232, 0.5293, 0.5221, 0.5179,
        0.5226, 0.5225, 0.5267, 0.5248, 0.5165, 0.5290, 0.5211],
       device='cuda:0') torch.Size([16])
percent tensor([0.5574, 0.5604, 0.5479, 0.5480, 0.5570, 0.5528, 0.5635, 0.5586, 0.5540,
        0.5613, 0.5559, 0.5513, 0.5562, 0.5563, 0.5598, 0.5578],
       device='cuda:0') torch.Size([16])
percent tensor([0.5048, 0.5068, 0.5042, 0.5073, 0.5057, 0.4968, 0.5039, 0.5061, 0.5072,
        0.5107, 0.5086, 0.5009, 0.5072, 0.5069, 0.4958, 0.5071],
       device='cuda:0') torch.Size([16])
percent tensor([0.5218, 0.5205, 0.5269, 0.5300, 0.5291, 0.5232, 0.5227, 0.5363, 0.5164,
        0.5214, 0.5163, 0.5194, 0.5167, 0.5190, 0.5189, 0.5291],
       device='cuda:0') torch.Size([16])
percent tensor([0.5295, 0.5270, 0.5324, 0.5338, 0.5378, 0.5229, 0.5358, 0.5557, 0.5296,
        0.5371, 0.5285, 0.5328, 0.5297, 0.5237, 0.5251, 0.5348],
       device='cuda:0') torch.Size([16])
percent tensor([0.6769, 0.6356, 0.6595, 0.6429, 0.6478, 0.6655, 0.6407, 0.6863, 0.6584,
        0.6754, 0.6744, 0.6604, 0.6682, 0.6663, 0.6656, 0.7013],
       device='cuda:0') torch.Size([16])
Epoch: 10 | Batch_idx: 0 |  Loss: (0.8538) |  Loss2: (0.0000) | Acc: (74.00%) (95/128)
Epoch: 10 | Batch_idx: 10 |  Loss: (0.9386) |  Loss2: (0.0000) | Acc: (66.00%) (942/1408)
Epoch: 10 | Batch_idx: 20 |  Loss: (0.9553) |  Loss2: (0.0000) | Acc: (66.00%) (1792/2688)
Epoch: 10 | Batch_idx: 30 |  Loss: (0.9436) |  Loss2: (0.0000) | Acc: (66.00%) (2636/3968)
Epoch: 10 | Batch_idx: 40 |  Loss: (0.9390) |  Loss2: (0.0000) | Acc: (66.00%) (3474/5248)
Epoch: 10 | Batch_idx: 50 |  Loss: (0.9430) |  Loss2: (0.0000) | Acc: (66.00%) (4317/6528)
Epoch: 10 | Batch_idx: 60 |  Loss: (0.9458) |  Loss2: (0.0000) | Acc: (66.00%) (5160/7808)
Epoch: 10 | Batch_idx: 70 |  Loss: (0.9392) |  Loss2: (0.0000) | Acc: (66.00%) (6032/9088)
Epoch: 10 | Batch_idx: 80 |  Loss: (0.9382) |  Loss2: (0.0000) | Acc: (66.00%) (6891/10368)
Epoch: 10 | Batch_idx: 90 |  Loss: (0.9413) |  Loss2: (0.0000) | Acc: (66.00%) (7717/11648)
Epoch: 10 | Batch_idx: 100 |  Loss: (0.9436) |  Loss2: (0.0000) | Acc: (66.00%) (8547/12928)
Epoch: 10 | Batch_idx: 110 |  Loss: (0.9424) |  Loss2: (0.0000) | Acc: (66.00%) (9389/14208)
Epoch: 10 | Batch_idx: 120 |  Loss: (0.9385) |  Loss2: (0.0000) | Acc: (66.00%) (10265/15488)
Epoch: 10 | Batch_idx: 130 |  Loss: (0.9403) |  Loss2: (0.0000) | Acc: (66.00%) (11108/16768)
Epoch: 10 | Batch_idx: 140 |  Loss: (0.9365) |  Loss2: (0.0000) | Acc: (66.00%) (11984/18048)
Epoch: 10 | Batch_idx: 150 |  Loss: (0.9373) |  Loss2: (0.0000) | Acc: (66.00%) (12851/19328)
Epoch: 10 | Batch_idx: 160 |  Loss: (0.9338) |  Loss2: (0.0000) | Acc: (66.00%) (13720/20608)
Epoch: 10 | Batch_idx: 170 |  Loss: (0.9354) |  Loss2: (0.0000) | Acc: (66.00%) (14565/21888)
Epoch: 10 | Batch_idx: 180 |  Loss: (0.9345) |  Loss2: (0.0000) | Acc: (66.00%) (15441/23168)
Epoch: 10 | Batch_idx: 190 |  Loss: (0.9346) |  Loss2: (0.0000) | Acc: (66.00%) (16307/24448)
Epoch: 10 | Batch_idx: 200 |  Loss: (0.9347) |  Loss2: (0.0000) | Acc: (66.00%) (17168/25728)
Epoch: 10 | Batch_idx: 210 |  Loss: (0.9353) |  Loss2: (0.0000) | Acc: (66.00%) (18021/27008)
Epoch: 10 | Batch_idx: 220 |  Loss: (0.9378) |  Loss2: (0.0000) | Acc: (66.00%) (18827/28288)
Epoch: 10 | Batch_idx: 230 |  Loss: (0.9383) |  Loss2: (0.0000) | Acc: (66.00%) (19667/29568)
Epoch: 10 | Batch_idx: 240 |  Loss: (0.9390) |  Loss2: (0.0000) | Acc: (66.00%) (20513/30848)
Epoch: 10 | Batch_idx: 250 |  Loss: (0.9395) |  Loss2: (0.0000) | Acc: (66.00%) (21351/32128)
Epoch: 10 | Batch_idx: 260 |  Loss: (0.9389) |  Loss2: (0.0000) | Acc: (66.00%) (22189/33408)
Epoch: 10 | Batch_idx: 270 |  Loss: (0.9385) |  Loss2: (0.0000) | Acc: (66.00%) (23047/34688)
Epoch: 10 | Batch_idx: 280 |  Loss: (0.9379) |  Loss2: (0.0000) | Acc: (66.00%) (23904/35968)
Epoch: 10 | Batch_idx: 290 |  Loss: (0.9390) |  Loss2: (0.0000) | Acc: (66.00%) (24741/37248)
Epoch: 10 | Batch_idx: 300 |  Loss: (0.9387) |  Loss2: (0.0000) | Acc: (66.00%) (25606/38528)
Epoch: 10 | Batch_idx: 310 |  Loss: (0.9380) |  Loss2: (0.0000) | Acc: (66.00%) (26454/39808)
Epoch: 10 | Batch_idx: 320 |  Loss: (0.9383) |  Loss2: (0.0000) | Acc: (66.00%) (27303/41088)
Epoch: 10 | Batch_idx: 330 |  Loss: (0.9388) |  Loss2: (0.0000) | Acc: (66.00%) (28144/42368)
Epoch: 10 | Batch_idx: 340 |  Loss: (0.9383) |  Loss2: (0.0000) | Acc: (66.00%) (29008/43648)
Epoch: 10 | Batch_idx: 350 |  Loss: (0.9384) |  Loss2: (0.0000) | Acc: (66.00%) (29858/44928)
Epoch: 10 | Batch_idx: 360 |  Loss: (0.9396) |  Loss2: (0.0000) | Acc: (66.00%) (30688/46208)
Epoch: 10 | Batch_idx: 370 |  Loss: (0.9401) |  Loss2: (0.0000) | Acc: (66.00%) (31523/47488)
Epoch: 10 | Batch_idx: 380 |  Loss: (0.9396) |  Loss2: (0.0000) | Acc: (66.00%) (32383/48768)
Epoch: 10 | Batch_idx: 390 |  Loss: (0.9385) |  Loss2: (0.0000) | Acc: (66.00%) (33196/50000)
=> saving checkpoint 'drive/app/torch/save_Schedule/checkpoint_010.pth.tar'
# TEST : Loss: (0.9447) | Acc: (66.00%) (6667/10000)
percent tensor([0.5068, 0.5068, 0.5137, 0.5058, 0.5138, 0.5077, 0.5100, 0.5073, 0.5075,
        0.5080, 0.5068, 0.5132, 0.5067, 0.5068, 0.5075, 0.5058],
       device='cuda:0') torch.Size([16])
percent tensor([0.4876, 0.4779, 0.4897, 0.4887, 0.4861, 0.4884, 0.4792, 0.4879, 0.4841,
        0.4831, 0.4815, 0.4869, 0.4854, 0.4749, 0.4823, 0.4855],
       device='cuda:0') torch.Size([16])
percent tensor([0.5284, 0.5285, 0.5291, 0.5199, 0.5283, 0.5287, 0.5340, 0.5247, 0.5205,
        0.5255, 0.5261, 0.5307, 0.5290, 0.5186, 0.5344, 0.5251],
       device='cuda:0') torch.Size([16])
percent tensor([0.5655, 0.5701, 0.5562, 0.5559, 0.5670, 0.5597, 0.5734, 0.5695, 0.5633,
        0.5721, 0.5647, 0.5594, 0.5641, 0.5663, 0.5682, 0.5666],
       device='cuda:0') torch.Size([16])
percent tensor([0.5085, 0.5119, 0.5012, 0.5065, 0.5054, 0.4961, 0.5054, 0.5050, 0.5118,
        0.5163, 0.5141, 0.4967, 0.5121, 0.5121, 0.4947, 0.5114],
       device='cuda:0') torch.Size([16])
percent tensor([0.5288, 0.5270, 0.5354, 0.5397, 0.5388, 0.5305, 0.5299, 0.5485, 0.5218,
        0.5289, 0.5214, 0.5250, 0.5217, 0.5254, 0.5247, 0.5386],
       device='cuda:0') torch.Size([16])
percent tensor([0.5324, 0.5314, 0.5397, 0.5415, 0.5483, 0.5249, 0.5434, 0.5734, 0.5333,
        0.5429, 0.5313, 0.5378, 0.5315, 0.5259, 0.5301, 0.5410],
       device='cuda:0') torch.Size([16])
percent tensor([0.7198, 0.6768, 0.7055, 0.6871, 0.6921, 0.7128, 0.6814, 0.7430, 0.7045,
        0.7212, 0.7268, 0.7053, 0.7139, 0.7114, 0.7108, 0.7483],
       device='cuda:0') torch.Size([16])
Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 3, 3, 3]) tensor(172.8428, device='cuda:0')
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(774.8228, device='cuda:0')
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(776.2842, device='cuda:0')
Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([128, 64, 3, 3]) tensor(1535.1558, device='cuda:0')
Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([128, 64, 1, 1]) tensor(506.8416, device='cuda:0')
Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([128, 128, 3, 3]) tensor(2171.8594, device='cuda:0')
Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([256, 128, 3, 3]) tensor(4331.1123, device='cuda:0')
Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([256, 128, 1, 1]) tensor(1436.3712, device='cuda:0')
Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([256, 256, 3, 3]) tensor(6109.6372, device='cuda:0')
Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([512, 256, 3, 3]) tensor(12233.6592, device='cuda:0')
Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([512, 256, 1, 1]) tensor(4081.2832, device='cuda:0')
Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([512, 512, 3, 3]) tensor(17275.4941, device='cuda:0')
Epoch: 11 | Batch_idx: 0 |  Loss: (0.8892) |  Loss2: (0.0000) | Acc: (66.00%) (85/128)
Epoch: 11 | Batch_idx: 10 |  Loss: (0.9167) |  Loss2: (0.0000) | Acc: (66.00%) (939/1408)
Epoch: 11 | Batch_idx: 20 |  Loss: (0.9301) |  Loss2: (0.0000) | Acc: (66.00%) (1784/2688)
Epoch: 11 | Batch_idx: 30 |  Loss: (0.9395) |  Loss2: (0.0000) | Acc: (65.00%) (2597/3968)
Epoch: 11 | Batch_idx: 40 |  Loss: (0.9400) |  Loss2: (0.0000) | Acc: (65.00%) (3433/5248)
Epoch: 11 | Batch_idx: 50 |  Loss: (0.9357) |  Loss2: (0.0000) | Acc: (65.00%) (4279/6528)
Epoch: 11 | Batch_idx: 60 |  Loss: (0.9302) |  Loss2: (0.0000) | Acc: (66.00%) (5155/7808)
Epoch: 11 | Batch_idx: 70 |  Loss: (0.9265) |  Loss2: (0.0000) | Acc: (66.00%) (6017/9088)
Epoch: 11 | Batch_idx: 80 |  Loss: (0.9245) |  Loss2: (0.0000) | Acc: (66.00%) (6874/10368)
Epoch: 11 | Batch_idx: 90 |  Loss: (0.9245) |  Loss2: (0.0000) | Acc: (66.00%) (7726/11648)
Epoch: 11 | Batch_idx: 100 |  Loss: (0.9244) |  Loss2: (0.0000) | Acc: (66.00%) (8589/12928)
Epoch: 11 | Batch_idx: 110 |  Loss: (0.9240) |  Loss2: (0.0000) | Acc: (66.00%) (9445/14208)
Epoch: 11 | Batch_idx: 120 |  Loss: (0.9215) |  Loss2: (0.0000) | Acc: (66.00%) (10314/15488)
Epoch: 11 | Batch_idx: 130 |  Loss: (0.9212) |  Loss2: (0.0000) | Acc: (66.00%) (11183/16768)
Epoch: 11 | Batch_idx: 140 |  Loss: (0.9222) |  Loss2: (0.0000) | Acc: (66.00%) (12025/18048)
Epoch: 11 | Batch_idx: 150 |  Loss: (0.9217) |  Loss2: (0.0000) | Acc: (66.00%) (12885/19328)
Epoch: 11 | Batch_idx: 160 |  Loss: (0.9231) |  Loss2: (0.0000) | Acc: (66.00%) (13740/20608)
Epoch: 11 | Batch_idx: 170 |  Loss: (0.9251) |  Loss2: (0.0000) | Acc: (66.00%) (14593/21888)
Epoch: 11 | Batch_idx: 180 |  Loss: (0.9256) |  Loss2: (0.0000) | Acc: (66.00%) (15450/23168)
Epoch: 11 | Batch_idx: 190 |  Loss: (0.9252) |  Loss2: (0.0000) | Acc: (66.00%) (16318/24448)
Epoch: 11 | Batch_idx: 200 |  Loss: (0.9240) |  Loss2: (0.0000) | Acc: (66.00%) (17185/25728)
Epoch: 11 | Batch_idx: 210 |  Loss: (0.9234) |  Loss2: (0.0000) | Acc: (66.00%) (18034/27008)
Epoch: 11 | Batch_idx: 220 |  Loss: (0.9271) |  Loss2: (0.0000) | Acc: (66.00%) (18847/28288)
Epoch: 11 | Batch_idx: 230 |  Loss: (0.9274) |  Loss2: (0.0000) | Acc: (66.00%) (19694/29568)
Epoch: 11 | Batch_idx: 240 |  Loss: (0.9256) |  Loss2: (0.0000) | Acc: (66.00%) (20582/30848)
Epoch: 11 | Batch_idx: 250 |  Loss: (0.9262) |  Loss2: (0.0000) | Acc: (66.00%) (21440/32128)
Epoch: 11 | Batch_idx: 260 |  Loss: (0.9258) |  Loss2: (0.0000) | Acc: (66.00%) (22300/33408)
Epoch: 11 | Batch_idx: 270 |  Loss: (0.9248) |  Loss2: (0.0000) | Acc: (66.00%) (23163/34688)
Epoch: 11 | Batch_idx: 280 |  Loss: (0.9246) |  Loss2: (0.0000) | Acc: (66.00%) (24033/35968)
Epoch: 11 | Batch_idx: 290 |  Loss: (0.9243) |  Loss2: (0.0000) | Acc: (66.00%) (24907/37248)
Epoch: 11 | Batch_idx: 300 |  Loss: (0.9244) |  Loss2: (0.0000) | Acc: (66.00%) (25775/38528)
Epoch: 11 | Batch_idx: 310 |  Loss: (0.9253) |  Loss2: (0.0000) | Acc: (66.00%) (26627/39808)
Epoch: 11 | Batch_idx: 320 |  Loss: (0.9244) |  Loss2: (0.0000) | Acc: (66.00%) (27499/41088)
Epoch: 11 | Batch_idx: 330 |  Loss: (0.9242) |  Loss2: (0.0000) | Acc: (66.00%) (28371/42368)
Epoch: 11 | Batch_idx: 340 |  Loss: (0.9242) |  Loss2: (0.0000) | Acc: (66.00%) (29239/43648)
Epoch: 11 | Batch_idx: 350 |  Loss: (0.9247) |  Loss2: (0.0000) | Acc: (66.00%) (30069/44928)
Epoch: 11 | Batch_idx: 360 |  Loss: (0.9241) |  Loss2: (0.0000) | Acc: (66.00%) (30939/46208)
Epoch: 11 | Batch_idx: 370 |  Loss: (0.9242) |  Loss2: (0.0000) | Acc: (66.00%) (31797/47488)
Epoch: 11 | Batch_idx: 380 |  Loss: (0.9241) |  Loss2: (0.0000) | Acc: (66.00%) (32646/48768)
Epoch: 11 | Batch_idx: 390 |  Loss: (0.9235) |  Loss2: (0.0000) | Acc: (66.00%) (33473/50000)
# TEST : Loss: (0.9380) | Acc: (67.00%) (6701/10000)
percent tensor([0.5076, 0.5079, 0.5154, 0.5061, 0.5157, 0.5087, 0.5114, 0.5080, 0.5086,
        0.5089, 0.5078, 0.5149, 0.5074, 0.5084, 0.5083, 0.5065],
       device='cuda:0') torch.Size([16])
percent tensor([0.4873, 0.4770, 0.4897, 0.4881, 0.4861, 0.4883, 0.4783, 0.4874, 0.4837,
        0.4825, 0.4810, 0.4865, 0.4850, 0.4736, 0.4816, 0.4850],
       device='cuda:0') torch.Size([16])
percent tensor([0.5302, 0.5298, 0.5285, 0.5193, 0.5283, 0.5314, 0.5353, 0.5236, 0.5210,
        0.5258, 0.5275, 0.5309, 0.5306, 0.5189, 0.5364, 0.5266],
       device='cuda:0') torch.Size([16])
percent tensor([0.5646, 0.5696, 0.5560, 0.5563, 0.5672, 0.5589, 0.5727, 0.5704, 0.5636,
        0.5723, 0.5642, 0.5585, 0.5632, 0.5671, 0.5667, 0.5662],
       device='cuda:0') torch.Size([16])
percent tensor([0.5119, 0.5145, 0.4974, 0.5054, 0.5041, 0.4966, 0.5048, 0.5023, 0.5146,
        0.5190, 0.5168, 0.4915, 0.5151, 0.5155, 0.4933, 0.5147],
       device='cuda:0') torch.Size([16])
percent tensor([0.5331, 0.5305, 0.5403, 0.5456, 0.5448, 0.5357, 0.5335, 0.5552, 0.5250,
        0.5331, 0.5237, 0.5276, 0.5247, 0.5296, 0.5271, 0.5443],
       device='cuda:0') torch.Size([16])
percent tensor([0.5341, 0.5341, 0.5441, 0.5461, 0.5566, 0.5263, 0.5477, 0.5859, 0.5350,
        0.5458, 0.5320, 0.5402, 0.5322, 0.5267, 0.5324, 0.5454],
       device='cuda:0') torch.Size([16])
percent tensor([0.7433, 0.6998, 0.7326, 0.7135, 0.7220, 0.7412, 0.7027, 0.7733, 0.7276,
        0.7437, 0.7541, 0.7305, 0.7372, 0.7336, 0.7338, 0.7692],
       device='cuda:0') torch.Size([16])
Epoch: 12 | Batch_idx: 0 |  Loss: (1.0494) |  Loss2: (0.0000) | Acc: (63.00%) (81/128)
Epoch: 12 | Batch_idx: 10 |  Loss: (0.9670) |  Loss2: (0.0000) | Acc: (65.00%) (918/1408)
Epoch: 12 | Batch_idx: 20 |  Loss: (0.9323) |  Loss2: (0.0000) | Acc: (66.00%) (1781/2688)
Epoch: 12 | Batch_idx: 30 |  Loss: (0.9335) |  Loss2: (0.0000) | Acc: (66.00%) (2623/3968)
Epoch: 12 | Batch_idx: 40 |  Loss: (0.9313) |  Loss2: (0.0000) | Acc: (66.00%) (3495/5248)
Epoch: 12 | Batch_idx: 50 |  Loss: (0.9340) |  Loss2: (0.0000) | Acc: (66.00%) (4321/6528)
Epoch: 12 | Batch_idx: 60 |  Loss: (0.9400) |  Loss2: (0.0000) | Acc: (66.00%) (5178/7808)
Epoch: 12 | Batch_idx: 70 |  Loss: (0.9433) |  Loss2: (0.0000) | Acc: (66.00%) (6017/9088)
Epoch: 12 | Batch_idx: 80 |  Loss: (0.9393) |  Loss2: (0.0000) | Acc: (66.00%) (6874/10368)
Epoch: 12 | Batch_idx: 90 |  Loss: (0.9412) |  Loss2: (0.0000) | Acc: (66.00%) (7697/11648)
Epoch: 12 | Batch_idx: 100 |  Loss: (0.9432) |  Loss2: (0.0000) | Acc: (65.00%) (8530/12928)
Epoch: 12 | Batch_idx: 110 |  Loss: (0.9408) |  Loss2: (0.0000) | Acc: (66.00%) (9396/14208)
Epoch: 12 | Batch_idx: 120 |  Loss: (0.9386) |  Loss2: (0.0000) | Acc: (66.00%) (10247/15488)
Epoch: 12 | Batch_idx: 130 |  Loss: (0.9330) |  Loss2: (0.0000) | Acc: (66.00%) (11129/16768)
Epoch: 12 | Batch_idx: 140 |  Loss: (0.9338) |  Loss2: (0.0000) | Acc: (66.00%) (11974/18048)
Epoch: 12 | Batch_idx: 150 |  Loss: (0.9312) |  Loss2: (0.0000) | Acc: (66.00%) (12840/19328)
Epoch: 12 | Batch_idx: 160 |  Loss: (0.9322) |  Loss2: (0.0000) | Acc: (66.00%) (13697/20608)
Epoch: 12 | Batch_idx: 170 |  Loss: (0.9316) |  Loss2: (0.0000) | Acc: (66.00%) (14555/21888)
Epoch: 12 | Batch_idx: 180 |  Loss: (0.9311) |  Loss2: (0.0000) | Acc: (66.00%) (15408/23168)
Epoch: 12 | Batch_idx: 190 |  Loss: (0.9324) |  Loss2: (0.0000) | Acc: (66.00%) (16247/24448)
Epoch: 12 | Batch_idx: 200 |  Loss: (0.9318) |  Loss2: (0.0000) | Acc: (66.00%) (17108/25728)
Epoch: 12 | Batch_idx: 210 |  Loss: (0.9300) |  Loss2: (0.0000) | Acc: (66.00%) (17976/27008)
Epoch: 12 | Batch_idx: 220 |  Loss: (0.9290) |  Loss2: (0.0000) | Acc: (66.00%) (18856/28288)
Epoch: 12 | Batch_idx: 230 |  Loss: (0.9278) |  Loss2: (0.0000) | Acc: (66.00%) (19729/29568)
Epoch: 12 | Batch_idx: 240 |  Loss: (0.9247) |  Loss2: (0.0000) | Acc: (66.00%) (20626/30848)
Epoch: 12 | Batch_idx: 250 |  Loss: (0.9253) |  Loss2: (0.0000) | Acc: (66.00%) (21471/32128)
Epoch: 12 | Batch_idx: 260 |  Loss: (0.9249) |  Loss2: (0.0000) | Acc: (66.00%) (22328/33408)
Epoch: 12 | Batch_idx: 270 |  Loss: (0.9242) |  Loss2: (0.0000) | Acc: (66.00%) (23195/34688)
Epoch: 12 | Batch_idx: 280 |  Loss: (0.9250) |  Loss2: (0.0000) | Acc: (66.00%) (24030/35968)
Epoch: 12 | Batch_idx: 290 |  Loss: (0.9260) |  Loss2: (0.0000) | Acc: (66.00%) (24882/37248)
Epoch: 12 | Batch_idx: 300 |  Loss: (0.9257) |  Loss2: (0.0000) | Acc: (66.00%) (25758/38528)
Epoch: 12 | Batch_idx: 310 |  Loss: (0.9259) |  Loss2: (0.0000) | Acc: (66.00%) (26607/39808)
Epoch: 12 | Batch_idx: 320 |  Loss: (0.9268) |  Loss2: (0.0000) | Acc: (66.00%) (27450/41088)
Epoch: 12 | Batch_idx: 330 |  Loss: (0.9278) |  Loss2: (0.0000) | Acc: (66.00%) (28297/42368)
Epoch: 12 | Batch_idx: 340 |  Loss: (0.9286) |  Loss2: (0.0000) | Acc: (66.00%) (29141/43648)
Epoch: 12 | Batch_idx: 350 |  Loss: (0.9284) |  Loss2: (0.0000) | Acc: (66.00%) (30019/44928)
Epoch: 12 | Batch_idx: 360 |  Loss: (0.9276) |  Loss2: (0.0000) | Acc: (66.00%) (30879/46208)
Epoch: 12 | Batch_idx: 370 |  Loss: (0.9286) |  Loss2: (0.0000) | Acc: (66.00%) (31723/47488)
Epoch: 12 | Batch_idx: 380 |  Loss: (0.9281) |  Loss2: (0.0000) | Acc: (66.00%) (32611/48768)
Epoch: 12 | Batch_idx: 390 |  Loss: (0.9269) |  Loss2: (0.0000) | Acc: (66.00%) (33461/50000)
# TEST : Loss: (0.9325) | Acc: (67.00%) (6701/10000)
percent tensor([0.5081, 0.5089, 0.5164, 0.5061, 0.5169, 0.5095, 0.5124, 0.5084, 0.5096,
        0.5094, 0.5086, 0.5159, 0.5078, 0.5098, 0.5089, 0.5072],
       device='cuda:0') torch.Size([16])
percent tensor([0.4872, 0.4765, 0.4892, 0.4873, 0.4857, 0.4885, 0.4778, 0.4868, 0.4836,
        0.4820, 0.4810, 0.4858, 0.4848, 0.4732, 0.4813, 0.4847],
       device='cuda:0') torch.Size([16])
percent tensor([0.5304, 0.5294, 0.5277, 0.5188, 0.5281, 0.5323, 0.5349, 0.5222, 0.5204,
        0.5249, 0.5270, 0.5303, 0.5304, 0.5181, 0.5365, 0.5265],
       device='cuda:0') torch.Size([16])
percent tensor([0.5620, 0.5674, 0.5533, 0.5544, 0.5647, 0.5567, 0.5699, 0.5683, 0.5616,
        0.5702, 0.5617, 0.5554, 0.5607, 0.5660, 0.5637, 0.5639],
       device='cuda:0') torch.Size([16])
percent tensor([0.5178, 0.5209, 0.4950, 0.5052, 0.5045, 0.4976, 0.5076, 0.5015, 0.5207,
        0.5260, 0.5233, 0.4882, 0.5218, 0.5229, 0.4942, 0.5210],
       device='cuda:0') torch.Size([16])
percent tensor([0.5347, 0.5319, 0.5410, 0.5472, 0.5468, 0.5373, 0.5343, 0.5571, 0.5263,
        0.5348, 0.5242, 0.5270, 0.5261, 0.5315, 0.5268, 0.5465],
       device='cuda:0') torch.Size([16])
percent tensor([0.5355, 0.5375, 0.5476, 0.5506, 0.5646, 0.5262, 0.5522, 0.5981, 0.5386,
        0.5505, 0.5342, 0.5430, 0.5344, 0.5290, 0.5359, 0.5484],
       device='cuda:0') torch.Size([16])
percent tensor([0.7437, 0.7030, 0.7260, 0.7096, 0.7161, 0.7429, 0.7026, 0.7665, 0.7333,
        0.7459, 0.7566, 0.7266, 0.7424, 0.7371, 0.7337, 0.7661],
       device='cuda:0') torch.Size([16])
Epoch: 13 | Batch_idx: 0 |  Loss: (0.9837) |  Loss2: (0.0000) | Acc: (63.00%) (81/128)
Epoch: 13 | Batch_idx: 10 |  Loss: (0.9126) |  Loss2: (0.0000) | Acc: (67.00%) (944/1408)
Epoch: 13 | Batch_idx: 20 |  Loss: (0.9069) |  Loss2: (0.0000) | Acc: (66.00%) (1800/2688)
Epoch: 13 | Batch_idx: 30 |  Loss: (0.9083) |  Loss2: (0.0000) | Acc: (66.00%) (2657/3968)
Epoch: 13 | Batch_idx: 40 |  Loss: (0.9116) |  Loss2: (0.0000) | Acc: (66.00%) (3495/5248)
Epoch: 13 | Batch_idx: 50 |  Loss: (0.9106) |  Loss2: (0.0000) | Acc: (66.00%) (4368/6528)
Epoch: 13 | Batch_idx: 60 |  Loss: (0.9160) |  Loss2: (0.0000) | Acc: (66.00%) (5230/7808)
Epoch: 13 | Batch_idx: 70 |  Loss: (0.9220) |  Loss2: (0.0000) | Acc: (66.00%) (6056/9088)
Epoch: 13 | Batch_idx: 80 |  Loss: (0.9219) |  Loss2: (0.0000) | Acc: (66.00%) (6923/10368)
Epoch: 13 | Batch_idx: 90 |  Loss: (0.9220) |  Loss2: (0.0000) | Acc: (66.00%) (7773/11648)
Epoch: 13 | Batch_idx: 100 |  Loss: (0.9272) |  Loss2: (0.0000) | Acc: (66.00%) (8611/12928)
Epoch: 13 | Batch_idx: 110 |  Loss: (0.9274) |  Loss2: (0.0000) | Acc: (66.00%) (9463/14208)
Epoch: 13 | Batch_idx: 120 |  Loss: (0.9230) |  Loss2: (0.0000) | Acc: (66.00%) (10343/15488)
Epoch: 13 | Batch_idx: 130 |  Loss: (0.9220) |  Loss2: (0.0000) | Acc: (66.00%) (11214/16768)
Epoch: 13 | Batch_idx: 140 |  Loss: (0.9222) |  Loss2: (0.0000) | Acc: (66.00%) (12058/18048)
Epoch: 13 | Batch_idx: 150 |  Loss: (0.9189) |  Loss2: (0.0000) | Acc: (66.00%) (12941/19328)
Epoch: 13 | Batch_idx: 160 |  Loss: (0.9189) |  Loss2: (0.0000) | Acc: (66.00%) (13784/20608)
Epoch: 13 | Batch_idx: 170 |  Loss: (0.9197) |  Loss2: (0.0000) | Acc: (66.00%) (14654/21888)
Epoch: 13 | Batch_idx: 180 |  Loss: (0.9202) |  Loss2: (0.0000) | Acc: (66.00%) (15501/23168)
Epoch: 13 | Batch_idx: 190 |  Loss: (0.9227) |  Loss2: (0.0000) | Acc: (66.00%) (16326/24448)
Epoch: 13 | Batch_idx: 200 |  Loss: (0.9224) |  Loss2: (0.0000) | Acc: (66.00%) (17172/25728)
Epoch: 13 | Batch_idx: 210 |  Loss: (0.9227) |  Loss2: (0.0000) | Acc: (66.00%) (18019/27008)
Epoch: 13 | Batch_idx: 220 |  Loss: (0.9233) |  Loss2: (0.0000) | Acc: (66.00%) (18875/28288)
Epoch: 13 | Batch_idx: 230 |  Loss: (0.9241) |  Loss2: (0.0000) | Acc: (66.00%) (19728/29568)
Epoch: 13 | Batch_idx: 240 |  Loss: (0.9235) |  Loss2: (0.0000) | Acc: (66.00%) (20577/30848)
Epoch: 13 | Batch_idx: 250 |  Loss: (0.9236) |  Loss2: (0.0000) | Acc: (66.00%) (21448/32128)
Epoch: 13 | Batch_idx: 260 |  Loss: (0.9220) |  Loss2: (0.0000) | Acc: (66.00%) (22318/33408)
Epoch: 13 | Batch_idx: 270 |  Loss: (0.9208) |  Loss2: (0.0000) | Acc: (66.00%) (23192/34688)
Epoch: 13 | Batch_idx: 280 |  Loss: (0.9228) |  Loss2: (0.0000) | Acc: (66.00%) (24019/35968)
Epoch: 13 | Batch_idx: 290 |  Loss: (0.9215) |  Loss2: (0.0000) | Acc: (66.00%) (24887/37248)
Epoch: 13 | Batch_idx: 300 |  Loss: (0.9224) |  Loss2: (0.0000) | Acc: (66.00%) (25726/38528)
Epoch: 13 | Batch_idx: 310 |  Loss: (0.9226) |  Loss2: (0.0000) | Acc: (66.00%) (26579/39808)
Epoch: 13 | Batch_idx: 320 |  Loss: (0.9223) |  Loss2: (0.0000) | Acc: (66.00%) (27452/41088)
Epoch: 13 | Batch_idx: 330 |  Loss: (0.9203) |  Loss2: (0.0000) | Acc: (66.00%) (28348/42368)
Epoch: 13 | Batch_idx: 340 |  Loss: (0.9198) |  Loss2: (0.0000) | Acc: (66.00%) (29210/43648)
Epoch: 13 | Batch_idx: 350 |  Loss: (0.9205) |  Loss2: (0.0000) | Acc: (66.00%) (30065/44928)
Epoch: 13 | Batch_idx: 360 |  Loss: (0.9200) |  Loss2: (0.0000) | Acc: (66.00%) (30931/46208)
Epoch: 13 | Batch_idx: 370 |  Loss: (0.9204) |  Loss2: (0.0000) | Acc: (66.00%) (31807/47488)
Epoch: 13 | Batch_idx: 380 |  Loss: (0.9192) |  Loss2: (0.0000) | Acc: (67.00%) (32682/48768)
Epoch: 13 | Batch_idx: 390 |  Loss: (0.9192) |  Loss2: (0.0000) | Acc: (67.00%) (33513/50000)
# TEST : Loss: (0.9281) | Acc: (67.00%) (6707/10000)
percent tensor([0.5075, 0.5089, 0.5157, 0.5051, 0.5164, 0.5091, 0.5120, 0.5076, 0.5092,
        0.5089, 0.5083, 0.5152, 0.5071, 0.5104, 0.5083, 0.5068],
       device='cuda:0') torch.Size([16])
percent tensor([0.4878, 0.4767, 0.4897, 0.4876, 0.4862, 0.4890, 0.4781, 0.4872, 0.4842,
        0.4824, 0.4815, 0.4865, 0.4853, 0.4731, 0.4815, 0.4850],
       device='cuda:0') torch.Size([16])
percent tensor([0.5309, 0.5294, 0.5270, 0.5183, 0.5276, 0.5333, 0.5344, 0.5211, 0.5199,
        0.5244, 0.5271, 0.5293, 0.5306, 0.5176, 0.5366, 0.5268],
       device='cuda:0') torch.Size([16])
percent tensor([0.5625, 0.5682, 0.5550, 0.5560, 0.5668, 0.5573, 0.5708, 0.5708, 0.5636,
        0.5715, 0.5628, 0.5562, 0.5610, 0.5679, 0.5641, 0.5649],
       device='cuda:0') torch.Size([16])
percent tensor([0.5233, 0.5266, 0.4941, 0.5068, 0.5063, 0.4983, 0.5104, 0.5034, 0.5267,
        0.5326, 0.5292, 0.4869, 0.5279, 0.5300, 0.4954, 0.5269],
       device='cuda:0') torch.Size([16])
percent tensor([0.5357, 0.5325, 0.5442, 0.5510, 0.5505, 0.5395, 0.5353, 0.5611, 0.5275,
        0.5360, 0.5241, 0.5284, 0.5265, 0.5329, 0.5267, 0.5490],
       device='cuda:0') torch.Size([16])
percent tensor([0.5351, 0.5379, 0.5547, 0.5580, 0.5728, 0.5260, 0.5548, 0.6099, 0.5393,
        0.5524, 0.5345, 0.5475, 0.5334, 0.5290, 0.5366, 0.5506],
       device='cuda:0') torch.Size([16])
percent tensor([0.7492, 0.7101, 0.7423, 0.7261, 0.7325, 0.7543, 0.7061, 0.7831, 0.7426,
        0.7517, 0.7712, 0.7401, 0.7536, 0.7453, 0.7447, 0.7700],
       device='cuda:0') torch.Size([16])
Epoch: 14 | Batch_idx: 0 |  Loss: (0.7962) |  Loss2: (0.0000) | Acc: (71.00%) (92/128)
Epoch: 14 | Batch_idx: 10 |  Loss: (0.8961) |  Loss2: (0.0000) | Acc: (67.00%) (950/1408)
Epoch: 14 | Batch_idx: 20 |  Loss: (0.8898) |  Loss2: (0.0000) | Acc: (68.00%) (1833/2688)
Epoch: 14 | Batch_idx: 30 |  Loss: (0.9015) |  Loss2: (0.0000) | Acc: (68.00%) (2700/3968)
Epoch: 14 | Batch_idx: 40 |  Loss: (0.9059) |  Loss2: (0.0000) | Acc: (67.00%) (3543/5248)
Epoch: 14 | Batch_idx: 50 |  Loss: (0.9150) |  Loss2: (0.0000) | Acc: (67.00%) (4390/6528)
Epoch: 14 | Batch_idx: 60 |  Loss: (0.9196) |  Loss2: (0.0000) | Acc: (67.00%) (5244/7808)
Epoch: 14 | Batch_idx: 70 |  Loss: (0.9167) |  Loss2: (0.0000) | Acc: (67.00%) (6113/9088)
Epoch: 14 | Batch_idx: 80 |  Loss: (0.9197) |  Loss2: (0.0000) | Acc: (67.00%) (6950/10368)
Epoch: 14 | Batch_idx: 90 |  Loss: (0.9181) |  Loss2: (0.0000) | Acc: (66.00%) (7798/11648)
Epoch: 14 | Batch_idx: 100 |  Loss: (0.9157) |  Loss2: (0.0000) | Acc: (67.00%) (8680/12928)
Epoch: 14 | Batch_idx: 110 |  Loss: (0.9122) |  Loss2: (0.0000) | Acc: (67.00%) (9555/14208)
Epoch: 14 | Batch_idx: 120 |  Loss: (0.9135) |  Loss2: (0.0000) | Acc: (67.00%) (10404/15488)
Epoch: 14 | Batch_idx: 130 |  Loss: (0.9141) |  Loss2: (0.0000) | Acc: (67.00%) (11279/16768)
Epoch: 14 | Batch_idx: 140 |  Loss: (0.9137) |  Loss2: (0.0000) | Acc: (67.00%) (12150/18048)
Epoch: 14 | Batch_idx: 150 |  Loss: (0.9128) |  Loss2: (0.0000) | Acc: (67.00%) (13025/19328)
Epoch: 14 | Batch_idx: 160 |  Loss: (0.9187) |  Loss2: (0.0000) | Acc: (67.00%) (13843/20608)
Epoch: 14 | Batch_idx: 170 |  Loss: (0.9169) |  Loss2: (0.0000) | Acc: (67.00%) (14715/21888)
Epoch: 14 | Batch_idx: 180 |  Loss: (0.9173) |  Loss2: (0.0000) | Acc: (67.00%) (15565/23168)
Epoch: 14 | Batch_idx: 190 |  Loss: (0.9175) |  Loss2: (0.0000) | Acc: (67.00%) (16425/24448)
Epoch: 14 | Batch_idx: 200 |  Loss: (0.9181) |  Loss2: (0.0000) | Acc: (67.00%) (17287/25728)
Epoch: 14 | Batch_idx: 210 |  Loss: (0.9179) |  Loss2: (0.0000) | Acc: (67.00%) (18146/27008)
Epoch: 14 | Batch_idx: 220 |  Loss: (0.9173) |  Loss2: (0.0000) | Acc: (67.00%) (19005/28288)
Epoch: 14 | Batch_idx: 230 |  Loss: (0.9189) |  Loss2: (0.0000) | Acc: (67.00%) (19828/29568)
Epoch: 14 | Batch_idx: 240 |  Loss: (0.9185) |  Loss2: (0.0000) | Acc: (67.00%) (20678/30848)
Epoch: 14 | Batch_idx: 250 |  Loss: (0.9189) |  Loss2: (0.0000) | Acc: (67.00%) (21526/32128)
Epoch: 14 | Batch_idx: 260 |  Loss: (0.9201) |  Loss2: (0.0000) | Acc: (66.00%) (22370/33408)
Epoch: 14 | Batch_idx: 270 |  Loss: (0.9203) |  Loss2: (0.0000) | Acc: (66.00%) (23216/34688)
Epoch: 14 | Batch_idx: 280 |  Loss: (0.9207) |  Loss2: (0.0000) | Acc: (66.00%) (24069/35968)
Epoch: 14 | Batch_idx: 290 |  Loss: (0.9216) |  Loss2: (0.0000) | Acc: (66.00%) (24919/37248)
Epoch: 14 | Batch_idx: 300 |  Loss: (0.9192) |  Loss2: (0.0000) | Acc: (66.00%) (25810/38528)
Epoch: 14 | Batch_idx: 310 |  Loss: (0.9191) |  Loss2: (0.0000) | Acc: (66.00%) (26656/39808)
Epoch: 14 | Batch_idx: 320 |  Loss: (0.9188) |  Loss2: (0.0000) | Acc: (66.00%) (27516/41088)
Epoch: 14 | Batch_idx: 330 |  Loss: (0.9164) |  Loss2: (0.0000) | Acc: (67.00%) (28416/42368)
Epoch: 14 | Batch_idx: 340 |  Loss: (0.9150) |  Loss2: (0.0000) | Acc: (67.00%) (29288/43648)
Epoch: 14 | Batch_idx: 350 |  Loss: (0.9154) |  Loss2: (0.0000) | Acc: (67.00%) (30155/44928)
Epoch: 14 | Batch_idx: 360 |  Loss: (0.9156) |  Loss2: (0.0000) | Acc: (67.00%) (31025/46208)
Epoch: 14 | Batch_idx: 370 |  Loss: (0.9163) |  Loss2: (0.0000) | Acc: (67.00%) (31871/47488)
Epoch: 14 | Batch_idx: 380 |  Loss: (0.9156) |  Loss2: (0.0000) | Acc: (67.00%) (32735/48768)
Epoch: 14 | Batch_idx: 390 |  Loss: (0.9159) |  Loss2: (0.0000) | Acc: (67.00%) (33547/50000)
# TEST : Loss: (0.9229) | Acc: (67.00%) (6718/10000)
percent tensor([0.5074, 0.5092, 0.5161, 0.5046, 0.5170, 0.5092, 0.5124, 0.5074, 0.5093,
        0.5089, 0.5084, 0.5156, 0.5069, 0.5112, 0.5083, 0.5067],
       device='cuda:0') torch.Size([16])
percent tensor([0.4885, 0.4776, 0.4902, 0.4879, 0.4869, 0.4898, 0.4791, 0.4879, 0.4852,
        0.4833, 0.4826, 0.4873, 0.4861, 0.4738, 0.4822, 0.4857],
       device='cuda:0') torch.Size([16])
percent tensor([0.5316, 0.5289, 0.5270, 0.5187, 0.5275, 0.5343, 0.5336, 0.5206, 0.5196,
        0.5237, 0.5266, 0.5289, 0.5308, 0.5169, 0.5365, 0.5274],
       device='cuda:0') torch.Size([16])
percent tensor([0.5612, 0.5673, 0.5542, 0.5553, 0.5662, 0.5560, 0.5696, 0.5703, 0.5632,
        0.5711, 0.5620, 0.5550, 0.5600, 0.5678, 0.5624, 0.5638],
       device='cuda:0') torch.Size([16])
percent tensor([0.5280, 0.5321, 0.4948, 0.5083, 0.5084, 0.4982, 0.5139, 0.5060, 0.5326,
        0.5396, 0.5348, 0.4874, 0.5336, 0.5364, 0.4961, 0.5316],
       device='cuda:0') torch.Size([16])
percent tensor([0.5362, 0.5324, 0.5453, 0.5531, 0.5523, 0.5407, 0.5352, 0.5624, 0.5281,
        0.5366, 0.5234, 0.5280, 0.5266, 0.5338, 0.5253, 0.5502],
       device='cuda:0') torch.Size([16])
percent tensor([0.5380, 0.5424, 0.5623, 0.5662, 0.5828, 0.5277, 0.5607, 0.6236, 0.5439,
        0.5588, 0.5387, 0.5533, 0.5367, 0.5322, 0.5411, 0.5554],
       device='cuda:0') torch.Size([16])
percent tensor([0.7550, 0.7155, 0.7502, 0.7360, 0.7419, 0.7631, 0.7130, 0.7923, 0.7511,
        0.7598, 0.7763, 0.7490, 0.7606, 0.7523, 0.7500, 0.7766],
       device='cuda:0') torch.Size([16])
Epoch: 15 | Batch_idx: 0 |  Loss: (0.8708) |  Loss2: (0.0000) | Acc: (67.00%) (87/128)
Epoch: 15 | Batch_idx: 10 |  Loss: (0.8623) |  Loss2: (0.0000) | Acc: (67.00%) (955/1408)
Epoch: 15 | Batch_idx: 20 |  Loss: (0.8741) |  Loss2: (0.0000) | Acc: (68.00%) (1836/2688)
Epoch: 15 | Batch_idx: 30 |  Loss: (0.8835) |  Loss2: (0.0000) | Acc: (68.00%) (2711/3968)
Epoch: 15 | Batch_idx: 40 |  Loss: (0.8793) |  Loss2: (0.0000) | Acc: (68.00%) (3577/5248)
Epoch: 15 | Batch_idx: 50 |  Loss: (0.8838) |  Loss2: (0.0000) | Acc: (68.00%) (4451/6528)
Epoch: 15 | Batch_idx: 60 |  Loss: (0.8891) |  Loss2: (0.0000) | Acc: (68.00%) (5313/7808)
Epoch: 15 | Batch_idx: 70 |  Loss: (0.8908) |  Loss2: (0.0000) | Acc: (68.00%) (6183/9088)
Epoch: 15 | Batch_idx: 80 |  Loss: (0.8931) |  Loss2: (0.0000) | Acc: (68.00%) (7053/10368)
Epoch: 15 | Batch_idx: 90 |  Loss: (0.8997) |  Loss2: (0.0000) | Acc: (67.00%) (7883/11648)
Epoch: 15 | Batch_idx: 100 |  Loss: (0.9006) |  Loss2: (0.0000) | Acc: (67.00%) (8741/12928)
Epoch: 15 | Batch_idx: 110 |  Loss: (0.8980) |  Loss2: (0.0000) | Acc: (67.00%) (9623/14208)
Epoch: 15 | Batch_idx: 120 |  Loss: (0.8998) |  Loss2: (0.0000) | Acc: (67.00%) (10474/15488)
Epoch: 15 | Batch_idx: 130 |  Loss: (0.8976) |  Loss2: (0.0000) | Acc: (67.00%) (11363/16768)
Epoch: 15 | Batch_idx: 140 |  Loss: (0.8969) |  Loss2: (0.0000) | Acc: (67.00%) (12239/18048)
Epoch: 15 | Batch_idx: 150 |  Loss: (0.9008) |  Loss2: (0.0000) | Acc: (67.00%) (13081/19328)
Epoch: 15 | Batch_idx: 160 |  Loss: (0.9018) |  Loss2: (0.0000) | Acc: (67.00%) (13927/20608)
Epoch: 15 | Batch_idx: 170 |  Loss: (0.9011) |  Loss2: (0.0000) | Acc: (67.00%) (14794/21888)
Epoch: 15 | Batch_idx: 180 |  Loss: (0.9033) |  Loss2: (0.0000) | Acc: (67.00%) (15653/23168)
Epoch: 15 | Batch_idx: 190 |  Loss: (0.9050) |  Loss2: (0.0000) | Acc: (67.00%) (16526/24448)
Epoch: 15 | Batch_idx: 200 |  Loss: (0.9066) |  Loss2: (0.0000) | Acc: (67.00%) (17387/25728)
Epoch: 15 | Batch_idx: 210 |  Loss: (0.9061) |  Loss2: (0.0000) | Acc: (67.00%) (18267/27008)
Epoch: 15 | Batch_idx: 220 |  Loss: (0.9062) |  Loss2: (0.0000) | Acc: (67.00%) (19141/28288)
Epoch: 15 | Batch_idx: 230 |  Loss: (0.9072) |  Loss2: (0.0000) | Acc: (67.00%) (19993/29568)
Epoch: 15 | Batch_idx: 240 |  Loss: (0.9075) |  Loss2: (0.0000) | Acc: (67.00%) (20842/30848)
Epoch: 15 | Batch_idx: 250 |  Loss: (0.9077) |  Loss2: (0.0000) | Acc: (67.00%) (21694/32128)
Epoch: 15 | Batch_idx: 260 |  Loss: (0.9069) |  Loss2: (0.0000) | Acc: (67.00%) (22548/33408)
Epoch: 15 | Batch_idx: 270 |  Loss: (0.9074) |  Loss2: (0.0000) | Acc: (67.00%) (23416/34688)
Epoch: 15 | Batch_idx: 280 |  Loss: (0.9076) |  Loss2: (0.0000) | Acc: (67.00%) (24271/35968)
Epoch: 15 | Batch_idx: 290 |  Loss: (0.9078) |  Loss2: (0.0000) | Acc: (67.00%) (25137/37248)
Epoch: 15 | Batch_idx: 300 |  Loss: (0.9068) |  Loss2: (0.0000) | Acc: (67.00%) (26022/38528)
Epoch: 15 | Batch_idx: 310 |  Loss: (0.9067) |  Loss2: (0.0000) | Acc: (67.00%) (26893/39808)
Epoch: 15 | Batch_idx: 320 |  Loss: (0.9071) |  Loss2: (0.0000) | Acc: (67.00%) (27733/41088)
Epoch: 15 | Batch_idx: 330 |  Loss: (0.9067) |  Loss2: (0.0000) | Acc: (67.00%) (28594/42368)
Epoch: 15 | Batch_idx: 340 |  Loss: (0.9077) |  Loss2: (0.0000) | Acc: (67.00%) (29423/43648)
Epoch: 15 | Batch_idx: 350 |  Loss: (0.9084) |  Loss2: (0.0000) | Acc: (67.00%) (30307/44928)
Epoch: 15 | Batch_idx: 360 |  Loss: (0.9082) |  Loss2: (0.0000) | Acc: (67.00%) (31193/46208)
Epoch: 15 | Batch_idx: 370 |  Loss: (0.9099) |  Loss2: (0.0000) | Acc: (67.00%) (32037/47488)
Epoch: 15 | Batch_idx: 380 |  Loss: (0.9099) |  Loss2: (0.0000) | Acc: (67.00%) (32892/48768)
Epoch: 15 | Batch_idx: 390 |  Loss: (0.9100) |  Loss2: (0.0000) | Acc: (67.00%) (33694/50000)
=> saving checkpoint 'drive/app/torch/save_Schedule/checkpoint_015.pth.tar'
# TEST : Loss: (0.9229) | Acc: (67.00%) (6719/10000)
percent tensor([0.5070, 0.5091, 0.5155, 0.5035, 0.5167, 0.5089, 0.5122, 0.5065, 0.5092,
        0.5084, 0.5084, 0.5151, 0.5065, 0.5117, 0.5078, 0.5064],
       device='cuda:0') torch.Size([16])
percent tensor([0.4881, 0.4769, 0.4893, 0.4867, 0.4861, 0.4896, 0.4781, 0.4867, 0.4847,
        0.4825, 0.4823, 0.4863, 0.4854, 0.4730, 0.4815, 0.4850],
       device='cuda:0') torch.Size([16])
percent tensor([0.5329, 0.5298, 0.5269, 0.5190, 0.5279, 0.5354, 0.5340, 0.5204, 0.5202,
        0.5242, 0.5275, 0.5291, 0.5318, 0.5173, 0.5372, 0.5285],
       device='cuda:0') torch.Size([16])
percent tensor([0.5604, 0.5666, 0.5533, 0.5546, 0.5655, 0.5563, 0.5686, 0.5699, 0.5630,
        0.5701, 0.5613, 0.5540, 0.5592, 0.5678, 0.5616, 0.5634],
       device='cuda:0') torch.Size([16])
percent tensor([0.5322, 0.5367, 0.4954, 0.5098, 0.5109, 0.4992, 0.5170, 0.5083, 0.5378,
        0.5448, 0.5391, 0.4876, 0.5378, 0.5427, 0.4973, 0.5361],
       device='cuda:0') torch.Size([16])
percent tensor([0.5355, 0.5315, 0.5463, 0.5544, 0.5533, 0.5414, 0.5344, 0.5629, 0.5284,
        0.5364, 0.5223, 0.5280, 0.5259, 0.5343, 0.5234, 0.5506],
       device='cuda:0') torch.Size([16])
percent tensor([0.5382, 0.5437, 0.5651, 0.5683, 0.5855, 0.5285, 0.5623, 0.6278, 0.5454,
        0.5607, 0.5388, 0.5554, 0.5366, 0.5336, 0.5416, 0.5569],
       device='cuda:0') torch.Size([16])
percent tensor([0.7610, 0.7219, 0.7581, 0.7439, 0.7491, 0.7700, 0.7175, 0.7968, 0.7600,
        0.7671, 0.7844, 0.7574, 0.7685, 0.7600, 0.7570, 0.7809],
       device='cuda:0') torch.Size([16])
True Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=128, out_features=16, bias=False)
False Linear(in_features=16, out_features=2, bias=False)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=128, out_features=16, bias=False)
False Linear(in_features=16, out_features=2, bias=False)
True Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=256, out_features=32, bias=False)
False Linear(in_features=32, out_features=2, bias=False)
True Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=256, out_features=32, bias=False)
False Linear(in_features=32, out_features=2, bias=False)
True Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=512, out_features=64, bias=False)
False Linear(in_features=64, out_features=2, bias=False)
True Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=512, out_features=64, bias=False)
False Linear(in_features=64, out_features=2, bias=False)
True Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1024, out_features=128, bias=False)
False Linear(in_features=128, out_features=2, bias=False)
True Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1024, out_features=128, bias=False)
False Linear(in_features=128, out_features=2, bias=False)
True Linear(in_features=512, out_features=10, bias=True)
Epoch: 16 | Batch_idx: 0 |  Loss: (0.9822) |  Loss2: (0.0000) | Acc: (65.00%) (84/128)
Epoch: 16 | Batch_idx: 10 |  Loss: (0.9384) |  Loss2: (0.0000) | Acc: (66.00%) (938/1408)
Epoch: 16 | Batch_idx: 20 |  Loss: (0.9418) |  Loss2: (0.0000) | Acc: (65.00%) (1772/2688)
Epoch: 16 | Batch_idx: 30 |  Loss: (0.9323) |  Loss2: (0.0000) | Acc: (66.00%) (2637/3968)
Epoch: 16 | Batch_idx: 40 |  Loss: (0.9354) |  Loss2: (0.0000) | Acc: (66.00%) (3494/5248)
Epoch: 16 | Batch_idx: 50 |  Loss: (0.9395) |  Loss2: (0.0000) | Acc: (66.00%) (4341/6528)
Epoch: 16 | Batch_idx: 60 |  Loss: (0.9333) |  Loss2: (0.0000) | Acc: (66.00%) (5200/7808)
Epoch: 16 | Batch_idx: 70 |  Loss: (0.9241) |  Loss2: (0.0000) | Acc: (66.00%) (6081/9088)
Epoch: 16 | Batch_idx: 80 |  Loss: (0.9244) |  Loss2: (0.0000) | Acc: (66.00%) (6941/10368)
Epoch: 16 | Batch_idx: 90 |  Loss: (0.9271) |  Loss2: (0.0000) | Acc: (66.00%) (7800/11648)
Epoch: 16 | Batch_idx: 100 |  Loss: (0.9275) |  Loss2: (0.0000) | Acc: (66.00%) (8651/12928)
Epoch: 16 | Batch_idx: 110 |  Loss: (0.9309) |  Loss2: (0.0000) | Acc: (66.00%) (9498/14208)
Epoch: 16 | Batch_idx: 120 |  Loss: (0.9315) |  Loss2: (0.0000) | Acc: (66.00%) (10346/15488)
Epoch: 16 | Batch_idx: 130 |  Loss: (0.9325) |  Loss2: (0.0000) | Acc: (66.00%) (11182/16768)
Epoch: 16 | Batch_idx: 140 |  Loss: (0.9344) |  Loss2: (0.0000) | Acc: (66.00%) (12015/18048)
Epoch: 16 | Batch_idx: 150 |  Loss: (0.9338) |  Loss2: (0.0000) | Acc: (66.00%) (12856/19328)
Epoch: 16 | Batch_idx: 160 |  Loss: (0.9357) |  Loss2: (0.0000) | Acc: (66.00%) (13695/20608)
Epoch: 16 | Batch_idx: 170 |  Loss: (0.9341) |  Loss2: (0.0000) | Acc: (66.00%) (14564/21888)
Epoch: 16 | Batch_idx: 180 |  Loss: (0.9350) |  Loss2: (0.0000) | Acc: (66.00%) (15419/23168)
Epoch: 16 | Batch_idx: 190 |  Loss: (0.9338) |  Loss2: (0.0000) | Acc: (66.00%) (16288/24448)
Epoch: 16 | Batch_idx: 200 |  Loss: (0.9348) |  Loss2: (0.0000) | Acc: (66.00%) (17142/25728)
Epoch: 16 | Batch_idx: 210 |  Loss: (0.9334) |  Loss2: (0.0000) | Acc: (66.00%) (17996/27008)
Epoch: 16 | Batch_idx: 220 |  Loss: (0.9324) |  Loss2: (0.0000) | Acc: (66.00%) (18861/28288)
Epoch: 16 | Batch_idx: 230 |  Loss: (0.9313) |  Loss2: (0.0000) | Acc: (66.00%) (19735/29568)
Epoch: 16 | Batch_idx: 240 |  Loss: (0.9303) |  Loss2: (0.0000) | Acc: (66.00%) (20590/30848)
Epoch: 16 | Batch_idx: 250 |  Loss: (0.9291) |  Loss2: (0.0000) | Acc: (66.00%) (21463/32128)
Epoch: 16 | Batch_idx: 260 |  Loss: (0.9284) |  Loss2: (0.0000) | Acc: (66.00%) (22310/33408)
Epoch: 16 | Batch_idx: 270 |  Loss: (0.9256) |  Loss2: (0.0000) | Acc: (66.00%) (23191/34688)
Epoch: 16 | Batch_idx: 280 |  Loss: (0.9243) |  Loss2: (0.0000) | Acc: (66.00%) (24048/35968)
Epoch: 16 | Batch_idx: 290 |  Loss: (0.9249) |  Loss2: (0.0000) | Acc: (66.00%) (24905/37248)
Epoch: 16 | Batch_idx: 300 |  Loss: (0.9234) |  Loss2: (0.0000) | Acc: (66.00%) (25789/38528)
Epoch: 16 | Batch_idx: 310 |  Loss: (0.9231) |  Loss2: (0.0000) | Acc: (66.00%) (26647/39808)
Epoch: 16 | Batch_idx: 320 |  Loss: (0.9208) |  Loss2: (0.0000) | Acc: (67.00%) (27564/41088)
Epoch: 16 | Batch_idx: 330 |  Loss: (0.9192) |  Loss2: (0.0000) | Acc: (67.00%) (28461/42368)
Epoch: 16 | Batch_idx: 340 |  Loss: (0.9194) |  Loss2: (0.0000) | Acc: (67.00%) (29315/43648)
Epoch: 16 | Batch_idx: 350 |  Loss: (0.9187) |  Loss2: (0.0000) | Acc: (67.00%) (30181/44928)
Epoch: 16 | Batch_idx: 360 |  Loss: (0.9173) |  Loss2: (0.0000) | Acc: (67.00%) (31051/46208)
Epoch: 16 | Batch_idx: 370 |  Loss: (0.9145) |  Loss2: (0.0000) | Acc: (67.00%) (31963/47488)
Epoch: 16 | Batch_idx: 380 |  Loss: (0.9147) |  Loss2: (0.0000) | Acc: (67.00%) (32832/48768)
Epoch: 16 | Batch_idx: 390 |  Loss: (0.9152) |  Loss2: (0.0000) | Acc: (67.00%) (33654/50000)
# TEST : Loss: (1.1817) | Acc: (59.00%) (5949/10000)
percent tensor([0.5066, 0.5087, 0.5129, 0.5036, 0.5143, 0.5086, 0.5115, 0.5063, 0.5080,
        0.5081, 0.5080, 0.5131, 0.5062, 0.5107, 0.5084, 0.5064],
       device='cuda:0') torch.Size([16])
percent tensor([0.4889, 0.4784, 0.4903, 0.4853, 0.4868, 0.4907, 0.4798, 0.4861, 0.4870,
        0.4833, 0.4839, 0.4869, 0.4859, 0.4777, 0.4823, 0.4857],
       device='cuda:0') torch.Size([16])
percent tensor([0.5326, 0.5278, 0.5232, 0.5159, 0.5245, 0.5308, 0.5313, 0.5183, 0.5173,
        0.5244, 0.5251, 0.5262, 0.5329, 0.5131, 0.5343, 0.5271],
       device='cuda:0') torch.Size([16])
percent tensor([0.5611, 0.5694, 0.5500, 0.5539, 0.5625, 0.5554, 0.5722, 0.5661, 0.5655,
        0.5740, 0.5654, 0.5588, 0.5624, 0.5733, 0.5637, 0.5650],
       device='cuda:0') torch.Size([16])
percent tensor([0.5367, 0.5414, 0.5064, 0.5164, 0.5147, 0.5055, 0.5289, 0.5136, 0.5453,
        0.5552, 0.5492, 0.5067, 0.5432, 0.5595, 0.5042, 0.5405],
       device='cuda:0') torch.Size([16])
percent tensor([0.5397, 0.5358, 0.5490, 0.5548, 0.5551, 0.5462, 0.5427, 0.5623, 0.5339,
        0.5407, 0.5278, 0.5396, 0.5314, 0.5391, 0.5314, 0.5521],
       device='cuda:0') torch.Size([16])
percent tensor([0.5474, 0.5456, 0.5641, 0.5608, 0.5805, 0.5288, 0.5769, 0.6256, 0.5494,
        0.5768, 0.5518, 0.5762, 0.5482, 0.5463, 0.5410, 0.5596],
       device='cuda:0') torch.Size([16])
percent tensor([0.7843, 0.7327, 0.7549, 0.7359, 0.7624, 0.7827, 0.7619, 0.7949, 0.7593,
        0.7984, 0.7930, 0.7888, 0.7782, 0.7927, 0.7406, 0.8009],
       device='cuda:0') torch.Size([16])
Epoch: 17 | Batch_idx: 0 |  Loss: (0.9277) |  Loss2: (0.0000) | Acc: (64.00%) (83/128)
Epoch: 17 | Batch_idx: 10 |  Loss: (0.8772) |  Loss2: (0.0000) | Acc: (70.00%) (993/1408)
Epoch: 17 | Batch_idx: 20 |  Loss: (0.8563) |  Loss2: (0.0000) | Acc: (70.00%) (1898/2688)
Epoch: 17 | Batch_idx: 30 |  Loss: (0.8563) |  Loss2: (0.0000) | Acc: (70.00%) (2796/3968)
Epoch: 17 | Batch_idx: 40 |  Loss: (0.8670) |  Loss2: (0.0000) | Acc: (69.00%) (3670/5248)
Epoch: 17 | Batch_idx: 50 |  Loss: (0.8674) |  Loss2: (0.0000) | Acc: (69.00%) (4563/6528)
Epoch: 17 | Batch_idx: 60 |  Loss: (0.8706) |  Loss2: (0.0000) | Acc: (69.00%) (5434/7808)
Epoch: 17 | Batch_idx: 70 |  Loss: (0.8657) |  Loss2: (0.0000) | Acc: (69.00%) (6323/9088)
Epoch: 17 | Batch_idx: 80 |  Loss: (0.8690) |  Loss2: (0.0000) | Acc: (69.00%) (7204/10368)
Epoch: 17 | Batch_idx: 90 |  Loss: (0.8722) |  Loss2: (0.0000) | Acc: (69.00%) (8066/11648)
Epoch: 17 | Batch_idx: 100 |  Loss: (0.8706) |  Loss2: (0.0000) | Acc: (69.00%) (8962/12928)
Epoch: 17 | Batch_idx: 110 |  Loss: (0.8667) |  Loss2: (0.0000) | Acc: (69.00%) (9866/14208)
Epoch: 17 | Batch_idx: 120 |  Loss: (0.8705) |  Loss2: (0.0000) | Acc: (69.00%) (10718/15488)
Epoch: 17 | Batch_idx: 130 |  Loss: (0.8722) |  Loss2: (0.0000) | Acc: (69.00%) (11598/16768)
Epoch: 17 | Batch_idx: 140 |  Loss: (0.8731) |  Loss2: (0.0000) | Acc: (69.00%) (12471/18048)
Epoch: 17 | Batch_idx: 150 |  Loss: (0.8705) |  Loss2: (0.0000) | Acc: (69.00%) (13374/19328)
Epoch: 17 | Batch_idx: 160 |  Loss: (0.8714) |  Loss2: (0.0000) | Acc: (69.00%) (14232/20608)
Epoch: 17 | Batch_idx: 170 |  Loss: (0.8695) |  Loss2: (0.0000) | Acc: (69.00%) (15139/21888)
Epoch: 17 | Batch_idx: 180 |  Loss: (0.8713) |  Loss2: (0.0000) | Acc: (69.00%) (16014/23168)
Epoch: 17 | Batch_idx: 190 |  Loss: (0.8732) |  Loss2: (0.0000) | Acc: (69.00%) (16881/24448)
Epoch: 17 | Batch_idx: 200 |  Loss: (0.8720) |  Loss2: (0.0000) | Acc: (69.00%) (17784/25728)
Epoch: 17 | Batch_idx: 210 |  Loss: (0.8723) |  Loss2: (0.0000) | Acc: (69.00%) (18662/27008)
Epoch: 17 | Batch_idx: 220 |  Loss: (0.8699) |  Loss2: (0.0000) | Acc: (69.00%) (19587/28288)
Epoch: 17 | Batch_idx: 230 |  Loss: (0.8691) |  Loss2: (0.0000) | Acc: (69.00%) (20473/29568)
Epoch: 17 | Batch_idx: 240 |  Loss: (0.8675) |  Loss2: (0.0000) | Acc: (69.00%) (21372/30848)
Epoch: 17 | Batch_idx: 250 |  Loss: (0.8667) |  Loss2: (0.0000) | Acc: (69.00%) (22263/32128)
Epoch: 17 | Batch_idx: 260 |  Loss: (0.8649) |  Loss2: (0.0000) | Acc: (69.00%) (23165/33408)
Epoch: 17 | Batch_idx: 270 |  Loss: (0.8662) |  Loss2: (0.0000) | Acc: (69.00%) (24018/34688)
Epoch: 17 | Batch_idx: 280 |  Loss: (0.8650) |  Loss2: (0.0000) | Acc: (69.00%) (24917/35968)
Epoch: 17 | Batch_idx: 290 |  Loss: (0.8644) |  Loss2: (0.0000) | Acc: (69.00%) (25811/37248)
Epoch: 17 | Batch_idx: 300 |  Loss: (0.8640) |  Loss2: (0.0000) | Acc: (69.00%) (26707/38528)
Epoch: 17 | Batch_idx: 310 |  Loss: (0.8626) |  Loss2: (0.0000) | Acc: (69.00%) (27600/39808)
Epoch: 17 | Batch_idx: 320 |  Loss: (0.8634) |  Loss2: (0.0000) | Acc: (69.00%) (28461/41088)
Epoch: 17 | Batch_idx: 330 |  Loss: (0.8620) |  Loss2: (0.0000) | Acc: (69.00%) (29386/42368)
Epoch: 17 | Batch_idx: 340 |  Loss: (0.8616) |  Loss2: (0.0000) | Acc: (69.00%) (30267/43648)
Epoch: 17 | Batch_idx: 350 |  Loss: (0.8610) |  Loss2: (0.0000) | Acc: (69.00%) (31187/44928)
Epoch: 17 | Batch_idx: 360 |  Loss: (0.8589) |  Loss2: (0.0000) | Acc: (69.00%) (32109/46208)
Epoch: 17 | Batch_idx: 370 |  Loss: (0.8584) |  Loss2: (0.0000) | Acc: (69.00%) (33018/47488)
Epoch: 17 | Batch_idx: 380 |  Loss: (0.8561) |  Loss2: (0.0000) | Acc: (69.00%) (33952/48768)
Epoch: 17 | Batch_idx: 390 |  Loss: (0.8548) |  Loss2: (0.0000) | Acc: (69.00%) (34835/50000)
# TEST : Loss: (0.9172) | Acc: (67.00%) (6776/10000)
percent tensor([0.5062, 0.5085, 0.5123, 0.5039, 0.5138, 0.5084, 0.5110, 0.5062, 0.5073,
        0.5077, 0.5078, 0.5126, 0.5059, 0.5100, 0.5083, 0.5061],
       device='cuda:0') torch.Size([16])
percent tensor([0.4880, 0.4779, 0.4908, 0.4848, 0.4873, 0.4901, 0.4800, 0.4864, 0.4862,
        0.4833, 0.4831, 0.4883, 0.4849, 0.4758, 0.4814, 0.4847],
       device='cuda:0') torch.Size([16])
percent tensor([0.5335, 0.5329, 0.5197, 0.5152, 0.5231, 0.5305, 0.5347, 0.5186, 0.5214,
        0.5268, 0.5292, 0.5239, 0.5354, 0.5237, 0.5361, 0.5296],
       device='cuda:0') torch.Size([16])
percent tensor([0.5609, 0.5691, 0.5548, 0.5543, 0.5653, 0.5562, 0.5725, 0.5695, 0.5631,
        0.5721, 0.5620, 0.5601, 0.5604, 0.5683, 0.5657, 0.5655],
       device='cuda:0') torch.Size([16])
percent tensor([0.5288, 0.5341, 0.5083, 0.5199, 0.5187, 0.5026, 0.5220, 0.5126, 0.5326,
        0.5504, 0.5370, 0.4994, 0.5331, 0.5422, 0.4976, 0.5311],
       device='cuda:0') torch.Size([16])
percent tensor([0.5384, 0.5367, 0.5555, 0.5579, 0.5637, 0.5465, 0.5432, 0.5612, 0.5336,
        0.5432, 0.5251, 0.5426, 0.5283, 0.5377, 0.5307, 0.5494],
       device='cuda:0') torch.Size([16])
percent tensor([0.5475, 0.5572, 0.5750, 0.5705, 0.5978, 0.5336, 0.5762, 0.6323, 0.5462,
        0.5673, 0.5396, 0.5689, 0.5375, 0.5370, 0.5612, 0.5560],
       device='cuda:0') torch.Size([16])
percent tensor([0.7470, 0.6963, 0.7414, 0.7404, 0.7477, 0.7689, 0.7144, 0.7954, 0.7412,
        0.7333, 0.7318, 0.7412, 0.7486, 0.7301, 0.7507, 0.7674],
       device='cuda:0') torch.Size([16])
Epoch: 18 | Batch_idx: 0 |  Loss: (0.8456) |  Loss2: (0.0000) | Acc: (75.00%) (96/128)
Epoch: 18 | Batch_idx: 10 |  Loss: (0.7755) |  Loss2: (0.0000) | Acc: (73.00%) (1041/1408)
Epoch: 18 | Batch_idx: 20 |  Loss: (0.8051) |  Loss2: (0.0000) | Acc: (72.00%) (1943/2688)
Epoch: 18 | Batch_idx: 30 |  Loss: (0.8123) |  Loss2: (0.0000) | Acc: (71.00%) (2847/3968)
Epoch: 18 | Batch_idx: 40 |  Loss: (0.8063) |  Loss2: (0.0000) | Acc: (71.00%) (3766/5248)
Epoch: 18 | Batch_idx: 50 |  Loss: (0.8150) |  Loss2: (0.0000) | Acc: (71.00%) (4676/6528)
Epoch: 18 | Batch_idx: 60 |  Loss: (0.8184) |  Loss2: (0.0000) | Acc: (71.00%) (5575/7808)
Epoch: 18 | Batch_idx: 70 |  Loss: (0.8150) |  Loss2: (0.0000) | Acc: (71.00%) (6497/9088)
Epoch: 18 | Batch_idx: 80 |  Loss: (0.8160) |  Loss2: (0.0000) | Acc: (71.00%) (7420/10368)
Epoch: 18 | Batch_idx: 90 |  Loss: (0.8176) |  Loss2: (0.0000) | Acc: (71.00%) (8329/11648)
Epoch: 18 | Batch_idx: 100 |  Loss: (0.8141) |  Loss2: (0.0000) | Acc: (71.00%) (9243/12928)
Epoch: 18 | Batch_idx: 110 |  Loss: (0.8126) |  Loss2: (0.0000) | Acc: (71.00%) (10156/14208)
Epoch: 18 | Batch_idx: 120 |  Loss: (0.8157) |  Loss2: (0.0000) | Acc: (71.00%) (11050/15488)
Epoch: 18 | Batch_idx: 130 |  Loss: (0.8135) |  Loss2: (0.0000) | Acc: (71.00%) (11971/16768)
Epoch: 18 | Batch_idx: 140 |  Loss: (0.8138) |  Loss2: (0.0000) | Acc: (71.00%) (12886/18048)
Epoch: 18 | Batch_idx: 150 |  Loss: (0.8120) |  Loss2: (0.0000) | Acc: (71.00%) (13831/19328)
Epoch: 18 | Batch_idx: 160 |  Loss: (0.8123) |  Loss2: (0.0000) | Acc: (71.00%) (14737/20608)
Epoch: 18 | Batch_idx: 170 |  Loss: (0.8125) |  Loss2: (0.0000) | Acc: (71.00%) (15652/21888)
Epoch: 18 | Batch_idx: 180 |  Loss: (0.8135) |  Loss2: (0.0000) | Acc: (71.00%) (16545/23168)
Epoch: 18 | Batch_idx: 190 |  Loss: (0.8147) |  Loss2: (0.0000) | Acc: (71.00%) (17422/24448)
Epoch: 18 | Batch_idx: 200 |  Loss: (0.8157) |  Loss2: (0.0000) | Acc: (71.00%) (18324/25728)
Epoch: 18 | Batch_idx: 210 |  Loss: (0.8172) |  Loss2: (0.0000) | Acc: (71.00%) (19228/27008)
Epoch: 18 | Batch_idx: 220 |  Loss: (0.8167) |  Loss2: (0.0000) | Acc: (71.00%) (20137/28288)
Epoch: 18 | Batch_idx: 230 |  Loss: (0.8153) |  Loss2: (0.0000) | Acc: (71.00%) (21048/29568)
Epoch: 18 | Batch_idx: 240 |  Loss: (0.8153) |  Loss2: (0.0000) | Acc: (71.00%) (21980/30848)
Epoch: 18 | Batch_idx: 250 |  Loss: (0.8157) |  Loss2: (0.0000) | Acc: (71.00%) (22889/32128)
Epoch: 18 | Batch_idx: 260 |  Loss: (0.8155) |  Loss2: (0.0000) | Acc: (71.00%) (23796/33408)
Epoch: 18 | Batch_idx: 270 |  Loss: (0.8153) |  Loss2: (0.0000) | Acc: (71.00%) (24699/34688)
Epoch: 18 | Batch_idx: 280 |  Loss: (0.8150) |  Loss2: (0.0000) | Acc: (71.00%) (25630/35968)
Epoch: 18 | Batch_idx: 290 |  Loss: (0.8143) |  Loss2: (0.0000) | Acc: (71.00%) (26529/37248)
Epoch: 18 | Batch_idx: 300 |  Loss: (0.8145) |  Loss2: (0.0000) | Acc: (71.00%) (27437/38528)
Epoch: 18 | Batch_idx: 310 |  Loss: (0.8134) |  Loss2: (0.0000) | Acc: (71.00%) (28353/39808)
Epoch: 18 | Batch_idx: 320 |  Loss: (0.8132) |  Loss2: (0.0000) | Acc: (71.00%) (29255/41088)
Epoch: 18 | Batch_idx: 330 |  Loss: (0.8121) |  Loss2: (0.0000) | Acc: (71.00%) (30188/42368)
Epoch: 18 | Batch_idx: 340 |  Loss: (0.8105) |  Loss2: (0.0000) | Acc: (71.00%) (31119/43648)
Epoch: 18 | Batch_idx: 350 |  Loss: (0.8095) |  Loss2: (0.0000) | Acc: (71.00%) (32056/44928)
Epoch: 18 | Batch_idx: 360 |  Loss: (0.8093) |  Loss2: (0.0000) | Acc: (71.00%) (32993/46208)
Epoch: 18 | Batch_idx: 370 |  Loss: (0.8076) |  Loss2: (0.0000) | Acc: (71.00%) (33933/47488)
Epoch: 18 | Batch_idx: 380 |  Loss: (0.8075) |  Loss2: (0.0000) | Acc: (71.00%) (34849/48768)
Epoch: 18 | Batch_idx: 390 |  Loss: (0.8067) |  Loss2: (0.0000) | Acc: (71.00%) (35740/50000)
# TEST : Loss: (1.1028) | Acc: (64.00%) (6409/10000)
percent tensor([0.5063, 0.5085, 0.5136, 0.5041, 0.5149, 0.5082, 0.5114, 0.5066, 0.5078,
        0.5082, 0.5079, 0.5134, 0.5061, 0.5104, 0.5081, 0.5062],
       device='cuda:0') torch.Size([16])
percent tensor([0.4884, 0.4790, 0.4903, 0.4858, 0.4875, 0.4894, 0.4812, 0.4866, 0.4866,
        0.4838, 0.4838, 0.4874, 0.4857, 0.4776, 0.4821, 0.4852],
       device='cuda:0') torch.Size([16])
percent tensor([0.5330, 0.5330, 0.5260, 0.5153, 0.5262, 0.5269, 0.5363, 0.5225, 0.5227,
        0.5294, 0.5287, 0.5305, 0.5361, 0.5220, 0.5342, 0.5298],
       device='cuda:0') torch.Size([16])
percent tensor([0.5636, 0.5703, 0.5528, 0.5538, 0.5629, 0.5554, 0.5744, 0.5683, 0.5639,
        0.5742, 0.5654, 0.5624, 0.5636, 0.5699, 0.5674, 0.5674],
       device='cuda:0') torch.Size([16])
percent tensor([0.5337, 0.5354, 0.5008, 0.5107, 0.5135, 0.5087, 0.5179, 0.5058, 0.5335,
        0.5489, 0.5405, 0.4978, 0.5359, 0.5403, 0.5014, 0.5314],
       device='cuda:0') torch.Size([16])
percent tensor([0.5377, 0.5339, 0.5462, 0.5521, 0.5543, 0.5503, 0.5368, 0.5547, 0.5306,
        0.5366, 0.5240, 0.5340, 0.5252, 0.5348, 0.5316, 0.5480],
       device='cuda:0') torch.Size([16])
percent tensor([0.5619, 0.5621, 0.5726, 0.5620, 0.5836, 0.5405, 0.5748, 0.6230, 0.5556,
        0.5790, 0.5505, 0.5738, 0.5494, 0.5462, 0.5658, 0.5683],
       device='cuda:0') torch.Size([16])
percent tensor([0.8000, 0.7645, 0.7567, 0.7502, 0.7297, 0.7832, 0.7698, 0.8050, 0.8087,
        0.8207, 0.7904, 0.7944, 0.7933, 0.8030, 0.7924, 0.7928],
       device='cuda:0') torch.Size([16])
Epoch: 19 | Batch_idx: 0 |  Loss: (0.8478) |  Loss2: (0.0000) | Acc: (69.00%) (89/128)
Epoch: 19 | Batch_idx: 10 |  Loss: (0.7909) |  Loss2: (0.0000) | Acc: (71.00%) (1012/1408)
Epoch: 19 | Batch_idx: 20 |  Loss: (0.7897) |  Loss2: (0.0000) | Acc: (71.00%) (1927/2688)
Epoch: 19 | Batch_idx: 30 |  Loss: (0.7879) |  Loss2: (0.0000) | Acc: (71.00%) (2836/3968)
Epoch: 19 | Batch_idx: 40 |  Loss: (0.7948) |  Loss2: (0.0000) | Acc: (71.00%) (3761/5248)
Epoch: 19 | Batch_idx: 50 |  Loss: (0.7895) |  Loss2: (0.0000) | Acc: (72.00%) (4712/6528)
Epoch: 19 | Batch_idx: 60 |  Loss: (0.7771) |  Loss2: (0.0000) | Acc: (72.00%) (5665/7808)
Epoch: 19 | Batch_idx: 70 |  Loss: (0.7725) |  Loss2: (0.0000) | Acc: (72.00%) (6628/9088)
Epoch: 19 | Batch_idx: 80 |  Loss: (0.7689) |  Loss2: (0.0000) | Acc: (73.00%) (7587/10368)
Epoch: 19 | Batch_idx: 90 |  Loss: (0.7702) |  Loss2: (0.0000) | Acc: (73.00%) (8522/11648)
Epoch: 19 | Batch_idx: 100 |  Loss: (0.7707) |  Loss2: (0.0000) | Acc: (73.00%) (9448/12928)
Epoch: 19 | Batch_idx: 110 |  Loss: (0.7672) |  Loss2: (0.0000) | Acc: (73.00%) (10406/14208)
Epoch: 19 | Batch_idx: 120 |  Loss: (0.7662) |  Loss2: (0.0000) | Acc: (73.00%) (11348/15488)
Epoch: 19 | Batch_idx: 130 |  Loss: (0.7701) |  Loss2: (0.0000) | Acc: (73.00%) (12271/16768)
Epoch: 19 | Batch_idx: 140 |  Loss: (0.7707) |  Loss2: (0.0000) | Acc: (73.00%) (13210/18048)
Epoch: 19 | Batch_idx: 150 |  Loss: (0.7748) |  Loss2: (0.0000) | Acc: (73.00%) (14119/19328)
Epoch: 19 | Batch_idx: 160 |  Loss: (0.7751) |  Loss2: (0.0000) | Acc: (72.00%) (15023/20608)
Epoch: 19 | Batch_idx: 170 |  Loss: (0.7720) |  Loss2: (0.0000) | Acc: (72.00%) (15976/21888)
Epoch: 19 | Batch_idx: 180 |  Loss: (0.7726) |  Loss2: (0.0000) | Acc: (72.00%) (16886/23168)
Epoch: 19 | Batch_idx: 190 |  Loss: (0.7722) |  Loss2: (0.0000) | Acc: (72.00%) (17839/24448)
Epoch: 19 | Batch_idx: 200 |  Loss: (0.7700) |  Loss2: (0.0000) | Acc: (73.00%) (18799/25728)
Epoch: 19 | Batch_idx: 210 |  Loss: (0.7714) |  Loss2: (0.0000) | Acc: (73.00%) (19719/27008)
Epoch: 19 | Batch_idx: 220 |  Loss: (0.7715) |  Loss2: (0.0000) | Acc: (73.00%) (20657/28288)
Epoch: 19 | Batch_idx: 230 |  Loss: (0.7704) |  Loss2: (0.0000) | Acc: (73.00%) (21598/29568)
Epoch: 19 | Batch_idx: 240 |  Loss: (0.7700) |  Loss2: (0.0000) | Acc: (73.00%) (22543/30848)
Epoch: 19 | Batch_idx: 250 |  Loss: (0.7694) |  Loss2: (0.0000) | Acc: (73.00%) (23467/32128)
Epoch: 19 | Batch_idx: 260 |  Loss: (0.7703) |  Loss2: (0.0000) | Acc: (73.00%) (24400/33408)
Epoch: 19 | Batch_idx: 270 |  Loss: (0.7682) |  Loss2: (0.0000) | Acc: (73.00%) (25364/34688)
Epoch: 19 | Batch_idx: 280 |  Loss: (0.7668) |  Loss2: (0.0000) | Acc: (73.00%) (26314/35968)
Epoch: 19 | Batch_idx: 290 |  Loss: (0.7659) |  Loss2: (0.0000) | Acc: (73.00%) (27273/37248)
Epoch: 19 | Batch_idx: 300 |  Loss: (0.7649) |  Loss2: (0.0000) | Acc: (73.00%) (28225/38528)
Epoch: 19 | Batch_idx: 310 |  Loss: (0.7648) |  Loss2: (0.0000) | Acc: (73.00%) (29154/39808)
Epoch: 19 | Batch_idx: 320 |  Loss: (0.7637) |  Loss2: (0.0000) | Acc: (73.00%) (30105/41088)
Epoch: 19 | Batch_idx: 330 |  Loss: (0.7645) |  Loss2: (0.0000) | Acc: (73.00%) (31053/42368)
Epoch: 19 | Batch_idx: 340 |  Loss: (0.7636) |  Loss2: (0.0000) | Acc: (73.00%) (31989/43648)
Epoch: 19 | Batch_idx: 350 |  Loss: (0.7643) |  Loss2: (0.0000) | Acc: (73.00%) (32904/44928)
Epoch: 19 | Batch_idx: 360 |  Loss: (0.7642) |  Loss2: (0.0000) | Acc: (73.00%) (33859/46208)
Epoch: 19 | Batch_idx: 370 |  Loss: (0.7636) |  Loss2: (0.0000) | Acc: (73.00%) (34792/47488)
Epoch: 19 | Batch_idx: 380 |  Loss: (0.7623) |  Loss2: (0.0000) | Acc: (73.00%) (35746/48768)
Epoch: 19 | Batch_idx: 390 |  Loss: (0.7615) |  Loss2: (0.0000) | Acc: (73.00%) (36660/50000)
# TEST : Loss: (0.9071) | Acc: (69.00%) (6921/10000)
percent tensor([0.5058, 0.5085, 0.5124, 0.5043, 0.5136, 0.5081, 0.5108, 0.5065, 0.5076,
        0.5077, 0.5078, 0.5124, 0.5056, 0.5106, 0.5086, 0.5061],
       device='cuda:0') torch.Size([16])
percent tensor([0.4873, 0.4774, 0.4908, 0.4851, 0.4860, 0.4877, 0.4796, 0.4867, 0.4852,
        0.4830, 0.4825, 0.4869, 0.4846, 0.4759, 0.4805, 0.4840],
       device='cuda:0') torch.Size([16])
percent tensor([0.5363, 0.5309, 0.5254, 0.5167, 0.5291, 0.5326, 0.5350, 0.5232, 0.5228,
        0.5278, 0.5277, 0.5292, 0.5378, 0.5157, 0.5366, 0.5309],
       device='cuda:0') torch.Size([16])
percent tensor([0.5647, 0.5739, 0.5551, 0.5542, 0.5677, 0.5588, 0.5789, 0.5675, 0.5652,
        0.5772, 0.5686, 0.5649, 0.5660, 0.5754, 0.5697, 0.5689],
       device='cuda:0') torch.Size([16])
percent tensor([0.5303, 0.5353, 0.5113, 0.5158, 0.5180, 0.5061, 0.5279, 0.5130, 0.5401,
        0.5521, 0.5411, 0.5018, 0.5350, 0.5526, 0.4982, 0.5323],
       device='cuda:0') torch.Size([16])
percent tensor([0.5380, 0.5391, 0.5482, 0.5479, 0.5557, 0.5436, 0.5441, 0.5560, 0.5352,
        0.5424, 0.5299, 0.5350, 0.5298, 0.5421, 0.5325, 0.5491],
       device='cuda:0') torch.Size([16])
percent tensor([0.5498, 0.5640, 0.5775, 0.5665, 0.5970, 0.5302, 0.5864, 0.6311, 0.5556,
        0.5755, 0.5543, 0.5784, 0.5485, 0.5408, 0.5734, 0.5638],
       device='cuda:0') torch.Size([16])
percent tensor([0.7408, 0.7304, 0.7590, 0.7556, 0.7416, 0.7749, 0.7549, 0.8055, 0.7735,
        0.7861, 0.7765, 0.7707, 0.7553, 0.7845, 0.7996, 0.7833],
       device='cuda:0') torch.Size([16])
Epoch: 20 | Batch_idx: 0 |  Loss: (0.6822) |  Loss2: (0.0000) | Acc: (75.00%) (97/128)
Epoch: 20 | Batch_idx: 10 |  Loss: (0.7325) |  Loss2: (0.0000) | Acc: (73.00%) (1030/1408)
Epoch: 20 | Batch_idx: 20 |  Loss: (0.7326) |  Loss2: (0.0000) | Acc: (73.00%) (1972/2688)
Epoch: 20 | Batch_idx: 30 |  Loss: (0.7119) |  Loss2: (0.0000) | Acc: (74.00%) (2966/3968)
Epoch: 20 | Batch_idx: 40 |  Loss: (0.7039) |  Loss2: (0.0000) | Acc: (75.00%) (3943/5248)
Epoch: 20 | Batch_idx: 50 |  Loss: (0.7109) |  Loss2: (0.0000) | Acc: (74.00%) (4881/6528)
Epoch: 20 | Batch_idx: 60 |  Loss: (0.7063) |  Loss2: (0.0000) | Acc: (75.00%) (5858/7808)
Epoch: 20 | Batch_idx: 70 |  Loss: (0.7139) |  Loss2: (0.0000) | Acc: (74.00%) (6797/9088)
Epoch: 20 | Batch_idx: 80 |  Loss: (0.7184) |  Loss2: (0.0000) | Acc: (74.00%) (7738/10368)
Epoch: 20 | Batch_idx: 90 |  Loss: (0.7231) |  Loss2: (0.0000) | Acc: (74.00%) (8691/11648)
Epoch: 20 | Batch_idx: 100 |  Loss: (0.7237) |  Loss2: (0.0000) | Acc: (74.00%) (9637/12928)
Epoch: 20 | Batch_idx: 110 |  Loss: (0.7274) |  Loss2: (0.0000) | Acc: (74.00%) (10570/14208)
Epoch: 20 | Batch_idx: 120 |  Loss: (0.7286) |  Loss2: (0.0000) | Acc: (74.00%) (11520/15488)
Epoch: 20 | Batch_idx: 130 |  Loss: (0.7300) |  Loss2: (0.0000) | Acc: (74.00%) (12457/16768)
Epoch: 20 | Batch_idx: 140 |  Loss: (0.7294) |  Loss2: (0.0000) | Acc: (74.00%) (13418/18048)
Epoch: 20 | Batch_idx: 150 |  Loss: (0.7304) |  Loss2: (0.0000) | Acc: (74.00%) (14371/19328)
Epoch: 20 | Batch_idx: 160 |  Loss: (0.7300) |  Loss2: (0.0000) | Acc: (74.00%) (15324/20608)
Epoch: 20 | Batch_idx: 170 |  Loss: (0.7291) |  Loss2: (0.0000) | Acc: (74.00%) (16300/21888)
Epoch: 20 | Batch_idx: 180 |  Loss: (0.7272) |  Loss2: (0.0000) | Acc: (74.00%) (17279/23168)
Epoch: 20 | Batch_idx: 190 |  Loss: (0.7262) |  Loss2: (0.0000) | Acc: (74.00%) (18237/24448)
Epoch: 20 | Batch_idx: 200 |  Loss: (0.7272) |  Loss2: (0.0000) | Acc: (74.00%) (19187/25728)
Epoch: 20 | Batch_idx: 210 |  Loss: (0.7272) |  Loss2: (0.0000) | Acc: (74.00%) (20123/27008)
Epoch: 20 | Batch_idx: 220 |  Loss: (0.7271) |  Loss2: (0.0000) | Acc: (74.00%) (21092/28288)
Epoch: 20 | Batch_idx: 230 |  Loss: (0.7270) |  Loss2: (0.0000) | Acc: (74.00%) (22044/29568)
Epoch: 20 | Batch_idx: 240 |  Loss: (0.7276) |  Loss2: (0.0000) | Acc: (74.00%) (22994/30848)
Epoch: 20 | Batch_idx: 250 |  Loss: (0.7282) |  Loss2: (0.0000) | Acc: (74.00%) (23931/32128)
Epoch: 20 | Batch_idx: 260 |  Loss: (0.7286) |  Loss2: (0.0000) | Acc: (74.00%) (24875/33408)
Epoch: 20 | Batch_idx: 270 |  Loss: (0.7272) |  Loss2: (0.0000) | Acc: (74.00%) (25845/34688)
Epoch: 20 | Batch_idx: 280 |  Loss: (0.7251) |  Loss2: (0.0000) | Acc: (74.00%) (26820/35968)
Epoch: 20 | Batch_idx: 290 |  Loss: (0.7260) |  Loss2: (0.0000) | Acc: (74.00%) (27771/37248)
Epoch: 20 | Batch_idx: 300 |  Loss: (0.7243) |  Loss2: (0.0000) | Acc: (74.00%) (28756/38528)
Epoch: 20 | Batch_idx: 310 |  Loss: (0.7243) |  Loss2: (0.0000) | Acc: (74.00%) (29704/39808)
Epoch: 20 | Batch_idx: 320 |  Loss: (0.7245) |  Loss2: (0.0000) | Acc: (74.00%) (30651/41088)
Epoch: 20 | Batch_idx: 330 |  Loss: (0.7239) |  Loss2: (0.0000) | Acc: (74.00%) (31594/42368)
Epoch: 20 | Batch_idx: 340 |  Loss: (0.7240) |  Loss2: (0.0000) | Acc: (74.00%) (32553/43648)
Epoch: 20 | Batch_idx: 350 |  Loss: (0.7239) |  Loss2: (0.0000) | Acc: (74.00%) (33518/44928)
Epoch: 20 | Batch_idx: 360 |  Loss: (0.7232) |  Loss2: (0.0000) | Acc: (74.00%) (34486/46208)
Epoch: 20 | Batch_idx: 370 |  Loss: (0.7227) |  Loss2: (0.0000) | Acc: (74.00%) (35450/47488)
Epoch: 20 | Batch_idx: 380 |  Loss: (0.7227) |  Loss2: (0.0000) | Acc: (74.00%) (36406/48768)
Epoch: 20 | Batch_idx: 390 |  Loss: (0.7228) |  Loss2: (0.0000) | Acc: (74.00%) (37336/50000)
=> saving checkpoint 'drive/app/torch/save_Schedule/checkpoint_020.pth.tar'
# TEST : Loss: (0.8257) | Acc: (71.00%) (7138/10000)
percent tensor([0.5058, 0.5084, 0.5132, 0.5048, 0.5142, 0.5075, 0.5104, 0.5068, 0.5074,
        0.5078, 0.5077, 0.5126, 0.5057, 0.5103, 0.5083, 0.5060],
       device='cuda:0') torch.Size([16])
percent tensor([0.4884, 0.4788, 0.4906, 0.4858, 0.4874, 0.4886, 0.4810, 0.4865, 0.4863,
        0.4838, 0.4835, 0.4877, 0.4854, 0.4780, 0.4814, 0.4848],
       device='cuda:0') torch.Size([16])
percent tensor([0.5356, 0.5325, 0.5260, 0.5186, 0.5274, 0.5307, 0.5345, 0.5240, 0.5205,
        0.5296, 0.5264, 0.5304, 0.5370, 0.5167, 0.5372, 0.5309],
       device='cuda:0') torch.Size([16])
percent tensor([0.5628, 0.5738, 0.5539, 0.5536, 0.5642, 0.5569, 0.5779, 0.5672, 0.5635,
        0.5751, 0.5672, 0.5644, 0.5637, 0.5744, 0.5687, 0.5672],
       device='cuda:0') torch.Size([16])
percent tensor([0.5300, 0.5310, 0.5050, 0.5077, 0.5114, 0.5082, 0.5217, 0.5063, 0.5360,
        0.5453, 0.5404, 0.4960, 0.5336, 0.5420, 0.4973, 0.5287],
       device='cuda:0') torch.Size([16])
percent tensor([0.5381, 0.5345, 0.5437, 0.5451, 0.5508, 0.5471, 0.5380, 0.5531, 0.5333,
        0.5395, 0.5294, 0.5336, 0.5286, 0.5393, 0.5309, 0.5477],
       device='cuda:0') torch.Size([16])
percent tensor([0.5562, 0.5540, 0.5794, 0.5635, 0.6006, 0.5299, 0.5784, 0.6293, 0.5518,
        0.5692, 0.5511, 0.5764, 0.5491, 0.5365, 0.5653, 0.5595],
       device='cuda:0') torch.Size([16])
percent tensor([0.7755, 0.7496, 0.7584, 0.7669, 0.7468, 0.7721, 0.7638, 0.8039, 0.7822,
        0.7781, 0.7913, 0.7844, 0.7655, 0.7830, 0.7923, 0.7797],
       device='cuda:0') torch.Size([16])
Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 3, 3, 3]) tensor(174.8762, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(783.8530, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(782.6003, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([128, 64, 3, 3]) tensor(1534.9706, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([128, 64, 1, 1]) tensor(505.0488, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([128, 128, 3, 3]) tensor(2183.9473, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([256, 128, 3, 3]) tensor(4321.2017, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([256, 128, 1, 1]) tensor(1431.2589, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([256, 256, 3, 3]) tensor(6095.3398, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([512, 256, 3, 3]) tensor(12184.9160, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([512, 256, 1, 1]) tensor(4065.0979, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([512, 512, 3, 3]) tensor(17198.7852, device='cuda:0', grad_fn=<NormBackward0>)
Epoch: 21 | Batch_idx: 0 |  Loss: (0.6932) |  Loss2: (0.0000) | Acc: (75.00%) (96/128)
Epoch: 21 | Batch_idx: 10 |  Loss: (0.6818) |  Loss2: (0.0000) | Acc: (75.00%) (1063/1408)
Epoch: 21 | Batch_idx: 20 |  Loss: (0.6761) |  Loss2: (0.0000) | Acc: (75.00%) (2041/2688)
Epoch: 21 | Batch_idx: 30 |  Loss: (0.6756) |  Loss2: (0.0000) | Acc: (76.00%) (3018/3968)
Epoch: 21 | Batch_idx: 40 |  Loss: (0.6800) |  Loss2: (0.0000) | Acc: (76.00%) (3993/5248)
Epoch: 21 | Batch_idx: 50 |  Loss: (0.6774) |  Loss2: (0.0000) | Acc: (76.00%) (4967/6528)
Epoch: 21 | Batch_idx: 60 |  Loss: (0.6844) |  Loss2: (0.0000) | Acc: (75.00%) (5919/7808)
Epoch: 21 | Batch_idx: 70 |  Loss: (0.6843) |  Loss2: (0.0000) | Acc: (76.00%) (6908/9088)
Epoch: 21 | Batch_idx: 80 |  Loss: (0.6839) |  Loss2: (0.0000) | Acc: (76.00%) (7881/10368)
Epoch: 21 | Batch_idx: 90 |  Loss: (0.6855) |  Loss2: (0.0000) | Acc: (75.00%) (8831/11648)
Epoch: 21 | Batch_idx: 100 |  Loss: (0.6911) |  Loss2: (0.0000) | Acc: (75.00%) (9769/12928)
Epoch: 21 | Batch_idx: 110 |  Loss: (0.6863) |  Loss2: (0.0000) | Acc: (75.00%) (10761/14208)
Epoch: 21 | Batch_idx: 120 |  Loss: (0.6863) |  Loss2: (0.0000) | Acc: (75.00%) (11749/15488)
Epoch: 21 | Batch_idx: 130 |  Loss: (0.6884) |  Loss2: (0.0000) | Acc: (75.00%) (12707/16768)
Epoch: 21 | Batch_idx: 140 |  Loss: (0.6851) |  Loss2: (0.0000) | Acc: (75.00%) (13692/18048)
Epoch: 21 | Batch_idx: 150 |  Loss: (0.6844) |  Loss2: (0.0000) | Acc: (75.00%) (14666/19328)
Epoch: 21 | Batch_idx: 160 |  Loss: (0.6827) |  Loss2: (0.0000) | Acc: (75.00%) (15657/20608)
Epoch: 21 | Batch_idx: 170 |  Loss: (0.6854) |  Loss2: (0.0000) | Acc: (75.00%) (16599/21888)
Epoch: 21 | Batch_idx: 180 |  Loss: (0.6878) |  Loss2: (0.0000) | Acc: (75.00%) (17573/23168)
Epoch: 21 | Batch_idx: 190 |  Loss: (0.6856) |  Loss2: (0.0000) | Acc: (75.00%) (18566/24448)
Epoch: 21 | Batch_idx: 200 |  Loss: (0.6839) |  Loss2: (0.0000) | Acc: (75.00%) (19553/25728)
Epoch: 21 | Batch_idx: 210 |  Loss: (0.6838) |  Loss2: (0.0000) | Acc: (76.00%) (20541/27008)
Epoch: 21 | Batch_idx: 220 |  Loss: (0.6827) |  Loss2: (0.0000) | Acc: (76.00%) (21530/28288)
Epoch: 21 | Batch_idx: 230 |  Loss: (0.6824) |  Loss2: (0.0000) | Acc: (76.00%) (22488/29568)
Epoch: 21 | Batch_idx: 240 |  Loss: (0.6836) |  Loss2: (0.0000) | Acc: (76.00%) (23450/30848)
Epoch: 21 | Batch_idx: 250 |  Loss: (0.6821) |  Loss2: (0.0000) | Acc: (76.00%) (24446/32128)
Epoch: 21 | Batch_idx: 260 |  Loss: (0.6842) |  Loss2: (0.0000) | Acc: (76.00%) (25400/33408)
Epoch: 21 | Batch_idx: 270 |  Loss: (0.6840) |  Loss2: (0.0000) | Acc: (76.00%) (26376/34688)
Epoch: 21 | Batch_idx: 280 |  Loss: (0.6839) |  Loss2: (0.0000) | Acc: (76.00%) (27355/35968)
Epoch: 21 | Batch_idx: 290 |  Loss: (0.6847) |  Loss2: (0.0000) | Acc: (76.00%) (28333/37248)
Epoch: 21 | Batch_idx: 300 |  Loss: (0.6847) |  Loss2: (0.0000) | Acc: (76.00%) (29313/38528)
Epoch: 21 | Batch_idx: 310 |  Loss: (0.6840) |  Loss2: (0.0000) | Acc: (76.00%) (30280/39808)
Epoch: 21 | Batch_idx: 320 |  Loss: (0.6838) |  Loss2: (0.0000) | Acc: (76.00%) (31247/41088)
Epoch: 21 | Batch_idx: 330 |  Loss: (0.6833) |  Loss2: (0.0000) | Acc: (76.00%) (32230/42368)
Epoch: 21 | Batch_idx: 340 |  Loss: (0.6840) |  Loss2: (0.0000) | Acc: (76.00%) (33190/43648)
Epoch: 21 | Batch_idx: 350 |  Loss: (0.6842) |  Loss2: (0.0000) | Acc: (76.00%) (34165/44928)
Epoch: 21 | Batch_idx: 360 |  Loss: (0.6837) |  Loss2: (0.0000) | Acc: (76.00%) (35138/46208)
Epoch: 21 | Batch_idx: 370 |  Loss: (0.6832) |  Loss2: (0.0000) | Acc: (76.00%) (36143/47488)
Epoch: 21 | Batch_idx: 380 |  Loss: (0.6830) |  Loss2: (0.0000) | Acc: (76.00%) (37125/48768)
Epoch: 21 | Batch_idx: 390 |  Loss: (0.6827) |  Loss2: (0.0000) | Acc: (76.00%) (38067/50000)
# TEST : Loss: (0.7978) | Acc: (72.00%) (7263/10000)
percent tensor([0.5056, 0.5081, 0.5126, 0.5049, 0.5139, 0.5072, 0.5105, 0.5065, 0.5072,
        0.5075, 0.5074, 0.5120, 0.5055, 0.5096, 0.5083, 0.5055],
       device='cuda:0') torch.Size([16])
percent tensor([0.4871, 0.4786, 0.4906, 0.4855, 0.4871, 0.4874, 0.4808, 0.4858, 0.4856,
        0.4837, 0.4828, 0.4870, 0.4844, 0.4778, 0.4807, 0.4843],
       device='cuda:0') torch.Size([16])
percent tensor([0.5340, 0.5304, 0.5239, 0.5151, 0.5249, 0.5303, 0.5333, 0.5219, 0.5231,
        0.5259, 0.5269, 0.5277, 0.5377, 0.5172, 0.5349, 0.5292],
       device='cuda:0') torch.Size([16])
percent tensor([0.5625, 0.5713, 0.5517, 0.5544, 0.5599, 0.5543, 0.5724, 0.5660, 0.5608,
        0.5736, 0.5648, 0.5616, 0.5642, 0.5733, 0.5660, 0.5661],
       device='cuda:0') torch.Size([16])
percent tensor([0.5317, 0.5388, 0.5181, 0.5195, 0.5225, 0.5054, 0.5337, 0.5200, 0.5394,
        0.5546, 0.5434, 0.5068, 0.5353, 0.5525, 0.5012, 0.5361],
       device='cuda:0') torch.Size([16])
percent tensor([0.5374, 0.5358, 0.5461, 0.5496, 0.5546, 0.5474, 0.5389, 0.5539, 0.5323,
        0.5389, 0.5279, 0.5336, 0.5292, 0.5418, 0.5322, 0.5478],
       device='cuda:0') torch.Size([16])
percent tensor([0.5519, 0.5611, 0.5671, 0.5625, 0.5843, 0.5333, 0.5739, 0.6178, 0.5487,
        0.5714, 0.5539, 0.5664, 0.5519, 0.5439, 0.5604, 0.5547],
       device='cuda:0') torch.Size([16])
percent tensor([0.7756, 0.7502, 0.7352, 0.7494, 0.7311, 0.7814, 0.7588, 0.7736, 0.7882,
        0.8036, 0.7932, 0.7821, 0.7684, 0.7825, 0.7724, 0.7858],
       device='cuda:0') torch.Size([16])
Epoch: 22 | Batch_idx: 0 |  Loss: (0.7769) |  Loss2: (0.0000) | Acc: (71.00%) (91/128)
Epoch: 22 | Batch_idx: 10 |  Loss: (0.6570) |  Loss2: (0.0000) | Acc: (76.00%) (1073/1408)
Epoch: 22 | Batch_idx: 20 |  Loss: (0.6396) |  Loss2: (0.0000) | Acc: (76.00%) (2062/2688)
Epoch: 22 | Batch_idx: 30 |  Loss: (0.6380) |  Loss2: (0.0000) | Acc: (77.00%) (3056/3968)
Epoch: 22 | Batch_idx: 40 |  Loss: (0.6447) |  Loss2: (0.0000) | Acc: (76.00%) (4032/5248)
Epoch: 22 | Batch_idx: 50 |  Loss: (0.6509) |  Loss2: (0.0000) | Acc: (76.00%) (5013/6528)
Epoch: 22 | Batch_idx: 60 |  Loss: (0.6532) |  Loss2: (0.0000) | Acc: (76.00%) (5998/7808)
Epoch: 22 | Batch_idx: 70 |  Loss: (0.6511) |  Loss2: (0.0000) | Acc: (76.00%) (6989/9088)
Epoch: 22 | Batch_idx: 80 |  Loss: (0.6566) |  Loss2: (0.0000) | Acc: (76.00%) (7957/10368)
Epoch: 22 | Batch_idx: 90 |  Loss: (0.6522) |  Loss2: (0.0000) | Acc: (76.00%) (8958/11648)
Epoch: 22 | Batch_idx: 100 |  Loss: (0.6524) |  Loss2: (0.0000) | Acc: (77.00%) (9959/12928)
Epoch: 22 | Batch_idx: 110 |  Loss: (0.6545) |  Loss2: (0.0000) | Acc: (76.00%) (10933/14208)
Epoch: 22 | Batch_idx: 120 |  Loss: (0.6537) |  Loss2: (0.0000) | Acc: (76.00%) (11925/15488)
Epoch: 22 | Batch_idx: 130 |  Loss: (0.6545) |  Loss2: (0.0000) | Acc: (76.00%) (12895/16768)
Epoch: 22 | Batch_idx: 140 |  Loss: (0.6557) |  Loss2: (0.0000) | Acc: (76.00%) (13871/18048)
Epoch: 22 | Batch_idx: 150 |  Loss: (0.6581) |  Loss2: (0.0000) | Acc: (76.00%) (14837/19328)
Epoch: 22 | Batch_idx: 160 |  Loss: (0.6576) |  Loss2: (0.0000) | Acc: (76.00%) (15838/20608)
Epoch: 22 | Batch_idx: 170 |  Loss: (0.6560) |  Loss2: (0.0000) | Acc: (76.00%) (16827/21888)
Epoch: 22 | Batch_idx: 180 |  Loss: (0.6571) |  Loss2: (0.0000) | Acc: (76.00%) (17815/23168)
Epoch: 22 | Batch_idx: 190 |  Loss: (0.6582) |  Loss2: (0.0000) | Acc: (76.00%) (18799/24448)
Epoch: 22 | Batch_idx: 200 |  Loss: (0.6574) |  Loss2: (0.0000) | Acc: (76.00%) (19795/25728)
Epoch: 22 | Batch_idx: 210 |  Loss: (0.6571) |  Loss2: (0.0000) | Acc: (76.00%) (20787/27008)
Epoch: 22 | Batch_idx: 220 |  Loss: (0.6571) |  Loss2: (0.0000) | Acc: (77.00%) (21784/28288)
Epoch: 22 | Batch_idx: 230 |  Loss: (0.6566) |  Loss2: (0.0000) | Acc: (77.00%) (22784/29568)
Epoch: 22 | Batch_idx: 240 |  Loss: (0.6564) |  Loss2: (0.0000) | Acc: (77.00%) (23773/30848)
Epoch: 22 | Batch_idx: 250 |  Loss: (0.6558) |  Loss2: (0.0000) | Acc: (77.00%) (24754/32128)
Epoch: 22 | Batch_idx: 260 |  Loss: (0.6553) |  Loss2: (0.0000) | Acc: (77.00%) (25736/33408)
Epoch: 22 | Batch_idx: 270 |  Loss: (0.6547) |  Loss2: (0.0000) | Acc: (77.00%) (26726/34688)
Epoch: 22 | Batch_idx: 280 |  Loss: (0.6557) |  Loss2: (0.0000) | Acc: (77.00%) (27706/35968)
Epoch: 22 | Batch_idx: 290 |  Loss: (0.6569) |  Loss2: (0.0000) | Acc: (77.00%) (28691/37248)
Epoch: 22 | Batch_idx: 300 |  Loss: (0.6575) |  Loss2: (0.0000) | Acc: (77.00%) (29671/38528)
Epoch: 22 | Batch_idx: 310 |  Loss: (0.6557) |  Loss2: (0.0000) | Acc: (77.00%) (30690/39808)
Epoch: 22 | Batch_idx: 320 |  Loss: (0.6562) |  Loss2: (0.0000) | Acc: (77.00%) (31684/41088)
Epoch: 22 | Batch_idx: 330 |  Loss: (0.6560) |  Loss2: (0.0000) | Acc: (77.00%) (32687/42368)
Epoch: 22 | Batch_idx: 340 |  Loss: (0.6559) |  Loss2: (0.0000) | Acc: (77.00%) (33667/43648)
Epoch: 22 | Batch_idx: 350 |  Loss: (0.6557) |  Loss2: (0.0000) | Acc: (77.00%) (34649/44928)
Epoch: 22 | Batch_idx: 360 |  Loss: (0.6543) |  Loss2: (0.0000) | Acc: (77.00%) (35657/46208)
Epoch: 22 | Batch_idx: 370 |  Loss: (0.6522) |  Loss2: (0.0000) | Acc: (77.00%) (36685/47488)
Epoch: 22 | Batch_idx: 380 |  Loss: (0.6524) |  Loss2: (0.0000) | Acc: (77.00%) (37675/48768)
Epoch: 22 | Batch_idx: 390 |  Loss: (0.6528) |  Loss2: (0.0000) | Acc: (77.00%) (38624/50000)
# TEST : Loss: (0.7227) | Acc: (74.00%) (7473/10000)
percent tensor([0.5055, 0.5084, 0.5108, 0.5045, 0.5124, 0.5072, 0.5105, 0.5061, 0.5071,
        0.5074, 0.5076, 0.5109, 0.5054, 0.5102, 0.5087, 0.5058],
       device='cuda:0') torch.Size([16])
percent tensor([0.4873, 0.4787, 0.4911, 0.4857, 0.4873, 0.4880, 0.4805, 0.4862, 0.4855,
        0.4836, 0.4833, 0.4872, 0.4847, 0.4764, 0.4810, 0.4847],
       device='cuda:0') torch.Size([16])
percent tensor([0.5350, 0.5333, 0.5218, 0.5150, 0.5235, 0.5308, 0.5345, 0.5226, 0.5218,
        0.5279, 0.5291, 0.5266, 0.5381, 0.5210, 0.5372, 0.5313],
       device='cuda:0') torch.Size([16])
percent tensor([0.5613, 0.5705, 0.5502, 0.5527, 0.5582, 0.5551, 0.5719, 0.5653, 0.5633,
        0.5715, 0.5658, 0.5608, 0.5642, 0.5721, 0.5665, 0.5662],
       device='cuda:0') torch.Size([16])
percent tensor([0.5270, 0.5309, 0.5164, 0.5212, 0.5203, 0.5041, 0.5218, 0.5108, 0.5381,
        0.5451, 0.5396, 0.5031, 0.5313, 0.5447, 0.4928, 0.5292],
       device='cuda:0') torch.Size([16])
percent tensor([0.5361, 0.5330, 0.5475, 0.5524, 0.5541, 0.5446, 0.5368, 0.5508, 0.5332,
        0.5368, 0.5276, 0.5346, 0.5283, 0.5393, 0.5305, 0.5470],
       device='cuda:0') torch.Size([16])
percent tensor([0.5458, 0.5534, 0.5677, 0.5633, 0.5872, 0.5258, 0.5666, 0.6056, 0.5475,
        0.5548, 0.5474, 0.5654, 0.5416, 0.5390, 0.5572, 0.5541],
       device='cuda:0') torch.Size([16])
percent tensor([0.7749, 0.7363, 0.7373, 0.7545, 0.7289, 0.7541, 0.7468, 0.7734, 0.7791,
        0.7668, 0.7757, 0.7658, 0.7543, 0.7699, 0.7620, 0.7850],
       device='cuda:0') torch.Size([16])
Epoch: 23 | Batch_idx: 0 |  Loss: (0.5792) |  Loss2: (0.0000) | Acc: (75.00%) (97/128)
Epoch: 23 | Batch_idx: 10 |  Loss: (0.6020) |  Loss2: (0.0000) | Acc: (78.00%) (1099/1408)
Epoch: 23 | Batch_idx: 20 |  Loss: (0.6227) |  Loss2: (0.0000) | Acc: (77.00%) (2078/2688)
Epoch: 23 | Batch_idx: 30 |  Loss: (0.6146) |  Loss2: (0.0000) | Acc: (77.00%) (3086/3968)
Epoch: 23 | Batch_idx: 40 |  Loss: (0.6101) |  Loss2: (0.0000) | Acc: (77.00%) (4091/5248)
Epoch: 23 | Batch_idx: 50 |  Loss: (0.6074) |  Loss2: (0.0000) | Acc: (78.00%) (5112/6528)
Epoch: 23 | Batch_idx: 60 |  Loss: (0.6144) |  Loss2: (0.0000) | Acc: (78.00%) (6107/7808)
Epoch: 23 | Batch_idx: 70 |  Loss: (0.6248) |  Loss2: (0.0000) | Acc: (78.00%) (7090/9088)
Epoch: 23 | Batch_idx: 80 |  Loss: (0.6314) |  Loss2: (0.0000) | Acc: (77.00%) (8076/10368)
Epoch: 23 | Batch_idx: 90 |  Loss: (0.6278) |  Loss2: (0.0000) | Acc: (78.00%) (9092/11648)
Epoch: 23 | Batch_idx: 100 |  Loss: (0.6297) |  Loss2: (0.0000) | Acc: (77.00%) (10076/12928)
Epoch: 23 | Batch_idx: 110 |  Loss: (0.6269) |  Loss2: (0.0000) | Acc: (78.00%) (11091/14208)
Epoch: 23 | Batch_idx: 120 |  Loss: (0.6283) |  Loss2: (0.0000) | Acc: (78.00%) (12084/15488)
Epoch: 23 | Batch_idx: 130 |  Loss: (0.6277) |  Loss2: (0.0000) | Acc: (78.00%) (13092/16768)
Epoch: 23 | Batch_idx: 140 |  Loss: (0.6256) |  Loss2: (0.0000) | Acc: (78.00%) (14107/18048)
Epoch: 23 | Batch_idx: 150 |  Loss: (0.6269) |  Loss2: (0.0000) | Acc: (78.00%) (15097/19328)
Epoch: 23 | Batch_idx: 160 |  Loss: (0.6273) |  Loss2: (0.0000) | Acc: (78.00%) (16101/20608)
Epoch: 23 | Batch_idx: 170 |  Loss: (0.6248) |  Loss2: (0.0000) | Acc: (78.00%) (17125/21888)
Epoch: 23 | Batch_idx: 180 |  Loss: (0.6243) |  Loss2: (0.0000) | Acc: (78.00%) (18133/23168)
Epoch: 23 | Batch_idx: 190 |  Loss: (0.6255) |  Loss2: (0.0000) | Acc: (78.00%) (19129/24448)
Epoch: 23 | Batch_idx: 200 |  Loss: (0.6243) |  Loss2: (0.0000) | Acc: (78.00%) (20143/25728)
Epoch: 23 | Batch_idx: 210 |  Loss: (0.6231) |  Loss2: (0.0000) | Acc: (78.00%) (21161/27008)
Epoch: 23 | Batch_idx: 220 |  Loss: (0.6237) |  Loss2: (0.0000) | Acc: (78.00%) (22165/28288)
Epoch: 23 | Batch_idx: 230 |  Loss: (0.6260) |  Loss2: (0.0000) | Acc: (78.00%) (23155/29568)
Epoch: 23 | Batch_idx: 240 |  Loss: (0.6257) |  Loss2: (0.0000) | Acc: (78.00%) (24162/30848)
Epoch: 23 | Batch_idx: 250 |  Loss: (0.6254) |  Loss2: (0.0000) | Acc: (78.00%) (25184/32128)
Epoch: 23 | Batch_idx: 260 |  Loss: (0.6262) |  Loss2: (0.0000) | Acc: (78.00%) (26174/33408)
Epoch: 23 | Batch_idx: 270 |  Loss: (0.6277) |  Loss2: (0.0000) | Acc: (78.00%) (27149/34688)
Epoch: 23 | Batch_idx: 280 |  Loss: (0.6264) |  Loss2: (0.0000) | Acc: (78.00%) (28171/35968)
Epoch: 23 | Batch_idx: 290 |  Loss: (0.6266) |  Loss2: (0.0000) | Acc: (78.00%) (29152/37248)
Epoch: 23 | Batch_idx: 300 |  Loss: (0.6261) |  Loss2: (0.0000) | Acc: (78.00%) (30157/38528)
Epoch: 23 | Batch_idx: 310 |  Loss: (0.6258) |  Loss2: (0.0000) | Acc: (78.00%) (31172/39808)
Epoch: 23 | Batch_idx: 320 |  Loss: (0.6251) |  Loss2: (0.0000) | Acc: (78.00%) (32180/41088)
Epoch: 23 | Batch_idx: 330 |  Loss: (0.6245) |  Loss2: (0.0000) | Acc: (78.00%) (33200/42368)
Epoch: 23 | Batch_idx: 340 |  Loss: (0.6254) |  Loss2: (0.0000) | Acc: (78.00%) (34181/43648)
Epoch: 23 | Batch_idx: 350 |  Loss: (0.6248) |  Loss2: (0.0000) | Acc: (78.00%) (35186/44928)
Epoch: 23 | Batch_idx: 360 |  Loss: (0.6234) |  Loss2: (0.0000) | Acc: (78.00%) (36214/46208)
Epoch: 23 | Batch_idx: 370 |  Loss: (0.6237) |  Loss2: (0.0000) | Acc: (78.00%) (37217/47488)
Epoch: 23 | Batch_idx: 380 |  Loss: (0.6248) |  Loss2: (0.0000) | Acc: (78.00%) (38210/48768)
Epoch: 23 | Batch_idx: 390 |  Loss: (0.6244) |  Loss2: (0.0000) | Acc: (78.00%) (39180/50000)
# TEST : Loss: (0.7440) | Acc: (74.00%) (7411/10000)
percent tensor([0.5058, 0.5084, 0.5117, 0.5047, 0.5131, 0.5072, 0.5102, 0.5066, 0.5072,
        0.5077, 0.5077, 0.5115, 0.5057, 0.5101, 0.5084, 0.5061],
       device='cuda:0') torch.Size([16])
percent tensor([0.4875, 0.4790, 0.4903, 0.4852, 0.4870, 0.4879, 0.4810, 0.4858, 0.4865,
        0.4840, 0.4838, 0.4868, 0.4853, 0.4782, 0.4809, 0.4846],
       device='cuda:0') torch.Size([16])
percent tensor([0.5343, 0.5318, 0.5246, 0.5176, 0.5261, 0.5314, 0.5326, 0.5229, 0.5210,
        0.5273, 0.5264, 0.5286, 0.5376, 0.5153, 0.5370, 0.5299],
       device='cuda:0') torch.Size([16])
percent tensor([0.5620, 0.5713, 0.5488, 0.5533, 0.5580, 0.5560, 0.5717, 0.5667, 0.5628,
        0.5725, 0.5651, 0.5596, 0.5649, 0.5720, 0.5658, 0.5670],
       device='cuda:0') torch.Size([16])
percent tensor([0.5262, 0.5342, 0.5030, 0.5083, 0.5092, 0.5056, 0.5225, 0.5087, 0.5388,
        0.5458, 0.5403, 0.4918, 0.5326, 0.5521, 0.4972, 0.5316],
       device='cuda:0') torch.Size([16])
percent tensor([0.5365, 0.5370, 0.5389, 0.5470, 0.5481, 0.5469, 0.5379, 0.5511, 0.5338,
        0.5388, 0.5286, 0.5300, 0.5274, 0.5428, 0.5315, 0.5487],
       device='cuda:0') torch.Size([16])
percent tensor([0.5482, 0.5571, 0.5593, 0.5707, 0.5821, 0.5335, 0.5655, 0.6163, 0.5461,
        0.5618, 0.5502, 0.5629, 0.5427, 0.5386, 0.5600, 0.5560],
       device='cuda:0') torch.Size([16])
percent tensor([0.7620, 0.7471, 0.7436, 0.7681, 0.7260, 0.7559, 0.7418, 0.7837, 0.7775,
        0.7903, 0.7856, 0.7753, 0.7624, 0.7612, 0.7816, 0.7848],
       device='cuda:0') torch.Size([16])
False Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=128, out_features=16, bias=False)
True Linear(in_features=16, out_features=2, bias=False)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=128, out_features=16, bias=False)
True Linear(in_features=16, out_features=2, bias=False)
False Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=256, out_features=32, bias=False)
True Linear(in_features=32, out_features=2, bias=False)
False Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=256, out_features=32, bias=False)
True Linear(in_features=32, out_features=2, bias=False)
False Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=512, out_features=64, bias=False)
True Linear(in_features=64, out_features=2, bias=False)
False Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=512, out_features=64, bias=False)
True Linear(in_features=64, out_features=2, bias=False)
False Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1024, out_features=128, bias=False)
True Linear(in_features=128, out_features=2, bias=False)
False Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1024, out_features=128, bias=False)
True Linear(in_features=128, out_features=2, bias=False)
False Linear(in_features=512, out_features=10, bias=True)
Epoch: 24 | Batch_idx: 0 |  Loss: (0.4424) |  Loss2: (0.0000) | Acc: (84.00%) (108/128)
Epoch: 24 | Batch_idx: 10 |  Loss: (0.6146) |  Loss2: (0.0000) | Acc: (78.00%) (1102/1408)
Epoch: 24 | Batch_idx: 20 |  Loss: (0.6680) |  Loss2: (0.0000) | Acc: (76.00%) (2051/2688)
Epoch: 24 | Batch_idx: 30 |  Loss: (0.7023) |  Loss2: (0.0000) | Acc: (75.00%) (3002/3968)
Epoch: 24 | Batch_idx: 40 |  Loss: (0.7189) |  Loss2: (0.0000) | Acc: (74.00%) (3930/5248)
Epoch: 24 | Batch_idx: 50 |  Loss: (0.7297) |  Loss2: (0.0000) | Acc: (74.00%) (4854/6528)
Epoch: 24 | Batch_idx: 60 |  Loss: (0.7420) |  Loss2: (0.0000) | Acc: (73.00%) (5777/7808)
Epoch: 24 | Batch_idx: 70 |  Loss: (0.7419) |  Loss2: (0.0000) | Acc: (73.00%) (6723/9088)
Epoch: 24 | Batch_idx: 80 |  Loss: (0.7436) |  Loss2: (0.0000) | Acc: (73.00%) (7661/10368)
Epoch: 24 | Batch_idx: 90 |  Loss: (0.7327) |  Loss2: (0.0000) | Acc: (74.00%) (8653/11648)
Epoch: 24 | Batch_idx: 100 |  Loss: (0.7326) |  Loss2: (0.0000) | Acc: (74.00%) (9608/12928)
Epoch: 24 | Batch_idx: 110 |  Loss: (0.7267) |  Loss2: (0.0000) | Acc: (74.00%) (10603/14208)
Epoch: 24 | Batch_idx: 120 |  Loss: (0.7244) |  Loss2: (0.0000) | Acc: (74.00%) (11577/15488)
Epoch: 24 | Batch_idx: 130 |  Loss: (0.7237) |  Loss2: (0.0000) | Acc: (74.00%) (12532/16768)
Epoch: 24 | Batch_idx: 140 |  Loss: (0.7232) |  Loss2: (0.0000) | Acc: (74.00%) (13475/18048)
Epoch: 24 | Batch_idx: 150 |  Loss: (0.7191) |  Loss2: (0.0000) | Acc: (74.00%) (14457/19328)
Epoch: 24 | Batch_idx: 160 |  Loss: (0.7157) |  Loss2: (0.0000) | Acc: (74.00%) (15448/20608)
Epoch: 24 | Batch_idx: 170 |  Loss: (0.7118) |  Loss2: (0.0000) | Acc: (75.00%) (16440/21888)
Epoch: 24 | Batch_idx: 180 |  Loss: (0.7103) |  Loss2: (0.0000) | Acc: (75.00%) (17413/23168)
Epoch: 24 | Batch_idx: 190 |  Loss: (0.7086) |  Loss2: (0.0000) | Acc: (75.00%) (18405/24448)
Epoch: 24 | Batch_idx: 200 |  Loss: (0.7070) |  Loss2: (0.0000) | Acc: (75.00%) (19374/25728)
Epoch: 24 | Batch_idx: 210 |  Loss: (0.7044) |  Loss2: (0.0000) | Acc: (75.00%) (20341/27008)
Epoch: 24 | Batch_idx: 220 |  Loss: (0.7038) |  Loss2: (0.0000) | Acc: (75.00%) (21309/28288)
Epoch: 24 | Batch_idx: 230 |  Loss: (0.7024) |  Loss2: (0.0000) | Acc: (75.00%) (22290/29568)
Epoch: 24 | Batch_idx: 240 |  Loss: (0.7003) |  Loss2: (0.0000) | Acc: (75.00%) (23273/30848)
Epoch: 24 | Batch_idx: 250 |  Loss: (0.6989) |  Loss2: (0.0000) | Acc: (75.00%) (24250/32128)
Epoch: 24 | Batch_idx: 260 |  Loss: (0.6978) |  Loss2: (0.0000) | Acc: (75.00%) (25223/33408)
Epoch: 24 | Batch_idx: 270 |  Loss: (0.6965) |  Loss2: (0.0000) | Acc: (75.00%) (26209/34688)
Epoch: 24 | Batch_idx: 280 |  Loss: (0.6936) |  Loss2: (0.0000) | Acc: (75.00%) (27222/35968)
Epoch: 24 | Batch_idx: 290 |  Loss: (0.6926) |  Loss2: (0.0000) | Acc: (75.00%) (28212/37248)
Epoch: 24 | Batch_idx: 300 |  Loss: (0.6914) |  Loss2: (0.0000) | Acc: (75.00%) (29187/38528)
Epoch: 24 | Batch_idx: 310 |  Loss: (0.6903) |  Loss2: (0.0000) | Acc: (75.00%) (30174/39808)
Epoch: 24 | Batch_idx: 320 |  Loss: (0.6891) |  Loss2: (0.0000) | Acc: (75.00%) (31161/41088)
Epoch: 24 | Batch_idx: 330 |  Loss: (0.6877) |  Loss2: (0.0000) | Acc: (75.00%) (32155/42368)
Epoch: 24 | Batch_idx: 340 |  Loss: (0.6864) |  Loss2: (0.0000) | Acc: (75.00%) (33149/43648)
Epoch: 24 | Batch_idx: 350 |  Loss: (0.6845) |  Loss2: (0.0000) | Acc: (76.00%) (34148/44928)
Epoch: 24 | Batch_idx: 360 |  Loss: (0.6834) |  Loss2: (0.0000) | Acc: (76.00%) (35128/46208)
Epoch: 24 | Batch_idx: 370 |  Loss: (0.6817) |  Loss2: (0.0000) | Acc: (76.00%) (36139/47488)
Epoch: 24 | Batch_idx: 380 |  Loss: (0.6798) |  Loss2: (0.0000) | Acc: (76.00%) (37157/48768)
Epoch: 24 | Batch_idx: 390 |  Loss: (0.6783) |  Loss2: (0.0000) | Acc: (76.00%) (38110/50000)
# TEST : Loss: (0.6875) | Acc: (76.00%) (7657/10000)
percent tensor([0.4994, 0.5005, 0.4988, 0.4963, 0.5004, 0.5015, 0.4999, 0.4961, 0.4995,
        0.4979, 0.5011, 0.4988, 0.4990, 0.5020, 0.5006, 0.4997],
       device='cuda:0') torch.Size([16])
percent tensor([0.4769, 0.4631, 0.4792, 0.4731, 0.4730, 0.4795, 0.4647, 0.4717, 0.4724,
        0.4690, 0.4694, 0.4725, 0.4724, 0.4610, 0.4678, 0.4731],
       device='cuda:0') torch.Size([16])
percent tensor([0.5426, 0.5466, 0.5071, 0.5075, 0.5116, 0.5475, 0.5412, 0.5113, 0.5200,
        0.5338, 0.5358, 0.5183, 0.5468, 0.5351, 0.5495, 0.5417],
       device='cuda:0') torch.Size([16])
percent tensor([0.5651, 0.5676, 0.5608, 0.5645, 0.5682, 0.5605, 0.5723, 0.5762, 0.5675,
        0.5707, 0.5643, 0.5704, 0.5639, 0.5660, 0.5713, 0.5683],
       device='cuda:0') torch.Size([16])
percent tensor([0.5150, 0.5115, 0.5045, 0.5049, 0.5083, 0.5060, 0.5006, 0.5006, 0.5261,
        0.5214, 0.5207, 0.4867, 0.5166, 0.5271, 0.4851, 0.5148],
       device='cuda:0') torch.Size([16])
percent tensor([0.5444, 0.5426, 0.5499, 0.5536, 0.5593, 0.5518, 0.5438, 0.5605, 0.5449,
        0.5460, 0.5376, 0.5411, 0.5366, 0.5471, 0.5399, 0.5541],
       device='cuda:0') torch.Size([16])
percent tensor([0.5498, 0.5634, 0.5446, 0.5454, 0.5560, 0.5288, 0.5572, 0.5660, 0.5528,
        0.5681, 0.5561, 0.5511, 0.5569, 0.5549, 0.5421, 0.5472],
       device='cuda:0') torch.Size([16])
percent tensor([0.8029, 0.8040, 0.8047, 0.8383, 0.7928, 0.8097, 0.7957, 0.8206, 0.8238,
        0.8511, 0.8392, 0.8331, 0.8159, 0.8147, 0.8054, 0.8200],
       device='cuda:0') torch.Size([16])
Epoch: 25 | Batch_idx: 0 |  Loss: (0.5719) |  Loss2: (0.0000) | Acc: (80.00%) (103/128)
Epoch: 25 | Batch_idx: 10 |  Loss: (0.6352) |  Loss2: (0.0000) | Acc: (77.00%) (1092/1408)
Epoch: 25 | Batch_idx: 20 |  Loss: (0.6633) |  Loss2: (0.0000) | Acc: (77.00%) (2082/2688)
Epoch: 25 | Batch_idx: 30 |  Loss: (0.6477) |  Loss2: (0.0000) | Acc: (77.00%) (3088/3968)
Epoch: 25 | Batch_idx: 40 |  Loss: (0.6377) |  Loss2: (0.0000) | Acc: (78.00%) (4104/5248)
Epoch: 25 | Batch_idx: 50 |  Loss: (0.6431) |  Loss2: (0.0000) | Acc: (77.00%) (5089/6528)
Epoch: 25 | Batch_idx: 60 |  Loss: (0.6345) |  Loss2: (0.0000) | Acc: (78.00%) (6111/7808)
Epoch: 25 | Batch_idx: 70 |  Loss: (0.6326) |  Loss2: (0.0000) | Acc: (78.00%) (7108/9088)
Epoch: 25 | Batch_idx: 80 |  Loss: (0.6298) |  Loss2: (0.0000) | Acc: (78.00%) (8118/10368)
Epoch: 25 | Batch_idx: 90 |  Loss: (0.6277) |  Loss2: (0.0000) | Acc: (78.00%) (9122/11648)
Epoch: 25 | Batch_idx: 100 |  Loss: (0.6282) |  Loss2: (0.0000) | Acc: (78.00%) (10107/12928)
Epoch: 25 | Batch_idx: 110 |  Loss: (0.6271) |  Loss2: (0.0000) | Acc: (78.00%) (11114/14208)
Epoch: 25 | Batch_idx: 120 |  Loss: (0.6267) |  Loss2: (0.0000) | Acc: (78.00%) (12147/15488)
Epoch: 25 | Batch_idx: 130 |  Loss: (0.6264) |  Loss2: (0.0000) | Acc: (78.00%) (13143/16768)
Epoch: 25 | Batch_idx: 140 |  Loss: (0.6276) |  Loss2: (0.0000) | Acc: (78.00%) (14123/18048)
Epoch: 25 | Batch_idx: 150 |  Loss: (0.6271) |  Loss2: (0.0000) | Acc: (78.00%) (15132/19328)
Epoch: 25 | Batch_idx: 160 |  Loss: (0.6258) |  Loss2: (0.0000) | Acc: (78.00%) (16129/20608)
Epoch: 25 | Batch_idx: 170 |  Loss: (0.6254) |  Loss2: (0.0000) | Acc: (78.00%) (17124/21888)
Epoch: 25 | Batch_idx: 180 |  Loss: (0.6284) |  Loss2: (0.0000) | Acc: (78.00%) (18095/23168)
Epoch: 25 | Batch_idx: 190 |  Loss: (0.6263) |  Loss2: (0.0000) | Acc: (78.00%) (19118/24448)
Epoch: 25 | Batch_idx: 200 |  Loss: (0.6283) |  Loss2: (0.0000) | Acc: (78.00%) (20076/25728)
Epoch: 25 | Batch_idx: 210 |  Loss: (0.6260) |  Loss2: (0.0000) | Acc: (78.00%) (21082/27008)
Epoch: 25 | Batch_idx: 220 |  Loss: (0.6262) |  Loss2: (0.0000) | Acc: (78.00%) (22085/28288)
Epoch: 25 | Batch_idx: 230 |  Loss: (0.6268) |  Loss2: (0.0000) | Acc: (78.00%) (23079/29568)
Epoch: 25 | Batch_idx: 240 |  Loss: (0.6258) |  Loss2: (0.0000) | Acc: (78.00%) (24111/30848)
Epoch: 25 | Batch_idx: 250 |  Loss: (0.6256) |  Loss2: (0.0000) | Acc: (78.00%) (25104/32128)
Epoch: 25 | Batch_idx: 260 |  Loss: (0.6238) |  Loss2: (0.0000) | Acc: (78.00%) (26127/33408)
Epoch: 25 | Batch_idx: 270 |  Loss: (0.6228) |  Loss2: (0.0000) | Acc: (78.00%) (27129/34688)
Epoch: 25 | Batch_idx: 280 |  Loss: (0.6228) |  Loss2: (0.0000) | Acc: (78.00%) (28135/35968)
Epoch: 25 | Batch_idx: 290 |  Loss: (0.6217) |  Loss2: (0.0000) | Acc: (78.00%) (29151/37248)
Epoch: 25 | Batch_idx: 300 |  Loss: (0.6221) |  Loss2: (0.0000) | Acc: (78.00%) (30138/38528)
Epoch: 25 | Batch_idx: 310 |  Loss: (0.6219) |  Loss2: (0.0000) | Acc: (78.00%) (31137/39808)
Epoch: 25 | Batch_idx: 320 |  Loss: (0.6212) |  Loss2: (0.0000) | Acc: (78.00%) (32142/41088)
Epoch: 25 | Batch_idx: 330 |  Loss: (0.6206) |  Loss2: (0.0000) | Acc: (78.00%) (33144/42368)
Epoch: 25 | Batch_idx: 340 |  Loss: (0.6199) |  Loss2: (0.0000) | Acc: (78.00%) (34157/43648)
Epoch: 25 | Batch_idx: 350 |  Loss: (0.6201) |  Loss2: (0.0000) | Acc: (78.00%) (35157/44928)
Epoch: 25 | Batch_idx: 360 |  Loss: (0.6206) |  Loss2: (0.0000) | Acc: (78.00%) (36141/46208)
Epoch: 25 | Batch_idx: 370 |  Loss: (0.6212) |  Loss2: (0.0000) | Acc: (78.00%) (37143/47488)
Epoch: 25 | Batch_idx: 380 |  Loss: (0.6217) |  Loss2: (0.0000) | Acc: (78.00%) (38132/48768)
Epoch: 25 | Batch_idx: 390 |  Loss: (0.6215) |  Loss2: (0.0000) | Acc: (78.00%) (39120/50000)
=> saving checkpoint 'drive/app/torch/save_Schedule/checkpoint_025.pth.tar'
# TEST : Loss: (0.6574) | Acc: (77.00%) (7750/10000)
percent tensor([0.4963, 0.4968, 0.4952, 0.4933, 0.4963, 0.4986, 0.4960, 0.4926, 0.4960,
        0.4944, 0.4977, 0.4949, 0.4959, 0.4979, 0.4972, 0.4966],
       device='cuda:0') torch.Size([16])
percent tensor([0.4726, 0.4565, 0.4740, 0.4694, 0.4671, 0.4773, 0.4579, 0.4662, 0.4666,
        0.4625, 0.4634, 0.4661, 0.4665, 0.4555, 0.4630, 0.4690],
       device='cuda:0') torch.Size([16])
percent tensor([0.5447, 0.5464, 0.4997, 0.4986, 0.5063, 0.5548, 0.5422, 0.5055, 0.5161,
        0.5307, 0.5343, 0.5103, 0.5458, 0.5342, 0.5528, 0.5425],
       device='cuda:0') torch.Size([16])
percent tensor([0.5645, 0.5633, 0.5635, 0.5689, 0.5701, 0.5631, 0.5706, 0.5777, 0.5671,
        0.5664, 0.5615, 0.5728, 0.5610, 0.5635, 0.5719, 0.5672],
       device='cuda:0') torch.Size([16])
percent tensor([0.5099, 0.5072, 0.4969, 0.4979, 0.4984, 0.5063, 0.4907, 0.4861, 0.5215,
        0.5148, 0.5159, 0.4772, 0.5136, 0.5247, 0.4784, 0.5078],
       device='cuda:0') torch.Size([16])
percent tensor([0.5555, 0.5554, 0.5619, 0.5673, 0.5712, 0.5600, 0.5575, 0.5747, 0.5571,
        0.5604, 0.5509, 0.5565, 0.5487, 0.5601, 0.5538, 0.5651],
       device='cuda:0') torch.Size([16])
percent tensor([0.5579, 0.5740, 0.5422, 0.5419, 0.5471, 0.5298, 0.5606, 0.5476, 0.5659,
        0.5833, 0.5688, 0.5541, 0.5759, 0.5713, 0.5381, 0.5498],
       device='cuda:0') torch.Size([16])
percent tensor([0.8517, 0.8551, 0.8502, 0.8809, 0.8423, 0.8554, 0.8437, 0.8680, 0.8765,
        0.9006, 0.8890, 0.8856, 0.8646, 0.8651, 0.8467, 0.8665],
       device='cuda:0') torch.Size([16])
Epoch: 26 | Batch_idx: 0 |  Loss: (0.5681) |  Loss2: (0.0000) | Acc: (78.00%) (101/128)
Epoch: 26 | Batch_idx: 10 |  Loss: (0.5844) |  Loss2: (0.0000) | Acc: (80.00%) (1132/1408)
Epoch: 26 | Batch_idx: 20 |  Loss: (0.5966) |  Loss2: (0.0000) | Acc: (79.00%) (2141/2688)
Epoch: 26 | Batch_idx: 30 |  Loss: (0.5897) |  Loss2: (0.0000) | Acc: (79.00%) (3163/3968)
Epoch: 26 | Batch_idx: 40 |  Loss: (0.5956) |  Loss2: (0.0000) | Acc: (79.00%) (4189/5248)
Epoch: 26 | Batch_idx: 50 |  Loss: (0.5959) |  Loss2: (0.0000) | Acc: (79.00%) (5193/6528)
Epoch: 26 | Batch_idx: 60 |  Loss: (0.5966) |  Loss2: (0.0000) | Acc: (79.00%) (6203/7808)
Epoch: 26 | Batch_idx: 70 |  Loss: (0.6012) |  Loss2: (0.0000) | Acc: (79.00%) (7198/9088)
Epoch: 26 | Batch_idx: 80 |  Loss: (0.6021) |  Loss2: (0.0000) | Acc: (79.00%) (8195/10368)
Epoch: 26 | Batch_idx: 90 |  Loss: (0.6001) |  Loss2: (0.0000) | Acc: (79.00%) (9220/11648)
Epoch: 26 | Batch_idx: 100 |  Loss: (0.6033) |  Loss2: (0.0000) | Acc: (79.00%) (10220/12928)
Epoch: 26 | Batch_idx: 110 |  Loss: (0.6031) |  Loss2: (0.0000) | Acc: (78.00%) (11223/14208)
Epoch: 26 | Batch_idx: 120 |  Loss: (0.6019) |  Loss2: (0.0000) | Acc: (79.00%) (12247/15488)
Epoch: 26 | Batch_idx: 130 |  Loss: (0.6020) |  Loss2: (0.0000) | Acc: (79.00%) (13277/16768)
Epoch: 26 | Batch_idx: 140 |  Loss: (0.6027) |  Loss2: (0.0000) | Acc: (79.00%) (14281/18048)
Epoch: 26 | Batch_idx: 150 |  Loss: (0.6023) |  Loss2: (0.0000) | Acc: (79.00%) (15300/19328)
Epoch: 26 | Batch_idx: 160 |  Loss: (0.6010) |  Loss2: (0.0000) | Acc: (79.00%) (16327/20608)
Epoch: 26 | Batch_idx: 170 |  Loss: (0.5991) |  Loss2: (0.0000) | Acc: (79.00%) (17340/21888)
Epoch: 26 | Batch_idx: 180 |  Loss: (0.5986) |  Loss2: (0.0000) | Acc: (79.00%) (18354/23168)
Epoch: 26 | Batch_idx: 190 |  Loss: (0.5989) |  Loss2: (0.0000) | Acc: (79.00%) (19366/24448)
Epoch: 26 | Batch_idx: 200 |  Loss: (0.5988) |  Loss2: (0.0000) | Acc: (79.00%) (20398/25728)
Epoch: 26 | Batch_idx: 210 |  Loss: (0.5984) |  Loss2: (0.0000) | Acc: (79.00%) (21428/27008)
Epoch: 26 | Batch_idx: 220 |  Loss: (0.6007) |  Loss2: (0.0000) | Acc: (79.00%) (22420/28288)
Epoch: 26 | Batch_idx: 230 |  Loss: (0.6018) |  Loss2: (0.0000) | Acc: (79.00%) (23415/29568)
Epoch: 26 | Batch_idx: 240 |  Loss: (0.6001) |  Loss2: (0.0000) | Acc: (79.00%) (24444/30848)
Epoch: 26 | Batch_idx: 250 |  Loss: (0.6010) |  Loss2: (0.0000) | Acc: (79.00%) (25427/32128)
Epoch: 26 | Batch_idx: 260 |  Loss: (0.6015) |  Loss2: (0.0000) | Acc: (79.00%) (26439/33408)
Epoch: 26 | Batch_idx: 270 |  Loss: (0.6030) |  Loss2: (0.0000) | Acc: (79.00%) (27417/34688)
Epoch: 26 | Batch_idx: 280 |  Loss: (0.6036) |  Loss2: (0.0000) | Acc: (79.00%) (28421/35968)
Epoch: 26 | Batch_idx: 290 |  Loss: (0.6026) |  Loss2: (0.0000) | Acc: (79.00%) (29429/37248)
Epoch: 26 | Batch_idx: 300 |  Loss: (0.6023) |  Loss2: (0.0000) | Acc: (79.00%) (30446/38528)
Epoch: 26 | Batch_idx: 310 |  Loss: (0.6013) |  Loss2: (0.0000) | Acc: (79.00%) (31476/39808)
Epoch: 26 | Batch_idx: 320 |  Loss: (0.6016) |  Loss2: (0.0000) | Acc: (79.00%) (32469/41088)
Epoch: 26 | Batch_idx: 330 |  Loss: (0.6017) |  Loss2: (0.0000) | Acc: (79.00%) (33480/42368)
Epoch: 26 | Batch_idx: 340 |  Loss: (0.6019) |  Loss2: (0.0000) | Acc: (79.00%) (34486/43648)
Epoch: 26 | Batch_idx: 350 |  Loss: (0.6035) |  Loss2: (0.0000) | Acc: (78.00%) (35463/44928)
Epoch: 26 | Batch_idx: 360 |  Loss: (0.6030) |  Loss2: (0.0000) | Acc: (78.00%) (36481/46208)
Epoch: 26 | Batch_idx: 370 |  Loss: (0.6023) |  Loss2: (0.0000) | Acc: (78.00%) (37514/47488)
Epoch: 26 | Batch_idx: 380 |  Loss: (0.6031) |  Loss2: (0.0000) | Acc: (78.00%) (38496/48768)
Epoch: 26 | Batch_idx: 390 |  Loss: (0.6022) |  Loss2: (0.0000) | Acc: (78.00%) (39479/50000)
# TEST : Loss: (0.6448) | Acc: (77.00%) (7790/10000)
percent tensor([0.4964, 0.4968, 0.4959, 0.4939, 0.4968, 0.4987, 0.4962, 0.4933, 0.4960,
        0.4948, 0.4977, 0.4956, 0.4962, 0.4977, 0.4973, 0.4967],
       device='cuda:0') torch.Size([16])
percent tensor([0.4728, 0.4564, 0.4739, 0.4705, 0.4669, 0.4786, 0.4577, 0.4663, 0.4660,
        0.4622, 0.4630, 0.4656, 0.4659, 0.4560, 0.4636, 0.4696],
       device='cuda:0') torch.Size([16])
percent tensor([0.5436, 0.5414, 0.4984, 0.4934, 0.5057, 0.5568, 0.5411, 0.5031, 0.5126,
        0.5258, 0.5297, 0.5059, 0.5408, 0.5290, 0.5514, 0.5395],
       device='cuda:0') torch.Size([16])
percent tensor([0.5665, 0.5628, 0.5674, 0.5739, 0.5734, 0.5669, 0.5718, 0.5809, 0.5692,
        0.5658, 0.5619, 0.5767, 0.5616, 0.5645, 0.5747, 0.5687],
       device='cuda:0') torch.Size([16])
percent tensor([0.5095, 0.5103, 0.4911, 0.4927, 0.4930, 0.5072, 0.4882, 0.4777, 0.5230,
        0.5159, 0.5190, 0.4719, 0.5171, 0.5294, 0.4761, 0.5060],
       device='cuda:0') torch.Size([16])
percent tensor([0.5620, 0.5635, 0.5687, 0.5746, 0.5783, 0.5643, 0.5659, 0.5832, 0.5641,
        0.5690, 0.5586, 0.5656, 0.5550, 0.5677, 0.5620, 0.5715],
       device='cuda:0') torch.Size([16])
percent tensor([0.5703, 0.5888, 0.5449, 0.5442, 0.5465, 0.5351, 0.5695, 0.5397, 0.5836,
        0.6022, 0.5869, 0.5627, 0.5989, 0.5913, 0.5398, 0.5564],
       device='cuda:0') torch.Size([16])
percent tensor([0.8743, 0.8820, 0.8764, 0.9033, 0.8696, 0.8759, 0.8677, 0.8934, 0.9042,
        0.9254, 0.9136, 0.9129, 0.8878, 0.8886, 0.8687, 0.8859],
       device='cuda:0') torch.Size([16])
Epoch: 27 | Batch_idx: 0 |  Loss: (0.6967) |  Loss2: (0.0000) | Acc: (73.00%) (94/128)
Epoch: 27 | Batch_idx: 10 |  Loss: (0.6014) |  Loss2: (0.0000) | Acc: (79.00%) (1115/1408)
Epoch: 27 | Batch_idx: 20 |  Loss: (0.6073) |  Loss2: (0.0000) | Acc: (78.00%) (2111/2688)
Epoch: 27 | Batch_idx: 30 |  Loss: (0.6037) |  Loss2: (0.0000) | Acc: (78.00%) (3117/3968)
Epoch: 27 | Batch_idx: 40 |  Loss: (0.6027) |  Loss2: (0.0000) | Acc: (78.00%) (4134/5248)
Epoch: 27 | Batch_idx: 50 |  Loss: (0.5938) |  Loss2: (0.0000) | Acc: (78.00%) (5157/6528)
Epoch: 27 | Batch_idx: 60 |  Loss: (0.5968) |  Loss2: (0.0000) | Acc: (78.00%) (6159/7808)
Epoch: 27 | Batch_idx: 70 |  Loss: (0.5949) |  Loss2: (0.0000) | Acc: (78.00%) (7166/9088)
Epoch: 27 | Batch_idx: 80 |  Loss: (0.5938) |  Loss2: (0.0000) | Acc: (78.00%) (8184/10368)
Epoch: 27 | Batch_idx: 90 |  Loss: (0.5954) |  Loss2: (0.0000) | Acc: (78.00%) (9196/11648)
Epoch: 27 | Batch_idx: 100 |  Loss: (0.6010) |  Loss2: (0.0000) | Acc: (78.00%) (10177/12928)
Epoch: 27 | Batch_idx: 110 |  Loss: (0.5996) |  Loss2: (0.0000) | Acc: (78.00%) (11184/14208)
Epoch: 27 | Batch_idx: 120 |  Loss: (0.5988) |  Loss2: (0.0000) | Acc: (78.00%) (12192/15488)
Epoch: 27 | Batch_idx: 130 |  Loss: (0.6003) |  Loss2: (0.0000) | Acc: (78.00%) (13197/16768)
Epoch: 27 | Batch_idx: 140 |  Loss: (0.6008) |  Loss2: (0.0000) | Acc: (78.00%) (14205/18048)
Epoch: 27 | Batch_idx: 150 |  Loss: (0.5987) |  Loss2: (0.0000) | Acc: (78.00%) (15250/19328)
Epoch: 27 | Batch_idx: 160 |  Loss: (0.5962) |  Loss2: (0.0000) | Acc: (78.00%) (16266/20608)
Epoch: 27 | Batch_idx: 170 |  Loss: (0.5954) |  Loss2: (0.0000) | Acc: (78.00%) (17284/21888)
Epoch: 27 | Batch_idx: 180 |  Loss: (0.5941) |  Loss2: (0.0000) | Acc: (78.00%) (18300/23168)
Epoch: 27 | Batch_idx: 190 |  Loss: (0.5945) |  Loss2: (0.0000) | Acc: (78.00%) (19312/24448)
Epoch: 27 | Batch_idx: 200 |  Loss: (0.5928) |  Loss2: (0.0000) | Acc: (79.00%) (20334/25728)
Epoch: 27 | Batch_idx: 210 |  Loss: (0.5925) |  Loss2: (0.0000) | Acc: (79.00%) (21358/27008)
Epoch: 27 | Batch_idx: 220 |  Loss: (0.5934) |  Loss2: (0.0000) | Acc: (79.00%) (22370/28288)
Epoch: 27 | Batch_idx: 230 |  Loss: (0.5932) |  Loss2: (0.0000) | Acc: (79.00%) (23384/29568)
Epoch: 27 | Batch_idx: 240 |  Loss: (0.5922) |  Loss2: (0.0000) | Acc: (79.00%) (24396/30848)
Epoch: 27 | Batch_idx: 250 |  Loss: (0.5924) |  Loss2: (0.0000) | Acc: (79.00%) (25422/32128)
Epoch: 27 | Batch_idx: 260 |  Loss: (0.5935) |  Loss2: (0.0000) | Acc: (79.00%) (26426/33408)
Epoch: 27 | Batch_idx: 270 |  Loss: (0.5930) |  Loss2: (0.0000) | Acc: (79.00%) (27444/34688)
Epoch: 27 | Batch_idx: 280 |  Loss: (0.5918) |  Loss2: (0.0000) | Acc: (79.00%) (28476/35968)
Epoch: 27 | Batch_idx: 290 |  Loss: (0.5899) |  Loss2: (0.0000) | Acc: (79.00%) (29510/37248)
Epoch: 27 | Batch_idx: 300 |  Loss: (0.5917) |  Loss2: (0.0000) | Acc: (79.00%) (30509/38528)
Epoch: 27 | Batch_idx: 310 |  Loss: (0.5916) |  Loss2: (0.0000) | Acc: (79.00%) (31512/39808)
Epoch: 27 | Batch_idx: 320 |  Loss: (0.5912) |  Loss2: (0.0000) | Acc: (79.00%) (32525/41088)
Epoch: 27 | Batch_idx: 330 |  Loss: (0.5906) |  Loss2: (0.0000) | Acc: (79.00%) (33552/42368)
Epoch: 27 | Batch_idx: 340 |  Loss: (0.5915) |  Loss2: (0.0000) | Acc: (79.00%) (34547/43648)
Epoch: 27 | Batch_idx: 350 |  Loss: (0.5902) |  Loss2: (0.0000) | Acc: (79.00%) (35575/44928)
Epoch: 27 | Batch_idx: 360 |  Loss: (0.5909) |  Loss2: (0.0000) | Acc: (79.00%) (36599/46208)
Epoch: 27 | Batch_idx: 370 |  Loss: (0.5911) |  Loss2: (0.0000) | Acc: (79.00%) (37617/47488)
Epoch: 27 | Batch_idx: 380 |  Loss: (0.5910) |  Loss2: (0.0000) | Acc: (79.00%) (38635/48768)
Epoch: 27 | Batch_idx: 390 |  Loss: (0.5897) |  Loss2: (0.0000) | Acc: (79.00%) (39626/50000)
# TEST : Loss: (0.6399) | Acc: (78.00%) (7822/10000)
percent tensor([0.4971, 0.4975, 0.4965, 0.4949, 0.4974, 0.4994, 0.4969, 0.4942, 0.4967,
        0.4957, 0.4983, 0.4965, 0.4969, 0.4982, 0.4981, 0.4974],
       device='cuda:0') torch.Size([16])
percent tensor([0.4735, 0.4570, 0.4743, 0.4718, 0.4675, 0.4801, 0.4583, 0.4674, 0.4663,
        0.4626, 0.4634, 0.4659, 0.4661, 0.4570, 0.4647, 0.4707],
       device='cuda:0') torch.Size([16])
percent tensor([0.5442, 0.5403, 0.4986, 0.4914, 0.5073, 0.5586, 0.5437, 0.5027, 0.5109,
        0.5243, 0.5272, 0.5051, 0.5386, 0.5274, 0.5525, 0.5392],
       device='cuda:0') torch.Size([16])
percent tensor([0.5666, 0.5613, 0.5684, 0.5769, 0.5740, 0.5689, 0.5716, 0.5814, 0.5695,
        0.5641, 0.5611, 0.5783, 0.5611, 0.5647, 0.5758, 0.5685],
       device='cuda:0') torch.Size([16])
percent tensor([0.5114, 0.5156, 0.4898, 0.4910, 0.4901, 0.5099, 0.4895, 0.4730, 0.5282,
        0.5199, 0.5246, 0.4713, 0.5228, 0.5372, 0.4767, 0.5072],
       device='cuda:0') torch.Size([16])
percent tensor([0.5660, 0.5678, 0.5728, 0.5802, 0.5829, 0.5676, 0.5712, 0.5884, 0.5685,
        0.5736, 0.5633, 0.5713, 0.5587, 0.5725, 0.5677, 0.5755],
       device='cuda:0') torch.Size([16])
percent tensor([0.5793, 0.5971, 0.5448, 0.5442, 0.5419, 0.5387, 0.5733, 0.5302, 0.5961,
        0.6140, 0.5973, 0.5669, 0.6134, 0.6043, 0.5410, 0.5601],
       device='cuda:0') torch.Size([16])
percent tensor([0.8977, 0.9022, 0.8963, 0.9218, 0.8910, 0.8965, 0.8881, 0.9153, 0.9280,
        0.9443, 0.9323, 0.9320, 0.9101, 0.9084, 0.8941, 0.9057],
       device='cuda:0') torch.Size([16])
Epoch: 28 | Batch_idx: 0 |  Loss: (0.5079) |  Loss2: (0.0000) | Acc: (82.00%) (106/128)
Epoch: 28 | Batch_idx: 10 |  Loss: (0.6344) |  Loss2: (0.0000) | Acc: (77.00%) (1093/1408)
Epoch: 28 | Batch_idx: 20 |  Loss: (0.6089) |  Loss2: (0.0000) | Acc: (78.00%) (2115/2688)
Epoch: 28 | Batch_idx: 30 |  Loss: (0.6047) |  Loss2: (0.0000) | Acc: (78.00%) (3120/3968)
Epoch: 28 | Batch_idx: 40 |  Loss: (0.6030) |  Loss2: (0.0000) | Acc: (78.00%) (4131/5248)
Epoch: 28 | Batch_idx: 50 |  Loss: (0.6059) |  Loss2: (0.0000) | Acc: (78.00%) (5155/6528)
Epoch: 28 | Batch_idx: 60 |  Loss: (0.6052) |  Loss2: (0.0000) | Acc: (79.00%) (6174/7808)
Epoch: 28 | Batch_idx: 70 |  Loss: (0.5994) |  Loss2: (0.0000) | Acc: (79.00%) (7213/9088)
Epoch: 28 | Batch_idx: 80 |  Loss: (0.5954) |  Loss2: (0.0000) | Acc: (79.00%) (8233/10368)
Epoch: 28 | Batch_idx: 90 |  Loss: (0.5890) |  Loss2: (0.0000) | Acc: (79.00%) (9274/11648)
Epoch: 28 | Batch_idx: 100 |  Loss: (0.5893) |  Loss2: (0.0000) | Acc: (79.00%) (10288/12928)
Epoch: 28 | Batch_idx: 110 |  Loss: (0.5846) |  Loss2: (0.0000) | Acc: (79.00%) (11325/14208)
Epoch: 28 | Batch_idx: 120 |  Loss: (0.5852) |  Loss2: (0.0000) | Acc: (79.00%) (12336/15488)
Epoch: 28 | Batch_idx: 130 |  Loss: (0.5847) |  Loss2: (0.0000) | Acc: (79.00%) (13370/16768)
Epoch: 28 | Batch_idx: 140 |  Loss: (0.5840) |  Loss2: (0.0000) | Acc: (79.00%) (14399/18048)
Epoch: 28 | Batch_idx: 150 |  Loss: (0.5842) |  Loss2: (0.0000) | Acc: (79.00%) (15400/19328)
Epoch: 28 | Batch_idx: 160 |  Loss: (0.5834) |  Loss2: (0.0000) | Acc: (79.00%) (16429/20608)
Epoch: 28 | Batch_idx: 170 |  Loss: (0.5829) |  Loss2: (0.0000) | Acc: (79.00%) (17464/21888)
Epoch: 28 | Batch_idx: 180 |  Loss: (0.5814) |  Loss2: (0.0000) | Acc: (79.00%) (18490/23168)
Epoch: 28 | Batch_idx: 190 |  Loss: (0.5813) |  Loss2: (0.0000) | Acc: (79.00%) (19510/24448)
Epoch: 28 | Batch_idx: 200 |  Loss: (0.5804) |  Loss2: (0.0000) | Acc: (79.00%) (20542/25728)
Epoch: 28 | Batch_idx: 210 |  Loss: (0.5807) |  Loss2: (0.0000) | Acc: (79.00%) (21557/27008)
Epoch: 28 | Batch_idx: 220 |  Loss: (0.5806) |  Loss2: (0.0000) | Acc: (79.00%) (22581/28288)
Epoch: 28 | Batch_idx: 230 |  Loss: (0.5815) |  Loss2: (0.0000) | Acc: (79.00%) (23584/29568)
Epoch: 28 | Batch_idx: 240 |  Loss: (0.5822) |  Loss2: (0.0000) | Acc: (79.00%) (24601/30848)
Epoch: 28 | Batch_idx: 250 |  Loss: (0.5842) |  Loss2: (0.0000) | Acc: (79.00%) (25620/32128)
Epoch: 28 | Batch_idx: 260 |  Loss: (0.5831) |  Loss2: (0.0000) | Acc: (79.00%) (26663/33408)
Epoch: 28 | Batch_idx: 270 |  Loss: (0.5830) |  Loss2: (0.0000) | Acc: (79.00%) (27682/34688)
Epoch: 28 | Batch_idx: 280 |  Loss: (0.5826) |  Loss2: (0.0000) | Acc: (79.00%) (28697/35968)
Epoch: 28 | Batch_idx: 290 |  Loss: (0.5823) |  Loss2: (0.0000) | Acc: (79.00%) (29702/37248)
Epoch: 28 | Batch_idx: 300 |  Loss: (0.5824) |  Loss2: (0.0000) | Acc: (79.00%) (30697/38528)
Epoch: 28 | Batch_idx: 310 |  Loss: (0.5815) |  Loss2: (0.0000) | Acc: (79.00%) (31729/39808)
Epoch: 28 | Batch_idx: 320 |  Loss: (0.5819) |  Loss2: (0.0000) | Acc: (79.00%) (32751/41088)
Epoch: 28 | Batch_idx: 330 |  Loss: (0.5832) |  Loss2: (0.0000) | Acc: (79.00%) (33758/42368)
Epoch: 28 | Batch_idx: 340 |  Loss: (0.5839) |  Loss2: (0.0000) | Acc: (79.00%) (34771/43648)
Epoch: 28 | Batch_idx: 350 |  Loss: (0.5836) |  Loss2: (0.0000) | Acc: (79.00%) (35793/44928)
Epoch: 28 | Batch_idx: 360 |  Loss: (0.5838) |  Loss2: (0.0000) | Acc: (79.00%) (36808/46208)
Epoch: 28 | Batch_idx: 370 |  Loss: (0.5845) |  Loss2: (0.0000) | Acc: (79.00%) (37812/47488)
Epoch: 28 | Batch_idx: 380 |  Loss: (0.5845) |  Loss2: (0.0000) | Acc: (79.00%) (38843/48768)
Epoch: 28 | Batch_idx: 390 |  Loss: (0.5857) |  Loss2: (0.0000) | Acc: (79.00%) (39796/50000)
# TEST : Loss: (0.6268) | Acc: (78.00%) (7842/10000)
percent tensor([0.4974, 0.4979, 0.4980, 0.4958, 0.4987, 0.4995, 0.4976, 0.4953, 0.4971,
        0.4967, 0.4984, 0.4978, 0.4974, 0.4984, 0.4985, 0.4978],
       device='cuda:0') torch.Size([16])
percent tensor([0.4731, 0.4565, 0.4739, 0.4724, 0.4666, 0.4804, 0.4575, 0.4670, 0.4652,
        0.4621, 0.4626, 0.4652, 0.4653, 0.4568, 0.4646, 0.4707],
       device='cuda:0') torch.Size([16])
percent tensor([0.5460, 0.5399, 0.5021, 0.4930, 0.5107, 0.5613, 0.5458, 0.5050, 0.5104,
        0.5248, 0.5259, 0.5063, 0.5379, 0.5260, 0.5534, 0.5403],
       device='cuda:0') torch.Size([16])
percent tensor([0.5669, 0.5607, 0.5698, 0.5792, 0.5749, 0.5702, 0.5716, 0.5821, 0.5699,
        0.5631, 0.5607, 0.5800, 0.5611, 0.5649, 0.5769, 0.5687],
       device='cuda:0') torch.Size([16])
percent tensor([0.5131, 0.5202, 0.4896, 0.4911, 0.4896, 0.5132, 0.4910, 0.4716, 0.5325,
        0.5228, 0.5294, 0.4719, 0.5270, 0.5439, 0.4784, 0.5091],
       device='cuda:0') torch.Size([16])
percent tensor([0.5664, 0.5683, 0.5743, 0.5820, 0.5847, 0.5678, 0.5723, 0.5903, 0.5691,
        0.5741, 0.5635, 0.5734, 0.5585, 0.5731, 0.5691, 0.5761],
       device='cuda:0') torch.Size([16])
percent tensor([0.5830, 0.6023, 0.5497, 0.5498, 0.5452, 0.5408, 0.5765, 0.5297, 0.6046,
        0.6210, 0.6062, 0.5743, 0.6230, 0.6140, 0.5420, 0.5631],
       device='cuda:0') torch.Size([16])
percent tensor([0.9030, 0.9081, 0.9081, 0.9304, 0.9039, 0.9005, 0.8930, 0.9274, 0.9330,
        0.9477, 0.9367, 0.9404, 0.9119, 0.9120, 0.9034, 0.9122],
       device='cuda:0') torch.Size([16])
Epoch: 29 | Batch_idx: 0 |  Loss: (0.4347) |  Loss2: (0.0000) | Acc: (83.00%) (107/128)
Epoch: 29 | Batch_idx: 10 |  Loss: (0.5567) |  Loss2: (0.0000) | Acc: (81.00%) (1142/1408)
Epoch: 29 | Batch_idx: 20 |  Loss: (0.5756) |  Loss2: (0.0000) | Acc: (80.00%) (2172/2688)
Epoch: 29 | Batch_idx: 30 |  Loss: (0.5842) |  Loss2: (0.0000) | Acc: (80.00%) (3181/3968)
Epoch: 29 | Batch_idx: 40 |  Loss: (0.5861) |  Loss2: (0.0000) | Acc: (79.00%) (4185/5248)
Epoch: 29 | Batch_idx: 50 |  Loss: (0.5900) |  Loss2: (0.0000) | Acc: (79.00%) (5191/6528)
Epoch: 29 | Batch_idx: 60 |  Loss: (0.5840) |  Loss2: (0.0000) | Acc: (79.00%) (6221/7808)
Epoch: 29 | Batch_idx: 70 |  Loss: (0.5876) |  Loss2: (0.0000) | Acc: (79.00%) (7229/9088)
Epoch: 29 | Batch_idx: 80 |  Loss: (0.5807) |  Loss2: (0.0000) | Acc: (79.00%) (8266/10368)
Epoch: 29 | Batch_idx: 90 |  Loss: (0.5841) |  Loss2: (0.0000) | Acc: (79.00%) (9283/11648)
Epoch: 29 | Batch_idx: 100 |  Loss: (0.5838) |  Loss2: (0.0000) | Acc: (79.00%) (10310/12928)
Epoch: 29 | Batch_idx: 110 |  Loss: (0.5880) |  Loss2: (0.0000) | Acc: (79.00%) (11319/14208)
Epoch: 29 | Batch_idx: 120 |  Loss: (0.5918) |  Loss2: (0.0000) | Acc: (79.00%) (12331/15488)
Epoch: 29 | Batch_idx: 130 |  Loss: (0.5918) |  Loss2: (0.0000) | Acc: (79.00%) (13342/16768)
Epoch: 29 | Batch_idx: 140 |  Loss: (0.5937) |  Loss2: (0.0000) | Acc: (79.00%) (14342/18048)
Epoch: 29 | Batch_idx: 150 |  Loss: (0.5941) |  Loss2: (0.0000) | Acc: (79.00%) (15351/19328)
Epoch: 29 | Batch_idx: 160 |  Loss: (0.5922) |  Loss2: (0.0000) | Acc: (79.00%) (16362/20608)
Epoch: 29 | Batch_idx: 170 |  Loss: (0.5926) |  Loss2: (0.0000) | Acc: (79.00%) (17377/21888)
Epoch: 29 | Batch_idx: 180 |  Loss: (0.5935) |  Loss2: (0.0000) | Acc: (79.00%) (18383/23168)
Epoch: 29 | Batch_idx: 190 |  Loss: (0.5902) |  Loss2: (0.0000) | Acc: (79.00%) (19428/24448)
Epoch: 29 | Batch_idx: 200 |  Loss: (0.5888) |  Loss2: (0.0000) | Acc: (79.00%) (20453/25728)
Epoch: 29 | Batch_idx: 210 |  Loss: (0.5889) |  Loss2: (0.0000) | Acc: (79.00%) (21464/27008)
Epoch: 29 | Batch_idx: 220 |  Loss: (0.5884) |  Loss2: (0.0000) | Acc: (79.00%) (22483/28288)
Epoch: 29 | Batch_idx: 230 |  Loss: (0.5881) |  Loss2: (0.0000) | Acc: (79.00%) (23494/29568)
Epoch: 29 | Batch_idx: 240 |  Loss: (0.5860) |  Loss2: (0.0000) | Acc: (79.00%) (24539/30848)
Epoch: 29 | Batch_idx: 250 |  Loss: (0.5855) |  Loss2: (0.0000) | Acc: (79.00%) (25560/32128)
Epoch: 29 | Batch_idx: 260 |  Loss: (0.5861) |  Loss2: (0.0000) | Acc: (79.00%) (26560/33408)
Epoch: 29 | Batch_idx: 270 |  Loss: (0.5869) |  Loss2: (0.0000) | Acc: (79.00%) (27561/34688)
Epoch: 29 | Batch_idx: 280 |  Loss: (0.5866) |  Loss2: (0.0000) | Acc: (79.00%) (28569/35968)
Epoch: 29 | Batch_idx: 290 |  Loss: (0.5876) |  Loss2: (0.0000) | Acc: (79.00%) (29581/37248)
Epoch: 29 | Batch_idx: 300 |  Loss: (0.5866) |  Loss2: (0.0000) | Acc: (79.00%) (30606/38528)
Epoch: 29 | Batch_idx: 310 |  Loss: (0.5851) |  Loss2: (0.0000) | Acc: (79.00%) (31645/39808)
Epoch: 29 | Batch_idx: 320 |  Loss: (0.5861) |  Loss2: (0.0000) | Acc: (79.00%) (32640/41088)
Epoch: 29 | Batch_idx: 330 |  Loss: (0.5857) |  Loss2: (0.0000) | Acc: (79.00%) (33675/42368)
Epoch: 29 | Batch_idx: 340 |  Loss: (0.5851) |  Loss2: (0.0000) | Acc: (79.00%) (34700/43648)
Epoch: 29 | Batch_idx: 350 |  Loss: (0.5848) |  Loss2: (0.0000) | Acc: (79.00%) (35723/44928)
Epoch: 29 | Batch_idx: 360 |  Loss: (0.5838) |  Loss2: (0.0000) | Acc: (79.00%) (36754/46208)
Epoch: 29 | Batch_idx: 370 |  Loss: (0.5832) |  Loss2: (0.0000) | Acc: (79.00%) (37780/47488)
Epoch: 29 | Batch_idx: 380 |  Loss: (0.5837) |  Loss2: (0.0000) | Acc: (79.00%) (38797/48768)
Epoch: 29 | Batch_idx: 390 |  Loss: (0.5839) |  Loss2: (0.0000) | Acc: (79.00%) (39783/50000)
# TEST : Loss: (0.6233) | Acc: (78.00%) (7850/10000)
percent tensor([0.4980, 0.4986, 0.4991, 0.4968, 0.4998, 0.4999, 0.4985, 0.4964, 0.4977,
        0.4978, 0.4989, 0.4991, 0.4981, 0.4990, 0.4991, 0.4984],
       device='cuda:0') torch.Size([16])
percent tensor([0.4725, 0.4562, 0.4729, 0.4719, 0.4654, 0.4801, 0.4567, 0.4663, 0.4644,
        0.4616, 0.4620, 0.4642, 0.4646, 0.4569, 0.4641, 0.4703],
       device='cuda:0') torch.Size([16])
percent tensor([0.5453, 0.5379, 0.5000, 0.4902, 0.5062, 0.5605, 0.5437, 0.5020, 0.5087,
        0.5227, 0.5241, 0.5028, 0.5355, 0.5269, 0.5500, 0.5388],
       device='cuda:0') torch.Size([16])
percent tensor([0.5666, 0.5599, 0.5700, 0.5805, 0.5744, 0.5712, 0.5709, 0.5817, 0.5700,
        0.5618, 0.5604, 0.5806, 0.5611, 0.5653, 0.5770, 0.5683],
       device='cuda:0') torch.Size([16])
percent tensor([0.5167, 0.5278, 0.4936, 0.4932, 0.4944, 0.5148, 0.4960, 0.4755, 0.5413,
        0.5305, 0.5384, 0.4768, 0.5347, 0.5537, 0.4819, 0.5130],
       device='cuda:0') torch.Size([16])
percent tensor([0.5625, 0.5639, 0.5720, 0.5801, 0.5829, 0.5650, 0.5688, 0.5876, 0.5655,
        0.5695, 0.5594, 0.5706, 0.5537, 0.5696, 0.5658, 0.5724],
       device='cuda:0') torch.Size([16])
percent tensor([0.5880, 0.6065, 0.5537, 0.5548, 0.5493, 0.5440, 0.5798, 0.5305, 0.6127,
        0.6279, 0.6123, 0.5815, 0.6318, 0.6216, 0.5436, 0.5656],
       device='cuda:0') torch.Size([16])
percent tensor([0.9080, 0.9167, 0.9179, 0.9359, 0.9169, 0.9065, 0.8990, 0.9359, 0.9413,
        0.9539, 0.9433, 0.9482, 0.9202, 0.9199, 0.9107, 0.9160],
       device='cuda:0') torch.Size([16])
Epoch: 30 | Batch_idx: 0 |  Loss: (0.5941) |  Loss2: (0.0000) | Acc: (80.00%) (103/128)
Epoch: 30 | Batch_idx: 10 |  Loss: (0.5613) |  Loss2: (0.0000) | Acc: (81.00%) (1141/1408)
Epoch: 30 | Batch_idx: 20 |  Loss: (0.5839) |  Loss2: (0.0000) | Acc: (79.00%) (2146/2688)
Epoch: 30 | Batch_idx: 30 |  Loss: (0.5952) |  Loss2: (0.0000) | Acc: (79.00%) (3160/3968)
Epoch: 30 | Batch_idx: 40 |  Loss: (0.5935) |  Loss2: (0.0000) | Acc: (79.00%) (4184/5248)
Epoch: 30 | Batch_idx: 50 |  Loss: (0.5829) |  Loss2: (0.0000) | Acc: (79.00%) (5215/6528)
Epoch: 30 | Batch_idx: 60 |  Loss: (0.5808) |  Loss2: (0.0000) | Acc: (79.00%) (6234/7808)
Epoch: 30 | Batch_idx: 70 |  Loss: (0.5776) |  Loss2: (0.0000) | Acc: (79.00%) (7267/9088)
Epoch: 30 | Batch_idx: 80 |  Loss: (0.5780) |  Loss2: (0.0000) | Acc: (79.00%) (8293/10368)
Epoch: 30 | Batch_idx: 90 |  Loss: (0.5770) |  Loss2: (0.0000) | Acc: (80.00%) (9325/11648)
Epoch: 30 | Batch_idx: 100 |  Loss: (0.5795) |  Loss2: (0.0000) | Acc: (79.00%) (10342/12928)
Epoch: 30 | Batch_idx: 110 |  Loss: (0.5823) |  Loss2: (0.0000) | Acc: (79.00%) (11344/14208)
Epoch: 30 | Batch_idx: 120 |  Loss: (0.5810) |  Loss2: (0.0000) | Acc: (79.00%) (12367/15488)
Epoch: 30 | Batch_idx: 130 |  Loss: (0.5839) |  Loss2: (0.0000) | Acc: (79.00%) (13377/16768)
Epoch: 30 | Batch_idx: 140 |  Loss: (0.5831) |  Loss2: (0.0000) | Acc: (79.00%) (14396/18048)
Epoch: 30 | Batch_idx: 150 |  Loss: (0.5805) |  Loss2: (0.0000) | Acc: (79.00%) (15428/19328)
Epoch: 30 | Batch_idx: 160 |  Loss: (0.5811) |  Loss2: (0.0000) | Acc: (79.00%) (16444/20608)
Epoch: 30 | Batch_idx: 170 |  Loss: (0.5816) |  Loss2: (0.0000) | Acc: (79.00%) (17461/21888)
Epoch: 30 | Batch_idx: 180 |  Loss: (0.5811) |  Loss2: (0.0000) | Acc: (79.00%) (18475/23168)
Epoch: 30 | Batch_idx: 190 |  Loss: (0.5825) |  Loss2: (0.0000) | Acc: (79.00%) (19483/24448)
Epoch: 30 | Batch_idx: 200 |  Loss: (0.5799) |  Loss2: (0.0000) | Acc: (79.00%) (20516/25728)
Epoch: 30 | Batch_idx: 210 |  Loss: (0.5811) |  Loss2: (0.0000) | Acc: (79.00%) (21513/27008)
Epoch: 30 | Batch_idx: 220 |  Loss: (0.5803) |  Loss2: (0.0000) | Acc: (79.00%) (22531/28288)
Epoch: 30 | Batch_idx: 230 |  Loss: (0.5812) |  Loss2: (0.0000) | Acc: (79.00%) (23539/29568)
Epoch: 30 | Batch_idx: 240 |  Loss: (0.5798) |  Loss2: (0.0000) | Acc: (79.00%) (24571/30848)
Epoch: 30 | Batch_idx: 250 |  Loss: (0.5785) |  Loss2: (0.0000) | Acc: (79.00%) (25601/32128)
Epoch: 30 | Batch_idx: 260 |  Loss: (0.5780) |  Loss2: (0.0000) | Acc: (79.00%) (26624/33408)
Epoch: 30 | Batch_idx: 270 |  Loss: (0.5798) |  Loss2: (0.0000) | Acc: (79.00%) (27628/34688)
Epoch: 30 | Batch_idx: 280 |  Loss: (0.5782) |  Loss2: (0.0000) | Acc: (79.00%) (28649/35968)
Epoch: 30 | Batch_idx: 290 |  Loss: (0.5783) |  Loss2: (0.0000) | Acc: (79.00%) (29665/37248)
Epoch: 30 | Batch_idx: 300 |  Loss: (0.5779) |  Loss2: (0.0000) | Acc: (79.00%) (30678/38528)
Epoch: 30 | Batch_idx: 310 |  Loss: (0.5770) |  Loss2: (0.0000) | Acc: (79.00%) (31716/39808)
Epoch: 30 | Batch_idx: 320 |  Loss: (0.5777) |  Loss2: (0.0000) | Acc: (79.00%) (32744/41088)
Epoch: 30 | Batch_idx: 330 |  Loss: (0.5766) |  Loss2: (0.0000) | Acc: (79.00%) (33790/42368)
Epoch: 30 | Batch_idx: 340 |  Loss: (0.5753) |  Loss2: (0.0000) | Acc: (79.00%) (34829/43648)
Epoch: 30 | Batch_idx: 350 |  Loss: (0.5738) |  Loss2: (0.0000) | Acc: (79.00%) (35876/44928)
Epoch: 30 | Batch_idx: 360 |  Loss: (0.5741) |  Loss2: (0.0000) | Acc: (79.00%) (36901/46208)
Epoch: 30 | Batch_idx: 370 |  Loss: (0.5744) |  Loss2: (0.0000) | Acc: (79.00%) (37918/47488)
Epoch: 30 | Batch_idx: 380 |  Loss: (0.5754) |  Loss2: (0.0000) | Acc: (79.00%) (38925/48768)
Epoch: 30 | Batch_idx: 390 |  Loss: (0.5756) |  Loss2: (0.0000) | Acc: (79.00%) (39900/50000)
=> saving checkpoint 'drive/app/torch/save_Schedule/checkpoint_030.pth.tar'
# TEST : Loss: (0.6207) | Acc: (78.00%) (7854/10000)
percent tensor([0.4984, 0.4992, 0.5004, 0.4976, 0.5011, 0.5000, 0.4994, 0.4974, 0.4981,
        0.4988, 0.4992, 0.5004, 0.4985, 0.4993, 0.4996, 0.4988],
       device='cuda:0') torch.Size([16])
percent tensor([0.4741, 0.4586, 0.4747, 0.4742, 0.4673, 0.4817, 0.4590, 0.4684, 0.4659,
        0.4640, 0.4639, 0.4663, 0.4665, 0.4591, 0.4663, 0.4724],
       device='cuda:0') torch.Size([16])
percent tensor([0.5476, 0.5379, 0.5025, 0.4908, 0.5084, 0.5617, 0.5462, 0.5033, 0.5089,
        0.5235, 0.5233, 0.5035, 0.5356, 0.5263, 0.5510, 0.5397],
       device='cuda:0') torch.Size([16])
percent tensor([0.5715, 0.5648, 0.5749, 0.5863, 0.5795, 0.5777, 0.5764, 0.5872, 0.5751,
        0.5660, 0.5652, 0.5870, 0.5661, 0.5710, 0.5838, 0.5735],
       device='cuda:0') torch.Size([16])
percent tensor([0.5132, 0.5298, 0.4864, 0.4862, 0.4876, 0.5122, 0.4928, 0.4669, 0.5418,
        0.5297, 0.5404, 0.4704, 0.5356, 0.5577, 0.4774, 0.5098],
       device='cuda:0') torch.Size([16])
percent tensor([0.5655, 0.5669, 0.5754, 0.5843, 0.5870, 0.5676, 0.5726, 0.5918, 0.5689,
        0.5728, 0.5627, 0.5755, 0.5562, 0.5731, 0.5698, 0.5756],
       device='cuda:0') torch.Size([16])
percent tensor([0.5953, 0.6140, 0.5618, 0.5640, 0.5559, 0.5494, 0.5868, 0.5348, 0.6234,
        0.6375, 0.6217, 0.5921, 0.6424, 0.6314, 0.5487, 0.5723],
       device='cuda:0') torch.Size([16])
percent tensor([0.9136, 0.9235, 0.9275, 0.9444, 0.9256, 0.9126, 0.9063, 0.9456, 0.9487,
        0.9589, 0.9499, 0.9559, 0.9252, 0.9250, 0.9203, 0.9219],
       device='cuda:0') torch.Size([16])
Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 3, 3, 3]) tensor(175.7282, device='cuda:0')
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(786.3437, device='cuda:0')
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(784.7574, device='cuda:0')
Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([128, 64, 3, 3]) tensor(1532.0848, device='cuda:0')
Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([128, 64, 1, 1]) tensor(503.1898, device='cuda:0')
Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([128, 128, 3, 3]) tensor(2186.7686, device='cuda:0')
Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([256, 128, 3, 3]) tensor(4309.0679, device='cuda:0')
Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([256, 128, 1, 1]) tensor(1426.1304, device='cuda:0')
Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([256, 256, 3, 3]) tensor(6079.9375, device='cuda:0')
Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([512, 256, 3, 3]) tensor(12137.0518, device='cuda:0')
Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([512, 256, 1, 1]) tensor(4049.0847, device='cuda:0')
Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([512, 512, 3, 3]) tensor(17125.2578, device='cuda:0')
Epoch: 31 | Batch_idx: 0 |  Loss: (0.7653) |  Loss2: (0.0000) | Acc: (75.00%) (96/128)
Epoch: 31 | Batch_idx: 10 |  Loss: (0.5906) |  Loss2: (0.0000) | Acc: (79.00%) (1124/1408)
Epoch: 31 | Batch_idx: 20 |  Loss: (0.5806) |  Loss2: (0.0000) | Acc: (79.00%) (2141/2688)
Epoch: 31 | Batch_idx: 30 |  Loss: (0.5673) |  Loss2: (0.0000) | Acc: (80.00%) (3180/3968)
Epoch: 31 | Batch_idx: 40 |  Loss: (0.5733) |  Loss2: (0.0000) | Acc: (80.00%) (4200/5248)
Epoch: 31 | Batch_idx: 50 |  Loss: (0.5668) |  Loss2: (0.0000) | Acc: (80.00%) (5243/6528)
Epoch: 31 | Batch_idx: 60 |  Loss: (0.5702) |  Loss2: (0.0000) | Acc: (80.00%) (6261/7808)
Epoch: 31 | Batch_idx: 70 |  Loss: (0.5737) |  Loss2: (0.0000) | Acc: (79.00%) (7264/9088)
Epoch: 31 | Batch_idx: 80 |  Loss: (0.5744) |  Loss2: (0.0000) | Acc: (79.00%) (8269/10368)
Epoch: 31 | Batch_idx: 90 |  Loss: (0.5698) |  Loss2: (0.0000) | Acc: (79.00%) (9305/11648)
Epoch: 31 | Batch_idx: 100 |  Loss: (0.5723) |  Loss2: (0.0000) | Acc: (79.00%) (10315/12928)
Epoch: 31 | Batch_idx: 110 |  Loss: (0.5700) |  Loss2: (0.0000) | Acc: (79.00%) (11346/14208)
Epoch: 31 | Batch_idx: 120 |  Loss: (0.5680) |  Loss2: (0.0000) | Acc: (79.00%) (12386/15488)
Epoch: 31 | Batch_idx: 130 |  Loss: (0.5675) |  Loss2: (0.0000) | Acc: (80.00%) (13416/16768)
Epoch: 31 | Batch_idx: 140 |  Loss: (0.5701) |  Loss2: (0.0000) | Acc: (79.00%) (14421/18048)
Epoch: 31 | Batch_idx: 150 |  Loss: (0.5677) |  Loss2: (0.0000) | Acc: (79.00%) (15462/19328)
Epoch: 31 | Batch_idx: 160 |  Loss: (0.5703) |  Loss2: (0.0000) | Acc: (79.00%) (16458/20608)
Epoch: 31 | Batch_idx: 170 |  Loss: (0.5699) |  Loss2: (0.0000) | Acc: (79.00%) (17484/21888)
Epoch: 31 | Batch_idx: 180 |  Loss: (0.5701) |  Loss2: (0.0000) | Acc: (79.00%) (18511/23168)
Epoch: 31 | Batch_idx: 190 |  Loss: (0.5712) |  Loss2: (0.0000) | Acc: (79.00%) (19521/24448)
Epoch: 31 | Batch_idx: 200 |  Loss: (0.5713) |  Loss2: (0.0000) | Acc: (79.00%) (20539/25728)
Epoch: 31 | Batch_idx: 210 |  Loss: (0.5726) |  Loss2: (0.0000) | Acc: (79.00%) (21548/27008)
Epoch: 31 | Batch_idx: 220 |  Loss: (0.5729) |  Loss2: (0.0000) | Acc: (79.00%) (22563/28288)
Epoch: 31 | Batch_idx: 230 |  Loss: (0.5731) |  Loss2: (0.0000) | Acc: (79.00%) (23589/29568)
Epoch: 31 | Batch_idx: 240 |  Loss: (0.5725) |  Loss2: (0.0000) | Acc: (79.00%) (24600/30848)
Epoch: 31 | Batch_idx: 250 |  Loss: (0.5721) |  Loss2: (0.0000) | Acc: (79.00%) (25638/32128)
Epoch: 31 | Batch_idx: 260 |  Loss: (0.5723) |  Loss2: (0.0000) | Acc: (79.00%) (26657/33408)
Epoch: 31 | Batch_idx: 270 |  Loss: (0.5722) |  Loss2: (0.0000) | Acc: (79.00%) (27690/34688)
Epoch: 31 | Batch_idx: 280 |  Loss: (0.5715) |  Loss2: (0.0000) | Acc: (79.00%) (28720/35968)
Epoch: 31 | Batch_idx: 290 |  Loss: (0.5712) |  Loss2: (0.0000) | Acc: (79.00%) (29750/37248)
Epoch: 31 | Batch_idx: 300 |  Loss: (0.5725) |  Loss2: (0.0000) | Acc: (79.00%) (30762/38528)
Epoch: 31 | Batch_idx: 310 |  Loss: (0.5727) |  Loss2: (0.0000) | Acc: (79.00%) (31779/39808)
Epoch: 31 | Batch_idx: 320 |  Loss: (0.5726) |  Loss2: (0.0000) | Acc: (79.00%) (32786/41088)
Epoch: 31 | Batch_idx: 330 |  Loss: (0.5734) |  Loss2: (0.0000) | Acc: (79.00%) (33799/42368)
Epoch: 31 | Batch_idx: 340 |  Loss: (0.5749) |  Loss2: (0.0000) | Acc: (79.00%) (34790/43648)
Epoch: 31 | Batch_idx: 350 |  Loss: (0.5749) |  Loss2: (0.0000) | Acc: (79.00%) (35815/44928)
Epoch: 31 | Batch_idx: 360 |  Loss: (0.5752) |  Loss2: (0.0000) | Acc: (79.00%) (36842/46208)
Epoch: 31 | Batch_idx: 370 |  Loss: (0.5747) |  Loss2: (0.0000) | Acc: (79.00%) (37854/47488)
Epoch: 31 | Batch_idx: 380 |  Loss: (0.5749) |  Loss2: (0.0000) | Acc: (79.00%) (38863/48768)
Epoch: 31 | Batch_idx: 390 |  Loss: (0.5754) |  Loss2: (0.0000) | Acc: (79.00%) (39843/50000)
# TEST : Loss: (0.6148) | Acc: (78.00%) (7889/10000)
percent tensor([0.4986, 0.4995, 0.5014, 0.4983, 0.5019, 0.5000, 0.5001, 0.4981, 0.4984,
        0.4997, 0.4993, 0.5015, 0.4989, 0.4995, 0.4999, 0.4991],
       device='cuda:0') torch.Size([16])
percent tensor([0.4733, 0.4573, 0.4740, 0.4739, 0.4662, 0.4814, 0.4576, 0.4676, 0.4647,
        0.4628, 0.4626, 0.4652, 0.4653, 0.4580, 0.4655, 0.4717],
       device='cuda:0') torch.Size([16])
percent tensor([0.5470, 0.5340, 0.5035, 0.4905, 0.5097, 0.5611, 0.5453, 0.5035, 0.5079,
        0.5206, 0.5193, 0.5023, 0.5311, 0.5248, 0.5480, 0.5378],
       device='cuda:0') torch.Size([16])
percent tensor([0.5752, 0.5672, 0.5783, 0.5909, 0.5826, 0.5827, 0.5795, 0.5903, 0.5785,
        0.5681, 0.5682, 0.5911, 0.5696, 0.5743, 0.5881, 0.5771],
       device='cuda:0') torch.Size([16])
percent tensor([0.5105, 0.5304, 0.4833, 0.4822, 0.4844, 0.5099, 0.4909, 0.4623, 0.5420,
        0.5295, 0.5413, 0.4684, 0.5366, 0.5588, 0.4749, 0.5077],
       device='cuda:0') torch.Size([16])
percent tensor([0.5631, 0.5640, 0.5734, 0.5828, 0.5855, 0.5666, 0.5704, 0.5896, 0.5665,
        0.5696, 0.5596, 0.5730, 0.5528, 0.5709, 0.5677, 0.5737],
       device='cuda:0') torch.Size([16])
percent tensor([0.5945, 0.6125, 0.5627, 0.5660, 0.5567, 0.5499, 0.5858, 0.5344, 0.6227,
        0.6354, 0.6201, 0.5929, 0.6399, 0.6300, 0.5494, 0.5730],
       device='cuda:0') torch.Size([16])
percent tensor([0.9178, 0.9258, 0.9329, 0.9491, 0.9316, 0.9165, 0.9081, 0.9511, 0.9523,
        0.9617, 0.9525, 0.9592, 0.9287, 0.9252, 0.9272, 0.9263],
       device='cuda:0') torch.Size([16])
True Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=128, out_features=16, bias=False)
False Linear(in_features=16, out_features=2, bias=False)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=128, out_features=16, bias=False)
False Linear(in_features=16, out_features=2, bias=False)
True Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=256, out_features=32, bias=False)
False Linear(in_features=32, out_features=2, bias=False)
True Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=256, out_features=32, bias=False)
False Linear(in_features=32, out_features=2, bias=False)
True Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=512, out_features=64, bias=False)
False Linear(in_features=64, out_features=2, bias=False)
True Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=512, out_features=64, bias=False)
False Linear(in_features=64, out_features=2, bias=False)
True Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1024, out_features=128, bias=False)
False Linear(in_features=128, out_features=2, bias=False)
True Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1024, out_features=128, bias=False)
False Linear(in_features=128, out_features=2, bias=False)
True Linear(in_features=512, out_features=10, bias=True)
Epoch: 32 | Batch_idx: 0 |  Loss: (0.5267) |  Loss2: (0.0000) | Acc: (78.00%) (100/128)
Epoch: 32 | Batch_idx: 10 |  Loss: (0.5907) |  Loss2: (0.0000) | Acc: (77.00%) (1096/1408)
Epoch: 32 | Batch_idx: 20 |  Loss: (0.5975) |  Loss2: (0.0000) | Acc: (78.00%) (2118/2688)
Epoch: 32 | Batch_idx: 30 |  Loss: (0.5887) |  Loss2: (0.0000) | Acc: (79.00%) (3138/3968)
Epoch: 32 | Batch_idx: 40 |  Loss: (0.5953) |  Loss2: (0.0000) | Acc: (78.00%) (4126/5248)
Epoch: 32 | Batch_idx: 50 |  Loss: (0.5902) |  Loss2: (0.0000) | Acc: (78.00%) (5147/6528)
Epoch: 32 | Batch_idx: 60 |  Loss: (0.5955) |  Loss2: (0.0000) | Acc: (78.00%) (6140/7808)
Epoch: 32 | Batch_idx: 70 |  Loss: (0.5957) |  Loss2: (0.0000) | Acc: (78.00%) (7156/9088)
Epoch: 32 | Batch_idx: 80 |  Loss: (0.5997) |  Loss2: (0.0000) | Acc: (78.00%) (8162/10368)
Epoch: 32 | Batch_idx: 90 |  Loss: (0.6008) |  Loss2: (0.0000) | Acc: (78.00%) (9173/11648)
Epoch: 32 | Batch_idx: 100 |  Loss: (0.6049) |  Loss2: (0.0000) | Acc: (78.00%) (10176/12928)
Epoch: 32 | Batch_idx: 110 |  Loss: (0.6080) |  Loss2: (0.0000) | Acc: (78.00%) (11170/14208)
Epoch: 32 | Batch_idx: 120 |  Loss: (0.6097) |  Loss2: (0.0000) | Acc: (78.00%) (12162/15488)
Epoch: 32 | Batch_idx: 130 |  Loss: (0.6114) |  Loss2: (0.0000) | Acc: (78.00%) (13160/16768)
Epoch: 32 | Batch_idx: 140 |  Loss: (0.6107) |  Loss2: (0.0000) | Acc: (78.00%) (14170/18048)
Epoch: 32 | Batch_idx: 150 |  Loss: (0.6093) |  Loss2: (0.0000) | Acc: (78.00%) (15199/19328)
Epoch: 32 | Batch_idx: 160 |  Loss: (0.6081) |  Loss2: (0.0000) | Acc: (78.00%) (16214/20608)
Epoch: 32 | Batch_idx: 170 |  Loss: (0.6083) |  Loss2: (0.0000) | Acc: (78.00%) (17227/21888)
Epoch: 32 | Batch_idx: 180 |  Loss: (0.6074) |  Loss2: (0.0000) | Acc: (78.00%) (18247/23168)
Epoch: 32 | Batch_idx: 190 |  Loss: (0.6066) |  Loss2: (0.0000) | Acc: (78.00%) (19251/24448)
Epoch: 32 | Batch_idx: 200 |  Loss: (0.6061) |  Loss2: (0.0000) | Acc: (78.00%) (20262/25728)
Epoch: 32 | Batch_idx: 210 |  Loss: (0.6069) |  Loss2: (0.0000) | Acc: (78.00%) (21267/27008)
Epoch: 32 | Batch_idx: 220 |  Loss: (0.6068) |  Loss2: (0.0000) | Acc: (78.00%) (22275/28288)
Epoch: 32 | Batch_idx: 230 |  Loss: (0.6057) |  Loss2: (0.0000) | Acc: (78.00%) (23287/29568)
Epoch: 32 | Batch_idx: 240 |  Loss: (0.6076) |  Loss2: (0.0000) | Acc: (78.00%) (24287/30848)
Epoch: 32 | Batch_idx: 250 |  Loss: (0.6077) |  Loss2: (0.0000) | Acc: (78.00%) (25295/32128)
Epoch: 32 | Batch_idx: 260 |  Loss: (0.6081) |  Loss2: (0.0000) | Acc: (78.00%) (26315/33408)
Epoch: 32 | Batch_idx: 270 |  Loss: (0.6084) |  Loss2: (0.0000) | Acc: (78.00%) (27330/34688)
Epoch: 32 | Batch_idx: 280 |  Loss: (0.6076) |  Loss2: (0.0000) | Acc: (78.00%) (28355/35968)
Epoch: 32 | Batch_idx: 290 |  Loss: (0.6079) |  Loss2: (0.0000) | Acc: (78.00%) (29371/37248)
Epoch: 32 | Batch_idx: 300 |  Loss: (0.6066) |  Loss2: (0.0000) | Acc: (78.00%) (30396/38528)
Epoch: 32 | Batch_idx: 310 |  Loss: (0.6063) |  Loss2: (0.0000) | Acc: (78.00%) (31403/39808)
Epoch: 32 | Batch_idx: 320 |  Loss: (0.6060) |  Loss2: (0.0000) | Acc: (78.00%) (32409/41088)
Epoch: 32 | Batch_idx: 330 |  Loss: (0.6056) |  Loss2: (0.0000) | Acc: (78.00%) (33435/42368)
Epoch: 32 | Batch_idx: 340 |  Loss: (0.6050) |  Loss2: (0.0000) | Acc: (78.00%) (34459/43648)
Epoch: 32 | Batch_idx: 350 |  Loss: (0.6054) |  Loss2: (0.0000) | Acc: (78.00%) (35476/44928)
Epoch: 32 | Batch_idx: 360 |  Loss: (0.6045) |  Loss2: (0.0000) | Acc: (79.00%) (36507/46208)
Epoch: 32 | Batch_idx: 370 |  Loss: (0.6032) |  Loss2: (0.0000) | Acc: (79.00%) (37535/47488)
Epoch: 32 | Batch_idx: 380 |  Loss: (0.6021) |  Loss2: (0.0000) | Acc: (79.00%) (38561/48768)
Epoch: 32 | Batch_idx: 390 |  Loss: (0.6011) |  Loss2: (0.0000) | Acc: (79.00%) (39547/50000)
# TEST : Loss: (0.6363) | Acc: (77.00%) (7763/10000)
percent tensor([0.4987, 0.4991, 0.5028, 0.4985, 0.5030, 0.5002, 0.5000, 0.4983, 0.4984,
        0.4996, 0.4991, 0.5018, 0.4989, 0.4987, 0.4999, 0.4990],
       device='cuda:0') torch.Size([16])
percent tensor([0.4718, 0.4585, 0.4742, 0.4760, 0.4663, 0.4822, 0.4586, 0.4692, 0.4636,
        0.4628, 0.4619, 0.4659, 0.4642, 0.4613, 0.4662, 0.4720],
       device='cuda:0') torch.Size([16])
percent tensor([0.5521, 0.5306, 0.5043, 0.4820, 0.5094, 0.5480, 0.5424, 0.5031, 0.5161,
        0.5218, 0.5233, 0.5006, 0.5375, 0.5159, 0.5373, 0.5390],
       device='cuda:0') torch.Size([16])
percent tensor([0.5760, 0.5706, 0.5816, 0.5898, 0.5831, 0.5798, 0.5795, 0.5944, 0.5777,
        0.5693, 0.5688, 0.5906, 0.5697, 0.5813, 0.5872, 0.5770],
       device='cuda:0') torch.Size([16])
percent tensor([0.5019, 0.5326, 0.4904, 0.4900, 0.4938, 0.5123, 0.4974, 0.4643, 0.5334,
        0.5312, 0.5372, 0.4824, 0.5323, 0.5562, 0.4764, 0.5094],
       device='cuda:0') torch.Size([16])
percent tensor([0.5583, 0.5617, 0.5762, 0.5814, 0.5853, 0.5645, 0.5701, 0.5928, 0.5634,
        0.5690, 0.5595, 0.5749, 0.5526, 0.5717, 0.5624, 0.5715],
       device='cuda:0') torch.Size([16])
percent tensor([0.5868, 0.6126, 0.5729, 0.5705, 0.5591, 0.5448, 0.5904, 0.5413, 0.6253,
        0.6260, 0.6148, 0.6131, 0.6377, 0.6247, 0.5449, 0.5641],
       device='cuda:0') torch.Size([16])
percent tensor([0.9207, 0.9362, 0.9357, 0.9407, 0.9303, 0.9107, 0.9224, 0.9546, 0.9625,
        0.9601, 0.9529, 0.9572, 0.9357, 0.9382, 0.9165, 0.9149],
       device='cuda:0') torch.Size([16])
Epoch: 33 | Batch_idx: 0 |  Loss: (0.5246) |  Loss2: (0.0000) | Acc: (80.00%) (103/128)
Epoch: 33 | Batch_idx: 10 |  Loss: (0.5848) |  Loss2: (0.0000) | Acc: (79.00%) (1114/1408)
Epoch: 33 | Batch_idx: 20 |  Loss: (0.5962) |  Loss2: (0.0000) | Acc: (79.00%) (2124/2688)
Epoch: 33 | Batch_idx: 30 |  Loss: (0.5954) |  Loss2: (0.0000) | Acc: (79.00%) (3146/3968)
Epoch: 33 | Batch_idx: 40 |  Loss: (0.5945) |  Loss2: (0.0000) | Acc: (79.00%) (4175/5248)
Epoch: 33 | Batch_idx: 50 |  Loss: (0.5807) |  Loss2: (0.0000) | Acc: (79.00%) (5219/6528)
Epoch: 33 | Batch_idx: 60 |  Loss: (0.5787) |  Loss2: (0.0000) | Acc: (79.00%) (6229/7808)
Epoch: 33 | Batch_idx: 70 |  Loss: (0.5806) |  Loss2: (0.0000) | Acc: (79.00%) (7249/9088)
Epoch: 33 | Batch_idx: 80 |  Loss: (0.5779) |  Loss2: (0.0000) | Acc: (79.00%) (8279/10368)
Epoch: 33 | Batch_idx: 90 |  Loss: (0.5779) |  Loss2: (0.0000) | Acc: (79.00%) (9298/11648)
Epoch: 33 | Batch_idx: 100 |  Loss: (0.5732) |  Loss2: (0.0000) | Acc: (80.00%) (10353/12928)
Epoch: 33 | Batch_idx: 110 |  Loss: (0.5700) |  Loss2: (0.0000) | Acc: (80.00%) (11395/14208)
Epoch: 33 | Batch_idx: 120 |  Loss: (0.5715) |  Loss2: (0.0000) | Acc: (80.00%) (12397/15488)
Epoch: 33 | Batch_idx: 130 |  Loss: (0.5716) |  Loss2: (0.0000) | Acc: (80.00%) (13427/16768)
Epoch: 33 | Batch_idx: 140 |  Loss: (0.5728) |  Loss2: (0.0000) | Acc: (80.00%) (14444/18048)
Epoch: 33 | Batch_idx: 150 |  Loss: (0.5736) |  Loss2: (0.0000) | Acc: (80.00%) (15466/19328)
Epoch: 33 | Batch_idx: 160 |  Loss: (0.5752) |  Loss2: (0.0000) | Acc: (79.00%) (16466/20608)
Epoch: 33 | Batch_idx: 170 |  Loss: (0.5763) |  Loss2: (0.0000) | Acc: (79.00%) (17486/21888)
Epoch: 33 | Batch_idx: 180 |  Loss: (0.5753) |  Loss2: (0.0000) | Acc: (79.00%) (18521/23168)
Epoch: 33 | Batch_idx: 190 |  Loss: (0.5730) |  Loss2: (0.0000) | Acc: (80.00%) (19560/24448)
Epoch: 33 | Batch_idx: 200 |  Loss: (0.5706) |  Loss2: (0.0000) | Acc: (80.00%) (20623/25728)
Epoch: 33 | Batch_idx: 210 |  Loss: (0.5714) |  Loss2: (0.0000) | Acc: (80.00%) (21625/27008)
Epoch: 33 | Batch_idx: 220 |  Loss: (0.5691) |  Loss2: (0.0000) | Acc: (80.00%) (22670/28288)
Epoch: 33 | Batch_idx: 230 |  Loss: (0.5686) |  Loss2: (0.0000) | Acc: (80.00%) (23686/29568)
Epoch: 33 | Batch_idx: 240 |  Loss: (0.5691) |  Loss2: (0.0000) | Acc: (80.00%) (24695/30848)
Epoch: 33 | Batch_idx: 250 |  Loss: (0.5685) |  Loss2: (0.0000) | Acc: (80.00%) (25728/32128)
Epoch: 33 | Batch_idx: 260 |  Loss: (0.5673) |  Loss2: (0.0000) | Acc: (80.00%) (26773/33408)
Epoch: 33 | Batch_idx: 270 |  Loss: (0.5675) |  Loss2: (0.0000) | Acc: (80.00%) (27793/34688)
Epoch: 33 | Batch_idx: 280 |  Loss: (0.5682) |  Loss2: (0.0000) | Acc: (80.00%) (28805/35968)
Epoch: 33 | Batch_idx: 290 |  Loss: (0.5687) |  Loss2: (0.0000) | Acc: (80.00%) (29811/37248)
Epoch: 33 | Batch_idx: 300 |  Loss: (0.5684) |  Loss2: (0.0000) | Acc: (79.00%) (30818/38528)
Epoch: 33 | Batch_idx: 310 |  Loss: (0.5685) |  Loss2: (0.0000) | Acc: (79.00%) (31839/39808)
Epoch: 33 | Batch_idx: 320 |  Loss: (0.5686) |  Loss2: (0.0000) | Acc: (80.00%) (32872/41088)
Epoch: 33 | Batch_idx: 330 |  Loss: (0.5683) |  Loss2: (0.0000) | Acc: (80.00%) (33916/42368)
Epoch: 33 | Batch_idx: 340 |  Loss: (0.5681) |  Loss2: (0.0000) | Acc: (80.00%) (34967/43648)
Epoch: 33 | Batch_idx: 350 |  Loss: (0.5686) |  Loss2: (0.0000) | Acc: (80.00%) (36001/44928)
Epoch: 33 | Batch_idx: 360 |  Loss: (0.5679) |  Loss2: (0.0000) | Acc: (80.00%) (37048/46208)
Epoch: 33 | Batch_idx: 370 |  Loss: (0.5683) |  Loss2: (0.0000) | Acc: (80.00%) (38054/47488)
Epoch: 33 | Batch_idx: 380 |  Loss: (0.5687) |  Loss2: (0.0000) | Acc: (80.00%) (39066/48768)
Epoch: 33 | Batch_idx: 390 |  Loss: (0.5685) |  Loss2: (0.0000) | Acc: (80.00%) (40059/50000)
# TEST : Loss: (0.7769) | Acc: (73.00%) (7347/10000)
percent tensor([0.4986, 0.4998, 0.5023, 0.4982, 0.5025, 0.5003, 0.5003, 0.4981, 0.4985,
        0.4997, 0.4994, 0.5011, 0.4989, 0.4998, 0.5003, 0.4991],
       device='cuda:0') torch.Size([16])
percent tensor([0.4713, 0.4552, 0.4782, 0.4755, 0.4685, 0.4788, 0.4579, 0.4680, 0.4635,
        0.4624, 0.4607, 0.4686, 0.4635, 0.4563, 0.4634, 0.4694],
       device='cuda:0') torch.Size([16])
percent tensor([0.5506, 0.5371, 0.5019, 0.4813, 0.5041, 0.5544, 0.5438, 0.5008, 0.5182,
        0.5259, 0.5302, 0.4964, 0.5386, 0.5242, 0.5437, 0.5399],
       device='cuda:0') torch.Size([16])
percent tensor([0.5768, 0.5737, 0.5834, 0.5934, 0.5847, 0.5852, 0.5834, 0.5953, 0.5809,
        0.5683, 0.5698, 0.5925, 0.5714, 0.5855, 0.5903, 0.5796],
       device='cuda:0') torch.Size([16])
percent tensor([0.4984, 0.5265, 0.4895, 0.4971, 0.4944, 0.5088, 0.4971, 0.4670, 0.5286,
        0.5280, 0.5310, 0.4873, 0.5273, 0.5533, 0.4690, 0.5017],
       device='cuda:0') torch.Size([16])
percent tensor([0.5595, 0.5599, 0.5796, 0.5856, 0.5852, 0.5632, 0.5685, 0.5877, 0.5608,
        0.5649, 0.5592, 0.5806, 0.5539, 0.5710, 0.5644, 0.5732],
       device='cuda:0') torch.Size([16])
percent tensor([0.5938, 0.5923, 0.5631, 0.5630, 0.5627, 0.5418, 0.5819, 0.5398, 0.6151,
        0.6073, 0.6033, 0.5880, 0.6271, 0.6067, 0.5451, 0.5670],
       device='cuda:0') torch.Size([16])
percent tensor([0.9332, 0.9161, 0.9318, 0.9401, 0.9348, 0.9170, 0.9183, 0.9488, 0.9554,
        0.9484, 0.9473, 0.9546, 0.9233, 0.9262, 0.9350, 0.9399],
       device='cuda:0') torch.Size([16])
Epoch: 34 | Batch_idx: 0 |  Loss: (0.4851) |  Loss2: (0.0000) | Acc: (82.00%) (105/128)
Epoch: 34 | Batch_idx: 10 |  Loss: (0.5592) |  Loss2: (0.0000) | Acc: (80.00%) (1129/1408)
Epoch: 34 | Batch_idx: 20 |  Loss: (0.5502) |  Loss2: (0.0000) | Acc: (80.00%) (2173/2688)
Epoch: 34 | Batch_idx: 30 |  Loss: (0.5609) |  Loss2: (0.0000) | Acc: (80.00%) (3198/3968)
Epoch: 34 | Batch_idx: 40 |  Loss: (0.5605) |  Loss2: (0.0000) | Acc: (80.00%) (4219/5248)
Epoch: 34 | Batch_idx: 50 |  Loss: (0.5606) |  Loss2: (0.0000) | Acc: (80.00%) (5236/6528)
Epoch: 34 | Batch_idx: 60 |  Loss: (0.5546) |  Loss2: (0.0000) | Acc: (80.00%) (6276/7808)
Epoch: 34 | Batch_idx: 70 |  Loss: (0.5546) |  Loss2: (0.0000) | Acc: (80.00%) (7311/9088)
Epoch: 34 | Batch_idx: 80 |  Loss: (0.5530) |  Loss2: (0.0000) | Acc: (80.00%) (8341/10368)
Epoch: 34 | Batch_idx: 90 |  Loss: (0.5533) |  Loss2: (0.0000) | Acc: (80.00%) (9357/11648)
Epoch: 34 | Batch_idx: 100 |  Loss: (0.5524) |  Loss2: (0.0000) | Acc: (80.00%) (10404/12928)
Epoch: 34 | Batch_idx: 110 |  Loss: (0.5472) |  Loss2: (0.0000) | Acc: (80.00%) (11460/14208)
Epoch: 34 | Batch_idx: 120 |  Loss: (0.5436) |  Loss2: (0.0000) | Acc: (80.00%) (12528/15488)
Epoch: 34 | Batch_idx: 130 |  Loss: (0.5442) |  Loss2: (0.0000) | Acc: (80.00%) (13571/16768)
Epoch: 34 | Batch_idx: 140 |  Loss: (0.5433) |  Loss2: (0.0000) | Acc: (81.00%) (14621/18048)
Epoch: 34 | Batch_idx: 150 |  Loss: (0.5445) |  Loss2: (0.0000) | Acc: (80.00%) (15655/19328)
Epoch: 34 | Batch_idx: 160 |  Loss: (0.5474) |  Loss2: (0.0000) | Acc: (80.00%) (16656/20608)
Epoch: 34 | Batch_idx: 170 |  Loss: (0.5467) |  Loss2: (0.0000) | Acc: (80.00%) (17697/21888)
Epoch: 34 | Batch_idx: 180 |  Loss: (0.5473) |  Loss2: (0.0000) | Acc: (80.00%) (18730/23168)
Epoch: 34 | Batch_idx: 190 |  Loss: (0.5472) |  Loss2: (0.0000) | Acc: (80.00%) (19765/24448)
Epoch: 34 | Batch_idx: 200 |  Loss: (0.5448) |  Loss2: (0.0000) | Acc: (80.00%) (20833/25728)
Epoch: 34 | Batch_idx: 210 |  Loss: (0.5438) |  Loss2: (0.0000) | Acc: (81.00%) (21883/27008)
Epoch: 34 | Batch_idx: 220 |  Loss: (0.5440) |  Loss2: (0.0000) | Acc: (80.00%) (22902/28288)
Epoch: 34 | Batch_idx: 230 |  Loss: (0.5443) |  Loss2: (0.0000) | Acc: (80.00%) (23945/29568)
Epoch: 34 | Batch_idx: 240 |  Loss: (0.5449) |  Loss2: (0.0000) | Acc: (81.00%) (24989/30848)
Epoch: 34 | Batch_idx: 250 |  Loss: (0.5443) |  Loss2: (0.0000) | Acc: (81.00%) (26035/32128)
Epoch: 34 | Batch_idx: 260 |  Loss: (0.5436) |  Loss2: (0.0000) | Acc: (81.00%) (27074/33408)
Epoch: 34 | Batch_idx: 270 |  Loss: (0.5436) |  Loss2: (0.0000) | Acc: (81.00%) (28112/34688)
Epoch: 34 | Batch_idx: 280 |  Loss: (0.5437) |  Loss2: (0.0000) | Acc: (81.00%) (29150/35968)
Epoch: 34 | Batch_idx: 290 |  Loss: (0.5439) |  Loss2: (0.0000) | Acc: (81.00%) (30182/37248)
Epoch: 34 | Batch_idx: 300 |  Loss: (0.5428) |  Loss2: (0.0000) | Acc: (81.00%) (31233/38528)
Epoch: 34 | Batch_idx: 310 |  Loss: (0.5424) |  Loss2: (0.0000) | Acc: (81.00%) (32291/39808)
Epoch: 34 | Batch_idx: 320 |  Loss: (0.5425) |  Loss2: (0.0000) | Acc: (81.00%) (33332/41088)
Epoch: 34 | Batch_idx: 330 |  Loss: (0.5432) |  Loss2: (0.0000) | Acc: (81.00%) (34364/42368)
Epoch: 34 | Batch_idx: 340 |  Loss: (0.5429) |  Loss2: (0.0000) | Acc: (81.00%) (35398/43648)
Epoch: 34 | Batch_idx: 350 |  Loss: (0.5435) |  Loss2: (0.0000) | Acc: (81.00%) (36416/44928)
Epoch: 34 | Batch_idx: 360 |  Loss: (0.5428) |  Loss2: (0.0000) | Acc: (81.00%) (37465/46208)
Epoch: 34 | Batch_idx: 370 |  Loss: (0.5432) |  Loss2: (0.0000) | Acc: (81.00%) (38503/47488)
Epoch: 34 | Batch_idx: 380 |  Loss: (0.5428) |  Loss2: (0.0000) | Acc: (81.00%) (39559/48768)
Epoch: 34 | Batch_idx: 390 |  Loss: (0.5423) |  Loss2: (0.0000) | Acc: (81.00%) (40573/50000)
# TEST : Loss: (0.6379) | Acc: (78.00%) (7818/10000)
percent tensor([0.4985, 0.4995, 0.5022, 0.4985, 0.5024, 0.5002, 0.5000, 0.4982, 0.4983,
        0.4995, 0.4991, 0.5012, 0.4988, 0.4990, 0.5000, 0.4989],
       device='cuda:0') torch.Size([16])
percent tensor([0.4724, 0.4574, 0.4779, 0.4765, 0.4694, 0.4811, 0.4588, 0.4697, 0.4660,
        0.4638, 0.4623, 0.4680, 0.4650, 0.4603, 0.4652, 0.4712],
       device='cuda:0') torch.Size([16])
percent tensor([0.5424, 0.5356, 0.5045, 0.4822, 0.5045, 0.5405, 0.5455, 0.5064, 0.5120,
        0.5237, 0.5188, 0.5015, 0.5304, 0.5205, 0.5395, 0.5334],
       device='cuda:0') torch.Size([16])
percent tensor([0.5745, 0.5703, 0.5842, 0.5902, 0.5850, 0.5830, 0.5824, 0.5948, 0.5780,
        0.5680, 0.5673, 0.5929, 0.5678, 0.5812, 0.5882, 0.5777],
       device='cuda:0') torch.Size([16])
percent tensor([0.5094, 0.5305, 0.4855, 0.5004, 0.4975, 0.5172, 0.5003, 0.4656, 0.5398,
        0.5307, 0.5395, 0.4856, 0.5333, 0.5599, 0.4742, 0.5129],
       device='cuda:0') torch.Size([16])
percent tensor([0.5616, 0.5631, 0.5832, 0.5875, 0.5898, 0.5651, 0.5733, 0.5884, 0.5684,
        0.5694, 0.5616, 0.5827, 0.5557, 0.5795, 0.5652, 0.5759],
       device='cuda:0') torch.Size([16])
percent tensor([0.5912, 0.5995, 0.5698, 0.5748, 0.5645, 0.5431, 0.5890, 0.5402, 0.6132,
        0.6180, 0.6104, 0.5989, 0.6385, 0.6094, 0.5512, 0.5708],
       device='cuda:0') torch.Size([16])
percent tensor([0.9274, 0.9261, 0.9174, 0.9379, 0.9273, 0.9349, 0.9301, 0.9439, 0.9484,
        0.9522, 0.9469, 0.9474, 0.9309, 0.9318, 0.9461, 0.9367],
       device='cuda:0') torch.Size([16])
Epoch: 35 | Batch_idx: 0 |  Loss: (0.4150) |  Loss2: (0.0000) | Acc: (86.00%) (111/128)
Epoch: 35 | Batch_idx: 10 |  Loss: (0.5184) |  Loss2: (0.0000) | Acc: (81.00%) (1154/1408)
Epoch: 35 | Batch_idx: 20 |  Loss: (0.5140) |  Loss2: (0.0000) | Acc: (81.00%) (2200/2688)
Epoch: 35 | Batch_idx: 30 |  Loss: (0.5181) |  Loss2: (0.0000) | Acc: (81.00%) (3226/3968)
Epoch: 35 | Batch_idx: 40 |  Loss: (0.5176) |  Loss2: (0.0000) | Acc: (81.00%) (4288/5248)
Epoch: 35 | Batch_idx: 50 |  Loss: (0.5209) |  Loss2: (0.0000) | Acc: (81.00%) (5328/6528)
Epoch: 35 | Batch_idx: 60 |  Loss: (0.5197) |  Loss2: (0.0000) | Acc: (81.00%) (6388/7808)
Epoch: 35 | Batch_idx: 70 |  Loss: (0.5268) |  Loss2: (0.0000) | Acc: (81.00%) (7401/9088)
Epoch: 35 | Batch_idx: 80 |  Loss: (0.5294) |  Loss2: (0.0000) | Acc: (81.00%) (8436/10368)
Epoch: 35 | Batch_idx: 90 |  Loss: (0.5273) |  Loss2: (0.0000) | Acc: (81.00%) (9498/11648)
Epoch: 35 | Batch_idx: 100 |  Loss: (0.5323) |  Loss2: (0.0000) | Acc: (81.00%) (10529/12928)
Epoch: 35 | Batch_idx: 110 |  Loss: (0.5301) |  Loss2: (0.0000) | Acc: (81.00%) (11588/14208)
Epoch: 35 | Batch_idx: 120 |  Loss: (0.5320) |  Loss2: (0.0000) | Acc: (81.00%) (12619/15488)
Epoch: 35 | Batch_idx: 130 |  Loss: (0.5306) |  Loss2: (0.0000) | Acc: (81.00%) (13659/16768)
Epoch: 35 | Batch_idx: 140 |  Loss: (0.5301) |  Loss2: (0.0000) | Acc: (81.00%) (14695/18048)
Epoch: 35 | Batch_idx: 150 |  Loss: (0.5296) |  Loss2: (0.0000) | Acc: (81.00%) (15731/19328)
Epoch: 35 | Batch_idx: 160 |  Loss: (0.5337) |  Loss2: (0.0000) | Acc: (81.00%) (16736/20608)
Epoch: 35 | Batch_idx: 170 |  Loss: (0.5323) |  Loss2: (0.0000) | Acc: (81.00%) (17773/21888)
Epoch: 35 | Batch_idx: 180 |  Loss: (0.5312) |  Loss2: (0.0000) | Acc: (81.00%) (18832/23168)
Epoch: 35 | Batch_idx: 190 |  Loss: (0.5298) |  Loss2: (0.0000) | Acc: (81.00%) (19894/24448)
Epoch: 35 | Batch_idx: 200 |  Loss: (0.5308) |  Loss2: (0.0000) | Acc: (81.00%) (20940/25728)
Epoch: 35 | Batch_idx: 210 |  Loss: (0.5298) |  Loss2: (0.0000) | Acc: (81.00%) (21998/27008)
Epoch: 35 | Batch_idx: 220 |  Loss: (0.5270) |  Loss2: (0.0000) | Acc: (81.00%) (23064/28288)
Epoch: 35 | Batch_idx: 230 |  Loss: (0.5286) |  Loss2: (0.0000) | Acc: (81.00%) (24086/29568)
Epoch: 35 | Batch_idx: 240 |  Loss: (0.5294) |  Loss2: (0.0000) | Acc: (81.00%) (25121/30848)
Epoch: 35 | Batch_idx: 250 |  Loss: (0.5278) |  Loss2: (0.0000) | Acc: (81.00%) (26174/32128)
Epoch: 35 | Batch_idx: 260 |  Loss: (0.5272) |  Loss2: (0.0000) | Acc: (81.00%) (27224/33408)
Epoch: 35 | Batch_idx: 270 |  Loss: (0.5270) |  Loss2: (0.0000) | Acc: (81.00%) (28276/34688)
Epoch: 35 | Batch_idx: 280 |  Loss: (0.5252) |  Loss2: (0.0000) | Acc: (81.00%) (29353/35968)
Epoch: 35 | Batch_idx: 290 |  Loss: (0.5255) |  Loss2: (0.0000) | Acc: (81.00%) (30399/37248)
Epoch: 35 | Batch_idx: 300 |  Loss: (0.5236) |  Loss2: (0.0000) | Acc: (81.00%) (31477/38528)
Epoch: 35 | Batch_idx: 310 |  Loss: (0.5230) |  Loss2: (0.0000) | Acc: (81.00%) (32533/39808)
Epoch: 35 | Batch_idx: 320 |  Loss: (0.5227) |  Loss2: (0.0000) | Acc: (81.00%) (33587/41088)
Epoch: 35 | Batch_idx: 330 |  Loss: (0.5225) |  Loss2: (0.0000) | Acc: (81.00%) (34640/42368)
Epoch: 35 | Batch_idx: 340 |  Loss: (0.5225) |  Loss2: (0.0000) | Acc: (81.00%) (35686/43648)
Epoch: 35 | Batch_idx: 350 |  Loss: (0.5231) |  Loss2: (0.0000) | Acc: (81.00%) (36729/44928)
Epoch: 35 | Batch_idx: 360 |  Loss: (0.5236) |  Loss2: (0.0000) | Acc: (81.00%) (37752/46208)
Epoch: 35 | Batch_idx: 370 |  Loss: (0.5229) |  Loss2: (0.0000) | Acc: (81.00%) (38809/47488)
Epoch: 35 | Batch_idx: 380 |  Loss: (0.5222) |  Loss2: (0.0000) | Acc: (81.00%) (39866/48768)
Epoch: 35 | Batch_idx: 390 |  Loss: (0.5220) |  Loss2: (0.0000) | Acc: (81.00%) (40875/50000)
=> saving checkpoint 'drive/app/torch/save_Schedule/checkpoint_035.pth.tar'
# TEST : Loss: (0.6317) | Acc: (77.00%) (7796/10000)
percent tensor([0.4983, 0.4995, 0.5023, 0.4986, 0.5021, 0.4997, 0.5000, 0.4985, 0.4982,
        0.4995, 0.4990, 0.5013, 0.4987, 0.4997, 0.5000, 0.4989],
       device='cuda:0') torch.Size([16])
percent tensor([0.4722, 0.4572, 0.4754, 0.4741, 0.4672, 0.4804, 0.4581, 0.4686, 0.4652,
        0.4637, 0.4626, 0.4679, 0.4649, 0.4599, 0.4641, 0.4706],
       device='cuda:0') torch.Size([16])
percent tensor([0.5408, 0.5293, 0.5031, 0.4852, 0.5047, 0.5408, 0.5372, 0.5032, 0.5127,
        0.5213, 0.5184, 0.4951, 0.5309, 0.5131, 0.5374, 0.5330],
       device='cuda:0') torch.Size([16])
percent tensor([0.5741, 0.5673, 0.5793, 0.5894, 0.5817, 0.5803, 0.5798, 0.5897, 0.5759,
        0.5658, 0.5658, 0.5870, 0.5675, 0.5790, 0.5855, 0.5750],
       device='cuda:0') torch.Size([16])
percent tensor([0.5102, 0.5296, 0.4910, 0.4941, 0.5001, 0.5159, 0.5055, 0.4746, 0.5412,
        0.5329, 0.5406, 0.4978, 0.5325, 0.5617, 0.4768, 0.5155],
       device='cuda:0') torch.Size([16])
percent tensor([0.5597, 0.5602, 0.5748, 0.5798, 0.5841, 0.5666, 0.5705, 0.5849, 0.5676,
        0.5656, 0.5622, 0.5788, 0.5557, 0.5817, 0.5629, 0.5735],
       device='cuda:0') torch.Size([16])
percent tensor([0.6056, 0.6087, 0.5660, 0.5639, 0.5660, 0.5498, 0.5956, 0.5399, 0.6190,
        0.6216, 0.6170, 0.6073, 0.6319, 0.6157, 0.5596, 0.5807],
       device='cuda:0') torch.Size([16])
percent tensor([0.9383, 0.9073, 0.9278, 0.9367, 0.9418, 0.9331, 0.9175, 0.9390, 0.9557,
        0.9487, 0.9542, 0.9550, 0.9362, 0.9237, 0.9306, 0.9217],
       device='cuda:0') torch.Size([16])
Epoch: 36 | Batch_idx: 0 |  Loss: (0.6399) |  Loss2: (0.0000) | Acc: (74.00%) (95/128)
Epoch: 36 | Batch_idx: 10 |  Loss: (0.5165) |  Loss2: (0.0000) | Acc: (81.00%) (1150/1408)
Epoch: 36 | Batch_idx: 20 |  Loss: (0.5098) |  Loss2: (0.0000) | Acc: (81.00%) (2199/2688)
Epoch: 36 | Batch_idx: 30 |  Loss: (0.5103) |  Loss2: (0.0000) | Acc: (82.00%) (3261/3968)
Epoch: 36 | Batch_idx: 40 |  Loss: (0.5111) |  Loss2: (0.0000) | Acc: (81.00%) (4299/5248)
Epoch: 36 | Batch_idx: 50 |  Loss: (0.5141) |  Loss2: (0.0000) | Acc: (81.00%) (5334/6528)
Epoch: 36 | Batch_idx: 60 |  Loss: (0.5219) |  Loss2: (0.0000) | Acc: (81.00%) (6360/7808)
Epoch: 36 | Batch_idx: 70 |  Loss: (0.5117) |  Loss2: (0.0000) | Acc: (81.00%) (7430/9088)
Epoch: 36 | Batch_idx: 80 |  Loss: (0.5150) |  Loss2: (0.0000) | Acc: (81.00%) (8472/10368)
Epoch: 36 | Batch_idx: 90 |  Loss: (0.5155) |  Loss2: (0.0000) | Acc: (81.00%) (9523/11648)
Epoch: 36 | Batch_idx: 100 |  Loss: (0.5115) |  Loss2: (0.0000) | Acc: (81.00%) (10589/12928)
Epoch: 36 | Batch_idx: 110 |  Loss: (0.5122) |  Loss2: (0.0000) | Acc: (81.00%) (11635/14208)
Epoch: 36 | Batch_idx: 120 |  Loss: (0.5130) |  Loss2: (0.0000) | Acc: (81.00%) (12686/15488)
Epoch: 36 | Batch_idx: 130 |  Loss: (0.5137) |  Loss2: (0.0000) | Acc: (81.00%) (13722/16768)
Epoch: 36 | Batch_idx: 140 |  Loss: (0.5158) |  Loss2: (0.0000) | Acc: (81.00%) (14755/18048)
Epoch: 36 | Batch_idx: 150 |  Loss: (0.5153) |  Loss2: (0.0000) | Acc: (81.00%) (15807/19328)
Epoch: 36 | Batch_idx: 160 |  Loss: (0.5117) |  Loss2: (0.0000) | Acc: (81.00%) (16881/20608)
Epoch: 36 | Batch_idx: 170 |  Loss: (0.5097) |  Loss2: (0.0000) | Acc: (82.00%) (17949/21888)
Epoch: 36 | Batch_idx: 180 |  Loss: (0.5093) |  Loss2: (0.0000) | Acc: (82.00%) (19001/23168)
Epoch: 36 | Batch_idx: 190 |  Loss: (0.5104) |  Loss2: (0.0000) | Acc: (81.00%) (20026/24448)
Epoch: 36 | Batch_idx: 200 |  Loss: (0.5111) |  Loss2: (0.0000) | Acc: (81.00%) (21083/25728)
Epoch: 36 | Batch_idx: 210 |  Loss: (0.5115) |  Loss2: (0.0000) | Acc: (81.00%) (22121/27008)
Epoch: 36 | Batch_idx: 220 |  Loss: (0.5107) |  Loss2: (0.0000) | Acc: (81.00%) (23192/28288)
Epoch: 36 | Batch_idx: 230 |  Loss: (0.5124) |  Loss2: (0.0000) | Acc: (81.00%) (24241/29568)
Epoch: 36 | Batch_idx: 240 |  Loss: (0.5108) |  Loss2: (0.0000) | Acc: (82.00%) (25320/30848)
Epoch: 36 | Batch_idx: 250 |  Loss: (0.5112) |  Loss2: (0.0000) | Acc: (82.00%) (26372/32128)
Epoch: 36 | Batch_idx: 260 |  Loss: (0.5105) |  Loss2: (0.0000) | Acc: (82.00%) (27432/33408)
Epoch: 36 | Batch_idx: 270 |  Loss: (0.5087) |  Loss2: (0.0000) | Acc: (82.00%) (28519/34688)
Epoch: 36 | Batch_idx: 280 |  Loss: (0.5087) |  Loss2: (0.0000) | Acc: (82.00%) (29580/35968)
Epoch: 36 | Batch_idx: 290 |  Loss: (0.5079) |  Loss2: (0.0000) | Acc: (82.00%) (30654/37248)
Epoch: 36 | Batch_idx: 300 |  Loss: (0.5089) |  Loss2: (0.0000) | Acc: (82.00%) (31699/38528)
Epoch: 36 | Batch_idx: 310 |  Loss: (0.5100) |  Loss2: (0.0000) | Acc: (82.00%) (32734/39808)
Epoch: 36 | Batch_idx: 320 |  Loss: (0.5099) |  Loss2: (0.0000) | Acc: (82.00%) (33794/41088)
Epoch: 36 | Batch_idx: 330 |  Loss: (0.5092) |  Loss2: (0.0000) | Acc: (82.00%) (34863/42368)
Epoch: 36 | Batch_idx: 340 |  Loss: (0.5101) |  Loss2: (0.0000) | Acc: (82.00%) (35911/43648)
Epoch: 36 | Batch_idx: 350 |  Loss: (0.5085) |  Loss2: (0.0000) | Acc: (82.00%) (36988/44928)
Epoch: 36 | Batch_idx: 360 |  Loss: (0.5077) |  Loss2: (0.0000) | Acc: (82.00%) (38051/46208)
Epoch: 36 | Batch_idx: 370 |  Loss: (0.5081) |  Loss2: (0.0000) | Acc: (82.00%) (39107/47488)
Epoch: 36 | Batch_idx: 380 |  Loss: (0.5071) |  Loss2: (0.0000) | Acc: (82.00%) (40176/48768)
Epoch: 36 | Batch_idx: 390 |  Loss: (0.5063) |  Loss2: (0.0000) | Acc: (82.00%) (41203/50000)
# TEST : Loss: (0.6361) | Acc: (78.00%) (7841/10000)
percent tensor([0.4987, 0.4996, 0.5017, 0.4984, 0.5017, 0.5002, 0.4998, 0.4981, 0.4983,
        0.4995, 0.4992, 0.5008, 0.4990, 0.4992, 0.5000, 0.4991],
       device='cuda:0') torch.Size([16])
percent tensor([0.4718, 0.4571, 0.4755, 0.4741, 0.4667, 0.4804, 0.4583, 0.4679, 0.4641,
        0.4631, 0.4622, 0.4680, 0.4646, 0.4595, 0.4652, 0.4703],
       device='cuda:0') torch.Size([16])
percent tensor([0.5486, 0.5356, 0.5001, 0.4873, 0.5038, 0.5411, 0.5429, 0.5057, 0.5110,
        0.5233, 0.5153, 0.4970, 0.5363, 0.5185, 0.5401, 0.5371],
       device='cuda:0') torch.Size([16])
percent tensor([0.5758, 0.5676, 0.5791, 0.5885, 0.5802, 0.5858, 0.5785, 0.5925, 0.5749,
        0.5636, 0.5662, 0.5852, 0.5668, 0.5775, 0.5881, 0.5778],
       device='cuda:0') torch.Size([16])
percent tensor([0.5084, 0.5273, 0.4996, 0.4984, 0.5063, 0.5194, 0.5016, 0.4706, 0.5373,
        0.5280, 0.5394, 0.4985, 0.5293, 0.5594, 0.4789, 0.5079],
       device='cuda:0') torch.Size([16])
percent tensor([0.5608, 0.5586, 0.5758, 0.5830, 0.5836, 0.5692, 0.5689, 0.5834, 0.5660,
        0.5622, 0.5618, 0.5745, 0.5544, 0.5790, 0.5650, 0.5754],
       device='cuda:0') torch.Size([16])
percent tensor([0.6048, 0.6252, 0.5831, 0.5721, 0.5736, 0.5599, 0.6110, 0.5475, 0.6194,
        0.6281, 0.6216, 0.6099, 0.6377, 0.6331, 0.5743, 0.5800],
       device='cuda:0') torch.Size([16])
percent tensor([0.9368, 0.9434, 0.9387, 0.9360, 0.9287, 0.9280, 0.9269, 0.9357, 0.9541,
        0.9540, 0.9577, 0.9481, 0.9392, 0.9483, 0.9479, 0.9295],
       device='cuda:0') torch.Size([16])
Epoch: 37 | Batch_idx: 0 |  Loss: (0.3297) |  Loss2: (0.0000) | Acc: (87.00%) (112/128)
Epoch: 37 | Batch_idx: 10 |  Loss: (0.4732) |  Loss2: (0.0000) | Acc: (83.00%) (1171/1408)
Epoch: 37 | Batch_idx: 20 |  Loss: (0.4753) |  Loss2: (0.0000) | Acc: (83.00%) (2236/2688)
Epoch: 37 | Batch_idx: 30 |  Loss: (0.4870) |  Loss2: (0.0000) | Acc: (82.00%) (3293/3968)
Epoch: 37 | Batch_idx: 40 |  Loss: (0.4829) |  Loss2: (0.0000) | Acc: (83.00%) (4361/5248)
Epoch: 37 | Batch_idx: 50 |  Loss: (0.4675) |  Loss2: (0.0000) | Acc: (83.00%) (5468/6528)
Epoch: 37 | Batch_idx: 60 |  Loss: (0.4697) |  Loss2: (0.0000) | Acc: (83.00%) (6543/7808)
Epoch: 37 | Batch_idx: 70 |  Loss: (0.4747) |  Loss2: (0.0000) | Acc: (83.00%) (7597/9088)
Epoch: 37 | Batch_idx: 80 |  Loss: (0.4746) |  Loss2: (0.0000) | Acc: (83.00%) (8683/10368)
Epoch: 37 | Batch_idx: 90 |  Loss: (0.4790) |  Loss2: (0.0000) | Acc: (83.00%) (9743/11648)
Epoch: 37 | Batch_idx: 100 |  Loss: (0.4815) |  Loss2: (0.0000) | Acc: (83.00%) (10789/12928)
Epoch: 37 | Batch_idx: 110 |  Loss: (0.4821) |  Loss2: (0.0000) | Acc: (83.00%) (11847/14208)
Epoch: 37 | Batch_idx: 120 |  Loss: (0.4838) |  Loss2: (0.0000) | Acc: (83.00%) (12915/15488)
Epoch: 37 | Batch_idx: 130 |  Loss: (0.4814) |  Loss2: (0.0000) | Acc: (83.00%) (13993/16768)
Epoch: 37 | Batch_idx: 140 |  Loss: (0.4840) |  Loss2: (0.0000) | Acc: (83.00%) (15042/18048)
Epoch: 37 | Batch_idx: 150 |  Loss: (0.4821) |  Loss2: (0.0000) | Acc: (83.00%) (16129/19328)
Epoch: 37 | Batch_idx: 160 |  Loss: (0.4811) |  Loss2: (0.0000) | Acc: (83.00%) (17210/20608)
Epoch: 37 | Batch_idx: 170 |  Loss: (0.4814) |  Loss2: (0.0000) | Acc: (83.00%) (18285/21888)
Epoch: 37 | Batch_idx: 180 |  Loss: (0.4818) |  Loss2: (0.0000) | Acc: (83.00%) (19347/23168)
Epoch: 37 | Batch_idx: 190 |  Loss: (0.4825) |  Loss2: (0.0000) | Acc: (83.00%) (20407/24448)
Epoch: 37 | Batch_idx: 200 |  Loss: (0.4825) |  Loss2: (0.0000) | Acc: (83.00%) (21475/25728)
Epoch: 37 | Batch_idx: 210 |  Loss: (0.4832) |  Loss2: (0.0000) | Acc: (83.00%) (22533/27008)
Epoch: 37 | Batch_idx: 220 |  Loss: (0.4831) |  Loss2: (0.0000) | Acc: (83.00%) (23593/28288)
Epoch: 37 | Batch_idx: 230 |  Loss: (0.4839) |  Loss2: (0.0000) | Acc: (83.00%) (24635/29568)
Epoch: 37 | Batch_idx: 240 |  Loss: (0.4839) |  Loss2: (0.0000) | Acc: (83.00%) (25702/30848)
Epoch: 37 | Batch_idx: 250 |  Loss: (0.4825) |  Loss2: (0.0000) | Acc: (83.00%) (26785/32128)
Epoch: 37 | Batch_idx: 260 |  Loss: (0.4842) |  Loss2: (0.0000) | Acc: (83.00%) (27829/33408)
Epoch: 37 | Batch_idx: 270 |  Loss: (0.4833) |  Loss2: (0.0000) | Acc: (83.00%) (28909/34688)
Epoch: 37 | Batch_idx: 280 |  Loss: (0.4837) |  Loss2: (0.0000) | Acc: (83.00%) (29963/35968)
Epoch: 37 | Batch_idx: 290 |  Loss: (0.4832) |  Loss2: (0.0000) | Acc: (83.00%) (31045/37248)
Epoch: 37 | Batch_idx: 300 |  Loss: (0.4847) |  Loss2: (0.0000) | Acc: (83.00%) (32086/38528)
Epoch: 37 | Batch_idx: 310 |  Loss: (0.4837) |  Loss2: (0.0000) | Acc: (83.00%) (33165/39808)
Epoch: 37 | Batch_idx: 320 |  Loss: (0.4841) |  Loss2: (0.0000) | Acc: (83.00%) (34227/41088)
Epoch: 37 | Batch_idx: 330 |  Loss: (0.4840) |  Loss2: (0.0000) | Acc: (83.00%) (35306/42368)
Epoch: 37 | Batch_idx: 340 |  Loss: (0.4844) |  Loss2: (0.0000) | Acc: (83.00%) (36363/43648)
Epoch: 37 | Batch_idx: 350 |  Loss: (0.4847) |  Loss2: (0.0000) | Acc: (83.00%) (37422/44928)
Epoch: 37 | Batch_idx: 360 |  Loss: (0.4849) |  Loss2: (0.0000) | Acc: (83.00%) (38487/46208)
Epoch: 37 | Batch_idx: 370 |  Loss: (0.4842) |  Loss2: (0.0000) | Acc: (83.00%) (39576/47488)
Epoch: 37 | Batch_idx: 380 |  Loss: (0.4852) |  Loss2: (0.0000) | Acc: (83.00%) (40628/48768)
Epoch: 37 | Batch_idx: 390 |  Loss: (0.4861) |  Loss2: (0.0000) | Acc: (83.00%) (41639/50000)
# TEST : Loss: (0.6735) | Acc: (77.00%) (7782/10000)
percent tensor([0.4987, 0.4993, 0.5030, 0.4988, 0.5027, 0.5001, 0.4999, 0.4983, 0.4982,
        0.4997, 0.4989, 0.5017, 0.4989, 0.4982, 0.4999, 0.4990],
       device='cuda:0') torch.Size([16])
percent tensor([0.4720, 0.4598, 0.4743, 0.4719, 0.4664, 0.4806, 0.4601, 0.4693, 0.4666,
        0.4640, 0.4641, 0.4670, 0.4652, 0.4641, 0.4655, 0.4711],
       device='cuda:0') torch.Size([16])
percent tensor([0.5538, 0.5339, 0.5063, 0.4867, 0.5130, 0.5522, 0.5457, 0.5062, 0.5144,
        0.5249, 0.5217, 0.5054, 0.5413, 0.5113, 0.5481, 0.5409],
       device='cuda:0') torch.Size([16])
percent tensor([0.5710, 0.5680, 0.5768, 0.5836, 0.5789, 0.5739, 0.5783, 0.5883, 0.5759,
        0.5654, 0.5668, 0.5843, 0.5670, 0.5802, 0.5827, 0.5711],
       device='cuda:0') torch.Size([16])
percent tensor([0.5056, 0.5262, 0.4850, 0.4988, 0.4897, 0.5158, 0.4973, 0.4671, 0.5381,
        0.5231, 0.5377, 0.4848, 0.5300, 0.5570, 0.4788, 0.5122],
       device='cuda:0') torch.Size([16])
percent tensor([0.5594, 0.5613, 0.5706, 0.5743, 0.5774, 0.5660, 0.5731, 0.5809, 0.5688,
        0.5646, 0.5627, 0.5736, 0.5551, 0.5825, 0.5603, 0.5733],
       device='cuda:0') torch.Size([16])
percent tensor([0.5963, 0.6096, 0.5720, 0.5695, 0.5567, 0.5539, 0.5985, 0.5427, 0.6017,
        0.6160, 0.6180, 0.6015, 0.6310, 0.6151, 0.5567, 0.5834],
       device='cuda:0') torch.Size([16])
percent tensor([0.9375, 0.9234, 0.9409, 0.9462, 0.9123, 0.9193, 0.9314, 0.9506, 0.9448,
        0.9509, 0.9571, 0.9597, 0.9283, 0.9366, 0.9342, 0.9274],
       device='cuda:0') torch.Size([16])
Epoch: 38 | Batch_idx: 0 |  Loss: (0.5257) |  Loss2: (0.0000) | Acc: (82.00%) (105/128)
Epoch: 38 | Batch_idx: 10 |  Loss: (0.4757) |  Loss2: (0.0000) | Acc: (83.00%) (1179/1408)
Epoch: 38 | Batch_idx: 20 |  Loss: (0.4802) |  Loss2: (0.0000) | Acc: (83.00%) (2251/2688)
Epoch: 38 | Batch_idx: 30 |  Loss: (0.4685) |  Loss2: (0.0000) | Acc: (83.00%) (3328/3968)
Epoch: 38 | Batch_idx: 40 |  Loss: (0.4805) |  Loss2: (0.0000) | Acc: (83.00%) (4376/5248)
Epoch: 38 | Batch_idx: 50 |  Loss: (0.4779) |  Loss2: (0.0000) | Acc: (83.00%) (5453/6528)
Epoch: 38 | Batch_idx: 60 |  Loss: (0.4716) |  Loss2: (0.0000) | Acc: (83.00%) (6528/7808)
Epoch: 38 | Batch_idx: 70 |  Loss: (0.4720) |  Loss2: (0.0000) | Acc: (83.00%) (7608/9088)
Epoch: 38 | Batch_idx: 80 |  Loss: (0.4665) |  Loss2: (0.0000) | Acc: (83.00%) (8688/10368)
Epoch: 38 | Batch_idx: 90 |  Loss: (0.4615) |  Loss2: (0.0000) | Acc: (84.00%) (9793/11648)
Epoch: 38 | Batch_idx: 100 |  Loss: (0.4649) |  Loss2: (0.0000) | Acc: (83.00%) (10858/12928)
Epoch: 38 | Batch_idx: 110 |  Loss: (0.4658) |  Loss2: (0.0000) | Acc: (83.00%) (11928/14208)
Epoch: 38 | Batch_idx: 120 |  Loss: (0.4645) |  Loss2: (0.0000) | Acc: (83.00%) (12999/15488)
Epoch: 38 | Batch_idx: 130 |  Loss: (0.4682) |  Loss2: (0.0000) | Acc: (83.00%) (14052/16768)
Epoch: 38 | Batch_idx: 140 |  Loss: (0.4704) |  Loss2: (0.0000) | Acc: (83.00%) (15111/18048)
Epoch: 38 | Batch_idx: 150 |  Loss: (0.4715) |  Loss2: (0.0000) | Acc: (83.00%) (16185/19328)
Epoch: 38 | Batch_idx: 160 |  Loss: (0.4719) |  Loss2: (0.0000) | Acc: (83.00%) (17253/20608)
Epoch: 38 | Batch_idx: 170 |  Loss: (0.4751) |  Loss2: (0.0000) | Acc: (83.00%) (18300/21888)
Epoch: 38 | Batch_idx: 180 |  Loss: (0.4730) |  Loss2: (0.0000) | Acc: (83.00%) (19386/23168)
Epoch: 38 | Batch_idx: 190 |  Loss: (0.4715) |  Loss2: (0.0000) | Acc: (83.00%) (20470/24448)
Epoch: 38 | Batch_idx: 200 |  Loss: (0.4694) |  Loss2: (0.0000) | Acc: (83.00%) (21556/25728)
Epoch: 38 | Batch_idx: 210 |  Loss: (0.4698) |  Loss2: (0.0000) | Acc: (83.00%) (22636/27008)
Epoch: 38 | Batch_idx: 220 |  Loss: (0.4696) |  Loss2: (0.0000) | Acc: (83.00%) (23715/28288)
Epoch: 38 | Batch_idx: 230 |  Loss: (0.4693) |  Loss2: (0.0000) | Acc: (83.00%) (24788/29568)
Epoch: 38 | Batch_idx: 240 |  Loss: (0.4685) |  Loss2: (0.0000) | Acc: (83.00%) (25881/30848)
Epoch: 38 | Batch_idx: 250 |  Loss: (0.4695) |  Loss2: (0.0000) | Acc: (83.00%) (26942/32128)
Epoch: 38 | Batch_idx: 260 |  Loss: (0.4703) |  Loss2: (0.0000) | Acc: (83.00%) (28011/33408)
Epoch: 38 | Batch_idx: 270 |  Loss: (0.4696) |  Loss2: (0.0000) | Acc: (83.00%) (29097/34688)
Epoch: 38 | Batch_idx: 280 |  Loss: (0.4702) |  Loss2: (0.0000) | Acc: (83.00%) (30157/35968)
Epoch: 38 | Batch_idx: 290 |  Loss: (0.4705) |  Loss2: (0.0000) | Acc: (83.00%) (31226/37248)
Epoch: 38 | Batch_idx: 300 |  Loss: (0.4723) |  Loss2: (0.0000) | Acc: (83.00%) (32268/38528)
Epoch: 38 | Batch_idx: 310 |  Loss: (0.4728) |  Loss2: (0.0000) | Acc: (83.00%) (33319/39808)
Epoch: 38 | Batch_idx: 320 |  Loss: (0.4730) |  Loss2: (0.0000) | Acc: (83.00%) (34382/41088)
Epoch: 38 | Batch_idx: 330 |  Loss: (0.4716) |  Loss2: (0.0000) | Acc: (83.00%) (35477/42368)
Epoch: 38 | Batch_idx: 340 |  Loss: (0.4720) |  Loss2: (0.0000) | Acc: (83.00%) (36536/43648)
Epoch: 38 | Batch_idx: 350 |  Loss: (0.4711) |  Loss2: (0.0000) | Acc: (83.00%) (37611/44928)
Epoch: 38 | Batch_idx: 360 |  Loss: (0.4717) |  Loss2: (0.0000) | Acc: (83.00%) (38664/46208)
Epoch: 38 | Batch_idx: 370 |  Loss: (0.4717) |  Loss2: (0.0000) | Acc: (83.00%) (39747/47488)
Epoch: 38 | Batch_idx: 380 |  Loss: (0.4724) |  Loss2: (0.0000) | Acc: (83.00%) (40816/48768)
Epoch: 38 | Batch_idx: 390 |  Loss: (0.4729) |  Loss2: (0.0000) | Acc: (83.00%) (41838/50000)
# TEST : Loss: (0.7636) | Acc: (76.00%) (7604/10000)
percent tensor([0.4987, 0.4996, 0.5023, 0.4989, 0.5024, 0.4999, 0.5003, 0.4987, 0.4985,
        0.4999, 0.4991, 0.5018, 0.4990, 0.4993, 0.5000, 0.4990],
       device='cuda:0') torch.Size([16])
percent tensor([0.4706, 0.4576, 0.4735, 0.4718, 0.4656, 0.4793, 0.4586, 0.4675, 0.4650,
        0.4629, 0.4624, 0.4665, 0.4633, 0.4623, 0.4641, 0.4701],
       device='cuda:0') torch.Size([16])
percent tensor([0.5468, 0.5376, 0.5032, 0.4896, 0.5050, 0.5380, 0.5438, 0.5089, 0.5110,
        0.5263, 0.5238, 0.5018, 0.5380, 0.5206, 0.5410, 0.5385],
       device='cuda:0') torch.Size([16])
percent tensor([0.5741, 0.5694, 0.5781, 0.5841, 0.5792, 0.5829, 0.5802, 0.5884, 0.5771,
        0.5649, 0.5685, 0.5851, 0.5672, 0.5791, 0.5853, 0.5755],
       device='cuda:0') torch.Size([16])
percent tensor([0.5142, 0.5252, 0.4938, 0.4946, 0.5011, 0.5178, 0.4997, 0.4666, 0.5371,
        0.5243, 0.5383, 0.4911, 0.5291, 0.5534, 0.4775, 0.5135],
       device='cuda:0') torch.Size([16])
percent tensor([0.5651, 0.5588, 0.5770, 0.5819, 0.5846, 0.5699, 0.5714, 0.5834, 0.5664,
        0.5620, 0.5647, 0.5782, 0.5560, 0.5761, 0.5664, 0.5773],
       device='cuda:0') torch.Size([16])
percent tensor([0.5896, 0.6084, 0.5681, 0.5635, 0.5678, 0.5484, 0.5879, 0.5388, 0.6059,
        0.6165, 0.6058, 0.5923, 0.6249, 0.6093, 0.5539, 0.5741],
       device='cuda:0') torch.Size([16])
percent tensor([0.9334, 0.9573, 0.9335, 0.9306, 0.9277, 0.9236, 0.9309, 0.9282, 0.9534,
        0.9643, 0.9662, 0.9591, 0.9404, 0.9482, 0.9426, 0.9225],
       device='cuda:0') torch.Size([16])
Epoch: 39 | Batch_idx: 0 |  Loss: (0.5963) |  Loss2: (0.0000) | Acc: (80.00%) (103/128)
Epoch: 39 | Batch_idx: 10 |  Loss: (0.4696) |  Loss2: (0.0000) | Acc: (83.00%) (1171/1408)
Epoch: 39 | Batch_idx: 20 |  Loss: (0.4749) |  Loss2: (0.0000) | Acc: (83.00%) (2232/2688)
Epoch: 39 | Batch_idx: 30 |  Loss: (0.4628) |  Loss2: (0.0000) | Acc: (83.00%) (3319/3968)
Epoch: 39 | Batch_idx: 40 |  Loss: (0.4535) |  Loss2: (0.0000) | Acc: (84.00%) (4417/5248)
Epoch: 39 | Batch_idx: 50 |  Loss: (0.4564) |  Loss2: (0.0000) | Acc: (83.00%) (5482/6528)
Epoch: 39 | Batch_idx: 60 |  Loss: (0.4582) |  Loss2: (0.0000) | Acc: (84.00%) (6561/7808)
Epoch: 39 | Batch_idx: 70 |  Loss: (0.4620) |  Loss2: (0.0000) | Acc: (84.00%) (7637/9088)
Epoch: 39 | Batch_idx: 80 |  Loss: (0.4603) |  Loss2: (0.0000) | Acc: (84.00%) (8715/10368)
Epoch: 39 | Batch_idx: 90 |  Loss: (0.4630) |  Loss2: (0.0000) | Acc: (83.00%) (9784/11648)
Epoch: 39 | Batch_idx: 100 |  Loss: (0.4605) |  Loss2: (0.0000) | Acc: (84.00%) (10862/12928)
Epoch: 39 | Batch_idx: 110 |  Loss: (0.4585) |  Loss2: (0.0000) | Acc: (84.00%) (11946/14208)
Epoch: 39 | Batch_idx: 120 |  Loss: (0.4585) |  Loss2: (0.0000) | Acc: (84.00%) (13020/15488)
Epoch: 39 | Batch_idx: 130 |  Loss: (0.4602) |  Loss2: (0.0000) | Acc: (84.00%) (14087/16768)
Epoch: 39 | Batch_idx: 140 |  Loss: (0.4573) |  Loss2: (0.0000) | Acc: (84.00%) (15191/18048)
Epoch: 39 | Batch_idx: 150 |  Loss: (0.4576) |  Loss2: (0.0000) | Acc: (84.00%) (16259/19328)
Epoch: 39 | Batch_idx: 160 |  Loss: (0.4594) |  Loss2: (0.0000) | Acc: (84.00%) (17321/20608)
Epoch: 39 | Batch_idx: 170 |  Loss: (0.4584) |  Loss2: (0.0000) | Acc: (84.00%) (18400/21888)
Epoch: 39 | Batch_idx: 180 |  Loss: (0.4602) |  Loss2: (0.0000) | Acc: (83.00%) (19447/23168)
Epoch: 39 | Batch_idx: 190 |  Loss: (0.4595) |  Loss2: (0.0000) | Acc: (83.00%) (20526/24448)
Epoch: 39 | Batch_idx: 200 |  Loss: (0.4595) |  Loss2: (0.0000) | Acc: (83.00%) (21590/25728)
Epoch: 39 | Batch_idx: 210 |  Loss: (0.4598) |  Loss2: (0.0000) | Acc: (83.00%) (22672/27008)
Epoch: 39 | Batch_idx: 220 |  Loss: (0.4582) |  Loss2: (0.0000) | Acc: (83.00%) (23754/28288)
Epoch: 39 | Batch_idx: 230 |  Loss: (0.4565) |  Loss2: (0.0000) | Acc: (83.00%) (24833/29568)
Epoch: 39 | Batch_idx: 240 |  Loss: (0.4567) |  Loss2: (0.0000) | Acc: (83.00%) (25910/30848)
Epoch: 39 | Batch_idx: 250 |  Loss: (0.4569) |  Loss2: (0.0000) | Acc: (84.00%) (26991/32128)
Epoch: 39 | Batch_idx: 260 |  Loss: (0.4568) |  Loss2: (0.0000) | Acc: (84.00%) (28067/33408)
Epoch: 39 | Batch_idx: 270 |  Loss: (0.4552) |  Loss2: (0.0000) | Acc: (84.00%) (29165/34688)
Epoch: 39 | Batch_idx: 280 |  Loss: (0.4548) |  Loss2: (0.0000) | Acc: (84.00%) (30255/35968)
Epoch: 39 | Batch_idx: 290 |  Loss: (0.4547) |  Loss2: (0.0000) | Acc: (84.00%) (31333/37248)
Epoch: 39 | Batch_idx: 300 |  Loss: (0.4546) |  Loss2: (0.0000) | Acc: (84.00%) (32401/38528)
Epoch: 39 | Batch_idx: 310 |  Loss: (0.4555) |  Loss2: (0.0000) | Acc: (84.00%) (33474/39808)
Epoch: 39 | Batch_idx: 320 |  Loss: (0.4546) |  Loss2: (0.0000) | Acc: (84.00%) (34570/41088)
Epoch: 39 | Batch_idx: 330 |  Loss: (0.4552) |  Loss2: (0.0000) | Acc: (84.00%) (35632/42368)
Epoch: 39 | Batch_idx: 340 |  Loss: (0.4551) |  Loss2: (0.0000) | Acc: (84.00%) (36720/43648)
Epoch: 39 | Batch_idx: 350 |  Loss: (0.4559) |  Loss2: (0.0000) | Acc: (84.00%) (37788/44928)
Epoch: 39 | Batch_idx: 360 |  Loss: (0.4553) |  Loss2: (0.0000) | Acc: (84.00%) (38883/46208)
Epoch: 39 | Batch_idx: 370 |  Loss: (0.4561) |  Loss2: (0.0000) | Acc: (84.00%) (39941/47488)
Epoch: 39 | Batch_idx: 380 |  Loss: (0.4555) |  Loss2: (0.0000) | Acc: (84.00%) (41031/48768)
Epoch: 39 | Batch_idx: 390 |  Loss: (0.4551) |  Loss2: (0.0000) | Acc: (84.00%) (42076/50000)
# TEST : Loss: (0.6334) | Acc: (79.00%) (7937/10000)
percent tensor([0.4986, 0.4997, 0.5019, 0.4987, 0.5017, 0.5001, 0.5002, 0.4985, 0.4983,
        0.4998, 0.4992, 0.5013, 0.4989, 0.4998, 0.5001, 0.4991],
       device='cuda:0') torch.Size([16])
percent tensor([0.4705, 0.4554, 0.4759, 0.4746, 0.4672, 0.4788, 0.4572, 0.4681, 0.4627,
        0.4621, 0.4595, 0.4676, 0.4629, 0.4562, 0.4637, 0.4696],
       device='cuda:0') torch.Size([16])
percent tensor([0.5500, 0.5334, 0.5040, 0.4874, 0.5090, 0.5456, 0.5469, 0.5046, 0.5125,
        0.5243, 0.5236, 0.5071, 0.5404, 0.5210, 0.5428, 0.5374],
       device='cuda:0') torch.Size([16])
percent tensor([0.5752, 0.5695, 0.5766, 0.5864, 0.5786, 0.5800, 0.5791, 0.5890, 0.5769,
        0.5674, 0.5686, 0.5855, 0.5691, 0.5795, 0.5837, 0.5769],
       device='cuda:0') torch.Size([16])
percent tensor([0.5112, 0.5294, 0.4977, 0.5017, 0.4995, 0.5201, 0.5014, 0.4771, 0.5419,
        0.5293, 0.5403, 0.4911, 0.5300, 0.5651, 0.4780, 0.5171],
       device='cuda:0') torch.Size([16])
percent tensor([0.5614, 0.5642, 0.5757, 0.5840, 0.5826, 0.5686, 0.5721, 0.5860, 0.5678,
        0.5685, 0.5650, 0.5767, 0.5569, 0.5857, 0.5651, 0.5785],
       device='cuda:0') torch.Size([16])
percent tensor([0.5986, 0.5881, 0.5686, 0.5686, 0.5672, 0.5606, 0.5884, 0.5429, 0.6129,
        0.6006, 0.6134, 0.5866, 0.6252, 0.6048, 0.5551, 0.5737],
       device='cuda:0') torch.Size([16])
percent tensor([0.9326, 0.9206, 0.9389, 0.9450, 0.9221, 0.9243, 0.9219, 0.9363, 0.9552,
        0.9565, 0.9635, 0.9579, 0.9233, 0.9135, 0.9351, 0.9307],
       device='cuda:0') torch.Size([16])
False Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=128, out_features=16, bias=False)
True Linear(in_features=16, out_features=2, bias=False)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=128, out_features=16, bias=False)
True Linear(in_features=16, out_features=2, bias=False)
False Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=256, out_features=32, bias=False)
True Linear(in_features=32, out_features=2, bias=False)
False Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=256, out_features=32, bias=False)
True Linear(in_features=32, out_features=2, bias=False)
False Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=512, out_features=64, bias=False)
True Linear(in_features=64, out_features=2, bias=False)
False Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=512, out_features=64, bias=False)
True Linear(in_features=64, out_features=2, bias=False)
False Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1024, out_features=128, bias=False)
True Linear(in_features=128, out_features=2, bias=False)
False Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1024, out_features=128, bias=False)
True Linear(in_features=128, out_features=2, bias=False)
False Linear(in_features=512, out_features=10, bias=True)
Epoch: 40 | Batch_idx: 0 |  Loss: (0.4951) |  Loss2: (0.0000) | Acc: (82.00%) (106/128)
Epoch: 40 | Batch_idx: 10 |  Loss: (0.5365) |  Loss2: (0.0000) | Acc: (81.00%) (1154/1408)
Epoch: 40 | Batch_idx: 20 |  Loss: (0.6031) |  Loss2: (0.0000) | Acc: (79.00%) (2143/2688)
Epoch: 40 | Batch_idx: 30 |  Loss: (0.6465) |  Loss2: (0.0000) | Acc: (77.00%) (3091/3968)
Epoch: 40 | Batch_idx: 40 |  Loss: (0.6728) |  Loss2: (0.0000) | Acc: (76.00%) (4033/5248)
Epoch: 40 | Batch_idx: 50 |  Loss: (0.6797) |  Loss2: (0.0000) | Acc: (76.00%) (5002/6528)
Epoch: 40 | Batch_idx: 60 |  Loss: (0.6863) |  Loss2: (0.0000) | Acc: (76.00%) (5969/7808)
Epoch: 40 | Batch_idx: 70 |  Loss: (0.6824) |  Loss2: (0.0000) | Acc: (76.00%) (6967/9088)
Epoch: 40 | Batch_idx: 80 |  Loss: (0.6796) |  Loss2: (0.0000) | Acc: (76.00%) (7944/10368)
Epoch: 40 | Batch_idx: 90 |  Loss: (0.6780) |  Loss2: (0.0000) | Acc: (76.00%) (8931/11648)
Epoch: 40 | Batch_idx: 100 |  Loss: (0.6763) |  Loss2: (0.0000) | Acc: (76.00%) (9919/12928)
Epoch: 40 | Batch_idx: 110 |  Loss: (0.6732) |  Loss2: (0.0000) | Acc: (76.00%) (10915/14208)
Epoch: 40 | Batch_idx: 120 |  Loss: (0.6689) |  Loss2: (0.0000) | Acc: (77.00%) (11926/15488)
Epoch: 40 | Batch_idx: 130 |  Loss: (0.6702) |  Loss2: (0.0000) | Acc: (76.00%) (12885/16768)
Epoch: 40 | Batch_idx: 140 |  Loss: (0.6660) |  Loss2: (0.0000) | Acc: (76.00%) (13891/18048)
Epoch: 40 | Batch_idx: 150 |  Loss: (0.6633) |  Loss2: (0.0000) | Acc: (77.00%) (14894/19328)
Epoch: 40 | Batch_idx: 160 |  Loss: (0.6611) |  Loss2: (0.0000) | Acc: (77.00%) (15898/20608)
Epoch: 40 | Batch_idx: 170 |  Loss: (0.6550) |  Loss2: (0.0000) | Acc: (77.00%) (16930/21888)
Epoch: 40 | Batch_idx: 180 |  Loss: (0.6520) |  Loss2: (0.0000) | Acc: (77.00%) (17946/23168)
Epoch: 40 | Batch_idx: 190 |  Loss: (0.6494) |  Loss2: (0.0000) | Acc: (77.00%) (18968/24448)
Epoch: 40 | Batch_idx: 200 |  Loss: (0.6455) |  Loss2: (0.0000) | Acc: (77.00%) (19997/25728)
Epoch: 40 | Batch_idx: 210 |  Loss: (0.6438) |  Loss2: (0.0000) | Acc: (77.00%) (21006/27008)
Epoch: 40 | Batch_idx: 220 |  Loss: (0.6406) |  Loss2: (0.0000) | Acc: (77.00%) (22036/28288)
Epoch: 40 | Batch_idx: 230 |  Loss: (0.6376) |  Loss2: (0.0000) | Acc: (78.00%) (23067/29568)
Epoch: 40 | Batch_idx: 240 |  Loss: (0.6352) |  Loss2: (0.0000) | Acc: (78.00%) (24073/30848)
Epoch: 40 | Batch_idx: 250 |  Loss: (0.6328) |  Loss2: (0.0000) | Acc: (78.00%) (25091/32128)
Epoch: 40 | Batch_idx: 260 |  Loss: (0.6323) |  Loss2: (0.0000) | Acc: (78.00%) (26091/33408)
Epoch: 40 | Batch_idx: 270 |  Loss: (0.6295) |  Loss2: (0.0000) | Acc: (78.00%) (27129/34688)
Epoch: 40 | Batch_idx: 280 |  Loss: (0.6262) |  Loss2: (0.0000) | Acc: (78.00%) (28180/35968)
Epoch: 40 | Batch_idx: 290 |  Loss: (0.6236) |  Loss2: (0.0000) | Acc: (78.00%) (29211/37248)
Epoch: 40 | Batch_idx: 300 |  Loss: (0.6207) |  Loss2: (0.0000) | Acc: (78.00%) (30249/38528)
Epoch: 40 | Batch_idx: 310 |  Loss: (0.6189) |  Loss2: (0.0000) | Acc: (78.00%) (31275/39808)
Epoch: 40 | Batch_idx: 320 |  Loss: (0.6173) |  Loss2: (0.0000) | Acc: (78.00%) (32310/41088)
Epoch: 40 | Batch_idx: 330 |  Loss: (0.6153) |  Loss2: (0.0000) | Acc: (78.00%) (33342/42368)
Epoch: 40 | Batch_idx: 340 |  Loss: (0.6135) |  Loss2: (0.0000) | Acc: (78.00%) (34391/43648)
Epoch: 40 | Batch_idx: 350 |  Loss: (0.6122) |  Loss2: (0.0000) | Acc: (78.00%) (35432/44928)
Epoch: 40 | Batch_idx: 360 |  Loss: (0.6108) |  Loss2: (0.0000) | Acc: (78.00%) (36477/46208)
Epoch: 40 | Batch_idx: 370 |  Loss: (0.6091) |  Loss2: (0.0000) | Acc: (79.00%) (37529/47488)
Epoch: 40 | Batch_idx: 380 |  Loss: (0.6090) |  Loss2: (0.0000) | Acc: (79.00%) (38535/48768)
Epoch: 40 | Batch_idx: 390 |  Loss: (0.6077) |  Loss2: (0.0000) | Acc: (79.00%) (39554/50000)
=> saving checkpoint 'drive/app/torch/save_Schedule/checkpoint_040.pth.tar'
# TEST : Loss: (0.6030) | Acc: (79.00%) (7949/10000)
percent tensor([0.4851, 0.4864, 0.4914, 0.4865, 0.4902, 0.4850, 0.4879, 0.4856, 0.4842,
        0.4883, 0.4848, 0.4907, 0.4853, 0.4855, 0.4860, 0.4852],
       device='cuda:0') torch.Size([16])
percent tensor([0.4745, 0.4527, 0.4796, 0.4827, 0.4702, 0.4849, 0.4547, 0.4746, 0.4651,
        0.4620, 0.4612, 0.4670, 0.4630, 0.4549, 0.4657, 0.4736],
       device='cuda:0') torch.Size([16])
percent tensor([0.5705, 0.5829, 0.5082, 0.4923, 0.5256, 0.5795, 0.5958, 0.5104, 0.5422,
        0.5609, 0.5704, 0.5339, 0.5688, 0.5910, 0.5809, 0.5664],
       device='cuda:0') torch.Size([16])
percent tensor([0.5898, 0.5710, 0.6023, 0.6136, 0.6017, 0.5971, 0.5887, 0.6133, 0.5957,
        0.5769, 0.5770, 0.6022, 0.5758, 0.5833, 0.5958, 0.5878],
       device='cuda:0') torch.Size([16])
percent tensor([0.5285, 0.5518, 0.5190, 0.5315, 0.5172, 0.5324, 0.5253, 0.5024, 0.5791,
        0.5561, 0.5706, 0.5089, 0.5496, 0.6101, 0.4907, 0.5416],
       device='cuda:0') torch.Size([16])
percent tensor([0.5318, 0.5280, 0.5459, 0.5611, 0.5514, 0.5479, 0.5365, 0.5486, 0.5359,
        0.5318, 0.5297, 0.5439, 0.5249, 0.5466, 0.5309, 0.5462],
       device='cuda:0') torch.Size([16])
percent tensor([0.5764, 0.5785, 0.5403, 0.5363, 0.5288, 0.5354, 0.5664, 0.5069, 0.5899,
        0.5915, 0.5992, 0.5525, 0.6146, 0.5862, 0.5278, 0.5446],
       device='cuda:0') torch.Size([16])
percent tensor([0.9088, 0.8934, 0.9107, 0.9149, 0.8997, 0.8906, 0.8860, 0.9055, 0.9281,
        0.9281, 0.9460, 0.9246, 0.9135, 0.8671, 0.8971, 0.9022],
       device='cuda:0') torch.Size([16])
Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 3, 3, 3]) tensor(179.7098, device='cuda:0')
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(796.7329, device='cuda:0')
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(794.6080, device='cuda:0')
Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([128, 64, 3, 3]) tensor(1534.8970, device='cuda:0')
Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([128, 64, 1, 1]) tensor(501.6132, device='cuda:0')
Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([128, 128, 3, 3]) tensor(2212.2437, device='cuda:0')
Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([256, 128, 3, 3]) tensor(4309.5513, device='cuda:0')
Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([256, 128, 1, 1]) tensor(1421.5393, device='cuda:0')
Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([256, 256, 3, 3]) tensor(6095.3301, device='cuda:0')
Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([512, 256, 3, 3]) tensor(12097.9268, device='cuda:0')
Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([512, 256, 1, 1]) tensor(4033.7422, device='cuda:0')
Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([512, 512, 3, 3]) tensor(17053.0293, device='cuda:0')
Epoch: 41 | Batch_idx: 0 |  Loss: (0.6829) |  Loss2: (0.0000) | Acc: (73.00%) (94/128)
Epoch: 41 | Batch_idx: 10 |  Loss: (0.5441) |  Loss2: (0.0000) | Acc: (81.00%) (1146/1408)
Epoch: 41 | Batch_idx: 20 |  Loss: (0.5497) |  Loss2: (0.0000) | Acc: (81.00%) (2185/2688)
Epoch: 41 | Batch_idx: 30 |  Loss: (0.5363) |  Loss2: (0.0000) | Acc: (81.00%) (3244/3968)
Epoch: 41 | Batch_idx: 40 |  Loss: (0.5311) |  Loss2: (0.0000) | Acc: (81.00%) (4295/5248)
Epoch: 41 | Batch_idx: 50 |  Loss: (0.5344) |  Loss2: (0.0000) | Acc: (81.00%) (5337/6528)
Epoch: 41 | Batch_idx: 60 |  Loss: (0.5357) |  Loss2: (0.0000) | Acc: (81.00%) (6370/7808)
Epoch: 41 | Batch_idx: 70 |  Loss: (0.5360) |  Loss2: (0.0000) | Acc: (81.00%) (7413/9088)
Epoch: 41 | Batch_idx: 80 |  Loss: (0.5308) |  Loss2: (0.0000) | Acc: (81.00%) (8477/10368)
Epoch: 41 | Batch_idx: 90 |  Loss: (0.5293) |  Loss2: (0.0000) | Acc: (81.00%) (9532/11648)
Epoch: 41 | Batch_idx: 100 |  Loss: (0.5285) |  Loss2: (0.0000) | Acc: (81.00%) (10575/12928)
Epoch: 41 | Batch_idx: 110 |  Loss: (0.5284) |  Loss2: (0.0000) | Acc: (81.00%) (11630/14208)
Epoch: 41 | Batch_idx: 120 |  Loss: (0.5290) |  Loss2: (0.0000) | Acc: (81.00%) (12667/15488)
Epoch: 41 | Batch_idx: 130 |  Loss: (0.5322) |  Loss2: (0.0000) | Acc: (81.00%) (13678/16768)
Epoch: 41 | Batch_idx: 140 |  Loss: (0.5328) |  Loss2: (0.0000) | Acc: (81.00%) (14716/18048)
Epoch: 41 | Batch_idx: 150 |  Loss: (0.5309) |  Loss2: (0.0000) | Acc: (81.00%) (15764/19328)
Epoch: 41 | Batch_idx: 160 |  Loss: (0.5296) |  Loss2: (0.0000) | Acc: (81.00%) (16816/20608)
Epoch: 41 | Batch_idx: 170 |  Loss: (0.5303) |  Loss2: (0.0000) | Acc: (81.00%) (17860/21888)
Epoch: 41 | Batch_idx: 180 |  Loss: (0.5291) |  Loss2: (0.0000) | Acc: (81.00%) (18922/23168)
Epoch: 41 | Batch_idx: 190 |  Loss: (0.5269) |  Loss2: (0.0000) | Acc: (81.00%) (19976/24448)
Epoch: 41 | Batch_idx: 200 |  Loss: (0.5265) |  Loss2: (0.0000) | Acc: (81.00%) (21026/25728)
Epoch: 41 | Batch_idx: 210 |  Loss: (0.5254) |  Loss2: (0.0000) | Acc: (81.00%) (22088/27008)
Epoch: 41 | Batch_idx: 220 |  Loss: (0.5261) |  Loss2: (0.0000) | Acc: (81.00%) (23126/28288)
Epoch: 41 | Batch_idx: 230 |  Loss: (0.5254) |  Loss2: (0.0000) | Acc: (81.00%) (24189/29568)
Epoch: 41 | Batch_idx: 240 |  Loss: (0.5260) |  Loss2: (0.0000) | Acc: (81.00%) (25228/30848)
Epoch: 41 | Batch_idx: 250 |  Loss: (0.5263) |  Loss2: (0.0000) | Acc: (81.00%) (26261/32128)
Epoch: 41 | Batch_idx: 260 |  Loss: (0.5288) |  Loss2: (0.0000) | Acc: (81.00%) (27271/33408)
Epoch: 41 | Batch_idx: 270 |  Loss: (0.5286) |  Loss2: (0.0000) | Acc: (81.00%) (28327/34688)
Epoch: 41 | Batch_idx: 280 |  Loss: (0.5281) |  Loss2: (0.0000) | Acc: (81.00%) (29371/35968)
Epoch: 41 | Batch_idx: 290 |  Loss: (0.5286) |  Loss2: (0.0000) | Acc: (81.00%) (30402/37248)
Epoch: 41 | Batch_idx: 300 |  Loss: (0.5277) |  Loss2: (0.0000) | Acc: (81.00%) (31454/38528)
Epoch: 41 | Batch_idx: 310 |  Loss: (0.5274) |  Loss2: (0.0000) | Acc: (81.00%) (32513/39808)
Epoch: 41 | Batch_idx: 320 |  Loss: (0.5270) |  Loss2: (0.0000) | Acc: (81.00%) (33555/41088)
Epoch: 41 | Batch_idx: 330 |  Loss: (0.5256) |  Loss2: (0.0000) | Acc: (81.00%) (34613/42368)
Epoch: 41 | Batch_idx: 340 |  Loss: (0.5249) |  Loss2: (0.0000) | Acc: (81.00%) (35666/43648)
Epoch: 41 | Batch_idx: 350 |  Loss: (0.5240) |  Loss2: (0.0000) | Acc: (81.00%) (36749/44928)
Epoch: 41 | Batch_idx: 360 |  Loss: (0.5238) |  Loss2: (0.0000) | Acc: (81.00%) (37803/46208)
Epoch: 41 | Batch_idx: 370 |  Loss: (0.5245) |  Loss2: (0.0000) | Acc: (81.00%) (38834/47488)
Epoch: 41 | Batch_idx: 380 |  Loss: (0.5238) |  Loss2: (0.0000) | Acc: (81.00%) (39897/48768)
Epoch: 41 | Batch_idx: 390 |  Loss: (0.5235) |  Loss2: (0.0000) | Acc: (81.00%) (40900/50000)
# TEST : Loss: (0.5618) | Acc: (80.00%) (8082/10000)
percent tensor([0.4762, 0.4780, 0.4867, 0.4794, 0.4845, 0.4753, 0.4805, 0.4778, 0.4749,
        0.4814, 0.4758, 0.4851, 0.4763, 0.4760, 0.4774, 0.4761],
       device='cuda:0') torch.Size([16])
percent tensor([0.4747, 0.4525, 0.4811, 0.4834, 0.4708, 0.4854, 0.4549, 0.4764, 0.4659,
        0.4620, 0.4614, 0.4674, 0.4616, 0.4576, 0.4653, 0.4739],
       device='cuda:0') torch.Size([16])
percent tensor([0.5632, 0.5786, 0.5042, 0.4882, 0.5243, 0.5781, 0.5937, 0.5084, 0.5325,
        0.5542, 0.5640, 0.5287, 0.5602, 0.5819, 0.5804, 0.5619],
       device='cuda:0') torch.Size([16])
percent tensor([0.5906, 0.5708, 0.6088, 0.6205, 0.6070, 0.5985, 0.5905, 0.6184, 0.6001,
        0.5786, 0.5779, 0.6052, 0.5727, 0.5896, 0.5957, 0.5884],
       device='cuda:0') torch.Size([16])
percent tensor([0.5230, 0.5599, 0.5098, 0.5153, 0.5038, 0.5252, 0.5244, 0.4824, 0.5874,
        0.5612, 0.5781, 0.4981, 0.5533, 0.6299, 0.4773, 0.5374],
       device='cuda:0') torch.Size([16])
percent tensor([0.5380, 0.5347, 0.5552, 0.5711, 0.5609, 0.5558, 0.5447, 0.5558, 0.5453,
        0.5402, 0.5378, 0.5536, 0.5335, 0.5572, 0.5363, 0.5538],
       device='cuda:0') torch.Size([16])
percent tensor([0.5945, 0.5954, 0.5525, 0.5439, 0.5350, 0.5479, 0.5809, 0.5040, 0.6142,
        0.6100, 0.6253, 0.5729, 0.6469, 0.6080, 0.5326, 0.5558],
       device='cuda:0') torch.Size([16])
percent tensor([0.9381, 0.9203, 0.9326, 0.9404, 0.9225, 0.9208, 0.9176, 0.9266, 0.9541,
        0.9487, 0.9669, 0.9517, 0.9412, 0.9059, 0.9145, 0.9349],
       device='cuda:0') torch.Size([16])
Epoch: 42 | Batch_idx: 0 |  Loss: (0.3561) |  Loss2: (0.0000) | Acc: (91.00%) (117/128)
Epoch: 42 | Batch_idx: 10 |  Loss: (0.4868) |  Loss2: (0.0000) | Acc: (83.00%) (1179/1408)
Epoch: 42 | Batch_idx: 20 |  Loss: (0.5250) |  Loss2: (0.0000) | Acc: (82.00%) (2208/2688)
Epoch: 42 | Batch_idx: 30 |  Loss: (0.5122) |  Loss2: (0.0000) | Acc: (82.00%) (3287/3968)
Epoch: 42 | Batch_idx: 40 |  Loss: (0.5202) |  Loss2: (0.0000) | Acc: (82.00%) (4339/5248)
Epoch: 42 | Batch_idx: 50 |  Loss: (0.5118) |  Loss2: (0.0000) | Acc: (82.00%) (5414/6528)
Epoch: 42 | Batch_idx: 60 |  Loss: (0.5094) |  Loss2: (0.0000) | Acc: (83.00%) (6488/7808)
Epoch: 42 | Batch_idx: 70 |  Loss: (0.5046) |  Loss2: (0.0000) | Acc: (83.00%) (7563/9088)
Epoch: 42 | Batch_idx: 80 |  Loss: (0.5059) |  Loss2: (0.0000) | Acc: (83.00%) (8614/10368)
Epoch: 42 | Batch_idx: 90 |  Loss: (0.5056) |  Loss2: (0.0000) | Acc: (82.00%) (9665/11648)
Epoch: 42 | Batch_idx: 100 |  Loss: (0.5049) |  Loss2: (0.0000) | Acc: (82.00%) (10715/12928)
Epoch: 42 | Batch_idx: 110 |  Loss: (0.4996) |  Loss2: (0.0000) | Acc: (83.00%) (11801/14208)
Epoch: 42 | Batch_idx: 120 |  Loss: (0.4981) |  Loss2: (0.0000) | Acc: (83.00%) (12872/15488)
Epoch: 42 | Batch_idx: 130 |  Loss: (0.4988) |  Loss2: (0.0000) | Acc: (83.00%) (13924/16768)
Epoch: 42 | Batch_idx: 140 |  Loss: (0.4982) |  Loss2: (0.0000) | Acc: (83.00%) (14992/18048)
Epoch: 42 | Batch_idx: 150 |  Loss: (0.4974) |  Loss2: (0.0000) | Acc: (83.00%) (16047/19328)
Epoch: 42 | Batch_idx: 160 |  Loss: (0.4991) |  Loss2: (0.0000) | Acc: (82.00%) (17100/20608)
Epoch: 42 | Batch_idx: 170 |  Loss: (0.4968) |  Loss2: (0.0000) | Acc: (83.00%) (18185/21888)
Epoch: 42 | Batch_idx: 180 |  Loss: (0.4968) |  Loss2: (0.0000) | Acc: (83.00%) (19245/23168)
Epoch: 42 | Batch_idx: 190 |  Loss: (0.4982) |  Loss2: (0.0000) | Acc: (82.00%) (20289/24448)
Epoch: 42 | Batch_idx: 200 |  Loss: (0.5005) |  Loss2: (0.0000) | Acc: (82.00%) (21337/25728)
Epoch: 42 | Batch_idx: 210 |  Loss: (0.5001) |  Loss2: (0.0000) | Acc: (82.00%) (22403/27008)
Epoch: 42 | Batch_idx: 220 |  Loss: (0.5015) |  Loss2: (0.0000) | Acc: (82.00%) (23436/28288)
Epoch: 42 | Batch_idx: 230 |  Loss: (0.5026) |  Loss2: (0.0000) | Acc: (82.00%) (24482/29568)
Epoch: 42 | Batch_idx: 240 |  Loss: (0.5028) |  Loss2: (0.0000) | Acc: (82.00%) (25554/30848)
Epoch: 42 | Batch_idx: 250 |  Loss: (0.5023) |  Loss2: (0.0000) | Acc: (82.00%) (26616/32128)
Epoch: 42 | Batch_idx: 260 |  Loss: (0.5016) |  Loss2: (0.0000) | Acc: (82.00%) (27681/33408)
Epoch: 42 | Batch_idx: 270 |  Loss: (0.4998) |  Loss2: (0.0000) | Acc: (82.00%) (28767/34688)
Epoch: 42 | Batch_idx: 280 |  Loss: (0.4995) |  Loss2: (0.0000) | Acc: (82.00%) (29830/35968)
Epoch: 42 | Batch_idx: 290 |  Loss: (0.4990) |  Loss2: (0.0000) | Acc: (82.00%) (30893/37248)
Epoch: 42 | Batch_idx: 300 |  Loss: (0.4987) |  Loss2: (0.0000) | Acc: (82.00%) (31957/38528)
Epoch: 42 | Batch_idx: 310 |  Loss: (0.4977) |  Loss2: (0.0000) | Acc: (82.00%) (33023/39808)
Epoch: 42 | Batch_idx: 320 |  Loss: (0.4969) |  Loss2: (0.0000) | Acc: (82.00%) (34099/41088)
Epoch: 42 | Batch_idx: 330 |  Loss: (0.4963) |  Loss2: (0.0000) | Acc: (82.00%) (35163/42368)
Epoch: 42 | Batch_idx: 340 |  Loss: (0.4964) |  Loss2: (0.0000) | Acc: (82.00%) (36212/43648)
Epoch: 42 | Batch_idx: 350 |  Loss: (0.4961) |  Loss2: (0.0000) | Acc: (82.00%) (37277/44928)
Epoch: 42 | Batch_idx: 360 |  Loss: (0.4955) |  Loss2: (0.0000) | Acc: (82.00%) (38349/46208)
Epoch: 42 | Batch_idx: 370 |  Loss: (0.4951) |  Loss2: (0.0000) | Acc: (83.00%) (39424/47488)
Epoch: 42 | Batch_idx: 380 |  Loss: (0.4945) |  Loss2: (0.0000) | Acc: (83.00%) (40499/48768)
Epoch: 42 | Batch_idx: 390 |  Loss: (0.4946) |  Loss2: (0.0000) | Acc: (83.00%) (41517/50000)
# TEST : Loss: (0.5412) | Acc: (81.00%) (8140/10000)
percent tensor([0.4728, 0.4753, 0.4867, 0.4773, 0.4842, 0.4717, 0.4787, 0.4756, 0.4721,
        0.4797, 0.4728, 0.4845, 0.4730, 0.4726, 0.4747, 0.4726],
       device='cuda:0') torch.Size([16])
percent tensor([0.4741, 0.4517, 0.4820, 0.4836, 0.4706, 0.4857, 0.4541, 0.4768, 0.4660,
        0.4616, 0.4610, 0.4669, 0.4600, 0.4586, 0.4643, 0.4734],
       device='cuda:0') torch.Size([16])
percent tensor([0.5617, 0.5768, 0.5030, 0.4881, 0.5233, 0.5785, 0.5926, 0.5081, 0.5280,
        0.5526, 0.5614, 0.5280, 0.5582, 0.5772, 0.5810, 0.5619],
       device='cuda:0') torch.Size([16])
percent tensor([0.5932, 0.5739, 0.6133, 0.6245, 0.6104, 0.5993, 0.5937, 0.6216, 0.6047,
        0.5827, 0.5813, 0.6089, 0.5747, 0.5951, 0.5974, 0.5908],
       device='cuda:0') torch.Size([16])
percent tensor([0.5237, 0.5655, 0.5098, 0.5131, 0.5036, 0.5233, 0.5284, 0.4795, 0.5926,
        0.5650, 0.5816, 0.4964, 0.5561, 0.6416, 0.4749, 0.5398],
       device='cuda:0') torch.Size([16])
percent tensor([0.5482, 0.5451, 0.5664, 0.5830, 0.5727, 0.5660, 0.5566, 0.5664, 0.5576,
        0.5524, 0.5495, 0.5668, 0.5451, 0.5710, 0.5461, 0.5649],
       device='cuda:0') torch.Size([16])
percent tensor([0.6089, 0.6066, 0.5603, 0.5491, 0.5395, 0.5568, 0.5910, 0.5032, 0.6289,
        0.6241, 0.6407, 0.5863, 0.6652, 0.6225, 0.5362, 0.5675],
       device='cuda:0') torch.Size([16])
percent tensor([0.9561, 0.9375, 0.9502, 0.9582, 0.9420, 0.9427, 0.9385, 0.9458, 0.9677,
        0.9624, 0.9773, 0.9689, 0.9572, 0.9299, 0.9295, 0.9542],
       device='cuda:0') torch.Size([16])
Epoch: 43 | Batch_idx: 0 |  Loss: (0.5149) |  Loss2: (0.0000) | Acc: (84.00%) (108/128)
Epoch: 43 | Batch_idx: 10 |  Loss: (0.4977) |  Loss2: (0.0000) | Acc: (82.00%) (1159/1408)
Epoch: 43 | Batch_idx: 20 |  Loss: (0.4916) |  Loss2: (0.0000) | Acc: (82.00%) (2229/2688)
Epoch: 43 | Batch_idx: 30 |  Loss: (0.4749) |  Loss2: (0.0000) | Acc: (83.00%) (3330/3968)
Epoch: 43 | Batch_idx: 40 |  Loss: (0.4781) |  Loss2: (0.0000) | Acc: (83.00%) (4387/5248)
Epoch: 43 | Batch_idx: 50 |  Loss: (0.4802) |  Loss2: (0.0000) | Acc: (83.00%) (5455/6528)
Epoch: 43 | Batch_idx: 60 |  Loss: (0.4867) |  Loss2: (0.0000) | Acc: (83.00%) (6501/7808)
Epoch: 43 | Batch_idx: 70 |  Loss: (0.4910) |  Loss2: (0.0000) | Acc: (83.00%) (7556/9088)
Epoch: 43 | Batch_idx: 80 |  Loss: (0.4871) |  Loss2: (0.0000) | Acc: (83.00%) (8635/10368)
Epoch: 43 | Batch_idx: 90 |  Loss: (0.4907) |  Loss2: (0.0000) | Acc: (83.00%) (9693/11648)
Epoch: 43 | Batch_idx: 100 |  Loss: (0.4907) |  Loss2: (0.0000) | Acc: (83.00%) (10763/12928)
Epoch: 43 | Batch_idx: 110 |  Loss: (0.4909) |  Loss2: (0.0000) | Acc: (83.00%) (11847/14208)
Epoch: 43 | Batch_idx: 120 |  Loss: (0.4923) |  Loss2: (0.0000) | Acc: (83.00%) (12914/15488)
Epoch: 43 | Batch_idx: 130 |  Loss: (0.4913) |  Loss2: (0.0000) | Acc: (83.00%) (13978/16768)
Epoch: 43 | Batch_idx: 140 |  Loss: (0.4910) |  Loss2: (0.0000) | Acc: (83.00%) (15040/18048)
Epoch: 43 | Batch_idx: 150 |  Loss: (0.4881) |  Loss2: (0.0000) | Acc: (83.00%) (16111/19328)
Epoch: 43 | Batch_idx: 160 |  Loss: (0.4872) |  Loss2: (0.0000) | Acc: (83.00%) (17180/20608)
Epoch: 43 | Batch_idx: 170 |  Loss: (0.4861) |  Loss2: (0.0000) | Acc: (83.00%) (18255/21888)
Epoch: 43 | Batch_idx: 180 |  Loss: (0.4845) |  Loss2: (0.0000) | Acc: (83.00%) (19333/23168)
Epoch: 43 | Batch_idx: 190 |  Loss: (0.4839) |  Loss2: (0.0000) | Acc: (83.00%) (20412/24448)
Epoch: 43 | Batch_idx: 200 |  Loss: (0.4847) |  Loss2: (0.0000) | Acc: (83.00%) (21461/25728)
Epoch: 43 | Batch_idx: 210 |  Loss: (0.4842) |  Loss2: (0.0000) | Acc: (83.00%) (22525/27008)
Epoch: 43 | Batch_idx: 220 |  Loss: (0.4850) |  Loss2: (0.0000) | Acc: (83.00%) (23583/28288)
Epoch: 43 | Batch_idx: 230 |  Loss: (0.4864) |  Loss2: (0.0000) | Acc: (83.00%) (24639/29568)
Epoch: 43 | Batch_idx: 240 |  Loss: (0.4853) |  Loss2: (0.0000) | Acc: (83.00%) (25709/30848)
Epoch: 43 | Batch_idx: 250 |  Loss: (0.4850) |  Loss2: (0.0000) | Acc: (83.00%) (26785/32128)
Epoch: 43 | Batch_idx: 260 |  Loss: (0.4840) |  Loss2: (0.0000) | Acc: (83.00%) (27868/33408)
Epoch: 43 | Batch_idx: 270 |  Loss: (0.4837) |  Loss2: (0.0000) | Acc: (83.00%) (28929/34688)
Epoch: 43 | Batch_idx: 280 |  Loss: (0.4827) |  Loss2: (0.0000) | Acc: (83.00%) (30000/35968)
Epoch: 43 | Batch_idx: 290 |  Loss: (0.4826) |  Loss2: (0.0000) | Acc: (83.00%) (31082/37248)
Epoch: 43 | Batch_idx: 300 |  Loss: (0.4814) |  Loss2: (0.0000) | Acc: (83.00%) (32161/38528)
Epoch: 43 | Batch_idx: 310 |  Loss: (0.4814) |  Loss2: (0.0000) | Acc: (83.00%) (33224/39808)
Epoch: 43 | Batch_idx: 320 |  Loss: (0.4819) |  Loss2: (0.0000) | Acc: (83.00%) (34285/41088)
Epoch: 43 | Batch_idx: 330 |  Loss: (0.4832) |  Loss2: (0.0000) | Acc: (83.00%) (35341/42368)
Epoch: 43 | Batch_idx: 340 |  Loss: (0.4818) |  Loss2: (0.0000) | Acc: (83.00%) (36436/43648)
Epoch: 43 | Batch_idx: 350 |  Loss: (0.4817) |  Loss2: (0.0000) | Acc: (83.00%) (37503/44928)
Epoch: 43 | Batch_idx: 360 |  Loss: (0.4812) |  Loss2: (0.0000) | Acc: (83.00%) (38564/46208)
Epoch: 43 | Batch_idx: 370 |  Loss: (0.4815) |  Loss2: (0.0000) | Acc: (83.00%) (39626/47488)
Epoch: 43 | Batch_idx: 380 |  Loss: (0.4808) |  Loss2: (0.0000) | Acc: (83.00%) (40694/48768)
Epoch: 43 | Batch_idx: 390 |  Loss: (0.4807) |  Loss2: (0.0000) | Acc: (83.00%) (41733/50000)
# TEST : Loss: (0.5306) | Acc: (81.00%) (8189/10000)
percent tensor([0.4725, 0.4760, 0.4890, 0.4776, 0.4864, 0.4711, 0.4801, 0.4763, 0.4726,
        0.4808, 0.4731, 0.4866, 0.4730, 0.4727, 0.4753, 0.4721],
       device='cuda:0') torch.Size([16])
percent tensor([0.4722, 0.4505, 0.4809, 0.4815, 0.4680, 0.4844, 0.4524, 0.4746, 0.4645,
        0.4605, 0.4599, 0.4650, 0.4579, 0.4583, 0.4620, 0.4718],
       device='cuda:0') torch.Size([16])
percent tensor([0.5604, 0.5763, 0.5023, 0.4875, 0.5215, 0.5786, 0.5918, 0.5080, 0.5248,
        0.5515, 0.5592, 0.5274, 0.5564, 0.5746, 0.5815, 0.5617],
       device='cuda:0') torch.Size([16])
percent tensor([0.5930, 0.5754, 0.6142, 0.6237, 0.6103, 0.5979, 0.5943, 0.6203, 0.6054,
        0.5844, 0.5827, 0.6090, 0.5752, 0.5973, 0.5966, 0.5911],
       device='cuda:0') torch.Size([16])
percent tensor([0.5207, 0.5705, 0.5027, 0.5042, 0.4959, 0.5135, 0.5299, 0.4716, 0.5914,
        0.5692, 0.5837, 0.4939, 0.5584, 0.6448, 0.4707, 0.5369],
       device='cuda:0') torch.Size([16])
percent tensor([0.5549, 0.5529, 0.5755, 0.5923, 0.5822, 0.5736, 0.5655, 0.5744, 0.5673,
        0.5617, 0.5588, 0.5763, 0.5538, 0.5816, 0.5526, 0.5726],
       device='cuda:0') torch.Size([16])
percent tensor([0.6144, 0.6112, 0.5684, 0.5563, 0.5458, 0.5639, 0.5963, 0.5041, 0.6372,
        0.6306, 0.6514, 0.5981, 0.6752, 0.6322, 0.5382, 0.5737],
       device='cuda:0') torch.Size([16])
percent tensor([0.9670, 0.9513, 0.9614, 0.9693, 0.9554, 0.9546, 0.9532, 0.9573, 0.9770,
        0.9727, 0.9849, 0.9787, 0.9680, 0.9471, 0.9417, 0.9652],
       device='cuda:0') torch.Size([16])
Epoch: 44 | Batch_idx: 0 |  Loss: (0.4778) |  Loss2: (0.0000) | Acc: (85.00%) (109/128)
Epoch: 44 | Batch_idx: 10 |  Loss: (0.4580) |  Loss2: (0.0000) | Acc: (84.00%) (1186/1408)
Epoch: 44 | Batch_idx: 20 |  Loss: (0.4574) |  Loss2: (0.0000) | Acc: (84.00%) (2264/2688)
Epoch: 44 | Batch_idx: 30 |  Loss: (0.4606) |  Loss2: (0.0000) | Acc: (84.00%) (3338/3968)
Epoch: 44 | Batch_idx: 40 |  Loss: (0.4628) |  Loss2: (0.0000) | Acc: (83.00%) (4407/5248)
Epoch: 44 | Batch_idx: 50 |  Loss: (0.4626) |  Loss2: (0.0000) | Acc: (84.00%) (5484/6528)
Epoch: 44 | Batch_idx: 60 |  Loss: (0.4584) |  Loss2: (0.0000) | Acc: (84.00%) (6567/7808)
Epoch: 44 | Batch_idx: 70 |  Loss: (0.4562) |  Loss2: (0.0000) | Acc: (84.00%) (7654/9088)
Epoch: 44 | Batch_idx: 80 |  Loss: (0.4565) |  Loss2: (0.0000) | Acc: (84.00%) (8734/10368)
Epoch: 44 | Batch_idx: 90 |  Loss: (0.4553) |  Loss2: (0.0000) | Acc: (84.00%) (9808/11648)
Epoch: 44 | Batch_idx: 100 |  Loss: (0.4568) |  Loss2: (0.0000) | Acc: (84.00%) (10870/12928)
Epoch: 44 | Batch_idx: 110 |  Loss: (0.4542) |  Loss2: (0.0000) | Acc: (84.00%) (11961/14208)
Epoch: 44 | Batch_idx: 120 |  Loss: (0.4532) |  Loss2: (0.0000) | Acc: (84.00%) (13059/15488)
Epoch: 44 | Batch_idx: 130 |  Loss: (0.4537) |  Loss2: (0.0000) | Acc: (84.00%) (14127/16768)
Epoch: 44 | Batch_idx: 140 |  Loss: (0.4547) |  Loss2: (0.0000) | Acc: (84.00%) (15203/18048)
Epoch: 44 | Batch_idx: 150 |  Loss: (0.4565) |  Loss2: (0.0000) | Acc: (84.00%) (16273/19328)
Epoch: 44 | Batch_idx: 160 |  Loss: (0.4556) |  Loss2: (0.0000) | Acc: (84.00%) (17368/20608)
Epoch: 44 | Batch_idx: 170 |  Loss: (0.4572) |  Loss2: (0.0000) | Acc: (84.00%) (18442/21888)
Epoch: 44 | Batch_idx: 180 |  Loss: (0.4575) |  Loss2: (0.0000) | Acc: (84.00%) (19516/23168)
Epoch: 44 | Batch_idx: 190 |  Loss: (0.4614) |  Loss2: (0.0000) | Acc: (84.00%) (20565/24448)
Epoch: 44 | Batch_idx: 200 |  Loss: (0.4624) |  Loss2: (0.0000) | Acc: (84.00%) (21632/25728)
Epoch: 44 | Batch_idx: 210 |  Loss: (0.4632) |  Loss2: (0.0000) | Acc: (84.00%) (22700/27008)
Epoch: 44 | Batch_idx: 220 |  Loss: (0.4632) |  Loss2: (0.0000) | Acc: (84.00%) (23791/28288)
Epoch: 44 | Batch_idx: 230 |  Loss: (0.4661) |  Loss2: (0.0000) | Acc: (84.00%) (24840/29568)
Epoch: 44 | Batch_idx: 240 |  Loss: (0.4674) |  Loss2: (0.0000) | Acc: (83.00%) (25898/30848)
Epoch: 44 | Batch_idx: 250 |  Loss: (0.4686) |  Loss2: (0.0000) | Acc: (83.00%) (26965/32128)
Epoch: 44 | Batch_idx: 260 |  Loss: (0.4686) |  Loss2: (0.0000) | Acc: (83.00%) (28034/33408)
Epoch: 44 | Batch_idx: 270 |  Loss: (0.4691) |  Loss2: (0.0000) | Acc: (83.00%) (29095/34688)
Epoch: 44 | Batch_idx: 280 |  Loss: (0.4681) |  Loss2: (0.0000) | Acc: (83.00%) (30179/35968)
Epoch: 44 | Batch_idx: 290 |  Loss: (0.4683) |  Loss2: (0.0000) | Acc: (83.00%) (31246/37248)
Epoch: 44 | Batch_idx: 300 |  Loss: (0.4688) |  Loss2: (0.0000) | Acc: (83.00%) (32324/38528)
Epoch: 44 | Batch_idx: 310 |  Loss: (0.4677) |  Loss2: (0.0000) | Acc: (83.00%) (33409/39808)
Epoch: 44 | Batch_idx: 320 |  Loss: (0.4670) |  Loss2: (0.0000) | Acc: (83.00%) (34502/41088)
Epoch: 44 | Batch_idx: 330 |  Loss: (0.4665) |  Loss2: (0.0000) | Acc: (83.00%) (35575/42368)
Epoch: 44 | Batch_idx: 340 |  Loss: (0.4665) |  Loss2: (0.0000) | Acc: (83.00%) (36655/43648)
Epoch: 44 | Batch_idx: 350 |  Loss: (0.4670) |  Loss2: (0.0000) | Acc: (83.00%) (37732/44928)
Epoch: 44 | Batch_idx: 360 |  Loss: (0.4659) |  Loss2: (0.0000) | Acc: (84.00%) (38826/46208)
Epoch: 44 | Batch_idx: 370 |  Loss: (0.4667) |  Loss2: (0.0000) | Acc: (83.00%) (39884/47488)
Epoch: 44 | Batch_idx: 380 |  Loss: (0.4678) |  Loss2: (0.0000) | Acc: (83.00%) (40931/48768)
Epoch: 44 | Batch_idx: 390 |  Loss: (0.4676) |  Loss2: (0.0000) | Acc: (83.00%) (41945/50000)
# TEST : Loss: (0.5241) | Acc: (82.00%) (8214/10000)
percent tensor([0.4739, 0.4781, 0.4919, 0.4794, 0.4894, 0.4728, 0.4826, 0.4784, 0.4743,
        0.4830, 0.4749, 0.4893, 0.4745, 0.4742, 0.4773, 0.4736],
       device='cuda:0') torch.Size([16])
percent tensor([0.4711, 0.4496, 0.4808, 0.4802, 0.4668, 0.4841, 0.4511, 0.4734, 0.4640,
        0.4598, 0.4593, 0.4638, 0.4565, 0.4580, 0.4605, 0.4708],
       device='cuda:0') torch.Size([16])
percent tensor([0.5594, 0.5718, 0.5049, 0.4906, 0.5242, 0.5773, 0.5902, 0.5110, 0.5205,
        0.5487, 0.5547, 0.5286, 0.5529, 0.5680, 0.5804, 0.5607],
       device='cuda:0') torch.Size([16])
percent tensor([0.5949, 0.5777, 0.6157, 0.6249, 0.6122, 0.5998, 0.5966, 0.6216, 0.6079,
        0.5865, 0.5848, 0.6103, 0.5769, 0.5996, 0.5989, 0.5937],
       device='cuda:0') torch.Size([16])
percent tensor([0.5261, 0.5760, 0.5096, 0.5106, 0.5054, 0.5145, 0.5383, 0.4829, 0.5944,
        0.5763, 0.5878, 0.5002, 0.5616, 0.6505, 0.4765, 0.5442],
       device='cuda:0') torch.Size([16])
percent tensor([0.5661, 0.5641, 0.5882, 0.6053, 0.5962, 0.5847, 0.5787, 0.5870, 0.5800,
        0.5749, 0.5711, 0.5894, 0.5656, 0.5955, 0.5633, 0.5852],
       device='cuda:0') torch.Size([16])
percent tensor([0.6241, 0.6198, 0.5805, 0.5689, 0.5574, 0.5736, 0.6072, 0.5097, 0.6463,
        0.6419, 0.6614, 0.6137, 0.6841, 0.6445, 0.5447, 0.5852],
       device='cuda:0') torch.Size([16])
percent tensor([0.9756, 0.9616, 0.9700, 0.9774, 0.9653, 0.9649, 0.9635, 0.9675, 0.9823,
        0.9795, 0.9890, 0.9848, 0.9748, 0.9603, 0.9529, 0.9749],
       device='cuda:0') torch.Size([16])
Epoch: 45 | Batch_idx: 0 |  Loss: (0.4753) |  Loss2: (0.0000) | Acc: (85.00%) (109/128)
Epoch: 45 | Batch_idx: 10 |  Loss: (0.4694) |  Loss2: (0.0000) | Acc: (84.00%) (1185/1408)
Epoch: 45 | Batch_idx: 20 |  Loss: (0.4710) |  Loss2: (0.0000) | Acc: (83.00%) (2256/2688)
Epoch: 45 | Batch_idx: 30 |  Loss: (0.4568) |  Loss2: (0.0000) | Acc: (84.00%) (3347/3968)
Epoch: 45 | Batch_idx: 40 |  Loss: (0.4602) |  Loss2: (0.0000) | Acc: (84.00%) (4412/5248)
Epoch: 45 | Batch_idx: 50 |  Loss: (0.4676) |  Loss2: (0.0000) | Acc: (83.00%) (5469/6528)
Epoch: 45 | Batch_idx: 60 |  Loss: (0.4815) |  Loss2: (0.0000) | Acc: (83.00%) (6490/7808)
Epoch: 45 | Batch_idx: 70 |  Loss: (0.4776) |  Loss2: (0.0000) | Acc: (83.00%) (7579/9088)
Epoch: 45 | Batch_idx: 80 |  Loss: (0.4705) |  Loss2: (0.0000) | Acc: (83.00%) (8677/10368)
Epoch: 45 | Batch_idx: 90 |  Loss: (0.4686) |  Loss2: (0.0000) | Acc: (83.00%) (9757/11648)
Epoch: 45 | Batch_idx: 100 |  Loss: (0.4698) |  Loss2: (0.0000) | Acc: (83.00%) (10820/12928)
Epoch: 45 | Batch_idx: 110 |  Loss: (0.4694) |  Loss2: (0.0000) | Acc: (83.00%) (11898/14208)
Epoch: 45 | Batch_idx: 120 |  Loss: (0.4699) |  Loss2: (0.0000) | Acc: (83.00%) (12963/15488)
Epoch: 45 | Batch_idx: 130 |  Loss: (0.4714) |  Loss2: (0.0000) | Acc: (83.00%) (14016/16768)
Epoch: 45 | Batch_idx: 140 |  Loss: (0.4688) |  Loss2: (0.0000) | Acc: (83.00%) (15093/18048)
Epoch: 45 | Batch_idx: 150 |  Loss: (0.4694) |  Loss2: (0.0000) | Acc: (83.00%) (16147/19328)
Epoch: 45 | Batch_idx: 160 |  Loss: (0.4677) |  Loss2: (0.0000) | Acc: (83.00%) (17243/20608)
Epoch: 45 | Batch_idx: 170 |  Loss: (0.4674) |  Loss2: (0.0000) | Acc: (83.00%) (18326/21888)
Epoch: 45 | Batch_idx: 180 |  Loss: (0.4666) |  Loss2: (0.0000) | Acc: (83.00%) (19405/23168)
Epoch: 45 | Batch_idx: 190 |  Loss: (0.4671) |  Loss2: (0.0000) | Acc: (83.00%) (20492/24448)
Epoch: 45 | Batch_idx: 200 |  Loss: (0.4672) |  Loss2: (0.0000) | Acc: (83.00%) (21548/25728)
Epoch: 45 | Batch_idx: 210 |  Loss: (0.4665) |  Loss2: (0.0000) | Acc: (83.00%) (22621/27008)
Epoch: 45 | Batch_idx: 220 |  Loss: (0.4681) |  Loss2: (0.0000) | Acc: (83.00%) (23687/28288)
Epoch: 45 | Batch_idx: 230 |  Loss: (0.4699) |  Loss2: (0.0000) | Acc: (83.00%) (24735/29568)
Epoch: 45 | Batch_idx: 240 |  Loss: (0.4697) |  Loss2: (0.0000) | Acc: (83.00%) (25821/30848)
Epoch: 45 | Batch_idx: 250 |  Loss: (0.4680) |  Loss2: (0.0000) | Acc: (83.00%) (26916/32128)
Epoch: 45 | Batch_idx: 260 |  Loss: (0.4685) |  Loss2: (0.0000) | Acc: (83.00%) (27994/33408)
Epoch: 45 | Batch_idx: 270 |  Loss: (0.4683) |  Loss2: (0.0000) | Acc: (83.00%) (29066/34688)
Epoch: 45 | Batch_idx: 280 |  Loss: (0.4691) |  Loss2: (0.0000) | Acc: (83.00%) (30123/35968)
Epoch: 45 | Batch_idx: 290 |  Loss: (0.4695) |  Loss2: (0.0000) | Acc: (83.00%) (31183/37248)
Epoch: 45 | Batch_idx: 300 |  Loss: (0.4697) |  Loss2: (0.0000) | Acc: (83.00%) (32245/38528)
Epoch: 45 | Batch_idx: 310 |  Loss: (0.4682) |  Loss2: (0.0000) | Acc: (83.00%) (33346/39808)
Epoch: 45 | Batch_idx: 320 |  Loss: (0.4683) |  Loss2: (0.0000) | Acc: (83.00%) (34409/41088)
Epoch: 45 | Batch_idx: 330 |  Loss: (0.4693) |  Loss2: (0.0000) | Acc: (83.00%) (35466/42368)
Epoch: 45 | Batch_idx: 340 |  Loss: (0.4691) |  Loss2: (0.0000) | Acc: (83.00%) (36545/43648)
Epoch: 45 | Batch_idx: 350 |  Loss: (0.4690) |  Loss2: (0.0000) | Acc: (83.00%) (37617/44928)
Epoch: 45 | Batch_idx: 360 |  Loss: (0.4682) |  Loss2: (0.0000) | Acc: (83.00%) (38711/46208)
Epoch: 45 | Batch_idx: 370 |  Loss: (0.4673) |  Loss2: (0.0000) | Acc: (83.00%) (39784/47488)
Epoch: 45 | Batch_idx: 380 |  Loss: (0.4672) |  Loss2: (0.0000) | Acc: (83.00%) (40855/48768)
Epoch: 45 | Batch_idx: 390 |  Loss: (0.4667) |  Loss2: (0.0000) | Acc: (83.00%) (41911/50000)
=> saving checkpoint 'drive/app/torch/save_Schedule/checkpoint_045.pth.tar'
# TEST : Loss: (0.5210) | Acc: (82.00%) (8208/10000)
percent tensor([0.4737, 0.4782, 0.4935, 0.4793, 0.4909, 0.4729, 0.4832, 0.4787, 0.4744,
        0.4835, 0.4750, 0.4905, 0.4743, 0.4738, 0.4775, 0.4733],
       device='cuda:0') torch.Size([16])
percent tensor([0.4703, 0.4498, 0.4804, 0.4781, 0.4652, 0.4838, 0.4507, 0.4721, 0.4640,
        0.4597, 0.4598, 0.4627, 0.4557, 0.4590, 0.4594, 0.4702],
       device='cuda:0') torch.Size([16])
percent tensor([0.5593, 0.5700, 0.5064, 0.4917, 0.5240, 0.5782, 0.5885, 0.5124, 0.5190,
        0.5470, 0.5522, 0.5283, 0.5514, 0.5655, 0.5796, 0.5608],
       device='cuda:0') torch.Size([16])
percent tensor([0.5973, 0.5805, 0.6168, 0.6251, 0.6129, 0.6014, 0.5988, 0.6221, 0.6103,
        0.5890, 0.5877, 0.6118, 0.5800, 0.6025, 0.6006, 0.5963],
       device='cuda:0') torch.Size([16])
percent tensor([0.5158, 0.5679, 0.4971, 0.4989, 0.4942, 0.5058, 0.5287, 0.4732, 0.5827,
        0.5673, 0.5772, 0.4871, 0.5521, 0.6420, 0.4677, 0.5349],
       device='cuda:0') torch.Size([16])
percent tensor([0.5732, 0.5716, 0.5966, 0.6145, 0.6052, 0.5925, 0.5874, 0.5957, 0.5890,
        0.5840, 0.5799, 0.5984, 0.5738, 0.6058, 0.5705, 0.5936],
       device='cuda:0') torch.Size([16])
percent tensor([0.6270, 0.6216, 0.5901, 0.5790, 0.5665, 0.5783, 0.6117, 0.5159, 0.6494,
        0.6468, 0.6665, 0.6249, 0.6868, 0.6502, 0.5477, 0.5924],
       device='cuda:0') torch.Size([16])
percent tensor([0.9785, 0.9666, 0.9749, 0.9812, 0.9715, 0.9698, 0.9683, 0.9724, 0.9850,
        0.9826, 0.9912, 0.9880, 0.9786, 0.9667, 0.9583, 0.9786],
       device='cuda:0') torch.Size([16])
Epoch: 46 | Batch_idx: 0 |  Loss: (0.4679) |  Loss2: (0.0000) | Acc: (84.00%) (108/128)
Epoch: 46 | Batch_idx: 10 |  Loss: (0.4523) |  Loss2: (0.0000) | Acc: (83.00%) (1173/1408)
Epoch: 46 | Batch_idx: 20 |  Loss: (0.4646) |  Loss2: (0.0000) | Acc: (83.00%) (2244/2688)
Epoch: 46 | Batch_idx: 30 |  Loss: (0.4668) |  Loss2: (0.0000) | Acc: (83.00%) (3315/3968)
Epoch: 46 | Batch_idx: 40 |  Loss: (0.4705) |  Loss2: (0.0000) | Acc: (83.00%) (4388/5248)
Epoch: 46 | Batch_idx: 50 |  Loss: (0.4736) |  Loss2: (0.0000) | Acc: (83.00%) (5449/6528)
Epoch: 46 | Batch_idx: 60 |  Loss: (0.4700) |  Loss2: (0.0000) | Acc: (83.00%) (6541/7808)
Epoch: 46 | Batch_idx: 70 |  Loss: (0.4719) |  Loss2: (0.0000) | Acc: (83.00%) (7617/9088)
Epoch: 46 | Batch_idx: 80 |  Loss: (0.4733) |  Loss2: (0.0000) | Acc: (83.00%) (8685/10368)
Epoch: 46 | Batch_idx: 90 |  Loss: (0.4738) |  Loss2: (0.0000) | Acc: (83.00%) (9749/11648)
Epoch: 46 | Batch_idx: 100 |  Loss: (0.4744) |  Loss2: (0.0000) | Acc: (83.00%) (10814/12928)
Epoch: 46 | Batch_idx: 110 |  Loss: (0.4721) |  Loss2: (0.0000) | Acc: (83.00%) (11884/14208)
Epoch: 46 | Batch_idx: 120 |  Loss: (0.4736) |  Loss2: (0.0000) | Acc: (83.00%) (12938/15488)
Epoch: 46 | Batch_idx: 130 |  Loss: (0.4712) |  Loss2: (0.0000) | Acc: (83.00%) (14019/16768)
Epoch: 46 | Batch_idx: 140 |  Loss: (0.4706) |  Loss2: (0.0000) | Acc: (83.00%) (15086/18048)
Epoch: 46 | Batch_idx: 150 |  Loss: (0.4658) |  Loss2: (0.0000) | Acc: (83.00%) (16195/19328)
Epoch: 46 | Batch_idx: 160 |  Loss: (0.4643) |  Loss2: (0.0000) | Acc: (83.00%) (17281/20608)
Epoch: 46 | Batch_idx: 170 |  Loss: (0.4636) |  Loss2: (0.0000) | Acc: (83.00%) (18352/21888)
Epoch: 46 | Batch_idx: 180 |  Loss: (0.4630) |  Loss2: (0.0000) | Acc: (83.00%) (19427/23168)
Epoch: 46 | Batch_idx: 190 |  Loss: (0.4615) |  Loss2: (0.0000) | Acc: (83.00%) (20517/24448)
Epoch: 46 | Batch_idx: 200 |  Loss: (0.4610) |  Loss2: (0.0000) | Acc: (83.00%) (21580/25728)
Epoch: 46 | Batch_idx: 210 |  Loss: (0.4605) |  Loss2: (0.0000) | Acc: (83.00%) (22662/27008)
Epoch: 46 | Batch_idx: 220 |  Loss: (0.4617) |  Loss2: (0.0000) | Acc: (83.00%) (23724/28288)
Epoch: 46 | Batch_idx: 230 |  Loss: (0.4613) |  Loss2: (0.0000) | Acc: (83.00%) (24788/29568)
Epoch: 46 | Batch_idx: 240 |  Loss: (0.4603) |  Loss2: (0.0000) | Acc: (83.00%) (25866/30848)
Epoch: 46 | Batch_idx: 250 |  Loss: (0.4592) |  Loss2: (0.0000) | Acc: (83.00%) (26943/32128)
Epoch: 46 | Batch_idx: 260 |  Loss: (0.4607) |  Loss2: (0.0000) | Acc: (83.00%) (28001/33408)
Epoch: 46 | Batch_idx: 270 |  Loss: (0.4615) |  Loss2: (0.0000) | Acc: (83.00%) (29075/34688)
Epoch: 46 | Batch_idx: 280 |  Loss: (0.4614) |  Loss2: (0.0000) | Acc: (83.00%) (30168/35968)
Epoch: 46 | Batch_idx: 290 |  Loss: (0.4610) |  Loss2: (0.0000) | Acc: (83.00%) (31256/37248)
Epoch: 46 | Batch_idx: 300 |  Loss: (0.4607) |  Loss2: (0.0000) | Acc: (83.00%) (32339/38528)
Epoch: 46 | Batch_idx: 310 |  Loss: (0.4608) |  Loss2: (0.0000) | Acc: (83.00%) (33418/39808)
Epoch: 46 | Batch_idx: 320 |  Loss: (0.4601) |  Loss2: (0.0000) | Acc: (83.00%) (34497/41088)
Epoch: 46 | Batch_idx: 330 |  Loss: (0.4590) |  Loss2: (0.0000) | Acc: (83.00%) (35584/42368)
Epoch: 46 | Batch_idx: 340 |  Loss: (0.4603) |  Loss2: (0.0000) | Acc: (83.00%) (36644/43648)
Epoch: 46 | Batch_idx: 350 |  Loss: (0.4607) |  Loss2: (0.0000) | Acc: (83.00%) (37721/44928)
Epoch: 46 | Batch_idx: 360 |  Loss: (0.4596) |  Loss2: (0.0000) | Acc: (83.00%) (38811/46208)
Epoch: 46 | Batch_idx: 370 |  Loss: (0.4595) |  Loss2: (0.0000) | Acc: (84.00%) (39891/47488)
Epoch: 46 | Batch_idx: 380 |  Loss: (0.4607) |  Loss2: (0.0000) | Acc: (83.00%) (40956/48768)
Epoch: 46 | Batch_idx: 390 |  Loss: (0.4600) |  Loss2: (0.0000) | Acc: (84.00%) (42006/50000)
# TEST : Loss: (0.5175) | Acc: (82.00%) (8227/10000)
percent tensor([0.4741, 0.4795, 0.4944, 0.4794, 0.4920, 0.4735, 0.4846, 0.4793, 0.4753,
        0.4846, 0.4760, 0.4915, 0.4749, 0.4750, 0.4785, 0.4738],
       device='cuda:0') torch.Size([16])
percent tensor([0.4684, 0.4484, 0.4791, 0.4756, 0.4628, 0.4829, 0.4488, 0.4701, 0.4626,
        0.4583, 0.4586, 0.4605, 0.4536, 0.4582, 0.4574, 0.4687],
       device='cuda:0') torch.Size([16])
percent tensor([0.5559, 0.5691, 0.5045, 0.4905, 0.5209, 0.5755, 0.5859, 0.5107, 0.5160,
        0.5454, 0.5492, 0.5269, 0.5484, 0.5636, 0.5772, 0.5580],
       device='cuda:0') torch.Size([16])
percent tensor([0.6001, 0.5833, 0.6196, 0.6277, 0.6154, 0.6030, 0.6016, 0.6247, 0.6135,
        0.5923, 0.5909, 0.6146, 0.5830, 0.6053, 0.6034, 0.5991],
       device='cuda:0') torch.Size([16])
percent tensor([0.5175, 0.5697, 0.4997, 0.5011, 0.4966, 0.5044, 0.5300, 0.4764, 0.5833,
        0.5700, 0.5795, 0.4918, 0.5546, 0.6420, 0.4704, 0.5356],
       device='cuda:0') torch.Size([16])
percent tensor([0.5734, 0.5731, 0.5977, 0.6161, 0.6059, 0.5938, 0.5893, 0.5954, 0.5918,
        0.5865, 0.5825, 0.6003, 0.5757, 0.6099, 0.5702, 0.5939],
       device='cuda:0') torch.Size([16])
percent tensor([0.6318, 0.6259, 0.5941, 0.5822, 0.5707, 0.5802, 0.6167, 0.5171, 0.6506,
        0.6520, 0.6687, 0.6315, 0.6874, 0.6511, 0.5503, 0.5975],
       device='cuda:0') torch.Size([16])
percent tensor([0.9837, 0.9728, 0.9788, 0.9850, 0.9756, 0.9749, 0.9747, 0.9767, 0.9885,
        0.9868, 0.9934, 0.9909, 0.9830, 0.9732, 0.9660, 0.9831],
       device='cuda:0') torch.Size([16])
Epoch: 47 | Batch_idx: 0 |  Loss: (0.5079) |  Loss2: (0.0000) | Acc: (82.00%) (106/128)
Epoch: 47 | Batch_idx: 10 |  Loss: (0.4584) |  Loss2: (0.0000) | Acc: (84.00%) (1184/1408)
Epoch: 47 | Batch_idx: 20 |  Loss: (0.4614) |  Loss2: (0.0000) | Acc: (84.00%) (2266/2688)
Epoch: 47 | Batch_idx: 30 |  Loss: (0.4796) |  Loss2: (0.0000) | Acc: (83.00%) (3314/3968)
Epoch: 47 | Batch_idx: 40 |  Loss: (0.4805) |  Loss2: (0.0000) | Acc: (83.00%) (4378/5248)
Epoch: 47 | Batch_idx: 50 |  Loss: (0.4669) |  Loss2: (0.0000) | Acc: (83.00%) (5478/6528)
Epoch: 47 | Batch_idx: 60 |  Loss: (0.4646) |  Loss2: (0.0000) | Acc: (83.00%) (6538/7808)
Epoch: 47 | Batch_idx: 70 |  Loss: (0.4607) |  Loss2: (0.0000) | Acc: (83.00%) (7627/9088)
Epoch: 47 | Batch_idx: 80 |  Loss: (0.4630) |  Loss2: (0.0000) | Acc: (83.00%) (8690/10368)
Epoch: 47 | Batch_idx: 90 |  Loss: (0.4611) |  Loss2: (0.0000) | Acc: (83.00%) (9767/11648)
Epoch: 47 | Batch_idx: 100 |  Loss: (0.4620) |  Loss2: (0.0000) | Acc: (83.00%) (10841/12928)
Epoch: 47 | Batch_idx: 110 |  Loss: (0.4607) |  Loss2: (0.0000) | Acc: (83.00%) (11925/14208)
Epoch: 47 | Batch_idx: 120 |  Loss: (0.4589) |  Loss2: (0.0000) | Acc: (84.00%) (13022/15488)
Epoch: 47 | Batch_idx: 130 |  Loss: (0.4583) |  Loss2: (0.0000) | Acc: (84.00%) (14093/16768)
Epoch: 47 | Batch_idx: 140 |  Loss: (0.4580) |  Loss2: (0.0000) | Acc: (84.00%) (15175/18048)
Epoch: 47 | Batch_idx: 150 |  Loss: (0.4634) |  Loss2: (0.0000) | Acc: (83.00%) (16214/19328)
Epoch: 47 | Batch_idx: 160 |  Loss: (0.4619) |  Loss2: (0.0000) | Acc: (84.00%) (17316/20608)
Epoch: 47 | Batch_idx: 170 |  Loss: (0.4603) |  Loss2: (0.0000) | Acc: (84.00%) (18410/21888)
Epoch: 47 | Batch_idx: 180 |  Loss: (0.4599) |  Loss2: (0.0000) | Acc: (84.00%) (19488/23168)
Epoch: 47 | Batch_idx: 190 |  Loss: (0.4583) |  Loss2: (0.0000) | Acc: (84.00%) (20562/24448)
Epoch: 47 | Batch_idx: 200 |  Loss: (0.4582) |  Loss2: (0.0000) | Acc: (84.00%) (21640/25728)
Epoch: 47 | Batch_idx: 210 |  Loss: (0.4586) |  Loss2: (0.0000) | Acc: (84.00%) (22708/27008)
Epoch: 47 | Batch_idx: 220 |  Loss: (0.4581) |  Loss2: (0.0000) | Acc: (84.00%) (23796/28288)
Epoch: 47 | Batch_idx: 230 |  Loss: (0.4588) |  Loss2: (0.0000) | Acc: (84.00%) (24858/29568)
Epoch: 47 | Batch_idx: 240 |  Loss: (0.4614) |  Loss2: (0.0000) | Acc: (84.00%) (25921/30848)
Epoch: 47 | Batch_idx: 250 |  Loss: (0.4611) |  Loss2: (0.0000) | Acc: (84.00%) (27006/32128)
Epoch: 47 | Batch_idx: 260 |  Loss: (0.4600) |  Loss2: (0.0000) | Acc: (84.00%) (28100/33408)
Epoch: 47 | Batch_idx: 270 |  Loss: (0.4587) |  Loss2: (0.0000) | Acc: (84.00%) (29185/34688)
Epoch: 47 | Batch_idx: 280 |  Loss: (0.4568) |  Loss2: (0.0000) | Acc: (84.00%) (30278/35968)
Epoch: 47 | Batch_idx: 290 |  Loss: (0.4558) |  Loss2: (0.0000) | Acc: (84.00%) (31378/37248)
Epoch: 47 | Batch_idx: 300 |  Loss: (0.4551) |  Loss2: (0.0000) | Acc: (84.00%) (32466/38528)
Epoch: 47 | Batch_idx: 310 |  Loss: (0.4546) |  Loss2: (0.0000) | Acc: (84.00%) (33553/39808)
Epoch: 47 | Batch_idx: 320 |  Loss: (0.4545) |  Loss2: (0.0000) | Acc: (84.00%) (34622/41088)
Epoch: 47 | Batch_idx: 330 |  Loss: (0.4549) |  Loss2: (0.0000) | Acc: (84.00%) (35682/42368)
Epoch: 47 | Batch_idx: 340 |  Loss: (0.4557) |  Loss2: (0.0000) | Acc: (84.00%) (36746/43648)
Epoch: 47 | Batch_idx: 350 |  Loss: (0.4566) |  Loss2: (0.0000) | Acc: (84.00%) (37810/44928)
Epoch: 47 | Batch_idx: 360 |  Loss: (0.4576) |  Loss2: (0.0000) | Acc: (84.00%) (38870/46208)
Epoch: 47 | Batch_idx: 370 |  Loss: (0.4584) |  Loss2: (0.0000) | Acc: (84.00%) (39942/47488)
Epoch: 47 | Batch_idx: 380 |  Loss: (0.4582) |  Loss2: (0.0000) | Acc: (84.00%) (41024/48768)
Epoch: 47 | Batch_idx: 390 |  Loss: (0.4595) |  Loss2: (0.0000) | Acc: (84.00%) (42049/50000)
# TEST : Loss: (0.5140) | Acc: (82.00%) (8240/10000)
percent tensor([0.4740, 0.4804, 0.4956, 0.4796, 0.4933, 0.4736, 0.4856, 0.4800, 0.4757,
        0.4854, 0.4764, 0.4928, 0.4750, 0.4756, 0.4791, 0.4738],
       device='cuda:0') torch.Size([16])
percent tensor([0.4687, 0.4495, 0.4802, 0.4753, 0.4630, 0.4834, 0.4496, 0.4703, 0.4635,
        0.4594, 0.4598, 0.4612, 0.4540, 0.4594, 0.4577, 0.4692],
       device='cuda:0') torch.Size([16])
percent tensor([0.5608, 0.5713, 0.5061, 0.4916, 0.5246, 0.5791, 0.5894, 0.5122, 0.5173,
        0.5482, 0.5511, 0.5292, 0.5517, 0.5634, 0.5810, 0.5622],
       device='cuda:0') torch.Size([16])
percent tensor([0.6015, 0.5865, 0.6197, 0.6274, 0.6157, 0.6045, 0.6040, 0.6249, 0.6153,
        0.5948, 0.5933, 0.6155, 0.5853, 0.6084, 0.6053, 0.6013],
       device='cuda:0') torch.Size([16])
percent tensor([0.5249, 0.5771, 0.5027, 0.5039, 0.5017, 0.5089, 0.5409, 0.4843, 0.5865,
        0.5774, 0.5841, 0.4973, 0.5597, 0.6481, 0.4786, 0.5446],
       device='cuda:0') torch.Size([16])
percent tensor([0.5814, 0.5824, 0.6070, 0.6259, 0.6161, 0.6025, 0.6000, 0.6036, 0.6018,
        0.5972, 0.5929, 0.6100, 0.5854, 0.6214, 0.5778, 0.6031],
       device='cuda:0') torch.Size([16])
percent tensor([0.6361, 0.6298, 0.6028, 0.5918, 0.5792, 0.5889, 0.6226, 0.5204, 0.6568,
        0.6568, 0.6745, 0.6422, 0.6925, 0.6577, 0.5530, 0.6049],
       device='cuda:0') torch.Size([16])
percent tensor([0.9855, 0.9762, 0.9823, 0.9876, 0.9800, 0.9787, 0.9782, 0.9801, 0.9903,
        0.9887, 0.9947, 0.9928, 0.9856, 0.9767, 0.9698, 0.9850],
       device='cuda:0') torch.Size([16])
True Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=128, out_features=16, bias=False)
False Linear(in_features=16, out_features=2, bias=False)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=128, out_features=16, bias=False)
False Linear(in_features=16, out_features=2, bias=False)
True Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=256, out_features=32, bias=False)
False Linear(in_features=32, out_features=2, bias=False)
True Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=256, out_features=32, bias=False)
False Linear(in_features=32, out_features=2, bias=False)
True Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=512, out_features=64, bias=False)
False Linear(in_features=64, out_features=2, bias=False)
True Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=512, out_features=64, bias=False)
False Linear(in_features=64, out_features=2, bias=False)
True Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1024, out_features=128, bias=False)
False Linear(in_features=128, out_features=2, bias=False)
True Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1024, out_features=128, bias=False)
False Linear(in_features=128, out_features=2, bias=False)
True Linear(in_features=512, out_features=10, bias=True)
Epoch: 48 | Batch_idx: 0 |  Loss: (0.5632) |  Loss2: (0.0000) | Acc: (78.00%) (101/128)
Epoch: 48 | Batch_idx: 10 |  Loss: (0.4523) |  Loss2: (0.0000) | Acc: (84.00%) (1188/1408)
Epoch: 48 | Batch_idx: 20 |  Loss: (0.4577) |  Loss2: (0.0000) | Acc: (84.00%) (2266/2688)
Epoch: 48 | Batch_idx: 30 |  Loss: (0.4522) |  Loss2: (0.0000) | Acc: (84.00%) (3364/3968)
Epoch: 48 | Batch_idx: 40 |  Loss: (0.4591) |  Loss2: (0.0000) | Acc: (84.00%) (4431/5248)
Epoch: 48 | Batch_idx: 50 |  Loss: (0.4596) |  Loss2: (0.0000) | Acc: (84.00%) (5516/6528)
Epoch: 48 | Batch_idx: 60 |  Loss: (0.4650) |  Loss2: (0.0000) | Acc: (84.00%) (6588/7808)
Epoch: 48 | Batch_idx: 70 |  Loss: (0.4606) |  Loss2: (0.0000) | Acc: (84.00%) (7684/9088)
Epoch: 48 | Batch_idx: 80 |  Loss: (0.4582) |  Loss2: (0.0000) | Acc: (84.00%) (8781/10368)
Epoch: 48 | Batch_idx: 90 |  Loss: (0.4543) |  Loss2: (0.0000) | Acc: (84.00%) (9882/11648)
Epoch: 48 | Batch_idx: 100 |  Loss: (0.4539) |  Loss2: (0.0000) | Acc: (84.00%) (10968/12928)
Epoch: 48 | Batch_idx: 110 |  Loss: (0.4557) |  Loss2: (0.0000) | Acc: (84.00%) (12036/14208)
Epoch: 48 | Batch_idx: 120 |  Loss: (0.4534) |  Loss2: (0.0000) | Acc: (84.00%) (13126/15488)
Epoch: 48 | Batch_idx: 130 |  Loss: (0.4560) |  Loss2: (0.0000) | Acc: (84.00%) (14185/16768)
Epoch: 48 | Batch_idx: 140 |  Loss: (0.4565) |  Loss2: (0.0000) | Acc: (84.00%) (15244/18048)
Epoch: 48 | Batch_idx: 150 |  Loss: (0.4549) |  Loss2: (0.0000) | Acc: (84.00%) (16333/19328)
Epoch: 48 | Batch_idx: 160 |  Loss: (0.4534) |  Loss2: (0.0000) | Acc: (84.00%) (17424/20608)
Epoch: 48 | Batch_idx: 170 |  Loss: (0.4522) |  Loss2: (0.0000) | Acc: (84.00%) (18514/21888)
Epoch: 48 | Batch_idx: 180 |  Loss: (0.4521) |  Loss2: (0.0000) | Acc: (84.00%) (19598/23168)
Epoch: 48 | Batch_idx: 190 |  Loss: (0.4505) |  Loss2: (0.0000) | Acc: (84.00%) (20677/24448)
Epoch: 48 | Batch_idx: 200 |  Loss: (0.4512) |  Loss2: (0.0000) | Acc: (84.00%) (21751/25728)
Epoch: 48 | Batch_idx: 210 |  Loss: (0.4522) |  Loss2: (0.0000) | Acc: (84.00%) (22828/27008)
Epoch: 48 | Batch_idx: 220 |  Loss: (0.4527) |  Loss2: (0.0000) | Acc: (84.00%) (23911/28288)
Epoch: 48 | Batch_idx: 230 |  Loss: (0.4530) |  Loss2: (0.0000) | Acc: (84.00%) (24997/29568)
Epoch: 48 | Batch_idx: 240 |  Loss: (0.4536) |  Loss2: (0.0000) | Acc: (84.00%) (26076/30848)
Epoch: 48 | Batch_idx: 250 |  Loss: (0.4525) |  Loss2: (0.0000) | Acc: (84.00%) (27163/32128)
Epoch: 48 | Batch_idx: 260 |  Loss: (0.4535) |  Loss2: (0.0000) | Acc: (84.00%) (28200/33408)
Epoch: 48 | Batch_idx: 270 |  Loss: (0.4528) |  Loss2: (0.0000) | Acc: (84.00%) (29277/34688)
Epoch: 48 | Batch_idx: 280 |  Loss: (0.4521) |  Loss2: (0.0000) | Acc: (84.00%) (30361/35968)
Epoch: 48 | Batch_idx: 290 |  Loss: (0.4520) |  Loss2: (0.0000) | Acc: (84.00%) (31443/37248)
Epoch: 48 | Batch_idx: 300 |  Loss: (0.4525) |  Loss2: (0.0000) | Acc: (84.00%) (32516/38528)
Epoch: 48 | Batch_idx: 310 |  Loss: (0.4523) |  Loss2: (0.0000) | Acc: (84.00%) (33596/39808)
Epoch: 48 | Batch_idx: 320 |  Loss: (0.4517) |  Loss2: (0.0000) | Acc: (84.00%) (34689/41088)
Epoch: 48 | Batch_idx: 330 |  Loss: (0.4534) |  Loss2: (0.0000) | Acc: (84.00%) (35739/42368)
Epoch: 48 | Batch_idx: 340 |  Loss: (0.4537) |  Loss2: (0.0000) | Acc: (84.00%) (36813/43648)
Epoch: 48 | Batch_idx: 350 |  Loss: (0.4541) |  Loss2: (0.0000) | Acc: (84.00%) (37889/44928)
Epoch: 48 | Batch_idx: 360 |  Loss: (0.4546) |  Loss2: (0.0000) | Acc: (84.00%) (38950/46208)
Epoch: 48 | Batch_idx: 370 |  Loss: (0.4553) |  Loss2: (0.0000) | Acc: (84.00%) (40020/47488)
Epoch: 48 | Batch_idx: 380 |  Loss: (0.4540) |  Loss2: (0.0000) | Acc: (84.00%) (41120/48768)
Epoch: 48 | Batch_idx: 390 |  Loss: (0.4538) |  Loss2: (0.0000) | Acc: (84.00%) (42158/50000)
# TEST : Loss: (0.4885) | Acc: (83.00%) (8352/10000)
percent tensor([0.4761, 0.4801, 0.4981, 0.4833, 0.4957, 0.4747, 0.4858, 0.4822, 0.4758,
        0.4866, 0.4763, 0.4955, 0.4766, 0.4731, 0.4807, 0.4747],
       device='cuda:0') torch.Size([16])
percent tensor([0.4682, 0.4501, 0.4821, 0.4694, 0.4651, 0.4847, 0.4548, 0.4662, 0.4658,
        0.4602, 0.4613, 0.4670, 0.4532, 0.4671, 0.4561, 0.4680],
       device='cuda:0') torch.Size([16])
percent tensor([0.5686, 0.5800, 0.5087, 0.4987, 0.5252, 0.5714, 0.5858, 0.5235, 0.5178,
        0.5586, 0.5541, 0.5177, 0.5585, 0.5493, 0.5906, 0.5712],
       device='cuda:0') torch.Size([16])
percent tensor([0.5972, 0.5802, 0.6200, 0.6279, 0.6176, 0.6057, 0.6027, 0.6177, 0.6139,
        0.5900, 0.5882, 0.6187, 0.5795, 0.6173, 0.5998, 0.5987],
       device='cuda:0') torch.Size([16])
percent tensor([0.5260, 0.5674, 0.5086, 0.5061, 0.5156, 0.5212, 0.5467, 0.4813, 0.5771,
        0.5766, 0.5834, 0.5073, 0.5532, 0.6369, 0.4825, 0.5462],
       device='cuda:0') torch.Size([16])
percent tensor([0.5828, 0.5794, 0.6132, 0.6189, 0.6239, 0.6059, 0.6026, 0.6007, 0.5990,
        0.5943, 0.5926, 0.6151, 0.5787, 0.6250, 0.5781, 0.6085],
       device='cuda:0') torch.Size([16])
percent tensor([0.6366, 0.6309, 0.6144, 0.5966, 0.5934, 0.5856, 0.6292, 0.5452, 0.6610,
        0.6586, 0.6668, 0.6446, 0.6869, 0.6587, 0.5533, 0.6028],
       device='cuda:0') torch.Size([16])
percent tensor([0.9853, 0.9792, 0.9866, 0.9837, 0.9830, 0.9786, 0.9818, 0.9869, 0.9929,
        0.9918, 0.9933, 0.9923, 0.9865, 0.9860, 0.9665, 0.9846],
       device='cuda:0') torch.Size([16])
Epoch: 49 | Batch_idx: 0 |  Loss: (0.4312) |  Loss2: (0.0000) | Acc: (85.00%) (109/128)
Epoch: 49 | Batch_idx: 10 |  Loss: (0.4090) |  Loss2: (0.0000) | Acc: (86.00%) (1213/1408)
Epoch: 49 | Batch_idx: 20 |  Loss: (0.4255) |  Loss2: (0.0000) | Acc: (85.00%) (2288/2688)
Epoch: 49 | Batch_idx: 30 |  Loss: (0.4187) |  Loss2: (0.0000) | Acc: (85.00%) (3390/3968)
Epoch: 49 | Batch_idx: 40 |  Loss: (0.4161) |  Loss2: (0.0000) | Acc: (85.00%) (4489/5248)
Epoch: 49 | Batch_idx: 50 |  Loss: (0.4192) |  Loss2: (0.0000) | Acc: (85.00%) (5569/6528)
Epoch: 49 | Batch_idx: 60 |  Loss: (0.4188) |  Loss2: (0.0000) | Acc: (85.00%) (6674/7808)
Epoch: 49 | Batch_idx: 70 |  Loss: (0.4254) |  Loss2: (0.0000) | Acc: (85.00%) (7747/9088)
Epoch: 49 | Batch_idx: 80 |  Loss: (0.4304) |  Loss2: (0.0000) | Acc: (85.00%) (8815/10368)
Epoch: 49 | Batch_idx: 90 |  Loss: (0.4282) |  Loss2: (0.0000) | Acc: (85.00%) (9913/11648)
Epoch: 49 | Batch_idx: 100 |  Loss: (0.4218) |  Loss2: (0.0000) | Acc: (85.00%) (11032/12928)
Epoch: 49 | Batch_idx: 110 |  Loss: (0.4206) |  Loss2: (0.0000) | Acc: (85.00%) (12129/14208)
Epoch: 49 | Batch_idx: 120 |  Loss: (0.4207) |  Loss2: (0.0000) | Acc: (85.00%) (13221/15488)
Epoch: 49 | Batch_idx: 130 |  Loss: (0.4275) |  Loss2: (0.0000) | Acc: (85.00%) (14271/16768)
Epoch: 49 | Batch_idx: 140 |  Loss: (0.4311) |  Loss2: (0.0000) | Acc: (84.00%) (15339/18048)
Epoch: 49 | Batch_idx: 150 |  Loss: (0.4300) |  Loss2: (0.0000) | Acc: (84.00%) (16428/19328)
Epoch: 49 | Batch_idx: 160 |  Loss: (0.4306) |  Loss2: (0.0000) | Acc: (85.00%) (17523/20608)
Epoch: 49 | Batch_idx: 170 |  Loss: (0.4307) |  Loss2: (0.0000) | Acc: (85.00%) (18609/21888)
Epoch: 49 | Batch_idx: 180 |  Loss: (0.4308) |  Loss2: (0.0000) | Acc: (85.00%) (19704/23168)
Epoch: 49 | Batch_idx: 190 |  Loss: (0.4318) |  Loss2: (0.0000) | Acc: (85.00%) (20806/24448)
Epoch: 49 | Batch_idx: 200 |  Loss: (0.4309) |  Loss2: (0.0000) | Acc: (85.00%) (21916/25728)
Epoch: 49 | Batch_idx: 210 |  Loss: (0.4313) |  Loss2: (0.0000) | Acc: (85.00%) (22999/27008)
Epoch: 49 | Batch_idx: 220 |  Loss: (0.4310) |  Loss2: (0.0000) | Acc: (85.00%) (24095/28288)
Epoch: 49 | Batch_idx: 230 |  Loss: (0.4318) |  Loss2: (0.0000) | Acc: (85.00%) (25183/29568)
Epoch: 49 | Batch_idx: 240 |  Loss: (0.4319) |  Loss2: (0.0000) | Acc: (85.00%) (26269/30848)
Epoch: 49 | Batch_idx: 250 |  Loss: (0.4319) |  Loss2: (0.0000) | Acc: (85.00%) (27358/32128)
Epoch: 49 | Batch_idx: 260 |  Loss: (0.4322) |  Loss2: (0.0000) | Acc: (85.00%) (28455/33408)
Epoch: 49 | Batch_idx: 270 |  Loss: (0.4320) |  Loss2: (0.0000) | Acc: (85.00%) (29552/34688)
Epoch: 49 | Batch_idx: 280 |  Loss: (0.4320) |  Loss2: (0.0000) | Acc: (85.00%) (30634/35968)
Epoch: 49 | Batch_idx: 290 |  Loss: (0.4328) |  Loss2: (0.0000) | Acc: (85.00%) (31705/37248)
Epoch: 49 | Batch_idx: 300 |  Loss: (0.4334) |  Loss2: (0.0000) | Acc: (85.00%) (32784/38528)
Epoch: 49 | Batch_idx: 310 |  Loss: (0.4328) |  Loss2: (0.0000) | Acc: (85.00%) (33881/39808)
Epoch: 49 | Batch_idx: 320 |  Loss: (0.4327) |  Loss2: (0.0000) | Acc: (85.00%) (34982/41088)
Epoch: 49 | Batch_idx: 330 |  Loss: (0.4322) |  Loss2: (0.0000) | Acc: (85.00%) (36082/42368)
Epoch: 49 | Batch_idx: 340 |  Loss: (0.4318) |  Loss2: (0.0000) | Acc: (85.00%) (37178/43648)
Epoch: 49 | Batch_idx: 350 |  Loss: (0.4329) |  Loss2: (0.0000) | Acc: (85.00%) (38258/44928)
Epoch: 49 | Batch_idx: 360 |  Loss: (0.4325) |  Loss2: (0.0000) | Acc: (85.00%) (39345/46208)
Epoch: 49 | Batch_idx: 370 |  Loss: (0.4328) |  Loss2: (0.0000) | Acc: (85.00%) (40430/47488)
Epoch: 49 | Batch_idx: 380 |  Loss: (0.4326) |  Loss2: (0.0000) | Acc: (85.00%) (41520/48768)
Epoch: 49 | Batch_idx: 390 |  Loss: (0.4328) |  Loss2: (0.0000) | Acc: (85.00%) (42550/50000)
# TEST : Loss: (0.5819) | Acc: (80.00%) (8045/10000)
percent tensor([0.4760, 0.4794, 0.4994, 0.4829, 0.4972, 0.4750, 0.4846, 0.4818, 0.4761,
        0.4864, 0.4763, 0.4949, 0.4766, 0.4714, 0.4804, 0.4745],
       device='cuda:0') torch.Size([16])
percent tensor([0.4686, 0.4485, 0.4830, 0.4735, 0.4652, 0.4825, 0.4535, 0.4668, 0.4666,
        0.4602, 0.4613, 0.4684, 0.4532, 0.4657, 0.4545, 0.4681],
       device='cuda:0') torch.Size([16])
percent tensor([0.5619, 0.5764, 0.5070, 0.4940, 0.5198, 0.5589, 0.5805, 0.5172, 0.5104,
        0.5564, 0.5440, 0.5127, 0.5532, 0.5409, 0.5807, 0.5642],
       device='cuda:0') torch.Size([16])
percent tensor([0.5984, 0.5804, 0.6183, 0.6186, 0.6149, 0.6037, 0.6045, 0.6169, 0.6129,
        0.5911, 0.5896, 0.6194, 0.5810, 0.6171, 0.5975, 0.5969],
       device='cuda:0') torch.Size([16])
percent tensor([0.5287, 0.5637, 0.5083, 0.5143, 0.5177, 0.5245, 0.5519, 0.4772, 0.5889,
        0.5784, 0.5864, 0.5115, 0.5584, 0.6334, 0.4815, 0.5459],
       device='cuda:0') torch.Size([16])
percent tensor([0.5844, 0.5786, 0.6089, 0.6176, 0.6173, 0.5987, 0.6039, 0.6005, 0.6066,
        0.5961, 0.5980, 0.6160, 0.5829, 0.6288, 0.5715, 0.6097],
       device='cuda:0') torch.Size([16])
percent tensor([0.6430, 0.6399, 0.6199, 0.6178, 0.6041, 0.5860, 0.6377, 0.5572, 0.6572,
        0.6731, 0.6638, 0.6515, 0.6826, 0.6651, 0.5834, 0.6077],
       device='cuda:0') torch.Size([16])
percent tensor([0.9873, 0.9840, 0.9888, 0.9919, 0.9884, 0.9798, 0.9876, 0.9838, 0.9901,
        0.9924, 0.9922, 0.9885, 0.9860, 0.9872, 0.9725, 0.9817],
       device='cuda:0') torch.Size([16])
Epoch: 50 | Batch_idx: 0 |  Loss: (0.4130) |  Loss2: (0.0000) | Acc: (87.00%) (112/128)
Epoch: 50 | Batch_idx: 10 |  Loss: (0.4051) |  Loss2: (0.0000) | Acc: (86.00%) (1217/1408)
Epoch: 50 | Batch_idx: 20 |  Loss: (0.4091) |  Loss2: (0.0000) | Acc: (86.00%) (2316/2688)
Epoch: 50 | Batch_idx: 30 |  Loss: (0.4231) |  Loss2: (0.0000) | Acc: (85.00%) (3391/3968)
Epoch: 50 | Batch_idx: 40 |  Loss: (0.4291) |  Loss2: (0.0000) | Acc: (85.00%) (4480/5248)
Epoch: 50 | Batch_idx: 50 |  Loss: (0.4263) |  Loss2: (0.0000) | Acc: (85.00%) (5578/6528)
Epoch: 50 | Batch_idx: 60 |  Loss: (0.4233) |  Loss2: (0.0000) | Acc: (85.00%) (6680/7808)
Epoch: 50 | Batch_idx: 70 |  Loss: (0.4199) |  Loss2: (0.0000) | Acc: (85.00%) (7787/9088)
Epoch: 50 | Batch_idx: 80 |  Loss: (0.4195) |  Loss2: (0.0000) | Acc: (85.00%) (8874/10368)
Epoch: 50 | Batch_idx: 90 |  Loss: (0.4202) |  Loss2: (0.0000) | Acc: (85.00%) (9971/11648)
Epoch: 50 | Batch_idx: 100 |  Loss: (0.4160) |  Loss2: (0.0000) | Acc: (85.00%) (11085/12928)
Epoch: 50 | Batch_idx: 110 |  Loss: (0.4146) |  Loss2: (0.0000) | Acc: (85.00%) (12196/14208)
Epoch: 50 | Batch_idx: 120 |  Loss: (0.4191) |  Loss2: (0.0000) | Acc: (85.00%) (13282/15488)
Epoch: 50 | Batch_idx: 130 |  Loss: (0.4187) |  Loss2: (0.0000) | Acc: (85.00%) (14367/16768)
Epoch: 50 | Batch_idx: 140 |  Loss: (0.4200) |  Loss2: (0.0000) | Acc: (85.00%) (15443/18048)
Epoch: 50 | Batch_idx: 150 |  Loss: (0.4202) |  Loss2: (0.0000) | Acc: (85.00%) (16530/19328)
Epoch: 50 | Batch_idx: 160 |  Loss: (0.4215) |  Loss2: (0.0000) | Acc: (85.00%) (17617/20608)
Epoch: 50 | Batch_idx: 170 |  Loss: (0.4222) |  Loss2: (0.0000) | Acc: (85.00%) (18712/21888)
Epoch: 50 | Batch_idx: 180 |  Loss: (0.4224) |  Loss2: (0.0000) | Acc: (85.00%) (19796/23168)
Epoch: 50 | Batch_idx: 190 |  Loss: (0.4227) |  Loss2: (0.0000) | Acc: (85.00%) (20883/24448)
Epoch: 50 | Batch_idx: 200 |  Loss: (0.4218) |  Loss2: (0.0000) | Acc: (85.00%) (21992/25728)
Epoch: 50 | Batch_idx: 210 |  Loss: (0.4222) |  Loss2: (0.0000) | Acc: (85.00%) (23079/27008)
Epoch: 50 | Batch_idx: 220 |  Loss: (0.4233) |  Loss2: (0.0000) | Acc: (85.00%) (24154/28288)
Epoch: 50 | Batch_idx: 230 |  Loss: (0.4228) |  Loss2: (0.0000) | Acc: (85.00%) (25258/29568)
Epoch: 50 | Batch_idx: 240 |  Loss: (0.4230) |  Loss2: (0.0000) | Acc: (85.00%) (26336/30848)
Epoch: 50 | Batch_idx: 250 |  Loss: (0.4233) |  Loss2: (0.0000) | Acc: (85.00%) (27433/32128)
Epoch: 50 | Batch_idx: 260 |  Loss: (0.4243) |  Loss2: (0.0000) | Acc: (85.00%) (28509/33408)
Epoch: 50 | Batch_idx: 270 |  Loss: (0.4237) |  Loss2: (0.0000) | Acc: (85.00%) (29599/34688)
Epoch: 50 | Batch_idx: 280 |  Loss: (0.4241) |  Loss2: (0.0000) | Acc: (85.00%) (30683/35968)
Epoch: 50 | Batch_idx: 290 |  Loss: (0.4235) |  Loss2: (0.0000) | Acc: (85.00%) (31795/37248)
Epoch: 50 | Batch_idx: 300 |  Loss: (0.4222) |  Loss2: (0.0000) | Acc: (85.00%) (32894/38528)
Epoch: 50 | Batch_idx: 310 |  Loss: (0.4220) |  Loss2: (0.0000) | Acc: (85.00%) (33999/39808)
Epoch: 50 | Batch_idx: 320 |  Loss: (0.4219) |  Loss2: (0.0000) | Acc: (85.00%) (35113/41088)
Epoch: 50 | Batch_idx: 330 |  Loss: (0.4215) |  Loss2: (0.0000) | Acc: (85.00%) (36220/42368)
Epoch: 50 | Batch_idx: 340 |  Loss: (0.4211) |  Loss2: (0.0000) | Acc: (85.00%) (37312/43648)
Epoch: 50 | Batch_idx: 350 |  Loss: (0.4211) |  Loss2: (0.0000) | Acc: (85.00%) (38409/44928)
Epoch: 50 | Batch_idx: 360 |  Loss: (0.4210) |  Loss2: (0.0000) | Acc: (85.00%) (39501/46208)
Epoch: 50 | Batch_idx: 370 |  Loss: (0.4212) |  Loss2: (0.0000) | Acc: (85.00%) (40591/47488)
Epoch: 50 | Batch_idx: 380 |  Loss: (0.4207) |  Loss2: (0.0000) | Acc: (85.00%) (41698/48768)
Epoch: 50 | Batch_idx: 390 |  Loss: (0.4212) |  Loss2: (0.0000) | Acc: (85.00%) (42746/50000)
=> saving checkpoint 'drive/app/torch/save_Schedule/checkpoint_050.pth.tar'
# TEST : Loss: (0.5195) | Acc: (81.00%) (8188/10000)
percent tensor([0.4762, 0.4789, 0.5002, 0.4815, 0.4968, 0.4750, 0.4844, 0.4815, 0.4764,
        0.4861, 0.4761, 0.4952, 0.4765, 0.4709, 0.4796, 0.4742],
       device='cuda:0') torch.Size([16])
percent tensor([0.4677, 0.4476, 0.4793, 0.4721, 0.4623, 0.4840, 0.4516, 0.4626, 0.4646,
        0.4582, 0.4606, 0.4650, 0.4520, 0.4664, 0.4534, 0.4679],
       device='cuda:0') torch.Size([16])
percent tensor([0.5724, 0.5825, 0.5094, 0.4899, 0.5252, 0.5760, 0.5904, 0.5172, 0.5180,
        0.5615, 0.5535, 0.5234, 0.5611, 0.5445, 0.5930, 0.5677],
       device='cuda:0') torch.Size([16])
percent tensor([0.5995, 0.5869, 0.6191, 0.6264, 0.6156, 0.6044, 0.6069, 0.6174, 0.6169,
        0.5954, 0.5975, 0.6193, 0.5854, 0.6239, 0.6025, 0.6003],
       device='cuda:0') torch.Size([16])
percent tensor([0.5185, 0.5691, 0.5049, 0.5045, 0.5036, 0.5074, 0.5498, 0.4741, 0.5753,
        0.5737, 0.5834, 0.5025, 0.5475, 0.6412, 0.4748, 0.5424],
       device='cuda:0') torch.Size([16])
percent tensor([0.5770, 0.5780, 0.6016, 0.6177, 0.6134, 0.6021, 0.6081, 0.5945, 0.6005,
        0.5926, 0.5923, 0.6073, 0.5753, 0.6283, 0.5738, 0.6060],
       device='cuda:0') torch.Size([16])
percent tensor([0.6397, 0.6370, 0.6074, 0.6064, 0.5872, 0.5996, 0.6287, 0.5318, 0.6447,
        0.6541, 0.6510, 0.6389, 0.6725, 0.6621, 0.5680, 0.5965],
       device='cuda:0') torch.Size([16])
percent tensor([0.9868, 0.9834, 0.9820, 0.9857, 0.9791, 0.9849, 0.9834, 0.9801, 0.9911,
        0.9911, 0.9909, 0.9884, 0.9822, 0.9852, 0.9752, 0.9843],
       device='cuda:0') torch.Size([16])
Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 3, 3, 3]) tensor(180.4142, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(798.1500, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(796.1039, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([128, 64, 3, 3]) tensor(1532.5140, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([128, 64, 1, 1]) tensor(499.9247, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([128, 128, 3, 3]) tensor(2215.8809, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([256, 128, 3, 3]) tensor(4300.3672, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([256, 128, 1, 1]) tensor(1416.3055, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([256, 256, 3, 3]) tensor(6089.5479, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([512, 256, 3, 3]) tensor(12055.8232, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([512, 256, 1, 1]) tensor(4018.0613, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([512, 512, 3, 3]) tensor(16986.2285, device='cuda:0', grad_fn=<NormBackward0>)
Epoch: 51 | Batch_idx: 0 |  Loss: (0.4316) |  Loss2: (0.0000) | Acc: (82.00%) (106/128)
Epoch: 51 | Batch_idx: 10 |  Loss: (0.3901) |  Loss2: (0.0000) | Acc: (86.00%) (1218/1408)
Epoch: 51 | Batch_idx: 20 |  Loss: (0.4049) |  Loss2: (0.0000) | Acc: (86.00%) (2317/2688)
Epoch: 51 | Batch_idx: 30 |  Loss: (0.3966) |  Loss2: (0.0000) | Acc: (86.00%) (3418/3968)
Epoch: 51 | Batch_idx: 40 |  Loss: (0.3989) |  Loss2: (0.0000) | Acc: (86.00%) (4519/5248)
Epoch: 51 | Batch_idx: 50 |  Loss: (0.4008) |  Loss2: (0.0000) | Acc: (85.00%) (5611/6528)
Epoch: 51 | Batch_idx: 60 |  Loss: (0.3907) |  Loss2: (0.0000) | Acc: (86.00%) (6750/7808)
Epoch: 51 | Batch_idx: 70 |  Loss: (0.3955) |  Loss2: (0.0000) | Acc: (86.00%) (7847/9088)
Epoch: 51 | Batch_idx: 80 |  Loss: (0.3925) |  Loss2: (0.0000) | Acc: (86.00%) (8966/10368)
Epoch: 51 | Batch_idx: 90 |  Loss: (0.3890) |  Loss2: (0.0000) | Acc: (86.00%) (10086/11648)
Epoch: 51 | Batch_idx: 100 |  Loss: (0.3941) |  Loss2: (0.0000) | Acc: (86.00%) (11163/12928)
Epoch: 51 | Batch_idx: 110 |  Loss: (0.4003) |  Loss2: (0.0000) | Acc: (86.00%) (12243/14208)
Epoch: 51 | Batch_idx: 120 |  Loss: (0.3973) |  Loss2: (0.0000) | Acc: (86.00%) (13355/15488)
Epoch: 51 | Batch_idx: 130 |  Loss: (0.3933) |  Loss2: (0.0000) | Acc: (86.00%) (14484/16768)
Epoch: 51 | Batch_idx: 140 |  Loss: (0.3934) |  Loss2: (0.0000) | Acc: (86.00%) (15599/18048)
Epoch: 51 | Batch_idx: 150 |  Loss: (0.3946) |  Loss2: (0.0000) | Acc: (86.00%) (16694/19328)
Epoch: 51 | Batch_idx: 160 |  Loss: (0.3993) |  Loss2: (0.0000) | Acc: (86.00%) (17772/20608)
Epoch: 51 | Batch_idx: 170 |  Loss: (0.4003) |  Loss2: (0.0000) | Acc: (86.00%) (18869/21888)
Epoch: 51 | Batch_idx: 180 |  Loss: (0.3988) |  Loss2: (0.0000) | Acc: (86.00%) (19998/23168)
Epoch: 51 | Batch_idx: 190 |  Loss: (0.3981) |  Loss2: (0.0000) | Acc: (86.00%) (21112/24448)
Epoch: 51 | Batch_idx: 200 |  Loss: (0.3995) |  Loss2: (0.0000) | Acc: (86.00%) (22199/25728)
Epoch: 51 | Batch_idx: 210 |  Loss: (0.4004) |  Loss2: (0.0000) | Acc: (86.00%) (23302/27008)
Epoch: 51 | Batch_idx: 220 |  Loss: (0.4002) |  Loss2: (0.0000) | Acc: (86.00%) (24410/28288)
Epoch: 51 | Batch_idx: 230 |  Loss: (0.3997) |  Loss2: (0.0000) | Acc: (86.00%) (25511/29568)
Epoch: 51 | Batch_idx: 240 |  Loss: (0.3995) |  Loss2: (0.0000) | Acc: (86.00%) (26621/30848)
Epoch: 51 | Batch_idx: 250 |  Loss: (0.3983) |  Loss2: (0.0000) | Acc: (86.00%) (27736/32128)
Epoch: 51 | Batch_idx: 260 |  Loss: (0.3988) |  Loss2: (0.0000) | Acc: (86.00%) (28831/33408)
Epoch: 51 | Batch_idx: 270 |  Loss: (0.3984) |  Loss2: (0.0000) | Acc: (86.00%) (29930/34688)
Epoch: 51 | Batch_idx: 280 |  Loss: (0.3990) |  Loss2: (0.0000) | Acc: (86.00%) (31017/35968)
Epoch: 51 | Batch_idx: 290 |  Loss: (0.4001) |  Loss2: (0.0000) | Acc: (86.00%) (32111/37248)
Epoch: 51 | Batch_idx: 300 |  Loss: (0.4006) |  Loss2: (0.0000) | Acc: (86.00%) (33217/38528)
Epoch: 51 | Batch_idx: 310 |  Loss: (0.4003) |  Loss2: (0.0000) | Acc: (86.00%) (34319/39808)
Epoch: 51 | Batch_idx: 320 |  Loss: (0.4019) |  Loss2: (0.0000) | Acc: (86.00%) (35402/41088)
Epoch: 51 | Batch_idx: 330 |  Loss: (0.4022) |  Loss2: (0.0000) | Acc: (86.00%) (36498/42368)
Epoch: 51 | Batch_idx: 340 |  Loss: (0.4029) |  Loss2: (0.0000) | Acc: (86.00%) (37585/43648)
Epoch: 51 | Batch_idx: 350 |  Loss: (0.4038) |  Loss2: (0.0000) | Acc: (86.00%) (38683/44928)
Epoch: 51 | Batch_idx: 360 |  Loss: (0.4029) |  Loss2: (0.0000) | Acc: (86.00%) (39809/46208)
Epoch: 51 | Batch_idx: 370 |  Loss: (0.4032) |  Loss2: (0.0000) | Acc: (86.00%) (40902/47488)
Epoch: 51 | Batch_idx: 380 |  Loss: (0.4025) |  Loss2: (0.0000) | Acc: (86.00%) (42012/48768)
Epoch: 51 | Batch_idx: 390 |  Loss: (0.4025) |  Loss2: (0.0000) | Acc: (86.00%) (43076/50000)
# TEST : Loss: (0.5424) | Acc: (82.00%) (8217/10000)
percent tensor([0.4771, 0.4786, 0.5032, 0.4838, 0.4991, 0.4748, 0.4853, 0.4842, 0.4769,
        0.4875, 0.4765, 0.4977, 0.4772, 0.4709, 0.4798, 0.4747],
       device='cuda:0') torch.Size([16])
percent tensor([0.4672, 0.4484, 0.4851, 0.4766, 0.4681, 0.4816, 0.4538, 0.4671, 0.4660,
        0.4601, 0.4597, 0.4709, 0.4535, 0.4649, 0.4540, 0.4660],
       device='cuda:0') torch.Size([16])
percent tensor([0.5660, 0.5805, 0.4997, 0.4913, 0.5118, 0.5736, 0.5810, 0.5148, 0.5150,
        0.5539, 0.5504, 0.5068, 0.5520, 0.5497, 0.5896, 0.5688],
       device='cuda:0') torch.Size([16])
percent tensor([0.5961, 0.5837, 0.6193, 0.6234, 0.6144, 0.5998, 0.6039, 0.6170, 0.6118,
        0.5936, 0.5911, 0.6173, 0.5827, 0.6130, 0.5979, 0.5965],
       device='cuda:0') torch.Size([16])
percent tensor([0.5298, 0.5709, 0.5302, 0.5231, 0.5386, 0.5119, 0.5584, 0.4868, 0.5826,
        0.5795, 0.5823, 0.5262, 0.5569, 0.6360, 0.4821, 0.5503],
       device='cuda:0') torch.Size([16])
percent tensor([0.5820, 0.5837, 0.6130, 0.6220, 0.6240, 0.5952, 0.6068, 0.6020, 0.6040,
        0.5981, 0.5955, 0.6178, 0.5856, 0.6265, 0.5770, 0.6095],
       device='cuda:0') torch.Size([16])
percent tensor([0.6371, 0.6281, 0.6223, 0.6268, 0.6100, 0.6010, 0.6262, 0.5467, 0.6493,
        0.6456, 0.6576, 0.6469, 0.6790, 0.6354, 0.5799, 0.6040],
       device='cuda:0') torch.Size([16])
percent tensor([0.9873, 0.9796, 0.9891, 0.9912, 0.9884, 0.9846, 0.9788, 0.9862, 0.9917,
        0.9872, 0.9935, 0.9909, 0.9895, 0.9797, 0.9773, 0.9830],
       device='cuda:0') torch.Size([16])
Epoch: 52 | Batch_idx: 0 |  Loss: (0.4706) |  Loss2: (0.0000) | Acc: (85.00%) (109/128)
Epoch: 52 | Batch_idx: 10 |  Loss: (0.3951) |  Loss2: (0.0000) | Acc: (86.00%) (1218/1408)
Epoch: 52 | Batch_idx: 20 |  Loss: (0.3755) |  Loss2: (0.0000) | Acc: (87.00%) (2340/2688)
Epoch: 52 | Batch_idx: 30 |  Loss: (0.3829) |  Loss2: (0.0000) | Acc: (86.00%) (3438/3968)
Epoch: 52 | Batch_idx: 40 |  Loss: (0.3849) |  Loss2: (0.0000) | Acc: (86.00%) (4552/5248)
Epoch: 52 | Batch_idx: 50 |  Loss: (0.3917) |  Loss2: (0.0000) | Acc: (86.00%) (5642/6528)
Epoch: 52 | Batch_idx: 60 |  Loss: (0.3915) |  Loss2: (0.0000) | Acc: (86.00%) (6748/7808)
Epoch: 52 | Batch_idx: 70 |  Loss: (0.3929) |  Loss2: (0.0000) | Acc: (86.00%) (7853/9088)
Epoch: 52 | Batch_idx: 80 |  Loss: (0.3924) |  Loss2: (0.0000) | Acc: (86.00%) (8963/10368)
Epoch: 52 | Batch_idx: 90 |  Loss: (0.3952) |  Loss2: (0.0000) | Acc: (86.00%) (10064/11648)
Epoch: 52 | Batch_idx: 100 |  Loss: (0.3944) |  Loss2: (0.0000) | Acc: (86.00%) (11188/12928)
Epoch: 52 | Batch_idx: 110 |  Loss: (0.3950) |  Loss2: (0.0000) | Acc: (86.00%) (12290/14208)
Epoch: 52 | Batch_idx: 120 |  Loss: (0.3951) |  Loss2: (0.0000) | Acc: (86.00%) (13406/15488)
Epoch: 52 | Batch_idx: 130 |  Loss: (0.3944) |  Loss2: (0.0000) | Acc: (86.00%) (14520/16768)
Epoch: 52 | Batch_idx: 140 |  Loss: (0.3918) |  Loss2: (0.0000) | Acc: (86.00%) (15641/18048)
Epoch: 52 | Batch_idx: 150 |  Loss: (0.3888) |  Loss2: (0.0000) | Acc: (86.00%) (16776/19328)
Epoch: 52 | Batch_idx: 160 |  Loss: (0.3875) |  Loss2: (0.0000) | Acc: (86.00%) (17882/20608)
Epoch: 52 | Batch_idx: 170 |  Loss: (0.3884) |  Loss2: (0.0000) | Acc: (86.00%) (18982/21888)
Epoch: 52 | Batch_idx: 180 |  Loss: (0.3884) |  Loss2: (0.0000) | Acc: (86.00%) (20091/23168)
Epoch: 52 | Batch_idx: 190 |  Loss: (0.3876) |  Loss2: (0.0000) | Acc: (86.00%) (21210/24448)
Epoch: 52 | Batch_idx: 200 |  Loss: (0.3870) |  Loss2: (0.0000) | Acc: (86.00%) (22328/25728)
Epoch: 52 | Batch_idx: 210 |  Loss: (0.3879) |  Loss2: (0.0000) | Acc: (86.00%) (23418/27008)
Epoch: 52 | Batch_idx: 220 |  Loss: (0.3901) |  Loss2: (0.0000) | Acc: (86.00%) (24509/28288)
Epoch: 52 | Batch_idx: 230 |  Loss: (0.3910) |  Loss2: (0.0000) | Acc: (86.00%) (25598/29568)
Epoch: 52 | Batch_idx: 240 |  Loss: (0.3915) |  Loss2: (0.0000) | Acc: (86.00%) (26696/30848)
Epoch: 52 | Batch_idx: 250 |  Loss: (0.3926) |  Loss2: (0.0000) | Acc: (86.00%) (27791/32128)
Epoch: 52 | Batch_idx: 260 |  Loss: (0.3938) |  Loss2: (0.0000) | Acc: (86.00%) (28884/33408)
Epoch: 52 | Batch_idx: 270 |  Loss: (0.3938) |  Loss2: (0.0000) | Acc: (86.00%) (30001/34688)
Epoch: 52 | Batch_idx: 280 |  Loss: (0.3938) |  Loss2: (0.0000) | Acc: (86.00%) (31105/35968)
Epoch: 52 | Batch_idx: 290 |  Loss: (0.3941) |  Loss2: (0.0000) | Acc: (86.00%) (32206/37248)
Epoch: 52 | Batch_idx: 300 |  Loss: (0.3934) |  Loss2: (0.0000) | Acc: (86.00%) (33319/38528)
Epoch: 52 | Batch_idx: 310 |  Loss: (0.3939) |  Loss2: (0.0000) | Acc: (86.00%) (34407/39808)
Epoch: 52 | Batch_idx: 320 |  Loss: (0.3925) |  Loss2: (0.0000) | Acc: (86.00%) (35533/41088)
Epoch: 52 | Batch_idx: 330 |  Loss: (0.3924) |  Loss2: (0.0000) | Acc: (86.00%) (36630/42368)
Epoch: 52 | Batch_idx: 340 |  Loss: (0.3915) |  Loss2: (0.0000) | Acc: (86.00%) (37763/43648)
Epoch: 52 | Batch_idx: 350 |  Loss: (0.3912) |  Loss2: (0.0000) | Acc: (86.00%) (38869/44928)
Epoch: 52 | Batch_idx: 360 |  Loss: (0.3912) |  Loss2: (0.0000) | Acc: (86.00%) (39976/46208)
Epoch: 52 | Batch_idx: 370 |  Loss: (0.3900) |  Loss2: (0.0000) | Acc: (86.00%) (41109/47488)
Epoch: 52 | Batch_idx: 380 |  Loss: (0.3913) |  Loss2: (0.0000) | Acc: (86.00%) (42194/48768)
Epoch: 52 | Batch_idx: 390 |  Loss: (0.3912) |  Loss2: (0.0000) | Acc: (86.00%) (43252/50000)
# TEST : Loss: (0.4957) | Acc: (83.00%) (8313/10000)
percent tensor([0.4771, 0.4800, 0.5013, 0.4851, 0.4979, 0.4760, 0.4854, 0.4841, 0.4763,
        0.4872, 0.4766, 0.4965, 0.4771, 0.4722, 0.4809, 0.4754],
       device='cuda:0') torch.Size([16])
percent tensor([0.4659, 0.4495, 0.4771, 0.4710, 0.4610, 0.4827, 0.4527, 0.4629, 0.4641,
        0.4585, 0.4608, 0.4631, 0.4512, 0.4690, 0.4548, 0.4680],
       device='cuda:0') torch.Size([16])
percent tensor([0.5709, 0.5711, 0.5068, 0.4923, 0.5206, 0.5751, 0.5786, 0.5216, 0.5203,
        0.5537, 0.5495, 0.5167, 0.5590, 0.5316, 0.5891, 0.5664],
       device='cuda:0') torch.Size([16])
percent tensor([0.5990, 0.5888, 0.6190, 0.6211, 0.6123, 0.5982, 0.6090, 0.6167, 0.6164,
        0.5981, 0.6004, 0.6197, 0.5850, 0.6285, 0.5992, 0.5994],
       device='cuda:0') torch.Size([16])
percent tensor([0.5145, 0.5651, 0.5155, 0.5069, 0.5155, 0.5053, 0.5428, 0.4703, 0.5688,
        0.5717, 0.5843, 0.5068, 0.5406, 0.6243, 0.4707, 0.5409],
       device='cuda:0') torch.Size([16])
percent tensor([0.5792, 0.5809, 0.6013, 0.6132, 0.6102, 0.5975, 0.6074, 0.5923, 0.6009,
        0.5953, 0.5990, 0.6105, 0.5763, 0.6304, 0.5765, 0.6086],
       device='cuda:0') torch.Size([16])
percent tensor([0.6461, 0.6361, 0.6151, 0.6109, 0.5885, 0.5920, 0.6217, 0.5448, 0.6492,
        0.6649, 0.6676, 0.6517, 0.6802, 0.6605, 0.5664, 0.6057],
       device='cuda:0') torch.Size([16])
percent tensor([0.9901, 0.9887, 0.9889, 0.9909, 0.9872, 0.9829, 0.9823, 0.9841, 0.9917,
        0.9935, 0.9954, 0.9931, 0.9903, 0.9871, 0.9732, 0.9857],
       device='cuda:0') torch.Size([16])
Epoch: 53 | Batch_idx: 0 |  Loss: (0.4164) |  Loss2: (0.0000) | Acc: (84.00%) (108/128)
Epoch: 53 | Batch_idx: 10 |  Loss: (0.4121) |  Loss2: (0.0000) | Acc: (85.00%) (1200/1408)
Epoch: 53 | Batch_idx: 20 |  Loss: (0.4115) |  Loss2: (0.0000) | Acc: (85.00%) (2297/2688)
Epoch: 53 | Batch_idx: 30 |  Loss: (0.4043) |  Loss2: (0.0000) | Acc: (85.00%) (3410/3968)
Epoch: 53 | Batch_idx: 40 |  Loss: (0.4047) |  Loss2: (0.0000) | Acc: (86.00%) (4518/5248)
Epoch: 53 | Batch_idx: 50 |  Loss: (0.3985) |  Loss2: (0.0000) | Acc: (86.00%) (5645/6528)
Epoch: 53 | Batch_idx: 60 |  Loss: (0.3934) |  Loss2: (0.0000) | Acc: (86.00%) (6765/7808)
Epoch: 53 | Batch_idx: 70 |  Loss: (0.3922) |  Loss2: (0.0000) | Acc: (86.00%) (7889/9088)
Epoch: 53 | Batch_idx: 80 |  Loss: (0.3889) |  Loss2: (0.0000) | Acc: (86.00%) (9001/10368)
Epoch: 53 | Batch_idx: 90 |  Loss: (0.3863) |  Loss2: (0.0000) | Acc: (86.00%) (10121/11648)
Epoch: 53 | Batch_idx: 100 |  Loss: (0.3849) |  Loss2: (0.0000) | Acc: (86.00%) (11237/12928)
Epoch: 53 | Batch_idx: 110 |  Loss: (0.3833) |  Loss2: (0.0000) | Acc: (86.00%) (12355/14208)
Epoch: 53 | Batch_idx: 120 |  Loss: (0.3807) |  Loss2: (0.0000) | Acc: (87.00%) (13485/15488)
Epoch: 53 | Batch_idx: 130 |  Loss: (0.3815) |  Loss2: (0.0000) | Acc: (86.00%) (14588/16768)
Epoch: 53 | Batch_idx: 140 |  Loss: (0.3825) |  Loss2: (0.0000) | Acc: (86.00%) (15686/18048)
Epoch: 53 | Batch_idx: 150 |  Loss: (0.3803) |  Loss2: (0.0000) | Acc: (86.00%) (16809/19328)
Epoch: 53 | Batch_idx: 160 |  Loss: (0.3804) |  Loss2: (0.0000) | Acc: (86.00%) (17919/20608)
Epoch: 53 | Batch_idx: 170 |  Loss: (0.3787) |  Loss2: (0.0000) | Acc: (87.00%) (19044/21888)
Epoch: 53 | Batch_idx: 180 |  Loss: (0.3790) |  Loss2: (0.0000) | Acc: (86.00%) (20140/23168)
Epoch: 53 | Batch_idx: 190 |  Loss: (0.3798) |  Loss2: (0.0000) | Acc: (86.00%) (21243/24448)
Epoch: 53 | Batch_idx: 200 |  Loss: (0.3793) |  Loss2: (0.0000) | Acc: (86.00%) (22362/25728)
Epoch: 53 | Batch_idx: 210 |  Loss: (0.3799) |  Loss2: (0.0000) | Acc: (86.00%) (23474/27008)
Epoch: 53 | Batch_idx: 220 |  Loss: (0.3806) |  Loss2: (0.0000) | Acc: (86.00%) (24581/28288)
Epoch: 53 | Batch_idx: 230 |  Loss: (0.3811) |  Loss2: (0.0000) | Acc: (86.00%) (25682/29568)
Epoch: 53 | Batch_idx: 240 |  Loss: (0.3827) |  Loss2: (0.0000) | Acc: (86.00%) (26774/30848)
Epoch: 53 | Batch_idx: 250 |  Loss: (0.3811) |  Loss2: (0.0000) | Acc: (86.00%) (27910/32128)
Epoch: 53 | Batch_idx: 260 |  Loss: (0.3813) |  Loss2: (0.0000) | Acc: (86.00%) (29021/33408)
Epoch: 53 | Batch_idx: 270 |  Loss: (0.3817) |  Loss2: (0.0000) | Acc: (86.00%) (30122/34688)
Epoch: 53 | Batch_idx: 280 |  Loss: (0.3814) |  Loss2: (0.0000) | Acc: (86.00%) (31241/35968)
Epoch: 53 | Batch_idx: 290 |  Loss: (0.3805) |  Loss2: (0.0000) | Acc: (86.00%) (32366/37248)
Epoch: 53 | Batch_idx: 300 |  Loss: (0.3802) |  Loss2: (0.0000) | Acc: (86.00%) (33483/38528)
Epoch: 53 | Batch_idx: 310 |  Loss: (0.3794) |  Loss2: (0.0000) | Acc: (86.00%) (34608/39808)
Epoch: 53 | Batch_idx: 320 |  Loss: (0.3796) |  Loss2: (0.0000) | Acc: (86.00%) (35722/41088)
Epoch: 53 | Batch_idx: 330 |  Loss: (0.3791) |  Loss2: (0.0000) | Acc: (86.00%) (36846/42368)
Epoch: 53 | Batch_idx: 340 |  Loss: (0.3786) |  Loss2: (0.0000) | Acc: (86.00%) (37958/43648)
Epoch: 53 | Batch_idx: 350 |  Loss: (0.3795) |  Loss2: (0.0000) | Acc: (86.00%) (39049/44928)
Epoch: 53 | Batch_idx: 360 |  Loss: (0.3782) |  Loss2: (0.0000) | Acc: (86.00%) (40177/46208)
Epoch: 53 | Batch_idx: 370 |  Loss: (0.3788) |  Loss2: (0.0000) | Acc: (86.00%) (41269/47488)
Epoch: 53 | Batch_idx: 380 |  Loss: (0.3784) |  Loss2: (0.0000) | Acc: (86.00%) (42387/48768)
Epoch: 53 | Batch_idx: 390 |  Loss: (0.3773) |  Loss2: (0.0000) | Acc: (86.00%) (43490/50000)
# TEST : Loss: (0.5243) | Acc: (82.00%) (8267/10000)
percent tensor([0.4770, 0.4803, 0.4992, 0.4827, 0.4962, 0.4760, 0.4855, 0.4831, 0.4769,
        0.4871, 0.4772, 0.4953, 0.4772, 0.4726, 0.4809, 0.4751],
       device='cuda:0') torch.Size([16])
percent tensor([0.4667, 0.4485, 0.4815, 0.4767, 0.4656, 0.4845, 0.4526, 0.4657, 0.4634,
        0.4581, 0.4598, 0.4658, 0.4515, 0.4633, 0.4567, 0.4678],
       device='cuda:0') torch.Size([16])
percent tensor([0.5758, 0.5757, 0.5122, 0.4927, 0.5319, 0.5786, 0.5876, 0.5191, 0.5288,
        0.5644, 0.5605, 0.5250, 0.5669, 0.5362, 0.5901, 0.5709],
       device='cuda:0') torch.Size([16])
percent tensor([0.5993, 0.5883, 0.6198, 0.6225, 0.6133, 0.6003, 0.6050, 0.6189, 0.6119,
        0.5939, 0.5949, 0.6179, 0.5838, 0.6182, 0.6022, 0.5987],
       device='cuda:0') torch.Size([16])
percent tensor([0.5232, 0.5657, 0.5243, 0.5126, 0.5255, 0.5089, 0.5516, 0.4793, 0.5813,
        0.5791, 0.5843, 0.5305, 0.5541, 0.6261, 0.4743, 0.5473],
       device='cuda:0') torch.Size([16])
percent tensor([0.5830, 0.5816, 0.6032, 0.6152, 0.6124, 0.6013, 0.6043, 0.5952, 0.6071,
        0.5971, 0.5988, 0.6106, 0.5872, 0.6283, 0.5777, 0.6114],
       device='cuda:0') torch.Size([16])
percent tensor([0.6208, 0.6114, 0.6001, 0.5930, 0.5814, 0.5931, 0.6025, 0.5381, 0.6295,
        0.6243, 0.6389, 0.6222, 0.6613, 0.6415, 0.5496, 0.5899],
       device='cuda:0') torch.Size([16])
percent tensor([0.9849, 0.9860, 0.9845, 0.9837, 0.9763, 0.9850, 0.9767, 0.9832, 0.9865,
        0.9888, 0.9927, 0.9855, 0.9834, 0.9840, 0.9729, 0.9820],
       device='cuda:0') torch.Size([16])
Epoch: 54 | Batch_idx: 0 |  Loss: (0.4361) |  Loss2: (0.0000) | Acc: (85.00%) (109/128)
Epoch: 54 | Batch_idx: 10 |  Loss: (0.3537) |  Loss2: (0.0000) | Acc: (87.00%) (1235/1408)
Epoch: 54 | Batch_idx: 20 |  Loss: (0.3723) |  Loss2: (0.0000) | Acc: (86.00%) (2327/2688)
Epoch: 54 | Batch_idx: 30 |  Loss: (0.3705) |  Loss2: (0.0000) | Acc: (86.00%) (3446/3968)
Epoch: 54 | Batch_idx: 40 |  Loss: (0.3728) |  Loss2: (0.0000) | Acc: (86.00%) (4558/5248)
Epoch: 54 | Batch_idx: 50 |  Loss: (0.3629) |  Loss2: (0.0000) | Acc: (87.00%) (5680/6528)
Epoch: 54 | Batch_idx: 60 |  Loss: (0.3674) |  Loss2: (0.0000) | Acc: (86.00%) (6785/7808)
Epoch: 54 | Batch_idx: 70 |  Loss: (0.3704) |  Loss2: (0.0000) | Acc: (86.00%) (7899/9088)
Epoch: 54 | Batch_idx: 80 |  Loss: (0.3709) |  Loss2: (0.0000) | Acc: (87.00%) (9022/10368)
Epoch: 54 | Batch_idx: 90 |  Loss: (0.3708) |  Loss2: (0.0000) | Acc: (87.00%) (10139/11648)
Epoch: 54 | Batch_idx: 100 |  Loss: (0.3695) |  Loss2: (0.0000) | Acc: (87.00%) (11256/12928)
Epoch: 54 | Batch_idx: 110 |  Loss: (0.3696) |  Loss2: (0.0000) | Acc: (87.00%) (12390/14208)
Epoch: 54 | Batch_idx: 120 |  Loss: (0.3712) |  Loss2: (0.0000) | Acc: (87.00%) (13498/15488)
Epoch: 54 | Batch_idx: 130 |  Loss: (0.3731) |  Loss2: (0.0000) | Acc: (87.00%) (14608/16768)
Epoch: 54 | Batch_idx: 140 |  Loss: (0.3756) |  Loss2: (0.0000) | Acc: (87.00%) (15702/18048)
Epoch: 54 | Batch_idx: 150 |  Loss: (0.3734) |  Loss2: (0.0000) | Acc: (87.00%) (16840/19328)
Epoch: 54 | Batch_idx: 160 |  Loss: (0.3720) |  Loss2: (0.0000) | Acc: (87.00%) (17970/20608)
Epoch: 54 | Batch_idx: 170 |  Loss: (0.3724) |  Loss2: (0.0000) | Acc: (87.00%) (19078/21888)
Epoch: 54 | Batch_idx: 180 |  Loss: (0.3734) |  Loss2: (0.0000) | Acc: (87.00%) (20185/23168)
Epoch: 54 | Batch_idx: 190 |  Loss: (0.3735) |  Loss2: (0.0000) | Acc: (87.00%) (21305/24448)
Epoch: 54 | Batch_idx: 200 |  Loss: (0.3737) |  Loss2: (0.0000) | Acc: (87.00%) (22427/25728)
Epoch: 54 | Batch_idx: 210 |  Loss: (0.3729) |  Loss2: (0.0000) | Acc: (87.00%) (23552/27008)
Epoch: 54 | Batch_idx: 220 |  Loss: (0.3740) |  Loss2: (0.0000) | Acc: (87.00%) (24657/28288)
Epoch: 54 | Batch_idx: 230 |  Loss: (0.3726) |  Loss2: (0.0000) | Acc: (87.00%) (25780/29568)
Epoch: 54 | Batch_idx: 240 |  Loss: (0.3732) |  Loss2: (0.0000) | Acc: (87.00%) (26894/30848)
Epoch: 54 | Batch_idx: 250 |  Loss: (0.3714) |  Loss2: (0.0000) | Acc: (87.00%) (28028/32128)
Epoch: 54 | Batch_idx: 260 |  Loss: (0.3723) |  Loss2: (0.0000) | Acc: (87.00%) (29138/33408)
Epoch: 54 | Batch_idx: 270 |  Loss: (0.3731) |  Loss2: (0.0000) | Acc: (87.00%) (30239/34688)
Epoch: 54 | Batch_idx: 280 |  Loss: (0.3726) |  Loss2: (0.0000) | Acc: (87.00%) (31371/35968)
Epoch: 54 | Batch_idx: 290 |  Loss: (0.3727) |  Loss2: (0.0000) | Acc: (87.00%) (32481/37248)
Epoch: 54 | Batch_idx: 300 |  Loss: (0.3722) |  Loss2: (0.0000) | Acc: (87.00%) (33616/38528)
Epoch: 54 | Batch_idx: 310 |  Loss: (0.3724) |  Loss2: (0.0000) | Acc: (87.00%) (34745/39808)
Epoch: 54 | Batch_idx: 320 |  Loss: (0.3727) |  Loss2: (0.0000) | Acc: (87.00%) (35857/41088)
Epoch: 54 | Batch_idx: 330 |  Loss: (0.3727) |  Loss2: (0.0000) | Acc: (87.00%) (36968/42368)
Epoch: 54 | Batch_idx: 340 |  Loss: (0.3720) |  Loss2: (0.0000) | Acc: (87.00%) (38087/43648)
Epoch: 54 | Batch_idx: 350 |  Loss: (0.3722) |  Loss2: (0.0000) | Acc: (87.00%) (39204/44928)
Epoch: 54 | Batch_idx: 360 |  Loss: (0.3730) |  Loss2: (0.0000) | Acc: (87.00%) (40302/46208)
Epoch: 54 | Batch_idx: 370 |  Loss: (0.3725) |  Loss2: (0.0000) | Acc: (87.00%) (41427/47488)
Epoch: 54 | Batch_idx: 380 |  Loss: (0.3725) |  Loss2: (0.0000) | Acc: (87.00%) (42546/48768)
Epoch: 54 | Batch_idx: 390 |  Loss: (0.3723) |  Loss2: (0.0000) | Acc: (87.00%) (43615/50000)
# TEST : Loss: (0.5080) | Acc: (83.00%) (8308/10000)
percent tensor([0.4775, 0.4798, 0.5009, 0.4830, 0.4979, 0.4766, 0.4851, 0.4832, 0.4767,
        0.4872, 0.4770, 0.4958, 0.4772, 0.4714, 0.4809, 0.4752],
       device='cuda:0') torch.Size([16])
percent tensor([0.4658, 0.4480, 0.4786, 0.4746, 0.4644, 0.4848, 0.4510, 0.4638, 0.4625,
        0.4569, 0.4571, 0.4625, 0.4501, 0.4641, 0.4547, 0.4678],
       device='cuda:0') torch.Size([16])
percent tensor([0.5688, 0.5786, 0.5102, 0.4996, 0.5239, 0.5614, 0.5841, 0.5262, 0.5106,
        0.5616, 0.5483, 0.5242, 0.5588, 0.5342, 0.5912, 0.5700],
       device='cuda:0') torch.Size([16])
percent tensor([0.5990, 0.5856, 0.6109, 0.6162, 0.6092, 0.6142, 0.6049, 0.6101, 0.6111,
        0.5892, 0.5968, 0.6137, 0.5834, 0.6209, 0.6032, 0.5980],
       device='cuda:0') torch.Size([16])
percent tensor([0.5292, 0.5663, 0.5135, 0.5191, 0.5229, 0.5170, 0.5475, 0.4844, 0.5723,
        0.5674, 0.5772, 0.5030, 0.5509, 0.6228, 0.4761, 0.5477],
       device='cuda:0') torch.Size([16])
percent tensor([0.5774, 0.5782, 0.6020, 0.6150, 0.6148, 0.5979, 0.6006, 0.5936, 0.5974,
        0.5898, 0.5949, 0.6071, 0.5806, 0.6263, 0.5759, 0.6072],
       device='cuda:0') torch.Size([16])
percent tensor([0.6269, 0.6208, 0.5997, 0.6068, 0.5885, 0.5800, 0.5934, 0.5278, 0.6222,
        0.6407, 0.6416, 0.6301, 0.6597, 0.6418, 0.5469, 0.6064],
       device='cuda:0') torch.Size([16])
percent tensor([0.9871, 0.9888, 0.9861, 0.9891, 0.9830, 0.9837, 0.9779, 0.9789, 0.9861,
        0.9934, 0.9927, 0.9906, 0.9884, 0.9878, 0.9702, 0.9850],
       device='cuda:0') torch.Size([16])
Epoch: 55 | Batch_idx: 0 |  Loss: (0.2692) |  Loss2: (0.0000) | Acc: (89.00%) (115/128)
Epoch: 55 | Batch_idx: 10 |  Loss: (0.3569) |  Loss2: (0.0000) | Acc: (87.00%) (1230/1408)
Epoch: 55 | Batch_idx: 20 |  Loss: (0.3368) |  Loss2: (0.0000) | Acc: (88.00%) (2372/2688)
Epoch: 55 | Batch_idx: 30 |  Loss: (0.3407) |  Loss2: (0.0000) | Acc: (88.00%) (3503/3968)
Epoch: 55 | Batch_idx: 40 |  Loss: (0.3419) |  Loss2: (0.0000) | Acc: (88.00%) (4643/5248)
Epoch: 55 | Batch_idx: 50 |  Loss: (0.3444) |  Loss2: (0.0000) | Acc: (88.00%) (5784/6528)
Epoch: 55 | Batch_idx: 60 |  Loss: (0.3473) |  Loss2: (0.0000) | Acc: (88.00%) (6906/7808)
Epoch: 55 | Batch_idx: 70 |  Loss: (0.3504) |  Loss2: (0.0000) | Acc: (88.00%) (8024/9088)
Epoch: 55 | Batch_idx: 80 |  Loss: (0.3505) |  Loss2: (0.0000) | Acc: (88.00%) (9147/10368)
Epoch: 55 | Batch_idx: 90 |  Loss: (0.3547) |  Loss2: (0.0000) | Acc: (88.00%) (10256/11648)
Epoch: 55 | Batch_idx: 100 |  Loss: (0.3528) |  Loss2: (0.0000) | Acc: (87.00%) (11376/12928)
Epoch: 55 | Batch_idx: 110 |  Loss: (0.3544) |  Loss2: (0.0000) | Acc: (87.00%) (12502/14208)
Epoch: 55 | Batch_idx: 120 |  Loss: (0.3573) |  Loss2: (0.0000) | Acc: (87.00%) (13622/15488)
Epoch: 55 | Batch_idx: 130 |  Loss: (0.3549) |  Loss2: (0.0000) | Acc: (88.00%) (14762/16768)
Epoch: 55 | Batch_idx: 140 |  Loss: (0.3569) |  Loss2: (0.0000) | Acc: (87.00%) (15874/18048)
Epoch: 55 | Batch_idx: 150 |  Loss: (0.3570) |  Loss2: (0.0000) | Acc: (87.00%) (16994/19328)
Epoch: 55 | Batch_idx: 160 |  Loss: (0.3574) |  Loss2: (0.0000) | Acc: (87.00%) (18115/20608)
Epoch: 55 | Batch_idx: 170 |  Loss: (0.3574) |  Loss2: (0.0000) | Acc: (87.00%) (19234/21888)
Epoch: 55 | Batch_idx: 180 |  Loss: (0.3563) |  Loss2: (0.0000) | Acc: (87.00%) (20349/23168)
Epoch: 55 | Batch_idx: 190 |  Loss: (0.3553) |  Loss2: (0.0000) | Acc: (87.00%) (21475/24448)
Epoch: 55 | Batch_idx: 200 |  Loss: (0.3563) |  Loss2: (0.0000) | Acc: (87.00%) (22596/25728)
Epoch: 55 | Batch_idx: 210 |  Loss: (0.3561) |  Loss2: (0.0000) | Acc: (87.00%) (23711/27008)
Epoch: 55 | Batch_idx: 220 |  Loss: (0.3564) |  Loss2: (0.0000) | Acc: (87.00%) (24823/28288)
Epoch: 55 | Batch_idx: 230 |  Loss: (0.3554) |  Loss2: (0.0000) | Acc: (87.00%) (25966/29568)
Epoch: 55 | Batch_idx: 240 |  Loss: (0.3567) |  Loss2: (0.0000) | Acc: (87.00%) (27079/30848)
Epoch: 55 | Batch_idx: 250 |  Loss: (0.3567) |  Loss2: (0.0000) | Acc: (87.00%) (28197/32128)
Epoch: 55 | Batch_idx: 260 |  Loss: (0.3558) |  Loss2: (0.0000) | Acc: (87.00%) (29329/33408)
Epoch: 55 | Batch_idx: 270 |  Loss: (0.3570) |  Loss2: (0.0000) | Acc: (87.00%) (30428/34688)
Epoch: 55 | Batch_idx: 280 |  Loss: (0.3566) |  Loss2: (0.0000) | Acc: (87.00%) (31548/35968)
Epoch: 55 | Batch_idx: 290 |  Loss: (0.3568) |  Loss2: (0.0000) | Acc: (87.00%) (32678/37248)
Epoch: 55 | Batch_idx: 300 |  Loss: (0.3579) |  Loss2: (0.0000) | Acc: (87.00%) (33779/38528)
Epoch: 55 | Batch_idx: 310 |  Loss: (0.3587) |  Loss2: (0.0000) | Acc: (87.00%) (34886/39808)
Epoch: 55 | Batch_idx: 320 |  Loss: (0.3593) |  Loss2: (0.0000) | Acc: (87.00%) (36007/41088)
Epoch: 55 | Batch_idx: 330 |  Loss: (0.3583) |  Loss2: (0.0000) | Acc: (87.00%) (37130/42368)
Epoch: 55 | Batch_idx: 340 |  Loss: (0.3583) |  Loss2: (0.0000) | Acc: (87.00%) (38257/43648)
Epoch: 55 | Batch_idx: 350 |  Loss: (0.3586) |  Loss2: (0.0000) | Acc: (87.00%) (39367/44928)
Epoch: 55 | Batch_idx: 360 |  Loss: (0.3587) |  Loss2: (0.0000) | Acc: (87.00%) (40480/46208)
Epoch: 55 | Batch_idx: 370 |  Loss: (0.3596) |  Loss2: (0.0000) | Acc: (87.00%) (41601/47488)
Epoch: 55 | Batch_idx: 380 |  Loss: (0.3596) |  Loss2: (0.0000) | Acc: (87.00%) (42722/48768)
Epoch: 55 | Batch_idx: 390 |  Loss: (0.3606) |  Loss2: (0.0000) | Acc: (87.00%) (43780/50000)
=> saving checkpoint 'drive/app/torch/save_Schedule/checkpoint_055.pth.tar'
# TEST : Loss: (0.4692) | Acc: (84.00%) (8424/10000)
percent tensor([0.4782, 0.4801, 0.4983, 0.4818, 0.4964, 0.4772, 0.4858, 0.4815, 0.4772,
        0.4869, 0.4779, 0.4951, 0.4776, 0.4723, 0.4810, 0.4755],
       device='cuda:0') torch.Size([16])
percent tensor([0.4647, 0.4483, 0.4803, 0.4778, 0.4633, 0.4819, 0.4505, 0.4654, 0.4637,
        0.4576, 0.4583, 0.4647, 0.4503, 0.4643, 0.4551, 0.4667],
       device='cuda:0') torch.Size([16])
percent tensor([0.5746, 0.5781, 0.5098, 0.4954, 0.5268, 0.5678, 0.5866, 0.5231, 0.5201,
        0.5617, 0.5562, 0.5223, 0.5650, 0.5537, 0.5894, 0.5736],
       device='cuda:0') torch.Size([16])
percent tensor([0.5980, 0.5879, 0.6146, 0.6229, 0.6128, 0.6056, 0.6066, 0.6164, 0.6183,
        0.5950, 0.5980, 0.6178, 0.5837, 0.6208, 0.6021, 0.6006],
       device='cuda:0') torch.Size([16])
percent tensor([0.5275, 0.5661, 0.5106, 0.5120, 0.5174, 0.5233, 0.5400, 0.4805, 0.5725,
        0.5742, 0.5833, 0.5033, 0.5494, 0.6256, 0.4799, 0.5562],
       device='cuda:0') torch.Size([16])
percent tensor([0.5799, 0.5789, 0.6097, 0.6184, 0.6194, 0.5994, 0.6042, 0.6001, 0.6039,
        0.5934, 0.5963, 0.6075, 0.5768, 0.6271, 0.5752, 0.6100],
       device='cuda:0') torch.Size([16])
percent tensor([0.6355, 0.6278, 0.6210, 0.6002, 0.5964, 0.5945, 0.6043, 0.5387, 0.6381,
        0.6440, 0.6551, 0.6349, 0.6714, 0.6428, 0.5555, 0.6066],
       device='cuda:0') torch.Size([16])
percent tensor([0.9878, 0.9865, 0.9894, 0.9856, 0.9816, 0.9844, 0.9756, 0.9861, 0.9921,
        0.9946, 0.9960, 0.9908, 0.9917, 0.9811, 0.9712, 0.9865],
       device='cuda:0') torch.Size([16])
False Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=128, out_features=16, bias=False)
True Linear(in_features=16, out_features=2, bias=False)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=128, out_features=16, bias=False)
True Linear(in_features=16, out_features=2, bias=False)
False Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=256, out_features=32, bias=False)
True Linear(in_features=32, out_features=2, bias=False)
False Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=256, out_features=32, bias=False)
True Linear(in_features=32, out_features=2, bias=False)
False Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=512, out_features=64, bias=False)
True Linear(in_features=64, out_features=2, bias=False)
False Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=512, out_features=64, bias=False)
True Linear(in_features=64, out_features=2, bias=False)
False Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1024, out_features=128, bias=False)
True Linear(in_features=128, out_features=2, bias=False)
False Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1024, out_features=128, bias=False)
True Linear(in_features=128, out_features=2, bias=False)
False Linear(in_features=512, out_features=10, bias=True)
Epoch: 56 | Batch_idx: 0 |  Loss: (0.2962) |  Loss2: (0.0000) | Acc: (91.00%) (117/128)
Epoch: 56 | Batch_idx: 10 |  Loss: (0.3781) |  Loss2: (0.0000) | Acc: (87.00%) (1231/1408)
Epoch: 56 | Batch_idx: 20 |  Loss: (0.4204) |  Loss2: (0.0000) | Acc: (85.00%) (2301/2688)
Epoch: 56 | Batch_idx: 30 |  Loss: (0.4453) |  Loss2: (0.0000) | Acc: (84.00%) (3350/3968)
Epoch: 56 | Batch_idx: 40 |  Loss: (0.4731) |  Loss2: (0.0000) | Acc: (83.00%) (4368/5248)
Epoch: 56 | Batch_idx: 50 |  Loss: (0.4727) |  Loss2: (0.0000) | Acc: (83.00%) (5433/6528)
Epoch: 56 | Batch_idx: 60 |  Loss: (0.4814) |  Loss2: (0.0000) | Acc: (83.00%) (6486/7808)
Epoch: 56 | Batch_idx: 70 |  Loss: (0.4796) |  Loss2: (0.0000) | Acc: (83.00%) (7559/9088)
Epoch: 56 | Batch_idx: 80 |  Loss: (0.4777) |  Loss2: (0.0000) | Acc: (83.00%) (8625/10368)
Epoch: 56 | Batch_idx: 90 |  Loss: (0.4827) |  Loss2: (0.0000) | Acc: (83.00%) (9678/11648)
Epoch: 56 | Batch_idx: 100 |  Loss: (0.4814) |  Loss2: (0.0000) | Acc: (83.00%) (10745/12928)
Epoch: 56 | Batch_idx: 110 |  Loss: (0.4781) |  Loss2: (0.0000) | Acc: (83.00%) (11820/14208)
Epoch: 56 | Batch_idx: 120 |  Loss: (0.4796) |  Loss2: (0.0000) | Acc: (83.00%) (12884/15488)
Epoch: 56 | Batch_idx: 130 |  Loss: (0.4809) |  Loss2: (0.0000) | Acc: (83.00%) (13952/16768)
Epoch: 56 | Batch_idx: 140 |  Loss: (0.4778) |  Loss2: (0.0000) | Acc: (83.00%) (15036/18048)
Epoch: 56 | Batch_idx: 150 |  Loss: (0.4787) |  Loss2: (0.0000) | Acc: (83.00%) (16092/19328)
Epoch: 56 | Batch_idx: 160 |  Loss: (0.4796) |  Loss2: (0.0000) | Acc: (83.00%) (17150/20608)
Epoch: 56 | Batch_idx: 170 |  Loss: (0.4764) |  Loss2: (0.0000) | Acc: (83.00%) (18227/21888)
Epoch: 56 | Batch_idx: 180 |  Loss: (0.4756) |  Loss2: (0.0000) | Acc: (83.00%) (19300/23168)
Epoch: 56 | Batch_idx: 190 |  Loss: (0.4760) |  Loss2: (0.0000) | Acc: (83.00%) (20362/24448)
Epoch: 56 | Batch_idx: 200 |  Loss: (0.4751) |  Loss2: (0.0000) | Acc: (83.00%) (21430/25728)
Epoch: 56 | Batch_idx: 210 |  Loss: (0.4745) |  Loss2: (0.0000) | Acc: (83.00%) (22498/27008)
Epoch: 56 | Batch_idx: 220 |  Loss: (0.4727) |  Loss2: (0.0000) | Acc: (83.00%) (23577/28288)
Epoch: 56 | Batch_idx: 230 |  Loss: (0.4710) |  Loss2: (0.0000) | Acc: (83.00%) (24653/29568)
Epoch: 56 | Batch_idx: 240 |  Loss: (0.4688) |  Loss2: (0.0000) | Acc: (83.00%) (25741/30848)
Epoch: 56 | Batch_idx: 250 |  Loss: (0.4685) |  Loss2: (0.0000) | Acc: (83.00%) (26801/32128)
Epoch: 56 | Batch_idx: 260 |  Loss: (0.4677) |  Loss2: (0.0000) | Acc: (83.00%) (27884/33408)
Epoch: 56 | Batch_idx: 270 |  Loss: (0.4664) |  Loss2: (0.0000) | Acc: (83.00%) (28973/34688)
Epoch: 56 | Batch_idx: 280 |  Loss: (0.4640) |  Loss2: (0.0000) | Acc: (83.00%) (30065/35968)
Epoch: 56 | Batch_idx: 290 |  Loss: (0.4627) |  Loss2: (0.0000) | Acc: (83.00%) (31146/37248)
Epoch: 56 | Batch_idx: 300 |  Loss: (0.4622) |  Loss2: (0.0000) | Acc: (83.00%) (32215/38528)
Epoch: 56 | Batch_idx: 310 |  Loss: (0.4604) |  Loss2: (0.0000) | Acc: (83.00%) (33310/39808)
Epoch: 56 | Batch_idx: 320 |  Loss: (0.4598) |  Loss2: (0.0000) | Acc: (83.00%) (34391/41088)
Epoch: 56 | Batch_idx: 330 |  Loss: (0.4591) |  Loss2: (0.0000) | Acc: (83.00%) (35482/42368)
Epoch: 56 | Batch_idx: 340 |  Loss: (0.4585) |  Loss2: (0.0000) | Acc: (83.00%) (36556/43648)
Epoch: 56 | Batch_idx: 350 |  Loss: (0.4577) |  Loss2: (0.0000) | Acc: (83.00%) (37647/44928)
Epoch: 56 | Batch_idx: 360 |  Loss: (0.4568) |  Loss2: (0.0000) | Acc: (83.00%) (38745/46208)
Epoch: 56 | Batch_idx: 370 |  Loss: (0.4559) |  Loss2: (0.0000) | Acc: (83.00%) (39833/47488)
Epoch: 56 | Batch_idx: 380 |  Loss: (0.4549) |  Loss2: (0.0000) | Acc: (83.00%) (40932/48768)
Epoch: 56 | Batch_idx: 390 |  Loss: (0.4533) |  Loss2: (0.0000) | Acc: (83.00%) (41990/50000)
# TEST : Loss: (0.5175) | Acc: (82.00%) (8222/10000)
percent tensor([0.4750, 0.4748, 0.4908, 0.4749, 0.4894, 0.4743, 0.4802, 0.4745, 0.4750,
        0.4810, 0.4751, 0.4881, 0.4742, 0.4715, 0.4760, 0.4732],
       device='cuda:0') torch.Size([16])
percent tensor([0.4840, 0.4658, 0.4886, 0.4959, 0.4795, 0.4969, 0.4659, 0.4818, 0.4814,
        0.4746, 0.4789, 0.4750, 0.4700, 0.4771, 0.4762, 0.4867],
       device='cuda:0') torch.Size([16])
percent tensor([0.5615, 0.5813, 0.5025, 0.4886, 0.5145, 0.5623, 0.5801, 0.5182, 0.5188,
        0.5514, 0.5512, 0.5119, 0.5547, 0.5700, 0.5865, 0.5645],
       device='cuda:0') torch.Size([16])
percent tensor([0.5778, 0.5648, 0.5956, 0.6143, 0.5944, 0.5994, 0.5796, 0.5935, 0.5982,
        0.5734, 0.5762, 0.5946, 0.5628, 0.5955, 0.5816, 0.5831],
       device='cuda:0') torch.Size([16])
percent tensor([0.5401, 0.5807, 0.5076, 0.5267, 0.5277, 0.5201, 0.5401, 0.5035, 0.5878,
        0.5859, 0.5964, 0.4931, 0.5576, 0.6614, 0.4838, 0.5694],
       device='cuda:0') torch.Size([16])
percent tensor([0.5283, 0.5235, 0.5657, 0.5818, 0.5795, 0.5567, 0.5444, 0.5538, 0.5472,
        0.5326, 0.5339, 0.5486, 0.5207, 0.5648, 0.5226, 0.5565],
       device='cuda:0') torch.Size([16])
percent tensor([0.5479, 0.5383, 0.5650, 0.5532, 0.5680, 0.4994, 0.5490, 0.5207, 0.5536,
        0.5610, 0.5563, 0.5663, 0.5532, 0.5534, 0.5060, 0.5344],
       device='cuda:0') torch.Size([16])
percent tensor([0.9873, 0.9856, 0.9884, 0.9837, 0.9819, 0.9799, 0.9710, 0.9837, 0.9922,
        0.9925, 0.9953, 0.9931, 0.9888, 0.9751, 0.9714, 0.9847],
       device='cuda:0') torch.Size([16])
Epoch: 57 | Batch_idx: 0 |  Loss: (0.4214) |  Loss2: (0.0000) | Acc: (84.00%) (108/128)
Epoch: 57 | Batch_idx: 10 |  Loss: (0.4216) |  Loss2: (0.0000) | Acc: (85.00%) (1209/1408)
Epoch: 57 | Batch_idx: 20 |  Loss: (0.4113) |  Loss2: (0.0000) | Acc: (86.00%) (2312/2688)
Epoch: 57 | Batch_idx: 30 |  Loss: (0.4084) |  Loss2: (0.0000) | Acc: (86.00%) (3414/3968)
Epoch: 57 | Batch_idx: 40 |  Loss: (0.4057) |  Loss2: (0.0000) | Acc: (85.00%) (4512/5248)
Epoch: 57 | Batch_idx: 50 |  Loss: (0.4076) |  Loss2: (0.0000) | Acc: (86.00%) (5620/6528)
Epoch: 57 | Batch_idx: 60 |  Loss: (0.4087) |  Loss2: (0.0000) | Acc: (85.00%) (6701/7808)
Epoch: 57 | Batch_idx: 70 |  Loss: (0.4076) |  Loss2: (0.0000) | Acc: (85.00%) (7802/9088)
Epoch: 57 | Batch_idx: 80 |  Loss: (0.4103) |  Loss2: (0.0000) | Acc: (85.00%) (8880/10368)
Epoch: 57 | Batch_idx: 90 |  Loss: (0.4134) |  Loss2: (0.0000) | Acc: (85.00%) (9971/11648)
Epoch: 57 | Batch_idx: 100 |  Loss: (0.4123) |  Loss2: (0.0000) | Acc: (85.00%) (11064/12928)
Epoch: 57 | Batch_idx: 110 |  Loss: (0.4155) |  Loss2: (0.0000) | Acc: (85.00%) (12140/14208)
Epoch: 57 | Batch_idx: 120 |  Loss: (0.4134) |  Loss2: (0.0000) | Acc: (85.00%) (13255/15488)
Epoch: 57 | Batch_idx: 130 |  Loss: (0.4128) |  Loss2: (0.0000) | Acc: (85.00%) (14348/16768)
Epoch: 57 | Batch_idx: 140 |  Loss: (0.4120) |  Loss2: (0.0000) | Acc: (85.00%) (15468/18048)
Epoch: 57 | Batch_idx: 150 |  Loss: (0.4107) |  Loss2: (0.0000) | Acc: (85.00%) (16583/19328)
Epoch: 57 | Batch_idx: 160 |  Loss: (0.4118) |  Loss2: (0.0000) | Acc: (85.00%) (17661/20608)
Epoch: 57 | Batch_idx: 170 |  Loss: (0.4119) |  Loss2: (0.0000) | Acc: (85.00%) (18752/21888)
Epoch: 57 | Batch_idx: 180 |  Loss: (0.4138) |  Loss2: (0.0000) | Acc: (85.00%) (19844/23168)
Epoch: 57 | Batch_idx: 190 |  Loss: (0.4142) |  Loss2: (0.0000) | Acc: (85.00%) (20940/24448)
Epoch: 57 | Batch_idx: 200 |  Loss: (0.4124) |  Loss2: (0.0000) | Acc: (85.00%) (22061/25728)
Epoch: 57 | Batch_idx: 210 |  Loss: (0.4128) |  Loss2: (0.0000) | Acc: (85.00%) (23148/27008)
Epoch: 57 | Batch_idx: 220 |  Loss: (0.4128) |  Loss2: (0.0000) | Acc: (85.00%) (24237/28288)
Epoch: 57 | Batch_idx: 230 |  Loss: (0.4123) |  Loss2: (0.0000) | Acc: (85.00%) (25336/29568)
Epoch: 57 | Batch_idx: 240 |  Loss: (0.4110) |  Loss2: (0.0000) | Acc: (85.00%) (26447/30848)
Epoch: 57 | Batch_idx: 250 |  Loss: (0.4105) |  Loss2: (0.0000) | Acc: (85.00%) (27554/32128)
Epoch: 57 | Batch_idx: 260 |  Loss: (0.4096) |  Loss2: (0.0000) | Acc: (85.00%) (28654/33408)
Epoch: 57 | Batch_idx: 270 |  Loss: (0.4096) |  Loss2: (0.0000) | Acc: (85.00%) (29736/34688)
Epoch: 57 | Batch_idx: 280 |  Loss: (0.4085) |  Loss2: (0.0000) | Acc: (85.00%) (30841/35968)
Epoch: 57 | Batch_idx: 290 |  Loss: (0.4070) |  Loss2: (0.0000) | Acc: (85.00%) (31961/37248)
Epoch: 57 | Batch_idx: 300 |  Loss: (0.4071) |  Loss2: (0.0000) | Acc: (85.00%) (33056/38528)
Epoch: 57 | Batch_idx: 310 |  Loss: (0.4062) |  Loss2: (0.0000) | Acc: (85.00%) (34170/39808)
Epoch: 57 | Batch_idx: 320 |  Loss: (0.4045) |  Loss2: (0.0000) | Acc: (85.00%) (35293/41088)
Epoch: 57 | Batch_idx: 330 |  Loss: (0.4034) |  Loss2: (0.0000) | Acc: (85.00%) (36400/42368)
Epoch: 57 | Batch_idx: 340 |  Loss: (0.4031) |  Loss2: (0.0000) | Acc: (85.00%) (37498/43648)
Epoch: 57 | Batch_idx: 350 |  Loss: (0.4033) |  Loss2: (0.0000) | Acc: (85.00%) (38586/44928)
Epoch: 57 | Batch_idx: 360 |  Loss: (0.4029) |  Loss2: (0.0000) | Acc: (85.00%) (39694/46208)
Epoch: 57 | Batch_idx: 370 |  Loss: (0.4035) |  Loss2: (0.0000) | Acc: (85.00%) (40776/47488)
Epoch: 57 | Batch_idx: 380 |  Loss: (0.4031) |  Loss2: (0.0000) | Acc: (85.00%) (41877/48768)
Epoch: 57 | Batch_idx: 390 |  Loss: (0.4035) |  Loss2: (0.0000) | Acc: (85.00%) (42936/50000)
# TEST : Loss: (0.4795) | Acc: (83.00%) (8358/10000)
percent tensor([0.4808, 0.4806, 0.4942, 0.4796, 0.4934, 0.4805, 0.4856, 0.4796, 0.4812,
        0.4859, 0.4815, 0.4923, 0.4803, 0.4779, 0.4819, 0.4791],
       device='cuda:0') torch.Size([16])
percent tensor([0.4865, 0.4678, 0.4890, 0.4968, 0.4803, 0.4994, 0.4672, 0.4820, 0.4834,
        0.4760, 0.4819, 0.4753, 0.4717, 0.4796, 0.4785, 0.4891],
       device='cuda:0') torch.Size([16])
percent tensor([0.5703, 0.5867, 0.5085, 0.4941, 0.5228, 0.5762, 0.5839, 0.5239, 0.5238,
        0.5566, 0.5570, 0.5159, 0.5631, 0.5699, 0.5956, 0.5725],
       device='cuda:0') torch.Size([16])
percent tensor([0.5788, 0.5654, 0.5945, 0.6165, 0.5930, 0.6066, 0.5787, 0.5926, 0.5991,
        0.5731, 0.5769, 0.5931, 0.5639, 0.5983, 0.5830, 0.5858],
       device='cuda:0') torch.Size([16])
percent tensor([0.5397, 0.5783, 0.5046, 0.5267, 0.5284, 0.5131, 0.5417, 0.5061, 0.5903,
        0.5870, 0.5986, 0.4887, 0.5531, 0.6674, 0.4790, 0.5705],
       device='cuda:0') torch.Size([16])
percent tensor([0.5307, 0.5209, 0.5746, 0.5915, 0.5923, 0.5649, 0.5482, 0.5632, 0.5498,
        0.5319, 0.5344, 0.5511, 0.5172, 0.5663, 0.5257, 0.5619],
       device='cuda:0') torch.Size([16])
percent tensor([0.5327, 0.5297, 0.5677, 0.5574, 0.5819, 0.4812, 0.5484, 0.5308, 0.5462,
        0.5585, 0.5457, 0.5728, 0.5336, 0.5461, 0.5053, 0.5236],
       device='cuda:0') torch.Size([16])
percent tensor([0.9899, 0.9879, 0.9904, 0.9870, 0.9862, 0.9834, 0.9768, 0.9871, 0.9936,
        0.9939, 0.9961, 0.9946, 0.9898, 0.9809, 0.9754, 0.9887],
       device='cuda:0') torch.Size([16])
Epoch: 58 | Batch_idx: 0 |  Loss: (0.3061) |  Loss2: (0.0000) | Acc: (90.00%) (116/128)
Epoch: 58 | Batch_idx: 10 |  Loss: (0.3544) |  Loss2: (0.0000) | Acc: (86.00%) (1223/1408)
Epoch: 58 | Batch_idx: 20 |  Loss: (0.3788) |  Loss2: (0.0000) | Acc: (86.00%) (2312/2688)
Epoch: 58 | Batch_idx: 30 |  Loss: (0.3820) |  Loss2: (0.0000) | Acc: (86.00%) (3413/3968)
Epoch: 58 | Batch_idx: 40 |  Loss: (0.3778) |  Loss2: (0.0000) | Acc: (86.00%) (4546/5248)
Epoch: 58 | Batch_idx: 50 |  Loss: (0.3760) |  Loss2: (0.0000) | Acc: (86.00%) (5662/6528)
Epoch: 58 | Batch_idx: 60 |  Loss: (0.3735) |  Loss2: (0.0000) | Acc: (86.00%) (6778/7808)
Epoch: 58 | Batch_idx: 70 |  Loss: (0.3716) |  Loss2: (0.0000) | Acc: (86.00%) (7902/9088)
Epoch: 58 | Batch_idx: 80 |  Loss: (0.3730) |  Loss2: (0.0000) | Acc: (86.00%) (9000/10368)
Epoch: 58 | Batch_idx: 90 |  Loss: (0.3734) |  Loss2: (0.0000) | Acc: (86.00%) (10110/11648)
Epoch: 58 | Batch_idx: 100 |  Loss: (0.3751) |  Loss2: (0.0000) | Acc: (86.00%) (11215/12928)
Epoch: 58 | Batch_idx: 110 |  Loss: (0.3764) |  Loss2: (0.0000) | Acc: (86.00%) (12316/14208)
Epoch: 58 | Batch_idx: 120 |  Loss: (0.3768) |  Loss2: (0.0000) | Acc: (86.00%) (13413/15488)
Epoch: 58 | Batch_idx: 130 |  Loss: (0.3788) |  Loss2: (0.0000) | Acc: (86.00%) (14507/16768)
Epoch: 58 | Batch_idx: 140 |  Loss: (0.3803) |  Loss2: (0.0000) | Acc: (86.00%) (15621/18048)
Epoch: 58 | Batch_idx: 150 |  Loss: (0.3787) |  Loss2: (0.0000) | Acc: (86.00%) (16735/19328)
Epoch: 58 | Batch_idx: 160 |  Loss: (0.3796) |  Loss2: (0.0000) | Acc: (86.00%) (17840/20608)
Epoch: 58 | Batch_idx: 170 |  Loss: (0.3812) |  Loss2: (0.0000) | Acc: (86.00%) (18939/21888)
Epoch: 58 | Batch_idx: 180 |  Loss: (0.3801) |  Loss2: (0.0000) | Acc: (86.00%) (20058/23168)
Epoch: 58 | Batch_idx: 190 |  Loss: (0.3788) |  Loss2: (0.0000) | Acc: (86.00%) (21168/24448)
Epoch: 58 | Batch_idx: 200 |  Loss: (0.3795) |  Loss2: (0.0000) | Acc: (86.00%) (22277/25728)
Epoch: 58 | Batch_idx: 210 |  Loss: (0.3788) |  Loss2: (0.0000) | Acc: (86.00%) (23397/27008)
Epoch: 58 | Batch_idx: 220 |  Loss: (0.3788) |  Loss2: (0.0000) | Acc: (86.00%) (24505/28288)
Epoch: 58 | Batch_idx: 230 |  Loss: (0.3785) |  Loss2: (0.0000) | Acc: (86.00%) (25624/29568)
Epoch: 58 | Batch_idx: 240 |  Loss: (0.3800) |  Loss2: (0.0000) | Acc: (86.00%) (26715/30848)
Epoch: 58 | Batch_idx: 250 |  Loss: (0.3793) |  Loss2: (0.0000) | Acc: (86.00%) (27849/32128)
Epoch: 58 | Batch_idx: 260 |  Loss: (0.3792) |  Loss2: (0.0000) | Acc: (86.00%) (28960/33408)
Epoch: 58 | Batch_idx: 270 |  Loss: (0.3786) |  Loss2: (0.0000) | Acc: (86.00%) (30083/34688)
Epoch: 58 | Batch_idx: 280 |  Loss: (0.3788) |  Loss2: (0.0000) | Acc: (86.00%) (31188/35968)
Epoch: 58 | Batch_idx: 290 |  Loss: (0.3792) |  Loss2: (0.0000) | Acc: (86.00%) (32286/37248)
Epoch: 58 | Batch_idx: 300 |  Loss: (0.3782) |  Loss2: (0.0000) | Acc: (86.00%) (33409/38528)
Epoch: 58 | Batch_idx: 310 |  Loss: (0.3780) |  Loss2: (0.0000) | Acc: (86.00%) (34516/39808)
Epoch: 58 | Batch_idx: 320 |  Loss: (0.3789) |  Loss2: (0.0000) | Acc: (86.00%) (35603/41088)
Epoch: 58 | Batch_idx: 330 |  Loss: (0.3782) |  Loss2: (0.0000) | Acc: (86.00%) (36719/42368)
Epoch: 58 | Batch_idx: 340 |  Loss: (0.3790) |  Loss2: (0.0000) | Acc: (86.00%) (37817/43648)
Epoch: 58 | Batch_idx: 350 |  Loss: (0.3789) |  Loss2: (0.0000) | Acc: (86.00%) (38942/44928)
Epoch: 58 | Batch_idx: 360 |  Loss: (0.3787) |  Loss2: (0.0000) | Acc: (86.00%) (40059/46208)
Epoch: 58 | Batch_idx: 370 |  Loss: (0.3789) |  Loss2: (0.0000) | Acc: (86.00%) (41172/47488)
Epoch: 58 | Batch_idx: 380 |  Loss: (0.3785) |  Loss2: (0.0000) | Acc: (86.00%) (42293/48768)
Epoch: 58 | Batch_idx: 390 |  Loss: (0.3784) |  Loss2: (0.0000) | Acc: (86.00%) (43366/50000)
# TEST : Loss: (0.4654) | Acc: (84.00%) (8409/10000)
percent tensor([0.4824, 0.4822, 0.4940, 0.4806, 0.4935, 0.4826, 0.4868, 0.4807, 0.4830,
        0.4869, 0.4835, 0.4927, 0.4823, 0.4805, 0.4835, 0.4813],
       device='cuda:0') torch.Size([16])
percent tensor([0.4868, 0.4672, 0.4878, 0.4965, 0.4786, 0.5003, 0.4660, 0.4801, 0.4833,
        0.4752, 0.4823, 0.4735, 0.4715, 0.4794, 0.4782, 0.4891],
       device='cuda:0') torch.Size([16])
percent tensor([0.5734, 0.5862, 0.5092, 0.4961, 0.5244, 0.5826, 0.5814, 0.5244, 0.5255,
        0.5557, 0.5587, 0.5146, 0.5649, 0.5692, 0.5961, 0.5744],
       device='cuda:0') torch.Size([16])
percent tensor([0.5842, 0.5700, 0.5980, 0.6226, 0.5960, 0.6159, 0.5825, 0.5965, 0.6042,
        0.5766, 0.5819, 0.5971, 0.5694, 0.6040, 0.5884, 0.5925],
       device='cuda:0') torch.Size([16])
percent tensor([0.5368, 0.5710, 0.5019, 0.5244, 0.5280, 0.5094, 0.5383, 0.5049, 0.5882,
        0.5830, 0.5936, 0.4823, 0.5455, 0.6672, 0.4723, 0.5693],
       device='cuda:0') torch.Size([16])
percent tensor([0.5355, 0.5208, 0.5845, 0.6014, 0.6048, 0.5756, 0.5526, 0.5729, 0.5548,
        0.5331, 0.5367, 0.5551, 0.5170, 0.5703, 0.5301, 0.5691],
       device='cuda:0') torch.Size([16])
percent tensor([0.5451, 0.5472, 0.5821, 0.5695, 0.6027, 0.4802, 0.5647, 0.5458, 0.5628,
        0.5807, 0.5634, 0.5957, 0.5459, 0.5603, 0.5187, 0.5297],
       device='cuda:0') torch.Size([16])
percent tensor([0.9928, 0.9907, 0.9926, 0.9899, 0.9902, 0.9870, 0.9822, 0.9901, 0.9954,
        0.9957, 0.9972, 0.9962, 0.9920, 0.9853, 0.9801, 0.9920],
       device='cuda:0') torch.Size([16])
Epoch: 59 | Batch_idx: 0 |  Loss: (0.4779) |  Loss2: (0.0000) | Acc: (83.00%) (107/128)
Epoch: 59 | Batch_idx: 10 |  Loss: (0.3599) |  Loss2: (0.0000) | Acc: (88.00%) (1240/1408)
Epoch: 59 | Batch_idx: 20 |  Loss: (0.3625) |  Loss2: (0.0000) | Acc: (88.00%) (2369/2688)
Epoch: 59 | Batch_idx: 30 |  Loss: (0.3748) |  Loss2: (0.0000) | Acc: (87.00%) (3461/3968)
Epoch: 59 | Batch_idx: 40 |  Loss: (0.3848) |  Loss2: (0.0000) | Acc: (86.00%) (4552/5248)
Epoch: 59 | Batch_idx: 50 |  Loss: (0.3856) |  Loss2: (0.0000) | Acc: (86.00%) (5660/6528)
Epoch: 59 | Batch_idx: 60 |  Loss: (0.3848) |  Loss2: (0.0000) | Acc: (86.00%) (6765/7808)
Epoch: 59 | Batch_idx: 70 |  Loss: (0.3772) |  Loss2: (0.0000) | Acc: (86.00%) (7898/9088)
Epoch: 59 | Batch_idx: 80 |  Loss: (0.3782) |  Loss2: (0.0000) | Acc: (86.00%) (8993/10368)
Epoch: 59 | Batch_idx: 90 |  Loss: (0.3776) |  Loss2: (0.0000) | Acc: (86.00%) (10119/11648)
Epoch: 59 | Batch_idx: 100 |  Loss: (0.3724) |  Loss2: (0.0000) | Acc: (87.00%) (11254/12928)
Epoch: 59 | Batch_idx: 110 |  Loss: (0.3746) |  Loss2: (0.0000) | Acc: (86.00%) (12346/14208)
Epoch: 59 | Batch_idx: 120 |  Loss: (0.3738) |  Loss2: (0.0000) | Acc: (86.00%) (13465/15488)
Epoch: 59 | Batch_idx: 130 |  Loss: (0.3737) |  Loss2: (0.0000) | Acc: (86.00%) (14584/16768)
Epoch: 59 | Batch_idx: 140 |  Loss: (0.3739) |  Loss2: (0.0000) | Acc: (86.00%) (15680/18048)
Epoch: 59 | Batch_idx: 150 |  Loss: (0.3741) |  Loss2: (0.0000) | Acc: (86.00%) (16799/19328)
Epoch: 59 | Batch_idx: 160 |  Loss: (0.3742) |  Loss2: (0.0000) | Acc: (86.00%) (17920/20608)
Epoch: 59 | Batch_idx: 170 |  Loss: (0.3724) |  Loss2: (0.0000) | Acc: (86.00%) (19042/21888)
Epoch: 59 | Batch_idx: 180 |  Loss: (0.3714) |  Loss2: (0.0000) | Acc: (86.00%) (20148/23168)
Epoch: 59 | Batch_idx: 190 |  Loss: (0.3704) |  Loss2: (0.0000) | Acc: (87.00%) (21275/24448)
Epoch: 59 | Batch_idx: 200 |  Loss: (0.3705) |  Loss2: (0.0000) | Acc: (86.00%) (22381/25728)
Epoch: 59 | Batch_idx: 210 |  Loss: (0.3700) |  Loss2: (0.0000) | Acc: (87.00%) (23499/27008)
Epoch: 59 | Batch_idx: 220 |  Loss: (0.3716) |  Loss2: (0.0000) | Acc: (86.00%) (24595/28288)
Epoch: 59 | Batch_idx: 230 |  Loss: (0.3706) |  Loss2: (0.0000) | Acc: (86.00%) (25723/29568)
Epoch: 59 | Batch_idx: 240 |  Loss: (0.3715) |  Loss2: (0.0000) | Acc: (87.00%) (26839/30848)
Epoch: 59 | Batch_idx: 250 |  Loss: (0.3710) |  Loss2: (0.0000) | Acc: (86.00%) (27950/32128)
Epoch: 59 | Batch_idx: 260 |  Loss: (0.3709) |  Loss2: (0.0000) | Acc: (87.00%) (29074/33408)
Epoch: 59 | Batch_idx: 270 |  Loss: (0.3705) |  Loss2: (0.0000) | Acc: (87.00%) (30195/34688)
Epoch: 59 | Batch_idx: 280 |  Loss: (0.3710) |  Loss2: (0.0000) | Acc: (87.00%) (31311/35968)
Epoch: 59 | Batch_idx: 290 |  Loss: (0.3710) |  Loss2: (0.0000) | Acc: (87.00%) (32432/37248)
Epoch: 59 | Batch_idx: 300 |  Loss: (0.3704) |  Loss2: (0.0000) | Acc: (87.00%) (33556/38528)
Epoch: 59 | Batch_idx: 310 |  Loss: (0.3704) |  Loss2: (0.0000) | Acc: (87.00%) (34688/39808)
Epoch: 59 | Batch_idx: 320 |  Loss: (0.3705) |  Loss2: (0.0000) | Acc: (87.00%) (35800/41088)
Epoch: 59 | Batch_idx: 330 |  Loss: (0.3707) |  Loss2: (0.0000) | Acc: (87.00%) (36915/42368)
Epoch: 59 | Batch_idx: 340 |  Loss: (0.3701) |  Loss2: (0.0000) | Acc: (87.00%) (38042/43648)
Epoch: 59 | Batch_idx: 350 |  Loss: (0.3698) |  Loss2: (0.0000) | Acc: (87.00%) (39154/44928)
Epoch: 59 | Batch_idx: 360 |  Loss: (0.3703) |  Loss2: (0.0000) | Acc: (87.00%) (40273/46208)
Epoch: 59 | Batch_idx: 370 |  Loss: (0.3697) |  Loss2: (0.0000) | Acc: (87.00%) (41390/47488)
Epoch: 59 | Batch_idx: 380 |  Loss: (0.3697) |  Loss2: (0.0000) | Acc: (87.00%) (42513/48768)
Epoch: 59 | Batch_idx: 390 |  Loss: (0.3698) |  Loss2: (0.0000) | Acc: (87.00%) (43579/50000)
# TEST : Loss: (0.4528) | Acc: (84.00%) (8467/10000)
percent tensor([0.4839, 0.4834, 0.4950, 0.4814, 0.4946, 0.4842, 0.4881, 0.4819, 0.4844,
        0.4879, 0.4850, 0.4938, 0.4838, 0.4818, 0.4848, 0.4826],
       device='cuda:0') torch.Size([16])
percent tensor([0.4892, 0.4698, 0.4882, 0.4970, 0.4795, 0.5018, 0.4681, 0.4811, 0.4855,
        0.4771, 0.4852, 0.4744, 0.4735, 0.4822, 0.4805, 0.4914],
       device='cuda:0') torch.Size([16])
percent tensor([0.5785, 0.5905, 0.5133, 0.5002, 0.5278, 0.5898, 0.5834, 0.5271, 0.5273,
        0.5598, 0.5622, 0.5182, 0.5705, 0.5713, 0.6003, 0.5795],
       device='cuda:0') torch.Size([16])
percent tensor([0.5851, 0.5711, 0.5975, 0.6235, 0.5951, 0.6192, 0.5823, 0.5957, 0.6049,
        0.5772, 0.5834, 0.5971, 0.5709, 0.6057, 0.5890, 0.5940],
       device='cuda:0') torch.Size([16])
percent tensor([0.5345, 0.5669, 0.5003, 0.5195, 0.5283, 0.5030, 0.5368, 0.5046, 0.5849,
        0.5813, 0.5900, 0.4791, 0.5440, 0.6609, 0.4685, 0.5664],
       device='cuda:0') torch.Size([16])
percent tensor([0.5432, 0.5236, 0.5967, 0.6138, 0.6203, 0.5885, 0.5602, 0.5861, 0.5621,
        0.5375, 0.5421, 0.5614, 0.5200, 0.5768, 0.5372, 0.5797],
       device='cuda:0') torch.Size([16])
percent tensor([0.5591, 0.5646, 0.5953, 0.5817, 0.6191, 0.4817, 0.5806, 0.5593, 0.5810,
        0.6014, 0.5839, 0.6166, 0.5609, 0.5758, 0.5345, 0.5368],
       device='cuda:0') torch.Size([16])
percent tensor([0.9946, 0.9924, 0.9938, 0.9919, 0.9922, 0.9897, 0.9856, 0.9916, 0.9964,
        0.9967, 0.9980, 0.9971, 0.9934, 0.9888, 0.9839, 0.9938],
       device='cuda:0') torch.Size([16])
Epoch: 60 | Batch_idx: 0 |  Loss: (0.3435) |  Loss2: (0.0000) | Acc: (88.00%) (113/128)
Epoch: 60 | Batch_idx: 10 |  Loss: (0.3942) |  Loss2: (0.0000) | Acc: (86.00%) (1222/1408)
Epoch: 60 | Batch_idx: 20 |  Loss: (0.3863) |  Loss2: (0.0000) | Acc: (87.00%) (2344/2688)
Epoch: 60 | Batch_idx: 30 |  Loss: (0.3808) |  Loss2: (0.0000) | Acc: (87.00%) (3464/3968)
Epoch: 60 | Batch_idx: 40 |  Loss: (0.3732) |  Loss2: (0.0000) | Acc: (87.00%) (4590/5248)
Epoch: 60 | Batch_idx: 50 |  Loss: (0.3701) |  Loss2: (0.0000) | Acc: (87.00%) (5716/6528)
Epoch: 60 | Batch_idx: 60 |  Loss: (0.3702) |  Loss2: (0.0000) | Acc: (87.00%) (6839/7808)
Epoch: 60 | Batch_idx: 70 |  Loss: (0.3683) |  Loss2: (0.0000) | Acc: (87.00%) (7964/9088)
Epoch: 60 | Batch_idx: 80 |  Loss: (0.3722) |  Loss2: (0.0000) | Acc: (87.00%) (9063/10368)
Epoch: 60 | Batch_idx: 90 |  Loss: (0.3726) |  Loss2: (0.0000) | Acc: (87.00%) (10179/11648)
Epoch: 60 | Batch_idx: 100 |  Loss: (0.3692) |  Loss2: (0.0000) | Acc: (87.00%) (11310/12928)
Epoch: 60 | Batch_idx: 110 |  Loss: (0.3709) |  Loss2: (0.0000) | Acc: (87.00%) (12426/14208)
Epoch: 60 | Batch_idx: 120 |  Loss: (0.3699) |  Loss2: (0.0000) | Acc: (87.00%) (13539/15488)
Epoch: 60 | Batch_idx: 130 |  Loss: (0.3671) |  Loss2: (0.0000) | Acc: (87.00%) (14668/16768)
Epoch: 60 | Batch_idx: 140 |  Loss: (0.3672) |  Loss2: (0.0000) | Acc: (87.00%) (15780/18048)
Epoch: 60 | Batch_idx: 150 |  Loss: (0.3680) |  Loss2: (0.0000) | Acc: (87.00%) (16885/19328)
Epoch: 60 | Batch_idx: 160 |  Loss: (0.3689) |  Loss2: (0.0000) | Acc: (87.00%) (17999/20608)
Epoch: 60 | Batch_idx: 170 |  Loss: (0.3677) |  Loss2: (0.0000) | Acc: (87.00%) (19142/21888)
Epoch: 60 | Batch_idx: 180 |  Loss: (0.3667) |  Loss2: (0.0000) | Acc: (87.00%) (20258/23168)
Epoch: 60 | Batch_idx: 190 |  Loss: (0.3666) |  Loss2: (0.0000) | Acc: (87.00%) (21366/24448)
Epoch: 60 | Batch_idx: 200 |  Loss: (0.3645) |  Loss2: (0.0000) | Acc: (87.00%) (22500/25728)
Epoch: 60 | Batch_idx: 210 |  Loss: (0.3650) |  Loss2: (0.0000) | Acc: (87.00%) (23601/27008)
Epoch: 60 | Batch_idx: 220 |  Loss: (0.3639) |  Loss2: (0.0000) | Acc: (87.00%) (24735/28288)
Epoch: 60 | Batch_idx: 230 |  Loss: (0.3643) |  Loss2: (0.0000) | Acc: (87.00%) (25841/29568)
Epoch: 60 | Batch_idx: 240 |  Loss: (0.3653) |  Loss2: (0.0000) | Acc: (87.00%) (26959/30848)
Epoch: 60 | Batch_idx: 250 |  Loss: (0.3653) |  Loss2: (0.0000) | Acc: (87.00%) (28091/32128)
Epoch: 60 | Batch_idx: 260 |  Loss: (0.3654) |  Loss2: (0.0000) | Acc: (87.00%) (29210/33408)
Epoch: 60 | Batch_idx: 270 |  Loss: (0.3653) |  Loss2: (0.0000) | Acc: (87.00%) (30335/34688)
Epoch: 60 | Batch_idx: 280 |  Loss: (0.3642) |  Loss2: (0.0000) | Acc: (87.00%) (31474/35968)
Epoch: 60 | Batch_idx: 290 |  Loss: (0.3630) |  Loss2: (0.0000) | Acc: (87.00%) (32611/37248)
Epoch: 60 | Batch_idx: 300 |  Loss: (0.3635) |  Loss2: (0.0000) | Acc: (87.00%) (33716/38528)
Epoch: 60 | Batch_idx: 310 |  Loss: (0.3631) |  Loss2: (0.0000) | Acc: (87.00%) (34839/39808)
Epoch: 60 | Batch_idx: 320 |  Loss: (0.3642) |  Loss2: (0.0000) | Acc: (87.00%) (35940/41088)
Epoch: 60 | Batch_idx: 330 |  Loss: (0.3638) |  Loss2: (0.0000) | Acc: (87.00%) (37053/42368)
Epoch: 60 | Batch_idx: 340 |  Loss: (0.3641) |  Loss2: (0.0000) | Acc: (87.00%) (38154/43648)
Epoch: 60 | Batch_idx: 350 |  Loss: (0.3643) |  Loss2: (0.0000) | Acc: (87.00%) (39270/44928)
Epoch: 60 | Batch_idx: 360 |  Loss: (0.3647) |  Loss2: (0.0000) | Acc: (87.00%) (40390/46208)
Epoch: 60 | Batch_idx: 370 |  Loss: (0.3650) |  Loss2: (0.0000) | Acc: (87.00%) (41507/47488)
Epoch: 60 | Batch_idx: 380 |  Loss: (0.3646) |  Loss2: (0.0000) | Acc: (87.00%) (42633/48768)
Epoch: 60 | Batch_idx: 390 |  Loss: (0.3645) |  Loss2: (0.0000) | Acc: (87.00%) (43706/50000)
=> saving checkpoint 'drive/app/torch/save_Schedule/checkpoint_060.pth.tar'
# TEST : Loss: (0.4461) | Acc: (84.00%) (8480/10000)
percent tensor([0.4849, 0.4843, 0.4952, 0.4820, 0.4949, 0.4853, 0.4888, 0.4827, 0.4853,
        0.4885, 0.4861, 0.4942, 0.4847, 0.4830, 0.4856, 0.4836],
       device='cuda:0') torch.Size([16])
percent tensor([0.4884, 0.4684, 0.4862, 0.4963, 0.4772, 0.5021, 0.4662, 0.4787, 0.4842,
        0.4754, 0.4845, 0.4720, 0.4722, 0.4814, 0.4792, 0.4904],
       device='cuda:0') torch.Size([16])
percent tensor([0.5814, 0.5923, 0.5147, 0.5018, 0.5295, 0.5937, 0.5839, 0.5278, 0.5290,
        0.5616, 0.5655, 0.5194, 0.5750, 0.5699, 0.6020, 0.5824],
       device='cuda:0') torch.Size([16])
percent tensor([0.5885, 0.5750, 0.6002, 0.6279, 0.5980, 0.6244, 0.5855, 0.5987, 0.6090,
        0.5804, 0.5871, 0.6007, 0.5747, 0.6109, 0.5926, 0.5981],
       device='cuda:0') torch.Size([16])
percent tensor([0.5386, 0.5715, 0.5010, 0.5211, 0.5327, 0.5045, 0.5421, 0.5073, 0.5897,
        0.5854, 0.5949, 0.4805, 0.5486, 0.6656, 0.4698, 0.5709],
       device='cuda:0') torch.Size([16])
percent tensor([0.5458, 0.5230, 0.6042, 0.6219, 0.6309, 0.5972, 0.5631, 0.5935, 0.5649,
        0.5372, 0.5433, 0.5632, 0.5197, 0.5798, 0.5390, 0.5856],
       device='cuda:0') torch.Size([16])
percent tensor([0.5699, 0.5780, 0.5994, 0.5845, 0.6248, 0.4821, 0.5907, 0.5605, 0.5962,
        0.6174, 0.6000, 0.6280, 0.5743, 0.5889, 0.5429, 0.5396],
       device='cuda:0') torch.Size([16])
percent tensor([0.9958, 0.9939, 0.9953, 0.9936, 0.9942, 0.9916, 0.9887, 0.9936, 0.9973,
        0.9975, 0.9985, 0.9979, 0.9946, 0.9916, 0.9870, 0.9954],
       device='cuda:0') torch.Size([16])
Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 3, 3, 3]) tensor(181.8890, device='cuda:0')
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(801.2604, device='cuda:0')
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(800.4089, device='cuda:0')
Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([128, 64, 3, 3]) tensor(1531.9901, device='cuda:0')
Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([128, 64, 1, 1]) tensor(498.2682, device='cuda:0')
Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([128, 128, 3, 3]) tensor(2226.9009, device='cuda:0')
Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([256, 128, 3, 3]) tensor(4295.7803, device='cuda:0')
Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([256, 128, 1, 1]) tensor(1411.3455, device='cuda:0')
Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([256, 256, 3, 3]) tensor(6095.7681, device='cuda:0')
Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([512, 256, 3, 3]) tensor(12016.5078, device='cuda:0')
Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([512, 256, 1, 1]) tensor(4002.4861, device='cuda:0')
Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([512, 512, 3, 3]) tensor(16917.4141, device='cuda:0')
Epoch: 61 | Batch_idx: 0 |  Loss: (0.2549) |  Loss2: (0.0000) | Acc: (90.00%) (116/128)
Epoch: 61 | Batch_idx: 10 |  Loss: (0.3578) |  Loss2: (0.0000) | Acc: (87.00%) (1229/1408)
Epoch: 61 | Batch_idx: 20 |  Loss: (0.3595) |  Loss2: (0.0000) | Acc: (87.00%) (2354/2688)
Epoch: 61 | Batch_idx: 30 |  Loss: (0.3634) |  Loss2: (0.0000) | Acc: (87.00%) (3474/3968)
Epoch: 61 | Batch_idx: 40 |  Loss: (0.3541) |  Loss2: (0.0000) | Acc: (88.00%) (4619/5248)
Epoch: 61 | Batch_idx: 50 |  Loss: (0.3603) |  Loss2: (0.0000) | Acc: (87.00%) (5726/6528)
Epoch: 61 | Batch_idx: 60 |  Loss: (0.3614) |  Loss2: (0.0000) | Acc: (87.00%) (6837/7808)
Epoch: 61 | Batch_idx: 70 |  Loss: (0.3629) |  Loss2: (0.0000) | Acc: (87.00%) (7949/9088)
Epoch: 61 | Batch_idx: 80 |  Loss: (0.3609) |  Loss2: (0.0000) | Acc: (87.00%) (9080/10368)
Epoch: 61 | Batch_idx: 90 |  Loss: (0.3586) |  Loss2: (0.0000) | Acc: (87.00%) (10213/11648)
Epoch: 61 | Batch_idx: 100 |  Loss: (0.3588) |  Loss2: (0.0000) | Acc: (87.00%) (11345/12928)
Epoch: 61 | Batch_idx: 110 |  Loss: (0.3567) |  Loss2: (0.0000) | Acc: (87.00%) (12480/14208)
Epoch: 61 | Batch_idx: 120 |  Loss: (0.3592) |  Loss2: (0.0000) | Acc: (87.00%) (13599/15488)
Epoch: 61 | Batch_idx: 130 |  Loss: (0.3617) |  Loss2: (0.0000) | Acc: (87.00%) (14714/16768)
Epoch: 61 | Batch_idx: 140 |  Loss: (0.3595) |  Loss2: (0.0000) | Acc: (87.00%) (15857/18048)
Epoch: 61 | Batch_idx: 150 |  Loss: (0.3608) |  Loss2: (0.0000) | Acc: (87.00%) (16977/19328)
Epoch: 61 | Batch_idx: 160 |  Loss: (0.3601) |  Loss2: (0.0000) | Acc: (87.00%) (18101/20608)
Epoch: 61 | Batch_idx: 170 |  Loss: (0.3620) |  Loss2: (0.0000) | Acc: (87.00%) (19199/21888)
Epoch: 61 | Batch_idx: 180 |  Loss: (0.3631) |  Loss2: (0.0000) | Acc: (87.00%) (20301/23168)
Epoch: 61 | Batch_idx: 190 |  Loss: (0.3636) |  Loss2: (0.0000) | Acc: (87.00%) (21416/24448)
Epoch: 61 | Batch_idx: 200 |  Loss: (0.3641) |  Loss2: (0.0000) | Acc: (87.00%) (22534/25728)
Epoch: 61 | Batch_idx: 210 |  Loss: (0.3638) |  Loss2: (0.0000) | Acc: (87.00%) (23658/27008)
Epoch: 61 | Batch_idx: 220 |  Loss: (0.3642) |  Loss2: (0.0000) | Acc: (87.00%) (24771/28288)
Epoch: 61 | Batch_idx: 230 |  Loss: (0.3663) |  Loss2: (0.0000) | Acc: (87.00%) (25873/29568)
Epoch: 61 | Batch_idx: 240 |  Loss: (0.3655) |  Loss2: (0.0000) | Acc: (87.00%) (27005/30848)
Epoch: 61 | Batch_idx: 250 |  Loss: (0.3638) |  Loss2: (0.0000) | Acc: (87.00%) (28156/32128)
Epoch: 61 | Batch_idx: 260 |  Loss: (0.3629) |  Loss2: (0.0000) | Acc: (87.00%) (29288/33408)
Epoch: 61 | Batch_idx: 270 |  Loss: (0.3621) |  Loss2: (0.0000) | Acc: (87.00%) (30420/34688)
Epoch: 61 | Batch_idx: 280 |  Loss: (0.3627) |  Loss2: (0.0000) | Acc: (87.00%) (31534/35968)
Epoch: 61 | Batch_idx: 290 |  Loss: (0.3616) |  Loss2: (0.0000) | Acc: (87.00%) (32681/37248)
Epoch: 61 | Batch_idx: 300 |  Loss: (0.3611) |  Loss2: (0.0000) | Acc: (87.00%) (33808/38528)
Epoch: 61 | Batch_idx: 310 |  Loss: (0.3615) |  Loss2: (0.0000) | Acc: (87.00%) (34925/39808)
Epoch: 61 | Batch_idx: 320 |  Loss: (0.3630) |  Loss2: (0.0000) | Acc: (87.00%) (36025/41088)
Epoch: 61 | Batch_idx: 330 |  Loss: (0.3624) |  Loss2: (0.0000) | Acc: (87.00%) (37155/42368)
Epoch: 61 | Batch_idx: 340 |  Loss: (0.3626) |  Loss2: (0.0000) | Acc: (87.00%) (38269/43648)
Epoch: 61 | Batch_idx: 350 |  Loss: (0.3624) |  Loss2: (0.0000) | Acc: (87.00%) (39382/44928)
Epoch: 61 | Batch_idx: 360 |  Loss: (0.3622) |  Loss2: (0.0000) | Acc: (87.00%) (40499/46208)
Epoch: 61 | Batch_idx: 370 |  Loss: (0.3622) |  Loss2: (0.0000) | Acc: (87.00%) (41619/47488)
Epoch: 61 | Batch_idx: 380 |  Loss: (0.3626) |  Loss2: (0.0000) | Acc: (87.00%) (42735/48768)
Epoch: 61 | Batch_idx: 390 |  Loss: (0.3627) |  Loss2: (0.0000) | Acc: (87.00%) (43812/50000)
# TEST : Loss: (0.4417) | Acc: (84.00%) (8495/10000)
percent tensor([0.4856, 0.4849, 0.4955, 0.4824, 0.4954, 0.4862, 0.4894, 0.4833, 0.4860,
        0.4890, 0.4868, 0.4946, 0.4853, 0.4835, 0.4864, 0.4843],
       device='cuda:0') torch.Size([16])
percent tensor([0.4884, 0.4685, 0.4854, 0.4955, 0.4762, 0.5024, 0.4659, 0.4778, 0.4842,
        0.4753, 0.4850, 0.4712, 0.4723, 0.4816, 0.4789, 0.4902],
       device='cuda:0') torch.Size([16])
percent tensor([0.5816, 0.5924, 0.5142, 0.5014, 0.5287, 0.5964, 0.5825, 0.5264, 0.5276,
        0.5608, 0.5646, 0.5184, 0.5762, 0.5678, 0.6025, 0.5825],
       device='cuda:0') torch.Size([16])
percent tensor([0.5873, 0.5739, 0.5979, 0.6270, 0.5949, 0.6244, 0.5832, 0.5955, 0.6081,
        0.5796, 0.5869, 0.5993, 0.5747, 0.6109, 0.5910, 0.5967],
       device='cuda:0') torch.Size([16])
percent tensor([0.5395, 0.5726, 0.4970, 0.5149, 0.5304, 0.5043, 0.5416, 0.5035, 0.5897,
        0.5864, 0.5958, 0.4771, 0.5516, 0.6633, 0.4683, 0.5709],
       device='cuda:0') torch.Size([16])
percent tensor([0.5465, 0.5204, 0.6093, 0.6265, 0.6376, 0.6034, 0.5632, 0.5981, 0.5653,
        0.5350, 0.5423, 0.5632, 0.5180, 0.5802, 0.5392, 0.5890],
       device='cuda:0') torch.Size([16])
percent tensor([0.5836, 0.5946, 0.6071, 0.5913, 0.6325, 0.4866, 0.6031, 0.5645, 0.6141,
        0.6348, 0.6188, 0.6414, 0.5909, 0.6059, 0.5556, 0.5476],
       device='cuda:0') torch.Size([16])
percent tensor([0.9965, 0.9948, 0.9959, 0.9946, 0.9954, 0.9928, 0.9904, 0.9945, 0.9978,
        0.9980, 0.9988, 0.9982, 0.9953, 0.9930, 0.9887, 0.9962],
       device='cuda:0') torch.Size([16])
Epoch: 62 | Batch_idx: 0 |  Loss: (0.3350) |  Loss2: (0.0000) | Acc: (89.00%) (115/128)
Epoch: 62 | Batch_idx: 10 |  Loss: (0.3602) |  Loss2: (0.0000) | Acc: (88.00%) (1245/1408)
Epoch: 62 | Batch_idx: 20 |  Loss: (0.3539) |  Loss2: (0.0000) | Acc: (88.00%) (2370/2688)
Epoch: 62 | Batch_idx: 30 |  Loss: (0.3519) |  Loss2: (0.0000) | Acc: (88.00%) (3496/3968)
Epoch: 62 | Batch_idx: 40 |  Loss: (0.3444) |  Loss2: (0.0000) | Acc: (88.00%) (4627/5248)
Epoch: 62 | Batch_idx: 50 |  Loss: (0.3459) |  Loss2: (0.0000) | Acc: (88.00%) (5755/6528)
Epoch: 62 | Batch_idx: 60 |  Loss: (0.3494) |  Loss2: (0.0000) | Acc: (88.00%) (6879/7808)
Epoch: 62 | Batch_idx: 70 |  Loss: (0.3554) |  Loss2: (0.0000) | Acc: (87.00%) (7990/9088)
Epoch: 62 | Batch_idx: 80 |  Loss: (0.3541) |  Loss2: (0.0000) | Acc: (88.00%) (9128/10368)
Epoch: 62 | Batch_idx: 90 |  Loss: (0.3587) |  Loss2: (0.0000) | Acc: (87.00%) (10232/11648)
Epoch: 62 | Batch_idx: 100 |  Loss: (0.3577) |  Loss2: (0.0000) | Acc: (87.00%) (11354/12928)
Epoch: 62 | Batch_idx: 110 |  Loss: (0.3590) |  Loss2: (0.0000) | Acc: (87.00%) (12465/14208)
Epoch: 62 | Batch_idx: 120 |  Loss: (0.3587) |  Loss2: (0.0000) | Acc: (87.00%) (13581/15488)
Epoch: 62 | Batch_idx: 130 |  Loss: (0.3575) |  Loss2: (0.0000) | Acc: (87.00%) (14709/16768)
Epoch: 62 | Batch_idx: 140 |  Loss: (0.3590) |  Loss2: (0.0000) | Acc: (87.00%) (15822/18048)
Epoch: 62 | Batch_idx: 150 |  Loss: (0.3578) |  Loss2: (0.0000) | Acc: (87.00%) (16950/19328)
Epoch: 62 | Batch_idx: 160 |  Loss: (0.3581) |  Loss2: (0.0000) | Acc: (87.00%) (18059/20608)
Epoch: 62 | Batch_idx: 170 |  Loss: (0.3576) |  Loss2: (0.0000) | Acc: (87.00%) (19183/21888)
Epoch: 62 | Batch_idx: 180 |  Loss: (0.3589) |  Loss2: (0.0000) | Acc: (87.00%) (20302/23168)
Epoch: 62 | Batch_idx: 190 |  Loss: (0.3601) |  Loss2: (0.0000) | Acc: (87.00%) (21419/24448)
Epoch: 62 | Batch_idx: 200 |  Loss: (0.3578) |  Loss2: (0.0000) | Acc: (87.00%) (22560/25728)
Epoch: 62 | Batch_idx: 210 |  Loss: (0.3583) |  Loss2: (0.0000) | Acc: (87.00%) (23691/27008)
Epoch: 62 | Batch_idx: 220 |  Loss: (0.3577) |  Loss2: (0.0000) | Acc: (87.00%) (24812/28288)
Epoch: 62 | Batch_idx: 230 |  Loss: (0.3574) |  Loss2: (0.0000) | Acc: (87.00%) (25929/29568)
Epoch: 62 | Batch_idx: 240 |  Loss: (0.3575) |  Loss2: (0.0000) | Acc: (87.00%) (27030/30848)
Epoch: 62 | Batch_idx: 250 |  Loss: (0.3575) |  Loss2: (0.0000) | Acc: (87.00%) (28156/32128)
Epoch: 62 | Batch_idx: 260 |  Loss: (0.3570) |  Loss2: (0.0000) | Acc: (87.00%) (29272/33408)
Epoch: 62 | Batch_idx: 270 |  Loss: (0.3568) |  Loss2: (0.0000) | Acc: (87.00%) (30409/34688)
Epoch: 62 | Batch_idx: 280 |  Loss: (0.3569) |  Loss2: (0.0000) | Acc: (87.00%) (31531/35968)
Epoch: 62 | Batch_idx: 290 |  Loss: (0.3559) |  Loss2: (0.0000) | Acc: (87.00%) (32676/37248)
Epoch: 62 | Batch_idx: 300 |  Loss: (0.3562) |  Loss2: (0.0000) | Acc: (87.00%) (33803/38528)
Epoch: 62 | Batch_idx: 310 |  Loss: (0.3553) |  Loss2: (0.0000) | Acc: (87.00%) (34932/39808)
Epoch: 62 | Batch_idx: 320 |  Loss: (0.3550) |  Loss2: (0.0000) | Acc: (87.00%) (36044/41088)
Epoch: 62 | Batch_idx: 330 |  Loss: (0.3557) |  Loss2: (0.0000) | Acc: (87.00%) (37149/42368)
Epoch: 62 | Batch_idx: 340 |  Loss: (0.3558) |  Loss2: (0.0000) | Acc: (87.00%) (38278/43648)
Epoch: 62 | Batch_idx: 350 |  Loss: (0.3561) |  Loss2: (0.0000) | Acc: (87.00%) (39395/44928)
Epoch: 62 | Batch_idx: 360 |  Loss: (0.3552) |  Loss2: (0.0000) | Acc: (87.00%) (40534/46208)
Epoch: 62 | Batch_idx: 370 |  Loss: (0.3556) |  Loss2: (0.0000) | Acc: (87.00%) (41643/47488)
Epoch: 62 | Batch_idx: 380 |  Loss: (0.3561) |  Loss2: (0.0000) | Acc: (87.00%) (42751/48768)
Epoch: 62 | Batch_idx: 390 |  Loss: (0.3560) |  Loss2: (0.0000) | Acc: (87.00%) (43829/50000)
# TEST : Loss: (0.4392) | Acc: (85.00%) (8501/10000)
percent tensor([0.4859, 0.4850, 0.4958, 0.4826, 0.4956, 0.4866, 0.4896, 0.4834, 0.4861,
        0.4891, 0.4871, 0.4948, 0.4854, 0.4834, 0.4866, 0.4843],
       device='cuda:0') torch.Size([16])
percent tensor([0.4856, 0.4652, 0.4816, 0.4923, 0.4724, 0.5017, 0.4621, 0.4738, 0.4810,
        0.4719, 0.4823, 0.4673, 0.4691, 0.4785, 0.4759, 0.4874],
       device='cuda:0') torch.Size([16])
percent tensor([0.5830, 0.5929, 0.5172, 0.5040, 0.5317, 0.5981, 0.5829, 0.5288, 0.5297,
        0.5621, 0.5660, 0.5210, 0.5786, 0.5685, 0.6032, 0.5835],
       device='cuda:0') torch.Size([16])
percent tensor([0.5808, 0.5684, 0.5917, 0.6216, 0.5882, 0.6179, 0.5763, 0.5882, 0.6018,
        0.5750, 0.5819, 0.5936, 0.5695, 0.6044, 0.5838, 0.5892],
       device='cuda:0') torch.Size([16])
percent tensor([0.5489, 0.5830, 0.5059, 0.5223, 0.5418, 0.5062, 0.5552, 0.5158, 0.5965,
        0.5981, 0.6036, 0.4883, 0.5610, 0.6714, 0.4780, 0.5800],
       device='cuda:0') torch.Size([16])
percent tensor([0.5513, 0.5231, 0.6177, 0.6338, 0.6476, 0.6122, 0.5685, 0.6066, 0.5700,
        0.5390, 0.5459, 0.5681, 0.5213, 0.5860, 0.5433, 0.5965],
       device='cuda:0') torch.Size([16])
percent tensor([0.5839, 0.5968, 0.6020, 0.5848, 0.6280, 0.4847, 0.6023, 0.5567, 0.6163,
        0.6365, 0.6220, 0.6372, 0.5935, 0.6090, 0.5540, 0.5459],
       device='cuda:0') torch.Size([16])
percent tensor([0.9969, 0.9954, 0.9964, 0.9952, 0.9959, 0.9937, 0.9915, 0.9954, 0.9980,
        0.9982, 0.9989, 0.9984, 0.9959, 0.9937, 0.9900, 0.9967],
       device='cuda:0') torch.Size([16])
Epoch: 63 | Batch_idx: 0 |  Loss: (0.3626) |  Loss2: (0.0000) | Acc: (88.00%) (113/128)
Epoch: 63 | Batch_idx: 10 |  Loss: (0.3483) |  Loss2: (0.0000) | Acc: (88.00%) (1242/1408)
Epoch: 63 | Batch_idx: 20 |  Loss: (0.3592) |  Loss2: (0.0000) | Acc: (87.00%) (2354/2688)
Epoch: 63 | Batch_idx: 30 |  Loss: (0.3613) |  Loss2: (0.0000) | Acc: (87.00%) (3470/3968)
Epoch: 63 | Batch_idx: 40 |  Loss: (0.3595) |  Loss2: (0.0000) | Acc: (87.00%) (4584/5248)
Epoch: 63 | Batch_idx: 50 |  Loss: (0.3494) |  Loss2: (0.0000) | Acc: (87.00%) (5741/6528)
Epoch: 63 | Batch_idx: 60 |  Loss: (0.3445) |  Loss2: (0.0000) | Acc: (88.00%) (6881/7808)
Epoch: 63 | Batch_idx: 70 |  Loss: (0.3477) |  Loss2: (0.0000) | Acc: (88.00%) (8002/9088)
Epoch: 63 | Batch_idx: 80 |  Loss: (0.3458) |  Loss2: (0.0000) | Acc: (88.00%) (9129/10368)
Epoch: 63 | Batch_idx: 90 |  Loss: (0.3460) |  Loss2: (0.0000) | Acc: (88.00%) (10252/11648)
Epoch: 63 | Batch_idx: 100 |  Loss: (0.3470) |  Loss2: (0.0000) | Acc: (88.00%) (11380/12928)
Epoch: 63 | Batch_idx: 110 |  Loss: (0.3460) |  Loss2: (0.0000) | Acc: (88.00%) (12519/14208)
Epoch: 63 | Batch_idx: 120 |  Loss: (0.3491) |  Loss2: (0.0000) | Acc: (88.00%) (13632/15488)
Epoch: 63 | Batch_idx: 130 |  Loss: (0.3519) |  Loss2: (0.0000) | Acc: (87.00%) (14742/16768)
Epoch: 63 | Batch_idx: 140 |  Loss: (0.3512) |  Loss2: (0.0000) | Acc: (87.00%) (15852/18048)
Epoch: 63 | Batch_idx: 150 |  Loss: (0.3514) |  Loss2: (0.0000) | Acc: (87.00%) (16980/19328)
Epoch: 63 | Batch_idx: 160 |  Loss: (0.3527) |  Loss2: (0.0000) | Acc: (87.00%) (18108/20608)
Epoch: 63 | Batch_idx: 170 |  Loss: (0.3526) |  Loss2: (0.0000) | Acc: (87.00%) (19230/21888)
Epoch: 63 | Batch_idx: 180 |  Loss: (0.3543) |  Loss2: (0.0000) | Acc: (87.00%) (20337/23168)
Epoch: 63 | Batch_idx: 190 |  Loss: (0.3526) |  Loss2: (0.0000) | Acc: (87.00%) (21487/24448)
Epoch: 63 | Batch_idx: 200 |  Loss: (0.3515) |  Loss2: (0.0000) | Acc: (87.00%) (22623/25728)
Epoch: 63 | Batch_idx: 210 |  Loss: (0.3504) |  Loss2: (0.0000) | Acc: (87.00%) (23753/27008)
Epoch: 63 | Batch_idx: 220 |  Loss: (0.3510) |  Loss2: (0.0000) | Acc: (87.00%) (24861/28288)
Epoch: 63 | Batch_idx: 230 |  Loss: (0.3497) |  Loss2: (0.0000) | Acc: (87.00%) (25994/29568)
Epoch: 63 | Batch_idx: 240 |  Loss: (0.3499) |  Loss2: (0.0000) | Acc: (87.00%) (27114/30848)
Epoch: 63 | Batch_idx: 250 |  Loss: (0.3490) |  Loss2: (0.0000) | Acc: (87.00%) (28256/32128)
Epoch: 63 | Batch_idx: 260 |  Loss: (0.3485) |  Loss2: (0.0000) | Acc: (87.00%) (29386/33408)
Epoch: 63 | Batch_idx: 270 |  Loss: (0.3492) |  Loss2: (0.0000) | Acc: (87.00%) (30521/34688)
Epoch: 63 | Batch_idx: 280 |  Loss: (0.3498) |  Loss2: (0.0000) | Acc: (87.00%) (31640/35968)
Epoch: 63 | Batch_idx: 290 |  Loss: (0.3508) |  Loss2: (0.0000) | Acc: (87.00%) (32757/37248)
Epoch: 63 | Batch_idx: 300 |  Loss: (0.3516) |  Loss2: (0.0000) | Acc: (87.00%) (33864/38528)
Epoch: 63 | Batch_idx: 310 |  Loss: (0.3515) |  Loss2: (0.0000) | Acc: (87.00%) (34996/39808)
Epoch: 63 | Batch_idx: 320 |  Loss: (0.3518) |  Loss2: (0.0000) | Acc: (87.00%) (36110/41088)
Epoch: 63 | Batch_idx: 330 |  Loss: (0.3524) |  Loss2: (0.0000) | Acc: (87.00%) (37234/42368)
Epoch: 63 | Batch_idx: 340 |  Loss: (0.3527) |  Loss2: (0.0000) | Acc: (87.00%) (38355/43648)
Epoch: 63 | Batch_idx: 350 |  Loss: (0.3524) |  Loss2: (0.0000) | Acc: (87.00%) (39487/44928)
Epoch: 63 | Batch_idx: 360 |  Loss: (0.3517) |  Loss2: (0.0000) | Acc: (87.00%) (40618/46208)
Epoch: 63 | Batch_idx: 370 |  Loss: (0.3520) |  Loss2: (0.0000) | Acc: (87.00%) (41740/47488)
Epoch: 63 | Batch_idx: 380 |  Loss: (0.3517) |  Loss2: (0.0000) | Acc: (87.00%) (42867/48768)
Epoch: 63 | Batch_idx: 390 |  Loss: (0.3512) |  Loss2: (0.0000) | Acc: (87.00%) (43958/50000)
# TEST : Loss: (0.4347) | Acc: (85.00%) (8525/10000)
percent tensor([0.4877, 0.4869, 0.4974, 0.4843, 0.4973, 0.4883, 0.4914, 0.4853, 0.4879,
        0.4909, 0.4889, 0.4967, 0.4870, 0.4849, 0.4884, 0.4858],
       device='cuda:0') torch.Size([16])
percent tensor([0.4884, 0.4678, 0.4839, 0.4950, 0.4749, 0.5027, 0.4648, 0.4763, 0.4838,
        0.4747, 0.4853, 0.4699, 0.4719, 0.4806, 0.4787, 0.4901],
       device='cuda:0') torch.Size([16])
percent tensor([0.5822, 0.5924, 0.5185, 0.5056, 0.5338, 0.5981, 0.5823, 0.5305, 0.5298,
        0.5617, 0.5650, 0.5223, 0.5786, 0.5684, 0.6022, 0.5831],
       device='cuda:0') torch.Size([16])
percent tensor([0.5881, 0.5767, 0.5982, 0.6294, 0.5949, 0.6262, 0.5840, 0.5955, 0.6100,
        0.5830, 0.5898, 0.6022, 0.5781, 0.6130, 0.5922, 0.5976],
       device='cuda:0') torch.Size([16])
percent tensor([0.5393, 0.5694, 0.5003, 0.5141, 0.5389, 0.5017, 0.5440, 0.5103, 0.5871,
        0.5860, 0.5906, 0.4767, 0.5492, 0.6605, 0.4662, 0.5723],
       device='cuda:0') torch.Size([16])
percent tensor([0.5505, 0.5189, 0.6222, 0.6384, 0.6546, 0.6174, 0.5679, 0.6105, 0.5702,
        0.5348, 0.5428, 0.5672, 0.5170, 0.5859, 0.5423, 0.5988],
       device='cuda:0') torch.Size([16])
percent tensor([0.5902, 0.6050, 0.6071, 0.5865, 0.6322, 0.4883, 0.6061, 0.5544, 0.6247,
        0.6432, 0.6330, 0.6404, 0.6037, 0.6193, 0.5571, 0.5486],
       device='cuda:0') torch.Size([16])
percent tensor([0.9974, 0.9959, 0.9969, 0.9959, 0.9967, 0.9947, 0.9927, 0.9961, 0.9982,
        0.9984, 0.9991, 0.9986, 0.9963, 0.9946, 0.9910, 0.9974],
       device='cuda:0') torch.Size([16])
True Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=128, out_features=16, bias=False)
False Linear(in_features=16, out_features=2, bias=False)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=128, out_features=16, bias=False)
False Linear(in_features=16, out_features=2, bias=False)
True Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=256, out_features=32, bias=False)
False Linear(in_features=32, out_features=2, bias=False)
True Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=256, out_features=32, bias=False)
False Linear(in_features=32, out_features=2, bias=False)
True Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=512, out_features=64, bias=False)
False Linear(in_features=64, out_features=2, bias=False)
True Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=512, out_features=64, bias=False)
False Linear(in_features=64, out_features=2, bias=False)
True Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1024, out_features=128, bias=False)
False Linear(in_features=128, out_features=2, bias=False)
True Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1024, out_features=128, bias=False)
False Linear(in_features=128, out_features=2, bias=False)
True Linear(in_features=512, out_features=10, bias=True)
Epoch: 64 | Batch_idx: 0 |  Loss: (0.2890) |  Loss2: (0.0000) | Acc: (89.00%) (115/128)
Epoch: 64 | Batch_idx: 10 |  Loss: (0.3558) |  Loss2: (0.0000) | Acc: (87.00%) (1232/1408)
Epoch: 64 | Batch_idx: 20 |  Loss: (0.3560) |  Loss2: (0.0000) | Acc: (87.00%) (2348/2688)
Epoch: 64 | Batch_idx: 30 |  Loss: (0.3475) |  Loss2: (0.0000) | Acc: (87.00%) (3471/3968)
Epoch: 64 | Batch_idx: 40 |  Loss: (0.3496) |  Loss2: (0.0000) | Acc: (87.00%) (4586/5248)
Epoch: 64 | Batch_idx: 50 |  Loss: (0.3515) |  Loss2: (0.0000) | Acc: (87.00%) (5701/6528)
Epoch: 64 | Batch_idx: 60 |  Loss: (0.3500) |  Loss2: (0.0000) | Acc: (87.00%) (6826/7808)
Epoch: 64 | Batch_idx: 70 |  Loss: (0.3490) |  Loss2: (0.0000) | Acc: (87.00%) (7958/9088)
Epoch: 64 | Batch_idx: 80 |  Loss: (0.3449) |  Loss2: (0.0000) | Acc: (87.00%) (9107/10368)
Epoch: 64 | Batch_idx: 90 |  Loss: (0.3458) |  Loss2: (0.0000) | Acc: (88.00%) (10263/11648)
Epoch: 64 | Batch_idx: 100 |  Loss: (0.3489) |  Loss2: (0.0000) | Acc: (87.00%) (11373/12928)
Epoch: 64 | Batch_idx: 110 |  Loss: (0.3465) |  Loss2: (0.0000) | Acc: (88.00%) (12507/14208)
Epoch: 64 | Batch_idx: 120 |  Loss: (0.3482) |  Loss2: (0.0000) | Acc: (87.00%) (13621/15488)
Epoch: 64 | Batch_idx: 130 |  Loss: (0.3503) |  Loss2: (0.0000) | Acc: (87.00%) (14728/16768)
Epoch: 64 | Batch_idx: 140 |  Loss: (0.3526) |  Loss2: (0.0000) | Acc: (87.00%) (15830/18048)
Epoch: 64 | Batch_idx: 150 |  Loss: (0.3548) |  Loss2: (0.0000) | Acc: (87.00%) (16945/19328)
Epoch: 64 | Batch_idx: 160 |  Loss: (0.3559) |  Loss2: (0.0000) | Acc: (87.00%) (18048/20608)
Epoch: 64 | Batch_idx: 170 |  Loss: (0.3568) |  Loss2: (0.0000) | Acc: (87.00%) (19170/21888)
Epoch: 64 | Batch_idx: 180 |  Loss: (0.3589) |  Loss2: (0.0000) | Acc: (87.00%) (20288/23168)
Epoch: 64 | Batch_idx: 190 |  Loss: (0.3594) |  Loss2: (0.0000) | Acc: (87.00%) (21411/24448)
Epoch: 64 | Batch_idx: 200 |  Loss: (0.3596) |  Loss2: (0.0000) | Acc: (87.00%) (22527/25728)
Epoch: 64 | Batch_idx: 210 |  Loss: (0.3585) |  Loss2: (0.0000) | Acc: (87.00%) (23655/27008)
Epoch: 64 | Batch_idx: 220 |  Loss: (0.3573) |  Loss2: (0.0000) | Acc: (87.00%) (24780/28288)
Epoch: 64 | Batch_idx: 230 |  Loss: (0.3562) |  Loss2: (0.0000) | Acc: (87.00%) (25919/29568)
Epoch: 64 | Batch_idx: 240 |  Loss: (0.3571) |  Loss2: (0.0000) | Acc: (87.00%) (27034/30848)
Epoch: 64 | Batch_idx: 250 |  Loss: (0.3574) |  Loss2: (0.0000) | Acc: (87.00%) (28155/32128)
Epoch: 64 | Batch_idx: 260 |  Loss: (0.3551) |  Loss2: (0.0000) | Acc: (87.00%) (29310/33408)
Epoch: 64 | Batch_idx: 270 |  Loss: (0.3556) |  Loss2: (0.0000) | Acc: (87.00%) (30426/34688)
Epoch: 64 | Batch_idx: 280 |  Loss: (0.3562) |  Loss2: (0.0000) | Acc: (87.00%) (31536/35968)
Epoch: 64 | Batch_idx: 290 |  Loss: (0.3565) |  Loss2: (0.0000) | Acc: (87.00%) (32656/37248)
Epoch: 64 | Batch_idx: 300 |  Loss: (0.3557) |  Loss2: (0.0000) | Acc: (87.00%) (33779/38528)
Epoch: 64 | Batch_idx: 310 |  Loss: (0.3568) |  Loss2: (0.0000) | Acc: (87.00%) (34884/39808)
Epoch: 64 | Batch_idx: 320 |  Loss: (0.3581) |  Loss2: (0.0000) | Acc: (87.00%) (35999/41088)
Epoch: 64 | Batch_idx: 330 |  Loss: (0.3588) |  Loss2: (0.0000) | Acc: (87.00%) (37108/42368)
Epoch: 64 | Batch_idx: 340 |  Loss: (0.3587) |  Loss2: (0.0000) | Acc: (87.00%) (38234/43648)
Epoch: 64 | Batch_idx: 350 |  Loss: (0.3594) |  Loss2: (0.0000) | Acc: (87.00%) (39360/44928)
Epoch: 64 | Batch_idx: 360 |  Loss: (0.3599) |  Loss2: (0.0000) | Acc: (87.00%) (40481/46208)
Epoch: 64 | Batch_idx: 370 |  Loss: (0.3593) |  Loss2: (0.0000) | Acc: (87.00%) (41612/47488)
Epoch: 64 | Batch_idx: 380 |  Loss: (0.3592) |  Loss2: (0.0000) | Acc: (87.00%) (42723/48768)
Epoch: 64 | Batch_idx: 390 |  Loss: (0.3593) |  Loss2: (0.0000) | Acc: (87.00%) (43797/50000)
# TEST : Loss: (0.5698) | Acc: (81.00%) (8171/10000)
percent tensor([0.4868, 0.4870, 0.4999, 0.4851, 0.4983, 0.4869, 0.4911, 0.4867, 0.4873,
        0.4911, 0.4881, 0.4973, 0.4865, 0.4856, 0.4876, 0.4856],
       device='cuda:0') torch.Size([16])
percent tensor([0.4879, 0.4674, 0.4894, 0.4885, 0.4787, 0.5026, 0.4683, 0.4743, 0.4822,
        0.4766, 0.4839, 0.4780, 0.4707, 0.4794, 0.4762, 0.4866],
       device='cuda:0') torch.Size([16])
percent tensor([0.5879, 0.5820, 0.5271, 0.5100, 0.5389, 0.5966, 0.5805, 0.5311, 0.5322,
        0.5623, 0.5640, 0.5282, 0.5836, 0.5427, 0.6011, 0.5770],
       device='cuda:0') torch.Size([16])
percent tensor([0.5892, 0.5802, 0.6030, 0.6223, 0.5971, 0.6247, 0.5892, 0.5929, 0.6061,
        0.5885, 0.5914, 0.6046, 0.5804, 0.6219, 0.5908, 0.5985],
       device='cuda:0') torch.Size([16])
percent tensor([0.5379, 0.5622, 0.5147, 0.5070, 0.5440, 0.5146, 0.5699, 0.4999, 0.5920,
        0.5858, 0.5919, 0.5047, 0.5516, 0.6573, 0.4624, 0.5710],
       device='cuda:0') torch.Size([16])
percent tensor([0.5491, 0.5119, 0.6240, 0.6272, 0.6502, 0.6110, 0.5754, 0.5927, 0.5659,
        0.5383, 0.5399, 0.5849, 0.5194, 0.5832, 0.5341, 0.5898],
       device='cuda:0') torch.Size([16])
percent tensor([0.5895, 0.6165, 0.6043, 0.5918, 0.6268, 0.4957, 0.6094, 0.5495, 0.6037,
        0.6454, 0.6394, 0.6329, 0.5988, 0.6217, 0.5601, 0.5535],
       device='cuda:0') torch.Size([16])
percent tensor([0.9983, 0.9969, 0.9973, 0.9976, 0.9956, 0.9962, 0.9956, 0.9960, 0.9964,
        0.9979, 0.9987, 0.9964, 0.9963, 0.9962, 0.9919, 0.9973],
       device='cuda:0') torch.Size([16])
Epoch: 65 | Batch_idx: 0 |  Loss: (0.2989) |  Loss2: (0.0000) | Acc: (91.00%) (117/128)
Epoch: 65 | Batch_idx: 10 |  Loss: (0.3209) |  Loss2: (0.0000) | Acc: (89.00%) (1254/1408)
Epoch: 65 | Batch_idx: 20 |  Loss: (0.3526) |  Loss2: (0.0000) | Acc: (87.00%) (2362/2688)
Epoch: 65 | Batch_idx: 30 |  Loss: (0.3571) |  Loss2: (0.0000) | Acc: (87.00%) (3472/3968)
Epoch: 65 | Batch_idx: 40 |  Loss: (0.3494) |  Loss2: (0.0000) | Acc: (87.00%) (4614/5248)
Epoch: 65 | Batch_idx: 50 |  Loss: (0.3575) |  Loss2: (0.0000) | Acc: (87.00%) (5728/6528)
Epoch: 65 | Batch_idx: 60 |  Loss: (0.3558) |  Loss2: (0.0000) | Acc: (87.00%) (6853/7808)
Epoch: 65 | Batch_idx: 70 |  Loss: (0.3530) |  Loss2: (0.0000) | Acc: (87.00%) (7980/9088)
Epoch: 65 | Batch_idx: 80 |  Loss: (0.3534) |  Loss2: (0.0000) | Acc: (87.00%) (9097/10368)
Epoch: 65 | Batch_idx: 90 |  Loss: (0.3487) |  Loss2: (0.0000) | Acc: (87.00%) (10240/11648)
Epoch: 65 | Batch_idx: 100 |  Loss: (0.3471) |  Loss2: (0.0000) | Acc: (87.00%) (11376/12928)
Epoch: 65 | Batch_idx: 110 |  Loss: (0.3469) |  Loss2: (0.0000) | Acc: (87.00%) (12495/14208)
Epoch: 65 | Batch_idx: 120 |  Loss: (0.3448) |  Loss2: (0.0000) | Acc: (87.00%) (13622/15488)
Epoch: 65 | Batch_idx: 130 |  Loss: (0.3449) |  Loss2: (0.0000) | Acc: (87.00%) (14743/16768)
Epoch: 65 | Batch_idx: 140 |  Loss: (0.3461) |  Loss2: (0.0000) | Acc: (87.00%) (15870/18048)
Epoch: 65 | Batch_idx: 150 |  Loss: (0.3462) |  Loss2: (0.0000) | Acc: (87.00%) (16998/19328)
Epoch: 65 | Batch_idx: 160 |  Loss: (0.3494) |  Loss2: (0.0000) | Acc: (87.00%) (18103/20608)
Epoch: 65 | Batch_idx: 170 |  Loss: (0.3481) |  Loss2: (0.0000) | Acc: (87.00%) (19237/21888)
Epoch: 65 | Batch_idx: 180 |  Loss: (0.3495) |  Loss2: (0.0000) | Acc: (87.00%) (20352/23168)
Epoch: 65 | Batch_idx: 190 |  Loss: (0.3503) |  Loss2: (0.0000) | Acc: (87.00%) (21475/24448)
Epoch: 65 | Batch_idx: 200 |  Loss: (0.3503) |  Loss2: (0.0000) | Acc: (87.00%) (22597/25728)
Epoch: 65 | Batch_idx: 210 |  Loss: (0.3496) |  Loss2: (0.0000) | Acc: (87.00%) (23728/27008)
Epoch: 65 | Batch_idx: 220 |  Loss: (0.3490) |  Loss2: (0.0000) | Acc: (87.00%) (24863/28288)
Epoch: 65 | Batch_idx: 230 |  Loss: (0.3489) |  Loss2: (0.0000) | Acc: (87.00%) (25989/29568)
Epoch: 65 | Batch_idx: 240 |  Loss: (0.3495) |  Loss2: (0.0000) | Acc: (87.00%) (27118/30848)
Epoch: 65 | Batch_idx: 250 |  Loss: (0.3495) |  Loss2: (0.0000) | Acc: (87.00%) (28233/32128)
Epoch: 65 | Batch_idx: 260 |  Loss: (0.3488) |  Loss2: (0.0000) | Acc: (87.00%) (29366/33408)
Epoch: 65 | Batch_idx: 270 |  Loss: (0.3483) |  Loss2: (0.0000) | Acc: (87.00%) (30493/34688)
Epoch: 65 | Batch_idx: 280 |  Loss: (0.3476) |  Loss2: (0.0000) | Acc: (87.00%) (31627/35968)
Epoch: 65 | Batch_idx: 290 |  Loss: (0.3475) |  Loss2: (0.0000) | Acc: (87.00%) (32760/37248)
Epoch: 65 | Batch_idx: 300 |  Loss: (0.3460) |  Loss2: (0.0000) | Acc: (88.00%) (33911/38528)
Epoch: 65 | Batch_idx: 310 |  Loss: (0.3457) |  Loss2: (0.0000) | Acc: (88.00%) (35035/39808)
Epoch: 65 | Batch_idx: 320 |  Loss: (0.3456) |  Loss2: (0.0000) | Acc: (88.00%) (36160/41088)
Epoch: 65 | Batch_idx: 330 |  Loss: (0.3451) |  Loss2: (0.0000) | Acc: (88.00%) (37284/42368)
Epoch: 65 | Batch_idx: 340 |  Loss: (0.3457) |  Loss2: (0.0000) | Acc: (88.00%) (38411/43648)
Epoch: 65 | Batch_idx: 350 |  Loss: (0.3462) |  Loss2: (0.0000) | Acc: (87.00%) (39510/44928)
Epoch: 65 | Batch_idx: 360 |  Loss: (0.3471) |  Loss2: (0.0000) | Acc: (87.00%) (40619/46208)
Epoch: 65 | Batch_idx: 370 |  Loss: (0.3475) |  Loss2: (0.0000) | Acc: (87.00%) (41744/47488)
Epoch: 65 | Batch_idx: 380 |  Loss: (0.3486) |  Loss2: (0.0000) | Acc: (87.00%) (42842/48768)
Epoch: 65 | Batch_idx: 390 |  Loss: (0.3494) |  Loss2: (0.0000) | Acc: (87.00%) (43908/50000)
=> saving checkpoint 'drive/app/torch/save_Schedule/checkpoint_065.pth.tar'
# TEST : Loss: (0.5062) | Acc: (82.00%) (8290/10000)
percent tensor([0.4864, 0.4889, 0.4980, 0.4853, 0.4969, 0.4862, 0.4917, 0.4872, 0.4877,
        0.4916, 0.4888, 0.4967, 0.4865, 0.4870, 0.4887, 0.4857],
       device='cuda:0') torch.Size([16])
percent tensor([0.4870, 0.4678, 0.4888, 0.4919, 0.4780, 0.5031, 0.4674, 0.4767, 0.4814,
        0.4756, 0.4828, 0.4782, 0.4694, 0.4809, 0.4777, 0.4869],
       device='cuda:0') torch.Size([16])
percent tensor([0.5920, 0.5937, 0.5259, 0.5083, 0.5425, 0.5896, 0.5958, 0.5348, 0.5326,
        0.5821, 0.5643, 0.5377, 0.5880, 0.5563, 0.6012, 0.5816],
       device='cuda:0') torch.Size([16])
percent tensor([0.5853, 0.5830, 0.6013, 0.6168, 0.5951, 0.6236, 0.5904, 0.5891, 0.6049,
        0.5846, 0.5872, 0.6084, 0.5790, 0.6234, 0.5947, 0.5944],
       device='cuda:0') torch.Size([16])
percent tensor([0.5277, 0.5791, 0.5233, 0.5119, 0.5515, 0.5114, 0.5739, 0.5036, 0.5967,
        0.5935, 0.5891, 0.5093, 0.5448, 0.6739, 0.4688, 0.5715],
       device='cuda:0') torch.Size([16])
percent tensor([0.5487, 0.5280, 0.6054, 0.6164, 0.6341, 0.6186, 0.5779, 0.5865, 0.5733,
        0.5473, 0.5486, 0.5873, 0.5228, 0.5971, 0.5469, 0.5910],
       device='cuda:0') torch.Size([16])
percent tensor([0.5899, 0.6013, 0.6078, 0.5760, 0.6164, 0.4999, 0.6069, 0.5411, 0.6381,
        0.6419, 0.6482, 0.6293, 0.6105, 0.6364, 0.5588, 0.5506],
       device='cuda:0') torch.Size([16])
percent tensor([0.9964, 0.9974, 0.9975, 0.9972, 0.9955, 0.9941, 0.9960, 0.9957, 0.9987,
        0.9985, 0.9989, 0.9980, 0.9973, 0.9970, 0.9909, 0.9958],
       device='cuda:0') torch.Size([16])
Epoch: 66 | Batch_idx: 0 |  Loss: (0.2864) |  Loss2: (0.0000) | Acc: (90.00%) (116/128)
Epoch: 66 | Batch_idx: 10 |  Loss: (0.3543) |  Loss2: (0.0000) | Acc: (87.00%) (1235/1408)
Epoch: 66 | Batch_idx: 20 |  Loss: (0.3607) |  Loss2: (0.0000) | Acc: (87.00%) (2355/2688)
Epoch: 66 | Batch_idx: 30 |  Loss: (0.3624) |  Loss2: (0.0000) | Acc: (87.00%) (3473/3968)
Epoch: 66 | Batch_idx: 40 |  Loss: (0.3512) |  Loss2: (0.0000) | Acc: (87.00%) (4601/5248)
Epoch: 66 | Batch_idx: 50 |  Loss: (0.3530) |  Loss2: (0.0000) | Acc: (87.00%) (5713/6528)
Epoch: 66 | Batch_idx: 60 |  Loss: (0.3564) |  Loss2: (0.0000) | Acc: (87.00%) (6824/7808)
Epoch: 66 | Batch_idx: 70 |  Loss: (0.3511) |  Loss2: (0.0000) | Acc: (87.00%) (7957/9088)
Epoch: 66 | Batch_idx: 80 |  Loss: (0.3516) |  Loss2: (0.0000) | Acc: (87.00%) (9077/10368)
Epoch: 66 | Batch_idx: 90 |  Loss: (0.3479) |  Loss2: (0.0000) | Acc: (87.00%) (10218/11648)
Epoch: 66 | Batch_idx: 100 |  Loss: (0.3509) |  Loss2: (0.0000) | Acc: (87.00%) (11336/12928)
Epoch: 66 | Batch_idx: 110 |  Loss: (0.3519) |  Loss2: (0.0000) | Acc: (87.00%) (12458/14208)
Epoch: 66 | Batch_idx: 120 |  Loss: (0.3520) |  Loss2: (0.0000) | Acc: (87.00%) (13587/15488)
Epoch: 66 | Batch_idx: 130 |  Loss: (0.3516) |  Loss2: (0.0000) | Acc: (87.00%) (14708/16768)
Epoch: 66 | Batch_idx: 140 |  Loss: (0.3528) |  Loss2: (0.0000) | Acc: (87.00%) (15829/18048)
Epoch: 66 | Batch_idx: 150 |  Loss: (0.3522) |  Loss2: (0.0000) | Acc: (87.00%) (16943/19328)
Epoch: 66 | Batch_idx: 160 |  Loss: (0.3511) |  Loss2: (0.0000) | Acc: (87.00%) (18063/20608)
Epoch: 66 | Batch_idx: 170 |  Loss: (0.3497) |  Loss2: (0.0000) | Acc: (87.00%) (19197/21888)
Epoch: 66 | Batch_idx: 180 |  Loss: (0.3479) |  Loss2: (0.0000) | Acc: (87.00%) (20330/23168)
Epoch: 66 | Batch_idx: 190 |  Loss: (0.3452) |  Loss2: (0.0000) | Acc: (87.00%) (21491/24448)
Epoch: 66 | Batch_idx: 200 |  Loss: (0.3429) |  Loss2: (0.0000) | Acc: (87.00%) (22629/25728)
Epoch: 66 | Batch_idx: 210 |  Loss: (0.3405) |  Loss2: (0.0000) | Acc: (88.00%) (23785/27008)
Epoch: 66 | Batch_idx: 220 |  Loss: (0.3416) |  Loss2: (0.0000) | Acc: (88.00%) (24909/28288)
Epoch: 66 | Batch_idx: 230 |  Loss: (0.3411) |  Loss2: (0.0000) | Acc: (88.00%) (26051/29568)
Epoch: 66 | Batch_idx: 240 |  Loss: (0.3414) |  Loss2: (0.0000) | Acc: (88.00%) (27169/30848)
Epoch: 66 | Batch_idx: 250 |  Loss: (0.3415) |  Loss2: (0.0000) | Acc: (88.00%) (28300/32128)
Epoch: 66 | Batch_idx: 260 |  Loss: (0.3420) |  Loss2: (0.0000) | Acc: (88.00%) (29429/33408)
Epoch: 66 | Batch_idx: 270 |  Loss: (0.3404) |  Loss2: (0.0000) | Acc: (88.00%) (30591/34688)
Epoch: 66 | Batch_idx: 280 |  Loss: (0.3411) |  Loss2: (0.0000) | Acc: (88.00%) (31717/35968)
Epoch: 66 | Batch_idx: 290 |  Loss: (0.3400) |  Loss2: (0.0000) | Acc: (88.00%) (32857/37248)
Epoch: 66 | Batch_idx: 300 |  Loss: (0.3404) |  Loss2: (0.0000) | Acc: (88.00%) (33983/38528)
Epoch: 66 | Batch_idx: 310 |  Loss: (0.3409) |  Loss2: (0.0000) | Acc: (88.00%) (35110/39808)
Epoch: 66 | Batch_idx: 320 |  Loss: (0.3413) |  Loss2: (0.0000) | Acc: (88.00%) (36230/41088)
Epoch: 66 | Batch_idx: 330 |  Loss: (0.3409) |  Loss2: (0.0000) | Acc: (88.00%) (37369/42368)
Epoch: 66 | Batch_idx: 340 |  Loss: (0.3417) |  Loss2: (0.0000) | Acc: (88.00%) (38478/43648)
Epoch: 66 | Batch_idx: 350 |  Loss: (0.3397) |  Loss2: (0.0000) | Acc: (88.00%) (39631/44928)
Epoch: 66 | Batch_idx: 360 |  Loss: (0.3405) |  Loss2: (0.0000) | Acc: (88.00%) (40745/46208)
Epoch: 66 | Batch_idx: 370 |  Loss: (0.3409) |  Loss2: (0.0000) | Acc: (88.00%) (41856/47488)
Epoch: 66 | Batch_idx: 380 |  Loss: (0.3411) |  Loss2: (0.0000) | Acc: (88.00%) (42996/48768)
Epoch: 66 | Batch_idx: 390 |  Loss: (0.3411) |  Loss2: (0.0000) | Acc: (88.00%) (44090/50000)
# TEST : Loss: (0.4806) | Acc: (83.00%) (8373/10000)
percent tensor([0.4869, 0.4879, 0.4974, 0.4845, 0.4966, 0.4869, 0.4915, 0.4861, 0.4875,
        0.4911, 0.4883, 0.4964, 0.4865, 0.4860, 0.4883, 0.4856],
       device='cuda:0') torch.Size([16])
percent tensor([0.4876, 0.4680, 0.4873, 0.4873, 0.4781, 0.5029, 0.4682, 0.4738, 0.4851,
        0.4765, 0.4863, 0.4779, 0.4713, 0.4825, 0.4765, 0.4867],
       device='cuda:0') torch.Size([16])
percent tensor([0.5730, 0.5736, 0.5142, 0.5015, 0.5309, 0.5813, 0.5711, 0.5278, 0.5223,
        0.5536, 0.5431, 0.5175, 0.5709, 0.5339, 0.5877, 0.5708],
       device='cuda:0') torch.Size([16])
percent tensor([0.5882, 0.5912, 0.6055, 0.6238, 0.6001, 0.6244, 0.5942, 0.5958, 0.6103,
        0.5941, 0.5962, 0.6132, 0.5840, 0.6269, 0.5968, 0.5974],
       device='cuda:0') torch.Size([16])
percent tensor([0.5370, 0.5753, 0.5234, 0.5209, 0.5558, 0.5037, 0.5672, 0.5041, 0.6098,
        0.6047, 0.6085, 0.5158, 0.5586, 0.6666, 0.4684, 0.5696],
       device='cuda:0') torch.Size([16])
percent tensor([0.5446, 0.5334, 0.6099, 0.6309, 0.6443, 0.6096, 0.5825, 0.5937, 0.5808,
        0.5568, 0.5529, 0.5878, 0.5300, 0.6033, 0.5487, 0.5953],
       device='cuda:0') torch.Size([16])
percent tensor([0.6051, 0.6130, 0.6176, 0.5955, 0.6332, 0.4998, 0.6153, 0.5475, 0.6416,
        0.6481, 0.6530, 0.6346, 0.6156, 0.6272, 0.5640, 0.5544],
       device='cuda:0') torch.Size([16])
percent tensor([0.9975, 0.9976, 0.9974, 0.9974, 0.9974, 0.9951, 0.9958, 0.9952, 0.9990,
        0.9989, 0.9993, 0.9985, 0.9973, 0.9956, 0.9928, 0.9963],
       device='cuda:0') torch.Size([16])
Epoch: 67 | Batch_idx: 0 |  Loss: (0.3385) |  Loss2: (0.0000) | Acc: (91.00%) (117/128)
Epoch: 67 | Batch_idx: 10 |  Loss: (0.3131) |  Loss2: (0.0000) | Acc: (89.00%) (1263/1408)
Epoch: 67 | Batch_idx: 20 |  Loss: (0.3312) |  Loss2: (0.0000) | Acc: (88.00%) (2390/2688)
Epoch: 67 | Batch_idx: 30 |  Loss: (0.3323) |  Loss2: (0.0000) | Acc: (88.00%) (3529/3968)
Epoch: 67 | Batch_idx: 40 |  Loss: (0.3287) |  Loss2: (0.0000) | Acc: (89.00%) (4671/5248)
Epoch: 67 | Batch_idx: 50 |  Loss: (0.3259) |  Loss2: (0.0000) | Acc: (89.00%) (5811/6528)
Epoch: 67 | Batch_idx: 60 |  Loss: (0.3228) |  Loss2: (0.0000) | Acc: (89.00%) (6957/7808)
Epoch: 67 | Batch_idx: 70 |  Loss: (0.3227) |  Loss2: (0.0000) | Acc: (89.00%) (8098/9088)
Epoch: 67 | Batch_idx: 80 |  Loss: (0.3226) |  Loss2: (0.0000) | Acc: (89.00%) (9229/10368)
Epoch: 67 | Batch_idx: 90 |  Loss: (0.3231) |  Loss2: (0.0000) | Acc: (88.00%) (10358/11648)
Epoch: 67 | Batch_idx: 100 |  Loss: (0.3252) |  Loss2: (0.0000) | Acc: (88.00%) (11482/12928)
Epoch: 67 | Batch_idx: 110 |  Loss: (0.3233) |  Loss2: (0.0000) | Acc: (88.00%) (12623/14208)
Epoch: 67 | Batch_idx: 120 |  Loss: (0.3225) |  Loss2: (0.0000) | Acc: (88.00%) (13762/15488)
Epoch: 67 | Batch_idx: 130 |  Loss: (0.3255) |  Loss2: (0.0000) | Acc: (88.00%) (14885/16768)
Epoch: 67 | Batch_idx: 140 |  Loss: (0.3255) |  Loss2: (0.0000) | Acc: (88.00%) (16028/18048)
Epoch: 67 | Batch_idx: 150 |  Loss: (0.3247) |  Loss2: (0.0000) | Acc: (88.00%) (17158/19328)
Epoch: 67 | Batch_idx: 160 |  Loss: (0.3275) |  Loss2: (0.0000) | Acc: (88.00%) (18279/20608)
Epoch: 67 | Batch_idx: 170 |  Loss: (0.3271) |  Loss2: (0.0000) | Acc: (88.00%) (19408/21888)
Epoch: 67 | Batch_idx: 180 |  Loss: (0.3249) |  Loss2: (0.0000) | Acc: (88.00%) (20569/23168)
Epoch: 67 | Batch_idx: 190 |  Loss: (0.3251) |  Loss2: (0.0000) | Acc: (88.00%) (21710/24448)
Epoch: 67 | Batch_idx: 200 |  Loss: (0.3253) |  Loss2: (0.0000) | Acc: (88.00%) (22847/25728)
Epoch: 67 | Batch_idx: 210 |  Loss: (0.3256) |  Loss2: (0.0000) | Acc: (88.00%) (23966/27008)
Epoch: 67 | Batch_idx: 220 |  Loss: (0.3244) |  Loss2: (0.0000) | Acc: (88.00%) (25110/28288)
Epoch: 67 | Batch_idx: 230 |  Loss: (0.3254) |  Loss2: (0.0000) | Acc: (88.00%) (26233/29568)
Epoch: 67 | Batch_idx: 240 |  Loss: (0.3244) |  Loss2: (0.0000) | Acc: (88.00%) (27383/30848)
Epoch: 67 | Batch_idx: 250 |  Loss: (0.3251) |  Loss2: (0.0000) | Acc: (88.00%) (28517/32128)
Epoch: 67 | Batch_idx: 260 |  Loss: (0.3249) |  Loss2: (0.0000) | Acc: (88.00%) (29662/33408)
Epoch: 67 | Batch_idx: 270 |  Loss: (0.3253) |  Loss2: (0.0000) | Acc: (88.00%) (30791/34688)
Epoch: 67 | Batch_idx: 280 |  Loss: (0.3256) |  Loss2: (0.0000) | Acc: (88.00%) (31922/35968)
Epoch: 67 | Batch_idx: 290 |  Loss: (0.3264) |  Loss2: (0.0000) | Acc: (88.00%) (33040/37248)
Epoch: 67 | Batch_idx: 300 |  Loss: (0.3266) |  Loss2: (0.0000) | Acc: (88.00%) (34168/38528)
Epoch: 67 | Batch_idx: 310 |  Loss: (0.3269) |  Loss2: (0.0000) | Acc: (88.00%) (35302/39808)
Epoch: 67 | Batch_idx: 320 |  Loss: (0.3265) |  Loss2: (0.0000) | Acc: (88.00%) (36434/41088)
Epoch: 67 | Batch_idx: 330 |  Loss: (0.3279) |  Loss2: (0.0000) | Acc: (88.00%) (37546/42368)
Epoch: 67 | Batch_idx: 340 |  Loss: (0.3282) |  Loss2: (0.0000) | Acc: (88.00%) (38682/43648)
Epoch: 67 | Batch_idx: 350 |  Loss: (0.3283) |  Loss2: (0.0000) | Acc: (88.00%) (39804/44928)
Epoch: 67 | Batch_idx: 360 |  Loss: (0.3291) |  Loss2: (0.0000) | Acc: (88.00%) (40923/46208)
Epoch: 67 | Batch_idx: 370 |  Loss: (0.3290) |  Loss2: (0.0000) | Acc: (88.00%) (42072/47488)
Epoch: 67 | Batch_idx: 380 |  Loss: (0.3290) |  Loss2: (0.0000) | Acc: (88.00%) (43207/48768)
Epoch: 67 | Batch_idx: 390 |  Loss: (0.3298) |  Loss2: (0.0000) | Acc: (88.00%) (44295/50000)
# TEST : Loss: (0.4864) | Acc: (83.00%) (8399/10000)
percent tensor([0.4872, 0.4881, 0.4974, 0.4857, 0.4967, 0.4874, 0.4916, 0.4867, 0.4879,
        0.4915, 0.4890, 0.4964, 0.4870, 0.4862, 0.4887, 0.4860],
       device='cuda:0') torch.Size([16])
percent tensor([0.4852, 0.4679, 0.4867, 0.4885, 0.4761, 0.5019, 0.4671, 0.4738, 0.4806,
        0.4756, 0.4829, 0.4769, 0.4682, 0.4835, 0.4753, 0.4859],
       device='cuda:0') torch.Size([16])
percent tensor([0.5896, 0.5905, 0.5136, 0.5019, 0.5339, 0.5990, 0.5871, 0.5329, 0.5464,
        0.5660, 0.5777, 0.5193, 0.5876, 0.5634, 0.6002, 0.5867],
       device='cuda:0') torch.Size([16])
percent tensor([0.5856, 0.5823, 0.6055, 0.6250, 0.5987, 0.6259, 0.5895, 0.5938, 0.5999,
        0.5887, 0.5851, 0.6087, 0.5754, 0.6163, 0.5942, 0.5949],
       device='cuda:0') torch.Size([16])
percent tensor([0.5265, 0.5766, 0.5252, 0.5160, 0.5466, 0.5094, 0.5546, 0.5023, 0.5854,
        0.6001, 0.5963, 0.5124, 0.5443, 0.6642, 0.4621, 0.5679],
       device='cuda:0') torch.Size([16])
percent tensor([0.5486, 0.5359, 0.6086, 0.6286, 0.6398, 0.6278, 0.5775, 0.5895, 0.5698,
        0.5595, 0.5500, 0.5852, 0.5244, 0.6094, 0.5433, 0.6006],
       device='cuda:0') torch.Size([16])
percent tensor([0.5785, 0.6053, 0.6169, 0.5822, 0.6257, 0.4966, 0.6033, 0.5445, 0.6276,
        0.6320, 0.6346, 0.6293, 0.6041, 0.6107, 0.5519, 0.5455],
       device='cuda:0') torch.Size([16])
percent tensor([0.9962, 0.9958, 0.9970, 0.9971, 0.9965, 0.9919, 0.9949, 0.9961, 0.9982,
        0.9974, 0.9978, 0.9982, 0.9968, 0.9937, 0.9921, 0.9956],
       device='cuda:0') torch.Size([16])
Epoch: 68 | Batch_idx: 0 |  Loss: (0.2929) |  Loss2: (0.0000) | Acc: (89.00%) (114/128)
Epoch: 68 | Batch_idx: 10 |  Loss: (0.3191) |  Loss2: (0.0000) | Acc: (87.00%) (1237/1408)
Epoch: 68 | Batch_idx: 20 |  Loss: (0.3271) |  Loss2: (0.0000) | Acc: (88.00%) (2366/2688)
Epoch: 68 | Batch_idx: 30 |  Loss: (0.3233) |  Loss2: (0.0000) | Acc: (88.00%) (3497/3968)
Epoch: 68 | Batch_idx: 40 |  Loss: (0.3233) |  Loss2: (0.0000) | Acc: (88.00%) (4630/5248)
Epoch: 68 | Batch_idx: 50 |  Loss: (0.3234) |  Loss2: (0.0000) | Acc: (88.00%) (5776/6528)
Epoch: 68 | Batch_idx: 60 |  Loss: (0.3198) |  Loss2: (0.0000) | Acc: (88.00%) (6926/7808)
Epoch: 68 | Batch_idx: 70 |  Loss: (0.3277) |  Loss2: (0.0000) | Acc: (88.00%) (8041/9088)
Epoch: 68 | Batch_idx: 80 |  Loss: (0.3287) |  Loss2: (0.0000) | Acc: (88.00%) (9177/10368)
Epoch: 68 | Batch_idx: 90 |  Loss: (0.3316) |  Loss2: (0.0000) | Acc: (88.00%) (10305/11648)
Epoch: 68 | Batch_idx: 100 |  Loss: (0.3289) |  Loss2: (0.0000) | Acc: (88.00%) (11445/12928)
Epoch: 68 | Batch_idx: 110 |  Loss: (0.3292) |  Loss2: (0.0000) | Acc: (88.00%) (12577/14208)
Epoch: 68 | Batch_idx: 120 |  Loss: (0.3270) |  Loss2: (0.0000) | Acc: (88.00%) (13722/15488)
Epoch: 68 | Batch_idx: 130 |  Loss: (0.3276) |  Loss2: (0.0000) | Acc: (88.00%) (14841/16768)
Epoch: 68 | Batch_idx: 140 |  Loss: (0.3281) |  Loss2: (0.0000) | Acc: (88.00%) (15967/18048)
Epoch: 68 | Batch_idx: 150 |  Loss: (0.3253) |  Loss2: (0.0000) | Acc: (88.00%) (17120/19328)
Epoch: 68 | Batch_idx: 160 |  Loss: (0.3251) |  Loss2: (0.0000) | Acc: (88.00%) (18255/20608)
Epoch: 68 | Batch_idx: 170 |  Loss: (0.3243) |  Loss2: (0.0000) | Acc: (88.00%) (19396/21888)
Epoch: 68 | Batch_idx: 180 |  Loss: (0.3236) |  Loss2: (0.0000) | Acc: (88.00%) (20531/23168)
Epoch: 68 | Batch_idx: 190 |  Loss: (0.3250) |  Loss2: (0.0000) | Acc: (88.00%) (21659/24448)
Epoch: 68 | Batch_idx: 200 |  Loss: (0.3229) |  Loss2: (0.0000) | Acc: (88.00%) (22819/25728)
Epoch: 68 | Batch_idx: 210 |  Loss: (0.3237) |  Loss2: (0.0000) | Acc: (88.00%) (23952/27008)
Epoch: 68 | Batch_idx: 220 |  Loss: (0.3223) |  Loss2: (0.0000) | Acc: (88.00%) (25110/28288)
Epoch: 68 | Batch_idx: 230 |  Loss: (0.3216) |  Loss2: (0.0000) | Acc: (88.00%) (26254/29568)
Epoch: 68 | Batch_idx: 240 |  Loss: (0.3218) |  Loss2: (0.0000) | Acc: (88.00%) (27389/30848)
Epoch: 68 | Batch_idx: 250 |  Loss: (0.3211) |  Loss2: (0.0000) | Acc: (88.00%) (28536/32128)
Epoch: 68 | Batch_idx: 260 |  Loss: (0.3203) |  Loss2: (0.0000) | Acc: (88.00%) (29683/33408)
Epoch: 68 | Batch_idx: 270 |  Loss: (0.3202) |  Loss2: (0.0000) | Acc: (88.00%) (30812/34688)
Epoch: 68 | Batch_idx: 280 |  Loss: (0.3204) |  Loss2: (0.0000) | Acc: (88.00%) (31957/35968)
Epoch: 68 | Batch_idx: 290 |  Loss: (0.3202) |  Loss2: (0.0000) | Acc: (88.00%) (33100/37248)
Epoch: 68 | Batch_idx: 300 |  Loss: (0.3196) |  Loss2: (0.0000) | Acc: (88.00%) (34255/38528)
Epoch: 68 | Batch_idx: 310 |  Loss: (0.3190) |  Loss2: (0.0000) | Acc: (88.00%) (35405/39808)
Epoch: 68 | Batch_idx: 320 |  Loss: (0.3191) |  Loss2: (0.0000) | Acc: (88.00%) (36551/41088)
Epoch: 68 | Batch_idx: 330 |  Loss: (0.3196) |  Loss2: (0.0000) | Acc: (88.00%) (37689/42368)
Epoch: 68 | Batch_idx: 340 |  Loss: (0.3197) |  Loss2: (0.0000) | Acc: (88.00%) (38826/43648)
Epoch: 68 | Batch_idx: 350 |  Loss: (0.3190) |  Loss2: (0.0000) | Acc: (88.00%) (39980/44928)
Epoch: 68 | Batch_idx: 360 |  Loss: (0.3196) |  Loss2: (0.0000) | Acc: (88.00%) (41124/46208)
Epoch: 68 | Batch_idx: 370 |  Loss: (0.3196) |  Loss2: (0.0000) | Acc: (88.00%) (42250/47488)
Epoch: 68 | Batch_idx: 380 |  Loss: (0.3192) |  Loss2: (0.0000) | Acc: (89.00%) (43407/48768)
Epoch: 68 | Batch_idx: 390 |  Loss: (0.3188) |  Loss2: (0.0000) | Acc: (89.00%) (44510/50000)
# TEST : Loss: (0.4524) | Acc: (84.00%) (8493/10000)
percent tensor([0.4870, 0.4884, 0.4966, 0.4853, 0.4962, 0.4877, 0.4916, 0.4865, 0.4878,
        0.4912, 0.4892, 0.4959, 0.4868, 0.4861, 0.4892, 0.4861],
       device='cuda:0') torch.Size([16])
percent tensor([0.4853, 0.4695, 0.4844, 0.4890, 0.4753, 0.5030, 0.4680, 0.4721, 0.4821,
        0.4746, 0.4842, 0.4751, 0.4677, 0.4865, 0.4773, 0.4861],
       device='cuda:0') torch.Size([16])
percent tensor([0.5830, 0.5895, 0.5162, 0.5020, 0.5317, 0.5815, 0.5847, 0.5320, 0.5344,
        0.5692, 0.5617, 0.5201, 0.5851, 0.5518, 0.5958, 0.5764],
       device='cuda:0') torch.Size([16])
percent tensor([0.5872, 0.5837, 0.6066, 0.6303, 0.6009, 0.6296, 0.5933, 0.5944, 0.6012,
        0.5858, 0.5837, 0.6140, 0.5754, 0.6291, 0.5960, 0.5987],
       device='cuda:0') torch.Size([16])
percent tensor([0.5439, 0.5907, 0.5408, 0.5312, 0.5643, 0.5229, 0.5844, 0.5155, 0.6064,
        0.6122, 0.6036, 0.5323, 0.5613, 0.6917, 0.4790, 0.5815],
       device='cuda:0') torch.Size([16])
percent tensor([0.5557, 0.5441, 0.6211, 0.6355, 0.6534, 0.6293, 0.5899, 0.5962, 0.5809,
        0.5603, 0.5594, 0.5963, 0.5378, 0.6138, 0.5537, 0.6028],
       device='cuda:0') torch.Size([16])
percent tensor([0.5947, 0.6029, 0.6148, 0.5860, 0.6355, 0.5138, 0.6225, 0.5524, 0.6166,
        0.6389, 0.6474, 0.6282, 0.6034, 0.6250, 0.5680, 0.5576],
       device='cuda:0') torch.Size([16])
percent tensor([0.9974, 0.9956, 0.9972, 0.9968, 0.9970, 0.9948, 0.9958, 0.9944, 0.9976,
        0.9980, 0.9984, 0.9975, 0.9968, 0.9958, 0.9933, 0.9959],
       device='cuda:0') torch.Size([16])
Epoch: 69 | Batch_idx: 0 |  Loss: (0.2459) |  Loss2: (0.0000) | Acc: (89.00%) (115/128)
Epoch: 69 | Batch_idx: 10 |  Loss: (0.2780) |  Loss2: (0.0000) | Acc: (90.00%) (1268/1408)
Epoch: 69 | Batch_idx: 20 |  Loss: (0.2807) |  Loss2: (0.0000) | Acc: (89.00%) (2417/2688)
Epoch: 69 | Batch_idx: 30 |  Loss: (0.2870) |  Loss2: (0.0000) | Acc: (89.00%) (3556/3968)
Epoch: 69 | Batch_idx: 40 |  Loss: (0.2897) |  Loss2: (0.0000) | Acc: (89.00%) (4705/5248)
Epoch: 69 | Batch_idx: 50 |  Loss: (0.2942) |  Loss2: (0.0000) | Acc: (89.00%) (5844/6528)
Epoch: 69 | Batch_idx: 60 |  Loss: (0.2991) |  Loss2: (0.0000) | Acc: (89.00%) (6970/7808)
Epoch: 69 | Batch_idx: 70 |  Loss: (0.3041) |  Loss2: (0.0000) | Acc: (89.00%) (8107/9088)
Epoch: 69 | Batch_idx: 80 |  Loss: (0.3037) |  Loss2: (0.0000) | Acc: (89.00%) (9247/10368)
Epoch: 69 | Batch_idx: 90 |  Loss: (0.3051) |  Loss2: (0.0000) | Acc: (89.00%) (10382/11648)
Epoch: 69 | Batch_idx: 100 |  Loss: (0.3016) |  Loss2: (0.0000) | Acc: (89.00%) (11541/12928)
Epoch: 69 | Batch_idx: 110 |  Loss: (0.3016) |  Loss2: (0.0000) | Acc: (89.00%) (12695/14208)
Epoch: 69 | Batch_idx: 120 |  Loss: (0.3022) |  Loss2: (0.0000) | Acc: (89.00%) (13834/15488)
Epoch: 69 | Batch_idx: 130 |  Loss: (0.3015) |  Loss2: (0.0000) | Acc: (89.00%) (14979/16768)
Epoch: 69 | Batch_idx: 140 |  Loss: (0.2980) |  Loss2: (0.0000) | Acc: (89.00%) (16146/18048)
Epoch: 69 | Batch_idx: 150 |  Loss: (0.3005) |  Loss2: (0.0000) | Acc: (89.00%) (17276/19328)
Epoch: 69 | Batch_idx: 160 |  Loss: (0.3012) |  Loss2: (0.0000) | Acc: (89.00%) (18425/20608)
Epoch: 69 | Batch_idx: 170 |  Loss: (0.3022) |  Loss2: (0.0000) | Acc: (89.00%) (19562/21888)
Epoch: 69 | Batch_idx: 180 |  Loss: (0.3015) |  Loss2: (0.0000) | Acc: (89.00%) (20716/23168)
Epoch: 69 | Batch_idx: 190 |  Loss: (0.3018) |  Loss2: (0.0000) | Acc: (89.00%) (21860/24448)
Epoch: 69 | Batch_idx: 200 |  Loss: (0.3028) |  Loss2: (0.0000) | Acc: (89.00%) (23002/25728)
Epoch: 69 | Batch_idx: 210 |  Loss: (0.3034) |  Loss2: (0.0000) | Acc: (89.00%) (24138/27008)
Epoch: 69 | Batch_idx: 220 |  Loss: (0.3020) |  Loss2: (0.0000) | Acc: (89.00%) (25290/28288)
Epoch: 69 | Batch_idx: 230 |  Loss: (0.3027) |  Loss2: (0.0000) | Acc: (89.00%) (26433/29568)
Epoch: 69 | Batch_idx: 240 |  Loss: (0.3047) |  Loss2: (0.0000) | Acc: (89.00%) (27570/30848)
Epoch: 69 | Batch_idx: 250 |  Loss: (0.3037) |  Loss2: (0.0000) | Acc: (89.00%) (28727/32128)
Epoch: 69 | Batch_idx: 260 |  Loss: (0.3040) |  Loss2: (0.0000) | Acc: (89.00%) (29863/33408)
Epoch: 69 | Batch_idx: 270 |  Loss: (0.3044) |  Loss2: (0.0000) | Acc: (89.00%) (31001/34688)
Epoch: 69 | Batch_idx: 280 |  Loss: (0.3047) |  Loss2: (0.0000) | Acc: (89.00%) (32144/35968)
Epoch: 69 | Batch_idx: 290 |  Loss: (0.3054) |  Loss2: (0.0000) | Acc: (89.00%) (33273/37248)
Epoch: 69 | Batch_idx: 300 |  Loss: (0.3059) |  Loss2: (0.0000) | Acc: (89.00%) (34424/38528)
Epoch: 69 | Batch_idx: 310 |  Loss: (0.3065) |  Loss2: (0.0000) | Acc: (89.00%) (35557/39808)
Epoch: 69 | Batch_idx: 320 |  Loss: (0.3075) |  Loss2: (0.0000) | Acc: (89.00%) (36689/41088)
Epoch: 69 | Batch_idx: 330 |  Loss: (0.3070) |  Loss2: (0.0000) | Acc: (89.00%) (37848/42368)
Epoch: 69 | Batch_idx: 340 |  Loss: (0.3079) |  Loss2: (0.0000) | Acc: (89.00%) (38975/43648)
Epoch: 69 | Batch_idx: 350 |  Loss: (0.3091) |  Loss2: (0.0000) | Acc: (89.00%) (40103/44928)
Epoch: 69 | Batch_idx: 360 |  Loss: (0.3087) |  Loss2: (0.0000) | Acc: (89.00%) (41260/46208)
Epoch: 69 | Batch_idx: 370 |  Loss: (0.3083) |  Loss2: (0.0000) | Acc: (89.00%) (42416/47488)
Epoch: 69 | Batch_idx: 380 |  Loss: (0.3085) |  Loss2: (0.0000) | Acc: (89.00%) (43542/48768)
Epoch: 69 | Batch_idx: 390 |  Loss: (0.3099) |  Loss2: (0.0000) | Acc: (89.00%) (44621/50000)
# TEST : Loss: (0.4431) | Acc: (85.00%) (8545/10000)
percent tensor([0.4878, 0.4885, 0.4967, 0.4856, 0.4965, 0.4886, 0.4922, 0.4860, 0.4882,
        0.4913, 0.4895, 0.4959, 0.4872, 0.4859, 0.4895, 0.4861],
       device='cuda:0') torch.Size([16])
percent tensor([0.4834, 0.4676, 0.4842, 0.4875, 0.4761, 0.5017, 0.4656, 0.4726, 0.4816,
        0.4752, 0.4822, 0.4746, 0.4673, 0.4832, 0.4744, 0.4858],
       device='cuda:0') torch.Size([16])
percent tensor([0.5798, 0.5878, 0.5107, 0.5055, 0.5280, 0.5868, 0.5812, 0.5335, 0.5274,
        0.5621, 0.5585, 0.5166, 0.5766, 0.5571, 0.5986, 0.5788],
       device='cuda:0') torch.Size([16])
percent tensor([0.5864, 0.5805, 0.6036, 0.6201, 0.5975, 0.6255, 0.5847, 0.5952, 0.6082,
        0.5887, 0.5885, 0.6125, 0.5785, 0.6241, 0.5924, 0.5964],
       device='cuda:0') torch.Size([16])
percent tensor([0.5392, 0.5769, 0.5273, 0.5197, 0.5550, 0.5134, 0.5531, 0.5003, 0.5945,
        0.5959, 0.6020, 0.5019, 0.5555, 0.6649, 0.4608, 0.5777],
       device='cuda:0') torch.Size([16])
percent tensor([0.5494, 0.5289, 0.6064, 0.6227, 0.6445, 0.6255, 0.5691, 0.5957, 0.5725,
        0.5473, 0.5514, 0.5808, 0.5320, 0.5896, 0.5439, 0.5913],
       device='cuda:0') torch.Size([16])
percent tensor([0.5956, 0.6145, 0.6164, 0.5785, 0.6379, 0.5152, 0.6029, 0.5444, 0.6227,
        0.6501, 0.6511, 0.6258, 0.6152, 0.6284, 0.5609, 0.5533],
       device='cuda:0') torch.Size([16])
percent tensor([0.9977, 0.9970, 0.9979, 0.9966, 0.9978, 0.9940, 0.9942, 0.9942, 0.9984,
        0.9989, 0.9993, 0.9979, 0.9971, 0.9971, 0.9928, 0.9959],
       device='cuda:0') torch.Size([16])
Epoch: 70 | Batch_idx: 0 |  Loss: (0.3086) |  Loss2: (0.0000) | Acc: (88.00%) (113/128)
Epoch: 70 | Batch_idx: 10 |  Loss: (0.2949) |  Loss2: (0.0000) | Acc: (89.00%) (1266/1408)
Epoch: 70 | Batch_idx: 20 |  Loss: (0.2900) |  Loss2: (0.0000) | Acc: (89.00%) (2416/2688)
Epoch: 70 | Batch_idx: 30 |  Loss: (0.2949) |  Loss2: (0.0000) | Acc: (89.00%) (3554/3968)
Epoch: 70 | Batch_idx: 40 |  Loss: (0.2938) |  Loss2: (0.0000) | Acc: (89.00%) (4704/5248)
Epoch: 70 | Batch_idx: 50 |  Loss: (0.2971) |  Loss2: (0.0000) | Acc: (89.00%) (5849/6528)
Epoch: 70 | Batch_idx: 60 |  Loss: (0.2971) |  Loss2: (0.0000) | Acc: (89.00%) (7005/7808)
Epoch: 70 | Batch_idx: 70 |  Loss: (0.2972) |  Loss2: (0.0000) | Acc: (89.00%) (8145/9088)
Epoch: 70 | Batch_idx: 80 |  Loss: (0.2970) |  Loss2: (0.0000) | Acc: (89.00%) (9297/10368)
Epoch: 70 | Batch_idx: 90 |  Loss: (0.2972) |  Loss2: (0.0000) | Acc: (89.00%) (10446/11648)
Epoch: 70 | Batch_idx: 100 |  Loss: (0.2986) |  Loss2: (0.0000) | Acc: (89.00%) (11575/12928)
Epoch: 70 | Batch_idx: 110 |  Loss: (0.2956) |  Loss2: (0.0000) | Acc: (89.00%) (12736/14208)
Epoch: 70 | Batch_idx: 120 |  Loss: (0.2943) |  Loss2: (0.0000) | Acc: (89.00%) (13894/15488)
Epoch: 70 | Batch_idx: 130 |  Loss: (0.2946) |  Loss2: (0.0000) | Acc: (89.00%) (15040/16768)
Epoch: 70 | Batch_idx: 140 |  Loss: (0.2939) |  Loss2: (0.0000) | Acc: (89.00%) (16197/18048)
Epoch: 70 | Batch_idx: 150 |  Loss: (0.2949) |  Loss2: (0.0000) | Acc: (89.00%) (17334/19328)
Epoch: 70 | Batch_idx: 160 |  Loss: (0.2953) |  Loss2: (0.0000) | Acc: (89.00%) (18462/20608)
Epoch: 70 | Batch_idx: 170 |  Loss: (0.2943) |  Loss2: (0.0000) | Acc: (89.00%) (19618/21888)
Epoch: 70 | Batch_idx: 180 |  Loss: (0.2934) |  Loss2: (0.0000) | Acc: (89.00%) (20772/23168)
Epoch: 70 | Batch_idx: 190 |  Loss: (0.2948) |  Loss2: (0.0000) | Acc: (89.00%) (21905/24448)
Epoch: 70 | Batch_idx: 200 |  Loss: (0.2951) |  Loss2: (0.0000) | Acc: (89.00%) (23063/25728)
Epoch: 70 | Batch_idx: 210 |  Loss: (0.2946) |  Loss2: (0.0000) | Acc: (89.00%) (24224/27008)
Epoch: 70 | Batch_idx: 220 |  Loss: (0.2952) |  Loss2: (0.0000) | Acc: (89.00%) (25374/28288)
Epoch: 70 | Batch_idx: 230 |  Loss: (0.2935) |  Loss2: (0.0000) | Acc: (89.00%) (26531/29568)
Epoch: 70 | Batch_idx: 240 |  Loss: (0.2935) |  Loss2: (0.0000) | Acc: (89.00%) (27676/30848)
Epoch: 70 | Batch_idx: 250 |  Loss: (0.2961) |  Loss2: (0.0000) | Acc: (89.00%) (28790/32128)
Epoch: 70 | Batch_idx: 260 |  Loss: (0.2961) |  Loss2: (0.0000) | Acc: (89.00%) (29945/33408)
Epoch: 70 | Batch_idx: 270 |  Loss: (0.2965) |  Loss2: (0.0000) | Acc: (89.00%) (31090/34688)
Epoch: 70 | Batch_idx: 280 |  Loss: (0.2961) |  Loss2: (0.0000) | Acc: (89.00%) (32255/35968)
Epoch: 70 | Batch_idx: 290 |  Loss: (0.2962) |  Loss2: (0.0000) | Acc: (89.00%) (33396/37248)
Epoch: 70 | Batch_idx: 300 |  Loss: (0.2960) |  Loss2: (0.0000) | Acc: (89.00%) (34550/38528)
Epoch: 70 | Batch_idx: 310 |  Loss: (0.2961) |  Loss2: (0.0000) | Acc: (89.00%) (35699/39808)
Epoch: 70 | Batch_idx: 320 |  Loss: (0.2971) |  Loss2: (0.0000) | Acc: (89.00%) (36843/41088)
Epoch: 70 | Batch_idx: 330 |  Loss: (0.2978) |  Loss2: (0.0000) | Acc: (89.00%) (37979/42368)
Epoch: 70 | Batch_idx: 340 |  Loss: (0.2984) |  Loss2: (0.0000) | Acc: (89.00%) (39122/43648)
Epoch: 70 | Batch_idx: 350 |  Loss: (0.2994) |  Loss2: (0.0000) | Acc: (89.00%) (40264/44928)
Epoch: 70 | Batch_idx: 360 |  Loss: (0.3004) |  Loss2: (0.0000) | Acc: (89.00%) (41392/46208)
Epoch: 70 | Batch_idx: 370 |  Loss: (0.3002) |  Loss2: (0.0000) | Acc: (89.00%) (42544/47488)
Epoch: 70 | Batch_idx: 380 |  Loss: (0.3013) |  Loss2: (0.0000) | Acc: (89.00%) (43665/48768)
Epoch: 70 | Batch_idx: 390 |  Loss: (0.3021) |  Loss2: (0.0000) | Acc: (89.00%) (44757/50000)
=> saving checkpoint 'drive/app/torch/save_Schedule/checkpoint_070.pth.tar'
# TEST : Loss: (0.4478) | Acc: (85.00%) (8537/10000)
percent tensor([0.4870, 0.4883, 0.4975, 0.4857, 0.4968, 0.4874, 0.4916, 0.4866, 0.4880,
        0.4913, 0.4894, 0.4963, 0.4870, 0.4864, 0.4891, 0.4859],
       device='cuda:0') torch.Size([16])
percent tensor([0.4860, 0.4659, 0.4861, 0.4873, 0.4767, 0.5025, 0.4667, 0.4732, 0.4817,
        0.4743, 0.4826, 0.4767, 0.4685, 0.4806, 0.4749, 0.4859],
       device='cuda:0') torch.Size([16])
percent tensor([0.5941, 0.5906, 0.5276, 0.5170, 0.5392, 0.6049, 0.5846, 0.5414, 0.5383,
        0.5715, 0.5672, 0.5237, 0.5863, 0.5525, 0.6106, 0.5909],
       device='cuda:0') torch.Size([16])
percent tensor([0.5843, 0.5771, 0.5971, 0.6132, 0.5929, 0.6231, 0.5871, 0.5903, 0.5987,
        0.5805, 0.5823, 0.6020, 0.5747, 0.6182, 0.5901, 0.5939],
       device='cuda:0') torch.Size([16])
percent tensor([0.5366, 0.5679, 0.5336, 0.5326, 0.5612, 0.5221, 0.5662, 0.5029, 0.5908,
        0.5796, 0.5880, 0.5111, 0.5466, 0.6583, 0.4731, 0.5734],
       device='cuda:0') torch.Size([16])
percent tensor([0.5444, 0.5174, 0.6193, 0.6272, 0.6456, 0.6222, 0.5749, 0.5955, 0.5596,
        0.5384, 0.5412, 0.5771, 0.5198, 0.5765, 0.5458, 0.5937],
       device='cuda:0') torch.Size([16])
percent tensor([0.5921, 0.6112, 0.6156, 0.5802, 0.6240, 0.5147, 0.6062, 0.5387, 0.6181,
        0.6441, 0.6542, 0.6110, 0.6105, 0.6333, 0.5553, 0.5577],
       device='cuda:0') torch.Size([16])
percent tensor([0.9978, 0.9965, 0.9983, 0.9979, 0.9979, 0.9933, 0.9950, 0.9960, 0.9983,
        0.9989, 0.9993, 0.9959, 0.9968, 0.9963, 0.9939, 0.9966],
       device='cuda:0') torch.Size([16])
Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 3, 3, 3]) tensor(184.3890, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(806.7349, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(807.3331, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([128, 64, 3, 3]) tensor(1534.1074, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([128, 64, 1, 1]) tensor(496.7439, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([128, 128, 3, 3]) tensor(2243.6724, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([256, 128, 3, 3]) tensor(4298.4863, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([256, 128, 1, 1]) tensor(1406.7864, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([256, 256, 3, 3]) tensor(6117.2510, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([512, 256, 3, 3]) tensor(11980.8975, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([512, 256, 1, 1]) tensor(3987.1174, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([512, 512, 3, 3]) tensor(16848.7949, device='cuda:0', grad_fn=<NormBackward0>)
Epoch: 71 | Batch_idx: 0 |  Loss: (0.3404) |  Loss2: (0.0000) | Acc: (85.00%) (109/128)
Epoch: 71 | Batch_idx: 10 |  Loss: (0.3247) |  Loss2: (0.0000) | Acc: (87.00%) (1237/1408)
Epoch: 71 | Batch_idx: 20 |  Loss: (0.3325) |  Loss2: (0.0000) | Acc: (88.00%) (2373/2688)
Epoch: 71 | Batch_idx: 30 |  Loss: (0.3123) |  Loss2: (0.0000) | Acc: (89.00%) (3537/3968)
Epoch: 71 | Batch_idx: 40 |  Loss: (0.3062) |  Loss2: (0.0000) | Acc: (89.00%) (4699/5248)
Epoch: 71 | Batch_idx: 50 |  Loss: (0.3120) |  Loss2: (0.0000) | Acc: (89.00%) (5830/6528)
Epoch: 71 | Batch_idx: 60 |  Loss: (0.3028) |  Loss2: (0.0000) | Acc: (89.00%) (6997/7808)
Epoch: 71 | Batch_idx: 70 |  Loss: (0.3018) |  Loss2: (0.0000) | Acc: (89.00%) (8151/9088)
Epoch: 71 | Batch_idx: 80 |  Loss: (0.3021) |  Loss2: (0.0000) | Acc: (89.00%) (9303/10368)
Epoch: 71 | Batch_idx: 90 |  Loss: (0.3035) |  Loss2: (0.0000) | Acc: (89.00%) (10450/11648)
Epoch: 71 | Batch_idx: 100 |  Loss: (0.3040) |  Loss2: (0.0000) | Acc: (89.00%) (11596/12928)
Epoch: 71 | Batch_idx: 110 |  Loss: (0.3050) |  Loss2: (0.0000) | Acc: (89.00%) (12740/14208)
Epoch: 71 | Batch_idx: 120 |  Loss: (0.3021) |  Loss2: (0.0000) | Acc: (89.00%) (13907/15488)
Epoch: 71 | Batch_idx: 130 |  Loss: (0.3000) |  Loss2: (0.0000) | Acc: (89.00%) (15059/16768)
Epoch: 71 | Batch_idx: 140 |  Loss: (0.3013) |  Loss2: (0.0000) | Acc: (89.00%) (16202/18048)
Epoch: 71 | Batch_idx: 150 |  Loss: (0.2989) |  Loss2: (0.0000) | Acc: (89.00%) (17368/19328)
Epoch: 71 | Batch_idx: 160 |  Loss: (0.2992) |  Loss2: (0.0000) | Acc: (89.00%) (18524/20608)
Epoch: 71 | Batch_idx: 170 |  Loss: (0.3002) |  Loss2: (0.0000) | Acc: (89.00%) (19656/21888)
Epoch: 71 | Batch_idx: 180 |  Loss: (0.2989) |  Loss2: (0.0000) | Acc: (89.00%) (20811/23168)
Epoch: 71 | Batch_idx: 190 |  Loss: (0.2979) |  Loss2: (0.0000) | Acc: (89.00%) (21969/24448)
Epoch: 71 | Batch_idx: 200 |  Loss: (0.2963) |  Loss2: (0.0000) | Acc: (89.00%) (23135/25728)
Epoch: 71 | Batch_idx: 210 |  Loss: (0.2966) |  Loss2: (0.0000) | Acc: (89.00%) (24270/27008)
Epoch: 71 | Batch_idx: 220 |  Loss: (0.2950) |  Loss2: (0.0000) | Acc: (89.00%) (25438/28288)
Epoch: 71 | Batch_idx: 230 |  Loss: (0.2947) |  Loss2: (0.0000) | Acc: (89.00%) (26592/29568)
Epoch: 71 | Batch_idx: 240 |  Loss: (0.2933) |  Loss2: (0.0000) | Acc: (89.00%) (27756/30848)
Epoch: 71 | Batch_idx: 250 |  Loss: (0.2940) |  Loss2: (0.0000) | Acc: (89.00%) (28906/32128)
Epoch: 71 | Batch_idx: 260 |  Loss: (0.2949) |  Loss2: (0.0000) | Acc: (89.00%) (30043/33408)
Epoch: 71 | Batch_idx: 270 |  Loss: (0.2949) |  Loss2: (0.0000) | Acc: (89.00%) (31193/34688)
Epoch: 71 | Batch_idx: 280 |  Loss: (0.2950) |  Loss2: (0.0000) | Acc: (89.00%) (32343/35968)
Epoch: 71 | Batch_idx: 290 |  Loss: (0.2950) |  Loss2: (0.0000) | Acc: (89.00%) (33490/37248)
Epoch: 71 | Batch_idx: 300 |  Loss: (0.2952) |  Loss2: (0.0000) | Acc: (89.00%) (34629/38528)
Epoch: 71 | Batch_idx: 310 |  Loss: (0.2940) |  Loss2: (0.0000) | Acc: (89.00%) (35785/39808)
Epoch: 71 | Batch_idx: 320 |  Loss: (0.2940) |  Loss2: (0.0000) | Acc: (89.00%) (36927/41088)
Epoch: 71 | Batch_idx: 330 |  Loss: (0.2944) |  Loss2: (0.0000) | Acc: (89.00%) (38071/42368)
Epoch: 71 | Batch_idx: 340 |  Loss: (0.2944) |  Loss2: (0.0000) | Acc: (89.00%) (39206/43648)
Epoch: 71 | Batch_idx: 350 |  Loss: (0.2946) |  Loss2: (0.0000) | Acc: (89.00%) (40352/44928)
Epoch: 71 | Batch_idx: 360 |  Loss: (0.2933) |  Loss2: (0.0000) | Acc: (89.00%) (41518/46208)
Epoch: 71 | Batch_idx: 370 |  Loss: (0.2937) |  Loss2: (0.0000) | Acc: (89.00%) (42667/47488)
Epoch: 71 | Batch_idx: 380 |  Loss: (0.2941) |  Loss2: (0.0000) | Acc: (89.00%) (43813/48768)
Epoch: 71 | Batch_idx: 390 |  Loss: (0.2935) |  Loss2: (0.0000) | Acc: (89.00%) (44936/50000)
# TEST : Loss: (0.4423) | Acc: (85.00%) (8545/10000)
percent tensor([0.4871, 0.4885, 0.4956, 0.4854, 0.4956, 0.4877, 0.4918, 0.4858, 0.4880,
        0.4911, 0.4893, 0.4957, 0.4867, 0.4866, 0.4891, 0.4859],
       device='cuda:0') torch.Size([16])
percent tensor([0.4850, 0.4671, 0.4900, 0.4929, 0.4783, 0.5022, 0.4681, 0.4744, 0.4786,
        0.4761, 0.4826, 0.4803, 0.4684, 0.4831, 0.4763, 0.4874],
       device='cuda:0') torch.Size([16])
percent tensor([0.5850, 0.5921, 0.5170, 0.5048, 0.5344, 0.5943, 0.5892, 0.5315, 0.5394,
        0.5652, 0.5673, 0.5212, 0.5864, 0.5602, 0.6038, 0.5819],
       device='cuda:0') torch.Size([16])
percent tensor([0.5859, 0.5820, 0.6031, 0.6186, 0.5946, 0.6215, 0.5885, 0.5926, 0.5999,
        0.5868, 0.5856, 0.6106, 0.5797, 0.6201, 0.5917, 0.5958],
       device='cuda:0') torch.Size([16])
percent tensor([0.5223, 0.5639, 0.5245, 0.5158, 0.5477, 0.5057, 0.5483, 0.4973, 0.5549,
        0.5857, 0.5805, 0.5084, 0.5376, 0.6492, 0.4622, 0.5659],
       device='cuda:0') torch.Size([16])
percent tensor([0.5483, 0.5359, 0.6174, 0.6260, 0.6415, 0.6132, 0.5800, 0.5914, 0.5660,
        0.5539, 0.5550, 0.5880, 0.5346, 0.5955, 0.5447, 0.5966],
       device='cuda:0') torch.Size([16])
percent tensor([0.5983, 0.6012, 0.6032, 0.5731, 0.6113, 0.5108, 0.5964, 0.5350, 0.6250,
        0.6319, 0.6562, 0.6100, 0.6091, 0.6235, 0.5509, 0.5578],
       device='cuda:0') torch.Size([16])
percent tensor([0.9982, 0.9963, 0.9970, 0.9976, 0.9963, 0.9974, 0.9923, 0.9950, 0.9986,
        0.9979, 0.9991, 0.9969, 0.9972, 0.9954, 0.9915, 0.9963],
       device='cuda:0') torch.Size([16])
False Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=128, out_features=16, bias=False)
True Linear(in_features=16, out_features=2, bias=False)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=128, out_features=16, bias=False)
True Linear(in_features=16, out_features=2, bias=False)
False Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=256, out_features=32, bias=False)
True Linear(in_features=32, out_features=2, bias=False)
False Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=256, out_features=32, bias=False)
True Linear(in_features=32, out_features=2, bias=False)
False Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=512, out_features=64, bias=False)
True Linear(in_features=64, out_features=2, bias=False)
False Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=512, out_features=64, bias=False)
True Linear(in_features=64, out_features=2, bias=False)
False Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1024, out_features=128, bias=False)
True Linear(in_features=128, out_features=2, bias=False)
False Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1024, out_features=128, bias=False)
True Linear(in_features=128, out_features=2, bias=False)
False Linear(in_features=512, out_features=10, bias=True)
Epoch: 72 | Batch_idx: 0 |  Loss: (0.2726) |  Loss2: (0.0000) | Acc: (90.00%) (116/128)
Epoch: 72 | Batch_idx: 10 |  Loss: (0.3119) |  Loss2: (0.0000) | Acc: (89.00%) (1259/1408)
Epoch: 72 | Batch_idx: 20 |  Loss: (0.3192) |  Loss2: (0.0000) | Acc: (89.00%) (2405/2688)
Epoch: 72 | Batch_idx: 30 |  Loss: (0.3253) |  Loss2: (0.0000) | Acc: (88.00%) (3531/3968)
Epoch: 72 | Batch_idx: 40 |  Loss: (0.3326) |  Loss2: (0.0000) | Acc: (88.00%) (4647/5248)
Epoch: 72 | Batch_idx: 50 |  Loss: (0.3311) |  Loss2: (0.0000) | Acc: (88.00%) (5778/6528)
Epoch: 72 | Batch_idx: 60 |  Loss: (0.3343) |  Loss2: (0.0000) | Acc: (88.00%) (6898/7808)
Epoch: 72 | Batch_idx: 70 |  Loss: (0.3411) |  Loss2: (0.0000) | Acc: (88.00%) (8000/9088)
Epoch: 72 | Batch_idx: 80 |  Loss: (0.3347) |  Loss2: (0.0000) | Acc: (88.00%) (9154/10368)
Epoch: 72 | Batch_idx: 90 |  Loss: (0.3376) |  Loss2: (0.0000) | Acc: (88.00%) (10267/11648)
Epoch: 72 | Batch_idx: 100 |  Loss: (0.3394) |  Loss2: (0.0000) | Acc: (88.00%) (11380/12928)
Epoch: 72 | Batch_idx: 110 |  Loss: (0.3375) |  Loss2: (0.0000) | Acc: (88.00%) (12523/14208)
Epoch: 72 | Batch_idx: 120 |  Loss: (0.3382) |  Loss2: (0.0000) | Acc: (88.00%) (13639/15488)
Epoch: 72 | Batch_idx: 130 |  Loss: (0.3407) |  Loss2: (0.0000) | Acc: (88.00%) (14761/16768)
Epoch: 72 | Batch_idx: 140 |  Loss: (0.3369) |  Loss2: (0.0000) | Acc: (88.00%) (15917/18048)
Epoch: 72 | Batch_idx: 150 |  Loss: (0.3361) |  Loss2: (0.0000) | Acc: (88.00%) (17060/19328)
Epoch: 72 | Batch_idx: 160 |  Loss: (0.3374) |  Loss2: (0.0000) | Acc: (88.00%) (18178/20608)
Epoch: 72 | Batch_idx: 170 |  Loss: (0.3371) |  Loss2: (0.0000) | Acc: (88.00%) (19301/21888)
Epoch: 72 | Batch_idx: 180 |  Loss: (0.3358) |  Loss2: (0.0000) | Acc: (88.00%) (20445/23168)
Epoch: 72 | Batch_idx: 190 |  Loss: (0.3343) |  Loss2: (0.0000) | Acc: (88.00%) (21590/24448)
Epoch: 72 | Batch_idx: 200 |  Loss: (0.3340) |  Loss2: (0.0000) | Acc: (88.00%) (22727/25728)
Epoch: 72 | Batch_idx: 210 |  Loss: (0.3338) |  Loss2: (0.0000) | Acc: (88.00%) (23852/27008)
Epoch: 72 | Batch_idx: 220 |  Loss: (0.3324) |  Loss2: (0.0000) | Acc: (88.00%) (25003/28288)
Epoch: 72 | Batch_idx: 230 |  Loss: (0.3313) |  Loss2: (0.0000) | Acc: (88.00%) (26140/29568)
Epoch: 72 | Batch_idx: 240 |  Loss: (0.3320) |  Loss2: (0.0000) | Acc: (88.00%) (27251/30848)
Epoch: 72 | Batch_idx: 250 |  Loss: (0.3316) |  Loss2: (0.0000) | Acc: (88.00%) (28386/32128)
Epoch: 72 | Batch_idx: 260 |  Loss: (0.3313) |  Loss2: (0.0000) | Acc: (88.00%) (29515/33408)
Epoch: 72 | Batch_idx: 270 |  Loss: (0.3304) |  Loss2: (0.0000) | Acc: (88.00%) (30661/34688)
Epoch: 72 | Batch_idx: 280 |  Loss: (0.3301) |  Loss2: (0.0000) | Acc: (88.00%) (31800/35968)
Epoch: 72 | Batch_idx: 290 |  Loss: (0.3292) |  Loss2: (0.0000) | Acc: (88.00%) (32945/37248)
Epoch: 72 | Batch_idx: 300 |  Loss: (0.3299) |  Loss2: (0.0000) | Acc: (88.00%) (34066/38528)
Epoch: 72 | Batch_idx: 310 |  Loss: (0.3277) |  Loss2: (0.0000) | Acc: (88.00%) (35226/39808)
Epoch: 72 | Batch_idx: 320 |  Loss: (0.3261) |  Loss2: (0.0000) | Acc: (88.00%) (36382/41088)
Epoch: 72 | Batch_idx: 330 |  Loss: (0.3260) |  Loss2: (0.0000) | Acc: (88.00%) (37532/42368)
Epoch: 72 | Batch_idx: 340 |  Loss: (0.3256) |  Loss2: (0.0000) | Acc: (88.00%) (38668/43648)
Epoch: 72 | Batch_idx: 350 |  Loss: (0.3259) |  Loss2: (0.0000) | Acc: (88.00%) (39790/44928)
Epoch: 72 | Batch_idx: 360 |  Loss: (0.3243) |  Loss2: (0.0000) | Acc: (88.00%) (40951/46208)
Epoch: 72 | Batch_idx: 370 |  Loss: (0.3234) |  Loss2: (0.0000) | Acc: (88.00%) (42097/47488)
Epoch: 72 | Batch_idx: 380 |  Loss: (0.3237) |  Loss2: (0.0000) | Acc: (88.00%) (43222/48768)
Epoch: 72 | Batch_idx: 390 |  Loss: (0.3243) |  Loss2: (0.0000) | Acc: (88.00%) (44307/50000)
# TEST : Loss: (0.4456) | Acc: (85.00%) (8514/10000)
percent tensor([0.4968, 0.4999, 0.5031, 0.4944, 0.5036, 0.4981, 0.5016, 0.4961, 0.4982,
        0.5002, 0.5002, 0.5034, 0.4968, 0.4970, 0.4999, 0.4961],
       device='cuda:0') torch.Size([16])
percent tensor([0.4937, 0.4809, 0.4936, 0.4978, 0.4865, 0.5024, 0.4807, 0.4834, 0.4874,
        0.4882, 0.4914, 0.4884, 0.4821, 0.4916, 0.4880, 0.4959],
       device='cuda:0') torch.Size([16])
percent tensor([0.5814, 0.5735, 0.5342, 0.5191, 0.5527, 0.5970, 0.5799, 0.5464, 0.5449,
        0.5550, 0.5577, 0.5311, 0.5727, 0.5526, 0.5978, 0.5736],
       device='cuda:0') torch.Size([16])
percent tensor([0.5890, 0.5908, 0.5925, 0.6098, 0.5843, 0.6334, 0.5882, 0.5845, 0.6020,
        0.5873, 0.5890, 0.6038, 0.5866, 0.6202, 0.5977, 0.6038],
       device='cuda:0') torch.Size([16])
percent tensor([0.5192, 0.5522, 0.5318, 0.5215, 0.5558, 0.4938, 0.5478, 0.5079, 0.5597,
        0.5921, 0.5739, 0.5175, 0.5283, 0.6471, 0.4540, 0.5631],
       device='cuda:0') torch.Size([16])
percent tensor([0.5442, 0.5276, 0.6141, 0.6246, 0.6394, 0.6135, 0.5744, 0.5890, 0.5641,
        0.5492, 0.5458, 0.5795, 0.5240, 0.5829, 0.5376, 0.5916],
       device='cuda:0') torch.Size([16])
percent tensor([0.5943, 0.6137, 0.6346, 0.6048, 0.6514, 0.5120, 0.6094, 0.5724, 0.6235,
        0.6307, 0.6561, 0.6361, 0.6040, 0.6236, 0.5765, 0.5620],
       device='cuda:0') torch.Size([16])
percent tensor([0.9979, 0.9974, 0.9974, 0.9977, 0.9966, 0.9970, 0.9941, 0.9957, 0.9983,
        0.9978, 0.9988, 0.9981, 0.9970, 0.9971, 0.9924, 0.9963],
       device='cuda:0') torch.Size([16])
Epoch: 73 | Batch_idx: 0 |  Loss: (0.3698) |  Loss2: (0.0000) | Acc: (86.00%) (111/128)
Epoch: 73 | Batch_idx: 10 |  Loss: (0.3056) |  Loss2: (0.0000) | Acc: (89.00%) (1262/1408)
Epoch: 73 | Batch_idx: 20 |  Loss: (0.2978) |  Loss2: (0.0000) | Acc: (89.00%) (2417/2688)
Epoch: 73 | Batch_idx: 30 |  Loss: (0.3085) |  Loss2: (0.0000) | Acc: (89.00%) (3546/3968)
Epoch: 73 | Batch_idx: 40 |  Loss: (0.3123) |  Loss2: (0.0000) | Acc: (89.00%) (4682/5248)
Epoch: 73 | Batch_idx: 50 |  Loss: (0.3161) |  Loss2: (0.0000) | Acc: (89.00%) (5819/6528)
Epoch: 73 | Batch_idx: 60 |  Loss: (0.3118) |  Loss2: (0.0000) | Acc: (89.00%) (6967/7808)
Epoch: 73 | Batch_idx: 70 |  Loss: (0.3039) |  Loss2: (0.0000) | Acc: (89.00%) (8126/9088)
Epoch: 73 | Batch_idx: 80 |  Loss: (0.3050) |  Loss2: (0.0000) | Acc: (89.00%) (9273/10368)
Epoch: 73 | Batch_idx: 90 |  Loss: (0.3047) |  Loss2: (0.0000) | Acc: (89.00%) (10413/11648)
Epoch: 73 | Batch_idx: 100 |  Loss: (0.3043) |  Loss2: (0.0000) | Acc: (89.00%) (11562/12928)
Epoch: 73 | Batch_idx: 110 |  Loss: (0.3059) |  Loss2: (0.0000) | Acc: (89.00%) (12689/14208)
Epoch: 73 | Batch_idx: 120 |  Loss: (0.3078) |  Loss2: (0.0000) | Acc: (89.00%) (13816/15488)
Epoch: 73 | Batch_idx: 130 |  Loss: (0.3094) |  Loss2: (0.0000) | Acc: (89.00%) (14944/16768)
Epoch: 73 | Batch_idx: 140 |  Loss: (0.3076) |  Loss2: (0.0000) | Acc: (89.00%) (16100/18048)
Epoch: 73 | Batch_idx: 150 |  Loss: (0.3077) |  Loss2: (0.0000) | Acc: (89.00%) (17238/19328)
Epoch: 73 | Batch_idx: 160 |  Loss: (0.3078) |  Loss2: (0.0000) | Acc: (89.00%) (18379/20608)
Epoch: 73 | Batch_idx: 170 |  Loss: (0.3089) |  Loss2: (0.0000) | Acc: (89.00%) (19515/21888)
Epoch: 73 | Batch_idx: 180 |  Loss: (0.3068) |  Loss2: (0.0000) | Acc: (89.00%) (20666/23168)
Epoch: 73 | Batch_idx: 190 |  Loss: (0.3057) |  Loss2: (0.0000) | Acc: (89.00%) (21828/24448)
Epoch: 73 | Batch_idx: 200 |  Loss: (0.3043) |  Loss2: (0.0000) | Acc: (89.00%) (22980/25728)
Epoch: 73 | Batch_idx: 210 |  Loss: (0.3047) |  Loss2: (0.0000) | Acc: (89.00%) (24123/27008)
Epoch: 73 | Batch_idx: 220 |  Loss: (0.3053) |  Loss2: (0.0000) | Acc: (89.00%) (25260/28288)
Epoch: 73 | Batch_idx: 230 |  Loss: (0.3056) |  Loss2: (0.0000) | Acc: (89.00%) (26399/29568)
Epoch: 73 | Batch_idx: 240 |  Loss: (0.3044) |  Loss2: (0.0000) | Acc: (89.00%) (27559/30848)
Epoch: 73 | Batch_idx: 250 |  Loss: (0.3031) |  Loss2: (0.0000) | Acc: (89.00%) (28717/32128)
Epoch: 73 | Batch_idx: 260 |  Loss: (0.3017) |  Loss2: (0.0000) | Acc: (89.00%) (29876/33408)
Epoch: 73 | Batch_idx: 270 |  Loss: (0.3023) |  Loss2: (0.0000) | Acc: (89.00%) (31009/34688)
Epoch: 73 | Batch_idx: 280 |  Loss: (0.3015) |  Loss2: (0.0000) | Acc: (89.00%) (32169/35968)
Epoch: 73 | Batch_idx: 290 |  Loss: (0.3014) |  Loss2: (0.0000) | Acc: (89.00%) (33321/37248)
Epoch: 73 | Batch_idx: 300 |  Loss: (0.3009) |  Loss2: (0.0000) | Acc: (89.00%) (34470/38528)
Epoch: 73 | Batch_idx: 310 |  Loss: (0.3019) |  Loss2: (0.0000) | Acc: (89.00%) (35602/39808)
Epoch: 73 | Batch_idx: 320 |  Loss: (0.3017) |  Loss2: (0.0000) | Acc: (89.00%) (36744/41088)
Epoch: 73 | Batch_idx: 330 |  Loss: (0.3013) |  Loss2: (0.0000) | Acc: (89.00%) (37889/42368)
Epoch: 73 | Batch_idx: 340 |  Loss: (0.3012) |  Loss2: (0.0000) | Acc: (89.00%) (39033/43648)
Epoch: 73 | Batch_idx: 350 |  Loss: (0.3014) |  Loss2: (0.0000) | Acc: (89.00%) (40174/44928)
Epoch: 73 | Batch_idx: 360 |  Loss: (0.3007) |  Loss2: (0.0000) | Acc: (89.00%) (41327/46208)
Epoch: 73 | Batch_idx: 370 |  Loss: (0.3002) |  Loss2: (0.0000) | Acc: (89.00%) (42476/47488)
Epoch: 73 | Batch_idx: 380 |  Loss: (0.2998) |  Loss2: (0.0000) | Acc: (89.00%) (43642/48768)
Epoch: 73 | Batch_idx: 390 |  Loss: (0.2994) |  Loss2: (0.0000) | Acc: (89.00%) (44756/50000)
# TEST : Loss: (0.4266) | Acc: (85.00%) (8551/10000)
percent tensor([0.4992, 0.5028, 0.5038, 0.4963, 0.5047, 0.5007, 0.5040, 0.4983, 0.5009,
        0.5023, 0.5031, 0.5044, 0.4994, 0.4999, 0.5026, 0.4989],
       device='cuda:0') torch.Size([16])
percent tensor([0.4920, 0.4811, 0.4910, 0.4953, 0.4835, 0.5020, 0.4797, 0.4807, 0.4858,
        0.4871, 0.4903, 0.4861, 0.4817, 0.4907, 0.4873, 0.4944],
       device='cuda:0') torch.Size([16])
percent tensor([0.5878, 0.5779, 0.5406, 0.5255, 0.5609, 0.6034, 0.5871, 0.5533, 0.5523,
        0.5612, 0.5634, 0.5374, 0.5783, 0.5589, 0.6056, 0.5789],
       device='cuda:0') torch.Size([16])
percent tensor([0.5950, 0.5979, 0.5951, 0.6141, 0.5856, 0.6495, 0.5934, 0.5862, 0.6050,
        0.5889, 0.5932, 0.6081, 0.5926, 0.6276, 0.6076, 0.6147],
       device='cuda:0') torch.Size([16])
percent tensor([0.5146, 0.5475, 0.5336, 0.5268, 0.5620, 0.4916, 0.5503, 0.5106, 0.5572,
        0.5908, 0.5727, 0.5198, 0.5171, 0.6543, 0.4497, 0.5664],
       device='cuda:0') torch.Size([16])
percent tensor([0.5467, 0.5298, 0.6170, 0.6273, 0.6448, 0.6193, 0.5780, 0.5943, 0.5661,
        0.5507, 0.5489, 0.5802, 0.5243, 0.5832, 0.5432, 0.5950],
       device='cuda:0') torch.Size([16])
percent tensor([0.5969, 0.6154, 0.6511, 0.6186, 0.6704, 0.5162, 0.6125, 0.5913, 0.6285,
        0.6299, 0.6605, 0.6422, 0.6060, 0.6182, 0.5856, 0.5595],
       device='cuda:0') torch.Size([16])
percent tensor([0.9981, 0.9975, 0.9978, 0.9980, 0.9970, 0.9972, 0.9945, 0.9962, 0.9986,
        0.9980, 0.9990, 0.9982, 0.9972, 0.9972, 0.9931, 0.9969],
       device='cuda:0') torch.Size([16])
Epoch: 74 | Batch_idx: 0 |  Loss: (0.2674) |  Loss2: (0.0000) | Acc: (89.00%) (114/128)
Epoch: 74 | Batch_idx: 10 |  Loss: (0.2731) |  Loss2: (0.0000) | Acc: (89.00%) (1266/1408)
Epoch: 74 | Batch_idx: 20 |  Loss: (0.2819) |  Loss2: (0.0000) | Acc: (90.00%) (2420/2688)
Epoch: 74 | Batch_idx: 30 |  Loss: (0.2814) |  Loss2: (0.0000) | Acc: (90.00%) (3577/3968)
Epoch: 74 | Batch_idx: 40 |  Loss: (0.2836) |  Loss2: (0.0000) | Acc: (90.00%) (4739/5248)
Epoch: 74 | Batch_idx: 50 |  Loss: (0.2868) |  Loss2: (0.0000) | Acc: (90.00%) (5891/6528)
Epoch: 74 | Batch_idx: 60 |  Loss: (0.2885) |  Loss2: (0.0000) | Acc: (90.00%) (7040/7808)
Epoch: 74 | Batch_idx: 70 |  Loss: (0.2889) |  Loss2: (0.0000) | Acc: (90.00%) (8186/9088)
Epoch: 74 | Batch_idx: 80 |  Loss: (0.2848) |  Loss2: (0.0000) | Acc: (90.00%) (9362/10368)
Epoch: 74 | Batch_idx: 90 |  Loss: (0.2858) |  Loss2: (0.0000) | Acc: (90.00%) (10515/11648)
Epoch: 74 | Batch_idx: 100 |  Loss: (0.2866) |  Loss2: (0.0000) | Acc: (90.00%) (11666/12928)
Epoch: 74 | Batch_idx: 110 |  Loss: (0.2865) |  Loss2: (0.0000) | Acc: (90.00%) (12814/14208)
Epoch: 74 | Batch_idx: 120 |  Loss: (0.2865) |  Loss2: (0.0000) | Acc: (90.00%) (13967/15488)
Epoch: 74 | Batch_idx: 130 |  Loss: (0.2864) |  Loss2: (0.0000) | Acc: (90.00%) (15116/16768)
Epoch: 74 | Batch_idx: 140 |  Loss: (0.2848) |  Loss2: (0.0000) | Acc: (90.00%) (16279/18048)
Epoch: 74 | Batch_idx: 150 |  Loss: (0.2823) |  Loss2: (0.0000) | Acc: (90.00%) (17450/19328)
Epoch: 74 | Batch_idx: 160 |  Loss: (0.2832) |  Loss2: (0.0000) | Acc: (90.00%) (18595/20608)
Epoch: 74 | Batch_idx: 170 |  Loss: (0.2837) |  Loss2: (0.0000) | Acc: (90.00%) (19750/21888)
Epoch: 74 | Batch_idx: 180 |  Loss: (0.2818) |  Loss2: (0.0000) | Acc: (90.00%) (20930/23168)
Epoch: 74 | Batch_idx: 190 |  Loss: (0.2803) |  Loss2: (0.0000) | Acc: (90.00%) (22099/24448)
Epoch: 74 | Batch_idx: 200 |  Loss: (0.2818) |  Loss2: (0.0000) | Acc: (90.00%) (23236/25728)
Epoch: 74 | Batch_idx: 210 |  Loss: (0.2831) |  Loss2: (0.0000) | Acc: (90.00%) (24381/27008)
Epoch: 74 | Batch_idx: 220 |  Loss: (0.2828) |  Loss2: (0.0000) | Acc: (90.00%) (25526/28288)
Epoch: 74 | Batch_idx: 230 |  Loss: (0.2822) |  Loss2: (0.0000) | Acc: (90.00%) (26690/29568)
Epoch: 74 | Batch_idx: 240 |  Loss: (0.2826) |  Loss2: (0.0000) | Acc: (90.00%) (27837/30848)
Epoch: 74 | Batch_idx: 250 |  Loss: (0.2833) |  Loss2: (0.0000) | Acc: (90.00%) (28985/32128)
Epoch: 74 | Batch_idx: 260 |  Loss: (0.2834) |  Loss2: (0.0000) | Acc: (90.00%) (30141/33408)
Epoch: 74 | Batch_idx: 270 |  Loss: (0.2838) |  Loss2: (0.0000) | Acc: (90.00%) (31282/34688)
Epoch: 74 | Batch_idx: 280 |  Loss: (0.2836) |  Loss2: (0.0000) | Acc: (90.00%) (32438/35968)
Epoch: 74 | Batch_idx: 290 |  Loss: (0.2841) |  Loss2: (0.0000) | Acc: (90.00%) (33584/37248)
Epoch: 74 | Batch_idx: 300 |  Loss: (0.2836) |  Loss2: (0.0000) | Acc: (90.00%) (34739/38528)
Epoch: 74 | Batch_idx: 310 |  Loss: (0.2843) |  Loss2: (0.0000) | Acc: (90.00%) (35893/39808)
Epoch: 74 | Batch_idx: 320 |  Loss: (0.2842) |  Loss2: (0.0000) | Acc: (90.00%) (37047/41088)
Epoch: 74 | Batch_idx: 330 |  Loss: (0.2851) |  Loss2: (0.0000) | Acc: (90.00%) (38192/42368)
Epoch: 74 | Batch_idx: 340 |  Loss: (0.2850) |  Loss2: (0.0000) | Acc: (90.00%) (39348/43648)
Epoch: 74 | Batch_idx: 350 |  Loss: (0.2849) |  Loss2: (0.0000) | Acc: (90.00%) (40500/44928)
Epoch: 74 | Batch_idx: 360 |  Loss: (0.2855) |  Loss2: (0.0000) | Acc: (90.00%) (41657/46208)
Epoch: 74 | Batch_idx: 370 |  Loss: (0.2852) |  Loss2: (0.0000) | Acc: (90.00%) (42810/47488)
Epoch: 74 | Batch_idx: 380 |  Loss: (0.2851) |  Loss2: (0.0000) | Acc: (90.00%) (43965/48768)
Epoch: 74 | Batch_idx: 390 |  Loss: (0.2854) |  Loss2: (0.0000) | Acc: (90.00%) (45071/50000)
# TEST : Loss: (0.4175) | Acc: (85.00%) (8594/10000)
percent tensor([0.5023, 0.5066, 0.5056, 0.4991, 0.5068, 0.5038, 0.5073, 0.5016, 0.5043,
        0.5055, 0.5068, 0.5065, 0.5027, 0.5038, 0.5061, 0.5023],
       device='cuda:0') torch.Size([16])
percent tensor([0.4939, 0.4841, 0.4917, 0.4967, 0.4850, 0.5026, 0.4818, 0.4822, 0.4876,
        0.4888, 0.4925, 0.4876, 0.4842, 0.4929, 0.4900, 0.4965],
       device='cuda:0') torch.Size([16])
percent tensor([0.5998, 0.5886, 0.5462, 0.5320, 0.5682, 0.6172, 0.5978, 0.5595, 0.5612,
        0.5716, 0.5741, 0.5442, 0.5900, 0.5681, 0.6194, 0.5900],
       device='cuda:0') torch.Size([16])
percent tensor([0.5984, 0.6018, 0.5963, 0.6160, 0.5868, 0.6602, 0.5956, 0.5872, 0.6058,
        0.5881, 0.5941, 0.6091, 0.5950, 0.6295, 0.6146, 0.6213],
       device='cuda:0') torch.Size([16])
percent tensor([0.5229, 0.5524, 0.5368, 0.5323, 0.5652, 0.4948, 0.5565, 0.5135, 0.5616,
        0.5945, 0.5780, 0.5228, 0.5212, 0.6602, 0.4546, 0.5759],
       device='cuda:0') torch.Size([16])
percent tensor([0.5570, 0.5391, 0.6272, 0.6372, 0.6569, 0.6307, 0.5890, 0.6063, 0.5745,
        0.5601, 0.5582, 0.5880, 0.5331, 0.5912, 0.5538, 0.6064],
       device='cuda:0') torch.Size([16])
percent tensor([0.6033, 0.6245, 0.6606, 0.6266, 0.6809, 0.5217, 0.6166, 0.5985, 0.6389,
        0.6350, 0.6720, 0.6479, 0.6181, 0.6213, 0.5921, 0.5573],
       device='cuda:0') torch.Size([16])
percent tensor([0.9982, 0.9977, 0.9980, 0.9983, 0.9974, 0.9974, 0.9950, 0.9965, 0.9988,
        0.9982, 0.9992, 0.9983, 0.9975, 0.9974, 0.9938, 0.9971],
       device='cuda:0') torch.Size([16])
Epoch: 75 | Batch_idx: 0 |  Loss: (0.2597) |  Loss2: (0.0000) | Acc: (89.00%) (115/128)
Epoch: 75 | Batch_idx: 10 |  Loss: (0.2913) |  Loss2: (0.0000) | Acc: (90.00%) (1268/1408)
Epoch: 75 | Batch_idx: 20 |  Loss: (0.2819) |  Loss2: (0.0000) | Acc: (90.00%) (2442/2688)
Epoch: 75 | Batch_idx: 30 |  Loss: (0.2912) |  Loss2: (0.0000) | Acc: (90.00%) (3600/3968)
Epoch: 75 | Batch_idx: 40 |  Loss: (0.2928) |  Loss2: (0.0000) | Acc: (90.00%) (4742/5248)
Epoch: 75 | Batch_idx: 50 |  Loss: (0.2866) |  Loss2: (0.0000) | Acc: (90.00%) (5903/6528)
Epoch: 75 | Batch_idx: 60 |  Loss: (0.2871) |  Loss2: (0.0000) | Acc: (90.00%) (7068/7808)
Epoch: 75 | Batch_idx: 70 |  Loss: (0.2883) |  Loss2: (0.0000) | Acc: (90.00%) (8215/9088)
Epoch: 75 | Batch_idx: 80 |  Loss: (0.2867) |  Loss2: (0.0000) | Acc: (90.00%) (9385/10368)
Epoch: 75 | Batch_idx: 90 |  Loss: (0.2908) |  Loss2: (0.0000) | Acc: (90.00%) (10521/11648)
Epoch: 75 | Batch_idx: 100 |  Loss: (0.2913) |  Loss2: (0.0000) | Acc: (90.00%) (11667/12928)
Epoch: 75 | Batch_idx: 110 |  Loss: (0.2914) |  Loss2: (0.0000) | Acc: (90.00%) (12810/14208)
Epoch: 75 | Batch_idx: 120 |  Loss: (0.2921) |  Loss2: (0.0000) | Acc: (90.00%) (13949/15488)
Epoch: 75 | Batch_idx: 130 |  Loss: (0.2906) |  Loss2: (0.0000) | Acc: (90.00%) (15112/16768)
Epoch: 75 | Batch_idx: 140 |  Loss: (0.2869) |  Loss2: (0.0000) | Acc: (90.00%) (16292/18048)
Epoch: 75 | Batch_idx: 150 |  Loss: (0.2848) |  Loss2: (0.0000) | Acc: (90.00%) (17463/19328)
Epoch: 75 | Batch_idx: 160 |  Loss: (0.2858) |  Loss2: (0.0000) | Acc: (90.00%) (18605/20608)
Epoch: 75 | Batch_idx: 170 |  Loss: (0.2860) |  Loss2: (0.0000) | Acc: (90.00%) (19762/21888)
Epoch: 75 | Batch_idx: 180 |  Loss: (0.2852) |  Loss2: (0.0000) | Acc: (90.00%) (20905/23168)
Epoch: 75 | Batch_idx: 190 |  Loss: (0.2850) |  Loss2: (0.0000) | Acc: (90.00%) (22060/24448)
Epoch: 75 | Batch_idx: 200 |  Loss: (0.2853) |  Loss2: (0.0000) | Acc: (90.00%) (23209/25728)
Epoch: 75 | Batch_idx: 210 |  Loss: (0.2854) |  Loss2: (0.0000) | Acc: (90.00%) (24360/27008)
Epoch: 75 | Batch_idx: 220 |  Loss: (0.2838) |  Loss2: (0.0000) | Acc: (90.00%) (25528/28288)
Epoch: 75 | Batch_idx: 230 |  Loss: (0.2834) |  Loss2: (0.0000) | Acc: (90.00%) (26691/29568)
Epoch: 75 | Batch_idx: 240 |  Loss: (0.2830) |  Loss2: (0.0000) | Acc: (90.00%) (27836/30848)
Epoch: 75 | Batch_idx: 250 |  Loss: (0.2823) |  Loss2: (0.0000) | Acc: (90.00%) (28985/32128)
Epoch: 75 | Batch_idx: 260 |  Loss: (0.2827) |  Loss2: (0.0000) | Acc: (90.00%) (30128/33408)
Epoch: 75 | Batch_idx: 270 |  Loss: (0.2819) |  Loss2: (0.0000) | Acc: (90.00%) (31284/34688)
Epoch: 75 | Batch_idx: 280 |  Loss: (0.2811) |  Loss2: (0.0000) | Acc: (90.00%) (32446/35968)
Epoch: 75 | Batch_idx: 290 |  Loss: (0.2801) |  Loss2: (0.0000) | Acc: (90.00%) (33606/37248)
Epoch: 75 | Batch_idx: 300 |  Loss: (0.2797) |  Loss2: (0.0000) | Acc: (90.00%) (34769/38528)
Epoch: 75 | Batch_idx: 310 |  Loss: (0.2808) |  Loss2: (0.0000) | Acc: (90.00%) (35907/39808)
Epoch: 75 | Batch_idx: 320 |  Loss: (0.2814) |  Loss2: (0.0000) | Acc: (90.00%) (37051/41088)
Epoch: 75 | Batch_idx: 330 |  Loss: (0.2812) |  Loss2: (0.0000) | Acc: (90.00%) (38207/42368)
Epoch: 75 | Batch_idx: 340 |  Loss: (0.2805) |  Loss2: (0.0000) | Acc: (90.00%) (39362/43648)
Epoch: 75 | Batch_idx: 350 |  Loss: (0.2806) |  Loss2: (0.0000) | Acc: (90.00%) (40511/44928)
Epoch: 75 | Batch_idx: 360 |  Loss: (0.2807) |  Loss2: (0.0000) | Acc: (90.00%) (41673/46208)
Epoch: 75 | Batch_idx: 370 |  Loss: (0.2810) |  Loss2: (0.0000) | Acc: (90.00%) (42829/47488)
Epoch: 75 | Batch_idx: 380 |  Loss: (0.2812) |  Loss2: (0.0000) | Acc: (90.00%) (43984/48768)
Epoch: 75 | Batch_idx: 390 |  Loss: (0.2805) |  Loss2: (0.0000) | Acc: (90.00%) (45110/50000)
=> saving checkpoint 'drive/app/torch/save_Schedule/checkpoint_075.pth.tar'
# TEST : Loss: (0.4118) | Acc: (86.00%) (8621/10000)
percent tensor([0.5012, 0.5054, 0.5046, 0.4981, 0.5057, 0.5030, 0.5061, 0.5004, 0.5032,
        0.5043, 0.5057, 0.5054, 0.5016, 0.5028, 0.5050, 0.5012],
       device='cuda:0') torch.Size([16])
percent tensor([0.4927, 0.4831, 0.4902, 0.4953, 0.4833, 0.5025, 0.4804, 0.4805, 0.4867,
        0.4878, 0.4916, 0.4861, 0.4832, 0.4922, 0.4887, 0.4953],
       device='cuda:0') torch.Size([16])
percent tensor([0.6002, 0.5874, 0.5449, 0.5303, 0.5674, 0.6173, 0.5971, 0.5584, 0.5620,
        0.5708, 0.5752, 0.5431, 0.5915, 0.5652, 0.6198, 0.5888],
       device='cuda:0') torch.Size([16])
percent tensor([0.5927, 0.5950, 0.5910, 0.6116, 0.5815, 0.6608, 0.5886, 0.5807, 0.5997,
        0.5810, 0.5871, 0.6025, 0.5883, 0.6234, 0.6100, 0.6179],
       device='cuda:0') torch.Size([16])
percent tensor([0.5248, 0.5511, 0.5386, 0.5372, 0.5690, 0.4957, 0.5581, 0.5142, 0.5632,
        0.5947, 0.5784, 0.5242, 0.5203, 0.6622, 0.4535, 0.5796],
       device='cuda:0') torch.Size([16])
percent tensor([0.5537, 0.5359, 0.6291, 0.6393, 0.6605, 0.6322, 0.5874, 0.6072, 0.5717,
        0.5578, 0.5546, 0.5872, 0.5284, 0.5868, 0.5521, 0.6050],
       device='cuda:0') torch.Size([16])
percent tensor([0.6122, 0.6369, 0.6705, 0.6353, 0.6904, 0.5294, 0.6212, 0.6041, 0.6505,
        0.6427, 0.6827, 0.6556, 0.6321, 0.6284, 0.5988, 0.5590],
       device='cuda:0') torch.Size([16])
percent tensor([0.9983, 0.9981, 0.9984, 0.9985, 0.9979, 0.9976, 0.9956, 0.9970, 0.9989,
        0.9984, 0.9993, 0.9986, 0.9978, 0.9978, 0.9945, 0.9975],
       device='cuda:0') torch.Size([16])
Epoch: 76 | Batch_idx: 0 |  Loss: (0.3058) |  Loss2: (0.0000) | Acc: (92.00%) (118/128)
Epoch: 76 | Batch_idx: 10 |  Loss: (0.2677) |  Loss2: (0.0000) | Acc: (91.00%) (1286/1408)
Epoch: 76 | Batch_idx: 20 |  Loss: (0.2721) |  Loss2: (0.0000) | Acc: (91.00%) (2449/2688)
Epoch: 76 | Batch_idx: 30 |  Loss: (0.2760) |  Loss2: (0.0000) | Acc: (90.00%) (3607/3968)
Epoch: 76 | Batch_idx: 40 |  Loss: (0.2757) |  Loss2: (0.0000) | Acc: (90.00%) (4769/5248)
Epoch: 76 | Batch_idx: 50 |  Loss: (0.2730) |  Loss2: (0.0000) | Acc: (90.00%) (5931/6528)
Epoch: 76 | Batch_idx: 60 |  Loss: (0.2698) |  Loss2: (0.0000) | Acc: (90.00%) (7102/7808)
Epoch: 76 | Batch_idx: 70 |  Loss: (0.2710) |  Loss2: (0.0000) | Acc: (90.00%) (8256/9088)
Epoch: 76 | Batch_idx: 80 |  Loss: (0.2708) |  Loss2: (0.0000) | Acc: (90.00%) (9415/10368)
Epoch: 76 | Batch_idx: 90 |  Loss: (0.2717) |  Loss2: (0.0000) | Acc: (90.00%) (10572/11648)
Epoch: 76 | Batch_idx: 100 |  Loss: (0.2710) |  Loss2: (0.0000) | Acc: (90.00%) (11741/12928)
Epoch: 76 | Batch_idx: 110 |  Loss: (0.2745) |  Loss2: (0.0000) | Acc: (90.00%) (12886/14208)
Epoch: 76 | Batch_idx: 120 |  Loss: (0.2749) |  Loss2: (0.0000) | Acc: (90.00%) (14035/15488)
Epoch: 76 | Batch_idx: 130 |  Loss: (0.2744) |  Loss2: (0.0000) | Acc: (90.00%) (15206/16768)
Epoch: 76 | Batch_idx: 140 |  Loss: (0.2738) |  Loss2: (0.0000) | Acc: (90.00%) (16356/18048)
Epoch: 76 | Batch_idx: 150 |  Loss: (0.2764) |  Loss2: (0.0000) | Acc: (90.00%) (17501/19328)
Epoch: 76 | Batch_idx: 160 |  Loss: (0.2779) |  Loss2: (0.0000) | Acc: (90.00%) (18650/20608)
Epoch: 76 | Batch_idx: 170 |  Loss: (0.2775) |  Loss2: (0.0000) | Acc: (90.00%) (19813/21888)
Epoch: 76 | Batch_idx: 180 |  Loss: (0.2782) |  Loss2: (0.0000) | Acc: (90.00%) (20961/23168)
Epoch: 76 | Batch_idx: 190 |  Loss: (0.2789) |  Loss2: (0.0000) | Acc: (90.00%) (22099/24448)
Epoch: 76 | Batch_idx: 200 |  Loss: (0.2805) |  Loss2: (0.0000) | Acc: (90.00%) (23244/25728)
Epoch: 76 | Batch_idx: 210 |  Loss: (0.2810) |  Loss2: (0.0000) | Acc: (90.00%) (24394/27008)
Epoch: 76 | Batch_idx: 220 |  Loss: (0.2811) |  Loss2: (0.0000) | Acc: (90.00%) (25550/28288)
Epoch: 76 | Batch_idx: 230 |  Loss: (0.2817) |  Loss2: (0.0000) | Acc: (90.00%) (26695/29568)
Epoch: 76 | Batch_idx: 240 |  Loss: (0.2823) |  Loss2: (0.0000) | Acc: (90.00%) (27848/30848)
Epoch: 76 | Batch_idx: 250 |  Loss: (0.2820) |  Loss2: (0.0000) | Acc: (90.00%) (29018/32128)
Epoch: 76 | Batch_idx: 260 |  Loss: (0.2813) |  Loss2: (0.0000) | Acc: (90.00%) (30182/33408)
Epoch: 76 | Batch_idx: 270 |  Loss: (0.2811) |  Loss2: (0.0000) | Acc: (90.00%) (31332/34688)
Epoch: 76 | Batch_idx: 280 |  Loss: (0.2809) |  Loss2: (0.0000) | Acc: (90.00%) (32493/35968)
Epoch: 76 | Batch_idx: 290 |  Loss: (0.2793) |  Loss2: (0.0000) | Acc: (90.00%) (33667/37248)
Epoch: 76 | Batch_idx: 300 |  Loss: (0.2797) |  Loss2: (0.0000) | Acc: (90.00%) (34814/38528)
Epoch: 76 | Batch_idx: 310 |  Loss: (0.2799) |  Loss2: (0.0000) | Acc: (90.00%) (35972/39808)
Epoch: 76 | Batch_idx: 320 |  Loss: (0.2792) |  Loss2: (0.0000) | Acc: (90.00%) (37133/41088)
Epoch: 76 | Batch_idx: 330 |  Loss: (0.2781) |  Loss2: (0.0000) | Acc: (90.00%) (38302/42368)
Epoch: 76 | Batch_idx: 340 |  Loss: (0.2777) |  Loss2: (0.0000) | Acc: (90.00%) (39453/43648)
Epoch: 76 | Batch_idx: 350 |  Loss: (0.2784) |  Loss2: (0.0000) | Acc: (90.00%) (40593/44928)
Epoch: 76 | Batch_idx: 360 |  Loss: (0.2781) |  Loss2: (0.0000) | Acc: (90.00%) (41755/46208)
Epoch: 76 | Batch_idx: 370 |  Loss: (0.2782) |  Loss2: (0.0000) | Acc: (90.00%) (42918/47488)
Epoch: 76 | Batch_idx: 380 |  Loss: (0.2778) |  Loss2: (0.0000) | Acc: (90.00%) (44083/48768)
Epoch: 76 | Batch_idx: 390 |  Loss: (0.2777) |  Loss2: (0.0000) | Acc: (90.00%) (45206/50000)
# TEST : Loss: (0.4090) | Acc: (86.00%) (8609/10000)
percent tensor([0.5018, 0.5059, 0.5049, 0.4984, 0.5061, 0.5036, 0.5065, 0.5009, 0.5038,
        0.5048, 0.5063, 0.5057, 0.5022, 0.5033, 0.5055, 0.5018],
       device='cuda:0') torch.Size([16])
percent tensor([0.4917, 0.4820, 0.4889, 0.4941, 0.4816, 0.5023, 0.4789, 0.4789, 0.4856,
        0.4866, 0.4906, 0.4846, 0.4823, 0.4915, 0.4876, 0.4942],
       device='cuda:0') torch.Size([16])
percent tensor([0.6036, 0.5894, 0.5452, 0.5317, 0.5678, 0.6215, 0.5987, 0.5587, 0.5653,
        0.5730, 0.5787, 0.5441, 0.5952, 0.5677, 0.6226, 0.5914],
       device='cuda:0') torch.Size([16])
percent tensor([0.5983, 0.6020, 0.5952, 0.6161, 0.5851, 0.6696, 0.5941, 0.5848, 0.6050,
        0.5856, 0.5930, 0.6081, 0.5952, 0.6292, 0.6181, 0.6252],
       device='cuda:0') torch.Size([16])
percent tensor([0.5209, 0.5516, 0.5283, 0.5302, 0.5576, 0.4893, 0.5525, 0.5015, 0.5614,
        0.5943, 0.5788, 0.5180, 0.5204, 0.6649, 0.4460, 0.5741],
       device='cuda:0') torch.Size([16])
percent tensor([0.5541, 0.5367, 0.6319, 0.6435, 0.6648, 0.6364, 0.5885, 0.6099, 0.5729,
        0.5586, 0.5545, 0.5893, 0.5287, 0.5871, 0.5540, 0.6068],
       device='cuda:0') torch.Size([16])
percent tensor([0.6118, 0.6385, 0.6752, 0.6389, 0.6952, 0.5293, 0.6215, 0.6036, 0.6532,
        0.6431, 0.6868, 0.6564, 0.6352, 0.6281, 0.5980, 0.5560],
       device='cuda:0') torch.Size([16])
percent tensor([0.9985, 0.9981, 0.9985, 0.9986, 0.9981, 0.9978, 0.9959, 0.9971, 0.9990,
        0.9985, 0.9993, 0.9987, 0.9979, 0.9980, 0.9950, 0.9979],
       device='cuda:0') torch.Size([16])
Epoch: 77 | Batch_idx: 0 |  Loss: (0.3147) |  Loss2: (0.0000) | Acc: (89.00%) (114/128)
Epoch: 77 | Batch_idx: 10 |  Loss: (0.2580) |  Loss2: (0.0000) | Acc: (90.00%) (1277/1408)
Epoch: 77 | Batch_idx: 20 |  Loss: (0.2674) |  Loss2: (0.0000) | Acc: (90.00%) (2436/2688)
Epoch: 77 | Batch_idx: 30 |  Loss: (0.2757) |  Loss2: (0.0000) | Acc: (90.00%) (3585/3968)
Epoch: 77 | Batch_idx: 40 |  Loss: (0.2772) |  Loss2: (0.0000) | Acc: (90.00%) (4737/5248)
Epoch: 77 | Batch_idx: 50 |  Loss: (0.2752) |  Loss2: (0.0000) | Acc: (90.00%) (5898/6528)
Epoch: 77 | Batch_idx: 60 |  Loss: (0.2736) |  Loss2: (0.0000) | Acc: (90.00%) (7063/7808)
Epoch: 77 | Batch_idx: 70 |  Loss: (0.2741) |  Loss2: (0.0000) | Acc: (90.00%) (8210/9088)
Epoch: 77 | Batch_idx: 80 |  Loss: (0.2734) |  Loss2: (0.0000) | Acc: (90.00%) (9362/10368)
Epoch: 77 | Batch_idx: 90 |  Loss: (0.2734) |  Loss2: (0.0000) | Acc: (90.00%) (10518/11648)
Epoch: 77 | Batch_idx: 100 |  Loss: (0.2737) |  Loss2: (0.0000) | Acc: (90.00%) (11675/12928)
Epoch: 77 | Batch_idx: 110 |  Loss: (0.2747) |  Loss2: (0.0000) | Acc: (90.00%) (12833/14208)
Epoch: 77 | Batch_idx: 120 |  Loss: (0.2751) |  Loss2: (0.0000) | Acc: (90.00%) (13993/15488)
Epoch: 77 | Batch_idx: 130 |  Loss: (0.2744) |  Loss2: (0.0000) | Acc: (90.00%) (15149/16768)
Epoch: 77 | Batch_idx: 140 |  Loss: (0.2736) |  Loss2: (0.0000) | Acc: (90.00%) (16313/18048)
Epoch: 77 | Batch_idx: 150 |  Loss: (0.2745) |  Loss2: (0.0000) | Acc: (90.00%) (17469/19328)
Epoch: 77 | Batch_idx: 160 |  Loss: (0.2754) |  Loss2: (0.0000) | Acc: (90.00%) (18623/20608)
Epoch: 77 | Batch_idx: 170 |  Loss: (0.2751) |  Loss2: (0.0000) | Acc: (90.00%) (19788/21888)
Epoch: 77 | Batch_idx: 180 |  Loss: (0.2749) |  Loss2: (0.0000) | Acc: (90.00%) (20947/23168)
Epoch: 77 | Batch_idx: 190 |  Loss: (0.2735) |  Loss2: (0.0000) | Acc: (90.00%) (22105/24448)
Epoch: 77 | Batch_idx: 200 |  Loss: (0.2748) |  Loss2: (0.0000) | Acc: (90.00%) (23268/25728)
Epoch: 77 | Batch_idx: 210 |  Loss: (0.2745) |  Loss2: (0.0000) | Acc: (90.00%) (24430/27008)
Epoch: 77 | Batch_idx: 220 |  Loss: (0.2739) |  Loss2: (0.0000) | Acc: (90.00%) (25593/28288)
Epoch: 77 | Batch_idx: 230 |  Loss: (0.2715) |  Loss2: (0.0000) | Acc: (90.00%) (26780/29568)
Epoch: 77 | Batch_idx: 240 |  Loss: (0.2719) |  Loss2: (0.0000) | Acc: (90.00%) (27947/30848)
Epoch: 77 | Batch_idx: 250 |  Loss: (0.2721) |  Loss2: (0.0000) | Acc: (90.00%) (29109/32128)
Epoch: 77 | Batch_idx: 260 |  Loss: (0.2722) |  Loss2: (0.0000) | Acc: (90.00%) (30271/33408)
Epoch: 77 | Batch_idx: 270 |  Loss: (0.2736) |  Loss2: (0.0000) | Acc: (90.00%) (31415/34688)
Epoch: 77 | Batch_idx: 280 |  Loss: (0.2742) |  Loss2: (0.0000) | Acc: (90.00%) (32561/35968)
Epoch: 77 | Batch_idx: 290 |  Loss: (0.2745) |  Loss2: (0.0000) | Acc: (90.00%) (33719/37248)
Epoch: 77 | Batch_idx: 300 |  Loss: (0.2745) |  Loss2: (0.0000) | Acc: (90.00%) (34869/38528)
Epoch: 77 | Batch_idx: 310 |  Loss: (0.2747) |  Loss2: (0.0000) | Acc: (90.00%) (36033/39808)
Epoch: 77 | Batch_idx: 320 |  Loss: (0.2748) |  Loss2: (0.0000) | Acc: (90.00%) (37195/41088)
Epoch: 77 | Batch_idx: 330 |  Loss: (0.2749) |  Loss2: (0.0000) | Acc: (90.00%) (38345/42368)
Epoch: 77 | Batch_idx: 340 |  Loss: (0.2751) |  Loss2: (0.0000) | Acc: (90.00%) (39492/43648)
Epoch: 77 | Batch_idx: 350 |  Loss: (0.2747) |  Loss2: (0.0000) | Acc: (90.00%) (40651/44928)
Epoch: 77 | Batch_idx: 360 |  Loss: (0.2742) |  Loss2: (0.0000) | Acc: (90.00%) (41819/46208)
Epoch: 77 | Batch_idx: 370 |  Loss: (0.2738) |  Loss2: (0.0000) | Acc: (90.00%) (42980/47488)
Epoch: 77 | Batch_idx: 380 |  Loss: (0.2734) |  Loss2: (0.0000) | Acc: (90.00%) (44147/48768)
Epoch: 77 | Batch_idx: 390 |  Loss: (0.2730) |  Loss2: (0.0000) | Acc: (90.00%) (45270/50000)
# TEST : Loss: (0.4008) | Acc: (86.00%) (8637/10000)
percent tensor([0.5025, 0.5065, 0.5052, 0.4990, 0.5067, 0.5045, 0.5071, 0.5015, 0.5045,
        0.5053, 0.5071, 0.5060, 0.5029, 0.5040, 0.5063, 0.5025],
       device='cuda:0') torch.Size([16])
percent tensor([0.4916, 0.4817, 0.4885, 0.4940, 0.4815, 0.5024, 0.4787, 0.4788, 0.4860,
        0.4863, 0.4906, 0.4844, 0.4822, 0.4917, 0.4871, 0.4940],
       device='cuda:0') torch.Size([16])
percent tensor([0.6025, 0.5868, 0.5416, 0.5279, 0.5647, 0.6193, 0.5970, 0.5555, 0.5627,
        0.5697, 0.5765, 0.5399, 0.5937, 0.5636, 0.6218, 0.5886],
       device='cuda:0') torch.Size([16])
percent tensor([0.5979, 0.6009, 0.5949, 0.6156, 0.5847, 0.6709, 0.5932, 0.5838, 0.6051,
        0.5843, 0.5920, 0.6073, 0.5950, 0.6284, 0.6182, 0.6254],
       device='cuda:0') torch.Size([16])
percent tensor([0.5297, 0.5587, 0.5313, 0.5344, 0.5622, 0.4943, 0.5597, 0.5055, 0.5710,
        0.6013, 0.5862, 0.5203, 0.5282, 0.6702, 0.4523, 0.5831],
       device='cuda:0') torch.Size([16])
percent tensor([0.5636, 0.5460, 0.6434, 0.6548, 0.6771, 0.6460, 0.5995, 0.6215, 0.5826,
        0.5693, 0.5644, 0.6002, 0.5372, 0.5971, 0.5634, 0.6175],
       device='cuda:0') torch.Size([16])
percent tensor([0.6077, 0.6392, 0.6726, 0.6349, 0.6942, 0.5272, 0.6159, 0.5985, 0.6525,
        0.6417, 0.6871, 0.6534, 0.6358, 0.6261, 0.5907, 0.5491],
       device='cuda:0') torch.Size([16])
percent tensor([0.9986, 0.9984, 0.9987, 0.9988, 0.9983, 0.9981, 0.9965, 0.9976, 0.9991,
        0.9987, 0.9994, 0.9988, 0.9981, 0.9982, 0.9954, 0.9981],
       device='cuda:0') torch.Size([16])
Epoch: 78 | Batch_idx: 0 |  Loss: (0.2095) |  Loss2: (0.0000) | Acc: (94.00%) (121/128)
Epoch: 78 | Batch_idx: 10 |  Loss: (0.2497) |  Loss2: (0.0000) | Acc: (91.00%) (1286/1408)
Epoch: 78 | Batch_idx: 20 |  Loss: (0.2536) |  Loss2: (0.0000) | Acc: (91.00%) (2450/2688)
Epoch: 78 | Batch_idx: 30 |  Loss: (0.2643) |  Loss2: (0.0000) | Acc: (90.00%) (3605/3968)
Epoch: 78 | Batch_idx: 40 |  Loss: (0.2599) |  Loss2: (0.0000) | Acc: (90.00%) (4768/5248)
Epoch: 78 | Batch_idx: 50 |  Loss: (0.2643) |  Loss2: (0.0000) | Acc: (90.00%) (5925/6528)
Epoch: 78 | Batch_idx: 60 |  Loss: (0.2655) |  Loss2: (0.0000) | Acc: (90.00%) (7081/7808)
Epoch: 78 | Batch_idx: 70 |  Loss: (0.2678) |  Loss2: (0.0000) | Acc: (90.00%) (8236/9088)
Epoch: 78 | Batch_idx: 80 |  Loss: (0.2655) |  Loss2: (0.0000) | Acc: (90.00%) (9413/10368)
Epoch: 78 | Batch_idx: 90 |  Loss: (0.2629) |  Loss2: (0.0000) | Acc: (90.00%) (10576/11648)
Epoch: 78 | Batch_idx: 100 |  Loss: (0.2652) |  Loss2: (0.0000) | Acc: (90.00%) (11734/12928)
Epoch: 78 | Batch_idx: 110 |  Loss: (0.2635) |  Loss2: (0.0000) | Acc: (90.00%) (12908/14208)
Epoch: 78 | Batch_idx: 120 |  Loss: (0.2637) |  Loss2: (0.0000) | Acc: (90.00%) (14073/15488)
Epoch: 78 | Batch_idx: 130 |  Loss: (0.2638) |  Loss2: (0.0000) | Acc: (90.00%) (15239/16768)
Epoch: 78 | Batch_idx: 140 |  Loss: (0.2654) |  Loss2: (0.0000) | Acc: (90.00%) (16383/18048)
Epoch: 78 | Batch_idx: 150 |  Loss: (0.2641) |  Loss2: (0.0000) | Acc: (90.00%) (17555/19328)
Epoch: 78 | Batch_idx: 160 |  Loss: (0.2627) |  Loss2: (0.0000) | Acc: (90.00%) (18721/20608)
Epoch: 78 | Batch_idx: 170 |  Loss: (0.2644) |  Loss2: (0.0000) | Acc: (90.00%) (19871/21888)
Epoch: 78 | Batch_idx: 180 |  Loss: (0.2659) |  Loss2: (0.0000) | Acc: (90.00%) (21025/23168)
Epoch: 78 | Batch_idx: 190 |  Loss: (0.2649) |  Loss2: (0.0000) | Acc: (90.00%) (22204/24448)
Epoch: 78 | Batch_idx: 200 |  Loss: (0.2656) |  Loss2: (0.0000) | Acc: (90.00%) (23358/25728)
Epoch: 78 | Batch_idx: 210 |  Loss: (0.2660) |  Loss2: (0.0000) | Acc: (90.00%) (24512/27008)
Epoch: 78 | Batch_idx: 220 |  Loss: (0.2657) |  Loss2: (0.0000) | Acc: (90.00%) (25682/28288)
Epoch: 78 | Batch_idx: 230 |  Loss: (0.2674) |  Loss2: (0.0000) | Acc: (90.00%) (26831/29568)
Epoch: 78 | Batch_idx: 240 |  Loss: (0.2680) |  Loss2: (0.0000) | Acc: (90.00%) (27985/30848)
Epoch: 78 | Batch_idx: 250 |  Loss: (0.2682) |  Loss2: (0.0000) | Acc: (90.00%) (29146/32128)
Epoch: 78 | Batch_idx: 260 |  Loss: (0.2676) |  Loss2: (0.0000) | Acc: (90.00%) (30317/33408)
Epoch: 78 | Batch_idx: 270 |  Loss: (0.2670) |  Loss2: (0.0000) | Acc: (90.00%) (31496/34688)
Epoch: 78 | Batch_idx: 280 |  Loss: (0.2678) |  Loss2: (0.0000) | Acc: (90.00%) (32654/35968)
Epoch: 78 | Batch_idx: 290 |  Loss: (0.2681) |  Loss2: (0.0000) | Acc: (90.00%) (33813/37248)
Epoch: 78 | Batch_idx: 300 |  Loss: (0.2694) |  Loss2: (0.0000) | Acc: (90.00%) (34967/38528)
Epoch: 78 | Batch_idx: 310 |  Loss: (0.2694) |  Loss2: (0.0000) | Acc: (90.00%) (36127/39808)
Epoch: 78 | Batch_idx: 320 |  Loss: (0.2695) |  Loss2: (0.0000) | Acc: (90.00%) (37286/41088)
Epoch: 78 | Batch_idx: 330 |  Loss: (0.2695) |  Loss2: (0.0000) | Acc: (90.00%) (38448/42368)
Epoch: 78 | Batch_idx: 340 |  Loss: (0.2704) |  Loss2: (0.0000) | Acc: (90.00%) (39588/43648)
Epoch: 78 | Batch_idx: 350 |  Loss: (0.2698) |  Loss2: (0.0000) | Acc: (90.00%) (40754/44928)
Epoch: 78 | Batch_idx: 360 |  Loss: (0.2700) |  Loss2: (0.0000) | Acc: (90.00%) (41908/46208)
Epoch: 78 | Batch_idx: 370 |  Loss: (0.2710) |  Loss2: (0.0000) | Acc: (90.00%) (43047/47488)
Epoch: 78 | Batch_idx: 380 |  Loss: (0.2704) |  Loss2: (0.0000) | Acc: (90.00%) (44220/48768)
Epoch: 78 | Batch_idx: 390 |  Loss: (0.2707) |  Loss2: (0.0000) | Acc: (90.00%) (45339/50000)
# TEST : Loss: (0.4008) | Acc: (86.00%) (8654/10000)
percent tensor([0.5022, 0.5060, 0.5046, 0.4987, 0.5062, 0.5043, 0.5066, 0.5012, 0.5042,
        0.5048, 0.5068, 0.5055, 0.5025, 0.5035, 0.5059, 0.5022],
       device='cuda:0') torch.Size([16])
percent tensor([0.4903, 0.4802, 0.4872, 0.4925, 0.4799, 0.5024, 0.4771, 0.4770, 0.4844,
        0.4848, 0.4893, 0.4825, 0.4805, 0.4904, 0.4859, 0.4928],
       device='cuda:0') torch.Size([16])
percent tensor([0.6113, 0.5963, 0.5439, 0.5313, 0.5683, 0.6281, 0.6058, 0.5582, 0.5701,
        0.5782, 0.5861, 0.5444, 0.6032, 0.5724, 0.6309, 0.5974],
       device='cuda:0') torch.Size([16])
percent tensor([0.6008, 0.6034, 0.5972, 0.6198, 0.5868, 0.6767, 0.5959, 0.5855, 0.6060,
        0.5858, 0.5944, 0.6104, 0.5969, 0.6304, 0.6230, 0.6292],
       device='cuda:0') torch.Size([16])
percent tensor([0.5363, 0.5673, 0.5315, 0.5344, 0.5611, 0.4942, 0.5671, 0.5053, 0.5746,
        0.6057, 0.5946, 0.5231, 0.5351, 0.6785, 0.4581, 0.5889],
       device='cuda:0') torch.Size([16])
percent tensor([0.5571, 0.5415, 0.6362, 0.6487, 0.6718, 0.6427, 0.5948, 0.6148, 0.5766,
        0.5637, 0.5592, 0.5939, 0.5326, 0.5916, 0.5577, 0.6122],
       device='cuda:0') torch.Size([16])
percent tensor([0.6108, 0.6424, 0.6704, 0.6348, 0.6925, 0.5299, 0.6156, 0.5930, 0.6594,
        0.6450, 0.6940, 0.6545, 0.6439, 0.6305, 0.5911, 0.5474],
       device='cuda:0') torch.Size([16])
percent tensor([0.9987, 0.9986, 0.9988, 0.9989, 0.9985, 0.9981, 0.9968, 0.9977, 0.9993,
        0.9989, 0.9995, 0.9989, 0.9984, 0.9984, 0.9960, 0.9983],
       device='cuda:0') torch.Size([16])
Epoch: 79 | Batch_idx: 0 |  Loss: (0.3297) |  Loss2: (0.0000) | Acc: (87.00%) (112/128)
Epoch: 79 | Batch_idx: 10 |  Loss: (0.2753) |  Loss2: (0.0000) | Acc: (90.00%) (1269/1408)
Epoch: 79 | Batch_idx: 20 |  Loss: (0.2761) |  Loss2: (0.0000) | Acc: (90.00%) (2428/2688)
Epoch: 79 | Batch_idx: 30 |  Loss: (0.2821) |  Loss2: (0.0000) | Acc: (90.00%) (3576/3968)
Epoch: 79 | Batch_idx: 40 |  Loss: (0.2717) |  Loss2: (0.0000) | Acc: (90.00%) (4750/5248)
Epoch: 79 | Batch_idx: 50 |  Loss: (0.2719) |  Loss2: (0.0000) | Acc: (90.00%) (5906/6528)
Epoch: 79 | Batch_idx: 60 |  Loss: (0.2681) |  Loss2: (0.0000) | Acc: (90.00%) (7078/7808)
Epoch: 79 | Batch_idx: 70 |  Loss: (0.2734) |  Loss2: (0.0000) | Acc: (90.00%) (8216/9088)
Epoch: 79 | Batch_idx: 80 |  Loss: (0.2690) |  Loss2: (0.0000) | Acc: (90.00%) (9391/10368)
Epoch: 79 | Batch_idx: 90 |  Loss: (0.2721) |  Loss2: (0.0000) | Acc: (90.00%) (10543/11648)
Epoch: 79 | Batch_idx: 100 |  Loss: (0.2699) |  Loss2: (0.0000) | Acc: (90.00%) (11698/12928)
Epoch: 79 | Batch_idx: 110 |  Loss: (0.2687) |  Loss2: (0.0000) | Acc: (90.00%) (12862/14208)
Epoch: 79 | Batch_idx: 120 |  Loss: (0.2699) |  Loss2: (0.0000) | Acc: (90.00%) (14026/15488)
Epoch: 79 | Batch_idx: 130 |  Loss: (0.2697) |  Loss2: (0.0000) | Acc: (90.00%) (15194/16768)
Epoch: 79 | Batch_idx: 140 |  Loss: (0.2674) |  Loss2: (0.0000) | Acc: (90.00%) (16378/18048)
Epoch: 79 | Batch_idx: 150 |  Loss: (0.2679) |  Loss2: (0.0000) | Acc: (90.00%) (17539/19328)
Epoch: 79 | Batch_idx: 160 |  Loss: (0.2692) |  Loss2: (0.0000) | Acc: (90.00%) (18690/20608)
Epoch: 79 | Batch_idx: 170 |  Loss: (0.2712) |  Loss2: (0.0000) | Acc: (90.00%) (19831/21888)
Epoch: 79 | Batch_idx: 180 |  Loss: (0.2718) |  Loss2: (0.0000) | Acc: (90.00%) (20985/23168)
Epoch: 79 | Batch_idx: 190 |  Loss: (0.2722) |  Loss2: (0.0000) | Acc: (90.00%) (22144/24448)
Epoch: 79 | Batch_idx: 200 |  Loss: (0.2726) |  Loss2: (0.0000) | Acc: (90.00%) (23309/25728)
Epoch: 79 | Batch_idx: 210 |  Loss: (0.2708) |  Loss2: (0.0000) | Acc: (90.00%) (24479/27008)
Epoch: 79 | Batch_idx: 220 |  Loss: (0.2699) |  Loss2: (0.0000) | Acc: (90.00%) (25649/28288)
Epoch: 79 | Batch_idx: 230 |  Loss: (0.2701) |  Loss2: (0.0000) | Acc: (90.00%) (26817/29568)
Epoch: 79 | Batch_idx: 240 |  Loss: (0.2699) |  Loss2: (0.0000) | Acc: (90.00%) (27987/30848)
Epoch: 79 | Batch_idx: 250 |  Loss: (0.2691) |  Loss2: (0.0000) | Acc: (90.00%) (29153/32128)
Epoch: 79 | Batch_idx: 260 |  Loss: (0.2705) |  Loss2: (0.0000) | Acc: (90.00%) (30310/33408)
Epoch: 79 | Batch_idx: 270 |  Loss: (0.2712) |  Loss2: (0.0000) | Acc: (90.00%) (31459/34688)
Epoch: 79 | Batch_idx: 280 |  Loss: (0.2710) |  Loss2: (0.0000) | Acc: (90.00%) (32626/35968)
Epoch: 79 | Batch_idx: 290 |  Loss: (0.2709) |  Loss2: (0.0000) | Acc: (90.00%) (33782/37248)
Epoch: 79 | Batch_idx: 300 |  Loss: (0.2700) |  Loss2: (0.0000) | Acc: (90.00%) (34967/38528)
Epoch: 79 | Batch_idx: 310 |  Loss: (0.2700) |  Loss2: (0.0000) | Acc: (90.00%) (36134/39808)
Epoch: 79 | Batch_idx: 320 |  Loss: (0.2703) |  Loss2: (0.0000) | Acc: (90.00%) (37289/41088)
Epoch: 79 | Batch_idx: 330 |  Loss: (0.2701) |  Loss2: (0.0000) | Acc: (90.00%) (38463/42368)
Epoch: 79 | Batch_idx: 340 |  Loss: (0.2697) |  Loss2: (0.0000) | Acc: (90.00%) (39635/43648)
Epoch: 79 | Batch_idx: 350 |  Loss: (0.2696) |  Loss2: (0.0000) | Acc: (90.00%) (40797/44928)
Epoch: 79 | Batch_idx: 360 |  Loss: (0.2687) |  Loss2: (0.0000) | Acc: (90.00%) (41972/46208)
Epoch: 79 | Batch_idx: 370 |  Loss: (0.2692) |  Loss2: (0.0000) | Acc: (90.00%) (43133/47488)
Epoch: 79 | Batch_idx: 380 |  Loss: (0.2694) |  Loss2: (0.0000) | Acc: (90.00%) (44287/48768)
Epoch: 79 | Batch_idx: 390 |  Loss: (0.2693) |  Loss2: (0.0000) | Acc: (90.00%) (45398/50000)
# TEST : Loss: (0.3997) | Acc: (86.00%) (8669/10000)
percent tensor([0.5019, 0.5057, 0.5049, 0.4986, 0.5064, 0.5040, 0.5064, 0.5011, 0.5039,
        0.5048, 0.5065, 0.5057, 0.5023, 0.5030, 0.5057, 0.5019],
       device='cuda:0') torch.Size([16])
percent tensor([0.4917, 0.4808, 0.4883, 0.4941, 0.4814, 0.5026, 0.4778, 0.4784, 0.4859,
        0.4858, 0.4908, 0.4838, 0.4813, 0.4918, 0.4866, 0.4941],
       device='cuda:0') torch.Size([16])
percent tensor([0.6126, 0.5963, 0.5429, 0.5300, 0.5683, 0.6280, 0.6066, 0.5578, 0.5701,
        0.5781, 0.5873, 0.5434, 0.6055, 0.5689, 0.6323, 0.5979],
       device='cuda:0') torch.Size([16])
percent tensor([0.6010, 0.6040, 0.5990, 0.6204, 0.5883, 0.6780, 0.5962, 0.5865, 0.6072,
        0.5860, 0.5950, 0.6117, 0.5975, 0.6307, 0.6246, 0.6301],
       device='cuda:0') torch.Size([16])
percent tensor([0.5384, 0.5654, 0.5328, 0.5351, 0.5637, 0.4958, 0.5653, 0.5064, 0.5754,
        0.6042, 0.5951, 0.5203, 0.5354, 0.6755, 0.4567, 0.5893],
       device='cuda:0') torch.Size([16])
percent tensor([0.5564, 0.5412, 0.6401, 0.6524, 0.6770, 0.6439, 0.5957, 0.6175, 0.5759,
        0.5641, 0.5587, 0.5955, 0.5309, 0.5903, 0.5581, 0.6132],
       device='cuda:0') torch.Size([16])
percent tensor([0.6103, 0.6452, 0.6776, 0.6406, 0.7020, 0.5323, 0.6197, 0.5980, 0.6613,
        0.6478, 0.6968, 0.6576, 0.6457, 0.6336, 0.5898, 0.5495],
       device='cuda:0') torch.Size([16])
percent tensor([0.9988, 0.9987, 0.9990, 0.9991, 0.9987, 0.9983, 0.9970, 0.9980, 0.9993,
        0.9989, 0.9996, 0.9990, 0.9985, 0.9984, 0.9961, 0.9984],
       device='cuda:0') torch.Size([16])
True Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=128, out_features=16, bias=False)
False Linear(in_features=16, out_features=2, bias=False)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=128, out_features=16, bias=False)
False Linear(in_features=16, out_features=2, bias=False)
True Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=256, out_features=32, bias=False)
False Linear(in_features=32, out_features=2, bias=False)
True Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=256, out_features=32, bias=False)
False Linear(in_features=32, out_features=2, bias=False)
True Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=512, out_features=64, bias=False)
False Linear(in_features=64, out_features=2, bias=False)
True Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=512, out_features=64, bias=False)
False Linear(in_features=64, out_features=2, bias=False)
True Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1024, out_features=128, bias=False)
False Linear(in_features=128, out_features=2, bias=False)
True Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1024, out_features=128, bias=False)
False Linear(in_features=128, out_features=2, bias=False)
True Linear(in_features=512, out_features=10, bias=True)
Epoch: 80 | Batch_idx: 0 |  Loss: (0.2148) |  Loss2: (0.0000) | Acc: (90.00%) (116/128)
Epoch: 80 | Batch_idx: 10 |  Loss: (0.2828) |  Loss2: (0.0000) | Acc: (90.00%) (1281/1408)
Epoch: 80 | Batch_idx: 20 |  Loss: (0.2955) |  Loss2: (0.0000) | Acc: (90.00%) (2431/2688)
Epoch: 80 | Batch_idx: 30 |  Loss: (0.2952) |  Loss2: (0.0000) | Acc: (90.00%) (3586/3968)
Epoch: 80 | Batch_idx: 40 |  Loss: (0.2955) |  Loss2: (0.0000) | Acc: (90.00%) (4735/5248)
Epoch: 80 | Batch_idx: 50 |  Loss: (0.2870) |  Loss2: (0.0000) | Acc: (90.00%) (5902/6528)
Epoch: 80 | Batch_idx: 60 |  Loss: (0.2872) |  Loss2: (0.0000) | Acc: (90.00%) (7048/7808)
Epoch: 80 | Batch_idx: 70 |  Loss: (0.2876) |  Loss2: (0.0000) | Acc: (90.00%) (8205/9088)
Epoch: 80 | Batch_idx: 80 |  Loss: (0.2829) |  Loss2: (0.0000) | Acc: (90.00%) (9376/10368)
Epoch: 80 | Batch_idx: 90 |  Loss: (0.2838) |  Loss2: (0.0000) | Acc: (90.00%) (10520/11648)
Epoch: 80 | Batch_idx: 100 |  Loss: (0.2865) |  Loss2: (0.0000) | Acc: (90.00%) (11664/12928)
Epoch: 80 | Batch_idx: 110 |  Loss: (0.2843) |  Loss2: (0.0000) | Acc: (90.00%) (12826/14208)
Epoch: 80 | Batch_idx: 120 |  Loss: (0.2849) |  Loss2: (0.0000) | Acc: (90.00%) (13977/15488)
Epoch: 80 | Batch_idx: 130 |  Loss: (0.2856) |  Loss2: (0.0000) | Acc: (90.00%) (15137/16768)
Epoch: 80 | Batch_idx: 140 |  Loss: (0.2886) |  Loss2: (0.0000) | Acc: (90.00%) (16272/18048)
Epoch: 80 | Batch_idx: 150 |  Loss: (0.2891) |  Loss2: (0.0000) | Acc: (90.00%) (17423/19328)
Epoch: 80 | Batch_idx: 160 |  Loss: (0.2892) |  Loss2: (0.0000) | Acc: (90.00%) (18581/20608)
Epoch: 80 | Batch_idx: 170 |  Loss: (0.2907) |  Loss2: (0.0000) | Acc: (90.00%) (19712/21888)
Epoch: 80 | Batch_idx: 180 |  Loss: (0.2900) |  Loss2: (0.0000) | Acc: (90.00%) (20861/23168)
Epoch: 80 | Batch_idx: 190 |  Loss: (0.2887) |  Loss2: (0.0000) | Acc: (90.00%) (22041/24448)
Epoch: 80 | Batch_idx: 200 |  Loss: (0.2895) |  Loss2: (0.0000) | Acc: (90.00%) (23178/25728)
Epoch: 80 | Batch_idx: 210 |  Loss: (0.2899) |  Loss2: (0.0000) | Acc: (90.00%) (24321/27008)
Epoch: 80 | Batch_idx: 220 |  Loss: (0.2899) |  Loss2: (0.0000) | Acc: (90.00%) (25466/28288)
Epoch: 80 | Batch_idx: 230 |  Loss: (0.2892) |  Loss2: (0.0000) | Acc: (90.00%) (26628/29568)
Epoch: 80 | Batch_idx: 240 |  Loss: (0.2893) |  Loss2: (0.0000) | Acc: (90.00%) (27778/30848)
Epoch: 80 | Batch_idx: 250 |  Loss: (0.2902) |  Loss2: (0.0000) | Acc: (90.00%) (28921/32128)
Epoch: 80 | Batch_idx: 260 |  Loss: (0.2898) |  Loss2: (0.0000) | Acc: (90.00%) (30070/33408)
Epoch: 80 | Batch_idx: 270 |  Loss: (0.2898) |  Loss2: (0.0000) | Acc: (90.00%) (31227/34688)
Epoch: 80 | Batch_idx: 280 |  Loss: (0.2898) |  Loss2: (0.0000) | Acc: (90.00%) (32374/35968)
Epoch: 80 | Batch_idx: 290 |  Loss: (0.2903) |  Loss2: (0.0000) | Acc: (89.00%) (33520/37248)
Epoch: 80 | Batch_idx: 300 |  Loss: (0.2904) |  Loss2: (0.0000) | Acc: (90.00%) (34676/38528)
Epoch: 80 | Batch_idx: 310 |  Loss: (0.2902) |  Loss2: (0.0000) | Acc: (90.00%) (35832/39808)
Epoch: 80 | Batch_idx: 320 |  Loss: (0.2912) |  Loss2: (0.0000) | Acc: (89.00%) (36965/41088)
Epoch: 80 | Batch_idx: 330 |  Loss: (0.2908) |  Loss2: (0.0000) | Acc: (89.00%) (38118/42368)
Epoch: 80 | Batch_idx: 340 |  Loss: (0.2911) |  Loss2: (0.0000) | Acc: (89.00%) (39265/43648)
Epoch: 80 | Batch_idx: 350 |  Loss: (0.2906) |  Loss2: (0.0000) | Acc: (89.00%) (40432/44928)
Epoch: 80 | Batch_idx: 360 |  Loss: (0.2910) |  Loss2: (0.0000) | Acc: (89.00%) (41580/46208)
Epoch: 80 | Batch_idx: 370 |  Loss: (0.2912) |  Loss2: (0.0000) | Acc: (89.00%) (42726/47488)
Epoch: 80 | Batch_idx: 380 |  Loss: (0.2926) |  Loss2: (0.0000) | Acc: (89.00%) (43846/48768)
Epoch: 80 | Batch_idx: 390 |  Loss: (0.2934) |  Loss2: (0.0000) | Acc: (89.00%) (44935/50000)
=> saving checkpoint 'drive/app/torch/save_Schedule/checkpoint_080.pth.tar'
# TEST : Loss: (0.4626) | Acc: (84.00%) (8491/10000)
percent tensor([0.5019, 0.5045, 0.5067, 0.4987, 0.5070, 0.5038, 0.5054, 0.5018, 0.5031,
        0.5045, 0.5057, 0.5059, 0.5021, 0.5027, 0.5050, 0.5013],
       device='cuda:0') torch.Size([16])
percent tensor([0.4932, 0.4822, 0.4871, 0.4906, 0.4808, 0.5035, 0.4785, 0.4777, 0.4875,
        0.4858, 0.4928, 0.4826, 0.4825, 0.4916, 0.4876, 0.4939],
       device='cuda:0') torch.Size([16])
percent tensor([0.6187, 0.6029, 0.5476, 0.5388, 0.5713, 0.6200, 0.6110, 0.5637, 0.5705,
        0.5882, 0.5876, 0.5508, 0.6105, 0.5679, 0.6338, 0.6063],
       device='cuda:0') torch.Size([16])
percent tensor([0.5995, 0.6016, 0.6028, 0.6300, 0.5902, 0.6829, 0.5998, 0.5912, 0.6166,
        0.5831, 0.5995, 0.6114, 0.5957, 0.6316, 0.6277, 0.6293],
       device='cuda:0') torch.Size([16])
percent tensor([0.5515, 0.5679, 0.5369, 0.5374, 0.5652, 0.5136, 0.5641, 0.5115, 0.5941,
        0.5921, 0.6046, 0.5175, 0.5426, 0.6614, 0.4643, 0.5901],
       device='cuda:0') torch.Size([16])
percent tensor([0.5564, 0.5327, 0.6338, 0.6539, 0.6756, 0.6518, 0.5894, 0.6157, 0.5765,
        0.5556, 0.5515, 0.5881, 0.5279, 0.5841, 0.5610, 0.6182],
       device='cuda:0') torch.Size([16])
percent tensor([0.5994, 0.6339, 0.6704, 0.6469, 0.7093, 0.5229, 0.6153, 0.5831, 0.6471,
        0.6485, 0.6793, 0.6616, 0.6365, 0.6235, 0.5790, 0.5435],
       device='cuda:0') torch.Size([16])
percent tensor([0.9989, 0.9987, 0.9989, 0.9990, 0.9986, 0.9979, 0.9978, 0.9974, 0.9994,
        0.9992, 0.9996, 0.9992, 0.9988, 0.9990, 0.9971, 0.9988],
       device='cuda:0') torch.Size([16])
Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 3, 3, 3]) tensor(184.4711, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(805.8889, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(806.5806, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([128, 64, 3, 3]) tensor(1530.1599, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([128, 64, 1, 1]) tensor(495.0147, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([128, 128, 3, 3]) tensor(2241.9702, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([256, 128, 3, 3]) tensor(4287.3726, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([256, 128, 1, 1]) tensor(1401.5964, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([256, 256, 3, 3]) tensor(6107.3169, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([512, 256, 3, 3]) tensor(11938.0615, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([512, 256, 1, 1]) tensor(3971.6541, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([512, 512, 3, 3]) tensor(16782.3145, device='cuda:0', grad_fn=<NormBackward0>)
Epoch: 81 | Batch_idx: 0 |  Loss: (0.2954) |  Loss2: (0.0000) | Acc: (90.00%) (116/128)
Epoch: 81 | Batch_idx: 10 |  Loss: (0.2734) |  Loss2: (0.0000) | Acc: (90.00%) (1273/1408)
Epoch: 81 | Batch_idx: 20 |  Loss: (0.2840) |  Loss2: (0.0000) | Acc: (89.00%) (2408/2688)
Epoch: 81 | Batch_idx: 30 |  Loss: (0.2820) |  Loss2: (0.0000) | Acc: (89.00%) (3560/3968)
Epoch: 81 | Batch_idx: 40 |  Loss: (0.2851) |  Loss2: (0.0000) | Acc: (89.00%) (4716/5248)
Epoch: 81 | Batch_idx: 50 |  Loss: (0.2819) |  Loss2: (0.0000) | Acc: (90.00%) (5876/6528)
Epoch: 81 | Batch_idx: 60 |  Loss: (0.2774) |  Loss2: (0.0000) | Acc: (90.00%) (7046/7808)
Epoch: 81 | Batch_idx: 70 |  Loss: (0.2726) |  Loss2: (0.0000) | Acc: (90.00%) (8223/9088)
Epoch: 81 | Batch_idx: 80 |  Loss: (0.2743) |  Loss2: (0.0000) | Acc: (90.00%) (9375/10368)
Epoch: 81 | Batch_idx: 90 |  Loss: (0.2768) |  Loss2: (0.0000) | Acc: (90.00%) (10531/11648)
Epoch: 81 | Batch_idx: 100 |  Loss: (0.2768) |  Loss2: (0.0000) | Acc: (90.00%) (11692/12928)
Epoch: 81 | Batch_idx: 110 |  Loss: (0.2734) |  Loss2: (0.0000) | Acc: (90.00%) (12862/14208)
Epoch: 81 | Batch_idx: 120 |  Loss: (0.2746) |  Loss2: (0.0000) | Acc: (90.00%) (14006/15488)
Epoch: 81 | Batch_idx: 130 |  Loss: (0.2739) |  Loss2: (0.0000) | Acc: (90.00%) (15179/16768)
Epoch: 81 | Batch_idx: 140 |  Loss: (0.2738) |  Loss2: (0.0000) | Acc: (90.00%) (16340/18048)
Epoch: 81 | Batch_idx: 150 |  Loss: (0.2745) |  Loss2: (0.0000) | Acc: (90.00%) (17498/19328)
Epoch: 81 | Batch_idx: 160 |  Loss: (0.2746) |  Loss2: (0.0000) | Acc: (90.00%) (18654/20608)
Epoch: 81 | Batch_idx: 170 |  Loss: (0.2750) |  Loss2: (0.0000) | Acc: (90.00%) (19820/21888)
Epoch: 81 | Batch_idx: 180 |  Loss: (0.2770) |  Loss2: (0.0000) | Acc: (90.00%) (20961/23168)
Epoch: 81 | Batch_idx: 190 |  Loss: (0.2781) |  Loss2: (0.0000) | Acc: (90.00%) (22112/24448)
Epoch: 81 | Batch_idx: 200 |  Loss: (0.2790) |  Loss2: (0.0000) | Acc: (90.00%) (23268/25728)
Epoch: 81 | Batch_idx: 210 |  Loss: (0.2807) |  Loss2: (0.0000) | Acc: (90.00%) (24396/27008)
Epoch: 81 | Batch_idx: 220 |  Loss: (0.2828) |  Loss2: (0.0000) | Acc: (90.00%) (25528/28288)
Epoch: 81 | Batch_idx: 230 |  Loss: (0.2836) |  Loss2: (0.0000) | Acc: (90.00%) (26671/29568)
Epoch: 81 | Batch_idx: 240 |  Loss: (0.2829) |  Loss2: (0.0000) | Acc: (90.00%) (27836/30848)
Epoch: 81 | Batch_idx: 250 |  Loss: (0.2830) |  Loss2: (0.0000) | Acc: (90.00%) (28994/32128)
Epoch: 81 | Batch_idx: 260 |  Loss: (0.2837) |  Loss2: (0.0000) | Acc: (90.00%) (30137/33408)
Epoch: 81 | Batch_idx: 270 |  Loss: (0.2836) |  Loss2: (0.0000) | Acc: (90.00%) (31294/34688)
Epoch: 81 | Batch_idx: 280 |  Loss: (0.2837) |  Loss2: (0.0000) | Acc: (90.00%) (32443/35968)
Epoch: 81 | Batch_idx: 290 |  Loss: (0.2839) |  Loss2: (0.0000) | Acc: (90.00%) (33590/37248)
Epoch: 81 | Batch_idx: 300 |  Loss: (0.2826) |  Loss2: (0.0000) | Acc: (90.00%) (34759/38528)
Epoch: 81 | Batch_idx: 310 |  Loss: (0.2827) |  Loss2: (0.0000) | Acc: (90.00%) (35910/39808)
Epoch: 81 | Batch_idx: 320 |  Loss: (0.2823) |  Loss2: (0.0000) | Acc: (90.00%) (37069/41088)
Epoch: 81 | Batch_idx: 330 |  Loss: (0.2823) |  Loss2: (0.0000) | Acc: (90.00%) (38209/42368)
Epoch: 81 | Batch_idx: 340 |  Loss: (0.2834) |  Loss2: (0.0000) | Acc: (90.00%) (39346/43648)
Epoch: 81 | Batch_idx: 350 |  Loss: (0.2842) |  Loss2: (0.0000) | Acc: (90.00%) (40491/44928)
Epoch: 81 | Batch_idx: 360 |  Loss: (0.2847) |  Loss2: (0.0000) | Acc: (90.00%) (41645/46208)
Epoch: 81 | Batch_idx: 370 |  Loss: (0.2845) |  Loss2: (0.0000) | Acc: (90.00%) (42810/47488)
Epoch: 81 | Batch_idx: 380 |  Loss: (0.2854) |  Loss2: (0.0000) | Acc: (90.00%) (43951/48768)
Epoch: 81 | Batch_idx: 390 |  Loss: (0.2850) |  Loss2: (0.0000) | Acc: (90.00%) (45065/50000)
# TEST : Loss: (0.5169) | Acc: (83.00%) (8340/10000)
percent tensor([0.5023, 0.5049, 0.5075, 0.4991, 0.5085, 0.5041, 0.5064, 0.5020, 0.5035,
        0.5052, 0.5059, 0.5067, 0.5023, 0.5017, 0.5052, 0.5014],
       device='cuda:0') torch.Size([16])
percent tensor([0.4931, 0.4791, 0.4874, 0.4913, 0.4815, 0.5040, 0.4754, 0.4772, 0.4872,
        0.4841, 0.4907, 0.4819, 0.4815, 0.4867, 0.4868, 0.4933],
       device='cuda:0') torch.Size([16])
percent tensor([0.6097, 0.5943, 0.5380, 0.5312, 0.5675, 0.6163, 0.5996, 0.5575, 0.5622,
        0.5748, 0.5803, 0.5397, 0.6032, 0.5624, 0.6271, 0.6005],
       device='cuda:0') torch.Size([16])
percent tensor([0.6033, 0.5971, 0.6145, 0.6326, 0.5938, 0.6784, 0.5929, 0.5924, 0.6181,
        0.5855, 0.5992, 0.6218, 0.5958, 0.6243, 0.6238, 0.6284],
       device='cuda:0') torch.Size([16])
percent tensor([0.5473, 0.5591, 0.5345, 0.5355, 0.5660, 0.5037, 0.5659, 0.5132, 0.6042,
        0.5845, 0.6054, 0.5214, 0.5483, 0.6682, 0.4649, 0.5833],
       device='cuda:0') torch.Size([16])
percent tensor([0.5604, 0.5297, 0.6416, 0.6574, 0.6799, 0.6489, 0.5951, 0.6200, 0.5870,
        0.5569, 0.5542, 0.6003, 0.5396, 0.5841, 0.5583, 0.6206],
       device='cuda:0') torch.Size([16])
percent tensor([0.5948, 0.6464, 0.6580, 0.6395, 0.6844, 0.5266, 0.6283, 0.5798, 0.6433,
        0.6579, 0.6744, 0.6393, 0.6416, 0.6430, 0.5675, 0.5531],
       device='cuda:0') torch.Size([16])
percent tensor([0.9982, 0.9988, 0.9990, 0.9985, 0.9984, 0.9967, 0.9965, 0.9986, 0.9985,
        0.9992, 0.9991, 0.9981, 0.9981, 0.9981, 0.9960, 0.9982],
       device='cuda:0') torch.Size([16])
Epoch: 82 | Batch_idx: 0 |  Loss: (0.2941) |  Loss2: (0.0000) | Acc: (89.00%) (115/128)
Epoch: 82 | Batch_idx: 10 |  Loss: (0.2866) |  Loss2: (0.0000) | Acc: (89.00%) (1259/1408)
Epoch: 82 | Batch_idx: 20 |  Loss: (0.2765) |  Loss2: (0.0000) | Acc: (89.00%) (2412/2688)
Epoch: 82 | Batch_idx: 30 |  Loss: (0.2765) |  Loss2: (0.0000) | Acc: (89.00%) (3563/3968)
Epoch: 82 | Batch_idx: 40 |  Loss: (0.2739) |  Loss2: (0.0000) | Acc: (90.00%) (4728/5248)
Epoch: 82 | Batch_idx: 50 |  Loss: (0.2719) |  Loss2: (0.0000) | Acc: (90.00%) (5894/6528)
Epoch: 82 | Batch_idx: 60 |  Loss: (0.2725) |  Loss2: (0.0000) | Acc: (90.00%) (7049/7808)
Epoch: 82 | Batch_idx: 70 |  Loss: (0.2723) |  Loss2: (0.0000) | Acc: (90.00%) (8206/9088)
Epoch: 82 | Batch_idx: 80 |  Loss: (0.2731) |  Loss2: (0.0000) | Acc: (90.00%) (9362/10368)
Epoch: 82 | Batch_idx: 90 |  Loss: (0.2739) |  Loss2: (0.0000) | Acc: (90.00%) (10525/11648)
Epoch: 82 | Batch_idx: 100 |  Loss: (0.2745) |  Loss2: (0.0000) | Acc: (90.00%) (11681/12928)
Epoch: 82 | Batch_idx: 110 |  Loss: (0.2765) |  Loss2: (0.0000) | Acc: (90.00%) (12830/14208)
Epoch: 82 | Batch_idx: 120 |  Loss: (0.2783) |  Loss2: (0.0000) | Acc: (90.00%) (13970/15488)
Epoch: 82 | Batch_idx: 130 |  Loss: (0.2776) |  Loss2: (0.0000) | Acc: (90.00%) (15125/16768)
Epoch: 82 | Batch_idx: 140 |  Loss: (0.2759) |  Loss2: (0.0000) | Acc: (90.00%) (16295/18048)
Epoch: 82 | Batch_idx: 150 |  Loss: (0.2750) |  Loss2: (0.0000) | Acc: (90.00%) (17466/19328)
Epoch: 82 | Batch_idx: 160 |  Loss: (0.2739) |  Loss2: (0.0000) | Acc: (90.00%) (18633/20608)
Epoch: 82 | Batch_idx: 170 |  Loss: (0.2745) |  Loss2: (0.0000) | Acc: (90.00%) (19790/21888)
Epoch: 82 | Batch_idx: 180 |  Loss: (0.2743) |  Loss2: (0.0000) | Acc: (90.00%) (20949/23168)
Epoch: 82 | Batch_idx: 190 |  Loss: (0.2758) |  Loss2: (0.0000) | Acc: (90.00%) (22083/24448)
Epoch: 82 | Batch_idx: 200 |  Loss: (0.2772) |  Loss2: (0.0000) | Acc: (90.00%) (23222/25728)
Epoch: 82 | Batch_idx: 210 |  Loss: (0.2781) |  Loss2: (0.0000) | Acc: (90.00%) (24381/27008)
Epoch: 82 | Batch_idx: 220 |  Loss: (0.2798) |  Loss2: (0.0000) | Acc: (90.00%) (25523/28288)
Epoch: 82 | Batch_idx: 230 |  Loss: (0.2799) |  Loss2: (0.0000) | Acc: (90.00%) (26675/29568)
Epoch: 82 | Batch_idx: 240 |  Loss: (0.2803) |  Loss2: (0.0000) | Acc: (90.00%) (27835/30848)
Epoch: 82 | Batch_idx: 250 |  Loss: (0.2814) |  Loss2: (0.0000) | Acc: (90.00%) (28985/32128)
Epoch: 82 | Batch_idx: 260 |  Loss: (0.2814) |  Loss2: (0.0000) | Acc: (90.00%) (30136/33408)
Epoch: 82 | Batch_idx: 270 |  Loss: (0.2817) |  Loss2: (0.0000) | Acc: (90.00%) (31284/34688)
Epoch: 82 | Batch_idx: 280 |  Loss: (0.2812) |  Loss2: (0.0000) | Acc: (90.00%) (32448/35968)
Epoch: 82 | Batch_idx: 290 |  Loss: (0.2810) |  Loss2: (0.0000) | Acc: (90.00%) (33603/37248)
Epoch: 82 | Batch_idx: 300 |  Loss: (0.2807) |  Loss2: (0.0000) | Acc: (90.00%) (34757/38528)
Epoch: 82 | Batch_idx: 310 |  Loss: (0.2806) |  Loss2: (0.0000) | Acc: (90.00%) (35912/39808)
Epoch: 82 | Batch_idx: 320 |  Loss: (0.2795) |  Loss2: (0.0000) | Acc: (90.00%) (37084/41088)
Epoch: 82 | Batch_idx: 330 |  Loss: (0.2788) |  Loss2: (0.0000) | Acc: (90.00%) (38240/42368)
Epoch: 82 | Batch_idx: 340 |  Loss: (0.2794) |  Loss2: (0.0000) | Acc: (90.00%) (39388/43648)
Epoch: 82 | Batch_idx: 350 |  Loss: (0.2792) |  Loss2: (0.0000) | Acc: (90.00%) (40541/44928)
Epoch: 82 | Batch_idx: 360 |  Loss: (0.2794) |  Loss2: (0.0000) | Acc: (90.00%) (41699/46208)
Epoch: 82 | Batch_idx: 370 |  Loss: (0.2790) |  Loss2: (0.0000) | Acc: (90.00%) (42868/47488)
Epoch: 82 | Batch_idx: 380 |  Loss: (0.2783) |  Loss2: (0.0000) | Acc: (90.00%) (44040/48768)
Epoch: 82 | Batch_idx: 390 |  Loss: (0.2781) |  Loss2: (0.0000) | Acc: (90.00%) (45152/50000)
# TEST : Loss: (0.4286) | Acc: (86.00%) (8602/10000)
percent tensor([0.5024, 0.5051, 0.5069, 0.4985, 0.5079, 0.5037, 0.5063, 0.5015, 0.5039,
        0.5050, 0.5062, 0.5063, 0.5025, 0.5023, 0.5051, 0.5016],
       device='cuda:0') torch.Size([16])
percent tensor([0.4928, 0.4805, 0.4854, 0.4905, 0.4803, 0.5037, 0.4759, 0.4759, 0.4882,
        0.4838, 0.4919, 0.4804, 0.4813, 0.4901, 0.4877, 0.4940],
       device='cuda:0') torch.Size([16])
percent tensor([0.6148, 0.5990, 0.5454, 0.5358, 0.5700, 0.6112, 0.6062, 0.5588, 0.5576,
        0.5817, 0.5773, 0.5476, 0.6049, 0.5588, 0.6295, 0.5999],
       device='cuda:0') torch.Size([16])
percent tensor([0.6014, 0.5957, 0.6026, 0.6270, 0.5934, 0.6694, 0.5913, 0.5915, 0.6159,
        0.5866, 0.5993, 0.6114, 0.5966, 0.6275, 0.6244, 0.6258],
       device='cuda:0') torch.Size([16])
percent tensor([0.5566, 0.5674, 0.5304, 0.5271, 0.5719, 0.5229, 0.5788, 0.5144, 0.6240,
        0.5894, 0.6146, 0.5066, 0.5496, 0.6818, 0.4699, 0.5931],
       device='cuda:0') torch.Size([16])
percent tensor([0.5640, 0.5293, 0.6346, 0.6447, 0.6728, 0.6491, 0.5859, 0.6155, 0.5904,
        0.5609, 0.5597, 0.5895, 0.5349, 0.5800, 0.5608, 0.6193],
       device='cuda:0') torch.Size([16])
percent tensor([0.6046, 0.6657, 0.6672, 0.6452, 0.6794, 0.5423, 0.6299, 0.5929, 0.6542,
        0.6741, 0.6927, 0.6699, 0.6582, 0.6539, 0.5813, 0.5601],
       device='cuda:0') torch.Size([16])
percent tensor([0.9990, 0.9987, 0.9991, 0.9991, 0.9984, 0.9985, 0.9972, 0.9979, 0.9989,
        0.9992, 0.9996, 0.9993, 0.9993, 0.9989, 0.9970, 0.9988],
       device='cuda:0') torch.Size([16])
Epoch: 83 | Batch_idx: 0 |  Loss: (0.2302) |  Loss2: (0.0000) | Acc: (92.00%) (119/128)
Epoch: 83 | Batch_idx: 10 |  Loss: (0.2395) |  Loss2: (0.0000) | Acc: (92.00%) (1298/1408)
Epoch: 83 | Batch_idx: 20 |  Loss: (0.2443) |  Loss2: (0.0000) | Acc: (91.00%) (2470/2688)
Epoch: 83 | Batch_idx: 30 |  Loss: (0.2468) |  Loss2: (0.0000) | Acc: (91.00%) (3637/3968)
Epoch: 83 | Batch_idx: 40 |  Loss: (0.2530) |  Loss2: (0.0000) | Acc: (91.00%) (4795/5248)
Epoch: 83 | Batch_idx: 50 |  Loss: (0.2561) |  Loss2: (0.0000) | Acc: (91.00%) (5959/6528)
Epoch: 83 | Batch_idx: 60 |  Loss: (0.2590) |  Loss2: (0.0000) | Acc: (91.00%) (7120/7808)
Epoch: 83 | Batch_idx: 70 |  Loss: (0.2619) |  Loss2: (0.0000) | Acc: (91.00%) (8274/9088)
Epoch: 83 | Batch_idx: 80 |  Loss: (0.2662) |  Loss2: (0.0000) | Acc: (90.00%) (9424/10368)
Epoch: 83 | Batch_idx: 90 |  Loss: (0.2675) |  Loss2: (0.0000) | Acc: (90.00%) (10589/11648)
Epoch: 83 | Batch_idx: 100 |  Loss: (0.2645) |  Loss2: (0.0000) | Acc: (91.00%) (11766/12928)
Epoch: 83 | Batch_idx: 110 |  Loss: (0.2650) |  Loss2: (0.0000) | Acc: (90.00%) (12929/14208)
Epoch: 83 | Batch_idx: 120 |  Loss: (0.2666) |  Loss2: (0.0000) | Acc: (90.00%) (14088/15488)
Epoch: 83 | Batch_idx: 130 |  Loss: (0.2643) |  Loss2: (0.0000) | Acc: (90.00%) (15256/16768)
Epoch: 83 | Batch_idx: 140 |  Loss: (0.2631) |  Loss2: (0.0000) | Acc: (91.00%) (16427/18048)
Epoch: 83 | Batch_idx: 150 |  Loss: (0.2610) |  Loss2: (0.0000) | Acc: (91.00%) (17601/19328)
Epoch: 83 | Batch_idx: 160 |  Loss: (0.2602) |  Loss2: (0.0000) | Acc: (91.00%) (18771/20608)
Epoch: 83 | Batch_idx: 170 |  Loss: (0.2600) |  Loss2: (0.0000) | Acc: (91.00%) (19946/21888)
Epoch: 83 | Batch_idx: 180 |  Loss: (0.2601) |  Loss2: (0.0000) | Acc: (91.00%) (21104/23168)
Epoch: 83 | Batch_idx: 190 |  Loss: (0.2607) |  Loss2: (0.0000) | Acc: (91.00%) (22272/24448)
Epoch: 83 | Batch_idx: 200 |  Loss: (0.2607) |  Loss2: (0.0000) | Acc: (91.00%) (23429/25728)
Epoch: 83 | Batch_idx: 210 |  Loss: (0.2635) |  Loss2: (0.0000) | Acc: (90.00%) (24576/27008)
Epoch: 83 | Batch_idx: 220 |  Loss: (0.2660) |  Loss2: (0.0000) | Acc: (90.00%) (25712/28288)
Epoch: 83 | Batch_idx: 230 |  Loss: (0.2654) |  Loss2: (0.0000) | Acc: (90.00%) (26872/29568)
Epoch: 83 | Batch_idx: 240 |  Loss: (0.2664) |  Loss2: (0.0000) | Acc: (90.00%) (28021/30848)
Epoch: 83 | Batch_idx: 250 |  Loss: (0.2665) |  Loss2: (0.0000) | Acc: (90.00%) (29184/32128)
Epoch: 83 | Batch_idx: 260 |  Loss: (0.2672) |  Loss2: (0.0000) | Acc: (90.00%) (30332/33408)
Epoch: 83 | Batch_idx: 270 |  Loss: (0.2702) |  Loss2: (0.0000) | Acc: (90.00%) (31460/34688)
Epoch: 83 | Batch_idx: 280 |  Loss: (0.2705) |  Loss2: (0.0000) | Acc: (90.00%) (32624/35968)
Epoch: 83 | Batch_idx: 290 |  Loss: (0.2707) |  Loss2: (0.0000) | Acc: (90.00%) (33781/37248)
Epoch: 83 | Batch_idx: 300 |  Loss: (0.2706) |  Loss2: (0.0000) | Acc: (90.00%) (34944/38528)
Epoch: 83 | Batch_idx: 310 |  Loss: (0.2707) |  Loss2: (0.0000) | Acc: (90.00%) (36108/39808)
Epoch: 83 | Batch_idx: 320 |  Loss: (0.2711) |  Loss2: (0.0000) | Acc: (90.00%) (37258/41088)
Epoch: 83 | Batch_idx: 330 |  Loss: (0.2713) |  Loss2: (0.0000) | Acc: (90.00%) (38419/42368)
Epoch: 83 | Batch_idx: 340 |  Loss: (0.2722) |  Loss2: (0.0000) | Acc: (90.00%) (39576/43648)
Epoch: 83 | Batch_idx: 350 |  Loss: (0.2720) |  Loss2: (0.0000) | Acc: (90.00%) (40751/44928)
Epoch: 83 | Batch_idx: 360 |  Loss: (0.2723) |  Loss2: (0.0000) | Acc: (90.00%) (41919/46208)
Epoch: 83 | Batch_idx: 370 |  Loss: (0.2723) |  Loss2: (0.0000) | Acc: (90.00%) (43075/47488)
Epoch: 83 | Batch_idx: 380 |  Loss: (0.2725) |  Loss2: (0.0000) | Acc: (90.00%) (44237/48768)
Epoch: 83 | Batch_idx: 390 |  Loss: (0.2730) |  Loss2: (0.0000) | Acc: (90.00%) (45338/50000)
# TEST : Loss: (0.4561) | Acc: (85.00%) (8544/10000)
percent tensor([0.5021, 0.5055, 0.5059, 0.4982, 0.5072, 0.5041, 0.5061, 0.5013, 0.5032,
        0.5047, 0.5063, 0.5058, 0.5020, 0.5035, 0.5053, 0.5017],
       device='cuda:0') torch.Size([16])
percent tensor([0.4927, 0.4807, 0.4869, 0.4923, 0.4795, 0.5035, 0.4760, 0.4773, 0.4883,
        0.4846, 0.4917, 0.4818, 0.4818, 0.4906, 0.4867, 0.4943],
       device='cuda:0') torch.Size([16])
percent tensor([0.6094, 0.5868, 0.5410, 0.5302, 0.5650, 0.6079, 0.5974, 0.5558, 0.5637,
        0.5765, 0.5753, 0.5415, 0.6004, 0.5594, 0.6158, 0.5910],
       device='cuda:0') torch.Size([16])
percent tensor([0.5989, 0.6036, 0.5973, 0.6250, 0.5873, 0.6789, 0.5933, 0.5903, 0.6137,
        0.5909, 0.6000, 0.6080, 0.5988, 0.6320, 0.6248, 0.6307],
       device='cuda:0') torch.Size([16])
percent tensor([0.5436, 0.5656, 0.5287, 0.5243, 0.5621, 0.5111, 0.5684, 0.4990, 0.6007,
        0.5978, 0.6054, 0.5083, 0.5499, 0.6646, 0.4546, 0.5820],
       device='cuda:0') torch.Size([16])
percent tensor([0.5560, 0.5324, 0.6298, 0.6450, 0.6646, 0.6517, 0.5891, 0.6078, 0.5760,
        0.5647, 0.5594, 0.5895, 0.5326, 0.5867, 0.5552, 0.6089],
       device='cuda:0') torch.Size([16])
percent tensor([0.6155, 0.6663, 0.6815, 0.6457, 0.7005, 0.5394, 0.6425, 0.5945, 0.6774,
        0.6690, 0.7040, 0.6783, 0.6629, 0.6506, 0.5924, 0.5614],
       device='cuda:0') torch.Size([16])
percent tensor([0.9991, 0.9991, 0.9994, 0.9990, 0.9993, 0.9983, 0.9985, 0.9984, 0.9996,
        0.9995, 0.9998, 0.9996, 0.9991, 0.9983, 0.9963, 0.9987],
       device='cuda:0') torch.Size([16])
Epoch: 84 | Batch_idx: 0 |  Loss: (0.2134) |  Loss2: (0.0000) | Acc: (93.00%) (120/128)
Epoch: 84 | Batch_idx: 10 |  Loss: (0.2376) |  Loss2: (0.0000) | Acc: (91.00%) (1294/1408)
Epoch: 84 | Batch_idx: 20 |  Loss: (0.2407) |  Loss2: (0.0000) | Acc: (91.00%) (2461/2688)
Epoch: 84 | Batch_idx: 30 |  Loss: (0.2470) |  Loss2: (0.0000) | Acc: (91.00%) (3622/3968)
Epoch: 84 | Batch_idx: 40 |  Loss: (0.2609) |  Loss2: (0.0000) | Acc: (90.00%) (4765/5248)
Epoch: 84 | Batch_idx: 50 |  Loss: (0.2588) |  Loss2: (0.0000) | Acc: (90.00%) (5927/6528)
Epoch: 84 | Batch_idx: 60 |  Loss: (0.2587) |  Loss2: (0.0000) | Acc: (90.00%) (7093/7808)
Epoch: 84 | Batch_idx: 70 |  Loss: (0.2621) |  Loss2: (0.0000) | Acc: (90.00%) (8249/9088)
Epoch: 84 | Batch_idx: 80 |  Loss: (0.2593) |  Loss2: (0.0000) | Acc: (90.00%) (9424/10368)
Epoch: 84 | Batch_idx: 90 |  Loss: (0.2613) |  Loss2: (0.0000) | Acc: (90.00%) (10577/11648)
Epoch: 84 | Batch_idx: 100 |  Loss: (0.2581) |  Loss2: (0.0000) | Acc: (90.00%) (11753/12928)
Epoch: 84 | Batch_idx: 110 |  Loss: (0.2613) |  Loss2: (0.0000) | Acc: (90.00%) (12900/14208)
Epoch: 84 | Batch_idx: 120 |  Loss: (0.2622) |  Loss2: (0.0000) | Acc: (90.00%) (14064/15488)
Epoch: 84 | Batch_idx: 130 |  Loss: (0.2630) |  Loss2: (0.0000) | Acc: (90.00%) (15212/16768)
Epoch: 84 | Batch_idx: 140 |  Loss: (0.2612) |  Loss2: (0.0000) | Acc: (90.00%) (16390/18048)
Epoch: 84 | Batch_idx: 150 |  Loss: (0.2604) |  Loss2: (0.0000) | Acc: (90.00%) (17564/19328)
Epoch: 84 | Batch_idx: 160 |  Loss: (0.2581) |  Loss2: (0.0000) | Acc: (90.00%) (18741/20608)
Epoch: 84 | Batch_idx: 170 |  Loss: (0.2579) |  Loss2: (0.0000) | Acc: (90.00%) (19907/21888)
Epoch: 84 | Batch_idx: 180 |  Loss: (0.2595) |  Loss2: (0.0000) | Acc: (90.00%) (21058/23168)
Epoch: 84 | Batch_idx: 190 |  Loss: (0.2611) |  Loss2: (0.0000) | Acc: (90.00%) (22206/24448)
Epoch: 84 | Batch_idx: 200 |  Loss: (0.2607) |  Loss2: (0.0000) | Acc: (90.00%) (23390/25728)
Epoch: 84 | Batch_idx: 210 |  Loss: (0.2603) |  Loss2: (0.0000) | Acc: (90.00%) (24562/27008)
Epoch: 84 | Batch_idx: 220 |  Loss: (0.2608) |  Loss2: (0.0000) | Acc: (90.00%) (25721/28288)
Epoch: 84 | Batch_idx: 230 |  Loss: (0.2609) |  Loss2: (0.0000) | Acc: (90.00%) (26893/29568)
Epoch: 84 | Batch_idx: 240 |  Loss: (0.2613) |  Loss2: (0.0000) | Acc: (90.00%) (28052/30848)
Epoch: 84 | Batch_idx: 250 |  Loss: (0.2619) |  Loss2: (0.0000) | Acc: (90.00%) (29210/32128)
Epoch: 84 | Batch_idx: 260 |  Loss: (0.2617) |  Loss2: (0.0000) | Acc: (90.00%) (30369/33408)
Epoch: 84 | Batch_idx: 270 |  Loss: (0.2612) |  Loss2: (0.0000) | Acc: (90.00%) (31547/34688)
Epoch: 84 | Batch_idx: 280 |  Loss: (0.2618) |  Loss2: (0.0000) | Acc: (90.00%) (32702/35968)
Epoch: 84 | Batch_idx: 290 |  Loss: (0.2618) |  Loss2: (0.0000) | Acc: (90.00%) (33869/37248)
Epoch: 84 | Batch_idx: 300 |  Loss: (0.2625) |  Loss2: (0.0000) | Acc: (90.00%) (35029/38528)
Epoch: 84 | Batch_idx: 310 |  Loss: (0.2621) |  Loss2: (0.0000) | Acc: (90.00%) (36192/39808)
Epoch: 84 | Batch_idx: 320 |  Loss: (0.2626) |  Loss2: (0.0000) | Acc: (90.00%) (37342/41088)
Epoch: 84 | Batch_idx: 330 |  Loss: (0.2618) |  Loss2: (0.0000) | Acc: (90.00%) (38517/42368)
Epoch: 84 | Batch_idx: 340 |  Loss: (0.2624) |  Loss2: (0.0000) | Acc: (90.00%) (39674/43648)
Epoch: 84 | Batch_idx: 350 |  Loss: (0.2620) |  Loss2: (0.0000) | Acc: (90.00%) (40844/44928)
Epoch: 84 | Batch_idx: 360 |  Loss: (0.2623) |  Loss2: (0.0000) | Acc: (90.00%) (42003/46208)
Epoch: 84 | Batch_idx: 370 |  Loss: (0.2633) |  Loss2: (0.0000) | Acc: (90.00%) (43143/47488)
Epoch: 84 | Batch_idx: 380 |  Loss: (0.2633) |  Loss2: (0.0000) | Acc: (90.00%) (44309/48768)
Epoch: 84 | Batch_idx: 390 |  Loss: (0.2632) |  Loss2: (0.0000) | Acc: (90.00%) (45427/50000)
# TEST : Loss: (0.4581) | Acc: (85.00%) (8560/10000)
percent tensor([0.5021, 0.5055, 0.5056, 0.4980, 0.5068, 0.5039, 0.5064, 0.5010, 0.5041,
        0.5045, 0.5064, 0.5058, 0.5022, 0.5035, 0.5051, 0.5015],
       device='cuda:0') torch.Size([16])
percent tensor([0.4938, 0.4807, 0.4887, 0.4932, 0.4819, 0.5040, 0.4776, 0.4773, 0.4897,
        0.4861, 0.4929, 0.4846, 0.4822, 0.4919, 0.4881, 0.4954],
       device='cuda:0') torch.Size([16])
percent tensor([0.6172, 0.6030, 0.5383, 0.5316, 0.5650, 0.6125, 0.6103, 0.5609, 0.5681,
        0.5893, 0.5925, 0.5438, 0.6131, 0.5688, 0.6296, 0.6051],
       device='cuda:0') torch.Size([16])
percent tensor([0.6011, 0.6017, 0.6034, 0.6281, 0.5955, 0.6769, 0.5964, 0.5899, 0.6054,
        0.5912, 0.5939, 0.6182, 0.5902, 0.6328, 0.6236, 0.6312],
       device='cuda:0') torch.Size([16])
percent tensor([0.5603, 0.5745, 0.5507, 0.5396, 0.5786, 0.5231, 0.5881, 0.5174, 0.6054,
        0.6110, 0.6206, 0.5232, 0.5544, 0.6835, 0.4740, 0.6018],
       device='cuda:0') torch.Size([16])
percent tensor([0.5586, 0.5418, 0.6270, 0.6448, 0.6698, 0.6423, 0.5925, 0.6123, 0.5771,
        0.5744, 0.5647, 0.5946, 0.5336, 0.5891, 0.5569, 0.6184],
       device='cuda:0') torch.Size([16])
percent tensor([0.6153, 0.6571, 0.6878, 0.6589, 0.7133, 0.5432, 0.6496, 0.5944, 0.6712,
        0.6684, 0.6918, 0.6663, 0.6461, 0.6430, 0.5932, 0.5627],
       device='cuda:0') torch.Size([16])
percent tensor([0.9992, 0.9987, 0.9995, 0.9989, 0.9994, 0.9977, 0.9987, 0.9980, 0.9993,
        0.9993, 0.9996, 0.9995, 0.9987, 0.9984, 0.9967, 0.9985],
       device='cuda:0') torch.Size([16])
Epoch: 85 | Batch_idx: 0 |  Loss: (0.1876) |  Loss2: (0.0000) | Acc: (94.00%) (121/128)
Epoch: 85 | Batch_idx: 10 |  Loss: (0.2216) |  Loss2: (0.0000) | Acc: (92.00%) (1296/1408)
Epoch: 85 | Batch_idx: 20 |  Loss: (0.2253) |  Loss2: (0.0000) | Acc: (92.00%) (2474/2688)
Epoch: 85 | Batch_idx: 30 |  Loss: (0.2367) |  Loss2: (0.0000) | Acc: (91.00%) (3638/3968)
Epoch: 85 | Batch_idx: 40 |  Loss: (0.2332) |  Loss2: (0.0000) | Acc: (91.00%) (4811/5248)
Epoch: 85 | Batch_idx: 50 |  Loss: (0.2368) |  Loss2: (0.0000) | Acc: (91.00%) (5982/6528)
Epoch: 85 | Batch_idx: 60 |  Loss: (0.2361) |  Loss2: (0.0000) | Acc: (91.00%) (7161/7808)
Epoch: 85 | Batch_idx: 70 |  Loss: (0.2327) |  Loss2: (0.0000) | Acc: (91.00%) (8346/9088)
Epoch: 85 | Batch_idx: 80 |  Loss: (0.2365) |  Loss2: (0.0000) | Acc: (91.00%) (9508/10368)
Epoch: 85 | Batch_idx: 90 |  Loss: (0.2387) |  Loss2: (0.0000) | Acc: (91.00%) (10672/11648)
Epoch: 85 | Batch_idx: 100 |  Loss: (0.2425) |  Loss2: (0.0000) | Acc: (91.00%) (11826/12928)
Epoch: 85 | Batch_idx: 110 |  Loss: (0.2455) |  Loss2: (0.0000) | Acc: (91.00%) (12986/14208)
Epoch: 85 | Batch_idx: 120 |  Loss: (0.2476) |  Loss2: (0.0000) | Acc: (91.00%) (14148/15488)
Epoch: 85 | Batch_idx: 130 |  Loss: (0.2506) |  Loss2: (0.0000) | Acc: (91.00%) (15308/16768)
Epoch: 85 | Batch_idx: 140 |  Loss: (0.2513) |  Loss2: (0.0000) | Acc: (91.00%) (16479/18048)
Epoch: 85 | Batch_idx: 150 |  Loss: (0.2518) |  Loss2: (0.0000) | Acc: (91.00%) (17647/19328)
Epoch: 85 | Batch_idx: 160 |  Loss: (0.2510) |  Loss2: (0.0000) | Acc: (91.00%) (18822/20608)
Epoch: 85 | Batch_idx: 170 |  Loss: (0.2519) |  Loss2: (0.0000) | Acc: (91.00%) (19987/21888)
Epoch: 85 | Batch_idx: 180 |  Loss: (0.2542) |  Loss2: (0.0000) | Acc: (91.00%) (21139/23168)
Epoch: 85 | Batch_idx: 190 |  Loss: (0.2542) |  Loss2: (0.0000) | Acc: (91.00%) (22307/24448)
Epoch: 85 | Batch_idx: 200 |  Loss: (0.2537) |  Loss2: (0.0000) | Acc: (91.00%) (23482/25728)
Epoch: 85 | Batch_idx: 210 |  Loss: (0.2529) |  Loss2: (0.0000) | Acc: (91.00%) (24663/27008)
Epoch: 85 | Batch_idx: 220 |  Loss: (0.2524) |  Loss2: (0.0000) | Acc: (91.00%) (25838/28288)
Epoch: 85 | Batch_idx: 230 |  Loss: (0.2525) |  Loss2: (0.0000) | Acc: (91.00%) (27012/29568)
Epoch: 85 | Batch_idx: 240 |  Loss: (0.2526) |  Loss2: (0.0000) | Acc: (91.00%) (28174/30848)
Epoch: 85 | Batch_idx: 250 |  Loss: (0.2527) |  Loss2: (0.0000) | Acc: (91.00%) (29340/32128)
Epoch: 85 | Batch_idx: 260 |  Loss: (0.2526) |  Loss2: (0.0000) | Acc: (91.00%) (30514/33408)
Epoch: 85 | Batch_idx: 270 |  Loss: (0.2526) |  Loss2: (0.0000) | Acc: (91.00%) (31675/34688)
Epoch: 85 | Batch_idx: 280 |  Loss: (0.2527) |  Loss2: (0.0000) | Acc: (91.00%) (32835/35968)
Epoch: 85 | Batch_idx: 290 |  Loss: (0.2534) |  Loss2: (0.0000) | Acc: (91.00%) (33994/37248)
Epoch: 85 | Batch_idx: 300 |  Loss: (0.2533) |  Loss2: (0.0000) | Acc: (91.00%) (35162/38528)
Epoch: 85 | Batch_idx: 310 |  Loss: (0.2541) |  Loss2: (0.0000) | Acc: (91.00%) (36313/39808)
Epoch: 85 | Batch_idx: 320 |  Loss: (0.2545) |  Loss2: (0.0000) | Acc: (91.00%) (37471/41088)
Epoch: 85 | Batch_idx: 330 |  Loss: (0.2549) |  Loss2: (0.0000) | Acc: (91.00%) (38629/42368)
Epoch: 85 | Batch_idx: 340 |  Loss: (0.2558) |  Loss2: (0.0000) | Acc: (91.00%) (39783/43648)
Epoch: 85 | Batch_idx: 350 |  Loss: (0.2563) |  Loss2: (0.0000) | Acc: (91.00%) (40953/44928)
Epoch: 85 | Batch_idx: 360 |  Loss: (0.2562) |  Loss2: (0.0000) | Acc: (91.00%) (42127/46208)
Epoch: 85 | Batch_idx: 370 |  Loss: (0.2566) |  Loss2: (0.0000) | Acc: (91.00%) (43284/47488)
Epoch: 85 | Batch_idx: 380 |  Loss: (0.2566) |  Loss2: (0.0000) | Acc: (91.00%) (44456/48768)
Epoch: 85 | Batch_idx: 390 |  Loss: (0.2569) |  Loss2: (0.0000) | Acc: (91.00%) (45587/50000)
=> saving checkpoint 'drive/app/torch/save_Schedule/checkpoint_085.pth.tar'
# TEST : Loss: (0.4065) | Acc: (86.00%) (8667/10000)
percent tensor([0.5022, 0.5053, 0.5062, 0.4978, 0.5072, 0.5037, 0.5063, 0.5011, 0.5035,
        0.5047, 0.5061, 0.5059, 0.5021, 0.5028, 0.5050, 0.5014],
       device='cuda:0') torch.Size([16])
percent tensor([0.4913, 0.4806, 0.4852, 0.4922, 0.4795, 0.5038, 0.4759, 0.4761, 0.4867,
        0.4832, 0.4900, 0.4801, 0.4793, 0.4913, 0.4871, 0.4935],
       device='cuda:0') torch.Size([16])
percent tensor([0.6119, 0.6035, 0.5438, 0.5355, 0.5670, 0.6045, 0.6108, 0.5640, 0.5622,
        0.5892, 0.5848, 0.5482, 0.6077, 0.5690, 0.6270, 0.6008],
       device='cuda:0') torch.Size([16])
percent tensor([0.6032, 0.6042, 0.6007, 0.6258, 0.5920, 0.6840, 0.5934, 0.5903, 0.6115,
        0.5881, 0.5985, 0.6148, 0.5989, 0.6314, 0.6276, 0.6319],
       device='cuda:0') torch.Size([16])
percent tensor([0.5560, 0.5649, 0.5421, 0.5455, 0.5771, 0.5279, 0.5682, 0.5169, 0.6098,
        0.5978, 0.6019, 0.5159, 0.5478, 0.6768, 0.4732, 0.5925],
       device='cuda:0') torch.Size([16])
percent tensor([0.5617, 0.5435, 0.6342, 0.6520, 0.6677, 0.6441, 0.5882, 0.6215, 0.5852,
        0.5709, 0.5600, 0.6036, 0.5502, 0.5864, 0.5672, 0.6164],
       device='cuda:0') torch.Size([16])
percent tensor([0.6106, 0.6641, 0.6799, 0.6450, 0.6818, 0.5138, 0.6378, 0.5806, 0.6673,
        0.6852, 0.7037, 0.6747, 0.6509, 0.6578, 0.5863, 0.5513],
       device='cuda:0') torch.Size([16])
percent tensor([0.9989, 0.9989, 0.9995, 0.9989, 0.9988, 0.9988, 0.9979, 0.9984, 0.9995,
        0.9995, 0.9998, 0.9996, 0.9987, 0.9989, 0.9962, 0.9984],
       device='cuda:0') torch.Size([16])
Epoch: 86 | Batch_idx: 0 |  Loss: (0.2602) |  Loss2: (0.0000) | Acc: (90.00%) (116/128)
Epoch: 86 | Batch_idx: 10 |  Loss: (0.2256) |  Loss2: (0.0000) | Acc: (92.00%) (1301/1408)
Epoch: 86 | Batch_idx: 20 |  Loss: (0.2292) |  Loss2: (0.0000) | Acc: (91.00%) (2466/2688)
Epoch: 86 | Batch_idx: 30 |  Loss: (0.2288) |  Loss2: (0.0000) | Acc: (91.00%) (3644/3968)
Epoch: 86 | Batch_idx: 40 |  Loss: (0.2372) |  Loss2: (0.0000) | Acc: (91.00%) (4812/5248)
Epoch: 86 | Batch_idx: 50 |  Loss: (0.2365) |  Loss2: (0.0000) | Acc: (91.00%) (5985/6528)
Epoch: 86 | Batch_idx: 60 |  Loss: (0.2383) |  Loss2: (0.0000) | Acc: (91.00%) (7170/7808)
Epoch: 86 | Batch_idx: 70 |  Loss: (0.2404) |  Loss2: (0.0000) | Acc: (91.00%) (8337/9088)
Epoch: 86 | Batch_idx: 80 |  Loss: (0.2394) |  Loss2: (0.0000) | Acc: (91.00%) (9512/10368)
Epoch: 86 | Batch_idx: 90 |  Loss: (0.2389) |  Loss2: (0.0000) | Acc: (91.00%) (10686/11648)
Epoch: 86 | Batch_idx: 100 |  Loss: (0.2419) |  Loss2: (0.0000) | Acc: (91.00%) (11838/12928)
Epoch: 86 | Batch_idx: 110 |  Loss: (0.2421) |  Loss2: (0.0000) | Acc: (91.00%) (13023/14208)
Epoch: 86 | Batch_idx: 120 |  Loss: (0.2446) |  Loss2: (0.0000) | Acc: (91.00%) (14189/15488)
Epoch: 86 | Batch_idx: 130 |  Loss: (0.2449) |  Loss2: (0.0000) | Acc: (91.00%) (15346/16768)
Epoch: 86 | Batch_idx: 140 |  Loss: (0.2451) |  Loss2: (0.0000) | Acc: (91.00%) (16516/18048)
Epoch: 86 | Batch_idx: 150 |  Loss: (0.2440) |  Loss2: (0.0000) | Acc: (91.00%) (17691/19328)
Epoch: 86 | Batch_idx: 160 |  Loss: (0.2450) |  Loss2: (0.0000) | Acc: (91.00%) (18854/20608)
Epoch: 86 | Batch_idx: 170 |  Loss: (0.2453) |  Loss2: (0.0000) | Acc: (91.00%) (20021/21888)
Epoch: 86 | Batch_idx: 180 |  Loss: (0.2472) |  Loss2: (0.0000) | Acc: (91.00%) (21176/23168)
Epoch: 86 | Batch_idx: 190 |  Loss: (0.2480) |  Loss2: (0.0000) | Acc: (91.00%) (22339/24448)
Epoch: 86 | Batch_idx: 200 |  Loss: (0.2479) |  Loss2: (0.0000) | Acc: (91.00%) (23513/25728)
Epoch: 86 | Batch_idx: 210 |  Loss: (0.2480) |  Loss2: (0.0000) | Acc: (91.00%) (24682/27008)
Epoch: 86 | Batch_idx: 220 |  Loss: (0.2491) |  Loss2: (0.0000) | Acc: (91.00%) (25836/28288)
Epoch: 86 | Batch_idx: 230 |  Loss: (0.2492) |  Loss2: (0.0000) | Acc: (91.00%) (27008/29568)
Epoch: 86 | Batch_idx: 240 |  Loss: (0.2492) |  Loss2: (0.0000) | Acc: (91.00%) (28177/30848)
Epoch: 86 | Batch_idx: 250 |  Loss: (0.2490) |  Loss2: (0.0000) | Acc: (91.00%) (29358/32128)
Epoch: 86 | Batch_idx: 260 |  Loss: (0.2481) |  Loss2: (0.0000) | Acc: (91.00%) (30550/33408)
Epoch: 86 | Batch_idx: 270 |  Loss: (0.2476) |  Loss2: (0.0000) | Acc: (91.00%) (31731/34688)
Epoch: 86 | Batch_idx: 280 |  Loss: (0.2479) |  Loss2: (0.0000) | Acc: (91.00%) (32898/35968)
Epoch: 86 | Batch_idx: 290 |  Loss: (0.2480) |  Loss2: (0.0000) | Acc: (91.00%) (34056/37248)
Epoch: 86 | Batch_idx: 300 |  Loss: (0.2483) |  Loss2: (0.0000) | Acc: (91.00%) (35231/38528)
Epoch: 86 | Batch_idx: 310 |  Loss: (0.2485) |  Loss2: (0.0000) | Acc: (91.00%) (36394/39808)
Epoch: 86 | Batch_idx: 320 |  Loss: (0.2484) |  Loss2: (0.0000) | Acc: (91.00%) (37558/41088)
Epoch: 86 | Batch_idx: 330 |  Loss: (0.2492) |  Loss2: (0.0000) | Acc: (91.00%) (38720/42368)
Epoch: 86 | Batch_idx: 340 |  Loss: (0.2488) |  Loss2: (0.0000) | Acc: (91.00%) (39891/43648)
Epoch: 86 | Batch_idx: 350 |  Loss: (0.2492) |  Loss2: (0.0000) | Acc: (91.00%) (41054/44928)
Epoch: 86 | Batch_idx: 360 |  Loss: (0.2491) |  Loss2: (0.0000) | Acc: (91.00%) (42225/46208)
Epoch: 86 | Batch_idx: 370 |  Loss: (0.2497) |  Loss2: (0.0000) | Acc: (91.00%) (43381/47488)
Epoch: 86 | Batch_idx: 380 |  Loss: (0.2493) |  Loss2: (0.0000) | Acc: (91.00%) (44552/48768)
Epoch: 86 | Batch_idx: 390 |  Loss: (0.2493) |  Loss2: (0.0000) | Acc: (91.00%) (45674/50000)
# TEST : Loss: (0.4488) | Acc: (85.00%) (8553/10000)
percent tensor([0.5027, 0.5047, 0.5086, 0.4992, 0.5094, 0.5041, 0.5065, 0.5023, 0.5036,
        0.5051, 0.5057, 0.5078, 0.5024, 0.5016, 0.5052, 0.5016],
       device='cuda:0') torch.Size([16])
percent tensor([0.4922, 0.4807, 0.4867, 0.4915, 0.4809, 0.5033, 0.4768, 0.4763, 0.4879,
        0.4844, 0.4911, 0.4824, 0.4812, 0.4914, 0.4865, 0.4942],
       device='cuda:0') torch.Size([16])
percent tensor([0.6227, 0.6062, 0.5474, 0.5362, 0.5700, 0.6117, 0.6119, 0.5638, 0.5734,
        0.5916, 0.5997, 0.5481, 0.6197, 0.5608, 0.6321, 0.6033],
       device='cuda:0') torch.Size([16])
percent tensor([0.6011, 0.5995, 0.5926, 0.6217, 0.5848, 0.6755, 0.5927, 0.5895, 0.6176,
        0.5845, 0.6025, 0.6075, 0.5985, 0.6310, 0.6233, 0.6325],
       device='cuda:0') torch.Size([16])
percent tensor([0.5469, 0.5708, 0.5406, 0.5429, 0.5692, 0.5078, 0.5771, 0.5100, 0.5883,
        0.6047, 0.5889, 0.5224, 0.5562, 0.6596, 0.4653, 0.5880],
       device='cuda:0') torch.Size([16])
percent tensor([0.5656, 0.5404, 0.6293, 0.6484, 0.6689, 0.6424, 0.5984, 0.6166, 0.5756,
        0.5653, 0.5569, 0.5931, 0.5415, 0.5851, 0.5680, 0.6158],
       device='cuda:0') torch.Size([16])
percent tensor([0.6105, 0.6510, 0.6707, 0.6471, 0.6903, 0.5446, 0.6226, 0.5877, 0.6511,
        0.6540, 0.6711, 0.6541, 0.6384, 0.6446, 0.5786, 0.5605],
       device='cuda:0') torch.Size([16])
percent tensor([0.9986, 0.9988, 0.9992, 0.9988, 0.9991, 0.9981, 0.9984, 0.9981, 0.9993,
        0.9991, 0.9995, 0.9993, 0.9986, 0.9988, 0.9961, 0.9984],
       device='cuda:0') torch.Size([16])
Epoch: 87 | Batch_idx: 0 |  Loss: (0.2298) |  Loss2: (0.0000) | Acc: (92.00%) (119/128)
Epoch: 87 | Batch_idx: 10 |  Loss: (0.2358) |  Loss2: (0.0000) | Acc: (91.00%) (1293/1408)
Epoch: 87 | Batch_idx: 20 |  Loss: (0.2407) |  Loss2: (0.0000) | Acc: (91.00%) (2459/2688)
Epoch: 87 | Batch_idx: 30 |  Loss: (0.2327) |  Loss2: (0.0000) | Acc: (91.00%) (3647/3968)
Epoch: 87 | Batch_idx: 40 |  Loss: (0.2320) |  Loss2: (0.0000) | Acc: (91.00%) (4817/5248)
Epoch: 87 | Batch_idx: 50 |  Loss: (0.2347) |  Loss2: (0.0000) | Acc: (91.00%) (5984/6528)
Epoch: 87 | Batch_idx: 60 |  Loss: (0.2350) |  Loss2: (0.0000) | Acc: (91.00%) (7157/7808)
Epoch: 87 | Batch_idx: 70 |  Loss: (0.2355) |  Loss2: (0.0000) | Acc: (91.00%) (8328/9088)
Epoch: 87 | Batch_idx: 80 |  Loss: (0.2356) |  Loss2: (0.0000) | Acc: (91.00%) (9506/10368)
Epoch: 87 | Batch_idx: 90 |  Loss: (0.2382) |  Loss2: (0.0000) | Acc: (91.00%) (10680/11648)
Epoch: 87 | Batch_idx: 100 |  Loss: (0.2423) |  Loss2: (0.0000) | Acc: (91.00%) (11833/12928)
Epoch: 87 | Batch_idx: 110 |  Loss: (0.2422) |  Loss2: (0.0000) | Acc: (91.00%) (12999/14208)
Epoch: 87 | Batch_idx: 120 |  Loss: (0.2455) |  Loss2: (0.0000) | Acc: (91.00%) (14157/15488)
Epoch: 87 | Batch_idx: 130 |  Loss: (0.2454) |  Loss2: (0.0000) | Acc: (91.00%) (15334/16768)
Epoch: 87 | Batch_idx: 140 |  Loss: (0.2459) |  Loss2: (0.0000) | Acc: (91.00%) (16500/18048)
Epoch: 87 | Batch_idx: 150 |  Loss: (0.2449) |  Loss2: (0.0000) | Acc: (91.00%) (17681/19328)
Epoch: 87 | Batch_idx: 160 |  Loss: (0.2438) |  Loss2: (0.0000) | Acc: (91.00%) (18860/20608)
Epoch: 87 | Batch_idx: 170 |  Loss: (0.2441) |  Loss2: (0.0000) | Acc: (91.00%) (20032/21888)
Epoch: 87 | Batch_idx: 180 |  Loss: (0.2434) |  Loss2: (0.0000) | Acc: (91.00%) (21205/23168)
Epoch: 87 | Batch_idx: 190 |  Loss: (0.2442) |  Loss2: (0.0000) | Acc: (91.00%) (22382/24448)
Epoch: 87 | Batch_idx: 200 |  Loss: (0.2442) |  Loss2: (0.0000) | Acc: (91.00%) (23553/25728)
Epoch: 87 | Batch_idx: 210 |  Loss: (0.2443) |  Loss2: (0.0000) | Acc: (91.00%) (24710/27008)
Epoch: 87 | Batch_idx: 220 |  Loss: (0.2441) |  Loss2: (0.0000) | Acc: (91.00%) (25888/28288)
Epoch: 87 | Batch_idx: 230 |  Loss: (0.2437) |  Loss2: (0.0000) | Acc: (91.00%) (27056/29568)
Epoch: 87 | Batch_idx: 240 |  Loss: (0.2433) |  Loss2: (0.0000) | Acc: (91.00%) (28241/30848)
Epoch: 87 | Batch_idx: 250 |  Loss: (0.2431) |  Loss2: (0.0000) | Acc: (91.00%) (29403/32128)
Epoch: 87 | Batch_idx: 260 |  Loss: (0.2429) |  Loss2: (0.0000) | Acc: (91.00%) (30574/33408)
Epoch: 87 | Batch_idx: 270 |  Loss: (0.2423) |  Loss2: (0.0000) | Acc: (91.00%) (31754/34688)
Epoch: 87 | Batch_idx: 280 |  Loss: (0.2423) |  Loss2: (0.0000) | Acc: (91.00%) (32928/35968)
Epoch: 87 | Batch_idx: 290 |  Loss: (0.2421) |  Loss2: (0.0000) | Acc: (91.00%) (34105/37248)
Epoch: 87 | Batch_idx: 300 |  Loss: (0.2421) |  Loss2: (0.0000) | Acc: (91.00%) (35288/38528)
Epoch: 87 | Batch_idx: 310 |  Loss: (0.2420) |  Loss2: (0.0000) | Acc: (91.00%) (36465/39808)
Epoch: 87 | Batch_idx: 320 |  Loss: (0.2419) |  Loss2: (0.0000) | Acc: (91.00%) (37639/41088)
Epoch: 87 | Batch_idx: 330 |  Loss: (0.2424) |  Loss2: (0.0000) | Acc: (91.00%) (38805/42368)
Epoch: 87 | Batch_idx: 340 |  Loss: (0.2432) |  Loss2: (0.0000) | Acc: (91.00%) (39966/43648)
Epoch: 87 | Batch_idx: 350 |  Loss: (0.2433) |  Loss2: (0.0000) | Acc: (91.00%) (41129/44928)
Epoch: 87 | Batch_idx: 360 |  Loss: (0.2435) |  Loss2: (0.0000) | Acc: (91.00%) (42303/46208)
Epoch: 87 | Batch_idx: 370 |  Loss: (0.2438) |  Loss2: (0.0000) | Acc: (91.00%) (43469/47488)
Epoch: 87 | Batch_idx: 380 |  Loss: (0.2436) |  Loss2: (0.0000) | Acc: (91.00%) (44641/48768)
Epoch: 87 | Batch_idx: 390 |  Loss: (0.2432) |  Loss2: (0.0000) | Acc: (91.00%) (45776/50000)
# TEST : Loss: (0.4464) | Acc: (85.00%) (8565/10000)
percent tensor([0.5017, 0.5052, 0.5058, 0.4988, 0.5066, 0.5031, 0.5057, 0.5014, 0.5034,
        0.5046, 0.5058, 0.5058, 0.5018, 0.5021, 0.5051, 0.5015],
       device='cuda:0') torch.Size([16])
percent tensor([0.4918, 0.4802, 0.4849, 0.4890, 0.4807, 0.5030, 0.4777, 0.4735, 0.4874,
        0.4840, 0.4909, 0.4814, 0.4804, 0.4891, 0.4854, 0.4929],
       device='cuda:0') torch.Size([16])
percent tensor([0.6142, 0.6042, 0.5350, 0.5302, 0.5615, 0.6151, 0.6127, 0.5576, 0.5670,
        0.5882, 0.5929, 0.5423, 0.6144, 0.5827, 0.6322, 0.6037],
       device='cuda:0') torch.Size([16])
percent tensor([0.6037, 0.6015, 0.6030, 0.6264, 0.6014, 0.6790, 0.6024, 0.5854, 0.6128,
        0.5874, 0.5975, 0.6229, 0.5996, 0.6272, 0.6256, 0.6265],
       device='cuda:0') torch.Size([16])
percent tensor([0.5533, 0.5848, 0.5336, 0.5314, 0.5708, 0.5144, 0.5933, 0.5125, 0.6101,
        0.5972, 0.6219, 0.5173, 0.5431, 0.7003, 0.4769, 0.5879],
       device='cuda:0') torch.Size([16])
percent tensor([0.5634, 0.5456, 0.6328, 0.6372, 0.6695, 0.6486, 0.5970, 0.6146, 0.5901,
        0.5648, 0.5673, 0.5959, 0.5452, 0.5970, 0.5656, 0.6167],
       device='cuda:0') torch.Size([16])
percent tensor([0.6087, 0.6403, 0.6752, 0.6494, 0.6913, 0.5481, 0.6180, 0.5861, 0.6488,
        0.6511, 0.6803, 0.6399, 0.6408, 0.6149, 0.5965, 0.5592],
       device='cuda:0') torch.Size([16])
percent tensor([0.9985, 0.9980, 0.9994, 0.9995, 0.9992, 0.9979, 0.9977, 0.9977, 0.9984,
        0.9987, 0.9993, 0.9989, 0.9985, 0.9965, 0.9966, 0.9984],
       device='cuda:0') torch.Size([16])
False Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=128, out_features=16, bias=False)
True Linear(in_features=16, out_features=2, bias=False)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=128, out_features=16, bias=False)
True Linear(in_features=16, out_features=2, bias=False)
False Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=256, out_features=32, bias=False)
True Linear(in_features=32, out_features=2, bias=False)
False Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=256, out_features=32, bias=False)
True Linear(in_features=32, out_features=2, bias=False)
False Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=512, out_features=64, bias=False)
True Linear(in_features=64, out_features=2, bias=False)
False Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=512, out_features=64, bias=False)
True Linear(in_features=64, out_features=2, bias=False)
False Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1024, out_features=128, bias=False)
True Linear(in_features=128, out_features=2, bias=False)
False Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1024, out_features=128, bias=False)
True Linear(in_features=128, out_features=2, bias=False)
False Linear(in_features=512, out_features=10, bias=True)
Epoch: 88 | Batch_idx: 0 |  Loss: (0.2555) |  Loss2: (0.0000) | Acc: (90.00%) (116/128)
Epoch: 88 | Batch_idx: 10 |  Loss: (0.2654) |  Loss2: (0.0000) | Acc: (90.00%) (1274/1408)
Epoch: 88 | Batch_idx: 20 |  Loss: (0.3187) |  Loss2: (0.0000) | Acc: (88.00%) (2381/2688)
Epoch: 88 | Batch_idx: 30 |  Loss: (0.3397) |  Loss2: (0.0000) | Acc: (87.00%) (3486/3968)
Epoch: 88 | Batch_idx: 40 |  Loss: (0.3510) |  Loss2: (0.0000) | Acc: (87.00%) (4596/5248)
Epoch: 88 | Batch_idx: 50 |  Loss: (0.3605) |  Loss2: (0.0000) | Acc: (87.00%) (5692/6528)
Epoch: 88 | Batch_idx: 60 |  Loss: (0.3691) |  Loss2: (0.0000) | Acc: (86.00%) (6786/7808)
Epoch: 88 | Batch_idx: 70 |  Loss: (0.3665) |  Loss2: (0.0000) | Acc: (87.00%) (7921/9088)
Epoch: 88 | Batch_idx: 80 |  Loss: (0.3642) |  Loss2: (0.0000) | Acc: (87.00%) (9038/10368)
Epoch: 88 | Batch_idx: 90 |  Loss: (0.3637) |  Loss2: (0.0000) | Acc: (87.00%) (10154/11648)
Epoch: 88 | Batch_idx: 100 |  Loss: (0.3692) |  Loss2: (0.0000) | Acc: (87.00%) (11248/12928)
Epoch: 88 | Batch_idx: 110 |  Loss: (0.3678) |  Loss2: (0.0000) | Acc: (87.00%) (12374/14208)
Epoch: 88 | Batch_idx: 120 |  Loss: (0.3669) |  Loss2: (0.0000) | Acc: (87.00%) (13502/15488)
Epoch: 88 | Batch_idx: 130 |  Loss: (0.3651) |  Loss2: (0.0000) | Acc: (87.00%) (14625/16768)
Epoch: 88 | Batch_idx: 140 |  Loss: (0.3667) |  Loss2: (0.0000) | Acc: (87.00%) (15733/18048)
Epoch: 88 | Batch_idx: 150 |  Loss: (0.3622) |  Loss2: (0.0000) | Acc: (87.00%) (16876/19328)
Epoch: 88 | Batch_idx: 160 |  Loss: (0.3610) |  Loss2: (0.0000) | Acc: (87.00%) (18007/20608)
Epoch: 88 | Batch_idx: 170 |  Loss: (0.3586) |  Loss2: (0.0000) | Acc: (87.00%) (19139/21888)
Epoch: 88 | Batch_idx: 180 |  Loss: (0.3607) |  Loss2: (0.0000) | Acc: (87.00%) (20237/23168)
Epoch: 88 | Batch_idx: 190 |  Loss: (0.3591) |  Loss2: (0.0000) | Acc: (87.00%) (21365/24448)
Epoch: 88 | Batch_idx: 200 |  Loss: (0.3584) |  Loss2: (0.0000) | Acc: (87.00%) (22482/25728)
Epoch: 88 | Batch_idx: 210 |  Loss: (0.3577) |  Loss2: (0.0000) | Acc: (87.00%) (23613/27008)
Epoch: 88 | Batch_idx: 220 |  Loss: (0.3562) |  Loss2: (0.0000) | Acc: (87.00%) (24728/28288)
Epoch: 88 | Batch_idx: 230 |  Loss: (0.3550) |  Loss2: (0.0000) | Acc: (87.00%) (25852/29568)
Epoch: 88 | Batch_idx: 240 |  Loss: (0.3532) |  Loss2: (0.0000) | Acc: (87.00%) (26995/30848)
Epoch: 88 | Batch_idx: 250 |  Loss: (0.3519) |  Loss2: (0.0000) | Acc: (87.00%) (28134/32128)
Epoch: 88 | Batch_idx: 260 |  Loss: (0.3513) |  Loss2: (0.0000) | Acc: (87.00%) (29273/33408)
Epoch: 88 | Batch_idx: 270 |  Loss: (0.3511) |  Loss2: (0.0000) | Acc: (87.00%) (30388/34688)
Epoch: 88 | Batch_idx: 280 |  Loss: (0.3506) |  Loss2: (0.0000) | Acc: (87.00%) (31523/35968)
Epoch: 88 | Batch_idx: 290 |  Loss: (0.3485) |  Loss2: (0.0000) | Acc: (87.00%) (32673/37248)
Epoch: 88 | Batch_idx: 300 |  Loss: (0.3471) |  Loss2: (0.0000) | Acc: (87.00%) (33817/38528)
Epoch: 88 | Batch_idx: 310 |  Loss: (0.3456) |  Loss2: (0.0000) | Acc: (87.00%) (34973/39808)
Epoch: 88 | Batch_idx: 320 |  Loss: (0.3454) |  Loss2: (0.0000) | Acc: (87.00%) (36105/41088)
Epoch: 88 | Batch_idx: 330 |  Loss: (0.3435) |  Loss2: (0.0000) | Acc: (87.00%) (37266/42368)
Epoch: 88 | Batch_idx: 340 |  Loss: (0.3424) |  Loss2: (0.0000) | Acc: (87.00%) (38408/43648)
Epoch: 88 | Batch_idx: 350 |  Loss: (0.3420) |  Loss2: (0.0000) | Acc: (88.00%) (39547/44928)
Epoch: 88 | Batch_idx: 360 |  Loss: (0.3405) |  Loss2: (0.0000) | Acc: (88.00%) (40695/46208)
Epoch: 88 | Batch_idx: 370 |  Loss: (0.3399) |  Loss2: (0.0000) | Acc: (88.00%) (41832/47488)
Epoch: 88 | Batch_idx: 380 |  Loss: (0.3395) |  Loss2: (0.0000) | Acc: (88.00%) (42978/48768)
Epoch: 88 | Batch_idx: 390 |  Loss: (0.3382) |  Loss2: (0.0000) | Acc: (88.00%) (44081/50000)
# TEST : Loss: (0.4623) | Acc: (84.00%) (8477/10000)
percent tensor([0.4965, 0.4984, 0.5012, 0.4937, 0.5016, 0.4993, 0.4993, 0.4956, 0.4978,
        0.4983, 0.4996, 0.5004, 0.4962, 0.4967, 0.4991, 0.4962],
       device='cuda:0') torch.Size([16])
percent tensor([0.4951, 0.4792, 0.4900, 0.4929, 0.4884, 0.5048, 0.4793, 0.4764, 0.4906,
        0.4826, 0.4938, 0.4827, 0.4807, 0.4888, 0.4879, 0.4950],
       device='cuda:0') torch.Size([16])
percent tensor([0.6306, 0.6205, 0.5699, 0.5618, 0.5948, 0.6258, 0.6385, 0.5930, 0.5906,
        0.6046, 0.6131, 0.5849, 0.6392, 0.5843, 0.6551, 0.6157],
       device='cuda:0') torch.Size([16])
percent tensor([0.5962, 0.5977, 0.6047, 0.6211, 0.6083, 0.6758, 0.5996, 0.5825, 0.6026,
        0.5787, 0.5916, 0.6212, 0.5941, 0.6139, 0.6242, 0.6187],
       device='cuda:0') torch.Size([16])
percent tensor([0.5412, 0.5729, 0.5242, 0.5234, 0.5588, 0.5352, 0.5763, 0.5107, 0.5824,
        0.5756, 0.5953, 0.5166, 0.5402, 0.6557, 0.4885, 0.5899],
       device='cuda:0') torch.Size([16])
percent tensor([0.6072, 0.5970, 0.6740, 0.6854, 0.7163, 0.6896, 0.6564, 0.6633, 0.6376,
        0.6143, 0.6153, 0.6520, 0.5945, 0.6540, 0.6168, 0.6648],
       device='cuda:0') torch.Size([16])
percent tensor([0.5283, 0.5558, 0.5927, 0.5739, 0.6197, 0.4940, 0.5497, 0.5182, 0.5828,
        0.5675, 0.6027, 0.5630, 0.5532, 0.5718, 0.5160, 0.4921],
       device='cuda:0') torch.Size([16])
percent tensor([0.9988, 0.9984, 0.9989, 0.9991, 0.9988, 0.9983, 0.9981, 0.9976, 0.9987,
        0.9988, 0.9992, 0.9988, 0.9990, 0.9966, 0.9967, 0.9984],
       device='cuda:0') torch.Size([16])
Epoch: 89 | Batch_idx: 0 |  Loss: (0.3958) |  Loss2: (0.0000) | Acc: (86.00%) (111/128)
Epoch: 89 | Batch_idx: 10 |  Loss: (0.3026) |  Loss2: (0.0000) | Acc: (89.00%) (1265/1408)
Epoch: 89 | Batch_idx: 20 |  Loss: (0.2869) |  Loss2: (0.0000) | Acc: (90.00%) (2424/2688)
Epoch: 89 | Batch_idx: 30 |  Loss: (0.3014) |  Loss2: (0.0000) | Acc: (89.00%) (3561/3968)
Epoch: 89 | Batch_idx: 40 |  Loss: (0.3004) |  Loss2: (0.0000) | Acc: (89.00%) (4710/5248)
Epoch: 89 | Batch_idx: 50 |  Loss: (0.2967) |  Loss2: (0.0000) | Acc: (89.00%) (5862/6528)
Epoch: 89 | Batch_idx: 60 |  Loss: (0.3020) |  Loss2: (0.0000) | Acc: (89.00%) (6990/7808)
Epoch: 89 | Batch_idx: 70 |  Loss: (0.3048) |  Loss2: (0.0000) | Acc: (89.00%) (8134/9088)
Epoch: 89 | Batch_idx: 80 |  Loss: (0.3053) |  Loss2: (0.0000) | Acc: (89.00%) (9277/10368)
Epoch: 89 | Batch_idx: 90 |  Loss: (0.3052) |  Loss2: (0.0000) | Acc: (89.00%) (10431/11648)
Epoch: 89 | Batch_idx: 100 |  Loss: (0.3064) |  Loss2: (0.0000) | Acc: (89.00%) (11575/12928)
Epoch: 89 | Batch_idx: 110 |  Loss: (0.3026) |  Loss2: (0.0000) | Acc: (89.00%) (12740/14208)
Epoch: 89 | Batch_idx: 120 |  Loss: (0.3026) |  Loss2: (0.0000) | Acc: (89.00%) (13881/15488)
Epoch: 89 | Batch_idx: 130 |  Loss: (0.3009) |  Loss2: (0.0000) | Acc: (89.00%) (15043/16768)
Epoch: 89 | Batch_idx: 140 |  Loss: (0.2996) |  Loss2: (0.0000) | Acc: (89.00%) (16202/18048)
Epoch: 89 | Batch_idx: 150 |  Loss: (0.2996) |  Loss2: (0.0000) | Acc: (89.00%) (17341/19328)
Epoch: 89 | Batch_idx: 160 |  Loss: (0.2995) |  Loss2: (0.0000) | Acc: (89.00%) (18491/20608)
Epoch: 89 | Batch_idx: 170 |  Loss: (0.2987) |  Loss2: (0.0000) | Acc: (89.00%) (19649/21888)
Epoch: 89 | Batch_idx: 180 |  Loss: (0.2986) |  Loss2: (0.0000) | Acc: (89.00%) (20795/23168)
Epoch: 89 | Batch_idx: 190 |  Loss: (0.2971) |  Loss2: (0.0000) | Acc: (89.00%) (21959/24448)
Epoch: 89 | Batch_idx: 200 |  Loss: (0.2966) |  Loss2: (0.0000) | Acc: (89.00%) (23101/25728)
Epoch: 89 | Batch_idx: 210 |  Loss: (0.2953) |  Loss2: (0.0000) | Acc: (89.00%) (24261/27008)
Epoch: 89 | Batch_idx: 220 |  Loss: (0.2944) |  Loss2: (0.0000) | Acc: (89.00%) (25416/28288)
Epoch: 89 | Batch_idx: 230 |  Loss: (0.2940) |  Loss2: (0.0000) | Acc: (89.00%) (26555/29568)
Epoch: 89 | Batch_idx: 240 |  Loss: (0.2948) |  Loss2: (0.0000) | Acc: (89.00%) (27690/30848)
Epoch: 89 | Batch_idx: 250 |  Loss: (0.2949) |  Loss2: (0.0000) | Acc: (89.00%) (28831/32128)
Epoch: 89 | Batch_idx: 260 |  Loss: (0.2938) |  Loss2: (0.0000) | Acc: (89.00%) (29994/33408)
Epoch: 89 | Batch_idx: 270 |  Loss: (0.2928) |  Loss2: (0.0000) | Acc: (89.00%) (31155/34688)
Epoch: 89 | Batch_idx: 280 |  Loss: (0.2915) |  Loss2: (0.0000) | Acc: (89.00%) (32319/35968)
Epoch: 89 | Batch_idx: 290 |  Loss: (0.2907) |  Loss2: (0.0000) | Acc: (89.00%) (33481/37248)
Epoch: 89 | Batch_idx: 300 |  Loss: (0.2915) |  Loss2: (0.0000) | Acc: (89.00%) (34605/38528)
Epoch: 89 | Batch_idx: 310 |  Loss: (0.2915) |  Loss2: (0.0000) | Acc: (89.00%) (35746/39808)
Epoch: 89 | Batch_idx: 320 |  Loss: (0.2915) |  Loss2: (0.0000) | Acc: (89.00%) (36900/41088)
Epoch: 89 | Batch_idx: 330 |  Loss: (0.2910) |  Loss2: (0.0000) | Acc: (89.00%) (38060/42368)
Epoch: 89 | Batch_idx: 340 |  Loss: (0.2907) |  Loss2: (0.0000) | Acc: (89.00%) (39213/43648)
Epoch: 89 | Batch_idx: 350 |  Loss: (0.2904) |  Loss2: (0.0000) | Acc: (89.00%) (40368/44928)
Epoch: 89 | Batch_idx: 360 |  Loss: (0.2893) |  Loss2: (0.0000) | Acc: (89.00%) (41546/46208)
Epoch: 89 | Batch_idx: 370 |  Loss: (0.2892) |  Loss2: (0.0000) | Acc: (89.00%) (42693/47488)
Epoch: 89 | Batch_idx: 380 |  Loss: (0.2886) |  Loss2: (0.0000) | Acc: (89.00%) (43857/48768)
Epoch: 89 | Batch_idx: 390 |  Loss: (0.2878) |  Loss2: (0.0000) | Acc: (89.00%) (44972/50000)
# TEST : Loss: (0.4290) | Acc: (85.00%) (8573/10000)
percent tensor([0.4966, 0.4981, 0.5008, 0.4935, 0.5013, 0.4996, 0.4991, 0.4952, 0.4978,
        0.4979, 0.4995, 0.4999, 0.4962, 0.4965, 0.4990, 0.4962],
       device='cuda:0') torch.Size([16])
percent tensor([0.4975, 0.4797, 0.4929, 0.4957, 0.4921, 0.5066, 0.4811, 0.4794, 0.4930,
        0.4830, 0.4957, 0.4850, 0.4812, 0.4896, 0.4909, 0.4971],
       device='cuda:0') torch.Size([16])
percent tensor([0.6234, 0.6181, 0.5746, 0.5642, 0.5957, 0.6148, 0.6364, 0.5961, 0.5868,
        0.6012, 0.6067, 0.5867, 0.6355, 0.5788, 0.6528, 0.6074],
       device='cuda:0') torch.Size([16])
percent tensor([0.5945, 0.5969, 0.6017, 0.6188, 0.6087, 0.6782, 0.5981, 0.5828, 0.5981,
        0.5740, 0.5892, 0.6189, 0.5917, 0.6101, 0.6276, 0.6177],
       device='cuda:0') torch.Size([16])
percent tensor([0.5405, 0.5738, 0.5222, 0.5234, 0.5569, 0.5373, 0.5756, 0.5098, 0.5783,
        0.5748, 0.5930, 0.5164, 0.5439, 0.6493, 0.4900, 0.5887],
       device='cuda:0') torch.Size([16])
percent tensor([0.6046, 0.5941, 0.6791, 0.6896, 0.7215, 0.6866, 0.6586, 0.6645, 0.6380,
        0.6137, 0.6136, 0.6564, 0.5920, 0.6538, 0.6161, 0.6594],
       device='cuda:0') torch.Size([16])
percent tensor([0.5243, 0.5608, 0.6008, 0.5788, 0.6265, 0.4859, 0.5526, 0.5139, 0.5919,
        0.5763, 0.6113, 0.5723, 0.5586, 0.5826, 0.5116, 0.4849],
       device='cuda:0') torch.Size([16])
percent tensor([0.9989, 0.9985, 0.9989, 0.9991, 0.9987, 0.9986, 0.9983, 0.9978, 0.9989,
        0.9989, 0.9993, 0.9989, 0.9990, 0.9969, 0.9970, 0.9986],
       device='cuda:0') torch.Size([16])
Epoch: 90 | Batch_idx: 0 |  Loss: (0.1786) |  Loss2: (0.0000) | Acc: (94.00%) (121/128)
Epoch: 90 | Batch_idx: 10 |  Loss: (0.2536) |  Loss2: (0.0000) | Acc: (91.00%) (1293/1408)
Epoch: 90 | Batch_idx: 20 |  Loss: (0.2430) |  Loss2: (0.0000) | Acc: (91.00%) (2467/2688)
Epoch: 90 | Batch_idx: 30 |  Loss: (0.2570) |  Loss2: (0.0000) | Acc: (91.00%) (3617/3968)
Epoch: 90 | Batch_idx: 40 |  Loss: (0.2600) |  Loss2: (0.0000) | Acc: (91.00%) (4784/5248)
Epoch: 90 | Batch_idx: 50 |  Loss: (0.2657) |  Loss2: (0.0000) | Acc: (90.00%) (5932/6528)
Epoch: 90 | Batch_idx: 60 |  Loss: (0.2681) |  Loss2: (0.0000) | Acc: (90.00%) (7089/7808)
Epoch: 90 | Batch_idx: 70 |  Loss: (0.2663) |  Loss2: (0.0000) | Acc: (90.00%) (8259/9088)
Epoch: 90 | Batch_idx: 80 |  Loss: (0.2644) |  Loss2: (0.0000) | Acc: (90.00%) (9419/10368)
Epoch: 90 | Batch_idx: 90 |  Loss: (0.2653) |  Loss2: (0.0000) | Acc: (90.00%) (10576/11648)
Epoch: 90 | Batch_idx: 100 |  Loss: (0.2695) |  Loss2: (0.0000) | Acc: (90.00%) (11711/12928)
Epoch: 90 | Batch_idx: 110 |  Loss: (0.2726) |  Loss2: (0.0000) | Acc: (90.00%) (12865/14208)
Epoch: 90 | Batch_idx: 120 |  Loss: (0.2723) |  Loss2: (0.0000) | Acc: (90.00%) (14008/15488)
Epoch: 90 | Batch_idx: 130 |  Loss: (0.2708) |  Loss2: (0.0000) | Acc: (90.00%) (15173/16768)
Epoch: 90 | Batch_idx: 140 |  Loss: (0.2720) |  Loss2: (0.0000) | Acc: (90.00%) (16330/18048)
Epoch: 90 | Batch_idx: 150 |  Loss: (0.2718) |  Loss2: (0.0000) | Acc: (90.00%) (17488/19328)
Epoch: 90 | Batch_idx: 160 |  Loss: (0.2719) |  Loss2: (0.0000) | Acc: (90.00%) (18645/20608)
Epoch: 90 | Batch_idx: 170 |  Loss: (0.2719) |  Loss2: (0.0000) | Acc: (90.00%) (19798/21888)
Epoch: 90 | Batch_idx: 180 |  Loss: (0.2726) |  Loss2: (0.0000) | Acc: (90.00%) (20941/23168)
Epoch: 90 | Batch_idx: 190 |  Loss: (0.2731) |  Loss2: (0.0000) | Acc: (90.00%) (22094/24448)
Epoch: 90 | Batch_idx: 200 |  Loss: (0.2745) |  Loss2: (0.0000) | Acc: (90.00%) (23238/25728)
Epoch: 90 | Batch_idx: 210 |  Loss: (0.2728) |  Loss2: (0.0000) | Acc: (90.00%) (24411/27008)
Epoch: 90 | Batch_idx: 220 |  Loss: (0.2716) |  Loss2: (0.0000) | Acc: (90.00%) (25580/28288)
Epoch: 90 | Batch_idx: 230 |  Loss: (0.2721) |  Loss2: (0.0000) | Acc: (90.00%) (26728/29568)
Epoch: 90 | Batch_idx: 240 |  Loss: (0.2715) |  Loss2: (0.0000) | Acc: (90.00%) (27897/30848)
Epoch: 90 | Batch_idx: 250 |  Loss: (0.2725) |  Loss2: (0.0000) | Acc: (90.00%) (29040/32128)
Epoch: 90 | Batch_idx: 260 |  Loss: (0.2719) |  Loss2: (0.0000) | Acc: (90.00%) (30200/33408)
Epoch: 90 | Batch_idx: 270 |  Loss: (0.2722) |  Loss2: (0.0000) | Acc: (90.00%) (31351/34688)
Epoch: 90 | Batch_idx: 280 |  Loss: (0.2723) |  Loss2: (0.0000) | Acc: (90.00%) (32507/35968)
Epoch: 90 | Batch_idx: 290 |  Loss: (0.2727) |  Loss2: (0.0000) | Acc: (90.00%) (33654/37248)
Epoch: 90 | Batch_idx: 300 |  Loss: (0.2729) |  Loss2: (0.0000) | Acc: (90.00%) (34814/38528)
Epoch: 90 | Batch_idx: 310 |  Loss: (0.2734) |  Loss2: (0.0000) | Acc: (90.00%) (35964/39808)
Epoch: 90 | Batch_idx: 320 |  Loss: (0.2722) |  Loss2: (0.0000) | Acc: (90.00%) (37129/41088)
Epoch: 90 | Batch_idx: 330 |  Loss: (0.2732) |  Loss2: (0.0000) | Acc: (90.00%) (38269/42368)
Epoch: 90 | Batch_idx: 340 |  Loss: (0.2729) |  Loss2: (0.0000) | Acc: (90.00%) (39443/43648)
Epoch: 90 | Batch_idx: 350 |  Loss: (0.2733) |  Loss2: (0.0000) | Acc: (90.00%) (40584/44928)
Epoch: 90 | Batch_idx: 360 |  Loss: (0.2719) |  Loss2: (0.0000) | Acc: (90.00%) (41768/46208)
Epoch: 90 | Batch_idx: 370 |  Loss: (0.2716) |  Loss2: (0.0000) | Acc: (90.00%) (42930/47488)
Epoch: 90 | Batch_idx: 380 |  Loss: (0.2709) |  Loss2: (0.0000) | Acc: (90.00%) (44105/48768)
Epoch: 90 | Batch_idx: 390 |  Loss: (0.2718) |  Loss2: (0.0000) | Acc: (90.00%) (45201/50000)
=> saving checkpoint 'drive/app/torch/save_Schedule/checkpoint_090.pth.tar'
# TEST : Loss: (0.4175) | Acc: (86.00%) (8603/10000)
percent tensor([0.4966, 0.4976, 0.5006, 0.4932, 0.5011, 0.4997, 0.4986, 0.4948, 0.4976,
        0.4974, 0.4994, 0.4996, 0.4960, 0.4961, 0.4987, 0.4961],
       device='cuda:0') torch.Size([16])
percent tensor([0.4963, 0.4767, 0.4921, 0.4952, 0.4920, 0.5075, 0.4789, 0.4786, 0.4922,
        0.4799, 0.4943, 0.4832, 0.4786, 0.4876, 0.4899, 0.4956],
       device='cuda:0') torch.Size([16])
percent tensor([0.6286, 0.6277, 0.5822, 0.5699, 0.6007, 0.6162, 0.6447, 0.6031, 0.5920,
        0.6087, 0.6131, 0.5938, 0.6445, 0.5833, 0.6609, 0.6117],
       device='cuda:0') torch.Size([16])
percent tensor([0.5972, 0.5999, 0.6043, 0.6223, 0.6133, 0.6849, 0.6014, 0.5874, 0.5995,
        0.5733, 0.5907, 0.6216, 0.5939, 0.6115, 0.6341, 0.6215],
       device='cuda:0') torch.Size([16])
percent tensor([0.5322, 0.5655, 0.5137, 0.5190, 0.5486, 0.5336, 0.5661, 0.5006, 0.5694,
        0.5676, 0.5862, 0.5058, 0.5382, 0.6421, 0.4808, 0.5839],
       device='cuda:0') torch.Size([16])
percent tensor([0.5984, 0.5885, 0.6762, 0.6869, 0.7186, 0.6809, 0.6556, 0.6580, 0.6346,
        0.6090, 0.6104, 0.6558, 0.5884, 0.6520, 0.6121, 0.6503],
       device='cuda:0') torch.Size([16])
percent tensor([0.5368, 0.5788, 0.6163, 0.5919, 0.6397, 0.4881, 0.5712, 0.5174, 0.6108,
        0.6002, 0.6348, 0.5936, 0.5767, 0.6047, 0.5204, 0.4881],
       device='cuda:0') torch.Size([16])
percent tensor([0.9989, 0.9987, 0.9989, 0.9992, 0.9987, 0.9987, 0.9985, 0.9979, 0.9991,
        0.9991, 0.9995, 0.9990, 0.9991, 0.9974, 0.9972, 0.9986],
       device='cuda:0') torch.Size([16])
Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 3, 3, 3]) tensor(186.2135, device='cuda:0')
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(811.0762, device='cuda:0')
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(812.6713, device='cuda:0')
Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([128, 64, 3, 3]) tensor(1532.5681, device='cuda:0')
Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([128, 64, 1, 1]) tensor(493.5678, device='cuda:0')
Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([128, 128, 3, 3]) tensor(2257.8467, device='cuda:0')
Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([256, 128, 3, 3]) tensor(4290.0049, device='cuda:0')
Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([256, 128, 1, 1]) tensor(1396.8564, device='cuda:0')
Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([256, 256, 3, 3]) tensor(6133.0718, device='cuda:0')
Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([512, 256, 3, 3]) tensor(11905.7471, device='cuda:0')
Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([512, 256, 1, 1]) tensor(3956.3389, device='cuda:0')
Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([512, 512, 3, 3]) tensor(16714.2969, device='cuda:0')
Epoch: 91 | Batch_idx: 0 |  Loss: (0.3084) |  Loss2: (0.0000) | Acc: (90.00%) (116/128)
Epoch: 91 | Batch_idx: 10 |  Loss: (0.2783) |  Loss2: (0.0000) | Acc: (90.00%) (1269/1408)
Epoch: 91 | Batch_idx: 20 |  Loss: (0.2580) |  Loss2: (0.0000) | Acc: (91.00%) (2459/2688)
Epoch: 91 | Batch_idx: 30 |  Loss: (0.2576) |  Loss2: (0.0000) | Acc: (91.00%) (3625/3968)
Epoch: 91 | Batch_idx: 40 |  Loss: (0.2533) |  Loss2: (0.0000) | Acc: (91.00%) (4792/5248)
Epoch: 91 | Batch_idx: 50 |  Loss: (0.2509) |  Loss2: (0.0000) | Acc: (91.00%) (5966/6528)
Epoch: 91 | Batch_idx: 60 |  Loss: (0.2492) |  Loss2: (0.0000) | Acc: (91.00%) (7136/7808)
Epoch: 91 | Batch_idx: 70 |  Loss: (0.2498) |  Loss2: (0.0000) | Acc: (91.00%) (8301/9088)
Epoch: 91 | Batch_idx: 80 |  Loss: (0.2460) |  Loss2: (0.0000) | Acc: (91.00%) (9489/10368)
Epoch: 91 | Batch_idx: 90 |  Loss: (0.2479) |  Loss2: (0.0000) | Acc: (91.00%) (10652/11648)
Epoch: 91 | Batch_idx: 100 |  Loss: (0.2492) |  Loss2: (0.0000) | Acc: (91.00%) (11811/12928)
Epoch: 91 | Batch_idx: 110 |  Loss: (0.2493) |  Loss2: (0.0000) | Acc: (91.00%) (12994/14208)
Epoch: 91 | Batch_idx: 120 |  Loss: (0.2517) |  Loss2: (0.0000) | Acc: (91.00%) (14149/15488)
Epoch: 91 | Batch_idx: 130 |  Loss: (0.2523) |  Loss2: (0.0000) | Acc: (91.00%) (15305/16768)
Epoch: 91 | Batch_idx: 140 |  Loss: (0.2519) |  Loss2: (0.0000) | Acc: (91.00%) (16477/18048)
Epoch: 91 | Batch_idx: 150 |  Loss: (0.2523) |  Loss2: (0.0000) | Acc: (91.00%) (17639/19328)
Epoch: 91 | Batch_idx: 160 |  Loss: (0.2528) |  Loss2: (0.0000) | Acc: (91.00%) (18803/20608)
Epoch: 91 | Batch_idx: 170 |  Loss: (0.2535) |  Loss2: (0.0000) | Acc: (91.00%) (19961/21888)
Epoch: 91 | Batch_idx: 180 |  Loss: (0.2551) |  Loss2: (0.0000) | Acc: (91.00%) (21116/23168)
Epoch: 91 | Batch_idx: 190 |  Loss: (0.2545) |  Loss2: (0.0000) | Acc: (91.00%) (22290/24448)
Epoch: 91 | Batch_idx: 200 |  Loss: (0.2546) |  Loss2: (0.0000) | Acc: (91.00%) (23451/25728)
Epoch: 91 | Batch_idx: 210 |  Loss: (0.2539) |  Loss2: (0.0000) | Acc: (91.00%) (24617/27008)
Epoch: 91 | Batch_idx: 220 |  Loss: (0.2541) |  Loss2: (0.0000) | Acc: (91.00%) (25775/28288)
Epoch: 91 | Batch_idx: 230 |  Loss: (0.2540) |  Loss2: (0.0000) | Acc: (91.00%) (26956/29568)
Epoch: 91 | Batch_idx: 240 |  Loss: (0.2547) |  Loss2: (0.0000) | Acc: (91.00%) (28110/30848)
Epoch: 91 | Batch_idx: 250 |  Loss: (0.2555) |  Loss2: (0.0000) | Acc: (91.00%) (29271/32128)
Epoch: 91 | Batch_idx: 260 |  Loss: (0.2540) |  Loss2: (0.0000) | Acc: (91.00%) (30457/33408)
Epoch: 91 | Batch_idx: 270 |  Loss: (0.2545) |  Loss2: (0.0000) | Acc: (91.00%) (31616/34688)
Epoch: 91 | Batch_idx: 280 |  Loss: (0.2548) |  Loss2: (0.0000) | Acc: (91.00%) (32773/35968)
Epoch: 91 | Batch_idx: 290 |  Loss: (0.2542) |  Loss2: (0.0000) | Acc: (91.00%) (33953/37248)
Epoch: 91 | Batch_idx: 300 |  Loss: (0.2555) |  Loss2: (0.0000) | Acc: (91.00%) (35105/38528)
Epoch: 91 | Batch_idx: 310 |  Loss: (0.2567) |  Loss2: (0.0000) | Acc: (91.00%) (36251/39808)
Epoch: 91 | Batch_idx: 320 |  Loss: (0.2564) |  Loss2: (0.0000) | Acc: (91.00%) (37418/41088)
Epoch: 91 | Batch_idx: 330 |  Loss: (0.2575) |  Loss2: (0.0000) | Acc: (91.00%) (38563/42368)
Epoch: 91 | Batch_idx: 340 |  Loss: (0.2575) |  Loss2: (0.0000) | Acc: (91.00%) (39738/43648)
Epoch: 91 | Batch_idx: 350 |  Loss: (0.2578) |  Loss2: (0.0000) | Acc: (91.00%) (40896/44928)
Epoch: 91 | Batch_idx: 360 |  Loss: (0.2581) |  Loss2: (0.0000) | Acc: (91.00%) (42052/46208)
Epoch: 91 | Batch_idx: 370 |  Loss: (0.2579) |  Loss2: (0.0000) | Acc: (91.00%) (43225/47488)
Epoch: 91 | Batch_idx: 380 |  Loss: (0.2582) |  Loss2: (0.0000) | Acc: (91.00%) (44382/48768)
Epoch: 91 | Batch_idx: 390 |  Loss: (0.2577) |  Loss2: (0.0000) | Acc: (91.00%) (45505/50000)
# TEST : Loss: (0.4056) | Acc: (86.00%) (8639/10000)
percent tensor([0.4983, 0.4996, 0.5021, 0.4950, 0.5028, 0.5013, 0.5006, 0.4968, 0.4995,
        0.4991, 0.5014, 0.5010, 0.4979, 0.4978, 0.5006, 0.4976],
       device='cuda:0') torch.Size([16])
percent tensor([0.4967, 0.4757, 0.4927, 0.4954, 0.4926, 0.5087, 0.4788, 0.4793, 0.4924,
        0.4788, 0.4941, 0.4832, 0.4778, 0.4873, 0.4903, 0.4957],
       device='cuda:0') torch.Size([16])
percent tensor([0.6225, 0.6239, 0.5790, 0.5656, 0.5950, 0.6093, 0.6398, 0.5993, 0.5871,
        0.6037, 0.6075, 0.5890, 0.6405, 0.5798, 0.6555, 0.6063],
       device='cuda:0') torch.Size([16])
percent tensor([0.5957, 0.5981, 0.6025, 0.6209, 0.6146, 0.6884, 0.6002, 0.5879, 0.5958,
        0.5682, 0.5876, 0.6191, 0.5906, 0.6091, 0.6358, 0.6216],
       device='cuda:0') torch.Size([16])
percent tensor([0.5360, 0.5701, 0.5136, 0.5227, 0.5486, 0.5349, 0.5678, 0.5023, 0.5716,
        0.5727, 0.5894, 0.5055, 0.5459, 0.6443, 0.4806, 0.5881],
       device='cuda:0') torch.Size([16])
percent tensor([0.6032, 0.5944, 0.6867, 0.6962, 0.7295, 0.6855, 0.6646, 0.6672, 0.6410,
        0.6161, 0.6169, 0.6673, 0.5933, 0.6604, 0.6195, 0.6554],
       device='cuda:0') torch.Size([16])
percent tensor([0.5582, 0.6046, 0.6439, 0.6183, 0.6642, 0.5001, 0.6002, 0.5309, 0.6387,
        0.6290, 0.6643, 0.6270, 0.6050, 0.6300, 0.5414, 0.4995],
       device='cuda:0') torch.Size([16])
percent tensor([0.9990, 0.9987, 0.9991, 0.9993, 0.9989, 0.9987, 0.9986, 0.9981, 0.9991,
        0.9992, 0.9995, 0.9991, 0.9991, 0.9976, 0.9973, 0.9987],
       device='cuda:0') torch.Size([16])
Epoch: 92 | Batch_idx: 0 |  Loss: (0.4404) |  Loss2: (0.0000) | Acc: (85.00%) (109/128)
Epoch: 92 | Batch_idx: 10 |  Loss: (0.2602) |  Loss2: (0.0000) | Acc: (91.00%) (1282/1408)
Epoch: 92 | Batch_idx: 20 |  Loss: (0.2500) |  Loss2: (0.0000) | Acc: (91.00%) (2462/2688)
Epoch: 92 | Batch_idx: 30 |  Loss: (0.2510) |  Loss2: (0.0000) | Acc: (91.00%) (3626/3968)
Epoch: 92 | Batch_idx: 40 |  Loss: (0.2532) |  Loss2: (0.0000) | Acc: (91.00%) (4800/5248)
Epoch: 92 | Batch_idx: 50 |  Loss: (0.2516) |  Loss2: (0.0000) | Acc: (91.00%) (5972/6528)
Epoch: 92 | Batch_idx: 60 |  Loss: (0.2549) |  Loss2: (0.0000) | Acc: (91.00%) (7130/7808)
Epoch: 92 | Batch_idx: 70 |  Loss: (0.2541) |  Loss2: (0.0000) | Acc: (91.00%) (8301/9088)
Epoch: 92 | Batch_idx: 80 |  Loss: (0.2525) |  Loss2: (0.0000) | Acc: (91.00%) (9474/10368)
Epoch: 92 | Batch_idx: 90 |  Loss: (0.2546) |  Loss2: (0.0000) | Acc: (91.00%) (10633/11648)
Epoch: 92 | Batch_idx: 100 |  Loss: (0.2568) |  Loss2: (0.0000) | Acc: (91.00%) (11799/12928)
Epoch: 92 | Batch_idx: 110 |  Loss: (0.2547) |  Loss2: (0.0000) | Acc: (91.00%) (12985/14208)
Epoch: 92 | Batch_idx: 120 |  Loss: (0.2546) |  Loss2: (0.0000) | Acc: (91.00%) (14147/15488)
Epoch: 92 | Batch_idx: 130 |  Loss: (0.2528) |  Loss2: (0.0000) | Acc: (91.00%) (15331/16768)
Epoch: 92 | Batch_idx: 140 |  Loss: (0.2514) |  Loss2: (0.0000) | Acc: (91.00%) (16510/18048)
Epoch: 92 | Batch_idx: 150 |  Loss: (0.2516) |  Loss2: (0.0000) | Acc: (91.00%) (17670/19328)
Epoch: 92 | Batch_idx: 160 |  Loss: (0.2517) |  Loss2: (0.0000) | Acc: (91.00%) (18838/20608)
Epoch: 92 | Batch_idx: 170 |  Loss: (0.2516) |  Loss2: (0.0000) | Acc: (91.00%) (20006/21888)
Epoch: 92 | Batch_idx: 180 |  Loss: (0.2524) |  Loss2: (0.0000) | Acc: (91.00%) (21174/23168)
Epoch: 92 | Batch_idx: 190 |  Loss: (0.2528) |  Loss2: (0.0000) | Acc: (91.00%) (22338/24448)
Epoch: 92 | Batch_idx: 200 |  Loss: (0.2514) |  Loss2: (0.0000) | Acc: (91.00%) (23521/25728)
Epoch: 92 | Batch_idx: 210 |  Loss: (0.2513) |  Loss2: (0.0000) | Acc: (91.00%) (24694/27008)
Epoch: 92 | Batch_idx: 220 |  Loss: (0.2503) |  Loss2: (0.0000) | Acc: (91.00%) (25875/28288)
Epoch: 92 | Batch_idx: 230 |  Loss: (0.2498) |  Loss2: (0.0000) | Acc: (91.00%) (27053/29568)
Epoch: 92 | Batch_idx: 240 |  Loss: (0.2493) |  Loss2: (0.0000) | Acc: (91.00%) (28235/30848)
Epoch: 92 | Batch_idx: 250 |  Loss: (0.2488) |  Loss2: (0.0000) | Acc: (91.00%) (29413/32128)
Epoch: 92 | Batch_idx: 260 |  Loss: (0.2485) |  Loss2: (0.0000) | Acc: (91.00%) (30593/33408)
Epoch: 92 | Batch_idx: 270 |  Loss: (0.2480) |  Loss2: (0.0000) | Acc: (91.00%) (31760/34688)
Epoch: 92 | Batch_idx: 280 |  Loss: (0.2477) |  Loss2: (0.0000) | Acc: (91.00%) (32936/35968)
Epoch: 92 | Batch_idx: 290 |  Loss: (0.2482) |  Loss2: (0.0000) | Acc: (91.00%) (34097/37248)
Epoch: 92 | Batch_idx: 300 |  Loss: (0.2483) |  Loss2: (0.0000) | Acc: (91.00%) (35261/38528)
Epoch: 92 | Batch_idx: 310 |  Loss: (0.2486) |  Loss2: (0.0000) | Acc: (91.00%) (36420/39808)
Epoch: 92 | Batch_idx: 320 |  Loss: (0.2486) |  Loss2: (0.0000) | Acc: (91.00%) (37587/41088)
Epoch: 92 | Batch_idx: 330 |  Loss: (0.2482) |  Loss2: (0.0000) | Acc: (91.00%) (38769/42368)
Epoch: 92 | Batch_idx: 340 |  Loss: (0.2486) |  Loss2: (0.0000) | Acc: (91.00%) (39924/43648)
Epoch: 92 | Batch_idx: 350 |  Loss: (0.2486) |  Loss2: (0.0000) | Acc: (91.00%) (41097/44928)
Epoch: 92 | Batch_idx: 360 |  Loss: (0.2488) |  Loss2: (0.0000) | Acc: (91.00%) (42261/46208)
Epoch: 92 | Batch_idx: 370 |  Loss: (0.2489) |  Loss2: (0.0000) | Acc: (91.00%) (43435/47488)
Epoch: 92 | Batch_idx: 380 |  Loss: (0.2494) |  Loss2: (0.0000) | Acc: (91.00%) (44584/48768)
Epoch: 92 | Batch_idx: 390 |  Loss: (0.2492) |  Loss2: (0.0000) | Acc: (91.00%) (45707/50000)
# TEST : Loss: (0.4034) | Acc: (86.00%) (8667/10000)
percent tensor([0.4982, 0.4994, 0.5020, 0.4947, 0.5027, 0.5011, 0.5004, 0.4966, 0.4994,
        0.4990, 0.5012, 0.5010, 0.4977, 0.4974, 0.5003, 0.4972],
       device='cuda:0') torch.Size([16])
percent tensor([0.4979, 0.4761, 0.4933, 0.4962, 0.4937, 0.5096, 0.4797, 0.4804, 0.4930,
        0.4790, 0.4948, 0.4844, 0.4783, 0.4878, 0.4918, 0.4967],
       device='cuda:0') torch.Size([16])
percent tensor([0.6222, 0.6253, 0.5800, 0.5665, 0.5944, 0.6085, 0.6396, 0.5994, 0.5874,
        0.6045, 0.6083, 0.5896, 0.6419, 0.5808, 0.6556, 0.6066],
       device='cuda:0') torch.Size([16])
percent tensor([0.6001, 0.6029, 0.6047, 0.6237, 0.6185, 0.6936, 0.6043, 0.5918, 0.5984,
        0.5704, 0.5921, 0.6221, 0.5944, 0.6125, 0.6422, 0.6269],
       device='cuda:0') torch.Size([16])
percent tensor([0.5356, 0.5735, 0.5129, 0.5252, 0.5479, 0.5292, 0.5690, 0.5013, 0.5740,
        0.5783, 0.5937, 0.5075, 0.5512, 0.6486, 0.4779, 0.5897],
       device='cuda:0') torch.Size([16])
percent tensor([0.5892, 0.5812, 0.6763, 0.6860, 0.7189, 0.6716, 0.6518, 0.6541, 0.6288,
        0.6031, 0.6047, 0.6579, 0.5797, 0.6482, 0.6062, 0.6387],
       device='cuda:0') torch.Size([16])
percent tensor([0.5707, 0.6219, 0.6571, 0.6314, 0.6728, 0.5039, 0.6141, 0.5380, 0.6542,
        0.6469, 0.6814, 0.6442, 0.6191, 0.6428, 0.5543, 0.5042],
       device='cuda:0') torch.Size([16])
percent tensor([0.9991, 0.9989, 0.9992, 0.9994, 0.9989, 0.9989, 0.9988, 0.9982, 0.9993,
        0.9993, 0.9996, 0.9992, 0.9993, 0.9979, 0.9976, 0.9988],
       device='cuda:0') torch.Size([16])
Epoch: 93 | Batch_idx: 0 |  Loss: (0.2047) |  Loss2: (0.0000) | Acc: (92.00%) (119/128)
Epoch: 93 | Batch_idx: 10 |  Loss: (0.2913) |  Loss2: (0.0000) | Acc: (89.00%) (1261/1408)
Epoch: 93 | Batch_idx: 20 |  Loss: (0.2640) |  Loss2: (0.0000) | Acc: (90.00%) (2440/2688)
Epoch: 93 | Batch_idx: 30 |  Loss: (0.2602) |  Loss2: (0.0000) | Acc: (91.00%) (3618/3968)
Epoch: 93 | Batch_idx: 40 |  Loss: (0.2603) |  Loss2: (0.0000) | Acc: (91.00%) (4777/5248)
Epoch: 93 | Batch_idx: 50 |  Loss: (0.2593) |  Loss2: (0.0000) | Acc: (90.00%) (5940/6528)
Epoch: 93 | Batch_idx: 60 |  Loss: (0.2602) |  Loss2: (0.0000) | Acc: (90.00%) (7097/7808)
Epoch: 93 | Batch_idx: 70 |  Loss: (0.2576) |  Loss2: (0.0000) | Acc: (90.00%) (8266/9088)
Epoch: 93 | Batch_idx: 80 |  Loss: (0.2545) |  Loss2: (0.0000) | Acc: (91.00%) (9446/10368)
Epoch: 93 | Batch_idx: 90 |  Loss: (0.2506) |  Loss2: (0.0000) | Acc: (91.00%) (10629/11648)
Epoch: 93 | Batch_idx: 100 |  Loss: (0.2489) |  Loss2: (0.0000) | Acc: (91.00%) (11807/12928)
Epoch: 93 | Batch_idx: 110 |  Loss: (0.2468) |  Loss2: (0.0000) | Acc: (91.00%) (12984/14208)
Epoch: 93 | Batch_idx: 120 |  Loss: (0.2486) |  Loss2: (0.0000) | Acc: (91.00%) (14152/15488)
Epoch: 93 | Batch_idx: 130 |  Loss: (0.2472) |  Loss2: (0.0000) | Acc: (91.00%) (15328/16768)
Epoch: 93 | Batch_idx: 140 |  Loss: (0.2483) |  Loss2: (0.0000) | Acc: (91.00%) (16485/18048)
Epoch: 93 | Batch_idx: 150 |  Loss: (0.2510) |  Loss2: (0.0000) | Acc: (91.00%) (17631/19328)
Epoch: 93 | Batch_idx: 160 |  Loss: (0.2512) |  Loss2: (0.0000) | Acc: (91.00%) (18792/20608)
Epoch: 93 | Batch_idx: 170 |  Loss: (0.2492) |  Loss2: (0.0000) | Acc: (91.00%) (19979/21888)
Epoch: 93 | Batch_idx: 180 |  Loss: (0.2488) |  Loss2: (0.0000) | Acc: (91.00%) (21143/23168)
Epoch: 93 | Batch_idx: 190 |  Loss: (0.2497) |  Loss2: (0.0000) | Acc: (91.00%) (22299/24448)
Epoch: 93 | Batch_idx: 200 |  Loss: (0.2506) |  Loss2: (0.0000) | Acc: (91.00%) (23461/25728)
Epoch: 93 | Batch_idx: 210 |  Loss: (0.2502) |  Loss2: (0.0000) | Acc: (91.00%) (24626/27008)
Epoch: 93 | Batch_idx: 220 |  Loss: (0.2495) |  Loss2: (0.0000) | Acc: (91.00%) (25797/28288)
Epoch: 93 | Batch_idx: 230 |  Loss: (0.2507) |  Loss2: (0.0000) | Acc: (91.00%) (26954/29568)
Epoch: 93 | Batch_idx: 240 |  Loss: (0.2494) |  Loss2: (0.0000) | Acc: (91.00%) (28145/30848)
Epoch: 93 | Batch_idx: 250 |  Loss: (0.2490) |  Loss2: (0.0000) | Acc: (91.00%) (29320/32128)
Epoch: 93 | Batch_idx: 260 |  Loss: (0.2486) |  Loss2: (0.0000) | Acc: (91.00%) (30501/33408)
Epoch: 93 | Batch_idx: 270 |  Loss: (0.2487) |  Loss2: (0.0000) | Acc: (91.00%) (31667/34688)
Epoch: 93 | Batch_idx: 280 |  Loss: (0.2474) |  Loss2: (0.0000) | Acc: (91.00%) (32849/35968)
Epoch: 93 | Batch_idx: 290 |  Loss: (0.2470) |  Loss2: (0.0000) | Acc: (91.00%) (34031/37248)
Epoch: 93 | Batch_idx: 300 |  Loss: (0.2479) |  Loss2: (0.0000) | Acc: (91.00%) (35195/38528)
Epoch: 93 | Batch_idx: 310 |  Loss: (0.2475) |  Loss2: (0.0000) | Acc: (91.00%) (36372/39808)
Epoch: 93 | Batch_idx: 320 |  Loss: (0.2483) |  Loss2: (0.0000) | Acc: (91.00%) (37537/41088)
Epoch: 93 | Batch_idx: 330 |  Loss: (0.2489) |  Loss2: (0.0000) | Acc: (91.00%) (38703/42368)
Epoch: 93 | Batch_idx: 340 |  Loss: (0.2488) |  Loss2: (0.0000) | Acc: (91.00%) (39882/43648)
Epoch: 93 | Batch_idx: 350 |  Loss: (0.2493) |  Loss2: (0.0000) | Acc: (91.00%) (41031/44928)
Epoch: 93 | Batch_idx: 360 |  Loss: (0.2498) |  Loss2: (0.0000) | Acc: (91.00%) (42194/46208)
Epoch: 93 | Batch_idx: 370 |  Loss: (0.2496) |  Loss2: (0.0000) | Acc: (91.00%) (43366/47488)
Epoch: 93 | Batch_idx: 380 |  Loss: (0.2500) |  Loss2: (0.0000) | Acc: (91.00%) (44519/48768)
Epoch: 93 | Batch_idx: 390 |  Loss: (0.2496) |  Loss2: (0.0000) | Acc: (91.00%) (45655/50000)
# TEST : Loss: (0.3989) | Acc: (86.00%) (8675/10000)
percent tensor([0.4987, 0.4999, 0.5030, 0.4954, 0.5036, 0.5016, 0.5011, 0.4972, 0.4999,
        0.4996, 0.5017, 0.5019, 0.4982, 0.4974, 0.5010, 0.4976],
       device='cuda:0') torch.Size([16])
percent tensor([0.4997, 0.4774, 0.4957, 0.4988, 0.4964, 0.5106, 0.4816, 0.4831, 0.4953,
        0.4804, 0.4966, 0.4866, 0.4798, 0.4896, 0.4937, 0.4981],
       device='cuda:0') torch.Size([16])
percent tensor([0.6219, 0.6255, 0.5820, 0.5687, 0.5948, 0.6082, 0.6394, 0.6008, 0.5876,
        0.6042, 0.6072, 0.5902, 0.6418, 0.5818, 0.6559, 0.6065],
       device='cuda:0') torch.Size([16])
percent tensor([0.5910, 0.5954, 0.5978, 0.6172, 0.6121, 0.6878, 0.5958, 0.5855, 0.5908,
        0.5628, 0.5837, 0.6151, 0.5860, 0.6049, 0.6349, 0.6180],
       device='cuda:0') torch.Size([16])
percent tensor([0.5378, 0.5756, 0.5144, 0.5262, 0.5478, 0.5279, 0.5697, 0.5005, 0.5789,
        0.5834, 0.5984, 0.5077, 0.5565, 0.6527, 0.4769, 0.5917],
       device='cuda:0') torch.Size([16])
percent tensor([0.5874, 0.5802, 0.6786, 0.6864, 0.7198, 0.6689, 0.6521, 0.6532, 0.6307,
        0.6041, 0.6051, 0.6609, 0.5788, 0.6501, 0.6048, 0.6345],
       device='cuda:0') torch.Size([16])
percent tensor([0.5730, 0.6262, 0.6643, 0.6351, 0.6778, 0.5015, 0.6195, 0.5399, 0.6569,
        0.6526, 0.6852, 0.6508, 0.6209, 0.6460, 0.5560, 0.5056],
       device='cuda:0') torch.Size([16])
percent tensor([0.9991, 0.9990, 0.9993, 0.9994, 0.9990, 0.9988, 0.9989, 0.9984, 0.9993,
        0.9993, 0.9996, 0.9993, 0.9993, 0.9981, 0.9976, 0.9989],
       device='cuda:0') torch.Size([16])
Epoch: 94 | Batch_idx: 0 |  Loss: (0.2447) |  Loss2: (0.0000) | Acc: (90.00%) (116/128)
Epoch: 94 | Batch_idx: 10 |  Loss: (0.2573) |  Loss2: (0.0000) | Acc: (90.00%) (1278/1408)
Epoch: 94 | Batch_idx: 20 |  Loss: (0.2572) |  Loss2: (0.0000) | Acc: (91.00%) (2447/2688)
Epoch: 94 | Batch_idx: 30 |  Loss: (0.2562) |  Loss2: (0.0000) | Acc: (91.00%) (3619/3968)
Epoch: 94 | Batch_idx: 40 |  Loss: (0.2528) |  Loss2: (0.0000) | Acc: (91.00%) (4793/5248)
Epoch: 94 | Batch_idx: 50 |  Loss: (0.2530) |  Loss2: (0.0000) | Acc: (91.00%) (5951/6528)
Epoch: 94 | Batch_idx: 60 |  Loss: (0.2502) |  Loss2: (0.0000) | Acc: (91.00%) (7123/7808)
Epoch: 94 | Batch_idx: 70 |  Loss: (0.2497) |  Loss2: (0.0000) | Acc: (91.00%) (8295/9088)
Epoch: 94 | Batch_idx: 80 |  Loss: (0.2480) |  Loss2: (0.0000) | Acc: (91.00%) (9471/10368)
Epoch: 94 | Batch_idx: 90 |  Loss: (0.2477) |  Loss2: (0.0000) | Acc: (91.00%) (10648/11648)
Epoch: 94 | Batch_idx: 100 |  Loss: (0.2484) |  Loss2: (0.0000) | Acc: (91.00%) (11821/12928)
Epoch: 94 | Batch_idx: 110 |  Loss: (0.2470) |  Loss2: (0.0000) | Acc: (91.00%) (13002/14208)
Epoch: 94 | Batch_idx: 120 |  Loss: (0.2479) |  Loss2: (0.0000) | Acc: (91.00%) (14168/15488)
Epoch: 94 | Batch_idx: 130 |  Loss: (0.2484) |  Loss2: (0.0000) | Acc: (91.00%) (15328/16768)
Epoch: 94 | Batch_idx: 140 |  Loss: (0.2483) |  Loss2: (0.0000) | Acc: (91.00%) (16513/18048)
Epoch: 94 | Batch_idx: 150 |  Loss: (0.2471) |  Loss2: (0.0000) | Acc: (91.00%) (17684/19328)
Epoch: 94 | Batch_idx: 160 |  Loss: (0.2467) |  Loss2: (0.0000) | Acc: (91.00%) (18868/20608)
Epoch: 94 | Batch_idx: 170 |  Loss: (0.2470) |  Loss2: (0.0000) | Acc: (91.00%) (20042/21888)
Epoch: 94 | Batch_idx: 180 |  Loss: (0.2478) |  Loss2: (0.0000) | Acc: (91.00%) (21213/23168)
Epoch: 94 | Batch_idx: 190 |  Loss: (0.2475) |  Loss2: (0.0000) | Acc: (91.00%) (22385/24448)
Epoch: 94 | Batch_idx: 200 |  Loss: (0.2472) |  Loss2: (0.0000) | Acc: (91.00%) (23561/25728)
Epoch: 94 | Batch_idx: 210 |  Loss: (0.2468) |  Loss2: (0.0000) | Acc: (91.00%) (24733/27008)
Epoch: 94 | Batch_idx: 220 |  Loss: (0.2448) |  Loss2: (0.0000) | Acc: (91.00%) (25923/28288)
Epoch: 94 | Batch_idx: 230 |  Loss: (0.2446) |  Loss2: (0.0000) | Acc: (91.00%) (27101/29568)
Epoch: 94 | Batch_idx: 240 |  Loss: (0.2451) |  Loss2: (0.0000) | Acc: (91.00%) (28258/30848)
Epoch: 94 | Batch_idx: 250 |  Loss: (0.2444) |  Loss2: (0.0000) | Acc: (91.00%) (29438/32128)
Epoch: 94 | Batch_idx: 260 |  Loss: (0.2452) |  Loss2: (0.0000) | Acc: (91.00%) (30607/33408)
Epoch: 94 | Batch_idx: 270 |  Loss: (0.2441) |  Loss2: (0.0000) | Acc: (91.00%) (31796/34688)
Epoch: 94 | Batch_idx: 280 |  Loss: (0.2434) |  Loss2: (0.0000) | Acc: (91.00%) (32979/35968)
Epoch: 94 | Batch_idx: 290 |  Loss: (0.2443) |  Loss2: (0.0000) | Acc: (91.00%) (34139/37248)
Epoch: 94 | Batch_idx: 300 |  Loss: (0.2437) |  Loss2: (0.0000) | Acc: (91.00%) (35319/38528)
Epoch: 94 | Batch_idx: 310 |  Loss: (0.2449) |  Loss2: (0.0000) | Acc: (91.00%) (36471/39808)
Epoch: 94 | Batch_idx: 320 |  Loss: (0.2443) |  Loss2: (0.0000) | Acc: (91.00%) (37645/41088)
Epoch: 94 | Batch_idx: 330 |  Loss: (0.2445) |  Loss2: (0.0000) | Acc: (91.00%) (38812/42368)
Epoch: 94 | Batch_idx: 340 |  Loss: (0.2439) |  Loss2: (0.0000) | Acc: (91.00%) (39991/43648)
Epoch: 94 | Batch_idx: 350 |  Loss: (0.2442) |  Loss2: (0.0000) | Acc: (91.00%) (41158/44928)
Epoch: 94 | Batch_idx: 360 |  Loss: (0.2438) |  Loss2: (0.0000) | Acc: (91.00%) (42333/46208)
Epoch: 94 | Batch_idx: 370 |  Loss: (0.2433) |  Loss2: (0.0000) | Acc: (91.00%) (43505/47488)
Epoch: 94 | Batch_idx: 380 |  Loss: (0.2431) |  Loss2: (0.0000) | Acc: (91.00%) (44694/48768)
Epoch: 94 | Batch_idx: 390 |  Loss: (0.2429) |  Loss2: (0.0000) | Acc: (91.00%) (45824/50000)
# TEST : Loss: (0.3928) | Acc: (87.00%) (8703/10000)
percent tensor([0.5003, 0.5019, 0.5047, 0.4971, 0.5054, 0.5031, 0.5031, 0.4991, 0.5018,
        0.5015, 0.5036, 0.5037, 0.5000, 0.4988, 0.5028, 0.4993],
       device='cuda:0') torch.Size([16])
percent tensor([0.5006, 0.4774, 0.4965, 0.4995, 0.4973, 0.5118, 0.4819, 0.4838, 0.4957,
        0.4806, 0.4971, 0.4874, 0.4799, 0.4898, 0.4946, 0.4990],
       device='cuda:0') torch.Size([16])
percent tensor([0.6156, 0.6223, 0.5777, 0.5646, 0.5891, 0.6024, 0.6342, 0.5961, 0.5828,
        0.6002, 0.6027, 0.5856, 0.6374, 0.5786, 0.6509, 0.6015],
       device='cuda:0') torch.Size([16])
percent tensor([0.5949, 0.5988, 0.6000, 0.6196, 0.6158, 0.6927, 0.5993, 0.5889, 0.5938,
        0.5656, 0.5876, 0.6174, 0.5890, 0.6081, 0.6396, 0.6221],
       device='cuda:0') torch.Size([16])
percent tensor([0.5386, 0.5784, 0.5156, 0.5288, 0.5488, 0.5246, 0.5720, 0.5042, 0.5793,
        0.5884, 0.6001, 0.5074, 0.5597, 0.6550, 0.4767, 0.5943],
       device='cuda:0') torch.Size([16])
percent tensor([0.5819, 0.5752, 0.6770, 0.6829, 0.7180, 0.6643, 0.6481, 0.6505, 0.6266,
        0.6003, 0.6008, 0.6592, 0.5735, 0.6456, 0.5996, 0.6292],
       device='cuda:0') torch.Size([16])
percent tensor([0.5836, 0.6367, 0.6732, 0.6450, 0.6837, 0.5104, 0.6270, 0.5417, 0.6685,
        0.6631, 0.6989, 0.6619, 0.6336, 0.6546, 0.5648, 0.5102],
       device='cuda:0') torch.Size([16])
percent tensor([0.9992, 0.9990, 0.9993, 0.9995, 0.9991, 0.9989, 0.9989, 0.9985, 0.9993,
        0.9993, 0.9997, 0.9993, 0.9993, 0.9981, 0.9978, 0.9989],
       device='cuda:0') torch.Size([16])
Epoch: 95 | Batch_idx: 0 |  Loss: (0.2546) |  Loss2: (0.0000) | Acc: (92.00%) (118/128)
Epoch: 95 | Batch_idx: 10 |  Loss: (0.2677) |  Loss2: (0.0000) | Acc: (91.00%) (1282/1408)
Epoch: 95 | Batch_idx: 20 |  Loss: (0.2494) |  Loss2: (0.0000) | Acc: (91.00%) (2461/2688)
Epoch: 95 | Batch_idx: 30 |  Loss: (0.2425) |  Loss2: (0.0000) | Acc: (91.00%) (3641/3968)
Epoch: 95 | Batch_idx: 40 |  Loss: (0.2368) |  Loss2: (0.0000) | Acc: (91.00%) (4822/5248)
Epoch: 95 | Batch_idx: 50 |  Loss: (0.2376) |  Loss2: (0.0000) | Acc: (91.00%) (5990/6528)
Epoch: 95 | Batch_idx: 60 |  Loss: (0.2353) |  Loss2: (0.0000) | Acc: (91.00%) (7176/7808)
Epoch: 95 | Batch_idx: 70 |  Loss: (0.2381) |  Loss2: (0.0000) | Acc: (91.00%) (8339/9088)
Epoch: 95 | Batch_idx: 80 |  Loss: (0.2392) |  Loss2: (0.0000) | Acc: (91.00%) (9514/10368)
Epoch: 95 | Batch_idx: 90 |  Loss: (0.2415) |  Loss2: (0.0000) | Acc: (91.00%) (10677/11648)
Epoch: 95 | Batch_idx: 100 |  Loss: (0.2430) |  Loss2: (0.0000) | Acc: (91.00%) (11847/12928)
Epoch: 95 | Batch_idx: 110 |  Loss: (0.2462) |  Loss2: (0.0000) | Acc: (91.00%) (12999/14208)
Epoch: 95 | Batch_idx: 120 |  Loss: (0.2449) |  Loss2: (0.0000) | Acc: (91.00%) (14179/15488)
Epoch: 95 | Batch_idx: 130 |  Loss: (0.2437) |  Loss2: (0.0000) | Acc: (91.00%) (15359/16768)
Epoch: 95 | Batch_idx: 140 |  Loss: (0.2442) |  Loss2: (0.0000) | Acc: (91.00%) (16527/18048)
Epoch: 95 | Batch_idx: 150 |  Loss: (0.2439) |  Loss2: (0.0000) | Acc: (91.00%) (17699/19328)
Epoch: 95 | Batch_idx: 160 |  Loss: (0.2455) |  Loss2: (0.0000) | Acc: (91.00%) (18853/20608)
Epoch: 95 | Batch_idx: 170 |  Loss: (0.2451) |  Loss2: (0.0000) | Acc: (91.00%) (20026/21888)
Epoch: 95 | Batch_idx: 180 |  Loss: (0.2448) |  Loss2: (0.0000) | Acc: (91.00%) (21203/23168)
Epoch: 95 | Batch_idx: 190 |  Loss: (0.2447) |  Loss2: (0.0000) | Acc: (91.00%) (22373/24448)
Epoch: 95 | Batch_idx: 200 |  Loss: (0.2446) |  Loss2: (0.0000) | Acc: (91.00%) (23554/25728)
Epoch: 95 | Batch_idx: 210 |  Loss: (0.2447) |  Loss2: (0.0000) | Acc: (91.00%) (24723/27008)
Epoch: 95 | Batch_idx: 220 |  Loss: (0.2455) |  Loss2: (0.0000) | Acc: (91.00%) (25883/28288)
Epoch: 95 | Batch_idx: 230 |  Loss: (0.2449) |  Loss2: (0.0000) | Acc: (91.00%) (27063/29568)
Epoch: 95 | Batch_idx: 240 |  Loss: (0.2450) |  Loss2: (0.0000) | Acc: (91.00%) (28243/30848)
Epoch: 95 | Batch_idx: 250 |  Loss: (0.2449) |  Loss2: (0.0000) | Acc: (91.00%) (29418/32128)
Epoch: 95 | Batch_idx: 260 |  Loss: (0.2445) |  Loss2: (0.0000) | Acc: (91.00%) (30589/33408)
Epoch: 95 | Batch_idx: 270 |  Loss: (0.2447) |  Loss2: (0.0000) | Acc: (91.00%) (31750/34688)
Epoch: 95 | Batch_idx: 280 |  Loss: (0.2448) |  Loss2: (0.0000) | Acc: (91.00%) (32913/35968)
Epoch: 95 | Batch_idx: 290 |  Loss: (0.2450) |  Loss2: (0.0000) | Acc: (91.00%) (34082/37248)
Epoch: 95 | Batch_idx: 300 |  Loss: (0.2446) |  Loss2: (0.0000) | Acc: (91.00%) (35259/38528)
Epoch: 95 | Batch_idx: 310 |  Loss: (0.2438) |  Loss2: (0.0000) | Acc: (91.00%) (36446/39808)
Epoch: 95 | Batch_idx: 320 |  Loss: (0.2435) |  Loss2: (0.0000) | Acc: (91.00%) (37616/41088)
Epoch: 95 | Batch_idx: 330 |  Loss: (0.2438) |  Loss2: (0.0000) | Acc: (91.00%) (38789/42368)
Epoch: 95 | Batch_idx: 340 |  Loss: (0.2431) |  Loss2: (0.0000) | Acc: (91.00%) (39976/43648)
Epoch: 95 | Batch_idx: 350 |  Loss: (0.2440) |  Loss2: (0.0000) | Acc: (91.00%) (41136/44928)
Epoch: 95 | Batch_idx: 360 |  Loss: (0.2444) |  Loss2: (0.0000) | Acc: (91.00%) (42299/46208)
Epoch: 95 | Batch_idx: 370 |  Loss: (0.2447) |  Loss2: (0.0000) | Acc: (91.00%) (43471/47488)
Epoch: 95 | Batch_idx: 380 |  Loss: (0.2448) |  Loss2: (0.0000) | Acc: (91.00%) (44631/48768)
Epoch: 95 | Batch_idx: 390 |  Loss: (0.2444) |  Loss2: (0.0000) | Acc: (91.00%) (45763/50000)
=> saving checkpoint 'drive/app/torch/save_Schedule/checkpoint_095.pth.tar'
# TEST : Loss: (0.3927) | Acc: (87.00%) (8700/10000)
percent tensor([0.5003, 0.5018, 0.5049, 0.4972, 0.5054, 0.5030, 0.5031, 0.4993, 0.5017,
        0.5015, 0.5035, 0.5039, 0.4999, 0.4987, 0.5027, 0.4992],
       device='cuda:0') torch.Size([16])
percent tensor([0.5017, 0.4778, 0.4976, 0.5008, 0.4986, 0.5127, 0.4827, 0.4855, 0.4968,
        0.4808, 0.4978, 0.4882, 0.4806, 0.4905, 0.4956, 0.4996],
       device='cuda:0') torch.Size([16])
percent tensor([0.6161, 0.6236, 0.5785, 0.5652, 0.5892, 0.6023, 0.6344, 0.5970, 0.5832,
        0.6010, 0.6037, 0.5859, 0.6399, 0.5781, 0.6517, 0.6019],
       device='cuda:0') torch.Size([16])
percent tensor([0.6007, 0.6055, 0.6043, 0.6249, 0.6204, 0.6978, 0.6058, 0.5953, 0.5994,
        0.5709, 0.5938, 0.6231, 0.5956, 0.6146, 0.6466, 0.6283],
       device='cuda:0') torch.Size([16])
percent tensor([0.5436, 0.5794, 0.5211, 0.5346, 0.5561, 0.5302, 0.5769, 0.5113, 0.5831,
        0.5907, 0.6025, 0.5109, 0.5640, 0.6573, 0.4811, 0.5994],
       device='cuda:0') torch.Size([16])
percent tensor([0.5840, 0.5792, 0.6817, 0.6884, 0.7236, 0.6650, 0.6528, 0.6548, 0.6311,
        0.6071, 0.6056, 0.6653, 0.5772, 0.6509, 0.6033, 0.6315],
       device='cuda:0') torch.Size([16])
percent tensor([0.5763, 0.6357, 0.6731, 0.6425, 0.6837, 0.5059, 0.6239, 0.5411, 0.6698,
        0.6631, 0.6993, 0.6608, 0.6303, 0.6506, 0.5631, 0.5060],
       device='cuda:0') torch.Size([16])
percent tensor([0.9992, 0.9991, 0.9994, 0.9995, 0.9992, 0.9990, 0.9991, 0.9987, 0.9994,
        0.9994, 0.9997, 0.9994, 0.9994, 0.9983, 0.9980, 0.9990],
       device='cuda:0') torch.Size([16])
True Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=128, out_features=16, bias=False)
False Linear(in_features=16, out_features=2, bias=False)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=128, out_features=16, bias=False)
False Linear(in_features=16, out_features=2, bias=False)
True Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=256, out_features=32, bias=False)
False Linear(in_features=32, out_features=2, bias=False)
True Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=256, out_features=32, bias=False)
False Linear(in_features=32, out_features=2, bias=False)
True Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=512, out_features=64, bias=False)
False Linear(in_features=64, out_features=2, bias=False)
True Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=512, out_features=64, bias=False)
False Linear(in_features=64, out_features=2, bias=False)
True Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1024, out_features=128, bias=False)
False Linear(in_features=128, out_features=2, bias=False)
True Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1024, out_features=128, bias=False)
False Linear(in_features=128, out_features=2, bias=False)
True Linear(in_features=512, out_features=10, bias=True)
Epoch: 96 | Batch_idx: 0 |  Loss: (0.2455) |  Loss2: (0.0000) | Acc: (90.00%) (116/128)
Epoch: 96 | Batch_idx: 10 |  Loss: (0.2350) |  Loss2: (0.0000) | Acc: (91.00%) (1284/1408)
Epoch: 96 | Batch_idx: 20 |  Loss: (0.2420) |  Loss2: (0.0000) | Acc: (91.00%) (2451/2688)
Epoch: 96 | Batch_idx: 30 |  Loss: (0.2462) |  Loss2: (0.0000) | Acc: (91.00%) (3618/3968)
Epoch: 96 | Batch_idx: 40 |  Loss: (0.2496) |  Loss2: (0.0000) | Acc: (91.00%) (4792/5248)
Epoch: 96 | Batch_idx: 50 |  Loss: (0.2506) |  Loss2: (0.0000) | Acc: (91.00%) (5962/6528)
Epoch: 96 | Batch_idx: 60 |  Loss: (0.2495) |  Loss2: (0.0000) | Acc: (91.00%) (7139/7808)
Epoch: 96 | Batch_idx: 70 |  Loss: (0.2418) |  Loss2: (0.0000) | Acc: (91.00%) (8335/9088)
Epoch: 96 | Batch_idx: 80 |  Loss: (0.2434) |  Loss2: (0.0000) | Acc: (91.00%) (9494/10368)
Epoch: 96 | Batch_idx: 90 |  Loss: (0.2450) |  Loss2: (0.0000) | Acc: (91.00%) (10654/11648)
Epoch: 96 | Batch_idx: 100 |  Loss: (0.2433) |  Loss2: (0.0000) | Acc: (91.00%) (11828/12928)
Epoch: 96 | Batch_idx: 110 |  Loss: (0.2420) |  Loss2: (0.0000) | Acc: (91.00%) (13003/14208)
Epoch: 96 | Batch_idx: 120 |  Loss: (0.2419) |  Loss2: (0.0000) | Acc: (91.00%) (14166/15488)
Epoch: 96 | Batch_idx: 130 |  Loss: (0.2424) |  Loss2: (0.0000) | Acc: (91.00%) (15330/16768)
Epoch: 96 | Batch_idx: 140 |  Loss: (0.2447) |  Loss2: (0.0000) | Acc: (91.00%) (16492/18048)
Epoch: 96 | Batch_idx: 150 |  Loss: (0.2447) |  Loss2: (0.0000) | Acc: (91.00%) (17662/19328)
Epoch: 96 | Batch_idx: 160 |  Loss: (0.2438) |  Loss2: (0.0000) | Acc: (91.00%) (18838/20608)
Epoch: 96 | Batch_idx: 170 |  Loss: (0.2458) |  Loss2: (0.0000) | Acc: (91.00%) (19996/21888)
Epoch: 96 | Batch_idx: 180 |  Loss: (0.2471) |  Loss2: (0.0000) | Acc: (91.00%) (21154/23168)
Epoch: 96 | Batch_idx: 190 |  Loss: (0.2468) |  Loss2: (0.0000) | Acc: (91.00%) (22324/24448)
Epoch: 96 | Batch_idx: 200 |  Loss: (0.2479) |  Loss2: (0.0000) | Acc: (91.00%) (23484/25728)
Epoch: 96 | Batch_idx: 210 |  Loss: (0.2481) |  Loss2: (0.0000) | Acc: (91.00%) (24650/27008)
Epoch: 96 | Batch_idx: 220 |  Loss: (0.2473) |  Loss2: (0.0000) | Acc: (91.00%) (25819/28288)
Epoch: 96 | Batch_idx: 230 |  Loss: (0.2467) |  Loss2: (0.0000) | Acc: (91.00%) (26997/29568)
Epoch: 96 | Batch_idx: 240 |  Loss: (0.2469) |  Loss2: (0.0000) | Acc: (91.00%) (28167/30848)
Epoch: 96 | Batch_idx: 250 |  Loss: (0.2474) |  Loss2: (0.0000) | Acc: (91.00%) (29340/32128)
Epoch: 96 | Batch_idx: 260 |  Loss: (0.2470) |  Loss2: (0.0000) | Acc: (91.00%) (30514/33408)
Epoch: 96 | Batch_idx: 270 |  Loss: (0.2472) |  Loss2: (0.0000) | Acc: (91.00%) (31689/34688)
Epoch: 96 | Batch_idx: 280 |  Loss: (0.2471) |  Loss2: (0.0000) | Acc: (91.00%) (32868/35968)
Epoch: 96 | Batch_idx: 290 |  Loss: (0.2467) |  Loss2: (0.0000) | Acc: (91.00%) (34054/37248)
Epoch: 96 | Batch_idx: 300 |  Loss: (0.2468) |  Loss2: (0.0000) | Acc: (91.00%) (35228/38528)
Epoch: 96 | Batch_idx: 310 |  Loss: (0.2462) |  Loss2: (0.0000) | Acc: (91.00%) (36411/39808)
Epoch: 96 | Batch_idx: 320 |  Loss: (0.2466) |  Loss2: (0.0000) | Acc: (91.00%) (37568/41088)
Epoch: 96 | Batch_idx: 330 |  Loss: (0.2467) |  Loss2: (0.0000) | Acc: (91.00%) (38733/42368)
Epoch: 96 | Batch_idx: 340 |  Loss: (0.2471) |  Loss2: (0.0000) | Acc: (91.00%) (39893/43648)
Epoch: 96 | Batch_idx: 350 |  Loss: (0.2469) |  Loss2: (0.0000) | Acc: (91.00%) (41069/44928)
Epoch: 96 | Batch_idx: 360 |  Loss: (0.2471) |  Loss2: (0.0000) | Acc: (91.00%) (42232/46208)
Epoch: 96 | Batch_idx: 370 |  Loss: (0.2472) |  Loss2: (0.0000) | Acc: (91.00%) (43392/47488)
Epoch: 96 | Batch_idx: 380 |  Loss: (0.2480) |  Loss2: (0.0000) | Acc: (91.00%) (44540/48768)
Epoch: 96 | Batch_idx: 390 |  Loss: (0.2480) |  Loss2: (0.0000) | Acc: (91.00%) (45660/50000)
# TEST : Loss: (0.4546) | Acc: (86.00%) (8601/10000)
percent tensor([0.5014, 0.5012, 0.5069, 0.4971, 0.5074, 0.5042, 0.5032, 0.4997, 0.5019,
        0.5019, 0.5039, 0.5048, 0.5006, 0.4983, 0.5029, 0.4996],
       device='cuda:0') torch.Size([16])
percent tensor([0.4997, 0.4800, 0.4964, 0.5009, 0.4902, 0.5124, 0.4812, 0.4866, 0.4973,
        0.4820, 0.4971, 0.4873, 0.4812, 0.4957, 0.4959, 0.5006],
       device='cuda:0') torch.Size([16])
percent tensor([0.6226, 0.6256, 0.5856, 0.5690, 0.5949, 0.6072, 0.6336, 0.5994, 0.5799,
        0.6032, 0.5995, 0.5832, 0.6352, 0.5726, 0.6554, 0.6077],
       device='cuda:0') torch.Size([16])
percent tensor([0.5992, 0.6123, 0.5956, 0.6284, 0.6003, 0.6966, 0.6015, 0.5980, 0.6076,
        0.5800, 0.5987, 0.6128, 0.5942, 0.6232, 0.6486, 0.6380],
       device='cuda:0') torch.Size([16])
percent tensor([0.5564, 0.5856, 0.5162, 0.5117, 0.5559, 0.5399, 0.5690, 0.5022, 0.5810,
        0.5953, 0.6107, 0.5071, 0.5740, 0.6554, 0.4725, 0.6014],
       device='cuda:0') torch.Size([16])
percent tensor([0.5841, 0.5710, 0.6842, 0.6973, 0.7299, 0.6712, 0.6479, 0.6581, 0.6358,
        0.6140, 0.6090, 0.6595, 0.5722, 0.6415, 0.6019, 0.6319],
       device='cuda:0') torch.Size([16])
percent tensor([0.5722, 0.6302, 0.6871, 0.6375, 0.6978, 0.4872, 0.6228, 0.5433, 0.6695,
        0.6567, 0.7215, 0.6605, 0.6241, 0.6486, 0.5544, 0.4979],
       device='cuda:0') torch.Size([16])
percent tensor([0.9995, 0.9993, 0.9997, 0.9992, 0.9994, 0.9989, 0.9989, 0.9986, 0.9996,
        0.9994, 0.9999, 0.9994, 0.9996, 0.9989, 0.9980, 0.9994],
       device='cuda:0') torch.Size([16])
Epoch: 97 | Batch_idx: 0 |  Loss: (0.2230) |  Loss2: (0.0000) | Acc: (93.00%) (120/128)
Epoch: 97 | Batch_idx: 10 |  Loss: (0.2176) |  Loss2: (0.0000) | Acc: (92.00%) (1304/1408)
Epoch: 97 | Batch_idx: 20 |  Loss: (0.2224) |  Loss2: (0.0000) | Acc: (92.00%) (2484/2688)
Epoch: 97 | Batch_idx: 30 |  Loss: (0.2197) |  Loss2: (0.0000) | Acc: (92.00%) (3680/3968)
Epoch: 97 | Batch_idx: 40 |  Loss: (0.2317) |  Loss2: (0.0000) | Acc: (92.00%) (4852/5248)
Epoch: 97 | Batch_idx: 50 |  Loss: (0.2290) |  Loss2: (0.0000) | Acc: (92.00%) (6035/6528)
Epoch: 97 | Batch_idx: 60 |  Loss: (0.2260) |  Loss2: (0.0000) | Acc: (92.00%) (7226/7808)
Epoch: 97 | Batch_idx: 70 |  Loss: (0.2269) |  Loss2: (0.0000) | Acc: (92.00%) (8398/9088)
Epoch: 97 | Batch_idx: 80 |  Loss: (0.2272) |  Loss2: (0.0000) | Acc: (92.00%) (9568/10368)
Epoch: 97 | Batch_idx: 90 |  Loss: (0.2276) |  Loss2: (0.0000) | Acc: (92.00%) (10742/11648)
Epoch: 97 | Batch_idx: 100 |  Loss: (0.2269) |  Loss2: (0.0000) | Acc: (92.00%) (11926/12928)
Epoch: 97 | Batch_idx: 110 |  Loss: (0.2304) |  Loss2: (0.0000) | Acc: (92.00%) (13094/14208)
Epoch: 97 | Batch_idx: 120 |  Loss: (0.2302) |  Loss2: (0.0000) | Acc: (92.00%) (14276/15488)
Epoch: 97 | Batch_idx: 130 |  Loss: (0.2302) |  Loss2: (0.0000) | Acc: (92.00%) (15455/16768)
Epoch: 97 | Batch_idx: 140 |  Loss: (0.2326) |  Loss2: (0.0000) | Acc: (92.00%) (16624/18048)
Epoch: 97 | Batch_idx: 150 |  Loss: (0.2331) |  Loss2: (0.0000) | Acc: (92.00%) (17788/19328)
Epoch: 97 | Batch_idx: 160 |  Loss: (0.2352) |  Loss2: (0.0000) | Acc: (91.00%) (18948/20608)
Epoch: 97 | Batch_idx: 170 |  Loss: (0.2348) |  Loss2: (0.0000) | Acc: (91.00%) (20133/21888)
Epoch: 97 | Batch_idx: 180 |  Loss: (0.2356) |  Loss2: (0.0000) | Acc: (91.00%) (21304/23168)
Epoch: 97 | Batch_idx: 190 |  Loss: (0.2357) |  Loss2: (0.0000) | Acc: (91.00%) (22490/24448)
Epoch: 97 | Batch_idx: 200 |  Loss: (0.2355) |  Loss2: (0.0000) | Acc: (91.00%) (23667/25728)
Epoch: 97 | Batch_idx: 210 |  Loss: (0.2353) |  Loss2: (0.0000) | Acc: (91.00%) (24834/27008)
Epoch: 97 | Batch_idx: 220 |  Loss: (0.2345) |  Loss2: (0.0000) | Acc: (91.00%) (26018/28288)
Epoch: 97 | Batch_idx: 230 |  Loss: (0.2355) |  Loss2: (0.0000) | Acc: (91.00%) (27183/29568)
Epoch: 97 | Batch_idx: 240 |  Loss: (0.2368) |  Loss2: (0.0000) | Acc: (91.00%) (28336/30848)
Epoch: 97 | Batch_idx: 250 |  Loss: (0.2379) |  Loss2: (0.0000) | Acc: (91.00%) (29499/32128)
Epoch: 97 | Batch_idx: 260 |  Loss: (0.2377) |  Loss2: (0.0000) | Acc: (91.00%) (30667/33408)
Epoch: 97 | Batch_idx: 270 |  Loss: (0.2385) |  Loss2: (0.0000) | Acc: (91.00%) (31837/34688)
Epoch: 97 | Batch_idx: 280 |  Loss: (0.2390) |  Loss2: (0.0000) | Acc: (91.00%) (33009/35968)
Epoch: 97 | Batch_idx: 290 |  Loss: (0.2401) |  Loss2: (0.0000) | Acc: (91.00%) (34166/37248)
Epoch: 97 | Batch_idx: 300 |  Loss: (0.2396) |  Loss2: (0.0000) | Acc: (91.00%) (35349/38528)
Epoch: 97 | Batch_idx: 310 |  Loss: (0.2399) |  Loss2: (0.0000) | Acc: (91.00%) (36518/39808)
Epoch: 97 | Batch_idx: 320 |  Loss: (0.2407) |  Loss2: (0.0000) | Acc: (91.00%) (37687/41088)
Epoch: 97 | Batch_idx: 330 |  Loss: (0.2401) |  Loss2: (0.0000) | Acc: (91.00%) (38869/42368)
Epoch: 97 | Batch_idx: 340 |  Loss: (0.2413) |  Loss2: (0.0000) | Acc: (91.00%) (40017/43648)
Epoch: 97 | Batch_idx: 350 |  Loss: (0.2419) |  Loss2: (0.0000) | Acc: (91.00%) (41178/44928)
Epoch: 97 | Batch_idx: 360 |  Loss: (0.2422) |  Loss2: (0.0000) | Acc: (91.00%) (42349/46208)
Epoch: 97 | Batch_idx: 370 |  Loss: (0.2425) |  Loss2: (0.0000) | Acc: (91.00%) (43520/47488)
Epoch: 97 | Batch_idx: 380 |  Loss: (0.2429) |  Loss2: (0.0000) | Acc: (91.00%) (44684/48768)
Epoch: 97 | Batch_idx: 390 |  Loss: (0.2426) |  Loss2: (0.0000) | Acc: (91.00%) (45817/50000)
# TEST : Loss: (0.4619) | Acc: (85.00%) (8508/10000)
percent tensor([0.5003, 0.5021, 0.5041, 0.4965, 0.5046, 0.5027, 0.5031, 0.4991, 0.5017,
        0.5018, 0.5041, 0.5032, 0.5000, 0.4994, 0.5026, 0.4997],
       device='cuda:0') torch.Size([16])
percent tensor([0.5018, 0.4796, 0.5001, 0.5049, 0.4962, 0.5136, 0.4827, 0.4866, 0.4982,
        0.4827, 0.4984, 0.4890, 0.4819, 0.4961, 0.4978, 0.5023],
       device='cuda:0') torch.Size([16])
percent tensor([0.6222, 0.6200, 0.5802, 0.5661, 0.5923, 0.6064, 0.6276, 0.5966, 0.5823,
        0.5995, 0.5998, 0.5823, 0.6377, 0.5680, 0.6487, 0.6021],
       device='cuda:0') torch.Size([16])
percent tensor([0.6021, 0.6105, 0.6031, 0.6287, 0.6158, 0.6945, 0.6079, 0.6027, 0.6118,
        0.5788, 0.5967, 0.6226, 0.6009, 0.6172, 0.6472, 0.6356],
       device='cuda:0') torch.Size([16])
percent tensor([0.5507, 0.5838, 0.5333, 0.5404, 0.5659, 0.5457, 0.5772, 0.5078, 0.5892,
        0.6039, 0.6101, 0.5272, 0.5663, 0.6568, 0.4822, 0.6086],
       device='cuda:0') torch.Size([16])
percent tensor([0.5864, 0.5822, 0.6874, 0.6988, 0.7240, 0.6679, 0.6480, 0.6601, 0.6294,
        0.6227, 0.6062, 0.6637, 0.5800, 0.6489, 0.6080, 0.6363],
       device='cuda:0') torch.Size([16])
percent tensor([0.5544, 0.6433, 0.6547, 0.6187, 0.6665, 0.4694, 0.6039, 0.5511, 0.6430,
        0.6583, 0.7058, 0.6378, 0.6153, 0.6374, 0.5615, 0.5078],
       device='cuda:0') torch.Size([16])
percent tensor([0.9995, 0.9993, 0.9992, 0.9994, 0.9985, 0.9992, 0.9990, 0.9992, 0.9992,
        0.9995, 0.9999, 0.9993, 0.9993, 0.9988, 0.9978, 0.9993],
       device='cuda:0') torch.Size([16])
Epoch: 98 | Batch_idx: 0 |  Loss: (0.1214) |  Loss2: (0.0000) | Acc: (97.00%) (125/128)
Epoch: 98 | Batch_idx: 10 |  Loss: (0.1911) |  Loss2: (0.0000) | Acc: (94.00%) (1324/1408)
Epoch: 98 | Batch_idx: 20 |  Loss: (0.2082) |  Loss2: (0.0000) | Acc: (93.00%) (2508/2688)
Epoch: 98 | Batch_idx: 30 |  Loss: (0.2147) |  Loss2: (0.0000) | Acc: (92.00%) (3687/3968)
Epoch: 98 | Batch_idx: 40 |  Loss: (0.2121) |  Loss2: (0.0000) | Acc: (92.00%) (4876/5248)
Epoch: 98 | Batch_idx: 50 |  Loss: (0.2167) |  Loss2: (0.0000) | Acc: (92.00%) (6060/6528)
Epoch: 98 | Batch_idx: 60 |  Loss: (0.2207) |  Loss2: (0.0000) | Acc: (92.00%) (7226/7808)
Epoch: 98 | Batch_idx: 70 |  Loss: (0.2238) |  Loss2: (0.0000) | Acc: (92.00%) (8395/9088)
Epoch: 98 | Batch_idx: 80 |  Loss: (0.2227) |  Loss2: (0.0000) | Acc: (92.00%) (9571/10368)
Epoch: 98 | Batch_idx: 90 |  Loss: (0.2207) |  Loss2: (0.0000) | Acc: (92.00%) (10763/11648)
Epoch: 98 | Batch_idx: 100 |  Loss: (0.2225) |  Loss2: (0.0000) | Acc: (92.00%) (11934/12928)
Epoch: 98 | Batch_idx: 110 |  Loss: (0.2243) |  Loss2: (0.0000) | Acc: (92.00%) (13100/14208)
Epoch: 98 | Batch_idx: 120 |  Loss: (0.2256) |  Loss2: (0.0000) | Acc: (92.00%) (14280/15488)
Epoch: 98 | Batch_idx: 130 |  Loss: (0.2280) |  Loss2: (0.0000) | Acc: (92.00%) (15433/16768)
Epoch: 98 | Batch_idx: 140 |  Loss: (0.2300) |  Loss2: (0.0000) | Acc: (92.00%) (16614/18048)
Epoch: 98 | Batch_idx: 150 |  Loss: (0.2293) |  Loss2: (0.0000) | Acc: (92.00%) (17795/19328)
Epoch: 98 | Batch_idx: 160 |  Loss: (0.2305) |  Loss2: (0.0000) | Acc: (91.00%) (18958/20608)
Epoch: 98 | Batch_idx: 170 |  Loss: (0.2302) |  Loss2: (0.0000) | Acc: (92.00%) (20142/21888)
Epoch: 98 | Batch_idx: 180 |  Loss: (0.2307) |  Loss2: (0.0000) | Acc: (91.00%) (21312/23168)
Epoch: 98 | Batch_idx: 190 |  Loss: (0.2301) |  Loss2: (0.0000) | Acc: (91.00%) (22482/24448)
Epoch: 98 | Batch_idx: 200 |  Loss: (0.2299) |  Loss2: (0.0000) | Acc: (91.00%) (23654/25728)
Epoch: 98 | Batch_idx: 210 |  Loss: (0.2289) |  Loss2: (0.0000) | Acc: (91.00%) (24841/27008)
Epoch: 98 | Batch_idx: 220 |  Loss: (0.2285) |  Loss2: (0.0000) | Acc: (91.00%) (26022/28288)
Epoch: 98 | Batch_idx: 230 |  Loss: (0.2288) |  Loss2: (0.0000) | Acc: (91.00%) (27200/29568)
Epoch: 98 | Batch_idx: 240 |  Loss: (0.2290) |  Loss2: (0.0000) | Acc: (91.00%) (28373/30848)
Epoch: 98 | Batch_idx: 250 |  Loss: (0.2293) |  Loss2: (0.0000) | Acc: (91.00%) (29547/32128)
Epoch: 98 | Batch_idx: 260 |  Loss: (0.2295) |  Loss2: (0.0000) | Acc: (91.00%) (30731/33408)
Epoch: 98 | Batch_idx: 270 |  Loss: (0.2284) |  Loss2: (0.0000) | Acc: (92.00%) (31918/34688)
Epoch: 98 | Batch_idx: 280 |  Loss: (0.2286) |  Loss2: (0.0000) | Acc: (91.00%) (33090/35968)
Epoch: 98 | Batch_idx: 290 |  Loss: (0.2289) |  Loss2: (0.0000) | Acc: (91.00%) (34258/37248)
Epoch: 98 | Batch_idx: 300 |  Loss: (0.2292) |  Loss2: (0.0000) | Acc: (91.00%) (35430/38528)
Epoch: 98 | Batch_idx: 310 |  Loss: (0.2300) |  Loss2: (0.0000) | Acc: (91.00%) (36594/39808)
Epoch: 98 | Batch_idx: 320 |  Loss: (0.2298) |  Loss2: (0.0000) | Acc: (91.00%) (37766/41088)
Epoch: 98 | Batch_idx: 330 |  Loss: (0.2299) |  Loss2: (0.0000) | Acc: (91.00%) (38936/42368)
Epoch: 98 | Batch_idx: 340 |  Loss: (0.2301) |  Loss2: (0.0000) | Acc: (91.00%) (40104/43648)
Epoch: 98 | Batch_idx: 350 |  Loss: (0.2300) |  Loss2: (0.0000) | Acc: (91.00%) (41281/44928)
Epoch: 98 | Batch_idx: 360 |  Loss: (0.2297) |  Loss2: (0.0000) | Acc: (91.00%) (42466/46208)
Epoch: 98 | Batch_idx: 370 |  Loss: (0.2302) |  Loss2: (0.0000) | Acc: (91.00%) (43637/47488)
Epoch: 98 | Batch_idx: 380 |  Loss: (0.2309) |  Loss2: (0.0000) | Acc: (91.00%) (44811/48768)
Epoch: 98 | Batch_idx: 390 |  Loss: (0.2303) |  Loss2: (0.0000) | Acc: (91.00%) (45955/50000)
# TEST : Loss: (0.4078) | Acc: (86.00%) (8696/10000)
percent tensor([0.5010, 0.5015, 0.5059, 0.4968, 0.5062, 0.5030, 0.5031, 0.4995, 0.5016,
        0.5019, 0.5039, 0.5043, 0.5005, 0.4983, 0.5023, 0.4996],
       device='cuda:0') torch.Size([16])
percent tensor([0.4987, 0.4778, 0.4962, 0.5018, 0.4938, 0.5130, 0.4794, 0.4861, 0.4972,
        0.4800, 0.4962, 0.4848, 0.4794, 0.4942, 0.4958, 0.5000],
       device='cuda:0') torch.Size([16])
percent tensor([0.6319, 0.6317, 0.5847, 0.5719, 0.5954, 0.6186, 0.6365, 0.5977, 0.5888,
        0.6089, 0.6068, 0.5850, 0.6460, 0.5808, 0.6605, 0.6150],
       device='cuda:0') torch.Size([16])
percent tensor([0.5981, 0.6083, 0.6038, 0.6318, 0.6119, 0.6966, 0.5994, 0.5992, 0.6043,
        0.5774, 0.5914, 0.6222, 0.5939, 0.6113, 0.6495, 0.6375],
       device='cuda:0') torch.Size([16])
percent tensor([0.5546, 0.5785, 0.5301, 0.5352, 0.5603, 0.5350, 0.5698, 0.5118, 0.5917,
        0.5912, 0.6033, 0.5052, 0.5698, 0.6570, 0.4734, 0.6107],
       device='cuda:0') torch.Size([16])
percent tensor([0.5901, 0.5815, 0.6884, 0.6991, 0.7262, 0.6762, 0.6525, 0.6535, 0.6348,
        0.6188, 0.6137, 0.6611, 0.5791, 0.6546, 0.6072, 0.6442],
       device='cuda:0') torch.Size([16])
percent tensor([0.5654, 0.6427, 0.6618, 0.6173, 0.6791, 0.4968, 0.5986, 0.5404, 0.6747,
        0.6522, 0.7210, 0.6477, 0.6406, 0.6442, 0.5453, 0.5125],
       device='cuda:0') torch.Size([16])
percent tensor([0.9993, 0.9993, 0.9991, 0.9994, 0.9989, 0.9984, 0.9989, 0.9988, 0.9996,
        0.9995, 0.9999, 0.9994, 0.9996, 0.9986, 0.9980, 0.9988],
       device='cuda:0') torch.Size([16])
Epoch: 99 | Batch_idx: 0 |  Loss: (0.2019) |  Loss2: (0.0000) | Acc: (92.00%) (119/128)
Epoch: 99 | Batch_idx: 10 |  Loss: (0.2376) |  Loss2: (0.0000) | Acc: (91.00%) (1286/1408)
Epoch: 99 | Batch_idx: 20 |  Loss: (0.2352) |  Loss2: (0.0000) | Acc: (91.00%) (2461/2688)
Epoch: 99 | Batch_idx: 30 |  Loss: (0.2296) |  Loss2: (0.0000) | Acc: (91.00%) (3639/3968)
Epoch: 99 | Batch_idx: 40 |  Loss: (0.2202) |  Loss2: (0.0000) | Acc: (92.00%) (4829/5248)
Epoch: 99 | Batch_idx: 50 |  Loss: (0.2197) |  Loss2: (0.0000) | Acc: (92.00%) (6010/6528)
Epoch: 99 | Batch_idx: 60 |  Loss: (0.2162) |  Loss2: (0.0000) | Acc: (92.00%) (7211/7808)
Epoch: 99 | Batch_idx: 70 |  Loss: (0.2135) |  Loss2: (0.0000) | Acc: (92.00%) (8405/9088)
Epoch: 99 | Batch_idx: 80 |  Loss: (0.2123) |  Loss2: (0.0000) | Acc: (92.00%) (9586/10368)
Epoch: 99 | Batch_idx: 90 |  Loss: (0.2123) |  Loss2: (0.0000) | Acc: (92.00%) (10777/11648)
Epoch: 99 | Batch_idx: 100 |  Loss: (0.2132) |  Loss2: (0.0000) | Acc: (92.00%) (11959/12928)
Epoch: 99 | Batch_idx: 110 |  Loss: (0.2128) |  Loss2: (0.0000) | Acc: (92.00%) (13142/14208)
Epoch: 99 | Batch_idx: 120 |  Loss: (0.2126) |  Loss2: (0.0000) | Acc: (92.00%) (14326/15488)
Epoch: 99 | Batch_idx: 130 |  Loss: (0.2152) |  Loss2: (0.0000) | Acc: (92.00%) (15492/16768)
Epoch: 99 | Batch_idx: 140 |  Loss: (0.2153) |  Loss2: (0.0000) | Acc: (92.00%) (16682/18048)
Epoch: 99 | Batch_idx: 150 |  Loss: (0.2171) |  Loss2: (0.0000) | Acc: (92.00%) (17853/19328)
Epoch: 99 | Batch_idx: 160 |  Loss: (0.2184) |  Loss2: (0.0000) | Acc: (92.00%) (19028/20608)
Epoch: 99 | Batch_idx: 170 |  Loss: (0.2179) |  Loss2: (0.0000) | Acc: (92.00%) (20218/21888)
Epoch: 99 | Batch_idx: 180 |  Loss: (0.2190) |  Loss2: (0.0000) | Acc: (92.00%) (21396/23168)
Epoch: 99 | Batch_idx: 190 |  Loss: (0.2202) |  Loss2: (0.0000) | Acc: (92.00%) (22562/24448)
Epoch: 99 | Batch_idx: 200 |  Loss: (0.2213) |  Loss2: (0.0000) | Acc: (92.00%) (23725/25728)
Epoch: 99 | Batch_idx: 210 |  Loss: (0.2211) |  Loss2: (0.0000) | Acc: (92.00%) (24910/27008)
Epoch: 99 | Batch_idx: 220 |  Loss: (0.2215) |  Loss2: (0.0000) | Acc: (92.00%) (26099/28288)
Epoch: 99 | Batch_idx: 230 |  Loss: (0.2225) |  Loss2: (0.0000) | Acc: (92.00%) (27270/29568)
Epoch: 99 | Batch_idx: 240 |  Loss: (0.2227) |  Loss2: (0.0000) | Acc: (92.00%) (28438/30848)
Epoch: 99 | Batch_idx: 250 |  Loss: (0.2229) |  Loss2: (0.0000) | Acc: (92.00%) (29611/32128)
Epoch: 99 | Batch_idx: 260 |  Loss: (0.2231) |  Loss2: (0.0000) | Acc: (92.00%) (30786/33408)
Epoch: 99 | Batch_idx: 270 |  Loss: (0.2227) |  Loss2: (0.0000) | Acc: (92.00%) (31981/34688)
Epoch: 99 | Batch_idx: 280 |  Loss: (0.2234) |  Loss2: (0.0000) | Acc: (92.00%) (33155/35968)
Epoch: 99 | Batch_idx: 290 |  Loss: (0.2242) |  Loss2: (0.0000) | Acc: (92.00%) (34325/37248)
Epoch: 99 | Batch_idx: 300 |  Loss: (0.2243) |  Loss2: (0.0000) | Acc: (92.00%) (35502/38528)
Epoch: 99 | Batch_idx: 310 |  Loss: (0.2248) |  Loss2: (0.0000) | Acc: (92.00%) (36668/39808)
Epoch: 99 | Batch_idx: 320 |  Loss: (0.2253) |  Loss2: (0.0000) | Acc: (92.00%) (37843/41088)
Epoch: 99 | Batch_idx: 330 |  Loss: (0.2249) |  Loss2: (0.0000) | Acc: (92.00%) (39031/42368)
Epoch: 99 | Batch_idx: 340 |  Loss: (0.2258) |  Loss2: (0.0000) | Acc: (92.00%) (40205/43648)
Epoch: 99 | Batch_idx: 350 |  Loss: (0.2253) |  Loss2: (0.0000) | Acc: (92.00%) (41394/44928)
Epoch: 99 | Batch_idx: 360 |  Loss: (0.2258) |  Loss2: (0.0000) | Acc: (92.00%) (42564/46208)
Epoch: 99 | Batch_idx: 370 |  Loss: (0.2248) |  Loss2: (0.0000) | Acc: (92.00%) (43756/47488)
Epoch: 99 | Batch_idx: 380 |  Loss: (0.2248) |  Loss2: (0.0000) | Acc: (92.00%) (44937/48768)
Epoch: 99 | Batch_idx: 390 |  Loss: (0.2259) |  Loss2: (0.0000) | Acc: (92.00%) (46056/50000)
# TEST : Loss: (0.4258) | Acc: (86.00%) (8626/10000)
percent tensor([0.5003, 0.5019, 0.5045, 0.4961, 0.5055, 0.5024, 0.5032, 0.4987, 0.5016,
        0.5019, 0.5037, 0.5043, 0.5000, 0.4992, 0.5023, 0.4992],
       device='cuda:0') torch.Size([16])
percent tensor([0.5001, 0.4793, 0.4914, 0.5016, 0.4882, 0.5128, 0.4793, 0.4860, 0.4967,
        0.4797, 0.4992, 0.4813, 0.4803, 0.4944, 0.4984, 0.5015],
       device='cuda:0') torch.Size([16])
percent tensor([0.6242, 0.6267, 0.5902, 0.5658, 0.5983, 0.6090, 0.6373, 0.5973, 0.5815,
        0.6117, 0.5974, 0.5911, 0.6395, 0.5747, 0.6508, 0.6049],
       device='cuda:0') torch.Size([16])
percent tensor([0.6032, 0.6105, 0.6071, 0.6389, 0.6115, 0.7048, 0.6012, 0.6012, 0.6053,
        0.5830, 0.5985, 0.6209, 0.5941, 0.6156, 0.6486, 0.6420],
       device='cuda:0') torch.Size([16])
percent tensor([0.5696, 0.5807, 0.5215, 0.5362, 0.5652, 0.5469, 0.5722, 0.5099, 0.6084,
        0.5906, 0.6144, 0.4967, 0.5674, 0.6636, 0.4877, 0.6114],
       device='cuda:0') torch.Size([16])
percent tensor([0.5967, 0.5746, 0.6900, 0.7044, 0.7288, 0.6872, 0.6421, 0.6541, 0.6488,
        0.6163, 0.6156, 0.6562, 0.5746, 0.6509, 0.6062, 0.6342],
       device='cuda:0') torch.Size([16])
percent tensor([0.5787, 0.6442, 0.6670, 0.6235, 0.6808, 0.4967, 0.6057, 0.5501, 0.6817,
        0.6725, 0.7099, 0.6604, 0.6336, 0.6538, 0.5685, 0.4947],
       device='cuda:0') torch.Size([16])
percent tensor([0.9994, 0.9992, 0.9994, 0.9992, 0.9989, 0.9991, 0.9987, 0.9991, 0.9993,
        0.9995, 0.9997, 0.9996, 0.9992, 0.9985, 0.9978, 0.9989],
       device='cuda:0') torch.Size([16])
Epoch: 100 | Batch_idx: 0 |  Loss: (0.1585) |  Loss2: (0.0000) | Acc: (92.00%) (118/128)
Epoch: 100 | Batch_idx: 10 |  Loss: (0.2105) |  Loss2: (0.0000) | Acc: (92.00%) (1299/1408)
Epoch: 100 | Batch_idx: 20 |  Loss: (0.2123) |  Loss2: (0.0000) | Acc: (92.00%) (2492/2688)
Epoch: 100 | Batch_idx: 30 |  Loss: (0.2152) |  Loss2: (0.0000) | Acc: (92.00%) (3676/3968)
Epoch: 100 | Batch_idx: 40 |  Loss: (0.2243) |  Loss2: (0.0000) | Acc: (92.00%) (4848/5248)
Epoch: 100 | Batch_idx: 50 |  Loss: (0.2218) |  Loss2: (0.0000) | Acc: (92.00%) (6038/6528)
Epoch: 100 | Batch_idx: 60 |  Loss: (0.2209) |  Loss2: (0.0000) | Acc: (92.00%) (7235/7808)
Epoch: 100 | Batch_idx: 70 |  Loss: (0.2192) |  Loss2: (0.0000) | Acc: (92.00%) (8415/9088)
Epoch: 100 | Batch_idx: 80 |  Loss: (0.2247) |  Loss2: (0.0000) | Acc: (92.00%) (9570/10368)
Epoch: 100 | Batch_idx: 90 |  Loss: (0.2217) |  Loss2: (0.0000) | Acc: (92.00%) (10756/11648)
Epoch: 100 | Batch_idx: 100 |  Loss: (0.2210) |  Loss2: (0.0000) | Acc: (92.00%) (11938/12928)
Epoch: 100 | Batch_idx: 110 |  Loss: (0.2203) |  Loss2: (0.0000) | Acc: (92.00%) (13125/14208)
Epoch: 100 | Batch_idx: 120 |  Loss: (0.2211) |  Loss2: (0.0000) | Acc: (92.00%) (14305/15488)
Epoch: 100 | Batch_idx: 130 |  Loss: (0.2189) |  Loss2: (0.0000) | Acc: (92.00%) (15500/16768)
Epoch: 100 | Batch_idx: 140 |  Loss: (0.2198) |  Loss2: (0.0000) | Acc: (92.00%) (16673/18048)
Epoch: 100 | Batch_idx: 150 |  Loss: (0.2193) |  Loss2: (0.0000) | Acc: (92.00%) (17857/19328)
Epoch: 100 | Batch_idx: 160 |  Loss: (0.2180) |  Loss2: (0.0000) | Acc: (92.00%) (19053/20608)
Epoch: 100 | Batch_idx: 170 |  Loss: (0.2166) |  Loss2: (0.0000) | Acc: (92.00%) (20251/21888)
Epoch: 100 | Batch_idx: 180 |  Loss: (0.2173) |  Loss2: (0.0000) | Acc: (92.00%) (21434/23168)
Epoch: 100 | Batch_idx: 190 |  Loss: (0.2164) |  Loss2: (0.0000) | Acc: (92.00%) (22629/24448)
Epoch: 100 | Batch_idx: 200 |  Loss: (0.2178) |  Loss2: (0.0000) | Acc: (92.00%) (23797/25728)
Epoch: 100 | Batch_idx: 210 |  Loss: (0.2166) |  Loss2: (0.0000) | Acc: (92.00%) (24996/27008)
Epoch: 100 | Batch_idx: 220 |  Loss: (0.2160) |  Loss2: (0.0000) | Acc: (92.00%) (26191/28288)
Epoch: 100 | Batch_idx: 230 |  Loss: (0.2170) |  Loss2: (0.0000) | Acc: (92.00%) (27362/29568)
Epoch: 100 | Batch_idx: 240 |  Loss: (0.2184) |  Loss2: (0.0000) | Acc: (92.00%) (28528/30848)
Epoch: 100 | Batch_idx: 250 |  Loss: (0.2172) |  Loss2: (0.0000) | Acc: (92.00%) (29716/32128)
Epoch: 100 | Batch_idx: 260 |  Loss: (0.2182) |  Loss2: (0.0000) | Acc: (92.00%) (30884/33408)
Epoch: 100 | Batch_idx: 270 |  Loss: (0.2191) |  Loss2: (0.0000) | Acc: (92.00%) (32057/34688)
Epoch: 100 | Batch_idx: 280 |  Loss: (0.2199) |  Loss2: (0.0000) | Acc: (92.00%) (33231/35968)
Epoch: 100 | Batch_idx: 290 |  Loss: (0.2195) |  Loss2: (0.0000) | Acc: (92.00%) (34408/37248)
Epoch: 100 | Batch_idx: 300 |  Loss: (0.2205) |  Loss2: (0.0000) | Acc: (92.00%) (35574/38528)
Epoch: 100 | Batch_idx: 310 |  Loss: (0.2205) |  Loss2: (0.0000) | Acc: (92.00%) (36765/39808)
Epoch: 100 | Batch_idx: 320 |  Loss: (0.2213) |  Loss2: (0.0000) | Acc: (92.00%) (37946/41088)
Epoch: 100 | Batch_idx: 330 |  Loss: (0.2212) |  Loss2: (0.0000) | Acc: (92.00%) (39130/42368)
Epoch: 100 | Batch_idx: 340 |  Loss: (0.2212) |  Loss2: (0.0000) | Acc: (92.00%) (40312/43648)
Epoch: 100 | Batch_idx: 350 |  Loss: (0.2212) |  Loss2: (0.0000) | Acc: (92.00%) (41487/44928)
Epoch: 100 | Batch_idx: 360 |  Loss: (0.2219) |  Loss2: (0.0000) | Acc: (92.00%) (42656/46208)
Epoch: 100 | Batch_idx: 370 |  Loss: (0.2225) |  Loss2: (0.0000) | Acc: (92.00%) (43816/47488)
Epoch: 100 | Batch_idx: 380 |  Loss: (0.2219) |  Loss2: (0.0000) | Acc: (92.00%) (45002/48768)
Epoch: 100 | Batch_idx: 390 |  Loss: (0.2223) |  Loss2: (0.0000) | Acc: (92.00%) (46128/50000)
=> saving checkpoint 'drive/app/torch/save_Schedule/checkpoint_100.pth.tar'
# TEST : Loss: (0.3987) | Acc: (87.00%) (8717/10000)
percent tensor([0.5003, 0.5013, 0.5049, 0.4971, 0.5056, 0.5030, 0.5028, 0.4992, 0.5006,
        0.5017, 0.5030, 0.5037, 0.4997, 0.4984, 0.5025, 0.4994],
       device='cuda:0') torch.Size([16])
percent tensor([0.5019, 0.4819, 0.4963, 0.5030, 0.4937, 0.5127, 0.4833, 0.4887, 0.4993,
        0.4826, 0.5005, 0.4873, 0.4826, 0.5000, 0.4978, 0.5028],
       device='cuda:0') torch.Size([16])
percent tensor([0.6185, 0.6211, 0.5827, 0.5641, 0.5921, 0.6040, 0.6314, 0.5976, 0.5748,
        0.6021, 0.5926, 0.5836, 0.6353, 0.5672, 0.6522, 0.6004],
       device='cuda:0') torch.Size([16])
percent tensor([0.6030, 0.6162, 0.5953, 0.6265, 0.6071, 0.7150, 0.6016, 0.5928, 0.6082,
        0.5859, 0.6031, 0.6142, 0.5980, 0.6250, 0.6559, 0.6463],
       device='cuda:0') torch.Size([16])
percent tensor([0.5603, 0.5854, 0.5264, 0.5369, 0.5630, 0.5345, 0.5715, 0.5139, 0.6101,
        0.5954, 0.6111, 0.5125, 0.5705, 0.6701, 0.4787, 0.6047],
       device='cuda:0') torch.Size([16])
percent tensor([0.5864, 0.5882, 0.6771, 0.6827, 0.7192, 0.6846, 0.6473, 0.6497, 0.6365,
        0.6237, 0.6115, 0.6517, 0.5826, 0.6559, 0.6081, 0.6365],
       device='cuda:0') torch.Size([16])
percent tensor([0.5576, 0.6408, 0.6653, 0.6189, 0.6736, 0.5037, 0.6063, 0.5314, 0.6528,
        0.6513, 0.6919, 0.6594, 0.6183, 0.6387, 0.5622, 0.4998],
       device='cuda:0') torch.Size([16])
percent tensor([0.9990, 0.9992, 0.9996, 0.9993, 0.9991, 0.9987, 0.9985, 0.9989, 0.9992,
        0.9992, 0.9998, 0.9996, 0.9991, 0.9985, 0.9979, 0.9990],
       device='cuda:0') torch.Size([16])
Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 3, 3, 3]) tensor(187.2358, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(813.7158, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(815.6087, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([128, 64, 3, 3]) tensor(1532.6382, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([128, 64, 1, 1]) tensor(492.0324, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([128, 128, 3, 3]) tensor(2266.8452, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([256, 128, 3, 3]) tensor(4286.8633, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([256, 128, 1, 1]) tensor(1392.1638, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([256, 256, 3, 3]) tensor(6146.4048, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([512, 256, 3, 3]) tensor(11869.1396, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([512, 256, 1, 1]) tensor(3941.1108, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([512, 512, 3, 3]) tensor(16647.2031, device='cuda:0', grad_fn=<NormBackward0>)
Epoch: 101 | Batch_idx: 0 |  Loss: (0.2122) |  Loss2: (0.0000) | Acc: (92.00%) (119/128)
Epoch: 101 | Batch_idx: 10 |  Loss: (0.1917) |  Loss2: (0.0000) | Acc: (93.00%) (1319/1408)
Epoch: 101 | Batch_idx: 20 |  Loss: (0.1993) |  Loss2: (0.0000) | Acc: (93.00%) (2516/2688)
Epoch: 101 | Batch_idx: 30 |  Loss: (0.2028) |  Loss2: (0.0000) | Acc: (93.00%) (3693/3968)
Epoch: 101 | Batch_idx: 40 |  Loss: (0.2001) |  Loss2: (0.0000) | Acc: (93.00%) (4892/5248)
Epoch: 101 | Batch_idx: 50 |  Loss: (0.2053) |  Loss2: (0.0000) | Acc: (93.00%) (6072/6528)
Epoch: 101 | Batch_idx: 60 |  Loss: (0.2053) |  Loss2: (0.0000) | Acc: (93.00%) (7269/7808)
Epoch: 101 | Batch_idx: 70 |  Loss: (0.2072) |  Loss2: (0.0000) | Acc: (92.00%) (8451/9088)
Epoch: 101 | Batch_idx: 80 |  Loss: (0.2079) |  Loss2: (0.0000) | Acc: (92.00%) (9640/10368)
Epoch: 101 | Batch_idx: 90 |  Loss: (0.2101) |  Loss2: (0.0000) | Acc: (92.00%) (10822/11648)
Epoch: 101 | Batch_idx: 100 |  Loss: (0.2098) |  Loss2: (0.0000) | Acc: (92.00%) (12015/12928)
Epoch: 101 | Batch_idx: 110 |  Loss: (0.2113) |  Loss2: (0.0000) | Acc: (92.00%) (13199/14208)
Epoch: 101 | Batch_idx: 120 |  Loss: (0.2121) |  Loss2: (0.0000) | Acc: (92.00%) (14381/15488)
Epoch: 101 | Batch_idx: 130 |  Loss: (0.2150) |  Loss2: (0.0000) | Acc: (92.00%) (15555/16768)
Epoch: 101 | Batch_idx: 140 |  Loss: (0.2156) |  Loss2: (0.0000) | Acc: (92.00%) (16728/18048)
Epoch: 101 | Batch_idx: 150 |  Loss: (0.2159) |  Loss2: (0.0000) | Acc: (92.00%) (17908/19328)
Epoch: 101 | Batch_idx: 160 |  Loss: (0.2169) |  Loss2: (0.0000) | Acc: (92.00%) (19091/20608)
Epoch: 101 | Batch_idx: 170 |  Loss: (0.2169) |  Loss2: (0.0000) | Acc: (92.00%) (20276/21888)
Epoch: 101 | Batch_idx: 180 |  Loss: (0.2172) |  Loss2: (0.0000) | Acc: (92.00%) (21452/23168)
Epoch: 101 | Batch_idx: 190 |  Loss: (0.2180) |  Loss2: (0.0000) | Acc: (92.00%) (22631/24448)
Epoch: 101 | Batch_idx: 200 |  Loss: (0.2174) |  Loss2: (0.0000) | Acc: (92.00%) (23824/25728)
Epoch: 101 | Batch_idx: 210 |  Loss: (0.2170) |  Loss2: (0.0000) | Acc: (92.00%) (25007/27008)
Epoch: 101 | Batch_idx: 220 |  Loss: (0.2169) |  Loss2: (0.0000) | Acc: (92.00%) (26191/28288)
Epoch: 101 | Batch_idx: 230 |  Loss: (0.2163) |  Loss2: (0.0000) | Acc: (92.00%) (27382/29568)
Epoch: 101 | Batch_idx: 240 |  Loss: (0.2166) |  Loss2: (0.0000) | Acc: (92.00%) (28562/30848)
Epoch: 101 | Batch_idx: 250 |  Loss: (0.2175) |  Loss2: (0.0000) | Acc: (92.00%) (29736/32128)
Epoch: 101 | Batch_idx: 260 |  Loss: (0.2167) |  Loss2: (0.0000) | Acc: (92.00%) (30924/33408)
Epoch: 101 | Batch_idx: 270 |  Loss: (0.2170) |  Loss2: (0.0000) | Acc: (92.00%) (32109/34688)
Epoch: 101 | Batch_idx: 280 |  Loss: (0.2158) |  Loss2: (0.0000) | Acc: (92.00%) (33308/35968)
Epoch: 101 | Batch_idx: 290 |  Loss: (0.2170) |  Loss2: (0.0000) | Acc: (92.00%) (34477/37248)
Epoch: 101 | Batch_idx: 300 |  Loss: (0.2171) |  Loss2: (0.0000) | Acc: (92.00%) (35660/38528)
Epoch: 101 | Batch_idx: 310 |  Loss: (0.2173) |  Loss2: (0.0000) | Acc: (92.00%) (36840/39808)
Epoch: 101 | Batch_idx: 320 |  Loss: (0.2167) |  Loss2: (0.0000) | Acc: (92.00%) (38038/41088)
Epoch: 101 | Batch_idx: 330 |  Loss: (0.2163) |  Loss2: (0.0000) | Acc: (92.00%) (39231/42368)
Epoch: 101 | Batch_idx: 340 |  Loss: (0.2168) |  Loss2: (0.0000) | Acc: (92.00%) (40406/43648)
Epoch: 101 | Batch_idx: 350 |  Loss: (0.2175) |  Loss2: (0.0000) | Acc: (92.00%) (41572/44928)
Epoch: 101 | Batch_idx: 360 |  Loss: (0.2174) |  Loss2: (0.0000) | Acc: (92.00%) (42754/46208)
Epoch: 101 | Batch_idx: 370 |  Loss: (0.2168) |  Loss2: (0.0000) | Acc: (92.00%) (43945/47488)
Epoch: 101 | Batch_idx: 380 |  Loss: (0.2169) |  Loss2: (0.0000) | Acc: (92.00%) (45129/48768)
Epoch: 101 | Batch_idx: 390 |  Loss: (0.2159) |  Loss2: (0.0000) | Acc: (92.00%) (46281/50000)
# TEST : Loss: (0.4187) | Acc: (86.00%) (8649/10000)
percent tensor([0.5005, 0.5021, 0.5049, 0.4971, 0.5056, 0.5025, 0.5032, 0.4994, 0.5010,
        0.5020, 0.5032, 0.5040, 0.4998, 0.4996, 0.5026, 0.4996],
       device='cuda:0') torch.Size([16])
percent tensor([0.4999, 0.4780, 0.4989, 0.5016, 0.4943, 0.5121, 0.4804, 0.4863, 0.4973,
        0.4801, 0.4965, 0.4898, 0.4796, 0.4956, 0.4957, 0.4993],
       device='cuda:0') torch.Size([16])
percent tensor([0.6249, 0.6266, 0.5765, 0.5648, 0.5914, 0.6101, 0.6342, 0.5949, 0.5836,
        0.6015, 0.6045, 0.5798, 0.6424, 0.5786, 0.6527, 0.6082],
       device='cuda:0') torch.Size([16])
percent tensor([0.6017, 0.6113, 0.6015, 0.6279, 0.6125, 0.6889, 0.6024, 0.6043, 0.6107,
        0.5820, 0.6033, 0.6291, 0.6007, 0.6135, 0.6499, 0.6324],
       device='cuda:0') torch.Size([16])
percent tensor([0.5517, 0.5815, 0.5241, 0.5311, 0.5567, 0.5357, 0.5672, 0.4984, 0.5957,
        0.5870, 0.6063, 0.5095, 0.5584, 0.6728, 0.4753, 0.6004],
       device='cuda:0') torch.Size([16])
percent tensor([0.5835, 0.5726, 0.6772, 0.6877, 0.7190, 0.6682, 0.6401, 0.6480, 0.6284,
        0.6122, 0.6059, 0.6561, 0.5839, 0.6375, 0.6043, 0.6321],
       device='cuda:0') torch.Size([16])
percent tensor([0.5925, 0.6395, 0.6659, 0.6281, 0.6775, 0.5299, 0.6105, 0.5373, 0.6574,
        0.6628, 0.6987, 0.6221, 0.6360, 0.6423, 0.5517, 0.5198],
       device='cuda:0') torch.Size([16])
percent tensor([0.9992, 0.9991, 0.9992, 0.9993, 0.9992, 0.9980, 0.9988, 0.9986, 0.9994,
        0.9996, 0.9999, 0.9991, 0.9994, 0.9983, 0.9976, 0.9982],
       device='cuda:0') torch.Size([16])
Epoch: 102 | Batch_idx: 0 |  Loss: (0.1869) |  Loss2: (0.0000) | Acc: (94.00%) (121/128)
Epoch: 102 | Batch_idx: 10 |  Loss: (0.2186) |  Loss2: (0.0000) | Acc: (92.00%) (1298/1408)
Epoch: 102 | Batch_idx: 20 |  Loss: (0.2170) |  Loss2: (0.0000) | Acc: (92.00%) (2476/2688)
Epoch: 102 | Batch_idx: 30 |  Loss: (0.2092) |  Loss2: (0.0000) | Acc: (92.00%) (3671/3968)
Epoch: 102 | Batch_idx: 40 |  Loss: (0.2023) |  Loss2: (0.0000) | Acc: (92.00%) (4869/5248)
Epoch: 102 | Batch_idx: 50 |  Loss: (0.2013) |  Loss2: (0.0000) | Acc: (92.00%) (6057/6528)
Epoch: 102 | Batch_idx: 60 |  Loss: (0.2012) |  Loss2: (0.0000) | Acc: (92.00%) (7248/7808)
Epoch: 102 | Batch_idx: 70 |  Loss: (0.2028) |  Loss2: (0.0000) | Acc: (92.00%) (8437/9088)
Epoch: 102 | Batch_idx: 80 |  Loss: (0.2017) |  Loss2: (0.0000) | Acc: (92.00%) (9636/10368)
Epoch: 102 | Batch_idx: 90 |  Loss: (0.2029) |  Loss2: (0.0000) | Acc: (92.00%) (10832/11648)
Epoch: 102 | Batch_idx: 100 |  Loss: (0.2025) |  Loss2: (0.0000) | Acc: (92.00%) (12023/12928)
Epoch: 102 | Batch_idx: 110 |  Loss: (0.2027) |  Loss2: (0.0000) | Acc: (93.00%) (13221/14208)
Epoch: 102 | Batch_idx: 120 |  Loss: (0.2009) |  Loss2: (0.0000) | Acc: (93.00%) (14419/15488)
Epoch: 102 | Batch_idx: 130 |  Loss: (0.2022) |  Loss2: (0.0000) | Acc: (93.00%) (15600/16768)
Epoch: 102 | Batch_idx: 140 |  Loss: (0.2015) |  Loss2: (0.0000) | Acc: (93.00%) (16794/18048)
Epoch: 102 | Batch_idx: 150 |  Loss: (0.2017) |  Loss2: (0.0000) | Acc: (93.00%) (17986/19328)
Epoch: 102 | Batch_idx: 160 |  Loss: (0.2037) |  Loss2: (0.0000) | Acc: (93.00%) (19167/20608)
Epoch: 102 | Batch_idx: 170 |  Loss: (0.2049) |  Loss2: (0.0000) | Acc: (92.00%) (20350/21888)
Epoch: 102 | Batch_idx: 180 |  Loss: (0.2059) |  Loss2: (0.0000) | Acc: (92.00%) (21520/23168)
Epoch: 102 | Batch_idx: 190 |  Loss: (0.2061) |  Loss2: (0.0000) | Acc: (92.00%) (22715/24448)
Epoch: 102 | Batch_idx: 200 |  Loss: (0.2059) |  Loss2: (0.0000) | Acc: (92.00%) (23911/25728)
Epoch: 102 | Batch_idx: 210 |  Loss: (0.2058) |  Loss2: (0.0000) | Acc: (92.00%) (25106/27008)
Epoch: 102 | Batch_idx: 220 |  Loss: (0.2058) |  Loss2: (0.0000) | Acc: (92.00%) (26290/28288)
Epoch: 102 | Batch_idx: 230 |  Loss: (0.2068) |  Loss2: (0.0000) | Acc: (92.00%) (27465/29568)
Epoch: 102 | Batch_idx: 240 |  Loss: (0.2068) |  Loss2: (0.0000) | Acc: (92.00%) (28649/30848)
Epoch: 102 | Batch_idx: 250 |  Loss: (0.2065) |  Loss2: (0.0000) | Acc: (92.00%) (29832/32128)
Epoch: 102 | Batch_idx: 260 |  Loss: (0.2063) |  Loss2: (0.0000) | Acc: (92.00%) (31023/33408)
Epoch: 102 | Batch_idx: 270 |  Loss: (0.2072) |  Loss2: (0.0000) | Acc: (92.00%) (32194/34688)
Epoch: 102 | Batch_idx: 280 |  Loss: (0.2077) |  Loss2: (0.0000) | Acc: (92.00%) (33379/35968)
Epoch: 102 | Batch_idx: 290 |  Loss: (0.2082) |  Loss2: (0.0000) | Acc: (92.00%) (34553/37248)
Epoch: 102 | Batch_idx: 300 |  Loss: (0.2089) |  Loss2: (0.0000) | Acc: (92.00%) (35737/38528)
Epoch: 102 | Batch_idx: 310 |  Loss: (0.2082) |  Loss2: (0.0000) | Acc: (92.00%) (36943/39808)
Epoch: 102 | Batch_idx: 320 |  Loss: (0.2085) |  Loss2: (0.0000) | Acc: (92.00%) (38122/41088)
Epoch: 102 | Batch_idx: 330 |  Loss: (0.2089) |  Loss2: (0.0000) | Acc: (92.00%) (39292/42368)
Epoch: 102 | Batch_idx: 340 |  Loss: (0.2099) |  Loss2: (0.0000) | Acc: (92.00%) (40464/43648)
Epoch: 102 | Batch_idx: 350 |  Loss: (0.2102) |  Loss2: (0.0000) | Acc: (92.00%) (41639/44928)
Epoch: 102 | Batch_idx: 360 |  Loss: (0.2106) |  Loss2: (0.0000) | Acc: (92.00%) (42828/46208)
Epoch: 102 | Batch_idx: 370 |  Loss: (0.2107) |  Loss2: (0.0000) | Acc: (92.00%) (44017/47488)
Epoch: 102 | Batch_idx: 380 |  Loss: (0.2107) |  Loss2: (0.0000) | Acc: (92.00%) (45201/48768)
Epoch: 102 | Batch_idx: 390 |  Loss: (0.2110) |  Loss2: (0.0000) | Acc: (92.00%) (46335/50000)
# TEST : Loss: (0.4539) | Acc: (85.00%) (8575/10000)
percent tensor([0.5003, 0.5016, 0.5049, 0.4974, 0.5055, 0.5030, 0.5027, 0.4993, 0.5007,
        0.5016, 0.5032, 0.5035, 0.4997, 0.4987, 0.5027, 0.4995],
       device='cuda:0') torch.Size([16])
percent tensor([0.5011, 0.4772, 0.4980, 0.5021, 0.4948, 0.5131, 0.4805, 0.4861, 0.4959,
        0.4806, 0.4963, 0.4885, 0.4805, 0.4919, 0.4960, 0.5011],
       device='cuda:0') torch.Size([16])
percent tensor([0.6260, 0.6359, 0.5858, 0.5718, 0.5971, 0.6136, 0.6352, 0.6011, 0.5858,
        0.6068, 0.6056, 0.5864, 0.6426, 0.5803, 0.6634, 0.6094],
       device='cuda:0') torch.Size([16])
percent tensor([0.6046, 0.6076, 0.5954, 0.6300, 0.6127, 0.7047, 0.5976, 0.5928, 0.6064,
        0.5806, 0.5969, 0.6117, 0.5941, 0.6119, 0.6507, 0.6421],
       device='cuda:0') torch.Size([16])
percent tensor([0.5686, 0.5705, 0.5492, 0.5338, 0.5671, 0.5350, 0.5779, 0.5090, 0.5956,
        0.5942, 0.6092, 0.5177, 0.5699, 0.6549, 0.4748, 0.6035],
       device='cuda:0') torch.Size([16])
percent tensor([0.5968, 0.5657, 0.7010, 0.7032, 0.7341, 0.6854, 0.6428, 0.6610, 0.6201,
        0.6192, 0.5998, 0.6565, 0.5855, 0.6269, 0.6095, 0.6388],
       device='cuda:0') torch.Size([16])
percent tensor([0.5654, 0.6522, 0.6662, 0.6320, 0.6658, 0.5102, 0.5868, 0.5421, 0.6583,
        0.6515, 0.6978, 0.6543, 0.6356, 0.6665, 0.5552, 0.5133],
       device='cuda:0') torch.Size([16])
percent tensor([0.9992, 0.9995, 0.9992, 0.9992, 0.9983, 0.9989, 0.9992, 0.9987, 0.9995,
        0.9994, 0.9998, 0.9997, 0.9993, 0.9991, 0.9980, 0.9985],
       device='cuda:0') torch.Size([16])
Epoch: 103 | Batch_idx: 0 |  Loss: (0.2172) |  Loss2: (0.0000) | Acc: (93.00%) (120/128)
Epoch: 103 | Batch_idx: 10 |  Loss: (0.2006) |  Loss2: (0.0000) | Acc: (92.00%) (1308/1408)
Epoch: 103 | Batch_idx: 20 |  Loss: (0.2098) |  Loss2: (0.0000) | Acc: (92.00%) (2494/2688)
Epoch: 103 | Batch_idx: 30 |  Loss: (0.2055) |  Loss2: (0.0000) | Acc: (92.00%) (3681/3968)
Epoch: 103 | Batch_idx: 40 |  Loss: (0.1999) |  Loss2: (0.0000) | Acc: (93.00%) (4888/5248)
Epoch: 103 | Batch_idx: 50 |  Loss: (0.2000) |  Loss2: (0.0000) | Acc: (93.00%) (6083/6528)
Epoch: 103 | Batch_idx: 60 |  Loss: (0.1964) |  Loss2: (0.0000) | Acc: (93.00%) (7273/7808)
Epoch: 103 | Batch_idx: 70 |  Loss: (0.1982) |  Loss2: (0.0000) | Acc: (93.00%) (8459/9088)
Epoch: 103 | Batch_idx: 80 |  Loss: (0.1959) |  Loss2: (0.0000) | Acc: (93.00%) (9664/10368)
Epoch: 103 | Batch_idx: 90 |  Loss: (0.1973) |  Loss2: (0.0000) | Acc: (93.00%) (10856/11648)
Epoch: 103 | Batch_idx: 100 |  Loss: (0.1981) |  Loss2: (0.0000) | Acc: (93.00%) (12037/12928)
Epoch: 103 | Batch_idx: 110 |  Loss: (0.1987) |  Loss2: (0.0000) | Acc: (93.00%) (13227/14208)
Epoch: 103 | Batch_idx: 120 |  Loss: (0.2018) |  Loss2: (0.0000) | Acc: (92.00%) (14399/15488)
Epoch: 103 | Batch_idx: 130 |  Loss: (0.2014) |  Loss2: (0.0000) | Acc: (93.00%) (15596/16768)
Epoch: 103 | Batch_idx: 140 |  Loss: (0.2024) |  Loss2: (0.0000) | Acc: (92.00%) (16776/18048)
Epoch: 103 | Batch_idx: 150 |  Loss: (0.2031) |  Loss2: (0.0000) | Acc: (92.00%) (17958/19328)
Epoch: 103 | Batch_idx: 160 |  Loss: (0.2042) |  Loss2: (0.0000) | Acc: (92.00%) (19145/20608)
Epoch: 103 | Batch_idx: 170 |  Loss: (0.2042) |  Loss2: (0.0000) | Acc: (92.00%) (20339/21888)
Epoch: 103 | Batch_idx: 180 |  Loss: (0.2028) |  Loss2: (0.0000) | Acc: (92.00%) (21539/23168)
Epoch: 103 | Batch_idx: 190 |  Loss: (0.2051) |  Loss2: (0.0000) | Acc: (92.00%) (22707/24448)
Epoch: 103 | Batch_idx: 200 |  Loss: (0.2056) |  Loss2: (0.0000) | Acc: (92.00%) (23898/25728)
Epoch: 103 | Batch_idx: 210 |  Loss: (0.2067) |  Loss2: (0.0000) | Acc: (92.00%) (25079/27008)
Epoch: 103 | Batch_idx: 220 |  Loss: (0.2074) |  Loss2: (0.0000) | Acc: (92.00%) (26256/28288)
Epoch: 103 | Batch_idx: 230 |  Loss: (0.2073) |  Loss2: (0.0000) | Acc: (92.00%) (27465/29568)
Epoch: 103 | Batch_idx: 240 |  Loss: (0.2078) |  Loss2: (0.0000) | Acc: (92.00%) (28655/30848)
Epoch: 103 | Batch_idx: 250 |  Loss: (0.2088) |  Loss2: (0.0000) | Acc: (92.00%) (29834/32128)
Epoch: 103 | Batch_idx: 260 |  Loss: (0.2093) |  Loss2: (0.0000) | Acc: (92.00%) (31006/33408)
Epoch: 103 | Batch_idx: 270 |  Loss: (0.2105) |  Loss2: (0.0000) | Acc: (92.00%) (32171/34688)
Epoch: 103 | Batch_idx: 280 |  Loss: (0.2103) |  Loss2: (0.0000) | Acc: (92.00%) (33360/35968)
Epoch: 103 | Batch_idx: 290 |  Loss: (0.2113) |  Loss2: (0.0000) | Acc: (92.00%) (34519/37248)
Epoch: 103 | Batch_idx: 300 |  Loss: (0.2110) |  Loss2: (0.0000) | Acc: (92.00%) (35711/38528)
Epoch: 103 | Batch_idx: 310 |  Loss: (0.2107) |  Loss2: (0.0000) | Acc: (92.00%) (36901/39808)
Epoch: 103 | Batch_idx: 320 |  Loss: (0.2114) |  Loss2: (0.0000) | Acc: (92.00%) (38070/41088)
Epoch: 103 | Batch_idx: 330 |  Loss: (0.2102) |  Loss2: (0.0000) | Acc: (92.00%) (39280/42368)
Epoch: 103 | Batch_idx: 340 |  Loss: (0.2105) |  Loss2: (0.0000) | Acc: (92.00%) (40460/43648)
Epoch: 103 | Batch_idx: 350 |  Loss: (0.2105) |  Loss2: (0.0000) | Acc: (92.00%) (41641/44928)
Epoch: 103 | Batch_idx: 360 |  Loss: (0.2109) |  Loss2: (0.0000) | Acc: (92.00%) (42821/46208)
Epoch: 103 | Batch_idx: 370 |  Loss: (0.2104) |  Loss2: (0.0000) | Acc: (92.00%) (44015/47488)
Epoch: 103 | Batch_idx: 380 |  Loss: (0.2102) |  Loss2: (0.0000) | Acc: (92.00%) (45206/48768)
Epoch: 103 | Batch_idx: 390 |  Loss: (0.2098) |  Loss2: (0.0000) | Acc: (92.00%) (46353/50000)
# TEST : Loss: (0.4103) | Acc: (87.00%) (8730/10000)
percent tensor([0.5008, 0.5008, 0.5063, 0.4974, 0.5070, 0.5033, 0.5030, 0.4997, 0.5007,
        0.5017, 0.5030, 0.5046, 0.4998, 0.4974, 0.5024, 0.4994],
       device='cuda:0') torch.Size([16])
percent tensor([0.4998, 0.4818, 0.4905, 0.5010, 0.4892, 0.5127, 0.4812, 0.4855, 0.4982,
        0.4817, 0.4991, 0.4838, 0.4805, 0.5003, 0.4987, 0.5029],
       device='cuda:0') torch.Size([16])
percent tensor([0.6197, 0.6150, 0.5772, 0.5622, 0.5885, 0.6046, 0.6257, 0.5911, 0.5730,
        0.5936, 0.5893, 0.5783, 0.6334, 0.5706, 0.6457, 0.5993],
       device='cuda:0') torch.Size([16])
percent tensor([0.6010, 0.6079, 0.6026, 0.6262, 0.6105, 0.6963, 0.6008, 0.5984, 0.6080,
        0.5857, 0.6004, 0.6242, 0.5985, 0.6104, 0.6463, 0.6390],
       device='cuda:0') torch.Size([16])
percent tensor([0.5709, 0.5931, 0.5407, 0.5401, 0.5700, 0.5440, 0.5788, 0.5202, 0.6129,
        0.6066, 0.6296, 0.5161, 0.5864, 0.6745, 0.4959, 0.6072],
       device='cuda:0') torch.Size([16])
percent tensor([0.5948, 0.5950, 0.6901, 0.6888, 0.7260, 0.6717, 0.6573, 0.6616, 0.6429,
        0.6403, 0.6298, 0.6638, 0.5992, 0.6673, 0.6125, 0.6412],
       device='cuda:0') torch.Size([16])
percent tensor([0.5867, 0.6524, 0.6863, 0.6241, 0.6827, 0.5145, 0.6132, 0.5577, 0.6617,
        0.6708, 0.7106, 0.6510, 0.6343, 0.6516, 0.5620, 0.5114],
       device='cuda:0') torch.Size([16])
percent tensor([0.9992, 0.9992, 0.9996, 0.9992, 0.9993, 0.9989, 0.9988, 0.9988, 0.9995,
        0.9995, 0.9999, 0.9996, 0.9993, 0.9988, 0.9980, 0.9991],
       device='cuda:0') torch.Size([16])
False Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=128, out_features=16, bias=False)
True Linear(in_features=16, out_features=2, bias=False)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=128, out_features=16, bias=False)
True Linear(in_features=16, out_features=2, bias=False)
False Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=256, out_features=32, bias=False)
True Linear(in_features=32, out_features=2, bias=False)
False Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=256, out_features=32, bias=False)
True Linear(in_features=32, out_features=2, bias=False)
False Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=512, out_features=64, bias=False)
True Linear(in_features=64, out_features=2, bias=False)
False Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=512, out_features=64, bias=False)
True Linear(in_features=64, out_features=2, bias=False)
False Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1024, out_features=128, bias=False)
True Linear(in_features=128, out_features=2, bias=False)
False Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1024, out_features=128, bias=False)
True Linear(in_features=128, out_features=2, bias=False)
False Linear(in_features=512, out_features=10, bias=True)
Epoch: 104 | Batch_idx: 0 |  Loss: (0.1235) |  Loss2: (0.0000) | Acc: (95.00%) (122/128)
Epoch: 104 | Batch_idx: 10 |  Loss: (0.2126) |  Loss2: (0.0000) | Acc: (92.00%) (1300/1408)
Epoch: 104 | Batch_idx: 20 |  Loss: (0.2078) |  Loss2: (0.0000) | Acc: (92.00%) (2495/2688)
Epoch: 104 | Batch_idx: 30 |  Loss: (0.2212) |  Loss2: (0.0000) | Acc: (92.00%) (3672/3968)
Epoch: 104 | Batch_idx: 40 |  Loss: (0.2245) |  Loss2: (0.0000) | Acc: (92.00%) (4854/5248)
Epoch: 104 | Batch_idx: 50 |  Loss: (0.2281) |  Loss2: (0.0000) | Acc: (92.00%) (6032/6528)
Epoch: 104 | Batch_idx: 60 |  Loss: (0.2251) |  Loss2: (0.0000) | Acc: (92.00%) (7225/7808)
Epoch: 104 | Batch_idx: 70 |  Loss: (0.2247) |  Loss2: (0.0000) | Acc: (92.00%) (8399/9088)
Epoch: 104 | Batch_idx: 80 |  Loss: (0.2236) |  Loss2: (0.0000) | Acc: (92.00%) (9577/10368)
Epoch: 104 | Batch_idx: 90 |  Loss: (0.2256) |  Loss2: (0.0000) | Acc: (92.00%) (10750/11648)
Epoch: 104 | Batch_idx: 100 |  Loss: (0.2268) |  Loss2: (0.0000) | Acc: (92.00%) (11923/12928)
Epoch: 104 | Batch_idx: 110 |  Loss: (0.2283) |  Loss2: (0.0000) | Acc: (92.00%) (13096/14208)
Epoch: 104 | Batch_idx: 120 |  Loss: (0.2264) |  Loss2: (0.0000) | Acc: (92.00%) (14292/15488)
Epoch: 104 | Batch_idx: 130 |  Loss: (0.2292) |  Loss2: (0.0000) | Acc: (92.00%) (15454/16768)
Epoch: 104 | Batch_idx: 140 |  Loss: (0.2304) |  Loss2: (0.0000) | Acc: (92.00%) (16621/18048)
Epoch: 104 | Batch_idx: 150 |  Loss: (0.2319) |  Loss2: (0.0000) | Acc: (92.00%) (17792/19328)
Epoch: 104 | Batch_idx: 160 |  Loss: (0.2316) |  Loss2: (0.0000) | Acc: (92.00%) (18973/20608)
Epoch: 104 | Batch_idx: 170 |  Loss: (0.2310) |  Loss2: (0.0000) | Acc: (92.00%) (20159/21888)
Epoch: 104 | Batch_idx: 180 |  Loss: (0.2308) |  Loss2: (0.0000) | Acc: (92.00%) (21335/23168)
Epoch: 104 | Batch_idx: 190 |  Loss: (0.2309) |  Loss2: (0.0000) | Acc: (92.00%) (22516/24448)
Epoch: 104 | Batch_idx: 200 |  Loss: (0.2300) |  Loss2: (0.0000) | Acc: (92.00%) (23701/25728)
Epoch: 104 | Batch_idx: 210 |  Loss: (0.2301) |  Loss2: (0.0000) | Acc: (92.00%) (24866/27008)
Epoch: 104 | Batch_idx: 220 |  Loss: (0.2292) |  Loss2: (0.0000) | Acc: (92.00%) (26047/28288)
Epoch: 104 | Batch_idx: 230 |  Loss: (0.2295) |  Loss2: (0.0000) | Acc: (92.00%) (27229/29568)
Epoch: 104 | Batch_idx: 240 |  Loss: (0.2290) |  Loss2: (0.0000) | Acc: (92.00%) (28408/30848)
Epoch: 104 | Batch_idx: 250 |  Loss: (0.2291) |  Loss2: (0.0000) | Acc: (92.00%) (29576/32128)
Epoch: 104 | Batch_idx: 260 |  Loss: (0.2289) |  Loss2: (0.0000) | Acc: (92.00%) (30758/33408)
Epoch: 104 | Batch_idx: 270 |  Loss: (0.2305) |  Loss2: (0.0000) | Acc: (92.00%) (31924/34688)
Epoch: 104 | Batch_idx: 280 |  Loss: (0.2304) |  Loss2: (0.0000) | Acc: (92.00%) (33096/35968)
Epoch: 104 | Batch_idx: 290 |  Loss: (0.2294) |  Loss2: (0.0000) | Acc: (92.00%) (34286/37248)
Epoch: 104 | Batch_idx: 300 |  Loss: (0.2276) |  Loss2: (0.0000) | Acc: (92.00%) (35493/38528)
Epoch: 104 | Batch_idx: 310 |  Loss: (0.2273) |  Loss2: (0.0000) | Acc: (92.00%) (36678/39808)
Epoch: 104 | Batch_idx: 320 |  Loss: (0.2271) |  Loss2: (0.0000) | Acc: (92.00%) (37861/41088)
Epoch: 104 | Batch_idx: 330 |  Loss: (0.2260) |  Loss2: (0.0000) | Acc: (92.00%) (39061/42368)
Epoch: 104 | Batch_idx: 340 |  Loss: (0.2258) |  Loss2: (0.0000) | Acc: (92.00%) (40238/43648)
Epoch: 104 | Batch_idx: 350 |  Loss: (0.2261) |  Loss2: (0.0000) | Acc: (92.00%) (41409/44928)
Epoch: 104 | Batch_idx: 360 |  Loss: (0.2256) |  Loss2: (0.0000) | Acc: (92.00%) (42601/46208)
Epoch: 104 | Batch_idx: 370 |  Loss: (0.2248) |  Loss2: (0.0000) | Acc: (92.00%) (43790/47488)
Epoch: 104 | Batch_idx: 380 |  Loss: (0.2248) |  Loss2: (0.0000) | Acc: (92.00%) (44969/48768)
Epoch: 104 | Batch_idx: 390 |  Loss: (0.2251) |  Loss2: (0.0000) | Acc: (92.00%) (46092/50000)
# TEST : Loss: (0.4084) | Acc: (87.00%) (8704/10000)
percent tensor([0.4997, 0.4980, 0.5069, 0.4966, 0.5073, 0.5026, 0.5011, 0.4984, 0.4990,
        0.5003, 0.5009, 0.5047, 0.4984, 0.4938, 0.5004, 0.4977],
       device='cuda:0') torch.Size([16])
percent tensor([0.4875, 0.4684, 0.4749, 0.4903, 0.4757, 0.5098, 0.4651, 0.4704, 0.4854,
        0.4697, 0.4862, 0.4680, 0.4689, 0.4846, 0.4858, 0.4928],
       device='cuda:0') torch.Size([16])
percent tensor([0.6317, 0.6182, 0.5692, 0.5536, 0.5791, 0.6167, 0.6284, 0.5789, 0.5686,
        0.5960, 0.5937, 0.5731, 0.6420, 0.5732, 0.6502, 0.6084],
       device='cuda:0') torch.Size([16])
percent tensor([0.6120, 0.6189, 0.6102, 0.6353, 0.6226, 0.7106, 0.6102, 0.6029, 0.6152,
        0.5981, 0.6138, 0.6366, 0.6105, 0.6187, 0.6613, 0.6500],
       device='cuda:0') torch.Size([16])
percent tensor([0.5658, 0.5878, 0.5423, 0.5419, 0.5794, 0.5663, 0.5804, 0.5257, 0.6022,
        0.5954, 0.6232, 0.4997, 0.5694, 0.6771, 0.4927, 0.6160],
       device='cuda:0') torch.Size([16])
percent tensor([0.5849, 0.5884, 0.6728, 0.6693, 0.7087, 0.6620, 0.6463, 0.6465, 0.6219,
        0.6264, 0.6170, 0.6511, 0.5952, 0.6448, 0.6039, 0.6272],
       device='cuda:0') torch.Size([16])
percent tensor([0.6007, 0.6756, 0.6985, 0.6092, 0.6729, 0.5020, 0.6181, 0.5429, 0.6963,
        0.6909, 0.7405, 0.6716, 0.6627, 0.6692, 0.5585, 0.4987],
       device='cuda:0') torch.Size([16])
percent tensor([0.9992, 0.9988, 0.9996, 0.9990, 0.9991, 0.9993, 0.9987, 0.9987, 0.9996,
        0.9994, 0.9999, 0.9997, 0.9992, 0.9987, 0.9981, 0.9991],
       device='cuda:0') torch.Size([16])
Epoch: 105 | Batch_idx: 0 |  Loss: (0.1575) |  Loss2: (0.0000) | Acc: (94.00%) (121/128)
Epoch: 105 | Batch_idx: 10 |  Loss: (0.2211) |  Loss2: (0.0000) | Acc: (92.00%) (1300/1408)
Epoch: 105 | Batch_idx: 20 |  Loss: (0.2248) |  Loss2: (0.0000) | Acc: (92.00%) (2475/2688)
Epoch: 105 | Batch_idx: 30 |  Loss: (0.2184) |  Loss2: (0.0000) | Acc: (92.00%) (3673/3968)
Epoch: 105 | Batch_idx: 40 |  Loss: (0.2166) |  Loss2: (0.0000) | Acc: (92.00%) (4867/5248)
Epoch: 105 | Batch_idx: 50 |  Loss: (0.2180) |  Loss2: (0.0000) | Acc: (92.00%) (6048/6528)
Epoch: 105 | Batch_idx: 60 |  Loss: (0.2224) |  Loss2: (0.0000) | Acc: (92.00%) (7221/7808)
Epoch: 105 | Batch_idx: 70 |  Loss: (0.2231) |  Loss2: (0.0000) | Acc: (92.00%) (8397/9088)
Epoch: 105 | Batch_idx: 80 |  Loss: (0.2208) |  Loss2: (0.0000) | Acc: (92.00%) (9595/10368)
Epoch: 105 | Batch_idx: 90 |  Loss: (0.2144) |  Loss2: (0.0000) | Acc: (92.00%) (10812/11648)
Epoch: 105 | Batch_idx: 100 |  Loss: (0.2135) |  Loss2: (0.0000) | Acc: (92.00%) (11997/12928)
Epoch: 105 | Batch_idx: 110 |  Loss: (0.2138) |  Loss2: (0.0000) | Acc: (92.00%) (13191/14208)
Epoch: 105 | Batch_idx: 120 |  Loss: (0.2137) |  Loss2: (0.0000) | Acc: (92.00%) (14377/15488)
Epoch: 105 | Batch_idx: 130 |  Loss: (0.2124) |  Loss2: (0.0000) | Acc: (92.00%) (15580/16768)
Epoch: 105 | Batch_idx: 140 |  Loss: (0.2121) |  Loss2: (0.0000) | Acc: (92.00%) (16771/18048)
Epoch: 105 | Batch_idx: 150 |  Loss: (0.2122) |  Loss2: (0.0000) | Acc: (92.00%) (17959/19328)
Epoch: 105 | Batch_idx: 160 |  Loss: (0.2119) |  Loss2: (0.0000) | Acc: (92.00%) (19145/20608)
Epoch: 105 | Batch_idx: 170 |  Loss: (0.2125) |  Loss2: (0.0000) | Acc: (92.00%) (20321/21888)
Epoch: 105 | Batch_idx: 180 |  Loss: (0.2116) |  Loss2: (0.0000) | Acc: (92.00%) (21515/23168)
Epoch: 105 | Batch_idx: 190 |  Loss: (0.2106) |  Loss2: (0.0000) | Acc: (92.00%) (22709/24448)
Epoch: 105 | Batch_idx: 200 |  Loss: (0.2109) |  Loss2: (0.0000) | Acc: (92.00%) (23890/25728)
Epoch: 105 | Batch_idx: 210 |  Loss: (0.2113) |  Loss2: (0.0000) | Acc: (92.00%) (25077/27008)
Epoch: 105 | Batch_idx: 220 |  Loss: (0.2108) |  Loss2: (0.0000) | Acc: (92.00%) (26272/28288)
Epoch: 105 | Batch_idx: 230 |  Loss: (0.2111) |  Loss2: (0.0000) | Acc: (92.00%) (27458/29568)
Epoch: 105 | Batch_idx: 240 |  Loss: (0.2097) |  Loss2: (0.0000) | Acc: (92.00%) (28651/30848)
Epoch: 105 | Batch_idx: 250 |  Loss: (0.2083) |  Loss2: (0.0000) | Acc: (92.00%) (29850/32128)
Epoch: 105 | Batch_idx: 260 |  Loss: (0.2076) |  Loss2: (0.0000) | Acc: (92.00%) (31049/33408)
Epoch: 105 | Batch_idx: 270 |  Loss: (0.2075) |  Loss2: (0.0000) | Acc: (92.00%) (32236/34688)
Epoch: 105 | Batch_idx: 280 |  Loss: (0.2068) |  Loss2: (0.0000) | Acc: (92.00%) (33428/35968)
Epoch: 105 | Batch_idx: 290 |  Loss: (0.2070) |  Loss2: (0.0000) | Acc: (92.00%) (34617/37248)
Epoch: 105 | Batch_idx: 300 |  Loss: (0.2068) |  Loss2: (0.0000) | Acc: (92.00%) (35809/38528)
Epoch: 105 | Batch_idx: 310 |  Loss: (0.2069) |  Loss2: (0.0000) | Acc: (92.00%) (36996/39808)
Epoch: 105 | Batch_idx: 320 |  Loss: (0.2071) |  Loss2: (0.0000) | Acc: (92.00%) (38178/41088)
Epoch: 105 | Batch_idx: 330 |  Loss: (0.2069) |  Loss2: (0.0000) | Acc: (92.00%) (39371/42368)
Epoch: 105 | Batch_idx: 340 |  Loss: (0.2070) |  Loss2: (0.0000) | Acc: (92.00%) (40551/43648)
Epoch: 105 | Batch_idx: 350 |  Loss: (0.2068) |  Loss2: (0.0000) | Acc: (92.00%) (41742/44928)
Epoch: 105 | Batch_idx: 360 |  Loss: (0.2059) |  Loss2: (0.0000) | Acc: (92.00%) (42953/46208)
Epoch: 105 | Batch_idx: 370 |  Loss: (0.2061) |  Loss2: (0.0000) | Acc: (92.00%) (44134/47488)
Epoch: 105 | Batch_idx: 380 |  Loss: (0.2068) |  Loss2: (0.0000) | Acc: (92.00%) (45304/48768)
Epoch: 105 | Batch_idx: 390 |  Loss: (0.2063) |  Loss2: (0.0000) | Acc: (92.00%) (46460/50000)
=> saving checkpoint 'drive/app/torch/save_Schedule/checkpoint_105.pth.tar'
# TEST : Loss: (0.3905) | Acc: (87.00%) (8766/10000)
percent tensor([0.5001, 0.4983, 0.5083, 0.4974, 0.5087, 0.5031, 0.5018, 0.4991, 0.4994,
        0.5011, 0.5013, 0.5060, 0.4988, 0.4933, 0.5010, 0.4981],
       device='cuda:0') torch.Size([16])
percent tensor([0.4933, 0.4740, 0.4831, 0.4973, 0.4830, 0.5103, 0.4716, 0.4777, 0.4909,
        0.4761, 0.4911, 0.4758, 0.4750, 0.4887, 0.4903, 0.4979],
       device='cuda:0') torch.Size([16])
percent tensor([0.6360, 0.6212, 0.5697, 0.5536, 0.5797, 0.6219, 0.6308, 0.5794, 0.5694,
        0.5967, 0.5958, 0.5724, 0.6445, 0.5743, 0.6538, 0.6126],
       device='cuda:0') torch.Size([16])
percent tensor([0.6067, 0.6156, 0.6063, 0.6338, 0.6193, 0.7056, 0.6059, 0.5977, 0.6129,
        0.5954, 0.6118, 0.6346, 0.6067, 0.6163, 0.6577, 0.6437],
       device='cuda:0') torch.Size([16])
percent tensor([0.5588, 0.5722, 0.5419, 0.5409, 0.5822, 0.5666, 0.5761, 0.5253, 0.5934,
        0.5841, 0.6116, 0.4911, 0.5541, 0.6723, 0.4844, 0.6105],
       device='cuda:0') torch.Size([16])
percent tensor([0.5882, 0.5897, 0.6756, 0.6701, 0.7096, 0.6636, 0.6465, 0.6457, 0.6246,
        0.6274, 0.6197, 0.6525, 0.6004, 0.6423, 0.6050, 0.6273],
       device='cuda:0') torch.Size([16])
percent tensor([0.6018, 0.6894, 0.6952, 0.5989, 0.6663, 0.4927, 0.6119, 0.5302, 0.7058,
        0.6981, 0.7542, 0.6718, 0.6744, 0.6769, 0.5540, 0.4887],
       device='cuda:0') torch.Size([16])
percent tensor([0.9993, 0.9989, 0.9996, 0.9991, 0.9991, 0.9993, 0.9988, 0.9987, 0.9996,
        0.9994, 0.9999, 0.9997, 0.9992, 0.9989, 0.9981, 0.9991],
       device='cuda:0') torch.Size([16])
Epoch: 106 | Batch_idx: 0 |  Loss: (0.1539) |  Loss2: (0.0000) | Acc: (95.00%) (122/128)
Epoch: 106 | Batch_idx: 10 |  Loss: (0.1746) |  Loss2: (0.0000) | Acc: (94.00%) (1332/1408)
Epoch: 106 | Batch_idx: 20 |  Loss: (0.1910) |  Loss2: (0.0000) | Acc: (93.00%) (2525/2688)
Epoch: 106 | Batch_idx: 30 |  Loss: (0.2000) |  Loss2: (0.0000) | Acc: (93.00%) (3711/3968)
Epoch: 106 | Batch_idx: 40 |  Loss: (0.2037) |  Loss2: (0.0000) | Acc: (93.00%) (4906/5248)
Epoch: 106 | Batch_idx: 50 |  Loss: (0.2033) |  Loss2: (0.0000) | Acc: (93.00%) (6100/6528)
Epoch: 106 | Batch_idx: 60 |  Loss: (0.2044) |  Loss2: (0.0000) | Acc: (93.00%) (7282/7808)
Epoch: 106 | Batch_idx: 70 |  Loss: (0.2014) |  Loss2: (0.0000) | Acc: (93.00%) (8487/9088)
Epoch: 106 | Batch_idx: 80 |  Loss: (0.2003) |  Loss2: (0.0000) | Acc: (93.00%) (9673/10368)
Epoch: 106 | Batch_idx: 90 |  Loss: (0.2023) |  Loss2: (0.0000) | Acc: (93.00%) (10851/11648)
Epoch: 106 | Batch_idx: 100 |  Loss: (0.2001) |  Loss2: (0.0000) | Acc: (93.00%) (12055/12928)
Epoch: 106 | Batch_idx: 110 |  Loss: (0.2028) |  Loss2: (0.0000) | Acc: (93.00%) (13235/14208)
Epoch: 106 | Batch_idx: 120 |  Loss: (0.2026) |  Loss2: (0.0000) | Acc: (93.00%) (14430/15488)
Epoch: 106 | Batch_idx: 130 |  Loss: (0.2025) |  Loss2: (0.0000) | Acc: (93.00%) (15617/16768)
Epoch: 106 | Batch_idx: 140 |  Loss: (0.2040) |  Loss2: (0.0000) | Acc: (93.00%) (16797/18048)
Epoch: 106 | Batch_idx: 150 |  Loss: (0.2038) |  Loss2: (0.0000) | Acc: (93.00%) (17987/19328)
Epoch: 106 | Batch_idx: 160 |  Loss: (0.2037) |  Loss2: (0.0000) | Acc: (93.00%) (19175/20608)
Epoch: 106 | Batch_idx: 170 |  Loss: (0.2042) |  Loss2: (0.0000) | Acc: (92.00%) (20352/21888)
Epoch: 106 | Batch_idx: 180 |  Loss: (0.2019) |  Loss2: (0.0000) | Acc: (93.00%) (21565/23168)
Epoch: 106 | Batch_idx: 190 |  Loss: (0.2014) |  Loss2: (0.0000) | Acc: (93.00%) (22756/24448)
Epoch: 106 | Batch_idx: 200 |  Loss: (0.2011) |  Loss2: (0.0000) | Acc: (93.00%) (23960/25728)
Epoch: 106 | Batch_idx: 210 |  Loss: (0.2011) |  Loss2: (0.0000) | Acc: (93.00%) (25154/27008)
Epoch: 106 | Batch_idx: 220 |  Loss: (0.2016) |  Loss2: (0.0000) | Acc: (93.00%) (26338/28288)
Epoch: 106 | Batch_idx: 230 |  Loss: (0.2004) |  Loss2: (0.0000) | Acc: (93.00%) (27547/29568)
Epoch: 106 | Batch_idx: 240 |  Loss: (0.2005) |  Loss2: (0.0000) | Acc: (93.00%) (28738/30848)
Epoch: 106 | Batch_idx: 250 |  Loss: (0.2003) |  Loss2: (0.0000) | Acc: (93.00%) (29928/32128)
Epoch: 106 | Batch_idx: 260 |  Loss: (0.2005) |  Loss2: (0.0000) | Acc: (93.00%) (31121/33408)
Epoch: 106 | Batch_idx: 270 |  Loss: (0.2017) |  Loss2: (0.0000) | Acc: (93.00%) (32300/34688)
Epoch: 106 | Batch_idx: 280 |  Loss: (0.2015) |  Loss2: (0.0000) | Acc: (93.00%) (33491/35968)
Epoch: 106 | Batch_idx: 290 |  Loss: (0.2011) |  Loss2: (0.0000) | Acc: (93.00%) (34680/37248)
Epoch: 106 | Batch_idx: 300 |  Loss: (0.2012) |  Loss2: (0.0000) | Acc: (93.00%) (35877/38528)
Epoch: 106 | Batch_idx: 310 |  Loss: (0.2016) |  Loss2: (0.0000) | Acc: (93.00%) (37061/39808)
Epoch: 106 | Batch_idx: 320 |  Loss: (0.2015) |  Loss2: (0.0000) | Acc: (93.00%) (38261/41088)
Epoch: 106 | Batch_idx: 330 |  Loss: (0.2012) |  Loss2: (0.0000) | Acc: (93.00%) (39463/42368)
Epoch: 106 | Batch_idx: 340 |  Loss: (0.2015) |  Loss2: (0.0000) | Acc: (93.00%) (40645/43648)
Epoch: 106 | Batch_idx: 350 |  Loss: (0.2008) |  Loss2: (0.0000) | Acc: (93.00%) (41846/44928)
Epoch: 106 | Batch_idx: 360 |  Loss: (0.2009) |  Loss2: (0.0000) | Acc: (93.00%) (43040/46208)
Epoch: 106 | Batch_idx: 370 |  Loss: (0.2012) |  Loss2: (0.0000) | Acc: (93.00%) (44232/47488)
Epoch: 106 | Batch_idx: 380 |  Loss: (0.1999) |  Loss2: (0.0000) | Acc: (93.00%) (45447/48768)
Epoch: 106 | Batch_idx: 390 |  Loss: (0.2000) |  Loss2: (0.0000) | Acc: (93.00%) (46605/50000)
# TEST : Loss: (0.3815) | Acc: (87.00%) (8784/10000)
percent tensor([0.5004, 0.4985, 0.5093, 0.4980, 0.5097, 0.5036, 0.5023, 0.4997, 0.4998,
        0.5016, 0.5016, 0.5069, 0.4991, 0.4931, 0.5014, 0.4984],
       device='cuda:0') torch.Size([16])
percent tensor([0.4947, 0.4753, 0.4864, 0.4990, 0.4856, 0.5103, 0.4736, 0.4803, 0.4929,
        0.4785, 0.4925, 0.4788, 0.4770, 0.4894, 0.4908, 0.4986],
       device='cuda:0') torch.Size([16])
percent tensor([0.6417, 0.6235, 0.5691, 0.5532, 0.5797, 0.6278, 0.6342, 0.5797, 0.5708,
        0.5974, 0.5984, 0.5720, 0.6478, 0.5777, 0.6580, 0.6176],
       device='cuda:0') torch.Size([16])
percent tensor([0.6136, 0.6240, 0.6130, 0.6411, 0.6257, 0.7097, 0.6142, 0.6043, 0.6219,
        0.6043, 0.6208, 0.6441, 0.6158, 0.6246, 0.6650, 0.6487],
       device='cuda:0') torch.Size([16])
percent tensor([0.5615, 0.5679, 0.5440, 0.5400, 0.5877, 0.5734, 0.5785, 0.5278, 0.5914,
        0.5806, 0.6095, 0.4835, 0.5499, 0.6732, 0.4816, 0.6160],
       device='cuda:0') torch.Size([16])
percent tensor([0.5891, 0.5892, 0.6747, 0.6683, 0.7069, 0.6628, 0.6453, 0.6428, 0.6257,
        0.6263, 0.6210, 0.6523, 0.6028, 0.6419, 0.6041, 0.6247],
       device='cuda:0') torch.Size([16])
percent tensor([0.6132, 0.7063, 0.7022, 0.6002, 0.6722, 0.4940, 0.6160, 0.5298, 0.7199,
        0.7131, 0.7679, 0.6771, 0.6883, 0.6892, 0.5583, 0.4881],
       device='cuda:0') torch.Size([16])
percent tensor([0.9993, 0.9989, 0.9996, 0.9991, 0.9991, 0.9992, 0.9988, 0.9988, 0.9996,
        0.9995, 0.9999, 0.9997, 0.9992, 0.9989, 0.9982, 0.9991],
       device='cuda:0') torch.Size([16])
Epoch: 107 | Batch_idx: 0 |  Loss: (0.2262) |  Loss2: (0.0000) | Acc: (89.00%) (115/128)
Epoch: 107 | Batch_idx: 10 |  Loss: (0.2006) |  Loss2: (0.0000) | Acc: (93.00%) (1315/1408)
Epoch: 107 | Batch_idx: 20 |  Loss: (0.1977) |  Loss2: (0.0000) | Acc: (93.00%) (2503/2688)
Epoch: 107 | Batch_idx: 30 |  Loss: (0.2080) |  Loss2: (0.0000) | Acc: (92.00%) (3682/3968)
Epoch: 107 | Batch_idx: 40 |  Loss: (0.2061) |  Loss2: (0.0000) | Acc: (92.00%) (4864/5248)
Epoch: 107 | Batch_idx: 50 |  Loss: (0.2041) |  Loss2: (0.0000) | Acc: (92.00%) (6054/6528)
Epoch: 107 | Batch_idx: 60 |  Loss: (0.2050) |  Loss2: (0.0000) | Acc: (92.00%) (7242/7808)
Epoch: 107 | Batch_idx: 70 |  Loss: (0.2026) |  Loss2: (0.0000) | Acc: (92.00%) (8430/9088)
Epoch: 107 | Batch_idx: 80 |  Loss: (0.2014) |  Loss2: (0.0000) | Acc: (92.00%) (9622/10368)
Epoch: 107 | Batch_idx: 90 |  Loss: (0.1995) |  Loss2: (0.0000) | Acc: (92.00%) (10820/11648)
Epoch: 107 | Batch_idx: 100 |  Loss: (0.1975) |  Loss2: (0.0000) | Acc: (92.00%) (12022/12928)
Epoch: 107 | Batch_idx: 110 |  Loss: (0.1990) |  Loss2: (0.0000) | Acc: (92.00%) (13207/14208)
Epoch: 107 | Batch_idx: 120 |  Loss: (0.2003) |  Loss2: (0.0000) | Acc: (92.00%) (14392/15488)
Epoch: 107 | Batch_idx: 130 |  Loss: (0.1988) |  Loss2: (0.0000) | Acc: (93.00%) (15598/16768)
Epoch: 107 | Batch_idx: 140 |  Loss: (0.1991) |  Loss2: (0.0000) | Acc: (93.00%) (16785/18048)
Epoch: 107 | Batch_idx: 150 |  Loss: (0.1993) |  Loss2: (0.0000) | Acc: (92.00%) (17975/19328)
Epoch: 107 | Batch_idx: 160 |  Loss: (0.1983) |  Loss2: (0.0000) | Acc: (93.00%) (19177/20608)
Epoch: 107 | Batch_idx: 170 |  Loss: (0.1972) |  Loss2: (0.0000) | Acc: (93.00%) (20374/21888)
Epoch: 107 | Batch_idx: 180 |  Loss: (0.1960) |  Loss2: (0.0000) | Acc: (93.00%) (21572/23168)
Epoch: 107 | Batch_idx: 190 |  Loss: (0.1973) |  Loss2: (0.0000) | Acc: (93.00%) (22757/24448)
Epoch: 107 | Batch_idx: 200 |  Loss: (0.1964) |  Loss2: (0.0000) | Acc: (93.00%) (23951/25728)
Epoch: 107 | Batch_idx: 210 |  Loss: (0.1967) |  Loss2: (0.0000) | Acc: (93.00%) (25140/27008)
Epoch: 107 | Batch_idx: 220 |  Loss: (0.1958) |  Loss2: (0.0000) | Acc: (93.00%) (26349/28288)
Epoch: 107 | Batch_idx: 230 |  Loss: (0.1950) |  Loss2: (0.0000) | Acc: (93.00%) (27551/29568)
Epoch: 107 | Batch_idx: 240 |  Loss: (0.1959) |  Loss2: (0.0000) | Acc: (93.00%) (28732/30848)
Epoch: 107 | Batch_idx: 250 |  Loss: (0.1961) |  Loss2: (0.0000) | Acc: (93.00%) (29915/32128)
Epoch: 107 | Batch_idx: 260 |  Loss: (0.1960) |  Loss2: (0.0000) | Acc: (93.00%) (31103/33408)
Epoch: 107 | Batch_idx: 270 |  Loss: (0.1969) |  Loss2: (0.0000) | Acc: (93.00%) (32285/34688)
Epoch: 107 | Batch_idx: 280 |  Loss: (0.1973) |  Loss2: (0.0000) | Acc: (93.00%) (33472/35968)
Epoch: 107 | Batch_idx: 290 |  Loss: (0.1972) |  Loss2: (0.0000) | Acc: (93.00%) (34662/37248)
Epoch: 107 | Batch_idx: 300 |  Loss: (0.1966) |  Loss2: (0.0000) | Acc: (93.00%) (35859/38528)
Epoch: 107 | Batch_idx: 310 |  Loss: (0.1971) |  Loss2: (0.0000) | Acc: (93.00%) (37044/39808)
Epoch: 107 | Batch_idx: 320 |  Loss: (0.1972) |  Loss2: (0.0000) | Acc: (93.00%) (38237/41088)
Epoch: 107 | Batch_idx: 330 |  Loss: (0.1968) |  Loss2: (0.0000) | Acc: (93.00%) (39437/42368)
Epoch: 107 | Batch_idx: 340 |  Loss: (0.1965) |  Loss2: (0.0000) | Acc: (93.00%) (40638/43648)
Epoch: 107 | Batch_idx: 350 |  Loss: (0.1959) |  Loss2: (0.0000) | Acc: (93.00%) (41839/44928)
Epoch: 107 | Batch_idx: 360 |  Loss: (0.1959) |  Loss2: (0.0000) | Acc: (93.00%) (43036/46208)
Epoch: 107 | Batch_idx: 370 |  Loss: (0.1956) |  Loss2: (0.0000) | Acc: (93.00%) (44239/47488)
Epoch: 107 | Batch_idx: 380 |  Loss: (0.1956) |  Loss2: (0.0000) | Acc: (93.00%) (45433/48768)
Epoch: 107 | Batch_idx: 390 |  Loss: (0.1955) |  Loss2: (0.0000) | Acc: (93.00%) (46587/50000)
# TEST : Loss: (0.3783) | Acc: (87.00%) (8791/10000)
percent tensor([0.4997, 0.4976, 0.5094, 0.4977, 0.5096, 0.5032, 0.5016, 0.4992, 0.4990,
        0.5011, 0.5007, 0.5068, 0.4983, 0.4916, 0.5007, 0.4976],
       device='cuda:0') torch.Size([16])
percent tensor([0.4952, 0.4759, 0.4886, 0.5004, 0.4872, 0.5102, 0.4749, 0.4819, 0.4939,
        0.4802, 0.4929, 0.4810, 0.4785, 0.4897, 0.4908, 0.4991],
       device='cuda:0') torch.Size([16])
percent tensor([0.6420, 0.6245, 0.5688, 0.5529, 0.5803, 0.6278, 0.6349, 0.5801, 0.5716,
        0.5965, 0.5994, 0.5715, 0.6483, 0.5786, 0.6577, 0.6187],
       device='cuda:0') torch.Size([16])
percent tensor([0.6114, 0.6238, 0.6118, 0.6409, 0.6249, 0.7077, 0.6131, 0.6024, 0.6223,
        0.6047, 0.6212, 0.6449, 0.6155, 0.6249, 0.6633, 0.6464],
       device='cuda:0') torch.Size([16])
percent tensor([0.5641, 0.5672, 0.5490, 0.5428, 0.5944, 0.5777, 0.5831, 0.5329, 0.5927,
        0.5794, 0.6107, 0.4844, 0.5503, 0.6725, 0.4836, 0.6190],
       device='cuda:0') torch.Size([16])
percent tensor([0.5899, 0.5889, 0.6754, 0.6681, 0.7062, 0.6649, 0.6441, 0.6418, 0.6268,
        0.6265, 0.6229, 0.6536, 0.6061, 0.6403, 0.6035, 0.6256],
       device='cuda:0') torch.Size([16])
percent tensor([0.6188, 0.7143, 0.7095, 0.6035, 0.6751, 0.4972, 0.6139, 0.5282, 0.7296,
        0.7199, 0.7791, 0.6815, 0.6977, 0.6959, 0.5613, 0.4835],
       device='cuda:0') torch.Size([16])
percent tensor([0.9994, 0.9990, 0.9997, 0.9992, 0.9992, 0.9993, 0.9989, 0.9989, 0.9996,
        0.9995, 0.9999, 0.9997, 0.9993, 0.9990, 0.9983, 0.9992],
       device='cuda:0') torch.Size([16])
Epoch: 108 | Batch_idx: 0 |  Loss: (0.0922) |  Loss2: (0.0000) | Acc: (96.00%) (124/128)
Epoch: 108 | Batch_idx: 10 |  Loss: (0.1975) |  Loss2: (0.0000) | Acc: (93.00%) (1312/1408)
Epoch: 108 | Batch_idx: 20 |  Loss: (0.1894) |  Loss2: (0.0000) | Acc: (93.00%) (2517/2688)
Epoch: 108 | Batch_idx: 30 |  Loss: (0.1835) |  Loss2: (0.0000) | Acc: (93.00%) (3722/3968)
Epoch: 108 | Batch_idx: 40 |  Loss: (0.1886) |  Loss2: (0.0000) | Acc: (93.00%) (4912/5248)
Epoch: 108 | Batch_idx: 50 |  Loss: (0.1927) |  Loss2: (0.0000) | Acc: (93.00%) (6105/6528)
Epoch: 108 | Batch_idx: 60 |  Loss: (0.1937) |  Loss2: (0.0000) | Acc: (93.00%) (7297/7808)
Epoch: 108 | Batch_idx: 70 |  Loss: (0.1970) |  Loss2: (0.0000) | Acc: (93.00%) (8472/9088)
Epoch: 108 | Batch_idx: 80 |  Loss: (0.1944) |  Loss2: (0.0000) | Acc: (93.00%) (9684/10368)
Epoch: 108 | Batch_idx: 90 |  Loss: (0.1931) |  Loss2: (0.0000) | Acc: (93.00%) (10893/11648)
Epoch: 108 | Batch_idx: 100 |  Loss: (0.1952) |  Loss2: (0.0000) | Acc: (93.00%) (12079/12928)
Epoch: 108 | Batch_idx: 110 |  Loss: (0.1953) |  Loss2: (0.0000) | Acc: (93.00%) (13279/14208)
Epoch: 108 | Batch_idx: 120 |  Loss: (0.1953) |  Loss2: (0.0000) | Acc: (93.00%) (14468/15488)
Epoch: 108 | Batch_idx: 130 |  Loss: (0.1942) |  Loss2: (0.0000) | Acc: (93.00%) (15676/16768)
Epoch: 108 | Batch_idx: 140 |  Loss: (0.1928) |  Loss2: (0.0000) | Acc: (93.00%) (16882/18048)
Epoch: 108 | Batch_idx: 150 |  Loss: (0.1924) |  Loss2: (0.0000) | Acc: (93.00%) (18080/19328)
Epoch: 108 | Batch_idx: 160 |  Loss: (0.1914) |  Loss2: (0.0000) | Acc: (93.00%) (19282/20608)
Epoch: 108 | Batch_idx: 170 |  Loss: (0.1907) |  Loss2: (0.0000) | Acc: (93.00%) (20488/21888)
Epoch: 108 | Batch_idx: 180 |  Loss: (0.1912) |  Loss2: (0.0000) | Acc: (93.00%) (21685/23168)
Epoch: 108 | Batch_idx: 190 |  Loss: (0.1928) |  Loss2: (0.0000) | Acc: (93.00%) (22862/24448)
Epoch: 108 | Batch_idx: 200 |  Loss: (0.1934) |  Loss2: (0.0000) | Acc: (93.00%) (24063/25728)
Epoch: 108 | Batch_idx: 210 |  Loss: (0.1938) |  Loss2: (0.0000) | Acc: (93.00%) (25255/27008)
Epoch: 108 | Batch_idx: 220 |  Loss: (0.1933) |  Loss2: (0.0000) | Acc: (93.00%) (26456/28288)
Epoch: 108 | Batch_idx: 230 |  Loss: (0.1937) |  Loss2: (0.0000) | Acc: (93.00%) (27653/29568)
Epoch: 108 | Batch_idx: 240 |  Loss: (0.1937) |  Loss2: (0.0000) | Acc: (93.00%) (28851/30848)
Epoch: 108 | Batch_idx: 250 |  Loss: (0.1931) |  Loss2: (0.0000) | Acc: (93.00%) (30063/32128)
Epoch: 108 | Batch_idx: 260 |  Loss: (0.1934) |  Loss2: (0.0000) | Acc: (93.00%) (31261/33408)
Epoch: 108 | Batch_idx: 270 |  Loss: (0.1940) |  Loss2: (0.0000) | Acc: (93.00%) (32447/34688)
Epoch: 108 | Batch_idx: 280 |  Loss: (0.1935) |  Loss2: (0.0000) | Acc: (93.00%) (33649/35968)
Epoch: 108 | Batch_idx: 290 |  Loss: (0.1937) |  Loss2: (0.0000) | Acc: (93.00%) (34846/37248)
Epoch: 108 | Batch_idx: 300 |  Loss: (0.1934) |  Loss2: (0.0000) | Acc: (93.00%) (36045/38528)
Epoch: 108 | Batch_idx: 310 |  Loss: (0.1927) |  Loss2: (0.0000) | Acc: (93.00%) (37260/39808)
Epoch: 108 | Batch_idx: 320 |  Loss: (0.1918) |  Loss2: (0.0000) | Acc: (93.00%) (38472/41088)
Epoch: 108 | Batch_idx: 330 |  Loss: (0.1917) |  Loss2: (0.0000) | Acc: (93.00%) (39677/42368)
Epoch: 108 | Batch_idx: 340 |  Loss: (0.1914) |  Loss2: (0.0000) | Acc: (93.00%) (40877/43648)
Epoch: 108 | Batch_idx: 350 |  Loss: (0.1914) |  Loss2: (0.0000) | Acc: (93.00%) (42074/44928)
Epoch: 108 | Batch_idx: 360 |  Loss: (0.1911) |  Loss2: (0.0000) | Acc: (93.00%) (43273/46208)
Epoch: 108 | Batch_idx: 370 |  Loss: (0.1913) |  Loss2: (0.0000) | Acc: (93.00%) (44467/47488)
Epoch: 108 | Batch_idx: 380 |  Loss: (0.1916) |  Loss2: (0.0000) | Acc: (93.00%) (45655/48768)
Epoch: 108 | Batch_idx: 390 |  Loss: (0.1908) |  Loss2: (0.0000) | Acc: (93.00%) (46820/50000)
# TEST : Loss: (0.3750) | Acc: (88.00%) (8804/10000)
percent tensor([0.5020, 0.5000, 0.5123, 0.5004, 0.5128, 0.5057, 0.5042, 0.5019, 0.5013,
        0.5037, 0.5031, 0.5098, 0.5007, 0.4926, 0.5033, 0.4999],
       device='cuda:0') torch.Size([16])
percent tensor([0.4953, 0.4764, 0.4894, 0.5009, 0.4878, 0.5102, 0.4754, 0.4827, 0.4943,
        0.4810, 0.4932, 0.4818, 0.4788, 0.4904, 0.4908, 0.4992],
       device='cuda:0') torch.Size([16])
percent tensor([0.6346, 0.6188, 0.5673, 0.5524, 0.5807, 0.6217, 0.6293, 0.5796, 0.5685,
        0.5908, 0.5939, 0.5695, 0.6407, 0.5728, 0.6510, 0.6129],
       device='cuda:0') torch.Size([16])
percent tensor([0.6106, 0.6239, 0.6121, 0.6421, 0.6254, 0.7078, 0.6132, 0.6024, 0.6248,
        0.6058, 0.6226, 0.6465, 0.6151, 0.6269, 0.6632, 0.6450],
       device='cuda:0') torch.Size([16])
percent tensor([0.5544, 0.5605, 0.5421, 0.5375, 0.5888, 0.5668, 0.5759, 0.5294, 0.5834,
        0.5722, 0.6045, 0.4809, 0.5408, 0.6656, 0.4774, 0.6097],
       device='cuda:0') torch.Size([16])
percent tensor([0.5912, 0.5897, 0.6798, 0.6733, 0.7111, 0.6664, 0.6469, 0.6460, 0.6323,
        0.6295, 0.6260, 0.6577, 0.6078, 0.6438, 0.6049, 0.6265],
       device='cuda:0') torch.Size([16])
percent tensor([0.6067, 0.7081, 0.7085, 0.6001, 0.6811, 0.4859, 0.6068, 0.5267, 0.7231,
        0.7161, 0.7750, 0.6776, 0.6892, 0.6889, 0.5530, 0.4761],
       device='cuda:0') torch.Size([16])
percent tensor([0.9994, 0.9990, 0.9997, 0.9992, 0.9993, 0.9993, 0.9990, 0.9990, 0.9996,
        0.9995, 0.9999, 0.9997, 0.9993, 0.9990, 0.9984, 0.9993],
       device='cuda:0') torch.Size([16])
Epoch: 109 | Batch_idx: 0 |  Loss: (0.1814) |  Loss2: (0.0000) | Acc: (94.00%) (121/128)
Epoch: 109 | Batch_idx: 10 |  Loss: (0.1728) |  Loss2: (0.0000) | Acc: (93.00%) (1323/1408)
Epoch: 109 | Batch_idx: 20 |  Loss: (0.1743) |  Loss2: (0.0000) | Acc: (93.00%) (2522/2688)
Epoch: 109 | Batch_idx: 30 |  Loss: (0.1796) |  Loss2: (0.0000) | Acc: (93.00%) (3713/3968)
Epoch: 109 | Batch_idx: 40 |  Loss: (0.1803) |  Loss2: (0.0000) | Acc: (93.00%) (4916/5248)
Epoch: 109 | Batch_idx: 50 |  Loss: (0.1756) |  Loss2: (0.0000) | Acc: (93.00%) (6132/6528)
Epoch: 109 | Batch_idx: 60 |  Loss: (0.1732) |  Loss2: (0.0000) | Acc: (94.00%) (7345/7808)
Epoch: 109 | Batch_idx: 70 |  Loss: (0.1728) |  Loss2: (0.0000) | Acc: (94.00%) (8544/9088)
Epoch: 109 | Batch_idx: 80 |  Loss: (0.1755) |  Loss2: (0.0000) | Acc: (93.00%) (9737/10368)
Epoch: 109 | Batch_idx: 90 |  Loss: (0.1756) |  Loss2: (0.0000) | Acc: (93.00%) (10937/11648)
Epoch: 109 | Batch_idx: 100 |  Loss: (0.1741) |  Loss2: (0.0000) | Acc: (93.00%) (12146/12928)
Epoch: 109 | Batch_idx: 110 |  Loss: (0.1778) |  Loss2: (0.0000) | Acc: (93.00%) (13337/14208)
Epoch: 109 | Batch_idx: 120 |  Loss: (0.1805) |  Loss2: (0.0000) | Acc: (93.00%) (14523/15488)
Epoch: 109 | Batch_idx: 130 |  Loss: (0.1805) |  Loss2: (0.0000) | Acc: (93.00%) (15724/16768)
Epoch: 109 | Batch_idx: 140 |  Loss: (0.1807) |  Loss2: (0.0000) | Acc: (93.00%) (16920/18048)
Epoch: 109 | Batch_idx: 150 |  Loss: (0.1806) |  Loss2: (0.0000) | Acc: (93.00%) (18123/19328)
Epoch: 109 | Batch_idx: 160 |  Loss: (0.1808) |  Loss2: (0.0000) | Acc: (93.00%) (19320/20608)
Epoch: 109 | Batch_idx: 170 |  Loss: (0.1833) |  Loss2: (0.0000) | Acc: (93.00%) (20500/21888)
Epoch: 109 | Batch_idx: 180 |  Loss: (0.1843) |  Loss2: (0.0000) | Acc: (93.00%) (21690/23168)
Epoch: 109 | Batch_idx: 190 |  Loss: (0.1844) |  Loss2: (0.0000) | Acc: (93.00%) (22888/24448)
Epoch: 109 | Batch_idx: 200 |  Loss: (0.1835) |  Loss2: (0.0000) | Acc: (93.00%) (24091/25728)
Epoch: 109 | Batch_idx: 210 |  Loss: (0.1831) |  Loss2: (0.0000) | Acc: (93.00%) (25293/27008)
Epoch: 109 | Batch_idx: 220 |  Loss: (0.1852) |  Loss2: (0.0000) | Acc: (93.00%) (26473/28288)
Epoch: 109 | Batch_idx: 230 |  Loss: (0.1864) |  Loss2: (0.0000) | Acc: (93.00%) (27660/29568)
Epoch: 109 | Batch_idx: 240 |  Loss: (0.1869) |  Loss2: (0.0000) | Acc: (93.00%) (28860/30848)
Epoch: 109 | Batch_idx: 250 |  Loss: (0.1861) |  Loss2: (0.0000) | Acc: (93.00%) (30068/32128)
Epoch: 109 | Batch_idx: 260 |  Loss: (0.1857) |  Loss2: (0.0000) | Acc: (93.00%) (31276/33408)
Epoch: 109 | Batch_idx: 270 |  Loss: (0.1856) |  Loss2: (0.0000) | Acc: (93.00%) (32479/34688)
Epoch: 109 | Batch_idx: 280 |  Loss: (0.1856) |  Loss2: (0.0000) | Acc: (93.00%) (33673/35968)
Epoch: 109 | Batch_idx: 290 |  Loss: (0.1849) |  Loss2: (0.0000) | Acc: (93.00%) (34887/37248)
Epoch: 109 | Batch_idx: 300 |  Loss: (0.1853) |  Loss2: (0.0000) | Acc: (93.00%) (36072/38528)
Epoch: 109 | Batch_idx: 310 |  Loss: (0.1859) |  Loss2: (0.0000) | Acc: (93.00%) (37259/39808)
Epoch: 109 | Batch_idx: 320 |  Loss: (0.1869) |  Loss2: (0.0000) | Acc: (93.00%) (38444/41088)
Epoch: 109 | Batch_idx: 330 |  Loss: (0.1865) |  Loss2: (0.0000) | Acc: (93.00%) (39649/42368)
Epoch: 109 | Batch_idx: 340 |  Loss: (0.1862) |  Loss2: (0.0000) | Acc: (93.00%) (40853/43648)
Epoch: 109 | Batch_idx: 350 |  Loss: (0.1866) |  Loss2: (0.0000) | Acc: (93.00%) (42054/44928)
Epoch: 109 | Batch_idx: 360 |  Loss: (0.1863) |  Loss2: (0.0000) | Acc: (93.00%) (43256/46208)
Epoch: 109 | Batch_idx: 370 |  Loss: (0.1866) |  Loss2: (0.0000) | Acc: (93.00%) (44450/47488)
Epoch: 109 | Batch_idx: 380 |  Loss: (0.1862) |  Loss2: (0.0000) | Acc: (93.00%) (45658/48768)
Epoch: 109 | Batch_idx: 390 |  Loss: (0.1864) |  Loss2: (0.0000) | Acc: (93.00%) (46808/50000)
# TEST : Loss: (0.3716) | Acc: (88.00%) (8819/10000)
percent tensor([0.5027, 0.5004, 0.5136, 0.5012, 0.5140, 0.5066, 0.5050, 0.5026, 0.5019,
        0.5043, 0.5038, 0.5108, 0.5013, 0.4928, 0.5041, 0.5006],
       device='cuda:0') torch.Size([16])
percent tensor([0.4958, 0.4772, 0.4902, 0.5016, 0.4884, 0.5102, 0.4762, 0.4836, 0.4944,
        0.4818, 0.4937, 0.4827, 0.4794, 0.4909, 0.4913, 0.4998],
       device='cuda:0') torch.Size([16])
percent tensor([0.6323, 0.6166, 0.5656, 0.5503, 0.5799, 0.6208, 0.6279, 0.5782, 0.5663,
        0.5875, 0.5922, 0.5676, 0.6384, 0.5695, 0.6494, 0.6117],
       device='cuda:0') torch.Size([16])
percent tensor([0.6159, 0.6309, 0.6160, 0.6470, 0.6307, 0.7141, 0.6193, 0.6063, 0.6303,
        0.6111, 0.6292, 0.6529, 0.6209, 0.6334, 0.6700, 0.6514],
       device='cuda:0') torch.Size([16])
percent tensor([0.5504, 0.5584, 0.5372, 0.5340, 0.5870, 0.5634, 0.5744, 0.5277, 0.5785,
        0.5676, 0.6019, 0.4763, 0.5372, 0.6634, 0.4727, 0.6084],
       device='cuda:0') torch.Size([16])
percent tensor([0.5839, 0.5820, 0.6757, 0.6680, 0.7061, 0.6609, 0.6397, 0.6394, 0.6262,
        0.6223, 0.6202, 0.6531, 0.6014, 0.6360, 0.5979, 0.6183],
       device='cuda:0') torch.Size([16])
percent tensor([0.6011, 0.7047, 0.7091, 0.6009, 0.6816, 0.4820, 0.5995, 0.5256, 0.7239,
        0.7147, 0.7770, 0.6743, 0.6877, 0.6854, 0.5471, 0.4686],
       device='cuda:0') torch.Size([16])
percent tensor([0.9995, 0.9991, 0.9997, 0.9993, 0.9994, 0.9993, 0.9990, 0.9991, 0.9997,
        0.9996, 0.9999, 0.9997, 0.9993, 0.9991, 0.9984, 0.9993],
       device='cuda:0') torch.Size([16])
Epoch: 110 | Batch_idx: 0 |  Loss: (0.1707) |  Loss2: (0.0000) | Acc: (93.00%) (120/128)
Epoch: 110 | Batch_idx: 10 |  Loss: (0.1807) |  Loss2: (0.0000) | Acc: (93.00%) (1323/1408)
Epoch: 110 | Batch_idx: 20 |  Loss: (0.1823) |  Loss2: (0.0000) | Acc: (93.00%) (2523/2688)
Epoch: 110 | Batch_idx: 30 |  Loss: (0.1826) |  Loss2: (0.0000) | Acc: (94.00%) (3731/3968)
Epoch: 110 | Batch_idx: 40 |  Loss: (0.1809) |  Loss2: (0.0000) | Acc: (94.00%) (4938/5248)
Epoch: 110 | Batch_idx: 50 |  Loss: (0.1836) |  Loss2: (0.0000) | Acc: (93.00%) (6130/6528)
Epoch: 110 | Batch_idx: 60 |  Loss: (0.1812) |  Loss2: (0.0000) | Acc: (94.00%) (7340/7808)
Epoch: 110 | Batch_idx: 70 |  Loss: (0.1822) |  Loss2: (0.0000) | Acc: (93.00%) (8540/9088)
Epoch: 110 | Batch_idx: 80 |  Loss: (0.1834) |  Loss2: (0.0000) | Acc: (93.00%) (9734/10368)
Epoch: 110 | Batch_idx: 90 |  Loss: (0.1853) |  Loss2: (0.0000) | Acc: (93.00%) (10917/11648)
Epoch: 110 | Batch_idx: 100 |  Loss: (0.1835) |  Loss2: (0.0000) | Acc: (93.00%) (12121/12928)
Epoch: 110 | Batch_idx: 110 |  Loss: (0.1833) |  Loss2: (0.0000) | Acc: (93.00%) (13319/14208)
Epoch: 110 | Batch_idx: 120 |  Loss: (0.1844) |  Loss2: (0.0000) | Acc: (93.00%) (14516/15488)
Epoch: 110 | Batch_idx: 130 |  Loss: (0.1850) |  Loss2: (0.0000) | Acc: (93.00%) (15706/16768)
Epoch: 110 | Batch_idx: 140 |  Loss: (0.1858) |  Loss2: (0.0000) | Acc: (93.00%) (16898/18048)
Epoch: 110 | Batch_idx: 150 |  Loss: (0.1864) |  Loss2: (0.0000) | Acc: (93.00%) (18092/19328)
Epoch: 110 | Batch_idx: 160 |  Loss: (0.1871) |  Loss2: (0.0000) | Acc: (93.00%) (19281/20608)
Epoch: 110 | Batch_idx: 170 |  Loss: (0.1865) |  Loss2: (0.0000) | Acc: (93.00%) (20485/21888)
Epoch: 110 | Batch_idx: 180 |  Loss: (0.1880) |  Loss2: (0.0000) | Acc: (93.00%) (21677/23168)
Epoch: 110 | Batch_idx: 190 |  Loss: (0.1879) |  Loss2: (0.0000) | Acc: (93.00%) (22870/24448)
Epoch: 110 | Batch_idx: 200 |  Loss: (0.1877) |  Loss2: (0.0000) | Acc: (93.00%) (24066/25728)
Epoch: 110 | Batch_idx: 210 |  Loss: (0.1878) |  Loss2: (0.0000) | Acc: (93.00%) (25262/27008)
Epoch: 110 | Batch_idx: 220 |  Loss: (0.1879) |  Loss2: (0.0000) | Acc: (93.00%) (26461/28288)
Epoch: 110 | Batch_idx: 230 |  Loss: (0.1877) |  Loss2: (0.0000) | Acc: (93.00%) (27654/29568)
Epoch: 110 | Batch_idx: 240 |  Loss: (0.1881) |  Loss2: (0.0000) | Acc: (93.00%) (28842/30848)
Epoch: 110 | Batch_idx: 250 |  Loss: (0.1876) |  Loss2: (0.0000) | Acc: (93.00%) (30043/32128)
Epoch: 110 | Batch_idx: 260 |  Loss: (0.1874) |  Loss2: (0.0000) | Acc: (93.00%) (31247/33408)
Epoch: 110 | Batch_idx: 270 |  Loss: (0.1878) |  Loss2: (0.0000) | Acc: (93.00%) (32442/34688)
Epoch: 110 | Batch_idx: 280 |  Loss: (0.1870) |  Loss2: (0.0000) | Acc: (93.00%) (33647/35968)
Epoch: 110 | Batch_idx: 290 |  Loss: (0.1871) |  Loss2: (0.0000) | Acc: (93.00%) (34838/37248)
Epoch: 110 | Batch_idx: 300 |  Loss: (0.1871) |  Loss2: (0.0000) | Acc: (93.00%) (36041/38528)
Epoch: 110 | Batch_idx: 310 |  Loss: (0.1858) |  Loss2: (0.0000) | Acc: (93.00%) (37259/39808)
Epoch: 110 | Batch_idx: 320 |  Loss: (0.1859) |  Loss2: (0.0000) | Acc: (93.00%) (38461/41088)
Epoch: 110 | Batch_idx: 330 |  Loss: (0.1869) |  Loss2: (0.0000) | Acc: (93.00%) (39652/42368)
Epoch: 110 | Batch_idx: 340 |  Loss: (0.1872) |  Loss2: (0.0000) | Acc: (93.00%) (40847/43648)
Epoch: 110 | Batch_idx: 350 |  Loss: (0.1870) |  Loss2: (0.0000) | Acc: (93.00%) (42046/44928)
Epoch: 110 | Batch_idx: 360 |  Loss: (0.1871) |  Loss2: (0.0000) | Acc: (93.00%) (43237/46208)
Epoch: 110 | Batch_idx: 370 |  Loss: (0.1872) |  Loss2: (0.0000) | Acc: (93.00%) (44429/47488)
Epoch: 110 | Batch_idx: 380 |  Loss: (0.1873) |  Loss2: (0.0000) | Acc: (93.00%) (45620/48768)
Epoch: 110 | Batch_idx: 390 |  Loss: (0.1877) |  Loss2: (0.0000) | Acc: (93.00%) (46762/50000)
=> saving checkpoint 'drive/app/torch/save_Schedule/checkpoint_110.pth.tar'
# TEST : Loss: (0.3715) | Acc: (88.00%) (8834/10000)
percent tensor([0.5012, 0.4987, 0.5124, 0.5000, 0.5127, 0.5052, 0.5033, 0.5011, 0.5003,
        0.5028, 0.5021, 0.5096, 0.4996, 0.4911, 0.5025, 0.4991],
       device='cuda:0') torch.Size([16])
percent tensor([0.4938, 0.4755, 0.4892, 0.5009, 0.4869, 0.5096, 0.4743, 0.4819, 0.4928,
        0.4805, 0.4919, 0.4816, 0.4779, 0.4891, 0.4890, 0.4977],
       device='cuda:0') torch.Size([16])
percent tensor([0.6304, 0.6158, 0.5630, 0.5477, 0.5782, 0.6180, 0.6269, 0.5762, 0.5658,
        0.5855, 0.5927, 0.5641, 0.6369, 0.5688, 0.6468, 0.6104],
       device='cuda:0') torch.Size([16])
percent tensor([0.6139, 0.6313, 0.6151, 0.6473, 0.6290, 0.7123, 0.6187, 0.6047, 0.6313,
        0.6124, 0.6300, 0.6536, 0.6208, 0.6343, 0.6685, 0.6493],
       device='cuda:0') torch.Size([16])
percent tensor([0.5476, 0.5597, 0.5357, 0.5310, 0.5848, 0.5633, 0.5725, 0.5227, 0.5755,
        0.5661, 0.6021, 0.4730, 0.5357, 0.6637, 0.4680, 0.6072],
       device='cuda:0') torch.Size([16])
percent tensor([0.5917, 0.5889, 0.6845, 0.6781, 0.7156, 0.6708, 0.6487, 0.6488, 0.6352,
        0.6315, 0.6295, 0.6623, 0.6106, 0.6444, 0.6065, 0.6274],
       device='cuda:0') torch.Size([16])
percent tensor([0.6010, 0.7049, 0.7123, 0.6017, 0.6843, 0.4824, 0.5949, 0.5239, 0.7272,
        0.7169, 0.7809, 0.6746, 0.6895, 0.6895, 0.5448, 0.4672],
       device='cuda:0') torch.Size([16])
percent tensor([0.9995, 0.9992, 0.9997, 0.9993, 0.9994, 0.9994, 0.9991, 0.9991, 0.9997,
        0.9996, 0.9999, 0.9997, 0.9994, 0.9993, 0.9985, 0.9994],
       device='cuda:0') torch.Size([16])
Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 3, 3, 3]) tensor(187.4898, device='cuda:0')
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(813.6107, device='cuda:0')
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(815.9016, device='cuda:0')
Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([128, 64, 3, 3]) tensor(1529.9434, device='cuda:0')
Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([128, 64, 1, 1]) tensor(490.2205, device='cuda:0')
Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([128, 128, 3, 3]) tensor(2268.5957, device='cuda:0')
Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([256, 128, 3, 3]) tensor(4278.2383, device='cuda:0')
Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([256, 128, 1, 1]) tensor(1386.9918, device='cuda:0')
Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([256, 256, 3, 3]) tensor(6145.0762, device='cuda:0')
Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([512, 256, 3, 3]) tensor(11828.7266, device='cuda:0')
Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([512, 256, 1, 1]) tensor(3925.7747, device='cuda:0')
Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([512, 512, 3, 3]) tensor(16581.2480, device='cuda:0')
Epoch: 111 | Batch_idx: 0 |  Loss: (0.2300) |  Loss2: (0.0000) | Acc: (93.00%) (120/128)
Epoch: 111 | Batch_idx: 10 |  Loss: (0.2022) |  Loss2: (0.0000) | Acc: (92.00%) (1307/1408)
Epoch: 111 | Batch_idx: 20 |  Loss: (0.1883) |  Loss2: (0.0000) | Acc: (93.00%) (2516/2688)
Epoch: 111 | Batch_idx: 30 |  Loss: (0.1894) |  Loss2: (0.0000) | Acc: (93.00%) (3711/3968)
Epoch: 111 | Batch_idx: 40 |  Loss: (0.1879) |  Loss2: (0.0000) | Acc: (93.00%) (4907/5248)
Epoch: 111 | Batch_idx: 50 |  Loss: (0.1884) |  Loss2: (0.0000) | Acc: (93.00%) (6111/6528)
Epoch: 111 | Batch_idx: 60 |  Loss: (0.1835) |  Loss2: (0.0000) | Acc: (93.00%) (7328/7808)
Epoch: 111 | Batch_idx: 70 |  Loss: (0.1812) |  Loss2: (0.0000) | Acc: (93.00%) (8539/9088)
Epoch: 111 | Batch_idx: 80 |  Loss: (0.1806) |  Loss2: (0.0000) | Acc: (94.00%) (9752/10368)
Epoch: 111 | Batch_idx: 90 |  Loss: (0.1805) |  Loss2: (0.0000) | Acc: (94.00%) (10950/11648)
Epoch: 111 | Batch_idx: 100 |  Loss: (0.1812) |  Loss2: (0.0000) | Acc: (93.00%) (12145/12928)
Epoch: 111 | Batch_idx: 110 |  Loss: (0.1834) |  Loss2: (0.0000) | Acc: (93.00%) (13330/14208)
Epoch: 111 | Batch_idx: 120 |  Loss: (0.1841) |  Loss2: (0.0000) | Acc: (93.00%) (14522/15488)
Epoch: 111 | Batch_idx: 130 |  Loss: (0.1846) |  Loss2: (0.0000) | Acc: (93.00%) (15717/16768)
Epoch: 111 | Batch_idx: 140 |  Loss: (0.1842) |  Loss2: (0.0000) | Acc: (93.00%) (16916/18048)
Epoch: 111 | Batch_idx: 150 |  Loss: (0.1842) |  Loss2: (0.0000) | Acc: (93.00%) (18114/19328)
Epoch: 111 | Batch_idx: 160 |  Loss: (0.1843) |  Loss2: (0.0000) | Acc: (93.00%) (19314/20608)
Epoch: 111 | Batch_idx: 170 |  Loss: (0.1840) |  Loss2: (0.0000) | Acc: (93.00%) (20513/21888)
Epoch: 111 | Batch_idx: 180 |  Loss: (0.1848) |  Loss2: (0.0000) | Acc: (93.00%) (21709/23168)
Epoch: 111 | Batch_idx: 190 |  Loss: (0.1851) |  Loss2: (0.0000) | Acc: (93.00%) (22917/24448)
Epoch: 111 | Batch_idx: 200 |  Loss: (0.1854) |  Loss2: (0.0000) | Acc: (93.00%) (24111/25728)
Epoch: 111 | Batch_idx: 210 |  Loss: (0.1861) |  Loss2: (0.0000) | Acc: (93.00%) (25302/27008)
Epoch: 111 | Batch_idx: 220 |  Loss: (0.1851) |  Loss2: (0.0000) | Acc: (93.00%) (26515/28288)
Epoch: 111 | Batch_idx: 230 |  Loss: (0.1851) |  Loss2: (0.0000) | Acc: (93.00%) (27712/29568)
Epoch: 111 | Batch_idx: 240 |  Loss: (0.1847) |  Loss2: (0.0000) | Acc: (93.00%) (28916/30848)
Epoch: 111 | Batch_idx: 250 |  Loss: (0.1842) |  Loss2: (0.0000) | Acc: (93.00%) (30127/32128)
Epoch: 111 | Batch_idx: 260 |  Loss: (0.1831) |  Loss2: (0.0000) | Acc: (93.00%) (31341/33408)
Epoch: 111 | Batch_idx: 270 |  Loss: (0.1828) |  Loss2: (0.0000) | Acc: (93.00%) (32548/34688)
Epoch: 111 | Batch_idx: 280 |  Loss: (0.1827) |  Loss2: (0.0000) | Acc: (93.00%) (33746/35968)
Epoch: 111 | Batch_idx: 290 |  Loss: (0.1828) |  Loss2: (0.0000) | Acc: (93.00%) (34944/37248)
Epoch: 111 | Batch_idx: 300 |  Loss: (0.1829) |  Loss2: (0.0000) | Acc: (93.00%) (36146/38528)
Epoch: 111 | Batch_idx: 310 |  Loss: (0.1826) |  Loss2: (0.0000) | Acc: (93.00%) (37350/39808)
Epoch: 111 | Batch_idx: 320 |  Loss: (0.1829) |  Loss2: (0.0000) | Acc: (93.00%) (38546/41088)
Epoch: 111 | Batch_idx: 330 |  Loss: (0.1827) |  Loss2: (0.0000) | Acc: (93.00%) (39744/42368)
Epoch: 111 | Batch_idx: 340 |  Loss: (0.1835) |  Loss2: (0.0000) | Acc: (93.00%) (40926/43648)
Epoch: 111 | Batch_idx: 350 |  Loss: (0.1835) |  Loss2: (0.0000) | Acc: (93.00%) (42126/44928)
Epoch: 111 | Batch_idx: 360 |  Loss: (0.1834) |  Loss2: (0.0000) | Acc: (93.00%) (43330/46208)
Epoch: 111 | Batch_idx: 370 |  Loss: (0.1835) |  Loss2: (0.0000) | Acc: (93.00%) (44531/47488)
Epoch: 111 | Batch_idx: 380 |  Loss: (0.1833) |  Loss2: (0.0000) | Acc: (93.00%) (45730/48768)
Epoch: 111 | Batch_idx: 390 |  Loss: (0.1831) |  Loss2: (0.0000) | Acc: (93.00%) (46892/50000)
# TEST : Loss: (0.3680) | Acc: (88.00%) (8817/10000)
percent tensor([0.5011, 0.4984, 0.5123, 0.4998, 0.5126, 0.5053, 0.5031, 0.5009, 0.5001,
        0.5026, 0.5019, 0.5094, 0.4995, 0.4906, 0.5023, 0.4989],
       device='cuda:0') torch.Size([16])
percent tensor([0.4967, 0.4782, 0.4923, 0.5030, 0.4904, 0.5101, 0.4777, 0.4855, 0.4957,
        0.4835, 0.4946, 0.4849, 0.4812, 0.4914, 0.4920, 0.5005],
       device='cuda:0') torch.Size([16])
percent tensor([0.6362, 0.6223, 0.5664, 0.5501, 0.5811, 0.6243, 0.6323, 0.5788, 0.5699,
        0.5907, 0.5987, 0.5685, 0.6437, 0.5730, 0.6531, 0.6169],
       device='cuda:0') torch.Size([16])
percent tensor([0.6173, 0.6344, 0.6172, 0.6501, 0.6324, 0.7159, 0.6218, 0.6075, 0.6339,
        0.6147, 0.6331, 0.6564, 0.6242, 0.6367, 0.6726, 0.6533],
       device='cuda:0') torch.Size([16])
percent tensor([0.5537, 0.5672, 0.5367, 0.5312, 0.5855, 0.5695, 0.5787, 0.5223, 0.5795,
        0.5702, 0.6078, 0.4757, 0.5418, 0.6670, 0.4748, 0.6138],
       device='cuda:0') torch.Size([16])
percent tensor([0.5853, 0.5828, 0.6793, 0.6717, 0.7098, 0.6666, 0.6417, 0.6406, 0.6301,
        0.6246, 0.6247, 0.6555, 0.6063, 0.6380, 0.5989, 0.6207],
       device='cuda:0') torch.Size([16])
percent tensor([0.5964, 0.7024, 0.7140, 0.6034, 0.6855, 0.4814, 0.5899, 0.5221, 0.7278,
        0.7154, 0.7828, 0.6739, 0.6868, 0.6892, 0.5386, 0.4619],
       device='cuda:0') torch.Size([16])
percent tensor([0.9995, 0.9991, 0.9997, 0.9993, 0.9994, 0.9994, 0.9991, 0.9991, 0.9997,
        0.9996, 0.9999, 0.9997, 0.9994, 0.9992, 0.9986, 0.9994],
       device='cuda:0') torch.Size([16])
True Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=128, out_features=16, bias=False)
False Linear(in_features=16, out_features=2, bias=False)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=128, out_features=16, bias=False)
False Linear(in_features=16, out_features=2, bias=False)
True Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=256, out_features=32, bias=False)
False Linear(in_features=32, out_features=2, bias=False)
True Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=256, out_features=32, bias=False)
False Linear(in_features=32, out_features=2, bias=False)
True Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=512, out_features=64, bias=False)
False Linear(in_features=64, out_features=2, bias=False)
True Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=512, out_features=64, bias=False)
False Linear(in_features=64, out_features=2, bias=False)
True Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1024, out_features=128, bias=False)
False Linear(in_features=128, out_features=2, bias=False)
True Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1024, out_features=128, bias=False)
False Linear(in_features=128, out_features=2, bias=False)
True Linear(in_features=512, out_features=10, bias=True)
Epoch: 112 | Batch_idx: 0 |  Loss: (0.1597) |  Loss2: (0.0000) | Acc: (95.00%) (122/128)
Epoch: 112 | Batch_idx: 10 |  Loss: (0.1996) |  Loss2: (0.0000) | Acc: (93.00%) (1312/1408)
Epoch: 112 | Batch_idx: 20 |  Loss: (0.2003) |  Loss2: (0.0000) | Acc: (93.00%) (2511/2688)
Epoch: 112 | Batch_idx: 30 |  Loss: (0.2037) |  Loss2: (0.0000) | Acc: (93.00%) (3702/3968)
Epoch: 112 | Batch_idx: 40 |  Loss: (0.2021) |  Loss2: (0.0000) | Acc: (93.00%) (4896/5248)
Epoch: 112 | Batch_idx: 50 |  Loss: (0.2014) |  Loss2: (0.0000) | Acc: (93.00%) (6088/6528)
Epoch: 112 | Batch_idx: 60 |  Loss: (0.1983) |  Loss2: (0.0000) | Acc: (93.00%) (7289/7808)
Epoch: 112 | Batch_idx: 70 |  Loss: (0.1968) |  Loss2: (0.0000) | Acc: (93.00%) (8476/9088)
Epoch: 112 | Batch_idx: 80 |  Loss: (0.1948) |  Loss2: (0.0000) | Acc: (93.00%) (9670/10368)
Epoch: 112 | Batch_idx: 90 |  Loss: (0.1978) |  Loss2: (0.0000) | Acc: (93.00%) (10853/11648)
Epoch: 112 | Batch_idx: 100 |  Loss: (0.1986) |  Loss2: (0.0000) | Acc: (93.00%) (12039/12928)
Epoch: 112 | Batch_idx: 110 |  Loss: (0.2003) |  Loss2: (0.0000) | Acc: (93.00%) (13218/14208)
Epoch: 112 | Batch_idx: 120 |  Loss: (0.2013) |  Loss2: (0.0000) | Acc: (93.00%) (14405/15488)
Epoch: 112 | Batch_idx: 130 |  Loss: (0.2026) |  Loss2: (0.0000) | Acc: (92.00%) (15580/16768)
Epoch: 112 | Batch_idx: 140 |  Loss: (0.2020) |  Loss2: (0.0000) | Acc: (92.00%) (16765/18048)
Epoch: 112 | Batch_idx: 150 |  Loss: (0.2016) |  Loss2: (0.0000) | Acc: (92.00%) (17943/19328)
Epoch: 112 | Batch_idx: 160 |  Loss: (0.2009) |  Loss2: (0.0000) | Acc: (92.00%) (19129/20608)
Epoch: 112 | Batch_idx: 170 |  Loss: (0.1991) |  Loss2: (0.0000) | Acc: (92.00%) (20341/21888)
Epoch: 112 | Batch_idx: 180 |  Loss: (0.1976) |  Loss2: (0.0000) | Acc: (93.00%) (21555/23168)
Epoch: 112 | Batch_idx: 190 |  Loss: (0.1973) |  Loss2: (0.0000) | Acc: (93.00%) (22744/24448)
Epoch: 112 | Batch_idx: 200 |  Loss: (0.1967) |  Loss2: (0.0000) | Acc: (93.00%) (23942/25728)
Epoch: 112 | Batch_idx: 210 |  Loss: (0.1959) |  Loss2: (0.0000) | Acc: (93.00%) (25154/27008)
Epoch: 112 | Batch_idx: 220 |  Loss: (0.1967) |  Loss2: (0.0000) | Acc: (93.00%) (26335/28288)
Epoch: 112 | Batch_idx: 230 |  Loss: (0.1980) |  Loss2: (0.0000) | Acc: (93.00%) (27518/29568)
Epoch: 112 | Batch_idx: 240 |  Loss: (0.1987) |  Loss2: (0.0000) | Acc: (93.00%) (28704/30848)
Epoch: 112 | Batch_idx: 250 |  Loss: (0.1998) |  Loss2: (0.0000) | Acc: (93.00%) (29891/32128)
Epoch: 112 | Batch_idx: 260 |  Loss: (0.2006) |  Loss2: (0.0000) | Acc: (92.00%) (31069/33408)
Epoch: 112 | Batch_idx: 270 |  Loss: (0.2013) |  Loss2: (0.0000) | Acc: (92.00%) (32249/34688)
Epoch: 112 | Batch_idx: 280 |  Loss: (0.2015) |  Loss2: (0.0000) | Acc: (92.00%) (33438/35968)
Epoch: 112 | Batch_idx: 290 |  Loss: (0.2008) |  Loss2: (0.0000) | Acc: (92.00%) (34632/37248)
Epoch: 112 | Batch_idx: 300 |  Loss: (0.2022) |  Loss2: (0.0000) | Acc: (92.00%) (35806/38528)
Epoch: 112 | Batch_idx: 310 |  Loss: (0.2023) |  Loss2: (0.0000) | Acc: (92.00%) (36985/39808)
Epoch: 112 | Batch_idx: 320 |  Loss: (0.2022) |  Loss2: (0.0000) | Acc: (92.00%) (38184/41088)
Epoch: 112 | Batch_idx: 330 |  Loss: (0.2029) |  Loss2: (0.0000) | Acc: (92.00%) (39373/42368)
Epoch: 112 | Batch_idx: 340 |  Loss: (0.2037) |  Loss2: (0.0000) | Acc: (92.00%) (40552/43648)
Epoch: 112 | Batch_idx: 350 |  Loss: (0.2038) |  Loss2: (0.0000) | Acc: (92.00%) (41741/44928)
Epoch: 112 | Batch_idx: 360 |  Loss: (0.2036) |  Loss2: (0.0000) | Acc: (92.00%) (42930/46208)
Epoch: 112 | Batch_idx: 370 |  Loss: (0.2041) |  Loss2: (0.0000) | Acc: (92.00%) (44117/47488)
Epoch: 112 | Batch_idx: 380 |  Loss: (0.2046) |  Loss2: (0.0000) | Acc: (92.00%) (45303/48768)
Epoch: 112 | Batch_idx: 390 |  Loss: (0.2047) |  Loss2: (0.0000) | Acc: (92.00%) (46447/50000)
# TEST : Loss: (0.4375) | Acc: (86.00%) (8624/10000)
percent tensor([0.4997, 0.4993, 0.5086, 0.4984, 0.5088, 0.5039, 0.5025, 0.4994, 0.4997,
        0.5020, 0.5019, 0.5067, 0.4986, 0.4931, 0.5020, 0.4986],
       device='cuda:0') torch.Size([16])
percent tensor([0.4975, 0.4780, 0.4993, 0.5039, 0.4943, 0.5093, 0.4802, 0.4883, 0.4974,
        0.4853, 0.4950, 0.4905, 0.4829, 0.4899, 0.4911, 0.4984],
       device='cuda:0') torch.Size([16])
percent tensor([0.6377, 0.6288, 0.5692, 0.5531, 0.5797, 0.6217, 0.6354, 0.5817, 0.5736,
        0.5964, 0.6050, 0.5676, 0.6470, 0.5769, 0.6565, 0.6220],
       device='cuda:0') torch.Size([16])
percent tensor([0.6168, 0.6275, 0.6115, 0.6473, 0.6287, 0.7109, 0.6218, 0.6048, 0.6342,
        0.6059, 0.6252, 0.6510, 0.6229, 0.6401, 0.6674, 0.6443],
       device='cuda:0') torch.Size([16])
percent tensor([0.5625, 0.5615, 0.5559, 0.5456, 0.5910, 0.5789, 0.5814, 0.5234, 0.5879,
        0.5744, 0.6114, 0.5020, 0.5416, 0.6639, 0.4778, 0.6191],
       device='cuda:0') torch.Size([16])
percent tensor([0.5882, 0.5801, 0.6737, 0.6841, 0.7081, 0.6832, 0.6400, 0.6382, 0.6327,
        0.6148, 0.6208, 0.6568, 0.5983, 0.6468, 0.5960, 0.6196],
       device='cuda:0') torch.Size([16])
percent tensor([0.5910, 0.6938, 0.7014, 0.6319, 0.6996, 0.5240, 0.5795, 0.5311, 0.7135,
        0.6987, 0.7444, 0.6703, 0.6684, 0.6449, 0.5378, 0.4859],
       device='cuda:0') torch.Size([16])
percent tensor([0.9996, 0.9992, 0.9997, 0.9997, 0.9995, 0.9993, 0.9995, 0.9992, 0.9997,
        0.9996, 0.9999, 0.9998, 0.9995, 0.9987, 0.9984, 0.9994],
       device='cuda:0') torch.Size([16])
Epoch: 113 | Batch_idx: 0 |  Loss: (0.1546) |  Loss2: (0.0000) | Acc: (93.00%) (120/128)
Epoch: 113 | Batch_idx: 10 |  Loss: (0.1889) |  Loss2: (0.0000) | Acc: (93.00%) (1315/1408)
Epoch: 113 | Batch_idx: 20 |  Loss: (0.1825) |  Loss2: (0.0000) | Acc: (93.00%) (2519/2688)
Epoch: 113 | Batch_idx: 30 |  Loss: (0.2005) |  Loss2: (0.0000) | Acc: (92.00%) (3686/3968)
Epoch: 113 | Batch_idx: 40 |  Loss: (0.1975) |  Loss2: (0.0000) | Acc: (93.00%) (4890/5248)
Epoch: 113 | Batch_idx: 50 |  Loss: (0.1994) |  Loss2: (0.0000) | Acc: (93.00%) (6085/6528)
Epoch: 113 | Batch_idx: 60 |  Loss: (0.2012) |  Loss2: (0.0000) | Acc: (93.00%) (7271/7808)
Epoch: 113 | Batch_idx: 70 |  Loss: (0.2005) |  Loss2: (0.0000) | Acc: (93.00%) (8464/9088)
Epoch: 113 | Batch_idx: 80 |  Loss: (0.1997) |  Loss2: (0.0000) | Acc: (93.00%) (9655/10368)
Epoch: 113 | Batch_idx: 90 |  Loss: (0.2004) |  Loss2: (0.0000) | Acc: (93.00%) (10848/11648)
Epoch: 113 | Batch_idx: 100 |  Loss: (0.2037) |  Loss2: (0.0000) | Acc: (93.00%) (12034/12928)
Epoch: 113 | Batch_idx: 110 |  Loss: (0.2032) |  Loss2: (0.0000) | Acc: (93.00%) (13226/14208)
Epoch: 113 | Batch_idx: 120 |  Loss: (0.2028) |  Loss2: (0.0000) | Acc: (93.00%) (14421/15488)
Epoch: 113 | Batch_idx: 130 |  Loss: (0.2024) |  Loss2: (0.0000) | Acc: (93.00%) (15608/16768)
Epoch: 113 | Batch_idx: 140 |  Loss: (0.2011) |  Loss2: (0.0000) | Acc: (93.00%) (16806/18048)
Epoch: 113 | Batch_idx: 150 |  Loss: (0.2016) |  Loss2: (0.0000) | Acc: (93.00%) (17997/19328)
Epoch: 113 | Batch_idx: 160 |  Loss: (0.2009) |  Loss2: (0.0000) | Acc: (93.00%) (19194/20608)
Epoch: 113 | Batch_idx: 170 |  Loss: (0.2016) |  Loss2: (0.0000) | Acc: (93.00%) (20371/21888)
Epoch: 113 | Batch_idx: 180 |  Loss: (0.2013) |  Loss2: (0.0000) | Acc: (93.00%) (21562/23168)
Epoch: 113 | Batch_idx: 190 |  Loss: (0.2007) |  Loss2: (0.0000) | Acc: (93.00%) (22763/24448)
Epoch: 113 | Batch_idx: 200 |  Loss: (0.2027) |  Loss2: (0.0000) | Acc: (92.00%) (23927/25728)
Epoch: 113 | Batch_idx: 210 |  Loss: (0.2020) |  Loss2: (0.0000) | Acc: (93.00%) (25125/27008)
Epoch: 113 | Batch_idx: 220 |  Loss: (0.1998) |  Loss2: (0.0000) | Acc: (93.00%) (26347/28288)
Epoch: 113 | Batch_idx: 230 |  Loss: (0.1986) |  Loss2: (0.0000) | Acc: (93.00%) (27550/29568)
Epoch: 113 | Batch_idx: 240 |  Loss: (0.1991) |  Loss2: (0.0000) | Acc: (93.00%) (28735/30848)
Epoch: 113 | Batch_idx: 250 |  Loss: (0.1984) |  Loss2: (0.0000) | Acc: (93.00%) (29936/32128)
Epoch: 113 | Batch_idx: 260 |  Loss: (0.1982) |  Loss2: (0.0000) | Acc: (93.00%) (31126/33408)
Epoch: 113 | Batch_idx: 270 |  Loss: (0.1974) |  Loss2: (0.0000) | Acc: (93.00%) (32329/34688)
Epoch: 113 | Batch_idx: 280 |  Loss: (0.1977) |  Loss2: (0.0000) | Acc: (93.00%) (33518/35968)
Epoch: 113 | Batch_idx: 290 |  Loss: (0.1991) |  Loss2: (0.0000) | Acc: (93.00%) (34704/37248)
Epoch: 113 | Batch_idx: 300 |  Loss: (0.1985) |  Loss2: (0.0000) | Acc: (93.00%) (35897/38528)
Epoch: 113 | Batch_idx: 310 |  Loss: (0.1978) |  Loss2: (0.0000) | Acc: (93.00%) (37101/39808)
Epoch: 113 | Batch_idx: 320 |  Loss: (0.1982) |  Loss2: (0.0000) | Acc: (93.00%) (38282/41088)
Epoch: 113 | Batch_idx: 330 |  Loss: (0.1980) |  Loss2: (0.0000) | Acc: (93.00%) (39475/42368)
Epoch: 113 | Batch_idx: 340 |  Loss: (0.1976) |  Loss2: (0.0000) | Acc: (93.00%) (40675/43648)
Epoch: 113 | Batch_idx: 350 |  Loss: (0.1976) |  Loss2: (0.0000) | Acc: (93.00%) (41867/44928)
Epoch: 113 | Batch_idx: 360 |  Loss: (0.1979) |  Loss2: (0.0000) | Acc: (93.00%) (43050/46208)
Epoch: 113 | Batch_idx: 370 |  Loss: (0.1985) |  Loss2: (0.0000) | Acc: (93.00%) (44234/47488)
Epoch: 113 | Batch_idx: 380 |  Loss: (0.1987) |  Loss2: (0.0000) | Acc: (93.00%) (45412/48768)
Epoch: 113 | Batch_idx: 390 |  Loss: (0.1990) |  Loss2: (0.0000) | Acc: (93.00%) (46551/50000)
# TEST : Loss: (0.4176) | Acc: (87.00%) (8732/10000)
percent tensor([0.4998, 0.4989, 0.5099, 0.4990, 0.5101, 0.5041, 0.5026, 0.4992, 0.4994,
        0.5018, 0.5015, 0.5077, 0.4984, 0.4933, 0.5020, 0.4983],
       device='cuda:0') torch.Size([16])
percent tensor([0.5011, 0.4784, 0.5038, 0.5050, 0.4957, 0.5103, 0.4807, 0.4897, 0.4984,
        0.4861, 0.4968, 0.4927, 0.4847, 0.4899, 0.4934, 0.5015],
       device='cuda:0') torch.Size([16])
percent tensor([0.6204, 0.6229, 0.5640, 0.5502, 0.5754, 0.6129, 0.6229, 0.5804, 0.5621,
        0.5824, 0.5923, 0.5598, 0.6312, 0.5612, 0.6513, 0.6055],
       device='cuda:0') torch.Size([16])
percent tensor([0.6203, 0.6427, 0.6184, 0.6564, 0.6259, 0.7053, 0.6261, 0.6156, 0.6476,
        0.6175, 0.6354, 0.6558, 0.6387, 0.6538, 0.6695, 0.6511],
       device='cuda:0') torch.Size([16])
percent tensor([0.5585, 0.5686, 0.5595, 0.5444, 0.5896, 0.5662, 0.5851, 0.5208, 0.6030,
        0.5885, 0.6095, 0.5075, 0.5528, 0.6759, 0.4676, 0.6130],
       device='cuda:0') torch.Size([16])
percent tensor([0.5865, 0.5897, 0.6811, 0.6889, 0.7129, 0.6589, 0.6408, 0.6405, 0.6503,
        0.6292, 0.6208, 0.6656, 0.6180, 0.6586, 0.5950, 0.6113],
       device='cuda:0') torch.Size([16])
percent tensor([0.5802, 0.7046, 0.6744, 0.6187, 0.6847, 0.4802, 0.5807, 0.5316, 0.7021,
        0.7030, 0.7602, 0.6315, 0.6813, 0.6813, 0.5247, 0.4769],
       device='cuda:0') torch.Size([16])
percent tensor([0.9994, 0.9996, 0.9995, 0.9997, 0.9996, 0.9996, 0.9993, 0.9992, 0.9995,
        0.9996, 0.9999, 0.9996, 0.9995, 0.9992, 0.9982, 0.9993],
       device='cuda:0') torch.Size([16])
Epoch: 114 | Batch_idx: 0 |  Loss: (0.1768) |  Loss2: (0.0000) | Acc: (94.00%) (121/128)
Epoch: 114 | Batch_idx: 10 |  Loss: (0.2120) |  Loss2: (0.0000) | Acc: (92.00%) (1300/1408)
Epoch: 114 | Batch_idx: 20 |  Loss: (0.1937) |  Loss2: (0.0000) | Acc: (93.00%) (2509/2688)
Epoch: 114 | Batch_idx: 30 |  Loss: (0.1990) |  Loss2: (0.0000) | Acc: (92.00%) (3689/3968)
Epoch: 114 | Batch_idx: 40 |  Loss: (0.1981) |  Loss2: (0.0000) | Acc: (93.00%) (4889/5248)
Epoch: 114 | Batch_idx: 50 |  Loss: (0.1976) |  Loss2: (0.0000) | Acc: (93.00%) (6078/6528)
Epoch: 114 | Batch_idx: 60 |  Loss: (0.1956) |  Loss2: (0.0000) | Acc: (93.00%) (7283/7808)
Epoch: 114 | Batch_idx: 70 |  Loss: (0.1959) |  Loss2: (0.0000) | Acc: (93.00%) (8467/9088)
Epoch: 114 | Batch_idx: 80 |  Loss: (0.1947) |  Loss2: (0.0000) | Acc: (93.00%) (9657/10368)
Epoch: 114 | Batch_idx: 90 |  Loss: (0.1941) |  Loss2: (0.0000) | Acc: (93.00%) (10857/11648)
Epoch: 114 | Batch_idx: 100 |  Loss: (0.1931) |  Loss2: (0.0000) | Acc: (93.00%) (12056/12928)
Epoch: 114 | Batch_idx: 110 |  Loss: (0.1933) |  Loss2: (0.0000) | Acc: (93.00%) (13244/14208)
Epoch: 114 | Batch_idx: 120 |  Loss: (0.1940) |  Loss2: (0.0000) | Acc: (93.00%) (14430/15488)
Epoch: 114 | Batch_idx: 130 |  Loss: (0.1949) |  Loss2: (0.0000) | Acc: (93.00%) (15612/16768)
Epoch: 114 | Batch_idx: 140 |  Loss: (0.1953) |  Loss2: (0.0000) | Acc: (93.00%) (16807/18048)
Epoch: 114 | Batch_idx: 150 |  Loss: (0.1956) |  Loss2: (0.0000) | Acc: (93.00%) (18001/19328)
Epoch: 114 | Batch_idx: 160 |  Loss: (0.1958) |  Loss2: (0.0000) | Acc: (93.00%) (19186/20608)
Epoch: 114 | Batch_idx: 170 |  Loss: (0.1948) |  Loss2: (0.0000) | Acc: (93.00%) (20380/21888)
Epoch: 114 | Batch_idx: 180 |  Loss: (0.1964) |  Loss2: (0.0000) | Acc: (93.00%) (21560/23168)
Epoch: 114 | Batch_idx: 190 |  Loss: (0.1971) |  Loss2: (0.0000) | Acc: (93.00%) (22749/24448)
Epoch: 114 | Batch_idx: 200 |  Loss: (0.1971) |  Loss2: (0.0000) | Acc: (93.00%) (23941/25728)
Epoch: 114 | Batch_idx: 210 |  Loss: (0.1973) |  Loss2: (0.0000) | Acc: (93.00%) (25133/27008)
Epoch: 114 | Batch_idx: 220 |  Loss: (0.1976) |  Loss2: (0.0000) | Acc: (93.00%) (26324/28288)
Epoch: 114 | Batch_idx: 230 |  Loss: (0.1973) |  Loss2: (0.0000) | Acc: (93.00%) (27527/29568)
Epoch: 114 | Batch_idx: 240 |  Loss: (0.1958) |  Loss2: (0.0000) | Acc: (93.00%) (28744/30848)
Epoch: 114 | Batch_idx: 250 |  Loss: (0.1959) |  Loss2: (0.0000) | Acc: (93.00%) (29935/32128)
Epoch: 114 | Batch_idx: 260 |  Loss: (0.1966) |  Loss2: (0.0000) | Acc: (93.00%) (31128/33408)
Epoch: 114 | Batch_idx: 270 |  Loss: (0.1965) |  Loss2: (0.0000) | Acc: (93.00%) (32325/34688)
Epoch: 114 | Batch_idx: 280 |  Loss: (0.1962) |  Loss2: (0.0000) | Acc: (93.00%) (33519/35968)
Epoch: 114 | Batch_idx: 290 |  Loss: (0.1961) |  Loss2: (0.0000) | Acc: (93.00%) (34716/37248)
Epoch: 114 | Batch_idx: 300 |  Loss: (0.1959) |  Loss2: (0.0000) | Acc: (93.00%) (35914/38528)
Epoch: 114 | Batch_idx: 310 |  Loss: (0.1961) |  Loss2: (0.0000) | Acc: (93.00%) (37102/39808)
Epoch: 114 | Batch_idx: 320 |  Loss: (0.1967) |  Loss2: (0.0000) | Acc: (93.00%) (38292/41088)
Epoch: 114 | Batch_idx: 330 |  Loss: (0.1955) |  Loss2: (0.0000) | Acc: (93.00%) (39504/42368)
Epoch: 114 | Batch_idx: 340 |  Loss: (0.1960) |  Loss2: (0.0000) | Acc: (93.00%) (40676/43648)
Epoch: 114 | Batch_idx: 350 |  Loss: (0.1967) |  Loss2: (0.0000) | Acc: (93.00%) (41864/44928)
Epoch: 114 | Batch_idx: 360 |  Loss: (0.1966) |  Loss2: (0.0000) | Acc: (93.00%) (43063/46208)
Epoch: 114 | Batch_idx: 370 |  Loss: (0.1971) |  Loss2: (0.0000) | Acc: (93.00%) (44245/47488)
Epoch: 114 | Batch_idx: 380 |  Loss: (0.1972) |  Loss2: (0.0000) | Acc: (93.00%) (45425/48768)
Epoch: 114 | Batch_idx: 390 |  Loss: (0.1962) |  Loss2: (0.0000) | Acc: (93.00%) (46587/50000)
# TEST : Loss: (0.4641) | Acc: (85.00%) (8570/10000)
percent tensor([0.5001, 0.4993, 0.5085, 0.4978, 0.5087, 0.5043, 0.5025, 0.4986, 0.5003,
        0.5017, 0.5026, 0.5067, 0.4988, 0.4938, 0.5020, 0.4986],
       device='cuda:0') torch.Size([16])
percent tensor([0.5001, 0.4760, 0.5017, 0.5032, 0.4939, 0.5103, 0.4788, 0.4876, 0.4980,
        0.4846, 0.4955, 0.4927, 0.4835, 0.4872, 0.4915, 0.4992],
       device='cuda:0') torch.Size([16])
percent tensor([0.6235, 0.6321, 0.5631, 0.5489, 0.5743, 0.6180, 0.6308, 0.5812, 0.5618,
        0.5930, 0.5947, 0.5633, 0.6332, 0.5696, 0.6577, 0.6174],
       device='cuda:0') torch.Size([16])
percent tensor([0.6222, 0.6365, 0.6189, 0.6542, 0.6295, 0.7208, 0.6210, 0.6115, 0.6359,
        0.6122, 0.6340, 0.6560, 0.6296, 0.6430, 0.6755, 0.6543],
       device='cuda:0') torch.Size([16])
percent tensor([0.5455, 0.5620, 0.5440, 0.5318, 0.5865, 0.5449, 0.5718, 0.5138, 0.5984,
        0.5734, 0.6048, 0.4967, 0.5380, 0.6707, 0.4532, 0.5987],
       device='cuda:0') torch.Size([16])
percent tensor([0.5847, 0.5722, 0.6694, 0.6784, 0.7049, 0.6671, 0.6271, 0.6387, 0.6370,
        0.6101, 0.6144, 0.6476, 0.5960, 0.6363, 0.5974, 0.6119],
       device='cuda:0') torch.Size([16])
percent tensor([0.6122, 0.6933, 0.7067, 0.6376, 0.7158, 0.5218, 0.5926, 0.5469, 0.7086,
        0.7237, 0.7594, 0.6506, 0.6825, 0.6907, 0.5484, 0.4878],
       device='cuda:0') torch.Size([16])
percent tensor([0.9996, 0.9995, 0.9997, 0.9996, 0.9997, 0.9988, 0.9994, 0.9996, 0.9997,
        0.9999, 0.9999, 0.9998, 0.9997, 0.9992, 0.9982, 0.9993],
       device='cuda:0') torch.Size([16])
Epoch: 115 | Batch_idx: 0 |  Loss: (0.1327) |  Loss2: (0.0000) | Acc: (96.00%) (123/128)
Epoch: 115 | Batch_idx: 10 |  Loss: (0.1688) |  Loss2: (0.0000) | Acc: (94.00%) (1330/1408)
Epoch: 115 | Batch_idx: 20 |  Loss: (0.1716) |  Loss2: (0.0000) | Acc: (94.00%) (2536/2688)
Epoch: 115 | Batch_idx: 30 |  Loss: (0.1762) |  Loss2: (0.0000) | Acc: (94.00%) (3733/3968)
Epoch: 115 | Batch_idx: 40 |  Loss: (0.1767) |  Loss2: (0.0000) | Acc: (94.00%) (4934/5248)
Epoch: 115 | Batch_idx: 50 |  Loss: (0.1780) |  Loss2: (0.0000) | Acc: (93.00%) (6129/6528)
Epoch: 115 | Batch_idx: 60 |  Loss: (0.1813) |  Loss2: (0.0000) | Acc: (93.00%) (7322/7808)
Epoch: 115 | Batch_idx: 70 |  Loss: (0.1825) |  Loss2: (0.0000) | Acc: (93.00%) (8517/9088)
Epoch: 115 | Batch_idx: 80 |  Loss: (0.1862) |  Loss2: (0.0000) | Acc: (93.00%) (9697/10368)
Epoch: 115 | Batch_idx: 90 |  Loss: (0.1893) |  Loss2: (0.0000) | Acc: (93.00%) (10878/11648)
Epoch: 115 | Batch_idx: 100 |  Loss: (0.1895) |  Loss2: (0.0000) | Acc: (93.00%) (12066/12928)
Epoch: 115 | Batch_idx: 110 |  Loss: (0.1886) |  Loss2: (0.0000) | Acc: (93.00%) (13273/14208)
Epoch: 115 | Batch_idx: 120 |  Loss: (0.1884) |  Loss2: (0.0000) | Acc: (93.00%) (14465/15488)
Epoch: 115 | Batch_idx: 130 |  Loss: (0.1874) |  Loss2: (0.0000) | Acc: (93.00%) (15664/16768)
Epoch: 115 | Batch_idx: 140 |  Loss: (0.1874) |  Loss2: (0.0000) | Acc: (93.00%) (16863/18048)
Epoch: 115 | Batch_idx: 150 |  Loss: (0.1879) |  Loss2: (0.0000) | Acc: (93.00%) (18061/19328)
Epoch: 115 | Batch_idx: 160 |  Loss: (0.1890) |  Loss2: (0.0000) | Acc: (93.00%) (19252/20608)
Epoch: 115 | Batch_idx: 170 |  Loss: (0.1903) |  Loss2: (0.0000) | Acc: (93.00%) (20438/21888)
Epoch: 115 | Batch_idx: 180 |  Loss: (0.1913) |  Loss2: (0.0000) | Acc: (93.00%) (21623/23168)
Epoch: 115 | Batch_idx: 190 |  Loss: (0.1914) |  Loss2: (0.0000) | Acc: (93.00%) (22809/24448)
Epoch: 115 | Batch_idx: 200 |  Loss: (0.1923) |  Loss2: (0.0000) | Acc: (93.00%) (23994/25728)
Epoch: 115 | Batch_idx: 210 |  Loss: (0.1921) |  Loss2: (0.0000) | Acc: (93.00%) (25190/27008)
Epoch: 115 | Batch_idx: 220 |  Loss: (0.1928) |  Loss2: (0.0000) | Acc: (93.00%) (26377/28288)
Epoch: 115 | Batch_idx: 230 |  Loss: (0.1926) |  Loss2: (0.0000) | Acc: (93.00%) (27579/29568)
Epoch: 115 | Batch_idx: 240 |  Loss: (0.1922) |  Loss2: (0.0000) | Acc: (93.00%) (28780/30848)
Epoch: 115 | Batch_idx: 250 |  Loss: (0.1922) |  Loss2: (0.0000) | Acc: (93.00%) (29979/32128)
Epoch: 115 | Batch_idx: 260 |  Loss: (0.1939) |  Loss2: (0.0000) | Acc: (93.00%) (31160/33408)
Epoch: 115 | Batch_idx: 270 |  Loss: (0.1939) |  Loss2: (0.0000) | Acc: (93.00%) (32351/34688)
Epoch: 115 | Batch_idx: 280 |  Loss: (0.1933) |  Loss2: (0.0000) | Acc: (93.00%) (33554/35968)
Epoch: 115 | Batch_idx: 290 |  Loss: (0.1933) |  Loss2: (0.0000) | Acc: (93.00%) (34750/37248)
Epoch: 115 | Batch_idx: 300 |  Loss: (0.1923) |  Loss2: (0.0000) | Acc: (93.00%) (35960/38528)
Epoch: 115 | Batch_idx: 310 |  Loss: (0.1926) |  Loss2: (0.0000) | Acc: (93.00%) (37148/39808)
Epoch: 115 | Batch_idx: 320 |  Loss: (0.1923) |  Loss2: (0.0000) | Acc: (93.00%) (38338/41088)
Epoch: 115 | Batch_idx: 330 |  Loss: (0.1921) |  Loss2: (0.0000) | Acc: (93.00%) (39529/42368)
Epoch: 115 | Batch_idx: 340 |  Loss: (0.1922) |  Loss2: (0.0000) | Acc: (93.00%) (40723/43648)
Epoch: 115 | Batch_idx: 350 |  Loss: (0.1922) |  Loss2: (0.0000) | Acc: (93.00%) (41923/44928)
Epoch: 115 | Batch_idx: 360 |  Loss: (0.1922) |  Loss2: (0.0000) | Acc: (93.00%) (43112/46208)
Epoch: 115 | Batch_idx: 370 |  Loss: (0.1930) |  Loss2: (0.0000) | Acc: (93.00%) (44302/47488)
Epoch: 115 | Batch_idx: 380 |  Loss: (0.1932) |  Loss2: (0.0000) | Acc: (93.00%) (45488/48768)
Epoch: 115 | Batch_idx: 390 |  Loss: (0.1930) |  Loss2: (0.0000) | Acc: (93.00%) (46621/50000)
=> saving checkpoint 'drive/app/torch/save_Schedule/checkpoint_115.pth.tar'
# TEST : Loss: (0.4409) | Acc: (85.00%) (8593/10000)
percent tensor([0.4996, 0.4990, 0.5098, 0.4989, 0.5095, 0.5041, 0.5024, 0.4995, 0.4995,
        0.5018, 0.5015, 0.5073, 0.4982, 0.4933, 0.5018, 0.4982],
       device='cuda:0') torch.Size([16])
percent tensor([0.4983, 0.4778, 0.5000, 0.5032, 0.4930, 0.5105, 0.4789, 0.4870, 0.4964,
        0.4843, 0.4948, 0.4890, 0.4825, 0.4889, 0.4924, 0.4995],
       device='cuda:0') torch.Size([16])
percent tensor([0.6229, 0.6267, 0.5662, 0.5461, 0.5767, 0.6072, 0.6244, 0.5804, 0.5697,
        0.5867, 0.5939, 0.5608, 0.6346, 0.5702, 0.6424, 0.6093],
       device='cuda:0') torch.Size([16])
percent tensor([0.6203, 0.6413, 0.6210, 0.6542, 0.6300, 0.7186, 0.6269, 0.6149, 0.6422,
        0.6139, 0.6317, 0.6560, 0.6292, 0.6528, 0.6733, 0.6566],
       device='cuda:0') torch.Size([16])
percent tensor([0.5529, 0.5658, 0.5489, 0.5493, 0.5877, 0.5550, 0.5680, 0.5231, 0.5947,
        0.5879, 0.6088, 0.5102, 0.5481, 0.6628, 0.4719, 0.6077],
       device='cuda:0') torch.Size([16])
percent tensor([0.5826, 0.5769, 0.6869, 0.6899, 0.7147, 0.6620, 0.6409, 0.6392, 0.6446,
        0.6181, 0.6183, 0.6662, 0.6031, 0.6481, 0.5976, 0.6104],
       device='cuda:0') torch.Size([16])
percent tensor([0.5957, 0.6868, 0.6809, 0.6438, 0.7050, 0.4969, 0.6030, 0.5273, 0.6974,
        0.6900, 0.7466, 0.6525, 0.6854, 0.6822, 0.5664, 0.4837],
       device='cuda:0') torch.Size([16])
percent tensor([0.9995, 0.9996, 0.9995, 0.9996, 0.9995, 0.9987, 0.9993, 0.9993, 0.9995,
        0.9997, 0.9999, 0.9996, 0.9996, 0.9995, 0.9988, 0.9993],
       device='cuda:0') torch.Size([16])
Epoch: 116 | Batch_idx: 0 |  Loss: (0.2241) |  Loss2: (0.0000) | Acc: (92.00%) (119/128)
Epoch: 116 | Batch_idx: 10 |  Loss: (0.1957) |  Loss2: (0.0000) | Acc: (93.00%) (1312/1408)
Epoch: 116 | Batch_idx: 20 |  Loss: (0.1980) |  Loss2: (0.0000) | Acc: (93.00%) (2502/2688)
Epoch: 116 | Batch_idx: 30 |  Loss: (0.1900) |  Loss2: (0.0000) | Acc: (93.00%) (3705/3968)
Epoch: 116 | Batch_idx: 40 |  Loss: (0.1857) |  Loss2: (0.0000) | Acc: (93.00%) (4906/5248)
Epoch: 116 | Batch_idx: 50 |  Loss: (0.1825) |  Loss2: (0.0000) | Acc: (93.00%) (6117/6528)
Epoch: 116 | Batch_idx: 60 |  Loss: (0.1859) |  Loss2: (0.0000) | Acc: (93.00%) (7302/7808)
Epoch: 116 | Batch_idx: 70 |  Loss: (0.1895) |  Loss2: (0.0000) | Acc: (93.00%) (8492/9088)
Epoch: 116 | Batch_idx: 80 |  Loss: (0.1877) |  Loss2: (0.0000) | Acc: (93.00%) (9698/10368)
Epoch: 116 | Batch_idx: 90 |  Loss: (0.1892) |  Loss2: (0.0000) | Acc: (93.00%) (10886/11648)
Epoch: 116 | Batch_idx: 100 |  Loss: (0.1902) |  Loss2: (0.0000) | Acc: (93.00%) (12085/12928)
Epoch: 116 | Batch_idx: 110 |  Loss: (0.1888) |  Loss2: (0.0000) | Acc: (93.00%) (13290/14208)
Epoch: 116 | Batch_idx: 120 |  Loss: (0.1872) |  Loss2: (0.0000) | Acc: (93.00%) (14492/15488)
Epoch: 116 | Batch_idx: 130 |  Loss: (0.1856) |  Loss2: (0.0000) | Acc: (93.00%) (15696/16768)
Epoch: 116 | Batch_idx: 140 |  Loss: (0.1870) |  Loss2: (0.0000) | Acc: (93.00%) (16865/18048)
Epoch: 116 | Batch_idx: 150 |  Loss: (0.1856) |  Loss2: (0.0000) | Acc: (93.00%) (18071/19328)
Epoch: 116 | Batch_idx: 160 |  Loss: (0.1856) |  Loss2: (0.0000) | Acc: (93.00%) (19274/20608)
Epoch: 116 | Batch_idx: 170 |  Loss: (0.1866) |  Loss2: (0.0000) | Acc: (93.00%) (20467/21888)
Epoch: 116 | Batch_idx: 180 |  Loss: (0.1868) |  Loss2: (0.0000) | Acc: (93.00%) (21662/23168)
Epoch: 116 | Batch_idx: 190 |  Loss: (0.1869) |  Loss2: (0.0000) | Acc: (93.00%) (22856/24448)
Epoch: 116 | Batch_idx: 200 |  Loss: (0.1877) |  Loss2: (0.0000) | Acc: (93.00%) (24045/25728)
Epoch: 116 | Batch_idx: 210 |  Loss: (0.1880) |  Loss2: (0.0000) | Acc: (93.00%) (25232/27008)
Epoch: 116 | Batch_idx: 220 |  Loss: (0.1880) |  Loss2: (0.0000) | Acc: (93.00%) (26421/28288)
Epoch: 116 | Batch_idx: 230 |  Loss: (0.1879) |  Loss2: (0.0000) | Acc: (93.00%) (27623/29568)
Epoch: 116 | Batch_idx: 240 |  Loss: (0.1892) |  Loss2: (0.0000) | Acc: (93.00%) (28801/30848)
Epoch: 116 | Batch_idx: 250 |  Loss: (0.1890) |  Loss2: (0.0000) | Acc: (93.00%) (29994/32128)
Epoch: 116 | Batch_idx: 260 |  Loss: (0.1892) |  Loss2: (0.0000) | Acc: (93.00%) (31187/33408)
Epoch: 116 | Batch_idx: 270 |  Loss: (0.1891) |  Loss2: (0.0000) | Acc: (93.00%) (32386/34688)
Epoch: 116 | Batch_idx: 280 |  Loss: (0.1884) |  Loss2: (0.0000) | Acc: (93.00%) (33595/35968)
Epoch: 116 | Batch_idx: 290 |  Loss: (0.1886) |  Loss2: (0.0000) | Acc: (93.00%) (34783/37248)
Epoch: 116 | Batch_idx: 300 |  Loss: (0.1893) |  Loss2: (0.0000) | Acc: (93.00%) (35970/38528)
Epoch: 116 | Batch_idx: 310 |  Loss: (0.1887) |  Loss2: (0.0000) | Acc: (93.00%) (37167/39808)
Epoch: 116 | Batch_idx: 320 |  Loss: (0.1880) |  Loss2: (0.0000) | Acc: (93.00%) (38378/41088)
Epoch: 116 | Batch_idx: 330 |  Loss: (0.1879) |  Loss2: (0.0000) | Acc: (93.00%) (39570/42368)
Epoch: 116 | Batch_idx: 340 |  Loss: (0.1877) |  Loss2: (0.0000) | Acc: (93.00%) (40774/43648)
Epoch: 116 | Batch_idx: 350 |  Loss: (0.1875) |  Loss2: (0.0000) | Acc: (93.00%) (41971/44928)
Epoch: 116 | Batch_idx: 360 |  Loss: (0.1871) |  Loss2: (0.0000) | Acc: (93.00%) (43179/46208)
Epoch: 116 | Batch_idx: 370 |  Loss: (0.1869) |  Loss2: (0.0000) | Acc: (93.00%) (44382/47488)
Epoch: 116 | Batch_idx: 380 |  Loss: (0.1861) |  Loss2: (0.0000) | Acc: (93.00%) (45592/48768)
Epoch: 116 | Batch_idx: 390 |  Loss: (0.1861) |  Loss2: (0.0000) | Acc: (93.00%) (46748/50000)
# TEST : Loss: (0.3946) | Acc: (87.00%) (8738/10000)
percent tensor([0.4996, 0.4997, 0.5078, 0.4980, 0.5080, 0.5037, 0.5025, 0.4990, 0.5001,
        0.5019, 0.5025, 0.5064, 0.4986, 0.4946, 0.5021, 0.4987],
       device='cuda:0') torch.Size([16])
percent tensor([0.4974, 0.4749, 0.5023, 0.5036, 0.4956, 0.5101, 0.4781, 0.4872, 0.4952,
        0.4838, 0.4930, 0.4919, 0.4811, 0.4871, 0.4901, 0.4986],
       device='cuda:0') torch.Size([16])
percent tensor([0.6326, 0.6417, 0.5574, 0.5488, 0.5738, 0.6160, 0.6333, 0.5815, 0.5795,
        0.5985, 0.6123, 0.5623, 0.6466, 0.5867, 0.6547, 0.6222],
       device='cuda:0') torch.Size([16])
percent tensor([0.6224, 0.6288, 0.6170, 0.6510, 0.6326, 0.7125, 0.6166, 0.6142, 0.6362,
        0.6066, 0.6251, 0.6460, 0.6291, 0.6378, 0.6663, 0.6556],
       device='cuda:0') torch.Size([16])
percent tensor([0.5627, 0.5704, 0.5603, 0.5491, 0.5973, 0.5635, 0.5801, 0.5241, 0.5937,
        0.5860, 0.6182, 0.5153, 0.5543, 0.6732, 0.4761, 0.6163],
       device='cuda:0') torch.Size([16])
percent tensor([0.5910, 0.5790, 0.6842, 0.6955, 0.7277, 0.6834, 0.6375, 0.6478, 0.6439,
        0.6210, 0.6239, 0.6577, 0.6081, 0.6460, 0.6022, 0.6250],
       device='cuda:0') torch.Size([16])
percent tensor([0.6065, 0.6953, 0.7079, 0.6570, 0.7214, 0.5105, 0.6115, 0.5437, 0.7258,
        0.7126, 0.7573, 0.6550, 0.6912, 0.6783, 0.5614, 0.4846],
       device='cuda:0') torch.Size([16])
percent tensor([0.9996, 0.9995, 0.9996, 0.9996, 0.9995, 0.9987, 0.9995, 0.9984, 0.9998,
        0.9997, 0.9999, 0.9996, 0.9997, 0.9991, 0.9982, 0.9991],
       device='cuda:0') torch.Size([16])
Epoch: 117 | Batch_idx: 0 |  Loss: (0.0973) |  Loss2: (0.0000) | Acc: (97.00%) (125/128)
Epoch: 117 | Batch_idx: 10 |  Loss: (0.1569) |  Loss2: (0.0000) | Acc: (95.00%) (1340/1408)
Epoch: 117 | Batch_idx: 20 |  Loss: (0.1595) |  Loss2: (0.0000) | Acc: (94.00%) (2548/2688)
Epoch: 117 | Batch_idx: 30 |  Loss: (0.1708) |  Loss2: (0.0000) | Acc: (94.00%) (3747/3968)
Epoch: 117 | Batch_idx: 40 |  Loss: (0.1725) |  Loss2: (0.0000) | Acc: (94.00%) (4953/5248)
Epoch: 117 | Batch_idx: 50 |  Loss: (0.1730) |  Loss2: (0.0000) | Acc: (94.00%) (6157/6528)
Epoch: 117 | Batch_idx: 60 |  Loss: (0.1750) |  Loss2: (0.0000) | Acc: (94.00%) (7356/7808)
Epoch: 117 | Batch_idx: 70 |  Loss: (0.1726) |  Loss2: (0.0000) | Acc: (94.00%) (8569/9088)
Epoch: 117 | Batch_idx: 80 |  Loss: (0.1719) |  Loss2: (0.0000) | Acc: (94.00%) (9775/10368)
Epoch: 117 | Batch_idx: 90 |  Loss: (0.1737) |  Loss2: (0.0000) | Acc: (94.00%) (10972/11648)
Epoch: 117 | Batch_idx: 100 |  Loss: (0.1722) |  Loss2: (0.0000) | Acc: (94.00%) (12183/12928)
Epoch: 117 | Batch_idx: 110 |  Loss: (0.1718) |  Loss2: (0.0000) | Acc: (94.00%) (13390/14208)
Epoch: 117 | Batch_idx: 120 |  Loss: (0.1720) |  Loss2: (0.0000) | Acc: (94.00%) (14585/15488)
Epoch: 117 | Batch_idx: 130 |  Loss: (0.1743) |  Loss2: (0.0000) | Acc: (94.00%) (15771/16768)
Epoch: 117 | Batch_idx: 140 |  Loss: (0.1744) |  Loss2: (0.0000) | Acc: (94.00%) (16978/18048)
Epoch: 117 | Batch_idx: 150 |  Loss: (0.1764) |  Loss2: (0.0000) | Acc: (94.00%) (18169/19328)
Epoch: 117 | Batch_idx: 160 |  Loss: (0.1777) |  Loss2: (0.0000) | Acc: (93.00%) (19361/20608)
Epoch: 117 | Batch_idx: 170 |  Loss: (0.1779) |  Loss2: (0.0000) | Acc: (93.00%) (20559/21888)
Epoch: 117 | Batch_idx: 180 |  Loss: (0.1788) |  Loss2: (0.0000) | Acc: (93.00%) (21751/23168)
Epoch: 117 | Batch_idx: 190 |  Loss: (0.1783) |  Loss2: (0.0000) | Acc: (93.00%) (22960/24448)
Epoch: 117 | Batch_idx: 200 |  Loss: (0.1787) |  Loss2: (0.0000) | Acc: (93.00%) (24149/25728)
Epoch: 117 | Batch_idx: 210 |  Loss: (0.1790) |  Loss2: (0.0000) | Acc: (93.00%) (25338/27008)
Epoch: 117 | Batch_idx: 220 |  Loss: (0.1791) |  Loss2: (0.0000) | Acc: (93.00%) (26539/28288)
Epoch: 117 | Batch_idx: 230 |  Loss: (0.1792) |  Loss2: (0.0000) | Acc: (93.00%) (27736/29568)
Epoch: 117 | Batch_idx: 240 |  Loss: (0.1802) |  Loss2: (0.0000) | Acc: (93.00%) (28922/30848)
Epoch: 117 | Batch_idx: 250 |  Loss: (0.1799) |  Loss2: (0.0000) | Acc: (93.00%) (30123/32128)
Epoch: 117 | Batch_idx: 260 |  Loss: (0.1799) |  Loss2: (0.0000) | Acc: (93.00%) (31327/33408)
Epoch: 117 | Batch_idx: 270 |  Loss: (0.1798) |  Loss2: (0.0000) | Acc: (93.00%) (32523/34688)
Epoch: 117 | Batch_idx: 280 |  Loss: (0.1795) |  Loss2: (0.0000) | Acc: (93.00%) (33734/35968)
Epoch: 117 | Batch_idx: 290 |  Loss: (0.1792) |  Loss2: (0.0000) | Acc: (93.00%) (34942/37248)
Epoch: 117 | Batch_idx: 300 |  Loss: (0.1792) |  Loss2: (0.0000) | Acc: (93.00%) (36141/38528)
Epoch: 117 | Batch_idx: 310 |  Loss: (0.1797) |  Loss2: (0.0000) | Acc: (93.00%) (37333/39808)
Epoch: 117 | Batch_idx: 320 |  Loss: (0.1801) |  Loss2: (0.0000) | Acc: (93.00%) (38532/41088)
Epoch: 117 | Batch_idx: 330 |  Loss: (0.1808) |  Loss2: (0.0000) | Acc: (93.00%) (39724/42368)
Epoch: 117 | Batch_idx: 340 |  Loss: (0.1807) |  Loss2: (0.0000) | Acc: (93.00%) (40928/43648)
Epoch: 117 | Batch_idx: 350 |  Loss: (0.1810) |  Loss2: (0.0000) | Acc: (93.00%) (42118/44928)
Epoch: 117 | Batch_idx: 360 |  Loss: (0.1814) |  Loss2: (0.0000) | Acc: (93.00%) (43317/46208)
Epoch: 117 | Batch_idx: 370 |  Loss: (0.1821) |  Loss2: (0.0000) | Acc: (93.00%) (44508/47488)
Epoch: 117 | Batch_idx: 380 |  Loss: (0.1817) |  Loss2: (0.0000) | Acc: (93.00%) (45717/48768)
Epoch: 117 | Batch_idx: 390 |  Loss: (0.1819) |  Loss2: (0.0000) | Acc: (93.00%) (46872/50000)
# TEST : Loss: (0.4366) | Acc: (86.00%) (8623/10000)
percent tensor([0.5004, 0.4990, 0.5087, 0.4979, 0.5092, 0.5051, 0.5022, 0.4990, 0.5001,
        0.5015, 0.5028, 0.5068, 0.4988, 0.4929, 0.5021, 0.4987],
       device='cuda:0') torch.Size([16])
percent tensor([0.4992, 0.4775, 0.5008, 0.5039, 0.4936, 0.5100, 0.4792, 0.4871, 0.4958,
        0.4848, 0.4953, 0.4904, 0.4825, 0.4892, 0.4914, 0.4997],
       device='cuda:0') torch.Size([16])
percent tensor([0.6311, 0.6341, 0.5735, 0.5547, 0.5832, 0.6099, 0.6348, 0.5844, 0.5768,
        0.6012, 0.6024, 0.5718, 0.6479, 0.5676, 0.6532, 0.6179],
       device='cuda:0') torch.Size([16])
percent tensor([0.6191, 0.6441, 0.6105, 0.6453, 0.6270, 0.7051, 0.6228, 0.6110, 0.6442,
        0.6128, 0.6360, 0.6460, 0.6314, 0.6560, 0.6681, 0.6562],
       device='cuda:0') torch.Size([16])
percent tensor([0.5626, 0.5813, 0.5686, 0.5558, 0.5991, 0.5638, 0.5874, 0.5301, 0.5949,
        0.5952, 0.6246, 0.5184, 0.5611, 0.6819, 0.4781, 0.6141],
       device='cuda:0') torch.Size([16])
percent tensor([0.5895, 0.5898, 0.6769, 0.6830, 0.7119, 0.6605, 0.6383, 0.6483, 0.6449,
        0.6272, 0.6214, 0.6614, 0.6149, 0.6471, 0.6008, 0.6217],
       device='cuda:0') torch.Size([16])
percent tensor([0.6023, 0.7011, 0.6951, 0.6592, 0.7092, 0.5193, 0.5994, 0.5467, 0.7268,
        0.7125, 0.7594, 0.6913, 0.6684, 0.6798, 0.5715, 0.4947],
       device='cuda:0') torch.Size([16])
percent tensor([0.9995, 0.9996, 0.9997, 0.9998, 0.9996, 0.9991, 0.9994, 0.9991, 0.9998,
        0.9998, 1.0000, 0.9998, 0.9997, 0.9993, 0.9982, 0.9988],
       device='cuda:0') torch.Size([16])
Epoch: 118 | Batch_idx: 0 |  Loss: (0.1449) |  Loss2: (0.0000) | Acc: (96.00%) (123/128)
Epoch: 118 | Batch_idx: 10 |  Loss: (0.1676) |  Loss2: (0.0000) | Acc: (95.00%) (1339/1408)
Epoch: 118 | Batch_idx: 20 |  Loss: (0.1706) |  Loss2: (0.0000) | Acc: (94.00%) (2535/2688)
Epoch: 118 | Batch_idx: 30 |  Loss: (0.1702) |  Loss2: (0.0000) | Acc: (94.00%) (3739/3968)
Epoch: 118 | Batch_idx: 40 |  Loss: (0.1682) |  Loss2: (0.0000) | Acc: (94.00%) (4950/5248)
Epoch: 118 | Batch_idx: 50 |  Loss: (0.1716) |  Loss2: (0.0000) | Acc: (94.00%) (6145/6528)
Epoch: 118 | Batch_idx: 60 |  Loss: (0.1738) |  Loss2: (0.0000) | Acc: (93.00%) (7337/7808)
Epoch: 118 | Batch_idx: 70 |  Loss: (0.1771) |  Loss2: (0.0000) | Acc: (93.00%) (8536/9088)
Epoch: 118 | Batch_idx: 80 |  Loss: (0.1726) |  Loss2: (0.0000) | Acc: (94.00%) (9752/10368)
Epoch: 118 | Batch_idx: 90 |  Loss: (0.1709) |  Loss2: (0.0000) | Acc: (94.00%) (10961/11648)
Epoch: 118 | Batch_idx: 100 |  Loss: (0.1696) |  Loss2: (0.0000) | Acc: (94.00%) (12171/12928)
Epoch: 118 | Batch_idx: 110 |  Loss: (0.1707) |  Loss2: (0.0000) | Acc: (94.00%) (13370/14208)
Epoch: 118 | Batch_idx: 120 |  Loss: (0.1697) |  Loss2: (0.0000) | Acc: (94.00%) (14587/15488)
Epoch: 118 | Batch_idx: 130 |  Loss: (0.1705) |  Loss2: (0.0000) | Acc: (94.00%) (15788/16768)
Epoch: 118 | Batch_idx: 140 |  Loss: (0.1710) |  Loss2: (0.0000) | Acc: (94.00%) (16986/18048)
Epoch: 118 | Batch_idx: 150 |  Loss: (0.1711) |  Loss2: (0.0000) | Acc: (94.00%) (18197/19328)
Epoch: 118 | Batch_idx: 160 |  Loss: (0.1708) |  Loss2: (0.0000) | Acc: (94.00%) (19411/20608)
Epoch: 118 | Batch_idx: 170 |  Loss: (0.1705) |  Loss2: (0.0000) | Acc: (94.00%) (20616/21888)
Epoch: 118 | Batch_idx: 180 |  Loss: (0.1709) |  Loss2: (0.0000) | Acc: (94.00%) (21820/23168)
Epoch: 118 | Batch_idx: 190 |  Loss: (0.1719) |  Loss2: (0.0000) | Acc: (94.00%) (23025/24448)
Epoch: 118 | Batch_idx: 200 |  Loss: (0.1716) |  Loss2: (0.0000) | Acc: (94.00%) (24235/25728)
Epoch: 118 | Batch_idx: 210 |  Loss: (0.1716) |  Loss2: (0.0000) | Acc: (94.00%) (25445/27008)
Epoch: 118 | Batch_idx: 220 |  Loss: (0.1704) |  Loss2: (0.0000) | Acc: (94.00%) (26650/28288)
Epoch: 118 | Batch_idx: 230 |  Loss: (0.1706) |  Loss2: (0.0000) | Acc: (94.00%) (27844/29568)
Epoch: 118 | Batch_idx: 240 |  Loss: (0.1719) |  Loss2: (0.0000) | Acc: (94.00%) (29030/30848)
Epoch: 118 | Batch_idx: 250 |  Loss: (0.1714) |  Loss2: (0.0000) | Acc: (94.00%) (30239/32128)
Epoch: 118 | Batch_idx: 260 |  Loss: (0.1719) |  Loss2: (0.0000) | Acc: (94.00%) (31439/33408)
Epoch: 118 | Batch_idx: 270 |  Loss: (0.1717) |  Loss2: (0.0000) | Acc: (94.00%) (32650/34688)
Epoch: 118 | Batch_idx: 280 |  Loss: (0.1717) |  Loss2: (0.0000) | Acc: (94.00%) (33856/35968)
Epoch: 118 | Batch_idx: 290 |  Loss: (0.1718) |  Loss2: (0.0000) | Acc: (94.00%) (35054/37248)
Epoch: 118 | Batch_idx: 300 |  Loss: (0.1713) |  Loss2: (0.0000) | Acc: (94.00%) (36265/38528)
Epoch: 118 | Batch_idx: 310 |  Loss: (0.1713) |  Loss2: (0.0000) | Acc: (94.00%) (37475/39808)
Epoch: 118 | Batch_idx: 320 |  Loss: (0.1721) |  Loss2: (0.0000) | Acc: (94.00%) (38666/41088)
Epoch: 118 | Batch_idx: 330 |  Loss: (0.1728) |  Loss2: (0.0000) | Acc: (94.00%) (39865/42368)
Epoch: 118 | Batch_idx: 340 |  Loss: (0.1734) |  Loss2: (0.0000) | Acc: (94.00%) (41061/43648)
Epoch: 118 | Batch_idx: 350 |  Loss: (0.1730) |  Loss2: (0.0000) | Acc: (94.00%) (42273/44928)
Epoch: 118 | Batch_idx: 360 |  Loss: (0.1730) |  Loss2: (0.0000) | Acc: (94.00%) (43475/46208)
Epoch: 118 | Batch_idx: 370 |  Loss: (0.1736) |  Loss2: (0.0000) | Acc: (94.00%) (44677/47488)
Epoch: 118 | Batch_idx: 380 |  Loss: (0.1733) |  Loss2: (0.0000) | Acc: (94.00%) (45886/48768)
Epoch: 118 | Batch_idx: 390 |  Loss: (0.1740) |  Loss2: (0.0000) | Acc: (94.00%) (47026/50000)
# TEST : Loss: (0.4305) | Acc: (86.00%) (8677/10000)
percent tensor([0.5004, 0.4996, 0.5096, 0.4988, 0.5096, 0.5049, 0.5026, 0.4994, 0.5002,
        0.5019, 0.5025, 0.5070, 0.4989, 0.4937, 0.5024, 0.4989],
       device='cuda:0') torch.Size([16])
percent tensor([0.4992, 0.4779, 0.5013, 0.5028, 0.4944, 0.5103, 0.4793, 0.4863, 0.4960,
        0.4851, 0.4958, 0.4917, 0.4822, 0.4909, 0.4919, 0.4990],
       device='cuda:0') torch.Size([16])
percent tensor([0.6301, 0.6364, 0.5691, 0.5568, 0.5794, 0.6064, 0.6339, 0.5860, 0.5816,
        0.6003, 0.6017, 0.5665, 0.6502, 0.5741, 0.6539, 0.6210],
       device='cuda:0') torch.Size([16])
percent tensor([0.6194, 0.6312, 0.6103, 0.6589, 0.6274, 0.7183, 0.6156, 0.6065, 0.6381,
        0.6076, 0.6316, 0.6408, 0.6195, 0.6446, 0.6728, 0.6572],
       device='cuda:0') torch.Size([16])
percent tensor([0.5743, 0.5736, 0.5634, 0.5419, 0.5959, 0.5605, 0.5808, 0.5332, 0.6037,
        0.5923, 0.6350, 0.5192, 0.5626, 0.6864, 0.4793, 0.6181],
       device='cuda:0') torch.Size([16])
percent tensor([0.5880, 0.5707, 0.6711, 0.6841, 0.7041, 0.6742, 0.6290, 0.6374, 0.6354,
        0.6083, 0.6207, 0.6484, 0.5972, 0.6488, 0.5949, 0.6231],
       device='cuda:0') torch.Size([16])
percent tensor([0.5652, 0.6675, 0.6957, 0.6144, 0.6775, 0.4826, 0.5797, 0.5271, 0.6916,
        0.6760, 0.7240, 0.6610, 0.6402, 0.6537, 0.5158, 0.4766],
       device='cuda:0') torch.Size([16])
percent tensor([0.9994, 0.9994, 0.9997, 0.9996, 0.9990, 0.9995, 0.9993, 0.9990, 0.9996,
        0.9996, 0.9999, 0.9996, 0.9995, 0.9990, 0.9983, 0.9990],
       device='cuda:0') torch.Size([16])
Epoch: 119 | Batch_idx: 0 |  Loss: (0.1709) |  Loss2: (0.0000) | Acc: (95.00%) (122/128)
Epoch: 119 | Batch_idx: 10 |  Loss: (0.1870) |  Loss2: (0.0000) | Acc: (93.00%) (1311/1408)
Epoch: 119 | Batch_idx: 20 |  Loss: (0.1733) |  Loss2: (0.0000) | Acc: (93.00%) (2516/2688)
Epoch: 119 | Batch_idx: 30 |  Loss: (0.1689) |  Loss2: (0.0000) | Acc: (94.00%) (3731/3968)
Epoch: 119 | Batch_idx: 40 |  Loss: (0.1659) |  Loss2: (0.0000) | Acc: (94.00%) (4944/5248)
Epoch: 119 | Batch_idx: 50 |  Loss: (0.1697) |  Loss2: (0.0000) | Acc: (93.00%) (6136/6528)
Epoch: 119 | Batch_idx: 60 |  Loss: (0.1708) |  Loss2: (0.0000) | Acc: (93.00%) (7338/7808)
Epoch: 119 | Batch_idx: 70 |  Loss: (0.1684) |  Loss2: (0.0000) | Acc: (94.00%) (8551/9088)
Epoch: 119 | Batch_idx: 80 |  Loss: (0.1666) |  Loss2: (0.0000) | Acc: (94.00%) (9770/10368)
Epoch: 119 | Batch_idx: 90 |  Loss: (0.1626) |  Loss2: (0.0000) | Acc: (94.00%) (10997/11648)
Epoch: 119 | Batch_idx: 100 |  Loss: (0.1645) |  Loss2: (0.0000) | Acc: (94.00%) (12195/12928)
Epoch: 119 | Batch_idx: 110 |  Loss: (0.1644) |  Loss2: (0.0000) | Acc: (94.00%) (13402/14208)
Epoch: 119 | Batch_idx: 120 |  Loss: (0.1649) |  Loss2: (0.0000) | Acc: (94.00%) (14609/15488)
Epoch: 119 | Batch_idx: 130 |  Loss: (0.1675) |  Loss2: (0.0000) | Acc: (94.00%) (15799/16768)
Epoch: 119 | Batch_idx: 140 |  Loss: (0.1672) |  Loss2: (0.0000) | Acc: (94.00%) (17003/18048)
Epoch: 119 | Batch_idx: 150 |  Loss: (0.1670) |  Loss2: (0.0000) | Acc: (94.00%) (18207/19328)
Epoch: 119 | Batch_idx: 160 |  Loss: (0.1687) |  Loss2: (0.0000) | Acc: (94.00%) (19398/20608)
Epoch: 119 | Batch_idx: 170 |  Loss: (0.1700) |  Loss2: (0.0000) | Acc: (94.00%) (20585/21888)
Epoch: 119 | Batch_idx: 180 |  Loss: (0.1703) |  Loss2: (0.0000) | Acc: (94.00%) (21794/23168)
Epoch: 119 | Batch_idx: 190 |  Loss: (0.1715) |  Loss2: (0.0000) | Acc: (94.00%) (22992/24448)
Epoch: 119 | Batch_idx: 200 |  Loss: (0.1728) |  Loss2: (0.0000) | Acc: (93.00%) (24183/25728)
Epoch: 119 | Batch_idx: 210 |  Loss: (0.1735) |  Loss2: (0.0000) | Acc: (93.00%) (25375/27008)
Epoch: 119 | Batch_idx: 220 |  Loss: (0.1728) |  Loss2: (0.0000) | Acc: (93.00%) (26586/28288)
Epoch: 119 | Batch_idx: 230 |  Loss: (0.1728) |  Loss2: (0.0000) | Acc: (93.00%) (27791/29568)
Epoch: 119 | Batch_idx: 240 |  Loss: (0.1727) |  Loss2: (0.0000) | Acc: (93.00%) (28995/30848)
Epoch: 119 | Batch_idx: 250 |  Loss: (0.1739) |  Loss2: (0.0000) | Acc: (93.00%) (30183/32128)
Epoch: 119 | Batch_idx: 260 |  Loss: (0.1738) |  Loss2: (0.0000) | Acc: (93.00%) (31391/33408)
Epoch: 119 | Batch_idx: 270 |  Loss: (0.1737) |  Loss2: (0.0000) | Acc: (93.00%) (32592/34688)
Epoch: 119 | Batch_idx: 280 |  Loss: (0.1736) |  Loss2: (0.0000) | Acc: (93.00%) (33799/35968)
Epoch: 119 | Batch_idx: 290 |  Loss: (0.1740) |  Loss2: (0.0000) | Acc: (93.00%) (35000/37248)
Epoch: 119 | Batch_idx: 300 |  Loss: (0.1737) |  Loss2: (0.0000) | Acc: (93.00%) (36206/38528)
Epoch: 119 | Batch_idx: 310 |  Loss: (0.1738) |  Loss2: (0.0000) | Acc: (93.00%) (37408/39808)
Epoch: 119 | Batch_idx: 320 |  Loss: (0.1735) |  Loss2: (0.0000) | Acc: (93.00%) (38617/41088)
Epoch: 119 | Batch_idx: 330 |  Loss: (0.1735) |  Loss2: (0.0000) | Acc: (93.00%) (39820/42368)
Epoch: 119 | Batch_idx: 340 |  Loss: (0.1739) |  Loss2: (0.0000) | Acc: (93.00%) (41024/43648)
Epoch: 119 | Batch_idx: 350 |  Loss: (0.1738) |  Loss2: (0.0000) | Acc: (93.00%) (42232/44928)
Epoch: 119 | Batch_idx: 360 |  Loss: (0.1739) |  Loss2: (0.0000) | Acc: (94.00%) (43440/46208)
Epoch: 119 | Batch_idx: 370 |  Loss: (0.1744) |  Loss2: (0.0000) | Acc: (93.00%) (44629/47488)
Epoch: 119 | Batch_idx: 380 |  Loss: (0.1749) |  Loss2: (0.0000) | Acc: (93.00%) (45824/48768)
Epoch: 119 | Batch_idx: 390 |  Loss: (0.1749) |  Loss2: (0.0000) | Acc: (93.00%) (46968/50000)
# TEST : Loss: (0.4049) | Acc: (87.00%) (8742/10000)
percent tensor([0.5005, 0.4987, 0.5109, 0.4987, 0.5106, 0.5051, 0.5026, 0.4996, 0.5000,
        0.5021, 0.5020, 0.5078, 0.4990, 0.4918, 0.5021, 0.4987],
       device='cuda:0') torch.Size([16])
percent tensor([0.4983, 0.4766, 0.4967, 0.5006, 0.4924, 0.5094, 0.4782, 0.4851, 0.4952,
        0.4838, 0.4935, 0.4872, 0.4818, 0.4862, 0.4894, 0.4985],
       device='cuda:0') torch.Size([16])
percent tensor([0.6294, 0.6429, 0.5604, 0.5514, 0.5721, 0.6088, 0.6367, 0.5807, 0.5744,
        0.5999, 0.6050, 0.5646, 0.6454, 0.5949, 0.6583, 0.6182],
       device='cuda:0') torch.Size([16])
percent tensor([0.6186, 0.6364, 0.6113, 0.6560, 0.6285, 0.7092, 0.6232, 0.6124, 0.6355,
        0.6159, 0.6285, 0.6520, 0.6210, 0.6461, 0.6697, 0.6550],
       device='cuda:0') torch.Size([16])
percent tensor([0.5630, 0.5682, 0.5430, 0.5386, 0.5865, 0.5567, 0.5772, 0.5250, 0.5921,
        0.5766, 0.6133, 0.5003, 0.5458, 0.6671, 0.4710, 0.6108],
       device='cuda:0') torch.Size([16])
percent tensor([0.5873, 0.5762, 0.6711, 0.6798, 0.7001, 0.6614, 0.6345, 0.6377, 0.6286,
        0.6179, 0.6147, 0.6582, 0.6024, 0.6474, 0.6024, 0.6190],
       device='cuda:0') torch.Size([16])
percent tensor([0.5798, 0.6975, 0.6831, 0.6196, 0.6793, 0.4796, 0.5847, 0.5335, 0.7098,
        0.7016, 0.7522, 0.6678, 0.6815, 0.6690, 0.5447, 0.4790],
       device='cuda:0') torch.Size([16])
percent tensor([0.9995, 0.9996, 0.9996, 0.9994, 0.9994, 0.9993, 0.9996, 0.9995, 0.9997,
        0.9998, 0.9999, 0.9998, 0.9998, 0.9995, 0.9982, 0.9989],
       device='cuda:0') torch.Size([16])
False Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=128, out_features=16, bias=False)
True Linear(in_features=16, out_features=2, bias=False)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=128, out_features=16, bias=False)
True Linear(in_features=16, out_features=2, bias=False)
False Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=256, out_features=32, bias=False)
True Linear(in_features=32, out_features=2, bias=False)
False Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=256, out_features=32, bias=False)
True Linear(in_features=32, out_features=2, bias=False)
False Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=512, out_features=64, bias=False)
True Linear(in_features=64, out_features=2, bias=False)
False Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=512, out_features=64, bias=False)
True Linear(in_features=64, out_features=2, bias=False)
False Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1024, out_features=128, bias=False)
True Linear(in_features=128, out_features=2, bias=False)
False Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1024, out_features=128, bias=False)
True Linear(in_features=128, out_features=2, bias=False)
False Linear(in_features=512, out_features=10, bias=True)
Epoch: 120 | Batch_idx: 0 |  Loss: (0.1375) |  Loss2: (0.0000) | Acc: (94.00%) (121/128)
Epoch: 120 | Batch_idx: 10 |  Loss: (0.1768) |  Loss2: (0.0000) | Acc: (93.00%) (1322/1408)
Epoch: 120 | Batch_idx: 20 |  Loss: (0.2019) |  Loss2: (0.0000) | Acc: (93.00%) (2503/2688)
Epoch: 120 | Batch_idx: 30 |  Loss: (0.2128) |  Loss2: (0.0000) | Acc: (92.00%) (3673/3968)
Epoch: 120 | Batch_idx: 40 |  Loss: (0.2185) |  Loss2: (0.0000) | Acc: (92.00%) (4851/5248)
Epoch: 120 | Batch_idx: 50 |  Loss: (0.2237) |  Loss2: (0.0000) | Acc: (92.00%) (6018/6528)
Epoch: 120 | Batch_idx: 60 |  Loss: (0.2239) |  Loss2: (0.0000) | Acc: (92.00%) (7196/7808)
Epoch: 120 | Batch_idx: 70 |  Loss: (0.2243) |  Loss2: (0.0000) | Acc: (92.00%) (8367/9088)
Epoch: 120 | Batch_idx: 80 |  Loss: (0.2240) |  Loss2: (0.0000) | Acc: (92.00%) (9544/10368)
Epoch: 120 | Batch_idx: 90 |  Loss: (0.2234) |  Loss2: (0.0000) | Acc: (92.00%) (10717/11648)
Epoch: 120 | Batch_idx: 100 |  Loss: (0.2215) |  Loss2: (0.0000) | Acc: (92.00%) (11907/12928)
Epoch: 120 | Batch_idx: 110 |  Loss: (0.2218) |  Loss2: (0.0000) | Acc: (92.00%) (13097/14208)
Epoch: 120 | Batch_idx: 120 |  Loss: (0.2204) |  Loss2: (0.0000) | Acc: (92.00%) (14289/15488)
Epoch: 120 | Batch_idx: 130 |  Loss: (0.2217) |  Loss2: (0.0000) | Acc: (92.00%) (15464/16768)
Epoch: 120 | Batch_idx: 140 |  Loss: (0.2205) |  Loss2: (0.0000) | Acc: (92.00%) (16655/18048)
Epoch: 120 | Batch_idx: 150 |  Loss: (0.2221) |  Loss2: (0.0000) | Acc: (92.00%) (17824/19328)
Epoch: 120 | Batch_idx: 160 |  Loss: (0.2208) |  Loss2: (0.0000) | Acc: (92.00%) (19011/20608)
Epoch: 120 | Batch_idx: 170 |  Loss: (0.2198) |  Loss2: (0.0000) | Acc: (92.00%) (20187/21888)
Epoch: 120 | Batch_idx: 180 |  Loss: (0.2200) |  Loss2: (0.0000) | Acc: (92.00%) (21367/23168)
Epoch: 120 | Batch_idx: 190 |  Loss: (0.2187) |  Loss2: (0.0000) | Acc: (92.00%) (22549/24448)
Epoch: 120 | Batch_idx: 200 |  Loss: (0.2180) |  Loss2: (0.0000) | Acc: (92.00%) (23741/25728)
Epoch: 120 | Batch_idx: 210 |  Loss: (0.2180) |  Loss2: (0.0000) | Acc: (92.00%) (24920/27008)
Epoch: 120 | Batch_idx: 220 |  Loss: (0.2177) |  Loss2: (0.0000) | Acc: (92.00%) (26105/28288)
Epoch: 120 | Batch_idx: 230 |  Loss: (0.2165) |  Loss2: (0.0000) | Acc: (92.00%) (27303/29568)
Epoch: 120 | Batch_idx: 240 |  Loss: (0.2157) |  Loss2: (0.0000) | Acc: (92.00%) (28500/30848)
Epoch: 120 | Batch_idx: 250 |  Loss: (0.2151) |  Loss2: (0.0000) | Acc: (92.00%) (29680/32128)
Epoch: 120 | Batch_idx: 260 |  Loss: (0.2155) |  Loss2: (0.0000) | Acc: (92.00%) (30867/33408)
Epoch: 120 | Batch_idx: 270 |  Loss: (0.2141) |  Loss2: (0.0000) | Acc: (92.00%) (32067/34688)
Epoch: 120 | Batch_idx: 280 |  Loss: (0.2134) |  Loss2: (0.0000) | Acc: (92.00%) (33252/35968)
Epoch: 120 | Batch_idx: 290 |  Loss: (0.2132) |  Loss2: (0.0000) | Acc: (92.00%) (34447/37248)
Epoch: 120 | Batch_idx: 300 |  Loss: (0.2130) |  Loss2: (0.0000) | Acc: (92.00%) (35634/38528)
Epoch: 120 | Batch_idx: 310 |  Loss: (0.2127) |  Loss2: (0.0000) | Acc: (92.00%) (36820/39808)
Epoch: 120 | Batch_idx: 320 |  Loss: (0.2121) |  Loss2: (0.0000) | Acc: (92.00%) (38009/41088)
Epoch: 120 | Batch_idx: 330 |  Loss: (0.2122) |  Loss2: (0.0000) | Acc: (92.00%) (39200/42368)
Epoch: 120 | Batch_idx: 340 |  Loss: (0.2118) |  Loss2: (0.0000) | Acc: (92.00%) (40378/43648)
Epoch: 120 | Batch_idx: 350 |  Loss: (0.2112) |  Loss2: (0.0000) | Acc: (92.00%) (41580/44928)
Epoch: 120 | Batch_idx: 360 |  Loss: (0.2103) |  Loss2: (0.0000) | Acc: (92.00%) (42784/46208)
Epoch: 120 | Batch_idx: 370 |  Loss: (0.2100) |  Loss2: (0.0000) | Acc: (92.00%) (43976/47488)
Epoch: 120 | Batch_idx: 380 |  Loss: (0.2097) |  Loss2: (0.0000) | Acc: (92.00%) (45165/48768)
Epoch: 120 | Batch_idx: 390 |  Loss: (0.2088) |  Loss2: (0.0000) | Acc: (92.00%) (46322/50000)
=> saving checkpoint 'drive/app/torch/save_Schedule/checkpoint_120.pth.tar'
# TEST : Loss: (0.4099) | Acc: (87.00%) (8717/10000)
percent tensor([0.4967, 0.4953, 0.5058, 0.4940, 0.5054, 0.5004, 0.4988, 0.4957, 0.4962,
        0.4984, 0.4982, 0.5036, 0.4955, 0.4903, 0.4978, 0.4949],
       device='cuda:0') torch.Size([16])
percent tensor([0.5072, 0.4887, 0.5087, 0.5075, 0.5070, 0.5121, 0.4927, 0.4963, 0.5071,
        0.4953, 0.5069, 0.5020, 0.4957, 0.4953, 0.5025, 0.5068],
       device='cuda:0') torch.Size([16])
percent tensor([0.6238, 0.6383, 0.5576, 0.5501, 0.5702, 0.5981, 0.6287, 0.5884, 0.5834,
        0.5903, 0.6090, 0.5631, 0.6358, 0.5938, 0.6512, 0.6106],
       device='cuda:0') torch.Size([16])
percent tensor([0.6296, 0.6453, 0.6265, 0.6665, 0.6338, 0.7147, 0.6327, 0.6195, 0.6471,
        0.6234, 0.6384, 0.6654, 0.6323, 0.6561, 0.6726, 0.6603],
       device='cuda:0') torch.Size([16])
percent tensor([0.5774, 0.5935, 0.5589, 0.5517, 0.5994, 0.5574, 0.5933, 0.5440, 0.6241,
        0.5956, 0.6366, 0.5300, 0.5702, 0.7049, 0.4853, 0.6139],
       device='cuda:0') torch.Size([16])
percent tensor([0.5781, 0.5602, 0.6741, 0.6892, 0.7060, 0.6699, 0.6196, 0.6379, 0.6248,
        0.5996, 0.6024, 0.6531, 0.5832, 0.6391, 0.5871, 0.6104],
       device='cuda:0') torch.Size([16])
percent tensor([0.5667, 0.6960, 0.7085, 0.6588, 0.7093, 0.5394, 0.5732, 0.5384, 0.7174,
        0.6759, 0.7528, 0.6657, 0.6837, 0.6633, 0.5586, 0.4740],
       device='cuda:0') torch.Size([16])
percent tensor([0.9994, 0.9996, 0.9996, 0.9994, 0.9995, 0.9994, 0.9996, 0.9993, 0.9995,
        0.9997, 0.9999, 0.9998, 0.9998, 0.9993, 0.9985, 0.9988],
       device='cuda:0') torch.Size([16])
Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 3, 3, 3]) tensor(189.2896, device='cuda:0')
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(818.8149, device='cuda:0')
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(821.8392, device='cuda:0')
Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([128, 64, 3, 3]) tensor(1532.8267, device='cuda:0')
Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([128, 64, 1, 1]) tensor(488.7348, device='cuda:0')
Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([128, 128, 3, 3]) tensor(2286.3992, device='cuda:0')
Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([256, 128, 3, 3]) tensor(4283.9844, device='cuda:0')
Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([256, 128, 1, 1]) tensor(1382.5051, device='cuda:0')
Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([256, 256, 3, 3]) tensor(6181.2046, device='cuda:0')
Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([512, 256, 3, 3]) tensor(11799.9248, device='cuda:0')
Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([512, 256, 1, 1]) tensor(3910.8120, device='cuda:0')
Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([512, 512, 3, 3]) tensor(16513.8789, device='cuda:0')
Epoch: 121 | Batch_idx: 0 |  Loss: (0.2433) |  Loss2: (0.0000) | Acc: (92.00%) (118/128)
Epoch: 121 | Batch_idx: 10 |  Loss: (0.1981) |  Loss2: (0.0000) | Acc: (92.00%) (1302/1408)
Epoch: 121 | Batch_idx: 20 |  Loss: (0.2147) |  Loss2: (0.0000) | Acc: (92.00%) (2474/2688)
Epoch: 121 | Batch_idx: 30 |  Loss: (0.2094) |  Loss2: (0.0000) | Acc: (92.00%) (3662/3968)
Epoch: 121 | Batch_idx: 40 |  Loss: (0.2103) |  Loss2: (0.0000) | Acc: (92.00%) (4847/5248)
Epoch: 121 | Batch_idx: 50 |  Loss: (0.2145) |  Loss2: (0.0000) | Acc: (92.00%) (6018/6528)
Epoch: 121 | Batch_idx: 60 |  Loss: (0.2108) |  Loss2: (0.0000) | Acc: (92.00%) (7219/7808)
Epoch: 121 | Batch_idx: 70 |  Loss: (0.2071) |  Loss2: (0.0000) | Acc: (92.00%) (8416/9088)
Epoch: 121 | Batch_idx: 80 |  Loss: (0.2064) |  Loss2: (0.0000) | Acc: (92.00%) (9596/10368)
Epoch: 121 | Batch_idx: 90 |  Loss: (0.2072) |  Loss2: (0.0000) | Acc: (92.00%) (10782/11648)
Epoch: 121 | Batch_idx: 100 |  Loss: (0.2011) |  Loss2: (0.0000) | Acc: (92.00%) (12004/12928)
Epoch: 121 | Batch_idx: 110 |  Loss: (0.1991) |  Loss2: (0.0000) | Acc: (92.00%) (13206/14208)
Epoch: 121 | Batch_idx: 120 |  Loss: (0.1971) |  Loss2: (0.0000) | Acc: (93.00%) (14411/15488)
Epoch: 121 | Batch_idx: 130 |  Loss: (0.1970) |  Loss2: (0.0000) | Acc: (93.00%) (15602/16768)
Epoch: 121 | Batch_idx: 140 |  Loss: (0.1960) |  Loss2: (0.0000) | Acc: (93.00%) (16796/18048)
Epoch: 121 | Batch_idx: 150 |  Loss: (0.1960) |  Loss2: (0.0000) | Acc: (93.00%) (17984/19328)
Epoch: 121 | Batch_idx: 160 |  Loss: (0.1956) |  Loss2: (0.0000) | Acc: (93.00%) (19172/20608)
Epoch: 121 | Batch_idx: 170 |  Loss: (0.1949) |  Loss2: (0.0000) | Acc: (93.00%) (20368/21888)
Epoch: 121 | Batch_idx: 180 |  Loss: (0.1929) |  Loss2: (0.0000) | Acc: (93.00%) (21581/23168)
Epoch: 121 | Batch_idx: 190 |  Loss: (0.1928) |  Loss2: (0.0000) | Acc: (93.00%) (22772/24448)
Epoch: 121 | Batch_idx: 200 |  Loss: (0.1914) |  Loss2: (0.0000) | Acc: (93.00%) (23973/25728)
Epoch: 121 | Batch_idx: 210 |  Loss: (0.1922) |  Loss2: (0.0000) | Acc: (93.00%) (25158/27008)
Epoch: 121 | Batch_idx: 220 |  Loss: (0.1921) |  Loss2: (0.0000) | Acc: (93.00%) (26353/28288)
Epoch: 121 | Batch_idx: 230 |  Loss: (0.1922) |  Loss2: (0.0000) | Acc: (93.00%) (27544/29568)
Epoch: 121 | Batch_idx: 240 |  Loss: (0.1917) |  Loss2: (0.0000) | Acc: (93.00%) (28740/30848)
Epoch: 121 | Batch_idx: 250 |  Loss: (0.1919) |  Loss2: (0.0000) | Acc: (93.00%) (29932/32128)
Epoch: 121 | Batch_idx: 260 |  Loss: (0.1916) |  Loss2: (0.0000) | Acc: (93.00%) (31133/33408)
Epoch: 121 | Batch_idx: 270 |  Loss: (0.1908) |  Loss2: (0.0000) | Acc: (93.00%) (32343/34688)
Epoch: 121 | Batch_idx: 280 |  Loss: (0.1907) |  Loss2: (0.0000) | Acc: (93.00%) (33530/35968)
Epoch: 121 | Batch_idx: 290 |  Loss: (0.1902) |  Loss2: (0.0000) | Acc: (93.00%) (34738/37248)
Epoch: 121 | Batch_idx: 300 |  Loss: (0.1893) |  Loss2: (0.0000) | Acc: (93.00%) (35946/38528)
Epoch: 121 | Batch_idx: 310 |  Loss: (0.1886) |  Loss2: (0.0000) | Acc: (93.00%) (37144/39808)
Epoch: 121 | Batch_idx: 320 |  Loss: (0.1887) |  Loss2: (0.0000) | Acc: (93.00%) (38348/41088)
Epoch: 121 | Batch_idx: 330 |  Loss: (0.1887) |  Loss2: (0.0000) | Acc: (93.00%) (39546/42368)
Epoch: 121 | Batch_idx: 340 |  Loss: (0.1883) |  Loss2: (0.0000) | Acc: (93.00%) (40749/43648)
Epoch: 121 | Batch_idx: 350 |  Loss: (0.1878) |  Loss2: (0.0000) | Acc: (93.00%) (41943/44928)
Epoch: 121 | Batch_idx: 360 |  Loss: (0.1881) |  Loss2: (0.0000) | Acc: (93.00%) (43125/46208)
Epoch: 121 | Batch_idx: 370 |  Loss: (0.1881) |  Loss2: (0.0000) | Acc: (93.00%) (44323/47488)
Epoch: 121 | Batch_idx: 380 |  Loss: (0.1876) |  Loss2: (0.0000) | Acc: (93.00%) (45529/48768)
Epoch: 121 | Batch_idx: 390 |  Loss: (0.1873) |  Loss2: (0.0000) | Acc: (93.00%) (46687/50000)
# TEST : Loss: (0.3984) | Acc: (87.00%) (8750/10000)
percent tensor([0.4970, 0.4957, 0.5059, 0.4944, 0.5054, 0.5001, 0.4991, 0.4964, 0.4967,
        0.4989, 0.4986, 0.5037, 0.4960, 0.4909, 0.4979, 0.4953],
       device='cuda:0') torch.Size([16])
percent tensor([0.5088, 0.4911, 0.5103, 0.5093, 0.5082, 0.5137, 0.4951, 0.4986, 0.5092,
        0.4973, 0.5095, 0.5041, 0.4975, 0.4990, 0.5044, 0.5084],
       device='cuda:0') torch.Size([16])
percent tensor([0.6250, 0.6337, 0.5605, 0.5495, 0.5717, 0.5965, 0.6267, 0.5885, 0.5851,
        0.5887, 0.6085, 0.5636, 0.6369, 0.5856, 0.6488, 0.6080],
       device='cuda:0') torch.Size([16])
percent tensor([0.6312, 0.6460, 0.6281, 0.6681, 0.6327, 0.7196, 0.6327, 0.6169, 0.6507,
        0.6247, 0.6418, 0.6666, 0.6353, 0.6597, 0.6735, 0.6621],
       device='cuda:0') torch.Size([16])
percent tensor([0.5601, 0.5747, 0.5505, 0.5425, 0.5897, 0.5364, 0.5795, 0.5358, 0.6181,
        0.5833, 0.6257, 0.5200, 0.5601, 0.6994, 0.4658, 0.5941],
       device='cuda:0') torch.Size([16])
percent tensor([0.5792, 0.5559, 0.6794, 0.6937, 0.7122, 0.6766, 0.6191, 0.6425, 0.6254,
        0.5981, 0.5985, 0.6537, 0.5817, 0.6331, 0.5921, 0.6121],
       device='cuda:0') torch.Size([16])
percent tensor([0.5697, 0.7072, 0.7221, 0.6671, 0.7176, 0.5560, 0.5727, 0.5468, 0.7234,
        0.6769, 0.7534, 0.6674, 0.6885, 0.6599, 0.5711, 0.4705],
       device='cuda:0') torch.Size([16])
percent tensor([0.9994, 0.9995, 0.9996, 0.9995, 0.9995, 0.9994, 0.9995, 0.9993, 0.9996,
        0.9997, 0.9999, 0.9998, 0.9998, 0.9993, 0.9985, 0.9988],
       device='cuda:0') torch.Size([16])
Epoch: 122 | Batch_idx: 0 |  Loss: (0.1869) |  Loss2: (0.0000) | Acc: (93.00%) (120/128)
Epoch: 122 | Batch_idx: 10 |  Loss: (0.1699) |  Loss2: (0.0000) | Acc: (93.00%) (1316/1408)
Epoch: 122 | Batch_idx: 20 |  Loss: (0.1765) |  Loss2: (0.0000) | Acc: (93.00%) (2518/2688)
Epoch: 122 | Batch_idx: 30 |  Loss: (0.1845) |  Loss2: (0.0000) | Acc: (93.00%) (3701/3968)
Epoch: 122 | Batch_idx: 40 |  Loss: (0.1810) |  Loss2: (0.0000) | Acc: (93.00%) (4900/5248)
Epoch: 122 | Batch_idx: 50 |  Loss: (0.1794) |  Loss2: (0.0000) | Acc: (93.00%) (6096/6528)
Epoch: 122 | Batch_idx: 60 |  Loss: (0.1810) |  Loss2: (0.0000) | Acc: (93.00%) (7297/7808)
Epoch: 122 | Batch_idx: 70 |  Loss: (0.1837) |  Loss2: (0.0000) | Acc: (93.00%) (8487/9088)
Epoch: 122 | Batch_idx: 80 |  Loss: (0.1826) |  Loss2: (0.0000) | Acc: (93.00%) (9699/10368)
Epoch: 122 | Batch_idx: 90 |  Loss: (0.1841) |  Loss2: (0.0000) | Acc: (93.00%) (10892/11648)
Epoch: 122 | Batch_idx: 100 |  Loss: (0.1842) |  Loss2: (0.0000) | Acc: (93.00%) (12087/12928)
Epoch: 122 | Batch_idx: 110 |  Loss: (0.1826) |  Loss2: (0.0000) | Acc: (93.00%) (13289/14208)
Epoch: 122 | Batch_idx: 120 |  Loss: (0.1818) |  Loss2: (0.0000) | Acc: (93.00%) (14486/15488)
Epoch: 122 | Batch_idx: 130 |  Loss: (0.1812) |  Loss2: (0.0000) | Acc: (93.00%) (15684/16768)
Epoch: 122 | Batch_idx: 140 |  Loss: (0.1813) |  Loss2: (0.0000) | Acc: (93.00%) (16883/18048)
Epoch: 122 | Batch_idx: 150 |  Loss: (0.1812) |  Loss2: (0.0000) | Acc: (93.00%) (18086/19328)
Epoch: 122 | Batch_idx: 160 |  Loss: (0.1820) |  Loss2: (0.0000) | Acc: (93.00%) (19282/20608)
Epoch: 122 | Batch_idx: 170 |  Loss: (0.1826) |  Loss2: (0.0000) | Acc: (93.00%) (20469/21888)
Epoch: 122 | Batch_idx: 180 |  Loss: (0.1817) |  Loss2: (0.0000) | Acc: (93.00%) (21676/23168)
Epoch: 122 | Batch_idx: 190 |  Loss: (0.1797) |  Loss2: (0.0000) | Acc: (93.00%) (22901/24448)
Epoch: 122 | Batch_idx: 200 |  Loss: (0.1796) |  Loss2: (0.0000) | Acc: (93.00%) (24104/25728)
Epoch: 122 | Batch_idx: 210 |  Loss: (0.1791) |  Loss2: (0.0000) | Acc: (93.00%) (25306/27008)
Epoch: 122 | Batch_idx: 220 |  Loss: (0.1782) |  Loss2: (0.0000) | Acc: (93.00%) (26517/28288)
Epoch: 122 | Batch_idx: 230 |  Loss: (0.1780) |  Loss2: (0.0000) | Acc: (93.00%) (27720/29568)
Epoch: 122 | Batch_idx: 240 |  Loss: (0.1780) |  Loss2: (0.0000) | Acc: (93.00%) (28926/30848)
Epoch: 122 | Batch_idx: 250 |  Loss: (0.1765) |  Loss2: (0.0000) | Acc: (93.00%) (30143/32128)
Epoch: 122 | Batch_idx: 260 |  Loss: (0.1757) |  Loss2: (0.0000) | Acc: (93.00%) (31352/33408)
Epoch: 122 | Batch_idx: 270 |  Loss: (0.1764) |  Loss2: (0.0000) | Acc: (93.00%) (32538/34688)
Epoch: 122 | Batch_idx: 280 |  Loss: (0.1765) |  Loss2: (0.0000) | Acc: (93.00%) (33739/35968)
Epoch: 122 | Batch_idx: 290 |  Loss: (0.1766) |  Loss2: (0.0000) | Acc: (93.00%) (34946/37248)
Epoch: 122 | Batch_idx: 300 |  Loss: (0.1765) |  Loss2: (0.0000) | Acc: (93.00%) (36148/38528)
Epoch: 122 | Batch_idx: 310 |  Loss: (0.1760) |  Loss2: (0.0000) | Acc: (93.00%) (37360/39808)
Epoch: 122 | Batch_idx: 320 |  Loss: (0.1758) |  Loss2: (0.0000) | Acc: (93.00%) (38562/41088)
Epoch: 122 | Batch_idx: 330 |  Loss: (0.1764) |  Loss2: (0.0000) | Acc: (93.00%) (39758/42368)
Epoch: 122 | Batch_idx: 340 |  Loss: (0.1773) |  Loss2: (0.0000) | Acc: (93.00%) (40947/43648)
Epoch: 122 | Batch_idx: 350 |  Loss: (0.1773) |  Loss2: (0.0000) | Acc: (93.00%) (42141/44928)
Epoch: 122 | Batch_idx: 360 |  Loss: (0.1770) |  Loss2: (0.0000) | Acc: (93.00%) (43350/46208)
Epoch: 122 | Batch_idx: 370 |  Loss: (0.1771) |  Loss2: (0.0000) | Acc: (93.00%) (44544/47488)
Epoch: 122 | Batch_idx: 380 |  Loss: (0.1773) |  Loss2: (0.0000) | Acc: (93.00%) (45739/48768)
Epoch: 122 | Batch_idx: 390 |  Loss: (0.1767) |  Loss2: (0.0000) | Acc: (93.00%) (46911/50000)
# TEST : Loss: (0.3893) | Acc: (87.00%) (8763/10000)
percent tensor([0.4957, 0.4943, 0.5040, 0.4928, 0.5034, 0.4983, 0.4974, 0.4948, 0.4954,
        0.4974, 0.4972, 0.5018, 0.4947, 0.4901, 0.4962, 0.4939],
       device='cuda:0') torch.Size([16])
percent tensor([0.5093, 0.4922, 0.5102, 0.5097, 0.5076, 0.5142, 0.4960, 0.4987, 0.5095,
        0.4982, 0.5106, 0.5045, 0.4982, 0.5007, 0.5049, 0.5088],
       device='cuda:0') torch.Size([16])
percent tensor([0.6325, 0.6393, 0.5667, 0.5531, 0.5767, 0.5992, 0.6331, 0.5928, 0.5926,
        0.5958, 0.6169, 0.5694, 0.6466, 0.5872, 0.6538, 0.6130],
       device='cuda:0') torch.Size([16])
percent tensor([0.6270, 0.6434, 0.6234, 0.6643, 0.6270, 0.7169, 0.6288, 0.6100, 0.6476,
        0.6217, 0.6404, 0.6616, 0.6320, 0.6583, 0.6694, 0.6594],
       device='cuda:0') torch.Size([16])
percent tensor([0.5593, 0.5720, 0.5567, 0.5439, 0.5921, 0.5318, 0.5806, 0.5389, 0.6238,
        0.5855, 0.6296, 0.5228, 0.5637, 0.7026, 0.4621, 0.5905],
       device='cuda:0') torch.Size([16])
percent tensor([0.5872, 0.5640, 0.6866, 0.7011, 0.7208, 0.6857, 0.6270, 0.6514, 0.6313,
        0.6043, 0.6047, 0.6594, 0.5883, 0.6366, 0.6025, 0.6214],
       device='cuda:0') torch.Size([16])
percent tensor([0.5773, 0.7150, 0.7337, 0.6739, 0.7240, 0.5770, 0.5740, 0.5535, 0.7300,
        0.6776, 0.7567, 0.6703, 0.6947, 0.6602, 0.5740, 0.4711],
       device='cuda:0') torch.Size([16])
percent tensor([0.9994, 0.9995, 0.9997, 0.9995, 0.9995, 0.9994, 0.9996, 0.9994, 0.9996,
        0.9997, 0.9999, 0.9998, 0.9998, 0.9993, 0.9985, 0.9989],
       device='cuda:0') torch.Size([16])
Epoch: 123 | Batch_idx: 0 |  Loss: (0.2141) |  Loss2: (0.0000) | Acc: (93.00%) (120/128)
Epoch: 123 | Batch_idx: 10 |  Loss: (0.1495) |  Loss2: (0.0000) | Acc: (95.00%) (1342/1408)
Epoch: 123 | Batch_idx: 20 |  Loss: (0.1596) |  Loss2: (0.0000) | Acc: (94.00%) (2535/2688)
Epoch: 123 | Batch_idx: 30 |  Loss: (0.1636) |  Loss2: (0.0000) | Acc: (93.00%) (3729/3968)
Epoch: 123 | Batch_idx: 40 |  Loss: (0.1639) |  Loss2: (0.0000) | Acc: (93.00%) (4932/5248)
Epoch: 123 | Batch_idx: 50 |  Loss: (0.1685) |  Loss2: (0.0000) | Acc: (94.00%) (6137/6528)
Epoch: 123 | Batch_idx: 60 |  Loss: (0.1697) |  Loss2: (0.0000) | Acc: (93.00%) (7338/7808)
Epoch: 123 | Batch_idx: 70 |  Loss: (0.1706) |  Loss2: (0.0000) | Acc: (93.00%) (8542/9088)
Epoch: 123 | Batch_idx: 80 |  Loss: (0.1725) |  Loss2: (0.0000) | Acc: (93.00%) (9733/10368)
Epoch: 123 | Batch_idx: 90 |  Loss: (0.1734) |  Loss2: (0.0000) | Acc: (93.00%) (10933/11648)
Epoch: 123 | Batch_idx: 100 |  Loss: (0.1737) |  Loss2: (0.0000) | Acc: (93.00%) (12141/12928)
Epoch: 123 | Batch_idx: 110 |  Loss: (0.1719) |  Loss2: (0.0000) | Acc: (93.00%) (13354/14208)
Epoch: 123 | Batch_idx: 120 |  Loss: (0.1719) |  Loss2: (0.0000) | Acc: (94.00%) (14559/15488)
Epoch: 123 | Batch_idx: 130 |  Loss: (0.1711) |  Loss2: (0.0000) | Acc: (94.00%) (15762/16768)
Epoch: 123 | Batch_idx: 140 |  Loss: (0.1721) |  Loss2: (0.0000) | Acc: (93.00%) (16958/18048)
Epoch: 123 | Batch_idx: 150 |  Loss: (0.1725) |  Loss2: (0.0000) | Acc: (93.00%) (18153/19328)
Epoch: 123 | Batch_idx: 160 |  Loss: (0.1736) |  Loss2: (0.0000) | Acc: (93.00%) (19354/20608)
Epoch: 123 | Batch_idx: 170 |  Loss: (0.1740) |  Loss2: (0.0000) | Acc: (93.00%) (20553/21888)
Epoch: 123 | Batch_idx: 180 |  Loss: (0.1744) |  Loss2: (0.0000) | Acc: (93.00%) (21758/23168)
Epoch: 123 | Batch_idx: 190 |  Loss: (0.1753) |  Loss2: (0.0000) | Acc: (93.00%) (22951/24448)
Epoch: 123 | Batch_idx: 200 |  Loss: (0.1741) |  Loss2: (0.0000) | Acc: (93.00%) (24166/25728)
Epoch: 123 | Batch_idx: 210 |  Loss: (0.1736) |  Loss2: (0.0000) | Acc: (93.00%) (25378/27008)
Epoch: 123 | Batch_idx: 220 |  Loss: (0.1733) |  Loss2: (0.0000) | Acc: (93.00%) (26588/28288)
Epoch: 123 | Batch_idx: 230 |  Loss: (0.1737) |  Loss2: (0.0000) | Acc: (93.00%) (27785/29568)
Epoch: 123 | Batch_idx: 240 |  Loss: (0.1741) |  Loss2: (0.0000) | Acc: (93.00%) (28981/30848)
Epoch: 123 | Batch_idx: 250 |  Loss: (0.1738) |  Loss2: (0.0000) | Acc: (93.00%) (30186/32128)
Epoch: 123 | Batch_idx: 260 |  Loss: (0.1740) |  Loss2: (0.0000) | Acc: (93.00%) (31388/33408)
Epoch: 123 | Batch_idx: 270 |  Loss: (0.1739) |  Loss2: (0.0000) | Acc: (93.00%) (32597/34688)
Epoch: 123 | Batch_idx: 280 |  Loss: (0.1731) |  Loss2: (0.0000) | Acc: (94.00%) (33820/35968)
Epoch: 123 | Batch_idx: 290 |  Loss: (0.1721) |  Loss2: (0.0000) | Acc: (94.00%) (35037/37248)
Epoch: 123 | Batch_idx: 300 |  Loss: (0.1715) |  Loss2: (0.0000) | Acc: (94.00%) (36246/38528)
Epoch: 123 | Batch_idx: 310 |  Loss: (0.1717) |  Loss2: (0.0000) | Acc: (94.00%) (37444/39808)
Epoch: 123 | Batch_idx: 320 |  Loss: (0.1716) |  Loss2: (0.0000) | Acc: (94.00%) (38648/41088)
Epoch: 123 | Batch_idx: 330 |  Loss: (0.1714) |  Loss2: (0.0000) | Acc: (94.00%) (39854/42368)
Epoch: 123 | Batch_idx: 340 |  Loss: (0.1711) |  Loss2: (0.0000) | Acc: (94.00%) (41059/43648)
Epoch: 123 | Batch_idx: 350 |  Loss: (0.1711) |  Loss2: (0.0000) | Acc: (94.00%) (42266/44928)
Epoch: 123 | Batch_idx: 360 |  Loss: (0.1708) |  Loss2: (0.0000) | Acc: (94.00%) (43471/46208)
Epoch: 123 | Batch_idx: 370 |  Loss: (0.1711) |  Loss2: (0.0000) | Acc: (94.00%) (44668/47488)
Epoch: 123 | Batch_idx: 380 |  Loss: (0.1711) |  Loss2: (0.0000) | Acc: (94.00%) (45866/48768)
Epoch: 123 | Batch_idx: 390 |  Loss: (0.1715) |  Loss2: (0.0000) | Acc: (94.00%) (47019/50000)
# TEST : Loss: (0.3854) | Acc: (87.00%) (8778/10000)
percent tensor([0.4949, 0.4937, 0.5029, 0.4919, 0.5023, 0.4970, 0.4966, 0.4941, 0.4947,
        0.4967, 0.4964, 0.5010, 0.4940, 0.4898, 0.4952, 0.4931],
       device='cuda:0') torch.Size([16])
percent tensor([0.5086, 0.4908, 0.5090, 0.5096, 0.5059, 0.5145, 0.4945, 0.4969, 0.5084,
        0.4974, 0.5100, 0.5034, 0.4969, 0.4998, 0.5034, 0.5086],
       device='cuda:0') torch.Size([16])
percent tensor([0.6328, 0.6374, 0.5659, 0.5517, 0.5751, 0.5988, 0.6304, 0.5896, 0.5932,
        0.5955, 0.6179, 0.5681, 0.6481, 0.5842, 0.6513, 0.6125],
       device='cuda:0') torch.Size([16])
percent tensor([0.6313, 0.6480, 0.6275, 0.6693, 0.6299, 0.7221, 0.6331, 0.6123, 0.6526,
        0.6267, 0.6466, 0.6653, 0.6365, 0.6647, 0.6742, 0.6645],
       device='cuda:0') torch.Size([16])
percent tensor([0.5573, 0.5687, 0.5567, 0.5423, 0.5910, 0.5280, 0.5781, 0.5371, 0.6280,
        0.5862, 0.6320, 0.5193, 0.5621, 0.7098, 0.4542, 0.5877],
       device='cuda:0') torch.Size([16])
percent tensor([0.5885, 0.5637, 0.6879, 0.7034, 0.7231, 0.6888, 0.6268, 0.6532, 0.6305,
        0.6045, 0.6045, 0.6580, 0.5874, 0.6341, 0.6056, 0.6218],
       device='cuda:0') torch.Size([16])
percent tensor([0.5637, 0.7070, 0.7269, 0.6642, 0.7197, 0.5704, 0.5611, 0.5452, 0.7212,
        0.6643, 0.7446, 0.6576, 0.6831, 0.6481, 0.5597, 0.4639],
       device='cuda:0') torch.Size([16])
percent tensor([0.9994, 0.9996, 0.9997, 0.9995, 0.9996, 0.9994, 0.9996, 0.9995, 0.9997,
        0.9997, 0.9999, 0.9998, 0.9998, 0.9994, 0.9985, 0.9989],
       device='cuda:0') torch.Size([16])
Epoch: 124 | Batch_idx: 0 |  Loss: (0.1458) |  Loss2: (0.0000) | Acc: (97.00%) (125/128)
Epoch: 124 | Batch_idx: 10 |  Loss: (0.1734) |  Loss2: (0.0000) | Acc: (94.00%) (1327/1408)
Epoch: 124 | Batch_idx: 20 |  Loss: (0.1757) |  Loss2: (0.0000) | Acc: (94.00%) (2527/2688)
Epoch: 124 | Batch_idx: 30 |  Loss: (0.1781) |  Loss2: (0.0000) | Acc: (94.00%) (3731/3968)
Epoch: 124 | Batch_idx: 40 |  Loss: (0.1737) |  Loss2: (0.0000) | Acc: (94.00%) (4938/5248)
Epoch: 124 | Batch_idx: 50 |  Loss: (0.1719) |  Loss2: (0.0000) | Acc: (94.00%) (6145/6528)
Epoch: 124 | Batch_idx: 60 |  Loss: (0.1727) |  Loss2: (0.0000) | Acc: (94.00%) (7346/7808)
Epoch: 124 | Batch_idx: 70 |  Loss: (0.1708) |  Loss2: (0.0000) | Acc: (94.00%) (8543/9088)
Epoch: 124 | Batch_idx: 80 |  Loss: (0.1705) |  Loss2: (0.0000) | Acc: (94.00%) (9752/10368)
Epoch: 124 | Batch_idx: 90 |  Loss: (0.1733) |  Loss2: (0.0000) | Acc: (93.00%) (10942/11648)
Epoch: 124 | Batch_idx: 100 |  Loss: (0.1724) |  Loss2: (0.0000) | Acc: (94.00%) (12158/12928)
Epoch: 124 | Batch_idx: 110 |  Loss: (0.1710) |  Loss2: (0.0000) | Acc: (94.00%) (13364/14208)
Epoch: 124 | Batch_idx: 120 |  Loss: (0.1709) |  Loss2: (0.0000) | Acc: (94.00%) (14562/15488)
Epoch: 124 | Batch_idx: 130 |  Loss: (0.1707) |  Loss2: (0.0000) | Acc: (94.00%) (15769/16768)
Epoch: 124 | Batch_idx: 140 |  Loss: (0.1718) |  Loss2: (0.0000) | Acc: (94.00%) (16970/18048)
Epoch: 124 | Batch_idx: 150 |  Loss: (0.1711) |  Loss2: (0.0000) | Acc: (94.00%) (18176/19328)
Epoch: 124 | Batch_idx: 160 |  Loss: (0.1712) |  Loss2: (0.0000) | Acc: (94.00%) (19389/20608)
Epoch: 124 | Batch_idx: 170 |  Loss: (0.1713) |  Loss2: (0.0000) | Acc: (94.00%) (20599/21888)
Epoch: 124 | Batch_idx: 180 |  Loss: (0.1701) |  Loss2: (0.0000) | Acc: (94.00%) (21811/23168)
Epoch: 124 | Batch_idx: 190 |  Loss: (0.1700) |  Loss2: (0.0000) | Acc: (94.00%) (23019/24448)
Epoch: 124 | Batch_idx: 200 |  Loss: (0.1697) |  Loss2: (0.0000) | Acc: (94.00%) (24228/25728)
Epoch: 124 | Batch_idx: 210 |  Loss: (0.1707) |  Loss2: (0.0000) | Acc: (94.00%) (25424/27008)
Epoch: 124 | Batch_idx: 220 |  Loss: (0.1711) |  Loss2: (0.0000) | Acc: (94.00%) (26618/28288)
Epoch: 124 | Batch_idx: 230 |  Loss: (0.1704) |  Loss2: (0.0000) | Acc: (94.00%) (27832/29568)
Epoch: 124 | Batch_idx: 240 |  Loss: (0.1706) |  Loss2: (0.0000) | Acc: (94.00%) (29022/30848)
Epoch: 124 | Batch_idx: 250 |  Loss: (0.1699) |  Loss2: (0.0000) | Acc: (94.00%) (30237/32128)
Epoch: 124 | Batch_idx: 260 |  Loss: (0.1701) |  Loss2: (0.0000) | Acc: (94.00%) (31438/33408)
Epoch: 124 | Batch_idx: 270 |  Loss: (0.1704) |  Loss2: (0.0000) | Acc: (94.00%) (32634/34688)
Epoch: 124 | Batch_idx: 280 |  Loss: (0.1710) |  Loss2: (0.0000) | Acc: (94.00%) (33834/35968)
Epoch: 124 | Batch_idx: 290 |  Loss: (0.1710) |  Loss2: (0.0000) | Acc: (94.00%) (35040/37248)
Epoch: 124 | Batch_idx: 300 |  Loss: (0.1711) |  Loss2: (0.0000) | Acc: (94.00%) (36249/38528)
Epoch: 124 | Batch_idx: 310 |  Loss: (0.1704) |  Loss2: (0.0000) | Acc: (94.00%) (37461/39808)
Epoch: 124 | Batch_idx: 320 |  Loss: (0.1707) |  Loss2: (0.0000) | Acc: (94.00%) (38664/41088)
Epoch: 124 | Batch_idx: 330 |  Loss: (0.1704) |  Loss2: (0.0000) | Acc: (94.00%) (39879/42368)
Epoch: 124 | Batch_idx: 340 |  Loss: (0.1702) |  Loss2: (0.0000) | Acc: (94.00%) (41087/43648)
Epoch: 124 | Batch_idx: 350 |  Loss: (0.1701) |  Loss2: (0.0000) | Acc: (94.00%) (42300/44928)
Epoch: 124 | Batch_idx: 360 |  Loss: (0.1702) |  Loss2: (0.0000) | Acc: (94.00%) (43508/46208)
Epoch: 124 | Batch_idx: 370 |  Loss: (0.1703) |  Loss2: (0.0000) | Acc: (94.00%) (44710/47488)
Epoch: 124 | Batch_idx: 380 |  Loss: (0.1702) |  Loss2: (0.0000) | Acc: (94.00%) (45924/48768)
Epoch: 124 | Batch_idx: 390 |  Loss: (0.1703) |  Loss2: (0.0000) | Acc: (94.00%) (47085/50000)
# TEST : Loss: (0.3802) | Acc: (87.00%) (8792/10000)
percent tensor([0.4950, 0.4938, 0.5025, 0.4917, 0.5018, 0.4968, 0.4965, 0.4941, 0.4949,
        0.4966, 0.4967, 0.5006, 0.4942, 0.4902, 0.4950, 0.4932],
       device='cuda:0') torch.Size([16])
percent tensor([0.5077, 0.4884, 0.5071, 0.5089, 0.5039, 0.5143, 0.4921, 0.4940, 0.5067,
        0.4956, 0.5081, 0.5013, 0.4946, 0.4977, 0.5011, 0.5082],
       device='cuda:0') torch.Size([16])
percent tensor([0.6340, 0.6371, 0.5672, 0.5507, 0.5757, 0.5997, 0.6310, 0.5888, 0.5940,
        0.5951, 0.6186, 0.5675, 0.6493, 0.5836, 0.6512, 0.6126],
       device='cuda:0') torch.Size([16])
percent tensor([0.6300, 0.6464, 0.6273, 0.6703, 0.6300, 0.7233, 0.6321, 0.6104, 0.6526,
        0.6246, 0.6461, 0.6656, 0.6350, 0.6643, 0.6737, 0.6628],
       device='cuda:0') torch.Size([16])
percent tensor([0.5535, 0.5619, 0.5593, 0.5430, 0.5916, 0.5258, 0.5748, 0.5370, 0.6263,
        0.5819, 0.6274, 0.5182, 0.5598, 0.7062, 0.4501, 0.5837],
       device='cuda:0') torch.Size([16])
percent tensor([0.5896, 0.5639, 0.6868, 0.7009, 0.7217, 0.6900, 0.6262, 0.6533, 0.6298,
        0.6016, 0.6031, 0.6555, 0.5879, 0.6306, 0.6074, 0.6218],
       device='cuda:0') torch.Size([16])
percent tensor([0.5717, 0.7155, 0.7344, 0.6715, 0.7269, 0.5792, 0.5705, 0.5532, 0.7270,
        0.6693, 0.7489, 0.6626, 0.6888, 0.6542, 0.5666, 0.4692],
       device='cuda:0') torch.Size([16])
percent tensor([0.9994, 0.9995, 0.9997, 0.9995, 0.9996, 0.9994, 0.9996, 0.9994, 0.9997,
        0.9997, 0.9999, 0.9998, 0.9998, 0.9994, 0.9985, 0.9990],
       device='cuda:0') torch.Size([16])
Epoch: 125 | Batch_idx: 0 |  Loss: (0.2456) |  Loss2: (0.0000) | Acc: (92.00%) (118/128)
Epoch: 125 | Batch_idx: 10 |  Loss: (0.1764) |  Loss2: (0.0000) | Acc: (94.00%) (1325/1408)
Epoch: 125 | Batch_idx: 20 |  Loss: (0.1626) |  Loss2: (0.0000) | Acc: (94.00%) (2552/2688)
Epoch: 125 | Batch_idx: 30 |  Loss: (0.1686) |  Loss2: (0.0000) | Acc: (94.00%) (3741/3968)
Epoch: 125 | Batch_idx: 40 |  Loss: (0.1663) |  Loss2: (0.0000) | Acc: (94.00%) (4954/5248)
Epoch: 125 | Batch_idx: 50 |  Loss: (0.1665) |  Loss2: (0.0000) | Acc: (94.00%) (6156/6528)
Epoch: 125 | Batch_idx: 60 |  Loss: (0.1690) |  Loss2: (0.0000) | Acc: (94.00%) (7367/7808)
Epoch: 125 | Batch_idx: 70 |  Loss: (0.1670) |  Loss2: (0.0000) | Acc: (94.00%) (8588/9088)
Epoch: 125 | Batch_idx: 80 |  Loss: (0.1718) |  Loss2: (0.0000) | Acc: (94.00%) (9780/10368)
Epoch: 125 | Batch_idx: 90 |  Loss: (0.1715) |  Loss2: (0.0000) | Acc: (94.00%) (10978/11648)
Epoch: 125 | Batch_idx: 100 |  Loss: (0.1717) |  Loss2: (0.0000) | Acc: (94.00%) (12186/12928)
Epoch: 125 | Batch_idx: 110 |  Loss: (0.1731) |  Loss2: (0.0000) | Acc: (94.00%) (13380/14208)
Epoch: 125 | Batch_idx: 120 |  Loss: (0.1713) |  Loss2: (0.0000) | Acc: (94.00%) (14599/15488)
Epoch: 125 | Batch_idx: 130 |  Loss: (0.1704) |  Loss2: (0.0000) | Acc: (94.00%) (15804/16768)
Epoch: 125 | Batch_idx: 140 |  Loss: (0.1701) |  Loss2: (0.0000) | Acc: (94.00%) (17021/18048)
Epoch: 125 | Batch_idx: 150 |  Loss: (0.1692) |  Loss2: (0.0000) | Acc: (94.00%) (18241/19328)
Epoch: 125 | Batch_idx: 160 |  Loss: (0.1676) |  Loss2: (0.0000) | Acc: (94.00%) (19453/20608)
Epoch: 125 | Batch_idx: 170 |  Loss: (0.1694) |  Loss2: (0.0000) | Acc: (94.00%) (20651/21888)
Epoch: 125 | Batch_idx: 180 |  Loss: (0.1686) |  Loss2: (0.0000) | Acc: (94.00%) (21868/23168)
Epoch: 125 | Batch_idx: 190 |  Loss: (0.1670) |  Loss2: (0.0000) | Acc: (94.00%) (23091/24448)
Epoch: 125 | Batch_idx: 200 |  Loss: (0.1662) |  Loss2: (0.0000) | Acc: (94.00%) (24306/25728)
Epoch: 125 | Batch_idx: 210 |  Loss: (0.1665) |  Loss2: (0.0000) | Acc: (94.00%) (25502/27008)
Epoch: 125 | Batch_idx: 220 |  Loss: (0.1669) |  Loss2: (0.0000) | Acc: (94.00%) (26703/28288)
Epoch: 125 | Batch_idx: 230 |  Loss: (0.1661) |  Loss2: (0.0000) | Acc: (94.00%) (27917/29568)
Epoch: 125 | Batch_idx: 240 |  Loss: (0.1656) |  Loss2: (0.0000) | Acc: (94.00%) (29131/30848)
Epoch: 125 | Batch_idx: 250 |  Loss: (0.1661) |  Loss2: (0.0000) | Acc: (94.00%) (30330/32128)
Epoch: 125 | Batch_idx: 260 |  Loss: (0.1654) |  Loss2: (0.0000) | Acc: (94.00%) (31546/33408)
Epoch: 125 | Batch_idx: 270 |  Loss: (0.1658) |  Loss2: (0.0000) | Acc: (94.00%) (32744/34688)
Epoch: 125 | Batch_idx: 280 |  Loss: (0.1657) |  Loss2: (0.0000) | Acc: (94.00%) (33949/35968)
Epoch: 125 | Batch_idx: 290 |  Loss: (0.1654) |  Loss2: (0.0000) | Acc: (94.00%) (35156/37248)
Epoch: 125 | Batch_idx: 300 |  Loss: (0.1650) |  Loss2: (0.0000) | Acc: (94.00%) (36367/38528)
Epoch: 125 | Batch_idx: 310 |  Loss: (0.1650) |  Loss2: (0.0000) | Acc: (94.00%) (37572/39808)
Epoch: 125 | Batch_idx: 320 |  Loss: (0.1654) |  Loss2: (0.0000) | Acc: (94.00%) (38767/41088)
Epoch: 125 | Batch_idx: 330 |  Loss: (0.1652) |  Loss2: (0.0000) | Acc: (94.00%) (39973/42368)
Epoch: 125 | Batch_idx: 340 |  Loss: (0.1656) |  Loss2: (0.0000) | Acc: (94.00%) (41178/43648)
Epoch: 125 | Batch_idx: 350 |  Loss: (0.1662) |  Loss2: (0.0000) | Acc: (94.00%) (42380/44928)
Epoch: 125 | Batch_idx: 360 |  Loss: (0.1666) |  Loss2: (0.0000) | Acc: (94.00%) (43580/46208)
Epoch: 125 | Batch_idx: 370 |  Loss: (0.1664) |  Loss2: (0.0000) | Acc: (94.00%) (44790/47488)
Epoch: 125 | Batch_idx: 380 |  Loss: (0.1662) |  Loss2: (0.0000) | Acc: (94.00%) (46004/48768)
Epoch: 125 | Batch_idx: 390 |  Loss: (0.1659) |  Loss2: (0.0000) | Acc: (94.00%) (47178/50000)
=> saving checkpoint 'drive/app/torch/save_Schedule/checkpoint_125.pth.tar'
# TEST : Loss: (0.3792) | Acc: (87.00%) (8793/10000)
percent tensor([0.4958, 0.4948, 0.5028, 0.4923, 0.5021, 0.4975, 0.4972, 0.4948, 0.4958,
        0.4973, 0.4977, 0.5009, 0.4951, 0.4911, 0.4958, 0.4940],
       device='cuda:0') torch.Size([16])
percent tensor([0.5077, 0.4879, 0.5062, 0.5089, 0.5021, 0.5143, 0.4911, 0.4924, 0.5056,
        0.4951, 0.5077, 0.5000, 0.4936, 0.4971, 0.5001, 0.5077],
       device='cuda:0') torch.Size([16])
percent tensor([0.6444, 0.6472, 0.5715, 0.5548, 0.5797, 0.6072, 0.6397, 0.5929, 0.6030,
        0.6045, 0.6297, 0.5723, 0.6615, 0.5894, 0.6607, 0.6221],
       device='cuda:0') torch.Size([16])
percent tensor([0.6260, 0.6438, 0.6237, 0.6657, 0.6243, 0.7209, 0.6285, 0.6038, 0.6491,
        0.6220, 0.6440, 0.6620, 0.6321, 0.6609, 0.6711, 0.6593],
       device='cuda:0') torch.Size([16])
percent tensor([0.5512, 0.5566, 0.5567, 0.5390, 0.5894, 0.5224, 0.5715, 0.5347, 0.6242,
        0.5774, 0.6254, 0.5126, 0.5582, 0.7041, 0.4465, 0.5808],
       device='cuda:0') torch.Size([16])
percent tensor([0.5907, 0.5652, 0.6875, 0.7020, 0.7231, 0.6916, 0.6271, 0.6552, 0.6282,
        0.6022, 0.6027, 0.6563, 0.5878, 0.6283, 0.6113, 0.6240],
       device='cuda:0') torch.Size([16])
percent tensor([0.5746, 0.7194, 0.7341, 0.6693, 0.7225, 0.5853, 0.5711, 0.5527, 0.7298,
        0.6684, 0.7487, 0.6624, 0.6902, 0.6556, 0.5642, 0.4697],
       device='cuda:0') torch.Size([16])
percent tensor([0.9994, 0.9996, 0.9997, 0.9996, 0.9995, 0.9994, 0.9996, 0.9995, 0.9997,
        0.9997, 0.9999, 0.9998, 0.9998, 0.9994, 0.9986, 0.9990],
       device='cuda:0') torch.Size([16])
Epoch: 126 | Batch_idx: 0 |  Loss: (0.1749) |  Loss2: (0.0000) | Acc: (92.00%) (119/128)
Epoch: 126 | Batch_idx: 10 |  Loss: (0.1859) |  Loss2: (0.0000) | Acc: (93.00%) (1312/1408)
Epoch: 126 | Batch_idx: 20 |  Loss: (0.1668) |  Loss2: (0.0000) | Acc: (94.00%) (2530/2688)
Epoch: 126 | Batch_idx: 30 |  Loss: (0.1623) |  Loss2: (0.0000) | Acc: (94.00%) (3749/3968)
Epoch: 126 | Batch_idx: 40 |  Loss: (0.1584) |  Loss2: (0.0000) | Acc: (94.00%) (4963/5248)
Epoch: 126 | Batch_idx: 50 |  Loss: (0.1604) |  Loss2: (0.0000) | Acc: (94.00%) (6180/6528)
Epoch: 126 | Batch_idx: 60 |  Loss: (0.1590) |  Loss2: (0.0000) | Acc: (94.00%) (7395/7808)
Epoch: 126 | Batch_idx: 70 |  Loss: (0.1575) |  Loss2: (0.0000) | Acc: (94.00%) (8617/9088)
Epoch: 126 | Batch_idx: 80 |  Loss: (0.1600) |  Loss2: (0.0000) | Acc: (94.00%) (9816/10368)
Epoch: 126 | Batch_idx: 90 |  Loss: (0.1634) |  Loss2: (0.0000) | Acc: (94.00%) (11019/11648)
Epoch: 126 | Batch_idx: 100 |  Loss: (0.1622) |  Loss2: (0.0000) | Acc: (94.00%) (12237/12928)
Epoch: 126 | Batch_idx: 110 |  Loss: (0.1630) |  Loss2: (0.0000) | Acc: (94.00%) (13440/14208)
Epoch: 126 | Batch_idx: 120 |  Loss: (0.1624) |  Loss2: (0.0000) | Acc: (94.00%) (14653/15488)
Epoch: 126 | Batch_idx: 130 |  Loss: (0.1620) |  Loss2: (0.0000) | Acc: (94.00%) (15864/16768)
Epoch: 126 | Batch_idx: 140 |  Loss: (0.1628) |  Loss2: (0.0000) | Acc: (94.00%) (17069/18048)
Epoch: 126 | Batch_idx: 150 |  Loss: (0.1640) |  Loss2: (0.0000) | Acc: (94.00%) (18272/19328)
Epoch: 126 | Batch_idx: 160 |  Loss: (0.1641) |  Loss2: (0.0000) | Acc: (94.00%) (19468/20608)
Epoch: 126 | Batch_idx: 170 |  Loss: (0.1647) |  Loss2: (0.0000) | Acc: (94.00%) (20670/21888)
Epoch: 126 | Batch_idx: 180 |  Loss: (0.1642) |  Loss2: (0.0000) | Acc: (94.00%) (21879/23168)
Epoch: 126 | Batch_idx: 190 |  Loss: (0.1646) |  Loss2: (0.0000) | Acc: (94.00%) (23085/24448)
Epoch: 126 | Batch_idx: 200 |  Loss: (0.1647) |  Loss2: (0.0000) | Acc: (94.00%) (24291/25728)
Epoch: 126 | Batch_idx: 210 |  Loss: (0.1655) |  Loss2: (0.0000) | Acc: (94.00%) (25487/27008)
Epoch: 126 | Batch_idx: 220 |  Loss: (0.1660) |  Loss2: (0.0000) | Acc: (94.00%) (26682/28288)
Epoch: 126 | Batch_idx: 230 |  Loss: (0.1660) |  Loss2: (0.0000) | Acc: (94.00%) (27885/29568)
Epoch: 126 | Batch_idx: 240 |  Loss: (0.1656) |  Loss2: (0.0000) | Acc: (94.00%) (29098/30848)
Epoch: 126 | Batch_idx: 250 |  Loss: (0.1672) |  Loss2: (0.0000) | Acc: (94.00%) (30288/32128)
Epoch: 126 | Batch_idx: 260 |  Loss: (0.1673) |  Loss2: (0.0000) | Acc: (94.00%) (31492/33408)
Epoch: 126 | Batch_idx: 270 |  Loss: (0.1670) |  Loss2: (0.0000) | Acc: (94.00%) (32700/34688)
Epoch: 126 | Batch_idx: 280 |  Loss: (0.1667) |  Loss2: (0.0000) | Acc: (94.00%) (33910/35968)
Epoch: 126 | Batch_idx: 290 |  Loss: (0.1659) |  Loss2: (0.0000) | Acc: (94.00%) (35126/37248)
Epoch: 126 | Batch_idx: 300 |  Loss: (0.1660) |  Loss2: (0.0000) | Acc: (94.00%) (36337/38528)
Epoch: 126 | Batch_idx: 310 |  Loss: (0.1659) |  Loss2: (0.0000) | Acc: (94.00%) (37539/39808)
Epoch: 126 | Batch_idx: 320 |  Loss: (0.1666) |  Loss2: (0.0000) | Acc: (94.00%) (38739/41088)
Epoch: 126 | Batch_idx: 330 |  Loss: (0.1665) |  Loss2: (0.0000) | Acc: (94.00%) (39948/42368)
Epoch: 126 | Batch_idx: 340 |  Loss: (0.1663) |  Loss2: (0.0000) | Acc: (94.00%) (41158/43648)
Epoch: 126 | Batch_idx: 350 |  Loss: (0.1660) |  Loss2: (0.0000) | Acc: (94.00%) (42373/44928)
Epoch: 126 | Batch_idx: 360 |  Loss: (0.1656) |  Loss2: (0.0000) | Acc: (94.00%) (43591/46208)
Epoch: 126 | Batch_idx: 370 |  Loss: (0.1659) |  Loss2: (0.0000) | Acc: (94.00%) (44782/47488)
Epoch: 126 | Batch_idx: 380 |  Loss: (0.1656) |  Loss2: (0.0000) | Acc: (94.00%) (45989/48768)
Epoch: 126 | Batch_idx: 390 |  Loss: (0.1657) |  Loss2: (0.0000) | Acc: (94.00%) (47152/50000)
# TEST : Loss: (0.3745) | Acc: (88.00%) (8805/10000)
percent tensor([0.4956, 0.4946, 0.5025, 0.4921, 0.5018, 0.4971, 0.4971, 0.4947, 0.4957,
        0.4972, 0.4976, 0.5007, 0.4950, 0.4909, 0.4955, 0.4939],
       device='cuda:0') torch.Size([16])
percent tensor([0.5073, 0.4877, 0.5054, 0.5084, 0.5011, 0.5137, 0.4905, 0.4916, 0.5053,
        0.4947, 0.5076, 0.4993, 0.4934, 0.4975, 0.4993, 0.5074],
       device='cuda:0') torch.Size([16])
percent tensor([0.6346, 0.6383, 0.5645, 0.5477, 0.5735, 0.5995, 0.6303, 0.5859, 0.5936,
        0.5959, 0.6208, 0.5653, 0.6525, 0.5797, 0.6515, 0.6131],
       device='cuda:0') torch.Size([16])
percent tensor([0.6236, 0.6422, 0.6204, 0.6629, 0.6209, 0.7186, 0.6250, 0.6003, 0.6480,
        0.6202, 0.6427, 0.6587, 0.6310, 0.6604, 0.6672, 0.6570],
       device='cuda:0') torch.Size([16])
percent tensor([0.5586, 0.5661, 0.5613, 0.5420, 0.5931, 0.5296, 0.5789, 0.5400, 0.6331,
        0.5878, 0.6313, 0.5180, 0.5651, 0.7109, 0.4539, 0.5885],
       device='cuda:0') torch.Size([16])
percent tensor([0.5937, 0.5693, 0.6911, 0.7060, 0.7278, 0.6967, 0.6295, 0.6590, 0.6309,
        0.6060, 0.6051, 0.6582, 0.5896, 0.6292, 0.6136, 0.6280],
       device='cuda:0') torch.Size([16])
percent tensor([0.5712, 0.7146, 0.7281, 0.6615, 0.7210, 0.5841, 0.5685, 0.5496, 0.7226,
        0.6625, 0.7437, 0.6561, 0.6843, 0.6485, 0.5607, 0.4697],
       device='cuda:0') torch.Size([16])
percent tensor([0.9994, 0.9996, 0.9997, 0.9995, 0.9996, 0.9995, 0.9996, 0.9995, 0.9997,
        0.9997, 0.9999, 0.9998, 0.9998, 0.9994, 0.9986, 0.9990],
       device='cuda:0') torch.Size([16])
Epoch: 127 | Batch_idx: 0 |  Loss: (0.0837) |  Loss2: (0.0000) | Acc: (97.00%) (125/128)
Epoch: 127 | Batch_idx: 10 |  Loss: (0.1548) |  Loss2: (0.0000) | Acc: (94.00%) (1327/1408)
Epoch: 127 | Batch_idx: 20 |  Loss: (0.1504) |  Loss2: (0.0000) | Acc: (94.00%) (2540/2688)
Epoch: 127 | Batch_idx: 30 |  Loss: (0.1490) |  Loss2: (0.0000) | Acc: (94.00%) (3755/3968)
Epoch: 127 | Batch_idx: 40 |  Loss: (0.1484) |  Loss2: (0.0000) | Acc: (94.00%) (4971/5248)
Epoch: 127 | Batch_idx: 50 |  Loss: (0.1520) |  Loss2: (0.0000) | Acc: (94.00%) (6175/6528)
Epoch: 127 | Batch_idx: 60 |  Loss: (0.1512) |  Loss2: (0.0000) | Acc: (94.00%) (7398/7808)
Epoch: 127 | Batch_idx: 70 |  Loss: (0.1529) |  Loss2: (0.0000) | Acc: (94.00%) (8608/9088)
Epoch: 127 | Batch_idx: 80 |  Loss: (0.1561) |  Loss2: (0.0000) | Acc: (94.00%) (9802/10368)
Epoch: 127 | Batch_idx: 90 |  Loss: (0.1590) |  Loss2: (0.0000) | Acc: (94.00%) (10996/11648)
Epoch: 127 | Batch_idx: 100 |  Loss: (0.1610) |  Loss2: (0.0000) | Acc: (94.00%) (12200/12928)
Epoch: 127 | Batch_idx: 110 |  Loss: (0.1602) |  Loss2: (0.0000) | Acc: (94.00%) (13413/14208)
Epoch: 127 | Batch_idx: 120 |  Loss: (0.1580) |  Loss2: (0.0000) | Acc: (94.00%) (14636/15488)
Epoch: 127 | Batch_idx: 130 |  Loss: (0.1564) |  Loss2: (0.0000) | Acc: (94.00%) (15860/16768)
Epoch: 127 | Batch_idx: 140 |  Loss: (0.1564) |  Loss2: (0.0000) | Acc: (94.00%) (17067/18048)
Epoch: 127 | Batch_idx: 150 |  Loss: (0.1563) |  Loss2: (0.0000) | Acc: (94.00%) (18282/19328)
Epoch: 127 | Batch_idx: 160 |  Loss: (0.1566) |  Loss2: (0.0000) | Acc: (94.00%) (19486/20608)
Epoch: 127 | Batch_idx: 170 |  Loss: (0.1581) |  Loss2: (0.0000) | Acc: (94.00%) (20681/21888)
Epoch: 127 | Batch_idx: 180 |  Loss: (0.1583) |  Loss2: (0.0000) | Acc: (94.00%) (21903/23168)
Epoch: 127 | Batch_idx: 190 |  Loss: (0.1579) |  Loss2: (0.0000) | Acc: (94.00%) (23117/24448)
Epoch: 127 | Batch_idx: 200 |  Loss: (0.1581) |  Loss2: (0.0000) | Acc: (94.00%) (24323/25728)
Epoch: 127 | Batch_idx: 210 |  Loss: (0.1588) |  Loss2: (0.0000) | Acc: (94.00%) (25523/27008)
Epoch: 127 | Batch_idx: 220 |  Loss: (0.1595) |  Loss2: (0.0000) | Acc: (94.00%) (26726/28288)
Epoch: 127 | Batch_idx: 230 |  Loss: (0.1598) |  Loss2: (0.0000) | Acc: (94.00%) (27931/29568)
Epoch: 127 | Batch_idx: 240 |  Loss: (0.1601) |  Loss2: (0.0000) | Acc: (94.00%) (29133/30848)
Epoch: 127 | Batch_idx: 250 |  Loss: (0.1615) |  Loss2: (0.0000) | Acc: (94.00%) (30328/32128)
Epoch: 127 | Batch_idx: 260 |  Loss: (0.1621) |  Loss2: (0.0000) | Acc: (94.00%) (31528/33408)
Epoch: 127 | Batch_idx: 270 |  Loss: (0.1619) |  Loss2: (0.0000) | Acc: (94.00%) (32747/34688)
Epoch: 127 | Batch_idx: 280 |  Loss: (0.1613) |  Loss2: (0.0000) | Acc: (94.00%) (33965/35968)
Epoch: 127 | Batch_idx: 290 |  Loss: (0.1609) |  Loss2: (0.0000) | Acc: (94.00%) (35179/37248)
Epoch: 127 | Batch_idx: 300 |  Loss: (0.1606) |  Loss2: (0.0000) | Acc: (94.00%) (36398/38528)
Epoch: 127 | Batch_idx: 310 |  Loss: (0.1604) |  Loss2: (0.0000) | Acc: (94.00%) (37610/39808)
Epoch: 127 | Batch_idx: 320 |  Loss: (0.1599) |  Loss2: (0.0000) | Acc: (94.00%) (38830/41088)
Epoch: 127 | Batch_idx: 330 |  Loss: (0.1600) |  Loss2: (0.0000) | Acc: (94.00%) (40037/42368)
Epoch: 127 | Batch_idx: 340 |  Loss: (0.1604) |  Loss2: (0.0000) | Acc: (94.00%) (41247/43648)
Epoch: 127 | Batch_idx: 350 |  Loss: (0.1608) |  Loss2: (0.0000) | Acc: (94.00%) (42451/44928)
Epoch: 127 | Batch_idx: 360 |  Loss: (0.1611) |  Loss2: (0.0000) | Acc: (94.00%) (43651/46208)
Epoch: 127 | Batch_idx: 370 |  Loss: (0.1608) |  Loss2: (0.0000) | Acc: (94.00%) (44869/47488)
Epoch: 127 | Batch_idx: 380 |  Loss: (0.1605) |  Loss2: (0.0000) | Acc: (94.00%) (46090/48768)
Epoch: 127 | Batch_idx: 390 |  Loss: (0.1608) |  Loss2: (0.0000) | Acc: (94.00%) (47256/50000)
# TEST : Loss: (0.3746) | Acc: (87.00%) (8794/10000)
percent tensor([0.4971, 0.4964, 0.5037, 0.4933, 0.5031, 0.4982, 0.4987, 0.4963, 0.4974,
        0.4988, 0.4992, 0.5019, 0.4966, 0.4923, 0.4970, 0.4953],
       device='cuda:0') torch.Size([16])
percent tensor([0.5077, 0.4892, 0.5060, 0.5086, 0.5017, 0.5139, 0.4920, 0.4925, 0.5062,
        0.4957, 0.5088, 0.5004, 0.4941, 0.4986, 0.5003, 0.5083],
       device='cuda:0') torch.Size([16])
percent tensor([0.6395, 0.6437, 0.5656, 0.5499, 0.5742, 0.6058, 0.6342, 0.5858, 0.5976,
        0.6007, 0.6268, 0.5670, 0.6582, 0.5840, 0.6565, 0.6189],
       device='cuda:0') torch.Size([16])
percent tensor([0.6279, 0.6465, 0.6235, 0.6677, 0.6252, 0.7234, 0.6306, 0.6038, 0.6516,
        0.6240, 0.6475, 0.6629, 0.6344, 0.6648, 0.6734, 0.6619],
       device='cuda:0') torch.Size([16])
percent tensor([0.5574, 0.5630, 0.5623, 0.5401, 0.5940, 0.5309, 0.5790, 0.5399, 0.6314,
        0.5831, 0.6296, 0.5149, 0.5626, 0.7092, 0.4538, 0.5876],
       device='cuda:0') torch.Size([16])
percent tensor([0.5878, 0.5642, 0.6843, 0.7011, 0.7211, 0.6925, 0.6222, 0.6519, 0.6233,
        0.5988, 0.5991, 0.6511, 0.5834, 0.6222, 0.6099, 0.6218],
       device='cuda:0') torch.Size([16])
percent tensor([0.5731, 0.7188, 0.7271, 0.6634, 0.7177, 0.5855, 0.5647, 0.5464, 0.7272,
        0.6646, 0.7465, 0.6574, 0.6878, 0.6568, 0.5556, 0.4705],
       device='cuda:0') torch.Size([16])
percent tensor([0.9995, 0.9996, 0.9997, 0.9996, 0.9996, 0.9995, 0.9996, 0.9995, 0.9997,
        0.9997, 0.9999, 0.9998, 0.9998, 0.9994, 0.9987, 0.9990],
       device='cuda:0') torch.Size([16])
True Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=128, out_features=16, bias=False)
False Linear(in_features=16, out_features=2, bias=False)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=128, out_features=16, bias=False)
False Linear(in_features=16, out_features=2, bias=False)
True Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=256, out_features=32, bias=False)
False Linear(in_features=32, out_features=2, bias=False)
True Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=256, out_features=32, bias=False)
False Linear(in_features=32, out_features=2, bias=False)
True Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=512, out_features=64, bias=False)
False Linear(in_features=64, out_features=2, bias=False)
True Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=512, out_features=64, bias=False)
False Linear(in_features=64, out_features=2, bias=False)
True Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1024, out_features=128, bias=False)
False Linear(in_features=128, out_features=2, bias=False)
True Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1024, out_features=128, bias=False)
False Linear(in_features=128, out_features=2, bias=False)
True Linear(in_features=512, out_features=10, bias=True)
Epoch: 128 | Batch_idx: 0 |  Loss: (0.0517) |  Loss2: (0.0000) | Acc: (100.00%) (128/128)
Epoch: 128 | Batch_idx: 10 |  Loss: (0.1380) |  Loss2: (0.0000) | Acc: (95.00%) (1344/1408)
Epoch: 128 | Batch_idx: 20 |  Loss: (0.1522) |  Loss2: (0.0000) | Acc: (94.00%) (2548/2688)
Epoch: 128 | Batch_idx: 30 |  Loss: (0.1644) |  Loss2: (0.0000) | Acc: (94.00%) (3739/3968)
Epoch: 128 | Batch_idx: 40 |  Loss: (0.1696) |  Loss2: (0.0000) | Acc: (94.00%) (4939/5248)
Epoch: 128 | Batch_idx: 50 |  Loss: (0.1696) |  Loss2: (0.0000) | Acc: (94.00%) (6149/6528)
Epoch: 128 | Batch_idx: 60 |  Loss: (0.1675) |  Loss2: (0.0000) | Acc: (94.00%) (7354/7808)
Epoch: 128 | Batch_idx: 70 |  Loss: (0.1695) |  Loss2: (0.0000) | Acc: (94.00%) (8554/9088)
Epoch: 128 | Batch_idx: 80 |  Loss: (0.1724) |  Loss2: (0.0000) | Acc: (94.00%) (9747/10368)
Epoch: 128 | Batch_idx: 90 |  Loss: (0.1719) |  Loss2: (0.0000) | Acc: (94.00%) (10954/11648)
Epoch: 128 | Batch_idx: 100 |  Loss: (0.1711) |  Loss2: (0.0000) | Acc: (94.00%) (12155/12928)
Epoch: 128 | Batch_idx: 110 |  Loss: (0.1706) |  Loss2: (0.0000) | Acc: (94.00%) (13361/14208)
Epoch: 128 | Batch_idx: 120 |  Loss: (0.1713) |  Loss2: (0.0000) | Acc: (93.00%) (14555/15488)
Epoch: 128 | Batch_idx: 130 |  Loss: (0.1712) |  Loss2: (0.0000) | Acc: (93.00%) (15761/16768)
Epoch: 128 | Batch_idx: 140 |  Loss: (0.1722) |  Loss2: (0.0000) | Acc: (93.00%) (16961/18048)
Epoch: 128 | Batch_idx: 150 |  Loss: (0.1729) |  Loss2: (0.0000) | Acc: (93.00%) (18164/19328)
Epoch: 128 | Batch_idx: 160 |  Loss: (0.1746) |  Loss2: (0.0000) | Acc: (93.00%) (19354/20608)
Epoch: 128 | Batch_idx: 170 |  Loss: (0.1739) |  Loss2: (0.0000) | Acc: (93.00%) (20566/21888)
Epoch: 128 | Batch_idx: 180 |  Loss: (0.1735) |  Loss2: (0.0000) | Acc: (93.00%) (21773/23168)
Epoch: 128 | Batch_idx: 190 |  Loss: (0.1733) |  Loss2: (0.0000) | Acc: (93.00%) (22981/24448)
Epoch: 128 | Batch_idx: 200 |  Loss: (0.1736) |  Loss2: (0.0000) | Acc: (94.00%) (24185/25728)
Epoch: 128 | Batch_idx: 210 |  Loss: (0.1744) |  Loss2: (0.0000) | Acc: (93.00%) (25383/27008)
Epoch: 128 | Batch_idx: 220 |  Loss: (0.1746) |  Loss2: (0.0000) | Acc: (93.00%) (26576/28288)
Epoch: 128 | Batch_idx: 230 |  Loss: (0.1751) |  Loss2: (0.0000) | Acc: (93.00%) (27770/29568)
Epoch: 128 | Batch_idx: 240 |  Loss: (0.1755) |  Loss2: (0.0000) | Acc: (93.00%) (28970/30848)
Epoch: 128 | Batch_idx: 250 |  Loss: (0.1759) |  Loss2: (0.0000) | Acc: (93.00%) (30173/32128)
Epoch: 128 | Batch_idx: 260 |  Loss: (0.1759) |  Loss2: (0.0000) | Acc: (93.00%) (31376/33408)
Epoch: 128 | Batch_idx: 270 |  Loss: (0.1750) |  Loss2: (0.0000) | Acc: (93.00%) (32598/34688)
Epoch: 128 | Batch_idx: 280 |  Loss: (0.1745) |  Loss2: (0.0000) | Acc: (93.00%) (33809/35968)
Epoch: 128 | Batch_idx: 290 |  Loss: (0.1743) |  Loss2: (0.0000) | Acc: (94.00%) (35014/37248)
Epoch: 128 | Batch_idx: 300 |  Loss: (0.1739) |  Loss2: (0.0000) | Acc: (94.00%) (36224/38528)
Epoch: 128 | Batch_idx: 310 |  Loss: (0.1734) |  Loss2: (0.0000) | Acc: (94.00%) (37434/39808)
Epoch: 128 | Batch_idx: 320 |  Loss: (0.1741) |  Loss2: (0.0000) | Acc: (94.00%) (38624/41088)
Epoch: 128 | Batch_idx: 330 |  Loss: (0.1745) |  Loss2: (0.0000) | Acc: (94.00%) (39828/42368)
Epoch: 128 | Batch_idx: 340 |  Loss: (0.1743) |  Loss2: (0.0000) | Acc: (94.00%) (41035/43648)
Epoch: 128 | Batch_idx: 350 |  Loss: (0.1749) |  Loss2: (0.0000) | Acc: (93.00%) (42221/44928)
Epoch: 128 | Batch_idx: 360 |  Loss: (0.1748) |  Loss2: (0.0000) | Acc: (93.00%) (43418/46208)
Epoch: 128 | Batch_idx: 370 |  Loss: (0.1746) |  Loss2: (0.0000) | Acc: (93.00%) (44624/47488)
Epoch: 128 | Batch_idx: 380 |  Loss: (0.1752) |  Loss2: (0.0000) | Acc: (93.00%) (45813/48768)
Epoch: 128 | Batch_idx: 390 |  Loss: (0.1756) |  Loss2: (0.0000) | Acc: (93.00%) (46966/50000)
# TEST : Loss: (0.4825) | Acc: (85.00%) (8546/10000)
percent tensor([0.4972, 0.4970, 0.5031, 0.4933, 0.5026, 0.4984, 0.4989, 0.4964, 0.4979,
        0.4987, 0.4998, 0.5017, 0.4967, 0.4932, 0.4971, 0.4957],
       device='cuda:0') torch.Size([16])
percent tensor([0.5063, 0.4910, 0.5056, 0.5100, 0.4989, 0.5136, 0.4917, 0.4933, 0.5065,
        0.4948, 0.5086, 0.4981, 0.4922, 0.5052, 0.4991, 0.5078],
       device='cuda:0') torch.Size([16])
percent tensor([0.6447, 0.6333, 0.5705, 0.5564, 0.5811, 0.6068, 0.6343, 0.5868, 0.5939,
        0.6032, 0.6209, 0.5706, 0.6642, 0.5688, 0.6528, 0.6230],
       device='cuda:0') torch.Size([16])
percent tensor([0.6254, 0.6517, 0.6194, 0.6591, 0.6244, 0.7174, 0.6344, 0.6009, 0.6525,
        0.6321, 0.6510, 0.6672, 0.6401, 0.6648, 0.6775, 0.6628],
       device='cuda:0') torch.Size([16])
percent tensor([0.5431, 0.5562, 0.5572, 0.5515, 0.5824, 0.5575, 0.5626, 0.5231, 0.6184,
        0.5874, 0.6147, 0.4983, 0.5492, 0.6918, 0.4515, 0.5844],
       device='cuda:0') torch.Size([16])
percent tensor([0.5851, 0.5734, 0.6781, 0.6986, 0.7227, 0.6979, 0.6257, 0.6497, 0.6231,
        0.6126, 0.6065, 0.6459, 0.5948, 0.6291, 0.6116, 0.6172],
       device='cuda:0') torch.Size([16])
percent tensor([0.5823, 0.7225, 0.7222, 0.6774, 0.7324, 0.5999, 0.5918, 0.5609, 0.7093,
        0.6766, 0.7374, 0.6575, 0.6970, 0.6438, 0.5657, 0.4700],
       device='cuda:0') torch.Size([16])
percent tensor([0.9996, 0.9997, 0.9998, 0.9996, 0.9997, 0.9996, 0.9995, 0.9993, 0.9998,
        0.9998, 0.9999, 0.9998, 0.9998, 0.9997, 0.9985, 0.9994],
       device='cuda:0') torch.Size([16])
Epoch: 129 | Batch_idx: 0 |  Loss: (0.1268) |  Loss2: (0.0000) | Acc: (95.00%) (122/128)
Epoch: 129 | Batch_idx: 10 |  Loss: (0.1817) |  Loss2: (0.0000) | Acc: (93.00%) (1322/1408)
Epoch: 129 | Batch_idx: 20 |  Loss: (0.1783) |  Loss2: (0.0000) | Acc: (94.00%) (2535/2688)
Epoch: 129 | Batch_idx: 30 |  Loss: (0.1721) |  Loss2: (0.0000) | Acc: (94.00%) (3746/3968)
Epoch: 129 | Batch_idx: 40 |  Loss: (0.1766) |  Loss2: (0.0000) | Acc: (94.00%) (4949/5248)
Epoch: 129 | Batch_idx: 50 |  Loss: (0.1726) |  Loss2: (0.0000) | Acc: (94.00%) (6158/6528)
Epoch: 129 | Batch_idx: 60 |  Loss: (0.1740) |  Loss2: (0.0000) | Acc: (94.00%) (7356/7808)
Epoch: 129 | Batch_idx: 70 |  Loss: (0.1725) |  Loss2: (0.0000) | Acc: (94.00%) (8566/9088)
Epoch: 129 | Batch_idx: 80 |  Loss: (0.1713) |  Loss2: (0.0000) | Acc: (94.00%) (9778/10368)
Epoch: 129 | Batch_idx: 90 |  Loss: (0.1711) |  Loss2: (0.0000) | Acc: (94.00%) (10987/11648)
Epoch: 129 | Batch_idx: 100 |  Loss: (0.1707) |  Loss2: (0.0000) | Acc: (94.00%) (12188/12928)
Epoch: 129 | Batch_idx: 110 |  Loss: (0.1706) |  Loss2: (0.0000) | Acc: (94.00%) (13392/14208)
Epoch: 129 | Batch_idx: 120 |  Loss: (0.1703) |  Loss2: (0.0000) | Acc: (94.00%) (14606/15488)
Epoch: 129 | Batch_idx: 130 |  Loss: (0.1698) |  Loss2: (0.0000) | Acc: (94.00%) (15811/16768)
Epoch: 129 | Batch_idx: 140 |  Loss: (0.1693) |  Loss2: (0.0000) | Acc: (94.00%) (17020/18048)
Epoch: 129 | Batch_idx: 150 |  Loss: (0.1686) |  Loss2: (0.0000) | Acc: (94.00%) (18225/19328)
Epoch: 129 | Batch_idx: 160 |  Loss: (0.1691) |  Loss2: (0.0000) | Acc: (94.00%) (19424/20608)
Epoch: 129 | Batch_idx: 170 |  Loss: (0.1695) |  Loss2: (0.0000) | Acc: (94.00%) (20625/21888)
Epoch: 129 | Batch_idx: 180 |  Loss: (0.1688) |  Loss2: (0.0000) | Acc: (94.00%) (21831/23168)
Epoch: 129 | Batch_idx: 190 |  Loss: (0.1681) |  Loss2: (0.0000) | Acc: (94.00%) (23047/24448)
Epoch: 129 | Batch_idx: 200 |  Loss: (0.1673) |  Loss2: (0.0000) | Acc: (94.00%) (24256/25728)
Epoch: 129 | Batch_idx: 210 |  Loss: (0.1666) |  Loss2: (0.0000) | Acc: (94.00%) (25469/27008)
Epoch: 129 | Batch_idx: 220 |  Loss: (0.1669) |  Loss2: (0.0000) | Acc: (94.00%) (26673/28288)
Epoch: 129 | Batch_idx: 230 |  Loss: (0.1670) |  Loss2: (0.0000) | Acc: (94.00%) (27877/29568)
Epoch: 129 | Batch_idx: 240 |  Loss: (0.1671) |  Loss2: (0.0000) | Acc: (94.00%) (29074/30848)
Epoch: 129 | Batch_idx: 250 |  Loss: (0.1675) |  Loss2: (0.0000) | Acc: (94.00%) (30280/32128)
Epoch: 129 | Batch_idx: 260 |  Loss: (0.1681) |  Loss2: (0.0000) | Acc: (94.00%) (31482/33408)
Epoch: 129 | Batch_idx: 270 |  Loss: (0.1676) |  Loss2: (0.0000) | Acc: (94.00%) (32690/34688)
Epoch: 129 | Batch_idx: 280 |  Loss: (0.1680) |  Loss2: (0.0000) | Acc: (94.00%) (33883/35968)
Epoch: 129 | Batch_idx: 290 |  Loss: (0.1676) |  Loss2: (0.0000) | Acc: (94.00%) (35090/37248)
Epoch: 129 | Batch_idx: 300 |  Loss: (0.1671) |  Loss2: (0.0000) | Acc: (94.00%) (36306/38528)
Epoch: 129 | Batch_idx: 310 |  Loss: (0.1676) |  Loss2: (0.0000) | Acc: (94.00%) (37506/39808)
Epoch: 129 | Batch_idx: 320 |  Loss: (0.1684) |  Loss2: (0.0000) | Acc: (94.00%) (38712/41088)
Epoch: 129 | Batch_idx: 330 |  Loss: (0.1682) |  Loss2: (0.0000) | Acc: (94.00%) (39920/42368)
Epoch: 129 | Batch_idx: 340 |  Loss: (0.1692) |  Loss2: (0.0000) | Acc: (94.00%) (41112/43648)
Epoch: 129 | Batch_idx: 350 |  Loss: (0.1695) |  Loss2: (0.0000) | Acc: (94.00%) (42309/44928)
Epoch: 129 | Batch_idx: 360 |  Loss: (0.1694) |  Loss2: (0.0000) | Acc: (94.00%) (43514/46208)
Epoch: 129 | Batch_idx: 370 |  Loss: (0.1697) |  Loss2: (0.0000) | Acc: (94.00%) (44709/47488)
Epoch: 129 | Batch_idx: 380 |  Loss: (0.1701) |  Loss2: (0.0000) | Acc: (94.00%) (45902/48768)
Epoch: 129 | Batch_idx: 390 |  Loss: (0.1697) |  Loss2: (0.0000) | Acc: (94.00%) (47073/50000)
# TEST : Loss: (0.4094) | Acc: (87.00%) (8707/10000)
percent tensor([0.4969, 0.4969, 0.5040, 0.4936, 0.5032, 0.4977, 0.4993, 0.4966, 0.4980,
        0.4990, 0.4997, 0.5024, 0.4966, 0.4940, 0.4970, 0.4954],
       device='cuda:0') torch.Size([16])
percent tensor([0.5068, 0.4900, 0.5052, 0.5078, 0.4964, 0.5135, 0.4913, 0.4929, 0.5073,
        0.4948, 0.5091, 0.4982, 0.4929, 0.5044, 0.4985, 0.5070],
       device='cuda:0') torch.Size([16])
percent tensor([0.6463, 0.6376, 0.5823, 0.5637, 0.5916, 0.6179, 0.6418, 0.5879, 0.5915,
        0.6082, 0.6184, 0.5798, 0.6651, 0.5688, 0.6572, 0.6284],
       device='cuda:0') torch.Size([16])
percent tensor([0.6272, 0.6456, 0.6215, 0.6641, 0.6253, 0.7304, 0.6308, 0.6026, 0.6562,
        0.6227, 0.6525, 0.6639, 0.6384, 0.6715, 0.6839, 0.6629],
       device='cuda:0') torch.Size([16])
percent tensor([0.5440, 0.5560, 0.5548, 0.5473, 0.5946, 0.5490, 0.5642, 0.5315, 0.6180,
        0.5857, 0.6104, 0.4946, 0.5497, 0.6854, 0.4434, 0.5875],
       device='cuda:0') torch.Size([16])
percent tensor([0.5856, 0.5726, 0.6757, 0.6939, 0.7198, 0.6781, 0.6268, 0.6535, 0.6310,
        0.6202, 0.6033, 0.6495, 0.5893, 0.6194, 0.6150, 0.6109],
       device='cuda:0') torch.Size([16])
percent tensor([0.5839, 0.7217, 0.7160, 0.6561, 0.7256, 0.5197, 0.5885, 0.5496, 0.7168,
        0.7050, 0.7415, 0.6720, 0.6796, 0.6503, 0.5429, 0.4653],
       device='cuda:0') torch.Size([16])
percent tensor([0.9994, 0.9997, 0.9997, 0.9997, 0.9995, 0.9989, 0.9994, 0.9990, 0.9996,
        0.9998, 0.9999, 0.9998, 0.9997, 0.9993, 0.9986, 0.9992],
       device='cuda:0') torch.Size([16])
Epoch: 130 | Batch_idx: 0 |  Loss: (0.1562) |  Loss2: (0.0000) | Acc: (94.00%) (121/128)
Epoch: 130 | Batch_idx: 10 |  Loss: (0.1587) |  Loss2: (0.0000) | Acc: (94.00%) (1329/1408)
Epoch: 130 | Batch_idx: 20 |  Loss: (0.1512) |  Loss2: (0.0000) | Acc: (94.00%) (2552/2688)
Epoch: 130 | Batch_idx: 30 |  Loss: (0.1520) |  Loss2: (0.0000) | Acc: (94.00%) (3767/3968)
Epoch: 130 | Batch_idx: 40 |  Loss: (0.1597) |  Loss2: (0.0000) | Acc: (94.00%) (4960/5248)
Epoch: 130 | Batch_idx: 50 |  Loss: (0.1557) |  Loss2: (0.0000) | Acc: (94.00%) (6182/6528)
Epoch: 130 | Batch_idx: 60 |  Loss: (0.1561) |  Loss2: (0.0000) | Acc: (94.00%) (7395/7808)
Epoch: 130 | Batch_idx: 70 |  Loss: (0.1568) |  Loss2: (0.0000) | Acc: (94.00%) (8606/9088)
Epoch: 130 | Batch_idx: 80 |  Loss: (0.1583) |  Loss2: (0.0000) | Acc: (94.00%) (9805/10368)
Epoch: 130 | Batch_idx: 90 |  Loss: (0.1581) |  Loss2: (0.0000) | Acc: (94.00%) (11022/11648)
Epoch: 130 | Batch_idx: 100 |  Loss: (0.1580) |  Loss2: (0.0000) | Acc: (94.00%) (12229/12928)
Epoch: 130 | Batch_idx: 110 |  Loss: (0.1573) |  Loss2: (0.0000) | Acc: (94.00%) (13440/14208)
Epoch: 130 | Batch_idx: 120 |  Loss: (0.1564) |  Loss2: (0.0000) | Acc: (94.00%) (14655/15488)
Epoch: 130 | Batch_idx: 130 |  Loss: (0.1566) |  Loss2: (0.0000) | Acc: (94.00%) (15855/16768)
Epoch: 130 | Batch_idx: 140 |  Loss: (0.1563) |  Loss2: (0.0000) | Acc: (94.00%) (17074/18048)
Epoch: 130 | Batch_idx: 150 |  Loss: (0.1573) |  Loss2: (0.0000) | Acc: (94.00%) (18276/19328)
Epoch: 130 | Batch_idx: 160 |  Loss: (0.1577) |  Loss2: (0.0000) | Acc: (94.00%) (19485/20608)
Epoch: 130 | Batch_idx: 170 |  Loss: (0.1578) |  Loss2: (0.0000) | Acc: (94.00%) (20693/21888)
Epoch: 130 | Batch_idx: 180 |  Loss: (0.1588) |  Loss2: (0.0000) | Acc: (94.00%) (21897/23168)
Epoch: 130 | Batch_idx: 190 |  Loss: (0.1589) |  Loss2: (0.0000) | Acc: (94.00%) (23112/24448)
Epoch: 130 | Batch_idx: 200 |  Loss: (0.1588) |  Loss2: (0.0000) | Acc: (94.00%) (24327/25728)
Epoch: 130 | Batch_idx: 210 |  Loss: (0.1588) |  Loss2: (0.0000) | Acc: (94.00%) (25542/27008)
Epoch: 130 | Batch_idx: 220 |  Loss: (0.1587) |  Loss2: (0.0000) | Acc: (94.00%) (26754/28288)
Epoch: 130 | Batch_idx: 230 |  Loss: (0.1581) |  Loss2: (0.0000) | Acc: (94.00%) (27974/29568)
Epoch: 130 | Batch_idx: 240 |  Loss: (0.1588) |  Loss2: (0.0000) | Acc: (94.00%) (29170/30848)
Epoch: 130 | Batch_idx: 250 |  Loss: (0.1583) |  Loss2: (0.0000) | Acc: (94.00%) (30384/32128)
Epoch: 130 | Batch_idx: 260 |  Loss: (0.1584) |  Loss2: (0.0000) | Acc: (94.00%) (31596/33408)
Epoch: 130 | Batch_idx: 270 |  Loss: (0.1586) |  Loss2: (0.0000) | Acc: (94.00%) (32794/34688)
Epoch: 130 | Batch_idx: 280 |  Loss: (0.1586) |  Loss2: (0.0000) | Acc: (94.00%) (33993/35968)
Epoch: 130 | Batch_idx: 290 |  Loss: (0.1588) |  Loss2: (0.0000) | Acc: (94.00%) (35197/37248)
Epoch: 130 | Batch_idx: 300 |  Loss: (0.1596) |  Loss2: (0.0000) | Acc: (94.00%) (36404/38528)
Epoch: 130 | Batch_idx: 310 |  Loss: (0.1596) |  Loss2: (0.0000) | Acc: (94.00%) (37609/39808)
Epoch: 130 | Batch_idx: 320 |  Loss: (0.1598) |  Loss2: (0.0000) | Acc: (94.00%) (38814/41088)
Epoch: 130 | Batch_idx: 330 |  Loss: (0.1598) |  Loss2: (0.0000) | Acc: (94.00%) (40030/42368)
Epoch: 130 | Batch_idx: 340 |  Loss: (0.1597) |  Loss2: (0.0000) | Acc: (94.00%) (41238/43648)
Epoch: 130 | Batch_idx: 350 |  Loss: (0.1603) |  Loss2: (0.0000) | Acc: (94.00%) (42436/44928)
Epoch: 130 | Batch_idx: 360 |  Loss: (0.1614) |  Loss2: (0.0000) | Acc: (94.00%) (43621/46208)
Epoch: 130 | Batch_idx: 370 |  Loss: (0.1619) |  Loss2: (0.0000) | Acc: (94.00%) (44821/47488)
Epoch: 130 | Batch_idx: 380 |  Loss: (0.1621) |  Loss2: (0.0000) | Acc: (94.00%) (46031/48768)
Epoch: 130 | Batch_idx: 390 |  Loss: (0.1626) |  Loss2: (0.0000) | Acc: (94.00%) (47183/50000)
=> saving checkpoint 'drive/app/torch/save_Schedule/checkpoint_130.pth.tar'
# TEST : Loss: (0.4293) | Acc: (86.00%) (8676/10000)
percent tensor([0.4972, 0.4979, 0.5027, 0.4938, 0.5020, 0.4979, 0.4995, 0.4969, 0.4985,
        0.4992, 0.5005, 0.5016, 0.4970, 0.4948, 0.4976, 0.4962],
       device='cuda:0') torch.Size([16])
percent tensor([0.5078, 0.4895, 0.5049, 0.5078, 0.4977, 0.5145, 0.4917, 0.4934, 0.5085,
        0.4958, 0.5100, 0.5002, 0.4946, 0.5026, 0.4985, 0.5072],
       device='cuda:0') torch.Size([16])
percent tensor([0.6397, 0.6373, 0.5761, 0.5622, 0.5881, 0.6112, 0.6396, 0.5868, 0.5900,
        0.6095, 0.6115, 0.5786, 0.6590, 0.5771, 0.6560, 0.6218],
       device='cuda:0') torch.Size([16])
percent tensor([0.6234, 0.6392, 0.6247, 0.6632, 0.6318, 0.7273, 0.6307, 0.6033, 0.6491,
        0.6187, 0.6464, 0.6672, 0.6363, 0.6564, 0.6770, 0.6588],
       device='cuda:0') torch.Size([16])
percent tensor([0.5565, 0.5678, 0.5586, 0.5438, 0.5990, 0.5483, 0.5773, 0.5425, 0.6324,
        0.5928, 0.6324, 0.5149, 0.5688, 0.6802, 0.4648, 0.5986],
       device='cuda:0') torch.Size([16])
percent tensor([0.5807, 0.5787, 0.6707, 0.6998, 0.7251, 0.6857, 0.6316, 0.6537, 0.6350,
        0.6089, 0.6154, 0.6472, 0.5927, 0.6246, 0.6081, 0.6187],
       device='cuda:0') torch.Size([16])
percent tensor([0.5628, 0.7095, 0.7145, 0.6344, 0.7040, 0.5505, 0.5670, 0.5488, 0.6908,
        0.6601, 0.7444, 0.6553, 0.6763, 0.6459, 0.5375, 0.4706],
       device='cuda:0') torch.Size([16])
percent tensor([0.9995, 0.9997, 0.9997, 0.9997, 0.9993, 0.9995, 0.9993, 0.9992, 0.9996,
        0.9997, 0.9999, 0.9996, 0.9998, 0.9994, 0.9986, 0.9994],
       device='cuda:0') torch.Size([16])
Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 3, 3, 3]) tensor(189.4569, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(818.6413, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(822.1082, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([128, 64, 3, 3]) tensor(1530.0544, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([128, 64, 1, 1]) tensor(487.1728, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([128, 128, 3, 3]) tensor(2287.1570, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([256, 128, 3, 3]) tensor(4275.8477, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([256, 128, 1, 1]) tensor(1377.4304, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([256, 256, 3, 3]) tensor(6180.0820, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([512, 256, 3, 3]) tensor(11761.0918, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([512, 256, 1, 1]) tensor(3895.6150, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([512, 512, 3, 3]) tensor(16448.4727, device='cuda:0', grad_fn=<NormBackward0>)
Epoch: 131 | Batch_idx: 0 |  Loss: (0.1994) |  Loss2: (0.0000) | Acc: (91.00%) (117/128)
Epoch: 131 | Batch_idx: 10 |  Loss: (0.1719) |  Loss2: (0.0000) | Acc: (93.00%) (1320/1408)
Epoch: 131 | Batch_idx: 20 |  Loss: (0.1756) |  Loss2: (0.0000) | Acc: (94.00%) (2529/2688)
Epoch: 131 | Batch_idx: 30 |  Loss: (0.1764) |  Loss2: (0.0000) | Acc: (94.00%) (3733/3968)
Epoch: 131 | Batch_idx: 40 |  Loss: (0.1696) |  Loss2: (0.0000) | Acc: (94.00%) (4944/5248)
Epoch: 131 | Batch_idx: 50 |  Loss: (0.1679) |  Loss2: (0.0000) | Acc: (94.00%) (6156/6528)
Epoch: 131 | Batch_idx: 60 |  Loss: (0.1672) |  Loss2: (0.0000) | Acc: (94.00%) (7364/7808)
Epoch: 131 | Batch_idx: 70 |  Loss: (0.1649) |  Loss2: (0.0000) | Acc: (94.00%) (8578/9088)
Epoch: 131 | Batch_idx: 80 |  Loss: (0.1650) |  Loss2: (0.0000) | Acc: (94.00%) (9791/10368)
Epoch: 131 | Batch_idx: 90 |  Loss: (0.1674) |  Loss2: (0.0000) | Acc: (94.00%) (10987/11648)
Epoch: 131 | Batch_idx: 100 |  Loss: (0.1662) |  Loss2: (0.0000) | Acc: (94.00%) (12198/12928)
Epoch: 131 | Batch_idx: 110 |  Loss: (0.1649) |  Loss2: (0.0000) | Acc: (94.00%) (13417/14208)
Epoch: 131 | Batch_idx: 120 |  Loss: (0.1635) |  Loss2: (0.0000) | Acc: (94.00%) (14632/15488)
Epoch: 131 | Batch_idx: 130 |  Loss: (0.1624) |  Loss2: (0.0000) | Acc: (94.00%) (15848/16768)
Epoch: 131 | Batch_idx: 140 |  Loss: (0.1618) |  Loss2: (0.0000) | Acc: (94.00%) (17061/18048)
Epoch: 131 | Batch_idx: 150 |  Loss: (0.1618) |  Loss2: (0.0000) | Acc: (94.00%) (18255/19328)
Epoch: 131 | Batch_idx: 160 |  Loss: (0.1630) |  Loss2: (0.0000) | Acc: (94.00%) (19453/20608)
Epoch: 131 | Batch_idx: 170 |  Loss: (0.1618) |  Loss2: (0.0000) | Acc: (94.00%) (20672/21888)
Epoch: 131 | Batch_idx: 180 |  Loss: (0.1609) |  Loss2: (0.0000) | Acc: (94.00%) (21888/23168)
Epoch: 131 | Batch_idx: 190 |  Loss: (0.1598) |  Loss2: (0.0000) | Acc: (94.00%) (23111/24448)
Epoch: 131 | Batch_idx: 200 |  Loss: (0.1596) |  Loss2: (0.0000) | Acc: (94.00%) (24329/25728)
Epoch: 131 | Batch_idx: 210 |  Loss: (0.1599) |  Loss2: (0.0000) | Acc: (94.00%) (25533/27008)
Epoch: 131 | Batch_idx: 220 |  Loss: (0.1598) |  Loss2: (0.0000) | Acc: (94.00%) (26744/28288)
Epoch: 131 | Batch_idx: 230 |  Loss: (0.1599) |  Loss2: (0.0000) | Acc: (94.00%) (27956/29568)
Epoch: 131 | Batch_idx: 240 |  Loss: (0.1597) |  Loss2: (0.0000) | Acc: (94.00%) (29172/30848)
Epoch: 131 | Batch_idx: 250 |  Loss: (0.1602) |  Loss2: (0.0000) | Acc: (94.00%) (30379/32128)
Epoch: 131 | Batch_idx: 260 |  Loss: (0.1603) |  Loss2: (0.0000) | Acc: (94.00%) (31588/33408)
Epoch: 131 | Batch_idx: 270 |  Loss: (0.1593) |  Loss2: (0.0000) | Acc: (94.00%) (32801/34688)
Epoch: 131 | Batch_idx: 280 |  Loss: (0.1597) |  Loss2: (0.0000) | Acc: (94.00%) (34009/35968)
Epoch: 131 | Batch_idx: 290 |  Loss: (0.1597) |  Loss2: (0.0000) | Acc: (94.00%) (35215/37248)
Epoch: 131 | Batch_idx: 300 |  Loss: (0.1603) |  Loss2: (0.0000) | Acc: (94.00%) (36425/38528)
Epoch: 131 | Batch_idx: 310 |  Loss: (0.1609) |  Loss2: (0.0000) | Acc: (94.00%) (37619/39808)
Epoch: 131 | Batch_idx: 320 |  Loss: (0.1618) |  Loss2: (0.0000) | Acc: (94.00%) (38806/41088)
Epoch: 131 | Batch_idx: 330 |  Loss: (0.1622) |  Loss2: (0.0000) | Acc: (94.00%) (40007/42368)
Epoch: 131 | Batch_idx: 340 |  Loss: (0.1622) |  Loss2: (0.0000) | Acc: (94.00%) (41216/43648)
Epoch: 131 | Batch_idx: 350 |  Loss: (0.1630) |  Loss2: (0.0000) | Acc: (94.00%) (42407/44928)
Epoch: 131 | Batch_idx: 360 |  Loss: (0.1628) |  Loss2: (0.0000) | Acc: (94.00%) (43622/46208)
Epoch: 131 | Batch_idx: 370 |  Loss: (0.1628) |  Loss2: (0.0000) | Acc: (94.00%) (44834/47488)
Epoch: 131 | Batch_idx: 380 |  Loss: (0.1637) |  Loss2: (0.0000) | Acc: (94.00%) (46020/48768)
Epoch: 131 | Batch_idx: 390 |  Loss: (0.1638) |  Loss2: (0.0000) | Acc: (94.00%) (47183/50000)
# TEST : Loss: (0.4563) | Acc: (86.00%) (8657/10000)
percent tensor([0.4972, 0.4972, 0.5039, 0.4936, 0.5031, 0.4977, 0.4992, 0.4967, 0.4981,
        0.4991, 0.4997, 0.5020, 0.4967, 0.4935, 0.4972, 0.4956],
       device='cuda:0') torch.Size([16])
percent tensor([0.5061, 0.4877, 0.5030, 0.5088, 0.4968, 0.5145, 0.4881, 0.4914, 0.5069,
        0.4936, 0.5084, 0.4974, 0.4919, 0.5001, 0.4973, 0.5059],
       device='cuda:0') torch.Size([16])
percent tensor([0.6460, 0.6413, 0.5838, 0.5647, 0.5897, 0.6127, 0.6439, 0.5930, 0.5980,
        0.6132, 0.6172, 0.5820, 0.6644, 0.5828, 0.6606, 0.6286],
       device='cuda:0') torch.Size([16])
percent tensor([0.6243, 0.6395, 0.6151, 0.6605, 0.6253, 0.7286, 0.6264, 0.5995, 0.6465,
        0.6143, 0.6401, 0.6567, 0.6275, 0.6620, 0.6774, 0.6639],
       device='cuda:0') torch.Size([16])
percent tensor([0.5622, 0.5632, 0.5616, 0.5555, 0.6023, 0.5463, 0.5759, 0.5458, 0.6358,
        0.5794, 0.6254, 0.5016, 0.5670, 0.6820, 0.4652, 0.5952],
       device='cuda:0') torch.Size([16])
percent tensor([0.5903, 0.5800, 0.6840, 0.6948, 0.7296, 0.6850, 0.6294, 0.6578, 0.6384,
        0.6061, 0.6147, 0.6506, 0.5959, 0.6239, 0.6084, 0.6253],
       device='cuda:0') torch.Size([16])
percent tensor([0.5802, 0.7146, 0.7322, 0.6553, 0.7273, 0.5692, 0.5602, 0.5525, 0.7119,
        0.6671, 0.7596, 0.6637, 0.6916, 0.6473, 0.5636, 0.4653],
       device='cuda:0') torch.Size([16])
percent tensor([0.9997, 0.9997, 0.9998, 0.9997, 0.9997, 0.9995, 0.9995, 0.9992, 0.9997,
        0.9996, 0.9999, 0.9998, 0.9997, 0.9995, 0.9984, 0.9996],
       device='cuda:0') torch.Size([16])
Epoch: 132 | Batch_idx: 0 |  Loss: (0.1557) |  Loss2: (0.0000) | Acc: (96.00%) (123/128)
Epoch: 132 | Batch_idx: 10 |  Loss: (0.1579) |  Loss2: (0.0000) | Acc: (94.00%) (1335/1408)
Epoch: 132 | Batch_idx: 20 |  Loss: (0.1531) |  Loss2: (0.0000) | Acc: (94.00%) (2543/2688)
Epoch: 132 | Batch_idx: 30 |  Loss: (0.1548) |  Loss2: (0.0000) | Acc: (94.00%) (3750/3968)
Epoch: 132 | Batch_idx: 40 |  Loss: (0.1488) |  Loss2: (0.0000) | Acc: (94.00%) (4980/5248)
Epoch: 132 | Batch_idx: 50 |  Loss: (0.1498) |  Loss2: (0.0000) | Acc: (94.00%) (6194/6528)
Epoch: 132 | Batch_idx: 60 |  Loss: (0.1517) |  Loss2: (0.0000) | Acc: (94.00%) (7403/7808)
Epoch: 132 | Batch_idx: 70 |  Loss: (0.1527) |  Loss2: (0.0000) | Acc: (94.00%) (8610/9088)
Epoch: 132 | Batch_idx: 80 |  Loss: (0.1512) |  Loss2: (0.0000) | Acc: (94.00%) (9831/10368)
Epoch: 132 | Batch_idx: 90 |  Loss: (0.1515) |  Loss2: (0.0000) | Acc: (94.00%) (11037/11648)
Epoch: 132 | Batch_idx: 100 |  Loss: (0.1497) |  Loss2: (0.0000) | Acc: (94.00%) (12264/12928)
Epoch: 132 | Batch_idx: 110 |  Loss: (0.1489) |  Loss2: (0.0000) | Acc: (94.00%) (13484/14208)
Epoch: 132 | Batch_idx: 120 |  Loss: (0.1486) |  Loss2: (0.0000) | Acc: (94.00%) (14705/15488)
Epoch: 132 | Batch_idx: 130 |  Loss: (0.1484) |  Loss2: (0.0000) | Acc: (94.00%) (15915/16768)
Epoch: 132 | Batch_idx: 140 |  Loss: (0.1494) |  Loss2: (0.0000) | Acc: (94.00%) (17125/18048)
Epoch: 132 | Batch_idx: 150 |  Loss: (0.1506) |  Loss2: (0.0000) | Acc: (94.00%) (18336/19328)
Epoch: 132 | Batch_idx: 160 |  Loss: (0.1512) |  Loss2: (0.0000) | Acc: (94.00%) (19545/20608)
Epoch: 132 | Batch_idx: 170 |  Loss: (0.1512) |  Loss2: (0.0000) | Acc: (94.00%) (20762/21888)
Epoch: 132 | Batch_idx: 180 |  Loss: (0.1528) |  Loss2: (0.0000) | Acc: (94.00%) (21967/23168)
Epoch: 132 | Batch_idx: 190 |  Loss: (0.1540) |  Loss2: (0.0000) | Acc: (94.00%) (23162/24448)
Epoch: 132 | Batch_idx: 200 |  Loss: (0.1548) |  Loss2: (0.0000) | Acc: (94.00%) (24360/25728)
Epoch: 132 | Batch_idx: 210 |  Loss: (0.1562) |  Loss2: (0.0000) | Acc: (94.00%) (25562/27008)
Epoch: 132 | Batch_idx: 220 |  Loss: (0.1564) |  Loss2: (0.0000) | Acc: (94.00%) (26771/28288)
Epoch: 132 | Batch_idx: 230 |  Loss: (0.1552) |  Loss2: (0.0000) | Acc: (94.00%) (27988/29568)
Epoch: 132 | Batch_idx: 240 |  Loss: (0.1558) |  Loss2: (0.0000) | Acc: (94.00%) (29194/30848)
Epoch: 132 | Batch_idx: 250 |  Loss: (0.1562) |  Loss2: (0.0000) | Acc: (94.00%) (30403/32128)
Epoch: 132 | Batch_idx: 260 |  Loss: (0.1574) |  Loss2: (0.0000) | Acc: (94.00%) (31599/33408)
Epoch: 132 | Batch_idx: 270 |  Loss: (0.1570) |  Loss2: (0.0000) | Acc: (94.00%) (32823/34688)
Epoch: 132 | Batch_idx: 280 |  Loss: (0.1564) |  Loss2: (0.0000) | Acc: (94.00%) (34043/35968)
Epoch: 132 | Batch_idx: 290 |  Loss: (0.1563) |  Loss2: (0.0000) | Acc: (94.00%) (35250/37248)
Epoch: 132 | Batch_idx: 300 |  Loss: (0.1555) |  Loss2: (0.0000) | Acc: (94.00%) (36467/38528)
Epoch: 132 | Batch_idx: 310 |  Loss: (0.1564) |  Loss2: (0.0000) | Acc: (94.00%) (37666/39808)
Epoch: 132 | Batch_idx: 320 |  Loss: (0.1572) |  Loss2: (0.0000) | Acc: (94.00%) (38865/41088)
Epoch: 132 | Batch_idx: 330 |  Loss: (0.1575) |  Loss2: (0.0000) | Acc: (94.00%) (40065/42368)
Epoch: 132 | Batch_idx: 340 |  Loss: (0.1571) |  Loss2: (0.0000) | Acc: (94.00%) (41287/43648)
Epoch: 132 | Batch_idx: 350 |  Loss: (0.1572) |  Loss2: (0.0000) | Acc: (94.00%) (42510/44928)
Epoch: 132 | Batch_idx: 360 |  Loss: (0.1568) |  Loss2: (0.0000) | Acc: (94.00%) (43732/46208)
Epoch: 132 | Batch_idx: 370 |  Loss: (0.1566) |  Loss2: (0.0000) | Acc: (94.00%) (44951/47488)
Epoch: 132 | Batch_idx: 380 |  Loss: (0.1566) |  Loss2: (0.0000) | Acc: (94.00%) (46166/48768)
Epoch: 132 | Batch_idx: 390 |  Loss: (0.1570) |  Loss2: (0.0000) | Acc: (94.00%) (47325/50000)
# TEST : Loss: (0.4044) | Acc: (87.00%) (8736/10000)
percent tensor([0.4973, 0.4973, 0.5037, 0.4935, 0.5032, 0.4984, 0.4993, 0.4965, 0.4980,
        0.4989, 0.4999, 0.5022, 0.4966, 0.4936, 0.4975, 0.4958],
       device='cuda:0') torch.Size([16])
percent tensor([0.5047, 0.4893, 0.5019, 0.5058, 0.4945, 0.5136, 0.4904, 0.4900, 0.5069,
        0.4946, 0.5077, 0.4962, 0.4907, 0.5060, 0.4963, 0.5051],
       device='cuda:0') torch.Size([16])
percent tensor([0.6467, 0.6373, 0.5857, 0.5652, 0.5921, 0.6099, 0.6423, 0.5907, 0.5993,
        0.6098, 0.6194, 0.5835, 0.6646, 0.5752, 0.6568, 0.6248],
       device='cuda:0') torch.Size([16])
percent tensor([0.6209, 0.6419, 0.6191, 0.6602, 0.6182, 0.7162, 0.6277, 0.6020, 0.6516,
        0.6244, 0.6417, 0.6605, 0.6309, 0.6677, 0.6719, 0.6566],
       device='cuda:0') torch.Size([16])
percent tensor([0.5525, 0.5577, 0.5471, 0.5379, 0.5968, 0.5550, 0.5780, 0.5307, 0.6342,
        0.5857, 0.6147, 0.4992, 0.5585, 0.7006, 0.4610, 0.5907],
       device='cuda:0') torch.Size([16])
percent tensor([0.5904, 0.5685, 0.6910, 0.6910, 0.7290, 0.6903, 0.6264, 0.6553, 0.6340,
        0.6109, 0.6059, 0.6485, 0.5882, 0.6291, 0.6061, 0.6179],
       device='cuda:0') torch.Size([16])
percent tensor([0.5847, 0.6961, 0.7143, 0.6656, 0.7190, 0.6056, 0.5530, 0.5493, 0.6964,
        0.6632, 0.7535, 0.6669, 0.6791, 0.6337, 0.5641, 0.4855],
       device='cuda:0') torch.Size([16])
percent tensor([0.9994, 0.9995, 0.9998, 0.9998, 0.9994, 0.9994, 0.9995, 0.9995, 0.9997,
        0.9997, 0.9999, 0.9999, 0.9996, 0.9994, 0.9984, 0.9994],
       device='cuda:0') torch.Size([16])
Epoch: 133 | Batch_idx: 0 |  Loss: (0.1940) |  Loss2: (0.0000) | Acc: (93.00%) (120/128)
Epoch: 133 | Batch_idx: 10 |  Loss: (0.1650) |  Loss2: (0.0000) | Acc: (94.00%) (1332/1408)
Epoch: 133 | Batch_idx: 20 |  Loss: (0.1580) |  Loss2: (0.0000) | Acc: (94.00%) (2543/2688)
Epoch: 133 | Batch_idx: 30 |  Loss: (0.1549) |  Loss2: (0.0000) | Acc: (94.00%) (3751/3968)
Epoch: 133 | Batch_idx: 40 |  Loss: (0.1497) |  Loss2: (0.0000) | Acc: (94.00%) (4973/5248)
Epoch: 133 | Batch_idx: 50 |  Loss: (0.1497) |  Loss2: (0.0000) | Acc: (94.00%) (6186/6528)
Epoch: 133 | Batch_idx: 60 |  Loss: (0.1509) |  Loss2: (0.0000) | Acc: (94.00%) (7399/7808)
Epoch: 133 | Batch_idx: 70 |  Loss: (0.1499) |  Loss2: (0.0000) | Acc: (94.00%) (8609/9088)
Epoch: 133 | Batch_idx: 80 |  Loss: (0.1481) |  Loss2: (0.0000) | Acc: (94.00%) (9831/10368)
Epoch: 133 | Batch_idx: 90 |  Loss: (0.1466) |  Loss2: (0.0000) | Acc: (94.00%) (11053/11648)
Epoch: 133 | Batch_idx: 100 |  Loss: (0.1442) |  Loss2: (0.0000) | Acc: (95.00%) (12286/12928)
Epoch: 133 | Batch_idx: 110 |  Loss: (0.1437) |  Loss2: (0.0000) | Acc: (95.00%) (13501/14208)
Epoch: 133 | Batch_idx: 120 |  Loss: (0.1428) |  Loss2: (0.0000) | Acc: (95.00%) (14730/15488)
Epoch: 133 | Batch_idx: 130 |  Loss: (0.1426) |  Loss2: (0.0000) | Acc: (95.00%) (15947/16768)
Epoch: 133 | Batch_idx: 140 |  Loss: (0.1422) |  Loss2: (0.0000) | Acc: (95.00%) (17172/18048)
Epoch: 133 | Batch_idx: 150 |  Loss: (0.1417) |  Loss2: (0.0000) | Acc: (95.00%) (18398/19328)
Epoch: 133 | Batch_idx: 160 |  Loss: (0.1432) |  Loss2: (0.0000) | Acc: (95.00%) (19591/20608)
Epoch: 133 | Batch_idx: 170 |  Loss: (0.1427) |  Loss2: (0.0000) | Acc: (95.00%) (20814/21888)
Epoch: 133 | Batch_idx: 180 |  Loss: (0.1434) |  Loss2: (0.0000) | Acc: (95.00%) (22033/23168)
Epoch: 133 | Batch_idx: 190 |  Loss: (0.1433) |  Loss2: (0.0000) | Acc: (95.00%) (23239/24448)
Epoch: 133 | Batch_idx: 200 |  Loss: (0.1434) |  Loss2: (0.0000) | Acc: (95.00%) (24455/25728)
Epoch: 133 | Batch_idx: 210 |  Loss: (0.1437) |  Loss2: (0.0000) | Acc: (95.00%) (25668/27008)
Epoch: 133 | Batch_idx: 220 |  Loss: (0.1444) |  Loss2: (0.0000) | Acc: (95.00%) (26885/28288)
Epoch: 133 | Batch_idx: 230 |  Loss: (0.1441) |  Loss2: (0.0000) | Acc: (95.00%) (28105/29568)
Epoch: 133 | Batch_idx: 240 |  Loss: (0.1447) |  Loss2: (0.0000) | Acc: (95.00%) (29316/30848)
Epoch: 133 | Batch_idx: 250 |  Loss: (0.1462) |  Loss2: (0.0000) | Acc: (94.00%) (30514/32128)
Epoch: 133 | Batch_idx: 260 |  Loss: (0.1473) |  Loss2: (0.0000) | Acc: (94.00%) (31718/33408)
Epoch: 133 | Batch_idx: 270 |  Loss: (0.1483) |  Loss2: (0.0000) | Acc: (94.00%) (32921/34688)
Epoch: 133 | Batch_idx: 280 |  Loss: (0.1480) |  Loss2: (0.0000) | Acc: (94.00%) (34138/35968)
Epoch: 133 | Batch_idx: 290 |  Loss: (0.1479) |  Loss2: (0.0000) | Acc: (94.00%) (35356/37248)
Epoch: 133 | Batch_idx: 300 |  Loss: (0.1481) |  Loss2: (0.0000) | Acc: (94.00%) (36565/38528)
Epoch: 133 | Batch_idx: 310 |  Loss: (0.1485) |  Loss2: (0.0000) | Acc: (94.00%) (37777/39808)
Epoch: 133 | Batch_idx: 320 |  Loss: (0.1491) |  Loss2: (0.0000) | Acc: (94.00%) (38984/41088)
Epoch: 133 | Batch_idx: 330 |  Loss: (0.1491) |  Loss2: (0.0000) | Acc: (94.00%) (40194/42368)
Epoch: 133 | Batch_idx: 340 |  Loss: (0.1493) |  Loss2: (0.0000) | Acc: (94.00%) (41409/43648)
Epoch: 133 | Batch_idx: 350 |  Loss: (0.1497) |  Loss2: (0.0000) | Acc: (94.00%) (42609/44928)
Epoch: 133 | Batch_idx: 360 |  Loss: (0.1490) |  Loss2: (0.0000) | Acc: (94.00%) (43838/46208)
Epoch: 133 | Batch_idx: 370 |  Loss: (0.1489) |  Loss2: (0.0000) | Acc: (94.00%) (45051/47488)
Epoch: 133 | Batch_idx: 380 |  Loss: (0.1486) |  Loss2: (0.0000) | Acc: (94.00%) (46263/48768)
Epoch: 133 | Batch_idx: 390 |  Loss: (0.1487) |  Loss2: (0.0000) | Acc: (94.00%) (47432/50000)
# TEST : Loss: (0.4106) | Acc: (87.00%) (8793/10000)
percent tensor([0.4972, 0.4972, 0.5036, 0.4933, 0.5031, 0.4976, 0.4992, 0.4969, 0.4984,
        0.4991, 0.5001, 0.5021, 0.4968, 0.4938, 0.4973, 0.4957],
       device='cuda:0') torch.Size([16])
percent tensor([0.5066, 0.4907, 0.5062, 0.5081, 0.4987, 0.5144, 0.4932, 0.4934, 0.5075,
        0.4972, 0.5099, 0.5013, 0.4929, 0.5050, 0.4988, 0.5073],
       device='cuda:0') torch.Size([16])
percent tensor([0.6432, 0.6379, 0.5754, 0.5582, 0.5840, 0.6158, 0.6368, 0.5884, 0.5930,
        0.6033, 0.6149, 0.5723, 0.6635, 0.5710, 0.6586, 0.6218],
       device='cuda:0') torch.Size([16])
percent tensor([0.6279, 0.6467, 0.6178, 0.6638, 0.6271, 0.7246, 0.6348, 0.6062, 0.6557,
        0.6292, 0.6524, 0.6642, 0.6392, 0.6718, 0.6794, 0.6640],
       device='cuda:0') torch.Size([16])
percent tensor([0.5585, 0.5659, 0.5640, 0.5488, 0.6044, 0.5478, 0.5834, 0.5355, 0.6223,
        0.5991, 0.6367, 0.5270, 0.5721, 0.6783, 0.4733, 0.5977],
       device='cuda:0') torch.Size([16])
percent tensor([0.5843, 0.5771, 0.6730, 0.7027, 0.7202, 0.6894, 0.6249, 0.6484, 0.6245,
        0.6142, 0.6111, 0.6460, 0.5928, 0.6263, 0.6069, 0.6217],
       device='cuda:0') torch.Size([16])
percent tensor([0.5684, 0.7057, 0.7125, 0.6624, 0.7066, 0.5522, 0.5668, 0.5469, 0.7059,
        0.6853, 0.7462, 0.6672, 0.6791, 0.6662, 0.5507, 0.4700],
       device='cuda:0') torch.Size([16])
percent tensor([0.9995, 0.9996, 0.9998, 0.9997, 0.9995, 0.9992, 0.9995, 0.9994, 0.9998,
        0.9997, 1.0000, 0.9998, 0.9997, 0.9994, 0.9983, 0.9993],
       device='cuda:0') torch.Size([16])
Epoch: 134 | Batch_idx: 0 |  Loss: (0.1179) |  Loss2: (0.0000) | Acc: (96.00%) (124/128)
Epoch: 134 | Batch_idx: 10 |  Loss: (0.1372) |  Loss2: (0.0000) | Acc: (95.00%) (1339/1408)
Epoch: 134 | Batch_idx: 20 |  Loss: (0.1524) |  Loss2: (0.0000) | Acc: (94.00%) (2549/2688)
Epoch: 134 | Batch_idx: 30 |  Loss: (0.1504) |  Loss2: (0.0000) | Acc: (94.00%) (3764/3968)
Epoch: 134 | Batch_idx: 40 |  Loss: (0.1444) |  Loss2: (0.0000) | Acc: (95.00%) (4990/5248)
Epoch: 134 | Batch_idx: 50 |  Loss: (0.1456) |  Loss2: (0.0000) | Acc: (95.00%) (6204/6528)
Epoch: 134 | Batch_idx: 60 |  Loss: (0.1427) |  Loss2: (0.0000) | Acc: (95.00%) (7432/7808)
Epoch: 134 | Batch_idx: 70 |  Loss: (0.1423) |  Loss2: (0.0000) | Acc: (95.00%) (8652/9088)
Epoch: 134 | Batch_idx: 80 |  Loss: (0.1424) |  Loss2: (0.0000) | Acc: (95.00%) (9866/10368)
Epoch: 134 | Batch_idx: 90 |  Loss: (0.1420) |  Loss2: (0.0000) | Acc: (95.00%) (11086/11648)
Epoch: 134 | Batch_idx: 100 |  Loss: (0.1425) |  Loss2: (0.0000) | Acc: (95.00%) (12299/12928)
Epoch: 134 | Batch_idx: 110 |  Loss: (0.1444) |  Loss2: (0.0000) | Acc: (95.00%) (13509/14208)
Epoch: 134 | Batch_idx: 120 |  Loss: (0.1461) |  Loss2: (0.0000) | Acc: (95.00%) (14720/15488)
Epoch: 134 | Batch_idx: 130 |  Loss: (0.1474) |  Loss2: (0.0000) | Acc: (94.00%) (15925/16768)
Epoch: 134 | Batch_idx: 140 |  Loss: (0.1469) |  Loss2: (0.0000) | Acc: (94.00%) (17139/18048)
Epoch: 134 | Batch_idx: 150 |  Loss: (0.1458) |  Loss2: (0.0000) | Acc: (95.00%) (18363/19328)
Epoch: 134 | Batch_idx: 160 |  Loss: (0.1457) |  Loss2: (0.0000) | Acc: (95.00%) (19578/20608)
Epoch: 134 | Batch_idx: 170 |  Loss: (0.1455) |  Loss2: (0.0000) | Acc: (95.00%) (20801/21888)
Epoch: 134 | Batch_idx: 180 |  Loss: (0.1469) |  Loss2: (0.0000) | Acc: (94.00%) (22002/23168)
Epoch: 134 | Batch_idx: 190 |  Loss: (0.1476) |  Loss2: (0.0000) | Acc: (94.00%) (23205/24448)
Epoch: 134 | Batch_idx: 200 |  Loss: (0.1472) |  Loss2: (0.0000) | Acc: (94.00%) (24424/25728)
Epoch: 134 | Batch_idx: 210 |  Loss: (0.1477) |  Loss2: (0.0000) | Acc: (94.00%) (25635/27008)
Epoch: 134 | Batch_idx: 220 |  Loss: (0.1478) |  Loss2: (0.0000) | Acc: (94.00%) (26848/28288)
Epoch: 134 | Batch_idx: 230 |  Loss: (0.1479) |  Loss2: (0.0000) | Acc: (94.00%) (28059/29568)
Epoch: 134 | Batch_idx: 240 |  Loss: (0.1481) |  Loss2: (0.0000) | Acc: (94.00%) (29265/30848)
Epoch: 134 | Batch_idx: 250 |  Loss: (0.1487) |  Loss2: (0.0000) | Acc: (94.00%) (30467/32128)
Epoch: 134 | Batch_idx: 260 |  Loss: (0.1489) |  Loss2: (0.0000) | Acc: (94.00%) (31678/33408)
Epoch: 134 | Batch_idx: 270 |  Loss: (0.1485) |  Loss2: (0.0000) | Acc: (94.00%) (32894/34688)
Epoch: 134 | Batch_idx: 280 |  Loss: (0.1477) |  Loss2: (0.0000) | Acc: (94.00%) (34119/35968)
Epoch: 134 | Batch_idx: 290 |  Loss: (0.1476) |  Loss2: (0.0000) | Acc: (94.00%) (35330/37248)
Epoch: 134 | Batch_idx: 300 |  Loss: (0.1466) |  Loss2: (0.0000) | Acc: (94.00%) (36560/38528)
Epoch: 134 | Batch_idx: 310 |  Loss: (0.1469) |  Loss2: (0.0000) | Acc: (94.00%) (37773/39808)
Epoch: 134 | Batch_idx: 320 |  Loss: (0.1472) |  Loss2: (0.0000) | Acc: (94.00%) (38982/41088)
Epoch: 134 | Batch_idx: 330 |  Loss: (0.1475) |  Loss2: (0.0000) | Acc: (94.00%) (40187/42368)
Epoch: 134 | Batch_idx: 340 |  Loss: (0.1477) |  Loss2: (0.0000) | Acc: (94.00%) (41403/43648)
Epoch: 134 | Batch_idx: 350 |  Loss: (0.1477) |  Loss2: (0.0000) | Acc: (94.00%) (42617/44928)
Epoch: 134 | Batch_idx: 360 |  Loss: (0.1478) |  Loss2: (0.0000) | Acc: (94.00%) (43821/46208)
Epoch: 134 | Batch_idx: 370 |  Loss: (0.1481) |  Loss2: (0.0000) | Acc: (94.00%) (45037/47488)
Epoch: 134 | Batch_idx: 380 |  Loss: (0.1482) |  Loss2: (0.0000) | Acc: (94.00%) (46243/48768)
Epoch: 134 | Batch_idx: 390 |  Loss: (0.1487) |  Loss2: (0.0000) | Acc: (94.00%) (47412/50000)
# TEST : Loss: (0.4153) | Acc: (87.00%) (8743/10000)
percent tensor([0.4977, 0.4974, 0.5034, 0.4932, 0.5030, 0.4984, 0.4994, 0.4962, 0.4985,
        0.4991, 0.5003, 0.5018, 0.4970, 0.4937, 0.4974, 0.4959],
       device='cuda:0') torch.Size([16])
percent tensor([0.5069, 0.4874, 0.5065, 0.5103, 0.4985, 0.5146, 0.4892, 0.4932, 0.5071,
        0.4953, 0.5080, 0.4997, 0.4921, 0.5005, 0.4978, 0.5068],
       device='cuda:0') torch.Size([16])
percent tensor([0.6400, 0.6379, 0.5718, 0.5522, 0.5814, 0.6100, 0.6386, 0.5846, 0.5886,
        0.6037, 0.6153, 0.5686, 0.6603, 0.5743, 0.6534, 0.6199],
       device='cuda:0') torch.Size([16])
percent tensor([0.6193, 0.6365, 0.6076, 0.6579, 0.6165, 0.7204, 0.6282, 0.5944, 0.6434,
        0.6242, 0.6426, 0.6551, 0.6241, 0.6685, 0.6696, 0.6598],
       device='cuda:0') torch.Size([16])
percent tensor([0.5523, 0.5508, 0.5515, 0.5493, 0.5903, 0.5489, 0.5596, 0.5289, 0.6190,
        0.5817, 0.6213, 0.4883, 0.5535, 0.6898, 0.4509, 0.5991],
       device='cuda:0') torch.Size([16])
percent tensor([0.5939, 0.5773, 0.6749, 0.6941, 0.7157, 0.6910, 0.6279, 0.6536, 0.6382,
        0.6136, 0.6188, 0.6509, 0.5968, 0.6341, 0.6046, 0.6204],
       device='cuda:0') torch.Size([16])
percent tensor([0.5961, 0.7212, 0.7105, 0.6471, 0.7068, 0.5707, 0.5874, 0.5713, 0.7121,
        0.6841, 0.7392, 0.6554, 0.6892, 0.6406, 0.5434, 0.4756],
       device='cuda:0') torch.Size([16])
percent tensor([0.9995, 0.9996, 0.9997, 0.9996, 0.9993, 0.9993, 0.9996, 0.9993, 0.9996,
        0.9998, 0.9999, 0.9998, 0.9996, 0.9993, 0.9983, 0.9993],
       device='cuda:0') torch.Size([16])
Epoch: 135 | Batch_idx: 0 |  Loss: (0.1385) |  Loss2: (0.0000) | Acc: (96.00%) (124/128)
Epoch: 135 | Batch_idx: 10 |  Loss: (0.1328) |  Loss2: (0.0000) | Acc: (95.00%) (1341/1408)
Epoch: 135 | Batch_idx: 20 |  Loss: (0.1332) |  Loss2: (0.0000) | Acc: (95.00%) (2561/2688)
Epoch: 135 | Batch_idx: 30 |  Loss: (0.1341) |  Loss2: (0.0000) | Acc: (95.00%) (3784/3968)
Epoch: 135 | Batch_idx: 40 |  Loss: (0.1369) |  Loss2: (0.0000) | Acc: (95.00%) (5003/5248)
Epoch: 135 | Batch_idx: 50 |  Loss: (0.1371) |  Loss2: (0.0000) | Acc: (95.00%) (6223/6528)
Epoch: 135 | Batch_idx: 60 |  Loss: (0.1342) |  Loss2: (0.0000) | Acc: (95.00%) (7447/7808)
Epoch: 135 | Batch_idx: 70 |  Loss: (0.1380) |  Loss2: (0.0000) | Acc: (95.00%) (8654/9088)
Epoch: 135 | Batch_idx: 80 |  Loss: (0.1374) |  Loss2: (0.0000) | Acc: (95.00%) (9878/10368)
Epoch: 135 | Batch_idx: 90 |  Loss: (0.1383) |  Loss2: (0.0000) | Acc: (95.00%) (11099/11648)
Epoch: 135 | Batch_idx: 100 |  Loss: (0.1369) |  Loss2: (0.0000) | Acc: (95.00%) (12327/12928)
Epoch: 135 | Batch_idx: 110 |  Loss: (0.1367) |  Loss2: (0.0000) | Acc: (95.00%) (13546/14208)
Epoch: 135 | Batch_idx: 120 |  Loss: (0.1378) |  Loss2: (0.0000) | Acc: (95.00%) (14763/15488)
Epoch: 135 | Batch_idx: 130 |  Loss: (0.1385) |  Loss2: (0.0000) | Acc: (95.00%) (15982/16768)
Epoch: 135 | Batch_idx: 140 |  Loss: (0.1396) |  Loss2: (0.0000) | Acc: (95.00%) (17181/18048)
Epoch: 135 | Batch_idx: 150 |  Loss: (0.1387) |  Loss2: (0.0000) | Acc: (95.00%) (18405/19328)
Epoch: 135 | Batch_idx: 160 |  Loss: (0.1387) |  Loss2: (0.0000) | Acc: (95.00%) (19625/20608)
Epoch: 135 | Batch_idx: 170 |  Loss: (0.1396) |  Loss2: (0.0000) | Acc: (95.00%) (20833/21888)
Epoch: 135 | Batch_idx: 180 |  Loss: (0.1390) |  Loss2: (0.0000) | Acc: (95.00%) (22060/23168)
Epoch: 135 | Batch_idx: 190 |  Loss: (0.1387) |  Loss2: (0.0000) | Acc: (95.00%) (23286/24448)
Epoch: 135 | Batch_idx: 200 |  Loss: (0.1390) |  Loss2: (0.0000) | Acc: (95.00%) (24503/25728)
Epoch: 135 | Batch_idx: 210 |  Loss: (0.1390) |  Loss2: (0.0000) | Acc: (95.00%) (25716/27008)
Epoch: 135 | Batch_idx: 220 |  Loss: (0.1394) |  Loss2: (0.0000) | Acc: (95.00%) (26933/28288)
Epoch: 135 | Batch_idx: 230 |  Loss: (0.1396) |  Loss2: (0.0000) | Acc: (95.00%) (28150/29568)
Epoch: 135 | Batch_idx: 240 |  Loss: (0.1397) |  Loss2: (0.0000) | Acc: (95.00%) (29372/30848)
Epoch: 135 | Batch_idx: 250 |  Loss: (0.1406) |  Loss2: (0.0000) | Acc: (95.00%) (30581/32128)
Epoch: 135 | Batch_idx: 260 |  Loss: (0.1412) |  Loss2: (0.0000) | Acc: (95.00%) (31790/33408)
Epoch: 135 | Batch_idx: 270 |  Loss: (0.1418) |  Loss2: (0.0000) | Acc: (95.00%) (33002/34688)
Epoch: 135 | Batch_idx: 280 |  Loss: (0.1423) |  Loss2: (0.0000) | Acc: (95.00%) (34208/35968)
Epoch: 135 | Batch_idx: 290 |  Loss: (0.1417) |  Loss2: (0.0000) | Acc: (95.00%) (35425/37248)
Epoch: 135 | Batch_idx: 300 |  Loss: (0.1415) |  Loss2: (0.0000) | Acc: (95.00%) (36643/38528)
Epoch: 135 | Batch_idx: 310 |  Loss: (0.1414) |  Loss2: (0.0000) | Acc: (95.00%) (37862/39808)
Epoch: 135 | Batch_idx: 320 |  Loss: (0.1417) |  Loss2: (0.0000) | Acc: (95.00%) (39087/41088)
Epoch: 135 | Batch_idx: 330 |  Loss: (0.1416) |  Loss2: (0.0000) | Acc: (95.00%) (40308/42368)
Epoch: 135 | Batch_idx: 340 |  Loss: (0.1414) |  Loss2: (0.0000) | Acc: (95.00%) (41532/43648)
Epoch: 135 | Batch_idx: 350 |  Loss: (0.1413) |  Loss2: (0.0000) | Acc: (95.00%) (42760/44928)
Epoch: 135 | Batch_idx: 360 |  Loss: (0.1424) |  Loss2: (0.0000) | Acc: (95.00%) (43959/46208)
Epoch: 135 | Batch_idx: 370 |  Loss: (0.1428) |  Loss2: (0.0000) | Acc: (95.00%) (45166/47488)
Epoch: 135 | Batch_idx: 380 |  Loss: (0.1429) |  Loss2: (0.0000) | Acc: (95.00%) (46380/48768)
Epoch: 135 | Batch_idx: 390 |  Loss: (0.1431) |  Loss2: (0.0000) | Acc: (95.00%) (47554/50000)
=> saving checkpoint 'drive/app/torch/save_Schedule/checkpoint_135.pth.tar'
# TEST : Loss: (0.4286) | Acc: (87.00%) (8778/10000)
percent tensor([0.4970, 0.4977, 0.5033, 0.4940, 0.5029, 0.4978, 0.4993, 0.4968, 0.4977,
        0.4991, 0.4996, 0.5014, 0.4964, 0.4944, 0.4975, 0.4959],
       device='cuda:0') torch.Size([16])
percent tensor([0.5055, 0.4877, 0.5060, 0.5073, 0.4975, 0.5130, 0.4901, 0.4931, 0.5053,
        0.4953, 0.5071, 0.4997, 0.4903, 0.5027, 0.4961, 0.5058],
       device='cuda:0') torch.Size([16])
percent tensor([0.6461, 0.6437, 0.5691, 0.5563, 0.5831, 0.6272, 0.6380, 0.5888, 0.6013,
        0.6035, 0.6257, 0.5669, 0.6678, 0.5767, 0.6600, 0.6289],
       device='cuda:0') torch.Size([16])
percent tensor([0.6261, 0.6454, 0.6128, 0.6562, 0.6178, 0.7341, 0.6276, 0.5954, 0.6532,
        0.6251, 0.6453, 0.6559, 0.6353, 0.6642, 0.6786, 0.6628],
       device='cuda:0') torch.Size([16])
percent tensor([0.5609, 0.5496, 0.5711, 0.5545, 0.6111, 0.5603, 0.5782, 0.5328, 0.6121,
        0.5855, 0.6152, 0.5295, 0.5596, 0.6787, 0.4641, 0.6019],
       device='cuda:0') torch.Size([16])
percent tensor([0.5898, 0.5789, 0.6729, 0.6929, 0.7113, 0.6899, 0.6266, 0.6536, 0.6331,
        0.6027, 0.6134, 0.6457, 0.5951, 0.6226, 0.6097, 0.6129],
       device='cuda:0') torch.Size([16])
percent tensor([0.5764, 0.7360, 0.7068, 0.6634, 0.7061, 0.5571, 0.5941, 0.5703, 0.7321,
        0.7088, 0.7645, 0.6879, 0.6971, 0.6688, 0.5380, 0.4633],
       device='cuda:0') torch.Size([16])
percent tensor([0.9996, 0.9997, 0.9998, 0.9998, 0.9997, 0.9992, 0.9997, 0.9995, 0.9998,
        0.9999, 1.0000, 0.9999, 0.9998, 0.9994, 0.9986, 0.9992],
       device='cuda:0') torch.Size([16])
False Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=128, out_features=16, bias=False)
True Linear(in_features=16, out_features=2, bias=False)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=128, out_features=16, bias=False)
True Linear(in_features=16, out_features=2, bias=False)
False Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=256, out_features=32, bias=False)
True Linear(in_features=32, out_features=2, bias=False)
False Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=256, out_features=32, bias=False)
True Linear(in_features=32, out_features=2, bias=False)
False Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=512, out_features=64, bias=False)
True Linear(in_features=64, out_features=2, bias=False)
False Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=512, out_features=64, bias=False)
True Linear(in_features=64, out_features=2, bias=False)
False Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1024, out_features=128, bias=False)
True Linear(in_features=128, out_features=2, bias=False)
False Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1024, out_features=128, bias=False)
True Linear(in_features=128, out_features=2, bias=False)
False Linear(in_features=512, out_features=10, bias=True)
Epoch: 136 | Batch_idx: 0 |  Loss: (0.1656) |  Loss2: (0.0000) | Acc: (93.00%) (120/128)
Epoch: 136 | Batch_idx: 10 |  Loss: (0.1703) |  Loss2: (0.0000) | Acc: (94.00%) (1329/1408)
Epoch: 136 | Batch_idx: 20 |  Loss: (0.1854) |  Loss2: (0.0000) | Acc: (93.00%) (2510/2688)
Epoch: 136 | Batch_idx: 30 |  Loss: (0.1961) |  Loss2: (0.0000) | Acc: (93.00%) (3692/3968)
Epoch: 136 | Batch_idx: 40 |  Loss: (0.2012) |  Loss2: (0.0000) | Acc: (92.00%) (4875/5248)
Epoch: 136 | Batch_idx: 50 |  Loss: (0.2010) |  Loss2: (0.0000) | Acc: (92.00%) (6061/6528)
Epoch: 136 | Batch_idx: 60 |  Loss: (0.1974) |  Loss2: (0.0000) | Acc: (92.00%) (7260/7808)
Epoch: 136 | Batch_idx: 70 |  Loss: (0.2034) |  Loss2: (0.0000) | Acc: (92.00%) (8435/9088)
Epoch: 136 | Batch_idx: 80 |  Loss: (0.2021) |  Loss2: (0.0000) | Acc: (92.00%) (9619/10368)
Epoch: 136 | Batch_idx: 90 |  Loss: (0.1994) |  Loss2: (0.0000) | Acc: (92.00%) (10819/11648)
Epoch: 136 | Batch_idx: 100 |  Loss: (0.2003) |  Loss2: (0.0000) | Acc: (92.00%) (12003/12928)
Epoch: 136 | Batch_idx: 110 |  Loss: (0.1984) |  Loss2: (0.0000) | Acc: (92.00%) (13195/14208)
Epoch: 136 | Batch_idx: 120 |  Loss: (0.1951) |  Loss2: (0.0000) | Acc: (93.00%) (14405/15488)
Epoch: 136 | Batch_idx: 130 |  Loss: (0.1944) |  Loss2: (0.0000) | Acc: (93.00%) (15596/16768)
Epoch: 136 | Batch_idx: 140 |  Loss: (0.1940) |  Loss2: (0.0000) | Acc: (92.00%) (16779/18048)
Epoch: 136 | Batch_idx: 150 |  Loss: (0.1950) |  Loss2: (0.0000) | Acc: (92.00%) (17952/19328)
Epoch: 136 | Batch_idx: 160 |  Loss: (0.1944) |  Loss2: (0.0000) | Acc: (92.00%) (19143/20608)
Epoch: 136 | Batch_idx: 170 |  Loss: (0.1939) |  Loss2: (0.0000) | Acc: (92.00%) (20339/21888)
Epoch: 136 | Batch_idx: 180 |  Loss: (0.1935) |  Loss2: (0.0000) | Acc: (92.00%) (21536/23168)
Epoch: 136 | Batch_idx: 190 |  Loss: (0.1930) |  Loss2: (0.0000) | Acc: (92.00%) (22731/24448)
Epoch: 136 | Batch_idx: 200 |  Loss: (0.1925) |  Loss2: (0.0000) | Acc: (93.00%) (23932/25728)
Epoch: 136 | Batch_idx: 210 |  Loss: (0.1916) |  Loss2: (0.0000) | Acc: (93.00%) (25129/27008)
Epoch: 136 | Batch_idx: 220 |  Loss: (0.1914) |  Loss2: (0.0000) | Acc: (93.00%) (26324/28288)
Epoch: 136 | Batch_idx: 230 |  Loss: (0.1898) |  Loss2: (0.0000) | Acc: (93.00%) (27530/29568)
Epoch: 136 | Batch_idx: 240 |  Loss: (0.1884) |  Loss2: (0.0000) | Acc: (93.00%) (28738/30848)
Epoch: 136 | Batch_idx: 250 |  Loss: (0.1881) |  Loss2: (0.0000) | Acc: (93.00%) (29933/32128)
Epoch: 136 | Batch_idx: 260 |  Loss: (0.1863) |  Loss2: (0.0000) | Acc: (93.00%) (31145/33408)
Epoch: 136 | Batch_idx: 270 |  Loss: (0.1856) |  Loss2: (0.0000) | Acc: (93.00%) (32355/34688)
Epoch: 136 | Batch_idx: 280 |  Loss: (0.1858) |  Loss2: (0.0000) | Acc: (93.00%) (33547/35968)
Epoch: 136 | Batch_idx: 290 |  Loss: (0.1855) |  Loss2: (0.0000) | Acc: (93.00%) (34749/37248)
Epoch: 136 | Batch_idx: 300 |  Loss: (0.1855) |  Loss2: (0.0000) | Acc: (93.00%) (35946/38528)
Epoch: 136 | Batch_idx: 310 |  Loss: (0.1856) |  Loss2: (0.0000) | Acc: (93.00%) (37132/39808)
Epoch: 136 | Batch_idx: 320 |  Loss: (0.1857) |  Loss2: (0.0000) | Acc: (93.00%) (38324/41088)
Epoch: 136 | Batch_idx: 330 |  Loss: (0.1852) |  Loss2: (0.0000) | Acc: (93.00%) (39526/42368)
Epoch: 136 | Batch_idx: 340 |  Loss: (0.1846) |  Loss2: (0.0000) | Acc: (93.00%) (40731/43648)
Epoch: 136 | Batch_idx: 350 |  Loss: (0.1845) |  Loss2: (0.0000) | Acc: (93.00%) (41933/44928)
Epoch: 136 | Batch_idx: 360 |  Loss: (0.1837) |  Loss2: (0.0000) | Acc: (93.00%) (43145/46208)
Epoch: 136 | Batch_idx: 370 |  Loss: (0.1823) |  Loss2: (0.0000) | Acc: (93.00%) (44373/47488)
Epoch: 136 | Batch_idx: 380 |  Loss: (0.1822) |  Loss2: (0.0000) | Acc: (93.00%) (45575/48768)
Epoch: 136 | Batch_idx: 390 |  Loss: (0.1819) |  Loss2: (0.0000) | Acc: (93.00%) (46735/50000)
# TEST : Loss: (0.4264) | Acc: (87.00%) (8744/10000)
percent tensor([0.5021, 0.5038, 0.5097, 0.4998, 0.5094, 0.5025, 0.5054, 0.5033, 0.5032,
        0.5050, 0.5051, 0.5077, 0.5019, 0.5002, 0.5033, 0.5010],
       device='cuda:0') torch.Size([16])
percent tensor([0.4975, 0.4813, 0.4976, 0.4988, 0.4878, 0.5058, 0.4820, 0.4843, 0.4972,
        0.4892, 0.4995, 0.4921, 0.4849, 0.4965, 0.4884, 0.4988],
       device='cuda:0') torch.Size([16])
percent tensor([0.6247, 0.6270, 0.5592, 0.5450, 0.5713, 0.5995, 0.6191, 0.5819, 0.5819,
        0.5855, 0.6033, 0.5523, 0.6396, 0.5610, 0.6377, 0.6081],
       device='cuda:0') torch.Size([16])
percent tensor([0.5883, 0.6183, 0.5810, 0.6353, 0.5789, 0.6993, 0.5949, 0.5597, 0.6322,
        0.5972, 0.6247, 0.6246, 0.5996, 0.6481, 0.6440, 0.6284],
       device='cuda:0') torch.Size([16])
percent tensor([0.5737, 0.5748, 0.5871, 0.5680, 0.6202, 0.5557, 0.5976, 0.5471, 0.6155,
        0.6125, 0.6277, 0.5495, 0.5727, 0.6954, 0.4744, 0.6123],
       device='cuda:0') torch.Size([16])
percent tensor([0.5836, 0.5583, 0.6701, 0.6883, 0.7027, 0.6849, 0.6126, 0.6472, 0.6129,
        0.5836, 0.5941, 0.6341, 0.5739, 0.5953, 0.5931, 0.6057],
       device='cuda:0') torch.Size([16])
percent tensor([0.6012, 0.7228, 0.7263, 0.6737, 0.7217, 0.5663, 0.6056, 0.5967, 0.7208,
        0.6916, 0.7559, 0.6990, 0.6882, 0.6582, 0.5620, 0.4788],
       device='cuda:0') torch.Size([16])
percent tensor([0.9996, 0.9997, 0.9997, 0.9998, 0.9996, 0.9988, 0.9996, 0.9993, 0.9997,
        0.9998, 1.0000, 0.9998, 0.9997, 0.9994, 0.9989, 0.9993],
       device='cuda:0') torch.Size([16])
Epoch: 137 | Batch_idx: 0 |  Loss: (0.1955) |  Loss2: (0.0000) | Acc: (93.00%) (120/128)
Epoch: 137 | Batch_idx: 10 |  Loss: (0.1558) |  Loss2: (0.0000) | Acc: (94.00%) (1335/1408)
Epoch: 137 | Batch_idx: 20 |  Loss: (0.1692) |  Loss2: (0.0000) | Acc: (94.00%) (2536/2688)
Epoch: 137 | Batch_idx: 30 |  Loss: (0.1795) |  Loss2: (0.0000) | Acc: (93.00%) (3725/3968)
Epoch: 137 | Batch_idx: 40 |  Loss: (0.1796) |  Loss2: (0.0000) | Acc: (93.00%) (4932/5248)
Epoch: 137 | Batch_idx: 50 |  Loss: (0.1699) |  Loss2: (0.0000) | Acc: (94.00%) (6165/6528)
Epoch: 137 | Batch_idx: 60 |  Loss: (0.1707) |  Loss2: (0.0000) | Acc: (94.00%) (7368/7808)
Epoch: 137 | Batch_idx: 70 |  Loss: (0.1702) |  Loss2: (0.0000) | Acc: (94.00%) (8567/9088)
Epoch: 137 | Batch_idx: 80 |  Loss: (0.1666) |  Loss2: (0.0000) | Acc: (94.00%) (9790/10368)
Epoch: 137 | Batch_idx: 90 |  Loss: (0.1664) |  Loss2: (0.0000) | Acc: (94.00%) (10994/11648)
Epoch: 137 | Batch_idx: 100 |  Loss: (0.1669) |  Loss2: (0.0000) | Acc: (94.00%) (12199/12928)
Epoch: 137 | Batch_idx: 110 |  Loss: (0.1681) |  Loss2: (0.0000) | Acc: (94.00%) (13401/14208)
Epoch: 137 | Batch_idx: 120 |  Loss: (0.1679) |  Loss2: (0.0000) | Acc: (94.00%) (14598/15488)
Epoch: 137 | Batch_idx: 130 |  Loss: (0.1682) |  Loss2: (0.0000) | Acc: (94.00%) (15793/16768)
Epoch: 137 | Batch_idx: 140 |  Loss: (0.1673) |  Loss2: (0.0000) | Acc: (94.00%) (17006/18048)
Epoch: 137 | Batch_idx: 150 |  Loss: (0.1662) |  Loss2: (0.0000) | Acc: (94.00%) (18224/19328)
Epoch: 137 | Batch_idx: 160 |  Loss: (0.1657) |  Loss2: (0.0000) | Acc: (94.00%) (19439/20608)
Epoch: 137 | Batch_idx: 170 |  Loss: (0.1661) |  Loss2: (0.0000) | Acc: (94.00%) (20639/21888)
Epoch: 137 | Batch_idx: 180 |  Loss: (0.1667) |  Loss2: (0.0000) | Acc: (94.00%) (21846/23168)
Epoch: 137 | Batch_idx: 190 |  Loss: (0.1672) |  Loss2: (0.0000) | Acc: (94.00%) (23050/24448)
Epoch: 137 | Batch_idx: 200 |  Loss: (0.1664) |  Loss2: (0.0000) | Acc: (94.00%) (24262/25728)
Epoch: 137 | Batch_idx: 210 |  Loss: (0.1657) |  Loss2: (0.0000) | Acc: (94.00%) (25475/27008)
Epoch: 137 | Batch_idx: 220 |  Loss: (0.1645) |  Loss2: (0.0000) | Acc: (94.00%) (26688/28288)
Epoch: 137 | Batch_idx: 230 |  Loss: (0.1660) |  Loss2: (0.0000) | Acc: (94.00%) (27883/29568)
Epoch: 137 | Batch_idx: 240 |  Loss: (0.1658) |  Loss2: (0.0000) | Acc: (94.00%) (29090/30848)
Epoch: 137 | Batch_idx: 250 |  Loss: (0.1654) |  Loss2: (0.0000) | Acc: (94.00%) (30300/32128)
Epoch: 137 | Batch_idx: 260 |  Loss: (0.1635) |  Loss2: (0.0000) | Acc: (94.00%) (31531/33408)
Epoch: 137 | Batch_idx: 270 |  Loss: (0.1634) |  Loss2: (0.0000) | Acc: (94.00%) (32733/34688)
Epoch: 137 | Batch_idx: 280 |  Loss: (0.1637) |  Loss2: (0.0000) | Acc: (94.00%) (33938/35968)
Epoch: 137 | Batch_idx: 290 |  Loss: (0.1635) |  Loss2: (0.0000) | Acc: (94.00%) (35142/37248)
Epoch: 137 | Batch_idx: 300 |  Loss: (0.1636) |  Loss2: (0.0000) | Acc: (94.00%) (36344/38528)
Epoch: 137 | Batch_idx: 310 |  Loss: (0.1627) |  Loss2: (0.0000) | Acc: (94.00%) (37563/39808)
Epoch: 137 | Batch_idx: 320 |  Loss: (0.1634) |  Loss2: (0.0000) | Acc: (94.00%) (38759/41088)
Epoch: 137 | Batch_idx: 330 |  Loss: (0.1636) |  Loss2: (0.0000) | Acc: (94.00%) (39955/42368)
Epoch: 137 | Batch_idx: 340 |  Loss: (0.1635) |  Loss2: (0.0000) | Acc: (94.00%) (41163/43648)
Epoch: 137 | Batch_idx: 350 |  Loss: (0.1634) |  Loss2: (0.0000) | Acc: (94.00%) (42371/44928)
Epoch: 137 | Batch_idx: 360 |  Loss: (0.1630) |  Loss2: (0.0000) | Acc: (94.00%) (43590/46208)
Epoch: 137 | Batch_idx: 370 |  Loss: (0.1621) |  Loss2: (0.0000) | Acc: (94.00%) (44807/47488)
Epoch: 137 | Batch_idx: 380 |  Loss: (0.1620) |  Loss2: (0.0000) | Acc: (94.00%) (46017/48768)
Epoch: 137 | Batch_idx: 390 |  Loss: (0.1617) |  Loss2: (0.0000) | Acc: (94.00%) (47186/50000)
# TEST : Loss: (0.4139) | Acc: (87.00%) (8761/10000)
percent tensor([0.5030, 0.5052, 0.5109, 0.5011, 0.5105, 0.5030, 0.5067, 0.5048, 0.5043,
        0.5064, 0.5062, 0.5089, 0.5029, 0.5017, 0.5043, 0.5020],
       device='cuda:0') torch.Size([16])
percent tensor([0.4931, 0.4775, 0.4940, 0.4941, 0.4831, 0.5027, 0.4780, 0.4804, 0.4939,
        0.4855, 0.4954, 0.4881, 0.4813, 0.4933, 0.4835, 0.4945],
       device='cuda:0') torch.Size([16])
percent tensor([0.6248, 0.6268, 0.5577, 0.5417, 0.5715, 0.5976, 0.6202, 0.5806, 0.5795,
        0.5873, 0.6038, 0.5510, 0.6402, 0.5568, 0.6379, 0.6085],
       device='cuda:0') torch.Size([16])
percent tensor([0.5853, 0.6154, 0.5827, 0.6406, 0.5790, 0.6969, 0.5931, 0.5568, 0.6360,
        0.5984, 0.6289, 0.6299, 0.5994, 0.6512, 0.6431, 0.6234],
       device='cuda:0') torch.Size([16])
percent tensor([0.5733, 0.5863, 0.5848, 0.5669, 0.6209, 0.5472, 0.6077, 0.5499, 0.6173,
        0.6207, 0.6279, 0.5502, 0.5729, 0.7056, 0.4775, 0.6167],
       device='cuda:0') torch.Size([16])
percent tensor([0.5967, 0.5682, 0.6792, 0.6972, 0.7140, 0.6997, 0.6250, 0.6594, 0.6234,
        0.5922, 0.6016, 0.6413, 0.5856, 0.6031, 0.6058, 0.6228],
       device='cuda:0') torch.Size([16])
percent tensor([0.6104, 0.7157, 0.7286, 0.6783, 0.7286, 0.5758, 0.6064, 0.6070, 0.7148,
        0.6844, 0.7460, 0.6933, 0.6844, 0.6431, 0.5721, 0.4881],
       device='cuda:0') torch.Size([16])
percent tensor([0.9997, 0.9997, 0.9997, 0.9998, 0.9996, 0.9989, 0.9996, 0.9993, 0.9997,
        0.9998, 1.0000, 0.9998, 0.9998, 0.9995, 0.9989, 0.9993],
       device='cuda:0') torch.Size([16])
Epoch: 138 | Batch_idx: 0 |  Loss: (0.1593) |  Loss2: (0.0000) | Acc: (95.00%) (122/128)
Epoch: 138 | Batch_idx: 10 |  Loss: (0.1564) |  Loss2: (0.0000) | Acc: (94.00%) (1336/1408)
Epoch: 138 | Batch_idx: 20 |  Loss: (0.1390) |  Loss2: (0.0000) | Acc: (95.00%) (2560/2688)
Epoch: 138 | Batch_idx: 30 |  Loss: (0.1494) |  Loss2: (0.0000) | Acc: (94.00%) (3761/3968)
Epoch: 138 | Batch_idx: 40 |  Loss: (0.1559) |  Loss2: (0.0000) | Acc: (94.00%) (4962/5248)
Epoch: 138 | Batch_idx: 50 |  Loss: (0.1559) |  Loss2: (0.0000) | Acc: (94.00%) (6168/6528)
Epoch: 138 | Batch_idx: 60 |  Loss: (0.1557) |  Loss2: (0.0000) | Acc: (94.00%) (7379/7808)
Epoch: 138 | Batch_idx: 70 |  Loss: (0.1584) |  Loss2: (0.0000) | Acc: (94.00%) (8577/9088)
Epoch: 138 | Batch_idx: 80 |  Loss: (0.1565) |  Loss2: (0.0000) | Acc: (94.00%) (9791/10368)
Epoch: 138 | Batch_idx: 90 |  Loss: (0.1546) |  Loss2: (0.0000) | Acc: (94.00%) (11020/11648)
Epoch: 138 | Batch_idx: 100 |  Loss: (0.1535) |  Loss2: (0.0000) | Acc: (94.00%) (12239/12928)
Epoch: 138 | Batch_idx: 110 |  Loss: (0.1548) |  Loss2: (0.0000) | Acc: (94.00%) (13446/14208)
Epoch: 138 | Batch_idx: 120 |  Loss: (0.1554) |  Loss2: (0.0000) | Acc: (94.00%) (14656/15488)
Epoch: 138 | Batch_idx: 130 |  Loss: (0.1569) |  Loss2: (0.0000) | Acc: (94.00%) (15857/16768)
Epoch: 138 | Batch_idx: 140 |  Loss: (0.1558) |  Loss2: (0.0000) | Acc: (94.00%) (17067/18048)
Epoch: 138 | Batch_idx: 150 |  Loss: (0.1551) |  Loss2: (0.0000) | Acc: (94.00%) (18276/19328)
Epoch: 138 | Batch_idx: 160 |  Loss: (0.1541) |  Loss2: (0.0000) | Acc: (94.00%) (19490/20608)
Epoch: 138 | Batch_idx: 170 |  Loss: (0.1531) |  Loss2: (0.0000) | Acc: (94.00%) (20705/21888)
Epoch: 138 | Batch_idx: 180 |  Loss: (0.1522) |  Loss2: (0.0000) | Acc: (94.00%) (21930/23168)
Epoch: 138 | Batch_idx: 190 |  Loss: (0.1502) |  Loss2: (0.0000) | Acc: (94.00%) (23162/24448)
Epoch: 138 | Batch_idx: 200 |  Loss: (0.1504) |  Loss2: (0.0000) | Acc: (94.00%) (24377/25728)
Epoch: 138 | Batch_idx: 210 |  Loss: (0.1514) |  Loss2: (0.0000) | Acc: (94.00%) (25583/27008)
Epoch: 138 | Batch_idx: 220 |  Loss: (0.1512) |  Loss2: (0.0000) | Acc: (94.00%) (26798/28288)
Epoch: 138 | Batch_idx: 230 |  Loss: (0.1511) |  Loss2: (0.0000) | Acc: (94.00%) (28021/29568)
Epoch: 138 | Batch_idx: 240 |  Loss: (0.1509) |  Loss2: (0.0000) | Acc: (94.00%) (29236/30848)
Epoch: 138 | Batch_idx: 250 |  Loss: (0.1508) |  Loss2: (0.0000) | Acc: (94.00%) (30447/32128)
Epoch: 138 | Batch_idx: 260 |  Loss: (0.1507) |  Loss2: (0.0000) | Acc: (94.00%) (31665/33408)
Epoch: 138 | Batch_idx: 270 |  Loss: (0.1503) |  Loss2: (0.0000) | Acc: (94.00%) (32875/34688)
Epoch: 138 | Batch_idx: 280 |  Loss: (0.1511) |  Loss2: (0.0000) | Acc: (94.00%) (34067/35968)
Epoch: 138 | Batch_idx: 290 |  Loss: (0.1508) |  Loss2: (0.0000) | Acc: (94.00%) (35272/37248)
Epoch: 138 | Batch_idx: 300 |  Loss: (0.1506) |  Loss2: (0.0000) | Acc: (94.00%) (36495/38528)
Epoch: 138 | Batch_idx: 310 |  Loss: (0.1503) |  Loss2: (0.0000) | Acc: (94.00%) (37715/39808)
Epoch: 138 | Batch_idx: 320 |  Loss: (0.1499) |  Loss2: (0.0000) | Acc: (94.00%) (38936/41088)
Epoch: 138 | Batch_idx: 330 |  Loss: (0.1500) |  Loss2: (0.0000) | Acc: (94.00%) (40145/42368)
Epoch: 138 | Batch_idx: 340 |  Loss: (0.1496) |  Loss2: (0.0000) | Acc: (94.00%) (41362/43648)
Epoch: 138 | Batch_idx: 350 |  Loss: (0.1500) |  Loss2: (0.0000) | Acc: (94.00%) (42566/44928)
Epoch: 138 | Batch_idx: 360 |  Loss: (0.1497) |  Loss2: (0.0000) | Acc: (94.00%) (43788/46208)
Epoch: 138 | Batch_idx: 370 |  Loss: (0.1500) |  Loss2: (0.0000) | Acc: (94.00%) (44987/47488)
Epoch: 138 | Batch_idx: 380 |  Loss: (0.1502) |  Loss2: (0.0000) | Acc: (94.00%) (46206/48768)
Epoch: 138 | Batch_idx: 390 |  Loss: (0.1501) |  Loss2: (0.0000) | Acc: (94.00%) (47377/50000)
# TEST : Loss: (0.4026) | Acc: (87.00%) (8793/10000)
percent tensor([0.5030, 0.5054, 0.5118, 0.5016, 0.5112, 0.5027, 0.5072, 0.5053, 0.5044,
        0.5070, 0.5062, 0.5098, 0.5030, 0.5019, 0.5044, 0.5020],
       device='cuda:0') torch.Size([16])
percent tensor([0.4931, 0.4780, 0.4948, 0.4946, 0.4834, 0.5023, 0.4785, 0.4812, 0.4944,
        0.4863, 0.4959, 0.4891, 0.4817, 0.4937, 0.4832, 0.4944],
       device='cuda:0') torch.Size([16])
percent tensor([0.6298, 0.6320, 0.5595, 0.5431, 0.5739, 0.6014, 0.6266, 0.5830, 0.5823,
        0.5908, 0.6079, 0.5526, 0.6461, 0.5581, 0.6439, 0.6134],
       device='cuda:0') torch.Size([16])
percent tensor([0.5898, 0.6201, 0.5894, 0.6477, 0.5841, 0.7000, 0.5994, 0.5593, 0.6437,
        0.6070, 0.6369, 0.6398, 0.6063, 0.6591, 0.6483, 0.6264],
       device='cuda:0') torch.Size([16])
percent tensor([0.5677, 0.5788, 0.5829, 0.5673, 0.6156, 0.5457, 0.6025, 0.5444, 0.6117,
        0.6160, 0.6208, 0.5446, 0.5624, 0.7061, 0.4693, 0.6144],
       device='cuda:0') torch.Size([16])
percent tensor([0.5980, 0.5677, 0.6781, 0.6974, 0.7133, 0.7049, 0.6263, 0.6603, 0.6235,
        0.5928, 0.6000, 0.6419, 0.5881, 0.6028, 0.6088, 0.6276],
       device='cuda:0') torch.Size([16])
percent tensor([0.6186, 0.7205, 0.7308, 0.6851, 0.7277, 0.5927, 0.6060, 0.6096, 0.7203,
        0.6837, 0.7513, 0.6950, 0.6936, 0.6435, 0.5790, 0.4926],
       device='cuda:0') torch.Size([16])
percent tensor([0.9996, 0.9997, 0.9997, 0.9998, 0.9996, 0.9990, 0.9996, 0.9993, 0.9997,
        0.9998, 1.0000, 0.9998, 0.9998, 0.9994, 0.9989, 0.9993],
       device='cuda:0') torch.Size([16])
Epoch: 139 | Batch_idx: 0 |  Loss: (0.2077) |  Loss2: (0.0000) | Acc: (94.00%) (121/128)
Epoch: 139 | Batch_idx: 10 |  Loss: (0.1605) |  Loss2: (0.0000) | Acc: (94.00%) (1328/1408)
Epoch: 139 | Batch_idx: 20 |  Loss: (0.1484) |  Loss2: (0.0000) | Acc: (94.00%) (2551/2688)
Epoch: 139 | Batch_idx: 30 |  Loss: (0.1493) |  Loss2: (0.0000) | Acc: (94.00%) (3764/3968)
Epoch: 139 | Batch_idx: 40 |  Loss: (0.1466) |  Loss2: (0.0000) | Acc: (95.00%) (4991/5248)
Epoch: 139 | Batch_idx: 50 |  Loss: (0.1435) |  Loss2: (0.0000) | Acc: (95.00%) (6214/6528)
Epoch: 139 | Batch_idx: 60 |  Loss: (0.1435) |  Loss2: (0.0000) | Acc: (95.00%) (7422/7808)
Epoch: 139 | Batch_idx: 70 |  Loss: (0.1419) |  Loss2: (0.0000) | Acc: (95.00%) (8646/9088)
Epoch: 139 | Batch_idx: 80 |  Loss: (0.1414) |  Loss2: (0.0000) | Acc: (95.00%) (9859/10368)
Epoch: 139 | Batch_idx: 90 |  Loss: (0.1430) |  Loss2: (0.0000) | Acc: (95.00%) (11069/11648)
Epoch: 139 | Batch_idx: 100 |  Loss: (0.1423) |  Loss2: (0.0000) | Acc: (95.00%) (12283/12928)
Epoch: 139 | Batch_idx: 110 |  Loss: (0.1423) |  Loss2: (0.0000) | Acc: (95.00%) (13505/14208)
Epoch: 139 | Batch_idx: 120 |  Loss: (0.1439) |  Loss2: (0.0000) | Acc: (95.00%) (14720/15488)
Epoch: 139 | Batch_idx: 130 |  Loss: (0.1426) |  Loss2: (0.0000) | Acc: (95.00%) (15951/16768)
Epoch: 139 | Batch_idx: 140 |  Loss: (0.1409) |  Loss2: (0.0000) | Acc: (95.00%) (17180/18048)
Epoch: 139 | Batch_idx: 150 |  Loss: (0.1395) |  Loss2: (0.0000) | Acc: (95.00%) (18408/19328)
Epoch: 139 | Batch_idx: 160 |  Loss: (0.1390) |  Loss2: (0.0000) | Acc: (95.00%) (19623/20608)
Epoch: 139 | Batch_idx: 170 |  Loss: (0.1408) |  Loss2: (0.0000) | Acc: (95.00%) (20821/21888)
Epoch: 139 | Batch_idx: 180 |  Loss: (0.1411) |  Loss2: (0.0000) | Acc: (95.00%) (22039/23168)
Epoch: 139 | Batch_idx: 190 |  Loss: (0.1412) |  Loss2: (0.0000) | Acc: (95.00%) (23260/24448)
Epoch: 139 | Batch_idx: 200 |  Loss: (0.1409) |  Loss2: (0.0000) | Acc: (95.00%) (24484/25728)
Epoch: 139 | Batch_idx: 210 |  Loss: (0.1410) |  Loss2: (0.0000) | Acc: (95.00%) (25698/27008)
Epoch: 139 | Batch_idx: 220 |  Loss: (0.1414) |  Loss2: (0.0000) | Acc: (95.00%) (26912/28288)
Epoch: 139 | Batch_idx: 230 |  Loss: (0.1415) |  Loss2: (0.0000) | Acc: (95.00%) (28126/29568)
Epoch: 139 | Batch_idx: 240 |  Loss: (0.1410) |  Loss2: (0.0000) | Acc: (95.00%) (29354/30848)
Epoch: 139 | Batch_idx: 250 |  Loss: (0.1403) |  Loss2: (0.0000) | Acc: (95.00%) (30580/32128)
Epoch: 139 | Batch_idx: 260 |  Loss: (0.1407) |  Loss2: (0.0000) | Acc: (95.00%) (31791/33408)
Epoch: 139 | Batch_idx: 270 |  Loss: (0.1406) |  Loss2: (0.0000) | Acc: (95.00%) (33008/34688)
Epoch: 139 | Batch_idx: 280 |  Loss: (0.1410) |  Loss2: (0.0000) | Acc: (95.00%) (34223/35968)
Epoch: 139 | Batch_idx: 290 |  Loss: (0.1419) |  Loss2: (0.0000) | Acc: (95.00%) (35426/37248)
Epoch: 139 | Batch_idx: 300 |  Loss: (0.1424) |  Loss2: (0.0000) | Acc: (95.00%) (36640/38528)
Epoch: 139 | Batch_idx: 310 |  Loss: (0.1425) |  Loss2: (0.0000) | Acc: (95.00%) (37860/39808)
Epoch: 139 | Batch_idx: 320 |  Loss: (0.1421) |  Loss2: (0.0000) | Acc: (95.00%) (39082/41088)
Epoch: 139 | Batch_idx: 330 |  Loss: (0.1420) |  Loss2: (0.0000) | Acc: (95.00%) (40303/42368)
Epoch: 139 | Batch_idx: 340 |  Loss: (0.1425) |  Loss2: (0.0000) | Acc: (95.00%) (41508/43648)
Epoch: 139 | Batch_idx: 350 |  Loss: (0.1418) |  Loss2: (0.0000) | Acc: (95.00%) (42732/44928)
Epoch: 139 | Batch_idx: 360 |  Loss: (0.1419) |  Loss2: (0.0000) | Acc: (95.00%) (43946/46208)
Epoch: 139 | Batch_idx: 370 |  Loss: (0.1418) |  Loss2: (0.0000) | Acc: (95.00%) (45170/47488)
Epoch: 139 | Batch_idx: 380 |  Loss: (0.1421) |  Loss2: (0.0000) | Acc: (95.00%) (46378/48768)
Epoch: 139 | Batch_idx: 390 |  Loss: (0.1416) |  Loss2: (0.0000) | Acc: (95.00%) (47555/50000)
# TEST : Loss: (0.3969) | Acc: (88.00%) (8819/10000)
percent tensor([0.5037, 0.5064, 0.5125, 0.5024, 0.5119, 0.5033, 0.5080, 0.5062, 0.5054,
        0.5078, 0.5072, 0.5105, 0.5039, 0.5029, 0.5051, 0.5028],
       device='cuda:0') torch.Size([16])
percent tensor([0.4928, 0.4782, 0.4948, 0.4942, 0.4832, 0.5018, 0.4789, 0.4817, 0.4946,
        0.4864, 0.4959, 0.4893, 0.4818, 0.4940, 0.4829, 0.4941],
       device='cuda:0') torch.Size([16])
percent tensor([0.6318, 0.6355, 0.5599, 0.5419, 0.5747, 0.6000, 0.6313, 0.5830, 0.5842,
        0.5937, 0.6112, 0.5538, 0.6494, 0.5596, 0.6458, 0.6158],
       device='cuda:0') torch.Size([16])
percent tensor([0.5915, 0.6242, 0.5907, 0.6530, 0.5859, 0.7033, 0.6023, 0.5602, 0.6493,
        0.6102, 0.6424, 0.6452, 0.6107, 0.6646, 0.6522, 0.6285],
       device='cuda:0') torch.Size([16])
percent tensor([0.5715, 0.5904, 0.5876, 0.5690, 0.6208, 0.5397, 0.6147, 0.5499, 0.6177,
        0.6257, 0.6252, 0.5494, 0.5707, 0.7142, 0.4754, 0.6197],
       device='cuda:0') torch.Size([16])
percent tensor([0.5975, 0.5654, 0.6752, 0.6945, 0.7116, 0.7074, 0.6253, 0.6587, 0.6218,
        0.5878, 0.5959, 0.6376, 0.5884, 0.5982, 0.6073, 0.6295],
       device='cuda:0') torch.Size([16])
percent tensor([0.6293, 0.7224, 0.7356, 0.6884, 0.7335, 0.6008, 0.6063, 0.6194, 0.7230,
        0.6854, 0.7523, 0.6951, 0.6988, 0.6416, 0.5850, 0.5004],
       device='cuda:0') torch.Size([16])
percent tensor([0.9997, 0.9997, 0.9997, 0.9998, 0.9996, 0.9990, 0.9996, 0.9993, 0.9997,
        0.9998, 1.0000, 0.9998, 0.9998, 0.9994, 0.9989, 0.9993],
       device='cuda:0') torch.Size([16])
Epoch: 140 | Batch_idx: 0 |  Loss: (0.1171) |  Loss2: (0.0000) | Acc: (95.00%) (122/128)
Epoch: 140 | Batch_idx: 10 |  Loss: (0.1538) |  Loss2: (0.0000) | Acc: (94.00%) (1333/1408)
Epoch: 140 | Batch_idx: 20 |  Loss: (0.1360) |  Loss2: (0.0000) | Acc: (95.00%) (2567/2688)
Epoch: 140 | Batch_idx: 30 |  Loss: (0.1361) |  Loss2: (0.0000) | Acc: (95.00%) (3786/3968)
Epoch: 140 | Batch_idx: 40 |  Loss: (0.1398) |  Loss2: (0.0000) | Acc: (95.00%) (5004/5248)
Epoch: 140 | Batch_idx: 50 |  Loss: (0.1368) |  Loss2: (0.0000) | Acc: (95.00%) (6225/6528)
Epoch: 140 | Batch_idx: 60 |  Loss: (0.1389) |  Loss2: (0.0000) | Acc: (95.00%) (7443/7808)
Epoch: 140 | Batch_idx: 70 |  Loss: (0.1393) |  Loss2: (0.0000) | Acc: (95.00%) (8660/9088)
Epoch: 140 | Batch_idx: 80 |  Loss: (0.1371) |  Loss2: (0.0000) | Acc: (95.00%) (9889/10368)
Epoch: 140 | Batch_idx: 90 |  Loss: (0.1387) |  Loss2: (0.0000) | Acc: (95.00%) (11099/11648)
Epoch: 140 | Batch_idx: 100 |  Loss: (0.1401) |  Loss2: (0.0000) | Acc: (95.00%) (12320/12928)
Epoch: 140 | Batch_idx: 110 |  Loss: (0.1402) |  Loss2: (0.0000) | Acc: (95.00%) (13537/14208)
Epoch: 140 | Batch_idx: 120 |  Loss: (0.1423) |  Loss2: (0.0000) | Acc: (95.00%) (14749/15488)
Epoch: 140 | Batch_idx: 130 |  Loss: (0.1419) |  Loss2: (0.0000) | Acc: (95.00%) (15967/16768)
Epoch: 140 | Batch_idx: 140 |  Loss: (0.1421) |  Loss2: (0.0000) | Acc: (95.00%) (17180/18048)
Epoch: 140 | Batch_idx: 150 |  Loss: (0.1419) |  Loss2: (0.0000) | Acc: (95.00%) (18404/19328)
Epoch: 140 | Batch_idx: 160 |  Loss: (0.1411) |  Loss2: (0.0000) | Acc: (95.00%) (19630/20608)
Epoch: 140 | Batch_idx: 170 |  Loss: (0.1403) |  Loss2: (0.0000) | Acc: (95.00%) (20852/21888)
Epoch: 140 | Batch_idx: 180 |  Loss: (0.1397) |  Loss2: (0.0000) | Acc: (95.00%) (22074/23168)
Epoch: 140 | Batch_idx: 190 |  Loss: (0.1398) |  Loss2: (0.0000) | Acc: (95.00%) (23288/24448)
Epoch: 140 | Batch_idx: 200 |  Loss: (0.1389) |  Loss2: (0.0000) | Acc: (95.00%) (24519/25728)
Epoch: 140 | Batch_idx: 210 |  Loss: (0.1390) |  Loss2: (0.0000) | Acc: (95.00%) (25734/27008)
Epoch: 140 | Batch_idx: 220 |  Loss: (0.1379) |  Loss2: (0.0000) | Acc: (95.00%) (26974/28288)
Epoch: 140 | Batch_idx: 230 |  Loss: (0.1396) |  Loss2: (0.0000) | Acc: (95.00%) (28172/29568)
Epoch: 140 | Batch_idx: 240 |  Loss: (0.1404) |  Loss2: (0.0000) | Acc: (95.00%) (29381/30848)
Epoch: 140 | Batch_idx: 250 |  Loss: (0.1401) |  Loss2: (0.0000) | Acc: (95.00%) (30604/32128)
Epoch: 140 | Batch_idx: 260 |  Loss: (0.1399) |  Loss2: (0.0000) | Acc: (95.00%) (31826/33408)
Epoch: 140 | Batch_idx: 270 |  Loss: (0.1399) |  Loss2: (0.0000) | Acc: (95.00%) (33037/34688)
Epoch: 140 | Batch_idx: 280 |  Loss: (0.1402) |  Loss2: (0.0000) | Acc: (95.00%) (34264/35968)
Epoch: 140 | Batch_idx: 290 |  Loss: (0.1400) |  Loss2: (0.0000) | Acc: (95.00%) (35480/37248)
Epoch: 140 | Batch_idx: 300 |  Loss: (0.1401) |  Loss2: (0.0000) | Acc: (95.00%) (36706/38528)
Epoch: 140 | Batch_idx: 310 |  Loss: (0.1401) |  Loss2: (0.0000) | Acc: (95.00%) (37925/39808)
Epoch: 140 | Batch_idx: 320 |  Loss: (0.1402) |  Loss2: (0.0000) | Acc: (95.00%) (39139/41088)
Epoch: 140 | Batch_idx: 330 |  Loss: (0.1399) |  Loss2: (0.0000) | Acc: (95.00%) (40359/42368)
Epoch: 140 | Batch_idx: 340 |  Loss: (0.1399) |  Loss2: (0.0000) | Acc: (95.00%) (41577/43648)
Epoch: 140 | Batch_idx: 350 |  Loss: (0.1397) |  Loss2: (0.0000) | Acc: (95.00%) (42802/44928)
Epoch: 140 | Batch_idx: 360 |  Loss: (0.1396) |  Loss2: (0.0000) | Acc: (95.00%) (44030/46208)
Epoch: 140 | Batch_idx: 370 |  Loss: (0.1399) |  Loss2: (0.0000) | Acc: (95.00%) (45244/47488)
Epoch: 140 | Batch_idx: 380 |  Loss: (0.1398) |  Loss2: (0.0000) | Acc: (95.00%) (46459/48768)
Epoch: 140 | Batch_idx: 390 |  Loss: (0.1394) |  Loss2: (0.0000) | Acc: (95.00%) (47637/50000)
=> saving checkpoint 'drive/app/torch/save_Schedule/checkpoint_140.pth.tar'
# TEST : Loss: (0.3947) | Acc: (88.00%) (8823/10000)
percent tensor([0.5038, 0.5067, 0.5132, 0.5027, 0.5125, 0.5031, 0.5085, 0.5066, 0.5056,
        0.5083, 0.5072, 0.5112, 0.5040, 0.5031, 0.5053, 0.5028],
       device='cuda:0') torch.Size([16])
percent tensor([0.4896, 0.4760, 0.4914, 0.4910, 0.4797, 0.4997, 0.4762, 0.4787, 0.4919,
        0.4839, 0.4931, 0.4866, 0.4794, 0.4916, 0.4800, 0.4911],
       device='cuda:0') torch.Size([16])
percent tensor([0.6333, 0.6338, 0.5633, 0.5459, 0.5775, 0.6032, 0.6326, 0.5864, 0.5860,
        0.5936, 0.6119, 0.5568, 0.6495, 0.5610, 0.6459, 0.6179],
       device='cuda:0') torch.Size([16])
percent tensor([0.5873, 0.6210, 0.5873, 0.6498, 0.5817, 0.7003, 0.5974, 0.5548, 0.6455,
        0.6061, 0.6394, 0.6426, 0.6071, 0.6611, 0.6482, 0.6244],
       device='cuda:0') torch.Size([16])
percent tensor([0.5692, 0.5964, 0.5818, 0.5670, 0.6129, 0.5320, 0.6151, 0.5436, 0.6182,
        0.6312, 0.6256, 0.5471, 0.5700, 0.7217, 0.4721, 0.6184],
       device='cuda:0') torch.Size([16])
percent tensor([0.6064, 0.5723, 0.6804, 0.7017, 0.7173, 0.7170, 0.6325, 0.6652, 0.6273,
        0.5930, 0.6020, 0.6440, 0.5948, 0.6045, 0.6167, 0.6412],
       device='cuda:0') torch.Size([16])
percent tensor([0.6338, 0.7206, 0.7335, 0.6881, 0.7295, 0.6081, 0.6043, 0.6192, 0.7214,
        0.6809, 0.7537, 0.6925, 0.7034, 0.6397, 0.5862, 0.5041],
       device='cuda:0') torch.Size([16])
percent tensor([0.9997, 0.9997, 0.9997, 0.9998, 0.9996, 0.9990, 0.9996, 0.9993, 0.9997,
        0.9998, 1.0000, 0.9998, 0.9998, 0.9994, 0.9989, 0.9994],
       device='cuda:0') torch.Size([16])
Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 3, 3, 3]) tensor(190.0964, device='cuda:0')
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(820.0949, device='cuda:0')
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(824.1774, device='cuda:0')
Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([128, 64, 3, 3]) tensor(1529.2095, device='cuda:0')
Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([128, 64, 1, 1]) tensor(485.5197, device='cuda:0')
Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([128, 128, 3, 3]) tensor(2294.1257, device='cuda:0')
Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([256, 128, 3, 3]) tensor(4274.2759, device='cuda:0')
Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([256, 128, 1, 1]) tensor(1372.7236, device='cuda:0')
Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([256, 256, 3, 3]) tensor(6193.7476, device='cuda:0')
Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([512, 256, 3, 3]) tensor(11726.3447, device='cuda:0')
Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([512, 256, 1, 1]) tensor(3880.3887, device='cuda:0')
Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([512, 512, 3, 3]) tensor(16382.7627, device='cuda:0')
Epoch: 141 | Batch_idx: 0 |  Loss: (0.1289) |  Loss2: (0.0000) | Acc: (96.00%) (124/128)
Epoch: 141 | Batch_idx: 10 |  Loss: (0.1444) |  Loss2: (0.0000) | Acc: (95.00%) (1339/1408)
Epoch: 141 | Batch_idx: 20 |  Loss: (0.1346) |  Loss2: (0.0000) | Acc: (95.00%) (2571/2688)
Epoch: 141 | Batch_idx: 30 |  Loss: (0.1344) |  Loss2: (0.0000) | Acc: (95.00%) (3791/3968)
Epoch: 141 | Batch_idx: 40 |  Loss: (0.1371) |  Loss2: (0.0000) | Acc: (95.00%) (5015/5248)
Epoch: 141 | Batch_idx: 50 |  Loss: (0.1368) |  Loss2: (0.0000) | Acc: (95.00%) (6236/6528)
Epoch: 141 | Batch_idx: 60 |  Loss: (0.1367) |  Loss2: (0.0000) | Acc: (95.00%) (7458/7808)
Epoch: 141 | Batch_idx: 70 |  Loss: (0.1367) |  Loss2: (0.0000) | Acc: (95.00%) (8674/9088)
Epoch: 141 | Batch_idx: 80 |  Loss: (0.1376) |  Loss2: (0.0000) | Acc: (95.00%) (9897/10368)
Epoch: 141 | Batch_idx: 90 |  Loss: (0.1367) |  Loss2: (0.0000) | Acc: (95.00%) (11119/11648)
Epoch: 141 | Batch_idx: 100 |  Loss: (0.1379) |  Loss2: (0.0000) | Acc: (95.00%) (12337/12928)
Epoch: 141 | Batch_idx: 110 |  Loss: (0.1378) |  Loss2: (0.0000) | Acc: (95.00%) (13555/14208)
Epoch: 141 | Batch_idx: 120 |  Loss: (0.1368) |  Loss2: (0.0000) | Acc: (95.00%) (14779/15488)
Epoch: 141 | Batch_idx: 130 |  Loss: (0.1361) |  Loss2: (0.0000) | Acc: (95.00%) (16006/16768)
Epoch: 141 | Batch_idx: 140 |  Loss: (0.1354) |  Loss2: (0.0000) | Acc: (95.00%) (17230/18048)
Epoch: 141 | Batch_idx: 150 |  Loss: (0.1355) |  Loss2: (0.0000) | Acc: (95.00%) (18447/19328)
Epoch: 141 | Batch_idx: 160 |  Loss: (0.1355) |  Loss2: (0.0000) | Acc: (95.00%) (19672/20608)
Epoch: 141 | Batch_idx: 170 |  Loss: (0.1347) |  Loss2: (0.0000) | Acc: (95.00%) (20906/21888)
Epoch: 141 | Batch_idx: 180 |  Loss: (0.1347) |  Loss2: (0.0000) | Acc: (95.00%) (22126/23168)
Epoch: 141 | Batch_idx: 190 |  Loss: (0.1352) |  Loss2: (0.0000) | Acc: (95.00%) (23336/24448)
Epoch: 141 | Batch_idx: 200 |  Loss: (0.1357) |  Loss2: (0.0000) | Acc: (95.00%) (24562/25728)
Epoch: 141 | Batch_idx: 210 |  Loss: (0.1364) |  Loss2: (0.0000) | Acc: (95.00%) (25776/27008)
Epoch: 141 | Batch_idx: 220 |  Loss: (0.1369) |  Loss2: (0.0000) | Acc: (95.00%) (26995/28288)
Epoch: 141 | Batch_idx: 230 |  Loss: (0.1367) |  Loss2: (0.0000) | Acc: (95.00%) (28217/29568)
Epoch: 141 | Batch_idx: 240 |  Loss: (0.1383) |  Loss2: (0.0000) | Acc: (95.00%) (29419/30848)
Epoch: 141 | Batch_idx: 250 |  Loss: (0.1387) |  Loss2: (0.0000) | Acc: (95.00%) (30634/32128)
Epoch: 141 | Batch_idx: 260 |  Loss: (0.1382) |  Loss2: (0.0000) | Acc: (95.00%) (31856/33408)
Epoch: 141 | Batch_idx: 270 |  Loss: (0.1373) |  Loss2: (0.0000) | Acc: (95.00%) (33087/34688)
Epoch: 141 | Batch_idx: 280 |  Loss: (0.1371) |  Loss2: (0.0000) | Acc: (95.00%) (34302/35968)
Epoch: 141 | Batch_idx: 290 |  Loss: (0.1377) |  Loss2: (0.0000) | Acc: (95.00%) (35519/37248)
Epoch: 141 | Batch_idx: 300 |  Loss: (0.1382) |  Loss2: (0.0000) | Acc: (95.00%) (36732/38528)
Epoch: 141 | Batch_idx: 310 |  Loss: (0.1385) |  Loss2: (0.0000) | Acc: (95.00%) (37950/39808)
Epoch: 141 | Batch_idx: 320 |  Loss: (0.1390) |  Loss2: (0.0000) | Acc: (95.00%) (39161/41088)
Epoch: 141 | Batch_idx: 330 |  Loss: (0.1391) |  Loss2: (0.0000) | Acc: (95.00%) (40379/42368)
Epoch: 141 | Batch_idx: 340 |  Loss: (0.1389) |  Loss2: (0.0000) | Acc: (95.00%) (41602/43648)
Epoch: 141 | Batch_idx: 350 |  Loss: (0.1393) |  Loss2: (0.0000) | Acc: (95.00%) (42814/44928)
Epoch: 141 | Batch_idx: 360 |  Loss: (0.1392) |  Loss2: (0.0000) | Acc: (95.00%) (44026/46208)
Epoch: 141 | Batch_idx: 370 |  Loss: (0.1389) |  Loss2: (0.0000) | Acc: (95.00%) (45248/47488)
Epoch: 141 | Batch_idx: 380 |  Loss: (0.1387) |  Loss2: (0.0000) | Acc: (95.00%) (46470/48768)
Epoch: 141 | Batch_idx: 390 |  Loss: (0.1387) |  Loss2: (0.0000) | Acc: (95.00%) (47636/50000)
# TEST : Loss: (0.3943) | Acc: (88.00%) (8834/10000)
percent tensor([0.5046, 0.5076, 0.5139, 0.5034, 0.5132, 0.5039, 0.5095, 0.5074, 0.5065,
        0.5092, 0.5082, 0.5120, 0.5049, 0.5040, 0.5061, 0.5036],
       device='cuda:0') torch.Size([16])
percent tensor([0.4929, 0.4796, 0.4947, 0.4942, 0.4833, 0.5016, 0.4800, 0.4824, 0.4952,
        0.4872, 0.4964, 0.4901, 0.4828, 0.4948, 0.4834, 0.4942],
       device='cuda:0') torch.Size([16])
percent tensor([0.6365, 0.6368, 0.5657, 0.5475, 0.5800, 0.6063, 0.6365, 0.5890, 0.5891,
        0.5964, 0.6150, 0.5591, 0.6528, 0.5619, 0.6502, 0.6214],
       device='cuda:0') torch.Size([16])
percent tensor([0.5970, 0.6293, 0.5936, 0.6569, 0.5894, 0.7093, 0.6065, 0.5616, 0.6549,
        0.6143, 0.6489, 0.6500, 0.6174, 0.6698, 0.6575, 0.6339],
       device='cuda:0') torch.Size([16])
percent tensor([0.5751, 0.5980, 0.5909, 0.5742, 0.6231, 0.5434, 0.6201, 0.5521, 0.6209,
        0.6312, 0.6252, 0.5508, 0.5716, 0.7206, 0.4798, 0.6257],
       device='cuda:0') torch.Size([16])
percent tensor([0.6072, 0.5725, 0.6801, 0.7017, 0.7166, 0.7202, 0.6335, 0.6650, 0.6287,
        0.5926, 0.6013, 0.6440, 0.5975, 0.6043, 0.6165, 0.6444],
       device='cuda:0') torch.Size([16])
percent tensor([0.6274, 0.7157, 0.7263, 0.6842, 0.7181, 0.6072, 0.5958, 0.6134, 0.7150,
        0.6758, 0.7467, 0.6879, 0.6994, 0.6355, 0.5790, 0.4997],
       device='cuda:0') torch.Size([16])
percent tensor([0.9997, 0.9998, 0.9997, 0.9998, 0.9996, 0.9992, 0.9997, 0.9994, 0.9997,
        0.9998, 1.0000, 0.9998, 0.9998, 0.9995, 0.9990, 0.9994],
       device='cuda:0') torch.Size([16])
Epoch: 142 | Batch_idx: 0 |  Loss: (0.3092) |  Loss2: (0.0000) | Acc: (87.00%) (112/128)
Epoch: 142 | Batch_idx: 10 |  Loss: (0.1580) |  Loss2: (0.0000) | Acc: (94.00%) (1327/1408)
Epoch: 142 | Batch_idx: 20 |  Loss: (0.1491) |  Loss2: (0.0000) | Acc: (94.00%) (2544/2688)
Epoch: 142 | Batch_idx: 30 |  Loss: (0.1379) |  Loss2: (0.0000) | Acc: (95.00%) (3774/3968)
Epoch: 142 | Batch_idx: 40 |  Loss: (0.1409) |  Loss2: (0.0000) | Acc: (95.00%) (4988/5248)
Epoch: 142 | Batch_idx: 50 |  Loss: (0.1423) |  Loss2: (0.0000) | Acc: (94.00%) (6198/6528)
Epoch: 142 | Batch_idx: 60 |  Loss: (0.1392) |  Loss2: (0.0000) | Acc: (95.00%) (7424/7808)
Epoch: 142 | Batch_idx: 70 |  Loss: (0.1361) |  Loss2: (0.0000) | Acc: (95.00%) (8653/9088)
Epoch: 142 | Batch_idx: 80 |  Loss: (0.1359) |  Loss2: (0.0000) | Acc: (95.00%) (9868/10368)
Epoch: 142 | Batch_idx: 90 |  Loss: (0.1365) |  Loss2: (0.0000) | Acc: (95.00%) (11089/11648)
Epoch: 142 | Batch_idx: 100 |  Loss: (0.1379) |  Loss2: (0.0000) | Acc: (95.00%) (12294/12928)
Epoch: 142 | Batch_idx: 110 |  Loss: (0.1374) |  Loss2: (0.0000) | Acc: (95.00%) (13517/14208)
Epoch: 142 | Batch_idx: 120 |  Loss: (0.1379) |  Loss2: (0.0000) | Acc: (95.00%) (14736/15488)
Epoch: 142 | Batch_idx: 130 |  Loss: (0.1393) |  Loss2: (0.0000) | Acc: (95.00%) (15953/16768)
Epoch: 142 | Batch_idx: 140 |  Loss: (0.1378) |  Loss2: (0.0000) | Acc: (95.00%) (17182/18048)
Epoch: 142 | Batch_idx: 150 |  Loss: (0.1378) |  Loss2: (0.0000) | Acc: (95.00%) (18404/19328)
Epoch: 142 | Batch_idx: 160 |  Loss: (0.1377) |  Loss2: (0.0000) | Acc: (95.00%) (19623/20608)
Epoch: 142 | Batch_idx: 170 |  Loss: (0.1377) |  Loss2: (0.0000) | Acc: (95.00%) (20846/21888)
Epoch: 142 | Batch_idx: 180 |  Loss: (0.1374) |  Loss2: (0.0000) | Acc: (95.00%) (22066/23168)
Epoch: 142 | Batch_idx: 190 |  Loss: (0.1377) |  Loss2: (0.0000) | Acc: (95.00%) (23277/24448)
Epoch: 142 | Batch_idx: 200 |  Loss: (0.1377) |  Loss2: (0.0000) | Acc: (95.00%) (24494/25728)
Epoch: 142 | Batch_idx: 210 |  Loss: (0.1369) |  Loss2: (0.0000) | Acc: (95.00%) (25721/27008)
Epoch: 142 | Batch_idx: 220 |  Loss: (0.1369) |  Loss2: (0.0000) | Acc: (95.00%) (26939/28288)
Epoch: 142 | Batch_idx: 230 |  Loss: (0.1368) |  Loss2: (0.0000) | Acc: (95.00%) (28162/29568)
Epoch: 142 | Batch_idx: 240 |  Loss: (0.1364) |  Loss2: (0.0000) | Acc: (95.00%) (29393/30848)
Epoch: 142 | Batch_idx: 250 |  Loss: (0.1357) |  Loss2: (0.0000) | Acc: (95.00%) (30615/32128)
Epoch: 142 | Batch_idx: 260 |  Loss: (0.1357) |  Loss2: (0.0000) | Acc: (95.00%) (31839/33408)
Epoch: 142 | Batch_idx: 270 |  Loss: (0.1363) |  Loss2: (0.0000) | Acc: (95.00%) (33049/34688)
Epoch: 142 | Batch_idx: 280 |  Loss: (0.1360) |  Loss2: (0.0000) | Acc: (95.00%) (34273/35968)
Epoch: 142 | Batch_idx: 290 |  Loss: (0.1360) |  Loss2: (0.0000) | Acc: (95.00%) (35501/37248)
Epoch: 142 | Batch_idx: 300 |  Loss: (0.1361) |  Loss2: (0.0000) | Acc: (95.00%) (36712/38528)
Epoch: 142 | Batch_idx: 310 |  Loss: (0.1361) |  Loss2: (0.0000) | Acc: (95.00%) (37934/39808)
Epoch: 142 | Batch_idx: 320 |  Loss: (0.1361) |  Loss2: (0.0000) | Acc: (95.00%) (39150/41088)
Epoch: 142 | Batch_idx: 330 |  Loss: (0.1360) |  Loss2: (0.0000) | Acc: (95.00%) (40372/42368)
Epoch: 142 | Batch_idx: 340 |  Loss: (0.1353) |  Loss2: (0.0000) | Acc: (95.00%) (41607/43648)
Epoch: 142 | Batch_idx: 350 |  Loss: (0.1353) |  Loss2: (0.0000) | Acc: (95.00%) (42825/44928)
Epoch: 142 | Batch_idx: 360 |  Loss: (0.1348) |  Loss2: (0.0000) | Acc: (95.00%) (44051/46208)
Epoch: 142 | Batch_idx: 370 |  Loss: (0.1354) |  Loss2: (0.0000) | Acc: (95.00%) (45263/47488)
Epoch: 142 | Batch_idx: 380 |  Loss: (0.1356) |  Loss2: (0.0000) | Acc: (95.00%) (46475/48768)
Epoch: 142 | Batch_idx: 390 |  Loss: (0.1350) |  Loss2: (0.0000) | Acc: (95.00%) (47657/50000)
# TEST : Loss: (0.3890) | Acc: (88.00%) (8838/10000)
percent tensor([0.5047, 0.5076, 0.5142, 0.5034, 0.5135, 0.5038, 0.5096, 0.5075, 0.5066,
        0.5093, 0.5083, 0.5123, 0.5049, 0.5040, 0.5061, 0.5036],
       device='cuda:0') torch.Size([16])
percent tensor([0.4940, 0.4812, 0.4959, 0.4954, 0.4846, 0.5023, 0.4817, 0.4843, 0.4964,
        0.4886, 0.4978, 0.4915, 0.4840, 0.4961, 0.4847, 0.4953],
       device='cuda:0') torch.Size([16])
percent tensor([0.6367, 0.6373, 0.5641, 0.5454, 0.5781, 0.6050, 0.6372, 0.5874, 0.5886,
        0.5959, 0.6146, 0.5577, 0.6536, 0.5611, 0.6499, 0.6218],
       device='cuda:0') torch.Size([16])
percent tensor([0.5969, 0.6295, 0.5931, 0.6575, 0.5903, 0.7099, 0.6078, 0.5618, 0.6558,
        0.6149, 0.6495, 0.6508, 0.6173, 0.6709, 0.6578, 0.6341],
       device='cuda:0') torch.Size([16])
percent tensor([0.5776, 0.5993, 0.5939, 0.5779, 0.6238, 0.5527, 0.6199, 0.5506, 0.6217,
        0.6322, 0.6256, 0.5520, 0.5732, 0.7205, 0.4804, 0.6296],
       device='cuda:0') torch.Size([16])
percent tensor([0.6017, 0.5664, 0.6743, 0.6971, 0.7108, 0.7176, 0.6283, 0.6599, 0.6234,
        0.5866, 0.5957, 0.6394, 0.5928, 0.5997, 0.6111, 0.6399],
       device='cuda:0') torch.Size([16])
percent tensor([0.6261, 0.7182, 0.7248, 0.6825, 0.7142, 0.6042, 0.5925, 0.6117, 0.7191,
        0.6771, 0.7508, 0.6886, 0.7032, 0.6359, 0.5794, 0.4964],
       device='cuda:0') torch.Size([16])
percent tensor([0.9997, 0.9998, 0.9997, 0.9998, 0.9996, 0.9992, 0.9997, 0.9994, 0.9997,
        0.9998, 1.0000, 0.9999, 0.9998, 0.9995, 0.9991, 0.9994],
       device='cuda:0') torch.Size([16])
Epoch: 143 | Batch_idx: 0 |  Loss: (0.1281) |  Loss2: (0.0000) | Acc: (95.00%) (122/128)
Epoch: 143 | Batch_idx: 10 |  Loss: (0.1432) |  Loss2: (0.0000) | Acc: (95.00%) (1338/1408)
Epoch: 143 | Batch_idx: 20 |  Loss: (0.1379) |  Loss2: (0.0000) | Acc: (95.00%) (2569/2688)
Epoch: 143 | Batch_idx: 30 |  Loss: (0.1338) |  Loss2: (0.0000) | Acc: (95.00%) (3798/3968)
Epoch: 143 | Batch_idx: 40 |  Loss: (0.1328) |  Loss2: (0.0000) | Acc: (95.00%) (5029/5248)
Epoch: 143 | Batch_idx: 50 |  Loss: (0.1380) |  Loss2: (0.0000) | Acc: (95.00%) (6245/6528)
Epoch: 143 | Batch_idx: 60 |  Loss: (0.1356) |  Loss2: (0.0000) | Acc: (95.00%) (7473/7808)
Epoch: 143 | Batch_idx: 70 |  Loss: (0.1371) |  Loss2: (0.0000) | Acc: (95.00%) (8690/9088)
Epoch: 143 | Batch_idx: 80 |  Loss: (0.1367) |  Loss2: (0.0000) | Acc: (95.00%) (9920/10368)
Epoch: 143 | Batch_idx: 90 |  Loss: (0.1365) |  Loss2: (0.0000) | Acc: (95.00%) (11139/11648)
Epoch: 143 | Batch_idx: 100 |  Loss: (0.1358) |  Loss2: (0.0000) | Acc: (95.00%) (12362/12928)
Epoch: 143 | Batch_idx: 110 |  Loss: (0.1333) |  Loss2: (0.0000) | Acc: (95.00%) (13597/14208)
Epoch: 143 | Batch_idx: 120 |  Loss: (0.1324) |  Loss2: (0.0000) | Acc: (95.00%) (14820/15488)
Epoch: 143 | Batch_idx: 130 |  Loss: (0.1324) |  Loss2: (0.0000) | Acc: (95.00%) (16049/16768)
Epoch: 143 | Batch_idx: 140 |  Loss: (0.1334) |  Loss2: (0.0000) | Acc: (95.00%) (17255/18048)
Epoch: 143 | Batch_idx: 150 |  Loss: (0.1324) |  Loss2: (0.0000) | Acc: (95.00%) (18480/19328)
Epoch: 143 | Batch_idx: 160 |  Loss: (0.1327) |  Loss2: (0.0000) | Acc: (95.00%) (19707/20608)
Epoch: 143 | Batch_idx: 170 |  Loss: (0.1326) |  Loss2: (0.0000) | Acc: (95.00%) (20929/21888)
Epoch: 143 | Batch_idx: 180 |  Loss: (0.1318) |  Loss2: (0.0000) | Acc: (95.00%) (22155/23168)
Epoch: 143 | Batch_idx: 190 |  Loss: (0.1319) |  Loss2: (0.0000) | Acc: (95.00%) (23378/24448)
Epoch: 143 | Batch_idx: 200 |  Loss: (0.1313) |  Loss2: (0.0000) | Acc: (95.00%) (24607/25728)
Epoch: 143 | Batch_idx: 210 |  Loss: (0.1314) |  Loss2: (0.0000) | Acc: (95.00%) (25833/27008)
Epoch: 143 | Batch_idx: 220 |  Loss: (0.1315) |  Loss2: (0.0000) | Acc: (95.00%) (27058/28288)
Epoch: 143 | Batch_idx: 230 |  Loss: (0.1309) |  Loss2: (0.0000) | Acc: (95.00%) (28291/29568)
Epoch: 143 | Batch_idx: 240 |  Loss: (0.1310) |  Loss2: (0.0000) | Acc: (95.00%) (29513/30848)
Epoch: 143 | Batch_idx: 250 |  Loss: (0.1306) |  Loss2: (0.0000) | Acc: (95.00%) (30738/32128)
Epoch: 143 | Batch_idx: 260 |  Loss: (0.1312) |  Loss2: (0.0000) | Acc: (95.00%) (31952/33408)
Epoch: 143 | Batch_idx: 270 |  Loss: (0.1309) |  Loss2: (0.0000) | Acc: (95.00%) (33181/34688)
Epoch: 143 | Batch_idx: 280 |  Loss: (0.1306) |  Loss2: (0.0000) | Acc: (95.00%) (34414/35968)
Epoch: 143 | Batch_idx: 290 |  Loss: (0.1308) |  Loss2: (0.0000) | Acc: (95.00%) (35634/37248)
Epoch: 143 | Batch_idx: 300 |  Loss: (0.1312) |  Loss2: (0.0000) | Acc: (95.00%) (36845/38528)
Epoch: 143 | Batch_idx: 310 |  Loss: (0.1316) |  Loss2: (0.0000) | Acc: (95.00%) (38071/39808)
Epoch: 143 | Batch_idx: 320 |  Loss: (0.1320) |  Loss2: (0.0000) | Acc: (95.00%) (39287/41088)
Epoch: 143 | Batch_idx: 330 |  Loss: (0.1320) |  Loss2: (0.0000) | Acc: (95.00%) (40512/42368)
Epoch: 143 | Batch_idx: 340 |  Loss: (0.1317) |  Loss2: (0.0000) | Acc: (95.00%) (41738/43648)
Epoch: 143 | Batch_idx: 350 |  Loss: (0.1313) |  Loss2: (0.0000) | Acc: (95.00%) (42975/44928)
Epoch: 143 | Batch_idx: 360 |  Loss: (0.1311) |  Loss2: (0.0000) | Acc: (95.00%) (44198/46208)
Epoch: 143 | Batch_idx: 370 |  Loss: (0.1310) |  Loss2: (0.0000) | Acc: (95.00%) (45416/47488)
Epoch: 143 | Batch_idx: 380 |  Loss: (0.1310) |  Loss2: (0.0000) | Acc: (95.00%) (46639/48768)
Epoch: 143 | Batch_idx: 390 |  Loss: (0.1312) |  Loss2: (0.0000) | Acc: (95.00%) (47813/50000)
# TEST : Loss: (0.3903) | Acc: (88.00%) (8840/10000)
percent tensor([0.5053, 0.5084, 0.5153, 0.5043, 0.5144, 0.5043, 0.5105, 0.5084, 0.5074,
        0.5102, 0.5090, 0.5133, 0.5057, 0.5048, 0.5068, 0.5043],
       device='cuda:0') torch.Size([16])
percent tensor([0.4943, 0.4815, 0.4965, 0.4962, 0.4847, 0.5024, 0.4819, 0.4849, 0.4967,
        0.4891, 0.4982, 0.4921, 0.4841, 0.4969, 0.4847, 0.4957],
       device='cuda:0') torch.Size([16])
percent tensor([0.6354, 0.6335, 0.5655, 0.5474, 0.5797, 0.6052, 0.6360, 0.5893, 0.5877,
        0.5928, 0.6121, 0.5583, 0.6508, 0.5590, 0.6482, 0.6206],
       device='cuda:0') torch.Size([16])
percent tensor([0.6029, 0.6348, 0.5998, 0.6630, 0.5961, 0.7146, 0.6136, 0.5674, 0.6614,
        0.6200, 0.6543, 0.6565, 0.6233, 0.6766, 0.6630, 0.6407],
       device='cuda:0') torch.Size([16])
percent tensor([0.5821, 0.6063, 0.5974, 0.5820, 0.6268, 0.5543, 0.6254, 0.5543, 0.6273,
        0.6376, 0.6289, 0.5549, 0.5787, 0.7238, 0.4839, 0.6337],
       device='cuda:0') torch.Size([16])
percent tensor([0.6121, 0.5766, 0.6828, 0.7065, 0.7199, 0.7280, 0.6390, 0.6687, 0.6339,
        0.5975, 0.6059, 0.6493, 0.6033, 0.6104, 0.6216, 0.6539],
       device='cuda:0') torch.Size([16])
percent tensor([0.6193, 0.7114, 0.7137, 0.6729, 0.7024, 0.6033, 0.5840, 0.5997, 0.7138,
        0.6679, 0.7493, 0.6800, 0.7004, 0.6302, 0.5738, 0.4910],
       device='cuda:0') torch.Size([16])
percent tensor([0.9997, 0.9998, 0.9997, 0.9998, 0.9996, 0.9993, 0.9997, 0.9994, 0.9997,
        0.9998, 1.0000, 0.9999, 0.9998, 0.9995, 0.9991, 0.9995],
       device='cuda:0') torch.Size([16])
True Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=128, out_features=16, bias=False)
False Linear(in_features=16, out_features=2, bias=False)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=128, out_features=16, bias=False)
False Linear(in_features=16, out_features=2, bias=False)
True Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=256, out_features=32, bias=False)
False Linear(in_features=32, out_features=2, bias=False)
True Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=256, out_features=32, bias=False)
False Linear(in_features=32, out_features=2, bias=False)
True Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=512, out_features=64, bias=False)
False Linear(in_features=64, out_features=2, bias=False)
True Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=512, out_features=64, bias=False)
False Linear(in_features=64, out_features=2, bias=False)
True Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1024, out_features=128, bias=False)
False Linear(in_features=128, out_features=2, bias=False)
True Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1024, out_features=128, bias=False)
False Linear(in_features=128, out_features=2, bias=False)
True Linear(in_features=512, out_features=10, bias=True)
Epoch: 144 | Batch_idx: 0 |  Loss: (0.1111) |  Loss2: (0.0000) | Acc: (96.00%) (123/128)
Epoch: 144 | Batch_idx: 10 |  Loss: (0.1218) |  Loss2: (0.0000) | Acc: (95.00%) (1348/1408)
Epoch: 144 | Batch_idx: 20 |  Loss: (0.1212) |  Loss2: (0.0000) | Acc: (95.00%) (2569/2688)
Epoch: 144 | Batch_idx: 30 |  Loss: (0.1261) |  Loss2: (0.0000) | Acc: (95.00%) (3795/3968)
Epoch: 144 | Batch_idx: 40 |  Loss: (0.1293) |  Loss2: (0.0000) | Acc: (95.00%) (5003/5248)
Epoch: 144 | Batch_idx: 50 |  Loss: (0.1364) |  Loss2: (0.0000) | Acc: (95.00%) (6209/6528)
Epoch: 144 | Batch_idx: 60 |  Loss: (0.1383) |  Loss2: (0.0000) | Acc: (95.00%) (7421/7808)
Epoch: 144 | Batch_idx: 70 |  Loss: (0.1408) |  Loss2: (0.0000) | Acc: (94.00%) (8631/9088)
Epoch: 144 | Batch_idx: 80 |  Loss: (0.1408) |  Loss2: (0.0000) | Acc: (95.00%) (9855/10368)
Epoch: 144 | Batch_idx: 90 |  Loss: (0.1415) |  Loss2: (0.0000) | Acc: (94.00%) (11065/11648)
Epoch: 144 | Batch_idx: 100 |  Loss: (0.1426) |  Loss2: (0.0000) | Acc: (95.00%) (12282/12928)
Epoch: 144 | Batch_idx: 110 |  Loss: (0.1426) |  Loss2: (0.0000) | Acc: (94.00%) (13497/14208)
Epoch: 144 | Batch_idx: 120 |  Loss: (0.1446) |  Loss2: (0.0000) | Acc: (94.00%) (14706/15488)
Epoch: 144 | Batch_idx: 130 |  Loss: (0.1443) |  Loss2: (0.0000) | Acc: (94.00%) (15921/16768)
Epoch: 144 | Batch_idx: 140 |  Loss: (0.1447) |  Loss2: (0.0000) | Acc: (94.00%) (17133/18048)
Epoch: 144 | Batch_idx: 150 |  Loss: (0.1456) |  Loss2: (0.0000) | Acc: (94.00%) (18340/19328)
Epoch: 144 | Batch_idx: 160 |  Loss: (0.1462) |  Loss2: (0.0000) | Acc: (94.00%) (19545/20608)
Epoch: 144 | Batch_idx: 170 |  Loss: (0.1460) |  Loss2: (0.0000) | Acc: (94.00%) (20767/21888)
Epoch: 144 | Batch_idx: 180 |  Loss: (0.1462) |  Loss2: (0.0000) | Acc: (94.00%) (21983/23168)
Epoch: 144 | Batch_idx: 190 |  Loss: (0.1462) |  Loss2: (0.0000) | Acc: (94.00%) (23205/24448)
Epoch: 144 | Batch_idx: 200 |  Loss: (0.1472) |  Loss2: (0.0000) | Acc: (94.00%) (24408/25728)
Epoch: 144 | Batch_idx: 210 |  Loss: (0.1462) |  Loss2: (0.0000) | Acc: (94.00%) (25634/27008)
Epoch: 144 | Batch_idx: 220 |  Loss: (0.1463) |  Loss2: (0.0000) | Acc: (94.00%) (26841/28288)
Epoch: 144 | Batch_idx: 230 |  Loss: (0.1460) |  Loss2: (0.0000) | Acc: (94.00%) (28063/29568)
Epoch: 144 | Batch_idx: 240 |  Loss: (0.1460) |  Loss2: (0.0000) | Acc: (94.00%) (29278/30848)
Epoch: 144 | Batch_idx: 250 |  Loss: (0.1457) |  Loss2: (0.0000) | Acc: (94.00%) (30496/32128)
Epoch: 144 | Batch_idx: 260 |  Loss: (0.1458) |  Loss2: (0.0000) | Acc: (94.00%) (31704/33408)
Epoch: 144 | Batch_idx: 270 |  Loss: (0.1466) |  Loss2: (0.0000) | Acc: (94.00%) (32902/34688)
Epoch: 144 | Batch_idx: 280 |  Loss: (0.1461) |  Loss2: (0.0000) | Acc: (94.00%) (34121/35968)
Epoch: 144 | Batch_idx: 290 |  Loss: (0.1462) |  Loss2: (0.0000) | Acc: (94.00%) (35329/37248)
Epoch: 144 | Batch_idx: 300 |  Loss: (0.1461) |  Loss2: (0.0000) | Acc: (94.00%) (36547/38528)
Epoch: 144 | Batch_idx: 310 |  Loss: (0.1466) |  Loss2: (0.0000) | Acc: (94.00%) (37750/39808)
Epoch: 144 | Batch_idx: 320 |  Loss: (0.1465) |  Loss2: (0.0000) | Acc: (94.00%) (38969/41088)
Epoch: 144 | Batch_idx: 330 |  Loss: (0.1466) |  Loss2: (0.0000) | Acc: (94.00%) (40188/42368)
Epoch: 144 | Batch_idx: 340 |  Loss: (0.1467) |  Loss2: (0.0000) | Acc: (94.00%) (41403/43648)
Epoch: 144 | Batch_idx: 350 |  Loss: (0.1467) |  Loss2: (0.0000) | Acc: (94.00%) (42617/44928)
Epoch: 144 | Batch_idx: 360 |  Loss: (0.1468) |  Loss2: (0.0000) | Acc: (94.00%) (43828/46208)
Epoch: 144 | Batch_idx: 370 |  Loss: (0.1466) |  Loss2: (0.0000) | Acc: (94.00%) (45049/47488)
Epoch: 144 | Batch_idx: 380 |  Loss: (0.1471) |  Loss2: (0.0000) | Acc: (94.00%) (46255/48768)
Epoch: 144 | Batch_idx: 390 |  Loss: (0.1473) |  Loss2: (0.0000) | Acc: (94.00%) (47415/50000)
# TEST : Loss: (0.4478) | Acc: (86.00%) (8680/10000)
percent tensor([0.5056, 0.5083, 0.5150, 0.5047, 0.5143, 0.5052, 0.5101, 0.5086, 0.5076,
        0.5101, 0.5090, 0.5129, 0.5060, 0.5042, 0.5072, 0.5045],
       device='cuda:0') torch.Size([16])
percent tensor([0.4938, 0.4810, 0.4945, 0.4929, 0.4847, 0.5051, 0.4816, 0.4818, 0.4972,
        0.4880, 0.4983, 0.4911, 0.4827, 0.4955, 0.4846, 0.4951],
       device='cuda:0') torch.Size([16])
percent tensor([0.6276, 0.6186, 0.5721, 0.5585, 0.5878, 0.6024, 0.6342, 0.5854, 0.5744,
        0.5919, 0.5938, 0.5737, 0.6455, 0.5543, 0.6467, 0.6130],
       device='cuda:0') torch.Size([16])
percent tensor([0.5970, 0.6393, 0.5977, 0.6593, 0.5969, 0.7077, 0.6126, 0.5666, 0.6525,
        0.6298, 0.6512, 0.6606, 0.6217, 0.6783, 0.6648, 0.6379],
       device='cuda:0') torch.Size([16])
percent tensor([0.5908, 0.6000, 0.5882, 0.5780, 0.6240, 0.5658, 0.6217, 0.5528, 0.6411,
        0.6355, 0.6263, 0.5324, 0.5714, 0.7167, 0.4849, 0.6336],
       device='cuda:0') torch.Size([16])
percent tensor([0.6149, 0.5775, 0.6881, 0.7086, 0.7276, 0.7254, 0.6388, 0.6647, 0.6512,
        0.6222, 0.6206, 0.6519, 0.6127, 0.6299, 0.6236, 0.6531],
       device='cuda:0') torch.Size([16])
percent tensor([0.6261, 0.7066, 0.7502, 0.7098, 0.7372, 0.6344, 0.5682, 0.6105, 0.7208,
        0.6731, 0.7532, 0.6905, 0.6953, 0.6139, 0.5998, 0.5087],
       device='cuda:0') torch.Size([16])
percent tensor([0.9998, 0.9998, 0.9999, 0.9999, 0.9998, 0.9992, 0.9998, 0.9996, 0.9998,
        0.9999, 1.0000, 0.9999, 0.9999, 0.9994, 0.9991, 0.9995],
       device='cuda:0') torch.Size([16])
Epoch: 145 | Batch_idx: 0 |  Loss: (0.1045) |  Loss2: (0.0000) | Acc: (96.00%) (123/128)
Epoch: 145 | Batch_idx: 10 |  Loss: (0.1413) |  Loss2: (0.0000) | Acc: (95.00%) (1347/1408)
Epoch: 145 | Batch_idx: 20 |  Loss: (0.1513) |  Loss2: (0.0000) | Acc: (95.00%) (2562/2688)
Epoch: 145 | Batch_idx: 30 |  Loss: (0.1475) |  Loss2: (0.0000) | Acc: (95.00%) (3780/3968)
Epoch: 145 | Batch_idx: 40 |  Loss: (0.1468) |  Loss2: (0.0000) | Acc: (95.00%) (4994/5248)
Epoch: 145 | Batch_idx: 50 |  Loss: (0.1459) |  Loss2: (0.0000) | Acc: (95.00%) (6209/6528)
Epoch: 145 | Batch_idx: 60 |  Loss: (0.1475) |  Loss2: (0.0000) | Acc: (94.00%) (7417/7808)
Epoch: 145 | Batch_idx: 70 |  Loss: (0.1464) |  Loss2: (0.0000) | Acc: (95.00%) (8643/9088)
Epoch: 145 | Batch_idx: 80 |  Loss: (0.1466) |  Loss2: (0.0000) | Acc: (95.00%) (9851/10368)
Epoch: 145 | Batch_idx: 90 |  Loss: (0.1452) |  Loss2: (0.0000) | Acc: (95.00%) (11071/11648)
Epoch: 145 | Batch_idx: 100 |  Loss: (0.1445) |  Loss2: (0.0000) | Acc: (95.00%) (12290/12928)
Epoch: 145 | Batch_idx: 110 |  Loss: (0.1454) |  Loss2: (0.0000) | Acc: (95.00%) (13515/14208)
Epoch: 145 | Batch_idx: 120 |  Loss: (0.1442) |  Loss2: (0.0000) | Acc: (95.00%) (14738/15488)
Epoch: 145 | Batch_idx: 130 |  Loss: (0.1432) |  Loss2: (0.0000) | Acc: (95.00%) (15962/16768)
Epoch: 145 | Batch_idx: 140 |  Loss: (0.1430) |  Loss2: (0.0000) | Acc: (95.00%) (17174/18048)
Epoch: 145 | Batch_idx: 150 |  Loss: (0.1434) |  Loss2: (0.0000) | Acc: (95.00%) (18391/19328)
Epoch: 145 | Batch_idx: 160 |  Loss: (0.1437) |  Loss2: (0.0000) | Acc: (95.00%) (19603/20608)
Epoch: 145 | Batch_idx: 170 |  Loss: (0.1436) |  Loss2: (0.0000) | Acc: (95.00%) (20820/21888)
Epoch: 145 | Batch_idx: 180 |  Loss: (0.1433) |  Loss2: (0.0000) | Acc: (95.00%) (22041/23168)
Epoch: 145 | Batch_idx: 190 |  Loss: (0.1432) |  Loss2: (0.0000) | Acc: (95.00%) (23258/24448)
Epoch: 145 | Batch_idx: 200 |  Loss: (0.1426) |  Loss2: (0.0000) | Acc: (95.00%) (24477/25728)
Epoch: 145 | Batch_idx: 210 |  Loss: (0.1418) |  Loss2: (0.0000) | Acc: (95.00%) (25703/27008)
Epoch: 145 | Batch_idx: 220 |  Loss: (0.1425) |  Loss2: (0.0000) | Acc: (95.00%) (26919/28288)
Epoch: 145 | Batch_idx: 230 |  Loss: (0.1423) |  Loss2: (0.0000) | Acc: (95.00%) (28144/29568)
Epoch: 145 | Batch_idx: 240 |  Loss: (0.1423) |  Loss2: (0.0000) | Acc: (95.00%) (29359/30848)
Epoch: 145 | Batch_idx: 250 |  Loss: (0.1424) |  Loss2: (0.0000) | Acc: (95.00%) (30578/32128)
Epoch: 145 | Batch_idx: 260 |  Loss: (0.1426) |  Loss2: (0.0000) | Acc: (95.00%) (31794/33408)
Epoch: 145 | Batch_idx: 270 |  Loss: (0.1425) |  Loss2: (0.0000) | Acc: (95.00%) (33014/34688)
Epoch: 145 | Batch_idx: 280 |  Loss: (0.1419) |  Loss2: (0.0000) | Acc: (95.00%) (34242/35968)
Epoch: 145 | Batch_idx: 290 |  Loss: (0.1421) |  Loss2: (0.0000) | Acc: (95.00%) (35458/37248)
Epoch: 145 | Batch_idx: 300 |  Loss: (0.1422) |  Loss2: (0.0000) | Acc: (95.00%) (36671/38528)
Epoch: 145 | Batch_idx: 310 |  Loss: (0.1418) |  Loss2: (0.0000) | Acc: (95.00%) (37893/39808)
Epoch: 145 | Batch_idx: 320 |  Loss: (0.1425) |  Loss2: (0.0000) | Acc: (95.00%) (39100/41088)
Epoch: 145 | Batch_idx: 330 |  Loss: (0.1426) |  Loss2: (0.0000) | Acc: (95.00%) (40315/42368)
Epoch: 145 | Batch_idx: 340 |  Loss: (0.1417) |  Loss2: (0.0000) | Acc: (95.00%) (41546/43648)
Epoch: 145 | Batch_idx: 350 |  Loss: (0.1415) |  Loss2: (0.0000) | Acc: (95.00%) (42769/44928)
Epoch: 145 | Batch_idx: 360 |  Loss: (0.1415) |  Loss2: (0.0000) | Acc: (95.00%) (43991/46208)
Epoch: 145 | Batch_idx: 370 |  Loss: (0.1411) |  Loss2: (0.0000) | Acc: (95.00%) (45220/47488)
Epoch: 145 | Batch_idx: 380 |  Loss: (0.1409) |  Loss2: (0.0000) | Acc: (95.00%) (46443/48768)
Epoch: 145 | Batch_idx: 390 |  Loss: (0.1405) |  Loss2: (0.0000) | Acc: (95.00%) (47623/50000)
=> saving checkpoint 'drive/app/torch/save_Schedule/checkpoint_145.pth.tar'
# TEST : Loss: (0.4071) | Acc: (87.00%) (8764/10000)
percent tensor([0.5059, 0.5083, 0.5154, 0.5038, 0.5146, 0.5048, 0.5107, 0.5083, 0.5088,
        0.5105, 0.5098, 0.5136, 0.5063, 0.5047, 0.5066, 0.5044],
       device='cuda:0') torch.Size([16])
percent tensor([0.4936, 0.4832, 0.4933, 0.4944, 0.4833, 0.5033, 0.4830, 0.4829, 0.4958,
        0.4891, 0.4997, 0.4910, 0.4835, 0.4972, 0.4862, 0.4960],
       device='cuda:0') torch.Size([16])
percent tensor([0.6399, 0.6224, 0.5777, 0.5596, 0.5925, 0.6137, 0.6402, 0.5886, 0.5834,
        0.5936, 0.6049, 0.5730, 0.6562, 0.5608, 0.6521, 0.6212],
       device='cuda:0') torch.Size([16])
percent tensor([0.5988, 0.6319, 0.5867, 0.6577, 0.6005, 0.7064, 0.6179, 0.5667, 0.6491,
        0.6276, 0.6524, 0.6616, 0.6235, 0.6806, 0.6656, 0.6356],
       device='cuda:0') torch.Size([16])
percent tensor([0.5921, 0.6126, 0.5842, 0.5758, 0.6194, 0.5679, 0.6219, 0.5581, 0.6471,
        0.6413, 0.6461, 0.5169, 0.5810, 0.7248, 0.4965, 0.6418],
       device='cuda:0') torch.Size([16])
percent tensor([0.6083, 0.5871, 0.6865, 0.7046, 0.7287, 0.7173, 0.6445, 0.6764, 0.6464,
        0.6238, 0.6222, 0.6532, 0.6113, 0.6262, 0.6294, 0.6632],
       device='cuda:0') torch.Size([16])
percent tensor([0.5982, 0.6887, 0.7377, 0.6829, 0.7191, 0.5994, 0.5761, 0.6025, 0.7189,
        0.6665, 0.7673, 0.6952, 0.7065, 0.6277, 0.5763, 0.4918],
       device='cuda:0') torch.Size([16])
percent tensor([0.9996, 0.9997, 0.9998, 0.9998, 0.9995, 0.9992, 0.9997, 0.9993, 0.9998,
        0.9998, 1.0000, 0.9999, 0.9999, 0.9994, 0.9990, 0.9994],
       device='cuda:0') torch.Size([16])
Epoch: 146 | Batch_idx: 0 |  Loss: (0.0599) |  Loss2: (0.0000) | Acc: (97.00%) (125/128)
Epoch: 146 | Batch_idx: 10 |  Loss: (0.1083) |  Loss2: (0.0000) | Acc: (96.00%) (1362/1408)
Epoch: 146 | Batch_idx: 20 |  Loss: (0.1128) |  Loss2: (0.0000) | Acc: (96.00%) (2589/2688)
Epoch: 146 | Batch_idx: 30 |  Loss: (0.1196) |  Loss2: (0.0000) | Acc: (96.00%) (3811/3968)
Epoch: 146 | Batch_idx: 40 |  Loss: (0.1177) |  Loss2: (0.0000) | Acc: (96.00%) (5041/5248)
Epoch: 146 | Batch_idx: 50 |  Loss: (0.1176) |  Loss2: (0.0000) | Acc: (96.00%) (6275/6528)
Epoch: 146 | Batch_idx: 60 |  Loss: (0.1170) |  Loss2: (0.0000) | Acc: (96.00%) (7505/7808)
Epoch: 146 | Batch_idx: 70 |  Loss: (0.1189) |  Loss2: (0.0000) | Acc: (95.00%) (8724/9088)
Epoch: 146 | Batch_idx: 80 |  Loss: (0.1173) |  Loss2: (0.0000) | Acc: (96.00%) (9963/10368)
Epoch: 146 | Batch_idx: 90 |  Loss: (0.1194) |  Loss2: (0.0000) | Acc: (95.00%) (11180/11648)
Epoch: 146 | Batch_idx: 100 |  Loss: (0.1220) |  Loss2: (0.0000) | Acc: (95.00%) (12397/12928)
Epoch: 146 | Batch_idx: 110 |  Loss: (0.1241) |  Loss2: (0.0000) | Acc: (95.00%) (13613/14208)
Epoch: 146 | Batch_idx: 120 |  Loss: (0.1267) |  Loss2: (0.0000) | Acc: (95.00%) (14817/15488)
Epoch: 146 | Batch_idx: 130 |  Loss: (0.1275) |  Loss2: (0.0000) | Acc: (95.00%) (16035/16768)
Epoch: 146 | Batch_idx: 140 |  Loss: (0.1288) |  Loss2: (0.0000) | Acc: (95.00%) (17256/18048)
Epoch: 146 | Batch_idx: 150 |  Loss: (0.1289) |  Loss2: (0.0000) | Acc: (95.00%) (18475/19328)
Epoch: 146 | Batch_idx: 160 |  Loss: (0.1310) |  Loss2: (0.0000) | Acc: (95.00%) (19674/20608)
Epoch: 146 | Batch_idx: 170 |  Loss: (0.1326) |  Loss2: (0.0000) | Acc: (95.00%) (20881/21888)
Epoch: 146 | Batch_idx: 180 |  Loss: (0.1326) |  Loss2: (0.0000) | Acc: (95.00%) (22096/23168)
Epoch: 146 | Batch_idx: 190 |  Loss: (0.1330) |  Loss2: (0.0000) | Acc: (95.00%) (23311/24448)
Epoch: 146 | Batch_idx: 200 |  Loss: (0.1335) |  Loss2: (0.0000) | Acc: (95.00%) (24531/25728)
Epoch: 146 | Batch_idx: 210 |  Loss: (0.1346) |  Loss2: (0.0000) | Acc: (95.00%) (25743/27008)
Epoch: 146 | Batch_idx: 220 |  Loss: (0.1353) |  Loss2: (0.0000) | Acc: (95.00%) (26956/28288)
Epoch: 146 | Batch_idx: 230 |  Loss: (0.1367) |  Loss2: (0.0000) | Acc: (95.00%) (28160/29568)
Epoch: 146 | Batch_idx: 240 |  Loss: (0.1368) |  Loss2: (0.0000) | Acc: (95.00%) (29379/30848)
Epoch: 146 | Batch_idx: 250 |  Loss: (0.1369) |  Loss2: (0.0000) | Acc: (95.00%) (30591/32128)
Epoch: 146 | Batch_idx: 260 |  Loss: (0.1362) |  Loss2: (0.0000) | Acc: (95.00%) (31826/33408)
Epoch: 146 | Batch_idx: 270 |  Loss: (0.1368) |  Loss2: (0.0000) | Acc: (95.00%) (33040/34688)
Epoch: 146 | Batch_idx: 280 |  Loss: (0.1372) |  Loss2: (0.0000) | Acc: (95.00%) (34250/35968)
Epoch: 146 | Batch_idx: 290 |  Loss: (0.1376) |  Loss2: (0.0000) | Acc: (95.00%) (35459/37248)
Epoch: 146 | Batch_idx: 300 |  Loss: (0.1375) |  Loss2: (0.0000) | Acc: (95.00%) (36676/38528)
Epoch: 146 | Batch_idx: 310 |  Loss: (0.1376) |  Loss2: (0.0000) | Acc: (95.00%) (37891/39808)
Epoch: 146 | Batch_idx: 320 |  Loss: (0.1382) |  Loss2: (0.0000) | Acc: (95.00%) (39099/41088)
Epoch: 146 | Batch_idx: 330 |  Loss: (0.1388) |  Loss2: (0.0000) | Acc: (95.00%) (40296/42368)
Epoch: 146 | Batch_idx: 340 |  Loss: (0.1391) |  Loss2: (0.0000) | Acc: (95.00%) (41500/43648)
Epoch: 146 | Batch_idx: 350 |  Loss: (0.1393) |  Loss2: (0.0000) | Acc: (95.00%) (42717/44928)
Epoch: 146 | Batch_idx: 360 |  Loss: (0.1397) |  Loss2: (0.0000) | Acc: (95.00%) (43933/46208)
Epoch: 146 | Batch_idx: 370 |  Loss: (0.1401) |  Loss2: (0.0000) | Acc: (95.00%) (45137/47488)
Epoch: 146 | Batch_idx: 380 |  Loss: (0.1405) |  Loss2: (0.0000) | Acc: (95.00%) (46342/48768)
Epoch: 146 | Batch_idx: 390 |  Loss: (0.1407) |  Loss2: (0.0000) | Acc: (95.00%) (47507/50000)
# TEST : Loss: (0.4278) | Acc: (87.00%) (8745/10000)
percent tensor([0.5061, 0.5080, 0.5146, 0.5033, 0.5138, 0.5053, 0.5101, 0.5078, 0.5086,
        0.5099, 0.5099, 0.5127, 0.5064, 0.5041, 0.5067, 0.5043],
       device='cuda:0') torch.Size([16])
percent tensor([0.4961, 0.4813, 0.4954, 0.4954, 0.4859, 0.5054, 0.4817, 0.4835, 0.4971,
        0.4885, 0.5000, 0.4909, 0.4854, 0.4945, 0.4859, 0.4966],
       device='cuda:0') torch.Size([16])
percent tensor([0.6294, 0.6326, 0.5673, 0.5557, 0.5819, 0.5994, 0.6466, 0.5834, 0.5858,
        0.5966, 0.6124, 0.5685, 0.6511, 0.5698, 0.6540, 0.6216],
       device='cuda:0') torch.Size([16])
percent tensor([0.6119, 0.6299, 0.6125, 0.6630, 0.6080, 0.7059, 0.6196, 0.5715, 0.6681,
        0.6227, 0.6561, 0.6758, 0.6301, 0.6737, 0.6626, 0.6393],
       device='cuda:0') torch.Size([16])
percent tensor([0.5887, 0.5875, 0.5655, 0.5812, 0.6119, 0.5761, 0.5980, 0.5406, 0.6358,
        0.6261, 0.6315, 0.5097, 0.5709, 0.7212, 0.4827, 0.6304],
       device='cuda:0') torch.Size([16])
percent tensor([0.6063, 0.5780, 0.6761, 0.6980, 0.7178, 0.7144, 0.6360, 0.6550, 0.6445,
        0.6152, 0.6167, 0.6632, 0.6131, 0.6387, 0.6208, 0.6503],
       device='cuda:0') torch.Size([16])
percent tensor([0.6016, 0.7191, 0.7263, 0.6660, 0.7171, 0.5942, 0.5572, 0.5920, 0.6948,
        0.6658, 0.7655, 0.6884, 0.6993, 0.6282, 0.5613, 0.4839],
       device='cuda:0') torch.Size([16])
percent tensor([0.9996, 0.9997, 0.9998, 0.9998, 0.9997, 0.9994, 0.9996, 0.9993, 0.9997,
        0.9998, 1.0000, 0.9999, 0.9999, 0.9990, 0.9988, 0.9994],
       device='cuda:0') torch.Size([16])
Epoch: 147 | Batch_idx: 0 |  Loss: (0.1226) |  Loss2: (0.0000) | Acc: (95.00%) (122/128)
Epoch: 147 | Batch_idx: 10 |  Loss: (0.1093) |  Loss2: (0.0000) | Acc: (96.00%) (1355/1408)
Epoch: 147 | Batch_idx: 20 |  Loss: (0.1097) |  Loss2: (0.0000) | Acc: (96.00%) (2591/2688)
Epoch: 147 | Batch_idx: 30 |  Loss: (0.1138) |  Loss2: (0.0000) | Acc: (96.00%) (3810/3968)
Epoch: 147 | Batch_idx: 40 |  Loss: (0.1155) |  Loss2: (0.0000) | Acc: (96.00%) (5042/5248)
Epoch: 147 | Batch_idx: 50 |  Loss: (0.1183) |  Loss2: (0.0000) | Acc: (95.00%) (6257/6528)
Epoch: 147 | Batch_idx: 60 |  Loss: (0.1175) |  Loss2: (0.0000) | Acc: (95.00%) (7491/7808)
Epoch: 147 | Batch_idx: 70 |  Loss: (0.1204) |  Loss2: (0.0000) | Acc: (95.00%) (8705/9088)
Epoch: 147 | Batch_idx: 80 |  Loss: (0.1191) |  Loss2: (0.0000) | Acc: (95.00%) (9942/10368)
Epoch: 147 | Batch_idx: 90 |  Loss: (0.1215) |  Loss2: (0.0000) | Acc: (95.00%) (11165/11648)
Epoch: 147 | Batch_idx: 100 |  Loss: (0.1210) |  Loss2: (0.0000) | Acc: (95.00%) (12402/12928)
Epoch: 147 | Batch_idx: 110 |  Loss: (0.1229) |  Loss2: (0.0000) | Acc: (95.00%) (13616/14208)
Epoch: 147 | Batch_idx: 120 |  Loss: (0.1238) |  Loss2: (0.0000) | Acc: (95.00%) (14834/15488)
Epoch: 147 | Batch_idx: 130 |  Loss: (0.1245) |  Loss2: (0.0000) | Acc: (95.00%) (16056/16768)
Epoch: 147 | Batch_idx: 140 |  Loss: (0.1246) |  Loss2: (0.0000) | Acc: (95.00%) (17280/18048)
Epoch: 147 | Batch_idx: 150 |  Loss: (0.1266) |  Loss2: (0.0000) | Acc: (95.00%) (18492/19328)
Epoch: 147 | Batch_idx: 160 |  Loss: (0.1277) |  Loss2: (0.0000) | Acc: (95.00%) (19705/20608)
Epoch: 147 | Batch_idx: 170 |  Loss: (0.1281) |  Loss2: (0.0000) | Acc: (95.00%) (20930/21888)
Epoch: 147 | Batch_idx: 180 |  Loss: (0.1277) |  Loss2: (0.0000) | Acc: (95.00%) (22151/23168)
Epoch: 147 | Batch_idx: 190 |  Loss: (0.1281) |  Loss2: (0.0000) | Acc: (95.00%) (23370/24448)
Epoch: 147 | Batch_idx: 200 |  Loss: (0.1285) |  Loss2: (0.0000) | Acc: (95.00%) (24584/25728)
Epoch: 147 | Batch_idx: 210 |  Loss: (0.1298) |  Loss2: (0.0000) | Acc: (95.00%) (25792/27008)
Epoch: 147 | Batch_idx: 220 |  Loss: (0.1302) |  Loss2: (0.0000) | Acc: (95.00%) (27015/28288)
Epoch: 147 | Batch_idx: 230 |  Loss: (0.1307) |  Loss2: (0.0000) | Acc: (95.00%) (28228/29568)
Epoch: 147 | Batch_idx: 240 |  Loss: (0.1302) |  Loss2: (0.0000) | Acc: (95.00%) (29454/30848)
Epoch: 147 | Batch_idx: 250 |  Loss: (0.1297) |  Loss2: (0.0000) | Acc: (95.00%) (30685/32128)
Epoch: 147 | Batch_idx: 260 |  Loss: (0.1305) |  Loss2: (0.0000) | Acc: (95.00%) (31896/33408)
Epoch: 147 | Batch_idx: 270 |  Loss: (0.1316) |  Loss2: (0.0000) | Acc: (95.00%) (33110/34688)
Epoch: 147 | Batch_idx: 280 |  Loss: (0.1329) |  Loss2: (0.0000) | Acc: (95.00%) (34318/35968)
Epoch: 147 | Batch_idx: 290 |  Loss: (0.1336) |  Loss2: (0.0000) | Acc: (95.00%) (35533/37248)
Epoch: 147 | Batch_idx: 300 |  Loss: (0.1336) |  Loss2: (0.0000) | Acc: (95.00%) (36753/38528)
Epoch: 147 | Batch_idx: 310 |  Loss: (0.1338) |  Loss2: (0.0000) | Acc: (95.00%) (37974/39808)
Epoch: 147 | Batch_idx: 320 |  Loss: (0.1336) |  Loss2: (0.0000) | Acc: (95.00%) (39201/41088)
Epoch: 147 | Batch_idx: 330 |  Loss: (0.1340) |  Loss2: (0.0000) | Acc: (95.00%) (40412/42368)
Epoch: 147 | Batch_idx: 340 |  Loss: (0.1348) |  Loss2: (0.0000) | Acc: (95.00%) (41625/43648)
Epoch: 147 | Batch_idx: 350 |  Loss: (0.1348) |  Loss2: (0.0000) | Acc: (95.00%) (42841/44928)
Epoch: 147 | Batch_idx: 360 |  Loss: (0.1346) |  Loss2: (0.0000) | Acc: (95.00%) (44058/46208)
Epoch: 147 | Batch_idx: 370 |  Loss: (0.1351) |  Loss2: (0.0000) | Acc: (95.00%) (45265/47488)
Epoch: 147 | Batch_idx: 380 |  Loss: (0.1352) |  Loss2: (0.0000) | Acc: (95.00%) (46478/48768)
Epoch: 147 | Batch_idx: 390 |  Loss: (0.1352) |  Loss2: (0.0000) | Acc: (95.00%) (47654/50000)
# TEST : Loss: (0.4866) | Acc: (85.00%) (8570/10000)
percent tensor([0.5063, 0.5081, 0.5144, 0.5035, 0.5140, 0.5060, 0.5104, 0.5076, 0.5085,
        0.5100, 0.5100, 0.5125, 0.5063, 0.5042, 0.5071, 0.5047],
       device='cuda:0') torch.Size([16])
percent tensor([0.4936, 0.4823, 0.4957, 0.4970, 0.4856, 0.5036, 0.4824, 0.4836, 0.4947,
        0.4879, 0.4973, 0.4914, 0.4821, 0.4966, 0.4862, 0.4951],
       device='cuda:0') torch.Size([16])
percent tensor([0.6413, 0.6235, 0.5715, 0.5517, 0.5866, 0.6068, 0.6415, 0.5796, 0.5930,
        0.5958, 0.6154, 0.5723, 0.6626, 0.5577, 0.6477, 0.6231],
       device='cuda:0') torch.Size([16])
percent tensor([0.6135, 0.6367, 0.6047, 0.6516, 0.6084, 0.7082, 0.6200, 0.5799, 0.6591,
        0.6264, 0.6525, 0.6692, 0.6343, 0.6690, 0.6683, 0.6374],
       device='cuda:0') torch.Size([16])
percent tensor([0.5917, 0.5935, 0.5739, 0.5752, 0.6149, 0.5863, 0.6100, 0.5407, 0.6340,
        0.6356, 0.6382, 0.5241, 0.5760, 0.7118, 0.4888, 0.6387],
       device='cuda:0') torch.Size([16])
percent tensor([0.6170, 0.5840, 0.6850, 0.7117, 0.7247, 0.7116, 0.6421, 0.6689, 0.6433,
        0.6237, 0.6201, 0.6602, 0.6206, 0.6245, 0.6285, 0.6587],
       device='cuda:0') torch.Size([16])
percent tensor([0.6154, 0.7119, 0.7265, 0.6704, 0.7301, 0.5800, 0.5889, 0.6279, 0.6905,
        0.6630, 0.7551, 0.6710, 0.7014, 0.6411, 0.6052, 0.5190],
       device='cuda:0') torch.Size([16])
percent tensor([0.9996, 0.9998, 0.9997, 0.9997, 0.9998, 0.9996, 0.9995, 0.9995, 0.9997,
        0.9998, 1.0000, 0.9998, 0.9998, 0.9990, 0.9990, 0.9992],
       device='cuda:0') torch.Size([16])
Epoch: 148 | Batch_idx: 0 |  Loss: (0.1199) |  Loss2: (0.0000) | Acc: (96.00%) (123/128)
Epoch: 148 | Batch_idx: 10 |  Loss: (0.1115) |  Loss2: (0.0000) | Acc: (96.00%) (1357/1408)
Epoch: 148 | Batch_idx: 20 |  Loss: (0.1129) |  Loss2: (0.0000) | Acc: (96.00%) (2588/2688)
Epoch: 148 | Batch_idx: 30 |  Loss: (0.1159) |  Loss2: (0.0000) | Acc: (96.00%) (3821/3968)
Epoch: 148 | Batch_idx: 40 |  Loss: (0.1184) |  Loss2: (0.0000) | Acc: (96.00%) (5053/5248)
Epoch: 148 | Batch_idx: 50 |  Loss: (0.1202) |  Loss2: (0.0000) | Acc: (96.00%) (6279/6528)
Epoch: 148 | Batch_idx: 60 |  Loss: (0.1197) |  Loss2: (0.0000) | Acc: (96.00%) (7511/7808)
Epoch: 148 | Batch_idx: 70 |  Loss: (0.1210) |  Loss2: (0.0000) | Acc: (96.00%) (8742/9088)
Epoch: 148 | Batch_idx: 80 |  Loss: (0.1187) |  Loss2: (0.0000) | Acc: (96.00%) (9981/10368)
Epoch: 148 | Batch_idx: 90 |  Loss: (0.1203) |  Loss2: (0.0000) | Acc: (96.00%) (11196/11648)
Epoch: 148 | Batch_idx: 100 |  Loss: (0.1221) |  Loss2: (0.0000) | Acc: (96.00%) (12412/12928)
Epoch: 148 | Batch_idx: 110 |  Loss: (0.1234) |  Loss2: (0.0000) | Acc: (95.00%) (13625/14208)
Epoch: 148 | Batch_idx: 120 |  Loss: (0.1236) |  Loss2: (0.0000) | Acc: (95.00%) (14847/15488)
Epoch: 148 | Batch_idx: 130 |  Loss: (0.1235) |  Loss2: (0.0000) | Acc: (95.00%) (16069/16768)
Epoch: 148 | Batch_idx: 140 |  Loss: (0.1219) |  Loss2: (0.0000) | Acc: (95.00%) (17311/18048)
Epoch: 148 | Batch_idx: 150 |  Loss: (0.1224) |  Loss2: (0.0000) | Acc: (95.00%) (18531/19328)
Epoch: 148 | Batch_idx: 160 |  Loss: (0.1233) |  Loss2: (0.0000) | Acc: (95.00%) (19746/20608)
Epoch: 148 | Batch_idx: 170 |  Loss: (0.1238) |  Loss2: (0.0000) | Acc: (95.00%) (20974/21888)
Epoch: 148 | Batch_idx: 180 |  Loss: (0.1237) |  Loss2: (0.0000) | Acc: (95.00%) (22198/23168)
Epoch: 148 | Batch_idx: 190 |  Loss: (0.1243) |  Loss2: (0.0000) | Acc: (95.00%) (23415/24448)
Epoch: 148 | Batch_idx: 200 |  Loss: (0.1256) |  Loss2: (0.0000) | Acc: (95.00%) (24630/25728)
Epoch: 148 | Batch_idx: 210 |  Loss: (0.1249) |  Loss2: (0.0000) | Acc: (95.00%) (25866/27008)
Epoch: 148 | Batch_idx: 220 |  Loss: (0.1247) |  Loss2: (0.0000) | Acc: (95.00%) (27091/28288)
Epoch: 148 | Batch_idx: 230 |  Loss: (0.1257) |  Loss2: (0.0000) | Acc: (95.00%) (28303/29568)
Epoch: 148 | Batch_idx: 240 |  Loss: (0.1264) |  Loss2: (0.0000) | Acc: (95.00%) (29517/30848)
Epoch: 148 | Batch_idx: 250 |  Loss: (0.1266) |  Loss2: (0.0000) | Acc: (95.00%) (30737/32128)
Epoch: 148 | Batch_idx: 260 |  Loss: (0.1271) |  Loss2: (0.0000) | Acc: (95.00%) (31945/33408)
Epoch: 148 | Batch_idx: 270 |  Loss: (0.1277) |  Loss2: (0.0000) | Acc: (95.00%) (33165/34688)
Epoch: 148 | Batch_idx: 280 |  Loss: (0.1277) |  Loss2: (0.0000) | Acc: (95.00%) (34389/35968)
Epoch: 148 | Batch_idx: 290 |  Loss: (0.1280) |  Loss2: (0.0000) | Acc: (95.00%) (35607/37248)
Epoch: 148 | Batch_idx: 300 |  Loss: (0.1290) |  Loss2: (0.0000) | Acc: (95.00%) (36818/38528)
Epoch: 148 | Batch_idx: 310 |  Loss: (0.1298) |  Loss2: (0.0000) | Acc: (95.00%) (38021/39808)
Epoch: 148 | Batch_idx: 320 |  Loss: (0.1297) |  Loss2: (0.0000) | Acc: (95.00%) (39244/41088)
Epoch: 148 | Batch_idx: 330 |  Loss: (0.1297) |  Loss2: (0.0000) | Acc: (95.00%) (40471/42368)
Epoch: 148 | Batch_idx: 340 |  Loss: (0.1298) |  Loss2: (0.0000) | Acc: (95.00%) (41696/43648)
Epoch: 148 | Batch_idx: 350 |  Loss: (0.1297) |  Loss2: (0.0000) | Acc: (95.00%) (42919/44928)
Epoch: 148 | Batch_idx: 360 |  Loss: (0.1307) |  Loss2: (0.0000) | Acc: (95.00%) (44131/46208)
Epoch: 148 | Batch_idx: 370 |  Loss: (0.1310) |  Loss2: (0.0000) | Acc: (95.00%) (45354/47488)
Epoch: 148 | Batch_idx: 380 |  Loss: (0.1307) |  Loss2: (0.0000) | Acc: (95.00%) (46577/48768)
Epoch: 148 | Batch_idx: 390 |  Loss: (0.1308) |  Loss2: (0.0000) | Acc: (95.00%) (47750/50000)
# TEST : Loss: (0.3979) | Acc: (88.00%) (8846/10000)
percent tensor([0.5057, 0.5079, 0.5144, 0.5032, 0.5137, 0.5050, 0.5101, 0.5075, 0.5081,
        0.5097, 0.5092, 0.5125, 0.5059, 0.5041, 0.5063, 0.5040],
       device='cuda:0') torch.Size([16])
percent tensor([0.4940, 0.4824, 0.4937, 0.4962, 0.4842, 0.5043, 0.4815, 0.4838, 0.4969,
        0.4885, 0.4985, 0.4895, 0.4830, 0.4966, 0.4861, 0.4962],
       device='cuda:0') torch.Size([16])
percent tensor([0.6435, 0.6266, 0.5729, 0.5539, 0.5919, 0.6090, 0.6448, 0.5823, 0.5871,
        0.5986, 0.6147, 0.5761, 0.6598, 0.5594, 0.6506, 0.6238],
       device='cuda:0') torch.Size([16])
percent tensor([0.6118, 0.6407, 0.5982, 0.6638, 0.6052, 0.7167, 0.6176, 0.5811, 0.6594,
        0.6289, 0.6600, 0.6631, 0.6255, 0.6806, 0.6766, 0.6499],
       device='cuda:0') torch.Size([16])
percent tensor([0.5857, 0.5924, 0.5911, 0.5640, 0.6129, 0.5657, 0.6059, 0.5512, 0.6452,
        0.6187, 0.6274, 0.5149, 0.5711, 0.7139, 0.4872, 0.6317],
       device='cuda:0') torch.Size([16])
percent tensor([0.6199, 0.5905, 0.6878, 0.6951, 0.7230, 0.7204, 0.6373, 0.6680, 0.6573,
        0.6206, 0.6225, 0.6616, 0.6282, 0.6392, 0.6338, 0.6620],
       device='cuda:0') torch.Size([16])
percent tensor([0.6047, 0.7133, 0.7156, 0.6623, 0.7083, 0.5818, 0.5668, 0.6063, 0.6957,
        0.6511, 0.7469, 0.6511, 0.6978, 0.6584, 0.5658, 0.4907],
       device='cuda:0') torch.Size([16])
percent tensor([0.9996, 0.9998, 0.9997, 0.9998, 0.9992, 0.9994, 0.9996, 0.9994, 0.9996,
        0.9997, 1.0000, 0.9997, 0.9998, 0.9994, 0.9987, 0.9994],
       device='cuda:0') torch.Size([16])
Epoch: 149 | Batch_idx: 0 |  Loss: (0.1453) |  Loss2: (0.0000) | Acc: (91.00%) (117/128)
Epoch: 149 | Batch_idx: 10 |  Loss: (0.1185) |  Loss2: (0.0000) | Acc: (95.00%) (1348/1408)
Epoch: 149 | Batch_idx: 20 |  Loss: (0.1292) |  Loss2: (0.0000) | Acc: (95.00%) (2562/2688)
Epoch: 149 | Batch_idx: 30 |  Loss: (0.1283) |  Loss2: (0.0000) | Acc: (95.00%) (3790/3968)
Epoch: 149 | Batch_idx: 40 |  Loss: (0.1278) |  Loss2: (0.0000) | Acc: (95.00%) (5013/5248)
Epoch: 149 | Batch_idx: 50 |  Loss: (0.1286) |  Loss2: (0.0000) | Acc: (95.00%) (6238/6528)
Epoch: 149 | Batch_idx: 60 |  Loss: (0.1273) |  Loss2: (0.0000) | Acc: (95.00%) (7467/7808)
Epoch: 149 | Batch_idx: 70 |  Loss: (0.1278) |  Loss2: (0.0000) | Acc: (95.00%) (8688/9088)
Epoch: 149 | Batch_idx: 80 |  Loss: (0.1275) |  Loss2: (0.0000) | Acc: (95.00%) (9908/10368)
Epoch: 149 | Batch_idx: 90 |  Loss: (0.1269) |  Loss2: (0.0000) | Acc: (95.00%) (11134/11648)
Epoch: 149 | Batch_idx: 100 |  Loss: (0.1263) |  Loss2: (0.0000) | Acc: (95.00%) (12354/12928)
Epoch: 149 | Batch_idx: 110 |  Loss: (0.1257) |  Loss2: (0.0000) | Acc: (95.00%) (13589/14208)
Epoch: 149 | Batch_idx: 120 |  Loss: (0.1256) |  Loss2: (0.0000) | Acc: (95.00%) (14816/15488)
Epoch: 149 | Batch_idx: 130 |  Loss: (0.1256) |  Loss2: (0.0000) | Acc: (95.00%) (16043/16768)
Epoch: 149 | Batch_idx: 140 |  Loss: (0.1256) |  Loss2: (0.0000) | Acc: (95.00%) (17263/18048)
Epoch: 149 | Batch_idx: 150 |  Loss: (0.1262) |  Loss2: (0.0000) | Acc: (95.00%) (18478/19328)
Epoch: 149 | Batch_idx: 160 |  Loss: (0.1255) |  Loss2: (0.0000) | Acc: (95.00%) (19708/20608)
Epoch: 149 | Batch_idx: 170 |  Loss: (0.1257) |  Loss2: (0.0000) | Acc: (95.00%) (20932/21888)
Epoch: 149 | Batch_idx: 180 |  Loss: (0.1265) |  Loss2: (0.0000) | Acc: (95.00%) (22154/23168)
Epoch: 149 | Batch_idx: 190 |  Loss: (0.1259) |  Loss2: (0.0000) | Acc: (95.00%) (23386/24448)
Epoch: 149 | Batch_idx: 200 |  Loss: (0.1260) |  Loss2: (0.0000) | Acc: (95.00%) (24606/25728)
Epoch: 149 | Batch_idx: 210 |  Loss: (0.1250) |  Loss2: (0.0000) | Acc: (95.00%) (25838/27008)
Epoch: 149 | Batch_idx: 220 |  Loss: (0.1242) |  Loss2: (0.0000) | Acc: (95.00%) (27077/28288)
Epoch: 149 | Batch_idx: 230 |  Loss: (0.1241) |  Loss2: (0.0000) | Acc: (95.00%) (28299/29568)
Epoch: 149 | Batch_idx: 240 |  Loss: (0.1237) |  Loss2: (0.0000) | Acc: (95.00%) (29531/30848)
Epoch: 149 | Batch_idx: 250 |  Loss: (0.1238) |  Loss2: (0.0000) | Acc: (95.00%) (30753/32128)
Epoch: 149 | Batch_idx: 260 |  Loss: (0.1234) |  Loss2: (0.0000) | Acc: (95.00%) (31976/33408)
Epoch: 149 | Batch_idx: 270 |  Loss: (0.1233) |  Loss2: (0.0000) | Acc: (95.00%) (33196/34688)
Epoch: 149 | Batch_idx: 280 |  Loss: (0.1230) |  Loss2: (0.0000) | Acc: (95.00%) (34427/35968)
Epoch: 149 | Batch_idx: 290 |  Loss: (0.1237) |  Loss2: (0.0000) | Acc: (95.00%) (35638/37248)
Epoch: 149 | Batch_idx: 300 |  Loss: (0.1236) |  Loss2: (0.0000) | Acc: (95.00%) (36868/38528)
Epoch: 149 | Batch_idx: 310 |  Loss: (0.1238) |  Loss2: (0.0000) | Acc: (95.00%) (38088/39808)
Epoch: 149 | Batch_idx: 320 |  Loss: (0.1236) |  Loss2: (0.0000) | Acc: (95.00%) (39315/41088)
Epoch: 149 | Batch_idx: 330 |  Loss: (0.1247) |  Loss2: (0.0000) | Acc: (95.00%) (40520/42368)
Epoch: 149 | Batch_idx: 340 |  Loss: (0.1250) |  Loss2: (0.0000) | Acc: (95.00%) (41739/43648)
Epoch: 149 | Batch_idx: 350 |  Loss: (0.1252) |  Loss2: (0.0000) | Acc: (95.00%) (42960/44928)
Epoch: 149 | Batch_idx: 360 |  Loss: (0.1259) |  Loss2: (0.0000) | Acc: (95.00%) (44172/46208)
Epoch: 149 | Batch_idx: 370 |  Loss: (0.1261) |  Loss2: (0.0000) | Acc: (95.00%) (45398/47488)
Epoch: 149 | Batch_idx: 380 |  Loss: (0.1265) |  Loss2: (0.0000) | Acc: (95.00%) (46616/48768)
Epoch: 149 | Batch_idx: 390 |  Loss: (0.1273) |  Loss2: (0.0000) | Acc: (95.00%) (47773/50000)
# TEST : Loss: (0.4174) | Acc: (87.00%) (8771/10000)
percent tensor([0.5054, 0.5086, 0.5130, 0.5032, 0.5124, 0.5048, 0.5100, 0.5076, 0.5079,
        0.5096, 0.5096, 0.5114, 0.5060, 0.5051, 0.5066, 0.5044],
       device='cuda:0') torch.Size([16])
percent tensor([0.4941, 0.4813, 0.4949, 0.4946, 0.4865, 0.5051, 0.4820, 0.4827, 0.4959,
        0.4883, 0.4978, 0.4913, 0.4827, 0.4964, 0.4852, 0.4950],
       device='cuda:0') torch.Size([16])
percent tensor([0.6342, 0.6285, 0.5649, 0.5536, 0.5817, 0.5897, 0.6424, 0.5831, 0.5847,
        0.6023, 0.6115, 0.5708, 0.6600, 0.5602, 0.6467, 0.6239],
       device='cuda:0') torch.Size([16])
percent tensor([0.6114, 0.6333, 0.6015, 0.6575, 0.6053, 0.7103, 0.6211, 0.5790, 0.6506,
        0.6291, 0.6571, 0.6703, 0.6249, 0.6797, 0.6685, 0.6449],
       device='cuda:0') torch.Size([16])
percent tensor([0.5928, 0.5909, 0.5848, 0.5702, 0.6166, 0.5825, 0.6094, 0.5519, 0.6259,
        0.6221, 0.6413, 0.5289, 0.5619, 0.7152, 0.4866, 0.6356],
       device='cuda:0') torch.Size([16])
percent tensor([0.6134, 0.5815, 0.6832, 0.7021, 0.7252, 0.7178, 0.6436, 0.6660, 0.6345,
        0.6118, 0.6230, 0.6614, 0.6094, 0.6324, 0.6318, 0.6596],
       device='cuda:0') torch.Size([16])
percent tensor([0.6014, 0.7135, 0.7301, 0.6783, 0.7267, 0.5874, 0.5650, 0.5966, 0.7057,
        0.6810, 0.7620, 0.6872, 0.6923, 0.6495, 0.5590, 0.4867],
       device='cuda:0') torch.Size([16])
percent tensor([0.9996, 0.9998, 0.9998, 0.9999, 0.9997, 0.9995, 0.9995, 0.9994, 0.9998,
        0.9999, 1.0000, 0.9999, 0.9999, 0.9995, 0.9989, 0.9993],
       device='cuda:0') torch.Size([16])
Epoch: 150 | Batch_idx: 0 |  Loss: (0.0924) |  Loss2: (0.0000) | Acc: (96.00%) (124/128)
Epoch: 150 | Batch_idx: 10 |  Loss: (0.1176) |  Loss2: (0.0000) | Acc: (95.00%) (1350/1408)
Epoch: 150 | Batch_idx: 20 |  Loss: (0.1170) |  Loss2: (0.0000) | Acc: (95.00%) (2577/2688)
Epoch: 150 | Batch_idx: 30 |  Loss: (0.1125) |  Loss2: (0.0000) | Acc: (96.00%) (3816/3968)
Epoch: 150 | Batch_idx: 40 |  Loss: (0.1134) |  Loss2: (0.0000) | Acc: (96.00%) (5046/5248)
Epoch: 150 | Batch_idx: 50 |  Loss: (0.1189) |  Loss2: (0.0000) | Acc: (95.00%) (6263/6528)
Epoch: 150 | Batch_idx: 60 |  Loss: (0.1170) |  Loss2: (0.0000) | Acc: (96.00%) (7500/7808)
Epoch: 150 | Batch_idx: 70 |  Loss: (0.1153) |  Loss2: (0.0000) | Acc: (96.00%) (8739/9088)
Epoch: 150 | Batch_idx: 80 |  Loss: (0.1151) |  Loss2: (0.0000) | Acc: (96.00%) (9961/10368)
Epoch: 150 | Batch_idx: 90 |  Loss: (0.1146) |  Loss2: (0.0000) | Acc: (96.00%) (11195/11648)
Epoch: 150 | Batch_idx: 100 |  Loss: (0.1156) |  Loss2: (0.0000) | Acc: (96.00%) (12411/12928)
Epoch: 150 | Batch_idx: 110 |  Loss: (0.1167) |  Loss2: (0.0000) | Acc: (95.00%) (13633/14208)
Epoch: 150 | Batch_idx: 120 |  Loss: (0.1169) |  Loss2: (0.0000) | Acc: (95.00%) (14855/15488)
Epoch: 150 | Batch_idx: 130 |  Loss: (0.1173) |  Loss2: (0.0000) | Acc: (95.00%) (16077/16768)
Epoch: 150 | Batch_idx: 140 |  Loss: (0.1178) |  Loss2: (0.0000) | Acc: (95.00%) (17305/18048)
Epoch: 150 | Batch_idx: 150 |  Loss: (0.1183) |  Loss2: (0.0000) | Acc: (95.00%) (18529/19328)
Epoch: 150 | Batch_idx: 160 |  Loss: (0.1183) |  Loss2: (0.0000) | Acc: (95.00%) (19758/20608)
Epoch: 150 | Batch_idx: 170 |  Loss: (0.1183) |  Loss2: (0.0000) | Acc: (95.00%) (20980/21888)
Epoch: 150 | Batch_idx: 180 |  Loss: (0.1192) |  Loss2: (0.0000) | Acc: (95.00%) (22197/23168)
Epoch: 150 | Batch_idx: 190 |  Loss: (0.1178) |  Loss2: (0.0000) | Acc: (95.00%) (23435/24448)
Epoch: 150 | Batch_idx: 200 |  Loss: (0.1183) |  Loss2: (0.0000) | Acc: (95.00%) (24659/25728)
Epoch: 150 | Batch_idx: 210 |  Loss: (0.1188) |  Loss2: (0.0000) | Acc: (95.00%) (25886/27008)
Epoch: 150 | Batch_idx: 220 |  Loss: (0.1195) |  Loss2: (0.0000) | Acc: (95.00%) (27104/28288)
Epoch: 150 | Batch_idx: 230 |  Loss: (0.1211) |  Loss2: (0.0000) | Acc: (95.00%) (28314/29568)
Epoch: 150 | Batch_idx: 240 |  Loss: (0.1212) |  Loss2: (0.0000) | Acc: (95.00%) (29535/30848)
Epoch: 150 | Batch_idx: 250 |  Loss: (0.1199) |  Loss2: (0.0000) | Acc: (95.00%) (30779/32128)
Epoch: 150 | Batch_idx: 260 |  Loss: (0.1204) |  Loss2: (0.0000) | Acc: (95.00%) (32000/33408)
Epoch: 150 | Batch_idx: 270 |  Loss: (0.1202) |  Loss2: (0.0000) | Acc: (95.00%) (33232/34688)
Epoch: 150 | Batch_idx: 280 |  Loss: (0.1202) |  Loss2: (0.0000) | Acc: (95.00%) (34454/35968)
Epoch: 150 | Batch_idx: 290 |  Loss: (0.1203) |  Loss2: (0.0000) | Acc: (95.00%) (35680/37248)
Epoch: 150 | Batch_idx: 300 |  Loss: (0.1209) |  Loss2: (0.0000) | Acc: (95.00%) (36899/38528)
Epoch: 150 | Batch_idx: 310 |  Loss: (0.1209) |  Loss2: (0.0000) | Acc: (95.00%) (38124/39808)
Epoch: 150 | Batch_idx: 320 |  Loss: (0.1209) |  Loss2: (0.0000) | Acc: (95.00%) (39355/41088)
Epoch: 150 | Batch_idx: 330 |  Loss: (0.1212) |  Loss2: (0.0000) | Acc: (95.00%) (40578/42368)
Epoch: 150 | Batch_idx: 340 |  Loss: (0.1210) |  Loss2: (0.0000) | Acc: (95.00%) (41813/43648)
Epoch: 150 | Batch_idx: 350 |  Loss: (0.1209) |  Loss2: (0.0000) | Acc: (95.00%) (43040/44928)
Epoch: 150 | Batch_idx: 360 |  Loss: (0.1213) |  Loss2: (0.0000) | Acc: (95.00%) (44261/46208)
Epoch: 150 | Batch_idx: 370 |  Loss: (0.1222) |  Loss2: (0.0000) | Acc: (95.00%) (45462/47488)
Epoch: 150 | Batch_idx: 380 |  Loss: (0.1226) |  Loss2: (0.0000) | Acc: (95.00%) (46676/48768)
Epoch: 150 | Batch_idx: 390 |  Loss: (0.1223) |  Loss2: (0.0000) | Acc: (95.00%) (47866/50000)
=> saving checkpoint 'drive/app/torch/save_Schedule/checkpoint_150.pth.tar'
# TEST : Loss: (0.4165) | Acc: (87.00%) (8784/10000)
percent tensor([0.5057, 0.5084, 0.5135, 0.5031, 0.5129, 0.5051, 0.5102, 0.5075, 0.5081,
        0.5100, 0.5095, 0.5118, 0.5061, 0.5046, 0.5067, 0.5045],
       device='cuda:0') torch.Size([16])
percent tensor([0.4955, 0.4819, 0.4938, 0.4967, 0.4864, 0.5054, 0.4820, 0.4825, 0.4972,
        0.4883, 0.4988, 0.4908, 0.4839, 0.4943, 0.4866, 0.4955],
       device='cuda:0') torch.Size([16])
percent tensor([0.6363, 0.6259, 0.5669, 0.5467, 0.5837, 0.6051, 0.6408, 0.5841, 0.5796,
        0.5974, 0.6119, 0.5702, 0.6579, 0.5620, 0.6514, 0.6226],
       device='cuda:0') torch.Size([16])
percent tensor([0.6090, 0.6423, 0.5941, 0.6638, 0.6050, 0.7084, 0.6198, 0.5710, 0.6480,
        0.6320, 0.6498, 0.6719, 0.6256, 0.6783, 0.6660, 0.6418],
       device='cuda:0') torch.Size([16])
percent tensor([0.5993, 0.6050, 0.5858, 0.5663, 0.6156, 0.5782, 0.6102, 0.5523, 0.6516,
        0.6440, 0.6566, 0.5307, 0.5902, 0.7104, 0.4991, 0.6368],
       device='cuda:0') torch.Size([16])
percent tensor([0.6145, 0.5861, 0.6839, 0.6924, 0.7200, 0.7226, 0.6404, 0.6621, 0.6406,
        0.6259, 0.6270, 0.6625, 0.6177, 0.6341, 0.6276, 0.6599],
       device='cuda:0') torch.Size([16])
percent tensor([0.5784, 0.7228, 0.7122, 0.6719, 0.6824, 0.5577, 0.5712, 0.5820, 0.7054,
        0.6649, 0.7635, 0.6726, 0.6754, 0.6649, 0.5632, 0.4839],
       device='cuda:0') torch.Size([16])
percent tensor([0.9994, 0.9999, 0.9998, 0.9998, 0.9994, 0.9995, 0.9994, 0.9991, 0.9997,
        0.9999, 1.0000, 0.9998, 0.9998, 0.9996, 0.9988, 0.9993],
       device='cuda:0') torch.Size([16])
Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 3, 3, 3]) tensor(191.1553, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(823.4994, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(828.0933, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([128, 64, 3, 3]) tensor(1530.7118, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([128, 64, 1, 1]) tensor(484.0552, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([128, 128, 3, 3]) tensor(2306.2151, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([256, 128, 3, 3]) tensor(4277.6431, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([256, 128, 1, 1]) tensor(1368.0983, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([256, 256, 3, 3]) tensor(6223.1006, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([512, 256, 3, 3]) tensor(11697.1992, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([512, 256, 1, 1]) tensor(3865.4971, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([512, 512, 3, 3]) tensor(16316.5537, device='cuda:0', grad_fn=<NormBackward0>)
Epoch: 151 | Batch_idx: 0 |  Loss: (0.1296) |  Loss2: (0.0000) | Acc: (96.00%) (123/128)
Epoch: 151 | Batch_idx: 10 |  Loss: (0.1158) |  Loss2: (0.0000) | Acc: (96.00%) (1360/1408)
Epoch: 151 | Batch_idx: 20 |  Loss: (0.1132) |  Loss2: (0.0000) | Acc: (96.00%) (2590/2688)
Epoch: 151 | Batch_idx: 30 |  Loss: (0.1123) |  Loss2: (0.0000) | Acc: (96.00%) (3827/3968)
Epoch: 151 | Batch_idx: 40 |  Loss: (0.1160) |  Loss2: (0.0000) | Acc: (96.00%) (5052/5248)
Epoch: 151 | Batch_idx: 50 |  Loss: (0.1136) |  Loss2: (0.0000) | Acc: (96.00%) (6290/6528)
Epoch: 151 | Batch_idx: 60 |  Loss: (0.1168) |  Loss2: (0.0000) | Acc: (96.00%) (7507/7808)
Epoch: 151 | Batch_idx: 70 |  Loss: (0.1167) |  Loss2: (0.0000) | Acc: (96.00%) (8732/9088)
Epoch: 151 | Batch_idx: 80 |  Loss: (0.1172) |  Loss2: (0.0000) | Acc: (95.00%) (9952/10368)
Epoch: 151 | Batch_idx: 90 |  Loss: (0.1173) |  Loss2: (0.0000) | Acc: (95.00%) (11177/11648)
Epoch: 151 | Batch_idx: 100 |  Loss: (0.1173) |  Loss2: (0.0000) | Acc: (95.00%) (12404/12928)
Epoch: 151 | Batch_idx: 110 |  Loss: (0.1167) |  Loss2: (0.0000) | Acc: (95.00%) (13633/14208)
Epoch: 151 | Batch_idx: 120 |  Loss: (0.1154) |  Loss2: (0.0000) | Acc: (96.00%) (14870/15488)
Epoch: 151 | Batch_idx: 130 |  Loss: (0.1142) |  Loss2: (0.0000) | Acc: (96.00%) (16110/16768)
Epoch: 151 | Batch_idx: 140 |  Loss: (0.1136) |  Loss2: (0.0000) | Acc: (96.00%) (17341/18048)
Epoch: 151 | Batch_idx: 150 |  Loss: (0.1136) |  Loss2: (0.0000) | Acc: (96.00%) (18573/19328)
Epoch: 151 | Batch_idx: 160 |  Loss: (0.1147) |  Loss2: (0.0000) | Acc: (96.00%) (19792/20608)
Epoch: 151 | Batch_idx: 170 |  Loss: (0.1144) |  Loss2: (0.0000) | Acc: (96.00%) (21022/21888)
Epoch: 151 | Batch_idx: 180 |  Loss: (0.1149) |  Loss2: (0.0000) | Acc: (96.00%) (22254/23168)
Epoch: 151 | Batch_idx: 190 |  Loss: (0.1160) |  Loss2: (0.0000) | Acc: (96.00%) (23473/24448)
Epoch: 151 | Batch_idx: 200 |  Loss: (0.1167) |  Loss2: (0.0000) | Acc: (96.00%) (24699/25728)
Epoch: 151 | Batch_idx: 210 |  Loss: (0.1173) |  Loss2: (0.0000) | Acc: (95.00%) (25921/27008)
Epoch: 151 | Batch_idx: 220 |  Loss: (0.1165) |  Loss2: (0.0000) | Acc: (96.00%) (27158/28288)
Epoch: 151 | Batch_idx: 230 |  Loss: (0.1163) |  Loss2: (0.0000) | Acc: (96.00%) (28394/29568)
Epoch: 151 | Batch_idx: 240 |  Loss: (0.1167) |  Loss2: (0.0000) | Acc: (96.00%) (29618/30848)
Epoch: 151 | Batch_idx: 250 |  Loss: (0.1172) |  Loss2: (0.0000) | Acc: (95.00%) (30836/32128)
Epoch: 151 | Batch_idx: 260 |  Loss: (0.1173) |  Loss2: (0.0000) | Acc: (95.00%) (32059/33408)
Epoch: 151 | Batch_idx: 270 |  Loss: (0.1178) |  Loss2: (0.0000) | Acc: (95.00%) (33278/34688)
Epoch: 151 | Batch_idx: 280 |  Loss: (0.1178) |  Loss2: (0.0000) | Acc: (95.00%) (34504/35968)
Epoch: 151 | Batch_idx: 290 |  Loss: (0.1178) |  Loss2: (0.0000) | Acc: (95.00%) (35736/37248)
Epoch: 151 | Batch_idx: 300 |  Loss: (0.1180) |  Loss2: (0.0000) | Acc: (95.00%) (36958/38528)
Epoch: 151 | Batch_idx: 310 |  Loss: (0.1182) |  Loss2: (0.0000) | Acc: (95.00%) (38180/39808)
Epoch: 151 | Batch_idx: 320 |  Loss: (0.1185) |  Loss2: (0.0000) | Acc: (95.00%) (39408/41088)
Epoch: 151 | Batch_idx: 330 |  Loss: (0.1186) |  Loss2: (0.0000) | Acc: (95.00%) (40638/42368)
Epoch: 151 | Batch_idx: 340 |  Loss: (0.1189) |  Loss2: (0.0000) | Acc: (95.00%) (41862/43648)
Epoch: 151 | Batch_idx: 350 |  Loss: (0.1193) |  Loss2: (0.0000) | Acc: (95.00%) (43078/44928)
Epoch: 151 | Batch_idx: 360 |  Loss: (0.1196) |  Loss2: (0.0000) | Acc: (95.00%) (44297/46208)
Epoch: 151 | Batch_idx: 370 |  Loss: (0.1204) |  Loss2: (0.0000) | Acc: (95.00%) (45509/47488)
Epoch: 151 | Batch_idx: 380 |  Loss: (0.1208) |  Loss2: (0.0000) | Acc: (95.00%) (46732/48768)
Epoch: 151 | Batch_idx: 390 |  Loss: (0.1202) |  Loss2: (0.0000) | Acc: (95.00%) (47924/50000)
# TEST : Loss: (0.4027) | Acc: (88.00%) (8823/10000)
percent tensor([0.5061, 0.5079, 0.5152, 0.5039, 0.5145, 0.5054, 0.5104, 0.5081, 0.5084,
        0.5101, 0.5096, 0.5132, 0.5065, 0.5035, 0.5067, 0.5045],
       device='cuda:0') torch.Size([16])
percent tensor([0.4942, 0.4822, 0.4939, 0.4970, 0.4838, 0.5040, 0.4814, 0.4824, 0.4977,
        0.4894, 0.5003, 0.4890, 0.4840, 0.4979, 0.4854, 0.4962],
       device='cuda:0') torch.Size([16])
percent tensor([0.6326, 0.6315, 0.5632, 0.5518, 0.5859, 0.6068, 0.6436, 0.5854, 0.5748,
        0.5968, 0.6047, 0.5690, 0.6501, 0.5613, 0.6529, 0.6220],
       device='cuda:0') torch.Size([16])
percent tensor([0.6054, 0.6317, 0.6027, 0.6514, 0.6008, 0.7131, 0.6068, 0.5738, 0.6533,
        0.6240, 0.6499, 0.6594, 0.6203, 0.6698, 0.6631, 0.6450],
       device='cuda:0') torch.Size([16])
percent tensor([0.5954, 0.5970, 0.5952, 0.5780, 0.6248, 0.5708, 0.6158, 0.5522, 0.6515,
        0.6334, 0.6496, 0.5244, 0.5880, 0.7182, 0.4860, 0.6333],
       device='cuda:0') torch.Size([16])
percent tensor([0.6014, 0.5804, 0.6803, 0.6906, 0.7229, 0.7278, 0.6426, 0.6603, 0.6509,
        0.6181, 0.6227, 0.6616, 0.6050, 0.6399, 0.6271, 0.6614],
       device='cuda:0') torch.Size([16])
percent tensor([0.5865, 0.7080, 0.7195, 0.6799, 0.7119, 0.5684, 0.5628, 0.5865, 0.7064,
        0.6504, 0.7472, 0.6773, 0.6822, 0.6474, 0.5479, 0.5030],
       device='cuda:0') torch.Size([16])
percent tensor([0.9996, 0.9998, 0.9997, 0.9999, 0.9997, 0.9994, 0.9996, 0.9992, 0.9997,
        0.9998, 1.0000, 0.9998, 0.9999, 0.9993, 0.9988, 0.9993],
       device='cuda:0') torch.Size([16])
False Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=128, out_features=16, bias=False)
True Linear(in_features=16, out_features=2, bias=False)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=128, out_features=16, bias=False)
True Linear(in_features=16, out_features=2, bias=False)
False Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=256, out_features=32, bias=False)
True Linear(in_features=32, out_features=2, bias=False)
False Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=256, out_features=32, bias=False)
True Linear(in_features=32, out_features=2, bias=False)
False Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=512, out_features=64, bias=False)
True Linear(in_features=64, out_features=2, bias=False)
False Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=512, out_features=64, bias=False)
True Linear(in_features=64, out_features=2, bias=False)
False Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1024, out_features=128, bias=False)
True Linear(in_features=128, out_features=2, bias=False)
False Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1024, out_features=128, bias=False)
True Linear(in_features=128, out_features=2, bias=False)
False Linear(in_features=512, out_features=10, bias=True)
Epoch: 152 | Batch_idx: 0 |  Loss: (0.1546) |  Loss2: (0.0000) | Acc: (92.00%) (119/128)
Epoch: 152 | Batch_idx: 10 |  Loss: (0.1299) |  Loss2: (0.0000) | Acc: (95.00%) (1346/1408)
Epoch: 152 | Batch_idx: 20 |  Loss: (0.1252) |  Loss2: (0.0000) | Acc: (95.00%) (2576/2688)
Epoch: 152 | Batch_idx: 30 |  Loss: (0.1288) |  Loss2: (0.0000) | Acc: (95.00%) (3791/3968)
Epoch: 152 | Batch_idx: 40 |  Loss: (0.1288) |  Loss2: (0.0000) | Acc: (95.00%) (5015/5248)
Epoch: 152 | Batch_idx: 50 |  Loss: (0.1359) |  Loss2: (0.0000) | Acc: (95.00%) (6224/6528)
Epoch: 152 | Batch_idx: 60 |  Loss: (0.1358) |  Loss2: (0.0000) | Acc: (95.00%) (7444/7808)
Epoch: 152 | Batch_idx: 70 |  Loss: (0.1382) |  Loss2: (0.0000) | Acc: (95.00%) (8659/9088)
Epoch: 152 | Batch_idx: 80 |  Loss: (0.1427) |  Loss2: (0.0000) | Acc: (95.00%) (9859/10368)
Epoch: 152 | Batch_idx: 90 |  Loss: (0.1412) |  Loss2: (0.0000) | Acc: (95.00%) (11081/11648)
Epoch: 152 | Batch_idx: 100 |  Loss: (0.1404) |  Loss2: (0.0000) | Acc: (95.00%) (12301/12928)
Epoch: 152 | Batch_idx: 110 |  Loss: (0.1408) |  Loss2: (0.0000) | Acc: (95.00%) (13514/14208)
Epoch: 152 | Batch_idx: 120 |  Loss: (0.1414) |  Loss2: (0.0000) | Acc: (95.00%) (14719/15488)
Epoch: 152 | Batch_idx: 130 |  Loss: (0.1419) |  Loss2: (0.0000) | Acc: (95.00%) (15936/16768)
Epoch: 152 | Batch_idx: 140 |  Loss: (0.1423) |  Loss2: (0.0000) | Acc: (94.00%) (17143/18048)
Epoch: 152 | Batch_idx: 150 |  Loss: (0.1432) |  Loss2: (0.0000) | Acc: (95.00%) (18364/19328)
Epoch: 152 | Batch_idx: 160 |  Loss: (0.1417) |  Loss2: (0.0000) | Acc: (95.00%) (19595/20608)
Epoch: 152 | Batch_idx: 170 |  Loss: (0.1413) |  Loss2: (0.0000) | Acc: (95.00%) (20819/21888)
Epoch: 152 | Batch_idx: 180 |  Loss: (0.1417) |  Loss2: (0.0000) | Acc: (95.00%) (22027/23168)
Epoch: 152 | Batch_idx: 190 |  Loss: (0.1414) |  Loss2: (0.0000) | Acc: (95.00%) (23246/24448)
Epoch: 152 | Batch_idx: 200 |  Loss: (0.1418) |  Loss2: (0.0000) | Acc: (95.00%) (24458/25728)
Epoch: 152 | Batch_idx: 210 |  Loss: (0.1416) |  Loss2: (0.0000) | Acc: (95.00%) (25679/27008)
Epoch: 152 | Batch_idx: 220 |  Loss: (0.1406) |  Loss2: (0.0000) | Acc: (95.00%) (26902/28288)
Epoch: 152 | Batch_idx: 230 |  Loss: (0.1409) |  Loss2: (0.0000) | Acc: (95.00%) (28112/29568)
Epoch: 152 | Batch_idx: 240 |  Loss: (0.1408) |  Loss2: (0.0000) | Acc: (95.00%) (29333/30848)
Epoch: 152 | Batch_idx: 250 |  Loss: (0.1406) |  Loss2: (0.0000) | Acc: (95.00%) (30560/32128)
Epoch: 152 | Batch_idx: 260 |  Loss: (0.1396) |  Loss2: (0.0000) | Acc: (95.00%) (31787/33408)
Epoch: 152 | Batch_idx: 270 |  Loss: (0.1388) |  Loss2: (0.0000) | Acc: (95.00%) (33014/34688)
Epoch: 152 | Batch_idx: 280 |  Loss: (0.1388) |  Loss2: (0.0000) | Acc: (95.00%) (34232/35968)
Epoch: 152 | Batch_idx: 290 |  Loss: (0.1383) |  Loss2: (0.0000) | Acc: (95.00%) (35464/37248)
Epoch: 152 | Batch_idx: 300 |  Loss: (0.1390) |  Loss2: (0.0000) | Acc: (95.00%) (36673/38528)
Epoch: 152 | Batch_idx: 310 |  Loss: (0.1387) |  Loss2: (0.0000) | Acc: (95.00%) (37892/39808)
Epoch: 152 | Batch_idx: 320 |  Loss: (0.1385) |  Loss2: (0.0000) | Acc: (95.00%) (39113/41088)
Epoch: 152 | Batch_idx: 330 |  Loss: (0.1384) |  Loss2: (0.0000) | Acc: (95.00%) (40331/42368)
Epoch: 152 | Batch_idx: 340 |  Loss: (0.1386) |  Loss2: (0.0000) | Acc: (95.00%) (41543/43648)
Epoch: 152 | Batch_idx: 350 |  Loss: (0.1386) |  Loss2: (0.0000) | Acc: (95.00%) (42761/44928)
Epoch: 152 | Batch_idx: 360 |  Loss: (0.1382) |  Loss2: (0.0000) | Acc: (95.00%) (43996/46208)
Epoch: 152 | Batch_idx: 370 |  Loss: (0.1377) |  Loss2: (0.0000) | Acc: (95.00%) (45222/47488)
Epoch: 152 | Batch_idx: 380 |  Loss: (0.1379) |  Loss2: (0.0000) | Acc: (95.00%) (46439/48768)
Epoch: 152 | Batch_idx: 390 |  Loss: (0.1382) |  Loss2: (0.0000) | Acc: (95.00%) (47601/50000)
# TEST : Loss: (0.4131) | Acc: (87.00%) (8784/10000)
percent tensor([0.5009, 0.5017, 0.5119, 0.4991, 0.5104, 0.5004, 0.5047, 0.5027, 0.5024,
        0.5048, 0.5033, 0.5094, 0.5006, 0.4968, 0.5010, 0.4989],
       device='cuda:0') torch.Size([16])
percent tensor([0.5026, 0.4890, 0.4986, 0.5047, 0.4896, 0.5086, 0.4883, 0.4917, 0.5045,
        0.4946, 0.5071, 0.4930, 0.4909, 0.5034, 0.4930, 0.5040],
       device='cuda:0') torch.Size([16])
percent tensor([0.6510, 0.6328, 0.5831, 0.5427, 0.6014, 0.6162, 0.6600, 0.5786, 0.5738,
        0.6067, 0.6101, 0.5888, 0.6721, 0.5487, 0.6656, 0.6311],
       device='cuda:0') torch.Size([16])
percent tensor([0.6270, 0.6510, 0.6115, 0.6638, 0.6220, 0.7304, 0.6241, 0.5926, 0.6720,
        0.6402, 0.6689, 0.6629, 0.6405, 0.6848, 0.6901, 0.6688],
       device='cuda:0') torch.Size([16])
percent tensor([0.6178, 0.6156, 0.6083, 0.5850, 0.6352, 0.5827, 0.6382, 0.5705, 0.6718,
        0.6544, 0.6623, 0.5187, 0.6127, 0.7315, 0.5021, 0.6486],
       device='cuda:0') torch.Size([16])
percent tensor([0.6035, 0.5844, 0.7020, 0.6915, 0.7335, 0.7347, 0.6489, 0.6637, 0.6548,
        0.6254, 0.6200, 0.6668, 0.6081, 0.6364, 0.6378, 0.6607],
       device='cuda:0') torch.Size([16])
percent tensor([0.5711, 0.6958, 0.7260, 0.6753, 0.7027, 0.5626, 0.5519, 0.5797, 0.7065,
        0.6451, 0.7290, 0.6918, 0.6690, 0.6424, 0.5396, 0.4775],
       device='cuda:0') torch.Size([16])
percent tensor([0.9997, 0.9998, 0.9998, 0.9999, 0.9997, 0.9996, 0.9996, 0.9991, 0.9997,
        0.9998, 1.0000, 0.9998, 0.9999, 0.9992, 0.9987, 0.9994],
       device='cuda:0') torch.Size([16])
Epoch: 153 | Batch_idx: 0 |  Loss: (0.0869) |  Loss2: (0.0000) | Acc: (96.00%) (124/128)
Epoch: 153 | Batch_idx: 10 |  Loss: (0.1454) |  Loss2: (0.0000) | Acc: (94.00%) (1333/1408)
Epoch: 153 | Batch_idx: 20 |  Loss: (0.1334) |  Loss2: (0.0000) | Acc: (95.00%) (2557/2688)
Epoch: 153 | Batch_idx: 30 |  Loss: (0.1318) |  Loss2: (0.0000) | Acc: (95.00%) (3786/3968)
Epoch: 153 | Batch_idx: 40 |  Loss: (0.1344) |  Loss2: (0.0000) | Acc: (95.00%) (5011/5248)
Epoch: 153 | Batch_idx: 50 |  Loss: (0.1318) |  Loss2: (0.0000) | Acc: (95.00%) (6242/6528)
Epoch: 153 | Batch_idx: 60 |  Loss: (0.1307) |  Loss2: (0.0000) | Acc: (95.00%) (7468/7808)
Epoch: 153 | Batch_idx: 70 |  Loss: (0.1313) |  Loss2: (0.0000) | Acc: (95.00%) (8693/9088)
Epoch: 153 | Batch_idx: 80 |  Loss: (0.1301) |  Loss2: (0.0000) | Acc: (95.00%) (9920/10368)
Epoch: 153 | Batch_idx: 90 |  Loss: (0.1283) |  Loss2: (0.0000) | Acc: (95.00%) (11152/11648)
Epoch: 153 | Batch_idx: 100 |  Loss: (0.1278) |  Loss2: (0.0000) | Acc: (95.00%) (12378/12928)
Epoch: 153 | Batch_idx: 110 |  Loss: (0.1280) |  Loss2: (0.0000) | Acc: (95.00%) (13593/14208)
Epoch: 153 | Batch_idx: 120 |  Loss: (0.1286) |  Loss2: (0.0000) | Acc: (95.00%) (14811/15488)
Epoch: 153 | Batch_idx: 130 |  Loss: (0.1298) |  Loss2: (0.0000) | Acc: (95.00%) (16016/16768)
Epoch: 153 | Batch_idx: 140 |  Loss: (0.1284) |  Loss2: (0.0000) | Acc: (95.00%) (17251/18048)
Epoch: 153 | Batch_idx: 150 |  Loss: (0.1298) |  Loss2: (0.0000) | Acc: (95.00%) (18460/19328)
Epoch: 153 | Batch_idx: 160 |  Loss: (0.1293) |  Loss2: (0.0000) | Acc: (95.00%) (19689/20608)
Epoch: 153 | Batch_idx: 170 |  Loss: (0.1284) |  Loss2: (0.0000) | Acc: (95.00%) (20923/21888)
Epoch: 153 | Batch_idx: 180 |  Loss: (0.1286) |  Loss2: (0.0000) | Acc: (95.00%) (22148/23168)
Epoch: 153 | Batch_idx: 190 |  Loss: (0.1288) |  Loss2: (0.0000) | Acc: (95.00%) (23367/24448)
Epoch: 153 | Batch_idx: 200 |  Loss: (0.1287) |  Loss2: (0.0000) | Acc: (95.00%) (24593/25728)
Epoch: 153 | Batch_idx: 210 |  Loss: (0.1282) |  Loss2: (0.0000) | Acc: (95.00%) (25824/27008)
Epoch: 153 | Batch_idx: 220 |  Loss: (0.1292) |  Loss2: (0.0000) | Acc: (95.00%) (27033/28288)
Epoch: 153 | Batch_idx: 230 |  Loss: (0.1286) |  Loss2: (0.0000) | Acc: (95.00%) (28267/29568)
Epoch: 153 | Batch_idx: 240 |  Loss: (0.1285) |  Loss2: (0.0000) | Acc: (95.00%) (29481/30848)
Epoch: 153 | Batch_idx: 250 |  Loss: (0.1276) |  Loss2: (0.0000) | Acc: (95.00%) (30721/32128)
Epoch: 153 | Batch_idx: 260 |  Loss: (0.1278) |  Loss2: (0.0000) | Acc: (95.00%) (31932/33408)
Epoch: 153 | Batch_idx: 270 |  Loss: (0.1278) |  Loss2: (0.0000) | Acc: (95.00%) (33162/34688)
Epoch: 153 | Batch_idx: 280 |  Loss: (0.1274) |  Loss2: (0.0000) | Acc: (95.00%) (34390/35968)
Epoch: 153 | Batch_idx: 290 |  Loss: (0.1268) |  Loss2: (0.0000) | Acc: (95.00%) (35622/37248)
Epoch: 153 | Batch_idx: 300 |  Loss: (0.1261) |  Loss2: (0.0000) | Acc: (95.00%) (36852/38528)
Epoch: 153 | Batch_idx: 310 |  Loss: (0.1263) |  Loss2: (0.0000) | Acc: (95.00%) (38067/39808)
Epoch: 153 | Batch_idx: 320 |  Loss: (0.1262) |  Loss2: (0.0000) | Acc: (95.00%) (39295/41088)
Epoch: 153 | Batch_idx: 330 |  Loss: (0.1262) |  Loss2: (0.0000) | Acc: (95.00%) (40519/42368)
Epoch: 153 | Batch_idx: 340 |  Loss: (0.1259) |  Loss2: (0.0000) | Acc: (95.00%) (41749/43648)
Epoch: 153 | Batch_idx: 350 |  Loss: (0.1259) |  Loss2: (0.0000) | Acc: (95.00%) (42966/44928)
Epoch: 153 | Batch_idx: 360 |  Loss: (0.1256) |  Loss2: (0.0000) | Acc: (95.00%) (44194/46208)
Epoch: 153 | Batch_idx: 370 |  Loss: (0.1254) |  Loss2: (0.0000) | Acc: (95.00%) (45418/47488)
Epoch: 153 | Batch_idx: 380 |  Loss: (0.1259) |  Loss2: (0.0000) | Acc: (95.00%) (46629/48768)
Epoch: 153 | Batch_idx: 390 |  Loss: (0.1254) |  Loss2: (0.0000) | Acc: (95.00%) (47818/50000)
# TEST : Loss: (0.4028) | Acc: (88.00%) (8827/10000)
percent tensor([0.5004, 0.5009, 0.5126, 0.4989, 0.5109, 0.4998, 0.5044, 0.5025, 0.5018,
        0.5046, 0.5025, 0.5099, 0.5000, 0.4956, 0.5005, 0.4981],
       device='cuda:0') torch.Size([16])
percent tensor([0.5031, 0.4873, 0.5001, 0.5059, 0.4911, 0.5098, 0.4877, 0.4921, 0.5047,
        0.4934, 0.5067, 0.4939, 0.4903, 0.5020, 0.4927, 0.5039],
       device='cuda:0') torch.Size([16])
percent tensor([0.6544, 0.6348, 0.5822, 0.5395, 0.6009, 0.6145, 0.6661, 0.5810, 0.5777,
        0.6068, 0.6129, 0.5870, 0.6768, 0.5542, 0.6687, 0.6342],
       device='cuda:0') torch.Size([16])
percent tensor([0.6168, 0.6401, 0.6049, 0.6581, 0.6171, 0.7246, 0.6168, 0.5854, 0.6615,
        0.6296, 0.6584, 0.6543, 0.6276, 0.6750, 0.6827, 0.6596],
       device='cuda:0') torch.Size([16])
percent tensor([0.6215, 0.6142, 0.6137, 0.5864, 0.6383, 0.5903, 0.6377, 0.5718, 0.6731,
        0.6538, 0.6631, 0.5153, 0.6129, 0.7310, 0.5007, 0.6508],
       device='cuda:0') torch.Size([16])
percent tensor([0.6021, 0.5829, 0.7004, 0.6917, 0.7349, 0.7344, 0.6484, 0.6668, 0.6478,
        0.6231, 0.6161, 0.6666, 0.6065, 0.6307, 0.6400, 0.6610],
       device='cuda:0') torch.Size([16])
percent tensor([0.5622, 0.6959, 0.7204, 0.6700, 0.6934, 0.5666, 0.5416, 0.5796, 0.7034,
        0.6406, 0.7197, 0.6848, 0.6710, 0.6312, 0.5410, 0.4748],
       device='cuda:0') torch.Size([16])
percent tensor([0.9996, 0.9998, 0.9998, 0.9999, 0.9997, 0.9996, 0.9996, 0.9992, 0.9998,
        0.9998, 0.9999, 0.9998, 0.9998, 0.9991, 0.9986, 0.9993],
       device='cuda:0') torch.Size([16])
Epoch: 154 | Batch_idx: 0 |  Loss: (0.1511) |  Loss2: (0.0000) | Acc: (93.00%) (120/128)
Epoch: 154 | Batch_idx: 10 |  Loss: (0.1260) |  Loss2: (0.0000) | Acc: (95.00%) (1345/1408)
Epoch: 154 | Batch_idx: 20 |  Loss: (0.1296) |  Loss2: (0.0000) | Acc: (95.00%) (2565/2688)
Epoch: 154 | Batch_idx: 30 |  Loss: (0.1247) |  Loss2: (0.0000) | Acc: (95.00%) (3792/3968)
Epoch: 154 | Batch_idx: 40 |  Loss: (0.1297) |  Loss2: (0.0000) | Acc: (95.00%) (5012/5248)
Epoch: 154 | Batch_idx: 50 |  Loss: (0.1275) |  Loss2: (0.0000) | Acc: (95.00%) (6244/6528)
Epoch: 154 | Batch_idx: 60 |  Loss: (0.1273) |  Loss2: (0.0000) | Acc: (95.00%) (7472/7808)
Epoch: 154 | Batch_idx: 70 |  Loss: (0.1253) |  Loss2: (0.0000) | Acc: (95.00%) (8699/9088)
Epoch: 154 | Batch_idx: 80 |  Loss: (0.1264) |  Loss2: (0.0000) | Acc: (95.00%) (9920/10368)
Epoch: 154 | Batch_idx: 90 |  Loss: (0.1264) |  Loss2: (0.0000) | Acc: (95.00%) (11147/11648)
Epoch: 154 | Batch_idx: 100 |  Loss: (0.1273) |  Loss2: (0.0000) | Acc: (95.00%) (12366/12928)
Epoch: 154 | Batch_idx: 110 |  Loss: (0.1251) |  Loss2: (0.0000) | Acc: (95.00%) (13598/14208)
Epoch: 154 | Batch_idx: 120 |  Loss: (0.1232) |  Loss2: (0.0000) | Acc: (95.00%) (14838/15488)
Epoch: 154 | Batch_idx: 130 |  Loss: (0.1250) |  Loss2: (0.0000) | Acc: (95.00%) (16050/16768)
Epoch: 154 | Batch_idx: 140 |  Loss: (0.1235) |  Loss2: (0.0000) | Acc: (95.00%) (17287/18048)
Epoch: 154 | Batch_idx: 150 |  Loss: (0.1230) |  Loss2: (0.0000) | Acc: (95.00%) (18515/19328)
Epoch: 154 | Batch_idx: 160 |  Loss: (0.1219) |  Loss2: (0.0000) | Acc: (95.00%) (19752/20608)
Epoch: 154 | Batch_idx: 170 |  Loss: (0.1216) |  Loss2: (0.0000) | Acc: (95.00%) (20984/21888)
Epoch: 154 | Batch_idx: 180 |  Loss: (0.1217) |  Loss2: (0.0000) | Acc: (95.00%) (22205/23168)
Epoch: 154 | Batch_idx: 190 |  Loss: (0.1216) |  Loss2: (0.0000) | Acc: (95.00%) (23428/24448)
Epoch: 154 | Batch_idx: 200 |  Loss: (0.1210) |  Loss2: (0.0000) | Acc: (95.00%) (24659/25728)
Epoch: 154 | Batch_idx: 210 |  Loss: (0.1196) |  Loss2: (0.0000) | Acc: (95.00%) (25903/27008)
Epoch: 154 | Batch_idx: 220 |  Loss: (0.1192) |  Loss2: (0.0000) | Acc: (95.00%) (27141/28288)
Epoch: 154 | Batch_idx: 230 |  Loss: (0.1194) |  Loss2: (0.0000) | Acc: (95.00%) (28368/29568)
Epoch: 154 | Batch_idx: 240 |  Loss: (0.1189) |  Loss2: (0.0000) | Acc: (95.00%) (29604/30848)
Epoch: 154 | Batch_idx: 250 |  Loss: (0.1192) |  Loss2: (0.0000) | Acc: (95.00%) (30830/32128)
Epoch: 154 | Batch_idx: 260 |  Loss: (0.1184) |  Loss2: (0.0000) | Acc: (96.00%) (32073/33408)
Epoch: 154 | Batch_idx: 270 |  Loss: (0.1181) |  Loss2: (0.0000) | Acc: (96.00%) (33303/34688)
Epoch: 154 | Batch_idx: 280 |  Loss: (0.1180) |  Loss2: (0.0000) | Acc: (96.00%) (34535/35968)
Epoch: 154 | Batch_idx: 290 |  Loss: (0.1176) |  Loss2: (0.0000) | Acc: (96.00%) (35768/37248)
Epoch: 154 | Batch_idx: 300 |  Loss: (0.1174) |  Loss2: (0.0000) | Acc: (96.00%) (37005/38528)
Epoch: 154 | Batch_idx: 310 |  Loss: (0.1176) |  Loss2: (0.0000) | Acc: (96.00%) (38222/39808)
Epoch: 154 | Batch_idx: 320 |  Loss: (0.1172) |  Loss2: (0.0000) | Acc: (96.00%) (39455/41088)
Epoch: 154 | Batch_idx: 330 |  Loss: (0.1177) |  Loss2: (0.0000) | Acc: (95.00%) (40669/42368)
Epoch: 154 | Batch_idx: 340 |  Loss: (0.1181) |  Loss2: (0.0000) | Acc: (95.00%) (41898/43648)
Epoch: 154 | Batch_idx: 350 |  Loss: (0.1179) |  Loss2: (0.0000) | Acc: (95.00%) (43128/44928)
Epoch: 154 | Batch_idx: 360 |  Loss: (0.1176) |  Loss2: (0.0000) | Acc: (95.00%) (44355/46208)
Epoch: 154 | Batch_idx: 370 |  Loss: (0.1175) |  Loss2: (0.0000) | Acc: (95.00%) (45587/47488)
Epoch: 154 | Batch_idx: 380 |  Loss: (0.1171) |  Loss2: (0.0000) | Acc: (96.00%) (46818/48768)
Epoch: 154 | Batch_idx: 390 |  Loss: (0.1170) |  Loss2: (0.0000) | Acc: (96.00%) (48006/50000)
# TEST : Loss: (0.3929) | Acc: (88.00%) (8851/10000)
percent tensor([0.5002, 0.5006, 0.5135, 0.4992, 0.5117, 0.4996, 0.5044, 0.5027, 0.5015,
        0.5047, 0.5022, 0.5106, 0.4997, 0.4949, 0.5004, 0.4978],
       device='cuda:0') torch.Size([16])
percent tensor([0.5000, 0.4828, 0.4972, 0.5029, 0.4881, 0.5083, 0.4836, 0.4886, 0.5012,
        0.4897, 0.5029, 0.4903, 0.4865, 0.4980, 0.4888, 0.5007],
       device='cuda:0') torch.Size([16])
percent tensor([0.6538, 0.6365, 0.5813, 0.5385, 0.5986, 0.6087, 0.6687, 0.5826, 0.5782,
        0.6078, 0.6133, 0.5859, 0.6766, 0.5618, 0.6679, 0.6333],
       device='cuda:0') torch.Size([16])
percent tensor([0.6163, 0.6373, 0.6075, 0.6599, 0.6203, 0.7243, 0.6180, 0.5872, 0.6618,
        0.6290, 0.6571, 0.6558, 0.6247, 0.6751, 0.6825, 0.6573],
       device='cuda:0') torch.Size([16])
percent tensor([0.6093, 0.6032, 0.5994, 0.5739, 0.6236, 0.5808, 0.6225, 0.5557, 0.6644,
        0.6438, 0.6530, 0.5012, 0.6023, 0.7251, 0.4829, 0.6368],
       device='cuda:0') torch.Size([16])
percent tensor([0.6095, 0.5880, 0.7061, 0.6988, 0.7422, 0.7375, 0.6562, 0.6776, 0.6533,
        0.6291, 0.6203, 0.6750, 0.6136, 0.6356, 0.6497, 0.6681],
       device='cuda:0') torch.Size([16])
percent tensor([0.5665, 0.7041, 0.7241, 0.6745, 0.6938, 0.5734, 0.5468, 0.5878, 0.7060,
        0.6456, 0.7199, 0.6882, 0.6801, 0.6307, 0.5529, 0.4757],
       device='cuda:0') torch.Size([16])
percent tensor([0.9996, 0.9998, 0.9998, 0.9999, 0.9997, 0.9996, 0.9996, 0.9992, 0.9998,
        0.9998, 0.9999, 0.9998, 0.9999, 0.9992, 0.9987, 0.9993],
       device='cuda:0') torch.Size([16])
Epoch: 155 | Batch_idx: 0 |  Loss: (0.0647) |  Loss2: (0.0000) | Acc: (98.00%) (126/128)
Epoch: 155 | Batch_idx: 10 |  Loss: (0.0985) |  Loss2: (0.0000) | Acc: (96.00%) (1354/1408)
Epoch: 155 | Batch_idx: 20 |  Loss: (0.1130) |  Loss2: (0.0000) | Acc: (95.00%) (2579/2688)
Epoch: 155 | Batch_idx: 30 |  Loss: (0.1145) |  Loss2: (0.0000) | Acc: (96.00%) (3810/3968)
Epoch: 155 | Batch_idx: 40 |  Loss: (0.1106) |  Loss2: (0.0000) | Acc: (96.00%) (5046/5248)
Epoch: 155 | Batch_idx: 50 |  Loss: (0.1088) |  Loss2: (0.0000) | Acc: (96.00%) (6279/6528)
Epoch: 155 | Batch_idx: 60 |  Loss: (0.1108) |  Loss2: (0.0000) | Acc: (96.00%) (7508/7808)
Epoch: 155 | Batch_idx: 70 |  Loss: (0.1127) |  Loss2: (0.0000) | Acc: (96.00%) (8737/9088)
Epoch: 155 | Batch_idx: 80 |  Loss: (0.1124) |  Loss2: (0.0000) | Acc: (96.00%) (9968/10368)
Epoch: 155 | Batch_idx: 90 |  Loss: (0.1116) |  Loss2: (0.0000) | Acc: (96.00%) (11198/11648)
Epoch: 155 | Batch_idx: 100 |  Loss: (0.1117) |  Loss2: (0.0000) | Acc: (96.00%) (12428/12928)
Epoch: 155 | Batch_idx: 110 |  Loss: (0.1134) |  Loss2: (0.0000) | Acc: (96.00%) (13645/14208)
Epoch: 155 | Batch_idx: 120 |  Loss: (0.1147) |  Loss2: (0.0000) | Acc: (96.00%) (14869/15488)
Epoch: 155 | Batch_idx: 130 |  Loss: (0.1139) |  Loss2: (0.0000) | Acc: (96.00%) (16102/16768)
Epoch: 155 | Batch_idx: 140 |  Loss: (0.1134) |  Loss2: (0.0000) | Acc: (96.00%) (17341/18048)
Epoch: 155 | Batch_idx: 150 |  Loss: (0.1126) |  Loss2: (0.0000) | Acc: (96.00%) (18567/19328)
Epoch: 155 | Batch_idx: 160 |  Loss: (0.1127) |  Loss2: (0.0000) | Acc: (96.00%) (19797/20608)
Epoch: 155 | Batch_idx: 170 |  Loss: (0.1121) |  Loss2: (0.0000) | Acc: (96.00%) (21034/21888)
Epoch: 155 | Batch_idx: 180 |  Loss: (0.1114) |  Loss2: (0.0000) | Acc: (96.00%) (22275/23168)
Epoch: 155 | Batch_idx: 190 |  Loss: (0.1110) |  Loss2: (0.0000) | Acc: (96.00%) (23514/24448)
Epoch: 155 | Batch_idx: 200 |  Loss: (0.1122) |  Loss2: (0.0000) | Acc: (96.00%) (24732/25728)
Epoch: 155 | Batch_idx: 210 |  Loss: (0.1121) |  Loss2: (0.0000) | Acc: (96.00%) (25967/27008)
Epoch: 155 | Batch_idx: 220 |  Loss: (0.1119) |  Loss2: (0.0000) | Acc: (96.00%) (27200/28288)
Epoch: 155 | Batch_idx: 230 |  Loss: (0.1125) |  Loss2: (0.0000) | Acc: (96.00%) (28425/29568)
Epoch: 155 | Batch_idx: 240 |  Loss: (0.1127) |  Loss2: (0.0000) | Acc: (96.00%) (29651/30848)
Epoch: 155 | Batch_idx: 250 |  Loss: (0.1120) |  Loss2: (0.0000) | Acc: (96.00%) (30894/32128)
Epoch: 155 | Batch_idx: 260 |  Loss: (0.1117) |  Loss2: (0.0000) | Acc: (96.00%) (32136/33408)
Epoch: 155 | Batch_idx: 270 |  Loss: (0.1111) |  Loss2: (0.0000) | Acc: (96.00%) (33381/34688)
Epoch: 155 | Batch_idx: 280 |  Loss: (0.1111) |  Loss2: (0.0000) | Acc: (96.00%) (34610/35968)
Epoch: 155 | Batch_idx: 290 |  Loss: (0.1112) |  Loss2: (0.0000) | Acc: (96.00%) (35835/37248)
Epoch: 155 | Batch_idx: 300 |  Loss: (0.1107) |  Loss2: (0.0000) | Acc: (96.00%) (37074/38528)
Epoch: 155 | Batch_idx: 310 |  Loss: (0.1110) |  Loss2: (0.0000) | Acc: (96.00%) (38298/39808)
Epoch: 155 | Batch_idx: 320 |  Loss: (0.1108) |  Loss2: (0.0000) | Acc: (96.00%) (39530/41088)
Epoch: 155 | Batch_idx: 330 |  Loss: (0.1109) |  Loss2: (0.0000) | Acc: (96.00%) (40760/42368)
Epoch: 155 | Batch_idx: 340 |  Loss: (0.1110) |  Loss2: (0.0000) | Acc: (96.00%) (41997/43648)
Epoch: 155 | Batch_idx: 350 |  Loss: (0.1110) |  Loss2: (0.0000) | Acc: (96.00%) (43226/44928)
Epoch: 155 | Batch_idx: 360 |  Loss: (0.1114) |  Loss2: (0.0000) | Acc: (96.00%) (44444/46208)
Epoch: 155 | Batch_idx: 370 |  Loss: (0.1118) |  Loss2: (0.0000) | Acc: (96.00%) (45670/47488)
Epoch: 155 | Batch_idx: 380 |  Loss: (0.1118) |  Loss2: (0.0000) | Acc: (96.00%) (46904/48768)
Epoch: 155 | Batch_idx: 390 |  Loss: (0.1121) |  Loss2: (0.0000) | Acc: (96.00%) (48088/50000)
=> saving checkpoint 'drive/app/torch/save_Schedule/checkpoint_155.pth.tar'
# TEST : Loss: (0.3926) | Acc: (88.00%) (8867/10000)
percent tensor([0.5006, 0.5007, 0.5146, 0.4995, 0.5127, 0.5001, 0.5049, 0.5030, 0.5019,
        0.5051, 0.5026, 0.5116, 0.5000, 0.4946, 0.5007, 0.4980],
       device='cuda:0') torch.Size([16])
percent tensor([0.5015, 0.4834, 0.4987, 0.5045, 0.4898, 0.5093, 0.4849, 0.4902, 0.5026,
        0.4904, 0.5041, 0.4918, 0.4875, 0.4989, 0.4900, 0.5018],
       device='cuda:0') torch.Size([16])
percent tensor([0.6470, 0.6307, 0.5779, 0.5348, 0.5935, 0.5984, 0.6649, 0.5801, 0.5730,
        0.6023, 0.6078, 0.5821, 0.6708, 0.5572, 0.6610, 0.6267],
       device='cuda:0') torch.Size([16])
percent tensor([0.6114, 0.6325, 0.6029, 0.6578, 0.6186, 0.7217, 0.6150, 0.5831, 0.6553,
        0.6226, 0.6508, 0.6504, 0.6179, 0.6703, 0.6787, 0.6531],
       device='cuda:0') torch.Size([16])
percent tensor([0.6104, 0.6075, 0.6037, 0.5773, 0.6269, 0.5823, 0.6265, 0.5608, 0.6675,
        0.6471, 0.6572, 0.5055, 0.6043, 0.7299, 0.4842, 0.6393],
       device='cuda:0') torch.Size([16])
percent tensor([0.6069, 0.5849, 0.7058, 0.6995, 0.7431, 0.7385, 0.6548, 0.6800, 0.6486,
        0.6252, 0.6171, 0.6749, 0.6100, 0.6314, 0.6501, 0.6664],
       device='cuda:0') torch.Size([16])
percent tensor([0.5729, 0.7106, 0.7237, 0.6761, 0.6897, 0.5823, 0.5420, 0.5949, 0.7090,
        0.6477, 0.7221, 0.6892, 0.6900, 0.6319, 0.5587, 0.4769],
       device='cuda:0') torch.Size([16])
percent tensor([0.9997, 0.9998, 0.9998, 0.9999, 0.9997, 0.9997, 0.9996, 0.9992, 0.9998,
        0.9998, 1.0000, 0.9998, 0.9999, 0.9993, 0.9987, 0.9994],
       device='cuda:0') torch.Size([16])
Epoch: 156 | Batch_idx: 0 |  Loss: (0.1155) |  Loss2: (0.0000) | Acc: (96.00%) (124/128)
Epoch: 156 | Batch_idx: 10 |  Loss: (0.1151) |  Loss2: (0.0000) | Acc: (96.00%) (1362/1408)
Epoch: 156 | Batch_idx: 20 |  Loss: (0.1063) |  Loss2: (0.0000) | Acc: (96.00%) (2602/2688)
Epoch: 156 | Batch_idx: 30 |  Loss: (0.1083) |  Loss2: (0.0000) | Acc: (96.00%) (3831/3968)
Epoch: 156 | Batch_idx: 40 |  Loss: (0.1078) |  Loss2: (0.0000) | Acc: (96.00%) (5069/5248)
Epoch: 156 | Batch_idx: 50 |  Loss: (0.1096) |  Loss2: (0.0000) | Acc: (96.00%) (6302/6528)
Epoch: 156 | Batch_idx: 60 |  Loss: (0.1071) |  Loss2: (0.0000) | Acc: (96.00%) (7539/7808)
Epoch: 156 | Batch_idx: 70 |  Loss: (0.1078) |  Loss2: (0.0000) | Acc: (96.00%) (8772/9088)
Epoch: 156 | Batch_idx: 80 |  Loss: (0.1076) |  Loss2: (0.0000) | Acc: (96.00%) (10014/10368)
Epoch: 156 | Batch_idx: 90 |  Loss: (0.1069) |  Loss2: (0.0000) | Acc: (96.00%) (11252/11648)
Epoch: 156 | Batch_idx: 100 |  Loss: (0.1076) |  Loss2: (0.0000) | Acc: (96.00%) (12482/12928)
Epoch: 156 | Batch_idx: 110 |  Loss: (0.1064) |  Loss2: (0.0000) | Acc: (96.00%) (13712/14208)
Epoch: 156 | Batch_idx: 120 |  Loss: (0.1063) |  Loss2: (0.0000) | Acc: (96.00%) (14937/15488)
Epoch: 156 | Batch_idx: 130 |  Loss: (0.1064) |  Loss2: (0.0000) | Acc: (96.00%) (16168/16768)
Epoch: 156 | Batch_idx: 140 |  Loss: (0.1065) |  Loss2: (0.0000) | Acc: (96.00%) (17401/18048)
Epoch: 156 | Batch_idx: 150 |  Loss: (0.1073) |  Loss2: (0.0000) | Acc: (96.00%) (18627/19328)
Epoch: 156 | Batch_idx: 160 |  Loss: (0.1072) |  Loss2: (0.0000) | Acc: (96.00%) (19855/20608)
Epoch: 156 | Batch_idx: 170 |  Loss: (0.1078) |  Loss2: (0.0000) | Acc: (96.00%) (21088/21888)
Epoch: 156 | Batch_idx: 180 |  Loss: (0.1082) |  Loss2: (0.0000) | Acc: (96.00%) (22317/23168)
Epoch: 156 | Batch_idx: 190 |  Loss: (0.1087) |  Loss2: (0.0000) | Acc: (96.00%) (23552/24448)
Epoch: 156 | Batch_idx: 200 |  Loss: (0.1084) |  Loss2: (0.0000) | Acc: (96.00%) (24789/25728)
Epoch: 156 | Batch_idx: 210 |  Loss: (0.1079) |  Loss2: (0.0000) | Acc: (96.00%) (26024/27008)
Epoch: 156 | Batch_idx: 220 |  Loss: (0.1079) |  Loss2: (0.0000) | Acc: (96.00%) (27258/28288)
Epoch: 156 | Batch_idx: 230 |  Loss: (0.1073) |  Loss2: (0.0000) | Acc: (96.00%) (28493/29568)
Epoch: 156 | Batch_idx: 240 |  Loss: (0.1075) |  Loss2: (0.0000) | Acc: (96.00%) (29735/30848)
Epoch: 156 | Batch_idx: 250 |  Loss: (0.1080) |  Loss2: (0.0000) | Acc: (96.00%) (30962/32128)
Epoch: 156 | Batch_idx: 260 |  Loss: (0.1084) |  Loss2: (0.0000) | Acc: (96.00%) (32197/33408)
Epoch: 156 | Batch_idx: 270 |  Loss: (0.1083) |  Loss2: (0.0000) | Acc: (96.00%) (33426/34688)
Epoch: 156 | Batch_idx: 280 |  Loss: (0.1080) |  Loss2: (0.0000) | Acc: (96.00%) (34662/35968)
Epoch: 156 | Batch_idx: 290 |  Loss: (0.1082) |  Loss2: (0.0000) | Acc: (96.00%) (35893/37248)
Epoch: 156 | Batch_idx: 300 |  Loss: (0.1083) |  Loss2: (0.0000) | Acc: (96.00%) (37125/38528)
Epoch: 156 | Batch_idx: 310 |  Loss: (0.1087) |  Loss2: (0.0000) | Acc: (96.00%) (38355/39808)
Epoch: 156 | Batch_idx: 320 |  Loss: (0.1087) |  Loss2: (0.0000) | Acc: (96.00%) (39580/41088)
Epoch: 156 | Batch_idx: 330 |  Loss: (0.1086) |  Loss2: (0.0000) | Acc: (96.00%) (40817/42368)
Epoch: 156 | Batch_idx: 340 |  Loss: (0.1088) |  Loss2: (0.0000) | Acc: (96.00%) (42041/43648)
Epoch: 156 | Batch_idx: 350 |  Loss: (0.1091) |  Loss2: (0.0000) | Acc: (96.00%) (43267/44928)
Epoch: 156 | Batch_idx: 360 |  Loss: (0.1088) |  Loss2: (0.0000) | Acc: (96.00%) (44508/46208)
Epoch: 156 | Batch_idx: 370 |  Loss: (0.1086) |  Loss2: (0.0000) | Acc: (96.00%) (45748/47488)
Epoch: 156 | Batch_idx: 380 |  Loss: (0.1093) |  Loss2: (0.0000) | Acc: (96.00%) (46968/48768)
Epoch: 156 | Batch_idx: 390 |  Loss: (0.1091) |  Loss2: (0.0000) | Acc: (96.00%) (48159/50000)
# TEST : Loss: (0.3865) | Acc: (88.00%) (8851/10000)
percent tensor([0.5013, 0.5013, 0.5161, 0.5006, 0.5142, 0.5009, 0.5058, 0.5041, 0.5027,
        0.5061, 0.5033, 0.5130, 0.5007, 0.4949, 0.5015, 0.4986],
       device='cuda:0') torch.Size([16])
percent tensor([0.5007, 0.4821, 0.4984, 0.5041, 0.4898, 0.5090, 0.4839, 0.4895, 0.5022,
        0.4895, 0.5033, 0.4913, 0.4871, 0.4977, 0.4890, 0.5009],
       device='cuda:0') torch.Size([16])
percent tensor([0.6524, 0.6334, 0.5792, 0.5392, 0.5935, 0.6061, 0.6668, 0.5829, 0.5776,
        0.6047, 0.6119, 0.5822, 0.6735, 0.5663, 0.6648, 0.6317],
       device='cuda:0') torch.Size([16])
percent tensor([0.6249, 0.6447, 0.6167, 0.6689, 0.6317, 0.7313, 0.6303, 0.5968, 0.6680,
        0.6363, 0.6631, 0.6635, 0.6305, 0.6832, 0.6915, 0.6653],
       device='cuda:0') torch.Size([16])
percent tensor([0.6109, 0.6081, 0.6011, 0.5749, 0.6253, 0.5844, 0.6262, 0.5586, 0.6669,
        0.6469, 0.6565, 0.5022, 0.6040, 0.7293, 0.4837, 0.6397],
       device='cuda:0') torch.Size([16])
percent tensor([0.6118, 0.5895, 0.7099, 0.7042, 0.7481, 0.7451, 0.6593, 0.6864, 0.6529,
        0.6314, 0.6218, 0.6805, 0.6149, 0.6383, 0.6556, 0.6728],
       device='cuda:0') torch.Size([16])
percent tensor([0.5634, 0.7046, 0.7228, 0.6780, 0.6898, 0.5856, 0.5370, 0.5928, 0.7025,
        0.6392, 0.7158, 0.6910, 0.6836, 0.6295, 0.5584, 0.4751],
       device='cuda:0') torch.Size([16])
percent tensor([0.9997, 0.9998, 0.9998, 0.9999, 0.9997, 0.9996, 0.9996, 0.9992, 0.9998,
        0.9998, 0.9999, 0.9998, 0.9999, 0.9993, 0.9987, 0.9994],
       device='cuda:0') torch.Size([16])
Epoch: 157 | Batch_idx: 0 |  Loss: (0.0499) |  Loss2: (0.0000) | Acc: (99.00%) (127/128)
Epoch: 157 | Batch_idx: 10 |  Loss: (0.0898) |  Loss2: (0.0000) | Acc: (96.00%) (1362/1408)
Epoch: 157 | Batch_idx: 20 |  Loss: (0.0951) |  Loss2: (0.0000) | Acc: (96.00%) (2598/2688)
Epoch: 157 | Batch_idx: 30 |  Loss: (0.1091) |  Loss2: (0.0000) | Acc: (96.00%) (3821/3968)
Epoch: 157 | Batch_idx: 40 |  Loss: (0.1017) |  Loss2: (0.0000) | Acc: (96.00%) (5070/5248)
Epoch: 157 | Batch_idx: 50 |  Loss: (0.1050) |  Loss2: (0.0000) | Acc: (96.00%) (6299/6528)
Epoch: 157 | Batch_idx: 60 |  Loss: (0.1035) |  Loss2: (0.0000) | Acc: (96.00%) (7531/7808)
Epoch: 157 | Batch_idx: 70 |  Loss: (0.1042) |  Loss2: (0.0000) | Acc: (96.00%) (8769/9088)
Epoch: 157 | Batch_idx: 80 |  Loss: (0.1056) |  Loss2: (0.0000) | Acc: (96.00%) (10003/10368)
Epoch: 157 | Batch_idx: 90 |  Loss: (0.1067) |  Loss2: (0.0000) | Acc: (96.00%) (11234/11648)
Epoch: 157 | Batch_idx: 100 |  Loss: (0.1081) |  Loss2: (0.0000) | Acc: (96.00%) (12463/12928)
Epoch: 157 | Batch_idx: 110 |  Loss: (0.1100) |  Loss2: (0.0000) | Acc: (96.00%) (13693/14208)
Epoch: 157 | Batch_idx: 120 |  Loss: (0.1091) |  Loss2: (0.0000) | Acc: (96.00%) (14939/15488)
Epoch: 157 | Batch_idx: 130 |  Loss: (0.1101) |  Loss2: (0.0000) | Acc: (96.00%) (16167/16768)
Epoch: 157 | Batch_idx: 140 |  Loss: (0.1100) |  Loss2: (0.0000) | Acc: (96.00%) (17409/18048)
Epoch: 157 | Batch_idx: 150 |  Loss: (0.1109) |  Loss2: (0.0000) | Acc: (96.00%) (18630/19328)
Epoch: 157 | Batch_idx: 160 |  Loss: (0.1101) |  Loss2: (0.0000) | Acc: (96.00%) (19862/20608)
Epoch: 157 | Batch_idx: 170 |  Loss: (0.1094) |  Loss2: (0.0000) | Acc: (96.00%) (21105/21888)
Epoch: 157 | Batch_idx: 180 |  Loss: (0.1091) |  Loss2: (0.0000) | Acc: (96.00%) (22342/23168)
Epoch: 157 | Batch_idx: 190 |  Loss: (0.1091) |  Loss2: (0.0000) | Acc: (96.00%) (23575/24448)
Epoch: 157 | Batch_idx: 200 |  Loss: (0.1092) |  Loss2: (0.0000) | Acc: (96.00%) (24812/25728)
Epoch: 157 | Batch_idx: 210 |  Loss: (0.1094) |  Loss2: (0.0000) | Acc: (96.00%) (26041/27008)
Epoch: 157 | Batch_idx: 220 |  Loss: (0.1091) |  Loss2: (0.0000) | Acc: (96.00%) (27276/28288)
Epoch: 157 | Batch_idx: 230 |  Loss: (0.1085) |  Loss2: (0.0000) | Acc: (96.00%) (28514/29568)
Epoch: 157 | Batch_idx: 240 |  Loss: (0.1090) |  Loss2: (0.0000) | Acc: (96.00%) (29741/30848)
Epoch: 157 | Batch_idx: 250 |  Loss: (0.1089) |  Loss2: (0.0000) | Acc: (96.00%) (30973/32128)
Epoch: 157 | Batch_idx: 260 |  Loss: (0.1092) |  Loss2: (0.0000) | Acc: (96.00%) (32213/33408)
Epoch: 157 | Batch_idx: 270 |  Loss: (0.1095) |  Loss2: (0.0000) | Acc: (96.00%) (33448/34688)
Epoch: 157 | Batch_idx: 280 |  Loss: (0.1087) |  Loss2: (0.0000) | Acc: (96.00%) (34693/35968)
Epoch: 157 | Batch_idx: 290 |  Loss: (0.1093) |  Loss2: (0.0000) | Acc: (96.00%) (35912/37248)
Epoch: 157 | Batch_idx: 300 |  Loss: (0.1085) |  Loss2: (0.0000) | Acc: (96.00%) (37162/38528)
Epoch: 157 | Batch_idx: 310 |  Loss: (0.1086) |  Loss2: (0.0000) | Acc: (96.00%) (38396/39808)
Epoch: 157 | Batch_idx: 320 |  Loss: (0.1084) |  Loss2: (0.0000) | Acc: (96.00%) (39632/41088)
Epoch: 157 | Batch_idx: 330 |  Loss: (0.1084) |  Loss2: (0.0000) | Acc: (96.00%) (40868/42368)
Epoch: 157 | Batch_idx: 340 |  Loss: (0.1082) |  Loss2: (0.0000) | Acc: (96.00%) (42104/43648)
Epoch: 157 | Batch_idx: 350 |  Loss: (0.1084) |  Loss2: (0.0000) | Acc: (96.00%) (43333/44928)
Epoch: 157 | Batch_idx: 360 |  Loss: (0.1083) |  Loss2: (0.0000) | Acc: (96.00%) (44565/46208)
Epoch: 157 | Batch_idx: 370 |  Loss: (0.1085) |  Loss2: (0.0000) | Acc: (96.00%) (45789/47488)
Epoch: 157 | Batch_idx: 380 |  Loss: (0.1085) |  Loss2: (0.0000) | Acc: (96.00%) (47026/48768)
Epoch: 157 | Batch_idx: 390 |  Loss: (0.1083) |  Loss2: (0.0000) | Acc: (96.00%) (48222/50000)
# TEST : Loss: (0.3852) | Acc: (88.00%) (8858/10000)
percent tensor([0.5019, 0.5019, 0.5176, 0.5015, 0.5155, 0.5014, 0.5066, 0.5050, 0.5034,
        0.5069, 0.5038, 0.5144, 0.5013, 0.4952, 0.5021, 0.4992],
       device='cuda:0') torch.Size([16])
percent tensor([0.5014, 0.4820, 0.4988, 0.5047, 0.4904, 0.5098, 0.4840, 0.4900, 0.5029,
        0.4895, 0.5038, 0.4915, 0.4874, 0.4978, 0.4895, 0.5013],
       device='cuda:0') torch.Size([16])
percent tensor([0.6563, 0.6405, 0.5857, 0.5468, 0.5991, 0.6079, 0.6726, 0.5895, 0.5850,
        0.6132, 0.6200, 0.5901, 0.6795, 0.5759, 0.6683, 0.6370],
       device='cuda:0') torch.Size([16])
percent tensor([0.6188, 0.6398, 0.6090, 0.6637, 0.6249, 0.7272, 0.6238, 0.5886, 0.6618,
        0.6300, 0.6585, 0.6559, 0.6242, 0.6789, 0.6855, 0.6611],
       device='cuda:0') torch.Size([16])
percent tensor([0.6074, 0.6079, 0.5994, 0.5741, 0.6220, 0.5788, 0.6233, 0.5574, 0.6687,
        0.6465, 0.6587, 0.5013, 0.6011, 0.7322, 0.4817, 0.6339],
       device='cuda:0') torch.Size([16])
percent tensor([0.6172, 0.5943, 0.7135, 0.7089, 0.7527, 0.7489, 0.6640, 0.6915, 0.6556,
        0.6343, 0.6265, 0.6848, 0.6190, 0.6429, 0.6611, 0.6773],
       device='cuda:0') torch.Size([16])
percent tensor([0.5665, 0.7075, 0.7275, 0.6796, 0.6939, 0.5923, 0.5383, 0.6035, 0.7018,
        0.6387, 0.7153, 0.6932, 0.6871, 0.6260, 0.5611, 0.4752],
       device='cuda:0') torch.Size([16])
percent tensor([0.9997, 0.9998, 0.9998, 0.9999, 0.9997, 0.9997, 0.9996, 0.9993, 0.9998,
        0.9998, 1.0000, 0.9998, 0.9999, 0.9994, 0.9988, 0.9994],
       device='cuda:0') torch.Size([16])
Epoch: 158 | Batch_idx: 0 |  Loss: (0.0742) |  Loss2: (0.0000) | Acc: (96.00%) (123/128)
Epoch: 158 | Batch_idx: 10 |  Loss: (0.0956) |  Loss2: (0.0000) | Acc: (96.00%) (1358/1408)
Epoch: 158 | Batch_idx: 20 |  Loss: (0.0992) |  Loss2: (0.0000) | Acc: (96.00%) (2595/2688)
Epoch: 158 | Batch_idx: 30 |  Loss: (0.0962) |  Loss2: (0.0000) | Acc: (96.00%) (3844/3968)
Epoch: 158 | Batch_idx: 40 |  Loss: (0.0994) |  Loss2: (0.0000) | Acc: (96.00%) (5072/5248)
Epoch: 158 | Batch_idx: 50 |  Loss: (0.1014) |  Loss2: (0.0000) | Acc: (96.00%) (6299/6528)
Epoch: 158 | Batch_idx: 60 |  Loss: (0.0995) |  Loss2: (0.0000) | Acc: (96.00%) (7542/7808)
Epoch: 158 | Batch_idx: 70 |  Loss: (0.1000) |  Loss2: (0.0000) | Acc: (96.00%) (8776/9088)
Epoch: 158 | Batch_idx: 80 |  Loss: (0.1028) |  Loss2: (0.0000) | Acc: (96.00%) (9995/10368)
Epoch: 158 | Batch_idx: 90 |  Loss: (0.1041) |  Loss2: (0.0000) | Acc: (96.00%) (11222/11648)
Epoch: 158 | Batch_idx: 100 |  Loss: (0.1037) |  Loss2: (0.0000) | Acc: (96.00%) (12462/12928)
Epoch: 158 | Batch_idx: 110 |  Loss: (0.1047) |  Loss2: (0.0000) | Acc: (96.00%) (13686/14208)
Epoch: 158 | Batch_idx: 120 |  Loss: (0.1047) |  Loss2: (0.0000) | Acc: (96.00%) (14918/15488)
Epoch: 158 | Batch_idx: 130 |  Loss: (0.1055) |  Loss2: (0.0000) | Acc: (96.00%) (16144/16768)
Epoch: 158 | Batch_idx: 140 |  Loss: (0.1050) |  Loss2: (0.0000) | Acc: (96.00%) (17378/18048)
Epoch: 158 | Batch_idx: 150 |  Loss: (0.1037) |  Loss2: (0.0000) | Acc: (96.00%) (18619/19328)
Epoch: 158 | Batch_idx: 160 |  Loss: (0.1045) |  Loss2: (0.0000) | Acc: (96.00%) (19847/20608)
Epoch: 158 | Batch_idx: 170 |  Loss: (0.1043) |  Loss2: (0.0000) | Acc: (96.00%) (21082/21888)
Epoch: 158 | Batch_idx: 180 |  Loss: (0.1052) |  Loss2: (0.0000) | Acc: (96.00%) (22302/23168)
Epoch: 158 | Batch_idx: 190 |  Loss: (0.1052) |  Loss2: (0.0000) | Acc: (96.00%) (23537/24448)
Epoch: 158 | Batch_idx: 200 |  Loss: (0.1045) |  Loss2: (0.0000) | Acc: (96.00%) (24782/25728)
Epoch: 158 | Batch_idx: 210 |  Loss: (0.1046) |  Loss2: (0.0000) | Acc: (96.00%) (26021/27008)
Epoch: 158 | Batch_idx: 220 |  Loss: (0.1045) |  Loss2: (0.0000) | Acc: (96.00%) (27258/28288)
Epoch: 158 | Batch_idx: 230 |  Loss: (0.1038) |  Loss2: (0.0000) | Acc: (96.00%) (28498/29568)
Epoch: 158 | Batch_idx: 240 |  Loss: (0.1043) |  Loss2: (0.0000) | Acc: (96.00%) (29719/30848)
Epoch: 158 | Batch_idx: 250 |  Loss: (0.1048) |  Loss2: (0.0000) | Acc: (96.00%) (30946/32128)
Epoch: 158 | Batch_idx: 260 |  Loss: (0.1046) |  Loss2: (0.0000) | Acc: (96.00%) (32187/33408)
Epoch: 158 | Batch_idx: 270 |  Loss: (0.1043) |  Loss2: (0.0000) | Acc: (96.00%) (33423/34688)
Epoch: 158 | Batch_idx: 280 |  Loss: (0.1050) |  Loss2: (0.0000) | Acc: (96.00%) (34646/35968)
Epoch: 158 | Batch_idx: 290 |  Loss: (0.1043) |  Loss2: (0.0000) | Acc: (96.00%) (35892/37248)
Epoch: 158 | Batch_idx: 300 |  Loss: (0.1038) |  Loss2: (0.0000) | Acc: (96.00%) (37135/38528)
Epoch: 158 | Batch_idx: 310 |  Loss: (0.1031) |  Loss2: (0.0000) | Acc: (96.00%) (38382/39808)
Epoch: 158 | Batch_idx: 320 |  Loss: (0.1032) |  Loss2: (0.0000) | Acc: (96.00%) (39615/41088)
Epoch: 158 | Batch_idx: 330 |  Loss: (0.1040) |  Loss2: (0.0000) | Acc: (96.00%) (40835/42368)
Epoch: 158 | Batch_idx: 340 |  Loss: (0.1042) |  Loss2: (0.0000) | Acc: (96.00%) (42072/43648)
Epoch: 158 | Batch_idx: 350 |  Loss: (0.1046) |  Loss2: (0.0000) | Acc: (96.00%) (43299/44928)
Epoch: 158 | Batch_idx: 360 |  Loss: (0.1045) |  Loss2: (0.0000) | Acc: (96.00%) (44535/46208)
Epoch: 158 | Batch_idx: 370 |  Loss: (0.1046) |  Loss2: (0.0000) | Acc: (96.00%) (45764/47488)
Epoch: 158 | Batch_idx: 380 |  Loss: (0.1045) |  Loss2: (0.0000) | Acc: (96.00%) (46998/48768)
Epoch: 158 | Batch_idx: 390 |  Loss: (0.1048) |  Loss2: (0.0000) | Acc: (96.00%) (48183/50000)
# TEST : Loss: (0.3832) | Acc: (88.00%) (8860/10000)
percent tensor([0.5001, 0.4998, 0.5162, 0.4998, 0.5139, 0.4998, 0.5047, 0.5031, 0.5015,
        0.5051, 0.5019, 0.5128, 0.4993, 0.4932, 0.5002, 0.4973],
       device='cuda:0') torch.Size([16])
percent tensor([0.5036, 0.4842, 0.5009, 0.5065, 0.4926, 0.5109, 0.4864, 0.4921, 0.5052,
        0.4912, 0.5063, 0.4940, 0.4897, 0.4995, 0.4917, 0.5033],
       device='cuda:0') torch.Size([16])
percent tensor([0.6570, 0.6387, 0.5859, 0.5470, 0.5977, 0.6084, 0.6719, 0.5896, 0.5848,
        0.6125, 0.6202, 0.5877, 0.6795, 0.5754, 0.6678, 0.6375],
       device='cuda:0') torch.Size([16])
percent tensor([0.6220, 0.6442, 0.6134, 0.6661, 0.6287, 0.7309, 0.6286, 0.5917, 0.6648,
        0.6345, 0.6618, 0.6602, 0.6289, 0.6824, 0.6900, 0.6650],
       device='cuda:0') torch.Size([16])
percent tensor([0.6027, 0.6055, 0.5942, 0.5706, 0.6171, 0.5718, 0.6183, 0.5533, 0.6665,
        0.6445, 0.6586, 0.4985, 0.5985, 0.7329, 0.4744, 0.6277],
       device='cuda:0') torch.Size([16])
percent tensor([0.6107, 0.5877, 0.7096, 0.7041, 0.7476, 0.7452, 0.6569, 0.6880, 0.6494,
        0.6279, 0.6193, 0.6800, 0.6128, 0.6361, 0.6573, 0.6720],
       device='cuda:0') torch.Size([16])
percent tensor([0.5657, 0.7073, 0.7257, 0.6811, 0.6848, 0.5964, 0.5364, 0.6032, 0.7001,
        0.6396, 0.7102, 0.6908, 0.6868, 0.6227, 0.5666, 0.4749],
       device='cuda:0') torch.Size([16])
percent tensor([0.9997, 0.9998, 0.9998, 0.9999, 0.9997, 0.9997, 0.9997, 0.9993, 0.9998,
        0.9998, 1.0000, 0.9998, 0.9999, 0.9994, 0.9987, 0.9994],
       device='cuda:0') torch.Size([16])
Epoch: 159 | Batch_idx: 0 |  Loss: (0.0926) |  Loss2: (0.0000) | Acc: (97.00%) (125/128)
Epoch: 159 | Batch_idx: 10 |  Loss: (0.1012) |  Loss2: (0.0000) | Acc: (96.00%) (1361/1408)
Epoch: 159 | Batch_idx: 20 |  Loss: (0.0980) |  Loss2: (0.0000) | Acc: (97.00%) (2612/2688)
Epoch: 159 | Batch_idx: 30 |  Loss: (0.0955) |  Loss2: (0.0000) | Acc: (97.00%) (3852/3968)
Epoch: 159 | Batch_idx: 40 |  Loss: (0.0905) |  Loss2: (0.0000) | Acc: (97.00%) (5099/5248)
Epoch: 159 | Batch_idx: 50 |  Loss: (0.0956) |  Loss2: (0.0000) | Acc: (97.00%) (6333/6528)
Epoch: 159 | Batch_idx: 60 |  Loss: (0.0957) |  Loss2: (0.0000) | Acc: (96.00%) (7571/7808)
Epoch: 159 | Batch_idx: 70 |  Loss: (0.0979) |  Loss2: (0.0000) | Acc: (96.00%) (8799/9088)
Epoch: 159 | Batch_idx: 80 |  Loss: (0.1000) |  Loss2: (0.0000) | Acc: (96.00%) (10029/10368)
Epoch: 159 | Batch_idx: 90 |  Loss: (0.1001) |  Loss2: (0.0000) | Acc: (96.00%) (11266/11648)
Epoch: 159 | Batch_idx: 100 |  Loss: (0.1011) |  Loss2: (0.0000) | Acc: (96.00%) (12498/12928)
Epoch: 159 | Batch_idx: 110 |  Loss: (0.1011) |  Loss2: (0.0000) | Acc: (96.00%) (13739/14208)
Epoch: 159 | Batch_idx: 120 |  Loss: (0.0989) |  Loss2: (0.0000) | Acc: (96.00%) (14993/15488)
Epoch: 159 | Batch_idx: 130 |  Loss: (0.0991) |  Loss2: (0.0000) | Acc: (96.00%) (16230/16768)
Epoch: 159 | Batch_idx: 140 |  Loss: (0.0997) |  Loss2: (0.0000) | Acc: (96.00%) (17461/18048)
Epoch: 159 | Batch_idx: 150 |  Loss: (0.1021) |  Loss2: (0.0000) | Acc: (96.00%) (18677/19328)
Epoch: 159 | Batch_idx: 160 |  Loss: (0.1023) |  Loss2: (0.0000) | Acc: (96.00%) (19907/20608)
Epoch: 159 | Batch_idx: 170 |  Loss: (0.1033) |  Loss2: (0.0000) | Acc: (96.00%) (21125/21888)
Epoch: 159 | Batch_idx: 180 |  Loss: (0.1027) |  Loss2: (0.0000) | Acc: (96.00%) (22363/23168)
Epoch: 159 | Batch_idx: 190 |  Loss: (0.1038) |  Loss2: (0.0000) | Acc: (96.00%) (23588/24448)
Epoch: 159 | Batch_idx: 200 |  Loss: (0.1038) |  Loss2: (0.0000) | Acc: (96.00%) (24829/25728)
Epoch: 159 | Batch_idx: 210 |  Loss: (0.1038) |  Loss2: (0.0000) | Acc: (96.00%) (26061/27008)
Epoch: 159 | Batch_idx: 220 |  Loss: (0.1036) |  Loss2: (0.0000) | Acc: (96.00%) (27297/28288)
Epoch: 159 | Batch_idx: 230 |  Loss: (0.1040) |  Loss2: (0.0000) | Acc: (96.00%) (28530/29568)
Epoch: 159 | Batch_idx: 240 |  Loss: (0.1045) |  Loss2: (0.0000) | Acc: (96.00%) (29758/30848)
Epoch: 159 | Batch_idx: 250 |  Loss: (0.1051) |  Loss2: (0.0000) | Acc: (96.00%) (30987/32128)
Epoch: 159 | Batch_idx: 260 |  Loss: (0.1048) |  Loss2: (0.0000) | Acc: (96.00%) (32226/33408)
Epoch: 159 | Batch_idx: 270 |  Loss: (0.1043) |  Loss2: (0.0000) | Acc: (96.00%) (33463/34688)
Epoch: 159 | Batch_idx: 280 |  Loss: (0.1047) |  Loss2: (0.0000) | Acc: (96.00%) (34699/35968)
Epoch: 159 | Batch_idx: 290 |  Loss: (0.1045) |  Loss2: (0.0000) | Acc: (96.00%) (35937/37248)
Epoch: 159 | Batch_idx: 300 |  Loss: (0.1042) |  Loss2: (0.0000) | Acc: (96.00%) (37178/38528)
Epoch: 159 | Batch_idx: 310 |  Loss: (0.1046) |  Loss2: (0.0000) | Acc: (96.00%) (38410/39808)
Epoch: 159 | Batch_idx: 320 |  Loss: (0.1043) |  Loss2: (0.0000) | Acc: (96.00%) (39643/41088)
Epoch: 159 | Batch_idx: 330 |  Loss: (0.1040) |  Loss2: (0.0000) | Acc: (96.00%) (40886/42368)
Epoch: 159 | Batch_idx: 340 |  Loss: (0.1040) |  Loss2: (0.0000) | Acc: (96.00%) (42121/43648)
Epoch: 159 | Batch_idx: 350 |  Loss: (0.1042) |  Loss2: (0.0000) | Acc: (96.00%) (43356/44928)
Epoch: 159 | Batch_idx: 360 |  Loss: (0.1044) |  Loss2: (0.0000) | Acc: (96.00%) (44585/46208)
Epoch: 159 | Batch_idx: 370 |  Loss: (0.1039) |  Loss2: (0.0000) | Acc: (96.00%) (45830/47488)
Epoch: 159 | Batch_idx: 380 |  Loss: (0.1040) |  Loss2: (0.0000) | Acc: (96.00%) (47063/48768)
Epoch: 159 | Batch_idx: 390 |  Loss: (0.1043) |  Loss2: (0.0000) | Acc: (96.00%) (48246/50000)
# TEST : Loss: (0.3824) | Acc: (88.00%) (8875/10000)
percent tensor([0.5005, 0.5001, 0.5165, 0.5003, 0.5144, 0.5003, 0.5051, 0.5034, 0.5019,
        0.5054, 0.5022, 0.5133, 0.4997, 0.4934, 0.5006, 0.4977],
       device='cuda:0') torch.Size([16])
percent tensor([0.5006, 0.4801, 0.4981, 0.5041, 0.4897, 0.5100, 0.4822, 0.4887, 0.5025,
        0.4878, 0.5030, 0.4906, 0.4866, 0.4959, 0.4882, 0.5002],
       device='cuda:0') torch.Size([16])
percent tensor([0.6507, 0.6331, 0.5854, 0.5460, 0.5961, 0.6015, 0.6677, 0.5891, 0.5807,
        0.6076, 0.6148, 0.5857, 0.6738, 0.5699, 0.6615, 0.6308],
       device='cuda:0') torch.Size([16])
percent tensor([0.6177, 0.6417, 0.6119, 0.6645, 0.6256, 0.7262, 0.6265, 0.5899, 0.6622,
        0.6324, 0.6586, 0.6588, 0.6265, 0.6799, 0.6861, 0.6606],
       device='cuda:0') torch.Size([16])
percent tensor([0.6053, 0.6109, 0.5974, 0.5725, 0.6194, 0.5764, 0.6222, 0.5570, 0.6702,
        0.6473, 0.6598, 0.5050, 0.6027, 0.7331, 0.4812, 0.6291],
       device='cuda:0') torch.Size([16])
percent tensor([0.6127, 0.5899, 0.7112, 0.7074, 0.7502, 0.7465, 0.6595, 0.6906, 0.6504,
        0.6307, 0.6209, 0.6825, 0.6140, 0.6378, 0.6589, 0.6739],
       device='cuda:0') torch.Size([16])
percent tensor([0.5738, 0.7146, 0.7239, 0.6801, 0.6863, 0.6005, 0.5392, 0.6043, 0.7068,
        0.6447, 0.7159, 0.6901, 0.6959, 0.6267, 0.5699, 0.4807],
       device='cuda:0') torch.Size([16])
percent tensor([0.9997, 0.9998, 0.9998, 0.9999, 0.9997, 0.9997, 0.9997, 0.9994, 0.9998,
        0.9998, 1.0000, 0.9998, 0.9999, 0.9994, 0.9988, 0.9994],
       device='cuda:0') torch.Size([16])
True Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=128, out_features=16, bias=False)
False Linear(in_features=16, out_features=2, bias=False)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=128, out_features=16, bias=False)
False Linear(in_features=16, out_features=2, bias=False)
True Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=256, out_features=32, bias=False)
False Linear(in_features=32, out_features=2, bias=False)
True Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=256, out_features=32, bias=False)
False Linear(in_features=32, out_features=2, bias=False)
True Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=512, out_features=64, bias=False)
False Linear(in_features=64, out_features=2, bias=False)
True Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=512, out_features=64, bias=False)
False Linear(in_features=64, out_features=2, bias=False)
True Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1024, out_features=128, bias=False)
False Linear(in_features=128, out_features=2, bias=False)
True Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1024, out_features=128, bias=False)
False Linear(in_features=128, out_features=2, bias=False)
True Linear(in_features=512, out_features=10, bias=True)
Epoch: 160 | Batch_idx: 0 |  Loss: (0.1487) |  Loss2: (0.0000) | Acc: (92.00%) (118/128)
Epoch: 160 | Batch_idx: 10 |  Loss: (0.0993) |  Loss2: (0.0000) | Acc: (96.00%) (1364/1408)
Epoch: 160 | Batch_idx: 20 |  Loss: (0.1123) |  Loss2: (0.0000) | Acc: (96.00%) (2585/2688)
Epoch: 160 | Batch_idx: 30 |  Loss: (0.1139) |  Loss2: (0.0000) | Acc: (96.00%) (3811/3968)
Epoch: 160 | Batch_idx: 40 |  Loss: (0.1159) |  Loss2: (0.0000) | Acc: (95.00%) (5038/5248)
Epoch: 160 | Batch_idx: 50 |  Loss: (0.1177) |  Loss2: (0.0000) | Acc: (96.00%) (6269/6528)
Epoch: 160 | Batch_idx: 60 |  Loss: (0.1211) |  Loss2: (0.0000) | Acc: (95.00%) (7491/7808)
Epoch: 160 | Batch_idx: 70 |  Loss: (0.1193) |  Loss2: (0.0000) | Acc: (95.00%) (8720/9088)
Epoch: 160 | Batch_idx: 80 |  Loss: (0.1181) |  Loss2: (0.0000) | Acc: (95.00%) (9947/10368)
Epoch: 160 | Batch_idx: 90 |  Loss: (0.1169) |  Loss2: (0.0000) | Acc: (96.00%) (11184/11648)
Epoch: 160 | Batch_idx: 100 |  Loss: (0.1173) |  Loss2: (0.0000) | Acc: (96.00%) (12412/12928)
Epoch: 160 | Batch_idx: 110 |  Loss: (0.1173) |  Loss2: (0.0000) | Acc: (95.00%) (13639/14208)
Epoch: 160 | Batch_idx: 120 |  Loss: (0.1170) |  Loss2: (0.0000) | Acc: (96.00%) (14869/15488)
Epoch: 160 | Batch_idx: 130 |  Loss: (0.1171) |  Loss2: (0.0000) | Acc: (96.00%) (16102/16768)
Epoch: 160 | Batch_idx: 140 |  Loss: (0.1186) |  Loss2: (0.0000) | Acc: (95.00%) (17317/18048)
Epoch: 160 | Batch_idx: 150 |  Loss: (0.1192) |  Loss2: (0.0000) | Acc: (95.00%) (18537/19328)
Epoch: 160 | Batch_idx: 160 |  Loss: (0.1193) |  Loss2: (0.0000) | Acc: (95.00%) (19772/20608)
Epoch: 160 | Batch_idx: 170 |  Loss: (0.1196) |  Loss2: (0.0000) | Acc: (95.00%) (20996/21888)
Epoch: 160 | Batch_idx: 180 |  Loss: (0.1195) |  Loss2: (0.0000) | Acc: (95.00%) (22221/23168)
Epoch: 160 | Batch_idx: 190 |  Loss: (0.1208) |  Loss2: (0.0000) | Acc: (95.00%) (23438/24448)
Epoch: 160 | Batch_idx: 200 |  Loss: (0.1206) |  Loss2: (0.0000) | Acc: (95.00%) (24665/25728)
Epoch: 160 | Batch_idx: 210 |  Loss: (0.1211) |  Loss2: (0.0000) | Acc: (95.00%) (25891/27008)
Epoch: 160 | Batch_idx: 220 |  Loss: (0.1211) |  Loss2: (0.0000) | Acc: (95.00%) (27117/28288)
Epoch: 160 | Batch_idx: 230 |  Loss: (0.1213) |  Loss2: (0.0000) | Acc: (95.00%) (28336/29568)
Epoch: 160 | Batch_idx: 240 |  Loss: (0.1217) |  Loss2: (0.0000) | Acc: (95.00%) (29562/30848)
Epoch: 160 | Batch_idx: 250 |  Loss: (0.1215) |  Loss2: (0.0000) | Acc: (95.00%) (30794/32128)
Epoch: 160 | Batch_idx: 260 |  Loss: (0.1216) |  Loss2: (0.0000) | Acc: (95.00%) (32022/33408)
Epoch: 160 | Batch_idx: 270 |  Loss: (0.1222) |  Loss2: (0.0000) | Acc: (95.00%) (33238/34688)
Epoch: 160 | Batch_idx: 280 |  Loss: (0.1223) |  Loss2: (0.0000) | Acc: (95.00%) (34456/35968)
Epoch: 160 | Batch_idx: 290 |  Loss: (0.1216) |  Loss2: (0.0000) | Acc: (95.00%) (35701/37248)
Epoch: 160 | Batch_idx: 300 |  Loss: (0.1219) |  Loss2: (0.0000) | Acc: (95.00%) (36930/38528)
Epoch: 160 | Batch_idx: 310 |  Loss: (0.1217) |  Loss2: (0.0000) | Acc: (95.00%) (38159/39808)
Epoch: 160 | Batch_idx: 320 |  Loss: (0.1219) |  Loss2: (0.0000) | Acc: (95.00%) (39386/41088)
Epoch: 160 | Batch_idx: 330 |  Loss: (0.1219) |  Loss2: (0.0000) | Acc: (95.00%) (40610/42368)
Epoch: 160 | Batch_idx: 340 |  Loss: (0.1221) |  Loss2: (0.0000) | Acc: (95.00%) (41840/43648)
Epoch: 160 | Batch_idx: 350 |  Loss: (0.1225) |  Loss2: (0.0000) | Acc: (95.00%) (43066/44928)
Epoch: 160 | Batch_idx: 360 |  Loss: (0.1226) |  Loss2: (0.0000) | Acc: (95.00%) (44289/46208)
Epoch: 160 | Batch_idx: 370 |  Loss: (0.1228) |  Loss2: (0.0000) | Acc: (95.00%) (45518/47488)
Epoch: 160 | Batch_idx: 380 |  Loss: (0.1231) |  Loss2: (0.0000) | Acc: (95.00%) (46737/48768)
Epoch: 160 | Batch_idx: 390 |  Loss: (0.1235) |  Loss2: (0.0000) | Acc: (95.00%) (47915/50000)
=> saving checkpoint 'drive/app/torch/save_Schedule/checkpoint_160.pth.tar'
# TEST : Loss: (0.4396) | Acc: (87.00%) (8751/10000)
percent tensor([0.5005, 0.5003, 0.5147, 0.4994, 0.5128, 0.4997, 0.5051, 0.5028, 0.5024,
        0.5056, 0.5028, 0.5123, 0.4998, 0.4941, 0.5003, 0.4978],
       device='cuda:0') torch.Size([16])
percent tensor([0.4989, 0.4782, 0.4989, 0.4985, 0.4925, 0.5077, 0.4840, 0.4866, 0.5020,
        0.4874, 0.5013, 0.4943, 0.4867, 0.4930, 0.4853, 0.4969],
       device='cuda:0') torch.Size([16])
percent tensor([0.6537, 0.6334, 0.5791, 0.5464, 0.5826, 0.6059, 0.6545, 0.5889, 0.5774,
        0.5990, 0.6097, 0.5637, 0.6671, 0.5748, 0.6608, 0.6322],
       device='cuda:0') torch.Size([16])
percent tensor([0.6200, 0.6350, 0.6175, 0.6832, 0.6366, 0.7243, 0.6426, 0.5967, 0.6587,
        0.6307, 0.6522, 0.6850, 0.6290, 0.6727, 0.6856, 0.6533],
       device='cuda:0') torch.Size([16])
percent tensor([0.5839, 0.5941, 0.5901, 0.5650, 0.6197, 0.5692, 0.6024, 0.5565, 0.6432,
        0.6338, 0.6482, 0.5167, 0.5832, 0.7171, 0.4735, 0.6275],
       device='cuda:0') torch.Size([16])
percent tensor([0.6270, 0.5914, 0.7185, 0.7199, 0.7511, 0.7359, 0.6584, 0.6986, 0.6553,
        0.6341, 0.6292, 0.6872, 0.6163, 0.6362, 0.6571, 0.6763],
       device='cuda:0') torch.Size([16])
percent tensor([0.5809, 0.7352, 0.7297, 0.6890, 0.6646, 0.5716, 0.5186, 0.6060, 0.6940,
        0.6256, 0.7237, 0.6453, 0.7091, 0.6157, 0.5820, 0.4692],
       device='cuda:0') torch.Size([16])
percent tensor([0.9996, 0.9998, 0.9999, 0.9999, 0.9996, 0.9995, 0.9997, 0.9991, 0.9997,
        0.9998, 1.0000, 0.9998, 0.9999, 0.9993, 0.9989, 0.9992],
       device='cuda:0') torch.Size([16])
Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 3, 3, 3]) tensor(190.9228, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(821.8083, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(826.9691, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([128, 64, 3, 3]) tensor(1526.7849, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([128, 64, 1, 1]) tensor(482.3256, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([128, 128, 3, 3]) tensor(2303.0066, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([256, 128, 3, 3]) tensor(4266.3887, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([256, 128, 1, 1]) tensor(1362.9406, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([256, 256, 3, 3]) tensor(6213.3120, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([512, 256, 3, 3]) tensor(11655.9600, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([512, 256, 1, 1]) tensor(3850.4001, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([512, 512, 3, 3]) tensor(16252.3057, device='cuda:0', grad_fn=<NormBackward0>)
Epoch: 161 | Batch_idx: 0 |  Loss: (0.0859) |  Loss2: (0.0000) | Acc: (96.00%) (124/128)
Epoch: 161 | Batch_idx: 10 |  Loss: (0.1240) |  Loss2: (0.0000) | Acc: (95.00%) (1344/1408)
Epoch: 161 | Batch_idx: 20 |  Loss: (0.1151) |  Loss2: (0.0000) | Acc: (95.00%) (2575/2688)
Epoch: 161 | Batch_idx: 30 |  Loss: (0.1175) |  Loss2: (0.0000) | Acc: (95.00%) (3798/3968)
Epoch: 161 | Batch_idx: 40 |  Loss: (0.1223) |  Loss2: (0.0000) | Acc: (95.00%) (5013/5248)
Epoch: 161 | Batch_idx: 50 |  Loss: (0.1226) |  Loss2: (0.0000) | Acc: (95.00%) (6238/6528)
Epoch: 161 | Batch_idx: 60 |  Loss: (0.1205) |  Loss2: (0.0000) | Acc: (95.00%) (7469/7808)
Epoch: 161 | Batch_idx: 70 |  Loss: (0.1224) |  Loss2: (0.0000) | Acc: (95.00%) (8694/9088)
Epoch: 161 | Batch_idx: 80 |  Loss: (0.1217) |  Loss2: (0.0000) | Acc: (95.00%) (9922/10368)
Epoch: 161 | Batch_idx: 90 |  Loss: (0.1203) |  Loss2: (0.0000) | Acc: (95.00%) (11149/11648)
Epoch: 161 | Batch_idx: 100 |  Loss: (0.1188) |  Loss2: (0.0000) | Acc: (95.00%) (12386/12928)
Epoch: 161 | Batch_idx: 110 |  Loss: (0.1199) |  Loss2: (0.0000) | Acc: (95.00%) (13605/14208)
Epoch: 161 | Batch_idx: 120 |  Loss: (0.1212) |  Loss2: (0.0000) | Acc: (95.00%) (14828/15488)
Epoch: 161 | Batch_idx: 130 |  Loss: (0.1213) |  Loss2: (0.0000) | Acc: (95.00%) (16050/16768)
Epoch: 161 | Batch_idx: 140 |  Loss: (0.1213) |  Loss2: (0.0000) | Acc: (95.00%) (17277/18048)
Epoch: 161 | Batch_idx: 150 |  Loss: (0.1210) |  Loss2: (0.0000) | Acc: (95.00%) (18503/19328)
Epoch: 161 | Batch_idx: 160 |  Loss: (0.1218) |  Loss2: (0.0000) | Acc: (95.00%) (19728/20608)
Epoch: 161 | Batch_idx: 170 |  Loss: (0.1211) |  Loss2: (0.0000) | Acc: (95.00%) (20963/21888)
Epoch: 161 | Batch_idx: 180 |  Loss: (0.1204) |  Loss2: (0.0000) | Acc: (95.00%) (22193/23168)
Epoch: 161 | Batch_idx: 190 |  Loss: (0.1202) |  Loss2: (0.0000) | Acc: (95.00%) (23421/24448)
Epoch: 161 | Batch_idx: 200 |  Loss: (0.1202) |  Loss2: (0.0000) | Acc: (95.00%) (24651/25728)
Epoch: 161 | Batch_idx: 210 |  Loss: (0.1197) |  Loss2: (0.0000) | Acc: (95.00%) (25881/27008)
Epoch: 161 | Batch_idx: 220 |  Loss: (0.1195) |  Loss2: (0.0000) | Acc: (95.00%) (27108/28288)
Epoch: 161 | Batch_idx: 230 |  Loss: (0.1188) |  Loss2: (0.0000) | Acc: (95.00%) (28343/29568)
Epoch: 161 | Batch_idx: 240 |  Loss: (0.1199) |  Loss2: (0.0000) | Acc: (95.00%) (29559/30848)
Epoch: 161 | Batch_idx: 250 |  Loss: (0.1200) |  Loss2: (0.0000) | Acc: (95.00%) (30792/32128)
Epoch: 161 | Batch_idx: 260 |  Loss: (0.1207) |  Loss2: (0.0000) | Acc: (95.00%) (32002/33408)
Epoch: 161 | Batch_idx: 270 |  Loss: (0.1201) |  Loss2: (0.0000) | Acc: (95.00%) (33232/34688)
Epoch: 161 | Batch_idx: 280 |  Loss: (0.1209) |  Loss2: (0.0000) | Acc: (95.00%) (34441/35968)
Epoch: 161 | Batch_idx: 290 |  Loss: (0.1206) |  Loss2: (0.0000) | Acc: (95.00%) (35670/37248)
Epoch: 161 | Batch_idx: 300 |  Loss: (0.1204) |  Loss2: (0.0000) | Acc: (95.00%) (36905/38528)
Epoch: 161 | Batch_idx: 310 |  Loss: (0.1209) |  Loss2: (0.0000) | Acc: (95.00%) (38124/39808)
Epoch: 161 | Batch_idx: 320 |  Loss: (0.1204) |  Loss2: (0.0000) | Acc: (95.00%) (39358/41088)
Epoch: 161 | Batch_idx: 330 |  Loss: (0.1204) |  Loss2: (0.0000) | Acc: (95.00%) (40592/42368)
Epoch: 161 | Batch_idx: 340 |  Loss: (0.1206) |  Loss2: (0.0000) | Acc: (95.00%) (41817/43648)
Epoch: 161 | Batch_idx: 350 |  Loss: (0.1203) |  Loss2: (0.0000) | Acc: (95.00%) (43048/44928)
Epoch: 161 | Batch_idx: 360 |  Loss: (0.1202) |  Loss2: (0.0000) | Acc: (95.00%) (44272/46208)
Epoch: 161 | Batch_idx: 370 |  Loss: (0.1204) |  Loss2: (0.0000) | Acc: (95.00%) (45501/47488)
Epoch: 161 | Batch_idx: 380 |  Loss: (0.1207) |  Loss2: (0.0000) | Acc: (95.00%) (46723/48768)
Epoch: 161 | Batch_idx: 390 |  Loss: (0.1204) |  Loss2: (0.0000) | Acc: (95.00%) (47910/50000)
# TEST : Loss: (0.4347) | Acc: (87.00%) (8784/10000)
percent tensor([0.5006, 0.5010, 0.5136, 0.4996, 0.5122, 0.5002, 0.5055, 0.5026, 0.5024,
        0.5057, 0.5032, 0.5115, 0.4999, 0.4957, 0.5010, 0.4982],
       device='cuda:0') torch.Size([16])
percent tensor([0.4995, 0.4802, 0.5000, 0.5017, 0.4917, 0.5106, 0.4846, 0.4865, 0.5029,
        0.4875, 0.5012, 0.4958, 0.4873, 0.4982, 0.4882, 0.4975],
       device='cuda:0') torch.Size([16])
percent tensor([0.6498, 0.6427, 0.5777, 0.5530, 0.5861, 0.6089, 0.6645, 0.5915, 0.5791,
        0.6082, 0.6168, 0.5731, 0.6691, 0.5736, 0.6676, 0.6352],
       device='cuda:0') torch.Size([16])
percent tensor([0.6206, 0.6362, 0.6113, 0.6662, 0.6243, 0.7278, 0.6415, 0.5857, 0.6616,
        0.6306, 0.6561, 0.6700, 0.6325, 0.6936, 0.6795, 0.6497],
       device='cuda:0') torch.Size([16])
percent tensor([0.5884, 0.6014, 0.5970, 0.5749, 0.6256, 0.5811, 0.6149, 0.5519, 0.6580,
        0.6353, 0.6402, 0.5354, 0.5828, 0.7390, 0.4882, 0.6209],
       device='cuda:0') torch.Size([16])
percent tensor([0.6183, 0.5838, 0.7113, 0.7202, 0.7552, 0.7525, 0.6528, 0.6924, 0.6537,
        0.6240, 0.6309, 0.6809, 0.6281, 0.6340, 0.6509, 0.6728],
       device='cuda:0') torch.Size([16])
percent tensor([0.5904, 0.7256, 0.7172, 0.6739, 0.6675, 0.6372, 0.5193, 0.6013, 0.6976,
        0.6582, 0.7485, 0.6476, 0.6992, 0.6017, 0.5878, 0.5018],
       device='cuda:0') torch.Size([16])
percent tensor([0.9997, 0.9999, 0.9998, 0.9998, 0.9996, 0.9996, 0.9998, 0.9990, 0.9997,
        0.9999, 1.0000, 0.9998, 0.9999, 0.9997, 0.9993, 0.9994],
       device='cuda:0') torch.Size([16])
Epoch: 162 | Batch_idx: 0 |  Loss: (0.1120) |  Loss2: (0.0000) | Acc: (94.00%) (121/128)
Epoch: 162 | Batch_idx: 10 |  Loss: (0.0884) |  Loss2: (0.0000) | Acc: (97.00%) (1367/1408)
Epoch: 162 | Batch_idx: 20 |  Loss: (0.1040) |  Loss2: (0.0000) | Acc: (96.00%) (2597/2688)
Epoch: 162 | Batch_idx: 30 |  Loss: (0.1047) |  Loss2: (0.0000) | Acc: (96.00%) (3839/3968)
Epoch: 162 | Batch_idx: 40 |  Loss: (0.1041) |  Loss2: (0.0000) | Acc: (96.00%) (5075/5248)
Epoch: 162 | Batch_idx: 50 |  Loss: (0.1032) |  Loss2: (0.0000) | Acc: (96.00%) (6318/6528)
Epoch: 162 | Batch_idx: 60 |  Loss: (0.1013) |  Loss2: (0.0000) | Acc: (96.00%) (7558/7808)
Epoch: 162 | Batch_idx: 70 |  Loss: (0.1049) |  Loss2: (0.0000) | Acc: (96.00%) (8774/9088)
Epoch: 162 | Batch_idx: 80 |  Loss: (0.1036) |  Loss2: (0.0000) | Acc: (96.00%) (10016/10368)
Epoch: 162 | Batch_idx: 90 |  Loss: (0.1035) |  Loss2: (0.0000) | Acc: (96.00%) (11253/11648)
Epoch: 162 | Batch_idx: 100 |  Loss: (0.1041) |  Loss2: (0.0000) | Acc: (96.00%) (12487/12928)
Epoch: 162 | Batch_idx: 110 |  Loss: (0.1055) |  Loss2: (0.0000) | Acc: (96.00%) (13713/14208)
Epoch: 162 | Batch_idx: 120 |  Loss: (0.1062) |  Loss2: (0.0000) | Acc: (96.00%) (14941/15488)
Epoch: 162 | Batch_idx: 130 |  Loss: (0.1066) |  Loss2: (0.0000) | Acc: (96.00%) (16177/16768)
Epoch: 162 | Batch_idx: 140 |  Loss: (0.1068) |  Loss2: (0.0000) | Acc: (96.00%) (17413/18048)
Epoch: 162 | Batch_idx: 150 |  Loss: (0.1064) |  Loss2: (0.0000) | Acc: (96.00%) (18652/19328)
Epoch: 162 | Batch_idx: 160 |  Loss: (0.1061) |  Loss2: (0.0000) | Acc: (96.00%) (19891/20608)
Epoch: 162 | Batch_idx: 170 |  Loss: (0.1073) |  Loss2: (0.0000) | Acc: (96.00%) (21116/21888)
Epoch: 162 | Batch_idx: 180 |  Loss: (0.1074) |  Loss2: (0.0000) | Acc: (96.00%) (22352/23168)
Epoch: 162 | Batch_idx: 190 |  Loss: (0.1082) |  Loss2: (0.0000) | Acc: (96.00%) (23572/24448)
Epoch: 162 | Batch_idx: 200 |  Loss: (0.1085) |  Loss2: (0.0000) | Acc: (96.00%) (24802/25728)
Epoch: 162 | Batch_idx: 210 |  Loss: (0.1086) |  Loss2: (0.0000) | Acc: (96.00%) (26031/27008)
Epoch: 162 | Batch_idx: 220 |  Loss: (0.1087) |  Loss2: (0.0000) | Acc: (96.00%) (27263/28288)
Epoch: 162 | Batch_idx: 230 |  Loss: (0.1103) |  Loss2: (0.0000) | Acc: (96.00%) (28473/29568)
Epoch: 162 | Batch_idx: 240 |  Loss: (0.1119) |  Loss2: (0.0000) | Acc: (96.00%) (29691/30848)
Epoch: 162 | Batch_idx: 250 |  Loss: (0.1124) |  Loss2: (0.0000) | Acc: (96.00%) (30913/32128)
Epoch: 162 | Batch_idx: 260 |  Loss: (0.1125) |  Loss2: (0.0000) | Acc: (96.00%) (32141/33408)
Epoch: 162 | Batch_idx: 270 |  Loss: (0.1127) |  Loss2: (0.0000) | Acc: (96.00%) (33369/34688)
Epoch: 162 | Batch_idx: 280 |  Loss: (0.1130) |  Loss2: (0.0000) | Acc: (96.00%) (34592/35968)
Epoch: 162 | Batch_idx: 290 |  Loss: (0.1134) |  Loss2: (0.0000) | Acc: (96.00%) (35809/37248)
Epoch: 162 | Batch_idx: 300 |  Loss: (0.1135) |  Loss2: (0.0000) | Acc: (96.00%) (37041/38528)
Epoch: 162 | Batch_idx: 310 |  Loss: (0.1137) |  Loss2: (0.0000) | Acc: (96.00%) (38269/39808)
Epoch: 162 | Batch_idx: 320 |  Loss: (0.1136) |  Loss2: (0.0000) | Acc: (96.00%) (39502/41088)
Epoch: 162 | Batch_idx: 330 |  Loss: (0.1146) |  Loss2: (0.0000) | Acc: (96.00%) (40714/42368)
Epoch: 162 | Batch_idx: 340 |  Loss: (0.1151) |  Loss2: (0.0000) | Acc: (96.00%) (41935/43648)
Epoch: 162 | Batch_idx: 350 |  Loss: (0.1150) |  Loss2: (0.0000) | Acc: (96.00%) (43164/44928)
Epoch: 162 | Batch_idx: 360 |  Loss: (0.1145) |  Loss2: (0.0000) | Acc: (96.00%) (44399/46208)
Epoch: 162 | Batch_idx: 370 |  Loss: (0.1153) |  Loss2: (0.0000) | Acc: (96.00%) (45609/47488)
Epoch: 162 | Batch_idx: 380 |  Loss: (0.1152) |  Loss2: (0.0000) | Acc: (96.00%) (46845/48768)
Epoch: 162 | Batch_idx: 390 |  Loss: (0.1159) |  Loss2: (0.0000) | Acc: (96.00%) (48019/50000)
# TEST : Loss: (0.4481) | Acc: (87.00%) (8732/10000)
percent tensor([0.5004, 0.5004, 0.5135, 0.4990, 0.5116, 0.4997, 0.5044, 0.5029, 0.5017,
        0.5052, 0.5029, 0.5114, 0.4998, 0.4946, 0.5003, 0.4978],
       device='cuda:0') torch.Size([16])
percent tensor([0.5014, 0.4814, 0.5001, 0.5040, 0.4940, 0.5111, 0.4859, 0.4887, 0.5038,
        0.4882, 0.5023, 0.4959, 0.4882, 0.4990, 0.4902, 0.5002],
       device='cuda:0') torch.Size([16])
percent tensor([0.6578, 0.6371, 0.5863, 0.5512, 0.5907, 0.6004, 0.6630, 0.5927, 0.5887,
        0.6095, 0.6174, 0.5810, 0.6743, 0.5679, 0.6583, 0.6359],
       device='cuda:0') torch.Size([16])
percent tensor([0.6250, 0.6378, 0.6035, 0.6664, 0.6230, 0.7253, 0.6331, 0.5854, 0.6679,
        0.6258, 0.6618, 0.6578, 0.6315, 0.6828, 0.6846, 0.6567],
       device='cuda:0') torch.Size([16])
percent tensor([0.5785, 0.5991, 0.6040, 0.5730, 0.6310, 0.5723, 0.6181, 0.5581, 0.6440,
        0.6439, 0.6475, 0.5349, 0.5773, 0.7292, 0.4787, 0.6181],
       device='cuda:0') torch.Size([16])
percent tensor([0.6182, 0.5918, 0.7209, 0.7251, 0.7636, 0.7360, 0.6576, 0.6964, 0.6506,
        0.6307, 0.6197, 0.6724, 0.6139, 0.6300, 0.6506, 0.6703],
       device='cuda:0') torch.Size([16])
percent tensor([0.6079, 0.7491, 0.7333, 0.6804, 0.7068, 0.5780, 0.5359, 0.6248, 0.7207,
        0.6820, 0.7379, 0.6832, 0.7030, 0.6434, 0.5946, 0.4787],
       device='cuda:0') torch.Size([16])
percent tensor([0.9998, 0.9999, 0.9998, 0.9999, 0.9997, 0.9996, 0.9996, 0.9991, 0.9998,
        0.9999, 0.9999, 0.9999, 0.9999, 0.9997, 0.9988, 0.9995],
       device='cuda:0') torch.Size([16])
Epoch: 163 | Batch_idx: 0 |  Loss: (0.0812) |  Loss2: (0.0000) | Acc: (97.00%) (125/128)
Epoch: 163 | Batch_idx: 10 |  Loss: (0.0923) |  Loss2: (0.0000) | Acc: (96.00%) (1362/1408)
Epoch: 163 | Batch_idx: 20 |  Loss: (0.1082) |  Loss2: (0.0000) | Acc: (95.00%) (2574/2688)
Epoch: 163 | Batch_idx: 30 |  Loss: (0.1113) |  Loss2: (0.0000) | Acc: (95.00%) (3802/3968)
Epoch: 163 | Batch_idx: 40 |  Loss: (0.1151) |  Loss2: (0.0000) | Acc: (95.00%) (5020/5248)
Epoch: 163 | Batch_idx: 50 |  Loss: (0.1146) |  Loss2: (0.0000) | Acc: (95.00%) (6254/6528)
Epoch: 163 | Batch_idx: 60 |  Loss: (0.1130) |  Loss2: (0.0000) | Acc: (95.00%) (7495/7808)
Epoch: 163 | Batch_idx: 70 |  Loss: (0.1151) |  Loss2: (0.0000) | Acc: (95.00%) (8714/9088)
Epoch: 163 | Batch_idx: 80 |  Loss: (0.1167) |  Loss2: (0.0000) | Acc: (95.00%) (9935/10368)
Epoch: 163 | Batch_idx: 90 |  Loss: (0.1169) |  Loss2: (0.0000) | Acc: (95.00%) (11170/11648)
Epoch: 163 | Batch_idx: 100 |  Loss: (0.1173) |  Loss2: (0.0000) | Acc: (95.00%) (12397/12928)
Epoch: 163 | Batch_idx: 110 |  Loss: (0.1174) |  Loss2: (0.0000) | Acc: (95.00%) (13628/14208)
Epoch: 163 | Batch_idx: 120 |  Loss: (0.1172) |  Loss2: (0.0000) | Acc: (95.00%) (14862/15488)
Epoch: 163 | Batch_idx: 130 |  Loss: (0.1166) |  Loss2: (0.0000) | Acc: (95.00%) (16094/16768)
Epoch: 163 | Batch_idx: 140 |  Loss: (0.1153) |  Loss2: (0.0000) | Acc: (96.00%) (17334/18048)
Epoch: 163 | Batch_idx: 150 |  Loss: (0.1147) |  Loss2: (0.0000) | Acc: (96.00%) (18570/19328)
Epoch: 163 | Batch_idx: 160 |  Loss: (0.1146) |  Loss2: (0.0000) | Acc: (96.00%) (19801/20608)
Epoch: 163 | Batch_idx: 170 |  Loss: (0.1135) |  Loss2: (0.0000) | Acc: (96.00%) (21043/21888)
Epoch: 163 | Batch_idx: 180 |  Loss: (0.1131) |  Loss2: (0.0000) | Acc: (96.00%) (22273/23168)
Epoch: 163 | Batch_idx: 190 |  Loss: (0.1132) |  Loss2: (0.0000) | Acc: (96.00%) (23505/24448)
Epoch: 163 | Batch_idx: 200 |  Loss: (0.1134) |  Loss2: (0.0000) | Acc: (96.00%) (24743/25728)
Epoch: 163 | Batch_idx: 210 |  Loss: (0.1132) |  Loss2: (0.0000) | Acc: (96.00%) (25974/27008)
Epoch: 163 | Batch_idx: 220 |  Loss: (0.1144) |  Loss2: (0.0000) | Acc: (96.00%) (27189/28288)
Epoch: 163 | Batch_idx: 230 |  Loss: (0.1138) |  Loss2: (0.0000) | Acc: (96.00%) (28427/29568)
Epoch: 163 | Batch_idx: 240 |  Loss: (0.1137) |  Loss2: (0.0000) | Acc: (96.00%) (29662/30848)
Epoch: 163 | Batch_idx: 250 |  Loss: (0.1136) |  Loss2: (0.0000) | Acc: (96.00%) (30889/32128)
Epoch: 163 | Batch_idx: 260 |  Loss: (0.1142) |  Loss2: (0.0000) | Acc: (96.00%) (32108/33408)
Epoch: 163 | Batch_idx: 270 |  Loss: (0.1158) |  Loss2: (0.0000) | Acc: (96.00%) (33313/34688)
Epoch: 163 | Batch_idx: 280 |  Loss: (0.1157) |  Loss2: (0.0000) | Acc: (96.00%) (34545/35968)
Epoch: 163 | Batch_idx: 290 |  Loss: (0.1154) |  Loss2: (0.0000) | Acc: (96.00%) (35789/37248)
Epoch: 163 | Batch_idx: 300 |  Loss: (0.1147) |  Loss2: (0.0000) | Acc: (96.00%) (37029/38528)
Epoch: 163 | Batch_idx: 310 |  Loss: (0.1148) |  Loss2: (0.0000) | Acc: (96.00%) (38254/39808)
Epoch: 163 | Batch_idx: 320 |  Loss: (0.1147) |  Loss2: (0.0000) | Acc: (96.00%) (39487/41088)
Epoch: 163 | Batch_idx: 330 |  Loss: (0.1143) |  Loss2: (0.0000) | Acc: (96.00%) (40723/42368)
Epoch: 163 | Batch_idx: 340 |  Loss: (0.1146) |  Loss2: (0.0000) | Acc: (96.00%) (41951/43648)
Epoch: 163 | Batch_idx: 350 |  Loss: (0.1147) |  Loss2: (0.0000) | Acc: (96.00%) (43185/44928)
Epoch: 163 | Batch_idx: 360 |  Loss: (0.1153) |  Loss2: (0.0000) | Acc: (96.00%) (44403/46208)
Epoch: 163 | Batch_idx: 370 |  Loss: (0.1151) |  Loss2: (0.0000) | Acc: (96.00%) (45631/47488)
Epoch: 163 | Batch_idx: 380 |  Loss: (0.1151) |  Loss2: (0.0000) | Acc: (96.00%) (46865/48768)
Epoch: 163 | Batch_idx: 390 |  Loss: (0.1156) |  Loss2: (0.0000) | Acc: (96.00%) (48035/50000)
# TEST : Loss: (0.4499) | Acc: (87.00%) (8702/10000)
percent tensor([0.4999, 0.5007, 0.5143, 0.4991, 0.5124, 0.4995, 0.5052, 0.5028, 0.5019,
        0.5056, 0.5026, 0.5120, 0.4995, 0.4953, 0.5004, 0.4976],
       device='cuda:0') torch.Size([16])
percent tensor([0.5006, 0.4815, 0.4994, 0.4995, 0.4918, 0.5121, 0.4855, 0.4862, 0.5031,
        0.4877, 0.5017, 0.4946, 0.4878, 0.4997, 0.4903, 0.4993],
       device='cuda:0') torch.Size([16])
percent tensor([0.6517, 0.6475, 0.5717, 0.5541, 0.5800, 0.5970, 0.6667, 0.5964, 0.5980,
        0.6055, 0.6207, 0.5725, 0.6763, 0.5837, 0.6645, 0.6387],
       device='cuda:0') torch.Size([16])
percent tensor([0.6176, 0.6395, 0.6203, 0.6833, 0.6279, 0.7220, 0.6459, 0.5814, 0.6686,
        0.6343, 0.6530, 0.6806, 0.6321, 0.6880, 0.6798, 0.6510],
       device='cuda:0') torch.Size([16])
percent tensor([0.5975, 0.6024, 0.6065, 0.5737, 0.6281, 0.6015, 0.6176, 0.5626, 0.6592,
        0.6405, 0.6515, 0.5360, 0.5862, 0.7270, 0.4865, 0.6287],
       device='cuda:0') torch.Size([16])
percent tensor([0.6086, 0.5828, 0.7028, 0.7153, 0.7451, 0.7268, 0.6575, 0.6860, 0.6643,
        0.6310, 0.6364, 0.6827, 0.6171, 0.6394, 0.6435, 0.6627],
       device='cuda:0') torch.Size([16])
percent tensor([0.5948, 0.7365, 0.6990, 0.6905, 0.6863, 0.5681, 0.5535, 0.5908, 0.7192,
        0.6807, 0.7594, 0.6870, 0.7038, 0.6395, 0.5721, 0.4772],
       device='cuda:0') torch.Size([16])
percent tensor([0.9997, 0.9999, 0.9998, 0.9999, 0.9998, 0.9993, 0.9997, 0.9994, 0.9998,
        0.9999, 1.0000, 0.9999, 0.9998, 0.9997, 0.9993, 0.9995],
       device='cuda:0') torch.Size([16])
Epoch: 164 | Batch_idx: 0 |  Loss: (0.0991) |  Loss2: (0.0000) | Acc: (96.00%) (123/128)
Epoch: 164 | Batch_idx: 10 |  Loss: (0.1138) |  Loss2: (0.0000) | Acc: (96.00%) (1357/1408)
Epoch: 164 | Batch_idx: 20 |  Loss: (0.1153) |  Loss2: (0.0000) | Acc: (96.00%) (2582/2688)
Epoch: 164 | Batch_idx: 30 |  Loss: (0.1073) |  Loss2: (0.0000) | Acc: (96.00%) (3819/3968)
Epoch: 164 | Batch_idx: 40 |  Loss: (0.1060) |  Loss2: (0.0000) | Acc: (96.00%) (5054/5248)
Epoch: 164 | Batch_idx: 50 |  Loss: (0.1080) |  Loss2: (0.0000) | Acc: (96.00%) (6289/6528)
Epoch: 164 | Batch_idx: 60 |  Loss: (0.1085) |  Loss2: (0.0000) | Acc: (96.00%) (7517/7808)
Epoch: 164 | Batch_idx: 70 |  Loss: (0.1079) |  Loss2: (0.0000) | Acc: (96.00%) (8747/9088)
Epoch: 164 | Batch_idx: 80 |  Loss: (0.1066) |  Loss2: (0.0000) | Acc: (96.00%) (9988/10368)
Epoch: 164 | Batch_idx: 90 |  Loss: (0.1084) |  Loss2: (0.0000) | Acc: (96.00%) (11213/11648)
Epoch: 164 | Batch_idx: 100 |  Loss: (0.1078) |  Loss2: (0.0000) | Acc: (96.00%) (12451/12928)
Epoch: 164 | Batch_idx: 110 |  Loss: (0.1073) |  Loss2: (0.0000) | Acc: (96.00%) (13688/14208)
Epoch: 164 | Batch_idx: 120 |  Loss: (0.1074) |  Loss2: (0.0000) | Acc: (96.00%) (14920/15488)
Epoch: 164 | Batch_idx: 130 |  Loss: (0.1062) |  Loss2: (0.0000) | Acc: (96.00%) (16159/16768)
Epoch: 164 | Batch_idx: 140 |  Loss: (0.1054) |  Loss2: (0.0000) | Acc: (96.00%) (17401/18048)
Epoch: 164 | Batch_idx: 150 |  Loss: (0.1058) |  Loss2: (0.0000) | Acc: (96.00%) (18638/19328)
Epoch: 164 | Batch_idx: 160 |  Loss: (0.1056) |  Loss2: (0.0000) | Acc: (96.00%) (19870/20608)
Epoch: 164 | Batch_idx: 170 |  Loss: (0.1057) |  Loss2: (0.0000) | Acc: (96.00%) (21106/21888)
Epoch: 164 | Batch_idx: 180 |  Loss: (0.1056) |  Loss2: (0.0000) | Acc: (96.00%) (22340/23168)
Epoch: 164 | Batch_idx: 190 |  Loss: (0.1052) |  Loss2: (0.0000) | Acc: (96.00%) (23577/24448)
Epoch: 164 | Batch_idx: 200 |  Loss: (0.1047) |  Loss2: (0.0000) | Acc: (96.00%) (24818/25728)
Epoch: 164 | Batch_idx: 210 |  Loss: (0.1043) |  Loss2: (0.0000) | Acc: (96.00%) (26055/27008)
Epoch: 164 | Batch_idx: 220 |  Loss: (0.1049) |  Loss2: (0.0000) | Acc: (96.00%) (27284/28288)
Epoch: 164 | Batch_idx: 230 |  Loss: (0.1044) |  Loss2: (0.0000) | Acc: (96.00%) (28519/29568)
Epoch: 164 | Batch_idx: 240 |  Loss: (0.1049) |  Loss2: (0.0000) | Acc: (96.00%) (29745/30848)
Epoch: 164 | Batch_idx: 250 |  Loss: (0.1059) |  Loss2: (0.0000) | Acc: (96.00%) (30967/32128)
Epoch: 164 | Batch_idx: 260 |  Loss: (0.1059) |  Loss2: (0.0000) | Acc: (96.00%) (32201/33408)
Epoch: 164 | Batch_idx: 270 |  Loss: (0.1064) |  Loss2: (0.0000) | Acc: (96.00%) (33431/34688)
Epoch: 164 | Batch_idx: 280 |  Loss: (0.1072) |  Loss2: (0.0000) | Acc: (96.00%) (34650/35968)
Epoch: 164 | Batch_idx: 290 |  Loss: (0.1073) |  Loss2: (0.0000) | Acc: (96.00%) (35884/37248)
Epoch: 164 | Batch_idx: 300 |  Loss: (0.1075) |  Loss2: (0.0000) | Acc: (96.00%) (37118/38528)
Epoch: 164 | Batch_idx: 310 |  Loss: (0.1071) |  Loss2: (0.0000) | Acc: (96.00%) (38361/39808)
Epoch: 164 | Batch_idx: 320 |  Loss: (0.1067) |  Loss2: (0.0000) | Acc: (96.00%) (39597/41088)
Epoch: 164 | Batch_idx: 330 |  Loss: (0.1067) |  Loss2: (0.0000) | Acc: (96.00%) (40830/42368)
Epoch: 164 | Batch_idx: 340 |  Loss: (0.1065) |  Loss2: (0.0000) | Acc: (96.00%) (42057/43648)
Epoch: 164 | Batch_idx: 350 |  Loss: (0.1068) |  Loss2: (0.0000) | Acc: (96.00%) (43283/44928)
Epoch: 164 | Batch_idx: 360 |  Loss: (0.1071) |  Loss2: (0.0000) | Acc: (96.00%) (44512/46208)
Epoch: 164 | Batch_idx: 370 |  Loss: (0.1073) |  Loss2: (0.0000) | Acc: (96.00%) (45740/47488)
Epoch: 164 | Batch_idx: 380 |  Loss: (0.1072) |  Loss2: (0.0000) | Acc: (96.00%) (46978/48768)
Epoch: 164 | Batch_idx: 390 |  Loss: (0.1076) |  Loss2: (0.0000) | Acc: (96.00%) (48165/50000)
# TEST : Loss: (0.4259) | Acc: (87.00%) (8799/10000)
percent tensor([0.5003, 0.5012, 0.5144, 0.5001, 0.5126, 0.4995, 0.5054, 0.5032, 0.5019,
        0.5058, 0.5024, 0.5119, 0.4996, 0.4963, 0.5008, 0.4979],
       device='cuda:0') torch.Size([16])
percent tensor([0.4990, 0.4802, 0.4974, 0.5001, 0.4908, 0.5112, 0.4845, 0.4872, 0.5032,
        0.4859, 0.5016, 0.4917, 0.4853, 0.4990, 0.4889, 0.4984],
       device='cuda:0') torch.Size([16])
percent tensor([0.6644, 0.6404, 0.5767, 0.5495, 0.5838, 0.6129, 0.6648, 0.5946, 0.5984,
        0.6164, 0.6252, 0.5821, 0.6838, 0.5689, 0.6681, 0.6444],
       device='cuda:0') torch.Size([16])
percent tensor([0.6194, 0.6323, 0.6086, 0.6659, 0.6297, 0.7245, 0.6341, 0.5818, 0.6713,
        0.6282, 0.6556, 0.6589, 0.6293, 0.6841, 0.6761, 0.6588],
       device='cuda:0') torch.Size([16])
percent tensor([0.5924, 0.6136, 0.5905, 0.5623, 0.6251, 0.5932, 0.6345, 0.5551, 0.6420,
        0.6407, 0.6499, 0.5226, 0.5840, 0.7339, 0.4980, 0.6293],
       device='cuda:0') torch.Size([16])
percent tensor([0.6221, 0.5911, 0.7095, 0.7117, 0.7498, 0.7382, 0.6511, 0.6880, 0.6570,
        0.6341, 0.6322, 0.6681, 0.6239, 0.6306, 0.6466, 0.6777],
       device='cuda:0') torch.Size([16])
percent tensor([0.6095, 0.7343, 0.7202, 0.6923, 0.6798, 0.6024, 0.5376, 0.5856, 0.7082,
        0.6680, 0.7495, 0.6776, 0.6859, 0.6113, 0.5880, 0.4709],
       device='cuda:0') torch.Size([16])
percent tensor([0.9998, 0.9998, 0.9998, 0.9998, 0.9997, 0.9995, 0.9996, 0.9992, 0.9999,
        0.9998, 1.0000, 0.9999, 0.9999, 0.9993, 0.9991, 0.9993],
       device='cuda:0') torch.Size([16])
Epoch: 165 | Batch_idx: 0 |  Loss: (0.0527) |  Loss2: (0.0000) | Acc: (98.00%) (126/128)
Epoch: 165 | Batch_idx: 10 |  Loss: (0.0955) |  Loss2: (0.0000) | Acc: (96.00%) (1357/1408)
Epoch: 165 | Batch_idx: 20 |  Loss: (0.0956) |  Loss2: (0.0000) | Acc: (96.00%) (2596/2688)
Epoch: 165 | Batch_idx: 30 |  Loss: (0.0981) |  Loss2: (0.0000) | Acc: (96.00%) (3834/3968)
Epoch: 165 | Batch_idx: 40 |  Loss: (0.1025) |  Loss2: (0.0000) | Acc: (96.00%) (5055/5248)
Epoch: 165 | Batch_idx: 50 |  Loss: (0.1031) |  Loss2: (0.0000) | Acc: (96.00%) (6293/6528)
Epoch: 165 | Batch_idx: 60 |  Loss: (0.1071) |  Loss2: (0.0000) | Acc: (96.00%) (7508/7808)
Epoch: 165 | Batch_idx: 70 |  Loss: (0.1040) |  Loss2: (0.0000) | Acc: (96.00%) (8755/9088)
Epoch: 165 | Batch_idx: 80 |  Loss: (0.1042) |  Loss2: (0.0000) | Acc: (96.00%) (9990/10368)
Epoch: 165 | Batch_idx: 90 |  Loss: (0.1046) |  Loss2: (0.0000) | Acc: (96.00%) (11225/11648)
Epoch: 165 | Batch_idx: 100 |  Loss: (0.1064) |  Loss2: (0.0000) | Acc: (96.00%) (12449/12928)
Epoch: 165 | Batch_idx: 110 |  Loss: (0.1061) |  Loss2: (0.0000) | Acc: (96.00%) (13683/14208)
Epoch: 165 | Batch_idx: 120 |  Loss: (0.1060) |  Loss2: (0.0000) | Acc: (96.00%) (14919/15488)
Epoch: 165 | Batch_idx: 130 |  Loss: (0.1054) |  Loss2: (0.0000) | Acc: (96.00%) (16160/16768)
Epoch: 165 | Batch_idx: 140 |  Loss: (0.1048) |  Loss2: (0.0000) | Acc: (96.00%) (17395/18048)
Epoch: 165 | Batch_idx: 150 |  Loss: (0.1063) |  Loss2: (0.0000) | Acc: (96.00%) (18616/19328)
Epoch: 165 | Batch_idx: 160 |  Loss: (0.1064) |  Loss2: (0.0000) | Acc: (96.00%) (19845/20608)
Epoch: 165 | Batch_idx: 170 |  Loss: (0.1066) |  Loss2: (0.0000) | Acc: (96.00%) (21083/21888)
Epoch: 165 | Batch_idx: 180 |  Loss: (0.1075) |  Loss2: (0.0000) | Acc: (96.00%) (22309/23168)
Epoch: 165 | Batch_idx: 190 |  Loss: (0.1080) |  Loss2: (0.0000) | Acc: (96.00%) (23546/24448)
Epoch: 165 | Batch_idx: 200 |  Loss: (0.1075) |  Loss2: (0.0000) | Acc: (96.00%) (24782/25728)
Epoch: 165 | Batch_idx: 210 |  Loss: (0.1069) |  Loss2: (0.0000) | Acc: (96.00%) (26015/27008)
Epoch: 165 | Batch_idx: 220 |  Loss: (0.1068) |  Loss2: (0.0000) | Acc: (96.00%) (27248/28288)
Epoch: 165 | Batch_idx: 230 |  Loss: (0.1070) |  Loss2: (0.0000) | Acc: (96.00%) (28480/29568)
Epoch: 165 | Batch_idx: 240 |  Loss: (0.1070) |  Loss2: (0.0000) | Acc: (96.00%) (29707/30848)
Epoch: 165 | Batch_idx: 250 |  Loss: (0.1071) |  Loss2: (0.0000) | Acc: (96.00%) (30940/32128)
Epoch: 165 | Batch_idx: 260 |  Loss: (0.1071) |  Loss2: (0.0000) | Acc: (96.00%) (32175/33408)
Epoch: 165 | Batch_idx: 270 |  Loss: (0.1066) |  Loss2: (0.0000) | Acc: (96.00%) (33418/34688)
Epoch: 165 | Batch_idx: 280 |  Loss: (0.1075) |  Loss2: (0.0000) | Acc: (96.00%) (34643/35968)
Epoch: 165 | Batch_idx: 290 |  Loss: (0.1077) |  Loss2: (0.0000) | Acc: (96.00%) (35869/37248)
Epoch: 165 | Batch_idx: 300 |  Loss: (0.1078) |  Loss2: (0.0000) | Acc: (96.00%) (37102/38528)
Epoch: 165 | Batch_idx: 310 |  Loss: (0.1074) |  Loss2: (0.0000) | Acc: (96.00%) (38350/39808)
Epoch: 165 | Batch_idx: 320 |  Loss: (0.1073) |  Loss2: (0.0000) | Acc: (96.00%) (39582/41088)
Epoch: 165 | Batch_idx: 330 |  Loss: (0.1076) |  Loss2: (0.0000) | Acc: (96.00%) (40807/42368)
Epoch: 165 | Batch_idx: 340 |  Loss: (0.1075) |  Loss2: (0.0000) | Acc: (96.00%) (42042/43648)
Epoch: 165 | Batch_idx: 350 |  Loss: (0.1076) |  Loss2: (0.0000) | Acc: (96.00%) (43275/44928)
Epoch: 165 | Batch_idx: 360 |  Loss: (0.1075) |  Loss2: (0.0000) | Acc: (96.00%) (44508/46208)
Epoch: 165 | Batch_idx: 370 |  Loss: (0.1076) |  Loss2: (0.0000) | Acc: (96.00%) (45734/47488)
Epoch: 165 | Batch_idx: 380 |  Loss: (0.1072) |  Loss2: (0.0000) | Acc: (96.00%) (46968/48768)
Epoch: 165 | Batch_idx: 390 |  Loss: (0.1073) |  Loss2: (0.0000) | Acc: (96.00%) (48150/50000)
=> saving checkpoint 'drive/app/torch/save_Schedule/checkpoint_165.pth.tar'
# TEST : Loss: (0.4488) | Acc: (87.00%) (8734/10000)
percent tensor([0.5006, 0.5004, 0.5158, 0.4995, 0.5138, 0.5000, 0.5052, 0.5034, 0.5023,
        0.5057, 0.5026, 0.5128, 0.4998, 0.4946, 0.5005, 0.4979],
       device='cuda:0') torch.Size([16])
percent tensor([0.4996, 0.4786, 0.4990, 0.5024, 0.4921, 0.5109, 0.4829, 0.4875, 0.5029,
        0.4867, 0.5010, 0.4926, 0.4869, 0.4942, 0.4881, 0.4989],
       device='cuda:0') torch.Size([16])
percent tensor([0.6499, 0.6473, 0.5846, 0.5522, 0.5891, 0.5993, 0.6672, 0.5957, 0.5928,
        0.6068, 0.6184, 0.5755, 0.6736, 0.5909, 0.6606, 0.6347],
       device='cuda:0') torch.Size([16])
percent tensor([0.6200, 0.6376, 0.6091, 0.6676, 0.6241, 0.7283, 0.6379, 0.5731, 0.6700,
        0.6241, 0.6527, 0.6704, 0.6301, 0.6880, 0.6786, 0.6504],
       device='cuda:0') torch.Size([16])
percent tensor([0.5816, 0.5905, 0.5853, 0.5628, 0.6224, 0.5776, 0.6094, 0.5513, 0.6589,
        0.6260, 0.6529, 0.5154, 0.5717, 0.7206, 0.4773, 0.6264],
       device='cuda:0') torch.Size([16])
percent tensor([0.6215, 0.5917, 0.7277, 0.7297, 0.7541, 0.7341, 0.6584, 0.7032, 0.6685,
        0.6343, 0.6406, 0.6903, 0.6240, 0.6368, 0.6504, 0.6741],
       device='cuda:0') torch.Size([16])
percent tensor([0.6136, 0.7511, 0.7462, 0.6969, 0.7095, 0.5848, 0.5746, 0.6208, 0.7242,
        0.6739, 0.7585, 0.6893, 0.7139, 0.6356, 0.5995, 0.4653],
       device='cuda:0') torch.Size([16])
percent tensor([0.9998, 0.9998, 0.9999, 0.9999, 0.9998, 0.9996, 0.9997, 0.9993, 0.9997,
        0.9998, 1.0000, 0.9999, 0.9999, 0.9998, 0.9987, 0.9996],
       device='cuda:0') torch.Size([16])
Epoch: 166 | Batch_idx: 0 |  Loss: (0.1282) |  Loss2: (0.0000) | Acc: (96.00%) (123/128)
Epoch: 166 | Batch_idx: 10 |  Loss: (0.0975) |  Loss2: (0.0000) | Acc: (96.00%) (1362/1408)
Epoch: 166 | Batch_idx: 20 |  Loss: (0.1047) |  Loss2: (0.0000) | Acc: (96.00%) (2589/2688)
Epoch: 166 | Batch_idx: 30 |  Loss: (0.1035) |  Loss2: (0.0000) | Acc: (96.00%) (3819/3968)
Epoch: 166 | Batch_idx: 40 |  Loss: (0.1016) |  Loss2: (0.0000) | Acc: (96.00%) (5056/5248)
Epoch: 166 | Batch_idx: 50 |  Loss: (0.0978) |  Loss2: (0.0000) | Acc: (96.00%) (6300/6528)
Epoch: 166 | Batch_idx: 60 |  Loss: (0.0980) |  Loss2: (0.0000) | Acc: (96.00%) (7535/7808)
Epoch: 166 | Batch_idx: 70 |  Loss: (0.0991) |  Loss2: (0.0000) | Acc: (96.00%) (8774/9088)
Epoch: 166 | Batch_idx: 80 |  Loss: (0.0973) |  Loss2: (0.0000) | Acc: (96.00%) (10013/10368)
Epoch: 166 | Batch_idx: 90 |  Loss: (0.0983) |  Loss2: (0.0000) | Acc: (96.00%) (11241/11648)
Epoch: 166 | Batch_idx: 100 |  Loss: (0.0983) |  Loss2: (0.0000) | Acc: (96.00%) (12478/12928)
Epoch: 166 | Batch_idx: 110 |  Loss: (0.0975) |  Loss2: (0.0000) | Acc: (96.00%) (13724/14208)
Epoch: 166 | Batch_idx: 120 |  Loss: (0.0982) |  Loss2: (0.0000) | Acc: (96.00%) (14955/15488)
Epoch: 166 | Batch_idx: 130 |  Loss: (0.0965) |  Loss2: (0.0000) | Acc: (96.00%) (16202/16768)
Epoch: 166 | Batch_idx: 140 |  Loss: (0.0962) |  Loss2: (0.0000) | Acc: (96.00%) (17436/18048)
Epoch: 166 | Batch_idx: 150 |  Loss: (0.0963) |  Loss2: (0.0000) | Acc: (96.00%) (18673/19328)
Epoch: 166 | Batch_idx: 160 |  Loss: (0.0968) |  Loss2: (0.0000) | Acc: (96.00%) (19905/20608)
Epoch: 166 | Batch_idx: 170 |  Loss: (0.0977) |  Loss2: (0.0000) | Acc: (96.00%) (21125/21888)
Epoch: 166 | Batch_idx: 180 |  Loss: (0.0976) |  Loss2: (0.0000) | Acc: (96.00%) (22362/23168)
Epoch: 166 | Batch_idx: 190 |  Loss: (0.0975) |  Loss2: (0.0000) | Acc: (96.00%) (23591/24448)
Epoch: 166 | Batch_idx: 200 |  Loss: (0.0976) |  Loss2: (0.0000) | Acc: (96.00%) (24824/25728)
Epoch: 166 | Batch_idx: 210 |  Loss: (0.0971) |  Loss2: (0.0000) | Acc: (96.00%) (26072/27008)
Epoch: 166 | Batch_idx: 220 |  Loss: (0.0976) |  Loss2: (0.0000) | Acc: (96.00%) (27306/28288)
Epoch: 166 | Batch_idx: 230 |  Loss: (0.0976) |  Loss2: (0.0000) | Acc: (96.00%) (28538/29568)
Epoch: 166 | Batch_idx: 240 |  Loss: (0.0972) |  Loss2: (0.0000) | Acc: (96.00%) (29779/30848)
Epoch: 166 | Batch_idx: 250 |  Loss: (0.0979) |  Loss2: (0.0000) | Acc: (96.00%) (31015/32128)
Epoch: 166 | Batch_idx: 260 |  Loss: (0.0987) |  Loss2: (0.0000) | Acc: (96.00%) (32245/33408)
Epoch: 166 | Batch_idx: 270 |  Loss: (0.0998) |  Loss2: (0.0000) | Acc: (96.00%) (33472/34688)
Epoch: 166 | Batch_idx: 280 |  Loss: (0.0994) |  Loss2: (0.0000) | Acc: (96.00%) (34712/35968)
Epoch: 166 | Batch_idx: 290 |  Loss: (0.0996) |  Loss2: (0.0000) | Acc: (96.00%) (35950/37248)
Epoch: 166 | Batch_idx: 300 |  Loss: (0.0996) |  Loss2: (0.0000) | Acc: (96.00%) (37187/38528)
Epoch: 166 | Batch_idx: 310 |  Loss: (0.1004) |  Loss2: (0.0000) | Acc: (96.00%) (38409/39808)
Epoch: 166 | Batch_idx: 320 |  Loss: (0.1011) |  Loss2: (0.0000) | Acc: (96.00%) (39633/41088)
Epoch: 166 | Batch_idx: 330 |  Loss: (0.1015) |  Loss2: (0.0000) | Acc: (96.00%) (40865/42368)
Epoch: 166 | Batch_idx: 340 |  Loss: (0.1021) |  Loss2: (0.0000) | Acc: (96.00%) (42091/43648)
Epoch: 166 | Batch_idx: 350 |  Loss: (0.1024) |  Loss2: (0.0000) | Acc: (96.00%) (43323/44928)
Epoch: 166 | Batch_idx: 360 |  Loss: (0.1028) |  Loss2: (0.0000) | Acc: (96.00%) (44548/46208)
Epoch: 166 | Batch_idx: 370 |  Loss: (0.1031) |  Loss2: (0.0000) | Acc: (96.00%) (45771/47488)
Epoch: 166 | Batch_idx: 380 |  Loss: (0.1037) |  Loss2: (0.0000) | Acc: (96.00%) (46992/48768)
Epoch: 166 | Batch_idx: 390 |  Loss: (0.1038) |  Loss2: (0.0000) | Acc: (96.00%) (48179/50000)
# TEST : Loss: (0.4158) | Acc: (87.00%) (8781/10000)
percent tensor([0.5002, 0.5009, 0.5136, 0.4996, 0.5117, 0.4993, 0.5049, 0.5032, 0.5018,
        0.5057, 0.5027, 0.5114, 0.4998, 0.4955, 0.5008, 0.4982],
       device='cuda:0') torch.Size([16])
percent tensor([0.5010, 0.4817, 0.5022, 0.5023, 0.4923, 0.5119, 0.4860, 0.4890, 0.5025,
        0.4884, 0.5027, 0.4961, 0.4881, 0.4984, 0.4897, 0.4994],
       device='cuda:0') torch.Size([16])
percent tensor([0.6511, 0.6478, 0.5690, 0.5443, 0.5795, 0.5964, 0.6651, 0.5928, 0.5991,
        0.6068, 0.6275, 0.5671, 0.6796, 0.5782, 0.6637, 0.6353],
       device='cuda:0') torch.Size([16])
percent tensor([0.6242, 0.6563, 0.6150, 0.6725, 0.6313, 0.7294, 0.6465, 0.5868, 0.6726,
        0.6422, 0.6710, 0.6782, 0.6409, 0.6967, 0.6907, 0.6641],
       device='cuda:0') torch.Size([16])
percent tensor([0.5946, 0.5957, 0.6135, 0.5769, 0.6353, 0.5990, 0.6147, 0.5597, 0.6519,
        0.6343, 0.6449, 0.5398, 0.5795, 0.7246, 0.4845, 0.6253],
       device='cuda:0') torch.Size([16])
percent tensor([0.6219, 0.5854, 0.7214, 0.7342, 0.7579, 0.7380, 0.6613, 0.6977, 0.6605,
        0.6296, 0.6380, 0.6824, 0.6175, 0.6273, 0.6602, 0.6730],
       device='cuda:0') torch.Size([16])
percent tensor([0.6003, 0.6985, 0.7208, 0.6990, 0.7088, 0.5946, 0.5495, 0.6083, 0.7136,
        0.6459, 0.7410, 0.6636, 0.6896, 0.6226, 0.5744, 0.4653],
       device='cuda:0') torch.Size([16])
percent tensor([0.9997, 0.9998, 0.9997, 0.9998, 0.9996, 0.9994, 0.9996, 0.9995, 0.9997,
        0.9998, 1.0000, 0.9998, 0.9998, 0.9995, 0.9989, 0.9991],
       device='cuda:0') torch.Size([16])
Epoch: 167 | Batch_idx: 0 |  Loss: (0.0545) |  Loss2: (0.0000) | Acc: (97.00%) (125/128)
Epoch: 167 | Batch_idx: 10 |  Loss: (0.1107) |  Loss2: (0.0000) | Acc: (95.00%) (1350/1408)
Epoch: 167 | Batch_idx: 20 |  Loss: (0.1037) |  Loss2: (0.0000) | Acc: (96.00%) (2586/2688)
Epoch: 167 | Batch_idx: 30 |  Loss: (0.1010) |  Loss2: (0.0000) | Acc: (96.00%) (3822/3968)
Epoch: 167 | Batch_idx: 40 |  Loss: (0.1004) |  Loss2: (0.0000) | Acc: (96.00%) (5061/5248)
Epoch: 167 | Batch_idx: 50 |  Loss: (0.1013) |  Loss2: (0.0000) | Acc: (96.00%) (6292/6528)
Epoch: 167 | Batch_idx: 60 |  Loss: (0.1009) |  Loss2: (0.0000) | Acc: (96.00%) (7532/7808)
Epoch: 167 | Batch_idx: 70 |  Loss: (0.0999) |  Loss2: (0.0000) | Acc: (96.00%) (8768/9088)
Epoch: 167 | Batch_idx: 80 |  Loss: (0.0986) |  Loss2: (0.0000) | Acc: (96.00%) (10004/10368)
Epoch: 167 | Batch_idx: 90 |  Loss: (0.0978) |  Loss2: (0.0000) | Acc: (96.00%) (11245/11648)
Epoch: 167 | Batch_idx: 100 |  Loss: (0.0987) |  Loss2: (0.0000) | Acc: (96.00%) (12470/12928)
Epoch: 167 | Batch_idx: 110 |  Loss: (0.0995) |  Loss2: (0.0000) | Acc: (96.00%) (13706/14208)
Epoch: 167 | Batch_idx: 120 |  Loss: (0.1011) |  Loss2: (0.0000) | Acc: (96.00%) (14938/15488)
Epoch: 167 | Batch_idx: 130 |  Loss: (0.1015) |  Loss2: (0.0000) | Acc: (96.00%) (16175/16768)
Epoch: 167 | Batch_idx: 140 |  Loss: (0.1004) |  Loss2: (0.0000) | Acc: (96.00%) (17422/18048)
Epoch: 167 | Batch_idx: 150 |  Loss: (0.1020) |  Loss2: (0.0000) | Acc: (96.00%) (18642/19328)
Epoch: 167 | Batch_idx: 160 |  Loss: (0.1016) |  Loss2: (0.0000) | Acc: (96.00%) (19878/20608)
Epoch: 167 | Batch_idx: 170 |  Loss: (0.1014) |  Loss2: (0.0000) | Acc: (96.00%) (21111/21888)
Epoch: 167 | Batch_idx: 180 |  Loss: (0.1013) |  Loss2: (0.0000) | Acc: (96.00%) (22346/23168)
Epoch: 167 | Batch_idx: 190 |  Loss: (0.1010) |  Loss2: (0.0000) | Acc: (96.00%) (23585/24448)
Epoch: 167 | Batch_idx: 200 |  Loss: (0.1002) |  Loss2: (0.0000) | Acc: (96.00%) (24828/25728)
Epoch: 167 | Batch_idx: 210 |  Loss: (0.0999) |  Loss2: (0.0000) | Acc: (96.00%) (26067/27008)
Epoch: 167 | Batch_idx: 220 |  Loss: (0.0991) |  Loss2: (0.0000) | Acc: (96.00%) (27310/28288)
Epoch: 167 | Batch_idx: 230 |  Loss: (0.0991) |  Loss2: (0.0000) | Acc: (96.00%) (28549/29568)
Epoch: 167 | Batch_idx: 240 |  Loss: (0.0994) |  Loss2: (0.0000) | Acc: (96.00%) (29781/30848)
Epoch: 167 | Batch_idx: 250 |  Loss: (0.1004) |  Loss2: (0.0000) | Acc: (96.00%) (30999/32128)
Epoch: 167 | Batch_idx: 260 |  Loss: (0.1006) |  Loss2: (0.0000) | Acc: (96.00%) (32238/33408)
Epoch: 167 | Batch_idx: 270 |  Loss: (0.1007) |  Loss2: (0.0000) | Acc: (96.00%) (33476/34688)
Epoch: 167 | Batch_idx: 280 |  Loss: (0.1005) |  Loss2: (0.0000) | Acc: (96.00%) (34718/35968)
Epoch: 167 | Batch_idx: 290 |  Loss: (0.1005) |  Loss2: (0.0000) | Acc: (96.00%) (35954/37248)
Epoch: 167 | Batch_idx: 300 |  Loss: (0.1011) |  Loss2: (0.0000) | Acc: (96.00%) (37174/38528)
Epoch: 167 | Batch_idx: 310 |  Loss: (0.1021) |  Loss2: (0.0000) | Acc: (96.00%) (38402/39808)
Epoch: 167 | Batch_idx: 320 |  Loss: (0.1026) |  Loss2: (0.0000) | Acc: (96.00%) (39622/41088)
Epoch: 167 | Batch_idx: 330 |  Loss: (0.1029) |  Loss2: (0.0000) | Acc: (96.00%) (40849/42368)
Epoch: 167 | Batch_idx: 340 |  Loss: (0.1038) |  Loss2: (0.0000) | Acc: (96.00%) (42069/43648)
Epoch: 167 | Batch_idx: 350 |  Loss: (0.1039) |  Loss2: (0.0000) | Acc: (96.00%) (43293/44928)
Epoch: 167 | Batch_idx: 360 |  Loss: (0.1040) |  Loss2: (0.0000) | Acc: (96.00%) (44538/46208)
Epoch: 167 | Batch_idx: 370 |  Loss: (0.1041) |  Loss2: (0.0000) | Acc: (96.00%) (45763/47488)
Epoch: 167 | Batch_idx: 380 |  Loss: (0.1043) |  Loss2: (0.0000) | Acc: (96.00%) (46993/48768)
Epoch: 167 | Batch_idx: 390 |  Loss: (0.1048) |  Loss2: (0.0000) | Acc: (96.00%) (48164/50000)
# TEST : Loss: (0.5016) | Acc: (86.00%) (8618/10000)
percent tensor([0.5008, 0.5004, 0.5154, 0.4990, 0.5135, 0.4995, 0.5053, 0.5030, 0.5027,
        0.5058, 0.5031, 0.5126, 0.5001, 0.4950, 0.5002, 0.4981],
       device='cuda:0') torch.Size([16])
percent tensor([0.5007, 0.4824, 0.4966, 0.4965, 0.4893, 0.5107, 0.4865, 0.4866, 0.5052,
        0.4881, 0.5045, 0.4910, 0.4878, 0.5012, 0.4894, 0.4998],
       device='cuda:0') torch.Size([16])
percent tensor([0.6448, 0.6430, 0.5770, 0.5501, 0.5817, 0.5994, 0.6592, 0.5922, 0.5785,
        0.6062, 0.6094, 0.5758, 0.6656, 0.5751, 0.6638, 0.6318],
       device='cuda:0') torch.Size([16])
percent tensor([0.6131, 0.6335, 0.6142, 0.6787, 0.6270, 0.7322, 0.6323, 0.5868, 0.6561,
        0.6267, 0.6527, 0.6700, 0.6181, 0.6843, 0.6822, 0.6561],
       device='cuda:0') torch.Size([16])
percent tensor([0.5938, 0.6070, 0.5844, 0.5658, 0.6197, 0.5926, 0.6137, 0.5396, 0.6571,
        0.6356, 0.6510, 0.5052, 0.5866, 0.7354, 0.4887, 0.6378],
       device='cuda:0') torch.Size([16])
percent tensor([0.6151, 0.5787, 0.7078, 0.7227, 0.7414, 0.7414, 0.6443, 0.6819, 0.6484,
        0.6243, 0.6308, 0.6751, 0.6045, 0.6268, 0.6529, 0.6711],
       device='cuda:0') torch.Size([16])
percent tensor([0.5723, 0.7051, 0.7133, 0.6831, 0.6928, 0.5673, 0.5411, 0.5918, 0.6956,
        0.6357, 0.7470, 0.6684, 0.6744, 0.5671, 0.5626, 0.4609],
       device='cuda:0') torch.Size([16])
percent tensor([0.9998, 0.9997, 0.9997, 0.9999, 0.9995, 0.9995, 0.9996, 0.9995, 0.9998,
        0.9999, 1.0000, 0.9999, 0.9999, 0.9995, 0.9990, 0.9996],
       device='cuda:0') torch.Size([16])
False Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=128, out_features=16, bias=False)
True Linear(in_features=16, out_features=2, bias=False)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=128, out_features=16, bias=False)
True Linear(in_features=16, out_features=2, bias=False)
False Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=256, out_features=32, bias=False)
True Linear(in_features=32, out_features=2, bias=False)
False Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=256, out_features=32, bias=False)
True Linear(in_features=32, out_features=2, bias=False)
False Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=512, out_features=64, bias=False)
True Linear(in_features=64, out_features=2, bias=False)
False Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=512, out_features=64, bias=False)
True Linear(in_features=64, out_features=2, bias=False)
False Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1024, out_features=128, bias=False)
True Linear(in_features=128, out_features=2, bias=False)
False Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1024, out_features=128, bias=False)
True Linear(in_features=128, out_features=2, bias=False)
False Linear(in_features=512, out_features=10, bias=True)
Epoch: 168 | Batch_idx: 0 |  Loss: (0.0398) |  Loss2: (0.0000) | Acc: (100.00%) (128/128)
Epoch: 168 | Batch_idx: 10 |  Loss: (0.1259) |  Loss2: (0.0000) | Acc: (95.00%) (1350/1408)
Epoch: 168 | Batch_idx: 20 |  Loss: (0.1519) |  Loss2: (0.0000) | Acc: (94.00%) (2550/2688)
Epoch: 168 | Batch_idx: 30 |  Loss: (0.1506) |  Loss2: (0.0000) | Acc: (94.00%) (3763/3968)
Epoch: 168 | Batch_idx: 40 |  Loss: (0.1488) |  Loss2: (0.0000) | Acc: (95.00%) (4986/5248)
Epoch: 168 | Batch_idx: 50 |  Loss: (0.1510) |  Loss2: (0.0000) | Acc: (94.00%) (6189/6528)
Epoch: 168 | Batch_idx: 60 |  Loss: (0.1559) |  Loss2: (0.0000) | Acc: (94.00%) (7391/7808)
Epoch: 168 | Batch_idx: 70 |  Loss: (0.1574) |  Loss2: (0.0000) | Acc: (94.00%) (8596/9088)
Epoch: 168 | Batch_idx: 80 |  Loss: (0.1533) |  Loss2: (0.0000) | Acc: (94.00%) (9823/10368)
Epoch: 168 | Batch_idx: 90 |  Loss: (0.1508) |  Loss2: (0.0000) | Acc: (94.00%) (11050/11648)
Epoch: 168 | Batch_idx: 100 |  Loss: (0.1513) |  Loss2: (0.0000) | Acc: (94.00%) (12261/12928)
Epoch: 168 | Batch_idx: 110 |  Loss: (0.1505) |  Loss2: (0.0000) | Acc: (94.00%) (13478/14208)
Epoch: 168 | Batch_idx: 120 |  Loss: (0.1504) |  Loss2: (0.0000) | Acc: (94.00%) (14687/15488)
Epoch: 168 | Batch_idx: 130 |  Loss: (0.1514) |  Loss2: (0.0000) | Acc: (94.00%) (15901/16768)
Epoch: 168 | Batch_idx: 140 |  Loss: (0.1501) |  Loss2: (0.0000) | Acc: (94.00%) (17119/18048)
Epoch: 168 | Batch_idx: 150 |  Loss: (0.1496) |  Loss2: (0.0000) | Acc: (94.00%) (18330/19328)
Epoch: 168 | Batch_idx: 160 |  Loss: (0.1496) |  Loss2: (0.0000) | Acc: (94.00%) (19542/20608)
Epoch: 168 | Batch_idx: 170 |  Loss: (0.1522) |  Loss2: (0.0000) | Acc: (94.00%) (20733/21888)
Epoch: 168 | Batch_idx: 180 |  Loss: (0.1512) |  Loss2: (0.0000) | Acc: (94.00%) (21951/23168)
Epoch: 168 | Batch_idx: 190 |  Loss: (0.1510) |  Loss2: (0.0000) | Acc: (94.00%) (23168/24448)
Epoch: 168 | Batch_idx: 200 |  Loss: (0.1505) |  Loss2: (0.0000) | Acc: (94.00%) (24388/25728)
Epoch: 168 | Batch_idx: 210 |  Loss: (0.1496) |  Loss2: (0.0000) | Acc: (94.00%) (25610/27008)
Epoch: 168 | Batch_idx: 220 |  Loss: (0.1492) |  Loss2: (0.0000) | Acc: (94.00%) (26828/28288)
Epoch: 168 | Batch_idx: 230 |  Loss: (0.1489) |  Loss2: (0.0000) | Acc: (94.00%) (28050/29568)
Epoch: 168 | Batch_idx: 240 |  Loss: (0.1486) |  Loss2: (0.0000) | Acc: (94.00%) (29264/30848)
Epoch: 168 | Batch_idx: 250 |  Loss: (0.1480) |  Loss2: (0.0000) | Acc: (94.00%) (30481/32128)
Epoch: 168 | Batch_idx: 260 |  Loss: (0.1471) |  Loss2: (0.0000) | Acc: (94.00%) (31704/33408)
Epoch: 168 | Batch_idx: 270 |  Loss: (0.1467) |  Loss2: (0.0000) | Acc: (94.00%) (32917/34688)
Epoch: 168 | Batch_idx: 280 |  Loss: (0.1469) |  Loss2: (0.0000) | Acc: (94.00%) (34124/35968)
Epoch: 168 | Batch_idx: 290 |  Loss: (0.1466) |  Loss2: (0.0000) | Acc: (94.00%) (35342/37248)
Epoch: 168 | Batch_idx: 300 |  Loss: (0.1466) |  Loss2: (0.0000) | Acc: (94.00%) (36550/38528)
Epoch: 168 | Batch_idx: 310 |  Loss: (0.1454) |  Loss2: (0.0000) | Acc: (94.00%) (37782/39808)
Epoch: 168 | Batch_idx: 320 |  Loss: (0.1449) |  Loss2: (0.0000) | Acc: (94.00%) (38998/41088)
Epoch: 168 | Batch_idx: 330 |  Loss: (0.1448) |  Loss2: (0.0000) | Acc: (94.00%) (40217/42368)
Epoch: 168 | Batch_idx: 340 |  Loss: (0.1445) |  Loss2: (0.0000) | Acc: (94.00%) (41445/43648)
Epoch: 168 | Batch_idx: 350 |  Loss: (0.1445) |  Loss2: (0.0000) | Acc: (94.00%) (42657/44928)
Epoch: 168 | Batch_idx: 360 |  Loss: (0.1439) |  Loss2: (0.0000) | Acc: (94.00%) (43880/46208)
Epoch: 168 | Batch_idx: 370 |  Loss: (0.1431) |  Loss2: (0.0000) | Acc: (94.00%) (45108/47488)
Epoch: 168 | Batch_idx: 380 |  Loss: (0.1427) |  Loss2: (0.0000) | Acc: (94.00%) (46325/48768)
Epoch: 168 | Batch_idx: 390 |  Loss: (0.1424) |  Loss2: (0.0000) | Acc: (94.00%) (47498/50000)
# TEST : Loss: (0.4457) | Acc: (87.00%) (8738/10000)
percent tensor([0.4970, 0.4957, 0.5099, 0.4950, 0.5084, 0.4964, 0.5001, 0.4985, 0.4983,
        0.5006, 0.4988, 0.5071, 0.4958, 0.4922, 0.4960, 0.4946],
       device='cuda:0') torch.Size([16])
percent tensor([0.5045, 0.4793, 0.5027, 0.5001, 0.4923, 0.5137, 0.4852, 0.4896, 0.5079,
        0.4872, 0.5050, 0.4929, 0.4882, 0.5005, 0.4894, 0.5014],
       device='cuda:0') torch.Size([16])
percent tensor([0.6319, 0.6332, 0.5798, 0.5530, 0.5782, 0.6013, 0.6451, 0.5910, 0.5678,
        0.5967, 0.5932, 0.5687, 0.6497, 0.5585, 0.6574, 0.6266],
       device='cuda:0') torch.Size([16])
percent tensor([0.5886, 0.5952, 0.6024, 0.6685, 0.6140, 0.7058, 0.6033, 0.5668, 0.6477,
        0.6044, 0.6314, 0.6544, 0.5866, 0.6671, 0.6444, 0.6229],
       device='cuda:0') torch.Size([16])
percent tensor([0.6066, 0.6043, 0.5976, 0.5843, 0.6385, 0.6080, 0.6196, 0.5426, 0.6799,
        0.6433, 0.6654, 0.5163, 0.5965, 0.7487, 0.4822, 0.6428],
       device='cuda:0') torch.Size([16])
percent tensor([0.6438, 0.5983, 0.7335, 0.7480, 0.7636, 0.7566, 0.6719, 0.7069, 0.6758,
        0.6523, 0.6535, 0.7013, 0.6247, 0.6488, 0.6776, 0.6943],
       device='cuda:0') torch.Size([16])
percent tensor([0.5740, 0.7054, 0.6547, 0.6444, 0.6278, 0.5367, 0.5297, 0.5472, 0.6774,
        0.6313, 0.7338, 0.6288, 0.6819, 0.5725, 0.5519, 0.4607],
       device='cuda:0') torch.Size([16])
percent tensor([0.9997, 0.9998, 0.9997, 0.9999, 0.9997, 0.9994, 0.9996, 0.9995, 0.9998,
        0.9998, 1.0000, 0.9998, 0.9999, 0.9995, 0.9990, 0.9995],
       device='cuda:0') torch.Size([16])
Epoch: 169 | Batch_idx: 0 |  Loss: (0.1002) |  Loss2: (0.0000) | Acc: (96.00%) (124/128)
Epoch: 169 | Batch_idx: 10 |  Loss: (0.1215) |  Loss2: (0.0000) | Acc: (95.00%) (1347/1408)
Epoch: 169 | Batch_idx: 20 |  Loss: (0.1254) |  Loss2: (0.0000) | Acc: (95.00%) (2572/2688)
Epoch: 169 | Batch_idx: 30 |  Loss: (0.1266) |  Loss2: (0.0000) | Acc: (95.00%) (3792/3968)
Epoch: 169 | Batch_idx: 40 |  Loss: (0.1237) |  Loss2: (0.0000) | Acc: (95.00%) (5022/5248)
Epoch: 169 | Batch_idx: 50 |  Loss: (0.1250) |  Loss2: (0.0000) | Acc: (95.00%) (6240/6528)
Epoch: 169 | Batch_idx: 60 |  Loss: (0.1240) |  Loss2: (0.0000) | Acc: (95.00%) (7473/7808)
Epoch: 169 | Batch_idx: 70 |  Loss: (0.1231) |  Loss2: (0.0000) | Acc: (95.00%) (8699/9088)
Epoch: 169 | Batch_idx: 80 |  Loss: (0.1236) |  Loss2: (0.0000) | Acc: (95.00%) (9917/10368)
Epoch: 169 | Batch_idx: 90 |  Loss: (0.1246) |  Loss2: (0.0000) | Acc: (95.00%) (11140/11648)
Epoch: 169 | Batch_idx: 100 |  Loss: (0.1236) |  Loss2: (0.0000) | Acc: (95.00%) (12365/12928)
Epoch: 169 | Batch_idx: 110 |  Loss: (0.1261) |  Loss2: (0.0000) | Acc: (95.00%) (13585/14208)
Epoch: 169 | Batch_idx: 120 |  Loss: (0.1277) |  Loss2: (0.0000) | Acc: (95.00%) (14796/15488)
Epoch: 169 | Batch_idx: 130 |  Loss: (0.1268) |  Loss2: (0.0000) | Acc: (95.00%) (16027/16768)
Epoch: 169 | Batch_idx: 140 |  Loss: (0.1266) |  Loss2: (0.0000) | Acc: (95.00%) (17248/18048)
Epoch: 169 | Batch_idx: 150 |  Loss: (0.1275) |  Loss2: (0.0000) | Acc: (95.00%) (18463/19328)
Epoch: 169 | Batch_idx: 160 |  Loss: (0.1278) |  Loss2: (0.0000) | Acc: (95.00%) (19683/20608)
Epoch: 169 | Batch_idx: 170 |  Loss: (0.1270) |  Loss2: (0.0000) | Acc: (95.00%) (20915/21888)
Epoch: 169 | Batch_idx: 180 |  Loss: (0.1274) |  Loss2: (0.0000) | Acc: (95.00%) (22137/23168)
Epoch: 169 | Batch_idx: 190 |  Loss: (0.1267) |  Loss2: (0.0000) | Acc: (95.00%) (23366/24448)
Epoch: 169 | Batch_idx: 200 |  Loss: (0.1265) |  Loss2: (0.0000) | Acc: (95.00%) (24591/25728)
Epoch: 169 | Batch_idx: 210 |  Loss: (0.1263) |  Loss2: (0.0000) | Acc: (95.00%) (25818/27008)
Epoch: 169 | Batch_idx: 220 |  Loss: (0.1256) |  Loss2: (0.0000) | Acc: (95.00%) (27047/28288)
Epoch: 169 | Batch_idx: 230 |  Loss: (0.1250) |  Loss2: (0.0000) | Acc: (95.00%) (28276/29568)
Epoch: 169 | Batch_idx: 240 |  Loss: (0.1256) |  Loss2: (0.0000) | Acc: (95.00%) (29496/30848)
Epoch: 169 | Batch_idx: 250 |  Loss: (0.1247) |  Loss2: (0.0000) | Acc: (95.00%) (30728/32128)
Epoch: 169 | Batch_idx: 260 |  Loss: (0.1239) |  Loss2: (0.0000) | Acc: (95.00%) (31967/33408)
Epoch: 169 | Batch_idx: 270 |  Loss: (0.1234) |  Loss2: (0.0000) | Acc: (95.00%) (33200/34688)
Epoch: 169 | Batch_idx: 280 |  Loss: (0.1238) |  Loss2: (0.0000) | Acc: (95.00%) (34419/35968)
Epoch: 169 | Batch_idx: 290 |  Loss: (0.1234) |  Loss2: (0.0000) | Acc: (95.00%) (35643/37248)
Epoch: 169 | Batch_idx: 300 |  Loss: (0.1235) |  Loss2: (0.0000) | Acc: (95.00%) (36867/38528)
Epoch: 169 | Batch_idx: 310 |  Loss: (0.1231) |  Loss2: (0.0000) | Acc: (95.00%) (38102/39808)
Epoch: 169 | Batch_idx: 320 |  Loss: (0.1221) |  Loss2: (0.0000) | Acc: (95.00%) (39338/41088)
Epoch: 169 | Batch_idx: 330 |  Loss: (0.1218) |  Loss2: (0.0000) | Acc: (95.00%) (40572/42368)
Epoch: 169 | Batch_idx: 340 |  Loss: (0.1211) |  Loss2: (0.0000) | Acc: (95.00%) (41807/43648)
Epoch: 169 | Batch_idx: 350 |  Loss: (0.1208) |  Loss2: (0.0000) | Acc: (95.00%) (43039/44928)
Epoch: 169 | Batch_idx: 360 |  Loss: (0.1208) |  Loss2: (0.0000) | Acc: (95.00%) (44262/46208)
Epoch: 169 | Batch_idx: 370 |  Loss: (0.1206) |  Loss2: (0.0000) | Acc: (95.00%) (45494/47488)
Epoch: 169 | Batch_idx: 380 |  Loss: (0.1207) |  Loss2: (0.0000) | Acc: (95.00%) (46716/48768)
Epoch: 169 | Batch_idx: 390 |  Loss: (0.1204) |  Loss2: (0.0000) | Acc: (95.00%) (47895/50000)
# TEST : Loss: (0.4197) | Acc: (87.00%) (8797/10000)
percent tensor([0.4956, 0.4940, 0.5077, 0.4936, 0.5064, 0.4953, 0.4982, 0.4967, 0.4966,
        0.4987, 0.4971, 0.5051, 0.4942, 0.4921, 0.4945, 0.4933],
       device='cuda:0') torch.Size([16])
percent tensor([0.5051, 0.4777, 0.5029, 0.5015, 0.4927, 0.5150, 0.4836, 0.4898, 0.5084,
        0.4862, 0.5047, 0.4922, 0.4876, 0.5004, 0.4891, 0.5014],
       device='cuda:0') torch.Size([16])
percent tensor([0.6316, 0.6316, 0.5807, 0.5531, 0.5771, 0.6019, 0.6427, 0.5894, 0.5671,
        0.5965, 0.5917, 0.5690, 0.6485, 0.5567, 0.6555, 0.6271],
       device='cuda:0') torch.Size([16])
percent tensor([0.5807, 0.5900, 0.5958, 0.6638, 0.6068, 0.6933, 0.5960, 0.5590, 0.6450,
        0.6006, 0.6288, 0.6501, 0.5812, 0.6646, 0.6354, 0.6109],
       device='cuda:0') torch.Size([16])
percent tensor([0.5961, 0.5983, 0.5900, 0.5784, 0.6304, 0.5982, 0.6103, 0.5355, 0.6705,
        0.6368, 0.6559, 0.5142, 0.5856, 0.7430, 0.4770, 0.6327],
       device='cuda:0') torch.Size([16])
percent tensor([0.6367, 0.5904, 0.7292, 0.7423, 0.7612, 0.7505, 0.6655, 0.7015, 0.6668,
        0.6445, 0.6437, 0.6947, 0.6157, 0.6385, 0.6715, 0.6881],
       device='cuda:0') torch.Size([16])
percent tensor([0.5871, 0.7108, 0.6556, 0.6472, 0.6340, 0.5493, 0.5455, 0.5545, 0.6816,
        0.6438, 0.7329, 0.6327, 0.6850, 0.5837, 0.5713, 0.4751],
       device='cuda:0') torch.Size([16])
percent tensor([0.9997, 0.9998, 0.9997, 0.9999, 0.9997, 0.9994, 0.9996, 0.9996, 0.9998,
        0.9998, 1.0000, 0.9998, 0.9999, 0.9995, 0.9990, 0.9994],
       device='cuda:0') torch.Size([16])
Epoch: 170 | Batch_idx: 0 |  Loss: (0.1092) |  Loss2: (0.0000) | Acc: (96.00%) (123/128)
Epoch: 170 | Batch_idx: 10 |  Loss: (0.1084) |  Loss2: (0.0000) | Acc: (96.00%) (1361/1408)
Epoch: 170 | Batch_idx: 20 |  Loss: (0.1070) |  Loss2: (0.0000) | Acc: (96.00%) (2596/2688)
Epoch: 170 | Batch_idx: 30 |  Loss: (0.1069) |  Loss2: (0.0000) | Acc: (96.00%) (3829/3968)
Epoch: 170 | Batch_idx: 40 |  Loss: (0.1112) |  Loss2: (0.0000) | Acc: (96.00%) (5052/5248)
Epoch: 170 | Batch_idx: 50 |  Loss: (0.1108) |  Loss2: (0.0000) | Acc: (96.00%) (6285/6528)
Epoch: 170 | Batch_idx: 60 |  Loss: (0.1122) |  Loss2: (0.0000) | Acc: (96.00%) (7516/7808)
Epoch: 170 | Batch_idx: 70 |  Loss: (0.1130) |  Loss2: (0.0000) | Acc: (96.00%) (8743/9088)
Epoch: 170 | Batch_idx: 80 |  Loss: (0.1137) |  Loss2: (0.0000) | Acc: (96.00%) (9968/10368)
Epoch: 170 | Batch_idx: 90 |  Loss: (0.1113) |  Loss2: (0.0000) | Acc: (96.00%) (11217/11648)
Epoch: 170 | Batch_idx: 100 |  Loss: (0.1122) |  Loss2: (0.0000) | Acc: (96.00%) (12434/12928)
Epoch: 170 | Batch_idx: 110 |  Loss: (0.1120) |  Loss2: (0.0000) | Acc: (96.00%) (13670/14208)
Epoch: 170 | Batch_idx: 120 |  Loss: (0.1109) |  Loss2: (0.0000) | Acc: (96.00%) (14904/15488)
Epoch: 170 | Batch_idx: 130 |  Loss: (0.1105) |  Loss2: (0.0000) | Acc: (96.00%) (16141/16768)
Epoch: 170 | Batch_idx: 140 |  Loss: (0.1101) |  Loss2: (0.0000) | Acc: (96.00%) (17373/18048)
Epoch: 170 | Batch_idx: 150 |  Loss: (0.1103) |  Loss2: (0.0000) | Acc: (96.00%) (18597/19328)
Epoch: 170 | Batch_idx: 160 |  Loss: (0.1095) |  Loss2: (0.0000) | Acc: (96.00%) (19835/20608)
Epoch: 170 | Batch_idx: 170 |  Loss: (0.1098) |  Loss2: (0.0000) | Acc: (96.00%) (21064/21888)
Epoch: 170 | Batch_idx: 180 |  Loss: (0.1100) |  Loss2: (0.0000) | Acc: (96.00%) (22294/23168)
Epoch: 170 | Batch_idx: 190 |  Loss: (0.1090) |  Loss2: (0.0000) | Acc: (96.00%) (23539/24448)
Epoch: 170 | Batch_idx: 200 |  Loss: (0.1103) |  Loss2: (0.0000) | Acc: (96.00%) (24752/25728)
Epoch: 170 | Batch_idx: 210 |  Loss: (0.1091) |  Loss2: (0.0000) | Acc: (96.00%) (25995/27008)
Epoch: 170 | Batch_idx: 220 |  Loss: (0.1096) |  Loss2: (0.0000) | Acc: (96.00%) (27214/28288)
Epoch: 170 | Batch_idx: 230 |  Loss: (0.1097) |  Loss2: (0.0000) | Acc: (96.00%) (28453/29568)
Epoch: 170 | Batch_idx: 240 |  Loss: (0.1092) |  Loss2: (0.0000) | Acc: (96.00%) (29690/30848)
Epoch: 170 | Batch_idx: 250 |  Loss: (0.1090) |  Loss2: (0.0000) | Acc: (96.00%) (30931/32128)
Epoch: 170 | Batch_idx: 260 |  Loss: (0.1091) |  Loss2: (0.0000) | Acc: (96.00%) (32165/33408)
Epoch: 170 | Batch_idx: 270 |  Loss: (0.1088) |  Loss2: (0.0000) | Acc: (96.00%) (33394/34688)
Epoch: 170 | Batch_idx: 280 |  Loss: (0.1087) |  Loss2: (0.0000) | Acc: (96.00%) (34630/35968)
Epoch: 170 | Batch_idx: 290 |  Loss: (0.1088) |  Loss2: (0.0000) | Acc: (96.00%) (35863/37248)
Epoch: 170 | Batch_idx: 300 |  Loss: (0.1088) |  Loss2: (0.0000) | Acc: (96.00%) (37091/38528)
Epoch: 170 | Batch_idx: 310 |  Loss: (0.1090) |  Loss2: (0.0000) | Acc: (96.00%) (38323/39808)
Epoch: 170 | Batch_idx: 320 |  Loss: (0.1087) |  Loss2: (0.0000) | Acc: (96.00%) (39558/41088)
Epoch: 170 | Batch_idx: 330 |  Loss: (0.1087) |  Loss2: (0.0000) | Acc: (96.00%) (40790/42368)
Epoch: 170 | Batch_idx: 340 |  Loss: (0.1089) |  Loss2: (0.0000) | Acc: (96.00%) (42011/43648)
Epoch: 170 | Batch_idx: 350 |  Loss: (0.1092) |  Loss2: (0.0000) | Acc: (96.00%) (43239/44928)
Epoch: 170 | Batch_idx: 360 |  Loss: (0.1090) |  Loss2: (0.0000) | Acc: (96.00%) (44472/46208)
Epoch: 170 | Batch_idx: 370 |  Loss: (0.1087) |  Loss2: (0.0000) | Acc: (96.00%) (45713/47488)
Epoch: 170 | Batch_idx: 380 |  Loss: (0.1086) |  Loss2: (0.0000) | Acc: (96.00%) (46943/48768)
Epoch: 170 | Batch_idx: 390 |  Loss: (0.1083) |  Loss2: (0.0000) | Acc: (96.00%) (48127/50000)
=> saving checkpoint 'drive/app/torch/save_Schedule/checkpoint_170.pth.tar'
# TEST : Loss: (0.4080) | Acc: (88.00%) (8827/10000)
percent tensor([0.4965, 0.4948, 0.5082, 0.4945, 0.5069, 0.4962, 0.4990, 0.4976, 0.4976,
        0.4993, 0.4980, 0.5055, 0.4951, 0.4931, 0.4954, 0.4942],
       device='cuda:0') torch.Size([16])
percent tensor([0.5076, 0.4794, 0.5053, 0.5047, 0.4956, 0.5166, 0.4856, 0.4930, 0.5108,
        0.4876, 0.5063, 0.4943, 0.4900, 0.5022, 0.4914, 0.5033],
       device='cuda:0') torch.Size([16])
percent tensor([0.6354, 0.6371, 0.5839, 0.5561, 0.5795, 0.6054, 0.6462, 0.5910, 0.5721,
        0.6032, 0.5982, 0.5738, 0.6536, 0.5625, 0.6582, 0.6327],
       device='cuda:0') torch.Size([16])
percent tensor([0.5902, 0.6034, 0.6014, 0.6699, 0.6132, 0.6949, 0.6067, 0.5680, 0.6546,
        0.6104, 0.6409, 0.6591, 0.5948, 0.6738, 0.6442, 0.6167],
       device='cuda:0') torch.Size([16])
percent tensor([0.5914, 0.6019, 0.5877, 0.5772, 0.6277, 0.5962, 0.6085, 0.5323, 0.6686,
        0.6392, 0.6553, 0.5141, 0.5870, 0.7433, 0.4744, 0.6324],
       device='cuda:0') torch.Size([16])
percent tensor([0.6418, 0.5938, 0.7329, 0.7458, 0.7668, 0.7532, 0.6706, 0.7067, 0.6720,
        0.6469, 0.6471, 0.6974, 0.6188, 0.6421, 0.6768, 0.6925],
       device='cuda:0') torch.Size([16])
percent tensor([0.5926, 0.7220, 0.6555, 0.6450, 0.6365, 0.5554, 0.5531, 0.5527, 0.6898,
        0.6536, 0.7401, 0.6374, 0.6896, 0.5964, 0.5781, 0.4775],
       device='cuda:0') torch.Size([16])
percent tensor([0.9997, 0.9998, 0.9997, 0.9999, 0.9997, 0.9994, 0.9996, 0.9996, 0.9998,
        0.9999, 1.0000, 0.9998, 0.9999, 0.9996, 0.9990, 0.9995],
       device='cuda:0') torch.Size([16])
Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 3, 3, 3]) tensor(191.9811, device='cuda:0')
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(824.6348, device='cuda:0')
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(830.6153, device='cuda:0')
Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([128, 64, 3, 3]) tensor(1527.6033, device='cuda:0')
Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([128, 64, 1, 1]) tensor(480.8666, device='cuda:0')
Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([128, 128, 3, 3]) tensor(2314.1582, device='cuda:0')
Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([256, 128, 3, 3]) tensor(4269.3657, device='cuda:0')
Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([256, 128, 1, 1]) tensor(1358.3597, device='cuda:0')
Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([256, 256, 3, 3]) tensor(6241.1714, device='cuda:0')
Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([512, 256, 3, 3]) tensor(11626.4346, device='cuda:0')
Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([512, 256, 1, 1]) tensor(3835.4292, device='cuda:0')
Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([512, 512, 3, 3]) tensor(16186.5234, device='cuda:0')
Epoch: 171 | Batch_idx: 0 |  Loss: (0.0927) |  Loss2: (0.0000) | Acc: (96.00%) (123/128)
Epoch: 171 | Batch_idx: 10 |  Loss: (0.1091) |  Loss2: (0.0000) | Acc: (96.00%) (1354/1408)
Epoch: 171 | Batch_idx: 20 |  Loss: (0.1045) |  Loss2: (0.0000) | Acc: (96.00%) (2588/2688)
Epoch: 171 | Batch_idx: 30 |  Loss: (0.1037) |  Loss2: (0.0000) | Acc: (96.00%) (3828/3968)
Epoch: 171 | Batch_idx: 40 |  Loss: (0.1034) |  Loss2: (0.0000) | Acc: (96.00%) (5064/5248)
Epoch: 171 | Batch_idx: 50 |  Loss: (0.1028) |  Loss2: (0.0000) | Acc: (96.00%) (6300/6528)
Epoch: 171 | Batch_idx: 60 |  Loss: (0.1020) |  Loss2: (0.0000) | Acc: (96.00%) (7541/7808)
Epoch: 171 | Batch_idx: 70 |  Loss: (0.1007) |  Loss2: (0.0000) | Acc: (96.00%) (8787/9088)
Epoch: 171 | Batch_idx: 80 |  Loss: (0.0988) |  Loss2: (0.0000) | Acc: (96.00%) (10030/10368)
Epoch: 171 | Batch_idx: 90 |  Loss: (0.0994) |  Loss2: (0.0000) | Acc: (96.00%) (11264/11648)
Epoch: 171 | Batch_idx: 100 |  Loss: (0.0995) |  Loss2: (0.0000) | Acc: (96.00%) (12503/12928)
Epoch: 171 | Batch_idx: 110 |  Loss: (0.1006) |  Loss2: (0.0000) | Acc: (96.00%) (13733/14208)
Epoch: 171 | Batch_idx: 120 |  Loss: (0.1003) |  Loss2: (0.0000) | Acc: (96.00%) (14967/15488)
Epoch: 171 | Batch_idx: 130 |  Loss: (0.1007) |  Loss2: (0.0000) | Acc: (96.00%) (16200/16768)
Epoch: 171 | Batch_idx: 140 |  Loss: (0.1014) |  Loss2: (0.0000) | Acc: (96.00%) (17426/18048)
Epoch: 171 | Batch_idx: 150 |  Loss: (0.1022) |  Loss2: (0.0000) | Acc: (96.00%) (18655/19328)
Epoch: 171 | Batch_idx: 160 |  Loss: (0.1025) |  Loss2: (0.0000) | Acc: (96.00%) (19890/20608)
Epoch: 171 | Batch_idx: 170 |  Loss: (0.1031) |  Loss2: (0.0000) | Acc: (96.00%) (21128/21888)
Epoch: 171 | Batch_idx: 180 |  Loss: (0.1045) |  Loss2: (0.0000) | Acc: (96.00%) (22360/23168)
Epoch: 171 | Batch_idx: 190 |  Loss: (0.1037) |  Loss2: (0.0000) | Acc: (96.00%) (23601/24448)
Epoch: 171 | Batch_idx: 200 |  Loss: (0.1038) |  Loss2: (0.0000) | Acc: (96.00%) (24832/25728)
Epoch: 171 | Batch_idx: 210 |  Loss: (0.1035) |  Loss2: (0.0000) | Acc: (96.00%) (26077/27008)
Epoch: 171 | Batch_idx: 220 |  Loss: (0.1039) |  Loss2: (0.0000) | Acc: (96.00%) (27306/28288)
Epoch: 171 | Batch_idx: 230 |  Loss: (0.1030) |  Loss2: (0.0000) | Acc: (96.00%) (28549/29568)
Epoch: 171 | Batch_idx: 240 |  Loss: (0.1042) |  Loss2: (0.0000) | Acc: (96.00%) (29768/30848)
Epoch: 171 | Batch_idx: 250 |  Loss: (0.1042) |  Loss2: (0.0000) | Acc: (96.00%) (30999/32128)
Epoch: 171 | Batch_idx: 260 |  Loss: (0.1044) |  Loss2: (0.0000) | Acc: (96.00%) (32224/33408)
Epoch: 171 | Batch_idx: 270 |  Loss: (0.1043) |  Loss2: (0.0000) | Acc: (96.00%) (33456/34688)
Epoch: 171 | Batch_idx: 280 |  Loss: (0.1043) |  Loss2: (0.0000) | Acc: (96.00%) (34691/35968)
Epoch: 171 | Batch_idx: 290 |  Loss: (0.1038) |  Loss2: (0.0000) | Acc: (96.00%) (35932/37248)
Epoch: 171 | Batch_idx: 300 |  Loss: (0.1036) |  Loss2: (0.0000) | Acc: (96.00%) (37166/38528)
Epoch: 171 | Batch_idx: 310 |  Loss: (0.1035) |  Loss2: (0.0000) | Acc: (96.00%) (38399/39808)
Epoch: 171 | Batch_idx: 320 |  Loss: (0.1030) |  Loss2: (0.0000) | Acc: (96.00%) (39640/41088)
Epoch: 171 | Batch_idx: 330 |  Loss: (0.1033) |  Loss2: (0.0000) | Acc: (96.00%) (40872/42368)
Epoch: 171 | Batch_idx: 340 |  Loss: (0.1038) |  Loss2: (0.0000) | Acc: (96.00%) (42099/43648)
Epoch: 171 | Batch_idx: 350 |  Loss: (0.1046) |  Loss2: (0.0000) | Acc: (96.00%) (43325/44928)
Epoch: 171 | Batch_idx: 360 |  Loss: (0.1051) |  Loss2: (0.0000) | Acc: (96.00%) (44556/46208)
Epoch: 171 | Batch_idx: 370 |  Loss: (0.1052) |  Loss2: (0.0000) | Acc: (96.00%) (45786/47488)
Epoch: 171 | Batch_idx: 380 |  Loss: (0.1051) |  Loss2: (0.0000) | Acc: (96.00%) (47022/48768)
Epoch: 171 | Batch_idx: 390 |  Loss: (0.1055) |  Loss2: (0.0000) | Acc: (96.00%) (48205/50000)
# TEST : Loss: (0.4005) | Acc: (88.00%) (8851/10000)
percent tensor([0.4978, 0.4963, 0.5098, 0.4961, 0.5085, 0.4976, 0.5005, 0.4993, 0.4990,
        0.5007, 0.4994, 0.5071, 0.4965, 0.4944, 0.4969, 0.4957],
       device='cuda:0') torch.Size([16])
percent tensor([0.5085, 0.4802, 0.5058, 0.5056, 0.4962, 0.5171, 0.4863, 0.4937, 0.5116,
        0.4884, 0.5074, 0.4948, 0.4906, 0.5035, 0.4922, 0.5041],
       device='cuda:0') torch.Size([16])
percent tensor([0.6328, 0.6350, 0.5798, 0.5505, 0.5747, 0.6022, 0.6431, 0.5865, 0.5690,
        0.6014, 0.5962, 0.5708, 0.6520, 0.5588, 0.6548, 0.6302],
       device='cuda:0') torch.Size([16])
percent tensor([0.5928, 0.6091, 0.6034, 0.6703, 0.6167, 0.6923, 0.6114, 0.5721, 0.6563,
        0.6151, 0.6456, 0.6630, 0.5999, 0.6759, 0.6480, 0.6175],
       device='cuda:0') torch.Size([16])
percent tensor([0.5901, 0.6022, 0.5870, 0.5811, 0.6292, 0.5996, 0.6054, 0.5310, 0.6659,
        0.6402, 0.6558, 0.5128, 0.5850, 0.7453, 0.4703, 0.6351],
       device='cuda:0') torch.Size([16])
percent tensor([0.6352, 0.5868, 0.7296, 0.7401, 0.7629, 0.7481, 0.6645, 0.7020, 0.6655,
        0.6410, 0.6402, 0.6928, 0.6115, 0.6365, 0.6718, 0.6856],
       device='cuda:0') torch.Size([16])
percent tensor([0.5955, 0.7221, 0.6636, 0.6560, 0.6469, 0.5674, 0.5609, 0.5571, 0.6945,
        0.6564, 0.7409, 0.6466, 0.6882, 0.6045, 0.5882, 0.4825],
       device='cuda:0') torch.Size([16])
percent tensor([0.9996, 0.9998, 0.9997, 0.9999, 0.9997, 0.9994, 0.9996, 0.9996, 0.9998,
        0.9999, 1.0000, 0.9998, 0.9999, 0.9996, 0.9990, 0.9995],
       device='cuda:0') torch.Size([16])
Epoch: 172 | Batch_idx: 0 |  Loss: (0.1164) |  Loss2: (0.0000) | Acc: (97.00%) (125/128)
Epoch: 172 | Batch_idx: 10 |  Loss: (0.1005) |  Loss2: (0.0000) | Acc: (96.00%) (1360/1408)
Epoch: 172 | Batch_idx: 20 |  Loss: (0.1033) |  Loss2: (0.0000) | Acc: (96.00%) (2597/2688)
Epoch: 172 | Batch_idx: 30 |  Loss: (0.1119) |  Loss2: (0.0000) | Acc: (96.00%) (3818/3968)
Epoch: 172 | Batch_idx: 40 |  Loss: (0.1121) |  Loss2: (0.0000) | Acc: (96.00%) (5052/5248)
Epoch: 172 | Batch_idx: 50 |  Loss: (0.1098) |  Loss2: (0.0000) | Acc: (96.00%) (6296/6528)
Epoch: 172 | Batch_idx: 60 |  Loss: (0.1095) |  Loss2: (0.0000) | Acc: (96.00%) (7535/7808)
Epoch: 172 | Batch_idx: 70 |  Loss: (0.1093) |  Loss2: (0.0000) | Acc: (96.00%) (8773/9088)
Epoch: 172 | Batch_idx: 80 |  Loss: (0.1066) |  Loss2: (0.0000) | Acc: (96.00%) (10017/10368)
Epoch: 172 | Batch_idx: 90 |  Loss: (0.1081) |  Loss2: (0.0000) | Acc: (96.00%) (11242/11648)
Epoch: 172 | Batch_idx: 100 |  Loss: (0.1071) |  Loss2: (0.0000) | Acc: (96.00%) (12481/12928)
Epoch: 172 | Batch_idx: 110 |  Loss: (0.1062) |  Loss2: (0.0000) | Acc: (96.00%) (13721/14208)
Epoch: 172 | Batch_idx: 120 |  Loss: (0.1068) |  Loss2: (0.0000) | Acc: (96.00%) (14941/15488)
Epoch: 172 | Batch_idx: 130 |  Loss: (0.1072) |  Loss2: (0.0000) | Acc: (96.00%) (16164/16768)
Epoch: 172 | Batch_idx: 140 |  Loss: (0.1078) |  Loss2: (0.0000) | Acc: (96.00%) (17389/18048)
Epoch: 172 | Batch_idx: 150 |  Loss: (0.1068) |  Loss2: (0.0000) | Acc: (96.00%) (18622/19328)
Epoch: 172 | Batch_idx: 160 |  Loss: (0.1062) |  Loss2: (0.0000) | Acc: (96.00%) (19863/20608)
Epoch: 172 | Batch_idx: 170 |  Loss: (0.1056) |  Loss2: (0.0000) | Acc: (96.00%) (21099/21888)
Epoch: 172 | Batch_idx: 180 |  Loss: (0.1074) |  Loss2: (0.0000) | Acc: (96.00%) (22314/23168)
Epoch: 172 | Batch_idx: 190 |  Loss: (0.1070) |  Loss2: (0.0000) | Acc: (96.00%) (23547/24448)
Epoch: 172 | Batch_idx: 200 |  Loss: (0.1068) |  Loss2: (0.0000) | Acc: (96.00%) (24782/25728)
Epoch: 172 | Batch_idx: 210 |  Loss: (0.1074) |  Loss2: (0.0000) | Acc: (96.00%) (26004/27008)
Epoch: 172 | Batch_idx: 220 |  Loss: (0.1071) |  Loss2: (0.0000) | Acc: (96.00%) (27244/28288)
Epoch: 172 | Batch_idx: 230 |  Loss: (0.1068) |  Loss2: (0.0000) | Acc: (96.00%) (28479/29568)
Epoch: 172 | Batch_idx: 240 |  Loss: (0.1070) |  Loss2: (0.0000) | Acc: (96.00%) (29706/30848)
Epoch: 172 | Batch_idx: 250 |  Loss: (0.1065) |  Loss2: (0.0000) | Acc: (96.00%) (30941/32128)
Epoch: 172 | Batch_idx: 260 |  Loss: (0.1064) |  Loss2: (0.0000) | Acc: (96.00%) (32170/33408)
Epoch: 172 | Batch_idx: 270 |  Loss: (0.1062) |  Loss2: (0.0000) | Acc: (96.00%) (33410/34688)
Epoch: 172 | Batch_idx: 280 |  Loss: (0.1060) |  Loss2: (0.0000) | Acc: (96.00%) (34643/35968)
Epoch: 172 | Batch_idx: 290 |  Loss: (0.1059) |  Loss2: (0.0000) | Acc: (96.00%) (35884/37248)
Epoch: 172 | Batch_idx: 300 |  Loss: (0.1052) |  Loss2: (0.0000) | Acc: (96.00%) (37128/38528)
Epoch: 172 | Batch_idx: 310 |  Loss: (0.1056) |  Loss2: (0.0000) | Acc: (96.00%) (38354/39808)
Epoch: 172 | Batch_idx: 320 |  Loss: (0.1052) |  Loss2: (0.0000) | Acc: (96.00%) (39595/41088)
Epoch: 172 | Batch_idx: 330 |  Loss: (0.1053) |  Loss2: (0.0000) | Acc: (96.00%) (40828/42368)
Epoch: 172 | Batch_idx: 340 |  Loss: (0.1050) |  Loss2: (0.0000) | Acc: (96.00%) (42065/43648)
Epoch: 172 | Batch_idx: 350 |  Loss: (0.1047) |  Loss2: (0.0000) | Acc: (96.00%) (43302/44928)
Epoch: 172 | Batch_idx: 360 |  Loss: (0.1049) |  Loss2: (0.0000) | Acc: (96.00%) (44534/46208)
Epoch: 172 | Batch_idx: 370 |  Loss: (0.1042) |  Loss2: (0.0000) | Acc: (96.00%) (45779/47488)
Epoch: 172 | Batch_idx: 380 |  Loss: (0.1038) |  Loss2: (0.0000) | Acc: (96.00%) (47025/48768)
Epoch: 172 | Batch_idx: 390 |  Loss: (0.1035) |  Loss2: (0.0000) | Acc: (96.00%) (48221/50000)
# TEST : Loss: (0.3959) | Acc: (88.00%) (8862/10000)
percent tensor([0.4987, 0.4972, 0.5108, 0.4971, 0.5096, 0.4986, 0.5013, 0.5003, 0.5000,
        0.5015, 0.5003, 0.5081, 0.4974, 0.4953, 0.4978, 0.4966],
       device='cuda:0') torch.Size([16])
percent tensor([0.5084, 0.4798, 0.5052, 0.5056, 0.4956, 0.5175, 0.4856, 0.4932, 0.5116,
        0.4880, 0.5073, 0.4941, 0.4907, 0.5031, 0.4918, 0.5038],
       device='cuda:0') torch.Size([16])
percent tensor([0.6346, 0.6360, 0.5813, 0.5505, 0.5755, 0.6031, 0.6442, 0.5872, 0.5698,
        0.6032, 0.5975, 0.5726, 0.6533, 0.5605, 0.6546, 0.6313],
       device='cuda:0') torch.Size([16])
percent tensor([0.5933, 0.6130, 0.6012, 0.6671, 0.6133, 0.6872, 0.6119, 0.5706, 0.6549,
        0.6169, 0.6475, 0.6630, 0.6046, 0.6746, 0.6479, 0.6164],
       device='cuda:0') torch.Size([16])
percent tensor([0.5925, 0.6089, 0.5863, 0.5830, 0.6280, 0.5980, 0.6068, 0.5323, 0.6685,
        0.6452, 0.6594, 0.5152, 0.5898, 0.7491, 0.4722, 0.6372],
       device='cuda:0') torch.Size([16])
percent tensor([0.6411, 0.5891, 0.7347, 0.7438, 0.7679, 0.7524, 0.6697, 0.7075, 0.6694,
        0.6457, 0.6440, 0.6975, 0.6150, 0.6404, 0.6774, 0.6902],
       device='cuda:0') torch.Size([16])
percent tensor([0.5923, 0.7162, 0.6669, 0.6568, 0.6519, 0.5747, 0.5608, 0.5588, 0.6888,
        0.6511, 0.7343, 0.6477, 0.6772, 0.6026, 0.5884, 0.4830],
       device='cuda:0') torch.Size([16])
percent tensor([0.9997, 0.9998, 0.9997, 0.9999, 0.9997, 0.9994, 0.9996, 0.9996, 0.9998,
        0.9999, 1.0000, 0.9998, 0.9999, 0.9996, 0.9990, 0.9995],
       device='cuda:0') torch.Size([16])
Epoch: 173 | Batch_idx: 0 |  Loss: (0.2134) |  Loss2: (0.0000) | Acc: (91.00%) (117/128)
Epoch: 173 | Batch_idx: 10 |  Loss: (0.0993) |  Loss2: (0.0000) | Acc: (96.00%) (1363/1408)
Epoch: 173 | Batch_idx: 20 |  Loss: (0.1024) |  Loss2: (0.0000) | Acc: (96.00%) (2600/2688)
Epoch: 173 | Batch_idx: 30 |  Loss: (0.1006) |  Loss2: (0.0000) | Acc: (96.00%) (3838/3968)
Epoch: 173 | Batch_idx: 40 |  Loss: (0.0956) |  Loss2: (0.0000) | Acc: (96.00%) (5088/5248)
Epoch: 173 | Batch_idx: 50 |  Loss: (0.0985) |  Loss2: (0.0000) | Acc: (96.00%) (6316/6528)
Epoch: 173 | Batch_idx: 60 |  Loss: (0.0984) |  Loss2: (0.0000) | Acc: (96.00%) (7557/7808)
Epoch: 173 | Batch_idx: 70 |  Loss: (0.0990) |  Loss2: (0.0000) | Acc: (96.00%) (8794/9088)
Epoch: 173 | Batch_idx: 80 |  Loss: (0.0994) |  Loss2: (0.0000) | Acc: (96.00%) (10032/10368)
Epoch: 173 | Batch_idx: 90 |  Loss: (0.0998) |  Loss2: (0.0000) | Acc: (96.00%) (11269/11648)
Epoch: 173 | Batch_idx: 100 |  Loss: (0.0999) |  Loss2: (0.0000) | Acc: (96.00%) (12504/12928)
Epoch: 173 | Batch_idx: 110 |  Loss: (0.1007) |  Loss2: (0.0000) | Acc: (96.00%) (13734/14208)
Epoch: 173 | Batch_idx: 120 |  Loss: (0.1024) |  Loss2: (0.0000) | Acc: (96.00%) (14949/15488)
Epoch: 173 | Batch_idx: 130 |  Loss: (0.1015) |  Loss2: (0.0000) | Acc: (96.00%) (16194/16768)
Epoch: 173 | Batch_idx: 140 |  Loss: (0.1001) |  Loss2: (0.0000) | Acc: (96.00%) (17437/18048)
Epoch: 173 | Batch_idx: 150 |  Loss: (0.1002) |  Loss2: (0.0000) | Acc: (96.00%) (18677/19328)
Epoch: 173 | Batch_idx: 160 |  Loss: (0.1010) |  Loss2: (0.0000) | Acc: (96.00%) (19906/20608)
Epoch: 173 | Batch_idx: 170 |  Loss: (0.1007) |  Loss2: (0.0000) | Acc: (96.00%) (21148/21888)
Epoch: 173 | Batch_idx: 180 |  Loss: (0.1002) |  Loss2: (0.0000) | Acc: (96.00%) (22398/23168)
Epoch: 173 | Batch_idx: 190 |  Loss: (0.0996) |  Loss2: (0.0000) | Acc: (96.00%) (23644/24448)
Epoch: 173 | Batch_idx: 200 |  Loss: (0.0997) |  Loss2: (0.0000) | Acc: (96.00%) (24875/25728)
Epoch: 173 | Batch_idx: 210 |  Loss: (0.0996) |  Loss2: (0.0000) | Acc: (96.00%) (26115/27008)
Epoch: 173 | Batch_idx: 220 |  Loss: (0.0992) |  Loss2: (0.0000) | Acc: (96.00%) (27353/28288)
Epoch: 173 | Batch_idx: 230 |  Loss: (0.0992) |  Loss2: (0.0000) | Acc: (96.00%) (28592/29568)
Epoch: 173 | Batch_idx: 240 |  Loss: (0.0997) |  Loss2: (0.0000) | Acc: (96.00%) (29821/30848)
Epoch: 173 | Batch_idx: 250 |  Loss: (0.0997) |  Loss2: (0.0000) | Acc: (96.00%) (31058/32128)
Epoch: 173 | Batch_idx: 260 |  Loss: (0.1000) |  Loss2: (0.0000) | Acc: (96.00%) (32295/33408)
Epoch: 173 | Batch_idx: 270 |  Loss: (0.0999) |  Loss2: (0.0000) | Acc: (96.00%) (33533/34688)
Epoch: 173 | Batch_idx: 280 |  Loss: (0.1008) |  Loss2: (0.0000) | Acc: (96.00%) (34756/35968)
Epoch: 173 | Batch_idx: 290 |  Loss: (0.1005) |  Loss2: (0.0000) | Acc: (96.00%) (35997/37248)
Epoch: 173 | Batch_idx: 300 |  Loss: (0.1002) |  Loss2: (0.0000) | Acc: (96.00%) (37240/38528)
Epoch: 173 | Batch_idx: 310 |  Loss: (0.0998) |  Loss2: (0.0000) | Acc: (96.00%) (38485/39808)
Epoch: 173 | Batch_idx: 320 |  Loss: (0.0996) |  Loss2: (0.0000) | Acc: (96.00%) (39721/41088)
Epoch: 173 | Batch_idx: 330 |  Loss: (0.1001) |  Loss2: (0.0000) | Acc: (96.00%) (40956/42368)
Epoch: 173 | Batch_idx: 340 |  Loss: (0.0999) |  Loss2: (0.0000) | Acc: (96.00%) (42197/43648)
Epoch: 173 | Batch_idx: 350 |  Loss: (0.1005) |  Loss2: (0.0000) | Acc: (96.00%) (43425/44928)
Epoch: 173 | Batch_idx: 360 |  Loss: (0.1007) |  Loss2: (0.0000) | Acc: (96.00%) (44660/46208)
Epoch: 173 | Batch_idx: 370 |  Loss: (0.1005) |  Loss2: (0.0000) | Acc: (96.00%) (45894/47488)
Epoch: 173 | Batch_idx: 380 |  Loss: (0.1007) |  Loss2: (0.0000) | Acc: (96.00%) (47123/48768)
Epoch: 173 | Batch_idx: 390 |  Loss: (0.1005) |  Loss2: (0.0000) | Acc: (96.00%) (48322/50000)
# TEST : Loss: (0.3927) | Acc: (88.00%) (8874/10000)
percent tensor([0.4995, 0.4980, 0.5114, 0.4979, 0.5102, 0.4994, 0.5021, 0.5011, 0.5009,
        0.5022, 0.5012, 0.5087, 0.4983, 0.4962, 0.4986, 0.4974],
       device='cuda:0') torch.Size([16])
percent tensor([0.5104, 0.4821, 0.5069, 0.5077, 0.4978, 0.5184, 0.4878, 0.4953, 0.5137,
        0.4899, 0.5093, 0.4961, 0.4929, 0.5053, 0.4939, 0.5056],
       device='cuda:0') torch.Size([16])
percent tensor([0.6376, 0.6407, 0.5845, 0.5521, 0.5799, 0.6044, 0.6488, 0.5915, 0.5738,
        0.6087, 0.6029, 0.5785, 0.6580, 0.5620, 0.6586, 0.6343],
       device='cuda:0') torch.Size([16])
percent tensor([0.5929, 0.6156, 0.6011, 0.6673, 0.6136, 0.6848, 0.6132, 0.5722, 0.6544,
        0.6172, 0.6483, 0.6629, 0.6057, 0.6745, 0.6493, 0.6152],
       device='cuda:0') torch.Size([16])
percent tensor([0.5852, 0.6112, 0.5773, 0.5750, 0.6181, 0.5877, 0.6023, 0.5246, 0.6603,
        0.6425, 0.6557, 0.5113, 0.5884, 0.7451, 0.4676, 0.6321],
       device='cuda:0') torch.Size([16])
percent tensor([0.6408, 0.5880, 0.7356, 0.7438, 0.7693, 0.7529, 0.6705, 0.7084, 0.6705,
        0.6457, 0.6437, 0.6978, 0.6145, 0.6406, 0.6782, 0.6900],
       device='cuda:0') torch.Size([16])
percent tensor([0.5993, 0.7214, 0.6744, 0.6640, 0.6566, 0.5836, 0.5637, 0.5593, 0.6965,
        0.6573, 0.7405, 0.6518, 0.6829, 0.6095, 0.5921, 0.4853],
       device='cuda:0') torch.Size([16])
percent tensor([0.9997, 0.9998, 0.9997, 0.9999, 0.9997, 0.9994, 0.9996, 0.9996, 0.9998,
        0.9999, 1.0000, 0.9998, 0.9999, 0.9996, 0.9990, 0.9995],
       device='cuda:0') torch.Size([16])
Epoch: 174 | Batch_idx: 0 |  Loss: (0.1291) |  Loss2: (0.0000) | Acc: (96.00%) (123/128)
Epoch: 174 | Batch_idx: 10 |  Loss: (0.1051) |  Loss2: (0.0000) | Acc: (96.00%) (1365/1408)
Epoch: 174 | Batch_idx: 20 |  Loss: (0.0983) |  Loss2: (0.0000) | Acc: (96.00%) (2600/2688)
Epoch: 174 | Batch_idx: 30 |  Loss: (0.0911) |  Loss2: (0.0000) | Acc: (97.00%) (3849/3968)
Epoch: 174 | Batch_idx: 40 |  Loss: (0.0915) |  Loss2: (0.0000) | Acc: (97.00%) (5094/5248)
Epoch: 174 | Batch_idx: 50 |  Loss: (0.0920) |  Loss2: (0.0000) | Acc: (96.00%) (6332/6528)
Epoch: 174 | Batch_idx: 60 |  Loss: (0.0966) |  Loss2: (0.0000) | Acc: (96.00%) (7560/7808)
Epoch: 174 | Batch_idx: 70 |  Loss: (0.0960) |  Loss2: (0.0000) | Acc: (96.00%) (8803/9088)
Epoch: 174 | Batch_idx: 80 |  Loss: (0.0969) |  Loss2: (0.0000) | Acc: (96.00%) (10037/10368)
Epoch: 174 | Batch_idx: 90 |  Loss: (0.0991) |  Loss2: (0.0000) | Acc: (96.00%) (11272/11648)
Epoch: 174 | Batch_idx: 100 |  Loss: (0.1008) |  Loss2: (0.0000) | Acc: (96.00%) (12499/12928)
Epoch: 174 | Batch_idx: 110 |  Loss: (0.0998) |  Loss2: (0.0000) | Acc: (96.00%) (13744/14208)
Epoch: 174 | Batch_idx: 120 |  Loss: (0.0998) |  Loss2: (0.0000) | Acc: (96.00%) (14984/15488)
Epoch: 174 | Batch_idx: 130 |  Loss: (0.1005) |  Loss2: (0.0000) | Acc: (96.00%) (16215/16768)
Epoch: 174 | Batch_idx: 140 |  Loss: (0.1001) |  Loss2: (0.0000) | Acc: (96.00%) (17448/18048)
Epoch: 174 | Batch_idx: 150 |  Loss: (0.1004) |  Loss2: (0.0000) | Acc: (96.00%) (18680/19328)
Epoch: 174 | Batch_idx: 160 |  Loss: (0.0999) |  Loss2: (0.0000) | Acc: (96.00%) (19926/20608)
Epoch: 174 | Batch_idx: 170 |  Loss: (0.0995) |  Loss2: (0.0000) | Acc: (96.00%) (21170/21888)
Epoch: 174 | Batch_idx: 180 |  Loss: (0.1001) |  Loss2: (0.0000) | Acc: (96.00%) (22398/23168)
Epoch: 174 | Batch_idx: 190 |  Loss: (0.1002) |  Loss2: (0.0000) | Acc: (96.00%) (23628/24448)
Epoch: 174 | Batch_idx: 200 |  Loss: (0.0998) |  Loss2: (0.0000) | Acc: (96.00%) (24865/25728)
Epoch: 174 | Batch_idx: 210 |  Loss: (0.0999) |  Loss2: (0.0000) | Acc: (96.00%) (26098/27008)
Epoch: 174 | Batch_idx: 220 |  Loss: (0.0995) |  Loss2: (0.0000) | Acc: (96.00%) (27340/28288)
Epoch: 174 | Batch_idx: 230 |  Loss: (0.0996) |  Loss2: (0.0000) | Acc: (96.00%) (28572/29568)
Epoch: 174 | Batch_idx: 240 |  Loss: (0.0989) |  Loss2: (0.0000) | Acc: (96.00%) (29818/30848)
Epoch: 174 | Batch_idx: 250 |  Loss: (0.0984) |  Loss2: (0.0000) | Acc: (96.00%) (31061/32128)
Epoch: 174 | Batch_idx: 260 |  Loss: (0.0980) |  Loss2: (0.0000) | Acc: (96.00%) (32306/33408)
Epoch: 174 | Batch_idx: 270 |  Loss: (0.0981) |  Loss2: (0.0000) | Acc: (96.00%) (33535/34688)
Epoch: 174 | Batch_idx: 280 |  Loss: (0.0980) |  Loss2: (0.0000) | Acc: (96.00%) (34779/35968)
Epoch: 174 | Batch_idx: 290 |  Loss: (0.0981) |  Loss2: (0.0000) | Acc: (96.00%) (36008/37248)
Epoch: 174 | Batch_idx: 300 |  Loss: (0.0986) |  Loss2: (0.0000) | Acc: (96.00%) (37240/38528)
Epoch: 174 | Batch_idx: 310 |  Loss: (0.0989) |  Loss2: (0.0000) | Acc: (96.00%) (38471/39808)
Epoch: 174 | Batch_idx: 320 |  Loss: (0.0987) |  Loss2: (0.0000) | Acc: (96.00%) (39714/41088)
Epoch: 174 | Batch_idx: 330 |  Loss: (0.0987) |  Loss2: (0.0000) | Acc: (96.00%) (40952/42368)
Epoch: 174 | Batch_idx: 340 |  Loss: (0.0986) |  Loss2: (0.0000) | Acc: (96.00%) (42188/43648)
Epoch: 174 | Batch_idx: 350 |  Loss: (0.0984) |  Loss2: (0.0000) | Acc: (96.00%) (43436/44928)
Epoch: 174 | Batch_idx: 360 |  Loss: (0.0983) |  Loss2: (0.0000) | Acc: (96.00%) (44677/46208)
Epoch: 174 | Batch_idx: 370 |  Loss: (0.0983) |  Loss2: (0.0000) | Acc: (96.00%) (45917/47488)
Epoch: 174 | Batch_idx: 380 |  Loss: (0.0981) |  Loss2: (0.0000) | Acc: (96.00%) (47158/48768)
Epoch: 174 | Batch_idx: 390 |  Loss: (0.0980) |  Loss2: (0.0000) | Acc: (96.00%) (48357/50000)
# TEST : Loss: (0.3901) | Acc: (88.00%) (8884/10000)
percent tensor([0.4992, 0.4975, 0.5111, 0.4976, 0.5100, 0.4992, 0.5017, 0.5007, 0.5004,
        0.5018, 0.5007, 0.5084, 0.4978, 0.4959, 0.4983, 0.4970],
       device='cuda:0') torch.Size([16])
percent tensor([0.5072, 0.4784, 0.5033, 0.5051, 0.4939, 0.5169, 0.4837, 0.4917, 0.5110,
        0.4868, 0.5065, 0.4923, 0.4897, 0.5028, 0.4899, 0.5027],
       device='cuda:0') torch.Size([16])
percent tensor([0.6361, 0.6433, 0.5802, 0.5486, 0.5750, 0.6019, 0.6490, 0.5866, 0.5731,
        0.6102, 0.6046, 0.5764, 0.6591, 0.5638, 0.6576, 0.6338],
       device='cuda:0') torch.Size([16])
percent tensor([0.5935, 0.6184, 0.6015, 0.6663, 0.6129, 0.6816, 0.6150, 0.5720, 0.6550,
        0.6196, 0.6504, 0.6650, 0.6091, 0.6767, 0.6495, 0.6145],
       device='cuda:0') torch.Size([16])
percent tensor([0.5900, 0.6105, 0.5836, 0.5824, 0.6256, 0.5994, 0.6033, 0.5294, 0.6629,
        0.6435, 0.6581, 0.5150, 0.5890, 0.7483, 0.4691, 0.6399],
       device='cuda:0') torch.Size([16])
percent tensor([0.6403, 0.5881, 0.7361, 0.7442, 0.7703, 0.7528, 0.6706, 0.7085, 0.6695,
        0.6469, 0.6432, 0.6981, 0.6133, 0.6416, 0.6790, 0.6895],
       device='cuda:0') torch.Size([16])
percent tensor([0.5987, 0.7198, 0.6792, 0.6672, 0.6642, 0.5894, 0.5667, 0.5629, 0.6974,
        0.6587, 0.7408, 0.6585, 0.6797, 0.6092, 0.5970, 0.4847],
       device='cuda:0') torch.Size([16])
percent tensor([0.9997, 0.9998, 0.9998, 0.9999, 0.9998, 0.9995, 0.9996, 0.9996, 0.9998,
        0.9999, 1.0000, 0.9998, 0.9999, 0.9996, 0.9990, 0.9995],
       device='cuda:0') torch.Size([16])
Epoch: 175 | Batch_idx: 0 |  Loss: (0.1163) |  Loss2: (0.0000) | Acc: (97.00%) (125/128)
Epoch: 175 | Batch_idx: 10 |  Loss: (0.0967) |  Loss2: (0.0000) | Acc: (96.00%) (1364/1408)
Epoch: 175 | Batch_idx: 20 |  Loss: (0.0939) |  Loss2: (0.0000) | Acc: (96.00%) (2607/2688)
Epoch: 175 | Batch_idx: 30 |  Loss: (0.0902) |  Loss2: (0.0000) | Acc: (97.00%) (3853/3968)
Epoch: 175 | Batch_idx: 40 |  Loss: (0.0929) |  Loss2: (0.0000) | Acc: (96.00%) (5087/5248)
Epoch: 175 | Batch_idx: 50 |  Loss: (0.0940) |  Loss2: (0.0000) | Acc: (96.00%) (6319/6528)
Epoch: 175 | Batch_idx: 60 |  Loss: (0.0954) |  Loss2: (0.0000) | Acc: (96.00%) (7553/7808)
Epoch: 175 | Batch_idx: 70 |  Loss: (0.0946) |  Loss2: (0.0000) | Acc: (96.00%) (8794/9088)
Epoch: 175 | Batch_idx: 80 |  Loss: (0.0942) |  Loss2: (0.0000) | Acc: (96.00%) (10036/10368)
Epoch: 175 | Batch_idx: 90 |  Loss: (0.0946) |  Loss2: (0.0000) | Acc: (96.00%) (11275/11648)
Epoch: 175 | Batch_idx: 100 |  Loss: (0.0934) |  Loss2: (0.0000) | Acc: (96.00%) (12520/12928)
Epoch: 175 | Batch_idx: 110 |  Loss: (0.0930) |  Loss2: (0.0000) | Acc: (96.00%) (13763/14208)
Epoch: 175 | Batch_idx: 120 |  Loss: (0.0942) |  Loss2: (0.0000) | Acc: (96.00%) (14998/15488)
Epoch: 175 | Batch_idx: 130 |  Loss: (0.0928) |  Loss2: (0.0000) | Acc: (96.00%) (16244/16768)
Epoch: 175 | Batch_idx: 140 |  Loss: (0.0928) |  Loss2: (0.0000) | Acc: (96.00%) (17483/18048)
Epoch: 175 | Batch_idx: 150 |  Loss: (0.0933) |  Loss2: (0.0000) | Acc: (96.00%) (18717/19328)
Epoch: 175 | Batch_idx: 160 |  Loss: (0.0938) |  Loss2: (0.0000) | Acc: (96.00%) (19954/20608)
Epoch: 175 | Batch_idx: 170 |  Loss: (0.0933) |  Loss2: (0.0000) | Acc: (96.00%) (21199/21888)
Epoch: 175 | Batch_idx: 180 |  Loss: (0.0930) |  Loss2: (0.0000) | Acc: (96.00%) (22444/23168)
Epoch: 175 | Batch_idx: 190 |  Loss: (0.0930) |  Loss2: (0.0000) | Acc: (96.00%) (23683/24448)
Epoch: 175 | Batch_idx: 200 |  Loss: (0.0929) |  Loss2: (0.0000) | Acc: (96.00%) (24927/25728)
Epoch: 175 | Batch_idx: 210 |  Loss: (0.0930) |  Loss2: (0.0000) | Acc: (96.00%) (26172/27008)
Epoch: 175 | Batch_idx: 220 |  Loss: (0.0929) |  Loss2: (0.0000) | Acc: (96.00%) (27414/28288)
Epoch: 175 | Batch_idx: 230 |  Loss: (0.0934) |  Loss2: (0.0000) | Acc: (96.00%) (28654/29568)
Epoch: 175 | Batch_idx: 240 |  Loss: (0.0936) |  Loss2: (0.0000) | Acc: (96.00%) (29898/30848)
Epoch: 175 | Batch_idx: 250 |  Loss: (0.0938) |  Loss2: (0.0000) | Acc: (96.00%) (31138/32128)
Epoch: 175 | Batch_idx: 260 |  Loss: (0.0936) |  Loss2: (0.0000) | Acc: (96.00%) (32385/33408)
Epoch: 175 | Batch_idx: 270 |  Loss: (0.0937) |  Loss2: (0.0000) | Acc: (96.00%) (33627/34688)
Epoch: 175 | Batch_idx: 280 |  Loss: (0.0936) |  Loss2: (0.0000) | Acc: (96.00%) (34871/35968)
Epoch: 175 | Batch_idx: 290 |  Loss: (0.0943) |  Loss2: (0.0000) | Acc: (96.00%) (36093/37248)
Epoch: 175 | Batch_idx: 300 |  Loss: (0.0942) |  Loss2: (0.0000) | Acc: (96.00%) (37341/38528)
Epoch: 175 | Batch_idx: 310 |  Loss: (0.0943) |  Loss2: (0.0000) | Acc: (96.00%) (38579/39808)
Epoch: 175 | Batch_idx: 320 |  Loss: (0.0942) |  Loss2: (0.0000) | Acc: (96.00%) (39822/41088)
Epoch: 175 | Batch_idx: 330 |  Loss: (0.0942) |  Loss2: (0.0000) | Acc: (96.00%) (41061/42368)
Epoch: 175 | Batch_idx: 340 |  Loss: (0.0943) |  Loss2: (0.0000) | Acc: (96.00%) (42296/43648)
Epoch: 175 | Batch_idx: 350 |  Loss: (0.0939) |  Loss2: (0.0000) | Acc: (96.00%) (43538/44928)
Epoch: 175 | Batch_idx: 360 |  Loss: (0.0939) |  Loss2: (0.0000) | Acc: (96.00%) (44782/46208)
Epoch: 175 | Batch_idx: 370 |  Loss: (0.0941) |  Loss2: (0.0000) | Acc: (96.00%) (46015/47488)
Epoch: 175 | Batch_idx: 380 |  Loss: (0.0940) |  Loss2: (0.0000) | Acc: (96.00%) (47251/48768)
Epoch: 175 | Batch_idx: 390 |  Loss: (0.0941) |  Loss2: (0.0000) | Acc: (96.00%) (48438/50000)
=> saving checkpoint 'drive/app/torch/save_Schedule/checkpoint_175.pth.tar'
# TEST : Loss: (0.3896) | Acc: (88.00%) (8878/10000)
percent tensor([0.5003, 0.4987, 0.5122, 0.4989, 0.5111, 0.5005, 0.5028, 0.5019, 0.5015,
        0.5028, 0.5019, 0.5095, 0.4989, 0.4968, 0.4995, 0.4983],
       device='cuda:0') torch.Size([16])
percent tensor([0.5108, 0.4825, 0.5065, 0.5087, 0.4977, 0.5186, 0.4878, 0.4957, 0.5144,
        0.4905, 0.5102, 0.4960, 0.4934, 0.5067, 0.4939, 0.5062],
       device='cuda:0') torch.Size([16])
percent tensor([0.6370, 0.6443, 0.5825, 0.5494, 0.5768, 0.6017, 0.6506, 0.5881, 0.5740,
        0.6116, 0.6049, 0.5793, 0.6596, 0.5651, 0.6576, 0.6349],
       device='cuda:0') torch.Size([16])
percent tensor([0.5964, 0.6231, 0.6023, 0.6683, 0.6144, 0.6838, 0.6178, 0.5753, 0.6564,
        0.6221, 0.6529, 0.6666, 0.6130, 0.6791, 0.6536, 0.6183],
       device='cuda:0') torch.Size([16])
percent tensor([0.5954, 0.6154, 0.5893, 0.5875, 0.6304, 0.6051, 0.6096, 0.5368, 0.6638,
        0.6469, 0.6602, 0.5204, 0.5937, 0.7505, 0.4758, 0.6471],
       device='cuda:0') torch.Size([16])
percent tensor([0.6398, 0.5880, 0.7376, 0.7422, 0.7706, 0.7531, 0.6714, 0.7091, 0.6709,
        0.6478, 0.6432, 0.6968, 0.6147, 0.6426, 0.6778, 0.6893],
       device='cuda:0') torch.Size([16])
percent tensor([0.5994, 0.7190, 0.6820, 0.6707, 0.6658, 0.5941, 0.5647, 0.5630, 0.6980,
        0.6610, 0.7410, 0.6631, 0.6790, 0.6091, 0.5974, 0.4837],
       device='cuda:0') torch.Size([16])
percent tensor([0.9997, 0.9998, 0.9998, 0.9999, 0.9998, 0.9995, 0.9996, 0.9996, 0.9998,
        0.9999, 1.0000, 0.9998, 0.9999, 0.9996, 0.9991, 0.9995],
       device='cuda:0') torch.Size([16])
True Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=128, out_features=16, bias=False)
False Linear(in_features=16, out_features=2, bias=False)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=128, out_features=16, bias=False)
False Linear(in_features=16, out_features=2, bias=False)
True Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=256, out_features=32, bias=False)
False Linear(in_features=32, out_features=2, bias=False)
True Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=256, out_features=32, bias=False)
False Linear(in_features=32, out_features=2, bias=False)
True Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=512, out_features=64, bias=False)
False Linear(in_features=64, out_features=2, bias=False)
True Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=512, out_features=64, bias=False)
False Linear(in_features=64, out_features=2, bias=False)
True Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1024, out_features=128, bias=False)
False Linear(in_features=128, out_features=2, bias=False)
True Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1024, out_features=128, bias=False)
False Linear(in_features=128, out_features=2, bias=False)
True Linear(in_features=512, out_features=10, bias=True)
Epoch: 176 | Batch_idx: 0 |  Loss: (0.1022) |  Loss2: (0.0000) | Acc: (98.00%) (126/128)
Epoch: 176 | Batch_idx: 10 |  Loss: (0.1023) |  Loss2: (0.0000) | Acc: (96.00%) (1362/1408)
Epoch: 176 | Batch_idx: 20 |  Loss: (0.1030) |  Loss2: (0.0000) | Acc: (96.00%) (2597/2688)
Epoch: 176 | Batch_idx: 30 |  Loss: (0.0998) |  Loss2: (0.0000) | Acc: (96.00%) (3833/3968)
Epoch: 176 | Batch_idx: 40 |  Loss: (0.0983) |  Loss2: (0.0000) | Acc: (96.00%) (5078/5248)
Epoch: 176 | Batch_idx: 50 |  Loss: (0.0969) |  Loss2: (0.0000) | Acc: (96.00%) (6315/6528)
Epoch: 176 | Batch_idx: 60 |  Loss: (0.0977) |  Loss2: (0.0000) | Acc: (96.00%) (7548/7808)
Epoch: 176 | Batch_idx: 70 |  Loss: (0.0984) |  Loss2: (0.0000) | Acc: (96.00%) (8773/9088)
Epoch: 176 | Batch_idx: 80 |  Loss: (0.0991) |  Loss2: (0.0000) | Acc: (96.00%) (10008/10368)
Epoch: 176 | Batch_idx: 90 |  Loss: (0.0995) |  Loss2: (0.0000) | Acc: (96.00%) (11247/11648)
Epoch: 176 | Batch_idx: 100 |  Loss: (0.0992) |  Loss2: (0.0000) | Acc: (96.00%) (12491/12928)
Epoch: 176 | Batch_idx: 110 |  Loss: (0.0983) |  Loss2: (0.0000) | Acc: (96.00%) (13736/14208)
Epoch: 176 | Batch_idx: 120 |  Loss: (0.0985) |  Loss2: (0.0000) | Acc: (96.00%) (14966/15488)
Epoch: 176 | Batch_idx: 130 |  Loss: (0.0990) |  Loss2: (0.0000) | Acc: (96.00%) (16201/16768)
Epoch: 176 | Batch_idx: 140 |  Loss: (0.0998) |  Loss2: (0.0000) | Acc: (96.00%) (17432/18048)
Epoch: 176 | Batch_idx: 150 |  Loss: (0.0995) |  Loss2: (0.0000) | Acc: (96.00%) (18670/19328)
Epoch: 176 | Batch_idx: 160 |  Loss: (0.0999) |  Loss2: (0.0000) | Acc: (96.00%) (19905/20608)
Epoch: 176 | Batch_idx: 170 |  Loss: (0.1000) |  Loss2: (0.0000) | Acc: (96.00%) (21138/21888)
Epoch: 176 | Batch_idx: 180 |  Loss: (0.0995) |  Loss2: (0.0000) | Acc: (96.00%) (22379/23168)
Epoch: 176 | Batch_idx: 190 |  Loss: (0.1008) |  Loss2: (0.0000) | Acc: (96.00%) (23604/24448)
Epoch: 176 | Batch_idx: 200 |  Loss: (0.1015) |  Loss2: (0.0000) | Acc: (96.00%) (24831/25728)
Epoch: 176 | Batch_idx: 210 |  Loss: (0.1027) |  Loss2: (0.0000) | Acc: (96.00%) (26060/27008)
Epoch: 176 | Batch_idx: 220 |  Loss: (0.1031) |  Loss2: (0.0000) | Acc: (96.00%) (27294/28288)
Epoch: 176 | Batch_idx: 230 |  Loss: (0.1034) |  Loss2: (0.0000) | Acc: (96.00%) (28525/29568)
Epoch: 176 | Batch_idx: 240 |  Loss: (0.1041) |  Loss2: (0.0000) | Acc: (96.00%) (29754/30848)
Epoch: 176 | Batch_idx: 250 |  Loss: (0.1043) |  Loss2: (0.0000) | Acc: (96.00%) (30984/32128)
Epoch: 176 | Batch_idx: 260 |  Loss: (0.1040) |  Loss2: (0.0000) | Acc: (96.00%) (32227/33408)
Epoch: 176 | Batch_idx: 270 |  Loss: (0.1033) |  Loss2: (0.0000) | Acc: (96.00%) (33463/34688)
Epoch: 176 | Batch_idx: 280 |  Loss: (0.1032) |  Loss2: (0.0000) | Acc: (96.00%) (34693/35968)
Epoch: 176 | Batch_idx: 290 |  Loss: (0.1039) |  Loss2: (0.0000) | Acc: (96.00%) (35919/37248)
Epoch: 176 | Batch_idx: 300 |  Loss: (0.1048) |  Loss2: (0.0000) | Acc: (96.00%) (37135/38528)
Epoch: 176 | Batch_idx: 310 |  Loss: (0.1050) |  Loss2: (0.0000) | Acc: (96.00%) (38373/39808)
Epoch: 176 | Batch_idx: 320 |  Loss: (0.1049) |  Loss2: (0.0000) | Acc: (96.00%) (39606/41088)
Epoch: 176 | Batch_idx: 330 |  Loss: (0.1054) |  Loss2: (0.0000) | Acc: (96.00%) (40829/42368)
Epoch: 176 | Batch_idx: 340 |  Loss: (0.1059) |  Loss2: (0.0000) | Acc: (96.00%) (42054/43648)
Epoch: 176 | Batch_idx: 350 |  Loss: (0.1062) |  Loss2: (0.0000) | Acc: (96.00%) (43279/44928)
Epoch: 176 | Batch_idx: 360 |  Loss: (0.1061) |  Loss2: (0.0000) | Acc: (96.00%) (44513/46208)
Epoch: 176 | Batch_idx: 370 |  Loss: (0.1063) |  Loss2: (0.0000) | Acc: (96.00%) (45739/47488)
Epoch: 176 | Batch_idx: 380 |  Loss: (0.1068) |  Loss2: (0.0000) | Acc: (96.00%) (46958/48768)
Epoch: 176 | Batch_idx: 390 |  Loss: (0.1066) |  Loss2: (0.0000) | Acc: (96.00%) (48149/50000)
# TEST : Loss: (0.4551) | Acc: (87.00%) (8729/10000)
percent tensor([0.4999, 0.4994, 0.5105, 0.4996, 0.5095, 0.5010, 0.5026, 0.5020, 0.5012,
        0.5029, 0.5020, 0.5081, 0.4988, 0.4968, 0.5002, 0.4986],
       device='cuda:0') torch.Size([16])
percent tensor([0.5098, 0.4820, 0.5100, 0.5161, 0.5016, 0.5204, 0.4877, 0.4975, 0.5135,
        0.4910, 0.5092, 0.5003, 0.4939, 0.5026, 0.4952, 0.5068],
       device='cuda:0') torch.Size([16])
percent tensor([0.6386, 0.6438, 0.5757, 0.5493, 0.5763, 0.5924, 0.6550, 0.5856, 0.5776,
        0.6108, 0.6052, 0.5739, 0.6619, 0.5770, 0.6490, 0.6315],
       device='cuda:0') torch.Size([16])
percent tensor([0.6021, 0.6365, 0.6047, 0.6633, 0.6148, 0.6805, 0.6269, 0.5805, 0.6768,
        0.6304, 0.6618, 0.6731, 0.6231, 0.6928, 0.6607, 0.6186],
       device='cuda:0') torch.Size([16])
percent tensor([0.5932, 0.5985, 0.6082, 0.5926, 0.6375, 0.6070, 0.6021, 0.5498, 0.6545,
        0.6245, 0.6522, 0.5318, 0.5851, 0.7286, 0.4748, 0.6472],
       device='cuda:0') torch.Size([16])
percent tensor([0.6466, 0.5931, 0.7367, 0.7449, 0.7805, 0.7505, 0.6727, 0.7142, 0.6837,
        0.6466, 0.6447, 0.7054, 0.6141, 0.6479, 0.6759, 0.6861],
       device='cuda:0') torch.Size([16])
percent tensor([0.5965, 0.7195, 0.6722, 0.6534, 0.6752, 0.5675, 0.5572, 0.5658, 0.7106,
        0.6765, 0.7380, 0.6315, 0.6763, 0.6399, 0.5868, 0.4766],
       device='cuda:0') torch.Size([16])
percent tensor([0.9997, 0.9998, 0.9997, 0.9998, 0.9997, 0.9993, 0.9998, 0.9991, 0.9998,
        0.9999, 1.0000, 0.9999, 0.9999, 0.9998, 0.9993, 0.9993],
       device='cuda:0') torch.Size([16])
Epoch: 177 | Batch_idx: 0 |  Loss: (0.0458) |  Loss2: (0.0000) | Acc: (100.00%) (128/128)
Epoch: 177 | Batch_idx: 10 |  Loss: (0.0990) |  Loss2: (0.0000) | Acc: (96.00%) (1365/1408)
Epoch: 177 | Batch_idx: 20 |  Loss: (0.0904) |  Loss2: (0.0000) | Acc: (97.00%) (2612/2688)
Epoch: 177 | Batch_idx: 30 |  Loss: (0.0916) |  Loss2: (0.0000) | Acc: (97.00%) (3850/3968)
Epoch: 177 | Batch_idx: 40 |  Loss: (0.0905) |  Loss2: (0.0000) | Acc: (97.00%) (5095/5248)
Epoch: 177 | Batch_idx: 50 |  Loss: (0.0958) |  Loss2: (0.0000) | Acc: (96.00%) (6322/6528)
Epoch: 177 | Batch_idx: 60 |  Loss: (0.0987) |  Loss2: (0.0000) | Acc: (96.00%) (7554/7808)
Epoch: 177 | Batch_idx: 70 |  Loss: (0.0980) |  Loss2: (0.0000) | Acc: (96.00%) (8794/9088)
Epoch: 177 | Batch_idx: 80 |  Loss: (0.0981) |  Loss2: (0.0000) | Acc: (96.00%) (10034/10368)
Epoch: 177 | Batch_idx: 90 |  Loss: (0.0974) |  Loss2: (0.0000) | Acc: (96.00%) (11273/11648)
Epoch: 177 | Batch_idx: 100 |  Loss: (0.0955) |  Loss2: (0.0000) | Acc: (96.00%) (12524/12928)
Epoch: 177 | Batch_idx: 110 |  Loss: (0.0947) |  Loss2: (0.0000) | Acc: (96.00%) (13769/14208)
Epoch: 177 | Batch_idx: 120 |  Loss: (0.0951) |  Loss2: (0.0000) | Acc: (96.00%) (15004/15488)
Epoch: 177 | Batch_idx: 130 |  Loss: (0.0949) |  Loss2: (0.0000) | Acc: (96.00%) (16245/16768)
Epoch: 177 | Batch_idx: 140 |  Loss: (0.0957) |  Loss2: (0.0000) | Acc: (96.00%) (17480/18048)
Epoch: 177 | Batch_idx: 150 |  Loss: (0.0955) |  Loss2: (0.0000) | Acc: (96.00%) (18714/19328)
Epoch: 177 | Batch_idx: 160 |  Loss: (0.0970) |  Loss2: (0.0000) | Acc: (96.00%) (19942/20608)
Epoch: 177 | Batch_idx: 170 |  Loss: (0.0975) |  Loss2: (0.0000) | Acc: (96.00%) (21170/21888)
Epoch: 177 | Batch_idx: 180 |  Loss: (0.0974) |  Loss2: (0.0000) | Acc: (96.00%) (22411/23168)
Epoch: 177 | Batch_idx: 190 |  Loss: (0.0988) |  Loss2: (0.0000) | Acc: (96.00%) (23642/24448)
Epoch: 177 | Batch_idx: 200 |  Loss: (0.0992) |  Loss2: (0.0000) | Acc: (96.00%) (24875/25728)
Epoch: 177 | Batch_idx: 210 |  Loss: (0.0989) |  Loss2: (0.0000) | Acc: (96.00%) (26112/27008)
Epoch: 177 | Batch_idx: 220 |  Loss: (0.0991) |  Loss2: (0.0000) | Acc: (96.00%) (27346/28288)
Epoch: 177 | Batch_idx: 230 |  Loss: (0.0990) |  Loss2: (0.0000) | Acc: (96.00%) (28586/29568)
Epoch: 177 | Batch_idx: 240 |  Loss: (0.0990) |  Loss2: (0.0000) | Acc: (96.00%) (29824/30848)
Epoch: 177 | Batch_idx: 250 |  Loss: (0.0990) |  Loss2: (0.0000) | Acc: (96.00%) (31063/32128)
Epoch: 177 | Batch_idx: 260 |  Loss: (0.0987) |  Loss2: (0.0000) | Acc: (96.00%) (32304/33408)
Epoch: 177 | Batch_idx: 270 |  Loss: (0.0984) |  Loss2: (0.0000) | Acc: (96.00%) (33546/34688)
Epoch: 177 | Batch_idx: 280 |  Loss: (0.0985) |  Loss2: (0.0000) | Acc: (96.00%) (34782/35968)
Epoch: 177 | Batch_idx: 290 |  Loss: (0.0986) |  Loss2: (0.0000) | Acc: (96.00%) (36014/37248)
Epoch: 177 | Batch_idx: 300 |  Loss: (0.0988) |  Loss2: (0.0000) | Acc: (96.00%) (37248/38528)
Epoch: 177 | Batch_idx: 310 |  Loss: (0.0989) |  Loss2: (0.0000) | Acc: (96.00%) (38483/39808)
Epoch: 177 | Batch_idx: 320 |  Loss: (0.0995) |  Loss2: (0.0000) | Acc: (96.00%) (39708/41088)
Epoch: 177 | Batch_idx: 330 |  Loss: (0.0995) |  Loss2: (0.0000) | Acc: (96.00%) (40944/42368)
Epoch: 177 | Batch_idx: 340 |  Loss: (0.0993) |  Loss2: (0.0000) | Acc: (96.00%) (42179/43648)
Epoch: 177 | Batch_idx: 350 |  Loss: (0.1000) |  Loss2: (0.0000) | Acc: (96.00%) (43399/44928)
Epoch: 177 | Batch_idx: 360 |  Loss: (0.1013) |  Loss2: (0.0000) | Acc: (96.00%) (44606/46208)
Epoch: 177 | Batch_idx: 370 |  Loss: (0.1014) |  Loss2: (0.0000) | Acc: (96.00%) (45840/47488)
Epoch: 177 | Batch_idx: 380 |  Loss: (0.1019) |  Loss2: (0.0000) | Acc: (96.00%) (47066/48768)
Epoch: 177 | Batch_idx: 390 |  Loss: (0.1022) |  Loss2: (0.0000) | Acc: (96.00%) (48246/50000)
# TEST : Loss: (0.4146) | Acc: (88.00%) (8805/10000)
percent tensor([0.5000, 0.4989, 0.5133, 0.5001, 0.5116, 0.5008, 0.5030, 0.5025, 0.5012,
        0.5031, 0.5013, 0.5100, 0.4989, 0.4966, 0.4999, 0.4981],
       device='cuda:0') torch.Size([16])
percent tensor([0.5083, 0.4827, 0.5118, 0.5145, 0.5025, 0.5187, 0.4890, 0.4975, 0.5128,
        0.4910, 0.5085, 0.5023, 0.4914, 0.5067, 0.4940, 0.5062],
       device='cuda:0') torch.Size([16])
percent tensor([0.6406, 0.6335, 0.5737, 0.5436, 0.5761, 0.6031, 0.6509, 0.5816, 0.5854,
        0.6044, 0.6110, 0.5790, 0.6648, 0.5648, 0.6495, 0.6284],
       device='cuda:0') torch.Size([16])
percent tensor([0.6028, 0.6296, 0.6138, 0.6597, 0.6215, 0.6935, 0.6258, 0.5742, 0.6671,
        0.6235, 0.6581, 0.6687, 0.6301, 0.6759, 0.6649, 0.6179],
       device='cuda:0') torch.Size([16])
percent tensor([0.5791, 0.6155, 0.5937, 0.5745, 0.6306, 0.6064, 0.6106, 0.5411, 0.6584,
        0.6377, 0.6566, 0.5250, 0.5936, 0.7231, 0.4866, 0.6376],
       device='cuda:0') torch.Size([16])
percent tensor([0.6303, 0.5926, 0.7272, 0.7440, 0.7722, 0.7513, 0.6797, 0.7174, 0.6826,
        0.6458, 0.6423, 0.6979, 0.6242, 0.6637, 0.6738, 0.6837],
       device='cuda:0') torch.Size([16])
percent tensor([0.5898, 0.7025, 0.6931, 0.6270, 0.6765, 0.6050, 0.5744, 0.5538, 0.7055,
        0.6593, 0.7320, 0.6567, 0.6802, 0.6023, 0.5782, 0.4769],
       device='cuda:0') torch.Size([16])
percent tensor([0.9998, 0.9999, 0.9998, 0.9998, 0.9998, 0.9994, 0.9998, 0.9995, 0.9999,
        0.9999, 1.0000, 0.9999, 0.9999, 0.9996, 0.9991, 0.9996],
       device='cuda:0') torch.Size([16])
Epoch: 178 | Batch_idx: 0 |  Loss: (0.0919) |  Loss2: (0.0000) | Acc: (96.00%) (124/128)
Epoch: 178 | Batch_idx: 10 |  Loss: (0.1055) |  Loss2: (0.0000) | Acc: (95.00%) (1350/1408)
Epoch: 178 | Batch_idx: 20 |  Loss: (0.1036) |  Loss2: (0.0000) | Acc: (96.00%) (2583/2688)
Epoch: 178 | Batch_idx: 30 |  Loss: (0.1043) |  Loss2: (0.0000) | Acc: (96.00%) (3813/3968)
Epoch: 178 | Batch_idx: 40 |  Loss: (0.1029) |  Loss2: (0.0000) | Acc: (96.00%) (5044/5248)
Epoch: 178 | Batch_idx: 50 |  Loss: (0.1015) |  Loss2: (0.0000) | Acc: (96.00%) (6281/6528)
Epoch: 178 | Batch_idx: 60 |  Loss: (0.0983) |  Loss2: (0.0000) | Acc: (96.00%) (7525/7808)
Epoch: 178 | Batch_idx: 70 |  Loss: (0.0978) |  Loss2: (0.0000) | Acc: (96.00%) (8759/9088)
Epoch: 178 | Batch_idx: 80 |  Loss: (0.0999) |  Loss2: (0.0000) | Acc: (96.00%) (9989/10368)
Epoch: 178 | Batch_idx: 90 |  Loss: (0.0990) |  Loss2: (0.0000) | Acc: (96.00%) (11230/11648)
Epoch: 178 | Batch_idx: 100 |  Loss: (0.0975) |  Loss2: (0.0000) | Acc: (96.00%) (12477/12928)
Epoch: 178 | Batch_idx: 110 |  Loss: (0.0970) |  Loss2: (0.0000) | Acc: (96.00%) (13716/14208)
Epoch: 178 | Batch_idx: 120 |  Loss: (0.0971) |  Loss2: (0.0000) | Acc: (96.00%) (14949/15488)
Epoch: 178 | Batch_idx: 130 |  Loss: (0.0969) |  Loss2: (0.0000) | Acc: (96.00%) (16188/16768)
Epoch: 178 | Batch_idx: 140 |  Loss: (0.0974) |  Loss2: (0.0000) | Acc: (96.00%) (17418/18048)
Epoch: 178 | Batch_idx: 150 |  Loss: (0.0971) |  Loss2: (0.0000) | Acc: (96.00%) (18662/19328)
Epoch: 178 | Batch_idx: 160 |  Loss: (0.0971) |  Loss2: (0.0000) | Acc: (96.00%) (19898/20608)
Epoch: 178 | Batch_idx: 170 |  Loss: (0.0977) |  Loss2: (0.0000) | Acc: (96.00%) (21128/21888)
Epoch: 178 | Batch_idx: 180 |  Loss: (0.0976) |  Loss2: (0.0000) | Acc: (96.00%) (22370/23168)
Epoch: 178 | Batch_idx: 190 |  Loss: (0.0975) |  Loss2: (0.0000) | Acc: (96.00%) (23606/24448)
Epoch: 178 | Batch_idx: 200 |  Loss: (0.0971) |  Loss2: (0.0000) | Acc: (96.00%) (24843/25728)
Epoch: 178 | Batch_idx: 210 |  Loss: (0.0970) |  Loss2: (0.0000) | Acc: (96.00%) (26082/27008)
Epoch: 178 | Batch_idx: 220 |  Loss: (0.0972) |  Loss2: (0.0000) | Acc: (96.00%) (27318/28288)
Epoch: 178 | Batch_idx: 230 |  Loss: (0.0971) |  Loss2: (0.0000) | Acc: (96.00%) (28561/29568)
Epoch: 178 | Batch_idx: 240 |  Loss: (0.0971) |  Loss2: (0.0000) | Acc: (96.00%) (29805/30848)
Epoch: 178 | Batch_idx: 250 |  Loss: (0.0971) |  Loss2: (0.0000) | Acc: (96.00%) (31043/32128)
Epoch: 178 | Batch_idx: 260 |  Loss: (0.0972) |  Loss2: (0.0000) | Acc: (96.00%) (32277/33408)
Epoch: 178 | Batch_idx: 270 |  Loss: (0.0974) |  Loss2: (0.0000) | Acc: (96.00%) (33510/34688)
Epoch: 178 | Batch_idx: 280 |  Loss: (0.0971) |  Loss2: (0.0000) | Acc: (96.00%) (34751/35968)
Epoch: 178 | Batch_idx: 290 |  Loss: (0.0968) |  Loss2: (0.0000) | Acc: (96.00%) (35989/37248)
Epoch: 178 | Batch_idx: 300 |  Loss: (0.0969) |  Loss2: (0.0000) | Acc: (96.00%) (37228/38528)
Epoch: 178 | Batch_idx: 310 |  Loss: (0.0974) |  Loss2: (0.0000) | Acc: (96.00%) (38458/39808)
Epoch: 178 | Batch_idx: 320 |  Loss: (0.0976) |  Loss2: (0.0000) | Acc: (96.00%) (39696/41088)
Epoch: 178 | Batch_idx: 330 |  Loss: (0.0975) |  Loss2: (0.0000) | Acc: (96.00%) (40929/42368)
Epoch: 178 | Batch_idx: 340 |  Loss: (0.0978) |  Loss2: (0.0000) | Acc: (96.00%) (42154/43648)
Epoch: 178 | Batch_idx: 350 |  Loss: (0.0979) |  Loss2: (0.0000) | Acc: (96.00%) (43389/44928)
Epoch: 178 | Batch_idx: 360 |  Loss: (0.0981) |  Loss2: (0.0000) | Acc: (96.00%) (44619/46208)
Epoch: 178 | Batch_idx: 370 |  Loss: (0.0983) |  Loss2: (0.0000) | Acc: (96.00%) (45853/47488)
Epoch: 178 | Batch_idx: 380 |  Loss: (0.0981) |  Loss2: (0.0000) | Acc: (96.00%) (47098/48768)
Epoch: 178 | Batch_idx: 390 |  Loss: (0.0986) |  Loss2: (0.0000) | Acc: (96.00%) (48279/50000)
# TEST : Loss: (0.4263) | Acc: (87.00%) (8794/10000)
percent tensor([0.4998, 0.4996, 0.5103, 0.4990, 0.5092, 0.5006, 0.5028, 0.5017, 0.5017,
        0.5029, 0.5023, 0.5081, 0.4991, 0.4968, 0.5000, 0.4982],
       device='cuda:0') torch.Size([16])
percent tensor([0.5091, 0.4797, 0.5152, 0.5133, 0.5045, 0.5186, 0.4871, 0.4984, 0.5118,
        0.4905, 0.5073, 0.5040, 0.4920, 0.5002, 0.4924, 0.5043],
       device='cuda:0') torch.Size([16])
percent tensor([0.6389, 0.6416, 0.5579, 0.5434, 0.5650, 0.5982, 0.6517, 0.5827, 0.5818,
        0.6041, 0.6100, 0.5639, 0.6652, 0.5815, 0.6515, 0.6335],
       device='cuda:0') torch.Size([16])
percent tensor([0.5901, 0.6236, 0.6127, 0.6639, 0.6145, 0.6733, 0.6196, 0.5777, 0.6566,
        0.6294, 0.6535, 0.6733, 0.6144, 0.6752, 0.6536, 0.6144],
       device='cuda:0') torch.Size([16])
percent tensor([0.5970, 0.6115, 0.6083, 0.5945, 0.6434, 0.6116, 0.6021, 0.5365, 0.6479,
        0.6562, 0.6583, 0.5530, 0.5916, 0.7335, 0.4770, 0.6470],
       device='cuda:0') torch.Size([16])
percent tensor([0.6214, 0.5928, 0.7182, 0.7311, 0.7650, 0.7482, 0.6624, 0.7007, 0.6570,
        0.6431, 0.6239, 0.6920, 0.6145, 0.6449, 0.6606, 0.6798],
       device='cuda:0') torch.Size([16])
percent tensor([0.5607, 0.7052, 0.6641, 0.6100, 0.6395, 0.5830, 0.5575, 0.5426, 0.6851,
        0.6374, 0.7304, 0.6264, 0.6749, 0.6121, 0.5643, 0.4840],
       device='cuda:0') torch.Size([16])
percent tensor([0.9997, 0.9998, 0.9998, 0.9998, 0.9997, 0.9994, 0.9997, 0.9997, 0.9999,
        0.9999, 1.0000, 0.9999, 0.9999, 0.9996, 0.9991, 0.9991],
       device='cuda:0') torch.Size([16])
Epoch: 179 | Batch_idx: 0 |  Loss: (0.0757) |  Loss2: (0.0000) | Acc: (97.00%) (125/128)
Epoch: 179 | Batch_idx: 10 |  Loss: (0.1027) |  Loss2: (0.0000) | Acc: (96.00%) (1360/1408)
Epoch: 179 | Batch_idx: 20 |  Loss: (0.0970) |  Loss2: (0.0000) | Acc: (96.00%) (2601/2688)
Epoch: 179 | Batch_idx: 30 |  Loss: (0.0973) |  Loss2: (0.0000) | Acc: (96.00%) (3837/3968)
Epoch: 179 | Batch_idx: 40 |  Loss: (0.0993) |  Loss2: (0.0000) | Acc: (96.00%) (5070/5248)
Epoch: 179 | Batch_idx: 50 |  Loss: (0.0991) |  Loss2: (0.0000) | Acc: (96.00%) (6306/6528)
Epoch: 179 | Batch_idx: 60 |  Loss: (0.0977) |  Loss2: (0.0000) | Acc: (96.00%) (7550/7808)
Epoch: 179 | Batch_idx: 70 |  Loss: (0.0960) |  Loss2: (0.0000) | Acc: (96.00%) (8792/9088)
Epoch: 179 | Batch_idx: 80 |  Loss: (0.0968) |  Loss2: (0.0000) | Acc: (96.00%) (10025/10368)
Epoch: 179 | Batch_idx: 90 |  Loss: (0.0959) |  Loss2: (0.0000) | Acc: (96.00%) (11264/11648)
Epoch: 179 | Batch_idx: 100 |  Loss: (0.0952) |  Loss2: (0.0000) | Acc: (96.00%) (12505/12928)
Epoch: 179 | Batch_idx: 110 |  Loss: (0.0942) |  Loss2: (0.0000) | Acc: (96.00%) (13756/14208)
Epoch: 179 | Batch_idx: 120 |  Loss: (0.0945) |  Loss2: (0.0000) | Acc: (96.00%) (14990/15488)
Epoch: 179 | Batch_idx: 130 |  Loss: (0.0952) |  Loss2: (0.0000) | Acc: (96.00%) (16224/16768)
Epoch: 179 | Batch_idx: 140 |  Loss: (0.0940) |  Loss2: (0.0000) | Acc: (96.00%) (17469/18048)
Epoch: 179 | Batch_idx: 150 |  Loss: (0.0932) |  Loss2: (0.0000) | Acc: (96.00%) (18715/19328)
Epoch: 179 | Batch_idx: 160 |  Loss: (0.0934) |  Loss2: (0.0000) | Acc: (96.00%) (19957/20608)
Epoch: 179 | Batch_idx: 170 |  Loss: (0.0930) |  Loss2: (0.0000) | Acc: (96.00%) (21194/21888)
Epoch: 179 | Batch_idx: 180 |  Loss: (0.0939) |  Loss2: (0.0000) | Acc: (96.00%) (22422/23168)
Epoch: 179 | Batch_idx: 190 |  Loss: (0.0936) |  Loss2: (0.0000) | Acc: (96.00%) (23664/24448)
Epoch: 179 | Batch_idx: 200 |  Loss: (0.0938) |  Loss2: (0.0000) | Acc: (96.00%) (24898/25728)
Epoch: 179 | Batch_idx: 210 |  Loss: (0.0938) |  Loss2: (0.0000) | Acc: (96.00%) (26136/27008)
Epoch: 179 | Batch_idx: 220 |  Loss: (0.0941) |  Loss2: (0.0000) | Acc: (96.00%) (27373/28288)
Epoch: 179 | Batch_idx: 230 |  Loss: (0.0947) |  Loss2: (0.0000) | Acc: (96.00%) (28610/29568)
Epoch: 179 | Batch_idx: 240 |  Loss: (0.0950) |  Loss2: (0.0000) | Acc: (96.00%) (29843/30848)
Epoch: 179 | Batch_idx: 250 |  Loss: (0.0955) |  Loss2: (0.0000) | Acc: (96.00%) (31075/32128)
Epoch: 179 | Batch_idx: 260 |  Loss: (0.0954) |  Loss2: (0.0000) | Acc: (96.00%) (32321/33408)
Epoch: 179 | Batch_idx: 270 |  Loss: (0.0952) |  Loss2: (0.0000) | Acc: (96.00%) (33562/34688)
Epoch: 179 | Batch_idx: 280 |  Loss: (0.0954) |  Loss2: (0.0000) | Acc: (96.00%) (34795/35968)
Epoch: 179 | Batch_idx: 290 |  Loss: (0.0958) |  Loss2: (0.0000) | Acc: (96.00%) (36019/37248)
Epoch: 179 | Batch_idx: 300 |  Loss: (0.0966) |  Loss2: (0.0000) | Acc: (96.00%) (37247/38528)
Epoch: 179 | Batch_idx: 310 |  Loss: (0.0966) |  Loss2: (0.0000) | Acc: (96.00%) (38478/39808)
Epoch: 179 | Batch_idx: 320 |  Loss: (0.0965) |  Loss2: (0.0000) | Acc: (96.00%) (39718/41088)
Epoch: 179 | Batch_idx: 330 |  Loss: (0.0964) |  Loss2: (0.0000) | Acc: (96.00%) (40952/42368)
Epoch: 179 | Batch_idx: 340 |  Loss: (0.0967) |  Loss2: (0.0000) | Acc: (96.00%) (42185/43648)
Epoch: 179 | Batch_idx: 350 |  Loss: (0.0973) |  Loss2: (0.0000) | Acc: (96.00%) (43408/44928)
Epoch: 179 | Batch_idx: 360 |  Loss: (0.0973) |  Loss2: (0.0000) | Acc: (96.00%) (44642/46208)
Epoch: 179 | Batch_idx: 370 |  Loss: (0.0978) |  Loss2: (0.0000) | Acc: (96.00%) (45869/47488)
Epoch: 179 | Batch_idx: 380 |  Loss: (0.0977) |  Loss2: (0.0000) | Acc: (96.00%) (47115/48768)
Epoch: 179 | Batch_idx: 390 |  Loss: (0.0978) |  Loss2: (0.0000) | Acc: (96.00%) (48306/50000)
# TEST : Loss: (0.4133) | Acc: (88.00%) (8869/10000)
percent tensor([0.4996, 0.4992, 0.5120, 0.4991, 0.5107, 0.5002, 0.5032, 0.5022, 0.5012,
        0.5031, 0.5016, 0.5093, 0.4988, 0.4963, 0.4997, 0.4978],
       device='cuda:0') torch.Size([16])
percent tensor([0.5092, 0.4828, 0.5089, 0.5128, 0.5000, 0.5174, 0.4878, 0.4978, 0.5130,
        0.4911, 0.5099, 0.4995, 0.4922, 0.5050, 0.4944, 0.5055],
       device='cuda:0') torch.Size([16])
percent tensor([0.6383, 0.6382, 0.5630, 0.5368, 0.5691, 0.6047, 0.6505, 0.5808, 0.5774,
        0.6030, 0.6065, 0.5665, 0.6616, 0.5770, 0.6488, 0.6299],
       device='cuda:0') torch.Size([16])
percent tensor([0.5933, 0.6289, 0.6038, 0.6631, 0.6262, 0.6836, 0.6305, 0.5743, 0.6635,
        0.6248, 0.6562, 0.6742, 0.6220, 0.6775, 0.6608, 0.6152],
       device='cuda:0') torch.Size([16])
percent tensor([0.5993, 0.6181, 0.6102, 0.5984, 0.6358, 0.5981, 0.6117, 0.5555, 0.6685,
        0.6584, 0.6726, 0.5444, 0.5970, 0.7398, 0.4875, 0.6499],
       device='cuda:0') torch.Size([16])
percent tensor([0.6412, 0.6018, 0.7311, 0.7454, 0.7769, 0.7637, 0.6852, 0.7184, 0.6802,
        0.6406, 0.6431, 0.6978, 0.6274, 0.6647, 0.6792, 0.6965],
       device='cuda:0') torch.Size([16])
percent tensor([0.5759, 0.7210, 0.6962, 0.6646, 0.6739, 0.5813, 0.5709, 0.5866, 0.6823,
        0.6550, 0.7391, 0.6654, 0.6801, 0.6014, 0.5919, 0.4772],
       device='cuda:0') torch.Size([16])
percent tensor([0.9998, 0.9998, 0.9999, 0.9999, 0.9998, 0.9996, 0.9997, 0.9998, 0.9998,
        0.9998, 1.0000, 0.9999, 0.9998, 0.9994, 0.9992, 0.9994],
       device='cuda:0') torch.Size([16])
Epoch: 180 | Batch_idx: 0 |  Loss: (0.0498) |  Loss2: (0.0000) | Acc: (99.00%) (127/128)
Epoch: 180 | Batch_idx: 10 |  Loss: (0.0809) |  Loss2: (0.0000) | Acc: (97.00%) (1371/1408)
Epoch: 180 | Batch_idx: 20 |  Loss: (0.0889) |  Loss2: (0.0000) | Acc: (97.00%) (2610/2688)
Epoch: 180 | Batch_idx: 30 |  Loss: (0.0870) |  Loss2: (0.0000) | Acc: (97.00%) (3850/3968)
Epoch: 180 | Batch_idx: 40 |  Loss: (0.0865) |  Loss2: (0.0000) | Acc: (97.00%) (5097/5248)
Epoch: 180 | Batch_idx: 50 |  Loss: (0.0856) |  Loss2: (0.0000) | Acc: (97.00%) (6344/6528)
Epoch: 180 | Batch_idx: 60 |  Loss: (0.0863) |  Loss2: (0.0000) | Acc: (97.00%) (7590/7808)
Epoch: 180 | Batch_idx: 70 |  Loss: (0.0861) |  Loss2: (0.0000) | Acc: (97.00%) (8844/9088)
Epoch: 180 | Batch_idx: 80 |  Loss: (0.0857) |  Loss2: (0.0000) | Acc: (97.00%) (10088/10368)
Epoch: 180 | Batch_idx: 90 |  Loss: (0.0854) |  Loss2: (0.0000) | Acc: (97.00%) (11340/11648)
Epoch: 180 | Batch_idx: 100 |  Loss: (0.0850) |  Loss2: (0.0000) | Acc: (97.00%) (12587/12928)
Epoch: 180 | Batch_idx: 110 |  Loss: (0.0847) |  Loss2: (0.0000) | Acc: (97.00%) (13833/14208)
Epoch: 180 | Batch_idx: 120 |  Loss: (0.0859) |  Loss2: (0.0000) | Acc: (97.00%) (15070/15488)
Epoch: 180 | Batch_idx: 130 |  Loss: (0.0871) |  Loss2: (0.0000) | Acc: (97.00%) (16300/16768)
Epoch: 180 | Batch_idx: 140 |  Loss: (0.0871) |  Loss2: (0.0000) | Acc: (97.00%) (17544/18048)
Epoch: 180 | Batch_idx: 150 |  Loss: (0.0890) |  Loss2: (0.0000) | Acc: (97.00%) (18766/19328)
Epoch: 180 | Batch_idx: 160 |  Loss: (0.0900) |  Loss2: (0.0000) | Acc: (97.00%) (20006/20608)
Epoch: 180 | Batch_idx: 170 |  Loss: (0.0898) |  Loss2: (0.0000) | Acc: (97.00%) (21254/21888)
Epoch: 180 | Batch_idx: 180 |  Loss: (0.0905) |  Loss2: (0.0000) | Acc: (97.00%) (22487/23168)
Epoch: 180 | Batch_idx: 190 |  Loss: (0.0895) |  Loss2: (0.0000) | Acc: (97.00%) (23740/24448)
Epoch: 180 | Batch_idx: 200 |  Loss: (0.0894) |  Loss2: (0.0000) | Acc: (97.00%) (24977/25728)
Epoch: 180 | Batch_idx: 210 |  Loss: (0.0900) |  Loss2: (0.0000) | Acc: (97.00%) (26212/27008)
Epoch: 180 | Batch_idx: 220 |  Loss: (0.0898) |  Loss2: (0.0000) | Acc: (97.00%) (27455/28288)
Epoch: 180 | Batch_idx: 230 |  Loss: (0.0903) |  Loss2: (0.0000) | Acc: (97.00%) (28689/29568)
Epoch: 180 | Batch_idx: 240 |  Loss: (0.0904) |  Loss2: (0.0000) | Acc: (97.00%) (29930/30848)
Epoch: 180 | Batch_idx: 250 |  Loss: (0.0917) |  Loss2: (0.0000) | Acc: (96.00%) (31153/32128)
Epoch: 180 | Batch_idx: 260 |  Loss: (0.0921) |  Loss2: (0.0000) | Acc: (96.00%) (32377/33408)
Epoch: 180 | Batch_idx: 270 |  Loss: (0.0921) |  Loss2: (0.0000) | Acc: (96.00%) (33609/34688)
Epoch: 180 | Batch_idx: 280 |  Loss: (0.0926) |  Loss2: (0.0000) | Acc: (96.00%) (34846/35968)
Epoch: 180 | Batch_idx: 290 |  Loss: (0.0931) |  Loss2: (0.0000) | Acc: (96.00%) (36083/37248)
Epoch: 180 | Batch_idx: 300 |  Loss: (0.0941) |  Loss2: (0.0000) | Acc: (96.00%) (37301/38528)
Epoch: 180 | Batch_idx: 310 |  Loss: (0.0951) |  Loss2: (0.0000) | Acc: (96.00%) (38527/39808)
Epoch: 180 | Batch_idx: 320 |  Loss: (0.0955) |  Loss2: (0.0000) | Acc: (96.00%) (39768/41088)
Epoch: 180 | Batch_idx: 330 |  Loss: (0.0955) |  Loss2: (0.0000) | Acc: (96.00%) (41007/42368)
Epoch: 180 | Batch_idx: 340 |  Loss: (0.0954) |  Loss2: (0.0000) | Acc: (96.00%) (42246/43648)
Epoch: 180 | Batch_idx: 350 |  Loss: (0.0958) |  Loss2: (0.0000) | Acc: (96.00%) (43473/44928)
Epoch: 180 | Batch_idx: 360 |  Loss: (0.0965) |  Loss2: (0.0000) | Acc: (96.00%) (44697/46208)
Epoch: 180 | Batch_idx: 370 |  Loss: (0.0966) |  Loss2: (0.0000) | Acc: (96.00%) (45931/47488)
Epoch: 180 | Batch_idx: 380 |  Loss: (0.0969) |  Loss2: (0.0000) | Acc: (96.00%) (47157/48768)
Epoch: 180 | Batch_idx: 390 |  Loss: (0.0968) |  Loss2: (0.0000) | Acc: (96.00%) (48354/50000)
=> saving checkpoint 'drive/app/torch/save_Schedule/checkpoint_180.pth.tar'
# TEST : Loss: (0.4313) | Acc: (87.00%) (8780/10000)
percent tensor([0.4996, 0.4998, 0.5122, 0.4995, 0.5107, 0.5003, 0.5035, 0.5028, 0.5013,
        0.5033, 0.5019, 0.5091, 0.4985, 0.4971, 0.5002, 0.4983],
       device='cuda:0') torch.Size([16])
percent tensor([0.5065, 0.4854, 0.5031, 0.5115, 0.4964, 0.5166, 0.4884, 0.4964, 0.5108,
        0.4911, 0.5069, 0.4959, 0.4913, 0.5089, 0.4928, 0.5041],
       device='cuda:0') torch.Size([16])
percent tensor([0.6442, 0.6248, 0.5808, 0.5405, 0.5824, 0.6032, 0.6499, 0.5807, 0.5865,
        0.5989, 0.6074, 0.5796, 0.6658, 0.5655, 0.6440, 0.6263],
       device='cuda:0') torch.Size([16])
percent tensor([0.5969, 0.6287, 0.6012, 0.6611, 0.6206, 0.6898, 0.6230, 0.5710, 0.6498,
        0.6302, 0.6522, 0.6596, 0.6103, 0.6779, 0.6613, 0.6192],
       device='cuda:0') torch.Size([16])
percent tensor([0.5989, 0.6330, 0.5961, 0.5976, 0.6373, 0.6010, 0.6271, 0.5674, 0.6642,
        0.6649, 0.6639, 0.5314, 0.5899, 0.7508, 0.4980, 0.6486],
       device='cuda:0') torch.Size([16])
percent tensor([0.6525, 0.6053, 0.7404, 0.7462, 0.7791, 0.7584, 0.6861, 0.7149, 0.6730,
        0.6599, 0.6394, 0.7023, 0.6298, 0.6605, 0.6737, 0.6877],
       device='cuda:0') torch.Size([16])
percent tensor([0.5932, 0.7002, 0.7074, 0.6708, 0.6932, 0.6275, 0.5587, 0.5624, 0.7103,
        0.6378, 0.7306, 0.6774, 0.6752, 0.5859, 0.6150, 0.4862],
       device='cuda:0') torch.Size([16])
percent tensor([0.9997, 0.9998, 0.9998, 0.9999, 0.9997, 0.9995, 0.9998, 0.9990, 0.9998,
        0.9999, 1.0000, 0.9999, 0.9998, 0.9995, 0.9989, 0.9994],
       device='cuda:0') torch.Size([16])
Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 3, 3, 3]) tensor(192.3234, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(825.2978, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(832.3706, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([128, 64, 3, 3]) tensor(1526.7697, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([128, 64, 1, 1]) tensor(479.2333, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([128, 128, 3, 3]) tensor(2318.6475, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([256, 128, 3, 3]) tensor(4266.3330, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([256, 128, 1, 1]) tensor(1353.6802, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([256, 256, 3, 3]) tensor(6253.3818, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([512, 256, 3, 3]) tensor(11591.6807, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([512, 256, 1, 1]) tensor(3820.5881, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([512, 512, 3, 3]) tensor(16122.1719, device='cuda:0', grad_fn=<NormBackward0>)
Epoch: 181 | Batch_idx: 0 |  Loss: (0.0769) |  Loss2: (0.0000) | Acc: (98.00%) (126/128)
Epoch: 181 | Batch_idx: 10 |  Loss: (0.0916) |  Loss2: (0.0000) | Acc: (96.00%) (1365/1408)
Epoch: 181 | Batch_idx: 20 |  Loss: (0.0916) |  Loss2: (0.0000) | Acc: (96.00%) (2601/2688)
Epoch: 181 | Batch_idx: 30 |  Loss: (0.0942) |  Loss2: (0.0000) | Acc: (96.00%) (3837/3968)
Epoch: 181 | Batch_idx: 40 |  Loss: (0.0910) |  Loss2: (0.0000) | Acc: (96.00%) (5087/5248)
Epoch: 181 | Batch_idx: 50 |  Loss: (0.0907) |  Loss2: (0.0000) | Acc: (96.00%) (6330/6528)
Epoch: 181 | Batch_idx: 60 |  Loss: (0.0909) |  Loss2: (0.0000) | Acc: (96.00%) (7566/7808)
Epoch: 181 | Batch_idx: 70 |  Loss: (0.0913) |  Loss2: (0.0000) | Acc: (96.00%) (8802/9088)
Epoch: 181 | Batch_idx: 80 |  Loss: (0.0923) |  Loss2: (0.0000) | Acc: (96.00%) (10045/10368)
Epoch: 181 | Batch_idx: 90 |  Loss: (0.0916) |  Loss2: (0.0000) | Acc: (96.00%) (11286/11648)
Epoch: 181 | Batch_idx: 100 |  Loss: (0.0924) |  Loss2: (0.0000) | Acc: (96.00%) (12520/12928)
Epoch: 181 | Batch_idx: 110 |  Loss: (0.0903) |  Loss2: (0.0000) | Acc: (96.00%) (13777/14208)
Epoch: 181 | Batch_idx: 120 |  Loss: (0.0898) |  Loss2: (0.0000) | Acc: (96.00%) (15015/15488)
Epoch: 181 | Batch_idx: 130 |  Loss: (0.0903) |  Loss2: (0.0000) | Acc: (96.00%) (16247/16768)
Epoch: 181 | Batch_idx: 140 |  Loss: (0.0911) |  Loss2: (0.0000) | Acc: (96.00%) (17476/18048)
Epoch: 181 | Batch_idx: 150 |  Loss: (0.0911) |  Loss2: (0.0000) | Acc: (96.00%) (18717/19328)
Epoch: 181 | Batch_idx: 160 |  Loss: (0.0906) |  Loss2: (0.0000) | Acc: (96.00%) (19961/20608)
Epoch: 181 | Batch_idx: 170 |  Loss: (0.0907) |  Loss2: (0.0000) | Acc: (96.00%) (21204/21888)
Epoch: 181 | Batch_idx: 180 |  Loss: (0.0903) |  Loss2: (0.0000) | Acc: (96.00%) (22452/23168)
Epoch: 181 | Batch_idx: 190 |  Loss: (0.0901) |  Loss2: (0.0000) | Acc: (96.00%) (23695/24448)
Epoch: 181 | Batch_idx: 200 |  Loss: (0.0904) |  Loss2: (0.0000) | Acc: (96.00%) (24937/25728)
Epoch: 181 | Batch_idx: 210 |  Loss: (0.0911) |  Loss2: (0.0000) | Acc: (96.00%) (26166/27008)
Epoch: 181 | Batch_idx: 220 |  Loss: (0.0910) |  Loss2: (0.0000) | Acc: (96.00%) (27404/28288)
Epoch: 181 | Batch_idx: 230 |  Loss: (0.0921) |  Loss2: (0.0000) | Acc: (96.00%) (28632/29568)
Epoch: 181 | Batch_idx: 240 |  Loss: (0.0919) |  Loss2: (0.0000) | Acc: (96.00%) (29881/30848)
Epoch: 181 | Batch_idx: 250 |  Loss: (0.0918) |  Loss2: (0.0000) | Acc: (96.00%) (31120/32128)
Epoch: 181 | Batch_idx: 260 |  Loss: (0.0925) |  Loss2: (0.0000) | Acc: (96.00%) (32345/33408)
Epoch: 181 | Batch_idx: 270 |  Loss: (0.0929) |  Loss2: (0.0000) | Acc: (96.00%) (33581/34688)
Epoch: 181 | Batch_idx: 280 |  Loss: (0.0932) |  Loss2: (0.0000) | Acc: (96.00%) (34818/35968)
Epoch: 181 | Batch_idx: 290 |  Loss: (0.0930) |  Loss2: (0.0000) | Acc: (96.00%) (36063/37248)
Epoch: 181 | Batch_idx: 300 |  Loss: (0.0932) |  Loss2: (0.0000) | Acc: (96.00%) (37298/38528)
Epoch: 181 | Batch_idx: 310 |  Loss: (0.0931) |  Loss2: (0.0000) | Acc: (96.00%) (38544/39808)
Epoch: 181 | Batch_idx: 320 |  Loss: (0.0932) |  Loss2: (0.0000) | Acc: (96.00%) (39784/41088)
Epoch: 181 | Batch_idx: 330 |  Loss: (0.0938) |  Loss2: (0.0000) | Acc: (96.00%) (41014/42368)
Epoch: 181 | Batch_idx: 340 |  Loss: (0.0939) |  Loss2: (0.0000) | Acc: (96.00%) (42259/43648)
Epoch: 181 | Batch_idx: 350 |  Loss: (0.0938) |  Loss2: (0.0000) | Acc: (96.00%) (43499/44928)
Epoch: 181 | Batch_idx: 360 |  Loss: (0.0938) |  Loss2: (0.0000) | Acc: (96.00%) (44733/46208)
Epoch: 181 | Batch_idx: 370 |  Loss: (0.0942) |  Loss2: (0.0000) | Acc: (96.00%) (45957/47488)
Epoch: 181 | Batch_idx: 380 |  Loss: (0.0944) |  Loss2: (0.0000) | Acc: (96.00%) (47189/48768)
Epoch: 181 | Batch_idx: 390 |  Loss: (0.0944) |  Loss2: (0.0000) | Acc: (96.00%) (48378/50000)
# TEST : Loss: (0.4986) | Acc: (86.00%) (8651/10000)
percent tensor([0.5008, 0.4988, 0.5125, 0.5000, 0.5115, 0.5019, 0.5031, 0.5021, 0.5018,
        0.5032, 0.5023, 0.5096, 0.4994, 0.4960, 0.5003, 0.4987],
       device='cuda:0') torch.Size([16])
percent tensor([0.5075, 0.4845, 0.5084, 0.5162, 0.4999, 0.5176, 0.4890, 0.4986, 0.5122,
        0.4909, 0.5076, 0.5000, 0.4912, 0.5081, 0.4941, 0.5045],
       device='cuda:0') torch.Size([16])
percent tensor([0.6377, 0.6306, 0.5692, 0.5445, 0.5722, 0.5983, 0.6466, 0.5838, 0.5762,
        0.6013, 0.6054, 0.5681, 0.6607, 0.5695, 0.6446, 0.6285],
       device='cuda:0') torch.Size([16])
percent tensor([0.5920, 0.6328, 0.6055, 0.6621, 0.6162, 0.6882, 0.6282, 0.5726, 0.6611,
        0.6239, 0.6564, 0.6732, 0.6196, 0.6833, 0.6580, 0.6179],
       device='cuda:0') torch.Size([16])
percent tensor([0.5773, 0.5981, 0.5944, 0.5856, 0.6368, 0.5945, 0.6019, 0.5462, 0.6430,
        0.6270, 0.6456, 0.5257, 0.5686, 0.7252, 0.4744, 0.6328],
       device='cuda:0') torch.Size([16])
percent tensor([0.6293, 0.5877, 0.7366, 0.7344, 0.7754, 0.7472, 0.6722, 0.7113, 0.6565,
        0.6369, 0.6263, 0.6955, 0.6227, 0.6415, 0.6643, 0.6710],
       device='cuda:0') torch.Size([16])
percent tensor([0.5864, 0.6910, 0.7047, 0.6373, 0.6722, 0.5837, 0.5444, 0.5530, 0.7015,
        0.6403, 0.7343, 0.6348, 0.6903, 0.6072, 0.5520, 0.4718],
       device='cuda:0') torch.Size([16])
percent tensor([0.9996, 0.9998, 0.9998, 0.9997, 0.9998, 0.9994, 0.9997, 0.9992, 0.9997,
        0.9998, 1.0000, 0.9997, 0.9998, 0.9996, 0.9991, 0.9995],
       device='cuda:0') torch.Size([16])
Epoch: 182 | Batch_idx: 0 |  Loss: (0.0211) |  Loss2: (0.0000) | Acc: (100.00%) (128/128)
Epoch: 182 | Batch_idx: 10 |  Loss: (0.0774) |  Loss2: (0.0000) | Acc: (97.00%) (1379/1408)
Epoch: 182 | Batch_idx: 20 |  Loss: (0.0695) |  Loss2: (0.0000) | Acc: (98.00%) (2641/2688)
Epoch: 182 | Batch_idx: 30 |  Loss: (0.0731) |  Loss2: (0.0000) | Acc: (97.00%) (3884/3968)
Epoch: 182 | Batch_idx: 40 |  Loss: (0.0800) |  Loss2: (0.0000) | Acc: (97.00%) (5125/5248)
Epoch: 182 | Batch_idx: 50 |  Loss: (0.0804) |  Loss2: (0.0000) | Acc: (97.00%) (6374/6528)
Epoch: 182 | Batch_idx: 60 |  Loss: (0.0838) |  Loss2: (0.0000) | Acc: (97.00%) (7606/7808)
Epoch: 182 | Batch_idx: 70 |  Loss: (0.0839) |  Loss2: (0.0000) | Acc: (97.00%) (8851/9088)
Epoch: 182 | Batch_idx: 80 |  Loss: (0.0845) |  Loss2: (0.0000) | Acc: (97.00%) (10089/10368)
Epoch: 182 | Batch_idx: 90 |  Loss: (0.0858) |  Loss2: (0.0000) | Acc: (97.00%) (11328/11648)
Epoch: 182 | Batch_idx: 100 |  Loss: (0.0866) |  Loss2: (0.0000) | Acc: (97.00%) (12566/12928)
Epoch: 182 | Batch_idx: 110 |  Loss: (0.0860) |  Loss2: (0.0000) | Acc: (97.00%) (13812/14208)
Epoch: 182 | Batch_idx: 120 |  Loss: (0.0869) |  Loss2: (0.0000) | Acc: (97.00%) (15046/15488)
Epoch: 182 | Batch_idx: 130 |  Loss: (0.0869) |  Loss2: (0.0000) | Acc: (97.00%) (16284/16768)
Epoch: 182 | Batch_idx: 140 |  Loss: (0.0870) |  Loss2: (0.0000) | Acc: (97.00%) (17524/18048)
Epoch: 182 | Batch_idx: 150 |  Loss: (0.0866) |  Loss2: (0.0000) | Acc: (97.00%) (18775/19328)
Epoch: 182 | Batch_idx: 160 |  Loss: (0.0860) |  Loss2: (0.0000) | Acc: (97.00%) (20017/20608)
Epoch: 182 | Batch_idx: 170 |  Loss: (0.0860) |  Loss2: (0.0000) | Acc: (97.00%) (21256/21888)
Epoch: 182 | Batch_idx: 180 |  Loss: (0.0852) |  Loss2: (0.0000) | Acc: (97.00%) (22504/23168)
Epoch: 182 | Batch_idx: 190 |  Loss: (0.0859) |  Loss2: (0.0000) | Acc: (97.00%) (23744/24448)
Epoch: 182 | Batch_idx: 200 |  Loss: (0.0857) |  Loss2: (0.0000) | Acc: (97.00%) (24985/25728)
Epoch: 182 | Batch_idx: 210 |  Loss: (0.0872) |  Loss2: (0.0000) | Acc: (97.00%) (26214/27008)
Epoch: 182 | Batch_idx: 220 |  Loss: (0.0860) |  Loss2: (0.0000) | Acc: (97.00%) (27468/28288)
Epoch: 182 | Batch_idx: 230 |  Loss: (0.0853) |  Loss2: (0.0000) | Acc: (97.00%) (28718/29568)
Epoch: 182 | Batch_idx: 240 |  Loss: (0.0850) |  Loss2: (0.0000) | Acc: (97.00%) (29962/30848)
Epoch: 182 | Batch_idx: 250 |  Loss: (0.0855) |  Loss2: (0.0000) | Acc: (97.00%) (31204/32128)
Epoch: 182 | Batch_idx: 260 |  Loss: (0.0861) |  Loss2: (0.0000) | Acc: (97.00%) (32439/33408)
Epoch: 182 | Batch_idx: 270 |  Loss: (0.0860) |  Loss2: (0.0000) | Acc: (97.00%) (33683/34688)
Epoch: 182 | Batch_idx: 280 |  Loss: (0.0870) |  Loss2: (0.0000) | Acc: (97.00%) (34916/35968)
Epoch: 182 | Batch_idx: 290 |  Loss: (0.0871) |  Loss2: (0.0000) | Acc: (97.00%) (36156/37248)
Epoch: 182 | Batch_idx: 300 |  Loss: (0.0868) |  Loss2: (0.0000) | Acc: (97.00%) (37402/38528)
Epoch: 182 | Batch_idx: 310 |  Loss: (0.0871) |  Loss2: (0.0000) | Acc: (97.00%) (38639/39808)
Epoch: 182 | Batch_idx: 320 |  Loss: (0.0873) |  Loss2: (0.0000) | Acc: (97.00%) (39873/41088)
Epoch: 182 | Batch_idx: 330 |  Loss: (0.0875) |  Loss2: (0.0000) | Acc: (97.00%) (41114/42368)
Epoch: 182 | Batch_idx: 340 |  Loss: (0.0875) |  Loss2: (0.0000) | Acc: (97.00%) (42358/43648)
Epoch: 182 | Batch_idx: 350 |  Loss: (0.0877) |  Loss2: (0.0000) | Acc: (97.00%) (43592/44928)
Epoch: 182 | Batch_idx: 360 |  Loss: (0.0879) |  Loss2: (0.0000) | Acc: (97.00%) (44831/46208)
Epoch: 182 | Batch_idx: 370 |  Loss: (0.0877) |  Loss2: (0.0000) | Acc: (97.00%) (46079/47488)
Epoch: 182 | Batch_idx: 380 |  Loss: (0.0882) |  Loss2: (0.0000) | Acc: (97.00%) (47323/48768)
Epoch: 182 | Batch_idx: 390 |  Loss: (0.0886) |  Loss2: (0.0000) | Acc: (97.00%) (48512/50000)
# TEST : Loss: (0.4568) | Acc: (87.00%) (8796/10000)
percent tensor([0.4999, 0.4997, 0.5119, 0.4993, 0.5106, 0.5007, 0.5034, 0.5024, 0.5017,
        0.5031, 0.5020, 0.5089, 0.4988, 0.4966, 0.5001, 0.4983],
       device='cuda:0') torch.Size([16])
percent tensor([0.5084, 0.4843, 0.5041, 0.5111, 0.4988, 0.5191, 0.4874, 0.4938, 0.5131,
        0.4903, 0.5089, 0.4971, 0.4919, 0.5072, 0.4950, 0.5050],
       device='cuda:0') torch.Size([16])
percent tensor([0.6383, 0.6363, 0.5762, 0.5510, 0.5752, 0.5918, 0.6516, 0.5925, 0.5733,
        0.6083, 0.5999, 0.5802, 0.6613, 0.5696, 0.6434, 0.6263],
       device='cuda:0') torch.Size([16])
percent tensor([0.6008, 0.6302, 0.6012, 0.6560, 0.6217, 0.6852, 0.6289, 0.5721, 0.6598,
        0.6258, 0.6566, 0.6673, 0.6182, 0.6846, 0.6591, 0.6207],
       device='cuda:0') torch.Size([16])
percent tensor([0.6041, 0.6280, 0.5992, 0.5806, 0.6310, 0.6092, 0.6211, 0.5573, 0.6695,
        0.6442, 0.6686, 0.5325, 0.6005, 0.7464, 0.4900, 0.6452],
       device='cuda:0') torch.Size([16])
percent tensor([0.6344, 0.6089, 0.7313, 0.7322, 0.7686, 0.7446, 0.6716, 0.7188, 0.6705,
        0.6496, 0.6412, 0.6996, 0.6239, 0.6462, 0.6689, 0.6791],
       device='cuda:0') torch.Size([16])
percent tensor([0.5747, 0.7217, 0.6894, 0.6618, 0.6624, 0.5851, 0.5472, 0.5613, 0.7082,
        0.6481, 0.7459, 0.6701, 0.6723, 0.6152, 0.5724, 0.4792],
       device='cuda:0') torch.Size([16])
percent tensor([0.9997, 0.9999, 0.9999, 0.9998, 0.9998, 0.9996, 0.9997, 0.9989, 0.9998,
        0.9999, 1.0000, 0.9999, 0.9999, 0.9998, 0.9988, 0.9994],
       device='cuda:0') torch.Size([16])
Epoch: 183 | Batch_idx: 0 |  Loss: (0.1326) |  Loss2: (0.0000) | Acc: (93.00%) (120/128)
Epoch: 183 | Batch_idx: 10 |  Loss: (0.0886) |  Loss2: (0.0000) | Acc: (96.00%) (1363/1408)
Epoch: 183 | Batch_idx: 20 |  Loss: (0.0910) |  Loss2: (0.0000) | Acc: (96.00%) (2601/2688)
Epoch: 183 | Batch_idx: 30 |  Loss: (0.0914) |  Loss2: (0.0000) | Acc: (96.00%) (3833/3968)
Epoch: 183 | Batch_idx: 40 |  Loss: (0.0863) |  Loss2: (0.0000) | Acc: (96.00%) (5085/5248)
Epoch: 183 | Batch_idx: 50 |  Loss: (0.0863) |  Loss2: (0.0000) | Acc: (96.00%) (6327/6528)
Epoch: 183 | Batch_idx: 60 |  Loss: (0.0847) |  Loss2: (0.0000) | Acc: (97.00%) (7575/7808)
Epoch: 183 | Batch_idx: 70 |  Loss: (0.0841) |  Loss2: (0.0000) | Acc: (97.00%) (8817/9088)
Epoch: 183 | Batch_idx: 80 |  Loss: (0.0839) |  Loss2: (0.0000) | Acc: (97.00%) (10063/10368)
Epoch: 183 | Batch_idx: 90 |  Loss: (0.0844) |  Loss2: (0.0000) | Acc: (97.00%) (11310/11648)
Epoch: 183 | Batch_idx: 100 |  Loss: (0.0834) |  Loss2: (0.0000) | Acc: (97.00%) (12562/12928)
Epoch: 183 | Batch_idx: 110 |  Loss: (0.0847) |  Loss2: (0.0000) | Acc: (97.00%) (13797/14208)
Epoch: 183 | Batch_idx: 120 |  Loss: (0.0845) |  Loss2: (0.0000) | Acc: (97.00%) (15037/15488)
Epoch: 183 | Batch_idx: 130 |  Loss: (0.0861) |  Loss2: (0.0000) | Acc: (97.00%) (16273/16768)
Epoch: 183 | Batch_idx: 140 |  Loss: (0.0870) |  Loss2: (0.0000) | Acc: (97.00%) (17507/18048)
Epoch: 183 | Batch_idx: 150 |  Loss: (0.0868) |  Loss2: (0.0000) | Acc: (97.00%) (18758/19328)
Epoch: 183 | Batch_idx: 160 |  Loss: (0.0861) |  Loss2: (0.0000) | Acc: (97.00%) (20005/20608)
Epoch: 183 | Batch_idx: 170 |  Loss: (0.0862) |  Loss2: (0.0000) | Acc: (97.00%) (21242/21888)
Epoch: 183 | Batch_idx: 180 |  Loss: (0.0865) |  Loss2: (0.0000) | Acc: (97.00%) (22477/23168)
Epoch: 183 | Batch_idx: 190 |  Loss: (0.0866) |  Loss2: (0.0000) | Acc: (97.00%) (23718/24448)
Epoch: 183 | Batch_idx: 200 |  Loss: (0.0868) |  Loss2: (0.0000) | Acc: (97.00%) (24957/25728)
Epoch: 183 | Batch_idx: 210 |  Loss: (0.0869) |  Loss2: (0.0000) | Acc: (96.00%) (26197/27008)
Epoch: 183 | Batch_idx: 220 |  Loss: (0.0868) |  Loss2: (0.0000) | Acc: (97.00%) (27443/28288)
Epoch: 183 | Batch_idx: 230 |  Loss: (0.0870) |  Loss2: (0.0000) | Acc: (97.00%) (28681/29568)
Epoch: 183 | Batch_idx: 240 |  Loss: (0.0865) |  Loss2: (0.0000) | Acc: (97.00%) (29932/30848)
Epoch: 183 | Batch_idx: 250 |  Loss: (0.0866) |  Loss2: (0.0000) | Acc: (97.00%) (31177/32128)
Epoch: 183 | Batch_idx: 260 |  Loss: (0.0868) |  Loss2: (0.0000) | Acc: (97.00%) (32416/33408)
Epoch: 183 | Batch_idx: 270 |  Loss: (0.0862) |  Loss2: (0.0000) | Acc: (97.00%) (33667/34688)
Epoch: 183 | Batch_idx: 280 |  Loss: (0.0867) |  Loss2: (0.0000) | Acc: (97.00%) (34904/35968)
Epoch: 183 | Batch_idx: 290 |  Loss: (0.0873) |  Loss2: (0.0000) | Acc: (97.00%) (36139/37248)
Epoch: 183 | Batch_idx: 300 |  Loss: (0.0872) |  Loss2: (0.0000) | Acc: (97.00%) (37383/38528)
Epoch: 183 | Batch_idx: 310 |  Loss: (0.0873) |  Loss2: (0.0000) | Acc: (97.00%) (38626/39808)
Epoch: 183 | Batch_idx: 320 |  Loss: (0.0869) |  Loss2: (0.0000) | Acc: (97.00%) (39873/41088)
Epoch: 183 | Batch_idx: 330 |  Loss: (0.0871) |  Loss2: (0.0000) | Acc: (97.00%) (41115/42368)
Epoch: 183 | Batch_idx: 340 |  Loss: (0.0870) |  Loss2: (0.0000) | Acc: (97.00%) (42360/43648)
Epoch: 183 | Batch_idx: 350 |  Loss: (0.0872) |  Loss2: (0.0000) | Acc: (97.00%) (43604/44928)
Epoch: 183 | Batch_idx: 360 |  Loss: (0.0867) |  Loss2: (0.0000) | Acc: (97.00%) (44852/46208)
Epoch: 183 | Batch_idx: 370 |  Loss: (0.0870) |  Loss2: (0.0000) | Acc: (97.00%) (46095/47488)
Epoch: 183 | Batch_idx: 380 |  Loss: (0.0872) |  Loss2: (0.0000) | Acc: (97.00%) (47331/48768)
Epoch: 183 | Batch_idx: 390 |  Loss: (0.0881) |  Loss2: (0.0000) | Acc: (97.00%) (48517/50000)
# TEST : Loss: (0.4221) | Acc: (88.00%) (8838/10000)
percent tensor([0.5008, 0.4992, 0.5114, 0.4993, 0.5103, 0.5015, 0.5031, 0.5019, 0.5019,
        0.5032, 0.5025, 0.5089, 0.4995, 0.4960, 0.5003, 0.4985],
       device='cuda:0') torch.Size([16])
percent tensor([0.5075, 0.4826, 0.5093, 0.5155, 0.5014, 0.5188, 0.4873, 0.4973, 0.5109,
        0.4899, 0.5062, 0.4996, 0.4907, 0.5058, 0.4944, 0.5042],
       device='cuda:0') torch.Size([16])
percent tensor([0.6453, 0.6362, 0.5709, 0.5475, 0.5751, 0.6061, 0.6521, 0.5875, 0.5860,
        0.6035, 0.6159, 0.5750, 0.6696, 0.5719, 0.6496, 0.6343],
       device='cuda:0') torch.Size([16])
percent tensor([0.6015, 0.6358, 0.6023, 0.6682, 0.6188, 0.6892, 0.6282, 0.5735, 0.6618,
        0.6297, 0.6579, 0.6681, 0.6205, 0.6841, 0.6661, 0.6264],
       device='cuda:0') torch.Size([16])
percent tensor([0.6034, 0.6249, 0.6040, 0.5919, 0.6408, 0.5968, 0.6275, 0.5583, 0.6671,
        0.6557, 0.6616, 0.5231, 0.5988, 0.7470, 0.4912, 0.6491],
       device='cuda:0') torch.Size([16])
percent tensor([0.6476, 0.6221, 0.7283, 0.7354, 0.7798, 0.7537, 0.6843, 0.7140, 0.6797,
        0.6623, 0.6484, 0.6955, 0.6392, 0.6655, 0.6850, 0.6931],
       device='cuda:0') torch.Size([16])
percent tensor([0.5929, 0.7188, 0.7079, 0.6734, 0.6944, 0.5759, 0.5683, 0.5684, 0.7247,
        0.6416, 0.7495, 0.6595, 0.7035, 0.6274, 0.5642, 0.4882],
       device='cuda:0') torch.Size([16])
percent tensor([0.9997, 0.9998, 0.9999, 0.9999, 0.9998, 0.9997, 0.9997, 0.9994, 0.9998,
        0.9998, 1.0000, 0.9998, 0.9999, 0.9997, 0.9991, 0.9993],
       device='cuda:0') torch.Size([16])
False Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=128, out_features=16, bias=False)
True Linear(in_features=16, out_features=2, bias=False)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=128, out_features=16, bias=False)
True Linear(in_features=16, out_features=2, bias=False)
False Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=256, out_features=32, bias=False)
True Linear(in_features=32, out_features=2, bias=False)
False Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=256, out_features=32, bias=False)
True Linear(in_features=32, out_features=2, bias=False)
False Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=512, out_features=64, bias=False)
True Linear(in_features=64, out_features=2, bias=False)
False Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=512, out_features=64, bias=False)
True Linear(in_features=64, out_features=2, bias=False)
False Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1024, out_features=128, bias=False)
True Linear(in_features=128, out_features=2, bias=False)
False Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1024, out_features=128, bias=False)
True Linear(in_features=128, out_features=2, bias=False)
False Linear(in_features=512, out_features=10, bias=True)
Epoch: 184 | Batch_idx: 0 |  Loss: (0.1075) |  Loss2: (0.0000) | Acc: (96.00%) (123/128)
Epoch: 184 | Batch_idx: 10 |  Loss: (0.1104) |  Loss2: (0.0000) | Acc: (95.00%) (1346/1408)
Epoch: 184 | Batch_idx: 20 |  Loss: (0.1253) |  Loss2: (0.0000) | Acc: (95.00%) (2555/2688)
Epoch: 184 | Batch_idx: 30 |  Loss: (0.1318) |  Loss2: (0.0000) | Acc: (94.00%) (3766/3968)
Epoch: 184 | Batch_idx: 40 |  Loss: (0.1383) |  Loss2: (0.0000) | Acc: (94.00%) (4967/5248)
Epoch: 184 | Batch_idx: 50 |  Loss: (0.1439) |  Loss2: (0.0000) | Acc: (94.00%) (6174/6528)
Epoch: 184 | Batch_idx: 60 |  Loss: (0.1469) |  Loss2: (0.0000) | Acc: (94.00%) (7388/7808)
Epoch: 184 | Batch_idx: 70 |  Loss: (0.1478) |  Loss2: (0.0000) | Acc: (94.00%) (8598/9088)
Epoch: 184 | Batch_idx: 80 |  Loss: (0.1494) |  Loss2: (0.0000) | Acc: (94.00%) (9798/10368)
Epoch: 184 | Batch_idx: 90 |  Loss: (0.1481) |  Loss2: (0.0000) | Acc: (94.00%) (11011/11648)
Epoch: 184 | Batch_idx: 100 |  Loss: (0.1468) |  Loss2: (0.0000) | Acc: (94.00%) (12229/12928)
Epoch: 184 | Batch_idx: 110 |  Loss: (0.1475) |  Loss2: (0.0000) | Acc: (94.00%) (13435/14208)
Epoch: 184 | Batch_idx: 120 |  Loss: (0.1449) |  Loss2: (0.0000) | Acc: (94.00%) (14671/15488)
Epoch: 184 | Batch_idx: 130 |  Loss: (0.1440) |  Loss2: (0.0000) | Acc: (94.00%) (15895/16768)
Epoch: 184 | Batch_idx: 140 |  Loss: (0.1442) |  Loss2: (0.0000) | Acc: (94.00%) (17113/18048)
Epoch: 184 | Batch_idx: 150 |  Loss: (0.1431) |  Loss2: (0.0000) | Acc: (94.00%) (18333/19328)
Epoch: 184 | Batch_idx: 160 |  Loss: (0.1417) |  Loss2: (0.0000) | Acc: (94.00%) (19560/20608)
Epoch: 184 | Batch_idx: 170 |  Loss: (0.1411) |  Loss2: (0.0000) | Acc: (94.00%) (20770/21888)
Epoch: 184 | Batch_idx: 180 |  Loss: (0.1408) |  Loss2: (0.0000) | Acc: (94.00%) (21996/23168)
Epoch: 184 | Batch_idx: 190 |  Loss: (0.1398) |  Loss2: (0.0000) | Acc: (94.00%) (23225/24448)
Epoch: 184 | Batch_idx: 200 |  Loss: (0.1400) |  Loss2: (0.0000) | Acc: (94.00%) (24436/25728)
Epoch: 184 | Batch_idx: 210 |  Loss: (0.1401) |  Loss2: (0.0000) | Acc: (94.00%) (25647/27008)
Epoch: 184 | Batch_idx: 220 |  Loss: (0.1389) |  Loss2: (0.0000) | Acc: (94.00%) (26871/28288)
Epoch: 184 | Batch_idx: 230 |  Loss: (0.1385) |  Loss2: (0.0000) | Acc: (95.00%) (28093/29568)
Epoch: 184 | Batch_idx: 240 |  Loss: (0.1383) |  Loss2: (0.0000) | Acc: (95.00%) (29312/30848)
Epoch: 184 | Batch_idx: 250 |  Loss: (0.1380) |  Loss2: (0.0000) | Acc: (95.00%) (30530/32128)
Epoch: 184 | Batch_idx: 260 |  Loss: (0.1375) |  Loss2: (0.0000) | Acc: (95.00%) (31758/33408)
Epoch: 184 | Batch_idx: 270 |  Loss: (0.1361) |  Loss2: (0.0000) | Acc: (95.00%) (32995/34688)
Epoch: 184 | Batch_idx: 280 |  Loss: (0.1358) |  Loss2: (0.0000) | Acc: (95.00%) (34215/35968)
Epoch: 184 | Batch_idx: 290 |  Loss: (0.1348) |  Loss2: (0.0000) | Acc: (95.00%) (35448/37248)
Epoch: 184 | Batch_idx: 300 |  Loss: (0.1339) |  Loss2: (0.0000) | Acc: (95.00%) (36681/38528)
Epoch: 184 | Batch_idx: 310 |  Loss: (0.1329) |  Loss2: (0.0000) | Acc: (95.00%) (37911/39808)
Epoch: 184 | Batch_idx: 320 |  Loss: (0.1324) |  Loss2: (0.0000) | Acc: (95.00%) (39138/41088)
Epoch: 184 | Batch_idx: 330 |  Loss: (0.1318) |  Loss2: (0.0000) | Acc: (95.00%) (40368/42368)
Epoch: 184 | Batch_idx: 340 |  Loss: (0.1314) |  Loss2: (0.0000) | Acc: (95.00%) (41595/43648)
Epoch: 184 | Batch_idx: 350 |  Loss: (0.1312) |  Loss2: (0.0000) | Acc: (95.00%) (42820/44928)
Epoch: 184 | Batch_idx: 360 |  Loss: (0.1302) |  Loss2: (0.0000) | Acc: (95.00%) (44058/46208)
Epoch: 184 | Batch_idx: 370 |  Loss: (0.1294) |  Loss2: (0.0000) | Acc: (95.00%) (45297/47488)
Epoch: 184 | Batch_idx: 380 |  Loss: (0.1288) |  Loss2: (0.0000) | Acc: (95.00%) (46525/48768)
Epoch: 184 | Batch_idx: 390 |  Loss: (0.1281) |  Loss2: (0.0000) | Acc: (95.00%) (47717/50000)
# TEST : Loss: (0.4366) | Acc: (87.00%) (8768/10000)
percent tensor([0.5145, 0.5156, 0.5262, 0.5136, 0.5261, 0.5147, 0.5191, 0.5178, 0.5171,
        0.5188, 0.5180, 0.5243, 0.5144, 0.5090, 0.5159, 0.5125],
       device='cuda:0') torch.Size([16])
percent tensor([0.4947, 0.4680, 0.4910, 0.5033, 0.4852, 0.5150, 0.4705, 0.4811, 0.4969,
        0.4735, 0.4920, 0.4791, 0.4763, 0.4930, 0.4823, 0.4937],
       device='cuda:0') torch.Size([16])
percent tensor([0.6489, 0.6362, 0.5925, 0.5661, 0.6008, 0.6093, 0.6606, 0.6022, 0.5933,
        0.6170, 0.6194, 0.6071, 0.6714, 0.5750, 0.6539, 0.6331],
       device='cuda:0') torch.Size([16])
percent tensor([0.6095, 0.6467, 0.6132, 0.6785, 0.6396, 0.7008, 0.6397, 0.5923, 0.6697,
        0.6368, 0.6636, 0.6723, 0.6227, 0.6917, 0.6797, 0.6376],
       device='cuda:0') torch.Size([16])
percent tensor([0.6001, 0.6108, 0.5970, 0.5959, 0.6406, 0.6129, 0.6202, 0.5580, 0.6681,
        0.6455, 0.6534, 0.5036, 0.5747, 0.7382, 0.4877, 0.6533],
       device='cuda:0') torch.Size([16])
percent tensor([0.6658, 0.6437, 0.7554, 0.7534, 0.8042, 0.7683, 0.7090, 0.7374, 0.7054,
        0.6869, 0.6702, 0.7187, 0.6509, 0.6903, 0.7053, 0.7071],
       device='cuda:0') torch.Size([16])
percent tensor([0.4867, 0.6479, 0.6704, 0.6290, 0.6634, 0.5214, 0.4942, 0.5122, 0.6559,
        0.5335, 0.6824, 0.5998, 0.6276, 0.5400, 0.4881, 0.4302],
       device='cuda:0') torch.Size([16])
percent tensor([0.9997, 0.9998, 0.9998, 0.9999, 0.9998, 0.9998, 0.9997, 0.9995, 0.9998,
        0.9998, 1.0000, 0.9998, 0.9999, 0.9997, 0.9991, 0.9993],
       device='cuda:0') torch.Size([16])
Epoch: 185 | Batch_idx: 0 |  Loss: (0.1223) |  Loss2: (0.0000) | Acc: (93.00%) (120/128)
Epoch: 185 | Batch_idx: 10 |  Loss: (0.1099) |  Loss2: (0.0000) | Acc: (96.00%) (1355/1408)
Epoch: 185 | Batch_idx: 20 |  Loss: (0.1148) |  Loss2: (0.0000) | Acc: (95.00%) (2577/2688)
Epoch: 185 | Batch_idx: 30 |  Loss: (0.1164) |  Loss2: (0.0000) | Acc: (95.00%) (3807/3968)
Epoch: 185 | Batch_idx: 40 |  Loss: (0.1178) |  Loss2: (0.0000) | Acc: (95.00%) (5034/5248)
Epoch: 185 | Batch_idx: 50 |  Loss: (0.1182) |  Loss2: (0.0000) | Acc: (95.00%) (6261/6528)
Epoch: 185 | Batch_idx: 60 |  Loss: (0.1158) |  Loss2: (0.0000) | Acc: (96.00%) (7498/7808)
Epoch: 185 | Batch_idx: 70 |  Loss: (0.1137) |  Loss2: (0.0000) | Acc: (96.00%) (8733/9088)
Epoch: 185 | Batch_idx: 80 |  Loss: (0.1150) |  Loss2: (0.0000) | Acc: (95.00%) (9951/10368)
Epoch: 185 | Batch_idx: 90 |  Loss: (0.1149) |  Loss2: (0.0000) | Acc: (95.00%) (11177/11648)
Epoch: 185 | Batch_idx: 100 |  Loss: (0.1120) |  Loss2: (0.0000) | Acc: (96.00%) (12422/12928)
Epoch: 185 | Batch_idx: 110 |  Loss: (0.1113) |  Loss2: (0.0000) | Acc: (96.00%) (13655/14208)
Epoch: 185 | Batch_idx: 120 |  Loss: (0.1111) |  Loss2: (0.0000) | Acc: (96.00%) (14887/15488)
Epoch: 185 | Batch_idx: 130 |  Loss: (0.1103) |  Loss2: (0.0000) | Acc: (96.00%) (16130/16768)
Epoch: 185 | Batch_idx: 140 |  Loss: (0.1090) |  Loss2: (0.0000) | Acc: (96.00%) (17374/18048)
Epoch: 185 | Batch_idx: 150 |  Loss: (0.1082) |  Loss2: (0.0000) | Acc: (96.00%) (18613/19328)
Epoch: 185 | Batch_idx: 160 |  Loss: (0.1082) |  Loss2: (0.0000) | Acc: (96.00%) (19842/20608)
Epoch: 185 | Batch_idx: 170 |  Loss: (0.1069) |  Loss2: (0.0000) | Acc: (96.00%) (21086/21888)
Epoch: 185 | Batch_idx: 180 |  Loss: (0.1065) |  Loss2: (0.0000) | Acc: (96.00%) (22322/23168)
Epoch: 185 | Batch_idx: 190 |  Loss: (0.1056) |  Loss2: (0.0000) | Acc: (96.00%) (23572/24448)
Epoch: 185 | Batch_idx: 200 |  Loss: (0.1051) |  Loss2: (0.0000) | Acc: (96.00%) (24804/25728)
Epoch: 185 | Batch_idx: 210 |  Loss: (0.1062) |  Loss2: (0.0000) | Acc: (96.00%) (26022/27008)
Epoch: 185 | Batch_idx: 220 |  Loss: (0.1062) |  Loss2: (0.0000) | Acc: (96.00%) (27260/28288)
Epoch: 185 | Batch_idx: 230 |  Loss: (0.1060) |  Loss2: (0.0000) | Acc: (96.00%) (28493/29568)
Epoch: 185 | Batch_idx: 240 |  Loss: (0.1062) |  Loss2: (0.0000) | Acc: (96.00%) (29725/30848)
Epoch: 185 | Batch_idx: 250 |  Loss: (0.1061) |  Loss2: (0.0000) | Acc: (96.00%) (30954/32128)
Epoch: 185 | Batch_idx: 260 |  Loss: (0.1062) |  Loss2: (0.0000) | Acc: (96.00%) (32184/33408)
Epoch: 185 | Batch_idx: 270 |  Loss: (0.1058) |  Loss2: (0.0000) | Acc: (96.00%) (33423/34688)
Epoch: 185 | Batch_idx: 280 |  Loss: (0.1050) |  Loss2: (0.0000) | Acc: (96.00%) (34671/35968)
Epoch: 185 | Batch_idx: 290 |  Loss: (0.1047) |  Loss2: (0.0000) | Acc: (96.00%) (35903/37248)
Epoch: 185 | Batch_idx: 300 |  Loss: (0.1044) |  Loss2: (0.0000) | Acc: (96.00%) (37148/38528)
Epoch: 185 | Batch_idx: 310 |  Loss: (0.1049) |  Loss2: (0.0000) | Acc: (96.00%) (38372/39808)
Epoch: 185 | Batch_idx: 320 |  Loss: (0.1049) |  Loss2: (0.0000) | Acc: (96.00%) (39607/41088)
Epoch: 185 | Batch_idx: 330 |  Loss: (0.1048) |  Loss2: (0.0000) | Acc: (96.00%) (40845/42368)
Epoch: 185 | Batch_idx: 340 |  Loss: (0.1043) |  Loss2: (0.0000) | Acc: (96.00%) (42085/43648)
Epoch: 185 | Batch_idx: 350 |  Loss: (0.1044) |  Loss2: (0.0000) | Acc: (96.00%) (43317/44928)
Epoch: 185 | Batch_idx: 360 |  Loss: (0.1040) |  Loss2: (0.0000) | Acc: (96.00%) (44557/46208)
Epoch: 185 | Batch_idx: 370 |  Loss: (0.1037) |  Loss2: (0.0000) | Acc: (96.00%) (45795/47488)
Epoch: 185 | Batch_idx: 380 |  Loss: (0.1034) |  Loss2: (0.0000) | Acc: (96.00%) (47038/48768)
Epoch: 185 | Batch_idx: 390 |  Loss: (0.1034) |  Loss2: (0.0000) | Acc: (96.00%) (48218/50000)
=> saving checkpoint 'drive/app/torch/save_Schedule/checkpoint_185.pth.tar'
# TEST : Loss: (0.4160) | Acc: (88.00%) (8835/10000)
percent tensor([0.5157, 0.5176, 0.5287, 0.5158, 0.5284, 0.5157, 0.5212, 0.5203, 0.5188,
        0.5210, 0.5194, 0.5269, 0.5160, 0.5108, 0.5176, 0.5138],
       device='cuda:0') torch.Size([16])
percent tensor([0.4906, 0.4624, 0.4877, 0.4994, 0.4823, 0.5134, 0.4654, 0.4769, 0.4929,
        0.4688, 0.4871, 0.4750, 0.4717, 0.4874, 0.4782, 0.4898],
       device='cuda:0') torch.Size([16])
percent tensor([0.6380, 0.6281, 0.5862, 0.5616, 0.5935, 0.5994, 0.6518, 0.5976, 0.5865,
        0.6092, 0.6108, 0.6008, 0.6634, 0.5688, 0.6446, 0.6240],
       device='cuda:0') torch.Size([16])
percent tensor([0.6128, 0.6462, 0.6168, 0.6796, 0.6450, 0.7070, 0.6382, 0.5974, 0.6683,
        0.6350, 0.6618, 0.6708, 0.6225, 0.6866, 0.6816, 0.6412],
       device='cuda:0') torch.Size([16])
percent tensor([0.6014, 0.6095, 0.6009, 0.6008, 0.6472, 0.6238, 0.6220, 0.5577, 0.6692,
        0.6440, 0.6496, 0.5111, 0.5707, 0.7362, 0.4853, 0.6557],
       device='cuda:0') torch.Size([16])
percent tensor([0.6639, 0.6404, 0.7592, 0.7583, 0.8083, 0.7664, 0.7092, 0.7429, 0.7033,
        0.6862, 0.6675, 0.7205, 0.6472, 0.6870, 0.7045, 0.7048],
       device='cuda:0') torch.Size([16])
percent tensor([0.4795, 0.6511, 0.6890, 0.6471, 0.6793, 0.5230, 0.4883, 0.5176, 0.6673,
        0.5382, 0.6950, 0.6095, 0.6402, 0.5456, 0.4887, 0.4193],
       device='cuda:0') torch.Size([16])
percent tensor([0.9997, 0.9998, 0.9999, 0.9999, 0.9998, 0.9998, 0.9997, 0.9995, 0.9998,
        0.9998, 1.0000, 0.9998, 0.9999, 0.9996, 0.9991, 0.9994],
       device='cuda:0') torch.Size([16])
Epoch: 186 | Batch_idx: 0 |  Loss: (0.1347) |  Loss2: (0.0000) | Acc: (96.00%) (124/128)
Epoch: 186 | Batch_idx: 10 |  Loss: (0.1058) |  Loss2: (0.0000) | Acc: (96.00%) (1356/1408)
Epoch: 186 | Batch_idx: 20 |  Loss: (0.1068) |  Loss2: (0.0000) | Acc: (96.00%) (2599/2688)
Epoch: 186 | Batch_idx: 30 |  Loss: (0.1050) |  Loss2: (0.0000) | Acc: (96.00%) (3836/3968)
Epoch: 186 | Batch_idx: 40 |  Loss: (0.1033) |  Loss2: (0.0000) | Acc: (96.00%) (5077/5248)
Epoch: 186 | Batch_idx: 50 |  Loss: (0.1011) |  Loss2: (0.0000) | Acc: (96.00%) (6316/6528)
Epoch: 186 | Batch_idx: 60 |  Loss: (0.0987) |  Loss2: (0.0000) | Acc: (96.00%) (7560/7808)
Epoch: 186 | Batch_idx: 70 |  Loss: (0.0988) |  Loss2: (0.0000) | Acc: (96.00%) (8796/9088)
Epoch: 186 | Batch_idx: 80 |  Loss: (0.0975) |  Loss2: (0.0000) | Acc: (96.00%) (10042/10368)
Epoch: 186 | Batch_idx: 90 |  Loss: (0.0972) |  Loss2: (0.0000) | Acc: (96.00%) (11281/11648)
Epoch: 186 | Batch_idx: 100 |  Loss: (0.0974) |  Loss2: (0.0000) | Acc: (96.00%) (12521/12928)
Epoch: 186 | Batch_idx: 110 |  Loss: (0.0968) |  Loss2: (0.0000) | Acc: (96.00%) (13759/14208)
Epoch: 186 | Batch_idx: 120 |  Loss: (0.0961) |  Loss2: (0.0000) | Acc: (96.00%) (15005/15488)
Epoch: 186 | Batch_idx: 130 |  Loss: (0.0957) |  Loss2: (0.0000) | Acc: (96.00%) (16244/16768)
Epoch: 186 | Batch_idx: 140 |  Loss: (0.0950) |  Loss2: (0.0000) | Acc: (96.00%) (17488/18048)
Epoch: 186 | Batch_idx: 150 |  Loss: (0.0950) |  Loss2: (0.0000) | Acc: (96.00%) (18722/19328)
Epoch: 186 | Batch_idx: 160 |  Loss: (0.0950) |  Loss2: (0.0000) | Acc: (96.00%) (19960/20608)
Epoch: 186 | Batch_idx: 170 |  Loss: (0.0958) |  Loss2: (0.0000) | Acc: (96.00%) (21187/21888)
Epoch: 186 | Batch_idx: 180 |  Loss: (0.0963) |  Loss2: (0.0000) | Acc: (96.00%) (22418/23168)
Epoch: 186 | Batch_idx: 190 |  Loss: (0.0959) |  Loss2: (0.0000) | Acc: (96.00%) (23663/24448)
Epoch: 186 | Batch_idx: 200 |  Loss: (0.0963) |  Loss2: (0.0000) | Acc: (96.00%) (24890/25728)
Epoch: 186 | Batch_idx: 210 |  Loss: (0.0968) |  Loss2: (0.0000) | Acc: (96.00%) (26125/27008)
Epoch: 186 | Batch_idx: 220 |  Loss: (0.0978) |  Loss2: (0.0000) | Acc: (96.00%) (27350/28288)
Epoch: 186 | Batch_idx: 230 |  Loss: (0.0985) |  Loss2: (0.0000) | Acc: (96.00%) (28577/29568)
Epoch: 186 | Batch_idx: 240 |  Loss: (0.0984) |  Loss2: (0.0000) | Acc: (96.00%) (29814/30848)
Epoch: 186 | Batch_idx: 250 |  Loss: (0.0984) |  Loss2: (0.0000) | Acc: (96.00%) (31052/32128)
Epoch: 186 | Batch_idx: 260 |  Loss: (0.0981) |  Loss2: (0.0000) | Acc: (96.00%) (32295/33408)
Epoch: 186 | Batch_idx: 270 |  Loss: (0.0982) |  Loss2: (0.0000) | Acc: (96.00%) (33535/34688)
Epoch: 186 | Batch_idx: 280 |  Loss: (0.0980) |  Loss2: (0.0000) | Acc: (96.00%) (34781/35968)
Epoch: 186 | Batch_idx: 290 |  Loss: (0.0976) |  Loss2: (0.0000) | Acc: (96.00%) (36021/37248)
Epoch: 186 | Batch_idx: 300 |  Loss: (0.0974) |  Loss2: (0.0000) | Acc: (96.00%) (37271/38528)
Epoch: 186 | Batch_idx: 310 |  Loss: (0.0969) |  Loss2: (0.0000) | Acc: (96.00%) (38516/39808)
Epoch: 186 | Batch_idx: 320 |  Loss: (0.0966) |  Loss2: (0.0000) | Acc: (96.00%) (39753/41088)
Epoch: 186 | Batch_idx: 330 |  Loss: (0.0962) |  Loss2: (0.0000) | Acc: (96.00%) (40999/42368)
Epoch: 186 | Batch_idx: 340 |  Loss: (0.0958) |  Loss2: (0.0000) | Acc: (96.00%) (42238/43648)
Epoch: 186 | Batch_idx: 350 |  Loss: (0.0957) |  Loss2: (0.0000) | Acc: (96.00%) (43484/44928)
Epoch: 186 | Batch_idx: 360 |  Loss: (0.0960) |  Loss2: (0.0000) | Acc: (96.00%) (44715/46208)
Epoch: 186 | Batch_idx: 370 |  Loss: (0.0957) |  Loss2: (0.0000) | Acc: (96.00%) (45959/47488)
Epoch: 186 | Batch_idx: 380 |  Loss: (0.0953) |  Loss2: (0.0000) | Acc: (96.00%) (47202/48768)
Epoch: 186 | Batch_idx: 390 |  Loss: (0.0952) |  Loss2: (0.0000) | Acc: (96.00%) (48396/50000)
# TEST : Loss: (0.4055) | Acc: (88.00%) (8862/10000)
percent tensor([0.5170, 0.5195, 0.5310, 0.5176, 0.5307, 0.5167, 0.5232, 0.5224, 0.5204,
        0.5230, 0.5209, 0.5293, 0.5174, 0.5123, 0.5193, 0.5151],
       device='cuda:0') torch.Size([16])
percent tensor([0.4893, 0.4606, 0.4866, 0.4984, 0.4818, 0.5136, 0.4635, 0.4757, 0.4915,
        0.4671, 0.4859, 0.4737, 0.4700, 0.4854, 0.4775, 0.4887],
       device='cuda:0') torch.Size([16])
percent tensor([0.6454, 0.6382, 0.5892, 0.5644, 0.5955, 0.6061, 0.6591, 0.5997, 0.5929,
        0.6170, 0.6191, 0.6072, 0.6749, 0.5733, 0.6529, 0.6317],
       device='cuda:0') torch.Size([16])
percent tensor([0.6065, 0.6378, 0.6095, 0.6718, 0.6413, 0.7047, 0.6299, 0.5915, 0.6590,
        0.6264, 0.6530, 0.6621, 0.6146, 0.6754, 0.6762, 0.6355],
       device='cuda:0') torch.Size([16])
percent tensor([0.6184, 0.6288, 0.6106, 0.6139, 0.6583, 0.6372, 0.6380, 0.5658, 0.6821,
        0.6611, 0.6663, 0.5259, 0.5880, 0.7485, 0.5002, 0.6727],
       device='cuda:0') torch.Size([16])
percent tensor([0.6553, 0.6289, 0.7552, 0.7531, 0.8039, 0.7582, 0.7020, 0.7392, 0.6932,
        0.6782, 0.6605, 0.7125, 0.6380, 0.6766, 0.6955, 0.6963],
       device='cuda:0') torch.Size([16])
percent tensor([0.4801, 0.6589, 0.7080, 0.6586, 0.6878, 0.5235, 0.4886, 0.5247, 0.6857,
        0.5439, 0.7122, 0.6232, 0.6577, 0.5496, 0.4894, 0.4111],
       device='cuda:0') torch.Size([16])
percent tensor([0.9997, 0.9998, 0.9999, 0.9999, 0.9998, 0.9998, 0.9997, 0.9995, 0.9998,
        0.9998, 1.0000, 0.9998, 0.9999, 0.9997, 0.9991, 0.9994],
       device='cuda:0') torch.Size([16])
Epoch: 187 | Batch_idx: 0 |  Loss: (0.1143) |  Loss2: (0.0000) | Acc: (94.00%) (121/128)
Epoch: 187 | Batch_idx: 10 |  Loss: (0.0796) |  Loss2: (0.0000) | Acc: (97.00%) (1369/1408)
Epoch: 187 | Batch_idx: 20 |  Loss: (0.0854) |  Loss2: (0.0000) | Acc: (97.00%) (2614/2688)
Epoch: 187 | Batch_idx: 30 |  Loss: (0.0852) |  Loss2: (0.0000) | Acc: (97.00%) (3861/3968)
Epoch: 187 | Batch_idx: 40 |  Loss: (0.0859) |  Loss2: (0.0000) | Acc: (97.00%) (5100/5248)
Epoch: 187 | Batch_idx: 50 |  Loss: (0.0815) |  Loss2: (0.0000) | Acc: (97.00%) (6358/6528)
Epoch: 187 | Batch_idx: 60 |  Loss: (0.0853) |  Loss2: (0.0000) | Acc: (97.00%) (7587/7808)
Epoch: 187 | Batch_idx: 70 |  Loss: (0.0853) |  Loss2: (0.0000) | Acc: (97.00%) (8829/9088)
Epoch: 187 | Batch_idx: 80 |  Loss: (0.0863) |  Loss2: (0.0000) | Acc: (97.00%) (10072/10368)
Epoch: 187 | Batch_idx: 90 |  Loss: (0.0858) |  Loss2: (0.0000) | Acc: (97.00%) (11322/11648)
Epoch: 187 | Batch_idx: 100 |  Loss: (0.0875) |  Loss2: (0.0000) | Acc: (97.00%) (12554/12928)
Epoch: 187 | Batch_idx: 110 |  Loss: (0.0888) |  Loss2: (0.0000) | Acc: (97.00%) (13783/14208)
Epoch: 187 | Batch_idx: 120 |  Loss: (0.0881) |  Loss2: (0.0000) | Acc: (97.00%) (15027/15488)
Epoch: 187 | Batch_idx: 130 |  Loss: (0.0896) |  Loss2: (0.0000) | Acc: (96.00%) (16253/16768)
Epoch: 187 | Batch_idx: 140 |  Loss: (0.0901) |  Loss2: (0.0000) | Acc: (96.00%) (17498/18048)
Epoch: 187 | Batch_idx: 150 |  Loss: (0.0897) |  Loss2: (0.0000) | Acc: (96.00%) (18743/19328)
Epoch: 187 | Batch_idx: 160 |  Loss: (0.0900) |  Loss2: (0.0000) | Acc: (96.00%) (19982/20608)
Epoch: 187 | Batch_idx: 170 |  Loss: (0.0900) |  Loss2: (0.0000) | Acc: (96.00%) (21220/21888)
Epoch: 187 | Batch_idx: 180 |  Loss: (0.0896) |  Loss2: (0.0000) | Acc: (96.00%) (22469/23168)
Epoch: 187 | Batch_idx: 190 |  Loss: (0.0899) |  Loss2: (0.0000) | Acc: (96.00%) (23712/24448)
Epoch: 187 | Batch_idx: 200 |  Loss: (0.0900) |  Loss2: (0.0000) | Acc: (96.00%) (24952/25728)
Epoch: 187 | Batch_idx: 210 |  Loss: (0.0897) |  Loss2: (0.0000) | Acc: (96.00%) (26196/27008)
Epoch: 187 | Batch_idx: 220 |  Loss: (0.0895) |  Loss2: (0.0000) | Acc: (97.00%) (27443/28288)
Epoch: 187 | Batch_idx: 230 |  Loss: (0.0899) |  Loss2: (0.0000) | Acc: (96.00%) (28680/29568)
Epoch: 187 | Batch_idx: 240 |  Loss: (0.0898) |  Loss2: (0.0000) | Acc: (97.00%) (29924/30848)
Epoch: 187 | Batch_idx: 250 |  Loss: (0.0896) |  Loss2: (0.0000) | Acc: (97.00%) (31167/32128)
Epoch: 187 | Batch_idx: 260 |  Loss: (0.0893) |  Loss2: (0.0000) | Acc: (97.00%) (32412/33408)
Epoch: 187 | Batch_idx: 270 |  Loss: (0.0887) |  Loss2: (0.0000) | Acc: (97.00%) (33663/34688)
Epoch: 187 | Batch_idx: 280 |  Loss: (0.0886) |  Loss2: (0.0000) | Acc: (97.00%) (34911/35968)
Epoch: 187 | Batch_idx: 290 |  Loss: (0.0881) |  Loss2: (0.0000) | Acc: (97.00%) (36158/37248)
Epoch: 187 | Batch_idx: 300 |  Loss: (0.0883) |  Loss2: (0.0000) | Acc: (97.00%) (37398/38528)
Epoch: 187 | Batch_idx: 310 |  Loss: (0.0875) |  Loss2: (0.0000) | Acc: (97.00%) (38651/39808)
Epoch: 187 | Batch_idx: 320 |  Loss: (0.0878) |  Loss2: (0.0000) | Acc: (97.00%) (39894/41088)
Epoch: 187 | Batch_idx: 330 |  Loss: (0.0876) |  Loss2: (0.0000) | Acc: (97.00%) (41142/42368)
Epoch: 187 | Batch_idx: 340 |  Loss: (0.0879) |  Loss2: (0.0000) | Acc: (97.00%) (42380/43648)
Epoch: 187 | Batch_idx: 350 |  Loss: (0.0878) |  Loss2: (0.0000) | Acc: (97.00%) (43626/44928)
Epoch: 187 | Batch_idx: 360 |  Loss: (0.0880) |  Loss2: (0.0000) | Acc: (97.00%) (44868/46208)
Epoch: 187 | Batch_idx: 370 |  Loss: (0.0881) |  Loss2: (0.0000) | Acc: (97.00%) (46104/47488)
Epoch: 187 | Batch_idx: 380 |  Loss: (0.0881) |  Loss2: (0.0000) | Acc: (97.00%) (47345/48768)
Epoch: 187 | Batch_idx: 390 |  Loss: (0.0883) |  Loss2: (0.0000) | Acc: (97.00%) (48526/50000)
# TEST : Loss: (0.4000) | Acc: (88.00%) (8884/10000)
percent tensor([0.5187, 0.5218, 0.5339, 0.5201, 0.5336, 0.5183, 0.5257, 0.5251, 0.5224,
        0.5255, 0.5228, 0.5321, 0.5193, 0.5141, 0.5215, 0.5169],
       device='cuda:0') torch.Size([16])
percent tensor([0.4915, 0.4624, 0.4894, 0.5011, 0.4849, 0.5159, 0.4656, 0.4785, 0.4937,
        0.4688, 0.4880, 0.4761, 0.4718, 0.4868, 0.4802, 0.4910],
       device='cuda:0') torch.Size([16])
percent tensor([0.6468, 0.6407, 0.5906, 0.5645, 0.5966, 0.6068, 0.6607, 0.6015, 0.5942,
        0.6184, 0.6201, 0.6089, 0.6785, 0.5728, 0.6548, 0.6327],
       device='cuda:0') torch.Size([16])
percent tensor([0.6135, 0.6436, 0.6155, 0.6755, 0.6487, 0.7120, 0.6357, 0.5995, 0.6622,
        0.6309, 0.6574, 0.6655, 0.6193, 0.6775, 0.6835, 0.6438],
       device='cuda:0') torch.Size([16])
percent tensor([0.6064, 0.6179, 0.6004, 0.6031, 0.6466, 0.6246, 0.6253, 0.5548, 0.6673,
        0.6482, 0.6512, 0.5154, 0.5779, 0.7340, 0.4883, 0.6595],
       device='cuda:0') torch.Size([16])
percent tensor([0.6594, 0.6312, 0.7598, 0.7577, 0.8093, 0.7619, 0.7056, 0.7449, 0.6960,
        0.6817, 0.6623, 0.7146, 0.6402, 0.6781, 0.7002, 0.7002],
       device='cuda:0') torch.Size([16])
percent tensor([0.4916, 0.6817, 0.7286, 0.6779, 0.7044, 0.5307, 0.4967, 0.5333, 0.7089,
        0.5657, 0.7372, 0.6448, 0.6831, 0.5689, 0.4986, 0.4104],
       device='cuda:0') torch.Size([16])
percent tensor([0.9997, 0.9998, 0.9999, 0.9999, 0.9998, 0.9998, 0.9997, 0.9995, 0.9998,
        0.9998, 1.0000, 0.9998, 0.9999, 0.9996, 0.9991, 0.9994],
       device='cuda:0') torch.Size([16])
Epoch: 188 | Batch_idx: 0 |  Loss: (0.0745) |  Loss2: (0.0000) | Acc: (98.00%) (126/128)
Epoch: 188 | Batch_idx: 10 |  Loss: (0.0822) |  Loss2: (0.0000) | Acc: (97.00%) (1371/1408)
Epoch: 188 | Batch_idx: 20 |  Loss: (0.0855) |  Loss2: (0.0000) | Acc: (97.00%) (2617/2688)
Epoch: 188 | Batch_idx: 30 |  Loss: (0.0870) |  Loss2: (0.0000) | Acc: (97.00%) (3857/3968)
Epoch: 188 | Batch_idx: 40 |  Loss: (0.0859) |  Loss2: (0.0000) | Acc: (97.00%) (5105/5248)
Epoch: 188 | Batch_idx: 50 |  Loss: (0.0913) |  Loss2: (0.0000) | Acc: (96.00%) (6328/6528)
Epoch: 188 | Batch_idx: 60 |  Loss: (0.0910) |  Loss2: (0.0000) | Acc: (96.00%) (7567/7808)
Epoch: 188 | Batch_idx: 70 |  Loss: (0.0920) |  Loss2: (0.0000) | Acc: (96.00%) (8806/9088)
Epoch: 188 | Batch_idx: 80 |  Loss: (0.0923) |  Loss2: (0.0000) | Acc: (96.00%) (10052/10368)
Epoch: 188 | Batch_idx: 90 |  Loss: (0.0894) |  Loss2: (0.0000) | Acc: (97.00%) (11304/11648)
Epoch: 188 | Batch_idx: 100 |  Loss: (0.0900) |  Loss2: (0.0000) | Acc: (97.00%) (12548/12928)
Epoch: 188 | Batch_idx: 110 |  Loss: (0.0890) |  Loss2: (0.0000) | Acc: (97.00%) (13794/14208)
Epoch: 188 | Batch_idx: 120 |  Loss: (0.0877) |  Loss2: (0.0000) | Acc: (97.00%) (15041/15488)
Epoch: 188 | Batch_idx: 130 |  Loss: (0.0879) |  Loss2: (0.0000) | Acc: (97.00%) (16280/16768)
Epoch: 188 | Batch_idx: 140 |  Loss: (0.0874) |  Loss2: (0.0000) | Acc: (97.00%) (17521/18048)
Epoch: 188 | Batch_idx: 150 |  Loss: (0.0873) |  Loss2: (0.0000) | Acc: (97.00%) (18756/19328)
Epoch: 188 | Batch_idx: 160 |  Loss: (0.0875) |  Loss2: (0.0000) | Acc: (97.00%) (19997/20608)
Epoch: 188 | Batch_idx: 170 |  Loss: (0.0870) |  Loss2: (0.0000) | Acc: (97.00%) (21248/21888)
Epoch: 188 | Batch_idx: 180 |  Loss: (0.0864) |  Loss2: (0.0000) | Acc: (97.00%) (22494/23168)
Epoch: 188 | Batch_idx: 190 |  Loss: (0.0860) |  Loss2: (0.0000) | Acc: (97.00%) (23740/24448)
Epoch: 188 | Batch_idx: 200 |  Loss: (0.0860) |  Loss2: (0.0000) | Acc: (97.00%) (24982/25728)
Epoch: 188 | Batch_idx: 210 |  Loss: (0.0868) |  Loss2: (0.0000) | Acc: (97.00%) (26210/27008)
Epoch: 188 | Batch_idx: 220 |  Loss: (0.0863) |  Loss2: (0.0000) | Acc: (97.00%) (27456/28288)
Epoch: 188 | Batch_idx: 230 |  Loss: (0.0863) |  Loss2: (0.0000) | Acc: (97.00%) (28699/29568)
Epoch: 188 | Batch_idx: 240 |  Loss: (0.0864) |  Loss2: (0.0000) | Acc: (97.00%) (29944/30848)
Epoch: 188 | Batch_idx: 250 |  Loss: (0.0873) |  Loss2: (0.0000) | Acc: (97.00%) (31179/32128)
Epoch: 188 | Batch_idx: 260 |  Loss: (0.0870) |  Loss2: (0.0000) | Acc: (97.00%) (32423/33408)
Epoch: 188 | Batch_idx: 270 |  Loss: (0.0861) |  Loss2: (0.0000) | Acc: (97.00%) (33683/34688)
Epoch: 188 | Batch_idx: 280 |  Loss: (0.0864) |  Loss2: (0.0000) | Acc: (97.00%) (34918/35968)
Epoch: 188 | Batch_idx: 290 |  Loss: (0.0870) |  Loss2: (0.0000) | Acc: (97.00%) (36156/37248)
Epoch: 188 | Batch_idx: 300 |  Loss: (0.0871) |  Loss2: (0.0000) | Acc: (97.00%) (37394/38528)
Epoch: 188 | Batch_idx: 310 |  Loss: (0.0866) |  Loss2: (0.0000) | Acc: (97.00%) (38647/39808)
Epoch: 188 | Batch_idx: 320 |  Loss: (0.0870) |  Loss2: (0.0000) | Acc: (97.00%) (39884/41088)
Epoch: 188 | Batch_idx: 330 |  Loss: (0.0870) |  Loss2: (0.0000) | Acc: (97.00%) (41125/42368)
Epoch: 188 | Batch_idx: 340 |  Loss: (0.0870) |  Loss2: (0.0000) | Acc: (97.00%) (42375/43648)
Epoch: 188 | Batch_idx: 350 |  Loss: (0.0876) |  Loss2: (0.0000) | Acc: (97.00%) (43607/44928)
Epoch: 188 | Batch_idx: 360 |  Loss: (0.0871) |  Loss2: (0.0000) | Acc: (97.00%) (44863/46208)
Epoch: 188 | Batch_idx: 370 |  Loss: (0.0869) |  Loss2: (0.0000) | Acc: (97.00%) (46109/47488)
Epoch: 188 | Batch_idx: 380 |  Loss: (0.0870) |  Loss2: (0.0000) | Acc: (97.00%) (47349/48768)
Epoch: 188 | Batch_idx: 390 |  Loss: (0.0866) |  Loss2: (0.0000) | Acc: (97.00%) (48553/50000)
# TEST : Loss: (0.3959) | Acc: (88.00%) (8886/10000)
percent tensor([0.5177, 0.5209, 0.5336, 0.5196, 0.5331, 0.5174, 0.5249, 0.5246, 0.5215,
        0.5249, 0.5217, 0.5317, 0.5184, 0.5133, 0.5206, 0.5160],
       device='cuda:0') torch.Size([16])
percent tensor([0.4890, 0.4597, 0.4869, 0.4984, 0.4824, 0.5144, 0.4628, 0.4760, 0.4911,
        0.4665, 0.4856, 0.4737, 0.4696, 0.4837, 0.4775, 0.4885],
       device='cuda:0') torch.Size([16])
percent tensor([0.6467, 0.6431, 0.5878, 0.5632, 0.5935, 0.6075, 0.6601, 0.5985, 0.5946,
        0.6199, 0.6214, 0.6077, 0.6808, 0.5744, 0.6549, 0.6336],
       device='cuda:0') torch.Size([16])
percent tensor([0.6124, 0.6413, 0.6148, 0.6729, 0.6477, 0.7122, 0.6333, 0.5989, 0.6598,
        0.6293, 0.6555, 0.6635, 0.6178, 0.6752, 0.6818, 0.6421],
       device='cuda:0') torch.Size([16])
percent tensor([0.6120, 0.6243, 0.6043, 0.6062, 0.6502, 0.6313, 0.6308, 0.5563, 0.6710,
        0.6516, 0.6557, 0.5225, 0.5833, 0.7386, 0.4938, 0.6658],
       device='cuda:0') torch.Size([16])
percent tensor([0.6588, 0.6309, 0.7610, 0.7591, 0.8107, 0.7613, 0.7070, 0.7471, 0.6953,
        0.6837, 0.6625, 0.7151, 0.6392, 0.6794, 0.7008, 0.7003],
       device='cuda:0') torch.Size([16])
percent tensor([0.4845, 0.6780, 0.7300, 0.6773, 0.7056, 0.5292, 0.4950, 0.5351, 0.7088,
        0.5640, 0.7345, 0.6411, 0.6804, 0.5651, 0.4957, 0.4052],
       device='cuda:0') torch.Size([16])
percent tensor([0.9997, 0.9998, 0.9999, 0.9999, 0.9998, 0.9998, 0.9997, 0.9995, 0.9998,
        0.9998, 1.0000, 0.9998, 0.9999, 0.9996, 0.9991, 0.9994],
       device='cuda:0') torch.Size([16])
Epoch: 189 | Batch_idx: 0 |  Loss: (0.0661) |  Loss2: (0.0000) | Acc: (96.00%) (124/128)
Epoch: 189 | Batch_idx: 10 |  Loss: (0.0820) |  Loss2: (0.0000) | Acc: (97.00%) (1368/1408)
Epoch: 189 | Batch_idx: 20 |  Loss: (0.0835) |  Loss2: (0.0000) | Acc: (97.00%) (2612/2688)
Epoch: 189 | Batch_idx: 30 |  Loss: (0.0847) |  Loss2: (0.0000) | Acc: (97.00%) (3855/3968)
Epoch: 189 | Batch_idx: 40 |  Loss: (0.0834) |  Loss2: (0.0000) | Acc: (97.00%) (5099/5248)
Epoch: 189 | Batch_idx: 50 |  Loss: (0.0807) |  Loss2: (0.0000) | Acc: (97.00%) (6352/6528)
Epoch: 189 | Batch_idx: 60 |  Loss: (0.0827) |  Loss2: (0.0000) | Acc: (97.00%) (7591/7808)
Epoch: 189 | Batch_idx: 70 |  Loss: (0.0823) |  Loss2: (0.0000) | Acc: (97.00%) (8841/9088)
Epoch: 189 | Batch_idx: 80 |  Loss: (0.0812) |  Loss2: (0.0000) | Acc: (97.00%) (10093/10368)
Epoch: 189 | Batch_idx: 90 |  Loss: (0.0814) |  Loss2: (0.0000) | Acc: (97.00%) (11337/11648)
Epoch: 189 | Batch_idx: 100 |  Loss: (0.0826) |  Loss2: (0.0000) | Acc: (97.00%) (12571/12928)
Epoch: 189 | Batch_idx: 110 |  Loss: (0.0842) |  Loss2: (0.0000) | Acc: (97.00%) (13806/14208)
Epoch: 189 | Batch_idx: 120 |  Loss: (0.0850) |  Loss2: (0.0000) | Acc: (97.00%) (15044/15488)
Epoch: 189 | Batch_idx: 130 |  Loss: (0.0859) |  Loss2: (0.0000) | Acc: (97.00%) (16283/16768)
Epoch: 189 | Batch_idx: 140 |  Loss: (0.0853) |  Loss2: (0.0000) | Acc: (97.00%) (17534/18048)
Epoch: 189 | Batch_idx: 150 |  Loss: (0.0864) |  Loss2: (0.0000) | Acc: (97.00%) (18770/19328)
Epoch: 189 | Batch_idx: 160 |  Loss: (0.0868) |  Loss2: (0.0000) | Acc: (97.00%) (20014/20608)
Epoch: 189 | Batch_idx: 170 |  Loss: (0.0866) |  Loss2: (0.0000) | Acc: (97.00%) (21259/21888)
Epoch: 189 | Batch_idx: 180 |  Loss: (0.0872) |  Loss2: (0.0000) | Acc: (97.00%) (22498/23168)
Epoch: 189 | Batch_idx: 190 |  Loss: (0.0882) |  Loss2: (0.0000) | Acc: (97.00%) (23732/24448)
Epoch: 189 | Batch_idx: 200 |  Loss: (0.0876) |  Loss2: (0.0000) | Acc: (97.00%) (24979/25728)
Epoch: 189 | Batch_idx: 210 |  Loss: (0.0872) |  Loss2: (0.0000) | Acc: (97.00%) (26221/27008)
Epoch: 189 | Batch_idx: 220 |  Loss: (0.0876) |  Loss2: (0.0000) | Acc: (97.00%) (27463/28288)
Epoch: 189 | Batch_idx: 230 |  Loss: (0.0876) |  Loss2: (0.0000) | Acc: (97.00%) (28698/29568)
Epoch: 189 | Batch_idx: 240 |  Loss: (0.0876) |  Loss2: (0.0000) | Acc: (97.00%) (29934/30848)
Epoch: 189 | Batch_idx: 250 |  Loss: (0.0870) |  Loss2: (0.0000) | Acc: (97.00%) (31184/32128)
Epoch: 189 | Batch_idx: 260 |  Loss: (0.0873) |  Loss2: (0.0000) | Acc: (97.00%) (32424/33408)
Epoch: 189 | Batch_idx: 270 |  Loss: (0.0871) |  Loss2: (0.0000) | Acc: (97.00%) (33670/34688)
Epoch: 189 | Batch_idx: 280 |  Loss: (0.0870) |  Loss2: (0.0000) | Acc: (97.00%) (34910/35968)
Epoch: 189 | Batch_idx: 290 |  Loss: (0.0874) |  Loss2: (0.0000) | Acc: (97.00%) (36149/37248)
Epoch: 189 | Batch_idx: 300 |  Loss: (0.0872) |  Loss2: (0.0000) | Acc: (97.00%) (37395/38528)
Epoch: 189 | Batch_idx: 310 |  Loss: (0.0869) |  Loss2: (0.0000) | Acc: (97.00%) (38644/39808)
Epoch: 189 | Batch_idx: 320 |  Loss: (0.0869) |  Loss2: (0.0000) | Acc: (97.00%) (39890/41088)
Epoch: 189 | Batch_idx: 330 |  Loss: (0.0868) |  Loss2: (0.0000) | Acc: (97.00%) (41134/42368)
Epoch: 189 | Batch_idx: 340 |  Loss: (0.0867) |  Loss2: (0.0000) | Acc: (97.00%) (42377/43648)
Epoch: 189 | Batch_idx: 350 |  Loss: (0.0864) |  Loss2: (0.0000) | Acc: (97.00%) (43631/44928)
Epoch: 189 | Batch_idx: 360 |  Loss: (0.0865) |  Loss2: (0.0000) | Acc: (97.00%) (44881/46208)
Epoch: 189 | Batch_idx: 370 |  Loss: (0.0862) |  Loss2: (0.0000) | Acc: (97.00%) (46134/47488)
Epoch: 189 | Batch_idx: 380 |  Loss: (0.0858) |  Loss2: (0.0000) | Acc: (97.00%) (47386/48768)
Epoch: 189 | Batch_idx: 390 |  Loss: (0.0857) |  Loss2: (0.0000) | Acc: (97.00%) (48585/50000)
# TEST : Loss: (0.3940) | Acc: (88.00%) (8885/10000)
percent tensor([0.5170, 0.5205, 0.5332, 0.5193, 0.5326, 0.5167, 0.5244, 0.5242, 0.5208,
        0.5245, 0.5210, 0.5313, 0.5178, 0.5129, 0.5201, 0.5154],
       device='cuda:0') torch.Size([16])
percent tensor([0.4852, 0.4549, 0.4828, 0.4948, 0.4783, 0.5124, 0.4577, 0.4714, 0.4871,
        0.4618, 0.4815, 0.4688, 0.4652, 0.4794, 0.4733, 0.4849],
       device='cuda:0') torch.Size([16])
percent tensor([0.6428, 0.6389, 0.5841, 0.5593, 0.5898, 0.6037, 0.6558, 0.5961, 0.5915,
        0.6157, 0.6177, 0.6026, 0.6771, 0.5717, 0.6504, 0.6294],
       device='cuda:0') torch.Size([16])
percent tensor([0.6119, 0.6405, 0.6140, 0.6728, 0.6478, 0.7125, 0.6319, 0.5988, 0.6589,
        0.6273, 0.6542, 0.6610, 0.6159, 0.6747, 0.6809, 0.6427],
       device='cuda:0') torch.Size([16])
percent tensor([0.6162, 0.6336, 0.6077, 0.6102, 0.6520, 0.6358, 0.6365, 0.5585, 0.6773,
        0.6584, 0.6616, 0.5285, 0.5888, 0.7472, 0.4989, 0.6708],
       device='cuda:0') torch.Size([16])
percent tensor([0.6648, 0.6362, 0.7667, 0.7653, 0.8167, 0.7669, 0.7125, 0.7547, 0.7007,
        0.6893, 0.6676, 0.7201, 0.6437, 0.6835, 0.7068, 0.7063],
       device='cuda:0') torch.Size([16])
percent tensor([0.4815, 0.6786, 0.7281, 0.6754, 0.7038, 0.5202, 0.4935, 0.5376, 0.7113,
        0.5636, 0.7366, 0.6470, 0.6849, 0.5583, 0.4941, 0.4004],
       device='cuda:0') torch.Size([16])
percent tensor([0.9997, 0.9999, 0.9999, 0.9999, 0.9998, 0.9998, 0.9997, 0.9995, 0.9999,
        0.9998, 1.0000, 0.9998, 0.9999, 0.9996, 0.9992, 0.9995],
       device='cuda:0') torch.Size([16])
Epoch: 190 | Batch_idx: 0 |  Loss: (0.1016) |  Loss2: (0.0000) | Acc: (97.00%) (125/128)
Epoch: 190 | Batch_idx: 10 |  Loss: (0.0966) |  Loss2: (0.0000) | Acc: (96.00%) (1363/1408)
Epoch: 190 | Batch_idx: 20 |  Loss: (0.0923) |  Loss2: (0.0000) | Acc: (96.00%) (2601/2688)
Epoch: 190 | Batch_idx: 30 |  Loss: (0.0875) |  Loss2: (0.0000) | Acc: (97.00%) (3850/3968)
Epoch: 190 | Batch_idx: 40 |  Loss: (0.0861) |  Loss2: (0.0000) | Acc: (97.00%) (5095/5248)
Epoch: 190 | Batch_idx: 50 |  Loss: (0.0847) |  Loss2: (0.0000) | Acc: (97.00%) (6342/6528)
Epoch: 190 | Batch_idx: 60 |  Loss: (0.0828) |  Loss2: (0.0000) | Acc: (97.00%) (7589/7808)
Epoch: 190 | Batch_idx: 70 |  Loss: (0.0799) |  Loss2: (0.0000) | Acc: (97.00%) (8844/9088)
Epoch: 190 | Batch_idx: 80 |  Loss: (0.0799) |  Loss2: (0.0000) | Acc: (97.00%) (10089/10368)
Epoch: 190 | Batch_idx: 90 |  Loss: (0.0818) |  Loss2: (0.0000) | Acc: (97.00%) (11330/11648)
Epoch: 190 | Batch_idx: 100 |  Loss: (0.0824) |  Loss2: (0.0000) | Acc: (97.00%) (12567/12928)
Epoch: 190 | Batch_idx: 110 |  Loss: (0.0833) |  Loss2: (0.0000) | Acc: (97.00%) (13805/14208)
Epoch: 190 | Batch_idx: 120 |  Loss: (0.0847) |  Loss2: (0.0000) | Acc: (97.00%) (15041/15488)
Epoch: 190 | Batch_idx: 130 |  Loss: (0.0852) |  Loss2: (0.0000) | Acc: (97.00%) (16284/16768)
Epoch: 190 | Batch_idx: 140 |  Loss: (0.0844) |  Loss2: (0.0000) | Acc: (97.00%) (17533/18048)
Epoch: 190 | Batch_idx: 150 |  Loss: (0.0846) |  Loss2: (0.0000) | Acc: (97.00%) (18771/19328)
Epoch: 190 | Batch_idx: 160 |  Loss: (0.0836) |  Loss2: (0.0000) | Acc: (97.00%) (20024/20608)
Epoch: 190 | Batch_idx: 170 |  Loss: (0.0834) |  Loss2: (0.0000) | Acc: (97.00%) (21268/21888)
Epoch: 190 | Batch_idx: 180 |  Loss: (0.0828) |  Loss2: (0.0000) | Acc: (97.00%) (22515/23168)
Epoch: 190 | Batch_idx: 190 |  Loss: (0.0833) |  Loss2: (0.0000) | Acc: (97.00%) (23760/24448)
Epoch: 190 | Batch_idx: 200 |  Loss: (0.0836) |  Loss2: (0.0000) | Acc: (97.00%) (25003/25728)
Epoch: 190 | Batch_idx: 210 |  Loss: (0.0832) |  Loss2: (0.0000) | Acc: (97.00%) (26252/27008)
Epoch: 190 | Batch_idx: 220 |  Loss: (0.0830) |  Loss2: (0.0000) | Acc: (97.00%) (27499/28288)
Epoch: 190 | Batch_idx: 230 |  Loss: (0.0827) |  Loss2: (0.0000) | Acc: (97.00%) (28748/29568)
Epoch: 190 | Batch_idx: 240 |  Loss: (0.0828) |  Loss2: (0.0000) | Acc: (97.00%) (29996/30848)
Epoch: 190 | Batch_idx: 250 |  Loss: (0.0829) |  Loss2: (0.0000) | Acc: (97.00%) (31235/32128)
Epoch: 190 | Batch_idx: 260 |  Loss: (0.0829) |  Loss2: (0.0000) | Acc: (97.00%) (32480/33408)
Epoch: 190 | Batch_idx: 270 |  Loss: (0.0823) |  Loss2: (0.0000) | Acc: (97.00%) (33730/34688)
Epoch: 190 | Batch_idx: 280 |  Loss: (0.0819) |  Loss2: (0.0000) | Acc: (97.00%) (34980/35968)
Epoch: 190 | Batch_idx: 290 |  Loss: (0.0817) |  Loss2: (0.0000) | Acc: (97.00%) (36222/37248)
Epoch: 190 | Batch_idx: 300 |  Loss: (0.0813) |  Loss2: (0.0000) | Acc: (97.00%) (37472/38528)
Epoch: 190 | Batch_idx: 310 |  Loss: (0.0815) |  Loss2: (0.0000) | Acc: (97.00%) (38715/39808)
Epoch: 190 | Batch_idx: 320 |  Loss: (0.0815) |  Loss2: (0.0000) | Acc: (97.00%) (39963/41088)
Epoch: 190 | Batch_idx: 330 |  Loss: (0.0813) |  Loss2: (0.0000) | Acc: (97.00%) (41213/42368)
Epoch: 190 | Batch_idx: 340 |  Loss: (0.0810) |  Loss2: (0.0000) | Acc: (97.00%) (42466/43648)
Epoch: 190 | Batch_idx: 350 |  Loss: (0.0809) |  Loss2: (0.0000) | Acc: (97.00%) (43712/44928)
Epoch: 190 | Batch_idx: 360 |  Loss: (0.0813) |  Loss2: (0.0000) | Acc: (97.00%) (44946/46208)
Epoch: 190 | Batch_idx: 370 |  Loss: (0.0815) |  Loss2: (0.0000) | Acc: (97.00%) (46187/47488)
Epoch: 190 | Batch_idx: 380 |  Loss: (0.0811) |  Loss2: (0.0000) | Acc: (97.00%) (47441/48768)
Epoch: 190 | Batch_idx: 390 |  Loss: (0.0813) |  Loss2: (0.0000) | Acc: (97.00%) (48638/50000)
=> saving checkpoint 'drive/app/torch/save_Schedule/checkpoint_190.pth.tar'
# TEST : Loss: (0.3935) | Acc: (88.00%) (8891/10000)
percent tensor([0.5175, 0.5211, 0.5337, 0.5196, 0.5331, 0.5174, 0.5250, 0.5247, 0.5213,
        0.5249, 0.5215, 0.5319, 0.5183, 0.5134, 0.5207, 0.5159],
       device='cuda:0') torch.Size([16])
percent tensor([0.4875, 0.4572, 0.4851, 0.4969, 0.4811, 0.5145, 0.4601, 0.4741, 0.4894,
        0.4640, 0.4837, 0.4713, 0.4675, 0.4812, 0.4758, 0.4872],
       device='cuda:0') torch.Size([16])
percent tensor([0.6430, 0.6421, 0.5826, 0.5571, 0.5878, 0.6002, 0.6571, 0.5943, 0.5916,
        0.6187, 0.6199, 0.6041, 0.6812, 0.5711, 0.6505, 0.6299],
       device='cuda:0') torch.Size([16])
percent tensor([0.6144, 0.6428, 0.6152, 0.6730, 0.6488, 0.7144, 0.6339, 0.6009, 0.6589,
        0.6282, 0.6556, 0.6620, 0.6190, 0.6735, 0.6835, 0.6452],
       device='cuda:0') torch.Size([16])
percent tensor([0.6071, 0.6280, 0.5994, 0.6015, 0.6424, 0.6264, 0.6281, 0.5500, 0.6695,
        0.6502, 0.6533, 0.5236, 0.5843, 0.7393, 0.4905, 0.6607],
       device='cuda:0') torch.Size([16])
percent tensor([0.6594, 0.6318, 0.7634, 0.7610, 0.8131, 0.7612, 0.7081, 0.7503, 0.6943,
        0.6838, 0.6623, 0.7147, 0.6386, 0.6753, 0.7018, 0.7004],
       device='cuda:0') torch.Size([16])
percent tensor([0.4843, 0.6868, 0.7344, 0.6783, 0.7092, 0.5194, 0.4963, 0.5385, 0.7209,
        0.5711, 0.7500, 0.6517, 0.6926, 0.5673, 0.4951, 0.4001],
       device='cuda:0') torch.Size([16])
percent tensor([0.9997, 0.9999, 0.9999, 0.9999, 0.9998, 0.9998, 0.9997, 0.9995, 0.9998,
        0.9998, 1.0000, 0.9999, 0.9999, 0.9996, 0.9992, 0.9995],
       device='cuda:0') torch.Size([16])
Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 3, 3, 3]) tensor(192.1670, device='cuda:0')
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(824.5405, device='cuda:0')
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(831.7943, device='cuda:0')
Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([128, 64, 3, 3]) tensor(1523.3047, device='cuda:0')
Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([128, 64, 1, 1]) tensor(477.3765, device='cuda:0')
Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([128, 128, 3, 3]) tensor(2317.4316, device='cuda:0')
Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([256, 128, 3, 3]) tensor(4257.6699, device='cuda:0')
Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([256, 128, 1, 1]) tensor(1348.6875, device='cuda:0')
Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([256, 256, 3, 3]) tensor(6250.1846, device='cuda:0')
Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([512, 256, 3, 3]) tensor(11552.6523, device='cuda:0')
Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([512, 256, 1, 1]) tensor(3805.7322, device='cuda:0')
Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([512, 512, 3, 3]) tensor(16058.4121, device='cuda:0')
Epoch: 191 | Batch_idx: 0 |  Loss: (0.0491) |  Loss2: (0.0000) | Acc: (99.00%) (127/128)
Epoch: 191 | Batch_idx: 10 |  Loss: (0.0839) |  Loss2: (0.0000) | Acc: (97.00%) (1370/1408)
Epoch: 191 | Batch_idx: 20 |  Loss: (0.0832) |  Loss2: (0.0000) | Acc: (97.00%) (2615/2688)
Epoch: 191 | Batch_idx: 30 |  Loss: (0.0820) |  Loss2: (0.0000) | Acc: (97.00%) (3861/3968)
Epoch: 191 | Batch_idx: 40 |  Loss: (0.0822) |  Loss2: (0.0000) | Acc: (97.00%) (5109/5248)
Epoch: 191 | Batch_idx: 50 |  Loss: (0.0848) |  Loss2: (0.0000) | Acc: (97.00%) (6349/6528)
Epoch: 191 | Batch_idx: 60 |  Loss: (0.0856) |  Loss2: (0.0000) | Acc: (97.00%) (7585/7808)
Epoch: 191 | Batch_idx: 70 |  Loss: (0.0861) |  Loss2: (0.0000) | Acc: (97.00%) (8828/9088)
Epoch: 191 | Batch_idx: 80 |  Loss: (0.0863) |  Loss2: (0.0000) | Acc: (97.00%) (10066/10368)
Epoch: 191 | Batch_idx: 90 |  Loss: (0.0861) |  Loss2: (0.0000) | Acc: (97.00%) (11308/11648)
Epoch: 191 | Batch_idx: 100 |  Loss: (0.0854) |  Loss2: (0.0000) | Acc: (97.00%) (12558/12928)
Epoch: 191 | Batch_idx: 110 |  Loss: (0.0851) |  Loss2: (0.0000) | Acc: (97.00%) (13805/14208)
Epoch: 191 | Batch_idx: 120 |  Loss: (0.0837) |  Loss2: (0.0000) | Acc: (97.00%) (15060/15488)
Epoch: 191 | Batch_idx: 130 |  Loss: (0.0831) |  Loss2: (0.0000) | Acc: (97.00%) (16312/16768)
Epoch: 191 | Batch_idx: 140 |  Loss: (0.0832) |  Loss2: (0.0000) | Acc: (97.00%) (17561/18048)
Epoch: 191 | Batch_idx: 150 |  Loss: (0.0828) |  Loss2: (0.0000) | Acc: (97.00%) (18806/19328)
Epoch: 191 | Batch_idx: 160 |  Loss: (0.0824) |  Loss2: (0.0000) | Acc: (97.00%) (20051/20608)
Epoch: 191 | Batch_idx: 170 |  Loss: (0.0824) |  Loss2: (0.0000) | Acc: (97.00%) (21302/21888)
Epoch: 191 | Batch_idx: 180 |  Loss: (0.0821) |  Loss2: (0.0000) | Acc: (97.00%) (22547/23168)
Epoch: 191 | Batch_idx: 190 |  Loss: (0.0816) |  Loss2: (0.0000) | Acc: (97.00%) (23798/24448)
Epoch: 191 | Batch_idx: 200 |  Loss: (0.0823) |  Loss2: (0.0000) | Acc: (97.00%) (25035/25728)
Epoch: 191 | Batch_idx: 210 |  Loss: (0.0827) |  Loss2: (0.0000) | Acc: (97.00%) (26277/27008)
Epoch: 191 | Batch_idx: 220 |  Loss: (0.0821) |  Loss2: (0.0000) | Acc: (97.00%) (27527/28288)
Epoch: 191 | Batch_idx: 230 |  Loss: (0.0815) |  Loss2: (0.0000) | Acc: (97.00%) (28778/29568)
Epoch: 191 | Batch_idx: 240 |  Loss: (0.0816) |  Loss2: (0.0000) | Acc: (97.00%) (30022/30848)
Epoch: 191 | Batch_idx: 250 |  Loss: (0.0820) |  Loss2: (0.0000) | Acc: (97.00%) (31257/32128)
Epoch: 191 | Batch_idx: 260 |  Loss: (0.0816) |  Loss2: (0.0000) | Acc: (97.00%) (32506/33408)
Epoch: 191 | Batch_idx: 270 |  Loss: (0.0819) |  Loss2: (0.0000) | Acc: (97.00%) (33754/34688)
Epoch: 191 | Batch_idx: 280 |  Loss: (0.0821) |  Loss2: (0.0000) | Acc: (97.00%) (35000/35968)
Epoch: 191 | Batch_idx: 290 |  Loss: (0.0829) |  Loss2: (0.0000) | Acc: (97.00%) (36236/37248)
Epoch: 191 | Batch_idx: 300 |  Loss: (0.0827) |  Loss2: (0.0000) | Acc: (97.00%) (37491/38528)
Epoch: 191 | Batch_idx: 310 |  Loss: (0.0822) |  Loss2: (0.0000) | Acc: (97.00%) (38747/39808)
Epoch: 191 | Batch_idx: 320 |  Loss: (0.0817) |  Loss2: (0.0000) | Acc: (97.00%) (40004/41088)
Epoch: 191 | Batch_idx: 330 |  Loss: (0.0816) |  Loss2: (0.0000) | Acc: (97.00%) (41244/42368)
Epoch: 191 | Batch_idx: 340 |  Loss: (0.0814) |  Loss2: (0.0000) | Acc: (97.00%) (42489/43648)
Epoch: 191 | Batch_idx: 350 |  Loss: (0.0811) |  Loss2: (0.0000) | Acc: (97.00%) (43743/44928)
Epoch: 191 | Batch_idx: 360 |  Loss: (0.0815) |  Loss2: (0.0000) | Acc: (97.00%) (44981/46208)
Epoch: 191 | Batch_idx: 370 |  Loss: (0.0816) |  Loss2: (0.0000) | Acc: (97.00%) (46225/47488)
Epoch: 191 | Batch_idx: 380 |  Loss: (0.0813) |  Loss2: (0.0000) | Acc: (97.00%) (47479/48768)
Epoch: 191 | Batch_idx: 390 |  Loss: (0.0812) |  Loss2: (0.0000) | Acc: (97.00%) (48679/50000)
# TEST : Loss: (0.3921) | Acc: (88.00%) (8891/10000)
percent tensor([0.5164, 0.5197, 0.5324, 0.5185, 0.5317, 0.5162, 0.5235, 0.5234, 0.5201,
        0.5235, 0.5203, 0.5304, 0.5170, 0.5123, 0.5194, 0.5147],
       device='cuda:0') torch.Size([16])
percent tensor([0.4899, 0.4593, 0.4872, 0.4994, 0.4835, 0.5160, 0.4624, 0.4766, 0.4918,
        0.4661, 0.4863, 0.4732, 0.4696, 0.4837, 0.4781, 0.4897],
       device='cuda:0') torch.Size([16])
percent tensor([0.6451, 0.6456, 0.5823, 0.5565, 0.5867, 0.6023, 0.6587, 0.5932, 0.5919,
        0.6203, 0.6215, 0.6043, 0.6846, 0.5716, 0.6533, 0.6318],
       device='cuda:0') torch.Size([16])
percent tensor([0.6164, 0.6435, 0.6147, 0.6723, 0.6496, 0.7161, 0.6340, 0.6009, 0.6595,
        0.6295, 0.6565, 0.6617, 0.6214, 0.6729, 0.6843, 0.6471],
       device='cuda:0') torch.Size([16])
percent tensor([0.6135, 0.6327, 0.6055, 0.6088, 0.6491, 0.6356, 0.6344, 0.5569, 0.6748,
        0.6541, 0.6572, 0.5310, 0.5889, 0.7451, 0.4978, 0.6673],
       device='cuda:0') torch.Size([16])
percent tensor([0.6495, 0.6217, 0.7560, 0.7520, 0.8059, 0.7522, 0.6986, 0.7422, 0.6847,
        0.6750, 0.6522, 0.7032, 0.6291, 0.6642, 0.6907, 0.6894],
       device='cuda:0') torch.Size([16])
percent tensor([0.4841, 0.6957, 0.7337, 0.6755, 0.7036, 0.5140, 0.4995, 0.5362, 0.7290,
        0.5830, 0.7568, 0.6546, 0.7014, 0.5730, 0.4954, 0.3977],
       device='cuda:0') torch.Size([16])
percent tensor([0.9997, 0.9999, 0.9999, 0.9999, 0.9999, 0.9998, 0.9997, 0.9995, 0.9998,
        0.9998, 1.0000, 0.9999, 0.9999, 0.9996, 0.9992, 0.9995],
       device='cuda:0') torch.Size([16])
True Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=128, out_features=16, bias=False)
False Linear(in_features=16, out_features=2, bias=False)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=128, out_features=16, bias=False)
False Linear(in_features=16, out_features=2, bias=False)
True Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=256, out_features=32, bias=False)
False Linear(in_features=32, out_features=2, bias=False)
True Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=256, out_features=32, bias=False)
False Linear(in_features=32, out_features=2, bias=False)
True Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=512, out_features=64, bias=False)
False Linear(in_features=64, out_features=2, bias=False)
True Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=512, out_features=64, bias=False)
False Linear(in_features=64, out_features=2, bias=False)
True Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1024, out_features=128, bias=False)
False Linear(in_features=128, out_features=2, bias=False)
True Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1024, out_features=128, bias=False)
False Linear(in_features=128, out_features=2, bias=False)
True Linear(in_features=512, out_features=10, bias=True)
Epoch: 192 | Batch_idx: 0 |  Loss: (0.1096) |  Loss2: (0.0000) | Acc: (96.00%) (124/128)
Epoch: 192 | Batch_idx: 10 |  Loss: (0.0844) |  Loss2: (0.0000) | Acc: (97.00%) (1366/1408)
Epoch: 192 | Batch_idx: 20 |  Loss: (0.0874) |  Loss2: (0.0000) | Acc: (96.00%) (2599/2688)
Epoch: 192 | Batch_idx: 30 |  Loss: (0.0805) |  Loss2: (0.0000) | Acc: (97.00%) (3856/3968)
Epoch: 192 | Batch_idx: 40 |  Loss: (0.0791) |  Loss2: (0.0000) | Acc: (97.00%) (5107/5248)
Epoch: 192 | Batch_idx: 50 |  Loss: (0.0805) |  Loss2: (0.0000) | Acc: (97.00%) (6343/6528)
Epoch: 192 | Batch_idx: 60 |  Loss: (0.0805) |  Loss2: (0.0000) | Acc: (97.00%) (7592/7808)
Epoch: 192 | Batch_idx: 70 |  Loss: (0.0837) |  Loss2: (0.0000) | Acc: (97.00%) (8822/9088)
Epoch: 192 | Batch_idx: 80 |  Loss: (0.0839) |  Loss2: (0.0000) | Acc: (97.00%) (10067/10368)
Epoch: 192 | Batch_idx: 90 |  Loss: (0.0838) |  Loss2: (0.0000) | Acc: (97.00%) (11315/11648)
Epoch: 192 | Batch_idx: 100 |  Loss: (0.0848) |  Loss2: (0.0000) | Acc: (97.00%) (12554/12928)
Epoch: 192 | Batch_idx: 110 |  Loss: (0.0844) |  Loss2: (0.0000) | Acc: (97.00%) (13803/14208)
Epoch: 192 | Batch_idx: 120 |  Loss: (0.0840) |  Loss2: (0.0000) | Acc: (97.00%) (15048/15488)
Epoch: 192 | Batch_idx: 130 |  Loss: (0.0843) |  Loss2: (0.0000) | Acc: (97.00%) (16294/16768)
Epoch: 192 | Batch_idx: 140 |  Loss: (0.0857) |  Loss2: (0.0000) | Acc: (97.00%) (17526/18048)
Epoch: 192 | Batch_idx: 150 |  Loss: (0.0854) |  Loss2: (0.0000) | Acc: (97.00%) (18778/19328)
Epoch: 192 | Batch_idx: 160 |  Loss: (0.0860) |  Loss2: (0.0000) | Acc: (97.00%) (20013/20608)
Epoch: 192 | Batch_idx: 170 |  Loss: (0.0862) |  Loss2: (0.0000) | Acc: (97.00%) (21244/21888)
Epoch: 192 | Batch_idx: 180 |  Loss: (0.0857) |  Loss2: (0.0000) | Acc: (97.00%) (22493/23168)
Epoch: 192 | Batch_idx: 190 |  Loss: (0.0861) |  Loss2: (0.0000) | Acc: (97.00%) (23730/24448)
Epoch: 192 | Batch_idx: 200 |  Loss: (0.0863) |  Loss2: (0.0000) | Acc: (97.00%) (24972/25728)
Epoch: 192 | Batch_idx: 210 |  Loss: (0.0863) |  Loss2: (0.0000) | Acc: (97.00%) (26216/27008)
Epoch: 192 | Batch_idx: 220 |  Loss: (0.0864) |  Loss2: (0.0000) | Acc: (97.00%) (27456/28288)
Epoch: 192 | Batch_idx: 230 |  Loss: (0.0870) |  Loss2: (0.0000) | Acc: (97.00%) (28694/29568)
Epoch: 192 | Batch_idx: 240 |  Loss: (0.0879) |  Loss2: (0.0000) | Acc: (97.00%) (29925/30848)
Epoch: 192 | Batch_idx: 250 |  Loss: (0.0884) |  Loss2: (0.0000) | Acc: (96.00%) (31163/32128)
Epoch: 192 | Batch_idx: 260 |  Loss: (0.0879) |  Loss2: (0.0000) | Acc: (97.00%) (32411/33408)
Epoch: 192 | Batch_idx: 270 |  Loss: (0.0886) |  Loss2: (0.0000) | Acc: (96.00%) (33644/34688)
Epoch: 192 | Batch_idx: 280 |  Loss: (0.0885) |  Loss2: (0.0000) | Acc: (96.00%) (34886/35968)
Epoch: 192 | Batch_idx: 290 |  Loss: (0.0889) |  Loss2: (0.0000) | Acc: (96.00%) (36125/37248)
Epoch: 192 | Batch_idx: 300 |  Loss: (0.0886) |  Loss2: (0.0000) | Acc: (97.00%) (37375/38528)
Epoch: 192 | Batch_idx: 310 |  Loss: (0.0888) |  Loss2: (0.0000) | Acc: (96.00%) (38610/39808)
Epoch: 192 | Batch_idx: 320 |  Loss: (0.0887) |  Loss2: (0.0000) | Acc: (97.00%) (39856/41088)
Epoch: 192 | Batch_idx: 330 |  Loss: (0.0886) |  Loss2: (0.0000) | Acc: (97.00%) (41098/42368)
Epoch: 192 | Batch_idx: 340 |  Loss: (0.0883) |  Loss2: (0.0000) | Acc: (97.00%) (42345/43648)
Epoch: 192 | Batch_idx: 350 |  Loss: (0.0884) |  Loss2: (0.0000) | Acc: (97.00%) (43585/44928)
Epoch: 192 | Batch_idx: 360 |  Loss: (0.0882) |  Loss2: (0.0000) | Acc: (97.00%) (44826/46208)
Epoch: 192 | Batch_idx: 370 |  Loss: (0.0881) |  Loss2: (0.0000) | Acc: (97.00%) (46070/47488)
Epoch: 192 | Batch_idx: 380 |  Loss: (0.0883) |  Loss2: (0.0000) | Acc: (97.00%) (47316/48768)
Epoch: 192 | Batch_idx: 390 |  Loss: (0.0882) |  Loss2: (0.0000) | Acc: (97.00%) (48507/50000)
# TEST : Loss: (0.4265) | Acc: (87.00%) (8786/10000)
percent tensor([0.5154, 0.5192, 0.5331, 0.5189, 0.5322, 0.5150, 0.5234, 0.5234, 0.5196,
        0.5234, 0.5192, 0.5308, 0.5161, 0.5128, 0.5187, 0.5145],
       device='cuda:0') torch.Size([16])
percent tensor([0.4890, 0.4584, 0.4870, 0.4985, 0.4824, 0.5152, 0.4627, 0.4743, 0.4937,
        0.4663, 0.4872, 0.4757, 0.4694, 0.4845, 0.4758, 0.4888],
       device='cuda:0') torch.Size([16])
percent tensor([0.6395, 0.6424, 0.5837, 0.5512, 0.5861, 0.5910, 0.6551, 0.5927, 0.5861,
        0.6161, 0.6145, 0.5934, 0.6786, 0.5685, 0.6484, 0.6280],
       device='cuda:0') torch.Size([16])
percent tensor([0.6210, 0.6423, 0.6214, 0.6782, 0.6500, 0.7073, 0.6359, 0.6036, 0.6664,
        0.6336, 0.6601, 0.6699, 0.6278, 0.6781, 0.6769, 0.6451],
       device='cuda:0') torch.Size([16])
percent tensor([0.6192, 0.6285, 0.5956, 0.5992, 0.6441, 0.6482, 0.6230, 0.5502, 0.6854,
        0.6430, 0.6711, 0.5338, 0.6124, 0.7336, 0.4942, 0.6675],
       device='cuda:0') torch.Size([16])
percent tensor([0.6353, 0.6080, 0.7501, 0.7501, 0.7947, 0.7628, 0.6869, 0.7403, 0.6835,
        0.6635, 0.6512, 0.6995, 0.6087, 0.6600, 0.6851, 0.6900],
       device='cuda:0') torch.Size([16])
percent tensor([0.4662, 0.7113, 0.7049, 0.6575, 0.6842, 0.5142, 0.5222, 0.5260, 0.6851,
        0.6309, 0.7541, 0.6571, 0.6505, 0.5689, 0.5088, 0.4023],
       device='cuda:0') torch.Size([16])
percent tensor([0.9998, 0.9999, 0.9998, 0.9999, 0.9997, 0.9996, 0.9997, 0.9995, 0.9997,
        0.9999, 1.0000, 0.9999, 0.9999, 0.9995, 0.9990, 0.9997],
       device='cuda:0') torch.Size([16])
Epoch: 193 | Batch_idx: 0 |  Loss: (0.0604) |  Loss2: (0.0000) | Acc: (98.00%) (126/128)
Epoch: 193 | Batch_idx: 10 |  Loss: (0.0699) |  Loss2: (0.0000) | Acc: (97.00%) (1377/1408)
Epoch: 193 | Batch_idx: 20 |  Loss: (0.0674) |  Loss2: (0.0000) | Acc: (97.00%) (2631/2688)
Epoch: 193 | Batch_idx: 30 |  Loss: (0.0752) |  Loss2: (0.0000) | Acc: (97.00%) (3873/3968)
Epoch: 193 | Batch_idx: 40 |  Loss: (0.0779) |  Loss2: (0.0000) | Acc: (97.00%) (5119/5248)
Epoch: 193 | Batch_idx: 50 |  Loss: (0.0808) |  Loss2: (0.0000) | Acc: (97.00%) (6358/6528)
Epoch: 193 | Batch_idx: 60 |  Loss: (0.0815) |  Loss2: (0.0000) | Acc: (97.00%) (7605/7808)
Epoch: 193 | Batch_idx: 70 |  Loss: (0.0832) |  Loss2: (0.0000) | Acc: (97.00%) (8848/9088)
Epoch: 193 | Batch_idx: 80 |  Loss: (0.0842) |  Loss2: (0.0000) | Acc: (97.00%) (10092/10368)
Epoch: 193 | Batch_idx: 90 |  Loss: (0.0830) |  Loss2: (0.0000) | Acc: (97.00%) (11339/11648)
Epoch: 193 | Batch_idx: 100 |  Loss: (0.0839) |  Loss2: (0.0000) | Acc: (97.00%) (12579/12928)
Epoch: 193 | Batch_idx: 110 |  Loss: (0.0829) |  Loss2: (0.0000) | Acc: (97.00%) (13830/14208)
Epoch: 193 | Batch_idx: 120 |  Loss: (0.0822) |  Loss2: (0.0000) | Acc: (97.00%) (15080/15488)
Epoch: 193 | Batch_idx: 130 |  Loss: (0.0827) |  Loss2: (0.0000) | Acc: (97.00%) (16313/16768)
Epoch: 193 | Batch_idx: 140 |  Loss: (0.0844) |  Loss2: (0.0000) | Acc: (97.00%) (17539/18048)
Epoch: 193 | Batch_idx: 150 |  Loss: (0.0848) |  Loss2: (0.0000) | Acc: (97.00%) (18784/19328)
Epoch: 193 | Batch_idx: 160 |  Loss: (0.0837) |  Loss2: (0.0000) | Acc: (97.00%) (20034/20608)
Epoch: 193 | Batch_idx: 170 |  Loss: (0.0834) |  Loss2: (0.0000) | Acc: (97.00%) (21279/21888)
Epoch: 193 | Batch_idx: 180 |  Loss: (0.0844) |  Loss2: (0.0000) | Acc: (97.00%) (22518/23168)
Epoch: 193 | Batch_idx: 190 |  Loss: (0.0852) |  Loss2: (0.0000) | Acc: (97.00%) (23750/24448)
Epoch: 193 | Batch_idx: 200 |  Loss: (0.0851) |  Loss2: (0.0000) | Acc: (97.00%) (24996/25728)
Epoch: 193 | Batch_idx: 210 |  Loss: (0.0847) |  Loss2: (0.0000) | Acc: (97.00%) (26242/27008)
Epoch: 193 | Batch_idx: 220 |  Loss: (0.0846) |  Loss2: (0.0000) | Acc: (97.00%) (27488/28288)
Epoch: 193 | Batch_idx: 230 |  Loss: (0.0850) |  Loss2: (0.0000) | Acc: (97.00%) (28725/29568)
Epoch: 193 | Batch_idx: 240 |  Loss: (0.0851) |  Loss2: (0.0000) | Acc: (97.00%) (29966/30848)
Epoch: 193 | Batch_idx: 250 |  Loss: (0.0858) |  Loss2: (0.0000) | Acc: (97.00%) (31196/32128)
Epoch: 193 | Batch_idx: 260 |  Loss: (0.0860) |  Loss2: (0.0000) | Acc: (97.00%) (32444/33408)
Epoch: 193 | Batch_idx: 270 |  Loss: (0.0859) |  Loss2: (0.0000) | Acc: (97.00%) (33685/34688)
Epoch: 193 | Batch_idx: 280 |  Loss: (0.0863) |  Loss2: (0.0000) | Acc: (97.00%) (34919/35968)
Epoch: 193 | Batch_idx: 290 |  Loss: (0.0860) |  Loss2: (0.0000) | Acc: (97.00%) (36164/37248)
Epoch: 193 | Batch_idx: 300 |  Loss: (0.0862) |  Loss2: (0.0000) | Acc: (97.00%) (37408/38528)
Epoch: 193 | Batch_idx: 310 |  Loss: (0.0863) |  Loss2: (0.0000) | Acc: (97.00%) (38647/39808)
Epoch: 193 | Batch_idx: 320 |  Loss: (0.0866) |  Loss2: (0.0000) | Acc: (97.00%) (39886/41088)
Epoch: 193 | Batch_idx: 330 |  Loss: (0.0868) |  Loss2: (0.0000) | Acc: (97.00%) (41123/42368)
Epoch: 193 | Batch_idx: 340 |  Loss: (0.0868) |  Loss2: (0.0000) | Acc: (97.00%) (42360/43648)
Epoch: 193 | Batch_idx: 350 |  Loss: (0.0870) |  Loss2: (0.0000) | Acc: (97.00%) (43607/44928)
Epoch: 193 | Batch_idx: 360 |  Loss: (0.0877) |  Loss2: (0.0000) | Acc: (97.00%) (44839/46208)
Epoch: 193 | Batch_idx: 370 |  Loss: (0.0877) |  Loss2: (0.0000) | Acc: (97.00%) (46082/47488)
Epoch: 193 | Batch_idx: 380 |  Loss: (0.0874) |  Loss2: (0.0000) | Acc: (97.00%) (47330/48768)
Epoch: 193 | Batch_idx: 390 |  Loss: (0.0874) |  Loss2: (0.0000) | Acc: (97.00%) (48519/50000)
# TEST : Loss: (0.4020) | Acc: (88.00%) (8871/10000)
percent tensor([0.5155, 0.5195, 0.5336, 0.5187, 0.5327, 0.5157, 0.5238, 0.5234, 0.5196,
        0.5233, 0.5195, 0.5312, 0.5161, 0.5131, 0.5190, 0.5146],
       device='cuda:0') torch.Size([16])
percent tensor([0.4885, 0.4590, 0.4893, 0.4985, 0.4852, 0.5139, 0.4639, 0.4765, 0.4951,
        0.4667, 0.4877, 0.4782, 0.4696, 0.4837, 0.4761, 0.4890],
       device='cuda:0') torch.Size([16])
percent tensor([0.6481, 0.6566, 0.5807, 0.5612, 0.5837, 0.6057, 0.6600, 0.5977, 0.5897,
        0.6198, 0.6177, 0.5912, 0.6822, 0.5846, 0.6597, 0.6390],
       device='cuda:0') torch.Size([16])
percent tensor([0.6219, 0.6425, 0.6087, 0.6653, 0.6450, 0.7171, 0.6380, 0.5956, 0.6673,
        0.6312, 0.6673, 0.6628, 0.6303, 0.6783, 0.6819, 0.6495],
       device='cuda:0') torch.Size([16])
percent tensor([0.5998, 0.6290, 0.5931, 0.5867, 0.6292, 0.6116, 0.6331, 0.5305, 0.6595,
        0.6516, 0.6643, 0.5554, 0.6003, 0.7483, 0.4832, 0.6472],
       device='cuda:0') torch.Size([16])
percent tensor([0.6509, 0.6021, 0.7563, 0.7633, 0.7948, 0.7710, 0.6812, 0.7389, 0.6722,
        0.6510, 0.6403, 0.7056, 0.6180, 0.6470, 0.6923, 0.6920],
       device='cuda:0') torch.Size([16])
percent tensor([0.5148, 0.7055, 0.7061, 0.6987, 0.6952, 0.5425, 0.5044, 0.5710, 0.6993,
        0.6265, 0.7596, 0.6564, 0.6698, 0.5995, 0.5356, 0.4136],
       device='cuda:0') torch.Size([16])
percent tensor([0.9998, 0.9998, 0.9998, 0.9999, 0.9999, 0.9997, 0.9997, 0.9996, 0.9999,
        0.9999, 1.0000, 0.9998, 0.9999, 0.9997, 0.9993, 0.9995],
       device='cuda:0') torch.Size([16])
Epoch: 194 | Batch_idx: 0 |  Loss: (0.0844) |  Loss2: (0.0000) | Acc: (97.00%) (125/128)
Epoch: 194 | Batch_idx: 10 |  Loss: (0.0841) |  Loss2: (0.0000) | Acc: (97.00%) (1372/1408)
Epoch: 194 | Batch_idx: 20 |  Loss: (0.0906) |  Loss2: (0.0000) | Acc: (97.00%) (2612/2688)
Epoch: 194 | Batch_idx: 30 |  Loss: (0.0881) |  Loss2: (0.0000) | Acc: (97.00%) (3857/3968)
Epoch: 194 | Batch_idx: 40 |  Loss: (0.0878) |  Loss2: (0.0000) | Acc: (97.00%) (5104/5248)
Epoch: 194 | Batch_idx: 50 |  Loss: (0.0881) |  Loss2: (0.0000) | Acc: (97.00%) (6345/6528)
Epoch: 194 | Batch_idx: 60 |  Loss: (0.0867) |  Loss2: (0.0000) | Acc: (97.00%) (7597/7808)
Epoch: 194 | Batch_idx: 70 |  Loss: (0.0839) |  Loss2: (0.0000) | Acc: (97.00%) (8849/9088)
Epoch: 194 | Batch_idx: 80 |  Loss: (0.0822) |  Loss2: (0.0000) | Acc: (97.00%) (10097/10368)
Epoch: 194 | Batch_idx: 90 |  Loss: (0.0806) |  Loss2: (0.0000) | Acc: (97.00%) (11349/11648)
Epoch: 194 | Batch_idx: 100 |  Loss: (0.0802) |  Loss2: (0.0000) | Acc: (97.00%) (12596/12928)
Epoch: 194 | Batch_idx: 110 |  Loss: (0.0790) |  Loss2: (0.0000) | Acc: (97.00%) (13847/14208)
Epoch: 194 | Batch_idx: 120 |  Loss: (0.0794) |  Loss2: (0.0000) | Acc: (97.00%) (15092/15488)
Epoch: 194 | Batch_idx: 130 |  Loss: (0.0792) |  Loss2: (0.0000) | Acc: (97.00%) (16340/16768)
Epoch: 194 | Batch_idx: 140 |  Loss: (0.0800) |  Loss2: (0.0000) | Acc: (97.00%) (17583/18048)
Epoch: 194 | Batch_idx: 150 |  Loss: (0.0795) |  Loss2: (0.0000) | Acc: (97.00%) (18834/19328)
Epoch: 194 | Batch_idx: 160 |  Loss: (0.0799) |  Loss2: (0.0000) | Acc: (97.00%) (20077/20608)
Epoch: 194 | Batch_idx: 170 |  Loss: (0.0793) |  Loss2: (0.0000) | Acc: (97.00%) (21326/21888)
Epoch: 194 | Batch_idx: 180 |  Loss: (0.0797) |  Loss2: (0.0000) | Acc: (97.00%) (22569/23168)
Epoch: 194 | Batch_idx: 190 |  Loss: (0.0796) |  Loss2: (0.0000) | Acc: (97.00%) (23821/24448)
Epoch: 194 | Batch_idx: 200 |  Loss: (0.0801) |  Loss2: (0.0000) | Acc: (97.00%) (25061/25728)
Epoch: 194 | Batch_idx: 210 |  Loss: (0.0800) |  Loss2: (0.0000) | Acc: (97.00%) (26309/27008)
Epoch: 194 | Batch_idx: 220 |  Loss: (0.0796) |  Loss2: (0.0000) | Acc: (97.00%) (27556/28288)
Epoch: 194 | Batch_idx: 230 |  Loss: (0.0795) |  Loss2: (0.0000) | Acc: (97.00%) (28800/29568)
Epoch: 194 | Batch_idx: 240 |  Loss: (0.0795) |  Loss2: (0.0000) | Acc: (97.00%) (30052/30848)
Epoch: 194 | Batch_idx: 250 |  Loss: (0.0792) |  Loss2: (0.0000) | Acc: (97.00%) (31298/32128)
Epoch: 194 | Batch_idx: 260 |  Loss: (0.0799) |  Loss2: (0.0000) | Acc: (97.00%) (32532/33408)
Epoch: 194 | Batch_idx: 270 |  Loss: (0.0799) |  Loss2: (0.0000) | Acc: (97.00%) (33779/34688)
Epoch: 194 | Batch_idx: 280 |  Loss: (0.0810) |  Loss2: (0.0000) | Acc: (97.00%) (35010/35968)
Epoch: 194 | Batch_idx: 290 |  Loss: (0.0809) |  Loss2: (0.0000) | Acc: (97.00%) (36253/37248)
Epoch: 194 | Batch_idx: 300 |  Loss: (0.0811) |  Loss2: (0.0000) | Acc: (97.00%) (37496/38528)
Epoch: 194 | Batch_idx: 310 |  Loss: (0.0811) |  Loss2: (0.0000) | Acc: (97.00%) (38743/39808)
Epoch: 194 | Batch_idx: 320 |  Loss: (0.0818) |  Loss2: (0.0000) | Acc: (97.00%) (39974/41088)
Epoch: 194 | Batch_idx: 330 |  Loss: (0.0825) |  Loss2: (0.0000) | Acc: (97.00%) (41215/42368)
Epoch: 194 | Batch_idx: 340 |  Loss: (0.0833) |  Loss2: (0.0000) | Acc: (97.00%) (42440/43648)
Epoch: 194 | Batch_idx: 350 |  Loss: (0.0838) |  Loss2: (0.0000) | Acc: (97.00%) (43667/44928)
Epoch: 194 | Batch_idx: 360 |  Loss: (0.0848) |  Loss2: (0.0000) | Acc: (97.00%) (44890/46208)
Epoch: 194 | Batch_idx: 370 |  Loss: (0.0848) |  Loss2: (0.0000) | Acc: (97.00%) (46134/47488)
Epoch: 194 | Batch_idx: 380 |  Loss: (0.0850) |  Loss2: (0.0000) | Acc: (97.00%) (47377/48768)
Epoch: 194 | Batch_idx: 390 |  Loss: (0.0852) |  Loss2: (0.0000) | Acc: (97.00%) (48572/50000)
# TEST : Loss: (0.4146) | Acc: (88.00%) (8861/10000)
percent tensor([0.5154, 0.5196, 0.5323, 0.5188, 0.5316, 0.5153, 0.5233, 0.5230, 0.5195,
        0.5232, 0.5195, 0.5300, 0.5160, 0.5135, 0.5190, 0.5146],
       device='cuda:0') torch.Size([16])
percent tensor([0.4899, 0.4599, 0.4905, 0.4978, 0.4847, 0.5137, 0.4637, 0.4782, 0.4951,
        0.4677, 0.4887, 0.4762, 0.4697, 0.4866, 0.4757, 0.4887],
       device='cuda:0') torch.Size([16])
percent tensor([0.6508, 0.6480, 0.5769, 0.5572, 0.5792, 0.6033, 0.6585, 0.5925, 0.5916,
        0.6173, 0.6219, 0.5911, 0.6890, 0.5690, 0.6584, 0.6356],
       device='cuda:0') torch.Size([16])
percent tensor([0.6128, 0.6425, 0.6141, 0.6625, 0.6395, 0.6993, 0.6378, 0.5964, 0.6635,
        0.6354, 0.6587, 0.6645, 0.6209, 0.6780, 0.6738, 0.6393],
       device='cuda:0') torch.Size([16])
percent tensor([0.6304, 0.6269, 0.6144, 0.5930, 0.6495, 0.6437, 0.6447, 0.5600, 0.6903,
        0.6467, 0.6818, 0.5362, 0.6128, 0.7402, 0.5076, 0.6582],
       device='cuda:0') torch.Size([16])
percent tensor([0.6543, 0.6091, 0.7601, 0.7516, 0.8028, 0.7720, 0.6969, 0.7425, 0.6988,
        0.6702, 0.6588, 0.7017, 0.6268, 0.6657, 0.6872, 0.6999],
       device='cuda:0') torch.Size([16])
percent tensor([0.4829, 0.7059, 0.7130, 0.6715, 0.6867, 0.5401, 0.5029, 0.5321, 0.6816,
        0.6213, 0.7499, 0.6284, 0.6586, 0.5802, 0.5314, 0.4186],
       device='cuda:0') torch.Size([16])
percent tensor([0.9997, 0.9999, 0.9998, 0.9999, 0.9997, 0.9994, 0.9998, 0.9992, 0.9998,
        0.9999, 1.0000, 0.9999, 0.9999, 0.9996, 0.9992, 0.9995],
       device='cuda:0') torch.Size([16])
Epoch: 195 | Batch_idx: 0 |  Loss: (0.0734) |  Loss2: (0.0000) | Acc: (96.00%) (124/128)
Epoch: 195 | Batch_idx: 10 |  Loss: (0.0914) |  Loss2: (0.0000) | Acc: (96.00%) (1362/1408)
Epoch: 195 | Batch_idx: 20 |  Loss: (0.0877) |  Loss2: (0.0000) | Acc: (96.00%) (2598/2688)
Epoch: 195 | Batch_idx: 30 |  Loss: (0.0885) |  Loss2: (0.0000) | Acc: (96.00%) (3838/3968)
Epoch: 195 | Batch_idx: 40 |  Loss: (0.0885) |  Loss2: (0.0000) | Acc: (96.00%) (5077/5248)
Epoch: 195 | Batch_idx: 50 |  Loss: (0.0883) |  Loss2: (0.0000) | Acc: (96.00%) (6317/6528)
Epoch: 195 | Batch_idx: 60 |  Loss: (0.0881) |  Loss2: (0.0000) | Acc: (96.00%) (7550/7808)
Epoch: 195 | Batch_idx: 70 |  Loss: (0.0863) |  Loss2: (0.0000) | Acc: (96.00%) (8801/9088)
Epoch: 195 | Batch_idx: 80 |  Loss: (0.0858) |  Loss2: (0.0000) | Acc: (96.00%) (10050/10368)
Epoch: 195 | Batch_idx: 90 |  Loss: (0.0861) |  Loss2: (0.0000) | Acc: (96.00%) (11293/11648)
Epoch: 195 | Batch_idx: 100 |  Loss: (0.0844) |  Loss2: (0.0000) | Acc: (97.00%) (12548/12928)
Epoch: 195 | Batch_idx: 110 |  Loss: (0.0837) |  Loss2: (0.0000) | Acc: (97.00%) (13799/14208)
Epoch: 195 | Batch_idx: 120 |  Loss: (0.0832) |  Loss2: (0.0000) | Acc: (97.00%) (15044/15488)
Epoch: 195 | Batch_idx: 130 |  Loss: (0.0846) |  Loss2: (0.0000) | Acc: (97.00%) (16279/16768)
Epoch: 195 | Batch_idx: 140 |  Loss: (0.0840) |  Loss2: (0.0000) | Acc: (97.00%) (17532/18048)
Epoch: 195 | Batch_idx: 150 |  Loss: (0.0845) |  Loss2: (0.0000) | Acc: (97.00%) (18770/19328)
Epoch: 195 | Batch_idx: 160 |  Loss: (0.0831) |  Loss2: (0.0000) | Acc: (97.00%) (20024/20608)
Epoch: 195 | Batch_idx: 170 |  Loss: (0.0836) |  Loss2: (0.0000) | Acc: (97.00%) (21262/21888)
Epoch: 195 | Batch_idx: 180 |  Loss: (0.0833) |  Loss2: (0.0000) | Acc: (97.00%) (22507/23168)
Epoch: 195 | Batch_idx: 190 |  Loss: (0.0837) |  Loss2: (0.0000) | Acc: (97.00%) (23748/24448)
Epoch: 195 | Batch_idx: 200 |  Loss: (0.0838) |  Loss2: (0.0000) | Acc: (97.00%) (24987/25728)
Epoch: 195 | Batch_idx: 210 |  Loss: (0.0842) |  Loss2: (0.0000) | Acc: (97.00%) (26225/27008)
Epoch: 195 | Batch_idx: 220 |  Loss: (0.0840) |  Loss2: (0.0000) | Acc: (97.00%) (27468/28288)
Epoch: 195 | Batch_idx: 230 |  Loss: (0.0843) |  Loss2: (0.0000) | Acc: (97.00%) (28704/29568)
Epoch: 195 | Batch_idx: 240 |  Loss: (0.0840) |  Loss2: (0.0000) | Acc: (97.00%) (29954/30848)
Epoch: 195 | Batch_idx: 250 |  Loss: (0.0836) |  Loss2: (0.0000) | Acc: (97.00%) (31201/32128)
Epoch: 195 | Batch_idx: 260 |  Loss: (0.0838) |  Loss2: (0.0000) | Acc: (97.00%) (32440/33408)
Epoch: 195 | Batch_idx: 270 |  Loss: (0.0840) |  Loss2: (0.0000) | Acc: (97.00%) (33682/34688)
Epoch: 195 | Batch_idx: 280 |  Loss: (0.0836) |  Loss2: (0.0000) | Acc: (97.00%) (34937/35968)
Epoch: 195 | Batch_idx: 290 |  Loss: (0.0843) |  Loss2: (0.0000) | Acc: (97.00%) (36175/37248)
Epoch: 195 | Batch_idx: 300 |  Loss: (0.0843) |  Loss2: (0.0000) | Acc: (97.00%) (37420/38528)
Epoch: 195 | Batch_idx: 310 |  Loss: (0.0847) |  Loss2: (0.0000) | Acc: (97.00%) (38652/39808)
Epoch: 195 | Batch_idx: 320 |  Loss: (0.0848) |  Loss2: (0.0000) | Acc: (97.00%) (39888/41088)
Epoch: 195 | Batch_idx: 330 |  Loss: (0.0850) |  Loss2: (0.0000) | Acc: (97.00%) (41131/42368)
Epoch: 195 | Batch_idx: 340 |  Loss: (0.0860) |  Loss2: (0.0000) | Acc: (97.00%) (42364/43648)
Epoch: 195 | Batch_idx: 350 |  Loss: (0.0858) |  Loss2: (0.0000) | Acc: (97.00%) (43609/44928)
Epoch: 195 | Batch_idx: 360 |  Loss: (0.0857) |  Loss2: (0.0000) | Acc: (97.00%) (44856/46208)
Epoch: 195 | Batch_idx: 370 |  Loss: (0.0857) |  Loss2: (0.0000) | Acc: (97.00%) (46096/47488)
Epoch: 195 | Batch_idx: 380 |  Loss: (0.0861) |  Loss2: (0.0000) | Acc: (97.00%) (47335/48768)
Epoch: 195 | Batch_idx: 390 |  Loss: (0.0863) |  Loss2: (0.0000) | Acc: (97.00%) (48524/50000)
=> saving checkpoint 'drive/app/torch/save_Schedule/checkpoint_195.pth.tar'
# TEST : Loss: (0.4233) | Acc: (88.00%) (8825/10000)
percent tensor([0.5152, 0.5196, 0.5327, 0.5189, 0.5321, 0.5144, 0.5235, 0.5235, 0.5199,
        0.5236, 0.5198, 0.5303, 0.5161, 0.5136, 0.5185, 0.5143],
       device='cuda:0') torch.Size([16])
percent tensor([0.4896, 0.4579, 0.4903, 0.4977, 0.4861, 0.5147, 0.4635, 0.4778, 0.4947,
        0.4673, 0.4882, 0.4773, 0.4700, 0.4832, 0.4772, 0.4905],
       device='cuda:0') torch.Size([16])
percent tensor([0.6507, 0.6632, 0.5804, 0.5614, 0.5799, 0.6003, 0.6635, 0.5981, 0.5884,
        0.6263, 0.6259, 0.5930, 0.6886, 0.5849, 0.6626, 0.6416],
       device='cuda:0') torch.Size([16])
percent tensor([0.6169, 0.6377, 0.6134, 0.6678, 0.6421, 0.7137, 0.6336, 0.6011, 0.6577,
        0.6235, 0.6572, 0.6648, 0.6257, 0.6698, 0.6823, 0.6492],
       device='cuda:0') torch.Size([16])
percent tensor([0.6149, 0.6229, 0.6096, 0.5954, 0.6517, 0.6321, 0.6347, 0.5534, 0.6814,
        0.6441, 0.6715, 0.5578, 0.6038, 0.7432, 0.4957, 0.6580],
       device='cuda:0') torch.Size([16])
percent tensor([0.6499, 0.6052, 0.7636, 0.7550, 0.8034, 0.7567, 0.7012, 0.7488, 0.6946,
        0.6659, 0.6581, 0.7104, 0.6350, 0.6523, 0.6916, 0.6991],
       device='cuda:0') torch.Size([16])
percent tensor([0.4954, 0.7166, 0.7155, 0.6573, 0.6803, 0.5222, 0.5438, 0.5525, 0.7054,
        0.6490, 0.7687, 0.6563, 0.6988, 0.6014, 0.5206, 0.4200],
       device='cuda:0') torch.Size([16])
percent tensor([0.9997, 0.9999, 0.9999, 0.9999, 0.9998, 0.9996, 0.9998, 0.9998, 0.9997,
        0.9999, 1.0000, 0.9999, 0.9999, 0.9996, 0.9994, 0.9996],
       device='cuda:0') torch.Size([16])
Epoch: 196 | Batch_idx: 0 |  Loss: (0.0413) |  Loss2: (0.0000) | Acc: (100.00%) (128/128)
Epoch: 196 | Batch_idx: 10 |  Loss: (0.0859) |  Loss2: (0.0000) | Acc: (97.00%) (1373/1408)
Epoch: 196 | Batch_idx: 20 |  Loss: (0.0929) |  Loss2: (0.0000) | Acc: (97.00%) (2609/2688)
Epoch: 196 | Batch_idx: 30 |  Loss: (0.0915) |  Loss2: (0.0000) | Acc: (97.00%) (3851/3968)
Epoch: 196 | Batch_idx: 40 |  Loss: (0.0883) |  Loss2: (0.0000) | Acc: (97.00%) (5101/5248)
Epoch: 196 | Batch_idx: 50 |  Loss: (0.0865) |  Loss2: (0.0000) | Acc: (97.00%) (6344/6528)
Epoch: 196 | Batch_idx: 60 |  Loss: (0.0866) |  Loss2: (0.0000) | Acc: (97.00%) (7589/7808)
Epoch: 196 | Batch_idx: 70 |  Loss: (0.0844) |  Loss2: (0.0000) | Acc: (97.00%) (8841/9088)
Epoch: 196 | Batch_idx: 80 |  Loss: (0.0847) |  Loss2: (0.0000) | Acc: (97.00%) (10084/10368)
Epoch: 196 | Batch_idx: 90 |  Loss: (0.0851) |  Loss2: (0.0000) | Acc: (97.00%) (11325/11648)
Epoch: 196 | Batch_idx: 100 |  Loss: (0.0840) |  Loss2: (0.0000) | Acc: (97.00%) (12579/12928)
Epoch: 196 | Batch_idx: 110 |  Loss: (0.0828) |  Loss2: (0.0000) | Acc: (97.00%) (13826/14208)
Epoch: 196 | Batch_idx: 120 |  Loss: (0.0829) |  Loss2: (0.0000) | Acc: (97.00%) (15070/15488)
Epoch: 196 | Batch_idx: 130 |  Loss: (0.0821) |  Loss2: (0.0000) | Acc: (97.00%) (16321/16768)
Epoch: 196 | Batch_idx: 140 |  Loss: (0.0832) |  Loss2: (0.0000) | Acc: (97.00%) (17557/18048)
Epoch: 196 | Batch_idx: 150 |  Loss: (0.0833) |  Loss2: (0.0000) | Acc: (97.00%) (18795/19328)
Epoch: 196 | Batch_idx: 160 |  Loss: (0.0832) |  Loss2: (0.0000) | Acc: (97.00%) (20040/20608)
Epoch: 196 | Batch_idx: 170 |  Loss: (0.0829) |  Loss2: (0.0000) | Acc: (97.00%) (21282/21888)
Epoch: 196 | Batch_idx: 180 |  Loss: (0.0828) |  Loss2: (0.0000) | Acc: (97.00%) (22528/23168)
Epoch: 196 | Batch_idx: 190 |  Loss: (0.0837) |  Loss2: (0.0000) | Acc: (97.00%) (23756/24448)
Epoch: 196 | Batch_idx: 200 |  Loss: (0.0832) |  Loss2: (0.0000) | Acc: (97.00%) (25001/25728)
Epoch: 196 | Batch_idx: 210 |  Loss: (0.0834) |  Loss2: (0.0000) | Acc: (97.00%) (26237/27008)
Epoch: 196 | Batch_idx: 220 |  Loss: (0.0836) |  Loss2: (0.0000) | Acc: (97.00%) (27480/28288)
Epoch: 196 | Batch_idx: 230 |  Loss: (0.0840) |  Loss2: (0.0000) | Acc: (97.00%) (28716/29568)
Epoch: 196 | Batch_idx: 240 |  Loss: (0.0844) |  Loss2: (0.0000) | Acc: (97.00%) (29951/30848)
Epoch: 196 | Batch_idx: 250 |  Loss: (0.0851) |  Loss2: (0.0000) | Acc: (97.00%) (31179/32128)
Epoch: 196 | Batch_idx: 260 |  Loss: (0.0853) |  Loss2: (0.0000) | Acc: (97.00%) (32420/33408)
Epoch: 196 | Batch_idx: 270 |  Loss: (0.0854) |  Loss2: (0.0000) | Acc: (97.00%) (33661/34688)
Epoch: 196 | Batch_idx: 280 |  Loss: (0.0850) |  Loss2: (0.0000) | Acc: (97.00%) (34902/35968)
Epoch: 196 | Batch_idx: 290 |  Loss: (0.0849) |  Loss2: (0.0000) | Acc: (97.00%) (36148/37248)
Epoch: 196 | Batch_idx: 300 |  Loss: (0.0851) |  Loss2: (0.0000) | Acc: (97.00%) (37392/38528)
Epoch: 196 | Batch_idx: 310 |  Loss: (0.0849) |  Loss2: (0.0000) | Acc: (97.00%) (38643/39808)
Epoch: 196 | Batch_idx: 320 |  Loss: (0.0852) |  Loss2: (0.0000) | Acc: (97.00%) (39881/41088)
Epoch: 196 | Batch_idx: 330 |  Loss: (0.0851) |  Loss2: (0.0000) | Acc: (97.00%) (41127/42368)
Epoch: 196 | Batch_idx: 340 |  Loss: (0.0849) |  Loss2: (0.0000) | Acc: (97.00%) (42372/43648)
Epoch: 196 | Batch_idx: 350 |  Loss: (0.0851) |  Loss2: (0.0000) | Acc: (97.00%) (43608/44928)
Epoch: 196 | Batch_idx: 360 |  Loss: (0.0853) |  Loss2: (0.0000) | Acc: (97.00%) (44853/46208)
Epoch: 196 | Batch_idx: 370 |  Loss: (0.0848) |  Loss2: (0.0000) | Acc: (97.00%) (46103/47488)
Epoch: 196 | Batch_idx: 380 |  Loss: (0.0852) |  Loss2: (0.0000) | Acc: (97.00%) (47335/48768)
Epoch: 196 | Batch_idx: 390 |  Loss: (0.0855) |  Loss2: (0.0000) | Acc: (97.00%) (48532/50000)
# TEST : Loss: (0.4283) | Acc: (88.00%) (8861/10000)
percent tensor([0.5153, 0.5190, 0.5325, 0.5189, 0.5319, 0.5143, 0.5234, 0.5233, 0.5189,
        0.5232, 0.5186, 0.5305, 0.5158, 0.5123, 0.5183, 0.5138],
       device='cuda:0') torch.Size([16])
percent tensor([0.4914, 0.4621, 0.4887, 0.5008, 0.4854, 0.5173, 0.4657, 0.4777, 0.4945,
        0.4694, 0.4893, 0.4764, 0.4722, 0.4888, 0.4800, 0.4926],
       device='cuda:0') torch.Size([16])
percent tensor([0.6460, 0.6522, 0.5748, 0.5528, 0.5775, 0.5954, 0.6544, 0.5925, 0.5869,
        0.6149, 0.6196, 0.5862, 0.6821, 0.5732, 0.6543, 0.6346],
       device='cuda:0') torch.Size([16])
percent tensor([0.6150, 0.6388, 0.6184, 0.6747, 0.6472, 0.7094, 0.6351, 0.6013, 0.6579,
        0.6240, 0.6531, 0.6689, 0.6199, 0.6774, 0.6814, 0.6466],
       device='cuda:0') torch.Size([16])
percent tensor([0.6170, 0.6321, 0.6262, 0.6072, 0.6597, 0.6340, 0.6409, 0.5771, 0.6847,
        0.6581, 0.6659, 0.5728, 0.6073, 0.7465, 0.5098, 0.6613],
       device='cuda:0') torch.Size([16])
percent tensor([0.6554, 0.6245, 0.7605, 0.7576, 0.8052, 0.7630, 0.6999, 0.7536, 0.7015,
        0.6770, 0.6682, 0.7129, 0.6428, 0.6674, 0.6883, 0.6997],
       device='cuda:0') torch.Size([16])
percent tensor([0.5252, 0.7464, 0.6981, 0.6464, 0.6774, 0.5865, 0.5384, 0.5427, 0.7238,
        0.6582, 0.7982, 0.6522, 0.7291, 0.6115, 0.5051, 0.4177],
       device='cuda:0') torch.Size([16])
percent tensor([0.9997, 0.9999, 0.9999, 0.9999, 0.9998, 0.9997, 0.9998, 0.9995, 0.9998,
        0.9998, 1.0000, 0.9999, 0.9999, 0.9997, 0.9994, 0.9994],
       device='cuda:0') torch.Size([16])
Epoch: 197 | Batch_idx: 0 |  Loss: (0.0598) |  Loss2: (0.0000) | Acc: (97.00%) (125/128)
Epoch: 197 | Batch_idx: 10 |  Loss: (0.0830) |  Loss2: (0.0000) | Acc: (97.00%) (1370/1408)
Epoch: 197 | Batch_idx: 20 |  Loss: (0.0846) |  Loss2: (0.0000) | Acc: (97.00%) (2612/2688)
Epoch: 197 | Batch_idx: 30 |  Loss: (0.0845) |  Loss2: (0.0000) | Acc: (97.00%) (3850/3968)
Epoch: 197 | Batch_idx: 40 |  Loss: (0.0842) |  Loss2: (0.0000) | Acc: (97.00%) (5092/5248)
Epoch: 197 | Batch_idx: 50 |  Loss: (0.0842) |  Loss2: (0.0000) | Acc: (97.00%) (6335/6528)
Epoch: 197 | Batch_idx: 60 |  Loss: (0.0802) |  Loss2: (0.0000) | Acc: (97.00%) (7587/7808)
Epoch: 197 | Batch_idx: 70 |  Loss: (0.0793) |  Loss2: (0.0000) | Acc: (97.00%) (8840/9088)
Epoch: 197 | Batch_idx: 80 |  Loss: (0.0782) |  Loss2: (0.0000) | Acc: (97.00%) (10094/10368)
Epoch: 197 | Batch_idx: 90 |  Loss: (0.0770) |  Loss2: (0.0000) | Acc: (97.00%) (11349/11648)
Epoch: 197 | Batch_idx: 100 |  Loss: (0.0757) |  Loss2: (0.0000) | Acc: (97.00%) (12605/12928)
Epoch: 197 | Batch_idx: 110 |  Loss: (0.0754) |  Loss2: (0.0000) | Acc: (97.00%) (13853/14208)
Epoch: 197 | Batch_idx: 120 |  Loss: (0.0759) |  Loss2: (0.0000) | Acc: (97.00%) (15102/15488)
Epoch: 197 | Batch_idx: 130 |  Loss: (0.0771) |  Loss2: (0.0000) | Acc: (97.00%) (16351/16768)
Epoch: 197 | Batch_idx: 140 |  Loss: (0.0764) |  Loss2: (0.0000) | Acc: (97.00%) (17603/18048)
Epoch: 197 | Batch_idx: 150 |  Loss: (0.0770) |  Loss2: (0.0000) | Acc: (97.00%) (18848/19328)
Epoch: 197 | Batch_idx: 160 |  Loss: (0.0770) |  Loss2: (0.0000) | Acc: (97.00%) (20096/20608)
Epoch: 197 | Batch_idx: 170 |  Loss: (0.0770) |  Loss2: (0.0000) | Acc: (97.00%) (21346/21888)
Epoch: 197 | Batch_idx: 180 |  Loss: (0.0769) |  Loss2: (0.0000) | Acc: (97.00%) (22590/23168)
Epoch: 197 | Batch_idx: 190 |  Loss: (0.0776) |  Loss2: (0.0000) | Acc: (97.00%) (23834/24448)
Epoch: 197 | Batch_idx: 200 |  Loss: (0.0774) |  Loss2: (0.0000) | Acc: (97.00%) (25081/25728)
Epoch: 197 | Batch_idx: 210 |  Loss: (0.0780) |  Loss2: (0.0000) | Acc: (97.00%) (26318/27008)
Epoch: 197 | Batch_idx: 220 |  Loss: (0.0776) |  Loss2: (0.0000) | Acc: (97.00%) (27566/28288)
Epoch: 197 | Batch_idx: 230 |  Loss: (0.0776) |  Loss2: (0.0000) | Acc: (97.00%) (28815/29568)
Epoch: 197 | Batch_idx: 240 |  Loss: (0.0781) |  Loss2: (0.0000) | Acc: (97.00%) (30056/30848)
Epoch: 197 | Batch_idx: 250 |  Loss: (0.0781) |  Loss2: (0.0000) | Acc: (97.00%) (31300/32128)
Epoch: 197 | Batch_idx: 260 |  Loss: (0.0782) |  Loss2: (0.0000) | Acc: (97.00%) (32538/33408)
Epoch: 197 | Batch_idx: 270 |  Loss: (0.0783) |  Loss2: (0.0000) | Acc: (97.00%) (33778/34688)
Epoch: 197 | Batch_idx: 280 |  Loss: (0.0779) |  Loss2: (0.0000) | Acc: (97.00%) (35030/35968)
Epoch: 197 | Batch_idx: 290 |  Loss: (0.0783) |  Loss2: (0.0000) | Acc: (97.00%) (36272/37248)
Epoch: 197 | Batch_idx: 300 |  Loss: (0.0782) |  Loss2: (0.0000) | Acc: (97.00%) (37520/38528)
Epoch: 197 | Batch_idx: 310 |  Loss: (0.0781) |  Loss2: (0.0000) | Acc: (97.00%) (38766/39808)
Epoch: 197 | Batch_idx: 320 |  Loss: (0.0786) |  Loss2: (0.0000) | Acc: (97.00%) (40001/41088)
Epoch: 197 | Batch_idx: 330 |  Loss: (0.0783) |  Loss2: (0.0000) | Acc: (97.00%) (41248/42368)
Epoch: 197 | Batch_idx: 340 |  Loss: (0.0787) |  Loss2: (0.0000) | Acc: (97.00%) (42493/43648)
Epoch: 197 | Batch_idx: 350 |  Loss: (0.0784) |  Loss2: (0.0000) | Acc: (97.00%) (43743/44928)
Epoch: 197 | Batch_idx: 360 |  Loss: (0.0786) |  Loss2: (0.0000) | Acc: (97.00%) (44990/46208)
Epoch: 197 | Batch_idx: 370 |  Loss: (0.0789) |  Loss2: (0.0000) | Acc: (97.00%) (46228/47488)
Epoch: 197 | Batch_idx: 380 |  Loss: (0.0788) |  Loss2: (0.0000) | Acc: (97.00%) (47476/48768)
Epoch: 197 | Batch_idx: 390 |  Loss: (0.0793) |  Loss2: (0.0000) | Acc: (97.00%) (48665/50000)
# TEST : Loss: (0.4143) | Acc: (88.00%) (8836/10000)
percent tensor([0.5157, 0.5189, 0.5344, 0.5190, 0.5334, 0.5149, 0.5237, 0.5235, 0.5194,
        0.5235, 0.5188, 0.5317, 0.5162, 0.5116, 0.5182, 0.5140],
       device='cuda:0') torch.Size([16])
percent tensor([0.4920, 0.4586, 0.4889, 0.4962, 0.4839, 0.5162, 0.4635, 0.4766, 0.4945,
        0.4681, 0.4892, 0.4763, 0.4710, 0.4829, 0.4774, 0.4908],
       device='cuda:0') torch.Size([16])
percent tensor([0.6473, 0.6484, 0.5853, 0.5555, 0.5874, 0.5953, 0.6624, 0.5955, 0.5922,
        0.6176, 0.6206, 0.5961, 0.6850, 0.5757, 0.6540, 0.6339],
       device='cuda:0') torch.Size([16])
percent tensor([0.6211, 0.6390, 0.6209, 0.6704, 0.6481, 0.7173, 0.6378, 0.5998, 0.6578,
        0.6298, 0.6593, 0.6650, 0.6194, 0.6783, 0.6851, 0.6488],
       device='cuda:0') torch.Size([16])
percent tensor([0.5981, 0.6407, 0.5995, 0.5909, 0.6433, 0.6206, 0.6397, 0.5628, 0.6622,
        0.6537, 0.6649, 0.5465, 0.5964, 0.7556, 0.4965, 0.6585],
       device='cuda:0') torch.Size([16])
percent tensor([0.6439, 0.6176, 0.7579, 0.7560, 0.8026, 0.7599, 0.6899, 0.7439, 0.6953,
        0.6724, 0.6537, 0.7138, 0.6302, 0.6765, 0.6893, 0.6844],
       device='cuda:0') torch.Size([16])
percent tensor([0.5168, 0.7035, 0.6782, 0.6567, 0.6646, 0.5498, 0.5063, 0.5290, 0.6951,
        0.6448, 0.7604, 0.6598, 0.7024, 0.5678, 0.5312, 0.4096],
       device='cuda:0') torch.Size([16])
percent tensor([0.9996, 0.9998, 0.9998, 0.9999, 0.9998, 0.9996, 0.9999, 0.9996, 0.9997,
        0.9999, 1.0000, 0.9999, 0.9999, 0.9994, 0.9994, 0.9994],
       device='cuda:0') torch.Size([16])
Epoch: 198 | Batch_idx: 0 |  Loss: (0.0412) |  Loss2: (0.0000) | Acc: (99.00%) (127/128)
Epoch: 198 | Batch_idx: 10 |  Loss: (0.0722) |  Loss2: (0.0000) | Acc: (97.00%) (1374/1408)
Epoch: 198 | Batch_idx: 20 |  Loss: (0.0780) |  Loss2: (0.0000) | Acc: (97.00%) (2616/2688)
Epoch: 198 | Batch_idx: 30 |  Loss: (0.0775) |  Loss2: (0.0000) | Acc: (97.00%) (3865/3968)
Epoch: 198 | Batch_idx: 40 |  Loss: (0.0748) |  Loss2: (0.0000) | Acc: (97.00%) (5120/5248)
Epoch: 198 | Batch_idx: 50 |  Loss: (0.0737) |  Loss2: (0.0000) | Acc: (97.00%) (6371/6528)
Epoch: 198 | Batch_idx: 60 |  Loss: (0.0753) |  Loss2: (0.0000) | Acc: (97.00%) (7611/7808)
Epoch: 198 | Batch_idx: 70 |  Loss: (0.0742) |  Loss2: (0.0000) | Acc: (97.00%) (8861/9088)
Epoch: 198 | Batch_idx: 80 |  Loss: (0.0724) |  Loss2: (0.0000) | Acc: (97.00%) (10115/10368)
Epoch: 198 | Batch_idx: 90 |  Loss: (0.0718) |  Loss2: (0.0000) | Acc: (97.00%) (11360/11648)
Epoch: 198 | Batch_idx: 100 |  Loss: (0.0726) |  Loss2: (0.0000) | Acc: (97.00%) (12605/12928)
Epoch: 198 | Batch_idx: 110 |  Loss: (0.0727) |  Loss2: (0.0000) | Acc: (97.00%) (13849/14208)
Epoch: 198 | Batch_idx: 120 |  Loss: (0.0724) |  Loss2: (0.0000) | Acc: (97.00%) (15095/15488)
Epoch: 198 | Batch_idx: 130 |  Loss: (0.0720) |  Loss2: (0.0000) | Acc: (97.00%) (16349/16768)
Epoch: 198 | Batch_idx: 140 |  Loss: (0.0721) |  Loss2: (0.0000) | Acc: (97.00%) (17599/18048)
Epoch: 198 | Batch_idx: 150 |  Loss: (0.0736) |  Loss2: (0.0000) | Acc: (97.00%) (18835/19328)
Epoch: 198 | Batch_idx: 160 |  Loss: (0.0732) |  Loss2: (0.0000) | Acc: (97.00%) (20085/20608)
Epoch: 198 | Batch_idx: 170 |  Loss: (0.0730) |  Loss2: (0.0000) | Acc: (97.00%) (21332/21888)
Epoch: 198 | Batch_idx: 180 |  Loss: (0.0734) |  Loss2: (0.0000) | Acc: (97.00%) (22575/23168)
Epoch: 198 | Batch_idx: 190 |  Loss: (0.0737) |  Loss2: (0.0000) | Acc: (97.00%) (23820/24448)
Epoch: 198 | Batch_idx: 200 |  Loss: (0.0734) |  Loss2: (0.0000) | Acc: (97.00%) (25067/25728)
Epoch: 198 | Batch_idx: 210 |  Loss: (0.0733) |  Loss2: (0.0000) | Acc: (97.00%) (26317/27008)
Epoch: 198 | Batch_idx: 220 |  Loss: (0.0735) |  Loss2: (0.0000) | Acc: (97.00%) (27563/28288)
Epoch: 198 | Batch_idx: 230 |  Loss: (0.0748) |  Loss2: (0.0000) | Acc: (97.00%) (28796/29568)
Epoch: 198 | Batch_idx: 240 |  Loss: (0.0748) |  Loss2: (0.0000) | Acc: (97.00%) (30041/30848)
Epoch: 198 | Batch_idx: 250 |  Loss: (0.0743) |  Loss2: (0.0000) | Acc: (97.00%) (31291/32128)
Epoch: 198 | Batch_idx: 260 |  Loss: (0.0742) |  Loss2: (0.0000) | Acc: (97.00%) (32542/33408)
Epoch: 198 | Batch_idx: 270 |  Loss: (0.0742) |  Loss2: (0.0000) | Acc: (97.00%) (33792/34688)
Epoch: 198 | Batch_idx: 280 |  Loss: (0.0745) |  Loss2: (0.0000) | Acc: (97.00%) (35037/35968)
Epoch: 198 | Batch_idx: 290 |  Loss: (0.0745) |  Loss2: (0.0000) | Acc: (97.00%) (36280/37248)
Epoch: 198 | Batch_idx: 300 |  Loss: (0.0748) |  Loss2: (0.0000) | Acc: (97.00%) (37528/38528)
Epoch: 198 | Batch_idx: 310 |  Loss: (0.0749) |  Loss2: (0.0000) | Acc: (97.00%) (38771/39808)
Epoch: 198 | Batch_idx: 320 |  Loss: (0.0745) |  Loss2: (0.0000) | Acc: (97.00%) (40029/41088)
Epoch: 198 | Batch_idx: 330 |  Loss: (0.0748) |  Loss2: (0.0000) | Acc: (97.00%) (41272/42368)
Epoch: 198 | Batch_idx: 340 |  Loss: (0.0747) |  Loss2: (0.0000) | Acc: (97.00%) (42522/43648)
Epoch: 198 | Batch_idx: 350 |  Loss: (0.0744) |  Loss2: (0.0000) | Acc: (97.00%) (43775/44928)
Epoch: 198 | Batch_idx: 360 |  Loss: (0.0744) |  Loss2: (0.0000) | Acc: (97.00%) (45020/46208)
Epoch: 198 | Batch_idx: 370 |  Loss: (0.0745) |  Loss2: (0.0000) | Acc: (97.00%) (46266/47488)
Epoch: 198 | Batch_idx: 380 |  Loss: (0.0749) |  Loss2: (0.0000) | Acc: (97.00%) (47506/48768)
Epoch: 198 | Batch_idx: 390 |  Loss: (0.0747) |  Loss2: (0.0000) | Acc: (97.00%) (48704/50000)
# TEST : Loss: (0.4313) | Acc: (88.00%) (8818/10000)
percent tensor([0.5154, 0.5191, 0.5334, 0.5186, 0.5324, 0.5148, 0.5236, 0.5234, 0.5199,
        0.5235, 0.5197, 0.5312, 0.5164, 0.5129, 0.5184, 0.5143],
       device='cuda:0') torch.Size([16])
percent tensor([0.4923, 0.4589, 0.4902, 0.4973, 0.4842, 0.5167, 0.4647, 0.4778, 0.4943,
        0.4709, 0.4903, 0.4790, 0.4726, 0.4856, 0.4784, 0.4922],
       device='cuda:0') torch.Size([16])
percent tensor([0.6333, 0.6543, 0.5657, 0.5511, 0.5714, 0.5858, 0.6544, 0.5904, 0.5864,
        0.6060, 0.6135, 0.5793, 0.6730, 0.5833, 0.6509, 0.6238],
       device='cuda:0') torch.Size([16])
percent tensor([0.6175, 0.6348, 0.6242, 0.6742, 0.6436, 0.7071, 0.6371, 0.6033, 0.6567,
        0.6264, 0.6540, 0.6735, 0.6192, 0.6736, 0.6752, 0.6439],
       device='cuda:0') torch.Size([16])
percent tensor([0.6140, 0.6311, 0.6119, 0.5845, 0.6495, 0.6235, 0.6298, 0.5577, 0.6793,
        0.6619, 0.6720, 0.5584, 0.6133, 0.7559, 0.4906, 0.6604],
       device='cuda:0') torch.Size([16])
percent tensor([0.6350, 0.6026, 0.7502, 0.7552, 0.7960, 0.7543, 0.6821, 0.7345, 0.6801,
        0.6647, 0.6477, 0.7073, 0.6158, 0.6604, 0.6739, 0.6781],
       device='cuda:0') torch.Size([16])
percent tensor([0.5065, 0.7098, 0.6892, 0.6648, 0.6732, 0.5775, 0.5240, 0.5264, 0.7228,
        0.6277, 0.7766, 0.6504, 0.7213, 0.5628, 0.5481, 0.4163],
       device='cuda:0') torch.Size([16])
percent tensor([0.9998, 0.9999, 0.9998, 0.9999, 0.9997, 0.9997, 0.9997, 0.9994, 0.9999,
        0.9999, 1.0000, 0.9999, 0.9999, 0.9994, 0.9993, 0.9996],
       device='cuda:0') torch.Size([16])
Epoch: 199 | Batch_idx: 0 |  Loss: (0.0348) |  Loss2: (0.0000) | Acc: (100.00%) (128/128)
Epoch: 199 | Batch_idx: 10 |  Loss: (0.0735) |  Loss2: (0.0000) | Acc: (97.00%) (1379/1408)
Epoch: 199 | Batch_idx: 20 |  Loss: (0.0655) |  Loss2: (0.0000) | Acc: (98.00%) (2636/2688)
Epoch: 199 | Batch_idx: 30 |  Loss: (0.0640) |  Loss2: (0.0000) | Acc: (98.00%) (3889/3968)
Epoch: 199 | Batch_idx: 40 |  Loss: (0.0641) |  Loss2: (0.0000) | Acc: (98.00%) (5144/5248)
Epoch: 199 | Batch_idx: 50 |  Loss: (0.0669) |  Loss2: (0.0000) | Acc: (97.00%) (6391/6528)
Epoch: 199 | Batch_idx: 60 |  Loss: (0.0687) |  Loss2: (0.0000) | Acc: (97.00%) (7639/7808)
Epoch: 199 | Batch_idx: 70 |  Loss: (0.0691) |  Loss2: (0.0000) | Acc: (97.00%) (8883/9088)
Epoch: 199 | Batch_idx: 80 |  Loss: (0.0681) |  Loss2: (0.0000) | Acc: (97.00%) (10141/10368)
Epoch: 199 | Batch_idx: 90 |  Loss: (0.0672) |  Loss2: (0.0000) | Acc: (97.00%) (11394/11648)
Epoch: 199 | Batch_idx: 100 |  Loss: (0.0674) |  Loss2: (0.0000) | Acc: (97.00%) (12647/12928)
Epoch: 199 | Batch_idx: 110 |  Loss: (0.0679) |  Loss2: (0.0000) | Acc: (97.00%) (13892/14208)
Epoch: 199 | Batch_idx: 120 |  Loss: (0.0689) |  Loss2: (0.0000) | Acc: (97.00%) (15133/15488)
Epoch: 199 | Batch_idx: 130 |  Loss: (0.0684) |  Loss2: (0.0000) | Acc: (97.00%) (16389/16768)
Epoch: 199 | Batch_idx: 140 |  Loss: (0.0687) |  Loss2: (0.0000) | Acc: (97.00%) (17636/18048)
Epoch: 199 | Batch_idx: 150 |  Loss: (0.0688) |  Loss2: (0.0000) | Acc: (97.00%) (18888/19328)
Epoch: 199 | Batch_idx: 160 |  Loss: (0.0692) |  Loss2: (0.0000) | Acc: (97.00%) (20138/20608)
Epoch: 199 | Batch_idx: 170 |  Loss: (0.0697) |  Loss2: (0.0000) | Acc: (97.00%) (21385/21888)
Epoch: 199 | Batch_idx: 180 |  Loss: (0.0704) |  Loss2: (0.0000) | Acc: (97.00%) (22631/23168)
Epoch: 199 | Batch_idx: 190 |  Loss: (0.0701) |  Loss2: (0.0000) | Acc: (97.00%) (23886/24448)
Epoch: 199 | Batch_idx: 200 |  Loss: (0.0709) |  Loss2: (0.0000) | Acc: (97.00%) (25130/25728)
Epoch: 199 | Batch_idx: 210 |  Loss: (0.0707) |  Loss2: (0.0000) | Acc: (97.00%) (26389/27008)
Epoch: 199 | Batch_idx: 220 |  Loss: (0.0708) |  Loss2: (0.0000) | Acc: (97.00%) (27634/28288)
Epoch: 199 | Batch_idx: 230 |  Loss: (0.0714) |  Loss2: (0.0000) | Acc: (97.00%) (28878/29568)
Epoch: 199 | Batch_idx: 240 |  Loss: (0.0714) |  Loss2: (0.0000) | Acc: (97.00%) (30129/30848)
Epoch: 199 | Batch_idx: 250 |  Loss: (0.0715) |  Loss2: (0.0000) | Acc: (97.00%) (31377/32128)
Epoch: 199 | Batch_idx: 260 |  Loss: (0.0718) |  Loss2: (0.0000) | Acc: (97.00%) (32618/33408)
Epoch: 199 | Batch_idx: 270 |  Loss: (0.0717) |  Loss2: (0.0000) | Acc: (97.00%) (33865/34688)
Epoch: 199 | Batch_idx: 280 |  Loss: (0.0717) |  Loss2: (0.0000) | Acc: (97.00%) (35115/35968)
Epoch: 199 | Batch_idx: 290 |  Loss: (0.0720) |  Loss2: (0.0000) | Acc: (97.00%) (36360/37248)
Epoch: 199 | Batch_idx: 300 |  Loss: (0.0719) |  Loss2: (0.0000) | Acc: (97.00%) (37609/38528)
Epoch: 199 | Batch_idx: 310 |  Loss: (0.0719) |  Loss2: (0.0000) | Acc: (97.00%) (38859/39808)
Epoch: 199 | Batch_idx: 320 |  Loss: (0.0719) |  Loss2: (0.0000) | Acc: (97.00%) (40107/41088)
Epoch: 199 | Batch_idx: 330 |  Loss: (0.0718) |  Loss2: (0.0000) | Acc: (97.00%) (41360/42368)
Epoch: 199 | Batch_idx: 340 |  Loss: (0.0716) |  Loss2: (0.0000) | Acc: (97.00%) (42614/43648)
Epoch: 199 | Batch_idx: 350 |  Loss: (0.0714) |  Loss2: (0.0000) | Acc: (97.00%) (43869/44928)
Epoch: 199 | Batch_idx: 360 |  Loss: (0.0714) |  Loss2: (0.0000) | Acc: (97.00%) (45123/46208)
Epoch: 199 | Batch_idx: 370 |  Loss: (0.0715) |  Loss2: (0.0000) | Acc: (97.00%) (46369/47488)
Epoch: 199 | Batch_idx: 380 |  Loss: (0.0719) |  Loss2: (0.0000) | Acc: (97.00%) (47609/48768)
Epoch: 199 | Batch_idx: 390 |  Loss: (0.0720) |  Loss2: (0.0000) | Acc: (97.00%) (48808/50000)
# TEST : Loss: (0.4296) | Acc: (88.00%) (8844/10000)
percent tensor([0.5159, 0.5185, 0.5355, 0.5193, 0.5346, 0.5158, 0.5240, 0.5237, 0.5202,
        0.5238, 0.5191, 0.5332, 0.5165, 0.5109, 0.5184, 0.5141],
       device='cuda:0') torch.Size([16])
percent tensor([0.4920, 0.4596, 0.4864, 0.4985, 0.4838, 0.5152, 0.4645, 0.4770, 0.4956,
        0.4691, 0.4913, 0.4769, 0.4715, 0.4850, 0.4779, 0.4922],
       device='cuda:0') torch.Size([16])
percent tensor([0.6456, 0.6515, 0.5844, 0.5556, 0.5853, 0.5991, 0.6598, 0.5957, 0.5862,
        0.6174, 0.6181, 0.5963, 0.6813, 0.5747, 0.6560, 0.6325],
       device='cuda:0') torch.Size([16])
percent tensor([0.6207, 0.6488, 0.6128, 0.6706, 0.6407, 0.7144, 0.6398, 0.5936, 0.6597,
        0.6355, 0.6636, 0.6719, 0.6340, 0.6835, 0.6861, 0.6466],
       device='cuda:0') torch.Size([16])
percent tensor([0.6031, 0.6374, 0.5907, 0.5754, 0.6352, 0.6312, 0.6379, 0.5488, 0.6809,
        0.6513, 0.6674, 0.5377, 0.6047, 0.7579, 0.4831, 0.6552],
       device='cuda:0') torch.Size([16])
percent tensor([0.6446, 0.6173, 0.7523, 0.7504, 0.7866, 0.7609, 0.6936, 0.7403, 0.6873,
        0.6630, 0.6467, 0.7157, 0.6314, 0.6689, 0.6948, 0.6913],
       device='cuda:0') torch.Size([16])
percent tensor([0.5335, 0.7184, 0.7430, 0.6747, 0.6782, 0.5561, 0.5414, 0.5691, 0.7105,
        0.6433, 0.7610, 0.6817, 0.7161, 0.5771, 0.5578, 0.4210],
       device='cuda:0') torch.Size([16])
percent tensor([0.9998, 0.9999, 0.9999, 0.9999, 0.9999, 0.9998, 0.9998, 0.9996, 0.9999,
        0.9999, 1.0000, 0.9999, 1.0000, 0.9994, 0.9992, 0.9993],
       device='cuda:0') torch.Size([16])
False Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=128, out_features=16, bias=False)
True Linear(in_features=16, out_features=2, bias=False)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=128, out_features=16, bias=False)
True Linear(in_features=16, out_features=2, bias=False)
False Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=256, out_features=32, bias=False)
True Linear(in_features=32, out_features=2, bias=False)
False Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=256, out_features=32, bias=False)
True Linear(in_features=32, out_features=2, bias=False)
False Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=512, out_features=64, bias=False)
True Linear(in_features=64, out_features=2, bias=False)
False Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=512, out_features=64, bias=False)
True Linear(in_features=64, out_features=2, bias=False)
False Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1024, out_features=128, bias=False)
True Linear(in_features=128, out_features=2, bias=False)
False Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1024, out_features=128, bias=False)
True Linear(in_features=128, out_features=2, bias=False)
False Linear(in_features=512, out_features=10, bias=True)
Epoch: 200 | Batch_idx: 0 |  Loss: (0.0559) |  Loss2: (0.0000) | Acc: (97.00%) (125/128)
Epoch: 200 | Batch_idx: 10 |  Loss: (0.0804) |  Loss2: (0.0000) | Acc: (97.00%) (1369/1408)
Epoch: 200 | Batch_idx: 20 |  Loss: (0.0755) |  Loss2: (0.0000) | Acc: (97.00%) (2623/2688)
Epoch: 200 | Batch_idx: 30 |  Loss: (0.0721) |  Loss2: (0.0000) | Acc: (97.00%) (3878/3968)
Epoch: 200 | Batch_idx: 40 |  Loss: (0.0701) |  Loss2: (0.0000) | Acc: (97.00%) (5129/5248)
Epoch: 200 | Batch_idx: 50 |  Loss: (0.0693) |  Loss2: (0.0000) | Acc: (97.00%) (6384/6528)
Epoch: 200 | Batch_idx: 60 |  Loss: (0.0693) |  Loss2: (0.0000) | Acc: (97.00%) (7638/7808)
Epoch: 200 | Batch_idx: 70 |  Loss: (0.0684) |  Loss2: (0.0000) | Acc: (97.00%) (8893/9088)
Epoch: 200 | Batch_idx: 80 |  Loss: (0.0712) |  Loss2: (0.0000) | Acc: (97.00%) (10131/10368)
Epoch: 200 | Batch_idx: 90 |  Loss: (0.0705) |  Loss2: (0.0000) | Acc: (97.00%) (11382/11648)
Epoch: 200 | Batch_idx: 100 |  Loss: (0.0715) |  Loss2: (0.0000) | Acc: (97.00%) (12625/12928)
Epoch: 200 | Batch_idx: 110 |  Loss: (0.0719) |  Loss2: (0.0000) | Acc: (97.00%) (13869/14208)
Epoch: 200 | Batch_idx: 120 |  Loss: (0.0739) |  Loss2: (0.0000) | Acc: (97.00%) (15110/15488)
Epoch: 200 | Batch_idx: 130 |  Loss: (0.0741) |  Loss2: (0.0000) | Acc: (97.00%) (16360/16768)
Epoch: 200 | Batch_idx: 140 |  Loss: (0.0744) |  Loss2: (0.0000) | Acc: (97.00%) (17607/18048)
Epoch: 200 | Batch_idx: 150 |  Loss: (0.0751) |  Loss2: (0.0000) | Acc: (97.00%) (18853/19328)
Epoch: 200 | Batch_idx: 160 |  Loss: (0.0753) |  Loss2: (0.0000) | Acc: (97.00%) (20099/20608)
Epoch: 200 | Batch_idx: 170 |  Loss: (0.0747) |  Loss2: (0.0000) | Acc: (97.00%) (21356/21888)
Epoch: 200 | Batch_idx: 180 |  Loss: (0.0750) |  Loss2: (0.0000) | Acc: (97.00%) (22602/23168)
Epoch: 200 | Batch_idx: 190 |  Loss: (0.0754) |  Loss2: (0.0000) | Acc: (97.00%) (23849/24448)
Epoch: 200 | Batch_idx: 200 |  Loss: (0.0753) |  Loss2: (0.0000) | Acc: (97.00%) (25094/25728)
Epoch: 200 | Batch_idx: 210 |  Loss: (0.0758) |  Loss2: (0.0000) | Acc: (97.00%) (26338/27008)
Epoch: 200 | Batch_idx: 220 |  Loss: (0.0764) |  Loss2: (0.0000) | Acc: (97.00%) (27581/28288)
Epoch: 200 | Batch_idx: 230 |  Loss: (0.0763) |  Loss2: (0.0000) | Acc: (97.00%) (28822/29568)
Epoch: 200 | Batch_idx: 240 |  Loss: (0.0760) |  Loss2: (0.0000) | Acc: (97.00%) (30068/30848)
Epoch: 200 | Batch_idx: 250 |  Loss: (0.0757) |  Loss2: (0.0000) | Acc: (97.00%) (31322/32128)
Epoch: 200 | Batch_idx: 260 |  Loss: (0.0755) |  Loss2: (0.0000) | Acc: (97.00%) (32570/33408)
Epoch: 200 | Batch_idx: 270 |  Loss: (0.0756) |  Loss2: (0.0000) | Acc: (97.00%) (33819/34688)
Epoch: 200 | Batch_idx: 280 |  Loss: (0.0754) |  Loss2: (0.0000) | Acc: (97.00%) (35074/35968)
Epoch: 200 | Batch_idx: 290 |  Loss: (0.0756) |  Loss2: (0.0000) | Acc: (97.00%) (36314/37248)
Epoch: 200 | Batch_idx: 300 |  Loss: (0.0753) |  Loss2: (0.0000) | Acc: (97.00%) (37567/38528)
Epoch: 200 | Batch_idx: 310 |  Loss: (0.0752) |  Loss2: (0.0000) | Acc: (97.00%) (38808/39808)
Epoch: 200 | Batch_idx: 320 |  Loss: (0.0753) |  Loss2: (0.0000) | Acc: (97.00%) (40053/41088)
Epoch: 200 | Batch_idx: 330 |  Loss: (0.0752) |  Loss2: (0.0000) | Acc: (97.00%) (41307/42368)
Epoch: 200 | Batch_idx: 340 |  Loss: (0.0748) |  Loss2: (0.0000) | Acc: (97.00%) (42562/43648)
Epoch: 200 | Batch_idx: 350 |  Loss: (0.0746) |  Loss2: (0.0000) | Acc: (97.00%) (43811/44928)
Epoch: 200 | Batch_idx: 360 |  Loss: (0.0752) |  Loss2: (0.0000) | Acc: (97.00%) (45050/46208)
Epoch: 200 | Batch_idx: 370 |  Loss: (0.0751) |  Loss2: (0.0000) | Acc: (97.00%) (46298/47488)
Epoch: 200 | Batch_idx: 380 |  Loss: (0.0754) |  Loss2: (0.0000) | Acc: (97.00%) (47543/48768)
Epoch: 200 | Batch_idx: 390 |  Loss: (0.0754) |  Loss2: (0.0000) | Acc: (97.00%) (48746/50000)
=> saving checkpoint 'drive/app/torch/save_Schedule/checkpoint_200.pth.tar'
# TEST : Loss: (0.4883) | Acc: (87.00%) (8725/10000)
percent tensor([0.5150, 0.5199, 0.5299, 0.5178, 0.5295, 0.5139, 0.5228, 0.5223, 0.5197,
        0.5228, 0.5199, 0.5284, 0.5163, 0.5142, 0.5187, 0.5145],
       device='cuda:0') torch.Size([16])
percent tensor([0.4946, 0.4626, 0.4943, 0.5035, 0.4888, 0.5165, 0.4682, 0.4821, 0.4966,
        0.4731, 0.4917, 0.4826, 0.4739, 0.4883, 0.4802, 0.4943],
       device='cuda:0') torch.Size([16])
percent tensor([0.6498, 0.6532, 0.5810, 0.5575, 0.5782, 0.5983, 0.6601, 0.5992, 0.5943,
        0.6235, 0.6251, 0.5932, 0.6871, 0.5774, 0.6613, 0.6387],
       device='cuda:0') torch.Size([16])
percent tensor([0.6240, 0.6484, 0.6277, 0.6741, 0.6501, 0.7205, 0.6420, 0.6040, 0.6647,
        0.6427, 0.6647, 0.6811, 0.6264, 0.6776, 0.6853, 0.6527],
       device='cuda:0') torch.Size([16])
percent tensor([0.6107, 0.6291, 0.5958, 0.5843, 0.6387, 0.6048, 0.6239, 0.5480, 0.6691,
        0.6484, 0.6717, 0.5260, 0.6012, 0.7360, 0.4841, 0.6576],
       device='cuda:0') torch.Size([16])
percent tensor([0.6467, 0.6108, 0.7471, 0.7483, 0.7911, 0.7643, 0.6870, 0.7401, 0.6922,
        0.6659, 0.6541, 0.7126, 0.6376, 0.6576, 0.6907, 0.6958],
       device='cuda:0') torch.Size([16])
percent tensor([0.5408, 0.7225, 0.7217, 0.6671, 0.6842, 0.5935, 0.5377, 0.5373, 0.7228,
        0.6625, 0.7885, 0.6485, 0.7255, 0.6089, 0.5653, 0.4245],
       device='cuda:0') torch.Size([16])
percent tensor([0.9998, 0.9999, 0.9999, 1.0000, 0.9998, 0.9996, 0.9998, 0.9997, 0.9999,
        0.9999, 1.0000, 0.9999, 0.9999, 0.9996, 0.9991, 0.9996],
       device='cuda:0') torch.Size([16])
Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 3, 3, 3]) tensor(193.3267, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(827.9388, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(836.1983, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([128, 64, 3, 3]) tensor(1525.3535, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([128, 64, 1, 1]) tensor(476.0501, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([128, 128, 3, 3]) tensor(2330.8293, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([256, 128, 3, 3]) tensor(4263.6509, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([256, 128, 1, 1]) tensor(1344.1936, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([256, 256, 3, 3]) tensor(6287.0942, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([512, 256, 3, 3]) tensor(11525.6523, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([512, 256, 1, 1]) tensor(3790.9807, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([512, 512, 3, 3]) tensor(15993.4268, device='cuda:0', grad_fn=<NormBackward0>)
Epoch: 201 | Batch_idx: 0 |  Loss: (0.0440) |  Loss2: (0.0000) | Acc: (99.00%) (127/128)
Epoch: 201 | Batch_idx: 10 |  Loss: (0.0679) |  Loss2: (0.0000) | Acc: (97.00%) (1377/1408)
Epoch: 201 | Batch_idx: 20 |  Loss: (0.0699) |  Loss2: (0.0000) | Acc: (97.00%) (2630/2688)
Epoch: 201 | Batch_idx: 30 |  Loss: (0.0683) |  Loss2: (0.0000) | Acc: (97.00%) (3883/3968)
Epoch: 201 | Batch_idx: 40 |  Loss: (0.0682) |  Loss2: (0.0000) | Acc: (97.00%) (5139/5248)
Epoch: 201 | Batch_idx: 50 |  Loss: (0.0693) |  Loss2: (0.0000) | Acc: (97.00%) (6391/6528)
Epoch: 201 | Batch_idx: 60 |  Loss: (0.0687) |  Loss2: (0.0000) | Acc: (97.00%) (7644/7808)
Epoch: 201 | Batch_idx: 70 |  Loss: (0.0691) |  Loss2: (0.0000) | Acc: (97.00%) (8892/9088)
Epoch: 201 | Batch_idx: 80 |  Loss: (0.0700) |  Loss2: (0.0000) | Acc: (97.00%) (10139/10368)
Epoch: 201 | Batch_idx: 90 |  Loss: (0.0696) |  Loss2: (0.0000) | Acc: (97.00%) (11392/11648)
Epoch: 201 | Batch_idx: 100 |  Loss: (0.0706) |  Loss2: (0.0000) | Acc: (97.00%) (12638/12928)
Epoch: 201 | Batch_idx: 110 |  Loss: (0.0707) |  Loss2: (0.0000) | Acc: (97.00%) (13884/14208)
Epoch: 201 | Batch_idx: 120 |  Loss: (0.0699) |  Loss2: (0.0000) | Acc: (97.00%) (15138/15488)
Epoch: 201 | Batch_idx: 130 |  Loss: (0.0701) |  Loss2: (0.0000) | Acc: (97.00%) (16395/16768)
Epoch: 201 | Batch_idx: 140 |  Loss: (0.0699) |  Loss2: (0.0000) | Acc: (97.00%) (17649/18048)
Epoch: 201 | Batch_idx: 150 |  Loss: (0.0694) |  Loss2: (0.0000) | Acc: (97.00%) (18906/19328)
Epoch: 201 | Batch_idx: 160 |  Loss: (0.0696) |  Loss2: (0.0000) | Acc: (97.00%) (20150/20608)
Epoch: 201 | Batch_idx: 170 |  Loss: (0.0698) |  Loss2: (0.0000) | Acc: (97.00%) (21402/21888)
Epoch: 201 | Batch_idx: 180 |  Loss: (0.0700) |  Loss2: (0.0000) | Acc: (97.00%) (22649/23168)
Epoch: 201 | Batch_idx: 190 |  Loss: (0.0697) |  Loss2: (0.0000) | Acc: (97.00%) (23902/24448)
Epoch: 201 | Batch_idx: 200 |  Loss: (0.0695) |  Loss2: (0.0000) | Acc: (97.00%) (25158/25728)
Epoch: 201 | Batch_idx: 210 |  Loss: (0.0702) |  Loss2: (0.0000) | Acc: (97.00%) (26398/27008)
Epoch: 201 | Batch_idx: 220 |  Loss: (0.0697) |  Loss2: (0.0000) | Acc: (97.00%) (27655/28288)
Epoch: 201 | Batch_idx: 230 |  Loss: (0.0704) |  Loss2: (0.0000) | Acc: (97.00%) (28893/29568)
Epoch: 201 | Batch_idx: 240 |  Loss: (0.0709) |  Loss2: (0.0000) | Acc: (97.00%) (30131/30848)
Epoch: 201 | Batch_idx: 250 |  Loss: (0.0715) |  Loss2: (0.0000) | Acc: (97.00%) (31373/32128)
Epoch: 201 | Batch_idx: 260 |  Loss: (0.0712) |  Loss2: (0.0000) | Acc: (97.00%) (32634/33408)
Epoch: 201 | Batch_idx: 270 |  Loss: (0.0711) |  Loss2: (0.0000) | Acc: (97.00%) (33885/34688)
Epoch: 201 | Batch_idx: 280 |  Loss: (0.0715) |  Loss2: (0.0000) | Acc: (97.00%) (35122/35968)
Epoch: 201 | Batch_idx: 290 |  Loss: (0.0713) |  Loss2: (0.0000) | Acc: (97.00%) (36372/37248)
Epoch: 201 | Batch_idx: 300 |  Loss: (0.0717) |  Loss2: (0.0000) | Acc: (97.00%) (37619/38528)
Epoch: 201 | Batch_idx: 310 |  Loss: (0.0715) |  Loss2: (0.0000) | Acc: (97.00%) (38871/39808)
Epoch: 201 | Batch_idx: 320 |  Loss: (0.0717) |  Loss2: (0.0000) | Acc: (97.00%) (40117/41088)
Epoch: 201 | Batch_idx: 330 |  Loss: (0.0719) |  Loss2: (0.0000) | Acc: (97.00%) (41363/42368)
Epoch: 201 | Batch_idx: 340 |  Loss: (0.0720) |  Loss2: (0.0000) | Acc: (97.00%) (42611/43648)
Epoch: 201 | Batch_idx: 350 |  Loss: (0.0721) |  Loss2: (0.0000) | Acc: (97.00%) (43863/44928)
Epoch: 201 | Batch_idx: 360 |  Loss: (0.0725) |  Loss2: (0.0000) | Acc: (97.00%) (45106/46208)
Epoch: 201 | Batch_idx: 370 |  Loss: (0.0723) |  Loss2: (0.0000) | Acc: (97.00%) (46357/47488)
Epoch: 201 | Batch_idx: 380 |  Loss: (0.0726) |  Loss2: (0.0000) | Acc: (97.00%) (47599/48768)
Epoch: 201 | Batch_idx: 390 |  Loss: (0.0736) |  Loss2: (0.0000) | Acc: (97.00%) (48788/50000)
# TEST : Loss: (0.4381) | Acc: (88.00%) (8868/10000)
percent tensor([0.5157, 0.5196, 0.5332, 0.5190, 0.5326, 0.5154, 0.5239, 0.5235, 0.5201,
        0.5237, 0.5199, 0.5312, 0.5167, 0.5130, 0.5191, 0.5147],
       device='cuda:0') torch.Size([16])
percent tensor([0.4949, 0.4649, 0.4926, 0.4984, 0.4879, 0.5151, 0.4700, 0.4821, 0.4998,
        0.4736, 0.4940, 0.4814, 0.4755, 0.4889, 0.4803, 0.4939],
       device='cuda:0') torch.Size([16])
percent tensor([0.6498, 0.6536, 0.5840, 0.5568, 0.5826, 0.6105, 0.6585, 0.5967, 0.5862,
        0.6210, 0.6213, 0.5928, 0.6865, 0.5810, 0.6634, 0.6398],
       device='cuda:0') torch.Size([16])
percent tensor([0.6350, 0.6490, 0.6302, 0.6829, 0.6517, 0.7284, 0.6418, 0.6124, 0.6698,
        0.6410, 0.6673, 0.6764, 0.6412, 0.6776, 0.6910, 0.6662],
       device='cuda:0') torch.Size([16])
percent tensor([0.6291, 0.6498, 0.6116, 0.6083, 0.6623, 0.6447, 0.6501, 0.5798, 0.6867,
        0.6640, 0.6726, 0.5551, 0.6257, 0.7522, 0.5266, 0.6695],
       device='cuda:0') torch.Size([16])
percent tensor([0.6548, 0.6205, 0.7725, 0.7612, 0.8070, 0.7772, 0.7057, 0.7567, 0.6935,
        0.6794, 0.6620, 0.7160, 0.6486, 0.6623, 0.6977, 0.7079],
       device='cuda:0') torch.Size([16])
percent tensor([0.4973, 0.7194, 0.7252, 0.6852, 0.6777, 0.5932, 0.5061, 0.5519, 0.6825,
        0.6664, 0.7553, 0.6552, 0.7039, 0.5773, 0.5353, 0.4131],
       device='cuda:0') torch.Size([16])
percent tensor([0.9997, 0.9999, 0.9999, 0.9999, 0.9998, 0.9998, 0.9997, 0.9994, 0.9999,
        0.9999, 1.0000, 0.9999, 0.9999, 0.9994, 0.9993, 0.9994],
       device='cuda:0') torch.Size([16])
Epoch: 202 | Batch_idx: 0 |  Loss: (0.0370) |  Loss2: (0.0000) | Acc: (97.00%) (125/128)
Epoch: 202 | Batch_idx: 10 |  Loss: (0.0626) |  Loss2: (0.0000) | Acc: (98.00%) (1384/1408)
Epoch: 202 | Batch_idx: 20 |  Loss: (0.0693) |  Loss2: (0.0000) | Acc: (97.00%) (2628/2688)
Epoch: 202 | Batch_idx: 30 |  Loss: (0.0693) |  Loss2: (0.0000) | Acc: (97.00%) (3877/3968)
Epoch: 202 | Batch_idx: 40 |  Loss: (0.0718) |  Loss2: (0.0000) | Acc: (97.00%) (5128/5248)
Epoch: 202 | Batch_idx: 50 |  Loss: (0.0746) |  Loss2: (0.0000) | Acc: (97.00%) (6368/6528)
Epoch: 202 | Batch_idx: 60 |  Loss: (0.0731) |  Loss2: (0.0000) | Acc: (97.00%) (7621/7808)
Epoch: 202 | Batch_idx: 70 |  Loss: (0.0732) |  Loss2: (0.0000) | Acc: (97.00%) (8870/9088)
Epoch: 202 | Batch_idx: 80 |  Loss: (0.0728) |  Loss2: (0.0000) | Acc: (97.00%) (10122/10368)
Epoch: 202 | Batch_idx: 90 |  Loss: (0.0718) |  Loss2: (0.0000) | Acc: (97.00%) (11376/11648)
Epoch: 202 | Batch_idx: 100 |  Loss: (0.0717) |  Loss2: (0.0000) | Acc: (97.00%) (12624/12928)
Epoch: 202 | Batch_idx: 110 |  Loss: (0.0718) |  Loss2: (0.0000) | Acc: (97.00%) (13871/14208)
Epoch: 202 | Batch_idx: 120 |  Loss: (0.0704) |  Loss2: (0.0000) | Acc: (97.00%) (15131/15488)
Epoch: 202 | Batch_idx: 130 |  Loss: (0.0702) |  Loss2: (0.0000) | Acc: (97.00%) (16381/16768)
Epoch: 202 | Batch_idx: 140 |  Loss: (0.0693) |  Loss2: (0.0000) | Acc: (97.00%) (17637/18048)
Epoch: 202 | Batch_idx: 150 |  Loss: (0.0700) |  Loss2: (0.0000) | Acc: (97.00%) (18886/19328)
Epoch: 202 | Batch_idx: 160 |  Loss: (0.0696) |  Loss2: (0.0000) | Acc: (97.00%) (20136/20608)
Epoch: 202 | Batch_idx: 170 |  Loss: (0.0696) |  Loss2: (0.0000) | Acc: (97.00%) (21388/21888)
Epoch: 202 | Batch_idx: 180 |  Loss: (0.0687) |  Loss2: (0.0000) | Acc: (97.00%) (22641/23168)
Epoch: 202 | Batch_idx: 190 |  Loss: (0.0694) |  Loss2: (0.0000) | Acc: (97.00%) (23890/24448)
Epoch: 202 | Batch_idx: 200 |  Loss: (0.0702) |  Loss2: (0.0000) | Acc: (97.00%) (25136/25728)
Epoch: 202 | Batch_idx: 210 |  Loss: (0.0707) |  Loss2: (0.0000) | Acc: (97.00%) (26377/27008)
Epoch: 202 | Batch_idx: 220 |  Loss: (0.0704) |  Loss2: (0.0000) | Acc: (97.00%) (27631/28288)
Epoch: 202 | Batch_idx: 230 |  Loss: (0.0701) |  Loss2: (0.0000) | Acc: (97.00%) (28884/29568)
Epoch: 202 | Batch_idx: 240 |  Loss: (0.0703) |  Loss2: (0.0000) | Acc: (97.00%) (30132/30848)
Epoch: 202 | Batch_idx: 250 |  Loss: (0.0705) |  Loss2: (0.0000) | Acc: (97.00%) (31377/32128)
Epoch: 202 | Batch_idx: 260 |  Loss: (0.0710) |  Loss2: (0.0000) | Acc: (97.00%) (32621/33408)
Epoch: 202 | Batch_idx: 270 |  Loss: (0.0714) |  Loss2: (0.0000) | Acc: (97.00%) (33868/34688)
Epoch: 202 | Batch_idx: 280 |  Loss: (0.0719) |  Loss2: (0.0000) | Acc: (97.00%) (35111/35968)
Epoch: 202 | Batch_idx: 290 |  Loss: (0.0722) |  Loss2: (0.0000) | Acc: (97.00%) (36360/37248)
Epoch: 202 | Batch_idx: 300 |  Loss: (0.0723) |  Loss2: (0.0000) | Acc: (97.00%) (37605/38528)
Epoch: 202 | Batch_idx: 310 |  Loss: (0.0724) |  Loss2: (0.0000) | Acc: (97.00%) (38851/39808)
Epoch: 202 | Batch_idx: 320 |  Loss: (0.0729) |  Loss2: (0.0000) | Acc: (97.00%) (40098/41088)
Epoch: 202 | Batch_idx: 330 |  Loss: (0.0729) |  Loss2: (0.0000) | Acc: (97.00%) (41344/42368)
Epoch: 202 | Batch_idx: 340 |  Loss: (0.0730) |  Loss2: (0.0000) | Acc: (97.00%) (42592/43648)
Epoch: 202 | Batch_idx: 350 |  Loss: (0.0730) |  Loss2: (0.0000) | Acc: (97.00%) (43842/44928)
Epoch: 202 | Batch_idx: 360 |  Loss: (0.0728) |  Loss2: (0.0000) | Acc: (97.00%) (45093/46208)
Epoch: 202 | Batch_idx: 370 |  Loss: (0.0726) |  Loss2: (0.0000) | Acc: (97.00%) (46347/47488)
Epoch: 202 | Batch_idx: 380 |  Loss: (0.0726) |  Loss2: (0.0000) | Acc: (97.00%) (47596/48768)
Epoch: 202 | Batch_idx: 390 |  Loss: (0.0724) |  Loss2: (0.0000) | Acc: (97.00%) (48807/50000)
# TEST : Loss: (0.4300) | Acc: (88.00%) (8862/10000)
percent tensor([0.5166, 0.5209, 0.5345, 0.5200, 0.5338, 0.5157, 0.5254, 0.5245, 0.5211,
        0.5248, 0.5208, 0.5323, 0.5174, 0.5144, 0.5197, 0.5153],
       device='cuda:0') torch.Size([16])
percent tensor([0.4985, 0.4686, 0.4964, 0.5036, 0.4930, 0.5180, 0.4737, 0.4850, 0.5009,
        0.4768, 0.4963, 0.4848, 0.4790, 0.4910, 0.4853, 0.4987],
       device='cuda:0') torch.Size([16])
percent tensor([0.6541, 0.6617, 0.5867, 0.5554, 0.5879, 0.6086, 0.6657, 0.6013, 0.6009,
        0.6240, 0.6338, 0.5934, 0.6915, 0.5886, 0.6632, 0.6423],
       device='cuda:0') torch.Size([16])
percent tensor([0.6379, 0.6694, 0.6193, 0.6874, 0.6477, 0.7269, 0.6517, 0.6106, 0.6806,
        0.6517, 0.6800, 0.6771, 0.6413, 0.7006, 0.7038, 0.6711],
       device='cuda:0') torch.Size([16])
percent tensor([0.6173, 0.6329, 0.6250, 0.5904, 0.6504, 0.6289, 0.6263, 0.5595, 0.6723,
        0.6559, 0.6715, 0.5505, 0.6111, 0.7413, 0.4978, 0.6668],
       device='cuda:0') torch.Size([16])
percent tensor([0.6671, 0.6408, 0.7703, 0.7698, 0.8049, 0.7626, 0.7175, 0.7541, 0.7100,
        0.7015, 0.6804, 0.7296, 0.6607, 0.6925, 0.7115, 0.7072],
       device='cuda:0') torch.Size([16])
percent tensor([0.5333, 0.7470, 0.7039, 0.6796, 0.6537, 0.5766, 0.5670, 0.5701, 0.7055,
        0.6921, 0.7905, 0.6522, 0.7001, 0.6549, 0.5320, 0.4037],
       device='cuda:0') torch.Size([16])
percent tensor([0.9997, 1.0000, 0.9999, 0.9999, 0.9998, 0.9998, 0.9999, 0.9996, 0.9999,
        0.9999, 1.0000, 0.9999, 0.9999, 0.9996, 0.9991, 0.9995],
       device='cuda:0') torch.Size([16])
Epoch: 203 | Batch_idx: 0 |  Loss: (0.0492) |  Loss2: (0.0000) | Acc: (99.00%) (127/128)
Epoch: 203 | Batch_idx: 10 |  Loss: (0.0610) |  Loss2: (0.0000) | Acc: (98.00%) (1380/1408)
Epoch: 203 | Batch_idx: 20 |  Loss: (0.0676) |  Loss2: (0.0000) | Acc: (97.00%) (2627/2688)
Epoch: 203 | Batch_idx: 30 |  Loss: (0.0653) |  Loss2: (0.0000) | Acc: (97.00%) (3879/3968)
Epoch: 203 | Batch_idx: 40 |  Loss: (0.0650) |  Loss2: (0.0000) | Acc: (97.00%) (5134/5248)
Epoch: 203 | Batch_idx: 50 |  Loss: (0.0626) |  Loss2: (0.0000) | Acc: (97.00%) (6396/6528)
Epoch: 203 | Batch_idx: 60 |  Loss: (0.0643) |  Loss2: (0.0000) | Acc: (97.00%) (7643/7808)
Epoch: 203 | Batch_idx: 70 |  Loss: (0.0636) |  Loss2: (0.0000) | Acc: (97.00%) (8891/9088)
Epoch: 203 | Batch_idx: 80 |  Loss: (0.0639) |  Loss2: (0.0000) | Acc: (97.00%) (10137/10368)
Epoch: 203 | Batch_idx: 90 |  Loss: (0.0625) |  Loss2: (0.0000) | Acc: (97.00%) (11398/11648)
Epoch: 203 | Batch_idx: 100 |  Loss: (0.0617) |  Loss2: (0.0000) | Acc: (97.00%) (12658/12928)
Epoch: 203 | Batch_idx: 110 |  Loss: (0.0623) |  Loss2: (0.0000) | Acc: (97.00%) (13912/14208)
Epoch: 203 | Batch_idx: 120 |  Loss: (0.0624) |  Loss2: (0.0000) | Acc: (97.00%) (15164/15488)
Epoch: 203 | Batch_idx: 130 |  Loss: (0.0623) |  Loss2: (0.0000) | Acc: (97.00%) (16420/16768)
Epoch: 203 | Batch_idx: 140 |  Loss: (0.0625) |  Loss2: (0.0000) | Acc: (97.00%) (17666/18048)
Epoch: 203 | Batch_idx: 150 |  Loss: (0.0632) |  Loss2: (0.0000) | Acc: (97.00%) (18911/19328)
Epoch: 203 | Batch_idx: 160 |  Loss: (0.0634) |  Loss2: (0.0000) | Acc: (97.00%) (20167/20608)
Epoch: 203 | Batch_idx: 170 |  Loss: (0.0627) |  Loss2: (0.0000) | Acc: (97.00%) (21430/21888)
Epoch: 203 | Batch_idx: 180 |  Loss: (0.0625) |  Loss2: (0.0000) | Acc: (97.00%) (22683/23168)
Epoch: 203 | Batch_idx: 190 |  Loss: (0.0623) |  Loss2: (0.0000) | Acc: (97.00%) (23939/24448)
Epoch: 203 | Batch_idx: 200 |  Loss: (0.0632) |  Loss2: (0.0000) | Acc: (97.00%) (25182/25728)
Epoch: 203 | Batch_idx: 210 |  Loss: (0.0640) |  Loss2: (0.0000) | Acc: (97.00%) (26427/27008)
Epoch: 203 | Batch_idx: 220 |  Loss: (0.0646) |  Loss2: (0.0000) | Acc: (97.00%) (27677/28288)
Epoch: 203 | Batch_idx: 230 |  Loss: (0.0650) |  Loss2: (0.0000) | Acc: (97.00%) (28920/29568)
Epoch: 203 | Batch_idx: 240 |  Loss: (0.0652) |  Loss2: (0.0000) | Acc: (97.00%) (30163/30848)
Epoch: 203 | Batch_idx: 250 |  Loss: (0.0664) |  Loss2: (0.0000) | Acc: (97.00%) (31400/32128)
Epoch: 203 | Batch_idx: 260 |  Loss: (0.0667) |  Loss2: (0.0000) | Acc: (97.00%) (32645/33408)
Epoch: 203 | Batch_idx: 270 |  Loss: (0.0668) |  Loss2: (0.0000) | Acc: (97.00%) (33891/34688)
Epoch: 203 | Batch_idx: 280 |  Loss: (0.0676) |  Loss2: (0.0000) | Acc: (97.00%) (35136/35968)
Epoch: 203 | Batch_idx: 290 |  Loss: (0.0672) |  Loss2: (0.0000) | Acc: (97.00%) (36392/37248)
Epoch: 203 | Batch_idx: 300 |  Loss: (0.0677) |  Loss2: (0.0000) | Acc: (97.00%) (37633/38528)
Epoch: 203 | Batch_idx: 310 |  Loss: (0.0678) |  Loss2: (0.0000) | Acc: (97.00%) (38884/39808)
Epoch: 203 | Batch_idx: 320 |  Loss: (0.0681) |  Loss2: (0.0000) | Acc: (97.00%) (40120/41088)
Epoch: 203 | Batch_idx: 330 |  Loss: (0.0684) |  Loss2: (0.0000) | Acc: (97.00%) (41364/42368)
Epoch: 203 | Batch_idx: 340 |  Loss: (0.0684) |  Loss2: (0.0000) | Acc: (97.00%) (42613/43648)
Epoch: 203 | Batch_idx: 350 |  Loss: (0.0683) |  Loss2: (0.0000) | Acc: (97.00%) (43867/44928)
Epoch: 203 | Batch_idx: 360 |  Loss: (0.0683) |  Loss2: (0.0000) | Acc: (97.00%) (45113/46208)
Epoch: 203 | Batch_idx: 370 |  Loss: (0.0685) |  Loss2: (0.0000) | Acc: (97.00%) (46356/47488)
Epoch: 203 | Batch_idx: 380 |  Loss: (0.0686) |  Loss2: (0.0000) | Acc: (97.00%) (47606/48768)
Epoch: 203 | Batch_idx: 390 |  Loss: (0.0685) |  Loss2: (0.0000) | Acc: (97.00%) (48815/50000)
# TEST : Loss: (0.4358) | Acc: (88.00%) (8837/10000)
percent tensor([0.5161, 0.5198, 0.5347, 0.5195, 0.5337, 0.5153, 0.5244, 0.5243, 0.5206,
        0.5240, 0.5201, 0.5322, 0.5168, 0.5128, 0.5192, 0.5149],
       device='cuda:0') torch.Size([16])
percent tensor([0.4997, 0.4711, 0.4949, 0.5036, 0.4910, 0.5171, 0.4752, 0.4859, 0.5025,
        0.4786, 0.4998, 0.4847, 0.4804, 0.4935, 0.4857, 0.4997],
       device='cuda:0') torch.Size([16])
percent tensor([0.6498, 0.6526, 0.5971, 0.5628, 0.5929, 0.6062, 0.6647, 0.5999, 0.5866,
        0.6218, 0.6156, 0.5996, 0.6866, 0.5775, 0.6620, 0.6363],
       device='cuda:0') torch.Size([16])
percent tensor([0.6353, 0.6556, 0.6243, 0.6824, 0.6540, 0.7235, 0.6434, 0.6061, 0.6799,
        0.6431, 0.6781, 0.6814, 0.6392, 0.6882, 0.6935, 0.6632],
       device='cuda:0') torch.Size([16])
percent tensor([0.6361, 0.6345, 0.6198, 0.6069, 0.6612, 0.6560, 0.6430, 0.5728, 0.6877,
        0.6686, 0.6810, 0.5376, 0.6250, 0.7504, 0.5158, 0.6736],
       device='cuda:0') torch.Size([16])
percent tensor([0.6678, 0.6289, 0.7802, 0.7670, 0.8103, 0.7727, 0.7051, 0.7517, 0.7090,
        0.6874, 0.6725, 0.7247, 0.6539, 0.6706, 0.6973, 0.7051],
       device='cuda:0') torch.Size([16])
percent tensor([0.5267, 0.7137, 0.7315, 0.6711, 0.6883, 0.6460, 0.5169, 0.5407, 0.6962,
        0.6233, 0.7793, 0.6769, 0.6878, 0.6152, 0.5567, 0.4163],
       device='cuda:0') torch.Size([16])
percent tensor([0.9998, 0.9999, 0.9999, 0.9999, 0.9998, 0.9998, 0.9998, 0.9994, 0.9998,
        0.9999, 1.0000, 0.9999, 0.9999, 0.9996, 0.9993, 0.9995],
       device='cuda:0') torch.Size([16])
Epoch: 204 | Batch_idx: 0 |  Loss: (0.0940) |  Loss2: (0.0000) | Acc: (96.00%) (124/128)
Epoch: 204 | Batch_idx: 10 |  Loss: (0.0746) |  Loss2: (0.0000) | Acc: (97.00%) (1370/1408)
Epoch: 204 | Batch_idx: 20 |  Loss: (0.0689) |  Loss2: (0.0000) | Acc: (97.00%) (2625/2688)
Epoch: 204 | Batch_idx: 30 |  Loss: (0.0686) |  Loss2: (0.0000) | Acc: (97.00%) (3877/3968)
Epoch: 204 | Batch_idx: 40 |  Loss: (0.0679) |  Loss2: (0.0000) | Acc: (97.00%) (5129/5248)
Epoch: 204 | Batch_idx: 50 |  Loss: (0.0676) |  Loss2: (0.0000) | Acc: (97.00%) (6379/6528)
Epoch: 204 | Batch_idx: 60 |  Loss: (0.0634) |  Loss2: (0.0000) | Acc: (97.00%) (7645/7808)
Epoch: 204 | Batch_idx: 70 |  Loss: (0.0632) |  Loss2: (0.0000) | Acc: (97.00%) (8896/9088)
Epoch: 204 | Batch_idx: 80 |  Loss: (0.0630) |  Loss2: (0.0000) | Acc: (97.00%) (10152/10368)
Epoch: 204 | Batch_idx: 90 |  Loss: (0.0634) |  Loss2: (0.0000) | Acc: (97.00%) (11407/11648)
Epoch: 204 | Batch_idx: 100 |  Loss: (0.0634) |  Loss2: (0.0000) | Acc: (97.00%) (12661/12928)
Epoch: 204 | Batch_idx: 110 |  Loss: (0.0631) |  Loss2: (0.0000) | Acc: (97.00%) (13917/14208)
Epoch: 204 | Batch_idx: 120 |  Loss: (0.0633) |  Loss2: (0.0000) | Acc: (97.00%) (15162/15488)
Epoch: 204 | Batch_idx: 130 |  Loss: (0.0627) |  Loss2: (0.0000) | Acc: (97.00%) (16416/16768)
Epoch: 204 | Batch_idx: 140 |  Loss: (0.0640) |  Loss2: (0.0000) | Acc: (97.00%) (17660/18048)
Epoch: 204 | Batch_idx: 150 |  Loss: (0.0645) |  Loss2: (0.0000) | Acc: (97.00%) (18904/19328)
Epoch: 204 | Batch_idx: 160 |  Loss: (0.0649) |  Loss2: (0.0000) | Acc: (97.00%) (20152/20608)
Epoch: 204 | Batch_idx: 170 |  Loss: (0.0654) |  Loss2: (0.0000) | Acc: (97.00%) (21394/21888)
Epoch: 204 | Batch_idx: 180 |  Loss: (0.0660) |  Loss2: (0.0000) | Acc: (97.00%) (22647/23168)
Epoch: 204 | Batch_idx: 190 |  Loss: (0.0663) |  Loss2: (0.0000) | Acc: (97.00%) (23896/24448)
Epoch: 204 | Batch_idx: 200 |  Loss: (0.0669) |  Loss2: (0.0000) | Acc: (97.00%) (25142/25728)
Epoch: 204 | Batch_idx: 210 |  Loss: (0.0679) |  Loss2: (0.0000) | Acc: (97.00%) (26381/27008)
Epoch: 204 | Batch_idx: 220 |  Loss: (0.0682) |  Loss2: (0.0000) | Acc: (97.00%) (27623/28288)
Epoch: 204 | Batch_idx: 230 |  Loss: (0.0682) |  Loss2: (0.0000) | Acc: (97.00%) (28880/29568)
Epoch: 204 | Batch_idx: 240 |  Loss: (0.0681) |  Loss2: (0.0000) | Acc: (97.00%) (30131/30848)
Epoch: 204 | Batch_idx: 250 |  Loss: (0.0682) |  Loss2: (0.0000) | Acc: (97.00%) (31380/32128)
Epoch: 204 | Batch_idx: 260 |  Loss: (0.0685) |  Loss2: (0.0000) | Acc: (97.00%) (32620/33408)
Epoch: 204 | Batch_idx: 270 |  Loss: (0.0685) |  Loss2: (0.0000) | Acc: (97.00%) (33874/34688)
Epoch: 204 | Batch_idx: 280 |  Loss: (0.0687) |  Loss2: (0.0000) | Acc: (97.00%) (35118/35968)
Epoch: 204 | Batch_idx: 290 |  Loss: (0.0687) |  Loss2: (0.0000) | Acc: (97.00%) (36369/37248)
Epoch: 204 | Batch_idx: 300 |  Loss: (0.0692) |  Loss2: (0.0000) | Acc: (97.00%) (37612/38528)
Epoch: 204 | Batch_idx: 310 |  Loss: (0.0697) |  Loss2: (0.0000) | Acc: (97.00%) (38851/39808)
Epoch: 204 | Batch_idx: 320 |  Loss: (0.0703) |  Loss2: (0.0000) | Acc: (97.00%) (40090/41088)
Epoch: 204 | Batch_idx: 330 |  Loss: (0.0703) |  Loss2: (0.0000) | Acc: (97.00%) (41337/42368)
Epoch: 204 | Batch_idx: 340 |  Loss: (0.0700) |  Loss2: (0.0000) | Acc: (97.00%) (42592/43648)
Epoch: 204 | Batch_idx: 350 |  Loss: (0.0700) |  Loss2: (0.0000) | Acc: (97.00%) (43842/44928)
Epoch: 204 | Batch_idx: 360 |  Loss: (0.0704) |  Loss2: (0.0000) | Acc: (97.00%) (45084/46208)
Epoch: 204 | Batch_idx: 370 |  Loss: (0.0707) |  Loss2: (0.0000) | Acc: (97.00%) (46333/47488)
Epoch: 204 | Batch_idx: 380 |  Loss: (0.0705) |  Loss2: (0.0000) | Acc: (97.00%) (47591/48768)
Epoch: 204 | Batch_idx: 390 |  Loss: (0.0707) |  Loss2: (0.0000) | Acc: (97.00%) (48788/50000)
# TEST : Loss: (0.4258) | Acc: (88.00%) (8850/10000)
percent tensor([0.5173, 0.5211, 0.5351, 0.5209, 0.5347, 0.5172, 0.5257, 0.5254, 0.5217,
        0.5252, 0.5211, 0.5329, 0.5181, 0.5139, 0.5208, 0.5161],
       device='cuda:0') torch.Size([16])
percent tensor([0.5024, 0.4723, 0.5011, 0.5083, 0.4967, 0.5183, 0.4782, 0.4893, 0.5052,
        0.4816, 0.5005, 0.4904, 0.4819, 0.4964, 0.4879, 0.5014],
       device='cuda:0') torch.Size([16])
percent tensor([0.6536, 0.6654, 0.5890, 0.5623, 0.5903, 0.6146, 0.6665, 0.6022, 0.5969,
        0.6255, 0.6327, 0.5947, 0.6934, 0.5877, 0.6709, 0.6460],
       device='cuda:0') torch.Size([16])
percent tensor([0.6423, 0.6684, 0.6344, 0.6942, 0.6611, 0.7246, 0.6558, 0.6210, 0.6680,
        0.6532, 0.6729, 0.6868, 0.6384, 0.6933, 0.7010, 0.6685],
       device='cuda:0') torch.Size([16])
percent tensor([0.6361, 0.6396, 0.6296, 0.6029, 0.6677, 0.6377, 0.6542, 0.5746, 0.6868,
        0.6593, 0.6786, 0.5599, 0.6201, 0.7440, 0.5108, 0.6664],
       device='cuda:0') torch.Size([16])
percent tensor([0.6790, 0.6326, 0.7750, 0.7643, 0.8105, 0.7796, 0.7109, 0.7559, 0.7037,
        0.6909, 0.6854, 0.7235, 0.6513, 0.6860, 0.7009, 0.7148],
       device='cuda:0') torch.Size([16])
percent tensor([0.5140, 0.7285, 0.7141, 0.6863, 0.6712, 0.5808, 0.5035, 0.5527, 0.6952,
        0.6566, 0.7977, 0.6759, 0.7013, 0.6269, 0.5462, 0.4147],
       device='cuda:0') torch.Size([16])
percent tensor([0.9998, 0.9999, 0.9999, 0.9999, 0.9998, 0.9996, 0.9998, 0.9995, 0.9995,
        0.9999, 1.0000, 0.9999, 0.9999, 0.9994, 0.9995, 0.9994],
       device='cuda:0') torch.Size([16])
Epoch: 205 | Batch_idx: 0 |  Loss: (0.0734) |  Loss2: (0.0000) | Acc: (98.00%) (126/128)
Epoch: 205 | Batch_idx: 10 |  Loss: (0.0620) |  Loss2: (0.0000) | Acc: (98.00%) (1381/1408)
Epoch: 205 | Batch_idx: 20 |  Loss: (0.0637) |  Loss2: (0.0000) | Acc: (97.00%) (2634/2688)
Epoch: 205 | Batch_idx: 30 |  Loss: (0.0663) |  Loss2: (0.0000) | Acc: (97.00%) (3882/3968)
Epoch: 205 | Batch_idx: 40 |  Loss: (0.0678) |  Loss2: (0.0000) | Acc: (97.00%) (5133/5248)
Epoch: 205 | Batch_idx: 50 |  Loss: (0.0682) |  Loss2: (0.0000) | Acc: (97.00%) (6375/6528)
Epoch: 205 | Batch_idx: 60 |  Loss: (0.0665) |  Loss2: (0.0000) | Acc: (97.00%) (7636/7808)
Epoch: 205 | Batch_idx: 70 |  Loss: (0.0659) |  Loss2: (0.0000) | Acc: (97.00%) (8889/9088)
Epoch: 205 | Batch_idx: 80 |  Loss: (0.0663) |  Loss2: (0.0000) | Acc: (97.00%) (10137/10368)
Epoch: 205 | Batch_idx: 90 |  Loss: (0.0664) |  Loss2: (0.0000) | Acc: (97.00%) (11387/11648)
Epoch: 205 | Batch_idx: 100 |  Loss: (0.0666) |  Loss2: (0.0000) | Acc: (97.00%) (12635/12928)
Epoch: 205 | Batch_idx: 110 |  Loss: (0.0675) |  Loss2: (0.0000) | Acc: (97.00%) (13872/14208)
Epoch: 205 | Batch_idx: 120 |  Loss: (0.0666) |  Loss2: (0.0000) | Acc: (97.00%) (15134/15488)
Epoch: 205 | Batch_idx: 130 |  Loss: (0.0663) |  Loss2: (0.0000) | Acc: (97.00%) (16390/16768)
Epoch: 205 | Batch_idx: 140 |  Loss: (0.0663) |  Loss2: (0.0000) | Acc: (97.00%) (17644/18048)
Epoch: 205 | Batch_idx: 150 |  Loss: (0.0658) |  Loss2: (0.0000) | Acc: (97.00%) (18902/19328)
Epoch: 205 | Batch_idx: 160 |  Loss: (0.0653) |  Loss2: (0.0000) | Acc: (97.00%) (20160/20608)
Epoch: 205 | Batch_idx: 170 |  Loss: (0.0653) |  Loss2: (0.0000) | Acc: (97.00%) (21412/21888)
Epoch: 205 | Batch_idx: 180 |  Loss: (0.0650) |  Loss2: (0.0000) | Acc: (97.00%) (22661/23168)
Epoch: 205 | Batch_idx: 190 |  Loss: (0.0650) |  Loss2: (0.0000) | Acc: (97.00%) (23913/24448)
Epoch: 205 | Batch_idx: 200 |  Loss: (0.0645) |  Loss2: (0.0000) | Acc: (97.00%) (25169/25728)
Epoch: 205 | Batch_idx: 210 |  Loss: (0.0644) |  Loss2: (0.0000) | Acc: (97.00%) (26427/27008)
Epoch: 205 | Batch_idx: 220 |  Loss: (0.0645) |  Loss2: (0.0000) | Acc: (97.00%) (27676/28288)
Epoch: 205 | Batch_idx: 230 |  Loss: (0.0640) |  Loss2: (0.0000) | Acc: (97.00%) (28931/29568)
Epoch: 205 | Batch_idx: 240 |  Loss: (0.0640) |  Loss2: (0.0000) | Acc: (97.00%) (30184/30848)
Epoch: 205 | Batch_idx: 250 |  Loss: (0.0642) |  Loss2: (0.0000) | Acc: (97.00%) (31434/32128)
Epoch: 205 | Batch_idx: 260 |  Loss: (0.0645) |  Loss2: (0.0000) | Acc: (97.00%) (32680/33408)
Epoch: 205 | Batch_idx: 270 |  Loss: (0.0645) |  Loss2: (0.0000) | Acc: (97.00%) (33930/34688)
Epoch: 205 | Batch_idx: 280 |  Loss: (0.0644) |  Loss2: (0.0000) | Acc: (97.00%) (35183/35968)
Epoch: 205 | Batch_idx: 290 |  Loss: (0.0646) |  Loss2: (0.0000) | Acc: (97.00%) (36431/37248)
Epoch: 205 | Batch_idx: 300 |  Loss: (0.0647) |  Loss2: (0.0000) | Acc: (97.00%) (37686/38528)
Epoch: 205 | Batch_idx: 310 |  Loss: (0.0647) |  Loss2: (0.0000) | Acc: (97.00%) (38939/39808)
Epoch: 205 | Batch_idx: 320 |  Loss: (0.0651) |  Loss2: (0.0000) | Acc: (97.00%) (40186/41088)
Epoch: 205 | Batch_idx: 330 |  Loss: (0.0652) |  Loss2: (0.0000) | Acc: (97.00%) (41441/42368)
Epoch: 205 | Batch_idx: 340 |  Loss: (0.0651) |  Loss2: (0.0000) | Acc: (97.00%) (42694/43648)
Epoch: 205 | Batch_idx: 350 |  Loss: (0.0649) |  Loss2: (0.0000) | Acc: (97.00%) (43950/44928)
Epoch: 205 | Batch_idx: 360 |  Loss: (0.0648) |  Loss2: (0.0000) | Acc: (97.00%) (45202/46208)
Epoch: 205 | Batch_idx: 370 |  Loss: (0.0650) |  Loss2: (0.0000) | Acc: (97.00%) (46454/47488)
Epoch: 205 | Batch_idx: 380 |  Loss: (0.0651) |  Loss2: (0.0000) | Acc: (97.00%) (47703/48768)
Epoch: 205 | Batch_idx: 390 |  Loss: (0.0651) |  Loss2: (0.0000) | Acc: (97.00%) (48905/50000)
=> saving checkpoint 'drive/app/torch/save_Schedule/checkpoint_205.pth.tar'
# TEST : Loss: (0.4291) | Acc: (88.00%) (8872/10000)
percent tensor([0.5182, 0.5218, 0.5370, 0.5213, 0.5361, 0.5179, 0.5269, 0.5262, 0.5230,
        0.5260, 0.5223, 0.5344, 0.5190, 0.5153, 0.5212, 0.5170],
       device='cuda:0') torch.Size([16])
percent tensor([0.5022, 0.4712, 0.5053, 0.5069, 0.4986, 0.5194, 0.4783, 0.4871, 0.5029,
        0.4819, 0.4993, 0.4926, 0.4822, 0.4927, 0.4878, 0.5009],
       device='cuda:0') torch.Size([16])
percent tensor([0.6493, 0.6632, 0.5805, 0.5573, 0.5816, 0.6025, 0.6644, 0.6020, 0.6000,
        0.6187, 0.6306, 0.5879, 0.6894, 0.5988, 0.6620, 0.6381],
       device='cuda:0') torch.Size([16])
percent tensor([0.6475, 0.6664, 0.6418, 0.7016, 0.6608, 0.7329, 0.6592, 0.6198, 0.6830,
        0.6550, 0.6815, 0.6893, 0.6418, 0.6995, 0.7044, 0.6712],
       device='cuda:0') torch.Size([16])
percent tensor([0.6141, 0.6293, 0.6155, 0.5938, 0.6559, 0.6369, 0.6392, 0.5661, 0.6615,
        0.6486, 0.6638, 0.5582, 0.5991, 0.7491, 0.5005, 0.6609],
       device='cuda:0') torch.Size([16])
percent tensor([0.6786, 0.6349, 0.7743, 0.7784, 0.8070, 0.7752, 0.7169, 0.7627, 0.7043,
        0.7027, 0.6829, 0.7364, 0.6615, 0.6892, 0.7102, 0.7140],
       device='cuda:0') torch.Size([16])
percent tensor([0.5416, 0.7315, 0.7184, 0.6765, 0.6677, 0.5861, 0.5600, 0.5680, 0.6836,
        0.6832, 0.7767, 0.6635, 0.7032, 0.6204, 0.5382, 0.4140],
       device='cuda:0') torch.Size([16])
percent tensor([0.9997, 0.9999, 0.9999, 0.9999, 0.9999, 0.9998, 0.9998, 0.9997, 0.9998,
        0.9999, 1.0000, 0.9999, 0.9999, 0.9996, 0.9992, 0.9995],
       device='cuda:0') torch.Size([16])
Epoch: 206 | Batch_idx: 0 |  Loss: (0.0627) |  Loss2: (0.0000) | Acc: (96.00%) (124/128)
Epoch: 206 | Batch_idx: 10 |  Loss: (0.0647) |  Loss2: (0.0000) | Acc: (97.00%) (1377/1408)
Epoch: 206 | Batch_idx: 20 |  Loss: (0.0576) |  Loss2: (0.0000) | Acc: (98.00%) (2635/2688)
Epoch: 206 | Batch_idx: 30 |  Loss: (0.0572) |  Loss2: (0.0000) | Acc: (98.00%) (3891/3968)
Epoch: 206 | Batch_idx: 40 |  Loss: (0.0594) |  Loss2: (0.0000) | Acc: (97.00%) (5137/5248)
Epoch: 206 | Batch_idx: 50 |  Loss: (0.0593) |  Loss2: (0.0000) | Acc: (97.00%) (6393/6528)
Epoch: 206 | Batch_idx: 60 |  Loss: (0.0598) |  Loss2: (0.0000) | Acc: (97.00%) (7646/7808)
Epoch: 206 | Batch_idx: 70 |  Loss: (0.0594) |  Loss2: (0.0000) | Acc: (97.00%) (8902/9088)
Epoch: 206 | Batch_idx: 80 |  Loss: (0.0617) |  Loss2: (0.0000) | Acc: (97.00%) (10145/10368)
Epoch: 206 | Batch_idx: 90 |  Loss: (0.0614) |  Loss2: (0.0000) | Acc: (97.00%) (11403/11648)
Epoch: 206 | Batch_idx: 100 |  Loss: (0.0623) |  Loss2: (0.0000) | Acc: (97.00%) (12653/12928)
Epoch: 206 | Batch_idx: 110 |  Loss: (0.0622) |  Loss2: (0.0000) | Acc: (97.00%) (13902/14208)
Epoch: 206 | Batch_idx: 120 |  Loss: (0.0627) |  Loss2: (0.0000) | Acc: (97.00%) (15156/15488)
Epoch: 206 | Batch_idx: 130 |  Loss: (0.0628) |  Loss2: (0.0000) | Acc: (97.00%) (16412/16768)
Epoch: 206 | Batch_idx: 140 |  Loss: (0.0624) |  Loss2: (0.0000) | Acc: (97.00%) (17663/18048)
Epoch: 206 | Batch_idx: 150 |  Loss: (0.0636) |  Loss2: (0.0000) | Acc: (97.00%) (18907/19328)
Epoch: 206 | Batch_idx: 160 |  Loss: (0.0632) |  Loss2: (0.0000) | Acc: (97.00%) (20164/20608)
Epoch: 206 | Batch_idx: 170 |  Loss: (0.0636) |  Loss2: (0.0000) | Acc: (97.00%) (21412/21888)
Epoch: 206 | Batch_idx: 180 |  Loss: (0.0638) |  Loss2: (0.0000) | Acc: (97.00%) (22661/23168)
Epoch: 206 | Batch_idx: 190 |  Loss: (0.0639) |  Loss2: (0.0000) | Acc: (97.00%) (23916/24448)
Epoch: 206 | Batch_idx: 200 |  Loss: (0.0635) |  Loss2: (0.0000) | Acc: (97.00%) (25173/25728)
Epoch: 206 | Batch_idx: 210 |  Loss: (0.0629) |  Loss2: (0.0000) | Acc: (97.00%) (26437/27008)
Epoch: 206 | Batch_idx: 220 |  Loss: (0.0626) |  Loss2: (0.0000) | Acc: (97.00%) (27693/28288)
Epoch: 206 | Batch_idx: 230 |  Loss: (0.0630) |  Loss2: (0.0000) | Acc: (97.00%) (28941/29568)
Epoch: 206 | Batch_idx: 240 |  Loss: (0.0622) |  Loss2: (0.0000) | Acc: (97.00%) (30206/30848)
Epoch: 206 | Batch_idx: 250 |  Loss: (0.0624) |  Loss2: (0.0000) | Acc: (97.00%) (31459/32128)
Epoch: 206 | Batch_idx: 260 |  Loss: (0.0622) |  Loss2: (0.0000) | Acc: (97.00%) (32713/33408)
Epoch: 206 | Batch_idx: 270 |  Loss: (0.0623) |  Loss2: (0.0000) | Acc: (97.00%) (33964/34688)
Epoch: 206 | Batch_idx: 280 |  Loss: (0.0624) |  Loss2: (0.0000) | Acc: (97.00%) (35218/35968)
Epoch: 206 | Batch_idx: 290 |  Loss: (0.0626) |  Loss2: (0.0000) | Acc: (97.00%) (36469/37248)
Epoch: 206 | Batch_idx: 300 |  Loss: (0.0628) |  Loss2: (0.0000) | Acc: (97.00%) (37721/38528)
Epoch: 206 | Batch_idx: 310 |  Loss: (0.0629) |  Loss2: (0.0000) | Acc: (97.00%) (38969/39808)
Epoch: 206 | Batch_idx: 320 |  Loss: (0.0627) |  Loss2: (0.0000) | Acc: (97.00%) (40223/41088)
Epoch: 206 | Batch_idx: 330 |  Loss: (0.0629) |  Loss2: (0.0000) | Acc: (97.00%) (41478/42368)
Epoch: 206 | Batch_idx: 340 |  Loss: (0.0627) |  Loss2: (0.0000) | Acc: (97.00%) (42742/43648)
Epoch: 206 | Batch_idx: 350 |  Loss: (0.0623) |  Loss2: (0.0000) | Acc: (97.00%) (44003/44928)
Epoch: 206 | Batch_idx: 360 |  Loss: (0.0623) |  Loss2: (0.0000) | Acc: (97.00%) (45256/46208)
Epoch: 206 | Batch_idx: 370 |  Loss: (0.0625) |  Loss2: (0.0000) | Acc: (97.00%) (46505/47488)
Epoch: 206 | Batch_idx: 380 |  Loss: (0.0623) |  Loss2: (0.0000) | Acc: (97.00%) (47762/48768)
Epoch: 206 | Batch_idx: 390 |  Loss: (0.0624) |  Loss2: (0.0000) | Acc: (97.00%) (48963/50000)
# TEST : Loss: (0.4439) | Acc: (88.00%) (8865/10000)
percent tensor([0.5179, 0.5223, 0.5351, 0.5209, 0.5349, 0.5177, 0.5267, 0.5257, 0.5227,
        0.5258, 0.5223, 0.5331, 0.5188, 0.5159, 0.5214, 0.5169],
       device='cuda:0') torch.Size([16])
percent tensor([0.5019, 0.4721, 0.4987, 0.5071, 0.4948, 0.5201, 0.4766, 0.4866, 0.5065,
        0.4804, 0.5019, 0.4872, 0.4834, 0.4972, 0.4875, 0.5028],
       device='cuda:0') torch.Size([16])
percent tensor([0.6546, 0.6669, 0.5804, 0.5588, 0.5835, 0.6080, 0.6692, 0.6012, 0.5932,
        0.6277, 0.6248, 0.5959, 0.6901, 0.5917, 0.6681, 0.6430],
       device='cuda:0') torch.Size([16])
percent tensor([0.6490, 0.6620, 0.6373, 0.7031, 0.6679, 0.7365, 0.6584, 0.6273, 0.6793,
        0.6501, 0.6796, 0.6826, 0.6427, 0.6987, 0.7071, 0.6771],
       device='cuda:0') torch.Size([16])
percent tensor([0.6168, 0.6224, 0.6124, 0.5965, 0.6498, 0.6275, 0.6216, 0.5701, 0.6775,
        0.6313, 0.6586, 0.5391, 0.6094, 0.7395, 0.4917, 0.6663],
       device='cuda:0') torch.Size([16])
percent tensor([0.6747, 0.6271, 0.7725, 0.7696, 0.8025, 0.7805, 0.7000, 0.7604, 0.7194,
        0.6922, 0.6852, 0.7290, 0.6578, 0.6910, 0.7100, 0.7120],
       device='cuda:0') torch.Size([16])
percent tensor([0.5414, 0.7513, 0.7139, 0.6975, 0.6718, 0.5910, 0.5524, 0.5683, 0.7087,
        0.6730, 0.7929, 0.6896, 0.7116, 0.6199, 0.5730, 0.4132],
       device='cuda:0') torch.Size([16])
percent tensor([0.9998, 0.9999, 0.9999, 1.0000, 0.9999, 0.9997, 0.9997, 0.9996, 0.9998,
        0.9999, 1.0000, 1.0000, 0.9999, 0.9995, 0.9991, 0.9995],
       device='cuda:0') torch.Size([16])
Epoch: 207 | Batch_idx: 0 |  Loss: (0.0968) |  Loss2: (0.0000) | Acc: (96.00%) (123/128)
Epoch: 207 | Batch_idx: 10 |  Loss: (0.0723) |  Loss2: (0.0000) | Acc: (97.00%) (1377/1408)
Epoch: 207 | Batch_idx: 20 |  Loss: (0.0659) |  Loss2: (0.0000) | Acc: (97.00%) (2632/2688)
Epoch: 207 | Batch_idx: 30 |  Loss: (0.0627) |  Loss2: (0.0000) | Acc: (98.00%) (3891/3968)
Epoch: 207 | Batch_idx: 40 |  Loss: (0.0640) |  Loss2: (0.0000) | Acc: (97.00%) (5139/5248)
Epoch: 207 | Batch_idx: 50 |  Loss: (0.0614) |  Loss2: (0.0000) | Acc: (98.00%) (6399/6528)
Epoch: 207 | Batch_idx: 60 |  Loss: (0.0619) |  Loss2: (0.0000) | Acc: (97.00%) (7649/7808)
Epoch: 207 | Batch_idx: 70 |  Loss: (0.0619) |  Loss2: (0.0000) | Acc: (97.00%) (8903/9088)
Epoch: 207 | Batch_idx: 80 |  Loss: (0.0607) |  Loss2: (0.0000) | Acc: (97.00%) (10159/10368)
Epoch: 207 | Batch_idx: 90 |  Loss: (0.0606) |  Loss2: (0.0000) | Acc: (97.00%) (11414/11648)
Epoch: 207 | Batch_idx: 100 |  Loss: (0.0612) |  Loss2: (0.0000) | Acc: (97.00%) (12667/12928)
Epoch: 207 | Batch_idx: 110 |  Loss: (0.0611) |  Loss2: (0.0000) | Acc: (97.00%) (13919/14208)
Epoch: 207 | Batch_idx: 120 |  Loss: (0.0614) |  Loss2: (0.0000) | Acc: (97.00%) (15174/15488)
Epoch: 207 | Batch_idx: 130 |  Loss: (0.0607) |  Loss2: (0.0000) | Acc: (98.00%) (16435/16768)
Epoch: 207 | Batch_idx: 140 |  Loss: (0.0597) |  Loss2: (0.0000) | Acc: (98.00%) (17695/18048)
Epoch: 207 | Batch_idx: 150 |  Loss: (0.0597) |  Loss2: (0.0000) | Acc: (98.00%) (18945/19328)
Epoch: 207 | Batch_idx: 160 |  Loss: (0.0596) |  Loss2: (0.0000) | Acc: (98.00%) (20200/20608)
Epoch: 207 | Batch_idx: 170 |  Loss: (0.0601) |  Loss2: (0.0000) | Acc: (97.00%) (21449/21888)
Epoch: 207 | Batch_idx: 180 |  Loss: (0.0600) |  Loss2: (0.0000) | Acc: (97.00%) (22702/23168)
Epoch: 207 | Batch_idx: 190 |  Loss: (0.0598) |  Loss2: (0.0000) | Acc: (98.00%) (23960/24448)
Epoch: 207 | Batch_idx: 200 |  Loss: (0.0595) |  Loss2: (0.0000) | Acc: (98.00%) (25222/25728)
Epoch: 207 | Batch_idx: 210 |  Loss: (0.0601) |  Loss2: (0.0000) | Acc: (98.00%) (26471/27008)
Epoch: 207 | Batch_idx: 220 |  Loss: (0.0603) |  Loss2: (0.0000) | Acc: (98.00%) (27724/28288)
Epoch: 207 | Batch_idx: 230 |  Loss: (0.0597) |  Loss2: (0.0000) | Acc: (98.00%) (28987/29568)
Epoch: 207 | Batch_idx: 240 |  Loss: (0.0596) |  Loss2: (0.0000) | Acc: (98.00%) (30249/30848)
Epoch: 207 | Batch_idx: 250 |  Loss: (0.0596) |  Loss2: (0.0000) | Acc: (98.00%) (31506/32128)
Epoch: 207 | Batch_idx: 260 |  Loss: (0.0598) |  Loss2: (0.0000) | Acc: (98.00%) (32758/33408)
Epoch: 207 | Batch_idx: 270 |  Loss: (0.0599) |  Loss2: (0.0000) | Acc: (98.00%) (34014/34688)
Epoch: 207 | Batch_idx: 280 |  Loss: (0.0606) |  Loss2: (0.0000) | Acc: (98.00%) (35259/35968)
Epoch: 207 | Batch_idx: 290 |  Loss: (0.0607) |  Loss2: (0.0000) | Acc: (98.00%) (36511/37248)
Epoch: 207 | Batch_idx: 300 |  Loss: (0.0606) |  Loss2: (0.0000) | Acc: (98.00%) (37766/38528)
Epoch: 207 | Batch_idx: 310 |  Loss: (0.0605) |  Loss2: (0.0000) | Acc: (98.00%) (39029/39808)
Epoch: 207 | Batch_idx: 320 |  Loss: (0.0617) |  Loss2: (0.0000) | Acc: (97.00%) (40263/41088)
Epoch: 207 | Batch_idx: 330 |  Loss: (0.0617) |  Loss2: (0.0000) | Acc: (97.00%) (41514/42368)
Epoch: 207 | Batch_idx: 340 |  Loss: (0.0615) |  Loss2: (0.0000) | Acc: (97.00%) (42770/43648)
Epoch: 207 | Batch_idx: 350 |  Loss: (0.0612) |  Loss2: (0.0000) | Acc: (98.00%) (44033/44928)
Epoch: 207 | Batch_idx: 360 |  Loss: (0.0610) |  Loss2: (0.0000) | Acc: (98.00%) (45292/46208)
Epoch: 207 | Batch_idx: 370 |  Loss: (0.0612) |  Loss2: (0.0000) | Acc: (98.00%) (46540/47488)
Epoch: 207 | Batch_idx: 380 |  Loss: (0.0611) |  Loss2: (0.0000) | Acc: (98.00%) (47802/48768)
Epoch: 207 | Batch_idx: 390 |  Loss: (0.0610) |  Loss2: (0.0000) | Acc: (98.00%) (49014/50000)
# TEST : Loss: (0.4233) | Acc: (88.00%) (8895/10000)
percent tensor([0.5192, 0.5220, 0.5361, 0.5212, 0.5355, 0.5188, 0.5269, 0.5261, 0.5236,
        0.5261, 0.5231, 0.5338, 0.5198, 0.5149, 0.5216, 0.5173],
       device='cuda:0') torch.Size([16])
percent tensor([0.5026, 0.4756, 0.4990, 0.5065, 0.4949, 0.5192, 0.4787, 0.4879, 0.5073,
        0.4825, 0.5033, 0.4877, 0.4841, 0.4996, 0.4894, 0.5032],
       device='cuda:0') torch.Size([16])
percent tensor([0.6598, 0.6610, 0.5917, 0.5586, 0.5957, 0.6144, 0.6740, 0.6046, 0.6009,
        0.6289, 0.6333, 0.6029, 0.6968, 0.5843, 0.6678, 0.6463],
       device='cuda:0') torch.Size([16])
percent tensor([0.6487, 0.6661, 0.6465, 0.7052, 0.6698, 0.7383, 0.6600, 0.6285, 0.6811,
        0.6594, 0.6775, 0.6927, 0.6428, 0.7037, 0.7065, 0.6770],
       device='cuda:0') torch.Size([16])
percent tensor([0.6251, 0.6485, 0.6228, 0.6072, 0.6539, 0.6404, 0.6480, 0.5739, 0.6843,
        0.6704, 0.6846, 0.5575, 0.6240, 0.7681, 0.5142, 0.6710],
       device='cuda:0') torch.Size([16])
percent tensor([0.6874, 0.6402, 0.7818, 0.7848, 0.8197, 0.7912, 0.7267, 0.7788, 0.7125,
        0.7082, 0.6823, 0.7369, 0.6539, 0.6997, 0.7223, 0.7295],
       device='cuda:0') torch.Size([16])
percent tensor([0.5553, 0.7456, 0.7267, 0.6945, 0.6851, 0.6126, 0.5351, 0.5653, 0.6933,
        0.6873, 0.7813, 0.6855, 0.7162, 0.6033, 0.5984, 0.4251],
       device='cuda:0') torch.Size([16])
percent tensor([0.9997, 0.9999, 0.9999, 0.9999, 0.9998, 0.9998, 0.9996, 0.9991, 0.9998,
        0.9999, 1.0000, 0.9999, 0.9999, 0.9996, 0.9993, 0.9992],
       device='cuda:0') torch.Size([16])
Epoch: 208 | Batch_idx: 0 |  Loss: (0.0722) |  Loss2: (0.0000) | Acc: (98.00%) (126/128)
Epoch: 208 | Batch_idx: 10 |  Loss: (0.0662) |  Loss2: (0.0000) | Acc: (97.00%) (1378/1408)
Epoch: 208 | Batch_idx: 20 |  Loss: (0.0619) |  Loss2: (0.0000) | Acc: (98.00%) (2637/2688)
Epoch: 208 | Batch_idx: 30 |  Loss: (0.0574) |  Loss2: (0.0000) | Acc: (98.00%) (3902/3968)
Epoch: 208 | Batch_idx: 40 |  Loss: (0.0605) |  Loss2: (0.0000) | Acc: (98.00%) (5148/5248)
Epoch: 208 | Batch_idx: 50 |  Loss: (0.0597) |  Loss2: (0.0000) | Acc: (98.00%) (6401/6528)
Epoch: 208 | Batch_idx: 60 |  Loss: (0.0602) |  Loss2: (0.0000) | Acc: (97.00%) (7650/7808)
Epoch: 208 | Batch_idx: 70 |  Loss: (0.0605) |  Loss2: (0.0000) | Acc: (97.00%) (8900/9088)
Epoch: 208 | Batch_idx: 80 |  Loss: (0.0604) |  Loss2: (0.0000) | Acc: (97.00%) (10158/10368)
Epoch: 208 | Batch_idx: 90 |  Loss: (0.0603) |  Loss2: (0.0000) | Acc: (98.00%) (11416/11648)
Epoch: 208 | Batch_idx: 100 |  Loss: (0.0601) |  Loss2: (0.0000) | Acc: (98.00%) (12670/12928)
Epoch: 208 | Batch_idx: 110 |  Loss: (0.0603) |  Loss2: (0.0000) | Acc: (98.00%) (13927/14208)
Epoch: 208 | Batch_idx: 120 |  Loss: (0.0603) |  Loss2: (0.0000) | Acc: (98.00%) (15181/15488)
Epoch: 208 | Batch_idx: 130 |  Loss: (0.0603) |  Loss2: (0.0000) | Acc: (98.00%) (16437/16768)
Epoch: 208 | Batch_idx: 140 |  Loss: (0.0598) |  Loss2: (0.0000) | Acc: (98.00%) (17701/18048)
Epoch: 208 | Batch_idx: 150 |  Loss: (0.0602) |  Loss2: (0.0000) | Acc: (98.00%) (18956/19328)
Epoch: 208 | Batch_idx: 160 |  Loss: (0.0599) |  Loss2: (0.0000) | Acc: (98.00%) (20214/20608)
Epoch: 208 | Batch_idx: 170 |  Loss: (0.0596) |  Loss2: (0.0000) | Acc: (98.00%) (21472/21888)
Epoch: 208 | Batch_idx: 180 |  Loss: (0.0594) |  Loss2: (0.0000) | Acc: (98.00%) (22733/23168)
Epoch: 208 | Batch_idx: 190 |  Loss: (0.0592) |  Loss2: (0.0000) | Acc: (98.00%) (23989/24448)
Epoch: 208 | Batch_idx: 200 |  Loss: (0.0588) |  Loss2: (0.0000) | Acc: (98.00%) (25248/25728)
Epoch: 208 | Batch_idx: 210 |  Loss: (0.0588) |  Loss2: (0.0000) | Acc: (98.00%) (26503/27008)
Epoch: 208 | Batch_idx: 220 |  Loss: (0.0593) |  Loss2: (0.0000) | Acc: (98.00%) (27755/28288)
Epoch: 208 | Batch_idx: 230 |  Loss: (0.0590) |  Loss2: (0.0000) | Acc: (98.00%) (29010/29568)
Epoch: 208 | Batch_idx: 240 |  Loss: (0.0594) |  Loss2: (0.0000) | Acc: (98.00%) (30254/30848)
Epoch: 208 | Batch_idx: 250 |  Loss: (0.0596) |  Loss2: (0.0000) | Acc: (98.00%) (31505/32128)
Epoch: 208 | Batch_idx: 260 |  Loss: (0.0602) |  Loss2: (0.0000) | Acc: (98.00%) (32751/33408)
Epoch: 208 | Batch_idx: 270 |  Loss: (0.0603) |  Loss2: (0.0000) | Acc: (98.00%) (34007/34688)
Epoch: 208 | Batch_idx: 280 |  Loss: (0.0606) |  Loss2: (0.0000) | Acc: (98.00%) (35259/35968)
Epoch: 208 | Batch_idx: 290 |  Loss: (0.0610) |  Loss2: (0.0000) | Acc: (98.00%) (36507/37248)
Epoch: 208 | Batch_idx: 300 |  Loss: (0.0609) |  Loss2: (0.0000) | Acc: (98.00%) (37763/38528)
Epoch: 208 | Batch_idx: 310 |  Loss: (0.0608) |  Loss2: (0.0000) | Acc: (98.00%) (39016/39808)
Epoch: 208 | Batch_idx: 320 |  Loss: (0.0610) |  Loss2: (0.0000) | Acc: (98.00%) (40269/41088)
Epoch: 208 | Batch_idx: 330 |  Loss: (0.0612) |  Loss2: (0.0000) | Acc: (98.00%) (41523/42368)
Epoch: 208 | Batch_idx: 340 |  Loss: (0.0615) |  Loss2: (0.0000) | Acc: (98.00%) (42776/43648)
Epoch: 208 | Batch_idx: 350 |  Loss: (0.0614) |  Loss2: (0.0000) | Acc: (98.00%) (44036/44928)
Epoch: 208 | Batch_idx: 360 |  Loss: (0.0615) |  Loss2: (0.0000) | Acc: (98.00%) (45284/46208)
Epoch: 208 | Batch_idx: 370 |  Loss: (0.0613) |  Loss2: (0.0000) | Acc: (97.00%) (46538/47488)
Epoch: 208 | Batch_idx: 380 |  Loss: (0.0614) |  Loss2: (0.0000) | Acc: (97.00%) (47788/48768)
Epoch: 208 | Batch_idx: 390 |  Loss: (0.0613) |  Loss2: (0.0000) | Acc: (97.00%) (48994/50000)
# TEST : Loss: (0.4530) | Acc: (88.00%) (8849/10000)
percent tensor([0.5201, 0.5241, 0.5363, 0.5225, 0.5364, 0.5200, 0.5284, 0.5276, 0.5247,
        0.5275, 0.5247, 0.5344, 0.5209, 0.5177, 0.5231, 0.5191],
       device='cuda:0') torch.Size([16])
percent tensor([0.5039, 0.4796, 0.4999, 0.5112, 0.4973, 0.5205, 0.4824, 0.4917, 0.5099,
        0.4853, 0.5064, 0.4919, 0.4865, 0.5045, 0.4935, 0.5050],
       device='cuda:0') torch.Size([16])
percent tensor([0.6583, 0.6573, 0.5937, 0.5575, 0.5952, 0.6138, 0.6720, 0.6005, 0.5934,
        0.6275, 0.6242, 0.6021, 0.6918, 0.5776, 0.6639, 0.6422],
       device='cuda:0') torch.Size([16])
percent tensor([0.6495, 0.6755, 0.6328, 0.6908, 0.6667, 0.7385, 0.6686, 0.6178, 0.6855,
        0.6624, 0.6880, 0.6880, 0.6543, 0.7114, 0.7090, 0.6777],
       device='cuda:0') torch.Size([16])
percent tensor([0.6202, 0.6372, 0.6188, 0.5997, 0.6509, 0.6445, 0.6361, 0.5832, 0.6994,
        0.6639, 0.6884, 0.5427, 0.6105, 0.7594, 0.5085, 0.6694],
       device='cuda:0') torch.Size([16])
percent tensor([0.6824, 0.6510, 0.7684, 0.7743, 0.8084, 0.7996, 0.7209, 0.7642, 0.7220,
        0.7085, 0.6886, 0.7334, 0.6684, 0.7110, 0.7188, 0.7250],
       device='cuda:0') torch.Size([16])
percent tensor([0.5525, 0.7577, 0.7178, 0.6885, 0.6992, 0.6279, 0.5714, 0.5745, 0.7174,
        0.7021, 0.8004, 0.6974, 0.7185, 0.6360, 0.5640, 0.4195],
       device='cuda:0') torch.Size([16])
percent tensor([0.9997, 0.9999, 0.9999, 0.9999, 0.9998, 0.9998, 0.9998, 0.9996, 0.9999,
        1.0000, 1.0000, 0.9999, 1.0000, 0.9997, 0.9993, 0.9993],
       device='cuda:0') torch.Size([16])
Epoch: 209 | Batch_idx: 0 |  Loss: (0.0559) |  Loss2: (0.0000) | Acc: (98.00%) (126/128)
Epoch: 209 | Batch_idx: 10 |  Loss: (0.0574) |  Loss2: (0.0000) | Acc: (97.00%) (1379/1408)
Epoch: 209 | Batch_idx: 20 |  Loss: (0.0588) |  Loss2: (0.0000) | Acc: (98.00%) (2636/2688)
Epoch: 209 | Batch_idx: 30 |  Loss: (0.0571) |  Loss2: (0.0000) | Acc: (97.00%) (3888/3968)
Epoch: 209 | Batch_idx: 40 |  Loss: (0.0577) |  Loss2: (0.0000) | Acc: (97.00%) (5143/5248)
Epoch: 209 | Batch_idx: 50 |  Loss: (0.0570) |  Loss2: (0.0000) | Acc: (98.00%) (6404/6528)
Epoch: 209 | Batch_idx: 60 |  Loss: (0.0553) |  Loss2: (0.0000) | Acc: (98.00%) (7666/7808)
Epoch: 209 | Batch_idx: 70 |  Loss: (0.0566) |  Loss2: (0.0000) | Acc: (98.00%) (8920/9088)
Epoch: 209 | Batch_idx: 80 |  Loss: (0.0568) |  Loss2: (0.0000) | Acc: (98.00%) (10178/10368)
Epoch: 209 | Batch_idx: 90 |  Loss: (0.0583) |  Loss2: (0.0000) | Acc: (98.00%) (11428/11648)
Epoch: 209 | Batch_idx: 100 |  Loss: (0.0575) |  Loss2: (0.0000) | Acc: (98.00%) (12684/12928)
Epoch: 209 | Batch_idx: 110 |  Loss: (0.0575) |  Loss2: (0.0000) | Acc: (98.00%) (13935/14208)
Epoch: 209 | Batch_idx: 120 |  Loss: (0.0592) |  Loss2: (0.0000) | Acc: (98.00%) (15183/15488)
Epoch: 209 | Batch_idx: 130 |  Loss: (0.0601) |  Loss2: (0.0000) | Acc: (98.00%) (16433/16768)
Epoch: 209 | Batch_idx: 140 |  Loss: (0.0596) |  Loss2: (0.0000) | Acc: (98.00%) (17689/18048)
Epoch: 209 | Batch_idx: 150 |  Loss: (0.0602) |  Loss2: (0.0000) | Acc: (97.00%) (18941/19328)
Epoch: 209 | Batch_idx: 160 |  Loss: (0.0604) |  Loss2: (0.0000) | Acc: (98.00%) (20197/20608)
Epoch: 209 | Batch_idx: 170 |  Loss: (0.0607) |  Loss2: (0.0000) | Acc: (97.00%) (21448/21888)
Epoch: 209 | Batch_idx: 180 |  Loss: (0.0605) |  Loss2: (0.0000) | Acc: (98.00%) (22705/23168)
Epoch: 209 | Batch_idx: 190 |  Loss: (0.0607) |  Loss2: (0.0000) | Acc: (97.00%) (23956/24448)
Epoch: 209 | Batch_idx: 200 |  Loss: (0.0605) |  Loss2: (0.0000) | Acc: (97.00%) (25211/25728)
Epoch: 209 | Batch_idx: 210 |  Loss: (0.0602) |  Loss2: (0.0000) | Acc: (98.00%) (26473/27008)
Epoch: 209 | Batch_idx: 220 |  Loss: (0.0601) |  Loss2: (0.0000) | Acc: (98.00%) (27726/28288)
Epoch: 209 | Batch_idx: 230 |  Loss: (0.0604) |  Loss2: (0.0000) | Acc: (98.00%) (28982/29568)
Epoch: 209 | Batch_idx: 240 |  Loss: (0.0599) |  Loss2: (0.0000) | Acc: (98.00%) (30243/30848)
Epoch: 209 | Batch_idx: 250 |  Loss: (0.0597) |  Loss2: (0.0000) | Acc: (98.00%) (31499/32128)
Epoch: 209 | Batch_idx: 260 |  Loss: (0.0597) |  Loss2: (0.0000) | Acc: (98.00%) (32749/33408)
Epoch: 209 | Batch_idx: 270 |  Loss: (0.0601) |  Loss2: (0.0000) | Acc: (98.00%) (34000/34688)
Epoch: 209 | Batch_idx: 280 |  Loss: (0.0604) |  Loss2: (0.0000) | Acc: (98.00%) (35251/35968)
Epoch: 209 | Batch_idx: 290 |  Loss: (0.0606) |  Loss2: (0.0000) | Acc: (97.00%) (36501/37248)
Epoch: 209 | Batch_idx: 300 |  Loss: (0.0608) |  Loss2: (0.0000) | Acc: (97.00%) (37753/38528)
Epoch: 209 | Batch_idx: 310 |  Loss: (0.0608) |  Loss2: (0.0000) | Acc: (98.00%) (39012/39808)
Epoch: 209 | Batch_idx: 320 |  Loss: (0.0603) |  Loss2: (0.0000) | Acc: (98.00%) (40272/41088)
Epoch: 209 | Batch_idx: 330 |  Loss: (0.0606) |  Loss2: (0.0000) | Acc: (97.00%) (41518/42368)
Epoch: 209 | Batch_idx: 340 |  Loss: (0.0604) |  Loss2: (0.0000) | Acc: (98.00%) (42776/43648)
Epoch: 209 | Batch_idx: 350 |  Loss: (0.0605) |  Loss2: (0.0000) | Acc: (98.00%) (44031/44928)
Epoch: 209 | Batch_idx: 360 |  Loss: (0.0608) |  Loss2: (0.0000) | Acc: (97.00%) (45278/46208)
Epoch: 209 | Batch_idx: 370 |  Loss: (0.0604) |  Loss2: (0.0000) | Acc: (98.00%) (46543/47488)
Epoch: 209 | Batch_idx: 380 |  Loss: (0.0601) |  Loss2: (0.0000) | Acc: (98.00%) (47804/48768)
Epoch: 209 | Batch_idx: 390 |  Loss: (0.0603) |  Loss2: (0.0000) | Acc: (98.00%) (49012/50000)
# TEST : Loss: (0.4596) | Acc: (87.00%) (8799/10000)
percent tensor([0.5213, 0.5261, 0.5369, 0.5233, 0.5377, 0.5210, 0.5302, 0.5286, 0.5267,
        0.5290, 0.5266, 0.5353, 0.5225, 0.5199, 0.5245, 0.5203],
       device='cuda:0') torch.Size([16])
percent tensor([0.5050, 0.4787, 0.5045, 0.5114, 0.4999, 0.5215, 0.4825, 0.4933, 0.5078,
        0.4854, 0.5059, 0.4937, 0.4865, 0.5012, 0.4942, 0.5039],
       device='cuda:0') torch.Size([16])
percent tensor([0.6691, 0.6674, 0.5854, 0.5652, 0.5904, 0.6252, 0.6708, 0.6028, 0.6036,
        0.6304, 0.6375, 0.5958, 0.7024, 0.5895, 0.6750, 0.6532],
       device='cuda:0') torch.Size([16])
percent tensor([0.6467, 0.6624, 0.6411, 0.6935, 0.6621, 0.7317, 0.6600, 0.6233, 0.6872,
        0.6576, 0.6813, 0.6862, 0.6488, 0.7035, 0.7003, 0.6740],
       device='cuda:0') torch.Size([16])
percent tensor([0.6304, 0.6672, 0.6262, 0.6075, 0.6633, 0.6545, 0.6577, 0.5829, 0.6920,
        0.6734, 0.7016, 0.5655, 0.6334, 0.7796, 0.5225, 0.6837],
       device='cuda:0') torch.Size([16])
percent tensor([0.6899, 0.6558, 0.7829, 0.7811, 0.8109, 0.7916, 0.7202, 0.7660, 0.7297,
        0.7148, 0.6932, 0.7376, 0.6736, 0.7186, 0.7154, 0.7235],
       device='cuda:0') torch.Size([16])
percent tensor([0.5379, 0.7329, 0.6979, 0.6688, 0.6683, 0.5780, 0.5433, 0.5489, 0.7026,
        0.6829, 0.7850, 0.6515, 0.7135, 0.6100, 0.5556, 0.4183],
       device='cuda:0') torch.Size([16])
percent tensor([0.9997, 0.9999, 0.9998, 0.9999, 0.9998, 0.9998, 0.9997, 0.9997, 0.9998,
        0.9999, 1.0000, 0.9999, 0.9999, 0.9997, 0.9996, 0.9994],
       device='cuda:0') torch.Size([16])
Epoch: 210 | Batch_idx: 0 |  Loss: (0.0505) |  Loss2: (0.0000) | Acc: (97.00%) (125/128)
Epoch: 210 | Batch_idx: 10 |  Loss: (0.0580) |  Loss2: (0.0000) | Acc: (98.00%) (1381/1408)
Epoch: 210 | Batch_idx: 20 |  Loss: (0.0596) |  Loss2: (0.0000) | Acc: (97.00%) (2633/2688)
Epoch: 210 | Batch_idx: 30 |  Loss: (0.0566) |  Loss2: (0.0000) | Acc: (98.00%) (3896/3968)
Epoch: 210 | Batch_idx: 40 |  Loss: (0.0561) |  Loss2: (0.0000) | Acc: (98.00%) (5151/5248)
Epoch: 210 | Batch_idx: 50 |  Loss: (0.0577) |  Loss2: (0.0000) | Acc: (98.00%) (6406/6528)
Epoch: 210 | Batch_idx: 60 |  Loss: (0.0591) |  Loss2: (0.0000) | Acc: (98.00%) (7663/7808)
Epoch: 210 | Batch_idx: 70 |  Loss: (0.0597) |  Loss2: (0.0000) | Acc: (98.00%) (8912/9088)
Epoch: 210 | Batch_idx: 80 |  Loss: (0.0586) |  Loss2: (0.0000) | Acc: (98.00%) (10165/10368)
Epoch: 210 | Batch_idx: 90 |  Loss: (0.0605) |  Loss2: (0.0000) | Acc: (97.00%) (11410/11648)
Epoch: 210 | Batch_idx: 100 |  Loss: (0.0603) |  Loss2: (0.0000) | Acc: (97.00%) (12660/12928)
Epoch: 210 | Batch_idx: 110 |  Loss: (0.0605) |  Loss2: (0.0000) | Acc: (97.00%) (13913/14208)
Epoch: 210 | Batch_idx: 120 |  Loss: (0.0601) |  Loss2: (0.0000) | Acc: (97.00%) (15170/15488)
Epoch: 210 | Batch_idx: 130 |  Loss: (0.0598) |  Loss2: (0.0000) | Acc: (97.00%) (16426/16768)
Epoch: 210 | Batch_idx: 140 |  Loss: (0.0596) |  Loss2: (0.0000) | Acc: (97.00%) (17677/18048)
Epoch: 210 | Batch_idx: 150 |  Loss: (0.0590) |  Loss2: (0.0000) | Acc: (97.00%) (18940/19328)
Epoch: 210 | Batch_idx: 160 |  Loss: (0.0594) |  Loss2: (0.0000) | Acc: (97.00%) (20192/20608)
Epoch: 210 | Batch_idx: 170 |  Loss: (0.0599) |  Loss2: (0.0000) | Acc: (97.00%) (21441/21888)
Epoch: 210 | Batch_idx: 180 |  Loss: (0.0600) |  Loss2: (0.0000) | Acc: (97.00%) (22698/23168)
Epoch: 210 | Batch_idx: 190 |  Loss: (0.0603) |  Loss2: (0.0000) | Acc: (97.00%) (23952/24448)
Epoch: 210 | Batch_idx: 200 |  Loss: (0.0600) |  Loss2: (0.0000) | Acc: (97.00%) (25209/25728)
Epoch: 210 | Batch_idx: 210 |  Loss: (0.0595) |  Loss2: (0.0000) | Acc: (98.00%) (26468/27008)
Epoch: 210 | Batch_idx: 220 |  Loss: (0.0598) |  Loss2: (0.0000) | Acc: (97.00%) (27721/28288)
Epoch: 210 | Batch_idx: 230 |  Loss: (0.0599) |  Loss2: (0.0000) | Acc: (97.00%) (28968/29568)
Epoch: 210 | Batch_idx: 240 |  Loss: (0.0604) |  Loss2: (0.0000) | Acc: (97.00%) (30215/30848)
Epoch: 210 | Batch_idx: 250 |  Loss: (0.0603) |  Loss2: (0.0000) | Acc: (97.00%) (31474/32128)
Epoch: 210 | Batch_idx: 260 |  Loss: (0.0599) |  Loss2: (0.0000) | Acc: (97.00%) (32734/33408)
Epoch: 210 | Batch_idx: 270 |  Loss: (0.0598) |  Loss2: (0.0000) | Acc: (97.00%) (33988/34688)
Epoch: 210 | Batch_idx: 280 |  Loss: (0.0594) |  Loss2: (0.0000) | Acc: (97.00%) (35246/35968)
Epoch: 210 | Batch_idx: 290 |  Loss: (0.0590) |  Loss2: (0.0000) | Acc: (98.00%) (36509/37248)
Epoch: 210 | Batch_idx: 300 |  Loss: (0.0591) |  Loss2: (0.0000) | Acc: (98.00%) (37761/38528)
Epoch: 210 | Batch_idx: 310 |  Loss: (0.0590) |  Loss2: (0.0000) | Acc: (98.00%) (39016/39808)
Epoch: 210 | Batch_idx: 320 |  Loss: (0.0591) |  Loss2: (0.0000) | Acc: (98.00%) (40271/41088)
Epoch: 210 | Batch_idx: 330 |  Loss: (0.0590) |  Loss2: (0.0000) | Acc: (98.00%) (41528/42368)
Epoch: 210 | Batch_idx: 340 |  Loss: (0.0593) |  Loss2: (0.0000) | Acc: (97.00%) (42774/43648)
Epoch: 210 | Batch_idx: 350 |  Loss: (0.0593) |  Loss2: (0.0000) | Acc: (97.00%) (44029/44928)
Epoch: 210 | Batch_idx: 360 |  Loss: (0.0593) |  Loss2: (0.0000) | Acc: (98.00%) (45286/46208)
Epoch: 210 | Batch_idx: 370 |  Loss: (0.0595) |  Loss2: (0.0000) | Acc: (97.00%) (46531/47488)
Epoch: 210 | Batch_idx: 380 |  Loss: (0.0598) |  Loss2: (0.0000) | Acc: (97.00%) (47778/48768)
Epoch: 210 | Batch_idx: 390 |  Loss: (0.0601) |  Loss2: (0.0000) | Acc: (97.00%) (48982/50000)
=> saving checkpoint 'drive/app/torch/save_Schedule/checkpoint_210.pth.tar'
# TEST : Loss: (0.4365) | Acc: (88.00%) (8890/10000)
percent tensor([0.5215, 0.5262, 0.5382, 0.5235, 0.5379, 0.5211, 0.5305, 0.5297, 0.5264,
        0.5297, 0.5265, 0.5361, 0.5227, 0.5193, 0.5251, 0.5206],
       device='cuda:0') torch.Size([16])
percent tensor([0.5055, 0.4804, 0.5049, 0.5116, 0.4999, 0.5203, 0.4844, 0.4946, 0.5095,
        0.4870, 0.5060, 0.4947, 0.4873, 0.5044, 0.4943, 0.5061],
       device='cuda:0') torch.Size([16])
percent tensor([0.6581, 0.6670, 0.5819, 0.5559, 0.5870, 0.6053, 0.6729, 0.5989, 0.6054,
        0.6320, 0.6407, 0.5926, 0.6989, 0.5962, 0.6665, 0.6437],
       device='cuda:0') torch.Size([16])
percent tensor([0.6434, 0.6740, 0.6398, 0.6990, 0.6611, 0.7284, 0.6607, 0.6232, 0.6799,
        0.6588, 0.6810, 0.6919, 0.6499, 0.7025, 0.7025, 0.6786],
       device='cuda:0') torch.Size([16])
percent tensor([0.6294, 0.6468, 0.6252, 0.6135, 0.6559, 0.6547, 0.6527, 0.5670, 0.6887,
        0.6663, 0.6823, 0.5712, 0.6247, 0.7638, 0.5162, 0.6706],
       device='cuda:0') torch.Size([16])
percent tensor([0.6913, 0.6508, 0.7835, 0.7882, 0.8259, 0.7914, 0.7325, 0.7686, 0.7179,
        0.7048, 0.6819, 0.7387, 0.6677, 0.7068, 0.7178, 0.7279],
       device='cuda:0') torch.Size([16])
percent tensor([0.5245, 0.7299, 0.6993, 0.6814, 0.6737, 0.5827, 0.5235, 0.5624, 0.6956,
        0.6639, 0.7739, 0.6589, 0.6992, 0.5986, 0.5522, 0.4163],
       device='cuda:0') torch.Size([16])
percent tensor([0.9998, 0.9999, 0.9999, 0.9999, 0.9998, 0.9998, 0.9998, 0.9996, 0.9998,
        0.9999, 1.0000, 0.9999, 0.9999, 0.9996, 0.9994, 0.9996],
       device='cuda:0') torch.Size([16])
Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 3, 3, 3]) tensor(194.2916, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(831.0999, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(840.2263, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([128, 64, 3, 3]) tensor(1527.0055, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([128, 64, 1, 1]) tensor(474.5221, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([128, 128, 3, 3]) tensor(2344.1685, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([256, 128, 3, 3]) tensor(4271.0225, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([256, 128, 1, 1]) tensor(1339.6077, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([256, 256, 3, 3]) tensor(6325.3945, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([512, 256, 3, 3]) tensor(11499.5986, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([512, 256, 1, 1]) tensor(3776.3699, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([512, 512, 3, 3]) tensor(15928.5801, device='cuda:0', grad_fn=<NormBackward0>)
Epoch: 211 | Batch_idx: 0 |  Loss: (0.0520) |  Loss2: (0.0000) | Acc: (98.00%) (126/128)
Epoch: 211 | Batch_idx: 10 |  Loss: (0.0594) |  Loss2: (0.0000) | Acc: (98.00%) (1380/1408)
Epoch: 211 | Batch_idx: 20 |  Loss: (0.0620) |  Loss2: (0.0000) | Acc: (97.00%) (2634/2688)
Epoch: 211 | Batch_idx: 30 |  Loss: (0.0595) |  Loss2: (0.0000) | Acc: (98.00%) (3890/3968)
Epoch: 211 | Batch_idx: 40 |  Loss: (0.0604) |  Loss2: (0.0000) | Acc: (97.00%) (5141/5248)
Epoch: 211 | Batch_idx: 50 |  Loss: (0.0582) |  Loss2: (0.0000) | Acc: (98.00%) (6403/6528)
Epoch: 211 | Batch_idx: 60 |  Loss: (0.0560) |  Loss2: (0.0000) | Acc: (98.00%) (7666/7808)
Epoch: 211 | Batch_idx: 70 |  Loss: (0.0568) |  Loss2: (0.0000) | Acc: (98.00%) (8920/9088)
Epoch: 211 | Batch_idx: 80 |  Loss: (0.0567) |  Loss2: (0.0000) | Acc: (98.00%) (10178/10368)
Epoch: 211 | Batch_idx: 90 |  Loss: (0.0569) |  Loss2: (0.0000) | Acc: (98.00%) (11435/11648)
Epoch: 211 | Batch_idx: 100 |  Loss: (0.0569) |  Loss2: (0.0000) | Acc: (98.00%) (12688/12928)
Epoch: 211 | Batch_idx: 110 |  Loss: (0.0575) |  Loss2: (0.0000) | Acc: (98.00%) (13937/14208)
Epoch: 211 | Batch_idx: 120 |  Loss: (0.0562) |  Loss2: (0.0000) | Acc: (98.00%) (15199/15488)
Epoch: 211 | Batch_idx: 130 |  Loss: (0.0571) |  Loss2: (0.0000) | Acc: (98.00%) (16445/16768)
Epoch: 211 | Batch_idx: 140 |  Loss: (0.0566) |  Loss2: (0.0000) | Acc: (98.00%) (17707/18048)
Epoch: 211 | Batch_idx: 150 |  Loss: (0.0579) |  Loss2: (0.0000) | Acc: (98.00%) (18952/19328)
Epoch: 211 | Batch_idx: 160 |  Loss: (0.0573) |  Loss2: (0.0000) | Acc: (98.00%) (20213/20608)
Epoch: 211 | Batch_idx: 170 |  Loss: (0.0573) |  Loss2: (0.0000) | Acc: (98.00%) (21469/21888)
Epoch: 211 | Batch_idx: 180 |  Loss: (0.0571) |  Loss2: (0.0000) | Acc: (98.00%) (22729/23168)
Epoch: 211 | Batch_idx: 190 |  Loss: (0.0573) |  Loss2: (0.0000) | Acc: (98.00%) (23985/24448)
Epoch: 211 | Batch_idx: 200 |  Loss: (0.0573) |  Loss2: (0.0000) | Acc: (98.00%) (25238/25728)
Epoch: 211 | Batch_idx: 210 |  Loss: (0.0565) |  Loss2: (0.0000) | Acc: (98.00%) (26502/27008)
Epoch: 211 | Batch_idx: 220 |  Loss: (0.0566) |  Loss2: (0.0000) | Acc: (98.00%) (27755/28288)
Epoch: 211 | Batch_idx: 230 |  Loss: (0.0571) |  Loss2: (0.0000) | Acc: (98.00%) (29014/29568)
Epoch: 211 | Batch_idx: 240 |  Loss: (0.0570) |  Loss2: (0.0000) | Acc: (98.00%) (30274/30848)
Epoch: 211 | Batch_idx: 250 |  Loss: (0.0568) |  Loss2: (0.0000) | Acc: (98.00%) (31532/32128)
Epoch: 211 | Batch_idx: 260 |  Loss: (0.0572) |  Loss2: (0.0000) | Acc: (98.00%) (32784/33408)
Epoch: 211 | Batch_idx: 270 |  Loss: (0.0573) |  Loss2: (0.0000) | Acc: (98.00%) (34035/34688)
Epoch: 211 | Batch_idx: 280 |  Loss: (0.0573) |  Loss2: (0.0000) | Acc: (98.00%) (35290/35968)
Epoch: 211 | Batch_idx: 290 |  Loss: (0.0570) |  Loss2: (0.0000) | Acc: (98.00%) (36551/37248)
Epoch: 211 | Batch_idx: 300 |  Loss: (0.0571) |  Loss2: (0.0000) | Acc: (98.00%) (37804/38528)
Epoch: 211 | Batch_idx: 310 |  Loss: (0.0572) |  Loss2: (0.0000) | Acc: (98.00%) (39059/39808)
Epoch: 211 | Batch_idx: 320 |  Loss: (0.0567) |  Loss2: (0.0000) | Acc: (98.00%) (40323/41088)
Epoch: 211 | Batch_idx: 330 |  Loss: (0.0570) |  Loss2: (0.0000) | Acc: (98.00%) (41576/42368)
Epoch: 211 | Batch_idx: 340 |  Loss: (0.0572) |  Loss2: (0.0000) | Acc: (98.00%) (42822/43648)
Epoch: 211 | Batch_idx: 350 |  Loss: (0.0577) |  Loss2: (0.0000) | Acc: (98.00%) (44070/44928)
Epoch: 211 | Batch_idx: 360 |  Loss: (0.0579) |  Loss2: (0.0000) | Acc: (98.00%) (45325/46208)
Epoch: 211 | Batch_idx: 370 |  Loss: (0.0583) |  Loss2: (0.0000) | Acc: (98.00%) (46576/47488)
Epoch: 211 | Batch_idx: 380 |  Loss: (0.0586) |  Loss2: (0.0000) | Acc: (98.00%) (47823/48768)
Epoch: 211 | Batch_idx: 390 |  Loss: (0.0587) |  Loss2: (0.0000) | Acc: (98.00%) (49028/50000)
# TEST : Loss: (0.4234) | Acc: (88.00%) (8885/10000)
percent tensor([0.5214, 0.5257, 0.5385, 0.5237, 0.5386, 0.5210, 0.5305, 0.5291, 0.5260,
        0.5290, 0.5259, 0.5362, 0.5223, 0.5188, 0.5246, 0.5201],
       device='cuda:0') torch.Size([16])
percent tensor([0.5033, 0.4766, 0.5016, 0.5085, 0.4969, 0.5194, 0.4806, 0.4912, 0.5074,
        0.4840, 0.5043, 0.4913, 0.4851, 0.5003, 0.4906, 0.5034],
       device='cuda:0') torch.Size([16])
percent tensor([0.6600, 0.6648, 0.5853, 0.5587, 0.5911, 0.6022, 0.6757, 0.6020, 0.6008,
        0.6298, 0.6322, 0.5990, 0.6986, 0.5868, 0.6658, 0.6454],
       device='cuda:0') torch.Size([16])
percent tensor([0.6434, 0.6658, 0.6382, 0.7010, 0.6674, 0.7362, 0.6586, 0.6237, 0.6931,
        0.6485, 0.6811, 0.6874, 0.6518, 0.6995, 0.7029, 0.6759],
       device='cuda:0') torch.Size([16])
percent tensor([0.6348, 0.6449, 0.6222, 0.5994, 0.6605, 0.6543, 0.6394, 0.5689, 0.6981,
        0.6621, 0.6972, 0.5528, 0.6330, 0.7587, 0.5119, 0.6709],
       device='cuda:0') torch.Size([16])
percent tensor([0.6854, 0.6407, 0.7663, 0.7677, 0.8103, 0.7791, 0.7204, 0.7572, 0.7295,
        0.6984, 0.6920, 0.7261, 0.6679, 0.7003, 0.7118, 0.7223],
       device='cuda:0') torch.Size([16])
percent tensor([0.5114, 0.7419, 0.7022, 0.6880, 0.6709, 0.5718, 0.5624, 0.5304, 0.6986,
        0.6749, 0.7897, 0.6719, 0.6895, 0.5834, 0.5601, 0.4161],
       device='cuda:0') torch.Size([16])
percent tensor([0.9998, 0.9999, 0.9998, 1.0000, 0.9998, 0.9998, 0.9998, 0.9995, 0.9999,
        0.9999, 1.0000, 0.9999, 0.9999, 0.9995, 0.9994, 0.9995],
       device='cuda:0') torch.Size([16])
Epoch: 212 | Batch_idx: 0 |  Loss: (0.0375) |  Loss2: (0.0000) | Acc: (99.00%) (127/128)
Epoch: 212 | Batch_idx: 10 |  Loss: (0.0500) |  Loss2: (0.0000) | Acc: (98.00%) (1387/1408)
Epoch: 212 | Batch_idx: 20 |  Loss: (0.0505) |  Loss2: (0.0000) | Acc: (98.00%) (2649/2688)
Epoch: 212 | Batch_idx: 30 |  Loss: (0.0542) |  Loss2: (0.0000) | Acc: (98.00%) (3897/3968)
Epoch: 212 | Batch_idx: 40 |  Loss: (0.0502) |  Loss2: (0.0000) | Acc: (98.00%) (5166/5248)
Epoch: 212 | Batch_idx: 50 |  Loss: (0.0510) |  Loss2: (0.0000) | Acc: (98.00%) (6416/6528)
Epoch: 212 | Batch_idx: 60 |  Loss: (0.0519) |  Loss2: (0.0000) | Acc: (98.00%) (7671/7808)
Epoch: 212 | Batch_idx: 70 |  Loss: (0.0522) |  Loss2: (0.0000) | Acc: (98.00%) (8929/9088)
Epoch: 212 | Batch_idx: 80 |  Loss: (0.0532) |  Loss2: (0.0000) | Acc: (98.00%) (10185/10368)
Epoch: 212 | Batch_idx: 90 |  Loss: (0.0544) |  Loss2: (0.0000) | Acc: (98.00%) (11437/11648)
Epoch: 212 | Batch_idx: 100 |  Loss: (0.0558) |  Loss2: (0.0000) | Acc: (98.00%) (12687/12928)
Epoch: 212 | Batch_idx: 110 |  Loss: (0.0557) |  Loss2: (0.0000) | Acc: (98.00%) (13948/14208)
Epoch: 212 | Batch_idx: 120 |  Loss: (0.0556) |  Loss2: (0.0000) | Acc: (98.00%) (15204/15488)
Epoch: 212 | Batch_idx: 130 |  Loss: (0.0552) |  Loss2: (0.0000) | Acc: (98.00%) (16465/16768)
Epoch: 212 | Batch_idx: 140 |  Loss: (0.0551) |  Loss2: (0.0000) | Acc: (98.00%) (17724/18048)
Epoch: 212 | Batch_idx: 150 |  Loss: (0.0544) |  Loss2: (0.0000) | Acc: (98.00%) (18983/19328)
Epoch: 212 | Batch_idx: 160 |  Loss: (0.0551) |  Loss2: (0.0000) | Acc: (98.00%) (20235/20608)
Epoch: 212 | Batch_idx: 170 |  Loss: (0.0557) |  Loss2: (0.0000) | Acc: (98.00%) (21490/21888)
Epoch: 212 | Batch_idx: 180 |  Loss: (0.0559) |  Loss2: (0.0000) | Acc: (98.00%) (22741/23168)
Epoch: 212 | Batch_idx: 190 |  Loss: (0.0566) |  Loss2: (0.0000) | Acc: (98.00%) (23995/24448)
Epoch: 212 | Batch_idx: 200 |  Loss: (0.0569) |  Loss2: (0.0000) | Acc: (98.00%) (25244/25728)
Epoch: 212 | Batch_idx: 210 |  Loss: (0.0568) |  Loss2: (0.0000) | Acc: (98.00%) (26501/27008)
Epoch: 212 | Batch_idx: 220 |  Loss: (0.0566) |  Loss2: (0.0000) | Acc: (98.00%) (27760/28288)
Epoch: 212 | Batch_idx: 230 |  Loss: (0.0563) |  Loss2: (0.0000) | Acc: (98.00%) (29021/29568)
Epoch: 212 | Batch_idx: 240 |  Loss: (0.0559) |  Loss2: (0.0000) | Acc: (98.00%) (30283/30848)
Epoch: 212 | Batch_idx: 250 |  Loss: (0.0565) |  Loss2: (0.0000) | Acc: (98.00%) (31535/32128)
Epoch: 212 | Batch_idx: 260 |  Loss: (0.0561) |  Loss2: (0.0000) | Acc: (98.00%) (32799/33408)
Epoch: 212 | Batch_idx: 270 |  Loss: (0.0561) |  Loss2: (0.0000) | Acc: (98.00%) (34056/34688)
Epoch: 212 | Batch_idx: 280 |  Loss: (0.0556) |  Loss2: (0.0000) | Acc: (98.00%) (35323/35968)
Epoch: 212 | Batch_idx: 290 |  Loss: (0.0558) |  Loss2: (0.0000) | Acc: (98.00%) (36577/37248)
Epoch: 212 | Batch_idx: 300 |  Loss: (0.0562) |  Loss2: (0.0000) | Acc: (98.00%) (37824/38528)
Epoch: 212 | Batch_idx: 310 |  Loss: (0.0566) |  Loss2: (0.0000) | Acc: (98.00%) (39070/39808)
Epoch: 212 | Batch_idx: 320 |  Loss: (0.0567) |  Loss2: (0.0000) | Acc: (98.00%) (40328/41088)
Epoch: 212 | Batch_idx: 330 |  Loss: (0.0565) |  Loss2: (0.0000) | Acc: (98.00%) (41589/42368)
Epoch: 212 | Batch_idx: 340 |  Loss: (0.0571) |  Loss2: (0.0000) | Acc: (98.00%) (42837/43648)
Epoch: 212 | Batch_idx: 350 |  Loss: (0.0577) |  Loss2: (0.0000) | Acc: (98.00%) (44088/44928)
Epoch: 212 | Batch_idx: 360 |  Loss: (0.0578) |  Loss2: (0.0000) | Acc: (98.00%) (45339/46208)
Epoch: 212 | Batch_idx: 370 |  Loss: (0.0577) |  Loss2: (0.0000) | Acc: (98.00%) (46594/47488)
Epoch: 212 | Batch_idx: 380 |  Loss: (0.0579) |  Loss2: (0.0000) | Acc: (98.00%) (47846/48768)
Epoch: 212 | Batch_idx: 390 |  Loss: (0.0580) |  Loss2: (0.0000) | Acc: (98.00%) (49053/50000)
# TEST : Loss: (0.4476) | Acc: (88.00%) (8885/10000)
percent tensor([0.5217, 0.5259, 0.5383, 0.5236, 0.5385, 0.5215, 0.5308, 0.5290, 0.5268,
        0.5294, 0.5267, 0.5364, 0.5228, 0.5189, 0.5249, 0.5204],
       device='cuda:0') torch.Size([16])
percent tensor([0.5049, 0.4790, 0.5033, 0.5111, 0.4995, 0.5197, 0.4839, 0.4925, 0.5109,
        0.4861, 0.5060, 0.4928, 0.4874, 0.5056, 0.4918, 0.5057],
       device='cuda:0') torch.Size([16])
percent tensor([0.6664, 0.6769, 0.5891, 0.5688, 0.5951, 0.6235, 0.6794, 0.6067, 0.6039,
        0.6380, 0.6385, 0.6030, 0.7022, 0.5926, 0.6783, 0.6530],
       device='cuda:0') torch.Size([16])
percent tensor([0.6453, 0.6701, 0.6410, 0.6986, 0.6659, 0.7334, 0.6647, 0.6285, 0.6902,
        0.6631, 0.6894, 0.6938, 0.6575, 0.7052, 0.7059, 0.6766],
       device='cuda:0') torch.Size([16])
percent tensor([0.6260, 0.6410, 0.6102, 0.5923, 0.6498, 0.6493, 0.6382, 0.5662, 0.6866,
        0.6637, 0.6824, 0.5559, 0.6310, 0.7510, 0.5221, 0.6650],
       device='cuda:0') torch.Size([16])
percent tensor([0.6801, 0.6433, 0.7629, 0.7646, 0.8075, 0.7909, 0.7167, 0.7493, 0.7157,
        0.6970, 0.6882, 0.7250, 0.6623, 0.6993, 0.7131, 0.7285],
       device='cuda:0') torch.Size([16])
percent tensor([0.5248, 0.7330, 0.6930, 0.6582, 0.6569, 0.5491, 0.5202, 0.5337, 0.7065,
        0.6600, 0.7859, 0.6611, 0.6942, 0.5896, 0.5569, 0.4122],
       device='cuda:0') torch.Size([16])
percent tensor([0.9998, 0.9999, 0.9999, 0.9999, 0.9998, 0.9998, 0.9998, 0.9992, 0.9999,
        0.9999, 1.0000, 0.9999, 1.0000, 0.9997, 0.9994, 0.9996],
       device='cuda:0') torch.Size([16])
Epoch: 213 | Batch_idx: 0 |  Loss: (0.0447) |  Loss2: (0.0000) | Acc: (98.00%) (126/128)
Epoch: 213 | Batch_idx: 10 |  Loss: (0.0462) |  Loss2: (0.0000) | Acc: (98.00%) (1383/1408)
Epoch: 213 | Batch_idx: 20 |  Loss: (0.0424) |  Loss2: (0.0000) | Acc: (98.00%) (2648/2688)
Epoch: 213 | Batch_idx: 30 |  Loss: (0.0451) |  Loss2: (0.0000) | Acc: (98.00%) (3909/3968)
Epoch: 213 | Batch_idx: 40 |  Loss: (0.0479) |  Loss2: (0.0000) | Acc: (98.00%) (5165/5248)
Epoch: 213 | Batch_idx: 50 |  Loss: (0.0481) |  Loss2: (0.0000) | Acc: (98.00%) (6429/6528)
Epoch: 213 | Batch_idx: 60 |  Loss: (0.0471) |  Loss2: (0.0000) | Acc: (98.00%) (7695/7808)
Epoch: 213 | Batch_idx: 70 |  Loss: (0.0495) |  Loss2: (0.0000) | Acc: (98.00%) (8946/9088)
Epoch: 213 | Batch_idx: 80 |  Loss: (0.0505) |  Loss2: (0.0000) | Acc: (98.00%) (10201/10368)
Epoch: 213 | Batch_idx: 90 |  Loss: (0.0514) |  Loss2: (0.0000) | Acc: (98.00%) (11462/11648)
Epoch: 213 | Batch_idx: 100 |  Loss: (0.0528) |  Loss2: (0.0000) | Acc: (98.00%) (12717/12928)
Epoch: 213 | Batch_idx: 110 |  Loss: (0.0536) |  Loss2: (0.0000) | Acc: (98.00%) (13969/14208)
Epoch: 213 | Batch_idx: 120 |  Loss: (0.0545) |  Loss2: (0.0000) | Acc: (98.00%) (15218/15488)
Epoch: 213 | Batch_idx: 130 |  Loss: (0.0543) |  Loss2: (0.0000) | Acc: (98.00%) (16478/16768)
Epoch: 213 | Batch_idx: 140 |  Loss: (0.0538) |  Loss2: (0.0000) | Acc: (98.00%) (17738/18048)
Epoch: 213 | Batch_idx: 150 |  Loss: (0.0535) |  Loss2: (0.0000) | Acc: (98.00%) (18998/19328)
Epoch: 213 | Batch_idx: 160 |  Loss: (0.0541) |  Loss2: (0.0000) | Acc: (98.00%) (20253/20608)
Epoch: 213 | Batch_idx: 170 |  Loss: (0.0544) |  Loss2: (0.0000) | Acc: (98.00%) (21506/21888)
Epoch: 213 | Batch_idx: 180 |  Loss: (0.0543) |  Loss2: (0.0000) | Acc: (98.00%) (22759/23168)
Epoch: 213 | Batch_idx: 190 |  Loss: (0.0545) |  Loss2: (0.0000) | Acc: (98.00%) (24015/24448)
Epoch: 213 | Batch_idx: 200 |  Loss: (0.0546) |  Loss2: (0.0000) | Acc: (98.00%) (25269/25728)
Epoch: 213 | Batch_idx: 210 |  Loss: (0.0544) |  Loss2: (0.0000) | Acc: (98.00%) (26528/27008)
Epoch: 213 | Batch_idx: 220 |  Loss: (0.0547) |  Loss2: (0.0000) | Acc: (98.00%) (27787/28288)
Epoch: 213 | Batch_idx: 230 |  Loss: (0.0542) |  Loss2: (0.0000) | Acc: (98.00%) (29048/29568)
Epoch: 213 | Batch_idx: 240 |  Loss: (0.0546) |  Loss2: (0.0000) | Acc: (98.00%) (30296/30848)
Epoch: 213 | Batch_idx: 250 |  Loss: (0.0541) |  Loss2: (0.0000) | Acc: (98.00%) (31558/32128)
Epoch: 213 | Batch_idx: 260 |  Loss: (0.0540) |  Loss2: (0.0000) | Acc: (98.00%) (32817/33408)
Epoch: 213 | Batch_idx: 270 |  Loss: (0.0539) |  Loss2: (0.0000) | Acc: (98.00%) (34079/34688)
Epoch: 213 | Batch_idx: 280 |  Loss: (0.0545) |  Loss2: (0.0000) | Acc: (98.00%) (35333/35968)
Epoch: 213 | Batch_idx: 290 |  Loss: (0.0545) |  Loss2: (0.0000) | Acc: (98.00%) (36588/37248)
Epoch: 213 | Batch_idx: 300 |  Loss: (0.0543) |  Loss2: (0.0000) | Acc: (98.00%) (37845/38528)
Epoch: 213 | Batch_idx: 310 |  Loss: (0.0543) |  Loss2: (0.0000) | Acc: (98.00%) (39100/39808)
Epoch: 213 | Batch_idx: 320 |  Loss: (0.0545) |  Loss2: (0.0000) | Acc: (98.00%) (40350/41088)
Epoch: 213 | Batch_idx: 330 |  Loss: (0.0547) |  Loss2: (0.0000) | Acc: (98.00%) (41605/42368)
Epoch: 213 | Batch_idx: 340 |  Loss: (0.0552) |  Loss2: (0.0000) | Acc: (98.00%) (42856/43648)
Epoch: 213 | Batch_idx: 350 |  Loss: (0.0553) |  Loss2: (0.0000) | Acc: (98.00%) (44110/44928)
Epoch: 213 | Batch_idx: 360 |  Loss: (0.0555) |  Loss2: (0.0000) | Acc: (98.00%) (45366/46208)
Epoch: 213 | Batch_idx: 370 |  Loss: (0.0557) |  Loss2: (0.0000) | Acc: (98.00%) (46614/47488)
Epoch: 213 | Batch_idx: 380 |  Loss: (0.0559) |  Loss2: (0.0000) | Acc: (98.00%) (47863/48768)
Epoch: 213 | Batch_idx: 390 |  Loss: (0.0558) |  Loss2: (0.0000) | Acc: (98.00%) (49076/50000)
# TEST : Loss: (0.4375) | Acc: (88.00%) (8895/10000)
percent tensor([0.5225, 0.5261, 0.5403, 0.5251, 0.5401, 0.5220, 0.5312, 0.5304, 0.5273,
        0.5302, 0.5267, 0.5380, 0.5236, 0.5189, 0.5256, 0.5210],
       device='cuda:0') torch.Size([16])
percent tensor([0.5084, 0.4803, 0.5088, 0.5163, 0.5034, 0.5234, 0.4856, 0.4959, 0.5111,
        0.4878, 0.5079, 0.4967, 0.4897, 0.5038, 0.4957, 0.5078],
       device='cuda:0') torch.Size([16])
percent tensor([0.6542, 0.6671, 0.5873, 0.5639, 0.5905, 0.6028, 0.6690, 0.6061, 0.6001,
        0.6275, 0.6265, 0.5972, 0.6906, 0.5950, 0.6671, 0.6453],
       device='cuda:0') torch.Size([16])
percent tensor([0.6413, 0.6654, 0.6354, 0.6968, 0.6619, 0.7349, 0.6586, 0.6271, 0.6847,
        0.6523, 0.6830, 0.6868, 0.6473, 0.6978, 0.6993, 0.6716],
       device='cuda:0') torch.Size([16])
percent tensor([0.6231, 0.6455, 0.6264, 0.5987, 0.6609, 0.6407, 0.6403, 0.5740, 0.6782,
        0.6647, 0.6736, 0.5592, 0.6156, 0.7669, 0.5056, 0.6629],
       device='cuda:0') torch.Size([16])
percent tensor([0.6839, 0.6523, 0.7886, 0.7845, 0.8256, 0.7894, 0.7327, 0.7681, 0.7220,
        0.7089, 0.6925, 0.7433, 0.6601, 0.7098, 0.7208, 0.7329],
       device='cuda:0') torch.Size([16])
percent tensor([0.5085, 0.7364, 0.6931, 0.6481, 0.6546, 0.5549, 0.5475, 0.5698, 0.6962,
        0.6466, 0.7703, 0.6605, 0.6761, 0.6293, 0.5683, 0.4096],
       device='cuda:0') torch.Size([16])
percent tensor([0.9998, 1.0000, 0.9999, 0.9999, 0.9999, 0.9997, 0.9999, 0.9996, 0.9999,
        0.9999, 1.0000, 0.9999, 0.9999, 0.9997, 0.9995, 0.9996],
       device='cuda:0') torch.Size([16])
Epoch: 214 | Batch_idx: 0 |  Loss: (0.0553) |  Loss2: (0.0000) | Acc: (98.00%) (126/128)
Epoch: 214 | Batch_idx: 10 |  Loss: (0.0553) |  Loss2: (0.0000) | Acc: (98.00%) (1386/1408)
Epoch: 214 | Batch_idx: 20 |  Loss: (0.0506) |  Loss2: (0.0000) | Acc: (98.00%) (2646/2688)
Epoch: 214 | Batch_idx: 30 |  Loss: (0.0498) |  Loss2: (0.0000) | Acc: (98.00%) (3909/3968)
Epoch: 214 | Batch_idx: 40 |  Loss: (0.0500) |  Loss2: (0.0000) | Acc: (98.00%) (5167/5248)
Epoch: 214 | Batch_idx: 50 |  Loss: (0.0514) |  Loss2: (0.0000) | Acc: (98.00%) (6422/6528)
Epoch: 214 | Batch_idx: 60 |  Loss: (0.0499) |  Loss2: (0.0000) | Acc: (98.00%) (7687/7808)
Epoch: 214 | Batch_idx: 70 |  Loss: (0.0516) |  Loss2: (0.0000) | Acc: (98.00%) (8937/9088)
Epoch: 214 | Batch_idx: 80 |  Loss: (0.0514) |  Loss2: (0.0000) | Acc: (98.00%) (10197/10368)
Epoch: 214 | Batch_idx: 90 |  Loss: (0.0505) |  Loss2: (0.0000) | Acc: (98.00%) (11461/11648)
Epoch: 214 | Batch_idx: 100 |  Loss: (0.0505) |  Loss2: (0.0000) | Acc: (98.00%) (12718/12928)
Epoch: 214 | Batch_idx: 110 |  Loss: (0.0499) |  Loss2: (0.0000) | Acc: (98.00%) (13983/14208)
Epoch: 214 | Batch_idx: 120 |  Loss: (0.0493) |  Loss2: (0.0000) | Acc: (98.00%) (15247/15488)
Epoch: 214 | Batch_idx: 130 |  Loss: (0.0494) |  Loss2: (0.0000) | Acc: (98.00%) (16506/16768)
Epoch: 214 | Batch_idx: 140 |  Loss: (0.0496) |  Loss2: (0.0000) | Acc: (98.00%) (17760/18048)
Epoch: 214 | Batch_idx: 150 |  Loss: (0.0498) |  Loss2: (0.0000) | Acc: (98.00%) (19013/19328)
Epoch: 214 | Batch_idx: 160 |  Loss: (0.0488) |  Loss2: (0.0000) | Acc: (98.00%) (20284/20608)
Epoch: 214 | Batch_idx: 170 |  Loss: (0.0492) |  Loss2: (0.0000) | Acc: (98.00%) (21536/21888)
Epoch: 214 | Batch_idx: 180 |  Loss: (0.0498) |  Loss2: (0.0000) | Acc: (98.00%) (22798/23168)
Epoch: 214 | Batch_idx: 190 |  Loss: (0.0497) |  Loss2: (0.0000) | Acc: (98.00%) (24058/24448)
Epoch: 214 | Batch_idx: 200 |  Loss: (0.0501) |  Loss2: (0.0000) | Acc: (98.00%) (25313/25728)
Epoch: 214 | Batch_idx: 210 |  Loss: (0.0501) |  Loss2: (0.0000) | Acc: (98.00%) (26572/27008)
Epoch: 214 | Batch_idx: 220 |  Loss: (0.0499) |  Loss2: (0.0000) | Acc: (98.00%) (27836/28288)
Epoch: 214 | Batch_idx: 230 |  Loss: (0.0505) |  Loss2: (0.0000) | Acc: (98.00%) (29087/29568)
Epoch: 214 | Batch_idx: 240 |  Loss: (0.0507) |  Loss2: (0.0000) | Acc: (98.00%) (30343/30848)
Epoch: 214 | Batch_idx: 250 |  Loss: (0.0507) |  Loss2: (0.0000) | Acc: (98.00%) (31598/32128)
Epoch: 214 | Batch_idx: 260 |  Loss: (0.0511) |  Loss2: (0.0000) | Acc: (98.00%) (32857/33408)
Epoch: 214 | Batch_idx: 270 |  Loss: (0.0510) |  Loss2: (0.0000) | Acc: (98.00%) (34118/34688)
Epoch: 214 | Batch_idx: 280 |  Loss: (0.0516) |  Loss2: (0.0000) | Acc: (98.00%) (35367/35968)
Epoch: 214 | Batch_idx: 290 |  Loss: (0.0519) |  Loss2: (0.0000) | Acc: (98.00%) (36621/37248)
Epoch: 214 | Batch_idx: 300 |  Loss: (0.0516) |  Loss2: (0.0000) | Acc: (98.00%) (37884/38528)
Epoch: 214 | Batch_idx: 310 |  Loss: (0.0516) |  Loss2: (0.0000) | Acc: (98.00%) (39142/39808)
Epoch: 214 | Batch_idx: 320 |  Loss: (0.0527) |  Loss2: (0.0000) | Acc: (98.00%) (40382/41088)
Epoch: 214 | Batch_idx: 330 |  Loss: (0.0530) |  Loss2: (0.0000) | Acc: (98.00%) (41636/42368)
Epoch: 214 | Batch_idx: 340 |  Loss: (0.0531) |  Loss2: (0.0000) | Acc: (98.00%) (42895/43648)
Epoch: 214 | Batch_idx: 350 |  Loss: (0.0530) |  Loss2: (0.0000) | Acc: (98.00%) (44152/44928)
Epoch: 214 | Batch_idx: 360 |  Loss: (0.0531) |  Loss2: (0.0000) | Acc: (98.00%) (45404/46208)
Epoch: 214 | Batch_idx: 370 |  Loss: (0.0531) |  Loss2: (0.0000) | Acc: (98.00%) (46664/47488)
Epoch: 214 | Batch_idx: 380 |  Loss: (0.0534) |  Loss2: (0.0000) | Acc: (98.00%) (47919/48768)
Epoch: 214 | Batch_idx: 390 |  Loss: (0.0539) |  Loss2: (0.0000) | Acc: (98.00%) (49121/50000)
# TEST : Loss: (0.4476) | Acc: (88.00%) (8877/10000)
percent tensor([0.5230, 0.5277, 0.5392, 0.5250, 0.5393, 0.5226, 0.5318, 0.5305, 0.5284,
        0.5307, 0.5282, 0.5373, 0.5244, 0.5211, 0.5264, 0.5220],
       device='cuda:0') torch.Size([16])
percent tensor([0.5053, 0.4800, 0.5049, 0.5135, 0.4993, 0.5211, 0.4845, 0.4962, 0.5098,
        0.4874, 0.5063, 0.4948, 0.4881, 0.5034, 0.4945, 0.5062],
       device='cuda:0') torch.Size([16])
percent tensor([0.6652, 0.6777, 0.5936, 0.5609, 0.5982, 0.6189, 0.6829, 0.6076, 0.5997,
        0.6419, 0.6339, 0.6087, 0.6991, 0.6036, 0.6720, 0.6506],
       device='cuda:0') torch.Size([16])
percent tensor([0.6415, 0.6574, 0.6392, 0.6957, 0.6624, 0.7296, 0.6555, 0.6173, 0.6872,
        0.6521, 0.6793, 0.6913, 0.6465, 0.6988, 0.6938, 0.6686],
       device='cuda:0') torch.Size([16])
percent tensor([0.6239, 0.6421, 0.6172, 0.5889, 0.6480, 0.6325, 0.6382, 0.5704, 0.6807,
        0.6659, 0.6867, 0.5487, 0.6335, 0.7576, 0.5060, 0.6595],
       device='cuda:0') torch.Size([16])
percent tensor([0.6816, 0.6462, 0.7777, 0.7741, 0.8114, 0.8006, 0.7244, 0.7647, 0.7170,
        0.7045, 0.6905, 0.7447, 0.6567, 0.7042, 0.7165, 0.7347],
       device='cuda:0') torch.Size([16])
percent tensor([0.5304, 0.7278, 0.6885, 0.6435, 0.6658, 0.6172, 0.5630, 0.5436, 0.6890,
        0.6695, 0.7763, 0.6815, 0.6845, 0.5812, 0.5875, 0.4263],
       device='cuda:0') torch.Size([16])
percent tensor([0.9998, 0.9999, 0.9998, 0.9999, 0.9998, 0.9996, 0.9998, 0.9994, 0.9999,
        0.9999, 1.0000, 0.9999, 1.0000, 0.9996, 0.9994, 0.9995],
       device='cuda:0') torch.Size([16])
Epoch: 215 | Batch_idx: 0 |  Loss: (0.0305) |  Loss2: (0.0000) | Acc: (100.00%) (128/128)
Epoch: 215 | Batch_idx: 10 |  Loss: (0.0554) |  Loss2: (0.0000) | Acc: (98.00%) (1384/1408)
Epoch: 215 | Batch_idx: 20 |  Loss: (0.0487) |  Loss2: (0.0000) | Acc: (98.00%) (2647/2688)
Epoch: 215 | Batch_idx: 30 |  Loss: (0.0470) |  Loss2: (0.0000) | Acc: (98.00%) (3915/3968)
Epoch: 215 | Batch_idx: 40 |  Loss: (0.0456) |  Loss2: (0.0000) | Acc: (98.00%) (5178/5248)
Epoch: 215 | Batch_idx: 50 |  Loss: (0.0474) |  Loss2: (0.0000) | Acc: (98.00%) (6439/6528)
Epoch: 215 | Batch_idx: 60 |  Loss: (0.0463) |  Loss2: (0.0000) | Acc: (98.00%) (7703/7808)
Epoch: 215 | Batch_idx: 70 |  Loss: (0.0452) |  Loss2: (0.0000) | Acc: (98.00%) (8969/9088)
Epoch: 215 | Batch_idx: 80 |  Loss: (0.0462) |  Loss2: (0.0000) | Acc: (98.00%) (10227/10368)
Epoch: 215 | Batch_idx: 90 |  Loss: (0.0457) |  Loss2: (0.0000) | Acc: (98.00%) (11492/11648)
Epoch: 215 | Batch_idx: 100 |  Loss: (0.0457) |  Loss2: (0.0000) | Acc: (98.00%) (12754/12928)
Epoch: 215 | Batch_idx: 110 |  Loss: (0.0455) |  Loss2: (0.0000) | Acc: (98.00%) (14019/14208)
Epoch: 215 | Batch_idx: 120 |  Loss: (0.0465) |  Loss2: (0.0000) | Acc: (98.00%) (15275/15488)
Epoch: 215 | Batch_idx: 130 |  Loss: (0.0475) |  Loss2: (0.0000) | Acc: (98.00%) (16529/16768)
Epoch: 215 | Batch_idx: 140 |  Loss: (0.0483) |  Loss2: (0.0000) | Acc: (98.00%) (17778/18048)
Epoch: 215 | Batch_idx: 150 |  Loss: (0.0485) |  Loss2: (0.0000) | Acc: (98.00%) (19035/19328)
Epoch: 215 | Batch_idx: 160 |  Loss: (0.0480) |  Loss2: (0.0000) | Acc: (98.00%) (20304/20608)
Epoch: 215 | Batch_idx: 170 |  Loss: (0.0491) |  Loss2: (0.0000) | Acc: (98.00%) (21558/21888)
Epoch: 215 | Batch_idx: 180 |  Loss: (0.0501) |  Loss2: (0.0000) | Acc: (98.00%) (22809/23168)
Epoch: 215 | Batch_idx: 190 |  Loss: (0.0500) |  Loss2: (0.0000) | Acc: (98.00%) (24071/24448)
Epoch: 215 | Batch_idx: 200 |  Loss: (0.0506) |  Loss2: (0.0000) | Acc: (98.00%) (25322/25728)
Epoch: 215 | Batch_idx: 210 |  Loss: (0.0507) |  Loss2: (0.0000) | Acc: (98.00%) (26578/27008)
Epoch: 215 | Batch_idx: 220 |  Loss: (0.0505) |  Loss2: (0.0000) | Acc: (98.00%) (27839/28288)
Epoch: 215 | Batch_idx: 230 |  Loss: (0.0506) |  Loss2: (0.0000) | Acc: (98.00%) (29103/29568)
Epoch: 215 | Batch_idx: 240 |  Loss: (0.0508) |  Loss2: (0.0000) | Acc: (98.00%) (30363/30848)
Epoch: 215 | Batch_idx: 250 |  Loss: (0.0506) |  Loss2: (0.0000) | Acc: (98.00%) (31622/32128)
Epoch: 215 | Batch_idx: 260 |  Loss: (0.0512) |  Loss2: (0.0000) | Acc: (98.00%) (32877/33408)
Epoch: 215 | Batch_idx: 270 |  Loss: (0.0517) |  Loss2: (0.0000) | Acc: (98.00%) (34131/34688)
Epoch: 215 | Batch_idx: 280 |  Loss: (0.0521) |  Loss2: (0.0000) | Acc: (98.00%) (35388/35968)
Epoch: 215 | Batch_idx: 290 |  Loss: (0.0523) |  Loss2: (0.0000) | Acc: (98.00%) (36647/37248)
Epoch: 215 | Batch_idx: 300 |  Loss: (0.0524) |  Loss2: (0.0000) | Acc: (98.00%) (37903/38528)
Epoch: 215 | Batch_idx: 310 |  Loss: (0.0525) |  Loss2: (0.0000) | Acc: (98.00%) (39158/39808)
Epoch: 215 | Batch_idx: 320 |  Loss: (0.0526) |  Loss2: (0.0000) | Acc: (98.00%) (40414/41088)
Epoch: 215 | Batch_idx: 330 |  Loss: (0.0526) |  Loss2: (0.0000) | Acc: (98.00%) (41674/42368)
Epoch: 215 | Batch_idx: 340 |  Loss: (0.0527) |  Loss2: (0.0000) | Acc: (98.00%) (42919/43648)
Epoch: 215 | Batch_idx: 350 |  Loss: (0.0525) |  Loss2: (0.0000) | Acc: (98.00%) (44180/44928)
Epoch: 215 | Batch_idx: 360 |  Loss: (0.0524) |  Loss2: (0.0000) | Acc: (98.00%) (45441/46208)
Epoch: 215 | Batch_idx: 370 |  Loss: (0.0525) |  Loss2: (0.0000) | Acc: (98.00%) (46696/47488)
Epoch: 215 | Batch_idx: 380 |  Loss: (0.0525) |  Loss2: (0.0000) | Acc: (98.00%) (47956/48768)
Epoch: 215 | Batch_idx: 390 |  Loss: (0.0525) |  Loss2: (0.0000) | Acc: (98.00%) (49161/50000)
=> saving checkpoint 'drive/app/torch/save_Schedule/checkpoint_215.pth.tar'
# TEST : Loss: (0.4609) | Acc: (88.00%) (8809/10000)
percent tensor([0.5236, 0.5282, 0.5392, 0.5245, 0.5397, 0.5230, 0.5324, 0.5307, 0.5291,
        0.5311, 0.5292, 0.5374, 0.5248, 0.5216, 0.5266, 0.5222],
       device='cuda:0') torch.Size([16])
percent tensor([0.5047, 0.4783, 0.5050, 0.5135, 0.4989, 0.5202, 0.4828, 0.4956, 0.5077,
        0.4871, 0.5053, 0.4947, 0.4863, 0.5025, 0.4927, 0.5050],
       device='cuda:0') torch.Size([16])
percent tensor([0.6668, 0.6738, 0.5939, 0.5612, 0.5953, 0.6136, 0.6811, 0.6104, 0.6079,
        0.6359, 0.6357, 0.6075, 0.7020, 0.5938, 0.6703, 0.6508],
       device='cuda:0') torch.Size([16])
percent tensor([0.6384, 0.6639, 0.6383, 0.7034, 0.6595, 0.7308, 0.6536, 0.6195, 0.6806,
        0.6524, 0.6743, 0.6856, 0.6375, 0.7023, 0.6973, 0.6661],
       device='cuda:0') torch.Size([16])
percent tensor([0.6200, 0.6356, 0.6379, 0.6070, 0.6694, 0.6445, 0.6486, 0.5811, 0.6802,
        0.6681, 0.6744, 0.5628, 0.6168, 0.7565, 0.5072, 0.6564],
       device='cuda:0') torch.Size([16])
percent tensor([0.6877, 0.6476, 0.7873, 0.7808, 0.8194, 0.7895, 0.7211, 0.7581, 0.7297,
        0.7070, 0.6843, 0.7409, 0.6731, 0.7083, 0.7112, 0.7267],
       device='cuda:0') torch.Size([16])
percent tensor([0.5152, 0.7103, 0.6846, 0.6525, 0.6834, 0.5716, 0.5240, 0.5325, 0.7070,
        0.6194, 0.7559, 0.6506, 0.6925, 0.6098, 0.5346, 0.4200],
       device='cuda:0') torch.Size([16])
percent tensor([0.9998, 0.9999, 0.9998, 0.9999, 0.9999, 0.9997, 0.9998, 0.9996, 0.9999,
        0.9999, 1.0000, 0.9999, 0.9999, 0.9996, 0.9995, 0.9994],
       device='cuda:0') torch.Size([16])
Epoch: 216 | Batch_idx: 0 |  Loss: (0.0415) |  Loss2: (0.0000) | Acc: (97.00%) (125/128)
Epoch: 216 | Batch_idx: 10 |  Loss: (0.0599) |  Loss2: (0.0000) | Acc: (97.00%) (1379/1408)
Epoch: 216 | Batch_idx: 20 |  Loss: (0.0571) |  Loss2: (0.0000) | Acc: (97.00%) (2634/2688)
Epoch: 216 | Batch_idx: 30 |  Loss: (0.0579) |  Loss2: (0.0000) | Acc: (97.00%) (3887/3968)
Epoch: 216 | Batch_idx: 40 |  Loss: (0.0564) |  Loss2: (0.0000) | Acc: (98.00%) (5146/5248)
Epoch: 216 | Batch_idx: 50 |  Loss: (0.0577) |  Loss2: (0.0000) | Acc: (98.00%) (6402/6528)
Epoch: 216 | Batch_idx: 60 |  Loss: (0.0554) |  Loss2: (0.0000) | Acc: (98.00%) (7663/7808)
Epoch: 216 | Batch_idx: 70 |  Loss: (0.0580) |  Loss2: (0.0000) | Acc: (98.00%) (8913/9088)
Epoch: 216 | Batch_idx: 80 |  Loss: (0.0575) |  Loss2: (0.0000) | Acc: (98.00%) (10173/10368)
Epoch: 216 | Batch_idx: 90 |  Loss: (0.0565) |  Loss2: (0.0000) | Acc: (98.00%) (11439/11648)
Epoch: 216 | Batch_idx: 100 |  Loss: (0.0561) |  Loss2: (0.0000) | Acc: (98.00%) (12693/12928)
Epoch: 216 | Batch_idx: 110 |  Loss: (0.0557) |  Loss2: (0.0000) | Acc: (98.00%) (13951/14208)
Epoch: 216 | Batch_idx: 120 |  Loss: (0.0555) |  Loss2: (0.0000) | Acc: (98.00%) (15209/15488)
Epoch: 216 | Batch_idx: 130 |  Loss: (0.0547) |  Loss2: (0.0000) | Acc: (98.00%) (16471/16768)
Epoch: 216 | Batch_idx: 140 |  Loss: (0.0542) |  Loss2: (0.0000) | Acc: (98.00%) (17731/18048)
Epoch: 216 | Batch_idx: 150 |  Loss: (0.0538) |  Loss2: (0.0000) | Acc: (98.00%) (18987/19328)
Epoch: 216 | Batch_idx: 160 |  Loss: (0.0551) |  Loss2: (0.0000) | Acc: (98.00%) (20233/20608)
Epoch: 216 | Batch_idx: 170 |  Loss: (0.0550) |  Loss2: (0.0000) | Acc: (98.00%) (21493/21888)
Epoch: 216 | Batch_idx: 180 |  Loss: (0.0549) |  Loss2: (0.0000) | Acc: (98.00%) (22753/23168)
Epoch: 216 | Batch_idx: 190 |  Loss: (0.0545) |  Loss2: (0.0000) | Acc: (98.00%) (24012/24448)
Epoch: 216 | Batch_idx: 200 |  Loss: (0.0545) |  Loss2: (0.0000) | Acc: (98.00%) (25265/25728)
Epoch: 216 | Batch_idx: 210 |  Loss: (0.0539) |  Loss2: (0.0000) | Acc: (98.00%) (26529/27008)
Epoch: 216 | Batch_idx: 220 |  Loss: (0.0538) |  Loss2: (0.0000) | Acc: (98.00%) (27783/28288)
Epoch: 216 | Batch_idx: 230 |  Loss: (0.0537) |  Loss2: (0.0000) | Acc: (98.00%) (29042/29568)
Epoch: 216 | Batch_idx: 240 |  Loss: (0.0536) |  Loss2: (0.0000) | Acc: (98.00%) (30300/30848)
Epoch: 216 | Batch_idx: 250 |  Loss: (0.0541) |  Loss2: (0.0000) | Acc: (98.00%) (31550/32128)
Epoch: 216 | Batch_idx: 260 |  Loss: (0.0538) |  Loss2: (0.0000) | Acc: (98.00%) (32811/33408)
Epoch: 216 | Batch_idx: 270 |  Loss: (0.0538) |  Loss2: (0.0000) | Acc: (98.00%) (34068/34688)
Epoch: 216 | Batch_idx: 280 |  Loss: (0.0542) |  Loss2: (0.0000) | Acc: (98.00%) (35321/35968)
Epoch: 216 | Batch_idx: 290 |  Loss: (0.0543) |  Loss2: (0.0000) | Acc: (98.00%) (36580/37248)
Epoch: 216 | Batch_idx: 300 |  Loss: (0.0540) |  Loss2: (0.0000) | Acc: (98.00%) (37846/38528)
Epoch: 216 | Batch_idx: 310 |  Loss: (0.0541) |  Loss2: (0.0000) | Acc: (98.00%) (39102/39808)
Epoch: 216 | Batch_idx: 320 |  Loss: (0.0540) |  Loss2: (0.0000) | Acc: (98.00%) (40360/41088)
Epoch: 216 | Batch_idx: 330 |  Loss: (0.0539) |  Loss2: (0.0000) | Acc: (98.00%) (41621/42368)
Epoch: 216 | Batch_idx: 340 |  Loss: (0.0538) |  Loss2: (0.0000) | Acc: (98.00%) (42878/43648)
Epoch: 216 | Batch_idx: 350 |  Loss: (0.0538) |  Loss2: (0.0000) | Acc: (98.00%) (44134/44928)
Epoch: 216 | Batch_idx: 360 |  Loss: (0.0536) |  Loss2: (0.0000) | Acc: (98.00%) (45395/46208)
Epoch: 216 | Batch_idx: 370 |  Loss: (0.0535) |  Loss2: (0.0000) | Acc: (98.00%) (46651/47488)
Epoch: 216 | Batch_idx: 380 |  Loss: (0.0534) |  Loss2: (0.0000) | Acc: (98.00%) (47907/48768)
Epoch: 216 | Batch_idx: 390 |  Loss: (0.0534) |  Loss2: (0.0000) | Acc: (98.00%) (49118/50000)
# TEST : Loss: (0.4353) | Acc: (88.00%) (8884/10000)
percent tensor([0.5223, 0.5285, 0.5383, 0.5253, 0.5386, 0.5219, 0.5324, 0.5310, 0.5285,
        0.5309, 0.5283, 0.5366, 0.5238, 0.5230, 0.5265, 0.5218],
       device='cuda:0') torch.Size([16])
percent tensor([0.5073, 0.4805, 0.5045, 0.5132, 0.4997, 0.5236, 0.4844, 0.4954, 0.5114,
        0.4878, 0.5094, 0.4925, 0.4883, 0.5040, 0.4955, 0.5090],
       device='cuda:0') torch.Size([16])
percent tensor([0.6686, 0.6776, 0.5942, 0.5678, 0.5971, 0.6122, 0.6845, 0.6088, 0.6079,
        0.6421, 0.6386, 0.6140, 0.7066, 0.6029, 0.6742, 0.6546],
       device='cuda:0') torch.Size([16])
percent tensor([0.6411, 0.6721, 0.6321, 0.6986, 0.6603, 0.7312, 0.6611, 0.6230, 0.6781,
        0.6570, 0.6789, 0.6881, 0.6464, 0.7042, 0.7030, 0.6754],
       device='cuda:0') torch.Size([16])
percent tensor([0.6375, 0.6364, 0.6323, 0.6069, 0.6609, 0.6477, 0.6412, 0.5885, 0.6902,
        0.6749, 0.6851, 0.5520, 0.6246, 0.7530, 0.5099, 0.6771],
       device='cuda:0') torch.Size([16])
percent tensor([0.6958, 0.6556, 0.7834, 0.7945, 0.8289, 0.8030, 0.7280, 0.7633, 0.7319,
        0.7130, 0.7013, 0.7404, 0.6793, 0.7104, 0.7214, 0.7409],
       device='cuda:0') torch.Size([16])
percent tensor([0.5116, 0.7163, 0.6895, 0.6616, 0.6768, 0.5620, 0.5187, 0.5301, 0.7070,
        0.6369, 0.7751, 0.6582, 0.6880, 0.6101, 0.5352, 0.4081],
       device='cuda:0') torch.Size([16])
percent tensor([0.9998, 0.9999, 0.9999, 0.9999, 0.9999, 0.9996, 0.9998, 0.9996, 0.9999,
        0.9999, 1.0000, 0.9999, 0.9999, 0.9994, 0.9994, 0.9996],
       device='cuda:0') torch.Size([16])
Epoch: 217 | Batch_idx: 0 |  Loss: (0.0299) |  Loss2: (0.0000) | Acc: (100.00%) (128/128)
Epoch: 217 | Batch_idx: 10 |  Loss: (0.0484) |  Loss2: (0.0000) | Acc: (98.00%) (1390/1408)
Epoch: 217 | Batch_idx: 20 |  Loss: (0.0539) |  Loss2: (0.0000) | Acc: (98.00%) (2647/2688)
Epoch: 217 | Batch_idx: 30 |  Loss: (0.0532) |  Loss2: (0.0000) | Acc: (98.00%) (3904/3968)
Epoch: 217 | Batch_idx: 40 |  Loss: (0.0529) |  Loss2: (0.0000) | Acc: (98.00%) (5162/5248)
Epoch: 217 | Batch_idx: 50 |  Loss: (0.0511) |  Loss2: (0.0000) | Acc: (98.00%) (6429/6528)
Epoch: 217 | Batch_idx: 60 |  Loss: (0.0522) |  Loss2: (0.0000) | Acc: (98.00%) (7683/7808)
Epoch: 217 | Batch_idx: 70 |  Loss: (0.0518) |  Loss2: (0.0000) | Acc: (98.00%) (8940/9088)
Epoch: 217 | Batch_idx: 80 |  Loss: (0.0510) |  Loss2: (0.0000) | Acc: (98.00%) (10203/10368)
Epoch: 217 | Batch_idx: 90 |  Loss: (0.0509) |  Loss2: (0.0000) | Acc: (98.00%) (11462/11648)
Epoch: 217 | Batch_idx: 100 |  Loss: (0.0513) |  Loss2: (0.0000) | Acc: (98.00%) (12716/12928)
Epoch: 217 | Batch_idx: 110 |  Loss: (0.0510) |  Loss2: (0.0000) | Acc: (98.00%) (13977/14208)
Epoch: 217 | Batch_idx: 120 |  Loss: (0.0499) |  Loss2: (0.0000) | Acc: (98.00%) (15247/15488)
Epoch: 217 | Batch_idx: 130 |  Loss: (0.0517) |  Loss2: (0.0000) | Acc: (98.00%) (16493/16768)
Epoch: 217 | Batch_idx: 140 |  Loss: (0.0523) |  Loss2: (0.0000) | Acc: (98.00%) (17742/18048)
Epoch: 217 | Batch_idx: 150 |  Loss: (0.0526) |  Loss2: (0.0000) | Acc: (98.00%) (18998/19328)
Epoch: 217 | Batch_idx: 160 |  Loss: (0.0529) |  Loss2: (0.0000) | Acc: (98.00%) (20250/20608)
Epoch: 217 | Batch_idx: 170 |  Loss: (0.0527) |  Loss2: (0.0000) | Acc: (98.00%) (21512/21888)
Epoch: 217 | Batch_idx: 180 |  Loss: (0.0529) |  Loss2: (0.0000) | Acc: (98.00%) (22774/23168)
Epoch: 217 | Batch_idx: 190 |  Loss: (0.0534) |  Loss2: (0.0000) | Acc: (98.00%) (24025/24448)
Epoch: 217 | Batch_idx: 200 |  Loss: (0.0532) |  Loss2: (0.0000) | Acc: (98.00%) (25286/25728)
Epoch: 217 | Batch_idx: 210 |  Loss: (0.0529) |  Loss2: (0.0000) | Acc: (98.00%) (26547/27008)
Epoch: 217 | Batch_idx: 220 |  Loss: (0.0528) |  Loss2: (0.0000) | Acc: (98.00%) (27802/28288)
Epoch: 217 | Batch_idx: 230 |  Loss: (0.0524) |  Loss2: (0.0000) | Acc: (98.00%) (29066/29568)
Epoch: 217 | Batch_idx: 240 |  Loss: (0.0521) |  Loss2: (0.0000) | Acc: (98.00%) (30328/30848)
Epoch: 217 | Batch_idx: 250 |  Loss: (0.0521) |  Loss2: (0.0000) | Acc: (98.00%) (31589/32128)
Epoch: 217 | Batch_idx: 260 |  Loss: (0.0520) |  Loss2: (0.0000) | Acc: (98.00%) (32849/33408)
Epoch: 217 | Batch_idx: 270 |  Loss: (0.0518) |  Loss2: (0.0000) | Acc: (98.00%) (34110/34688)
Epoch: 217 | Batch_idx: 280 |  Loss: (0.0516) |  Loss2: (0.0000) | Acc: (98.00%) (35372/35968)
Epoch: 217 | Batch_idx: 290 |  Loss: (0.0518) |  Loss2: (0.0000) | Acc: (98.00%) (36628/37248)
Epoch: 217 | Batch_idx: 300 |  Loss: (0.0520) |  Loss2: (0.0000) | Acc: (98.00%) (37883/38528)
Epoch: 217 | Batch_idx: 310 |  Loss: (0.0519) |  Loss2: (0.0000) | Acc: (98.00%) (39144/39808)
Epoch: 217 | Batch_idx: 320 |  Loss: (0.0518) |  Loss2: (0.0000) | Acc: (98.00%) (40403/41088)
Epoch: 217 | Batch_idx: 330 |  Loss: (0.0520) |  Loss2: (0.0000) | Acc: (98.00%) (41658/42368)
Epoch: 217 | Batch_idx: 340 |  Loss: (0.0519) |  Loss2: (0.0000) | Acc: (98.00%) (42921/43648)
Epoch: 217 | Batch_idx: 350 |  Loss: (0.0519) |  Loss2: (0.0000) | Acc: (98.00%) (44179/44928)
Epoch: 217 | Batch_idx: 360 |  Loss: (0.0519) |  Loss2: (0.0000) | Acc: (98.00%) (45436/46208)
Epoch: 217 | Batch_idx: 370 |  Loss: (0.0519) |  Loss2: (0.0000) | Acc: (98.00%) (46696/47488)
Epoch: 217 | Batch_idx: 380 |  Loss: (0.0518) |  Loss2: (0.0000) | Acc: (98.00%) (47957/48768)
Epoch: 217 | Batch_idx: 390 |  Loss: (0.0516) |  Loss2: (0.0000) | Acc: (98.00%) (49170/50000)
# TEST : Loss: (0.4328) | Acc: (88.00%) (8892/10000)
percent tensor([0.5231, 0.5261, 0.5407, 0.5252, 0.5403, 0.5228, 0.5312, 0.5308, 0.5286,
        0.5304, 0.5277, 0.5380, 0.5240, 0.5185, 0.5257, 0.5214],
       device='cuda:0') torch.Size([16])
percent tensor([0.5103, 0.4844, 0.5074, 0.5160, 0.5025, 0.5232, 0.4877, 0.4989, 0.5150,
        0.4906, 0.5123, 0.4966, 0.4920, 0.5044, 0.4981, 0.5106],
       device='cuda:0') torch.Size([16])
percent tensor([0.6581, 0.6624, 0.5956, 0.5733, 0.5982, 0.6136, 0.6700, 0.6089, 0.5956,
        0.6263, 0.6240, 0.6037, 0.6887, 0.5897, 0.6693, 0.6467],
       device='cuda:0') torch.Size([16])
percent tensor([0.6516, 0.6857, 0.6365, 0.7011, 0.6614, 0.7338, 0.6758, 0.6291, 0.6991,
        0.6674, 0.6964, 0.6994, 0.6681, 0.7126, 0.7113, 0.6851],
       device='cuda:0') torch.Size([16])
percent tensor([0.6474, 0.6600, 0.6375, 0.6127, 0.6681, 0.6672, 0.6569, 0.5865, 0.7054,
        0.6835, 0.7024, 0.5603, 0.6354, 0.7647, 0.5173, 0.6889],
       device='cuda:0') torch.Size([16])
percent tensor([0.6952, 0.6489, 0.7876, 0.7832, 0.8241, 0.7990, 0.7326, 0.7683, 0.7390,
        0.7199, 0.7057, 0.7602, 0.6845, 0.7116, 0.7226, 0.7364],
       device='cuda:0') torch.Size([16])
percent tensor([0.4953, 0.7078, 0.6905, 0.6519, 0.6569, 0.5541, 0.5126, 0.5362, 0.6988,
        0.6408, 0.7701, 0.6555, 0.6685, 0.6046, 0.5242, 0.3998],
       device='cuda:0') torch.Size([16])
percent tensor([0.9998, 0.9999, 0.9998, 0.9999, 0.9998, 0.9997, 0.9998, 0.9995, 0.9997,
        0.9999, 1.0000, 0.9999, 0.9999, 0.9997, 0.9993, 0.9996],
       device='cuda:0') torch.Size([16])
Epoch: 218 | Batch_idx: 0 |  Loss: (0.0463) |  Loss2: (0.0000) | Acc: (98.00%) (126/128)
Epoch: 218 | Batch_idx: 10 |  Loss: (0.0533) |  Loss2: (0.0000) | Acc: (97.00%) (1378/1408)
Epoch: 218 | Batch_idx: 20 |  Loss: (0.0510) |  Loss2: (0.0000) | Acc: (98.00%) (2643/2688)
Epoch: 218 | Batch_idx: 30 |  Loss: (0.0484) |  Loss2: (0.0000) | Acc: (98.00%) (3902/3968)
Epoch: 218 | Batch_idx: 40 |  Loss: (0.0509) |  Loss2: (0.0000) | Acc: (98.00%) (5159/5248)
Epoch: 218 | Batch_idx: 50 |  Loss: (0.0505) |  Loss2: (0.0000) | Acc: (98.00%) (6419/6528)
Epoch: 218 | Batch_idx: 60 |  Loss: (0.0495) |  Loss2: (0.0000) | Acc: (98.00%) (7681/7808)
Epoch: 218 | Batch_idx: 70 |  Loss: (0.0507) |  Loss2: (0.0000) | Acc: (98.00%) (8939/9088)
Epoch: 218 | Batch_idx: 80 |  Loss: (0.0493) |  Loss2: (0.0000) | Acc: (98.00%) (10206/10368)
Epoch: 218 | Batch_idx: 90 |  Loss: (0.0490) |  Loss2: (0.0000) | Acc: (98.00%) (11467/11648)
Epoch: 218 | Batch_idx: 100 |  Loss: (0.0502) |  Loss2: (0.0000) | Acc: (98.00%) (12720/12928)
Epoch: 218 | Batch_idx: 110 |  Loss: (0.0493) |  Loss2: (0.0000) | Acc: (98.00%) (13986/14208)
Epoch: 218 | Batch_idx: 120 |  Loss: (0.0500) |  Loss2: (0.0000) | Acc: (98.00%) (15243/15488)
Epoch: 218 | Batch_idx: 130 |  Loss: (0.0498) |  Loss2: (0.0000) | Acc: (98.00%) (16506/16768)
Epoch: 218 | Batch_idx: 140 |  Loss: (0.0498) |  Loss2: (0.0000) | Acc: (98.00%) (17766/18048)
Epoch: 218 | Batch_idx: 150 |  Loss: (0.0499) |  Loss2: (0.0000) | Acc: (98.00%) (19025/19328)
Epoch: 218 | Batch_idx: 160 |  Loss: (0.0500) |  Loss2: (0.0000) | Acc: (98.00%) (20284/20608)
Epoch: 218 | Batch_idx: 170 |  Loss: (0.0501) |  Loss2: (0.0000) | Acc: (98.00%) (21539/21888)
Epoch: 218 | Batch_idx: 180 |  Loss: (0.0503) |  Loss2: (0.0000) | Acc: (98.00%) (22797/23168)
Epoch: 218 | Batch_idx: 190 |  Loss: (0.0501) |  Loss2: (0.0000) | Acc: (98.00%) (24062/24448)
Epoch: 218 | Batch_idx: 200 |  Loss: (0.0504) |  Loss2: (0.0000) | Acc: (98.00%) (25318/25728)
Epoch: 218 | Batch_idx: 210 |  Loss: (0.0511) |  Loss2: (0.0000) | Acc: (98.00%) (26564/27008)
Epoch: 218 | Batch_idx: 220 |  Loss: (0.0509) |  Loss2: (0.0000) | Acc: (98.00%) (27824/28288)
Epoch: 218 | Batch_idx: 230 |  Loss: (0.0508) |  Loss2: (0.0000) | Acc: (98.00%) (29090/29568)
Epoch: 218 | Batch_idx: 240 |  Loss: (0.0506) |  Loss2: (0.0000) | Acc: (98.00%) (30353/30848)
Epoch: 218 | Batch_idx: 250 |  Loss: (0.0507) |  Loss2: (0.0000) | Acc: (98.00%) (31610/32128)
Epoch: 218 | Batch_idx: 260 |  Loss: (0.0510) |  Loss2: (0.0000) | Acc: (98.00%) (32865/33408)
Epoch: 218 | Batch_idx: 270 |  Loss: (0.0508) |  Loss2: (0.0000) | Acc: (98.00%) (34124/34688)
Epoch: 218 | Batch_idx: 280 |  Loss: (0.0506) |  Loss2: (0.0000) | Acc: (98.00%) (35382/35968)
Epoch: 218 | Batch_idx: 290 |  Loss: (0.0507) |  Loss2: (0.0000) | Acc: (98.00%) (36643/37248)
Epoch: 218 | Batch_idx: 300 |  Loss: (0.0512) |  Loss2: (0.0000) | Acc: (98.00%) (37893/38528)
Epoch: 218 | Batch_idx: 310 |  Loss: (0.0512) |  Loss2: (0.0000) | Acc: (98.00%) (39150/39808)
Epoch: 218 | Batch_idx: 320 |  Loss: (0.0515) |  Loss2: (0.0000) | Acc: (98.00%) (40407/41088)
Epoch: 218 | Batch_idx: 330 |  Loss: (0.0518) |  Loss2: (0.0000) | Acc: (98.00%) (41668/42368)
Epoch: 218 | Batch_idx: 340 |  Loss: (0.0519) |  Loss2: (0.0000) | Acc: (98.00%) (42922/43648)
Epoch: 218 | Batch_idx: 350 |  Loss: (0.0521) |  Loss2: (0.0000) | Acc: (98.00%) (44183/44928)
Epoch: 218 | Batch_idx: 360 |  Loss: (0.0520) |  Loss2: (0.0000) | Acc: (98.00%) (45447/46208)
Epoch: 218 | Batch_idx: 370 |  Loss: (0.0522) |  Loss2: (0.0000) | Acc: (98.00%) (46698/47488)
Epoch: 218 | Batch_idx: 380 |  Loss: (0.0524) |  Loss2: (0.0000) | Acc: (98.00%) (47953/48768)
Epoch: 218 | Batch_idx: 390 |  Loss: (0.0528) |  Loss2: (0.0000) | Acc: (98.00%) (49158/50000)
# TEST : Loss: (0.4336) | Acc: (88.00%) (8899/10000)
percent tensor([0.5237, 0.5283, 0.5409, 0.5262, 0.5411, 0.5233, 0.5332, 0.5318, 0.5295,
        0.5320, 0.5290, 0.5387, 0.5249, 0.5214, 0.5271, 0.5226],
       device='cuda:0') torch.Size([16])
percent tensor([0.5088, 0.4825, 0.5070, 0.5148, 0.5025, 0.5235, 0.4878, 0.4972, 0.5150,
        0.4896, 0.5105, 0.4983, 0.4920, 0.5050, 0.4968, 0.5090],
       device='cuda:0') torch.Size([16])
percent tensor([0.6601, 0.6683, 0.6017, 0.5734, 0.6028, 0.6130, 0.6789, 0.6139, 0.5969,
        0.6353, 0.6278, 0.6099, 0.6896, 0.5909, 0.6728, 0.6482],
       device='cuda:0') torch.Size([16])
percent tensor([0.6522, 0.6790, 0.6362, 0.7005, 0.6664, 0.7398, 0.6726, 0.6300, 0.6870,
        0.6655, 0.6886, 0.6961, 0.6575, 0.7110, 0.7125, 0.6819],
       device='cuda:0') torch.Size([16])
percent tensor([0.6400, 0.6387, 0.6302, 0.5957, 0.6620, 0.6507, 0.6472, 0.5856, 0.6988,
        0.6637, 0.6972, 0.5512, 0.6312, 0.7556, 0.5132, 0.6725],
       device='cuda:0') torch.Size([16])
percent tensor([0.6877, 0.6529, 0.7858, 0.7850, 0.8227, 0.8020, 0.7280, 0.7734, 0.7347,
        0.7171, 0.6931, 0.7483, 0.6726, 0.7113, 0.7227, 0.7368],
       device='cuda:0') torch.Size([16])
percent tensor([0.4990, 0.7438, 0.6741, 0.6399, 0.6486, 0.5885, 0.5160, 0.5074, 0.7191,
        0.6724, 0.7971, 0.6607, 0.6849, 0.6280, 0.5287, 0.4088],
       device='cuda:0') torch.Size([16])
percent tensor([0.9998, 0.9999, 0.9998, 0.9999, 0.9997, 0.9998, 0.9998, 0.9995, 0.9999,
        0.9999, 1.0000, 0.9999, 0.9999, 0.9996, 0.9994, 0.9995],
       device='cuda:0') torch.Size([16])
Epoch: 219 | Batch_idx: 0 |  Loss: (0.0333) |  Loss2: (0.0000) | Acc: (98.00%) (126/128)
Epoch: 219 | Batch_idx: 10 |  Loss: (0.0345) |  Loss2: (0.0000) | Acc: (98.00%) (1392/1408)
Epoch: 219 | Batch_idx: 20 |  Loss: (0.0407) |  Loss2: (0.0000) | Acc: (98.00%) (2654/2688)
Epoch: 219 | Batch_idx: 30 |  Loss: (0.0428) |  Loss2: (0.0000) | Acc: (98.00%) (3915/3968)
Epoch: 219 | Batch_idx: 40 |  Loss: (0.0435) |  Loss2: (0.0000) | Acc: (98.00%) (5177/5248)
Epoch: 219 | Batch_idx: 50 |  Loss: (0.0417) |  Loss2: (0.0000) | Acc: (98.00%) (6442/6528)
Epoch: 219 | Batch_idx: 60 |  Loss: (0.0421) |  Loss2: (0.0000) | Acc: (98.00%) (7702/7808)
Epoch: 219 | Batch_idx: 70 |  Loss: (0.0418) |  Loss2: (0.0000) | Acc: (98.00%) (8967/9088)
Epoch: 219 | Batch_idx: 80 |  Loss: (0.0423) |  Loss2: (0.0000) | Acc: (98.00%) (10230/10368)
Epoch: 219 | Batch_idx: 90 |  Loss: (0.0433) |  Loss2: (0.0000) | Acc: (98.00%) (11489/11648)
Epoch: 219 | Batch_idx: 100 |  Loss: (0.0446) |  Loss2: (0.0000) | Acc: (98.00%) (12751/12928)
Epoch: 219 | Batch_idx: 110 |  Loss: (0.0444) |  Loss2: (0.0000) | Acc: (98.00%) (14014/14208)
Epoch: 219 | Batch_idx: 120 |  Loss: (0.0447) |  Loss2: (0.0000) | Acc: (98.00%) (15277/15488)
Epoch: 219 | Batch_idx: 130 |  Loss: (0.0462) |  Loss2: (0.0000) | Acc: (98.00%) (16528/16768)
Epoch: 219 | Batch_idx: 140 |  Loss: (0.0465) |  Loss2: (0.0000) | Acc: (98.00%) (17788/18048)
Epoch: 219 | Batch_idx: 150 |  Loss: (0.0471) |  Loss2: (0.0000) | Acc: (98.00%) (19044/19328)
Epoch: 219 | Batch_idx: 160 |  Loss: (0.0474) |  Loss2: (0.0000) | Acc: (98.00%) (20305/20608)
Epoch: 219 | Batch_idx: 170 |  Loss: (0.0472) |  Loss2: (0.0000) | Acc: (98.00%) (21565/21888)
Epoch: 219 | Batch_idx: 180 |  Loss: (0.0470) |  Loss2: (0.0000) | Acc: (98.00%) (22827/23168)
Epoch: 219 | Batch_idx: 190 |  Loss: (0.0470) |  Loss2: (0.0000) | Acc: (98.00%) (24088/24448)
Epoch: 219 | Batch_idx: 200 |  Loss: (0.0469) |  Loss2: (0.0000) | Acc: (98.00%) (25352/25728)
Epoch: 219 | Batch_idx: 210 |  Loss: (0.0469) |  Loss2: (0.0000) | Acc: (98.00%) (26612/27008)
Epoch: 219 | Batch_idx: 220 |  Loss: (0.0467) |  Loss2: (0.0000) | Acc: (98.00%) (27875/28288)
Epoch: 219 | Batch_idx: 230 |  Loss: (0.0464) |  Loss2: (0.0000) | Acc: (98.00%) (29141/29568)
Epoch: 219 | Batch_idx: 240 |  Loss: (0.0464) |  Loss2: (0.0000) | Acc: (98.00%) (30403/30848)
Epoch: 219 | Batch_idx: 250 |  Loss: (0.0465) |  Loss2: (0.0000) | Acc: (98.00%) (31659/32128)
Epoch: 219 | Batch_idx: 260 |  Loss: (0.0466) |  Loss2: (0.0000) | Acc: (98.00%) (32919/33408)
Epoch: 219 | Batch_idx: 270 |  Loss: (0.0467) |  Loss2: (0.0000) | Acc: (98.00%) (34180/34688)
Epoch: 219 | Batch_idx: 280 |  Loss: (0.0467) |  Loss2: (0.0000) | Acc: (98.00%) (35445/35968)
Epoch: 219 | Batch_idx: 290 |  Loss: (0.0472) |  Loss2: (0.0000) | Acc: (98.00%) (36696/37248)
Epoch: 219 | Batch_idx: 300 |  Loss: (0.0475) |  Loss2: (0.0000) | Acc: (98.00%) (37951/38528)
Epoch: 219 | Batch_idx: 310 |  Loss: (0.0481) |  Loss2: (0.0000) | Acc: (98.00%) (39201/39808)
Epoch: 219 | Batch_idx: 320 |  Loss: (0.0482) |  Loss2: (0.0000) | Acc: (98.00%) (40459/41088)
Epoch: 219 | Batch_idx: 330 |  Loss: (0.0485) |  Loss2: (0.0000) | Acc: (98.00%) (41713/42368)
Epoch: 219 | Batch_idx: 340 |  Loss: (0.0487) |  Loss2: (0.0000) | Acc: (98.00%) (42970/43648)
Epoch: 219 | Batch_idx: 350 |  Loss: (0.0487) |  Loss2: (0.0000) | Acc: (98.00%) (44230/44928)
Epoch: 219 | Batch_idx: 360 |  Loss: (0.0488) |  Loss2: (0.0000) | Acc: (98.00%) (45489/46208)
Epoch: 219 | Batch_idx: 370 |  Loss: (0.0490) |  Loss2: (0.0000) | Acc: (98.00%) (46749/47488)
Epoch: 219 | Batch_idx: 380 |  Loss: (0.0490) |  Loss2: (0.0000) | Acc: (98.00%) (48007/48768)
Epoch: 219 | Batch_idx: 390 |  Loss: (0.0490) |  Loss2: (0.0000) | Acc: (98.00%) (49216/50000)
# TEST : Loss: (0.4386) | Acc: (89.00%) (8923/10000)
percent tensor([0.5243, 0.5285, 0.5424, 0.5269, 0.5421, 0.5239, 0.5333, 0.5324, 0.5295,
        0.5323, 0.5291, 0.5400, 0.5254, 0.5210, 0.5275, 0.5230],
       device='cuda:0') torch.Size([16])
percent tensor([0.5099, 0.4853, 0.5111, 0.5194, 0.5060, 0.5238, 0.4897, 0.5002, 0.5148,
        0.4922, 0.5121, 0.5025, 0.4925, 0.5085, 0.4991, 0.5110],
       device='cuda:0') torch.Size([16])
percent tensor([0.6699, 0.6659, 0.6031, 0.5690, 0.6005, 0.6120, 0.6783, 0.6152, 0.6106,
        0.6327, 0.6409, 0.6061, 0.7057, 0.5873, 0.6704, 0.6530],
       device='cuda:0') torch.Size([16])
percent tensor([0.6545, 0.6812, 0.6380, 0.7032, 0.6637, 0.7370, 0.6745, 0.6249, 0.6903,
        0.6660, 0.6931, 0.7004, 0.6609, 0.7130, 0.7135, 0.6823],
       device='cuda:0') torch.Size([16])
percent tensor([0.6143, 0.6430, 0.6355, 0.6001, 0.6687, 0.6456, 0.6484, 0.5748, 0.6845,
        0.6826, 0.6885, 0.5682, 0.6306, 0.7568, 0.5100, 0.6690],
       device='cuda:0') torch.Size([16])
percent tensor([0.6927, 0.6679, 0.7899, 0.7868, 0.8226, 0.7914, 0.7385, 0.7708, 0.7379,
        0.7221, 0.6977, 0.7550, 0.6919, 0.7248, 0.7262, 0.7352],
       device='cuda:0') torch.Size([16])
percent tensor([0.5238, 0.7360, 0.6718, 0.6543, 0.6511, 0.5820, 0.5230, 0.5277, 0.7360,
        0.6571, 0.7826, 0.6722, 0.7126, 0.6233, 0.5278, 0.4147],
       device='cuda:0') torch.Size([16])
percent tensor([0.9998, 0.9999, 0.9998, 0.9999, 0.9999, 0.9998, 0.9999, 0.9996, 0.9999,
        0.9999, 1.0000, 0.9999, 0.9999, 0.9996, 0.9994, 0.9994],
       device='cuda:0') torch.Size([16])
Epoch: 220 | Batch_idx: 0 |  Loss: (0.0264) |  Loss2: (0.0000) | Acc: (99.00%) (127/128)
Epoch: 220 | Batch_idx: 10 |  Loss: (0.0437) |  Loss2: (0.0000) | Acc: (98.00%) (1389/1408)
Epoch: 220 | Batch_idx: 20 |  Loss: (0.0448) |  Loss2: (0.0000) | Acc: (98.00%) (2651/2688)
Epoch: 220 | Batch_idx: 30 |  Loss: (0.0411) |  Loss2: (0.0000) | Acc: (98.00%) (3917/3968)
Epoch: 220 | Batch_idx: 40 |  Loss: (0.0414) |  Loss2: (0.0000) | Acc: (98.00%) (5181/5248)
Epoch: 220 | Batch_idx: 50 |  Loss: (0.0405) |  Loss2: (0.0000) | Acc: (98.00%) (6447/6528)
Epoch: 220 | Batch_idx: 60 |  Loss: (0.0409) |  Loss2: (0.0000) | Acc: (98.00%) (7708/7808)
Epoch: 220 | Batch_idx: 70 |  Loss: (0.0412) |  Loss2: (0.0000) | Acc: (98.00%) (8971/9088)
Epoch: 220 | Batch_idx: 80 |  Loss: (0.0428) |  Loss2: (0.0000) | Acc: (98.00%) (10233/10368)
Epoch: 220 | Batch_idx: 90 |  Loss: (0.0426) |  Loss2: (0.0000) | Acc: (98.00%) (11494/11648)
Epoch: 220 | Batch_idx: 100 |  Loss: (0.0420) |  Loss2: (0.0000) | Acc: (98.00%) (12762/12928)
Epoch: 220 | Batch_idx: 110 |  Loss: (0.0422) |  Loss2: (0.0000) | Acc: (98.00%) (14023/14208)
Epoch: 220 | Batch_idx: 120 |  Loss: (0.0420) |  Loss2: (0.0000) | Acc: (98.00%) (15290/15488)
Epoch: 220 | Batch_idx: 130 |  Loss: (0.0415) |  Loss2: (0.0000) | Acc: (98.00%) (16558/16768)
Epoch: 220 | Batch_idx: 140 |  Loss: (0.0417) |  Loss2: (0.0000) | Acc: (98.00%) (17823/18048)
Epoch: 220 | Batch_idx: 150 |  Loss: (0.0417) |  Loss2: (0.0000) | Acc: (98.00%) (19080/19328)
Epoch: 220 | Batch_idx: 160 |  Loss: (0.0421) |  Loss2: (0.0000) | Acc: (98.00%) (20341/20608)
Epoch: 220 | Batch_idx: 170 |  Loss: (0.0421) |  Loss2: (0.0000) | Acc: (98.00%) (21607/21888)
Epoch: 220 | Batch_idx: 180 |  Loss: (0.0430) |  Loss2: (0.0000) | Acc: (98.00%) (22860/23168)
Epoch: 220 | Batch_idx: 190 |  Loss: (0.0435) |  Loss2: (0.0000) | Acc: (98.00%) (24114/24448)
Epoch: 220 | Batch_idx: 200 |  Loss: (0.0439) |  Loss2: (0.0000) | Acc: (98.00%) (25375/25728)
Epoch: 220 | Batch_idx: 210 |  Loss: (0.0440) |  Loss2: (0.0000) | Acc: (98.00%) (26638/27008)
Epoch: 220 | Batch_idx: 220 |  Loss: (0.0443) |  Loss2: (0.0000) | Acc: (98.00%) (27895/28288)
Epoch: 220 | Batch_idx: 230 |  Loss: (0.0446) |  Loss2: (0.0000) | Acc: (98.00%) (29155/29568)
Epoch: 220 | Batch_idx: 240 |  Loss: (0.0450) |  Loss2: (0.0000) | Acc: (98.00%) (30418/30848)
Epoch: 220 | Batch_idx: 250 |  Loss: (0.0451) |  Loss2: (0.0000) | Acc: (98.00%) (31680/32128)
Epoch: 220 | Batch_idx: 260 |  Loss: (0.0449) |  Loss2: (0.0000) | Acc: (98.00%) (32945/33408)
Epoch: 220 | Batch_idx: 270 |  Loss: (0.0448) |  Loss2: (0.0000) | Acc: (98.00%) (34206/34688)
Epoch: 220 | Batch_idx: 280 |  Loss: (0.0449) |  Loss2: (0.0000) | Acc: (98.00%) (35468/35968)
Epoch: 220 | Batch_idx: 290 |  Loss: (0.0450) |  Loss2: (0.0000) | Acc: (98.00%) (36731/37248)
Epoch: 220 | Batch_idx: 300 |  Loss: (0.0446) |  Loss2: (0.0000) | Acc: (98.00%) (38001/38528)
Epoch: 220 | Batch_idx: 310 |  Loss: (0.0443) |  Loss2: (0.0000) | Acc: (98.00%) (39270/39808)
Epoch: 220 | Batch_idx: 320 |  Loss: (0.0442) |  Loss2: (0.0000) | Acc: (98.00%) (40535/41088)
Epoch: 220 | Batch_idx: 330 |  Loss: (0.0442) |  Loss2: (0.0000) | Acc: (98.00%) (41793/42368)
Epoch: 220 | Batch_idx: 340 |  Loss: (0.0446) |  Loss2: (0.0000) | Acc: (98.00%) (43045/43648)
Epoch: 220 | Batch_idx: 350 |  Loss: (0.0445) |  Loss2: (0.0000) | Acc: (98.00%) (44310/44928)
Epoch: 220 | Batch_idx: 360 |  Loss: (0.0448) |  Loss2: (0.0000) | Acc: (98.00%) (45567/46208)
Epoch: 220 | Batch_idx: 370 |  Loss: (0.0450) |  Loss2: (0.0000) | Acc: (98.00%) (46823/47488)
Epoch: 220 | Batch_idx: 380 |  Loss: (0.0454) |  Loss2: (0.0000) | Acc: (98.00%) (48081/48768)
Epoch: 220 | Batch_idx: 390 |  Loss: (0.0455) |  Loss2: (0.0000) | Acc: (98.00%) (49292/50000)
=> saving checkpoint 'drive/app/torch/save_Schedule/checkpoint_220.pth.tar'
# TEST : Loss: (0.4443) | Acc: (89.00%) (8917/10000)
percent tensor([0.5238, 0.5296, 0.5391, 0.5261, 0.5397, 0.5243, 0.5332, 0.5312, 0.5292,
        0.5318, 0.5292, 0.5372, 0.5249, 0.5230, 0.5280, 0.5233],
       device='cuda:0') torch.Size([16])
percent tensor([0.5146, 0.4869, 0.5118, 0.5181, 0.5087, 0.5250, 0.4916, 0.5013, 0.5187,
        0.4944, 0.5155, 0.5030, 0.4963, 0.5099, 0.5006, 0.5134],
       device='cuda:0') torch.Size([16])
percent tensor([0.6649, 0.6761, 0.5932, 0.5745, 0.5965, 0.6165, 0.6803, 0.6123, 0.6043,
        0.6381, 0.6357, 0.6037, 0.7018, 0.6038, 0.6754, 0.6559],
       device='cuda:0') torch.Size([16])
percent tensor([0.6455, 0.6752, 0.6344, 0.6955, 0.6621, 0.7371, 0.6711, 0.6258, 0.6877,
        0.6592, 0.6862, 0.6964, 0.6536, 0.7102, 0.7034, 0.6740],
       device='cuda:0') torch.Size([16])
percent tensor([0.6330, 0.6533, 0.6340, 0.6028, 0.6726, 0.6609, 0.6515, 0.5723, 0.7045,
        0.6772, 0.6921, 0.5554, 0.6286, 0.7578, 0.5173, 0.6726],
       device='cuda:0') torch.Size([16])
percent tensor([0.7006, 0.6680, 0.7906, 0.7940, 0.8224, 0.8084, 0.7424, 0.7783, 0.7412,
        0.7166, 0.7139, 0.7584, 0.6986, 0.7180, 0.7306, 0.7414],
       device='cuda:0') torch.Size([16])
percent tensor([0.5115, 0.7313, 0.6909, 0.7010, 0.6761, 0.6127, 0.5316, 0.5483, 0.7102,
        0.6576, 0.7670, 0.6593, 0.6909, 0.6105, 0.5480, 0.4144],
       device='cuda:0') torch.Size([16])
percent tensor([0.9998, 0.9999, 0.9998, 0.9999, 0.9998, 0.9997, 0.9998, 0.9995, 0.9998,
        0.9999, 1.0000, 0.9999, 0.9999, 0.9996, 0.9994, 0.9994],
       device='cuda:0') torch.Size([16])
Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 3, 3, 3]) tensor(194.9766, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(833.7877, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(843.7758, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([128, 64, 3, 3]) tensor(1527.9570, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([128, 64, 1, 1]) tensor(473.0264, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([128, 128, 3, 3]) tensor(2353.5212, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([256, 128, 3, 3]) tensor(4274.6294, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([256, 128, 1, 1]) tensor(1335.0149, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([256, 256, 3, 3]) tensor(6355.0166, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([512, 256, 3, 3]) tensor(11471.1318, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([512, 256, 1, 1]) tensor(3761.7776, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([512, 512, 3, 3]) tensor(15864.0977, device='cuda:0', grad_fn=<NormBackward0>)
Epoch: 221 | Batch_idx: 0 |  Loss: (0.0293) |  Loss2: (0.0000) | Acc: (99.00%) (127/128)
Epoch: 221 | Batch_idx: 10 |  Loss: (0.0561) |  Loss2: (0.0000) | Acc: (98.00%) (1381/1408)
Epoch: 221 | Batch_idx: 20 |  Loss: (0.0460) |  Loss2: (0.0000) | Acc: (98.00%) (2644/2688)
Epoch: 221 | Batch_idx: 30 |  Loss: (0.0441) |  Loss2: (0.0000) | Acc: (98.00%) (3904/3968)
Epoch: 221 | Batch_idx: 40 |  Loss: (0.0450) |  Loss2: (0.0000) | Acc: (98.00%) (5165/5248)
Epoch: 221 | Batch_idx: 50 |  Loss: (0.0456) |  Loss2: (0.0000) | Acc: (98.00%) (6428/6528)
Epoch: 221 | Batch_idx: 60 |  Loss: (0.0449) |  Loss2: (0.0000) | Acc: (98.00%) (7692/7808)
Epoch: 221 | Batch_idx: 70 |  Loss: (0.0449) |  Loss2: (0.0000) | Acc: (98.00%) (8954/9088)
Epoch: 221 | Batch_idx: 80 |  Loss: (0.0466) |  Loss2: (0.0000) | Acc: (98.00%) (10208/10368)
Epoch: 221 | Batch_idx: 90 |  Loss: (0.0479) |  Loss2: (0.0000) | Acc: (98.00%) (11461/11648)
Epoch: 221 | Batch_idx: 100 |  Loss: (0.0467) |  Loss2: (0.0000) | Acc: (98.00%) (12731/12928)
Epoch: 221 | Batch_idx: 110 |  Loss: (0.0470) |  Loss2: (0.0000) | Acc: (98.00%) (13990/14208)
Epoch: 221 | Batch_idx: 120 |  Loss: (0.0473) |  Loss2: (0.0000) | Acc: (98.00%) (15250/15488)
Epoch: 221 | Batch_idx: 130 |  Loss: (0.0470) |  Loss2: (0.0000) | Acc: (98.00%) (16511/16768)
Epoch: 221 | Batch_idx: 140 |  Loss: (0.0470) |  Loss2: (0.0000) | Acc: (98.00%) (17773/18048)
Epoch: 221 | Batch_idx: 150 |  Loss: (0.0478) |  Loss2: (0.0000) | Acc: (98.00%) (19022/19328)
Epoch: 221 | Batch_idx: 160 |  Loss: (0.0483) |  Loss2: (0.0000) | Acc: (98.00%) (20279/20608)
Epoch: 221 | Batch_idx: 170 |  Loss: (0.0481) |  Loss2: (0.0000) | Acc: (98.00%) (21543/21888)
Epoch: 221 | Batch_idx: 180 |  Loss: (0.0477) |  Loss2: (0.0000) | Acc: (98.00%) (22808/23168)
Epoch: 221 | Batch_idx: 190 |  Loss: (0.0477) |  Loss2: (0.0000) | Acc: (98.00%) (24068/24448)
Epoch: 221 | Batch_idx: 200 |  Loss: (0.0476) |  Loss2: (0.0000) | Acc: (98.00%) (25332/25728)
Epoch: 221 | Batch_idx: 210 |  Loss: (0.0476) |  Loss2: (0.0000) | Acc: (98.00%) (26593/27008)
Epoch: 221 | Batch_idx: 220 |  Loss: (0.0475) |  Loss2: (0.0000) | Acc: (98.00%) (27849/28288)
Epoch: 221 | Batch_idx: 230 |  Loss: (0.0476) |  Loss2: (0.0000) | Acc: (98.00%) (29107/29568)
Epoch: 221 | Batch_idx: 240 |  Loss: (0.0473) |  Loss2: (0.0000) | Acc: (98.00%) (30374/30848)
Epoch: 221 | Batch_idx: 250 |  Loss: (0.0473) |  Loss2: (0.0000) | Acc: (98.00%) (31636/32128)
Epoch: 221 | Batch_idx: 260 |  Loss: (0.0472) |  Loss2: (0.0000) | Acc: (98.00%) (32900/33408)
Epoch: 221 | Batch_idx: 270 |  Loss: (0.0472) |  Loss2: (0.0000) | Acc: (98.00%) (34160/34688)
Epoch: 221 | Batch_idx: 280 |  Loss: (0.0472) |  Loss2: (0.0000) | Acc: (98.00%) (35416/35968)
Epoch: 221 | Batch_idx: 290 |  Loss: (0.0472) |  Loss2: (0.0000) | Acc: (98.00%) (36679/37248)
Epoch: 221 | Batch_idx: 300 |  Loss: (0.0471) |  Loss2: (0.0000) | Acc: (98.00%) (37943/38528)
Epoch: 221 | Batch_idx: 310 |  Loss: (0.0469) |  Loss2: (0.0000) | Acc: (98.00%) (39205/39808)
Epoch: 221 | Batch_idx: 320 |  Loss: (0.0470) |  Loss2: (0.0000) | Acc: (98.00%) (40463/41088)
Epoch: 221 | Batch_idx: 330 |  Loss: (0.0467) |  Loss2: (0.0000) | Acc: (98.00%) (41729/42368)
Epoch: 221 | Batch_idx: 340 |  Loss: (0.0470) |  Loss2: (0.0000) | Acc: (98.00%) (42987/43648)
Epoch: 221 | Batch_idx: 350 |  Loss: (0.0470) |  Loss2: (0.0000) | Acc: (98.00%) (44244/44928)
Epoch: 221 | Batch_idx: 360 |  Loss: (0.0473) |  Loss2: (0.0000) | Acc: (98.00%) (45499/46208)
Epoch: 221 | Batch_idx: 370 |  Loss: (0.0476) |  Loss2: (0.0000) | Acc: (98.00%) (46750/47488)
Epoch: 221 | Batch_idx: 380 |  Loss: (0.0477) |  Loss2: (0.0000) | Acc: (98.00%) (48005/48768)
Epoch: 221 | Batch_idx: 390 |  Loss: (0.0481) |  Loss2: (0.0000) | Acc: (98.00%) (49216/50000)
# TEST : Loss: (0.4530) | Acc: (88.00%) (8893/10000)
percent tensor([0.5230, 0.5277, 0.5406, 0.5257, 0.5402, 0.5234, 0.5320, 0.5308, 0.5281,
        0.5308, 0.5282, 0.5377, 0.5240, 0.5207, 0.5265, 0.5221],
       device='cuda:0') torch.Size([16])
percent tensor([0.5146, 0.4868, 0.5124, 0.5197, 0.5073, 0.5261, 0.4897, 0.5021, 0.5188,
        0.4942, 0.5156, 0.5022, 0.4965, 0.5070, 0.5021, 0.5146],
       device='cuda:0') torch.Size([16])
percent tensor([0.6561, 0.6710, 0.5938, 0.5647, 0.5958, 0.6156, 0.6771, 0.6069, 0.5961,
        0.6296, 0.6241, 0.6025, 0.6927, 0.6008, 0.6716, 0.6484],
       device='cuda:0') torch.Size([16])
percent tensor([0.6496, 0.6878, 0.6347, 0.6992, 0.6663, 0.7432, 0.6726, 0.6272, 0.6964,
        0.6690, 0.6923, 0.6973, 0.6637, 0.7165, 0.7128, 0.6821],
       device='cuda:0') torch.Size([16])
percent tensor([0.6302, 0.6489, 0.6297, 0.5948, 0.6586, 0.6463, 0.6502, 0.5724, 0.7001,
        0.6774, 0.6997, 0.5606, 0.6300, 0.7554, 0.5037, 0.6726],
       device='cuda:0') torch.Size([16])
percent tensor([0.6931, 0.6719, 0.8008, 0.7936, 0.8247, 0.7992, 0.7417, 0.7833, 0.7466,
        0.7223, 0.7046, 0.7647, 0.6953, 0.7314, 0.7263, 0.7400],
       device='cuda:0') torch.Size([16])
percent tensor([0.5126, 0.7530, 0.6841, 0.6813, 0.6502, 0.5800, 0.5318, 0.5504, 0.7147,
        0.6636, 0.7847, 0.6865, 0.7028, 0.6424, 0.5407, 0.4060],
       device='cuda:0') torch.Size([16])
percent tensor([0.9998, 0.9999, 0.9998, 1.0000, 0.9998, 0.9996, 0.9999, 0.9995, 0.9999,
        0.9999, 1.0000, 0.9999, 1.0000, 0.9997, 0.9991, 0.9996],
       device='cuda:0') torch.Size([16])
Epoch: 222 | Batch_idx: 0 |  Loss: (0.0298) |  Loss2: (0.0000) | Acc: (99.00%) (127/128)
Epoch: 222 | Batch_idx: 10 |  Loss: (0.0557) |  Loss2: (0.0000) | Acc: (98.00%) (1383/1408)
Epoch: 222 | Batch_idx: 20 |  Loss: (0.0521) |  Loss2: (0.0000) | Acc: (98.00%) (2642/2688)
Epoch: 222 | Batch_idx: 30 |  Loss: (0.0526) |  Loss2: (0.0000) | Acc: (98.00%) (3901/3968)
Epoch: 222 | Batch_idx: 40 |  Loss: (0.0500) |  Loss2: (0.0000) | Acc: (98.00%) (5166/5248)
Epoch: 222 | Batch_idx: 50 |  Loss: (0.0463) |  Loss2: (0.0000) | Acc: (98.00%) (6437/6528)
Epoch: 222 | Batch_idx: 60 |  Loss: (0.0457) |  Loss2: (0.0000) | Acc: (98.00%) (7697/7808)
Epoch: 222 | Batch_idx: 70 |  Loss: (0.0445) |  Loss2: (0.0000) | Acc: (98.00%) (8961/9088)
Epoch: 222 | Batch_idx: 80 |  Loss: (0.0441) |  Loss2: (0.0000) | Acc: (98.00%) (10222/10368)
Epoch: 222 | Batch_idx: 90 |  Loss: (0.0443) |  Loss2: (0.0000) | Acc: (98.00%) (11483/11648)
Epoch: 222 | Batch_idx: 100 |  Loss: (0.0448) |  Loss2: (0.0000) | Acc: (98.00%) (12740/12928)
Epoch: 222 | Batch_idx: 110 |  Loss: (0.0454) |  Loss2: (0.0000) | Acc: (98.00%) (13999/14208)
Epoch: 222 | Batch_idx: 120 |  Loss: (0.0445) |  Loss2: (0.0000) | Acc: (98.00%) (15264/15488)
Epoch: 222 | Batch_idx: 130 |  Loss: (0.0449) |  Loss2: (0.0000) | Acc: (98.00%) (16517/16768)
Epoch: 222 | Batch_idx: 140 |  Loss: (0.0442) |  Loss2: (0.0000) | Acc: (98.00%) (17781/18048)
Epoch: 222 | Batch_idx: 150 |  Loss: (0.0442) |  Loss2: (0.0000) | Acc: (98.00%) (19042/19328)
Epoch: 222 | Batch_idx: 160 |  Loss: (0.0446) |  Loss2: (0.0000) | Acc: (98.00%) (20298/20608)
Epoch: 222 | Batch_idx: 170 |  Loss: (0.0442) |  Loss2: (0.0000) | Acc: (98.00%) (21564/21888)
Epoch: 222 | Batch_idx: 180 |  Loss: (0.0442) |  Loss2: (0.0000) | Acc: (98.00%) (22826/23168)
Epoch: 222 | Batch_idx: 190 |  Loss: (0.0447) |  Loss2: (0.0000) | Acc: (98.00%) (24080/24448)
Epoch: 222 | Batch_idx: 200 |  Loss: (0.0452) |  Loss2: (0.0000) | Acc: (98.00%) (25335/25728)
Epoch: 222 | Batch_idx: 210 |  Loss: (0.0451) |  Loss2: (0.0000) | Acc: (98.00%) (26597/27008)
Epoch: 222 | Batch_idx: 220 |  Loss: (0.0449) |  Loss2: (0.0000) | Acc: (98.00%) (27864/28288)
Epoch: 222 | Batch_idx: 230 |  Loss: (0.0448) |  Loss2: (0.0000) | Acc: (98.00%) (29128/29568)
Epoch: 222 | Batch_idx: 240 |  Loss: (0.0445) |  Loss2: (0.0000) | Acc: (98.00%) (30394/30848)
Epoch: 222 | Batch_idx: 250 |  Loss: (0.0447) |  Loss2: (0.0000) | Acc: (98.00%) (31650/32128)
Epoch: 222 | Batch_idx: 260 |  Loss: (0.0451) |  Loss2: (0.0000) | Acc: (98.00%) (32907/33408)
Epoch: 222 | Batch_idx: 270 |  Loss: (0.0454) |  Loss2: (0.0000) | Acc: (98.00%) (34157/34688)
Epoch: 222 | Batch_idx: 280 |  Loss: (0.0459) |  Loss2: (0.0000) | Acc: (98.00%) (35410/35968)
Epoch: 222 | Batch_idx: 290 |  Loss: (0.0458) |  Loss2: (0.0000) | Acc: (98.00%) (36672/37248)
Epoch: 222 | Batch_idx: 300 |  Loss: (0.0459) |  Loss2: (0.0000) | Acc: (98.00%) (37935/38528)
Epoch: 222 | Batch_idx: 310 |  Loss: (0.0458) |  Loss2: (0.0000) | Acc: (98.00%) (39195/39808)
Epoch: 222 | Batch_idx: 320 |  Loss: (0.0460) |  Loss2: (0.0000) | Acc: (98.00%) (40451/41088)
Epoch: 222 | Batch_idx: 330 |  Loss: (0.0458) |  Loss2: (0.0000) | Acc: (98.00%) (41713/42368)
Epoch: 222 | Batch_idx: 340 |  Loss: (0.0457) |  Loss2: (0.0000) | Acc: (98.00%) (42979/43648)
Epoch: 222 | Batch_idx: 350 |  Loss: (0.0456) |  Loss2: (0.0000) | Acc: (98.00%) (44244/44928)
Epoch: 222 | Batch_idx: 360 |  Loss: (0.0458) |  Loss2: (0.0000) | Acc: (98.00%) (45502/46208)
Epoch: 222 | Batch_idx: 370 |  Loss: (0.0459) |  Loss2: (0.0000) | Acc: (98.00%) (46758/47488)
Epoch: 222 | Batch_idx: 380 |  Loss: (0.0462) |  Loss2: (0.0000) | Acc: (98.00%) (48013/48768)
Epoch: 222 | Batch_idx: 390 |  Loss: (0.0462) |  Loss2: (0.0000) | Acc: (98.00%) (49226/50000)
# TEST : Loss: (0.4844) | Acc: (88.00%) (8810/10000)
percent tensor([0.5256, 0.5294, 0.5433, 0.5279, 0.5437, 0.5258, 0.5344, 0.5333, 0.5301,
        0.5335, 0.5299, 0.5410, 0.5265, 0.5209, 0.5286, 0.5240],
       device='cuda:0') torch.Size([16])
percent tensor([0.5158, 0.4879, 0.5128, 0.5186, 0.5101, 0.5261, 0.4931, 0.5011, 0.5201,
        0.4947, 0.5174, 0.5040, 0.4975, 0.5077, 0.5030, 0.5144],
       device='cuda:0') torch.Size([16])
percent tensor([0.6695, 0.6745, 0.6013, 0.5741, 0.6020, 0.6220, 0.6800, 0.6143, 0.5981,
        0.6336, 0.6274, 0.6078, 0.7019, 0.5951, 0.6792, 0.6600],
       device='cuda:0') torch.Size([16])
percent tensor([0.6571, 0.6865, 0.6420, 0.6985, 0.6707, 0.7392, 0.6756, 0.6275, 0.6989,
        0.6694, 0.7015, 0.6982, 0.6644, 0.7145, 0.7146, 0.6882],
       device='cuda:0') torch.Size([16])
percent tensor([0.6390, 0.6588, 0.6398, 0.6098, 0.6694, 0.6593, 0.6583, 0.5913, 0.7092,
        0.6811, 0.7072, 0.5665, 0.6346, 0.7646, 0.5158, 0.6789],
       device='cuda:0') torch.Size([16])
percent tensor([0.7023, 0.6704, 0.7979, 0.7911, 0.8219, 0.8013, 0.7429, 0.7828, 0.7473,
        0.7264, 0.7171, 0.7584, 0.6877, 0.7255, 0.7323, 0.7416],
       device='cuda:0') torch.Size([16])
percent tensor([0.5136, 0.7508, 0.7164, 0.6965, 0.6813, 0.6142, 0.5504, 0.5819, 0.7189,
        0.6605, 0.7692, 0.6975, 0.7055, 0.6315, 0.5646, 0.4092],
       device='cuda:0') torch.Size([16])
percent tensor([0.9998, 0.9999, 0.9999, 1.0000, 0.9999, 0.9998, 0.9999, 0.9996, 0.9999,
        0.9999, 1.0000, 0.9999, 1.0000, 0.9998, 0.9993, 0.9995],
       device='cuda:0') torch.Size([16])
Epoch: 223 | Batch_idx: 0 |  Loss: (0.0869) |  Loss2: (0.0000) | Acc: (96.00%) (123/128)
Epoch: 223 | Batch_idx: 10 |  Loss: (0.0575) |  Loss2: (0.0000) | Acc: (98.00%) (1380/1408)
Epoch: 223 | Batch_idx: 20 |  Loss: (0.0497) |  Loss2: (0.0000) | Acc: (98.00%) (2646/2688)
Epoch: 223 | Batch_idx: 30 |  Loss: (0.0470) |  Loss2: (0.0000) | Acc: (98.00%) (3909/3968)
Epoch: 223 | Batch_idx: 40 |  Loss: (0.0470) |  Loss2: (0.0000) | Acc: (98.00%) (5168/5248)
Epoch: 223 | Batch_idx: 50 |  Loss: (0.0452) |  Loss2: (0.0000) | Acc: (98.00%) (6433/6528)
Epoch: 223 | Batch_idx: 60 |  Loss: (0.0435) |  Loss2: (0.0000) | Acc: (98.00%) (7698/7808)
Epoch: 223 | Batch_idx: 70 |  Loss: (0.0428) |  Loss2: (0.0000) | Acc: (98.00%) (8964/9088)
Epoch: 223 | Batch_idx: 80 |  Loss: (0.0440) |  Loss2: (0.0000) | Acc: (98.00%) (10223/10368)
Epoch: 223 | Batch_idx: 90 |  Loss: (0.0442) |  Loss2: (0.0000) | Acc: (98.00%) (11479/11648)
Epoch: 223 | Batch_idx: 100 |  Loss: (0.0439) |  Loss2: (0.0000) | Acc: (98.00%) (12746/12928)
Epoch: 223 | Batch_idx: 110 |  Loss: (0.0437) |  Loss2: (0.0000) | Acc: (98.00%) (14006/14208)
Epoch: 223 | Batch_idx: 120 |  Loss: (0.0436) |  Loss2: (0.0000) | Acc: (98.00%) (15272/15488)
Epoch: 223 | Batch_idx: 130 |  Loss: (0.0446) |  Loss2: (0.0000) | Acc: (98.00%) (16529/16768)
Epoch: 223 | Batch_idx: 140 |  Loss: (0.0449) |  Loss2: (0.0000) | Acc: (98.00%) (17794/18048)
Epoch: 223 | Batch_idx: 150 |  Loss: (0.0451) |  Loss2: (0.0000) | Acc: (98.00%) (19054/19328)
Epoch: 223 | Batch_idx: 160 |  Loss: (0.0448) |  Loss2: (0.0000) | Acc: (98.00%) (20321/20608)
Epoch: 223 | Batch_idx: 170 |  Loss: (0.0448) |  Loss2: (0.0000) | Acc: (98.00%) (21585/21888)
Epoch: 223 | Batch_idx: 180 |  Loss: (0.0448) |  Loss2: (0.0000) | Acc: (98.00%) (22846/23168)
Epoch: 223 | Batch_idx: 190 |  Loss: (0.0448) |  Loss2: (0.0000) | Acc: (98.00%) (24101/24448)
Epoch: 223 | Batch_idx: 200 |  Loss: (0.0443) |  Loss2: (0.0000) | Acc: (98.00%) (25363/25728)
Epoch: 223 | Batch_idx: 210 |  Loss: (0.0437) |  Loss2: (0.0000) | Acc: (98.00%) (26632/27008)
Epoch: 223 | Batch_idx: 220 |  Loss: (0.0431) |  Loss2: (0.0000) | Acc: (98.00%) (27904/28288)
Epoch: 223 | Batch_idx: 230 |  Loss: (0.0431) |  Loss2: (0.0000) | Acc: (98.00%) (29162/29568)
Epoch: 223 | Batch_idx: 240 |  Loss: (0.0430) |  Loss2: (0.0000) | Acc: (98.00%) (30425/30848)
Epoch: 223 | Batch_idx: 250 |  Loss: (0.0427) |  Loss2: (0.0000) | Acc: (98.00%) (31689/32128)
Epoch: 223 | Batch_idx: 260 |  Loss: (0.0427) |  Loss2: (0.0000) | Acc: (98.00%) (32948/33408)
Epoch: 223 | Batch_idx: 270 |  Loss: (0.0429) |  Loss2: (0.0000) | Acc: (98.00%) (34209/34688)
Epoch: 223 | Batch_idx: 280 |  Loss: (0.0434) |  Loss2: (0.0000) | Acc: (98.00%) (35464/35968)
Epoch: 223 | Batch_idx: 290 |  Loss: (0.0435) |  Loss2: (0.0000) | Acc: (98.00%) (36722/37248)
Epoch: 223 | Batch_idx: 300 |  Loss: (0.0435) |  Loss2: (0.0000) | Acc: (98.00%) (37986/38528)
Epoch: 223 | Batch_idx: 310 |  Loss: (0.0436) |  Loss2: (0.0000) | Acc: (98.00%) (39250/39808)
Epoch: 223 | Batch_idx: 320 |  Loss: (0.0435) |  Loss2: (0.0000) | Acc: (98.00%) (40512/41088)
Epoch: 223 | Batch_idx: 330 |  Loss: (0.0432) |  Loss2: (0.0000) | Acc: (98.00%) (41778/42368)
Epoch: 223 | Batch_idx: 340 |  Loss: (0.0433) |  Loss2: (0.0000) | Acc: (98.00%) (43039/43648)
Epoch: 223 | Batch_idx: 350 |  Loss: (0.0434) |  Loss2: (0.0000) | Acc: (98.00%) (44299/44928)
Epoch: 223 | Batch_idx: 360 |  Loss: (0.0431) |  Loss2: (0.0000) | Acc: (98.00%) (45567/46208)
Epoch: 223 | Batch_idx: 370 |  Loss: (0.0432) |  Loss2: (0.0000) | Acc: (98.00%) (46830/47488)
Epoch: 223 | Batch_idx: 380 |  Loss: (0.0431) |  Loss2: (0.0000) | Acc: (98.00%) (48091/48768)
Epoch: 223 | Batch_idx: 390 |  Loss: (0.0433) |  Loss2: (0.0000) | Acc: (98.00%) (49303/50000)
# TEST : Loss: (0.4387) | Acc: (89.00%) (8916/10000)
percent tensor([0.5249, 0.5305, 0.5410, 0.5264, 0.5415, 0.5244, 0.5347, 0.5325, 0.5308,
        0.5330, 0.5306, 0.5390, 0.5262, 0.5241, 0.5285, 0.5238],
       device='cuda:0') torch.Size([16])
percent tensor([0.5117, 0.4873, 0.5113, 0.5180, 0.5064, 0.5251, 0.4908, 0.5015, 0.5168,
        0.4939, 0.5144, 0.5019, 0.4951, 0.5064, 0.5012, 0.5129],
       device='cuda:0') torch.Size([16])
percent tensor([0.6658, 0.6785, 0.5872, 0.5608, 0.5937, 0.6213, 0.6846, 0.6098, 0.6067,
        0.6330, 0.6371, 0.6018, 0.7016, 0.6135, 0.6764, 0.6565],
       device='cuda:0') torch.Size([16])
percent tensor([0.6537, 0.6812, 0.6420, 0.7001, 0.6665, 0.7477, 0.6712, 0.6300, 0.6969,
        0.6645, 0.6928, 0.7009, 0.6620, 0.7161, 0.7165, 0.6862],
       device='cuda:0') torch.Size([16])
percent tensor([0.6249, 0.6490, 0.6266, 0.6039, 0.6539, 0.6420, 0.6466, 0.5789, 0.6843,
        0.6688, 0.6917, 0.5547, 0.6275, 0.7506, 0.5136, 0.6752],
       device='cuda:0') torch.Size([16])
percent tensor([0.6989, 0.6616, 0.7888, 0.7846, 0.8165, 0.7935, 0.7358, 0.7833, 0.7296,
        0.7209, 0.7081, 0.7573, 0.6956, 0.7171, 0.7251, 0.7393],
       device='cuda:0') torch.Size([16])
percent tensor([0.5345, 0.7364, 0.6828, 0.6672, 0.6513, 0.5952, 0.5217, 0.5629, 0.7177,
        0.6539, 0.7709, 0.6783, 0.7078, 0.6283, 0.5496, 0.4080],
       device='cuda:0') torch.Size([16])
percent tensor([0.9998, 0.9999, 0.9999, 1.0000, 0.9999, 0.9998, 0.9998, 0.9997, 0.9999,
        0.9999, 1.0000, 0.9999, 1.0000, 0.9997, 0.9994, 0.9996],
       device='cuda:0') torch.Size([16])
Epoch: 224 | Batch_idx: 0 |  Loss: (0.0425) |  Loss2: (0.0000) | Acc: (98.00%) (126/128)
Epoch: 224 | Batch_idx: 10 |  Loss: (0.0488) |  Loss2: (0.0000) | Acc: (98.00%) (1383/1408)
Epoch: 224 | Batch_idx: 20 |  Loss: (0.0458) |  Loss2: (0.0000) | Acc: (98.00%) (2641/2688)
Epoch: 224 | Batch_idx: 30 |  Loss: (0.0499) |  Loss2: (0.0000) | Acc: (98.00%) (3893/3968)
Epoch: 224 | Batch_idx: 40 |  Loss: (0.0486) |  Loss2: (0.0000) | Acc: (98.00%) (5154/5248)
Epoch: 224 | Batch_idx: 50 |  Loss: (0.0473) |  Loss2: (0.0000) | Acc: (98.00%) (6421/6528)
Epoch: 224 | Batch_idx: 60 |  Loss: (0.0498) |  Loss2: (0.0000) | Acc: (98.00%) (7670/7808)
Epoch: 224 | Batch_idx: 70 |  Loss: (0.0481) |  Loss2: (0.0000) | Acc: (98.00%) (8935/9088)
Epoch: 224 | Batch_idx: 80 |  Loss: (0.0478) |  Loss2: (0.0000) | Acc: (98.00%) (10200/10368)
Epoch: 224 | Batch_idx: 90 |  Loss: (0.0473) |  Loss2: (0.0000) | Acc: (98.00%) (11467/11648)
Epoch: 224 | Batch_idx: 100 |  Loss: (0.0474) |  Loss2: (0.0000) | Acc: (98.00%) (12729/12928)
Epoch: 224 | Batch_idx: 110 |  Loss: (0.0476) |  Loss2: (0.0000) | Acc: (98.00%) (13986/14208)
Epoch: 224 | Batch_idx: 120 |  Loss: (0.0466) |  Loss2: (0.0000) | Acc: (98.00%) (15253/15488)
Epoch: 224 | Batch_idx: 130 |  Loss: (0.0462) |  Loss2: (0.0000) | Acc: (98.00%) (16516/16768)
Epoch: 224 | Batch_idx: 140 |  Loss: (0.0454) |  Loss2: (0.0000) | Acc: (98.00%) (17784/18048)
Epoch: 224 | Batch_idx: 150 |  Loss: (0.0457) |  Loss2: (0.0000) | Acc: (98.00%) (19042/19328)
Epoch: 224 | Batch_idx: 160 |  Loss: (0.0459) |  Loss2: (0.0000) | Acc: (98.00%) (20301/20608)
Epoch: 224 | Batch_idx: 170 |  Loss: (0.0452) |  Loss2: (0.0000) | Acc: (98.00%) (21568/21888)
Epoch: 224 | Batch_idx: 180 |  Loss: (0.0447) |  Loss2: (0.0000) | Acc: (98.00%) (22838/23168)
Epoch: 224 | Batch_idx: 190 |  Loss: (0.0448) |  Loss2: (0.0000) | Acc: (98.00%) (24096/24448)
Epoch: 224 | Batch_idx: 200 |  Loss: (0.0453) |  Loss2: (0.0000) | Acc: (98.00%) (25357/25728)
Epoch: 224 | Batch_idx: 210 |  Loss: (0.0450) |  Loss2: (0.0000) | Acc: (98.00%) (26626/27008)
Epoch: 224 | Batch_idx: 220 |  Loss: (0.0448) |  Loss2: (0.0000) | Acc: (98.00%) (27891/28288)
Epoch: 224 | Batch_idx: 230 |  Loss: (0.0449) |  Loss2: (0.0000) | Acc: (98.00%) (29151/29568)
Epoch: 224 | Batch_idx: 240 |  Loss: (0.0446) |  Loss2: (0.0000) | Acc: (98.00%) (30418/30848)
Epoch: 224 | Batch_idx: 250 |  Loss: (0.0445) |  Loss2: (0.0000) | Acc: (98.00%) (31683/32128)
Epoch: 224 | Batch_idx: 260 |  Loss: (0.0444) |  Loss2: (0.0000) | Acc: (98.00%) (32951/33408)
Epoch: 224 | Batch_idx: 270 |  Loss: (0.0446) |  Loss2: (0.0000) | Acc: (98.00%) (34214/34688)
Epoch: 224 | Batch_idx: 280 |  Loss: (0.0446) |  Loss2: (0.0000) | Acc: (98.00%) (35474/35968)
Epoch: 224 | Batch_idx: 290 |  Loss: (0.0445) |  Loss2: (0.0000) | Acc: (98.00%) (36737/37248)
Epoch: 224 | Batch_idx: 300 |  Loss: (0.0448) |  Loss2: (0.0000) | Acc: (98.00%) (37990/38528)
Epoch: 224 | Batch_idx: 310 |  Loss: (0.0449) |  Loss2: (0.0000) | Acc: (98.00%) (39250/39808)
Epoch: 224 | Batch_idx: 320 |  Loss: (0.0452) |  Loss2: (0.0000) | Acc: (98.00%) (40504/41088)
Epoch: 224 | Batch_idx: 330 |  Loss: (0.0453) |  Loss2: (0.0000) | Acc: (98.00%) (41761/42368)
Epoch: 224 | Batch_idx: 340 |  Loss: (0.0456) |  Loss2: (0.0000) | Acc: (98.00%) (43020/43648)
Epoch: 224 | Batch_idx: 350 |  Loss: (0.0459) |  Loss2: (0.0000) | Acc: (98.00%) (44274/44928)
Epoch: 224 | Batch_idx: 360 |  Loss: (0.0458) |  Loss2: (0.0000) | Acc: (98.00%) (45539/46208)
Epoch: 224 | Batch_idx: 370 |  Loss: (0.0459) |  Loss2: (0.0000) | Acc: (98.00%) (46800/47488)
Epoch: 224 | Batch_idx: 380 |  Loss: (0.0457) |  Loss2: (0.0000) | Acc: (98.00%) (48064/48768)
Epoch: 224 | Batch_idx: 390 |  Loss: (0.0457) |  Loss2: (0.0000) | Acc: (98.00%) (49275/50000)
# TEST : Loss: (0.4718) | Acc: (88.00%) (8886/10000)
percent tensor([0.5249, 0.5300, 0.5415, 0.5264, 0.5417, 0.5245, 0.5342, 0.5324, 0.5304,
        0.5329, 0.5305, 0.5391, 0.5261, 0.5230, 0.5282, 0.5238],
       device='cuda:0') torch.Size([16])
percent tensor([0.5124, 0.4874, 0.5118, 0.5166, 0.5060, 0.5246, 0.4915, 0.5017, 0.5167,
        0.4944, 0.5140, 0.5018, 0.4953, 0.5081, 0.5002, 0.5125],
       device='cuda:0') torch.Size([16])
percent tensor([0.6623, 0.6728, 0.5958, 0.5614, 0.5983, 0.6187, 0.6778, 0.6068, 0.5977,
        0.6315, 0.6277, 0.6037, 0.6968, 0.5887, 0.6718, 0.6505],
       device='cuda:0') torch.Size([16])
percent tensor([0.6562, 0.6846, 0.6465, 0.7096, 0.6707, 0.7486, 0.6782, 0.6336, 0.6976,
        0.6677, 0.6930, 0.7026, 0.6659, 0.7223, 0.7215, 0.6918],
       device='cuda:0') torch.Size([16])
percent tensor([0.6207, 0.6458, 0.6296, 0.6044, 0.6588, 0.6570, 0.6471, 0.5807, 0.6932,
        0.6682, 0.6992, 0.5615, 0.6243, 0.7685, 0.5163, 0.6781],
       device='cuda:0') torch.Size([16])
percent tensor([0.7084, 0.6766, 0.7946, 0.7941, 0.8231, 0.8031, 0.7410, 0.7814, 0.7439,
        0.7284, 0.7100, 0.7544, 0.6967, 0.7302, 0.7372, 0.7474],
       device='cuda:0') torch.Size([16])
percent tensor([0.5317, 0.7713, 0.6851, 0.6862, 0.6590, 0.5892, 0.5171, 0.5670, 0.7225,
        0.6817, 0.7664, 0.6907, 0.7087, 0.6192, 0.5644, 0.4025],
       device='cuda:0') torch.Size([16])
percent tensor([0.9999, 0.9999, 0.9998, 0.9999, 0.9998, 0.9997, 0.9997, 0.9996, 0.9999,
        0.9999, 1.0000, 0.9999, 0.9999, 0.9996, 0.9994, 0.9995],
       device='cuda:0') torch.Size([16])
Epoch: 225 | Batch_idx: 0 |  Loss: (0.0189) |  Loss2: (0.0000) | Acc: (100.00%) (128/128)
Epoch: 225 | Batch_idx: 10 |  Loss: (0.0323) |  Loss2: (0.0000) | Acc: (99.00%) (1394/1408)
Epoch: 225 | Batch_idx: 20 |  Loss: (0.0362) |  Loss2: (0.0000) | Acc: (98.00%) (2660/2688)
Epoch: 225 | Batch_idx: 30 |  Loss: (0.0381) |  Loss2: (0.0000) | Acc: (98.00%) (3922/3968)
Epoch: 225 | Batch_idx: 40 |  Loss: (0.0384) |  Loss2: (0.0000) | Acc: (98.00%) (5189/5248)
Epoch: 225 | Batch_idx: 50 |  Loss: (0.0388) |  Loss2: (0.0000) | Acc: (98.00%) (6454/6528)
Epoch: 225 | Batch_idx: 60 |  Loss: (0.0386) |  Loss2: (0.0000) | Acc: (98.00%) (7719/7808)
Epoch: 225 | Batch_idx: 70 |  Loss: (0.0402) |  Loss2: (0.0000) | Acc: (98.00%) (8979/9088)
Epoch: 225 | Batch_idx: 80 |  Loss: (0.0406) |  Loss2: (0.0000) | Acc: (98.00%) (10239/10368)
Epoch: 225 | Batch_idx: 90 |  Loss: (0.0401) |  Loss2: (0.0000) | Acc: (98.00%) (11507/11648)
Epoch: 225 | Batch_idx: 100 |  Loss: (0.0404) |  Loss2: (0.0000) | Acc: (98.00%) (12771/12928)
Epoch: 225 | Batch_idx: 110 |  Loss: (0.0396) |  Loss2: (0.0000) | Acc: (98.00%) (14038/14208)
Epoch: 225 | Batch_idx: 120 |  Loss: (0.0410) |  Loss2: (0.0000) | Acc: (98.00%) (15292/15488)
Epoch: 225 | Batch_idx: 130 |  Loss: (0.0411) |  Loss2: (0.0000) | Acc: (98.00%) (16552/16768)
Epoch: 225 | Batch_idx: 140 |  Loss: (0.0409) |  Loss2: (0.0000) | Acc: (98.00%) (17818/18048)
Epoch: 225 | Batch_idx: 150 |  Loss: (0.0407) |  Loss2: (0.0000) | Acc: (98.00%) (19082/19328)
Epoch: 225 | Batch_idx: 160 |  Loss: (0.0407) |  Loss2: (0.0000) | Acc: (98.00%) (20349/20608)
Epoch: 225 | Batch_idx: 170 |  Loss: (0.0407) |  Loss2: (0.0000) | Acc: (98.00%) (21612/21888)
Epoch: 225 | Batch_idx: 180 |  Loss: (0.0406) |  Loss2: (0.0000) | Acc: (98.00%) (22879/23168)
Epoch: 225 | Batch_idx: 190 |  Loss: (0.0410) |  Loss2: (0.0000) | Acc: (98.00%) (24139/24448)
Epoch: 225 | Batch_idx: 200 |  Loss: (0.0408) |  Loss2: (0.0000) | Acc: (98.00%) (25402/25728)
Epoch: 225 | Batch_idx: 210 |  Loss: (0.0414) |  Loss2: (0.0000) | Acc: (98.00%) (26651/27008)
Epoch: 225 | Batch_idx: 220 |  Loss: (0.0410) |  Loss2: (0.0000) | Acc: (98.00%) (27923/28288)
Epoch: 225 | Batch_idx: 230 |  Loss: (0.0409) |  Loss2: (0.0000) | Acc: (98.00%) (29188/29568)
Epoch: 225 | Batch_idx: 240 |  Loss: (0.0409) |  Loss2: (0.0000) | Acc: (98.00%) (30450/30848)
Epoch: 225 | Batch_idx: 250 |  Loss: (0.0414) |  Loss2: (0.0000) | Acc: (98.00%) (31703/32128)
Epoch: 225 | Batch_idx: 260 |  Loss: (0.0413) |  Loss2: (0.0000) | Acc: (98.00%) (32968/33408)
Epoch: 225 | Batch_idx: 270 |  Loss: (0.0415) |  Loss2: (0.0000) | Acc: (98.00%) (34234/34688)
Epoch: 225 | Batch_idx: 280 |  Loss: (0.0415) |  Loss2: (0.0000) | Acc: (98.00%) (35501/35968)
Epoch: 225 | Batch_idx: 290 |  Loss: (0.0418) |  Loss2: (0.0000) | Acc: (98.00%) (36756/37248)
Epoch: 225 | Batch_idx: 300 |  Loss: (0.0417) |  Loss2: (0.0000) | Acc: (98.00%) (38019/38528)
Epoch: 225 | Batch_idx: 310 |  Loss: (0.0417) |  Loss2: (0.0000) | Acc: (98.00%) (39285/39808)
Epoch: 225 | Batch_idx: 320 |  Loss: (0.0417) |  Loss2: (0.0000) | Acc: (98.00%) (40549/41088)
Epoch: 225 | Batch_idx: 330 |  Loss: (0.0415) |  Loss2: (0.0000) | Acc: (98.00%) (41818/42368)
Epoch: 225 | Batch_idx: 340 |  Loss: (0.0416) |  Loss2: (0.0000) | Acc: (98.00%) (43081/43648)
Epoch: 225 | Batch_idx: 350 |  Loss: (0.0417) |  Loss2: (0.0000) | Acc: (98.00%) (44343/44928)
Epoch: 225 | Batch_idx: 360 |  Loss: (0.0423) |  Loss2: (0.0000) | Acc: (98.00%) (45595/46208)
Epoch: 225 | Batch_idx: 370 |  Loss: (0.0426) |  Loss2: (0.0000) | Acc: (98.00%) (46851/47488)
Epoch: 225 | Batch_idx: 380 |  Loss: (0.0430) |  Loss2: (0.0000) | Acc: (98.00%) (48103/48768)
Epoch: 225 | Batch_idx: 390 |  Loss: (0.0431) |  Loss2: (0.0000) | Acc: (98.00%) (49319/50000)
=> saving checkpoint 'drive/app/torch/save_Schedule/checkpoint_225.pth.tar'
# TEST : Loss: (0.4896) | Acc: (87.00%) (8787/10000)
percent tensor([0.5253, 0.5312, 0.5425, 0.5271, 0.5429, 0.5247, 0.5358, 0.5334, 0.5313,
        0.5343, 0.5311, 0.5406, 0.5267, 0.5248, 0.5291, 0.5245],
       device='cuda:0') torch.Size([16])
percent tensor([0.5126, 0.4891, 0.5128, 0.5188, 0.5077, 0.5254, 0.4932, 0.5038, 0.5195,
        0.4955, 0.5154, 0.5042, 0.4962, 0.5100, 0.5020, 0.5137],
       device='cuda:0') torch.Size([16])
percent tensor([0.6623, 0.6721, 0.6013, 0.5689, 0.5991, 0.6130, 0.6788, 0.6120, 0.5952,
        0.6346, 0.6257, 0.6090, 0.6986, 0.5963, 0.6753, 0.6534],
       device='cuda:0') torch.Size([16])
percent tensor([0.6532, 0.6839, 0.6371, 0.7050, 0.6685, 0.7425, 0.6763, 0.6276, 0.6910,
        0.6693, 0.6912, 0.6983, 0.6614, 0.7186, 0.7153, 0.6946],
       device='cuda:0') torch.Size([16])
percent tensor([0.6395, 0.6579, 0.6322, 0.5948, 0.6604, 0.6711, 0.6529, 0.5757, 0.7065,
        0.6831, 0.7004, 0.5609, 0.6423, 0.7586, 0.5224, 0.6907],
       device='cuda:0') torch.Size([16])
percent tensor([0.7058, 0.6708, 0.8037, 0.7900, 0.8240, 0.8061, 0.7395, 0.7799, 0.7407,
        0.7319, 0.7179, 0.7618, 0.6868, 0.7250, 0.7345, 0.7483],
       device='cuda:0') torch.Size([16])
percent tensor([0.5200, 0.7514, 0.6909, 0.6691, 0.6472, 0.5984, 0.5328, 0.5407, 0.6846,
        0.6394, 0.7731, 0.6817, 0.6746, 0.6445, 0.5703, 0.4019],
       device='cuda:0') torch.Size([16])
percent tensor([0.9999, 0.9999, 0.9998, 1.0000, 0.9995, 0.9997, 0.9998, 0.9995, 0.9998,
        0.9999, 1.0000, 0.9999, 0.9999, 0.9999, 0.9996, 0.9995],
       device='cuda:0') torch.Size([16])
Epoch: 226 | Batch_idx: 0 |  Loss: (0.0352) |  Loss2: (0.0000) | Acc: (99.00%) (127/128)
Epoch: 226 | Batch_idx: 10 |  Loss: (0.0436) |  Loss2: (0.0000) | Acc: (98.00%) (1388/1408)
Epoch: 226 | Batch_idx: 20 |  Loss: (0.0430) |  Loss2: (0.0000) | Acc: (98.00%) (2650/2688)
Epoch: 226 | Batch_idx: 30 |  Loss: (0.0433) |  Loss2: (0.0000) | Acc: (98.00%) (3910/3968)
Epoch: 226 | Batch_idx: 40 |  Loss: (0.0419) |  Loss2: (0.0000) | Acc: (98.00%) (5177/5248)
Epoch: 226 | Batch_idx: 50 |  Loss: (0.0424) |  Loss2: (0.0000) | Acc: (98.00%) (6441/6528)
Epoch: 226 | Batch_idx: 60 |  Loss: (0.0412) |  Loss2: (0.0000) | Acc: (98.00%) (7705/7808)
Epoch: 226 | Batch_idx: 70 |  Loss: (0.0406) |  Loss2: (0.0000) | Acc: (98.00%) (8969/9088)
Epoch: 226 | Batch_idx: 80 |  Loss: (0.0412) |  Loss2: (0.0000) | Acc: (98.00%) (10229/10368)
Epoch: 226 | Batch_idx: 90 |  Loss: (0.0412) |  Loss2: (0.0000) | Acc: (98.00%) (11490/11648)
Epoch: 226 | Batch_idx: 100 |  Loss: (0.0407) |  Loss2: (0.0000) | Acc: (98.00%) (12756/12928)
Epoch: 226 | Batch_idx: 110 |  Loss: (0.0407) |  Loss2: (0.0000) | Acc: (98.00%) (14022/14208)
Epoch: 226 | Batch_idx: 120 |  Loss: (0.0406) |  Loss2: (0.0000) | Acc: (98.00%) (15287/15488)
Epoch: 226 | Batch_idx: 130 |  Loss: (0.0407) |  Loss2: (0.0000) | Acc: (98.00%) (16552/16768)
Epoch: 226 | Batch_idx: 140 |  Loss: (0.0412) |  Loss2: (0.0000) | Acc: (98.00%) (17813/18048)
Epoch: 226 | Batch_idx: 150 |  Loss: (0.0421) |  Loss2: (0.0000) | Acc: (98.00%) (19064/19328)
Epoch: 226 | Batch_idx: 160 |  Loss: (0.0431) |  Loss2: (0.0000) | Acc: (98.00%) (20322/20608)
Epoch: 226 | Batch_idx: 170 |  Loss: (0.0431) |  Loss2: (0.0000) | Acc: (98.00%) (21587/21888)
Epoch: 226 | Batch_idx: 180 |  Loss: (0.0437) |  Loss2: (0.0000) | Acc: (98.00%) (22847/23168)
Epoch: 226 | Batch_idx: 190 |  Loss: (0.0438) |  Loss2: (0.0000) | Acc: (98.00%) (24105/24448)
Epoch: 226 | Batch_idx: 200 |  Loss: (0.0439) |  Loss2: (0.0000) | Acc: (98.00%) (25367/25728)
Epoch: 226 | Batch_idx: 210 |  Loss: (0.0438) |  Loss2: (0.0000) | Acc: (98.00%) (26627/27008)
Epoch: 226 | Batch_idx: 220 |  Loss: (0.0441) |  Loss2: (0.0000) | Acc: (98.00%) (27885/28288)
Epoch: 226 | Batch_idx: 230 |  Loss: (0.0443) |  Loss2: (0.0000) | Acc: (98.00%) (29148/29568)
Epoch: 226 | Batch_idx: 240 |  Loss: (0.0444) |  Loss2: (0.0000) | Acc: (98.00%) (30409/30848)
Epoch: 226 | Batch_idx: 250 |  Loss: (0.0449) |  Loss2: (0.0000) | Acc: (98.00%) (31661/32128)
Epoch: 226 | Batch_idx: 260 |  Loss: (0.0452) |  Loss2: (0.0000) | Acc: (98.00%) (32915/33408)
Epoch: 226 | Batch_idx: 270 |  Loss: (0.0454) |  Loss2: (0.0000) | Acc: (98.00%) (34177/34688)
Epoch: 226 | Batch_idx: 280 |  Loss: (0.0454) |  Loss2: (0.0000) | Acc: (98.00%) (35435/35968)
Epoch: 226 | Batch_idx: 290 |  Loss: (0.0455) |  Loss2: (0.0000) | Acc: (98.00%) (36693/37248)
Epoch: 226 | Batch_idx: 300 |  Loss: (0.0454) |  Loss2: (0.0000) | Acc: (98.00%) (37954/38528)
Epoch: 226 | Batch_idx: 310 |  Loss: (0.0454) |  Loss2: (0.0000) | Acc: (98.00%) (39211/39808)
Epoch: 226 | Batch_idx: 320 |  Loss: (0.0454) |  Loss2: (0.0000) | Acc: (98.00%) (40469/41088)
Epoch: 226 | Batch_idx: 330 |  Loss: (0.0453) |  Loss2: (0.0000) | Acc: (98.00%) (41732/42368)
Epoch: 226 | Batch_idx: 340 |  Loss: (0.0455) |  Loss2: (0.0000) | Acc: (98.00%) (42991/43648)
Epoch: 226 | Batch_idx: 350 |  Loss: (0.0454) |  Loss2: (0.0000) | Acc: (98.00%) (44257/44928)
Epoch: 226 | Batch_idx: 360 |  Loss: (0.0454) |  Loss2: (0.0000) | Acc: (98.00%) (45521/46208)
Epoch: 226 | Batch_idx: 370 |  Loss: (0.0452) |  Loss2: (0.0000) | Acc: (98.00%) (46787/47488)
Epoch: 226 | Batch_idx: 380 |  Loss: (0.0452) |  Loss2: (0.0000) | Acc: (98.00%) (48048/48768)
Epoch: 226 | Batch_idx: 390 |  Loss: (0.0450) |  Loss2: (0.0000) | Acc: (98.00%) (49270/50000)
# TEST : Loss: (0.4685) | Acc: (88.00%) (8883/10000)
percent tensor([0.5258, 0.5317, 0.5424, 0.5279, 0.5430, 0.5252, 0.5363, 0.5339, 0.5316,
        0.5346, 0.5313, 0.5407, 0.5272, 0.5254, 0.5294, 0.5250],
       device='cuda:0') torch.Size([16])
percent tensor([0.5111, 0.4878, 0.5116, 0.5194, 0.5061, 0.5249, 0.4914, 0.5024, 0.5178,
        0.4946, 0.5145, 0.5028, 0.4947, 0.5098, 0.5002, 0.5122],
       device='cuda:0') torch.Size([16])
percent tensor([0.6695, 0.6720, 0.5972, 0.5671, 0.5965, 0.6237, 0.6783, 0.6119, 0.6032,
        0.6326, 0.6342, 0.6041, 0.7037, 0.5971, 0.6765, 0.6538],
       device='cuda:0') torch.Size([16])
percent tensor([0.6561, 0.6774, 0.6452, 0.7042, 0.6687, 0.7476, 0.6704, 0.6297, 0.6947,
        0.6709, 0.6964, 0.6985, 0.6610, 0.7142, 0.7143, 0.6863],
       device='cuda:0') torch.Size([16])
percent tensor([0.6250, 0.6546, 0.6237, 0.6053, 0.6686, 0.6550, 0.6523, 0.5738, 0.6978,
        0.6758, 0.6892, 0.5595, 0.6224, 0.7578, 0.5119, 0.6714],
       device='cuda:0') torch.Size([16])
percent tensor([0.7107, 0.6769, 0.7966, 0.7948, 0.8297, 0.8071, 0.7422, 0.7821, 0.7484,
        0.7372, 0.7176, 0.7597, 0.6985, 0.7310, 0.7362, 0.7511],
       device='cuda:0') torch.Size([16])
percent tensor([0.5365, 0.7668, 0.6934, 0.6415, 0.6482, 0.6109, 0.5430, 0.5475, 0.7276,
        0.6767, 0.7839, 0.6952, 0.7308, 0.6298, 0.5606, 0.4198],
       device='cuda:0') torch.Size([16])
percent tensor([0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9998, 0.9999, 0.9998, 0.9999,
        1.0000, 1.0000, 1.0000, 1.0000, 0.9997, 0.9993, 0.9995],
       device='cuda:0') torch.Size([16])
Epoch: 227 | Batch_idx: 0 |  Loss: (0.0458) |  Loss2: (0.0000) | Acc: (98.00%) (126/128)
Epoch: 227 | Batch_idx: 10 |  Loss: (0.0411) |  Loss2: (0.0000) | Acc: (99.00%) (1394/1408)
Epoch: 227 | Batch_idx: 20 |  Loss: (0.0399) |  Loss2: (0.0000) | Acc: (98.00%) (2658/2688)
Epoch: 227 | Batch_idx: 30 |  Loss: (0.0416) |  Loss2: (0.0000) | Acc: (98.00%) (3922/3968)
Epoch: 227 | Batch_idx: 40 |  Loss: (0.0392) |  Loss2: (0.0000) | Acc: (98.00%) (5188/5248)
Epoch: 227 | Batch_idx: 50 |  Loss: (0.0389) |  Loss2: (0.0000) | Acc: (98.00%) (6449/6528)
Epoch: 227 | Batch_idx: 60 |  Loss: (0.0386) |  Loss2: (0.0000) | Acc: (98.00%) (7717/7808)
Epoch: 227 | Batch_idx: 70 |  Loss: (0.0390) |  Loss2: (0.0000) | Acc: (98.00%) (8977/9088)
Epoch: 227 | Batch_idx: 80 |  Loss: (0.0395) |  Loss2: (0.0000) | Acc: (98.00%) (10238/10368)
Epoch: 227 | Batch_idx: 90 |  Loss: (0.0396) |  Loss2: (0.0000) | Acc: (98.00%) (11503/11648)
Epoch: 227 | Batch_idx: 100 |  Loss: (0.0396) |  Loss2: (0.0000) | Acc: (98.00%) (12764/12928)
Epoch: 227 | Batch_idx: 110 |  Loss: (0.0399) |  Loss2: (0.0000) | Acc: (98.00%) (14023/14208)
Epoch: 227 | Batch_idx: 120 |  Loss: (0.0409) |  Loss2: (0.0000) | Acc: (98.00%) (15278/15488)
Epoch: 227 | Batch_idx: 130 |  Loss: (0.0403) |  Loss2: (0.0000) | Acc: (98.00%) (16544/16768)
Epoch: 227 | Batch_idx: 140 |  Loss: (0.0406) |  Loss2: (0.0000) | Acc: (98.00%) (17805/18048)
Epoch: 227 | Batch_idx: 150 |  Loss: (0.0411) |  Loss2: (0.0000) | Acc: (98.00%) (19067/19328)
Epoch: 227 | Batch_idx: 160 |  Loss: (0.0419) |  Loss2: (0.0000) | Acc: (98.00%) (20322/20608)
Epoch: 227 | Batch_idx: 170 |  Loss: (0.0419) |  Loss2: (0.0000) | Acc: (98.00%) (21588/21888)
Epoch: 227 | Batch_idx: 180 |  Loss: (0.0418) |  Loss2: (0.0000) | Acc: (98.00%) (22849/23168)
Epoch: 227 | Batch_idx: 190 |  Loss: (0.0418) |  Loss2: (0.0000) | Acc: (98.00%) (24107/24448)
Epoch: 227 | Batch_idx: 200 |  Loss: (0.0414) |  Loss2: (0.0000) | Acc: (98.00%) (25375/25728)
Epoch: 227 | Batch_idx: 210 |  Loss: (0.0414) |  Loss2: (0.0000) | Acc: (98.00%) (26642/27008)
Epoch: 227 | Batch_idx: 220 |  Loss: (0.0413) |  Loss2: (0.0000) | Acc: (98.00%) (27906/28288)
Epoch: 227 | Batch_idx: 230 |  Loss: (0.0411) |  Loss2: (0.0000) | Acc: (98.00%) (29173/29568)
Epoch: 227 | Batch_idx: 240 |  Loss: (0.0409) |  Loss2: (0.0000) | Acc: (98.00%) (30438/30848)
Epoch: 227 | Batch_idx: 250 |  Loss: (0.0411) |  Loss2: (0.0000) | Acc: (98.00%) (31701/32128)
Epoch: 227 | Batch_idx: 260 |  Loss: (0.0411) |  Loss2: (0.0000) | Acc: (98.00%) (32963/33408)
Epoch: 227 | Batch_idx: 270 |  Loss: (0.0416) |  Loss2: (0.0000) | Acc: (98.00%) (34221/34688)
Epoch: 227 | Batch_idx: 280 |  Loss: (0.0414) |  Loss2: (0.0000) | Acc: (98.00%) (35485/35968)
Epoch: 227 | Batch_idx: 290 |  Loss: (0.0417) |  Loss2: (0.0000) | Acc: (98.00%) (36747/37248)
Epoch: 227 | Batch_idx: 300 |  Loss: (0.0416) |  Loss2: (0.0000) | Acc: (98.00%) (38008/38528)
Epoch: 227 | Batch_idx: 310 |  Loss: (0.0415) |  Loss2: (0.0000) | Acc: (98.00%) (39274/39808)
Epoch: 227 | Batch_idx: 320 |  Loss: (0.0416) |  Loss2: (0.0000) | Acc: (98.00%) (40537/41088)
Epoch: 227 | Batch_idx: 330 |  Loss: (0.0414) |  Loss2: (0.0000) | Acc: (98.00%) (41803/42368)
Epoch: 227 | Batch_idx: 340 |  Loss: (0.0413) |  Loss2: (0.0000) | Acc: (98.00%) (43065/43648)
Epoch: 227 | Batch_idx: 350 |  Loss: (0.0414) |  Loss2: (0.0000) | Acc: (98.00%) (44326/44928)
Epoch: 227 | Batch_idx: 360 |  Loss: (0.0413) |  Loss2: (0.0000) | Acc: (98.00%) (45595/46208)
Epoch: 227 | Batch_idx: 370 |  Loss: (0.0416) |  Loss2: (0.0000) | Acc: (98.00%) (46857/47488)
Epoch: 227 | Batch_idx: 380 |  Loss: (0.0417) |  Loss2: (0.0000) | Acc: (98.00%) (48119/48768)
Epoch: 227 | Batch_idx: 390 |  Loss: (0.0416) |  Loss2: (0.0000) | Acc: (98.00%) (49333/50000)
# TEST : Loss: (0.4355) | Acc: (89.00%) (8925/10000)
percent tensor([0.5264, 0.5318, 0.5439, 0.5285, 0.5443, 0.5256, 0.5365, 0.5347, 0.5326,
        0.5351, 0.5321, 0.5420, 0.5280, 0.5247, 0.5298, 0.5249],
       device='cuda:0') torch.Size([16])
percent tensor([0.5119, 0.4880, 0.5132, 0.5178, 0.5065, 0.5250, 0.4920, 0.5035, 0.5172,
        0.4950, 0.5142, 0.5048, 0.4951, 0.5101, 0.5011, 0.5120],
       device='cuda:0') torch.Size([16])
percent tensor([0.6695, 0.6802, 0.5941, 0.5632, 0.5953, 0.6219, 0.6813, 0.6094, 0.5996,
        0.6390, 0.6392, 0.6040, 0.7047, 0.5917, 0.6799, 0.6566],
       device='cuda:0') torch.Size([16])
percent tensor([0.6506, 0.6820, 0.6409, 0.7027, 0.6629, 0.7438, 0.6679, 0.6311, 0.6894,
        0.6715, 0.6914, 0.6996, 0.6524, 0.7194, 0.7136, 0.6873],
       device='cuda:0') torch.Size([16])
percent tensor([0.6397, 0.6581, 0.6400, 0.6093, 0.6728, 0.6665, 0.6633, 0.5799, 0.7038,
        0.6741, 0.7021, 0.5512, 0.6329, 0.7694, 0.5205, 0.6875],
       device='cuda:0') torch.Size([16])
percent tensor([0.7087, 0.6791, 0.7874, 0.7905, 0.8250, 0.8169, 0.7501, 0.7812, 0.7464,
        0.7323, 0.7200, 0.7536, 0.6957, 0.7383, 0.7454, 0.7579],
       device='cuda:0') torch.Size([16])
percent tensor([0.5263, 0.7731, 0.6948, 0.6740, 0.6495, 0.5986, 0.5307, 0.5644, 0.7048,
        0.6847, 0.7851, 0.6819, 0.7022, 0.6188, 0.5710, 0.4150],
       device='cuda:0') torch.Size([16])
percent tensor([0.9999, 0.9999, 0.9998, 1.0000, 0.9998, 0.9997, 0.9998, 0.9998, 0.9997,
        1.0000, 1.0000, 0.9999, 0.9999, 0.9996, 0.9993, 0.9994],
       device='cuda:0') torch.Size([16])
Epoch: 228 | Batch_idx: 0 |  Loss: (0.0469) |  Loss2: (0.0000) | Acc: (97.00%) (125/128)
Epoch: 228 | Batch_idx: 10 |  Loss: (0.0479) |  Loss2: (0.0000) | Acc: (98.00%) (1388/1408)
Epoch: 228 | Batch_idx: 20 |  Loss: (0.0419) |  Loss2: (0.0000) | Acc: (98.00%) (2653/2688)
Epoch: 228 | Batch_idx: 30 |  Loss: (0.0441) |  Loss2: (0.0000) | Acc: (98.00%) (3911/3968)
Epoch: 228 | Batch_idx: 40 |  Loss: (0.0458) |  Loss2: (0.0000) | Acc: (98.00%) (5169/5248)
Epoch: 228 | Batch_idx: 50 |  Loss: (0.0446) |  Loss2: (0.0000) | Acc: (98.00%) (6433/6528)
Epoch: 228 | Batch_idx: 60 |  Loss: (0.0433) |  Loss2: (0.0000) | Acc: (98.00%) (7701/7808)
Epoch: 228 | Batch_idx: 70 |  Loss: (0.0439) |  Loss2: (0.0000) | Acc: (98.00%) (8962/9088)
Epoch: 228 | Batch_idx: 80 |  Loss: (0.0458) |  Loss2: (0.0000) | Acc: (98.00%) (10216/10368)
Epoch: 228 | Batch_idx: 90 |  Loss: (0.0457) |  Loss2: (0.0000) | Acc: (98.00%) (11480/11648)
Epoch: 228 | Batch_idx: 100 |  Loss: (0.0453) |  Loss2: (0.0000) | Acc: (98.00%) (12742/12928)
Epoch: 228 | Batch_idx: 110 |  Loss: (0.0452) |  Loss2: (0.0000) | Acc: (98.00%) (14004/14208)
Epoch: 228 | Batch_idx: 120 |  Loss: (0.0446) |  Loss2: (0.0000) | Acc: (98.00%) (15271/15488)
Epoch: 228 | Batch_idx: 130 |  Loss: (0.0443) |  Loss2: (0.0000) | Acc: (98.00%) (16534/16768)
Epoch: 228 | Batch_idx: 140 |  Loss: (0.0435) |  Loss2: (0.0000) | Acc: (98.00%) (17804/18048)
Epoch: 228 | Batch_idx: 150 |  Loss: (0.0439) |  Loss2: (0.0000) | Acc: (98.00%) (19069/19328)
Epoch: 228 | Batch_idx: 160 |  Loss: (0.0436) |  Loss2: (0.0000) | Acc: (98.00%) (20333/20608)
Epoch: 228 | Batch_idx: 170 |  Loss: (0.0432) |  Loss2: (0.0000) | Acc: (98.00%) (21596/21888)
Epoch: 228 | Batch_idx: 180 |  Loss: (0.0435) |  Loss2: (0.0000) | Acc: (98.00%) (22855/23168)
Epoch: 228 | Batch_idx: 190 |  Loss: (0.0437) |  Loss2: (0.0000) | Acc: (98.00%) (24116/24448)
Epoch: 228 | Batch_idx: 200 |  Loss: (0.0438) |  Loss2: (0.0000) | Acc: (98.00%) (25376/25728)
Epoch: 228 | Batch_idx: 210 |  Loss: (0.0436) |  Loss2: (0.0000) | Acc: (98.00%) (26639/27008)
Epoch: 228 | Batch_idx: 220 |  Loss: (0.0443) |  Loss2: (0.0000) | Acc: (98.00%) (27895/28288)
Epoch: 228 | Batch_idx: 230 |  Loss: (0.0441) |  Loss2: (0.0000) | Acc: (98.00%) (29161/29568)
Epoch: 228 | Batch_idx: 240 |  Loss: (0.0439) |  Loss2: (0.0000) | Acc: (98.00%) (30425/30848)
Epoch: 228 | Batch_idx: 250 |  Loss: (0.0438) |  Loss2: (0.0000) | Acc: (98.00%) (31687/32128)
Epoch: 228 | Batch_idx: 260 |  Loss: (0.0435) |  Loss2: (0.0000) | Acc: (98.00%) (32956/33408)
Epoch: 228 | Batch_idx: 270 |  Loss: (0.0440) |  Loss2: (0.0000) | Acc: (98.00%) (34212/34688)
Epoch: 228 | Batch_idx: 280 |  Loss: (0.0440) |  Loss2: (0.0000) | Acc: (98.00%) (35474/35968)
Epoch: 228 | Batch_idx: 290 |  Loss: (0.0438) |  Loss2: (0.0000) | Acc: (98.00%) (36740/37248)
Epoch: 228 | Batch_idx: 300 |  Loss: (0.0439) |  Loss2: (0.0000) | Acc: (98.00%) (38004/38528)
Epoch: 228 | Batch_idx: 310 |  Loss: (0.0438) |  Loss2: (0.0000) | Acc: (98.00%) (39269/39808)
Epoch: 228 | Batch_idx: 320 |  Loss: (0.0436) |  Loss2: (0.0000) | Acc: (98.00%) (40535/41088)
Epoch: 228 | Batch_idx: 330 |  Loss: (0.0438) |  Loss2: (0.0000) | Acc: (98.00%) (41796/42368)
Epoch: 228 | Batch_idx: 340 |  Loss: (0.0434) |  Loss2: (0.0000) | Acc: (98.00%) (43063/43648)
Epoch: 228 | Batch_idx: 350 |  Loss: (0.0436) |  Loss2: (0.0000) | Acc: (98.00%) (44321/44928)
Epoch: 228 | Batch_idx: 360 |  Loss: (0.0434) |  Loss2: (0.0000) | Acc: (98.00%) (45585/46208)
Epoch: 228 | Batch_idx: 370 |  Loss: (0.0434) |  Loss2: (0.0000) | Acc: (98.00%) (46847/47488)
Epoch: 228 | Batch_idx: 380 |  Loss: (0.0432) |  Loss2: (0.0000) | Acc: (98.00%) (48111/48768)
Epoch: 228 | Batch_idx: 390 |  Loss: (0.0432) |  Loss2: (0.0000) | Acc: (98.00%) (49325/50000)
# TEST : Loss: (0.4623) | Acc: (89.00%) (8910/10000)
percent tensor([0.5268, 0.5323, 0.5429, 0.5287, 0.5440, 0.5262, 0.5368, 0.5348, 0.5327,
        0.5354, 0.5325, 0.5414, 0.5283, 0.5257, 0.5303, 0.5258],
       device='cuda:0') torch.Size([16])
percent tensor([0.5106, 0.4856, 0.5106, 0.5178, 0.5049, 0.5244, 0.4888, 0.5009, 0.5152,
        0.4937, 0.5124, 0.5012, 0.4937, 0.5068, 0.4992, 0.5122],
       device='cuda:0') torch.Size([16])
percent tensor([0.6673, 0.6800, 0.5893, 0.5607, 0.5948, 0.6179, 0.6820, 0.6105, 0.6037,
        0.6306, 0.6357, 0.5992, 0.7021, 0.6008, 0.6787, 0.6531],
       device='cuda:0') torch.Size([16])
percent tensor([0.6593, 0.6845, 0.6443, 0.7106, 0.6671, 0.7439, 0.6765, 0.6356, 0.6999,
        0.6816, 0.6972, 0.7077, 0.6670, 0.7268, 0.7146, 0.6934],
       device='cuda:0') torch.Size([16])
percent tensor([0.6338, 0.6528, 0.6407, 0.6047, 0.6757, 0.6543, 0.6575, 0.5773, 0.6992,
        0.6854, 0.6984, 0.5700, 0.6307, 0.7590, 0.5193, 0.6722],
       device='cuda:0') torch.Size([16])
percent tensor([0.7032, 0.6684, 0.7910, 0.7938, 0.8282, 0.8066, 0.7334, 0.7738, 0.7320,
        0.7279, 0.7072, 0.7552, 0.6889, 0.7200, 0.7320, 0.7492],
       device='cuda:0') torch.Size([16])
percent tensor([0.5204, 0.7717, 0.6785, 0.6790, 0.6563, 0.5867, 0.5200, 0.5459, 0.7237,
        0.6823, 0.7804, 0.6888, 0.7214, 0.6340, 0.5323, 0.4171],
       device='cuda:0') torch.Size([16])
percent tensor([0.9998, 1.0000, 0.9999, 1.0000, 0.9999, 0.9998, 0.9998, 0.9996, 1.0000,
        1.0000, 1.0000, 1.0000, 1.0000, 0.9998, 0.9994, 0.9995],
       device='cuda:0') torch.Size([16])
Epoch: 229 | Batch_idx: 0 |  Loss: (0.0185) |  Loss2: (0.0000) | Acc: (100.00%) (128/128)
Epoch: 229 | Batch_idx: 10 |  Loss: (0.0351) |  Loss2: (0.0000) | Acc: (99.00%) (1394/1408)
Epoch: 229 | Batch_idx: 20 |  Loss: (0.0413) |  Loss2: (0.0000) | Acc: (98.00%) (2655/2688)
Epoch: 229 | Batch_idx: 30 |  Loss: (0.0396) |  Loss2: (0.0000) | Acc: (98.00%) (3922/3968)
Epoch: 229 | Batch_idx: 40 |  Loss: (0.0385) |  Loss2: (0.0000) | Acc: (98.00%) (5187/5248)
Epoch: 229 | Batch_idx: 50 |  Loss: (0.0386) |  Loss2: (0.0000) | Acc: (98.00%) (6452/6528)
Epoch: 229 | Batch_idx: 60 |  Loss: (0.0375) |  Loss2: (0.0000) | Acc: (98.00%) (7723/7808)
Epoch: 229 | Batch_idx: 70 |  Loss: (0.0383) |  Loss2: (0.0000) | Acc: (98.00%) (8988/9088)
Epoch: 229 | Batch_idx: 80 |  Loss: (0.0390) |  Loss2: (0.0000) | Acc: (98.00%) (10254/10368)
Epoch: 229 | Batch_idx: 90 |  Loss: (0.0389) |  Loss2: (0.0000) | Acc: (98.00%) (11515/11648)
Epoch: 229 | Batch_idx: 100 |  Loss: (0.0390) |  Loss2: (0.0000) | Acc: (98.00%) (12777/12928)
Epoch: 229 | Batch_idx: 110 |  Loss: (0.0392) |  Loss2: (0.0000) | Acc: (98.00%) (14043/14208)
Epoch: 229 | Batch_idx: 120 |  Loss: (0.0391) |  Loss2: (0.0000) | Acc: (98.00%) (15307/15488)
Epoch: 229 | Batch_idx: 130 |  Loss: (0.0395) |  Loss2: (0.0000) | Acc: (98.00%) (16573/16768)
Epoch: 229 | Batch_idx: 140 |  Loss: (0.0400) |  Loss2: (0.0000) | Acc: (98.00%) (17837/18048)
Epoch: 229 | Batch_idx: 150 |  Loss: (0.0404) |  Loss2: (0.0000) | Acc: (98.00%) (19097/19328)
Epoch: 229 | Batch_idx: 160 |  Loss: (0.0400) |  Loss2: (0.0000) | Acc: (98.00%) (20360/20608)
Epoch: 229 | Batch_idx: 170 |  Loss: (0.0403) |  Loss2: (0.0000) | Acc: (98.00%) (21619/21888)
Epoch: 229 | Batch_idx: 180 |  Loss: (0.0402) |  Loss2: (0.0000) | Acc: (98.00%) (22882/23168)
Epoch: 229 | Batch_idx: 190 |  Loss: (0.0407) |  Loss2: (0.0000) | Acc: (98.00%) (24141/24448)
Epoch: 229 | Batch_idx: 200 |  Loss: (0.0407) |  Loss2: (0.0000) | Acc: (98.00%) (25402/25728)
Epoch: 229 | Batch_idx: 210 |  Loss: (0.0407) |  Loss2: (0.0000) | Acc: (98.00%) (26665/27008)
Epoch: 229 | Batch_idx: 220 |  Loss: (0.0406) |  Loss2: (0.0000) | Acc: (98.00%) (27929/28288)
Epoch: 229 | Batch_idx: 230 |  Loss: (0.0410) |  Loss2: (0.0000) | Acc: (98.00%) (29192/29568)
Epoch: 229 | Batch_idx: 240 |  Loss: (0.0408) |  Loss2: (0.0000) | Acc: (98.00%) (30460/30848)
Epoch: 229 | Batch_idx: 250 |  Loss: (0.0407) |  Loss2: (0.0000) | Acc: (98.00%) (31722/32128)
Epoch: 229 | Batch_idx: 260 |  Loss: (0.0413) |  Loss2: (0.0000) | Acc: (98.00%) (32977/33408)
Epoch: 229 | Batch_idx: 270 |  Loss: (0.0416) |  Loss2: (0.0000) | Acc: (98.00%) (34241/34688)
Epoch: 229 | Batch_idx: 280 |  Loss: (0.0415) |  Loss2: (0.0000) | Acc: (98.00%) (35507/35968)
Epoch: 229 | Batch_idx: 290 |  Loss: (0.0415) |  Loss2: (0.0000) | Acc: (98.00%) (36765/37248)
Epoch: 229 | Batch_idx: 300 |  Loss: (0.0412) |  Loss2: (0.0000) | Acc: (98.00%) (38035/38528)
Epoch: 229 | Batch_idx: 310 |  Loss: (0.0410) |  Loss2: (0.0000) | Acc: (98.00%) (39300/39808)
Epoch: 229 | Batch_idx: 320 |  Loss: (0.0409) |  Loss2: (0.0000) | Acc: (98.00%) (40562/41088)
Epoch: 229 | Batch_idx: 330 |  Loss: (0.0407) |  Loss2: (0.0000) | Acc: (98.00%) (41830/42368)
Epoch: 229 | Batch_idx: 340 |  Loss: (0.0403) |  Loss2: (0.0000) | Acc: (98.00%) (43103/43648)
Epoch: 229 | Batch_idx: 350 |  Loss: (0.0404) |  Loss2: (0.0000) | Acc: (98.00%) (44366/44928)
Epoch: 229 | Batch_idx: 360 |  Loss: (0.0405) |  Loss2: (0.0000) | Acc: (98.00%) (45628/46208)
Epoch: 229 | Batch_idx: 370 |  Loss: (0.0405) |  Loss2: (0.0000) | Acc: (98.00%) (46893/47488)
Epoch: 229 | Batch_idx: 380 |  Loss: (0.0404) |  Loss2: (0.0000) | Acc: (98.00%) (48159/48768)
Epoch: 229 | Batch_idx: 390 |  Loss: (0.0405) |  Loss2: (0.0000) | Acc: (98.00%) (49373/50000)
# TEST : Loss: (0.4701) | Acc: (89.00%) (8901/10000)
percent tensor([0.5265, 0.5332, 0.5434, 0.5299, 0.5439, 0.5257, 0.5370, 0.5358, 0.5327,
        0.5363, 0.5323, 0.5418, 0.5284, 0.5267, 0.5307, 0.5262],
       device='cuda:0') torch.Size([16])
percent tensor([0.5126, 0.4875, 0.5064, 0.5163, 0.5031, 0.5260, 0.4904, 0.4989, 0.5181,
        0.4931, 0.5156, 0.4994, 0.4957, 0.5070, 0.5008, 0.5129],
       device='cuda:0') torch.Size([16])
percent tensor([0.6702, 0.6771, 0.6074, 0.5695, 0.6033, 0.6179, 0.6827, 0.6125, 0.5994,
        0.6454, 0.6310, 0.6168, 0.7049, 0.6021, 0.6791, 0.6551],
       device='cuda:0') torch.Size([16])
percent tensor([0.6650, 0.6829, 0.6419, 0.7118, 0.6705, 0.7505, 0.6741, 0.6328, 0.6932,
        0.6734, 0.6997, 0.6984, 0.6680, 0.7189, 0.7190, 0.6979],
       device='cuda:0') torch.Size([16])
percent tensor([0.6467, 0.6546, 0.6251, 0.5981, 0.6711, 0.6576, 0.6656, 0.5752, 0.7073,
        0.6710, 0.7114, 0.5559, 0.6337, 0.7692, 0.5224, 0.6846],
       device='cuda:0') torch.Size([16])
percent tensor([0.7033, 0.6742, 0.8022, 0.7902, 0.8291, 0.7956, 0.7494, 0.7795, 0.7363,
        0.7311, 0.7217, 0.7610, 0.6870, 0.7406, 0.7374, 0.7426],
       device='cuda:0') torch.Size([16])
percent tensor([0.5352, 0.7457, 0.7226, 0.6893, 0.6778, 0.5980, 0.5505, 0.5829, 0.7273,
        0.6956, 0.7774, 0.7039, 0.6983, 0.6470, 0.5777, 0.4129],
       device='cuda:0') torch.Size([16])
percent tensor([0.9998, 0.9999, 0.9999, 1.0000, 0.9999, 0.9997, 0.9998, 0.9997, 0.9999,
        0.9999, 1.0000, 0.9999, 0.9999, 0.9995, 0.9992, 0.9996],
       device='cuda:0') torch.Size([16])
Epoch: 230 | Batch_idx: 0 |  Loss: (0.0185) |  Loss2: (0.0000) | Acc: (99.00%) (127/128)
Epoch: 230 | Batch_idx: 10 |  Loss: (0.0344) |  Loss2: (0.0000) | Acc: (98.00%) (1391/1408)
Epoch: 230 | Batch_idx: 20 |  Loss: (0.0365) |  Loss2: (0.0000) | Acc: (98.00%) (2655/2688)
Epoch: 230 | Batch_idx: 30 |  Loss: (0.0361) |  Loss2: (0.0000) | Acc: (98.00%) (3919/3968)
Epoch: 230 | Batch_idx: 40 |  Loss: (0.0375) |  Loss2: (0.0000) | Acc: (98.00%) (5182/5248)
Epoch: 230 | Batch_idx: 50 |  Loss: (0.0390) |  Loss2: (0.0000) | Acc: (98.00%) (6443/6528)
Epoch: 230 | Batch_idx: 60 |  Loss: (0.0379) |  Loss2: (0.0000) | Acc: (98.00%) (7713/7808)
Epoch: 230 | Batch_idx: 70 |  Loss: (0.0369) |  Loss2: (0.0000) | Acc: (98.00%) (8979/9088)
Epoch: 230 | Batch_idx: 80 |  Loss: (0.0364) |  Loss2: (0.0000) | Acc: (98.00%) (10249/10368)
Epoch: 230 | Batch_idx: 90 |  Loss: (0.0370) |  Loss2: (0.0000) | Acc: (98.00%) (11511/11648)
Epoch: 230 | Batch_idx: 100 |  Loss: (0.0371) |  Loss2: (0.0000) | Acc: (98.00%) (12777/12928)
Epoch: 230 | Batch_idx: 110 |  Loss: (0.0375) |  Loss2: (0.0000) | Acc: (98.00%) (14036/14208)
Epoch: 230 | Batch_idx: 120 |  Loss: (0.0380) |  Loss2: (0.0000) | Acc: (98.00%) (15296/15488)
Epoch: 230 | Batch_idx: 130 |  Loss: (0.0385) |  Loss2: (0.0000) | Acc: (98.00%) (16556/16768)
Epoch: 230 | Batch_idx: 140 |  Loss: (0.0381) |  Loss2: (0.0000) | Acc: (98.00%) (17822/18048)
Epoch: 230 | Batch_idx: 150 |  Loss: (0.0382) |  Loss2: (0.0000) | Acc: (98.00%) (19086/19328)
Epoch: 230 | Batch_idx: 160 |  Loss: (0.0382) |  Loss2: (0.0000) | Acc: (98.00%) (20354/20608)
Epoch: 230 | Batch_idx: 170 |  Loss: (0.0384) |  Loss2: (0.0000) | Acc: (98.00%) (21617/21888)
Epoch: 230 | Batch_idx: 180 |  Loss: (0.0379) |  Loss2: (0.0000) | Acc: (98.00%) (22887/23168)
Epoch: 230 | Batch_idx: 190 |  Loss: (0.0379) |  Loss2: (0.0000) | Acc: (98.00%) (24152/24448)
Epoch: 230 | Batch_idx: 200 |  Loss: (0.0376) |  Loss2: (0.0000) | Acc: (98.00%) (25419/25728)
Epoch: 230 | Batch_idx: 210 |  Loss: (0.0383) |  Loss2: (0.0000) | Acc: (98.00%) (26676/27008)
Epoch: 230 | Batch_idx: 220 |  Loss: (0.0383) |  Loss2: (0.0000) | Acc: (98.00%) (27942/28288)
Epoch: 230 | Batch_idx: 230 |  Loss: (0.0383) |  Loss2: (0.0000) | Acc: (98.00%) (29206/29568)
Epoch: 230 | Batch_idx: 240 |  Loss: (0.0385) |  Loss2: (0.0000) | Acc: (98.00%) (30467/30848)
Epoch: 230 | Batch_idx: 250 |  Loss: (0.0387) |  Loss2: (0.0000) | Acc: (98.00%) (31730/32128)
Epoch: 230 | Batch_idx: 260 |  Loss: (0.0385) |  Loss2: (0.0000) | Acc: (98.00%) (32993/33408)
Epoch: 230 | Batch_idx: 270 |  Loss: (0.0383) |  Loss2: (0.0000) | Acc: (98.00%) (34264/34688)
Epoch: 230 | Batch_idx: 280 |  Loss: (0.0382) |  Loss2: (0.0000) | Acc: (98.00%) (35534/35968)
Epoch: 230 | Batch_idx: 290 |  Loss: (0.0386) |  Loss2: (0.0000) | Acc: (98.00%) (36793/37248)
Epoch: 230 | Batch_idx: 300 |  Loss: (0.0388) |  Loss2: (0.0000) | Acc: (98.00%) (38055/38528)
Epoch: 230 | Batch_idx: 310 |  Loss: (0.0392) |  Loss2: (0.0000) | Acc: (98.00%) (39311/39808)
Epoch: 230 | Batch_idx: 320 |  Loss: (0.0391) |  Loss2: (0.0000) | Acc: (98.00%) (40580/41088)
Epoch: 230 | Batch_idx: 330 |  Loss: (0.0393) |  Loss2: (0.0000) | Acc: (98.00%) (41839/42368)
Epoch: 230 | Batch_idx: 340 |  Loss: (0.0392) |  Loss2: (0.0000) | Acc: (98.00%) (43108/43648)
Epoch: 230 | Batch_idx: 350 |  Loss: (0.0390) |  Loss2: (0.0000) | Acc: (98.00%) (44379/44928)
Epoch: 230 | Batch_idx: 360 |  Loss: (0.0388) |  Loss2: (0.0000) | Acc: (98.00%) (45647/46208)
Epoch: 230 | Batch_idx: 370 |  Loss: (0.0388) |  Loss2: (0.0000) | Acc: (98.00%) (46914/47488)
Epoch: 230 | Batch_idx: 380 |  Loss: (0.0389) |  Loss2: (0.0000) | Acc: (98.00%) (48179/48768)
Epoch: 230 | Batch_idx: 390 |  Loss: (0.0391) |  Loss2: (0.0000) | Acc: (98.00%) (49391/50000)
=> saving checkpoint 'drive/app/torch/save_Schedule/checkpoint_230.pth.tar'
# TEST : Loss: (0.4645) | Acc: (88.00%) (8873/10000)
percent tensor([0.5265, 0.5328, 0.5437, 0.5294, 0.5443, 0.5261, 0.5372, 0.5355, 0.5324,
        0.5360, 0.5323, 0.5418, 0.5283, 0.5258, 0.5306, 0.5260],
       device='cuda:0') torch.Size([16])
percent tensor([0.5149, 0.4906, 0.5148, 0.5215, 0.5095, 0.5270, 0.4943, 0.5039, 0.5216,
        0.4969, 0.5174, 0.5057, 0.4985, 0.5122, 0.5041, 0.5153],
       device='cuda:0') torch.Size([16])
percent tensor([0.6712, 0.6810, 0.5960, 0.5640, 0.5996, 0.6283, 0.6829, 0.6098, 0.5997,
        0.6362, 0.6355, 0.6077, 0.7063, 0.5972, 0.6836, 0.6594],
       device='cuda:0') torch.Size([16])
percent tensor([0.6543, 0.6778, 0.6363, 0.6973, 0.6621, 0.7476, 0.6641, 0.6206, 0.6916,
        0.6701, 0.6975, 0.6912, 0.6666, 0.7103, 0.7110, 0.6895],
       device='cuda:0') torch.Size([16])
percent tensor([0.6454, 0.6589, 0.6208, 0.6010, 0.6625, 0.6590, 0.6554, 0.5721, 0.7073,
        0.6989, 0.7150, 0.5687, 0.6540, 0.7677, 0.5194, 0.6907],
       device='cuda:0') torch.Size([16])
percent tensor([0.7012, 0.6671, 0.7886, 0.7850, 0.8199, 0.7969, 0.7362, 0.7743, 0.7287,
        0.7324, 0.7166, 0.7540, 0.6889, 0.7246, 0.7304, 0.7458],
       device='cuda:0') torch.Size([16])
percent tensor([0.5135, 0.7435, 0.6906, 0.6531, 0.6553, 0.5735, 0.5314, 0.5718, 0.7195,
        0.6913, 0.7822, 0.6947, 0.7034, 0.6432, 0.5480, 0.4035],
       device='cuda:0') torch.Size([16])
percent tensor([0.9998, 1.0000, 0.9998, 1.0000, 0.9998, 0.9996, 0.9998, 0.9997, 0.9999,
        0.9999, 1.0000, 0.9999, 1.0000, 0.9997, 0.9994, 0.9997],
       device='cuda:0') torch.Size([16])
Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 3, 3, 3]) tensor(195.5872, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(835.5115, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(846.2609, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([128, 64, 3, 3]) tensor(1528.2394, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([128, 64, 1, 1]) tensor(471.4932, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([128, 128, 3, 3]) tensor(2361.2014, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([256, 128, 3, 3]) tensor(4276.6318, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([256, 128, 1, 1]) tensor(1330.3372, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([256, 256, 3, 3]) tensor(6380.2065, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([512, 256, 3, 3]) tensor(11441.2588, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([512, 256, 1, 1]) tensor(3747.1846, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([512, 512, 3, 3]) tensor(15800.0752, device='cuda:0', grad_fn=<NormBackward0>)
Epoch: 231 | Batch_idx: 0 |  Loss: (0.0122) |  Loss2: (0.0000) | Acc: (100.00%) (128/128)
Epoch: 231 | Batch_idx: 10 |  Loss: (0.0385) |  Loss2: (0.0000) | Acc: (98.00%) (1390/1408)
Epoch: 231 | Batch_idx: 20 |  Loss: (0.0381) |  Loss2: (0.0000) | Acc: (98.00%) (2658/2688)
Epoch: 231 | Batch_idx: 30 |  Loss: (0.0381) |  Loss2: (0.0000) | Acc: (98.00%) (3926/3968)
Epoch: 231 | Batch_idx: 40 |  Loss: (0.0371) |  Loss2: (0.0000) | Acc: (98.00%) (5195/5248)
Epoch: 231 | Batch_idx: 50 |  Loss: (0.0365) |  Loss2: (0.0000) | Acc: (98.00%) (6460/6528)
Epoch: 231 | Batch_idx: 60 |  Loss: (0.0378) |  Loss2: (0.0000) | Acc: (98.00%) (7722/7808)
Epoch: 231 | Batch_idx: 70 |  Loss: (0.0376) |  Loss2: (0.0000) | Acc: (98.00%) (8989/9088)
Epoch: 231 | Batch_idx: 80 |  Loss: (0.0382) |  Loss2: (0.0000) | Acc: (98.00%) (10249/10368)
Epoch: 231 | Batch_idx: 90 |  Loss: (0.0387) |  Loss2: (0.0000) | Acc: (98.00%) (11513/11648)
Epoch: 231 | Batch_idx: 100 |  Loss: (0.0380) |  Loss2: (0.0000) | Acc: (98.00%) (12781/12928)
Epoch: 231 | Batch_idx: 110 |  Loss: (0.0375) |  Loss2: (0.0000) | Acc: (98.00%) (14050/14208)
Epoch: 231 | Batch_idx: 120 |  Loss: (0.0371) |  Loss2: (0.0000) | Acc: (98.00%) (15315/15488)
Epoch: 231 | Batch_idx: 130 |  Loss: (0.0375) |  Loss2: (0.0000) | Acc: (98.00%) (16576/16768)
Epoch: 231 | Batch_idx: 140 |  Loss: (0.0377) |  Loss2: (0.0000) | Acc: (98.00%) (17836/18048)
Epoch: 231 | Batch_idx: 150 |  Loss: (0.0372) |  Loss2: (0.0000) | Acc: (98.00%) (19106/19328)
Epoch: 231 | Batch_idx: 160 |  Loss: (0.0370) |  Loss2: (0.0000) | Acc: (98.00%) (20374/20608)
Epoch: 231 | Batch_idx: 170 |  Loss: (0.0368) |  Loss2: (0.0000) | Acc: (98.00%) (21645/21888)
Epoch: 231 | Batch_idx: 180 |  Loss: (0.0367) |  Loss2: (0.0000) | Acc: (98.00%) (22914/23168)
Epoch: 231 | Batch_idx: 190 |  Loss: (0.0368) |  Loss2: (0.0000) | Acc: (98.00%) (24178/24448)
Epoch: 231 | Batch_idx: 200 |  Loss: (0.0369) |  Loss2: (0.0000) | Acc: (98.00%) (25443/25728)
Epoch: 231 | Batch_idx: 210 |  Loss: (0.0363) |  Loss2: (0.0000) | Acc: (98.00%) (26718/27008)
Epoch: 231 | Batch_idx: 220 |  Loss: (0.0363) |  Loss2: (0.0000) | Acc: (98.00%) (27988/28288)
Epoch: 231 | Batch_idx: 230 |  Loss: (0.0362) |  Loss2: (0.0000) | Acc: (98.00%) (29255/29568)
Epoch: 231 | Batch_idx: 240 |  Loss: (0.0363) |  Loss2: (0.0000) | Acc: (98.00%) (30522/30848)
Epoch: 231 | Batch_idx: 250 |  Loss: (0.0368) |  Loss2: (0.0000) | Acc: (98.00%) (31785/32128)
Epoch: 231 | Batch_idx: 260 |  Loss: (0.0379) |  Loss2: (0.0000) | Acc: (98.00%) (33035/33408)
Epoch: 231 | Batch_idx: 270 |  Loss: (0.0382) |  Loss2: (0.0000) | Acc: (98.00%) (34294/34688)
Epoch: 231 | Batch_idx: 280 |  Loss: (0.0381) |  Loss2: (0.0000) | Acc: (98.00%) (35556/35968)
Epoch: 231 | Batch_idx: 290 |  Loss: (0.0385) |  Loss2: (0.0000) | Acc: (98.00%) (36814/37248)
Epoch: 231 | Batch_idx: 300 |  Loss: (0.0387) |  Loss2: (0.0000) | Acc: (98.00%) (38076/38528)
Epoch: 231 | Batch_idx: 310 |  Loss: (0.0389) |  Loss2: (0.0000) | Acc: (98.00%) (39332/39808)
Epoch: 231 | Batch_idx: 320 |  Loss: (0.0390) |  Loss2: (0.0000) | Acc: (98.00%) (40592/41088)
Epoch: 231 | Batch_idx: 330 |  Loss: (0.0391) |  Loss2: (0.0000) | Acc: (98.00%) (41854/42368)
Epoch: 231 | Batch_idx: 340 |  Loss: (0.0389) |  Loss2: (0.0000) | Acc: (98.00%) (43118/43648)
Epoch: 231 | Batch_idx: 350 |  Loss: (0.0391) |  Loss2: (0.0000) | Acc: (98.00%) (44379/44928)
Epoch: 231 | Batch_idx: 360 |  Loss: (0.0391) |  Loss2: (0.0000) | Acc: (98.00%) (45642/46208)
Epoch: 231 | Batch_idx: 370 |  Loss: (0.0392) |  Loss2: (0.0000) | Acc: (98.00%) (46906/47488)
Epoch: 231 | Batch_idx: 380 |  Loss: (0.0394) |  Loss2: (0.0000) | Acc: (98.00%) (48165/48768)
Epoch: 231 | Batch_idx: 390 |  Loss: (0.0397) |  Loss2: (0.0000) | Acc: (98.00%) (49379/50000)
# TEST : Loss: (0.4624) | Acc: (89.00%) (8901/10000)
percent tensor([0.5259, 0.5319, 0.5426, 0.5285, 0.5431, 0.5253, 0.5362, 0.5346, 0.5321,
        0.5351, 0.5319, 0.5411, 0.5277, 0.5256, 0.5298, 0.5255],
       device='cuda:0') torch.Size([16])
percent tensor([0.5139, 0.4894, 0.5135, 0.5194, 0.5074, 0.5258, 0.4928, 0.5035, 0.5185,
        0.4955, 0.5161, 0.5029, 0.4975, 0.5112, 0.5029, 0.5143],
       device='cuda:0') torch.Size([16])
percent tensor([0.6748, 0.6931, 0.5931, 0.5722, 0.5980, 0.6275, 0.6906, 0.6160, 0.6068,
        0.6450, 0.6413, 0.6071, 0.7078, 0.6115, 0.6916, 0.6648],
       device='cuda:0') torch.Size([16])
percent tensor([0.6622, 0.6811, 0.6488, 0.7136, 0.6731, 0.7525, 0.6779, 0.6315, 0.6950,
        0.6737, 0.6990, 0.7022, 0.6648, 0.7202, 0.7204, 0.7013],
       device='cuda:0') torch.Size([16])
percent tensor([0.6507, 0.6494, 0.6345, 0.6104, 0.6780, 0.6663, 0.6561, 0.5773, 0.7038,
        0.6752, 0.6963, 0.5743, 0.6419, 0.7729, 0.5247, 0.6884],
       device='cuda:0') torch.Size([16])
percent tensor([0.7047, 0.6692, 0.7954, 0.7914, 0.8233, 0.8028, 0.7415, 0.7757, 0.7285,
        0.7253, 0.7158, 0.7643, 0.6871, 0.7381, 0.7385, 0.7476],
       device='cuda:0') torch.Size([16])
percent tensor([0.5412, 0.7734, 0.6825, 0.6791, 0.6320, 0.6020, 0.5266, 0.5517, 0.7161,
        0.6784, 0.7874, 0.7052, 0.7016, 0.6305, 0.5641, 0.4108],
       device='cuda:0') torch.Size([16])
percent tensor([0.9998, 0.9999, 0.9998, 1.0000, 0.9998, 0.9997, 0.9999, 0.9998, 0.9999,
        1.0000, 1.0000, 1.0000, 0.9999, 0.9996, 0.9996, 0.9996],
       device='cuda:0') torch.Size([16])
Epoch: 232 | Batch_idx: 0 |  Loss: (0.0284) |  Loss2: (0.0000) | Acc: (99.00%) (127/128)
Epoch: 232 | Batch_idx: 10 |  Loss: (0.0354) |  Loss2: (0.0000) | Acc: (98.00%) (1392/1408)
Epoch: 232 | Batch_idx: 20 |  Loss: (0.0350) |  Loss2: (0.0000) | Acc: (98.00%) (2655/2688)
Epoch: 232 | Batch_idx: 30 |  Loss: (0.0337) |  Loss2: (0.0000) | Acc: (98.00%) (3922/3968)
Epoch: 232 | Batch_idx: 40 |  Loss: (0.0342) |  Loss2: (0.0000) | Acc: (98.00%) (5187/5248)
Epoch: 232 | Batch_idx: 50 |  Loss: (0.0369) |  Loss2: (0.0000) | Acc: (98.00%) (6443/6528)
Epoch: 232 | Batch_idx: 60 |  Loss: (0.0375) |  Loss2: (0.0000) | Acc: (98.00%) (7703/7808)
Epoch: 232 | Batch_idx: 70 |  Loss: (0.0376) |  Loss2: (0.0000) | Acc: (98.00%) (8969/9088)
Epoch: 232 | Batch_idx: 80 |  Loss: (0.0380) |  Loss2: (0.0000) | Acc: (98.00%) (10238/10368)
Epoch: 232 | Batch_idx: 90 |  Loss: (0.0372) |  Loss2: (0.0000) | Acc: (98.00%) (11509/11648)
Epoch: 232 | Batch_idx: 100 |  Loss: (0.0375) |  Loss2: (0.0000) | Acc: (98.00%) (12773/12928)
Epoch: 232 | Batch_idx: 110 |  Loss: (0.0377) |  Loss2: (0.0000) | Acc: (98.00%) (14035/14208)
Epoch: 232 | Batch_idx: 120 |  Loss: (0.0386) |  Loss2: (0.0000) | Acc: (98.00%) (15295/15488)
Epoch: 232 | Batch_idx: 130 |  Loss: (0.0390) |  Loss2: (0.0000) | Acc: (98.00%) (16553/16768)
Epoch: 232 | Batch_idx: 140 |  Loss: (0.0394) |  Loss2: (0.0000) | Acc: (98.00%) (17812/18048)
Epoch: 232 | Batch_idx: 150 |  Loss: (0.0393) |  Loss2: (0.0000) | Acc: (98.00%) (19077/19328)
Epoch: 232 | Batch_idx: 160 |  Loss: (0.0397) |  Loss2: (0.0000) | Acc: (98.00%) (20344/20608)
Epoch: 232 | Batch_idx: 170 |  Loss: (0.0402) |  Loss2: (0.0000) | Acc: (98.00%) (21600/21888)
Epoch: 232 | Batch_idx: 180 |  Loss: (0.0409) |  Loss2: (0.0000) | Acc: (98.00%) (22860/23168)
Epoch: 232 | Batch_idx: 190 |  Loss: (0.0411) |  Loss2: (0.0000) | Acc: (98.00%) (24118/24448)
Epoch: 232 | Batch_idx: 200 |  Loss: (0.0414) |  Loss2: (0.0000) | Acc: (98.00%) (25379/25728)
Epoch: 232 | Batch_idx: 210 |  Loss: (0.0410) |  Loss2: (0.0000) | Acc: (98.00%) (26649/27008)
Epoch: 232 | Batch_idx: 220 |  Loss: (0.0412) |  Loss2: (0.0000) | Acc: (98.00%) (27911/28288)
Epoch: 232 | Batch_idx: 230 |  Loss: (0.0416) |  Loss2: (0.0000) | Acc: (98.00%) (29170/29568)
Epoch: 232 | Batch_idx: 240 |  Loss: (0.0413) |  Loss2: (0.0000) | Acc: (98.00%) (30433/30848)
Epoch: 232 | Batch_idx: 250 |  Loss: (0.0413) |  Loss2: (0.0000) | Acc: (98.00%) (31695/32128)
Epoch: 232 | Batch_idx: 260 |  Loss: (0.0412) |  Loss2: (0.0000) | Acc: (98.00%) (32957/33408)
Epoch: 232 | Batch_idx: 270 |  Loss: (0.0410) |  Loss2: (0.0000) | Acc: (98.00%) (34223/34688)
Epoch: 232 | Batch_idx: 280 |  Loss: (0.0406) |  Loss2: (0.0000) | Acc: (98.00%) (35494/35968)
Epoch: 232 | Batch_idx: 290 |  Loss: (0.0406) |  Loss2: (0.0000) | Acc: (98.00%) (36755/37248)
Epoch: 232 | Batch_idx: 300 |  Loss: (0.0403) |  Loss2: (0.0000) | Acc: (98.00%) (38023/38528)
Epoch: 232 | Batch_idx: 310 |  Loss: (0.0400) |  Loss2: (0.0000) | Acc: (98.00%) (39293/39808)
Epoch: 232 | Batch_idx: 320 |  Loss: (0.0398) |  Loss2: (0.0000) | Acc: (98.00%) (40559/41088)
Epoch: 232 | Batch_idx: 330 |  Loss: (0.0398) |  Loss2: (0.0000) | Acc: (98.00%) (41824/42368)
Epoch: 232 | Batch_idx: 340 |  Loss: (0.0395) |  Loss2: (0.0000) | Acc: (98.00%) (43090/43648)
Epoch: 232 | Batch_idx: 350 |  Loss: (0.0396) |  Loss2: (0.0000) | Acc: (98.00%) (44354/44928)
Epoch: 232 | Batch_idx: 360 |  Loss: (0.0397) |  Loss2: (0.0000) | Acc: (98.00%) (45614/46208)
Epoch: 232 | Batch_idx: 370 |  Loss: (0.0398) |  Loss2: (0.0000) | Acc: (98.00%) (46876/47488)
Epoch: 232 | Batch_idx: 380 |  Loss: (0.0399) |  Loss2: (0.0000) | Acc: (98.00%) (48137/48768)
Epoch: 232 | Batch_idx: 390 |  Loss: (0.0401) |  Loss2: (0.0000) | Acc: (98.00%) (49348/50000)
# TEST : Loss: (0.4832) | Acc: (89.00%) (8906/10000)
percent tensor([0.5272, 0.5328, 0.5440, 0.5298, 0.5445, 0.5267, 0.5373, 0.5355, 0.5326,
        0.5360, 0.5327, 0.5422, 0.5285, 0.5258, 0.5310, 0.5261],
       device='cuda:0') torch.Size([16])
percent tensor([0.5106, 0.4885, 0.5081, 0.5158, 0.5040, 0.5236, 0.4917, 0.4990, 0.5149,
        0.4939, 0.5139, 0.5011, 0.4939, 0.5098, 0.5000, 0.5115],
       device='cuda:0') torch.Size([16])
percent tensor([0.6689, 0.6778, 0.5985, 0.5726, 0.5980, 0.6262, 0.6814, 0.6146, 0.6026,
        0.6352, 0.6345, 0.6055, 0.7028, 0.6020, 0.6821, 0.6604],
       device='cuda:0') torch.Size([16])
percent tensor([0.6623, 0.6832, 0.6485, 0.7110, 0.6724, 0.7502, 0.6762, 0.6329, 0.6995,
        0.6723, 0.7020, 0.7018, 0.6656, 0.7182, 0.7187, 0.6944],
       device='cuda:0') torch.Size([16])
percent tensor([0.6437, 0.6566, 0.6219, 0.5998, 0.6641, 0.6637, 0.6525, 0.5719, 0.6965,
        0.6720, 0.7006, 0.5562, 0.6377, 0.7698, 0.5204, 0.6927],
       device='cuda:0') torch.Size([16])
percent tensor([0.6981, 0.6713, 0.7939, 0.7937, 0.8233, 0.7988, 0.7395, 0.7771, 0.7357,
        0.7219, 0.7088, 0.7542, 0.6865, 0.7335, 0.7328, 0.7477],
       device='cuda:0') torch.Size([16])
percent tensor([0.5275, 0.7360, 0.7021, 0.6660, 0.6696, 0.6299, 0.5565, 0.5631, 0.7271,
        0.6658, 0.7701, 0.6787, 0.7144, 0.6022, 0.5443, 0.4059],
       device='cuda:0') torch.Size([16])
percent tensor([0.9999, 0.9999, 0.9998, 0.9999, 0.9998, 0.9998, 0.9998, 0.9998, 0.9998,
        0.9999, 1.0000, 0.9999, 0.9999, 0.9996, 0.9995, 0.9996],
       device='cuda:0') torch.Size([16])
Epoch: 233 | Batch_idx: 0 |  Loss: (0.0423) |  Loss2: (0.0000) | Acc: (98.00%) (126/128)
Epoch: 233 | Batch_idx: 10 |  Loss: (0.0403) |  Loss2: (0.0000) | Acc: (98.00%) (1390/1408)
Epoch: 233 | Batch_idx: 20 |  Loss: (0.0413) |  Loss2: (0.0000) | Acc: (98.00%) (2652/2688)
Epoch: 233 | Batch_idx: 30 |  Loss: (0.0406) |  Loss2: (0.0000) | Acc: (98.00%) (3915/3968)
Epoch: 233 | Batch_idx: 40 |  Loss: (0.0396) |  Loss2: (0.0000) | Acc: (98.00%) (5179/5248)
Epoch: 233 | Batch_idx: 50 |  Loss: (0.0368) |  Loss2: (0.0000) | Acc: (98.00%) (6452/6528)
Epoch: 233 | Batch_idx: 60 |  Loss: (0.0368) |  Loss2: (0.0000) | Acc: (98.00%) (7714/7808)
Epoch: 233 | Batch_idx: 70 |  Loss: (0.0359) |  Loss2: (0.0000) | Acc: (98.00%) (8984/9088)
Epoch: 233 | Batch_idx: 80 |  Loss: (0.0354) |  Loss2: (0.0000) | Acc: (98.00%) (10252/10368)
Epoch: 233 | Batch_idx: 90 |  Loss: (0.0357) |  Loss2: (0.0000) | Acc: (98.00%) (11515/11648)
Epoch: 233 | Batch_idx: 100 |  Loss: (0.0357) |  Loss2: (0.0000) | Acc: (98.00%) (12782/12928)
Epoch: 233 | Batch_idx: 110 |  Loss: (0.0359) |  Loss2: (0.0000) | Acc: (98.00%) (14043/14208)
Epoch: 233 | Batch_idx: 120 |  Loss: (0.0359) |  Loss2: (0.0000) | Acc: (98.00%) (15307/15488)
Epoch: 233 | Batch_idx: 130 |  Loss: (0.0367) |  Loss2: (0.0000) | Acc: (98.00%) (16565/16768)
Epoch: 233 | Batch_idx: 140 |  Loss: (0.0368) |  Loss2: (0.0000) | Acc: (98.00%) (17831/18048)
Epoch: 233 | Batch_idx: 150 |  Loss: (0.0375) |  Loss2: (0.0000) | Acc: (98.00%) (19091/19328)
Epoch: 233 | Batch_idx: 160 |  Loss: (0.0377) |  Loss2: (0.0000) | Acc: (98.00%) (20354/20608)
Epoch: 233 | Batch_idx: 170 |  Loss: (0.0376) |  Loss2: (0.0000) | Acc: (98.00%) (21622/21888)
Epoch: 233 | Batch_idx: 180 |  Loss: (0.0373) |  Loss2: (0.0000) | Acc: (98.00%) (22889/23168)
Epoch: 233 | Batch_idx: 190 |  Loss: (0.0371) |  Loss2: (0.0000) | Acc: (98.00%) (24154/24448)
Epoch: 233 | Batch_idx: 200 |  Loss: (0.0371) |  Loss2: (0.0000) | Acc: (98.00%) (25417/25728)
Epoch: 233 | Batch_idx: 210 |  Loss: (0.0369) |  Loss2: (0.0000) | Acc: (98.00%) (26686/27008)
Epoch: 233 | Batch_idx: 220 |  Loss: (0.0365) |  Loss2: (0.0000) | Acc: (98.00%) (27955/28288)
Epoch: 233 | Batch_idx: 230 |  Loss: (0.0364) |  Loss2: (0.0000) | Acc: (98.00%) (29221/29568)
Epoch: 233 | Batch_idx: 240 |  Loss: (0.0363) |  Loss2: (0.0000) | Acc: (98.00%) (30487/30848)
Epoch: 233 | Batch_idx: 250 |  Loss: (0.0366) |  Loss2: (0.0000) | Acc: (98.00%) (31750/32128)
Epoch: 233 | Batch_idx: 260 |  Loss: (0.0366) |  Loss2: (0.0000) | Acc: (98.00%) (33013/33408)
Epoch: 233 | Batch_idx: 270 |  Loss: (0.0369) |  Loss2: (0.0000) | Acc: (98.00%) (34275/34688)
Epoch: 233 | Batch_idx: 280 |  Loss: (0.0370) |  Loss2: (0.0000) | Acc: (98.00%) (35534/35968)
Epoch: 233 | Batch_idx: 290 |  Loss: (0.0370) |  Loss2: (0.0000) | Acc: (98.00%) (36801/37248)
Epoch: 233 | Batch_idx: 300 |  Loss: (0.0371) |  Loss2: (0.0000) | Acc: (98.00%) (38057/38528)
Epoch: 233 | Batch_idx: 310 |  Loss: (0.0373) |  Loss2: (0.0000) | Acc: (98.00%) (39315/39808)
Epoch: 233 | Batch_idx: 320 |  Loss: (0.0369) |  Loss2: (0.0000) | Acc: (98.00%) (40582/41088)
Epoch: 233 | Batch_idx: 330 |  Loss: (0.0369) |  Loss2: (0.0000) | Acc: (98.00%) (41852/42368)
Epoch: 233 | Batch_idx: 340 |  Loss: (0.0370) |  Loss2: (0.0000) | Acc: (98.00%) (43120/43648)
Epoch: 233 | Batch_idx: 350 |  Loss: (0.0374) |  Loss2: (0.0000) | Acc: (98.00%) (44377/44928)
Epoch: 233 | Batch_idx: 360 |  Loss: (0.0375) |  Loss2: (0.0000) | Acc: (98.00%) (45643/46208)
Epoch: 233 | Batch_idx: 370 |  Loss: (0.0377) |  Loss2: (0.0000) | Acc: (98.00%) (46905/47488)
Epoch: 233 | Batch_idx: 380 |  Loss: (0.0378) |  Loss2: (0.0000) | Acc: (98.00%) (48172/48768)
Epoch: 233 | Batch_idx: 390 |  Loss: (0.0381) |  Loss2: (0.0000) | Acc: (98.00%) (49384/50000)
# TEST : Loss: (0.4524) | Acc: (88.00%) (8881/10000)
percent tensor([0.5282, 0.5332, 0.5456, 0.5299, 0.5463, 0.5281, 0.5380, 0.5364, 0.5338,
        0.5366, 0.5332, 0.5433, 0.5296, 0.5253, 0.5315, 0.5267],
       device='cuda:0') torch.Size([16])
percent tensor([0.5124, 0.4886, 0.5098, 0.5160, 0.5056, 0.5249, 0.4920, 0.5014, 0.5154,
        0.4948, 0.5145, 0.5009, 0.4955, 0.5067, 0.5014, 0.5133],
       device='cuda:0') torch.Size([16])
percent tensor([0.6688, 0.6736, 0.6025, 0.5695, 0.6031, 0.6234, 0.6807, 0.6138, 0.6021,
        0.6334, 0.6372, 0.6102, 0.7023, 0.5986, 0.6792, 0.6570],
       device='cuda:0') torch.Size([16])
percent tensor([0.6670, 0.6856, 0.6650, 0.7226, 0.6855, 0.7504, 0.6815, 0.6418, 0.7050,
        0.6759, 0.7022, 0.7154, 0.6720, 0.7190, 0.7218, 0.6955],
       device='cuda:0') torch.Size([16])
percent tensor([0.6342, 0.6502, 0.6201, 0.6042, 0.6635, 0.6530, 0.6484, 0.5816, 0.7097,
        0.6661, 0.7041, 0.5393, 0.6347, 0.7815, 0.5199, 0.6894],
       device='cuda:0') torch.Size([16])
percent tensor([0.7045, 0.6864, 0.7911, 0.7987, 0.8221, 0.8025, 0.7377, 0.7786, 0.7520,
        0.7287, 0.7189, 0.7642, 0.6921, 0.7510, 0.7355, 0.7537],
       device='cuda:0') torch.Size([16])
percent tensor([0.5186, 0.7509, 0.7040, 0.6761, 0.6834, 0.5892, 0.5504, 0.5378, 0.7299,
        0.6602, 0.7755, 0.6884, 0.7341, 0.5940, 0.5472, 0.4006],
       device='cuda:0') torch.Size([16])
percent tensor([0.9998, 0.9999, 0.9999, 0.9999, 0.9999, 0.9997, 0.9998, 0.9997, 1.0000,
        0.9999, 1.0000, 0.9999, 1.0000, 0.9997, 0.9994, 0.9996],
       device='cuda:0') torch.Size([16])
Epoch: 234 | Batch_idx: 0 |  Loss: (0.0166) |  Loss2: (0.0000) | Acc: (100.00%) (128/128)
Epoch: 234 | Batch_idx: 10 |  Loss: (0.0440) |  Loss2: (0.0000) | Acc: (98.00%) (1389/1408)
Epoch: 234 | Batch_idx: 20 |  Loss: (0.0456) |  Loss2: (0.0000) | Acc: (98.00%) (2651/2688)
Epoch: 234 | Batch_idx: 30 |  Loss: (0.0440) |  Loss2: (0.0000) | Acc: (98.00%) (3914/3968)
Epoch: 234 | Batch_idx: 40 |  Loss: (0.0436) |  Loss2: (0.0000) | Acc: (98.00%) (5180/5248)
Epoch: 234 | Batch_idx: 50 |  Loss: (0.0425) |  Loss2: (0.0000) | Acc: (98.00%) (6448/6528)
Epoch: 234 | Batch_idx: 60 |  Loss: (0.0416) |  Loss2: (0.0000) | Acc: (98.00%) (7710/7808)
Epoch: 234 | Batch_idx: 70 |  Loss: (0.0402) |  Loss2: (0.0000) | Acc: (98.00%) (8977/9088)
Epoch: 234 | Batch_idx: 80 |  Loss: (0.0395) |  Loss2: (0.0000) | Acc: (98.00%) (10242/10368)
Epoch: 234 | Batch_idx: 90 |  Loss: (0.0392) |  Loss2: (0.0000) | Acc: (98.00%) (11508/11648)
Epoch: 234 | Batch_idx: 100 |  Loss: (0.0398) |  Loss2: (0.0000) | Acc: (98.00%) (12766/12928)
Epoch: 234 | Batch_idx: 110 |  Loss: (0.0401) |  Loss2: (0.0000) | Acc: (98.00%) (14029/14208)
Epoch: 234 | Batch_idx: 120 |  Loss: (0.0397) |  Loss2: (0.0000) | Acc: (98.00%) (15299/15488)
Epoch: 234 | Batch_idx: 130 |  Loss: (0.0391) |  Loss2: (0.0000) | Acc: (98.00%) (16562/16768)
Epoch: 234 | Batch_idx: 140 |  Loss: (0.0392) |  Loss2: (0.0000) | Acc: (98.00%) (17825/18048)
Epoch: 234 | Batch_idx: 150 |  Loss: (0.0396) |  Loss2: (0.0000) | Acc: (98.00%) (19083/19328)
Epoch: 234 | Batch_idx: 160 |  Loss: (0.0391) |  Loss2: (0.0000) | Acc: (98.00%) (20352/20608)
Epoch: 234 | Batch_idx: 170 |  Loss: (0.0390) |  Loss2: (0.0000) | Acc: (98.00%) (21618/21888)
Epoch: 234 | Batch_idx: 180 |  Loss: (0.0389) |  Loss2: (0.0000) | Acc: (98.00%) (22884/23168)
Epoch: 234 | Batch_idx: 190 |  Loss: (0.0389) |  Loss2: (0.0000) | Acc: (98.00%) (24146/24448)
Epoch: 234 | Batch_idx: 200 |  Loss: (0.0383) |  Loss2: (0.0000) | Acc: (98.00%) (25416/25728)
Epoch: 234 | Batch_idx: 210 |  Loss: (0.0380) |  Loss2: (0.0000) | Acc: (98.00%) (26686/27008)
Epoch: 234 | Batch_idx: 220 |  Loss: (0.0383) |  Loss2: (0.0000) | Acc: (98.00%) (27943/28288)
Epoch: 234 | Batch_idx: 230 |  Loss: (0.0382) |  Loss2: (0.0000) | Acc: (98.00%) (29212/29568)
Epoch: 234 | Batch_idx: 240 |  Loss: (0.0379) |  Loss2: (0.0000) | Acc: (98.00%) (30483/30848)
Epoch: 234 | Batch_idx: 250 |  Loss: (0.0382) |  Loss2: (0.0000) | Acc: (98.00%) (31748/32128)
Epoch: 234 | Batch_idx: 260 |  Loss: (0.0386) |  Loss2: (0.0000) | Acc: (98.00%) (33006/33408)
Epoch: 234 | Batch_idx: 270 |  Loss: (0.0388) |  Loss2: (0.0000) | Acc: (98.00%) (34270/34688)
Epoch: 234 | Batch_idx: 280 |  Loss: (0.0386) |  Loss2: (0.0000) | Acc: (98.00%) (35541/35968)
Epoch: 234 | Batch_idx: 290 |  Loss: (0.0386) |  Loss2: (0.0000) | Acc: (98.00%) (36807/37248)
Epoch: 234 | Batch_idx: 300 |  Loss: (0.0387) |  Loss2: (0.0000) | Acc: (98.00%) (38071/38528)
Epoch: 234 | Batch_idx: 310 |  Loss: (0.0390) |  Loss2: (0.0000) | Acc: (98.00%) (39326/39808)
Epoch: 234 | Batch_idx: 320 |  Loss: (0.0389) |  Loss2: (0.0000) | Acc: (98.00%) (40588/41088)
Epoch: 234 | Batch_idx: 330 |  Loss: (0.0388) |  Loss2: (0.0000) | Acc: (98.00%) (41855/42368)
Epoch: 234 | Batch_idx: 340 |  Loss: (0.0388) |  Loss2: (0.0000) | Acc: (98.00%) (43119/43648)
Epoch: 234 | Batch_idx: 350 |  Loss: (0.0387) |  Loss2: (0.0000) | Acc: (98.00%) (44388/44928)
Epoch: 234 | Batch_idx: 360 |  Loss: (0.0389) |  Loss2: (0.0000) | Acc: (98.00%) (45649/46208)
Epoch: 234 | Batch_idx: 370 |  Loss: (0.0392) |  Loss2: (0.0000) | Acc: (98.00%) (46910/47488)
Epoch: 234 | Batch_idx: 380 |  Loss: (0.0390) |  Loss2: (0.0000) | Acc: (98.00%) (48174/48768)
Epoch: 234 | Batch_idx: 390 |  Loss: (0.0390) |  Loss2: (0.0000) | Acc: (98.00%) (49394/50000)
# TEST : Loss: (0.4467) | Acc: (89.00%) (8955/10000)
percent tensor([0.5283, 0.5332, 0.5455, 0.5308, 0.5461, 0.5285, 0.5382, 0.5363, 0.5336,
        0.5368, 0.5332, 0.5432, 0.5296, 0.5255, 0.5320, 0.5270],
       device='cuda:0') torch.Size([16])
percent tensor([0.5107, 0.4878, 0.5094, 0.5173, 0.5049, 0.5250, 0.4908, 0.4990, 0.5131,
        0.4937, 0.5135, 0.5001, 0.4934, 0.5064, 0.5008, 0.5130],
       device='cuda:0') torch.Size([16])
percent tensor([0.6786, 0.6779, 0.6042, 0.5757, 0.6042, 0.6319, 0.6839, 0.6210, 0.6104,
        0.6434, 0.6399, 0.6145, 0.7104, 0.6058, 0.6831, 0.6641],
       device='cuda:0') torch.Size([16])
percent tensor([0.6485, 0.6791, 0.6379, 0.7041, 0.6647, 0.7467, 0.6691, 0.6299, 0.6916,
        0.6659, 0.6927, 0.6953, 0.6596, 0.7104, 0.7157, 0.6886],
       device='cuda:0') torch.Size([16])
percent tensor([0.6252, 0.6495, 0.6341, 0.5996, 0.6651, 0.6524, 0.6521, 0.5778, 0.6925,
        0.6726, 0.6937, 0.5470, 0.6252, 0.7656, 0.5177, 0.6856],
       device='cuda:0') torch.Size([16])
percent tensor([0.6974, 0.6789, 0.7907, 0.7876, 0.8229, 0.7959, 0.7362, 0.7741, 0.7363,
        0.7259, 0.7126, 0.7633, 0.6957, 0.7380, 0.7274, 0.7471],
       device='cuda:0') torch.Size([16])
percent tensor([0.4974, 0.7365, 0.6814, 0.6374, 0.6361, 0.5733, 0.5217, 0.5238, 0.6997,
        0.6353, 0.7645, 0.6595, 0.7164, 0.5956, 0.5250, 0.3921],
       device='cuda:0') torch.Size([16])
percent tensor([0.9998, 0.9999, 0.9999, 0.9999, 0.9998, 0.9998, 0.9998, 0.9995, 0.9999,
        0.9999, 1.0000, 0.9999, 1.0000, 0.9997, 0.9996, 0.9996],
       device='cuda:0') torch.Size([16])
Epoch: 235 | Batch_idx: 0 |  Loss: (0.0122) |  Loss2: (0.0000) | Acc: (100.00%) (128/128)
Epoch: 235 | Batch_idx: 10 |  Loss: (0.0378) |  Loss2: (0.0000) | Acc: (99.00%) (1394/1408)
Epoch: 235 | Batch_idx: 20 |  Loss: (0.0329) |  Loss2: (0.0000) | Acc: (99.00%) (2665/2688)
Epoch: 235 | Batch_idx: 30 |  Loss: (0.0369) |  Loss2: (0.0000) | Acc: (98.00%) (3926/3968)
Epoch: 235 | Batch_idx: 40 |  Loss: (0.0362) |  Loss2: (0.0000) | Acc: (98.00%) (5189/5248)
Epoch: 235 | Batch_idx: 50 |  Loss: (0.0365) |  Loss2: (0.0000) | Acc: (98.00%) (6449/6528)
Epoch: 235 | Batch_idx: 60 |  Loss: (0.0361) |  Loss2: (0.0000) | Acc: (98.00%) (7713/7808)
Epoch: 235 | Batch_idx: 70 |  Loss: (0.0367) |  Loss2: (0.0000) | Acc: (98.00%) (8978/9088)
Epoch: 235 | Batch_idx: 80 |  Loss: (0.0365) |  Loss2: (0.0000) | Acc: (98.00%) (10248/10368)
Epoch: 235 | Batch_idx: 90 |  Loss: (0.0368) |  Loss2: (0.0000) | Acc: (98.00%) (11511/11648)
Epoch: 235 | Batch_idx: 100 |  Loss: (0.0367) |  Loss2: (0.0000) | Acc: (98.00%) (12778/12928)
Epoch: 235 | Batch_idx: 110 |  Loss: (0.0362) |  Loss2: (0.0000) | Acc: (98.00%) (14048/14208)
Epoch: 235 | Batch_idx: 120 |  Loss: (0.0364) |  Loss2: (0.0000) | Acc: (98.00%) (15312/15488)
Epoch: 235 | Batch_idx: 130 |  Loss: (0.0370) |  Loss2: (0.0000) | Acc: (98.00%) (16572/16768)
Epoch: 235 | Batch_idx: 140 |  Loss: (0.0369) |  Loss2: (0.0000) | Acc: (98.00%) (17839/18048)
Epoch: 235 | Batch_idx: 150 |  Loss: (0.0365) |  Loss2: (0.0000) | Acc: (98.00%) (19105/19328)
Epoch: 235 | Batch_idx: 160 |  Loss: (0.0360) |  Loss2: (0.0000) | Acc: (98.00%) (20375/20608)
Epoch: 235 | Batch_idx: 170 |  Loss: (0.0356) |  Loss2: (0.0000) | Acc: (98.00%) (21643/21888)
Epoch: 235 | Batch_idx: 180 |  Loss: (0.0355) |  Loss2: (0.0000) | Acc: (98.00%) (22910/23168)
Epoch: 235 | Batch_idx: 190 |  Loss: (0.0353) |  Loss2: (0.0000) | Acc: (98.00%) (24179/24448)
Epoch: 235 | Batch_idx: 200 |  Loss: (0.0346) |  Loss2: (0.0000) | Acc: (98.00%) (25453/25728)
Epoch: 235 | Batch_idx: 210 |  Loss: (0.0347) |  Loss2: (0.0000) | Acc: (98.00%) (26718/27008)
Epoch: 235 | Batch_idx: 220 |  Loss: (0.0353) |  Loss2: (0.0000) | Acc: (98.00%) (27984/28288)
Epoch: 235 | Batch_idx: 230 |  Loss: (0.0349) |  Loss2: (0.0000) | Acc: (98.00%) (29253/29568)
Epoch: 235 | Batch_idx: 240 |  Loss: (0.0350) |  Loss2: (0.0000) | Acc: (98.00%) (30517/30848)
Epoch: 235 | Batch_idx: 250 |  Loss: (0.0345) |  Loss2: (0.0000) | Acc: (98.00%) (31792/32128)
Epoch: 235 | Batch_idx: 260 |  Loss: (0.0351) |  Loss2: (0.0000) | Acc: (98.00%) (33048/33408)
Epoch: 235 | Batch_idx: 270 |  Loss: (0.0352) |  Loss2: (0.0000) | Acc: (98.00%) (34313/34688)
Epoch: 235 | Batch_idx: 280 |  Loss: (0.0358) |  Loss2: (0.0000) | Acc: (98.00%) (35570/35968)
Epoch: 235 | Batch_idx: 290 |  Loss: (0.0363) |  Loss2: (0.0000) | Acc: (98.00%) (36830/37248)
Epoch: 235 | Batch_idx: 300 |  Loss: (0.0365) |  Loss2: (0.0000) | Acc: (98.00%) (38095/38528)
Epoch: 235 | Batch_idx: 310 |  Loss: (0.0365) |  Loss2: (0.0000) | Acc: (98.00%) (39359/39808)
Epoch: 235 | Batch_idx: 320 |  Loss: (0.0368) |  Loss2: (0.0000) | Acc: (98.00%) (40618/41088)
Epoch: 235 | Batch_idx: 330 |  Loss: (0.0366) |  Loss2: (0.0000) | Acc: (98.00%) (41886/42368)
Epoch: 235 | Batch_idx: 340 |  Loss: (0.0367) |  Loss2: (0.0000) | Acc: (98.00%) (43154/43648)
Epoch: 235 | Batch_idx: 350 |  Loss: (0.0365) |  Loss2: (0.0000) | Acc: (98.00%) (44421/44928)
Epoch: 235 | Batch_idx: 360 |  Loss: (0.0364) |  Loss2: (0.0000) | Acc: (98.00%) (45689/46208)
Epoch: 235 | Batch_idx: 370 |  Loss: (0.0362) |  Loss2: (0.0000) | Acc: (98.00%) (46961/47488)
Epoch: 235 | Batch_idx: 380 |  Loss: (0.0360) |  Loss2: (0.0000) | Acc: (98.00%) (48233/48768)
Epoch: 235 | Batch_idx: 390 |  Loss: (0.0358) |  Loss2: (0.0000) | Acc: (98.00%) (49455/50000)
=> saving checkpoint 'drive/app/torch/save_Schedule/checkpoint_235.pth.tar'
# TEST : Loss: (0.4547) | Acc: (89.00%) (8908/10000)
percent tensor([0.5276, 0.5323, 0.5441, 0.5288, 0.5451, 0.5271, 0.5375, 0.5349, 0.5333,
        0.5359, 0.5329, 0.5422, 0.5289, 0.5252, 0.5307, 0.5260],
       device='cuda:0') torch.Size([16])
percent tensor([0.5114, 0.4897, 0.5117, 0.5201, 0.5060, 0.5250, 0.4923, 0.5034, 0.5144,
        0.4952, 0.5134, 0.5025, 0.4945, 0.5111, 0.5018, 0.5135],
       device='cuda:0') torch.Size([16])
percent tensor([0.6753, 0.6809, 0.6047, 0.5752, 0.6090, 0.6305, 0.6853, 0.6174, 0.6119,
        0.6403, 0.6414, 0.6148, 0.7073, 0.6033, 0.6806, 0.6613],
       device='cuda:0') torch.Size([16])
percent tensor([0.6629, 0.6814, 0.6459, 0.7146, 0.6704, 0.7488, 0.6808, 0.6409, 0.6986,
        0.6758, 0.7028, 0.7050, 0.6744, 0.7183, 0.7213, 0.6989],
       device='cuda:0') torch.Size([16])
percent tensor([0.6215, 0.6498, 0.6228, 0.6048, 0.6543, 0.6431, 0.6447, 0.5667, 0.6901,
        0.6769, 0.6869, 0.5454, 0.6238, 0.7752, 0.5029, 0.6825],
       device='cuda:0') torch.Size([16])
percent tensor([0.7039, 0.6810, 0.7978, 0.7937, 0.8281, 0.8068, 0.7405, 0.7720, 0.7410,
        0.7281, 0.7186, 0.7655, 0.6970, 0.7427, 0.7353, 0.7522],
       device='cuda:0') torch.Size([16])
percent tensor([0.5701, 0.7607, 0.7118, 0.6479, 0.6631, 0.6191, 0.5365, 0.5446, 0.7350,
        0.6856, 0.7922, 0.6944, 0.7357, 0.6279, 0.5688, 0.4084],
       device='cuda:0') torch.Size([16])
percent tensor([0.9998, 0.9999, 0.9998, 0.9999, 0.9998, 0.9998, 0.9998, 0.9996, 1.0000,
        1.0000, 1.0000, 1.0000, 1.0000, 0.9997, 0.9995, 0.9995],
       device='cuda:0') torch.Size([16])
Epoch: 236 | Batch_idx: 0 |  Loss: (0.0274) |  Loss2: (0.0000) | Acc: (99.00%) (127/128)
Epoch: 236 | Batch_idx: 10 |  Loss: (0.0355) |  Loss2: (0.0000) | Acc: (98.00%) (1392/1408)
Epoch: 236 | Batch_idx: 20 |  Loss: (0.0369) |  Loss2: (0.0000) | Acc: (98.00%) (2659/2688)
Epoch: 236 | Batch_idx: 30 |  Loss: (0.0390) |  Loss2: (0.0000) | Acc: (98.00%) (3921/3968)
Epoch: 236 | Batch_idx: 40 |  Loss: (0.0376) |  Loss2: (0.0000) | Acc: (98.00%) (5191/5248)
Epoch: 236 | Batch_idx: 50 |  Loss: (0.0378) |  Loss2: (0.0000) | Acc: (98.00%) (6454/6528)
Epoch: 236 | Batch_idx: 60 |  Loss: (0.0372) |  Loss2: (0.0000) | Acc: (98.00%) (7722/7808)
Epoch: 236 | Batch_idx: 70 |  Loss: (0.0367) |  Loss2: (0.0000) | Acc: (98.00%) (8991/9088)
Epoch: 236 | Batch_idx: 80 |  Loss: (0.0361) |  Loss2: (0.0000) | Acc: (98.00%) (10260/10368)
Epoch: 236 | Batch_idx: 90 |  Loss: (0.0370) |  Loss2: (0.0000) | Acc: (98.00%) (11523/11648)
Epoch: 236 | Batch_idx: 100 |  Loss: (0.0371) |  Loss2: (0.0000) | Acc: (98.00%) (12786/12928)
Epoch: 236 | Batch_idx: 110 |  Loss: (0.0364) |  Loss2: (0.0000) | Acc: (98.00%) (14056/14208)
Epoch: 236 | Batch_idx: 120 |  Loss: (0.0372) |  Loss2: (0.0000) | Acc: (98.00%) (15312/15488)
Epoch: 236 | Batch_idx: 130 |  Loss: (0.0369) |  Loss2: (0.0000) | Acc: (98.00%) (16579/16768)
Epoch: 236 | Batch_idx: 140 |  Loss: (0.0375) |  Loss2: (0.0000) | Acc: (98.00%) (17837/18048)
Epoch: 236 | Batch_idx: 150 |  Loss: (0.0373) |  Loss2: (0.0000) | Acc: (98.00%) (19102/19328)
Epoch: 236 | Batch_idx: 160 |  Loss: (0.0378) |  Loss2: (0.0000) | Acc: (98.00%) (20360/20608)
Epoch: 236 | Batch_idx: 170 |  Loss: (0.0376) |  Loss2: (0.0000) | Acc: (98.00%) (21629/21888)
Epoch: 236 | Batch_idx: 180 |  Loss: (0.0380) |  Loss2: (0.0000) | Acc: (98.00%) (22891/23168)
Epoch: 236 | Batch_idx: 190 |  Loss: (0.0383) |  Loss2: (0.0000) | Acc: (98.00%) (24151/24448)
Epoch: 236 | Batch_idx: 200 |  Loss: (0.0382) |  Loss2: (0.0000) | Acc: (98.00%) (25412/25728)
Epoch: 236 | Batch_idx: 210 |  Loss: (0.0385) |  Loss2: (0.0000) | Acc: (98.00%) (26672/27008)
Epoch: 236 | Batch_idx: 220 |  Loss: (0.0387) |  Loss2: (0.0000) | Acc: (98.00%) (27934/28288)
Epoch: 236 | Batch_idx: 230 |  Loss: (0.0389) |  Loss2: (0.0000) | Acc: (98.00%) (29199/29568)
Epoch: 236 | Batch_idx: 240 |  Loss: (0.0389) |  Loss2: (0.0000) | Acc: (98.00%) (30464/30848)
Epoch: 236 | Batch_idx: 250 |  Loss: (0.0383) |  Loss2: (0.0000) | Acc: (98.00%) (31731/32128)
Epoch: 236 | Batch_idx: 260 |  Loss: (0.0381) |  Loss2: (0.0000) | Acc: (98.00%) (32996/33408)
Epoch: 236 | Batch_idx: 270 |  Loss: (0.0383) |  Loss2: (0.0000) | Acc: (98.00%) (34257/34688)
Epoch: 236 | Batch_idx: 280 |  Loss: (0.0380) |  Loss2: (0.0000) | Acc: (98.00%) (35526/35968)
Epoch: 236 | Batch_idx: 290 |  Loss: (0.0383) |  Loss2: (0.0000) | Acc: (98.00%) (36788/37248)
Epoch: 236 | Batch_idx: 300 |  Loss: (0.0380) |  Loss2: (0.0000) | Acc: (98.00%) (38055/38528)
Epoch: 236 | Batch_idx: 310 |  Loss: (0.0378) |  Loss2: (0.0000) | Acc: (98.00%) (39321/39808)
Epoch: 236 | Batch_idx: 320 |  Loss: (0.0379) |  Loss2: (0.0000) | Acc: (98.00%) (40584/41088)
Epoch: 236 | Batch_idx: 330 |  Loss: (0.0377) |  Loss2: (0.0000) | Acc: (98.00%) (41849/42368)
Epoch: 236 | Batch_idx: 340 |  Loss: (0.0376) |  Loss2: (0.0000) | Acc: (98.00%) (43112/43648)
Epoch: 236 | Batch_idx: 350 |  Loss: (0.0378) |  Loss2: (0.0000) | Acc: (98.00%) (44369/44928)
Epoch: 236 | Batch_idx: 360 |  Loss: (0.0377) |  Loss2: (0.0000) | Acc: (98.00%) (45639/46208)
Epoch: 236 | Batch_idx: 370 |  Loss: (0.0376) |  Loss2: (0.0000) | Acc: (98.00%) (46905/47488)
Epoch: 236 | Batch_idx: 380 |  Loss: (0.0376) |  Loss2: (0.0000) | Acc: (98.00%) (48173/48768)
Epoch: 236 | Batch_idx: 390 |  Loss: (0.0375) |  Loss2: (0.0000) | Acc: (98.00%) (49392/50000)
# TEST : Loss: (0.4525) | Acc: (89.00%) (8921/10000)
percent tensor([0.5288, 0.5331, 0.5455, 0.5299, 0.5466, 0.5286, 0.5385, 0.5359, 0.5341,
        0.5369, 0.5337, 0.5435, 0.5298, 0.5254, 0.5319, 0.5268],
       device='cuda:0') torch.Size([16])
percent tensor([0.5132, 0.4891, 0.5079, 0.5152, 0.5043, 0.5264, 0.4922, 0.5000, 0.5150,
        0.4943, 0.5146, 0.5005, 0.4966, 0.5083, 0.5024, 0.5130],
       device='cuda:0') torch.Size([16])
percent tensor([0.6781, 0.6785, 0.6045, 0.5754, 0.6078, 0.6289, 0.6859, 0.6167, 0.6116,
        0.6409, 0.6421, 0.6134, 0.7079, 0.6018, 0.6845, 0.6638],
       device='cuda:0') torch.Size([16])
percent tensor([0.6702, 0.6919, 0.6518, 0.7244, 0.6771, 0.7574, 0.6826, 0.6427, 0.7001,
        0.6808, 0.7077, 0.7056, 0.6735, 0.7260, 0.7303, 0.7018],
       device='cuda:0') torch.Size([16])
percent tensor([0.6283, 0.6528, 0.6317, 0.6046, 0.6647, 0.6686, 0.6490, 0.5662, 0.7019,
        0.6804, 0.7044, 0.5526, 0.6364, 0.7693, 0.5085, 0.6776],
       device='cuda:0') torch.Size([16])
percent tensor([0.7034, 0.6645, 0.7891, 0.7941, 0.8266, 0.8118, 0.7313, 0.7690, 0.7404,
        0.7226, 0.7155, 0.7583, 0.6858, 0.7314, 0.7330, 0.7497],
       device='cuda:0') torch.Size([16])
percent tensor([0.5557, 0.7680, 0.7080, 0.6559, 0.6588, 0.6223, 0.5366, 0.5591, 0.7002,
        0.6793, 0.8003, 0.7067, 0.7081, 0.6439, 0.5780, 0.4060],
       device='cuda:0') torch.Size([16])
percent tensor([0.9999, 1.0000, 0.9999, 0.9999, 0.9998, 0.9999, 0.9998, 0.9996, 0.9999,
        1.0000, 1.0000, 1.0000, 0.9999, 0.9997, 0.9996, 0.9997],
       device='cuda:0') torch.Size([16])
Epoch: 237 | Batch_idx: 0 |  Loss: (0.0450) |  Loss2: (0.0000) | Acc: (98.00%) (126/128)
Epoch: 237 | Batch_idx: 10 |  Loss: (0.0287) |  Loss2: (0.0000) | Acc: (99.00%) (1395/1408)
Epoch: 237 | Batch_idx: 20 |  Loss: (0.0292) |  Loss2: (0.0000) | Acc: (99.00%) (2665/2688)
Epoch: 237 | Batch_idx: 30 |  Loss: (0.0288) |  Loss2: (0.0000) | Acc: (99.00%) (3936/3968)
Epoch: 237 | Batch_idx: 40 |  Loss: (0.0307) |  Loss2: (0.0000) | Acc: (99.00%) (5201/5248)
Epoch: 237 | Batch_idx: 50 |  Loss: (0.0314) |  Loss2: (0.0000) | Acc: (99.00%) (6469/6528)
Epoch: 237 | Batch_idx: 60 |  Loss: (0.0322) |  Loss2: (0.0000) | Acc: (99.00%) (7735/7808)
Epoch: 237 | Batch_idx: 70 |  Loss: (0.0337) |  Loss2: (0.0000) | Acc: (99.00%) (8998/9088)
Epoch: 237 | Batch_idx: 80 |  Loss: (0.0350) |  Loss2: (0.0000) | Acc: (98.00%) (10257/10368)
Epoch: 237 | Batch_idx: 90 |  Loss: (0.0349) |  Loss2: (0.0000) | Acc: (98.00%) (11523/11648)
Epoch: 237 | Batch_idx: 100 |  Loss: (0.0360) |  Loss2: (0.0000) | Acc: (98.00%) (12785/12928)
Epoch: 237 | Batch_idx: 110 |  Loss: (0.0370) |  Loss2: (0.0000) | Acc: (98.00%) (14049/14208)
Epoch: 237 | Batch_idx: 120 |  Loss: (0.0369) |  Loss2: (0.0000) | Acc: (98.00%) (15316/15488)
Epoch: 237 | Batch_idx: 130 |  Loss: (0.0366) |  Loss2: (0.0000) | Acc: (98.00%) (16579/16768)
Epoch: 237 | Batch_idx: 140 |  Loss: (0.0368) |  Loss2: (0.0000) | Acc: (98.00%) (17844/18048)
Epoch: 237 | Batch_idx: 150 |  Loss: (0.0366) |  Loss2: (0.0000) | Acc: (98.00%) (19109/19328)
Epoch: 237 | Batch_idx: 160 |  Loss: (0.0369) |  Loss2: (0.0000) | Acc: (98.00%) (20371/20608)
Epoch: 237 | Batch_idx: 170 |  Loss: (0.0364) |  Loss2: (0.0000) | Acc: (98.00%) (21641/21888)
Epoch: 237 | Batch_idx: 180 |  Loss: (0.0361) |  Loss2: (0.0000) | Acc: (98.00%) (22910/23168)
Epoch: 237 | Batch_idx: 190 |  Loss: (0.0359) |  Loss2: (0.0000) | Acc: (98.00%) (24176/24448)
Epoch: 237 | Batch_idx: 200 |  Loss: (0.0362) |  Loss2: (0.0000) | Acc: (98.00%) (25443/25728)
Epoch: 237 | Batch_idx: 210 |  Loss: (0.0361) |  Loss2: (0.0000) | Acc: (98.00%) (26710/27008)
Epoch: 237 | Batch_idx: 220 |  Loss: (0.0357) |  Loss2: (0.0000) | Acc: (98.00%) (27978/28288)
Epoch: 237 | Batch_idx: 230 |  Loss: (0.0361) |  Loss2: (0.0000) | Acc: (98.00%) (29241/29568)
Epoch: 237 | Batch_idx: 240 |  Loss: (0.0358) |  Loss2: (0.0000) | Acc: (98.00%) (30511/30848)
Epoch: 237 | Batch_idx: 250 |  Loss: (0.0358) |  Loss2: (0.0000) | Acc: (98.00%) (31781/32128)
Epoch: 237 | Batch_idx: 260 |  Loss: (0.0358) |  Loss2: (0.0000) | Acc: (98.00%) (33045/33408)
Epoch: 237 | Batch_idx: 270 |  Loss: (0.0357) |  Loss2: (0.0000) | Acc: (98.00%) (34308/34688)
Epoch: 237 | Batch_idx: 280 |  Loss: (0.0356) |  Loss2: (0.0000) | Acc: (98.00%) (35575/35968)
Epoch: 237 | Batch_idx: 290 |  Loss: (0.0354) |  Loss2: (0.0000) | Acc: (98.00%) (36841/37248)
Epoch: 237 | Batch_idx: 300 |  Loss: (0.0356) |  Loss2: (0.0000) | Acc: (98.00%) (38107/38528)
Epoch: 237 | Batch_idx: 310 |  Loss: (0.0357) |  Loss2: (0.0000) | Acc: (98.00%) (39374/39808)
Epoch: 237 | Batch_idx: 320 |  Loss: (0.0354) |  Loss2: (0.0000) | Acc: (98.00%) (40642/41088)
Epoch: 237 | Batch_idx: 330 |  Loss: (0.0354) |  Loss2: (0.0000) | Acc: (98.00%) (41905/42368)
Epoch: 237 | Batch_idx: 340 |  Loss: (0.0355) |  Loss2: (0.0000) | Acc: (98.00%) (43170/43648)
Epoch: 237 | Batch_idx: 350 |  Loss: (0.0354) |  Loss2: (0.0000) | Acc: (98.00%) (44439/44928)
Epoch: 237 | Batch_idx: 360 |  Loss: (0.0353) |  Loss2: (0.0000) | Acc: (98.00%) (45704/46208)
Epoch: 237 | Batch_idx: 370 |  Loss: (0.0352) |  Loss2: (0.0000) | Acc: (98.00%) (46970/47488)
Epoch: 237 | Batch_idx: 380 |  Loss: (0.0352) |  Loss2: (0.0000) | Acc: (98.00%) (48235/48768)
Epoch: 237 | Batch_idx: 390 |  Loss: (0.0351) |  Loss2: (0.0000) | Acc: (98.00%) (49455/50000)
# TEST : Loss: (0.4396) | Acc: (89.00%) (8928/10000)
percent tensor([0.5293, 0.5343, 0.5453, 0.5312, 0.5462, 0.5297, 0.5389, 0.5370, 0.5346,
        0.5373, 0.5348, 0.5431, 0.5305, 0.5270, 0.5332, 0.5281],
       device='cuda:0') torch.Size([16])
percent tensor([0.5116, 0.4891, 0.5106, 0.5192, 0.5064, 0.5259, 0.4921, 0.5015, 0.5142,
        0.4943, 0.5136, 0.5002, 0.4942, 0.5091, 0.5019, 0.5131],
       device='cuda:0') torch.Size([16])
percent tensor([0.6786, 0.6839, 0.6020, 0.5790, 0.6036, 0.6359, 0.6863, 0.6173, 0.6201,
        0.6424, 0.6494, 0.6112, 0.7116, 0.6097, 0.6869, 0.6655],
       device='cuda:0') torch.Size([16])
percent tensor([0.6604, 0.6873, 0.6484, 0.7159, 0.6715, 0.7440, 0.6810, 0.6369, 0.6975,
        0.6726, 0.6958, 0.7065, 0.6657, 0.7219, 0.7207, 0.6967],
       device='cuda:0') torch.Size([16])
percent tensor([0.6363, 0.6491, 0.6346, 0.6087, 0.6743, 0.6706, 0.6443, 0.5715, 0.6865,
        0.6666, 0.6941, 0.5538, 0.6223, 0.7616, 0.5125, 0.6795],
       device='cuda:0') torch.Size([16])
percent tensor([0.7168, 0.6869, 0.8121, 0.8044, 0.8409, 0.8108, 0.7465, 0.7849, 0.7449,
        0.7338, 0.7270, 0.7740, 0.7005, 0.7384, 0.7434, 0.7571],
       device='cuda:0') torch.Size([16])
percent tensor([0.5400, 0.7777, 0.7110, 0.6421, 0.6767, 0.6316, 0.5551, 0.5468, 0.7268,
        0.6706, 0.7979, 0.7010, 0.7294, 0.6144, 0.5843, 0.4041],
       device='cuda:0') torch.Size([16])
percent tensor([0.9998, 0.9999, 0.9998, 0.9999, 0.9998, 0.9997, 0.9997, 0.9995, 0.9999,
        0.9999, 1.0000, 1.0000, 0.9999, 0.9996, 0.9994, 0.9995],
       device='cuda:0') torch.Size([16])
Epoch: 238 | Batch_idx: 0 |  Loss: (0.0205) |  Loss2: (0.0000) | Acc: (100.00%) (128/128)
Epoch: 238 | Batch_idx: 10 |  Loss: (0.0306) |  Loss2: (0.0000) | Acc: (99.00%) (1397/1408)
Epoch: 238 | Batch_idx: 20 |  Loss: (0.0352) |  Loss2: (0.0000) | Acc: (98.00%) (2658/2688)
Epoch: 238 | Batch_idx: 30 |  Loss: (0.0404) |  Loss2: (0.0000) | Acc: (98.00%) (3915/3968)
Epoch: 238 | Batch_idx: 40 |  Loss: (0.0398) |  Loss2: (0.0000) | Acc: (98.00%) (5181/5248)
Epoch: 238 | Batch_idx: 50 |  Loss: (0.0399) |  Loss2: (0.0000) | Acc: (98.00%) (6441/6528)
Epoch: 238 | Batch_idx: 60 |  Loss: (0.0380) |  Loss2: (0.0000) | Acc: (98.00%) (7712/7808)
Epoch: 238 | Batch_idx: 70 |  Loss: (0.0382) |  Loss2: (0.0000) | Acc: (98.00%) (8975/9088)
Epoch: 238 | Batch_idx: 80 |  Loss: (0.0387) |  Loss2: (0.0000) | Acc: (98.00%) (10238/10368)
Epoch: 238 | Batch_idx: 90 |  Loss: (0.0401) |  Loss2: (0.0000) | Acc: (98.00%) (11492/11648)
Epoch: 238 | Batch_idx: 100 |  Loss: (0.0392) |  Loss2: (0.0000) | Acc: (98.00%) (12762/12928)
Epoch: 238 | Batch_idx: 110 |  Loss: (0.0393) |  Loss2: (0.0000) | Acc: (98.00%) (14023/14208)
Epoch: 238 | Batch_idx: 120 |  Loss: (0.0390) |  Loss2: (0.0000) | Acc: (98.00%) (15291/15488)
Epoch: 238 | Batch_idx: 130 |  Loss: (0.0394) |  Loss2: (0.0000) | Acc: (98.00%) (16551/16768)
Epoch: 238 | Batch_idx: 140 |  Loss: (0.0395) |  Loss2: (0.0000) | Acc: (98.00%) (17812/18048)
Epoch: 238 | Batch_idx: 150 |  Loss: (0.0385) |  Loss2: (0.0000) | Acc: (98.00%) (19086/19328)
Epoch: 238 | Batch_idx: 160 |  Loss: (0.0386) |  Loss2: (0.0000) | Acc: (98.00%) (20349/20608)
Epoch: 238 | Batch_idx: 170 |  Loss: (0.0385) |  Loss2: (0.0000) | Acc: (98.00%) (21615/21888)
Epoch: 238 | Batch_idx: 180 |  Loss: (0.0384) |  Loss2: (0.0000) | Acc: (98.00%) (22878/23168)
Epoch: 238 | Batch_idx: 190 |  Loss: (0.0392) |  Loss2: (0.0000) | Acc: (98.00%) (24130/24448)
Epoch: 238 | Batch_idx: 200 |  Loss: (0.0392) |  Loss2: (0.0000) | Acc: (98.00%) (25390/25728)
Epoch: 238 | Batch_idx: 210 |  Loss: (0.0391) |  Loss2: (0.0000) | Acc: (98.00%) (26648/27008)
Epoch: 238 | Batch_idx: 220 |  Loss: (0.0391) |  Loss2: (0.0000) | Acc: (98.00%) (27913/28288)
Epoch: 238 | Batch_idx: 230 |  Loss: (0.0387) |  Loss2: (0.0000) | Acc: (98.00%) (29186/29568)
Epoch: 238 | Batch_idx: 240 |  Loss: (0.0385) |  Loss2: (0.0000) | Acc: (98.00%) (30453/30848)
Epoch: 238 | Batch_idx: 250 |  Loss: (0.0387) |  Loss2: (0.0000) | Acc: (98.00%) (31711/32128)
Epoch: 238 | Batch_idx: 260 |  Loss: (0.0389) |  Loss2: (0.0000) | Acc: (98.00%) (32978/33408)
Epoch: 238 | Batch_idx: 270 |  Loss: (0.0390) |  Loss2: (0.0000) | Acc: (98.00%) (34239/34688)
Epoch: 238 | Batch_idx: 280 |  Loss: (0.0392) |  Loss2: (0.0000) | Acc: (98.00%) (35501/35968)
Epoch: 238 | Batch_idx: 290 |  Loss: (0.0389) |  Loss2: (0.0000) | Acc: (98.00%) (36766/37248)
Epoch: 238 | Batch_idx: 300 |  Loss: (0.0391) |  Loss2: (0.0000) | Acc: (98.00%) (38026/38528)
Epoch: 238 | Batch_idx: 310 |  Loss: (0.0390) |  Loss2: (0.0000) | Acc: (98.00%) (39295/39808)
Epoch: 238 | Batch_idx: 320 |  Loss: (0.0387) |  Loss2: (0.0000) | Acc: (98.00%) (40560/41088)
Epoch: 238 | Batch_idx: 330 |  Loss: (0.0390) |  Loss2: (0.0000) | Acc: (98.00%) (41819/42368)
Epoch: 238 | Batch_idx: 340 |  Loss: (0.0389) |  Loss2: (0.0000) | Acc: (98.00%) (43085/43648)
Epoch: 238 | Batch_idx: 350 |  Loss: (0.0389) |  Loss2: (0.0000) | Acc: (98.00%) (44349/44928)
Epoch: 238 | Batch_idx: 360 |  Loss: (0.0390) |  Loss2: (0.0000) | Acc: (98.00%) (45611/46208)
Epoch: 238 | Batch_idx: 370 |  Loss: (0.0389) |  Loss2: (0.0000) | Acc: (98.00%) (46878/47488)
Epoch: 238 | Batch_idx: 380 |  Loss: (0.0387) |  Loss2: (0.0000) | Acc: (98.00%) (48143/48768)
Epoch: 238 | Batch_idx: 390 |  Loss: (0.0385) |  Loss2: (0.0000) | Acc: (98.00%) (49364/50000)
# TEST : Loss: (0.4506) | Acc: (89.00%) (8938/10000)
percent tensor([0.5285, 0.5332, 0.5453, 0.5306, 0.5462, 0.5286, 0.5381, 0.5362, 0.5339,
        0.5367, 0.5335, 0.5434, 0.5297, 0.5254, 0.5320, 0.5273],
       device='cuda:0') torch.Size([16])
percent tensor([0.5141, 0.4909, 0.5131, 0.5188, 0.5098, 0.5277, 0.4958, 0.5030, 0.5178,
        0.4953, 0.5161, 0.5045, 0.4966, 0.5121, 0.5034, 0.5150],
       device='cuda:0') torch.Size([16])
percent tensor([0.6770, 0.6796, 0.6102, 0.5790, 0.6125, 0.6325, 0.6871, 0.6193, 0.6166,
        0.6427, 0.6402, 0.6190, 0.7120, 0.5988, 0.6851, 0.6639],
       device='cuda:0') torch.Size([16])
percent tensor([0.6576, 0.6847, 0.6433, 0.7065, 0.6690, 0.7398, 0.6796, 0.6369, 0.6946,
        0.6745, 0.6941, 0.7087, 0.6685, 0.7206, 0.7139, 0.6876],
       device='cuda:0') torch.Size([16])
percent tensor([0.6460, 0.6666, 0.6462, 0.6115, 0.6812, 0.6788, 0.6704, 0.5858, 0.7012,
        0.6809, 0.7072, 0.5636, 0.6408, 0.7723, 0.5293, 0.6924],
       device='cuda:0') torch.Size([16])
percent tensor([0.7035, 0.6727, 0.8015, 0.7972, 0.8314, 0.8170, 0.7373, 0.7781, 0.7382,
        0.7231, 0.7141, 0.7585, 0.6950, 0.7310, 0.7287, 0.7555],
       device='cuda:0') torch.Size([16])
percent tensor([0.4905, 0.7406, 0.7051, 0.6555, 0.6551, 0.5715, 0.4870, 0.5479, 0.7013,
        0.6619, 0.7955, 0.6760, 0.6837, 0.6277, 0.5346, 0.3821],
       device='cuda:0') torch.Size([16])
percent tensor([0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9998, 0.9998, 0.9996, 0.9998,
        1.0000, 1.0000, 0.9999, 0.9999, 0.9997, 0.9995, 0.9997],
       device='cuda:0') torch.Size([16])
Epoch: 239 | Batch_idx: 0 |  Loss: (0.0158) |  Loss2: (0.0000) | Acc: (100.00%) (128/128)
Epoch: 239 | Batch_idx: 10 |  Loss: (0.0292) |  Loss2: (0.0000) | Acc: (99.00%) (1401/1408)
Epoch: 239 | Batch_idx: 20 |  Loss: (0.0318) |  Loss2: (0.0000) | Acc: (99.00%) (2667/2688)
Epoch: 239 | Batch_idx: 30 |  Loss: (0.0315) |  Loss2: (0.0000) | Acc: (99.00%) (3936/3968)
Epoch: 239 | Batch_idx: 40 |  Loss: (0.0298) |  Loss2: (0.0000) | Acc: (99.00%) (5208/5248)
Epoch: 239 | Batch_idx: 50 |  Loss: (0.0308) |  Loss2: (0.0000) | Acc: (99.00%) (6473/6528)
Epoch: 239 | Batch_idx: 60 |  Loss: (0.0311) |  Loss2: (0.0000) | Acc: (99.00%) (7736/7808)
Epoch: 239 | Batch_idx: 70 |  Loss: (0.0316) |  Loss2: (0.0000) | Acc: (99.00%) (9002/9088)
Epoch: 239 | Batch_idx: 80 |  Loss: (0.0315) |  Loss2: (0.0000) | Acc: (99.00%) (10269/10368)
Epoch: 239 | Batch_idx: 90 |  Loss: (0.0309) |  Loss2: (0.0000) | Acc: (99.00%) (11539/11648)
Epoch: 239 | Batch_idx: 100 |  Loss: (0.0308) |  Loss2: (0.0000) | Acc: (99.00%) (12807/12928)
Epoch: 239 | Batch_idx: 110 |  Loss: (0.0308) |  Loss2: (0.0000) | Acc: (99.00%) (14072/14208)
Epoch: 239 | Batch_idx: 120 |  Loss: (0.0313) |  Loss2: (0.0000) | Acc: (99.00%) (15334/15488)
Epoch: 239 | Batch_idx: 130 |  Loss: (0.0315) |  Loss2: (0.0000) | Acc: (98.00%) (16599/16768)
Epoch: 239 | Batch_idx: 140 |  Loss: (0.0316) |  Loss2: (0.0000) | Acc: (98.00%) (17866/18048)
Epoch: 239 | Batch_idx: 150 |  Loss: (0.0322) |  Loss2: (0.0000) | Acc: (98.00%) (19130/19328)
Epoch: 239 | Batch_idx: 160 |  Loss: (0.0321) |  Loss2: (0.0000) | Acc: (99.00%) (20402/20608)
Epoch: 239 | Batch_idx: 170 |  Loss: (0.0318) |  Loss2: (0.0000) | Acc: (99.00%) (21672/21888)
Epoch: 239 | Batch_idx: 180 |  Loss: (0.0325) |  Loss2: (0.0000) | Acc: (98.00%) (22936/23168)
Epoch: 239 | Batch_idx: 190 |  Loss: (0.0329) |  Loss2: (0.0000) | Acc: (98.00%) (24196/24448)
Epoch: 239 | Batch_idx: 200 |  Loss: (0.0330) |  Loss2: (0.0000) | Acc: (98.00%) (25462/25728)
Epoch: 239 | Batch_idx: 210 |  Loss: (0.0328) |  Loss2: (0.0000) | Acc: (98.00%) (26733/27008)
Epoch: 239 | Batch_idx: 220 |  Loss: (0.0327) |  Loss2: (0.0000) | Acc: (98.00%) (28000/28288)
Epoch: 239 | Batch_idx: 230 |  Loss: (0.0331) |  Loss2: (0.0000) | Acc: (98.00%) (29261/29568)
Epoch: 239 | Batch_idx: 240 |  Loss: (0.0330) |  Loss2: (0.0000) | Acc: (98.00%) (30531/30848)
Epoch: 239 | Batch_idx: 250 |  Loss: (0.0334) |  Loss2: (0.0000) | Acc: (98.00%) (31795/32128)
Epoch: 239 | Batch_idx: 260 |  Loss: (0.0334) |  Loss2: (0.0000) | Acc: (98.00%) (33061/33408)
Epoch: 239 | Batch_idx: 270 |  Loss: (0.0333) |  Loss2: (0.0000) | Acc: (98.00%) (34332/34688)
Epoch: 239 | Batch_idx: 280 |  Loss: (0.0334) |  Loss2: (0.0000) | Acc: (98.00%) (35595/35968)
Epoch: 239 | Batch_idx: 290 |  Loss: (0.0332) |  Loss2: (0.0000) | Acc: (98.00%) (36865/37248)
Epoch: 239 | Batch_idx: 300 |  Loss: (0.0330) |  Loss2: (0.0000) | Acc: (98.00%) (38135/38528)
Epoch: 239 | Batch_idx: 310 |  Loss: (0.0331) |  Loss2: (0.0000) | Acc: (98.00%) (39398/39808)
Epoch: 239 | Batch_idx: 320 |  Loss: (0.0328) |  Loss2: (0.0000) | Acc: (98.00%) (40666/41088)
Epoch: 239 | Batch_idx: 330 |  Loss: (0.0329) |  Loss2: (0.0000) | Acc: (98.00%) (41929/42368)
Epoch: 239 | Batch_idx: 340 |  Loss: (0.0332) |  Loss2: (0.0000) | Acc: (98.00%) (43193/43648)
Epoch: 239 | Batch_idx: 350 |  Loss: (0.0333) |  Loss2: (0.0000) | Acc: (98.00%) (44457/44928)
Epoch: 239 | Batch_idx: 360 |  Loss: (0.0337) |  Loss2: (0.0000) | Acc: (98.00%) (45716/46208)
Epoch: 239 | Batch_idx: 370 |  Loss: (0.0338) |  Loss2: (0.0000) | Acc: (98.00%) (46980/47488)
Epoch: 239 | Batch_idx: 380 |  Loss: (0.0340) |  Loss2: (0.0000) | Acc: (98.00%) (48243/48768)
Epoch: 239 | Batch_idx: 390 |  Loss: (0.0342) |  Loss2: (0.0000) | Acc: (98.00%) (49458/50000)
# TEST : Loss: (0.4569) | Acc: (89.00%) (8923/10000)
percent tensor([0.5299, 0.5359, 0.5466, 0.5322, 0.5474, 0.5296, 0.5407, 0.5386, 0.5364,
        0.5389, 0.5360, 0.5449, 0.5317, 0.5293, 0.5339, 0.5291],
       device='cuda:0') torch.Size([16])
percent tensor([0.5101, 0.4880, 0.5079, 0.5161, 0.5047, 0.5257, 0.4908, 0.4988, 0.5122,
        0.4928, 0.5127, 0.4988, 0.4931, 0.5069, 0.5002, 0.5117],
       device='cuda:0') torch.Size([16])
percent tensor([0.6738, 0.6842, 0.6012, 0.5772, 0.6038, 0.6205, 0.6861, 0.6213, 0.6125,
        0.6439, 0.6422, 0.6133, 0.7084, 0.6085, 0.6817, 0.6597],
       device='cuda:0') torch.Size([16])
percent tensor([0.6522, 0.6808, 0.6396, 0.7114, 0.6626, 0.7413, 0.6740, 0.6278, 0.6870,
        0.6639, 0.6890, 0.7040, 0.6546, 0.7192, 0.7111, 0.6893],
       device='cuda:0') torch.Size([16])
percent tensor([0.6381, 0.6595, 0.6334, 0.6057, 0.6698, 0.6630, 0.6555, 0.5777, 0.6960,
        0.6682, 0.7038, 0.5538, 0.6326, 0.7721, 0.5161, 0.6813],
       device='cuda:0') torch.Size([16])
percent tensor([0.7031, 0.6755, 0.7992, 0.8031, 0.8296, 0.8134, 0.7417, 0.7820, 0.7378,
        0.7218, 0.7132, 0.7752, 0.6975, 0.7269, 0.7417, 0.7516],
       device='cuda:0') torch.Size([16])
percent tensor([0.5017, 0.7436, 0.6933, 0.6593, 0.6622, 0.5846, 0.5338, 0.5261, 0.7158,
        0.6550, 0.7984, 0.6972, 0.7038, 0.6053, 0.5610, 0.3948],
       device='cuda:0') torch.Size([16])
percent tensor([0.9998, 1.0000, 0.9998, 0.9999, 0.9998, 0.9998, 0.9998, 0.9996, 0.9999,
        1.0000, 1.0000, 1.0000, 0.9999, 0.9997, 0.9994, 0.9996],
       device='cuda:0') torch.Size([16])
Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 3, 3, 3]) tensor(195.8649, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(836.7278, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(848.2100, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([128, 64, 3, 3]) tensor(1527.8217, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([128, 64, 1, 1]) tensor(470.0894, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([128, 128, 3, 3]) tensor(2366.4097, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([256, 128, 3, 3]) tensor(4277.6680, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([256, 128, 1, 1]) tensor(1325.9723, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([256, 256, 3, 3]) tensor(6399.0757, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([512, 256, 3, 3]) tensor(11413.0811, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([512, 256, 1, 1]) tensor(3734.1377, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([512, 512, 3, 3]) tensor(15742.8887, device='cuda:0', grad_fn=<NormBackward0>)
6 hours 8 mins 5 secs for training