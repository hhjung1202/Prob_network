Files already downloaded and verified
USE 1 GPUs!
Epoch: 0 | Batch_idx: 0 |  Loss: (2.3125) |  Loss2: (0.0000) | Acc: (12.00%) (16/128)
Epoch: 0 | Batch_idx: 10 |  Loss: (2.3062) |  Loss2: (0.0000) | Acc: (11.00%) (168/1408)
Epoch: 0 | Batch_idx: 20 |  Loss: (2.2976) |  Loss2: (0.0000) | Acc: (12.00%) (327/2688)
Epoch: 0 | Batch_idx: 30 |  Loss: (2.2936) |  Loss2: (0.0000) | Acc: (12.00%) (491/3968)
Epoch: 0 | Batch_idx: 40 |  Loss: (2.2864) |  Loss2: (0.0000) | Acc: (13.00%) (694/5248)
Epoch: 0 | Batch_idx: 50 |  Loss: (2.2792) |  Loss2: (0.0000) | Acc: (14.00%) (922/6528)
Epoch: 0 | Batch_idx: 60 |  Loss: (2.2703) |  Loss2: (0.0000) | Acc: (15.00%) (1218/7808)
Epoch: 0 | Batch_idx: 70 |  Loss: (2.2629) |  Loss2: (0.0000) | Acc: (16.00%) (1486/9088)
Epoch: 0 | Batch_idx: 80 |  Loss: (2.2554) |  Loss2: (0.0000) | Acc: (16.00%) (1751/10368)
Epoch: 0 | Batch_idx: 90 |  Loss: (2.2461) |  Loss2: (0.0000) | Acc: (17.00%) (2066/11648)
Epoch: 0 | Batch_idx: 100 |  Loss: (2.2367) |  Loss2: (0.0000) | Acc: (18.00%) (2367/12928)
Epoch: 0 | Batch_idx: 110 |  Loss: (2.2286) |  Loss2: (0.0000) | Acc: (18.00%) (2654/14208)
Epoch: 0 | Batch_idx: 120 |  Loss: (2.2198) |  Loss2: (0.0000) | Acc: (19.00%) (2951/15488)
Epoch: 0 | Batch_idx: 130 |  Loss: (2.2114) |  Loss2: (0.0000) | Acc: (19.00%) (3255/16768)
Epoch: 0 | Batch_idx: 140 |  Loss: (2.2033) |  Loss2: (0.0000) | Acc: (19.00%) (3564/18048)
Epoch: 0 | Batch_idx: 150 |  Loss: (2.1947) |  Loss2: (0.0000) | Acc: (20.00%) (3883/19328)
Epoch: 0 | Batch_idx: 160 |  Loss: (2.1859) |  Loss2: (0.0000) | Acc: (20.00%) (4209/20608)
Epoch: 0 | Batch_idx: 170 |  Loss: (2.1759) |  Loss2: (0.0000) | Acc: (20.00%) (4568/21888)
Epoch: 0 | Batch_idx: 180 |  Loss: (2.1685) |  Loss2: (0.0000) | Acc: (20.00%) (4853/23168)
Epoch: 0 | Batch_idx: 190 |  Loss: (2.1616) |  Loss2: (0.0000) | Acc: (21.00%) (5166/24448)
Epoch: 0 | Batch_idx: 200 |  Loss: (2.1539) |  Loss2: (0.0000) | Acc: (21.00%) (5502/25728)
Epoch: 0 | Batch_idx: 210 |  Loss: (2.1463) |  Loss2: (0.0000) | Acc: (21.00%) (5827/27008)
Epoch: 0 | Batch_idx: 220 |  Loss: (2.1396) |  Loss2: (0.0000) | Acc: (21.00%) (6154/28288)
Epoch: 0 | Batch_idx: 230 |  Loss: (2.1325) |  Loss2: (0.0000) | Acc: (22.00%) (6513/29568)
Epoch: 0 | Batch_idx: 240 |  Loss: (2.1250) |  Loss2: (0.0000) | Acc: (22.00%) (6882/30848)
Epoch: 0 | Batch_idx: 250 |  Loss: (2.1184) |  Loss2: (0.0000) | Acc: (22.00%) (7245/32128)
Epoch: 0 | Batch_idx: 260 |  Loss: (2.1118) |  Loss2: (0.0000) | Acc: (22.00%) (7596/33408)
Epoch: 0 | Batch_idx: 270 |  Loss: (2.1049) |  Loss2: (0.0000) | Acc: (23.00%) (7981/34688)
Epoch: 0 | Batch_idx: 280 |  Loss: (2.0990) |  Loss2: (0.0000) | Acc: (23.00%) (8340/35968)
Epoch: 0 | Batch_idx: 290 |  Loss: (2.0924) |  Loss2: (0.0000) | Acc: (23.00%) (8723/37248)
Epoch: 0 | Batch_idx: 300 |  Loss: (2.0854) |  Loss2: (0.0000) | Acc: (23.00%) (9138/38528)
Epoch: 0 | Batch_idx: 310 |  Loss: (2.0792) |  Loss2: (0.0000) | Acc: (23.00%) (9508/39808)
Epoch: 0 | Batch_idx: 320 |  Loss: (2.0725) |  Loss2: (0.0000) | Acc: (24.00%) (9905/41088)
Epoch: 0 | Batch_idx: 330 |  Loss: (2.0663) |  Loss2: (0.0000) | Acc: (24.00%) (10286/42368)
Epoch: 0 | Batch_idx: 340 |  Loss: (2.0610) |  Loss2: (0.0000) | Acc: (24.00%) (10698/43648)
Epoch: 0 | Batch_idx: 350 |  Loss: (2.0552) |  Loss2: (0.0000) | Acc: (24.00%) (11113/44928)
Epoch: 0 | Batch_idx: 360 |  Loss: (2.0495) |  Loss2: (0.0000) | Acc: (24.00%) (11526/46208)
Epoch: 0 | Batch_idx: 370 |  Loss: (2.0445) |  Loss2: (0.0000) | Acc: (25.00%) (11948/47488)
Epoch: 0 | Batch_idx: 380 |  Loss: (2.0395) |  Loss2: (0.0000) | Acc: (25.00%) (12345/48768)
Epoch: 0 | Batch_idx: 390 |  Loss: (2.0346) |  Loss2: (0.0000) | Acc: (25.00%) (12745/50000)
/usr/local/lib/python3.6/dist-packages/torch/serialization.py:241: UserWarning: Couldn't retrieve source code for container of type ResNet. It won't be checked for correctness upon loading.
  "type " + obj.__name__ + ". It won't be checked "
/usr/local/lib/python3.6/dist-packages/torch/serialization.py:241: UserWarning: Couldn't retrieve source code for container of type BasicBlock. It won't be checked for correctness upon loading.
  "type " + obj.__name__ + ". It won't be checked "
/usr/local/lib/python3.6/dist-packages/torch/serialization.py:241: UserWarning: Couldn't retrieve source code for container of type _Gate. It won't be checked for correctness upon loading.
  "type " + obj.__name__ + ". It won't be checked "
=> saving checkpoint 'drive/app/torch/save_Schedule/checkpoint_000.pth.tar'
# TEST : Loss: (1.8287) | Acc: (31.00%) (3155/10000)
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 3, 3, 3]) tensor(167.6931, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(762.6533, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(766.9043, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([128, 64, 3, 3]) tensor(1537.0205, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([128, 64, 1, 1]) tensor(516.4957, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([128, 128, 3, 3]) tensor(2175.7988, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([256, 128, 3, 3]) tensor(4350.7666, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([256, 128, 1, 1]) tensor(1440.4689, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([256, 256, 3, 3]) tensor(6136.3564, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([512, 256, 3, 3]) tensor(12284.6377, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([512, 256, 1, 1]) tensor(4096.1021, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([512, 512, 3, 3]) tensor(17365.4473, device='cuda:0', grad_fn=<NormBackward0>)
Epoch: 1 | Batch_idx: 0 |  Loss: (1.8982) |  Loss2: (0.0000) | Acc: (30.00%) (39/128)
Epoch: 1 | Batch_idx: 10 |  Loss: (1.8299) |  Loss2: (0.0000) | Acc: (33.00%) (466/1408)
Epoch: 1 | Batch_idx: 20 |  Loss: (1.8239) |  Loss2: (0.0000) | Acc: (33.00%) (910/2688)
Epoch: 1 | Batch_idx: 30 |  Loss: (1.8092) |  Loss2: (0.0000) | Acc: (34.00%) (1377/3968)
Epoch: 1 | Batch_idx: 40 |  Loss: (1.8046) |  Loss2: (0.0000) | Acc: (34.00%) (1808/5248)
Epoch: 1 | Batch_idx: 50 |  Loss: (1.8020) |  Loss2: (0.0000) | Acc: (34.00%) (2246/6528)
Epoch: 1 | Batch_idx: 60 |  Loss: (1.7998) |  Loss2: (0.0000) | Acc: (34.00%) (2661/7808)
Epoch: 1 | Batch_idx: 70 |  Loss: (1.7967) |  Loss2: (0.0000) | Acc: (34.00%) (3097/9088)
Epoch: 1 | Batch_idx: 80 |  Loss: (1.7905) |  Loss2: (0.0000) | Acc: (34.00%) (3570/10368)
Epoch: 1 | Batch_idx: 90 |  Loss: (1.7867) |  Loss2: (0.0000) | Acc: (34.00%) (4023/11648)
Epoch: 1 | Batch_idx: 100 |  Loss: (1.7818) |  Loss2: (0.0000) | Acc: (34.00%) (4499/12928)
Epoch: 1 | Batch_idx: 110 |  Loss: (1.7799) |  Loss2: (0.0000) | Acc: (34.00%) (4958/14208)
Epoch: 1 | Batch_idx: 120 |  Loss: (1.7757) |  Loss2: (0.0000) | Acc: (34.00%) (5408/15488)
Epoch: 1 | Batch_idx: 130 |  Loss: (1.7727) |  Loss2: (0.0000) | Acc: (35.00%) (5874/16768)
Epoch: 1 | Batch_idx: 140 |  Loss: (1.7676) |  Loss2: (0.0000) | Acc: (35.00%) (6350/18048)
Epoch: 1 | Batch_idx: 150 |  Loss: (1.7643) |  Loss2: (0.0000) | Acc: (35.00%) (6834/19328)
Epoch: 1 | Batch_idx: 160 |  Loss: (1.7607) |  Loss2: (0.0000) | Acc: (35.00%) (7299/20608)
Epoch: 1 | Batch_idx: 170 |  Loss: (1.7581) |  Loss2: (0.0000) | Acc: (35.00%) (7773/21888)
Epoch: 1 | Batch_idx: 180 |  Loss: (1.7526) |  Loss2: (0.0000) | Acc: (35.00%) (8268/23168)
Epoch: 1 | Batch_idx: 190 |  Loss: (1.7500) |  Loss2: (0.0000) | Acc: (35.00%) (8723/24448)
Epoch: 1 | Batch_idx: 200 |  Loss: (1.7476) |  Loss2: (0.0000) | Acc: (35.00%) (9198/25728)
Epoch: 1 | Batch_idx: 210 |  Loss: (1.7455) |  Loss2: (0.0000) | Acc: (35.00%) (9698/27008)
Epoch: 1 | Batch_idx: 220 |  Loss: (1.7436) |  Loss2: (0.0000) | Acc: (36.00%) (10215/28288)
Epoch: 1 | Batch_idx: 230 |  Loss: (1.7417) |  Loss2: (0.0000) | Acc: (36.00%) (10686/29568)
Epoch: 1 | Batch_idx: 240 |  Loss: (1.7383) |  Loss2: (0.0000) | Acc: (36.00%) (11193/30848)
Epoch: 1 | Batch_idx: 250 |  Loss: (1.7345) |  Loss2: (0.0000) | Acc: (36.00%) (11687/32128)
Epoch: 1 | Batch_idx: 260 |  Loss: (1.7313) |  Loss2: (0.0000) | Acc: (36.00%) (12186/33408)
Epoch: 1 | Batch_idx: 270 |  Loss: (1.7280) |  Loss2: (0.0000) | Acc: (36.00%) (12693/34688)
Epoch: 1 | Batch_idx: 280 |  Loss: (1.7256) |  Loss2: (0.0000) | Acc: (36.00%) (13175/35968)
Epoch: 1 | Batch_idx: 290 |  Loss: (1.7228) |  Loss2: (0.0000) | Acc: (36.00%) (13700/37248)
Epoch: 1 | Batch_idx: 300 |  Loss: (1.7203) |  Loss2: (0.0000) | Acc: (36.00%) (14189/38528)
Epoch: 1 | Batch_idx: 310 |  Loss: (1.7175) |  Loss2: (0.0000) | Acc: (36.00%) (14719/39808)
Epoch: 1 | Batch_idx: 320 |  Loss: (1.7148) |  Loss2: (0.0000) | Acc: (37.00%) (15225/41088)
Epoch: 1 | Batch_idx: 330 |  Loss: (1.7130) |  Loss2: (0.0000) | Acc: (37.00%) (15730/42368)
Epoch: 1 | Batch_idx: 340 |  Loss: (1.7113) |  Loss2: (0.0000) | Acc: (37.00%) (16221/43648)
Epoch: 1 | Batch_idx: 350 |  Loss: (1.7079) |  Loss2: (0.0000) | Acc: (37.00%) (16755/44928)
Epoch: 1 | Batch_idx: 360 |  Loss: (1.7051) |  Loss2: (0.0000) | Acc: (37.00%) (17250/46208)
Epoch: 1 | Batch_idx: 370 |  Loss: (1.7022) |  Loss2: (0.0000) | Acc: (37.00%) (17783/47488)
Epoch: 1 | Batch_idx: 380 |  Loss: (1.6992) |  Loss2: (0.0000) | Acc: (37.00%) (18323/48768)
Epoch: 1 | Batch_idx: 390 |  Loss: (1.6962) |  Loss2: (0.0000) | Acc: (37.00%) (18827/50000)
# TEST : Loss: (1.6376) | Acc: (37.00%) (3748/10000)
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
Epoch: 2 | Batch_idx: 0 |  Loss: (1.6160) |  Loss2: (0.0000) | Acc: (37.00%) (48/128)
Epoch: 2 | Batch_idx: 10 |  Loss: (1.5952) |  Loss2: (0.0000) | Acc: (41.00%) (587/1408)
Epoch: 2 | Batch_idx: 20 |  Loss: (1.5881) |  Loss2: (0.0000) | Acc: (40.00%) (1092/2688)
Epoch: 2 | Batch_idx: 30 |  Loss: (1.5778) |  Loss2: (0.0000) | Acc: (41.00%) (1644/3968)
Epoch: 2 | Batch_idx: 40 |  Loss: (1.5781) |  Loss2: (0.0000) | Acc: (41.00%) (2152/5248)
Epoch: 2 | Batch_idx: 50 |  Loss: (1.5764) |  Loss2: (0.0000) | Acc: (41.00%) (2699/6528)
Epoch: 2 | Batch_idx: 60 |  Loss: (1.5793) |  Loss2: (0.0000) | Acc: (41.00%) (3205/7808)
Epoch: 2 | Batch_idx: 70 |  Loss: (1.5735) |  Loss2: (0.0000) | Acc: (41.00%) (3737/9088)
Epoch: 2 | Batch_idx: 80 |  Loss: (1.5743) |  Loss2: (0.0000) | Acc: (41.00%) (4258/10368)
Epoch: 2 | Batch_idx: 90 |  Loss: (1.5720) |  Loss2: (0.0000) | Acc: (41.00%) (4810/11648)
Epoch: 2 | Batch_idx: 100 |  Loss: (1.5682) |  Loss2: (0.0000) | Acc: (41.00%) (5382/12928)
Epoch: 2 | Batch_idx: 110 |  Loss: (1.5686) |  Loss2: (0.0000) | Acc: (41.00%) (5927/14208)
Epoch: 2 | Batch_idx: 120 |  Loss: (1.5674) |  Loss2: (0.0000) | Acc: (41.00%) (6454/15488)
Epoch: 2 | Batch_idx: 130 |  Loss: (1.5650) |  Loss2: (0.0000) | Acc: (41.00%) (6996/16768)
Epoch: 2 | Batch_idx: 140 |  Loss: (1.5627) |  Loss2: (0.0000) | Acc: (41.00%) (7569/18048)
Epoch: 2 | Batch_idx: 150 |  Loss: (1.5611) |  Loss2: (0.0000) | Acc: (42.00%) (8144/19328)
Epoch: 2 | Batch_idx: 160 |  Loss: (1.5598) |  Loss2: (0.0000) | Acc: (42.00%) (8674/20608)
Epoch: 2 | Batch_idx: 170 |  Loss: (1.5591) |  Loss2: (0.0000) | Acc: (42.00%) (9232/21888)
Epoch: 2 | Batch_idx: 180 |  Loss: (1.5579) |  Loss2: (0.0000) | Acc: (42.00%) (9784/23168)
Epoch: 2 | Batch_idx: 190 |  Loss: (1.5548) |  Loss2: (0.0000) | Acc: (42.00%) (10351/24448)
Epoch: 2 | Batch_idx: 200 |  Loss: (1.5532) |  Loss2: (0.0000) | Acc: (42.00%) (10906/25728)
Epoch: 2 | Batch_idx: 210 |  Loss: (1.5521) |  Loss2: (0.0000) | Acc: (42.00%) (11472/27008)
Epoch: 2 | Batch_idx: 220 |  Loss: (1.5502) |  Loss2: (0.0000) | Acc: (42.00%) (12033/28288)
Epoch: 2 | Batch_idx: 230 |  Loss: (1.5483) |  Loss2: (0.0000) | Acc: (42.00%) (12589/29568)
Epoch: 2 | Batch_idx: 240 |  Loss: (1.5470) |  Loss2: (0.0000) | Acc: (42.00%) (13154/30848)
Epoch: 2 | Batch_idx: 250 |  Loss: (1.5468) |  Loss2: (0.0000) | Acc: (42.00%) (13702/32128)
Epoch: 2 | Batch_idx: 260 |  Loss: (1.5458) |  Loss2: (0.0000) | Acc: (42.00%) (14270/33408)
Epoch: 2 | Batch_idx: 270 |  Loss: (1.5435) |  Loss2: (0.0000) | Acc: (42.00%) (14855/34688)
Epoch: 2 | Batch_idx: 280 |  Loss: (1.5424) |  Loss2: (0.0000) | Acc: (42.00%) (15427/35968)
Epoch: 2 | Batch_idx: 290 |  Loss: (1.5405) |  Loss2: (0.0000) | Acc: (42.00%) (15982/37248)
Epoch: 2 | Batch_idx: 300 |  Loss: (1.5382) |  Loss2: (0.0000) | Acc: (43.00%) (16580/38528)
Epoch: 2 | Batch_idx: 310 |  Loss: (1.5359) |  Loss2: (0.0000) | Acc: (43.00%) (17137/39808)
Epoch: 2 | Batch_idx: 320 |  Loss: (1.5341) |  Loss2: (0.0000) | Acc: (43.00%) (17704/41088)
Epoch: 2 | Batch_idx: 330 |  Loss: (1.5324) |  Loss2: (0.0000) | Acc: (43.00%) (18244/42368)
Epoch: 2 | Batch_idx: 340 |  Loss: (1.5306) |  Loss2: (0.0000) | Acc: (43.00%) (18828/43648)
Epoch: 2 | Batch_idx: 350 |  Loss: (1.5294) |  Loss2: (0.0000) | Acc: (43.00%) (19387/44928)
Epoch: 2 | Batch_idx: 360 |  Loss: (1.5284) |  Loss2: (0.0000) | Acc: (43.00%) (19965/46208)
Epoch: 2 | Batch_idx: 370 |  Loss: (1.5272) |  Loss2: (0.0000) | Acc: (43.00%) (20548/47488)
Epoch: 2 | Batch_idx: 380 |  Loss: (1.5255) |  Loss2: (0.0000) | Acc: (43.00%) (21120/48768)
Epoch: 2 | Batch_idx: 390 |  Loss: (1.5238) |  Loss2: (0.0000) | Acc: (43.00%) (21696/50000)
# TEST : Loss: (1.4931) | Acc: (43.00%) (4352/10000)
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
Epoch: 3 | Batch_idx: 0 |  Loss: (1.4480) |  Loss2: (0.0000) | Acc: (51.00%) (66/128)
Epoch: 3 | Batch_idx: 10 |  Loss: (1.4880) |  Loss2: (0.0000) | Acc: (46.00%) (661/1408)
Epoch: 3 | Batch_idx: 20 |  Loss: (1.4591) |  Loss2: (0.0000) | Acc: (47.00%) (1266/2688)
Epoch: 3 | Batch_idx: 30 |  Loss: (1.4667) |  Loss2: (0.0000) | Acc: (46.00%) (1854/3968)
Epoch: 3 | Batch_idx: 40 |  Loss: (1.4603) |  Loss2: (0.0000) | Acc: (46.00%) (2464/5248)
Epoch: 3 | Batch_idx: 50 |  Loss: (1.4577) |  Loss2: (0.0000) | Acc: (46.00%) (3045/6528)
Epoch: 3 | Batch_idx: 60 |  Loss: (1.4591) |  Loss2: (0.0000) | Acc: (46.00%) (3622/7808)
Epoch: 3 | Batch_idx: 70 |  Loss: (1.4557) |  Loss2: (0.0000) | Acc: (46.00%) (4214/9088)
Epoch: 3 | Batch_idx: 80 |  Loss: (1.4504) |  Loss2: (0.0000) | Acc: (46.00%) (4841/10368)
Epoch: 3 | Batch_idx: 90 |  Loss: (1.4459) |  Loss2: (0.0000) | Acc: (47.00%) (5485/11648)
Epoch: 3 | Batch_idx: 100 |  Loss: (1.4403) |  Loss2: (0.0000) | Acc: (47.00%) (6122/12928)
Epoch: 3 | Batch_idx: 110 |  Loss: (1.4368) |  Loss2: (0.0000) | Acc: (47.00%) (6748/14208)
Epoch: 3 | Batch_idx: 120 |  Loss: (1.4350) |  Loss2: (0.0000) | Acc: (47.00%) (7391/15488)
Epoch: 3 | Batch_idx: 130 |  Loss: (1.4357) |  Loss2: (0.0000) | Acc: (47.00%) (7994/16768)
Epoch: 3 | Batch_idx: 140 |  Loss: (1.4362) |  Loss2: (0.0000) | Acc: (47.00%) (8588/18048)
Epoch: 3 | Batch_idx: 150 |  Loss: (1.4351) |  Loss2: (0.0000) | Acc: (47.00%) (9218/19328)
Epoch: 3 | Batch_idx: 160 |  Loss: (1.4340) |  Loss2: (0.0000) | Acc: (47.00%) (9824/20608)
Epoch: 3 | Batch_idx: 170 |  Loss: (1.4316) |  Loss2: (0.0000) | Acc: (47.00%) (10447/21888)
Epoch: 3 | Batch_idx: 180 |  Loss: (1.4298) |  Loss2: (0.0000) | Acc: (47.00%) (11079/23168)
Epoch: 3 | Batch_idx: 190 |  Loss: (1.4275) |  Loss2: (0.0000) | Acc: (47.00%) (11693/24448)
Epoch: 3 | Batch_idx: 200 |  Loss: (1.4260) |  Loss2: (0.0000) | Acc: (47.00%) (12313/25728)
Epoch: 3 | Batch_idx: 210 |  Loss: (1.4255) |  Loss2: (0.0000) | Acc: (47.00%) (12935/27008)
Epoch: 3 | Batch_idx: 220 |  Loss: (1.4229) |  Loss2: (0.0000) | Acc: (47.00%) (13564/28288)
Epoch: 3 | Batch_idx: 230 |  Loss: (1.4197) |  Loss2: (0.0000) | Acc: (48.00%) (14209/29568)
Epoch: 3 | Batch_idx: 240 |  Loss: (1.4171) |  Loss2: (0.0000) | Acc: (48.00%) (14874/30848)
Epoch: 3 | Batch_idx: 250 |  Loss: (1.4152) |  Loss2: (0.0000) | Acc: (48.00%) (15516/32128)
Epoch: 3 | Batch_idx: 260 |  Loss: (1.4141) |  Loss2: (0.0000) | Acc: (48.00%) (16155/33408)
Epoch: 3 | Batch_idx: 270 |  Loss: (1.4128) |  Loss2: (0.0000) | Acc: (48.00%) (16820/34688)
Epoch: 3 | Batch_idx: 280 |  Loss: (1.4105) |  Loss2: (0.0000) | Acc: (48.00%) (17467/35968)
Epoch: 3 | Batch_idx: 290 |  Loss: (1.4065) |  Loss2: (0.0000) | Acc: (48.00%) (18142/37248)
Epoch: 3 | Batch_idx: 300 |  Loss: (1.4041) |  Loss2: (0.0000) | Acc: (48.00%) (18800/38528)
Epoch: 3 | Batch_idx: 310 |  Loss: (1.4012) |  Loss2: (0.0000) | Acc: (48.00%) (19479/39808)
Epoch: 3 | Batch_idx: 320 |  Loss: (1.4001) |  Loss2: (0.0000) | Acc: (49.00%) (20136/41088)
Epoch: 3 | Batch_idx: 330 |  Loss: (1.3988) |  Loss2: (0.0000) | Acc: (49.00%) (20787/42368)
Epoch: 3 | Batch_idx: 340 |  Loss: (1.3972) |  Loss2: (0.0000) | Acc: (49.00%) (21429/43648)
Epoch: 3 | Batch_idx: 350 |  Loss: (1.3960) |  Loss2: (0.0000) | Acc: (49.00%) (22093/44928)
Epoch: 3 | Batch_idx: 360 |  Loss: (1.3947) |  Loss2: (0.0000) | Acc: (49.00%) (22760/46208)
Epoch: 3 | Batch_idx: 370 |  Loss: (1.3929) |  Loss2: (0.0000) | Acc: (49.00%) (23449/47488)
Epoch: 3 | Batch_idx: 380 |  Loss: (1.3909) |  Loss2: (0.0000) | Acc: (49.00%) (24113/48768)
Epoch: 3 | Batch_idx: 390 |  Loss: (1.3894) |  Loss2: (0.0000) | Acc: (49.00%) (24744/50000)
# TEST : Loss: (1.3115) | Acc: (52.00%) (5220/10000)
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
Epoch: 4 | Batch_idx: 0 |  Loss: (1.3228) |  Loss2: (0.0000) | Acc: (55.00%) (71/128)
Epoch: 4 | Batch_idx: 10 |  Loss: (1.2887) |  Loss2: (0.0000) | Acc: (53.00%) (755/1408)
Epoch: 4 | Batch_idx: 20 |  Loss: (1.3015) |  Loss2: (0.0000) | Acc: (53.00%) (1451/2688)
Epoch: 4 | Batch_idx: 30 |  Loss: (1.2971) |  Loss2: (0.0000) | Acc: (53.00%) (2131/3968)
Epoch: 4 | Batch_idx: 40 |  Loss: (1.2994) |  Loss2: (0.0000) | Acc: (53.00%) (2811/5248)
Epoch: 4 | Batch_idx: 50 |  Loss: (1.3014) |  Loss2: (0.0000) | Acc: (53.00%) (3489/6528)
Epoch: 4 | Batch_idx: 60 |  Loss: (1.3069) |  Loss2: (0.0000) | Acc: (52.00%) (4136/7808)
Epoch: 4 | Batch_idx: 70 |  Loss: (1.3067) |  Loss2: (0.0000) | Acc: (52.00%) (4806/9088)
Epoch: 4 | Batch_idx: 80 |  Loss: (1.3094) |  Loss2: (0.0000) | Acc: (52.00%) (5486/10368)
Epoch: 4 | Batch_idx: 90 |  Loss: (1.3078) |  Loss2: (0.0000) | Acc: (52.00%) (6171/11648)
Epoch: 4 | Batch_idx: 100 |  Loss: (1.3106) |  Loss2: (0.0000) | Acc: (52.00%) (6821/12928)
Epoch: 4 | Batch_idx: 110 |  Loss: (1.3088) |  Loss2: (0.0000) | Acc: (52.00%) (7496/14208)
Epoch: 4 | Batch_idx: 120 |  Loss: (1.3059) |  Loss2: (0.0000) | Acc: (52.00%) (8192/15488)
Epoch: 4 | Batch_idx: 130 |  Loss: (1.3052) |  Loss2: (0.0000) | Acc: (52.00%) (8884/16768)
Epoch: 4 | Batch_idx: 140 |  Loss: (1.3046) |  Loss2: (0.0000) | Acc: (53.00%) (9571/18048)
Epoch: 4 | Batch_idx: 150 |  Loss: (1.3016) |  Loss2: (0.0000) | Acc: (53.00%) (10282/19328)
Epoch: 4 | Batch_idx: 160 |  Loss: (1.2998) |  Loss2: (0.0000) | Acc: (53.00%) (10987/20608)
Epoch: 4 | Batch_idx: 170 |  Loss: (1.2995) |  Loss2: (0.0000) | Acc: (53.00%) (11670/21888)
Epoch: 4 | Batch_idx: 180 |  Loss: (1.2956) |  Loss2: (0.0000) | Acc: (53.00%) (12387/23168)
Epoch: 4 | Batch_idx: 190 |  Loss: (1.2938) |  Loss2: (0.0000) | Acc: (53.00%) (13101/24448)
Epoch: 4 | Batch_idx: 200 |  Loss: (1.2937) |  Loss2: (0.0000) | Acc: (53.00%) (13800/25728)
Epoch: 4 | Batch_idx: 210 |  Loss: (1.2911) |  Loss2: (0.0000) | Acc: (53.00%) (14527/27008)
Epoch: 4 | Batch_idx: 220 |  Loss: (1.2886) |  Loss2: (0.0000) | Acc: (53.00%) (15222/28288)
Epoch: 4 | Batch_idx: 230 |  Loss: (1.2884) |  Loss2: (0.0000) | Acc: (53.00%) (15913/29568)
Epoch: 4 | Batch_idx: 240 |  Loss: (1.2867) |  Loss2: (0.0000) | Acc: (53.00%) (16603/30848)
Epoch: 4 | Batch_idx: 250 |  Loss: (1.2842) |  Loss2: (0.0000) | Acc: (53.00%) (17328/32128)
Epoch: 4 | Batch_idx: 260 |  Loss: (1.2821) |  Loss2: (0.0000) | Acc: (54.00%) (18062/33408)
Epoch: 4 | Batch_idx: 270 |  Loss: (1.2795) |  Loss2: (0.0000) | Acc: (54.00%) (18790/34688)
Epoch: 4 | Batch_idx: 280 |  Loss: (1.2762) |  Loss2: (0.0000) | Acc: (54.00%) (19545/35968)
Epoch: 4 | Batch_idx: 290 |  Loss: (1.2737) |  Loss2: (0.0000) | Acc: (54.00%) (20275/37248)
Epoch: 4 | Batch_idx: 300 |  Loss: (1.2716) |  Loss2: (0.0000) | Acc: (54.00%) (21025/38528)
Epoch: 4 | Batch_idx: 310 |  Loss: (1.2699) |  Loss2: (0.0000) | Acc: (54.00%) (21755/39808)
Epoch: 4 | Batch_idx: 320 |  Loss: (1.2688) |  Loss2: (0.0000) | Acc: (54.00%) (22452/41088)
Epoch: 4 | Batch_idx: 330 |  Loss: (1.2664) |  Loss2: (0.0000) | Acc: (54.00%) (23187/42368)
Epoch: 4 | Batch_idx: 340 |  Loss: (1.2651) |  Loss2: (0.0000) | Acc: (54.00%) (23906/43648)
Epoch: 4 | Batch_idx: 350 |  Loss: (1.2627) |  Loss2: (0.0000) | Acc: (54.00%) (24640/44928)
Epoch: 4 | Batch_idx: 360 |  Loss: (1.2607) |  Loss2: (0.0000) | Acc: (54.00%) (25385/46208)
Epoch: 4 | Batch_idx: 370 |  Loss: (1.2594) |  Loss2: (0.0000) | Acc: (55.00%) (26126/47488)
Epoch: 4 | Batch_idx: 380 |  Loss: (1.2574) |  Loss2: (0.0000) | Acc: (55.00%) (26857/48768)
Epoch: 4 | Batch_idx: 390 |  Loss: (1.2553) |  Loss2: (0.0000) | Acc: (55.00%) (27569/50000)
# TEST : Loss: (1.2599) | Acc: (54.00%) (5477/10000)
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
Epoch: 5 | Batch_idx: 0 |  Loss: (1.2675) |  Loss2: (0.0000) | Acc: (53.00%) (68/128)
Epoch: 5 | Batch_idx: 10 |  Loss: (1.1926) |  Loss2: (0.0000) | Acc: (57.00%) (816/1408)
Epoch: 5 | Batch_idx: 20 |  Loss: (1.1922) |  Loss2: (0.0000) | Acc: (58.00%) (1563/2688)
Epoch: 5 | Batch_idx: 30 |  Loss: (1.1861) |  Loss2: (0.0000) | Acc: (58.00%) (2324/3968)
Epoch: 5 | Batch_idx: 40 |  Loss: (1.1761) |  Loss2: (0.0000) | Acc: (58.00%) (3081/5248)
Epoch: 5 | Batch_idx: 50 |  Loss: (1.1760) |  Loss2: (0.0000) | Acc: (58.00%) (3810/6528)
Epoch: 5 | Batch_idx: 60 |  Loss: (1.1706) |  Loss2: (0.0000) | Acc: (58.00%) (4568/7808)
Epoch: 5 | Batch_idx: 70 |  Loss: (1.1629) |  Loss2: (0.0000) | Acc: (58.00%) (5348/9088)
Epoch: 5 | Batch_idx: 80 |  Loss: (1.1627) |  Loss2: (0.0000) | Acc: (59.00%) (6123/10368)
Epoch: 5 | Batch_idx: 90 |  Loss: (1.1636) |  Loss2: (0.0000) | Acc: (59.00%) (6887/11648)
Epoch: 5 | Batch_idx: 100 |  Loss: (1.1667) |  Loss2: (0.0000) | Acc: (58.00%) (7616/12928)
Epoch: 5 | Batch_idx: 110 |  Loss: (1.1640) |  Loss2: (0.0000) | Acc: (58.00%) (8382/14208)
Epoch: 5 | Batch_idx: 120 |  Loss: (1.1639) |  Loss2: (0.0000) | Acc: (58.00%) (9133/15488)
Epoch: 5 | Batch_idx: 130 |  Loss: (1.1673) |  Loss2: (0.0000) | Acc: (58.00%) (9853/16768)
Epoch: 5 | Batch_idx: 140 |  Loss: (1.1670) |  Loss2: (0.0000) | Acc: (58.00%) (10614/18048)
Epoch: 5 | Batch_idx: 150 |  Loss: (1.1662) |  Loss2: (0.0000) | Acc: (58.00%) (11366/19328)
Epoch: 5 | Batch_idx: 160 |  Loss: (1.1654) |  Loss2: (0.0000) | Acc: (58.00%) (12120/20608)
Epoch: 5 | Batch_idx: 170 |  Loss: (1.1629) |  Loss2: (0.0000) | Acc: (58.00%) (12909/21888)
Epoch: 5 | Batch_idx: 180 |  Loss: (1.1624) |  Loss2: (0.0000) | Acc: (59.00%) (13677/23168)
Epoch: 5 | Batch_idx: 190 |  Loss: (1.1618) |  Loss2: (0.0000) | Acc: (59.00%) (14427/24448)
Epoch: 5 | Batch_idx: 200 |  Loss: (1.1613) |  Loss2: (0.0000) | Acc: (58.00%) (15178/25728)
Epoch: 5 | Batch_idx: 210 |  Loss: (1.1620) |  Loss2: (0.0000) | Acc: (58.00%) (15901/27008)
Epoch: 5 | Batch_idx: 220 |  Loss: (1.1616) |  Loss2: (0.0000) | Acc: (58.00%) (16636/28288)
Epoch: 5 | Batch_idx: 230 |  Loss: (1.1608) |  Loss2: (0.0000) | Acc: (58.00%) (17385/29568)
Epoch: 5 | Batch_idx: 240 |  Loss: (1.1592) |  Loss2: (0.0000) | Acc: (58.00%) (18175/30848)
Epoch: 5 | Batch_idx: 250 |  Loss: (1.1591) |  Loss2: (0.0000) | Acc: (58.00%) (18915/32128)
Epoch: 5 | Batch_idx: 260 |  Loss: (1.1575) |  Loss2: (0.0000) | Acc: (58.00%) (19676/33408)
Epoch: 5 | Batch_idx: 270 |  Loss: (1.1570) |  Loss2: (0.0000) | Acc: (58.00%) (20442/34688)
Epoch: 5 | Batch_idx: 280 |  Loss: (1.1555) |  Loss2: (0.0000) | Acc: (58.00%) (21216/35968)
Epoch: 5 | Batch_idx: 290 |  Loss: (1.1543) |  Loss2: (0.0000) | Acc: (59.00%) (21993/37248)
Epoch: 5 | Batch_idx: 300 |  Loss: (1.1523) |  Loss2: (0.0000) | Acc: (59.00%) (22791/38528)
Epoch: 5 | Batch_idx: 310 |  Loss: (1.1508) |  Loss2: (0.0000) | Acc: (59.00%) (23570/39808)
Epoch: 5 | Batch_idx: 320 |  Loss: (1.1483) |  Loss2: (0.0000) | Acc: (59.00%) (24373/41088)
Epoch: 5 | Batch_idx: 330 |  Loss: (1.1463) |  Loss2: (0.0000) | Acc: (59.00%) (25177/42368)
Epoch: 5 | Batch_idx: 340 |  Loss: (1.1450) |  Loss2: (0.0000) | Acc: (59.00%) (25963/43648)
Epoch: 5 | Batch_idx: 350 |  Loss: (1.1449) |  Loss2: (0.0000) | Acc: (59.00%) (26722/44928)
Epoch: 5 | Batch_idx: 360 |  Loss: (1.1435) |  Loss2: (0.0000) | Acc: (59.00%) (27519/46208)
Epoch: 5 | Batch_idx: 370 |  Loss: (1.1426) |  Loss2: (0.0000) | Acc: (59.00%) (28296/47488)
Epoch: 5 | Batch_idx: 380 |  Loss: (1.1414) |  Loss2: (0.0000) | Acc: (59.00%) (29051/48768)
Epoch: 5 | Batch_idx: 390 |  Loss: (1.1401) |  Loss2: (0.0000) | Acc: (59.00%) (29811/50000)
=> saving checkpoint 'drive/app/torch/save_Schedule/checkpoint_005.pth.tar'
# TEST : Loss: (1.0938) | Acc: (61.00%) (6104/10000)
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
Epoch: 6 | Batch_idx: 0 |  Loss: (1.0262) |  Loss2: (0.0000) | Acc: (60.00%) (77/128)
Epoch: 6 | Batch_idx: 10 |  Loss: (1.0754) |  Loss2: (0.0000) | Acc: (62.00%) (881/1408)
Epoch: 6 | Batch_idx: 20 |  Loss: (1.0521) |  Loss2: (0.0000) | Acc: (63.00%) (1706/2688)
Epoch: 6 | Batch_idx: 30 |  Loss: (1.0629) |  Loss2: (0.0000) | Acc: (62.00%) (2495/3968)
Epoch: 6 | Batch_idx: 40 |  Loss: (1.0729) |  Loss2: (0.0000) | Acc: (62.00%) (3275/5248)
Epoch: 6 | Batch_idx: 50 |  Loss: (1.0732) |  Loss2: (0.0000) | Acc: (62.00%) (4069/6528)
Epoch: 6 | Batch_idx: 60 |  Loss: (1.0779) |  Loss2: (0.0000) | Acc: (62.00%) (4849/7808)
Epoch: 6 | Batch_idx: 70 |  Loss: (1.0793) |  Loss2: (0.0000) | Acc: (62.00%) (5650/9088)
Epoch: 6 | Batch_idx: 80 |  Loss: (1.0809) |  Loss2: (0.0000) | Acc: (62.00%) (6432/10368)
Epoch: 6 | Batch_idx: 90 |  Loss: (1.0748) |  Loss2: (0.0000) | Acc: (62.00%) (7235/11648)
Epoch: 6 | Batch_idx: 100 |  Loss: (1.0761) |  Loss2: (0.0000) | Acc: (61.00%) (8014/12928)
Epoch: 6 | Batch_idx: 110 |  Loss: (1.0771) |  Loss2: (0.0000) | Acc: (61.00%) (8805/14208)
Epoch: 6 | Batch_idx: 120 |  Loss: (1.0770) |  Loss2: (0.0000) | Acc: (61.00%) (9601/15488)
Epoch: 6 | Batch_idx: 130 |  Loss: (1.0753) |  Loss2: (0.0000) | Acc: (61.00%) (10396/16768)
Epoch: 6 | Batch_idx: 140 |  Loss: (1.0767) |  Loss2: (0.0000) | Acc: (61.00%) (11182/18048)
Epoch: 6 | Batch_idx: 150 |  Loss: (1.0753) |  Loss2: (0.0000) | Acc: (62.00%) (11985/19328)
Epoch: 6 | Batch_idx: 160 |  Loss: (1.0754) |  Loss2: (0.0000) | Acc: (62.00%) (12778/20608)
Epoch: 6 | Batch_idx: 170 |  Loss: (1.0737) |  Loss2: (0.0000) | Acc: (62.00%) (13590/21888)
Epoch: 6 | Batch_idx: 180 |  Loss: (1.0709) |  Loss2: (0.0000) | Acc: (62.00%) (14412/23168)
Epoch: 6 | Batch_idx: 190 |  Loss: (1.0734) |  Loss2: (0.0000) | Acc: (62.00%) (15184/24448)
Epoch: 6 | Batch_idx: 200 |  Loss: (1.0730) |  Loss2: (0.0000) | Acc: (62.00%) (16004/25728)
Epoch: 6 | Batch_idx: 210 |  Loss: (1.0720) |  Loss2: (0.0000) | Acc: (62.00%) (16800/27008)
Epoch: 6 | Batch_idx: 220 |  Loss: (1.0712) |  Loss2: (0.0000) | Acc: (62.00%) (17614/28288)
Epoch: 6 | Batch_idx: 230 |  Loss: (1.0707) |  Loss2: (0.0000) | Acc: (62.00%) (18430/29568)
Epoch: 6 | Batch_idx: 240 |  Loss: (1.0699) |  Loss2: (0.0000) | Acc: (62.00%) (19238/30848)
Epoch: 6 | Batch_idx: 250 |  Loss: (1.0691) |  Loss2: (0.0000) | Acc: (62.00%) (20032/32128)
Epoch: 6 | Batch_idx: 260 |  Loss: (1.0676) |  Loss2: (0.0000) | Acc: (62.00%) (20845/33408)
Epoch: 6 | Batch_idx: 270 |  Loss: (1.0667) |  Loss2: (0.0000) | Acc: (62.00%) (21645/34688)
Epoch: 6 | Batch_idx: 280 |  Loss: (1.0647) |  Loss2: (0.0000) | Acc: (62.00%) (22460/35968)
Epoch: 6 | Batch_idx: 290 |  Loss: (1.0637) |  Loss2: (0.0000) | Acc: (62.00%) (23250/37248)
Epoch: 6 | Batch_idx: 300 |  Loss: (1.0629) |  Loss2: (0.0000) | Acc: (62.00%) (24057/38528)
Epoch: 6 | Batch_idx: 310 |  Loss: (1.0616) |  Loss2: (0.0000) | Acc: (62.00%) (24892/39808)
Epoch: 6 | Batch_idx: 320 |  Loss: (1.0600) |  Loss2: (0.0000) | Acc: (62.00%) (25700/41088)
Epoch: 6 | Batch_idx: 330 |  Loss: (1.0589) |  Loss2: (0.0000) | Acc: (62.00%) (26503/42368)
Epoch: 6 | Batch_idx: 340 |  Loss: (1.0573) |  Loss2: (0.0000) | Acc: (62.00%) (27339/43648)
Epoch: 6 | Batch_idx: 350 |  Loss: (1.0560) |  Loss2: (0.0000) | Acc: (62.00%) (28173/44928)
Epoch: 6 | Batch_idx: 360 |  Loss: (1.0559) |  Loss2: (0.0000) | Acc: (62.00%) (28988/46208)
Epoch: 6 | Batch_idx: 370 |  Loss: (1.0562) |  Loss2: (0.0000) | Acc: (62.00%) (29795/47488)
Epoch: 6 | Batch_idx: 380 |  Loss: (1.0567) |  Loss2: (0.0000) | Acc: (62.00%) (30599/48768)
Epoch: 6 | Batch_idx: 390 |  Loss: (1.0569) |  Loss2: (0.0000) | Acc: (62.00%) (31369/50000)
# TEST : Loss: (1.1242) | Acc: (59.00%) (5955/10000)
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
False Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=128, out_features=16, bias=False)
True Linear(in_features=16, out_features=2, bias=False)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=128, out_features=16, bias=False)
True Linear(in_features=16, out_features=2, bias=False)
False Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=256, out_features=32, bias=False)
True Linear(in_features=32, out_features=2, bias=False)
False Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=256, out_features=32, bias=False)
True Linear(in_features=32, out_features=2, bias=False)
False Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=512, out_features=64, bias=False)
True Linear(in_features=64, out_features=2, bias=False)
False Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=512, out_features=64, bias=False)
True Linear(in_features=64, out_features=2, bias=False)
False Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1024, out_features=128, bias=False)
True Linear(in_features=128, out_features=2, bias=False)
False Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1024, out_features=128, bias=False)
True Linear(in_features=128, out_features=2, bias=False)
False Linear(in_features=512, out_features=10, bias=True)
Epoch: 7 | Batch_idx: 0 |  Loss: (1.0999) |  Loss2: (0.0000) | Acc: (56.00%) (72/128)
Epoch: 7 | Batch_idx: 10 |  Loss: (1.0325) |  Loss2: (0.0000) | Acc: (62.00%) (887/1408)
Epoch: 7 | Batch_idx: 20 |  Loss: (1.0648) |  Loss2: (0.0000) | Acc: (61.00%) (1654/2688)
Epoch: 7 | Batch_idx: 30 |  Loss: (1.0884) |  Loss2: (0.0000) | Acc: (60.00%) (2404/3968)
Epoch: 7 | Batch_idx: 40 |  Loss: (1.0970) |  Loss2: (0.0000) | Acc: (60.00%) (3163/5248)
Epoch: 7 | Batch_idx: 50 |  Loss: (1.1123) |  Loss2: (0.0000) | Acc: (59.00%) (3892/6528)
Epoch: 7 | Batch_idx: 60 |  Loss: (1.1203) |  Loss2: (0.0000) | Acc: (59.00%) (4622/7808)
Epoch: 7 | Batch_idx: 70 |  Loss: (1.1164) |  Loss2: (0.0000) | Acc: (59.00%) (5400/9088)
Epoch: 7 | Batch_idx: 80 |  Loss: (1.1114) |  Loss2: (0.0000) | Acc: (59.00%) (6192/10368)
Epoch: 7 | Batch_idx: 90 |  Loss: (1.1096) |  Loss2: (0.0000) | Acc: (59.00%) (6969/11648)
Epoch: 7 | Batch_idx: 100 |  Loss: (1.1124) |  Loss2: (0.0000) | Acc: (59.00%) (7702/12928)
Epoch: 7 | Batch_idx: 110 |  Loss: (1.1150) |  Loss2: (0.0000) | Acc: (59.00%) (8449/14208)
Epoch: 7 | Batch_idx: 120 |  Loss: (1.1170) |  Loss2: (0.0000) | Acc: (59.00%) (9200/15488)
Epoch: 7 | Batch_idx: 130 |  Loss: (1.1171) |  Loss2: (0.0000) | Acc: (59.00%) (9976/16768)
Epoch: 7 | Batch_idx: 140 |  Loss: (1.1159) |  Loss2: (0.0000) | Acc: (59.00%) (10769/18048)
Epoch: 7 | Batch_idx: 150 |  Loss: (1.1178) |  Loss2: (0.0000) | Acc: (59.00%) (11548/19328)
Epoch: 7 | Batch_idx: 160 |  Loss: (1.1176) |  Loss2: (0.0000) | Acc: (59.00%) (12326/20608)
Epoch: 7 | Batch_idx: 170 |  Loss: (1.1162) |  Loss2: (0.0000) | Acc: (59.00%) (13117/21888)
Epoch: 7 | Batch_idx: 180 |  Loss: (1.1131) |  Loss2: (0.0000) | Acc: (60.00%) (13901/23168)
Epoch: 7 | Batch_idx: 190 |  Loss: (1.1127) |  Loss2: (0.0000) | Acc: (59.00%) (14665/24448)
Epoch: 7 | Batch_idx: 200 |  Loss: (1.1118) |  Loss2: (0.0000) | Acc: (60.00%) (15445/25728)
Epoch: 7 | Batch_idx: 210 |  Loss: (1.1099) |  Loss2: (0.0000) | Acc: (60.00%) (16239/27008)
Epoch: 7 | Batch_idx: 220 |  Loss: (1.1076) |  Loss2: (0.0000) | Acc: (60.00%) (17009/28288)
Epoch: 7 | Batch_idx: 230 |  Loss: (1.1067) |  Loss2: (0.0000) | Acc: (60.00%) (17779/29568)
Epoch: 7 | Batch_idx: 240 |  Loss: (1.1038) |  Loss2: (0.0000) | Acc: (60.00%) (18580/30848)
Epoch: 7 | Batch_idx: 250 |  Loss: (1.1023) |  Loss2: (0.0000) | Acc: (60.00%) (19356/32128)
Epoch: 7 | Batch_idx: 260 |  Loss: (1.1011) |  Loss2: (0.0000) | Acc: (60.00%) (20149/33408)
Epoch: 7 | Batch_idx: 270 |  Loss: (1.0999) |  Loss2: (0.0000) | Acc: (60.00%) (20925/34688)
Epoch: 7 | Batch_idx: 280 |  Loss: (1.0978) |  Loss2: (0.0000) | Acc: (60.00%) (21746/35968)
Epoch: 7 | Batch_idx: 290 |  Loss: (1.0976) |  Loss2: (0.0000) | Acc: (60.00%) (22520/37248)
Epoch: 7 | Batch_idx: 300 |  Loss: (1.0981) |  Loss2: (0.0000) | Acc: (60.00%) (23299/38528)
Epoch: 7 | Batch_idx: 310 |  Loss: (1.0976) |  Loss2: (0.0000) | Acc: (60.00%) (24080/39808)
Epoch: 7 | Batch_idx: 320 |  Loss: (1.0957) |  Loss2: (0.0000) | Acc: (60.00%) (24874/41088)
Epoch: 7 | Batch_idx: 330 |  Loss: (1.0932) |  Loss2: (0.0000) | Acc: (60.00%) (25690/42368)
Epoch: 7 | Batch_idx: 340 |  Loss: (1.0912) |  Loss2: (0.0000) | Acc: (60.00%) (26505/43648)
Epoch: 7 | Batch_idx: 350 |  Loss: (1.0902) |  Loss2: (0.0000) | Acc: (60.00%) (27280/44928)
Epoch: 7 | Batch_idx: 360 |  Loss: (1.0884) |  Loss2: (0.0000) | Acc: (60.00%) (28096/46208)
Epoch: 7 | Batch_idx: 370 |  Loss: (1.0869) |  Loss2: (0.0000) | Acc: (60.00%) (28905/47488)
Epoch: 7 | Batch_idx: 380 |  Loss: (1.0873) |  Loss2: (0.0000) | Acc: (60.00%) (29669/48768)
Epoch: 7 | Batch_idx: 390 |  Loss: (1.0875) |  Loss2: (0.0000) | Acc: (60.00%) (30409/50000)
# TEST : Loss: (1.0381) | Acc: (62.00%) (6240/10000)
percent tensor([0.5018, 0.5043, 0.5014, 0.5017, 0.5020, 0.5025, 0.5036, 0.5023, 0.5028,
        0.5024, 0.5031, 0.5017, 0.5021, 0.5057, 0.5028, 0.5025],
       device='cuda:0') torch.Size([16])
percent tensor([0.5043, 0.5058, 0.5045, 0.5041, 0.5050, 0.5056, 0.5057, 0.5052, 0.5043,
        0.5052, 0.5046, 0.5050, 0.5041, 0.5048, 0.5058, 0.5052],
       device='cuda:0') torch.Size([16])
percent tensor([0.5040, 0.5032, 0.5016, 0.5026, 0.5008, 0.5037, 0.5021, 0.5023, 0.5023,
        0.5028, 0.5037, 0.5014, 0.5035, 0.5043, 0.5032, 0.5044],
       device='cuda:0') torch.Size([16])
percent tensor([0.4999, 0.4993, 0.4987, 0.4991, 0.4986, 0.5007, 0.4987, 0.4987, 0.4988,
        0.4988, 0.4993, 0.4986, 0.4996, 0.4987, 0.5003, 0.4998],
       device='cuda:0') torch.Size([16])
percent tensor([0.4869, 0.4942, 0.4639, 0.4676, 0.4688, 0.4830, 0.4858, 0.4677, 0.4869,
        0.4852, 0.4934, 0.4729, 0.4910, 0.4913, 0.4890, 0.4855],
       device='cuda:0') torch.Size([16])
percent tensor([0.4973, 0.4959, 0.4899, 0.4933, 0.4889, 0.4980, 0.4930, 0.4871, 0.4959,
        0.4944, 0.4968, 0.4927, 0.4978, 0.4972, 0.4932, 0.4943],
       device='cuda:0') torch.Size([16])
percent tensor([0.5059, 0.5052, 0.5136, 0.5135, 0.5143, 0.5069, 0.5099, 0.5186, 0.5072,
        0.5106, 0.5056, 0.5113, 0.5063, 0.5055, 0.5075, 0.5125],
       device='cuda:0') torch.Size([16])
percent tensor([0.5540, 0.5495, 0.5619, 0.5538, 0.5534, 0.5710, 0.5519, 0.5802, 0.5570,
        0.5671, 0.5600, 0.5560, 0.5651, 0.5624, 0.5660, 0.5973],
       device='cuda:0') torch.Size([16])
Epoch: 8 | Batch_idx: 0 |  Loss: (1.1187) |  Loss2: (0.0000) | Acc: (59.00%) (76/128)
Epoch: 8 | Batch_idx: 10 |  Loss: (1.0880) |  Loss2: (0.0000) | Acc: (60.00%) (850/1408)
Epoch: 8 | Batch_idx: 20 |  Loss: (1.0537) |  Loss2: (0.0000) | Acc: (62.00%) (1670/2688)
Epoch: 8 | Batch_idx: 30 |  Loss: (1.0391) |  Loss2: (0.0000) | Acc: (62.00%) (2480/3968)
Epoch: 8 | Batch_idx: 40 |  Loss: (1.0302) |  Loss2: (0.0000) | Acc: (63.00%) (3309/5248)
Epoch: 8 | Batch_idx: 50 |  Loss: (1.0278) |  Loss2: (0.0000) | Acc: (62.00%) (4101/6528)
Epoch: 8 | Batch_idx: 60 |  Loss: (1.0272) |  Loss2: (0.0000) | Acc: (62.00%) (4895/7808)
Epoch: 8 | Batch_idx: 70 |  Loss: (1.0316) |  Loss2: (0.0000) | Acc: (62.00%) (5655/9088)
Epoch: 8 | Batch_idx: 80 |  Loss: (1.0249) |  Loss2: (0.0000) | Acc: (62.00%) (6491/10368)
Epoch: 8 | Batch_idx: 90 |  Loss: (1.0214) |  Loss2: (0.0000) | Acc: (62.00%) (7308/11648)
Epoch: 8 | Batch_idx: 100 |  Loss: (1.0233) |  Loss2: (0.0000) | Acc: (62.00%) (8120/12928)
Epoch: 8 | Batch_idx: 110 |  Loss: (1.0259) |  Loss2: (0.0000) | Acc: (62.00%) (8917/14208)
Epoch: 8 | Batch_idx: 120 |  Loss: (1.0301) |  Loss2: (0.0000) | Acc: (62.00%) (9709/15488)
Epoch: 8 | Batch_idx: 130 |  Loss: (1.0290) |  Loss2: (0.0000) | Acc: (62.00%) (10512/16768)
Epoch: 8 | Batch_idx: 140 |  Loss: (1.0309) |  Loss2: (0.0000) | Acc: (62.00%) (11316/18048)
Epoch: 8 | Batch_idx: 150 |  Loss: (1.0320) |  Loss2: (0.0000) | Acc: (62.00%) (12115/19328)
Epoch: 8 | Batch_idx: 160 |  Loss: (1.0323) |  Loss2: (0.0000) | Acc: (62.00%) (12919/20608)
Epoch: 8 | Batch_idx: 170 |  Loss: (1.0304) |  Loss2: (0.0000) | Acc: (62.00%) (13732/21888)
Epoch: 8 | Batch_idx: 180 |  Loss: (1.0299) |  Loss2: (0.0000) | Acc: (62.00%) (14553/23168)
Epoch: 8 | Batch_idx: 190 |  Loss: (1.0293) |  Loss2: (0.0000) | Acc: (62.00%) (15357/24448)
Epoch: 8 | Batch_idx: 200 |  Loss: (1.0306) |  Loss2: (0.0000) | Acc: (62.00%) (16149/25728)
Epoch: 8 | Batch_idx: 210 |  Loss: (1.0287) |  Loss2: (0.0000) | Acc: (62.00%) (16982/27008)
Epoch: 8 | Batch_idx: 220 |  Loss: (1.0299) |  Loss2: (0.0000) | Acc: (62.00%) (17765/28288)
Epoch: 8 | Batch_idx: 230 |  Loss: (1.0307) |  Loss2: (0.0000) | Acc: (62.00%) (18558/29568)
Epoch: 8 | Batch_idx: 240 |  Loss: (1.0303) |  Loss2: (0.0000) | Acc: (62.00%) (19359/30848)
Epoch: 8 | Batch_idx: 250 |  Loss: (1.0297) |  Loss2: (0.0000) | Acc: (62.00%) (20187/32128)
Epoch: 8 | Batch_idx: 260 |  Loss: (1.0290) |  Loss2: (0.0000) | Acc: (62.00%) (21002/33408)
Epoch: 8 | Batch_idx: 270 |  Loss: (1.0290) |  Loss2: (0.0000) | Acc: (62.00%) (21818/34688)
Epoch: 8 | Batch_idx: 280 |  Loss: (1.0295) |  Loss2: (0.0000) | Acc: (62.00%) (22626/35968)
Epoch: 8 | Batch_idx: 290 |  Loss: (1.0288) |  Loss2: (0.0000) | Acc: (62.00%) (23458/37248)
Epoch: 8 | Batch_idx: 300 |  Loss: (1.0282) |  Loss2: (0.0000) | Acc: (62.00%) (24263/38528)
Epoch: 8 | Batch_idx: 310 |  Loss: (1.0264) |  Loss2: (0.0000) | Acc: (63.00%) (25089/39808)
Epoch: 8 | Batch_idx: 320 |  Loss: (1.0263) |  Loss2: (0.0000) | Acc: (63.00%) (25918/41088)
Epoch: 8 | Batch_idx: 330 |  Loss: (1.0259) |  Loss2: (0.0000) | Acc: (63.00%) (26733/42368)
Epoch: 8 | Batch_idx: 340 |  Loss: (1.0261) |  Loss2: (0.0000) | Acc: (63.00%) (27566/43648)
Epoch: 8 | Batch_idx: 350 |  Loss: (1.0246) |  Loss2: (0.0000) | Acc: (63.00%) (28388/44928)
Epoch: 8 | Batch_idx: 360 |  Loss: (1.0238) |  Loss2: (0.0000) | Acc: (63.00%) (29221/46208)
Epoch: 8 | Batch_idx: 370 |  Loss: (1.0240) |  Loss2: (0.0000) | Acc: (63.00%) (30024/47488)
Epoch: 8 | Batch_idx: 380 |  Loss: (1.0227) |  Loss2: (0.0000) | Acc: (63.00%) (30838/48768)
Epoch: 8 | Batch_idx: 390 |  Loss: (1.0234) |  Loss2: (0.0000) | Acc: (63.00%) (31612/50000)
# TEST : Loss: (1.0148) | Acc: (63.00%) (6358/10000)
percent tensor([0.5033, 0.5068, 0.5022, 0.5030, 0.5032, 0.5049, 0.5057, 0.5039, 0.5047,
        0.5039, 0.5051, 0.5026, 0.5036, 0.5088, 0.5049, 0.5042],
       device='cuda:0') torch.Size([16])
percent tensor([0.5075, 0.5095, 0.5069, 0.5066, 0.5078, 0.5098, 0.5093, 0.5085, 0.5072,
        0.5083, 0.5078, 0.5081, 0.5069, 0.5081, 0.5098, 0.5088],
       device='cuda:0') torch.Size([16])
percent tensor([0.5070, 0.5058, 0.5038, 0.5049, 0.5025, 0.5062, 0.5045, 0.5048, 0.5048,
        0.5055, 0.5069, 0.5034, 0.5064, 0.5080, 0.5057, 0.5079],
       device='cuda:0') torch.Size([16])
percent tensor([0.5035, 0.5020, 0.5021, 0.5028, 0.5020, 0.5054, 0.5014, 0.5021, 0.5017,
        0.5016, 0.5020, 0.5017, 0.5024, 0.5015, 0.5041, 0.5032],
       device='cuda:0') torch.Size([16])
percent tensor([0.4813, 0.4924, 0.4443, 0.4482, 0.4519, 0.4753, 0.4806, 0.4511, 0.4816,
        0.4789, 0.4909, 0.4589, 0.4871, 0.4893, 0.4855, 0.4785],
       device='cuda:0') torch.Size([16])
percent tensor([0.4980, 0.4966, 0.4927, 0.4960, 0.4912, 0.4984, 0.4942, 0.4887, 0.4978,
        0.4952, 0.4977, 0.4953, 0.4988, 0.4986, 0.4926, 0.4943],
       device='cuda:0') torch.Size([16])
percent tensor([0.5101, 0.5102, 0.5302, 0.5295, 0.5311, 0.5102, 0.5200, 0.5406, 0.5137,
        0.5205, 0.5099, 0.5228, 0.5099, 0.5108, 0.5149, 0.5226],
       device='cuda:0') torch.Size([16])
percent tensor([0.6388, 0.6316, 0.6862, 0.6621, 0.6568, 0.6669, 0.6462, 0.7346, 0.6453,
        0.6750, 0.6456, 0.6492, 0.6536, 0.6583, 0.6839, 0.7322],
       device='cuda:0') torch.Size([16])
Epoch: 9 | Batch_idx: 0 |  Loss: (1.0275) |  Loss2: (0.0000) | Acc: (58.00%) (75/128)
Epoch: 9 | Batch_idx: 10 |  Loss: (1.0132) |  Loss2: (0.0000) | Acc: (62.00%) (880/1408)
Epoch: 9 | Batch_idx: 20 |  Loss: (1.0418) |  Loss2: (0.0000) | Acc: (61.00%) (1664/2688)
Epoch: 9 | Batch_idx: 30 |  Loss: (1.0292) |  Loss2: (0.0000) | Acc: (62.00%) (2490/3968)
Epoch: 9 | Batch_idx: 40 |  Loss: (1.0140) |  Loss2: (0.0000) | Acc: (63.00%) (3337/5248)
Epoch: 9 | Batch_idx: 50 |  Loss: (1.0154) |  Loss2: (0.0000) | Acc: (63.00%) (4136/6528)
Epoch: 9 | Batch_idx: 60 |  Loss: (1.0184) |  Loss2: (0.0000) | Acc: (63.00%) (4934/7808)
Epoch: 9 | Batch_idx: 70 |  Loss: (1.0176) |  Loss2: (0.0000) | Acc: (63.00%) (5747/9088)
Epoch: 9 | Batch_idx: 80 |  Loss: (1.0175) |  Loss2: (0.0000) | Acc: (63.00%) (6560/10368)
Epoch: 9 | Batch_idx: 90 |  Loss: (1.0130) |  Loss2: (0.0000) | Acc: (63.00%) (7387/11648)
Epoch: 9 | Batch_idx: 100 |  Loss: (1.0164) |  Loss2: (0.0000) | Acc: (63.00%) (8191/12928)
Epoch: 9 | Batch_idx: 110 |  Loss: (1.0183) |  Loss2: (0.0000) | Acc: (63.00%) (8993/14208)
Epoch: 9 | Batch_idx: 120 |  Loss: (1.0168) |  Loss2: (0.0000) | Acc: (63.00%) (9820/15488)
Epoch: 9 | Batch_idx: 130 |  Loss: (1.0160) |  Loss2: (0.0000) | Acc: (63.00%) (10636/16768)
Epoch: 9 | Batch_idx: 140 |  Loss: (1.0136) |  Loss2: (0.0000) | Acc: (63.00%) (11481/18048)
Epoch: 9 | Batch_idx: 150 |  Loss: (1.0139) |  Loss2: (0.0000) | Acc: (63.00%) (12280/19328)
Epoch: 9 | Batch_idx: 160 |  Loss: (1.0137) |  Loss2: (0.0000) | Acc: (63.00%) (13113/20608)
Epoch: 9 | Batch_idx: 170 |  Loss: (1.0167) |  Loss2: (0.0000) | Acc: (63.00%) (13882/21888)
Epoch: 9 | Batch_idx: 180 |  Loss: (1.0143) |  Loss2: (0.0000) | Acc: (63.00%) (14703/23168)
Epoch: 9 | Batch_idx: 190 |  Loss: (1.0123) |  Loss2: (0.0000) | Acc: (63.00%) (15520/24448)
Epoch: 9 | Batch_idx: 200 |  Loss: (1.0110) |  Loss2: (0.0000) | Acc: (63.00%) (16343/25728)
Epoch: 9 | Batch_idx: 210 |  Loss: (1.0125) |  Loss2: (0.0000) | Acc: (63.00%) (17143/27008)
Epoch: 9 | Batch_idx: 220 |  Loss: (1.0114) |  Loss2: (0.0000) | Acc: (63.00%) (17978/28288)
Epoch: 9 | Batch_idx: 230 |  Loss: (1.0103) |  Loss2: (0.0000) | Acc: (63.00%) (18802/29568)
Epoch: 9 | Batch_idx: 240 |  Loss: (1.0061) |  Loss2: (0.0000) | Acc: (63.00%) (19669/30848)
Epoch: 9 | Batch_idx: 250 |  Loss: (1.0065) |  Loss2: (0.0000) | Acc: (63.00%) (20484/32128)
Epoch: 9 | Batch_idx: 260 |  Loss: (1.0061) |  Loss2: (0.0000) | Acc: (63.00%) (21309/33408)
Epoch: 9 | Batch_idx: 270 |  Loss: (1.0049) |  Loss2: (0.0000) | Acc: (63.00%) (22150/34688)
Epoch: 9 | Batch_idx: 280 |  Loss: (1.0043) |  Loss2: (0.0000) | Acc: (63.00%) (22965/35968)
Epoch: 9 | Batch_idx: 290 |  Loss: (1.0045) |  Loss2: (0.0000) | Acc: (63.00%) (23781/37248)
Epoch: 9 | Batch_idx: 300 |  Loss: (1.0036) |  Loss2: (0.0000) | Acc: (63.00%) (24626/38528)
Epoch: 9 | Batch_idx: 310 |  Loss: (1.0045) |  Loss2: (0.0000) | Acc: (63.00%) (25423/39808)
Epoch: 9 | Batch_idx: 320 |  Loss: (1.0050) |  Loss2: (0.0000) | Acc: (63.00%) (26230/41088)
Epoch: 9 | Batch_idx: 330 |  Loss: (1.0046) |  Loss2: (0.0000) | Acc: (63.00%) (27046/42368)
Epoch: 9 | Batch_idx: 340 |  Loss: (1.0047) |  Loss2: (0.0000) | Acc: (63.00%) (27853/43648)
Epoch: 9 | Batch_idx: 350 |  Loss: (1.0027) |  Loss2: (0.0000) | Acc: (63.00%) (28702/44928)
Epoch: 9 | Batch_idx: 360 |  Loss: (1.0028) |  Loss2: (0.0000) | Acc: (63.00%) (29524/46208)
Epoch: 9 | Batch_idx: 370 |  Loss: (1.0014) |  Loss2: (0.0000) | Acc: (63.00%) (30372/47488)
Epoch: 9 | Batch_idx: 380 |  Loss: (1.0012) |  Loss2: (0.0000) | Acc: (63.00%) (31179/48768)
Epoch: 9 | Batch_idx: 390 |  Loss: (1.0013) |  Loss2: (0.0000) | Acc: (63.00%) (31946/50000)
# TEST : Loss: (1.0023) | Acc: (64.00%) (6424/10000)
percent tensor([0.5056, 0.5105, 0.5040, 0.5053, 0.5053, 0.5083, 0.5088, 0.5062, 0.5074,
        0.5064, 0.5081, 0.5045, 0.5060, 0.5128, 0.5082, 0.5069],
       device='cuda:0') torch.Size([16])
percent tensor([0.5097, 0.5121, 0.5080, 0.5082, 0.5094, 0.5131, 0.5117, 0.5106, 0.5089,
        0.5102, 0.5099, 0.5098, 0.5088, 0.5105, 0.5129, 0.5113],
       device='cuda:0') torch.Size([16])
percent tensor([0.5098, 0.5084, 0.5070, 0.5078, 0.5053, 0.5080, 0.5072, 0.5081, 0.5076,
        0.5085, 0.5097, 0.5062, 0.5090, 0.5118, 0.5078, 0.5111],
       device='cuda:0') torch.Size([16])
percent tensor([0.5082, 0.5059, 0.5066, 0.5074, 0.5065, 0.5112, 0.5056, 0.5064, 0.5056,
        0.5056, 0.5059, 0.5060, 0.5062, 0.5053, 0.5091, 0.5077],
       device='cuda:0') torch.Size([16])
percent tensor([0.4806, 0.4923, 0.4404, 0.4444, 0.4494, 0.4736, 0.4807, 0.4481, 0.4810,
        0.4757, 0.4898, 0.4562, 0.4854, 0.4900, 0.4865, 0.4759],
       device='cuda:0') torch.Size([16])
percent tensor([0.4985, 0.4971, 0.4953, 0.4984, 0.4931, 0.4986, 0.4954, 0.4906, 0.4993,
        0.4957, 0.4983, 0.4975, 0.4991, 0.4996, 0.4921, 0.4939],
       device='cuda:0') torch.Size([16])
percent tensor([0.5095, 0.5114, 0.5389, 0.5372, 0.5401, 0.5069, 0.5243, 0.5520, 0.5157,
        0.5235, 0.5097, 0.5279, 0.5079, 0.5121, 0.5180, 0.5246],
       device='cuda:0') torch.Size([16])
percent tensor([0.6866, 0.6819, 0.7631, 0.7279, 0.7255, 0.7101, 0.7030, 0.8208, 0.6970,
        0.7376, 0.6909, 0.7095, 0.6959, 0.7137, 0.7530, 0.7937],
       device='cuda:0') torch.Size([16])
Epoch: 10 | Batch_idx: 0 |  Loss: (1.0554) |  Loss2: (0.0000) | Acc: (60.00%) (77/128)
Epoch: 10 | Batch_idx: 10 |  Loss: (1.0113) |  Loss2: (0.0000) | Acc: (62.00%) (877/1408)
Epoch: 10 | Batch_idx: 20 |  Loss: (1.0121) |  Loss2: (0.0000) | Acc: (64.00%) (1722/2688)
Epoch: 10 | Batch_idx: 30 |  Loss: (1.0205) |  Loss2: (0.0000) | Acc: (63.00%) (2515/3968)
Epoch: 10 | Batch_idx: 40 |  Loss: (1.0226) |  Loss2: (0.0000) | Acc: (63.00%) (3326/5248)
Epoch: 10 | Batch_idx: 50 |  Loss: (1.0090) |  Loss2: (0.0000) | Acc: (63.00%) (4164/6528)
Epoch: 10 | Batch_idx: 60 |  Loss: (1.0080) |  Loss2: (0.0000) | Acc: (63.00%) (4974/7808)
Epoch: 10 | Batch_idx: 70 |  Loss: (1.0052) |  Loss2: (0.0000) | Acc: (63.00%) (5798/9088)
Epoch: 10 | Batch_idx: 80 |  Loss: (1.0022) |  Loss2: (0.0000) | Acc: (63.00%) (6629/10368)
Epoch: 10 | Batch_idx: 90 |  Loss: (0.9963) |  Loss2: (0.0000) | Acc: (64.00%) (7465/11648)
Epoch: 10 | Batch_idx: 100 |  Loss: (0.9990) |  Loss2: (0.0000) | Acc: (64.00%) (8286/12928)
Epoch: 10 | Batch_idx: 110 |  Loss: (0.9982) |  Loss2: (0.0000) | Acc: (64.00%) (9110/14208)
Epoch: 10 | Batch_idx: 120 |  Loss: (0.9952) |  Loss2: (0.0000) | Acc: (64.00%) (9957/15488)
Epoch: 10 | Batch_idx: 130 |  Loss: (0.9966) |  Loss2: (0.0000) | Acc: (64.00%) (10784/16768)
Epoch: 10 | Batch_idx: 140 |  Loss: (0.9980) |  Loss2: (0.0000) | Acc: (64.00%) (11599/18048)
Epoch: 10 | Batch_idx: 150 |  Loss: (1.0014) |  Loss2: (0.0000) | Acc: (64.00%) (12409/19328)
Epoch: 10 | Batch_idx: 160 |  Loss: (0.9997) |  Loss2: (0.0000) | Acc: (64.00%) (13221/20608)
Epoch: 10 | Batch_idx: 170 |  Loss: (0.9984) |  Loss2: (0.0000) | Acc: (64.00%) (14028/21888)
Epoch: 10 | Batch_idx: 180 |  Loss: (0.9968) |  Loss2: (0.0000) | Acc: (64.00%) (14864/23168)
Epoch: 10 | Batch_idx: 190 |  Loss: (0.9949) |  Loss2: (0.0000) | Acc: (64.00%) (15696/24448)
Epoch: 10 | Batch_idx: 200 |  Loss: (0.9973) |  Loss2: (0.0000) | Acc: (64.00%) (16503/25728)
Epoch: 10 | Batch_idx: 210 |  Loss: (0.9924) |  Loss2: (0.0000) | Acc: (64.00%) (17383/27008)
Epoch: 10 | Batch_idx: 220 |  Loss: (0.9924) |  Loss2: (0.0000) | Acc: (64.00%) (18194/28288)
Epoch: 10 | Batch_idx: 230 |  Loss: (0.9909) |  Loss2: (0.0000) | Acc: (64.00%) (19032/29568)
Epoch: 10 | Batch_idx: 240 |  Loss: (0.9916) |  Loss2: (0.0000) | Acc: (64.00%) (19859/30848)
Epoch: 10 | Batch_idx: 250 |  Loss: (0.9922) |  Loss2: (0.0000) | Acc: (64.00%) (20683/32128)
Epoch: 10 | Batch_idx: 260 |  Loss: (0.9929) |  Loss2: (0.0000) | Acc: (64.00%) (21508/33408)
Epoch: 10 | Batch_idx: 270 |  Loss: (0.9916) |  Loss2: (0.0000) | Acc: (64.00%) (22354/34688)
Epoch: 10 | Batch_idx: 280 |  Loss: (0.9914) |  Loss2: (0.0000) | Acc: (64.00%) (23201/35968)
Epoch: 10 | Batch_idx: 290 |  Loss: (0.9917) |  Loss2: (0.0000) | Acc: (64.00%) (24013/37248)
Epoch: 10 | Batch_idx: 300 |  Loss: (0.9911) |  Loss2: (0.0000) | Acc: (64.00%) (24833/38528)
Epoch: 10 | Batch_idx: 310 |  Loss: (0.9910) |  Loss2: (0.0000) | Acc: (64.00%) (25669/39808)
Epoch: 10 | Batch_idx: 320 |  Loss: (0.9922) |  Loss2: (0.0000) | Acc: (64.00%) (26477/41088)
Epoch: 10 | Batch_idx: 330 |  Loss: (0.9922) |  Loss2: (0.0000) | Acc: (64.00%) (27317/42368)
Epoch: 10 | Batch_idx: 340 |  Loss: (0.9928) |  Loss2: (0.0000) | Acc: (64.00%) (28125/43648)
Epoch: 10 | Batch_idx: 350 |  Loss: (0.9931) |  Loss2: (0.0000) | Acc: (64.00%) (28925/44928)
Epoch: 10 | Batch_idx: 360 |  Loss: (0.9929) |  Loss2: (0.0000) | Acc: (64.00%) (29756/46208)
Epoch: 10 | Batch_idx: 370 |  Loss: (0.9928) |  Loss2: (0.0000) | Acc: (64.00%) (30576/47488)
Epoch: 10 | Batch_idx: 380 |  Loss: (0.9919) |  Loss2: (0.0000) | Acc: (64.00%) (31415/48768)
Epoch: 10 | Batch_idx: 390 |  Loss: (0.9903) |  Loss2: (0.0000) | Acc: (64.00%) (32244/50000)
=> saving checkpoint 'drive/app/torch/save_Schedule/checkpoint_010.pth.tar'
# TEST : Loss: (0.9965) | Acc: (64.00%) (6450/10000)
percent tensor([0.5077, 0.5136, 0.5056, 0.5074, 0.5071, 0.5118, 0.5114, 0.5083, 0.5098,
        0.5086, 0.5107, 0.5062, 0.5081, 0.5161, 0.5113, 0.5092],
       device='cuda:0') torch.Size([16])
percent tensor([0.5112, 0.5134, 0.5084, 0.5090, 0.5101, 0.5157, 0.5130, 0.5117, 0.5098,
        0.5108, 0.5111, 0.5104, 0.5099, 0.5120, 0.5150, 0.5130],
       device='cuda:0') torch.Size([16])
percent tensor([0.5125, 0.5109, 0.5103, 0.5111, 0.5082, 0.5094, 0.5099, 0.5115, 0.5105,
        0.5114, 0.5123, 0.5092, 0.5116, 0.5154, 0.5097, 0.5140],
       device='cuda:0') torch.Size([16])
percent tensor([0.5125, 0.5096, 0.5107, 0.5118, 0.5107, 0.5166, 0.5096, 0.5105, 0.5094,
        0.5093, 0.5096, 0.5098, 0.5098, 0.5093, 0.5138, 0.5119],
       device='cuda:0') torch.Size([16])
percent tensor([0.4807, 0.4915, 0.4410, 0.4447, 0.4506, 0.4744, 0.4816, 0.4493, 0.4815,
        0.4735, 0.4881, 0.4563, 0.4841, 0.4907, 0.4882, 0.4743],
       device='cuda:0') torch.Size([16])
percent tensor([0.4986, 0.4979, 0.4975, 0.5004, 0.4950, 0.4980, 0.4967, 0.4917, 0.5012,
        0.4966, 0.4992, 0.4996, 0.4997, 0.5011, 0.4913, 0.4932],
       device='cuda:0') torch.Size([16])
percent tensor([0.5080, 0.5119, 0.5467, 0.5438, 0.5478, 0.5027, 0.5273, 0.5625, 0.5165,
        0.5244, 0.5085, 0.5318, 0.5042, 0.5124, 0.5205, 0.5245],
       device='cuda:0') torch.Size([16])
percent tensor([0.7098, 0.7073, 0.8050, 0.7662, 0.7650, 0.7301, 0.7324, 0.8659, 0.7204,
        0.7671, 0.7094, 0.7427, 0.7088, 0.7412, 0.7920, 0.8193],
       device='cuda:0') torch.Size([16])
Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 3, 3, 3]) tensor(169.0385, device='cuda:0')
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(769.7264, device='cuda:0')
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(773.7220, device='cuda:0')
Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([128, 64, 3, 3]) tensor(1533.6801, device='cuda:0')
Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([128, 64, 1, 1]) tensor(514.6865, device='cuda:0')
Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([128, 128, 3, 3]) tensor(2170.6909, device='cuda:0')
Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([256, 128, 3, 3]) tensor(4332.7295, device='cuda:0')
Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([256, 128, 1, 1]) tensor(1434.7788, device='cuda:0')
Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([256, 256, 3, 3]) tensor(6104.9819, device='cuda:0')
Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([512, 256, 3, 3]) tensor(12228.0781, device='cuda:0')
Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([512, 256, 1, 1]) tensor(4079.1433, device='cuda:0')
Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([512, 512, 3, 3]) tensor(17273.7422, device='cuda:0')
Epoch: 11 | Batch_idx: 0 |  Loss: (0.9426) |  Loss2: (0.0000) | Acc: (64.00%) (83/128)
Epoch: 11 | Batch_idx: 10 |  Loss: (1.0030) |  Loss2: (0.0000) | Acc: (64.00%) (903/1408)
Epoch: 11 | Batch_idx: 20 |  Loss: (0.9860) |  Loss2: (0.0000) | Acc: (64.00%) (1732/2688)
Epoch: 11 | Batch_idx: 30 |  Loss: (0.9640) |  Loss2: (0.0000) | Acc: (65.00%) (2588/3968)
Epoch: 11 | Batch_idx: 40 |  Loss: (0.9636) |  Loss2: (0.0000) | Acc: (65.00%) (3416/5248)
Epoch: 11 | Batch_idx: 50 |  Loss: (0.9554) |  Loss2: (0.0000) | Acc: (65.00%) (4259/6528)
Epoch: 11 | Batch_idx: 60 |  Loss: (0.9640) |  Loss2: (0.0000) | Acc: (65.00%) (5077/7808)
Epoch: 11 | Batch_idx: 70 |  Loss: (0.9684) |  Loss2: (0.0000) | Acc: (65.00%) (5908/9088)
Epoch: 11 | Batch_idx: 80 |  Loss: (0.9737) |  Loss2: (0.0000) | Acc: (64.00%) (6731/10368)
Epoch: 11 | Batch_idx: 90 |  Loss: (0.9751) |  Loss2: (0.0000) | Acc: (64.00%) (7568/11648)
Epoch: 11 | Batch_idx: 100 |  Loss: (0.9771) |  Loss2: (0.0000) | Acc: (64.00%) (8382/12928)
Epoch: 11 | Batch_idx: 110 |  Loss: (0.9813) |  Loss2: (0.0000) | Acc: (64.00%) (9178/14208)
Epoch: 11 | Batch_idx: 120 |  Loss: (0.9831) |  Loss2: (0.0000) | Acc: (64.00%) (9994/15488)
Epoch: 11 | Batch_idx: 130 |  Loss: (0.9819) |  Loss2: (0.0000) | Acc: (64.00%) (10836/16768)
Epoch: 11 | Batch_idx: 140 |  Loss: (0.9818) |  Loss2: (0.0000) | Acc: (64.00%) (11649/18048)
Epoch: 11 | Batch_idx: 150 |  Loss: (0.9825) |  Loss2: (0.0000) | Acc: (64.00%) (12490/19328)
Epoch: 11 | Batch_idx: 160 |  Loss: (0.9833) |  Loss2: (0.0000) | Acc: (64.00%) (13317/20608)
Epoch: 11 | Batch_idx: 170 |  Loss: (0.9851) |  Loss2: (0.0000) | Acc: (64.00%) (14128/21888)
Epoch: 11 | Batch_idx: 180 |  Loss: (0.9869) |  Loss2: (0.0000) | Acc: (64.00%) (14943/23168)
Epoch: 11 | Batch_idx: 190 |  Loss: (0.9876) |  Loss2: (0.0000) | Acc: (64.00%) (15768/24448)
Epoch: 11 | Batch_idx: 200 |  Loss: (0.9864) |  Loss2: (0.0000) | Acc: (64.00%) (16608/25728)
Epoch: 11 | Batch_idx: 210 |  Loss: (0.9860) |  Loss2: (0.0000) | Acc: (64.00%) (17425/27008)
Epoch: 11 | Batch_idx: 220 |  Loss: (0.9850) |  Loss2: (0.0000) | Acc: (64.00%) (18263/28288)
Epoch: 11 | Batch_idx: 230 |  Loss: (0.9859) |  Loss2: (0.0000) | Acc: (64.00%) (19080/29568)
Epoch: 11 | Batch_idx: 240 |  Loss: (0.9821) |  Loss2: (0.0000) | Acc: (64.00%) (19945/30848)
Epoch: 11 | Batch_idx: 250 |  Loss: (0.9798) |  Loss2: (0.0000) | Acc: (64.00%) (20777/32128)
Epoch: 11 | Batch_idx: 260 |  Loss: (0.9804) |  Loss2: (0.0000) | Acc: (64.00%) (21597/33408)
Epoch: 11 | Batch_idx: 270 |  Loss: (0.9804) |  Loss2: (0.0000) | Acc: (64.00%) (22423/34688)
Epoch: 11 | Batch_idx: 280 |  Loss: (0.9814) |  Loss2: (0.0000) | Acc: (64.00%) (23230/35968)
Epoch: 11 | Batch_idx: 290 |  Loss: (0.9823) |  Loss2: (0.0000) | Acc: (64.00%) (24054/37248)
Epoch: 11 | Batch_idx: 300 |  Loss: (0.9815) |  Loss2: (0.0000) | Acc: (64.00%) (24879/38528)
Epoch: 11 | Batch_idx: 310 |  Loss: (0.9825) |  Loss2: (0.0000) | Acc: (64.00%) (25709/39808)
Epoch: 11 | Batch_idx: 320 |  Loss: (0.9842) |  Loss2: (0.0000) | Acc: (64.00%) (26539/41088)
Epoch: 11 | Batch_idx: 330 |  Loss: (0.9840) |  Loss2: (0.0000) | Acc: (64.00%) (27366/42368)
Epoch: 11 | Batch_idx: 340 |  Loss: (0.9826) |  Loss2: (0.0000) | Acc: (64.00%) (28223/43648)
Epoch: 11 | Batch_idx: 350 |  Loss: (0.9832) |  Loss2: (0.0000) | Acc: (64.00%) (29041/44928)
Epoch: 11 | Batch_idx: 360 |  Loss: (0.9836) |  Loss2: (0.0000) | Acc: (64.00%) (29877/46208)
Epoch: 11 | Batch_idx: 370 |  Loss: (0.9836) |  Loss2: (0.0000) | Acc: (64.00%) (30702/47488)
Epoch: 11 | Batch_idx: 380 |  Loss: (0.9825) |  Loss2: (0.0000) | Acc: (64.00%) (31553/48768)
Epoch: 11 | Batch_idx: 390 |  Loss: (0.9828) |  Loss2: (0.0000) | Acc: (64.00%) (32345/50000)
# TEST : Loss: (0.9854) | Acc: (64.00%) (6489/10000)
percent tensor([0.5099, 0.5169, 0.5071, 0.5094, 0.5090, 0.5155, 0.5140, 0.5104, 0.5123,
        0.5107, 0.5135, 0.5077, 0.5103, 0.5194, 0.5146, 0.5117],
       device='cuda:0') torch.Size([16])
percent tensor([0.5131, 0.5152, 0.5095, 0.5104, 0.5116, 0.5188, 0.5149, 0.5134, 0.5113,
        0.5120, 0.5126, 0.5117, 0.5115, 0.5140, 0.5176, 0.5150],
       device='cuda:0') torch.Size([16])
percent tensor([0.5157, 0.5135, 0.5141, 0.5151, 0.5116, 0.5112, 0.5129, 0.5155, 0.5138,
        0.5145, 0.5151, 0.5126, 0.5146, 0.5193, 0.5120, 0.5173],
       device='cuda:0') torch.Size([16])
percent tensor([0.5172, 0.5135, 0.5151, 0.5164, 0.5152, 0.5226, 0.5138, 0.5149, 0.5136,
        0.5131, 0.5136, 0.5140, 0.5139, 0.5135, 0.5189, 0.5165],
       device='cuda:0') torch.Size([16])
percent tensor([0.4822, 0.4913, 0.4450, 0.4473, 0.4546, 0.4762, 0.4838, 0.4533, 0.4835,
        0.4734, 0.4875, 0.4593, 0.4843, 0.4920, 0.4908, 0.4744],
       device='cuda:0') torch.Size([16])
percent tensor([0.4991, 0.4986, 0.4997, 0.5025, 0.4969, 0.4980, 0.4980, 0.4926, 0.5032,
        0.4975, 0.5002, 0.5020, 0.5005, 0.5027, 0.4905, 0.4927],
       device='cuda:0') torch.Size([16])
percent tensor([0.5056, 0.5109, 0.5508, 0.5476, 0.5507, 0.4984, 0.5274, 0.5668, 0.5155,
        0.5226, 0.5061, 0.5332, 0.4998, 0.5114, 0.5210, 0.5213],
       device='cuda:0') torch.Size([16])
percent tensor([0.7280, 0.7264, 0.8351, 0.7967, 0.7916, 0.7517, 0.7520, 0.8939, 0.7351,
        0.7870, 0.7219, 0.7674, 0.7173, 0.7624, 0.8188, 0.8398],
       device='cuda:0') torch.Size([16])
Epoch: 12 | Batch_idx: 0 |  Loss: (1.0836) |  Loss2: (0.0000) | Acc: (60.00%) (78/128)
Epoch: 12 | Batch_idx: 10 |  Loss: (1.0384) |  Loss2: (0.0000) | Acc: (63.00%) (894/1408)
Epoch: 12 | Batch_idx: 20 |  Loss: (1.0360) |  Loss2: (0.0000) | Acc: (63.00%) (1710/2688)
Epoch: 12 | Batch_idx: 30 |  Loss: (0.9965) |  Loss2: (0.0000) | Acc: (65.00%) (2581/3968)
Epoch: 12 | Batch_idx: 40 |  Loss: (0.9922) |  Loss2: (0.0000) | Acc: (64.00%) (3405/5248)
Epoch: 12 | Batch_idx: 50 |  Loss: (0.9858) |  Loss2: (0.0000) | Acc: (65.00%) (4256/6528)
Epoch: 12 | Batch_idx: 60 |  Loss: (0.9795) |  Loss2: (0.0000) | Acc: (65.00%) (5105/7808)
Epoch: 12 | Batch_idx: 70 |  Loss: (0.9734) |  Loss2: (0.0000) | Acc: (65.00%) (5970/9088)
Epoch: 12 | Batch_idx: 80 |  Loss: (0.9788) |  Loss2: (0.0000) | Acc: (65.00%) (6778/10368)
Epoch: 12 | Batch_idx: 90 |  Loss: (0.9777) |  Loss2: (0.0000) | Acc: (65.00%) (7603/11648)
Epoch: 12 | Batch_idx: 100 |  Loss: (0.9814) |  Loss2: (0.0000) | Acc: (65.00%) (8410/12928)
Epoch: 12 | Batch_idx: 110 |  Loss: (0.9796) |  Loss2: (0.0000) | Acc: (64.00%) (9229/14208)
Epoch: 12 | Batch_idx: 120 |  Loss: (0.9792) |  Loss2: (0.0000) | Acc: (64.00%) (10067/15488)
Epoch: 12 | Batch_idx: 130 |  Loss: (0.9791) |  Loss2: (0.0000) | Acc: (65.00%) (10900/16768)
Epoch: 12 | Batch_idx: 140 |  Loss: (0.9740) |  Loss2: (0.0000) | Acc: (65.00%) (11791/18048)
Epoch: 12 | Batch_idx: 150 |  Loss: (0.9693) |  Loss2: (0.0000) | Acc: (65.00%) (12655/19328)
Epoch: 12 | Batch_idx: 160 |  Loss: (0.9709) |  Loss2: (0.0000) | Acc: (65.00%) (13472/20608)
Epoch: 12 | Batch_idx: 170 |  Loss: (0.9698) |  Loss2: (0.0000) | Acc: (65.00%) (14288/21888)
Epoch: 12 | Batch_idx: 180 |  Loss: (0.9701) |  Loss2: (0.0000) | Acc: (65.00%) (15128/23168)
Epoch: 12 | Batch_idx: 190 |  Loss: (0.9694) |  Loss2: (0.0000) | Acc: (65.00%) (15988/24448)
Epoch: 12 | Batch_idx: 200 |  Loss: (0.9687) |  Loss2: (0.0000) | Acc: (65.00%) (16830/25728)
Epoch: 12 | Batch_idx: 210 |  Loss: (0.9684) |  Loss2: (0.0000) | Acc: (65.00%) (17650/27008)
Epoch: 12 | Batch_idx: 220 |  Loss: (0.9684) |  Loss2: (0.0000) | Acc: (65.00%) (18474/28288)
Epoch: 12 | Batch_idx: 230 |  Loss: (0.9702) |  Loss2: (0.0000) | Acc: (65.00%) (19280/29568)
Epoch: 12 | Batch_idx: 240 |  Loss: (0.9709) |  Loss2: (0.0000) | Acc: (65.00%) (20089/30848)
Epoch: 12 | Batch_idx: 250 |  Loss: (0.9729) |  Loss2: (0.0000) | Acc: (65.00%) (20896/32128)
Epoch: 12 | Batch_idx: 260 |  Loss: (0.9723) |  Loss2: (0.0000) | Acc: (65.00%) (21719/33408)
Epoch: 12 | Batch_idx: 270 |  Loss: (0.9728) |  Loss2: (0.0000) | Acc: (64.00%) (22532/34688)
Epoch: 12 | Batch_idx: 280 |  Loss: (0.9730) |  Loss2: (0.0000) | Acc: (64.00%) (23370/35968)
Epoch: 12 | Batch_idx: 290 |  Loss: (0.9718) |  Loss2: (0.0000) | Acc: (64.00%) (24206/37248)
Epoch: 12 | Batch_idx: 300 |  Loss: (0.9711) |  Loss2: (0.0000) | Acc: (65.00%) (25061/38528)
Epoch: 12 | Batch_idx: 310 |  Loss: (0.9729) |  Loss2: (0.0000) | Acc: (64.00%) (25865/39808)
Epoch: 12 | Batch_idx: 320 |  Loss: (0.9725) |  Loss2: (0.0000) | Acc: (64.00%) (26706/41088)
Epoch: 12 | Batch_idx: 330 |  Loss: (0.9723) |  Loss2: (0.0000) | Acc: (65.00%) (27541/42368)
Epoch: 12 | Batch_idx: 340 |  Loss: (0.9725) |  Loss2: (0.0000) | Acc: (64.00%) (28364/43648)
Epoch: 12 | Batch_idx: 350 |  Loss: (0.9735) |  Loss2: (0.0000) | Acc: (64.00%) (29181/44928)
Epoch: 12 | Batch_idx: 360 |  Loss: (0.9743) |  Loss2: (0.0000) | Acc: (64.00%) (30010/46208)
Epoch: 12 | Batch_idx: 370 |  Loss: (0.9744) |  Loss2: (0.0000) | Acc: (64.00%) (30842/47488)
Epoch: 12 | Batch_idx: 380 |  Loss: (0.9741) |  Loss2: (0.0000) | Acc: (64.00%) (31688/48768)
Epoch: 12 | Batch_idx: 390 |  Loss: (0.9754) |  Loss2: (0.0000) | Acc: (64.00%) (32450/50000)
# TEST : Loss: (0.9808) | Acc: (65.00%) (6513/10000)
percent tensor([0.5110, 0.5181, 0.5073, 0.5104, 0.5093, 0.5183, 0.5147, 0.5110, 0.5130,
        0.5110, 0.5147, 0.5080, 0.5112, 0.5204, 0.5165, 0.5130],
       device='cuda:0') torch.Size([16])
percent tensor([0.5148, 0.5164, 0.5100, 0.5114, 0.5126, 0.5217, 0.5161, 0.5145, 0.5122,
        0.5127, 0.5136, 0.5125, 0.5126, 0.5154, 0.5197, 0.5168],
       device='cuda:0') torch.Size([16])
percent tensor([0.5181, 0.5152, 0.5182, 0.5188, 0.5152, 0.5122, 0.5153, 0.5194, 0.5165,
        0.5170, 0.5170, 0.5161, 0.5170, 0.5219, 0.5134, 0.5198],
       device='cuda:0') torch.Size([16])
percent tensor([0.5224, 0.5181, 0.5199, 0.5213, 0.5201, 0.5291, 0.5185, 0.5196, 0.5180,
        0.5174, 0.5182, 0.5186, 0.5181, 0.5181, 0.5246, 0.5216],
       device='cuda:0') torch.Size([16])
percent tensor([0.4843, 0.4918, 0.4507, 0.4529, 0.4608, 0.4789, 0.4869, 0.4593, 0.4856,
        0.4735, 0.4875, 0.4642, 0.4845, 0.4940, 0.4942, 0.4756],
       device='cuda:0') torch.Size([16])
percent tensor([0.4988, 0.4984, 0.5006, 0.5041, 0.4969, 0.4972, 0.4977, 0.4916, 0.5043,
        0.4971, 0.5002, 0.5028, 0.5006, 0.5036, 0.4882, 0.4905],
       device='cuda:0') torch.Size([16])
percent tensor([0.5040, 0.5107, 0.5554, 0.5508, 0.5553, 0.4950, 0.5279, 0.5717, 0.5161,
        0.5224, 0.5049, 0.5350, 0.4971, 0.5106, 0.5218, 0.5192],
       device='cuda:0') torch.Size([16])
percent tensor([0.7471, 0.7430, 0.8633, 0.8196, 0.8208, 0.7668, 0.7697, 0.9149, 0.7532,
        0.8064, 0.7324, 0.7899, 0.7301, 0.7760, 0.8391, 0.8546],
       device='cuda:0') torch.Size([16])
Epoch: 13 | Batch_idx: 0 |  Loss: (1.1806) |  Loss2: (0.0000) | Acc: (60.00%) (77/128)
Epoch: 13 | Batch_idx: 10 |  Loss: (0.9991) |  Loss2: (0.0000) | Acc: (64.00%) (914/1408)
Epoch: 13 | Batch_idx: 20 |  Loss: (0.9908) |  Loss2: (0.0000) | Acc: (64.00%) (1741/2688)
Epoch: 13 | Batch_idx: 30 |  Loss: (0.9732) |  Loss2: (0.0000) | Acc: (65.00%) (2604/3968)
Epoch: 13 | Batch_idx: 40 |  Loss: (0.9794) |  Loss2: (0.0000) | Acc: (65.00%) (3424/5248)
Epoch: 13 | Batch_idx: 50 |  Loss: (0.9826) |  Loss2: (0.0000) | Acc: (65.00%) (4253/6528)
Epoch: 13 | Batch_idx: 60 |  Loss: (0.9816) |  Loss2: (0.0000) | Acc: (65.00%) (5087/7808)
Epoch: 13 | Batch_idx: 70 |  Loss: (0.9844) |  Loss2: (0.0000) | Acc: (65.00%) (5911/9088)
Epoch: 13 | Batch_idx: 80 |  Loss: (0.9922) |  Loss2: (0.0000) | Acc: (64.00%) (6725/10368)
Epoch: 13 | Batch_idx: 90 |  Loss: (0.9917) |  Loss2: (0.0000) | Acc: (64.00%) (7545/11648)
Epoch: 13 | Batch_idx: 100 |  Loss: (0.9903) |  Loss2: (0.0000) | Acc: (64.00%) (8364/12928)
Epoch: 13 | Batch_idx: 110 |  Loss: (0.9880) |  Loss2: (0.0000) | Acc: (64.00%) (9195/14208)
Epoch: 13 | Batch_idx: 120 |  Loss: (0.9836) |  Loss2: (0.0000) | Acc: (64.00%) (10054/15488)
Epoch: 13 | Batch_idx: 130 |  Loss: (0.9818) |  Loss2: (0.0000) | Acc: (64.00%) (10875/16768)
Epoch: 13 | Batch_idx: 140 |  Loss: (0.9785) |  Loss2: (0.0000) | Acc: (64.00%) (11731/18048)
Epoch: 13 | Batch_idx: 150 |  Loss: (0.9797) |  Loss2: (0.0000) | Acc: (64.00%) (12546/19328)
Epoch: 13 | Batch_idx: 160 |  Loss: (0.9782) |  Loss2: (0.0000) | Acc: (64.00%) (13394/20608)
Epoch: 13 | Batch_idx: 170 |  Loss: (0.9756) |  Loss2: (0.0000) | Acc: (65.00%) (14246/21888)
Epoch: 13 | Batch_idx: 180 |  Loss: (0.9764) |  Loss2: (0.0000) | Acc: (65.00%) (15067/23168)
Epoch: 13 | Batch_idx: 190 |  Loss: (0.9772) |  Loss2: (0.0000) | Acc: (65.00%) (15900/24448)
Epoch: 13 | Batch_idx: 200 |  Loss: (0.9775) |  Loss2: (0.0000) | Acc: (64.00%) (16714/25728)
Epoch: 13 | Batch_idx: 210 |  Loss: (0.9750) |  Loss2: (0.0000) | Acc: (65.00%) (17561/27008)
Epoch: 13 | Batch_idx: 220 |  Loss: (0.9742) |  Loss2: (0.0000) | Acc: (65.00%) (18394/28288)
Epoch: 13 | Batch_idx: 230 |  Loss: (0.9731) |  Loss2: (0.0000) | Acc: (65.00%) (19224/29568)
Epoch: 13 | Batch_idx: 240 |  Loss: (0.9754) |  Loss2: (0.0000) | Acc: (64.00%) (20026/30848)
Epoch: 13 | Batch_idx: 250 |  Loss: (0.9749) |  Loss2: (0.0000) | Acc: (64.00%) (20860/32128)
Epoch: 13 | Batch_idx: 260 |  Loss: (0.9755) |  Loss2: (0.0000) | Acc: (64.00%) (21677/33408)
Epoch: 13 | Batch_idx: 270 |  Loss: (0.9749) |  Loss2: (0.0000) | Acc: (64.00%) (22500/34688)
Epoch: 13 | Batch_idx: 280 |  Loss: (0.9731) |  Loss2: (0.0000) | Acc: (64.00%) (23361/35968)
Epoch: 13 | Batch_idx: 290 |  Loss: (0.9751) |  Loss2: (0.0000) | Acc: (64.00%) (24184/37248)
Epoch: 13 | Batch_idx: 300 |  Loss: (0.9749) |  Loss2: (0.0000) | Acc: (64.00%) (25024/38528)
Epoch: 13 | Batch_idx: 310 |  Loss: (0.9751) |  Loss2: (0.0000) | Acc: (64.00%) (25868/39808)
Epoch: 13 | Batch_idx: 320 |  Loss: (0.9751) |  Loss2: (0.0000) | Acc: (64.00%) (26694/41088)
Epoch: 13 | Batch_idx: 330 |  Loss: (0.9744) |  Loss2: (0.0000) | Acc: (65.00%) (27540/42368)
Epoch: 13 | Batch_idx: 340 |  Loss: (0.9746) |  Loss2: (0.0000) | Acc: (64.00%) (28369/43648)
Epoch: 13 | Batch_idx: 350 |  Loss: (0.9731) |  Loss2: (0.0000) | Acc: (65.00%) (29236/44928)
Epoch: 13 | Batch_idx: 360 |  Loss: (0.9735) |  Loss2: (0.0000) | Acc: (65.00%) (30053/46208)
Epoch: 13 | Batch_idx: 370 |  Loss: (0.9725) |  Loss2: (0.0000) | Acc: (65.00%) (30904/47488)
Epoch: 13 | Batch_idx: 380 |  Loss: (0.9722) |  Loss2: (0.0000) | Acc: (65.00%) (31736/48768)
Epoch: 13 | Batch_idx: 390 |  Loss: (0.9712) |  Loss2: (0.0000) | Acc: (65.00%) (32538/50000)
# TEST : Loss: (0.9769) | Acc: (65.00%) (6530/10000)
percent tensor([0.5130, 0.5209, 0.5089, 0.5124, 0.5111, 0.5218, 0.5170, 0.5129, 0.5151,
        0.5129, 0.5171, 0.5095, 0.5132, 0.5229, 0.5196, 0.5153],
       device='cuda:0') torch.Size([16])
percent tensor([0.5149, 0.5163, 0.5088, 0.5110, 0.5115, 0.5229, 0.5156, 0.5140, 0.5115,
        0.5118, 0.5134, 0.5114, 0.5124, 0.5154, 0.5204, 0.5171],
       device='cuda:0') torch.Size([16])
percent tensor([0.5192, 0.5158, 0.5211, 0.5218, 0.5177, 0.5121, 0.5166, 0.5221, 0.5182,
        0.5184, 0.5176, 0.5185, 0.5181, 0.5234, 0.5135, 0.5209],
       device='cuda:0') torch.Size([16])
percent tensor([0.5256, 0.5210, 0.5225, 0.5241, 0.5228, 0.5334, 0.5213, 0.5223, 0.5207,
        0.5200, 0.5211, 0.5212, 0.5210, 0.5210, 0.5284, 0.5247],
       device='cuda:0') torch.Size([16])
percent tensor([0.4857, 0.4924, 0.4547, 0.4570, 0.4645, 0.4806, 0.4889, 0.4632, 0.4876,
        0.4736, 0.4873, 0.4673, 0.4850, 0.4957, 0.4965, 0.4757],
       device='cuda:0') torch.Size([16])
percent tensor([0.4980, 0.4979, 0.5003, 0.5039, 0.4963, 0.4961, 0.4970, 0.4893, 0.5054,
        0.4967, 0.5004, 0.5031, 0.5006, 0.5043, 0.4849, 0.4878],
       device='cuda:0') torch.Size([16])
percent tensor([0.5024, 0.5116, 0.5599, 0.5551, 0.5598, 0.4918, 0.5290, 0.5778, 0.5169,
        0.5232, 0.5048, 0.5373, 0.4945, 0.5111, 0.5239, 0.5175],
       device='cuda:0') torch.Size([16])
percent tensor([0.7669, 0.7681, 0.8808, 0.8404, 0.8394, 0.7912, 0.7895, 0.9313, 0.7738,
        0.8289, 0.7550, 0.8108, 0.7482, 0.8003, 0.8635, 0.8728],
       device='cuda:0') torch.Size([16])
True Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=128, out_features=16, bias=False)
False Linear(in_features=16, out_features=2, bias=False)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=128, out_features=16, bias=False)
False Linear(in_features=16, out_features=2, bias=False)
True Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=256, out_features=32, bias=False)
False Linear(in_features=32, out_features=2, bias=False)
True Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=256, out_features=32, bias=False)
False Linear(in_features=32, out_features=2, bias=False)
True Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=512, out_features=64, bias=False)
False Linear(in_features=64, out_features=2, bias=False)
True Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=512, out_features=64, bias=False)
False Linear(in_features=64, out_features=2, bias=False)
True Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1024, out_features=128, bias=False)
False Linear(in_features=128, out_features=2, bias=False)
True Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1024, out_features=128, bias=False)
False Linear(in_features=128, out_features=2, bias=False)
True Linear(in_features=512, out_features=10, bias=True)
Epoch: 14 | Batch_idx: 0 |  Loss: (1.0685) |  Loss2: (0.0000) | Acc: (60.00%) (78/128)
Epoch: 14 | Batch_idx: 10 |  Loss: (1.0316) |  Loss2: (0.0000) | Acc: (63.00%) (901/1408)
Epoch: 14 | Batch_idx: 20 |  Loss: (1.0111) |  Loss2: (0.0000) | Acc: (64.00%) (1724/2688)
Epoch: 14 | Batch_idx: 30 |  Loss: (1.0057) |  Loss2: (0.0000) | Acc: (64.00%) (2560/3968)
Epoch: 14 | Batch_idx: 40 |  Loss: (0.9977) |  Loss2: (0.0000) | Acc: (64.00%) (3400/5248)
Epoch: 14 | Batch_idx: 50 |  Loss: (0.9874) |  Loss2: (0.0000) | Acc: (64.00%) (4238/6528)
Epoch: 14 | Batch_idx: 60 |  Loss: (0.9835) |  Loss2: (0.0000) | Acc: (65.00%) (5083/7808)
Epoch: 14 | Batch_idx: 70 |  Loss: (0.9857) |  Loss2: (0.0000) | Acc: (64.00%) (5901/9088)
Epoch: 14 | Batch_idx: 80 |  Loss: (0.9830) |  Loss2: (0.0000) | Acc: (64.00%) (6736/10368)
Epoch: 14 | Batch_idx: 90 |  Loss: (0.9841) |  Loss2: (0.0000) | Acc: (64.00%) (7560/11648)
Epoch: 14 | Batch_idx: 100 |  Loss: (0.9844) |  Loss2: (0.0000) | Acc: (64.00%) (8386/12928)
Epoch: 14 | Batch_idx: 110 |  Loss: (0.9833) |  Loss2: (0.0000) | Acc: (64.00%) (9223/14208)
Epoch: 14 | Batch_idx: 120 |  Loss: (0.9855) |  Loss2: (0.0000) | Acc: (64.00%) (10024/15488)
Epoch: 14 | Batch_idx: 130 |  Loss: (0.9860) |  Loss2: (0.0000) | Acc: (64.00%) (10862/16768)
Epoch: 14 | Batch_idx: 140 |  Loss: (0.9883) |  Loss2: (0.0000) | Acc: (64.00%) (11646/18048)
Epoch: 14 | Batch_idx: 150 |  Loss: (0.9884) |  Loss2: (0.0000) | Acc: (64.00%) (12470/19328)
Epoch: 14 | Batch_idx: 160 |  Loss: (0.9890) |  Loss2: (0.0000) | Acc: (64.00%) (13266/20608)
Epoch: 14 | Batch_idx: 170 |  Loss: (0.9889) |  Loss2: (0.0000) | Acc: (64.00%) (14089/21888)
Epoch: 14 | Batch_idx: 180 |  Loss: (0.9888) |  Loss2: (0.0000) | Acc: (64.00%) (14939/23168)
Epoch: 14 | Batch_idx: 190 |  Loss: (0.9862) |  Loss2: (0.0000) | Acc: (64.00%) (15787/24448)
Epoch: 14 | Batch_idx: 200 |  Loss: (0.9837) |  Loss2: (0.0000) | Acc: (64.00%) (16625/25728)
Epoch: 14 | Batch_idx: 210 |  Loss: (0.9824) |  Loss2: (0.0000) | Acc: (64.00%) (17471/27008)
Epoch: 14 | Batch_idx: 220 |  Loss: (0.9821) |  Loss2: (0.0000) | Acc: (64.00%) (18305/28288)
Epoch: 14 | Batch_idx: 230 |  Loss: (0.9845) |  Loss2: (0.0000) | Acc: (64.00%) (19111/29568)
Epoch: 14 | Batch_idx: 240 |  Loss: (0.9834) |  Loss2: (0.0000) | Acc: (64.00%) (19940/30848)
Epoch: 14 | Batch_idx: 250 |  Loss: (0.9833) |  Loss2: (0.0000) | Acc: (64.00%) (20769/32128)
Epoch: 14 | Batch_idx: 260 |  Loss: (0.9811) |  Loss2: (0.0000) | Acc: (64.00%) (21631/33408)
Epoch: 14 | Batch_idx: 270 |  Loss: (0.9808) |  Loss2: (0.0000) | Acc: (64.00%) (22475/34688)
Epoch: 14 | Batch_idx: 280 |  Loss: (0.9815) |  Loss2: (0.0000) | Acc: (64.00%) (23299/35968)
Epoch: 14 | Batch_idx: 290 |  Loss: (0.9800) |  Loss2: (0.0000) | Acc: (64.00%) (24156/37248)
Epoch: 14 | Batch_idx: 300 |  Loss: (0.9798) |  Loss2: (0.0000) | Acc: (64.00%) (24993/38528)
Epoch: 14 | Batch_idx: 310 |  Loss: (0.9794) |  Loss2: (0.0000) | Acc: (64.00%) (25838/39808)
Epoch: 14 | Batch_idx: 320 |  Loss: (0.9770) |  Loss2: (0.0000) | Acc: (65.00%) (26717/41088)
Epoch: 14 | Batch_idx: 330 |  Loss: (0.9767) |  Loss2: (0.0000) | Acc: (65.00%) (27557/42368)
Epoch: 14 | Batch_idx: 340 |  Loss: (0.9762) |  Loss2: (0.0000) | Acc: (65.00%) (28401/43648)
Epoch: 14 | Batch_idx: 350 |  Loss: (0.9746) |  Loss2: (0.0000) | Acc: (65.00%) (29256/44928)
Epoch: 14 | Batch_idx: 360 |  Loss: (0.9732) |  Loss2: (0.0000) | Acc: (65.00%) (30143/46208)
Epoch: 14 | Batch_idx: 370 |  Loss: (0.9723) |  Loss2: (0.0000) | Acc: (65.00%) (30998/47488)
Epoch: 14 | Batch_idx: 380 |  Loss: (0.9719) |  Loss2: (0.0000) | Acc: (65.00%) (31841/48768)
Epoch: 14 | Batch_idx: 390 |  Loss: (0.9714) |  Loss2: (0.0000) | Acc: (65.00%) (32679/50000)
# TEST : Loss: (1.1507) | Acc: (59.00%) (5987/10000)
percent tensor([0.5134, 0.5202, 0.5093, 0.5136, 0.5114, 0.5226, 0.5163, 0.5133, 0.5147,
        0.5129, 0.5170, 0.5094, 0.5137, 0.5204, 0.5203, 0.5159],
       device='cuda:0') torch.Size([16])
percent tensor([0.5147, 0.5150, 0.5119, 0.5119, 0.5147, 0.5227, 0.5162, 0.5147, 0.5121,
        0.5126, 0.5129, 0.5143, 0.5123, 0.5132, 0.5200, 0.5161],
       device='cuda:0') torch.Size([16])
percent tensor([0.5197, 0.5152, 0.5199, 0.5203, 0.5161, 0.5117, 0.5160, 0.5215, 0.5171,
        0.5174, 0.5174, 0.5178, 0.5174, 0.5241, 0.5130, 0.5207],
       device='cuda:0') torch.Size([16])
percent tensor([0.5252, 0.5214, 0.5235, 0.5249, 0.5239, 0.5325, 0.5219, 0.5233, 0.5208,
        0.5218, 0.5219, 0.5228, 0.5212, 0.5216, 0.5289, 0.5245],
       device='cuda:0') torch.Size([16])
percent tensor([0.4807, 0.4875, 0.4584, 0.4616, 0.4669, 0.4752, 0.4843, 0.4665, 0.4863,
        0.4713, 0.4834, 0.4682, 0.4816, 0.4895, 0.4901, 0.4731],
       device='cuda:0') torch.Size([16])
percent tensor([0.4983, 0.4985, 0.5012, 0.5023, 0.4973, 0.4997, 0.4970, 0.4887, 0.5062,
        0.4959, 0.5001, 0.5019, 0.5005, 0.5068, 0.4892, 0.4906],
       device='cuda:0') torch.Size([16])
percent tensor([0.5088, 0.5135, 0.5521, 0.5505, 0.5611, 0.4983, 0.5334, 0.5707, 0.5216,
        0.5261, 0.5131, 0.5384, 0.5067, 0.5205, 0.5214, 0.5143],
       device='cuda:0') torch.Size([16])
percent tensor([0.8213, 0.7728, 0.8569, 0.8356, 0.8694, 0.8220, 0.8198, 0.9182, 0.7920,
        0.8440, 0.7965, 0.8267, 0.8133, 0.8009, 0.8250, 0.8705],
       device='cuda:0') torch.Size([16])
Epoch: 15 | Batch_idx: 0 |  Loss: (0.8712) |  Loss2: (0.0000) | Acc: (69.00%) (89/128)
Epoch: 15 | Batch_idx: 10 |  Loss: (0.9267) |  Loss2: (0.0000) | Acc: (66.00%) (935/1408)
Epoch: 15 | Batch_idx: 20 |  Loss: (0.9238) |  Loss2: (0.0000) | Acc: (66.00%) (1800/2688)
Epoch: 15 | Batch_idx: 30 |  Loss: (0.9249) |  Loss2: (0.0000) | Acc: (67.00%) (2659/3968)
Epoch: 15 | Batch_idx: 40 |  Loss: (0.9222) |  Loss2: (0.0000) | Acc: (67.00%) (3526/5248)
Epoch: 15 | Batch_idx: 50 |  Loss: (0.9241) |  Loss2: (0.0000) | Acc: (67.00%) (4383/6528)
Epoch: 15 | Batch_idx: 60 |  Loss: (0.9237) |  Loss2: (0.0000) | Acc: (67.00%) (5245/7808)
Epoch: 15 | Batch_idx: 70 |  Loss: (0.9190) |  Loss2: (0.0000) | Acc: (67.00%) (6134/9088)
Epoch: 15 | Batch_idx: 80 |  Loss: (0.9198) |  Loss2: (0.0000) | Acc: (67.00%) (6978/10368)
Epoch: 15 | Batch_idx: 90 |  Loss: (0.9203) |  Loss2: (0.0000) | Acc: (67.00%) (7833/11648)
Epoch: 15 | Batch_idx: 100 |  Loss: (0.9225) |  Loss2: (0.0000) | Acc: (67.00%) (8677/12928)
Epoch: 15 | Batch_idx: 110 |  Loss: (0.9228) |  Loss2: (0.0000) | Acc: (67.00%) (9533/14208)
Epoch: 15 | Batch_idx: 120 |  Loss: (0.9242) |  Loss2: (0.0000) | Acc: (67.00%) (10393/15488)
Epoch: 15 | Batch_idx: 130 |  Loss: (0.9265) |  Loss2: (0.0000) | Acc: (67.00%) (11241/16768)
Epoch: 15 | Batch_idx: 140 |  Loss: (0.9240) |  Loss2: (0.0000) | Acc: (67.00%) (12110/18048)
Epoch: 15 | Batch_idx: 150 |  Loss: (0.9205) |  Loss2: (0.0000) | Acc: (67.00%) (13005/19328)
Epoch: 15 | Batch_idx: 160 |  Loss: (0.9181) |  Loss2: (0.0000) | Acc: (67.00%) (13883/20608)
Epoch: 15 | Batch_idx: 170 |  Loss: (0.9204) |  Loss2: (0.0000) | Acc: (67.00%) (14743/21888)
Epoch: 15 | Batch_idx: 180 |  Loss: (0.9213) |  Loss2: (0.0000) | Acc: (67.00%) (15592/23168)
Epoch: 15 | Batch_idx: 190 |  Loss: (0.9203) |  Loss2: (0.0000) | Acc: (67.00%) (16465/24448)
Epoch: 15 | Batch_idx: 200 |  Loss: (0.9212) |  Loss2: (0.0000) | Acc: (67.00%) (17309/25728)
Epoch: 15 | Batch_idx: 210 |  Loss: (0.9197) |  Loss2: (0.0000) | Acc: (67.00%) (18214/27008)
Epoch: 15 | Batch_idx: 220 |  Loss: (0.9198) |  Loss2: (0.0000) | Acc: (67.00%) (19081/28288)
Epoch: 15 | Batch_idx: 230 |  Loss: (0.9195) |  Loss2: (0.0000) | Acc: (67.00%) (19966/29568)
Epoch: 15 | Batch_idx: 240 |  Loss: (0.9215) |  Loss2: (0.0000) | Acc: (67.00%) (20775/30848)
Epoch: 15 | Batch_idx: 250 |  Loss: (0.9178) |  Loss2: (0.0000) | Acc: (67.00%) (21690/32128)
Epoch: 15 | Batch_idx: 260 |  Loss: (0.9163) |  Loss2: (0.0000) | Acc: (67.00%) (22579/33408)
Epoch: 15 | Batch_idx: 270 |  Loss: (0.9139) |  Loss2: (0.0000) | Acc: (67.00%) (23483/34688)
Epoch: 15 | Batch_idx: 280 |  Loss: (0.9108) |  Loss2: (0.0000) | Acc: (67.00%) (24385/35968)
Epoch: 15 | Batch_idx: 290 |  Loss: (0.9115) |  Loss2: (0.0000) | Acc: (67.00%) (25242/37248)
Epoch: 15 | Batch_idx: 300 |  Loss: (0.9128) |  Loss2: (0.0000) | Acc: (67.00%) (26077/38528)
Epoch: 15 | Batch_idx: 310 |  Loss: (0.9126) |  Loss2: (0.0000) | Acc: (67.00%) (26942/39808)
Epoch: 15 | Batch_idx: 320 |  Loss: (0.9122) |  Loss2: (0.0000) | Acc: (67.00%) (27804/41088)
Epoch: 15 | Batch_idx: 330 |  Loss: (0.9113) |  Loss2: (0.0000) | Acc: (67.00%) (28676/42368)
Epoch: 15 | Batch_idx: 340 |  Loss: (0.9101) |  Loss2: (0.0000) | Acc: (67.00%) (29551/43648)
Epoch: 15 | Batch_idx: 350 |  Loss: (0.9105) |  Loss2: (0.0000) | Acc: (67.00%) (30418/44928)
Epoch: 15 | Batch_idx: 360 |  Loss: (0.9089) |  Loss2: (0.0000) | Acc: (67.00%) (31284/46208)
Epoch: 15 | Batch_idx: 370 |  Loss: (0.9068) |  Loss2: (0.0000) | Acc: (67.00%) (32195/47488)
Epoch: 15 | Batch_idx: 380 |  Loss: (0.9053) |  Loss2: (0.0000) | Acc: (67.00%) (33088/48768)
Epoch: 15 | Batch_idx: 390 |  Loss: (0.9053) |  Loss2: (0.0000) | Acc: (67.00%) (33941/50000)
=> saving checkpoint 'drive/app/torch/save_Schedule/checkpoint_015.pth.tar'
# TEST : Loss: (1.2404) | Acc: (58.00%) (5809/10000)
percent tensor([0.5127, 0.5201, 0.5100, 0.5134, 0.5120, 0.5202, 0.5167, 0.5136, 0.5147,
        0.5131, 0.5165, 0.5097, 0.5132, 0.5208, 0.5191, 0.5151],
       device='cuda:0') torch.Size([16])
percent tensor([0.5144, 0.5162, 0.5113, 0.5117, 0.5144, 0.5219, 0.5173, 0.5146, 0.5133,
        0.5131, 0.5136, 0.5142, 0.5129, 0.5161, 0.5203, 0.5160],
       device='cuda:0') torch.Size([16])
percent tensor([0.5212, 0.5166, 0.5200, 0.5202, 0.5158, 0.5124, 0.5171, 0.5212, 0.5197,
        0.5187, 0.5200, 0.5190, 0.5194, 0.5257, 0.5143, 0.5211],
       device='cuda:0') torch.Size([16])
percent tensor([0.5250, 0.5207, 0.5216, 0.5236, 0.5231, 0.5311, 0.5217, 0.5231, 0.5204,
        0.5203, 0.5213, 0.5211, 0.5212, 0.5200, 0.5281, 0.5236],
       device='cuda:0') torch.Size([16])
percent tensor([0.4883, 0.4897, 0.4690, 0.4705, 0.4768, 0.4819, 0.4872, 0.4697, 0.4912,
        0.4742, 0.4881, 0.4749, 0.4871, 0.4894, 0.4960, 0.4792],
       device='cuda:0') torch.Size([16])
percent tensor([0.4946, 0.4966, 0.4971, 0.4989, 0.4933, 0.4953, 0.4917, 0.4890, 0.5051,
        0.4959, 0.4989, 0.4919, 0.4991, 0.5046, 0.4826, 0.4857],
       device='cuda:0') torch.Size([16])
percent tensor([0.5040, 0.5139, 0.5383, 0.5389, 0.5421, 0.4895, 0.5316, 0.5626, 0.5187,
        0.5227, 0.5100, 0.5417, 0.5049, 0.5204, 0.5235, 0.5170],
       device='cuda:0') torch.Size([16])
percent tensor([0.7896, 0.8063, 0.8286, 0.8170, 0.8150, 0.7838, 0.8508, 0.9058, 0.7967,
        0.8492, 0.7953, 0.8433, 0.8020, 0.8418, 0.8612, 0.8613],
       device='cuda:0') torch.Size([16])
Epoch: 16 | Batch_idx: 0 |  Loss: (0.9106) |  Loss2: (0.0000) | Acc: (71.00%) (91/128)
Epoch: 16 | Batch_idx: 10 |  Loss: (0.8784) |  Loss2: (0.0000) | Acc: (69.00%) (974/1408)
Epoch: 16 | Batch_idx: 20 |  Loss: (0.8580) |  Loss2: (0.0000) | Acc: (70.00%) (1897/2688)
Epoch: 16 | Batch_idx: 30 |  Loss: (0.8643) |  Loss2: (0.0000) | Acc: (70.00%) (2810/3968)
Epoch: 16 | Batch_idx: 40 |  Loss: (0.8702) |  Loss2: (0.0000) | Acc: (70.00%) (3691/5248)
Epoch: 16 | Batch_idx: 50 |  Loss: (0.8629) |  Loss2: (0.0000) | Acc: (70.00%) (4590/6528)
Epoch: 16 | Batch_idx: 60 |  Loss: (0.8692) |  Loss2: (0.0000) | Acc: (69.00%) (5455/7808)
Epoch: 16 | Batch_idx: 70 |  Loss: (0.8673) |  Loss2: (0.0000) | Acc: (69.00%) (6328/9088)
Epoch: 16 | Batch_idx: 80 |  Loss: (0.8672) |  Loss2: (0.0000) | Acc: (69.00%) (7221/10368)
Epoch: 16 | Batch_idx: 90 |  Loss: (0.8624) |  Loss2: (0.0000) | Acc: (69.00%) (8119/11648)
Epoch: 16 | Batch_idx: 100 |  Loss: (0.8669) |  Loss2: (0.0000) | Acc: (69.00%) (8992/12928)
Epoch: 16 | Batch_idx: 110 |  Loss: (0.8681) |  Loss2: (0.0000) | Acc: (69.00%) (9845/14208)
Epoch: 16 | Batch_idx: 120 |  Loss: (0.8664) |  Loss2: (0.0000) | Acc: (69.00%) (10748/15488)
Epoch: 16 | Batch_idx: 130 |  Loss: (0.8667) |  Loss2: (0.0000) | Acc: (69.00%) (11642/16768)
Epoch: 16 | Batch_idx: 140 |  Loss: (0.8662) |  Loss2: (0.0000) | Acc: (69.00%) (12527/18048)
Epoch: 16 | Batch_idx: 150 |  Loss: (0.8669) |  Loss2: (0.0000) | Acc: (69.00%) (13413/19328)
Epoch: 16 | Batch_idx: 160 |  Loss: (0.8658) |  Loss2: (0.0000) | Acc: (69.00%) (14307/20608)
Epoch: 16 | Batch_idx: 170 |  Loss: (0.8656) |  Loss2: (0.0000) | Acc: (69.00%) (15202/21888)
Epoch: 16 | Batch_idx: 180 |  Loss: (0.8650) |  Loss2: (0.0000) | Acc: (69.00%) (16095/23168)
Epoch: 16 | Batch_idx: 190 |  Loss: (0.8633) |  Loss2: (0.0000) | Acc: (69.00%) (17019/24448)
Epoch: 16 | Batch_idx: 200 |  Loss: (0.8621) |  Loss2: (0.0000) | Acc: (69.00%) (17906/25728)
Epoch: 16 | Batch_idx: 210 |  Loss: (0.8638) |  Loss2: (0.0000) | Acc: (69.00%) (18787/27008)
Epoch: 16 | Batch_idx: 220 |  Loss: (0.8647) |  Loss2: (0.0000) | Acc: (69.00%) (19668/28288)
Epoch: 16 | Batch_idx: 230 |  Loss: (0.8631) |  Loss2: (0.0000) | Acc: (69.00%) (20570/29568)
Epoch: 16 | Batch_idx: 240 |  Loss: (0.8643) |  Loss2: (0.0000) | Acc: (69.00%) (21461/30848)
Epoch: 16 | Batch_idx: 250 |  Loss: (0.8635) |  Loss2: (0.0000) | Acc: (69.00%) (22369/32128)
Epoch: 16 | Batch_idx: 260 |  Loss: (0.8614) |  Loss2: (0.0000) | Acc: (69.00%) (23286/33408)
Epoch: 16 | Batch_idx: 270 |  Loss: (0.8601) |  Loss2: (0.0000) | Acc: (69.00%) (24199/34688)
Epoch: 16 | Batch_idx: 280 |  Loss: (0.8611) |  Loss2: (0.0000) | Acc: (69.00%) (25071/35968)
Epoch: 16 | Batch_idx: 290 |  Loss: (0.8600) |  Loss2: (0.0000) | Acc: (69.00%) (25984/37248)
Epoch: 16 | Batch_idx: 300 |  Loss: (0.8597) |  Loss2: (0.0000) | Acc: (69.00%) (26870/38528)
Epoch: 16 | Batch_idx: 310 |  Loss: (0.8597) |  Loss2: (0.0000) | Acc: (69.00%) (27761/39808)
Epoch: 16 | Batch_idx: 320 |  Loss: (0.8604) |  Loss2: (0.0000) | Acc: (69.00%) (28621/41088)
Epoch: 16 | Batch_idx: 330 |  Loss: (0.8600) |  Loss2: (0.0000) | Acc: (69.00%) (29520/42368)
Epoch: 16 | Batch_idx: 340 |  Loss: (0.8601) |  Loss2: (0.0000) | Acc: (69.00%) (30411/43648)
Epoch: 16 | Batch_idx: 350 |  Loss: (0.8584) |  Loss2: (0.0000) | Acc: (69.00%) (31309/44928)
Epoch: 16 | Batch_idx: 360 |  Loss: (0.8567) |  Loss2: (0.0000) | Acc: (69.00%) (32232/46208)
Epoch: 16 | Batch_idx: 370 |  Loss: (0.8553) |  Loss2: (0.0000) | Acc: (69.00%) (33133/47488)
Epoch: 16 | Batch_idx: 380 |  Loss: (0.8542) |  Loss2: (0.0000) | Acc: (69.00%) (34051/48768)
Epoch: 16 | Batch_idx: 390 |  Loss: (0.8529) |  Loss2: (0.0000) | Acc: (69.00%) (34941/50000)
# TEST : Loss: (0.9219) | Acc: (67.00%) (6744/10000)
percent tensor([0.5129, 0.5198, 0.5104, 0.5133, 0.5125, 0.5200, 0.5163, 0.5134, 0.5147,
        0.5130, 0.5164, 0.5099, 0.5133, 0.5206, 0.5189, 0.5151],
       device='cuda:0') torch.Size([16])
percent tensor([0.5139, 0.5158, 0.5102, 0.5129, 0.5123, 0.5202, 0.5165, 0.5147, 0.5121,
        0.5130, 0.5125, 0.5130, 0.5121, 0.5165, 0.5193, 0.5159],
       device='cuda:0') torch.Size([16])
percent tensor([0.5192, 0.5158, 0.5185, 0.5203, 0.5156, 0.5118, 0.5174, 0.5197, 0.5189,
        0.5186, 0.5192, 0.5192, 0.5181, 0.5241, 0.5137, 0.5205],
       device='cuda:0') torch.Size([16])
percent tensor([0.5243, 0.5208, 0.5232, 0.5249, 0.5242, 0.5292, 0.5223, 0.5236, 0.5210,
        0.5202, 0.5207, 0.5215, 0.5203, 0.5223, 0.5269, 0.5231],
       device='cuda:0') torch.Size([16])
percent tensor([0.4831, 0.4896, 0.4588, 0.4615, 0.4661, 0.4777, 0.4860, 0.4664, 0.4865,
        0.4714, 0.4852, 0.4689, 0.4828, 0.4928, 0.4934, 0.4752],
       device='cuda:0') torch.Size([16])
percent tensor([0.4963, 0.4957, 0.5035, 0.5047, 0.5007, 0.4994, 0.4977, 0.4936, 0.5058,
        0.4947, 0.5003, 0.4993, 0.4991, 0.5035, 0.4863, 0.4902],
       device='cuda:0') torch.Size([16])
percent tensor([0.5119, 0.5148, 0.5537, 0.5518, 0.5584, 0.4993, 0.5338, 0.5693, 0.5208,
        0.5281, 0.5102, 0.5466, 0.5078, 0.5174, 0.5284, 0.5193],
       device='cuda:0') torch.Size([16])
percent tensor([0.8184, 0.7857, 0.8633, 0.8368, 0.8641, 0.8089, 0.8348, 0.8993, 0.7777,
        0.8466, 0.7811, 0.8490, 0.7850, 0.8189, 0.8376, 0.8583],
       device='cuda:0') torch.Size([16])
Epoch: 17 | Batch_idx: 0 |  Loss: (0.7330) |  Loss2: (0.0000) | Acc: (75.00%) (96/128)
Epoch: 17 | Batch_idx: 10 |  Loss: (0.7768) |  Loss2: (0.0000) | Acc: (73.00%) (1032/1408)
Epoch: 17 | Batch_idx: 20 |  Loss: (0.7996) |  Loss2: (0.0000) | Acc: (72.00%) (1936/2688)
Epoch: 17 | Batch_idx: 30 |  Loss: (0.8108) |  Loss2: (0.0000) | Acc: (71.00%) (2829/3968)
Epoch: 17 | Batch_idx: 40 |  Loss: (0.8097) |  Loss2: (0.0000) | Acc: (71.00%) (3749/5248)
Epoch: 17 | Batch_idx: 50 |  Loss: (0.8168) |  Loss2: (0.0000) | Acc: (71.00%) (4640/6528)
Epoch: 17 | Batch_idx: 60 |  Loss: (0.8112) |  Loss2: (0.0000) | Acc: (70.00%) (5541/7808)
Epoch: 17 | Batch_idx: 70 |  Loss: (0.8109) |  Loss2: (0.0000) | Acc: (70.00%) (6449/9088)
Epoch: 17 | Batch_idx: 80 |  Loss: (0.8130) |  Loss2: (0.0000) | Acc: (70.00%) (7356/10368)
Epoch: 17 | Batch_idx: 90 |  Loss: (0.8084) |  Loss2: (0.0000) | Acc: (71.00%) (8306/11648)
Epoch: 17 | Batch_idx: 100 |  Loss: (0.8061) |  Loss2: (0.0000) | Acc: (71.00%) (9200/12928)
Epoch: 17 | Batch_idx: 110 |  Loss: (0.8057) |  Loss2: (0.0000) | Acc: (71.00%) (10121/14208)
Epoch: 17 | Batch_idx: 120 |  Loss: (0.8069) |  Loss2: (0.0000) | Acc: (71.00%) (11025/15488)
Epoch: 17 | Batch_idx: 130 |  Loss: (0.8109) |  Loss2: (0.0000) | Acc: (71.00%) (11917/16768)
Epoch: 17 | Batch_idx: 140 |  Loss: (0.8092) |  Loss2: (0.0000) | Acc: (71.00%) (12848/18048)
Epoch: 17 | Batch_idx: 150 |  Loss: (0.8084) |  Loss2: (0.0000) | Acc: (71.00%) (13753/19328)
Epoch: 17 | Batch_idx: 160 |  Loss: (0.8081) |  Loss2: (0.0000) | Acc: (71.00%) (14662/20608)
Epoch: 17 | Batch_idx: 170 |  Loss: (0.8108) |  Loss2: (0.0000) | Acc: (71.00%) (15562/21888)
Epoch: 17 | Batch_idx: 180 |  Loss: (0.8095) |  Loss2: (0.0000) | Acc: (71.00%) (16485/23168)
Epoch: 17 | Batch_idx: 190 |  Loss: (0.8092) |  Loss2: (0.0000) | Acc: (71.00%) (17401/24448)
Epoch: 17 | Batch_idx: 200 |  Loss: (0.8096) |  Loss2: (0.0000) | Acc: (71.00%) (18325/25728)
Epoch: 17 | Batch_idx: 210 |  Loss: (0.8085) |  Loss2: (0.0000) | Acc: (71.00%) (19245/27008)
Epoch: 17 | Batch_idx: 220 |  Loss: (0.8079) |  Loss2: (0.0000) | Acc: (71.00%) (20166/28288)
Epoch: 17 | Batch_idx: 230 |  Loss: (0.8076) |  Loss2: (0.0000) | Acc: (71.00%) (21080/29568)
Epoch: 17 | Batch_idx: 240 |  Loss: (0.8069) |  Loss2: (0.0000) | Acc: (71.00%) (21998/30848)
Epoch: 17 | Batch_idx: 250 |  Loss: (0.8071) |  Loss2: (0.0000) | Acc: (71.00%) (22902/32128)
Epoch: 17 | Batch_idx: 260 |  Loss: (0.8073) |  Loss2: (0.0000) | Acc: (71.00%) (23829/33408)
Epoch: 17 | Batch_idx: 270 |  Loss: (0.8076) |  Loss2: (0.0000) | Acc: (71.00%) (24739/34688)
Epoch: 17 | Batch_idx: 280 |  Loss: (0.8087) |  Loss2: (0.0000) | Acc: (71.00%) (25652/35968)
Epoch: 17 | Batch_idx: 290 |  Loss: (0.8087) |  Loss2: (0.0000) | Acc: (71.00%) (26566/37248)
Epoch: 17 | Batch_idx: 300 |  Loss: (0.8107) |  Loss2: (0.0000) | Acc: (71.00%) (27464/38528)
Epoch: 17 | Batch_idx: 310 |  Loss: (0.8109) |  Loss2: (0.0000) | Acc: (71.00%) (28383/39808)
Epoch: 17 | Batch_idx: 320 |  Loss: (0.8110) |  Loss2: (0.0000) | Acc: (71.00%) (29309/41088)
Epoch: 17 | Batch_idx: 330 |  Loss: (0.8102) |  Loss2: (0.0000) | Acc: (71.00%) (30236/42368)
Epoch: 17 | Batch_idx: 340 |  Loss: (0.8091) |  Loss2: (0.0000) | Acc: (71.00%) (31169/43648)
Epoch: 17 | Batch_idx: 350 |  Loss: (0.8087) |  Loss2: (0.0000) | Acc: (71.00%) (32100/44928)
Epoch: 17 | Batch_idx: 360 |  Loss: (0.8073) |  Loss2: (0.0000) | Acc: (71.00%) (33022/46208)
Epoch: 17 | Batch_idx: 370 |  Loss: (0.8059) |  Loss2: (0.0000) | Acc: (71.00%) (33973/47488)
Epoch: 17 | Batch_idx: 380 |  Loss: (0.8059) |  Loss2: (0.0000) | Acc: (71.00%) (34889/48768)
Epoch: 17 | Batch_idx: 390 |  Loss: (0.8056) |  Loss2: (0.0000) | Acc: (71.00%) (35788/50000)
# TEST : Loss: (0.9492) | Acc: (66.00%) (6685/10000)
percent tensor([0.5131, 0.5192, 0.5087, 0.5132, 0.5111, 0.5202, 0.5156, 0.5131, 0.5141,
        0.5126, 0.5165, 0.5083, 0.5136, 0.5194, 0.5187, 0.5153],
       device='cuda:0') torch.Size([16])
percent tensor([0.5152, 0.5167, 0.5116, 0.5121, 0.5142, 0.5216, 0.5175, 0.5152, 0.5139,
        0.5134, 0.5138, 0.5137, 0.5134, 0.5176, 0.5196, 0.5164],
       device='cuda:0') torch.Size([16])
percent tensor([0.5196, 0.5151, 0.5198, 0.5195, 0.5160, 0.5116, 0.5164, 0.5193, 0.5181,
        0.5184, 0.5178, 0.5205, 0.5173, 0.5220, 0.5142, 0.5202],
       device='cuda:0') torch.Size([16])
percent tensor([0.5253, 0.5197, 0.5225, 0.5235, 0.5241, 0.5302, 0.5217, 0.5237, 0.5206,
        0.5200, 0.5206, 0.5215, 0.5209, 0.5197, 0.5281, 0.5235],
       device='cuda:0') torch.Size([16])
percent tensor([0.4870, 0.4892, 0.4662, 0.4650, 0.4729, 0.4798, 0.4878, 0.4713, 0.4902,
        0.4738, 0.4870, 0.4735, 0.4864, 0.4909, 0.4954, 0.4783],
       device='cuda:0') torch.Size([16])
percent tensor([0.4971, 0.4944, 0.5000, 0.5037, 0.4980, 0.5023, 0.4951, 0.4936, 0.5043,
        0.4956, 0.4994, 0.4965, 0.4988, 0.5024, 0.4871, 0.4910],
       device='cuda:0') torch.Size([16])
percent tensor([0.5063, 0.5159, 0.5452, 0.5431, 0.5501, 0.4936, 0.5259, 0.5585, 0.5250,
        0.5231, 0.5129, 0.5406, 0.5070, 0.5218, 0.5230, 0.5160],
       device='cuda:0') torch.Size([16])
percent tensor([0.7963, 0.7944, 0.8610, 0.8255, 0.8567, 0.7863, 0.8134, 0.8745, 0.8069,
        0.8336, 0.7987, 0.8293, 0.8082, 0.8249, 0.8186, 0.8371],
       device='cuda:0') torch.Size([16])
Epoch: 18 | Batch_idx: 0 |  Loss: (0.6834) |  Loss2: (0.0000) | Acc: (73.00%) (94/128)
Epoch: 18 | Batch_idx: 10 |  Loss: (0.7968) |  Loss2: (0.0000) | Acc: (72.00%) (1015/1408)
Epoch: 18 | Batch_idx: 20 |  Loss: (0.7735) |  Loss2: (0.0000) | Acc: (72.00%) (1952/2688)
Epoch: 18 | Batch_idx: 30 |  Loss: (0.7804) |  Loss2: (0.0000) | Acc: (72.00%) (2876/3968)
Epoch: 18 | Batch_idx: 40 |  Loss: (0.7739) |  Loss2: (0.0000) | Acc: (72.00%) (3821/5248)
Epoch: 18 | Batch_idx: 50 |  Loss: (0.7728) |  Loss2: (0.0000) | Acc: (72.00%) (4743/6528)
Epoch: 18 | Batch_idx: 60 |  Loss: (0.7688) |  Loss2: (0.0000) | Acc: (72.00%) (5680/7808)
Epoch: 18 | Batch_idx: 70 |  Loss: (0.7674) |  Loss2: (0.0000) | Acc: (72.00%) (6614/9088)
Epoch: 18 | Batch_idx: 80 |  Loss: (0.7678) |  Loss2: (0.0000) | Acc: (72.00%) (7536/10368)
Epoch: 18 | Batch_idx: 90 |  Loss: (0.7665) |  Loss2: (0.0000) | Acc: (72.00%) (8486/11648)
Epoch: 18 | Batch_idx: 100 |  Loss: (0.7729) |  Loss2: (0.0000) | Acc: (72.00%) (9400/12928)
Epoch: 18 | Batch_idx: 110 |  Loss: (0.7713) |  Loss2: (0.0000) | Acc: (72.00%) (10351/14208)
Epoch: 18 | Batch_idx: 120 |  Loss: (0.7678) |  Loss2: (0.0000) | Acc: (72.00%) (11295/15488)
Epoch: 18 | Batch_idx: 130 |  Loss: (0.7631) |  Loss2: (0.0000) | Acc: (73.00%) (12268/16768)
Epoch: 18 | Batch_idx: 140 |  Loss: (0.7633) |  Loss2: (0.0000) | Acc: (73.00%) (13199/18048)
Epoch: 18 | Batch_idx: 150 |  Loss: (0.7627) |  Loss2: (0.0000) | Acc: (73.00%) (14139/19328)
Epoch: 18 | Batch_idx: 160 |  Loss: (0.7663) |  Loss2: (0.0000) | Acc: (72.00%) (15036/20608)
Epoch: 18 | Batch_idx: 170 |  Loss: (0.7683) |  Loss2: (0.0000) | Acc: (72.00%) (15952/21888)
Epoch: 18 | Batch_idx: 180 |  Loss: (0.7692) |  Loss2: (0.0000) | Acc: (72.00%) (16882/23168)
Epoch: 18 | Batch_idx: 190 |  Loss: (0.7687) |  Loss2: (0.0000) | Acc: (72.00%) (17811/24448)
Epoch: 18 | Batch_idx: 200 |  Loss: (0.7701) |  Loss2: (0.0000) | Acc: (72.00%) (18729/25728)
Epoch: 18 | Batch_idx: 210 |  Loss: (0.7692) |  Loss2: (0.0000) | Acc: (72.00%) (19672/27008)
Epoch: 18 | Batch_idx: 220 |  Loss: (0.7701) |  Loss2: (0.0000) | Acc: (72.00%) (20600/28288)
Epoch: 18 | Batch_idx: 230 |  Loss: (0.7715) |  Loss2: (0.0000) | Acc: (72.00%) (21519/29568)
Epoch: 18 | Batch_idx: 240 |  Loss: (0.7702) |  Loss2: (0.0000) | Acc: (72.00%) (22455/30848)
Epoch: 18 | Batch_idx: 250 |  Loss: (0.7708) |  Loss2: (0.0000) | Acc: (72.00%) (23386/32128)
Epoch: 18 | Batch_idx: 260 |  Loss: (0.7708) |  Loss2: (0.0000) | Acc: (72.00%) (24315/33408)
Epoch: 18 | Batch_idx: 270 |  Loss: (0.7708) |  Loss2: (0.0000) | Acc: (72.00%) (25249/34688)
Epoch: 18 | Batch_idx: 280 |  Loss: (0.7698) |  Loss2: (0.0000) | Acc: (72.00%) (26202/35968)
Epoch: 18 | Batch_idx: 290 |  Loss: (0.7684) |  Loss2: (0.0000) | Acc: (72.00%) (27147/37248)
Epoch: 18 | Batch_idx: 300 |  Loss: (0.7667) |  Loss2: (0.0000) | Acc: (72.00%) (28110/38528)
Epoch: 18 | Batch_idx: 310 |  Loss: (0.7672) |  Loss2: (0.0000) | Acc: (72.00%) (29052/39808)
Epoch: 18 | Batch_idx: 320 |  Loss: (0.7678) |  Loss2: (0.0000) | Acc: (72.00%) (29976/41088)
Epoch: 18 | Batch_idx: 330 |  Loss: (0.7684) |  Loss2: (0.0000) | Acc: (72.00%) (30899/42368)
Epoch: 18 | Batch_idx: 340 |  Loss: (0.7666) |  Loss2: (0.0000) | Acc: (73.00%) (31871/43648)
Epoch: 18 | Batch_idx: 350 |  Loss: (0.7664) |  Loss2: (0.0000) | Acc: (73.00%) (32806/44928)
Epoch: 18 | Batch_idx: 360 |  Loss: (0.7664) |  Loss2: (0.0000) | Acc: (72.00%) (33729/46208)
Epoch: 18 | Batch_idx: 370 |  Loss: (0.7656) |  Loss2: (0.0000) | Acc: (73.00%) (34688/47488)
Epoch: 18 | Batch_idx: 380 |  Loss: (0.7663) |  Loss2: (0.0000) | Acc: (72.00%) (35592/48768)
Epoch: 18 | Batch_idx: 390 |  Loss: (0.7683) |  Loss2: (0.0000) | Acc: (72.00%) (36435/50000)
# TEST : Loss: (0.8277) | Acc: (71.00%) (7104/10000)
percent tensor([0.5126, 0.5195, 0.5092, 0.5133, 0.5117, 0.5203, 0.5160, 0.5130, 0.5139,
        0.5126, 0.5159, 0.5091, 0.5131, 0.5199, 0.5187, 0.5147],
       device='cuda:0') torch.Size([16])
percent tensor([0.5142, 0.5142, 0.5121, 0.5120, 0.5142, 0.5197, 0.5165, 0.5150, 0.5125,
        0.5131, 0.5122, 0.5148, 0.5124, 0.5147, 0.5181, 0.5156],
       device='cuda:0') torch.Size([16])
percent tensor([0.5207, 0.5185, 0.5192, 0.5199, 0.5167, 0.5116, 0.5189, 0.5220, 0.5188,
        0.5201, 0.5198, 0.5212, 0.5186, 0.5254, 0.5162, 0.5217],
       device='cuda:0') torch.Size([16])
percent tensor([0.5254, 0.5207, 0.5222, 0.5234, 0.5235, 0.5291, 0.5229, 0.5248, 0.5210,
        0.5211, 0.5210, 0.5235, 0.5222, 0.5212, 0.5284, 0.5238],
       device='cuda:0') torch.Size([16])
percent tensor([0.4853, 0.4849, 0.4736, 0.4694, 0.4780, 0.4793, 0.4857, 0.4717, 0.4886,
        0.4684, 0.4837, 0.4753, 0.4826, 0.4892, 0.4925, 0.4738],
       device='cuda:0') torch.Size([16])
percent tensor([0.4935, 0.4931, 0.4918, 0.5002, 0.4908, 0.5010, 0.4909, 0.4868, 0.5018,
        0.4907, 0.4978, 0.4894, 0.4961, 0.5052, 0.4855, 0.4893],
       device='cuda:0') torch.Size([16])
percent tensor([0.5080, 0.5163, 0.5374, 0.5409, 0.5467, 0.4973, 0.5288, 0.5634, 0.5213,
        0.5260, 0.5128, 0.5458, 0.5071, 0.5235, 0.5238, 0.5179],
       device='cuda:0') torch.Size([16])
percent tensor([0.8110, 0.7776, 0.8558, 0.8331, 0.8587, 0.7890, 0.8371, 0.9002, 0.7774,
        0.8391, 0.7764, 0.8686, 0.7735, 0.7879, 0.8214, 0.8480],
       device='cuda:0') torch.Size([16])
Epoch: 19 | Batch_idx: 0 |  Loss: (0.7244) |  Loss2: (0.0000) | Acc: (72.00%) (93/128)
Epoch: 19 | Batch_idx: 10 |  Loss: (0.7275) |  Loss2: (0.0000) | Acc: (74.00%) (1046/1408)
Epoch: 19 | Batch_idx: 20 |  Loss: (0.7380) |  Loss2: (0.0000) | Acc: (74.00%) (2006/2688)
Epoch: 19 | Batch_idx: 30 |  Loss: (0.7267) |  Loss2: (0.0000) | Acc: (74.00%) (2958/3968)
Epoch: 19 | Batch_idx: 40 |  Loss: (0.7246) |  Loss2: (0.0000) | Acc: (74.00%) (3932/5248)
Epoch: 19 | Batch_idx: 50 |  Loss: (0.7294) |  Loss2: (0.0000) | Acc: (74.00%) (4881/6528)
Epoch: 19 | Batch_idx: 60 |  Loss: (0.7263) |  Loss2: (0.0000) | Acc: (74.00%) (5854/7808)
Epoch: 19 | Batch_idx: 70 |  Loss: (0.7321) |  Loss2: (0.0000) | Acc: (74.00%) (6786/9088)
Epoch: 19 | Batch_idx: 80 |  Loss: (0.7287) |  Loss2: (0.0000) | Acc: (74.00%) (7752/10368)
Epoch: 19 | Batch_idx: 90 |  Loss: (0.7290) |  Loss2: (0.0000) | Acc: (74.00%) (8704/11648)
Epoch: 19 | Batch_idx: 100 |  Loss: (0.7295) |  Loss2: (0.0000) | Acc: (74.00%) (9659/12928)
Epoch: 19 | Batch_idx: 110 |  Loss: (0.7287) |  Loss2: (0.0000) | Acc: (74.00%) (10609/14208)
Epoch: 19 | Batch_idx: 120 |  Loss: (0.7328) |  Loss2: (0.0000) | Acc: (74.00%) (11539/15488)
Epoch: 19 | Batch_idx: 130 |  Loss: (0.7346) |  Loss2: (0.0000) | Acc: (74.00%) (12467/16768)
Epoch: 19 | Batch_idx: 140 |  Loss: (0.7368) |  Loss2: (0.0000) | Acc: (74.00%) (13418/18048)
Epoch: 19 | Batch_idx: 150 |  Loss: (0.7349) |  Loss2: (0.0000) | Acc: (74.00%) (14381/19328)
Epoch: 19 | Batch_idx: 160 |  Loss: (0.7332) |  Loss2: (0.0000) | Acc: (74.00%) (15337/20608)
Epoch: 19 | Batch_idx: 170 |  Loss: (0.7311) |  Loss2: (0.0000) | Acc: (74.00%) (16309/21888)
Epoch: 19 | Batch_idx: 180 |  Loss: (0.7305) |  Loss2: (0.0000) | Acc: (74.00%) (17262/23168)
Epoch: 19 | Batch_idx: 190 |  Loss: (0.7283) |  Loss2: (0.0000) | Acc: (74.00%) (18230/24448)
Epoch: 19 | Batch_idx: 200 |  Loss: (0.7280) |  Loss2: (0.0000) | Acc: (74.00%) (19185/25728)
Epoch: 19 | Batch_idx: 210 |  Loss: (0.7276) |  Loss2: (0.0000) | Acc: (74.00%) (20160/27008)
Epoch: 19 | Batch_idx: 220 |  Loss: (0.7289) |  Loss2: (0.0000) | Acc: (74.00%) (21113/28288)
Epoch: 19 | Batch_idx: 230 |  Loss: (0.7288) |  Loss2: (0.0000) | Acc: (74.00%) (22056/29568)
Epoch: 19 | Batch_idx: 240 |  Loss: (0.7299) |  Loss2: (0.0000) | Acc: (74.00%) (23009/30848)
Epoch: 19 | Batch_idx: 250 |  Loss: (0.7290) |  Loss2: (0.0000) | Acc: (74.00%) (23974/32128)
Epoch: 19 | Batch_idx: 260 |  Loss: (0.7302) |  Loss2: (0.0000) | Acc: (74.00%) (24919/33408)
Epoch: 19 | Batch_idx: 270 |  Loss: (0.7311) |  Loss2: (0.0000) | Acc: (74.00%) (25865/34688)
Epoch: 19 | Batch_idx: 280 |  Loss: (0.7305) |  Loss2: (0.0000) | Acc: (74.00%) (26816/35968)
Epoch: 19 | Batch_idx: 290 |  Loss: (0.7296) |  Loss2: (0.0000) | Acc: (74.00%) (27779/37248)
Epoch: 19 | Batch_idx: 300 |  Loss: (0.7294) |  Loss2: (0.0000) | Acc: (74.00%) (28736/38528)
Epoch: 19 | Batch_idx: 310 |  Loss: (0.7309) |  Loss2: (0.0000) | Acc: (74.00%) (29664/39808)
Epoch: 19 | Batch_idx: 320 |  Loss: (0.7306) |  Loss2: (0.0000) | Acc: (74.00%) (30602/41088)
Epoch: 19 | Batch_idx: 330 |  Loss: (0.7314) |  Loss2: (0.0000) | Acc: (74.00%) (31551/42368)
Epoch: 19 | Batch_idx: 340 |  Loss: (0.7307) |  Loss2: (0.0000) | Acc: (74.00%) (32519/43648)
Epoch: 19 | Batch_idx: 350 |  Loss: (0.7316) |  Loss2: (0.0000) | Acc: (74.00%) (33455/44928)
Epoch: 19 | Batch_idx: 360 |  Loss: (0.7319) |  Loss2: (0.0000) | Acc: (74.00%) (34398/46208)
Epoch: 19 | Batch_idx: 370 |  Loss: (0.7317) |  Loss2: (0.0000) | Acc: (74.00%) (35356/47488)
Epoch: 19 | Batch_idx: 380 |  Loss: (0.7316) |  Loss2: (0.0000) | Acc: (74.00%) (36307/48768)
Epoch: 19 | Batch_idx: 390 |  Loss: (0.7307) |  Loss2: (0.0000) | Acc: (74.00%) (37249/50000)
# TEST : Loss: (0.8309) | Acc: (70.00%) (7099/10000)
percent tensor([0.5133, 0.5194, 0.5100, 0.5138, 0.5121, 0.5200, 0.5160, 0.5134, 0.5146,
        0.5127, 0.5164, 0.5094, 0.5139, 0.5198, 0.5188, 0.5153],
       device='cuda:0') torch.Size([16])
percent tensor([0.5147, 0.5158, 0.5099, 0.5124, 0.5124, 0.5198, 0.5169, 0.5142, 0.5131,
        0.5133, 0.5132, 0.5128, 0.5129, 0.5173, 0.5189, 0.5160],
       device='cuda:0') torch.Size([16])
percent tensor([0.5201, 0.5172, 0.5204, 0.5192, 0.5180, 0.5113, 0.5197, 0.5195, 0.5211,
        0.5200, 0.5193, 0.5240, 0.5180, 0.5269, 0.5158, 0.5203],
       device='cuda:0') torch.Size([16])
percent tensor([0.5257, 0.5210, 0.5228, 0.5238, 0.5236, 0.5296, 0.5242, 0.5234, 0.5221,
        0.5210, 0.5212, 0.5229, 0.5214, 0.5210, 0.5285, 0.5244],
       device='cuda:0') torch.Size([16])
percent tensor([0.4860, 0.4924, 0.4661, 0.4685, 0.4719, 0.4808, 0.4900, 0.4697, 0.4898,
        0.4758, 0.4860, 0.4750, 0.4861, 0.4972, 0.4955, 0.4768],
       device='cuda:0') torch.Size([16])
percent tensor([0.4969, 0.4948, 0.5038, 0.5019, 0.4987, 0.5036, 0.4936, 0.4920, 0.5063,
        0.4966, 0.4996, 0.4991, 0.4980, 0.5043, 0.4883, 0.4899],
       device='cuda:0') torch.Size([16])
percent tensor([0.5124, 0.5167, 0.5425, 0.5450, 0.5558, 0.5037, 0.5288, 0.5622, 0.5245,
        0.5212, 0.5157, 0.5404, 0.5069, 0.5210, 0.5260, 0.5163],
       device='cuda:0') torch.Size([16])
percent tensor([0.8022, 0.7951, 0.8404, 0.8266, 0.8603, 0.7798, 0.8166, 0.8927, 0.7877,
        0.8450, 0.8046, 0.8235, 0.7723, 0.7991, 0.8136, 0.8393],
       device='cuda:0') torch.Size([16])
Epoch: 20 | Batch_idx: 0 |  Loss: (0.6610) |  Loss2: (0.0000) | Acc: (77.00%) (99/128)
Epoch: 20 | Batch_idx: 10 |  Loss: (0.7305) |  Loss2: (0.0000) | Acc: (75.00%) (1060/1408)
Epoch: 20 | Batch_idx: 20 |  Loss: (0.7343) |  Loss2: (0.0000) | Acc: (75.00%) (2023/2688)
Epoch: 20 | Batch_idx: 30 |  Loss: (0.7091) |  Loss2: (0.0000) | Acc: (76.00%) (3030/3968)
Epoch: 20 | Batch_idx: 40 |  Loss: (0.7058) |  Loss2: (0.0000) | Acc: (76.00%) (3994/5248)
Epoch: 20 | Batch_idx: 50 |  Loss: (0.7076) |  Loss2: (0.0000) | Acc: (75.00%) (4956/6528)
Epoch: 20 | Batch_idx: 60 |  Loss: (0.7046) |  Loss2: (0.0000) | Acc: (75.00%) (5927/7808)
Epoch: 20 | Batch_idx: 70 |  Loss: (0.7116) |  Loss2: (0.0000) | Acc: (75.00%) (6872/9088)
Epoch: 20 | Batch_idx: 80 |  Loss: (0.7102) |  Loss2: (0.0000) | Acc: (75.00%) (7838/10368)
Epoch: 20 | Batch_idx: 90 |  Loss: (0.7072) |  Loss2: (0.0000) | Acc: (75.00%) (8814/11648)
Epoch: 20 | Batch_idx: 100 |  Loss: (0.7054) |  Loss2: (0.0000) | Acc: (75.00%) (9772/12928)
Epoch: 20 | Batch_idx: 110 |  Loss: (0.7031) |  Loss2: (0.0000) | Acc: (75.00%) (10755/14208)
Epoch: 20 | Batch_idx: 120 |  Loss: (0.7041) |  Loss2: (0.0000) | Acc: (75.00%) (11699/15488)
Epoch: 20 | Batch_idx: 130 |  Loss: (0.7042) |  Loss2: (0.0000) | Acc: (75.00%) (12658/16768)
Epoch: 20 | Batch_idx: 140 |  Loss: (0.7060) |  Loss2: (0.0000) | Acc: (75.00%) (13601/18048)
Epoch: 20 | Batch_idx: 150 |  Loss: (0.7025) |  Loss2: (0.0000) | Acc: (75.00%) (14597/19328)
Epoch: 20 | Batch_idx: 160 |  Loss: (0.7031) |  Loss2: (0.0000) | Acc: (75.00%) (15549/20608)
Epoch: 20 | Batch_idx: 170 |  Loss: (0.7025) |  Loss2: (0.0000) | Acc: (75.00%) (16515/21888)
Epoch: 20 | Batch_idx: 180 |  Loss: (0.7021) |  Loss2: (0.0000) | Acc: (75.00%) (17500/23168)
Epoch: 20 | Batch_idx: 190 |  Loss: (0.7038) |  Loss2: (0.0000) | Acc: (75.00%) (18463/24448)
Epoch: 20 | Batch_idx: 200 |  Loss: (0.7029) |  Loss2: (0.0000) | Acc: (75.00%) (19434/25728)
Epoch: 20 | Batch_idx: 210 |  Loss: (0.7049) |  Loss2: (0.0000) | Acc: (75.00%) (20385/27008)
Epoch: 20 | Batch_idx: 220 |  Loss: (0.7056) |  Loss2: (0.0000) | Acc: (75.00%) (21339/28288)
Epoch: 20 | Batch_idx: 230 |  Loss: (0.7029) |  Loss2: (0.0000) | Acc: (75.00%) (22348/29568)
Epoch: 20 | Batch_idx: 240 |  Loss: (0.7040) |  Loss2: (0.0000) | Acc: (75.00%) (23313/30848)
Epoch: 20 | Batch_idx: 250 |  Loss: (0.7027) |  Loss2: (0.0000) | Acc: (75.00%) (24288/32128)
Epoch: 20 | Batch_idx: 260 |  Loss: (0.7027) |  Loss2: (0.0000) | Acc: (75.00%) (25262/33408)
Epoch: 20 | Batch_idx: 270 |  Loss: (0.7015) |  Loss2: (0.0000) | Acc: (75.00%) (26222/34688)
Epoch: 20 | Batch_idx: 280 |  Loss: (0.7007) |  Loss2: (0.0000) | Acc: (75.00%) (27190/35968)
Epoch: 20 | Batch_idx: 290 |  Loss: (0.7012) |  Loss2: (0.0000) | Acc: (75.00%) (28161/37248)
Epoch: 20 | Batch_idx: 300 |  Loss: (0.7008) |  Loss2: (0.0000) | Acc: (75.00%) (29133/38528)
Epoch: 20 | Batch_idx: 310 |  Loss: (0.7001) |  Loss2: (0.0000) | Acc: (75.00%) (30097/39808)
Epoch: 20 | Batch_idx: 320 |  Loss: (0.6982) |  Loss2: (0.0000) | Acc: (75.00%) (31088/41088)
Epoch: 20 | Batch_idx: 330 |  Loss: (0.6992) |  Loss2: (0.0000) | Acc: (75.00%) (32048/42368)
Epoch: 20 | Batch_idx: 340 |  Loss: (0.6996) |  Loss2: (0.0000) | Acc: (75.00%) (33027/43648)
Epoch: 20 | Batch_idx: 350 |  Loss: (0.6999) |  Loss2: (0.0000) | Acc: (75.00%) (33996/44928)
Epoch: 20 | Batch_idx: 360 |  Loss: (0.7012) |  Loss2: (0.0000) | Acc: (75.00%) (34924/46208)
Epoch: 20 | Batch_idx: 370 |  Loss: (0.7005) |  Loss2: (0.0000) | Acc: (75.00%) (35899/47488)
Epoch: 20 | Batch_idx: 380 |  Loss: (0.7007) |  Loss2: (0.0000) | Acc: (75.00%) (36874/48768)
Epoch: 20 | Batch_idx: 390 |  Loss: (0.6993) |  Loss2: (0.0000) | Acc: (75.00%) (37829/50000)
=> saving checkpoint 'drive/app/torch/save_Schedule/checkpoint_020.pth.tar'
# TEST : Loss: (0.9151) | Acc: (68.00%) (6885/10000)
percent tensor([0.5137, 0.5185, 0.5105, 0.5134, 0.5130, 0.5205, 0.5160, 0.5132, 0.5146,
        0.5126, 0.5163, 0.5102, 0.5141, 0.5187, 0.5182, 0.5149],
       device='cuda:0') torch.Size([16])
percent tensor([0.5143, 0.5143, 0.5104, 0.5124, 0.5122, 0.5197, 0.5157, 0.5141, 0.5120,
        0.5124, 0.5124, 0.5123, 0.5121, 0.5149, 0.5185, 0.5154],
       device='cuda:0') torch.Size([16])
percent tensor([0.5198, 0.5184, 0.5191, 0.5193, 0.5176, 0.5121, 0.5189, 0.5192, 0.5195,
        0.5195, 0.5191, 0.5216, 0.5181, 0.5255, 0.5165, 0.5204],
       device='cuda:0') torch.Size([16])
percent tensor([0.5255, 0.5205, 0.5226, 0.5251, 0.5241, 0.5289, 0.5227, 0.5255, 0.5214,
        0.5208, 0.5212, 0.5224, 0.5215, 0.5214, 0.5280, 0.5242],
       device='cuda:0') torch.Size([16])
percent tensor([0.4839, 0.4866, 0.4717, 0.4673, 0.4765, 0.4793, 0.4878, 0.4714, 0.4888,
        0.4714, 0.4835, 0.4750, 0.4834, 0.4904, 0.4913, 0.4742],
       device='cuda:0') torch.Size([16])
percent tensor([0.4935, 0.4957, 0.4970, 0.5000, 0.4958, 0.5027, 0.4949, 0.4906, 0.5049,
        0.4969, 0.4992, 0.4923, 0.4980, 0.5077, 0.4858, 0.4920],
       device='cuda:0') torch.Size([16])
percent tensor([0.5121, 0.5144, 0.5519, 0.5499, 0.5617, 0.5000, 0.5339, 0.5673, 0.5256,
        0.5218, 0.5143, 0.5555, 0.5065, 0.5195, 0.5260, 0.5152],
       device='cuda:0') torch.Size([16])
percent tensor([0.8010, 0.7815, 0.8803, 0.8549, 0.8795, 0.7675, 0.8163, 0.9140, 0.8108,
        0.8565, 0.8090, 0.8913, 0.7744, 0.7926, 0.8343, 0.8301],
       device='cuda:0') torch.Size([16])
False Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=128, out_features=16, bias=False)
True Linear(in_features=16, out_features=2, bias=False)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=128, out_features=16, bias=False)
True Linear(in_features=16, out_features=2, bias=False)
False Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=256, out_features=32, bias=False)
True Linear(in_features=32, out_features=2, bias=False)
False Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=256, out_features=32, bias=False)
True Linear(in_features=32, out_features=2, bias=False)
False Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=512, out_features=64, bias=False)
True Linear(in_features=64, out_features=2, bias=False)
False Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=512, out_features=64, bias=False)
True Linear(in_features=64, out_features=2, bias=False)
False Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1024, out_features=128, bias=False)
True Linear(in_features=128, out_features=2, bias=False)
False Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1024, out_features=128, bias=False)
True Linear(in_features=128, out_features=2, bias=False)
False Linear(in_features=512, out_features=10, bias=True)
Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 3, 3, 3]) tensor(172.7522, device='cuda:0')
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(781.6471, device='cuda:0')
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(787.5430, device='cuda:0')
Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([128, 64, 3, 3]) tensor(1535.4384, device='cuda:0')
Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([128, 64, 1, 1]) tensor(513.0586, device='cuda:0')
Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([128, 128, 3, 3]) tensor(2181.9990, device='cuda:0')
Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([256, 128, 3, 3]) tensor(4323.5347, device='cuda:0')
Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([256, 128, 1, 1]) tensor(1429.5914, device='cuda:0')
Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([256, 256, 3, 3]) tensor(6092.2070, device='cuda:0')
Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([512, 256, 3, 3]) tensor(12178.8574, device='cuda:0')
Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([512, 256, 1, 1]) tensor(4063.1492, device='cuda:0')
Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([512, 512, 3, 3]) tensor(17191.7637, device='cuda:0')
Epoch: 21 | Batch_idx: 0 |  Loss: (0.7378) |  Loss2: (0.0000) | Acc: (75.00%) (96/128)
Epoch: 21 | Batch_idx: 10 |  Loss: (0.7499) |  Loss2: (0.0000) | Acc: (74.00%) (1046/1408)
Epoch: 21 | Batch_idx: 20 |  Loss: (0.7990) |  Loss2: (0.0000) | Acc: (71.00%) (1934/2688)
Epoch: 21 | Batch_idx: 30 |  Loss: (0.8417) |  Loss2: (0.0000) | Acc: (70.00%) (2802/3968)
Epoch: 21 | Batch_idx: 40 |  Loss: (0.8638) |  Loss2: (0.0000) | Acc: (69.00%) (3661/5248)
Epoch: 21 | Batch_idx: 50 |  Loss: (0.8747) |  Loss2: (0.0000) | Acc: (69.00%) (4510/6528)
Epoch: 21 | Batch_idx: 60 |  Loss: (0.8778) |  Loss2: (0.0000) | Acc: (69.00%) (5402/7808)
Epoch: 21 | Batch_idx: 70 |  Loss: (0.8844) |  Loss2: (0.0000) | Acc: (69.00%) (6271/9088)
Epoch: 21 | Batch_idx: 80 |  Loss: (0.8784) |  Loss2: (0.0000) | Acc: (69.00%) (7191/10368)
Epoch: 21 | Batch_idx: 90 |  Loss: (0.8809) |  Loss2: (0.0000) | Acc: (69.00%) (8075/11648)
Epoch: 21 | Batch_idx: 100 |  Loss: (0.8812) |  Loss2: (0.0000) | Acc: (69.00%) (8959/12928)
Epoch: 21 | Batch_idx: 110 |  Loss: (0.8740) |  Loss2: (0.0000) | Acc: (69.00%) (9876/14208)
Epoch: 21 | Batch_idx: 120 |  Loss: (0.8727) |  Loss2: (0.0000) | Acc: (69.00%) (10792/15488)
Epoch: 21 | Batch_idx: 130 |  Loss: (0.8651) |  Loss2: (0.0000) | Acc: (69.00%) (11720/16768)
Epoch: 21 | Batch_idx: 140 |  Loss: (0.8607) |  Loss2: (0.0000) | Acc: (70.00%) (12636/18048)
Epoch: 21 | Batch_idx: 150 |  Loss: (0.8544) |  Loss2: (0.0000) | Acc: (70.00%) (13589/19328)
Epoch: 21 | Batch_idx: 160 |  Loss: (0.8522) |  Loss2: (0.0000) | Acc: (70.00%) (14496/20608)
Epoch: 21 | Batch_idx: 170 |  Loss: (0.8491) |  Loss2: (0.0000) | Acc: (70.00%) (15415/21888)
Epoch: 21 | Batch_idx: 180 |  Loss: (0.8457) |  Loss2: (0.0000) | Acc: (70.00%) (16349/23168)
Epoch: 21 | Batch_idx: 190 |  Loss: (0.8379) |  Loss2: (0.0000) | Acc: (70.00%) (17313/24448)
Epoch: 21 | Batch_idx: 200 |  Loss: (0.8356) |  Loss2: (0.0000) | Acc: (70.00%) (18223/25728)
Epoch: 21 | Batch_idx: 210 |  Loss: (0.8314) |  Loss2: (0.0000) | Acc: (71.00%) (19182/27008)
Epoch: 21 | Batch_idx: 220 |  Loss: (0.8292) |  Loss2: (0.0000) | Acc: (71.00%) (20094/28288)
Epoch: 21 | Batch_idx: 230 |  Loss: (0.8277) |  Loss2: (0.0000) | Acc: (71.00%) (21046/29568)
Epoch: 21 | Batch_idx: 240 |  Loss: (0.8225) |  Loss2: (0.0000) | Acc: (71.00%) (22000/30848)
Epoch: 21 | Batch_idx: 250 |  Loss: (0.8196) |  Loss2: (0.0000) | Acc: (71.00%) (22943/32128)
Epoch: 21 | Batch_idx: 260 |  Loss: (0.8183) |  Loss2: (0.0000) | Acc: (71.00%) (23869/33408)
Epoch: 21 | Batch_idx: 270 |  Loss: (0.8159) |  Loss2: (0.0000) | Acc: (71.00%) (24805/34688)
Epoch: 21 | Batch_idx: 280 |  Loss: (0.8129) |  Loss2: (0.0000) | Acc: (71.00%) (25761/35968)
Epoch: 21 | Batch_idx: 290 |  Loss: (0.8110) |  Loss2: (0.0000) | Acc: (71.00%) (26694/37248)
Epoch: 21 | Batch_idx: 300 |  Loss: (0.8093) |  Loss2: (0.0000) | Acc: (71.00%) (27625/38528)
Epoch: 21 | Batch_idx: 310 |  Loss: (0.8077) |  Loss2: (0.0000) | Acc: (71.00%) (28557/39808)
Epoch: 21 | Batch_idx: 320 |  Loss: (0.8065) |  Loss2: (0.0000) | Acc: (71.00%) (29487/41088)
Epoch: 21 | Batch_idx: 330 |  Loss: (0.8056) |  Loss2: (0.0000) | Acc: (71.00%) (30416/42368)
Epoch: 21 | Batch_idx: 340 |  Loss: (0.8046) |  Loss2: (0.0000) | Acc: (71.00%) (31344/43648)
Epoch: 21 | Batch_idx: 350 |  Loss: (0.8022) |  Loss2: (0.0000) | Acc: (71.00%) (32295/44928)
Epoch: 21 | Batch_idx: 360 |  Loss: (0.8002) |  Loss2: (0.0000) | Acc: (71.00%) (33251/46208)
Epoch: 21 | Batch_idx: 370 |  Loss: (0.7986) |  Loss2: (0.0000) | Acc: (72.00%) (34201/47488)
Epoch: 21 | Batch_idx: 380 |  Loss: (0.7959) |  Loss2: (0.0000) | Acc: (72.00%) (35174/48768)
Epoch: 21 | Batch_idx: 390 |  Loss: (0.7964) |  Loss2: (0.0000) | Acc: (72.00%) (36064/50000)
# TEST : Loss: (0.7745) | Acc: (73.00%) (7361/10000)
percent tensor([0.5338, 0.5436, 0.5385, 0.5353, 0.5422, 0.5408, 0.5440, 0.5381, 0.5372,
        0.5374, 0.5379, 0.5392, 0.5353, 0.5390, 0.5416, 0.5343],
       device='cuda:0') torch.Size([16])
percent tensor([0.5718, 0.5801, 0.5734, 0.5711, 0.5782, 0.5782, 0.5843, 0.5773, 0.5718,
        0.5767, 0.5736, 0.5779, 0.5697, 0.5739, 0.5822, 0.5746],
       device='cuda:0') torch.Size([16])
percent tensor([0.5286, 0.5298, 0.5235, 0.5231, 0.5240, 0.5181, 0.5280, 0.5251, 0.5260,
        0.5292, 0.5293, 0.5297, 0.5278, 0.5326, 0.5263, 0.5299],
       device='cuda:0') torch.Size([16])
percent tensor([0.5349, 0.5265, 0.5349, 0.5392, 0.5367, 0.5398, 0.5326, 0.5399, 0.5299,
        0.5290, 0.5279, 0.5310, 0.5278, 0.5270, 0.5380, 0.5338],
       device='cuda:0') torch.Size([16])
percent tensor([0.4674, 0.4643, 0.4754, 0.4728, 0.4824, 0.4663, 0.4804, 0.4758, 0.4853,
        0.4563, 0.4656, 0.4785, 0.4625, 0.4775, 0.4783, 0.4578],
       device='cuda:0') torch.Size([16])
percent tensor([0.4951, 0.4981, 0.5076, 0.5136, 0.5068, 0.5037, 0.4992, 0.5042, 0.5085,
        0.4999, 0.5019, 0.4984, 0.4966, 0.5082, 0.4931, 0.4970],
       device='cuda:0') torch.Size([16])
percent tensor([0.5049, 0.5089, 0.5600, 0.5572, 0.5664, 0.4874, 0.5339, 0.5771, 0.5243,
        0.5159, 0.5087, 0.5501, 0.4975, 0.5135, 0.5175, 0.5127],
       device='cuda:0') torch.Size([16])
percent tensor([0.8695, 0.8454, 0.9259, 0.9021, 0.9160, 0.8651, 0.8671, 0.9522, 0.8625,
        0.8974, 0.8695, 0.9141, 0.8500, 0.8426, 0.8722, 0.8977],
       device='cuda:0') torch.Size([16])
Epoch: 22 | Batch_idx: 0 |  Loss: (0.5960) |  Loss2: (0.0000) | Acc: (78.00%) (101/128)
Epoch: 22 | Batch_idx: 10 |  Loss: (0.6993) |  Loss2: (0.0000) | Acc: (74.00%) (1055/1408)
Epoch: 22 | Batch_idx: 20 |  Loss: (0.7127) |  Loss2: (0.0000) | Acc: (75.00%) (2020/2688)
Epoch: 22 | Batch_idx: 30 |  Loss: (0.7171) |  Loss2: (0.0000) | Acc: (74.00%) (2975/3968)
Epoch: 22 | Batch_idx: 40 |  Loss: (0.7238) |  Loss2: (0.0000) | Acc: (74.00%) (3932/5248)
Epoch: 22 | Batch_idx: 50 |  Loss: (0.7203) |  Loss2: (0.0000) | Acc: (74.00%) (4891/6528)
Epoch: 22 | Batch_idx: 60 |  Loss: (0.7170) |  Loss2: (0.0000) | Acc: (75.00%) (5866/7808)
Epoch: 22 | Batch_idx: 70 |  Loss: (0.7180) |  Loss2: (0.0000) | Acc: (75.00%) (6825/9088)
Epoch: 22 | Batch_idx: 80 |  Loss: (0.7186) |  Loss2: (0.0000) | Acc: (75.00%) (7779/10368)
Epoch: 22 | Batch_idx: 90 |  Loss: (0.7232) |  Loss2: (0.0000) | Acc: (75.00%) (8746/11648)
Epoch: 22 | Batch_idx: 100 |  Loss: (0.7257) |  Loss2: (0.0000) | Acc: (74.00%) (9690/12928)
Epoch: 22 | Batch_idx: 110 |  Loss: (0.7238) |  Loss2: (0.0000) | Acc: (74.00%) (10654/14208)
Epoch: 22 | Batch_idx: 120 |  Loss: (0.7242) |  Loss2: (0.0000) | Acc: (74.00%) (11613/15488)
Epoch: 22 | Batch_idx: 130 |  Loss: (0.7226) |  Loss2: (0.0000) | Acc: (75.00%) (12587/16768)
Epoch: 22 | Batch_idx: 140 |  Loss: (0.7193) |  Loss2: (0.0000) | Acc: (75.00%) (13563/18048)
Epoch: 22 | Batch_idx: 150 |  Loss: (0.7182) |  Loss2: (0.0000) | Acc: (75.00%) (14529/19328)
Epoch: 22 | Batch_idx: 160 |  Loss: (0.7174) |  Loss2: (0.0000) | Acc: (75.00%) (15491/20608)
Epoch: 22 | Batch_idx: 170 |  Loss: (0.7187) |  Loss2: (0.0000) | Acc: (75.00%) (16432/21888)
Epoch: 22 | Batch_idx: 180 |  Loss: (0.7199) |  Loss2: (0.0000) | Acc: (74.00%) (17373/23168)
Epoch: 22 | Batch_idx: 190 |  Loss: (0.7202) |  Loss2: (0.0000) | Acc: (74.00%) (18335/24448)
Epoch: 22 | Batch_idx: 200 |  Loss: (0.7206) |  Loss2: (0.0000) | Acc: (74.00%) (19277/25728)
Epoch: 22 | Batch_idx: 210 |  Loss: (0.7203) |  Loss2: (0.0000) | Acc: (74.00%) (20238/27008)
Epoch: 22 | Batch_idx: 220 |  Loss: (0.7185) |  Loss2: (0.0000) | Acc: (74.00%) (21201/28288)
Epoch: 22 | Batch_idx: 230 |  Loss: (0.7175) |  Loss2: (0.0000) | Acc: (74.00%) (22174/29568)
Epoch: 22 | Batch_idx: 240 |  Loss: (0.7149) |  Loss2: (0.0000) | Acc: (75.00%) (23156/30848)
Epoch: 22 | Batch_idx: 250 |  Loss: (0.7153) |  Loss2: (0.0000) | Acc: (75.00%) (24104/32128)
Epoch: 22 | Batch_idx: 260 |  Loss: (0.7157) |  Loss2: (0.0000) | Acc: (74.00%) (25051/33408)
Epoch: 22 | Batch_idx: 270 |  Loss: (0.7151) |  Loss2: (0.0000) | Acc: (74.00%) (26010/34688)
Epoch: 22 | Batch_idx: 280 |  Loss: (0.7130) |  Loss2: (0.0000) | Acc: (75.00%) (26996/35968)
Epoch: 22 | Batch_idx: 290 |  Loss: (0.7130) |  Loss2: (0.0000) | Acc: (75.00%) (27939/37248)
Epoch: 22 | Batch_idx: 300 |  Loss: (0.7119) |  Loss2: (0.0000) | Acc: (75.00%) (28909/38528)
Epoch: 22 | Batch_idx: 310 |  Loss: (0.7116) |  Loss2: (0.0000) | Acc: (75.00%) (29871/39808)
Epoch: 22 | Batch_idx: 320 |  Loss: (0.7108) |  Loss2: (0.0000) | Acc: (75.00%) (30844/41088)
Epoch: 22 | Batch_idx: 330 |  Loss: (0.7105) |  Loss2: (0.0000) | Acc: (75.00%) (31795/42368)
Epoch: 22 | Batch_idx: 340 |  Loss: (0.7105) |  Loss2: (0.0000) | Acc: (75.00%) (32759/43648)
Epoch: 22 | Batch_idx: 350 |  Loss: (0.7102) |  Loss2: (0.0000) | Acc: (75.00%) (33743/44928)
Epoch: 22 | Batch_idx: 360 |  Loss: (0.7095) |  Loss2: (0.0000) | Acc: (75.00%) (34713/46208)
Epoch: 22 | Batch_idx: 370 |  Loss: (0.7088) |  Loss2: (0.0000) | Acc: (75.00%) (35698/47488)
Epoch: 22 | Batch_idx: 380 |  Loss: (0.7075) |  Loss2: (0.0000) | Acc: (75.00%) (36698/48768)
Epoch: 22 | Batch_idx: 390 |  Loss: (0.7056) |  Loss2: (0.0000) | Acc: (75.00%) (37645/50000)
# TEST : Loss: (0.7336) | Acc: (74.00%) (7485/10000)
percent tensor([0.5336, 0.5424, 0.5409, 0.5363, 0.5440, 0.5408, 0.5441, 0.5388, 0.5370,
        0.5374, 0.5370, 0.5410, 0.5348, 0.5373, 0.5412, 0.5338],
       device='cuda:0') torch.Size([16])
percent tensor([0.5711, 0.5788, 0.5749, 0.5723, 0.5789, 0.5773, 0.5836, 0.5769, 0.5713,
        0.5763, 0.5725, 0.5789, 0.5684, 0.5727, 0.5809, 0.5736],
       device='cuda:0') torch.Size([16])
percent tensor([0.5358, 0.5401, 0.5281, 0.5285, 0.5298, 0.5234, 0.5366, 0.5315, 0.5333,
        0.5386, 0.5377, 0.5372, 0.5363, 0.5420, 0.5344, 0.5380],
       device='cuda:0') torch.Size([16])
percent tensor([0.5445, 0.5343, 0.5448, 0.5505, 0.5474, 0.5507, 0.5418, 0.5505, 0.5383,
        0.5381, 0.5360, 0.5402, 0.5354, 0.5340, 0.5485, 0.5439],
       device='cuda:0') torch.Size([16])
percent tensor([0.4614, 0.4574, 0.4797, 0.4804, 0.4865, 0.4638, 0.4772, 0.4820, 0.4835,
        0.4514, 0.4596, 0.4790, 0.4536, 0.4732, 0.4746, 0.4539],
       device='cuda:0') torch.Size([16])
percent tensor([0.5040, 0.5066, 0.5218, 0.5281, 0.5217, 0.5112, 0.5120, 0.5226, 0.5177,
        0.5087, 0.5090, 0.5123, 0.5025, 0.5163, 0.5049, 0.5078],
       device='cuda:0') torch.Size([16])
percent tensor([0.5113, 0.5165, 0.5799, 0.5776, 0.5895, 0.4922, 0.5457, 0.5983, 0.5387,
        0.5286, 0.5204, 0.5661, 0.5050, 0.5259, 0.5255, 0.5209],
       device='cuda:0') torch.Size([16])
percent tensor([0.9192, 0.8953, 0.9570, 0.9399, 0.9553, 0.9111, 0.9138, 0.9764, 0.9101,
        0.9410, 0.9189, 0.9464, 0.9033, 0.8925, 0.9187, 0.9373],
       device='cuda:0') torch.Size([16])
Epoch: 23 | Batch_idx: 0 |  Loss: (0.8909) |  Loss2: (0.0000) | Acc: (66.00%) (85/128)
Epoch: 23 | Batch_idx: 10 |  Loss: (0.6786) |  Loss2: (0.0000) | Acc: (77.00%) (1091/1408)
Epoch: 23 | Batch_idx: 20 |  Loss: (0.7084) |  Loss2: (0.0000) | Acc: (76.00%) (2047/2688)
Epoch: 23 | Batch_idx: 30 |  Loss: (0.7141) |  Loss2: (0.0000) | Acc: (75.00%) (3002/3968)
Epoch: 23 | Batch_idx: 40 |  Loss: (0.7004) |  Loss2: (0.0000) | Acc: (75.00%) (3985/5248)
Epoch: 23 | Batch_idx: 50 |  Loss: (0.7059) |  Loss2: (0.0000) | Acc: (75.00%) (4939/6528)
Epoch: 23 | Batch_idx: 60 |  Loss: (0.7053) |  Loss2: (0.0000) | Acc: (75.00%) (5909/7808)
Epoch: 23 | Batch_idx: 70 |  Loss: (0.7017) |  Loss2: (0.0000) | Acc: (75.00%) (6900/9088)
Epoch: 23 | Batch_idx: 80 |  Loss: (0.6977) |  Loss2: (0.0000) | Acc: (75.00%) (7879/10368)
Epoch: 23 | Batch_idx: 90 |  Loss: (0.6975) |  Loss2: (0.0000) | Acc: (75.00%) (8839/11648)
Epoch: 23 | Batch_idx: 100 |  Loss: (0.6966) |  Loss2: (0.0000) | Acc: (75.00%) (9812/12928)
Epoch: 23 | Batch_idx: 110 |  Loss: (0.6955) |  Loss2: (0.0000) | Acc: (75.00%) (10782/14208)
Epoch: 23 | Batch_idx: 120 |  Loss: (0.6936) |  Loss2: (0.0000) | Acc: (75.00%) (11745/15488)
Epoch: 23 | Batch_idx: 130 |  Loss: (0.6897) |  Loss2: (0.0000) | Acc: (75.00%) (12741/16768)
Epoch: 23 | Batch_idx: 140 |  Loss: (0.6925) |  Loss2: (0.0000) | Acc: (75.00%) (13671/18048)
Epoch: 23 | Batch_idx: 150 |  Loss: (0.6953) |  Loss2: (0.0000) | Acc: (75.00%) (14625/19328)
Epoch: 23 | Batch_idx: 160 |  Loss: (0.6967) |  Loss2: (0.0000) | Acc: (75.00%) (15580/20608)
Epoch: 23 | Batch_idx: 170 |  Loss: (0.6947) |  Loss2: (0.0000) | Acc: (75.00%) (16564/21888)
Epoch: 23 | Batch_idx: 180 |  Loss: (0.6943) |  Loss2: (0.0000) | Acc: (75.00%) (17542/23168)
Epoch: 23 | Batch_idx: 190 |  Loss: (0.6950) |  Loss2: (0.0000) | Acc: (75.00%) (18496/24448)
Epoch: 23 | Batch_idx: 200 |  Loss: (0.6937) |  Loss2: (0.0000) | Acc: (75.00%) (19474/25728)
Epoch: 23 | Batch_idx: 210 |  Loss: (0.6957) |  Loss2: (0.0000) | Acc: (75.00%) (20423/27008)
Epoch: 23 | Batch_idx: 220 |  Loss: (0.6968) |  Loss2: (0.0000) | Acc: (75.00%) (21394/28288)
Epoch: 23 | Batch_idx: 230 |  Loss: (0.6969) |  Loss2: (0.0000) | Acc: (75.00%) (22362/29568)
Epoch: 23 | Batch_idx: 240 |  Loss: (0.6944) |  Loss2: (0.0000) | Acc: (75.00%) (23365/30848)
Epoch: 23 | Batch_idx: 250 |  Loss: (0.6941) |  Loss2: (0.0000) | Acc: (75.00%) (24330/32128)
Epoch: 23 | Batch_idx: 260 |  Loss: (0.6920) |  Loss2: (0.0000) | Acc: (75.00%) (25331/33408)
Epoch: 23 | Batch_idx: 270 |  Loss: (0.6918) |  Loss2: (0.0000) | Acc: (75.00%) (26288/34688)
Epoch: 23 | Batch_idx: 280 |  Loss: (0.6910) |  Loss2: (0.0000) | Acc: (75.00%) (27263/35968)
Epoch: 23 | Batch_idx: 290 |  Loss: (0.6894) |  Loss2: (0.0000) | Acc: (75.00%) (28262/37248)
Epoch: 23 | Batch_idx: 300 |  Loss: (0.6886) |  Loss2: (0.0000) | Acc: (75.00%) (29254/38528)
Epoch: 23 | Batch_idx: 310 |  Loss: (0.6862) |  Loss2: (0.0000) | Acc: (76.00%) (30268/39808)
Epoch: 23 | Batch_idx: 320 |  Loss: (0.6854) |  Loss2: (0.0000) | Acc: (76.00%) (31243/41088)
Epoch: 23 | Batch_idx: 330 |  Loss: (0.6868) |  Loss2: (0.0000) | Acc: (76.00%) (32201/42368)
Epoch: 23 | Batch_idx: 340 |  Loss: (0.6869) |  Loss2: (0.0000) | Acc: (75.00%) (33170/43648)
Epoch: 23 | Batch_idx: 350 |  Loss: (0.6872) |  Loss2: (0.0000) | Acc: (75.00%) (34130/44928)
Epoch: 23 | Batch_idx: 360 |  Loss: (0.6865) |  Loss2: (0.0000) | Acc: (75.00%) (35114/46208)
Epoch: 23 | Batch_idx: 370 |  Loss: (0.6867) |  Loss2: (0.0000) | Acc: (75.00%) (36089/47488)
Epoch: 23 | Batch_idx: 380 |  Loss: (0.6872) |  Loss2: (0.0000) | Acc: (75.00%) (37054/48768)
Epoch: 23 | Batch_idx: 390 |  Loss: (0.6868) |  Loss2: (0.0000) | Acc: (75.00%) (37992/50000)
# TEST : Loss: (0.7199) | Acc: (75.00%) (7539/10000)
percent tensor([0.5371, 0.5459, 0.5460, 0.5406, 0.5491, 0.5451, 0.5482, 0.5431, 0.5406,
        0.5412, 0.5403, 0.5458, 0.5382, 0.5397, 0.5453, 0.5371],
       device='cuda:0') torch.Size([16])
percent tensor([0.5664, 0.5723, 0.5700, 0.5675, 0.5731, 0.5730, 0.5775, 0.5704, 0.5660,
        0.5706, 0.5672, 0.5741, 0.5631, 0.5667, 0.5754, 0.5685],
       device='cuda:0') torch.Size([16])
percent tensor([0.5369, 0.5432, 0.5291, 0.5291, 0.5309, 0.5224, 0.5390, 0.5333, 0.5355,
        0.5414, 0.5399, 0.5388, 0.5384, 0.5451, 0.5356, 0.5393],
       device='cuda:0') torch.Size([16])
percent tensor([0.5528, 0.5410, 0.5522, 0.5589, 0.5552, 0.5601, 0.5492, 0.5578, 0.5451,
        0.5459, 0.5436, 0.5480, 0.5425, 0.5402, 0.5573, 0.5523],
       device='cuda:0') torch.Size([16])
percent tensor([0.4591, 0.4547, 0.4818, 0.4847, 0.4883, 0.4638, 0.4757, 0.4846, 0.4828,
        0.4503, 0.4580, 0.4802, 0.4500, 0.4710, 0.4742, 0.4523],
       device='cuda:0') torch.Size([16])
percent tensor([0.5083, 0.5113, 0.5291, 0.5361, 0.5293, 0.5157, 0.5182, 0.5317, 0.5229,
        0.5134, 0.5137, 0.5196, 0.5059, 0.5208, 0.5105, 0.5133],
       device='cuda:0') torch.Size([16])
percent tensor([0.5169, 0.5238, 0.5953, 0.5934, 0.6069, 0.4950, 0.5563, 0.6164, 0.5508,
        0.5391, 0.5311, 0.5819, 0.5117, 0.5363, 0.5346, 0.5268],
       device='cuda:0') torch.Size([16])
percent tensor([0.9404, 0.9169, 0.9692, 0.9546, 0.9691, 0.9301, 0.9349, 0.9846, 0.9301,
        0.9563, 0.9381, 0.9598, 0.9253, 0.9142, 0.9390, 0.9552],
       device='cuda:0') torch.Size([16])
Epoch: 24 | Batch_idx: 0 |  Loss: (0.6655) |  Loss2: (0.0000) | Acc: (72.00%) (93/128)
Epoch: 24 | Batch_idx: 10 |  Loss: (0.7002) |  Loss2: (0.0000) | Acc: (74.00%) (1054/1408)
Epoch: 24 | Batch_idx: 20 |  Loss: (0.6861) |  Loss2: (0.0000) | Acc: (76.00%) (2048/2688)
Epoch: 24 | Batch_idx: 30 |  Loss: (0.6844) |  Loss2: (0.0000) | Acc: (76.00%) (3024/3968)
Epoch: 24 | Batch_idx: 40 |  Loss: (0.6775) |  Loss2: (0.0000) | Acc: (76.00%) (4014/5248)
Epoch: 24 | Batch_idx: 50 |  Loss: (0.6716) |  Loss2: (0.0000) | Acc: (76.00%) (5021/6528)
Epoch: 24 | Batch_idx: 60 |  Loss: (0.6685) |  Loss2: (0.0000) | Acc: (76.00%) (6011/7808)
Epoch: 24 | Batch_idx: 70 |  Loss: (0.6645) |  Loss2: (0.0000) | Acc: (77.00%) (7015/9088)
Epoch: 24 | Batch_idx: 80 |  Loss: (0.6724) |  Loss2: (0.0000) | Acc: (76.00%) (7981/10368)
Epoch: 24 | Batch_idx: 90 |  Loss: (0.6784) |  Loss2: (0.0000) | Acc: (76.00%) (8931/11648)
Epoch: 24 | Batch_idx: 100 |  Loss: (0.6717) |  Loss2: (0.0000) | Acc: (76.00%) (9923/12928)
Epoch: 24 | Batch_idx: 110 |  Loss: (0.6653) |  Loss2: (0.0000) | Acc: (77.00%) (10942/14208)
Epoch: 24 | Batch_idx: 120 |  Loss: (0.6675) |  Loss2: (0.0000) | Acc: (76.00%) (11906/15488)
Epoch: 24 | Batch_idx: 130 |  Loss: (0.6686) |  Loss2: (0.0000) | Acc: (76.00%) (12893/16768)
Epoch: 24 | Batch_idx: 140 |  Loss: (0.6663) |  Loss2: (0.0000) | Acc: (76.00%) (13894/18048)
Epoch: 24 | Batch_idx: 150 |  Loss: (0.6667) |  Loss2: (0.0000) | Acc: (77.00%) (14884/19328)
Epoch: 24 | Batch_idx: 160 |  Loss: (0.6647) |  Loss2: (0.0000) | Acc: (77.00%) (15895/20608)
Epoch: 24 | Batch_idx: 170 |  Loss: (0.6653) |  Loss2: (0.0000) | Acc: (77.00%) (16862/21888)
Epoch: 24 | Batch_idx: 180 |  Loss: (0.6666) |  Loss2: (0.0000) | Acc: (76.00%) (17832/23168)
Epoch: 24 | Batch_idx: 190 |  Loss: (0.6693) |  Loss2: (0.0000) | Acc: (76.00%) (18790/24448)
Epoch: 24 | Batch_idx: 200 |  Loss: (0.6670) |  Loss2: (0.0000) | Acc: (77.00%) (19812/25728)
Epoch: 24 | Batch_idx: 210 |  Loss: (0.6677) |  Loss2: (0.0000) | Acc: (76.00%) (20786/27008)
Epoch: 24 | Batch_idx: 220 |  Loss: (0.6680) |  Loss2: (0.0000) | Acc: (77.00%) (21782/28288)
Epoch: 24 | Batch_idx: 230 |  Loss: (0.6721) |  Loss2: (0.0000) | Acc: (76.00%) (22721/29568)
Epoch: 24 | Batch_idx: 240 |  Loss: (0.6713) |  Loss2: (0.0000) | Acc: (76.00%) (23698/30848)
Epoch: 24 | Batch_idx: 250 |  Loss: (0.6710) |  Loss2: (0.0000) | Acc: (76.00%) (24676/32128)
Epoch: 24 | Batch_idx: 260 |  Loss: (0.6721) |  Loss2: (0.0000) | Acc: (76.00%) (25652/33408)
Epoch: 24 | Batch_idx: 270 |  Loss: (0.6735) |  Loss2: (0.0000) | Acc: (76.00%) (26601/34688)
Epoch: 24 | Batch_idx: 280 |  Loss: (0.6742) |  Loss2: (0.0000) | Acc: (76.00%) (27574/35968)
Epoch: 24 | Batch_idx: 290 |  Loss: (0.6729) |  Loss2: (0.0000) | Acc: (76.00%) (28560/37248)
Epoch: 24 | Batch_idx: 300 |  Loss: (0.6738) |  Loss2: (0.0000) | Acc: (76.00%) (29525/38528)
Epoch: 24 | Batch_idx: 310 |  Loss: (0.6745) |  Loss2: (0.0000) | Acc: (76.00%) (30489/39808)
Epoch: 24 | Batch_idx: 320 |  Loss: (0.6740) |  Loss2: (0.0000) | Acc: (76.00%) (31455/41088)
Epoch: 24 | Batch_idx: 330 |  Loss: (0.6741) |  Loss2: (0.0000) | Acc: (76.00%) (32433/42368)
Epoch: 24 | Batch_idx: 340 |  Loss: (0.6765) |  Loss2: (0.0000) | Acc: (76.00%) (33379/43648)
Epoch: 24 | Batch_idx: 350 |  Loss: (0.6768) |  Loss2: (0.0000) | Acc: (76.00%) (34358/44928)
Epoch: 24 | Batch_idx: 360 |  Loss: (0.6759) |  Loss2: (0.0000) | Acc: (76.00%) (35340/46208)
Epoch: 24 | Batch_idx: 370 |  Loss: (0.6766) |  Loss2: (0.0000) | Acc: (76.00%) (36326/47488)
Epoch: 24 | Batch_idx: 380 |  Loss: (0.6758) |  Loss2: (0.0000) | Acc: (76.00%) (37304/48768)
Epoch: 24 | Batch_idx: 390 |  Loss: (0.6769) |  Loss2: (0.0000) | Acc: (76.00%) (38221/50000)
# TEST : Loss: (0.7092) | Acc: (75.00%) (7576/10000)
percent tensor([0.5339, 0.5414, 0.5426, 0.5379, 0.5454, 0.5422, 0.5440, 0.5396, 0.5370,
        0.5372, 0.5366, 0.5419, 0.5346, 0.5357, 0.5417, 0.5339],
       device='cuda:0') torch.Size([16])
percent tensor([0.5607, 0.5656, 0.5634, 0.5610, 0.5660, 0.5671, 0.5707, 0.5629, 0.5599,
        0.5642, 0.5615, 0.5682, 0.5573, 0.5606, 0.5689, 0.5623],
       device='cuda:0') torch.Size([16])
percent tensor([0.5385, 0.5455, 0.5307, 0.5308, 0.5325, 0.5226, 0.5412, 0.5356, 0.5378,
        0.5436, 0.5416, 0.5406, 0.5405, 0.5479, 0.5371, 0.5407],
       device='cuda:0') torch.Size([16])
percent tensor([0.5563, 0.5440, 0.5542, 0.5615, 0.5576, 0.5645, 0.5520, 0.5589, 0.5475,
        0.5491, 0.5473, 0.5510, 0.5458, 0.5426, 0.5612, 0.5559],
       device='cuda:0') torch.Size([16])
percent tensor([0.4591, 0.4547, 0.4837, 0.4888, 0.4897, 0.4655, 0.4754, 0.4863, 0.4835,
        0.4514, 0.4583, 0.4823, 0.4495, 0.4711, 0.4753, 0.4526],
       device='cuda:0') torch.Size([16])
percent tensor([0.5079, 0.5111, 0.5294, 0.5368, 0.5301, 0.5168, 0.5182, 0.5319, 0.5233,
        0.5126, 0.5139, 0.5201, 0.5053, 0.5213, 0.5101, 0.5134],
       device='cuda:0') torch.Size([16])
percent tensor([0.5227, 0.5308, 0.6048, 0.6019, 0.6173, 0.4981, 0.5641, 0.6248, 0.5612,
        0.5492, 0.5414, 0.5943, 0.5205, 0.5459, 0.5411, 0.5315],
       device='cuda:0') torch.Size([16])
percent tensor([0.9509, 0.9285, 0.9755, 0.9625, 0.9759, 0.9406, 0.9459, 0.9883, 0.9418,
        0.9652, 0.9482, 0.9687, 0.9374, 0.9265, 0.9505, 0.9635],
       device='cuda:0') torch.Size([16])
Epoch: 25 | Batch_idx: 0 |  Loss: (0.8302) |  Loss2: (0.0000) | Acc: (67.00%) (87/128)
Epoch: 25 | Batch_idx: 10 |  Loss: (0.6766) |  Loss2: (0.0000) | Acc: (76.00%) (1072/1408)
Epoch: 25 | Batch_idx: 20 |  Loss: (0.6591) |  Loss2: (0.0000) | Acc: (76.00%) (2058/2688)
Epoch: 25 | Batch_idx: 30 |  Loss: (0.6589) |  Loss2: (0.0000) | Acc: (76.00%) (3051/3968)
Epoch: 25 | Batch_idx: 40 |  Loss: (0.6635) |  Loss2: (0.0000) | Acc: (76.00%) (4032/5248)
Epoch: 25 | Batch_idx: 50 |  Loss: (0.6630) |  Loss2: (0.0000) | Acc: (76.00%) (5011/6528)
Epoch: 25 | Batch_idx: 60 |  Loss: (0.6608) |  Loss2: (0.0000) | Acc: (76.00%) (5995/7808)
Epoch: 25 | Batch_idx: 70 |  Loss: (0.6685) |  Loss2: (0.0000) | Acc: (76.00%) (6955/9088)
Epoch: 25 | Batch_idx: 80 |  Loss: (0.6665) |  Loss2: (0.0000) | Acc: (76.00%) (7943/10368)
Epoch: 25 | Batch_idx: 90 |  Loss: (0.6680) |  Loss2: (0.0000) | Acc: (76.00%) (8911/11648)
Epoch: 25 | Batch_idx: 100 |  Loss: (0.6732) |  Loss2: (0.0000) | Acc: (76.00%) (9874/12928)
Epoch: 25 | Batch_idx: 110 |  Loss: (0.6768) |  Loss2: (0.0000) | Acc: (76.00%) (10848/14208)
Epoch: 25 | Batch_idx: 120 |  Loss: (0.6805) |  Loss2: (0.0000) | Acc: (76.00%) (11788/15488)
Epoch: 25 | Batch_idx: 130 |  Loss: (0.6774) |  Loss2: (0.0000) | Acc: (76.00%) (12781/16768)
Epoch: 25 | Batch_idx: 140 |  Loss: (0.6790) |  Loss2: (0.0000) | Acc: (76.00%) (13755/18048)
Epoch: 25 | Batch_idx: 150 |  Loss: (0.6766) |  Loss2: (0.0000) | Acc: (76.00%) (14732/19328)
Epoch: 25 | Batch_idx: 160 |  Loss: (0.6792) |  Loss2: (0.0000) | Acc: (76.00%) (15695/20608)
Epoch: 25 | Batch_idx: 170 |  Loss: (0.6761) |  Loss2: (0.0000) | Acc: (76.00%) (16691/21888)
Epoch: 25 | Batch_idx: 180 |  Loss: (0.6730) |  Loss2: (0.0000) | Acc: (76.00%) (17684/23168)
Epoch: 25 | Batch_idx: 190 |  Loss: (0.6710) |  Loss2: (0.0000) | Acc: (76.00%) (18673/24448)
Epoch: 25 | Batch_idx: 200 |  Loss: (0.6704) |  Loss2: (0.0000) | Acc: (76.00%) (19653/25728)
Epoch: 25 | Batch_idx: 210 |  Loss: (0.6708) |  Loss2: (0.0000) | Acc: (76.00%) (20622/27008)
Epoch: 25 | Batch_idx: 220 |  Loss: (0.6718) |  Loss2: (0.0000) | Acc: (76.00%) (21602/28288)
Epoch: 25 | Batch_idx: 230 |  Loss: (0.6701) |  Loss2: (0.0000) | Acc: (76.00%) (22603/29568)
Epoch: 25 | Batch_idx: 240 |  Loss: (0.6682) |  Loss2: (0.0000) | Acc: (76.00%) (23604/30848)
Epoch: 25 | Batch_idx: 250 |  Loss: (0.6669) |  Loss2: (0.0000) | Acc: (76.00%) (24592/32128)
Epoch: 25 | Batch_idx: 260 |  Loss: (0.6682) |  Loss2: (0.0000) | Acc: (76.00%) (25550/33408)
Epoch: 25 | Batch_idx: 270 |  Loss: (0.6675) |  Loss2: (0.0000) | Acc: (76.00%) (26534/34688)
Epoch: 25 | Batch_idx: 280 |  Loss: (0.6680) |  Loss2: (0.0000) | Acc: (76.00%) (27513/35968)
Epoch: 25 | Batch_idx: 290 |  Loss: (0.6690) |  Loss2: (0.0000) | Acc: (76.00%) (28486/37248)
Epoch: 25 | Batch_idx: 300 |  Loss: (0.6703) |  Loss2: (0.0000) | Acc: (76.00%) (29459/38528)
Epoch: 25 | Batch_idx: 310 |  Loss: (0.6697) |  Loss2: (0.0000) | Acc: (76.00%) (30461/39808)
Epoch: 25 | Batch_idx: 320 |  Loss: (0.6688) |  Loss2: (0.0000) | Acc: (76.00%) (31447/41088)
Epoch: 25 | Batch_idx: 330 |  Loss: (0.6691) |  Loss2: (0.0000) | Acc: (76.00%) (32427/42368)
Epoch: 25 | Batch_idx: 340 |  Loss: (0.6676) |  Loss2: (0.0000) | Acc: (76.00%) (33431/43648)
Epoch: 25 | Batch_idx: 350 |  Loss: (0.6675) |  Loss2: (0.0000) | Acc: (76.00%) (34414/44928)
Epoch: 25 | Batch_idx: 360 |  Loss: (0.6660) |  Loss2: (0.0000) | Acc: (76.00%) (35418/46208)
Epoch: 25 | Batch_idx: 370 |  Loss: (0.6653) |  Loss2: (0.0000) | Acc: (76.00%) (36410/47488)
Epoch: 25 | Batch_idx: 380 |  Loss: (0.6648) |  Loss2: (0.0000) | Acc: (76.00%) (37389/48768)
Epoch: 25 | Batch_idx: 390 |  Loss: (0.6637) |  Loss2: (0.0000) | Acc: (76.00%) (38343/50000)
=> saving checkpoint 'drive/app/torch/save_Schedule/checkpoint_025.pth.tar'
# TEST : Loss: (0.7026) | Acc: (75.00%) (7572/10000)
percent tensor([0.5340, 0.5410, 0.5433, 0.5386, 0.5459, 0.5426, 0.5440, 0.5400, 0.5370,
        0.5373, 0.5365, 0.5423, 0.5346, 0.5350, 0.5418, 0.5340],
       device='cuda:0') torch.Size([16])
percent tensor([0.5563, 0.5602, 0.5582, 0.5560, 0.5603, 0.5629, 0.5654, 0.5567, 0.5550,
        0.5592, 0.5571, 0.5636, 0.5527, 0.5556, 0.5640, 0.5577],
       device='cuda:0') torch.Size([16])
percent tensor([0.5397, 0.5473, 0.5319, 0.5324, 0.5334, 0.5226, 0.5426, 0.5372, 0.5398,
        0.5455, 0.5430, 0.5418, 0.5423, 0.5503, 0.5380, 0.5421],
       device='cuda:0') torch.Size([16])
percent tensor([0.5592, 0.5460, 0.5560, 0.5641, 0.5594, 0.5684, 0.5539, 0.5598, 0.5490,
        0.5515, 0.5498, 0.5533, 0.5482, 0.5440, 0.5644, 0.5589],
       device='cuda:0') torch.Size([16])
percent tensor([0.4626, 0.4584, 0.4862, 0.4924, 0.4914, 0.4695, 0.4782, 0.4887, 0.4867,
        0.4568, 0.4625, 0.4872, 0.4535, 0.4749, 0.4796, 0.4566],
       device='cuda:0') torch.Size([16])
percent tensor([0.5087, 0.5121, 0.5312, 0.5395, 0.5320, 0.5189, 0.5191, 0.5332, 0.5252,
        0.5133, 0.5155, 0.5221, 0.5060, 0.5235, 0.5106, 0.5144],
       device='cuda:0') torch.Size([16])
percent tensor([0.5292, 0.5398, 0.6167, 0.6143, 0.6304, 0.5036, 0.5726, 0.6354, 0.5748,
        0.5613, 0.5554, 0.6098, 0.5309, 0.5588, 0.5481, 0.5371],
       device='cuda:0') torch.Size([16])
percent tensor([0.9614, 0.9414, 0.9808, 0.9700, 0.9812, 0.9512, 0.9552, 0.9910, 0.9537,
        0.9739, 0.9601, 0.9763, 0.9499, 0.9403, 0.9591, 0.9714],
       device='cuda:0') torch.Size([16])
Epoch: 26 | Batch_idx: 0 |  Loss: (0.6466) |  Loss2: (0.0000) | Acc: (78.00%) (101/128)
Epoch: 26 | Batch_idx: 10 |  Loss: (0.6437) |  Loss2: (0.0000) | Acc: (77.00%) (1086/1408)
Epoch: 26 | Batch_idx: 20 |  Loss: (0.6385) |  Loss2: (0.0000) | Acc: (78.00%) (2100/2688)
Epoch: 26 | Batch_idx: 30 |  Loss: (0.6440) |  Loss2: (0.0000) | Acc: (78.00%) (3096/3968)
Epoch: 26 | Batch_idx: 40 |  Loss: (0.6470) |  Loss2: (0.0000) | Acc: (78.00%) (4094/5248)
Epoch: 26 | Batch_idx: 50 |  Loss: (0.6435) |  Loss2: (0.0000) | Acc: (78.00%) (5095/6528)
Epoch: 26 | Batch_idx: 60 |  Loss: (0.6456) |  Loss2: (0.0000) | Acc: (77.00%) (6080/7808)
Epoch: 26 | Batch_idx: 70 |  Loss: (0.6547) |  Loss2: (0.0000) | Acc: (77.00%) (7046/9088)
Epoch: 26 | Batch_idx: 80 |  Loss: (0.6609) |  Loss2: (0.0000) | Acc: (77.00%) (8007/10368)
Epoch: 26 | Batch_idx: 90 |  Loss: (0.6602) |  Loss2: (0.0000) | Acc: (77.00%) (8987/11648)
Epoch: 26 | Batch_idx: 100 |  Loss: (0.6557) |  Loss2: (0.0000) | Acc: (77.00%) (9981/12928)
Epoch: 26 | Batch_idx: 110 |  Loss: (0.6546) |  Loss2: (0.0000) | Acc: (77.00%) (10967/14208)
Epoch: 26 | Batch_idx: 120 |  Loss: (0.6544) |  Loss2: (0.0000) | Acc: (77.00%) (11947/15488)
Epoch: 26 | Batch_idx: 130 |  Loss: (0.6567) |  Loss2: (0.0000) | Acc: (77.00%) (12924/16768)
Epoch: 26 | Batch_idx: 140 |  Loss: (0.6563) |  Loss2: (0.0000) | Acc: (76.00%) (13891/18048)
Epoch: 26 | Batch_idx: 150 |  Loss: (0.6555) |  Loss2: (0.0000) | Acc: (77.00%) (14884/19328)
Epoch: 26 | Batch_idx: 160 |  Loss: (0.6539) |  Loss2: (0.0000) | Acc: (77.00%) (15874/20608)
Epoch: 26 | Batch_idx: 170 |  Loss: (0.6552) |  Loss2: (0.0000) | Acc: (76.00%) (16842/21888)
Epoch: 26 | Batch_idx: 180 |  Loss: (0.6535) |  Loss2: (0.0000) | Acc: (76.00%) (17839/23168)
Epoch: 26 | Batch_idx: 190 |  Loss: (0.6543) |  Loss2: (0.0000) | Acc: (76.00%) (18824/24448)
Epoch: 26 | Batch_idx: 200 |  Loss: (0.6537) |  Loss2: (0.0000) | Acc: (77.00%) (19834/25728)
Epoch: 26 | Batch_idx: 210 |  Loss: (0.6560) |  Loss2: (0.0000) | Acc: (76.00%) (20793/27008)
Epoch: 26 | Batch_idx: 220 |  Loss: (0.6545) |  Loss2: (0.0000) | Acc: (76.00%) (21779/28288)
Epoch: 26 | Batch_idx: 230 |  Loss: (0.6546) |  Loss2: (0.0000) | Acc: (76.00%) (22767/29568)
Epoch: 26 | Batch_idx: 240 |  Loss: (0.6562) |  Loss2: (0.0000) | Acc: (76.00%) (23735/30848)
Epoch: 26 | Batch_idx: 250 |  Loss: (0.6548) |  Loss2: (0.0000) | Acc: (77.00%) (24747/32128)
Epoch: 26 | Batch_idx: 260 |  Loss: (0.6563) |  Loss2: (0.0000) | Acc: (77.00%) (25725/33408)
Epoch: 26 | Batch_idx: 270 |  Loss: (0.6552) |  Loss2: (0.0000) | Acc: (77.00%) (26742/34688)
Epoch: 26 | Batch_idx: 280 |  Loss: (0.6556) |  Loss2: (0.0000) | Acc: (77.00%) (27732/35968)
Epoch: 26 | Batch_idx: 290 |  Loss: (0.6557) |  Loss2: (0.0000) | Acc: (77.00%) (28704/37248)
Epoch: 26 | Batch_idx: 300 |  Loss: (0.6552) |  Loss2: (0.0000) | Acc: (77.00%) (29711/38528)
Epoch: 26 | Batch_idx: 310 |  Loss: (0.6561) |  Loss2: (0.0000) | Acc: (77.00%) (30681/39808)
Epoch: 26 | Batch_idx: 320 |  Loss: (0.6568) |  Loss2: (0.0000) | Acc: (77.00%) (31670/41088)
Epoch: 26 | Batch_idx: 330 |  Loss: (0.6566) |  Loss2: (0.0000) | Acc: (77.00%) (32662/42368)
Epoch: 26 | Batch_idx: 340 |  Loss: (0.6573) |  Loss2: (0.0000) | Acc: (77.00%) (33609/43648)
Epoch: 26 | Batch_idx: 350 |  Loss: (0.6569) |  Loss2: (0.0000) | Acc: (77.00%) (34601/44928)
Epoch: 26 | Batch_idx: 360 |  Loss: (0.6561) |  Loss2: (0.0000) | Acc: (77.00%) (35606/46208)
Epoch: 26 | Batch_idx: 370 |  Loss: (0.6588) |  Loss2: (0.0000) | Acc: (76.00%) (36544/47488)
Epoch: 26 | Batch_idx: 380 |  Loss: (0.6590) |  Loss2: (0.0000) | Acc: (76.00%) (37542/48768)
Epoch: 26 | Batch_idx: 390 |  Loss: (0.6590) |  Loss2: (0.0000) | Acc: (76.00%) (38480/50000)
# TEST : Loss: (0.6975) | Acc: (75.00%) (7596/10000)
percent tensor([0.5338, 0.5402, 0.5432, 0.5386, 0.5458, 0.5427, 0.5434, 0.5397, 0.5367,
        0.5368, 0.5360, 0.5420, 0.5342, 0.5343, 0.5415, 0.5337],
       device='cuda:0') torch.Size([16])
percent tensor([0.5532, 0.5566, 0.5545, 0.5522, 0.5563, 0.5597, 0.5618, 0.5524, 0.5516,
        0.5558, 0.5541, 0.5605, 0.5496, 0.5524, 0.5605, 0.5544],
       device='cuda:0') torch.Size([16])
percent tensor([0.5385, 0.5458, 0.5320, 0.5320, 0.5326, 0.5202, 0.5416, 0.5373, 0.5399,
        0.5443, 0.5415, 0.5413, 0.5415, 0.5501, 0.5361, 0.5403],
       device='cuda:0') torch.Size([16])
percent tensor([0.5594, 0.5458, 0.5552, 0.5639, 0.5586, 0.5692, 0.5533, 0.5578, 0.5486,
        0.5512, 0.5502, 0.5532, 0.5483, 0.5437, 0.5644, 0.5589],
       device='cuda:0') torch.Size([16])
percent tensor([0.4640, 0.4596, 0.4873, 0.4946, 0.4919, 0.4715, 0.4787, 0.4894, 0.4880,
        0.4589, 0.4641, 0.4898, 0.4552, 0.4759, 0.4813, 0.4584],
       device='cuda:0') torch.Size([16])
percent tensor([0.5034, 0.5067, 0.5273, 0.5360, 0.5280, 0.5177, 0.5127, 0.5264, 0.5218,
        0.5073, 0.5112, 0.5170, 0.5009, 0.5197, 0.5036, 0.5093],
       device='cuda:0') torch.Size([16])
percent tensor([0.5307, 0.5433, 0.6239, 0.6211, 0.6386, 0.5058, 0.5768, 0.6391, 0.5825,
        0.5670, 0.5633, 0.6191, 0.5360, 0.5648, 0.5507, 0.5376],
       device='cuda:0') torch.Size([16])
percent tensor([0.9675, 0.9492, 0.9851, 0.9762, 0.9859, 0.9591, 0.9635, 0.9933, 0.9611,
        0.9786, 0.9663, 0.9816, 0.9569, 0.9476, 0.9670, 0.9762],
       device='cuda:0') torch.Size([16])
Epoch: 27 | Batch_idx: 0 |  Loss: (0.4700) |  Loss2: (0.0000) | Acc: (86.00%) (111/128)
Epoch: 27 | Batch_idx: 10 |  Loss: (0.6128) |  Loss2: (0.0000) | Acc: (78.00%) (1107/1408)
Epoch: 27 | Batch_idx: 20 |  Loss: (0.6531) |  Loss2: (0.0000) | Acc: (77.00%) (2089/2688)
Epoch: 27 | Batch_idx: 30 |  Loss: (0.6525) |  Loss2: (0.0000) | Acc: (77.00%) (3086/3968)
Epoch: 27 | Batch_idx: 40 |  Loss: (0.6531) |  Loss2: (0.0000) | Acc: (77.00%) (4074/5248)
Epoch: 27 | Batch_idx: 50 |  Loss: (0.6563) |  Loss2: (0.0000) | Acc: (77.00%) (5064/6528)
Epoch: 27 | Batch_idx: 60 |  Loss: (0.6490) |  Loss2: (0.0000) | Acc: (77.00%) (6060/7808)
Epoch: 27 | Batch_idx: 70 |  Loss: (0.6528) |  Loss2: (0.0000) | Acc: (77.00%) (7035/9088)
Epoch: 27 | Batch_idx: 80 |  Loss: (0.6578) |  Loss2: (0.0000) | Acc: (77.00%) (8006/10368)
Epoch: 27 | Batch_idx: 90 |  Loss: (0.6533) |  Loss2: (0.0000) | Acc: (77.00%) (9024/11648)
Epoch: 27 | Batch_idx: 100 |  Loss: (0.6485) |  Loss2: (0.0000) | Acc: (77.00%) (10037/12928)
Epoch: 27 | Batch_idx: 110 |  Loss: (0.6514) |  Loss2: (0.0000) | Acc: (77.00%) (11019/14208)
Epoch: 27 | Batch_idx: 120 |  Loss: (0.6538) |  Loss2: (0.0000) | Acc: (77.00%) (12014/15488)
Epoch: 27 | Batch_idx: 130 |  Loss: (0.6554) |  Loss2: (0.0000) | Acc: (77.00%) (12992/16768)
Epoch: 27 | Batch_idx: 140 |  Loss: (0.6545) |  Loss2: (0.0000) | Acc: (77.00%) (13985/18048)
Epoch: 27 | Batch_idx: 150 |  Loss: (0.6520) |  Loss2: (0.0000) | Acc: (77.00%) (14982/19328)
Epoch: 27 | Batch_idx: 160 |  Loss: (0.6546) |  Loss2: (0.0000) | Acc: (77.00%) (15956/20608)
Epoch: 27 | Batch_idx: 170 |  Loss: (0.6556) |  Loss2: (0.0000) | Acc: (77.00%) (16921/21888)
Epoch: 27 | Batch_idx: 180 |  Loss: (0.6570) |  Loss2: (0.0000) | Acc: (77.00%) (17894/23168)
Epoch: 27 | Batch_idx: 190 |  Loss: (0.6562) |  Loss2: (0.0000) | Acc: (77.00%) (18898/24448)
Epoch: 27 | Batch_idx: 200 |  Loss: (0.6540) |  Loss2: (0.0000) | Acc: (77.00%) (19907/25728)
Epoch: 27 | Batch_idx: 210 |  Loss: (0.6549) |  Loss2: (0.0000) | Acc: (77.00%) (20891/27008)
Epoch: 27 | Batch_idx: 220 |  Loss: (0.6551) |  Loss2: (0.0000) | Acc: (77.00%) (21899/28288)
Epoch: 27 | Batch_idx: 230 |  Loss: (0.6563) |  Loss2: (0.0000) | Acc: (77.00%) (22876/29568)
Epoch: 27 | Batch_idx: 240 |  Loss: (0.6578) |  Loss2: (0.0000) | Acc: (77.00%) (23844/30848)
Epoch: 27 | Batch_idx: 250 |  Loss: (0.6584) |  Loss2: (0.0000) | Acc: (77.00%) (24802/32128)
Epoch: 27 | Batch_idx: 260 |  Loss: (0.6585) |  Loss2: (0.0000) | Acc: (77.00%) (25763/33408)
Epoch: 27 | Batch_idx: 270 |  Loss: (0.6594) |  Loss2: (0.0000) | Acc: (77.00%) (26727/34688)
Epoch: 27 | Batch_idx: 280 |  Loss: (0.6604) |  Loss2: (0.0000) | Acc: (77.00%) (27698/35968)
Epoch: 27 | Batch_idx: 290 |  Loss: (0.6589) |  Loss2: (0.0000) | Acc: (77.00%) (28691/37248)
Epoch: 27 | Batch_idx: 300 |  Loss: (0.6580) |  Loss2: (0.0000) | Acc: (77.00%) (29699/38528)
Epoch: 27 | Batch_idx: 310 |  Loss: (0.6572) |  Loss2: (0.0000) | Acc: (77.00%) (30706/39808)
Epoch: 27 | Batch_idx: 320 |  Loss: (0.6564) |  Loss2: (0.0000) | Acc: (77.00%) (31693/41088)
Epoch: 27 | Batch_idx: 330 |  Loss: (0.6565) |  Loss2: (0.0000) | Acc: (77.00%) (32676/42368)
Epoch: 27 | Batch_idx: 340 |  Loss: (0.6572) |  Loss2: (0.0000) | Acc: (77.00%) (33649/43648)
Epoch: 27 | Batch_idx: 350 |  Loss: (0.6571) |  Loss2: (0.0000) | Acc: (77.00%) (34640/44928)
Epoch: 27 | Batch_idx: 360 |  Loss: (0.6570) |  Loss2: (0.0000) | Acc: (77.00%) (35630/46208)
Epoch: 27 | Batch_idx: 370 |  Loss: (0.6578) |  Loss2: (0.0000) | Acc: (77.00%) (36603/47488)
Epoch: 27 | Batch_idx: 380 |  Loss: (0.6563) |  Loss2: (0.0000) | Acc: (77.00%) (37619/48768)
Epoch: 27 | Batch_idx: 390 |  Loss: (0.6562) |  Loss2: (0.0000) | Acc: (77.00%) (38573/50000)
# TEST : Loss: (0.6926) | Acc: (76.00%) (7632/10000)
percent tensor([0.5366, 0.5437, 0.5461, 0.5419, 0.5491, 0.5464, 0.5469, 0.5430, 0.5398,
        0.5399, 0.5391, 0.5450, 0.5372, 0.5374, 0.5452, 0.5368],
       device='cuda:0') torch.Size([16])
percent tensor([0.5498, 0.5526, 0.5500, 0.5478, 0.5516, 0.5562, 0.5576, 0.5475, 0.5479,
        0.5519, 0.5509, 0.5566, 0.5462, 0.5489, 0.5566, 0.5507],
       device='cuda:0') torch.Size([16])
percent tensor([0.5408, 0.5494, 0.5344, 0.5343, 0.5352, 0.5205, 0.5448, 0.5408, 0.5433,
        0.5476, 0.5442, 0.5441, 0.5444, 0.5543, 0.5383, 0.5427],
       device='cuda:0') torch.Size([16])
percent tensor([0.5591, 0.5455, 0.5534, 0.5622, 0.5568, 0.5697, 0.5523, 0.5549, 0.5473,
        0.5508, 0.5505, 0.5524, 0.5484, 0.5430, 0.5643, 0.5586],
       device='cuda:0') torch.Size([16])
percent tensor([0.4657, 0.4598, 0.4893, 0.4976, 0.4935, 0.4744, 0.4789, 0.4911, 0.4885,
        0.4606, 0.4644, 0.4920, 0.4559, 0.4762, 0.4830, 0.4604],
       device='cuda:0') torch.Size([16])
percent tensor([0.5027, 0.5063, 0.5277, 0.5368, 0.5292, 0.5184, 0.5125, 0.5270, 0.5219,
        0.5064, 0.5113, 0.5179, 0.4996, 0.5198, 0.5033, 0.5090],
       device='cuda:0') torch.Size([16])
percent tensor([0.5281, 0.5451, 0.6271, 0.6245, 0.6431, 0.5058, 0.5775, 0.6408, 0.5861,
        0.5693, 0.5679, 0.6241, 0.5364, 0.5677, 0.5507, 0.5355],
       device='cuda:0') torch.Size([16])
percent tensor([0.9703, 0.9539, 0.9871, 0.9787, 0.9871, 0.9612, 0.9668, 0.9941, 0.9644,
        0.9806, 0.9693, 0.9839, 0.9600, 0.9510, 0.9702, 0.9785],
       device='cuda:0') torch.Size([16])
True Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=128, out_features=16, bias=False)
False Linear(in_features=16, out_features=2, bias=False)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=128, out_features=16, bias=False)
False Linear(in_features=16, out_features=2, bias=False)
True Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=256, out_features=32, bias=False)
False Linear(in_features=32, out_features=2, bias=False)
True Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=256, out_features=32, bias=False)
False Linear(in_features=32, out_features=2, bias=False)
True Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=512, out_features=64, bias=False)
False Linear(in_features=64, out_features=2, bias=False)
True Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=512, out_features=64, bias=False)
False Linear(in_features=64, out_features=2, bias=False)
True Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1024, out_features=128, bias=False)
False Linear(in_features=128, out_features=2, bias=False)
True Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1024, out_features=128, bias=False)
False Linear(in_features=128, out_features=2, bias=False)
True Linear(in_features=512, out_features=10, bias=True)
Epoch: 28 | Batch_idx: 0 |  Loss: (0.5627) |  Loss2: (0.0000) | Acc: (82.00%) (106/128)
Epoch: 28 | Batch_idx: 10 |  Loss: (0.6641) |  Loss2: (0.0000) | Acc: (77.00%) (1089/1408)
Epoch: 28 | Batch_idx: 20 |  Loss: (0.6900) |  Loss2: (0.0000) | Acc: (76.00%) (2047/2688)
Epoch: 28 | Batch_idx: 30 |  Loss: (0.6982) |  Loss2: (0.0000) | Acc: (75.00%) (3013/3968)
Epoch: 28 | Batch_idx: 40 |  Loss: (0.6966) |  Loss2: (0.0000) | Acc: (75.00%) (3979/5248)
Epoch: 28 | Batch_idx: 50 |  Loss: (0.6974) |  Loss2: (0.0000) | Acc: (75.00%) (4954/6528)
Epoch: 28 | Batch_idx: 60 |  Loss: (0.6989) |  Loss2: (0.0000) | Acc: (75.00%) (5927/7808)
Epoch: 28 | Batch_idx: 70 |  Loss: (0.6976) |  Loss2: (0.0000) | Acc: (75.00%) (6883/9088)
Epoch: 28 | Batch_idx: 80 |  Loss: (0.6901) |  Loss2: (0.0000) | Acc: (75.00%) (7865/10368)
Epoch: 28 | Batch_idx: 90 |  Loss: (0.6861) |  Loss2: (0.0000) | Acc: (75.00%) (8852/11648)
Epoch: 28 | Batch_idx: 100 |  Loss: (0.6871) |  Loss2: (0.0000) | Acc: (76.00%) (9827/12928)
Epoch: 28 | Batch_idx: 110 |  Loss: (0.6840) |  Loss2: (0.0000) | Acc: (76.00%) (10799/14208)
Epoch: 28 | Batch_idx: 120 |  Loss: (0.6815) |  Loss2: (0.0000) | Acc: (76.00%) (11797/15488)
Epoch: 28 | Batch_idx: 130 |  Loss: (0.6827) |  Loss2: (0.0000) | Acc: (76.00%) (12756/16768)
Epoch: 28 | Batch_idx: 140 |  Loss: (0.6847) |  Loss2: (0.0000) | Acc: (76.00%) (13736/18048)
Epoch: 28 | Batch_idx: 150 |  Loss: (0.6865) |  Loss2: (0.0000) | Acc: (76.00%) (14700/19328)
Epoch: 28 | Batch_idx: 160 |  Loss: (0.6874) |  Loss2: (0.0000) | Acc: (76.00%) (15666/20608)
Epoch: 28 | Batch_idx: 170 |  Loss: (0.6858) |  Loss2: (0.0000) | Acc: (75.00%) (16629/21888)
Epoch: 28 | Batch_idx: 180 |  Loss: (0.6849) |  Loss2: (0.0000) | Acc: (75.00%) (17600/23168)
Epoch: 28 | Batch_idx: 190 |  Loss: (0.6850) |  Loss2: (0.0000) | Acc: (75.00%) (18575/24448)
Epoch: 28 | Batch_idx: 200 |  Loss: (0.6830) |  Loss2: (0.0000) | Acc: (76.00%) (19575/25728)
Epoch: 28 | Batch_idx: 210 |  Loss: (0.6818) |  Loss2: (0.0000) | Acc: (76.00%) (20556/27008)
Epoch: 28 | Batch_idx: 220 |  Loss: (0.6812) |  Loss2: (0.0000) | Acc: (76.00%) (21538/28288)
Epoch: 28 | Batch_idx: 230 |  Loss: (0.6801) |  Loss2: (0.0000) | Acc: (76.00%) (22521/29568)
Epoch: 28 | Batch_idx: 240 |  Loss: (0.6793) |  Loss2: (0.0000) | Acc: (76.00%) (23503/30848)
Epoch: 28 | Batch_idx: 250 |  Loss: (0.6783) |  Loss2: (0.0000) | Acc: (76.00%) (24483/32128)
Epoch: 28 | Batch_idx: 260 |  Loss: (0.6761) |  Loss2: (0.0000) | Acc: (76.00%) (25491/33408)
Epoch: 28 | Batch_idx: 270 |  Loss: (0.6751) |  Loss2: (0.0000) | Acc: (76.00%) (26476/34688)
Epoch: 28 | Batch_idx: 280 |  Loss: (0.6746) |  Loss2: (0.0000) | Acc: (76.00%) (27453/35968)
Epoch: 28 | Batch_idx: 290 |  Loss: (0.6724) |  Loss2: (0.0000) | Acc: (76.00%) (28468/37248)
Epoch: 28 | Batch_idx: 300 |  Loss: (0.6717) |  Loss2: (0.0000) | Acc: (76.00%) (29460/38528)
Epoch: 28 | Batch_idx: 310 |  Loss: (0.6713) |  Loss2: (0.0000) | Acc: (76.00%) (30444/39808)
Epoch: 28 | Batch_idx: 320 |  Loss: (0.6706) |  Loss2: (0.0000) | Acc: (76.00%) (31447/41088)
Epoch: 28 | Batch_idx: 330 |  Loss: (0.6705) |  Loss2: (0.0000) | Acc: (76.00%) (32442/42368)
Epoch: 28 | Batch_idx: 340 |  Loss: (0.6690) |  Loss2: (0.0000) | Acc: (76.00%) (33448/43648)
Epoch: 28 | Batch_idx: 350 |  Loss: (0.6692) |  Loss2: (0.0000) | Acc: (76.00%) (34439/44928)
Epoch: 28 | Batch_idx: 360 |  Loss: (0.6692) |  Loss2: (0.0000) | Acc: (76.00%) (35420/46208)
Epoch: 28 | Batch_idx: 370 |  Loss: (0.6676) |  Loss2: (0.0000) | Acc: (76.00%) (36413/47488)
Epoch: 28 | Batch_idx: 380 |  Loss: (0.6663) |  Loss2: (0.0000) | Acc: (76.00%) (37429/48768)
Epoch: 28 | Batch_idx: 390 |  Loss: (0.6664) |  Loss2: (0.0000) | Acc: (76.00%) (38364/50000)
# TEST : Loss: (0.7606) | Acc: (74.00%) (7419/10000)
percent tensor([0.5391, 0.5438, 0.5494, 0.5440, 0.5517, 0.5487, 0.5479, 0.5445, 0.5406,
        0.5411, 0.5405, 0.5475, 0.5391, 0.5361, 0.5465, 0.5382],
       device='cuda:0') torch.Size([16])
percent tensor([0.5502, 0.5524, 0.5515, 0.5474, 0.5551, 0.5571, 0.5583, 0.5485, 0.5497,
        0.5534, 0.5519, 0.5600, 0.5470, 0.5481, 0.5569, 0.5509],
       device='cuda:0') torch.Size([16])
percent tensor([0.5420, 0.5483, 0.5377, 0.5353, 0.5382, 0.5241, 0.5441, 0.5431, 0.5443,
        0.5486, 0.5447, 0.5441, 0.5448, 0.5526, 0.5397, 0.5437],
       device='cuda:0') torch.Size([16])
percent tensor([0.5582, 0.5451, 0.5530, 0.5588, 0.5572, 0.5704, 0.5527, 0.5511, 0.5508,
        0.5505, 0.5499, 0.5543, 0.5483, 0.5492, 0.5631, 0.5567],
       device='cuda:0') torch.Size([16])
percent tensor([0.4628, 0.4566, 0.4900, 0.4944, 0.4912, 0.4764, 0.4727, 0.4889, 0.4860,
        0.4569, 0.4636, 0.4929, 0.4528, 0.4798, 0.4820, 0.4575],
       device='cuda:0') torch.Size([16])
percent tensor([0.4985, 0.5019, 0.5255, 0.5338, 0.5249, 0.5153, 0.5104, 0.5164, 0.5222,
        0.5062, 0.5118, 0.5230, 0.4989, 0.5204, 0.4984, 0.5028],
       device='cuda:0') torch.Size([16])
percent tensor([0.5349, 0.5528, 0.6080, 0.6148, 0.6492, 0.5175, 0.5767, 0.6276, 0.5819,
        0.5637, 0.5730, 0.6011, 0.5380, 0.5785, 0.5634, 0.5428],
       device='cuda:0') torch.Size([16])
percent tensor([0.9765, 0.9675, 0.9787, 0.9752, 0.9921, 0.9713, 0.9798, 0.9939, 0.9643,
        0.9766, 0.9716, 0.9750, 0.9620, 0.9631, 0.9815, 0.9842],
       device='cuda:0') torch.Size([16])
Epoch: 29 | Batch_idx: 0 |  Loss: (0.5916) |  Loss2: (0.0000) | Acc: (78.00%) (101/128)
Epoch: 29 | Batch_idx: 10 |  Loss: (0.6411) |  Loss2: (0.0000) | Acc: (77.00%) (1089/1408)
Epoch: 29 | Batch_idx: 20 |  Loss: (0.6455) |  Loss2: (0.0000) | Acc: (77.00%) (2087/2688)
Epoch: 29 | Batch_idx: 30 |  Loss: (0.6481) |  Loss2: (0.0000) | Acc: (77.00%) (3062/3968)
Epoch: 29 | Batch_idx: 40 |  Loss: (0.6473) |  Loss2: (0.0000) | Acc: (77.00%) (4064/5248)
Epoch: 29 | Batch_idx: 50 |  Loss: (0.6513) |  Loss2: (0.0000) | Acc: (77.00%) (5044/6528)
Epoch: 29 | Batch_idx: 60 |  Loss: (0.6493) |  Loss2: (0.0000) | Acc: (77.00%) (6039/7808)
Epoch: 29 | Batch_idx: 70 |  Loss: (0.6461) |  Loss2: (0.0000) | Acc: (77.00%) (7037/9088)
Epoch: 29 | Batch_idx: 80 |  Loss: (0.6524) |  Loss2: (0.0000) | Acc: (77.00%) (7999/10368)
Epoch: 29 | Batch_idx: 90 |  Loss: (0.6496) |  Loss2: (0.0000) | Acc: (77.00%) (9003/11648)
Epoch: 29 | Batch_idx: 100 |  Loss: (0.6488) |  Loss2: (0.0000) | Acc: (77.00%) (9990/12928)
Epoch: 29 | Batch_idx: 110 |  Loss: (0.6469) |  Loss2: (0.0000) | Acc: (77.00%) (10969/14208)
Epoch: 29 | Batch_idx: 120 |  Loss: (0.6481) |  Loss2: (0.0000) | Acc: (77.00%) (11946/15488)
Epoch: 29 | Batch_idx: 130 |  Loss: (0.6478) |  Loss2: (0.0000) | Acc: (77.00%) (12937/16768)
Epoch: 29 | Batch_idx: 140 |  Loss: (0.6446) |  Loss2: (0.0000) | Acc: (77.00%) (13956/18048)
Epoch: 29 | Batch_idx: 150 |  Loss: (0.6417) |  Loss2: (0.0000) | Acc: (77.00%) (14961/19328)
Epoch: 29 | Batch_idx: 160 |  Loss: (0.6412) |  Loss2: (0.0000) | Acc: (77.00%) (15944/20608)
Epoch: 29 | Batch_idx: 170 |  Loss: (0.6403) |  Loss2: (0.0000) | Acc: (77.00%) (16950/21888)
Epoch: 29 | Batch_idx: 180 |  Loss: (0.6380) |  Loss2: (0.0000) | Acc: (77.00%) (17972/23168)
Epoch: 29 | Batch_idx: 190 |  Loss: (0.6354) |  Loss2: (0.0000) | Acc: (77.00%) (18992/24448)
Epoch: 29 | Batch_idx: 200 |  Loss: (0.6338) |  Loss2: (0.0000) | Acc: (77.00%) (19989/25728)
Epoch: 29 | Batch_idx: 210 |  Loss: (0.6344) |  Loss2: (0.0000) | Acc: (77.00%) (20974/27008)
Epoch: 29 | Batch_idx: 220 |  Loss: (0.6329) |  Loss2: (0.0000) | Acc: (77.00%) (21985/28288)
Epoch: 29 | Batch_idx: 230 |  Loss: (0.6305) |  Loss2: (0.0000) | Acc: (77.00%) (23018/29568)
Epoch: 29 | Batch_idx: 240 |  Loss: (0.6290) |  Loss2: (0.0000) | Acc: (77.00%) (24023/30848)
Epoch: 29 | Batch_idx: 250 |  Loss: (0.6288) |  Loss2: (0.0000) | Acc: (77.00%) (25033/32128)
Epoch: 29 | Batch_idx: 260 |  Loss: (0.6270) |  Loss2: (0.0000) | Acc: (77.00%) (26046/33408)
Epoch: 29 | Batch_idx: 270 |  Loss: (0.6273) |  Loss2: (0.0000) | Acc: (77.00%) (27049/34688)
Epoch: 29 | Batch_idx: 280 |  Loss: (0.6275) |  Loss2: (0.0000) | Acc: (77.00%) (28037/35968)
Epoch: 29 | Batch_idx: 290 |  Loss: (0.6283) |  Loss2: (0.0000) | Acc: (77.00%) (29034/37248)
Epoch: 29 | Batch_idx: 300 |  Loss: (0.6289) |  Loss2: (0.0000) | Acc: (77.00%) (30025/38528)
Epoch: 29 | Batch_idx: 310 |  Loss: (0.6299) |  Loss2: (0.0000) | Acc: (77.00%) (31017/39808)
Epoch: 29 | Batch_idx: 320 |  Loss: (0.6298) |  Loss2: (0.0000) | Acc: (77.00%) (32016/41088)
Epoch: 29 | Batch_idx: 330 |  Loss: (0.6298) |  Loss2: (0.0000) | Acc: (77.00%) (33014/42368)
Epoch: 29 | Batch_idx: 340 |  Loss: (0.6290) |  Loss2: (0.0000) | Acc: (77.00%) (34021/43648)
Epoch: 29 | Batch_idx: 350 |  Loss: (0.6287) |  Loss2: (0.0000) | Acc: (77.00%) (35029/44928)
Epoch: 29 | Batch_idx: 360 |  Loss: (0.6278) |  Loss2: (0.0000) | Acc: (77.00%) (36036/46208)
Epoch: 29 | Batch_idx: 370 |  Loss: (0.6271) |  Loss2: (0.0000) | Acc: (78.00%) (37041/47488)
Epoch: 29 | Batch_idx: 380 |  Loss: (0.6264) |  Loss2: (0.0000) | Acc: (78.00%) (38054/48768)
Epoch: 29 | Batch_idx: 390 |  Loss: (0.6264) |  Loss2: (0.0000) | Acc: (78.00%) (39030/50000)
# TEST : Loss: (0.6937) | Acc: (76.00%) (7618/10000)
percent tensor([0.5380, 0.5429, 0.5476, 0.5434, 0.5505, 0.5475, 0.5469, 0.5435, 0.5395,
        0.5405, 0.5389, 0.5462, 0.5387, 0.5359, 0.5456, 0.5376],
       device='cuda:0') torch.Size([16])
percent tensor([0.5486, 0.5519, 0.5491, 0.5474, 0.5508, 0.5562, 0.5562, 0.5489, 0.5469,
        0.5517, 0.5510, 0.5575, 0.5456, 0.5483, 0.5562, 0.5500],
       device='cuda:0') torch.Size([16])
percent tensor([0.5439, 0.5501, 0.5375, 0.5333, 0.5372, 0.5228, 0.5434, 0.5416, 0.5441,
        0.5504, 0.5461, 0.5453, 0.5476, 0.5533, 0.5391, 0.5448],
       device='cuda:0') torch.Size([16])
percent tensor([0.5580, 0.5475, 0.5499, 0.5602, 0.5530, 0.5699, 0.5533, 0.5534, 0.5497,
        0.5495, 0.5520, 0.5509, 0.5488, 0.5516, 0.5650, 0.5580],
       device='cuda:0') torch.Size([16])
percent tensor([0.4641, 0.4647, 0.4853, 0.4976, 0.4895, 0.4817, 0.4794, 0.4883, 0.4888,
        0.4590, 0.4682, 0.4934, 0.4536, 0.4903, 0.4873, 0.4612],
       device='cuda:0') torch.Size([16])
percent tensor([0.4989, 0.5079, 0.5233, 0.5322, 0.5258, 0.5208, 0.5125, 0.5230, 0.5246,
        0.5053, 0.5148, 0.5215, 0.5003, 0.5244, 0.5041, 0.5068],
       device='cuda:0') torch.Size([16])
percent tensor([0.5284, 0.5370, 0.6053, 0.6174, 0.6357, 0.5222, 0.5726, 0.6222, 0.5771,
        0.5491, 0.5544, 0.6083, 0.5222, 0.5730, 0.5495, 0.5296],
       device='cuda:0') torch.Size([16])
percent tensor([0.9753, 0.9572, 0.9842, 0.9780, 0.9869, 0.9619, 0.9766, 0.9930, 0.9584,
        0.9720, 0.9623, 0.9810, 0.9535, 0.9612, 0.9803, 0.9763],
       device='cuda:0') torch.Size([16])
Epoch: 30 | Batch_idx: 0 |  Loss: (0.6086) |  Loss2: (0.0000) | Acc: (75.00%) (96/128)
Epoch: 30 | Batch_idx: 10 |  Loss: (0.5922) |  Loss2: (0.0000) | Acc: (78.00%) (1101/1408)
Epoch: 30 | Batch_idx: 20 |  Loss: (0.5887) |  Loss2: (0.0000) | Acc: (78.00%) (2123/2688)
Epoch: 30 | Batch_idx: 30 |  Loss: (0.6036) |  Loss2: (0.0000) | Acc: (78.00%) (3119/3968)
Epoch: 30 | Batch_idx: 40 |  Loss: (0.5961) |  Loss2: (0.0000) | Acc: (79.00%) (4148/5248)
Epoch: 30 | Batch_idx: 50 |  Loss: (0.5952) |  Loss2: (0.0000) | Acc: (78.00%) (5156/6528)
Epoch: 30 | Batch_idx: 60 |  Loss: (0.5970) |  Loss2: (0.0000) | Acc: (78.00%) (6165/7808)
Epoch: 30 | Batch_idx: 70 |  Loss: (0.5943) |  Loss2: (0.0000) | Acc: (78.00%) (7175/9088)
Epoch: 30 | Batch_idx: 80 |  Loss: (0.5996) |  Loss2: (0.0000) | Acc: (78.00%) (8164/10368)
Epoch: 30 | Batch_idx: 90 |  Loss: (0.5947) |  Loss2: (0.0000) | Acc: (78.00%) (9197/11648)
Epoch: 30 | Batch_idx: 100 |  Loss: (0.5971) |  Loss2: (0.0000) | Acc: (78.00%) (10187/12928)
Epoch: 30 | Batch_idx: 110 |  Loss: (0.5965) |  Loss2: (0.0000) | Acc: (78.00%) (11189/14208)
Epoch: 30 | Batch_idx: 120 |  Loss: (0.5993) |  Loss2: (0.0000) | Acc: (78.00%) (12190/15488)
Epoch: 30 | Batch_idx: 130 |  Loss: (0.5967) |  Loss2: (0.0000) | Acc: (78.00%) (13223/16768)
Epoch: 30 | Batch_idx: 140 |  Loss: (0.5960) |  Loss2: (0.0000) | Acc: (78.00%) (14243/18048)
Epoch: 30 | Batch_idx: 150 |  Loss: (0.5966) |  Loss2: (0.0000) | Acc: (78.00%) (15254/19328)
Epoch: 30 | Batch_idx: 160 |  Loss: (0.5971) |  Loss2: (0.0000) | Acc: (78.00%) (16269/20608)
Epoch: 30 | Batch_idx: 170 |  Loss: (0.5998) |  Loss2: (0.0000) | Acc: (78.00%) (17251/21888)
Epoch: 30 | Batch_idx: 180 |  Loss: (0.6028) |  Loss2: (0.0000) | Acc: (78.00%) (18241/23168)
Epoch: 30 | Batch_idx: 190 |  Loss: (0.6018) |  Loss2: (0.0000) | Acc: (78.00%) (19262/24448)
Epoch: 30 | Batch_idx: 200 |  Loss: (0.6009) |  Loss2: (0.0000) | Acc: (78.00%) (20285/25728)
Epoch: 30 | Batch_idx: 210 |  Loss: (0.6013) |  Loss2: (0.0000) | Acc: (78.00%) (21285/27008)
Epoch: 30 | Batch_idx: 220 |  Loss: (0.6016) |  Loss2: (0.0000) | Acc: (78.00%) (22283/28288)
Epoch: 30 | Batch_idx: 230 |  Loss: (0.6019) |  Loss2: (0.0000) | Acc: (78.00%) (23294/29568)
Epoch: 30 | Batch_idx: 240 |  Loss: (0.6018) |  Loss2: (0.0000) | Acc: (78.00%) (24307/30848)
Epoch: 30 | Batch_idx: 250 |  Loss: (0.6020) |  Loss2: (0.0000) | Acc: (78.00%) (25311/32128)
Epoch: 30 | Batch_idx: 260 |  Loss: (0.6025) |  Loss2: (0.0000) | Acc: (78.00%) (26322/33408)
Epoch: 30 | Batch_idx: 270 |  Loss: (0.6017) |  Loss2: (0.0000) | Acc: (78.00%) (27344/34688)
Epoch: 30 | Batch_idx: 280 |  Loss: (0.6009) |  Loss2: (0.0000) | Acc: (78.00%) (28360/35968)
Epoch: 30 | Batch_idx: 290 |  Loss: (0.5997) |  Loss2: (0.0000) | Acc: (78.00%) (29382/37248)
Epoch: 30 | Batch_idx: 300 |  Loss: (0.5979) |  Loss2: (0.0000) | Acc: (78.00%) (30414/38528)
Epoch: 30 | Batch_idx: 310 |  Loss: (0.5979) |  Loss2: (0.0000) | Acc: (78.00%) (31414/39808)
Epoch: 30 | Batch_idx: 320 |  Loss: (0.5976) |  Loss2: (0.0000) | Acc: (78.00%) (32435/41088)
Epoch: 30 | Batch_idx: 330 |  Loss: (0.5980) |  Loss2: (0.0000) | Acc: (78.00%) (33443/42368)
Epoch: 30 | Batch_idx: 340 |  Loss: (0.5974) |  Loss2: (0.0000) | Acc: (78.00%) (34469/43648)
Epoch: 30 | Batch_idx: 350 |  Loss: (0.5968) |  Loss2: (0.0000) | Acc: (79.00%) (35495/44928)
Epoch: 30 | Batch_idx: 360 |  Loss: (0.5948) |  Loss2: (0.0000) | Acc: (79.00%) (36542/46208)
Epoch: 30 | Batch_idx: 370 |  Loss: (0.5939) |  Loss2: (0.0000) | Acc: (79.00%) (37567/47488)
Epoch: 30 | Batch_idx: 380 |  Loss: (0.5937) |  Loss2: (0.0000) | Acc: (79.00%) (38591/48768)
Epoch: 30 | Batch_idx: 390 |  Loss: (0.5946) |  Loss2: (0.0000) | Acc: (79.00%) (39564/50000)
=> saving checkpoint 'drive/app/torch/save_Schedule/checkpoint_030.pth.tar'
# TEST : Loss: (0.7387) | Acc: (74.00%) (7450/10000)
percent tensor([0.5385, 0.5433, 0.5479, 0.5442, 0.5510, 0.5474, 0.5469, 0.5440, 0.5394,
        0.5409, 0.5390, 0.5462, 0.5390, 0.5355, 0.5460, 0.5381],
       device='cuda:0') torch.Size([16])
percent tensor([0.5497, 0.5532, 0.5496, 0.5477, 0.5519, 0.5573, 0.5573, 0.5496, 0.5487,
        0.5523, 0.5524, 0.5574, 0.5470, 0.5509, 0.5568, 0.5513],
       device='cuda:0') torch.Size([16])
percent tensor([0.5435, 0.5486, 0.5390, 0.5327, 0.5367, 0.5230, 0.5422, 0.5404, 0.5453,
        0.5489, 0.5459, 0.5453, 0.5462, 0.5538, 0.5389, 0.5440],
       device='cuda:0') torch.Size([16])
percent tensor([0.5586, 0.5484, 0.5487, 0.5571, 0.5515, 0.5729, 0.5527, 0.5494, 0.5514,
        0.5499, 0.5529, 0.5498, 0.5482, 0.5546, 0.5644, 0.5593],
       device='cuda:0') torch.Size([16])
percent tensor([0.4689, 0.4616, 0.4879, 0.4995, 0.4922, 0.4863, 0.4754, 0.4909, 0.4906,
        0.4588, 0.4662, 0.4915, 0.4551, 0.4885, 0.4879, 0.4615],
       device='cuda:0') torch.Size([16])
percent tensor([0.5038, 0.5016, 0.5243, 0.5329, 0.5238, 0.5243, 0.5081, 0.5193, 0.5238,
        0.5043, 0.5159, 0.5222, 0.4992, 0.5233, 0.5058, 0.5049],
       device='cuda:0') torch.Size([16])
percent tensor([0.5378, 0.5425, 0.6085, 0.6170, 0.6400, 0.5256, 0.5735, 0.6184, 0.5851,
        0.5616, 0.5595, 0.6100, 0.5346, 0.5712, 0.5596, 0.5351],
       device='cuda:0') torch.Size([16])
percent tensor([0.9744, 0.9648, 0.9742, 0.9730, 0.9851, 0.9623, 0.9730, 0.9908, 0.9674,
        0.9796, 0.9598, 0.9768, 0.9669, 0.9642, 0.9791, 0.9785],
       device='cuda:0') torch.Size([16])
Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 3, 3, 3]) tensor(173.8078, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(784.2868, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(791.3708, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([128, 64, 3, 3]) tensor(1533.3527, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([128, 64, 1, 1]) tensor(511.3082, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([128, 128, 3, 3]) tensor(2183.7664, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([256, 128, 3, 3]) tensor(4312.1470, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([256, 128, 1, 1]) tensor(1424.3632, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([256, 256, 3, 3]) tensor(6081.4966, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([512, 256, 3, 3]) tensor(12134.2480, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([512, 256, 1, 1]) tensor(4047.3984, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([512, 512, 3, 3]) tensor(17122.3633, device='cuda:0', grad_fn=<NormBackward0>)
Epoch: 31 | Batch_idx: 0 |  Loss: (0.6612) |  Loss2: (0.0000) | Acc: (78.00%) (100/128)
Epoch: 31 | Batch_idx: 10 |  Loss: (0.5852) |  Loss2: (0.0000) | Acc: (78.00%) (1111/1408)
Epoch: 31 | Batch_idx: 20 |  Loss: (0.5742) |  Loss2: (0.0000) | Acc: (79.00%) (2132/2688)
Epoch: 31 | Batch_idx: 30 |  Loss: (0.5650) |  Loss2: (0.0000) | Acc: (79.00%) (3170/3968)
Epoch: 31 | Batch_idx: 40 |  Loss: (0.5623) |  Loss2: (0.0000) | Acc: (79.00%) (4197/5248)
Epoch: 31 | Batch_idx: 50 |  Loss: (0.5546) |  Loss2: (0.0000) | Acc: (80.00%) (5246/6528)
Epoch: 31 | Batch_idx: 60 |  Loss: (0.5594) |  Loss2: (0.0000) | Acc: (80.00%) (6252/7808)
Epoch: 31 | Batch_idx: 70 |  Loss: (0.5598) |  Loss2: (0.0000) | Acc: (80.00%) (7279/9088)
Epoch: 31 | Batch_idx: 80 |  Loss: (0.5592) |  Loss2: (0.0000) | Acc: (80.00%) (8310/10368)
Epoch: 31 | Batch_idx: 90 |  Loss: (0.5609) |  Loss2: (0.0000) | Acc: (80.00%) (9336/11648)
Epoch: 31 | Batch_idx: 100 |  Loss: (0.5609) |  Loss2: (0.0000) | Acc: (80.00%) (10362/12928)
Epoch: 31 | Batch_idx: 110 |  Loss: (0.5600) |  Loss2: (0.0000) | Acc: (80.00%) (11388/14208)
Epoch: 31 | Batch_idx: 120 |  Loss: (0.5607) |  Loss2: (0.0000) | Acc: (80.00%) (12402/15488)
Epoch: 31 | Batch_idx: 130 |  Loss: (0.5588) |  Loss2: (0.0000) | Acc: (80.00%) (13440/16768)
Epoch: 31 | Batch_idx: 140 |  Loss: (0.5611) |  Loss2: (0.0000) | Acc: (80.00%) (14457/18048)
Epoch: 31 | Batch_idx: 150 |  Loss: (0.5614) |  Loss2: (0.0000) | Acc: (80.00%) (15489/19328)
Epoch: 31 | Batch_idx: 160 |  Loss: (0.5607) |  Loss2: (0.0000) | Acc: (80.00%) (16548/20608)
Epoch: 31 | Batch_idx: 170 |  Loss: (0.5620) |  Loss2: (0.0000) | Acc: (80.00%) (17569/21888)
Epoch: 31 | Batch_idx: 180 |  Loss: (0.5606) |  Loss2: (0.0000) | Acc: (80.00%) (18597/23168)
Epoch: 31 | Batch_idx: 190 |  Loss: (0.5584) |  Loss2: (0.0000) | Acc: (80.00%) (19643/24448)
Epoch: 31 | Batch_idx: 200 |  Loss: (0.5595) |  Loss2: (0.0000) | Acc: (80.00%) (20655/25728)
Epoch: 31 | Batch_idx: 210 |  Loss: (0.5596) |  Loss2: (0.0000) | Acc: (80.00%) (21692/27008)
Epoch: 31 | Batch_idx: 220 |  Loss: (0.5605) |  Loss2: (0.0000) | Acc: (80.00%) (22705/28288)
Epoch: 31 | Batch_idx: 230 |  Loss: (0.5627) |  Loss2: (0.0000) | Acc: (80.00%) (23695/29568)
Epoch: 31 | Batch_idx: 240 |  Loss: (0.5626) |  Loss2: (0.0000) | Acc: (80.00%) (24727/30848)
Epoch: 31 | Batch_idx: 250 |  Loss: (0.5625) |  Loss2: (0.0000) | Acc: (80.00%) (25762/32128)
Epoch: 31 | Batch_idx: 260 |  Loss: (0.5620) |  Loss2: (0.0000) | Acc: (80.00%) (26819/33408)
Epoch: 31 | Batch_idx: 270 |  Loss: (0.5632) |  Loss2: (0.0000) | Acc: (80.00%) (27843/34688)
Epoch: 31 | Batch_idx: 280 |  Loss: (0.5641) |  Loss2: (0.0000) | Acc: (80.00%) (28865/35968)
Epoch: 31 | Batch_idx: 290 |  Loss: (0.5647) |  Loss2: (0.0000) | Acc: (80.00%) (29886/37248)
Epoch: 31 | Batch_idx: 300 |  Loss: (0.5663) |  Loss2: (0.0000) | Acc: (80.00%) (30876/38528)
Epoch: 31 | Batch_idx: 310 |  Loss: (0.5655) |  Loss2: (0.0000) | Acc: (80.00%) (31918/39808)
Epoch: 31 | Batch_idx: 320 |  Loss: (0.5651) |  Loss2: (0.0000) | Acc: (80.00%) (32955/41088)
Epoch: 31 | Batch_idx: 330 |  Loss: (0.5660) |  Loss2: (0.0000) | Acc: (80.00%) (33982/42368)
Epoch: 31 | Batch_idx: 340 |  Loss: (0.5661) |  Loss2: (0.0000) | Acc: (80.00%) (35018/43648)
Epoch: 31 | Batch_idx: 350 |  Loss: (0.5653) |  Loss2: (0.0000) | Acc: (80.00%) (36050/44928)
Epoch: 31 | Batch_idx: 360 |  Loss: (0.5652) |  Loss2: (0.0000) | Acc: (80.00%) (37084/46208)
Epoch: 31 | Batch_idx: 370 |  Loss: (0.5649) |  Loss2: (0.0000) | Acc: (80.00%) (38113/47488)
Epoch: 31 | Batch_idx: 380 |  Loss: (0.5656) |  Loss2: (0.0000) | Acc: (80.00%) (39149/48768)
Epoch: 31 | Batch_idx: 390 |  Loss: (0.5648) |  Loss2: (0.0000) | Acc: (80.00%) (40159/50000)
# TEST : Loss: (0.6963) | Acc: (76.00%) (7631/10000)
percent tensor([0.5377, 0.5431, 0.5494, 0.5445, 0.5521, 0.5466, 0.5476, 0.5447, 0.5401,
        0.5415, 0.5383, 0.5479, 0.5386, 0.5368, 0.5457, 0.5381],
       device='cuda:0') torch.Size([16])
percent tensor([0.5489, 0.5529, 0.5495, 0.5482, 0.5519, 0.5559, 0.5579, 0.5493, 0.5481,
        0.5522, 0.5513, 0.5578, 0.5461, 0.5507, 0.5566, 0.5504],
       device='cuda:0') torch.Size([16])
percent tensor([0.5444, 0.5503, 0.5367, 0.5353, 0.5363, 0.5236, 0.5451, 0.5400, 0.5447,
        0.5509, 0.5475, 0.5476, 0.5478, 0.5579, 0.5404, 0.5461],
       device='cuda:0') torch.Size([16])
percent tensor([0.5579, 0.5475, 0.5552, 0.5610, 0.5559, 0.5670, 0.5554, 0.5549, 0.5526,
        0.5515, 0.5506, 0.5548, 0.5486, 0.5534, 0.5612, 0.5569],
       device='cuda:0') torch.Size([16])
percent tensor([0.4635, 0.4653, 0.4916, 0.4985, 0.4945, 0.4804, 0.4817, 0.4928, 0.4910,
        0.4624, 0.4666, 0.4949, 0.4538, 0.4906, 0.4861, 0.4597],
       device='cuda:0') torch.Size([16])
percent tensor([0.5008, 0.5089, 0.5226, 0.5316, 0.5255, 0.5178, 0.5169, 0.5228, 0.5235,
        0.5108, 0.5160, 0.5253, 0.5005, 0.5271, 0.5023, 0.5036],
       device='cuda:0') torch.Size([16])
percent tensor([0.5349, 0.5451, 0.6109, 0.6199, 0.6410, 0.5278, 0.5840, 0.6250, 0.5886,
        0.5598, 0.5635, 0.6182, 0.5357, 0.5863, 0.5585, 0.5333],
       device='cuda:0') torch.Size([16])
percent tensor([0.9757, 0.9615, 0.9819, 0.9777, 0.9919, 0.9684, 0.9801, 0.9939, 0.9653,
        0.9767, 0.9682, 0.9806, 0.9623, 0.9748, 0.9807, 0.9785],
       device='cuda:0') torch.Size([16])
Epoch: 32 | Batch_idx: 0 |  Loss: (0.6031) |  Loss2: (0.0000) | Acc: (78.00%) (101/128)
Epoch: 32 | Batch_idx: 10 |  Loss: (0.5267) |  Loss2: (0.0000) | Acc: (81.00%) (1150/1408)
Epoch: 32 | Batch_idx: 20 |  Loss: (0.5296) |  Loss2: (0.0000) | Acc: (81.00%) (2194/2688)
Epoch: 32 | Batch_idx: 30 |  Loss: (0.5340) |  Loss2: (0.0000) | Acc: (81.00%) (3236/3968)
Epoch: 32 | Batch_idx: 40 |  Loss: (0.5318) |  Loss2: (0.0000) | Acc: (81.00%) (4277/5248)
Epoch: 32 | Batch_idx: 50 |  Loss: (0.5317) |  Loss2: (0.0000) | Acc: (81.00%) (5333/6528)
Epoch: 32 | Batch_idx: 60 |  Loss: (0.5289) |  Loss2: (0.0000) | Acc: (81.00%) (6385/7808)
Epoch: 32 | Batch_idx: 70 |  Loss: (0.5279) |  Loss2: (0.0000) | Acc: (81.00%) (7431/9088)
Epoch: 32 | Batch_idx: 80 |  Loss: (0.5334) |  Loss2: (0.0000) | Acc: (81.00%) (8467/10368)
Epoch: 32 | Batch_idx: 90 |  Loss: (0.5359) |  Loss2: (0.0000) | Acc: (81.00%) (9501/11648)
Epoch: 32 | Batch_idx: 100 |  Loss: (0.5393) |  Loss2: (0.0000) | Acc: (81.00%) (10530/12928)
Epoch: 32 | Batch_idx: 110 |  Loss: (0.5408) |  Loss2: (0.0000) | Acc: (81.00%) (11544/14208)
Epoch: 32 | Batch_idx: 120 |  Loss: (0.5410) |  Loss2: (0.0000) | Acc: (81.00%) (12593/15488)
Epoch: 32 | Batch_idx: 130 |  Loss: (0.5421) |  Loss2: (0.0000) | Acc: (81.00%) (13619/16768)
Epoch: 32 | Batch_idx: 140 |  Loss: (0.5413) |  Loss2: (0.0000) | Acc: (81.00%) (14670/18048)
Epoch: 32 | Batch_idx: 150 |  Loss: (0.5400) |  Loss2: (0.0000) | Acc: (81.00%) (15715/19328)
Epoch: 32 | Batch_idx: 160 |  Loss: (0.5382) |  Loss2: (0.0000) | Acc: (81.00%) (16770/20608)
Epoch: 32 | Batch_idx: 170 |  Loss: (0.5387) |  Loss2: (0.0000) | Acc: (81.00%) (17799/21888)
Epoch: 32 | Batch_idx: 180 |  Loss: (0.5413) |  Loss2: (0.0000) | Acc: (81.00%) (18809/23168)
Epoch: 32 | Batch_idx: 190 |  Loss: (0.5436) |  Loss2: (0.0000) | Acc: (81.00%) (19830/24448)
Epoch: 32 | Batch_idx: 200 |  Loss: (0.5449) |  Loss2: (0.0000) | Acc: (81.00%) (20850/25728)
Epoch: 32 | Batch_idx: 210 |  Loss: (0.5444) |  Loss2: (0.0000) | Acc: (81.00%) (21903/27008)
Epoch: 32 | Batch_idx: 220 |  Loss: (0.5459) |  Loss2: (0.0000) | Acc: (81.00%) (22927/28288)
Epoch: 32 | Batch_idx: 230 |  Loss: (0.5451) |  Loss2: (0.0000) | Acc: (81.00%) (23972/29568)
Epoch: 32 | Batch_idx: 240 |  Loss: (0.5452) |  Loss2: (0.0000) | Acc: (81.00%) (25009/30848)
Epoch: 32 | Batch_idx: 250 |  Loss: (0.5450) |  Loss2: (0.0000) | Acc: (81.00%) (26038/32128)
Epoch: 32 | Batch_idx: 260 |  Loss: (0.5453) |  Loss2: (0.0000) | Acc: (81.00%) (27079/33408)
Epoch: 32 | Batch_idx: 270 |  Loss: (0.5449) |  Loss2: (0.0000) | Acc: (81.00%) (28108/34688)
Epoch: 32 | Batch_idx: 280 |  Loss: (0.5437) |  Loss2: (0.0000) | Acc: (81.00%) (29161/35968)
Epoch: 32 | Batch_idx: 290 |  Loss: (0.5439) |  Loss2: (0.0000) | Acc: (81.00%) (30201/37248)
Epoch: 32 | Batch_idx: 300 |  Loss: (0.5429) |  Loss2: (0.0000) | Acc: (81.00%) (31253/38528)
Epoch: 32 | Batch_idx: 310 |  Loss: (0.5426) |  Loss2: (0.0000) | Acc: (81.00%) (32295/39808)
Epoch: 32 | Batch_idx: 320 |  Loss: (0.5443) |  Loss2: (0.0000) | Acc: (81.00%) (33317/41088)
Epoch: 32 | Batch_idx: 330 |  Loss: (0.5443) |  Loss2: (0.0000) | Acc: (81.00%) (34364/42368)
Epoch: 32 | Batch_idx: 340 |  Loss: (0.5427) |  Loss2: (0.0000) | Acc: (81.00%) (35423/43648)
Epoch: 32 | Batch_idx: 350 |  Loss: (0.5421) |  Loss2: (0.0000) | Acc: (81.00%) (36460/44928)
Epoch: 32 | Batch_idx: 360 |  Loss: (0.5413) |  Loss2: (0.0000) | Acc: (81.00%) (37510/46208)
Epoch: 32 | Batch_idx: 370 |  Loss: (0.5410) |  Loss2: (0.0000) | Acc: (81.00%) (38564/47488)
Epoch: 32 | Batch_idx: 380 |  Loss: (0.5422) |  Loss2: (0.0000) | Acc: (81.00%) (39572/48768)
Epoch: 32 | Batch_idx: 390 |  Loss: (0.5429) |  Loss2: (0.0000) | Acc: (81.00%) (40564/50000)
# TEST : Loss: (0.6181) | Acc: (78.00%) (7866/10000)
percent tensor([0.5383, 0.5445, 0.5471, 0.5441, 0.5503, 0.5456, 0.5474, 0.5451, 0.5405,
        0.5412, 0.5394, 0.5454, 0.5393, 0.5385, 0.5457, 0.5384],
       device='cuda:0') torch.Size([16])
percent tensor([0.5513, 0.5530, 0.5513, 0.5481, 0.5530, 0.5561, 0.5580, 0.5503, 0.5496,
        0.5528, 0.5526, 0.5586, 0.5479, 0.5520, 0.5563, 0.5526],
       device='cuda:0') torch.Size([16])
percent tensor([0.5453, 0.5508, 0.5375, 0.5367, 0.5388, 0.5281, 0.5472, 0.5408, 0.5472,
        0.5515, 0.5478, 0.5473, 0.5487, 0.5579, 0.5429, 0.5471],
       device='cuda:0') torch.Size([16])
percent tensor([0.5593, 0.5453, 0.5556, 0.5588, 0.5557, 0.5683, 0.5545, 0.5532, 0.5533,
        0.5519, 0.5513, 0.5552, 0.5499, 0.5514, 0.5611, 0.5578],
       device='cuda:0') torch.Size([16])
percent tensor([0.4689, 0.4625, 0.4929, 0.4990, 0.4937, 0.4837, 0.4796, 0.4919, 0.4933,
        0.4619, 0.4684, 0.4930, 0.4567, 0.4871, 0.4863, 0.4640],
       device='cuda:0') torch.Size([16])
percent tensor([0.5065, 0.5070, 0.5274, 0.5373, 0.5298, 0.5238, 0.5181, 0.5240, 0.5274,
        0.5094, 0.5182, 0.5273, 0.5035, 0.5269, 0.5082, 0.5101],
       device='cuda:0') torch.Size([16])
percent tensor([0.5354, 0.5393, 0.6019, 0.6049, 0.6293, 0.5316, 0.5732, 0.6146, 0.5825,
        0.5637, 0.5575, 0.5996, 0.5412, 0.5834, 0.5541, 0.5393],
       device='cuda:0') torch.Size([16])
percent tensor([0.9775, 0.9564, 0.9782, 0.9638, 0.9891, 0.9684, 0.9792, 0.9929, 0.9642,
        0.9779, 0.9675, 0.9793, 0.9644, 0.9663, 0.9781, 0.9814],
       device='cuda:0') torch.Size([16])
Epoch: 33 | Batch_idx: 0 |  Loss: (0.5300) |  Loss2: (0.0000) | Acc: (82.00%) (105/128)
Epoch: 33 | Batch_idx: 10 |  Loss: (0.5329) |  Loss2: (0.0000) | Acc: (81.00%) (1149/1408)
Epoch: 33 | Batch_idx: 20 |  Loss: (0.5259) |  Loss2: (0.0000) | Acc: (81.00%) (2199/2688)
Epoch: 33 | Batch_idx: 30 |  Loss: (0.5411) |  Loss2: (0.0000) | Acc: (81.00%) (3221/3968)
Epoch: 33 | Batch_idx: 40 |  Loss: (0.5447) |  Loss2: (0.0000) | Acc: (81.00%) (4260/5248)
Epoch: 33 | Batch_idx: 50 |  Loss: (0.5390) |  Loss2: (0.0000) | Acc: (81.00%) (5305/6528)
Epoch: 33 | Batch_idx: 60 |  Loss: (0.5341) |  Loss2: (0.0000) | Acc: (81.00%) (6367/7808)
Epoch: 33 | Batch_idx: 70 |  Loss: (0.5352) |  Loss2: (0.0000) | Acc: (81.00%) (7406/9088)
Epoch: 33 | Batch_idx: 80 |  Loss: (0.5332) |  Loss2: (0.0000) | Acc: (81.00%) (8443/10368)
Epoch: 33 | Batch_idx: 90 |  Loss: (0.5345) |  Loss2: (0.0000) | Acc: (81.00%) (9486/11648)
Epoch: 33 | Batch_idx: 100 |  Loss: (0.5349) |  Loss2: (0.0000) | Acc: (81.00%) (10524/12928)
Epoch: 33 | Batch_idx: 110 |  Loss: (0.5348) |  Loss2: (0.0000) | Acc: (81.00%) (11565/14208)
Epoch: 33 | Batch_idx: 120 |  Loss: (0.5329) |  Loss2: (0.0000) | Acc: (81.00%) (12631/15488)
Epoch: 33 | Batch_idx: 130 |  Loss: (0.5303) |  Loss2: (0.0000) | Acc: (81.00%) (13693/16768)
Epoch: 33 | Batch_idx: 140 |  Loss: (0.5330) |  Loss2: (0.0000) | Acc: (81.00%) (14714/18048)
Epoch: 33 | Batch_idx: 150 |  Loss: (0.5326) |  Loss2: (0.0000) | Acc: (81.00%) (15748/19328)
Epoch: 33 | Batch_idx: 160 |  Loss: (0.5300) |  Loss2: (0.0000) | Acc: (81.00%) (16817/20608)
Epoch: 33 | Batch_idx: 170 |  Loss: (0.5286) |  Loss2: (0.0000) | Acc: (81.00%) (17870/21888)
Epoch: 33 | Batch_idx: 180 |  Loss: (0.5282) |  Loss2: (0.0000) | Acc: (81.00%) (18926/23168)
Epoch: 33 | Batch_idx: 190 |  Loss: (0.5280) |  Loss2: (0.0000) | Acc: (81.00%) (19966/24448)
Epoch: 33 | Batch_idx: 200 |  Loss: (0.5286) |  Loss2: (0.0000) | Acc: (81.00%) (21013/25728)
Epoch: 33 | Batch_idx: 210 |  Loss: (0.5274) |  Loss2: (0.0000) | Acc: (81.00%) (22054/27008)
Epoch: 33 | Batch_idx: 220 |  Loss: (0.5267) |  Loss2: (0.0000) | Acc: (81.00%) (23109/28288)
Epoch: 33 | Batch_idx: 230 |  Loss: (0.5261) |  Loss2: (0.0000) | Acc: (81.00%) (24145/29568)
Epoch: 33 | Batch_idx: 240 |  Loss: (0.5254) |  Loss2: (0.0000) | Acc: (81.00%) (25200/30848)
Epoch: 33 | Batch_idx: 250 |  Loss: (0.5253) |  Loss2: (0.0000) | Acc: (81.00%) (26250/32128)
Epoch: 33 | Batch_idx: 260 |  Loss: (0.5272) |  Loss2: (0.0000) | Acc: (81.00%) (27276/33408)
Epoch: 33 | Batch_idx: 270 |  Loss: (0.5271) |  Loss2: (0.0000) | Acc: (81.00%) (28319/34688)
Epoch: 33 | Batch_idx: 280 |  Loss: (0.5279) |  Loss2: (0.0000) | Acc: (81.00%) (29359/35968)
Epoch: 33 | Batch_idx: 290 |  Loss: (0.5275) |  Loss2: (0.0000) | Acc: (81.00%) (30415/37248)
Epoch: 33 | Batch_idx: 300 |  Loss: (0.5263) |  Loss2: (0.0000) | Acc: (81.00%) (31468/38528)
Epoch: 33 | Batch_idx: 310 |  Loss: (0.5260) |  Loss2: (0.0000) | Acc: (81.00%) (32521/39808)
Epoch: 33 | Batch_idx: 320 |  Loss: (0.5252) |  Loss2: (0.0000) | Acc: (81.00%) (33581/41088)
Epoch: 33 | Batch_idx: 330 |  Loss: (0.5246) |  Loss2: (0.0000) | Acc: (81.00%) (34658/42368)
Epoch: 33 | Batch_idx: 340 |  Loss: (0.5242) |  Loss2: (0.0000) | Acc: (81.00%) (35712/43648)
Epoch: 33 | Batch_idx: 350 |  Loss: (0.5234) |  Loss2: (0.0000) | Acc: (81.00%) (36771/44928)
Epoch: 33 | Batch_idx: 360 |  Loss: (0.5236) |  Loss2: (0.0000) | Acc: (81.00%) (37821/46208)
Epoch: 33 | Batch_idx: 370 |  Loss: (0.5237) |  Loss2: (0.0000) | Acc: (81.00%) (38867/47488)
Epoch: 33 | Batch_idx: 380 |  Loss: (0.5235) |  Loss2: (0.0000) | Acc: (81.00%) (39912/48768)
Epoch: 33 | Batch_idx: 390 |  Loss: (0.5244) |  Loss2: (0.0000) | Acc: (81.00%) (40913/50000)
# TEST : Loss: (0.6488) | Acc: (78.00%) (7812/10000)
percent tensor([0.5380, 0.5418, 0.5476, 0.5441, 0.5505, 0.5467, 0.5456, 0.5443, 0.5397,
        0.5399, 0.5387, 0.5451, 0.5389, 0.5348, 0.5451, 0.5379],
       device='cuda:0') torch.Size([16])
percent tensor([0.5512, 0.5532, 0.5478, 0.5465, 0.5513, 0.5580, 0.5569, 0.5482, 0.5489,
        0.5517, 0.5526, 0.5555, 0.5477, 0.5509, 0.5580, 0.5520],
       device='cuda:0') torch.Size([16])
percent tensor([0.5464, 0.5524, 0.5367, 0.5364, 0.5362, 0.5270, 0.5470, 0.5420, 0.5477,
        0.5527, 0.5490, 0.5463, 0.5504, 0.5610, 0.5429, 0.5485],
       device='cuda:0') torch.Size([16])
percent tensor([0.5593, 0.5480, 0.5507, 0.5545, 0.5533, 0.5686, 0.5546, 0.5508, 0.5521,
        0.5523, 0.5536, 0.5519, 0.5508, 0.5526, 0.5635, 0.5577],
       device='cuda:0') torch.Size([16])
percent tensor([0.4690, 0.4627, 0.4923, 0.4978, 0.4936, 0.4866, 0.4817, 0.4915, 0.4917,
        0.4628, 0.4726, 0.4937, 0.4568, 0.4862, 0.4902, 0.4609],
       device='cuda:0') torch.Size([16])
percent tensor([0.5064, 0.5073, 0.5287, 0.5327, 0.5309, 0.5244, 0.5179, 0.5249, 0.5262,
        0.5089, 0.5196, 0.5288, 0.5063, 0.5264, 0.5089, 0.5091],
       device='cuda:0') torch.Size([16])
percent tensor([0.5408, 0.5502, 0.6147, 0.6112, 0.6393, 0.5345, 0.5837, 0.6169, 0.5894,
        0.5607, 0.5657, 0.6156, 0.5449, 0.5846, 0.5602, 0.5364],
       device='cuda:0') torch.Size([16])
percent tensor([0.9780, 0.9612, 0.9783, 0.9685, 0.9895, 0.9656, 0.9799, 0.9889, 0.9677,
        0.9812, 0.9685, 0.9791, 0.9666, 0.9700, 0.9817, 0.9796],
       device='cuda:0') torch.Size([16])
Epoch: 34 | Batch_idx: 0 |  Loss: (0.4283) |  Loss2: (0.0000) | Acc: (86.00%) (111/128)
Epoch: 34 | Batch_idx: 10 |  Loss: (0.4642) |  Loss2: (0.0000) | Acc: (83.00%) (1182/1408)
Epoch: 34 | Batch_idx: 20 |  Loss: (0.4722) |  Loss2: (0.0000) | Acc: (83.00%) (2247/2688)
Epoch: 34 | Batch_idx: 30 |  Loss: (0.4765) |  Loss2: (0.0000) | Acc: (83.00%) (3327/3968)
Epoch: 34 | Batch_idx: 40 |  Loss: (0.4730) |  Loss2: (0.0000) | Acc: (84.00%) (4412/5248)
Epoch: 34 | Batch_idx: 50 |  Loss: (0.4849) |  Loss2: (0.0000) | Acc: (83.00%) (5462/6528)
Epoch: 34 | Batch_idx: 60 |  Loss: (0.4870) |  Loss2: (0.0000) | Acc: (83.00%) (6526/7808)
Epoch: 34 | Batch_idx: 70 |  Loss: (0.4845) |  Loss2: (0.0000) | Acc: (83.00%) (7591/9088)
Epoch: 34 | Batch_idx: 80 |  Loss: (0.4889) |  Loss2: (0.0000) | Acc: (83.00%) (8644/10368)
Epoch: 34 | Batch_idx: 90 |  Loss: (0.4873) |  Loss2: (0.0000) | Acc: (83.00%) (9721/11648)
Epoch: 34 | Batch_idx: 100 |  Loss: (0.4912) |  Loss2: (0.0000) | Acc: (83.00%) (10773/12928)
Epoch: 34 | Batch_idx: 110 |  Loss: (0.4912) |  Loss2: (0.0000) | Acc: (83.00%) (11833/14208)
Epoch: 34 | Batch_idx: 120 |  Loss: (0.4952) |  Loss2: (0.0000) | Acc: (83.00%) (12882/15488)
Epoch: 34 | Batch_idx: 130 |  Loss: (0.4968) |  Loss2: (0.0000) | Acc: (83.00%) (13952/16768)
Epoch: 34 | Batch_idx: 140 |  Loss: (0.4938) |  Loss2: (0.0000) | Acc: (83.00%) (15036/18048)
Epoch: 34 | Batch_idx: 150 |  Loss: (0.4987) |  Loss2: (0.0000) | Acc: (83.00%) (16069/19328)
Epoch: 34 | Batch_idx: 160 |  Loss: (0.5012) |  Loss2: (0.0000) | Acc: (82.00%) (17101/20608)
Epoch: 34 | Batch_idx: 170 |  Loss: (0.5040) |  Loss2: (0.0000) | Acc: (82.00%) (18143/21888)
Epoch: 34 | Batch_idx: 180 |  Loss: (0.5037) |  Loss2: (0.0000) | Acc: (82.00%) (19204/23168)
Epoch: 34 | Batch_idx: 190 |  Loss: (0.5054) |  Loss2: (0.0000) | Acc: (82.00%) (20240/24448)
Epoch: 34 | Batch_idx: 200 |  Loss: (0.5073) |  Loss2: (0.0000) | Acc: (82.00%) (21289/25728)
Epoch: 34 | Batch_idx: 210 |  Loss: (0.5068) |  Loss2: (0.0000) | Acc: (82.00%) (22359/27008)
Epoch: 34 | Batch_idx: 220 |  Loss: (0.5077) |  Loss2: (0.0000) | Acc: (82.00%) (23411/28288)
Epoch: 34 | Batch_idx: 230 |  Loss: (0.5074) |  Loss2: (0.0000) | Acc: (82.00%) (24473/29568)
Epoch: 34 | Batch_idx: 240 |  Loss: (0.5058) |  Loss2: (0.0000) | Acc: (82.00%) (25538/30848)
Epoch: 34 | Batch_idx: 250 |  Loss: (0.5073) |  Loss2: (0.0000) | Acc: (82.00%) (26568/32128)
Epoch: 34 | Batch_idx: 260 |  Loss: (0.5071) |  Loss2: (0.0000) | Acc: (82.00%) (27623/33408)
Epoch: 34 | Batch_idx: 270 |  Loss: (0.5052) |  Loss2: (0.0000) | Acc: (82.00%) (28697/34688)
Epoch: 34 | Batch_idx: 280 |  Loss: (0.5064) |  Loss2: (0.0000) | Acc: (82.00%) (29729/35968)
Epoch: 34 | Batch_idx: 290 |  Loss: (0.5061) |  Loss2: (0.0000) | Acc: (82.00%) (30786/37248)
Epoch: 34 | Batch_idx: 300 |  Loss: (0.5050) |  Loss2: (0.0000) | Acc: (82.00%) (31863/38528)
Epoch: 34 | Batch_idx: 310 |  Loss: (0.5040) |  Loss2: (0.0000) | Acc: (82.00%) (32931/39808)
Epoch: 34 | Batch_idx: 320 |  Loss: (0.5044) |  Loss2: (0.0000) | Acc: (82.00%) (33983/41088)
Epoch: 34 | Batch_idx: 330 |  Loss: (0.5046) |  Loss2: (0.0000) | Acc: (82.00%) (35032/42368)
Epoch: 34 | Batch_idx: 340 |  Loss: (0.5041) |  Loss2: (0.0000) | Acc: (82.00%) (36080/43648)
Epoch: 34 | Batch_idx: 350 |  Loss: (0.5054) |  Loss2: (0.0000) | Acc: (82.00%) (37127/44928)
Epoch: 34 | Batch_idx: 360 |  Loss: (0.5044) |  Loss2: (0.0000) | Acc: (82.00%) (38197/46208)
Epoch: 34 | Batch_idx: 370 |  Loss: (0.5046) |  Loss2: (0.0000) | Acc: (82.00%) (39264/47488)
Epoch: 34 | Batch_idx: 380 |  Loss: (0.5039) |  Loss2: (0.0000) | Acc: (82.00%) (40329/48768)
Epoch: 34 | Batch_idx: 390 |  Loss: (0.5042) |  Loss2: (0.0000) | Acc: (82.00%) (41331/50000)
# TEST : Loss: (0.6849) | Acc: (76.00%) (7694/10000)
percent tensor([0.5382, 0.5445, 0.5470, 0.5437, 0.5497, 0.5455, 0.5473, 0.5452, 0.5397,
        0.5411, 0.5390, 0.5457, 0.5388, 0.5385, 0.5461, 0.5384],
       device='cuda:0') torch.Size([16])
percent tensor([0.5504, 0.5506, 0.5477, 0.5451, 0.5513, 0.5562, 0.5553, 0.5482, 0.5489,
        0.5508, 0.5533, 0.5561, 0.5475, 0.5467, 0.5560, 0.5509],
       device='cuda:0') torch.Size([16])
percent tensor([0.5460, 0.5504, 0.5392, 0.5361, 0.5377, 0.5252, 0.5455, 0.5415, 0.5471,
        0.5526, 0.5487, 0.5483, 0.5499, 0.5580, 0.5411, 0.5473],
       device='cuda:0') torch.Size([16])
percent tensor([0.5586, 0.5465, 0.5500, 0.5566, 0.5521, 0.5666, 0.5520, 0.5510, 0.5520,
        0.5502, 0.5526, 0.5511, 0.5491, 0.5523, 0.5616, 0.5582],
       device='cuda:0') torch.Size([16])
percent tensor([0.4657, 0.4596, 0.4889, 0.4979, 0.4934, 0.4841, 0.4752, 0.4900, 0.4905,
        0.4595, 0.4679, 0.4911, 0.4531, 0.4824, 0.4843, 0.4593],
       device='cuda:0') torch.Size([16])
percent tensor([0.5013, 0.5023, 0.5215, 0.5305, 0.5284, 0.5222, 0.5116, 0.5176, 0.5224,
        0.5018, 0.5157, 0.5192, 0.4985, 0.5212, 0.5015, 0.5043],
       device='cuda:0') torch.Size([16])
percent tensor([0.5410, 0.5400, 0.6029, 0.6098, 0.6296, 0.5407, 0.5745, 0.6079, 0.5786,
        0.5658, 0.5604, 0.6074, 0.5390, 0.5723, 0.5561, 0.5299],
       device='cuda:0') torch.Size([16])
percent tensor([0.9731, 0.9605, 0.9730, 0.9728, 0.9877, 0.9583, 0.9792, 0.9857, 0.9710,
        0.9841, 0.9614, 0.9810, 0.9662, 0.9745, 0.9806, 0.9726],
       device='cuda:0') torch.Size([16])
False Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=128, out_features=16, bias=False)
True Linear(in_features=16, out_features=2, bias=False)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=128, out_features=16, bias=False)
True Linear(in_features=16, out_features=2, bias=False)
False Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=256, out_features=32, bias=False)
True Linear(in_features=32, out_features=2, bias=False)
False Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=256, out_features=32, bias=False)
True Linear(in_features=32, out_features=2, bias=False)
False Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=512, out_features=64, bias=False)
True Linear(in_features=64, out_features=2, bias=False)
False Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=512, out_features=64, bias=False)
True Linear(in_features=64, out_features=2, bias=False)
False Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1024, out_features=128, bias=False)
True Linear(in_features=128, out_features=2, bias=False)
False Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1024, out_features=128, bias=False)
True Linear(in_features=128, out_features=2, bias=False)
False Linear(in_features=512, out_features=10, bias=True)
Epoch: 35 | Batch_idx: 0 |  Loss: (0.4445) |  Loss2: (0.0000) | Acc: (86.00%) (111/128)
Epoch: 35 | Batch_idx: 10 |  Loss: (0.5675) |  Loss2: (0.0000) | Acc: (79.00%) (1126/1408)
Epoch: 35 | Batch_idx: 20 |  Loss: (0.6135) |  Loss2: (0.0000) | Acc: (78.00%) (2108/2688)
Epoch: 35 | Batch_idx: 30 |  Loss: (0.6256) |  Loss2: (0.0000) | Acc: (78.00%) (3101/3968)
Epoch: 35 | Batch_idx: 40 |  Loss: (0.6325) |  Loss2: (0.0000) | Acc: (77.00%) (4072/5248)
Epoch: 35 | Batch_idx: 50 |  Loss: (0.6309) |  Loss2: (0.0000) | Acc: (77.00%) (5074/6528)
Epoch: 35 | Batch_idx: 60 |  Loss: (0.6412) |  Loss2: (0.0000) | Acc: (77.00%) (6042/7808)
Epoch: 35 | Batch_idx: 70 |  Loss: (0.6388) |  Loss2: (0.0000) | Acc: (77.00%) (7050/9088)
Epoch: 35 | Batch_idx: 80 |  Loss: (0.6385) |  Loss2: (0.0000) | Acc: (77.00%) (8040/10368)
Epoch: 35 | Batch_idx: 90 |  Loss: (0.6357) |  Loss2: (0.0000) | Acc: (77.00%) (9028/11648)
Epoch: 35 | Batch_idx: 100 |  Loss: (0.6365) |  Loss2: (0.0000) | Acc: (77.00%) (10015/12928)
Epoch: 35 | Batch_idx: 110 |  Loss: (0.6349) |  Loss2: (0.0000) | Acc: (77.00%) (11031/14208)
Epoch: 35 | Batch_idx: 120 |  Loss: (0.6346) |  Loss2: (0.0000) | Acc: (77.00%) (12039/15488)
Epoch: 35 | Batch_idx: 130 |  Loss: (0.6323) |  Loss2: (0.0000) | Acc: (77.00%) (13029/16768)
Epoch: 35 | Batch_idx: 140 |  Loss: (0.6289) |  Loss2: (0.0000) | Acc: (77.00%) (14046/18048)
Epoch: 35 | Batch_idx: 150 |  Loss: (0.6251) |  Loss2: (0.0000) | Acc: (78.00%) (15081/19328)
Epoch: 35 | Batch_idx: 160 |  Loss: (0.6229) |  Loss2: (0.0000) | Acc: (78.00%) (16086/20608)
Epoch: 35 | Batch_idx: 170 |  Loss: (0.6204) |  Loss2: (0.0000) | Acc: (78.00%) (17120/21888)
Epoch: 35 | Batch_idx: 180 |  Loss: (0.6185) |  Loss2: (0.0000) | Acc: (78.00%) (18132/23168)
Epoch: 35 | Batch_idx: 190 |  Loss: (0.6189) |  Loss2: (0.0000) | Acc: (78.00%) (19136/24448)
Epoch: 35 | Batch_idx: 200 |  Loss: (0.6171) |  Loss2: (0.0000) | Acc: (78.00%) (20166/25728)
Epoch: 35 | Batch_idx: 210 |  Loss: (0.6151) |  Loss2: (0.0000) | Acc: (78.00%) (21192/27008)
Epoch: 35 | Batch_idx: 220 |  Loss: (0.6126) |  Loss2: (0.0000) | Acc: (78.00%) (22209/28288)
Epoch: 35 | Batch_idx: 230 |  Loss: (0.6097) |  Loss2: (0.0000) | Acc: (78.00%) (23239/29568)
Epoch: 35 | Batch_idx: 240 |  Loss: (0.6081) |  Loss2: (0.0000) | Acc: (78.00%) (24269/30848)
Epoch: 35 | Batch_idx: 250 |  Loss: (0.6071) |  Loss2: (0.0000) | Acc: (78.00%) (25280/32128)
Epoch: 35 | Batch_idx: 260 |  Loss: (0.6050) |  Loss2: (0.0000) | Acc: (78.00%) (26308/33408)
Epoch: 35 | Batch_idx: 270 |  Loss: (0.6030) |  Loss2: (0.0000) | Acc: (78.00%) (27356/34688)
Epoch: 35 | Batch_idx: 280 |  Loss: (0.6014) |  Loss2: (0.0000) | Acc: (78.00%) (28379/35968)
Epoch: 35 | Batch_idx: 290 |  Loss: (0.6009) |  Loss2: (0.0000) | Acc: (78.00%) (29400/37248)
Epoch: 35 | Batch_idx: 300 |  Loss: (0.5991) |  Loss2: (0.0000) | Acc: (78.00%) (30419/38528)
Epoch: 35 | Batch_idx: 310 |  Loss: (0.5976) |  Loss2: (0.0000) | Acc: (79.00%) (31456/39808)
Epoch: 35 | Batch_idx: 320 |  Loss: (0.5971) |  Loss2: (0.0000) | Acc: (79.00%) (32475/41088)
Epoch: 35 | Batch_idx: 330 |  Loss: (0.5957) |  Loss2: (0.0000) | Acc: (79.00%) (33505/42368)
Epoch: 35 | Batch_idx: 340 |  Loss: (0.5943) |  Loss2: (0.0000) | Acc: (79.00%) (34555/43648)
Epoch: 35 | Batch_idx: 350 |  Loss: (0.5944) |  Loss2: (0.0000) | Acc: (79.00%) (35575/44928)
Epoch: 35 | Batch_idx: 360 |  Loss: (0.5947) |  Loss2: (0.0000) | Acc: (79.00%) (36581/46208)
Epoch: 35 | Batch_idx: 370 |  Loss: (0.5936) |  Loss2: (0.0000) | Acc: (79.00%) (37607/47488)
Epoch: 35 | Batch_idx: 380 |  Loss: (0.5911) |  Loss2: (0.0000) | Acc: (79.00%) (38675/48768)
Epoch: 35 | Batch_idx: 390 |  Loss: (0.5908) |  Loss2: (0.0000) | Acc: (79.00%) (39658/50000)
=> saving checkpoint 'drive/app/torch/save_Schedule/checkpoint_035.pth.tar'
# TEST : Loss: (0.6216) | Acc: (79.00%) (7901/10000)
percent tensor([0.5218, 0.5250, 0.5271, 0.5278, 0.5286, 0.5278, 0.5264, 0.5271, 0.5223,
        0.5225, 0.5218, 0.5248, 0.5216, 0.5224, 0.5270, 0.5225],
       device='cuda:0') torch.Size([16])
percent tensor([0.5561, 0.5592, 0.5510, 0.5508, 0.5546, 0.5623, 0.5620, 0.5542, 0.5562,
        0.5570, 0.5605, 0.5596, 0.5539, 0.5571, 0.5631, 0.5586],
       device='cuda:0') torch.Size([16])
percent tensor([0.5449, 0.5584, 0.5331, 0.5289, 0.5364, 0.5210, 0.5508, 0.5399, 0.5455,
        0.5559, 0.5525, 0.5475, 0.5517, 0.5621, 0.5440, 0.5483],
       device='cuda:0') torch.Size([16])
percent tensor([0.5573, 0.5487, 0.5463, 0.5555, 0.5488, 0.5642, 0.5518, 0.5504, 0.5519,
        0.5498, 0.5537, 0.5471, 0.5486, 0.5529, 0.5615, 0.5584],
       device='cuda:0') torch.Size([16])
percent tensor([0.4240, 0.4166, 0.4680, 0.4892, 0.4854, 0.4659, 0.4416, 0.4741, 0.4645,
        0.4137, 0.4237, 0.4404, 0.3985, 0.4569, 0.4386, 0.4298],
       device='cuda:0') torch.Size([16])
percent tensor([0.4648, 0.4639, 0.4934, 0.5061, 0.4968, 0.5072, 0.4744, 0.4739, 0.4971,
        0.4630, 0.4827, 0.4840, 0.4625, 0.4922, 0.4571, 0.4701],
       device='cuda:0') torch.Size([16])
percent tensor([0.5094, 0.5019, 0.5823, 0.5955, 0.6007, 0.5238, 0.5430, 0.5826, 0.5473,
        0.5233, 0.5213, 0.5723, 0.5007, 0.5364, 0.5264, 0.5083],
       device='cuda:0') torch.Size([16])
percent tensor([0.9809, 0.9648, 0.9825, 0.9814, 0.9919, 0.9745, 0.9854, 0.9920, 0.9760,
        0.9844, 0.9736, 0.9863, 0.9755, 0.9764, 0.9854, 0.9830],
       device='cuda:0') torch.Size([16])
Epoch: 36 | Batch_idx: 0 |  Loss: (0.5161) |  Loss2: (0.0000) | Acc: (82.00%) (106/128)
Epoch: 36 | Batch_idx: 10 |  Loss: (0.5540) |  Loss2: (0.0000) | Acc: (81.00%) (1143/1408)
Epoch: 36 | Batch_idx: 20 |  Loss: (0.5435) |  Loss2: (0.0000) | Acc: (81.00%) (2178/2688)
Epoch: 36 | Batch_idx: 30 |  Loss: (0.5486) |  Loss2: (0.0000) | Acc: (81.00%) (3216/3968)
Epoch: 36 | Batch_idx: 40 |  Loss: (0.5413) |  Loss2: (0.0000) | Acc: (81.00%) (4274/5248)
Epoch: 36 | Batch_idx: 50 |  Loss: (0.5356) |  Loss2: (0.0000) | Acc: (81.00%) (5315/6528)
Epoch: 36 | Batch_idx: 60 |  Loss: (0.5335) |  Loss2: (0.0000) | Acc: (81.00%) (6367/7808)
Epoch: 36 | Batch_idx: 70 |  Loss: (0.5370) |  Loss2: (0.0000) | Acc: (81.00%) (7397/9088)
Epoch: 36 | Batch_idx: 80 |  Loss: (0.5388) |  Loss2: (0.0000) | Acc: (81.00%) (8419/10368)
Epoch: 36 | Batch_idx: 90 |  Loss: (0.5393) |  Loss2: (0.0000) | Acc: (81.00%) (9438/11648)
Epoch: 36 | Batch_idx: 100 |  Loss: (0.5371) |  Loss2: (0.0000) | Acc: (81.00%) (10492/12928)
Epoch: 36 | Batch_idx: 110 |  Loss: (0.5399) |  Loss2: (0.0000) | Acc: (81.00%) (11518/14208)
Epoch: 36 | Batch_idx: 120 |  Loss: (0.5418) |  Loss2: (0.0000) | Acc: (80.00%) (12536/15488)
Epoch: 36 | Batch_idx: 130 |  Loss: (0.5410) |  Loss2: (0.0000) | Acc: (81.00%) (13587/16768)
Epoch: 36 | Batch_idx: 140 |  Loss: (0.5390) |  Loss2: (0.0000) | Acc: (81.00%) (14640/18048)
Epoch: 36 | Batch_idx: 150 |  Loss: (0.5366) |  Loss2: (0.0000) | Acc: (81.00%) (15704/19328)
Epoch: 36 | Batch_idx: 160 |  Loss: (0.5361) |  Loss2: (0.0000) | Acc: (81.00%) (16745/20608)
Epoch: 36 | Batch_idx: 170 |  Loss: (0.5365) |  Loss2: (0.0000) | Acc: (81.00%) (17784/21888)
Epoch: 36 | Batch_idx: 180 |  Loss: (0.5356) |  Loss2: (0.0000) | Acc: (81.00%) (18840/23168)
Epoch: 36 | Batch_idx: 190 |  Loss: (0.5357) |  Loss2: (0.0000) | Acc: (81.00%) (19886/24448)
Epoch: 36 | Batch_idx: 200 |  Loss: (0.5357) |  Loss2: (0.0000) | Acc: (81.00%) (20929/25728)
Epoch: 36 | Batch_idx: 210 |  Loss: (0.5360) |  Loss2: (0.0000) | Acc: (81.00%) (21976/27008)
Epoch: 36 | Batch_idx: 220 |  Loss: (0.5349) |  Loss2: (0.0000) | Acc: (81.00%) (23020/28288)
Epoch: 36 | Batch_idx: 230 |  Loss: (0.5349) |  Loss2: (0.0000) | Acc: (81.00%) (24056/29568)
Epoch: 36 | Batch_idx: 240 |  Loss: (0.5353) |  Loss2: (0.0000) | Acc: (81.00%) (25096/30848)
Epoch: 36 | Batch_idx: 250 |  Loss: (0.5365) |  Loss2: (0.0000) | Acc: (81.00%) (26126/32128)
Epoch: 36 | Batch_idx: 260 |  Loss: (0.5345) |  Loss2: (0.0000) | Acc: (81.00%) (27188/33408)
Epoch: 36 | Batch_idx: 270 |  Loss: (0.5333) |  Loss2: (0.0000) | Acc: (81.00%) (28243/34688)
Epoch: 36 | Batch_idx: 280 |  Loss: (0.5341) |  Loss2: (0.0000) | Acc: (81.00%) (29275/35968)
Epoch: 36 | Batch_idx: 290 |  Loss: (0.5346) |  Loss2: (0.0000) | Acc: (81.00%) (30321/37248)
Epoch: 36 | Batch_idx: 300 |  Loss: (0.5357) |  Loss2: (0.0000) | Acc: (81.00%) (31351/38528)
Epoch: 36 | Batch_idx: 310 |  Loss: (0.5357) |  Loss2: (0.0000) | Acc: (81.00%) (32396/39808)
Epoch: 36 | Batch_idx: 320 |  Loss: (0.5359) |  Loss2: (0.0000) | Acc: (81.00%) (33432/41088)
Epoch: 36 | Batch_idx: 330 |  Loss: (0.5349) |  Loss2: (0.0000) | Acc: (81.00%) (34477/42368)
Epoch: 36 | Batch_idx: 340 |  Loss: (0.5336) |  Loss2: (0.0000) | Acc: (81.00%) (35532/43648)
Epoch: 36 | Batch_idx: 350 |  Loss: (0.5337) |  Loss2: (0.0000) | Acc: (81.00%) (36570/44928)
Epoch: 36 | Batch_idx: 360 |  Loss: (0.5339) |  Loss2: (0.0000) | Acc: (81.00%) (37603/46208)
Epoch: 36 | Batch_idx: 370 |  Loss: (0.5336) |  Loss2: (0.0000) | Acc: (81.00%) (38654/47488)
Epoch: 36 | Batch_idx: 380 |  Loss: (0.5342) |  Loss2: (0.0000) | Acc: (81.00%) (39689/48768)
Epoch: 36 | Batch_idx: 390 |  Loss: (0.5343) |  Loss2: (0.0000) | Acc: (81.00%) (40684/50000)
# TEST : Loss: (0.5845) | Acc: (80.00%) (8018/10000)
percent tensor([0.5200, 0.5226, 0.5249, 0.5265, 0.5260, 0.5264, 0.5236, 0.5250, 0.5201,
        0.5202, 0.5196, 0.5220, 0.5194, 0.5205, 0.5248, 0.5208],
       device='cuda:0') torch.Size([16])
percent tensor([0.5533, 0.5559, 0.5490, 0.5472, 0.5522, 0.5602, 0.5587, 0.5505, 0.5530,
        0.5536, 0.5572, 0.5565, 0.5506, 0.5535, 0.5603, 0.5552],
       device='cuda:0') torch.Size([16])
percent tensor([0.5455, 0.5627, 0.5333, 0.5273, 0.5377, 0.5197, 0.5541, 0.5422, 0.5456,
        0.5583, 0.5540, 0.5487, 0.5535, 0.5645, 0.5467, 0.5502],
       device='cuda:0') torch.Size([16])
percent tensor([0.5596, 0.5532, 0.5472, 0.5544, 0.5506, 0.5653, 0.5547, 0.5502, 0.5534,
        0.5535, 0.5575, 0.5487, 0.5521, 0.5557, 0.5646, 0.5605],
       device='cuda:0') torch.Size([16])
percent tensor([0.4226, 0.4232, 0.4730, 0.4926, 0.4957, 0.4659, 0.4508, 0.4821, 0.4645,
        0.4172, 0.4257, 0.4373, 0.3924, 0.4655, 0.4418, 0.4342],
       device='cuda:0') torch.Size([16])
percent tensor([0.4575, 0.4571, 0.4928, 0.5061, 0.4977, 0.5078, 0.4719, 0.4674, 0.4955,
        0.4554, 0.4795, 0.4801, 0.4536, 0.4909, 0.4484, 0.4635],
       device='cuda:0') torch.Size([16])
percent tensor([0.5105, 0.5065, 0.5861, 0.5970, 0.6053, 0.5289, 0.5477, 0.5818, 0.5504,
        0.5257, 0.5231, 0.5719, 0.4997, 0.5448, 0.5289, 0.5100],
       device='cuda:0') torch.Size([16])
percent tensor([0.9880, 0.9764, 0.9890, 0.9880, 0.9947, 0.9840, 0.9912, 0.9952, 0.9854,
        0.9901, 0.9827, 0.9916, 0.9839, 0.9864, 0.9907, 0.9898],
       device='cuda:0') torch.Size([16])
Epoch: 37 | Batch_idx: 0 |  Loss: (0.4726) |  Loss2: (0.0000) | Acc: (82.00%) (106/128)
Epoch: 37 | Batch_idx: 10 |  Loss: (0.5595) |  Loss2: (0.0000) | Acc: (80.00%) (1136/1408)
Epoch: 37 | Batch_idx: 20 |  Loss: (0.5465) |  Loss2: (0.0000) | Acc: (80.00%) (2175/2688)
Epoch: 37 | Batch_idx: 30 |  Loss: (0.5450) |  Loss2: (0.0000) | Acc: (80.00%) (3199/3968)
Epoch: 37 | Batch_idx: 40 |  Loss: (0.5421) |  Loss2: (0.0000) | Acc: (80.00%) (4230/5248)
Epoch: 37 | Batch_idx: 50 |  Loss: (0.5303) |  Loss2: (0.0000) | Acc: (81.00%) (5303/6528)
Epoch: 37 | Batch_idx: 60 |  Loss: (0.5233) |  Loss2: (0.0000) | Acc: (81.00%) (6353/7808)
Epoch: 37 | Batch_idx: 70 |  Loss: (0.5216) |  Loss2: (0.0000) | Acc: (81.00%) (7405/9088)
Epoch: 37 | Batch_idx: 80 |  Loss: (0.5174) |  Loss2: (0.0000) | Acc: (81.00%) (8466/10368)
Epoch: 37 | Batch_idx: 90 |  Loss: (0.5151) |  Loss2: (0.0000) | Acc: (81.00%) (9521/11648)
Epoch: 37 | Batch_idx: 100 |  Loss: (0.5149) |  Loss2: (0.0000) | Acc: (81.00%) (10575/12928)
Epoch: 37 | Batch_idx: 110 |  Loss: (0.5135) |  Loss2: (0.0000) | Acc: (81.00%) (11623/14208)
Epoch: 37 | Batch_idx: 120 |  Loss: (0.5108) |  Loss2: (0.0000) | Acc: (81.00%) (12690/15488)
Epoch: 37 | Batch_idx: 130 |  Loss: (0.5127) |  Loss2: (0.0000) | Acc: (81.00%) (13732/16768)
Epoch: 37 | Batch_idx: 140 |  Loss: (0.5141) |  Loss2: (0.0000) | Acc: (81.00%) (14783/18048)
Epoch: 37 | Batch_idx: 150 |  Loss: (0.5151) |  Loss2: (0.0000) | Acc: (81.00%) (15831/19328)
Epoch: 37 | Batch_idx: 160 |  Loss: (0.5134) |  Loss2: (0.0000) | Acc: (82.00%) (16900/20608)
Epoch: 37 | Batch_idx: 170 |  Loss: (0.5131) |  Loss2: (0.0000) | Acc: (82.00%) (17955/21888)
Epoch: 37 | Batch_idx: 180 |  Loss: (0.5124) |  Loss2: (0.0000) | Acc: (82.00%) (19009/23168)
Epoch: 37 | Batch_idx: 190 |  Loss: (0.5120) |  Loss2: (0.0000) | Acc: (82.00%) (20071/24448)
Epoch: 37 | Batch_idx: 200 |  Loss: (0.5142) |  Loss2: (0.0000) | Acc: (82.00%) (21101/25728)
Epoch: 37 | Batch_idx: 210 |  Loss: (0.5138) |  Loss2: (0.0000) | Acc: (82.00%) (22151/27008)
Epoch: 37 | Batch_idx: 220 |  Loss: (0.5138) |  Loss2: (0.0000) | Acc: (82.00%) (23198/28288)
Epoch: 37 | Batch_idx: 230 |  Loss: (0.5142) |  Loss2: (0.0000) | Acc: (82.00%) (24249/29568)
Epoch: 37 | Batch_idx: 240 |  Loss: (0.5139) |  Loss2: (0.0000) | Acc: (81.00%) (25295/30848)
Epoch: 37 | Batch_idx: 250 |  Loss: (0.5138) |  Loss2: (0.0000) | Acc: (82.00%) (26357/32128)
Epoch: 37 | Batch_idx: 260 |  Loss: (0.5141) |  Loss2: (0.0000) | Acc: (82.00%) (27401/33408)
Epoch: 37 | Batch_idx: 270 |  Loss: (0.5150) |  Loss2: (0.0000) | Acc: (82.00%) (28463/34688)
Epoch: 37 | Batch_idx: 280 |  Loss: (0.5162) |  Loss2: (0.0000) | Acc: (82.00%) (29515/35968)
Epoch: 37 | Batch_idx: 290 |  Loss: (0.5153) |  Loss2: (0.0000) | Acc: (82.00%) (30583/37248)
Epoch: 37 | Batch_idx: 300 |  Loss: (0.5153) |  Loss2: (0.0000) | Acc: (82.00%) (31631/38528)
Epoch: 37 | Batch_idx: 310 |  Loss: (0.5149) |  Loss2: (0.0000) | Acc: (82.00%) (32697/39808)
Epoch: 37 | Batch_idx: 320 |  Loss: (0.5144) |  Loss2: (0.0000) | Acc: (82.00%) (33757/41088)
Epoch: 37 | Batch_idx: 330 |  Loss: (0.5130) |  Loss2: (0.0000) | Acc: (82.00%) (34837/42368)
Epoch: 37 | Batch_idx: 340 |  Loss: (0.5124) |  Loss2: (0.0000) | Acc: (82.00%) (35892/43648)
Epoch: 37 | Batch_idx: 350 |  Loss: (0.5116) |  Loss2: (0.0000) | Acc: (82.00%) (36951/44928)
Epoch: 37 | Batch_idx: 360 |  Loss: (0.5114) |  Loss2: (0.0000) | Acc: (82.00%) (38008/46208)
Epoch: 37 | Batch_idx: 370 |  Loss: (0.5124) |  Loss2: (0.0000) | Acc: (82.00%) (39043/47488)
Epoch: 37 | Batch_idx: 380 |  Loss: (0.5124) |  Loss2: (0.0000) | Acc: (82.00%) (40089/48768)
Epoch: 37 | Batch_idx: 390 |  Loss: (0.5122) |  Loss2: (0.0000) | Acc: (82.00%) (41104/50000)
# TEST : Loss: (0.5737) | Acc: (80.00%) (8054/10000)
percent tensor([0.5221, 0.5250, 0.5275, 0.5296, 0.5286, 0.5293, 0.5260, 0.5277, 0.5221,
        0.5224, 0.5217, 0.5243, 0.5215, 0.5227, 0.5275, 0.5233],
       device='cuda:0') torch.Size([16])
percent tensor([0.5483, 0.5496, 0.5446, 0.5419, 0.5468, 0.5557, 0.5525, 0.5443, 0.5474,
        0.5476, 0.5515, 0.5509, 0.5452, 0.5472, 0.5548, 0.5498],
       device='cuda:0') torch.Size([16])
percent tensor([0.5418, 0.5599, 0.5308, 0.5242, 0.5354, 0.5175, 0.5515, 0.5401, 0.5417,
        0.5549, 0.5498, 0.5454, 0.5497, 0.5605, 0.5440, 0.5469],
       device='cuda:0') torch.Size([16])
percent tensor([0.5613, 0.5556, 0.5477, 0.5537, 0.5511, 0.5667, 0.5563, 0.5496, 0.5541,
        0.5556, 0.5598, 0.5492, 0.5545, 0.5569, 0.5667, 0.5622],
       device='cuda:0') torch.Size([16])
percent tensor([0.4292, 0.4330, 0.4845, 0.5005, 0.5045, 0.4722, 0.4647, 0.4935, 0.4706,
        0.4262, 0.4327, 0.4446, 0.3945, 0.4749, 0.4527, 0.4437],
       device='cuda:0') torch.Size([16])
percent tensor([0.4548, 0.4545, 0.4943, 0.5088, 0.5006, 0.5110, 0.4722, 0.4645, 0.4975,
        0.4525, 0.4810, 0.4802, 0.4505, 0.4925, 0.4441, 0.4610],
       device='cuda:0') torch.Size([16])
percent tensor([0.5186, 0.5167, 0.5991, 0.6079, 0.6192, 0.5395, 0.5603, 0.5927, 0.5603,
        0.5357, 0.5325, 0.5841, 0.5056, 0.5582, 0.5399, 0.5179],
       device='cuda:0') torch.Size([16])
percent tensor([0.9920, 0.9841, 0.9929, 0.9917, 0.9969, 0.9886, 0.9947, 0.9968, 0.9906,
        0.9938, 0.9880, 0.9947, 0.9890, 0.9917, 0.9936, 0.9933],
       device='cuda:0') torch.Size([16])
Epoch: 38 | Batch_idx: 0 |  Loss: (0.3933) |  Loss2: (0.0000) | Acc: (87.00%) (112/128)
Epoch: 38 | Batch_idx: 10 |  Loss: (0.5200) |  Loss2: (0.0000) | Acc: (82.00%) (1158/1408)
Epoch: 38 | Batch_idx: 20 |  Loss: (0.5223) |  Loss2: (0.0000) | Acc: (81.00%) (2198/2688)
Epoch: 38 | Batch_idx: 30 |  Loss: (0.5268) |  Loss2: (0.0000) | Acc: (81.00%) (3238/3968)
Epoch: 38 | Batch_idx: 40 |  Loss: (0.5107) |  Loss2: (0.0000) | Acc: (82.00%) (4308/5248)
Epoch: 38 | Batch_idx: 50 |  Loss: (0.5084) |  Loss2: (0.0000) | Acc: (82.00%) (5358/6528)
Epoch: 38 | Batch_idx: 60 |  Loss: (0.5056) |  Loss2: (0.0000) | Acc: (82.00%) (6410/7808)
Epoch: 38 | Batch_idx: 70 |  Loss: (0.5126) |  Loss2: (0.0000) | Acc: (81.00%) (7443/9088)
Epoch: 38 | Batch_idx: 80 |  Loss: (0.5094) |  Loss2: (0.0000) | Acc: (82.00%) (8503/10368)
Epoch: 38 | Batch_idx: 90 |  Loss: (0.5054) |  Loss2: (0.0000) | Acc: (82.00%) (9552/11648)
Epoch: 38 | Batch_idx: 100 |  Loss: (0.5035) |  Loss2: (0.0000) | Acc: (82.00%) (10614/12928)
Epoch: 38 | Batch_idx: 110 |  Loss: (0.5044) |  Loss2: (0.0000) | Acc: (82.00%) (11652/14208)
Epoch: 38 | Batch_idx: 120 |  Loss: (0.5005) |  Loss2: (0.0000) | Acc: (82.00%) (12728/15488)
Epoch: 38 | Batch_idx: 130 |  Loss: (0.4988) |  Loss2: (0.0000) | Acc: (82.00%) (13791/16768)
Epoch: 38 | Batch_idx: 140 |  Loss: (0.5004) |  Loss2: (0.0000) | Acc: (82.00%) (14844/18048)
Epoch: 38 | Batch_idx: 150 |  Loss: (0.4993) |  Loss2: (0.0000) | Acc: (82.00%) (15918/19328)
Epoch: 38 | Batch_idx: 160 |  Loss: (0.5017) |  Loss2: (0.0000) | Acc: (82.00%) (16960/20608)
Epoch: 38 | Batch_idx: 170 |  Loss: (0.5000) |  Loss2: (0.0000) | Acc: (82.00%) (18036/21888)
Epoch: 38 | Batch_idx: 180 |  Loss: (0.5008) |  Loss2: (0.0000) | Acc: (82.00%) (19099/23168)
Epoch: 38 | Batch_idx: 190 |  Loss: (0.5005) |  Loss2: (0.0000) | Acc: (82.00%) (20160/24448)
Epoch: 38 | Batch_idx: 200 |  Loss: (0.4997) |  Loss2: (0.0000) | Acc: (82.00%) (21225/25728)
Epoch: 38 | Batch_idx: 210 |  Loss: (0.4997) |  Loss2: (0.0000) | Acc: (82.00%) (22285/27008)
Epoch: 38 | Batch_idx: 220 |  Loss: (0.5018) |  Loss2: (0.0000) | Acc: (82.00%) (23330/28288)
Epoch: 38 | Batch_idx: 230 |  Loss: (0.5009) |  Loss2: (0.0000) | Acc: (82.00%) (24401/29568)
Epoch: 38 | Batch_idx: 240 |  Loss: (0.5004) |  Loss2: (0.0000) | Acc: (82.00%) (25482/30848)
Epoch: 38 | Batch_idx: 250 |  Loss: (0.5012) |  Loss2: (0.0000) | Acc: (82.00%) (26528/32128)
Epoch: 38 | Batch_idx: 260 |  Loss: (0.5009) |  Loss2: (0.0000) | Acc: (82.00%) (27594/33408)
Epoch: 38 | Batch_idx: 270 |  Loss: (0.5004) |  Loss2: (0.0000) | Acc: (82.00%) (28663/34688)
Epoch: 38 | Batch_idx: 280 |  Loss: (0.5004) |  Loss2: (0.0000) | Acc: (82.00%) (29725/35968)
Epoch: 38 | Batch_idx: 290 |  Loss: (0.4999) |  Loss2: (0.0000) | Acc: (82.00%) (30798/37248)
Epoch: 38 | Batch_idx: 300 |  Loss: (0.5004) |  Loss2: (0.0000) | Acc: (82.00%) (31836/38528)
Epoch: 38 | Batch_idx: 310 |  Loss: (0.5000) |  Loss2: (0.0000) | Acc: (82.00%) (32908/39808)
Epoch: 38 | Batch_idx: 320 |  Loss: (0.5004) |  Loss2: (0.0000) | Acc: (82.00%) (33978/41088)
Epoch: 38 | Batch_idx: 330 |  Loss: (0.5003) |  Loss2: (0.0000) | Acc: (82.00%) (35028/42368)
Epoch: 38 | Batch_idx: 340 |  Loss: (0.4991) |  Loss2: (0.0000) | Acc: (82.00%) (36111/43648)
Epoch: 38 | Batch_idx: 350 |  Loss: (0.4988) |  Loss2: (0.0000) | Acc: (82.00%) (37181/44928)
Epoch: 38 | Batch_idx: 360 |  Loss: (0.4997) |  Loss2: (0.0000) | Acc: (82.00%) (38218/46208)
Epoch: 38 | Batch_idx: 370 |  Loss: (0.4993) |  Loss2: (0.0000) | Acc: (82.00%) (39285/47488)
Epoch: 38 | Batch_idx: 380 |  Loss: (0.4993) |  Loss2: (0.0000) | Acc: (82.00%) (40347/48768)
Epoch: 38 | Batch_idx: 390 |  Loss: (0.5000) |  Loss2: (0.0000) | Acc: (82.00%) (41355/50000)
# TEST : Loss: (0.5644) | Acc: (81.00%) (8103/10000)
percent tensor([0.5239, 0.5269, 0.5295, 0.5324, 0.5306, 0.5319, 0.5277, 0.5299, 0.5236,
        0.5241, 0.5233, 0.5259, 0.5232, 0.5244, 0.5298, 0.5254],
       device='cuda:0') torch.Size([16])
percent tensor([0.5486, 0.5493, 0.5448, 0.5420, 0.5468, 0.5570, 0.5522, 0.5437, 0.5471,
        0.5472, 0.5514, 0.5507, 0.5449, 0.5468, 0.5553, 0.5502],
       device='cuda:0') torch.Size([16])
percent tensor([0.5460, 0.5653, 0.5349, 0.5274, 0.5396, 0.5192, 0.5564, 0.5446, 0.5452,
        0.5603, 0.5538, 0.5501, 0.5544, 0.5647, 0.5490, 0.5516],
       device='cuda:0') torch.Size([16])
percent tensor([0.5653, 0.5598, 0.5499, 0.5551, 0.5535, 0.5700, 0.5600, 0.5512, 0.5570,
        0.5600, 0.5643, 0.5520, 0.5589, 0.5603, 0.5709, 0.5664],
       device='cuda:0') torch.Size([16])
percent tensor([0.4358, 0.4390, 0.4918, 0.5062, 0.5103, 0.4776, 0.4720, 0.5006, 0.4724,
        0.4324, 0.4364, 0.4454, 0.3963, 0.4756, 0.4600, 0.4534],
       device='cuda:0') torch.Size([16])
percent tensor([0.4583, 0.4591, 0.5004, 0.5154, 0.5077, 0.5163, 0.4788, 0.4690, 0.5052,
        0.4564, 0.4889, 0.4863, 0.4542, 0.5010, 0.4473, 0.4646],
       device='cuda:0') torch.Size([16])
percent tensor([0.5266, 0.5250, 0.6073, 0.6146, 0.6286, 0.5486, 0.5693, 0.5995, 0.5680,
        0.5448, 0.5396, 0.5904, 0.5115, 0.5681, 0.5472, 0.5261],
       device='cuda:0') torch.Size([16])
percent tensor([0.9944, 0.9882, 0.9949, 0.9939, 0.9979, 0.9918, 0.9962, 0.9978, 0.9932,
        0.9957, 0.9910, 0.9962, 0.9920, 0.9941, 0.9954, 0.9955],
       device='cuda:0') torch.Size([16])
Epoch: 39 | Batch_idx: 0 |  Loss: (0.5082) |  Loss2: (0.0000) | Acc: (81.00%) (104/128)
Epoch: 39 | Batch_idx: 10 |  Loss: (0.4902) |  Loss2: (0.0000) | Acc: (83.00%) (1169/1408)
Epoch: 39 | Batch_idx: 20 |  Loss: (0.4818) |  Loss2: (0.0000) | Acc: (83.00%) (2237/2688)
Epoch: 39 | Batch_idx: 30 |  Loss: (0.4984) |  Loss2: (0.0000) | Acc: (82.00%) (3274/3968)
Epoch: 39 | Batch_idx: 40 |  Loss: (0.5012) |  Loss2: (0.0000) | Acc: (82.00%) (4330/5248)
Epoch: 39 | Batch_idx: 50 |  Loss: (0.4961) |  Loss2: (0.0000) | Acc: (82.00%) (5410/6528)
Epoch: 39 | Batch_idx: 60 |  Loss: (0.4976) |  Loss2: (0.0000) | Acc: (82.00%) (6472/7808)
Epoch: 39 | Batch_idx: 70 |  Loss: (0.4943) |  Loss2: (0.0000) | Acc: (82.00%) (7540/9088)
Epoch: 39 | Batch_idx: 80 |  Loss: (0.4908) |  Loss2: (0.0000) | Acc: (83.00%) (8616/10368)
Epoch: 39 | Batch_idx: 90 |  Loss: (0.4912) |  Loss2: (0.0000) | Acc: (83.00%) (9676/11648)
Epoch: 39 | Batch_idx: 100 |  Loss: (0.4936) |  Loss2: (0.0000) | Acc: (82.00%) (10714/12928)
Epoch: 39 | Batch_idx: 110 |  Loss: (0.4928) |  Loss2: (0.0000) | Acc: (82.00%) (11782/14208)
Epoch: 39 | Batch_idx: 120 |  Loss: (0.4940) |  Loss2: (0.0000) | Acc: (82.00%) (12845/15488)
Epoch: 39 | Batch_idx: 130 |  Loss: (0.4931) |  Loss2: (0.0000) | Acc: (83.00%) (13928/16768)
Epoch: 39 | Batch_idx: 140 |  Loss: (0.4941) |  Loss2: (0.0000) | Acc: (83.00%) (14985/18048)
Epoch: 39 | Batch_idx: 150 |  Loss: (0.4939) |  Loss2: (0.0000) | Acc: (83.00%) (16049/19328)
Epoch: 39 | Batch_idx: 160 |  Loss: (0.4936) |  Loss2: (0.0000) | Acc: (83.00%) (17112/20608)
Epoch: 39 | Batch_idx: 170 |  Loss: (0.4933) |  Loss2: (0.0000) | Acc: (83.00%) (18177/21888)
Epoch: 39 | Batch_idx: 180 |  Loss: (0.4937) |  Loss2: (0.0000) | Acc: (83.00%) (19235/23168)
Epoch: 39 | Batch_idx: 190 |  Loss: (0.4919) |  Loss2: (0.0000) | Acc: (83.00%) (20298/24448)
Epoch: 39 | Batch_idx: 200 |  Loss: (0.4899) |  Loss2: (0.0000) | Acc: (83.00%) (21379/25728)
Epoch: 39 | Batch_idx: 210 |  Loss: (0.4907) |  Loss2: (0.0000) | Acc: (83.00%) (22442/27008)
Epoch: 39 | Batch_idx: 220 |  Loss: (0.4905) |  Loss2: (0.0000) | Acc: (83.00%) (23500/28288)
Epoch: 39 | Batch_idx: 230 |  Loss: (0.4905) |  Loss2: (0.0000) | Acc: (83.00%) (24564/29568)
Epoch: 39 | Batch_idx: 240 |  Loss: (0.4906) |  Loss2: (0.0000) | Acc: (83.00%) (25630/30848)
Epoch: 39 | Batch_idx: 250 |  Loss: (0.4914) |  Loss2: (0.0000) | Acc: (83.00%) (26676/32128)
Epoch: 39 | Batch_idx: 260 |  Loss: (0.4911) |  Loss2: (0.0000) | Acc: (83.00%) (27746/33408)
Epoch: 39 | Batch_idx: 270 |  Loss: (0.4898) |  Loss2: (0.0000) | Acc: (83.00%) (28831/34688)
Epoch: 39 | Batch_idx: 280 |  Loss: (0.4884) |  Loss2: (0.0000) | Acc: (83.00%) (29918/35968)
Epoch: 39 | Batch_idx: 290 |  Loss: (0.4890) |  Loss2: (0.0000) | Acc: (83.00%) (30988/37248)
Epoch: 39 | Batch_idx: 300 |  Loss: (0.4901) |  Loss2: (0.0000) | Acc: (83.00%) (32032/38528)
Epoch: 39 | Batch_idx: 310 |  Loss: (0.4896) |  Loss2: (0.0000) | Acc: (83.00%) (33104/39808)
Epoch: 39 | Batch_idx: 320 |  Loss: (0.4898) |  Loss2: (0.0000) | Acc: (83.00%) (34158/41088)
Epoch: 39 | Batch_idx: 330 |  Loss: (0.4893) |  Loss2: (0.0000) | Acc: (83.00%) (35230/42368)
Epoch: 39 | Batch_idx: 340 |  Loss: (0.4886) |  Loss2: (0.0000) | Acc: (83.00%) (36305/43648)
Epoch: 39 | Batch_idx: 350 |  Loss: (0.4895) |  Loss2: (0.0000) | Acc: (83.00%) (37369/44928)
Epoch: 39 | Batch_idx: 360 |  Loss: (0.4886) |  Loss2: (0.0000) | Acc: (83.00%) (38462/46208)
Epoch: 39 | Batch_idx: 370 |  Loss: (0.4893) |  Loss2: (0.0000) | Acc: (83.00%) (39508/47488)
Epoch: 39 | Batch_idx: 380 |  Loss: (0.4892) |  Loss2: (0.0000) | Acc: (83.00%) (40571/48768)
Epoch: 39 | Batch_idx: 390 |  Loss: (0.4895) |  Loss2: (0.0000) | Acc: (83.00%) (41594/50000)
# TEST : Loss: (0.5558) | Acc: (81.00%) (8130/10000)
percent tensor([0.5243, 0.5271, 0.5299, 0.5334, 0.5309, 0.5330, 0.5278, 0.5303, 0.5238,
        0.5242, 0.5235, 0.5259, 0.5234, 0.5247, 0.5304, 0.5260],
       device='cuda:0') torch.Size([16])
percent tensor([0.5492, 0.5495, 0.5455, 0.5423, 0.5473, 0.5582, 0.5524, 0.5436, 0.5471,
        0.5475, 0.5518, 0.5510, 0.5451, 0.5466, 0.5560, 0.5507],
       device='cuda:0') torch.Size([16])
percent tensor([0.5472, 0.5661, 0.5369, 0.5281, 0.5413, 0.5193, 0.5578, 0.5462, 0.5462,
        0.5618, 0.5544, 0.5520, 0.5556, 0.5651, 0.5500, 0.5526],
       device='cuda:0') torch.Size([16])
percent tensor([0.5667, 0.5613, 0.5502, 0.5546, 0.5537, 0.5710, 0.5610, 0.5506, 0.5574,
        0.5615, 0.5660, 0.5524, 0.5605, 0.5610, 0.5721, 0.5678],
       device='cuda:0') torch.Size([16])
percent tensor([0.4453, 0.4509, 0.5005, 0.5135, 0.5187, 0.4833, 0.4837, 0.5096, 0.4788,
        0.4435, 0.4477, 0.4521, 0.4036, 0.4826, 0.4731, 0.4629],
       device='cuda:0') torch.Size([16])
percent tensor([0.4591, 0.4619, 0.5036, 0.5192, 0.5118, 0.5200, 0.4821, 0.4704, 0.5099,
        0.4583, 0.4939, 0.4894, 0.4560, 0.5064, 0.4482, 0.4659],
       device='cuda:0') torch.Size([16])
percent tensor([0.5283, 0.5285, 0.6128, 0.6190, 0.6360, 0.5508, 0.5737, 0.6052, 0.5719,
        0.5488, 0.5430, 0.5952, 0.5121, 0.5723, 0.5513, 0.5278],
       device='cuda:0') torch.Size([16])
percent tensor([0.9956, 0.9903, 0.9959, 0.9948, 0.9983, 0.9934, 0.9970, 0.9982, 0.9947,
        0.9966, 0.9928, 0.9969, 0.9935, 0.9952, 0.9963, 0.9965],
       device='cuda:0') torch.Size([16])
Epoch: 40 | Batch_idx: 0 |  Loss: (0.5691) |  Loss2: (0.0000) | Acc: (78.00%) (101/128)
Epoch: 40 | Batch_idx: 10 |  Loss: (0.5031) |  Loss2: (0.0000) | Acc: (82.00%) (1168/1408)
Epoch: 40 | Batch_idx: 20 |  Loss: (0.4907) |  Loss2: (0.0000) | Acc: (83.00%) (2233/2688)
Epoch: 40 | Batch_idx: 30 |  Loss: (0.4927) |  Loss2: (0.0000) | Acc: (83.00%) (3305/3968)
Epoch: 40 | Batch_idx: 40 |  Loss: (0.4942) |  Loss2: (0.0000) | Acc: (83.00%) (4361/5248)
Epoch: 40 | Batch_idx: 50 |  Loss: (0.4892) |  Loss2: (0.0000) | Acc: (83.00%) (5436/6528)
Epoch: 40 | Batch_idx: 60 |  Loss: (0.4869) |  Loss2: (0.0000) | Acc: (83.00%) (6491/7808)
Epoch: 40 | Batch_idx: 70 |  Loss: (0.4898) |  Loss2: (0.0000) | Acc: (82.00%) (7540/9088)
Epoch: 40 | Batch_idx: 80 |  Loss: (0.4895) |  Loss2: (0.0000) | Acc: (82.00%) (8592/10368)
Epoch: 40 | Batch_idx: 90 |  Loss: (0.4894) |  Loss2: (0.0000) | Acc: (82.00%) (9651/11648)
Epoch: 40 | Batch_idx: 100 |  Loss: (0.4924) |  Loss2: (0.0000) | Acc: (82.00%) (10701/12928)
Epoch: 40 | Batch_idx: 110 |  Loss: (0.4857) |  Loss2: (0.0000) | Acc: (83.00%) (11805/14208)
Epoch: 40 | Batch_idx: 120 |  Loss: (0.4846) |  Loss2: (0.0000) | Acc: (83.00%) (12880/15488)
Epoch: 40 | Batch_idx: 130 |  Loss: (0.4872) |  Loss2: (0.0000) | Acc: (83.00%) (13930/16768)
Epoch: 40 | Batch_idx: 140 |  Loss: (0.4899) |  Loss2: (0.0000) | Acc: (83.00%) (14986/18048)
Epoch: 40 | Batch_idx: 150 |  Loss: (0.4906) |  Loss2: (0.0000) | Acc: (82.00%) (16039/19328)
Epoch: 40 | Batch_idx: 160 |  Loss: (0.4900) |  Loss2: (0.0000) | Acc: (83.00%) (17120/20608)
Epoch: 40 | Batch_idx: 170 |  Loss: (0.4903) |  Loss2: (0.0000) | Acc: (83.00%) (18178/21888)
Epoch: 40 | Batch_idx: 180 |  Loss: (0.4887) |  Loss2: (0.0000) | Acc: (83.00%) (19248/23168)
Epoch: 40 | Batch_idx: 190 |  Loss: (0.4896) |  Loss2: (0.0000) | Acc: (83.00%) (20302/24448)
Epoch: 40 | Batch_idx: 200 |  Loss: (0.4909) |  Loss2: (0.0000) | Acc: (83.00%) (21355/25728)
Epoch: 40 | Batch_idx: 210 |  Loss: (0.4912) |  Loss2: (0.0000) | Acc: (83.00%) (22427/27008)
Epoch: 40 | Batch_idx: 220 |  Loss: (0.4905) |  Loss2: (0.0000) | Acc: (83.00%) (23492/28288)
Epoch: 40 | Batch_idx: 230 |  Loss: (0.4896) |  Loss2: (0.0000) | Acc: (83.00%) (24551/29568)
Epoch: 40 | Batch_idx: 240 |  Loss: (0.4887) |  Loss2: (0.0000) | Acc: (83.00%) (25604/30848)
Epoch: 40 | Batch_idx: 250 |  Loss: (0.4889) |  Loss2: (0.0000) | Acc: (82.00%) (26658/32128)
Epoch: 40 | Batch_idx: 260 |  Loss: (0.4897) |  Loss2: (0.0000) | Acc: (82.00%) (27700/33408)
Epoch: 40 | Batch_idx: 270 |  Loss: (0.4900) |  Loss2: (0.0000) | Acc: (82.00%) (28757/34688)
Epoch: 40 | Batch_idx: 280 |  Loss: (0.4915) |  Loss2: (0.0000) | Acc: (82.00%) (29804/35968)
Epoch: 40 | Batch_idx: 290 |  Loss: (0.4917) |  Loss2: (0.0000) | Acc: (82.00%) (30884/37248)
Epoch: 40 | Batch_idx: 300 |  Loss: (0.4916) |  Loss2: (0.0000) | Acc: (82.00%) (31958/38528)
Epoch: 40 | Batch_idx: 310 |  Loss: (0.4906) |  Loss2: (0.0000) | Acc: (83.00%) (33055/39808)
Epoch: 40 | Batch_idx: 320 |  Loss: (0.4909) |  Loss2: (0.0000) | Acc: (83.00%) (34117/41088)
Epoch: 40 | Batch_idx: 330 |  Loss: (0.4903) |  Loss2: (0.0000) | Acc: (83.00%) (35196/42368)
Epoch: 40 | Batch_idx: 340 |  Loss: (0.4899) |  Loss2: (0.0000) | Acc: (83.00%) (36275/43648)
Epoch: 40 | Batch_idx: 350 |  Loss: (0.4900) |  Loss2: (0.0000) | Acc: (83.00%) (37340/44928)
Epoch: 40 | Batch_idx: 360 |  Loss: (0.4904) |  Loss2: (0.0000) | Acc: (83.00%) (38386/46208)
Epoch: 40 | Batch_idx: 370 |  Loss: (0.4901) |  Loss2: (0.0000) | Acc: (83.00%) (39453/47488)
Epoch: 40 | Batch_idx: 380 |  Loss: (0.4899) |  Loss2: (0.0000) | Acc: (83.00%) (40515/48768)
Epoch: 40 | Batch_idx: 390 |  Loss: (0.4895) |  Loss2: (0.0000) | Acc: (83.00%) (41552/50000)
=> saving checkpoint 'drive/app/torch/save_Schedule/checkpoint_040.pth.tar'
# TEST : Loss: (0.5504) | Acc: (81.00%) (8137/10000)
percent tensor([0.5254, 0.5280, 0.5312, 0.5349, 0.5321, 0.5343, 0.5288, 0.5316, 0.5246,
        0.5252, 0.5244, 0.5270, 0.5243, 0.5254, 0.5315, 0.5272],
       device='cuda:0') torch.Size([16])
percent tensor([0.5475, 0.5470, 0.5444, 0.5406, 0.5458, 0.5569, 0.5501, 0.5414, 0.5451,
        0.5452, 0.5497, 0.5492, 0.5431, 0.5439, 0.5541, 0.5489],
       device='cuda:0') torch.Size([16])
percent tensor([0.5481, 0.5676, 0.5383, 0.5288, 0.5429, 0.5198, 0.5593, 0.5477, 0.5471,
        0.5633, 0.5551, 0.5536, 0.5566, 0.5657, 0.5515, 0.5537],
       device='cuda:0') torch.Size([16])
percent tensor([0.5680, 0.5620, 0.5508, 0.5548, 0.5542, 0.5721, 0.5617, 0.5508, 0.5577,
        0.5625, 0.5668, 0.5527, 0.5616, 0.5612, 0.5731, 0.5692],
       device='cuda:0') torch.Size([16])
percent tensor([0.4542, 0.4541, 0.5109, 0.5211, 0.5260, 0.4897, 0.4915, 0.5181, 0.4856,
        0.4496, 0.4508, 0.4596, 0.4063, 0.4864, 0.4807, 0.4714],
       device='cuda:0') torch.Size([16])
percent tensor([0.4601, 0.4639, 0.5065, 0.5232, 0.5152, 0.5240, 0.4843, 0.4705, 0.5149,
        0.4592, 0.4997, 0.4925, 0.4588, 0.5106, 0.4482, 0.4664],
       device='cuda:0') torch.Size([16])
percent tensor([0.5326, 0.5331, 0.6173, 0.6226, 0.6415, 0.5538, 0.5794, 0.6108, 0.5771,
        0.5552, 0.5467, 0.6006, 0.5156, 0.5777, 0.5567, 0.5324],
       device='cuda:0') torch.Size([16])
percent tensor([0.9967, 0.9920, 0.9968, 0.9960, 0.9987, 0.9949, 0.9978, 0.9987, 0.9960,
        0.9974, 0.9944, 0.9977, 0.9948, 0.9962, 0.9972, 0.9974],
       device='cuda:0') torch.Size([16])
Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 3, 3, 3]) tensor(175.4464, device='cuda:0')
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(787.2029, device='cuda:0')
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(796.2224, device='cuda:0')
Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([128, 64, 3, 3]) tensor(1531.9700, device='cuda:0')
Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([128, 64, 1, 1]) tensor(509.6935, device='cuda:0')
Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([128, 128, 3, 3]) tensor(2188.0503, device='cuda:0')
Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([256, 128, 3, 3]) tensor(4302.8789, device='cuda:0')
Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([256, 128, 1, 1]) tensor(1419.2042, device='cuda:0')
Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([256, 256, 3, 3]) tensor(6077.1177, device='cuda:0')
Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([512, 256, 3, 3]) tensor(12090.8242, device='cuda:0')
Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([512, 256, 1, 1]) tensor(4031.7012, device='cuda:0')
Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([512, 512, 3, 3]) tensor(17051.1543, device='cuda:0')
Epoch: 41 | Batch_idx: 0 |  Loss: (0.5759) |  Loss2: (0.0000) | Acc: (79.00%) (102/128)
Epoch: 41 | Batch_idx: 10 |  Loss: (0.4779) |  Loss2: (0.0000) | Acc: (84.00%) (1193/1408)
Epoch: 41 | Batch_idx: 20 |  Loss: (0.4857) |  Loss2: (0.0000) | Acc: (83.00%) (2244/2688)
Epoch: 41 | Batch_idx: 30 |  Loss: (0.4808) |  Loss2: (0.0000) | Acc: (83.00%) (3323/3968)
Epoch: 41 | Batch_idx: 40 |  Loss: (0.4863) |  Loss2: (0.0000) | Acc: (83.00%) (4369/5248)
Epoch: 41 | Batch_idx: 50 |  Loss: (0.4897) |  Loss2: (0.0000) | Acc: (82.00%) (5413/6528)
Epoch: 41 | Batch_idx: 60 |  Loss: (0.4920) |  Loss2: (0.0000) | Acc: (83.00%) (6484/7808)
Epoch: 41 | Batch_idx: 70 |  Loss: (0.4947) |  Loss2: (0.0000) | Acc: (82.00%) (7535/9088)
Epoch: 41 | Batch_idx: 80 |  Loss: (0.4929) |  Loss2: (0.0000) | Acc: (82.00%) (8597/10368)
Epoch: 41 | Batch_idx: 90 |  Loss: (0.4923) |  Loss2: (0.0000) | Acc: (82.00%) (9665/11648)
Epoch: 41 | Batch_idx: 100 |  Loss: (0.4924) |  Loss2: (0.0000) | Acc: (82.00%) (10723/12928)
Epoch: 41 | Batch_idx: 110 |  Loss: (0.4922) |  Loss2: (0.0000) | Acc: (83.00%) (11796/14208)
Epoch: 41 | Batch_idx: 120 |  Loss: (0.4893) |  Loss2: (0.0000) | Acc: (83.00%) (12868/15488)
Epoch: 41 | Batch_idx: 130 |  Loss: (0.4894) |  Loss2: (0.0000) | Acc: (83.00%) (13932/16768)
Epoch: 41 | Batch_idx: 140 |  Loss: (0.4897) |  Loss2: (0.0000) | Acc: (83.00%) (14983/18048)
Epoch: 41 | Batch_idx: 150 |  Loss: (0.4901) |  Loss2: (0.0000) | Acc: (82.00%) (16040/19328)
Epoch: 41 | Batch_idx: 160 |  Loss: (0.4878) |  Loss2: (0.0000) | Acc: (83.00%) (17120/20608)
Epoch: 41 | Batch_idx: 170 |  Loss: (0.4856) |  Loss2: (0.0000) | Acc: (83.00%) (18214/21888)
Epoch: 41 | Batch_idx: 180 |  Loss: (0.4856) |  Loss2: (0.0000) | Acc: (83.00%) (19278/23168)
Epoch: 41 | Batch_idx: 190 |  Loss: (0.4867) |  Loss2: (0.0000) | Acc: (83.00%) (20335/24448)
Epoch: 41 | Batch_idx: 200 |  Loss: (0.4846) |  Loss2: (0.0000) | Acc: (83.00%) (21394/25728)
Epoch: 41 | Batch_idx: 210 |  Loss: (0.4839) |  Loss2: (0.0000) | Acc: (83.00%) (22470/27008)
Epoch: 41 | Batch_idx: 220 |  Loss: (0.4840) |  Loss2: (0.0000) | Acc: (83.00%) (23532/28288)
Epoch: 41 | Batch_idx: 230 |  Loss: (0.4839) |  Loss2: (0.0000) | Acc: (83.00%) (24605/29568)
Epoch: 41 | Batch_idx: 240 |  Loss: (0.4840) |  Loss2: (0.0000) | Acc: (83.00%) (25671/30848)
Epoch: 41 | Batch_idx: 250 |  Loss: (0.4841) |  Loss2: (0.0000) | Acc: (83.00%) (26722/32128)
Epoch: 41 | Batch_idx: 260 |  Loss: (0.4846) |  Loss2: (0.0000) | Acc: (83.00%) (27782/33408)
Epoch: 41 | Batch_idx: 270 |  Loss: (0.4847) |  Loss2: (0.0000) | Acc: (83.00%) (28851/34688)
Epoch: 41 | Batch_idx: 280 |  Loss: (0.4843) |  Loss2: (0.0000) | Acc: (83.00%) (29934/35968)
Epoch: 41 | Batch_idx: 290 |  Loss: (0.4843) |  Loss2: (0.0000) | Acc: (83.00%) (31016/37248)
Epoch: 41 | Batch_idx: 300 |  Loss: (0.4843) |  Loss2: (0.0000) | Acc: (83.00%) (32073/38528)
Epoch: 41 | Batch_idx: 310 |  Loss: (0.4854) |  Loss2: (0.0000) | Acc: (83.00%) (33118/39808)
Epoch: 41 | Batch_idx: 320 |  Loss: (0.4838) |  Loss2: (0.0000) | Acc: (83.00%) (34213/41088)
Epoch: 41 | Batch_idx: 330 |  Loss: (0.4829) |  Loss2: (0.0000) | Acc: (83.00%) (35284/42368)
Epoch: 41 | Batch_idx: 340 |  Loss: (0.4827) |  Loss2: (0.0000) | Acc: (83.00%) (36356/43648)
Epoch: 41 | Batch_idx: 350 |  Loss: (0.4815) |  Loss2: (0.0000) | Acc: (83.00%) (37441/44928)
Epoch: 41 | Batch_idx: 360 |  Loss: (0.4807) |  Loss2: (0.0000) | Acc: (83.00%) (38534/46208)
Epoch: 41 | Batch_idx: 370 |  Loss: (0.4804) |  Loss2: (0.0000) | Acc: (83.00%) (39601/47488)
Epoch: 41 | Batch_idx: 380 |  Loss: (0.4813) |  Loss2: (0.0000) | Acc: (83.00%) (40648/48768)
Epoch: 41 | Batch_idx: 390 |  Loss: (0.4810) |  Loss2: (0.0000) | Acc: (83.00%) (41682/50000)
# TEST : Loss: (0.5490) | Acc: (81.00%) (8143/10000)
percent tensor([0.5263, 0.5290, 0.5323, 0.5366, 0.5331, 0.5359, 0.5296, 0.5328, 0.5253,
        0.5261, 0.5252, 0.5277, 0.5252, 0.5263, 0.5329, 0.5284],
       device='cuda:0') torch.Size([16])
percent tensor([0.5498, 0.5493, 0.5470, 0.5424, 0.5485, 0.5598, 0.5527, 0.5433, 0.5472,
        0.5474, 0.5521, 0.5519, 0.5452, 0.5457, 0.5568, 0.5511],
       device='cuda:0') torch.Size([16])
percent tensor([0.5509, 0.5707, 0.5411, 0.5306, 0.5463, 0.5206, 0.5630, 0.5507, 0.5499,
        0.5664, 0.5580, 0.5566, 0.5593, 0.5688, 0.5543, 0.5564],
       device='cuda:0') torch.Size([16])
percent tensor([0.5695, 0.5634, 0.5511, 0.5542, 0.5546, 0.5729, 0.5628, 0.5506, 0.5584,
        0.5642, 0.5685, 0.5533, 0.5633, 0.5618, 0.5744, 0.5706],
       device='cuda:0') torch.Size([16])
percent tensor([0.4514, 0.4511, 0.5108, 0.5206, 0.5281, 0.4867, 0.4893, 0.5193, 0.4829,
        0.4473, 0.4470, 0.4561, 0.4002, 0.4823, 0.4771, 0.4679],
       device='cuda:0') torch.Size([16])
percent tensor([0.4660, 0.4708, 0.5144, 0.5327, 0.5248, 0.5312, 0.4933, 0.4790, 0.5245,
        0.4647, 0.5091, 0.5011, 0.4643, 0.5203, 0.4560, 0.4721],
       device='cuda:0') torch.Size([16])
percent tensor([0.5387, 0.5397, 0.6229, 0.6271, 0.6474, 0.5613, 0.5853, 0.6160, 0.5840,
        0.5622, 0.5534, 0.6057, 0.5212, 0.5855, 0.5626, 0.5383],
       device='cuda:0') torch.Size([16])
percent tensor([0.9971, 0.9932, 0.9972, 0.9967, 0.9989, 0.9955, 0.9981, 0.9989, 0.9966,
        0.9978, 0.9951, 0.9980, 0.9955, 0.9968, 0.9975, 0.9978],
       device='cuda:0') torch.Size([16])
True Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=128, out_features=16, bias=False)
False Linear(in_features=16, out_features=2, bias=False)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=128, out_features=16, bias=False)
False Linear(in_features=16, out_features=2, bias=False)
True Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=256, out_features=32, bias=False)
False Linear(in_features=32, out_features=2, bias=False)
True Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=256, out_features=32, bias=False)
False Linear(in_features=32, out_features=2, bias=False)
True Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=512, out_features=64, bias=False)
False Linear(in_features=64, out_features=2, bias=False)
True Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=512, out_features=64, bias=False)
False Linear(in_features=64, out_features=2, bias=False)
True Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1024, out_features=128, bias=False)
False Linear(in_features=128, out_features=2, bias=False)
True Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1024, out_features=128, bias=False)
False Linear(in_features=128, out_features=2, bias=False)
True Linear(in_features=512, out_features=10, bias=True)
Epoch: 42 | Batch_idx: 0 |  Loss: (0.4284) |  Loss2: (0.0000) | Acc: (88.00%) (113/128)
Epoch: 42 | Batch_idx: 10 |  Loss: (0.4952) |  Loss2: (0.0000) | Acc: (82.00%) (1168/1408)
Epoch: 42 | Batch_idx: 20 |  Loss: (0.4809) |  Loss2: (0.0000) | Acc: (83.00%) (2246/2688)
Epoch: 42 | Batch_idx: 30 |  Loss: (0.4852) |  Loss2: (0.0000) | Acc: (83.00%) (3317/3968)
Epoch: 42 | Batch_idx: 40 |  Loss: (0.4846) |  Loss2: (0.0000) | Acc: (83.00%) (4371/5248)
Epoch: 42 | Batch_idx: 50 |  Loss: (0.4869) |  Loss2: (0.0000) | Acc: (83.00%) (5423/6528)
Epoch: 42 | Batch_idx: 60 |  Loss: (0.4870) |  Loss2: (0.0000) | Acc: (83.00%) (6484/7808)
Epoch: 42 | Batch_idx: 70 |  Loss: (0.4846) |  Loss2: (0.0000) | Acc: (83.00%) (7553/9088)
Epoch: 42 | Batch_idx: 80 |  Loss: (0.4819) |  Loss2: (0.0000) | Acc: (83.00%) (8636/10368)
Epoch: 42 | Batch_idx: 90 |  Loss: (0.4881) |  Loss2: (0.0000) | Acc: (82.00%) (9667/11648)
Epoch: 42 | Batch_idx: 100 |  Loss: (0.4901) |  Loss2: (0.0000) | Acc: (82.00%) (10720/12928)
Epoch: 42 | Batch_idx: 110 |  Loss: (0.4932) |  Loss2: (0.0000) | Acc: (82.00%) (11776/14208)
Epoch: 42 | Batch_idx: 120 |  Loss: (0.4971) |  Loss2: (0.0000) | Acc: (82.00%) (12816/15488)
Epoch: 42 | Batch_idx: 130 |  Loss: (0.4969) |  Loss2: (0.0000) | Acc: (82.00%) (13886/16768)
Epoch: 42 | Batch_idx: 140 |  Loss: (0.4995) |  Loss2: (0.0000) | Acc: (82.00%) (14914/18048)
Epoch: 42 | Batch_idx: 150 |  Loss: (0.4983) |  Loss2: (0.0000) | Acc: (82.00%) (15983/19328)
Epoch: 42 | Batch_idx: 160 |  Loss: (0.4993) |  Loss2: (0.0000) | Acc: (82.00%) (17027/20608)
Epoch: 42 | Batch_idx: 170 |  Loss: (0.4980) |  Loss2: (0.0000) | Acc: (82.00%) (18099/21888)
Epoch: 42 | Batch_idx: 180 |  Loss: (0.4997) |  Loss2: (0.0000) | Acc: (82.00%) (19148/23168)
Epoch: 42 | Batch_idx: 190 |  Loss: (0.5003) |  Loss2: (0.0000) | Acc: (82.00%) (20191/24448)
Epoch: 42 | Batch_idx: 200 |  Loss: (0.4995) |  Loss2: (0.0000) | Acc: (82.00%) (21245/25728)
Epoch: 42 | Batch_idx: 210 |  Loss: (0.4981) |  Loss2: (0.0000) | Acc: (82.00%) (22310/27008)
Epoch: 42 | Batch_idx: 220 |  Loss: (0.4986) |  Loss2: (0.0000) | Acc: (82.00%) (23372/28288)
Epoch: 42 | Batch_idx: 230 |  Loss: (0.4997) |  Loss2: (0.0000) | Acc: (82.00%) (24410/29568)
Epoch: 42 | Batch_idx: 240 |  Loss: (0.5017) |  Loss2: (0.0000) | Acc: (82.00%) (25445/30848)
Epoch: 42 | Batch_idx: 250 |  Loss: (0.5007) |  Loss2: (0.0000) | Acc: (82.00%) (26527/32128)
Epoch: 42 | Batch_idx: 260 |  Loss: (0.5006) |  Loss2: (0.0000) | Acc: (82.00%) (27584/33408)
Epoch: 42 | Batch_idx: 270 |  Loss: (0.4995) |  Loss2: (0.0000) | Acc: (82.00%) (28648/34688)
Epoch: 42 | Batch_idx: 280 |  Loss: (0.4985) |  Loss2: (0.0000) | Acc: (82.00%) (29727/35968)
Epoch: 42 | Batch_idx: 290 |  Loss: (0.4967) |  Loss2: (0.0000) | Acc: (82.00%) (30809/37248)
Epoch: 42 | Batch_idx: 300 |  Loss: (0.4961) |  Loss2: (0.0000) | Acc: (82.00%) (31874/38528)
Epoch: 42 | Batch_idx: 310 |  Loss: (0.4954) |  Loss2: (0.0000) | Acc: (82.00%) (32943/39808)
Epoch: 42 | Batch_idx: 320 |  Loss: (0.4946) |  Loss2: (0.0000) | Acc: (82.00%) (34009/41088)
Epoch: 42 | Batch_idx: 330 |  Loss: (0.4959) |  Loss2: (0.0000) | Acc: (82.00%) (35045/42368)
Epoch: 42 | Batch_idx: 340 |  Loss: (0.4955) |  Loss2: (0.0000) | Acc: (82.00%) (36114/43648)
Epoch: 42 | Batch_idx: 350 |  Loss: (0.4951) |  Loss2: (0.0000) | Acc: (82.00%) (37186/44928)
Epoch: 42 | Batch_idx: 360 |  Loss: (0.4946) |  Loss2: (0.0000) | Acc: (82.00%) (38262/46208)
Epoch: 42 | Batch_idx: 370 |  Loss: (0.4941) |  Loss2: (0.0000) | Acc: (82.00%) (39331/47488)
Epoch: 42 | Batch_idx: 380 |  Loss: (0.4946) |  Loss2: (0.0000) | Acc: (82.00%) (40384/48768)
Epoch: 42 | Batch_idx: 390 |  Loss: (0.4935) |  Loss2: (0.0000) | Acc: (82.00%) (41423/50000)
# TEST : Loss: (0.6214) | Acc: (79.00%) (7947/10000)
percent tensor([0.5269, 0.5288, 0.5341, 0.5365, 0.5348, 0.5373, 0.5306, 0.5329, 0.5259,
        0.5267, 0.5253, 0.5296, 0.5254, 0.5264, 0.5333, 0.5288],
       device='cuda:0') torch.Size([16])
percent tensor([0.5507, 0.5499, 0.5478, 0.5438, 0.5504, 0.5631, 0.5546, 0.5434, 0.5475,
        0.5479, 0.5522, 0.5533, 0.5454, 0.5491, 0.5575, 0.5524],
       device='cuda:0') torch.Size([16])
percent tensor([0.5539, 0.5662, 0.5391, 0.5309, 0.5430, 0.5233, 0.5603, 0.5480, 0.5499,
        0.5635, 0.5560, 0.5543, 0.5592, 0.5667, 0.5545, 0.5564],
       device='cuda:0') torch.Size([16])
percent tensor([0.5709, 0.5644, 0.5529, 0.5540, 0.5561, 0.5772, 0.5667, 0.5490, 0.5594,
        0.5668, 0.5710, 0.5570, 0.5640, 0.5667, 0.5761, 0.5702],
       device='cuda:0') torch.Size([16])
percent tensor([0.4624, 0.4730, 0.5148, 0.5145, 0.5312, 0.4907, 0.5040, 0.5190, 0.4831,
        0.4717, 0.4644, 0.4719, 0.4219, 0.4881, 0.4864, 0.4753],
       device='cuda:0') torch.Size([16])
percent tensor([0.4662, 0.4671, 0.5087, 0.5270, 0.5179, 0.5265, 0.4982, 0.4696, 0.5238,
        0.4628, 0.5187, 0.5032, 0.4686, 0.5204, 0.4548, 0.4696],
       device='cuda:0') torch.Size([16])
percent tensor([0.5469, 0.5458, 0.6275, 0.6249, 0.6510, 0.5555, 0.5887, 0.6197, 0.5928,
        0.5708, 0.5657, 0.6080, 0.5366, 0.6011, 0.5576, 0.5405],
       device='cuda:0') torch.Size([16])
percent tensor([0.9972, 0.9937, 0.9982, 0.9968, 0.9989, 0.9957, 0.9980, 0.9995, 0.9973,
        0.9975, 0.9969, 0.9979, 0.9968, 0.9969, 0.9972, 0.9978],
       device='cuda:0') torch.Size([16])
Epoch: 43 | Batch_idx: 0 |  Loss: (0.4471) |  Loss2: (0.0000) | Acc: (84.00%) (108/128)
Epoch: 43 | Batch_idx: 10 |  Loss: (0.4935) |  Loss2: (0.0000) | Acc: (82.00%) (1165/1408)
Epoch: 43 | Batch_idx: 20 |  Loss: (0.4790) |  Loss2: (0.0000) | Acc: (83.00%) (2242/2688)
Epoch: 43 | Batch_idx: 30 |  Loss: (0.4775) |  Loss2: (0.0000) | Acc: (83.00%) (3322/3968)
Epoch: 43 | Batch_idx: 40 |  Loss: (0.4758) |  Loss2: (0.0000) | Acc: (83.00%) (4401/5248)
Epoch: 43 | Batch_idx: 50 |  Loss: (0.4729) |  Loss2: (0.0000) | Acc: (83.00%) (5471/6528)
Epoch: 43 | Batch_idx: 60 |  Loss: (0.4712) |  Loss2: (0.0000) | Acc: (83.00%) (6551/7808)
Epoch: 43 | Batch_idx: 70 |  Loss: (0.4741) |  Loss2: (0.0000) | Acc: (83.00%) (7598/9088)
Epoch: 43 | Batch_idx: 80 |  Loss: (0.4781) |  Loss2: (0.0000) | Acc: (83.00%) (8654/10368)
Epoch: 43 | Batch_idx: 90 |  Loss: (0.4775) |  Loss2: (0.0000) | Acc: (83.00%) (9713/11648)
Epoch: 43 | Batch_idx: 100 |  Loss: (0.4778) |  Loss2: (0.0000) | Acc: (83.00%) (10792/12928)
Epoch: 43 | Batch_idx: 110 |  Loss: (0.4781) |  Loss2: (0.0000) | Acc: (83.00%) (11856/14208)
Epoch: 43 | Batch_idx: 120 |  Loss: (0.4776) |  Loss2: (0.0000) | Acc: (83.00%) (12927/15488)
Epoch: 43 | Batch_idx: 130 |  Loss: (0.4781) |  Loss2: (0.0000) | Acc: (83.00%) (13994/16768)
Epoch: 43 | Batch_idx: 140 |  Loss: (0.4794) |  Loss2: (0.0000) | Acc: (83.00%) (15052/18048)
Epoch: 43 | Batch_idx: 150 |  Loss: (0.4798) |  Loss2: (0.0000) | Acc: (83.00%) (16105/19328)
Epoch: 43 | Batch_idx: 160 |  Loss: (0.4791) |  Loss2: (0.0000) | Acc: (83.00%) (17185/20608)
Epoch: 43 | Batch_idx: 170 |  Loss: (0.4776) |  Loss2: (0.0000) | Acc: (83.00%) (18265/21888)
Epoch: 43 | Batch_idx: 180 |  Loss: (0.4760) |  Loss2: (0.0000) | Acc: (83.00%) (19350/23168)
Epoch: 43 | Batch_idx: 190 |  Loss: (0.4749) |  Loss2: (0.0000) | Acc: (83.00%) (20420/24448)
Epoch: 43 | Batch_idx: 200 |  Loss: (0.4734) |  Loss2: (0.0000) | Acc: (83.00%) (21514/25728)
Epoch: 43 | Batch_idx: 210 |  Loss: (0.4727) |  Loss2: (0.0000) | Acc: (83.00%) (22594/27008)
Epoch: 43 | Batch_idx: 220 |  Loss: (0.4729) |  Loss2: (0.0000) | Acc: (83.00%) (23669/28288)
Epoch: 43 | Batch_idx: 230 |  Loss: (0.4733) |  Loss2: (0.0000) | Acc: (83.00%) (24738/29568)
Epoch: 43 | Batch_idx: 240 |  Loss: (0.4719) |  Loss2: (0.0000) | Acc: (83.00%) (25815/30848)
Epoch: 43 | Batch_idx: 250 |  Loss: (0.4716) |  Loss2: (0.0000) | Acc: (83.00%) (26878/32128)
Epoch: 43 | Batch_idx: 260 |  Loss: (0.4709) |  Loss2: (0.0000) | Acc: (83.00%) (27951/33408)
Epoch: 43 | Batch_idx: 270 |  Loss: (0.4721) |  Loss2: (0.0000) | Acc: (83.00%) (29006/34688)
Epoch: 43 | Batch_idx: 280 |  Loss: (0.4726) |  Loss2: (0.0000) | Acc: (83.00%) (30071/35968)
Epoch: 43 | Batch_idx: 290 |  Loss: (0.4718) |  Loss2: (0.0000) | Acc: (83.00%) (31162/37248)
Epoch: 43 | Batch_idx: 300 |  Loss: (0.4718) |  Loss2: (0.0000) | Acc: (83.00%) (32234/38528)
Epoch: 43 | Batch_idx: 310 |  Loss: (0.4710) |  Loss2: (0.0000) | Acc: (83.00%) (33321/39808)
Epoch: 43 | Batch_idx: 320 |  Loss: (0.4718) |  Loss2: (0.0000) | Acc: (83.00%) (34393/41088)
Epoch: 43 | Batch_idx: 330 |  Loss: (0.4722) |  Loss2: (0.0000) | Acc: (83.00%) (35449/42368)
Epoch: 43 | Batch_idx: 340 |  Loss: (0.4723) |  Loss2: (0.0000) | Acc: (83.00%) (36509/43648)
Epoch: 43 | Batch_idx: 350 |  Loss: (0.4716) |  Loss2: (0.0000) | Acc: (83.00%) (37591/44928)
Epoch: 43 | Batch_idx: 360 |  Loss: (0.4713) |  Loss2: (0.0000) | Acc: (83.00%) (38658/46208)
Epoch: 43 | Batch_idx: 370 |  Loss: (0.4721) |  Loss2: (0.0000) | Acc: (83.00%) (39716/47488)
Epoch: 43 | Batch_idx: 380 |  Loss: (0.4721) |  Loss2: (0.0000) | Acc: (83.00%) (40793/48768)
Epoch: 43 | Batch_idx: 390 |  Loss: (0.4720) |  Loss2: (0.0000) | Acc: (83.00%) (41840/50000)
# TEST : Loss: (0.6644) | Acc: (77.00%) (7794/10000)
percent tensor([0.5268, 0.5284, 0.5333, 0.5366, 0.5344, 0.5385, 0.5301, 0.5326, 0.5255,
        0.5263, 0.5250, 0.5288, 0.5255, 0.5253, 0.5339, 0.5289],
       device='cuda:0') torch.Size([16])
percent tensor([0.5489, 0.5453, 0.5473, 0.5414, 0.5493, 0.5608, 0.5512, 0.5429, 0.5434,
        0.5454, 0.5487, 0.5517, 0.5429, 0.5402, 0.5556, 0.5491],
       device='cuda:0') torch.Size([16])
percent tensor([0.5560, 0.5685, 0.5426, 0.5352, 0.5454, 0.5265, 0.5630, 0.5505, 0.5514,
        0.5653, 0.5586, 0.5591, 0.5615, 0.5693, 0.5577, 0.5587],
       device='cuda:0') torch.Size([16])
percent tensor([0.5695, 0.5600, 0.5526, 0.5516, 0.5546, 0.5767, 0.5620, 0.5471, 0.5566,
        0.5636, 0.5669, 0.5531, 0.5627, 0.5560, 0.5731, 0.5688],
       device='cuda:0') torch.Size([16])
percent tensor([0.4414, 0.4407, 0.4999, 0.5065, 0.5296, 0.4838, 0.4710, 0.5062, 0.4640,
        0.4377, 0.4323, 0.4343, 0.3936, 0.4650, 0.4666, 0.4540],
       device='cuda:0') torch.Size([16])
percent tensor([0.4580, 0.4644, 0.5049, 0.5277, 0.5159, 0.5125, 0.4825, 0.4687, 0.5235,
        0.4682, 0.5098, 0.5071, 0.4724, 0.5149, 0.4503, 0.4627],
       device='cuda:0') torch.Size([16])
percent tensor([0.5383, 0.5265, 0.6101, 0.6131, 0.6329, 0.5452, 0.5726, 0.6133, 0.5824,
        0.5556, 0.5553, 0.5942, 0.5213, 0.5861, 0.5590, 0.5340],
       device='cuda:0') torch.Size([16])
percent tensor([0.9981, 0.9933, 0.9972, 0.9968, 0.9979, 0.9951, 0.9983, 0.9993, 0.9957,
        0.9975, 0.9969, 0.9968, 0.9957, 0.9968, 0.9979, 0.9982],
       device='cuda:0') torch.Size([16])
Epoch: 44 | Batch_idx: 0 |  Loss: (0.5394) |  Loss2: (0.0000) | Acc: (80.00%) (103/128)
Epoch: 44 | Batch_idx: 10 |  Loss: (0.4648) |  Loss2: (0.0000) | Acc: (83.00%) (1181/1408)
Epoch: 44 | Batch_idx: 20 |  Loss: (0.4810) |  Loss2: (0.0000) | Acc: (83.00%) (2238/2688)
Epoch: 44 | Batch_idx: 30 |  Loss: (0.4701) |  Loss2: (0.0000) | Acc: (83.00%) (3319/3968)
Epoch: 44 | Batch_idx: 40 |  Loss: (0.4674) |  Loss2: (0.0000) | Acc: (83.00%) (4394/5248)
Epoch: 44 | Batch_idx: 50 |  Loss: (0.4647) |  Loss2: (0.0000) | Acc: (83.00%) (5473/6528)
Epoch: 44 | Batch_idx: 60 |  Loss: (0.4591) |  Loss2: (0.0000) | Acc: (84.00%) (6569/7808)
Epoch: 44 | Batch_idx: 70 |  Loss: (0.4584) |  Loss2: (0.0000) | Acc: (84.00%) (7635/9088)
Epoch: 44 | Batch_idx: 80 |  Loss: (0.4620) |  Loss2: (0.0000) | Acc: (83.00%) (8702/10368)
Epoch: 44 | Batch_idx: 90 |  Loss: (0.4572) |  Loss2: (0.0000) | Acc: (84.00%) (9803/11648)
Epoch: 44 | Batch_idx: 100 |  Loss: (0.4539) |  Loss2: (0.0000) | Acc: (84.00%) (10899/12928)
Epoch: 44 | Batch_idx: 110 |  Loss: (0.4496) |  Loss2: (0.0000) | Acc: (84.00%) (11999/14208)
Epoch: 44 | Batch_idx: 120 |  Loss: (0.4531) |  Loss2: (0.0000) | Acc: (84.00%) (13064/15488)
Epoch: 44 | Batch_idx: 130 |  Loss: (0.4531) |  Loss2: (0.0000) | Acc: (84.00%) (14137/16768)
Epoch: 44 | Batch_idx: 140 |  Loss: (0.4550) |  Loss2: (0.0000) | Acc: (84.00%) (15197/18048)
Epoch: 44 | Batch_idx: 150 |  Loss: (0.4528) |  Loss2: (0.0000) | Acc: (84.00%) (16297/19328)
Epoch: 44 | Batch_idx: 160 |  Loss: (0.4514) |  Loss2: (0.0000) | Acc: (84.00%) (17395/20608)
Epoch: 44 | Batch_idx: 170 |  Loss: (0.4529) |  Loss2: (0.0000) | Acc: (84.00%) (18471/21888)
Epoch: 44 | Batch_idx: 180 |  Loss: (0.4522) |  Loss2: (0.0000) | Acc: (84.00%) (19555/23168)
Epoch: 44 | Batch_idx: 190 |  Loss: (0.4536) |  Loss2: (0.0000) | Acc: (84.00%) (20625/24448)
Epoch: 44 | Batch_idx: 200 |  Loss: (0.4548) |  Loss2: (0.0000) | Acc: (84.00%) (21694/25728)
Epoch: 44 | Batch_idx: 210 |  Loss: (0.4536) |  Loss2: (0.0000) | Acc: (84.00%) (22788/27008)
Epoch: 44 | Batch_idx: 220 |  Loss: (0.4546) |  Loss2: (0.0000) | Acc: (84.00%) (23853/28288)
Epoch: 44 | Batch_idx: 230 |  Loss: (0.4555) |  Loss2: (0.0000) | Acc: (84.00%) (24920/29568)
Epoch: 44 | Batch_idx: 240 |  Loss: (0.4544) |  Loss2: (0.0000) | Acc: (84.00%) (26002/30848)
Epoch: 44 | Batch_idx: 250 |  Loss: (0.4564) |  Loss2: (0.0000) | Acc: (84.00%) (27061/32128)
Epoch: 44 | Batch_idx: 260 |  Loss: (0.4570) |  Loss2: (0.0000) | Acc: (84.00%) (28134/33408)
Epoch: 44 | Batch_idx: 270 |  Loss: (0.4572) |  Loss2: (0.0000) | Acc: (84.00%) (29199/34688)
Epoch: 44 | Batch_idx: 280 |  Loss: (0.4575) |  Loss2: (0.0000) | Acc: (84.00%) (30265/35968)
Epoch: 44 | Batch_idx: 290 |  Loss: (0.4571) |  Loss2: (0.0000) | Acc: (84.00%) (31350/37248)
Epoch: 44 | Batch_idx: 300 |  Loss: (0.4561) |  Loss2: (0.0000) | Acc: (84.00%) (32443/38528)
Epoch: 44 | Batch_idx: 310 |  Loss: (0.4557) |  Loss2: (0.0000) | Acc: (84.00%) (33533/39808)
Epoch: 44 | Batch_idx: 320 |  Loss: (0.4575) |  Loss2: (0.0000) | Acc: (84.00%) (34581/41088)
Epoch: 44 | Batch_idx: 330 |  Loss: (0.4567) |  Loss2: (0.0000) | Acc: (84.00%) (35675/42368)
Epoch: 44 | Batch_idx: 340 |  Loss: (0.4574) |  Loss2: (0.0000) | Acc: (84.00%) (36741/43648)
Epoch: 44 | Batch_idx: 350 |  Loss: (0.4572) |  Loss2: (0.0000) | Acc: (84.00%) (37808/44928)
Epoch: 44 | Batch_idx: 360 |  Loss: (0.4566) |  Loss2: (0.0000) | Acc: (84.00%) (38886/46208)
Epoch: 44 | Batch_idx: 370 |  Loss: (0.4555) |  Loss2: (0.0000) | Acc: (84.00%) (39988/47488)
Epoch: 44 | Batch_idx: 380 |  Loss: (0.4556) |  Loss2: (0.0000) | Acc: (84.00%) (41071/48768)
Epoch: 44 | Batch_idx: 390 |  Loss: (0.4555) |  Loss2: (0.0000) | Acc: (84.00%) (42109/50000)
# TEST : Loss: (0.5334) | Acc: (82.00%) (8200/10000)
percent tensor([0.5252, 0.5281, 0.5323, 0.5360, 0.5341, 0.5369, 0.5296, 0.5313, 0.5245,
        0.5255, 0.5240, 0.5283, 0.5242, 0.5249, 0.5330, 0.5275],
       device='cuda:0') torch.Size([16])
percent tensor([0.5493, 0.5475, 0.5464, 0.5445, 0.5499, 0.5621, 0.5525, 0.5435, 0.5459,
        0.5459, 0.5511, 0.5517, 0.5443, 0.5452, 0.5570, 0.5517],
       device='cuda:0') torch.Size([16])
percent tensor([0.5578, 0.5717, 0.5397, 0.5348, 0.5457, 0.5287, 0.5650, 0.5501, 0.5536,
        0.5659, 0.5609, 0.5542, 0.5643, 0.5725, 0.5592, 0.5615],
       device='cuda:0') torch.Size([16])
percent tensor([0.5700, 0.5619, 0.5490, 0.5555, 0.5531, 0.5786, 0.5643, 0.5479, 0.5593,
        0.5634, 0.5691, 0.5522, 0.5627, 0.5609, 0.5768, 0.5704],
       device='cuda:0') torch.Size([16])
percent tensor([0.4548, 0.4666, 0.5058, 0.5150, 0.5288, 0.4953, 0.4998, 0.5134, 0.4782,
        0.4541, 0.4569, 0.4579, 0.4142, 0.4957, 0.4842, 0.4737],
       device='cuda:0') torch.Size([16])
percent tensor([0.4643, 0.4671, 0.5050, 0.5241, 0.5163, 0.5147, 0.4884, 0.4709, 0.5243,
        0.4731, 0.5117, 0.5085, 0.4760, 0.5263, 0.4549, 0.4669],
       device='cuda:0') torch.Size([16])
percent tensor([0.5490, 0.5443, 0.6225, 0.6198, 0.6336, 0.5495, 0.5931, 0.6138, 0.5866,
        0.5625, 0.5653, 0.6113, 0.5375, 0.6076, 0.5636, 0.5423],
       device='cuda:0') torch.Size([16])
percent tensor([0.9969, 0.9947, 0.9977, 0.9965, 0.9982, 0.9967, 0.9987, 0.9992, 0.9954,
        0.9976, 0.9972, 0.9980, 0.9956, 0.9968, 0.9968, 0.9976],
       device='cuda:0') torch.Size([16])
Epoch: 45 | Batch_idx: 0 |  Loss: (0.3786) |  Loss2: (0.0000) | Acc: (88.00%) (113/128)
Epoch: 45 | Batch_idx: 10 |  Loss: (0.4041) |  Loss2: (0.0000) | Acc: (86.00%) (1212/1408)
Epoch: 45 | Batch_idx: 20 |  Loss: (0.4323) |  Loss2: (0.0000) | Acc: (85.00%) (2289/2688)
Epoch: 45 | Batch_idx: 30 |  Loss: (0.4384) |  Loss2: (0.0000) | Acc: (85.00%) (3382/3968)
Epoch: 45 | Batch_idx: 40 |  Loss: (0.4481) |  Loss2: (0.0000) | Acc: (84.00%) (4460/5248)
Epoch: 45 | Batch_idx: 50 |  Loss: (0.4433) |  Loss2: (0.0000) | Acc: (85.00%) (5560/6528)
Epoch: 45 | Batch_idx: 60 |  Loss: (0.4401) |  Loss2: (0.0000) | Acc: (85.00%) (6642/7808)
Epoch: 45 | Batch_idx: 70 |  Loss: (0.4363) |  Loss2: (0.0000) | Acc: (85.00%) (7725/9088)
Epoch: 45 | Batch_idx: 80 |  Loss: (0.4392) |  Loss2: (0.0000) | Acc: (85.00%) (8814/10368)
Epoch: 45 | Batch_idx: 90 |  Loss: (0.4402) |  Loss2: (0.0000) | Acc: (84.00%) (9893/11648)
Epoch: 45 | Batch_idx: 100 |  Loss: (0.4387) |  Loss2: (0.0000) | Acc: (85.00%) (10995/12928)
Epoch: 45 | Batch_idx: 110 |  Loss: (0.4404) |  Loss2: (0.0000) | Acc: (84.00%) (12070/14208)
Epoch: 45 | Batch_idx: 120 |  Loss: (0.4408) |  Loss2: (0.0000) | Acc: (84.00%) (13144/15488)
Epoch: 45 | Batch_idx: 130 |  Loss: (0.4440) |  Loss2: (0.0000) | Acc: (84.00%) (14193/16768)
Epoch: 45 | Batch_idx: 140 |  Loss: (0.4409) |  Loss2: (0.0000) | Acc: (84.00%) (15300/18048)
Epoch: 45 | Batch_idx: 150 |  Loss: (0.4413) |  Loss2: (0.0000) | Acc: (84.00%) (16381/19328)
Epoch: 45 | Batch_idx: 160 |  Loss: (0.4437) |  Loss2: (0.0000) | Acc: (84.00%) (17452/20608)
Epoch: 45 | Batch_idx: 170 |  Loss: (0.4414) |  Loss2: (0.0000) | Acc: (84.00%) (18551/21888)
Epoch: 45 | Batch_idx: 180 |  Loss: (0.4415) |  Loss2: (0.0000) | Acc: (84.00%) (19631/23168)
Epoch: 45 | Batch_idx: 190 |  Loss: (0.4400) |  Loss2: (0.0000) | Acc: (84.00%) (20731/24448)
Epoch: 45 | Batch_idx: 200 |  Loss: (0.4381) |  Loss2: (0.0000) | Acc: (84.00%) (21834/25728)
Epoch: 45 | Batch_idx: 210 |  Loss: (0.4400) |  Loss2: (0.0000) | Acc: (84.00%) (22894/27008)
Epoch: 45 | Batch_idx: 220 |  Loss: (0.4421) |  Loss2: (0.0000) | Acc: (84.00%) (23950/28288)
Epoch: 45 | Batch_idx: 230 |  Loss: (0.4438) |  Loss2: (0.0000) | Acc: (84.00%) (25009/29568)
Epoch: 45 | Batch_idx: 240 |  Loss: (0.4446) |  Loss2: (0.0000) | Acc: (84.00%) (26080/30848)
Epoch: 45 | Batch_idx: 250 |  Loss: (0.4441) |  Loss2: (0.0000) | Acc: (84.00%) (27167/32128)
Epoch: 45 | Batch_idx: 260 |  Loss: (0.4450) |  Loss2: (0.0000) | Acc: (84.00%) (28245/33408)
Epoch: 45 | Batch_idx: 270 |  Loss: (0.4448) |  Loss2: (0.0000) | Acc: (84.00%) (29331/34688)
Epoch: 45 | Batch_idx: 280 |  Loss: (0.4459) |  Loss2: (0.0000) | Acc: (84.00%) (30393/35968)
Epoch: 45 | Batch_idx: 290 |  Loss: (0.4453) |  Loss2: (0.0000) | Acc: (84.00%) (31491/37248)
Epoch: 45 | Batch_idx: 300 |  Loss: (0.4464) |  Loss2: (0.0000) | Acc: (84.00%) (32554/38528)
Epoch: 45 | Batch_idx: 310 |  Loss: (0.4477) |  Loss2: (0.0000) | Acc: (84.00%) (33629/39808)
Epoch: 45 | Batch_idx: 320 |  Loss: (0.4473) |  Loss2: (0.0000) | Acc: (84.00%) (34720/41088)
Epoch: 45 | Batch_idx: 330 |  Loss: (0.4468) |  Loss2: (0.0000) | Acc: (84.00%) (35813/42368)
Epoch: 45 | Batch_idx: 340 |  Loss: (0.4474) |  Loss2: (0.0000) | Acc: (84.00%) (36898/43648)
Epoch: 45 | Batch_idx: 350 |  Loss: (0.4478) |  Loss2: (0.0000) | Acc: (84.00%) (37959/44928)
Epoch: 45 | Batch_idx: 360 |  Loss: (0.4475) |  Loss2: (0.0000) | Acc: (84.00%) (39046/46208)
Epoch: 45 | Batch_idx: 370 |  Loss: (0.4468) |  Loss2: (0.0000) | Acc: (84.00%) (40139/47488)
Epoch: 45 | Batch_idx: 380 |  Loss: (0.4471) |  Loss2: (0.0000) | Acc: (84.00%) (41230/48768)
Epoch: 45 | Batch_idx: 390 |  Loss: (0.4480) |  Loss2: (0.0000) | Acc: (84.00%) (42259/50000)
=> saving checkpoint 'drive/app/torch/save_Schedule/checkpoint_045.pth.tar'
# TEST : Loss: (0.5367) | Acc: (81.00%) (8194/10000)
percent tensor([0.5263, 0.5277, 0.5353, 0.5372, 0.5363, 0.5390, 0.5301, 0.5331, 0.5248,
        0.5262, 0.5241, 0.5302, 0.5249, 0.5242, 0.5335, 0.5286],
       device='cuda:0') torch.Size([16])
percent tensor([0.5508, 0.5484, 0.5464, 0.5446, 0.5495, 0.5639, 0.5529, 0.5448, 0.5462,
        0.5464, 0.5523, 0.5506, 0.5450, 0.5473, 0.5578, 0.5531],
       device='cuda:0') torch.Size([16])
percent tensor([0.5528, 0.5732, 0.5373, 0.5322, 0.5424, 0.5211, 0.5647, 0.5492, 0.5526,
        0.5676, 0.5587, 0.5541, 0.5610, 0.5764, 0.5556, 0.5568],
       device='cuda:0') torch.Size([16])
percent tensor([0.5711, 0.5632, 0.5521, 0.5557, 0.5553, 0.5793, 0.5664, 0.5517, 0.5595,
        0.5658, 0.5686, 0.5530, 0.5630, 0.5662, 0.5768, 0.5717],
       device='cuda:0') torch.Size([16])
percent tensor([0.4612, 0.4620, 0.5095, 0.5119, 0.5280, 0.5013, 0.4841, 0.5197, 0.4720,
        0.4628, 0.4562, 0.4578, 0.4203, 0.4779, 0.4837, 0.4722],
       device='cuda:0') torch.Size([16])
percent tensor([0.4742, 0.4866, 0.5148, 0.5319, 0.5259, 0.5272, 0.4959, 0.4824, 0.5304,
        0.4767, 0.5235, 0.5178, 0.4814, 0.5334, 0.4686, 0.4797],
       device='cuda:0') torch.Size([16])
percent tensor([0.5535, 0.5451, 0.6172, 0.6175, 0.6460, 0.5530, 0.5822, 0.6138, 0.5876,
        0.5666, 0.5603, 0.6020, 0.5368, 0.5969, 0.5561, 0.5469],
       device='cuda:0') torch.Size([16])
percent tensor([0.9962, 0.9934, 0.9966, 0.9960, 0.9989, 0.9946, 0.9973, 0.9993, 0.9950,
        0.9978, 0.9966, 0.9964, 0.9947, 0.9956, 0.9974, 0.9978],
       device='cuda:0') torch.Size([16])
Epoch: 46 | Batch_idx: 0 |  Loss: (0.2949) |  Loss2: (0.0000) | Acc: (91.00%) (117/128)
Epoch: 46 | Batch_idx: 10 |  Loss: (0.4130) |  Loss2: (0.0000) | Acc: (84.00%) (1193/1408)
Epoch: 46 | Batch_idx: 20 |  Loss: (0.4033) |  Loss2: (0.0000) | Acc: (85.00%) (2294/2688)
Epoch: 46 | Batch_idx: 30 |  Loss: (0.4097) |  Loss2: (0.0000) | Acc: (85.00%) (3390/3968)
Epoch: 46 | Batch_idx: 40 |  Loss: (0.4189) |  Loss2: (0.0000) | Acc: (85.00%) (4468/5248)
Epoch: 46 | Batch_idx: 50 |  Loss: (0.4236) |  Loss2: (0.0000) | Acc: (84.00%) (5540/6528)
Epoch: 46 | Batch_idx: 60 |  Loss: (0.4197) |  Loss2: (0.0000) | Acc: (85.00%) (6651/7808)
Epoch: 46 | Batch_idx: 70 |  Loss: (0.4259) |  Loss2: (0.0000) | Acc: (84.00%) (7720/9088)
Epoch: 46 | Batch_idx: 80 |  Loss: (0.4297) |  Loss2: (0.0000) | Acc: (84.00%) (8786/10368)
Epoch: 46 | Batch_idx: 90 |  Loss: (0.4315) |  Loss2: (0.0000) | Acc: (84.00%) (9859/11648)
Epoch: 46 | Batch_idx: 100 |  Loss: (0.4297) |  Loss2: (0.0000) | Acc: (84.00%) (10956/12928)
Epoch: 46 | Batch_idx: 110 |  Loss: (0.4331) |  Loss2: (0.0000) | Acc: (84.00%) (12034/14208)
Epoch: 46 | Batch_idx: 120 |  Loss: (0.4316) |  Loss2: (0.0000) | Acc: (84.00%) (13124/15488)
Epoch: 46 | Batch_idx: 130 |  Loss: (0.4299) |  Loss2: (0.0000) | Acc: (84.00%) (14211/16768)
Epoch: 46 | Batch_idx: 140 |  Loss: (0.4346) |  Loss2: (0.0000) | Acc: (84.00%) (15266/18048)
Epoch: 46 | Batch_idx: 150 |  Loss: (0.4351) |  Loss2: (0.0000) | Acc: (84.00%) (16344/19328)
Epoch: 46 | Batch_idx: 160 |  Loss: (0.4350) |  Loss2: (0.0000) | Acc: (84.00%) (17423/20608)
Epoch: 46 | Batch_idx: 170 |  Loss: (0.4358) |  Loss2: (0.0000) | Acc: (84.00%) (18484/21888)
Epoch: 46 | Batch_idx: 180 |  Loss: (0.4356) |  Loss2: (0.0000) | Acc: (84.00%) (19566/23168)
Epoch: 46 | Batch_idx: 190 |  Loss: (0.4345) |  Loss2: (0.0000) | Acc: (84.00%) (20657/24448)
Epoch: 46 | Batch_idx: 200 |  Loss: (0.4337) |  Loss2: (0.0000) | Acc: (84.00%) (21765/25728)
Epoch: 46 | Batch_idx: 210 |  Loss: (0.4316) |  Loss2: (0.0000) | Acc: (84.00%) (22878/27008)
Epoch: 46 | Batch_idx: 220 |  Loss: (0.4317) |  Loss2: (0.0000) | Acc: (84.00%) (23963/28288)
Epoch: 46 | Batch_idx: 230 |  Loss: (0.4318) |  Loss2: (0.0000) | Acc: (84.00%) (25049/29568)
Epoch: 46 | Batch_idx: 240 |  Loss: (0.4307) |  Loss2: (0.0000) | Acc: (84.00%) (26151/30848)
Epoch: 46 | Batch_idx: 250 |  Loss: (0.4294) |  Loss2: (0.0000) | Acc: (84.00%) (27255/32128)
Epoch: 46 | Batch_idx: 260 |  Loss: (0.4294) |  Loss2: (0.0000) | Acc: (84.00%) (28350/33408)
Epoch: 46 | Batch_idx: 270 |  Loss: (0.4280) |  Loss2: (0.0000) | Acc: (84.00%) (29468/34688)
Epoch: 46 | Batch_idx: 280 |  Loss: (0.4275) |  Loss2: (0.0000) | Acc: (84.00%) (30568/35968)
Epoch: 46 | Batch_idx: 290 |  Loss: (0.4274) |  Loss2: (0.0000) | Acc: (84.00%) (31648/37248)
Epoch: 46 | Batch_idx: 300 |  Loss: (0.4275) |  Loss2: (0.0000) | Acc: (84.00%) (32742/38528)
Epoch: 46 | Batch_idx: 310 |  Loss: (0.4285) |  Loss2: (0.0000) | Acc: (84.00%) (33826/39808)
Epoch: 46 | Batch_idx: 320 |  Loss: (0.4276) |  Loss2: (0.0000) | Acc: (84.00%) (34924/41088)
Epoch: 46 | Batch_idx: 330 |  Loss: (0.4282) |  Loss2: (0.0000) | Acc: (85.00%) (36016/42368)
Epoch: 46 | Batch_idx: 340 |  Loss: (0.4275) |  Loss2: (0.0000) | Acc: (85.00%) (37115/43648)
Epoch: 46 | Batch_idx: 350 |  Loss: (0.4280) |  Loss2: (0.0000) | Acc: (85.00%) (38194/44928)
Epoch: 46 | Batch_idx: 360 |  Loss: (0.4286) |  Loss2: (0.0000) | Acc: (84.00%) (39273/46208)
Epoch: 46 | Batch_idx: 370 |  Loss: (0.4281) |  Loss2: (0.0000) | Acc: (85.00%) (40381/47488)
Epoch: 46 | Batch_idx: 380 |  Loss: (0.4278) |  Loss2: (0.0000) | Acc: (85.00%) (41488/48768)
Epoch: 46 | Batch_idx: 390 |  Loss: (0.4274) |  Loss2: (0.0000) | Acc: (85.00%) (42546/50000)
# TEST : Loss: (0.5133) | Acc: (82.00%) (8287/10000)
percent tensor([0.5257, 0.5280, 0.5336, 0.5364, 0.5343, 0.5372, 0.5297, 0.5333, 0.5248,
        0.5261, 0.5239, 0.5285, 0.5246, 0.5264, 0.5334, 0.5289],
       device='cuda:0') torch.Size([16])
percent tensor([0.5487, 0.5474, 0.5455, 0.5445, 0.5488, 0.5625, 0.5513, 0.5424, 0.5444,
        0.5458, 0.5491, 0.5504, 0.5430, 0.5462, 0.5572, 0.5507],
       device='cuda:0') torch.Size([16])
percent tensor([0.5533, 0.5685, 0.5396, 0.5334, 0.5454, 0.5230, 0.5639, 0.5497, 0.5525,
        0.5651, 0.5570, 0.5563, 0.5618, 0.5734, 0.5546, 0.5562],
       device='cuda:0') torch.Size([16])
percent tensor([0.5695, 0.5597, 0.5520, 0.5528, 0.5545, 0.5757, 0.5642, 0.5488, 0.5573,
        0.5651, 0.5667, 0.5528, 0.5617, 0.5612, 0.5744, 0.5682],
       device='cuda:0') torch.Size([16])
percent tensor([0.4597, 0.4716, 0.5083, 0.5125, 0.5302, 0.4981, 0.4979, 0.5185, 0.4738,
        0.4645, 0.4539, 0.4585, 0.4168, 0.5004, 0.4932, 0.4800],
       device='cuda:0') torch.Size([16])
percent tensor([0.4637, 0.4730, 0.5107, 0.5211, 0.5244, 0.5253, 0.4913, 0.4730, 0.5184,
        0.4652, 0.5128, 0.5151, 0.4552, 0.5249, 0.4678, 0.4723],
       device='cuda:0') torch.Size([16])
percent tensor([0.5495, 0.5421, 0.6193, 0.6178, 0.6411, 0.5536, 0.5839, 0.6091, 0.5819,
        0.5611, 0.5566, 0.5999, 0.5343, 0.5995, 0.5616, 0.5453],
       device='cuda:0') torch.Size([16])
percent tensor([0.9970, 0.9932, 0.9978, 0.9970, 0.9990, 0.9957, 0.9975, 0.9995, 0.9959,
        0.9975, 0.9951, 0.9973, 0.9957, 0.9956, 0.9972, 0.9973],
       device='cuda:0') torch.Size([16])
Epoch: 47 | Batch_idx: 0 |  Loss: (0.2984) |  Loss2: (0.0000) | Acc: (90.00%) (116/128)
Epoch: 47 | Batch_idx: 10 |  Loss: (0.3816) |  Loss2: (0.0000) | Acc: (87.00%) (1227/1408)
Epoch: 47 | Batch_idx: 20 |  Loss: (0.4080) |  Loss2: (0.0000) | Acc: (86.00%) (2318/2688)
Epoch: 47 | Batch_idx: 30 |  Loss: (0.4113) |  Loss2: (0.0000) | Acc: (85.00%) (3393/3968)
Epoch: 47 | Batch_idx: 40 |  Loss: (0.4203) |  Loss2: (0.0000) | Acc: (85.00%) (4482/5248)
Epoch: 47 | Batch_idx: 50 |  Loss: (0.4177) |  Loss2: (0.0000) | Acc: (85.00%) (5575/6528)
Epoch: 47 | Batch_idx: 60 |  Loss: (0.4191) |  Loss2: (0.0000) | Acc: (85.00%) (6666/7808)
Epoch: 47 | Batch_idx: 70 |  Loss: (0.4134) |  Loss2: (0.0000) | Acc: (85.00%) (7781/9088)
Epoch: 47 | Batch_idx: 80 |  Loss: (0.4113) |  Loss2: (0.0000) | Acc: (85.00%) (8890/10368)
Epoch: 47 | Batch_idx: 90 |  Loss: (0.4094) |  Loss2: (0.0000) | Acc: (85.00%) (9993/11648)
Epoch: 47 | Batch_idx: 100 |  Loss: (0.4101) |  Loss2: (0.0000) | Acc: (85.00%) (11080/12928)
Epoch: 47 | Batch_idx: 110 |  Loss: (0.4079) |  Loss2: (0.0000) | Acc: (85.00%) (12182/14208)
Epoch: 47 | Batch_idx: 120 |  Loss: (0.4082) |  Loss2: (0.0000) | Acc: (85.00%) (13290/15488)
Epoch: 47 | Batch_idx: 130 |  Loss: (0.4079) |  Loss2: (0.0000) | Acc: (85.00%) (14395/16768)
Epoch: 47 | Batch_idx: 140 |  Loss: (0.4087) |  Loss2: (0.0000) | Acc: (85.00%) (15471/18048)
Epoch: 47 | Batch_idx: 150 |  Loss: (0.4082) |  Loss2: (0.0000) | Acc: (85.00%) (16579/19328)
Epoch: 47 | Batch_idx: 160 |  Loss: (0.4096) |  Loss2: (0.0000) | Acc: (85.00%) (17689/20608)
Epoch: 47 | Batch_idx: 170 |  Loss: (0.4108) |  Loss2: (0.0000) | Acc: (85.00%) (18782/21888)
Epoch: 47 | Batch_idx: 180 |  Loss: (0.4116) |  Loss2: (0.0000) | Acc: (85.00%) (19880/23168)
Epoch: 47 | Batch_idx: 190 |  Loss: (0.4109) |  Loss2: (0.0000) | Acc: (85.00%) (20974/24448)
Epoch: 47 | Batch_idx: 200 |  Loss: (0.4124) |  Loss2: (0.0000) | Acc: (85.00%) (22059/25728)
Epoch: 47 | Batch_idx: 210 |  Loss: (0.4114) |  Loss2: (0.0000) | Acc: (85.00%) (23175/27008)
Epoch: 47 | Batch_idx: 220 |  Loss: (0.4133) |  Loss2: (0.0000) | Acc: (85.00%) (24251/28288)
Epoch: 47 | Batch_idx: 230 |  Loss: (0.4114) |  Loss2: (0.0000) | Acc: (85.00%) (25370/29568)
Epoch: 47 | Batch_idx: 240 |  Loss: (0.4131) |  Loss2: (0.0000) | Acc: (85.00%) (26458/30848)
Epoch: 47 | Batch_idx: 250 |  Loss: (0.4131) |  Loss2: (0.0000) | Acc: (85.00%) (27547/32128)
Epoch: 47 | Batch_idx: 260 |  Loss: (0.4130) |  Loss2: (0.0000) | Acc: (85.00%) (28647/33408)
Epoch: 47 | Batch_idx: 270 |  Loss: (0.4129) |  Loss2: (0.0000) | Acc: (85.00%) (29765/34688)
Epoch: 47 | Batch_idx: 280 |  Loss: (0.4125) |  Loss2: (0.0000) | Acc: (85.00%) (30877/35968)
Epoch: 47 | Batch_idx: 290 |  Loss: (0.4112) |  Loss2: (0.0000) | Acc: (85.00%) (31981/37248)
Epoch: 47 | Batch_idx: 300 |  Loss: (0.4105) |  Loss2: (0.0000) | Acc: (85.00%) (33083/38528)
Epoch: 47 | Batch_idx: 310 |  Loss: (0.4108) |  Loss2: (0.0000) | Acc: (85.00%) (34192/39808)
Epoch: 47 | Batch_idx: 320 |  Loss: (0.4114) |  Loss2: (0.0000) | Acc: (85.00%) (35280/41088)
Epoch: 47 | Batch_idx: 330 |  Loss: (0.4131) |  Loss2: (0.0000) | Acc: (85.00%) (36354/42368)
Epoch: 47 | Batch_idx: 340 |  Loss: (0.4133) |  Loss2: (0.0000) | Acc: (85.00%) (37451/43648)
Epoch: 47 | Batch_idx: 350 |  Loss: (0.4144) |  Loss2: (0.0000) | Acc: (85.00%) (38526/44928)
Epoch: 47 | Batch_idx: 360 |  Loss: (0.4145) |  Loss2: (0.0000) | Acc: (85.00%) (39610/46208)
Epoch: 47 | Batch_idx: 370 |  Loss: (0.4151) |  Loss2: (0.0000) | Acc: (85.00%) (40697/47488)
Epoch: 47 | Batch_idx: 380 |  Loss: (0.4152) |  Loss2: (0.0000) | Acc: (85.00%) (41784/48768)
Epoch: 47 | Batch_idx: 390 |  Loss: (0.4163) |  Loss2: (0.0000) | Acc: (85.00%) (42816/50000)
# TEST : Loss: (0.6291) | Acc: (79.00%) (7905/10000)
percent tensor([0.5256, 0.5271, 0.5341, 0.5373, 0.5349, 0.5365, 0.5291, 0.5331, 0.5243,
        0.5259, 0.5233, 0.5295, 0.5242, 0.5237, 0.5327, 0.5278],
       device='cuda:0') torch.Size([16])
percent tensor([0.5525, 0.5502, 0.5503, 0.5450, 0.5524, 0.5638, 0.5552, 0.5450, 0.5487,
        0.5482, 0.5531, 0.5550, 0.5461, 0.5496, 0.5591, 0.5530],
       device='cuda:0') torch.Size([16])
percent tensor([0.5562, 0.5726, 0.5419, 0.5344, 0.5473, 0.5273, 0.5660, 0.5493, 0.5535,
        0.5687, 0.5608, 0.5590, 0.5648, 0.5752, 0.5583, 0.5604],
       device='cuda:0') torch.Size([16])
percent tensor([0.5756, 0.5657, 0.5551, 0.5550, 0.5589, 0.5799, 0.5689, 0.5521, 0.5620,
        0.5708, 0.5733, 0.5580, 0.5676, 0.5647, 0.5805, 0.5725],
       device='cuda:0') torch.Size([16])
percent tensor([0.4768, 0.4666, 0.5200, 0.5135, 0.5371, 0.5081, 0.5008, 0.5213, 0.4883,
        0.4550, 0.4627, 0.4640, 0.4168, 0.4977, 0.4956, 0.4833],
       device='cuda:0') torch.Size([16])
percent tensor([0.4713, 0.4749, 0.4997, 0.5207, 0.5058, 0.5294, 0.4924, 0.4683, 0.5264,
        0.4655, 0.5170, 0.5088, 0.4699, 0.5360, 0.4643, 0.4750],
       device='cuda:0') torch.Size([16])
percent tensor([0.5516, 0.5379, 0.6190, 0.6095, 0.6386, 0.5568, 0.5860, 0.6075, 0.5882,
        0.5617, 0.5628, 0.6143, 0.5329, 0.5973, 0.5635, 0.5394],
       device='cuda:0') torch.Size([16])
percent tensor([0.9967, 0.9959, 0.9982, 0.9971, 0.9992, 0.9967, 0.9978, 0.9994, 0.9965,
        0.9986, 0.9977, 0.9986, 0.9960, 0.9973, 0.9989, 0.9971],
       device='cuda:0') torch.Size([16])
Epoch: 48 | Batch_idx: 0 |  Loss: (0.3197) |  Loss2: (0.0000) | Acc: (90.00%) (116/128)
Epoch: 48 | Batch_idx: 10 |  Loss: (0.4151) |  Loss2: (0.0000) | Acc: (86.00%) (1215/1408)
Epoch: 48 | Batch_idx: 20 |  Loss: (0.4071) |  Loss2: (0.0000) | Acc: (86.00%) (2319/2688)
Epoch: 48 | Batch_idx: 30 |  Loss: (0.3947) |  Loss2: (0.0000) | Acc: (86.00%) (3430/3968)
Epoch: 48 | Batch_idx: 40 |  Loss: (0.4020) |  Loss2: (0.0000) | Acc: (86.00%) (4517/5248)
Epoch: 48 | Batch_idx: 50 |  Loss: (0.3990) |  Loss2: (0.0000) | Acc: (86.00%) (5628/6528)
Epoch: 48 | Batch_idx: 60 |  Loss: (0.4009) |  Loss2: (0.0000) | Acc: (86.00%) (6732/7808)
Epoch: 48 | Batch_idx: 70 |  Loss: (0.3964) |  Loss2: (0.0000) | Acc: (86.00%) (7857/9088)
Epoch: 48 | Batch_idx: 80 |  Loss: (0.3919) |  Loss2: (0.0000) | Acc: (86.00%) (8977/10368)
Epoch: 48 | Batch_idx: 90 |  Loss: (0.4000) |  Loss2: (0.0000) | Acc: (86.00%) (10058/11648)
Epoch: 48 | Batch_idx: 100 |  Loss: (0.4014) |  Loss2: (0.0000) | Acc: (86.00%) (11153/12928)
Epoch: 48 | Batch_idx: 110 |  Loss: (0.4020) |  Loss2: (0.0000) | Acc: (86.00%) (12241/14208)
Epoch: 48 | Batch_idx: 120 |  Loss: (0.3988) |  Loss2: (0.0000) | Acc: (86.00%) (13358/15488)
Epoch: 48 | Batch_idx: 130 |  Loss: (0.3995) |  Loss2: (0.0000) | Acc: (86.00%) (14459/16768)
Epoch: 48 | Batch_idx: 140 |  Loss: (0.3984) |  Loss2: (0.0000) | Acc: (86.00%) (15576/18048)
Epoch: 48 | Batch_idx: 150 |  Loss: (0.3977) |  Loss2: (0.0000) | Acc: (86.00%) (16670/19328)
Epoch: 48 | Batch_idx: 160 |  Loss: (0.3987) |  Loss2: (0.0000) | Acc: (86.00%) (17778/20608)
Epoch: 48 | Batch_idx: 170 |  Loss: (0.3990) |  Loss2: (0.0000) | Acc: (86.00%) (18883/21888)
Epoch: 48 | Batch_idx: 180 |  Loss: (0.3995) |  Loss2: (0.0000) | Acc: (86.00%) (19986/23168)
Epoch: 48 | Batch_idx: 190 |  Loss: (0.3993) |  Loss2: (0.0000) | Acc: (86.00%) (21104/24448)
Epoch: 48 | Batch_idx: 200 |  Loss: (0.3996) |  Loss2: (0.0000) | Acc: (86.00%) (22204/25728)
Epoch: 48 | Batch_idx: 210 |  Loss: (0.4011) |  Loss2: (0.0000) | Acc: (86.00%) (23297/27008)
Epoch: 48 | Batch_idx: 220 |  Loss: (0.4029) |  Loss2: (0.0000) | Acc: (86.00%) (24382/28288)
Epoch: 48 | Batch_idx: 230 |  Loss: (0.4031) |  Loss2: (0.0000) | Acc: (86.00%) (25487/29568)
Epoch: 48 | Batch_idx: 240 |  Loss: (0.4029) |  Loss2: (0.0000) | Acc: (86.00%) (26589/30848)
Epoch: 48 | Batch_idx: 250 |  Loss: (0.4030) |  Loss2: (0.0000) | Acc: (86.00%) (27689/32128)
Epoch: 48 | Batch_idx: 260 |  Loss: (0.4026) |  Loss2: (0.0000) | Acc: (86.00%) (28804/33408)
Epoch: 48 | Batch_idx: 270 |  Loss: (0.4036) |  Loss2: (0.0000) | Acc: (86.00%) (29884/34688)
Epoch: 48 | Batch_idx: 280 |  Loss: (0.4044) |  Loss2: (0.0000) | Acc: (86.00%) (30955/35968)
Epoch: 48 | Batch_idx: 290 |  Loss: (0.4028) |  Loss2: (0.0000) | Acc: (86.00%) (32086/37248)
Epoch: 48 | Batch_idx: 300 |  Loss: (0.4025) |  Loss2: (0.0000) | Acc: (86.00%) (33201/38528)
Epoch: 48 | Batch_idx: 310 |  Loss: (0.4026) |  Loss2: (0.0000) | Acc: (86.00%) (34298/39808)
Epoch: 48 | Batch_idx: 320 |  Loss: (0.4039) |  Loss2: (0.0000) | Acc: (86.00%) (35377/41088)
Epoch: 48 | Batch_idx: 330 |  Loss: (0.4044) |  Loss2: (0.0000) | Acc: (86.00%) (36476/42368)
Epoch: 48 | Batch_idx: 340 |  Loss: (0.4037) |  Loss2: (0.0000) | Acc: (86.00%) (37598/43648)
Epoch: 48 | Batch_idx: 350 |  Loss: (0.4033) |  Loss2: (0.0000) | Acc: (86.00%) (38694/44928)
Epoch: 48 | Batch_idx: 360 |  Loss: (0.4041) |  Loss2: (0.0000) | Acc: (86.00%) (39775/46208)
Epoch: 48 | Batch_idx: 370 |  Loss: (0.4041) |  Loss2: (0.0000) | Acc: (86.00%) (40873/47488)
Epoch: 48 | Batch_idx: 380 |  Loss: (0.4038) |  Loss2: (0.0000) | Acc: (86.00%) (41990/48768)
Epoch: 48 | Batch_idx: 390 |  Loss: (0.4036) |  Loss2: (0.0000) | Acc: (86.00%) (43048/50000)
# TEST : Loss: (0.5672) | Acc: (81.00%) (8102/10000)
percent tensor([0.5263, 0.5273, 0.5356, 0.5371, 0.5362, 0.5372, 0.5298, 0.5332, 0.5259,
        0.5266, 0.5244, 0.5305, 0.5255, 0.5241, 0.5330, 0.5284],
       device='cuda:0') torch.Size([16])
percent tensor([0.5500, 0.5491, 0.5468, 0.5455, 0.5504, 0.5610, 0.5536, 0.5456, 0.5462,
        0.5475, 0.5511, 0.5526, 0.5445, 0.5474, 0.5578, 0.5527],
       device='cuda:0') torch.Size([16])
percent tensor([0.5550, 0.5740, 0.5406, 0.5325, 0.5442, 0.5260, 0.5637, 0.5481, 0.5518,
        0.5662, 0.5608, 0.5573, 0.5639, 0.5736, 0.5570, 0.5576],
       device='cuda:0') torch.Size([16])
percent tensor([0.5715, 0.5645, 0.5553, 0.5591, 0.5575, 0.5791, 0.5678, 0.5542, 0.5617,
        0.5678, 0.5700, 0.5572, 0.5657, 0.5643, 0.5783, 0.5717],
       device='cuda:0') torch.Size([16])
percent tensor([0.4560, 0.4492, 0.5088, 0.5195, 0.5334, 0.5046, 0.4861, 0.5184, 0.4719,
        0.4439, 0.4440, 0.4410, 0.3971, 0.4810, 0.4847, 0.4803],
       device='cuda:0') torch.Size([16])
percent tensor([0.4769, 0.5008, 0.5070, 0.5162, 0.5143, 0.5294, 0.5071, 0.4791, 0.5334,
        0.4961, 0.5306, 0.5213, 0.4889, 0.5488, 0.4785, 0.4913],
       device='cuda:0') torch.Size([16])
percent tensor([0.5442, 0.5279, 0.6147, 0.6139, 0.6285, 0.5633, 0.5886, 0.6062, 0.5882,
        0.5568, 0.5586, 0.6130, 0.5200, 0.5962, 0.5600, 0.5474],
       device='cuda:0') torch.Size([16])
percent tensor([0.9966, 0.9915, 0.9972, 0.9968, 0.9982, 0.9942, 0.9975, 0.9988, 0.9953,
        0.9964, 0.9960, 0.9978, 0.9943, 0.9940, 0.9959, 0.9971],
       device='cuda:0') torch.Size([16])
False Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=128, out_features=16, bias=False)
True Linear(in_features=16, out_features=2, bias=False)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=128, out_features=16, bias=False)
True Linear(in_features=16, out_features=2, bias=False)
False Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=256, out_features=32, bias=False)
True Linear(in_features=32, out_features=2, bias=False)
False Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=256, out_features=32, bias=False)
True Linear(in_features=32, out_features=2, bias=False)
False Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=512, out_features=64, bias=False)
True Linear(in_features=64, out_features=2, bias=False)
False Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=512, out_features=64, bias=False)
True Linear(in_features=64, out_features=2, bias=False)
False Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1024, out_features=128, bias=False)
True Linear(in_features=128, out_features=2, bias=False)
False Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1024, out_features=128, bias=False)
True Linear(in_features=128, out_features=2, bias=False)
False Linear(in_features=512, out_features=10, bias=True)
Epoch: 49 | Batch_idx: 0 |  Loss: (0.2455) |  Loss2: (0.0000) | Acc: (90.00%) (116/128)
Epoch: 49 | Batch_idx: 10 |  Loss: (0.4091) |  Loss2: (0.0000) | Acc: (85.00%) (1209/1408)
Epoch: 49 | Batch_idx: 20 |  Loss: (0.4618) |  Loss2: (0.0000) | Acc: (84.00%) (2266/2688)
Epoch: 49 | Batch_idx: 30 |  Loss: (0.4785) |  Loss2: (0.0000) | Acc: (83.00%) (3314/3968)
Epoch: 49 | Batch_idx: 40 |  Loss: (0.4819) |  Loss2: (0.0000) | Acc: (83.00%) (4372/5248)
Epoch: 49 | Batch_idx: 50 |  Loss: (0.4848) |  Loss2: (0.0000) | Acc: (83.00%) (5429/6528)
Epoch: 49 | Batch_idx: 60 |  Loss: (0.4859) |  Loss2: (0.0000) | Acc: (83.00%) (6502/7808)
Epoch: 49 | Batch_idx: 70 |  Loss: (0.4825) |  Loss2: (0.0000) | Acc: (83.00%) (7577/9088)
Epoch: 49 | Batch_idx: 80 |  Loss: (0.4817) |  Loss2: (0.0000) | Acc: (83.00%) (8638/10368)
Epoch: 49 | Batch_idx: 90 |  Loss: (0.4790) |  Loss2: (0.0000) | Acc: (83.00%) (9719/11648)
Epoch: 49 | Batch_idx: 100 |  Loss: (0.4812) |  Loss2: (0.0000) | Acc: (83.00%) (10765/12928)
Epoch: 49 | Batch_idx: 110 |  Loss: (0.4779) |  Loss2: (0.0000) | Acc: (83.00%) (11841/14208)
Epoch: 49 | Batch_idx: 120 |  Loss: (0.4760) |  Loss2: (0.0000) | Acc: (83.00%) (12927/15488)
Epoch: 49 | Batch_idx: 130 |  Loss: (0.4758) |  Loss2: (0.0000) | Acc: (83.00%) (13996/16768)
Epoch: 49 | Batch_idx: 140 |  Loss: (0.4749) |  Loss2: (0.0000) | Acc: (83.00%) (15064/18048)
Epoch: 49 | Batch_idx: 150 |  Loss: (0.4758) |  Loss2: (0.0000) | Acc: (83.00%) (16125/19328)
Epoch: 49 | Batch_idx: 160 |  Loss: (0.4727) |  Loss2: (0.0000) | Acc: (83.00%) (17212/20608)
Epoch: 49 | Batch_idx: 170 |  Loss: (0.4721) |  Loss2: (0.0000) | Acc: (83.00%) (18290/21888)
Epoch: 49 | Batch_idx: 180 |  Loss: (0.4711) |  Loss2: (0.0000) | Acc: (83.00%) (19362/23168)
Epoch: 49 | Batch_idx: 190 |  Loss: (0.4680) |  Loss2: (0.0000) | Acc: (83.00%) (20460/24448)
Epoch: 49 | Batch_idx: 200 |  Loss: (0.4684) |  Loss2: (0.0000) | Acc: (83.00%) (21526/25728)
Epoch: 49 | Batch_idx: 210 |  Loss: (0.4676) |  Loss2: (0.0000) | Acc: (83.00%) (22599/27008)
Epoch: 49 | Batch_idx: 220 |  Loss: (0.4640) |  Loss2: (0.0000) | Acc: (83.00%) (23710/28288)
Epoch: 49 | Batch_idx: 230 |  Loss: (0.4645) |  Loss2: (0.0000) | Acc: (83.00%) (24779/29568)
Epoch: 49 | Batch_idx: 240 |  Loss: (0.4636) |  Loss2: (0.0000) | Acc: (83.00%) (25866/30848)
Epoch: 49 | Batch_idx: 250 |  Loss: (0.4623) |  Loss2: (0.0000) | Acc: (83.00%) (26958/32128)
Epoch: 49 | Batch_idx: 260 |  Loss: (0.4599) |  Loss2: (0.0000) | Acc: (83.00%) (28057/33408)
Epoch: 49 | Batch_idx: 270 |  Loss: (0.4596) |  Loss2: (0.0000) | Acc: (84.00%) (29144/34688)
Epoch: 49 | Batch_idx: 280 |  Loss: (0.4582) |  Loss2: (0.0000) | Acc: (84.00%) (30258/35968)
Epoch: 49 | Batch_idx: 290 |  Loss: (0.4578) |  Loss2: (0.0000) | Acc: (84.00%) (31341/37248)
Epoch: 49 | Batch_idx: 300 |  Loss: (0.4570) |  Loss2: (0.0000) | Acc: (84.00%) (32419/38528)
Epoch: 49 | Batch_idx: 310 |  Loss: (0.4558) |  Loss2: (0.0000) | Acc: (84.00%) (33511/39808)
Epoch: 49 | Batch_idx: 320 |  Loss: (0.4553) |  Loss2: (0.0000) | Acc: (84.00%) (34602/41088)
Epoch: 49 | Batch_idx: 330 |  Loss: (0.4545) |  Loss2: (0.0000) | Acc: (84.00%) (35685/42368)
Epoch: 49 | Batch_idx: 340 |  Loss: (0.4531) |  Loss2: (0.0000) | Acc: (84.00%) (36788/43648)
Epoch: 49 | Batch_idx: 350 |  Loss: (0.4526) |  Loss2: (0.0000) | Acc: (84.00%) (37872/44928)
Epoch: 49 | Batch_idx: 360 |  Loss: (0.4512) |  Loss2: (0.0000) | Acc: (84.00%) (38979/46208)
Epoch: 49 | Batch_idx: 370 |  Loss: (0.4504) |  Loss2: (0.0000) | Acc: (84.00%) (40070/47488)
Epoch: 49 | Batch_idx: 380 |  Loss: (0.4494) |  Loss2: (0.0000) | Acc: (84.00%) (41169/48768)
Epoch: 49 | Batch_idx: 390 |  Loss: (0.4478) |  Loss2: (0.0000) | Acc: (84.00%) (42229/50000)
# TEST : Loss: (0.5024) | Acc: (83.00%) (8327/10000)
percent tensor([0.5298, 0.5325, 0.5399, 0.5403, 0.5411, 0.5408, 0.5348, 0.5377, 0.5293,
        0.5312, 0.5283, 0.5352, 0.5294, 0.5278, 0.5375, 0.5322],
       device='cuda:0') torch.Size([16])
percent tensor([0.5713, 0.5816, 0.5661, 0.5618, 0.5729, 0.5793, 0.5832, 0.5686, 0.5684,
        0.5754, 0.5780, 0.5776, 0.5697, 0.5721, 0.5843, 0.5749],
       device='cuda:0') torch.Size([16])
percent tensor([0.5412, 0.5627, 0.5263, 0.5188, 0.5303, 0.5157, 0.5513, 0.5341, 0.5366,
        0.5547, 0.5490, 0.5444, 0.5514, 0.5570, 0.5447, 0.5451],
       device='cuda:0') torch.Size([16])
percent tensor([0.5841, 0.5860, 0.5686, 0.5711, 0.5711, 0.5869, 0.5872, 0.5703, 0.5778,
        0.5866, 0.5889, 0.5778, 0.5832, 0.5844, 0.5938, 0.5838],
       device='cuda:0') torch.Size([16])
percent tensor([0.4864, 0.5066, 0.5097, 0.5115, 0.5253, 0.4916, 0.5161, 0.5201, 0.5039,
        0.5006, 0.5030, 0.4867, 0.4640, 0.5161, 0.5156, 0.4998],
       device='cuda:0') torch.Size([16])
percent tensor([0.4598, 0.4906, 0.5158, 0.5307, 0.5383, 0.5358, 0.5125, 0.4988, 0.5338,
        0.4785, 0.5223, 0.5289, 0.4705, 0.5418, 0.4785, 0.4812],
       device='cuda:0') torch.Size([16])
percent tensor([0.5463, 0.5320, 0.6132, 0.6127, 0.6304, 0.5666, 0.5851, 0.6061, 0.5802,
        0.5617, 0.5571, 0.5993, 0.5318, 0.5868, 0.5523, 0.5481],
       device='cuda:0') torch.Size([16])
percent tensor([0.9976, 0.9944, 0.9978, 0.9972, 0.9988, 0.9963, 0.9980, 0.9992, 0.9963,
        0.9979, 0.9972, 0.9971, 0.9963, 0.9958, 0.9970, 0.9980],
       device='cuda:0') torch.Size([16])
Epoch: 50 | Batch_idx: 0 |  Loss: (0.4192) |  Loss2: (0.0000) | Acc: (84.00%) (108/128)
Epoch: 50 | Batch_idx: 10 |  Loss: (0.3885) |  Loss2: (0.0000) | Acc: (87.00%) (1229/1408)
Epoch: 50 | Batch_idx: 20 |  Loss: (0.4019) |  Loss2: (0.0000) | Acc: (86.00%) (2335/2688)
Epoch: 50 | Batch_idx: 30 |  Loss: (0.4027) |  Loss2: (0.0000) | Acc: (86.00%) (3416/3968)
Epoch: 50 | Batch_idx: 40 |  Loss: (0.4062) |  Loss2: (0.0000) | Acc: (86.00%) (4524/5248)
Epoch: 50 | Batch_idx: 50 |  Loss: (0.4008) |  Loss2: (0.0000) | Acc: (86.00%) (5648/6528)
Epoch: 50 | Batch_idx: 60 |  Loss: (0.4023) |  Loss2: (0.0000) | Acc: (86.00%) (6746/7808)
Epoch: 50 | Batch_idx: 70 |  Loss: (0.4053) |  Loss2: (0.0000) | Acc: (86.00%) (7849/9088)
Epoch: 50 | Batch_idx: 80 |  Loss: (0.4089) |  Loss2: (0.0000) | Acc: (86.00%) (8941/10368)
Epoch: 50 | Batch_idx: 90 |  Loss: (0.4048) |  Loss2: (0.0000) | Acc: (86.00%) (10061/11648)
Epoch: 50 | Batch_idx: 100 |  Loss: (0.4066) |  Loss2: (0.0000) | Acc: (86.00%) (11138/12928)
Epoch: 50 | Batch_idx: 110 |  Loss: (0.4069) |  Loss2: (0.0000) | Acc: (86.00%) (12226/14208)
Epoch: 50 | Batch_idx: 120 |  Loss: (0.4080) |  Loss2: (0.0000) | Acc: (86.00%) (13329/15488)
Epoch: 50 | Batch_idx: 130 |  Loss: (0.4077) |  Loss2: (0.0000) | Acc: (86.00%) (14438/16768)
Epoch: 50 | Batch_idx: 140 |  Loss: (0.4075) |  Loss2: (0.0000) | Acc: (86.00%) (15540/18048)
Epoch: 50 | Batch_idx: 150 |  Loss: (0.4049) |  Loss2: (0.0000) | Acc: (86.00%) (16654/19328)
Epoch: 50 | Batch_idx: 160 |  Loss: (0.4036) |  Loss2: (0.0000) | Acc: (86.00%) (17771/20608)
Epoch: 50 | Batch_idx: 170 |  Loss: (0.4036) |  Loss2: (0.0000) | Acc: (86.00%) (18883/21888)
Epoch: 50 | Batch_idx: 180 |  Loss: (0.4056) |  Loss2: (0.0000) | Acc: (86.00%) (19961/23168)
Epoch: 50 | Batch_idx: 190 |  Loss: (0.4062) |  Loss2: (0.0000) | Acc: (86.00%) (21049/24448)
Epoch: 50 | Batch_idx: 200 |  Loss: (0.4076) |  Loss2: (0.0000) | Acc: (86.00%) (22159/25728)
Epoch: 50 | Batch_idx: 210 |  Loss: (0.4093) |  Loss2: (0.0000) | Acc: (86.00%) (23239/27008)
Epoch: 50 | Batch_idx: 220 |  Loss: (0.4093) |  Loss2: (0.0000) | Acc: (86.00%) (24334/28288)
Epoch: 50 | Batch_idx: 230 |  Loss: (0.4082) |  Loss2: (0.0000) | Acc: (86.00%) (25453/29568)
Epoch: 50 | Batch_idx: 240 |  Loss: (0.4080) |  Loss2: (0.0000) | Acc: (86.00%) (26565/30848)
Epoch: 50 | Batch_idx: 250 |  Loss: (0.4077) |  Loss2: (0.0000) | Acc: (86.00%) (27669/32128)
Epoch: 50 | Batch_idx: 260 |  Loss: (0.4073) |  Loss2: (0.0000) | Acc: (86.00%) (28773/33408)
Epoch: 50 | Batch_idx: 270 |  Loss: (0.4066) |  Loss2: (0.0000) | Acc: (86.00%) (29887/34688)
Epoch: 50 | Batch_idx: 280 |  Loss: (0.4071) |  Loss2: (0.0000) | Acc: (86.00%) (30985/35968)
Epoch: 50 | Batch_idx: 290 |  Loss: (0.4079) |  Loss2: (0.0000) | Acc: (86.00%) (32081/37248)
Epoch: 50 | Batch_idx: 300 |  Loss: (0.4076) |  Loss2: (0.0000) | Acc: (86.00%) (33186/38528)
Epoch: 50 | Batch_idx: 310 |  Loss: (0.4083) |  Loss2: (0.0000) | Acc: (86.00%) (34278/39808)
Epoch: 50 | Batch_idx: 320 |  Loss: (0.4084) |  Loss2: (0.0000) | Acc: (86.00%) (35371/41088)
Epoch: 50 | Batch_idx: 330 |  Loss: (0.4075) |  Loss2: (0.0000) | Acc: (86.00%) (36490/42368)
Epoch: 50 | Batch_idx: 340 |  Loss: (0.4080) |  Loss2: (0.0000) | Acc: (86.00%) (37587/43648)
Epoch: 50 | Batch_idx: 350 |  Loss: (0.4076) |  Loss2: (0.0000) | Acc: (86.00%) (38689/44928)
Epoch: 50 | Batch_idx: 360 |  Loss: (0.4072) |  Loss2: (0.0000) | Acc: (86.00%) (39795/46208)
Epoch: 50 | Batch_idx: 370 |  Loss: (0.4073) |  Loss2: (0.0000) | Acc: (86.00%) (40889/47488)
Epoch: 50 | Batch_idx: 380 |  Loss: (0.4076) |  Loss2: (0.0000) | Acc: (86.00%) (41999/48768)
Epoch: 50 | Batch_idx: 390 |  Loss: (0.4068) |  Loss2: (0.0000) | Acc: (86.00%) (43080/50000)
=> saving checkpoint 'drive/app/torch/save_Schedule/checkpoint_050.pth.tar'
# TEST : Loss: (0.4842) | Acc: (84.00%) (8405/10000)
percent tensor([0.5286, 0.5315, 0.5393, 0.5397, 0.5404, 0.5401, 0.5338, 0.5368, 0.5281,
        0.5304, 0.5270, 0.5344, 0.5282, 0.5264, 0.5366, 0.5314],
       device='cuda:0') torch.Size([16])
percent tensor([0.5683, 0.5792, 0.5632, 0.5572, 0.5696, 0.5749, 0.5806, 0.5649, 0.5649,
        0.5729, 0.5751, 0.5751, 0.5675, 0.5681, 0.5809, 0.5715],
       device='cuda:0') torch.Size([16])
percent tensor([0.5471, 0.5715, 0.5291, 0.5212, 0.5328, 0.5182, 0.5585, 0.5373, 0.5411,
        0.5628, 0.5572, 0.5505, 0.5593, 0.5638, 0.5517, 0.5522],
       device='cuda:0') torch.Size([16])
percent tensor([0.5937, 0.5981, 0.5788, 0.5805, 0.5815, 0.5950, 0.5984, 0.5813, 0.5888,
        0.5984, 0.6000, 0.5898, 0.5939, 0.5965, 0.6040, 0.5936],
       device='cuda:0') torch.Size([16])
percent tensor([0.4735, 0.4933, 0.5046, 0.5070, 0.5193, 0.4822, 0.5013, 0.5155, 0.4989,
        0.4891, 0.4939, 0.4820, 0.4554, 0.5082, 0.5006, 0.4851],
       device='cuda:0') torch.Size([16])
percent tensor([0.4514, 0.4786, 0.5212, 0.5374, 0.5498, 0.5407, 0.5100, 0.5006, 0.5352,
        0.4683, 0.5175, 0.5286, 0.4592, 0.5369, 0.4730, 0.4751],
       device='cuda:0') torch.Size([16])
percent tensor([0.5565, 0.5377, 0.6247, 0.6205, 0.6388, 0.5824, 0.5891, 0.6090, 0.5883,
        0.5684, 0.5651, 0.6006, 0.5426, 0.5929, 0.5524, 0.5573],
       device='cuda:0') torch.Size([16])
percent tensor([0.9977, 0.9949, 0.9982, 0.9974, 0.9990, 0.9969, 0.9982, 0.9994, 0.9968,
        0.9980, 0.9976, 0.9974, 0.9965, 0.9964, 0.9970, 0.9982],
       device='cuda:0') torch.Size([16])
Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 3, 3, 3]) tensor(178.4817, device='cuda:0')
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(793.4560, device='cuda:0')
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(804.7452, device='cuda:0')
Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([128, 64, 3, 3]) tensor(1534.3881, device='cuda:0')
Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([128, 64, 1, 1]) tensor(508.0449, device='cuda:0')
Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([128, 128, 3, 3]) tensor(2202.8923, device='cuda:0')
Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([256, 128, 3, 3]) tensor(4300.5684, device='cuda:0')
Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([256, 128, 1, 1]) tensor(1414.4386, device='cuda:0')
Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([256, 256, 3, 3]) tensor(6093.2900, device='cuda:0')
Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([512, 256, 3, 3]) tensor(12054.0596, device='cuda:0')
Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([512, 256, 1, 1]) tensor(4016.4072, device='cuda:0')
Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([512, 512, 3, 3]) tensor(16980.6270, device='cuda:0')
Epoch: 51 | Batch_idx: 0 |  Loss: (0.4665) |  Loss2: (0.0000) | Acc: (84.00%) (108/128)
Epoch: 51 | Batch_idx: 10 |  Loss: (0.4136) |  Loss2: (0.0000) | Acc: (86.00%) (1213/1408)
Epoch: 51 | Batch_idx: 20 |  Loss: (0.4189) |  Loss2: (0.0000) | Acc: (85.00%) (2303/2688)
Epoch: 51 | Batch_idx: 30 |  Loss: (0.4093) |  Loss2: (0.0000) | Acc: (85.00%) (3393/3968)
Epoch: 51 | Batch_idx: 40 |  Loss: (0.4039) |  Loss2: (0.0000) | Acc: (85.00%) (4497/5248)
Epoch: 51 | Batch_idx: 50 |  Loss: (0.4073) |  Loss2: (0.0000) | Acc: (85.00%) (5591/6528)
Epoch: 51 | Batch_idx: 60 |  Loss: (0.4091) |  Loss2: (0.0000) | Acc: (85.00%) (6683/7808)
Epoch: 51 | Batch_idx: 70 |  Loss: (0.4099) |  Loss2: (0.0000) | Acc: (85.00%) (7792/9088)
Epoch: 51 | Batch_idx: 80 |  Loss: (0.4094) |  Loss2: (0.0000) | Acc: (85.00%) (8886/10368)
Epoch: 51 | Batch_idx: 90 |  Loss: (0.4082) |  Loss2: (0.0000) | Acc: (85.00%) (10001/11648)
Epoch: 51 | Batch_idx: 100 |  Loss: (0.4060) |  Loss2: (0.0000) | Acc: (85.00%) (11115/12928)
Epoch: 51 | Batch_idx: 110 |  Loss: (0.4059) |  Loss2: (0.0000) | Acc: (86.00%) (12231/14208)
Epoch: 51 | Batch_idx: 120 |  Loss: (0.4054) |  Loss2: (0.0000) | Acc: (86.00%) (13326/15488)
Epoch: 51 | Batch_idx: 130 |  Loss: (0.4046) |  Loss2: (0.0000) | Acc: (86.00%) (14431/16768)
Epoch: 51 | Batch_idx: 140 |  Loss: (0.4030) |  Loss2: (0.0000) | Acc: (86.00%) (15542/18048)
Epoch: 51 | Batch_idx: 150 |  Loss: (0.4017) |  Loss2: (0.0000) | Acc: (86.00%) (16649/19328)
Epoch: 51 | Batch_idx: 160 |  Loss: (0.4011) |  Loss2: (0.0000) | Acc: (86.00%) (17766/20608)
Epoch: 51 | Batch_idx: 170 |  Loss: (0.4001) |  Loss2: (0.0000) | Acc: (86.00%) (18888/21888)
Epoch: 51 | Batch_idx: 180 |  Loss: (0.3986) |  Loss2: (0.0000) | Acc: (86.00%) (20004/23168)
Epoch: 51 | Batch_idx: 190 |  Loss: (0.3980) |  Loss2: (0.0000) | Acc: (86.00%) (21112/24448)
Epoch: 51 | Batch_idx: 200 |  Loss: (0.3978) |  Loss2: (0.0000) | Acc: (86.00%) (22221/25728)
Epoch: 51 | Batch_idx: 210 |  Loss: (0.3967) |  Loss2: (0.0000) | Acc: (86.00%) (23336/27008)
Epoch: 51 | Batch_idx: 220 |  Loss: (0.3967) |  Loss2: (0.0000) | Acc: (86.00%) (24440/28288)
Epoch: 51 | Batch_idx: 230 |  Loss: (0.3950) |  Loss2: (0.0000) | Acc: (86.00%) (25568/29568)
Epoch: 51 | Batch_idx: 240 |  Loss: (0.3933) |  Loss2: (0.0000) | Acc: (86.00%) (26685/30848)
Epoch: 51 | Batch_idx: 250 |  Loss: (0.3940) |  Loss2: (0.0000) | Acc: (86.00%) (27777/32128)
Epoch: 51 | Batch_idx: 260 |  Loss: (0.3960) |  Loss2: (0.0000) | Acc: (86.00%) (28856/33408)
Epoch: 51 | Batch_idx: 270 |  Loss: (0.3961) |  Loss2: (0.0000) | Acc: (86.00%) (29959/34688)
Epoch: 51 | Batch_idx: 280 |  Loss: (0.3961) |  Loss2: (0.0000) | Acc: (86.00%) (31063/35968)
Epoch: 51 | Batch_idx: 290 |  Loss: (0.3947) |  Loss2: (0.0000) | Acc: (86.00%) (32178/37248)
Epoch: 51 | Batch_idx: 300 |  Loss: (0.3951) |  Loss2: (0.0000) | Acc: (86.00%) (33287/38528)
Epoch: 51 | Batch_idx: 310 |  Loss: (0.3946) |  Loss2: (0.0000) | Acc: (86.00%) (34403/39808)
Epoch: 51 | Batch_idx: 320 |  Loss: (0.3944) |  Loss2: (0.0000) | Acc: (86.00%) (35517/41088)
Epoch: 51 | Batch_idx: 330 |  Loss: (0.3949) |  Loss2: (0.0000) | Acc: (86.00%) (36614/42368)
Epoch: 51 | Batch_idx: 340 |  Loss: (0.3949) |  Loss2: (0.0000) | Acc: (86.00%) (37729/43648)
Epoch: 51 | Batch_idx: 350 |  Loss: (0.3947) |  Loss2: (0.0000) | Acc: (86.00%) (38825/44928)
Epoch: 51 | Batch_idx: 360 |  Loss: (0.3951) |  Loss2: (0.0000) | Acc: (86.00%) (39920/46208)
Epoch: 51 | Batch_idx: 370 |  Loss: (0.3944) |  Loss2: (0.0000) | Acc: (86.00%) (41045/47488)
Epoch: 51 | Batch_idx: 380 |  Loss: (0.3935) |  Loss2: (0.0000) | Acc: (86.00%) (42172/48768)
Epoch: 51 | Batch_idx: 390 |  Loss: (0.3930) |  Loss2: (0.0000) | Acc: (86.00%) (43252/50000)
# TEST : Loss: (0.4747) | Acc: (84.00%) (8416/10000)
percent tensor([0.5276, 0.5305, 0.5386, 0.5391, 0.5396, 0.5395, 0.5328, 0.5361, 0.5269,
        0.5295, 0.5259, 0.5334, 0.5271, 0.5254, 0.5358, 0.5307],
       device='cuda:0') torch.Size([16])
percent tensor([0.5648, 0.5755, 0.5595, 0.5531, 0.5656, 0.5705, 0.5767, 0.5609, 0.5608,
        0.5692, 0.5711, 0.5712, 0.5641, 0.5638, 0.5768, 0.5677],
       device='cuda:0') torch.Size([16])
percent tensor([0.5533, 0.5786, 0.5339, 0.5248, 0.5366, 0.5208, 0.5650, 0.5419, 0.5463,
        0.5700, 0.5641, 0.5570, 0.5664, 0.5700, 0.5582, 0.5584],
       device='cuda:0') torch.Size([16])
percent tensor([0.6018, 0.6073, 0.5872, 0.5884, 0.5901, 0.6019, 0.6076, 0.5904, 0.5977,
        0.6079, 0.6088, 0.5993, 0.6026, 0.6060, 0.6124, 0.6019],
       device='cuda:0') torch.Size([16])
percent tensor([0.4585, 0.4813, 0.4971, 0.5018, 0.5174, 0.4754, 0.4900, 0.5118, 0.4938,
        0.4753, 0.4834, 0.4733, 0.4433, 0.5045, 0.4860, 0.4702],
       device='cuda:0') torch.Size([16])
percent tensor([0.4569, 0.4817, 0.5307, 0.5476, 0.5628, 0.5481, 0.5176, 0.5104, 0.5418,
        0.4720, 0.5230, 0.5359, 0.4613, 0.5411, 0.4813, 0.4808],
       device='cuda:0') torch.Size([16])
percent tensor([0.5638, 0.5424, 0.6328, 0.6263, 0.6456, 0.5960, 0.5930, 0.6100, 0.5949,
        0.5739, 0.5703, 0.6009, 0.5510, 0.5995, 0.5516, 0.5643],
       device='cuda:0') torch.Size([16])
percent tensor([0.9979, 0.9954, 0.9984, 0.9975, 0.9991, 0.9972, 0.9984, 0.9995, 0.9972,
        0.9981, 0.9978, 0.9975, 0.9969, 0.9970, 0.9972, 0.9984],
       device='cuda:0') torch.Size([16])
Epoch: 52 | Batch_idx: 0 |  Loss: (0.3461) |  Loss2: (0.0000) | Acc: (89.00%) (115/128)
Epoch: 52 | Batch_idx: 10 |  Loss: (0.3926) |  Loss2: (0.0000) | Acc: (87.00%) (1228/1408)
Epoch: 52 | Batch_idx: 20 |  Loss: (0.3883) |  Loss2: (0.0000) | Acc: (87.00%) (2341/2688)
Epoch: 52 | Batch_idx: 30 |  Loss: (0.3751) |  Loss2: (0.0000) | Acc: (87.00%) (3465/3968)
Epoch: 52 | Batch_idx: 40 |  Loss: (0.3717) |  Loss2: (0.0000) | Acc: (87.00%) (4588/5248)
Epoch: 52 | Batch_idx: 50 |  Loss: (0.3792) |  Loss2: (0.0000) | Acc: (87.00%) (5681/6528)
Epoch: 52 | Batch_idx: 60 |  Loss: (0.3784) |  Loss2: (0.0000) | Acc: (87.00%) (6796/7808)
Epoch: 52 | Batch_idx: 70 |  Loss: (0.3793) |  Loss2: (0.0000) | Acc: (87.00%) (7908/9088)
Epoch: 52 | Batch_idx: 80 |  Loss: (0.3815) |  Loss2: (0.0000) | Acc: (86.00%) (9013/10368)
Epoch: 52 | Batch_idx: 90 |  Loss: (0.3841) |  Loss2: (0.0000) | Acc: (86.00%) (10121/11648)
Epoch: 52 | Batch_idx: 100 |  Loss: (0.3908) |  Loss2: (0.0000) | Acc: (86.00%) (11200/12928)
Epoch: 52 | Batch_idx: 110 |  Loss: (0.3913) |  Loss2: (0.0000) | Acc: (86.00%) (12306/14208)
Epoch: 52 | Batch_idx: 120 |  Loss: (0.3909) |  Loss2: (0.0000) | Acc: (86.00%) (13421/15488)
Epoch: 52 | Batch_idx: 130 |  Loss: (0.3889) |  Loss2: (0.0000) | Acc: (86.00%) (14547/16768)
Epoch: 52 | Batch_idx: 140 |  Loss: (0.3885) |  Loss2: (0.0000) | Acc: (86.00%) (15660/18048)
Epoch: 52 | Batch_idx: 150 |  Loss: (0.3889) |  Loss2: (0.0000) | Acc: (86.00%) (16759/19328)
Epoch: 52 | Batch_idx: 160 |  Loss: (0.3876) |  Loss2: (0.0000) | Acc: (86.00%) (17886/20608)
Epoch: 52 | Batch_idx: 170 |  Loss: (0.3886) |  Loss2: (0.0000) | Acc: (86.00%) (18997/21888)
Epoch: 52 | Batch_idx: 180 |  Loss: (0.3907) |  Loss2: (0.0000) | Acc: (86.00%) (20098/23168)
Epoch: 52 | Batch_idx: 190 |  Loss: (0.3888) |  Loss2: (0.0000) | Acc: (86.00%) (21214/24448)
Epoch: 52 | Batch_idx: 200 |  Loss: (0.3904) |  Loss2: (0.0000) | Acc: (86.00%) (22307/25728)
Epoch: 52 | Batch_idx: 210 |  Loss: (0.3912) |  Loss2: (0.0000) | Acc: (86.00%) (23399/27008)
Epoch: 52 | Batch_idx: 220 |  Loss: (0.3923) |  Loss2: (0.0000) | Acc: (86.00%) (24489/28288)
Epoch: 52 | Batch_idx: 230 |  Loss: (0.3936) |  Loss2: (0.0000) | Acc: (86.00%) (25584/29568)
Epoch: 52 | Batch_idx: 240 |  Loss: (0.3914) |  Loss2: (0.0000) | Acc: (86.00%) (26712/30848)
Epoch: 52 | Batch_idx: 250 |  Loss: (0.3910) |  Loss2: (0.0000) | Acc: (86.00%) (27835/32128)
Epoch: 52 | Batch_idx: 260 |  Loss: (0.3905) |  Loss2: (0.0000) | Acc: (86.00%) (28941/33408)
Epoch: 52 | Batch_idx: 270 |  Loss: (0.3909) |  Loss2: (0.0000) | Acc: (86.00%) (30046/34688)
Epoch: 52 | Batch_idx: 280 |  Loss: (0.3915) |  Loss2: (0.0000) | Acc: (86.00%) (31146/35968)
Epoch: 52 | Batch_idx: 290 |  Loss: (0.3914) |  Loss2: (0.0000) | Acc: (86.00%) (32258/37248)
Epoch: 52 | Batch_idx: 300 |  Loss: (0.3915) |  Loss2: (0.0000) | Acc: (86.00%) (33363/38528)
Epoch: 52 | Batch_idx: 310 |  Loss: (0.3909) |  Loss2: (0.0000) | Acc: (86.00%) (34484/39808)
Epoch: 52 | Batch_idx: 320 |  Loss: (0.3904) |  Loss2: (0.0000) | Acc: (86.00%) (35599/41088)
Epoch: 52 | Batch_idx: 330 |  Loss: (0.3920) |  Loss2: (0.0000) | Acc: (86.00%) (36673/42368)
Epoch: 52 | Batch_idx: 340 |  Loss: (0.3920) |  Loss2: (0.0000) | Acc: (86.00%) (37775/43648)
Epoch: 52 | Batch_idx: 350 |  Loss: (0.3916) |  Loss2: (0.0000) | Acc: (86.00%) (38898/44928)
Epoch: 52 | Batch_idx: 360 |  Loss: (0.3910) |  Loss2: (0.0000) | Acc: (86.00%) (40001/46208)
Epoch: 52 | Batch_idx: 370 |  Loss: (0.3901) |  Loss2: (0.0000) | Acc: (86.00%) (41121/47488)
Epoch: 52 | Batch_idx: 380 |  Loss: (0.3898) |  Loss2: (0.0000) | Acc: (86.00%) (42228/48768)
Epoch: 52 | Batch_idx: 390 |  Loss: (0.3893) |  Loss2: (0.0000) | Acc: (86.00%) (43304/50000)
# TEST : Loss: (0.4703) | Acc: (84.00%) (8437/10000)
percent tensor([0.5248, 0.5272, 0.5357, 0.5363, 0.5365, 0.5368, 0.5296, 0.5331, 0.5239,
        0.5264, 0.5228, 0.5303, 0.5241, 0.5224, 0.5326, 0.5280],
       device='cuda:0') torch.Size([16])
percent tensor([0.5620, 0.5723, 0.5574, 0.5505, 0.5630, 0.5673, 0.5738, 0.5584, 0.5580,
        0.5662, 0.5678, 0.5687, 0.5614, 0.5604, 0.5737, 0.5646],
       device='cuda:0') torch.Size([16])
percent tensor([0.5562, 0.5802, 0.5366, 0.5278, 0.5387, 0.5234, 0.5671, 0.5444, 0.5485,
        0.5717, 0.5662, 0.5597, 0.5690, 0.5712, 0.5611, 0.5612],
       device='cuda:0') torch.Size([16])
percent tensor([0.5987, 0.6052, 0.5858, 0.5867, 0.5884, 0.5986, 0.6053, 0.5894, 0.5963,
        0.6057, 0.6063, 0.5982, 0.6005, 0.6045, 0.6092, 0.5993],
       device='cuda:0') torch.Size([16])
percent tensor([0.4630, 0.4855, 0.5042, 0.5096, 0.5214, 0.4807, 0.4941, 0.5169, 0.5047,
        0.4806, 0.4916, 0.4836, 0.4499, 0.5134, 0.4909, 0.4721],
       device='cuda:0') torch.Size([16])
percent tensor([0.4556, 0.4814, 0.5313, 0.5484, 0.5655, 0.5511, 0.5180, 0.5093, 0.5426,
        0.4721, 0.5232, 0.5346, 0.4615, 0.5413, 0.4787, 0.4812],
       device='cuda:0') torch.Size([16])
percent tensor([0.5705, 0.5489, 0.6388, 0.6290, 0.6493, 0.6097, 0.5956, 0.6072, 0.6021,
        0.5818, 0.5776, 0.6015, 0.5613, 0.6058, 0.5502, 0.5704],
       device='cuda:0') torch.Size([16])
percent tensor([0.9982, 0.9957, 0.9986, 0.9977, 0.9992, 0.9976, 0.9985, 0.9995, 0.9977,
        0.9983, 0.9980, 0.9978, 0.9972, 0.9974, 0.9973, 0.9986],
       device='cuda:0') torch.Size([16])
Epoch: 53 | Batch_idx: 0 |  Loss: (0.2539) |  Loss2: (0.0000) | Acc: (92.00%) (118/128)
Epoch: 53 | Batch_idx: 10 |  Loss: (0.3576) |  Loss2: (0.0000) | Acc: (87.00%) (1230/1408)
Epoch: 53 | Batch_idx: 20 |  Loss: (0.3658) |  Loss2: (0.0000) | Acc: (87.00%) (2355/2688)
Epoch: 53 | Batch_idx: 30 |  Loss: (0.3589) |  Loss2: (0.0000) | Acc: (87.00%) (3489/3968)
Epoch: 53 | Batch_idx: 40 |  Loss: (0.3589) |  Loss2: (0.0000) | Acc: (87.00%) (4605/5248)
Epoch: 53 | Batch_idx: 50 |  Loss: (0.3589) |  Loss2: (0.0000) | Acc: (87.00%) (5726/6528)
Epoch: 53 | Batch_idx: 60 |  Loss: (0.3619) |  Loss2: (0.0000) | Acc: (87.00%) (6839/7808)
Epoch: 53 | Batch_idx: 70 |  Loss: (0.3623) |  Loss2: (0.0000) | Acc: (87.00%) (7967/9088)
Epoch: 53 | Batch_idx: 80 |  Loss: (0.3631) |  Loss2: (0.0000) | Acc: (87.00%) (9079/10368)
Epoch: 53 | Batch_idx: 90 |  Loss: (0.3644) |  Loss2: (0.0000) | Acc: (87.00%) (10190/11648)
Epoch: 53 | Batch_idx: 100 |  Loss: (0.3636) |  Loss2: (0.0000) | Acc: (87.00%) (11308/12928)
Epoch: 53 | Batch_idx: 110 |  Loss: (0.3664) |  Loss2: (0.0000) | Acc: (87.00%) (12415/14208)
Epoch: 53 | Batch_idx: 120 |  Loss: (0.3699) |  Loss2: (0.0000) | Acc: (87.00%) (13505/15488)
Epoch: 53 | Batch_idx: 130 |  Loss: (0.3673) |  Loss2: (0.0000) | Acc: (87.00%) (14632/16768)
Epoch: 53 | Batch_idx: 140 |  Loss: (0.3714) |  Loss2: (0.0000) | Acc: (87.00%) (15718/18048)
Epoch: 53 | Batch_idx: 150 |  Loss: (0.3739) |  Loss2: (0.0000) | Acc: (87.00%) (16821/19328)
Epoch: 53 | Batch_idx: 160 |  Loss: (0.3753) |  Loss2: (0.0000) | Acc: (86.00%) (17924/20608)
Epoch: 53 | Batch_idx: 170 |  Loss: (0.3750) |  Loss2: (0.0000) | Acc: (87.00%) (19054/21888)
Epoch: 53 | Batch_idx: 180 |  Loss: (0.3758) |  Loss2: (0.0000) | Acc: (87.00%) (20171/23168)
Epoch: 53 | Batch_idx: 190 |  Loss: (0.3776) |  Loss2: (0.0000) | Acc: (86.00%) (21259/24448)
Epoch: 53 | Batch_idx: 200 |  Loss: (0.3780) |  Loss2: (0.0000) | Acc: (86.00%) (22373/25728)
Epoch: 53 | Batch_idx: 210 |  Loss: (0.3785) |  Loss2: (0.0000) | Acc: (86.00%) (23478/27008)
Epoch: 53 | Batch_idx: 220 |  Loss: (0.3787) |  Loss2: (0.0000) | Acc: (86.00%) (24579/28288)
Epoch: 53 | Batch_idx: 230 |  Loss: (0.3794) |  Loss2: (0.0000) | Acc: (86.00%) (25688/29568)
Epoch: 53 | Batch_idx: 240 |  Loss: (0.3796) |  Loss2: (0.0000) | Acc: (86.00%) (26808/30848)
Epoch: 53 | Batch_idx: 250 |  Loss: (0.3794) |  Loss2: (0.0000) | Acc: (86.00%) (27926/32128)
Epoch: 53 | Batch_idx: 260 |  Loss: (0.3800) |  Loss2: (0.0000) | Acc: (86.00%) (29024/33408)
Epoch: 53 | Batch_idx: 270 |  Loss: (0.3817) |  Loss2: (0.0000) | Acc: (86.00%) (30121/34688)
Epoch: 53 | Batch_idx: 280 |  Loss: (0.3813) |  Loss2: (0.0000) | Acc: (86.00%) (31258/35968)
Epoch: 53 | Batch_idx: 290 |  Loss: (0.3824) |  Loss2: (0.0000) | Acc: (86.00%) (32367/37248)
Epoch: 53 | Batch_idx: 300 |  Loss: (0.3819) |  Loss2: (0.0000) | Acc: (86.00%) (33490/38528)
Epoch: 53 | Batch_idx: 310 |  Loss: (0.3830) |  Loss2: (0.0000) | Acc: (86.00%) (34585/39808)
Epoch: 53 | Batch_idx: 320 |  Loss: (0.3821) |  Loss2: (0.0000) | Acc: (86.00%) (35702/41088)
Epoch: 53 | Batch_idx: 330 |  Loss: (0.3822) |  Loss2: (0.0000) | Acc: (86.00%) (36807/42368)
Epoch: 53 | Batch_idx: 340 |  Loss: (0.3831) |  Loss2: (0.0000) | Acc: (86.00%) (37895/43648)
Epoch: 53 | Batch_idx: 350 |  Loss: (0.3835) |  Loss2: (0.0000) | Acc: (86.00%) (39000/44928)
Epoch: 53 | Batch_idx: 360 |  Loss: (0.3823) |  Loss2: (0.0000) | Acc: (86.00%) (40133/46208)
Epoch: 53 | Batch_idx: 370 |  Loss: (0.3819) |  Loss2: (0.0000) | Acc: (86.00%) (41249/47488)
Epoch: 53 | Batch_idx: 380 |  Loss: (0.3810) |  Loss2: (0.0000) | Acc: (86.00%) (42382/48768)
Epoch: 53 | Batch_idx: 390 |  Loss: (0.3800) |  Loss2: (0.0000) | Acc: (86.00%) (43460/50000)
# TEST : Loss: (0.4655) | Acc: (84.00%) (8455/10000)
percent tensor([0.5266, 0.5293, 0.5388, 0.5393, 0.5396, 0.5394, 0.5319, 0.5359, 0.5257,
        0.5286, 0.5244, 0.5330, 0.5258, 0.5239, 0.5351, 0.5301],
       device='cuda:0') torch.Size([16])
percent tensor([0.5606, 0.5704, 0.5557, 0.5489, 0.5612, 0.5659, 0.5720, 0.5568, 0.5561,
        0.5642, 0.5658, 0.5669, 0.5598, 0.5586, 0.5722, 0.5631],
       device='cuda:0') torch.Size([16])
percent tensor([0.5592, 0.5823, 0.5390, 0.5300, 0.5404, 0.5258, 0.5697, 0.5468, 0.5507,
        0.5741, 0.5686, 0.5626, 0.5717, 0.5732, 0.5642, 0.5640],
       device='cuda:0') torch.Size([16])
percent tensor([0.6015, 0.6082, 0.5888, 0.5899, 0.5916, 0.6009, 0.6084, 0.5929, 0.5997,
        0.6090, 0.6093, 0.6017, 0.6035, 0.6080, 0.6119, 0.6022],
       device='cuda:0') torch.Size([16])
percent tensor([0.4552, 0.4735, 0.5043, 0.5105, 0.5211, 0.4794, 0.4850, 0.5167, 0.5017,
        0.4696, 0.4812, 0.4777, 0.4406, 0.5061, 0.4823, 0.4636],
       device='cuda:0') torch.Size([16])
percent tensor([0.4586, 0.4851, 0.5375, 0.5545, 0.5745, 0.5552, 0.5232, 0.5158, 0.5468,
        0.4767, 0.5268, 0.5388, 0.4648, 0.5437, 0.4825, 0.4848],
       device='cuda:0') torch.Size([16])
percent tensor([0.5801, 0.5560, 0.6499, 0.6378, 0.6590, 0.6219, 0.6038, 0.6154, 0.6105,
        0.5907, 0.5844, 0.6066, 0.5712, 0.6110, 0.5534, 0.5808],
       device='cuda:0') torch.Size([16])
percent tensor([0.9984, 0.9960, 0.9988, 0.9979, 0.9993, 0.9979, 0.9987, 0.9996, 0.9979,
        0.9984, 0.9981, 0.9980, 0.9974, 0.9976, 0.9977, 0.9988],
       device='cuda:0') torch.Size([16])
Epoch: 54 | Batch_idx: 0 |  Loss: (0.3687) |  Loss2: (0.0000) | Acc: (84.00%) (108/128)
Epoch: 54 | Batch_idx: 10 |  Loss: (0.3791) |  Loss2: (0.0000) | Acc: (86.00%) (1215/1408)
Epoch: 54 | Batch_idx: 20 |  Loss: (0.3758) |  Loss2: (0.0000) | Acc: (87.00%) (2345/2688)
Epoch: 54 | Batch_idx: 30 |  Loss: (0.3835) |  Loss2: (0.0000) | Acc: (86.00%) (3444/3968)
Epoch: 54 | Batch_idx: 40 |  Loss: (0.3811) |  Loss2: (0.0000) | Acc: (87.00%) (4571/5248)
Epoch: 54 | Batch_idx: 50 |  Loss: (0.3816) |  Loss2: (0.0000) | Acc: (87.00%) (5683/6528)
Epoch: 54 | Batch_idx: 60 |  Loss: (0.3885) |  Loss2: (0.0000) | Acc: (86.00%) (6762/7808)
Epoch: 54 | Batch_idx: 70 |  Loss: (0.3832) |  Loss2: (0.0000) | Acc: (86.00%) (7881/9088)
Epoch: 54 | Batch_idx: 80 |  Loss: (0.3856) |  Loss2: (0.0000) | Acc: (86.00%) (8989/10368)
Epoch: 54 | Batch_idx: 90 |  Loss: (0.3822) |  Loss2: (0.0000) | Acc: (86.00%) (10119/11648)
Epoch: 54 | Batch_idx: 100 |  Loss: (0.3818) |  Loss2: (0.0000) | Acc: (86.00%) (11225/12928)
Epoch: 54 | Batch_idx: 110 |  Loss: (0.3824) |  Loss2: (0.0000) | Acc: (86.00%) (12333/14208)
Epoch: 54 | Batch_idx: 120 |  Loss: (0.3828) |  Loss2: (0.0000) | Acc: (86.00%) (13452/15488)
Epoch: 54 | Batch_idx: 130 |  Loss: (0.3837) |  Loss2: (0.0000) | Acc: (86.00%) (14555/16768)
Epoch: 54 | Batch_idx: 140 |  Loss: (0.3807) |  Loss2: (0.0000) | Acc: (86.00%) (15687/18048)
Epoch: 54 | Batch_idx: 150 |  Loss: (0.3802) |  Loss2: (0.0000) | Acc: (87.00%) (16819/19328)
Epoch: 54 | Batch_idx: 160 |  Loss: (0.3815) |  Loss2: (0.0000) | Acc: (86.00%) (17926/20608)
Epoch: 54 | Batch_idx: 170 |  Loss: (0.3834) |  Loss2: (0.0000) | Acc: (86.00%) (19030/21888)
Epoch: 54 | Batch_idx: 180 |  Loss: (0.3824) |  Loss2: (0.0000) | Acc: (86.00%) (20148/23168)
Epoch: 54 | Batch_idx: 190 |  Loss: (0.3831) |  Loss2: (0.0000) | Acc: (86.00%) (21257/24448)
Epoch: 54 | Batch_idx: 200 |  Loss: (0.3820) |  Loss2: (0.0000) | Acc: (87.00%) (22391/25728)
Epoch: 54 | Batch_idx: 210 |  Loss: (0.3821) |  Loss2: (0.0000) | Acc: (87.00%) (23506/27008)
Epoch: 54 | Batch_idx: 220 |  Loss: (0.3794) |  Loss2: (0.0000) | Acc: (87.00%) (24649/28288)
Epoch: 54 | Batch_idx: 230 |  Loss: (0.3775) |  Loss2: (0.0000) | Acc: (87.00%) (25781/29568)
Epoch: 54 | Batch_idx: 240 |  Loss: (0.3762) |  Loss2: (0.0000) | Acc: (87.00%) (26910/30848)
Epoch: 54 | Batch_idx: 250 |  Loss: (0.3761) |  Loss2: (0.0000) | Acc: (87.00%) (28024/32128)
Epoch: 54 | Batch_idx: 260 |  Loss: (0.3770) |  Loss2: (0.0000) | Acc: (87.00%) (29123/33408)
Epoch: 54 | Batch_idx: 270 |  Loss: (0.3765) |  Loss2: (0.0000) | Acc: (87.00%) (30242/34688)
Epoch: 54 | Batch_idx: 280 |  Loss: (0.3768) |  Loss2: (0.0000) | Acc: (87.00%) (31349/35968)
Epoch: 54 | Batch_idx: 290 |  Loss: (0.3776) |  Loss2: (0.0000) | Acc: (87.00%) (32447/37248)
Epoch: 54 | Batch_idx: 300 |  Loss: (0.3779) |  Loss2: (0.0000) | Acc: (87.00%) (33558/38528)
Epoch: 54 | Batch_idx: 310 |  Loss: (0.3787) |  Loss2: (0.0000) | Acc: (87.00%) (34648/39808)
Epoch: 54 | Batch_idx: 320 |  Loss: (0.3795) |  Loss2: (0.0000) | Acc: (87.00%) (35751/41088)
Epoch: 54 | Batch_idx: 330 |  Loss: (0.3791) |  Loss2: (0.0000) | Acc: (87.00%) (36864/42368)
Epoch: 54 | Batch_idx: 340 |  Loss: (0.3791) |  Loss2: (0.0000) | Acc: (87.00%) (37984/43648)
Epoch: 54 | Batch_idx: 350 |  Loss: (0.3794) |  Loss2: (0.0000) | Acc: (86.00%) (39084/44928)
Epoch: 54 | Batch_idx: 360 |  Loss: (0.3806) |  Loss2: (0.0000) | Acc: (86.00%) (40163/46208)
Epoch: 54 | Batch_idx: 370 |  Loss: (0.3809) |  Loss2: (0.0000) | Acc: (86.00%) (41269/47488)
Epoch: 54 | Batch_idx: 380 |  Loss: (0.3808) |  Loss2: (0.0000) | Acc: (86.00%) (42383/48768)
Epoch: 54 | Batch_idx: 390 |  Loss: (0.3803) |  Loss2: (0.0000) | Acc: (86.00%) (43453/50000)
# TEST : Loss: (0.4638) | Acc: (84.00%) (8451/10000)
percent tensor([0.5270, 0.5298, 0.5400, 0.5405, 0.5408, 0.5403, 0.5327, 0.5369, 0.5260,
        0.5292, 0.5246, 0.5340, 0.5262, 0.5242, 0.5359, 0.5308],
       device='cuda:0') torch.Size([16])
percent tensor([0.5582, 0.5677, 0.5535, 0.5466, 0.5588, 0.5634, 0.5693, 0.5544, 0.5536,
        0.5616, 0.5631, 0.5645, 0.5575, 0.5557, 0.5697, 0.5606],
       device='cuda:0') torch.Size([16])
percent tensor([0.5648, 0.5861, 0.5446, 0.5358, 0.5453, 0.5310, 0.5744, 0.5525, 0.5556,
        0.5782, 0.5728, 0.5680, 0.5767, 0.5776, 0.5698, 0.5692],
       device='cuda:0') torch.Size([16])
percent tensor([0.6001, 0.6078, 0.5877, 0.5884, 0.5903, 0.5994, 0.6076, 0.5919, 0.5991,
        0.6085, 0.6087, 0.6015, 0.6032, 0.6076, 0.6106, 0.6013],
       device='cuda:0') torch.Size([16])
percent tensor([0.4541, 0.4711, 0.5067, 0.5133, 0.5226, 0.4806, 0.4827, 0.5187, 0.5036,
        0.4675, 0.4801, 0.4779, 0.4386, 0.5060, 0.4813, 0.4613],
       device='cuda:0') torch.Size([16])
percent tensor([0.4588, 0.4850, 0.5361, 0.5514, 0.5738, 0.5542, 0.5227, 0.5136, 0.5455,
        0.4768, 0.5265, 0.5360, 0.4648, 0.5435, 0.4811, 0.4850],
       device='cuda:0') torch.Size([16])
percent tensor([0.5836, 0.5586, 0.6533, 0.6408, 0.6630, 0.6256, 0.6074, 0.6186, 0.6134,
        0.5937, 0.5863, 0.6076, 0.5736, 0.6133, 0.5553, 0.5852],
       device='cuda:0') torch.Size([16])
percent tensor([0.9985, 0.9964, 0.9989, 0.9979, 0.9994, 0.9980, 0.9988, 0.9996, 0.9982,
        0.9986, 0.9983, 0.9981, 0.9977, 0.9979, 0.9978, 0.9989],
       device='cuda:0') torch.Size([16])
Epoch: 55 | Batch_idx: 0 |  Loss: (0.3129) |  Loss2: (0.0000) | Acc: (86.00%) (111/128)
Epoch: 55 | Batch_idx: 10 |  Loss: (0.3780) |  Loss2: (0.0000) | Acc: (86.00%) (1219/1408)
Epoch: 55 | Batch_idx: 20 |  Loss: (0.3769) |  Loss2: (0.0000) | Acc: (86.00%) (2329/2688)
Epoch: 55 | Batch_idx: 30 |  Loss: (0.3741) |  Loss2: (0.0000) | Acc: (86.00%) (3446/3968)
Epoch: 55 | Batch_idx: 40 |  Loss: (0.3628) |  Loss2: (0.0000) | Acc: (87.00%) (4585/5248)
Epoch: 55 | Batch_idx: 50 |  Loss: (0.3649) |  Loss2: (0.0000) | Acc: (87.00%) (5702/6528)
Epoch: 55 | Batch_idx: 60 |  Loss: (0.3645) |  Loss2: (0.0000) | Acc: (87.00%) (6825/7808)
Epoch: 55 | Batch_idx: 70 |  Loss: (0.3700) |  Loss2: (0.0000) | Acc: (87.00%) (7924/9088)
Epoch: 55 | Batch_idx: 80 |  Loss: (0.3658) |  Loss2: (0.0000) | Acc: (87.00%) (9060/10368)
Epoch: 55 | Batch_idx: 90 |  Loss: (0.3664) |  Loss2: (0.0000) | Acc: (87.00%) (10187/11648)
Epoch: 55 | Batch_idx: 100 |  Loss: (0.3667) |  Loss2: (0.0000) | Acc: (87.00%) (11303/12928)
Epoch: 55 | Batch_idx: 110 |  Loss: (0.3676) |  Loss2: (0.0000) | Acc: (87.00%) (12416/14208)
Epoch: 55 | Batch_idx: 120 |  Loss: (0.3663) |  Loss2: (0.0000) | Acc: (87.00%) (13534/15488)
Epoch: 55 | Batch_idx: 130 |  Loss: (0.3669) |  Loss2: (0.0000) | Acc: (87.00%) (14647/16768)
Epoch: 55 | Batch_idx: 140 |  Loss: (0.3657) |  Loss2: (0.0000) | Acc: (87.00%) (15775/18048)
Epoch: 55 | Batch_idx: 150 |  Loss: (0.3644) |  Loss2: (0.0000) | Acc: (87.00%) (16910/19328)
Epoch: 55 | Batch_idx: 160 |  Loss: (0.3656) |  Loss2: (0.0000) | Acc: (87.00%) (18021/20608)
Epoch: 55 | Batch_idx: 170 |  Loss: (0.3682) |  Loss2: (0.0000) | Acc: (87.00%) (19123/21888)
Epoch: 55 | Batch_idx: 180 |  Loss: (0.3660) |  Loss2: (0.0000) | Acc: (87.00%) (20258/23168)
Epoch: 55 | Batch_idx: 190 |  Loss: (0.3678) |  Loss2: (0.0000) | Acc: (87.00%) (21371/24448)
Epoch: 55 | Batch_idx: 200 |  Loss: (0.3706) |  Loss2: (0.0000) | Acc: (87.00%) (22461/25728)
Epoch: 55 | Batch_idx: 210 |  Loss: (0.3699) |  Loss2: (0.0000) | Acc: (87.00%) (23573/27008)
Epoch: 55 | Batch_idx: 220 |  Loss: (0.3698) |  Loss2: (0.0000) | Acc: (87.00%) (24671/28288)
Epoch: 55 | Batch_idx: 230 |  Loss: (0.3719) |  Loss2: (0.0000) | Acc: (87.00%) (25763/29568)
Epoch: 55 | Batch_idx: 240 |  Loss: (0.3721) |  Loss2: (0.0000) | Acc: (87.00%) (26878/30848)
Epoch: 55 | Batch_idx: 250 |  Loss: (0.3725) |  Loss2: (0.0000) | Acc: (87.00%) (27991/32128)
Epoch: 55 | Batch_idx: 260 |  Loss: (0.3712) |  Loss2: (0.0000) | Acc: (87.00%) (29129/33408)
Epoch: 55 | Batch_idx: 270 |  Loss: (0.3721) |  Loss2: (0.0000) | Acc: (87.00%) (30243/34688)
Epoch: 55 | Batch_idx: 280 |  Loss: (0.3708) |  Loss2: (0.0000) | Acc: (87.00%) (31386/35968)
Epoch: 55 | Batch_idx: 290 |  Loss: (0.3723) |  Loss2: (0.0000) | Acc: (87.00%) (32478/37248)
Epoch: 55 | Batch_idx: 300 |  Loss: (0.3742) |  Loss2: (0.0000) | Acc: (87.00%) (33569/38528)
Epoch: 55 | Batch_idx: 310 |  Loss: (0.3734) |  Loss2: (0.0000) | Acc: (87.00%) (34699/39808)
Epoch: 55 | Batch_idx: 320 |  Loss: (0.3735) |  Loss2: (0.0000) | Acc: (87.00%) (35826/41088)
Epoch: 55 | Batch_idx: 330 |  Loss: (0.3731) |  Loss2: (0.0000) | Acc: (87.00%) (36958/42368)
Epoch: 55 | Batch_idx: 340 |  Loss: (0.3735) |  Loss2: (0.0000) | Acc: (87.00%) (38071/43648)
Epoch: 55 | Batch_idx: 350 |  Loss: (0.3744) |  Loss2: (0.0000) | Acc: (87.00%) (39180/44928)
Epoch: 55 | Batch_idx: 360 |  Loss: (0.3739) |  Loss2: (0.0000) | Acc: (87.00%) (40303/46208)
Epoch: 55 | Batch_idx: 370 |  Loss: (0.3736) |  Loss2: (0.0000) | Acc: (87.00%) (41422/47488)
Epoch: 55 | Batch_idx: 380 |  Loss: (0.3737) |  Loss2: (0.0000) | Acc: (87.00%) (42541/48768)
Epoch: 55 | Batch_idx: 390 |  Loss: (0.3748) |  Loss2: (0.0000) | Acc: (87.00%) (43611/50000)
=> saving checkpoint 'drive/app/torch/save_Schedule/checkpoint_055.pth.tar'
# TEST : Loss: (0.4594) | Acc: (84.00%) (8469/10000)
percent tensor([0.5275, 0.5304, 0.5409, 0.5414, 0.5417, 0.5412, 0.5334, 0.5378, 0.5264,
        0.5298, 0.5250, 0.5347, 0.5266, 0.5246, 0.5367, 0.5315],
       device='cuda:0') torch.Size([16])
percent tensor([0.5575, 0.5674, 0.5529, 0.5458, 0.5582, 0.5626, 0.5690, 0.5541, 0.5529,
        0.5610, 0.5623, 0.5640, 0.5570, 0.5550, 0.5693, 0.5599],
       device='cuda:0') torch.Size([16])
percent tensor([0.5647, 0.5850, 0.5444, 0.5356, 0.5444, 0.5314, 0.5738, 0.5520, 0.5550,
        0.5768, 0.5719, 0.5676, 0.5762, 0.5762, 0.5697, 0.5688],
       device='cuda:0') torch.Size([16])
percent tensor([0.6016, 0.6097, 0.5892, 0.5896, 0.5918, 0.6007, 0.6095, 0.5938, 0.6009,
        0.6104, 0.6103, 0.6035, 0.6051, 0.6094, 0.6122, 0.6030],
       device='cuda:0') torch.Size([16])
percent tensor([0.4528, 0.4691, 0.5064, 0.5128, 0.5221, 0.4819, 0.4812, 0.5178, 0.5039,
        0.4656, 0.4790, 0.4768, 0.4378, 0.5038, 0.4793, 0.4597],
       device='cuda:0') torch.Size([16])
percent tensor([0.4538, 0.4799, 0.5325, 0.5483, 0.5721, 0.5526, 0.5182, 0.5091, 0.5427,
        0.4731, 0.5231, 0.5310, 0.4608, 0.5386, 0.4746, 0.4805],
       device='cuda:0') torch.Size([16])
percent tensor([0.5815, 0.5556, 0.6510, 0.6375, 0.6598, 0.6284, 0.6030, 0.6134, 0.6110,
        0.5921, 0.5834, 0.6020, 0.5719, 0.6087, 0.5499, 0.5841],
       device='cuda:0') torch.Size([16])
percent tensor([0.9987, 0.9968, 0.9991, 0.9983, 0.9995, 0.9984, 0.9990, 0.9997, 0.9984,
        0.9987, 0.9985, 0.9984, 0.9979, 0.9981, 0.9982, 0.9991],
       device='cuda:0') torch.Size([16])
True Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=128, out_features=16, bias=False)
False Linear(in_features=16, out_features=2, bias=False)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=128, out_features=16, bias=False)
False Linear(in_features=16, out_features=2, bias=False)
True Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=256, out_features=32, bias=False)
False Linear(in_features=32, out_features=2, bias=False)
True Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=256, out_features=32, bias=False)
False Linear(in_features=32, out_features=2, bias=False)
True Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=512, out_features=64, bias=False)
False Linear(in_features=64, out_features=2, bias=False)
True Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=512, out_features=64, bias=False)
False Linear(in_features=64, out_features=2, bias=False)
True Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1024, out_features=128, bias=False)
False Linear(in_features=128, out_features=2, bias=False)
True Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1024, out_features=128, bias=False)
False Linear(in_features=128, out_features=2, bias=False)
True Linear(in_features=512, out_features=10, bias=True)
Epoch: 56 | Batch_idx: 0 |  Loss: (0.3830) |  Loss2: (0.0000) | Acc: (86.00%) (111/128)
Epoch: 56 | Batch_idx: 10 |  Loss: (0.3554) |  Loss2: (0.0000) | Acc: (88.00%) (1241/1408)
Epoch: 56 | Batch_idx: 20 |  Loss: (0.3610) |  Loss2: (0.0000) | Acc: (87.00%) (2343/2688)
Epoch: 56 | Batch_idx: 30 |  Loss: (0.3787) |  Loss2: (0.0000) | Acc: (86.00%) (3430/3968)
Epoch: 56 | Batch_idx: 40 |  Loss: (0.3844) |  Loss2: (0.0000) | Acc: (86.00%) (4542/5248)
Epoch: 56 | Batch_idx: 50 |  Loss: (0.3830) |  Loss2: (0.0000) | Acc: (86.00%) (5655/6528)
Epoch: 56 | Batch_idx: 60 |  Loss: (0.3836) |  Loss2: (0.0000) | Acc: (86.00%) (6767/7808)
Epoch: 56 | Batch_idx: 70 |  Loss: (0.3841) |  Loss2: (0.0000) | Acc: (86.00%) (7888/9088)
Epoch: 56 | Batch_idx: 80 |  Loss: (0.3831) |  Loss2: (0.0000) | Acc: (86.00%) (8997/10368)
Epoch: 56 | Batch_idx: 90 |  Loss: (0.3873) |  Loss2: (0.0000) | Acc: (86.00%) (10087/11648)
Epoch: 56 | Batch_idx: 100 |  Loss: (0.3886) |  Loss2: (0.0000) | Acc: (86.00%) (11178/12928)
Epoch: 56 | Batch_idx: 110 |  Loss: (0.3878) |  Loss2: (0.0000) | Acc: (86.00%) (12281/14208)
Epoch: 56 | Batch_idx: 120 |  Loss: (0.3852) |  Loss2: (0.0000) | Acc: (86.00%) (13404/15488)
Epoch: 56 | Batch_idx: 130 |  Loss: (0.3869) |  Loss2: (0.0000) | Acc: (86.00%) (14515/16768)
Epoch: 56 | Batch_idx: 140 |  Loss: (0.3871) |  Loss2: (0.0000) | Acc: (86.00%) (15612/18048)
Epoch: 56 | Batch_idx: 150 |  Loss: (0.3872) |  Loss2: (0.0000) | Acc: (86.00%) (16719/19328)
Epoch: 56 | Batch_idx: 160 |  Loss: (0.3884) |  Loss2: (0.0000) | Acc: (86.00%) (17806/20608)
Epoch: 56 | Batch_idx: 170 |  Loss: (0.3884) |  Loss2: (0.0000) | Acc: (86.00%) (18916/21888)
Epoch: 56 | Batch_idx: 180 |  Loss: (0.3882) |  Loss2: (0.0000) | Acc: (86.00%) (20027/23168)
Epoch: 56 | Batch_idx: 190 |  Loss: (0.3889) |  Loss2: (0.0000) | Acc: (86.00%) (21130/24448)
Epoch: 56 | Batch_idx: 200 |  Loss: (0.3903) |  Loss2: (0.0000) | Acc: (86.00%) (22223/25728)
Epoch: 56 | Batch_idx: 210 |  Loss: (0.3908) |  Loss2: (0.0000) | Acc: (86.00%) (23346/27008)
Epoch: 56 | Batch_idx: 220 |  Loss: (0.3896) |  Loss2: (0.0000) | Acc: (86.00%) (24470/28288)
Epoch: 56 | Batch_idx: 230 |  Loss: (0.3910) |  Loss2: (0.0000) | Acc: (86.00%) (25557/29568)
Epoch: 56 | Batch_idx: 240 |  Loss: (0.3917) |  Loss2: (0.0000) | Acc: (86.00%) (26662/30848)
Epoch: 56 | Batch_idx: 250 |  Loss: (0.3923) |  Loss2: (0.0000) | Acc: (86.00%) (27771/32128)
Epoch: 56 | Batch_idx: 260 |  Loss: (0.3950) |  Loss2: (0.0000) | Acc: (86.00%) (28842/33408)
Epoch: 56 | Batch_idx: 270 |  Loss: (0.3962) |  Loss2: (0.0000) | Acc: (86.00%) (29937/34688)
Epoch: 56 | Batch_idx: 280 |  Loss: (0.3967) |  Loss2: (0.0000) | Acc: (86.00%) (31026/35968)
Epoch: 56 | Batch_idx: 290 |  Loss: (0.3963) |  Loss2: (0.0000) | Acc: (86.00%) (32142/37248)
Epoch: 56 | Batch_idx: 300 |  Loss: (0.3964) |  Loss2: (0.0000) | Acc: (86.00%) (33234/38528)
Epoch: 56 | Batch_idx: 310 |  Loss: (0.3968) |  Loss2: (0.0000) | Acc: (86.00%) (34328/39808)
Epoch: 56 | Batch_idx: 320 |  Loss: (0.3977) |  Loss2: (0.0000) | Acc: (86.00%) (35412/41088)
Epoch: 56 | Batch_idx: 330 |  Loss: (0.3974) |  Loss2: (0.0000) | Acc: (86.00%) (36507/42368)
Epoch: 56 | Batch_idx: 340 |  Loss: (0.3966) |  Loss2: (0.0000) | Acc: (86.00%) (37636/43648)
Epoch: 56 | Batch_idx: 350 |  Loss: (0.3975) |  Loss2: (0.0000) | Acc: (86.00%) (38712/44928)
Epoch: 56 | Batch_idx: 360 |  Loss: (0.3974) |  Loss2: (0.0000) | Acc: (86.00%) (39815/46208)
Epoch: 56 | Batch_idx: 370 |  Loss: (0.3978) |  Loss2: (0.0000) | Acc: (86.00%) (40915/47488)
Epoch: 56 | Batch_idx: 380 |  Loss: (0.3987) |  Loss2: (0.0000) | Acc: (86.00%) (41995/48768)
Epoch: 56 | Batch_idx: 390 |  Loss: (0.3986) |  Loss2: (0.0000) | Acc: (86.00%) (43062/50000)
# TEST : Loss: (0.5871) | Acc: (80.00%) (8089/10000)
percent tensor([0.5260, 0.5314, 0.5381, 0.5412, 0.5391, 0.5404, 0.5328, 0.5377, 0.5252,
        0.5296, 0.5241, 0.5320, 0.5254, 0.5267, 0.5368, 0.5313],
       device='cuda:0') torch.Size([16])
percent tensor([0.5578, 0.5652, 0.5528, 0.5464, 0.5577, 0.5653, 0.5672, 0.5536, 0.5531,
        0.5602, 0.5626, 0.5632, 0.5567, 0.5541, 0.5693, 0.5607],
       device='cuda:0') torch.Size([16])
percent tensor([0.5667, 0.5828, 0.5446, 0.5337, 0.5454, 0.5317, 0.5749, 0.5517, 0.5576,
        0.5776, 0.5751, 0.5671, 0.5797, 0.5734, 0.5692, 0.5683],
       device='cuda:0') torch.Size([16])
percent tensor([0.6045, 0.6094, 0.5901, 0.5890, 0.5961, 0.5995, 0.6124, 0.5951, 0.6035,
        0.6133, 0.6125, 0.6059, 0.6067, 0.6115, 0.6108, 0.6040],
       device='cuda:0') torch.Size([16])
percent tensor([0.4499, 0.4771, 0.5057, 0.5089, 0.5165, 0.4880, 0.4823, 0.5137, 0.5071,
        0.4683, 0.4836, 0.4660, 0.4395, 0.5150, 0.4851, 0.4654],
       device='cuda:0') torch.Size([16])
percent tensor([0.4561, 0.4704, 0.5316, 0.5408, 0.5593, 0.5370, 0.5068, 0.4959, 0.5419,
        0.4643, 0.5279, 0.5148, 0.4517, 0.5335, 0.4613, 0.4757],
       device='cuda:0') torch.Size([16])
percent tensor([0.5850, 0.5692, 0.6405, 0.6211, 0.6449, 0.6151, 0.6097, 0.6010, 0.6189,
        0.5954, 0.5863, 0.5990, 0.5754, 0.6306, 0.5526, 0.5774],
       device='cuda:0') torch.Size([16])
percent tensor([0.9990, 0.9970, 0.9989, 0.9979, 0.9994, 0.9979, 0.9994, 0.9997, 0.9992,
        0.9991, 0.9986, 0.9990, 0.9988, 0.9991, 0.9982, 0.9986],
       device='cuda:0') torch.Size([16])
Epoch: 57 | Batch_idx: 0 |  Loss: (0.4134) |  Loss2: (0.0000) | Acc: (89.00%) (114/128)
Epoch: 57 | Batch_idx: 10 |  Loss: (0.3957) |  Loss2: (0.0000) | Acc: (86.00%) (1216/1408)
Epoch: 57 | Batch_idx: 20 |  Loss: (0.3820) |  Loss2: (0.0000) | Acc: (86.00%) (2334/2688)
Epoch: 57 | Batch_idx: 30 |  Loss: (0.3787) |  Loss2: (0.0000) | Acc: (87.00%) (3454/3968)
Epoch: 57 | Batch_idx: 40 |  Loss: (0.3749) |  Loss2: (0.0000) | Acc: (87.00%) (4591/5248)
Epoch: 57 | Batch_idx: 50 |  Loss: (0.3762) |  Loss2: (0.0000) | Acc: (87.00%) (5697/6528)
Epoch: 57 | Batch_idx: 60 |  Loss: (0.3749) |  Loss2: (0.0000) | Acc: (87.00%) (6815/7808)
Epoch: 57 | Batch_idx: 70 |  Loss: (0.3782) |  Loss2: (0.0000) | Acc: (87.00%) (7922/9088)
Epoch: 57 | Batch_idx: 80 |  Loss: (0.3794) |  Loss2: (0.0000) | Acc: (87.00%) (9025/10368)
Epoch: 57 | Batch_idx: 90 |  Loss: (0.3821) |  Loss2: (0.0000) | Acc: (86.00%) (10110/11648)
Epoch: 57 | Batch_idx: 100 |  Loss: (0.3822) |  Loss2: (0.0000) | Acc: (86.00%) (11225/12928)
Epoch: 57 | Batch_idx: 110 |  Loss: (0.3814) |  Loss2: (0.0000) | Acc: (86.00%) (12335/14208)
Epoch: 57 | Batch_idx: 120 |  Loss: (0.3814) |  Loss2: (0.0000) | Acc: (86.00%) (13450/15488)
Epoch: 57 | Batch_idx: 130 |  Loss: (0.3805) |  Loss2: (0.0000) | Acc: (86.00%) (14573/16768)
Epoch: 57 | Batch_idx: 140 |  Loss: (0.3841) |  Loss2: (0.0000) | Acc: (86.00%) (15663/18048)
Epoch: 57 | Batch_idx: 150 |  Loss: (0.3830) |  Loss2: (0.0000) | Acc: (86.00%) (16773/19328)
Epoch: 57 | Batch_idx: 160 |  Loss: (0.3860) |  Loss2: (0.0000) | Acc: (86.00%) (17867/20608)
Epoch: 57 | Batch_idx: 170 |  Loss: (0.3879) |  Loss2: (0.0000) | Acc: (86.00%) (18964/21888)
Epoch: 57 | Batch_idx: 180 |  Loss: (0.3844) |  Loss2: (0.0000) | Acc: (86.00%) (20097/23168)
Epoch: 57 | Batch_idx: 190 |  Loss: (0.3855) |  Loss2: (0.0000) | Acc: (86.00%) (21197/24448)
Epoch: 57 | Batch_idx: 200 |  Loss: (0.3866) |  Loss2: (0.0000) | Acc: (86.00%) (22311/25728)
Epoch: 57 | Batch_idx: 210 |  Loss: (0.3863) |  Loss2: (0.0000) | Acc: (86.00%) (23402/27008)
Epoch: 57 | Batch_idx: 220 |  Loss: (0.3861) |  Loss2: (0.0000) | Acc: (86.00%) (24508/28288)
Epoch: 57 | Batch_idx: 230 |  Loss: (0.3867) |  Loss2: (0.0000) | Acc: (86.00%) (25614/29568)
Epoch: 57 | Batch_idx: 240 |  Loss: (0.3873) |  Loss2: (0.0000) | Acc: (86.00%) (26716/30848)
Epoch: 57 | Batch_idx: 250 |  Loss: (0.3880) |  Loss2: (0.0000) | Acc: (86.00%) (27818/32128)
Epoch: 57 | Batch_idx: 260 |  Loss: (0.3869) |  Loss2: (0.0000) | Acc: (86.00%) (28952/33408)
Epoch: 57 | Batch_idx: 270 |  Loss: (0.3862) |  Loss2: (0.0000) | Acc: (86.00%) (30077/34688)
Epoch: 57 | Batch_idx: 280 |  Loss: (0.3864) |  Loss2: (0.0000) | Acc: (86.00%) (31172/35968)
Epoch: 57 | Batch_idx: 290 |  Loss: (0.3866) |  Loss2: (0.0000) | Acc: (86.00%) (32296/37248)
Epoch: 57 | Batch_idx: 300 |  Loss: (0.3863) |  Loss2: (0.0000) | Acc: (86.00%) (33421/38528)
Epoch: 57 | Batch_idx: 310 |  Loss: (0.3871) |  Loss2: (0.0000) | Acc: (86.00%) (34518/39808)
Epoch: 57 | Batch_idx: 320 |  Loss: (0.3879) |  Loss2: (0.0000) | Acc: (86.00%) (35602/41088)
Epoch: 57 | Batch_idx: 330 |  Loss: (0.3872) |  Loss2: (0.0000) | Acc: (86.00%) (36723/42368)
Epoch: 57 | Batch_idx: 340 |  Loss: (0.3866) |  Loss2: (0.0000) | Acc: (86.00%) (37826/43648)
Epoch: 57 | Batch_idx: 350 |  Loss: (0.3870) |  Loss2: (0.0000) | Acc: (86.00%) (38924/44928)
Epoch: 57 | Batch_idx: 360 |  Loss: (0.3871) |  Loss2: (0.0000) | Acc: (86.00%) (40031/46208)
Epoch: 57 | Batch_idx: 370 |  Loss: (0.3878) |  Loss2: (0.0000) | Acc: (86.00%) (41132/47488)
Epoch: 57 | Batch_idx: 380 |  Loss: (0.3877) |  Loss2: (0.0000) | Acc: (86.00%) (42248/48768)
Epoch: 57 | Batch_idx: 390 |  Loss: (0.3872) |  Loss2: (0.0000) | Acc: (86.00%) (43324/50000)
# TEST : Loss: (0.6045) | Acc: (80.00%) (8018/10000)
percent tensor([0.5253, 0.5295, 0.5384, 0.5404, 0.5388, 0.5385, 0.5313, 0.5374, 0.5241,
        0.5282, 0.5227, 0.5316, 0.5240, 0.5240, 0.5354, 0.5298],
       device='cuda:0') torch.Size([16])
percent tensor([0.5594, 0.5672, 0.5530, 0.5460, 0.5582, 0.5666, 0.5684, 0.5540, 0.5553,
        0.5607, 0.5640, 0.5634, 0.5579, 0.5584, 0.5700, 0.5630],
       device='cuda:0') torch.Size([16])
percent tensor([0.5687, 0.5874, 0.5482, 0.5371, 0.5481, 0.5339, 0.5794, 0.5534, 0.5592,
        0.5823, 0.5770, 0.5715, 0.5823, 0.5787, 0.5729, 0.5731],
       device='cuda:0') torch.Size([16])
percent tensor([0.6054, 0.6108, 0.5865, 0.5863, 0.5919, 0.6017, 0.6122, 0.5929, 0.6037,
        0.6135, 0.6130, 0.6038, 0.6063, 0.6142, 0.6136, 0.6065],
       device='cuda:0') torch.Size([16])
percent tensor([0.4516, 0.4717, 0.5107, 0.5174, 0.5206, 0.4809, 0.4732, 0.5099, 0.4970,
        0.4707, 0.4691, 0.4738, 0.4356, 0.5080, 0.4762, 0.4518],
       device='cuda:0') torch.Size([16])
percent tensor([0.4686, 0.4799, 0.5298, 0.5403, 0.5703, 0.5446, 0.5106, 0.5104, 0.5357,
        0.4650, 0.5145, 0.5280, 0.4526, 0.5492, 0.4765, 0.4782],
       device='cuda:0') torch.Size([16])
percent tensor([0.5784, 0.5617, 0.6359, 0.6286, 0.6507, 0.6152, 0.5975, 0.6091, 0.6057,
        0.5842, 0.5727, 0.6063, 0.5635, 0.6258, 0.5531, 0.5650],
       device='cuda:0') torch.Size([16])
percent tensor([0.9985, 0.9977, 0.9986, 0.9982, 0.9994, 0.9972, 0.9989, 0.9996, 0.9990,
        0.9991, 0.9985, 0.9992, 0.9987, 0.9988, 0.9985, 0.9983],
       device='cuda:0') torch.Size([16])
Epoch: 58 | Batch_idx: 0 |  Loss: (0.2818) |  Loss2: (0.0000) | Acc: (89.00%) (114/128)
Epoch: 58 | Batch_idx: 10 |  Loss: (0.3411) |  Loss2: (0.0000) | Acc: (88.00%) (1240/1408)
Epoch: 58 | Batch_idx: 20 |  Loss: (0.3538) |  Loss2: (0.0000) | Acc: (87.00%) (2348/2688)
Epoch: 58 | Batch_idx: 30 |  Loss: (0.3527) |  Loss2: (0.0000) | Acc: (87.00%) (3477/3968)
Epoch: 58 | Batch_idx: 40 |  Loss: (0.3577) |  Loss2: (0.0000) | Acc: (87.00%) (4594/5248)
Epoch: 58 | Batch_idx: 50 |  Loss: (0.3623) |  Loss2: (0.0000) | Acc: (87.00%) (5707/6528)
Epoch: 58 | Batch_idx: 60 |  Loss: (0.3638) |  Loss2: (0.0000) | Acc: (87.00%) (6823/7808)
Epoch: 58 | Batch_idx: 70 |  Loss: (0.3660) |  Loss2: (0.0000) | Acc: (87.00%) (7925/9088)
Epoch: 58 | Batch_idx: 80 |  Loss: (0.3687) |  Loss2: (0.0000) | Acc: (87.00%) (9045/10368)
Epoch: 58 | Batch_idx: 90 |  Loss: (0.3685) |  Loss2: (0.0000) | Acc: (87.00%) (10162/11648)
Epoch: 58 | Batch_idx: 100 |  Loss: (0.3711) |  Loss2: (0.0000) | Acc: (87.00%) (11276/12928)
Epoch: 58 | Batch_idx: 110 |  Loss: (0.3701) |  Loss2: (0.0000) | Acc: (87.00%) (12389/14208)
Epoch: 58 | Batch_idx: 120 |  Loss: (0.3693) |  Loss2: (0.0000) | Acc: (87.00%) (13511/15488)
Epoch: 58 | Batch_idx: 130 |  Loss: (0.3711) |  Loss2: (0.0000) | Acc: (87.00%) (14614/16768)
Epoch: 58 | Batch_idx: 140 |  Loss: (0.3736) |  Loss2: (0.0000) | Acc: (87.00%) (15713/18048)
Epoch: 58 | Batch_idx: 150 |  Loss: (0.3724) |  Loss2: (0.0000) | Acc: (87.00%) (16841/19328)
Epoch: 58 | Batch_idx: 160 |  Loss: (0.3705) |  Loss2: (0.0000) | Acc: (87.00%) (17973/20608)
Epoch: 58 | Batch_idx: 170 |  Loss: (0.3709) |  Loss2: (0.0000) | Acc: (87.00%) (19104/21888)
Epoch: 58 | Batch_idx: 180 |  Loss: (0.3705) |  Loss2: (0.0000) | Acc: (87.00%) (20215/23168)
Epoch: 58 | Batch_idx: 190 |  Loss: (0.3702) |  Loss2: (0.0000) | Acc: (87.00%) (21336/24448)
Epoch: 58 | Batch_idx: 200 |  Loss: (0.3698) |  Loss2: (0.0000) | Acc: (87.00%) (22458/25728)
Epoch: 58 | Batch_idx: 210 |  Loss: (0.3693) |  Loss2: (0.0000) | Acc: (87.00%) (23581/27008)
Epoch: 58 | Batch_idx: 220 |  Loss: (0.3688) |  Loss2: (0.0000) | Acc: (87.00%) (24704/28288)
Epoch: 58 | Batch_idx: 230 |  Loss: (0.3705) |  Loss2: (0.0000) | Acc: (87.00%) (25805/29568)
Epoch: 58 | Batch_idx: 240 |  Loss: (0.3707) |  Loss2: (0.0000) | Acc: (87.00%) (26916/30848)
Epoch: 58 | Batch_idx: 250 |  Loss: (0.3693) |  Loss2: (0.0000) | Acc: (87.00%) (28057/32128)
Epoch: 58 | Batch_idx: 260 |  Loss: (0.3693) |  Loss2: (0.0000) | Acc: (87.00%) (29164/33408)
Epoch: 58 | Batch_idx: 270 |  Loss: (0.3685) |  Loss2: (0.0000) | Acc: (87.00%) (30299/34688)
Epoch: 58 | Batch_idx: 280 |  Loss: (0.3683) |  Loss2: (0.0000) | Acc: (87.00%) (31432/35968)
Epoch: 58 | Batch_idx: 290 |  Loss: (0.3693) |  Loss2: (0.0000) | Acc: (87.00%) (32541/37248)
Epoch: 58 | Batch_idx: 300 |  Loss: (0.3700) |  Loss2: (0.0000) | Acc: (87.00%) (33640/38528)
Epoch: 58 | Batch_idx: 310 |  Loss: (0.3705) |  Loss2: (0.0000) | Acc: (87.00%) (34743/39808)
Epoch: 58 | Batch_idx: 320 |  Loss: (0.3702) |  Loss2: (0.0000) | Acc: (87.00%) (35859/41088)
Epoch: 58 | Batch_idx: 330 |  Loss: (0.3696) |  Loss2: (0.0000) | Acc: (87.00%) (36994/42368)
Epoch: 58 | Batch_idx: 340 |  Loss: (0.3694) |  Loss2: (0.0000) | Acc: (87.00%) (38112/43648)
Epoch: 58 | Batch_idx: 350 |  Loss: (0.3689) |  Loss2: (0.0000) | Acc: (87.00%) (39234/44928)
Epoch: 58 | Batch_idx: 360 |  Loss: (0.3703) |  Loss2: (0.0000) | Acc: (87.00%) (40326/46208)
Epoch: 58 | Batch_idx: 370 |  Loss: (0.3704) |  Loss2: (0.0000) | Acc: (87.00%) (41448/47488)
Epoch: 58 | Batch_idx: 380 |  Loss: (0.3708) |  Loss2: (0.0000) | Acc: (87.00%) (42562/48768)
Epoch: 58 | Batch_idx: 390 |  Loss: (0.3705) |  Loss2: (0.0000) | Acc: (87.00%) (43625/50000)
# TEST : Loss: (0.5916) | Acc: (81.00%) (8128/10000)
percent tensor([0.5264, 0.5303, 0.5389, 0.5411, 0.5404, 0.5405, 0.5328, 0.5379, 0.5258,
        0.5294, 0.5241, 0.5332, 0.5254, 0.5256, 0.5364, 0.5313],
       device='cuda:0') torch.Size([16])
percent tensor([0.5577, 0.5646, 0.5521, 0.5471, 0.5586, 0.5664, 0.5665, 0.5526, 0.5519,
        0.5580, 0.5606, 0.5602, 0.5557, 0.5536, 0.5692, 0.5607],
       device='cuda:0') torch.Size([16])
percent tensor([0.5657, 0.5842, 0.5455, 0.5342, 0.5434, 0.5311, 0.5734, 0.5498, 0.5560,
        0.5771, 0.5731, 0.5655, 0.5770, 0.5753, 0.5696, 0.5680],
       device='cuda:0') torch.Size([16])
percent tensor([0.6030, 0.6076, 0.5878, 0.5863, 0.5914, 0.6020, 0.6089, 0.5923, 0.5997,
        0.6086, 0.6089, 0.6006, 0.6030, 0.6073, 0.6114, 0.6030],
       device='cuda:0') torch.Size([16])
percent tensor([0.4540, 0.4796, 0.5130, 0.5145, 0.5261, 0.4968, 0.4853, 0.5172, 0.5053,
        0.4684, 0.4734, 0.4689, 0.4319, 0.5116, 0.4854, 0.4652],
       device='cuda:0') torch.Size([16])
percent tensor([0.4716, 0.5033, 0.5227, 0.5419, 0.5575, 0.5501, 0.5236, 0.4984, 0.5529,
        0.4870, 0.5268, 0.5248, 0.4658, 0.5610, 0.4804, 0.4886],
       device='cuda:0') torch.Size([16])
percent tensor([0.5869, 0.5679, 0.6296, 0.6204, 0.6503, 0.6234, 0.6063, 0.5978, 0.6105,
        0.6007, 0.5789, 0.6022, 0.5648, 0.6307, 0.5558, 0.5828],
       device='cuda:0') torch.Size([16])
percent tensor([0.9984, 0.9970, 0.9989, 0.9988, 0.9995, 0.9978, 0.9992, 0.9998, 0.9981,
        0.9987, 0.9984, 0.9989, 0.9972, 0.9990, 0.9988, 0.9987],
       device='cuda:0') torch.Size([16])
Epoch: 59 | Batch_idx: 0 |  Loss: (0.3479) |  Loss2: (0.0000) | Acc: (86.00%) (111/128)
Epoch: 59 | Batch_idx: 10 |  Loss: (0.3671) |  Loss2: (0.0000) | Acc: (86.00%) (1222/1408)
Epoch: 59 | Batch_idx: 20 |  Loss: (0.3723) |  Loss2: (0.0000) | Acc: (86.00%) (2335/2688)
Epoch: 59 | Batch_idx: 30 |  Loss: (0.3744) |  Loss2: (0.0000) | Acc: (86.00%) (3439/3968)
Epoch: 59 | Batch_idx: 40 |  Loss: (0.3681) |  Loss2: (0.0000) | Acc: (87.00%) (4571/5248)
Epoch: 59 | Batch_idx: 50 |  Loss: (0.3716) |  Loss2: (0.0000) | Acc: (87.00%) (5686/6528)
Epoch: 59 | Batch_idx: 60 |  Loss: (0.3679) |  Loss2: (0.0000) | Acc: (87.00%) (6821/7808)
Epoch: 59 | Batch_idx: 70 |  Loss: (0.3642) |  Loss2: (0.0000) | Acc: (87.00%) (7961/9088)
Epoch: 59 | Batch_idx: 80 |  Loss: (0.3666) |  Loss2: (0.0000) | Acc: (87.00%) (9070/10368)
Epoch: 59 | Batch_idx: 90 |  Loss: (0.3677) |  Loss2: (0.0000) | Acc: (87.00%) (10190/11648)
Epoch: 59 | Batch_idx: 100 |  Loss: (0.3664) |  Loss2: (0.0000) | Acc: (87.00%) (11307/12928)
Epoch: 59 | Batch_idx: 110 |  Loss: (0.3705) |  Loss2: (0.0000) | Acc: (87.00%) (12395/14208)
Epoch: 59 | Batch_idx: 120 |  Loss: (0.3707) |  Loss2: (0.0000) | Acc: (87.00%) (13503/15488)
Epoch: 59 | Batch_idx: 130 |  Loss: (0.3737) |  Loss2: (0.0000) | Acc: (87.00%) (14599/16768)
Epoch: 59 | Batch_idx: 140 |  Loss: (0.3716) |  Loss2: (0.0000) | Acc: (87.00%) (15733/18048)
Epoch: 59 | Batch_idx: 150 |  Loss: (0.3714) |  Loss2: (0.0000) | Acc: (87.00%) (16849/19328)
Epoch: 59 | Batch_idx: 160 |  Loss: (0.3701) |  Loss2: (0.0000) | Acc: (87.00%) (17982/20608)
Epoch: 59 | Batch_idx: 170 |  Loss: (0.3696) |  Loss2: (0.0000) | Acc: (87.00%) (19106/21888)
Epoch: 59 | Batch_idx: 180 |  Loss: (0.3686) |  Loss2: (0.0000) | Acc: (87.00%) (20236/23168)
Epoch: 59 | Batch_idx: 190 |  Loss: (0.3672) |  Loss2: (0.0000) | Acc: (87.00%) (21372/24448)
Epoch: 59 | Batch_idx: 200 |  Loss: (0.3673) |  Loss2: (0.0000) | Acc: (87.00%) (22483/25728)
Epoch: 59 | Batch_idx: 210 |  Loss: (0.3669) |  Loss2: (0.0000) | Acc: (87.00%) (23605/27008)
Epoch: 59 | Batch_idx: 220 |  Loss: (0.3652) |  Loss2: (0.0000) | Acc: (87.00%) (24752/28288)
Epoch: 59 | Batch_idx: 230 |  Loss: (0.3653) |  Loss2: (0.0000) | Acc: (87.00%) (25875/29568)
Epoch: 59 | Batch_idx: 240 |  Loss: (0.3648) |  Loss2: (0.0000) | Acc: (87.00%) (26995/30848)
Epoch: 59 | Batch_idx: 250 |  Loss: (0.3664) |  Loss2: (0.0000) | Acc: (87.00%) (28089/32128)
Epoch: 59 | Batch_idx: 260 |  Loss: (0.3653) |  Loss2: (0.0000) | Acc: (87.00%) (29218/33408)
Epoch: 59 | Batch_idx: 270 |  Loss: (0.3662) |  Loss2: (0.0000) | Acc: (87.00%) (30323/34688)
Epoch: 59 | Batch_idx: 280 |  Loss: (0.3660) |  Loss2: (0.0000) | Acc: (87.00%) (31435/35968)
Epoch: 59 | Batch_idx: 290 |  Loss: (0.3655) |  Loss2: (0.0000) | Acc: (87.00%) (32568/37248)
Epoch: 59 | Batch_idx: 300 |  Loss: (0.3669) |  Loss2: (0.0000) | Acc: (87.00%) (33663/38528)
Epoch: 59 | Batch_idx: 310 |  Loss: (0.3674) |  Loss2: (0.0000) | Acc: (87.00%) (34781/39808)
Epoch: 59 | Batch_idx: 320 |  Loss: (0.3667) |  Loss2: (0.0000) | Acc: (87.00%) (35913/41088)
Epoch: 59 | Batch_idx: 330 |  Loss: (0.3665) |  Loss2: (0.0000) | Acc: (87.00%) (37031/42368)
Epoch: 59 | Batch_idx: 340 |  Loss: (0.3666) |  Loss2: (0.0000) | Acc: (87.00%) (38149/43648)
Epoch: 59 | Batch_idx: 350 |  Loss: (0.3662) |  Loss2: (0.0000) | Acc: (87.00%) (39274/44928)
Epoch: 59 | Batch_idx: 360 |  Loss: (0.3654) |  Loss2: (0.0000) | Acc: (87.00%) (40400/46208)
Epoch: 59 | Batch_idx: 370 |  Loss: (0.3650) |  Loss2: (0.0000) | Acc: (87.00%) (41517/47488)
Epoch: 59 | Batch_idx: 380 |  Loss: (0.3647) |  Loss2: (0.0000) | Acc: (87.00%) (42656/48768)
Epoch: 59 | Batch_idx: 390 |  Loss: (0.3645) |  Loss2: (0.0000) | Acc: (87.00%) (43741/50000)
# TEST : Loss: (0.4672) | Acc: (84.00%) (8460/10000)
percent tensor([0.5263, 0.5294, 0.5399, 0.5415, 0.5397, 0.5401, 0.5321, 0.5377, 0.5240,
        0.5287, 0.5231, 0.5331, 0.5246, 0.5242, 0.5360, 0.5302],
       device='cuda:0') torch.Size([16])
percent tensor([0.5580, 0.5677, 0.5519, 0.5455, 0.5567, 0.5665, 0.5692, 0.5537, 0.5539,
        0.5600, 0.5639, 0.5617, 0.5565, 0.5595, 0.5706, 0.5615],
       device='cuda:0') torch.Size([16])
percent tensor([0.5685, 0.5876, 0.5503, 0.5398, 0.5490, 0.5345, 0.5784, 0.5553, 0.5609,
        0.5831, 0.5758, 0.5719, 0.5808, 0.5833, 0.5725, 0.5729],
       device='cuda:0') torch.Size([16])
percent tensor([0.6060, 0.6117, 0.5864, 0.5877, 0.5902, 0.6041, 0.6129, 0.5930, 0.6025,
        0.6137, 0.6139, 0.6036, 0.6064, 0.6152, 0.6139, 0.6071],
       device='cuda:0') torch.Size([16])
percent tensor([0.4530, 0.4677, 0.5118, 0.5111, 0.5212, 0.5017, 0.4721, 0.5156, 0.4980,
        0.4552, 0.4707, 0.4627, 0.4297, 0.5008, 0.4861, 0.4654],
       device='cuda:0') torch.Size([16])
percent tensor([0.4671, 0.4900, 0.5295, 0.5561, 0.5624, 0.5488, 0.5219, 0.5084, 0.5431,
        0.4677, 0.5193, 0.5178, 0.4504, 0.5422, 0.4791, 0.4878],
       device='cuda:0') torch.Size([16])
percent tensor([0.5861, 0.5668, 0.6427, 0.6327, 0.6594, 0.6287, 0.6115, 0.6084, 0.6141,
        0.5884, 0.5744, 0.5987, 0.5720, 0.6156, 0.5575, 0.5892],
       device='cuda:0') torch.Size([16])
percent tensor([0.9988, 0.9962, 0.9987, 0.9981, 0.9995, 0.9982, 0.9989, 0.9997, 0.9986,
        0.9985, 0.9982, 0.9985, 0.9976, 0.9983, 0.9990, 0.9990],
       device='cuda:0') torch.Size([16])
Epoch: 60 | Batch_idx: 0 |  Loss: (0.2690) |  Loss2: (0.0000) | Acc: (90.00%) (116/128)
Epoch: 60 | Batch_idx: 10 |  Loss: (0.2918) |  Loss2: (0.0000) | Acc: (89.00%) (1265/1408)
Epoch: 60 | Batch_idx: 20 |  Loss: (0.3190) |  Loss2: (0.0000) | Acc: (88.00%) (2388/2688)
Epoch: 60 | Batch_idx: 30 |  Loss: (0.3306) |  Loss2: (0.0000) | Acc: (88.00%) (3505/3968)
Epoch: 60 | Batch_idx: 40 |  Loss: (0.3241) |  Loss2: (0.0000) | Acc: (88.00%) (4650/5248)
Epoch: 60 | Batch_idx: 50 |  Loss: (0.3354) |  Loss2: (0.0000) | Acc: (88.00%) (5747/6528)
Epoch: 60 | Batch_idx: 60 |  Loss: (0.3345) |  Loss2: (0.0000) | Acc: (87.00%) (6871/7808)
Epoch: 60 | Batch_idx: 70 |  Loss: (0.3379) |  Loss2: (0.0000) | Acc: (87.00%) (7983/9088)
Epoch: 60 | Batch_idx: 80 |  Loss: (0.3362) |  Loss2: (0.0000) | Acc: (88.00%) (9124/10368)
Epoch: 60 | Batch_idx: 90 |  Loss: (0.3394) |  Loss2: (0.0000) | Acc: (87.00%) (10248/11648)
Epoch: 60 | Batch_idx: 100 |  Loss: (0.3446) |  Loss2: (0.0000) | Acc: (87.00%) (11351/12928)
Epoch: 60 | Batch_idx: 110 |  Loss: (0.3456) |  Loss2: (0.0000) | Acc: (87.00%) (12470/14208)
Epoch: 60 | Batch_idx: 120 |  Loss: (0.3450) |  Loss2: (0.0000) | Acc: (87.00%) (13600/15488)
Epoch: 60 | Batch_idx: 130 |  Loss: (0.3444) |  Loss2: (0.0000) | Acc: (87.00%) (14723/16768)
Epoch: 60 | Batch_idx: 140 |  Loss: (0.3439) |  Loss2: (0.0000) | Acc: (87.00%) (15857/18048)
Epoch: 60 | Batch_idx: 150 |  Loss: (0.3438) |  Loss2: (0.0000) | Acc: (87.00%) (16991/19328)
Epoch: 60 | Batch_idx: 160 |  Loss: (0.3449) |  Loss2: (0.0000) | Acc: (87.00%) (18104/20608)
Epoch: 60 | Batch_idx: 170 |  Loss: (0.3471) |  Loss2: (0.0000) | Acc: (87.00%) (19213/21888)
Epoch: 60 | Batch_idx: 180 |  Loss: (0.3477) |  Loss2: (0.0000) | Acc: (87.00%) (20333/23168)
Epoch: 60 | Batch_idx: 190 |  Loss: (0.3502) |  Loss2: (0.0000) | Acc: (87.00%) (21449/24448)
Epoch: 60 | Batch_idx: 200 |  Loss: (0.3528) |  Loss2: (0.0000) | Acc: (87.00%) (22546/25728)
Epoch: 60 | Batch_idx: 210 |  Loss: (0.3537) |  Loss2: (0.0000) | Acc: (87.00%) (23672/27008)
Epoch: 60 | Batch_idx: 220 |  Loss: (0.3533) |  Loss2: (0.0000) | Acc: (87.00%) (24806/28288)
Epoch: 60 | Batch_idx: 230 |  Loss: (0.3529) |  Loss2: (0.0000) | Acc: (87.00%) (25933/29568)
Epoch: 60 | Batch_idx: 240 |  Loss: (0.3530) |  Loss2: (0.0000) | Acc: (87.00%) (27039/30848)
Epoch: 60 | Batch_idx: 250 |  Loss: (0.3526) |  Loss2: (0.0000) | Acc: (87.00%) (28184/32128)
Epoch: 60 | Batch_idx: 260 |  Loss: (0.3545) |  Loss2: (0.0000) | Acc: (87.00%) (29283/33408)
Epoch: 60 | Batch_idx: 270 |  Loss: (0.3542) |  Loss2: (0.0000) | Acc: (87.00%) (30413/34688)
Epoch: 60 | Batch_idx: 280 |  Loss: (0.3539) |  Loss2: (0.0000) | Acc: (87.00%) (31544/35968)
Epoch: 60 | Batch_idx: 290 |  Loss: (0.3539) |  Loss2: (0.0000) | Acc: (87.00%) (32667/37248)
Epoch: 60 | Batch_idx: 300 |  Loss: (0.3534) |  Loss2: (0.0000) | Acc: (87.00%) (33794/38528)
Epoch: 60 | Batch_idx: 310 |  Loss: (0.3523) |  Loss2: (0.0000) | Acc: (87.00%) (34925/39808)
Epoch: 60 | Batch_idx: 320 |  Loss: (0.3513) |  Loss2: (0.0000) | Acc: (87.00%) (36069/41088)
Epoch: 60 | Batch_idx: 330 |  Loss: (0.3512) |  Loss2: (0.0000) | Acc: (87.00%) (37184/42368)
Epoch: 60 | Batch_idx: 340 |  Loss: (0.3513) |  Loss2: (0.0000) | Acc: (87.00%) (38306/43648)
Epoch: 60 | Batch_idx: 350 |  Loss: (0.3512) |  Loss2: (0.0000) | Acc: (87.00%) (39444/44928)
Epoch: 60 | Batch_idx: 360 |  Loss: (0.3507) |  Loss2: (0.0000) | Acc: (87.00%) (40575/46208)
Epoch: 60 | Batch_idx: 370 |  Loss: (0.3509) |  Loss2: (0.0000) | Acc: (87.00%) (41703/47488)
Epoch: 60 | Batch_idx: 380 |  Loss: (0.3515) |  Loss2: (0.0000) | Acc: (87.00%) (42815/48768)
Epoch: 60 | Batch_idx: 390 |  Loss: (0.3521) |  Loss2: (0.0000) | Acc: (87.00%) (43892/50000)
=> saving checkpoint 'drive/app/torch/save_Schedule/checkpoint_060.pth.tar'
# TEST : Loss: (0.4864) | Acc: (84.00%) (8431/10000)
percent tensor([0.5265, 0.5302, 0.5398, 0.5413, 0.5403, 0.5402, 0.5333, 0.5375, 0.5263,
        0.5294, 0.5243, 0.5337, 0.5256, 0.5265, 0.5362, 0.5308],
       device='cuda:0') torch.Size([16])
percent tensor([0.5581, 0.5639, 0.5516, 0.5462, 0.5560, 0.5654, 0.5656, 0.5541, 0.5525,
        0.5578, 0.5613, 0.5606, 0.5566, 0.5535, 0.5687, 0.5606],
       device='cuda:0') torch.Size([16])
percent tensor([0.5706, 0.5847, 0.5473, 0.5341, 0.5486, 0.5328, 0.5762, 0.5510, 0.5606,
        0.5799, 0.5780, 0.5704, 0.5837, 0.5784, 0.5700, 0.5704],
       device='cuda:0') torch.Size([16])
percent tensor([0.6060, 0.6072, 0.5869, 0.5880, 0.5896, 0.6027, 0.6104, 0.5924, 0.6033,
        0.6128, 0.6123, 0.6043, 0.6078, 0.6104, 0.6115, 0.6055],
       device='cuda:0') torch.Size([16])
percent tensor([0.4484, 0.4828, 0.5086, 0.5187, 0.5224, 0.5041, 0.4883, 0.5080, 0.5004,
        0.4713, 0.4746, 0.4733, 0.4248, 0.5225, 0.4979, 0.4731],
       device='cuda:0') torch.Size([16])
percent tensor([0.4701, 0.4954, 0.5310, 0.5419, 0.5637, 0.5473, 0.5178, 0.5110, 0.5405,
        0.4705, 0.5139, 0.5250, 0.4583, 0.5428, 0.4711, 0.4904],
       device='cuda:0') torch.Size([16])
percent tensor([0.5816, 0.5706, 0.6414, 0.6223, 0.6608, 0.6233, 0.6066, 0.6105, 0.6063,
        0.5890, 0.5661, 0.5966, 0.5619, 0.6218, 0.5544, 0.5845],
       device='cuda:0') torch.Size([16])
percent tensor([0.9988, 0.9961, 0.9980, 0.9983, 0.9993, 0.9977, 0.9992, 0.9997, 0.9983,
        0.9982, 0.9982, 0.9983, 0.9977, 0.9982, 0.9986, 0.9989],
       device='cuda:0') torch.Size([16])
Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 3, 3, 3]) tensor(180.2442, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(796.7375, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(809.7769, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([128, 64, 3, 3]) tensor(1534.3069, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([128, 64, 1, 1]) tensor(506.2375, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([128, 128, 3, 3]) tensor(2211.4358, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([256, 128, 3, 3]) tensor(4295.0654, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([256, 128, 1, 1]) tensor(1409.4423, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([256, 256, 3, 3]) tensor(6100.6753, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([512, 256, 3, 3]) tensor(12015.6729, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([512, 256, 1, 1]) tensor(4000.8066, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([512, 512, 3, 3]) tensor(16912.3594, device='cuda:0', grad_fn=<NormBackward0>)
Epoch: 61 | Batch_idx: 0 |  Loss: (0.2401) |  Loss2: (0.0000) | Acc: (91.00%) (117/128)
Epoch: 61 | Batch_idx: 10 |  Loss: (0.3444) |  Loss2: (0.0000) | Acc: (88.00%) (1242/1408)
Epoch: 61 | Batch_idx: 20 |  Loss: (0.3429) |  Loss2: (0.0000) | Acc: (88.00%) (2375/2688)
Epoch: 61 | Batch_idx: 30 |  Loss: (0.3493) |  Loss2: (0.0000) | Acc: (88.00%) (3496/3968)
Epoch: 61 | Batch_idx: 40 |  Loss: (0.3487) |  Loss2: (0.0000) | Acc: (88.00%) (4626/5248)
Epoch: 61 | Batch_idx: 50 |  Loss: (0.3386) |  Loss2: (0.0000) | Acc: (88.00%) (5781/6528)
Epoch: 61 | Batch_idx: 60 |  Loss: (0.3422) |  Loss2: (0.0000) | Acc: (88.00%) (6902/7808)
Epoch: 61 | Batch_idx: 70 |  Loss: (0.3410) |  Loss2: (0.0000) | Acc: (88.00%) (8032/9088)
Epoch: 61 | Batch_idx: 80 |  Loss: (0.3398) |  Loss2: (0.0000) | Acc: (88.00%) (9157/10368)
Epoch: 61 | Batch_idx: 90 |  Loss: (0.3447) |  Loss2: (0.0000) | Acc: (88.00%) (10273/11648)
Epoch: 61 | Batch_idx: 100 |  Loss: (0.3459) |  Loss2: (0.0000) | Acc: (88.00%) (11397/12928)
Epoch: 61 | Batch_idx: 110 |  Loss: (0.3434) |  Loss2: (0.0000) | Acc: (88.00%) (12526/14208)
Epoch: 61 | Batch_idx: 120 |  Loss: (0.3440) |  Loss2: (0.0000) | Acc: (88.00%) (13644/15488)
Epoch: 61 | Batch_idx: 130 |  Loss: (0.3440) |  Loss2: (0.0000) | Acc: (88.00%) (14789/16768)
Epoch: 61 | Batch_idx: 140 |  Loss: (0.3445) |  Loss2: (0.0000) | Acc: (88.00%) (15913/18048)
Epoch: 61 | Batch_idx: 150 |  Loss: (0.3441) |  Loss2: (0.0000) | Acc: (88.00%) (17036/19328)
Epoch: 61 | Batch_idx: 160 |  Loss: (0.3441) |  Loss2: (0.0000) | Acc: (88.00%) (18183/20608)
Epoch: 61 | Batch_idx: 170 |  Loss: (0.3451) |  Loss2: (0.0000) | Acc: (88.00%) (19310/21888)
Epoch: 61 | Batch_idx: 180 |  Loss: (0.3439) |  Loss2: (0.0000) | Acc: (88.00%) (20460/23168)
Epoch: 61 | Batch_idx: 190 |  Loss: (0.3456) |  Loss2: (0.0000) | Acc: (88.00%) (21578/24448)
Epoch: 61 | Batch_idx: 200 |  Loss: (0.3458) |  Loss2: (0.0000) | Acc: (88.00%) (22697/25728)
Epoch: 61 | Batch_idx: 210 |  Loss: (0.3455) |  Loss2: (0.0000) | Acc: (88.00%) (23825/27008)
Epoch: 61 | Batch_idx: 220 |  Loss: (0.3462) |  Loss2: (0.0000) | Acc: (88.00%) (24946/28288)
Epoch: 61 | Batch_idx: 230 |  Loss: (0.3454) |  Loss2: (0.0000) | Acc: (88.00%) (26083/29568)
Epoch: 61 | Batch_idx: 240 |  Loss: (0.3453) |  Loss2: (0.0000) | Acc: (88.00%) (27196/30848)
Epoch: 61 | Batch_idx: 250 |  Loss: (0.3461) |  Loss2: (0.0000) | Acc: (88.00%) (28297/32128)
Epoch: 61 | Batch_idx: 260 |  Loss: (0.3476) |  Loss2: (0.0000) | Acc: (87.00%) (29398/33408)
Epoch: 61 | Batch_idx: 270 |  Loss: (0.3486) |  Loss2: (0.0000) | Acc: (87.00%) (30518/34688)
Epoch: 61 | Batch_idx: 280 |  Loss: (0.3493) |  Loss2: (0.0000) | Acc: (87.00%) (31634/35968)
Epoch: 61 | Batch_idx: 290 |  Loss: (0.3489) |  Loss2: (0.0000) | Acc: (87.00%) (32769/37248)
Epoch: 61 | Batch_idx: 300 |  Loss: (0.3500) |  Loss2: (0.0000) | Acc: (87.00%) (33888/38528)
Epoch: 61 | Batch_idx: 310 |  Loss: (0.3504) |  Loss2: (0.0000) | Acc: (87.00%) (34991/39808)
Epoch: 61 | Batch_idx: 320 |  Loss: (0.3504) |  Loss2: (0.0000) | Acc: (87.00%) (36117/41088)
Epoch: 61 | Batch_idx: 330 |  Loss: (0.3500) |  Loss2: (0.0000) | Acc: (87.00%) (37243/42368)
Epoch: 61 | Batch_idx: 340 |  Loss: (0.3496) |  Loss2: (0.0000) | Acc: (87.00%) (38368/43648)
Epoch: 61 | Batch_idx: 350 |  Loss: (0.3491) |  Loss2: (0.0000) | Acc: (87.00%) (39503/44928)
Epoch: 61 | Batch_idx: 360 |  Loss: (0.3492) |  Loss2: (0.0000) | Acc: (87.00%) (40632/46208)
Epoch: 61 | Batch_idx: 370 |  Loss: (0.3491) |  Loss2: (0.0000) | Acc: (87.00%) (41757/47488)
Epoch: 61 | Batch_idx: 380 |  Loss: (0.3485) |  Loss2: (0.0000) | Acc: (87.00%) (42902/48768)
Epoch: 61 | Batch_idx: 390 |  Loss: (0.3474) |  Loss2: (0.0000) | Acc: (87.00%) (43996/50000)
# TEST : Loss: (0.4841) | Acc: (84.00%) (8413/10000)
percent tensor([0.5255, 0.5310, 0.5376, 0.5411, 0.5390, 0.5391, 0.5329, 0.5368, 0.5251,
        0.5290, 0.5236, 0.5326, 0.5246, 0.5272, 0.5364, 0.5306],
       device='cuda:0') torch.Size([16])
percent tensor([0.5590, 0.5649, 0.5535, 0.5467, 0.5577, 0.5644, 0.5665, 0.5552, 0.5531,
        0.5584, 0.5616, 0.5617, 0.5573, 0.5550, 0.5694, 0.5615],
       device='cuda:0') torch.Size([16])
percent tensor([0.5672, 0.5852, 0.5455, 0.5371, 0.5471, 0.5337, 0.5763, 0.5521, 0.5589,
        0.5791, 0.5733, 0.5679, 0.5812, 0.5787, 0.5703, 0.5697],
       device='cuda:0') torch.Size([16])
percent tensor([0.6046, 0.6054, 0.5886, 0.5862, 0.5900, 0.6020, 0.6080, 0.5907, 0.6013,
        0.6120, 0.6112, 0.6034, 0.6066, 0.6075, 0.6113, 0.6033],
       device='cuda:0') torch.Size([16])
percent tensor([0.4571, 0.4673, 0.5158, 0.5183, 0.5276, 0.4934, 0.4867, 0.5174, 0.4988,
        0.4613, 0.4644, 0.4742, 0.4218, 0.5124, 0.4810, 0.4729],
       device='cuda:0') torch.Size([16])
percent tensor([0.4606, 0.4893, 0.5183, 0.5362, 0.5539, 0.5364, 0.5161, 0.5040, 0.5307,
        0.4736, 0.5153, 0.5296, 0.4588, 0.5382, 0.4700, 0.4975],
       device='cuda:0') torch.Size([16])
percent tensor([0.5830, 0.5652, 0.6267, 0.6233, 0.6548, 0.6197, 0.6031, 0.6110, 0.6115,
        0.5880, 0.5692, 0.6032, 0.5641, 0.6214, 0.5541, 0.5873],
       device='cuda:0') torch.Size([16])
percent tensor([0.9986, 0.9969, 0.9986, 0.9983, 0.9997, 0.9973, 0.9990, 0.9998, 0.9991,
        0.9989, 0.9982, 0.9986, 0.9976, 0.9987, 0.9985, 0.9984],
       device='cuda:0') torch.Size([16])
Epoch: 62 | Batch_idx: 0 |  Loss: (0.4239) |  Loss2: (0.0000) | Acc: (88.00%) (113/128)
Epoch: 62 | Batch_idx: 10 |  Loss: (0.3615) |  Loss2: (0.0000) | Acc: (88.00%) (1241/1408)
Epoch: 62 | Batch_idx: 20 |  Loss: (0.3351) |  Loss2: (0.0000) | Acc: (88.00%) (2392/2688)
Epoch: 62 | Batch_idx: 30 |  Loss: (0.3245) |  Loss2: (0.0000) | Acc: (89.00%) (3539/3968)
Epoch: 62 | Batch_idx: 40 |  Loss: (0.3217) |  Loss2: (0.0000) | Acc: (89.00%) (4685/5248)
Epoch: 62 | Batch_idx: 50 |  Loss: (0.3251) |  Loss2: (0.0000) | Acc: (89.00%) (5811/6528)
Epoch: 62 | Batch_idx: 60 |  Loss: (0.3163) |  Loss2: (0.0000) | Acc: (89.00%) (6966/7808)
Epoch: 62 | Batch_idx: 70 |  Loss: (0.3204) |  Loss2: (0.0000) | Acc: (88.00%) (8087/9088)
Epoch: 62 | Batch_idx: 80 |  Loss: (0.3202) |  Loss2: (0.0000) | Acc: (88.00%) (9227/10368)
Epoch: 62 | Batch_idx: 90 |  Loss: (0.3214) |  Loss2: (0.0000) | Acc: (88.00%) (10353/11648)
Epoch: 62 | Batch_idx: 100 |  Loss: (0.3229) |  Loss2: (0.0000) | Acc: (88.00%) (11481/12928)
Epoch: 62 | Batch_idx: 110 |  Loss: (0.3242) |  Loss2: (0.0000) | Acc: (88.00%) (12607/14208)
Epoch: 62 | Batch_idx: 120 |  Loss: (0.3261) |  Loss2: (0.0000) | Acc: (88.00%) (13741/15488)
Epoch: 62 | Batch_idx: 130 |  Loss: (0.3299) |  Loss2: (0.0000) | Acc: (88.00%) (14854/16768)
Epoch: 62 | Batch_idx: 140 |  Loss: (0.3293) |  Loss2: (0.0000) | Acc: (88.00%) (16001/18048)
Epoch: 62 | Batch_idx: 150 |  Loss: (0.3308) |  Loss2: (0.0000) | Acc: (88.00%) (17119/19328)
Epoch: 62 | Batch_idx: 160 |  Loss: (0.3312) |  Loss2: (0.0000) | Acc: (88.00%) (18251/20608)
Epoch: 62 | Batch_idx: 170 |  Loss: (0.3324) |  Loss2: (0.0000) | Acc: (88.00%) (19372/21888)
Epoch: 62 | Batch_idx: 180 |  Loss: (0.3317) |  Loss2: (0.0000) | Acc: (88.00%) (20509/23168)
Epoch: 62 | Batch_idx: 190 |  Loss: (0.3317) |  Loss2: (0.0000) | Acc: (88.00%) (21648/24448)
Epoch: 62 | Batch_idx: 200 |  Loss: (0.3327) |  Loss2: (0.0000) | Acc: (88.00%) (22760/25728)
Epoch: 62 | Batch_idx: 210 |  Loss: (0.3354) |  Loss2: (0.0000) | Acc: (88.00%) (23876/27008)
Epoch: 62 | Batch_idx: 220 |  Loss: (0.3368) |  Loss2: (0.0000) | Acc: (88.00%) (24987/28288)
Epoch: 62 | Batch_idx: 230 |  Loss: (0.3379) |  Loss2: (0.0000) | Acc: (88.00%) (26115/29568)
Epoch: 62 | Batch_idx: 240 |  Loss: (0.3391) |  Loss2: (0.0000) | Acc: (88.00%) (27232/30848)
Epoch: 62 | Batch_idx: 250 |  Loss: (0.3387) |  Loss2: (0.0000) | Acc: (88.00%) (28369/32128)
Epoch: 62 | Batch_idx: 260 |  Loss: (0.3377) |  Loss2: (0.0000) | Acc: (88.00%) (29512/33408)
Epoch: 62 | Batch_idx: 270 |  Loss: (0.3364) |  Loss2: (0.0000) | Acc: (88.00%) (30660/34688)
Epoch: 62 | Batch_idx: 280 |  Loss: (0.3356) |  Loss2: (0.0000) | Acc: (88.00%) (31810/35968)
Epoch: 62 | Batch_idx: 290 |  Loss: (0.3357) |  Loss2: (0.0000) | Acc: (88.00%) (32937/37248)
Epoch: 62 | Batch_idx: 300 |  Loss: (0.3359) |  Loss2: (0.0000) | Acc: (88.00%) (34065/38528)
Epoch: 62 | Batch_idx: 310 |  Loss: (0.3359) |  Loss2: (0.0000) | Acc: (88.00%) (35192/39808)
Epoch: 62 | Batch_idx: 320 |  Loss: (0.3358) |  Loss2: (0.0000) | Acc: (88.00%) (36342/41088)
Epoch: 62 | Batch_idx: 330 |  Loss: (0.3338) |  Loss2: (0.0000) | Acc: (88.00%) (37503/42368)
Epoch: 62 | Batch_idx: 340 |  Loss: (0.3349) |  Loss2: (0.0000) | Acc: (88.00%) (38610/43648)
Epoch: 62 | Batch_idx: 350 |  Loss: (0.3347) |  Loss2: (0.0000) | Acc: (88.00%) (39749/44928)
Epoch: 62 | Batch_idx: 360 |  Loss: (0.3352) |  Loss2: (0.0000) | Acc: (88.00%) (40875/46208)
Epoch: 62 | Batch_idx: 370 |  Loss: (0.3351) |  Loss2: (0.0000) | Acc: (88.00%) (42016/47488)
Epoch: 62 | Batch_idx: 380 |  Loss: (0.3355) |  Loss2: (0.0000) | Acc: (88.00%) (43138/48768)
Epoch: 62 | Batch_idx: 390 |  Loss: (0.3353) |  Loss2: (0.0000) | Acc: (88.00%) (44229/50000)
# TEST : Loss: (0.4849) | Acc: (84.00%) (8416/10000)
percent tensor([0.5263, 0.5301, 0.5393, 0.5417, 0.5401, 0.5405, 0.5328, 0.5378, 0.5248,
        0.5290, 0.5234, 0.5334, 0.5251, 0.5251, 0.5365, 0.5311],
       device='cuda:0') torch.Size([16])
percent tensor([0.5568, 0.5639, 0.5518, 0.5461, 0.5571, 0.5651, 0.5659, 0.5539, 0.5521,
        0.5575, 0.5595, 0.5605, 0.5558, 0.5538, 0.5677, 0.5604],
       device='cuda:0') torch.Size([16])
percent tensor([0.5651, 0.5822, 0.5433, 0.5321, 0.5429, 0.5302, 0.5747, 0.5511, 0.5587,
        0.5753, 0.5720, 0.5649, 0.5776, 0.5771, 0.5674, 0.5667],
       device='cuda:0') torch.Size([16])
percent tensor([0.6030, 0.6083, 0.5872, 0.5891, 0.5910, 0.6030, 0.6099, 0.5920, 0.6011,
        0.6118, 0.6106, 0.6009, 0.6040, 0.6109, 0.6116, 0.6034],
       device='cuda:0') torch.Size([16])
percent tensor([0.4651, 0.4780, 0.5207, 0.5156, 0.5299, 0.4971, 0.4864, 0.5201, 0.5010,
        0.4751, 0.4783, 0.4769, 0.4314, 0.5062, 0.4897, 0.4772],
       device='cuda:0') torch.Size([16])
percent tensor([0.4613, 0.4995, 0.5413, 0.5497, 0.5652, 0.5311, 0.5162, 0.5220, 0.5379,
        0.4829, 0.5178, 0.5315, 0.4730, 0.5446, 0.4743, 0.4894],
       device='cuda:0') torch.Size([16])
percent tensor([0.5919, 0.5716, 0.6401, 0.6214, 0.6548, 0.6126, 0.6103, 0.6162, 0.6064,
        0.5934, 0.5764, 0.6020, 0.5733, 0.6249, 0.5585, 0.5868],
       device='cuda:0') torch.Size([16])
percent tensor([0.9985, 0.9964, 0.9983, 0.9981, 0.9994, 0.9977, 0.9991, 0.9996, 0.9988,
        0.9979, 0.9982, 0.9984, 0.9979, 0.9983, 0.9987, 0.9988],
       device='cuda:0') torch.Size([16])
False Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=128, out_features=16, bias=False)
True Linear(in_features=16, out_features=2, bias=False)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=128, out_features=16, bias=False)
True Linear(in_features=16, out_features=2, bias=False)
False Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=256, out_features=32, bias=False)
True Linear(in_features=32, out_features=2, bias=False)
False Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=256, out_features=32, bias=False)
True Linear(in_features=32, out_features=2, bias=False)
False Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=512, out_features=64, bias=False)
True Linear(in_features=64, out_features=2, bias=False)
False Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=512, out_features=64, bias=False)
True Linear(in_features=64, out_features=2, bias=False)
False Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1024, out_features=128, bias=False)
True Linear(in_features=128, out_features=2, bias=False)
False Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1024, out_features=128, bias=False)
True Linear(in_features=128, out_features=2, bias=False)
False Linear(in_features=512, out_features=10, bias=True)
Epoch: 63 | Batch_idx: 0 |  Loss: (0.2403) |  Loss2: (0.0000) | Acc: (92.00%) (118/128)
Epoch: 63 | Batch_idx: 10 |  Loss: (0.3228) |  Loss2: (0.0000) | Acc: (89.00%) (1255/1408)
Epoch: 63 | Batch_idx: 20 |  Loss: (0.3699) |  Loss2: (0.0000) | Acc: (87.00%) (2349/2688)
Epoch: 63 | Batch_idx: 30 |  Loss: (0.3811) |  Loss2: (0.0000) | Acc: (86.00%) (3437/3968)
Epoch: 63 | Batch_idx: 40 |  Loss: (0.3963) |  Loss2: (0.0000) | Acc: (86.00%) (4518/5248)
Epoch: 63 | Batch_idx: 50 |  Loss: (0.4029) |  Loss2: (0.0000) | Acc: (85.00%) (5612/6528)
Epoch: 63 | Batch_idx: 60 |  Loss: (0.4113) |  Loss2: (0.0000) | Acc: (85.00%) (6689/7808)
Epoch: 63 | Batch_idx: 70 |  Loss: (0.4126) |  Loss2: (0.0000) | Acc: (85.00%) (7795/9088)
Epoch: 63 | Batch_idx: 80 |  Loss: (0.4072) |  Loss2: (0.0000) | Acc: (86.00%) (8919/10368)
Epoch: 63 | Batch_idx: 90 |  Loss: (0.4074) |  Loss2: (0.0000) | Acc: (85.00%) (10016/11648)
Epoch: 63 | Batch_idx: 100 |  Loss: (0.4150) |  Loss2: (0.0000) | Acc: (85.00%) (11077/12928)
Epoch: 63 | Batch_idx: 110 |  Loss: (0.4131) |  Loss2: (0.0000) | Acc: (85.00%) (12173/14208)
Epoch: 63 | Batch_idx: 120 |  Loss: (0.4121) |  Loss2: (0.0000) | Acc: (85.00%) (13267/15488)
Epoch: 63 | Batch_idx: 130 |  Loss: (0.4142) |  Loss2: (0.0000) | Acc: (85.00%) (14365/16768)
Epoch: 63 | Batch_idx: 140 |  Loss: (0.4136) |  Loss2: (0.0000) | Acc: (85.00%) (15469/18048)
Epoch: 63 | Batch_idx: 150 |  Loss: (0.4124) |  Loss2: (0.0000) | Acc: (85.00%) (16575/19328)
Epoch: 63 | Batch_idx: 160 |  Loss: (0.4128) |  Loss2: (0.0000) | Acc: (85.00%) (17683/20608)
Epoch: 63 | Batch_idx: 170 |  Loss: (0.4138) |  Loss2: (0.0000) | Acc: (85.00%) (18772/21888)
Epoch: 63 | Batch_idx: 180 |  Loss: (0.4095) |  Loss2: (0.0000) | Acc: (85.00%) (19902/23168)
Epoch: 63 | Batch_idx: 190 |  Loss: (0.4083) |  Loss2: (0.0000) | Acc: (85.00%) (21009/24448)
Epoch: 63 | Batch_idx: 200 |  Loss: (0.4078) |  Loss2: (0.0000) | Acc: (85.00%) (22118/25728)
Epoch: 63 | Batch_idx: 210 |  Loss: (0.4089) |  Loss2: (0.0000) | Acc: (85.00%) (23198/27008)
Epoch: 63 | Batch_idx: 220 |  Loss: (0.4090) |  Loss2: (0.0000) | Acc: (85.00%) (24297/28288)
Epoch: 63 | Batch_idx: 230 |  Loss: (0.4087) |  Loss2: (0.0000) | Acc: (85.00%) (25399/29568)
Epoch: 63 | Batch_idx: 240 |  Loss: (0.4070) |  Loss2: (0.0000) | Acc: (85.00%) (26517/30848)
Epoch: 63 | Batch_idx: 250 |  Loss: (0.4073) |  Loss2: (0.0000) | Acc: (85.00%) (27617/32128)
Epoch: 63 | Batch_idx: 260 |  Loss: (0.4065) |  Loss2: (0.0000) | Acc: (85.00%) (28718/33408)
Epoch: 63 | Batch_idx: 270 |  Loss: (0.4044) |  Loss2: (0.0000) | Acc: (86.00%) (29840/34688)
Epoch: 63 | Batch_idx: 280 |  Loss: (0.4033) |  Loss2: (0.0000) | Acc: (86.00%) (30953/35968)
Epoch: 63 | Batch_idx: 290 |  Loss: (0.4033) |  Loss2: (0.0000) | Acc: (86.00%) (32057/37248)
Epoch: 63 | Batch_idx: 300 |  Loss: (0.4014) |  Loss2: (0.0000) | Acc: (86.00%) (33182/38528)
Epoch: 63 | Batch_idx: 310 |  Loss: (0.3995) |  Loss2: (0.0000) | Acc: (86.00%) (34310/39808)
Epoch: 63 | Batch_idx: 320 |  Loss: (0.3993) |  Loss2: (0.0000) | Acc: (86.00%) (35418/41088)
Epoch: 63 | Batch_idx: 330 |  Loss: (0.3988) |  Loss2: (0.0000) | Acc: (86.00%) (36532/42368)
Epoch: 63 | Batch_idx: 340 |  Loss: (0.3988) |  Loss2: (0.0000) | Acc: (86.00%) (37644/43648)
Epoch: 63 | Batch_idx: 350 |  Loss: (0.3975) |  Loss2: (0.0000) | Acc: (86.00%) (38768/44928)
Epoch: 63 | Batch_idx: 360 |  Loss: (0.3972) |  Loss2: (0.0000) | Acc: (86.00%) (39873/46208)
Epoch: 63 | Batch_idx: 370 |  Loss: (0.3960) |  Loss2: (0.0000) | Acc: (86.00%) (40991/47488)
Epoch: 63 | Batch_idx: 380 |  Loss: (0.3965) |  Loss2: (0.0000) | Acc: (86.00%) (42090/48768)
Epoch: 63 | Batch_idx: 390 |  Loss: (0.3959) |  Loss2: (0.0000) | Acc: (86.00%) (43159/50000)
# TEST : Loss: (0.4882) | Acc: (84.00%) (8403/10000)
percent tensor([0.5495, 0.5580, 0.5707, 0.5688, 0.5740, 0.5644, 0.5634, 0.5670, 0.5507,
        0.5581, 0.5485, 0.5666, 0.5509, 0.5470, 0.5641, 0.5544],
       device='cuda:0') torch.Size([16])
percent tensor([0.5447, 0.5510, 0.5397, 0.5347, 0.5443, 0.5516, 0.5527, 0.5423, 0.5409,
        0.5452, 0.5474, 0.5479, 0.5445, 0.5429, 0.5545, 0.5485],
       device='cuda:0') torch.Size([16])
percent tensor([0.5488, 0.5583, 0.5322, 0.5209, 0.5307, 0.5244, 0.5538, 0.5377, 0.5425,
        0.5526, 0.5505, 0.5472, 0.5580, 0.5536, 0.5496, 0.5496],
       device='cuda:0') torch.Size([16])
percent tensor([0.6045, 0.6107, 0.5876, 0.5893, 0.5920, 0.6056, 0.6121, 0.5928, 0.6040,
        0.6149, 0.6140, 0.6019, 0.6074, 0.6140, 0.6122, 0.6066],
       device='cuda:0') torch.Size([16])
percent tensor([0.4896, 0.5136, 0.5465, 0.5446, 0.5481, 0.5268, 0.5180, 0.5438, 0.5212,
        0.5156, 0.5271, 0.5185, 0.4741, 0.5285, 0.5266, 0.5093],
       device='cuda:0') torch.Size([16])
percent tensor([0.4700, 0.5071, 0.5649, 0.5648, 0.5930, 0.5541, 0.5212, 0.5421, 0.5380,
        0.4948, 0.5205, 0.5300, 0.4695, 0.5446, 0.4746, 0.5042],
       device='cuda:0') torch.Size([16])
percent tensor([0.6011, 0.5826, 0.6479, 0.6239, 0.6698, 0.6218, 0.6113, 0.6176, 0.6113,
        0.6052, 0.5901, 0.6043, 0.5852, 0.6227, 0.5630, 0.5942],
       device='cuda:0') torch.Size([16])
percent tensor([0.9985, 0.9963, 0.9981, 0.9986, 0.9994, 0.9971, 0.9992, 0.9996, 0.9987,
        0.9973, 0.9978, 0.9989, 0.9974, 0.9981, 0.9989, 0.9988],
       device='cuda:0') torch.Size([16])
Epoch: 64 | Batch_idx: 0 |  Loss: (0.4892) |  Loss2: (0.0000) | Acc: (85.00%) (109/128)
Epoch: 64 | Batch_idx: 10 |  Loss: (0.3645) |  Loss2: (0.0000) | Acc: (87.00%) (1230/1408)
Epoch: 64 | Batch_idx: 20 |  Loss: (0.3503) |  Loss2: (0.0000) | Acc: (87.00%) (2355/2688)
Epoch: 64 | Batch_idx: 30 |  Loss: (0.3656) |  Loss2: (0.0000) | Acc: (87.00%) (3458/3968)
Epoch: 64 | Batch_idx: 40 |  Loss: (0.3669) |  Loss2: (0.0000) | Acc: (87.00%) (4575/5248)
Epoch: 64 | Batch_idx: 50 |  Loss: (0.3708) |  Loss2: (0.0000) | Acc: (87.00%) (5685/6528)
Epoch: 64 | Batch_idx: 60 |  Loss: (0.3632) |  Loss2: (0.0000) | Acc: (87.00%) (6820/7808)
Epoch: 64 | Batch_idx: 70 |  Loss: (0.3647) |  Loss2: (0.0000) | Acc: (87.00%) (7944/9088)
Epoch: 64 | Batch_idx: 80 |  Loss: (0.3646) |  Loss2: (0.0000) | Acc: (87.00%) (9059/10368)
Epoch: 64 | Batch_idx: 90 |  Loss: (0.3664) |  Loss2: (0.0000) | Acc: (87.00%) (10167/11648)
Epoch: 64 | Batch_idx: 100 |  Loss: (0.3676) |  Loss2: (0.0000) | Acc: (87.00%) (11271/12928)
Epoch: 64 | Batch_idx: 110 |  Loss: (0.3684) |  Loss2: (0.0000) | Acc: (87.00%) (12391/14208)
Epoch: 64 | Batch_idx: 120 |  Loss: (0.3667) |  Loss2: (0.0000) | Acc: (87.00%) (13513/15488)
Epoch: 64 | Batch_idx: 130 |  Loss: (0.3657) |  Loss2: (0.0000) | Acc: (87.00%) (14635/16768)
Epoch: 64 | Batch_idx: 140 |  Loss: (0.3661) |  Loss2: (0.0000) | Acc: (87.00%) (15737/18048)
Epoch: 64 | Batch_idx: 150 |  Loss: (0.3671) |  Loss2: (0.0000) | Acc: (87.00%) (16847/19328)
Epoch: 64 | Batch_idx: 160 |  Loss: (0.3656) |  Loss2: (0.0000) | Acc: (87.00%) (17977/20608)
Epoch: 64 | Batch_idx: 170 |  Loss: (0.3647) |  Loss2: (0.0000) | Acc: (87.00%) (19114/21888)
Epoch: 64 | Batch_idx: 180 |  Loss: (0.3651) |  Loss2: (0.0000) | Acc: (87.00%) (20234/23168)
Epoch: 64 | Batch_idx: 190 |  Loss: (0.3667) |  Loss2: (0.0000) | Acc: (87.00%) (21340/24448)
Epoch: 64 | Batch_idx: 200 |  Loss: (0.3662) |  Loss2: (0.0000) | Acc: (87.00%) (22453/25728)
Epoch: 64 | Batch_idx: 210 |  Loss: (0.3670) |  Loss2: (0.0000) | Acc: (87.00%) (23569/27008)
Epoch: 64 | Batch_idx: 220 |  Loss: (0.3664) |  Loss2: (0.0000) | Acc: (87.00%) (24699/28288)
Epoch: 64 | Batch_idx: 230 |  Loss: (0.3659) |  Loss2: (0.0000) | Acc: (87.00%) (25830/29568)
Epoch: 64 | Batch_idx: 240 |  Loss: (0.3657) |  Loss2: (0.0000) | Acc: (87.00%) (26953/30848)
Epoch: 64 | Batch_idx: 250 |  Loss: (0.3648) |  Loss2: (0.0000) | Acc: (87.00%) (28079/32128)
Epoch: 64 | Batch_idx: 260 |  Loss: (0.3646) |  Loss2: (0.0000) | Acc: (87.00%) (29212/33408)
Epoch: 64 | Batch_idx: 270 |  Loss: (0.3641) |  Loss2: (0.0000) | Acc: (87.00%) (30338/34688)
Epoch: 64 | Batch_idx: 280 |  Loss: (0.3630) |  Loss2: (0.0000) | Acc: (87.00%) (31471/35968)
Epoch: 64 | Batch_idx: 290 |  Loss: (0.3626) |  Loss2: (0.0000) | Acc: (87.00%) (32594/37248)
Epoch: 64 | Batch_idx: 300 |  Loss: (0.3613) |  Loss2: (0.0000) | Acc: (87.00%) (33736/38528)
Epoch: 64 | Batch_idx: 310 |  Loss: (0.3612) |  Loss2: (0.0000) | Acc: (87.00%) (34853/39808)
Epoch: 64 | Batch_idx: 320 |  Loss: (0.3612) |  Loss2: (0.0000) | Acc: (87.00%) (35977/41088)
Epoch: 64 | Batch_idx: 330 |  Loss: (0.3619) |  Loss2: (0.0000) | Acc: (87.00%) (37077/42368)
Epoch: 64 | Batch_idx: 340 |  Loss: (0.3611) |  Loss2: (0.0000) | Acc: (87.00%) (38217/43648)
Epoch: 64 | Batch_idx: 350 |  Loss: (0.3610) |  Loss2: (0.0000) | Acc: (87.00%) (39349/44928)
Epoch: 64 | Batch_idx: 360 |  Loss: (0.3606) |  Loss2: (0.0000) | Acc: (87.00%) (40481/46208)
Epoch: 64 | Batch_idx: 370 |  Loss: (0.3607) |  Loss2: (0.0000) | Acc: (87.00%) (41599/47488)
Epoch: 64 | Batch_idx: 380 |  Loss: (0.3603) |  Loss2: (0.0000) | Acc: (87.00%) (42721/48768)
Epoch: 64 | Batch_idx: 390 |  Loss: (0.3598) |  Loss2: (0.0000) | Acc: (87.00%) (43797/50000)
# TEST : Loss: (0.4641) | Acc: (84.00%) (8493/10000)
percent tensor([0.5514, 0.5601, 0.5750, 0.5705, 0.5778, 0.5643, 0.5664, 0.5701, 0.5538,
        0.5614, 0.5505, 0.5713, 0.5532, 0.5490, 0.5652, 0.5556],
       device='cuda:0') torch.Size([16])
percent tensor([0.5465, 0.5528, 0.5411, 0.5359, 0.5460, 0.5534, 0.5546, 0.5440, 0.5426,
        0.5469, 0.5495, 0.5495, 0.5466, 0.5442, 0.5564, 0.5500],
       device='cuda:0') torch.Size([16])
percent tensor([0.5582, 0.5647, 0.5411, 0.5292, 0.5392, 0.5360, 0.5615, 0.5453, 0.5501,
        0.5594, 0.5570, 0.5554, 0.5668, 0.5570, 0.5599, 0.5588],
       device='cuda:0') torch.Size([16])
percent tensor([0.6042, 0.6093, 0.5865, 0.5871, 0.5907, 0.6064, 0.6107, 0.5907, 0.6024,
        0.6140, 0.6126, 0.6003, 0.6066, 0.6120, 0.6109, 0.6070],
       device='cuda:0') torch.Size([16])
percent tensor([0.4927, 0.5163, 0.5534, 0.5551, 0.5550, 0.5345, 0.5209, 0.5496, 0.5315,
        0.5192, 0.5362, 0.5269, 0.4786, 0.5390, 0.5283, 0.5164],
       device='cuda:0') torch.Size([16])
percent tensor([0.4705, 0.5056, 0.5645, 0.5611, 0.5970, 0.5608, 0.5184, 0.5437, 0.5365,
        0.4896, 0.5191, 0.5215, 0.4692, 0.5387, 0.4734, 0.5012],
       device='cuda:0') torch.Size([16])
percent tensor([0.6080, 0.5879, 0.6513, 0.6281, 0.6764, 0.6287, 0.6168, 0.6229, 0.6177,
        0.6092, 0.5960, 0.6096, 0.5937, 0.6277, 0.5689, 0.5996],
       device='cuda:0') torch.Size([16])
percent tensor([0.9986, 0.9964, 0.9980, 0.9985, 0.9994, 0.9972, 0.9991, 0.9996, 0.9989,
        0.9975, 0.9978, 0.9988, 0.9976, 0.9981, 0.9988, 0.9988],
       device='cuda:0') torch.Size([16])
Epoch: 65 | Batch_idx: 0 |  Loss: (0.3993) |  Loss2: (0.0000) | Acc: (88.00%) (113/128)
Epoch: 65 | Batch_idx: 10 |  Loss: (0.3508) |  Loss2: (0.0000) | Acc: (87.00%) (1235/1408)
Epoch: 65 | Batch_idx: 20 |  Loss: (0.3689) |  Loss2: (0.0000) | Acc: (87.00%) (2349/2688)
Epoch: 65 | Batch_idx: 30 |  Loss: (0.3644) |  Loss2: (0.0000) | Acc: (87.00%) (3467/3968)
Epoch: 65 | Batch_idx: 40 |  Loss: (0.3610) |  Loss2: (0.0000) | Acc: (87.00%) (4595/5248)
Epoch: 65 | Batch_idx: 50 |  Loss: (0.3584) |  Loss2: (0.0000) | Acc: (87.00%) (5727/6528)
Epoch: 65 | Batch_idx: 60 |  Loss: (0.3577) |  Loss2: (0.0000) | Acc: (87.00%) (6854/7808)
Epoch: 65 | Batch_idx: 70 |  Loss: (0.3592) |  Loss2: (0.0000) | Acc: (87.00%) (7968/9088)
Epoch: 65 | Batch_idx: 80 |  Loss: (0.3591) |  Loss2: (0.0000) | Acc: (87.00%) (9080/10368)
Epoch: 65 | Batch_idx: 90 |  Loss: (0.3608) |  Loss2: (0.0000) | Acc: (87.00%) (10199/11648)
Epoch: 65 | Batch_idx: 100 |  Loss: (0.3586) |  Loss2: (0.0000) | Acc: (87.00%) (11329/12928)
Epoch: 65 | Batch_idx: 110 |  Loss: (0.3578) |  Loss2: (0.0000) | Acc: (87.00%) (12442/14208)
Epoch: 65 | Batch_idx: 120 |  Loss: (0.3581) |  Loss2: (0.0000) | Acc: (87.00%) (13562/15488)
Epoch: 65 | Batch_idx: 130 |  Loss: (0.3567) |  Loss2: (0.0000) | Acc: (87.00%) (14690/16768)
Epoch: 65 | Batch_idx: 140 |  Loss: (0.3534) |  Loss2: (0.0000) | Acc: (87.00%) (15836/18048)
Epoch: 65 | Batch_idx: 150 |  Loss: (0.3536) |  Loss2: (0.0000) | Acc: (87.00%) (16959/19328)
Epoch: 65 | Batch_idx: 160 |  Loss: (0.3526) |  Loss2: (0.0000) | Acc: (87.00%) (18096/20608)
Epoch: 65 | Batch_idx: 170 |  Loss: (0.3511) |  Loss2: (0.0000) | Acc: (87.00%) (19219/21888)
Epoch: 65 | Batch_idx: 180 |  Loss: (0.3493) |  Loss2: (0.0000) | Acc: (87.00%) (20361/23168)
Epoch: 65 | Batch_idx: 190 |  Loss: (0.3502) |  Loss2: (0.0000) | Acc: (87.00%) (21483/24448)
Epoch: 65 | Batch_idx: 200 |  Loss: (0.3489) |  Loss2: (0.0000) | Acc: (87.00%) (22615/25728)
Epoch: 65 | Batch_idx: 210 |  Loss: (0.3473) |  Loss2: (0.0000) | Acc: (87.00%) (23756/27008)
Epoch: 65 | Batch_idx: 220 |  Loss: (0.3470) |  Loss2: (0.0000) | Acc: (87.00%) (24883/28288)
Epoch: 65 | Batch_idx: 230 |  Loss: (0.3467) |  Loss2: (0.0000) | Acc: (87.00%) (26016/29568)
Epoch: 65 | Batch_idx: 240 |  Loss: (0.3465) |  Loss2: (0.0000) | Acc: (87.00%) (27146/30848)
Epoch: 65 | Batch_idx: 250 |  Loss: (0.3452) |  Loss2: (0.0000) | Acc: (88.00%) (28277/32128)
Epoch: 65 | Batch_idx: 260 |  Loss: (0.3456) |  Loss2: (0.0000) | Acc: (87.00%) (29398/33408)
Epoch: 65 | Batch_idx: 270 |  Loss: (0.3440) |  Loss2: (0.0000) | Acc: (88.00%) (30545/34688)
Epoch: 65 | Batch_idx: 280 |  Loss: (0.3440) |  Loss2: (0.0000) | Acc: (88.00%) (31675/35968)
Epoch: 65 | Batch_idx: 290 |  Loss: (0.3440) |  Loss2: (0.0000) | Acc: (88.00%) (32790/37248)
Epoch: 65 | Batch_idx: 300 |  Loss: (0.3435) |  Loss2: (0.0000) | Acc: (88.00%) (33933/38528)
Epoch: 65 | Batch_idx: 310 |  Loss: (0.3432) |  Loss2: (0.0000) | Acc: (88.00%) (35058/39808)
Epoch: 65 | Batch_idx: 320 |  Loss: (0.3431) |  Loss2: (0.0000) | Acc: (88.00%) (36201/41088)
Epoch: 65 | Batch_idx: 330 |  Loss: (0.3427) |  Loss2: (0.0000) | Acc: (88.00%) (37331/42368)
Epoch: 65 | Batch_idx: 340 |  Loss: (0.3431) |  Loss2: (0.0000) | Acc: (88.00%) (38458/43648)
Epoch: 65 | Batch_idx: 350 |  Loss: (0.3436) |  Loss2: (0.0000) | Acc: (88.00%) (39576/44928)
Epoch: 65 | Batch_idx: 360 |  Loss: (0.3436) |  Loss2: (0.0000) | Acc: (88.00%) (40705/46208)
Epoch: 65 | Batch_idx: 370 |  Loss: (0.3435) |  Loss2: (0.0000) | Acc: (88.00%) (41824/47488)
Epoch: 65 | Batch_idx: 380 |  Loss: (0.3434) |  Loss2: (0.0000) | Acc: (88.00%) (42954/48768)
Epoch: 65 | Batch_idx: 390 |  Loss: (0.3435) |  Loss2: (0.0000) | Acc: (88.00%) (44037/50000)
=> saving checkpoint 'drive/app/torch/save_Schedule/checkpoint_065.pth.tar'
# TEST : Loss: (0.4516) | Acc: (84.00%) (8491/10000)
percent tensor([0.5517, 0.5601, 0.5769, 0.5701, 0.5791, 0.5625, 0.5671, 0.5709, 0.5548,
        0.5624, 0.5507, 0.5733, 0.5538, 0.5490, 0.5643, 0.5550],
       device='cuda:0') torch.Size([16])
percent tensor([0.5466, 0.5529, 0.5411, 0.5353, 0.5460, 0.5531, 0.5549, 0.5441, 0.5429,
        0.5470, 0.5499, 0.5496, 0.5470, 0.5441, 0.5564, 0.5498],
       device='cuda:0') torch.Size([16])
percent tensor([0.5682, 0.5723, 0.5498, 0.5376, 0.5477, 0.5481, 0.5698, 0.5530, 0.5583,
        0.5672, 0.5649, 0.5635, 0.5763, 0.5625, 0.5706, 0.5687],
       device='cuda:0') torch.Size([16])
percent tensor([0.6060, 0.6100, 0.5876, 0.5874, 0.5922, 0.6088, 0.6118, 0.5915, 0.6033,
        0.6154, 0.6136, 0.6008, 0.6076, 0.6129, 0.6117, 0.6093],
       device='cuda:0') torch.Size([16])
percent tensor([0.4882, 0.5106, 0.5522, 0.5531, 0.5555, 0.5336, 0.5163, 0.5470, 0.5313,
        0.5133, 0.5331, 0.5236, 0.4737, 0.5399, 0.5228, 0.5126],
       device='cuda:0') torch.Size([16])
percent tensor([0.4701, 0.5020, 0.5654, 0.5605, 0.6004, 0.5676, 0.5167, 0.5418, 0.5396,
        0.4852, 0.5190, 0.5178, 0.4704, 0.5369, 0.4696, 0.4981],
       device='cuda:0') torch.Size([16])
percent tensor([0.6114, 0.5898, 0.6553, 0.6324, 0.6814, 0.6355, 0.6212, 0.6262, 0.6227,
        0.6103, 0.5997, 0.6143, 0.5994, 0.6330, 0.5714, 0.6029],
       device='cuda:0') torch.Size([16])
percent tensor([0.9985, 0.9966, 0.9981, 0.9987, 0.9995, 0.9972, 0.9991, 0.9996, 0.9990,
        0.9976, 0.9979, 0.9989, 0.9976, 0.9982, 0.9989, 0.9988],
       device='cuda:0') torch.Size([16])
Epoch: 66 | Batch_idx: 0 |  Loss: (0.4409) |  Loss2: (0.0000) | Acc: (85.00%) (110/128)
Epoch: 66 | Batch_idx: 10 |  Loss: (0.3197) |  Loss2: (0.0000) | Acc: (88.00%) (1251/1408)
Epoch: 66 | Batch_idx: 20 |  Loss: (0.3212) |  Loss2: (0.0000) | Acc: (88.00%) (2382/2688)
Epoch: 66 | Batch_idx: 30 |  Loss: (0.3138) |  Loss2: (0.0000) | Acc: (89.00%) (3538/3968)
Epoch: 66 | Batch_idx: 40 |  Loss: (0.3155) |  Loss2: (0.0000) | Acc: (89.00%) (4685/5248)
Epoch: 66 | Batch_idx: 50 |  Loss: (0.3197) |  Loss2: (0.0000) | Acc: (88.00%) (5798/6528)
Epoch: 66 | Batch_idx: 60 |  Loss: (0.3188) |  Loss2: (0.0000) | Acc: (88.00%) (6930/7808)
Epoch: 66 | Batch_idx: 70 |  Loss: (0.3229) |  Loss2: (0.0000) | Acc: (88.00%) (8057/9088)
Epoch: 66 | Batch_idx: 80 |  Loss: (0.3267) |  Loss2: (0.0000) | Acc: (88.00%) (9178/10368)
Epoch: 66 | Batch_idx: 90 |  Loss: (0.3283) |  Loss2: (0.0000) | Acc: (88.00%) (10312/11648)
Epoch: 66 | Batch_idx: 100 |  Loss: (0.3297) |  Loss2: (0.0000) | Acc: (88.00%) (11439/12928)
Epoch: 66 | Batch_idx: 110 |  Loss: (0.3311) |  Loss2: (0.0000) | Acc: (88.00%) (12572/14208)
Epoch: 66 | Batch_idx: 120 |  Loss: (0.3309) |  Loss2: (0.0000) | Acc: (88.00%) (13711/15488)
Epoch: 66 | Batch_idx: 130 |  Loss: (0.3306) |  Loss2: (0.0000) | Acc: (88.00%) (14845/16768)
Epoch: 66 | Batch_idx: 140 |  Loss: (0.3314) |  Loss2: (0.0000) | Acc: (88.00%) (15974/18048)
Epoch: 66 | Batch_idx: 150 |  Loss: (0.3327) |  Loss2: (0.0000) | Acc: (88.00%) (17099/19328)
Epoch: 66 | Batch_idx: 160 |  Loss: (0.3352) |  Loss2: (0.0000) | Acc: (88.00%) (18206/20608)
Epoch: 66 | Batch_idx: 170 |  Loss: (0.3358) |  Loss2: (0.0000) | Acc: (88.00%) (19333/21888)
Epoch: 66 | Batch_idx: 180 |  Loss: (0.3340) |  Loss2: (0.0000) | Acc: (88.00%) (20479/23168)
Epoch: 66 | Batch_idx: 190 |  Loss: (0.3351) |  Loss2: (0.0000) | Acc: (88.00%) (21600/24448)
Epoch: 66 | Batch_idx: 200 |  Loss: (0.3338) |  Loss2: (0.0000) | Acc: (88.00%) (22738/25728)
Epoch: 66 | Batch_idx: 210 |  Loss: (0.3345) |  Loss2: (0.0000) | Acc: (88.00%) (23862/27008)
Epoch: 66 | Batch_idx: 220 |  Loss: (0.3347) |  Loss2: (0.0000) | Acc: (88.00%) (25002/28288)
Epoch: 66 | Batch_idx: 230 |  Loss: (0.3341) |  Loss2: (0.0000) | Acc: (88.00%) (26134/29568)
Epoch: 66 | Batch_idx: 240 |  Loss: (0.3334) |  Loss2: (0.0000) | Acc: (88.00%) (27274/30848)
Epoch: 66 | Batch_idx: 250 |  Loss: (0.3333) |  Loss2: (0.0000) | Acc: (88.00%) (28411/32128)
Epoch: 66 | Batch_idx: 260 |  Loss: (0.3334) |  Loss2: (0.0000) | Acc: (88.00%) (29542/33408)
Epoch: 66 | Batch_idx: 270 |  Loss: (0.3321) |  Loss2: (0.0000) | Acc: (88.00%) (30693/34688)
Epoch: 66 | Batch_idx: 280 |  Loss: (0.3325) |  Loss2: (0.0000) | Acc: (88.00%) (31826/35968)
Epoch: 66 | Batch_idx: 290 |  Loss: (0.3321) |  Loss2: (0.0000) | Acc: (88.00%) (32961/37248)
Epoch: 66 | Batch_idx: 300 |  Loss: (0.3333) |  Loss2: (0.0000) | Acc: (88.00%) (34082/38528)
Epoch: 66 | Batch_idx: 310 |  Loss: (0.3344) |  Loss2: (0.0000) | Acc: (88.00%) (35204/39808)
Epoch: 66 | Batch_idx: 320 |  Loss: (0.3345) |  Loss2: (0.0000) | Acc: (88.00%) (36325/41088)
Epoch: 66 | Batch_idx: 330 |  Loss: (0.3344) |  Loss2: (0.0000) | Acc: (88.00%) (37459/42368)
Epoch: 66 | Batch_idx: 340 |  Loss: (0.3342) |  Loss2: (0.0000) | Acc: (88.00%) (38588/43648)
Epoch: 66 | Batch_idx: 350 |  Loss: (0.3343) |  Loss2: (0.0000) | Acc: (88.00%) (39720/44928)
Epoch: 66 | Batch_idx: 360 |  Loss: (0.3345) |  Loss2: (0.0000) | Acc: (88.00%) (40856/46208)
Epoch: 66 | Batch_idx: 370 |  Loss: (0.3353) |  Loss2: (0.0000) | Acc: (88.00%) (41978/47488)
Epoch: 66 | Batch_idx: 380 |  Loss: (0.3341) |  Loss2: (0.0000) | Acc: (88.00%) (43138/48768)
Epoch: 66 | Batch_idx: 390 |  Loss: (0.3338) |  Loss2: (0.0000) | Acc: (88.00%) (44232/50000)
# TEST : Loss: (0.4461) | Acc: (85.00%) (8525/10000)
percent tensor([0.5512, 0.5591, 0.5771, 0.5692, 0.5789, 0.5607, 0.5665, 0.5705, 0.5546,
        0.5621, 0.5500, 0.5735, 0.5533, 0.5485, 0.5627, 0.5538],
       device='cuda:0') torch.Size([16])
percent tensor([0.5485, 0.5547, 0.5429, 0.5369, 0.5480, 0.5551, 0.5568, 0.5462, 0.5448,
        0.5488, 0.5520, 0.5514, 0.5490, 0.5458, 0.5584, 0.5516],
       device='cuda:0') torch.Size([16])
percent tensor([0.5759, 0.5773, 0.5568, 0.5446, 0.5544, 0.5587, 0.5757, 0.5589, 0.5643,
        0.5725, 0.5705, 0.5696, 0.5832, 0.5658, 0.5790, 0.5763],
       device='cuda:0') torch.Size([16])
percent tensor([0.6077, 0.6102, 0.5890, 0.5887, 0.5939, 0.6121, 0.6124, 0.5928, 0.6038,
        0.6160, 0.6136, 0.6013, 0.6080, 0.6130, 0.6129, 0.6114],
       device='cuda:0') torch.Size([16])
percent tensor([0.4790, 0.4999, 0.5472, 0.5492, 0.5540, 0.5299, 0.5069, 0.5423, 0.5241,
        0.5006, 0.5215, 0.5157, 0.4618, 0.5326, 0.5147, 0.5048],
       device='cuda:0') torch.Size([16])
percent tensor([0.4769, 0.5099, 0.5720, 0.5661, 0.6108, 0.5790, 0.5247, 0.5495, 0.5470,
        0.4908, 0.5250, 0.5196, 0.4787, 0.5427, 0.4751, 0.5043],
       device='cuda:0') torch.Size([16])
percent tensor([0.6127, 0.5907, 0.6563, 0.6346, 0.6861, 0.6366, 0.6253, 0.6322, 0.6222,
        0.6108, 0.5990, 0.6159, 0.5984, 0.6349, 0.5756, 0.6053],
       device='cuda:0') torch.Size([16])
percent tensor([0.9987, 0.9967, 0.9982, 0.9987, 0.9996, 0.9974, 0.9991, 0.9997, 0.9990,
        0.9978, 0.9979, 0.9989, 0.9977, 0.9981, 0.9988, 0.9989],
       device='cuda:0') torch.Size([16])
Epoch: 67 | Batch_idx: 0 |  Loss: (0.3207) |  Loss2: (0.0000) | Acc: (89.00%) (115/128)
Epoch: 67 | Batch_idx: 10 |  Loss: (0.3156) |  Loss2: (0.0000) | Acc: (88.00%) (1252/1408)
Epoch: 67 | Batch_idx: 20 |  Loss: (0.3138) |  Loss2: (0.0000) | Acc: (89.00%) (2400/2688)
Epoch: 67 | Batch_idx: 30 |  Loss: (0.3300) |  Loss2: (0.0000) | Acc: (88.00%) (3529/3968)
Epoch: 67 | Batch_idx: 40 |  Loss: (0.3330) |  Loss2: (0.0000) | Acc: (88.00%) (4659/5248)
Epoch: 67 | Batch_idx: 50 |  Loss: (0.3268) |  Loss2: (0.0000) | Acc: (89.00%) (5810/6528)
Epoch: 67 | Batch_idx: 60 |  Loss: (0.3265) |  Loss2: (0.0000) | Acc: (89.00%) (6955/7808)
Epoch: 67 | Batch_idx: 70 |  Loss: (0.3282) |  Loss2: (0.0000) | Acc: (89.00%) (8091/9088)
Epoch: 67 | Batch_idx: 80 |  Loss: (0.3283) |  Loss2: (0.0000) | Acc: (88.00%) (9218/10368)
Epoch: 67 | Batch_idx: 90 |  Loss: (0.3274) |  Loss2: (0.0000) | Acc: (88.00%) (10353/11648)
Epoch: 67 | Batch_idx: 100 |  Loss: (0.3277) |  Loss2: (0.0000) | Acc: (88.00%) (11480/12928)
Epoch: 67 | Batch_idx: 110 |  Loss: (0.3320) |  Loss2: (0.0000) | Acc: (88.00%) (12594/14208)
Epoch: 67 | Batch_idx: 120 |  Loss: (0.3316) |  Loss2: (0.0000) | Acc: (88.00%) (13737/15488)
Epoch: 67 | Batch_idx: 130 |  Loss: (0.3315) |  Loss2: (0.0000) | Acc: (88.00%) (14870/16768)
Epoch: 67 | Batch_idx: 140 |  Loss: (0.3309) |  Loss2: (0.0000) | Acc: (88.00%) (16001/18048)
Epoch: 67 | Batch_idx: 150 |  Loss: (0.3307) |  Loss2: (0.0000) | Acc: (88.00%) (17142/19328)
Epoch: 67 | Batch_idx: 160 |  Loss: (0.3309) |  Loss2: (0.0000) | Acc: (88.00%) (18271/20608)
Epoch: 67 | Batch_idx: 170 |  Loss: (0.3317) |  Loss2: (0.0000) | Acc: (88.00%) (19395/21888)
Epoch: 67 | Batch_idx: 180 |  Loss: (0.3321) |  Loss2: (0.0000) | Acc: (88.00%) (20536/23168)
Epoch: 67 | Batch_idx: 190 |  Loss: (0.3307) |  Loss2: (0.0000) | Acc: (88.00%) (21686/24448)
Epoch: 67 | Batch_idx: 200 |  Loss: (0.3339) |  Loss2: (0.0000) | Acc: (88.00%) (22797/25728)
Epoch: 67 | Batch_idx: 210 |  Loss: (0.3334) |  Loss2: (0.0000) | Acc: (88.00%) (23942/27008)
Epoch: 67 | Batch_idx: 220 |  Loss: (0.3325) |  Loss2: (0.0000) | Acc: (88.00%) (25074/28288)
Epoch: 67 | Batch_idx: 230 |  Loss: (0.3328) |  Loss2: (0.0000) | Acc: (88.00%) (26204/29568)
Epoch: 67 | Batch_idx: 240 |  Loss: (0.3324) |  Loss2: (0.0000) | Acc: (88.00%) (27335/30848)
Epoch: 67 | Batch_idx: 250 |  Loss: (0.3310) |  Loss2: (0.0000) | Acc: (88.00%) (28490/32128)
Epoch: 67 | Batch_idx: 260 |  Loss: (0.3306) |  Loss2: (0.0000) | Acc: (88.00%) (29627/33408)
Epoch: 67 | Batch_idx: 270 |  Loss: (0.3323) |  Loss2: (0.0000) | Acc: (88.00%) (30739/34688)
Epoch: 67 | Batch_idx: 280 |  Loss: (0.3337) |  Loss2: (0.0000) | Acc: (88.00%) (31850/35968)
Epoch: 67 | Batch_idx: 290 |  Loss: (0.3322) |  Loss2: (0.0000) | Acc: (88.00%) (33004/37248)
Epoch: 67 | Batch_idx: 300 |  Loss: (0.3312) |  Loss2: (0.0000) | Acc: (88.00%) (34155/38528)
Epoch: 67 | Batch_idx: 310 |  Loss: (0.3314) |  Loss2: (0.0000) | Acc: (88.00%) (35288/39808)
Epoch: 67 | Batch_idx: 320 |  Loss: (0.3320) |  Loss2: (0.0000) | Acc: (88.00%) (36409/41088)
Epoch: 67 | Batch_idx: 330 |  Loss: (0.3324) |  Loss2: (0.0000) | Acc: (88.00%) (37537/42368)
Epoch: 67 | Batch_idx: 340 |  Loss: (0.3321) |  Loss2: (0.0000) | Acc: (88.00%) (38663/43648)
Epoch: 67 | Batch_idx: 350 |  Loss: (0.3323) |  Loss2: (0.0000) | Acc: (88.00%) (39790/44928)
Epoch: 67 | Batch_idx: 360 |  Loss: (0.3320) |  Loss2: (0.0000) | Acc: (88.00%) (40932/46208)
Epoch: 67 | Batch_idx: 370 |  Loss: (0.3310) |  Loss2: (0.0000) | Acc: (88.00%) (42085/47488)
Epoch: 67 | Batch_idx: 380 |  Loss: (0.3304) |  Loss2: (0.0000) | Acc: (88.00%) (43238/48768)
Epoch: 67 | Batch_idx: 390 |  Loss: (0.3302) |  Loss2: (0.0000) | Acc: (88.00%) (44337/50000)
# TEST : Loss: (0.4385) | Acc: (85.00%) (8544/10000)
percent tensor([0.5507, 0.5582, 0.5781, 0.5683, 0.5793, 0.5591, 0.5663, 0.5703, 0.5546,
        0.5621, 0.5494, 0.5745, 0.5530, 0.5476, 0.5615, 0.5526],
       device='cuda:0') torch.Size([16])
percent tensor([0.5510, 0.5571, 0.5454, 0.5391, 0.5509, 0.5576, 0.5595, 0.5491, 0.5474,
        0.5510, 0.5544, 0.5540, 0.5515, 0.5478, 0.5610, 0.5538],
       device='cuda:0') torch.Size([16])
percent tensor([0.5800, 0.5776, 0.5615, 0.5490, 0.5588, 0.5648, 0.5776, 0.5624, 0.5677,
        0.5737, 0.5722, 0.5725, 0.5859, 0.5656, 0.5823, 0.5795],
       device='cuda:0') torch.Size([16])
percent tensor([0.6112, 0.6124, 0.5923, 0.5918, 0.5976, 0.6165, 0.6153, 0.5961, 0.6067,
        0.6187, 0.6159, 0.6038, 0.6101, 0.6158, 0.6157, 0.6153],
       device='cuda:0') torch.Size([16])
percent tensor([0.4768, 0.4978, 0.5460, 0.5483, 0.5547, 0.5289, 0.5064, 0.5435, 0.5237,
        0.4972, 0.5190, 0.5143, 0.4575, 0.5343, 0.5150, 0.5035],
       device='cuda:0') torch.Size([16])
percent tensor([0.4753, 0.5105, 0.5717, 0.5645, 0.6125, 0.5818, 0.5243, 0.5479, 0.5475,
        0.4898, 0.5255, 0.5162, 0.4800, 0.5417, 0.4706, 0.5023],
       device='cuda:0') torch.Size([16])
percent tensor([0.6169, 0.5946, 0.6610, 0.6391, 0.6899, 0.6427, 0.6293, 0.6342, 0.6273,
        0.6140, 0.6035, 0.6206, 0.6035, 0.6408, 0.5790, 0.6089],
       device='cuda:0') torch.Size([16])
percent tensor([0.9987, 0.9968, 0.9983, 0.9988, 0.9996, 0.9976, 0.9992, 0.9997, 0.9991,
        0.9978, 0.9979, 0.9989, 0.9978, 0.9982, 0.9989, 0.9989],
       device='cuda:0') torch.Size([16])
Epoch: 68 | Batch_idx: 0 |  Loss: (0.2478) |  Loss2: (0.0000) | Acc: (92.00%) (118/128)
Epoch: 68 | Batch_idx: 10 |  Loss: (0.3141) |  Loss2: (0.0000) | Acc: (88.00%) (1253/1408)
Epoch: 68 | Batch_idx: 20 |  Loss: (0.3222) |  Loss2: (0.0000) | Acc: (88.00%) (2382/2688)
Epoch: 68 | Batch_idx: 30 |  Loss: (0.3185) |  Loss2: (0.0000) | Acc: (88.00%) (3527/3968)
Epoch: 68 | Batch_idx: 40 |  Loss: (0.3268) |  Loss2: (0.0000) | Acc: (88.00%) (4657/5248)
Epoch: 68 | Batch_idx: 50 |  Loss: (0.3190) |  Loss2: (0.0000) | Acc: (88.00%) (5806/6528)
Epoch: 68 | Batch_idx: 60 |  Loss: (0.3159) |  Loss2: (0.0000) | Acc: (88.00%) (6947/7808)
Epoch: 68 | Batch_idx: 70 |  Loss: (0.3200) |  Loss2: (0.0000) | Acc: (88.00%) (8074/9088)
Epoch: 68 | Batch_idx: 80 |  Loss: (0.3169) |  Loss2: (0.0000) | Acc: (88.00%) (9224/10368)
Epoch: 68 | Batch_idx: 90 |  Loss: (0.3200) |  Loss2: (0.0000) | Acc: (88.00%) (10354/11648)
Epoch: 68 | Batch_idx: 100 |  Loss: (0.3208) |  Loss2: (0.0000) | Acc: (88.00%) (11490/12928)
Epoch: 68 | Batch_idx: 110 |  Loss: (0.3220) |  Loss2: (0.0000) | Acc: (88.00%) (12608/14208)
Epoch: 68 | Batch_idx: 120 |  Loss: (0.3206) |  Loss2: (0.0000) | Acc: (88.00%) (13755/15488)
Epoch: 68 | Batch_idx: 130 |  Loss: (0.3185) |  Loss2: (0.0000) | Acc: (88.00%) (14904/16768)
Epoch: 68 | Batch_idx: 140 |  Loss: (0.3191) |  Loss2: (0.0000) | Acc: (88.00%) (16039/18048)
Epoch: 68 | Batch_idx: 150 |  Loss: (0.3202) |  Loss2: (0.0000) | Acc: (88.00%) (17161/19328)
Epoch: 68 | Batch_idx: 160 |  Loss: (0.3205) |  Loss2: (0.0000) | Acc: (88.00%) (18301/20608)
Epoch: 68 | Batch_idx: 170 |  Loss: (0.3193) |  Loss2: (0.0000) | Acc: (88.00%) (19457/21888)
Epoch: 68 | Batch_idx: 180 |  Loss: (0.3192) |  Loss2: (0.0000) | Acc: (88.00%) (20600/23168)
Epoch: 68 | Batch_idx: 190 |  Loss: (0.3194) |  Loss2: (0.0000) | Acc: (88.00%) (21740/24448)
Epoch: 68 | Batch_idx: 200 |  Loss: (0.3195) |  Loss2: (0.0000) | Acc: (88.00%) (22883/25728)
Epoch: 68 | Batch_idx: 210 |  Loss: (0.3185) |  Loss2: (0.0000) | Acc: (88.00%) (24037/27008)
Epoch: 68 | Batch_idx: 220 |  Loss: (0.3193) |  Loss2: (0.0000) | Acc: (88.00%) (25173/28288)
Epoch: 68 | Batch_idx: 230 |  Loss: (0.3199) |  Loss2: (0.0000) | Acc: (88.00%) (26315/29568)
Epoch: 68 | Batch_idx: 240 |  Loss: (0.3220) |  Loss2: (0.0000) | Acc: (88.00%) (27434/30848)
Epoch: 68 | Batch_idx: 250 |  Loss: (0.3226) |  Loss2: (0.0000) | Acc: (88.00%) (28563/32128)
Epoch: 68 | Batch_idx: 260 |  Loss: (0.3230) |  Loss2: (0.0000) | Acc: (88.00%) (29699/33408)
Epoch: 68 | Batch_idx: 270 |  Loss: (0.3237) |  Loss2: (0.0000) | Acc: (88.00%) (30834/34688)
Epoch: 68 | Batch_idx: 280 |  Loss: (0.3234) |  Loss2: (0.0000) | Acc: (88.00%) (31973/35968)
Epoch: 68 | Batch_idx: 290 |  Loss: (0.3236) |  Loss2: (0.0000) | Acc: (88.00%) (33104/37248)
Epoch: 68 | Batch_idx: 300 |  Loss: (0.3227) |  Loss2: (0.0000) | Acc: (88.00%) (34248/38528)
Epoch: 68 | Batch_idx: 310 |  Loss: (0.3224) |  Loss2: (0.0000) | Acc: (88.00%) (35387/39808)
Epoch: 68 | Batch_idx: 320 |  Loss: (0.3227) |  Loss2: (0.0000) | Acc: (88.00%) (36530/41088)
Epoch: 68 | Batch_idx: 330 |  Loss: (0.3239) |  Loss2: (0.0000) | Acc: (88.00%) (37654/42368)
Epoch: 68 | Batch_idx: 340 |  Loss: (0.3241) |  Loss2: (0.0000) | Acc: (88.00%) (38781/43648)
Epoch: 68 | Batch_idx: 350 |  Loss: (0.3241) |  Loss2: (0.0000) | Acc: (88.00%) (39910/44928)
Epoch: 68 | Batch_idx: 360 |  Loss: (0.3232) |  Loss2: (0.0000) | Acc: (88.00%) (41046/46208)
Epoch: 68 | Batch_idx: 370 |  Loss: (0.3228) |  Loss2: (0.0000) | Acc: (88.00%) (42179/47488)
Epoch: 68 | Batch_idx: 380 |  Loss: (0.3229) |  Loss2: (0.0000) | Acc: (88.00%) (43315/48768)
Epoch: 68 | Batch_idx: 390 |  Loss: (0.3229) |  Loss2: (0.0000) | Acc: (88.00%) (44409/50000)
# TEST : Loss: (0.4342) | Acc: (85.00%) (8546/10000)
percent tensor([0.5485, 0.5552, 0.5756, 0.5649, 0.5764, 0.5556, 0.5635, 0.5674, 0.5524,
        0.5596, 0.5472, 0.5720, 0.5507, 0.5451, 0.5580, 0.5498],
       device='cuda:0') torch.Size([16])
percent tensor([0.5522, 0.5579, 0.5466, 0.5400, 0.5523, 0.5587, 0.5606, 0.5504, 0.5486,
        0.5519, 0.5554, 0.5550, 0.5526, 0.5485, 0.5619, 0.5547],
       device='cuda:0') torch.Size([16])
percent tensor([0.5880, 0.5828, 0.5689, 0.5567, 0.5659, 0.5754, 0.5837, 0.5689, 0.5744,
        0.5791, 0.5782, 0.5785, 0.5923, 0.5704, 0.5905, 0.5874],
       device='cuda:0') torch.Size([16])
percent tensor([0.6100, 0.6104, 0.5912, 0.5904, 0.5968, 0.6162, 0.6135, 0.5949, 0.6047,
        0.6169, 0.6134, 0.6016, 0.6079, 0.6137, 0.6139, 0.6146],
       device='cuda:0') torch.Size([16])
percent tensor([0.4849, 0.5004, 0.5535, 0.5560, 0.5611, 0.5374, 0.5122, 0.5517, 0.5275,
        0.4998, 0.5188, 0.5196, 0.4609, 0.5384, 0.5213, 0.5126],
       device='cuda:0') torch.Size([16])
percent tensor([0.4726, 0.5075, 0.5692, 0.5617, 0.6119, 0.5838, 0.5212, 0.5418, 0.5468,
        0.4851, 0.5235, 0.5088, 0.4783, 0.5396, 0.4639, 0.4979],
       device='cuda:0') torch.Size([16])
percent tensor([0.6188, 0.5950, 0.6632, 0.6413, 0.6933, 0.6439, 0.6330, 0.6364, 0.6290,
        0.6143, 0.6038, 0.6232, 0.6047, 0.6432, 0.5808, 0.6105],
       device='cuda:0') torch.Size([16])
percent tensor([0.9989, 0.9971, 0.9985, 0.9989, 0.9997, 0.9978, 0.9992, 0.9997, 0.9992,
        0.9981, 0.9981, 0.9990, 0.9980, 0.9984, 0.9990, 0.9991],
       device='cuda:0') torch.Size([16])
Epoch: 69 | Batch_idx: 0 |  Loss: (0.3081) |  Loss2: (0.0000) | Acc: (90.00%) (116/128)
Epoch: 69 | Batch_idx: 10 |  Loss: (0.3298) |  Loss2: (0.0000) | Acc: (88.00%) (1251/1408)
Epoch: 69 | Batch_idx: 20 |  Loss: (0.3273) |  Loss2: (0.0000) | Acc: (88.00%) (2390/2688)
Epoch: 69 | Batch_idx: 30 |  Loss: (0.3213) |  Loss2: (0.0000) | Acc: (89.00%) (3540/3968)
Epoch: 69 | Batch_idx: 40 |  Loss: (0.3280) |  Loss2: (0.0000) | Acc: (88.00%) (4670/5248)
Epoch: 69 | Batch_idx: 50 |  Loss: (0.3265) |  Loss2: (0.0000) | Acc: (88.00%) (5799/6528)
Epoch: 69 | Batch_idx: 60 |  Loss: (0.3245) |  Loss2: (0.0000) | Acc: (88.00%) (6941/7808)
Epoch: 69 | Batch_idx: 70 |  Loss: (0.3242) |  Loss2: (0.0000) | Acc: (88.00%) (8070/9088)
Epoch: 69 | Batch_idx: 80 |  Loss: (0.3206) |  Loss2: (0.0000) | Acc: (88.00%) (9224/10368)
Epoch: 69 | Batch_idx: 90 |  Loss: (0.3248) |  Loss2: (0.0000) | Acc: (88.00%) (10340/11648)
Epoch: 69 | Batch_idx: 100 |  Loss: (0.3279) |  Loss2: (0.0000) | Acc: (88.00%) (11464/12928)
Epoch: 69 | Batch_idx: 110 |  Loss: (0.3276) |  Loss2: (0.0000) | Acc: (88.00%) (12605/14208)
Epoch: 69 | Batch_idx: 120 |  Loss: (0.3254) |  Loss2: (0.0000) | Acc: (88.00%) (13742/15488)
Epoch: 69 | Batch_idx: 130 |  Loss: (0.3222) |  Loss2: (0.0000) | Acc: (88.00%) (14901/16768)
Epoch: 69 | Batch_idx: 140 |  Loss: (0.3218) |  Loss2: (0.0000) | Acc: (88.00%) (16039/18048)
Epoch: 69 | Batch_idx: 150 |  Loss: (0.3208) |  Loss2: (0.0000) | Acc: (88.00%) (17180/19328)
Epoch: 69 | Batch_idx: 160 |  Loss: (0.3197) |  Loss2: (0.0000) | Acc: (88.00%) (18329/20608)
Epoch: 69 | Batch_idx: 170 |  Loss: (0.3209) |  Loss2: (0.0000) | Acc: (88.00%) (19453/21888)
Epoch: 69 | Batch_idx: 180 |  Loss: (0.3207) |  Loss2: (0.0000) | Acc: (88.00%) (20576/23168)
Epoch: 69 | Batch_idx: 190 |  Loss: (0.3221) |  Loss2: (0.0000) | Acc: (88.00%) (21696/24448)
Epoch: 69 | Batch_idx: 200 |  Loss: (0.3225) |  Loss2: (0.0000) | Acc: (88.00%) (22812/25728)
Epoch: 69 | Batch_idx: 210 |  Loss: (0.3230) |  Loss2: (0.0000) | Acc: (88.00%) (23956/27008)
Epoch: 69 | Batch_idx: 220 |  Loss: (0.3228) |  Loss2: (0.0000) | Acc: (88.00%) (25092/28288)
Epoch: 69 | Batch_idx: 230 |  Loss: (0.3230) |  Loss2: (0.0000) | Acc: (88.00%) (26220/29568)
Epoch: 69 | Batch_idx: 240 |  Loss: (0.3222) |  Loss2: (0.0000) | Acc: (88.00%) (27370/30848)
Epoch: 69 | Batch_idx: 250 |  Loss: (0.3224) |  Loss2: (0.0000) | Acc: (88.00%) (28504/32128)
Epoch: 69 | Batch_idx: 260 |  Loss: (0.3232) |  Loss2: (0.0000) | Acc: (88.00%) (29628/33408)
Epoch: 69 | Batch_idx: 270 |  Loss: (0.3232) |  Loss2: (0.0000) | Acc: (88.00%) (30759/34688)
Epoch: 69 | Batch_idx: 280 |  Loss: (0.3248) |  Loss2: (0.0000) | Acc: (88.00%) (31881/35968)
Epoch: 69 | Batch_idx: 290 |  Loss: (0.3262) |  Loss2: (0.0000) | Acc: (88.00%) (33007/37248)
Epoch: 69 | Batch_idx: 300 |  Loss: (0.3252) |  Loss2: (0.0000) | Acc: (88.00%) (34147/38528)
Epoch: 69 | Batch_idx: 310 |  Loss: (0.3256) |  Loss2: (0.0000) | Acc: (88.00%) (35282/39808)
Epoch: 69 | Batch_idx: 320 |  Loss: (0.3266) |  Loss2: (0.0000) | Acc: (88.00%) (36402/41088)
Epoch: 69 | Batch_idx: 330 |  Loss: (0.3263) |  Loss2: (0.0000) | Acc: (88.00%) (37536/42368)
Epoch: 69 | Batch_idx: 340 |  Loss: (0.3258) |  Loss2: (0.0000) | Acc: (88.00%) (38678/43648)
Epoch: 69 | Batch_idx: 350 |  Loss: (0.3249) |  Loss2: (0.0000) | Acc: (88.00%) (39821/44928)
Epoch: 69 | Batch_idx: 360 |  Loss: (0.3243) |  Loss2: (0.0000) | Acc: (88.00%) (40963/46208)
Epoch: 69 | Batch_idx: 370 |  Loss: (0.3235) |  Loss2: (0.0000) | Acc: (88.00%) (42115/47488)
Epoch: 69 | Batch_idx: 380 |  Loss: (0.3238) |  Loss2: (0.0000) | Acc: (88.00%) (43255/48768)
Epoch: 69 | Batch_idx: 390 |  Loss: (0.3228) |  Loss2: (0.0000) | Acc: (88.00%) (44373/50000)
# TEST : Loss: (0.4327) | Acc: (85.00%) (8552/10000)
percent tensor([0.5480, 0.5539, 0.5756, 0.5639, 0.5760, 0.5545, 0.5627, 0.5666, 0.5520,
        0.5589, 0.5464, 0.5718, 0.5502, 0.5440, 0.5566, 0.5488],
       device='cuda:0') torch.Size([16])
percent tensor([0.5506, 0.5557, 0.5451, 0.5380, 0.5506, 0.5566, 0.5587, 0.5489, 0.5471,
        0.5499, 0.5537, 0.5533, 0.5510, 0.5465, 0.5598, 0.5527],
       device='cuda:0') torch.Size([16])
percent tensor([0.5888, 0.5817, 0.5699, 0.5573, 0.5672, 0.5783, 0.5834, 0.5695, 0.5747,
        0.5782, 0.5775, 0.5782, 0.5921, 0.5690, 0.5912, 0.5879],
       device='cuda:0') torch.Size([16])
percent tensor([0.6074, 0.6068, 0.5890, 0.5879, 0.5947, 0.6147, 0.6100, 0.5923, 0.6015,
        0.6133, 0.6097, 0.5980, 0.6044, 0.6102, 0.6104, 0.6123],
       device='cuda:0') torch.Size([16])
percent tensor([0.4882, 0.5033, 0.5561, 0.5572, 0.5645, 0.5412, 0.5154, 0.5544, 0.5295,
        0.5022, 0.5203, 0.5202, 0.4628, 0.5407, 0.5239, 0.5172],
       device='cuda:0') torch.Size([16])
percent tensor([0.4728, 0.5075, 0.5700, 0.5617, 0.6135, 0.5862, 0.5219, 0.5430, 0.5484,
        0.4869, 0.5239, 0.5077, 0.4797, 0.5402, 0.4633, 0.4982],
       device='cuda:0') torch.Size([16])
percent tensor([0.6135, 0.5901, 0.6573, 0.6364, 0.6874, 0.6379, 0.6291, 0.6310, 0.6235,
        0.6101, 0.5985, 0.6191, 0.5993, 0.6388, 0.5763, 0.6075],
       device='cuda:0') torch.Size([16])
percent tensor([0.9989, 0.9971, 0.9985, 0.9989, 0.9997, 0.9979, 0.9993, 0.9997, 0.9992,
        0.9981, 0.9980, 0.9990, 0.9980, 0.9984, 0.9989, 0.9991],
       device='cuda:0') torch.Size([16])
True Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=128, out_features=16, bias=False)
False Linear(in_features=16, out_features=2, bias=False)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=128, out_features=16, bias=False)
False Linear(in_features=16, out_features=2, bias=False)
True Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=256, out_features=32, bias=False)
False Linear(in_features=32, out_features=2, bias=False)
True Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=256, out_features=32, bias=False)
False Linear(in_features=32, out_features=2, bias=False)
True Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=512, out_features=64, bias=False)
False Linear(in_features=64, out_features=2, bias=False)
True Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=512, out_features=64, bias=False)
False Linear(in_features=64, out_features=2, bias=False)
True Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1024, out_features=128, bias=False)
False Linear(in_features=128, out_features=2, bias=False)
True Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1024, out_features=128, bias=False)
False Linear(in_features=128, out_features=2, bias=False)
True Linear(in_features=512, out_features=10, bias=True)
Epoch: 70 | Batch_idx: 0 |  Loss: (0.2822) |  Loss2: (0.0000) | Acc: (89.00%) (115/128)
Epoch: 70 | Batch_idx: 10 |  Loss: (0.3083) |  Loss2: (0.0000) | Acc: (88.00%) (1245/1408)
Epoch: 70 | Batch_idx: 20 |  Loss: (0.3219) |  Loss2: (0.0000) | Acc: (88.00%) (2373/2688)
Epoch: 70 | Batch_idx: 30 |  Loss: (0.3196) |  Loss2: (0.0000) | Acc: (88.00%) (3517/3968)
Epoch: 70 | Batch_idx: 40 |  Loss: (0.3226) |  Loss2: (0.0000) | Acc: (88.00%) (4655/5248)
Epoch: 70 | Batch_idx: 50 |  Loss: (0.3305) |  Loss2: (0.0000) | Acc: (88.00%) (5789/6528)
Epoch: 70 | Batch_idx: 60 |  Loss: (0.3240) |  Loss2: (0.0000) | Acc: (88.00%) (6948/7808)
Epoch: 70 | Batch_idx: 70 |  Loss: (0.3279) |  Loss2: (0.0000) | Acc: (88.00%) (8075/9088)
Epoch: 70 | Batch_idx: 80 |  Loss: (0.3303) |  Loss2: (0.0000) | Acc: (88.00%) (9206/10368)
Epoch: 70 | Batch_idx: 90 |  Loss: (0.3326) |  Loss2: (0.0000) | Acc: (88.00%) (10326/11648)
Epoch: 70 | Batch_idx: 100 |  Loss: (0.3313) |  Loss2: (0.0000) | Acc: (88.00%) (11466/12928)
Epoch: 70 | Batch_idx: 110 |  Loss: (0.3323) |  Loss2: (0.0000) | Acc: (88.00%) (12593/14208)
Epoch: 70 | Batch_idx: 120 |  Loss: (0.3308) |  Loss2: (0.0000) | Acc: (88.00%) (13732/15488)
Epoch: 70 | Batch_idx: 130 |  Loss: (0.3325) |  Loss2: (0.0000) | Acc: (88.00%) (14853/16768)
Epoch: 70 | Batch_idx: 140 |  Loss: (0.3303) |  Loss2: (0.0000) | Acc: (88.00%) (16000/18048)
Epoch: 70 | Batch_idx: 150 |  Loss: (0.3323) |  Loss2: (0.0000) | Acc: (88.00%) (17122/19328)
Epoch: 70 | Batch_idx: 160 |  Loss: (0.3316) |  Loss2: (0.0000) | Acc: (88.00%) (18253/20608)
Epoch: 70 | Batch_idx: 170 |  Loss: (0.3328) |  Loss2: (0.0000) | Acc: (88.00%) (19385/21888)
Epoch: 70 | Batch_idx: 180 |  Loss: (0.3332) |  Loss2: (0.0000) | Acc: (88.00%) (20508/23168)
Epoch: 70 | Batch_idx: 190 |  Loss: (0.3336) |  Loss2: (0.0000) | Acc: (88.00%) (21631/24448)
Epoch: 70 | Batch_idx: 200 |  Loss: (0.3355) |  Loss2: (0.0000) | Acc: (88.00%) (22742/25728)
Epoch: 70 | Batch_idx: 210 |  Loss: (0.3361) |  Loss2: (0.0000) | Acc: (88.00%) (23878/27008)
Epoch: 70 | Batch_idx: 220 |  Loss: (0.3347) |  Loss2: (0.0000) | Acc: (88.00%) (25034/28288)
Epoch: 70 | Batch_idx: 230 |  Loss: (0.3348) |  Loss2: (0.0000) | Acc: (88.00%) (26168/29568)
Epoch: 70 | Batch_idx: 240 |  Loss: (0.3349) |  Loss2: (0.0000) | Acc: (88.00%) (27301/30848)
Epoch: 70 | Batch_idx: 250 |  Loss: (0.3349) |  Loss2: (0.0000) | Acc: (88.00%) (28433/32128)
Epoch: 70 | Batch_idx: 260 |  Loss: (0.3336) |  Loss2: (0.0000) | Acc: (88.00%) (29573/33408)
Epoch: 70 | Batch_idx: 270 |  Loss: (0.3340) |  Loss2: (0.0000) | Acc: (88.00%) (30705/34688)
Epoch: 70 | Batch_idx: 280 |  Loss: (0.3346) |  Loss2: (0.0000) | Acc: (88.00%) (31821/35968)
Epoch: 70 | Batch_idx: 290 |  Loss: (0.3352) |  Loss2: (0.0000) | Acc: (88.00%) (32949/37248)
Epoch: 70 | Batch_idx: 300 |  Loss: (0.3354) |  Loss2: (0.0000) | Acc: (88.00%) (34075/38528)
Epoch: 70 | Batch_idx: 310 |  Loss: (0.3348) |  Loss2: (0.0000) | Acc: (88.00%) (35216/39808)
Epoch: 70 | Batch_idx: 320 |  Loss: (0.3341) |  Loss2: (0.0000) | Acc: (88.00%) (36364/41088)
Epoch: 70 | Batch_idx: 330 |  Loss: (0.3331) |  Loss2: (0.0000) | Acc: (88.00%) (37522/42368)
Epoch: 70 | Batch_idx: 340 |  Loss: (0.3333) |  Loss2: (0.0000) | Acc: (88.00%) (38642/43648)
Epoch: 70 | Batch_idx: 350 |  Loss: (0.3328) |  Loss2: (0.0000) | Acc: (88.00%) (39794/44928)
Epoch: 70 | Batch_idx: 360 |  Loss: (0.3323) |  Loss2: (0.0000) | Acc: (88.00%) (40931/46208)
Epoch: 70 | Batch_idx: 370 |  Loss: (0.3325) |  Loss2: (0.0000) | Acc: (88.00%) (42049/47488)
Epoch: 70 | Batch_idx: 380 |  Loss: (0.3328) |  Loss2: (0.0000) | Acc: (88.00%) (43177/48768)
Epoch: 70 | Batch_idx: 390 |  Loss: (0.3328) |  Loss2: (0.0000) | Acc: (88.00%) (44266/50000)
=> saving checkpoint 'drive/app/torch/save_Schedule/checkpoint_070.pth.tar'
# TEST : Loss: (0.5100) | Acc: (83.00%) (8387/10000)
percent tensor([0.5464, 0.5566, 0.5695, 0.5631, 0.5712, 0.5544, 0.5624, 0.5646, 0.5511,
        0.5579, 0.5463, 0.5666, 0.5484, 0.5499, 0.5574, 0.5492],
       device='cuda:0') torch.Size([16])
percent tensor([0.5507, 0.5547, 0.5443, 0.5359, 0.5493, 0.5542, 0.5588, 0.5459, 0.5468,
        0.5495, 0.5540, 0.5533, 0.5508, 0.5466, 0.5574, 0.5515],
       device='cuda:0') torch.Size([16])
percent tensor([0.5893, 0.5845, 0.5700, 0.5598, 0.5693, 0.5794, 0.5852, 0.5676, 0.5756,
        0.5810, 0.5794, 0.5793, 0.5939, 0.5761, 0.5937, 0.5890],
       device='cuda:0') torch.Size([16])
percent tensor([0.6077, 0.6051, 0.5904, 0.5830, 0.5953, 0.6129, 0.6098, 0.5903, 0.6006,
        0.6122, 0.6088, 0.5990, 0.6044, 0.6062, 0.6085, 0.6113],
       device='cuda:0') torch.Size([16])
percent tensor([0.4810, 0.5060, 0.5411, 0.5641, 0.5570, 0.5375, 0.5147, 0.5506, 0.5434,
        0.4971, 0.5139, 0.5155, 0.4582, 0.5673, 0.5180, 0.5188],
       device='cuda:0') torch.Size([16])
percent tensor([0.4821, 0.5314, 0.5630, 0.5490, 0.6124, 0.5881, 0.5472, 0.5181, 0.5618,
        0.5095, 0.5529, 0.5410, 0.5073, 0.5616, 0.4706, 0.5085],
       device='cuda:0') torch.Size([16])
percent tensor([0.6211, 0.6175, 0.6691, 0.6378, 0.6845, 0.6397, 0.6487, 0.6245, 0.6346,
        0.6320, 0.6114, 0.6382, 0.6141, 0.6625, 0.5886, 0.6199],
       device='cuda:0') torch.Size([16])
percent tensor([0.9991, 0.9982, 0.9991, 0.9985, 0.9998, 0.9977, 0.9992, 0.9997, 0.9991,
        0.9994, 0.9985, 0.9989, 0.9986, 0.9991, 0.9986, 0.9992],
       device='cuda:0') torch.Size([16])
Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 3, 3, 3]) tensor(180.8897, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(797.6413, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(811.4717, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([128, 64, 3, 3]) tensor(1531.4281, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([128, 64, 1, 1]) tensor(504.3292, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([128, 128, 3, 3]) tensor(2212.8713, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([256, 128, 3, 3]) tensor(4285.7661, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([256, 128, 1, 1]) tensor(1404.2698, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([256, 256, 3, 3]) tensor(6096.3770, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([512, 256, 3, 3]) tensor(11974.4766, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([512, 256, 1, 1]) tensor(3985.3569, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([512, 512, 3, 3]) tensor(16845.2930, device='cuda:0', grad_fn=<NormBackward0>)
Epoch: 71 | Batch_idx: 0 |  Loss: (0.3541) |  Loss2: (0.0000) | Acc: (88.00%) (113/128)
Epoch: 71 | Batch_idx: 10 |  Loss: (0.3272) |  Loss2: (0.0000) | Acc: (89.00%) (1255/1408)
Epoch: 71 | Batch_idx: 20 |  Loss: (0.3337) |  Loss2: (0.0000) | Acc: (88.00%) (2384/2688)
Epoch: 71 | Batch_idx: 30 |  Loss: (0.3378) |  Loss2: (0.0000) | Acc: (88.00%) (3510/3968)
Epoch: 71 | Batch_idx: 40 |  Loss: (0.3361) |  Loss2: (0.0000) | Acc: (88.00%) (4652/5248)
Epoch: 71 | Batch_idx: 50 |  Loss: (0.3357) |  Loss2: (0.0000) | Acc: (88.00%) (5784/6528)
Epoch: 71 | Batch_idx: 60 |  Loss: (0.3277) |  Loss2: (0.0000) | Acc: (88.00%) (6929/7808)
Epoch: 71 | Batch_idx: 70 |  Loss: (0.3333) |  Loss2: (0.0000) | Acc: (88.00%) (8051/9088)
Epoch: 71 | Batch_idx: 80 |  Loss: (0.3346) |  Loss2: (0.0000) | Acc: (88.00%) (9171/10368)
Epoch: 71 | Batch_idx: 90 |  Loss: (0.3322) |  Loss2: (0.0000) | Acc: (88.00%) (10302/11648)
Epoch: 71 | Batch_idx: 100 |  Loss: (0.3328) |  Loss2: (0.0000) | Acc: (88.00%) (11433/12928)
Epoch: 71 | Batch_idx: 110 |  Loss: (0.3329) |  Loss2: (0.0000) | Acc: (88.00%) (12568/14208)
Epoch: 71 | Batch_idx: 120 |  Loss: (0.3353) |  Loss2: (0.0000) | Acc: (88.00%) (13696/15488)
Epoch: 71 | Batch_idx: 130 |  Loss: (0.3301) |  Loss2: (0.0000) | Acc: (88.00%) (14860/16768)
Epoch: 71 | Batch_idx: 140 |  Loss: (0.3313) |  Loss2: (0.0000) | Acc: (88.00%) (15981/18048)
Epoch: 71 | Batch_idx: 150 |  Loss: (0.3307) |  Loss2: (0.0000) | Acc: (88.00%) (17123/19328)
Epoch: 71 | Batch_idx: 160 |  Loss: (0.3285) |  Loss2: (0.0000) | Acc: (88.00%) (18275/20608)
Epoch: 71 | Batch_idx: 170 |  Loss: (0.3277) |  Loss2: (0.0000) | Acc: (88.00%) (19414/21888)
Epoch: 71 | Batch_idx: 180 |  Loss: (0.3269) |  Loss2: (0.0000) | Acc: (88.00%) (20553/23168)
Epoch: 71 | Batch_idx: 190 |  Loss: (0.3271) |  Loss2: (0.0000) | Acc: (88.00%) (21686/24448)
Epoch: 71 | Batch_idx: 200 |  Loss: (0.3271) |  Loss2: (0.0000) | Acc: (88.00%) (22820/25728)
Epoch: 71 | Batch_idx: 210 |  Loss: (0.3257) |  Loss2: (0.0000) | Acc: (88.00%) (23967/27008)
Epoch: 71 | Batch_idx: 220 |  Loss: (0.3248) |  Loss2: (0.0000) | Acc: (88.00%) (25116/28288)
Epoch: 71 | Batch_idx: 230 |  Loss: (0.3243) |  Loss2: (0.0000) | Acc: (88.00%) (26251/29568)
Epoch: 71 | Batch_idx: 240 |  Loss: (0.3237) |  Loss2: (0.0000) | Acc: (88.00%) (27390/30848)
Epoch: 71 | Batch_idx: 250 |  Loss: (0.3241) |  Loss2: (0.0000) | Acc: (88.00%) (28525/32128)
Epoch: 71 | Batch_idx: 260 |  Loss: (0.3240) |  Loss2: (0.0000) | Acc: (88.00%) (29661/33408)
Epoch: 71 | Batch_idx: 270 |  Loss: (0.3230) |  Loss2: (0.0000) | Acc: (88.00%) (30815/34688)
Epoch: 71 | Batch_idx: 280 |  Loss: (0.3234) |  Loss2: (0.0000) | Acc: (88.00%) (31939/35968)
Epoch: 71 | Batch_idx: 290 |  Loss: (0.3228) |  Loss2: (0.0000) | Acc: (88.00%) (33081/37248)
Epoch: 71 | Batch_idx: 300 |  Loss: (0.3222) |  Loss2: (0.0000) | Acc: (88.00%) (34223/38528)
Epoch: 71 | Batch_idx: 310 |  Loss: (0.3231) |  Loss2: (0.0000) | Acc: (88.00%) (35338/39808)
Epoch: 71 | Batch_idx: 320 |  Loss: (0.3234) |  Loss2: (0.0000) | Acc: (88.00%) (36471/41088)
Epoch: 71 | Batch_idx: 330 |  Loss: (0.3230) |  Loss2: (0.0000) | Acc: (88.00%) (37616/42368)
Epoch: 71 | Batch_idx: 340 |  Loss: (0.3236) |  Loss2: (0.0000) | Acc: (88.00%) (38745/43648)
Epoch: 71 | Batch_idx: 350 |  Loss: (0.3217) |  Loss2: (0.0000) | Acc: (88.00%) (39909/44928)
Epoch: 71 | Batch_idx: 360 |  Loss: (0.3219) |  Loss2: (0.0000) | Acc: (88.00%) (41040/46208)
Epoch: 71 | Batch_idx: 370 |  Loss: (0.3216) |  Loss2: (0.0000) | Acc: (88.00%) (42183/47488)
Epoch: 71 | Batch_idx: 380 |  Loss: (0.3221) |  Loss2: (0.0000) | Acc: (88.00%) (43302/48768)
Epoch: 71 | Batch_idx: 390 |  Loss: (0.3218) |  Loss2: (0.0000) | Acc: (88.00%) (44401/50000)
# TEST : Loss: (0.5129) | Acc: (83.00%) (8324/10000)
percent tensor([0.5480, 0.5544, 0.5778, 0.5639, 0.5777, 0.5548, 0.5635, 0.5668, 0.5536,
        0.5591, 0.5465, 0.5733, 0.5500, 0.5461, 0.5563, 0.5487],
       device='cuda:0') torch.Size([16])
percent tensor([0.5510, 0.5546, 0.5451, 0.5398, 0.5494, 0.5564, 0.5572, 0.5480, 0.5465,
        0.5492, 0.5533, 0.5519, 0.5516, 0.5444, 0.5597, 0.5526],
       device='cuda:0') torch.Size([16])
percent tensor([0.5893, 0.5830, 0.5700, 0.5578, 0.5659, 0.5782, 0.5820, 0.5674, 0.5722,
        0.5804, 0.5766, 0.5772, 0.5932, 0.5689, 0.5915, 0.5894],
       device='cuda:0') torch.Size([16])
percent tensor([0.6068, 0.6050, 0.5881, 0.5884, 0.5929, 0.6160, 0.6088, 0.5904, 0.6013,
        0.6123, 0.6096, 0.5959, 0.6036, 0.6080, 0.6106, 0.6132],
       device='cuda:0') torch.Size([16])
percent tensor([0.4873, 0.5003, 0.5464, 0.5577, 0.5650, 0.5435, 0.5203, 0.5492, 0.5500,
        0.4989, 0.5187, 0.5279, 0.4607, 0.5580, 0.5251, 0.5123],
       device='cuda:0') torch.Size([16])
percent tensor([0.4816, 0.5413, 0.5601, 0.5593, 0.6001, 0.5876, 0.5497, 0.5255, 0.5649,
        0.5043, 0.5528, 0.5465, 0.5090, 0.5810, 0.4777, 0.5038],
       device='cuda:0') torch.Size([16])
percent tensor([0.6114, 0.6098, 0.6658, 0.6477, 0.6783, 0.6466, 0.6455, 0.6410, 0.6340,
        0.6215, 0.6081, 0.6374, 0.6070, 0.6630, 0.5846, 0.6141],
       device='cuda:0') torch.Size([16])
percent tensor([0.9991, 0.9980, 0.9991, 0.9988, 0.9995, 0.9986, 0.9992, 0.9999, 0.9992,
        0.9988, 0.9990, 0.9991, 0.9984, 0.9991, 0.9984, 0.9990],
       device='cuda:0') torch.Size([16])
Epoch: 72 | Batch_idx: 0 |  Loss: (0.3398) |  Loss2: (0.0000) | Acc: (87.00%) (112/128)
Epoch: 72 | Batch_idx: 10 |  Loss: (0.2956) |  Loss2: (0.0000) | Acc: (90.00%) (1268/1408)
Epoch: 72 | Batch_idx: 20 |  Loss: (0.3049) |  Loss2: (0.0000) | Acc: (89.00%) (2400/2688)
Epoch: 72 | Batch_idx: 30 |  Loss: (0.3080) |  Loss2: (0.0000) | Acc: (89.00%) (3541/3968)
Epoch: 72 | Batch_idx: 40 |  Loss: (0.3116) |  Loss2: (0.0000) | Acc: (89.00%) (4680/5248)
Epoch: 72 | Batch_idx: 50 |  Loss: (0.3128) |  Loss2: (0.0000) | Acc: (89.00%) (5827/6528)
Epoch: 72 | Batch_idx: 60 |  Loss: (0.3089) |  Loss2: (0.0000) | Acc: (89.00%) (6976/7808)
Epoch: 72 | Batch_idx: 70 |  Loss: (0.3071) |  Loss2: (0.0000) | Acc: (89.00%) (8120/9088)
Epoch: 72 | Batch_idx: 80 |  Loss: (0.3050) |  Loss2: (0.0000) | Acc: (89.00%) (9269/10368)
Epoch: 72 | Batch_idx: 90 |  Loss: (0.3080) |  Loss2: (0.0000) | Acc: (89.00%) (10410/11648)
Epoch: 72 | Batch_idx: 100 |  Loss: (0.3066) |  Loss2: (0.0000) | Acc: (89.00%) (11563/12928)
Epoch: 72 | Batch_idx: 110 |  Loss: (0.3076) |  Loss2: (0.0000) | Acc: (89.00%) (12710/14208)
Epoch: 72 | Batch_idx: 120 |  Loss: (0.3081) |  Loss2: (0.0000) | Acc: (89.00%) (13843/15488)
Epoch: 72 | Batch_idx: 130 |  Loss: (0.3102) |  Loss2: (0.0000) | Acc: (89.00%) (14967/16768)
Epoch: 72 | Batch_idx: 140 |  Loss: (0.3112) |  Loss2: (0.0000) | Acc: (89.00%) (16099/18048)
Epoch: 72 | Batch_idx: 150 |  Loss: (0.3101) |  Loss2: (0.0000) | Acc: (89.00%) (17247/19328)
Epoch: 72 | Batch_idx: 160 |  Loss: (0.3103) |  Loss2: (0.0000) | Acc: (89.00%) (18392/20608)
Epoch: 72 | Batch_idx: 170 |  Loss: (0.3102) |  Loss2: (0.0000) | Acc: (89.00%) (19533/21888)
Epoch: 72 | Batch_idx: 180 |  Loss: (0.3122) |  Loss2: (0.0000) | Acc: (89.00%) (20660/23168)
Epoch: 72 | Batch_idx: 190 |  Loss: (0.3134) |  Loss2: (0.0000) | Acc: (89.00%) (21784/24448)
Epoch: 72 | Batch_idx: 200 |  Loss: (0.3138) |  Loss2: (0.0000) | Acc: (89.00%) (22934/25728)
Epoch: 72 | Batch_idx: 210 |  Loss: (0.3137) |  Loss2: (0.0000) | Acc: (89.00%) (24077/27008)
Epoch: 72 | Batch_idx: 220 |  Loss: (0.3130) |  Loss2: (0.0000) | Acc: (89.00%) (25234/28288)
Epoch: 72 | Batch_idx: 230 |  Loss: (0.3136) |  Loss2: (0.0000) | Acc: (89.00%) (26371/29568)
Epoch: 72 | Batch_idx: 240 |  Loss: (0.3135) |  Loss2: (0.0000) | Acc: (89.00%) (27513/30848)
Epoch: 72 | Batch_idx: 250 |  Loss: (0.3135) |  Loss2: (0.0000) | Acc: (89.00%) (28659/32128)
Epoch: 72 | Batch_idx: 260 |  Loss: (0.3145) |  Loss2: (0.0000) | Acc: (89.00%) (29791/33408)
Epoch: 72 | Batch_idx: 270 |  Loss: (0.3130) |  Loss2: (0.0000) | Acc: (89.00%) (30949/34688)
Epoch: 72 | Batch_idx: 280 |  Loss: (0.3140) |  Loss2: (0.0000) | Acc: (89.00%) (32074/35968)
Epoch: 72 | Batch_idx: 290 |  Loss: (0.3132) |  Loss2: (0.0000) | Acc: (89.00%) (33218/37248)
Epoch: 72 | Batch_idx: 300 |  Loss: (0.3127) |  Loss2: (0.0000) | Acc: (89.00%) (34363/38528)
Epoch: 72 | Batch_idx: 310 |  Loss: (0.3131) |  Loss2: (0.0000) | Acc: (89.00%) (35493/39808)
Epoch: 72 | Batch_idx: 320 |  Loss: (0.3125) |  Loss2: (0.0000) | Acc: (89.00%) (36650/41088)
Epoch: 72 | Batch_idx: 330 |  Loss: (0.3128) |  Loss2: (0.0000) | Acc: (89.00%) (37778/42368)
Epoch: 72 | Batch_idx: 340 |  Loss: (0.3121) |  Loss2: (0.0000) | Acc: (89.00%) (38926/43648)
Epoch: 72 | Batch_idx: 350 |  Loss: (0.3122) |  Loss2: (0.0000) | Acc: (89.00%) (40074/44928)
Epoch: 72 | Batch_idx: 360 |  Loss: (0.3121) |  Loss2: (0.0000) | Acc: (89.00%) (41227/46208)
Epoch: 72 | Batch_idx: 370 |  Loss: (0.3114) |  Loss2: (0.0000) | Acc: (89.00%) (42390/47488)
Epoch: 72 | Batch_idx: 380 |  Loss: (0.3115) |  Loss2: (0.0000) | Acc: (89.00%) (43538/48768)
Epoch: 72 | Batch_idx: 390 |  Loss: (0.3117) |  Loss2: (0.0000) | Acc: (89.00%) (44628/50000)
# TEST : Loss: (0.4748) | Acc: (84.00%) (8457/10000)
percent tensor([0.5463, 0.5549, 0.5711, 0.5623, 0.5719, 0.5529, 0.5610, 0.5643, 0.5520,
        0.5574, 0.5461, 0.5664, 0.5481, 0.5478, 0.5557, 0.5483],
       device='cuda:0') torch.Size([16])
percent tensor([0.5516, 0.5584, 0.5441, 0.5380, 0.5487, 0.5551, 0.5601, 0.5468, 0.5483,
        0.5517, 0.5560, 0.5527, 0.5526, 0.5500, 0.5604, 0.5536],
       device='cuda:0') torch.Size([16])
percent tensor([0.5900, 0.5867, 0.5678, 0.5574, 0.5661, 0.5800, 0.5849, 0.5707, 0.5755,
        0.5806, 0.5800, 0.5747, 0.5952, 0.5734, 0.5944, 0.5917],
       device='cuda:0') torch.Size([16])
percent tensor([0.6105, 0.6111, 0.5911, 0.5870, 0.5960, 0.6179, 0.6142, 0.5892, 0.6031,
        0.6158, 0.6136, 0.6015, 0.6089, 0.6152, 0.6118, 0.6150],
       device='cuda:0') torch.Size([16])
percent tensor([0.4897, 0.4942, 0.5503, 0.5556, 0.5648, 0.5514, 0.5193, 0.5438, 0.5419,
        0.5005, 0.5188, 0.5139, 0.4602, 0.5454, 0.5244, 0.5115],
       device='cuda:0') torch.Size([16])
percent tensor([0.4756, 0.5230, 0.5454, 0.5409, 0.5922, 0.5844, 0.5368, 0.5201, 0.5474,
        0.4924, 0.5429, 0.5204, 0.4645, 0.5641, 0.4595, 0.5004],
       device='cuda:0') torch.Size([16])
percent tensor([0.6175, 0.6061, 0.6594, 0.6330, 0.6670, 0.6522, 0.6442, 0.6302, 0.6308,
        0.6225, 0.6094, 0.6253, 0.6087, 0.6494, 0.5806, 0.6166],
       device='cuda:0') torch.Size([16])
percent tensor([0.9989, 0.9981, 0.9993, 0.9989, 0.9995, 0.9986, 0.9993, 0.9998, 0.9992,
        0.9990, 0.9988, 0.9988, 0.9986, 0.9989, 0.9993, 0.9991],
       device='cuda:0') torch.Size([16])
Epoch: 73 | Batch_idx: 0 |  Loss: (0.2837) |  Loss2: (0.0000) | Acc: (88.00%) (113/128)
Epoch: 73 | Batch_idx: 10 |  Loss: (0.2933) |  Loss2: (0.0000) | Acc: (89.00%) (1256/1408)
Epoch: 73 | Batch_idx: 20 |  Loss: (0.3059) |  Loss2: (0.0000) | Acc: (89.00%) (2394/2688)
Epoch: 73 | Batch_idx: 30 |  Loss: (0.2963) |  Loss2: (0.0000) | Acc: (89.00%) (3548/3968)
Epoch: 73 | Batch_idx: 40 |  Loss: (0.3019) |  Loss2: (0.0000) | Acc: (89.00%) (4692/5248)
Epoch: 73 | Batch_idx: 50 |  Loss: (0.3061) |  Loss2: (0.0000) | Acc: (89.00%) (5837/6528)
Epoch: 73 | Batch_idx: 60 |  Loss: (0.2984) |  Loss2: (0.0000) | Acc: (89.00%) (6997/7808)
Epoch: 73 | Batch_idx: 70 |  Loss: (0.2945) |  Loss2: (0.0000) | Acc: (89.00%) (8161/9088)
Epoch: 73 | Batch_idx: 80 |  Loss: (0.2933) |  Loss2: (0.0000) | Acc: (89.00%) (9307/10368)
Epoch: 73 | Batch_idx: 90 |  Loss: (0.2940) |  Loss2: (0.0000) | Acc: (89.00%) (10465/11648)
Epoch: 73 | Batch_idx: 100 |  Loss: (0.3004) |  Loss2: (0.0000) | Acc: (89.00%) (11583/12928)
Epoch: 73 | Batch_idx: 110 |  Loss: (0.3015) |  Loss2: (0.0000) | Acc: (89.00%) (12722/14208)
Epoch: 73 | Batch_idx: 120 |  Loss: (0.3018) |  Loss2: (0.0000) | Acc: (89.00%) (13864/15488)
Epoch: 73 | Batch_idx: 130 |  Loss: (0.3013) |  Loss2: (0.0000) | Acc: (89.00%) (15018/16768)
Epoch: 73 | Batch_idx: 140 |  Loss: (0.3011) |  Loss2: (0.0000) | Acc: (89.00%) (16164/18048)
Epoch: 73 | Batch_idx: 150 |  Loss: (0.3043) |  Loss2: (0.0000) | Acc: (89.00%) (17290/19328)
Epoch: 73 | Batch_idx: 160 |  Loss: (0.3049) |  Loss2: (0.0000) | Acc: (89.00%) (18435/20608)
Epoch: 73 | Batch_idx: 170 |  Loss: (0.3033) |  Loss2: (0.0000) | Acc: (89.00%) (19588/21888)
Epoch: 73 | Batch_idx: 180 |  Loss: (0.3027) |  Loss2: (0.0000) | Acc: (89.00%) (20738/23168)
Epoch: 73 | Batch_idx: 190 |  Loss: (0.3028) |  Loss2: (0.0000) | Acc: (89.00%) (21880/24448)
Epoch: 73 | Batch_idx: 200 |  Loss: (0.3037) |  Loss2: (0.0000) | Acc: (89.00%) (23028/25728)
Epoch: 73 | Batch_idx: 210 |  Loss: (0.3036) |  Loss2: (0.0000) | Acc: (89.00%) (24182/27008)
Epoch: 73 | Batch_idx: 220 |  Loss: (0.3038) |  Loss2: (0.0000) | Acc: (89.00%) (25318/28288)
Epoch: 73 | Batch_idx: 230 |  Loss: (0.3029) |  Loss2: (0.0000) | Acc: (89.00%) (26474/29568)
Epoch: 73 | Batch_idx: 240 |  Loss: (0.3032) |  Loss2: (0.0000) | Acc: (89.00%) (27626/30848)
Epoch: 73 | Batch_idx: 250 |  Loss: (0.3031) |  Loss2: (0.0000) | Acc: (89.00%) (28778/32128)
Epoch: 73 | Batch_idx: 260 |  Loss: (0.3047) |  Loss2: (0.0000) | Acc: (89.00%) (29903/33408)
Epoch: 73 | Batch_idx: 270 |  Loss: (0.3046) |  Loss2: (0.0000) | Acc: (89.00%) (31034/34688)
Epoch: 73 | Batch_idx: 280 |  Loss: (0.3043) |  Loss2: (0.0000) | Acc: (89.00%) (32186/35968)
Epoch: 73 | Batch_idx: 290 |  Loss: (0.3041) |  Loss2: (0.0000) | Acc: (89.00%) (33345/37248)
Epoch: 73 | Batch_idx: 300 |  Loss: (0.3049) |  Loss2: (0.0000) | Acc: (89.00%) (34479/38528)
Epoch: 73 | Batch_idx: 310 |  Loss: (0.3043) |  Loss2: (0.0000) | Acc: (89.00%) (35639/39808)
Epoch: 73 | Batch_idx: 320 |  Loss: (0.3041) |  Loss2: (0.0000) | Acc: (89.00%) (36806/41088)
Epoch: 73 | Batch_idx: 330 |  Loss: (0.3040) |  Loss2: (0.0000) | Acc: (89.00%) (37947/42368)
Epoch: 73 | Batch_idx: 340 |  Loss: (0.3033) |  Loss2: (0.0000) | Acc: (89.00%) (39109/43648)
Epoch: 73 | Batch_idx: 350 |  Loss: (0.3032) |  Loss2: (0.0000) | Acc: (89.00%) (40261/44928)
Epoch: 73 | Batch_idx: 360 |  Loss: (0.3029) |  Loss2: (0.0000) | Acc: (89.00%) (41408/46208)
Epoch: 73 | Batch_idx: 370 |  Loss: (0.3022) |  Loss2: (0.0000) | Acc: (89.00%) (42563/47488)
Epoch: 73 | Batch_idx: 380 |  Loss: (0.3030) |  Loss2: (0.0000) | Acc: (89.00%) (43700/48768)
Epoch: 73 | Batch_idx: 390 |  Loss: (0.3027) |  Loss2: (0.0000) | Acc: (89.00%) (44810/50000)
# TEST : Loss: (0.5130) | Acc: (83.00%) (8332/10000)
percent tensor([0.5465, 0.5544, 0.5736, 0.5638, 0.5736, 0.5521, 0.5618, 0.5661, 0.5512,
        0.5586, 0.5454, 0.5699, 0.5486, 0.5467, 0.5558, 0.5487],
       device='cuda:0') torch.Size([16])
percent tensor([0.5511, 0.5537, 0.5467, 0.5362, 0.5493, 0.5559, 0.5576, 0.5467, 0.5476,
        0.5491, 0.5543, 0.5539, 0.5516, 0.5442, 0.5577, 0.5514],
       device='cuda:0') torch.Size([16])
percent tensor([0.5909, 0.5851, 0.5710, 0.5627, 0.5671, 0.5806, 0.5837, 0.5682, 0.5758,
        0.5806, 0.5785, 0.5778, 0.5952, 0.5750, 0.5940, 0.5913],
       device='cuda:0') torch.Size([16])
percent tensor([0.6104, 0.6079, 0.5901, 0.5842, 0.5937, 0.6135, 0.6112, 0.5905, 0.6027,
        0.6149, 0.6121, 0.5978, 0.6078, 0.6102, 0.6096, 0.6128],
       device='cuda:0') torch.Size([16])
percent tensor([0.4762, 0.4815, 0.5399, 0.5544, 0.5610, 0.5408, 0.5100, 0.5459, 0.5369,
        0.4858, 0.5071, 0.5092, 0.4433, 0.5568, 0.5193, 0.5141],
       device='cuda:0') torch.Size([16])
percent tensor([0.4857, 0.5257, 0.5582, 0.5492, 0.5992, 0.5901, 0.5472, 0.5366, 0.5541,
        0.5023, 0.5542, 0.5226, 0.4892, 0.5546, 0.4764, 0.5028],
       device='cuda:0') torch.Size([16])
percent tensor([0.6175, 0.5929, 0.6698, 0.6335, 0.6800, 0.6459, 0.6423, 0.6340, 0.6235,
        0.6154, 0.6052, 0.6222, 0.5950, 0.6495, 0.5788, 0.6151],
       device='cuda:0') torch.Size([16])
percent tensor([0.9993, 0.9983, 0.9994, 0.9987, 0.9997, 0.9982, 0.9997, 0.9998, 0.9995,
        0.9994, 0.9994, 0.9994, 0.9986, 0.9996, 0.9993, 0.9993],
       device='cuda:0') torch.Size([16])
Epoch: 74 | Batch_idx: 0 |  Loss: (0.3532) |  Loss2: (0.0000) | Acc: (86.00%) (111/128)
Epoch: 74 | Batch_idx: 10 |  Loss: (0.3034) |  Loss2: (0.0000) | Acc: (89.00%) (1256/1408)
Epoch: 74 | Batch_idx: 20 |  Loss: (0.3014) |  Loss2: (0.0000) | Acc: (89.00%) (2397/2688)
Epoch: 74 | Batch_idx: 30 |  Loss: (0.2956) |  Loss2: (0.0000) | Acc: (89.00%) (3558/3968)
Epoch: 74 | Batch_idx: 40 |  Loss: (0.2921) |  Loss2: (0.0000) | Acc: (89.00%) (4710/5248)
Epoch: 74 | Batch_idx: 50 |  Loss: (0.2914) |  Loss2: (0.0000) | Acc: (90.00%) (5877/6528)
Epoch: 74 | Batch_idx: 60 |  Loss: (0.2900) |  Loss2: (0.0000) | Acc: (90.00%) (7031/7808)
Epoch: 74 | Batch_idx: 70 |  Loss: (0.2927) |  Loss2: (0.0000) | Acc: (89.00%) (8168/9088)
Epoch: 74 | Batch_idx: 80 |  Loss: (0.2945) |  Loss2: (0.0000) | Acc: (89.00%) (9311/10368)
Epoch: 74 | Batch_idx: 90 |  Loss: (0.2941) |  Loss2: (0.0000) | Acc: (89.00%) (10458/11648)
Epoch: 74 | Batch_idx: 100 |  Loss: (0.2919) |  Loss2: (0.0000) | Acc: (89.00%) (11614/12928)
Epoch: 74 | Batch_idx: 110 |  Loss: (0.2953) |  Loss2: (0.0000) | Acc: (89.00%) (12758/14208)
Epoch: 74 | Batch_idx: 120 |  Loss: (0.2939) |  Loss2: (0.0000) | Acc: (89.00%) (13916/15488)
Epoch: 74 | Batch_idx: 130 |  Loss: (0.2939) |  Loss2: (0.0000) | Acc: (89.00%) (15070/16768)
Epoch: 74 | Batch_idx: 140 |  Loss: (0.2922) |  Loss2: (0.0000) | Acc: (89.00%) (16236/18048)
Epoch: 74 | Batch_idx: 150 |  Loss: (0.2914) |  Loss2: (0.0000) | Acc: (89.00%) (17381/19328)
Epoch: 74 | Batch_idx: 160 |  Loss: (0.2929) |  Loss2: (0.0000) | Acc: (89.00%) (18527/20608)
Epoch: 74 | Batch_idx: 170 |  Loss: (0.2921) |  Loss2: (0.0000) | Acc: (89.00%) (19692/21888)
Epoch: 74 | Batch_idx: 180 |  Loss: (0.2925) |  Loss2: (0.0000) | Acc: (89.00%) (20838/23168)
Epoch: 74 | Batch_idx: 190 |  Loss: (0.2935) |  Loss2: (0.0000) | Acc: (89.00%) (21970/24448)
Epoch: 74 | Batch_idx: 200 |  Loss: (0.2911) |  Loss2: (0.0000) | Acc: (89.00%) (23143/25728)
Epoch: 74 | Batch_idx: 210 |  Loss: (0.2934) |  Loss2: (0.0000) | Acc: (89.00%) (24277/27008)
Epoch: 74 | Batch_idx: 220 |  Loss: (0.2947) |  Loss2: (0.0000) | Acc: (89.00%) (25418/28288)
Epoch: 74 | Batch_idx: 230 |  Loss: (0.2933) |  Loss2: (0.0000) | Acc: (89.00%) (26595/29568)
Epoch: 74 | Batch_idx: 240 |  Loss: (0.2933) |  Loss2: (0.0000) | Acc: (89.00%) (27750/30848)
Epoch: 74 | Batch_idx: 250 |  Loss: (0.2936) |  Loss2: (0.0000) | Acc: (89.00%) (28896/32128)
Epoch: 74 | Batch_idx: 260 |  Loss: (0.2942) |  Loss2: (0.0000) | Acc: (89.00%) (30041/33408)
Epoch: 74 | Batch_idx: 270 |  Loss: (0.2946) |  Loss2: (0.0000) | Acc: (89.00%) (31175/34688)
Epoch: 74 | Batch_idx: 280 |  Loss: (0.2956) |  Loss2: (0.0000) | Acc: (89.00%) (32310/35968)
Epoch: 74 | Batch_idx: 290 |  Loss: (0.2961) |  Loss2: (0.0000) | Acc: (89.00%) (33458/37248)
Epoch: 74 | Batch_idx: 300 |  Loss: (0.2960) |  Loss2: (0.0000) | Acc: (89.00%) (34608/38528)
Epoch: 74 | Batch_idx: 310 |  Loss: (0.2958) |  Loss2: (0.0000) | Acc: (89.00%) (35765/39808)
Epoch: 74 | Batch_idx: 320 |  Loss: (0.2957) |  Loss2: (0.0000) | Acc: (89.00%) (36929/41088)
Epoch: 74 | Batch_idx: 330 |  Loss: (0.2958) |  Loss2: (0.0000) | Acc: (89.00%) (38069/42368)
Epoch: 74 | Batch_idx: 340 |  Loss: (0.2950) |  Loss2: (0.0000) | Acc: (89.00%) (39221/43648)
Epoch: 74 | Batch_idx: 350 |  Loss: (0.2955) |  Loss2: (0.0000) | Acc: (89.00%) (40365/44928)
Epoch: 74 | Batch_idx: 360 |  Loss: (0.2947) |  Loss2: (0.0000) | Acc: (89.00%) (41537/46208)
Epoch: 74 | Batch_idx: 370 |  Loss: (0.2956) |  Loss2: (0.0000) | Acc: (89.00%) (42664/47488)
Epoch: 74 | Batch_idx: 380 |  Loss: (0.2952) |  Loss2: (0.0000) | Acc: (89.00%) (43814/48768)
Epoch: 74 | Batch_idx: 390 |  Loss: (0.2958) |  Loss2: (0.0000) | Acc: (89.00%) (44918/50000)
# TEST : Loss: (0.5191) | Acc: (83.00%) (8335/10000)
percent tensor([0.5465, 0.5570, 0.5692, 0.5620, 0.5705, 0.5531, 0.5618, 0.5648, 0.5515,
        0.5576, 0.5466, 0.5660, 0.5488, 0.5508, 0.5565, 0.5492],
       device='cuda:0') torch.Size([16])
percent tensor([0.5514, 0.5553, 0.5449, 0.5383, 0.5497, 0.5571, 0.5587, 0.5471, 0.5466,
        0.5501, 0.5546, 0.5538, 0.5517, 0.5457, 0.5599, 0.5525],
       device='cuda:0') torch.Size([16])
percent tensor([0.5863, 0.5832, 0.5639, 0.5572, 0.5622, 0.5769, 0.5814, 0.5660, 0.5700,
        0.5778, 0.5753, 0.5712, 0.5918, 0.5690, 0.5919, 0.5885],
       device='cuda:0') torch.Size([16])
percent tensor([0.6103, 0.6062, 0.5901, 0.5874, 0.5960, 0.6188, 0.6108, 0.5903, 0.6009,
        0.6116, 0.6116, 0.5980, 0.6061, 0.6095, 0.6133, 0.6132],
       device='cuda:0') torch.Size([16])
percent tensor([0.4986, 0.4955, 0.5576, 0.5636, 0.5694, 0.5514, 0.5133, 0.5525, 0.5483,
        0.4972, 0.5111, 0.5284, 0.4665, 0.5573, 0.5300, 0.5203],
       device='cuda:0') torch.Size([16])
percent tensor([0.4729, 0.5156, 0.5540, 0.5682, 0.6016, 0.5859, 0.5359, 0.5214, 0.5489,
        0.4699, 0.5389, 0.5328, 0.4835, 0.5587, 0.4773, 0.4878],
       device='cuda:0') torch.Size([16])
percent tensor([0.6136, 0.5950, 0.6684, 0.6337, 0.6830, 0.6380, 0.6347, 0.6316, 0.6279,
        0.5997, 0.6086, 0.6328, 0.6043, 0.6409, 0.5777, 0.6017],
       device='cuda:0') torch.Size([16])
percent tensor([0.9990, 0.9985, 0.9996, 0.9981, 0.9998, 0.9976, 0.9994, 0.9998, 0.9996,
        0.9990, 0.9995, 0.9993, 0.9985, 0.9987, 0.9988, 0.9990],
       device='cuda:0') torch.Size([16])
Epoch: 75 | Batch_idx: 0 |  Loss: (0.3810) |  Loss2: (0.0000) | Acc: (85.00%) (110/128)
Epoch: 75 | Batch_idx: 10 |  Loss: (0.2763) |  Loss2: (0.0000) | Acc: (90.00%) (1271/1408)
Epoch: 75 | Batch_idx: 20 |  Loss: (0.2926) |  Loss2: (0.0000) | Acc: (89.00%) (2411/2688)
Epoch: 75 | Batch_idx: 30 |  Loss: (0.2926) |  Loss2: (0.0000) | Acc: (89.00%) (3568/3968)
Epoch: 75 | Batch_idx: 40 |  Loss: (0.2903) |  Loss2: (0.0000) | Acc: (90.00%) (4733/5248)
Epoch: 75 | Batch_idx: 50 |  Loss: (0.2833) |  Loss2: (0.0000) | Acc: (90.00%) (5890/6528)
Epoch: 75 | Batch_idx: 60 |  Loss: (0.2813) |  Loss2: (0.0000) | Acc: (90.00%) (7045/7808)
Epoch: 75 | Batch_idx: 70 |  Loss: (0.2805) |  Loss2: (0.0000) | Acc: (90.00%) (8189/9088)
Epoch: 75 | Batch_idx: 80 |  Loss: (0.2810) |  Loss2: (0.0000) | Acc: (90.00%) (9337/10368)
Epoch: 75 | Batch_idx: 90 |  Loss: (0.2807) |  Loss2: (0.0000) | Acc: (90.00%) (10501/11648)
Epoch: 75 | Batch_idx: 100 |  Loss: (0.2803) |  Loss2: (0.0000) | Acc: (90.00%) (11662/12928)
Epoch: 75 | Batch_idx: 110 |  Loss: (0.2809) |  Loss2: (0.0000) | Acc: (90.00%) (12813/14208)
Epoch: 75 | Batch_idx: 120 |  Loss: (0.2791) |  Loss2: (0.0000) | Acc: (90.00%) (13974/15488)
Epoch: 75 | Batch_idx: 130 |  Loss: (0.2827) |  Loss2: (0.0000) | Acc: (90.00%) (15108/16768)
Epoch: 75 | Batch_idx: 140 |  Loss: (0.2835) |  Loss2: (0.0000) | Acc: (90.00%) (16248/18048)
Epoch: 75 | Batch_idx: 150 |  Loss: (0.2849) |  Loss2: (0.0000) | Acc: (89.00%) (17389/19328)
Epoch: 75 | Batch_idx: 160 |  Loss: (0.2863) |  Loss2: (0.0000) | Acc: (89.00%) (18539/20608)
Epoch: 75 | Batch_idx: 170 |  Loss: (0.2879) |  Loss2: (0.0000) | Acc: (89.00%) (19677/21888)
Epoch: 75 | Batch_idx: 180 |  Loss: (0.2875) |  Loss2: (0.0000) | Acc: (89.00%) (20835/23168)
Epoch: 75 | Batch_idx: 190 |  Loss: (0.2872) |  Loss2: (0.0000) | Acc: (89.00%) (21980/24448)
Epoch: 75 | Batch_idx: 200 |  Loss: (0.2885) |  Loss2: (0.0000) | Acc: (89.00%) (23114/25728)
Epoch: 75 | Batch_idx: 210 |  Loss: (0.2887) |  Loss2: (0.0000) | Acc: (89.00%) (24260/27008)
Epoch: 75 | Batch_idx: 220 |  Loss: (0.2889) |  Loss2: (0.0000) | Acc: (89.00%) (25413/28288)
Epoch: 75 | Batch_idx: 230 |  Loss: (0.2892) |  Loss2: (0.0000) | Acc: (89.00%) (26564/29568)
Epoch: 75 | Batch_idx: 240 |  Loss: (0.2879) |  Loss2: (0.0000) | Acc: (89.00%) (27735/30848)
Epoch: 75 | Batch_idx: 250 |  Loss: (0.2877) |  Loss2: (0.0000) | Acc: (89.00%) (28889/32128)
Epoch: 75 | Batch_idx: 260 |  Loss: (0.2871) |  Loss2: (0.0000) | Acc: (89.00%) (30042/33408)
Epoch: 75 | Batch_idx: 270 |  Loss: (0.2872) |  Loss2: (0.0000) | Acc: (89.00%) (31185/34688)
Epoch: 75 | Batch_idx: 280 |  Loss: (0.2874) |  Loss2: (0.0000) | Acc: (89.00%) (32331/35968)
Epoch: 75 | Batch_idx: 290 |  Loss: (0.2866) |  Loss2: (0.0000) | Acc: (89.00%) (33495/37248)
Epoch: 75 | Batch_idx: 300 |  Loss: (0.2864) |  Loss2: (0.0000) | Acc: (89.00%) (34654/38528)
Epoch: 75 | Batch_idx: 310 |  Loss: (0.2867) |  Loss2: (0.0000) | Acc: (89.00%) (35800/39808)
Epoch: 75 | Batch_idx: 320 |  Loss: (0.2861) |  Loss2: (0.0000) | Acc: (89.00%) (36951/41088)
Epoch: 75 | Batch_idx: 330 |  Loss: (0.2854) |  Loss2: (0.0000) | Acc: (89.00%) (38112/42368)
Epoch: 75 | Batch_idx: 340 |  Loss: (0.2859) |  Loss2: (0.0000) | Acc: (89.00%) (39260/43648)
Epoch: 75 | Batch_idx: 350 |  Loss: (0.2863) |  Loss2: (0.0000) | Acc: (89.00%) (40411/44928)
Epoch: 75 | Batch_idx: 360 |  Loss: (0.2862) |  Loss2: (0.0000) | Acc: (89.00%) (41559/46208)
Epoch: 75 | Batch_idx: 370 |  Loss: (0.2865) |  Loss2: (0.0000) | Acc: (89.00%) (42703/47488)
Epoch: 75 | Batch_idx: 380 |  Loss: (0.2870) |  Loss2: (0.0000) | Acc: (89.00%) (43848/48768)
Epoch: 75 | Batch_idx: 390 |  Loss: (0.2869) |  Loss2: (0.0000) | Acc: (89.00%) (44963/50000)
=> saving checkpoint 'drive/app/torch/save_Schedule/checkpoint_075.pth.tar'
# TEST : Loss: (0.4961) | Acc: (84.00%) (8407/10000)
percent tensor([0.5472, 0.5554, 0.5700, 0.5624, 0.5711, 0.5537, 0.5609, 0.5645, 0.5514,
        0.5570, 0.5464, 0.5663, 0.5487, 0.5488, 0.5565, 0.5488],
       device='cuda:0') torch.Size([16])
percent tensor([0.5514, 0.5567, 0.5432, 0.5378, 0.5474, 0.5557, 0.5584, 0.5475, 0.5470,
        0.5502, 0.5557, 0.5518, 0.5521, 0.5474, 0.5597, 0.5527],
       device='cuda:0') torch.Size([16])
percent tensor([0.5927, 0.5874, 0.5683, 0.5592, 0.5655, 0.5852, 0.5851, 0.5671, 0.5749,
        0.5803, 0.5824, 0.5759, 0.5979, 0.5703, 0.5972, 0.5929],
       device='cuda:0') torch.Size([16])
percent tensor([0.6092, 0.6086, 0.5867, 0.5837, 0.5930, 0.6155, 0.6106, 0.5894, 0.6021,
        0.6140, 0.6133, 0.5961, 0.6073, 0.6107, 0.6117, 0.6135],
       device='cuda:0') torch.Size([16])
percent tensor([0.4848, 0.4964, 0.5560, 0.5581, 0.5674, 0.5369, 0.5190, 0.5548, 0.5408,
        0.5032, 0.5126, 0.5288, 0.4494, 0.5587, 0.5174, 0.5156],
       device='cuda:0') torch.Size([16])
percent tensor([0.4973, 0.5448, 0.5583, 0.5567, 0.6028, 0.5977, 0.5447, 0.5264, 0.5595,
        0.5078, 0.5621, 0.5376, 0.5067, 0.5697, 0.4889, 0.5136],
       device='cuda:0') torch.Size([16])
percent tensor([0.6110, 0.6043, 0.6687, 0.6372, 0.6771, 0.6404, 0.6402, 0.6341, 0.6275,
        0.6177, 0.6100, 0.6308, 0.6092, 0.6523, 0.5779, 0.6048],
       device='cuda:0') torch.Size([16])
percent tensor([0.9989, 0.9977, 0.9997, 0.9987, 0.9997, 0.9979, 0.9994, 0.9999, 0.9994,
        0.9992, 0.9993, 0.9990, 0.9986, 0.9988, 0.9992, 0.9987],
       device='cuda:0') torch.Size([16])
Epoch: 76 | Batch_idx: 0 |  Loss: (0.3422) |  Loss2: (0.0000) | Acc: (89.00%) (114/128)
Epoch: 76 | Batch_idx: 10 |  Loss: (0.2962) |  Loss2: (0.0000) | Acc: (88.00%) (1253/1408)
Epoch: 76 | Batch_idx: 20 |  Loss: (0.2884) |  Loss2: (0.0000) | Acc: (90.00%) (2424/2688)
Epoch: 76 | Batch_idx: 30 |  Loss: (0.2857) |  Loss2: (0.0000) | Acc: (90.00%) (3583/3968)
Epoch: 76 | Batch_idx: 40 |  Loss: (0.2840) |  Loss2: (0.0000) | Acc: (90.00%) (4743/5248)
Epoch: 76 | Batch_idx: 50 |  Loss: (0.2813) |  Loss2: (0.0000) | Acc: (90.00%) (5900/6528)
Epoch: 76 | Batch_idx: 60 |  Loss: (0.2763) |  Loss2: (0.0000) | Acc: (90.00%) (7066/7808)
Epoch: 76 | Batch_idx: 70 |  Loss: (0.2792) |  Loss2: (0.0000) | Acc: (90.00%) (8220/9088)
Epoch: 76 | Batch_idx: 80 |  Loss: (0.2865) |  Loss2: (0.0000) | Acc: (90.00%) (9355/10368)
Epoch: 76 | Batch_idx: 90 |  Loss: (0.2827) |  Loss2: (0.0000) | Acc: (90.00%) (10524/11648)
Epoch: 76 | Batch_idx: 100 |  Loss: (0.2826) |  Loss2: (0.0000) | Acc: (90.00%) (11681/12928)
Epoch: 76 | Batch_idx: 110 |  Loss: (0.2812) |  Loss2: (0.0000) | Acc: (90.00%) (12846/14208)
Epoch: 76 | Batch_idx: 120 |  Loss: (0.2810) |  Loss2: (0.0000) | Acc: (90.00%) (14005/15488)
Epoch: 76 | Batch_idx: 130 |  Loss: (0.2796) |  Loss2: (0.0000) | Acc: (90.00%) (15165/16768)
Epoch: 76 | Batch_idx: 140 |  Loss: (0.2784) |  Loss2: (0.0000) | Acc: (90.00%) (16323/18048)
Epoch: 76 | Batch_idx: 150 |  Loss: (0.2786) |  Loss2: (0.0000) | Acc: (90.00%) (17479/19328)
Epoch: 76 | Batch_idx: 160 |  Loss: (0.2784) |  Loss2: (0.0000) | Acc: (90.00%) (18632/20608)
Epoch: 76 | Batch_idx: 170 |  Loss: (0.2784) |  Loss2: (0.0000) | Acc: (90.00%) (19791/21888)
Epoch: 76 | Batch_idx: 180 |  Loss: (0.2790) |  Loss2: (0.0000) | Acc: (90.00%) (20944/23168)
Epoch: 76 | Batch_idx: 190 |  Loss: (0.2793) |  Loss2: (0.0000) | Acc: (90.00%) (22103/24448)
Epoch: 76 | Batch_idx: 200 |  Loss: (0.2802) |  Loss2: (0.0000) | Acc: (90.00%) (23254/25728)
Epoch: 76 | Batch_idx: 210 |  Loss: (0.2803) |  Loss2: (0.0000) | Acc: (90.00%) (24409/27008)
Epoch: 76 | Batch_idx: 220 |  Loss: (0.2795) |  Loss2: (0.0000) | Acc: (90.00%) (25567/28288)
Epoch: 76 | Batch_idx: 230 |  Loss: (0.2792) |  Loss2: (0.0000) | Acc: (90.00%) (26720/29568)
Epoch: 76 | Batch_idx: 240 |  Loss: (0.2793) |  Loss2: (0.0000) | Acc: (90.00%) (27875/30848)
Epoch: 76 | Batch_idx: 250 |  Loss: (0.2801) |  Loss2: (0.0000) | Acc: (90.00%) (29013/32128)
Epoch: 76 | Batch_idx: 260 |  Loss: (0.2798) |  Loss2: (0.0000) | Acc: (90.00%) (30168/33408)
Epoch: 76 | Batch_idx: 270 |  Loss: (0.2798) |  Loss2: (0.0000) | Acc: (90.00%) (31326/34688)
Epoch: 76 | Batch_idx: 280 |  Loss: (0.2804) |  Loss2: (0.0000) | Acc: (90.00%) (32484/35968)
Epoch: 76 | Batch_idx: 290 |  Loss: (0.2802) |  Loss2: (0.0000) | Acc: (90.00%) (33648/37248)
Epoch: 76 | Batch_idx: 300 |  Loss: (0.2801) |  Loss2: (0.0000) | Acc: (90.00%) (34796/38528)
Epoch: 76 | Batch_idx: 310 |  Loss: (0.2799) |  Loss2: (0.0000) | Acc: (90.00%) (35954/39808)
Epoch: 76 | Batch_idx: 320 |  Loss: (0.2803) |  Loss2: (0.0000) | Acc: (90.00%) (37103/41088)
Epoch: 76 | Batch_idx: 330 |  Loss: (0.2805) |  Loss2: (0.0000) | Acc: (90.00%) (38258/42368)
Epoch: 76 | Batch_idx: 340 |  Loss: (0.2807) |  Loss2: (0.0000) | Acc: (90.00%) (39404/43648)
Epoch: 76 | Batch_idx: 350 |  Loss: (0.2806) |  Loss2: (0.0000) | Acc: (90.00%) (40558/44928)
Epoch: 76 | Batch_idx: 360 |  Loss: (0.2813) |  Loss2: (0.0000) | Acc: (90.00%) (41704/46208)
Epoch: 76 | Batch_idx: 370 |  Loss: (0.2816) |  Loss2: (0.0000) | Acc: (90.00%) (42858/47488)
Epoch: 76 | Batch_idx: 380 |  Loss: (0.2819) |  Loss2: (0.0000) | Acc: (90.00%) (44003/48768)
Epoch: 76 | Batch_idx: 390 |  Loss: (0.2817) |  Loss2: (0.0000) | Acc: (90.00%) (45128/50000)
# TEST : Loss: (0.4296) | Acc: (86.00%) (8628/10000)
percent tensor([0.5469, 0.5541, 0.5707, 0.5620, 0.5713, 0.5524, 0.5598, 0.5653, 0.5504,
        0.5567, 0.5454, 0.5658, 0.5486, 0.5459, 0.5555, 0.5482],
       device='cuda:0') torch.Size([16])
percent tensor([0.5525, 0.5566, 0.5434, 0.5361, 0.5494, 0.5587, 0.5590, 0.5456, 0.5482,
        0.5504, 0.5574, 0.5522, 0.5527, 0.5465, 0.5607, 0.5537],
       device='cuda:0') torch.Size([16])
percent tensor([0.5903, 0.5868, 0.5711, 0.5622, 0.5682, 0.5828, 0.5854, 0.5673, 0.5742,
        0.5813, 0.5774, 0.5769, 0.5954, 0.5731, 0.5959, 0.5922],
       device='cuda:0') torch.Size([16])
percent tensor([0.6086, 0.6042, 0.5901, 0.5856, 0.5943, 0.6154, 0.6077, 0.5904, 0.5996,
        0.6113, 0.6112, 0.5980, 0.6040, 0.6092, 0.6083, 0.6125],
       device='cuda:0') torch.Size([16])
percent tensor([0.4987, 0.4889, 0.5547, 0.5585, 0.5708, 0.5456, 0.5114, 0.5564, 0.5406,
        0.4891, 0.5126, 0.5206, 0.4597, 0.5467, 0.5161, 0.5203],
       device='cuda:0') torch.Size([16])
percent tensor([0.4848, 0.5287, 0.5651, 0.5679, 0.6010, 0.5960, 0.5410, 0.5244, 0.5579,
        0.5035, 0.5628, 0.5366, 0.4960, 0.5714, 0.4749, 0.4980],
       device='cuda:0') torch.Size([16])
percent tensor([0.6129, 0.5984, 0.6614, 0.6242, 0.6730, 0.6349, 0.6412, 0.6264, 0.6268,
        0.6159, 0.6159, 0.6340, 0.6095, 0.6567, 0.5744, 0.6021],
       device='cuda:0') torch.Size([16])
percent tensor([0.9992, 0.9985, 0.9992, 0.9981, 0.9996, 0.9985, 0.9995, 0.9998, 0.9992,
        0.9991, 0.9992, 0.9990, 0.9987, 0.9992, 0.9994, 0.9991],
       device='cuda:0') torch.Size([16])
False Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=128, out_features=16, bias=False)
True Linear(in_features=16, out_features=2, bias=False)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=128, out_features=16, bias=False)
True Linear(in_features=16, out_features=2, bias=False)
False Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=256, out_features=32, bias=False)
True Linear(in_features=32, out_features=2, bias=False)
False Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=256, out_features=32, bias=False)
True Linear(in_features=32, out_features=2, bias=False)
False Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=512, out_features=64, bias=False)
True Linear(in_features=64, out_features=2, bias=False)
False Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=512, out_features=64, bias=False)
True Linear(in_features=64, out_features=2, bias=False)
False Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1024, out_features=128, bias=False)
True Linear(in_features=128, out_features=2, bias=False)
False Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1024, out_features=128, bias=False)
True Linear(in_features=128, out_features=2, bias=False)
False Linear(in_features=512, out_features=10, bias=True)
Epoch: 77 | Batch_idx: 0 |  Loss: (0.3955) |  Loss2: (0.0000) | Acc: (87.00%) (112/128)
Epoch: 77 | Batch_idx: 10 |  Loss: (0.3105) |  Loss2: (0.0000) | Acc: (89.00%) (1267/1408)
Epoch: 77 | Batch_idx: 20 |  Loss: (0.3164) |  Loss2: (0.0000) | Acc: (89.00%) (2394/2688)
Epoch: 77 | Batch_idx: 30 |  Loss: (0.3279) |  Loss2: (0.0000) | Acc: (88.00%) (3503/3968)
Epoch: 77 | Batch_idx: 40 |  Loss: (0.3277) |  Loss2: (0.0000) | Acc: (88.00%) (4633/5248)
Epoch: 77 | Batch_idx: 50 |  Loss: (0.3300) |  Loss2: (0.0000) | Acc: (88.00%) (5760/6528)
Epoch: 77 | Batch_idx: 60 |  Loss: (0.3298) |  Loss2: (0.0000) | Acc: (88.00%) (6888/7808)
Epoch: 77 | Batch_idx: 70 |  Loss: (0.3278) |  Loss2: (0.0000) | Acc: (88.00%) (8035/9088)
Epoch: 77 | Batch_idx: 80 |  Loss: (0.3253) |  Loss2: (0.0000) | Acc: (88.00%) (9183/10368)
Epoch: 77 | Batch_idx: 90 |  Loss: (0.3210) |  Loss2: (0.0000) | Acc: (88.00%) (10330/11648)
Epoch: 77 | Batch_idx: 100 |  Loss: (0.3253) |  Loss2: (0.0000) | Acc: (88.00%) (11443/12928)
Epoch: 77 | Batch_idx: 110 |  Loss: (0.3297) |  Loss2: (0.0000) | Acc: (88.00%) (12564/14208)
Epoch: 77 | Batch_idx: 120 |  Loss: (0.3303) |  Loss2: (0.0000) | Acc: (88.00%) (13688/15488)
Epoch: 77 | Batch_idx: 130 |  Loss: (0.3303) |  Loss2: (0.0000) | Acc: (88.00%) (14836/16768)
Epoch: 77 | Batch_idx: 140 |  Loss: (0.3278) |  Loss2: (0.0000) | Acc: (88.00%) (15989/18048)
Epoch: 77 | Batch_idx: 150 |  Loss: (0.3273) |  Loss2: (0.0000) | Acc: (88.00%) (17128/19328)
Epoch: 77 | Batch_idx: 160 |  Loss: (0.3270) |  Loss2: (0.0000) | Acc: (88.00%) (18267/20608)
Epoch: 77 | Batch_idx: 170 |  Loss: (0.3261) |  Loss2: (0.0000) | Acc: (88.00%) (19409/21888)
Epoch: 77 | Batch_idx: 180 |  Loss: (0.3253) |  Loss2: (0.0000) | Acc: (88.00%) (20546/23168)
Epoch: 77 | Batch_idx: 190 |  Loss: (0.3250) |  Loss2: (0.0000) | Acc: (88.00%) (21692/24448)
Epoch: 77 | Batch_idx: 200 |  Loss: (0.3241) |  Loss2: (0.0000) | Acc: (88.00%) (22834/25728)
Epoch: 77 | Batch_idx: 210 |  Loss: (0.3230) |  Loss2: (0.0000) | Acc: (88.00%) (23972/27008)
Epoch: 77 | Batch_idx: 220 |  Loss: (0.3228) |  Loss2: (0.0000) | Acc: (88.00%) (25107/28288)
Epoch: 77 | Batch_idx: 230 |  Loss: (0.3216) |  Loss2: (0.0000) | Acc: (88.00%) (26253/29568)
Epoch: 77 | Batch_idx: 240 |  Loss: (0.3210) |  Loss2: (0.0000) | Acc: (88.00%) (27403/30848)
Epoch: 77 | Batch_idx: 250 |  Loss: (0.3214) |  Loss2: (0.0000) | Acc: (88.00%) (28532/32128)
Epoch: 77 | Batch_idx: 260 |  Loss: (0.3206) |  Loss2: (0.0000) | Acc: (88.00%) (29682/33408)
Epoch: 77 | Batch_idx: 270 |  Loss: (0.3186) |  Loss2: (0.0000) | Acc: (88.00%) (30843/34688)
Epoch: 77 | Batch_idx: 280 |  Loss: (0.3170) |  Loss2: (0.0000) | Acc: (89.00%) (32012/35968)
Epoch: 77 | Batch_idx: 290 |  Loss: (0.3164) |  Loss2: (0.0000) | Acc: (89.00%) (33153/37248)
Epoch: 77 | Batch_idx: 300 |  Loss: (0.3162) |  Loss2: (0.0000) | Acc: (89.00%) (34294/38528)
Epoch: 77 | Batch_idx: 310 |  Loss: (0.3167) |  Loss2: (0.0000) | Acc: (88.00%) (35416/39808)
Epoch: 77 | Batch_idx: 320 |  Loss: (0.3157) |  Loss2: (0.0000) | Acc: (89.00%) (36573/41088)
Epoch: 77 | Batch_idx: 330 |  Loss: (0.3150) |  Loss2: (0.0000) | Acc: (89.00%) (37726/42368)
Epoch: 77 | Batch_idx: 340 |  Loss: (0.3148) |  Loss2: (0.0000) | Acc: (89.00%) (38862/43648)
Epoch: 77 | Batch_idx: 350 |  Loss: (0.3146) |  Loss2: (0.0000) | Acc: (89.00%) (40010/44928)
Epoch: 77 | Batch_idx: 360 |  Loss: (0.3145) |  Loss2: (0.0000) | Acc: (89.00%) (41153/46208)
Epoch: 77 | Batch_idx: 370 |  Loss: (0.3145) |  Loss2: (0.0000) | Acc: (89.00%) (42289/47488)
Epoch: 77 | Batch_idx: 380 |  Loss: (0.3140) |  Loss2: (0.0000) | Acc: (89.00%) (43435/48768)
Epoch: 77 | Batch_idx: 390 |  Loss: (0.3151) |  Loss2: (0.0000) | Acc: (89.00%) (44512/50000)
# TEST : Loss: (0.4341) | Acc: (85.00%) (8579/10000)
percent tensor([0.5498, 0.5629, 0.5718, 0.5668, 0.5749, 0.5558, 0.5666, 0.5707, 0.5545,
        0.5623, 0.5499, 0.5690, 0.5520, 0.5568, 0.5617, 0.5530],
       device='cuda:0') torch.Size([16])
percent tensor([0.5640, 0.5683, 0.5562, 0.5493, 0.5638, 0.5723, 0.5720, 0.5594, 0.5598,
        0.5618, 0.5682, 0.5648, 0.5628, 0.5587, 0.5736, 0.5653],
       device='cuda:0') torch.Size([16])
percent tensor([0.5759, 0.5711, 0.5577, 0.5494, 0.5549, 0.5707, 0.5696, 0.5547, 0.5614,
        0.5665, 0.5638, 0.5627, 0.5805, 0.5579, 0.5810, 0.5768],
       device='cuda:0') torch.Size([16])
percent tensor([0.6042, 0.5985, 0.5874, 0.5866, 0.5937, 0.6144, 0.6023, 0.5888, 0.5961,
        0.6044, 0.6057, 0.5943, 0.5979, 0.6032, 0.6060, 0.6082],
       device='cuda:0') torch.Size([16])
percent tensor([0.4582, 0.4663, 0.5096, 0.5132, 0.5336, 0.5060, 0.4828, 0.5174, 0.5114,
        0.4612, 0.4822, 0.4769, 0.4278, 0.5121, 0.4903, 0.4762],
       device='cuda:0') torch.Size([16])
percent tensor([0.5145, 0.5512, 0.5978, 0.6047, 0.6453, 0.6314, 0.5678, 0.5594, 0.5949,
        0.5185, 0.5869, 0.5674, 0.5218, 0.5952, 0.4984, 0.5225],
       device='cuda:0') torch.Size([16])
percent tensor([0.5885, 0.5705, 0.6563, 0.6263, 0.6797, 0.6109, 0.6274, 0.6419, 0.6037,
        0.5888, 0.5839, 0.6207, 0.5695, 0.6294, 0.5632, 0.5861],
       device='cuda:0') torch.Size([16])
percent tensor([0.9988, 0.9984, 0.9992, 0.9979, 0.9997, 0.9982, 0.9993, 0.9998, 0.9993,
        0.9989, 0.9993, 0.9990, 0.9986, 0.9990, 0.9994, 0.9989],
       device='cuda:0') torch.Size([16])
Epoch: 78 | Batch_idx: 0 |  Loss: (0.2737) |  Loss2: (0.0000) | Acc: (91.00%) (117/128)
Epoch: 78 | Batch_idx: 10 |  Loss: (0.2938) |  Loss2: (0.0000) | Acc: (90.00%) (1271/1408)
Epoch: 78 | Batch_idx: 20 |  Loss: (0.3021) |  Loss2: (0.0000) | Acc: (89.00%) (2418/2688)
Epoch: 78 | Batch_idx: 30 |  Loss: (0.2992) |  Loss2: (0.0000) | Acc: (90.00%) (3576/3968)
Epoch: 78 | Batch_idx: 40 |  Loss: (0.2977) |  Loss2: (0.0000) | Acc: (90.00%) (4729/5248)
Epoch: 78 | Batch_idx: 50 |  Loss: (0.2992) |  Loss2: (0.0000) | Acc: (89.00%) (5874/6528)
Epoch: 78 | Batch_idx: 60 |  Loss: (0.3058) |  Loss2: (0.0000) | Acc: (89.00%) (6989/7808)
Epoch: 78 | Batch_idx: 70 |  Loss: (0.3053) |  Loss2: (0.0000) | Acc: (89.00%) (8146/9088)
Epoch: 78 | Batch_idx: 80 |  Loss: (0.3066) |  Loss2: (0.0000) | Acc: (89.00%) (9283/10368)
Epoch: 78 | Batch_idx: 90 |  Loss: (0.3063) |  Loss2: (0.0000) | Acc: (89.00%) (10438/11648)
Epoch: 78 | Batch_idx: 100 |  Loss: (0.3091) |  Loss2: (0.0000) | Acc: (89.00%) (11575/12928)
Epoch: 78 | Batch_idx: 110 |  Loss: (0.3091) |  Loss2: (0.0000) | Acc: (89.00%) (12713/14208)
Epoch: 78 | Batch_idx: 120 |  Loss: (0.3091) |  Loss2: (0.0000) | Acc: (89.00%) (13854/15488)
Epoch: 78 | Batch_idx: 130 |  Loss: (0.3074) |  Loss2: (0.0000) | Acc: (89.00%) (15008/16768)
Epoch: 78 | Batch_idx: 140 |  Loss: (0.3042) |  Loss2: (0.0000) | Acc: (89.00%) (16172/18048)
Epoch: 78 | Batch_idx: 150 |  Loss: (0.3040) |  Loss2: (0.0000) | Acc: (89.00%) (17327/19328)
Epoch: 78 | Batch_idx: 160 |  Loss: (0.3028) |  Loss2: (0.0000) | Acc: (89.00%) (18487/20608)
Epoch: 78 | Batch_idx: 170 |  Loss: (0.3046) |  Loss2: (0.0000) | Acc: (89.00%) (19608/21888)
Epoch: 78 | Batch_idx: 180 |  Loss: (0.3046) |  Loss2: (0.0000) | Acc: (89.00%) (20762/23168)
Epoch: 78 | Batch_idx: 190 |  Loss: (0.3041) |  Loss2: (0.0000) | Acc: (89.00%) (21909/24448)
Epoch: 78 | Batch_idx: 200 |  Loss: (0.3034) |  Loss2: (0.0000) | Acc: (89.00%) (23054/25728)
Epoch: 78 | Batch_idx: 210 |  Loss: (0.3035) |  Loss2: (0.0000) | Acc: (89.00%) (24185/27008)
Epoch: 78 | Batch_idx: 220 |  Loss: (0.3034) |  Loss2: (0.0000) | Acc: (89.00%) (25335/28288)
Epoch: 78 | Batch_idx: 230 |  Loss: (0.3029) |  Loss2: (0.0000) | Acc: (89.00%) (26489/29568)
Epoch: 78 | Batch_idx: 240 |  Loss: (0.3025) |  Loss2: (0.0000) | Acc: (89.00%) (27640/30848)
Epoch: 78 | Batch_idx: 250 |  Loss: (0.3011) |  Loss2: (0.0000) | Acc: (89.00%) (28796/32128)
Epoch: 78 | Batch_idx: 260 |  Loss: (0.3012) |  Loss2: (0.0000) | Acc: (89.00%) (29941/33408)
Epoch: 78 | Batch_idx: 270 |  Loss: (0.3006) |  Loss2: (0.0000) | Acc: (89.00%) (31105/34688)
Epoch: 78 | Batch_idx: 280 |  Loss: (0.2992) |  Loss2: (0.0000) | Acc: (89.00%) (32273/35968)
Epoch: 78 | Batch_idx: 290 |  Loss: (0.2986) |  Loss2: (0.0000) | Acc: (89.00%) (33422/37248)
Epoch: 78 | Batch_idx: 300 |  Loss: (0.2982) |  Loss2: (0.0000) | Acc: (89.00%) (34567/38528)
Epoch: 78 | Batch_idx: 310 |  Loss: (0.2982) |  Loss2: (0.0000) | Acc: (89.00%) (35723/39808)
Epoch: 78 | Batch_idx: 320 |  Loss: (0.2980) |  Loss2: (0.0000) | Acc: (89.00%) (36864/41088)
Epoch: 78 | Batch_idx: 330 |  Loss: (0.2974) |  Loss2: (0.0000) | Acc: (89.00%) (38014/42368)
Epoch: 78 | Batch_idx: 340 |  Loss: (0.2971) |  Loss2: (0.0000) | Acc: (89.00%) (39160/43648)
Epoch: 78 | Batch_idx: 350 |  Loss: (0.2966) |  Loss2: (0.0000) | Acc: (89.00%) (40314/44928)
Epoch: 78 | Batch_idx: 360 |  Loss: (0.2967) |  Loss2: (0.0000) | Acc: (89.00%) (41460/46208)
Epoch: 78 | Batch_idx: 370 |  Loss: (0.2967) |  Loss2: (0.0000) | Acc: (89.00%) (42617/47488)
Epoch: 78 | Batch_idx: 380 |  Loss: (0.2960) |  Loss2: (0.0000) | Acc: (89.00%) (43781/48768)
Epoch: 78 | Batch_idx: 390 |  Loss: (0.2959) |  Loss2: (0.0000) | Acc: (89.00%) (44894/50000)
# TEST : Loss: (0.4188) | Acc: (86.00%) (8645/10000)
percent tensor([0.5489, 0.5634, 0.5710, 0.5666, 0.5748, 0.5549, 0.5669, 0.5710, 0.5539,
        0.5623, 0.5494, 0.5686, 0.5513, 0.5580, 0.5615, 0.5524],
       device='cuda:0') torch.Size([16])
percent tensor([0.5638, 0.5676, 0.5564, 0.5505, 0.5645, 0.5731, 0.5719, 0.5602, 0.5597,
        0.5609, 0.5672, 0.5646, 0.5619, 0.5593, 0.5737, 0.5652],
       device='cuda:0') torch.Size([16])
percent tensor([0.5737, 0.5699, 0.5542, 0.5469, 0.5519, 0.5693, 0.5677, 0.5536, 0.5605,
        0.5644, 0.5622, 0.5599, 0.5787, 0.5593, 0.5794, 0.5745],
       device='cuda:0') torch.Size([16])
percent tensor([0.6075, 0.6010, 0.5908, 0.5918, 0.5979, 0.6196, 0.6063, 0.5933, 0.6001,
        0.6062, 0.6087, 0.5977, 0.5999, 0.6074, 0.6107, 0.6116],
       device='cuda:0') torch.Size([16])
percent tensor([0.4649, 0.4748, 0.5103, 0.5121, 0.5322, 0.5061, 0.4927, 0.5206, 0.5164,
        0.4709, 0.4899, 0.4863, 0.4350, 0.5169, 0.5034, 0.4809],
       device='cuda:0') torch.Size([16])
percent tensor([0.5281, 0.5623, 0.6132, 0.6206, 0.6622, 0.6486, 0.5817, 0.5725, 0.6096,
        0.5310, 0.6012, 0.5806, 0.5354, 0.6130, 0.5020, 0.5384],
       device='cuda:0') torch.Size([16])
percent tensor([0.5959, 0.5722, 0.6697, 0.6361, 0.6959, 0.6135, 0.6399, 0.6622, 0.6074,
        0.5958, 0.5853, 0.6280, 0.5658, 0.6359, 0.5710, 0.5932],
       device='cuda:0') torch.Size([16])
percent tensor([0.9988, 0.9985, 0.9992, 0.9979, 0.9997, 0.9983, 0.9994, 0.9998, 0.9993,
        0.9989, 0.9993, 0.9990, 0.9987, 0.9991, 0.9994, 0.9989],
       device='cuda:0') torch.Size([16])
Epoch: 79 | Batch_idx: 0 |  Loss: (0.2672) |  Loss2: (0.0000) | Acc: (90.00%) (116/128)
Epoch: 79 | Batch_idx: 10 |  Loss: (0.2855) |  Loss2: (0.0000) | Acc: (90.00%) (1275/1408)
Epoch: 79 | Batch_idx: 20 |  Loss: (0.2811) |  Loss2: (0.0000) | Acc: (90.00%) (2428/2688)
Epoch: 79 | Batch_idx: 30 |  Loss: (0.2782) |  Loss2: (0.0000) | Acc: (90.00%) (3579/3968)
Epoch: 79 | Batch_idx: 40 |  Loss: (0.2828) |  Loss2: (0.0000) | Acc: (90.00%) (4727/5248)
Epoch: 79 | Batch_idx: 50 |  Loss: (0.2793) |  Loss2: (0.0000) | Acc: (90.00%) (5884/6528)
Epoch: 79 | Batch_idx: 60 |  Loss: (0.2821) |  Loss2: (0.0000) | Acc: (89.00%) (7024/7808)
Epoch: 79 | Batch_idx: 70 |  Loss: (0.2828) |  Loss2: (0.0000) | Acc: (89.00%) (8177/9088)
Epoch: 79 | Batch_idx: 80 |  Loss: (0.2859) |  Loss2: (0.0000) | Acc: (89.00%) (9330/10368)
Epoch: 79 | Batch_idx: 90 |  Loss: (0.2847) |  Loss2: (0.0000) | Acc: (90.00%) (10496/11648)
Epoch: 79 | Batch_idx: 100 |  Loss: (0.2848) |  Loss2: (0.0000) | Acc: (90.00%) (11656/12928)
Epoch: 79 | Batch_idx: 110 |  Loss: (0.2843) |  Loss2: (0.0000) | Acc: (90.00%) (12811/14208)
Epoch: 79 | Batch_idx: 120 |  Loss: (0.2836) |  Loss2: (0.0000) | Acc: (90.00%) (13959/15488)
Epoch: 79 | Batch_idx: 130 |  Loss: (0.2835) |  Loss2: (0.0000) | Acc: (90.00%) (15123/16768)
Epoch: 79 | Batch_idx: 140 |  Loss: (0.2860) |  Loss2: (0.0000) | Acc: (90.00%) (16259/18048)
Epoch: 79 | Batch_idx: 150 |  Loss: (0.2866) |  Loss2: (0.0000) | Acc: (90.00%) (17414/19328)
Epoch: 79 | Batch_idx: 160 |  Loss: (0.2852) |  Loss2: (0.0000) | Acc: (90.00%) (18587/20608)
Epoch: 79 | Batch_idx: 170 |  Loss: (0.2826) |  Loss2: (0.0000) | Acc: (90.00%) (19761/21888)
Epoch: 79 | Batch_idx: 180 |  Loss: (0.2842) |  Loss2: (0.0000) | Acc: (90.00%) (20909/23168)
Epoch: 79 | Batch_idx: 190 |  Loss: (0.2838) |  Loss2: (0.0000) | Acc: (90.00%) (22055/24448)
Epoch: 79 | Batch_idx: 200 |  Loss: (0.2841) |  Loss2: (0.0000) | Acc: (90.00%) (23207/25728)
Epoch: 79 | Batch_idx: 210 |  Loss: (0.2829) |  Loss2: (0.0000) | Acc: (90.00%) (24369/27008)
Epoch: 79 | Batch_idx: 220 |  Loss: (0.2836) |  Loss2: (0.0000) | Acc: (90.00%) (25508/28288)
Epoch: 79 | Batch_idx: 230 |  Loss: (0.2837) |  Loss2: (0.0000) | Acc: (90.00%) (26662/29568)
Epoch: 79 | Batch_idx: 240 |  Loss: (0.2836) |  Loss2: (0.0000) | Acc: (90.00%) (27808/30848)
Epoch: 79 | Batch_idx: 250 |  Loss: (0.2834) |  Loss2: (0.0000) | Acc: (90.00%) (28959/32128)
Epoch: 79 | Batch_idx: 260 |  Loss: (0.2825) |  Loss2: (0.0000) | Acc: (90.00%) (30119/33408)
Epoch: 79 | Batch_idx: 270 |  Loss: (0.2829) |  Loss2: (0.0000) | Acc: (90.00%) (31268/34688)
Epoch: 79 | Batch_idx: 280 |  Loss: (0.2833) |  Loss2: (0.0000) | Acc: (90.00%) (32407/35968)
Epoch: 79 | Batch_idx: 290 |  Loss: (0.2816) |  Loss2: (0.0000) | Acc: (90.00%) (33589/37248)
Epoch: 79 | Batch_idx: 300 |  Loss: (0.2820) |  Loss2: (0.0000) | Acc: (90.00%) (34745/38528)
Epoch: 79 | Batch_idx: 310 |  Loss: (0.2825) |  Loss2: (0.0000) | Acc: (90.00%) (35891/39808)
Epoch: 79 | Batch_idx: 320 |  Loss: (0.2829) |  Loss2: (0.0000) | Acc: (90.00%) (37037/41088)
Epoch: 79 | Batch_idx: 330 |  Loss: (0.2832) |  Loss2: (0.0000) | Acc: (90.00%) (38189/42368)
Epoch: 79 | Batch_idx: 340 |  Loss: (0.2836) |  Loss2: (0.0000) | Acc: (90.00%) (39333/43648)
Epoch: 79 | Batch_idx: 350 |  Loss: (0.2843) |  Loss2: (0.0000) | Acc: (90.00%) (40477/44928)
Epoch: 79 | Batch_idx: 360 |  Loss: (0.2836) |  Loss2: (0.0000) | Acc: (90.00%) (41638/46208)
Epoch: 79 | Batch_idx: 370 |  Loss: (0.2835) |  Loss2: (0.0000) | Acc: (90.00%) (42798/47488)
Epoch: 79 | Batch_idx: 380 |  Loss: (0.2833) |  Loss2: (0.0000) | Acc: (90.00%) (43953/48768)
Epoch: 79 | Batch_idx: 390 |  Loss: (0.2822) |  Loss2: (0.0000) | Acc: (90.00%) (45075/50000)
# TEST : Loss: (0.4095) | Acc: (86.00%) (8680/10000)
percent tensor([0.5427, 0.5567, 0.5642, 0.5609, 0.5677, 0.5484, 0.5599, 0.5648, 0.5477,
        0.5558, 0.5430, 0.5615, 0.5450, 0.5531, 0.5548, 0.5465],
       device='cuda:0') torch.Size([16])
percent tensor([0.5634, 0.5666, 0.5560, 0.5504, 0.5645, 0.5731, 0.5714, 0.5603, 0.5593,
        0.5598, 0.5662, 0.5639, 0.5610, 0.5592, 0.5731, 0.5645],
       device='cuda:0') torch.Size([16])
percent tensor([0.5756, 0.5713, 0.5543, 0.5476, 0.5517, 0.5716, 0.5690, 0.5551, 0.5625,
        0.5653, 0.5637, 0.5606, 0.5808, 0.5622, 0.5816, 0.5762],
       device='cuda:0') torch.Size([16])
percent tensor([0.6101, 0.6020, 0.5928, 0.5953, 0.6008, 0.6240, 0.6088, 0.5963, 0.6024,
        0.6066, 0.6102, 0.5997, 0.6009, 0.6092, 0.6141, 0.6138],
       device='cuda:0') torch.Size([16])
percent tensor([0.4653, 0.4730, 0.5139, 0.5183, 0.5348, 0.5098, 0.4946, 0.5258, 0.5161,
        0.4691, 0.4869, 0.4888, 0.4286, 0.5191, 0.5074, 0.4830],
       device='cuda:0') torch.Size([16])
percent tensor([0.5066, 0.5447, 0.5977, 0.6066, 0.6484, 0.6390, 0.5637, 0.5506, 0.5934,
        0.5112, 0.5860, 0.5597, 0.5177, 0.5985, 0.4741, 0.5165],
       device='cuda:0') torch.Size([16])
percent tensor([0.6049, 0.5761, 0.6830, 0.6469, 0.7132, 0.6232, 0.6540, 0.6781, 0.6118,
        0.6028, 0.5897, 0.6354, 0.5647, 0.6446, 0.5793, 0.6030],
       device='cuda:0') torch.Size([16])
percent tensor([0.9990, 0.9985, 0.9993, 0.9982, 0.9998, 0.9985, 0.9995, 0.9998, 0.9994,
        0.9990, 0.9993, 0.9991, 0.9987, 0.9991, 0.9993, 0.9990],
       device='cuda:0') torch.Size([16])
Epoch: 80 | Batch_idx: 0 |  Loss: (0.3849) |  Loss2: (0.0000) | Acc: (87.00%) (112/128)
Epoch: 80 | Batch_idx: 10 |  Loss: (0.2839) |  Loss2: (0.0000) | Acc: (89.00%) (1257/1408)
Epoch: 80 | Batch_idx: 20 |  Loss: (0.2790) |  Loss2: (0.0000) | Acc: (89.00%) (2414/2688)
Epoch: 80 | Batch_idx: 30 |  Loss: (0.2804) |  Loss2: (0.0000) | Acc: (89.00%) (3571/3968)
Epoch: 80 | Batch_idx: 40 |  Loss: (0.2814) |  Loss2: (0.0000) | Acc: (89.00%) (4723/5248)
Epoch: 80 | Batch_idx: 50 |  Loss: (0.2727) |  Loss2: (0.0000) | Acc: (90.00%) (5897/6528)
Epoch: 80 | Batch_idx: 60 |  Loss: (0.2740) |  Loss2: (0.0000) | Acc: (90.00%) (7050/7808)
Epoch: 80 | Batch_idx: 70 |  Loss: (0.2707) |  Loss2: (0.0000) | Acc: (90.00%) (8221/9088)
Epoch: 80 | Batch_idx: 80 |  Loss: (0.2718) |  Loss2: (0.0000) | Acc: (90.00%) (9372/10368)
Epoch: 80 | Batch_idx: 90 |  Loss: (0.2728) |  Loss2: (0.0000) | Acc: (90.00%) (10525/11648)
Epoch: 80 | Batch_idx: 100 |  Loss: (0.2746) |  Loss2: (0.0000) | Acc: (90.00%) (11677/12928)
Epoch: 80 | Batch_idx: 110 |  Loss: (0.2751) |  Loss2: (0.0000) | Acc: (90.00%) (12826/14208)
Epoch: 80 | Batch_idx: 120 |  Loss: (0.2780) |  Loss2: (0.0000) | Acc: (90.00%) (13955/15488)
Epoch: 80 | Batch_idx: 130 |  Loss: (0.2783) |  Loss2: (0.0000) | Acc: (90.00%) (15118/16768)
Epoch: 80 | Batch_idx: 140 |  Loss: (0.2797) |  Loss2: (0.0000) | Acc: (90.00%) (16259/18048)
Epoch: 80 | Batch_idx: 150 |  Loss: (0.2798) |  Loss2: (0.0000) | Acc: (90.00%) (17409/19328)
Epoch: 80 | Batch_idx: 160 |  Loss: (0.2781) |  Loss2: (0.0000) | Acc: (90.00%) (18577/20608)
Epoch: 80 | Batch_idx: 170 |  Loss: (0.2784) |  Loss2: (0.0000) | Acc: (90.00%) (19739/21888)
Epoch: 80 | Batch_idx: 180 |  Loss: (0.2784) |  Loss2: (0.0000) | Acc: (90.00%) (20892/23168)
Epoch: 80 | Batch_idx: 190 |  Loss: (0.2792) |  Loss2: (0.0000) | Acc: (90.00%) (22045/24448)
Epoch: 80 | Batch_idx: 200 |  Loss: (0.2791) |  Loss2: (0.0000) | Acc: (90.00%) (23211/25728)
Epoch: 80 | Batch_idx: 210 |  Loss: (0.2790) |  Loss2: (0.0000) | Acc: (90.00%) (24367/27008)
Epoch: 80 | Batch_idx: 220 |  Loss: (0.2785) |  Loss2: (0.0000) | Acc: (90.00%) (25524/28288)
Epoch: 80 | Batch_idx: 230 |  Loss: (0.2789) |  Loss2: (0.0000) | Acc: (90.00%) (26677/29568)
Epoch: 80 | Batch_idx: 240 |  Loss: (0.2784) |  Loss2: (0.0000) | Acc: (90.00%) (27845/30848)
Epoch: 80 | Batch_idx: 250 |  Loss: (0.2774) |  Loss2: (0.0000) | Acc: (90.00%) (29001/32128)
Epoch: 80 | Batch_idx: 260 |  Loss: (0.2763) |  Loss2: (0.0000) | Acc: (90.00%) (30165/33408)
Epoch: 80 | Batch_idx: 270 |  Loss: (0.2759) |  Loss2: (0.0000) | Acc: (90.00%) (31330/34688)
Epoch: 80 | Batch_idx: 280 |  Loss: (0.2750) |  Loss2: (0.0000) | Acc: (90.00%) (32509/35968)
Epoch: 80 | Batch_idx: 290 |  Loss: (0.2756) |  Loss2: (0.0000) | Acc: (90.00%) (33662/37248)
Epoch: 80 | Batch_idx: 300 |  Loss: (0.2758) |  Loss2: (0.0000) | Acc: (90.00%) (34817/38528)
Epoch: 80 | Batch_idx: 310 |  Loss: (0.2752) |  Loss2: (0.0000) | Acc: (90.00%) (35979/39808)
Epoch: 80 | Batch_idx: 320 |  Loss: (0.2757) |  Loss2: (0.0000) | Acc: (90.00%) (37124/41088)
Epoch: 80 | Batch_idx: 330 |  Loss: (0.2763) |  Loss2: (0.0000) | Acc: (90.00%) (38268/42368)
Epoch: 80 | Batch_idx: 340 |  Loss: (0.2762) |  Loss2: (0.0000) | Acc: (90.00%) (39435/43648)
Epoch: 80 | Batch_idx: 350 |  Loss: (0.2765) |  Loss2: (0.0000) | Acc: (90.00%) (40602/44928)
Epoch: 80 | Batch_idx: 360 |  Loss: (0.2762) |  Loss2: (0.0000) | Acc: (90.00%) (41759/46208)
Epoch: 80 | Batch_idx: 370 |  Loss: (0.2759) |  Loss2: (0.0000) | Acc: (90.00%) (42931/47488)
Epoch: 80 | Batch_idx: 380 |  Loss: (0.2756) |  Loss2: (0.0000) | Acc: (90.00%) (44098/48768)
Epoch: 80 | Batch_idx: 390 |  Loss: (0.2747) |  Loss2: (0.0000) | Acc: (90.00%) (45234/50000)
=> saving checkpoint 'drive/app/torch/save_Schedule/checkpoint_080.pth.tar'
# TEST : Loss: (0.4036) | Acc: (86.00%) (8684/10000)
percent tensor([0.5448, 0.5601, 0.5677, 0.5640, 0.5716, 0.5504, 0.5635, 0.5686, 0.5505,
        0.5592, 0.5453, 0.5651, 0.5473, 0.5565, 0.5576, 0.5487],
       device='cuda:0') torch.Size([16])
percent tensor([0.5622, 0.5649, 0.5550, 0.5495, 0.5635, 0.5724, 0.5701, 0.5595, 0.5581,
        0.5581, 0.5644, 0.5626, 0.5594, 0.5581, 0.5720, 0.5633],
       device='cuda:0') torch.Size([16])
percent tensor([0.5751, 0.5722, 0.5531, 0.5461, 0.5507, 0.5717, 0.5690, 0.5550, 0.5627,
        0.5652, 0.5635, 0.5601, 0.5809, 0.5635, 0.5820, 0.5759],
       device='cuda:0') torch.Size([16])
percent tensor([0.6090, 0.5999, 0.5918, 0.5947, 0.5998, 0.6245, 0.6075, 0.5950, 0.6013,
        0.6040, 0.6083, 0.5983, 0.5992, 0.6074, 0.6135, 0.6126],
       device='cuda:0') torch.Size([16])
percent tensor([0.4660, 0.4743, 0.5142, 0.5176, 0.5345, 0.5100, 0.4964, 0.5269, 0.5161,
        0.4719, 0.4861, 0.4893, 0.4262, 0.5201, 0.5115, 0.4841],
       device='cuda:0') torch.Size([16])
percent tensor([0.5111, 0.5482, 0.6023, 0.6100, 0.6532, 0.6427, 0.5680, 0.5533, 0.5974,
        0.5170, 0.5920, 0.5643, 0.5231, 0.6053, 0.4726, 0.5199],
       device='cuda:0') torch.Size([16])
percent tensor([0.6162, 0.5846, 0.6938, 0.6532, 0.7244, 0.6314, 0.6662, 0.6894, 0.6197,
        0.6135, 0.5979, 0.6425, 0.5695, 0.6542, 0.5889, 0.6115],
       device='cuda:0') torch.Size([16])
percent tensor([0.9990, 0.9987, 0.9993, 0.9982, 0.9998, 0.9986, 0.9995, 0.9998, 0.9994,
        0.9990, 0.9993, 0.9991, 0.9987, 0.9992, 0.9994, 0.9990],
       device='cuda:0') torch.Size([16])
Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 3, 3, 3]) tensor(182.6601, device='cuda:0')
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(802.6929, device='cuda:0')
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(817.0869, device='cuda:0')
Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([128, 64, 3, 3]) tensor(1531.6162, device='cuda:0')
Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([128, 64, 1, 1]) tensor(502.6548, device='cuda:0')
Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([128, 128, 3, 3]) tensor(2223.9316, device='cuda:0')
Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([256, 128, 3, 3]) tensor(4283.9736, device='cuda:0')
Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([256, 128, 1, 1]) tensor(1399.5697, device='cuda:0')
Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([256, 256, 3, 3]) tensor(6112.5356, device='cuda:0')
Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([512, 256, 3, 3]) tensor(11939.7051, device='cuda:0')
Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([512, 256, 1, 1]) tensor(3970.0293, device='cuda:0')
Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([512, 512, 3, 3]) tensor(16777.1758, device='cuda:0')
Epoch: 81 | Batch_idx: 0 |  Loss: (0.2075) |  Loss2: (0.0000) | Acc: (92.00%) (119/128)
Epoch: 81 | Batch_idx: 10 |  Loss: (0.2638) |  Loss2: (0.0000) | Acc: (90.00%) (1277/1408)
Epoch: 81 | Batch_idx: 20 |  Loss: (0.2693) |  Loss2: (0.0000) | Acc: (90.00%) (2429/2688)
Epoch: 81 | Batch_idx: 30 |  Loss: (0.2757) |  Loss2: (0.0000) | Acc: (90.00%) (3586/3968)
Epoch: 81 | Batch_idx: 40 |  Loss: (0.2749) |  Loss2: (0.0000) | Acc: (90.00%) (4751/5248)
Epoch: 81 | Batch_idx: 50 |  Loss: (0.2663) |  Loss2: (0.0000) | Acc: (90.00%) (5936/6528)
Epoch: 81 | Batch_idx: 60 |  Loss: (0.2643) |  Loss2: (0.0000) | Acc: (90.00%) (7095/7808)
Epoch: 81 | Batch_idx: 70 |  Loss: (0.2691) |  Loss2: (0.0000) | Acc: (90.00%) (8236/9088)
Epoch: 81 | Batch_idx: 80 |  Loss: (0.2690) |  Loss2: (0.0000) | Acc: (90.00%) (9386/10368)
Epoch: 81 | Batch_idx: 90 |  Loss: (0.2684) |  Loss2: (0.0000) | Acc: (90.00%) (10552/11648)
Epoch: 81 | Batch_idx: 100 |  Loss: (0.2714) |  Loss2: (0.0000) | Acc: (90.00%) (11700/12928)
Epoch: 81 | Batch_idx: 110 |  Loss: (0.2685) |  Loss2: (0.0000) | Acc: (90.00%) (12876/14208)
Epoch: 81 | Batch_idx: 120 |  Loss: (0.2657) |  Loss2: (0.0000) | Acc: (90.00%) (14054/15488)
Epoch: 81 | Batch_idx: 130 |  Loss: (0.2669) |  Loss2: (0.0000) | Acc: (90.00%) (15210/16768)
Epoch: 81 | Batch_idx: 140 |  Loss: (0.2645) |  Loss2: (0.0000) | Acc: (90.00%) (16391/18048)
Epoch: 81 | Batch_idx: 150 |  Loss: (0.2631) |  Loss2: (0.0000) | Acc: (90.00%) (17567/19328)
Epoch: 81 | Batch_idx: 160 |  Loss: (0.2621) |  Loss2: (0.0000) | Acc: (90.00%) (18743/20608)
Epoch: 81 | Batch_idx: 170 |  Loss: (0.2639) |  Loss2: (0.0000) | Acc: (90.00%) (19900/21888)
Epoch: 81 | Batch_idx: 180 |  Loss: (0.2653) |  Loss2: (0.0000) | Acc: (90.00%) (21055/23168)
Epoch: 81 | Batch_idx: 190 |  Loss: (0.2645) |  Loss2: (0.0000) | Acc: (90.00%) (22223/24448)
Epoch: 81 | Batch_idx: 200 |  Loss: (0.2647) |  Loss2: (0.0000) | Acc: (90.00%) (23390/25728)
Epoch: 81 | Batch_idx: 210 |  Loss: (0.2664) |  Loss2: (0.0000) | Acc: (90.00%) (24546/27008)
Epoch: 81 | Batch_idx: 220 |  Loss: (0.2664) |  Loss2: (0.0000) | Acc: (90.00%) (25705/28288)
Epoch: 81 | Batch_idx: 230 |  Loss: (0.2657) |  Loss2: (0.0000) | Acc: (90.00%) (26868/29568)
Epoch: 81 | Batch_idx: 240 |  Loss: (0.2661) |  Loss2: (0.0000) | Acc: (90.00%) (28019/30848)
Epoch: 81 | Batch_idx: 250 |  Loss: (0.2666) |  Loss2: (0.0000) | Acc: (90.00%) (29169/32128)
Epoch: 81 | Batch_idx: 260 |  Loss: (0.2683) |  Loss2: (0.0000) | Acc: (90.00%) (30321/33408)
Epoch: 81 | Batch_idx: 270 |  Loss: (0.2685) |  Loss2: (0.0000) | Acc: (90.00%) (31475/34688)
Epoch: 81 | Batch_idx: 280 |  Loss: (0.2675) |  Loss2: (0.0000) | Acc: (90.00%) (32644/35968)
Epoch: 81 | Batch_idx: 290 |  Loss: (0.2676) |  Loss2: (0.0000) | Acc: (90.00%) (33805/37248)
Epoch: 81 | Batch_idx: 300 |  Loss: (0.2688) |  Loss2: (0.0000) | Acc: (90.00%) (34952/38528)
Epoch: 81 | Batch_idx: 310 |  Loss: (0.2685) |  Loss2: (0.0000) | Acc: (90.00%) (36130/39808)
Epoch: 81 | Batch_idx: 320 |  Loss: (0.2689) |  Loss2: (0.0000) | Acc: (90.00%) (37283/41088)
Epoch: 81 | Batch_idx: 330 |  Loss: (0.2686) |  Loss2: (0.0000) | Acc: (90.00%) (38449/42368)
Epoch: 81 | Batch_idx: 340 |  Loss: (0.2683) |  Loss2: (0.0000) | Acc: (90.00%) (39622/43648)
Epoch: 81 | Batch_idx: 350 |  Loss: (0.2682) |  Loss2: (0.0000) | Acc: (90.00%) (40778/44928)
Epoch: 81 | Batch_idx: 360 |  Loss: (0.2688) |  Loss2: (0.0000) | Acc: (90.00%) (41930/46208)
Epoch: 81 | Batch_idx: 370 |  Loss: (0.2683) |  Loss2: (0.0000) | Acc: (90.00%) (43096/47488)
Epoch: 81 | Batch_idx: 380 |  Loss: (0.2680) |  Loss2: (0.0000) | Acc: (90.00%) (44264/48768)
Epoch: 81 | Batch_idx: 390 |  Loss: (0.2684) |  Loss2: (0.0000) | Acc: (90.00%) (45382/50000)
# TEST : Loss: (0.4005) | Acc: (86.00%) (8689/10000)
percent tensor([0.5418, 0.5563, 0.5646, 0.5613, 0.5682, 0.5473, 0.5598, 0.5656, 0.5472,
        0.5557, 0.5418, 0.5616, 0.5440, 0.5538, 0.5540, 0.5458],
       device='cuda:0') torch.Size([16])
percent tensor([0.5620, 0.5640, 0.5552, 0.5499, 0.5637, 0.5725, 0.5696, 0.5597, 0.5578,
        0.5573, 0.5635, 0.5622, 0.5588, 0.5577, 0.5716, 0.5629],
       device='cuda:0') torch.Size([16])
percent tensor([0.5798, 0.5779, 0.5559, 0.5486, 0.5536, 0.5760, 0.5739, 0.5587, 0.5676,
        0.5701, 0.5686, 0.5642, 0.5865, 0.5696, 0.5874, 0.5806],
       device='cuda:0') torch.Size([16])
percent tensor([0.6134, 0.6034, 0.5956, 0.5989, 0.6039, 0.6301, 0.6120, 0.5992, 0.6055,
        0.6073, 0.6122, 0.6025, 0.6030, 0.6111, 0.6188, 0.6168],
       device='cuda:0') torch.Size([16])
percent tensor([0.4716, 0.4790, 0.5176, 0.5225, 0.5356, 0.5180, 0.5020, 0.5293, 0.5196,
        0.4797, 0.4905, 0.4961, 0.4305, 0.5278, 0.5187, 0.4918],
       device='cuda:0') torch.Size([16])
percent tensor([0.5167, 0.5522, 0.6068, 0.6145, 0.6568, 0.6479, 0.5721, 0.5568, 0.6005,
        0.5199, 0.5973, 0.5663, 0.5282, 0.6084, 0.4723, 0.5226],
       device='cuda:0') torch.Size([16])
percent tensor([0.6200, 0.5871, 0.7006, 0.6584, 0.7326, 0.6377, 0.6713, 0.6965, 0.6194,
        0.6171, 0.5991, 0.6444, 0.5682, 0.6565, 0.5912, 0.6160],
       device='cuda:0') torch.Size([16])
percent tensor([0.9990, 0.9987, 0.9994, 0.9983, 0.9998, 0.9986, 0.9995, 0.9998, 0.9994,
        0.9991, 0.9994, 0.9991, 0.9987, 0.9992, 0.9994, 0.9990],
       device='cuda:0') torch.Size([16])
Epoch: 82 | Batch_idx: 0 |  Loss: (0.2923) |  Loss2: (0.0000) | Acc: (90.00%) (116/128)
Epoch: 82 | Batch_idx: 10 |  Loss: (0.2758) |  Loss2: (0.0000) | Acc: (90.00%) (1273/1408)
Epoch: 82 | Batch_idx: 20 |  Loss: (0.2850) |  Loss2: (0.0000) | Acc: (90.00%) (2423/2688)
Epoch: 82 | Batch_idx: 30 |  Loss: (0.2900) |  Loss2: (0.0000) | Acc: (90.00%) (3577/3968)
Epoch: 82 | Batch_idx: 40 |  Loss: (0.2813) |  Loss2: (0.0000) | Acc: (90.00%) (4739/5248)
Epoch: 82 | Batch_idx: 50 |  Loss: (0.2793) |  Loss2: (0.0000) | Acc: (90.00%) (5889/6528)
Epoch: 82 | Batch_idx: 60 |  Loss: (0.2858) |  Loss2: (0.0000) | Acc: (89.00%) (7023/7808)
Epoch: 82 | Batch_idx: 70 |  Loss: (0.2839) |  Loss2: (0.0000) | Acc: (90.00%) (8192/9088)
Epoch: 82 | Batch_idx: 80 |  Loss: (0.2804) |  Loss2: (0.0000) | Acc: (90.00%) (9361/10368)
Epoch: 82 | Batch_idx: 90 |  Loss: (0.2793) |  Loss2: (0.0000) | Acc: (90.00%) (10521/11648)
Epoch: 82 | Batch_idx: 100 |  Loss: (0.2779) |  Loss2: (0.0000) | Acc: (90.00%) (11684/12928)
Epoch: 82 | Batch_idx: 110 |  Loss: (0.2761) |  Loss2: (0.0000) | Acc: (90.00%) (12852/14208)
Epoch: 82 | Batch_idx: 120 |  Loss: (0.2740) |  Loss2: (0.0000) | Acc: (90.00%) (14017/15488)
Epoch: 82 | Batch_idx: 130 |  Loss: (0.2751) |  Loss2: (0.0000) | Acc: (90.00%) (15171/16768)
Epoch: 82 | Batch_idx: 140 |  Loss: (0.2741) |  Loss2: (0.0000) | Acc: (90.00%) (16336/18048)
Epoch: 82 | Batch_idx: 150 |  Loss: (0.2726) |  Loss2: (0.0000) | Acc: (90.00%) (17506/19328)
Epoch: 82 | Batch_idx: 160 |  Loss: (0.2726) |  Loss2: (0.0000) | Acc: (90.00%) (18668/20608)
Epoch: 82 | Batch_idx: 170 |  Loss: (0.2725) |  Loss2: (0.0000) | Acc: (90.00%) (19822/21888)
Epoch: 82 | Batch_idx: 180 |  Loss: (0.2719) |  Loss2: (0.0000) | Acc: (90.00%) (20988/23168)
Epoch: 82 | Batch_idx: 190 |  Loss: (0.2704) |  Loss2: (0.0000) | Acc: (90.00%) (22159/24448)
Epoch: 82 | Batch_idx: 200 |  Loss: (0.2700) |  Loss2: (0.0000) | Acc: (90.00%) (23319/25728)
Epoch: 82 | Batch_idx: 210 |  Loss: (0.2704) |  Loss2: (0.0000) | Acc: (90.00%) (24474/27008)
Epoch: 82 | Batch_idx: 220 |  Loss: (0.2702) |  Loss2: (0.0000) | Acc: (90.00%) (25629/28288)
Epoch: 82 | Batch_idx: 230 |  Loss: (0.2688) |  Loss2: (0.0000) | Acc: (90.00%) (26812/29568)
Epoch: 82 | Batch_idx: 240 |  Loss: (0.2693) |  Loss2: (0.0000) | Acc: (90.00%) (27964/30848)
Epoch: 82 | Batch_idx: 250 |  Loss: (0.2687) |  Loss2: (0.0000) | Acc: (90.00%) (29132/32128)
Epoch: 82 | Batch_idx: 260 |  Loss: (0.2689) |  Loss2: (0.0000) | Acc: (90.00%) (30292/33408)
Epoch: 82 | Batch_idx: 270 |  Loss: (0.2688) |  Loss2: (0.0000) | Acc: (90.00%) (31458/34688)
Epoch: 82 | Batch_idx: 280 |  Loss: (0.2685) |  Loss2: (0.0000) | Acc: (90.00%) (32623/35968)
Epoch: 82 | Batch_idx: 290 |  Loss: (0.2672) |  Loss2: (0.0000) | Acc: (90.00%) (33813/37248)
Epoch: 82 | Batch_idx: 300 |  Loss: (0.2672) |  Loss2: (0.0000) | Acc: (90.00%) (34979/38528)
Epoch: 82 | Batch_idx: 310 |  Loss: (0.2663) |  Loss2: (0.0000) | Acc: (90.00%) (36159/39808)
Epoch: 82 | Batch_idx: 320 |  Loss: (0.2653) |  Loss2: (0.0000) | Acc: (90.00%) (37342/41088)
Epoch: 82 | Batch_idx: 330 |  Loss: (0.2656) |  Loss2: (0.0000) | Acc: (90.00%) (38498/42368)
Epoch: 82 | Batch_idx: 340 |  Loss: (0.2653) |  Loss2: (0.0000) | Acc: (90.00%) (39659/43648)
Epoch: 82 | Batch_idx: 350 |  Loss: (0.2649) |  Loss2: (0.0000) | Acc: (90.00%) (40822/44928)
Epoch: 82 | Batch_idx: 360 |  Loss: (0.2651) |  Loss2: (0.0000) | Acc: (90.00%) (41991/46208)
Epoch: 82 | Batch_idx: 370 |  Loss: (0.2646) |  Loss2: (0.0000) | Acc: (90.00%) (43157/47488)
Epoch: 82 | Batch_idx: 380 |  Loss: (0.2653) |  Loss2: (0.0000) | Acc: (90.00%) (44311/48768)
Epoch: 82 | Batch_idx: 390 |  Loss: (0.2653) |  Loss2: (0.0000) | Acc: (90.00%) (45429/50000)
# TEST : Loss: (0.3990) | Acc: (87.00%) (8701/10000)
percent tensor([0.5399, 0.5546, 0.5629, 0.5597, 0.5666, 0.5450, 0.5581, 0.5643, 0.5457,
        0.5542, 0.5400, 0.5599, 0.5422, 0.5530, 0.5519, 0.5440],
       device='cuda:0') torch.Size([16])
percent tensor([0.5599, 0.5614, 0.5532, 0.5481, 0.5618, 0.5708, 0.5672, 0.5578, 0.5558,
        0.5547, 0.5609, 0.5600, 0.5564, 0.5556, 0.5695, 0.5607],
       device='cuda:0') torch.Size([16])
percent tensor([0.5795, 0.5775, 0.5547, 0.5476, 0.5517, 0.5758, 0.5730, 0.5576, 0.5674,
        0.5693, 0.5682, 0.5633, 0.5868, 0.5696, 0.5869, 0.5801],
       device='cuda:0') torch.Size([16])
percent tensor([0.6155, 0.6050, 0.5970, 0.6004, 0.6054, 0.6336, 0.6138, 0.6002, 0.6072,
        0.6084, 0.6140, 0.6041, 0.6047, 0.6126, 0.6217, 0.6189],
       device='cuda:0') torch.Size([16])
percent tensor([0.4830, 0.4897, 0.5273, 0.5327, 0.5411, 0.5275, 0.5134, 0.5383, 0.5288,
        0.4931, 0.5002, 0.5081, 0.4386, 0.5408, 0.5308, 0.5030],
       device='cuda:0') torch.Size([16])
percent tensor([0.4923, 0.5339, 0.5882, 0.5957, 0.6397, 0.6350, 0.5506, 0.5331, 0.5822,
        0.4969, 0.5807, 0.5420, 0.5090, 0.5901, 0.4414, 0.4988],
       device='cuda:0') torch.Size([16])
percent tensor([0.6231, 0.5915, 0.6988, 0.6541, 0.7303, 0.6402, 0.6729, 0.6921, 0.6210,
        0.6215, 0.6044, 0.6435, 0.5727, 0.6591, 0.5949, 0.6169],
       device='cuda:0') torch.Size([16])
percent tensor([0.9991, 0.9988, 0.9994, 0.9984, 0.9998, 0.9988, 0.9996, 0.9998, 0.9995,
        0.9992, 0.9994, 0.9991, 0.9988, 0.9993, 0.9994, 0.9992],
       device='cuda:0') torch.Size([16])
Epoch: 83 | Batch_idx: 0 |  Loss: (0.2899) |  Loss2: (0.0000) | Acc: (90.00%) (116/128)
Epoch: 83 | Batch_idx: 10 |  Loss: (0.2731) |  Loss2: (0.0000) | Acc: (91.00%) (1283/1408)
Epoch: 83 | Batch_idx: 20 |  Loss: (0.2712) |  Loss2: (0.0000) | Acc: (91.00%) (2451/2688)
Epoch: 83 | Batch_idx: 30 |  Loss: (0.2716) |  Loss2: (0.0000) | Acc: (91.00%) (3613/3968)
Epoch: 83 | Batch_idx: 40 |  Loss: (0.2758) |  Loss2: (0.0000) | Acc: (90.00%) (4766/5248)
Epoch: 83 | Batch_idx: 50 |  Loss: (0.2758) |  Loss2: (0.0000) | Acc: (90.00%) (5920/6528)
Epoch: 83 | Batch_idx: 60 |  Loss: (0.2778) |  Loss2: (0.0000) | Acc: (90.00%) (7072/7808)
Epoch: 83 | Batch_idx: 70 |  Loss: (0.2728) |  Loss2: (0.0000) | Acc: (90.00%) (8252/9088)
Epoch: 83 | Batch_idx: 80 |  Loss: (0.2702) |  Loss2: (0.0000) | Acc: (90.00%) (9420/10368)
Epoch: 83 | Batch_idx: 90 |  Loss: (0.2697) |  Loss2: (0.0000) | Acc: (90.00%) (10589/11648)
Epoch: 83 | Batch_idx: 100 |  Loss: (0.2699) |  Loss2: (0.0000) | Acc: (90.00%) (11741/12928)
Epoch: 83 | Batch_idx: 110 |  Loss: (0.2672) |  Loss2: (0.0000) | Acc: (90.00%) (12912/14208)
Epoch: 83 | Batch_idx: 120 |  Loss: (0.2660) |  Loss2: (0.0000) | Acc: (90.00%) (14074/15488)
Epoch: 83 | Batch_idx: 130 |  Loss: (0.2648) |  Loss2: (0.0000) | Acc: (90.00%) (15248/16768)
Epoch: 83 | Batch_idx: 140 |  Loss: (0.2647) |  Loss2: (0.0000) | Acc: (90.00%) (16411/18048)
Epoch: 83 | Batch_idx: 150 |  Loss: (0.2653) |  Loss2: (0.0000) | Acc: (90.00%) (17587/19328)
Epoch: 83 | Batch_idx: 160 |  Loss: (0.2662) |  Loss2: (0.0000) | Acc: (90.00%) (18745/20608)
Epoch: 83 | Batch_idx: 170 |  Loss: (0.2683) |  Loss2: (0.0000) | Acc: (90.00%) (19895/21888)
Epoch: 83 | Batch_idx: 180 |  Loss: (0.2679) |  Loss2: (0.0000) | Acc: (90.00%) (21060/23168)
Epoch: 83 | Batch_idx: 190 |  Loss: (0.2674) |  Loss2: (0.0000) | Acc: (90.00%) (22215/24448)
Epoch: 83 | Batch_idx: 200 |  Loss: (0.2676) |  Loss2: (0.0000) | Acc: (90.00%) (23383/25728)
Epoch: 83 | Batch_idx: 210 |  Loss: (0.2678) |  Loss2: (0.0000) | Acc: (90.00%) (24543/27008)
Epoch: 83 | Batch_idx: 220 |  Loss: (0.2692) |  Loss2: (0.0000) | Acc: (90.00%) (25703/28288)
Epoch: 83 | Batch_idx: 230 |  Loss: (0.2696) |  Loss2: (0.0000) | Acc: (90.00%) (26859/29568)
Epoch: 83 | Batch_idx: 240 |  Loss: (0.2693) |  Loss2: (0.0000) | Acc: (90.00%) (28016/30848)
Epoch: 83 | Batch_idx: 250 |  Loss: (0.2694) |  Loss2: (0.0000) | Acc: (90.00%) (29183/32128)
Epoch: 83 | Batch_idx: 260 |  Loss: (0.2693) |  Loss2: (0.0000) | Acc: (90.00%) (30353/33408)
Epoch: 83 | Batch_idx: 270 |  Loss: (0.2686) |  Loss2: (0.0000) | Acc: (90.00%) (31534/34688)
Epoch: 83 | Batch_idx: 280 |  Loss: (0.2676) |  Loss2: (0.0000) | Acc: (90.00%) (32720/35968)
Epoch: 83 | Batch_idx: 290 |  Loss: (0.2675) |  Loss2: (0.0000) | Acc: (90.00%) (33890/37248)
Epoch: 83 | Batch_idx: 300 |  Loss: (0.2661) |  Loss2: (0.0000) | Acc: (91.00%) (35076/38528)
Epoch: 83 | Batch_idx: 310 |  Loss: (0.2656) |  Loss2: (0.0000) | Acc: (91.00%) (36240/39808)
Epoch: 83 | Batch_idx: 320 |  Loss: (0.2653) |  Loss2: (0.0000) | Acc: (91.00%) (37408/41088)
Epoch: 83 | Batch_idx: 330 |  Loss: (0.2654) |  Loss2: (0.0000) | Acc: (91.00%) (38568/42368)
Epoch: 83 | Batch_idx: 340 |  Loss: (0.2666) |  Loss2: (0.0000) | Acc: (90.00%) (39713/43648)
Epoch: 83 | Batch_idx: 350 |  Loss: (0.2667) |  Loss2: (0.0000) | Acc: (90.00%) (40878/44928)
Epoch: 83 | Batch_idx: 360 |  Loss: (0.2666) |  Loss2: (0.0000) | Acc: (90.00%) (42042/46208)
Epoch: 83 | Batch_idx: 370 |  Loss: (0.2669) |  Loss2: (0.0000) | Acc: (90.00%) (43195/47488)
Epoch: 83 | Batch_idx: 380 |  Loss: (0.2664) |  Loss2: (0.0000) | Acc: (90.00%) (44369/48768)
Epoch: 83 | Batch_idx: 390 |  Loss: (0.2659) |  Loss2: (0.0000) | Acc: (91.00%) (45502/50000)
# TEST : Loss: (0.3967) | Acc: (87.00%) (8714/10000)
percent tensor([0.5406, 0.5557, 0.5641, 0.5613, 0.5678, 0.5461, 0.5592, 0.5658, 0.5466,
        0.5553, 0.5406, 0.5608, 0.5429, 0.5547, 0.5530, 0.5450],
       device='cuda:0') torch.Size([16])
percent tensor([0.5588, 0.5597, 0.5525, 0.5475, 0.5609, 0.5698, 0.5658, 0.5571, 0.5547,
        0.5532, 0.5593, 0.5587, 0.5549, 0.5546, 0.5680, 0.5596],
       device='cuda:0') torch.Size([16])
percent tensor([0.5816, 0.5796, 0.5558, 0.5483, 0.5527, 0.5778, 0.5750, 0.5595, 0.5697,
        0.5710, 0.5701, 0.5650, 0.5888, 0.5728, 0.5893, 0.5819],
       device='cuda:0') torch.Size([16])
percent tensor([0.6154, 0.6037, 0.5966, 0.6003, 0.6054, 0.6343, 0.6133, 0.6001, 0.6070,
        0.6068, 0.6130, 0.6035, 0.6039, 0.6113, 0.6217, 0.6181],
       device='cuda:0') torch.Size([16])
percent tensor([0.4791, 0.4827, 0.5232, 0.5271, 0.5356, 0.5258, 0.5076, 0.5321, 0.5217,
        0.4878, 0.4920, 0.5001, 0.4321, 0.5340, 0.5248, 0.4994],
       device='cuda:0') torch.Size([16])
percent tensor([0.5034, 0.5447, 0.5997, 0.6071, 0.6510, 0.6406, 0.5633, 0.5470, 0.5934,
        0.5096, 0.5905, 0.5540, 0.5194, 0.6001, 0.4549, 0.5083],
       device='cuda:0') torch.Size([16])
percent tensor([0.6244, 0.5929, 0.7030, 0.6565, 0.7347, 0.6380, 0.6779, 0.6995, 0.6206,
        0.6222, 0.6031, 0.6429, 0.5702, 0.6581, 0.5970, 0.6182],
       device='cuda:0') torch.Size([16])
percent tensor([0.9992, 0.9989, 0.9995, 0.9985, 0.9998, 0.9988, 0.9996, 0.9998, 0.9995,
        0.9993, 0.9995, 0.9991, 0.9989, 0.9994, 0.9994, 0.9992],
       device='cuda:0') torch.Size([16])
True Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=128, out_features=16, bias=False)
False Linear(in_features=16, out_features=2, bias=False)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=128, out_features=16, bias=False)
False Linear(in_features=16, out_features=2, bias=False)
True Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=256, out_features=32, bias=False)
False Linear(in_features=32, out_features=2, bias=False)
True Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=256, out_features=32, bias=False)
False Linear(in_features=32, out_features=2, bias=False)
True Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=512, out_features=64, bias=False)
False Linear(in_features=64, out_features=2, bias=False)
True Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=512, out_features=64, bias=False)
False Linear(in_features=64, out_features=2, bias=False)
True Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1024, out_features=128, bias=False)
False Linear(in_features=128, out_features=2, bias=False)
True Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1024, out_features=128, bias=False)
False Linear(in_features=128, out_features=2, bias=False)
True Linear(in_features=512, out_features=10, bias=True)
Epoch: 84 | Batch_idx: 0 |  Loss: (0.2097) |  Loss2: (0.0000) | Acc: (95.00%) (122/128)
Epoch: 84 | Batch_idx: 10 |  Loss: (0.2990) |  Loss2: (0.0000) | Acc: (89.00%) (1263/1408)
Epoch: 84 | Batch_idx: 20 |  Loss: (0.2770) |  Loss2: (0.0000) | Acc: (90.00%) (2434/2688)
Epoch: 84 | Batch_idx: 30 |  Loss: (0.2662) |  Loss2: (0.0000) | Acc: (90.00%) (3607/3968)
Epoch: 84 | Batch_idx: 40 |  Loss: (0.2605) |  Loss2: (0.0000) | Acc: (91.00%) (4786/5248)
Epoch: 84 | Batch_idx: 50 |  Loss: (0.2665) |  Loss2: (0.0000) | Acc: (90.00%) (5939/6528)
Epoch: 84 | Batch_idx: 60 |  Loss: (0.2736) |  Loss2: (0.0000) | Acc: (90.00%) (7074/7808)
Epoch: 84 | Batch_idx: 70 |  Loss: (0.2779) |  Loss2: (0.0000) | Acc: (90.00%) (8216/9088)
Epoch: 84 | Batch_idx: 80 |  Loss: (0.2735) |  Loss2: (0.0000) | Acc: (90.00%) (9393/10368)
Epoch: 84 | Batch_idx: 90 |  Loss: (0.2764) |  Loss2: (0.0000) | Acc: (90.00%) (10544/11648)
Epoch: 84 | Batch_idx: 100 |  Loss: (0.2766) |  Loss2: (0.0000) | Acc: (90.00%) (11717/12928)
Epoch: 84 | Batch_idx: 110 |  Loss: (0.2751) |  Loss2: (0.0000) | Acc: (90.00%) (12891/14208)
Epoch: 84 | Batch_idx: 120 |  Loss: (0.2755) |  Loss2: (0.0000) | Acc: (90.00%) (14049/15488)
Epoch: 84 | Batch_idx: 130 |  Loss: (0.2780) |  Loss2: (0.0000) | Acc: (90.00%) (15200/16768)
Epoch: 84 | Batch_idx: 140 |  Loss: (0.2796) |  Loss2: (0.0000) | Acc: (90.00%) (16342/18048)
Epoch: 84 | Batch_idx: 150 |  Loss: (0.2784) |  Loss2: (0.0000) | Acc: (90.00%) (17505/19328)
Epoch: 84 | Batch_idx: 160 |  Loss: (0.2775) |  Loss2: (0.0000) | Acc: (90.00%) (18671/20608)
Epoch: 84 | Batch_idx: 170 |  Loss: (0.2784) |  Loss2: (0.0000) | Acc: (90.00%) (19811/21888)
Epoch: 84 | Batch_idx: 180 |  Loss: (0.2791) |  Loss2: (0.0000) | Acc: (90.00%) (20963/23168)
Epoch: 84 | Batch_idx: 190 |  Loss: (0.2783) |  Loss2: (0.0000) | Acc: (90.00%) (22122/24448)
Epoch: 84 | Batch_idx: 200 |  Loss: (0.2782) |  Loss2: (0.0000) | Acc: (90.00%) (23287/25728)
Epoch: 84 | Batch_idx: 210 |  Loss: (0.2783) |  Loss2: (0.0000) | Acc: (90.00%) (24452/27008)
Epoch: 84 | Batch_idx: 220 |  Loss: (0.2782) |  Loss2: (0.0000) | Acc: (90.00%) (25619/28288)
Epoch: 84 | Batch_idx: 230 |  Loss: (0.2768) |  Loss2: (0.0000) | Acc: (90.00%) (26783/29568)
Epoch: 84 | Batch_idx: 240 |  Loss: (0.2771) |  Loss2: (0.0000) | Acc: (90.00%) (27945/30848)
Epoch: 84 | Batch_idx: 250 |  Loss: (0.2772) |  Loss2: (0.0000) | Acc: (90.00%) (29102/32128)
Epoch: 84 | Batch_idx: 260 |  Loss: (0.2776) |  Loss2: (0.0000) | Acc: (90.00%) (30244/33408)
Epoch: 84 | Batch_idx: 270 |  Loss: (0.2775) |  Loss2: (0.0000) | Acc: (90.00%) (31401/34688)
Epoch: 84 | Batch_idx: 280 |  Loss: (0.2779) |  Loss2: (0.0000) | Acc: (90.00%) (32551/35968)
Epoch: 84 | Batch_idx: 290 |  Loss: (0.2784) |  Loss2: (0.0000) | Acc: (90.00%) (33704/37248)
Epoch: 84 | Batch_idx: 300 |  Loss: (0.2788) |  Loss2: (0.0000) | Acc: (90.00%) (34858/38528)
Epoch: 84 | Batch_idx: 310 |  Loss: (0.2786) |  Loss2: (0.0000) | Acc: (90.00%) (36018/39808)
Epoch: 84 | Batch_idx: 320 |  Loss: (0.2789) |  Loss2: (0.0000) | Acc: (90.00%) (37174/41088)
Epoch: 84 | Batch_idx: 330 |  Loss: (0.2787) |  Loss2: (0.0000) | Acc: (90.00%) (38343/42368)
Epoch: 84 | Batch_idx: 340 |  Loss: (0.2796) |  Loss2: (0.0000) | Acc: (90.00%) (39497/43648)
Epoch: 84 | Batch_idx: 350 |  Loss: (0.2795) |  Loss2: (0.0000) | Acc: (90.00%) (40657/44928)
Epoch: 84 | Batch_idx: 360 |  Loss: (0.2798) |  Loss2: (0.0000) | Acc: (90.00%) (41812/46208)
Epoch: 84 | Batch_idx: 370 |  Loss: (0.2806) |  Loss2: (0.0000) | Acc: (90.00%) (42954/47488)
Epoch: 84 | Batch_idx: 380 |  Loss: (0.2809) |  Loss2: (0.0000) | Acc: (90.00%) (44096/48768)
Epoch: 84 | Batch_idx: 390 |  Loss: (0.2809) |  Loss2: (0.0000) | Acc: (90.00%) (45200/50000)
# TEST : Loss: (0.4980) | Acc: (84.00%) (8431/10000)
percent tensor([0.5401, 0.5549, 0.5643, 0.5612, 0.5673, 0.5466, 0.5587, 0.5654, 0.5472,
        0.5553, 0.5409, 0.5611, 0.5434, 0.5535, 0.5532, 0.5451],
       device='cuda:0') torch.Size([16])
percent tensor([0.5578, 0.5604, 0.5526, 0.5482, 0.5598, 0.5663, 0.5660, 0.5578, 0.5538,
        0.5538, 0.5584, 0.5600, 0.5554, 0.5544, 0.5678, 0.5584],
       device='cuda:0') torch.Size([16])
percent tensor([0.5818, 0.5795, 0.5570, 0.5503, 0.5542, 0.5760, 0.5769, 0.5622, 0.5702,
        0.5730, 0.5725, 0.5686, 0.5913, 0.5731, 0.5881, 0.5831],
       device='cuda:0') torch.Size([16])
percent tensor([0.6166, 0.6066, 0.5942, 0.5964, 0.6021, 0.6376, 0.6169, 0.5980, 0.6091,
        0.6077, 0.6167, 0.6026, 0.6053, 0.6141, 0.6234, 0.6190],
       device='cuda:0') torch.Size([16])
percent tensor([0.4720, 0.5022, 0.5210, 0.5365, 0.5236, 0.5249, 0.5194, 0.5376, 0.5357,
        0.4852, 0.5017, 0.5006, 0.4424, 0.5637, 0.5359, 0.5054],
       device='cuda:0') torch.Size([16])
percent tensor([0.5145, 0.5616, 0.5931, 0.5933, 0.6273, 0.6331, 0.5712, 0.5442, 0.5991,
        0.5275, 0.6036, 0.5477, 0.5185, 0.6021, 0.4813, 0.5191],
       device='cuda:0') torch.Size([16])
percent tensor([0.6240, 0.6050, 0.6946, 0.6585, 0.7284, 0.6579, 0.6853, 0.6858, 0.6213,
        0.6206, 0.6026, 0.6408, 0.5733, 0.6591, 0.6037, 0.6258],
       device='cuda:0') torch.Size([16])
percent tensor([0.9991, 0.9987, 0.9995, 0.9986, 0.9998, 0.9990, 0.9997, 0.9999, 0.9993,
        0.9992, 0.9990, 0.9992, 0.9986, 0.9994, 0.9996, 0.9992],
       device='cuda:0') torch.Size([16])
Epoch: 85 | Batch_idx: 0 |  Loss: (0.2823) |  Loss2: (0.0000) | Acc: (91.00%) (117/128)
Epoch: 85 | Batch_idx: 10 |  Loss: (0.2570) |  Loss2: (0.0000) | Acc: (91.00%) (1290/1408)
Epoch: 85 | Batch_idx: 20 |  Loss: (0.2531) |  Loss2: (0.0000) | Acc: (91.00%) (2467/2688)
Epoch: 85 | Batch_idx: 30 |  Loss: (0.2496) |  Loss2: (0.0000) | Acc: (91.00%) (3643/3968)
Epoch: 85 | Batch_idx: 40 |  Loss: (0.2561) |  Loss2: (0.0000) | Acc: (91.00%) (4810/5248)
Epoch: 85 | Batch_idx: 50 |  Loss: (0.2637) |  Loss2: (0.0000) | Acc: (91.00%) (5960/6528)
Epoch: 85 | Batch_idx: 60 |  Loss: (0.2623) |  Loss2: (0.0000) | Acc: (91.00%) (7129/7808)
Epoch: 85 | Batch_idx: 70 |  Loss: (0.2616) |  Loss2: (0.0000) | Acc: (91.00%) (8300/9088)
Epoch: 85 | Batch_idx: 80 |  Loss: (0.2637) |  Loss2: (0.0000) | Acc: (91.00%) (9457/10368)
Epoch: 85 | Batch_idx: 90 |  Loss: (0.2613) |  Loss2: (0.0000) | Acc: (91.00%) (10630/11648)
Epoch: 85 | Batch_idx: 100 |  Loss: (0.2644) |  Loss2: (0.0000) | Acc: (91.00%) (11769/12928)
Epoch: 85 | Batch_idx: 110 |  Loss: (0.2654) |  Loss2: (0.0000) | Acc: (91.00%) (12933/14208)
Epoch: 85 | Batch_idx: 120 |  Loss: (0.2653) |  Loss2: (0.0000) | Acc: (91.00%) (14100/15488)
Epoch: 85 | Batch_idx: 130 |  Loss: (0.2635) |  Loss2: (0.0000) | Acc: (91.00%) (15270/16768)
Epoch: 85 | Batch_idx: 140 |  Loss: (0.2640) |  Loss2: (0.0000) | Acc: (91.00%) (16424/18048)
Epoch: 85 | Batch_idx: 150 |  Loss: (0.2642) |  Loss2: (0.0000) | Acc: (90.00%) (17585/19328)
Epoch: 85 | Batch_idx: 160 |  Loss: (0.2638) |  Loss2: (0.0000) | Acc: (90.00%) (18745/20608)
Epoch: 85 | Batch_idx: 170 |  Loss: (0.2658) |  Loss2: (0.0000) | Acc: (90.00%) (19893/21888)
Epoch: 85 | Batch_idx: 180 |  Loss: (0.2654) |  Loss2: (0.0000) | Acc: (90.00%) (21058/23168)
Epoch: 85 | Batch_idx: 190 |  Loss: (0.2664) |  Loss2: (0.0000) | Acc: (90.00%) (22207/24448)
Epoch: 85 | Batch_idx: 200 |  Loss: (0.2661) |  Loss2: (0.0000) | Acc: (90.00%) (23364/25728)
Epoch: 85 | Batch_idx: 210 |  Loss: (0.2676) |  Loss2: (0.0000) | Acc: (90.00%) (24521/27008)
Epoch: 85 | Batch_idx: 220 |  Loss: (0.2675) |  Loss2: (0.0000) | Acc: (90.00%) (25684/28288)
Epoch: 85 | Batch_idx: 230 |  Loss: (0.2686) |  Loss2: (0.0000) | Acc: (90.00%) (26836/29568)
Epoch: 85 | Batch_idx: 240 |  Loss: (0.2699) |  Loss2: (0.0000) | Acc: (90.00%) (27989/30848)
Epoch: 85 | Batch_idx: 250 |  Loss: (0.2714) |  Loss2: (0.0000) | Acc: (90.00%) (29131/32128)
Epoch: 85 | Batch_idx: 260 |  Loss: (0.2713) |  Loss2: (0.0000) | Acc: (90.00%) (30285/33408)
Epoch: 85 | Batch_idx: 270 |  Loss: (0.2719) |  Loss2: (0.0000) | Acc: (90.00%) (31440/34688)
Epoch: 85 | Batch_idx: 280 |  Loss: (0.2710) |  Loss2: (0.0000) | Acc: (90.00%) (32603/35968)
Epoch: 85 | Batch_idx: 290 |  Loss: (0.2716) |  Loss2: (0.0000) | Acc: (90.00%) (33750/37248)
Epoch: 85 | Batch_idx: 300 |  Loss: (0.2709) |  Loss2: (0.0000) | Acc: (90.00%) (34920/38528)
Epoch: 85 | Batch_idx: 310 |  Loss: (0.2706) |  Loss2: (0.0000) | Acc: (90.00%) (36085/39808)
Epoch: 85 | Batch_idx: 320 |  Loss: (0.2719) |  Loss2: (0.0000) | Acc: (90.00%) (37233/41088)
Epoch: 85 | Batch_idx: 330 |  Loss: (0.2719) |  Loss2: (0.0000) | Acc: (90.00%) (38387/42368)
Epoch: 85 | Batch_idx: 340 |  Loss: (0.2720) |  Loss2: (0.0000) | Acc: (90.00%) (39535/43648)
Epoch: 85 | Batch_idx: 350 |  Loss: (0.2728) |  Loss2: (0.0000) | Acc: (90.00%) (40674/44928)
Epoch: 85 | Batch_idx: 360 |  Loss: (0.2736) |  Loss2: (0.0000) | Acc: (90.00%) (41810/46208)
Epoch: 85 | Batch_idx: 370 |  Loss: (0.2740) |  Loss2: (0.0000) | Acc: (90.00%) (42966/47488)
Epoch: 85 | Batch_idx: 380 |  Loss: (0.2751) |  Loss2: (0.0000) | Acc: (90.00%) (44099/48768)
Epoch: 85 | Batch_idx: 390 |  Loss: (0.2753) |  Loss2: (0.0000) | Acc: (90.00%) (45208/50000)
=> saving checkpoint 'drive/app/torch/save_Schedule/checkpoint_085.pth.tar'
# TEST : Loss: (0.4348) | Acc: (86.00%) (8624/10000)
percent tensor([0.5412, 0.5539, 0.5681, 0.5622, 0.5698, 0.5478, 0.5592, 0.5670, 0.5471,
        0.5566, 0.5413, 0.5638, 0.5439, 0.5509, 0.5534, 0.5456],
       device='cuda:0') torch.Size([16])
percent tensor([0.5591, 0.5582, 0.5555, 0.5498, 0.5621, 0.5676, 0.5648, 0.5590, 0.5543,
        0.5537, 0.5573, 0.5609, 0.5560, 0.5515, 0.5671, 0.5584],
       device='cuda:0') torch.Size([16])
percent tensor([0.5791, 0.5752, 0.5572, 0.5520, 0.5520, 0.5755, 0.5738, 0.5638, 0.5682,
        0.5700, 0.5675, 0.5676, 0.5878, 0.5723, 0.5854, 0.5803],
       device='cuda:0') torch.Size([16])
percent tensor([0.6168, 0.6047, 0.5999, 0.5985, 0.6043, 0.6339, 0.6156, 0.5997, 0.6095,
        0.6098, 0.6145, 0.6035, 0.6040, 0.6126, 0.6222, 0.6179],
       device='cuda:0') torch.Size([16])
percent tensor([0.4795, 0.4828, 0.5363, 0.5479, 0.5426, 0.5318, 0.5165, 0.5428, 0.5176,
        0.4864, 0.4863, 0.5215, 0.4411, 0.5329, 0.5439, 0.5074],
       device='cuda:0') torch.Size([16])
percent tensor([0.5072, 0.5340, 0.6065, 0.5979, 0.6389, 0.6254, 0.5647, 0.5465, 0.5843,
        0.5110, 0.5756, 0.5600, 0.5084, 0.5957, 0.4762, 0.4990],
       device='cuda:0') torch.Size([16])
percent tensor([0.6328, 0.5930, 0.7100, 0.6697, 0.7337, 0.6579, 0.6804, 0.6972, 0.6154,
        0.6195, 0.6005, 0.6469, 0.5792, 0.6497, 0.6110, 0.6226],
       device='cuda:0') torch.Size([16])
percent tensor([0.9991, 0.9984, 0.9995, 0.9989, 0.9998, 0.9989, 0.9995, 0.9999, 0.9991,
        0.9989, 0.9988, 0.9990, 0.9984, 0.9989, 0.9990, 0.9992],
       device='cuda:0') torch.Size([16])
Epoch: 86 | Batch_idx: 0 |  Loss: (0.1980) |  Loss2: (0.0000) | Acc: (94.00%) (121/128)
Epoch: 86 | Batch_idx: 10 |  Loss: (0.2471) |  Loss2: (0.0000) | Acc: (91.00%) (1290/1408)
Epoch: 86 | Batch_idx: 20 |  Loss: (0.2481) |  Loss2: (0.0000) | Acc: (91.00%) (2458/2688)
Epoch: 86 | Batch_idx: 30 |  Loss: (0.2437) |  Loss2: (0.0000) | Acc: (91.00%) (3634/3968)
Epoch: 86 | Batch_idx: 40 |  Loss: (0.2471) |  Loss2: (0.0000) | Acc: (91.00%) (4801/5248)
Epoch: 86 | Batch_idx: 50 |  Loss: (0.2534) |  Loss2: (0.0000) | Acc: (91.00%) (5956/6528)
Epoch: 86 | Batch_idx: 60 |  Loss: (0.2515) |  Loss2: (0.0000) | Acc: (91.00%) (7131/7808)
Epoch: 86 | Batch_idx: 70 |  Loss: (0.2535) |  Loss2: (0.0000) | Acc: (91.00%) (8286/9088)
Epoch: 86 | Batch_idx: 80 |  Loss: (0.2511) |  Loss2: (0.0000) | Acc: (91.00%) (9472/10368)
Epoch: 86 | Batch_idx: 90 |  Loss: (0.2509) |  Loss2: (0.0000) | Acc: (91.00%) (10650/11648)
Epoch: 86 | Batch_idx: 100 |  Loss: (0.2518) |  Loss2: (0.0000) | Acc: (91.00%) (11818/12928)
Epoch: 86 | Batch_idx: 110 |  Loss: (0.2536) |  Loss2: (0.0000) | Acc: (91.00%) (12977/14208)
Epoch: 86 | Batch_idx: 120 |  Loss: (0.2582) |  Loss2: (0.0000) | Acc: (91.00%) (14119/15488)
Epoch: 86 | Batch_idx: 130 |  Loss: (0.2574) |  Loss2: (0.0000) | Acc: (91.00%) (15287/16768)
Epoch: 86 | Batch_idx: 140 |  Loss: (0.2605) |  Loss2: (0.0000) | Acc: (91.00%) (16430/18048)
Epoch: 86 | Batch_idx: 150 |  Loss: (0.2615) |  Loss2: (0.0000) | Acc: (90.00%) (17587/19328)
Epoch: 86 | Batch_idx: 160 |  Loss: (0.2618) |  Loss2: (0.0000) | Acc: (90.00%) (18751/20608)
Epoch: 86 | Batch_idx: 170 |  Loss: (0.2615) |  Loss2: (0.0000) | Acc: (91.00%) (19921/21888)
Epoch: 86 | Batch_idx: 180 |  Loss: (0.2626) |  Loss2: (0.0000) | Acc: (90.00%) (21081/23168)
Epoch: 86 | Batch_idx: 190 |  Loss: (0.2629) |  Loss2: (0.0000) | Acc: (90.00%) (22243/24448)
Epoch: 86 | Batch_idx: 200 |  Loss: (0.2634) |  Loss2: (0.0000) | Acc: (90.00%) (23411/25728)
Epoch: 86 | Batch_idx: 210 |  Loss: (0.2625) |  Loss2: (0.0000) | Acc: (91.00%) (24584/27008)
Epoch: 86 | Batch_idx: 220 |  Loss: (0.2621) |  Loss2: (0.0000) | Acc: (91.00%) (25761/28288)
Epoch: 86 | Batch_idx: 230 |  Loss: (0.2613) |  Loss2: (0.0000) | Acc: (91.00%) (26933/29568)
Epoch: 86 | Batch_idx: 240 |  Loss: (0.2619) |  Loss2: (0.0000) | Acc: (91.00%) (28081/30848)
Epoch: 86 | Batch_idx: 250 |  Loss: (0.2623) |  Loss2: (0.0000) | Acc: (91.00%) (29246/32128)
Epoch: 86 | Batch_idx: 260 |  Loss: (0.2635) |  Loss2: (0.0000) | Acc: (90.00%) (30393/33408)
Epoch: 86 | Batch_idx: 270 |  Loss: (0.2631) |  Loss2: (0.0000) | Acc: (90.00%) (31566/34688)
Epoch: 86 | Batch_idx: 280 |  Loss: (0.2629) |  Loss2: (0.0000) | Acc: (90.00%) (32713/35968)
Epoch: 86 | Batch_idx: 290 |  Loss: (0.2638) |  Loss2: (0.0000) | Acc: (90.00%) (33855/37248)
Epoch: 86 | Batch_idx: 300 |  Loss: (0.2644) |  Loss2: (0.0000) | Acc: (90.00%) (35002/38528)
Epoch: 86 | Batch_idx: 310 |  Loss: (0.2647) |  Loss2: (0.0000) | Acc: (90.00%) (36160/39808)
Epoch: 86 | Batch_idx: 320 |  Loss: (0.2653) |  Loss2: (0.0000) | Acc: (90.00%) (37327/41088)
Epoch: 86 | Batch_idx: 330 |  Loss: (0.2652) |  Loss2: (0.0000) | Acc: (90.00%) (38492/42368)
Epoch: 86 | Batch_idx: 340 |  Loss: (0.2647) |  Loss2: (0.0000) | Acc: (90.00%) (39667/43648)
Epoch: 86 | Batch_idx: 350 |  Loss: (0.2642) |  Loss2: (0.0000) | Acc: (90.00%) (40842/44928)
Epoch: 86 | Batch_idx: 360 |  Loss: (0.2651) |  Loss2: (0.0000) | Acc: (90.00%) (41985/46208)
Epoch: 86 | Batch_idx: 370 |  Loss: (0.2653) |  Loss2: (0.0000) | Acc: (90.00%) (43145/47488)
Epoch: 86 | Batch_idx: 380 |  Loss: (0.2653) |  Loss2: (0.0000) | Acc: (90.00%) (44310/48768)
Epoch: 86 | Batch_idx: 390 |  Loss: (0.2657) |  Loss2: (0.0000) | Acc: (90.00%) (45421/50000)
# TEST : Loss: (0.4314) | Acc: (86.00%) (8630/10000)
percent tensor([0.5415, 0.5550, 0.5672, 0.5632, 0.5699, 0.5492, 0.5598, 0.5666, 0.5485,
        0.5564, 0.5425, 0.5632, 0.5446, 0.5527, 0.5543, 0.5468],
       device='cuda:0') torch.Size([16])
percent tensor([0.5598, 0.5597, 0.5538, 0.5503, 0.5621, 0.5690, 0.5654, 0.5581, 0.5548,
        0.5541, 0.5583, 0.5604, 0.5571, 0.5520, 0.5686, 0.5591],
       device='cuda:0') torch.Size([16])
percent tensor([0.5804, 0.5820, 0.5576, 0.5521, 0.5546, 0.5775, 0.5776, 0.5612, 0.5689,
        0.5733, 0.5698, 0.5690, 0.5905, 0.5750, 0.5884, 0.5835],
       device='cuda:0') torch.Size([16])
percent tensor([0.6167, 0.6064, 0.5987, 0.5958, 0.6039, 0.6341, 0.6154, 0.5996, 0.6112,
        0.6113, 0.6159, 0.6049, 0.6067, 0.6130, 0.6224, 0.6184],
       device='cuda:0') torch.Size([16])
percent tensor([0.4852, 0.4865, 0.5151, 0.5333, 0.5314, 0.5323, 0.5153, 0.5265, 0.5192,
        0.4793, 0.4920, 0.5111, 0.4423, 0.5437, 0.5375, 0.5024],
       device='cuda:0') torch.Size([16])
percent tensor([0.5176, 0.5554, 0.6076, 0.5901, 0.6385, 0.6347, 0.5771, 0.5517, 0.5982,
        0.5285, 0.5926, 0.5591, 0.5365, 0.6006, 0.4788, 0.5144],
       device='cuda:0') torch.Size([16])
percent tensor([0.6399, 0.5956, 0.6987, 0.6725, 0.7291, 0.6609, 0.6745, 0.6904, 0.6171,
        0.6192, 0.6059, 0.6349, 0.5746, 0.6521, 0.6016, 0.6276],
       device='cuda:0') torch.Size([16])
percent tensor([0.9990, 0.9987, 0.9992, 0.9992, 0.9998, 0.9985, 0.9996, 0.9998, 0.9992,
        0.9992, 0.9996, 0.9986, 0.9985, 0.9992, 0.9991, 0.9993],
       device='cuda:0') torch.Size([16])
Epoch: 87 | Batch_idx: 0 |  Loss: (0.1772) |  Loss2: (0.0000) | Acc: (93.00%) (120/128)
Epoch: 87 | Batch_idx: 10 |  Loss: (0.2701) |  Loss2: (0.0000) | Acc: (91.00%) (1282/1408)
Epoch: 87 | Batch_idx: 20 |  Loss: (0.2564) |  Loss2: (0.0000) | Acc: (91.00%) (2458/2688)
Epoch: 87 | Batch_idx: 30 |  Loss: (0.2608) |  Loss2: (0.0000) | Acc: (91.00%) (3622/3968)
Epoch: 87 | Batch_idx: 40 |  Loss: (0.2594) |  Loss2: (0.0000) | Acc: (91.00%) (4794/5248)
Epoch: 87 | Batch_idx: 50 |  Loss: (0.2612) |  Loss2: (0.0000) | Acc: (91.00%) (5954/6528)
Epoch: 87 | Batch_idx: 60 |  Loss: (0.2604) |  Loss2: (0.0000) | Acc: (91.00%) (7120/7808)
Epoch: 87 | Batch_idx: 70 |  Loss: (0.2602) |  Loss2: (0.0000) | Acc: (91.00%) (8290/9088)
Epoch: 87 | Batch_idx: 80 |  Loss: (0.2576) |  Loss2: (0.0000) | Acc: (91.00%) (9471/10368)
Epoch: 87 | Batch_idx: 90 |  Loss: (0.2595) |  Loss2: (0.0000) | Acc: (91.00%) (10632/11648)
Epoch: 87 | Batch_idx: 100 |  Loss: (0.2582) |  Loss2: (0.0000) | Acc: (91.00%) (11799/12928)
Epoch: 87 | Batch_idx: 110 |  Loss: (0.2560) |  Loss2: (0.0000) | Acc: (91.00%) (12979/14208)
Epoch: 87 | Batch_idx: 120 |  Loss: (0.2537) |  Loss2: (0.0000) | Acc: (91.00%) (14156/15488)
Epoch: 87 | Batch_idx: 130 |  Loss: (0.2569) |  Loss2: (0.0000) | Acc: (91.00%) (15313/16768)
Epoch: 87 | Batch_idx: 140 |  Loss: (0.2575) |  Loss2: (0.0000) | Acc: (91.00%) (16468/18048)
Epoch: 87 | Batch_idx: 150 |  Loss: (0.2561) |  Loss2: (0.0000) | Acc: (91.00%) (17635/19328)
Epoch: 87 | Batch_idx: 160 |  Loss: (0.2558) |  Loss2: (0.0000) | Acc: (91.00%) (18804/20608)
Epoch: 87 | Batch_idx: 170 |  Loss: (0.2547) |  Loss2: (0.0000) | Acc: (91.00%) (19975/21888)
Epoch: 87 | Batch_idx: 180 |  Loss: (0.2559) |  Loss2: (0.0000) | Acc: (91.00%) (21125/23168)
Epoch: 87 | Batch_idx: 190 |  Loss: (0.2568) |  Loss2: (0.0000) | Acc: (91.00%) (22290/24448)
Epoch: 87 | Batch_idx: 200 |  Loss: (0.2568) |  Loss2: (0.0000) | Acc: (91.00%) (23453/25728)
Epoch: 87 | Batch_idx: 210 |  Loss: (0.2570) |  Loss2: (0.0000) | Acc: (91.00%) (24616/27008)
Epoch: 87 | Batch_idx: 220 |  Loss: (0.2568) |  Loss2: (0.0000) | Acc: (91.00%) (25797/28288)
Epoch: 87 | Batch_idx: 230 |  Loss: (0.2550) |  Loss2: (0.0000) | Acc: (91.00%) (26989/29568)
Epoch: 87 | Batch_idx: 240 |  Loss: (0.2553) |  Loss2: (0.0000) | Acc: (91.00%) (28148/30848)
Epoch: 87 | Batch_idx: 250 |  Loss: (0.2552) |  Loss2: (0.0000) | Acc: (91.00%) (29309/32128)
Epoch: 87 | Batch_idx: 260 |  Loss: (0.2550) |  Loss2: (0.0000) | Acc: (91.00%) (30504/33408)
Epoch: 87 | Batch_idx: 270 |  Loss: (0.2545) |  Loss2: (0.0000) | Acc: (91.00%) (31685/34688)
Epoch: 87 | Batch_idx: 280 |  Loss: (0.2536) |  Loss2: (0.0000) | Acc: (91.00%) (32862/35968)
Epoch: 87 | Batch_idx: 290 |  Loss: (0.2542) |  Loss2: (0.0000) | Acc: (91.00%) (34029/37248)
Epoch: 87 | Batch_idx: 300 |  Loss: (0.2541) |  Loss2: (0.0000) | Acc: (91.00%) (35204/38528)
Epoch: 87 | Batch_idx: 310 |  Loss: (0.2552) |  Loss2: (0.0000) | Acc: (91.00%) (36349/39808)
Epoch: 87 | Batch_idx: 320 |  Loss: (0.2548) |  Loss2: (0.0000) | Acc: (91.00%) (37521/41088)
Epoch: 87 | Batch_idx: 330 |  Loss: (0.2555) |  Loss2: (0.0000) | Acc: (91.00%) (38678/42368)
Epoch: 87 | Batch_idx: 340 |  Loss: (0.2557) |  Loss2: (0.0000) | Acc: (91.00%) (39831/43648)
Epoch: 87 | Batch_idx: 350 |  Loss: (0.2556) |  Loss2: (0.0000) | Acc: (91.00%) (40998/44928)
Epoch: 87 | Batch_idx: 360 |  Loss: (0.2552) |  Loss2: (0.0000) | Acc: (91.00%) (42171/46208)
Epoch: 87 | Batch_idx: 370 |  Loss: (0.2553) |  Loss2: (0.0000) | Acc: (91.00%) (43343/47488)
Epoch: 87 | Batch_idx: 380 |  Loss: (0.2563) |  Loss2: (0.0000) | Acc: (91.00%) (44493/48768)
Epoch: 87 | Batch_idx: 390 |  Loss: (0.2563) |  Loss2: (0.0000) | Acc: (91.00%) (45613/50000)
# TEST : Loss: (0.6149) | Acc: (81.00%) (8102/10000)
percent tensor([0.5417, 0.5539, 0.5685, 0.5632, 0.5705, 0.5486, 0.5593, 0.5671, 0.5476,
        0.5560, 0.5408, 0.5642, 0.5442, 0.5517, 0.5535, 0.5459],
       device='cuda:0') torch.Size([16])
percent tensor([0.5598, 0.5626, 0.5522, 0.5494, 0.5603, 0.5678, 0.5676, 0.5591, 0.5557,
        0.5560, 0.5601, 0.5608, 0.5575, 0.5576, 0.5693, 0.5606],
       device='cuda:0') torch.Size([16])
percent tensor([0.5833, 0.5810, 0.5595, 0.5511, 0.5562, 0.5758, 0.5781, 0.5659, 0.5704,
        0.5750, 0.5694, 0.5735, 0.5917, 0.5736, 0.5892, 0.5831],
       device='cuda:0') torch.Size([16])
percent tensor([0.6163, 0.6096, 0.5939, 0.5935, 0.6004, 0.6374, 0.6193, 0.5967, 0.6085,
        0.6107, 0.6178, 0.6031, 0.6057, 0.6165, 0.6255, 0.6189],
       device='cuda:0') torch.Size([16])
percent tensor([0.4829, 0.4691, 0.5373, 0.5302, 0.5432, 0.5315, 0.5022, 0.5355, 0.5258,
        0.4806, 0.4802, 0.5076, 0.4318, 0.5324, 0.5211, 0.4972],
       device='cuda:0') torch.Size([16])
percent tensor([0.5149, 0.5796, 0.5921, 0.6017, 0.6337, 0.6278, 0.5883, 0.5541, 0.5990,
        0.5305, 0.5883, 0.5625, 0.5268, 0.6291, 0.4944, 0.5052],
       device='cuda:0') torch.Size([16])
percent tensor([0.6299, 0.5951, 0.6914, 0.6645, 0.7304, 0.6532, 0.6830, 0.6846, 0.6238,
        0.6216, 0.6046, 0.6349, 0.5781, 0.6663, 0.6033, 0.6179],
       device='cuda:0') torch.Size([16])
percent tensor([0.9991, 0.9990, 0.9995, 0.9992, 0.9998, 0.9993, 0.9998, 0.9998, 0.9995,
        0.9996, 0.9996, 0.9994, 0.9990, 0.9995, 0.9997, 0.9992],
       device='cuda:0') torch.Size([16])
Epoch: 88 | Batch_idx: 0 |  Loss: (0.2375) |  Loss2: (0.0000) | Acc: (92.00%) (118/128)
Epoch: 88 | Batch_idx: 10 |  Loss: (0.2401) |  Loss2: (0.0000) | Acc: (92.00%) (1297/1408)
Epoch: 88 | Batch_idx: 20 |  Loss: (0.2540) |  Loss2: (0.0000) | Acc: (91.00%) (2451/2688)
Epoch: 88 | Batch_idx: 30 |  Loss: (0.2394) |  Loss2: (0.0000) | Acc: (91.00%) (3637/3968)
Epoch: 88 | Batch_idx: 40 |  Loss: (0.2426) |  Loss2: (0.0000) | Acc: (91.00%) (4806/5248)
Epoch: 88 | Batch_idx: 50 |  Loss: (0.2440) |  Loss2: (0.0000) | Acc: (91.00%) (5967/6528)
Epoch: 88 | Batch_idx: 60 |  Loss: (0.2435) |  Loss2: (0.0000) | Acc: (91.00%) (7145/7808)
Epoch: 88 | Batch_idx: 70 |  Loss: (0.2456) |  Loss2: (0.0000) | Acc: (91.00%) (8307/9088)
Epoch: 88 | Batch_idx: 80 |  Loss: (0.2472) |  Loss2: (0.0000) | Acc: (91.00%) (9457/10368)
Epoch: 88 | Batch_idx: 90 |  Loss: (0.2449) |  Loss2: (0.0000) | Acc: (91.00%) (10638/11648)
Epoch: 88 | Batch_idx: 100 |  Loss: (0.2471) |  Loss2: (0.0000) | Acc: (91.00%) (11802/12928)
Epoch: 88 | Batch_idx: 110 |  Loss: (0.2489) |  Loss2: (0.0000) | Acc: (91.00%) (12964/14208)
Epoch: 88 | Batch_idx: 120 |  Loss: (0.2521) |  Loss2: (0.0000) | Acc: (91.00%) (14111/15488)
Epoch: 88 | Batch_idx: 130 |  Loss: (0.2503) |  Loss2: (0.0000) | Acc: (91.00%) (15297/16768)
Epoch: 88 | Batch_idx: 140 |  Loss: (0.2514) |  Loss2: (0.0000) | Acc: (91.00%) (16464/18048)
Epoch: 88 | Batch_idx: 150 |  Loss: (0.2499) |  Loss2: (0.0000) | Acc: (91.00%) (17631/19328)
Epoch: 88 | Batch_idx: 160 |  Loss: (0.2503) |  Loss2: (0.0000) | Acc: (91.00%) (18794/20608)
Epoch: 88 | Batch_idx: 170 |  Loss: (0.2508) |  Loss2: (0.0000) | Acc: (91.00%) (19964/21888)
Epoch: 88 | Batch_idx: 180 |  Loss: (0.2515) |  Loss2: (0.0000) | Acc: (91.00%) (21126/23168)
Epoch: 88 | Batch_idx: 190 |  Loss: (0.2508) |  Loss2: (0.0000) | Acc: (91.00%) (22300/24448)
Epoch: 88 | Batch_idx: 200 |  Loss: (0.2498) |  Loss2: (0.0000) | Acc: (91.00%) (23479/25728)
Epoch: 88 | Batch_idx: 210 |  Loss: (0.2486) |  Loss2: (0.0000) | Acc: (91.00%) (24658/27008)
Epoch: 88 | Batch_idx: 220 |  Loss: (0.2494) |  Loss2: (0.0000) | Acc: (91.00%) (25823/28288)
Epoch: 88 | Batch_idx: 230 |  Loss: (0.2488) |  Loss2: (0.0000) | Acc: (91.00%) (27005/29568)
Epoch: 88 | Batch_idx: 240 |  Loss: (0.2491) |  Loss2: (0.0000) | Acc: (91.00%) (28167/30848)
Epoch: 88 | Batch_idx: 250 |  Loss: (0.2503) |  Loss2: (0.0000) | Acc: (91.00%) (29323/32128)
Epoch: 88 | Batch_idx: 260 |  Loss: (0.2510) |  Loss2: (0.0000) | Acc: (91.00%) (30494/33408)
Epoch: 88 | Batch_idx: 270 |  Loss: (0.2517) |  Loss2: (0.0000) | Acc: (91.00%) (31663/34688)
Epoch: 88 | Batch_idx: 280 |  Loss: (0.2531) |  Loss2: (0.0000) | Acc: (91.00%) (32809/35968)
Epoch: 88 | Batch_idx: 290 |  Loss: (0.2531) |  Loss2: (0.0000) | Acc: (91.00%) (33977/37248)
Epoch: 88 | Batch_idx: 300 |  Loss: (0.2533) |  Loss2: (0.0000) | Acc: (91.00%) (35134/38528)
Epoch: 88 | Batch_idx: 310 |  Loss: (0.2532) |  Loss2: (0.0000) | Acc: (91.00%) (36307/39808)
Epoch: 88 | Batch_idx: 320 |  Loss: (0.2532) |  Loss2: (0.0000) | Acc: (91.00%) (37476/41088)
Epoch: 88 | Batch_idx: 330 |  Loss: (0.2540) |  Loss2: (0.0000) | Acc: (91.00%) (38628/42368)
Epoch: 88 | Batch_idx: 340 |  Loss: (0.2541) |  Loss2: (0.0000) | Acc: (91.00%) (39788/43648)
Epoch: 88 | Batch_idx: 350 |  Loss: (0.2547) |  Loss2: (0.0000) | Acc: (91.00%) (40943/44928)
Epoch: 88 | Batch_idx: 360 |  Loss: (0.2547) |  Loss2: (0.0000) | Acc: (91.00%) (42116/46208)
Epoch: 88 | Batch_idx: 370 |  Loss: (0.2547) |  Loss2: (0.0000) | Acc: (91.00%) (43286/47488)
Epoch: 88 | Batch_idx: 380 |  Loss: (0.2551) |  Loss2: (0.0000) | Acc: (91.00%) (44446/48768)
Epoch: 88 | Batch_idx: 390 |  Loss: (0.2545) |  Loss2: (0.0000) | Acc: (91.00%) (45578/50000)
# TEST : Loss: (0.4906) | Acc: (84.00%) (8433/10000)
percent tensor([0.5412, 0.5563, 0.5633, 0.5609, 0.5668, 0.5483, 0.5598, 0.5646, 0.5475,
        0.5551, 0.5422, 0.5604, 0.5434, 0.5564, 0.5540, 0.5461],
       device='cuda:0') torch.Size([16])
percent tensor([0.5602, 0.5607, 0.5557, 0.5515, 0.5636, 0.5677, 0.5664, 0.5587, 0.5559,
        0.5552, 0.5593, 0.5608, 0.5575, 0.5548, 0.5682, 0.5604],
       device='cuda:0') torch.Size([16])
percent tensor([0.5817, 0.5819, 0.5562, 0.5513, 0.5553, 0.5775, 0.5775, 0.5614, 0.5701,
        0.5725, 0.5704, 0.5669, 0.5913, 0.5750, 0.5898, 0.5849],
       device='cuda:0') torch.Size([16])
percent tensor([0.6154, 0.6062, 0.5980, 0.5976, 0.6057, 0.6357, 0.6156, 0.5981, 0.6091,
        0.6093, 0.6171, 0.6028, 0.6064, 0.6125, 0.6222, 0.6190],
       device='cuda:0') torch.Size([16])
percent tensor([0.4786, 0.4871, 0.5091, 0.5357, 0.5299, 0.5394, 0.5054, 0.5305, 0.5291,
        0.4857, 0.5011, 0.4950, 0.4444, 0.5643, 0.5371, 0.5035],
       device='cuda:0') torch.Size([16])
percent tensor([0.5061, 0.5522, 0.5888, 0.5620, 0.6153, 0.6151, 0.5750, 0.5327, 0.6001,
        0.5288, 0.6059, 0.5654, 0.5428, 0.6007, 0.4530, 0.4987],
       device='cuda:0') torch.Size([16])
percent tensor([0.6280, 0.5949, 0.6947, 0.6503, 0.7127, 0.6494, 0.6671, 0.6747, 0.6289,
        0.6167, 0.6069, 0.6313, 0.5834, 0.6592, 0.6018, 0.6124],
       device='cuda:0') torch.Size([16])
percent tensor([0.9991, 0.9994, 0.9994, 0.9987, 0.9995, 0.9991, 0.9996, 0.9998, 0.9995,
        0.9994, 0.9995, 0.9990, 0.9989, 0.9994, 0.9994, 0.9992],
       device='cuda:0') torch.Size([16])
Epoch: 89 | Batch_idx: 0 |  Loss: (0.2266) |  Loss2: (0.0000) | Acc: (91.00%) (117/128)
Epoch: 89 | Batch_idx: 10 |  Loss: (0.2309) |  Loss2: (0.0000) | Acc: (91.00%) (1282/1408)
Epoch: 89 | Batch_idx: 20 |  Loss: (0.2358) |  Loss2: (0.0000) | Acc: (91.00%) (2461/2688)
Epoch: 89 | Batch_idx: 30 |  Loss: (0.2413) |  Loss2: (0.0000) | Acc: (91.00%) (3624/3968)
Epoch: 89 | Batch_idx: 40 |  Loss: (0.2381) |  Loss2: (0.0000) | Acc: (91.00%) (4805/5248)
Epoch: 89 | Batch_idx: 50 |  Loss: (0.2382) |  Loss2: (0.0000) | Acc: (91.00%) (5974/6528)
Epoch: 89 | Batch_idx: 60 |  Loss: (0.2374) |  Loss2: (0.0000) | Acc: (91.00%) (7158/7808)
Epoch: 89 | Batch_idx: 70 |  Loss: (0.2357) |  Loss2: (0.0000) | Acc: (91.00%) (8347/9088)
Epoch: 89 | Batch_idx: 80 |  Loss: (0.2377) |  Loss2: (0.0000) | Acc: (91.00%) (9516/10368)
Epoch: 89 | Batch_idx: 90 |  Loss: (0.2379) |  Loss2: (0.0000) | Acc: (91.00%) (10687/11648)
Epoch: 89 | Batch_idx: 100 |  Loss: (0.2370) |  Loss2: (0.0000) | Acc: (91.00%) (11865/12928)
Epoch: 89 | Batch_idx: 110 |  Loss: (0.2391) |  Loss2: (0.0000) | Acc: (91.00%) (13032/14208)
Epoch: 89 | Batch_idx: 120 |  Loss: (0.2382) |  Loss2: (0.0000) | Acc: (91.00%) (14216/15488)
Epoch: 89 | Batch_idx: 130 |  Loss: (0.2398) |  Loss2: (0.0000) | Acc: (91.00%) (15378/16768)
Epoch: 89 | Batch_idx: 140 |  Loss: (0.2410) |  Loss2: (0.0000) | Acc: (91.00%) (16543/18048)
Epoch: 89 | Batch_idx: 150 |  Loss: (0.2410) |  Loss2: (0.0000) | Acc: (91.00%) (17716/19328)
Epoch: 89 | Batch_idx: 160 |  Loss: (0.2430) |  Loss2: (0.0000) | Acc: (91.00%) (18883/20608)
Epoch: 89 | Batch_idx: 170 |  Loss: (0.2422) |  Loss2: (0.0000) | Acc: (91.00%) (20061/21888)
Epoch: 89 | Batch_idx: 180 |  Loss: (0.2424) |  Loss2: (0.0000) | Acc: (91.00%) (21236/23168)
Epoch: 89 | Batch_idx: 190 |  Loss: (0.2425) |  Loss2: (0.0000) | Acc: (91.00%) (22409/24448)
Epoch: 89 | Batch_idx: 200 |  Loss: (0.2420) |  Loss2: (0.0000) | Acc: (91.00%) (23575/25728)
Epoch: 89 | Batch_idx: 210 |  Loss: (0.2418) |  Loss2: (0.0000) | Acc: (91.00%) (24753/27008)
Epoch: 89 | Batch_idx: 220 |  Loss: (0.2429) |  Loss2: (0.0000) | Acc: (91.00%) (25913/28288)
Epoch: 89 | Batch_idx: 230 |  Loss: (0.2430) |  Loss2: (0.0000) | Acc: (91.00%) (27082/29568)
Epoch: 89 | Batch_idx: 240 |  Loss: (0.2422) |  Loss2: (0.0000) | Acc: (91.00%) (28264/30848)
Epoch: 89 | Batch_idx: 250 |  Loss: (0.2417) |  Loss2: (0.0000) | Acc: (91.00%) (29448/32128)
Epoch: 89 | Batch_idx: 260 |  Loss: (0.2400) |  Loss2: (0.0000) | Acc: (91.00%) (30647/33408)
Epoch: 89 | Batch_idx: 270 |  Loss: (0.2394) |  Loss2: (0.0000) | Acc: (91.00%) (31829/34688)
Epoch: 89 | Batch_idx: 280 |  Loss: (0.2398) |  Loss2: (0.0000) | Acc: (91.00%) (32996/35968)
Epoch: 89 | Batch_idx: 290 |  Loss: (0.2400) |  Loss2: (0.0000) | Acc: (91.00%) (34165/37248)
Epoch: 89 | Batch_idx: 300 |  Loss: (0.2414) |  Loss2: (0.0000) | Acc: (91.00%) (35325/38528)
Epoch: 89 | Batch_idx: 310 |  Loss: (0.2406) |  Loss2: (0.0000) | Acc: (91.00%) (36501/39808)
Epoch: 89 | Batch_idx: 320 |  Loss: (0.2395) |  Loss2: (0.0000) | Acc: (91.00%) (37692/41088)
Epoch: 89 | Batch_idx: 330 |  Loss: (0.2401) |  Loss2: (0.0000) | Acc: (91.00%) (38866/42368)
Epoch: 89 | Batch_idx: 340 |  Loss: (0.2407) |  Loss2: (0.0000) | Acc: (91.00%) (40033/43648)
Epoch: 89 | Batch_idx: 350 |  Loss: (0.2417) |  Loss2: (0.0000) | Acc: (91.00%) (41182/44928)
Epoch: 89 | Batch_idx: 360 |  Loss: (0.2427) |  Loss2: (0.0000) | Acc: (91.00%) (42336/46208)
Epoch: 89 | Batch_idx: 370 |  Loss: (0.2442) |  Loss2: (0.0000) | Acc: (91.00%) (43485/47488)
Epoch: 89 | Batch_idx: 380 |  Loss: (0.2448) |  Loss2: (0.0000) | Acc: (91.00%) (44659/48768)
Epoch: 89 | Batch_idx: 390 |  Loss: (0.2449) |  Loss2: (0.0000) | Acc: (91.00%) (45785/50000)
# TEST : Loss: (0.4437) | Acc: (85.00%) (8596/10000)
percent tensor([0.5423, 0.5540, 0.5677, 0.5612, 0.5706, 0.5498, 0.5593, 0.5656, 0.5486,
        0.5554, 0.5419, 0.5643, 0.5448, 0.5505, 0.5539, 0.5457],
       device='cuda:0') torch.Size([16])
percent tensor([0.5593, 0.5599, 0.5543, 0.5496, 0.5620, 0.5676, 0.5658, 0.5590, 0.5548,
        0.5542, 0.5586, 0.5611, 0.5566, 0.5538, 0.5676, 0.5599],
       device='cuda:0') torch.Size([16])
percent tensor([0.5836, 0.5776, 0.5616, 0.5495, 0.5592, 0.5767, 0.5764, 0.5654, 0.5692,
        0.5726, 0.5690, 0.5719, 0.5927, 0.5659, 0.5871, 0.5855],
       device='cuda:0') torch.Size([16])
percent tensor([0.6166, 0.6057, 0.5936, 0.5950, 0.6007, 0.6361, 0.6144, 0.5954, 0.6061,
        0.6092, 0.6154, 0.6002, 0.6047, 0.6136, 0.6225, 0.6205],
       device='cuda:0') torch.Size([16])
percent tensor([0.4931, 0.4712, 0.5351, 0.5407, 0.5471, 0.5495, 0.4948, 0.5334, 0.5239,
        0.4813, 0.4913, 0.5100, 0.4400, 0.5449, 0.5360, 0.5052],
       device='cuda:0') torch.Size([16])
percent tensor([0.5132, 0.5693, 0.5935, 0.5905, 0.6184, 0.6250, 0.5769, 0.5408, 0.6077,
        0.5310, 0.6110, 0.5725, 0.5622, 0.6135, 0.4750, 0.5055],
       device='cuda:0') torch.Size([16])
percent tensor([0.6274, 0.5908, 0.6944, 0.6495, 0.7051, 0.6304, 0.6721, 0.6704, 0.6261,
        0.6141, 0.6152, 0.6342, 0.5793, 0.6648, 0.5963, 0.6166],
       device='cuda:0') torch.Size([16])
percent tensor([0.9991, 0.9990, 0.9995, 0.9989, 0.9996, 0.9984, 0.9996, 0.9999, 0.9995,
        0.9994, 0.9996, 0.9990, 0.9989, 0.9996, 0.9991, 0.9993],
       device='cuda:0') torch.Size([16])
Epoch: 90 | Batch_idx: 0 |  Loss: (0.3070) |  Loss2: (0.0000) | Acc: (88.00%) (113/128)
Epoch: 90 | Batch_idx: 10 |  Loss: (0.1995) |  Loss2: (0.0000) | Acc: (93.00%) (1318/1408)
Epoch: 90 | Batch_idx: 20 |  Loss: (0.2042) |  Loss2: (0.0000) | Acc: (93.00%) (2511/2688)
Epoch: 90 | Batch_idx: 30 |  Loss: (0.2181) |  Loss2: (0.0000) | Acc: (92.00%) (3687/3968)
Epoch: 90 | Batch_idx: 40 |  Loss: (0.2261) |  Loss2: (0.0000) | Acc: (92.00%) (4858/5248)
Epoch: 90 | Batch_idx: 50 |  Loss: (0.2286) |  Loss2: (0.0000) | Acc: (92.00%) (6042/6528)
Epoch: 90 | Batch_idx: 60 |  Loss: (0.2292) |  Loss2: (0.0000) | Acc: (92.00%) (7213/7808)
Epoch: 90 | Batch_idx: 70 |  Loss: (0.2311) |  Loss2: (0.0000) | Acc: (92.00%) (8378/9088)
Epoch: 90 | Batch_idx: 80 |  Loss: (0.2308) |  Loss2: (0.0000) | Acc: (92.00%) (9551/10368)
Epoch: 90 | Batch_idx: 90 |  Loss: (0.2304) |  Loss2: (0.0000) | Acc: (92.00%) (10725/11648)
Epoch: 90 | Batch_idx: 100 |  Loss: (0.2326) |  Loss2: (0.0000) | Acc: (91.00%) (11881/12928)
Epoch: 90 | Batch_idx: 110 |  Loss: (0.2371) |  Loss2: (0.0000) | Acc: (91.00%) (13033/14208)
Epoch: 90 | Batch_idx: 120 |  Loss: (0.2398) |  Loss2: (0.0000) | Acc: (91.00%) (14178/15488)
Epoch: 90 | Batch_idx: 130 |  Loss: (0.2395) |  Loss2: (0.0000) | Acc: (91.00%) (15355/16768)
Epoch: 90 | Batch_idx: 140 |  Loss: (0.2375) |  Loss2: (0.0000) | Acc: (91.00%) (16541/18048)
Epoch: 90 | Batch_idx: 150 |  Loss: (0.2380) |  Loss2: (0.0000) | Acc: (91.00%) (17716/19328)
Epoch: 90 | Batch_idx: 160 |  Loss: (0.2395) |  Loss2: (0.0000) | Acc: (91.00%) (18882/20608)
Epoch: 90 | Batch_idx: 170 |  Loss: (0.2393) |  Loss2: (0.0000) | Acc: (91.00%) (20048/21888)
Epoch: 90 | Batch_idx: 180 |  Loss: (0.2403) |  Loss2: (0.0000) | Acc: (91.00%) (21220/23168)
Epoch: 90 | Batch_idx: 190 |  Loss: (0.2406) |  Loss2: (0.0000) | Acc: (91.00%) (22394/24448)
Epoch: 90 | Batch_idx: 200 |  Loss: (0.2435) |  Loss2: (0.0000) | Acc: (91.00%) (23537/25728)
Epoch: 90 | Batch_idx: 210 |  Loss: (0.2424) |  Loss2: (0.0000) | Acc: (91.00%) (24721/27008)
Epoch: 90 | Batch_idx: 220 |  Loss: (0.2423) |  Loss2: (0.0000) | Acc: (91.00%) (25892/28288)
Epoch: 90 | Batch_idx: 230 |  Loss: (0.2414) |  Loss2: (0.0000) | Acc: (91.00%) (27070/29568)
Epoch: 90 | Batch_idx: 240 |  Loss: (0.2405) |  Loss2: (0.0000) | Acc: (91.00%) (28262/30848)
Epoch: 90 | Batch_idx: 250 |  Loss: (0.2427) |  Loss2: (0.0000) | Acc: (91.00%) (29410/32128)
Epoch: 90 | Batch_idx: 260 |  Loss: (0.2417) |  Loss2: (0.0000) | Acc: (91.00%) (30597/33408)
Epoch: 90 | Batch_idx: 270 |  Loss: (0.2408) |  Loss2: (0.0000) | Acc: (91.00%) (31778/34688)
Epoch: 90 | Batch_idx: 280 |  Loss: (0.2412) |  Loss2: (0.0000) | Acc: (91.00%) (32934/35968)
Epoch: 90 | Batch_idx: 290 |  Loss: (0.2409) |  Loss2: (0.0000) | Acc: (91.00%) (34112/37248)
Epoch: 90 | Batch_idx: 300 |  Loss: (0.2405) |  Loss2: (0.0000) | Acc: (91.00%) (35292/38528)
Epoch: 90 | Batch_idx: 310 |  Loss: (0.2400) |  Loss2: (0.0000) | Acc: (91.00%) (36475/39808)
Epoch: 90 | Batch_idx: 320 |  Loss: (0.2404) |  Loss2: (0.0000) | Acc: (91.00%) (37648/41088)
Epoch: 90 | Batch_idx: 330 |  Loss: (0.2402) |  Loss2: (0.0000) | Acc: (91.00%) (38832/42368)
Epoch: 90 | Batch_idx: 340 |  Loss: (0.2404) |  Loss2: (0.0000) | Acc: (91.00%) (40002/43648)
Epoch: 90 | Batch_idx: 350 |  Loss: (0.2414) |  Loss2: (0.0000) | Acc: (91.00%) (41168/44928)
Epoch: 90 | Batch_idx: 360 |  Loss: (0.2426) |  Loss2: (0.0000) | Acc: (91.00%) (42308/46208)
Epoch: 90 | Batch_idx: 370 |  Loss: (0.2431) |  Loss2: (0.0000) | Acc: (91.00%) (43468/47488)
Epoch: 90 | Batch_idx: 380 |  Loss: (0.2427) |  Loss2: (0.0000) | Acc: (91.00%) (44646/48768)
Epoch: 90 | Batch_idx: 390 |  Loss: (0.2420) |  Loss2: (0.0000) | Acc: (91.00%) (45786/50000)
=> saving checkpoint 'drive/app/torch/save_Schedule/checkpoint_090.pth.tar'
# TEST : Loss: (0.4780) | Acc: (85.00%) (8507/10000)
percent tensor([0.5423, 0.5541, 0.5681, 0.5620, 0.5703, 0.5487, 0.5598, 0.5663, 0.5491,
        0.5559, 0.5420, 0.5646, 0.5446, 0.5529, 0.5532, 0.5465],
       device='cuda:0') torch.Size([16])
percent tensor([0.5595, 0.5599, 0.5545, 0.5502, 0.5616, 0.5663, 0.5658, 0.5598, 0.5545,
        0.5545, 0.5578, 0.5606, 0.5562, 0.5544, 0.5679, 0.5600],
       device='cuda:0') torch.Size([16])
percent tensor([0.5830, 0.5788, 0.5624, 0.5514, 0.5570, 0.5747, 0.5771, 0.5653, 0.5733,
        0.5742, 0.5695, 0.5720, 0.5918, 0.5715, 0.5852, 0.5846],
       device='cuda:0') torch.Size([16])
percent tensor([0.6153, 0.6044, 0.5937, 0.5964, 0.6023, 0.6364, 0.6141, 0.5972, 0.6081,
        0.6065, 0.6136, 0.5997, 0.6043, 0.6138, 0.6211, 0.6181],
       device='cuda:0') torch.Size([16])
percent tensor([0.4958, 0.4806, 0.5324, 0.5388, 0.5364, 0.5433, 0.5065, 0.5307, 0.5253,
        0.4808, 0.5107, 0.5068, 0.4547, 0.5466, 0.5336, 0.5162],
       device='cuda:0') torch.Size([16])
percent tensor([0.4993, 0.5652, 0.5954, 0.5960, 0.6176, 0.6277, 0.5672, 0.5477, 0.5901,
        0.5249, 0.5986, 0.5518, 0.5294, 0.5998, 0.4620, 0.5001],
       device='cuda:0') torch.Size([16])
percent tensor([0.6275, 0.6014, 0.6932, 0.6603, 0.7056, 0.6298, 0.6750, 0.6845, 0.6141,
        0.6211, 0.6153, 0.6322, 0.5832, 0.6656, 0.5931, 0.6136],
       device='cuda:0') torch.Size([16])
percent tensor([0.9992, 0.9989, 0.9992, 0.9987, 0.9995, 0.9987, 0.9996, 0.9998, 0.9996,
        0.9994, 0.9996, 0.9985, 0.9991, 0.9996, 0.9995, 0.9994],
       device='cuda:0') torch.Size([16])
False Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=128, out_features=16, bias=False)
True Linear(in_features=16, out_features=2, bias=False)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=128, out_features=16, bias=False)
True Linear(in_features=16, out_features=2, bias=False)
False Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=256, out_features=32, bias=False)
True Linear(in_features=32, out_features=2, bias=False)
False Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=256, out_features=32, bias=False)
True Linear(in_features=32, out_features=2, bias=False)
False Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=512, out_features=64, bias=False)
True Linear(in_features=64, out_features=2, bias=False)
False Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=512, out_features=64, bias=False)
True Linear(in_features=64, out_features=2, bias=False)
False Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1024, out_features=128, bias=False)
True Linear(in_features=128, out_features=2, bias=False)
False Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1024, out_features=128, bias=False)
True Linear(in_features=128, out_features=2, bias=False)
False Linear(in_features=512, out_features=10, bias=True)
Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 3, 3, 3]) tensor(184.4956, device='cuda:0')
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(807.8283, device='cuda:0')
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(823.9525, device='cuda:0')
Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([128, 64, 3, 3]) tensor(1533.0037, device='cuda:0')
Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([128, 64, 1, 1]) tensor(501.0329, device='cuda:0')
Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([128, 128, 3, 3]) tensor(2237.5347, device='cuda:0')
Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([256, 128, 3, 3]) tensor(4284.2061, device='cuda:0')
Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([256, 128, 1, 1]) tensor(1395.1287, device='cuda:0')
Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([256, 256, 3, 3]) tensor(6138.9199, device='cuda:0')
Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([512, 256, 3, 3]) tensor(11907.6924, device='cuda:0')
Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([512, 256, 1, 1]) tensor(3954.7678, device='cuda:0')
Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([512, 512, 3, 3]) tensor(16709.6133, device='cuda:0')
Epoch: 91 | Batch_idx: 0 |  Loss: (0.2120) |  Loss2: (0.0000) | Acc: (92.00%) (119/128)
Epoch: 91 | Batch_idx: 10 |  Loss: (0.2782) |  Loss2: (0.0000) | Acc: (90.00%) (1274/1408)
Epoch: 91 | Batch_idx: 20 |  Loss: (0.2587) |  Loss2: (0.0000) | Acc: (91.00%) (2450/2688)
Epoch: 91 | Batch_idx: 30 |  Loss: (0.2637) |  Loss2: (0.0000) | Acc: (91.00%) (3611/3968)
Epoch: 91 | Batch_idx: 40 |  Loss: (0.2588) |  Loss2: (0.0000) | Acc: (91.00%) (4784/5248)
Epoch: 91 | Batch_idx: 50 |  Loss: (0.2639) |  Loss2: (0.0000) | Acc: (91.00%) (5944/6528)
Epoch: 91 | Batch_idx: 60 |  Loss: (0.2638) |  Loss2: (0.0000) | Acc: (91.00%) (7113/7808)
Epoch: 91 | Batch_idx: 70 |  Loss: (0.2654) |  Loss2: (0.0000) | Acc: (90.00%) (8263/9088)
Epoch: 91 | Batch_idx: 80 |  Loss: (0.2635) |  Loss2: (0.0000) | Acc: (91.00%) (9435/10368)
Epoch: 91 | Batch_idx: 90 |  Loss: (0.2663) |  Loss2: (0.0000) | Acc: (90.00%) (10596/11648)
Epoch: 91 | Batch_idx: 100 |  Loss: (0.2654) |  Loss2: (0.0000) | Acc: (90.00%) (11764/12928)
Epoch: 91 | Batch_idx: 110 |  Loss: (0.2660) |  Loss2: (0.0000) | Acc: (90.00%) (12918/14208)
Epoch: 91 | Batch_idx: 120 |  Loss: (0.2672) |  Loss2: (0.0000) | Acc: (90.00%) (14066/15488)
Epoch: 91 | Batch_idx: 130 |  Loss: (0.2671) |  Loss2: (0.0000) | Acc: (90.00%) (15226/16768)
Epoch: 91 | Batch_idx: 140 |  Loss: (0.2655) |  Loss2: (0.0000) | Acc: (90.00%) (16389/18048)
Epoch: 91 | Batch_idx: 150 |  Loss: (0.2663) |  Loss2: (0.0000) | Acc: (90.00%) (17539/19328)
Epoch: 91 | Batch_idx: 160 |  Loss: (0.2648) |  Loss2: (0.0000) | Acc: (90.00%) (18712/20608)
Epoch: 91 | Batch_idx: 170 |  Loss: (0.2640) |  Loss2: (0.0000) | Acc: (90.00%) (19863/21888)
Epoch: 91 | Batch_idx: 180 |  Loss: (0.2624) |  Loss2: (0.0000) | Acc: (90.00%) (21045/23168)
Epoch: 91 | Batch_idx: 190 |  Loss: (0.2623) |  Loss2: (0.0000) | Acc: (90.00%) (22206/24448)
Epoch: 91 | Batch_idx: 200 |  Loss: (0.2620) |  Loss2: (0.0000) | Acc: (90.00%) (23372/25728)
Epoch: 91 | Batch_idx: 210 |  Loss: (0.2611) |  Loss2: (0.0000) | Acc: (90.00%) (24546/27008)
Epoch: 91 | Batch_idx: 220 |  Loss: (0.2594) |  Loss2: (0.0000) | Acc: (90.00%) (25732/28288)
Epoch: 91 | Batch_idx: 230 |  Loss: (0.2585) |  Loss2: (0.0000) | Acc: (90.00%) (26899/29568)
Epoch: 91 | Batch_idx: 240 |  Loss: (0.2593) |  Loss2: (0.0000) | Acc: (90.00%) (28054/30848)
Epoch: 91 | Batch_idx: 250 |  Loss: (0.2592) |  Loss2: (0.0000) | Acc: (90.00%) (29214/32128)
Epoch: 91 | Batch_idx: 260 |  Loss: (0.2590) |  Loss2: (0.0000) | Acc: (90.00%) (30379/33408)
Epoch: 91 | Batch_idx: 270 |  Loss: (0.2578) |  Loss2: (0.0000) | Acc: (90.00%) (31561/34688)
Epoch: 91 | Batch_idx: 280 |  Loss: (0.2570) |  Loss2: (0.0000) | Acc: (91.00%) (32736/35968)
Epoch: 91 | Batch_idx: 290 |  Loss: (0.2568) |  Loss2: (0.0000) | Acc: (91.00%) (33905/37248)
Epoch: 91 | Batch_idx: 300 |  Loss: (0.2560) |  Loss2: (0.0000) | Acc: (91.00%) (35082/38528)
Epoch: 91 | Batch_idx: 310 |  Loss: (0.2558) |  Loss2: (0.0000) | Acc: (91.00%) (36252/39808)
Epoch: 91 | Batch_idx: 320 |  Loss: (0.2553) |  Loss2: (0.0000) | Acc: (91.00%) (37431/41088)
Epoch: 91 | Batch_idx: 330 |  Loss: (0.2546) |  Loss2: (0.0000) | Acc: (91.00%) (38618/42368)
Epoch: 91 | Batch_idx: 340 |  Loss: (0.2544) |  Loss2: (0.0000) | Acc: (91.00%) (39791/43648)
Epoch: 91 | Batch_idx: 350 |  Loss: (0.2547) |  Loss2: (0.0000) | Acc: (91.00%) (40948/44928)
Epoch: 91 | Batch_idx: 360 |  Loss: (0.2543) |  Loss2: (0.0000) | Acc: (91.00%) (42126/46208)
Epoch: 91 | Batch_idx: 370 |  Loss: (0.2544) |  Loss2: (0.0000) | Acc: (91.00%) (43285/47488)
Epoch: 91 | Batch_idx: 380 |  Loss: (0.2538) |  Loss2: (0.0000) | Acc: (91.00%) (44460/48768)
Epoch: 91 | Batch_idx: 390 |  Loss: (0.2541) |  Loss2: (0.0000) | Acc: (91.00%) (45578/50000)
# TEST : Loss: (0.4147) | Acc: (86.00%) (8667/10000)
percent tensor([0.5403, 0.5524, 0.5648, 0.5603, 0.5675, 0.5463, 0.5574, 0.5641, 0.5475,
        0.5542, 0.5406, 0.5620, 0.5433, 0.5517, 0.5511, 0.5446],
       device='cuda:0') torch.Size([16])
percent tensor([0.5722, 0.5741, 0.5663, 0.5626, 0.5748, 0.5797, 0.5795, 0.5735, 0.5664,
        0.5673, 0.5707, 0.5731, 0.5693, 0.5670, 0.5822, 0.5727],
       device='cuda:0') torch.Size([16])
percent tensor([0.5751, 0.5699, 0.5546, 0.5441, 0.5499, 0.5668, 0.5689, 0.5572, 0.5651,
        0.5662, 0.5624, 0.5633, 0.5829, 0.5622, 0.5761, 0.5766],
       device='cuda:0') torch.Size([16])
percent tensor([0.6241, 0.6140, 0.6010, 0.6019, 0.6096, 0.6450, 0.6230, 0.6039, 0.6158,
        0.6165, 0.6223, 0.6088, 0.6155, 0.6203, 0.6298, 0.6269],
       device='cuda:0') torch.Size([16])
percent tensor([0.4799, 0.4423, 0.5480, 0.5718, 0.5583, 0.5496, 0.4878, 0.5548, 0.5255,
        0.4479, 0.4884, 0.5200, 0.4140, 0.5467, 0.5239, 0.5030],
       device='cuda:0') torch.Size([16])
percent tensor([0.5199, 0.5932, 0.6101, 0.6094, 0.6366, 0.6311, 0.5917, 0.5661, 0.6078,
        0.5469, 0.6155, 0.5778, 0.5625, 0.6031, 0.4978, 0.5151],
       device='cuda:0') torch.Size([16])
percent tensor([0.6305, 0.6129, 0.6878, 0.6502, 0.6999, 0.6281, 0.6760, 0.6777, 0.6218,
        0.6274, 0.6246, 0.6357, 0.5971, 0.6617, 0.6051, 0.6162],
       device='cuda:0') torch.Size([16])
percent tensor([0.9988, 0.9987, 0.9993, 0.9990, 0.9997, 0.9986, 0.9995, 0.9998, 0.9995,
        0.9992, 0.9994, 0.9985, 0.9990, 0.9995, 0.9993, 0.9992],
       device='cuda:0') torch.Size([16])
Epoch: 92 | Batch_idx: 0 |  Loss: (0.2565) |  Loss2: (0.0000) | Acc: (91.00%) (117/128)
Epoch: 92 | Batch_idx: 10 |  Loss: (0.2735) |  Loss2: (0.0000) | Acc: (90.00%) (1270/1408)
Epoch: 92 | Batch_idx: 20 |  Loss: (0.2644) |  Loss2: (0.0000) | Acc: (90.00%) (2427/2688)
Epoch: 92 | Batch_idx: 30 |  Loss: (0.2631) |  Loss2: (0.0000) | Acc: (90.00%) (3591/3968)
Epoch: 92 | Batch_idx: 40 |  Loss: (0.2560) |  Loss2: (0.0000) | Acc: (91.00%) (4780/5248)
Epoch: 92 | Batch_idx: 50 |  Loss: (0.2533) |  Loss2: (0.0000) | Acc: (91.00%) (5950/6528)
Epoch: 92 | Batch_idx: 60 |  Loss: (0.2554) |  Loss2: (0.0000) | Acc: (90.00%) (7105/7808)
Epoch: 92 | Batch_idx: 70 |  Loss: (0.2524) |  Loss2: (0.0000) | Acc: (91.00%) (8281/9088)
Epoch: 92 | Batch_idx: 80 |  Loss: (0.2503) |  Loss2: (0.0000) | Acc: (91.00%) (9450/10368)
Epoch: 92 | Batch_idx: 90 |  Loss: (0.2466) |  Loss2: (0.0000) | Acc: (91.00%) (10638/11648)
Epoch: 92 | Batch_idx: 100 |  Loss: (0.2455) |  Loss2: (0.0000) | Acc: (91.00%) (11813/12928)
Epoch: 92 | Batch_idx: 110 |  Loss: (0.2439) |  Loss2: (0.0000) | Acc: (91.00%) (12992/14208)
Epoch: 92 | Batch_idx: 120 |  Loss: (0.2433) |  Loss2: (0.0000) | Acc: (91.00%) (14175/15488)
Epoch: 92 | Batch_idx: 130 |  Loss: (0.2434) |  Loss2: (0.0000) | Acc: (91.00%) (15349/16768)
Epoch: 92 | Batch_idx: 140 |  Loss: (0.2425) |  Loss2: (0.0000) | Acc: (91.00%) (16527/18048)
Epoch: 92 | Batch_idx: 150 |  Loss: (0.2419) |  Loss2: (0.0000) | Acc: (91.00%) (17696/19328)
Epoch: 92 | Batch_idx: 160 |  Loss: (0.2425) |  Loss2: (0.0000) | Acc: (91.00%) (18860/20608)
Epoch: 92 | Batch_idx: 170 |  Loss: (0.2423) |  Loss2: (0.0000) | Acc: (91.00%) (20039/21888)
Epoch: 92 | Batch_idx: 180 |  Loss: (0.2417) |  Loss2: (0.0000) | Acc: (91.00%) (21211/23168)
Epoch: 92 | Batch_idx: 190 |  Loss: (0.2417) |  Loss2: (0.0000) | Acc: (91.00%) (22380/24448)
Epoch: 92 | Batch_idx: 200 |  Loss: (0.2407) |  Loss2: (0.0000) | Acc: (91.00%) (23557/25728)
Epoch: 92 | Batch_idx: 210 |  Loss: (0.2398) |  Loss2: (0.0000) | Acc: (91.00%) (24744/27008)
Epoch: 92 | Batch_idx: 220 |  Loss: (0.2397) |  Loss2: (0.0000) | Acc: (91.00%) (25916/28288)
Epoch: 92 | Batch_idx: 230 |  Loss: (0.2389) |  Loss2: (0.0000) | Acc: (91.00%) (27100/29568)
Epoch: 92 | Batch_idx: 240 |  Loss: (0.2389) |  Loss2: (0.0000) | Acc: (91.00%) (28265/30848)
Epoch: 92 | Batch_idx: 250 |  Loss: (0.2392) |  Loss2: (0.0000) | Acc: (91.00%) (29445/32128)
Epoch: 92 | Batch_idx: 260 |  Loss: (0.2391) |  Loss2: (0.0000) | Acc: (91.00%) (30611/33408)
Epoch: 92 | Batch_idx: 270 |  Loss: (0.2390) |  Loss2: (0.0000) | Acc: (91.00%) (31784/34688)
Epoch: 92 | Batch_idx: 280 |  Loss: (0.2389) |  Loss2: (0.0000) | Acc: (91.00%) (32960/35968)
Epoch: 92 | Batch_idx: 290 |  Loss: (0.2390) |  Loss2: (0.0000) | Acc: (91.00%) (34128/37248)
Epoch: 92 | Batch_idx: 300 |  Loss: (0.2387) |  Loss2: (0.0000) | Acc: (91.00%) (35298/38528)
Epoch: 92 | Batch_idx: 310 |  Loss: (0.2385) |  Loss2: (0.0000) | Acc: (91.00%) (36473/39808)
Epoch: 92 | Batch_idx: 320 |  Loss: (0.2386) |  Loss2: (0.0000) | Acc: (91.00%) (37651/41088)
Epoch: 92 | Batch_idx: 330 |  Loss: (0.2388) |  Loss2: (0.0000) | Acc: (91.00%) (38816/42368)
Epoch: 92 | Batch_idx: 340 |  Loss: (0.2386) |  Loss2: (0.0000) | Acc: (91.00%) (39993/43648)
Epoch: 92 | Batch_idx: 350 |  Loss: (0.2381) |  Loss2: (0.0000) | Acc: (91.00%) (41175/44928)
Epoch: 92 | Batch_idx: 360 |  Loss: (0.2379) |  Loss2: (0.0000) | Acc: (91.00%) (42357/46208)
Epoch: 92 | Batch_idx: 370 |  Loss: (0.2369) |  Loss2: (0.0000) | Acc: (91.00%) (43547/47488)
Epoch: 92 | Batch_idx: 380 |  Loss: (0.2364) |  Loss2: (0.0000) | Acc: (91.00%) (44728/48768)
Epoch: 92 | Batch_idx: 390 |  Loss: (0.2359) |  Loss2: (0.0000) | Acc: (91.00%) (45869/50000)
# TEST : Loss: (0.3995) | Acc: (86.00%) (8696/10000)
percent tensor([0.5435, 0.5562, 0.5688, 0.5636, 0.5717, 0.5492, 0.5615, 0.5681, 0.5512,
        0.5580, 0.5439, 0.5661, 0.5467, 0.5551, 0.5546, 0.5477],
       device='cuda:0') torch.Size([16])
percent tensor([0.5717, 0.5743, 0.5658, 0.5620, 0.5743, 0.5787, 0.5794, 0.5732, 0.5664,
        0.5674, 0.5705, 0.5728, 0.5692, 0.5671, 0.5819, 0.5722],
       device='cuda:0') torch.Size([16])
percent tensor([0.5760, 0.5716, 0.5539, 0.5429, 0.5484, 0.5664, 0.5695, 0.5554, 0.5650,
        0.5675, 0.5635, 0.5633, 0.5846, 0.5630, 0.5766, 0.5778],
       device='cuda:0') torch.Size([16])
percent tensor([0.6295, 0.6222, 0.6039, 0.6037, 0.6128, 0.6491, 0.6302, 0.6066, 0.6216,
        0.6246, 0.6303, 0.6147, 0.6239, 0.6270, 0.6354, 0.6330],
       device='cuda:0') torch.Size([16])
percent tensor([0.4825, 0.4434, 0.5542, 0.5796, 0.5658, 0.5527, 0.4896, 0.5618, 0.5298,
        0.4531, 0.4883, 0.5276, 0.4137, 0.5530, 0.5218, 0.5063],
       device='cuda:0') torch.Size([16])
percent tensor([0.5174, 0.5957, 0.6066, 0.6034, 0.6309, 0.6247, 0.5906, 0.5634, 0.6049,
        0.5448, 0.6165, 0.5792, 0.5639, 0.6024, 0.5012, 0.5099],
       device='cuda:0') torch.Size([16])
percent tensor([0.6406, 0.6307, 0.6868, 0.6451, 0.6982, 0.6340, 0.6853, 0.6784, 0.6371,
        0.6423, 0.6393, 0.6444, 0.6151, 0.6701, 0.6195, 0.6237],
       device='cuda:0') torch.Size([16])
percent tensor([0.9989, 0.9987, 0.9993, 0.9989, 0.9997, 0.9986, 0.9996, 0.9998, 0.9996,
        0.9993, 0.9995, 0.9987, 0.9991, 0.9995, 0.9993, 0.9992],
       device='cuda:0') torch.Size([16])
Epoch: 93 | Batch_idx: 0 |  Loss: (0.2057) |  Loss2: (0.0000) | Acc: (94.00%) (121/128)
Epoch: 93 | Batch_idx: 10 |  Loss: (0.2171) |  Loss2: (0.0000) | Acc: (92.00%) (1302/1408)
Epoch: 93 | Batch_idx: 20 |  Loss: (0.2181) |  Loss2: (0.0000) | Acc: (92.00%) (2487/2688)
Epoch: 93 | Batch_idx: 30 |  Loss: (0.2163) |  Loss2: (0.0000) | Acc: (92.00%) (3683/3968)
Epoch: 93 | Batch_idx: 40 |  Loss: (0.2185) |  Loss2: (0.0000) | Acc: (92.00%) (4870/5248)
Epoch: 93 | Batch_idx: 50 |  Loss: (0.2239) |  Loss2: (0.0000) | Acc: (92.00%) (6038/6528)
Epoch: 93 | Batch_idx: 60 |  Loss: (0.2262) |  Loss2: (0.0000) | Acc: (92.00%) (7215/7808)
Epoch: 93 | Batch_idx: 70 |  Loss: (0.2288) |  Loss2: (0.0000) | Acc: (92.00%) (8394/9088)
Epoch: 93 | Batch_idx: 80 |  Loss: (0.2269) |  Loss2: (0.0000) | Acc: (92.00%) (9582/10368)
Epoch: 93 | Batch_idx: 90 |  Loss: (0.2282) |  Loss2: (0.0000) | Acc: (92.00%) (10752/11648)
Epoch: 93 | Batch_idx: 100 |  Loss: (0.2289) |  Loss2: (0.0000) | Acc: (92.00%) (11937/12928)
Epoch: 93 | Batch_idx: 110 |  Loss: (0.2294) |  Loss2: (0.0000) | Acc: (92.00%) (13113/14208)
Epoch: 93 | Batch_idx: 120 |  Loss: (0.2291) |  Loss2: (0.0000) | Acc: (92.00%) (14297/15488)
Epoch: 93 | Batch_idx: 130 |  Loss: (0.2309) |  Loss2: (0.0000) | Acc: (92.00%) (15468/16768)
Epoch: 93 | Batch_idx: 140 |  Loss: (0.2309) |  Loss2: (0.0000) | Acc: (92.00%) (16642/18048)
Epoch: 93 | Batch_idx: 150 |  Loss: (0.2292) |  Loss2: (0.0000) | Acc: (92.00%) (17830/19328)
Epoch: 93 | Batch_idx: 160 |  Loss: (0.2272) |  Loss2: (0.0000) | Acc: (92.00%) (19019/20608)
Epoch: 93 | Batch_idx: 170 |  Loss: (0.2272) |  Loss2: (0.0000) | Acc: (92.00%) (20192/21888)
Epoch: 93 | Batch_idx: 180 |  Loss: (0.2265) |  Loss2: (0.0000) | Acc: (92.00%) (21372/23168)
Epoch: 93 | Batch_idx: 190 |  Loss: (0.2265) |  Loss2: (0.0000) | Acc: (92.00%) (22557/24448)
Epoch: 93 | Batch_idx: 200 |  Loss: (0.2260) |  Loss2: (0.0000) | Acc: (92.00%) (23742/25728)
Epoch: 93 | Batch_idx: 210 |  Loss: (0.2263) |  Loss2: (0.0000) | Acc: (92.00%) (24912/27008)
Epoch: 93 | Batch_idx: 220 |  Loss: (0.2261) |  Loss2: (0.0000) | Acc: (92.00%) (26093/28288)
Epoch: 93 | Batch_idx: 230 |  Loss: (0.2264) |  Loss2: (0.0000) | Acc: (92.00%) (27267/29568)
Epoch: 93 | Batch_idx: 240 |  Loss: (0.2281) |  Loss2: (0.0000) | Acc: (92.00%) (28429/30848)
Epoch: 93 | Batch_idx: 250 |  Loss: (0.2284) |  Loss2: (0.0000) | Acc: (92.00%) (29613/32128)
Epoch: 93 | Batch_idx: 260 |  Loss: (0.2278) |  Loss2: (0.0000) | Acc: (92.00%) (30801/33408)
Epoch: 93 | Batch_idx: 270 |  Loss: (0.2283) |  Loss2: (0.0000) | Acc: (92.00%) (31979/34688)
Epoch: 93 | Batch_idx: 280 |  Loss: (0.2278) |  Loss2: (0.0000) | Acc: (92.00%) (33157/35968)
Epoch: 93 | Batch_idx: 290 |  Loss: (0.2271) |  Loss2: (0.0000) | Acc: (92.00%) (34348/37248)
Epoch: 93 | Batch_idx: 300 |  Loss: (0.2271) |  Loss2: (0.0000) | Acc: (92.00%) (35519/38528)
Epoch: 93 | Batch_idx: 310 |  Loss: (0.2277) |  Loss2: (0.0000) | Acc: (92.00%) (36687/39808)
Epoch: 93 | Batch_idx: 320 |  Loss: (0.2278) |  Loss2: (0.0000) | Acc: (92.00%) (37866/41088)
Epoch: 93 | Batch_idx: 330 |  Loss: (0.2273) |  Loss2: (0.0000) | Acc: (92.00%) (39057/42368)
Epoch: 93 | Batch_idx: 340 |  Loss: (0.2277) |  Loss2: (0.0000) | Acc: (92.00%) (40231/43648)
Epoch: 93 | Batch_idx: 350 |  Loss: (0.2283) |  Loss2: (0.0000) | Acc: (92.00%) (41406/44928)
Epoch: 93 | Batch_idx: 360 |  Loss: (0.2285) |  Loss2: (0.0000) | Acc: (92.00%) (42588/46208)
Epoch: 93 | Batch_idx: 370 |  Loss: (0.2283) |  Loss2: (0.0000) | Acc: (92.00%) (43760/47488)
Epoch: 93 | Batch_idx: 380 |  Loss: (0.2282) |  Loss2: (0.0000) | Acc: (92.00%) (44941/48768)
Epoch: 93 | Batch_idx: 390 |  Loss: (0.2286) |  Loss2: (0.0000) | Acc: (92.00%) (46070/50000)
# TEST : Loss: (0.3924) | Acc: (87.00%) (8715/10000)
percent tensor([0.5441, 0.5568, 0.5692, 0.5643, 0.5722, 0.5498, 0.5620, 0.5688, 0.5520,
        0.5585, 0.5447, 0.5663, 0.5474, 0.5559, 0.5552, 0.5482],
       device='cuda:0') torch.Size([16])
percent tensor([0.5717, 0.5748, 0.5652, 0.5615, 0.5739, 0.5789, 0.5794, 0.5729, 0.5664,
        0.5675, 0.5707, 0.5725, 0.5694, 0.5677, 0.5822, 0.5722],
       device='cuda:0') torch.Size([16])
percent tensor([0.5797, 0.5768, 0.5563, 0.5448, 0.5512, 0.5684, 0.5741, 0.5575, 0.5680,
        0.5724, 0.5679, 0.5668, 0.5893, 0.5672, 0.5804, 0.5820],
       device='cuda:0') torch.Size([16])
percent tensor([0.6298, 0.6243, 0.6023, 0.6017, 0.6114, 0.6493, 0.6314, 0.6053, 0.6220,
        0.6261, 0.6321, 0.6152, 0.6259, 0.6284, 0.6359, 0.6340],
       device='cuda:0') torch.Size([16])
percent tensor([0.4813, 0.4413, 0.5539, 0.5823, 0.5688, 0.5511, 0.4870, 0.5628, 0.5263,
        0.4539, 0.4849, 0.5256, 0.4096, 0.5538, 0.5153, 0.5084],
       device='cuda:0') torch.Size([16])
percent tensor([0.5155, 0.6005, 0.6058, 0.5973, 0.6269, 0.6230, 0.5905, 0.5605, 0.6041,
        0.5447, 0.6215, 0.5828, 0.5659, 0.6078, 0.5040, 0.5067],
       device='cuda:0') torch.Size([16])
percent tensor([0.6463, 0.6423, 0.6882, 0.6422, 0.6965, 0.6415, 0.6873, 0.6727, 0.6456,
        0.6504, 0.6497, 0.6466, 0.6264, 0.6766, 0.6249, 0.6256],
       device='cuda:0') torch.Size([16])
percent tensor([0.9990, 0.9988, 0.9993, 0.9988, 0.9997, 0.9987, 0.9995, 0.9998, 0.9996,
        0.9994, 0.9995, 0.9986, 0.9991, 0.9996, 0.9993, 0.9992],
       device='cuda:0') torch.Size([16])
Epoch: 94 | Batch_idx: 0 |  Loss: (0.1799) |  Loss2: (0.0000) | Acc: (92.00%) (119/128)
Epoch: 94 | Batch_idx: 10 |  Loss: (0.1929) |  Loss2: (0.0000) | Acc: (93.00%) (1316/1408)
Epoch: 94 | Batch_idx: 20 |  Loss: (0.2110) |  Loss2: (0.0000) | Acc: (92.00%) (2481/2688)
Epoch: 94 | Batch_idx: 30 |  Loss: (0.2170) |  Loss2: (0.0000) | Acc: (91.00%) (3649/3968)
Epoch: 94 | Batch_idx: 40 |  Loss: (0.2216) |  Loss2: (0.0000) | Acc: (91.00%) (4819/5248)
Epoch: 94 | Batch_idx: 50 |  Loss: (0.2242) |  Loss2: (0.0000) | Acc: (91.00%) (5991/6528)
Epoch: 94 | Batch_idx: 60 |  Loss: (0.2249) |  Loss2: (0.0000) | Acc: (91.00%) (7169/7808)
Epoch: 94 | Batch_idx: 70 |  Loss: (0.2234) |  Loss2: (0.0000) | Acc: (91.00%) (8355/9088)
Epoch: 94 | Batch_idx: 80 |  Loss: (0.2241) |  Loss2: (0.0000) | Acc: (91.00%) (9536/10368)
Epoch: 94 | Batch_idx: 90 |  Loss: (0.2220) |  Loss2: (0.0000) | Acc: (92.00%) (10725/11648)
Epoch: 94 | Batch_idx: 100 |  Loss: (0.2274) |  Loss2: (0.0000) | Acc: (91.00%) (11887/12928)
Epoch: 94 | Batch_idx: 110 |  Loss: (0.2257) |  Loss2: (0.0000) | Acc: (91.00%) (13069/14208)
Epoch: 94 | Batch_idx: 120 |  Loss: (0.2253) |  Loss2: (0.0000) | Acc: (92.00%) (14254/15488)
Epoch: 94 | Batch_idx: 130 |  Loss: (0.2236) |  Loss2: (0.0000) | Acc: (92.00%) (15455/16768)
Epoch: 94 | Batch_idx: 140 |  Loss: (0.2242) |  Loss2: (0.0000) | Acc: (92.00%) (16635/18048)
Epoch: 94 | Batch_idx: 150 |  Loss: (0.2251) |  Loss2: (0.0000) | Acc: (92.00%) (17821/19328)
Epoch: 94 | Batch_idx: 160 |  Loss: (0.2233) |  Loss2: (0.0000) | Acc: (92.00%) (19017/20608)
Epoch: 94 | Batch_idx: 170 |  Loss: (0.2233) |  Loss2: (0.0000) | Acc: (92.00%) (20210/21888)
Epoch: 94 | Batch_idx: 180 |  Loss: (0.2222) |  Loss2: (0.0000) | Acc: (92.00%) (21398/23168)
Epoch: 94 | Batch_idx: 190 |  Loss: (0.2216) |  Loss2: (0.0000) | Acc: (92.00%) (22587/24448)
Epoch: 94 | Batch_idx: 200 |  Loss: (0.2211) |  Loss2: (0.0000) | Acc: (92.00%) (23774/25728)
Epoch: 94 | Batch_idx: 210 |  Loss: (0.2211) |  Loss2: (0.0000) | Acc: (92.00%) (24957/27008)
Epoch: 94 | Batch_idx: 220 |  Loss: (0.2211) |  Loss2: (0.0000) | Acc: (92.00%) (26146/28288)
Epoch: 94 | Batch_idx: 230 |  Loss: (0.2213) |  Loss2: (0.0000) | Acc: (92.00%) (27330/29568)
Epoch: 94 | Batch_idx: 240 |  Loss: (0.2219) |  Loss2: (0.0000) | Acc: (92.00%) (28508/30848)
Epoch: 94 | Batch_idx: 250 |  Loss: (0.2218) |  Loss2: (0.0000) | Acc: (92.00%) (29693/32128)
Epoch: 94 | Batch_idx: 260 |  Loss: (0.2221) |  Loss2: (0.0000) | Acc: (92.00%) (30877/33408)
Epoch: 94 | Batch_idx: 270 |  Loss: (0.2230) |  Loss2: (0.0000) | Acc: (92.00%) (32041/34688)
Epoch: 94 | Batch_idx: 280 |  Loss: (0.2228) |  Loss2: (0.0000) | Acc: (92.00%) (33228/35968)
Epoch: 94 | Batch_idx: 290 |  Loss: (0.2239) |  Loss2: (0.0000) | Acc: (92.00%) (34409/37248)
Epoch: 94 | Batch_idx: 300 |  Loss: (0.2235) |  Loss2: (0.0000) | Acc: (92.00%) (35578/38528)
Epoch: 94 | Batch_idx: 310 |  Loss: (0.2226) |  Loss2: (0.0000) | Acc: (92.00%) (36776/39808)
Epoch: 94 | Batch_idx: 320 |  Loss: (0.2231) |  Loss2: (0.0000) | Acc: (92.00%) (37947/41088)
Epoch: 94 | Batch_idx: 330 |  Loss: (0.2232) |  Loss2: (0.0000) | Acc: (92.00%) (39131/42368)
Epoch: 94 | Batch_idx: 340 |  Loss: (0.2237) |  Loss2: (0.0000) | Acc: (92.00%) (40310/43648)
Epoch: 94 | Batch_idx: 350 |  Loss: (0.2229) |  Loss2: (0.0000) | Acc: (92.00%) (41510/44928)
Epoch: 94 | Batch_idx: 360 |  Loss: (0.2229) |  Loss2: (0.0000) | Acc: (92.00%) (42696/46208)
Epoch: 94 | Batch_idx: 370 |  Loss: (0.2225) |  Loss2: (0.0000) | Acc: (92.00%) (43895/47488)
Epoch: 94 | Batch_idx: 380 |  Loss: (0.2223) |  Loss2: (0.0000) | Acc: (92.00%) (45076/48768)
Epoch: 94 | Batch_idx: 390 |  Loss: (0.2224) |  Loss2: (0.0000) | Acc: (92.00%) (46212/50000)
# TEST : Loss: (0.3857) | Acc: (87.00%) (8738/10000)
percent tensor([0.5450, 0.5577, 0.5704, 0.5656, 0.5734, 0.5507, 0.5629, 0.5700, 0.5530,
        0.5593, 0.5453, 0.5672, 0.5483, 0.5568, 0.5561, 0.5491],
       device='cuda:0') torch.Size([16])
percent tensor([0.5709, 0.5743, 0.5643, 0.5608, 0.5731, 0.5781, 0.5787, 0.5723, 0.5659,
        0.5668, 0.5700, 0.5717, 0.5687, 0.5673, 0.5816, 0.5715],
       device='cuda:0') torch.Size([16])
percent tensor([0.5823, 0.5798, 0.5571, 0.5445, 0.5524, 0.5695, 0.5766, 0.5583, 0.5694,
        0.5751, 0.5703, 0.5682, 0.5923, 0.5694, 0.5827, 0.5846],
       device='cuda:0') torch.Size([16])
percent tensor([0.6305, 0.6264, 0.6012, 0.6002, 0.6106, 0.6493, 0.6328, 0.6043, 0.6226,
        0.6278, 0.6337, 0.6155, 0.6282, 0.6296, 0.6363, 0.6351],
       device='cuda:0') torch.Size([16])
percent tensor([0.4937, 0.4543, 0.5610, 0.5878, 0.5764, 0.5580, 0.5003, 0.5722, 0.5334,
        0.4666, 0.4928, 0.5333, 0.4203, 0.5642, 0.5230, 0.5232],
       device='cuda:0') torch.Size([16])
percent tensor([0.5014, 0.5920, 0.5977, 0.5886, 0.6161, 0.6136, 0.5787, 0.5485, 0.5954,
        0.5308, 0.6148, 0.5744, 0.5547, 0.6004, 0.4936, 0.4909],
       device='cuda:0') torch.Size([16])
percent tensor([0.6499, 0.6478, 0.6890, 0.6419, 0.6954, 0.6473, 0.6894, 0.6710, 0.6506,
        0.6546, 0.6545, 0.6477, 0.6321, 0.6792, 0.6293, 0.6273],
       device='cuda:0') torch.Size([16])
percent tensor([0.9990, 0.9989, 0.9993, 0.9988, 0.9997, 0.9988, 0.9996, 0.9998, 0.9996,
        0.9994, 0.9995, 0.9987, 0.9991, 0.9996, 0.9993, 0.9993],
       device='cuda:0') torch.Size([16])
Epoch: 95 | Batch_idx: 0 |  Loss: (0.1606) |  Loss2: (0.0000) | Acc: (94.00%) (121/128)
Epoch: 95 | Batch_idx: 10 |  Loss: (0.2304) |  Loss2: (0.0000) | Acc: (91.00%) (1289/1408)
Epoch: 95 | Batch_idx: 20 |  Loss: (0.2425) |  Loss2: (0.0000) | Acc: (91.00%) (2461/2688)
Epoch: 95 | Batch_idx: 30 |  Loss: (0.2293) |  Loss2: (0.0000) | Acc: (92.00%) (3661/3968)
Epoch: 95 | Batch_idx: 40 |  Loss: (0.2330) |  Loss2: (0.0000) | Acc: (92.00%) (4839/5248)
Epoch: 95 | Batch_idx: 50 |  Loss: (0.2300) |  Loss2: (0.0000) | Acc: (92.00%) (6030/6528)
Epoch: 95 | Batch_idx: 60 |  Loss: (0.2290) |  Loss2: (0.0000) | Acc: (92.00%) (7211/7808)
Epoch: 95 | Batch_idx: 70 |  Loss: (0.2250) |  Loss2: (0.0000) | Acc: (92.00%) (8409/9088)
Epoch: 95 | Batch_idx: 80 |  Loss: (0.2224) |  Loss2: (0.0000) | Acc: (92.00%) (9603/10368)
Epoch: 95 | Batch_idx: 90 |  Loss: (0.2246) |  Loss2: (0.0000) | Acc: (92.00%) (10773/11648)
Epoch: 95 | Batch_idx: 100 |  Loss: (0.2232) |  Loss2: (0.0000) | Acc: (92.00%) (11959/12928)
Epoch: 95 | Batch_idx: 110 |  Loss: (0.2230) |  Loss2: (0.0000) | Acc: (92.00%) (13140/14208)
Epoch: 95 | Batch_idx: 120 |  Loss: (0.2254) |  Loss2: (0.0000) | Acc: (92.00%) (14300/15488)
Epoch: 95 | Batch_idx: 130 |  Loss: (0.2260) |  Loss2: (0.0000) | Acc: (92.00%) (15479/16768)
Epoch: 95 | Batch_idx: 140 |  Loss: (0.2245) |  Loss2: (0.0000) | Acc: (92.00%) (16667/18048)
Epoch: 95 | Batch_idx: 150 |  Loss: (0.2221) |  Loss2: (0.0000) | Acc: (92.00%) (17859/19328)
Epoch: 95 | Batch_idx: 160 |  Loss: (0.2218) |  Loss2: (0.0000) | Acc: (92.00%) (19053/20608)
Epoch: 95 | Batch_idx: 170 |  Loss: (0.2204) |  Loss2: (0.0000) | Acc: (92.00%) (20253/21888)
Epoch: 95 | Batch_idx: 180 |  Loss: (0.2204) |  Loss2: (0.0000) | Acc: (92.00%) (21437/23168)
Epoch: 95 | Batch_idx: 190 |  Loss: (0.2209) |  Loss2: (0.0000) | Acc: (92.00%) (22617/24448)
Epoch: 95 | Batch_idx: 200 |  Loss: (0.2200) |  Loss2: (0.0000) | Acc: (92.00%) (23806/25728)
Epoch: 95 | Batch_idx: 210 |  Loss: (0.2199) |  Loss2: (0.0000) | Acc: (92.00%) (25001/27008)
Epoch: 95 | Batch_idx: 220 |  Loss: (0.2210) |  Loss2: (0.0000) | Acc: (92.00%) (26169/28288)
Epoch: 95 | Batch_idx: 230 |  Loss: (0.2211) |  Loss2: (0.0000) | Acc: (92.00%) (27355/29568)
Epoch: 95 | Batch_idx: 240 |  Loss: (0.2204) |  Loss2: (0.0000) | Acc: (92.00%) (28549/30848)
Epoch: 95 | Batch_idx: 250 |  Loss: (0.2204) |  Loss2: (0.0000) | Acc: (92.00%) (29729/32128)
Epoch: 95 | Batch_idx: 260 |  Loss: (0.2203) |  Loss2: (0.0000) | Acc: (92.00%) (30907/33408)
Epoch: 95 | Batch_idx: 270 |  Loss: (0.2205) |  Loss2: (0.0000) | Acc: (92.00%) (32085/34688)
Epoch: 95 | Batch_idx: 280 |  Loss: (0.2202) |  Loss2: (0.0000) | Acc: (92.00%) (33266/35968)
Epoch: 95 | Batch_idx: 290 |  Loss: (0.2200) |  Loss2: (0.0000) | Acc: (92.00%) (34448/37248)
Epoch: 95 | Batch_idx: 300 |  Loss: (0.2203) |  Loss2: (0.0000) | Acc: (92.00%) (35626/38528)
Epoch: 95 | Batch_idx: 310 |  Loss: (0.2202) |  Loss2: (0.0000) | Acc: (92.00%) (36819/39808)
Epoch: 95 | Batch_idx: 320 |  Loss: (0.2205) |  Loss2: (0.0000) | Acc: (92.00%) (37999/41088)
Epoch: 95 | Batch_idx: 330 |  Loss: (0.2214) |  Loss2: (0.0000) | Acc: (92.00%) (39179/42368)
Epoch: 95 | Batch_idx: 340 |  Loss: (0.2211) |  Loss2: (0.0000) | Acc: (92.00%) (40370/43648)
Epoch: 95 | Batch_idx: 350 |  Loss: (0.2202) |  Loss2: (0.0000) | Acc: (92.00%) (41566/44928)
Epoch: 95 | Batch_idx: 360 |  Loss: (0.2194) |  Loss2: (0.0000) | Acc: (92.00%) (42765/46208)
Epoch: 95 | Batch_idx: 370 |  Loss: (0.2194) |  Loss2: (0.0000) | Acc: (92.00%) (43942/47488)
Epoch: 95 | Batch_idx: 380 |  Loss: (0.2197) |  Loss2: (0.0000) | Acc: (92.00%) (45119/48768)
Epoch: 95 | Batch_idx: 390 |  Loss: (0.2190) |  Loss2: (0.0000) | Acc: (92.00%) (46261/50000)
=> saving checkpoint 'drive/app/torch/save_Schedule/checkpoint_095.pth.tar'
# TEST : Loss: (0.3810) | Acc: (87.00%) (8747/10000)
percent tensor([0.5439, 0.5563, 0.5693, 0.5646, 0.5721, 0.5493, 0.5615, 0.5690, 0.5520,
        0.5581, 0.5441, 0.5659, 0.5472, 0.5558, 0.5547, 0.5480],
       device='cuda:0') torch.Size([16])
percent tensor([0.5681, 0.5712, 0.5615, 0.5582, 0.5700, 0.5754, 0.5755, 0.5693, 0.5633,
        0.5639, 0.5672, 0.5688, 0.5658, 0.5648, 0.5786, 0.5686],
       device='cuda:0') torch.Size([16])
percent tensor([0.5873, 0.5855, 0.5601, 0.5473, 0.5551, 0.5731, 0.5816, 0.5612, 0.5735,
        0.5807, 0.5758, 0.5722, 0.5980, 0.5750, 0.5875, 0.5902],
       device='cuda:0') torch.Size([16])
percent tensor([0.6306, 0.6280, 0.5998, 0.5992, 0.6094, 0.6491, 0.6335, 0.6030, 0.6229,
        0.6293, 0.6354, 0.6157, 0.6296, 0.6308, 0.6361, 0.6357],
       device='cuda:0') torch.Size([16])
percent tensor([0.4958, 0.4560, 0.5592, 0.5865, 0.5747, 0.5573, 0.4989, 0.5700, 0.5329,
        0.4701, 0.4936, 0.5322, 0.4229, 0.5665, 0.5183, 0.5274],
       device='cuda:0') torch.Size([16])
percent tensor([0.5038, 0.5968, 0.6033, 0.5939, 0.6214, 0.6165, 0.5860, 0.5538, 0.6018,
        0.5369, 0.6209, 0.5823, 0.5593, 0.6094, 0.5022, 0.4940],
       device='cuda:0') torch.Size([16])
percent tensor([0.6486, 0.6492, 0.6895, 0.6414, 0.6971, 0.6474, 0.6904, 0.6721, 0.6505,
        0.6556, 0.6542, 0.6477, 0.6309, 0.6786, 0.6302, 0.6273],
       device='cuda:0') torch.Size([16])
percent tensor([0.9990, 0.9990, 0.9994, 0.9989, 0.9997, 0.9989, 0.9996, 0.9998, 0.9996,
        0.9995, 0.9996, 0.9988, 0.9992, 0.9996, 0.9994, 0.9993],
       device='cuda:0') torch.Size([16])
Epoch: 96 | Batch_idx: 0 |  Loss: (0.2443) |  Loss2: (0.0000) | Acc: (93.00%) (120/128)
Epoch: 96 | Batch_idx: 10 |  Loss: (0.2291) |  Loss2: (0.0000) | Acc: (92.00%) (1299/1408)
Epoch: 96 | Batch_idx: 20 |  Loss: (0.2198) |  Loss2: (0.0000) | Acc: (92.00%) (2490/2688)
Epoch: 96 | Batch_idx: 30 |  Loss: (0.2191) |  Loss2: (0.0000) | Acc: (92.00%) (3672/3968)
Epoch: 96 | Batch_idx: 40 |  Loss: (0.2128) |  Loss2: (0.0000) | Acc: (92.00%) (4867/5248)
Epoch: 96 | Batch_idx: 50 |  Loss: (0.2156) |  Loss2: (0.0000) | Acc: (92.00%) (6053/6528)
Epoch: 96 | Batch_idx: 60 |  Loss: (0.2126) |  Loss2: (0.0000) | Acc: (92.00%) (7252/7808)
Epoch: 96 | Batch_idx: 70 |  Loss: (0.2144) |  Loss2: (0.0000) | Acc: (92.00%) (8433/9088)
Epoch: 96 | Batch_idx: 80 |  Loss: (0.2149) |  Loss2: (0.0000) | Acc: (92.00%) (9621/10368)
Epoch: 96 | Batch_idx: 90 |  Loss: (0.2145) |  Loss2: (0.0000) | Acc: (92.00%) (10811/11648)
Epoch: 96 | Batch_idx: 100 |  Loss: (0.2155) |  Loss2: (0.0000) | Acc: (92.00%) (11995/12928)
Epoch: 96 | Batch_idx: 110 |  Loss: (0.2148) |  Loss2: (0.0000) | Acc: (92.00%) (13187/14208)
Epoch: 96 | Batch_idx: 120 |  Loss: (0.2149) |  Loss2: (0.0000) | Acc: (92.00%) (14373/15488)
Epoch: 96 | Batch_idx: 130 |  Loss: (0.2164) |  Loss2: (0.0000) | Acc: (92.00%) (15536/16768)
Epoch: 96 | Batch_idx: 140 |  Loss: (0.2162) |  Loss2: (0.0000) | Acc: (92.00%) (16725/18048)
Epoch: 96 | Batch_idx: 150 |  Loss: (0.2147) |  Loss2: (0.0000) | Acc: (92.00%) (17917/19328)
Epoch: 96 | Batch_idx: 160 |  Loss: (0.2132) |  Loss2: (0.0000) | Acc: (92.00%) (19115/20608)
Epoch: 96 | Batch_idx: 170 |  Loss: (0.2122) |  Loss2: (0.0000) | Acc: (92.00%) (20320/21888)
Epoch: 96 | Batch_idx: 180 |  Loss: (0.2140) |  Loss2: (0.0000) | Acc: (92.00%) (21492/23168)
Epoch: 96 | Batch_idx: 190 |  Loss: (0.2136) |  Loss2: (0.0000) | Acc: (92.00%) (22684/24448)
Epoch: 96 | Batch_idx: 200 |  Loss: (0.2139) |  Loss2: (0.0000) | Acc: (92.00%) (23859/25728)
Epoch: 96 | Batch_idx: 210 |  Loss: (0.2139) |  Loss2: (0.0000) | Acc: (92.00%) (25052/27008)
Epoch: 96 | Batch_idx: 220 |  Loss: (0.2138) |  Loss2: (0.0000) | Acc: (92.00%) (26239/28288)
Epoch: 96 | Batch_idx: 230 |  Loss: (0.2147) |  Loss2: (0.0000) | Acc: (92.00%) (27412/29568)
Epoch: 96 | Batch_idx: 240 |  Loss: (0.2148) |  Loss2: (0.0000) | Acc: (92.00%) (28592/30848)
Epoch: 96 | Batch_idx: 250 |  Loss: (0.2162) |  Loss2: (0.0000) | Acc: (92.00%) (29764/32128)
Epoch: 96 | Batch_idx: 260 |  Loss: (0.2148) |  Loss2: (0.0000) | Acc: (92.00%) (30967/33408)
Epoch: 96 | Batch_idx: 270 |  Loss: (0.2147) |  Loss2: (0.0000) | Acc: (92.00%) (32150/34688)
Epoch: 96 | Batch_idx: 280 |  Loss: (0.2154) |  Loss2: (0.0000) | Acc: (92.00%) (33332/35968)
Epoch: 96 | Batch_idx: 290 |  Loss: (0.2154) |  Loss2: (0.0000) | Acc: (92.00%) (34523/37248)
Epoch: 96 | Batch_idx: 300 |  Loss: (0.2152) |  Loss2: (0.0000) | Acc: (92.00%) (35716/38528)
Epoch: 96 | Batch_idx: 310 |  Loss: (0.2153) |  Loss2: (0.0000) | Acc: (92.00%) (36894/39808)
Epoch: 96 | Batch_idx: 320 |  Loss: (0.2162) |  Loss2: (0.0000) | Acc: (92.00%) (38066/41088)
Epoch: 96 | Batch_idx: 330 |  Loss: (0.2171) |  Loss2: (0.0000) | Acc: (92.00%) (39239/42368)
Epoch: 96 | Batch_idx: 340 |  Loss: (0.2165) |  Loss2: (0.0000) | Acc: (92.00%) (40426/43648)
Epoch: 96 | Batch_idx: 350 |  Loss: (0.2164) |  Loss2: (0.0000) | Acc: (92.00%) (41611/44928)
Epoch: 96 | Batch_idx: 360 |  Loss: (0.2166) |  Loss2: (0.0000) | Acc: (92.00%) (42800/46208)
Epoch: 96 | Batch_idx: 370 |  Loss: (0.2161) |  Loss2: (0.0000) | Acc: (92.00%) (44000/47488)
Epoch: 96 | Batch_idx: 380 |  Loss: (0.2160) |  Loss2: (0.0000) | Acc: (92.00%) (45189/48768)
Epoch: 96 | Batch_idx: 390 |  Loss: (0.2156) |  Loss2: (0.0000) | Acc: (92.00%) (46336/50000)
# TEST : Loss: (0.3824) | Acc: (87.00%) (8739/10000)
percent tensor([0.5449, 0.5575, 0.5706, 0.5656, 0.5736, 0.5504, 0.5628, 0.5702, 0.5532,
        0.5592, 0.5453, 0.5672, 0.5482, 0.5568, 0.5559, 0.5489],
       device='cuda:0') torch.Size([16])
percent tensor([0.5699, 0.5733, 0.5634, 0.5601, 0.5721, 0.5771, 0.5777, 0.5716, 0.5653,
        0.5657, 0.5690, 0.5708, 0.5676, 0.5669, 0.5807, 0.5704],
       device='cuda:0') torch.Size([16])
percent tensor([0.5914, 0.5897, 0.5629, 0.5501, 0.5585, 0.5770, 0.5856, 0.5641, 0.5775,
        0.5846, 0.5801, 0.5754, 0.6023, 0.5789, 0.5917, 0.5944],
       device='cuda:0') torch.Size([16])
percent tensor([0.6268, 0.6260, 0.5958, 0.5947, 0.6050, 0.6450, 0.6307, 0.5990, 0.6199,
        0.6265, 0.6326, 0.6126, 0.6274, 0.6284, 0.6324, 0.6322],
       device='cuda:0') torch.Size([16])
percent tensor([0.4985, 0.4551, 0.5602, 0.5867, 0.5774, 0.5605, 0.4987, 0.5723, 0.5309,
        0.4709, 0.4913, 0.5307, 0.4216, 0.5625, 0.5178, 0.5301],
       device='cuda:0') torch.Size([16])
percent tensor([0.5056, 0.6011, 0.6036, 0.5937, 0.6215, 0.6200, 0.5873, 0.5519, 0.6046,
        0.5367, 0.6246, 0.5851, 0.5647, 0.6133, 0.5033, 0.4953],
       device='cuda:0') torch.Size([16])
percent tensor([0.6528, 0.6535, 0.6924, 0.6420, 0.6968, 0.6560, 0.6920, 0.6708, 0.6560,
        0.6594, 0.6586, 0.6496, 0.6362, 0.6821, 0.6327, 0.6294],
       device='cuda:0') torch.Size([16])
percent tensor([0.9991, 0.9990, 0.9994, 0.9989, 0.9997, 0.9989, 0.9996, 0.9998, 0.9997,
        0.9995, 0.9996, 0.9989, 0.9992, 0.9997, 0.9994, 0.9993],
       device='cuda:0') torch.Size([16])
Epoch: 97 | Batch_idx: 0 |  Loss: (0.1486) |  Loss2: (0.0000) | Acc: (94.00%) (121/128)
Epoch: 97 | Batch_idx: 10 |  Loss: (0.2101) |  Loss2: (0.0000) | Acc: (92.00%) (1309/1408)
Epoch: 97 | Batch_idx: 20 |  Loss: (0.2134) |  Loss2: (0.0000) | Acc: (92.00%) (2499/2688)
Epoch: 97 | Batch_idx: 30 |  Loss: (0.2184) |  Loss2: (0.0000) | Acc: (92.00%) (3673/3968)
Epoch: 97 | Batch_idx: 40 |  Loss: (0.2245) |  Loss2: (0.0000) | Acc: (92.00%) (4841/5248)
Epoch: 97 | Batch_idx: 50 |  Loss: (0.2192) |  Loss2: (0.0000) | Acc: (92.00%) (6045/6528)
Epoch: 97 | Batch_idx: 60 |  Loss: (0.2173) |  Loss2: (0.0000) | Acc: (92.00%) (7225/7808)
Epoch: 97 | Batch_idx: 70 |  Loss: (0.2181) |  Loss2: (0.0000) | Acc: (92.00%) (8410/9088)
Epoch: 97 | Batch_idx: 80 |  Loss: (0.2175) |  Loss2: (0.0000) | Acc: (92.00%) (9590/10368)
Epoch: 97 | Batch_idx: 90 |  Loss: (0.2149) |  Loss2: (0.0000) | Acc: (92.00%) (10793/11648)
Epoch: 97 | Batch_idx: 100 |  Loss: (0.2146) |  Loss2: (0.0000) | Acc: (92.00%) (11986/12928)
Epoch: 97 | Batch_idx: 110 |  Loss: (0.2160) |  Loss2: (0.0000) | Acc: (92.00%) (13156/14208)
Epoch: 97 | Batch_idx: 120 |  Loss: (0.2142) |  Loss2: (0.0000) | Acc: (92.00%) (14346/15488)
Epoch: 97 | Batch_idx: 130 |  Loss: (0.2144) |  Loss2: (0.0000) | Acc: (92.00%) (15526/16768)
Epoch: 97 | Batch_idx: 140 |  Loss: (0.2145) |  Loss2: (0.0000) | Acc: (92.00%) (16724/18048)
Epoch: 97 | Batch_idx: 150 |  Loss: (0.2143) |  Loss2: (0.0000) | Acc: (92.00%) (17910/19328)
Epoch: 97 | Batch_idx: 160 |  Loss: (0.2140) |  Loss2: (0.0000) | Acc: (92.00%) (19092/20608)
Epoch: 97 | Batch_idx: 170 |  Loss: (0.2163) |  Loss2: (0.0000) | Acc: (92.00%) (20248/21888)
Epoch: 97 | Batch_idx: 180 |  Loss: (0.2159) |  Loss2: (0.0000) | Acc: (92.00%) (21440/23168)
Epoch: 97 | Batch_idx: 190 |  Loss: (0.2156) |  Loss2: (0.0000) | Acc: (92.00%) (22638/24448)
Epoch: 97 | Batch_idx: 200 |  Loss: (0.2154) |  Loss2: (0.0000) | Acc: (92.00%) (23824/25728)
Epoch: 97 | Batch_idx: 210 |  Loss: (0.2146) |  Loss2: (0.0000) | Acc: (92.00%) (25024/27008)
Epoch: 97 | Batch_idx: 220 |  Loss: (0.2146) |  Loss2: (0.0000) | Acc: (92.00%) (26217/28288)
Epoch: 97 | Batch_idx: 230 |  Loss: (0.2152) |  Loss2: (0.0000) | Acc: (92.00%) (27407/29568)
Epoch: 97 | Batch_idx: 240 |  Loss: (0.2160) |  Loss2: (0.0000) | Acc: (92.00%) (28590/30848)
Epoch: 97 | Batch_idx: 250 |  Loss: (0.2158) |  Loss2: (0.0000) | Acc: (92.00%) (29780/32128)
Epoch: 97 | Batch_idx: 260 |  Loss: (0.2157) |  Loss2: (0.0000) | Acc: (92.00%) (30968/33408)
Epoch: 97 | Batch_idx: 270 |  Loss: (0.2158) |  Loss2: (0.0000) | Acc: (92.00%) (32158/34688)
Epoch: 97 | Batch_idx: 280 |  Loss: (0.2150) |  Loss2: (0.0000) | Acc: (92.00%) (33353/35968)
Epoch: 97 | Batch_idx: 290 |  Loss: (0.2150) |  Loss2: (0.0000) | Acc: (92.00%) (34541/37248)
Epoch: 97 | Batch_idx: 300 |  Loss: (0.2152) |  Loss2: (0.0000) | Acc: (92.00%) (35728/38528)
Epoch: 97 | Batch_idx: 310 |  Loss: (0.2159) |  Loss2: (0.0000) | Acc: (92.00%) (36901/39808)
Epoch: 97 | Batch_idx: 320 |  Loss: (0.2161) |  Loss2: (0.0000) | Acc: (92.00%) (38079/41088)
Epoch: 97 | Batch_idx: 330 |  Loss: (0.2163) |  Loss2: (0.0000) | Acc: (92.00%) (39259/42368)
Epoch: 97 | Batch_idx: 340 |  Loss: (0.2162) |  Loss2: (0.0000) | Acc: (92.00%) (40447/43648)
Epoch: 97 | Batch_idx: 350 |  Loss: (0.2156) |  Loss2: (0.0000) | Acc: (92.00%) (41647/44928)
Epoch: 97 | Batch_idx: 360 |  Loss: (0.2157) |  Loss2: (0.0000) | Acc: (92.00%) (42839/46208)
Epoch: 97 | Batch_idx: 370 |  Loss: (0.2155) |  Loss2: (0.0000) | Acc: (92.00%) (44035/47488)
Epoch: 97 | Batch_idx: 380 |  Loss: (0.2156) |  Loss2: (0.0000) | Acc: (92.00%) (45214/48768)
Epoch: 97 | Batch_idx: 390 |  Loss: (0.2150) |  Loss2: (0.0000) | Acc: (92.00%) (46361/50000)
# TEST : Loss: (0.3762) | Acc: (87.00%) (8749/10000)
percent tensor([0.5445, 0.5566, 0.5696, 0.5649, 0.5725, 0.5501, 0.5619, 0.5692, 0.5525,
        0.5583, 0.5447, 0.5660, 0.5476, 0.5561, 0.5552, 0.5484],
       device='cuda:0') torch.Size([16])
percent tensor([0.5698, 0.5731, 0.5631, 0.5601, 0.5720, 0.5775, 0.5774, 0.5715, 0.5652,
        0.5654, 0.5689, 0.5705, 0.5673, 0.5669, 0.5807, 0.5703],
       device='cuda:0') torch.Size([16])
percent tensor([0.5938, 0.5916, 0.5647, 0.5521, 0.5601, 0.5790, 0.5877, 0.5655, 0.5793,
        0.5870, 0.5825, 0.5774, 0.6042, 0.5815, 0.5939, 0.5969],
       device='cuda:0') torch.Size([16])
percent tensor([0.6310, 0.6302, 0.5984, 0.5974, 0.6083, 0.6487, 0.6350, 0.6020, 0.6235,
        0.6309, 0.6370, 0.6165, 0.6318, 0.6325, 0.6364, 0.6366],
       device='cuda:0') torch.Size([16])
percent tensor([0.5075, 0.4659, 0.5635, 0.5883, 0.5810, 0.5629, 0.5051, 0.5772, 0.5338,
        0.4802, 0.4968, 0.5322, 0.4332, 0.5646, 0.5230, 0.5400],
       device='cuda:0') torch.Size([16])
percent tensor([0.5058, 0.6049, 0.6070, 0.5971, 0.6241, 0.6200, 0.5908, 0.5544, 0.6082,
        0.5390, 0.6303, 0.5912, 0.5647, 0.6218, 0.5076, 0.4947],
       device='cuda:0') torch.Size([16])
percent tensor([0.6451, 0.6481, 0.6865, 0.6371, 0.6904, 0.6491, 0.6851, 0.6646, 0.6501,
        0.6531, 0.6531, 0.6432, 0.6287, 0.6752, 0.6275, 0.6216],
       device='cuda:0') torch.Size([16])
percent tensor([0.9991, 0.9991, 0.9994, 0.9989, 0.9997, 0.9990, 0.9996, 0.9998, 0.9997,
        0.9995, 0.9996, 0.9989, 0.9993, 0.9996, 0.9994, 0.9994],
       device='cuda:0') torch.Size([16])
True Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=128, out_features=16, bias=False)
False Linear(in_features=16, out_features=2, bias=False)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=128, out_features=16, bias=False)
False Linear(in_features=16, out_features=2, bias=False)
True Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=256, out_features=32, bias=False)
False Linear(in_features=32, out_features=2, bias=False)
True Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=256, out_features=32, bias=False)
False Linear(in_features=32, out_features=2, bias=False)
True Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=512, out_features=64, bias=False)
False Linear(in_features=64, out_features=2, bias=False)
True Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=512, out_features=64, bias=False)
False Linear(in_features=64, out_features=2, bias=False)
True Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1024, out_features=128, bias=False)
False Linear(in_features=128, out_features=2, bias=False)
True Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1024, out_features=128, bias=False)
False Linear(in_features=128, out_features=2, bias=False)
True Linear(in_features=512, out_features=10, bias=True)
Epoch: 98 | Batch_idx: 0 |  Loss: (0.3223) |  Loss2: (0.0000) | Acc: (85.00%) (110/128)
Epoch: 98 | Batch_idx: 10 |  Loss: (0.2206) |  Loss2: (0.0000) | Acc: (91.00%) (1293/1408)
Epoch: 98 | Batch_idx: 20 |  Loss: (0.2248) |  Loss2: (0.0000) | Acc: (91.00%) (2471/2688)
Epoch: 98 | Batch_idx: 30 |  Loss: (0.2267) |  Loss2: (0.0000) | Acc: (91.00%) (3645/3968)
Epoch: 98 | Batch_idx: 40 |  Loss: (0.2282) |  Loss2: (0.0000) | Acc: (91.00%) (4818/5248)
Epoch: 98 | Batch_idx: 50 |  Loss: (0.2311) |  Loss2: (0.0000) | Acc: (91.00%) (5998/6528)
Epoch: 98 | Batch_idx: 60 |  Loss: (0.2308) |  Loss2: (0.0000) | Acc: (91.00%) (7177/7808)
Epoch: 98 | Batch_idx: 70 |  Loss: (0.2291) |  Loss2: (0.0000) | Acc: (91.00%) (8358/9088)
Epoch: 98 | Batch_idx: 80 |  Loss: (0.2288) |  Loss2: (0.0000) | Acc: (91.00%) (9536/10368)
Epoch: 98 | Batch_idx: 90 |  Loss: (0.2287) |  Loss2: (0.0000) | Acc: (92.00%) (10722/11648)
Epoch: 98 | Batch_idx: 100 |  Loss: (0.2285) |  Loss2: (0.0000) | Acc: (92.00%) (11896/12928)
Epoch: 98 | Batch_idx: 110 |  Loss: (0.2276) |  Loss2: (0.0000) | Acc: (92.00%) (13079/14208)
Epoch: 98 | Batch_idx: 120 |  Loss: (0.2288) |  Loss2: (0.0000) | Acc: (92.00%) (14253/15488)
Epoch: 98 | Batch_idx: 130 |  Loss: (0.2292) |  Loss2: (0.0000) | Acc: (91.00%) (15425/16768)
Epoch: 98 | Batch_idx: 140 |  Loss: (0.2295) |  Loss2: (0.0000) | Acc: (91.00%) (16600/18048)
Epoch: 98 | Batch_idx: 150 |  Loss: (0.2291) |  Loss2: (0.0000) | Acc: (92.00%) (17782/19328)
Epoch: 98 | Batch_idx: 160 |  Loss: (0.2290) |  Loss2: (0.0000) | Acc: (92.00%) (18966/20608)
Epoch: 98 | Batch_idx: 170 |  Loss: (0.2298) |  Loss2: (0.0000) | Acc: (92.00%) (20142/21888)
Epoch: 98 | Batch_idx: 180 |  Loss: (0.2311) |  Loss2: (0.0000) | Acc: (91.00%) (21307/23168)
Epoch: 98 | Batch_idx: 190 |  Loss: (0.2341) |  Loss2: (0.0000) | Acc: (91.00%) (22454/24448)
Epoch: 98 | Batch_idx: 200 |  Loss: (0.2335) |  Loss2: (0.0000) | Acc: (91.00%) (23632/25728)
Epoch: 98 | Batch_idx: 210 |  Loss: (0.2343) |  Loss2: (0.0000) | Acc: (91.00%) (24801/27008)
Epoch: 98 | Batch_idx: 220 |  Loss: (0.2335) |  Loss2: (0.0000) | Acc: (91.00%) (25984/28288)
Epoch: 98 | Batch_idx: 230 |  Loss: (0.2346) |  Loss2: (0.0000) | Acc: (91.00%) (27149/29568)
Epoch: 98 | Batch_idx: 240 |  Loss: (0.2357) |  Loss2: (0.0000) | Acc: (91.00%) (28309/30848)
Epoch: 98 | Batch_idx: 250 |  Loss: (0.2351) |  Loss2: (0.0000) | Acc: (91.00%) (29490/32128)
Epoch: 98 | Batch_idx: 260 |  Loss: (0.2353) |  Loss2: (0.0000) | Acc: (91.00%) (30668/33408)
Epoch: 98 | Batch_idx: 270 |  Loss: (0.2346) |  Loss2: (0.0000) | Acc: (91.00%) (31858/34688)
Epoch: 98 | Batch_idx: 280 |  Loss: (0.2350) |  Loss2: (0.0000) | Acc: (91.00%) (33020/35968)
Epoch: 98 | Batch_idx: 290 |  Loss: (0.2346) |  Loss2: (0.0000) | Acc: (91.00%) (34192/37248)
Epoch: 98 | Batch_idx: 300 |  Loss: (0.2349) |  Loss2: (0.0000) | Acc: (91.00%) (35349/38528)
Epoch: 98 | Batch_idx: 310 |  Loss: (0.2356) |  Loss2: (0.0000) | Acc: (91.00%) (36514/39808)
Epoch: 98 | Batch_idx: 320 |  Loss: (0.2364) |  Loss2: (0.0000) | Acc: (91.00%) (37679/41088)
Epoch: 98 | Batch_idx: 330 |  Loss: (0.2364) |  Loss2: (0.0000) | Acc: (91.00%) (38854/42368)
Epoch: 98 | Batch_idx: 340 |  Loss: (0.2364) |  Loss2: (0.0000) | Acc: (91.00%) (40028/43648)
Epoch: 98 | Batch_idx: 350 |  Loss: (0.2372) |  Loss2: (0.0000) | Acc: (91.00%) (41189/44928)
Epoch: 98 | Batch_idx: 360 |  Loss: (0.2373) |  Loss2: (0.0000) | Acc: (91.00%) (42351/46208)
Epoch: 98 | Batch_idx: 370 |  Loss: (0.2368) |  Loss2: (0.0000) | Acc: (91.00%) (43536/47488)
Epoch: 98 | Batch_idx: 380 |  Loss: (0.2358) |  Loss2: (0.0000) | Acc: (91.00%) (44734/48768)
Epoch: 98 | Batch_idx: 390 |  Loss: (0.2365) |  Loss2: (0.0000) | Acc: (91.00%) (45844/50000)
# TEST : Loss: (0.4161) | Acc: (86.00%) (8626/10000)
percent tensor([0.5446, 0.5572, 0.5687, 0.5641, 0.5722, 0.5501, 0.5619, 0.5681, 0.5524,
        0.5579, 0.5459, 0.5650, 0.5480, 0.5559, 0.5558, 0.5487],
       device='cuda:0') torch.Size([16])
percent tensor([0.5693, 0.5732, 0.5630, 0.5594, 0.5722, 0.5778, 0.5777, 0.5706, 0.5662,
        0.5658, 0.5704, 0.5702, 0.5677, 0.5661, 0.5800, 0.5695],
       device='cuda:0') torch.Size([16])
percent tensor([0.5973, 0.5912, 0.5651, 0.5513, 0.5621, 0.5847, 0.5868, 0.5652, 0.5777,
        0.5842, 0.5836, 0.5769, 0.6061, 0.5775, 0.5974, 0.5957],
       device='cuda:0') torch.Size([16])
percent tensor([0.6313, 0.6322, 0.5974, 0.5955, 0.6079, 0.6466, 0.6356, 0.6030, 0.6238,
        0.6333, 0.6393, 0.6160, 0.6337, 0.6364, 0.6389, 0.6369],
       device='cuda:0') torch.Size([16])
percent tensor([0.4999, 0.4725, 0.5625, 0.5818, 0.5885, 0.5543, 0.5199, 0.5810, 0.5369,
        0.4924, 0.4878, 0.5340, 0.4280, 0.5680, 0.5181, 0.5349],
       device='cuda:0') torch.Size([16])
percent tensor([0.4954, 0.5976, 0.5804, 0.5836, 0.6157, 0.6341, 0.5846, 0.5377, 0.6115,
        0.5404, 0.6266, 0.5760, 0.5667, 0.6209, 0.5168, 0.5022],
       device='cuda:0') torch.Size([16])
percent tensor([0.6457, 0.6440, 0.6881, 0.6525, 0.6984, 0.6720, 0.6928, 0.6658, 0.6536,
        0.6439, 0.6512, 0.6412, 0.6213, 0.6722, 0.6262, 0.6191],
       device='cuda:0') torch.Size([16])
percent tensor([0.9994, 0.9988, 0.9996, 0.9996, 0.9998, 0.9991, 0.9998, 0.9999, 0.9996,
        0.9991, 0.9996, 0.9992, 0.9990, 0.9995, 0.9993, 0.9993],
       device='cuda:0') torch.Size([16])
Epoch: 99 | Batch_idx: 0 |  Loss: (0.2524) |  Loss2: (0.0000) | Acc: (89.00%) (115/128)
Epoch: 99 | Batch_idx: 10 |  Loss: (0.2300) |  Loss2: (0.0000) | Acc: (91.00%) (1290/1408)
Epoch: 99 | Batch_idx: 20 |  Loss: (0.2293) |  Loss2: (0.0000) | Acc: (91.00%) (2468/2688)
Epoch: 99 | Batch_idx: 30 |  Loss: (0.2265) |  Loss2: (0.0000) | Acc: (91.00%) (3649/3968)
Epoch: 99 | Batch_idx: 40 |  Loss: (0.2298) |  Loss2: (0.0000) | Acc: (91.00%) (4827/5248)
Epoch: 99 | Batch_idx: 50 |  Loss: (0.2300) |  Loss2: (0.0000) | Acc: (91.00%) (6005/6528)
Epoch: 99 | Batch_idx: 60 |  Loss: (0.2277) |  Loss2: (0.0000) | Acc: (92.00%) (7192/7808)
Epoch: 99 | Batch_idx: 70 |  Loss: (0.2272) |  Loss2: (0.0000) | Acc: (92.00%) (8376/9088)
Epoch: 99 | Batch_idx: 80 |  Loss: (0.2286) |  Loss2: (0.0000) | Acc: (92.00%) (9553/10368)
Epoch: 99 | Batch_idx: 90 |  Loss: (0.2269) |  Loss2: (0.0000) | Acc: (92.00%) (10739/11648)
Epoch: 99 | Batch_idx: 100 |  Loss: (0.2268) |  Loss2: (0.0000) | Acc: (92.00%) (11916/12928)
Epoch: 99 | Batch_idx: 110 |  Loss: (0.2256) |  Loss2: (0.0000) | Acc: (92.00%) (13106/14208)
Epoch: 99 | Batch_idx: 120 |  Loss: (0.2277) |  Loss2: (0.0000) | Acc: (92.00%) (14262/15488)
Epoch: 99 | Batch_idx: 130 |  Loss: (0.2293) |  Loss2: (0.0000) | Acc: (92.00%) (15430/16768)
Epoch: 99 | Batch_idx: 140 |  Loss: (0.2320) |  Loss2: (0.0000) | Acc: (91.00%) (16589/18048)
Epoch: 99 | Batch_idx: 150 |  Loss: (0.2318) |  Loss2: (0.0000) | Acc: (91.00%) (17762/19328)
Epoch: 99 | Batch_idx: 160 |  Loss: (0.2327) |  Loss2: (0.0000) | Acc: (91.00%) (18935/20608)
Epoch: 99 | Batch_idx: 170 |  Loss: (0.2315) |  Loss2: (0.0000) | Acc: (91.00%) (20125/21888)
Epoch: 99 | Batch_idx: 180 |  Loss: (0.2307) |  Loss2: (0.0000) | Acc: (91.00%) (21310/23168)
Epoch: 99 | Batch_idx: 190 |  Loss: (0.2316) |  Loss2: (0.0000) | Acc: (91.00%) (22476/24448)
Epoch: 99 | Batch_idx: 200 |  Loss: (0.2302) |  Loss2: (0.0000) | Acc: (91.00%) (23663/25728)
Epoch: 99 | Batch_idx: 210 |  Loss: (0.2300) |  Loss2: (0.0000) | Acc: (92.00%) (24849/27008)
Epoch: 99 | Batch_idx: 220 |  Loss: (0.2299) |  Loss2: (0.0000) | Acc: (92.00%) (26026/28288)
Epoch: 99 | Batch_idx: 230 |  Loss: (0.2299) |  Loss2: (0.0000) | Acc: (92.00%) (27210/29568)
Epoch: 99 | Batch_idx: 240 |  Loss: (0.2297) |  Loss2: (0.0000) | Acc: (92.00%) (28387/30848)
Epoch: 99 | Batch_idx: 250 |  Loss: (0.2294) |  Loss2: (0.0000) | Acc: (92.00%) (29572/32128)
Epoch: 99 | Batch_idx: 260 |  Loss: (0.2294) |  Loss2: (0.0000) | Acc: (92.00%) (30750/33408)
Epoch: 99 | Batch_idx: 270 |  Loss: (0.2293) |  Loss2: (0.0000) | Acc: (92.00%) (31923/34688)
Epoch: 99 | Batch_idx: 280 |  Loss: (0.2296) |  Loss2: (0.0000) | Acc: (91.00%) (33088/35968)
Epoch: 99 | Batch_idx: 290 |  Loss: (0.2305) |  Loss2: (0.0000) | Acc: (91.00%) (34244/37248)
Epoch: 99 | Batch_idx: 300 |  Loss: (0.2310) |  Loss2: (0.0000) | Acc: (91.00%) (35419/38528)
Epoch: 99 | Batch_idx: 310 |  Loss: (0.2303) |  Loss2: (0.0000) | Acc: (91.00%) (36602/39808)
Epoch: 99 | Batch_idx: 320 |  Loss: (0.2296) |  Loss2: (0.0000) | Acc: (91.00%) (37789/41088)
Epoch: 99 | Batch_idx: 330 |  Loss: (0.2307) |  Loss2: (0.0000) | Acc: (91.00%) (38940/42368)
Epoch: 99 | Batch_idx: 340 |  Loss: (0.2307) |  Loss2: (0.0000) | Acc: (91.00%) (40117/43648)
Epoch: 99 | Batch_idx: 350 |  Loss: (0.2305) |  Loss2: (0.0000) | Acc: (91.00%) (41298/44928)
Epoch: 99 | Batch_idx: 360 |  Loss: (0.2301) |  Loss2: (0.0000) | Acc: (91.00%) (42480/46208)
Epoch: 99 | Batch_idx: 370 |  Loss: (0.2302) |  Loss2: (0.0000) | Acc: (91.00%) (43655/47488)
Epoch: 99 | Batch_idx: 380 |  Loss: (0.2299) |  Loss2: (0.0000) | Acc: (91.00%) (44830/48768)
Epoch: 99 | Batch_idx: 390 |  Loss: (0.2307) |  Loss2: (0.0000) | Acc: (91.00%) (45955/50000)
# TEST : Loss: (0.4183) | Acc: (86.00%) (8657/10000)
percent tensor([0.5453, 0.5559, 0.5712, 0.5647, 0.5738, 0.5523, 0.5617, 0.5686, 0.5520,
        0.5575, 0.5446, 0.5663, 0.5476, 0.5540, 0.5561, 0.5484],
       device='cuda:0') torch.Size([16])
percent tensor([0.5693, 0.5718, 0.5649, 0.5590, 0.5733, 0.5774, 0.5775, 0.5708, 0.5656,
        0.5651, 0.5690, 0.5716, 0.5674, 0.5655, 0.5791, 0.5694],
       device='cuda:0') torch.Size([16])
percent tensor([0.5974, 0.5952, 0.5661, 0.5520, 0.5608, 0.5799, 0.5891, 0.5676, 0.5823,
        0.5885, 0.5873, 0.5780, 0.6082, 0.5874, 0.5974, 0.5971],
       device='cuda:0') torch.Size([16])
percent tensor([0.6289, 0.6289, 0.6005, 0.5958, 0.6080, 0.6442, 0.6328, 0.6031, 0.6242,
        0.6321, 0.6346, 0.6170, 0.6316, 0.6336, 0.6354, 0.6351],
       device='cuda:0') torch.Size([16])
percent tensor([0.4907, 0.4657, 0.5635, 0.5823, 0.5823, 0.5591, 0.5012, 0.5721, 0.5200,
        0.4811, 0.4815, 0.5234, 0.4142, 0.5523, 0.5161, 0.5308],
       device='cuda:0') torch.Size([16])
percent tensor([0.5042, 0.5965, 0.6047, 0.6005, 0.6285, 0.6307, 0.5974, 0.5382, 0.6173,
        0.5349, 0.6208, 0.5823, 0.5897, 0.6293, 0.5055, 0.4977],
       device='cuda:0') torch.Size([16])
percent tensor([0.6447, 0.6477, 0.6895, 0.6490, 0.7001, 0.6580, 0.6830, 0.6607, 0.6493,
        0.6398, 0.6492, 0.6393, 0.6083, 0.6887, 0.6215, 0.6200],
       device='cuda:0') torch.Size([16])
percent tensor([0.9994, 0.9990, 0.9998, 0.9996, 0.9999, 0.9992, 0.9998, 0.9999, 0.9995,
        0.9993, 0.9996, 0.9994, 0.9987, 0.9995, 0.9993, 0.9995],
       device='cuda:0') torch.Size([16])
Epoch: 100 | Batch_idx: 0 |  Loss: (0.2234) |  Loss2: (0.0000) | Acc: (93.00%) (120/128)
Epoch: 100 | Batch_idx: 10 |  Loss: (0.2123) |  Loss2: (0.0000) | Acc: (92.00%) (1302/1408)
Epoch: 100 | Batch_idx: 20 |  Loss: (0.2200) |  Loss2: (0.0000) | Acc: (92.00%) (2480/2688)
Epoch: 100 | Batch_idx: 30 |  Loss: (0.2130) |  Loss2: (0.0000) | Acc: (92.00%) (3671/3968)
Epoch: 100 | Batch_idx: 40 |  Loss: (0.2164) |  Loss2: (0.0000) | Acc: (92.00%) (4841/5248)
Epoch: 100 | Batch_idx: 50 |  Loss: (0.2125) |  Loss2: (0.0000) | Acc: (92.00%) (6031/6528)
Epoch: 100 | Batch_idx: 60 |  Loss: (0.2125) |  Loss2: (0.0000) | Acc: (92.00%) (7226/7808)
Epoch: 100 | Batch_idx: 70 |  Loss: (0.2125) |  Loss2: (0.0000) | Acc: (92.00%) (8423/9088)
Epoch: 100 | Batch_idx: 80 |  Loss: (0.2105) |  Loss2: (0.0000) | Acc: (92.00%) (9623/10368)
Epoch: 100 | Batch_idx: 90 |  Loss: (0.2102) |  Loss2: (0.0000) | Acc: (92.00%) (10813/11648)
Epoch: 100 | Batch_idx: 100 |  Loss: (0.2102) |  Loss2: (0.0000) | Acc: (92.00%) (11997/12928)
Epoch: 100 | Batch_idx: 110 |  Loss: (0.2099) |  Loss2: (0.0000) | Acc: (92.00%) (13192/14208)
Epoch: 100 | Batch_idx: 120 |  Loss: (0.2125) |  Loss2: (0.0000) | Acc: (92.00%) (14356/15488)
Epoch: 100 | Batch_idx: 130 |  Loss: (0.2121) |  Loss2: (0.0000) | Acc: (92.00%) (15541/16768)
Epoch: 100 | Batch_idx: 140 |  Loss: (0.2124) |  Loss2: (0.0000) | Acc: (92.00%) (16720/18048)
Epoch: 100 | Batch_idx: 150 |  Loss: (0.2142) |  Loss2: (0.0000) | Acc: (92.00%) (17889/19328)
Epoch: 100 | Batch_idx: 160 |  Loss: (0.2143) |  Loss2: (0.0000) | Acc: (92.00%) (19069/20608)
Epoch: 100 | Batch_idx: 170 |  Loss: (0.2153) |  Loss2: (0.0000) | Acc: (92.00%) (20249/21888)
Epoch: 100 | Batch_idx: 180 |  Loss: (0.2146) |  Loss2: (0.0000) | Acc: (92.00%) (21433/23168)
Epoch: 100 | Batch_idx: 190 |  Loss: (0.2159) |  Loss2: (0.0000) | Acc: (92.00%) (22609/24448)
Epoch: 100 | Batch_idx: 200 |  Loss: (0.2166) |  Loss2: (0.0000) | Acc: (92.00%) (23790/25728)
Epoch: 100 | Batch_idx: 210 |  Loss: (0.2169) |  Loss2: (0.0000) | Acc: (92.00%) (24964/27008)
Epoch: 100 | Batch_idx: 220 |  Loss: (0.2168) |  Loss2: (0.0000) | Acc: (92.00%) (26146/28288)
Epoch: 100 | Batch_idx: 230 |  Loss: (0.2162) |  Loss2: (0.0000) | Acc: (92.00%) (27336/29568)
Epoch: 100 | Batch_idx: 240 |  Loss: (0.2160) |  Loss2: (0.0000) | Acc: (92.00%) (28516/30848)
Epoch: 100 | Batch_idx: 250 |  Loss: (0.2171) |  Loss2: (0.0000) | Acc: (92.00%) (29692/32128)
Epoch: 100 | Batch_idx: 260 |  Loss: (0.2170) |  Loss2: (0.0000) | Acc: (92.00%) (30878/33408)
Epoch: 100 | Batch_idx: 270 |  Loss: (0.2173) |  Loss2: (0.0000) | Acc: (92.00%) (32056/34688)
Epoch: 100 | Batch_idx: 280 |  Loss: (0.2174) |  Loss2: (0.0000) | Acc: (92.00%) (33245/35968)
Epoch: 100 | Batch_idx: 290 |  Loss: (0.2182) |  Loss2: (0.0000) | Acc: (92.00%) (34412/37248)
Epoch: 100 | Batch_idx: 300 |  Loss: (0.2182) |  Loss2: (0.0000) | Acc: (92.00%) (35589/38528)
Epoch: 100 | Batch_idx: 310 |  Loss: (0.2192) |  Loss2: (0.0000) | Acc: (92.00%) (36764/39808)
Epoch: 100 | Batch_idx: 320 |  Loss: (0.2194) |  Loss2: (0.0000) | Acc: (92.00%) (37945/41088)
Epoch: 100 | Batch_idx: 330 |  Loss: (0.2197) |  Loss2: (0.0000) | Acc: (92.00%) (39119/42368)
Epoch: 100 | Batch_idx: 340 |  Loss: (0.2200) |  Loss2: (0.0000) | Acc: (92.00%) (40304/43648)
Epoch: 100 | Batch_idx: 350 |  Loss: (0.2201) |  Loss2: (0.0000) | Acc: (92.00%) (41494/44928)
Epoch: 100 | Batch_idx: 360 |  Loss: (0.2207) |  Loss2: (0.0000) | Acc: (92.00%) (42684/46208)
Epoch: 100 | Batch_idx: 370 |  Loss: (0.2207) |  Loss2: (0.0000) | Acc: (92.00%) (43869/47488)
Epoch: 100 | Batch_idx: 380 |  Loss: (0.2213) |  Loss2: (0.0000) | Acc: (92.00%) (45036/48768)
Epoch: 100 | Batch_idx: 390 |  Loss: (0.2218) |  Loss2: (0.0000) | Acc: (92.00%) (46155/50000)
=> saving checkpoint 'drive/app/torch/save_Schedule/checkpoint_100.pth.tar'
# TEST : Loss: (0.4284) | Acc: (86.00%) (8615/10000)
percent tensor([0.5455, 0.5553, 0.5731, 0.5651, 0.5754, 0.5513, 0.5624, 0.5699, 0.5527,
        0.5587, 0.5444, 0.5682, 0.5480, 0.5527, 0.5555, 0.5481],
       device='cuda:0') torch.Size([16])
percent tensor([0.5702, 0.5706, 0.5659, 0.5603, 0.5745, 0.5778, 0.5766, 0.5718, 0.5662,
        0.5655, 0.5689, 0.5734, 0.5680, 0.5638, 0.5790, 0.5694],
       device='cuda:0') torch.Size([16])
percent tensor([0.5930, 0.5887, 0.5616, 0.5464, 0.5545, 0.5806, 0.5826, 0.5634, 0.5751,
        0.5819, 0.5820, 0.5732, 0.6026, 0.5781, 0.5955, 0.5937],
       device='cuda:0') torch.Size([16])
percent tensor([0.6317, 0.6277, 0.6024, 0.6004, 0.6097, 0.6472, 0.6325, 0.6008, 0.6253,
        0.6315, 0.6383, 0.6176, 0.6305, 0.6326, 0.6367, 0.6351],
       device='cuda:0') torch.Size([16])
percent tensor([0.5171, 0.4753, 0.5746, 0.5946, 0.5967, 0.5781, 0.5200, 0.5847, 0.5500,
        0.4840, 0.4953, 0.5337, 0.4459, 0.5740, 0.5385, 0.5464],
       device='cuda:0') torch.Size([16])
percent tensor([0.5055, 0.5855, 0.5971, 0.5799, 0.6202, 0.6164, 0.5862, 0.5445, 0.6223,
        0.5516, 0.6269, 0.5778, 0.5830, 0.6193, 0.4972, 0.5014],
       device='cuda:0') torch.Size([16])
percent tensor([0.6581, 0.6376, 0.6896, 0.6338, 0.6963, 0.6582, 0.6900, 0.6698, 0.6604,
        0.6495, 0.6475, 0.6338, 0.6278, 0.6728, 0.6271, 0.6204],
       device='cuda:0') torch.Size([16])
percent tensor([0.9993, 0.9993, 0.9996, 0.9991, 0.9998, 0.9988, 0.9998, 0.9999, 0.9993,
        0.9995, 0.9994, 0.9994, 0.9986, 0.9994, 0.9994, 0.9994],
       device='cuda:0') torch.Size([16])
Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 3, 3, 3]) tensor(184.7701, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(808.2367, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(824.8434, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([128, 64, 3, 3]) tensor(1530.3367, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([128, 64, 1, 1]) tensor(499.3163, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([128, 128, 3, 3]) tensor(2238.6519, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([256, 128, 3, 3]) tensor(4275.2935, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([256, 128, 1, 1]) tensor(1389.9304, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([256, 256, 3, 3]) tensor(6136.8057, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([512, 256, 3, 3]) tensor(11868.2881, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([512, 256, 1, 1]) tensor(3939.3867, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([512, 512, 3, 3]) tensor(16643.3496, device='cuda:0', grad_fn=<NormBackward0>)
Epoch: 101 | Batch_idx: 0 |  Loss: (0.1952) |  Loss2: (0.0000) | Acc: (94.00%) (121/128)
Epoch: 101 | Batch_idx: 10 |  Loss: (0.2036) |  Loss2: (0.0000) | Acc: (93.00%) (1311/1408)
Epoch: 101 | Batch_idx: 20 |  Loss: (0.2058) |  Loss2: (0.0000) | Acc: (93.00%) (2510/2688)
Epoch: 101 | Batch_idx: 30 |  Loss: (0.2119) |  Loss2: (0.0000) | Acc: (93.00%) (3691/3968)
Epoch: 101 | Batch_idx: 40 |  Loss: (0.2082) |  Loss2: (0.0000) | Acc: (93.00%) (4892/5248)
Epoch: 101 | Batch_idx: 50 |  Loss: (0.2032) |  Loss2: (0.0000) | Acc: (93.00%) (6090/6528)
Epoch: 101 | Batch_idx: 60 |  Loss: (0.2028) |  Loss2: (0.0000) | Acc: (93.00%) (7278/7808)
Epoch: 101 | Batch_idx: 70 |  Loss: (0.2039) |  Loss2: (0.0000) | Acc: (93.00%) (8471/9088)
Epoch: 101 | Batch_idx: 80 |  Loss: (0.2053) |  Loss2: (0.0000) | Acc: (93.00%) (9653/10368)
Epoch: 101 | Batch_idx: 90 |  Loss: (0.2077) |  Loss2: (0.0000) | Acc: (93.00%) (10834/11648)
Epoch: 101 | Batch_idx: 100 |  Loss: (0.2070) |  Loss2: (0.0000) | Acc: (92.00%) (12022/12928)
Epoch: 101 | Batch_idx: 110 |  Loss: (0.2086) |  Loss2: (0.0000) | Acc: (92.00%) (13209/14208)
Epoch: 101 | Batch_idx: 120 |  Loss: (0.2105) |  Loss2: (0.0000) | Acc: (92.00%) (14392/15488)
Epoch: 101 | Batch_idx: 130 |  Loss: (0.2117) |  Loss2: (0.0000) | Acc: (92.00%) (15572/16768)
Epoch: 101 | Batch_idx: 140 |  Loss: (0.2109) |  Loss2: (0.0000) | Acc: (92.00%) (16755/18048)
Epoch: 101 | Batch_idx: 150 |  Loss: (0.2101) |  Loss2: (0.0000) | Acc: (92.00%) (17954/19328)
Epoch: 101 | Batch_idx: 160 |  Loss: (0.2114) |  Loss2: (0.0000) | Acc: (92.00%) (19128/20608)
Epoch: 101 | Batch_idx: 170 |  Loss: (0.2110) |  Loss2: (0.0000) | Acc: (92.00%) (20318/21888)
Epoch: 101 | Batch_idx: 180 |  Loss: (0.2108) |  Loss2: (0.0000) | Acc: (92.00%) (21504/23168)
Epoch: 101 | Batch_idx: 190 |  Loss: (0.2131) |  Loss2: (0.0000) | Acc: (92.00%) (22666/24448)
Epoch: 101 | Batch_idx: 200 |  Loss: (0.2135) |  Loss2: (0.0000) | Acc: (92.00%) (23840/25728)
Epoch: 101 | Batch_idx: 210 |  Loss: (0.2136) |  Loss2: (0.0000) | Acc: (92.00%) (25024/27008)
Epoch: 101 | Batch_idx: 220 |  Loss: (0.2137) |  Loss2: (0.0000) | Acc: (92.00%) (26202/28288)
Epoch: 101 | Batch_idx: 230 |  Loss: (0.2151) |  Loss2: (0.0000) | Acc: (92.00%) (27375/29568)
Epoch: 101 | Batch_idx: 240 |  Loss: (0.2157) |  Loss2: (0.0000) | Acc: (92.00%) (28547/30848)
Epoch: 101 | Batch_idx: 250 |  Loss: (0.2161) |  Loss2: (0.0000) | Acc: (92.00%) (29727/32128)
Epoch: 101 | Batch_idx: 260 |  Loss: (0.2151) |  Loss2: (0.0000) | Acc: (92.00%) (30931/33408)
Epoch: 101 | Batch_idx: 270 |  Loss: (0.2145) |  Loss2: (0.0000) | Acc: (92.00%) (32106/34688)
Epoch: 101 | Batch_idx: 280 |  Loss: (0.2156) |  Loss2: (0.0000) | Acc: (92.00%) (33273/35968)
Epoch: 101 | Batch_idx: 290 |  Loss: (0.2172) |  Loss2: (0.0000) | Acc: (92.00%) (34435/37248)
Epoch: 101 | Batch_idx: 300 |  Loss: (0.2175) |  Loss2: (0.0000) | Acc: (92.00%) (35610/38528)
Epoch: 101 | Batch_idx: 310 |  Loss: (0.2172) |  Loss2: (0.0000) | Acc: (92.00%) (36803/39808)
Epoch: 101 | Batch_idx: 320 |  Loss: (0.2174) |  Loss2: (0.0000) | Acc: (92.00%) (37983/41088)
Epoch: 101 | Batch_idx: 330 |  Loss: (0.2181) |  Loss2: (0.0000) | Acc: (92.00%) (39162/42368)
Epoch: 101 | Batch_idx: 340 |  Loss: (0.2176) |  Loss2: (0.0000) | Acc: (92.00%) (40357/43648)
Epoch: 101 | Batch_idx: 350 |  Loss: (0.2178) |  Loss2: (0.0000) | Acc: (92.00%) (41530/44928)
Epoch: 101 | Batch_idx: 360 |  Loss: (0.2172) |  Loss2: (0.0000) | Acc: (92.00%) (42719/46208)
Epoch: 101 | Batch_idx: 370 |  Loss: (0.2171) |  Loss2: (0.0000) | Acc: (92.00%) (43903/47488)
Epoch: 101 | Batch_idx: 380 |  Loss: (0.2166) |  Loss2: (0.0000) | Acc: (92.00%) (45097/48768)
Epoch: 101 | Batch_idx: 390 |  Loss: (0.2172) |  Loss2: (0.0000) | Acc: (92.00%) (46225/50000)
# TEST : Loss: (0.4336) | Acc: (86.00%) (8623/10000)
percent tensor([0.5449, 0.5577, 0.5736, 0.5667, 0.5748, 0.5500, 0.5631, 0.5714, 0.5522,
        0.5591, 0.5437, 0.5688, 0.5475, 0.5558, 0.5563, 0.5487],
       device='cuda:0') torch.Size([16])
percent tensor([0.5708, 0.5719, 0.5638, 0.5580, 0.5739, 0.5801, 0.5777, 0.5707, 0.5669,
        0.5655, 0.5696, 0.5713, 0.5683, 0.5648, 0.5802, 0.5706],
       device='cuda:0') torch.Size([16])
percent tensor([0.5976, 0.5927, 0.5627, 0.5464, 0.5590, 0.5858, 0.5828, 0.5637, 0.5793,
        0.5846, 0.5876, 0.5768, 0.6067, 0.5744, 0.5978, 0.5984],
       device='cuda:0') torch.Size([16])
percent tensor([0.6344, 0.6314, 0.6004, 0.5980, 0.6117, 0.6532, 0.6357, 0.6030, 0.6273,
        0.6328, 0.6387, 0.6160, 0.6325, 0.6330, 0.6415, 0.6406],
       device='cuda:0') torch.Size([16])
percent tensor([0.5040, 0.4630, 0.5666, 0.5805, 0.5823, 0.5602, 0.5112, 0.5699, 0.5220,
        0.4883, 0.4805, 0.5290, 0.4319, 0.5491, 0.5193, 0.5315],
       device='cuda:0') torch.Size([16])
percent tensor([0.4961, 0.5774, 0.6011, 0.5824, 0.6237, 0.6180, 0.5723, 0.5273, 0.5963,
        0.5153, 0.6028, 0.5764, 0.5505, 0.5972, 0.4984, 0.4905],
       device='cuda:0') torch.Size([16])
percent tensor([0.6515, 0.6305, 0.6935, 0.6450, 0.6990, 0.6645, 0.6803, 0.6647, 0.6473,
        0.6381, 0.6438, 0.6311, 0.6195, 0.6538, 0.6233, 0.6221],
       device='cuda:0') torch.Size([16])
percent tensor([0.9992, 0.9990, 0.9997, 0.9996, 0.9998, 0.9994, 0.9996, 0.9999, 0.9995,
        0.9997, 0.9993, 0.9991, 0.9988, 0.9992, 0.9994, 0.9994],
       device='cuda:0') torch.Size([16])
Epoch: 102 | Batch_idx: 0 |  Loss: (0.2118) |  Loss2: (0.0000) | Acc: (93.00%) (120/128)
Epoch: 102 | Batch_idx: 10 |  Loss: (0.2121) |  Loss2: (0.0000) | Acc: (93.00%) (1314/1408)
Epoch: 102 | Batch_idx: 20 |  Loss: (0.2128) |  Loss2: (0.0000) | Acc: (93.00%) (2506/2688)
Epoch: 102 | Batch_idx: 30 |  Loss: (0.2105) |  Loss2: (0.0000) | Acc: (93.00%) (3693/3968)
Epoch: 102 | Batch_idx: 40 |  Loss: (0.2158) |  Loss2: (0.0000) | Acc: (92.00%) (4861/5248)
Epoch: 102 | Batch_idx: 50 |  Loss: (0.2172) |  Loss2: (0.0000) | Acc: (92.00%) (6040/6528)
Epoch: 102 | Batch_idx: 60 |  Loss: (0.2161) |  Loss2: (0.0000) | Acc: (92.00%) (7226/7808)
Epoch: 102 | Batch_idx: 70 |  Loss: (0.2132) |  Loss2: (0.0000) | Acc: (92.00%) (8419/9088)
Epoch: 102 | Batch_idx: 80 |  Loss: (0.2149) |  Loss2: (0.0000) | Acc: (92.00%) (9600/10368)
Epoch: 102 | Batch_idx: 90 |  Loss: (0.2150) |  Loss2: (0.0000) | Acc: (92.00%) (10786/11648)
Epoch: 102 | Batch_idx: 100 |  Loss: (0.2132) |  Loss2: (0.0000) | Acc: (92.00%) (11977/12928)
Epoch: 102 | Batch_idx: 110 |  Loss: (0.2112) |  Loss2: (0.0000) | Acc: (92.00%) (13175/14208)
Epoch: 102 | Batch_idx: 120 |  Loss: (0.2107) |  Loss2: (0.0000) | Acc: (92.00%) (14359/15488)
Epoch: 102 | Batch_idx: 130 |  Loss: (0.2099) |  Loss2: (0.0000) | Acc: (92.00%) (15550/16768)
Epoch: 102 | Batch_idx: 140 |  Loss: (0.2099) |  Loss2: (0.0000) | Acc: (92.00%) (16737/18048)
Epoch: 102 | Batch_idx: 150 |  Loss: (0.2097) |  Loss2: (0.0000) | Acc: (92.00%) (17929/19328)
Epoch: 102 | Batch_idx: 160 |  Loss: (0.2129) |  Loss2: (0.0000) | Acc: (92.00%) (19103/20608)
Epoch: 102 | Batch_idx: 170 |  Loss: (0.2136) |  Loss2: (0.0000) | Acc: (92.00%) (20279/21888)
Epoch: 102 | Batch_idx: 180 |  Loss: (0.2132) |  Loss2: (0.0000) | Acc: (92.00%) (21466/23168)
Epoch: 102 | Batch_idx: 190 |  Loss: (0.2127) |  Loss2: (0.0000) | Acc: (92.00%) (22654/24448)
Epoch: 102 | Batch_idx: 200 |  Loss: (0.2137) |  Loss2: (0.0000) | Acc: (92.00%) (23830/25728)
Epoch: 102 | Batch_idx: 210 |  Loss: (0.2135) |  Loss2: (0.0000) | Acc: (92.00%) (25011/27008)
Epoch: 102 | Batch_idx: 220 |  Loss: (0.2135) |  Loss2: (0.0000) | Acc: (92.00%) (26191/28288)
Epoch: 102 | Batch_idx: 230 |  Loss: (0.2139) |  Loss2: (0.0000) | Acc: (92.00%) (27383/29568)
Epoch: 102 | Batch_idx: 240 |  Loss: (0.2130) |  Loss2: (0.0000) | Acc: (92.00%) (28573/30848)
Epoch: 102 | Batch_idx: 250 |  Loss: (0.2124) |  Loss2: (0.0000) | Acc: (92.00%) (29769/32128)
Epoch: 102 | Batch_idx: 260 |  Loss: (0.2133) |  Loss2: (0.0000) | Acc: (92.00%) (30932/33408)
Epoch: 102 | Batch_idx: 270 |  Loss: (0.2132) |  Loss2: (0.0000) | Acc: (92.00%) (32115/34688)
Epoch: 102 | Batch_idx: 280 |  Loss: (0.2148) |  Loss2: (0.0000) | Acc: (92.00%) (33282/35968)
Epoch: 102 | Batch_idx: 290 |  Loss: (0.2159) |  Loss2: (0.0000) | Acc: (92.00%) (34453/37248)
Epoch: 102 | Batch_idx: 300 |  Loss: (0.2161) |  Loss2: (0.0000) | Acc: (92.00%) (35631/38528)
Epoch: 102 | Batch_idx: 310 |  Loss: (0.2168) |  Loss2: (0.0000) | Acc: (92.00%) (36805/39808)
Epoch: 102 | Batch_idx: 320 |  Loss: (0.2166) |  Loss2: (0.0000) | Acc: (92.00%) (37988/41088)
Epoch: 102 | Batch_idx: 330 |  Loss: (0.2169) |  Loss2: (0.0000) | Acc: (92.00%) (39168/42368)
Epoch: 102 | Batch_idx: 340 |  Loss: (0.2169) |  Loss2: (0.0000) | Acc: (92.00%) (40351/43648)
Epoch: 102 | Batch_idx: 350 |  Loss: (0.2176) |  Loss2: (0.0000) | Acc: (92.00%) (41518/44928)
Epoch: 102 | Batch_idx: 360 |  Loss: (0.2184) |  Loss2: (0.0000) | Acc: (92.00%) (42693/46208)
Epoch: 102 | Batch_idx: 370 |  Loss: (0.2184) |  Loss2: (0.0000) | Acc: (92.00%) (43874/47488)
Epoch: 102 | Batch_idx: 380 |  Loss: (0.2183) |  Loss2: (0.0000) | Acc: (92.00%) (45060/48768)
Epoch: 102 | Batch_idx: 390 |  Loss: (0.2181) |  Loss2: (0.0000) | Acc: (92.00%) (46202/50000)
# TEST : Loss: (0.4327) | Acc: (86.00%) (8635/10000)
percent tensor([0.5444, 0.5581, 0.5704, 0.5656, 0.5722, 0.5497, 0.5627, 0.5713, 0.5527,
        0.5583, 0.5445, 0.5657, 0.5472, 0.5581, 0.5560, 0.5487],
       device='cuda:0') torch.Size([16])
percent tensor([0.5698, 0.5712, 0.5657, 0.5608, 0.5746, 0.5784, 0.5771, 0.5721, 0.5665,
        0.5655, 0.5681, 0.5727, 0.5674, 0.5651, 0.5794, 0.5699],
       device='cuda:0') torch.Size([16])
percent tensor([0.5947, 0.5891, 0.5658, 0.5516, 0.5600, 0.5811, 0.5847, 0.5672, 0.5791,
        0.5846, 0.5824, 0.5759, 0.6045, 0.5792, 0.5936, 0.5945],
       device='cuda:0') torch.Size([16])
percent tensor([0.6289, 0.6275, 0.6019, 0.5964, 0.6090, 0.6422, 0.6331, 0.6019, 0.6252,
        0.6302, 0.6353, 0.6172, 0.6289, 0.6320, 0.6333, 0.6333],
       device='cuda:0') torch.Size([16])
percent tensor([0.5048, 0.4698, 0.5684, 0.5823, 0.5890, 0.5627, 0.5158, 0.5795, 0.5419,
        0.4691, 0.4877, 0.5247, 0.4364, 0.5594, 0.5274, 0.5392],
       device='cuda:0') torch.Size([16])
percent tensor([0.4880, 0.5800, 0.5975, 0.5930, 0.6154, 0.6191, 0.5891, 0.5459, 0.6037,
        0.5196, 0.6108, 0.5686, 0.5462, 0.6041, 0.4808, 0.4805],
       device='cuda:0') torch.Size([16])
percent tensor([0.6480, 0.6352, 0.6928, 0.6449, 0.6999, 0.6727, 0.6880, 0.6578, 0.6528,
        0.6370, 0.6441, 0.6388, 0.6165, 0.6809, 0.6180, 0.6229],
       device='cuda:0') torch.Size([16])
percent tensor([0.9994, 0.9991, 0.9997, 0.9994, 0.9999, 0.9993, 0.9997, 0.9998, 0.9995,
        0.9997, 0.9996, 0.9993, 0.9987, 0.9997, 0.9995, 0.9994],
       device='cuda:0') torch.Size([16])
Epoch: 103 | Batch_idx: 0 |  Loss: (0.1595) |  Loss2: (0.0000) | Acc: (94.00%) (121/128)
Epoch: 103 | Batch_idx: 10 |  Loss: (0.2132) |  Loss2: (0.0000) | Acc: (92.00%) (1304/1408)
Epoch: 103 | Batch_idx: 20 |  Loss: (0.1960) |  Loss2: (0.0000) | Acc: (93.00%) (2509/2688)
Epoch: 103 | Batch_idx: 30 |  Loss: (0.2061) |  Loss2: (0.0000) | Acc: (92.00%) (3685/3968)
Epoch: 103 | Batch_idx: 40 |  Loss: (0.2052) |  Loss2: (0.0000) | Acc: (93.00%) (4888/5248)
Epoch: 103 | Batch_idx: 50 |  Loss: (0.2032) |  Loss2: (0.0000) | Acc: (93.00%) (6084/6528)
Epoch: 103 | Batch_idx: 60 |  Loss: (0.2018) |  Loss2: (0.0000) | Acc: (93.00%) (7288/7808)
Epoch: 103 | Batch_idx: 70 |  Loss: (0.2033) |  Loss2: (0.0000) | Acc: (93.00%) (8473/9088)
Epoch: 103 | Batch_idx: 80 |  Loss: (0.2045) |  Loss2: (0.0000) | Acc: (93.00%) (9660/10368)
Epoch: 103 | Batch_idx: 90 |  Loss: (0.2058) |  Loss2: (0.0000) | Acc: (93.00%) (10842/11648)
Epoch: 103 | Batch_idx: 100 |  Loss: (0.2056) |  Loss2: (0.0000) | Acc: (93.00%) (12029/12928)
Epoch: 103 | Batch_idx: 110 |  Loss: (0.2046) |  Loss2: (0.0000) | Acc: (93.00%) (13221/14208)
Epoch: 103 | Batch_idx: 120 |  Loss: (0.2064) |  Loss2: (0.0000) | Acc: (93.00%) (14413/15488)
Epoch: 103 | Batch_idx: 130 |  Loss: (0.2071) |  Loss2: (0.0000) | Acc: (93.00%) (15603/16768)
Epoch: 103 | Batch_idx: 140 |  Loss: (0.2054) |  Loss2: (0.0000) | Acc: (93.00%) (16804/18048)
Epoch: 103 | Batch_idx: 150 |  Loss: (0.2047) |  Loss2: (0.0000) | Acc: (93.00%) (18002/19328)
Epoch: 103 | Batch_idx: 160 |  Loss: (0.2060) |  Loss2: (0.0000) | Acc: (93.00%) (19188/20608)
Epoch: 103 | Batch_idx: 170 |  Loss: (0.2067) |  Loss2: (0.0000) | Acc: (93.00%) (20363/21888)
Epoch: 103 | Batch_idx: 180 |  Loss: (0.2071) |  Loss2: (0.0000) | Acc: (93.00%) (21548/23168)
Epoch: 103 | Batch_idx: 190 |  Loss: (0.2070) |  Loss2: (0.0000) | Acc: (93.00%) (22743/24448)
Epoch: 103 | Batch_idx: 200 |  Loss: (0.2079) |  Loss2: (0.0000) | Acc: (92.00%) (23923/25728)
Epoch: 103 | Batch_idx: 210 |  Loss: (0.2082) |  Loss2: (0.0000) | Acc: (92.00%) (25106/27008)
Epoch: 103 | Batch_idx: 220 |  Loss: (0.2087) |  Loss2: (0.0000) | Acc: (92.00%) (26280/28288)
Epoch: 103 | Batch_idx: 230 |  Loss: (0.2087) |  Loss2: (0.0000) | Acc: (92.00%) (27464/29568)
Epoch: 103 | Batch_idx: 240 |  Loss: (0.2091) |  Loss2: (0.0000) | Acc: (92.00%) (28653/30848)
Epoch: 103 | Batch_idx: 250 |  Loss: (0.2087) |  Loss2: (0.0000) | Acc: (92.00%) (29853/32128)
Epoch: 103 | Batch_idx: 260 |  Loss: (0.2079) |  Loss2: (0.0000) | Acc: (92.00%) (31052/33408)
Epoch: 103 | Batch_idx: 270 |  Loss: (0.2092) |  Loss2: (0.0000) | Acc: (92.00%) (32224/34688)
Epoch: 103 | Batch_idx: 280 |  Loss: (0.2096) |  Loss2: (0.0000) | Acc: (92.00%) (33403/35968)
Epoch: 103 | Batch_idx: 290 |  Loss: (0.2095) |  Loss2: (0.0000) | Acc: (92.00%) (34592/37248)
Epoch: 103 | Batch_idx: 300 |  Loss: (0.2093) |  Loss2: (0.0000) | Acc: (92.00%) (35783/38528)
Epoch: 103 | Batch_idx: 310 |  Loss: (0.2086) |  Loss2: (0.0000) | Acc: (92.00%) (36985/39808)
Epoch: 103 | Batch_idx: 320 |  Loss: (0.2088) |  Loss2: (0.0000) | Acc: (92.00%) (38170/41088)
Epoch: 103 | Batch_idx: 330 |  Loss: (0.2089) |  Loss2: (0.0000) | Acc: (92.00%) (39353/42368)
Epoch: 103 | Batch_idx: 340 |  Loss: (0.2085) |  Loss2: (0.0000) | Acc: (92.00%) (40549/43648)
Epoch: 103 | Batch_idx: 350 |  Loss: (0.2078) |  Loss2: (0.0000) | Acc: (92.00%) (41747/44928)
Epoch: 103 | Batch_idx: 360 |  Loss: (0.2085) |  Loss2: (0.0000) | Acc: (92.00%) (42918/46208)
Epoch: 103 | Batch_idx: 370 |  Loss: (0.2077) |  Loss2: (0.0000) | Acc: (92.00%) (44121/47488)
Epoch: 103 | Batch_idx: 380 |  Loss: (0.2077) |  Loss2: (0.0000) | Acc: (92.00%) (45310/48768)
Epoch: 103 | Batch_idx: 390 |  Loss: (0.2075) |  Loss2: (0.0000) | Acc: (92.00%) (46468/50000)
# TEST : Loss: (0.4455) | Acc: (86.00%) (8634/10000)
percent tensor([0.5470, 0.5546, 0.5758, 0.5656, 0.5784, 0.5520, 0.5637, 0.5705, 0.5549,
        0.5588, 0.5455, 0.5713, 0.5496, 0.5530, 0.5554, 0.5482],
       device='cuda:0') torch.Size([16])
percent tensor([0.5706, 0.5719, 0.5644, 0.5596, 0.5731, 0.5762, 0.5776, 0.5719, 0.5666,
        0.5658, 0.5696, 0.5715, 0.5686, 0.5660, 0.5795, 0.5705],
       device='cuda:0') torch.Size([16])
percent tensor([0.5925, 0.5865, 0.5613, 0.5460, 0.5552, 0.5777, 0.5840, 0.5621, 0.5764,
        0.5807, 0.5810, 0.5712, 0.6027, 0.5801, 0.5899, 0.5933],
       device='cuda:0') torch.Size([16])
percent tensor([0.6318, 0.6269, 0.5984, 0.5973, 0.6081, 0.6491, 0.6342, 0.6001, 0.6229,
        0.6292, 0.6377, 0.6145, 0.6291, 0.6300, 0.6364, 0.6373],
       device='cuda:0') torch.Size([16])
percent tensor([0.5153, 0.4899, 0.5633, 0.5834, 0.5887, 0.5620, 0.5331, 0.5860, 0.5431,
        0.4983, 0.5090, 0.5450, 0.4507, 0.5711, 0.5447, 0.5468],
       device='cuda:0') torch.Size([16])
percent tensor([0.5052, 0.5831, 0.6180, 0.6004, 0.6269, 0.6312, 0.5826, 0.5461, 0.6235,
        0.5421, 0.6279, 0.5900, 0.5553, 0.6343, 0.5005, 0.4984],
       device='cuda:0') torch.Size([16])
percent tensor([0.6536, 0.6411, 0.6939, 0.6419, 0.6971, 0.6638, 0.6984, 0.6683, 0.6560,
        0.6418, 0.6499, 0.6388, 0.6239, 0.6820, 0.6246, 0.6308],
       device='cuda:0') torch.Size([16])
percent tensor([0.9992, 0.9991, 0.9996, 0.9992, 0.9998, 0.9989, 0.9999, 0.9999, 0.9996,
        0.9995, 0.9996, 0.9996, 0.9989, 0.9996, 0.9994, 0.9992],
       device='cuda:0') torch.Size([16])
Epoch: 104 | Batch_idx: 0 |  Loss: (0.2298) |  Loss2: (0.0000) | Acc: (92.00%) (118/128)
Epoch: 104 | Batch_idx: 10 |  Loss: (0.1669) |  Loss2: (0.0000) | Acc: (94.00%) (1328/1408)
Epoch: 104 | Batch_idx: 20 |  Loss: (0.1796) |  Loss2: (0.0000) | Acc: (93.00%) (2525/2688)
Epoch: 104 | Batch_idx: 30 |  Loss: (0.1845) |  Loss2: (0.0000) | Acc: (93.00%) (3719/3968)
Epoch: 104 | Batch_idx: 40 |  Loss: (0.1830) |  Loss2: (0.0000) | Acc: (93.00%) (4923/5248)
Epoch: 104 | Batch_idx: 50 |  Loss: (0.1911) |  Loss2: (0.0000) | Acc: (93.00%) (6105/6528)
Epoch: 104 | Batch_idx: 60 |  Loss: (0.1956) |  Loss2: (0.0000) | Acc: (93.00%) (7298/7808)
Epoch: 104 | Batch_idx: 70 |  Loss: (0.1938) |  Loss2: (0.0000) | Acc: (93.00%) (8507/9088)
Epoch: 104 | Batch_idx: 80 |  Loss: (0.1920) |  Loss2: (0.0000) | Acc: (93.00%) (9711/10368)
Epoch: 104 | Batch_idx: 90 |  Loss: (0.1957) |  Loss2: (0.0000) | Acc: (93.00%) (10889/11648)
Epoch: 104 | Batch_idx: 100 |  Loss: (0.1986) |  Loss2: (0.0000) | Acc: (93.00%) (12072/12928)
Epoch: 104 | Batch_idx: 110 |  Loss: (0.2006) |  Loss2: (0.0000) | Acc: (93.00%) (13256/14208)
Epoch: 104 | Batch_idx: 120 |  Loss: (0.2001) |  Loss2: (0.0000) | Acc: (93.00%) (14460/15488)
Epoch: 104 | Batch_idx: 130 |  Loss: (0.2010) |  Loss2: (0.0000) | Acc: (93.00%) (15644/16768)
Epoch: 104 | Batch_idx: 140 |  Loss: (0.2017) |  Loss2: (0.0000) | Acc: (93.00%) (16825/18048)
Epoch: 104 | Batch_idx: 150 |  Loss: (0.2018) |  Loss2: (0.0000) | Acc: (93.00%) (18016/19328)
Epoch: 104 | Batch_idx: 160 |  Loss: (0.2024) |  Loss2: (0.0000) | Acc: (93.00%) (19196/20608)
Epoch: 104 | Batch_idx: 170 |  Loss: (0.2017) |  Loss2: (0.0000) | Acc: (93.00%) (20386/21888)
Epoch: 104 | Batch_idx: 180 |  Loss: (0.2039) |  Loss2: (0.0000) | Acc: (93.00%) (21566/23168)
Epoch: 104 | Batch_idx: 190 |  Loss: (0.2047) |  Loss2: (0.0000) | Acc: (93.00%) (22746/24448)
Epoch: 104 | Batch_idx: 200 |  Loss: (0.2054) |  Loss2: (0.0000) | Acc: (93.00%) (23940/25728)
Epoch: 104 | Batch_idx: 210 |  Loss: (0.2057) |  Loss2: (0.0000) | Acc: (93.00%) (25129/27008)
Epoch: 104 | Batch_idx: 220 |  Loss: (0.2054) |  Loss2: (0.0000) | Acc: (93.00%) (26316/28288)
Epoch: 104 | Batch_idx: 230 |  Loss: (0.2060) |  Loss2: (0.0000) | Acc: (92.00%) (27495/29568)
Epoch: 104 | Batch_idx: 240 |  Loss: (0.2065) |  Loss2: (0.0000) | Acc: (92.00%) (28681/30848)
Epoch: 104 | Batch_idx: 250 |  Loss: (0.2058) |  Loss2: (0.0000) | Acc: (92.00%) (29877/32128)
Epoch: 104 | Batch_idx: 260 |  Loss: (0.2059) |  Loss2: (0.0000) | Acc: (93.00%) (31072/33408)
Epoch: 104 | Batch_idx: 270 |  Loss: (0.2061) |  Loss2: (0.0000) | Acc: (92.00%) (32257/34688)
Epoch: 104 | Batch_idx: 280 |  Loss: (0.2057) |  Loss2: (0.0000) | Acc: (92.00%) (33448/35968)
Epoch: 104 | Batch_idx: 290 |  Loss: (0.2057) |  Loss2: (0.0000) | Acc: (93.00%) (34642/37248)
Epoch: 104 | Batch_idx: 300 |  Loss: (0.2058) |  Loss2: (0.0000) | Acc: (93.00%) (35832/38528)
Epoch: 104 | Batch_idx: 310 |  Loss: (0.2060) |  Loss2: (0.0000) | Acc: (93.00%) (37022/39808)
Epoch: 104 | Batch_idx: 320 |  Loss: (0.2057) |  Loss2: (0.0000) | Acc: (93.00%) (38216/41088)
Epoch: 104 | Batch_idx: 330 |  Loss: (0.2058) |  Loss2: (0.0000) | Acc: (93.00%) (39404/42368)
Epoch: 104 | Batch_idx: 340 |  Loss: (0.2063) |  Loss2: (0.0000) | Acc: (92.00%) (40591/43648)
Epoch: 104 | Batch_idx: 350 |  Loss: (0.2069) |  Loss2: (0.0000) | Acc: (92.00%) (41770/44928)
Epoch: 104 | Batch_idx: 360 |  Loss: (0.2077) |  Loss2: (0.0000) | Acc: (92.00%) (42949/46208)
Epoch: 104 | Batch_idx: 370 |  Loss: (0.2067) |  Loss2: (0.0000) | Acc: (92.00%) (44161/47488)
Epoch: 104 | Batch_idx: 380 |  Loss: (0.2062) |  Loss2: (0.0000) | Acc: (93.00%) (45361/48768)
Epoch: 104 | Batch_idx: 390 |  Loss: (0.2060) |  Loss2: (0.0000) | Acc: (93.00%) (46505/50000)
# TEST : Loss: (0.4499) | Acc: (86.00%) (8643/10000)
percent tensor([0.5460, 0.5546, 0.5745, 0.5659, 0.5771, 0.5513, 0.5624, 0.5711, 0.5537,
        0.5591, 0.5453, 0.5692, 0.5488, 0.5516, 0.5556, 0.5487],
       device='cuda:0') torch.Size([16])
percent tensor([0.5702, 0.5730, 0.5644, 0.5598, 0.5730, 0.5776, 0.5775, 0.5707, 0.5671,
        0.5660, 0.5698, 0.5713, 0.5681, 0.5659, 0.5805, 0.5702],
       device='cuda:0') torch.Size([16])
percent tensor([0.5948, 0.5957, 0.5624, 0.5507, 0.5580, 0.5832, 0.5890, 0.5648, 0.5807,
        0.5875, 0.5839, 0.5760, 0.6052, 0.5856, 0.5977, 0.5979],
       device='cuda:0') torch.Size([16])
percent tensor([0.6337, 0.6311, 0.6041, 0.5974, 0.6138, 0.6455, 0.6352, 0.6034, 0.6247,
        0.6340, 0.6389, 0.6203, 0.6305, 0.6287, 0.6383, 0.6373],
       device='cuda:0') torch.Size([16])
percent tensor([0.5099, 0.4717, 0.5679, 0.5743, 0.5874, 0.5533, 0.5205, 0.5709, 0.5422,
        0.4870, 0.5033, 0.5201, 0.4364, 0.5571, 0.5288, 0.5340],
       device='cuda:0') torch.Size([16])
percent tensor([0.5119, 0.5951, 0.5968, 0.5931, 0.6169, 0.6343, 0.5729, 0.5304, 0.6134,
        0.5390, 0.6202, 0.5851, 0.5470, 0.6417, 0.5061, 0.5107],
       device='cuda:0') torch.Size([16])
percent tensor([0.6528, 0.6442, 0.6909, 0.6473, 0.7011, 0.6648, 0.6885, 0.6597, 0.6591,
        0.6482, 0.6474, 0.6257, 0.6151, 0.6793, 0.6201, 0.6312],
       device='cuda:0') torch.Size([16])
percent tensor([0.9994, 0.9989, 0.9996, 0.9994, 0.9999, 0.9989, 0.9998, 0.9998, 0.9995,
        0.9996, 0.9996, 0.9993, 0.9990, 0.9994, 0.9995, 0.9996],
       device='cuda:0') torch.Size([16])
False Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=128, out_features=16, bias=False)
True Linear(in_features=16, out_features=2, bias=False)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=128, out_features=16, bias=False)
True Linear(in_features=16, out_features=2, bias=False)
False Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=256, out_features=32, bias=False)
True Linear(in_features=32, out_features=2, bias=False)
False Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=256, out_features=32, bias=False)
True Linear(in_features=32, out_features=2, bias=False)
False Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=512, out_features=64, bias=False)
True Linear(in_features=64, out_features=2, bias=False)
False Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=512, out_features=64, bias=False)
True Linear(in_features=64, out_features=2, bias=False)
False Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1024, out_features=128, bias=False)
True Linear(in_features=128, out_features=2, bias=False)
False Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1024, out_features=128, bias=False)
True Linear(in_features=128, out_features=2, bias=False)
False Linear(in_features=512, out_features=10, bias=True)
Epoch: 105 | Batch_idx: 0 |  Loss: (0.1362) |  Loss2: (0.0000) | Acc: (96.00%) (123/128)
Epoch: 105 | Batch_idx: 10 |  Loss: (0.2008) |  Loss2: (0.0000) | Acc: (92.00%) (1305/1408)
Epoch: 105 | Batch_idx: 20 |  Loss: (0.2228) |  Loss2: (0.0000) | Acc: (92.00%) (2478/2688)
Epoch: 105 | Batch_idx: 30 |  Loss: (0.2398) |  Loss2: (0.0000) | Acc: (91.00%) (3636/3968)
Epoch: 105 | Batch_idx: 40 |  Loss: (0.2544) |  Loss2: (0.0000) | Acc: (91.00%) (4778/5248)
Epoch: 105 | Batch_idx: 50 |  Loss: (0.2527) |  Loss2: (0.0000) | Acc: (91.00%) (5946/6528)
Epoch: 105 | Batch_idx: 60 |  Loss: (0.2539) |  Loss2: (0.0000) | Acc: (90.00%) (7105/7808)
Epoch: 105 | Batch_idx: 70 |  Loss: (0.2503) |  Loss2: (0.0000) | Acc: (91.00%) (8285/9088)
Epoch: 105 | Batch_idx: 80 |  Loss: (0.2517) |  Loss2: (0.0000) | Acc: (91.00%) (9455/10368)
Epoch: 105 | Batch_idx: 90 |  Loss: (0.2498) |  Loss2: (0.0000) | Acc: (91.00%) (10627/11648)
Epoch: 105 | Batch_idx: 100 |  Loss: (0.2541) |  Loss2: (0.0000) | Acc: (91.00%) (11776/12928)
Epoch: 105 | Batch_idx: 110 |  Loss: (0.2544) |  Loss2: (0.0000) | Acc: (91.00%) (12938/14208)
Epoch: 105 | Batch_idx: 120 |  Loss: (0.2531) |  Loss2: (0.0000) | Acc: (91.00%) (14116/15488)
Epoch: 105 | Batch_idx: 130 |  Loss: (0.2514) |  Loss2: (0.0000) | Acc: (91.00%) (15288/16768)
Epoch: 105 | Batch_idx: 140 |  Loss: (0.2517) |  Loss2: (0.0000) | Acc: (91.00%) (16453/18048)
Epoch: 105 | Batch_idx: 150 |  Loss: (0.2519) |  Loss2: (0.0000) | Acc: (91.00%) (17621/19328)
Epoch: 105 | Batch_idx: 160 |  Loss: (0.2510) |  Loss2: (0.0000) | Acc: (91.00%) (18794/20608)
Epoch: 105 | Batch_idx: 170 |  Loss: (0.2517) |  Loss2: (0.0000) | Acc: (91.00%) (19959/21888)
Epoch: 105 | Batch_idx: 180 |  Loss: (0.2543) |  Loss2: (0.0000) | Acc: (91.00%) (21112/23168)
Epoch: 105 | Batch_idx: 190 |  Loss: (0.2545) |  Loss2: (0.0000) | Acc: (91.00%) (22273/24448)
Epoch: 105 | Batch_idx: 200 |  Loss: (0.2532) |  Loss2: (0.0000) | Acc: (91.00%) (23455/25728)
Epoch: 105 | Batch_idx: 210 |  Loss: (0.2526) |  Loss2: (0.0000) | Acc: (91.00%) (24626/27008)
Epoch: 105 | Batch_idx: 220 |  Loss: (0.2517) |  Loss2: (0.0000) | Acc: (91.00%) (25800/28288)
Epoch: 105 | Batch_idx: 230 |  Loss: (0.2511) |  Loss2: (0.0000) | Acc: (91.00%) (26966/29568)
Epoch: 105 | Batch_idx: 240 |  Loss: (0.2506) |  Loss2: (0.0000) | Acc: (91.00%) (28135/30848)
Epoch: 105 | Batch_idx: 250 |  Loss: (0.2502) |  Loss2: (0.0000) | Acc: (91.00%) (29319/32128)
Epoch: 105 | Batch_idx: 260 |  Loss: (0.2497) |  Loss2: (0.0000) | Acc: (91.00%) (30492/33408)
Epoch: 105 | Batch_idx: 270 |  Loss: (0.2500) |  Loss2: (0.0000) | Acc: (91.00%) (31655/34688)
Epoch: 105 | Batch_idx: 280 |  Loss: (0.2487) |  Loss2: (0.0000) | Acc: (91.00%) (32839/35968)
Epoch: 105 | Batch_idx: 290 |  Loss: (0.2467) |  Loss2: (0.0000) | Acc: (91.00%) (34035/37248)
Epoch: 105 | Batch_idx: 300 |  Loss: (0.2448) |  Loss2: (0.0000) | Acc: (91.00%) (35226/38528)
Epoch: 105 | Batch_idx: 310 |  Loss: (0.2439) |  Loss2: (0.0000) | Acc: (91.00%) (36418/39808)
Epoch: 105 | Batch_idx: 320 |  Loss: (0.2441) |  Loss2: (0.0000) | Acc: (91.00%) (37588/41088)
Epoch: 105 | Batch_idx: 330 |  Loss: (0.2443) |  Loss2: (0.0000) | Acc: (91.00%) (38754/42368)
Epoch: 105 | Batch_idx: 340 |  Loss: (0.2435) |  Loss2: (0.0000) | Acc: (91.00%) (39941/43648)
Epoch: 105 | Batch_idx: 350 |  Loss: (0.2432) |  Loss2: (0.0000) | Acc: (91.00%) (41110/44928)
Epoch: 105 | Batch_idx: 360 |  Loss: (0.2425) |  Loss2: (0.0000) | Acc: (91.00%) (42294/46208)
Epoch: 105 | Batch_idx: 370 |  Loss: (0.2427) |  Loss2: (0.0000) | Acc: (91.00%) (43462/47488)
Epoch: 105 | Batch_idx: 380 |  Loss: (0.2426) |  Loss2: (0.0000) | Acc: (91.00%) (44624/48768)
Epoch: 105 | Batch_idx: 390 |  Loss: (0.2425) |  Loss2: (0.0000) | Acc: (91.00%) (45738/50000)
=> saving checkpoint 'drive/app/torch/save_Schedule/checkpoint_105.pth.tar'
# TEST : Loss: (0.4352) | Acc: (86.00%) (8656/10000)
percent tensor([0.5451, 0.5547, 0.5724, 0.5650, 0.5750, 0.5498, 0.5616, 0.5700, 0.5535,
        0.5579, 0.5447, 0.5665, 0.5480, 0.5525, 0.5543, 0.5477],
       device='cuda:0') torch.Size([16])
percent tensor([0.5709, 0.5750, 0.5634, 0.5591, 0.5707, 0.5761, 0.5785, 0.5698, 0.5682,
        0.5672, 0.5719, 0.5710, 0.5690, 0.5695, 0.5810, 0.5703],
       device='cuda:0') torch.Size([16])
percent tensor([0.5884, 0.5919, 0.5540, 0.5412, 0.5518, 0.5749, 0.5842, 0.5591, 0.5762,
        0.5846, 0.5829, 0.5711, 0.6023, 0.5797, 0.5907, 0.5912],
       device='cuda:0') torch.Size([16])
percent tensor([0.6591, 0.6547, 0.6262, 0.6195, 0.6362, 0.6666, 0.6597, 0.6260, 0.6472,
        0.6578, 0.6630, 0.6435, 0.6540, 0.6531, 0.6622, 0.6600],
       device='cuda:0') torch.Size([16])
percent tensor([0.5043, 0.4947, 0.5564, 0.5593, 0.5770, 0.5162, 0.5313, 0.5820, 0.5416,
        0.4926, 0.5016, 0.5156, 0.4419, 0.5747, 0.5414, 0.5129],
       device='cuda:0') torch.Size([16])
percent tensor([0.5737, 0.6414, 0.6408, 0.6445, 0.6700, 0.6833, 0.6341, 0.5909, 0.6614,
        0.5876, 0.6685, 0.6278, 0.6019, 0.6789, 0.5559, 0.5723],
       device='cuda:0') torch.Size([16])
percent tensor([0.6486, 0.6543, 0.7009, 0.6508, 0.7105, 0.6665, 0.6904, 0.6761, 0.6553,
        0.6542, 0.6430, 0.6232, 0.6216, 0.6680, 0.6199, 0.6342],
       device='cuda:0') torch.Size([16])
percent tensor([0.9994, 0.9991, 0.9997, 0.9993, 0.9998, 0.9986, 0.9998, 0.9999, 0.9994,
        0.9995, 0.9995, 0.9995, 0.9991, 0.9995, 0.9995, 0.9994],
       device='cuda:0') torch.Size([16])
Epoch: 106 | Batch_idx: 0 |  Loss: (0.2363) |  Loss2: (0.0000) | Acc: (92.00%) (119/128)
Epoch: 106 | Batch_idx: 10 |  Loss: (0.2478) |  Loss2: (0.0000) | Acc: (91.00%) (1293/1408)
Epoch: 106 | Batch_idx: 20 |  Loss: (0.2372) |  Loss2: (0.0000) | Acc: (92.00%) (2475/2688)
Epoch: 106 | Batch_idx: 30 |  Loss: (0.2267) |  Loss2: (0.0000) | Acc: (92.00%) (3663/3968)
Epoch: 106 | Batch_idx: 40 |  Loss: (0.2264) |  Loss2: (0.0000) | Acc: (92.00%) (4842/5248)
Epoch: 106 | Batch_idx: 50 |  Loss: (0.2283) |  Loss2: (0.0000) | Acc: (92.00%) (6008/6528)
Epoch: 106 | Batch_idx: 60 |  Loss: (0.2310) |  Loss2: (0.0000) | Acc: (92.00%) (7184/7808)
Epoch: 106 | Batch_idx: 70 |  Loss: (0.2308) |  Loss2: (0.0000) | Acc: (92.00%) (8366/9088)
Epoch: 106 | Batch_idx: 80 |  Loss: (0.2331) |  Loss2: (0.0000) | Acc: (92.00%) (9544/10368)
Epoch: 106 | Batch_idx: 90 |  Loss: (0.2310) |  Loss2: (0.0000) | Acc: (92.00%) (10730/11648)
Epoch: 106 | Batch_idx: 100 |  Loss: (0.2308) |  Loss2: (0.0000) | Acc: (92.00%) (11912/12928)
Epoch: 106 | Batch_idx: 110 |  Loss: (0.2300) |  Loss2: (0.0000) | Acc: (92.00%) (13091/14208)
Epoch: 106 | Batch_idx: 120 |  Loss: (0.2298) |  Loss2: (0.0000) | Acc: (92.00%) (14276/15488)
Epoch: 106 | Batch_idx: 130 |  Loss: (0.2294) |  Loss2: (0.0000) | Acc: (92.00%) (15461/16768)
Epoch: 106 | Batch_idx: 140 |  Loss: (0.2289) |  Loss2: (0.0000) | Acc: (92.00%) (16632/18048)
Epoch: 106 | Batch_idx: 150 |  Loss: (0.2293) |  Loss2: (0.0000) | Acc: (92.00%) (17807/19328)
Epoch: 106 | Batch_idx: 160 |  Loss: (0.2281) |  Loss2: (0.0000) | Acc: (92.00%) (18993/20608)
Epoch: 106 | Batch_idx: 170 |  Loss: (0.2299) |  Loss2: (0.0000) | Acc: (92.00%) (20155/21888)
Epoch: 106 | Batch_idx: 180 |  Loss: (0.2282) |  Loss2: (0.0000) | Acc: (92.00%) (21347/23168)
Epoch: 106 | Batch_idx: 190 |  Loss: (0.2268) |  Loss2: (0.0000) | Acc: (92.00%) (22539/24448)
Epoch: 106 | Batch_idx: 200 |  Loss: (0.2249) |  Loss2: (0.0000) | Acc: (92.00%) (23730/25728)
Epoch: 106 | Batch_idx: 210 |  Loss: (0.2253) |  Loss2: (0.0000) | Acc: (92.00%) (24915/27008)
Epoch: 106 | Batch_idx: 220 |  Loss: (0.2246) |  Loss2: (0.0000) | Acc: (92.00%) (26099/28288)
Epoch: 106 | Batch_idx: 230 |  Loss: (0.2251) |  Loss2: (0.0000) | Acc: (92.00%) (27273/29568)
Epoch: 106 | Batch_idx: 240 |  Loss: (0.2256) |  Loss2: (0.0000) | Acc: (92.00%) (28447/30848)
Epoch: 106 | Batch_idx: 250 |  Loss: (0.2267) |  Loss2: (0.0000) | Acc: (92.00%) (29619/32128)
Epoch: 106 | Batch_idx: 260 |  Loss: (0.2260) |  Loss2: (0.0000) | Acc: (92.00%) (30802/33408)
Epoch: 106 | Batch_idx: 270 |  Loss: (0.2254) |  Loss2: (0.0000) | Acc: (92.00%) (31998/34688)
Epoch: 106 | Batch_idx: 280 |  Loss: (0.2245) |  Loss2: (0.0000) | Acc: (92.00%) (33180/35968)
Epoch: 106 | Batch_idx: 290 |  Loss: (0.2238) |  Loss2: (0.0000) | Acc: (92.00%) (34373/37248)
Epoch: 106 | Batch_idx: 300 |  Loss: (0.2229) |  Loss2: (0.0000) | Acc: (92.00%) (35558/38528)
Epoch: 106 | Batch_idx: 310 |  Loss: (0.2228) |  Loss2: (0.0000) | Acc: (92.00%) (36734/39808)
Epoch: 106 | Batch_idx: 320 |  Loss: (0.2227) |  Loss2: (0.0000) | Acc: (92.00%) (37926/41088)
Epoch: 106 | Batch_idx: 330 |  Loss: (0.2222) |  Loss2: (0.0000) | Acc: (92.00%) (39112/42368)
Epoch: 106 | Batch_idx: 340 |  Loss: (0.2225) |  Loss2: (0.0000) | Acc: (92.00%) (40290/43648)
Epoch: 106 | Batch_idx: 350 |  Loss: (0.2222) |  Loss2: (0.0000) | Acc: (92.00%) (41479/44928)
Epoch: 106 | Batch_idx: 360 |  Loss: (0.2218) |  Loss2: (0.0000) | Acc: (92.00%) (42668/46208)
Epoch: 106 | Batch_idx: 370 |  Loss: (0.2212) |  Loss2: (0.0000) | Acc: (92.00%) (43854/47488)
Epoch: 106 | Batch_idx: 380 |  Loss: (0.2209) |  Loss2: (0.0000) | Acc: (92.00%) (45037/48768)
Epoch: 106 | Batch_idx: 390 |  Loss: (0.2210) |  Loss2: (0.0000) | Acc: (92.00%) (46170/50000)
# TEST : Loss: (0.4141) | Acc: (87.00%) (8738/10000)
percent tensor([0.5456, 0.5553, 0.5737, 0.5649, 0.5761, 0.5495, 0.5626, 0.5707, 0.5543,
        0.5589, 0.5451, 0.5679, 0.5485, 0.5529, 0.5542, 0.5478],
       device='cuda:0') torch.Size([16])
percent tensor([0.5693, 0.5734, 0.5607, 0.5565, 0.5677, 0.5742, 0.5765, 0.5671, 0.5666,
        0.5655, 0.5706, 0.5688, 0.5676, 0.5683, 0.5792, 0.5684],
       device='cuda:0') torch.Size([16])
percent tensor([0.5887, 0.5913, 0.5553, 0.5424, 0.5514, 0.5744, 0.5841, 0.5588, 0.5778,
        0.5851, 0.5838, 0.5727, 0.6033, 0.5811, 0.5896, 0.5905],
       device='cuda:0') torch.Size([16])
percent tensor([0.6600, 0.6566, 0.6259, 0.6203, 0.6361, 0.6680, 0.6605, 0.6261, 0.6478,
        0.6587, 0.6640, 0.6437, 0.6553, 0.6553, 0.6634, 0.6607],
       device='cuda:0') torch.Size([16])
percent tensor([0.5011, 0.4898, 0.5539, 0.5594, 0.5761, 0.4983, 0.5279, 0.5905, 0.5385,
        0.4852, 0.4992, 0.5147, 0.4353, 0.5697, 0.5432, 0.4980],
       device='cuda:0') torch.Size([16])
percent tensor([0.5663, 0.6360, 0.6371, 0.6412, 0.6676, 0.6836, 0.6263, 0.5829, 0.6537,
        0.5815, 0.6591, 0.6186, 0.5959, 0.6719, 0.5431, 0.5679],
       device='cuda:0') torch.Size([16])
percent tensor([0.6561, 0.6649, 0.7114, 0.6604, 0.7247, 0.6765, 0.6990, 0.6870, 0.6603,
        0.6649, 0.6465, 0.6271, 0.6311, 0.6730, 0.6240, 0.6443],
       device='cuda:0') torch.Size([16])
percent tensor([0.9993, 0.9991, 0.9997, 0.9992, 0.9999, 0.9985, 0.9998, 0.9999, 0.9994,
        0.9996, 0.9996, 0.9994, 0.9991, 0.9995, 0.9995, 0.9994],
       device='cuda:0') torch.Size([16])
Epoch: 107 | Batch_idx: 0 |  Loss: (0.1596) |  Loss2: (0.0000) | Acc: (93.00%) (120/128)
Epoch: 107 | Batch_idx: 10 |  Loss: (0.2034) |  Loss2: (0.0000) | Acc: (93.00%) (1310/1408)
Epoch: 107 | Batch_idx: 20 |  Loss: (0.2082) |  Loss2: (0.0000) | Acc: (93.00%) (2502/2688)
Epoch: 107 | Batch_idx: 30 |  Loss: (0.2121) |  Loss2: (0.0000) | Acc: (92.00%) (3683/3968)
Epoch: 107 | Batch_idx: 40 |  Loss: (0.2100) |  Loss2: (0.0000) | Acc: (92.00%) (4880/5248)
Epoch: 107 | Batch_idx: 50 |  Loss: (0.2061) |  Loss2: (0.0000) | Acc: (93.00%) (6084/6528)
Epoch: 107 | Batch_idx: 60 |  Loss: (0.2099) |  Loss2: (0.0000) | Acc: (93.00%) (7265/7808)
Epoch: 107 | Batch_idx: 70 |  Loss: (0.2144) |  Loss2: (0.0000) | Acc: (92.00%) (8430/9088)
Epoch: 107 | Batch_idx: 80 |  Loss: (0.2154) |  Loss2: (0.0000) | Acc: (92.00%) (9613/10368)
Epoch: 107 | Batch_idx: 90 |  Loss: (0.2163) |  Loss2: (0.0000) | Acc: (92.00%) (10794/11648)
Epoch: 107 | Batch_idx: 100 |  Loss: (0.2138) |  Loss2: (0.0000) | Acc: (92.00%) (11993/12928)
Epoch: 107 | Batch_idx: 110 |  Loss: (0.2139) |  Loss2: (0.0000) | Acc: (92.00%) (13175/14208)
Epoch: 107 | Batch_idx: 120 |  Loss: (0.2136) |  Loss2: (0.0000) | Acc: (92.00%) (14367/15488)
Epoch: 107 | Batch_idx: 130 |  Loss: (0.2136) |  Loss2: (0.0000) | Acc: (92.00%) (15556/16768)
Epoch: 107 | Batch_idx: 140 |  Loss: (0.2130) |  Loss2: (0.0000) | Acc: (92.00%) (16742/18048)
Epoch: 107 | Batch_idx: 150 |  Loss: (0.2119) |  Loss2: (0.0000) | Acc: (92.00%) (17932/19328)
Epoch: 107 | Batch_idx: 160 |  Loss: (0.2107) |  Loss2: (0.0000) | Acc: (92.00%) (19134/20608)
Epoch: 107 | Batch_idx: 170 |  Loss: (0.2106) |  Loss2: (0.0000) | Acc: (92.00%) (20327/21888)
Epoch: 107 | Batch_idx: 180 |  Loss: (0.2110) |  Loss2: (0.0000) | Acc: (92.00%) (21509/23168)
Epoch: 107 | Batch_idx: 190 |  Loss: (0.2109) |  Loss2: (0.0000) | Acc: (92.00%) (22698/24448)
Epoch: 107 | Batch_idx: 200 |  Loss: (0.2108) |  Loss2: (0.0000) | Acc: (92.00%) (23875/25728)
Epoch: 107 | Batch_idx: 210 |  Loss: (0.2107) |  Loss2: (0.0000) | Acc: (92.00%) (25062/27008)
Epoch: 107 | Batch_idx: 220 |  Loss: (0.2106) |  Loss2: (0.0000) | Acc: (92.00%) (26250/28288)
Epoch: 107 | Batch_idx: 230 |  Loss: (0.2089) |  Loss2: (0.0000) | Acc: (92.00%) (27464/29568)
Epoch: 107 | Batch_idx: 240 |  Loss: (0.2084) |  Loss2: (0.0000) | Acc: (92.00%) (28667/30848)
Epoch: 107 | Batch_idx: 250 |  Loss: (0.2085) |  Loss2: (0.0000) | Acc: (92.00%) (29865/32128)
Epoch: 107 | Batch_idx: 260 |  Loss: (0.2082) |  Loss2: (0.0000) | Acc: (92.00%) (31058/33408)
Epoch: 107 | Batch_idx: 270 |  Loss: (0.2073) |  Loss2: (0.0000) | Acc: (93.00%) (32266/34688)
Epoch: 107 | Batch_idx: 280 |  Loss: (0.2081) |  Loss2: (0.0000) | Acc: (92.00%) (33449/35968)
Epoch: 107 | Batch_idx: 290 |  Loss: (0.2089) |  Loss2: (0.0000) | Acc: (92.00%) (34625/37248)
Epoch: 107 | Batch_idx: 300 |  Loss: (0.2084) |  Loss2: (0.0000) | Acc: (92.00%) (35826/38528)
Epoch: 107 | Batch_idx: 310 |  Loss: (0.2090) |  Loss2: (0.0000) | Acc: (92.00%) (37004/39808)
Epoch: 107 | Batch_idx: 320 |  Loss: (0.2085) |  Loss2: (0.0000) | Acc: (92.00%) (38196/41088)
Epoch: 107 | Batch_idx: 330 |  Loss: (0.2081) |  Loss2: (0.0000) | Acc: (92.00%) (39386/42368)
Epoch: 107 | Batch_idx: 340 |  Loss: (0.2083) |  Loss2: (0.0000) | Acc: (92.00%) (40563/43648)
Epoch: 107 | Batch_idx: 350 |  Loss: (0.2083) |  Loss2: (0.0000) | Acc: (92.00%) (41747/44928)
Epoch: 107 | Batch_idx: 360 |  Loss: (0.2092) |  Loss2: (0.0000) | Acc: (92.00%) (42925/46208)
Epoch: 107 | Batch_idx: 370 |  Loss: (0.2092) |  Loss2: (0.0000) | Acc: (92.00%) (44109/47488)
Epoch: 107 | Batch_idx: 380 |  Loss: (0.2096) |  Loss2: (0.0000) | Acc: (92.00%) (45291/48768)
Epoch: 107 | Batch_idx: 390 |  Loss: (0.2097) |  Loss2: (0.0000) | Acc: (92.00%) (46424/50000)
# TEST : Loss: (0.4046) | Acc: (87.00%) (8752/10000)
percent tensor([0.5468, 0.5565, 0.5750, 0.5656, 0.5774, 0.5504, 0.5641, 0.5718, 0.5557,
        0.5602, 0.5464, 0.5694, 0.5496, 0.5543, 0.5552, 0.5487],
       device='cuda:0') torch.Size([16])
percent tensor([0.5683, 0.5722, 0.5593, 0.5550, 0.5660, 0.5730, 0.5753, 0.5657, 0.5658,
        0.5645, 0.5699, 0.5675, 0.5667, 0.5677, 0.5779, 0.5673],
       device='cuda:0') torch.Size([16])
percent tensor([0.5892, 0.5905, 0.5569, 0.5440, 0.5512, 0.5749, 0.5839, 0.5590, 0.5791,
        0.5853, 0.5845, 0.5737, 0.6040, 0.5826, 0.5888, 0.5906],
       device='cuda:0') torch.Size([16])
percent tensor([0.6535, 0.6509, 0.6190, 0.6148, 0.6294, 0.6624, 0.6538, 0.6196, 0.6414,
        0.6518, 0.6576, 0.6367, 0.6492, 0.6501, 0.6571, 0.6543],
       device='cuda:0') torch.Size([16])
percent tensor([0.5015, 0.4892, 0.5571, 0.5672, 0.5810, 0.4922, 0.5282, 0.5995, 0.5396,
        0.4850, 0.5013, 0.5195, 0.4306, 0.5731, 0.5459, 0.4930],
       device='cuda:0') torch.Size([16])
percent tensor([0.5619, 0.6340, 0.6348, 0.6384, 0.6661, 0.6860, 0.6230, 0.5759, 0.6506,
        0.5793, 0.6547, 0.6135, 0.5969, 0.6703, 0.5363, 0.5676],
       device='cuda:0') torch.Size([16])
percent tensor([0.6574, 0.6690, 0.7153, 0.6635, 0.7305, 0.6830, 0.7006, 0.6865, 0.6610,
        0.6695, 0.6469, 0.6282, 0.6347, 0.6751, 0.6222, 0.6494],
       device='cuda:0') torch.Size([16])
percent tensor([0.9993, 0.9992, 0.9997, 0.9992, 0.9999, 0.9984, 0.9998, 0.9999, 0.9994,
        0.9995, 0.9996, 0.9994, 0.9991, 0.9995, 0.9995, 0.9994],
       device='cuda:0') torch.Size([16])
Epoch: 108 | Batch_idx: 0 |  Loss: (0.2910) |  Loss2: (0.0000) | Acc: (89.00%) (115/128)
Epoch: 108 | Batch_idx: 10 |  Loss: (0.2103) |  Loss2: (0.0000) | Acc: (92.00%) (1309/1408)
Epoch: 108 | Batch_idx: 20 |  Loss: (0.2074) |  Loss2: (0.0000) | Acc: (92.00%) (2495/2688)
Epoch: 108 | Batch_idx: 30 |  Loss: (0.2036) |  Loss2: (0.0000) | Acc: (93.00%) (3693/3968)
Epoch: 108 | Batch_idx: 40 |  Loss: (0.2027) |  Loss2: (0.0000) | Acc: (93.00%) (4887/5248)
Epoch: 108 | Batch_idx: 50 |  Loss: (0.2000) |  Loss2: (0.0000) | Acc: (93.00%) (6085/6528)
Epoch: 108 | Batch_idx: 60 |  Loss: (0.1976) |  Loss2: (0.0000) | Acc: (93.00%) (7289/7808)
Epoch: 108 | Batch_idx: 70 |  Loss: (0.1968) |  Loss2: (0.0000) | Acc: (93.00%) (8492/9088)
Epoch: 108 | Batch_idx: 80 |  Loss: (0.1988) |  Loss2: (0.0000) | Acc: (93.00%) (9678/10368)
Epoch: 108 | Batch_idx: 90 |  Loss: (0.1974) |  Loss2: (0.0000) | Acc: (93.00%) (10872/11648)
Epoch: 108 | Batch_idx: 100 |  Loss: (0.1983) |  Loss2: (0.0000) | Acc: (93.00%) (12067/12928)
Epoch: 108 | Batch_idx: 110 |  Loss: (0.1957) |  Loss2: (0.0000) | Acc: (93.00%) (13270/14208)
Epoch: 108 | Batch_idx: 120 |  Loss: (0.1957) |  Loss2: (0.0000) | Acc: (93.00%) (14466/15488)
Epoch: 108 | Batch_idx: 130 |  Loss: (0.1961) |  Loss2: (0.0000) | Acc: (93.00%) (15657/16768)
Epoch: 108 | Batch_idx: 140 |  Loss: (0.1970) |  Loss2: (0.0000) | Acc: (93.00%) (16845/18048)
Epoch: 108 | Batch_idx: 150 |  Loss: (0.1990) |  Loss2: (0.0000) | Acc: (93.00%) (18024/19328)
Epoch: 108 | Batch_idx: 160 |  Loss: (0.2002) |  Loss2: (0.0000) | Acc: (93.00%) (19210/20608)
Epoch: 108 | Batch_idx: 170 |  Loss: (0.2000) |  Loss2: (0.0000) | Acc: (93.00%) (20403/21888)
Epoch: 108 | Batch_idx: 180 |  Loss: (0.2001) |  Loss2: (0.0000) | Acc: (93.00%) (21591/23168)
Epoch: 108 | Batch_idx: 190 |  Loss: (0.1985) |  Loss2: (0.0000) | Acc: (93.00%) (22798/24448)
Epoch: 108 | Batch_idx: 200 |  Loss: (0.1992) |  Loss2: (0.0000) | Acc: (93.00%) (23981/25728)
Epoch: 108 | Batch_idx: 210 |  Loss: (0.1996) |  Loss2: (0.0000) | Acc: (93.00%) (25170/27008)
Epoch: 108 | Batch_idx: 220 |  Loss: (0.2003) |  Loss2: (0.0000) | Acc: (93.00%) (26363/28288)
Epoch: 108 | Batch_idx: 230 |  Loss: (0.2010) |  Loss2: (0.0000) | Acc: (93.00%) (27547/29568)
Epoch: 108 | Batch_idx: 240 |  Loss: (0.2029) |  Loss2: (0.0000) | Acc: (93.00%) (28715/30848)
Epoch: 108 | Batch_idx: 250 |  Loss: (0.2020) |  Loss2: (0.0000) | Acc: (93.00%) (29916/32128)
Epoch: 108 | Batch_idx: 260 |  Loss: (0.2027) |  Loss2: (0.0000) | Acc: (93.00%) (31098/33408)
Epoch: 108 | Batch_idx: 270 |  Loss: (0.2024) |  Loss2: (0.0000) | Acc: (93.00%) (32295/34688)
Epoch: 108 | Batch_idx: 280 |  Loss: (0.2024) |  Loss2: (0.0000) | Acc: (93.00%) (33483/35968)
Epoch: 108 | Batch_idx: 290 |  Loss: (0.2025) |  Loss2: (0.0000) | Acc: (93.00%) (34672/37248)
Epoch: 108 | Batch_idx: 300 |  Loss: (0.2011) |  Loss2: (0.0000) | Acc: (93.00%) (35887/38528)
Epoch: 108 | Batch_idx: 310 |  Loss: (0.2012) |  Loss2: (0.0000) | Acc: (93.00%) (37079/39808)
Epoch: 108 | Batch_idx: 320 |  Loss: (0.2011) |  Loss2: (0.0000) | Acc: (93.00%) (38271/41088)
Epoch: 108 | Batch_idx: 330 |  Loss: (0.2009) |  Loss2: (0.0000) | Acc: (93.00%) (39462/42368)
Epoch: 108 | Batch_idx: 340 |  Loss: (0.2013) |  Loss2: (0.0000) | Acc: (93.00%) (40657/43648)
Epoch: 108 | Batch_idx: 350 |  Loss: (0.2015) |  Loss2: (0.0000) | Acc: (93.00%) (41844/44928)
Epoch: 108 | Batch_idx: 360 |  Loss: (0.2017) |  Loss2: (0.0000) | Acc: (93.00%) (43022/46208)
Epoch: 108 | Batch_idx: 370 |  Loss: (0.2017) |  Loss2: (0.0000) | Acc: (93.00%) (44207/47488)
Epoch: 108 | Batch_idx: 380 |  Loss: (0.2020) |  Loss2: (0.0000) | Acc: (93.00%) (45394/48768)
Epoch: 108 | Batch_idx: 390 |  Loss: (0.2017) |  Loss2: (0.0000) | Acc: (93.00%) (46537/50000)
# TEST : Loss: (0.3979) | Acc: (87.00%) (8773/10000)
percent tensor([0.5475, 0.5575, 0.5762, 0.5662, 0.5785, 0.5510, 0.5652, 0.5727, 0.5567,
        0.5613, 0.5473, 0.5705, 0.5504, 0.5551, 0.5559, 0.5493],
       device='cuda:0') torch.Size([16])
percent tensor([0.5686, 0.5724, 0.5593, 0.5546, 0.5657, 0.5728, 0.5753, 0.5655, 0.5660,
        0.5647, 0.5703, 0.5677, 0.5671, 0.5677, 0.5779, 0.5673],
       device='cuda:0') torch.Size([16])
percent tensor([0.5932, 0.5948, 0.5606, 0.5468, 0.5537, 0.5781, 0.5876, 0.5619, 0.5831,
        0.5898, 0.5888, 0.5782, 0.6092, 0.5861, 0.5924, 0.5944],
       device='cuda:0') torch.Size([16])
percent tensor([0.6526, 0.6506, 0.6175, 0.6142, 0.6279, 0.6617, 0.6526, 0.6186, 0.6401,
        0.6510, 0.6567, 0.6354, 0.6490, 0.6489, 0.6562, 0.6536],
       device='cuda:0') torch.Size([16])
percent tensor([0.5124, 0.4975, 0.5661, 0.5763, 0.5871, 0.4973, 0.5367, 0.6084, 0.5516,
        0.4956, 0.5146, 0.5309, 0.4408, 0.5825, 0.5575, 0.4976],
       device='cuda:0') torch.Size([16])
percent tensor([0.5592, 0.6284, 0.6343, 0.6368, 0.6668, 0.6881, 0.6194, 0.5748, 0.6466,
        0.5757, 0.6492, 0.6094, 0.5929, 0.6672, 0.5265, 0.5659],
       device='cuda:0') torch.Size([16])
percent tensor([0.6547, 0.6647, 0.7174, 0.6649, 0.7357, 0.6882, 0.6974, 0.6866, 0.6571,
        0.6690, 0.6407, 0.6254, 0.6328, 0.6708, 0.6165, 0.6508],
       device='cuda:0') torch.Size([16])
percent tensor([0.9993, 0.9992, 0.9997, 0.9992, 0.9999, 0.9983, 0.9998, 0.9999, 0.9994,
        0.9996, 0.9996, 0.9994, 0.9991, 0.9996, 0.9995, 0.9994],
       device='cuda:0') torch.Size([16])
Epoch: 109 | Batch_idx: 0 |  Loss: (0.2086) |  Loss2: (0.0000) | Acc: (95.00%) (122/128)
Epoch: 109 | Batch_idx: 10 |  Loss: (0.2117) |  Loss2: (0.0000) | Acc: (92.00%) (1298/1408)
Epoch: 109 | Batch_idx: 20 |  Loss: (0.2140) |  Loss2: (0.0000) | Acc: (92.00%) (2479/2688)
Epoch: 109 | Batch_idx: 30 |  Loss: (0.2011) |  Loss2: (0.0000) | Acc: (92.00%) (3688/3968)
Epoch: 109 | Batch_idx: 40 |  Loss: (0.2042) |  Loss2: (0.0000) | Acc: (92.00%) (4873/5248)
Epoch: 109 | Batch_idx: 50 |  Loss: (0.2094) |  Loss2: (0.0000) | Acc: (92.00%) (6051/6528)
Epoch: 109 | Batch_idx: 60 |  Loss: (0.2076) |  Loss2: (0.0000) | Acc: (92.00%) (7246/7808)
Epoch: 109 | Batch_idx: 70 |  Loss: (0.2064) |  Loss2: (0.0000) | Acc: (92.00%) (8443/9088)
Epoch: 109 | Batch_idx: 80 |  Loss: (0.2042) |  Loss2: (0.0000) | Acc: (92.00%) (9628/10368)
Epoch: 109 | Batch_idx: 90 |  Loss: (0.2038) |  Loss2: (0.0000) | Acc: (92.00%) (10825/11648)
Epoch: 109 | Batch_idx: 100 |  Loss: (0.2054) |  Loss2: (0.0000) | Acc: (92.00%) (12006/12928)
Epoch: 109 | Batch_idx: 110 |  Loss: (0.2050) |  Loss2: (0.0000) | Acc: (92.00%) (13203/14208)
Epoch: 109 | Batch_idx: 120 |  Loss: (0.2030) |  Loss2: (0.0000) | Acc: (93.00%) (14408/15488)
Epoch: 109 | Batch_idx: 130 |  Loss: (0.2036) |  Loss2: (0.0000) | Acc: (92.00%) (15591/16768)
Epoch: 109 | Batch_idx: 140 |  Loss: (0.2037) |  Loss2: (0.0000) | Acc: (93.00%) (16786/18048)
Epoch: 109 | Batch_idx: 150 |  Loss: (0.2040) |  Loss2: (0.0000) | Acc: (92.00%) (17968/19328)
Epoch: 109 | Batch_idx: 160 |  Loss: (0.2045) |  Loss2: (0.0000) | Acc: (92.00%) (19144/20608)
Epoch: 109 | Batch_idx: 170 |  Loss: (0.2044) |  Loss2: (0.0000) | Acc: (92.00%) (20328/21888)
Epoch: 109 | Batch_idx: 180 |  Loss: (0.2047) |  Loss2: (0.0000) | Acc: (92.00%) (21521/23168)
Epoch: 109 | Batch_idx: 190 |  Loss: (0.2034) |  Loss2: (0.0000) | Acc: (92.00%) (22727/24448)
Epoch: 109 | Batch_idx: 200 |  Loss: (0.2033) |  Loss2: (0.0000) | Acc: (92.00%) (23920/25728)
Epoch: 109 | Batch_idx: 210 |  Loss: (0.2030) |  Loss2: (0.0000) | Acc: (93.00%) (25118/27008)
Epoch: 109 | Batch_idx: 220 |  Loss: (0.2020) |  Loss2: (0.0000) | Acc: (93.00%) (26320/28288)
Epoch: 109 | Batch_idx: 230 |  Loss: (0.2019) |  Loss2: (0.0000) | Acc: (93.00%) (27505/29568)
Epoch: 109 | Batch_idx: 240 |  Loss: (0.2012) |  Loss2: (0.0000) | Acc: (93.00%) (28704/30848)
Epoch: 109 | Batch_idx: 250 |  Loss: (0.2016) |  Loss2: (0.0000) | Acc: (93.00%) (29880/32128)
Epoch: 109 | Batch_idx: 260 |  Loss: (0.2022) |  Loss2: (0.0000) | Acc: (92.00%) (31058/33408)
Epoch: 109 | Batch_idx: 270 |  Loss: (0.2022) |  Loss2: (0.0000) | Acc: (92.00%) (32252/34688)
Epoch: 109 | Batch_idx: 280 |  Loss: (0.2016) |  Loss2: (0.0000) | Acc: (92.00%) (33446/35968)
Epoch: 109 | Batch_idx: 290 |  Loss: (0.2006) |  Loss2: (0.0000) | Acc: (93.00%) (34653/37248)
Epoch: 109 | Batch_idx: 300 |  Loss: (0.2007) |  Loss2: (0.0000) | Acc: (93.00%) (35838/38528)
Epoch: 109 | Batch_idx: 310 |  Loss: (0.2004) |  Loss2: (0.0000) | Acc: (93.00%) (37043/39808)
Epoch: 109 | Batch_idx: 320 |  Loss: (0.2000) |  Loss2: (0.0000) | Acc: (93.00%) (38244/41088)
Epoch: 109 | Batch_idx: 330 |  Loss: (0.1997) |  Loss2: (0.0000) | Acc: (93.00%) (39443/42368)
Epoch: 109 | Batch_idx: 340 |  Loss: (0.1998) |  Loss2: (0.0000) | Acc: (93.00%) (40640/43648)
Epoch: 109 | Batch_idx: 350 |  Loss: (0.1990) |  Loss2: (0.0000) | Acc: (93.00%) (41850/44928)
Epoch: 109 | Batch_idx: 360 |  Loss: (0.1989) |  Loss2: (0.0000) | Acc: (93.00%) (43043/46208)
Epoch: 109 | Batch_idx: 370 |  Loss: (0.1980) |  Loss2: (0.0000) | Acc: (93.00%) (44258/47488)
Epoch: 109 | Batch_idx: 380 |  Loss: (0.1976) |  Loss2: (0.0000) | Acc: (93.00%) (45465/48768)
Epoch: 109 | Batch_idx: 390 |  Loss: (0.1981) |  Loss2: (0.0000) | Acc: (93.00%) (46611/50000)
# TEST : Loss: (0.3958) | Acc: (87.00%) (8778/10000)
percent tensor([0.5487, 0.5584, 0.5778, 0.5673, 0.5800, 0.5522, 0.5666, 0.5738, 0.5579,
        0.5624, 0.5483, 0.5721, 0.5514, 0.5560, 0.5569, 0.5503],
       device='cuda:0') torch.Size([16])
percent tensor([0.5700, 0.5738, 0.5607, 0.5559, 0.5672, 0.5740, 0.5769, 0.5670, 0.5675,
        0.5661, 0.5718, 0.5692, 0.5685, 0.5691, 0.5794, 0.5685],
       device='cuda:0') torch.Size([16])
percent tensor([0.5920, 0.5941, 0.5600, 0.5455, 0.5530, 0.5769, 0.5868, 0.5609, 0.5826,
        0.5888, 0.5882, 0.5775, 0.6083, 0.5857, 0.5913, 0.5930],
       device='cuda:0') torch.Size([16])
percent tensor([0.6505, 0.6489, 0.6154, 0.6131, 0.6261, 0.6605, 0.6503, 0.6167, 0.6379,
        0.6486, 0.6542, 0.6327, 0.6470, 0.6467, 0.6543, 0.6518],
       device='cuda:0') torch.Size([16])
percent tensor([0.5051, 0.4911, 0.5607, 0.5706, 0.5821, 0.4906, 0.5277, 0.6018, 0.5443,
        0.4902, 0.5085, 0.5217, 0.4329, 0.5755, 0.5486, 0.4887],
       device='cuda:0') torch.Size([16])
percent tensor([0.5543, 0.6266, 0.6301, 0.6329, 0.6619, 0.6849, 0.6154, 0.5663, 0.6430,
        0.5742, 0.6436, 0.6043, 0.5935, 0.6631, 0.5188, 0.5611],
       device='cuda:0') torch.Size([16])
percent tensor([0.6595, 0.6724, 0.7241, 0.6725, 0.7426, 0.6959, 0.7041, 0.6904, 0.6616,
        0.6772, 0.6435, 0.6287, 0.6378, 0.6764, 0.6176, 0.6574],
       device='cuda:0') torch.Size([16])
percent tensor([0.9992, 0.9992, 0.9997, 0.9993, 0.9999, 0.9983, 0.9998, 0.9999, 0.9994,
        0.9996, 0.9996, 0.9994, 0.9991, 0.9995, 0.9994, 0.9994],
       device='cuda:0') torch.Size([16])
Epoch: 110 | Batch_idx: 0 |  Loss: (0.2077) |  Loss2: (0.0000) | Acc: (91.00%) (117/128)
Epoch: 110 | Batch_idx: 10 |  Loss: (0.1728) |  Loss2: (0.0000) | Acc: (93.00%) (1318/1408)
Epoch: 110 | Batch_idx: 20 |  Loss: (0.1797) |  Loss2: (0.0000) | Acc: (93.00%) (2513/2688)
Epoch: 110 | Batch_idx: 30 |  Loss: (0.1772) |  Loss2: (0.0000) | Acc: (93.00%) (3721/3968)
Epoch: 110 | Batch_idx: 40 |  Loss: (0.1773) |  Loss2: (0.0000) | Acc: (93.00%) (4922/5248)
Epoch: 110 | Batch_idx: 50 |  Loss: (0.1848) |  Loss2: (0.0000) | Acc: (93.00%) (6104/6528)
Epoch: 110 | Batch_idx: 60 |  Loss: (0.1865) |  Loss2: (0.0000) | Acc: (93.00%) (7296/7808)
Epoch: 110 | Batch_idx: 70 |  Loss: (0.1876) |  Loss2: (0.0000) | Acc: (93.00%) (8484/9088)
Epoch: 110 | Batch_idx: 80 |  Loss: (0.1875) |  Loss2: (0.0000) | Acc: (93.00%) (9682/10368)
Epoch: 110 | Batch_idx: 90 |  Loss: (0.1881) |  Loss2: (0.0000) | Acc: (93.00%) (10876/11648)
Epoch: 110 | Batch_idx: 100 |  Loss: (0.1879) |  Loss2: (0.0000) | Acc: (93.00%) (12068/12928)
Epoch: 110 | Batch_idx: 110 |  Loss: (0.1895) |  Loss2: (0.0000) | Acc: (93.00%) (13263/14208)
Epoch: 110 | Batch_idx: 120 |  Loss: (0.1889) |  Loss2: (0.0000) | Acc: (93.00%) (14464/15488)
Epoch: 110 | Batch_idx: 130 |  Loss: (0.1879) |  Loss2: (0.0000) | Acc: (93.00%) (15672/16768)
Epoch: 110 | Batch_idx: 140 |  Loss: (0.1885) |  Loss2: (0.0000) | Acc: (93.00%) (16858/18048)
Epoch: 110 | Batch_idx: 150 |  Loss: (0.1888) |  Loss2: (0.0000) | Acc: (93.00%) (18058/19328)
Epoch: 110 | Batch_idx: 160 |  Loss: (0.1916) |  Loss2: (0.0000) | Acc: (93.00%) (19239/20608)
Epoch: 110 | Batch_idx: 170 |  Loss: (0.1916) |  Loss2: (0.0000) | Acc: (93.00%) (20440/21888)
Epoch: 110 | Batch_idx: 180 |  Loss: (0.1914) |  Loss2: (0.0000) | Acc: (93.00%) (21631/23168)
Epoch: 110 | Batch_idx: 190 |  Loss: (0.1917) |  Loss2: (0.0000) | Acc: (93.00%) (22825/24448)
Epoch: 110 | Batch_idx: 200 |  Loss: (0.1922) |  Loss2: (0.0000) | Acc: (93.00%) (24015/25728)
Epoch: 110 | Batch_idx: 210 |  Loss: (0.1916) |  Loss2: (0.0000) | Acc: (93.00%) (25220/27008)
Epoch: 110 | Batch_idx: 220 |  Loss: (0.1922) |  Loss2: (0.0000) | Acc: (93.00%) (26419/28288)
Epoch: 110 | Batch_idx: 230 |  Loss: (0.1928) |  Loss2: (0.0000) | Acc: (93.00%) (27620/29568)
Epoch: 110 | Batch_idx: 240 |  Loss: (0.1937) |  Loss2: (0.0000) | Acc: (93.00%) (28808/30848)
Epoch: 110 | Batch_idx: 250 |  Loss: (0.1932) |  Loss2: (0.0000) | Acc: (93.00%) (30003/32128)
Epoch: 110 | Batch_idx: 260 |  Loss: (0.1938) |  Loss2: (0.0000) | Acc: (93.00%) (31185/33408)
Epoch: 110 | Batch_idx: 270 |  Loss: (0.1937) |  Loss2: (0.0000) | Acc: (93.00%) (32384/34688)
Epoch: 110 | Batch_idx: 280 |  Loss: (0.1932) |  Loss2: (0.0000) | Acc: (93.00%) (33585/35968)
Epoch: 110 | Batch_idx: 290 |  Loss: (0.1926) |  Loss2: (0.0000) | Acc: (93.00%) (34788/37248)
Epoch: 110 | Batch_idx: 300 |  Loss: (0.1927) |  Loss2: (0.0000) | Acc: (93.00%) (35979/38528)
Epoch: 110 | Batch_idx: 310 |  Loss: (0.1928) |  Loss2: (0.0000) | Acc: (93.00%) (37182/39808)
Epoch: 110 | Batch_idx: 320 |  Loss: (0.1923) |  Loss2: (0.0000) | Acc: (93.00%) (38390/41088)
Epoch: 110 | Batch_idx: 330 |  Loss: (0.1915) |  Loss2: (0.0000) | Acc: (93.00%) (39596/42368)
Epoch: 110 | Batch_idx: 340 |  Loss: (0.1917) |  Loss2: (0.0000) | Acc: (93.00%) (40783/43648)
Epoch: 110 | Batch_idx: 350 |  Loss: (0.1911) |  Loss2: (0.0000) | Acc: (93.00%) (41985/44928)
Epoch: 110 | Batch_idx: 360 |  Loss: (0.1906) |  Loss2: (0.0000) | Acc: (93.00%) (43187/46208)
Epoch: 110 | Batch_idx: 370 |  Loss: (0.1915) |  Loss2: (0.0000) | Acc: (93.00%) (44374/47488)
Epoch: 110 | Batch_idx: 380 |  Loss: (0.1910) |  Loss2: (0.0000) | Acc: (93.00%) (45576/48768)
Epoch: 110 | Batch_idx: 390 |  Loss: (0.1909) |  Loss2: (0.0000) | Acc: (93.00%) (46720/50000)
=> saving checkpoint 'drive/app/torch/save_Schedule/checkpoint_110.pth.tar'
# TEST : Loss: (0.3888) | Acc: (88.00%) (8803/10000)
percent tensor([0.5491, 0.5581, 0.5784, 0.5673, 0.5803, 0.5528, 0.5665, 0.5737, 0.5579,
        0.5623, 0.5483, 0.5723, 0.5514, 0.5555, 0.5569, 0.5504],
       device='cuda:0') torch.Size([16])
percent tensor([0.5716, 0.5753, 0.5618, 0.5568, 0.5683, 0.5757, 0.5783, 0.5681, 0.5689,
        0.5673, 0.5736, 0.5704, 0.5701, 0.5702, 0.5810, 0.5699],
       device='cuda:0') torch.Size([16])
percent tensor([0.5956, 0.5965, 0.5641, 0.5489, 0.5557, 0.5802, 0.5899, 0.5639, 0.5866,
        0.5921, 0.5917, 0.5814, 0.6123, 0.5887, 0.5940, 0.5962],
       device='cuda:0') torch.Size([16])
percent tensor([0.6486, 0.6471, 0.6131, 0.6114, 0.6236, 0.6589, 0.6481, 0.6144, 0.6360,
        0.6464, 0.6525, 0.6301, 0.6454, 0.6451, 0.6521, 0.6499],
       device='cuda:0') torch.Size([16])
percent tensor([0.5169, 0.5000, 0.5705, 0.5798, 0.5892, 0.5019, 0.5364, 0.6087, 0.5564,
        0.5029, 0.5236, 0.5305, 0.4436, 0.5838, 0.5600, 0.4963],
       device='cuda:0') torch.Size([16])
percent tensor([0.5482, 0.6234, 0.6270, 0.6284, 0.6592, 0.6859, 0.6108, 0.5610, 0.6387,
        0.5689, 0.6418, 0.6000, 0.5899, 0.6616, 0.5106, 0.5582],
       device='cuda:0') torch.Size([16])
percent tensor([0.6586, 0.6725, 0.7244, 0.6714, 0.7435, 0.6967, 0.7027, 0.6897, 0.6598,
        0.6788, 0.6409, 0.6259, 0.6380, 0.6762, 0.6149, 0.6590],
       device='cuda:0') torch.Size([16])
percent tensor([0.9993, 0.9992, 0.9997, 0.9992, 0.9999, 0.9986, 0.9998, 0.9999, 0.9995,
        0.9996, 0.9996, 0.9994, 0.9992, 0.9996, 0.9994, 0.9994],
       device='cuda:0') torch.Size([16])
Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 3, 3, 3]) tensor(185.3980, device='cuda:0')
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(809.8487, device='cuda:0')
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(827.2550, device='cuda:0')
Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([128, 64, 3, 3]) tensor(1528.8212, device='cuda:0')
Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([128, 64, 1, 1]) tensor(497.6572, device='cuda:0')
Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([128, 128, 3, 3]) tensor(2242.6729, device='cuda:0')
Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([256, 128, 3, 3]) tensor(4268.6284, device='cuda:0')
Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([256, 128, 1, 1]) tensor(1384.8990, device='cuda:0')
Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([256, 256, 3, 3]) tensor(6142.7285, device='cuda:0')
Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([512, 256, 3, 3]) tensor(11830.8184, device='cuda:0')
Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([512, 256, 1, 1]) tensor(3924.1755, device='cuda:0')
Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([512, 512, 3, 3]) tensor(16576.8633, device='cuda:0')
Epoch: 111 | Batch_idx: 0 |  Loss: (0.1105) |  Loss2: (0.0000) | Acc: (96.00%) (124/128)
Epoch: 111 | Batch_idx: 10 |  Loss: (0.1853) |  Loss2: (0.0000) | Acc: (93.00%) (1322/1408)
Epoch: 111 | Batch_idx: 20 |  Loss: (0.1832) |  Loss2: (0.0000) | Acc: (93.00%) (2525/2688)
Epoch: 111 | Batch_idx: 30 |  Loss: (0.1862) |  Loss2: (0.0000) | Acc: (93.00%) (3715/3968)
Epoch: 111 | Batch_idx: 40 |  Loss: (0.1845) |  Loss2: (0.0000) | Acc: (93.00%) (4910/5248)
Epoch: 111 | Batch_idx: 50 |  Loss: (0.1850) |  Loss2: (0.0000) | Acc: (93.00%) (6111/6528)
Epoch: 111 | Batch_idx: 60 |  Loss: (0.1839) |  Loss2: (0.0000) | Acc: (93.00%) (7316/7808)
Epoch: 111 | Batch_idx: 70 |  Loss: (0.1860) |  Loss2: (0.0000) | Acc: (93.00%) (8511/9088)
Epoch: 111 | Batch_idx: 80 |  Loss: (0.1858) |  Loss2: (0.0000) | Acc: (93.00%) (9712/10368)
Epoch: 111 | Batch_idx: 90 |  Loss: (0.1850) |  Loss2: (0.0000) | Acc: (93.00%) (10918/11648)
Epoch: 111 | Batch_idx: 100 |  Loss: (0.1855) |  Loss2: (0.0000) | Acc: (93.00%) (12115/12928)
Epoch: 111 | Batch_idx: 110 |  Loss: (0.1848) |  Loss2: (0.0000) | Acc: (93.00%) (13322/14208)
Epoch: 111 | Batch_idx: 120 |  Loss: (0.1857) |  Loss2: (0.0000) | Acc: (93.00%) (14510/15488)
Epoch: 111 | Batch_idx: 130 |  Loss: (0.1842) |  Loss2: (0.0000) | Acc: (93.00%) (15721/16768)
Epoch: 111 | Batch_idx: 140 |  Loss: (0.1845) |  Loss2: (0.0000) | Acc: (93.00%) (16912/18048)
Epoch: 111 | Batch_idx: 150 |  Loss: (0.1848) |  Loss2: (0.0000) | Acc: (93.00%) (18104/19328)
Epoch: 111 | Batch_idx: 160 |  Loss: (0.1863) |  Loss2: (0.0000) | Acc: (93.00%) (19297/20608)
Epoch: 111 | Batch_idx: 170 |  Loss: (0.1865) |  Loss2: (0.0000) | Acc: (93.00%) (20494/21888)
Epoch: 111 | Batch_idx: 180 |  Loss: (0.1873) |  Loss2: (0.0000) | Acc: (93.00%) (21688/23168)
Epoch: 111 | Batch_idx: 190 |  Loss: (0.1873) |  Loss2: (0.0000) | Acc: (93.00%) (22899/24448)
Epoch: 111 | Batch_idx: 200 |  Loss: (0.1879) |  Loss2: (0.0000) | Acc: (93.00%) (24089/25728)
Epoch: 111 | Batch_idx: 210 |  Loss: (0.1886) |  Loss2: (0.0000) | Acc: (93.00%) (25283/27008)
Epoch: 111 | Batch_idx: 220 |  Loss: (0.1894) |  Loss2: (0.0000) | Acc: (93.00%) (26467/28288)
Epoch: 111 | Batch_idx: 230 |  Loss: (0.1900) |  Loss2: (0.0000) | Acc: (93.00%) (27662/29568)
Epoch: 111 | Batch_idx: 240 |  Loss: (0.1903) |  Loss2: (0.0000) | Acc: (93.00%) (28863/30848)
Epoch: 111 | Batch_idx: 250 |  Loss: (0.1909) |  Loss2: (0.0000) | Acc: (93.00%) (30050/32128)
Epoch: 111 | Batch_idx: 260 |  Loss: (0.1895) |  Loss2: (0.0000) | Acc: (93.00%) (31268/33408)
Epoch: 111 | Batch_idx: 270 |  Loss: (0.1891) |  Loss2: (0.0000) | Acc: (93.00%) (32474/34688)
Epoch: 111 | Batch_idx: 280 |  Loss: (0.1897) |  Loss2: (0.0000) | Acc: (93.00%) (33668/35968)
Epoch: 111 | Batch_idx: 290 |  Loss: (0.1897) |  Loss2: (0.0000) | Acc: (93.00%) (34865/37248)
Epoch: 111 | Batch_idx: 300 |  Loss: (0.1890) |  Loss2: (0.0000) | Acc: (93.00%) (36076/38528)
Epoch: 111 | Batch_idx: 310 |  Loss: (0.1892) |  Loss2: (0.0000) | Acc: (93.00%) (37273/39808)
Epoch: 111 | Batch_idx: 320 |  Loss: (0.1897) |  Loss2: (0.0000) | Acc: (93.00%) (38466/41088)
Epoch: 111 | Batch_idx: 330 |  Loss: (0.1899) |  Loss2: (0.0000) | Acc: (93.00%) (39656/42368)
Epoch: 111 | Batch_idx: 340 |  Loss: (0.1907) |  Loss2: (0.0000) | Acc: (93.00%) (40844/43648)
Epoch: 111 | Batch_idx: 350 |  Loss: (0.1905) |  Loss2: (0.0000) | Acc: (93.00%) (42048/44928)
Epoch: 111 | Batch_idx: 360 |  Loss: (0.1902) |  Loss2: (0.0000) | Acc: (93.00%) (43245/46208)
Epoch: 111 | Batch_idx: 370 |  Loss: (0.1902) |  Loss2: (0.0000) | Acc: (93.00%) (44439/47488)
Epoch: 111 | Batch_idx: 380 |  Loss: (0.1896) |  Loss2: (0.0000) | Acc: (93.00%) (45650/48768)
Epoch: 111 | Batch_idx: 390 |  Loss: (0.1893) |  Loss2: (0.0000) | Acc: (93.00%) (46812/50000)
# TEST : Loss: (0.3854) | Acc: (88.00%) (8816/10000)
percent tensor([0.5499, 0.5588, 0.5790, 0.5674, 0.5811, 0.5535, 0.5674, 0.5742, 0.5589,
        0.5630, 0.5492, 0.5729, 0.5521, 0.5563, 0.5574, 0.5510],
       device='cuda:0') torch.Size([16])
percent tensor([0.5720, 0.5757, 0.5621, 0.5567, 0.5685, 0.5758, 0.5787, 0.5682, 0.5692,
        0.5677, 0.5740, 0.5709, 0.5704, 0.5705, 0.5814, 0.5702],
       device='cuda:0') torch.Size([16])
percent tensor([0.5971, 0.5975, 0.5668, 0.5522, 0.5578, 0.5830, 0.5907, 0.5652, 0.5879,
        0.5936, 0.5927, 0.5833, 0.6135, 0.5891, 0.5953, 0.5982],
       device='cuda:0') torch.Size([16])
percent tensor([0.6487, 0.6471, 0.6129, 0.6111, 0.6230, 0.6596, 0.6474, 0.6137, 0.6352,
        0.6461, 0.6517, 0.6296, 0.6457, 0.6444, 0.6523, 0.6501],
       device='cuda:0') torch.Size([16])
percent tensor([0.5245, 0.5074, 0.5742, 0.5825, 0.5930, 0.5101, 0.5432, 0.6109, 0.5625,
        0.5110, 0.5327, 0.5325, 0.4494, 0.5898, 0.5669, 0.5016],
       device='cuda:0') torch.Size([16])
percent tensor([0.5571, 0.6312, 0.6323, 0.6335, 0.6650, 0.6952, 0.6163, 0.5653, 0.6455,
        0.5742, 0.6472, 0.6044, 0.6002, 0.6692, 0.5136, 0.5672],
       device='cuda:0') torch.Size([16])
percent tensor([0.6582, 0.6720, 0.7235, 0.6696, 0.7417, 0.7004, 0.7004, 0.6847, 0.6591,
        0.6797, 0.6400, 0.6226, 0.6393, 0.6778, 0.6105, 0.6600],
       device='cuda:0') torch.Size([16])
percent tensor([0.9993, 0.9992, 0.9997, 0.9992, 0.9999, 0.9986, 0.9998, 0.9999, 0.9995,
        0.9997, 0.9997, 0.9993, 0.9993, 0.9996, 0.9995, 0.9994],
       device='cuda:0') torch.Size([16])
True Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=128, out_features=16, bias=False)
False Linear(in_features=16, out_features=2, bias=False)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=128, out_features=16, bias=False)
False Linear(in_features=16, out_features=2, bias=False)
True Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=256, out_features=32, bias=False)
False Linear(in_features=32, out_features=2, bias=False)
True Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=256, out_features=32, bias=False)
False Linear(in_features=32, out_features=2, bias=False)
True Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=512, out_features=64, bias=False)
False Linear(in_features=64, out_features=2, bias=False)
True Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=512, out_features=64, bias=False)
False Linear(in_features=64, out_features=2, bias=False)
True Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1024, out_features=128, bias=False)
False Linear(in_features=128, out_features=2, bias=False)
True Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1024, out_features=128, bias=False)
False Linear(in_features=128, out_features=2, bias=False)
True Linear(in_features=512, out_features=10, bias=True)
Epoch: 112 | Batch_idx: 0 |  Loss: (0.1633) |  Loss2: (0.0000) | Acc: (94.00%) (121/128)
Epoch: 112 | Batch_idx: 10 |  Loss: (0.1752) |  Loss2: (0.0000) | Acc: (94.00%) (1326/1408)
Epoch: 112 | Batch_idx: 20 |  Loss: (0.1886) |  Loss2: (0.0000) | Acc: (93.00%) (2513/2688)
Epoch: 112 | Batch_idx: 30 |  Loss: (0.1927) |  Loss2: (0.0000) | Acc: (93.00%) (3709/3968)
Epoch: 112 | Batch_idx: 40 |  Loss: (0.2017) |  Loss2: (0.0000) | Acc: (93.00%) (4881/5248)
Epoch: 112 | Batch_idx: 50 |  Loss: (0.2027) |  Loss2: (0.0000) | Acc: (92.00%) (6068/6528)
Epoch: 112 | Batch_idx: 60 |  Loss: (0.2028) |  Loss2: (0.0000) | Acc: (92.00%) (7259/7808)
Epoch: 112 | Batch_idx: 70 |  Loss: (0.2050) |  Loss2: (0.0000) | Acc: (92.00%) (8449/9088)
Epoch: 112 | Batch_idx: 80 |  Loss: (0.2023) |  Loss2: (0.0000) | Acc: (92.00%) (9642/10368)
Epoch: 112 | Batch_idx: 90 |  Loss: (0.1990) |  Loss2: (0.0000) | Acc: (93.00%) (10860/11648)
Epoch: 112 | Batch_idx: 100 |  Loss: (0.1967) |  Loss2: (0.0000) | Acc: (93.00%) (12062/12928)
Epoch: 112 | Batch_idx: 110 |  Loss: (0.1975) |  Loss2: (0.0000) | Acc: (93.00%) (13245/14208)
Epoch: 112 | Batch_idx: 120 |  Loss: (0.1996) |  Loss2: (0.0000) | Acc: (93.00%) (14425/15488)
Epoch: 112 | Batch_idx: 130 |  Loss: (0.2010) |  Loss2: (0.0000) | Acc: (93.00%) (15607/16768)
Epoch: 112 | Batch_idx: 140 |  Loss: (0.2016) |  Loss2: (0.0000) | Acc: (93.00%) (16792/18048)
Epoch: 112 | Batch_idx: 150 |  Loss: (0.2022) |  Loss2: (0.0000) | Acc: (93.00%) (17987/19328)
Epoch: 112 | Batch_idx: 160 |  Loss: (0.2027) |  Loss2: (0.0000) | Acc: (93.00%) (19172/20608)
Epoch: 112 | Batch_idx: 170 |  Loss: (0.2012) |  Loss2: (0.0000) | Acc: (93.00%) (20368/21888)
Epoch: 112 | Batch_idx: 180 |  Loss: (0.1997) |  Loss2: (0.0000) | Acc: (93.00%) (21577/23168)
Epoch: 112 | Batch_idx: 190 |  Loss: (0.2001) |  Loss2: (0.0000) | Acc: (93.00%) (22771/24448)
Epoch: 112 | Batch_idx: 200 |  Loss: (0.1997) |  Loss2: (0.0000) | Acc: (93.00%) (23975/25728)
Epoch: 112 | Batch_idx: 210 |  Loss: (0.2001) |  Loss2: (0.0000) | Acc: (93.00%) (25168/27008)
Epoch: 112 | Batch_idx: 220 |  Loss: (0.1993) |  Loss2: (0.0000) | Acc: (93.00%) (26375/28288)
Epoch: 112 | Batch_idx: 230 |  Loss: (0.1995) |  Loss2: (0.0000) | Acc: (93.00%) (27561/29568)
Epoch: 112 | Batch_idx: 240 |  Loss: (0.1995) |  Loss2: (0.0000) | Acc: (93.00%) (28745/30848)
Epoch: 112 | Batch_idx: 250 |  Loss: (0.1997) |  Loss2: (0.0000) | Acc: (93.00%) (29925/32128)
Epoch: 112 | Batch_idx: 260 |  Loss: (0.1997) |  Loss2: (0.0000) | Acc: (93.00%) (31116/33408)
Epoch: 112 | Batch_idx: 270 |  Loss: (0.2005) |  Loss2: (0.0000) | Acc: (93.00%) (32305/34688)
Epoch: 112 | Batch_idx: 280 |  Loss: (0.2003) |  Loss2: (0.0000) | Acc: (93.00%) (33497/35968)
Epoch: 112 | Batch_idx: 290 |  Loss: (0.2011) |  Loss2: (0.0000) | Acc: (93.00%) (34681/37248)
Epoch: 112 | Batch_idx: 300 |  Loss: (0.2017) |  Loss2: (0.0000) | Acc: (93.00%) (35854/38528)
Epoch: 112 | Batch_idx: 310 |  Loss: (0.2016) |  Loss2: (0.0000) | Acc: (93.00%) (37048/39808)
Epoch: 112 | Batch_idx: 320 |  Loss: (0.2018) |  Loss2: (0.0000) | Acc: (93.00%) (38236/41088)
Epoch: 112 | Batch_idx: 330 |  Loss: (0.2015) |  Loss2: (0.0000) | Acc: (93.00%) (39434/42368)
Epoch: 112 | Batch_idx: 340 |  Loss: (0.2018) |  Loss2: (0.0000) | Acc: (93.00%) (40619/43648)
Epoch: 112 | Batch_idx: 350 |  Loss: (0.2027) |  Loss2: (0.0000) | Acc: (93.00%) (41787/44928)
Epoch: 112 | Batch_idx: 360 |  Loss: (0.2032) |  Loss2: (0.0000) | Acc: (92.00%) (42965/46208)
Epoch: 112 | Batch_idx: 370 |  Loss: (0.2037) |  Loss2: (0.0000) | Acc: (92.00%) (44149/47488)
Epoch: 112 | Batch_idx: 380 |  Loss: (0.2043) |  Loss2: (0.0000) | Acc: (92.00%) (45319/48768)
Epoch: 112 | Batch_idx: 390 |  Loss: (0.2040) |  Loss2: (0.0000) | Acc: (92.00%) (46478/50000)
# TEST : Loss: (0.4435) | Acc: (86.00%) (8638/10000)
percent tensor([0.5484, 0.5602, 0.5736, 0.5651, 0.5756, 0.5530, 0.5665, 0.5718, 0.5576,
        0.5615, 0.5486, 0.5691, 0.5500, 0.5613, 0.5574, 0.5513],
       device='cuda:0') torch.Size([16])
percent tensor([0.5715, 0.5737, 0.5633, 0.5571, 0.5710, 0.5765, 0.5788, 0.5694, 0.5692,
        0.5671, 0.5724, 0.5728, 0.5709, 0.5688, 0.5796, 0.5708],
       device='cuda:0') torch.Size([16])
percent tensor([0.5972, 0.5964, 0.5704, 0.5526, 0.5580, 0.5828, 0.5892, 0.5614, 0.5865,
        0.5917, 0.5908, 0.5858, 0.6128, 0.5881, 0.5955, 0.5963],
       device='cuda:0') torch.Size([16])
percent tensor([0.6443, 0.6411, 0.6085, 0.6089, 0.6200, 0.6571, 0.6453, 0.6125, 0.6320,
        0.6411, 0.6454, 0.6254, 0.6418, 0.6412, 0.6477, 0.6486],
       device='cuda:0') torch.Size([16])
percent tensor([0.5302, 0.5152, 0.5795, 0.5913, 0.5973, 0.5274, 0.5446, 0.6091, 0.5749,
        0.5254, 0.5468, 0.5476, 0.4576, 0.5982, 0.5682, 0.5166],
       device='cuda:0') torch.Size([16])
percent tensor([0.5326, 0.5927, 0.6326, 0.6191, 0.6622, 0.6745, 0.5953, 0.5467, 0.6396,
        0.5482, 0.6359, 0.5888, 0.5874, 0.6511, 0.4766, 0.5389],
       device='cuda:0') torch.Size([16])
percent tensor([0.6669, 0.6637, 0.7158, 0.6596, 0.7388, 0.7032, 0.7025, 0.6809, 0.6760,
        0.6717, 0.6537, 0.6318, 0.6430, 0.6990, 0.6131, 0.6497],
       device='cuda:0') torch.Size([16])
percent tensor([0.9996, 0.9995, 0.9997, 0.9993, 0.9999, 0.9994, 0.9999, 0.9999, 0.9998,
        0.9998, 0.9997, 0.9995, 0.9992, 0.9998, 0.9995, 0.9994],
       device='cuda:0') torch.Size([16])
Epoch: 113 | Batch_idx: 0 |  Loss: (0.3248) |  Loss2: (0.0000) | Acc: (90.00%) (116/128)
Epoch: 113 | Batch_idx: 10 |  Loss: (0.2226) |  Loss2: (0.0000) | Acc: (92.00%) (1302/1408)
Epoch: 113 | Batch_idx: 20 |  Loss: (0.1972) |  Loss2: (0.0000) | Acc: (93.00%) (2507/2688)
Epoch: 113 | Batch_idx: 30 |  Loss: (0.1962) |  Loss2: (0.0000) | Acc: (93.00%) (3701/3968)
Epoch: 113 | Batch_idx: 40 |  Loss: (0.1962) |  Loss2: (0.0000) | Acc: (93.00%) (4893/5248)
Epoch: 113 | Batch_idx: 50 |  Loss: (0.1932) |  Loss2: (0.0000) | Acc: (93.00%) (6097/6528)
Epoch: 113 | Batch_idx: 60 |  Loss: (0.1962) |  Loss2: (0.0000) | Acc: (93.00%) (7289/7808)
Epoch: 113 | Batch_idx: 70 |  Loss: (0.1965) |  Loss2: (0.0000) | Acc: (93.00%) (8470/9088)
Epoch: 113 | Batch_idx: 80 |  Loss: (0.1972) |  Loss2: (0.0000) | Acc: (93.00%) (9657/10368)
Epoch: 113 | Batch_idx: 90 |  Loss: (0.1966) |  Loss2: (0.0000) | Acc: (93.00%) (10856/11648)
Epoch: 113 | Batch_idx: 100 |  Loss: (0.1959) |  Loss2: (0.0000) | Acc: (93.00%) (12051/12928)
Epoch: 113 | Batch_idx: 110 |  Loss: (0.1942) |  Loss2: (0.0000) | Acc: (93.00%) (13247/14208)
Epoch: 113 | Batch_idx: 120 |  Loss: (0.1952) |  Loss2: (0.0000) | Acc: (93.00%) (14438/15488)
Epoch: 113 | Batch_idx: 130 |  Loss: (0.1953) |  Loss2: (0.0000) | Acc: (93.00%) (15632/16768)
Epoch: 113 | Batch_idx: 140 |  Loss: (0.1967) |  Loss2: (0.0000) | Acc: (93.00%) (16812/18048)
Epoch: 113 | Batch_idx: 150 |  Loss: (0.1984) |  Loss2: (0.0000) | Acc: (93.00%) (17995/19328)
Epoch: 113 | Batch_idx: 160 |  Loss: (0.1995) |  Loss2: (0.0000) | Acc: (93.00%) (19192/20608)
Epoch: 113 | Batch_idx: 170 |  Loss: (0.1997) |  Loss2: (0.0000) | Acc: (93.00%) (20385/21888)
Epoch: 113 | Batch_idx: 180 |  Loss: (0.1997) |  Loss2: (0.0000) | Acc: (93.00%) (21575/23168)
Epoch: 113 | Batch_idx: 190 |  Loss: (0.1994) |  Loss2: (0.0000) | Acc: (93.00%) (22774/24448)
Epoch: 113 | Batch_idx: 200 |  Loss: (0.1971) |  Loss2: (0.0000) | Acc: (93.00%) (23987/25728)
Epoch: 113 | Batch_idx: 210 |  Loss: (0.1981) |  Loss2: (0.0000) | Acc: (93.00%) (25168/27008)
Epoch: 113 | Batch_idx: 220 |  Loss: (0.1976) |  Loss2: (0.0000) | Acc: (93.00%) (26357/28288)
Epoch: 113 | Batch_idx: 230 |  Loss: (0.1979) |  Loss2: (0.0000) | Acc: (93.00%) (27543/29568)
Epoch: 113 | Batch_idx: 240 |  Loss: (0.1995) |  Loss2: (0.0000) | Acc: (93.00%) (28727/30848)
Epoch: 113 | Batch_idx: 250 |  Loss: (0.1991) |  Loss2: (0.0000) | Acc: (93.00%) (29928/32128)
Epoch: 113 | Batch_idx: 260 |  Loss: (0.1996) |  Loss2: (0.0000) | Acc: (93.00%) (31117/33408)
Epoch: 113 | Batch_idx: 270 |  Loss: (0.2005) |  Loss2: (0.0000) | Acc: (93.00%) (32304/34688)
Epoch: 113 | Batch_idx: 280 |  Loss: (0.2002) |  Loss2: (0.0000) | Acc: (93.00%) (33502/35968)
Epoch: 113 | Batch_idx: 290 |  Loss: (0.1997) |  Loss2: (0.0000) | Acc: (93.00%) (34700/37248)
Epoch: 113 | Batch_idx: 300 |  Loss: (0.2004) |  Loss2: (0.0000) | Acc: (93.00%) (35886/38528)
Epoch: 113 | Batch_idx: 310 |  Loss: (0.2005) |  Loss2: (0.0000) | Acc: (93.00%) (37072/39808)
Epoch: 113 | Batch_idx: 320 |  Loss: (0.2003) |  Loss2: (0.0000) | Acc: (93.00%) (38277/41088)
Epoch: 113 | Batch_idx: 330 |  Loss: (0.2007) |  Loss2: (0.0000) | Acc: (93.00%) (39464/42368)
Epoch: 113 | Batch_idx: 340 |  Loss: (0.2006) |  Loss2: (0.0000) | Acc: (93.00%) (40653/43648)
Epoch: 113 | Batch_idx: 350 |  Loss: (0.2000) |  Loss2: (0.0000) | Acc: (93.00%) (41859/44928)
Epoch: 113 | Batch_idx: 360 |  Loss: (0.2000) |  Loss2: (0.0000) | Acc: (93.00%) (43059/46208)
Epoch: 113 | Batch_idx: 370 |  Loss: (0.2003) |  Loss2: (0.0000) | Acc: (93.00%) (44241/47488)
Epoch: 113 | Batch_idx: 380 |  Loss: (0.2004) |  Loss2: (0.0000) | Acc: (93.00%) (45430/48768)
Epoch: 113 | Batch_idx: 390 |  Loss: (0.2008) |  Loss2: (0.0000) | Acc: (93.00%) (46565/50000)
# TEST : Loss: (0.4483) | Acc: (86.00%) (8643/10000)
percent tensor([0.5488, 0.5596, 0.5791, 0.5670, 0.5804, 0.5533, 0.5682, 0.5737, 0.5582,
        0.5639, 0.5485, 0.5744, 0.5511, 0.5580, 0.5579, 0.5506],
       device='cuda:0') torch.Size([16])
percent tensor([0.5702, 0.5736, 0.5601, 0.5550, 0.5680, 0.5742, 0.5774, 0.5673, 0.5668,
        0.5663, 0.5717, 0.5706, 0.5695, 0.5690, 0.5791, 0.5699],
       device='cuda:0') torch.Size([16])
percent tensor([0.5949, 0.5941, 0.5655, 0.5476, 0.5528, 0.5757, 0.5859, 0.5628, 0.5821,
        0.5876, 0.5866, 0.5798, 0.6089, 0.5849, 0.5915, 0.5934],
       device='cuda:0') torch.Size([16])
percent tensor([0.6417, 0.6421, 0.6073, 0.6058, 0.6208, 0.6541, 0.6464, 0.6094, 0.6308,
        0.6430, 0.6473, 0.6264, 0.6399, 0.6439, 0.6470, 0.6472],
       device='cuda:0') torch.Size([16])
percent tensor([0.5370, 0.5164, 0.5893, 0.6070, 0.5982, 0.5487, 0.5406, 0.6153, 0.5725,
        0.5252, 0.5613, 0.5474, 0.4791, 0.5919, 0.5741, 0.5267],
       device='cuda:0') torch.Size([16])
percent tensor([0.5363, 0.6271, 0.6422, 0.6219, 0.6619, 0.6760, 0.6316, 0.5558, 0.6364,
        0.5791, 0.6471, 0.6125, 0.5995, 0.6506, 0.4796, 0.5528],
       device='cuda:0') torch.Size([16])
percent tensor([0.6615, 0.6704, 0.7260, 0.6676, 0.7402, 0.6989, 0.7106, 0.6770, 0.6653,
        0.6727, 0.6588, 0.6306, 0.6575, 0.6824, 0.6030, 0.6399],
       device='cuda:0') torch.Size([16])
percent tensor([0.9994, 0.9994, 0.9998, 0.9994, 0.9999, 0.9992, 0.9998, 0.9997, 0.9996,
        0.9997, 0.9997, 0.9993, 0.9994, 0.9995, 0.9993, 0.9992],
       device='cuda:0') torch.Size([16])
Epoch: 114 | Batch_idx: 0 |  Loss: (0.0950) |  Loss2: (0.0000) | Acc: (96.00%) (124/128)
Epoch: 114 | Batch_idx: 10 |  Loss: (0.1725) |  Loss2: (0.0000) | Acc: (93.00%) (1319/1408)
Epoch: 114 | Batch_idx: 20 |  Loss: (0.1971) |  Loss2: (0.0000) | Acc: (92.00%) (2493/2688)
Epoch: 114 | Batch_idx: 30 |  Loss: (0.1963) |  Loss2: (0.0000) | Acc: (93.00%) (3692/3968)
Epoch: 114 | Batch_idx: 40 |  Loss: (0.1963) |  Loss2: (0.0000) | Acc: (93.00%) (4892/5248)
Epoch: 114 | Batch_idx: 50 |  Loss: (0.1935) |  Loss2: (0.0000) | Acc: (93.00%) (6084/6528)
Epoch: 114 | Batch_idx: 60 |  Loss: (0.1937) |  Loss2: (0.0000) | Acc: (93.00%) (7281/7808)
Epoch: 114 | Batch_idx: 70 |  Loss: (0.1929) |  Loss2: (0.0000) | Acc: (93.00%) (8477/9088)
Epoch: 114 | Batch_idx: 80 |  Loss: (0.1895) |  Loss2: (0.0000) | Acc: (93.00%) (9683/10368)
Epoch: 114 | Batch_idx: 90 |  Loss: (0.1883) |  Loss2: (0.0000) | Acc: (93.00%) (10879/11648)
Epoch: 114 | Batch_idx: 100 |  Loss: (0.1858) |  Loss2: (0.0000) | Acc: (93.00%) (12094/12928)
Epoch: 114 | Batch_idx: 110 |  Loss: (0.1883) |  Loss2: (0.0000) | Acc: (93.00%) (13275/14208)
Epoch: 114 | Batch_idx: 120 |  Loss: (0.1892) |  Loss2: (0.0000) | Acc: (93.00%) (14470/15488)
Epoch: 114 | Batch_idx: 130 |  Loss: (0.1895) |  Loss2: (0.0000) | Acc: (93.00%) (15658/16768)
Epoch: 114 | Batch_idx: 140 |  Loss: (0.1885) |  Loss2: (0.0000) | Acc: (93.00%) (16862/18048)
Epoch: 114 | Batch_idx: 150 |  Loss: (0.1889) |  Loss2: (0.0000) | Acc: (93.00%) (18052/19328)
Epoch: 114 | Batch_idx: 160 |  Loss: (0.1872) |  Loss2: (0.0000) | Acc: (93.00%) (19266/20608)
Epoch: 114 | Batch_idx: 170 |  Loss: (0.1864) |  Loss2: (0.0000) | Acc: (93.00%) (20479/21888)
Epoch: 114 | Batch_idx: 180 |  Loss: (0.1872) |  Loss2: (0.0000) | Acc: (93.00%) (21665/23168)
Epoch: 114 | Batch_idx: 190 |  Loss: (0.1887) |  Loss2: (0.0000) | Acc: (93.00%) (22843/24448)
Epoch: 114 | Batch_idx: 200 |  Loss: (0.1894) |  Loss2: (0.0000) | Acc: (93.00%) (24038/25728)
Epoch: 114 | Batch_idx: 210 |  Loss: (0.1913) |  Loss2: (0.0000) | Acc: (93.00%) (25215/27008)
Epoch: 114 | Batch_idx: 220 |  Loss: (0.1913) |  Loss2: (0.0000) | Acc: (93.00%) (26405/28288)
Epoch: 114 | Batch_idx: 230 |  Loss: (0.1925) |  Loss2: (0.0000) | Acc: (93.00%) (27594/29568)
Epoch: 114 | Batch_idx: 240 |  Loss: (0.1925) |  Loss2: (0.0000) | Acc: (93.00%) (28784/30848)
Epoch: 114 | Batch_idx: 250 |  Loss: (0.1930) |  Loss2: (0.0000) | Acc: (93.00%) (29994/32128)
Epoch: 114 | Batch_idx: 260 |  Loss: (0.1927) |  Loss2: (0.0000) | Acc: (93.00%) (31189/33408)
Epoch: 114 | Batch_idx: 270 |  Loss: (0.1928) |  Loss2: (0.0000) | Acc: (93.00%) (32389/34688)
Epoch: 114 | Batch_idx: 280 |  Loss: (0.1938) |  Loss2: (0.0000) | Acc: (93.00%) (33575/35968)
Epoch: 114 | Batch_idx: 290 |  Loss: (0.1937) |  Loss2: (0.0000) | Acc: (93.00%) (34763/37248)
Epoch: 114 | Batch_idx: 300 |  Loss: (0.1935) |  Loss2: (0.0000) | Acc: (93.00%) (35964/38528)
Epoch: 114 | Batch_idx: 310 |  Loss: (0.1926) |  Loss2: (0.0000) | Acc: (93.00%) (37173/39808)
Epoch: 114 | Batch_idx: 320 |  Loss: (0.1926) |  Loss2: (0.0000) | Acc: (93.00%) (38372/41088)
Epoch: 114 | Batch_idx: 330 |  Loss: (0.1927) |  Loss2: (0.0000) | Acc: (93.00%) (39572/42368)
Epoch: 114 | Batch_idx: 340 |  Loss: (0.1929) |  Loss2: (0.0000) | Acc: (93.00%) (40766/43648)
Epoch: 114 | Batch_idx: 350 |  Loss: (0.1927) |  Loss2: (0.0000) | Acc: (93.00%) (41960/44928)
Epoch: 114 | Batch_idx: 360 |  Loss: (0.1930) |  Loss2: (0.0000) | Acc: (93.00%) (43148/46208)
Epoch: 114 | Batch_idx: 370 |  Loss: (0.1931) |  Loss2: (0.0000) | Acc: (93.00%) (44339/47488)
Epoch: 114 | Batch_idx: 380 |  Loss: (0.1935) |  Loss2: (0.0000) | Acc: (93.00%) (45529/48768)
Epoch: 114 | Batch_idx: 390 |  Loss: (0.1930) |  Loss2: (0.0000) | Acc: (93.00%) (46694/50000)
# TEST : Loss: (0.4564) | Acc: (86.00%) (8604/10000)
percent tensor([0.5482, 0.5595, 0.5759, 0.5646, 0.5773, 0.5516, 0.5669, 0.5731, 0.5574,
        0.5629, 0.5479, 0.5716, 0.5498, 0.5589, 0.5570, 0.5504],
       device='cuda:0') torch.Size([16])
percent tensor([0.5709, 0.5743, 0.5625, 0.5561, 0.5701, 0.5757, 0.5777, 0.5695, 0.5671,
        0.5671, 0.5710, 0.5725, 0.5695, 0.5679, 0.5802, 0.5707],
       device='cuda:0') torch.Size([16])
percent tensor([0.5991, 0.5989, 0.5653, 0.5544, 0.5533, 0.5869, 0.5883, 0.5641, 0.5865,
        0.5923, 0.5936, 0.5792, 0.6148, 0.5866, 0.5994, 0.6012],
       device='cuda:0') torch.Size([16])
percent tensor([0.6446, 0.6446, 0.6075, 0.6112, 0.6215, 0.6637, 0.6443, 0.6131, 0.6307,
        0.6434, 0.6463, 0.6244, 0.6436, 0.6424, 0.6528, 0.6520],
       device='cuda:0') torch.Size([16])
percent tensor([0.5204, 0.5009, 0.5982, 0.5947, 0.6003, 0.5380, 0.5364, 0.6107, 0.5695,
        0.5114, 0.5383, 0.5540, 0.4457, 0.5887, 0.5696, 0.5123],
       device='cuda:0') torch.Size([16])
percent tensor([0.5356, 0.6191, 0.6249, 0.6420, 0.6561, 0.6775, 0.6135, 0.5662, 0.6402,
        0.5506, 0.6423, 0.6003, 0.6062, 0.6491, 0.5106, 0.5356],
       device='cuda:0') torch.Size([16])
percent tensor([0.6533, 0.6540, 0.7085, 0.6763, 0.7317, 0.6990, 0.7128, 0.6838, 0.6742,
        0.6530, 0.6558, 0.6419, 0.6326, 0.7021, 0.6025, 0.6308],
       device='cuda:0') torch.Size([16])
percent tensor([0.9994, 0.9992, 0.9997, 0.9993, 0.9998, 0.9991, 0.9999, 0.9999, 0.9998,
        0.9998, 0.9998, 0.9995, 0.9996, 0.9997, 0.9993, 0.9994],
       device='cuda:0') torch.Size([16])
Epoch: 115 | Batch_idx: 0 |  Loss: (0.2056) |  Loss2: (0.0000) | Acc: (91.00%) (117/128)
Epoch: 115 | Batch_idx: 10 |  Loss: (0.1684) |  Loss2: (0.0000) | Acc: (93.00%) (1322/1408)
Epoch: 115 | Batch_idx: 20 |  Loss: (0.1722) |  Loss2: (0.0000) | Acc: (93.00%) (2521/2688)
Epoch: 115 | Batch_idx: 30 |  Loss: (0.1682) |  Loss2: (0.0000) | Acc: (93.00%) (3729/3968)
Epoch: 115 | Batch_idx: 40 |  Loss: (0.1853) |  Loss2: (0.0000) | Acc: (93.00%) (4910/5248)
Epoch: 115 | Batch_idx: 50 |  Loss: (0.1826) |  Loss2: (0.0000) | Acc: (93.00%) (6117/6528)
Epoch: 115 | Batch_idx: 60 |  Loss: (0.1841) |  Loss2: (0.0000) | Acc: (93.00%) (7314/7808)
Epoch: 115 | Batch_idx: 70 |  Loss: (0.1831) |  Loss2: (0.0000) | Acc: (93.00%) (8513/9088)
Epoch: 115 | Batch_idx: 80 |  Loss: (0.1839) |  Loss2: (0.0000) | Acc: (93.00%) (9697/10368)
Epoch: 115 | Batch_idx: 90 |  Loss: (0.1853) |  Loss2: (0.0000) | Acc: (93.00%) (10897/11648)
Epoch: 115 | Batch_idx: 100 |  Loss: (0.1837) |  Loss2: (0.0000) | Acc: (93.00%) (12098/12928)
Epoch: 115 | Batch_idx: 110 |  Loss: (0.1828) |  Loss2: (0.0000) | Acc: (93.00%) (13303/14208)
Epoch: 115 | Batch_idx: 120 |  Loss: (0.1834) |  Loss2: (0.0000) | Acc: (93.00%) (14507/15488)
Epoch: 115 | Batch_idx: 130 |  Loss: (0.1868) |  Loss2: (0.0000) | Acc: (93.00%) (15684/16768)
Epoch: 115 | Batch_idx: 140 |  Loss: (0.1872) |  Loss2: (0.0000) | Acc: (93.00%) (16878/18048)
Epoch: 115 | Batch_idx: 150 |  Loss: (0.1888) |  Loss2: (0.0000) | Acc: (93.00%) (18064/19328)
Epoch: 115 | Batch_idx: 160 |  Loss: (0.1875) |  Loss2: (0.0000) | Acc: (93.00%) (19270/20608)
Epoch: 115 | Batch_idx: 170 |  Loss: (0.1884) |  Loss2: (0.0000) | Acc: (93.00%) (20465/21888)
Epoch: 115 | Batch_idx: 180 |  Loss: (0.1886) |  Loss2: (0.0000) | Acc: (93.00%) (21667/23168)
Epoch: 115 | Batch_idx: 190 |  Loss: (0.1887) |  Loss2: (0.0000) | Acc: (93.00%) (22862/24448)
Epoch: 115 | Batch_idx: 200 |  Loss: (0.1880) |  Loss2: (0.0000) | Acc: (93.00%) (24059/25728)
Epoch: 115 | Batch_idx: 210 |  Loss: (0.1887) |  Loss2: (0.0000) | Acc: (93.00%) (25252/27008)
Epoch: 115 | Batch_idx: 220 |  Loss: (0.1895) |  Loss2: (0.0000) | Acc: (93.00%) (26443/28288)
Epoch: 115 | Batch_idx: 230 |  Loss: (0.1909) |  Loss2: (0.0000) | Acc: (93.00%) (27621/29568)
Epoch: 115 | Batch_idx: 240 |  Loss: (0.1906) |  Loss2: (0.0000) | Acc: (93.00%) (28830/30848)
Epoch: 115 | Batch_idx: 250 |  Loss: (0.1895) |  Loss2: (0.0000) | Acc: (93.00%) (30034/32128)
Epoch: 115 | Batch_idx: 260 |  Loss: (0.1891) |  Loss2: (0.0000) | Acc: (93.00%) (31234/33408)
Epoch: 115 | Batch_idx: 270 |  Loss: (0.1883) |  Loss2: (0.0000) | Acc: (93.00%) (32442/34688)
Epoch: 115 | Batch_idx: 280 |  Loss: (0.1888) |  Loss2: (0.0000) | Acc: (93.00%) (33638/35968)
Epoch: 115 | Batch_idx: 290 |  Loss: (0.1898) |  Loss2: (0.0000) | Acc: (93.00%) (34812/37248)
Epoch: 115 | Batch_idx: 300 |  Loss: (0.1894) |  Loss2: (0.0000) | Acc: (93.00%) (36014/38528)
Epoch: 115 | Batch_idx: 310 |  Loss: (0.1892) |  Loss2: (0.0000) | Acc: (93.00%) (37209/39808)
Epoch: 115 | Batch_idx: 320 |  Loss: (0.1892) |  Loss2: (0.0000) | Acc: (93.00%) (38411/41088)
Epoch: 115 | Batch_idx: 330 |  Loss: (0.1894) |  Loss2: (0.0000) | Acc: (93.00%) (39594/42368)
Epoch: 115 | Batch_idx: 340 |  Loss: (0.1896) |  Loss2: (0.0000) | Acc: (93.00%) (40784/43648)
Epoch: 115 | Batch_idx: 350 |  Loss: (0.1897) |  Loss2: (0.0000) | Acc: (93.00%) (41996/44928)
Epoch: 115 | Batch_idx: 360 |  Loss: (0.1898) |  Loss2: (0.0000) | Acc: (93.00%) (43188/46208)
Epoch: 115 | Batch_idx: 370 |  Loss: (0.1899) |  Loss2: (0.0000) | Acc: (93.00%) (44384/47488)
Epoch: 115 | Batch_idx: 380 |  Loss: (0.1900) |  Loss2: (0.0000) | Acc: (93.00%) (45577/48768)
Epoch: 115 | Batch_idx: 390 |  Loss: (0.1905) |  Loss2: (0.0000) | Acc: (93.00%) (46717/50000)
=> saving checkpoint 'drive/app/torch/save_Schedule/checkpoint_115.pth.tar'
# TEST : Loss: (0.4318) | Acc: (86.00%) (8680/10000)
percent tensor([0.5488, 0.5594, 0.5751, 0.5651, 0.5770, 0.5540, 0.5665, 0.5722, 0.5579,
        0.5622, 0.5492, 0.5705, 0.5505, 0.5582, 0.5575, 0.5506],
       device='cuda:0') torch.Size([16])
percent tensor([0.5712, 0.5750, 0.5611, 0.5569, 0.5701, 0.5754, 0.5786, 0.5679, 0.5681,
        0.5676, 0.5727, 0.5722, 0.5702, 0.5690, 0.5806, 0.5704],
       device='cuda:0') torch.Size([16])
percent tensor([0.5958, 0.5970, 0.5668, 0.5485, 0.5534, 0.5769, 0.5887, 0.5635, 0.5826,
        0.5935, 0.5895, 0.5821, 0.6124, 0.5876, 0.5933, 0.5961],
       device='cuda:0') torch.Size([16])
percent tensor([0.6442, 0.6457, 0.6092, 0.6109, 0.6226, 0.6563, 0.6477, 0.6119, 0.6337,
        0.6475, 0.6486, 0.6282, 0.6434, 0.6467, 0.6485, 0.6492],
       device='cuda:0') torch.Size([16])
percent tensor([0.5275, 0.5094, 0.5872, 0.6032, 0.5893, 0.5478, 0.5321, 0.6126, 0.5608,
        0.5124, 0.5494, 0.5289, 0.4507, 0.5785, 0.5776, 0.5271],
       device='cuda:0') torch.Size([16])
percent tensor([0.5343, 0.6412, 0.6467, 0.6282, 0.6593, 0.6682, 0.6368, 0.5661, 0.6430,
        0.5796, 0.6660, 0.6301, 0.6044, 0.6749, 0.5111, 0.5484],
       device='cuda:0') torch.Size([16])
percent tensor([0.6553, 0.6619, 0.7177, 0.6711, 0.7342, 0.6876, 0.7157, 0.6796, 0.6507,
        0.6496, 0.6533, 0.6406, 0.6290, 0.6885, 0.5970, 0.6388],
       device='cuda:0') torch.Size([16])
percent tensor([0.9995, 0.9992, 0.9998, 0.9996, 0.9998, 0.9990, 0.9999, 0.9999, 0.9995,
        0.9996, 0.9996, 0.9993, 0.9993, 0.9995, 0.9994, 0.9992],
       device='cuda:0') torch.Size([16])
Epoch: 116 | Batch_idx: 0 |  Loss: (0.1803) |  Loss2: (0.0000) | Acc: (94.00%) (121/128)
Epoch: 116 | Batch_idx: 10 |  Loss: (0.2138) |  Loss2: (0.0000) | Acc: (92.00%) (1309/1408)
Epoch: 116 | Batch_idx: 20 |  Loss: (0.1909) |  Loss2: (0.0000) | Acc: (93.00%) (2521/2688)
Epoch: 116 | Batch_idx: 30 |  Loss: (0.1884) |  Loss2: (0.0000) | Acc: (93.00%) (3722/3968)
Epoch: 116 | Batch_idx: 40 |  Loss: (0.1865) |  Loss2: (0.0000) | Acc: (93.00%) (4917/5248)
Epoch: 116 | Batch_idx: 50 |  Loss: (0.1911) |  Loss2: (0.0000) | Acc: (93.00%) (6110/6528)
Epoch: 116 | Batch_idx: 60 |  Loss: (0.1891) |  Loss2: (0.0000) | Acc: (93.00%) (7308/7808)
Epoch: 116 | Batch_idx: 70 |  Loss: (0.1823) |  Loss2: (0.0000) | Acc: (93.00%) (8530/9088)
Epoch: 116 | Batch_idx: 80 |  Loss: (0.1824) |  Loss2: (0.0000) | Acc: (93.00%) (9733/10368)
Epoch: 116 | Batch_idx: 90 |  Loss: (0.1811) |  Loss2: (0.0000) | Acc: (93.00%) (10943/11648)
Epoch: 116 | Batch_idx: 100 |  Loss: (0.1788) |  Loss2: (0.0000) | Acc: (93.00%) (12152/12928)
Epoch: 116 | Batch_idx: 110 |  Loss: (0.1759) |  Loss2: (0.0000) | Acc: (94.00%) (13371/14208)
Epoch: 116 | Batch_idx: 120 |  Loss: (0.1751) |  Loss2: (0.0000) | Acc: (94.00%) (14579/15488)
Epoch: 116 | Batch_idx: 130 |  Loss: (0.1741) |  Loss2: (0.0000) | Acc: (94.00%) (15784/16768)
Epoch: 116 | Batch_idx: 140 |  Loss: (0.1746) |  Loss2: (0.0000) | Acc: (94.00%) (16991/18048)
Epoch: 116 | Batch_idx: 150 |  Loss: (0.1751) |  Loss2: (0.0000) | Acc: (94.00%) (18193/19328)
Epoch: 116 | Batch_idx: 160 |  Loss: (0.1752) |  Loss2: (0.0000) | Acc: (94.00%) (19394/20608)
Epoch: 116 | Batch_idx: 170 |  Loss: (0.1761) |  Loss2: (0.0000) | Acc: (94.00%) (20589/21888)
Epoch: 116 | Batch_idx: 180 |  Loss: (0.1774) |  Loss2: (0.0000) | Acc: (94.00%) (21781/23168)
Epoch: 116 | Batch_idx: 190 |  Loss: (0.1777) |  Loss2: (0.0000) | Acc: (93.00%) (22981/24448)
Epoch: 116 | Batch_idx: 200 |  Loss: (0.1777) |  Loss2: (0.0000) | Acc: (93.00%) (24184/25728)
Epoch: 116 | Batch_idx: 210 |  Loss: (0.1779) |  Loss2: (0.0000) | Acc: (93.00%) (25381/27008)
Epoch: 116 | Batch_idx: 220 |  Loss: (0.1771) |  Loss2: (0.0000) | Acc: (94.00%) (26598/28288)
Epoch: 116 | Batch_idx: 230 |  Loss: (0.1771) |  Loss2: (0.0000) | Acc: (94.00%) (27797/29568)
Epoch: 116 | Batch_idx: 240 |  Loss: (0.1780) |  Loss2: (0.0000) | Acc: (93.00%) (28989/30848)
Epoch: 116 | Batch_idx: 250 |  Loss: (0.1786) |  Loss2: (0.0000) | Acc: (93.00%) (30182/32128)
Epoch: 116 | Batch_idx: 260 |  Loss: (0.1796) |  Loss2: (0.0000) | Acc: (93.00%) (31374/33408)
Epoch: 116 | Batch_idx: 270 |  Loss: (0.1801) |  Loss2: (0.0000) | Acc: (93.00%) (32556/34688)
Epoch: 116 | Batch_idx: 280 |  Loss: (0.1810) |  Loss2: (0.0000) | Acc: (93.00%) (33736/35968)
Epoch: 116 | Batch_idx: 290 |  Loss: (0.1817) |  Loss2: (0.0000) | Acc: (93.00%) (34926/37248)
Epoch: 116 | Batch_idx: 300 |  Loss: (0.1827) |  Loss2: (0.0000) | Acc: (93.00%) (36112/38528)
Epoch: 116 | Batch_idx: 310 |  Loss: (0.1832) |  Loss2: (0.0000) | Acc: (93.00%) (37306/39808)
Epoch: 116 | Batch_idx: 320 |  Loss: (0.1825) |  Loss2: (0.0000) | Acc: (93.00%) (38516/41088)
Epoch: 116 | Batch_idx: 330 |  Loss: (0.1823) |  Loss2: (0.0000) | Acc: (93.00%) (39719/42368)
Epoch: 116 | Batch_idx: 340 |  Loss: (0.1830) |  Loss2: (0.0000) | Acc: (93.00%) (40911/43648)
Epoch: 116 | Batch_idx: 350 |  Loss: (0.1839) |  Loss2: (0.0000) | Acc: (93.00%) (42098/44928)
Epoch: 116 | Batch_idx: 360 |  Loss: (0.1840) |  Loss2: (0.0000) | Acc: (93.00%) (43293/46208)
Epoch: 116 | Batch_idx: 370 |  Loss: (0.1843) |  Loss2: (0.0000) | Acc: (93.00%) (44492/47488)
Epoch: 116 | Batch_idx: 380 |  Loss: (0.1854) |  Loss2: (0.0000) | Acc: (93.00%) (45683/48768)
Epoch: 116 | Batch_idx: 390 |  Loss: (0.1855) |  Loss2: (0.0000) | Acc: (93.00%) (46832/50000)
# TEST : Loss: (0.4174) | Acc: (87.00%) (8706/10000)
percent tensor([0.5510, 0.5596, 0.5784, 0.5684, 0.5806, 0.5567, 0.5674, 0.5742, 0.5577,
        0.5633, 0.5489, 0.5730, 0.5517, 0.5577, 0.5594, 0.5524],
       device='cuda:0') torch.Size([16])
percent tensor([0.5716, 0.5734, 0.5628, 0.5576, 0.5707, 0.5762, 0.5779, 0.5688, 0.5676,
        0.5672, 0.5722, 0.5723, 0.5712, 0.5671, 0.5797, 0.5703],
       device='cuda:0') torch.Size([16])
percent tensor([0.5987, 0.5945, 0.5743, 0.5558, 0.5621, 0.5827, 0.5885, 0.5695, 0.5862,
        0.5921, 0.5912, 0.5867, 0.6142, 0.5833, 0.5944, 0.5980],
       device='cuda:0') torch.Size([16])
percent tensor([0.6453, 0.6440, 0.6101, 0.6100, 0.6232, 0.6585, 0.6466, 0.6116, 0.6332,
        0.6466, 0.6507, 0.6300, 0.6458, 0.6441, 0.6477, 0.6482],
       device='cuda:0') torch.Size([16])
percent tensor([0.5305, 0.5105, 0.5924, 0.6068, 0.5988, 0.5551, 0.5391, 0.6164, 0.5833,
        0.5090, 0.5454, 0.5390, 0.4611, 0.5890, 0.5783, 0.5277],
       device='cuda:0') torch.Size([16])
percent tensor([0.5515, 0.6226, 0.6396, 0.6486, 0.6732, 0.6793, 0.6342, 0.5816, 0.6496,
        0.5865, 0.6630, 0.6286, 0.6190, 0.6707, 0.5081, 0.5594],
       device='cuda:0') torch.Size([16])
percent tensor([0.6523, 0.6530, 0.7201, 0.6768, 0.7312, 0.6899, 0.7032, 0.6775, 0.6599,
        0.6572, 0.6547, 0.6382, 0.6316, 0.6872, 0.5978, 0.6365],
       device='cuda:0') torch.Size([16])
percent tensor([0.9993, 0.9993, 0.9997, 0.9993, 0.9997, 0.9988, 0.9998, 0.9998, 0.9997,
        0.9996, 0.9998, 0.9992, 0.9993, 0.9996, 0.9996, 0.9993],
       device='cuda:0') torch.Size([16])
Epoch: 117 | Batch_idx: 0 |  Loss: (0.1459) |  Loss2: (0.0000) | Acc: (93.00%) (120/128)
Epoch: 117 | Batch_idx: 10 |  Loss: (0.1755) |  Loss2: (0.0000) | Acc: (94.00%) (1324/1408)
Epoch: 117 | Batch_idx: 20 |  Loss: (0.1715) |  Loss2: (0.0000) | Acc: (94.00%) (2534/2688)
Epoch: 117 | Batch_idx: 30 |  Loss: (0.1693) |  Loss2: (0.0000) | Acc: (94.00%) (3736/3968)
Epoch: 117 | Batch_idx: 40 |  Loss: (0.1749) |  Loss2: (0.0000) | Acc: (94.00%) (4935/5248)
Epoch: 117 | Batch_idx: 50 |  Loss: (0.1765) |  Loss2: (0.0000) | Acc: (93.00%) (6127/6528)
Epoch: 117 | Batch_idx: 60 |  Loss: (0.1794) |  Loss2: (0.0000) | Acc: (93.00%) (7319/7808)
Epoch: 117 | Batch_idx: 70 |  Loss: (0.1797) |  Loss2: (0.0000) | Acc: (93.00%) (8515/9088)
Epoch: 117 | Batch_idx: 80 |  Loss: (0.1800) |  Loss2: (0.0000) | Acc: (93.00%) (9701/10368)
Epoch: 117 | Batch_idx: 90 |  Loss: (0.1812) |  Loss2: (0.0000) | Acc: (93.00%) (10894/11648)
Epoch: 117 | Batch_idx: 100 |  Loss: (0.1807) |  Loss2: (0.0000) | Acc: (93.00%) (12097/12928)
Epoch: 117 | Batch_idx: 110 |  Loss: (0.1797) |  Loss2: (0.0000) | Acc: (93.00%) (13308/14208)
Epoch: 117 | Batch_idx: 120 |  Loss: (0.1814) |  Loss2: (0.0000) | Acc: (93.00%) (14497/15488)
Epoch: 117 | Batch_idx: 130 |  Loss: (0.1810) |  Loss2: (0.0000) | Acc: (93.00%) (15697/16768)
Epoch: 117 | Batch_idx: 140 |  Loss: (0.1808) |  Loss2: (0.0000) | Acc: (93.00%) (16909/18048)
Epoch: 117 | Batch_idx: 150 |  Loss: (0.1811) |  Loss2: (0.0000) | Acc: (93.00%) (18109/19328)
Epoch: 117 | Batch_idx: 160 |  Loss: (0.1801) |  Loss2: (0.0000) | Acc: (93.00%) (19321/20608)
Epoch: 117 | Batch_idx: 170 |  Loss: (0.1798) |  Loss2: (0.0000) | Acc: (93.00%) (20521/21888)
Epoch: 117 | Batch_idx: 180 |  Loss: (0.1790) |  Loss2: (0.0000) | Acc: (93.00%) (21725/23168)
Epoch: 117 | Batch_idx: 190 |  Loss: (0.1782) |  Loss2: (0.0000) | Acc: (93.00%) (22935/24448)
Epoch: 117 | Batch_idx: 200 |  Loss: (0.1774) |  Loss2: (0.0000) | Acc: (93.00%) (24143/25728)
Epoch: 117 | Batch_idx: 210 |  Loss: (0.1767) |  Loss2: (0.0000) | Acc: (93.00%) (25350/27008)
Epoch: 117 | Batch_idx: 220 |  Loss: (0.1789) |  Loss2: (0.0000) | Acc: (93.00%) (26519/28288)
Epoch: 117 | Batch_idx: 230 |  Loss: (0.1789) |  Loss2: (0.0000) | Acc: (93.00%) (27722/29568)
Epoch: 117 | Batch_idx: 240 |  Loss: (0.1788) |  Loss2: (0.0000) | Acc: (93.00%) (28920/30848)
Epoch: 117 | Batch_idx: 250 |  Loss: (0.1789) |  Loss2: (0.0000) | Acc: (93.00%) (30120/32128)
Epoch: 117 | Batch_idx: 260 |  Loss: (0.1792) |  Loss2: (0.0000) | Acc: (93.00%) (31318/33408)
Epoch: 117 | Batch_idx: 270 |  Loss: (0.1789) |  Loss2: (0.0000) | Acc: (93.00%) (32521/34688)
Epoch: 117 | Batch_idx: 280 |  Loss: (0.1790) |  Loss2: (0.0000) | Acc: (93.00%) (33718/35968)
Epoch: 117 | Batch_idx: 290 |  Loss: (0.1790) |  Loss2: (0.0000) | Acc: (93.00%) (34917/37248)
Epoch: 117 | Batch_idx: 300 |  Loss: (0.1789) |  Loss2: (0.0000) | Acc: (93.00%) (36114/38528)
Epoch: 117 | Batch_idx: 310 |  Loss: (0.1795) |  Loss2: (0.0000) | Acc: (93.00%) (37307/39808)
Epoch: 117 | Batch_idx: 320 |  Loss: (0.1791) |  Loss2: (0.0000) | Acc: (93.00%) (38508/41088)
Epoch: 117 | Batch_idx: 330 |  Loss: (0.1791) |  Loss2: (0.0000) | Acc: (93.00%) (39705/42368)
Epoch: 117 | Batch_idx: 340 |  Loss: (0.1801) |  Loss2: (0.0000) | Acc: (93.00%) (40896/43648)
Epoch: 117 | Batch_idx: 350 |  Loss: (0.1812) |  Loss2: (0.0000) | Acc: (93.00%) (42091/44928)
Epoch: 117 | Batch_idx: 360 |  Loss: (0.1813) |  Loss2: (0.0000) | Acc: (93.00%) (43294/46208)
Epoch: 117 | Batch_idx: 370 |  Loss: (0.1814) |  Loss2: (0.0000) | Acc: (93.00%) (44486/47488)
Epoch: 117 | Batch_idx: 380 |  Loss: (0.1816) |  Loss2: (0.0000) | Acc: (93.00%) (45690/48768)
Epoch: 117 | Batch_idx: 390 |  Loss: (0.1815) |  Loss2: (0.0000) | Acc: (93.00%) (46845/50000)
# TEST : Loss: (0.4164) | Acc: (87.00%) (8760/10000)
percent tensor([0.5493, 0.5589, 0.5802, 0.5673, 0.5812, 0.5543, 0.5678, 0.5745, 0.5592,
        0.5635, 0.5489, 0.5751, 0.5518, 0.5572, 0.5580, 0.5509],
       device='cuda:0') torch.Size([16])
percent tensor([0.5703, 0.5732, 0.5610, 0.5563, 0.5688, 0.5758, 0.5768, 0.5691, 0.5664,
        0.5664, 0.5714, 0.5705, 0.5701, 0.5658, 0.5804, 0.5696],
       device='cuda:0') torch.Size([16])
percent tensor([0.5961, 0.5969, 0.5683, 0.5501, 0.5601, 0.5808, 0.5880, 0.5638, 0.5827,
        0.5913, 0.5909, 0.5835, 0.6134, 0.5855, 0.5951, 0.5948],
       device='cuda:0') torch.Size([16])
percent tensor([0.6432, 0.6474, 0.6060, 0.6068, 0.6183, 0.6613, 0.6465, 0.6103, 0.6304,
        0.6466, 0.6493, 0.6282, 0.6450, 0.6431, 0.6512, 0.6478],
       device='cuda:0') torch.Size([16])
percent tensor([0.5161, 0.4963, 0.5791, 0.5983, 0.5918, 0.5433, 0.5366, 0.6113, 0.5766,
        0.5100, 0.5365, 0.5296, 0.4545, 0.5932, 0.5630, 0.5234],
       device='cuda:0') torch.Size([16])
percent tensor([0.5320, 0.6086, 0.6392, 0.6271, 0.6381, 0.6579, 0.6100, 0.5495, 0.6407,
        0.5524, 0.6479, 0.6109, 0.5864, 0.6511, 0.4862, 0.5199],
       device='cuda:0') torch.Size([16])
percent tensor([0.6457, 0.6553, 0.7194, 0.6697, 0.7215, 0.6773, 0.7053, 0.6811, 0.6661,
        0.6478, 0.6520, 0.6338, 0.6411, 0.6972, 0.5903, 0.6323],
       device='cuda:0') torch.Size([16])
percent tensor([0.9994, 0.9992, 0.9997, 0.9994, 0.9998, 0.9995, 0.9998, 0.9999, 0.9994,
        0.9994, 0.9996, 0.9992, 0.9994, 0.9996, 0.9995, 0.9992],
       device='cuda:0') torch.Size([16])
Epoch: 118 | Batch_idx: 0 |  Loss: (0.1810) |  Loss2: (0.0000) | Acc: (93.00%) (120/128)
Epoch: 118 | Batch_idx: 10 |  Loss: (0.1359) |  Loss2: (0.0000) | Acc: (95.00%) (1347/1408)
Epoch: 118 | Batch_idx: 20 |  Loss: (0.1465) |  Loss2: (0.0000) | Acc: (95.00%) (2556/2688)
Epoch: 118 | Batch_idx: 30 |  Loss: (0.1496) |  Loss2: (0.0000) | Acc: (94.00%) (3765/3968)
Epoch: 118 | Batch_idx: 40 |  Loss: (0.1476) |  Loss2: (0.0000) | Acc: (94.00%) (4982/5248)
Epoch: 118 | Batch_idx: 50 |  Loss: (0.1529) |  Loss2: (0.0000) | Acc: (94.00%) (6186/6528)
Epoch: 118 | Batch_idx: 60 |  Loss: (0.1562) |  Loss2: (0.0000) | Acc: (94.00%) (7384/7808)
Epoch: 118 | Batch_idx: 70 |  Loss: (0.1615) |  Loss2: (0.0000) | Acc: (94.00%) (8578/9088)
Epoch: 118 | Batch_idx: 80 |  Loss: (0.1657) |  Loss2: (0.0000) | Acc: (94.00%) (9775/10368)
Epoch: 118 | Batch_idx: 90 |  Loss: (0.1654) |  Loss2: (0.0000) | Acc: (94.00%) (10985/11648)
Epoch: 118 | Batch_idx: 100 |  Loss: (0.1667) |  Loss2: (0.0000) | Acc: (94.00%) (12176/12928)
Epoch: 118 | Batch_idx: 110 |  Loss: (0.1689) |  Loss2: (0.0000) | Acc: (94.00%) (13374/14208)
Epoch: 118 | Batch_idx: 120 |  Loss: (0.1715) |  Loss2: (0.0000) | Acc: (93.00%) (14558/15488)
Epoch: 118 | Batch_idx: 130 |  Loss: (0.1715) |  Loss2: (0.0000) | Acc: (93.00%) (15760/16768)
Epoch: 118 | Batch_idx: 140 |  Loss: (0.1725) |  Loss2: (0.0000) | Acc: (93.00%) (16955/18048)
Epoch: 118 | Batch_idx: 150 |  Loss: (0.1724) |  Loss2: (0.0000) | Acc: (93.00%) (18156/19328)
Epoch: 118 | Batch_idx: 160 |  Loss: (0.1711) |  Loss2: (0.0000) | Acc: (94.00%) (19377/20608)
Epoch: 118 | Batch_idx: 170 |  Loss: (0.1714) |  Loss2: (0.0000) | Acc: (94.00%) (20581/21888)
Epoch: 118 | Batch_idx: 180 |  Loss: (0.1714) |  Loss2: (0.0000) | Acc: (94.00%) (21778/23168)
Epoch: 118 | Batch_idx: 190 |  Loss: (0.1722) |  Loss2: (0.0000) | Acc: (93.00%) (22969/24448)
Epoch: 118 | Batch_idx: 200 |  Loss: (0.1716) |  Loss2: (0.0000) | Acc: (93.00%) (24169/25728)
Epoch: 118 | Batch_idx: 210 |  Loss: (0.1729) |  Loss2: (0.0000) | Acc: (93.00%) (25368/27008)
Epoch: 118 | Batch_idx: 220 |  Loss: (0.1736) |  Loss2: (0.0000) | Acc: (93.00%) (26567/28288)
Epoch: 118 | Batch_idx: 230 |  Loss: (0.1732) |  Loss2: (0.0000) | Acc: (93.00%) (27771/29568)
Epoch: 118 | Batch_idx: 240 |  Loss: (0.1737) |  Loss2: (0.0000) | Acc: (93.00%) (28965/30848)
Epoch: 118 | Batch_idx: 250 |  Loss: (0.1742) |  Loss2: (0.0000) | Acc: (93.00%) (30166/32128)
Epoch: 118 | Batch_idx: 260 |  Loss: (0.1756) |  Loss2: (0.0000) | Acc: (93.00%) (31344/33408)
Epoch: 118 | Batch_idx: 270 |  Loss: (0.1753) |  Loss2: (0.0000) | Acc: (93.00%) (32549/34688)
Epoch: 118 | Batch_idx: 280 |  Loss: (0.1756) |  Loss2: (0.0000) | Acc: (93.00%) (33749/35968)
Epoch: 118 | Batch_idx: 290 |  Loss: (0.1756) |  Loss2: (0.0000) | Acc: (93.00%) (34946/37248)
Epoch: 118 | Batch_idx: 300 |  Loss: (0.1759) |  Loss2: (0.0000) | Acc: (93.00%) (36151/38528)
Epoch: 118 | Batch_idx: 310 |  Loss: (0.1758) |  Loss2: (0.0000) | Acc: (93.00%) (37347/39808)
Epoch: 118 | Batch_idx: 320 |  Loss: (0.1762) |  Loss2: (0.0000) | Acc: (93.00%) (38536/41088)
Epoch: 118 | Batch_idx: 330 |  Loss: (0.1762) |  Loss2: (0.0000) | Acc: (93.00%) (39734/42368)
Epoch: 118 | Batch_idx: 340 |  Loss: (0.1767) |  Loss2: (0.0000) | Acc: (93.00%) (40933/43648)
Epoch: 118 | Batch_idx: 350 |  Loss: (0.1767) |  Loss2: (0.0000) | Acc: (93.00%) (42137/44928)
Epoch: 118 | Batch_idx: 360 |  Loss: (0.1763) |  Loss2: (0.0000) | Acc: (93.00%) (43350/46208)
Epoch: 118 | Batch_idx: 370 |  Loss: (0.1758) |  Loss2: (0.0000) | Acc: (93.00%) (44558/47488)
Epoch: 118 | Batch_idx: 380 |  Loss: (0.1766) |  Loss2: (0.0000) | Acc: (93.00%) (45739/48768)
Epoch: 118 | Batch_idx: 390 |  Loss: (0.1764) |  Loss2: (0.0000) | Acc: (93.00%) (46906/50000)
# TEST : Loss: (0.4106) | Acc: (87.00%) (8752/10000)
percent tensor([0.5501, 0.5582, 0.5814, 0.5674, 0.5819, 0.5554, 0.5675, 0.5746, 0.5588,
        0.5631, 0.5492, 0.5752, 0.5518, 0.5558, 0.5582, 0.5511],
       device='cuda:0') torch.Size([16])
percent tensor([0.5702, 0.5730, 0.5588, 0.5543, 0.5670, 0.5751, 0.5759, 0.5669, 0.5659,
        0.5655, 0.5721, 0.5684, 0.5696, 0.5660, 0.5793, 0.5697],
       device='cuda:0') torch.Size([16])
percent tensor([0.5975, 0.5938, 0.5688, 0.5532, 0.5569, 0.5809, 0.5863, 0.5654, 0.5831,
        0.5896, 0.5882, 0.5817, 0.6134, 0.5816, 0.5943, 0.5952],
       device='cuda:0') torch.Size([16])
percent tensor([0.6419, 0.6441, 0.6032, 0.6067, 0.6144, 0.6578, 0.6429, 0.6095, 0.6293,
        0.6411, 0.6472, 0.6234, 0.6430, 0.6449, 0.6484, 0.6476],
       device='cuda:0') torch.Size([16])
percent tensor([0.5269, 0.5008, 0.5914, 0.6021, 0.5987, 0.5609, 0.5341, 0.6100, 0.5589,
        0.5163, 0.5322, 0.5372, 0.4530, 0.5881, 0.5689, 0.5296],
       device='cuda:0') torch.Size([16])
percent tensor([0.5392, 0.6304, 0.6550, 0.6509, 0.6605, 0.6735, 0.6209, 0.5827, 0.6446,
        0.5875, 0.6574, 0.6257, 0.6070, 0.6656, 0.5001, 0.5402],
       device='cuda:0') torch.Size([16])
percent tensor([0.6571, 0.6656, 0.7275, 0.6799, 0.7324, 0.7048, 0.7160, 0.6910, 0.6654,
        0.6704, 0.6608, 0.6436, 0.6469, 0.6923, 0.5975, 0.6386],
       device='cuda:0') torch.Size([16])
percent tensor([0.9995, 0.9991, 0.9998, 0.9996, 0.9998, 0.9995, 0.9999, 0.9999, 0.9998,
        0.9996, 0.9997, 0.9993, 0.9995, 0.9996, 0.9995, 0.9994],
       device='cuda:0') torch.Size([16])
False Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=128, out_features=16, bias=False)
True Linear(in_features=16, out_features=2, bias=False)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=128, out_features=16, bias=False)
True Linear(in_features=16, out_features=2, bias=False)
False Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=256, out_features=32, bias=False)
True Linear(in_features=32, out_features=2, bias=False)
False Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=256, out_features=32, bias=False)
True Linear(in_features=32, out_features=2, bias=False)
False Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=512, out_features=64, bias=False)
True Linear(in_features=64, out_features=2, bias=False)
False Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=512, out_features=64, bias=False)
True Linear(in_features=64, out_features=2, bias=False)
False Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1024, out_features=128, bias=False)
True Linear(in_features=128, out_features=2, bias=False)
False Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1024, out_features=128, bias=False)
True Linear(in_features=128, out_features=2, bias=False)
False Linear(in_features=512, out_features=10, bias=True)
Epoch: 119 | Batch_idx: 0 |  Loss: (0.1328) |  Loss2: (0.0000) | Acc: (95.00%) (122/128)
Epoch: 119 | Batch_idx: 10 |  Loss: (0.1712) |  Loss2: (0.0000) | Acc: (94.00%) (1326/1408)
Epoch: 119 | Batch_idx: 20 |  Loss: (0.1808) |  Loss2: (0.0000) | Acc: (93.00%) (2517/2688)
Epoch: 119 | Batch_idx: 30 |  Loss: (0.1892) |  Loss2: (0.0000) | Acc: (93.00%) (3709/3968)
Epoch: 119 | Batch_idx: 40 |  Loss: (0.1905) |  Loss2: (0.0000) | Acc: (93.00%) (4905/5248)
Epoch: 119 | Batch_idx: 50 |  Loss: (0.1962) |  Loss2: (0.0000) | Acc: (93.00%) (6083/6528)
Epoch: 119 | Batch_idx: 60 |  Loss: (0.1954) |  Loss2: (0.0000) | Acc: (93.00%) (7277/7808)
Epoch: 119 | Batch_idx: 70 |  Loss: (0.1962) |  Loss2: (0.0000) | Acc: (93.00%) (8470/9088)
Epoch: 119 | Batch_idx: 80 |  Loss: (0.1971) |  Loss2: (0.0000) | Acc: (93.00%) (9661/10368)
Epoch: 119 | Batch_idx: 90 |  Loss: (0.1977) |  Loss2: (0.0000) | Acc: (93.00%) (10847/11648)
Epoch: 119 | Batch_idx: 100 |  Loss: (0.1995) |  Loss2: (0.0000) | Acc: (93.00%) (12035/12928)
Epoch: 119 | Batch_idx: 110 |  Loss: (0.2010) |  Loss2: (0.0000) | Acc: (93.00%) (13216/14208)
Epoch: 119 | Batch_idx: 120 |  Loss: (0.2017) |  Loss2: (0.0000) | Acc: (92.00%) (14401/15488)
Epoch: 119 | Batch_idx: 130 |  Loss: (0.2008) |  Loss2: (0.0000) | Acc: (92.00%) (15591/16768)
Epoch: 119 | Batch_idx: 140 |  Loss: (0.2017) |  Loss2: (0.0000) | Acc: (92.00%) (16769/18048)
Epoch: 119 | Batch_idx: 150 |  Loss: (0.2007) |  Loss2: (0.0000) | Acc: (92.00%) (17969/19328)
Epoch: 119 | Batch_idx: 160 |  Loss: (0.1990) |  Loss2: (0.0000) | Acc: (93.00%) (19166/20608)
Epoch: 119 | Batch_idx: 170 |  Loss: (0.1987) |  Loss2: (0.0000) | Acc: (92.00%) (20350/21888)
Epoch: 119 | Batch_idx: 180 |  Loss: (0.1982) |  Loss2: (0.0000) | Acc: (93.00%) (21547/23168)
Epoch: 119 | Batch_idx: 190 |  Loss: (0.1968) |  Loss2: (0.0000) | Acc: (93.00%) (22756/24448)
Epoch: 119 | Batch_idx: 200 |  Loss: (0.1961) |  Loss2: (0.0000) | Acc: (93.00%) (23959/25728)
Epoch: 119 | Batch_idx: 210 |  Loss: (0.1962) |  Loss2: (0.0000) | Acc: (93.00%) (25147/27008)
Epoch: 119 | Batch_idx: 220 |  Loss: (0.1967) |  Loss2: (0.0000) | Acc: (93.00%) (26338/28288)
Epoch: 119 | Batch_idx: 230 |  Loss: (0.1960) |  Loss2: (0.0000) | Acc: (93.00%) (27540/29568)
Epoch: 119 | Batch_idx: 240 |  Loss: (0.1968) |  Loss2: (0.0000) | Acc: (93.00%) (28718/30848)
Epoch: 119 | Batch_idx: 250 |  Loss: (0.1956) |  Loss2: (0.0000) | Acc: (93.00%) (29921/32128)
Epoch: 119 | Batch_idx: 260 |  Loss: (0.1954) |  Loss2: (0.0000) | Acc: (93.00%) (31112/33408)
Epoch: 119 | Batch_idx: 270 |  Loss: (0.1945) |  Loss2: (0.0000) | Acc: (93.00%) (32323/34688)
Epoch: 119 | Batch_idx: 280 |  Loss: (0.1934) |  Loss2: (0.0000) | Acc: (93.00%) (33532/35968)
Epoch: 119 | Batch_idx: 290 |  Loss: (0.1936) |  Loss2: (0.0000) | Acc: (93.00%) (34728/37248)
Epoch: 119 | Batch_idx: 300 |  Loss: (0.1924) |  Loss2: (0.0000) | Acc: (93.00%) (35948/38528)
Epoch: 119 | Batch_idx: 310 |  Loss: (0.1928) |  Loss2: (0.0000) | Acc: (93.00%) (37136/39808)
Epoch: 119 | Batch_idx: 320 |  Loss: (0.1933) |  Loss2: (0.0000) | Acc: (93.00%) (38327/41088)
Epoch: 119 | Batch_idx: 330 |  Loss: (0.1928) |  Loss2: (0.0000) | Acc: (93.00%) (39524/42368)
Epoch: 119 | Batch_idx: 340 |  Loss: (0.1924) |  Loss2: (0.0000) | Acc: (93.00%) (40722/43648)
Epoch: 119 | Batch_idx: 350 |  Loss: (0.1921) |  Loss2: (0.0000) | Acc: (93.00%) (41926/44928)
Epoch: 119 | Batch_idx: 360 |  Loss: (0.1913) |  Loss2: (0.0000) | Acc: (93.00%) (43124/46208)
Epoch: 119 | Batch_idx: 370 |  Loss: (0.1909) |  Loss2: (0.0000) | Acc: (93.00%) (44321/47488)
Epoch: 119 | Batch_idx: 380 |  Loss: (0.1913) |  Loss2: (0.0000) | Acc: (93.00%) (45514/48768)
Epoch: 119 | Batch_idx: 390 |  Loss: (0.1910) |  Loss2: (0.0000) | Acc: (93.00%) (46661/50000)
# TEST : Loss: (0.4015) | Acc: (87.00%) (8751/10000)
percent tensor([0.5553, 0.5644, 0.5889, 0.5743, 0.5898, 0.5600, 0.5747, 0.5813, 0.5649,
        0.5701, 0.5546, 0.5837, 0.5576, 0.5614, 0.5639, 0.5564],
       device='cuda:0') torch.Size([16])
percent tensor([0.5606, 0.5610, 0.5526, 0.5466, 0.5588, 0.5644, 0.5651, 0.5575, 0.5562,
        0.5558, 0.5610, 0.5602, 0.5597, 0.5544, 0.5675, 0.5598],
       device='cuda:0') torch.Size([16])
percent tensor([0.5926, 0.5897, 0.5681, 0.5490, 0.5558, 0.5721, 0.5824, 0.5630, 0.5795,
        0.5881, 0.5852, 0.5816, 0.6102, 0.5756, 0.5874, 0.5901],
       device='cuda:0') torch.Size([16])
percent tensor([0.6248, 0.6265, 0.5947, 0.5969, 0.6033, 0.6375, 0.6260, 0.5971, 0.6134,
        0.6247, 0.6281, 0.6099, 0.6262, 0.6257, 0.6295, 0.6295],
       device='cuda:0') torch.Size([16])
percent tensor([0.5412, 0.5432, 0.5963, 0.6040, 0.6023, 0.5389, 0.5669, 0.6180, 0.5721,
        0.5510, 0.5660, 0.5543, 0.4763, 0.6234, 0.5909, 0.5435],
       device='cuda:0') torch.Size([16])
percent tensor([0.5572, 0.6342, 0.6676, 0.6588, 0.6715, 0.6813, 0.6237, 0.5965, 0.6553,
        0.5950, 0.6667, 0.6298, 0.6199, 0.6661, 0.5120, 0.5564],
       device='cuda:0') torch.Size([16])
percent tensor([0.6280, 0.6375, 0.6924, 0.6378, 0.6890, 0.6680, 0.6767, 0.6371, 0.6374,
        0.6407, 0.6419, 0.6146, 0.6276, 0.6598, 0.5685, 0.6082],
       device='cuda:0') torch.Size([16])
percent tensor([0.9996, 0.9991, 0.9998, 0.9995, 0.9998, 0.9993, 0.9999, 0.9999, 0.9998,
        0.9995, 0.9997, 0.9992, 0.9996, 0.9996, 0.9995, 0.9994],
       device='cuda:0') torch.Size([16])
Epoch: 120 | Batch_idx: 0 |  Loss: (0.1336) |  Loss2: (0.0000) | Acc: (93.00%) (120/128)
Epoch: 120 | Batch_idx: 10 |  Loss: (0.1996) |  Loss2: (0.0000) | Acc: (93.00%) (1313/1408)
Epoch: 120 | Batch_idx: 20 |  Loss: (0.1846) |  Loss2: (0.0000) | Acc: (93.00%) (2518/2688)
Epoch: 120 | Batch_idx: 30 |  Loss: (0.1901) |  Loss2: (0.0000) | Acc: (93.00%) (3705/3968)
Epoch: 120 | Batch_idx: 40 |  Loss: (0.1868) |  Loss2: (0.0000) | Acc: (93.00%) (4913/5248)
Epoch: 120 | Batch_idx: 50 |  Loss: (0.1795) |  Loss2: (0.0000) | Acc: (93.00%) (6128/6528)
Epoch: 120 | Batch_idx: 60 |  Loss: (0.1788) |  Loss2: (0.0000) | Acc: (93.00%) (7328/7808)
Epoch: 120 | Batch_idx: 70 |  Loss: (0.1788) |  Loss2: (0.0000) | Acc: (93.00%) (8530/9088)
Epoch: 120 | Batch_idx: 80 |  Loss: (0.1798) |  Loss2: (0.0000) | Acc: (93.00%) (9727/10368)
Epoch: 120 | Batch_idx: 90 |  Loss: (0.1782) |  Loss2: (0.0000) | Acc: (93.00%) (10925/11648)
Epoch: 120 | Batch_idx: 100 |  Loss: (0.1786) |  Loss2: (0.0000) | Acc: (93.00%) (12125/12928)
Epoch: 120 | Batch_idx: 110 |  Loss: (0.1763) |  Loss2: (0.0000) | Acc: (93.00%) (13339/14208)
Epoch: 120 | Batch_idx: 120 |  Loss: (0.1767) |  Loss2: (0.0000) | Acc: (93.00%) (14534/15488)
Epoch: 120 | Batch_idx: 130 |  Loss: (0.1758) |  Loss2: (0.0000) | Acc: (93.00%) (15735/16768)
Epoch: 120 | Batch_idx: 140 |  Loss: (0.1783) |  Loss2: (0.0000) | Acc: (93.00%) (16921/18048)
Epoch: 120 | Batch_idx: 150 |  Loss: (0.1770) |  Loss2: (0.0000) | Acc: (93.00%) (18133/19328)
Epoch: 120 | Batch_idx: 160 |  Loss: (0.1770) |  Loss2: (0.0000) | Acc: (93.00%) (19331/20608)
Epoch: 120 | Batch_idx: 170 |  Loss: (0.1768) |  Loss2: (0.0000) | Acc: (93.00%) (20545/21888)
Epoch: 120 | Batch_idx: 180 |  Loss: (0.1751) |  Loss2: (0.0000) | Acc: (93.00%) (21765/23168)
Epoch: 120 | Batch_idx: 190 |  Loss: (0.1745) |  Loss2: (0.0000) | Acc: (93.00%) (22965/24448)
Epoch: 120 | Batch_idx: 200 |  Loss: (0.1758) |  Loss2: (0.0000) | Acc: (93.00%) (24158/25728)
Epoch: 120 | Batch_idx: 210 |  Loss: (0.1750) |  Loss2: (0.0000) | Acc: (93.00%) (25366/27008)
Epoch: 120 | Batch_idx: 220 |  Loss: (0.1745) |  Loss2: (0.0000) | Acc: (93.00%) (26581/28288)
Epoch: 120 | Batch_idx: 230 |  Loss: (0.1743) |  Loss2: (0.0000) | Acc: (93.00%) (27790/29568)
Epoch: 120 | Batch_idx: 240 |  Loss: (0.1743) |  Loss2: (0.0000) | Acc: (94.00%) (29006/30848)
Epoch: 120 | Batch_idx: 250 |  Loss: (0.1738) |  Loss2: (0.0000) | Acc: (94.00%) (30212/32128)
Epoch: 120 | Batch_idx: 260 |  Loss: (0.1730) |  Loss2: (0.0000) | Acc: (94.00%) (31428/33408)
Epoch: 120 | Batch_idx: 270 |  Loss: (0.1731) |  Loss2: (0.0000) | Acc: (94.00%) (32632/34688)
Epoch: 120 | Batch_idx: 280 |  Loss: (0.1723) |  Loss2: (0.0000) | Acc: (94.00%) (33843/35968)
Epoch: 120 | Batch_idx: 290 |  Loss: (0.1725) |  Loss2: (0.0000) | Acc: (94.00%) (35037/37248)
Epoch: 120 | Batch_idx: 300 |  Loss: (0.1732) |  Loss2: (0.0000) | Acc: (94.00%) (36232/38528)
Epoch: 120 | Batch_idx: 310 |  Loss: (0.1728) |  Loss2: (0.0000) | Acc: (94.00%) (37446/39808)
Epoch: 120 | Batch_idx: 320 |  Loss: (0.1720) |  Loss2: (0.0000) | Acc: (94.00%) (38661/41088)
Epoch: 120 | Batch_idx: 330 |  Loss: (0.1716) |  Loss2: (0.0000) | Acc: (94.00%) (39868/42368)
Epoch: 120 | Batch_idx: 340 |  Loss: (0.1720) |  Loss2: (0.0000) | Acc: (94.00%) (41062/43648)
Epoch: 120 | Batch_idx: 350 |  Loss: (0.1716) |  Loss2: (0.0000) | Acc: (94.00%) (42273/44928)
Epoch: 120 | Batch_idx: 360 |  Loss: (0.1722) |  Loss2: (0.0000) | Acc: (94.00%) (43470/46208)
Epoch: 120 | Batch_idx: 370 |  Loss: (0.1717) |  Loss2: (0.0000) | Acc: (94.00%) (44681/47488)
Epoch: 120 | Batch_idx: 380 |  Loss: (0.1715) |  Loss2: (0.0000) | Acc: (94.00%) (45889/48768)
Epoch: 120 | Batch_idx: 390 |  Loss: (0.1716) |  Loss2: (0.0000) | Acc: (94.00%) (47047/50000)
=> saving checkpoint 'drive/app/torch/save_Schedule/checkpoint_120.pth.tar'
# TEST : Loss: (0.3895) | Acc: (88.00%) (8811/10000)
percent tensor([0.5552, 0.5648, 0.5904, 0.5759, 0.5913, 0.5598, 0.5754, 0.5827, 0.5653,
        0.5710, 0.5546, 0.5851, 0.5578, 0.5619, 0.5641, 0.5568],
       device='cuda:0') torch.Size([16])
percent tensor([0.5617, 0.5628, 0.5538, 0.5478, 0.5603, 0.5651, 0.5670, 0.5592, 0.5575,
        0.5575, 0.5625, 0.5620, 0.5612, 0.5559, 0.5689, 0.5611],
       device='cuda:0') torch.Size([16])
percent tensor([0.5927, 0.5914, 0.5680, 0.5487, 0.5546, 0.5702, 0.5831, 0.5624, 0.5802,
        0.5901, 0.5859, 0.5824, 0.6120, 0.5777, 0.5864, 0.5907],
       device='cuda:0') torch.Size([16])
percent tensor([0.6278, 0.6305, 0.5980, 0.6001, 0.6067, 0.6381, 0.6302, 0.6017, 0.6164,
        0.6288, 0.6313, 0.6143, 0.6293, 0.6293, 0.6332, 0.6321],
       device='cuda:0') torch.Size([16])
percent tensor([0.5295, 0.5373, 0.5941, 0.6044, 0.6033, 0.5207, 0.5607, 0.6191, 0.5634,
        0.5474, 0.5561, 0.5535, 0.4658, 0.6184, 0.5790, 0.5339],
       device='cuda:0') torch.Size([16])
percent tensor([0.5577, 0.6353, 0.6649, 0.6511, 0.6681, 0.6817, 0.6221, 0.5954, 0.6516,
        0.5905, 0.6651, 0.6217, 0.6218, 0.6610, 0.5137, 0.5579],
       device='cuda:0') torch.Size([16])
percent tensor([0.6353, 0.6458, 0.6883, 0.6327, 0.6820, 0.6722, 0.6789, 0.6291, 0.6447,
        0.6460, 0.6547, 0.6146, 0.6414, 0.6704, 0.5716, 0.6115],
       device='cuda:0') torch.Size([16])
percent tensor([0.9996, 0.9992, 0.9998, 0.9995, 0.9998, 0.9993, 0.9998, 0.9999, 0.9998,
        0.9995, 0.9997, 0.9993, 0.9996, 0.9996, 0.9996, 0.9994],
       device='cuda:0') torch.Size([16])
Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 3, 3, 3]) tensor(186.9335, device='cuda:0')
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(814.5782, device='cuda:0')
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(832.8795, device='cuda:0')
Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([128, 64, 3, 3]) tensor(1530.3167, device='cuda:0')
Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([128, 64, 1, 1]) tensor(495.9685, device='cuda:0')
Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([128, 128, 3, 3]) tensor(2256.0779, device='cuda:0')
Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([256, 128, 3, 3]) tensor(4270.3608, device='cuda:0')
Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([256, 128, 1, 1]) tensor(1380.1716, device='cuda:0')
Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([256, 256, 3, 3]) tensor(6171.5547, device='cuda:0')
Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([512, 256, 3, 3]) tensor(11801.8721, device='cuda:0')
Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([512, 256, 1, 1]) tensor(3908.9824, device='cuda:0')
Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([512, 512, 3, 3]) tensor(16510.2324, device='cuda:0')
Epoch: 121 | Batch_idx: 0 |  Loss: (0.1613) |  Loss2: (0.0000) | Acc: (94.00%) (121/128)
Epoch: 121 | Batch_idx: 10 |  Loss: (0.1557) |  Loss2: (0.0000) | Acc: (94.00%) (1327/1408)
Epoch: 121 | Batch_idx: 20 |  Loss: (0.1597) |  Loss2: (0.0000) | Acc: (94.00%) (2543/2688)
Epoch: 121 | Batch_idx: 30 |  Loss: (0.1677) |  Loss2: (0.0000) | Acc: (94.00%) (3745/3968)
Epoch: 121 | Batch_idx: 40 |  Loss: (0.1684) |  Loss2: (0.0000) | Acc: (94.00%) (4954/5248)
Epoch: 121 | Batch_idx: 50 |  Loss: (0.1702) |  Loss2: (0.0000) | Acc: (94.00%) (6163/6528)
Epoch: 121 | Batch_idx: 60 |  Loss: (0.1699) |  Loss2: (0.0000) | Acc: (94.00%) (7369/7808)
Epoch: 121 | Batch_idx: 70 |  Loss: (0.1675) |  Loss2: (0.0000) | Acc: (94.00%) (8582/9088)
Epoch: 121 | Batch_idx: 80 |  Loss: (0.1648) |  Loss2: (0.0000) | Acc: (94.00%) (9798/10368)
Epoch: 121 | Batch_idx: 90 |  Loss: (0.1620) |  Loss2: (0.0000) | Acc: (94.00%) (11030/11648)
Epoch: 121 | Batch_idx: 100 |  Loss: (0.1611) |  Loss2: (0.0000) | Acc: (94.00%) (12242/12928)
Epoch: 121 | Batch_idx: 110 |  Loss: (0.1607) |  Loss2: (0.0000) | Acc: (94.00%) (13452/14208)
Epoch: 121 | Batch_idx: 120 |  Loss: (0.1603) |  Loss2: (0.0000) | Acc: (94.00%) (14668/15488)
Epoch: 121 | Batch_idx: 130 |  Loss: (0.1589) |  Loss2: (0.0000) | Acc: (94.00%) (15886/16768)
Epoch: 121 | Batch_idx: 140 |  Loss: (0.1593) |  Loss2: (0.0000) | Acc: (94.00%) (17095/18048)
Epoch: 121 | Batch_idx: 150 |  Loss: (0.1591) |  Loss2: (0.0000) | Acc: (94.00%) (18304/19328)
Epoch: 121 | Batch_idx: 160 |  Loss: (0.1600) |  Loss2: (0.0000) | Acc: (94.00%) (19509/20608)
Epoch: 121 | Batch_idx: 170 |  Loss: (0.1596) |  Loss2: (0.0000) | Acc: (94.00%) (20733/21888)
Epoch: 121 | Batch_idx: 180 |  Loss: (0.1602) |  Loss2: (0.0000) | Acc: (94.00%) (21934/23168)
Epoch: 121 | Batch_idx: 190 |  Loss: (0.1613) |  Loss2: (0.0000) | Acc: (94.00%) (23130/24448)
Epoch: 121 | Batch_idx: 200 |  Loss: (0.1619) |  Loss2: (0.0000) | Acc: (94.00%) (24328/25728)
Epoch: 121 | Batch_idx: 210 |  Loss: (0.1627) |  Loss2: (0.0000) | Acc: (94.00%) (25529/27008)
Epoch: 121 | Batch_idx: 220 |  Loss: (0.1631) |  Loss2: (0.0000) | Acc: (94.00%) (26731/28288)
Epoch: 121 | Batch_idx: 230 |  Loss: (0.1631) |  Loss2: (0.0000) | Acc: (94.00%) (27937/29568)
Epoch: 121 | Batch_idx: 240 |  Loss: (0.1630) |  Loss2: (0.0000) | Acc: (94.00%) (29146/30848)
Epoch: 121 | Batch_idx: 250 |  Loss: (0.1630) |  Loss2: (0.0000) | Acc: (94.00%) (30366/32128)
Epoch: 121 | Batch_idx: 260 |  Loss: (0.1630) |  Loss2: (0.0000) | Acc: (94.00%) (31576/33408)
Epoch: 121 | Batch_idx: 270 |  Loss: (0.1627) |  Loss2: (0.0000) | Acc: (94.00%) (32785/34688)
Epoch: 121 | Batch_idx: 280 |  Loss: (0.1626) |  Loss2: (0.0000) | Acc: (94.00%) (33999/35968)
Epoch: 121 | Batch_idx: 290 |  Loss: (0.1621) |  Loss2: (0.0000) | Acc: (94.00%) (35216/37248)
Epoch: 121 | Batch_idx: 300 |  Loss: (0.1626) |  Loss2: (0.0000) | Acc: (94.00%) (36419/38528)
Epoch: 121 | Batch_idx: 310 |  Loss: (0.1622) |  Loss2: (0.0000) | Acc: (94.00%) (37633/39808)
Epoch: 121 | Batch_idx: 320 |  Loss: (0.1621) |  Loss2: (0.0000) | Acc: (94.00%) (38843/41088)
Epoch: 121 | Batch_idx: 330 |  Loss: (0.1624) |  Loss2: (0.0000) | Acc: (94.00%) (40050/42368)
Epoch: 121 | Batch_idx: 340 |  Loss: (0.1617) |  Loss2: (0.0000) | Acc: (94.00%) (41274/43648)
Epoch: 121 | Batch_idx: 350 |  Loss: (0.1619) |  Loss2: (0.0000) | Acc: (94.00%) (42490/44928)
Epoch: 121 | Batch_idx: 360 |  Loss: (0.1632) |  Loss2: (0.0000) | Acc: (94.00%) (43683/46208)
Epoch: 121 | Batch_idx: 370 |  Loss: (0.1635) |  Loss2: (0.0000) | Acc: (94.00%) (44884/47488)
Epoch: 121 | Batch_idx: 380 |  Loss: (0.1634) |  Loss2: (0.0000) | Acc: (94.00%) (46088/48768)
Epoch: 121 | Batch_idx: 390 |  Loss: (0.1636) |  Loss2: (0.0000) | Acc: (94.00%) (47237/50000)
# TEST : Loss: (0.3842) | Acc: (88.00%) (8823/10000)
percent tensor([0.5519, 0.5611, 0.5883, 0.5737, 0.5886, 0.5559, 0.5721, 0.5800, 0.5621,
        0.5682, 0.5508, 0.5828, 0.5546, 0.5587, 0.5604, 0.5537],
       device='cuda:0') torch.Size([16])
percent tensor([0.5650, 0.5668, 0.5572, 0.5507, 0.5641, 0.5678, 0.5712, 0.5630, 0.5613,
        0.5616, 0.5665, 0.5662, 0.5649, 0.5597, 0.5723, 0.5645],
       device='cuda:0') torch.Size([16])
percent tensor([0.5985, 0.5995, 0.5726, 0.5522, 0.5578, 0.5729, 0.5898, 0.5665, 0.5859,
        0.5986, 0.5934, 0.5884, 0.6202, 0.5855, 0.5915, 0.5972],
       device='cuda:0') torch.Size([16])
percent tensor([0.6260, 0.6288, 0.5968, 0.5984, 0.6051, 0.6343, 0.6287, 0.6011, 0.6147,
        0.6271, 0.6292, 0.6132, 0.6276, 0.6271, 0.6312, 0.6294],
       device='cuda:0') torch.Size([16])
percent tensor([0.5233, 0.5334, 0.5931, 0.6086, 0.6043, 0.5123, 0.5569, 0.6199, 0.5605,
        0.5450, 0.5505, 0.5546, 0.4590, 0.6178, 0.5724, 0.5293],
       device='cuda:0') torch.Size([16])
percent tensor([0.5550, 0.6342, 0.6608, 0.6431, 0.6629, 0.6809, 0.6184, 0.5878, 0.6486,
        0.5902, 0.6623, 0.6129, 0.6233, 0.6582, 0.5078, 0.5546],
       device='cuda:0') torch.Size([16])
percent tensor([0.6477, 0.6573, 0.6929, 0.6342, 0.6859, 0.6831, 0.6865, 0.6284, 0.6571,
        0.6567, 0.6685, 0.6177, 0.6575, 0.6807, 0.5767, 0.6199],
       device='cuda:0') torch.Size([16])
percent tensor([0.9996, 0.9992, 0.9998, 0.9995, 0.9999, 0.9994, 0.9999, 0.9999, 0.9998,
        0.9996, 0.9997, 0.9993, 0.9996, 0.9996, 0.9995, 0.9994],
       device='cuda:0') torch.Size([16])
Epoch: 122 | Batch_idx: 0 |  Loss: (0.1138) |  Loss2: (0.0000) | Acc: (96.00%) (124/128)
Epoch: 122 | Batch_idx: 10 |  Loss: (0.1712) |  Loss2: (0.0000) | Acc: (93.00%) (1318/1408)
Epoch: 122 | Batch_idx: 20 |  Loss: (0.1767) |  Loss2: (0.0000) | Acc: (93.00%) (2520/2688)
Epoch: 122 | Batch_idx: 30 |  Loss: (0.1638) |  Loss2: (0.0000) | Acc: (94.00%) (3742/3968)
Epoch: 122 | Batch_idx: 40 |  Loss: (0.1661) |  Loss2: (0.0000) | Acc: (94.00%) (4942/5248)
Epoch: 122 | Batch_idx: 50 |  Loss: (0.1680) |  Loss2: (0.0000) | Acc: (94.00%) (6146/6528)
Epoch: 122 | Batch_idx: 60 |  Loss: (0.1675) |  Loss2: (0.0000) | Acc: (94.00%) (7360/7808)
Epoch: 122 | Batch_idx: 70 |  Loss: (0.1676) |  Loss2: (0.0000) | Acc: (94.00%) (8565/9088)
Epoch: 122 | Batch_idx: 80 |  Loss: (0.1683) |  Loss2: (0.0000) | Acc: (94.00%) (9769/10368)
Epoch: 122 | Batch_idx: 90 |  Loss: (0.1681) |  Loss2: (0.0000) | Acc: (94.00%) (10963/11648)
Epoch: 122 | Batch_idx: 100 |  Loss: (0.1682) |  Loss2: (0.0000) | Acc: (94.00%) (12164/12928)
Epoch: 122 | Batch_idx: 110 |  Loss: (0.1657) |  Loss2: (0.0000) | Acc: (94.00%) (13386/14208)
Epoch: 122 | Batch_idx: 120 |  Loss: (0.1654) |  Loss2: (0.0000) | Acc: (94.00%) (14610/15488)
Epoch: 122 | Batch_idx: 130 |  Loss: (0.1639) |  Loss2: (0.0000) | Acc: (94.00%) (15833/16768)
Epoch: 122 | Batch_idx: 140 |  Loss: (0.1625) |  Loss2: (0.0000) | Acc: (94.00%) (17054/18048)
Epoch: 122 | Batch_idx: 150 |  Loss: (0.1620) |  Loss2: (0.0000) | Acc: (94.00%) (18263/19328)
Epoch: 122 | Batch_idx: 160 |  Loss: (0.1619) |  Loss2: (0.0000) | Acc: (94.00%) (19477/20608)
Epoch: 122 | Batch_idx: 170 |  Loss: (0.1612) |  Loss2: (0.0000) | Acc: (94.00%) (20689/21888)
Epoch: 122 | Batch_idx: 180 |  Loss: (0.1602) |  Loss2: (0.0000) | Acc: (94.00%) (21905/23168)
Epoch: 122 | Batch_idx: 190 |  Loss: (0.1598) |  Loss2: (0.0000) | Acc: (94.00%) (23122/24448)
Epoch: 122 | Batch_idx: 200 |  Loss: (0.1601) |  Loss2: (0.0000) | Acc: (94.00%) (24325/25728)
Epoch: 122 | Batch_idx: 210 |  Loss: (0.1594) |  Loss2: (0.0000) | Acc: (94.00%) (25550/27008)
Epoch: 122 | Batch_idx: 220 |  Loss: (0.1592) |  Loss2: (0.0000) | Acc: (94.00%) (26766/28288)
Epoch: 122 | Batch_idx: 230 |  Loss: (0.1598) |  Loss2: (0.0000) | Acc: (94.00%) (27969/29568)
Epoch: 122 | Batch_idx: 240 |  Loss: (0.1601) |  Loss2: (0.0000) | Acc: (94.00%) (29185/30848)
Epoch: 122 | Batch_idx: 250 |  Loss: (0.1597) |  Loss2: (0.0000) | Acc: (94.00%) (30404/32128)
Epoch: 122 | Batch_idx: 260 |  Loss: (0.1594) |  Loss2: (0.0000) | Acc: (94.00%) (31617/33408)
Epoch: 122 | Batch_idx: 270 |  Loss: (0.1589) |  Loss2: (0.0000) | Acc: (94.00%) (32839/34688)
Epoch: 122 | Batch_idx: 280 |  Loss: (0.1593) |  Loss2: (0.0000) | Acc: (94.00%) (34044/35968)
Epoch: 122 | Batch_idx: 290 |  Loss: (0.1590) |  Loss2: (0.0000) | Acc: (94.00%) (35266/37248)
Epoch: 122 | Batch_idx: 300 |  Loss: (0.1583) |  Loss2: (0.0000) | Acc: (94.00%) (36484/38528)
Epoch: 122 | Batch_idx: 310 |  Loss: (0.1580) |  Loss2: (0.0000) | Acc: (94.00%) (37706/39808)
Epoch: 122 | Batch_idx: 320 |  Loss: (0.1582) |  Loss2: (0.0000) | Acc: (94.00%) (38908/41088)
Epoch: 122 | Batch_idx: 330 |  Loss: (0.1580) |  Loss2: (0.0000) | Acc: (94.00%) (40121/42368)
Epoch: 122 | Batch_idx: 340 |  Loss: (0.1580) |  Loss2: (0.0000) | Acc: (94.00%) (41334/43648)
Epoch: 122 | Batch_idx: 350 |  Loss: (0.1586) |  Loss2: (0.0000) | Acc: (94.00%) (42528/44928)
Epoch: 122 | Batch_idx: 360 |  Loss: (0.1587) |  Loss2: (0.0000) | Acc: (94.00%) (43734/46208)
Epoch: 122 | Batch_idx: 370 |  Loss: (0.1584) |  Loss2: (0.0000) | Acc: (94.00%) (44948/47488)
Epoch: 122 | Batch_idx: 380 |  Loss: (0.1577) |  Loss2: (0.0000) | Acc: (94.00%) (46177/48768)
Epoch: 122 | Batch_idx: 390 |  Loss: (0.1575) |  Loss2: (0.0000) | Acc: (94.00%) (47346/50000)
# TEST : Loss: (0.3787) | Acc: (88.00%) (8841/10000)
percent tensor([0.5502, 0.5590, 0.5869, 0.5726, 0.5870, 0.5542, 0.5702, 0.5785, 0.5602,
        0.5665, 0.5489, 0.5812, 0.5528, 0.5570, 0.5585, 0.5522],
       device='cuda:0') torch.Size([16])
percent tensor([0.5636, 0.5657, 0.5560, 0.5496, 0.5627, 0.5661, 0.5700, 0.5618, 0.5602,
        0.5606, 0.5655, 0.5651, 0.5638, 0.5589, 0.5708, 0.5632],
       device='cuda:0') torch.Size([16])
percent tensor([0.6016, 0.6042, 0.5752, 0.5539, 0.5591, 0.5741, 0.5934, 0.5685, 0.5886,
        0.6033, 0.5973, 0.5918, 0.6244, 0.5902, 0.5943, 0.6005],
       device='cuda:0') torch.Size([16])
percent tensor([0.6294, 0.6321, 0.6006, 0.6019, 0.6087, 0.6366, 0.6325, 0.6055, 0.6180,
        0.6307, 0.6323, 0.6172, 0.6305, 0.6304, 0.6348, 0.6325],
       device='cuda:0') torch.Size([16])
percent tensor([0.5196, 0.5257, 0.5950, 0.6124, 0.6104, 0.5154, 0.5538, 0.6224, 0.5571,
        0.5386, 0.5419, 0.5508, 0.4510, 0.6129, 0.5665, 0.5287],
       device='cuda:0') torch.Size([16])
percent tensor([0.5538, 0.6351, 0.6564, 0.6341, 0.6556, 0.6782, 0.6141, 0.5820, 0.6447,
        0.5933, 0.6623, 0.6094, 0.6270, 0.6561, 0.5040, 0.5506],
       device='cuda:0') torch.Size([16])
percent tensor([0.6545, 0.6661, 0.6945, 0.6338, 0.6867, 0.6903, 0.6919, 0.6269, 0.6644,
        0.6641, 0.6778, 0.6192, 0.6669, 0.6883, 0.5785, 0.6242],
       device='cuda:0') torch.Size([16])
percent tensor([0.9996, 0.9992, 0.9999, 0.9995, 0.9999, 0.9995, 0.9999, 0.9999, 0.9998,
        0.9996, 0.9997, 0.9993, 0.9996, 0.9996, 0.9995, 0.9994],
       device='cuda:0') torch.Size([16])
Epoch: 123 | Batch_idx: 0 |  Loss: (0.1230) |  Loss2: (0.0000) | Acc: (96.00%) (123/128)
Epoch: 123 | Batch_idx: 10 |  Loss: (0.1602) |  Loss2: (0.0000) | Acc: (94.00%) (1337/1408)
Epoch: 123 | Batch_idx: 20 |  Loss: (0.1542) |  Loss2: (0.0000) | Acc: (94.00%) (2550/2688)
Epoch: 123 | Batch_idx: 30 |  Loss: (0.1566) |  Loss2: (0.0000) | Acc: (94.00%) (3757/3968)
Epoch: 123 | Batch_idx: 40 |  Loss: (0.1577) |  Loss2: (0.0000) | Acc: (94.00%) (4966/5248)
Epoch: 123 | Batch_idx: 50 |  Loss: (0.1579) |  Loss2: (0.0000) | Acc: (94.00%) (6183/6528)
Epoch: 123 | Batch_idx: 60 |  Loss: (0.1554) |  Loss2: (0.0000) | Acc: (94.00%) (7405/7808)
Epoch: 123 | Batch_idx: 70 |  Loss: (0.1582) |  Loss2: (0.0000) | Acc: (94.00%) (8605/9088)
Epoch: 123 | Batch_idx: 80 |  Loss: (0.1581) |  Loss2: (0.0000) | Acc: (94.00%) (9822/10368)
Epoch: 123 | Batch_idx: 90 |  Loss: (0.1574) |  Loss2: (0.0000) | Acc: (94.00%) (11031/11648)
Epoch: 123 | Batch_idx: 100 |  Loss: (0.1584) |  Loss2: (0.0000) | Acc: (94.00%) (12236/12928)
Epoch: 123 | Batch_idx: 110 |  Loss: (0.1580) |  Loss2: (0.0000) | Acc: (94.00%) (13448/14208)
Epoch: 123 | Batch_idx: 120 |  Loss: (0.1558) |  Loss2: (0.0000) | Acc: (94.00%) (14678/15488)
Epoch: 123 | Batch_idx: 130 |  Loss: (0.1575) |  Loss2: (0.0000) | Acc: (94.00%) (15883/16768)
Epoch: 123 | Batch_idx: 140 |  Loss: (0.1573) |  Loss2: (0.0000) | Acc: (94.00%) (17102/18048)
Epoch: 123 | Batch_idx: 150 |  Loss: (0.1570) |  Loss2: (0.0000) | Acc: (94.00%) (18313/19328)
Epoch: 123 | Batch_idx: 160 |  Loss: (0.1569) |  Loss2: (0.0000) | Acc: (94.00%) (19530/20608)
Epoch: 123 | Batch_idx: 170 |  Loss: (0.1560) |  Loss2: (0.0000) | Acc: (94.00%) (20750/21888)
Epoch: 123 | Batch_idx: 180 |  Loss: (0.1564) |  Loss2: (0.0000) | Acc: (94.00%) (21960/23168)
Epoch: 123 | Batch_idx: 190 |  Loss: (0.1566) |  Loss2: (0.0000) | Acc: (94.00%) (23176/24448)
Epoch: 123 | Batch_idx: 200 |  Loss: (0.1566) |  Loss2: (0.0000) | Acc: (94.00%) (24389/25728)
Epoch: 123 | Batch_idx: 210 |  Loss: (0.1557) |  Loss2: (0.0000) | Acc: (94.00%) (25606/27008)
Epoch: 123 | Batch_idx: 220 |  Loss: (0.1548) |  Loss2: (0.0000) | Acc: (94.00%) (26829/28288)
Epoch: 123 | Batch_idx: 230 |  Loss: (0.1546) |  Loss2: (0.0000) | Acc: (94.00%) (28047/29568)
Epoch: 123 | Batch_idx: 240 |  Loss: (0.1545) |  Loss2: (0.0000) | Acc: (94.00%) (29269/30848)
Epoch: 123 | Batch_idx: 250 |  Loss: (0.1551) |  Loss2: (0.0000) | Acc: (94.00%) (30490/32128)
Epoch: 123 | Batch_idx: 260 |  Loss: (0.1560) |  Loss2: (0.0000) | Acc: (94.00%) (31690/33408)
Epoch: 123 | Batch_idx: 270 |  Loss: (0.1562) |  Loss2: (0.0000) | Acc: (94.00%) (32907/34688)
Epoch: 123 | Batch_idx: 280 |  Loss: (0.1569) |  Loss2: (0.0000) | Acc: (94.00%) (34110/35968)
Epoch: 123 | Batch_idx: 290 |  Loss: (0.1573) |  Loss2: (0.0000) | Acc: (94.00%) (35317/37248)
Epoch: 123 | Batch_idx: 300 |  Loss: (0.1572) |  Loss2: (0.0000) | Acc: (94.00%) (36526/38528)
Epoch: 123 | Batch_idx: 310 |  Loss: (0.1571) |  Loss2: (0.0000) | Acc: (94.00%) (37747/39808)
Epoch: 123 | Batch_idx: 320 |  Loss: (0.1570) |  Loss2: (0.0000) | Acc: (94.00%) (38964/41088)
Epoch: 123 | Batch_idx: 330 |  Loss: (0.1561) |  Loss2: (0.0000) | Acc: (94.00%) (40192/42368)
Epoch: 123 | Batch_idx: 340 |  Loss: (0.1565) |  Loss2: (0.0000) | Acc: (94.00%) (41400/43648)
Epoch: 123 | Batch_idx: 350 |  Loss: (0.1559) |  Loss2: (0.0000) | Acc: (94.00%) (42620/44928)
Epoch: 123 | Batch_idx: 360 |  Loss: (0.1558) |  Loss2: (0.0000) | Acc: (94.00%) (43841/46208)
Epoch: 123 | Batch_idx: 370 |  Loss: (0.1554) |  Loss2: (0.0000) | Acc: (94.00%) (45062/47488)
Epoch: 123 | Batch_idx: 380 |  Loss: (0.1565) |  Loss2: (0.0000) | Acc: (94.00%) (46259/48768)
Epoch: 123 | Batch_idx: 390 |  Loss: (0.1566) |  Loss2: (0.0000) | Acc: (94.00%) (47420/50000)
# TEST : Loss: (0.3780) | Acc: (88.00%) (8835/10000)
percent tensor([0.5522, 0.5611, 0.5901, 0.5750, 0.5902, 0.5558, 0.5728, 0.5813, 0.5625,
        0.5690, 0.5507, 0.5843, 0.5549, 0.5588, 0.5604, 0.5542],
       device='cuda:0') torch.Size([16])
percent tensor([0.5642, 0.5668, 0.5570, 0.5503, 0.5637, 0.5664, 0.5712, 0.5628, 0.5611,
        0.5618, 0.5664, 0.5663, 0.5646, 0.5598, 0.5714, 0.5639],
       device='cuda:0') torch.Size([16])
percent tensor([0.5986, 0.6022, 0.5728, 0.5520, 0.5560, 0.5710, 0.5904, 0.5653, 0.5864,
        0.6016, 0.5951, 0.5895, 0.6220, 0.5892, 0.5905, 0.5983],
       device='cuda:0') torch.Size([16])
percent tensor([0.6371, 0.6399, 0.6083, 0.6095, 0.6166, 0.6429, 0.6409, 0.6140, 0.6256,
        0.6388, 0.6398, 0.6254, 0.6378, 0.6382, 0.6428, 0.6400],
       device='cuda:0') torch.Size([16])
percent tensor([0.5186, 0.5218, 0.5987, 0.6190, 0.6163, 0.5177, 0.5532, 0.6275, 0.5569,
        0.5365, 0.5397, 0.5525, 0.4467, 0.6119, 0.5646, 0.5288],
       device='cuda:0') torch.Size([16])
percent tensor([0.5539, 0.6398, 0.6582, 0.6342, 0.6573, 0.6819, 0.6151, 0.5802, 0.6470,
        0.5928, 0.6656, 0.6087, 0.6328, 0.6569, 0.5031, 0.5494],
       device='cuda:0') torch.Size([16])
percent tensor([0.6641, 0.6747, 0.6988, 0.6371, 0.6894, 0.6987, 0.6980, 0.6292, 0.6721,
        0.6708, 0.6867, 0.6213, 0.6768, 0.6953, 0.5829, 0.6316],
       device='cuda:0') torch.Size([16])
percent tensor([0.9996, 0.9993, 0.9999, 0.9996, 0.9999, 0.9995, 0.9999, 0.9999, 0.9998,
        0.9996, 0.9997, 0.9993, 0.9996, 0.9997, 0.9995, 0.9994],
       device='cuda:0') torch.Size([16])
Epoch: 124 | Batch_idx: 0 |  Loss: (0.1980) |  Loss2: (0.0000) | Acc: (93.00%) (120/128)
Epoch: 124 | Batch_idx: 10 |  Loss: (0.1737) |  Loss2: (0.0000) | Acc: (93.00%) (1320/1408)
Epoch: 124 | Batch_idx: 20 |  Loss: (0.1673) |  Loss2: (0.0000) | Acc: (94.00%) (2532/2688)
Epoch: 124 | Batch_idx: 30 |  Loss: (0.1673) |  Loss2: (0.0000) | Acc: (94.00%) (3741/3968)
Epoch: 124 | Batch_idx: 40 |  Loss: (0.1623) |  Loss2: (0.0000) | Acc: (94.00%) (4960/5248)
Epoch: 124 | Batch_idx: 50 |  Loss: (0.1580) |  Loss2: (0.0000) | Acc: (94.00%) (6179/6528)
Epoch: 124 | Batch_idx: 60 |  Loss: (0.1566) |  Loss2: (0.0000) | Acc: (94.00%) (7398/7808)
Epoch: 124 | Batch_idx: 70 |  Loss: (0.1579) |  Loss2: (0.0000) | Acc: (94.00%) (8598/9088)
Epoch: 124 | Batch_idx: 80 |  Loss: (0.1568) |  Loss2: (0.0000) | Acc: (94.00%) (9813/10368)
Epoch: 124 | Batch_idx: 90 |  Loss: (0.1595) |  Loss2: (0.0000) | Acc: (94.00%) (11011/11648)
Epoch: 124 | Batch_idx: 100 |  Loss: (0.1591) |  Loss2: (0.0000) | Acc: (94.00%) (12228/12928)
Epoch: 124 | Batch_idx: 110 |  Loss: (0.1585) |  Loss2: (0.0000) | Acc: (94.00%) (13441/14208)
Epoch: 124 | Batch_idx: 120 |  Loss: (0.1569) |  Loss2: (0.0000) | Acc: (94.00%) (14659/15488)
Epoch: 124 | Batch_idx: 130 |  Loss: (0.1562) |  Loss2: (0.0000) | Acc: (94.00%) (15878/16768)
Epoch: 124 | Batch_idx: 140 |  Loss: (0.1558) |  Loss2: (0.0000) | Acc: (94.00%) (17088/18048)
Epoch: 124 | Batch_idx: 150 |  Loss: (0.1568) |  Loss2: (0.0000) | Acc: (94.00%) (18295/19328)
Epoch: 124 | Batch_idx: 160 |  Loss: (0.1577) |  Loss2: (0.0000) | Acc: (94.00%) (19492/20608)
Epoch: 124 | Batch_idx: 170 |  Loss: (0.1588) |  Loss2: (0.0000) | Acc: (94.00%) (20703/21888)
Epoch: 124 | Batch_idx: 180 |  Loss: (0.1573) |  Loss2: (0.0000) | Acc: (94.00%) (21930/23168)
Epoch: 124 | Batch_idx: 190 |  Loss: (0.1564) |  Loss2: (0.0000) | Acc: (94.00%) (23150/24448)
Epoch: 124 | Batch_idx: 200 |  Loss: (0.1542) |  Loss2: (0.0000) | Acc: (94.00%) (24381/25728)
Epoch: 124 | Batch_idx: 210 |  Loss: (0.1539) |  Loss2: (0.0000) | Acc: (94.00%) (25594/27008)
Epoch: 124 | Batch_idx: 220 |  Loss: (0.1542) |  Loss2: (0.0000) | Acc: (94.00%) (26809/28288)
Epoch: 124 | Batch_idx: 230 |  Loss: (0.1531) |  Loss2: (0.0000) | Acc: (94.00%) (28031/29568)
Epoch: 124 | Batch_idx: 240 |  Loss: (0.1539) |  Loss2: (0.0000) | Acc: (94.00%) (29236/30848)
Epoch: 124 | Batch_idx: 250 |  Loss: (0.1540) |  Loss2: (0.0000) | Acc: (94.00%) (30451/32128)
Epoch: 124 | Batch_idx: 260 |  Loss: (0.1540) |  Loss2: (0.0000) | Acc: (94.00%) (31661/33408)
Epoch: 124 | Batch_idx: 270 |  Loss: (0.1537) |  Loss2: (0.0000) | Acc: (94.00%) (32874/34688)
Epoch: 124 | Batch_idx: 280 |  Loss: (0.1539) |  Loss2: (0.0000) | Acc: (94.00%) (34087/35968)
Epoch: 124 | Batch_idx: 290 |  Loss: (0.1547) |  Loss2: (0.0000) | Acc: (94.00%) (35280/37248)
Epoch: 124 | Batch_idx: 300 |  Loss: (0.1544) |  Loss2: (0.0000) | Acc: (94.00%) (36497/38528)
Epoch: 124 | Batch_idx: 310 |  Loss: (0.1542) |  Loss2: (0.0000) | Acc: (94.00%) (37714/39808)
Epoch: 124 | Batch_idx: 320 |  Loss: (0.1543) |  Loss2: (0.0000) | Acc: (94.00%) (38927/41088)
Epoch: 124 | Batch_idx: 330 |  Loss: (0.1541) |  Loss2: (0.0000) | Acc: (94.00%) (40153/42368)
Epoch: 124 | Batch_idx: 340 |  Loss: (0.1541) |  Loss2: (0.0000) | Acc: (94.00%) (41372/43648)
Epoch: 124 | Batch_idx: 350 |  Loss: (0.1541) |  Loss2: (0.0000) | Acc: (94.00%) (42590/44928)
Epoch: 124 | Batch_idx: 360 |  Loss: (0.1538) |  Loss2: (0.0000) | Acc: (94.00%) (43804/46208)
Epoch: 124 | Batch_idx: 370 |  Loss: (0.1535) |  Loss2: (0.0000) | Acc: (94.00%) (45024/47488)
Epoch: 124 | Batch_idx: 380 |  Loss: (0.1535) |  Loss2: (0.0000) | Acc: (94.00%) (46239/48768)
Epoch: 124 | Batch_idx: 390 |  Loss: (0.1537) |  Loss2: (0.0000) | Acc: (94.00%) (47404/50000)
# TEST : Loss: (0.3761) | Acc: (88.00%) (8841/10000)
percent tensor([0.5523, 0.5612, 0.5909, 0.5756, 0.5910, 0.5557, 0.5732, 0.5818, 0.5626,
        0.5695, 0.5507, 0.5850, 0.5550, 0.5589, 0.5606, 0.5544],
       device='cuda:0') torch.Size([16])
percent tensor([0.5667, 0.5699, 0.5594, 0.5526, 0.5664, 0.5685, 0.5743, 0.5655, 0.5639,
        0.5648, 0.5694, 0.5693, 0.5675, 0.5627, 0.5741, 0.5665],
       device='cuda:0') torch.Size([16])
percent tensor([0.6020, 0.6073, 0.5752, 0.5536, 0.5578, 0.5727, 0.5942, 0.5671, 0.5898,
        0.6068, 0.5999, 0.5929, 0.6269, 0.5941, 0.5935, 0.6021],
       device='cuda:0') torch.Size([16])
percent tensor([0.6363, 0.6397, 0.6079, 0.6087, 0.6160, 0.6409, 0.6406, 0.6138, 0.6251,
        0.6387, 0.6395, 0.6252, 0.6374, 0.6377, 0.6421, 0.6389],
       device='cuda:0') torch.Size([16])
percent tensor([0.5119, 0.5172, 0.5916, 0.6105, 0.6096, 0.5096, 0.5470, 0.6196, 0.5497,
        0.5313, 0.5335, 0.5469, 0.4415, 0.6051, 0.5578, 0.5227],
       device='cuda:0') torch.Size([16])
percent tensor([0.5503, 0.6362, 0.6532, 0.6271, 0.6514, 0.6797, 0.6098, 0.5733, 0.6424,
        0.5902, 0.6628, 0.6036, 0.6307, 0.6542, 0.4975, 0.5453],
       device='cuda:0') torch.Size([16])
percent tensor([0.6662, 0.6760, 0.6965, 0.6356, 0.6882, 0.6998, 0.6996, 0.6298, 0.6734,
        0.6730, 0.6880, 0.6219, 0.6786, 0.6974, 0.5865, 0.6344],
       device='cuda:0') torch.Size([16])
percent tensor([0.9996, 0.9993, 0.9999, 0.9996, 0.9999, 0.9995, 0.9999, 0.9999, 0.9998,
        0.9997, 0.9997, 0.9993, 0.9996, 0.9997, 0.9995, 0.9993],
       device='cuda:0') torch.Size([16])
Epoch: 125 | Batch_idx: 0 |  Loss: (0.2319) |  Loss2: (0.0000) | Acc: (93.00%) (120/128)
Epoch: 125 | Batch_idx: 10 |  Loss: (0.1726) |  Loss2: (0.0000) | Acc: (94.00%) (1329/1408)
Epoch: 125 | Batch_idx: 20 |  Loss: (0.1592) |  Loss2: (0.0000) | Acc: (94.00%) (2548/2688)
Epoch: 125 | Batch_idx: 30 |  Loss: (0.1547) |  Loss2: (0.0000) | Acc: (94.00%) (3767/3968)
Epoch: 125 | Batch_idx: 40 |  Loss: (0.1475) |  Loss2: (0.0000) | Acc: (95.00%) (4998/5248)
Epoch: 125 | Batch_idx: 50 |  Loss: (0.1438) |  Loss2: (0.0000) | Acc: (95.00%) (6223/6528)
Epoch: 125 | Batch_idx: 60 |  Loss: (0.1456) |  Loss2: (0.0000) | Acc: (95.00%) (7443/7808)
Epoch: 125 | Batch_idx: 70 |  Loss: (0.1457) |  Loss2: (0.0000) | Acc: (95.00%) (8659/9088)
Epoch: 125 | Batch_idx: 80 |  Loss: (0.1471) |  Loss2: (0.0000) | Acc: (95.00%) (9875/10368)
Epoch: 125 | Batch_idx: 90 |  Loss: (0.1468) |  Loss2: (0.0000) | Acc: (95.00%) (11094/11648)
Epoch: 125 | Batch_idx: 100 |  Loss: (0.1483) |  Loss2: (0.0000) | Acc: (95.00%) (12304/12928)
Epoch: 125 | Batch_idx: 110 |  Loss: (0.1486) |  Loss2: (0.0000) | Acc: (95.00%) (13531/14208)
Epoch: 125 | Batch_idx: 120 |  Loss: (0.1499) |  Loss2: (0.0000) | Acc: (95.00%) (14740/15488)
Epoch: 125 | Batch_idx: 130 |  Loss: (0.1504) |  Loss2: (0.0000) | Acc: (95.00%) (15953/16768)
Epoch: 125 | Batch_idx: 140 |  Loss: (0.1504) |  Loss2: (0.0000) | Acc: (95.00%) (17172/18048)
Epoch: 125 | Batch_idx: 150 |  Loss: (0.1509) |  Loss2: (0.0000) | Acc: (95.00%) (18382/19328)
Epoch: 125 | Batch_idx: 160 |  Loss: (0.1509) |  Loss2: (0.0000) | Acc: (95.00%) (19600/20608)
Epoch: 125 | Batch_idx: 170 |  Loss: (0.1505) |  Loss2: (0.0000) | Acc: (95.00%) (20815/21888)
Epoch: 125 | Batch_idx: 180 |  Loss: (0.1501) |  Loss2: (0.0000) | Acc: (95.00%) (22036/23168)
Epoch: 125 | Batch_idx: 190 |  Loss: (0.1504) |  Loss2: (0.0000) | Acc: (95.00%) (23251/24448)
Epoch: 125 | Batch_idx: 200 |  Loss: (0.1509) |  Loss2: (0.0000) | Acc: (95.00%) (24463/25728)
Epoch: 125 | Batch_idx: 210 |  Loss: (0.1501) |  Loss2: (0.0000) | Acc: (95.00%) (25681/27008)
Epoch: 125 | Batch_idx: 220 |  Loss: (0.1499) |  Loss2: (0.0000) | Acc: (95.00%) (26899/28288)
Epoch: 125 | Batch_idx: 230 |  Loss: (0.1506) |  Loss2: (0.0000) | Acc: (95.00%) (28108/29568)
Epoch: 125 | Batch_idx: 240 |  Loss: (0.1510) |  Loss2: (0.0000) | Acc: (95.00%) (29324/30848)
Epoch: 125 | Batch_idx: 250 |  Loss: (0.1508) |  Loss2: (0.0000) | Acc: (95.00%) (30537/32128)
Epoch: 125 | Batch_idx: 260 |  Loss: (0.1511) |  Loss2: (0.0000) | Acc: (95.00%) (31748/33408)
Epoch: 125 | Batch_idx: 270 |  Loss: (0.1503) |  Loss2: (0.0000) | Acc: (95.00%) (32980/34688)
Epoch: 125 | Batch_idx: 280 |  Loss: (0.1507) |  Loss2: (0.0000) | Acc: (95.00%) (34194/35968)
Epoch: 125 | Batch_idx: 290 |  Loss: (0.1509) |  Loss2: (0.0000) | Acc: (95.00%) (35409/37248)
Epoch: 125 | Batch_idx: 300 |  Loss: (0.1508) |  Loss2: (0.0000) | Acc: (95.00%) (36630/38528)
Epoch: 125 | Batch_idx: 310 |  Loss: (0.1507) |  Loss2: (0.0000) | Acc: (95.00%) (37845/39808)
Epoch: 125 | Batch_idx: 320 |  Loss: (0.1515) |  Loss2: (0.0000) | Acc: (95.00%) (39048/41088)
Epoch: 125 | Batch_idx: 330 |  Loss: (0.1518) |  Loss2: (0.0000) | Acc: (95.00%) (40263/42368)
Epoch: 125 | Batch_idx: 340 |  Loss: (0.1524) |  Loss2: (0.0000) | Acc: (95.00%) (41471/43648)
Epoch: 125 | Batch_idx: 350 |  Loss: (0.1526) |  Loss2: (0.0000) | Acc: (95.00%) (42682/44928)
Epoch: 125 | Batch_idx: 360 |  Loss: (0.1530) |  Loss2: (0.0000) | Acc: (94.00%) (43884/46208)
Epoch: 125 | Batch_idx: 370 |  Loss: (0.1529) |  Loss2: (0.0000) | Acc: (94.00%) (45103/47488)
Epoch: 125 | Batch_idx: 380 |  Loss: (0.1532) |  Loss2: (0.0000) | Acc: (94.00%) (46311/48768)
Epoch: 125 | Batch_idx: 390 |  Loss: (0.1536) |  Loss2: (0.0000) | Acc: (94.00%) (47462/50000)
=> saving checkpoint 'drive/app/torch/save_Schedule/checkpoint_125.pth.tar'
# TEST : Loss: (0.3762) | Acc: (88.00%) (8858/10000)
percent tensor([0.5511, 0.5602, 0.5896, 0.5747, 0.5897, 0.5546, 0.5720, 0.5808, 0.5615,
        0.5684, 0.5496, 0.5836, 0.5539, 0.5581, 0.5595, 0.5533],
       device='cuda:0') torch.Size([16])
percent tensor([0.5672, 0.5705, 0.5602, 0.5531, 0.5673, 0.5687, 0.5750, 0.5665, 0.5645,
        0.5656, 0.5699, 0.5703, 0.5681, 0.5633, 0.5746, 0.5669],
       device='cuda:0') torch.Size([16])
percent tensor([0.6035, 0.6091, 0.5774, 0.5554, 0.5583, 0.5733, 0.5954, 0.5681, 0.5907,
        0.6091, 0.6010, 0.5952, 0.6288, 0.5956, 0.5943, 0.6040],
       device='cuda:0') torch.Size([16])
percent tensor([0.6358, 0.6389, 0.6081, 0.6083, 0.6158, 0.6399, 0.6399, 0.6140, 0.6242,
        0.6377, 0.6383, 0.6249, 0.6363, 0.6365, 0.6417, 0.6380],
       device='cuda:0') torch.Size([16])
percent tensor([0.5166, 0.5202, 0.5995, 0.6187, 0.6167, 0.5133, 0.5522, 0.6261, 0.5564,
        0.5354, 0.5370, 0.5548, 0.4455, 0.6095, 0.5621, 0.5274],
       device='cuda:0') torch.Size([16])
percent tensor([0.5446, 0.6345, 0.6524, 0.6236, 0.6480, 0.6813, 0.6049, 0.5693, 0.6392,
        0.5843, 0.6602, 0.5983, 0.6270, 0.6518, 0.4885, 0.5392],
       device='cuda:0') torch.Size([16])
percent tensor([0.6693, 0.6786, 0.6964, 0.6350, 0.6868, 0.7056, 0.6997, 0.6255, 0.6769,
        0.6737, 0.6928, 0.6199, 0.6839, 0.7005, 0.5851, 0.6351],
       device='cuda:0') torch.Size([16])
percent tensor([0.9996, 0.9993, 0.9999, 0.9996, 0.9999, 0.9996, 0.9999, 0.9999, 0.9998,
        0.9997, 0.9998, 0.9994, 0.9996, 0.9997, 0.9995, 0.9994],
       device='cuda:0') torch.Size([16])
True Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=128, out_features=16, bias=False)
False Linear(in_features=16, out_features=2, bias=False)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=128, out_features=16, bias=False)
False Linear(in_features=16, out_features=2, bias=False)
True Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=256, out_features=32, bias=False)
False Linear(in_features=32, out_features=2, bias=False)
True Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=256, out_features=32, bias=False)
False Linear(in_features=32, out_features=2, bias=False)
True Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=512, out_features=64, bias=False)
False Linear(in_features=64, out_features=2, bias=False)
True Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=512, out_features=64, bias=False)
False Linear(in_features=64, out_features=2, bias=False)
True Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1024, out_features=128, bias=False)
False Linear(in_features=128, out_features=2, bias=False)
True Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1024, out_features=128, bias=False)
False Linear(in_features=128, out_features=2, bias=False)
True Linear(in_features=512, out_features=10, bias=True)
Epoch: 126 | Batch_idx: 0 |  Loss: (0.0891) |  Loss2: (0.0000) | Acc: (96.00%) (124/128)
Epoch: 126 | Batch_idx: 10 |  Loss: (0.1437) |  Loss2: (0.0000) | Acc: (94.00%) (1331/1408)
Epoch: 126 | Batch_idx: 20 |  Loss: (0.1714) |  Loss2: (0.0000) | Acc: (93.00%) (2526/2688)
Epoch: 126 | Batch_idx: 30 |  Loss: (0.1719) |  Loss2: (0.0000) | Acc: (93.00%) (3727/3968)
Epoch: 126 | Batch_idx: 40 |  Loss: (0.1667) |  Loss2: (0.0000) | Acc: (94.00%) (4946/5248)
Epoch: 126 | Batch_idx: 50 |  Loss: (0.1711) |  Loss2: (0.0000) | Acc: (94.00%) (6145/6528)
Epoch: 126 | Batch_idx: 60 |  Loss: (0.1675) |  Loss2: (0.0000) | Acc: (94.00%) (7360/7808)
Epoch: 126 | Batch_idx: 70 |  Loss: (0.1670) |  Loss2: (0.0000) | Acc: (94.00%) (8567/9088)
Epoch: 126 | Batch_idx: 80 |  Loss: (0.1672) |  Loss2: (0.0000) | Acc: (94.00%) (9768/10368)
Epoch: 126 | Batch_idx: 90 |  Loss: (0.1691) |  Loss2: (0.0000) | Acc: (94.00%) (10962/11648)
Epoch: 126 | Batch_idx: 100 |  Loss: (0.1675) |  Loss2: (0.0000) | Acc: (94.00%) (12183/12928)
Epoch: 126 | Batch_idx: 110 |  Loss: (0.1682) |  Loss2: (0.0000) | Acc: (94.00%) (13393/14208)
Epoch: 126 | Batch_idx: 120 |  Loss: (0.1705) |  Loss2: (0.0000) | Acc: (94.00%) (14581/15488)
Epoch: 126 | Batch_idx: 130 |  Loss: (0.1706) |  Loss2: (0.0000) | Acc: (94.00%) (15791/16768)
Epoch: 126 | Batch_idx: 140 |  Loss: (0.1709) |  Loss2: (0.0000) | Acc: (94.00%) (16992/18048)
Epoch: 126 | Batch_idx: 150 |  Loss: (0.1702) |  Loss2: (0.0000) | Acc: (94.00%) (18201/19328)
Epoch: 126 | Batch_idx: 160 |  Loss: (0.1701) |  Loss2: (0.0000) | Acc: (94.00%) (19396/20608)
Epoch: 126 | Batch_idx: 170 |  Loss: (0.1699) |  Loss2: (0.0000) | Acc: (94.00%) (20598/21888)
Epoch: 126 | Batch_idx: 180 |  Loss: (0.1710) |  Loss2: (0.0000) | Acc: (94.00%) (21800/23168)
Epoch: 126 | Batch_idx: 190 |  Loss: (0.1711) |  Loss2: (0.0000) | Acc: (94.00%) (23004/24448)
Epoch: 126 | Batch_idx: 200 |  Loss: (0.1709) |  Loss2: (0.0000) | Acc: (94.00%) (24218/25728)
Epoch: 126 | Batch_idx: 210 |  Loss: (0.1712) |  Loss2: (0.0000) | Acc: (94.00%) (25426/27008)
Epoch: 126 | Batch_idx: 220 |  Loss: (0.1721) |  Loss2: (0.0000) | Acc: (94.00%) (26629/28288)
Epoch: 126 | Batch_idx: 230 |  Loss: (0.1731) |  Loss2: (0.0000) | Acc: (94.00%) (27822/29568)
Epoch: 126 | Batch_idx: 240 |  Loss: (0.1733) |  Loss2: (0.0000) | Acc: (94.00%) (29019/30848)
Epoch: 126 | Batch_idx: 250 |  Loss: (0.1743) |  Loss2: (0.0000) | Acc: (94.00%) (30213/32128)
Epoch: 126 | Batch_idx: 260 |  Loss: (0.1748) |  Loss2: (0.0000) | Acc: (94.00%) (31413/33408)
Epoch: 126 | Batch_idx: 270 |  Loss: (0.1756) |  Loss2: (0.0000) | Acc: (93.00%) (32592/34688)
Epoch: 126 | Batch_idx: 280 |  Loss: (0.1751) |  Loss2: (0.0000) | Acc: (93.00%) (33800/35968)
Epoch: 126 | Batch_idx: 290 |  Loss: (0.1760) |  Loss2: (0.0000) | Acc: (93.00%) (34984/37248)
Epoch: 126 | Batch_idx: 300 |  Loss: (0.1759) |  Loss2: (0.0000) | Acc: (93.00%) (36189/38528)
Epoch: 126 | Batch_idx: 310 |  Loss: (0.1760) |  Loss2: (0.0000) | Acc: (93.00%) (37392/39808)
Epoch: 126 | Batch_idx: 320 |  Loss: (0.1764) |  Loss2: (0.0000) | Acc: (93.00%) (38582/41088)
Epoch: 126 | Batch_idx: 330 |  Loss: (0.1764) |  Loss2: (0.0000) | Acc: (93.00%) (39781/42368)
Epoch: 126 | Batch_idx: 340 |  Loss: (0.1769) |  Loss2: (0.0000) | Acc: (93.00%) (40970/43648)
Epoch: 126 | Batch_idx: 350 |  Loss: (0.1759) |  Loss2: (0.0000) | Acc: (93.00%) (42191/44928)
Epoch: 126 | Batch_idx: 360 |  Loss: (0.1759) |  Loss2: (0.0000) | Acc: (93.00%) (43384/46208)
Epoch: 126 | Batch_idx: 370 |  Loss: (0.1757) |  Loss2: (0.0000) | Acc: (93.00%) (44598/47488)
Epoch: 126 | Batch_idx: 380 |  Loss: (0.1756) |  Loss2: (0.0000) | Acc: (93.00%) (45806/48768)
Epoch: 126 | Batch_idx: 390 |  Loss: (0.1753) |  Loss2: (0.0000) | Acc: (93.00%) (46979/50000)
# TEST : Loss: (0.4365) | Acc: (86.00%) (8677/10000)
percent tensor([0.5510, 0.5606, 0.5904, 0.5751, 0.5894, 0.5533, 0.5719, 0.5825, 0.5606,
        0.5689, 0.5488, 0.5836, 0.5536, 0.5574, 0.5596, 0.5536],
       device='cuda:0') torch.Size([16])
percent tensor([0.5660, 0.5712, 0.5580, 0.5511, 0.5670, 0.5676, 0.5756, 0.5643, 0.5647,
        0.5648, 0.5697, 0.5690, 0.5676, 0.5648, 0.5742, 0.5661],
       device='cuda:0') torch.Size([16])
percent tensor([0.6051, 0.6127, 0.5737, 0.5504, 0.5528, 0.5774, 0.5960, 0.5655, 0.5900,
        0.6082, 0.6028, 0.5898, 0.6293, 0.5989, 0.5958, 0.6054],
       device='cuda:0') torch.Size([16])
percent tensor([0.6360, 0.6387, 0.6020, 0.6012, 0.6148, 0.6392, 0.6398, 0.6092, 0.6260,
        0.6371, 0.6405, 0.6203, 0.6354, 0.6367, 0.6404, 0.6369],
       device='cuda:0') torch.Size([16])
percent tensor([0.5280, 0.5102, 0.6153, 0.6218, 0.6327, 0.5220, 0.5581, 0.6372, 0.5634,
        0.5305, 0.5339, 0.5725, 0.4618, 0.5789, 0.5640, 0.5223],
       device='cuda:0') torch.Size([16])
percent tensor([0.5580, 0.6462, 0.6343, 0.6231, 0.6555, 0.6951, 0.6233, 0.5572, 0.6299,
        0.5917, 0.6546, 0.5898, 0.6278, 0.6629, 0.5057, 0.5536],
       device='cuda:0') torch.Size([16])
percent tensor([0.6754, 0.6838, 0.6845, 0.6430, 0.6894, 0.7108, 0.7082, 0.6395, 0.6641,
        0.6734, 0.6925, 0.6174, 0.6717, 0.6985, 0.5903, 0.6389],
       device='cuda:0') torch.Size([16])
percent tensor([0.9997, 0.9996, 0.9999, 0.9996, 0.9999, 0.9994, 0.9999, 0.9999, 0.9996,
        0.9999, 0.9997, 0.9995, 0.9995, 0.9996, 0.9996, 0.9995],
       device='cuda:0') torch.Size([16])
Epoch: 127 | Batch_idx: 0 |  Loss: (0.2313) |  Loss2: (0.0000) | Acc: (92.00%) (118/128)
Epoch: 127 | Batch_idx: 10 |  Loss: (0.1590) |  Loss2: (0.0000) | Acc: (94.00%) (1332/1408)
Epoch: 127 | Batch_idx: 20 |  Loss: (0.1683) |  Loss2: (0.0000) | Acc: (94.00%) (2534/2688)
Epoch: 127 | Batch_idx: 30 |  Loss: (0.1731) |  Loss2: (0.0000) | Acc: (94.00%) (3731/3968)
Epoch: 127 | Batch_idx: 40 |  Loss: (0.1736) |  Loss2: (0.0000) | Acc: (94.00%) (4938/5248)
Epoch: 127 | Batch_idx: 50 |  Loss: (0.1695) |  Loss2: (0.0000) | Acc: (94.00%) (6153/6528)
Epoch: 127 | Batch_idx: 60 |  Loss: (0.1678) |  Loss2: (0.0000) | Acc: (94.00%) (7362/7808)
Epoch: 127 | Batch_idx: 70 |  Loss: (0.1685) |  Loss2: (0.0000) | Acc: (94.00%) (8558/9088)
Epoch: 127 | Batch_idx: 80 |  Loss: (0.1665) |  Loss2: (0.0000) | Acc: (94.00%) (9774/10368)
Epoch: 127 | Batch_idx: 90 |  Loss: (0.1652) |  Loss2: (0.0000) | Acc: (94.00%) (10980/11648)
Epoch: 127 | Batch_idx: 100 |  Loss: (0.1664) |  Loss2: (0.0000) | Acc: (94.00%) (12176/12928)
Epoch: 127 | Batch_idx: 110 |  Loss: (0.1667) |  Loss2: (0.0000) | Acc: (94.00%) (13380/14208)
Epoch: 127 | Batch_idx: 120 |  Loss: (0.1688) |  Loss2: (0.0000) | Acc: (94.00%) (14577/15488)
Epoch: 127 | Batch_idx: 130 |  Loss: (0.1692) |  Loss2: (0.0000) | Acc: (94.00%) (15782/16768)
Epoch: 127 | Batch_idx: 140 |  Loss: (0.1679) |  Loss2: (0.0000) | Acc: (94.00%) (16999/18048)
Epoch: 127 | Batch_idx: 150 |  Loss: (0.1686) |  Loss2: (0.0000) | Acc: (94.00%) (18198/19328)
Epoch: 127 | Batch_idx: 160 |  Loss: (0.1687) |  Loss2: (0.0000) | Acc: (94.00%) (19401/20608)
Epoch: 127 | Batch_idx: 170 |  Loss: (0.1695) |  Loss2: (0.0000) | Acc: (94.00%) (20599/21888)
Epoch: 127 | Batch_idx: 180 |  Loss: (0.1687) |  Loss2: (0.0000) | Acc: (94.00%) (21813/23168)
Epoch: 127 | Batch_idx: 190 |  Loss: (0.1698) |  Loss2: (0.0000) | Acc: (94.00%) (23005/24448)
Epoch: 127 | Batch_idx: 200 |  Loss: (0.1696) |  Loss2: (0.0000) | Acc: (94.00%) (24220/25728)
Epoch: 127 | Batch_idx: 210 |  Loss: (0.1703) |  Loss2: (0.0000) | Acc: (94.00%) (25420/27008)
Epoch: 127 | Batch_idx: 220 |  Loss: (0.1700) |  Loss2: (0.0000) | Acc: (94.00%) (26628/28288)
Epoch: 127 | Batch_idx: 230 |  Loss: (0.1710) |  Loss2: (0.0000) | Acc: (94.00%) (27820/29568)
Epoch: 127 | Batch_idx: 240 |  Loss: (0.1713) |  Loss2: (0.0000) | Acc: (94.00%) (29028/30848)
Epoch: 127 | Batch_idx: 250 |  Loss: (0.1708) |  Loss2: (0.0000) | Acc: (94.00%) (30235/32128)
Epoch: 127 | Batch_idx: 260 |  Loss: (0.1715) |  Loss2: (0.0000) | Acc: (94.00%) (31432/33408)
Epoch: 127 | Batch_idx: 270 |  Loss: (0.1714) |  Loss2: (0.0000) | Acc: (94.00%) (32646/34688)
Epoch: 127 | Batch_idx: 280 |  Loss: (0.1715) |  Loss2: (0.0000) | Acc: (94.00%) (33847/35968)
Epoch: 127 | Batch_idx: 290 |  Loss: (0.1711) |  Loss2: (0.0000) | Acc: (94.00%) (35055/37248)
Epoch: 127 | Batch_idx: 300 |  Loss: (0.1710) |  Loss2: (0.0000) | Acc: (94.00%) (36261/38528)
Epoch: 127 | Batch_idx: 310 |  Loss: (0.1712) |  Loss2: (0.0000) | Acc: (94.00%) (37464/39808)
Epoch: 127 | Batch_idx: 320 |  Loss: (0.1709) |  Loss2: (0.0000) | Acc: (94.00%) (38666/41088)
Epoch: 127 | Batch_idx: 330 |  Loss: (0.1710) |  Loss2: (0.0000) | Acc: (94.00%) (39873/42368)
Epoch: 127 | Batch_idx: 340 |  Loss: (0.1710) |  Loss2: (0.0000) | Acc: (94.00%) (41080/43648)
Epoch: 127 | Batch_idx: 350 |  Loss: (0.1705) |  Loss2: (0.0000) | Acc: (94.00%) (42284/44928)
Epoch: 127 | Batch_idx: 360 |  Loss: (0.1704) |  Loss2: (0.0000) | Acc: (94.00%) (43490/46208)
Epoch: 127 | Batch_idx: 370 |  Loss: (0.1703) |  Loss2: (0.0000) | Acc: (94.00%) (44693/47488)
Epoch: 127 | Batch_idx: 380 |  Loss: (0.1705) |  Loss2: (0.0000) | Acc: (94.00%) (45887/48768)
Epoch: 127 | Batch_idx: 390 |  Loss: (0.1703) |  Loss2: (0.0000) | Acc: (94.00%) (47049/50000)
# TEST : Loss: (0.4180) | Acc: (86.00%) (8692/10000)
percent tensor([0.5502, 0.5633, 0.5863, 0.5749, 0.5858, 0.5517, 0.5720, 0.5818, 0.5608,
        0.5690, 0.5498, 0.5802, 0.5532, 0.5618, 0.5595, 0.5544],
       device='cuda:0') torch.Size([16])
percent tensor([0.5670, 0.5733, 0.5573, 0.5516, 0.5658, 0.5708, 0.5773, 0.5651, 0.5656,
        0.5659, 0.5711, 0.5696, 0.5685, 0.5670, 0.5767, 0.5670],
       device='cuda:0') torch.Size([16])
percent tensor([0.6012, 0.6099, 0.5723, 0.5510, 0.5532, 0.5746, 0.5955, 0.5656, 0.5877,
        0.6069, 0.5992, 0.5887, 0.6257, 0.6000, 0.5955, 0.6006],
       device='cuda:0') torch.Size([16])
percent tensor([0.6358, 0.6381, 0.6020, 0.6000, 0.6138, 0.6411, 0.6399, 0.6094, 0.6255,
        0.6358, 0.6385, 0.6212, 0.6346, 0.6377, 0.6432, 0.6370],
       device='cuda:0') torch.Size([16])
percent tensor([0.5395, 0.5037, 0.6204, 0.6182, 0.6307, 0.5275, 0.5654, 0.6269, 0.5806,
        0.5275, 0.5368, 0.5717, 0.4528, 0.5957, 0.5541, 0.5292],
       device='cuda:0') torch.Size([16])
percent tensor([0.5483, 0.6336, 0.6247, 0.5987, 0.6488, 0.6805, 0.6189, 0.5309, 0.6510,
        0.5790, 0.6593, 0.6040, 0.6359, 0.6625, 0.5046, 0.5274],
       device='cuda:0') torch.Size([16])
percent tensor([0.6734, 0.6785, 0.6775, 0.6436, 0.6951, 0.6950, 0.7136, 0.6360, 0.6799,
        0.6821, 0.6917, 0.6383, 0.6757, 0.6977, 0.5927, 0.6335],
       device='cuda:0') torch.Size([16])
percent tensor([0.9996, 0.9995, 0.9996, 0.9997, 0.9998, 0.9994, 0.9999, 0.9999, 0.9999,
        0.9999, 0.9997, 0.9996, 0.9996, 0.9996, 0.9996, 0.9994],
       device='cuda:0') torch.Size([16])
Epoch: 128 | Batch_idx: 0 |  Loss: (0.0966) |  Loss2: (0.0000) | Acc: (98.00%) (126/128)
Epoch: 128 | Batch_idx: 10 |  Loss: (0.1485) |  Loss2: (0.0000) | Acc: (95.00%) (1338/1408)
Epoch: 128 | Batch_idx: 20 |  Loss: (0.1498) |  Loss2: (0.0000) | Acc: (95.00%) (2557/2688)
Epoch: 128 | Batch_idx: 30 |  Loss: (0.1579) |  Loss2: (0.0000) | Acc: (94.00%) (3755/3968)
Epoch: 128 | Batch_idx: 40 |  Loss: (0.1584) |  Loss2: (0.0000) | Acc: (94.00%) (4959/5248)
Epoch: 128 | Batch_idx: 50 |  Loss: (0.1617) |  Loss2: (0.0000) | Acc: (94.00%) (6163/6528)
Epoch: 128 | Batch_idx: 60 |  Loss: (0.1641) |  Loss2: (0.0000) | Acc: (94.00%) (7362/7808)
Epoch: 128 | Batch_idx: 70 |  Loss: (0.1657) |  Loss2: (0.0000) | Acc: (94.00%) (8560/9088)
Epoch: 128 | Batch_idx: 80 |  Loss: (0.1655) |  Loss2: (0.0000) | Acc: (94.00%) (9760/10368)
Epoch: 128 | Batch_idx: 90 |  Loss: (0.1668) |  Loss2: (0.0000) | Acc: (94.00%) (10966/11648)
Epoch: 128 | Batch_idx: 100 |  Loss: (0.1673) |  Loss2: (0.0000) | Acc: (94.00%) (12175/12928)
Epoch: 128 | Batch_idx: 110 |  Loss: (0.1663) |  Loss2: (0.0000) | Acc: (94.00%) (13389/14208)
Epoch: 128 | Batch_idx: 120 |  Loss: (0.1676) |  Loss2: (0.0000) | Acc: (94.00%) (14588/15488)
Epoch: 128 | Batch_idx: 130 |  Loss: (0.1667) |  Loss2: (0.0000) | Acc: (94.00%) (15798/16768)
Epoch: 128 | Batch_idx: 140 |  Loss: (0.1635) |  Loss2: (0.0000) | Acc: (94.00%) (17029/18048)
Epoch: 128 | Batch_idx: 150 |  Loss: (0.1648) |  Loss2: (0.0000) | Acc: (94.00%) (18226/19328)
Epoch: 128 | Batch_idx: 160 |  Loss: (0.1645) |  Loss2: (0.0000) | Acc: (94.00%) (19440/20608)
Epoch: 128 | Batch_idx: 170 |  Loss: (0.1652) |  Loss2: (0.0000) | Acc: (94.00%) (20639/21888)
Epoch: 128 | Batch_idx: 180 |  Loss: (0.1655) |  Loss2: (0.0000) | Acc: (94.00%) (21843/23168)
Epoch: 128 | Batch_idx: 190 |  Loss: (0.1667) |  Loss2: (0.0000) | Acc: (94.00%) (23030/24448)
Epoch: 128 | Batch_idx: 200 |  Loss: (0.1668) |  Loss2: (0.0000) | Acc: (94.00%) (24236/25728)
Epoch: 128 | Batch_idx: 210 |  Loss: (0.1680) |  Loss2: (0.0000) | Acc: (94.00%) (25430/27008)
Epoch: 128 | Batch_idx: 220 |  Loss: (0.1674) |  Loss2: (0.0000) | Acc: (94.00%) (26639/28288)
Epoch: 128 | Batch_idx: 230 |  Loss: (0.1667) |  Loss2: (0.0000) | Acc: (94.00%) (27860/29568)
Epoch: 128 | Batch_idx: 240 |  Loss: (0.1652) |  Loss2: (0.0000) | Acc: (94.00%) (29082/30848)
Epoch: 128 | Batch_idx: 250 |  Loss: (0.1660) |  Loss2: (0.0000) | Acc: (94.00%) (30277/32128)
Epoch: 128 | Batch_idx: 260 |  Loss: (0.1661) |  Loss2: (0.0000) | Acc: (94.00%) (31475/33408)
Epoch: 128 | Batch_idx: 270 |  Loss: (0.1657) |  Loss2: (0.0000) | Acc: (94.00%) (32688/34688)
Epoch: 128 | Batch_idx: 280 |  Loss: (0.1651) |  Loss2: (0.0000) | Acc: (94.00%) (33902/35968)
Epoch: 128 | Batch_idx: 290 |  Loss: (0.1647) |  Loss2: (0.0000) | Acc: (94.00%) (35120/37248)
Epoch: 128 | Batch_idx: 300 |  Loss: (0.1653) |  Loss2: (0.0000) | Acc: (94.00%) (36321/38528)
Epoch: 128 | Batch_idx: 310 |  Loss: (0.1659) |  Loss2: (0.0000) | Acc: (94.00%) (37521/39808)
Epoch: 128 | Batch_idx: 320 |  Loss: (0.1660) |  Loss2: (0.0000) | Acc: (94.00%) (38722/41088)
Epoch: 128 | Batch_idx: 330 |  Loss: (0.1660) |  Loss2: (0.0000) | Acc: (94.00%) (39923/42368)
Epoch: 128 | Batch_idx: 340 |  Loss: (0.1657) |  Loss2: (0.0000) | Acc: (94.00%) (41131/43648)
Epoch: 128 | Batch_idx: 350 |  Loss: (0.1653) |  Loss2: (0.0000) | Acc: (94.00%) (42349/44928)
Epoch: 128 | Batch_idx: 360 |  Loss: (0.1655) |  Loss2: (0.0000) | Acc: (94.00%) (43549/46208)
Epoch: 128 | Batch_idx: 370 |  Loss: (0.1653) |  Loss2: (0.0000) | Acc: (94.00%) (44761/47488)
Epoch: 128 | Batch_idx: 380 |  Loss: (0.1653) |  Loss2: (0.0000) | Acc: (94.00%) (45965/48768)
Epoch: 128 | Batch_idx: 390 |  Loss: (0.1654) |  Loss2: (0.0000) | Acc: (94.00%) (47128/50000)
# TEST : Loss: (0.4329) | Acc: (86.00%) (8694/10000)
percent tensor([0.5511, 0.5598, 0.5894, 0.5733, 0.5889, 0.5531, 0.5720, 0.5811, 0.5604,
        0.5683, 0.5483, 0.5841, 0.5531, 0.5583, 0.5583, 0.5529],
       device='cuda:0') torch.Size([16])
percent tensor([0.5670, 0.5723, 0.5586, 0.5536, 0.5662, 0.5678, 0.5755, 0.5665, 0.5643,
        0.5664, 0.5697, 0.5693, 0.5686, 0.5654, 0.5746, 0.5669],
       device='cuda:0') torch.Size([16])
percent tensor([0.6031, 0.6123, 0.5808, 0.5506, 0.5608, 0.5716, 0.5989, 0.5694, 0.5913,
        0.6098, 0.6011, 0.5973, 0.6286, 0.5994, 0.5955, 0.6021],
       device='cuda:0') torch.Size([16])
percent tensor([0.6360, 0.6386, 0.6074, 0.6066, 0.6164, 0.6351, 0.6379, 0.6144, 0.6247,
        0.6399, 0.6399, 0.6252, 0.6379, 0.6322, 0.6397, 0.6360],
       device='cuda:0') torch.Size([16])
percent tensor([0.5202, 0.5097, 0.5866, 0.6069, 0.6168, 0.5287, 0.5490, 0.6197, 0.5727,
        0.5130, 0.5291, 0.5449, 0.4438, 0.6078, 0.5546, 0.5338],
       device='cuda:0') torch.Size([16])
percent tensor([0.5489, 0.6504, 0.6630, 0.6220, 0.6595, 0.6958, 0.6358, 0.5706, 0.6438,
        0.5982, 0.6642, 0.6143, 0.6275, 0.6566, 0.5076, 0.5473],
       device='cuda:0') torch.Size([16])
percent tensor([0.6614, 0.6746, 0.6879, 0.6378, 0.6915, 0.7037, 0.7110, 0.6329, 0.6771,
        0.6671, 0.6852, 0.6249, 0.6753, 0.7066, 0.5851, 0.6341],
       device='cuda:0') torch.Size([16])
percent tensor([0.9995, 0.9994, 0.9997, 0.9995, 0.9998, 0.9992, 0.9998, 0.9999, 0.9997,
        0.9999, 0.9998, 0.9995, 0.9995, 0.9997, 0.9996, 0.9994],
       device='cuda:0') torch.Size([16])
Epoch: 129 | Batch_idx: 0 |  Loss: (0.1499) |  Loss2: (0.0000) | Acc: (94.00%) (121/128)
Epoch: 129 | Batch_idx: 10 |  Loss: (0.1708) |  Loss2: (0.0000) | Acc: (93.00%) (1321/1408)
Epoch: 129 | Batch_idx: 20 |  Loss: (0.1582) |  Loss2: (0.0000) | Acc: (94.00%) (2539/2688)
Epoch: 129 | Batch_idx: 30 |  Loss: (0.1553) |  Loss2: (0.0000) | Acc: (94.00%) (3749/3968)
Epoch: 129 | Batch_idx: 40 |  Loss: (0.1566) |  Loss2: (0.0000) | Acc: (94.00%) (4963/5248)
Epoch: 129 | Batch_idx: 50 |  Loss: (0.1566) |  Loss2: (0.0000) | Acc: (94.00%) (6173/6528)
Epoch: 129 | Batch_idx: 60 |  Loss: (0.1536) |  Loss2: (0.0000) | Acc: (94.00%) (7397/7808)
Epoch: 129 | Batch_idx: 70 |  Loss: (0.1549) |  Loss2: (0.0000) | Acc: (94.00%) (8614/9088)
Epoch: 129 | Batch_idx: 80 |  Loss: (0.1557) |  Loss2: (0.0000) | Acc: (94.00%) (9826/10368)
Epoch: 129 | Batch_idx: 90 |  Loss: (0.1552) |  Loss2: (0.0000) | Acc: (94.00%) (11038/11648)
Epoch: 129 | Batch_idx: 100 |  Loss: (0.1556) |  Loss2: (0.0000) | Acc: (94.00%) (12249/12928)
Epoch: 129 | Batch_idx: 110 |  Loss: (0.1552) |  Loss2: (0.0000) | Acc: (94.00%) (13464/14208)
Epoch: 129 | Batch_idx: 120 |  Loss: (0.1562) |  Loss2: (0.0000) | Acc: (94.00%) (14674/15488)
Epoch: 129 | Batch_idx: 130 |  Loss: (0.1556) |  Loss2: (0.0000) | Acc: (94.00%) (15899/16768)
Epoch: 129 | Batch_idx: 140 |  Loss: (0.1559) |  Loss2: (0.0000) | Acc: (94.00%) (17104/18048)
Epoch: 129 | Batch_idx: 150 |  Loss: (0.1565) |  Loss2: (0.0000) | Acc: (94.00%) (18311/19328)
Epoch: 129 | Batch_idx: 160 |  Loss: (0.1566) |  Loss2: (0.0000) | Acc: (94.00%) (19524/20608)
Epoch: 129 | Batch_idx: 170 |  Loss: (0.1568) |  Loss2: (0.0000) | Acc: (94.00%) (20732/21888)
Epoch: 129 | Batch_idx: 180 |  Loss: (0.1565) |  Loss2: (0.0000) | Acc: (94.00%) (21945/23168)
Epoch: 129 | Batch_idx: 190 |  Loss: (0.1563) |  Loss2: (0.0000) | Acc: (94.00%) (23155/24448)
Epoch: 129 | Batch_idx: 200 |  Loss: (0.1564) |  Loss2: (0.0000) | Acc: (94.00%) (24365/25728)
Epoch: 129 | Batch_idx: 210 |  Loss: (0.1566) |  Loss2: (0.0000) | Acc: (94.00%) (25568/27008)
Epoch: 129 | Batch_idx: 220 |  Loss: (0.1569) |  Loss2: (0.0000) | Acc: (94.00%) (26782/28288)
Epoch: 129 | Batch_idx: 230 |  Loss: (0.1572) |  Loss2: (0.0000) | Acc: (94.00%) (27994/29568)
Epoch: 129 | Batch_idx: 240 |  Loss: (0.1573) |  Loss2: (0.0000) | Acc: (94.00%) (29201/30848)
Epoch: 129 | Batch_idx: 250 |  Loss: (0.1577) |  Loss2: (0.0000) | Acc: (94.00%) (30405/32128)
Epoch: 129 | Batch_idx: 260 |  Loss: (0.1581) |  Loss2: (0.0000) | Acc: (94.00%) (31606/33408)
Epoch: 129 | Batch_idx: 270 |  Loss: (0.1588) |  Loss2: (0.0000) | Acc: (94.00%) (32808/34688)
Epoch: 129 | Batch_idx: 280 |  Loss: (0.1592) |  Loss2: (0.0000) | Acc: (94.00%) (34017/35968)
Epoch: 129 | Batch_idx: 290 |  Loss: (0.1602) |  Loss2: (0.0000) | Acc: (94.00%) (35213/37248)
Epoch: 129 | Batch_idx: 300 |  Loss: (0.1605) |  Loss2: (0.0000) | Acc: (94.00%) (36413/38528)
Epoch: 129 | Batch_idx: 310 |  Loss: (0.1611) |  Loss2: (0.0000) | Acc: (94.00%) (37611/39808)
Epoch: 129 | Batch_idx: 320 |  Loss: (0.1618) |  Loss2: (0.0000) | Acc: (94.00%) (38807/41088)
Epoch: 129 | Batch_idx: 330 |  Loss: (0.1620) |  Loss2: (0.0000) | Acc: (94.00%) (40013/42368)
Epoch: 129 | Batch_idx: 340 |  Loss: (0.1613) |  Loss2: (0.0000) | Acc: (94.00%) (41232/43648)
Epoch: 129 | Batch_idx: 350 |  Loss: (0.1613) |  Loss2: (0.0000) | Acc: (94.00%) (42441/44928)
Epoch: 129 | Batch_idx: 360 |  Loss: (0.1610) |  Loss2: (0.0000) | Acc: (94.00%) (43657/46208)
Epoch: 129 | Batch_idx: 370 |  Loss: (0.1608) |  Loss2: (0.0000) | Acc: (94.00%) (44877/47488)
Epoch: 129 | Batch_idx: 380 |  Loss: (0.1607) |  Loss2: (0.0000) | Acc: (94.00%) (46090/48768)
Epoch: 129 | Batch_idx: 390 |  Loss: (0.1613) |  Loss2: (0.0000) | Acc: (94.00%) (47244/50000)
# TEST : Loss: (0.4273) | Acc: (87.00%) (8712/10000)
percent tensor([0.5520, 0.5612, 0.5884, 0.5733, 0.5880, 0.5559, 0.5724, 0.5804, 0.5628,
        0.5677, 0.5509, 0.5822, 0.5541, 0.5601, 0.5600, 0.5539],
       device='cuda:0') torch.Size([16])
percent tensor([0.5680, 0.5711, 0.5600, 0.5537, 0.5675, 0.5692, 0.5751, 0.5670, 0.5652,
        0.5661, 0.5705, 0.5700, 0.5686, 0.5641, 0.5757, 0.5672],
       device='cuda:0') torch.Size([16])
percent tensor([0.6027, 0.6156, 0.5776, 0.5522, 0.5567, 0.5724, 0.5976, 0.5686, 0.5913,
        0.6107, 0.6029, 0.5952, 0.6280, 0.6019, 0.5955, 0.6035],
       device='cuda:0') torch.Size([16])
percent tensor([0.6382, 0.6365, 0.6070, 0.6054, 0.6187, 0.6407, 0.6378, 0.6136, 0.6262,
        0.6394, 0.6388, 0.6232, 0.6356, 0.6352, 0.6420, 0.6377],
       device='cuda:0') torch.Size([16])
percent tensor([0.5165, 0.5027, 0.6022, 0.6187, 0.6270, 0.5341, 0.5570, 0.6218, 0.5682,
        0.5151, 0.5240, 0.5513, 0.4383, 0.6149, 0.5557, 0.5283],
       device='cuda:0') torch.Size([16])
percent tensor([0.5385, 0.6379, 0.6532, 0.6172, 0.6602, 0.6672, 0.6334, 0.5766, 0.6384,
        0.5750, 0.6510, 0.6129, 0.6104, 0.6537, 0.4998, 0.5203],
       device='cuda:0') torch.Size([16])
percent tensor([0.6613, 0.6799, 0.6981, 0.6378, 0.6891, 0.6934, 0.7090, 0.6453, 0.6659,
        0.6626, 0.6879, 0.6280, 0.6612, 0.7075, 0.5862, 0.6236],
       device='cuda:0') torch.Size([16])
percent tensor([0.9997, 0.9995, 0.9998, 0.9996, 0.9997, 0.9997, 0.9998, 0.9999, 0.9996,
        0.9998, 0.9997, 0.9992, 0.9994, 0.9998, 0.9996, 0.9995],
       device='cuda:0') torch.Size([16])
Epoch: 130 | Batch_idx: 0 |  Loss: (0.2117) |  Loss2: (0.0000) | Acc: (90.00%) (116/128)
Epoch: 130 | Batch_idx: 10 |  Loss: (0.1449) |  Loss2: (0.0000) | Acc: (94.00%) (1330/1408)
Epoch: 130 | Batch_idx: 20 |  Loss: (0.1388) |  Loss2: (0.0000) | Acc: (94.00%) (2552/2688)
Epoch: 130 | Batch_idx: 30 |  Loss: (0.1463) |  Loss2: (0.0000) | Acc: (94.00%) (3762/3968)
Epoch: 130 | Batch_idx: 40 |  Loss: (0.1464) |  Loss2: (0.0000) | Acc: (95.00%) (4986/5248)
Epoch: 130 | Batch_idx: 50 |  Loss: (0.1470) |  Loss2: (0.0000) | Acc: (95.00%) (6209/6528)
Epoch: 130 | Batch_idx: 60 |  Loss: (0.1514) |  Loss2: (0.0000) | Acc: (95.00%) (7419/7808)
Epoch: 130 | Batch_idx: 70 |  Loss: (0.1497) |  Loss2: (0.0000) | Acc: (95.00%) (8642/9088)
Epoch: 130 | Batch_idx: 80 |  Loss: (0.1482) |  Loss2: (0.0000) | Acc: (95.00%) (9867/10368)
Epoch: 130 | Batch_idx: 90 |  Loss: (0.1496) |  Loss2: (0.0000) | Acc: (95.00%) (11077/11648)
Epoch: 130 | Batch_idx: 100 |  Loss: (0.1519) |  Loss2: (0.0000) | Acc: (94.00%) (12280/12928)
Epoch: 130 | Batch_idx: 110 |  Loss: (0.1526) |  Loss2: (0.0000) | Acc: (94.00%) (13494/14208)
Epoch: 130 | Batch_idx: 120 |  Loss: (0.1534) |  Loss2: (0.0000) | Acc: (94.00%) (14699/15488)
Epoch: 130 | Batch_idx: 130 |  Loss: (0.1521) |  Loss2: (0.0000) | Acc: (94.00%) (15920/16768)
Epoch: 130 | Batch_idx: 140 |  Loss: (0.1523) |  Loss2: (0.0000) | Acc: (94.00%) (17137/18048)
Epoch: 130 | Batch_idx: 150 |  Loss: (0.1532) |  Loss2: (0.0000) | Acc: (94.00%) (18348/19328)
Epoch: 130 | Batch_idx: 160 |  Loss: (0.1541) |  Loss2: (0.0000) | Acc: (94.00%) (19553/20608)
Epoch: 130 | Batch_idx: 170 |  Loss: (0.1535) |  Loss2: (0.0000) | Acc: (94.00%) (20769/21888)
Epoch: 130 | Batch_idx: 180 |  Loss: (0.1532) |  Loss2: (0.0000) | Acc: (94.00%) (21979/23168)
Epoch: 130 | Batch_idx: 190 |  Loss: (0.1536) |  Loss2: (0.0000) | Acc: (94.00%) (23193/24448)
Epoch: 130 | Batch_idx: 200 |  Loss: (0.1552) |  Loss2: (0.0000) | Acc: (94.00%) (24388/25728)
Epoch: 130 | Batch_idx: 210 |  Loss: (0.1567) |  Loss2: (0.0000) | Acc: (94.00%) (25589/27008)
Epoch: 130 | Batch_idx: 220 |  Loss: (0.1559) |  Loss2: (0.0000) | Acc: (94.00%) (26808/28288)
Epoch: 130 | Batch_idx: 230 |  Loss: (0.1554) |  Loss2: (0.0000) | Acc: (94.00%) (28032/29568)
Epoch: 130 | Batch_idx: 240 |  Loss: (0.1557) |  Loss2: (0.0000) | Acc: (94.00%) (29232/30848)
Epoch: 130 | Batch_idx: 250 |  Loss: (0.1554) |  Loss2: (0.0000) | Acc: (94.00%) (30439/32128)
Epoch: 130 | Batch_idx: 260 |  Loss: (0.1550) |  Loss2: (0.0000) | Acc: (94.00%) (31657/33408)
Epoch: 130 | Batch_idx: 270 |  Loss: (0.1544) |  Loss2: (0.0000) | Acc: (94.00%) (32878/34688)
Epoch: 130 | Batch_idx: 280 |  Loss: (0.1546) |  Loss2: (0.0000) | Acc: (94.00%) (34090/35968)
Epoch: 130 | Batch_idx: 290 |  Loss: (0.1560) |  Loss2: (0.0000) | Acc: (94.00%) (35282/37248)
Epoch: 130 | Batch_idx: 300 |  Loss: (0.1562) |  Loss2: (0.0000) | Acc: (94.00%) (36497/38528)
Epoch: 130 | Batch_idx: 310 |  Loss: (0.1563) |  Loss2: (0.0000) | Acc: (94.00%) (37702/39808)
Epoch: 130 | Batch_idx: 320 |  Loss: (0.1554) |  Loss2: (0.0000) | Acc: (94.00%) (38926/41088)
Epoch: 130 | Batch_idx: 330 |  Loss: (0.1563) |  Loss2: (0.0000) | Acc: (94.00%) (40123/42368)
Epoch: 130 | Batch_idx: 340 |  Loss: (0.1559) |  Loss2: (0.0000) | Acc: (94.00%) (41334/43648)
Epoch: 130 | Batch_idx: 350 |  Loss: (0.1569) |  Loss2: (0.0000) | Acc: (94.00%) (42528/44928)
Epoch: 130 | Batch_idx: 360 |  Loss: (0.1578) |  Loss2: (0.0000) | Acc: (94.00%) (43728/46208)
Epoch: 130 | Batch_idx: 370 |  Loss: (0.1582) |  Loss2: (0.0000) | Acc: (94.00%) (44931/47488)
Epoch: 130 | Batch_idx: 380 |  Loss: (0.1578) |  Loss2: (0.0000) | Acc: (94.00%) (46140/48768)
Epoch: 130 | Batch_idx: 390 |  Loss: (0.1583) |  Loss2: (0.0000) | Acc: (94.00%) (47299/50000)
=> saving checkpoint 'drive/app/torch/save_Schedule/checkpoint_130.pth.tar'
# TEST : Loss: (0.4217) | Acc: (87.00%) (8736/10000)
percent tensor([0.5509, 0.5609, 0.5858, 0.5728, 0.5861, 0.5536, 0.5714, 0.5805, 0.5606,
        0.5676, 0.5496, 0.5803, 0.5531, 0.5597, 0.5591, 0.5537],
       device='cuda:0') torch.Size([16])
percent tensor([0.5668, 0.5715, 0.5573, 0.5529, 0.5659, 0.5694, 0.5755, 0.5647, 0.5640,
        0.5650, 0.5699, 0.5691, 0.5679, 0.5650, 0.5756, 0.5667],
       device='cuda:0') torch.Size([16])
percent tensor([0.6030, 0.6147, 0.5750, 0.5496, 0.5534, 0.5720, 0.5950, 0.5676, 0.5896,
        0.6087, 0.6021, 0.5930, 0.6301, 0.6002, 0.5953, 0.6025],
       device='cuda:0') torch.Size([16])
percent tensor([0.6357, 0.6363, 0.6047, 0.6056, 0.6160, 0.6414, 0.6376, 0.6111, 0.6259,
        0.6365, 0.6391, 0.6227, 0.6356, 0.6336, 0.6407, 0.6378],
       device='cuda:0') torch.Size([16])
percent tensor([0.5303, 0.5064, 0.6026, 0.6204, 0.6241, 0.5440, 0.5648, 0.6262, 0.5675,
        0.5239, 0.5341, 0.5505, 0.4537, 0.6008, 0.5645, 0.5432],
       device='cuda:0') torch.Size([16])
percent tensor([0.5442, 0.6501, 0.6473, 0.6205, 0.6562, 0.6803, 0.6124, 0.5541, 0.6534,
        0.6000, 0.6583, 0.6069, 0.6320, 0.6607, 0.5133, 0.5316],
       device='cuda:0') torch.Size([16])
percent tensor([0.6639, 0.6848, 0.7001, 0.6392, 0.6994, 0.7016, 0.7191, 0.6454, 0.6813,
        0.6793, 0.6894, 0.6346, 0.6667, 0.7031, 0.5942, 0.6275],
       device='cuda:0') torch.Size([16])
percent tensor([0.9996, 0.9993, 0.9998, 0.9997, 0.9998, 0.9997, 0.9999, 0.9999, 0.9998,
        0.9998, 0.9998, 0.9994, 0.9995, 0.9995, 0.9997, 0.9995],
       device='cuda:0') torch.Size([16])
Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 3, 3, 3]) tensor(187.6708, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(816.8531, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(835.9274, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([128, 64, 3, 3]) tensor(1529.6360, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([128, 64, 1, 1]) tensor(494.1965, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([128, 128, 3, 3]) tensor(2262.3062, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([256, 128, 3, 3]) tensor(4267.4370, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([256, 128, 1, 1]) tensor(1375.3455, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([256, 256, 3, 3]) tensor(6185.0718, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([512, 256, 3, 3]) tensor(11767.7305, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([512, 256, 1, 1]) tensor(3893.8279, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([512, 512, 3, 3]) tensor(16444.3750, device='cuda:0', grad_fn=<NormBackward0>)
Epoch: 131 | Batch_idx: 0 |  Loss: (0.1390) |  Loss2: (0.0000) | Acc: (96.00%) (123/128)
Epoch: 131 | Batch_idx: 10 |  Loss: (0.1617) |  Loss2: (0.0000) | Acc: (94.00%) (1334/1408)
Epoch: 131 | Batch_idx: 20 |  Loss: (0.1730) |  Loss2: (0.0000) | Acc: (94.00%) (2536/2688)
Epoch: 131 | Batch_idx: 30 |  Loss: (0.1645) |  Loss2: (0.0000) | Acc: (94.00%) (3757/3968)
Epoch: 131 | Batch_idx: 40 |  Loss: (0.1662) |  Loss2: (0.0000) | Acc: (94.00%) (4956/5248)
Epoch: 131 | Batch_idx: 50 |  Loss: (0.1667) |  Loss2: (0.0000) | Acc: (94.00%) (6153/6528)
Epoch: 131 | Batch_idx: 60 |  Loss: (0.1639) |  Loss2: (0.0000) | Acc: (94.00%) (7364/7808)
Epoch: 131 | Batch_idx: 70 |  Loss: (0.1623) |  Loss2: (0.0000) | Acc: (94.00%) (8570/9088)
Epoch: 131 | Batch_idx: 80 |  Loss: (0.1604) |  Loss2: (0.0000) | Acc: (94.00%) (9783/10368)
Epoch: 131 | Batch_idx: 90 |  Loss: (0.1586) |  Loss2: (0.0000) | Acc: (94.00%) (11001/11648)
Epoch: 131 | Batch_idx: 100 |  Loss: (0.1588) |  Loss2: (0.0000) | Acc: (94.00%) (12215/12928)
Epoch: 131 | Batch_idx: 110 |  Loss: (0.1551) |  Loss2: (0.0000) | Acc: (94.00%) (13447/14208)
Epoch: 131 | Batch_idx: 120 |  Loss: (0.1536) |  Loss2: (0.0000) | Acc: (94.00%) (14673/15488)
Epoch: 131 | Batch_idx: 130 |  Loss: (0.1539) |  Loss2: (0.0000) | Acc: (94.00%) (15882/16768)
Epoch: 131 | Batch_idx: 140 |  Loss: (0.1543) |  Loss2: (0.0000) | Acc: (94.00%) (17095/18048)
Epoch: 131 | Batch_idx: 150 |  Loss: (0.1529) |  Loss2: (0.0000) | Acc: (94.00%) (18320/19328)
Epoch: 131 | Batch_idx: 160 |  Loss: (0.1524) |  Loss2: (0.0000) | Acc: (94.00%) (19538/20608)
Epoch: 131 | Batch_idx: 170 |  Loss: (0.1508) |  Loss2: (0.0000) | Acc: (94.00%) (20768/21888)
Epoch: 131 | Batch_idx: 180 |  Loss: (0.1508) |  Loss2: (0.0000) | Acc: (94.00%) (21982/23168)
Epoch: 131 | Batch_idx: 190 |  Loss: (0.1500) |  Loss2: (0.0000) | Acc: (94.00%) (23212/24448)
Epoch: 131 | Batch_idx: 200 |  Loss: (0.1501) |  Loss2: (0.0000) | Acc: (94.00%) (24435/25728)
Epoch: 131 | Batch_idx: 210 |  Loss: (0.1503) |  Loss2: (0.0000) | Acc: (94.00%) (25645/27008)
Epoch: 131 | Batch_idx: 220 |  Loss: (0.1511) |  Loss2: (0.0000) | Acc: (94.00%) (26857/28288)
Epoch: 131 | Batch_idx: 230 |  Loss: (0.1505) |  Loss2: (0.0000) | Acc: (94.00%) (28078/29568)
Epoch: 131 | Batch_idx: 240 |  Loss: (0.1507) |  Loss2: (0.0000) | Acc: (94.00%) (29296/30848)
Epoch: 131 | Batch_idx: 250 |  Loss: (0.1509) |  Loss2: (0.0000) | Acc: (94.00%) (30508/32128)
Epoch: 131 | Batch_idx: 260 |  Loss: (0.1520) |  Loss2: (0.0000) | Acc: (94.00%) (31707/33408)
Epoch: 131 | Batch_idx: 270 |  Loss: (0.1513) |  Loss2: (0.0000) | Acc: (94.00%) (32939/34688)
Epoch: 131 | Batch_idx: 280 |  Loss: (0.1511) |  Loss2: (0.0000) | Acc: (94.00%) (34156/35968)
Epoch: 131 | Batch_idx: 290 |  Loss: (0.1510) |  Loss2: (0.0000) | Acc: (94.00%) (35367/37248)
Epoch: 131 | Batch_idx: 300 |  Loss: (0.1514) |  Loss2: (0.0000) | Acc: (94.00%) (36575/38528)
Epoch: 131 | Batch_idx: 310 |  Loss: (0.1517) |  Loss2: (0.0000) | Acc: (94.00%) (37784/39808)
Epoch: 131 | Batch_idx: 320 |  Loss: (0.1517) |  Loss2: (0.0000) | Acc: (94.00%) (38997/41088)
Epoch: 131 | Batch_idx: 330 |  Loss: (0.1511) |  Loss2: (0.0000) | Acc: (94.00%) (40221/42368)
Epoch: 131 | Batch_idx: 340 |  Loss: (0.1514) |  Loss2: (0.0000) | Acc: (94.00%) (41422/43648)
Epoch: 131 | Batch_idx: 350 |  Loss: (0.1511) |  Loss2: (0.0000) | Acc: (94.00%) (42640/44928)
Epoch: 131 | Batch_idx: 360 |  Loss: (0.1512) |  Loss2: (0.0000) | Acc: (94.00%) (43858/46208)
Epoch: 131 | Batch_idx: 370 |  Loss: (0.1523) |  Loss2: (0.0000) | Acc: (94.00%) (45054/47488)
Epoch: 131 | Batch_idx: 380 |  Loss: (0.1524) |  Loss2: (0.0000) | Acc: (94.00%) (46260/48768)
Epoch: 131 | Batch_idx: 390 |  Loss: (0.1525) |  Loss2: (0.0000) | Acc: (94.00%) (47432/50000)
# TEST : Loss: (0.4320) | Acc: (87.00%) (8714/10000)
percent tensor([0.5518, 0.5602, 0.5884, 0.5728, 0.5889, 0.5556, 0.5718, 0.5812, 0.5621,
        0.5686, 0.5503, 0.5827, 0.5538, 0.5581, 0.5597, 0.5538],
       device='cuda:0') torch.Size([16])
percent tensor([0.5656, 0.5717, 0.5578, 0.5518, 0.5656, 0.5679, 0.5749, 0.5651, 0.5629,
        0.5655, 0.5687, 0.5688, 0.5666, 0.5642, 0.5751, 0.5658],
       device='cuda:0') torch.Size([16])
percent tensor([0.6000, 0.6098, 0.5751, 0.5541, 0.5560, 0.5734, 0.5962, 0.5671, 0.5922,
        0.6057, 0.5980, 0.5914, 0.6261, 0.6014, 0.5936, 0.6029],
       device='cuda:0') torch.Size([16])
percent tensor([0.6342, 0.6372, 0.6069, 0.6059, 0.6183, 0.6425, 0.6390, 0.6114, 0.6236,
        0.6362, 0.6378, 0.6233, 0.6338, 0.6343, 0.6423, 0.6365],
       device='cuda:0') torch.Size([16])
percent tensor([0.5335, 0.5010, 0.6085, 0.6100, 0.6234, 0.5371, 0.5502, 0.6214, 0.5845,
        0.5336, 0.5387, 0.5575, 0.4731, 0.5905, 0.5562, 0.5424],
       device='cuda:0') torch.Size([16])
percent tensor([0.5287, 0.6403, 0.6391, 0.6158, 0.6524, 0.6737, 0.6217, 0.5684, 0.6462,
        0.5803, 0.6482, 0.6168, 0.6223, 0.6562, 0.5061, 0.5229],
       device='cuda:0') torch.Size([16])
percent tensor([0.6669, 0.6778, 0.6915, 0.6438, 0.6865, 0.7011, 0.7086, 0.6359, 0.6808,
        0.6751, 0.6906, 0.6296, 0.6723, 0.6921, 0.5866, 0.6217],
       device='cuda:0') torch.Size([16])
percent tensor([0.9996, 0.9994, 0.9998, 0.9997, 0.9999, 0.9995, 0.9998, 0.9998, 0.9997,
        0.9998, 0.9997, 0.9996, 0.9994, 0.9996, 0.9995, 0.9992],
       device='cuda:0') torch.Size([16])
Epoch: 132 | Batch_idx: 0 |  Loss: (0.0938) |  Loss2: (0.0000) | Acc: (98.00%) (126/128)
Epoch: 132 | Batch_idx: 10 |  Loss: (0.1384) |  Loss2: (0.0000) | Acc: (95.00%) (1346/1408)
Epoch: 132 | Batch_idx: 20 |  Loss: (0.1351) |  Loss2: (0.0000) | Acc: (95.00%) (2568/2688)
Epoch: 132 | Batch_idx: 30 |  Loss: (0.1444) |  Loss2: (0.0000) | Acc: (95.00%) (3770/3968)
Epoch: 132 | Batch_idx: 40 |  Loss: (0.1424) |  Loss2: (0.0000) | Acc: (95.00%) (4997/5248)
Epoch: 132 | Batch_idx: 50 |  Loss: (0.1461) |  Loss2: (0.0000) | Acc: (94.00%) (6197/6528)
Epoch: 132 | Batch_idx: 60 |  Loss: (0.1436) |  Loss2: (0.0000) | Acc: (95.00%) (7418/7808)
Epoch: 132 | Batch_idx: 70 |  Loss: (0.1438) |  Loss2: (0.0000) | Acc: (94.00%) (8630/9088)
Epoch: 132 | Batch_idx: 80 |  Loss: (0.1423) |  Loss2: (0.0000) | Acc: (95.00%) (9852/10368)
Epoch: 132 | Batch_idx: 90 |  Loss: (0.1415) |  Loss2: (0.0000) | Acc: (95.00%) (11069/11648)
Epoch: 132 | Batch_idx: 100 |  Loss: (0.1404) |  Loss2: (0.0000) | Acc: (94.00%) (12281/12928)
Epoch: 132 | Batch_idx: 110 |  Loss: (0.1412) |  Loss2: (0.0000) | Acc: (95.00%) (13501/14208)
Epoch: 132 | Batch_idx: 120 |  Loss: (0.1415) |  Loss2: (0.0000) | Acc: (94.00%) (14711/15488)
Epoch: 132 | Batch_idx: 130 |  Loss: (0.1422) |  Loss2: (0.0000) | Acc: (94.00%) (15920/16768)
Epoch: 132 | Batch_idx: 140 |  Loss: (0.1418) |  Loss2: (0.0000) | Acc: (94.00%) (17145/18048)
Epoch: 132 | Batch_idx: 150 |  Loss: (0.1438) |  Loss2: (0.0000) | Acc: (94.00%) (18349/19328)
Epoch: 132 | Batch_idx: 160 |  Loss: (0.1441) |  Loss2: (0.0000) | Acc: (94.00%) (19569/20608)
Epoch: 132 | Batch_idx: 170 |  Loss: (0.1440) |  Loss2: (0.0000) | Acc: (94.00%) (20784/21888)
Epoch: 132 | Batch_idx: 180 |  Loss: (0.1451) |  Loss2: (0.0000) | Acc: (94.00%) (21990/23168)
Epoch: 132 | Batch_idx: 190 |  Loss: (0.1449) |  Loss2: (0.0000) | Acc: (94.00%) (23213/24448)
Epoch: 132 | Batch_idx: 200 |  Loss: (0.1455) |  Loss2: (0.0000) | Acc: (94.00%) (24420/25728)
Epoch: 132 | Batch_idx: 210 |  Loss: (0.1467) |  Loss2: (0.0000) | Acc: (94.00%) (25627/27008)
Epoch: 132 | Batch_idx: 220 |  Loss: (0.1465) |  Loss2: (0.0000) | Acc: (94.00%) (26846/28288)
Epoch: 132 | Batch_idx: 230 |  Loss: (0.1464) |  Loss2: (0.0000) | Acc: (94.00%) (28061/29568)
Epoch: 132 | Batch_idx: 240 |  Loss: (0.1481) |  Loss2: (0.0000) | Acc: (94.00%) (29259/30848)
Epoch: 132 | Batch_idx: 250 |  Loss: (0.1490) |  Loss2: (0.0000) | Acc: (94.00%) (30465/32128)
Epoch: 132 | Batch_idx: 260 |  Loss: (0.1485) |  Loss2: (0.0000) | Acc: (94.00%) (31690/33408)
Epoch: 132 | Batch_idx: 270 |  Loss: (0.1496) |  Loss2: (0.0000) | Acc: (94.00%) (32896/34688)
Epoch: 132 | Batch_idx: 280 |  Loss: (0.1493) |  Loss2: (0.0000) | Acc: (94.00%) (34107/35968)
Epoch: 132 | Batch_idx: 290 |  Loss: (0.1499) |  Loss2: (0.0000) | Acc: (94.00%) (35315/37248)
Epoch: 132 | Batch_idx: 300 |  Loss: (0.1510) |  Loss2: (0.0000) | Acc: (94.00%) (36517/38528)
Epoch: 132 | Batch_idx: 310 |  Loss: (0.1510) |  Loss2: (0.0000) | Acc: (94.00%) (37729/39808)
Epoch: 132 | Batch_idx: 320 |  Loss: (0.1512) |  Loss2: (0.0000) | Acc: (94.00%) (38941/41088)
Epoch: 132 | Batch_idx: 330 |  Loss: (0.1510) |  Loss2: (0.0000) | Acc: (94.00%) (40158/42368)
Epoch: 132 | Batch_idx: 340 |  Loss: (0.1512) |  Loss2: (0.0000) | Acc: (94.00%) (41373/43648)
Epoch: 132 | Batch_idx: 350 |  Loss: (0.1513) |  Loss2: (0.0000) | Acc: (94.00%) (42584/44928)
Epoch: 132 | Batch_idx: 360 |  Loss: (0.1513) |  Loss2: (0.0000) | Acc: (94.00%) (43793/46208)
Epoch: 132 | Batch_idx: 370 |  Loss: (0.1512) |  Loss2: (0.0000) | Acc: (94.00%) (44999/47488)
Epoch: 132 | Batch_idx: 380 |  Loss: (0.1506) |  Loss2: (0.0000) | Acc: (94.00%) (46223/48768)
Epoch: 132 | Batch_idx: 390 |  Loss: (0.1509) |  Loss2: (0.0000) | Acc: (94.00%) (47382/50000)
# TEST : Loss: (0.4635) | Acc: (86.00%) (8617/10000)
percent tensor([0.5506, 0.5608, 0.5842, 0.5729, 0.5849, 0.5544, 0.5699, 0.5797, 0.5597,
        0.5668, 0.5486, 0.5782, 0.5527, 0.5591, 0.5602, 0.5533],
       device='cuda:0') torch.Size([16])
percent tensor([0.5672, 0.5702, 0.5613, 0.5533, 0.5689, 0.5699, 0.5752, 0.5671, 0.5640,
        0.5654, 0.5691, 0.5718, 0.5684, 0.5623, 0.5751, 0.5661],
       device='cuda:0') torch.Size([16])
percent tensor([0.6050, 0.6111, 0.5816, 0.5566, 0.5600, 0.5755, 0.5957, 0.5737, 0.5923,
        0.6105, 0.6016, 0.5956, 0.6299, 0.5932, 0.5961, 0.6054],
       device='cuda:0') torch.Size([16])
percent tensor([0.6356, 0.6340, 0.6075, 0.6081, 0.6184, 0.6439, 0.6370, 0.6119, 0.6244,
        0.6348, 0.6371, 0.6244, 0.6330, 0.6324, 0.6404, 0.6369],
       device='cuda:0') torch.Size([16])
percent tensor([0.5206, 0.5039, 0.6136, 0.6230, 0.6342, 0.5465, 0.5530, 0.6183, 0.5757,
        0.5222, 0.5227, 0.5684, 0.4470, 0.6177, 0.5541, 0.5349],
       device='cuda:0') torch.Size([16])
percent tensor([0.5307, 0.6021, 0.6250, 0.6059, 0.6304, 0.6786, 0.5838, 0.5468, 0.6295,
        0.5643, 0.6477, 0.5738, 0.6313, 0.6135, 0.4886, 0.5063],
       device='cuda:0') torch.Size([16])
percent tensor([0.6578, 0.6611, 0.6850, 0.6356, 0.6756, 0.6984, 0.6863, 0.6269, 0.6668,
        0.6788, 0.6813, 0.6117, 0.6628, 0.6942, 0.5910, 0.6193],
       device='cuda:0') torch.Size([16])
percent tensor([0.9997, 0.9996, 0.9998, 0.9998, 0.9999, 0.9997, 0.9999, 0.9999, 0.9997,
        0.9998, 0.9997, 0.9996, 0.9995, 0.9998, 0.9995, 0.9995],
       device='cuda:0') torch.Size([16])
False Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=128, out_features=16, bias=False)
True Linear(in_features=16, out_features=2, bias=False)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=128, out_features=16, bias=False)
True Linear(in_features=16, out_features=2, bias=False)
False Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=256, out_features=32, bias=False)
True Linear(in_features=32, out_features=2, bias=False)
False Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=256, out_features=32, bias=False)
True Linear(in_features=32, out_features=2, bias=False)
False Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=512, out_features=64, bias=False)
True Linear(in_features=64, out_features=2, bias=False)
False Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=512, out_features=64, bias=False)
True Linear(in_features=64, out_features=2, bias=False)
False Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1024, out_features=128, bias=False)
True Linear(in_features=128, out_features=2, bias=False)
False Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1024, out_features=128, bias=False)
True Linear(in_features=128, out_features=2, bias=False)
False Linear(in_features=512, out_features=10, bias=True)
Epoch: 133 | Batch_idx: 0 |  Loss: (0.0989) |  Loss2: (0.0000) | Acc: (97.00%) (125/128)
Epoch: 133 | Batch_idx: 10 |  Loss: (0.1735) |  Loss2: (0.0000) | Acc: (93.00%) (1318/1408)
Epoch: 133 | Batch_idx: 20 |  Loss: (0.1863) |  Loss2: (0.0000) | Acc: (93.00%) (2511/2688)
Epoch: 133 | Batch_idx: 30 |  Loss: (0.2026) |  Loss2: (0.0000) | Acc: (92.00%) (3688/3968)
Epoch: 133 | Batch_idx: 40 |  Loss: (0.2004) |  Loss2: (0.0000) | Acc: (92.00%) (4875/5248)
Epoch: 133 | Batch_idx: 50 |  Loss: (0.1983) |  Loss2: (0.0000) | Acc: (92.00%) (6061/6528)
Epoch: 133 | Batch_idx: 60 |  Loss: (0.2011) |  Loss2: (0.0000) | Acc: (92.00%) (7245/7808)
Epoch: 133 | Batch_idx: 70 |  Loss: (0.2008) |  Loss2: (0.0000) | Acc: (92.00%) (8440/9088)
Epoch: 133 | Batch_idx: 80 |  Loss: (0.1991) |  Loss2: (0.0000) | Acc: (92.00%) (9635/10368)
Epoch: 133 | Batch_idx: 90 |  Loss: (0.1983) |  Loss2: (0.0000) | Acc: (92.00%) (10826/11648)
Epoch: 133 | Batch_idx: 100 |  Loss: (0.1989) |  Loss2: (0.0000) | Acc: (92.00%) (12019/12928)
Epoch: 133 | Batch_idx: 110 |  Loss: (0.2005) |  Loss2: (0.0000) | Acc: (92.00%) (13200/14208)
Epoch: 133 | Batch_idx: 120 |  Loss: (0.2002) |  Loss2: (0.0000) | Acc: (92.00%) (14391/15488)
Epoch: 133 | Batch_idx: 130 |  Loss: (0.1992) |  Loss2: (0.0000) | Acc: (92.00%) (15578/16768)
Epoch: 133 | Batch_idx: 140 |  Loss: (0.1973) |  Loss2: (0.0000) | Acc: (92.00%) (16779/18048)
Epoch: 133 | Batch_idx: 150 |  Loss: (0.1981) |  Loss2: (0.0000) | Acc: (92.00%) (17956/19328)
Epoch: 133 | Batch_idx: 160 |  Loss: (0.1962) |  Loss2: (0.0000) | Acc: (92.00%) (19159/20608)
Epoch: 133 | Batch_idx: 170 |  Loss: (0.1953) |  Loss2: (0.0000) | Acc: (93.00%) (20356/21888)
Epoch: 133 | Batch_idx: 180 |  Loss: (0.1954) |  Loss2: (0.0000) | Acc: (92.00%) (21546/23168)
Epoch: 133 | Batch_idx: 190 |  Loss: (0.1944) |  Loss2: (0.0000) | Acc: (93.00%) (22743/24448)
Epoch: 133 | Batch_idx: 200 |  Loss: (0.1943) |  Loss2: (0.0000) | Acc: (93.00%) (23939/25728)
Epoch: 133 | Batch_idx: 210 |  Loss: (0.1939) |  Loss2: (0.0000) | Acc: (93.00%) (25133/27008)
Epoch: 133 | Batch_idx: 220 |  Loss: (0.1947) |  Loss2: (0.0000) | Acc: (93.00%) (26317/28288)
Epoch: 133 | Batch_idx: 230 |  Loss: (0.1951) |  Loss2: (0.0000) | Acc: (93.00%) (27504/29568)
Epoch: 133 | Batch_idx: 240 |  Loss: (0.1937) |  Loss2: (0.0000) | Acc: (93.00%) (28712/30848)
Epoch: 133 | Batch_idx: 250 |  Loss: (0.1933) |  Loss2: (0.0000) | Acc: (93.00%) (29904/32128)
Epoch: 133 | Batch_idx: 260 |  Loss: (0.1925) |  Loss2: (0.0000) | Acc: (93.00%) (31107/33408)
Epoch: 133 | Batch_idx: 270 |  Loss: (0.1919) |  Loss2: (0.0000) | Acc: (93.00%) (32304/34688)
Epoch: 133 | Batch_idx: 280 |  Loss: (0.1918) |  Loss2: (0.0000) | Acc: (93.00%) (33498/35968)
Epoch: 133 | Batch_idx: 290 |  Loss: (0.1914) |  Loss2: (0.0000) | Acc: (93.00%) (34695/37248)
Epoch: 133 | Batch_idx: 300 |  Loss: (0.1906) |  Loss2: (0.0000) | Acc: (93.00%) (35905/38528)
Epoch: 133 | Batch_idx: 310 |  Loss: (0.1900) |  Loss2: (0.0000) | Acc: (93.00%) (37099/39808)
Epoch: 133 | Batch_idx: 320 |  Loss: (0.1892) |  Loss2: (0.0000) | Acc: (93.00%) (38302/41088)
Epoch: 133 | Batch_idx: 330 |  Loss: (0.1890) |  Loss2: (0.0000) | Acc: (93.00%) (39491/42368)
Epoch: 133 | Batch_idx: 340 |  Loss: (0.1884) |  Loss2: (0.0000) | Acc: (93.00%) (40698/43648)
Epoch: 133 | Batch_idx: 350 |  Loss: (0.1885) |  Loss2: (0.0000) | Acc: (93.00%) (41890/44928)
Epoch: 133 | Batch_idx: 360 |  Loss: (0.1880) |  Loss2: (0.0000) | Acc: (93.00%) (43088/46208)
Epoch: 133 | Batch_idx: 370 |  Loss: (0.1880) |  Loss2: (0.0000) | Acc: (93.00%) (44282/47488)
Epoch: 133 | Batch_idx: 380 |  Loss: (0.1886) |  Loss2: (0.0000) | Acc: (93.00%) (45473/48768)
Epoch: 133 | Batch_idx: 390 |  Loss: (0.1882) |  Loss2: (0.0000) | Acc: (93.00%) (46631/50000)
# TEST : Loss: (0.4363) | Acc: (86.00%) (8676/10000)
percent tensor([0.5614, 0.5748, 0.5929, 0.5841, 0.5947, 0.5657, 0.5825, 0.5917, 0.5711,
        0.5777, 0.5597, 0.5882, 0.5636, 0.5745, 0.5727, 0.5647],
       device='cuda:0') torch.Size([16])
percent tensor([0.5719, 0.5733, 0.5672, 0.5588, 0.5735, 0.5748, 0.5789, 0.5723, 0.5680,
        0.5692, 0.5733, 0.5762, 0.5725, 0.5656, 0.5787, 0.5710],
       device='cuda:0') torch.Size([16])
percent tensor([0.6152, 0.6219, 0.5912, 0.5657, 0.5709, 0.5831, 0.6078, 0.5868, 0.5996,
        0.6234, 0.6122, 0.6098, 0.6412, 0.6015, 0.6089, 0.6151],
       device='cuda:0') torch.Size([16])
percent tensor([0.6206, 0.6145, 0.5957, 0.5983, 0.6073, 0.6313, 0.6204, 0.6002, 0.6100,
        0.6164, 0.6189, 0.6083, 0.6137, 0.6153, 0.6241, 0.6223],
       device='cuda:0') torch.Size([16])
percent tensor([0.5449, 0.5046, 0.6375, 0.6451, 0.6535, 0.5914, 0.5597, 0.6399, 0.5878,
        0.5142, 0.5225, 0.5765, 0.4531, 0.6025, 0.5735, 0.5540],
       device='cuda:0') torch.Size([16])
percent tensor([0.5815, 0.6600, 0.6751, 0.6557, 0.6844, 0.7236, 0.6409, 0.5916, 0.6804,
        0.6339, 0.6929, 0.6269, 0.6799, 0.6820, 0.5358, 0.5738],
       device='cuda:0') torch.Size([16])
percent tensor([0.6629, 0.6688, 0.6899, 0.6426, 0.6905, 0.6951, 0.6916, 0.6389, 0.6694,
        0.6842, 0.6808, 0.6194, 0.6650, 0.6961, 0.5911, 0.6325],
       device='cuda:0') torch.Size([16])
percent tensor([0.9997, 0.9995, 0.9997, 0.9997, 0.9998, 0.9997, 0.9999, 0.9999, 0.9997,
        0.9998, 0.9997, 0.9995, 0.9996, 0.9996, 0.9994, 0.9995],
       device='cuda:0') torch.Size([16])
Epoch: 134 | Batch_idx: 0 |  Loss: (0.1257) |  Loss2: (0.0000) | Acc: (96.00%) (123/128)
Epoch: 134 | Batch_idx: 10 |  Loss: (0.1811) |  Loss2: (0.0000) | Acc: (93.00%) (1313/1408)
Epoch: 134 | Batch_idx: 20 |  Loss: (0.1762) |  Loss2: (0.0000) | Acc: (93.00%) (2522/2688)
Epoch: 134 | Batch_idx: 30 |  Loss: (0.1743) |  Loss2: (0.0000) | Acc: (93.00%) (3721/3968)
Epoch: 134 | Batch_idx: 40 |  Loss: (0.1717) |  Loss2: (0.0000) | Acc: (93.00%) (4924/5248)
Epoch: 134 | Batch_idx: 50 |  Loss: (0.1730) |  Loss2: (0.0000) | Acc: (93.00%) (6133/6528)
Epoch: 134 | Batch_idx: 60 |  Loss: (0.1755) |  Loss2: (0.0000) | Acc: (93.00%) (7326/7808)
Epoch: 134 | Batch_idx: 70 |  Loss: (0.1742) |  Loss2: (0.0000) | Acc: (93.00%) (8528/9088)
Epoch: 134 | Batch_idx: 80 |  Loss: (0.1754) |  Loss2: (0.0000) | Acc: (93.00%) (9731/10368)
Epoch: 134 | Batch_idx: 90 |  Loss: (0.1766) |  Loss2: (0.0000) | Acc: (93.00%) (10925/11648)
Epoch: 134 | Batch_idx: 100 |  Loss: (0.1744) |  Loss2: (0.0000) | Acc: (93.00%) (12141/12928)
Epoch: 134 | Batch_idx: 110 |  Loss: (0.1742) |  Loss2: (0.0000) | Acc: (93.00%) (13354/14208)
Epoch: 134 | Batch_idx: 120 |  Loss: (0.1726) |  Loss2: (0.0000) | Acc: (93.00%) (14554/15488)
Epoch: 134 | Batch_idx: 130 |  Loss: (0.1707) |  Loss2: (0.0000) | Acc: (94.00%) (15767/16768)
Epoch: 134 | Batch_idx: 140 |  Loss: (0.1692) |  Loss2: (0.0000) | Acc: (94.00%) (16986/18048)
Epoch: 134 | Batch_idx: 150 |  Loss: (0.1697) |  Loss2: (0.0000) | Acc: (94.00%) (18191/19328)
Epoch: 134 | Batch_idx: 160 |  Loss: (0.1694) |  Loss2: (0.0000) | Acc: (94.00%) (19395/20608)
Epoch: 134 | Batch_idx: 170 |  Loss: (0.1689) |  Loss2: (0.0000) | Acc: (94.00%) (20608/21888)
Epoch: 134 | Batch_idx: 180 |  Loss: (0.1697) |  Loss2: (0.0000) | Acc: (94.00%) (21805/23168)
Epoch: 134 | Batch_idx: 190 |  Loss: (0.1693) |  Loss2: (0.0000) | Acc: (94.00%) (23015/24448)
Epoch: 134 | Batch_idx: 200 |  Loss: (0.1688) |  Loss2: (0.0000) | Acc: (94.00%) (24225/25728)
Epoch: 134 | Batch_idx: 210 |  Loss: (0.1681) |  Loss2: (0.0000) | Acc: (94.00%) (25432/27008)
Epoch: 134 | Batch_idx: 220 |  Loss: (0.1682) |  Loss2: (0.0000) | Acc: (94.00%) (26631/28288)
Epoch: 134 | Batch_idx: 230 |  Loss: (0.1678) |  Loss2: (0.0000) | Acc: (94.00%) (27836/29568)
Epoch: 134 | Batch_idx: 240 |  Loss: (0.1686) |  Loss2: (0.0000) | Acc: (94.00%) (29037/30848)
Epoch: 134 | Batch_idx: 250 |  Loss: (0.1678) |  Loss2: (0.0000) | Acc: (94.00%) (30258/32128)
Epoch: 134 | Batch_idx: 260 |  Loss: (0.1673) |  Loss2: (0.0000) | Acc: (94.00%) (31469/33408)
Epoch: 134 | Batch_idx: 270 |  Loss: (0.1669) |  Loss2: (0.0000) | Acc: (94.00%) (32678/34688)
Epoch: 134 | Batch_idx: 280 |  Loss: (0.1669) |  Loss2: (0.0000) | Acc: (94.00%) (33883/35968)
Epoch: 134 | Batch_idx: 290 |  Loss: (0.1670) |  Loss2: (0.0000) | Acc: (94.00%) (35094/37248)
Epoch: 134 | Batch_idx: 300 |  Loss: (0.1666) |  Loss2: (0.0000) | Acc: (94.00%) (36309/38528)
Epoch: 134 | Batch_idx: 310 |  Loss: (0.1659) |  Loss2: (0.0000) | Acc: (94.00%) (37524/39808)
Epoch: 134 | Batch_idx: 320 |  Loss: (0.1657) |  Loss2: (0.0000) | Acc: (94.00%) (38729/41088)
Epoch: 134 | Batch_idx: 330 |  Loss: (0.1653) |  Loss2: (0.0000) | Acc: (94.00%) (39939/42368)
Epoch: 134 | Batch_idx: 340 |  Loss: (0.1652) |  Loss2: (0.0000) | Acc: (94.00%) (41147/43648)
Epoch: 134 | Batch_idx: 350 |  Loss: (0.1652) |  Loss2: (0.0000) | Acc: (94.00%) (42351/44928)
Epoch: 134 | Batch_idx: 360 |  Loss: (0.1648) |  Loss2: (0.0000) | Acc: (94.00%) (43559/46208)
Epoch: 134 | Batch_idx: 370 |  Loss: (0.1646) |  Loss2: (0.0000) | Acc: (94.00%) (44764/47488)
Epoch: 134 | Batch_idx: 380 |  Loss: (0.1649) |  Loss2: (0.0000) | Acc: (94.00%) (45962/48768)
Epoch: 134 | Batch_idx: 390 |  Loss: (0.1644) |  Loss2: (0.0000) | Acc: (94.00%) (47138/50000)
# TEST : Loss: (0.4159) | Acc: (87.00%) (8742/10000)
percent tensor([0.5611, 0.5739, 0.5931, 0.5840, 0.5944, 0.5656, 0.5820, 0.5911, 0.5706,
        0.5773, 0.5590, 0.5883, 0.5631, 0.5738, 0.5721, 0.5643],
       device='cuda:0') torch.Size([16])
percent tensor([0.5770, 0.5783, 0.5722, 0.5640, 0.5786, 0.5799, 0.5841, 0.5771, 0.5729,
        0.5746, 0.5788, 0.5816, 0.5773, 0.5701, 0.5839, 0.5761],
       device='cuda:0') torch.Size([16])
percent tensor([0.6082, 0.6160, 0.5833, 0.5595, 0.5648, 0.5770, 0.6026, 0.5806, 0.5925,
        0.6163, 0.6065, 0.6023, 0.6331, 0.5952, 0.6039, 0.6084],
       device='cuda:0') torch.Size([16])
percent tensor([0.6248, 0.6168, 0.6002, 0.6047, 0.6133, 0.6373, 0.6247, 0.6063, 0.6146,
        0.6188, 0.6220, 0.6123, 0.6155, 0.6195, 0.6288, 0.6266],
       device='cuda:0') torch.Size([16])
percent tensor([0.5336, 0.4832, 0.6341, 0.6439, 0.6505, 0.5946, 0.5438, 0.6378, 0.5750,
        0.4889, 0.5024, 0.5603, 0.4313, 0.5775, 0.5658, 0.5412],
       device='cuda:0') torch.Size([16])
percent tensor([0.5835, 0.6660, 0.6761, 0.6581, 0.6861, 0.7267, 0.6455, 0.5913, 0.6831,
        0.6437, 0.6956, 0.6321, 0.6836, 0.6917, 0.5351, 0.5729],
       device='cuda:0') torch.Size([16])
percent tensor([0.6726, 0.6770, 0.7007, 0.6534, 0.7003, 0.7069, 0.7055, 0.6476, 0.6755,
        0.6904, 0.6870, 0.6276, 0.6728, 0.7045, 0.5927, 0.6399],
       device='cuda:0') torch.Size([16])
percent tensor([0.9997, 0.9995, 0.9998, 0.9997, 0.9999, 0.9997, 0.9999, 0.9999, 0.9998,
        0.9998, 0.9997, 0.9995, 0.9995, 0.9995, 0.9994, 0.9995],
       device='cuda:0') torch.Size([16])
Epoch: 135 | Batch_idx: 0 |  Loss: (0.1358) |  Loss2: (0.0000) | Acc: (94.00%) (121/128)
Epoch: 135 | Batch_idx: 10 |  Loss: (0.1366) |  Loss2: (0.0000) | Acc: (94.00%) (1337/1408)
Epoch: 135 | Batch_idx: 20 |  Loss: (0.1449) |  Loss2: (0.0000) | Acc: (94.00%) (2545/2688)
Epoch: 135 | Batch_idx: 30 |  Loss: (0.1511) |  Loss2: (0.0000) | Acc: (94.00%) (3740/3968)
Epoch: 135 | Batch_idx: 40 |  Loss: (0.1554) |  Loss2: (0.0000) | Acc: (94.00%) (4951/5248)
Epoch: 135 | Batch_idx: 50 |  Loss: (0.1588) |  Loss2: (0.0000) | Acc: (94.00%) (6148/6528)
Epoch: 135 | Batch_idx: 60 |  Loss: (0.1587) |  Loss2: (0.0000) | Acc: (94.00%) (7358/7808)
Epoch: 135 | Batch_idx: 70 |  Loss: (0.1614) |  Loss2: (0.0000) | Acc: (94.00%) (8558/9088)
Epoch: 135 | Batch_idx: 80 |  Loss: (0.1616) |  Loss2: (0.0000) | Acc: (94.00%) (9765/10368)
Epoch: 135 | Batch_idx: 90 |  Loss: (0.1612) |  Loss2: (0.0000) | Acc: (94.00%) (10975/11648)
Epoch: 135 | Batch_idx: 100 |  Loss: (0.1628) |  Loss2: (0.0000) | Acc: (94.00%) (12170/12928)
Epoch: 135 | Batch_idx: 110 |  Loss: (0.1636) |  Loss2: (0.0000) | Acc: (94.00%) (13366/14208)
Epoch: 135 | Batch_idx: 120 |  Loss: (0.1628) |  Loss2: (0.0000) | Acc: (94.00%) (14579/15488)
Epoch: 135 | Batch_idx: 130 |  Loss: (0.1615) |  Loss2: (0.0000) | Acc: (94.00%) (15792/16768)
Epoch: 135 | Batch_idx: 140 |  Loss: (0.1607) |  Loss2: (0.0000) | Acc: (94.00%) (17006/18048)
Epoch: 135 | Batch_idx: 150 |  Loss: (0.1606) |  Loss2: (0.0000) | Acc: (94.00%) (18215/19328)
Epoch: 135 | Batch_idx: 160 |  Loss: (0.1598) |  Loss2: (0.0000) | Acc: (94.00%) (19438/20608)
Epoch: 135 | Batch_idx: 170 |  Loss: (0.1587) |  Loss2: (0.0000) | Acc: (94.00%) (20652/21888)
Epoch: 135 | Batch_idx: 180 |  Loss: (0.1579) |  Loss2: (0.0000) | Acc: (94.00%) (21865/23168)
Epoch: 135 | Batch_idx: 190 |  Loss: (0.1591) |  Loss2: (0.0000) | Acc: (94.00%) (23071/24448)
Epoch: 135 | Batch_idx: 200 |  Loss: (0.1590) |  Loss2: (0.0000) | Acc: (94.00%) (24278/25728)
Epoch: 135 | Batch_idx: 210 |  Loss: (0.1596) |  Loss2: (0.0000) | Acc: (94.00%) (25474/27008)
Epoch: 135 | Batch_idx: 220 |  Loss: (0.1590) |  Loss2: (0.0000) | Acc: (94.00%) (26681/28288)
Epoch: 135 | Batch_idx: 230 |  Loss: (0.1583) |  Loss2: (0.0000) | Acc: (94.00%) (27900/29568)
Epoch: 135 | Batch_idx: 240 |  Loss: (0.1591) |  Loss2: (0.0000) | Acc: (94.00%) (29100/30848)
Epoch: 135 | Batch_idx: 250 |  Loss: (0.1580) |  Loss2: (0.0000) | Acc: (94.00%) (30322/32128)
Epoch: 135 | Batch_idx: 260 |  Loss: (0.1577) |  Loss2: (0.0000) | Acc: (94.00%) (31536/33408)
Epoch: 135 | Batch_idx: 270 |  Loss: (0.1579) |  Loss2: (0.0000) | Acc: (94.00%) (32747/34688)
Epoch: 135 | Batch_idx: 280 |  Loss: (0.1584) |  Loss2: (0.0000) | Acc: (94.00%) (33950/35968)
Epoch: 135 | Batch_idx: 290 |  Loss: (0.1584) |  Loss2: (0.0000) | Acc: (94.00%) (35153/37248)
Epoch: 135 | Batch_idx: 300 |  Loss: (0.1573) |  Loss2: (0.0000) | Acc: (94.00%) (36379/38528)
Epoch: 135 | Batch_idx: 310 |  Loss: (0.1576) |  Loss2: (0.0000) | Acc: (94.00%) (37579/39808)
Epoch: 135 | Batch_idx: 320 |  Loss: (0.1574) |  Loss2: (0.0000) | Acc: (94.00%) (38794/41088)
Epoch: 135 | Batch_idx: 330 |  Loss: (0.1567) |  Loss2: (0.0000) | Acc: (94.00%) (40021/42368)
Epoch: 135 | Batch_idx: 340 |  Loss: (0.1573) |  Loss2: (0.0000) | Acc: (94.00%) (41212/43648)
Epoch: 135 | Batch_idx: 350 |  Loss: (0.1568) |  Loss2: (0.0000) | Acc: (94.00%) (42433/44928)
Epoch: 135 | Batch_idx: 360 |  Loss: (0.1564) |  Loss2: (0.0000) | Acc: (94.00%) (43653/46208)
Epoch: 135 | Batch_idx: 370 |  Loss: (0.1568) |  Loss2: (0.0000) | Acc: (94.00%) (44856/47488)
Epoch: 135 | Batch_idx: 380 |  Loss: (0.1566) |  Loss2: (0.0000) | Acc: (94.00%) (46070/48768)
Epoch: 135 | Batch_idx: 390 |  Loss: (0.1572) |  Loss2: (0.0000) | Acc: (94.00%) (47225/50000)
=> saving checkpoint 'drive/app/torch/save_Schedule/checkpoint_135.pth.tar'
# TEST : Loss: (0.4032) | Acc: (87.00%) (8780/10000)
percent tensor([0.5594, 0.5719, 0.5909, 0.5818, 0.5921, 0.5640, 0.5798, 0.5888, 0.5686,
        0.5753, 0.5572, 0.5862, 0.5612, 0.5720, 0.5701, 0.5625],
       device='cuda:0') torch.Size([16])
percent tensor([0.5805, 0.5822, 0.5756, 0.5673, 0.5821, 0.5836, 0.5879, 0.5804, 0.5761,
        0.5784, 0.5826, 0.5853, 0.5806, 0.5734, 0.5878, 0.5797],
       device='cuda:0') torch.Size([16])
percent tensor([0.6064, 0.6149, 0.5813, 0.5583, 0.5646, 0.5755, 0.6020, 0.5797, 0.5904,
        0.6149, 0.6051, 0.6008, 0.6312, 0.5928, 0.6033, 0.6067],
       device='cuda:0') torch.Size([16])
percent tensor([0.6263, 0.6179, 0.6013, 0.6072, 0.6157, 0.6406, 0.6266, 0.6086, 0.6163,
        0.6195, 0.6231, 0.6134, 0.6161, 0.6216, 0.6311, 0.6286],
       device='cuda:0') torch.Size([16])
percent tensor([0.5314, 0.4812, 0.6304, 0.6438, 0.6505, 0.5957, 0.5443, 0.6394, 0.5695,
        0.4838, 0.4996, 0.5561, 0.4245, 0.5727, 0.5682, 0.5403],
       device='cuda:0') torch.Size([16])
percent tensor([0.5815, 0.6648, 0.6740, 0.6535, 0.6840, 0.7292, 0.6420, 0.5862, 0.6792,
        0.6413, 0.6934, 0.6295, 0.6809, 0.6937, 0.5279, 0.5710],
       device='cuda:0') torch.Size([16])
percent tensor([0.6810, 0.6844, 0.7083, 0.6601, 0.7072, 0.7166, 0.7137, 0.6528, 0.6791,
        0.6940, 0.6930, 0.6324, 0.6792, 0.7108, 0.5962, 0.6459],
       device='cuda:0') torch.Size([16])
percent tensor([0.9997, 0.9995, 0.9997, 0.9997, 0.9999, 0.9997, 0.9999, 0.9999, 0.9998,
        0.9998, 0.9997, 0.9994, 0.9995, 0.9995, 0.9994, 0.9995],
       device='cuda:0') torch.Size([16])
Epoch: 136 | Batch_idx: 0 |  Loss: (0.1203) |  Loss2: (0.0000) | Acc: (94.00%) (121/128)
Epoch: 136 | Batch_idx: 10 |  Loss: (0.1663) |  Loss2: (0.0000) | Acc: (94.00%) (1328/1408)
Epoch: 136 | Batch_idx: 20 |  Loss: (0.1585) |  Loss2: (0.0000) | Acc: (94.00%) (2545/2688)
Epoch: 136 | Batch_idx: 30 |  Loss: (0.1489) |  Loss2: (0.0000) | Acc: (94.00%) (3768/3968)
Epoch: 136 | Batch_idx: 40 |  Loss: (0.1561) |  Loss2: (0.0000) | Acc: (94.00%) (4963/5248)
Epoch: 136 | Batch_idx: 50 |  Loss: (0.1569) |  Loss2: (0.0000) | Acc: (94.00%) (6167/6528)
Epoch: 136 | Batch_idx: 60 |  Loss: (0.1583) |  Loss2: (0.0000) | Acc: (94.00%) (7371/7808)
Epoch: 136 | Batch_idx: 70 |  Loss: (0.1541) |  Loss2: (0.0000) | Acc: (94.00%) (8599/9088)
Epoch: 136 | Batch_idx: 80 |  Loss: (0.1538) |  Loss2: (0.0000) | Acc: (94.00%) (9806/10368)
Epoch: 136 | Batch_idx: 90 |  Loss: (0.1520) |  Loss2: (0.0000) | Acc: (94.00%) (11024/11648)
Epoch: 136 | Batch_idx: 100 |  Loss: (0.1518) |  Loss2: (0.0000) | Acc: (94.00%) (12239/12928)
Epoch: 136 | Batch_idx: 110 |  Loss: (0.1519) |  Loss2: (0.0000) | Acc: (94.00%) (13454/14208)
Epoch: 136 | Batch_idx: 120 |  Loss: (0.1524) |  Loss2: (0.0000) | Acc: (94.00%) (14663/15488)
Epoch: 136 | Batch_idx: 130 |  Loss: (0.1510) |  Loss2: (0.0000) | Acc: (94.00%) (15889/16768)
Epoch: 136 | Batch_idx: 140 |  Loss: (0.1512) |  Loss2: (0.0000) | Acc: (94.00%) (17091/18048)
Epoch: 136 | Batch_idx: 150 |  Loss: (0.1510) |  Loss2: (0.0000) | Acc: (94.00%) (18302/19328)
Epoch: 136 | Batch_idx: 160 |  Loss: (0.1504) |  Loss2: (0.0000) | Acc: (94.00%) (19521/20608)
Epoch: 136 | Batch_idx: 170 |  Loss: (0.1505) |  Loss2: (0.0000) | Acc: (94.00%) (20730/21888)
Epoch: 136 | Batch_idx: 180 |  Loss: (0.1512) |  Loss2: (0.0000) | Acc: (94.00%) (21943/23168)
Epoch: 136 | Batch_idx: 190 |  Loss: (0.1507) |  Loss2: (0.0000) | Acc: (94.00%) (23155/24448)
Epoch: 136 | Batch_idx: 200 |  Loss: (0.1501) |  Loss2: (0.0000) | Acc: (94.00%) (24373/25728)
Epoch: 136 | Batch_idx: 210 |  Loss: (0.1504) |  Loss2: (0.0000) | Acc: (94.00%) (25584/27008)
Epoch: 136 | Batch_idx: 220 |  Loss: (0.1506) |  Loss2: (0.0000) | Acc: (94.00%) (26797/28288)
Epoch: 136 | Batch_idx: 230 |  Loss: (0.1496) |  Loss2: (0.0000) | Acc: (94.00%) (28025/29568)
Epoch: 136 | Batch_idx: 240 |  Loss: (0.1495) |  Loss2: (0.0000) | Acc: (94.00%) (29237/30848)
Epoch: 136 | Batch_idx: 250 |  Loss: (0.1496) |  Loss2: (0.0000) | Acc: (94.00%) (30446/32128)
Epoch: 136 | Batch_idx: 260 |  Loss: (0.1480) |  Loss2: (0.0000) | Acc: (94.00%) (31681/33408)
Epoch: 136 | Batch_idx: 270 |  Loss: (0.1475) |  Loss2: (0.0000) | Acc: (94.00%) (32890/34688)
Epoch: 136 | Batch_idx: 280 |  Loss: (0.1478) |  Loss2: (0.0000) | Acc: (94.00%) (34099/35968)
Epoch: 136 | Batch_idx: 290 |  Loss: (0.1478) |  Loss2: (0.0000) | Acc: (94.00%) (35314/37248)
Epoch: 136 | Batch_idx: 300 |  Loss: (0.1479) |  Loss2: (0.0000) | Acc: (94.00%) (36531/38528)
Epoch: 136 | Batch_idx: 310 |  Loss: (0.1481) |  Loss2: (0.0000) | Acc: (94.00%) (37734/39808)
Epoch: 136 | Batch_idx: 320 |  Loss: (0.1488) |  Loss2: (0.0000) | Acc: (94.00%) (38940/41088)
Epoch: 136 | Batch_idx: 330 |  Loss: (0.1490) |  Loss2: (0.0000) | Acc: (94.00%) (40158/42368)
Epoch: 136 | Batch_idx: 340 |  Loss: (0.1489) |  Loss2: (0.0000) | Acc: (94.00%) (41371/43648)
Epoch: 136 | Batch_idx: 350 |  Loss: (0.1487) |  Loss2: (0.0000) | Acc: (94.00%) (42587/44928)
Epoch: 136 | Batch_idx: 360 |  Loss: (0.1480) |  Loss2: (0.0000) | Acc: (94.00%) (43816/46208)
Epoch: 136 | Batch_idx: 370 |  Loss: (0.1482) |  Loss2: (0.0000) | Acc: (94.00%) (45025/47488)
Epoch: 136 | Batch_idx: 380 |  Loss: (0.1480) |  Loss2: (0.0000) | Acc: (94.00%) (46235/48768)
Epoch: 136 | Batch_idx: 390 |  Loss: (0.1484) |  Loss2: (0.0000) | Acc: (94.00%) (47402/50000)
# TEST : Loss: (0.3971) | Acc: (87.00%) (8789/10000)
percent tensor([0.5568, 0.5688, 0.5878, 0.5792, 0.5887, 0.5616, 0.5765, 0.5858, 0.5657,
        0.5723, 0.5544, 0.5829, 0.5585, 0.5693, 0.5672, 0.5599],
       device='cuda:0') torch.Size([16])
percent tensor([0.5829, 0.5844, 0.5782, 0.5703, 0.5848, 0.5865, 0.5903, 0.5830, 0.5782,
        0.5807, 0.5849, 0.5877, 0.5826, 0.5756, 0.5904, 0.5823],
       device='cuda:0') torch.Size([16])
percent tensor([0.6117, 0.6202, 0.5848, 0.5622, 0.5679, 0.5804, 0.6071, 0.5834, 0.5943,
        0.6197, 0.6103, 0.6052, 0.6362, 0.5966, 0.6091, 0.6120],
       device='cuda:0') torch.Size([16])
percent tensor([0.6348, 0.6254, 0.6083, 0.6157, 0.6241, 0.6500, 0.6353, 0.6173, 0.6239,
        0.6273, 0.6305, 0.6214, 0.6232, 0.6296, 0.6401, 0.6376],
       device='cuda:0') torch.Size([16])
percent tensor([0.5433, 0.4895, 0.6354, 0.6498, 0.6548, 0.6059, 0.5541, 0.6473, 0.5729,
        0.4920, 0.5082, 0.5621, 0.4340, 0.5735, 0.5794, 0.5529],
       device='cuda:0') torch.Size([16])
percent tensor([0.5671, 0.6542, 0.6672, 0.6449, 0.6786, 0.7251, 0.6288, 0.5771, 0.6705,
        0.6303, 0.6859, 0.6198, 0.6709, 0.6881, 0.5117, 0.5551],
       device='cuda:0') torch.Size([16])
percent tensor([0.6826, 0.6852, 0.7091, 0.6605, 0.7073, 0.7182, 0.7134, 0.6531, 0.6784,
        0.6930, 0.6966, 0.6321, 0.6837, 0.7119, 0.5948, 0.6437],
       device='cuda:0') torch.Size([16])
percent tensor([0.9997, 0.9995, 0.9997, 0.9997, 0.9999, 0.9998, 0.9999, 0.9999, 0.9998,
        0.9998, 0.9997, 0.9994, 0.9996, 0.9995, 0.9994, 0.9995],
       device='cuda:0') torch.Size([16])
Epoch: 137 | Batch_idx: 0 |  Loss: (0.1489) |  Loss2: (0.0000) | Acc: (95.00%) (122/128)
Epoch: 137 | Batch_idx: 10 |  Loss: (0.1421) |  Loss2: (0.0000) | Acc: (95.00%) (1344/1408)
Epoch: 137 | Batch_idx: 20 |  Loss: (0.1413) |  Loss2: (0.0000) | Acc: (95.00%) (2561/2688)
Epoch: 137 | Batch_idx: 30 |  Loss: (0.1397) |  Loss2: (0.0000) | Acc: (95.00%) (3783/3968)
Epoch: 137 | Batch_idx: 40 |  Loss: (0.1416) |  Loss2: (0.0000) | Acc: (95.00%) (4991/5248)
Epoch: 137 | Batch_idx: 50 |  Loss: (0.1406) |  Loss2: (0.0000) | Acc: (95.00%) (6217/6528)
Epoch: 137 | Batch_idx: 60 |  Loss: (0.1390) |  Loss2: (0.0000) | Acc: (95.00%) (7434/7808)
Epoch: 137 | Batch_idx: 70 |  Loss: (0.1376) |  Loss2: (0.0000) | Acc: (95.00%) (8652/9088)
Epoch: 137 | Batch_idx: 80 |  Loss: (0.1370) |  Loss2: (0.0000) | Acc: (95.00%) (9878/10368)
Epoch: 137 | Batch_idx: 90 |  Loss: (0.1382) |  Loss2: (0.0000) | Acc: (95.00%) (11090/11648)
Epoch: 137 | Batch_idx: 100 |  Loss: (0.1398) |  Loss2: (0.0000) | Acc: (95.00%) (12299/12928)
Epoch: 137 | Batch_idx: 110 |  Loss: (0.1403) |  Loss2: (0.0000) | Acc: (95.00%) (13512/14208)
Epoch: 137 | Batch_idx: 120 |  Loss: (0.1422) |  Loss2: (0.0000) | Acc: (94.00%) (14711/15488)
Epoch: 137 | Batch_idx: 130 |  Loss: (0.1421) |  Loss2: (0.0000) | Acc: (94.00%) (15929/16768)
Epoch: 137 | Batch_idx: 140 |  Loss: (0.1417) |  Loss2: (0.0000) | Acc: (95.00%) (17148/18048)
Epoch: 137 | Batch_idx: 150 |  Loss: (0.1414) |  Loss2: (0.0000) | Acc: (95.00%) (18370/19328)
Epoch: 137 | Batch_idx: 160 |  Loss: (0.1435) |  Loss2: (0.0000) | Acc: (94.00%) (19576/20608)
Epoch: 137 | Batch_idx: 170 |  Loss: (0.1439) |  Loss2: (0.0000) | Acc: (94.00%) (20788/21888)
Epoch: 137 | Batch_idx: 180 |  Loss: (0.1446) |  Loss2: (0.0000) | Acc: (94.00%) (21993/23168)
Epoch: 137 | Batch_idx: 190 |  Loss: (0.1448) |  Loss2: (0.0000) | Acc: (94.00%) (23212/24448)
Epoch: 137 | Batch_idx: 200 |  Loss: (0.1455) |  Loss2: (0.0000) | Acc: (94.00%) (24423/25728)
Epoch: 137 | Batch_idx: 210 |  Loss: (0.1455) |  Loss2: (0.0000) | Acc: (94.00%) (25640/27008)
Epoch: 137 | Batch_idx: 220 |  Loss: (0.1456) |  Loss2: (0.0000) | Acc: (94.00%) (26852/28288)
Epoch: 137 | Batch_idx: 230 |  Loss: (0.1457) |  Loss2: (0.0000) | Acc: (94.00%) (28067/29568)
Epoch: 137 | Batch_idx: 240 |  Loss: (0.1448) |  Loss2: (0.0000) | Acc: (94.00%) (29298/30848)
Epoch: 137 | Batch_idx: 250 |  Loss: (0.1449) |  Loss2: (0.0000) | Acc: (94.00%) (30510/32128)
Epoch: 137 | Batch_idx: 260 |  Loss: (0.1453) |  Loss2: (0.0000) | Acc: (94.00%) (31719/33408)
Epoch: 137 | Batch_idx: 270 |  Loss: (0.1456) |  Loss2: (0.0000) | Acc: (94.00%) (32934/34688)
Epoch: 137 | Batch_idx: 280 |  Loss: (0.1453) |  Loss2: (0.0000) | Acc: (94.00%) (34153/35968)
Epoch: 137 | Batch_idx: 290 |  Loss: (0.1453) |  Loss2: (0.0000) | Acc: (94.00%) (35372/37248)
Epoch: 137 | Batch_idx: 300 |  Loss: (0.1447) |  Loss2: (0.0000) | Acc: (94.00%) (36600/38528)
Epoch: 137 | Batch_idx: 310 |  Loss: (0.1449) |  Loss2: (0.0000) | Acc: (94.00%) (37811/39808)
Epoch: 137 | Batch_idx: 320 |  Loss: (0.1447) |  Loss2: (0.0000) | Acc: (94.00%) (39027/41088)
Epoch: 137 | Batch_idx: 330 |  Loss: (0.1448) |  Loss2: (0.0000) | Acc: (94.00%) (40236/42368)
Epoch: 137 | Batch_idx: 340 |  Loss: (0.1446) |  Loss2: (0.0000) | Acc: (94.00%) (41455/43648)
Epoch: 137 | Batch_idx: 350 |  Loss: (0.1449) |  Loss2: (0.0000) | Acc: (94.00%) (42673/44928)
Epoch: 137 | Batch_idx: 360 |  Loss: (0.1452) |  Loss2: (0.0000) | Acc: (94.00%) (43885/46208)
Epoch: 137 | Batch_idx: 370 |  Loss: (0.1450) |  Loss2: (0.0000) | Acc: (94.00%) (45098/47488)
Epoch: 137 | Batch_idx: 380 |  Loss: (0.1448) |  Loss2: (0.0000) | Acc: (94.00%) (46318/48768)
Epoch: 137 | Batch_idx: 390 |  Loss: (0.1450) |  Loss2: (0.0000) | Acc: (94.00%) (47483/50000)
# TEST : Loss: (0.3924) | Acc: (88.00%) (8813/10000)
percent tensor([0.5586, 0.5711, 0.5903, 0.5812, 0.5914, 0.5638, 0.5790, 0.5880, 0.5677,
        0.5744, 0.5565, 0.5855, 0.5605, 0.5710, 0.5694, 0.5617],
       device='cuda:0') torch.Size([16])
percent tensor([0.5833, 0.5845, 0.5787, 0.5712, 0.5851, 0.5870, 0.5906, 0.5834, 0.5786,
        0.5811, 0.5853, 0.5883, 0.5827, 0.5758, 0.5908, 0.5828],
       device='cuda:0') torch.Size([16])
percent tensor([0.6099, 0.6189, 0.5832, 0.5617, 0.5670, 0.5800, 0.6061, 0.5820, 0.5930,
        0.6181, 0.6091, 0.6039, 0.6342, 0.5953, 0.6085, 0.6105],
       device='cuda:0') torch.Size([16])
percent tensor([0.6383, 0.6290, 0.6110, 0.6192, 0.6278, 0.6543, 0.6394, 0.6207, 0.6273,
        0.6307, 0.6342, 0.6248, 0.6265, 0.6335, 0.6440, 0.6413],
       device='cuda:0') torch.Size([16])
percent tensor([0.5443, 0.4929, 0.6323, 0.6485, 0.6528, 0.6033, 0.5557, 0.6457, 0.5726,
        0.4969, 0.5158, 0.5667, 0.4351, 0.5774, 0.5827, 0.5535],
       device='cuda:0') torch.Size([16])
percent tensor([0.5651, 0.6505, 0.6643, 0.6419, 0.6767, 0.7255, 0.6260, 0.5744, 0.6675,
        0.6266, 0.6830, 0.6170, 0.6679, 0.6852, 0.5070, 0.5526],
       device='cuda:0') torch.Size([16])
percent tensor([0.6820, 0.6838, 0.7057, 0.6575, 0.7026, 0.7172, 0.7092, 0.6483, 0.6748,
        0.6900, 0.6948, 0.6293, 0.6850, 0.7096, 0.5902, 0.6413],
       device='cuda:0') torch.Size([16])
percent tensor([0.9997, 0.9995, 0.9997, 0.9997, 0.9999, 0.9997, 0.9999, 0.9999, 0.9998,
        0.9998, 0.9997, 0.9994, 0.9996, 0.9996, 0.9993, 0.9995],
       device='cuda:0') torch.Size([16])
Epoch: 138 | Batch_idx: 0 |  Loss: (0.1905) |  Loss2: (0.0000) | Acc: (92.00%) (118/128)
Epoch: 138 | Batch_idx: 10 |  Loss: (0.1380) |  Loss2: (0.0000) | Acc: (94.00%) (1336/1408)
Epoch: 138 | Batch_idx: 20 |  Loss: (0.1341) |  Loss2: (0.0000) | Acc: (95.00%) (2561/2688)
Epoch: 138 | Batch_idx: 30 |  Loss: (0.1293) |  Loss2: (0.0000) | Acc: (95.00%) (3792/3968)
Epoch: 138 | Batch_idx: 40 |  Loss: (0.1321) |  Loss2: (0.0000) | Acc: (95.00%) (5010/5248)
Epoch: 138 | Batch_idx: 50 |  Loss: (0.1379) |  Loss2: (0.0000) | Acc: (95.00%) (6213/6528)
Epoch: 138 | Batch_idx: 60 |  Loss: (0.1391) |  Loss2: (0.0000) | Acc: (95.00%) (7419/7808)
Epoch: 138 | Batch_idx: 70 |  Loss: (0.1384) |  Loss2: (0.0000) | Acc: (95.00%) (8634/9088)
Epoch: 138 | Batch_idx: 80 |  Loss: (0.1386) |  Loss2: (0.0000) | Acc: (95.00%) (9857/10368)
Epoch: 138 | Batch_idx: 90 |  Loss: (0.1388) |  Loss2: (0.0000) | Acc: (95.00%) (11074/11648)
Epoch: 138 | Batch_idx: 100 |  Loss: (0.1378) |  Loss2: (0.0000) | Acc: (95.00%) (12297/12928)
Epoch: 138 | Batch_idx: 110 |  Loss: (0.1382) |  Loss2: (0.0000) | Acc: (95.00%) (13509/14208)
Epoch: 138 | Batch_idx: 120 |  Loss: (0.1396) |  Loss2: (0.0000) | Acc: (95.00%) (14718/15488)
Epoch: 138 | Batch_idx: 130 |  Loss: (0.1401) |  Loss2: (0.0000) | Acc: (95.00%) (15930/16768)
Epoch: 138 | Batch_idx: 140 |  Loss: (0.1398) |  Loss2: (0.0000) | Acc: (95.00%) (17152/18048)
Epoch: 138 | Batch_idx: 150 |  Loss: (0.1403) |  Loss2: (0.0000) | Acc: (95.00%) (18366/19328)
Epoch: 138 | Batch_idx: 160 |  Loss: (0.1405) |  Loss2: (0.0000) | Acc: (95.00%) (19592/20608)
Epoch: 138 | Batch_idx: 170 |  Loss: (0.1412) |  Loss2: (0.0000) | Acc: (95.00%) (20803/21888)
Epoch: 138 | Batch_idx: 180 |  Loss: (0.1410) |  Loss2: (0.0000) | Acc: (95.00%) (22023/23168)
Epoch: 138 | Batch_idx: 190 |  Loss: (0.1405) |  Loss2: (0.0000) | Acc: (95.00%) (23245/24448)
Epoch: 138 | Batch_idx: 200 |  Loss: (0.1406) |  Loss2: (0.0000) | Acc: (95.00%) (24464/25728)
Epoch: 138 | Batch_idx: 210 |  Loss: (0.1411) |  Loss2: (0.0000) | Acc: (95.00%) (25683/27008)
Epoch: 138 | Batch_idx: 220 |  Loss: (0.1415) |  Loss2: (0.0000) | Acc: (95.00%) (26900/28288)
Epoch: 138 | Batch_idx: 230 |  Loss: (0.1417) |  Loss2: (0.0000) | Acc: (95.00%) (28117/29568)
Epoch: 138 | Batch_idx: 240 |  Loss: (0.1420) |  Loss2: (0.0000) | Acc: (95.00%) (29335/30848)
Epoch: 138 | Batch_idx: 250 |  Loss: (0.1417) |  Loss2: (0.0000) | Acc: (95.00%) (30552/32128)
Epoch: 138 | Batch_idx: 260 |  Loss: (0.1420) |  Loss2: (0.0000) | Acc: (95.00%) (31767/33408)
Epoch: 138 | Batch_idx: 270 |  Loss: (0.1415) |  Loss2: (0.0000) | Acc: (95.00%) (32990/34688)
Epoch: 138 | Batch_idx: 280 |  Loss: (0.1415) |  Loss2: (0.0000) | Acc: (95.00%) (34204/35968)
Epoch: 138 | Batch_idx: 290 |  Loss: (0.1421) |  Loss2: (0.0000) | Acc: (95.00%) (35415/37248)
Epoch: 138 | Batch_idx: 300 |  Loss: (0.1423) |  Loss2: (0.0000) | Acc: (95.00%) (36619/38528)
Epoch: 138 | Batch_idx: 310 |  Loss: (0.1420) |  Loss2: (0.0000) | Acc: (95.00%) (37838/39808)
Epoch: 138 | Batch_idx: 320 |  Loss: (0.1411) |  Loss2: (0.0000) | Acc: (95.00%) (39064/41088)
Epoch: 138 | Batch_idx: 330 |  Loss: (0.1417) |  Loss2: (0.0000) | Acc: (95.00%) (40269/42368)
Epoch: 138 | Batch_idx: 340 |  Loss: (0.1416) |  Loss2: (0.0000) | Acc: (95.00%) (41497/43648)
Epoch: 138 | Batch_idx: 350 |  Loss: (0.1413) |  Loss2: (0.0000) | Acc: (95.00%) (42719/44928)
Epoch: 138 | Batch_idx: 360 |  Loss: (0.1420) |  Loss2: (0.0000) | Acc: (95.00%) (43928/46208)
Epoch: 138 | Batch_idx: 370 |  Loss: (0.1417) |  Loss2: (0.0000) | Acc: (95.00%) (45148/47488)
Epoch: 138 | Batch_idx: 380 |  Loss: (0.1417) |  Loss2: (0.0000) | Acc: (95.00%) (46373/48768)
Epoch: 138 | Batch_idx: 390 |  Loss: (0.1421) |  Loss2: (0.0000) | Acc: (95.00%) (47536/50000)
# TEST : Loss: (0.3928) | Acc: (88.00%) (8817/10000)
percent tensor([0.5564, 0.5686, 0.5868, 0.5785, 0.5879, 0.5619, 0.5760, 0.5848, 0.5651,
        0.5717, 0.5543, 0.5821, 0.5580, 0.5689, 0.5670, 0.5597],
       device='cuda:0') torch.Size([16])
percent tensor([0.5835, 0.5843, 0.5789, 0.5717, 0.5853, 0.5876, 0.5904, 0.5834, 0.5784,
        0.5810, 0.5854, 0.5882, 0.5823, 0.5758, 0.5910, 0.5830],
       device='cuda:0') torch.Size([16])
percent tensor([0.6141, 0.6231, 0.5862, 0.5652, 0.5704, 0.5834, 0.6102, 0.5855, 0.5962,
        0.6220, 0.6130, 0.6075, 0.6383, 0.5987, 0.6129, 0.6146],
       device='cuda:0') torch.Size([16])
percent tensor([0.6342, 0.6240, 0.6069, 0.6155, 0.6241, 0.6512, 0.6348, 0.6172, 0.6231,
        0.6254, 0.6290, 0.6201, 0.6218, 0.6286, 0.6398, 0.6373],
       device='cuda:0') torch.Size([16])
percent tensor([0.5295, 0.4794, 0.6169, 0.6347, 0.6409, 0.5900, 0.5417, 0.6319, 0.5582,
        0.4823, 0.5011, 0.5498, 0.4207, 0.5634, 0.5683, 0.5378],
       device='cuda:0') torch.Size([16])
percent tensor([0.5727, 0.6602, 0.6700, 0.6468, 0.6829, 0.7288, 0.6357, 0.5834, 0.6748,
        0.6345, 0.6885, 0.6250, 0.6750, 0.6947, 0.5187, 0.5599],
       device='cuda:0') torch.Size([16])
percent tensor([0.6853, 0.6878, 0.7084, 0.6553, 0.7005, 0.7190, 0.7115, 0.6457, 0.6745,
        0.6901, 0.6988, 0.6261, 0.6900, 0.7104, 0.5861, 0.6398],
       device='cuda:0') torch.Size([16])
percent tensor([0.9997, 0.9995, 0.9997, 0.9997, 0.9999, 0.9998, 0.9999, 0.9999, 0.9998,
        0.9998, 0.9997, 0.9994, 0.9996, 0.9995, 0.9994, 0.9995],
       device='cuda:0') torch.Size([16])
Epoch: 139 | Batch_idx: 0 |  Loss: (0.1147) |  Loss2: (0.0000) | Acc: (95.00%) (122/128)
Epoch: 139 | Batch_idx: 10 |  Loss: (0.1270) |  Loss2: (0.0000) | Acc: (95.00%) (1348/1408)
Epoch: 139 | Batch_idx: 20 |  Loss: (0.1303) |  Loss2: (0.0000) | Acc: (95.00%) (2571/2688)
Epoch: 139 | Batch_idx: 30 |  Loss: (0.1411) |  Loss2: (0.0000) | Acc: (95.00%) (3782/3968)
Epoch: 139 | Batch_idx: 40 |  Loss: (0.1409) |  Loss2: (0.0000) | Acc: (95.00%) (5001/5248)
Epoch: 139 | Batch_idx: 50 |  Loss: (0.1440) |  Loss2: (0.0000) | Acc: (95.00%) (6206/6528)
Epoch: 139 | Batch_idx: 60 |  Loss: (0.1428) |  Loss2: (0.0000) | Acc: (95.00%) (7432/7808)
Epoch: 139 | Batch_idx: 70 |  Loss: (0.1446) |  Loss2: (0.0000) | Acc: (95.00%) (8648/9088)
Epoch: 139 | Batch_idx: 80 |  Loss: (0.1438) |  Loss2: (0.0000) | Acc: (95.00%) (9862/10368)
Epoch: 139 | Batch_idx: 90 |  Loss: (0.1484) |  Loss2: (0.0000) | Acc: (94.00%) (11049/11648)
Epoch: 139 | Batch_idx: 100 |  Loss: (0.1458) |  Loss2: (0.0000) | Acc: (94.00%) (12276/12928)
Epoch: 139 | Batch_idx: 110 |  Loss: (0.1439) |  Loss2: (0.0000) | Acc: (95.00%) (13500/14208)
Epoch: 139 | Batch_idx: 120 |  Loss: (0.1424) |  Loss2: (0.0000) | Acc: (95.00%) (14725/15488)
Epoch: 139 | Batch_idx: 130 |  Loss: (0.1419) |  Loss2: (0.0000) | Acc: (95.00%) (15939/16768)
Epoch: 139 | Batch_idx: 140 |  Loss: (0.1412) |  Loss2: (0.0000) | Acc: (95.00%) (17166/18048)
Epoch: 139 | Batch_idx: 150 |  Loss: (0.1411) |  Loss2: (0.0000) | Acc: (95.00%) (18382/19328)
Epoch: 139 | Batch_idx: 160 |  Loss: (0.1403) |  Loss2: (0.0000) | Acc: (95.00%) (19601/20608)
Epoch: 139 | Batch_idx: 170 |  Loss: (0.1397) |  Loss2: (0.0000) | Acc: (95.00%) (20820/21888)
Epoch: 139 | Batch_idx: 180 |  Loss: (0.1408) |  Loss2: (0.0000) | Acc: (95.00%) (22026/23168)
Epoch: 139 | Batch_idx: 190 |  Loss: (0.1410) |  Loss2: (0.0000) | Acc: (95.00%) (23246/24448)
Epoch: 139 | Batch_idx: 200 |  Loss: (0.1413) |  Loss2: (0.0000) | Acc: (95.00%) (24466/25728)
Epoch: 139 | Batch_idx: 210 |  Loss: (0.1411) |  Loss2: (0.0000) | Acc: (95.00%) (25688/27008)
Epoch: 139 | Batch_idx: 220 |  Loss: (0.1408) |  Loss2: (0.0000) | Acc: (95.00%) (26904/28288)
Epoch: 139 | Batch_idx: 230 |  Loss: (0.1406) |  Loss2: (0.0000) | Acc: (95.00%) (28123/29568)
Epoch: 139 | Batch_idx: 240 |  Loss: (0.1412) |  Loss2: (0.0000) | Acc: (95.00%) (29334/30848)
Epoch: 139 | Batch_idx: 250 |  Loss: (0.1417) |  Loss2: (0.0000) | Acc: (95.00%) (30550/32128)
Epoch: 139 | Batch_idx: 260 |  Loss: (0.1417) |  Loss2: (0.0000) | Acc: (95.00%) (31769/33408)
Epoch: 139 | Batch_idx: 270 |  Loss: (0.1422) |  Loss2: (0.0000) | Acc: (95.00%) (32970/34688)
Epoch: 139 | Batch_idx: 280 |  Loss: (0.1423) |  Loss2: (0.0000) | Acc: (95.00%) (34182/35968)
Epoch: 139 | Batch_idx: 290 |  Loss: (0.1423) |  Loss2: (0.0000) | Acc: (95.00%) (35405/37248)
Epoch: 139 | Batch_idx: 300 |  Loss: (0.1418) |  Loss2: (0.0000) | Acc: (95.00%) (36634/38528)
Epoch: 139 | Batch_idx: 310 |  Loss: (0.1419) |  Loss2: (0.0000) | Acc: (95.00%) (37855/39808)
Epoch: 139 | Batch_idx: 320 |  Loss: (0.1418) |  Loss2: (0.0000) | Acc: (95.00%) (39071/41088)
Epoch: 139 | Batch_idx: 330 |  Loss: (0.1418) |  Loss2: (0.0000) | Acc: (95.00%) (40287/42368)
Epoch: 139 | Batch_idx: 340 |  Loss: (0.1412) |  Loss2: (0.0000) | Acc: (95.00%) (41515/43648)
Epoch: 139 | Batch_idx: 350 |  Loss: (0.1414) |  Loss2: (0.0000) | Acc: (95.00%) (42731/44928)
Epoch: 139 | Batch_idx: 360 |  Loss: (0.1417) |  Loss2: (0.0000) | Acc: (95.00%) (43949/46208)
Epoch: 139 | Batch_idx: 370 |  Loss: (0.1415) |  Loss2: (0.0000) | Acc: (95.00%) (45179/47488)
Epoch: 139 | Batch_idx: 380 |  Loss: (0.1419) |  Loss2: (0.0000) | Acc: (95.00%) (46391/48768)
Epoch: 139 | Batch_idx: 390 |  Loss: (0.1421) |  Loss2: (0.0000) | Acc: (95.00%) (47560/50000)
# TEST : Loss: (0.3876) | Acc: (88.00%) (8820/10000)
percent tensor([0.5605, 0.5732, 0.5910, 0.5829, 0.5923, 0.5665, 0.5805, 0.5893, 0.5692,
        0.5758, 0.5585, 0.5862, 0.5622, 0.5731, 0.5718, 0.5640],
       device='cuda:0') torch.Size([16])
percent tensor([0.5841, 0.5845, 0.5799, 0.5731, 0.5860, 0.5887, 0.5906, 0.5841, 0.5788,
        0.5814, 0.5857, 0.5886, 0.5824, 0.5764, 0.5916, 0.5839],
       device='cuda:0') torch.Size([16])
percent tensor([0.6122, 0.6214, 0.5856, 0.5652, 0.5708, 0.5825, 0.6091, 0.5852, 0.5942,
        0.6197, 0.6104, 0.6064, 0.6354, 0.5966, 0.6123, 0.6126],
       device='cuda:0') torch.Size([16])
percent tensor([0.6367, 0.6263, 0.6087, 0.6179, 0.6266, 0.6544, 0.6375, 0.6197, 0.6254,
        0.6277, 0.6314, 0.6223, 0.6242, 0.6309, 0.6427, 0.6402],
       device='cuda:0') torch.Size([16])
percent tensor([0.5344, 0.4831, 0.6217, 0.6429, 0.6470, 0.5982, 0.5490, 0.6371, 0.5655,
        0.4895, 0.5106, 0.5586, 0.4259, 0.5742, 0.5749, 0.5462],
       device='cuda:0') torch.Size([16])
percent tensor([0.5605, 0.6499, 0.6590, 0.6341, 0.6711, 0.7187, 0.6217, 0.5704, 0.6629,
        0.6223, 0.6774, 0.6119, 0.6629, 0.6820, 0.5030, 0.5442],
       device='cuda:0') torch.Size([16])
percent tensor([0.6899, 0.6942, 0.7081, 0.6528, 0.6961, 0.7242, 0.7118, 0.6374, 0.6789,
        0.6940, 0.7071, 0.6265, 0.7022, 0.7168, 0.5825, 0.6384],
       device='cuda:0') torch.Size([16])
percent tensor([0.9997, 0.9995, 0.9997, 0.9997, 0.9999, 0.9998, 0.9999, 0.9999, 0.9998,
        0.9998, 0.9997, 0.9993, 0.9996, 0.9996, 0.9994, 0.9995],
       device='cuda:0') torch.Size([16])
True Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=128, out_features=16, bias=False)
False Linear(in_features=16, out_features=2, bias=False)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=128, out_features=16, bias=False)
False Linear(in_features=16, out_features=2, bias=False)
True Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=256, out_features=32, bias=False)
False Linear(in_features=32, out_features=2, bias=False)
True Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=256, out_features=32, bias=False)
False Linear(in_features=32, out_features=2, bias=False)
True Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=512, out_features=64, bias=False)
False Linear(in_features=64, out_features=2, bias=False)
True Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=512, out_features=64, bias=False)
False Linear(in_features=64, out_features=2, bias=False)
True Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1024, out_features=128, bias=False)
False Linear(in_features=128, out_features=2, bias=False)
True Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1024, out_features=128, bias=False)
False Linear(in_features=128, out_features=2, bias=False)
True Linear(in_features=512, out_features=10, bias=True)
Epoch: 140 | Batch_idx: 0 |  Loss: (0.1875) |  Loss2: (0.0000) | Acc: (96.00%) (123/128)
Epoch: 140 | Batch_idx: 10 |  Loss: (0.1380) |  Loss2: (0.0000) | Acc: (95.00%) (1345/1408)
Epoch: 140 | Batch_idx: 20 |  Loss: (0.1406) |  Loss2: (0.0000) | Acc: (95.00%) (2557/2688)
Epoch: 140 | Batch_idx: 30 |  Loss: (0.1409) |  Loss2: (0.0000) | Acc: (95.00%) (3776/3968)
Epoch: 140 | Batch_idx: 40 |  Loss: (0.1451) |  Loss2: (0.0000) | Acc: (94.00%) (4983/5248)
Epoch: 140 | Batch_idx: 50 |  Loss: (0.1457) |  Loss2: (0.0000) | Acc: (94.00%) (6201/6528)
Epoch: 140 | Batch_idx: 60 |  Loss: (0.1475) |  Loss2: (0.0000) | Acc: (94.00%) (7415/7808)
Epoch: 140 | Batch_idx: 70 |  Loss: (0.1522) |  Loss2: (0.0000) | Acc: (94.00%) (8608/9088)
Epoch: 140 | Batch_idx: 80 |  Loss: (0.1517) |  Loss2: (0.0000) | Acc: (94.00%) (9823/10368)
Epoch: 140 | Batch_idx: 90 |  Loss: (0.1504) |  Loss2: (0.0000) | Acc: (94.00%) (11047/11648)
Epoch: 140 | Batch_idx: 100 |  Loss: (0.1507) |  Loss2: (0.0000) | Acc: (94.00%) (12271/12928)
Epoch: 140 | Batch_idx: 110 |  Loss: (0.1533) |  Loss2: (0.0000) | Acc: (94.00%) (13467/14208)
Epoch: 140 | Batch_idx: 120 |  Loss: (0.1519) |  Loss2: (0.0000) | Acc: (94.00%) (14688/15488)
Epoch: 140 | Batch_idx: 130 |  Loss: (0.1520) |  Loss2: (0.0000) | Acc: (94.00%) (15896/16768)
Epoch: 140 | Batch_idx: 140 |  Loss: (0.1513) |  Loss2: (0.0000) | Acc: (94.00%) (17112/18048)
Epoch: 140 | Batch_idx: 150 |  Loss: (0.1502) |  Loss2: (0.0000) | Acc: (94.00%) (18332/19328)
Epoch: 140 | Batch_idx: 160 |  Loss: (0.1502) |  Loss2: (0.0000) | Acc: (94.00%) (19552/20608)
Epoch: 140 | Batch_idx: 170 |  Loss: (0.1499) |  Loss2: (0.0000) | Acc: (94.00%) (20762/21888)
Epoch: 140 | Batch_idx: 180 |  Loss: (0.1503) |  Loss2: (0.0000) | Acc: (94.00%) (21975/23168)
Epoch: 140 | Batch_idx: 190 |  Loss: (0.1502) |  Loss2: (0.0000) | Acc: (94.00%) (23189/24448)
Epoch: 140 | Batch_idx: 200 |  Loss: (0.1509) |  Loss2: (0.0000) | Acc: (94.00%) (24388/25728)
Epoch: 140 | Batch_idx: 210 |  Loss: (0.1502) |  Loss2: (0.0000) | Acc: (94.00%) (25609/27008)
Epoch: 140 | Batch_idx: 220 |  Loss: (0.1512) |  Loss2: (0.0000) | Acc: (94.00%) (26814/28288)
Epoch: 140 | Batch_idx: 230 |  Loss: (0.1510) |  Loss2: (0.0000) | Acc: (94.00%) (28033/29568)
Epoch: 140 | Batch_idx: 240 |  Loss: (0.1524) |  Loss2: (0.0000) | Acc: (94.00%) (29231/30848)
Epoch: 140 | Batch_idx: 250 |  Loss: (0.1523) |  Loss2: (0.0000) | Acc: (94.00%) (30448/32128)
Epoch: 140 | Batch_idx: 260 |  Loss: (0.1526) |  Loss2: (0.0000) | Acc: (94.00%) (31658/33408)
Epoch: 140 | Batch_idx: 270 |  Loss: (0.1530) |  Loss2: (0.0000) | Acc: (94.00%) (32866/34688)
Epoch: 140 | Batch_idx: 280 |  Loss: (0.1537) |  Loss2: (0.0000) | Acc: (94.00%) (34063/35968)
Epoch: 140 | Batch_idx: 290 |  Loss: (0.1541) |  Loss2: (0.0000) | Acc: (94.00%) (35266/37248)
Epoch: 140 | Batch_idx: 300 |  Loss: (0.1540) |  Loss2: (0.0000) | Acc: (94.00%) (36471/38528)
Epoch: 140 | Batch_idx: 310 |  Loss: (0.1544) |  Loss2: (0.0000) | Acc: (94.00%) (37681/39808)
Epoch: 140 | Batch_idx: 320 |  Loss: (0.1548) |  Loss2: (0.0000) | Acc: (94.00%) (38876/41088)
Epoch: 140 | Batch_idx: 330 |  Loss: (0.1561) |  Loss2: (0.0000) | Acc: (94.00%) (40071/42368)
Epoch: 140 | Batch_idx: 340 |  Loss: (0.1558) |  Loss2: (0.0000) | Acc: (94.00%) (41284/43648)
Epoch: 140 | Batch_idx: 350 |  Loss: (0.1567) |  Loss2: (0.0000) | Acc: (94.00%) (42477/44928)
Epoch: 140 | Batch_idx: 360 |  Loss: (0.1571) |  Loss2: (0.0000) | Acc: (94.00%) (43682/46208)
Epoch: 140 | Batch_idx: 370 |  Loss: (0.1564) |  Loss2: (0.0000) | Acc: (94.00%) (44901/47488)
Epoch: 140 | Batch_idx: 380 |  Loss: (0.1566) |  Loss2: (0.0000) | Acc: (94.00%) (46109/48768)
Epoch: 140 | Batch_idx: 390 |  Loss: (0.1562) |  Loss2: (0.0000) | Acc: (94.00%) (47274/50000)
=> saving checkpoint 'drive/app/torch/save_Schedule/checkpoint_140.pth.tar'
# TEST : Loss: (0.4252) | Acc: (87.00%) (8760/10000)
percent tensor([0.5608, 0.5704, 0.5964, 0.5825, 0.5967, 0.5673, 0.5811, 0.5897, 0.5690,
        0.5767, 0.5591, 0.5904, 0.5619, 0.5673, 0.5710, 0.5638],
       device='cuda:0') torch.Size([16])
percent tensor([0.5840, 0.5861, 0.5773, 0.5718, 0.5849, 0.5882, 0.5920, 0.5818, 0.5779,
        0.5814, 0.5864, 0.5872, 0.5817, 0.5782, 0.5928, 0.5849],
       device='cuda:0') torch.Size([16])
percent tensor([0.6114, 0.6266, 0.5841, 0.5624, 0.5708, 0.5817, 0.6135, 0.5793, 0.5989,
        0.6208, 0.6121, 0.6077, 0.6356, 0.6059, 0.6122, 0.6134],
       device='cuda:0') torch.Size([16])
percent tensor([0.6379, 0.6291, 0.6060, 0.6142, 0.6259, 0.6513, 0.6411, 0.6191, 0.6259,
        0.6312, 0.6328, 0.6199, 0.6277, 0.6325, 0.6442, 0.6400],
       device='cuda:0') torch.Size([16])
percent tensor([0.5340, 0.4633, 0.6034, 0.6357, 0.6323, 0.5734, 0.5320, 0.6319, 0.5505,
        0.4871, 0.5110, 0.5433, 0.4320, 0.5567, 0.5667, 0.5370],
       device='cuda:0') torch.Size([16])
percent tensor([0.5509, 0.6672, 0.6555, 0.6384, 0.6888, 0.7137, 0.6413, 0.5825, 0.6641,
        0.6158, 0.6708, 0.6389, 0.6565, 0.6722, 0.5214, 0.5534],
       device='cuda:0') torch.Size([16])
percent tensor([0.6917, 0.7138, 0.7089, 0.6585, 0.7087, 0.7296, 0.7307, 0.6713, 0.6938,
        0.6843, 0.7125, 0.6356, 0.6991, 0.7176, 0.5816, 0.6446],
       device='cuda:0') torch.Size([16])
percent tensor([0.9998, 0.9997, 0.9998, 0.9996, 0.9999, 0.9997, 0.9999, 1.0000, 0.9999,
        0.9999, 0.9999, 0.9992, 0.9996, 0.9998, 0.9996, 0.9994],
       device='cuda:0') torch.Size([16])
Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 3, 3, 3]) tensor(187.9267, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(816.8217, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(836.3827, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([128, 64, 3, 3]) tensor(1526.7078, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([128, 64, 1, 1]) tensor(492.4101, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([128, 128, 3, 3]) tensor(2262.6309, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([256, 128, 3, 3]) tensor(4258.5225, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([256, 128, 1, 1]) tensor(1370.3550, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([256, 256, 3, 3]) tensor(6183.2388, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([512, 256, 3, 3]) tensor(11729.1934, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([512, 256, 1, 1]) tensor(3878.6555, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([512, 512, 3, 3]) tensor(16379.4941, device='cuda:0', grad_fn=<NormBackward0>)
Epoch: 141 | Batch_idx: 0 |  Loss: (0.1861) |  Loss2: (0.0000) | Acc: (92.00%) (118/128)
Epoch: 141 | Batch_idx: 10 |  Loss: (0.1446) |  Loss2: (0.0000) | Acc: (94.00%) (1334/1408)
Epoch: 141 | Batch_idx: 20 |  Loss: (0.1465) |  Loss2: (0.0000) | Acc: (94.00%) (2550/2688)
Epoch: 141 | Batch_idx: 30 |  Loss: (0.1462) |  Loss2: (0.0000) | Acc: (94.00%) (3766/3968)
Epoch: 141 | Batch_idx: 40 |  Loss: (0.1447) |  Loss2: (0.0000) | Acc: (95.00%) (4991/5248)
Epoch: 141 | Batch_idx: 50 |  Loss: (0.1377) |  Loss2: (0.0000) | Acc: (95.00%) (6224/6528)
Epoch: 141 | Batch_idx: 60 |  Loss: (0.1354) |  Loss2: (0.0000) | Acc: (95.00%) (7450/7808)
Epoch: 141 | Batch_idx: 70 |  Loss: (0.1379) |  Loss2: (0.0000) | Acc: (95.00%) (8667/9088)
Epoch: 141 | Batch_idx: 80 |  Loss: (0.1379) |  Loss2: (0.0000) | Acc: (95.00%) (9887/10368)
Epoch: 141 | Batch_idx: 90 |  Loss: (0.1391) |  Loss2: (0.0000) | Acc: (95.00%) (11104/11648)
Epoch: 141 | Batch_idx: 100 |  Loss: (0.1409) |  Loss2: (0.0000) | Acc: (95.00%) (12303/12928)
Epoch: 141 | Batch_idx: 110 |  Loss: (0.1408) |  Loss2: (0.0000) | Acc: (95.00%) (13520/14208)
Epoch: 141 | Batch_idx: 120 |  Loss: (0.1432) |  Loss2: (0.0000) | Acc: (95.00%) (14717/15488)
Epoch: 141 | Batch_idx: 130 |  Loss: (0.1435) |  Loss2: (0.0000) | Acc: (95.00%) (15937/16768)
Epoch: 141 | Batch_idx: 140 |  Loss: (0.1434) |  Loss2: (0.0000) | Acc: (95.00%) (17153/18048)
Epoch: 141 | Batch_idx: 150 |  Loss: (0.1446) |  Loss2: (0.0000) | Acc: (94.00%) (18354/19328)
Epoch: 141 | Batch_idx: 160 |  Loss: (0.1436) |  Loss2: (0.0000) | Acc: (94.00%) (19576/20608)
Epoch: 141 | Batch_idx: 170 |  Loss: (0.1438) |  Loss2: (0.0000) | Acc: (94.00%) (20788/21888)
Epoch: 141 | Batch_idx: 180 |  Loss: (0.1435) |  Loss2: (0.0000) | Acc: (94.00%) (22007/23168)
Epoch: 141 | Batch_idx: 190 |  Loss: (0.1449) |  Loss2: (0.0000) | Acc: (94.00%) (23204/24448)
Epoch: 141 | Batch_idx: 200 |  Loss: (0.1442) |  Loss2: (0.0000) | Acc: (94.00%) (24430/25728)
Epoch: 141 | Batch_idx: 210 |  Loss: (0.1443) |  Loss2: (0.0000) | Acc: (94.00%) (25648/27008)
Epoch: 141 | Batch_idx: 220 |  Loss: (0.1447) |  Loss2: (0.0000) | Acc: (94.00%) (26858/28288)
Epoch: 141 | Batch_idx: 230 |  Loss: (0.1439) |  Loss2: (0.0000) | Acc: (94.00%) (28084/29568)
Epoch: 141 | Batch_idx: 240 |  Loss: (0.1450) |  Loss2: (0.0000) | Acc: (94.00%) (29290/30848)
Epoch: 141 | Batch_idx: 250 |  Loss: (0.1450) |  Loss2: (0.0000) | Acc: (94.00%) (30507/32128)
Epoch: 141 | Batch_idx: 260 |  Loss: (0.1450) |  Loss2: (0.0000) | Acc: (94.00%) (31722/33408)
Epoch: 141 | Batch_idx: 270 |  Loss: (0.1454) |  Loss2: (0.0000) | Acc: (94.00%) (32925/34688)
Epoch: 141 | Batch_idx: 280 |  Loss: (0.1454) |  Loss2: (0.0000) | Acc: (94.00%) (34133/35968)
Epoch: 141 | Batch_idx: 290 |  Loss: (0.1459) |  Loss2: (0.0000) | Acc: (94.00%) (35344/37248)
Epoch: 141 | Batch_idx: 300 |  Loss: (0.1467) |  Loss2: (0.0000) | Acc: (94.00%) (36547/38528)
Epoch: 141 | Batch_idx: 310 |  Loss: (0.1466) |  Loss2: (0.0000) | Acc: (94.00%) (37767/39808)
Epoch: 141 | Batch_idx: 320 |  Loss: (0.1474) |  Loss2: (0.0000) | Acc: (94.00%) (38963/41088)
Epoch: 141 | Batch_idx: 330 |  Loss: (0.1476) |  Loss2: (0.0000) | Acc: (94.00%) (40168/42368)
Epoch: 141 | Batch_idx: 340 |  Loss: (0.1478) |  Loss2: (0.0000) | Acc: (94.00%) (41381/43648)
Epoch: 141 | Batch_idx: 350 |  Loss: (0.1480) |  Loss2: (0.0000) | Acc: (94.00%) (42597/44928)
Epoch: 141 | Batch_idx: 360 |  Loss: (0.1482) |  Loss2: (0.0000) | Acc: (94.00%) (43806/46208)
Epoch: 141 | Batch_idx: 370 |  Loss: (0.1485) |  Loss2: (0.0000) | Acc: (94.00%) (45015/47488)
Epoch: 141 | Batch_idx: 380 |  Loss: (0.1484) |  Loss2: (0.0000) | Acc: (94.00%) (46223/48768)
Epoch: 141 | Batch_idx: 390 |  Loss: (0.1487) |  Loss2: (0.0000) | Acc: (94.00%) (47383/50000)
# TEST : Loss: (0.4375) | Acc: (87.00%) (8728/10000)
percent tensor([0.5610, 0.5694, 0.5979, 0.5831, 0.5975, 0.5669, 0.5806, 0.5905, 0.5690,
        0.5760, 0.5579, 0.5909, 0.5618, 0.5659, 0.5704, 0.5633],
       device='cuda:0') torch.Size([16])
percent tensor([0.5844, 0.5860, 0.5798, 0.5743, 0.5849, 0.5869, 0.5913, 0.5840, 0.5791,
        0.5819, 0.5867, 0.5887, 0.5828, 0.5786, 0.5928, 0.5844],
       device='cuda:0') torch.Size([16])
percent tensor([0.6115, 0.6246, 0.5820, 0.5585, 0.5664, 0.5823, 0.6095, 0.5801, 0.5963,
        0.6196, 0.6134, 0.6031, 0.6369, 0.6012, 0.6112, 0.6128],
       device='cuda:0') torch.Size([16])
percent tensor([0.6351, 0.6295, 0.6064, 0.6142, 0.6219, 0.6518, 0.6360, 0.6191, 0.6245,
        0.6297, 0.6332, 0.6208, 0.6257, 0.6329, 0.6422, 0.6396],
       device='cuda:0') torch.Size([16])
percent tensor([0.5314, 0.4975, 0.6063, 0.6234, 0.6295, 0.5622, 0.5672, 0.6375, 0.5747,
        0.5096, 0.5295, 0.5660, 0.4439, 0.6059, 0.5757, 0.5543],
       device='cuda:0') torch.Size([16])
percent tensor([0.5395, 0.6491, 0.6515, 0.6206, 0.6571, 0.7088, 0.6309, 0.5711, 0.6634,
        0.6004, 0.6734, 0.6180, 0.6391, 0.6642, 0.5043, 0.5246],
       device='cuda:0') torch.Size([16])
percent tensor([0.6881, 0.7066, 0.7182, 0.6620, 0.7080, 0.7246, 0.7345, 0.6682, 0.6728,
        0.6797, 0.6945, 0.6346, 0.6952, 0.7063, 0.5917, 0.6350],
       device='cuda:0') torch.Size([16])
percent tensor([0.9997, 0.9997, 0.9998, 0.9997, 0.9999, 0.9997, 0.9999, 0.9999, 0.9998,
        0.9999, 0.9998, 0.9995, 0.9995, 0.9998, 0.9996, 0.9995],
       device='cuda:0') torch.Size([16])
Epoch: 142 | Batch_idx: 0 |  Loss: (0.1359) |  Loss2: (0.0000) | Acc: (94.00%) (121/128)
Epoch: 142 | Batch_idx: 10 |  Loss: (0.1271) |  Loss2: (0.0000) | Acc: (96.00%) (1355/1408)
Epoch: 142 | Batch_idx: 20 |  Loss: (0.1213) |  Loss2: (0.0000) | Acc: (96.00%) (2583/2688)
Epoch: 142 | Batch_idx: 30 |  Loss: (0.1244) |  Loss2: (0.0000) | Acc: (95.00%) (3804/3968)
Epoch: 142 | Batch_idx: 40 |  Loss: (0.1277) |  Loss2: (0.0000) | Acc: (95.00%) (5027/5248)
Epoch: 142 | Batch_idx: 50 |  Loss: (0.1278) |  Loss2: (0.0000) | Acc: (95.00%) (6255/6528)
Epoch: 142 | Batch_idx: 60 |  Loss: (0.1305) |  Loss2: (0.0000) | Acc: (95.00%) (7475/7808)
Epoch: 142 | Batch_idx: 70 |  Loss: (0.1300) |  Loss2: (0.0000) | Acc: (95.00%) (8696/9088)
Epoch: 142 | Batch_idx: 80 |  Loss: (0.1345) |  Loss2: (0.0000) | Acc: (95.00%) (9907/10368)
Epoch: 142 | Batch_idx: 90 |  Loss: (0.1349) |  Loss2: (0.0000) | Acc: (95.00%) (11127/11648)
Epoch: 142 | Batch_idx: 100 |  Loss: (0.1338) |  Loss2: (0.0000) | Acc: (95.00%) (12351/12928)
Epoch: 142 | Batch_idx: 110 |  Loss: (0.1341) |  Loss2: (0.0000) | Acc: (95.00%) (13572/14208)
Epoch: 142 | Batch_idx: 120 |  Loss: (0.1352) |  Loss2: (0.0000) | Acc: (95.00%) (14786/15488)
Epoch: 142 | Batch_idx: 130 |  Loss: (0.1349) |  Loss2: (0.0000) | Acc: (95.00%) (16015/16768)
Epoch: 142 | Batch_idx: 140 |  Loss: (0.1367) |  Loss2: (0.0000) | Acc: (95.00%) (17224/18048)
Epoch: 142 | Batch_idx: 150 |  Loss: (0.1376) |  Loss2: (0.0000) | Acc: (95.00%) (18426/19328)
Epoch: 142 | Batch_idx: 160 |  Loss: (0.1379) |  Loss2: (0.0000) | Acc: (95.00%) (19646/20608)
Epoch: 142 | Batch_idx: 170 |  Loss: (0.1383) |  Loss2: (0.0000) | Acc: (95.00%) (20865/21888)
Epoch: 142 | Batch_idx: 180 |  Loss: (0.1381) |  Loss2: (0.0000) | Acc: (95.00%) (22090/23168)
Epoch: 142 | Batch_idx: 190 |  Loss: (0.1379) |  Loss2: (0.0000) | Acc: (95.00%) (23314/24448)
Epoch: 142 | Batch_idx: 200 |  Loss: (0.1388) |  Loss2: (0.0000) | Acc: (95.00%) (24526/25728)
Epoch: 142 | Batch_idx: 210 |  Loss: (0.1401) |  Loss2: (0.0000) | Acc: (95.00%) (25738/27008)
Epoch: 142 | Batch_idx: 220 |  Loss: (0.1404) |  Loss2: (0.0000) | Acc: (95.00%) (26945/28288)
Epoch: 142 | Batch_idx: 230 |  Loss: (0.1414) |  Loss2: (0.0000) | Acc: (95.00%) (28152/29568)
Epoch: 142 | Batch_idx: 240 |  Loss: (0.1420) |  Loss2: (0.0000) | Acc: (95.00%) (29357/30848)
Epoch: 142 | Batch_idx: 250 |  Loss: (0.1423) |  Loss2: (0.0000) | Acc: (95.00%) (30572/32128)
Epoch: 142 | Batch_idx: 260 |  Loss: (0.1430) |  Loss2: (0.0000) | Acc: (95.00%) (31777/33408)
Epoch: 142 | Batch_idx: 270 |  Loss: (0.1440) |  Loss2: (0.0000) | Acc: (95.00%) (32974/34688)
Epoch: 142 | Batch_idx: 280 |  Loss: (0.1441) |  Loss2: (0.0000) | Acc: (95.00%) (34190/35968)
Epoch: 142 | Batch_idx: 290 |  Loss: (0.1450) |  Loss2: (0.0000) | Acc: (95.00%) (35392/37248)
Epoch: 142 | Batch_idx: 300 |  Loss: (0.1446) |  Loss2: (0.0000) | Acc: (95.00%) (36615/38528)
Epoch: 142 | Batch_idx: 310 |  Loss: (0.1443) |  Loss2: (0.0000) | Acc: (95.00%) (37834/39808)
Epoch: 142 | Batch_idx: 320 |  Loss: (0.1451) |  Loss2: (0.0000) | Acc: (95.00%) (39047/41088)
Epoch: 142 | Batch_idx: 330 |  Loss: (0.1453) |  Loss2: (0.0000) | Acc: (95.00%) (40260/42368)
Epoch: 142 | Batch_idx: 340 |  Loss: (0.1455) |  Loss2: (0.0000) | Acc: (95.00%) (41478/43648)
Epoch: 142 | Batch_idx: 350 |  Loss: (0.1455) |  Loss2: (0.0000) | Acc: (95.00%) (42693/44928)
Epoch: 142 | Batch_idx: 360 |  Loss: (0.1460) |  Loss2: (0.0000) | Acc: (95.00%) (43904/46208)
Epoch: 142 | Batch_idx: 370 |  Loss: (0.1457) |  Loss2: (0.0000) | Acc: (95.00%) (45118/47488)
Epoch: 142 | Batch_idx: 380 |  Loss: (0.1456) |  Loss2: (0.0000) | Acc: (95.00%) (46336/48768)
Epoch: 142 | Batch_idx: 390 |  Loss: (0.1452) |  Loss2: (0.0000) | Acc: (95.00%) (47510/50000)
# TEST : Loss: (0.4585) | Acc: (86.00%) (8677/10000)
percent tensor([0.5591, 0.5704, 0.5970, 0.5840, 0.5961, 0.5651, 0.5804, 0.5907, 0.5678,
        0.5759, 0.5572, 0.5897, 0.5609, 0.5677, 0.5703, 0.5629],
       device='cuda:0') torch.Size([16])
percent tensor([0.5833, 0.5873, 0.5774, 0.5725, 0.5848, 0.5878, 0.5916, 0.5822, 0.5785,
        0.5823, 0.5871, 0.5877, 0.5817, 0.5790, 0.5931, 0.5845],
       device='cuda:0') torch.Size([16])
percent tensor([0.6135, 0.6236, 0.5822, 0.5655, 0.5677, 0.5888, 0.6090, 0.5779, 0.5987,
        0.6180, 0.6130, 0.6033, 0.6369, 0.6004, 0.6140, 0.6142],
       device='cuda:0') torch.Size([16])
percent tensor([0.6358, 0.6329, 0.6056, 0.6115, 0.6226, 0.6507, 0.6403, 0.6194, 0.6258,
        0.6310, 0.6340, 0.6203, 0.6277, 0.6370, 0.6451, 0.6403],
       device='cuda:0') torch.Size([16])
percent tensor([0.5178, 0.4725, 0.6094, 0.6164, 0.6320, 0.5509, 0.5391, 0.6342, 0.5587,
        0.4963, 0.5098, 0.5541, 0.4347, 0.5658, 0.5517, 0.5306],
       device='cuda:0') torch.Size([16])
percent tensor([0.5456, 0.6521, 0.6696, 0.6560, 0.6778, 0.7115, 0.6373, 0.5968, 0.6606,
        0.6022, 0.6639, 0.6270, 0.6581, 0.6561, 0.5373, 0.5252],
       device='cuda:0') torch.Size([16])
percent tensor([0.6935, 0.7033, 0.7217, 0.6751, 0.7127, 0.7211, 0.7371, 0.6599, 0.6810,
        0.6873, 0.6967, 0.6486, 0.7096, 0.7055, 0.6030, 0.6373],
       device='cuda:0') torch.Size([16])
percent tensor([0.9997, 0.9996, 0.9998, 0.9997, 0.9999, 0.9996, 0.9999, 0.9999, 0.9998,
        0.9998, 0.9998, 0.9996, 0.9996, 0.9998, 0.9993, 0.9994],
       device='cuda:0') torch.Size([16])
Epoch: 143 | Batch_idx: 0 |  Loss: (0.1905) |  Loss2: (0.0000) | Acc: (91.00%) (117/128)
Epoch: 143 | Batch_idx: 10 |  Loss: (0.1426) |  Loss2: (0.0000) | Acc: (95.00%) (1338/1408)
Epoch: 143 | Batch_idx: 20 |  Loss: (0.1322) |  Loss2: (0.0000) | Acc: (95.00%) (2567/2688)
Epoch: 143 | Batch_idx: 30 |  Loss: (0.1322) |  Loss2: (0.0000) | Acc: (95.00%) (3798/3968)
Epoch: 143 | Batch_idx: 40 |  Loss: (0.1339) |  Loss2: (0.0000) | Acc: (95.00%) (5018/5248)
Epoch: 143 | Batch_idx: 50 |  Loss: (0.1335) |  Loss2: (0.0000) | Acc: (95.00%) (6233/6528)
Epoch: 143 | Batch_idx: 60 |  Loss: (0.1346) |  Loss2: (0.0000) | Acc: (95.00%) (7449/7808)
Epoch: 143 | Batch_idx: 70 |  Loss: (0.1361) |  Loss2: (0.0000) | Acc: (95.00%) (8660/9088)
Epoch: 143 | Batch_idx: 80 |  Loss: (0.1346) |  Loss2: (0.0000) | Acc: (95.00%) (9879/10368)
Epoch: 143 | Batch_idx: 90 |  Loss: (0.1351) |  Loss2: (0.0000) | Acc: (95.00%) (11102/11648)
Epoch: 143 | Batch_idx: 100 |  Loss: (0.1348) |  Loss2: (0.0000) | Acc: (95.00%) (12325/12928)
Epoch: 143 | Batch_idx: 110 |  Loss: (0.1320) |  Loss2: (0.0000) | Acc: (95.00%) (13560/14208)
Epoch: 143 | Batch_idx: 120 |  Loss: (0.1330) |  Loss2: (0.0000) | Acc: (95.00%) (14782/15488)
Epoch: 143 | Batch_idx: 130 |  Loss: (0.1352) |  Loss2: (0.0000) | Acc: (95.00%) (15989/16768)
Epoch: 143 | Batch_idx: 140 |  Loss: (0.1346) |  Loss2: (0.0000) | Acc: (95.00%) (17212/18048)
Epoch: 143 | Batch_idx: 150 |  Loss: (0.1348) |  Loss2: (0.0000) | Acc: (95.00%) (18431/19328)
Epoch: 143 | Batch_idx: 160 |  Loss: (0.1346) |  Loss2: (0.0000) | Acc: (95.00%) (19654/20608)
Epoch: 143 | Batch_idx: 170 |  Loss: (0.1349) |  Loss2: (0.0000) | Acc: (95.00%) (20872/21888)
Epoch: 143 | Batch_idx: 180 |  Loss: (0.1345) |  Loss2: (0.0000) | Acc: (95.00%) (22095/23168)
Epoch: 143 | Batch_idx: 190 |  Loss: (0.1341) |  Loss2: (0.0000) | Acc: (95.00%) (23328/24448)
Epoch: 143 | Batch_idx: 200 |  Loss: (0.1336) |  Loss2: (0.0000) | Acc: (95.00%) (24555/25728)
Epoch: 143 | Batch_idx: 210 |  Loss: (0.1335) |  Loss2: (0.0000) | Acc: (95.00%) (25774/27008)
Epoch: 143 | Batch_idx: 220 |  Loss: (0.1350) |  Loss2: (0.0000) | Acc: (95.00%) (26984/28288)
Epoch: 143 | Batch_idx: 230 |  Loss: (0.1370) |  Loss2: (0.0000) | Acc: (95.00%) (28181/29568)
Epoch: 143 | Batch_idx: 240 |  Loss: (0.1374) |  Loss2: (0.0000) | Acc: (95.00%) (29397/30848)
Epoch: 143 | Batch_idx: 250 |  Loss: (0.1381) |  Loss2: (0.0000) | Acc: (95.00%) (30611/32128)
Epoch: 143 | Batch_idx: 260 |  Loss: (0.1376) |  Loss2: (0.0000) | Acc: (95.00%) (31841/33408)
Epoch: 143 | Batch_idx: 270 |  Loss: (0.1377) |  Loss2: (0.0000) | Acc: (95.00%) (33062/34688)
Epoch: 143 | Batch_idx: 280 |  Loss: (0.1378) |  Loss2: (0.0000) | Acc: (95.00%) (34272/35968)
Epoch: 143 | Batch_idx: 290 |  Loss: (0.1378) |  Loss2: (0.0000) | Acc: (95.00%) (35482/37248)
Epoch: 143 | Batch_idx: 300 |  Loss: (0.1381) |  Loss2: (0.0000) | Acc: (95.00%) (36698/38528)
Epoch: 143 | Batch_idx: 310 |  Loss: (0.1382) |  Loss2: (0.0000) | Acc: (95.00%) (37913/39808)
Epoch: 143 | Batch_idx: 320 |  Loss: (0.1384) |  Loss2: (0.0000) | Acc: (95.00%) (39126/41088)
Epoch: 143 | Batch_idx: 330 |  Loss: (0.1390) |  Loss2: (0.0000) | Acc: (95.00%) (40342/42368)
Epoch: 143 | Batch_idx: 340 |  Loss: (0.1400) |  Loss2: (0.0000) | Acc: (95.00%) (41539/43648)
Epoch: 143 | Batch_idx: 350 |  Loss: (0.1405) |  Loss2: (0.0000) | Acc: (95.00%) (42744/44928)
Epoch: 143 | Batch_idx: 360 |  Loss: (0.1406) |  Loss2: (0.0000) | Acc: (95.00%) (43958/46208)
Epoch: 143 | Batch_idx: 370 |  Loss: (0.1406) |  Loss2: (0.0000) | Acc: (95.00%) (45176/47488)
Epoch: 143 | Batch_idx: 380 |  Loss: (0.1412) |  Loss2: (0.0000) | Acc: (95.00%) (46369/48768)
Epoch: 143 | Batch_idx: 390 |  Loss: (0.1416) |  Loss2: (0.0000) | Acc: (95.00%) (47537/50000)
# TEST : Loss: (0.4583) | Acc: (86.00%) (8664/10000)
percent tensor([0.5601, 0.5691, 0.5974, 0.5834, 0.5965, 0.5663, 0.5800, 0.5909, 0.5673,
        0.5758, 0.5561, 0.5905, 0.5606, 0.5649, 0.5700, 0.5630],
       device='cuda:0') torch.Size([16])
percent tensor([0.5830, 0.5859, 0.5759, 0.5702, 0.5838, 0.5863, 0.5915, 0.5806, 0.5779,
        0.5812, 0.5859, 0.5881, 0.5812, 0.5790, 0.5915, 0.5829],
       device='cuda:0') torch.Size([16])
percent tensor([0.6109, 0.6217, 0.5870, 0.5602, 0.5699, 0.5845, 0.6086, 0.5752, 0.5948,
        0.6194, 0.6120, 0.6037, 0.6331, 0.5999, 0.6096, 0.6136],
       device='cuda:0') torch.Size([16])
percent tensor([0.6360, 0.6307, 0.6052, 0.6142, 0.6198, 0.6489, 0.6381, 0.6186, 0.6257,
        0.6294, 0.6340, 0.6213, 0.6259, 0.6359, 0.6412, 0.6390],
       device='cuda:0') torch.Size([16])
percent tensor([0.5270, 0.4935, 0.5953, 0.6314, 0.6260, 0.5591, 0.5480, 0.6307, 0.5761,
        0.5136, 0.5335, 0.5612, 0.4462, 0.5831, 0.5742, 0.5411],
       device='cuda:0') torch.Size([16])
percent tensor([0.5379, 0.6397, 0.6494, 0.6250, 0.6684, 0.6994, 0.6307, 0.5737, 0.6604,
        0.6027, 0.6669, 0.6225, 0.6393, 0.6609, 0.4905, 0.5257],
       device='cuda:0') torch.Size([16])
percent tensor([0.6870, 0.6818, 0.7105, 0.6413, 0.7012, 0.7188, 0.7276, 0.6565, 0.6723,
        0.6708, 0.6886, 0.6299, 0.6900, 0.7014, 0.5828, 0.6444],
       device='cuda:0') torch.Size([16])
percent tensor([0.9997, 0.9997, 0.9998, 0.9996, 0.9998, 0.9995, 0.9999, 0.9999, 0.9998,
        0.9999, 0.9999, 0.9997, 0.9997, 0.9998, 0.9995, 0.9994],
       device='cuda:0') torch.Size([16])
Epoch: 144 | Batch_idx: 0 |  Loss: (0.1503) |  Loss2: (0.0000) | Acc: (94.00%) (121/128)
Epoch: 144 | Batch_idx: 10 |  Loss: (0.1278) |  Loss2: (0.0000) | Acc: (95.00%) (1345/1408)
Epoch: 144 | Batch_idx: 20 |  Loss: (0.1251) |  Loss2: (0.0000) | Acc: (95.00%) (2574/2688)
Epoch: 144 | Batch_idx: 30 |  Loss: (0.1304) |  Loss2: (0.0000) | Acc: (95.00%) (3793/3968)
Epoch: 144 | Batch_idx: 40 |  Loss: (0.1325) |  Loss2: (0.0000) | Acc: (95.00%) (5010/5248)
Epoch: 144 | Batch_idx: 50 |  Loss: (0.1329) |  Loss2: (0.0000) | Acc: (95.00%) (6230/6528)
Epoch: 144 | Batch_idx: 60 |  Loss: (0.1335) |  Loss2: (0.0000) | Acc: (95.00%) (7452/7808)
Epoch: 144 | Batch_idx: 70 |  Loss: (0.1345) |  Loss2: (0.0000) | Acc: (95.00%) (8668/9088)
Epoch: 144 | Batch_idx: 80 |  Loss: (0.1354) |  Loss2: (0.0000) | Acc: (95.00%) (9880/10368)
Epoch: 144 | Batch_idx: 90 |  Loss: (0.1340) |  Loss2: (0.0000) | Acc: (95.00%) (11107/11648)
Epoch: 144 | Batch_idx: 100 |  Loss: (0.1336) |  Loss2: (0.0000) | Acc: (95.00%) (12333/12928)
Epoch: 144 | Batch_idx: 110 |  Loss: (0.1335) |  Loss2: (0.0000) | Acc: (95.00%) (13553/14208)
Epoch: 144 | Batch_idx: 120 |  Loss: (0.1340) |  Loss2: (0.0000) | Acc: (95.00%) (14775/15488)
Epoch: 144 | Batch_idx: 130 |  Loss: (0.1331) |  Loss2: (0.0000) | Acc: (95.00%) (15994/16768)
Epoch: 144 | Batch_idx: 140 |  Loss: (0.1351) |  Loss2: (0.0000) | Acc: (95.00%) (17205/18048)
Epoch: 144 | Batch_idx: 150 |  Loss: (0.1352) |  Loss2: (0.0000) | Acc: (95.00%) (18428/19328)
Epoch: 144 | Batch_idx: 160 |  Loss: (0.1341) |  Loss2: (0.0000) | Acc: (95.00%) (19660/20608)
Epoch: 144 | Batch_idx: 170 |  Loss: (0.1337) |  Loss2: (0.0000) | Acc: (95.00%) (20875/21888)
Epoch: 144 | Batch_idx: 180 |  Loss: (0.1335) |  Loss2: (0.0000) | Acc: (95.00%) (22089/23168)
Epoch: 144 | Batch_idx: 190 |  Loss: (0.1328) |  Loss2: (0.0000) | Acc: (95.00%) (23322/24448)
Epoch: 144 | Batch_idx: 200 |  Loss: (0.1322) |  Loss2: (0.0000) | Acc: (95.00%) (24547/25728)
Epoch: 144 | Batch_idx: 210 |  Loss: (0.1323) |  Loss2: (0.0000) | Acc: (95.00%) (25766/27008)
Epoch: 144 | Batch_idx: 220 |  Loss: (0.1323) |  Loss2: (0.0000) | Acc: (95.00%) (26987/28288)
Epoch: 144 | Batch_idx: 230 |  Loss: (0.1335) |  Loss2: (0.0000) | Acc: (95.00%) (28194/29568)
Epoch: 144 | Batch_idx: 240 |  Loss: (0.1346) |  Loss2: (0.0000) | Acc: (95.00%) (29403/30848)
Epoch: 144 | Batch_idx: 250 |  Loss: (0.1348) |  Loss2: (0.0000) | Acc: (95.00%) (30620/32128)
Epoch: 144 | Batch_idx: 260 |  Loss: (0.1344) |  Loss2: (0.0000) | Acc: (95.00%) (31837/33408)
Epoch: 144 | Batch_idx: 270 |  Loss: (0.1349) |  Loss2: (0.0000) | Acc: (95.00%) (33053/34688)
Epoch: 144 | Batch_idx: 280 |  Loss: (0.1349) |  Loss2: (0.0000) | Acc: (95.00%) (34273/35968)
Epoch: 144 | Batch_idx: 290 |  Loss: (0.1358) |  Loss2: (0.0000) | Acc: (95.00%) (35473/37248)
Epoch: 144 | Batch_idx: 300 |  Loss: (0.1359) |  Loss2: (0.0000) | Acc: (95.00%) (36694/38528)
Epoch: 144 | Batch_idx: 310 |  Loss: (0.1362) |  Loss2: (0.0000) | Acc: (95.00%) (37911/39808)
Epoch: 144 | Batch_idx: 320 |  Loss: (0.1366) |  Loss2: (0.0000) | Acc: (95.00%) (39118/41088)
Epoch: 144 | Batch_idx: 330 |  Loss: (0.1370) |  Loss2: (0.0000) | Acc: (95.00%) (40341/42368)
Epoch: 144 | Batch_idx: 340 |  Loss: (0.1369) |  Loss2: (0.0000) | Acc: (95.00%) (41563/43648)
Epoch: 144 | Batch_idx: 350 |  Loss: (0.1364) |  Loss2: (0.0000) | Acc: (95.00%) (42792/44928)
Epoch: 144 | Batch_idx: 360 |  Loss: (0.1367) |  Loss2: (0.0000) | Acc: (95.00%) (44005/46208)
Epoch: 144 | Batch_idx: 370 |  Loss: (0.1372) |  Loss2: (0.0000) | Acc: (95.00%) (45205/47488)
Epoch: 144 | Batch_idx: 380 |  Loss: (0.1376) |  Loss2: (0.0000) | Acc: (95.00%) (46416/48768)
Epoch: 144 | Batch_idx: 390 |  Loss: (0.1381) |  Loss2: (0.0000) | Acc: (95.00%) (47585/50000)
# TEST : Loss: (0.4660) | Acc: (86.00%) (8641/10000)
percent tensor([0.5594, 0.5711, 0.5941, 0.5828, 0.5949, 0.5667, 0.5806, 0.5880, 0.5681,
        0.5755, 0.5573, 0.5880, 0.5607, 0.5694, 0.5706, 0.5629],
       device='cuda:0') torch.Size([16])
percent tensor([0.5837, 0.5851, 0.5765, 0.5728, 0.5847, 0.5882, 0.5919, 0.5807, 0.5779,
        0.5816, 0.5861, 0.5887, 0.5817, 0.5773, 0.5931, 0.5839],
       device='cuda:0') torch.Size([16])
percent tensor([0.6069, 0.6168, 0.5813, 0.5584, 0.5661, 0.5797, 0.6038, 0.5728, 0.5909,
        0.6138, 0.6051, 0.5992, 0.6300, 0.5975, 0.6057, 0.6077],
       device='cuda:0') torch.Size([16])
percent tensor([0.6379, 0.6309, 0.6104, 0.6154, 0.6261, 0.6533, 0.6410, 0.6207, 0.6273,
        0.6320, 0.6334, 0.6244, 0.6272, 0.6342, 0.6444, 0.6404],
       device='cuda:0') torch.Size([16])
percent tensor([0.5514, 0.5257, 0.6197, 0.6341, 0.6368, 0.5816, 0.5796, 0.6462, 0.5916,
        0.5230, 0.5525, 0.5699, 0.4612, 0.6167, 0.5906, 0.5644],
       device='cuda:0') torch.Size([16])
percent tensor([0.5324, 0.6643, 0.6546, 0.6289, 0.6673, 0.7044, 0.6326, 0.5748, 0.6606,
        0.6301, 0.6715, 0.6311, 0.6495, 0.6525, 0.4930, 0.5491],
       device='cuda:0') torch.Size([16])
percent tensor([0.6822, 0.7007, 0.7188, 0.6701, 0.6852, 0.7134, 0.7189, 0.6435, 0.6760,
        0.6938, 0.7108, 0.6431, 0.6943, 0.7098, 0.5822, 0.6498],
       device='cuda:0') torch.Size([16])
percent tensor([0.9997, 0.9995, 0.9999, 0.9997, 0.9997, 0.9996, 0.9998, 0.9999, 0.9998,
        0.9998, 0.9999, 0.9993, 0.9996, 0.9996, 0.9997, 0.9996],
       device='cuda:0') torch.Size([16])
Epoch: 145 | Batch_idx: 0 |  Loss: (0.0965) |  Loss2: (0.0000) | Acc: (96.00%) (124/128)
Epoch: 145 | Batch_idx: 10 |  Loss: (0.1428) |  Loss2: (0.0000) | Acc: (94.00%) (1333/1408)
Epoch: 145 | Batch_idx: 20 |  Loss: (0.1370) |  Loss2: (0.0000) | Acc: (95.00%) (2557/2688)
Epoch: 145 | Batch_idx: 30 |  Loss: (0.1332) |  Loss2: (0.0000) | Acc: (95.00%) (3784/3968)
Epoch: 145 | Batch_idx: 40 |  Loss: (0.1326) |  Loss2: (0.0000) | Acc: (95.00%) (5013/5248)
Epoch: 145 | Batch_idx: 50 |  Loss: (0.1302) |  Loss2: (0.0000) | Acc: (95.00%) (6249/6528)
Epoch: 145 | Batch_idx: 60 |  Loss: (0.1338) |  Loss2: (0.0000) | Acc: (95.00%) (7456/7808)
Epoch: 145 | Batch_idx: 70 |  Loss: (0.1303) |  Loss2: (0.0000) | Acc: (95.00%) (8685/9088)
Epoch: 145 | Batch_idx: 80 |  Loss: (0.1298) |  Loss2: (0.0000) | Acc: (95.00%) (9910/10368)
Epoch: 145 | Batch_idx: 90 |  Loss: (0.1276) |  Loss2: (0.0000) | Acc: (95.00%) (11154/11648)
Epoch: 145 | Batch_idx: 100 |  Loss: (0.1273) |  Loss2: (0.0000) | Acc: (95.00%) (12376/12928)
Epoch: 145 | Batch_idx: 110 |  Loss: (0.1259) |  Loss2: (0.0000) | Acc: (95.00%) (13608/14208)
Epoch: 145 | Batch_idx: 120 |  Loss: (0.1254) |  Loss2: (0.0000) | Acc: (95.00%) (14835/15488)
Epoch: 145 | Batch_idx: 130 |  Loss: (0.1254) |  Loss2: (0.0000) | Acc: (95.00%) (16062/16768)
Epoch: 145 | Batch_idx: 140 |  Loss: (0.1246) |  Loss2: (0.0000) | Acc: (95.00%) (17289/18048)
Epoch: 145 | Batch_idx: 150 |  Loss: (0.1261) |  Loss2: (0.0000) | Acc: (95.00%) (18506/19328)
Epoch: 145 | Batch_idx: 160 |  Loss: (0.1259) |  Loss2: (0.0000) | Acc: (95.00%) (19732/20608)
Epoch: 145 | Batch_idx: 170 |  Loss: (0.1271) |  Loss2: (0.0000) | Acc: (95.00%) (20953/21888)
Epoch: 145 | Batch_idx: 180 |  Loss: (0.1275) |  Loss2: (0.0000) | Acc: (95.00%) (22186/23168)
Epoch: 145 | Batch_idx: 190 |  Loss: (0.1269) |  Loss2: (0.0000) | Acc: (95.00%) (23420/24448)
Epoch: 145 | Batch_idx: 200 |  Loss: (0.1272) |  Loss2: (0.0000) | Acc: (95.00%) (24638/25728)
Epoch: 145 | Batch_idx: 210 |  Loss: (0.1277) |  Loss2: (0.0000) | Acc: (95.00%) (25857/27008)
Epoch: 145 | Batch_idx: 220 |  Loss: (0.1277) |  Loss2: (0.0000) | Acc: (95.00%) (27075/28288)
Epoch: 145 | Batch_idx: 230 |  Loss: (0.1281) |  Loss2: (0.0000) | Acc: (95.00%) (28302/29568)
Epoch: 145 | Batch_idx: 240 |  Loss: (0.1284) |  Loss2: (0.0000) | Acc: (95.00%) (29521/30848)
Epoch: 145 | Batch_idx: 250 |  Loss: (0.1288) |  Loss2: (0.0000) | Acc: (95.00%) (30733/32128)
Epoch: 145 | Batch_idx: 260 |  Loss: (0.1298) |  Loss2: (0.0000) | Acc: (95.00%) (31950/33408)
Epoch: 145 | Batch_idx: 270 |  Loss: (0.1300) |  Loss2: (0.0000) | Acc: (95.00%) (33164/34688)
Epoch: 145 | Batch_idx: 280 |  Loss: (0.1307) |  Loss2: (0.0000) | Acc: (95.00%) (34370/35968)
Epoch: 145 | Batch_idx: 290 |  Loss: (0.1305) |  Loss2: (0.0000) | Acc: (95.00%) (35593/37248)
Epoch: 145 | Batch_idx: 300 |  Loss: (0.1303) |  Loss2: (0.0000) | Acc: (95.00%) (36810/38528)
Epoch: 145 | Batch_idx: 310 |  Loss: (0.1307) |  Loss2: (0.0000) | Acc: (95.00%) (38031/39808)
Epoch: 145 | Batch_idx: 320 |  Loss: (0.1313) |  Loss2: (0.0000) | Acc: (95.00%) (39250/41088)
Epoch: 145 | Batch_idx: 330 |  Loss: (0.1308) |  Loss2: (0.0000) | Acc: (95.00%) (40479/42368)
Epoch: 145 | Batch_idx: 340 |  Loss: (0.1309) |  Loss2: (0.0000) | Acc: (95.00%) (41691/43648)
Epoch: 145 | Batch_idx: 350 |  Loss: (0.1310) |  Loss2: (0.0000) | Acc: (95.00%) (42919/44928)
Epoch: 145 | Batch_idx: 360 |  Loss: (0.1308) |  Loss2: (0.0000) | Acc: (95.00%) (44149/46208)
Epoch: 145 | Batch_idx: 370 |  Loss: (0.1307) |  Loss2: (0.0000) | Acc: (95.00%) (45374/47488)
Epoch: 145 | Batch_idx: 380 |  Loss: (0.1318) |  Loss2: (0.0000) | Acc: (95.00%) (46572/48768)
Epoch: 145 | Batch_idx: 390 |  Loss: (0.1328) |  Loss2: (0.0000) | Acc: (95.00%) (47723/50000)
=> saving checkpoint 'drive/app/torch/save_Schedule/checkpoint_145.pth.tar'
# TEST : Loss: (0.4831) | Acc: (86.00%) (8619/10000)
percent tensor([0.5609, 0.5701, 0.5980, 0.5848, 0.5969, 0.5677, 0.5807, 0.5905, 0.5684,
        0.5765, 0.5580, 0.5908, 0.5618, 0.5667, 0.5705, 0.5637],
       device='cuda:0') torch.Size([16])
percent tensor([0.5844, 0.5850, 0.5780, 0.5737, 0.5857, 0.5889, 0.5914, 0.5826, 0.5783,
        0.5814, 0.5866, 0.5881, 0.5815, 0.5781, 0.5926, 0.5850],
       device='cuda:0') torch.Size([16])
percent tensor([0.6094, 0.6212, 0.5765, 0.5549, 0.5609, 0.5791, 0.6054, 0.5709, 0.5957,
        0.6147, 0.6119, 0.5980, 0.6346, 0.5988, 0.6088, 0.6103],
       device='cuda:0') torch.Size([16])
percent tensor([0.6377, 0.6285, 0.6075, 0.6188, 0.6243, 0.6531, 0.6384, 0.6196, 0.6235,
        0.6285, 0.6301, 0.6202, 0.6247, 0.6360, 0.6437, 0.6421],
       device='cuda:0') torch.Size([16])
percent tensor([0.5324, 0.4974, 0.6140, 0.6332, 0.6371, 0.5559, 0.5636, 0.6400, 0.5757,
        0.5190, 0.5310, 0.5632, 0.4472, 0.5968, 0.5730, 0.5427],
       device='cuda:0') torch.Size([16])
percent tensor([0.5268, 0.6555, 0.6466, 0.6462, 0.6543, 0.7038, 0.6419, 0.5714, 0.6592,
        0.6083, 0.6642, 0.6292, 0.6336, 0.6502, 0.5131, 0.5252],
       device='cuda:0') torch.Size([16])
percent tensor([0.6827, 0.6931, 0.7191, 0.6809, 0.6848, 0.7230, 0.7370, 0.6535, 0.6814,
        0.6862, 0.6963, 0.6515, 0.6966, 0.7056, 0.5941, 0.6421],
       device='cuda:0') torch.Size([16])
percent tensor([0.9997, 0.9996, 0.9998, 0.9998, 0.9998, 0.9996, 0.9999, 0.9999, 0.9997,
        0.9998, 0.9997, 0.9996, 0.9994, 0.9996, 0.9997, 0.9996],
       device='cuda:0') torch.Size([16])
Epoch: 146 | Batch_idx: 0 |  Loss: (0.0948) |  Loss2: (0.0000) | Acc: (98.00%) (126/128)
Epoch: 146 | Batch_idx: 10 |  Loss: (0.1172) |  Loss2: (0.0000) | Acc: (96.00%) (1352/1408)
Epoch: 146 | Batch_idx: 20 |  Loss: (0.1098) |  Loss2: (0.0000) | Acc: (96.00%) (2589/2688)
Epoch: 146 | Batch_idx: 30 |  Loss: (0.1181) |  Loss2: (0.0000) | Acc: (95.00%) (3803/3968)
Epoch: 146 | Batch_idx: 40 |  Loss: (0.1225) |  Loss2: (0.0000) | Acc: (95.00%) (5020/5248)
Epoch: 146 | Batch_idx: 50 |  Loss: (0.1236) |  Loss2: (0.0000) | Acc: (95.00%) (6243/6528)
Epoch: 146 | Batch_idx: 60 |  Loss: (0.1216) |  Loss2: (0.0000) | Acc: (95.00%) (7473/7808)
Epoch: 146 | Batch_idx: 70 |  Loss: (0.1249) |  Loss2: (0.0000) | Acc: (95.00%) (8689/9088)
Epoch: 146 | Batch_idx: 80 |  Loss: (0.1240) |  Loss2: (0.0000) | Acc: (95.00%) (9922/10368)
Epoch: 146 | Batch_idx: 90 |  Loss: (0.1246) |  Loss2: (0.0000) | Acc: (95.00%) (11147/11648)
Epoch: 146 | Batch_idx: 100 |  Loss: (0.1258) |  Loss2: (0.0000) | Acc: (95.00%) (12362/12928)
Epoch: 146 | Batch_idx: 110 |  Loss: (0.1264) |  Loss2: (0.0000) | Acc: (95.00%) (13578/14208)
Epoch: 146 | Batch_idx: 120 |  Loss: (0.1270) |  Loss2: (0.0000) | Acc: (95.00%) (14797/15488)
Epoch: 146 | Batch_idx: 130 |  Loss: (0.1283) |  Loss2: (0.0000) | Acc: (95.00%) (16010/16768)
Epoch: 146 | Batch_idx: 140 |  Loss: (0.1268) |  Loss2: (0.0000) | Acc: (95.00%) (17242/18048)
Epoch: 146 | Batch_idx: 150 |  Loss: (0.1257) |  Loss2: (0.0000) | Acc: (95.00%) (18471/19328)
Epoch: 146 | Batch_idx: 160 |  Loss: (0.1253) |  Loss2: (0.0000) | Acc: (95.00%) (19699/20608)
Epoch: 146 | Batch_idx: 170 |  Loss: (0.1253) |  Loss2: (0.0000) | Acc: (95.00%) (20926/21888)
Epoch: 146 | Batch_idx: 180 |  Loss: (0.1249) |  Loss2: (0.0000) | Acc: (95.00%) (22154/23168)
Epoch: 146 | Batch_idx: 190 |  Loss: (0.1244) |  Loss2: (0.0000) | Acc: (95.00%) (23380/24448)
Epoch: 146 | Batch_idx: 200 |  Loss: (0.1247) |  Loss2: (0.0000) | Acc: (95.00%) (24605/25728)
Epoch: 146 | Batch_idx: 210 |  Loss: (0.1246) |  Loss2: (0.0000) | Acc: (95.00%) (25832/27008)
Epoch: 146 | Batch_idx: 220 |  Loss: (0.1243) |  Loss2: (0.0000) | Acc: (95.00%) (27071/28288)
Epoch: 146 | Batch_idx: 230 |  Loss: (0.1253) |  Loss2: (0.0000) | Acc: (95.00%) (28296/29568)
Epoch: 146 | Batch_idx: 240 |  Loss: (0.1259) |  Loss2: (0.0000) | Acc: (95.00%) (29511/30848)
Epoch: 146 | Batch_idx: 250 |  Loss: (0.1262) |  Loss2: (0.0000) | Acc: (95.00%) (30725/32128)
Epoch: 146 | Batch_idx: 260 |  Loss: (0.1272) |  Loss2: (0.0000) | Acc: (95.00%) (31937/33408)
Epoch: 146 | Batch_idx: 270 |  Loss: (0.1274) |  Loss2: (0.0000) | Acc: (95.00%) (33161/34688)
Epoch: 146 | Batch_idx: 280 |  Loss: (0.1277) |  Loss2: (0.0000) | Acc: (95.00%) (34368/35968)
Epoch: 146 | Batch_idx: 290 |  Loss: (0.1280) |  Loss2: (0.0000) | Acc: (95.00%) (35584/37248)
Epoch: 146 | Batch_idx: 300 |  Loss: (0.1280) |  Loss2: (0.0000) | Acc: (95.00%) (36802/38528)
Epoch: 146 | Batch_idx: 310 |  Loss: (0.1283) |  Loss2: (0.0000) | Acc: (95.00%) (38023/39808)
Epoch: 146 | Batch_idx: 320 |  Loss: (0.1293) |  Loss2: (0.0000) | Acc: (95.00%) (39229/41088)
Epoch: 146 | Batch_idx: 330 |  Loss: (0.1296) |  Loss2: (0.0000) | Acc: (95.00%) (40449/42368)
Epoch: 146 | Batch_idx: 340 |  Loss: (0.1294) |  Loss2: (0.0000) | Acc: (95.00%) (41678/43648)
Epoch: 146 | Batch_idx: 350 |  Loss: (0.1297) |  Loss2: (0.0000) | Acc: (95.00%) (42901/44928)
Epoch: 146 | Batch_idx: 360 |  Loss: (0.1302) |  Loss2: (0.0000) | Acc: (95.00%) (44114/46208)
Epoch: 146 | Batch_idx: 370 |  Loss: (0.1305) |  Loss2: (0.0000) | Acc: (95.00%) (45324/47488)
Epoch: 146 | Batch_idx: 380 |  Loss: (0.1309) |  Loss2: (0.0000) | Acc: (95.00%) (46543/48768)
Epoch: 146 | Batch_idx: 390 |  Loss: (0.1309) |  Loss2: (0.0000) | Acc: (95.00%) (47715/50000)
# TEST : Loss: (0.4364) | Acc: (87.00%) (8724/10000)
percent tensor([0.5602, 0.5705, 0.5965, 0.5843, 0.5960, 0.5667, 0.5806, 0.5897, 0.5687,
        0.5763, 0.5570, 0.5903, 0.5620, 0.5677, 0.5705, 0.5637],
       device='cuda:0') torch.Size([16])
percent tensor([0.5830, 0.5869, 0.5749, 0.5701, 0.5838, 0.5871, 0.5920, 0.5809, 0.5781,
        0.5812, 0.5862, 0.5882, 0.5816, 0.5790, 0.5923, 0.5829],
       device='cuda:0') torch.Size([16])
percent tensor([0.6093, 0.6225, 0.5890, 0.5647, 0.5723, 0.5813, 0.6090, 0.5768, 0.5909,
        0.6185, 0.6071, 0.6079, 0.6326, 0.5962, 0.6103, 0.6102],
       device='cuda:0') torch.Size([16])
percent tensor([0.6359, 0.6298, 0.6054, 0.6126, 0.6215, 0.6511, 0.6392, 0.6195, 0.6262,
        0.6275, 0.6318, 0.6209, 0.6241, 0.6327, 0.6435, 0.6390],
       device='cuda:0') torch.Size([16])
percent tensor([0.5441, 0.4943, 0.6125, 0.6416, 0.6369, 0.5774, 0.5503, 0.6356, 0.5922,
        0.5148, 0.5328, 0.5729, 0.4508, 0.5895, 0.5826, 0.5501],
       device='cuda:0') torch.Size([16])
percent tensor([0.5346, 0.6693, 0.6581, 0.6383, 0.6627, 0.7070, 0.6365, 0.5750, 0.6581,
        0.6075, 0.6642, 0.6283, 0.6434, 0.6691, 0.5297, 0.5246],
       device='cuda:0') torch.Size([16])
percent tensor([0.6915, 0.7068, 0.7124, 0.6612, 0.6923, 0.7087, 0.7318, 0.6563, 0.6746,
        0.6943, 0.6977, 0.6349, 0.7008, 0.7127, 0.5864, 0.6382],
       device='cuda:0') torch.Size([16])
percent tensor([0.9997, 0.9998, 0.9999, 0.9995, 0.9998, 0.9993, 0.9999, 0.9999, 0.9998,
        0.9999, 0.9999, 0.9995, 0.9997, 0.9998, 0.9996, 0.9995],
       device='cuda:0') torch.Size([16])
False Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=128, out_features=16, bias=False)
True Linear(in_features=16, out_features=2, bias=False)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=128, out_features=16, bias=False)
True Linear(in_features=16, out_features=2, bias=False)
False Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=256, out_features=32, bias=False)
True Linear(in_features=32, out_features=2, bias=False)
False Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=256, out_features=32, bias=False)
True Linear(in_features=32, out_features=2, bias=False)
False Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=512, out_features=64, bias=False)
True Linear(in_features=64, out_features=2, bias=False)
False Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=512, out_features=64, bias=False)
True Linear(in_features=64, out_features=2, bias=False)
False Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1024, out_features=128, bias=False)
True Linear(in_features=128, out_features=2, bias=False)
False Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1024, out_features=128, bias=False)
True Linear(in_features=128, out_features=2, bias=False)
False Linear(in_features=512, out_features=10, bias=True)
Epoch: 147 | Batch_idx: 0 |  Loss: (0.1498) |  Loss2: (0.0000) | Acc: (96.00%) (124/128)
Epoch: 147 | Batch_idx: 10 |  Loss: (0.1424) |  Loss2: (0.0000) | Acc: (95.00%) (1340/1408)
Epoch: 147 | Batch_idx: 20 |  Loss: (0.1497) |  Loss2: (0.0000) | Acc: (95.00%) (2555/2688)
Epoch: 147 | Batch_idx: 30 |  Loss: (0.1517) |  Loss2: (0.0000) | Acc: (94.00%) (3767/3968)
Epoch: 147 | Batch_idx: 40 |  Loss: (0.1643) |  Loss2: (0.0000) | Acc: (94.00%) (4949/5248)
Epoch: 147 | Batch_idx: 50 |  Loss: (0.1665) |  Loss2: (0.0000) | Acc: (94.00%) (6149/6528)
Epoch: 147 | Batch_idx: 60 |  Loss: (0.1655) |  Loss2: (0.0000) | Acc: (94.00%) (7362/7808)
Epoch: 147 | Batch_idx: 70 |  Loss: (0.1656) |  Loss2: (0.0000) | Acc: (94.00%) (8563/9088)
Epoch: 147 | Batch_idx: 80 |  Loss: (0.1687) |  Loss2: (0.0000) | Acc: (94.00%) (9762/10368)
Epoch: 147 | Batch_idx: 90 |  Loss: (0.1695) |  Loss2: (0.0000) | Acc: (94.00%) (10956/11648)
Epoch: 147 | Batch_idx: 100 |  Loss: (0.1680) |  Loss2: (0.0000) | Acc: (94.00%) (12163/12928)
Epoch: 147 | Batch_idx: 110 |  Loss: (0.1681) |  Loss2: (0.0000) | Acc: (94.00%) (13362/14208)
Epoch: 147 | Batch_idx: 120 |  Loss: (0.1657) |  Loss2: (0.0000) | Acc: (94.00%) (14581/15488)
Epoch: 147 | Batch_idx: 130 |  Loss: (0.1683) |  Loss2: (0.0000) | Acc: (93.00%) (15760/16768)
Epoch: 147 | Batch_idx: 140 |  Loss: (0.1668) |  Loss2: (0.0000) | Acc: (94.00%) (16969/18048)
Epoch: 147 | Batch_idx: 150 |  Loss: (0.1664) |  Loss2: (0.0000) | Acc: (94.00%) (18178/19328)
Epoch: 147 | Batch_idx: 160 |  Loss: (0.1676) |  Loss2: (0.0000) | Acc: (94.00%) (19385/20608)
Epoch: 147 | Batch_idx: 170 |  Loss: (0.1664) |  Loss2: (0.0000) | Acc: (94.00%) (20590/21888)
Epoch: 147 | Batch_idx: 180 |  Loss: (0.1660) |  Loss2: (0.0000) | Acc: (94.00%) (21806/23168)
Epoch: 147 | Batch_idx: 190 |  Loss: (0.1651) |  Loss2: (0.0000) | Acc: (94.00%) (23010/24448)
Epoch: 147 | Batch_idx: 200 |  Loss: (0.1638) |  Loss2: (0.0000) | Acc: (94.00%) (24223/25728)
Epoch: 147 | Batch_idx: 210 |  Loss: (0.1644) |  Loss2: (0.0000) | Acc: (94.00%) (25414/27008)
Epoch: 147 | Batch_idx: 220 |  Loss: (0.1643) |  Loss2: (0.0000) | Acc: (94.00%) (26623/28288)
Epoch: 147 | Batch_idx: 230 |  Loss: (0.1646) |  Loss2: (0.0000) | Acc: (94.00%) (27831/29568)
Epoch: 147 | Batch_idx: 240 |  Loss: (0.1641) |  Loss2: (0.0000) | Acc: (94.00%) (29037/30848)
Epoch: 147 | Batch_idx: 250 |  Loss: (0.1634) |  Loss2: (0.0000) | Acc: (94.00%) (30256/32128)
Epoch: 147 | Batch_idx: 260 |  Loss: (0.1632) |  Loss2: (0.0000) | Acc: (94.00%) (31463/33408)
Epoch: 147 | Batch_idx: 270 |  Loss: (0.1629) |  Loss2: (0.0000) | Acc: (94.00%) (32670/34688)
Epoch: 147 | Batch_idx: 280 |  Loss: (0.1614) |  Loss2: (0.0000) | Acc: (94.00%) (33896/35968)
Epoch: 147 | Batch_idx: 290 |  Loss: (0.1608) |  Loss2: (0.0000) | Acc: (94.00%) (35110/37248)
Epoch: 147 | Batch_idx: 300 |  Loss: (0.1599) |  Loss2: (0.0000) | Acc: (94.00%) (36329/38528)
Epoch: 147 | Batch_idx: 310 |  Loss: (0.1598) |  Loss2: (0.0000) | Acc: (94.00%) (37536/39808)
Epoch: 147 | Batch_idx: 320 |  Loss: (0.1598) |  Loss2: (0.0000) | Acc: (94.00%) (38747/41088)
Epoch: 147 | Batch_idx: 330 |  Loss: (0.1592) |  Loss2: (0.0000) | Acc: (94.00%) (39959/42368)
Epoch: 147 | Batch_idx: 340 |  Loss: (0.1588) |  Loss2: (0.0000) | Acc: (94.00%) (41170/43648)
Epoch: 147 | Batch_idx: 350 |  Loss: (0.1583) |  Loss2: (0.0000) | Acc: (94.00%) (42387/44928)
Epoch: 147 | Batch_idx: 360 |  Loss: (0.1581) |  Loss2: (0.0000) | Acc: (94.00%) (43598/46208)
Epoch: 147 | Batch_idx: 370 |  Loss: (0.1575) |  Loss2: (0.0000) | Acc: (94.00%) (44805/47488)
Epoch: 147 | Batch_idx: 380 |  Loss: (0.1569) |  Loss2: (0.0000) | Acc: (94.00%) (46028/48768)
Epoch: 147 | Batch_idx: 390 |  Loss: (0.1573) |  Loss2: (0.0000) | Acc: (94.00%) (47184/50000)
# TEST : Loss: (0.4379) | Acc: (87.00%) (8719/10000)
percent tensor([0.5656, 0.5779, 0.5999, 0.5902, 0.6008, 0.5720, 0.5867, 0.5961, 0.5741,
        0.5826, 0.5634, 0.5954, 0.5682, 0.5747, 0.5767, 0.5692],
       device='cuda:0') torch.Size([16])
percent tensor([0.5850, 0.5891, 0.5765, 0.5730, 0.5858, 0.5886, 0.5944, 0.5831, 0.5796,
        0.5833, 0.5882, 0.5902, 0.5842, 0.5808, 0.5942, 0.5849],
       device='cuda:0') torch.Size([16])
percent tensor([0.5932, 0.6011, 0.5709, 0.5478, 0.5558, 0.5709, 0.5890, 0.5574, 0.5755,
        0.5979, 0.5904, 0.5864, 0.6133, 0.5811, 0.5909, 0.5943],
       device='cuda:0') torch.Size([16])
percent tensor([0.6322, 0.6272, 0.6015, 0.6090, 0.6178, 0.6474, 0.6356, 0.6148, 0.6230,
        0.6240, 0.6301, 0.6175, 0.6217, 0.6296, 0.6393, 0.6344],
       device='cuda:0') torch.Size([16])
percent tensor([0.5252, 0.4903, 0.5926, 0.6243, 0.6177, 0.5610, 0.5436, 0.6163, 0.5864,
        0.5130, 0.5304, 0.5658, 0.4430, 0.5863, 0.5627, 0.5332],
       device='cuda:0') torch.Size([16])
percent tensor([0.5201, 0.6668, 0.6546, 0.6252, 0.6574, 0.7140, 0.6277, 0.5667, 0.6560,
        0.5950, 0.6619, 0.6386, 0.6423, 0.6689, 0.5286, 0.5132],
       device='cuda:0') torch.Size([16])
percent tensor([0.6304, 0.6664, 0.6725, 0.6038, 0.6340, 0.6744, 0.6654, 0.5787, 0.6249,
        0.6369, 0.6531, 0.5761, 0.6668, 0.6646, 0.5362, 0.5767],
       device='cuda:0') torch.Size([16])
percent tensor([0.9997, 0.9997, 0.9998, 0.9997, 0.9997, 0.9991, 0.9999, 0.9999, 0.9998,
        0.9999, 0.9999, 0.9996, 0.9996, 0.9997, 0.9996, 0.9996],
       device='cuda:0') torch.Size([16])
Epoch: 148 | Batch_idx: 0 |  Loss: (0.2265) |  Loss2: (0.0000) | Acc: (92.00%) (118/128)
Epoch: 148 | Batch_idx: 10 |  Loss: (0.1547) |  Loss2: (0.0000) | Acc: (94.00%) (1337/1408)
Epoch: 148 | Batch_idx: 20 |  Loss: (0.1501) |  Loss2: (0.0000) | Acc: (94.00%) (2546/2688)
Epoch: 148 | Batch_idx: 30 |  Loss: (0.1481) |  Loss2: (0.0000) | Acc: (94.00%) (3755/3968)
Epoch: 148 | Batch_idx: 40 |  Loss: (0.1361) |  Loss2: (0.0000) | Acc: (95.00%) (4997/5248)
Epoch: 148 | Batch_idx: 50 |  Loss: (0.1361) |  Loss2: (0.0000) | Acc: (95.00%) (6218/6528)
Epoch: 148 | Batch_idx: 60 |  Loss: (0.1349) |  Loss2: (0.0000) | Acc: (95.00%) (7441/7808)
Epoch: 148 | Batch_idx: 70 |  Loss: (0.1339) |  Loss2: (0.0000) | Acc: (95.00%) (8669/9088)
Epoch: 148 | Batch_idx: 80 |  Loss: (0.1357) |  Loss2: (0.0000) | Acc: (95.00%) (9883/10368)
Epoch: 148 | Batch_idx: 90 |  Loss: (0.1344) |  Loss2: (0.0000) | Acc: (95.00%) (11100/11648)
Epoch: 148 | Batch_idx: 100 |  Loss: (0.1358) |  Loss2: (0.0000) | Acc: (95.00%) (12318/12928)
Epoch: 148 | Batch_idx: 110 |  Loss: (0.1362) |  Loss2: (0.0000) | Acc: (95.00%) (13545/14208)
Epoch: 148 | Batch_idx: 120 |  Loss: (0.1346) |  Loss2: (0.0000) | Acc: (95.00%) (14771/15488)
Epoch: 148 | Batch_idx: 130 |  Loss: (0.1350) |  Loss2: (0.0000) | Acc: (95.00%) (15985/16768)
Epoch: 148 | Batch_idx: 140 |  Loss: (0.1365) |  Loss2: (0.0000) | Acc: (95.00%) (17201/18048)
Epoch: 148 | Batch_idx: 150 |  Loss: (0.1384) |  Loss2: (0.0000) | Acc: (95.00%) (18395/19328)
Epoch: 148 | Batch_idx: 160 |  Loss: (0.1401) |  Loss2: (0.0000) | Acc: (95.00%) (19599/20608)
Epoch: 148 | Batch_idx: 170 |  Loss: (0.1394) |  Loss2: (0.0000) | Acc: (95.00%) (20828/21888)
Epoch: 148 | Batch_idx: 180 |  Loss: (0.1400) |  Loss2: (0.0000) | Acc: (95.00%) (22041/23168)
Epoch: 148 | Batch_idx: 190 |  Loss: (0.1397) |  Loss2: (0.0000) | Acc: (95.00%) (23269/24448)
Epoch: 148 | Batch_idx: 200 |  Loss: (0.1406) |  Loss2: (0.0000) | Acc: (95.00%) (24477/25728)
Epoch: 148 | Batch_idx: 210 |  Loss: (0.1417) |  Loss2: (0.0000) | Acc: (95.00%) (25688/27008)
Epoch: 148 | Batch_idx: 220 |  Loss: (0.1421) |  Loss2: (0.0000) | Acc: (95.00%) (26902/28288)
Epoch: 148 | Batch_idx: 230 |  Loss: (0.1415) |  Loss2: (0.0000) | Acc: (95.00%) (28120/29568)
Epoch: 148 | Batch_idx: 240 |  Loss: (0.1416) |  Loss2: (0.0000) | Acc: (95.00%) (29337/30848)
Epoch: 148 | Batch_idx: 250 |  Loss: (0.1419) |  Loss2: (0.0000) | Acc: (95.00%) (30549/32128)
Epoch: 148 | Batch_idx: 260 |  Loss: (0.1424) |  Loss2: (0.0000) | Acc: (95.00%) (31756/33408)
Epoch: 148 | Batch_idx: 270 |  Loss: (0.1411) |  Loss2: (0.0000) | Acc: (95.00%) (32993/34688)
Epoch: 148 | Batch_idx: 280 |  Loss: (0.1402) |  Loss2: (0.0000) | Acc: (95.00%) (34228/35968)
Epoch: 148 | Batch_idx: 290 |  Loss: (0.1403) |  Loss2: (0.0000) | Acc: (95.00%) (35440/37248)
Epoch: 148 | Batch_idx: 300 |  Loss: (0.1395) |  Loss2: (0.0000) | Acc: (95.00%) (36673/38528)
Epoch: 148 | Batch_idx: 310 |  Loss: (0.1391) |  Loss2: (0.0000) | Acc: (95.00%) (37904/39808)
Epoch: 148 | Batch_idx: 320 |  Loss: (0.1385) |  Loss2: (0.0000) | Acc: (95.00%) (39134/41088)
Epoch: 148 | Batch_idx: 330 |  Loss: (0.1384) |  Loss2: (0.0000) | Acc: (95.00%) (40362/42368)
Epoch: 148 | Batch_idx: 340 |  Loss: (0.1379) |  Loss2: (0.0000) | Acc: (95.00%) (41587/43648)
Epoch: 148 | Batch_idx: 350 |  Loss: (0.1378) |  Loss2: (0.0000) | Acc: (95.00%) (42809/44928)
Epoch: 148 | Batch_idx: 360 |  Loss: (0.1383) |  Loss2: (0.0000) | Acc: (95.00%) (44016/46208)
Epoch: 148 | Batch_idx: 370 |  Loss: (0.1384) |  Loss2: (0.0000) | Acc: (95.00%) (45225/47488)
Epoch: 148 | Batch_idx: 380 |  Loss: (0.1377) |  Loss2: (0.0000) | Acc: (95.00%) (46451/48768)
Epoch: 148 | Batch_idx: 390 |  Loss: (0.1381) |  Loss2: (0.0000) | Acc: (95.00%) (47620/50000)
# TEST : Loss: (0.4120) | Acc: (88.00%) (8817/10000)
percent tensor([0.5693, 0.5821, 0.6035, 0.5939, 0.6047, 0.5753, 0.5907, 0.6006, 0.5783,
        0.5867, 0.5676, 0.5991, 0.5723, 0.5789, 0.5804, 0.5729],
       device='cuda:0') torch.Size([16])
percent tensor([0.5828, 0.5867, 0.5758, 0.5710, 0.5842, 0.5859, 0.5920, 0.5812, 0.5773,
        0.5814, 0.5857, 0.5884, 0.5821, 0.5777, 0.5916, 0.5827],
       device='cuda:0') torch.Size([16])
percent tensor([0.5945, 0.6020, 0.5703, 0.5484, 0.5545, 0.5742, 0.5891, 0.5568, 0.5770,
        0.5986, 0.5919, 0.5862, 0.6144, 0.5845, 0.5918, 0.5966],
       device='cuda:0') torch.Size([16])
percent tensor([0.6321, 0.6270, 0.6006, 0.6082, 0.6172, 0.6480, 0.6352, 0.6132, 0.6223,
        0.6236, 0.6301, 0.6165, 0.6215, 0.6289, 0.6390, 0.6343],
       device='cuda:0') torch.Size([16])
percent tensor([0.5257, 0.4898, 0.5848, 0.6213, 0.6168, 0.5642, 0.5411, 0.6111, 0.5842,
        0.5125, 0.5334, 0.5548, 0.4410, 0.5889, 0.5608, 0.5365],
       device='cuda:0') torch.Size([16])
percent tensor([0.5148, 0.6708, 0.6590, 0.6269, 0.6605, 0.7152, 0.6273, 0.5667, 0.6635,
        0.5968, 0.6664, 0.6520, 0.6472, 0.6776, 0.5264, 0.5082],
       device='cuda:0') torch.Size([16])
percent tensor([0.6267, 0.6735, 0.6782, 0.6004, 0.6306, 0.6792, 0.6619, 0.5691, 0.6298,
        0.6386, 0.6602, 0.5787, 0.6751, 0.6695, 0.5293, 0.5681],
       device='cuda:0') torch.Size([16])
percent tensor([0.9997, 0.9997, 0.9998, 0.9997, 0.9997, 0.9993, 0.9999, 0.9999, 0.9998,
        0.9999, 0.9999, 0.9996, 0.9996, 0.9997, 0.9996, 0.9996],
       device='cuda:0') torch.Size([16])
Epoch: 149 | Batch_idx: 0 |  Loss: (0.1696) |  Loss2: (0.0000) | Acc: (92.00%) (118/128)
Epoch: 149 | Batch_idx: 10 |  Loss: (0.1551) |  Loss2: (0.0000) | Acc: (94.00%) (1336/1408)
Epoch: 149 | Batch_idx: 20 |  Loss: (0.1559) |  Loss2: (0.0000) | Acc: (94.00%) (2550/2688)
Epoch: 149 | Batch_idx: 30 |  Loss: (0.1505) |  Loss2: (0.0000) | Acc: (94.00%) (3767/3968)
Epoch: 149 | Batch_idx: 40 |  Loss: (0.1441) |  Loss2: (0.0000) | Acc: (95.00%) (4994/5248)
Epoch: 149 | Batch_idx: 50 |  Loss: (0.1413) |  Loss2: (0.0000) | Acc: (95.00%) (6213/6528)
Epoch: 149 | Batch_idx: 60 |  Loss: (0.1409) |  Loss2: (0.0000) | Acc: (95.00%) (7441/7808)
Epoch: 149 | Batch_idx: 70 |  Loss: (0.1393) |  Loss2: (0.0000) | Acc: (95.00%) (8662/9088)
Epoch: 149 | Batch_idx: 80 |  Loss: (0.1385) |  Loss2: (0.0000) | Acc: (95.00%) (9882/10368)
Epoch: 149 | Batch_idx: 90 |  Loss: (0.1359) |  Loss2: (0.0000) | Acc: (95.00%) (11110/11648)
Epoch: 149 | Batch_idx: 100 |  Loss: (0.1325) |  Loss2: (0.0000) | Acc: (95.00%) (12353/12928)
Epoch: 149 | Batch_idx: 110 |  Loss: (0.1326) |  Loss2: (0.0000) | Acc: (95.00%) (13574/14208)
Epoch: 149 | Batch_idx: 120 |  Loss: (0.1333) |  Loss2: (0.0000) | Acc: (95.00%) (14786/15488)
Epoch: 149 | Batch_idx: 130 |  Loss: (0.1338) |  Loss2: (0.0000) | Acc: (95.00%) (16006/16768)
Epoch: 149 | Batch_idx: 140 |  Loss: (0.1347) |  Loss2: (0.0000) | Acc: (95.00%) (17211/18048)
Epoch: 149 | Batch_idx: 150 |  Loss: (0.1334) |  Loss2: (0.0000) | Acc: (95.00%) (18444/19328)
Epoch: 149 | Batch_idx: 160 |  Loss: (0.1319) |  Loss2: (0.0000) | Acc: (95.00%) (19673/20608)
Epoch: 149 | Batch_idx: 170 |  Loss: (0.1322) |  Loss2: (0.0000) | Acc: (95.00%) (20896/21888)
Epoch: 149 | Batch_idx: 180 |  Loss: (0.1315) |  Loss2: (0.0000) | Acc: (95.00%) (22123/23168)
Epoch: 149 | Batch_idx: 190 |  Loss: (0.1313) |  Loss2: (0.0000) | Acc: (95.00%) (23344/24448)
Epoch: 149 | Batch_idx: 200 |  Loss: (0.1309) |  Loss2: (0.0000) | Acc: (95.00%) (24575/25728)
Epoch: 149 | Batch_idx: 210 |  Loss: (0.1298) |  Loss2: (0.0000) | Acc: (95.00%) (25807/27008)
Epoch: 149 | Batch_idx: 220 |  Loss: (0.1292) |  Loss2: (0.0000) | Acc: (95.00%) (27029/28288)
Epoch: 149 | Batch_idx: 230 |  Loss: (0.1303) |  Loss2: (0.0000) | Acc: (95.00%) (28241/29568)
Epoch: 149 | Batch_idx: 240 |  Loss: (0.1303) |  Loss2: (0.0000) | Acc: (95.00%) (29458/30848)
Epoch: 149 | Batch_idx: 250 |  Loss: (0.1302) |  Loss2: (0.0000) | Acc: (95.00%) (30685/32128)
Epoch: 149 | Batch_idx: 260 |  Loss: (0.1298) |  Loss2: (0.0000) | Acc: (95.00%) (31918/33408)
Epoch: 149 | Batch_idx: 270 |  Loss: (0.1302) |  Loss2: (0.0000) | Acc: (95.00%) (33135/34688)
Epoch: 149 | Batch_idx: 280 |  Loss: (0.1298) |  Loss2: (0.0000) | Acc: (95.00%) (34363/35968)
Epoch: 149 | Batch_idx: 290 |  Loss: (0.1298) |  Loss2: (0.0000) | Acc: (95.00%) (35593/37248)
Epoch: 149 | Batch_idx: 300 |  Loss: (0.1303) |  Loss2: (0.0000) | Acc: (95.00%) (36811/38528)
Epoch: 149 | Batch_idx: 310 |  Loss: (0.1301) |  Loss2: (0.0000) | Acc: (95.00%) (38039/39808)
Epoch: 149 | Batch_idx: 320 |  Loss: (0.1300) |  Loss2: (0.0000) | Acc: (95.00%) (39262/41088)
Epoch: 149 | Batch_idx: 330 |  Loss: (0.1300) |  Loss2: (0.0000) | Acc: (95.00%) (40492/42368)
Epoch: 149 | Batch_idx: 340 |  Loss: (0.1307) |  Loss2: (0.0000) | Acc: (95.00%) (41706/43648)
Epoch: 149 | Batch_idx: 350 |  Loss: (0.1301) |  Loss2: (0.0000) | Acc: (95.00%) (42946/44928)
Epoch: 149 | Batch_idx: 360 |  Loss: (0.1298) |  Loss2: (0.0000) | Acc: (95.00%) (44176/46208)
Epoch: 149 | Batch_idx: 370 |  Loss: (0.1295) |  Loss2: (0.0000) | Acc: (95.00%) (45405/47488)
Epoch: 149 | Batch_idx: 380 |  Loss: (0.1291) |  Loss2: (0.0000) | Acc: (95.00%) (46639/48768)
Epoch: 149 | Batch_idx: 390 |  Loss: (0.1300) |  Loss2: (0.0000) | Acc: (95.00%) (47803/50000)
# TEST : Loss: (0.4011) | Acc: (88.00%) (8826/10000)
percent tensor([0.5698, 0.5827, 0.6036, 0.5947, 0.6047, 0.5758, 0.5910, 0.6014, 0.5787,
        0.5871, 0.5681, 0.5991, 0.5729, 0.5799, 0.5810, 0.5738],
       device='cuda:0') torch.Size([16])
percent tensor([0.5852, 0.5888, 0.5789, 0.5738, 0.5873, 0.5879, 0.5945, 0.5840, 0.5798,
        0.5838, 0.5880, 0.5908, 0.5843, 0.5798, 0.5937, 0.5850],
       device='cuda:0') torch.Size([16])
percent tensor([0.5965, 0.6030, 0.5700, 0.5490, 0.5539, 0.5771, 0.5898, 0.5570, 0.5783,
        0.6001, 0.5943, 0.5861, 0.6163, 0.5875, 0.5928, 0.5991],
       device='cuda:0') torch.Size([16])
percent tensor([0.6351, 0.6293, 0.6028, 0.6114, 0.6201, 0.6509, 0.6383, 0.6158, 0.6253,
        0.6261, 0.6334, 0.6190, 0.6236, 0.6319, 0.6420, 0.6369],
       device='cuda:0') torch.Size([16])
percent tensor([0.5266, 0.4909, 0.5808, 0.6211, 0.6163, 0.5648, 0.5402, 0.6108, 0.5806,
        0.5113, 0.5343, 0.5495, 0.4377, 0.5877, 0.5612, 0.5406],
       device='cuda:0') torch.Size([16])
percent tensor([0.5189, 0.6755, 0.6620, 0.6324, 0.6625, 0.7151, 0.6315, 0.5686, 0.6674,
        0.6035, 0.6734, 0.6614, 0.6530, 0.6870, 0.5309, 0.5095],
       device='cuda:0') torch.Size([16])
percent tensor([0.6385, 0.6879, 0.6894, 0.6079, 0.6365, 0.6883, 0.6714, 0.5715, 0.6400,
        0.6528, 0.6741, 0.5894, 0.6898, 0.6830, 0.5340, 0.5739],
       device='cuda:0') torch.Size([16])
percent tensor([0.9997, 0.9997, 0.9998, 0.9997, 0.9997, 0.9992, 0.9999, 0.9999, 0.9998,
        0.9999, 0.9999, 0.9996, 0.9996, 0.9997, 0.9996, 0.9996],
       device='cuda:0') torch.Size([16])
Epoch: 150 | Batch_idx: 0 |  Loss: (0.1037) |  Loss2: (0.0000) | Acc: (94.00%) (121/128)
Epoch: 150 | Batch_idx: 10 |  Loss: (0.1285) |  Loss2: (0.0000) | Acc: (95.00%) (1346/1408)
Epoch: 150 | Batch_idx: 20 |  Loss: (0.1281) |  Loss2: (0.0000) | Acc: (95.00%) (2575/2688)
Epoch: 150 | Batch_idx: 30 |  Loss: (0.1256) |  Loss2: (0.0000) | Acc: (95.00%) (3801/3968)
Epoch: 150 | Batch_idx: 40 |  Loss: (0.1206) |  Loss2: (0.0000) | Acc: (95.00%) (5035/5248)
Epoch: 150 | Batch_idx: 50 |  Loss: (0.1207) |  Loss2: (0.0000) | Acc: (96.00%) (6267/6528)
Epoch: 150 | Batch_idx: 60 |  Loss: (0.1187) |  Loss2: (0.0000) | Acc: (95.00%) (7493/7808)
Epoch: 150 | Batch_idx: 70 |  Loss: (0.1199) |  Loss2: (0.0000) | Acc: (95.00%) (8714/9088)
Epoch: 150 | Batch_idx: 80 |  Loss: (0.1197) |  Loss2: (0.0000) | Acc: (95.00%) (9940/10368)
Epoch: 150 | Batch_idx: 90 |  Loss: (0.1184) |  Loss2: (0.0000) | Acc: (95.00%) (11172/11648)
Epoch: 150 | Batch_idx: 100 |  Loss: (0.1202) |  Loss2: (0.0000) | Acc: (95.00%) (12387/12928)
Epoch: 150 | Batch_idx: 110 |  Loss: (0.1202) |  Loss2: (0.0000) | Acc: (95.00%) (13625/14208)
Epoch: 150 | Batch_idx: 120 |  Loss: (0.1193) |  Loss2: (0.0000) | Acc: (95.00%) (14861/15488)
Epoch: 150 | Batch_idx: 130 |  Loss: (0.1196) |  Loss2: (0.0000) | Acc: (95.00%) (16086/16768)
Epoch: 150 | Batch_idx: 140 |  Loss: (0.1210) |  Loss2: (0.0000) | Acc: (95.00%) (17302/18048)
Epoch: 150 | Batch_idx: 150 |  Loss: (0.1219) |  Loss2: (0.0000) | Acc: (95.00%) (18528/19328)
Epoch: 150 | Batch_idx: 160 |  Loss: (0.1218) |  Loss2: (0.0000) | Acc: (95.00%) (19759/20608)
Epoch: 150 | Batch_idx: 170 |  Loss: (0.1224) |  Loss2: (0.0000) | Acc: (95.00%) (20981/21888)
Epoch: 150 | Batch_idx: 180 |  Loss: (0.1222) |  Loss2: (0.0000) | Acc: (95.00%) (22210/23168)
Epoch: 150 | Batch_idx: 190 |  Loss: (0.1224) |  Loss2: (0.0000) | Acc: (95.00%) (23437/24448)
Epoch: 150 | Batch_idx: 200 |  Loss: (0.1227) |  Loss2: (0.0000) | Acc: (95.00%) (24659/25728)
Epoch: 150 | Batch_idx: 210 |  Loss: (0.1230) |  Loss2: (0.0000) | Acc: (95.00%) (25879/27008)
Epoch: 150 | Batch_idx: 220 |  Loss: (0.1234) |  Loss2: (0.0000) | Acc: (95.00%) (27102/28288)
Epoch: 150 | Batch_idx: 230 |  Loss: (0.1239) |  Loss2: (0.0000) | Acc: (95.00%) (28317/29568)
Epoch: 150 | Batch_idx: 240 |  Loss: (0.1235) |  Loss2: (0.0000) | Acc: (95.00%) (29555/30848)
Epoch: 150 | Batch_idx: 250 |  Loss: (0.1234) |  Loss2: (0.0000) | Acc: (95.00%) (30786/32128)
Epoch: 150 | Batch_idx: 260 |  Loss: (0.1231) |  Loss2: (0.0000) | Acc: (95.00%) (32022/33408)
Epoch: 150 | Batch_idx: 270 |  Loss: (0.1232) |  Loss2: (0.0000) | Acc: (95.00%) (33248/34688)
Epoch: 150 | Batch_idx: 280 |  Loss: (0.1231) |  Loss2: (0.0000) | Acc: (95.00%) (34475/35968)
Epoch: 150 | Batch_idx: 290 |  Loss: (0.1224) |  Loss2: (0.0000) | Acc: (95.00%) (35712/37248)
Epoch: 150 | Batch_idx: 300 |  Loss: (0.1226) |  Loss2: (0.0000) | Acc: (95.00%) (36935/38528)
Epoch: 150 | Batch_idx: 310 |  Loss: (0.1229) |  Loss2: (0.0000) | Acc: (95.00%) (38157/39808)
Epoch: 150 | Batch_idx: 320 |  Loss: (0.1229) |  Loss2: (0.0000) | Acc: (95.00%) (39387/41088)
Epoch: 150 | Batch_idx: 330 |  Loss: (0.1227) |  Loss2: (0.0000) | Acc: (95.00%) (40616/42368)
Epoch: 150 | Batch_idx: 340 |  Loss: (0.1226) |  Loss2: (0.0000) | Acc: (95.00%) (41837/43648)
Epoch: 150 | Batch_idx: 350 |  Loss: (0.1228) |  Loss2: (0.0000) | Acc: (95.00%) (43068/44928)
Epoch: 150 | Batch_idx: 360 |  Loss: (0.1232) |  Loss2: (0.0000) | Acc: (95.00%) (44289/46208)
Epoch: 150 | Batch_idx: 370 |  Loss: (0.1236) |  Loss2: (0.0000) | Acc: (95.00%) (45518/47488)
Epoch: 150 | Batch_idx: 380 |  Loss: (0.1237) |  Loss2: (0.0000) | Acc: (95.00%) (46746/48768)
Epoch: 150 | Batch_idx: 390 |  Loss: (0.1236) |  Loss2: (0.0000) | Acc: (95.00%) (47927/50000)
=> saving checkpoint 'drive/app/torch/save_Schedule/checkpoint_150.pth.tar'
# TEST : Loss: (0.4014) | Acc: (88.00%) (8836/10000)
percent tensor([0.5679, 0.5798, 0.6012, 0.5922, 0.6023, 0.5739, 0.5883, 0.5990, 0.5767,
        0.5845, 0.5660, 0.5967, 0.5707, 0.5773, 0.5784, 0.5714],
       device='cuda:0') torch.Size([16])
percent tensor([0.5867, 0.5904, 0.5813, 0.5756, 0.5893, 0.5890, 0.5963, 0.5859, 0.5813,
        0.5858, 0.5895, 0.5932, 0.5858, 0.5807, 0.5951, 0.5865],
       device='cuda:0') torch.Size([16])
percent tensor([0.6018, 0.6081, 0.5742, 0.5543, 0.5580, 0.5834, 0.5942, 0.5613, 0.5833,
        0.6053, 0.5998, 0.5908, 0.6216, 0.5929, 0.5983, 0.6051],
       device='cuda:0') torch.Size([16])
percent tensor([0.6326, 0.6267, 0.6005, 0.6095, 0.6175, 0.6489, 0.6358, 0.6133, 0.6225,
        0.6234, 0.6306, 0.6163, 0.6210, 0.6293, 0.6397, 0.6345],
       device='cuda:0') torch.Size([16])
percent tensor([0.5263, 0.4917, 0.5748, 0.6174, 0.6164, 0.5646, 0.5418, 0.6089, 0.5809,
        0.5133, 0.5365, 0.5480, 0.4389, 0.5901, 0.5636, 0.5415],
       device='cuda:0') torch.Size([16])
percent tensor([0.5380, 0.6902, 0.6752, 0.6444, 0.6758, 0.7280, 0.6480, 0.5852, 0.6834,
        0.6200, 0.6901, 0.6786, 0.6707, 0.7038, 0.5463, 0.5290],
       device='cuda:0') torch.Size([16])
percent tensor([0.6547, 0.7055, 0.7052, 0.6181, 0.6476, 0.7046, 0.6827, 0.5805, 0.6561,
        0.6690, 0.6919, 0.6006, 0.7076, 0.6968, 0.5381, 0.5859],
       device='cuda:0') torch.Size([16])
percent tensor([0.9997, 0.9997, 0.9998, 0.9997, 0.9997, 0.9992, 0.9999, 0.9999, 0.9998,
        0.9999, 0.9999, 0.9996, 0.9997, 0.9997, 0.9997, 0.9995],
       device='cuda:0') torch.Size([16])
Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 3, 3, 3]) tensor(188.8050, device='cuda:0')
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(819.6708, device='cuda:0')
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(839.7834, device='cuda:0')
Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([128, 64, 3, 3]) tensor(1527.1182, device='cuda:0')
Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([128, 64, 1, 1]) tensor(490.6761, device='cuda:0')
Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([128, 128, 3, 3]) tensor(2271.0911, device='cuda:0')
Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([256, 128, 3, 3]) tensor(4258.0215, device='cuda:0')
Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([256, 128, 1, 1]) tensor(1365.5509, device='cuda:0')
Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([256, 256, 3, 3]) tensor(6204.4473, device='cuda:0')
Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([512, 256, 3, 3]) tensor(11697.8320, device='cuda:0')
Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([512, 256, 1, 1]) tensor(3863.7036, device='cuda:0')
Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([512, 512, 3, 3]) tensor(16313.9844, device='cuda:0')
Epoch: 151 | Batch_idx: 0 |  Loss: (0.0917) |  Loss2: (0.0000) | Acc: (97.00%) (125/128)
Epoch: 151 | Batch_idx: 10 |  Loss: (0.1133) |  Loss2: (0.0000) | Acc: (96.00%) (1359/1408)
Epoch: 151 | Batch_idx: 20 |  Loss: (0.1215) |  Loss2: (0.0000) | Acc: (96.00%) (2588/2688)
Epoch: 151 | Batch_idx: 30 |  Loss: (0.1251) |  Loss2: (0.0000) | Acc: (96.00%) (3810/3968)
Epoch: 151 | Batch_idx: 40 |  Loss: (0.1229) |  Loss2: (0.0000) | Acc: (96.00%) (5046/5248)
Epoch: 151 | Batch_idx: 50 |  Loss: (0.1199) |  Loss2: (0.0000) | Acc: (96.00%) (6280/6528)
Epoch: 151 | Batch_idx: 60 |  Loss: (0.1228) |  Loss2: (0.0000) | Acc: (96.00%) (7505/7808)
Epoch: 151 | Batch_idx: 70 |  Loss: (0.1240) |  Loss2: (0.0000) | Acc: (96.00%) (8725/9088)
Epoch: 151 | Batch_idx: 80 |  Loss: (0.1226) |  Loss2: (0.0000) | Acc: (96.00%) (9959/10368)
Epoch: 151 | Batch_idx: 90 |  Loss: (0.1226) |  Loss2: (0.0000) | Acc: (95.00%) (11178/11648)
Epoch: 151 | Batch_idx: 100 |  Loss: (0.1225) |  Loss2: (0.0000) | Acc: (95.00%) (12403/12928)
Epoch: 151 | Batch_idx: 110 |  Loss: (0.1217) |  Loss2: (0.0000) | Acc: (95.00%) (13635/14208)
Epoch: 151 | Batch_idx: 120 |  Loss: (0.1222) |  Loss2: (0.0000) | Acc: (95.00%) (14868/15488)
Epoch: 151 | Batch_idx: 130 |  Loss: (0.1236) |  Loss2: (0.0000) | Acc: (95.00%) (16087/16768)
Epoch: 151 | Batch_idx: 140 |  Loss: (0.1231) |  Loss2: (0.0000) | Acc: (95.00%) (17322/18048)
Epoch: 151 | Batch_idx: 150 |  Loss: (0.1236) |  Loss2: (0.0000) | Acc: (95.00%) (18552/19328)
Epoch: 151 | Batch_idx: 160 |  Loss: (0.1228) |  Loss2: (0.0000) | Acc: (95.00%) (19777/20608)
Epoch: 151 | Batch_idx: 170 |  Loss: (0.1222) |  Loss2: (0.0000) | Acc: (96.00%) (21016/21888)
Epoch: 151 | Batch_idx: 180 |  Loss: (0.1222) |  Loss2: (0.0000) | Acc: (96.00%) (22242/23168)
Epoch: 151 | Batch_idx: 190 |  Loss: (0.1229) |  Loss2: (0.0000) | Acc: (95.00%) (23461/24448)
Epoch: 151 | Batch_idx: 200 |  Loss: (0.1224) |  Loss2: (0.0000) | Acc: (95.00%) (24690/25728)
Epoch: 151 | Batch_idx: 210 |  Loss: (0.1226) |  Loss2: (0.0000) | Acc: (95.00%) (25918/27008)
Epoch: 151 | Batch_idx: 220 |  Loss: (0.1225) |  Loss2: (0.0000) | Acc: (95.00%) (27154/28288)
Epoch: 151 | Batch_idx: 230 |  Loss: (0.1222) |  Loss2: (0.0000) | Acc: (96.00%) (28387/29568)
Epoch: 151 | Batch_idx: 240 |  Loss: (0.1218) |  Loss2: (0.0000) | Acc: (96.00%) (29618/30848)
Epoch: 151 | Batch_idx: 250 |  Loss: (0.1209) |  Loss2: (0.0000) | Acc: (96.00%) (30857/32128)
Epoch: 151 | Batch_idx: 260 |  Loss: (0.1209) |  Loss2: (0.0000) | Acc: (96.00%) (32081/33408)
Epoch: 151 | Batch_idx: 270 |  Loss: (0.1213) |  Loss2: (0.0000) | Acc: (96.00%) (33301/34688)
Epoch: 151 | Batch_idx: 280 |  Loss: (0.1209) |  Loss2: (0.0000) | Acc: (96.00%) (34535/35968)
Epoch: 151 | Batch_idx: 290 |  Loss: (0.1208) |  Loss2: (0.0000) | Acc: (96.00%) (35774/37248)
Epoch: 151 | Batch_idx: 300 |  Loss: (0.1198) |  Loss2: (0.0000) | Acc: (96.00%) (37019/38528)
Epoch: 151 | Batch_idx: 310 |  Loss: (0.1196) |  Loss2: (0.0000) | Acc: (96.00%) (38251/39808)
Epoch: 151 | Batch_idx: 320 |  Loss: (0.1198) |  Loss2: (0.0000) | Acc: (96.00%) (39471/41088)
Epoch: 151 | Batch_idx: 330 |  Loss: (0.1200) |  Loss2: (0.0000) | Acc: (96.00%) (40699/42368)
Epoch: 151 | Batch_idx: 340 |  Loss: (0.1197) |  Loss2: (0.0000) | Acc: (96.00%) (41937/43648)
Epoch: 151 | Batch_idx: 350 |  Loss: (0.1196) |  Loss2: (0.0000) | Acc: (96.00%) (43169/44928)
Epoch: 151 | Batch_idx: 360 |  Loss: (0.1196) |  Loss2: (0.0000) | Acc: (96.00%) (44392/46208)
Epoch: 151 | Batch_idx: 370 |  Loss: (0.1192) |  Loss2: (0.0000) | Acc: (96.00%) (45631/47488)
Epoch: 151 | Batch_idx: 380 |  Loss: (0.1186) |  Loss2: (0.0000) | Acc: (96.00%) (46857/48768)
Epoch: 151 | Batch_idx: 390 |  Loss: (0.1187) |  Loss2: (0.0000) | Acc: (96.00%) (48040/50000)
# TEST : Loss: (0.3939) | Acc: (88.00%) (8856/10000)
percent tensor([0.5691, 0.5814, 0.6023, 0.5937, 0.6036, 0.5751, 0.5896, 0.6007, 0.5784,
        0.5860, 0.5676, 0.5978, 0.5723, 0.5792, 0.5798, 0.5728],
       device='cuda:0') torch.Size([16])
percent tensor([0.5850, 0.5886, 0.5799, 0.5737, 0.5875, 0.5870, 0.5944, 0.5842, 0.5795,
        0.5843, 0.5877, 0.5916, 0.5841, 0.5787, 0.5932, 0.5848],
       device='cuda:0') torch.Size([16])
percent tensor([0.6043, 0.6099, 0.5753, 0.5565, 0.5582, 0.5862, 0.5955, 0.5619, 0.5851,
        0.6079, 0.6025, 0.5925, 0.6244, 0.5953, 0.5998, 0.6084],
       device='cuda:0') torch.Size([16])
percent tensor([0.6395, 0.6333, 0.6052, 0.6144, 0.6230, 0.6553, 0.6427, 0.6188, 0.6284,
        0.6299, 0.6377, 0.6226, 0.6273, 0.6358, 0.6466, 0.6412],
       device='cuda:0') torch.Size([16])
percent tensor([0.5304, 0.4958, 0.5767, 0.6233, 0.6208, 0.5679, 0.5457, 0.6134, 0.5849,
        0.5189, 0.5421, 0.5507, 0.4402, 0.5978, 0.5673, 0.5476],
       device='cuda:0') torch.Size([16])
percent tensor([0.5158, 0.6755, 0.6629, 0.6284, 0.6601, 0.7157, 0.6301, 0.5674, 0.6710,
        0.6038, 0.6763, 0.6662, 0.6549, 0.6922, 0.5273, 0.5064],
       device='cuda:0') torch.Size([16])
percent tensor([0.6596, 0.7116, 0.7130, 0.6235, 0.6548, 0.7093, 0.6895, 0.5878, 0.6631,
        0.6767, 0.6962, 0.6052, 0.7128, 0.6998, 0.5424, 0.5891],
       device='cuda:0') torch.Size([16])
percent tensor([0.9997, 0.9997, 0.9998, 0.9997, 0.9997, 0.9993, 0.9999, 0.9999, 0.9998,
        0.9999, 0.9999, 0.9996, 0.9997, 0.9998, 0.9996, 0.9995],
       device='cuda:0') torch.Size([16])
Epoch: 152 | Batch_idx: 0 |  Loss: (0.1005) |  Loss2: (0.0000) | Acc: (96.00%) (124/128)
Epoch: 152 | Batch_idx: 10 |  Loss: (0.1296) |  Loss2: (0.0000) | Acc: (95.00%) (1342/1408)
Epoch: 152 | Batch_idx: 20 |  Loss: (0.1187) |  Loss2: (0.0000) | Acc: (95.00%) (2577/2688)
Epoch: 152 | Batch_idx: 30 |  Loss: (0.1185) |  Loss2: (0.0000) | Acc: (96.00%) (3812/3968)
Epoch: 152 | Batch_idx: 40 |  Loss: (0.1208) |  Loss2: (0.0000) | Acc: (96.00%) (5039/5248)
Epoch: 152 | Batch_idx: 50 |  Loss: (0.1178) |  Loss2: (0.0000) | Acc: (96.00%) (6275/6528)
Epoch: 152 | Batch_idx: 60 |  Loss: (0.1198) |  Loss2: (0.0000) | Acc: (96.00%) (7504/7808)
Epoch: 152 | Batch_idx: 70 |  Loss: (0.1205) |  Loss2: (0.0000) | Acc: (96.00%) (8729/9088)
Epoch: 152 | Batch_idx: 80 |  Loss: (0.1208) |  Loss2: (0.0000) | Acc: (95.00%) (9948/10368)
Epoch: 152 | Batch_idx: 90 |  Loss: (0.1210) |  Loss2: (0.0000) | Acc: (95.00%) (11173/11648)
Epoch: 152 | Batch_idx: 100 |  Loss: (0.1221) |  Loss2: (0.0000) | Acc: (95.00%) (12395/12928)
Epoch: 152 | Batch_idx: 110 |  Loss: (0.1222) |  Loss2: (0.0000) | Acc: (95.00%) (13621/14208)
Epoch: 152 | Batch_idx: 120 |  Loss: (0.1209) |  Loss2: (0.0000) | Acc: (95.00%) (14851/15488)
Epoch: 152 | Batch_idx: 130 |  Loss: (0.1221) |  Loss2: (0.0000) | Acc: (95.00%) (16068/16768)
Epoch: 152 | Batch_idx: 140 |  Loss: (0.1224) |  Loss2: (0.0000) | Acc: (95.00%) (17296/18048)
Epoch: 152 | Batch_idx: 150 |  Loss: (0.1216) |  Loss2: (0.0000) | Acc: (95.00%) (18528/19328)
Epoch: 152 | Batch_idx: 160 |  Loss: (0.1219) |  Loss2: (0.0000) | Acc: (95.00%) (19751/20608)
Epoch: 152 | Batch_idx: 170 |  Loss: (0.1216) |  Loss2: (0.0000) | Acc: (95.00%) (20979/21888)
Epoch: 152 | Batch_idx: 180 |  Loss: (0.1222) |  Loss2: (0.0000) | Acc: (95.00%) (22205/23168)
Epoch: 152 | Batch_idx: 190 |  Loss: (0.1221) |  Loss2: (0.0000) | Acc: (95.00%) (23432/24448)
Epoch: 152 | Batch_idx: 200 |  Loss: (0.1217) |  Loss2: (0.0000) | Acc: (95.00%) (24663/25728)
Epoch: 152 | Batch_idx: 210 |  Loss: (0.1207) |  Loss2: (0.0000) | Acc: (95.00%) (25898/27008)
Epoch: 152 | Batch_idx: 220 |  Loss: (0.1204) |  Loss2: (0.0000) | Acc: (95.00%) (27130/28288)
Epoch: 152 | Batch_idx: 230 |  Loss: (0.1205) |  Loss2: (0.0000) | Acc: (95.00%) (28356/29568)
Epoch: 152 | Batch_idx: 240 |  Loss: (0.1206) |  Loss2: (0.0000) | Acc: (95.00%) (29582/30848)
Epoch: 152 | Batch_idx: 250 |  Loss: (0.1203) |  Loss2: (0.0000) | Acc: (95.00%) (30816/32128)
Epoch: 152 | Batch_idx: 260 |  Loss: (0.1198) |  Loss2: (0.0000) | Acc: (95.00%) (32052/33408)
Epoch: 152 | Batch_idx: 270 |  Loss: (0.1198) |  Loss2: (0.0000) | Acc: (95.00%) (33280/34688)
Epoch: 152 | Batch_idx: 280 |  Loss: (0.1204) |  Loss2: (0.0000) | Acc: (95.00%) (34507/35968)
Epoch: 152 | Batch_idx: 290 |  Loss: (0.1208) |  Loss2: (0.0000) | Acc: (95.00%) (35726/37248)
Epoch: 152 | Batch_idx: 300 |  Loss: (0.1210) |  Loss2: (0.0000) | Acc: (95.00%) (36951/38528)
Epoch: 152 | Batch_idx: 310 |  Loss: (0.1207) |  Loss2: (0.0000) | Acc: (95.00%) (38190/39808)
Epoch: 152 | Batch_idx: 320 |  Loss: (0.1206) |  Loss2: (0.0000) | Acc: (95.00%) (39423/41088)
Epoch: 152 | Batch_idx: 330 |  Loss: (0.1204) |  Loss2: (0.0000) | Acc: (95.00%) (40655/42368)
Epoch: 152 | Batch_idx: 340 |  Loss: (0.1201) |  Loss2: (0.0000) | Acc: (95.00%) (41886/43648)
Epoch: 152 | Batch_idx: 350 |  Loss: (0.1200) |  Loss2: (0.0000) | Acc: (95.00%) (43112/44928)
Epoch: 152 | Batch_idx: 360 |  Loss: (0.1197) |  Loss2: (0.0000) | Acc: (95.00%) (44349/46208)
Epoch: 152 | Batch_idx: 370 |  Loss: (0.1198) |  Loss2: (0.0000) | Acc: (95.00%) (45579/47488)
Epoch: 152 | Batch_idx: 380 |  Loss: (0.1198) |  Loss2: (0.0000) | Acc: (95.00%) (46808/48768)
Epoch: 152 | Batch_idx: 390 |  Loss: (0.1195) |  Loss2: (0.0000) | Acc: (95.00%) (47999/50000)
# TEST : Loss: (0.3907) | Acc: (88.00%) (8866/10000)
percent tensor([0.5687, 0.5805, 0.6013, 0.5929, 0.6025, 0.5745, 0.5887, 0.6001, 0.5778,
        0.5852, 0.5671, 0.5967, 0.5718, 0.5787, 0.5790, 0.5724],
       device='cuda:0') torch.Size([16])
percent tensor([0.5850, 0.5887, 0.5807, 0.5742, 0.5878, 0.5865, 0.5945, 0.5844, 0.5795,
        0.5848, 0.5878, 0.5920, 0.5841, 0.5787, 0.5929, 0.5850],
       device='cuda:0') torch.Size([16])
percent tensor([0.6037, 0.6098, 0.5744, 0.5567, 0.5574, 0.5860, 0.5950, 0.5615, 0.5847,
        0.6080, 0.6026, 0.5918, 0.6241, 0.5958, 0.5993, 0.6083],
       device='cuda:0') torch.Size([16])
percent tensor([0.6393, 0.6332, 0.6047, 0.6144, 0.6224, 0.6553, 0.6425, 0.6183, 0.6280,
        0.6297, 0.6377, 0.6222, 0.6269, 0.6360, 0.6467, 0.6410],
       device='cuda:0') torch.Size([16])
percent tensor([0.5226, 0.4886, 0.5696, 0.6190, 0.6146, 0.5611, 0.5366, 0.6095, 0.5746,
        0.5087, 0.5308, 0.5426, 0.4321, 0.5875, 0.5615, 0.5412],
       device='cuda:0') torch.Size([16])
percent tensor([0.5224, 0.6819, 0.6648, 0.6315, 0.6619, 0.7197, 0.6369, 0.5681, 0.6758,
        0.6138, 0.6845, 0.6718, 0.6625, 0.6999, 0.5311, 0.5107],
       device='cuda:0') torch.Size([16])
percent tensor([0.6641, 0.7181, 0.7190, 0.6292, 0.6563, 0.7162, 0.6922, 0.5873, 0.6685,
        0.6827, 0.7027, 0.6098, 0.7186, 0.7056, 0.5408, 0.5900],
       device='cuda:0') torch.Size([16])
percent tensor([0.9997, 0.9997, 0.9998, 0.9997, 0.9997, 0.9993, 0.9999, 0.9999, 0.9998,
        0.9999, 0.9999, 0.9996, 0.9997, 0.9998, 0.9997, 0.9995],
       device='cuda:0') torch.Size([16])
Epoch: 153 | Batch_idx: 0 |  Loss: (0.0848) |  Loss2: (0.0000) | Acc: (98.00%) (126/128)
Epoch: 153 | Batch_idx: 10 |  Loss: (0.1086) |  Loss2: (0.0000) | Acc: (96.00%) (1353/1408)
Epoch: 153 | Batch_idx: 20 |  Loss: (0.1085) |  Loss2: (0.0000) | Acc: (96.00%) (2586/2688)
Epoch: 153 | Batch_idx: 30 |  Loss: (0.1104) |  Loss2: (0.0000) | Acc: (96.00%) (3815/3968)
Epoch: 153 | Batch_idx: 40 |  Loss: (0.1071) |  Loss2: (0.0000) | Acc: (96.00%) (5049/5248)
Epoch: 153 | Batch_idx: 50 |  Loss: (0.1126) |  Loss2: (0.0000) | Acc: (96.00%) (6270/6528)
Epoch: 153 | Batch_idx: 60 |  Loss: (0.1130) |  Loss2: (0.0000) | Acc: (96.00%) (7500/7808)
Epoch: 153 | Batch_idx: 70 |  Loss: (0.1144) |  Loss2: (0.0000) | Acc: (96.00%) (8727/9088)
Epoch: 153 | Batch_idx: 80 |  Loss: (0.1161) |  Loss2: (0.0000) | Acc: (95.00%) (9953/10368)
Epoch: 153 | Batch_idx: 90 |  Loss: (0.1164) |  Loss2: (0.0000) | Acc: (96.00%) (11184/11648)
Epoch: 153 | Batch_idx: 100 |  Loss: (0.1178) |  Loss2: (0.0000) | Acc: (95.00%) (12400/12928)
Epoch: 153 | Batch_idx: 110 |  Loss: (0.1170) |  Loss2: (0.0000) | Acc: (95.00%) (13629/14208)
Epoch: 153 | Batch_idx: 120 |  Loss: (0.1164) |  Loss2: (0.0000) | Acc: (95.00%) (14867/15488)
Epoch: 153 | Batch_idx: 130 |  Loss: (0.1178) |  Loss2: (0.0000) | Acc: (95.00%) (16094/16768)
Epoch: 153 | Batch_idx: 140 |  Loss: (0.1168) |  Loss2: (0.0000) | Acc: (96.00%) (17330/18048)
Epoch: 153 | Batch_idx: 150 |  Loss: (0.1168) |  Loss2: (0.0000) | Acc: (96.00%) (18561/19328)
Epoch: 153 | Batch_idx: 160 |  Loss: (0.1168) |  Loss2: (0.0000) | Acc: (96.00%) (19791/20608)
Epoch: 153 | Batch_idx: 170 |  Loss: (0.1170) |  Loss2: (0.0000) | Acc: (96.00%) (21020/21888)
Epoch: 153 | Batch_idx: 180 |  Loss: (0.1194) |  Loss2: (0.0000) | Acc: (95.00%) (22236/23168)
Epoch: 153 | Batch_idx: 190 |  Loss: (0.1191) |  Loss2: (0.0000) | Acc: (95.00%) (23468/24448)
Epoch: 153 | Batch_idx: 200 |  Loss: (0.1201) |  Loss2: (0.0000) | Acc: (95.00%) (24681/25728)
Epoch: 153 | Batch_idx: 210 |  Loss: (0.1203) |  Loss2: (0.0000) | Acc: (95.00%) (25913/27008)
Epoch: 153 | Batch_idx: 220 |  Loss: (0.1202) |  Loss2: (0.0000) | Acc: (95.00%) (27139/28288)
Epoch: 153 | Batch_idx: 230 |  Loss: (0.1197) |  Loss2: (0.0000) | Acc: (95.00%) (28374/29568)
Epoch: 153 | Batch_idx: 240 |  Loss: (0.1196) |  Loss2: (0.0000) | Acc: (95.00%) (29603/30848)
Epoch: 153 | Batch_idx: 250 |  Loss: (0.1199) |  Loss2: (0.0000) | Acc: (95.00%) (30830/32128)
Epoch: 153 | Batch_idx: 260 |  Loss: (0.1195) |  Loss2: (0.0000) | Acc: (95.00%) (32063/33408)
Epoch: 153 | Batch_idx: 270 |  Loss: (0.1194) |  Loss2: (0.0000) | Acc: (95.00%) (33291/34688)
Epoch: 153 | Batch_idx: 280 |  Loss: (0.1199) |  Loss2: (0.0000) | Acc: (95.00%) (34514/35968)
Epoch: 153 | Batch_idx: 290 |  Loss: (0.1199) |  Loss2: (0.0000) | Acc: (95.00%) (35742/37248)
Epoch: 153 | Batch_idx: 300 |  Loss: (0.1198) |  Loss2: (0.0000) | Acc: (95.00%) (36974/38528)
Epoch: 153 | Batch_idx: 310 |  Loss: (0.1198) |  Loss2: (0.0000) | Acc: (95.00%) (38197/39808)
Epoch: 153 | Batch_idx: 320 |  Loss: (0.1204) |  Loss2: (0.0000) | Acc: (95.00%) (39419/41088)
Epoch: 153 | Batch_idx: 330 |  Loss: (0.1197) |  Loss2: (0.0000) | Acc: (95.00%) (40662/42368)
Epoch: 153 | Batch_idx: 340 |  Loss: (0.1191) |  Loss2: (0.0000) | Acc: (95.00%) (41894/43648)
Epoch: 153 | Batch_idx: 350 |  Loss: (0.1188) |  Loss2: (0.0000) | Acc: (96.00%) (43132/44928)
Epoch: 153 | Batch_idx: 360 |  Loss: (0.1184) |  Loss2: (0.0000) | Acc: (96.00%) (44367/46208)
Epoch: 153 | Batch_idx: 370 |  Loss: (0.1181) |  Loss2: (0.0000) | Acc: (96.00%) (45605/47488)
Epoch: 153 | Batch_idx: 380 |  Loss: (0.1183) |  Loss2: (0.0000) | Acc: (96.00%) (46835/48768)
Epoch: 153 | Batch_idx: 390 |  Loss: (0.1185) |  Loss2: (0.0000) | Acc: (96.00%) (48022/50000)
# TEST : Loss: (0.3859) | Acc: (88.00%) (8869/10000)
percent tensor([0.5685, 0.5796, 0.6009, 0.5925, 0.6019, 0.5740, 0.5879, 0.5996, 0.5775,
        0.5846, 0.5666, 0.5960, 0.5714, 0.5785, 0.5782, 0.5721],
       device='cuda:0') torch.Size([16])
percent tensor([0.5874, 0.5913, 0.5836, 0.5766, 0.5904, 0.5885, 0.5971, 0.5870, 0.5821,
        0.5876, 0.5905, 0.5948, 0.5865, 0.5811, 0.5952, 0.5874],
       device='cuda:0') torch.Size([16])
percent tensor([0.6050, 0.6111, 0.5750, 0.5585, 0.5585, 0.5883, 0.5959, 0.5622, 0.5866,
        0.6094, 0.6049, 0.5926, 0.6257, 0.5979, 0.6007, 0.6101],
       device='cuda:0') torch.Size([16])
percent tensor([0.6393, 0.6330, 0.6048, 0.6144, 0.6224, 0.6558, 0.6423, 0.6178, 0.6280,
        0.6294, 0.6378, 0.6217, 0.6264, 0.6359, 0.6465, 0.6411],
       device='cuda:0') torch.Size([16])
percent tensor([0.5327, 0.4986, 0.5756, 0.6234, 0.6213, 0.5680, 0.5469, 0.6167, 0.5826,
        0.5176, 0.5399, 0.5519, 0.4431, 0.5929, 0.5735, 0.5505],
       device='cuda:0') torch.Size([16])
percent tensor([0.5265, 0.6837, 0.6693, 0.6367, 0.6658, 0.7231, 0.6382, 0.5696, 0.6813,
        0.6185, 0.6906, 0.6744, 0.6685, 0.7071, 0.5288, 0.5131],
       device='cuda:0') torch.Size([16])
percent tensor([0.6618, 0.7159, 0.7184, 0.6270, 0.6528, 0.7140, 0.6874, 0.5824, 0.6690,
        0.6820, 0.7028, 0.6090, 0.7179, 0.7050, 0.5346, 0.5852],
       device='cuda:0') torch.Size([16])
percent tensor([0.9997, 0.9997, 0.9998, 0.9997, 0.9997, 0.9993, 0.9999, 0.9999, 0.9998,
        0.9999, 0.9999, 0.9996, 0.9997, 0.9997, 0.9996, 0.9995],
       device='cuda:0') torch.Size([16])
True Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=128, out_features=16, bias=False)
False Linear(in_features=16, out_features=2, bias=False)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=128, out_features=16, bias=False)
False Linear(in_features=16, out_features=2, bias=False)
True Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=256, out_features=32, bias=False)
False Linear(in_features=32, out_features=2, bias=False)
True Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=256, out_features=32, bias=False)
False Linear(in_features=32, out_features=2, bias=False)
True Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=512, out_features=64, bias=False)
False Linear(in_features=64, out_features=2, bias=False)
True Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=512, out_features=64, bias=False)
False Linear(in_features=64, out_features=2, bias=False)
True Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1024, out_features=128, bias=False)
False Linear(in_features=128, out_features=2, bias=False)
True Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1024, out_features=128, bias=False)
False Linear(in_features=128, out_features=2, bias=False)
True Linear(in_features=512, out_features=10, bias=True)
Epoch: 154 | Batch_idx: 0 |  Loss: (0.0785) |  Loss2: (0.0000) | Acc: (97.00%) (125/128)
Epoch: 154 | Batch_idx: 10 |  Loss: (0.1112) |  Loss2: (0.0000) | Acc: (96.00%) (1364/1408)
Epoch: 154 | Batch_idx: 20 |  Loss: (0.1172) |  Loss2: (0.0000) | Acc: (96.00%) (2592/2688)
Epoch: 154 | Batch_idx: 30 |  Loss: (0.1216) |  Loss2: (0.0000) | Acc: (96.00%) (3822/3968)
Epoch: 154 | Batch_idx: 40 |  Loss: (0.1226) |  Loss2: (0.0000) | Acc: (96.00%) (5043/5248)
Epoch: 154 | Batch_idx: 50 |  Loss: (0.1234) |  Loss2: (0.0000) | Acc: (96.00%) (6271/6528)
Epoch: 154 | Batch_idx: 60 |  Loss: (0.1259) |  Loss2: (0.0000) | Acc: (95.00%) (7482/7808)
Epoch: 154 | Batch_idx: 70 |  Loss: (0.1236) |  Loss2: (0.0000) | Acc: (95.00%) (8712/9088)
Epoch: 154 | Batch_idx: 80 |  Loss: (0.1240) |  Loss2: (0.0000) | Acc: (95.00%) (9937/10368)
Epoch: 154 | Batch_idx: 90 |  Loss: (0.1235) |  Loss2: (0.0000) | Acc: (95.00%) (11161/11648)
Epoch: 154 | Batch_idx: 100 |  Loss: (0.1244) |  Loss2: (0.0000) | Acc: (95.00%) (12385/12928)
Epoch: 154 | Batch_idx: 110 |  Loss: (0.1240) |  Loss2: (0.0000) | Acc: (95.00%) (13614/14208)
Epoch: 154 | Batch_idx: 120 |  Loss: (0.1252) |  Loss2: (0.0000) | Acc: (95.00%) (14823/15488)
Epoch: 154 | Batch_idx: 130 |  Loss: (0.1270) |  Loss2: (0.0000) | Acc: (95.00%) (16037/16768)
Epoch: 154 | Batch_idx: 140 |  Loss: (0.1269) |  Loss2: (0.0000) | Acc: (95.00%) (17258/18048)
Epoch: 154 | Batch_idx: 150 |  Loss: (0.1268) |  Loss2: (0.0000) | Acc: (95.00%) (18485/19328)
Epoch: 154 | Batch_idx: 160 |  Loss: (0.1281) |  Loss2: (0.0000) | Acc: (95.00%) (19706/20608)
Epoch: 154 | Batch_idx: 170 |  Loss: (0.1288) |  Loss2: (0.0000) | Acc: (95.00%) (20920/21888)
Epoch: 154 | Batch_idx: 180 |  Loss: (0.1285) |  Loss2: (0.0000) | Acc: (95.00%) (22147/23168)
Epoch: 154 | Batch_idx: 190 |  Loss: (0.1283) |  Loss2: (0.0000) | Acc: (95.00%) (23377/24448)
Epoch: 154 | Batch_idx: 200 |  Loss: (0.1292) |  Loss2: (0.0000) | Acc: (95.00%) (24593/25728)
Epoch: 154 | Batch_idx: 210 |  Loss: (0.1292) |  Loss2: (0.0000) | Acc: (95.00%) (25810/27008)
Epoch: 154 | Batch_idx: 220 |  Loss: (0.1289) |  Loss2: (0.0000) | Acc: (95.00%) (27032/28288)
Epoch: 154 | Batch_idx: 230 |  Loss: (0.1293) |  Loss2: (0.0000) | Acc: (95.00%) (28248/29568)
Epoch: 154 | Batch_idx: 240 |  Loss: (0.1294) |  Loss2: (0.0000) | Acc: (95.00%) (29465/30848)
Epoch: 154 | Batch_idx: 250 |  Loss: (0.1296) |  Loss2: (0.0000) | Acc: (95.00%) (30685/32128)
Epoch: 154 | Batch_idx: 260 |  Loss: (0.1302) |  Loss2: (0.0000) | Acc: (95.00%) (31897/33408)
Epoch: 154 | Batch_idx: 270 |  Loss: (0.1297) |  Loss2: (0.0000) | Acc: (95.00%) (33128/34688)
Epoch: 154 | Batch_idx: 280 |  Loss: (0.1294) |  Loss2: (0.0000) | Acc: (95.00%) (34355/35968)
Epoch: 154 | Batch_idx: 290 |  Loss: (0.1298) |  Loss2: (0.0000) | Acc: (95.00%) (35564/37248)
Epoch: 154 | Batch_idx: 300 |  Loss: (0.1301) |  Loss2: (0.0000) | Acc: (95.00%) (36782/38528)
Epoch: 154 | Batch_idx: 310 |  Loss: (0.1303) |  Loss2: (0.0000) | Acc: (95.00%) (38002/39808)
Epoch: 154 | Batch_idx: 320 |  Loss: (0.1296) |  Loss2: (0.0000) | Acc: (95.00%) (39234/41088)
Epoch: 154 | Batch_idx: 330 |  Loss: (0.1294) |  Loss2: (0.0000) | Acc: (95.00%) (40462/42368)
Epoch: 154 | Batch_idx: 340 |  Loss: (0.1293) |  Loss2: (0.0000) | Acc: (95.00%) (41686/43648)
Epoch: 154 | Batch_idx: 350 |  Loss: (0.1294) |  Loss2: (0.0000) | Acc: (95.00%) (42908/44928)
Epoch: 154 | Batch_idx: 360 |  Loss: (0.1296) |  Loss2: (0.0000) | Acc: (95.00%) (44136/46208)
Epoch: 154 | Batch_idx: 370 |  Loss: (0.1301) |  Loss2: (0.0000) | Acc: (95.00%) (45349/47488)
Epoch: 154 | Batch_idx: 380 |  Loss: (0.1304) |  Loss2: (0.0000) | Acc: (95.00%) (46570/48768)
Epoch: 154 | Batch_idx: 390 |  Loss: (0.1306) |  Loss2: (0.0000) | Acc: (95.00%) (47749/50000)
# TEST : Loss: (0.4604) | Acc: (86.00%) (8688/10000)
percent tensor([0.5703, 0.5803, 0.6051, 0.5936, 0.6052, 0.5746, 0.5893, 0.6008, 0.5791,
        0.5860, 0.5684, 0.5988, 0.5720, 0.5782, 0.5793, 0.5731],
       device='cuda:0') torch.Size([16])
percent tensor([0.5880, 0.5909, 0.5843, 0.5774, 0.5900, 0.5898, 0.5960, 0.5864, 0.5828,
        0.5883, 0.5907, 0.5935, 0.5860, 0.5818, 0.5955, 0.5885],
       device='cuda:0') torch.Size([16])
percent tensor([0.6044, 0.6106, 0.5734, 0.5568, 0.5567, 0.5867, 0.5978, 0.5642, 0.5911,
        0.6087, 0.6072, 0.5891, 0.6244, 0.5986, 0.5989, 0.6107],
       device='cuda:0') torch.Size([16])
percent tensor([0.6405, 0.6280, 0.6084, 0.6212, 0.6261, 0.6622, 0.6415, 0.6174, 0.6262,
        0.6278, 0.6357, 0.6217, 0.6243, 0.6342, 0.6483, 0.6423],
       device='cuda:0') torch.Size([16])
percent tensor([0.5346, 0.5022, 0.5824, 0.6079, 0.6281, 0.5635, 0.5578, 0.6120, 0.5634,
        0.5272, 0.5437, 0.5575, 0.4452, 0.6106, 0.5752, 0.5465],
       device='cuda:0') torch.Size([16])
percent tensor([0.5304, 0.6755, 0.6594, 0.6452, 0.6593, 0.6985, 0.6436, 0.5671, 0.6877,
        0.6064, 0.6999, 0.6593, 0.6798, 0.7012, 0.5083, 0.5228],
       device='cuda:0') torch.Size([16])
percent tensor([0.6623, 0.7141, 0.7119, 0.6422, 0.6381, 0.6988, 0.6795, 0.5990, 0.6690,
        0.6596, 0.7068, 0.6093, 0.7203, 0.7012, 0.5367, 0.5822],
       device='cuda:0') torch.Size([16])
percent tensor([0.9998, 0.9997, 0.9999, 0.9998, 0.9998, 0.9996, 0.9998, 0.9999, 0.9997,
        0.9998, 0.9998, 0.9996, 0.9995, 0.9998, 0.9998, 0.9995],
       device='cuda:0') torch.Size([16])
Epoch: 155 | Batch_idx: 0 |  Loss: (0.1820) |  Loss2: (0.0000) | Acc: (92.00%) (118/128)
Epoch: 155 | Batch_idx: 10 |  Loss: (0.1407) |  Loss2: (0.0000) | Acc: (95.00%) (1341/1408)
Epoch: 155 | Batch_idx: 20 |  Loss: (0.1406) |  Loss2: (0.0000) | Acc: (95.00%) (2562/2688)
Epoch: 155 | Batch_idx: 30 |  Loss: (0.1310) |  Loss2: (0.0000) | Acc: (95.00%) (3795/3968)
Epoch: 155 | Batch_idx: 40 |  Loss: (0.1233) |  Loss2: (0.0000) | Acc: (95.00%) (5034/5248)
Epoch: 155 | Batch_idx: 50 |  Loss: (0.1217) |  Loss2: (0.0000) | Acc: (95.00%) (6261/6528)
Epoch: 155 | Batch_idx: 60 |  Loss: (0.1188) |  Loss2: (0.0000) | Acc: (95.00%) (7493/7808)
Epoch: 155 | Batch_idx: 70 |  Loss: (0.1156) |  Loss2: (0.0000) | Acc: (96.00%) (8728/9088)
Epoch: 155 | Batch_idx: 80 |  Loss: (0.1134) |  Loss2: (0.0000) | Acc: (96.00%) (9966/10368)
Epoch: 155 | Batch_idx: 90 |  Loss: (0.1154) |  Loss2: (0.0000) | Acc: (96.00%) (11187/11648)
Epoch: 155 | Batch_idx: 100 |  Loss: (0.1166) |  Loss2: (0.0000) | Acc: (95.00%) (12410/12928)
Epoch: 155 | Batch_idx: 110 |  Loss: (0.1176) |  Loss2: (0.0000) | Acc: (95.00%) (13631/14208)
Epoch: 155 | Batch_idx: 120 |  Loss: (0.1175) |  Loss2: (0.0000) | Acc: (95.00%) (14860/15488)
Epoch: 155 | Batch_idx: 130 |  Loss: (0.1194) |  Loss2: (0.0000) | Acc: (95.00%) (16079/16768)
Epoch: 155 | Batch_idx: 140 |  Loss: (0.1211) |  Loss2: (0.0000) | Acc: (95.00%) (17287/18048)
Epoch: 155 | Batch_idx: 150 |  Loss: (0.1211) |  Loss2: (0.0000) | Acc: (95.00%) (18512/19328)
Epoch: 155 | Batch_idx: 160 |  Loss: (0.1216) |  Loss2: (0.0000) | Acc: (95.00%) (19728/20608)
Epoch: 155 | Batch_idx: 170 |  Loss: (0.1214) |  Loss2: (0.0000) | Acc: (95.00%) (20958/21888)
Epoch: 155 | Batch_idx: 180 |  Loss: (0.1219) |  Loss2: (0.0000) | Acc: (95.00%) (22181/23168)
Epoch: 155 | Batch_idx: 190 |  Loss: (0.1220) |  Loss2: (0.0000) | Acc: (95.00%) (23409/24448)
Epoch: 155 | Batch_idx: 200 |  Loss: (0.1227) |  Loss2: (0.0000) | Acc: (95.00%) (24631/25728)
Epoch: 155 | Batch_idx: 210 |  Loss: (0.1233) |  Loss2: (0.0000) | Acc: (95.00%) (25847/27008)
Epoch: 155 | Batch_idx: 220 |  Loss: (0.1233) |  Loss2: (0.0000) | Acc: (95.00%) (27071/28288)
Epoch: 155 | Batch_idx: 230 |  Loss: (0.1239) |  Loss2: (0.0000) | Acc: (95.00%) (28281/29568)
Epoch: 155 | Batch_idx: 240 |  Loss: (0.1237) |  Loss2: (0.0000) | Acc: (95.00%) (29505/30848)
Epoch: 155 | Batch_idx: 250 |  Loss: (0.1236) |  Loss2: (0.0000) | Acc: (95.00%) (30734/32128)
Epoch: 155 | Batch_idx: 260 |  Loss: (0.1235) |  Loss2: (0.0000) | Acc: (95.00%) (31963/33408)
Epoch: 155 | Batch_idx: 270 |  Loss: (0.1232) |  Loss2: (0.0000) | Acc: (95.00%) (33191/34688)
Epoch: 155 | Batch_idx: 280 |  Loss: (0.1235) |  Loss2: (0.0000) | Acc: (95.00%) (34415/35968)
Epoch: 155 | Batch_idx: 290 |  Loss: (0.1241) |  Loss2: (0.0000) | Acc: (95.00%) (35634/37248)
Epoch: 155 | Batch_idx: 300 |  Loss: (0.1241) |  Loss2: (0.0000) | Acc: (95.00%) (36854/38528)
Epoch: 155 | Batch_idx: 310 |  Loss: (0.1240) |  Loss2: (0.0000) | Acc: (95.00%) (38073/39808)
Epoch: 155 | Batch_idx: 320 |  Loss: (0.1240) |  Loss2: (0.0000) | Acc: (95.00%) (39297/41088)
Epoch: 155 | Batch_idx: 330 |  Loss: (0.1242) |  Loss2: (0.0000) | Acc: (95.00%) (40523/42368)
Epoch: 155 | Batch_idx: 340 |  Loss: (0.1246) |  Loss2: (0.0000) | Acc: (95.00%) (41748/43648)
Epoch: 155 | Batch_idx: 350 |  Loss: (0.1244) |  Loss2: (0.0000) | Acc: (95.00%) (42979/44928)
Epoch: 155 | Batch_idx: 360 |  Loss: (0.1243) |  Loss2: (0.0000) | Acc: (95.00%) (44207/46208)
Epoch: 155 | Batch_idx: 370 |  Loss: (0.1250) |  Loss2: (0.0000) | Acc: (95.00%) (45421/47488)
Epoch: 155 | Batch_idx: 380 |  Loss: (0.1251) |  Loss2: (0.0000) | Acc: (95.00%) (46636/48768)
Epoch: 155 | Batch_idx: 390 |  Loss: (0.1254) |  Loss2: (0.0000) | Acc: (95.00%) (47819/50000)
=> saving checkpoint 'drive/app/torch/save_Schedule/checkpoint_155.pth.tar'
# TEST : Loss: (0.4309) | Acc: (87.00%) (8744/10000)
percent tensor([0.5690, 0.5777, 0.6055, 0.5930, 0.6059, 0.5748, 0.5885, 0.5994, 0.5773,
        0.5849, 0.5668, 0.5993, 0.5709, 0.5738, 0.5784, 0.5716],
       device='cuda:0') torch.Size([16])
percent tensor([0.5877, 0.5923, 0.5825, 0.5768, 0.5898, 0.5881, 0.5964, 0.5876, 0.5821,
        0.5886, 0.5907, 0.5927, 0.5862, 0.5839, 0.5958, 0.5885],
       device='cuda:0') torch.Size([16])
percent tensor([0.6039, 0.6112, 0.5699, 0.5552, 0.5535, 0.5847, 0.5943, 0.5605, 0.5910,
        0.6089, 0.6079, 0.5882, 0.6249, 0.5996, 0.5994, 0.6083],
       device='cuda:0') torch.Size([16])
percent tensor([0.6407, 0.6349, 0.6040, 0.6148, 0.6214, 0.6561, 0.6445, 0.6185, 0.6281,
        0.6330, 0.6377, 0.6213, 0.6293, 0.6415, 0.6488, 0.6443],
       device='cuda:0') torch.Size([16])
percent tensor([0.5319, 0.4899, 0.5804, 0.6192, 0.6303, 0.5638, 0.5539, 0.6258, 0.5633,
        0.5070, 0.5250, 0.5374, 0.4370, 0.6023, 0.5710, 0.5536],
       device='cuda:0') torch.Size([16])
percent tensor([0.5364, 0.6970, 0.6601, 0.6455, 0.6417, 0.7212, 0.6496, 0.5626, 0.6925,
        0.6372, 0.7142, 0.6791, 0.6870, 0.7000, 0.5392, 0.5507],
       device='cuda:0') torch.Size([16])
percent tensor([0.6436, 0.7148, 0.6991, 0.6532, 0.6356, 0.7237, 0.6775, 0.5795, 0.6736,
        0.6705, 0.7055, 0.6319, 0.7171, 0.7009, 0.5376, 0.5894],
       device='cuda:0') torch.Size([16])
percent tensor([0.9995, 0.9996, 0.9997, 0.9998, 0.9998, 0.9997, 0.9997, 0.9999, 0.9998,
        0.9998, 0.9999, 0.9994, 0.9996, 0.9997, 0.9997, 0.9992],
       device='cuda:0') torch.Size([16])
Epoch: 156 | Batch_idx: 0 |  Loss: (0.1214) |  Loss2: (0.0000) | Acc: (96.00%) (123/128)
Epoch: 156 | Batch_idx: 10 |  Loss: (0.1173) |  Loss2: (0.0000) | Acc: (96.00%) (1355/1408)
Epoch: 156 | Batch_idx: 20 |  Loss: (0.1295) |  Loss2: (0.0000) | Acc: (95.00%) (2570/2688)
Epoch: 156 | Batch_idx: 30 |  Loss: (0.1276) |  Loss2: (0.0000) | Acc: (95.00%) (3789/3968)
Epoch: 156 | Batch_idx: 40 |  Loss: (0.1273) |  Loss2: (0.0000) | Acc: (95.00%) (5008/5248)
Epoch: 156 | Batch_idx: 50 |  Loss: (0.1265) |  Loss2: (0.0000) | Acc: (95.00%) (6230/6528)
Epoch: 156 | Batch_idx: 60 |  Loss: (0.1254) |  Loss2: (0.0000) | Acc: (95.00%) (7455/7808)
Epoch: 156 | Batch_idx: 70 |  Loss: (0.1263) |  Loss2: (0.0000) | Acc: (95.00%) (8684/9088)
Epoch: 156 | Batch_idx: 80 |  Loss: (0.1239) |  Loss2: (0.0000) | Acc: (95.00%) (9915/10368)
Epoch: 156 | Batch_idx: 90 |  Loss: (0.1235) |  Loss2: (0.0000) | Acc: (95.00%) (11142/11648)
Epoch: 156 | Batch_idx: 100 |  Loss: (0.1232) |  Loss2: (0.0000) | Acc: (95.00%) (12366/12928)
Epoch: 156 | Batch_idx: 110 |  Loss: (0.1240) |  Loss2: (0.0000) | Acc: (95.00%) (13590/14208)
Epoch: 156 | Batch_idx: 120 |  Loss: (0.1227) |  Loss2: (0.0000) | Acc: (95.00%) (14831/15488)
Epoch: 156 | Batch_idx: 130 |  Loss: (0.1237) |  Loss2: (0.0000) | Acc: (95.00%) (16055/16768)
Epoch: 156 | Batch_idx: 140 |  Loss: (0.1234) |  Loss2: (0.0000) | Acc: (95.00%) (17285/18048)
Epoch: 156 | Batch_idx: 150 |  Loss: (0.1240) |  Loss2: (0.0000) | Acc: (95.00%) (18507/19328)
Epoch: 156 | Batch_idx: 160 |  Loss: (0.1253) |  Loss2: (0.0000) | Acc: (95.00%) (19726/20608)
Epoch: 156 | Batch_idx: 170 |  Loss: (0.1251) |  Loss2: (0.0000) | Acc: (95.00%) (20950/21888)
Epoch: 156 | Batch_idx: 180 |  Loss: (0.1248) |  Loss2: (0.0000) | Acc: (95.00%) (22177/23168)
Epoch: 156 | Batch_idx: 190 |  Loss: (0.1242) |  Loss2: (0.0000) | Acc: (95.00%) (23402/24448)
Epoch: 156 | Batch_idx: 200 |  Loss: (0.1247) |  Loss2: (0.0000) | Acc: (95.00%) (24620/25728)
Epoch: 156 | Batch_idx: 210 |  Loss: (0.1249) |  Loss2: (0.0000) | Acc: (95.00%) (25850/27008)
Epoch: 156 | Batch_idx: 220 |  Loss: (0.1252) |  Loss2: (0.0000) | Acc: (95.00%) (27063/28288)
Epoch: 156 | Batch_idx: 230 |  Loss: (0.1244) |  Loss2: (0.0000) | Acc: (95.00%) (28298/29568)
Epoch: 156 | Batch_idx: 240 |  Loss: (0.1244) |  Loss2: (0.0000) | Acc: (95.00%) (29520/30848)
Epoch: 156 | Batch_idx: 250 |  Loss: (0.1252) |  Loss2: (0.0000) | Acc: (95.00%) (30739/32128)
Epoch: 156 | Batch_idx: 260 |  Loss: (0.1248) |  Loss2: (0.0000) | Acc: (95.00%) (31970/33408)
Epoch: 156 | Batch_idx: 270 |  Loss: (0.1250) |  Loss2: (0.0000) | Acc: (95.00%) (33202/34688)
Epoch: 156 | Batch_idx: 280 |  Loss: (0.1247) |  Loss2: (0.0000) | Acc: (95.00%) (34435/35968)
Epoch: 156 | Batch_idx: 290 |  Loss: (0.1244) |  Loss2: (0.0000) | Acc: (95.00%) (35667/37248)
Epoch: 156 | Batch_idx: 300 |  Loss: (0.1246) |  Loss2: (0.0000) | Acc: (95.00%) (36896/38528)
Epoch: 156 | Batch_idx: 310 |  Loss: (0.1241) |  Loss2: (0.0000) | Acc: (95.00%) (38130/39808)
Epoch: 156 | Batch_idx: 320 |  Loss: (0.1243) |  Loss2: (0.0000) | Acc: (95.00%) (39357/41088)
Epoch: 156 | Batch_idx: 330 |  Loss: (0.1243) |  Loss2: (0.0000) | Acc: (95.00%) (40580/42368)
Epoch: 156 | Batch_idx: 340 |  Loss: (0.1244) |  Loss2: (0.0000) | Acc: (95.00%) (41804/43648)
Epoch: 156 | Batch_idx: 350 |  Loss: (0.1243) |  Loss2: (0.0000) | Acc: (95.00%) (43024/44928)
Epoch: 156 | Batch_idx: 360 |  Loss: (0.1240) |  Loss2: (0.0000) | Acc: (95.00%) (44258/46208)
Epoch: 156 | Batch_idx: 370 |  Loss: (0.1240) |  Loss2: (0.0000) | Acc: (95.00%) (45484/47488)
Epoch: 156 | Batch_idx: 380 |  Loss: (0.1241) |  Loss2: (0.0000) | Acc: (95.00%) (46710/48768)
Epoch: 156 | Batch_idx: 390 |  Loss: (0.1236) |  Loss2: (0.0000) | Acc: (95.00%) (47900/50000)
# TEST : Loss: (0.4300) | Acc: (87.00%) (8739/10000)
percent tensor([0.5678, 0.5781, 0.6005, 0.5921, 0.6024, 0.5736, 0.5870, 0.5974, 0.5772,
        0.5837, 0.5673, 0.5949, 0.5704, 0.5764, 0.5782, 0.5716],
       device='cuda:0') torch.Size([16])
percent tensor([0.5891, 0.5905, 0.5849, 0.5782, 0.5911, 0.5913, 0.5958, 0.5876, 0.5821,
        0.5878, 0.5915, 0.5941, 0.5870, 0.5802, 0.5960, 0.5889],
       device='cuda:0') torch.Size([16])
percent tensor([0.6069, 0.6129, 0.5648, 0.5554, 0.5506, 0.5890, 0.5950, 0.5580, 0.5900,
        0.6095, 0.6086, 0.5855, 0.6275, 0.6033, 0.6010, 0.6107],
       device='cuda:0') torch.Size([16])
percent tensor([0.6412, 0.6318, 0.6100, 0.6181, 0.6258, 0.6640, 0.6411, 0.6179, 0.6283,
        0.6329, 0.6383, 0.6236, 0.6298, 0.6379, 0.6481, 0.6447],
       device='cuda:0') torch.Size([16])
percent tensor([0.5392, 0.4968, 0.6037, 0.6229, 0.6295, 0.5739, 0.5609, 0.6242, 0.5655,
        0.5092, 0.5514, 0.5424, 0.4368, 0.6013, 0.5708, 0.5575],
       device='cuda:0') torch.Size([16])
percent tensor([0.5422, 0.6735, 0.6585, 0.6665, 0.6677, 0.7103, 0.6460, 0.5723, 0.6709,
        0.6362, 0.6981, 0.6578, 0.6715, 0.6900, 0.5115, 0.5315],
       device='cuda:0') torch.Size([16])
percent tensor([0.6590, 0.7064, 0.7026, 0.6543, 0.6594, 0.7172, 0.6948, 0.5997, 0.6496,
        0.6724, 0.7029, 0.6190, 0.7204, 0.6816, 0.5368, 0.5917],
       device='cuda:0') torch.Size([16])
percent tensor([0.9995, 0.9997, 0.9998, 0.9998, 0.9998, 0.9996, 0.9998, 0.9999, 0.9998,
        0.9998, 0.9999, 0.9996, 0.9997, 0.9998, 0.9997, 0.9992],
       device='cuda:0') torch.Size([16])
Epoch: 157 | Batch_idx: 0 |  Loss: (0.1632) |  Loss2: (0.0000) | Acc: (94.00%) (121/128)
Epoch: 157 | Batch_idx: 10 |  Loss: (0.1332) |  Loss2: (0.0000) | Acc: (95.00%) (1344/1408)
Epoch: 157 | Batch_idx: 20 |  Loss: (0.1234) |  Loss2: (0.0000) | Acc: (95.00%) (2574/2688)
Epoch: 157 | Batch_idx: 30 |  Loss: (0.1213) |  Loss2: (0.0000) | Acc: (95.00%) (3796/3968)
Epoch: 157 | Batch_idx: 40 |  Loss: (0.1206) |  Loss2: (0.0000) | Acc: (95.00%) (5027/5248)
Epoch: 157 | Batch_idx: 50 |  Loss: (0.1177) |  Loss2: (0.0000) | Acc: (96.00%) (6268/6528)
Epoch: 157 | Batch_idx: 60 |  Loss: (0.1176) |  Loss2: (0.0000) | Acc: (95.00%) (7493/7808)
Epoch: 157 | Batch_idx: 70 |  Loss: (0.1169) |  Loss2: (0.0000) | Acc: (96.00%) (8726/9088)
Epoch: 157 | Batch_idx: 80 |  Loss: (0.1161) |  Loss2: (0.0000) | Acc: (96.00%) (9956/10368)
Epoch: 157 | Batch_idx: 90 |  Loss: (0.1156) |  Loss2: (0.0000) | Acc: (96.00%) (11188/11648)
Epoch: 157 | Batch_idx: 100 |  Loss: (0.1144) |  Loss2: (0.0000) | Acc: (96.00%) (12421/12928)
Epoch: 157 | Batch_idx: 110 |  Loss: (0.1142) |  Loss2: (0.0000) | Acc: (96.00%) (13654/14208)
Epoch: 157 | Batch_idx: 120 |  Loss: (0.1138) |  Loss2: (0.0000) | Acc: (96.00%) (14889/15488)
Epoch: 157 | Batch_idx: 130 |  Loss: (0.1125) |  Loss2: (0.0000) | Acc: (96.00%) (16126/16768)
Epoch: 157 | Batch_idx: 140 |  Loss: (0.1127) |  Loss2: (0.0000) | Acc: (96.00%) (17355/18048)
Epoch: 157 | Batch_idx: 150 |  Loss: (0.1133) |  Loss2: (0.0000) | Acc: (96.00%) (18580/19328)
Epoch: 157 | Batch_idx: 160 |  Loss: (0.1137) |  Loss2: (0.0000) | Acc: (96.00%) (19809/20608)
Epoch: 157 | Batch_idx: 170 |  Loss: (0.1139) |  Loss2: (0.0000) | Acc: (96.00%) (21040/21888)
Epoch: 157 | Batch_idx: 180 |  Loss: (0.1140) |  Loss2: (0.0000) | Acc: (96.00%) (22262/23168)
Epoch: 157 | Batch_idx: 190 |  Loss: (0.1142) |  Loss2: (0.0000) | Acc: (96.00%) (23492/24448)
Epoch: 157 | Batch_idx: 200 |  Loss: (0.1146) |  Loss2: (0.0000) | Acc: (96.00%) (24718/25728)
Epoch: 157 | Batch_idx: 210 |  Loss: (0.1141) |  Loss2: (0.0000) | Acc: (96.00%) (25959/27008)
Epoch: 157 | Batch_idx: 220 |  Loss: (0.1138) |  Loss2: (0.0000) | Acc: (96.00%) (27193/28288)
Epoch: 157 | Batch_idx: 230 |  Loss: (0.1148) |  Loss2: (0.0000) | Acc: (96.00%) (28418/29568)
Epoch: 157 | Batch_idx: 240 |  Loss: (0.1147) |  Loss2: (0.0000) | Acc: (96.00%) (29648/30848)
Epoch: 157 | Batch_idx: 250 |  Loss: (0.1147) |  Loss2: (0.0000) | Acc: (96.00%) (30879/32128)
Epoch: 157 | Batch_idx: 260 |  Loss: (0.1149) |  Loss2: (0.0000) | Acc: (96.00%) (32104/33408)
Epoch: 157 | Batch_idx: 270 |  Loss: (0.1155) |  Loss2: (0.0000) | Acc: (96.00%) (33325/34688)
Epoch: 157 | Batch_idx: 280 |  Loss: (0.1154) |  Loss2: (0.0000) | Acc: (96.00%) (34553/35968)
Epoch: 157 | Batch_idx: 290 |  Loss: (0.1156) |  Loss2: (0.0000) | Acc: (96.00%) (35784/37248)
Epoch: 157 | Batch_idx: 300 |  Loss: (0.1154) |  Loss2: (0.0000) | Acc: (96.00%) (37018/38528)
Epoch: 157 | Batch_idx: 310 |  Loss: (0.1152) |  Loss2: (0.0000) | Acc: (96.00%) (38249/39808)
Epoch: 157 | Batch_idx: 320 |  Loss: (0.1160) |  Loss2: (0.0000) | Acc: (96.00%) (39469/41088)
Epoch: 157 | Batch_idx: 330 |  Loss: (0.1158) |  Loss2: (0.0000) | Acc: (96.00%) (40704/42368)
Epoch: 157 | Batch_idx: 340 |  Loss: (0.1165) |  Loss2: (0.0000) | Acc: (96.00%) (41918/43648)
Epoch: 157 | Batch_idx: 350 |  Loss: (0.1168) |  Loss2: (0.0000) | Acc: (96.00%) (43142/44928)
Epoch: 157 | Batch_idx: 360 |  Loss: (0.1171) |  Loss2: (0.0000) | Acc: (96.00%) (44364/46208)
Epoch: 157 | Batch_idx: 370 |  Loss: (0.1174) |  Loss2: (0.0000) | Acc: (95.00%) (45587/47488)
Epoch: 157 | Batch_idx: 380 |  Loss: (0.1181) |  Loss2: (0.0000) | Acc: (95.00%) (46814/48768)
Epoch: 157 | Batch_idx: 390 |  Loss: (0.1185) |  Loss2: (0.0000) | Acc: (95.00%) (47989/50000)
# TEST : Loss: (0.4442) | Acc: (87.00%) (8747/10000)
percent tensor([0.5688, 0.5799, 0.6030, 0.5920, 0.6042, 0.5749, 0.5892, 0.5987, 0.5784,
        0.5848, 0.5679, 0.5968, 0.5706, 0.5788, 0.5789, 0.5723],
       device='cuda:0') torch.Size([16])
percent tensor([0.5884, 0.5920, 0.5831, 0.5777, 0.5902, 0.5912, 0.5973, 0.5867, 0.5824,
        0.5885, 0.5907, 0.5940, 0.5862, 0.5837, 0.5969, 0.5895],
       device='cuda:0') torch.Size([16])
percent tensor([0.6020, 0.6108, 0.5693, 0.5540, 0.5510, 0.5817, 0.5948, 0.5587, 0.5877,
        0.6087, 0.6050, 0.5872, 0.6225, 0.6017, 0.5964, 0.6073],
       device='cuda:0') torch.Size([16])
percent tensor([0.6419, 0.6323, 0.6109, 0.6192, 0.6255, 0.6595, 0.6428, 0.6183, 0.6270,
        0.6315, 0.6361, 0.6217, 0.6281, 0.6375, 0.6496, 0.6455],
       device='cuda:0') torch.Size([16])
percent tensor([0.5351, 0.4889, 0.5825, 0.6238, 0.6330, 0.5791, 0.5582, 0.6209, 0.5720,
        0.5011, 0.5350, 0.5289, 0.4478, 0.5934, 0.5794, 0.5518],
       device='cuda:0') torch.Size([16])
percent tensor([0.5202, 0.6647, 0.6628, 0.6332, 0.6749, 0.7016, 0.6489, 0.5575, 0.6551,
        0.6303, 0.6858, 0.6648, 0.6662, 0.7035, 0.4955, 0.4969],
       device='cuda:0') torch.Size([16])
percent tensor([0.6528, 0.6885, 0.7023, 0.6391, 0.6598, 0.7110, 0.7038, 0.5876, 0.6577,
        0.6673, 0.6984, 0.6156, 0.7033, 0.6870, 0.5233, 0.5758],
       device='cuda:0') torch.Size([16])
percent tensor([0.9997, 0.9997, 0.9998, 0.9997, 0.9998, 0.9995, 0.9999, 0.9999, 0.9999,
        0.9999, 0.9998, 0.9995, 0.9994, 0.9998, 0.9998, 0.9995],
       device='cuda:0') torch.Size([16])
Epoch: 158 | Batch_idx: 0 |  Loss: (0.1276) |  Loss2: (0.0000) | Acc: (93.00%) (120/128)
Epoch: 158 | Batch_idx: 10 |  Loss: (0.1374) |  Loss2: (0.0000) | Acc: (95.00%) (1343/1408)
Epoch: 158 | Batch_idx: 20 |  Loss: (0.1356) |  Loss2: (0.0000) | Acc: (95.00%) (2566/2688)
Epoch: 158 | Batch_idx: 30 |  Loss: (0.1266) |  Loss2: (0.0000) | Acc: (95.00%) (3802/3968)
Epoch: 158 | Batch_idx: 40 |  Loss: (0.1266) |  Loss2: (0.0000) | Acc: (95.00%) (5028/5248)
Epoch: 158 | Batch_idx: 50 |  Loss: (0.1216) |  Loss2: (0.0000) | Acc: (95.00%) (6264/6528)
Epoch: 158 | Batch_idx: 60 |  Loss: (0.1196) |  Loss2: (0.0000) | Acc: (95.00%) (7494/7808)
Epoch: 158 | Batch_idx: 70 |  Loss: (0.1173) |  Loss2: (0.0000) | Acc: (96.00%) (8731/9088)
Epoch: 158 | Batch_idx: 80 |  Loss: (0.1171) |  Loss2: (0.0000) | Acc: (96.00%) (9964/10368)
Epoch: 158 | Batch_idx: 90 |  Loss: (0.1173) |  Loss2: (0.0000) | Acc: (96.00%) (11191/11648)
Epoch: 158 | Batch_idx: 100 |  Loss: (0.1178) |  Loss2: (0.0000) | Acc: (96.00%) (12421/12928)
Epoch: 158 | Batch_idx: 110 |  Loss: (0.1161) |  Loss2: (0.0000) | Acc: (96.00%) (13661/14208)
Epoch: 158 | Batch_idx: 120 |  Loss: (0.1166) |  Loss2: (0.0000) | Acc: (96.00%) (14881/15488)
Epoch: 158 | Batch_idx: 130 |  Loss: (0.1164) |  Loss2: (0.0000) | Acc: (96.00%) (16111/16768)
Epoch: 158 | Batch_idx: 140 |  Loss: (0.1176) |  Loss2: (0.0000) | Acc: (95.00%) (17324/18048)
Epoch: 158 | Batch_idx: 150 |  Loss: (0.1178) |  Loss2: (0.0000) | Acc: (95.00%) (18551/19328)
Epoch: 158 | Batch_idx: 160 |  Loss: (0.1175) |  Loss2: (0.0000) | Acc: (96.00%) (19785/20608)
Epoch: 158 | Batch_idx: 170 |  Loss: (0.1180) |  Loss2: (0.0000) | Acc: (95.00%) (21009/21888)
Epoch: 158 | Batch_idx: 180 |  Loss: (0.1174) |  Loss2: (0.0000) | Acc: (96.00%) (22244/23168)
Epoch: 158 | Batch_idx: 190 |  Loss: (0.1167) |  Loss2: (0.0000) | Acc: (96.00%) (23481/24448)
Epoch: 158 | Batch_idx: 200 |  Loss: (0.1180) |  Loss2: (0.0000) | Acc: (95.00%) (24697/25728)
Epoch: 158 | Batch_idx: 210 |  Loss: (0.1172) |  Loss2: (0.0000) | Acc: (96.00%) (25936/27008)
Epoch: 158 | Batch_idx: 220 |  Loss: (0.1177) |  Loss2: (0.0000) | Acc: (95.00%) (27155/28288)
Epoch: 158 | Batch_idx: 230 |  Loss: (0.1173) |  Loss2: (0.0000) | Acc: (95.00%) (28384/29568)
Epoch: 158 | Batch_idx: 240 |  Loss: (0.1177) |  Loss2: (0.0000) | Acc: (95.00%) (29600/30848)
Epoch: 158 | Batch_idx: 250 |  Loss: (0.1185) |  Loss2: (0.0000) | Acc: (95.00%) (30816/32128)
Epoch: 158 | Batch_idx: 260 |  Loss: (0.1189) |  Loss2: (0.0000) | Acc: (95.00%) (32039/33408)
Epoch: 158 | Batch_idx: 270 |  Loss: (0.1191) |  Loss2: (0.0000) | Acc: (95.00%) (33254/34688)
Epoch: 158 | Batch_idx: 280 |  Loss: (0.1187) |  Loss2: (0.0000) | Acc: (95.00%) (34486/35968)
Epoch: 158 | Batch_idx: 290 |  Loss: (0.1183) |  Loss2: (0.0000) | Acc: (95.00%) (35718/37248)
Epoch: 158 | Batch_idx: 300 |  Loss: (0.1183) |  Loss2: (0.0000) | Acc: (95.00%) (36946/38528)
Epoch: 158 | Batch_idx: 310 |  Loss: (0.1178) |  Loss2: (0.0000) | Acc: (95.00%) (38186/39808)
Epoch: 158 | Batch_idx: 320 |  Loss: (0.1183) |  Loss2: (0.0000) | Acc: (95.00%) (39405/41088)
Epoch: 158 | Batch_idx: 330 |  Loss: (0.1180) |  Loss2: (0.0000) | Acc: (95.00%) (40638/42368)
Epoch: 158 | Batch_idx: 340 |  Loss: (0.1178) |  Loss2: (0.0000) | Acc: (95.00%) (41869/43648)
Epoch: 158 | Batch_idx: 350 |  Loss: (0.1178) |  Loss2: (0.0000) | Acc: (95.00%) (43098/44928)
Epoch: 158 | Batch_idx: 360 |  Loss: (0.1183) |  Loss2: (0.0000) | Acc: (95.00%) (44321/46208)
Epoch: 158 | Batch_idx: 370 |  Loss: (0.1184) |  Loss2: (0.0000) | Acc: (95.00%) (45538/47488)
Epoch: 158 | Batch_idx: 380 |  Loss: (0.1188) |  Loss2: (0.0000) | Acc: (95.00%) (46761/48768)
Epoch: 158 | Batch_idx: 390 |  Loss: (0.1188) |  Loss2: (0.0000) | Acc: (95.00%) (47938/50000)
# TEST : Loss: (0.3964) | Acc: (88.00%) (8825/10000)
percent tensor([0.5675, 0.5783, 0.6029, 0.5928, 0.6031, 0.5739, 0.5876, 0.5983, 0.5763,
        0.5839, 0.5659, 0.5962, 0.5693, 0.5766, 0.5781, 0.5711],
       device='cuda:0') torch.Size([16])
percent tensor([0.5874, 0.5899, 0.5833, 0.5750, 0.5899, 0.5892, 0.5961, 0.5865, 0.5827,
        0.5873, 0.5908, 0.5930, 0.5863, 0.5816, 0.5942, 0.5877],
       device='cuda:0') torch.Size([16])
percent tensor([0.6018, 0.6118, 0.5705, 0.5514, 0.5526, 0.5805, 0.5969, 0.5572, 0.5886,
        0.6098, 0.6047, 0.5881, 0.6236, 0.6021, 0.5954, 0.6069],
       device='cuda:0') torch.Size([16])
percent tensor([0.6426, 0.6304, 0.6080, 0.6137, 0.6273, 0.6584, 0.6435, 0.6185, 0.6284,
        0.6292, 0.6368, 0.6210, 0.6277, 0.6377, 0.6450, 0.6433],
       device='cuda:0') torch.Size([16])
percent tensor([0.5445, 0.4994, 0.6017, 0.6397, 0.6371, 0.5796, 0.5582, 0.6231, 0.5822,
        0.5106, 0.5592, 0.5512, 0.4509, 0.5928, 0.5787, 0.5596],
       device='cuda:0') torch.Size([16])
percent tensor([0.5523, 0.6861, 0.6796, 0.6434, 0.6748, 0.7239, 0.6609, 0.5768, 0.6916,
        0.6562, 0.7148, 0.6822, 0.6946, 0.7105, 0.5231, 0.5190],
       device='cuda:0') torch.Size([16])
percent tensor([0.6658, 0.7168, 0.7177, 0.6367, 0.6481, 0.7262, 0.7061, 0.6014, 0.6757,
        0.6977, 0.7081, 0.6321, 0.7244, 0.6976, 0.5408, 0.5920],
       device='cuda:0') torch.Size([16])
percent tensor([0.9997, 0.9998, 0.9998, 0.9997, 0.9998, 0.9994, 0.9999, 0.9999, 0.9998,
        0.9999, 0.9999, 0.9996, 0.9995, 0.9997, 0.9998, 0.9995],
       device='cuda:0') torch.Size([16])
Epoch: 159 | Batch_idx: 0 |  Loss: (0.0993) |  Loss2: (0.0000) | Acc: (96.00%) (124/128)
Epoch: 159 | Batch_idx: 10 |  Loss: (0.1312) |  Loss2: (0.0000) | Acc: (95.00%) (1341/1408)
Epoch: 159 | Batch_idx: 20 |  Loss: (0.1163) |  Loss2: (0.0000) | Acc: (96.00%) (2581/2688)
Epoch: 159 | Batch_idx: 30 |  Loss: (0.1122) |  Loss2: (0.0000) | Acc: (96.00%) (3818/3968)
Epoch: 159 | Batch_idx: 40 |  Loss: (0.1115) |  Loss2: (0.0000) | Acc: (96.00%) (5046/5248)
Epoch: 159 | Batch_idx: 50 |  Loss: (0.1111) |  Loss2: (0.0000) | Acc: (96.00%) (6273/6528)
Epoch: 159 | Batch_idx: 60 |  Loss: (0.1084) |  Loss2: (0.0000) | Acc: (96.00%) (7510/7808)
Epoch: 159 | Batch_idx: 70 |  Loss: (0.1098) |  Loss2: (0.0000) | Acc: (96.00%) (8744/9088)
Epoch: 159 | Batch_idx: 80 |  Loss: (0.1089) |  Loss2: (0.0000) | Acc: (96.00%) (9976/10368)
Epoch: 159 | Batch_idx: 90 |  Loss: (0.1094) |  Loss2: (0.0000) | Acc: (96.00%) (11208/11648)
Epoch: 159 | Batch_idx: 100 |  Loss: (0.1088) |  Loss2: (0.0000) | Acc: (96.00%) (12446/12928)
Epoch: 159 | Batch_idx: 110 |  Loss: (0.1087) |  Loss2: (0.0000) | Acc: (96.00%) (13681/14208)
Epoch: 159 | Batch_idx: 120 |  Loss: (0.1077) |  Loss2: (0.0000) | Acc: (96.00%) (14921/15488)
Epoch: 159 | Batch_idx: 130 |  Loss: (0.1076) |  Loss2: (0.0000) | Acc: (96.00%) (16149/16768)
Epoch: 159 | Batch_idx: 140 |  Loss: (0.1065) |  Loss2: (0.0000) | Acc: (96.00%) (17391/18048)
Epoch: 159 | Batch_idx: 150 |  Loss: (0.1064) |  Loss2: (0.0000) | Acc: (96.00%) (18627/19328)
Epoch: 159 | Batch_idx: 160 |  Loss: (0.1078) |  Loss2: (0.0000) | Acc: (96.00%) (19847/20608)
Epoch: 159 | Batch_idx: 170 |  Loss: (0.1082) |  Loss2: (0.0000) | Acc: (96.00%) (21067/21888)
Epoch: 159 | Batch_idx: 180 |  Loss: (0.1081) |  Loss2: (0.0000) | Acc: (96.00%) (22298/23168)
Epoch: 159 | Batch_idx: 190 |  Loss: (0.1081) |  Loss2: (0.0000) | Acc: (96.00%) (23540/24448)
Epoch: 159 | Batch_idx: 200 |  Loss: (0.1086) |  Loss2: (0.0000) | Acc: (96.00%) (24774/25728)
Epoch: 159 | Batch_idx: 210 |  Loss: (0.1088) |  Loss2: (0.0000) | Acc: (96.00%) (26002/27008)
Epoch: 159 | Batch_idx: 220 |  Loss: (0.1086) |  Loss2: (0.0000) | Acc: (96.00%) (27237/28288)
Epoch: 159 | Batch_idx: 230 |  Loss: (0.1098) |  Loss2: (0.0000) | Acc: (96.00%) (28459/29568)
Epoch: 159 | Batch_idx: 240 |  Loss: (0.1103) |  Loss2: (0.0000) | Acc: (96.00%) (29683/30848)
Epoch: 159 | Batch_idx: 250 |  Loss: (0.1102) |  Loss2: (0.0000) | Acc: (96.00%) (30908/32128)
Epoch: 159 | Batch_idx: 260 |  Loss: (0.1102) |  Loss2: (0.0000) | Acc: (96.00%) (32147/33408)
Epoch: 159 | Batch_idx: 270 |  Loss: (0.1101) |  Loss2: (0.0000) | Acc: (96.00%) (33373/34688)
Epoch: 159 | Batch_idx: 280 |  Loss: (0.1108) |  Loss2: (0.0000) | Acc: (96.00%) (34589/35968)
Epoch: 159 | Batch_idx: 290 |  Loss: (0.1105) |  Loss2: (0.0000) | Acc: (96.00%) (35824/37248)
Epoch: 159 | Batch_idx: 300 |  Loss: (0.1102) |  Loss2: (0.0000) | Acc: (96.00%) (37061/38528)
Epoch: 159 | Batch_idx: 310 |  Loss: (0.1103) |  Loss2: (0.0000) | Acc: (96.00%) (38293/39808)
Epoch: 159 | Batch_idx: 320 |  Loss: (0.1102) |  Loss2: (0.0000) | Acc: (96.00%) (39518/41088)
Epoch: 159 | Batch_idx: 330 |  Loss: (0.1100) |  Loss2: (0.0000) | Acc: (96.00%) (40746/42368)
Epoch: 159 | Batch_idx: 340 |  Loss: (0.1105) |  Loss2: (0.0000) | Acc: (96.00%) (41968/43648)
Epoch: 159 | Batch_idx: 350 |  Loss: (0.1109) |  Loss2: (0.0000) | Acc: (96.00%) (43187/44928)
Epoch: 159 | Batch_idx: 360 |  Loss: (0.1112) |  Loss2: (0.0000) | Acc: (96.00%) (44414/46208)
Epoch: 159 | Batch_idx: 370 |  Loss: (0.1114) |  Loss2: (0.0000) | Acc: (96.00%) (45647/47488)
Epoch: 159 | Batch_idx: 380 |  Loss: (0.1117) |  Loss2: (0.0000) | Acc: (96.00%) (46872/48768)
Epoch: 159 | Batch_idx: 390 |  Loss: (0.1119) |  Loss2: (0.0000) | Acc: (96.00%) (48048/50000)
# TEST : Loss: (0.4198) | Acc: (88.00%) (8828/10000)
percent tensor([0.5685, 0.5766, 0.6070, 0.5938, 0.6070, 0.5739, 0.5880, 0.5991, 0.5777,
        0.5844, 0.5658, 0.5999, 0.5701, 0.5729, 0.5776, 0.5709],
       device='cuda:0') torch.Size([16])
percent tensor([0.5873, 0.5919, 0.5828, 0.5776, 0.5890, 0.5898, 0.5965, 0.5874, 0.5813,
        0.5881, 0.5897, 0.5928, 0.5862, 0.5825, 0.5961, 0.5879],
       device='cuda:0') torch.Size([16])
percent tensor([0.6049, 0.6107, 0.5691, 0.5568, 0.5542, 0.5861, 0.5968, 0.5584, 0.5892,
        0.6112, 0.6060, 0.5878, 0.6261, 0.5993, 0.5997, 0.6081],
       device='cuda:0') torch.Size([16])
percent tensor([0.6397, 0.6317, 0.6066, 0.6168, 0.6228, 0.6596, 0.6421, 0.6181, 0.6265,
        0.6300, 0.6364, 0.6210, 0.6288, 0.6385, 0.6480, 0.6429],
       device='cuda:0') torch.Size([16])
percent tensor([0.5315, 0.4956, 0.5924, 0.6238, 0.6304, 0.5697, 0.5552, 0.6192, 0.5829,
        0.5043, 0.5435, 0.5559, 0.4491, 0.5904, 0.5701, 0.5495],
       device='cuda:0') torch.Size([16])
percent tensor([0.5493, 0.6793, 0.6642, 0.6585, 0.6520, 0.7168, 0.6378, 0.5773, 0.6691,
        0.6400, 0.7049, 0.6468, 0.6811, 0.6955, 0.5215, 0.5308],
       device='cuda:0') torch.Size([16])
percent tensor([0.6672, 0.7106, 0.7078, 0.6389, 0.6539, 0.7095, 0.6965, 0.6090, 0.6647,
        0.6841, 0.6950, 0.5912, 0.7106, 0.6938, 0.5320, 0.5959],
       device='cuda:0') torch.Size([16])
percent tensor([0.9997, 0.9997, 0.9997, 0.9995, 0.9998, 0.9995, 0.9999, 0.9999, 0.9999,
        0.9998, 0.9999, 0.9997, 0.9996, 0.9998, 0.9997, 0.9994],
       device='cuda:0') torch.Size([16])
Epoch: 160 | Batch_idx: 0 |  Loss: (0.0787) |  Loss2: (0.0000) | Acc: (98.00%) (126/128)
Epoch: 160 | Batch_idx: 10 |  Loss: (0.0915) |  Loss2: (0.0000) | Acc: (97.00%) (1368/1408)
Epoch: 160 | Batch_idx: 20 |  Loss: (0.1043) |  Loss2: (0.0000) | Acc: (96.00%) (2593/2688)
Epoch: 160 | Batch_idx: 30 |  Loss: (0.1052) |  Loss2: (0.0000) | Acc: (96.00%) (3834/3968)
Epoch: 160 | Batch_idx: 40 |  Loss: (0.1116) |  Loss2: (0.0000) | Acc: (96.00%) (5054/5248)
Epoch: 160 | Batch_idx: 50 |  Loss: (0.1091) |  Loss2: (0.0000) | Acc: (96.00%) (6297/6528)
Epoch: 160 | Batch_idx: 60 |  Loss: (0.1043) |  Loss2: (0.0000) | Acc: (96.00%) (7547/7808)
Epoch: 160 | Batch_idx: 70 |  Loss: (0.1038) |  Loss2: (0.0000) | Acc: (96.00%) (8786/9088)
Epoch: 160 | Batch_idx: 80 |  Loss: (0.1037) |  Loss2: (0.0000) | Acc: (96.00%) (10024/10368)
Epoch: 160 | Batch_idx: 90 |  Loss: (0.1014) |  Loss2: (0.0000) | Acc: (96.00%) (11273/11648)
Epoch: 160 | Batch_idx: 100 |  Loss: (0.1013) |  Loss2: (0.0000) | Acc: (96.00%) (12516/12928)
Epoch: 160 | Batch_idx: 110 |  Loss: (0.1009) |  Loss2: (0.0000) | Acc: (96.00%) (13763/14208)
Epoch: 160 | Batch_idx: 120 |  Loss: (0.1011) |  Loss2: (0.0000) | Acc: (96.00%) (14996/15488)
Epoch: 160 | Batch_idx: 130 |  Loss: (0.1027) |  Loss2: (0.0000) | Acc: (96.00%) (16221/16768)
Epoch: 160 | Batch_idx: 140 |  Loss: (0.1039) |  Loss2: (0.0000) | Acc: (96.00%) (17446/18048)
Epoch: 160 | Batch_idx: 150 |  Loss: (0.1056) |  Loss2: (0.0000) | Acc: (96.00%) (18665/19328)
Epoch: 160 | Batch_idx: 160 |  Loss: (0.1060) |  Loss2: (0.0000) | Acc: (96.00%) (19895/20608)
Epoch: 160 | Batch_idx: 170 |  Loss: (0.1072) |  Loss2: (0.0000) | Acc: (96.00%) (21119/21888)
Epoch: 160 | Batch_idx: 180 |  Loss: (0.1072) |  Loss2: (0.0000) | Acc: (96.00%) (22349/23168)
Epoch: 160 | Batch_idx: 190 |  Loss: (0.1069) |  Loss2: (0.0000) | Acc: (96.00%) (23586/24448)
Epoch: 160 | Batch_idx: 200 |  Loss: (0.1070) |  Loss2: (0.0000) | Acc: (96.00%) (24813/25728)
Epoch: 160 | Batch_idx: 210 |  Loss: (0.1076) |  Loss2: (0.0000) | Acc: (96.00%) (26042/27008)
Epoch: 160 | Batch_idx: 220 |  Loss: (0.1082) |  Loss2: (0.0000) | Acc: (96.00%) (27271/28288)
Epoch: 160 | Batch_idx: 230 |  Loss: (0.1089) |  Loss2: (0.0000) | Acc: (96.00%) (28493/29568)
Epoch: 160 | Batch_idx: 240 |  Loss: (0.1093) |  Loss2: (0.0000) | Acc: (96.00%) (29721/30848)
Epoch: 160 | Batch_idx: 250 |  Loss: (0.1090) |  Loss2: (0.0000) | Acc: (96.00%) (30960/32128)
Epoch: 160 | Batch_idx: 260 |  Loss: (0.1091) |  Loss2: (0.0000) | Acc: (96.00%) (32191/33408)
Epoch: 160 | Batch_idx: 270 |  Loss: (0.1094) |  Loss2: (0.0000) | Acc: (96.00%) (33428/34688)
Epoch: 160 | Batch_idx: 280 |  Loss: (0.1093) |  Loss2: (0.0000) | Acc: (96.00%) (34653/35968)
Epoch: 160 | Batch_idx: 290 |  Loss: (0.1102) |  Loss2: (0.0000) | Acc: (96.00%) (35875/37248)
Epoch: 160 | Batch_idx: 300 |  Loss: (0.1104) |  Loss2: (0.0000) | Acc: (96.00%) (37103/38528)
Epoch: 160 | Batch_idx: 310 |  Loss: (0.1108) |  Loss2: (0.0000) | Acc: (96.00%) (38328/39808)
Epoch: 160 | Batch_idx: 320 |  Loss: (0.1112) |  Loss2: (0.0000) | Acc: (96.00%) (39544/41088)
Epoch: 160 | Batch_idx: 330 |  Loss: (0.1119) |  Loss2: (0.0000) | Acc: (96.00%) (40765/42368)
Epoch: 160 | Batch_idx: 340 |  Loss: (0.1121) |  Loss2: (0.0000) | Acc: (96.00%) (41990/43648)
Epoch: 160 | Batch_idx: 350 |  Loss: (0.1123) |  Loss2: (0.0000) | Acc: (96.00%) (43223/44928)
Epoch: 160 | Batch_idx: 360 |  Loss: (0.1122) |  Loss2: (0.0000) | Acc: (96.00%) (44454/46208)
Epoch: 160 | Batch_idx: 370 |  Loss: (0.1120) |  Loss2: (0.0000) | Acc: (96.00%) (45685/47488)
Epoch: 160 | Batch_idx: 380 |  Loss: (0.1122) |  Loss2: (0.0000) | Acc: (96.00%) (46915/48768)
Epoch: 160 | Batch_idx: 390 |  Loss: (0.1122) |  Loss2: (0.0000) | Acc: (96.00%) (48099/50000)
=> saving checkpoint 'drive/app/torch/save_Schedule/checkpoint_160.pth.tar'
# TEST : Loss: (0.4068) | Acc: (88.00%) (8817/10000)
percent tensor([0.5688, 0.5767, 0.6077, 0.5933, 0.6066, 0.5737, 0.5881, 0.5993, 0.5777,
        0.5848, 0.5666, 0.6006, 0.5707, 0.5735, 0.5773, 0.5712],
       device='cuda:0') torch.Size([16])
percent tensor([0.5883, 0.5911, 0.5835, 0.5767, 0.5897, 0.5893, 0.5964, 0.5874, 0.5829,
        0.5884, 0.5908, 0.5934, 0.5871, 0.5828, 0.5960, 0.5885],
       device='cuda:0') torch.Size([16])
percent tensor([0.6059, 0.6140, 0.5716, 0.5538, 0.5560, 0.5863, 0.5994, 0.5599, 0.5916,
        0.6121, 0.6080, 0.5883, 0.6286, 0.6002, 0.5993, 0.6098],
       device='cuda:0') torch.Size([16])
percent tensor([0.6425, 0.6320, 0.6107, 0.6157, 0.6262, 0.6552, 0.6451, 0.6202, 0.6279,
        0.6310, 0.6358, 0.6239, 0.6305, 0.6377, 0.6488, 0.6441],
       device='cuda:0') torch.Size([16])
percent tensor([0.5431, 0.4997, 0.6013, 0.6268, 0.6289, 0.5899, 0.5591, 0.6224, 0.5770,
        0.5168, 0.5472, 0.5462, 0.4419, 0.6025, 0.5844, 0.5611],
       device='cuda:0') torch.Size([16])
percent tensor([0.5370, 0.6763, 0.6653, 0.6522, 0.6485, 0.7100, 0.6592, 0.5777, 0.6720,
        0.6376, 0.7021, 0.6726, 0.6606, 0.7074, 0.5311, 0.5290],
       device='cuda:0') torch.Size([16])
percent tensor([0.6464, 0.6907, 0.6981, 0.6294, 0.6341, 0.7105, 0.7006, 0.6094, 0.6606,
        0.6716, 0.6953, 0.6064, 0.6900, 0.6865, 0.5372, 0.5912],
       device='cuda:0') torch.Size([16])
percent tensor([0.9996, 0.9997, 0.9998, 0.9996, 0.9998, 0.9994, 0.9999, 1.0000, 0.9998,
        0.9999, 0.9998, 0.9997, 0.9995, 0.9997, 0.9998, 0.9994],
       device='cuda:0') torch.Size([16])
False Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=128, out_features=16, bias=False)
True Linear(in_features=16, out_features=2, bias=False)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=128, out_features=16, bias=False)
True Linear(in_features=16, out_features=2, bias=False)
False Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=256, out_features=32, bias=False)
True Linear(in_features=32, out_features=2, bias=False)
False Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=256, out_features=32, bias=False)
True Linear(in_features=32, out_features=2, bias=False)
False Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=512, out_features=64, bias=False)
True Linear(in_features=64, out_features=2, bias=False)
False Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=512, out_features=64, bias=False)
True Linear(in_features=64, out_features=2, bias=False)
False Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1024, out_features=128, bias=False)
True Linear(in_features=128, out_features=2, bias=False)
False Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1024, out_features=128, bias=False)
True Linear(in_features=128, out_features=2, bias=False)
False Linear(in_features=512, out_features=10, bias=True)
Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 3, 3, 3]) tensor(189.7531, device='cuda:0')
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(823.5213, device='cuda:0')
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(844.0344, device='cuda:0')
Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([128, 64, 3, 3]) tensor(1527.5671, device='cuda:0')
Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([128, 64, 1, 1]) tensor(488.9222, device='cuda:0')
Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([128, 128, 3, 3]) tensor(2281.1580, device='cuda:0')
Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([256, 128, 3, 3]) tensor(4259.3647, device='cuda:0')
Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([256, 128, 1, 1]) tensor(1360.7377, device='cuda:0')
Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([256, 256, 3, 3]) tensor(6231.6440, device='cuda:0')
Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([512, 256, 3, 3]) tensor(11668.0938, device='cuda:0')
Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([512, 256, 1, 1]) tensor(3848.7991, device='cuda:0')
Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([512, 512, 3, 3]) tensor(16248.4746, device='cuda:0')
Epoch: 161 | Batch_idx: 0 |  Loss: (0.0988) |  Loss2: (0.0000) | Acc: (97.00%) (125/128)
Epoch: 161 | Batch_idx: 10 |  Loss: (0.1046) |  Loss2: (0.0000) | Acc: (97.00%) (1367/1408)
Epoch: 161 | Batch_idx: 20 |  Loss: (0.1089) |  Loss2: (0.0000) | Acc: (96.00%) (2602/2688)
Epoch: 161 | Batch_idx: 30 |  Loss: (0.1164) |  Loss2: (0.0000) | Acc: (96.00%) (3824/3968)
Epoch: 161 | Batch_idx: 40 |  Loss: (0.1159) |  Loss2: (0.0000) | Acc: (96.00%) (5057/5248)
Epoch: 161 | Batch_idx: 50 |  Loss: (0.1174) |  Loss2: (0.0000) | Acc: (96.00%) (6279/6528)
Epoch: 161 | Batch_idx: 60 |  Loss: (0.1175) |  Loss2: (0.0000) | Acc: (96.00%) (7507/7808)
Epoch: 161 | Batch_idx: 70 |  Loss: (0.1189) |  Loss2: (0.0000) | Acc: (96.00%) (8725/9088)
Epoch: 161 | Batch_idx: 80 |  Loss: (0.1188) |  Loss2: (0.0000) | Acc: (95.00%) (9951/10368)
Epoch: 161 | Batch_idx: 90 |  Loss: (0.1178) |  Loss2: (0.0000) | Acc: (96.00%) (11189/11648)
Epoch: 161 | Batch_idx: 100 |  Loss: (0.1163) |  Loss2: (0.0000) | Acc: (96.00%) (12418/12928)
Epoch: 161 | Batch_idx: 110 |  Loss: (0.1162) |  Loss2: (0.0000) | Acc: (96.00%) (13653/14208)
Epoch: 161 | Batch_idx: 120 |  Loss: (0.1161) |  Loss2: (0.0000) | Acc: (96.00%) (14882/15488)
Epoch: 161 | Batch_idx: 130 |  Loss: (0.1181) |  Loss2: (0.0000) | Acc: (95.00%) (16097/16768)
Epoch: 161 | Batch_idx: 140 |  Loss: (0.1191) |  Loss2: (0.0000) | Acc: (95.00%) (17320/18048)
Epoch: 161 | Batch_idx: 150 |  Loss: (0.1181) |  Loss2: (0.0000) | Acc: (96.00%) (18555/19328)
Epoch: 161 | Batch_idx: 160 |  Loss: (0.1178) |  Loss2: (0.0000) | Acc: (96.00%) (19785/20608)
Epoch: 161 | Batch_idx: 170 |  Loss: (0.1176) |  Loss2: (0.0000) | Acc: (95.00%) (21009/21888)
Epoch: 161 | Batch_idx: 180 |  Loss: (0.1187) |  Loss2: (0.0000) | Acc: (95.00%) (22229/23168)
Epoch: 161 | Batch_idx: 190 |  Loss: (0.1193) |  Loss2: (0.0000) | Acc: (95.00%) (23449/24448)
Epoch: 161 | Batch_idx: 200 |  Loss: (0.1194) |  Loss2: (0.0000) | Acc: (95.00%) (24673/25728)
Epoch: 161 | Batch_idx: 210 |  Loss: (0.1197) |  Loss2: (0.0000) | Acc: (95.00%) (25900/27008)
Epoch: 161 | Batch_idx: 220 |  Loss: (0.1197) |  Loss2: (0.0000) | Acc: (95.00%) (27125/28288)
Epoch: 161 | Batch_idx: 230 |  Loss: (0.1201) |  Loss2: (0.0000) | Acc: (95.00%) (28352/29568)
Epoch: 161 | Batch_idx: 240 |  Loss: (0.1208) |  Loss2: (0.0000) | Acc: (95.00%) (29562/30848)
Epoch: 161 | Batch_idx: 250 |  Loss: (0.1202) |  Loss2: (0.0000) | Acc: (95.00%) (30801/32128)
Epoch: 161 | Batch_idx: 260 |  Loss: (0.1197) |  Loss2: (0.0000) | Acc: (95.00%) (32042/33408)
Epoch: 161 | Batch_idx: 270 |  Loss: (0.1197) |  Loss2: (0.0000) | Acc: (95.00%) (33273/34688)
Epoch: 161 | Batch_idx: 280 |  Loss: (0.1185) |  Loss2: (0.0000) | Acc: (95.00%) (34517/35968)
Epoch: 161 | Batch_idx: 290 |  Loss: (0.1185) |  Loss2: (0.0000) | Acc: (95.00%) (35748/37248)
Epoch: 161 | Batch_idx: 300 |  Loss: (0.1184) |  Loss2: (0.0000) | Acc: (95.00%) (36977/38528)
Epoch: 161 | Batch_idx: 310 |  Loss: (0.1186) |  Loss2: (0.0000) | Acc: (95.00%) (38195/39808)
Epoch: 161 | Batch_idx: 320 |  Loss: (0.1185) |  Loss2: (0.0000) | Acc: (95.00%) (39429/41088)
Epoch: 161 | Batch_idx: 330 |  Loss: (0.1186) |  Loss2: (0.0000) | Acc: (95.00%) (40662/42368)
Epoch: 161 | Batch_idx: 340 |  Loss: (0.1182) |  Loss2: (0.0000) | Acc: (95.00%) (41900/43648)
Epoch: 161 | Batch_idx: 350 |  Loss: (0.1176) |  Loss2: (0.0000) | Acc: (96.00%) (43140/44928)
Epoch: 161 | Batch_idx: 360 |  Loss: (0.1179) |  Loss2: (0.0000) | Acc: (96.00%) (44363/46208)
Epoch: 161 | Batch_idx: 370 |  Loss: (0.1177) |  Loss2: (0.0000) | Acc: (96.00%) (45592/47488)
Epoch: 161 | Batch_idx: 380 |  Loss: (0.1173) |  Loss2: (0.0000) | Acc: (96.00%) (46828/48768)
Epoch: 161 | Batch_idx: 390 |  Loss: (0.1174) |  Loss2: (0.0000) | Acc: (96.00%) (48006/50000)
# TEST : Loss: (0.4143) | Acc: (88.00%) (8805/10000)
percent tensor([0.5669, 0.5751, 0.6090, 0.5938, 0.6076, 0.5722, 0.5875, 0.5997, 0.5766,
        0.5847, 0.5644, 0.6011, 0.5689, 0.5721, 0.5758, 0.5698],
       device='cuda:0') torch.Size([16])
percent tensor([0.5821, 0.5856, 0.5775, 0.5714, 0.5843, 0.5828, 0.5908, 0.5826, 0.5773,
        0.5828, 0.5845, 0.5873, 0.5809, 0.5778, 0.5899, 0.5824],
       device='cuda:0') torch.Size([16])
percent tensor([0.6111, 0.6207, 0.5704, 0.5546, 0.5562, 0.5874, 0.6052, 0.5641, 0.5979,
        0.6181, 0.6162, 0.5908, 0.6355, 0.6114, 0.6039, 0.6149],
       device='cuda:0') torch.Size([16])
percent tensor([0.6287, 0.6216, 0.5961, 0.6016, 0.6104, 0.6388, 0.6329, 0.6089, 0.6150,
        0.6194, 0.6240, 0.6122, 0.6192, 0.6270, 0.6355, 0.6297],
       device='cuda:0') torch.Size([16])
percent tensor([0.5418, 0.5059, 0.6063, 0.6396, 0.6243, 0.5794, 0.5613, 0.6198, 0.5823,
        0.5241, 0.5567, 0.5769, 0.4465, 0.6179, 0.5873, 0.5562],
       device='cuda:0') torch.Size([16])
percent tensor([0.5114, 0.6689, 0.6388, 0.6395, 0.6289, 0.6981, 0.6432, 0.5400, 0.6549,
        0.6288, 0.6951, 0.6612, 0.6382, 0.7044, 0.5120, 0.5046],
       device='cuda:0') torch.Size([16])
percent tensor([0.6703, 0.7135, 0.7046, 0.6322, 0.6375, 0.7213, 0.7106, 0.6149, 0.6803,
        0.6954, 0.7167, 0.6253, 0.7087, 0.7127, 0.5613, 0.6163],
       device='cuda:0') torch.Size([16])
percent tensor([0.9995, 0.9998, 0.9998, 0.9996, 0.9998, 0.9994, 0.9999, 0.9999, 0.9999,
        0.9999, 0.9999, 0.9997, 0.9996, 0.9998, 0.9997, 0.9993],
       device='cuda:0') torch.Size([16])
Epoch: 162 | Batch_idx: 0 |  Loss: (0.0636) |  Loss2: (0.0000) | Acc: (97.00%) (125/128)
Epoch: 162 | Batch_idx: 10 |  Loss: (0.1105) |  Loss2: (0.0000) | Acc: (96.00%) (1364/1408)
Epoch: 162 | Batch_idx: 20 |  Loss: (0.1175) |  Loss2: (0.0000) | Acc: (96.00%) (2594/2688)
Epoch: 162 | Batch_idx: 30 |  Loss: (0.1152) |  Loss2: (0.0000) | Acc: (96.00%) (3824/3968)
Epoch: 162 | Batch_idx: 40 |  Loss: (0.1251) |  Loss2: (0.0000) | Acc: (96.00%) (5042/5248)
Epoch: 162 | Batch_idx: 50 |  Loss: (0.1199) |  Loss2: (0.0000) | Acc: (96.00%) (6276/6528)
Epoch: 162 | Batch_idx: 60 |  Loss: (0.1183) |  Loss2: (0.0000) | Acc: (96.00%) (7507/7808)
Epoch: 162 | Batch_idx: 70 |  Loss: (0.1154) |  Loss2: (0.0000) | Acc: (96.00%) (8743/9088)
Epoch: 162 | Batch_idx: 80 |  Loss: (0.1179) |  Loss2: (0.0000) | Acc: (96.00%) (9968/10368)
Epoch: 162 | Batch_idx: 90 |  Loss: (0.1170) |  Loss2: (0.0000) | Acc: (96.00%) (11200/11648)
Epoch: 162 | Batch_idx: 100 |  Loss: (0.1156) |  Loss2: (0.0000) | Acc: (96.00%) (12437/12928)
Epoch: 162 | Batch_idx: 110 |  Loss: (0.1156) |  Loss2: (0.0000) | Acc: (96.00%) (13658/14208)
Epoch: 162 | Batch_idx: 120 |  Loss: (0.1161) |  Loss2: (0.0000) | Acc: (96.00%) (14885/15488)
Epoch: 162 | Batch_idx: 130 |  Loss: (0.1142) |  Loss2: (0.0000) | Acc: (96.00%) (16132/16768)
Epoch: 162 | Batch_idx: 140 |  Loss: (0.1142) |  Loss2: (0.0000) | Acc: (96.00%) (17361/18048)
Epoch: 162 | Batch_idx: 150 |  Loss: (0.1126) |  Loss2: (0.0000) | Acc: (96.00%) (18604/19328)
Epoch: 162 | Batch_idx: 160 |  Loss: (0.1123) |  Loss2: (0.0000) | Acc: (96.00%) (19849/20608)
Epoch: 162 | Batch_idx: 170 |  Loss: (0.1130) |  Loss2: (0.0000) | Acc: (96.00%) (21070/21888)
Epoch: 162 | Batch_idx: 180 |  Loss: (0.1139) |  Loss2: (0.0000) | Acc: (96.00%) (22285/23168)
Epoch: 162 | Batch_idx: 190 |  Loss: (0.1144) |  Loss2: (0.0000) | Acc: (96.00%) (23511/24448)
Epoch: 162 | Batch_idx: 200 |  Loss: (0.1136) |  Loss2: (0.0000) | Acc: (96.00%) (24749/25728)
Epoch: 162 | Batch_idx: 210 |  Loss: (0.1131) |  Loss2: (0.0000) | Acc: (96.00%) (25982/27008)
Epoch: 162 | Batch_idx: 220 |  Loss: (0.1132) |  Loss2: (0.0000) | Acc: (96.00%) (27222/28288)
Epoch: 162 | Batch_idx: 230 |  Loss: (0.1123) |  Loss2: (0.0000) | Acc: (96.00%) (28457/29568)
Epoch: 162 | Batch_idx: 240 |  Loss: (0.1122) |  Loss2: (0.0000) | Acc: (96.00%) (29692/30848)
Epoch: 162 | Batch_idx: 250 |  Loss: (0.1114) |  Loss2: (0.0000) | Acc: (96.00%) (30940/32128)
Epoch: 162 | Batch_idx: 260 |  Loss: (0.1120) |  Loss2: (0.0000) | Acc: (96.00%) (32162/33408)
Epoch: 162 | Batch_idx: 270 |  Loss: (0.1118) |  Loss2: (0.0000) | Acc: (96.00%) (33394/34688)
Epoch: 162 | Batch_idx: 280 |  Loss: (0.1121) |  Loss2: (0.0000) | Acc: (96.00%) (34620/35968)
Epoch: 162 | Batch_idx: 290 |  Loss: (0.1119) |  Loss2: (0.0000) | Acc: (96.00%) (35854/37248)
Epoch: 162 | Batch_idx: 300 |  Loss: (0.1118) |  Loss2: (0.0000) | Acc: (96.00%) (37091/38528)
Epoch: 162 | Batch_idx: 310 |  Loss: (0.1121) |  Loss2: (0.0000) | Acc: (96.00%) (38319/39808)
Epoch: 162 | Batch_idx: 320 |  Loss: (0.1121) |  Loss2: (0.0000) | Acc: (96.00%) (39557/41088)
Epoch: 162 | Batch_idx: 330 |  Loss: (0.1124) |  Loss2: (0.0000) | Acc: (96.00%) (40785/42368)
Epoch: 162 | Batch_idx: 340 |  Loss: (0.1123) |  Loss2: (0.0000) | Acc: (96.00%) (42016/43648)
Epoch: 162 | Batch_idx: 350 |  Loss: (0.1123) |  Loss2: (0.0000) | Acc: (96.00%) (43253/44928)
Epoch: 162 | Batch_idx: 360 |  Loss: (0.1118) |  Loss2: (0.0000) | Acc: (96.00%) (44493/46208)
Epoch: 162 | Batch_idx: 370 |  Loss: (0.1112) |  Loss2: (0.0000) | Acc: (96.00%) (45740/47488)
Epoch: 162 | Batch_idx: 380 |  Loss: (0.1108) |  Loss2: (0.0000) | Acc: (96.00%) (46978/48768)
Epoch: 162 | Batch_idx: 390 |  Loss: (0.1104) |  Loss2: (0.0000) | Acc: (96.00%) (48176/50000)
# TEST : Loss: (0.4012) | Acc: (88.00%) (8847/10000)
percent tensor([0.5736, 0.5829, 0.6185, 0.6025, 0.6173, 0.5787, 0.5960, 0.6092, 0.5842,
        0.5929, 0.5710, 0.6104, 0.5759, 0.5795, 0.5831, 0.5768],
       device='cuda:0') torch.Size([16])
percent tensor([0.5816, 0.5849, 0.5777, 0.5718, 0.5844, 0.5820, 0.5904, 0.5830, 0.5772,
        0.5825, 0.5838, 0.5870, 0.5803, 0.5783, 0.5889, 0.5820],
       device='cuda:0') torch.Size([16])
percent tensor([0.6117, 0.6222, 0.5716, 0.5540, 0.5571, 0.5856, 0.6064, 0.5654, 0.5987,
        0.6196, 0.6168, 0.5920, 0.6367, 0.6130, 0.6042, 0.6150],
       device='cuda:0') torch.Size([16])
percent tensor([0.6348, 0.6275, 0.6009, 0.6068, 0.6150, 0.6442, 0.6394, 0.6144, 0.6207,
        0.6259, 0.6306, 0.6189, 0.6257, 0.6335, 0.6421, 0.6354],
       device='cuda:0') torch.Size([16])
percent tensor([0.5395, 0.5057, 0.6069, 0.6431, 0.6226, 0.5815, 0.5594, 0.6193, 0.5875,
        0.5208, 0.5590, 0.5850, 0.4470, 0.6229, 0.5874, 0.5555],
       device='cuda:0') torch.Size([16])
percent tensor([0.5242, 0.6800, 0.6445, 0.6513, 0.6377, 0.7089, 0.6525, 0.5427, 0.6670,
        0.6418, 0.7103, 0.6730, 0.6532, 0.7156, 0.5222, 0.5163],
       device='cuda:0') torch.Size([16])
percent tensor([0.6751, 0.7186, 0.7003, 0.6291, 0.6386, 0.7199, 0.7128, 0.6127, 0.6849,
        0.7019, 0.7214, 0.6206, 0.7135, 0.7146, 0.5652, 0.6210],
       device='cuda:0') torch.Size([16])
percent tensor([0.9996, 0.9998, 0.9998, 0.9997, 0.9998, 0.9993, 0.9999, 0.9999, 0.9999,
        0.9999, 0.9999, 0.9998, 0.9996, 0.9998, 0.9997, 0.9993],
       device='cuda:0') torch.Size([16])
Epoch: 163 | Batch_idx: 0 |  Loss: (0.1271) |  Loss2: (0.0000) | Acc: (94.00%) (121/128)
Epoch: 163 | Batch_idx: 10 |  Loss: (0.1262) |  Loss2: (0.0000) | Acc: (95.00%) (1351/1408)
Epoch: 163 | Batch_idx: 20 |  Loss: (0.1249) |  Loss2: (0.0000) | Acc: (95.00%) (2579/2688)
Epoch: 163 | Batch_idx: 30 |  Loss: (0.1216) |  Loss2: (0.0000) | Acc: (96.00%) (3813/3968)
Epoch: 163 | Batch_idx: 40 |  Loss: (0.1131) |  Loss2: (0.0000) | Acc: (96.00%) (5058/5248)
Epoch: 163 | Batch_idx: 50 |  Loss: (0.1112) |  Loss2: (0.0000) | Acc: (96.00%) (6296/6528)
Epoch: 163 | Batch_idx: 60 |  Loss: (0.1095) |  Loss2: (0.0000) | Acc: (96.00%) (7533/7808)
Epoch: 163 | Batch_idx: 70 |  Loss: (0.1088) |  Loss2: (0.0000) | Acc: (96.00%) (8770/9088)
Epoch: 163 | Batch_idx: 80 |  Loss: (0.1067) |  Loss2: (0.0000) | Acc: (96.00%) (10013/10368)
Epoch: 163 | Batch_idx: 90 |  Loss: (0.1081) |  Loss2: (0.0000) | Acc: (96.00%) (11244/11648)
Epoch: 163 | Batch_idx: 100 |  Loss: (0.1072) |  Loss2: (0.0000) | Acc: (96.00%) (12474/12928)
Epoch: 163 | Batch_idx: 110 |  Loss: (0.1054) |  Loss2: (0.0000) | Acc: (96.00%) (13714/14208)
Epoch: 163 | Batch_idx: 120 |  Loss: (0.1053) |  Loss2: (0.0000) | Acc: (96.00%) (14956/15488)
Epoch: 163 | Batch_idx: 130 |  Loss: (0.1059) |  Loss2: (0.0000) | Acc: (96.00%) (16187/16768)
Epoch: 163 | Batch_idx: 140 |  Loss: (0.1064) |  Loss2: (0.0000) | Acc: (96.00%) (17416/18048)
Epoch: 163 | Batch_idx: 150 |  Loss: (0.1067) |  Loss2: (0.0000) | Acc: (96.00%) (18645/19328)
Epoch: 163 | Batch_idx: 160 |  Loss: (0.1061) |  Loss2: (0.0000) | Acc: (96.00%) (19880/20608)
Epoch: 163 | Batch_idx: 170 |  Loss: (0.1060) |  Loss2: (0.0000) | Acc: (96.00%) (21118/21888)
Epoch: 163 | Batch_idx: 180 |  Loss: (0.1057) |  Loss2: (0.0000) | Acc: (96.00%) (22350/23168)
Epoch: 163 | Batch_idx: 190 |  Loss: (0.1053) |  Loss2: (0.0000) | Acc: (96.00%) (23587/24448)
Epoch: 163 | Batch_idx: 200 |  Loss: (0.1049) |  Loss2: (0.0000) | Acc: (96.00%) (24831/25728)
Epoch: 163 | Batch_idx: 210 |  Loss: (0.1052) |  Loss2: (0.0000) | Acc: (96.00%) (26062/27008)
Epoch: 163 | Batch_idx: 220 |  Loss: (0.1045) |  Loss2: (0.0000) | Acc: (96.00%) (27308/28288)
Epoch: 163 | Batch_idx: 230 |  Loss: (0.1051) |  Loss2: (0.0000) | Acc: (96.00%) (28539/29568)
Epoch: 163 | Batch_idx: 240 |  Loss: (0.1054) |  Loss2: (0.0000) | Acc: (96.00%) (29772/30848)
Epoch: 163 | Batch_idx: 250 |  Loss: (0.1053) |  Loss2: (0.0000) | Acc: (96.00%) (31011/32128)
Epoch: 163 | Batch_idx: 260 |  Loss: (0.1049) |  Loss2: (0.0000) | Acc: (96.00%) (32250/33408)
Epoch: 163 | Batch_idx: 270 |  Loss: (0.1044) |  Loss2: (0.0000) | Acc: (96.00%) (33491/34688)
Epoch: 163 | Batch_idx: 280 |  Loss: (0.1047) |  Loss2: (0.0000) | Acc: (96.00%) (34724/35968)
Epoch: 163 | Batch_idx: 290 |  Loss: (0.1044) |  Loss2: (0.0000) | Acc: (96.00%) (35962/37248)
Epoch: 163 | Batch_idx: 300 |  Loss: (0.1044) |  Loss2: (0.0000) | Acc: (96.00%) (37197/38528)
Epoch: 163 | Batch_idx: 310 |  Loss: (0.1040) |  Loss2: (0.0000) | Acc: (96.00%) (38435/39808)
Epoch: 163 | Batch_idx: 320 |  Loss: (0.1038) |  Loss2: (0.0000) | Acc: (96.00%) (39668/41088)
Epoch: 163 | Batch_idx: 330 |  Loss: (0.1035) |  Loss2: (0.0000) | Acc: (96.00%) (40904/42368)
Epoch: 163 | Batch_idx: 340 |  Loss: (0.1032) |  Loss2: (0.0000) | Acc: (96.00%) (42145/43648)
Epoch: 163 | Batch_idx: 350 |  Loss: (0.1031) |  Loss2: (0.0000) | Acc: (96.00%) (43381/44928)
Epoch: 163 | Batch_idx: 360 |  Loss: (0.1031) |  Loss2: (0.0000) | Acc: (96.00%) (44616/46208)
Epoch: 163 | Batch_idx: 370 |  Loss: (0.1028) |  Loss2: (0.0000) | Acc: (96.00%) (45854/47488)
Epoch: 163 | Batch_idx: 380 |  Loss: (0.1031) |  Loss2: (0.0000) | Acc: (96.00%) (47082/48768)
Epoch: 163 | Batch_idx: 390 |  Loss: (0.1033) |  Loss2: (0.0000) | Acc: (96.00%) (48268/50000)
# TEST : Loss: (0.3925) | Acc: (88.00%) (8867/10000)
percent tensor([0.5679, 0.5765, 0.6127, 0.5971, 0.6113, 0.5731, 0.5898, 0.6036, 0.5784,
        0.5869, 0.5650, 0.6042, 0.5698, 0.5743, 0.5770, 0.5712],
       device='cuda:0') torch.Size([16])
percent tensor([0.5812, 0.5846, 0.5772, 0.5717, 0.5841, 0.5814, 0.5900, 0.5830, 0.5767,
        0.5821, 0.5832, 0.5867, 0.5798, 0.5784, 0.5884, 0.5817],
       device='cuda:0') torch.Size([16])
percent tensor([0.6152, 0.6256, 0.5738, 0.5557, 0.5580, 0.5877, 0.6091, 0.5678, 0.6010,
        0.6231, 0.6199, 0.5943, 0.6405, 0.6163, 0.6071, 0.6184],
       device='cuda:0') torch.Size([16])
percent tensor([0.6370, 0.6291, 0.6014, 0.6076, 0.6145, 0.6473, 0.6410, 0.6155, 0.6216,
        0.6271, 0.6322, 0.6202, 0.6280, 0.6345, 0.6452, 0.6375],
       device='cuda:0') torch.Size([16])
percent tensor([0.5355, 0.5016, 0.6079, 0.6440, 0.6225, 0.5802, 0.5570, 0.6199, 0.5854,
        0.5153, 0.5534, 0.5869, 0.4398, 0.6225, 0.5876, 0.5512],
       device='cuda:0') torch.Size([16])
percent tensor([0.5201, 0.6840, 0.6411, 0.6475, 0.6328, 0.7108, 0.6531, 0.5323, 0.6672,
        0.6442, 0.7159, 0.6717, 0.6573, 0.7199, 0.5170, 0.5098],
       device='cuda:0') torch.Size([16])
percent tensor([0.6743, 0.7193, 0.6977, 0.6255, 0.6378, 0.7156, 0.7130, 0.6106, 0.6843,
        0.7013, 0.7218, 0.6156, 0.7141, 0.7115, 0.5669, 0.6209],
       device='cuda:0') torch.Size([16])
percent tensor([0.9995, 0.9997, 0.9998, 0.9997, 0.9998, 0.9994, 0.9999, 0.9999, 0.9999,
        0.9999, 0.9999, 0.9998, 0.9996, 0.9998, 0.9997, 0.9993],
       device='cuda:0') torch.Size([16])
Epoch: 164 | Batch_idx: 0 |  Loss: (0.1156) |  Loss2: (0.0000) | Acc: (93.00%) (120/128)
Epoch: 164 | Batch_idx: 10 |  Loss: (0.1073) |  Loss2: (0.0000) | Acc: (95.00%) (1346/1408)
Epoch: 164 | Batch_idx: 20 |  Loss: (0.1027) |  Loss2: (0.0000) | Acc: (95.00%) (2580/2688)
Epoch: 164 | Batch_idx: 30 |  Loss: (0.1004) |  Loss2: (0.0000) | Acc: (96.00%) (3817/3968)
Epoch: 164 | Batch_idx: 40 |  Loss: (0.0964) |  Loss2: (0.0000) | Acc: (96.00%) (5065/5248)
Epoch: 164 | Batch_idx: 50 |  Loss: (0.0960) |  Loss2: (0.0000) | Acc: (96.00%) (6307/6528)
Epoch: 164 | Batch_idx: 60 |  Loss: (0.0970) |  Loss2: (0.0000) | Acc: (96.00%) (7544/7808)
Epoch: 164 | Batch_idx: 70 |  Loss: (0.0987) |  Loss2: (0.0000) | Acc: (96.00%) (8771/9088)
Epoch: 164 | Batch_idx: 80 |  Loss: (0.1007) |  Loss2: (0.0000) | Acc: (96.00%) (9999/10368)
Epoch: 164 | Batch_idx: 90 |  Loss: (0.0992) |  Loss2: (0.0000) | Acc: (96.00%) (11245/11648)
Epoch: 164 | Batch_idx: 100 |  Loss: (0.0989) |  Loss2: (0.0000) | Acc: (96.00%) (12491/12928)
Epoch: 164 | Batch_idx: 110 |  Loss: (0.0983) |  Loss2: (0.0000) | Acc: (96.00%) (13729/14208)
Epoch: 164 | Batch_idx: 120 |  Loss: (0.0998) |  Loss2: (0.0000) | Acc: (96.00%) (14962/15488)
Epoch: 164 | Batch_idx: 130 |  Loss: (0.0999) |  Loss2: (0.0000) | Acc: (96.00%) (16200/16768)
Epoch: 164 | Batch_idx: 140 |  Loss: (0.1014) |  Loss2: (0.0000) | Acc: (96.00%) (17432/18048)
Epoch: 164 | Batch_idx: 150 |  Loss: (0.1022) |  Loss2: (0.0000) | Acc: (96.00%) (18667/19328)
Epoch: 164 | Batch_idx: 160 |  Loss: (0.1013) |  Loss2: (0.0000) | Acc: (96.00%) (19905/20608)
Epoch: 164 | Batch_idx: 170 |  Loss: (0.1015) |  Loss2: (0.0000) | Acc: (96.00%) (21135/21888)
Epoch: 164 | Batch_idx: 180 |  Loss: (0.1020) |  Loss2: (0.0000) | Acc: (96.00%) (22368/23168)
Epoch: 164 | Batch_idx: 190 |  Loss: (0.1022) |  Loss2: (0.0000) | Acc: (96.00%) (23608/24448)
Epoch: 164 | Batch_idx: 200 |  Loss: (0.1015) |  Loss2: (0.0000) | Acc: (96.00%) (24851/25728)
Epoch: 164 | Batch_idx: 210 |  Loss: (0.1005) |  Loss2: (0.0000) | Acc: (96.00%) (26095/27008)
Epoch: 164 | Batch_idx: 220 |  Loss: (0.1002) |  Loss2: (0.0000) | Acc: (96.00%) (27338/28288)
Epoch: 164 | Batch_idx: 230 |  Loss: (0.1003) |  Loss2: (0.0000) | Acc: (96.00%) (28574/29568)
Epoch: 164 | Batch_idx: 240 |  Loss: (0.0999) |  Loss2: (0.0000) | Acc: (96.00%) (29818/30848)
Epoch: 164 | Batch_idx: 250 |  Loss: (0.0995) |  Loss2: (0.0000) | Acc: (96.00%) (31066/32128)
Epoch: 164 | Batch_idx: 260 |  Loss: (0.0993) |  Loss2: (0.0000) | Acc: (96.00%) (32313/33408)
Epoch: 164 | Batch_idx: 270 |  Loss: (0.0996) |  Loss2: (0.0000) | Acc: (96.00%) (33550/34688)
Epoch: 164 | Batch_idx: 280 |  Loss: (0.0992) |  Loss2: (0.0000) | Acc: (96.00%) (34797/35968)
Epoch: 164 | Batch_idx: 290 |  Loss: (0.0987) |  Loss2: (0.0000) | Acc: (96.00%) (36043/37248)
Epoch: 164 | Batch_idx: 300 |  Loss: (0.0989) |  Loss2: (0.0000) | Acc: (96.00%) (37276/38528)
Epoch: 164 | Batch_idx: 310 |  Loss: (0.0991) |  Loss2: (0.0000) | Acc: (96.00%) (38507/39808)
Epoch: 164 | Batch_idx: 320 |  Loss: (0.0988) |  Loss2: (0.0000) | Acc: (96.00%) (39750/41088)
Epoch: 164 | Batch_idx: 330 |  Loss: (0.0999) |  Loss2: (0.0000) | Acc: (96.00%) (40968/42368)
Epoch: 164 | Batch_idx: 340 |  Loss: (0.0997) |  Loss2: (0.0000) | Acc: (96.00%) (42207/43648)
Epoch: 164 | Batch_idx: 350 |  Loss: (0.0997) |  Loss2: (0.0000) | Acc: (96.00%) (43452/44928)
Epoch: 164 | Batch_idx: 360 |  Loss: (0.0999) |  Loss2: (0.0000) | Acc: (96.00%) (44683/46208)
Epoch: 164 | Batch_idx: 370 |  Loss: (0.1000) |  Loss2: (0.0000) | Acc: (96.00%) (45919/47488)
Epoch: 164 | Batch_idx: 380 |  Loss: (0.0999) |  Loss2: (0.0000) | Acc: (96.00%) (47157/48768)
Epoch: 164 | Batch_idx: 390 |  Loss: (0.1003) |  Loss2: (0.0000) | Acc: (96.00%) (48330/50000)
# TEST : Loss: (0.3918) | Acc: (88.00%) (8874/10000)
percent tensor([0.5673, 0.5756, 0.6126, 0.5969, 0.6111, 0.5726, 0.5891, 0.6034, 0.5778,
        0.5863, 0.5641, 0.6038, 0.5689, 0.5738, 0.5761, 0.5706],
       device='cuda:0') torch.Size([16])
percent tensor([0.5774, 0.5802, 0.5737, 0.5684, 0.5802, 0.5775, 0.5858, 0.5793, 0.5729,
        0.5779, 0.5789, 0.5824, 0.5756, 0.5747, 0.5841, 0.5778],
       device='cuda:0') torch.Size([16])
percent tensor([0.6111, 0.6215, 0.5704, 0.5520, 0.5549, 0.5827, 0.6053, 0.5654, 0.5970,
        0.6186, 0.6151, 0.5909, 0.6366, 0.6123, 0.6030, 0.6138],
       device='cuda:0') torch.Size([16])
percent tensor([0.6365, 0.6290, 0.6001, 0.6064, 0.6126, 0.6468, 0.6404, 0.6142, 0.6209,
        0.6267, 0.6323, 0.6196, 0.6283, 0.6343, 0.6451, 0.6368],
       device='cuda:0') torch.Size([16])
percent tensor([0.5331, 0.5055, 0.6033, 0.6404, 0.6167, 0.5772, 0.5539, 0.6150, 0.5811,
        0.5185, 0.5558, 0.5855, 0.4431, 0.6218, 0.5836, 0.5529],
       device='cuda:0') torch.Size([16])
percent tensor([0.5235, 0.6854, 0.6433, 0.6488, 0.6348, 0.7140, 0.6569, 0.5360, 0.6705,
        0.6431, 0.7167, 0.6724, 0.6614, 0.7202, 0.5224, 0.5134],
       device='cuda:0') torch.Size([16])
percent tensor([0.6857, 0.7292, 0.7067, 0.6341, 0.6468, 0.7244, 0.7243, 0.6193, 0.6932,
        0.7123, 0.7294, 0.6190, 0.7238, 0.7193, 0.5728, 0.6331],
       device='cuda:0') torch.Size([16])
percent tensor([0.9996, 0.9998, 0.9998, 0.9997, 0.9998, 0.9995, 0.9999, 0.9999, 0.9999,
        0.9999, 0.9999, 0.9998, 0.9996, 0.9998, 0.9997, 0.9994],
       device='cuda:0') torch.Size([16])
Epoch: 165 | Batch_idx: 0 |  Loss: (0.1251) |  Loss2: (0.0000) | Acc: (94.00%) (121/128)
Epoch: 165 | Batch_idx: 10 |  Loss: (0.0890) |  Loss2: (0.0000) | Acc: (97.00%) (1368/1408)
Epoch: 165 | Batch_idx: 20 |  Loss: (0.1016) |  Loss2: (0.0000) | Acc: (96.00%) (2597/2688)
Epoch: 165 | Batch_idx: 30 |  Loss: (0.0961) |  Loss2: (0.0000) | Acc: (96.00%) (3840/3968)
Epoch: 165 | Batch_idx: 40 |  Loss: (0.0960) |  Loss2: (0.0000) | Acc: (96.00%) (5078/5248)
Epoch: 165 | Batch_idx: 50 |  Loss: (0.0950) |  Loss2: (0.0000) | Acc: (96.00%) (6320/6528)
Epoch: 165 | Batch_idx: 60 |  Loss: (0.0956) |  Loss2: (0.0000) | Acc: (96.00%) (7561/7808)
Epoch: 165 | Batch_idx: 70 |  Loss: (0.0971) |  Loss2: (0.0000) | Acc: (96.00%) (8797/9088)
Epoch: 165 | Batch_idx: 80 |  Loss: (0.0958) |  Loss2: (0.0000) | Acc: (96.00%) (10045/10368)
Epoch: 165 | Batch_idx: 90 |  Loss: (0.0976) |  Loss2: (0.0000) | Acc: (96.00%) (11283/11648)
Epoch: 165 | Batch_idx: 100 |  Loss: (0.0956) |  Loss2: (0.0000) | Acc: (96.00%) (12527/12928)
Epoch: 165 | Batch_idx: 110 |  Loss: (0.0965) |  Loss2: (0.0000) | Acc: (96.00%) (13763/14208)
Epoch: 165 | Batch_idx: 120 |  Loss: (0.0967) |  Loss2: (0.0000) | Acc: (96.00%) (15001/15488)
Epoch: 165 | Batch_idx: 130 |  Loss: (0.0969) |  Loss2: (0.0000) | Acc: (96.00%) (16242/16768)
Epoch: 165 | Batch_idx: 140 |  Loss: (0.0961) |  Loss2: (0.0000) | Acc: (96.00%) (17483/18048)
Epoch: 165 | Batch_idx: 150 |  Loss: (0.0974) |  Loss2: (0.0000) | Acc: (96.00%) (18716/19328)
Epoch: 165 | Batch_idx: 160 |  Loss: (0.0982) |  Loss2: (0.0000) | Acc: (96.00%) (19950/20608)
Epoch: 165 | Batch_idx: 170 |  Loss: (0.0971) |  Loss2: (0.0000) | Acc: (96.00%) (21202/21888)
Epoch: 165 | Batch_idx: 180 |  Loss: (0.0970) |  Loss2: (0.0000) | Acc: (96.00%) (22446/23168)
Epoch: 165 | Batch_idx: 190 |  Loss: (0.0963) |  Loss2: (0.0000) | Acc: (96.00%) (23692/24448)
Epoch: 165 | Batch_idx: 200 |  Loss: (0.0959) |  Loss2: (0.0000) | Acc: (96.00%) (24936/25728)
Epoch: 165 | Batch_idx: 210 |  Loss: (0.0955) |  Loss2: (0.0000) | Acc: (96.00%) (26181/27008)
Epoch: 165 | Batch_idx: 220 |  Loss: (0.0963) |  Loss2: (0.0000) | Acc: (96.00%) (27412/28288)
Epoch: 165 | Batch_idx: 230 |  Loss: (0.0958) |  Loss2: (0.0000) | Acc: (96.00%) (28656/29568)
Epoch: 165 | Batch_idx: 240 |  Loss: (0.0966) |  Loss2: (0.0000) | Acc: (96.00%) (29893/30848)
Epoch: 165 | Batch_idx: 250 |  Loss: (0.0967) |  Loss2: (0.0000) | Acc: (96.00%) (31137/32128)
Epoch: 165 | Batch_idx: 260 |  Loss: (0.0970) |  Loss2: (0.0000) | Acc: (96.00%) (32364/33408)
Epoch: 165 | Batch_idx: 270 |  Loss: (0.0968) |  Loss2: (0.0000) | Acc: (96.00%) (33608/34688)
Epoch: 165 | Batch_idx: 280 |  Loss: (0.0975) |  Loss2: (0.0000) | Acc: (96.00%) (34839/35968)
Epoch: 165 | Batch_idx: 290 |  Loss: (0.0975) |  Loss2: (0.0000) | Acc: (96.00%) (36079/37248)
Epoch: 165 | Batch_idx: 300 |  Loss: (0.0977) |  Loss2: (0.0000) | Acc: (96.00%) (37307/38528)
Epoch: 165 | Batch_idx: 310 |  Loss: (0.0972) |  Loss2: (0.0000) | Acc: (96.00%) (38547/39808)
Epoch: 165 | Batch_idx: 320 |  Loss: (0.0974) |  Loss2: (0.0000) | Acc: (96.00%) (39788/41088)
Epoch: 165 | Batch_idx: 330 |  Loss: (0.0975) |  Loss2: (0.0000) | Acc: (96.00%) (41014/42368)
Epoch: 165 | Batch_idx: 340 |  Loss: (0.0975) |  Loss2: (0.0000) | Acc: (96.00%) (42255/43648)
Epoch: 165 | Batch_idx: 350 |  Loss: (0.0977) |  Loss2: (0.0000) | Acc: (96.00%) (43491/44928)
Epoch: 165 | Batch_idx: 360 |  Loss: (0.0979) |  Loss2: (0.0000) | Acc: (96.00%) (44723/46208)
Epoch: 165 | Batch_idx: 370 |  Loss: (0.0983) |  Loss2: (0.0000) | Acc: (96.00%) (45953/47488)
Epoch: 165 | Batch_idx: 380 |  Loss: (0.0982) |  Loss2: (0.0000) | Acc: (96.00%) (47190/48768)
Epoch: 165 | Batch_idx: 390 |  Loss: (0.0983) |  Loss2: (0.0000) | Acc: (96.00%) (48375/50000)
=> saving checkpoint 'drive/app/torch/save_Schedule/checkpoint_165.pth.tar'
# TEST : Loss: (0.3883) | Acc: (88.00%) (8879/10000)
percent tensor([0.5679, 0.5764, 0.6143, 0.5985, 0.6127, 0.5732, 0.5903, 0.6049, 0.5787,
        0.5874, 0.5645, 0.6053, 0.5696, 0.5745, 0.5769, 0.5714],
       device='cuda:0') torch.Size([16])
percent tensor([0.5785, 0.5813, 0.5753, 0.5697, 0.5820, 0.5782, 0.5873, 0.5813, 0.5743,
        0.5791, 0.5799, 0.5840, 0.5767, 0.5761, 0.5850, 0.5788],
       device='cuda:0') torch.Size([16])
percent tensor([0.6139, 0.6263, 0.5717, 0.5524, 0.5562, 0.5834, 0.6089, 0.5676, 0.5995,
        0.6227, 0.6187, 0.5935, 0.6404, 0.6173, 0.6061, 0.6170],
       device='cuda:0') torch.Size([16])
percent tensor([0.6405, 0.6326, 0.6029, 0.6093, 0.6152, 0.6500, 0.6445, 0.6178, 0.6247,
        0.6307, 0.6364, 0.6236, 0.6327, 0.6377, 0.6494, 0.6403],
       device='cuda:0') torch.Size([16])
percent tensor([0.5307, 0.4997, 0.6035, 0.6411, 0.6179, 0.5775, 0.5530, 0.6163, 0.5819,
        0.5138, 0.5507, 0.5865, 0.4363, 0.6207, 0.5823, 0.5496],
       device='cuda:0') torch.Size([16])
percent tensor([0.5283, 0.6938, 0.6490, 0.6608, 0.6441, 0.7205, 0.6627, 0.5401, 0.6787,
        0.6541, 0.7256, 0.6823, 0.6710, 0.7284, 0.5305, 0.5202],
       device='cuda:0') torch.Size([16])
percent tensor([0.6826, 0.7282, 0.7057, 0.6338, 0.6498, 0.7242, 0.7234, 0.6178, 0.6908,
        0.7121, 0.7268, 0.6158, 0.7215, 0.7164, 0.5700, 0.6325],
       device='cuda:0') torch.Size([16])
percent tensor([0.9995, 0.9998, 0.9998, 0.9997, 0.9998, 0.9994, 0.9999, 0.9999, 0.9999,
        0.9999, 0.9999, 0.9998, 0.9996, 0.9998, 0.9997, 0.9993],
       device='cuda:0') torch.Size([16])
Epoch: 166 | Batch_idx: 0 |  Loss: (0.0600) |  Loss2: (0.0000) | Acc: (98.00%) (126/128)
Epoch: 166 | Batch_idx: 10 |  Loss: (0.0976) |  Loss2: (0.0000) | Acc: (96.00%) (1355/1408)
Epoch: 166 | Batch_idx: 20 |  Loss: (0.0905) |  Loss2: (0.0000) | Acc: (96.00%) (2604/2688)
Epoch: 166 | Batch_idx: 30 |  Loss: (0.0925) |  Loss2: (0.0000) | Acc: (96.00%) (3846/3968)
Epoch: 166 | Batch_idx: 40 |  Loss: (0.0948) |  Loss2: (0.0000) | Acc: (96.00%) (5082/5248)
Epoch: 166 | Batch_idx: 50 |  Loss: (0.0960) |  Loss2: (0.0000) | Acc: (96.00%) (6318/6528)
Epoch: 166 | Batch_idx: 60 |  Loss: (0.1008) |  Loss2: (0.0000) | Acc: (96.00%) (7544/7808)
Epoch: 166 | Batch_idx: 70 |  Loss: (0.0998) |  Loss2: (0.0000) | Acc: (96.00%) (8790/9088)
Epoch: 166 | Batch_idx: 80 |  Loss: (0.0988) |  Loss2: (0.0000) | Acc: (96.00%) (10034/10368)
Epoch: 166 | Batch_idx: 90 |  Loss: (0.1000) |  Loss2: (0.0000) | Acc: (96.00%) (11267/11648)
Epoch: 166 | Batch_idx: 100 |  Loss: (0.1009) |  Loss2: (0.0000) | Acc: (96.00%) (12491/12928)
Epoch: 166 | Batch_idx: 110 |  Loss: (0.1006) |  Loss2: (0.0000) | Acc: (96.00%) (13732/14208)
Epoch: 166 | Batch_idx: 120 |  Loss: (0.0985) |  Loss2: (0.0000) | Acc: (96.00%) (14987/15488)
Epoch: 166 | Batch_idx: 130 |  Loss: (0.0977) |  Loss2: (0.0000) | Acc: (96.00%) (16229/16768)
Epoch: 166 | Batch_idx: 140 |  Loss: (0.0976) |  Loss2: (0.0000) | Acc: (96.00%) (17463/18048)
Epoch: 166 | Batch_idx: 150 |  Loss: (0.0972) |  Loss2: (0.0000) | Acc: (96.00%) (18702/19328)
Epoch: 166 | Batch_idx: 160 |  Loss: (0.0969) |  Loss2: (0.0000) | Acc: (96.00%) (19941/20608)
Epoch: 166 | Batch_idx: 170 |  Loss: (0.0967) |  Loss2: (0.0000) | Acc: (96.00%) (21188/21888)
Epoch: 166 | Batch_idx: 180 |  Loss: (0.0971) |  Loss2: (0.0000) | Acc: (96.00%) (22419/23168)
Epoch: 166 | Batch_idx: 190 |  Loss: (0.0972) |  Loss2: (0.0000) | Acc: (96.00%) (23658/24448)
Epoch: 166 | Batch_idx: 200 |  Loss: (0.0976) |  Loss2: (0.0000) | Acc: (96.00%) (24887/25728)
Epoch: 166 | Batch_idx: 210 |  Loss: (0.0979) |  Loss2: (0.0000) | Acc: (96.00%) (26126/27008)
Epoch: 166 | Batch_idx: 220 |  Loss: (0.0977) |  Loss2: (0.0000) | Acc: (96.00%) (27372/28288)
Epoch: 166 | Batch_idx: 230 |  Loss: (0.0978) |  Loss2: (0.0000) | Acc: (96.00%) (28604/29568)
Epoch: 166 | Batch_idx: 240 |  Loss: (0.0981) |  Loss2: (0.0000) | Acc: (96.00%) (29840/30848)
Epoch: 166 | Batch_idx: 250 |  Loss: (0.0982) |  Loss2: (0.0000) | Acc: (96.00%) (31078/32128)
Epoch: 166 | Batch_idx: 260 |  Loss: (0.0979) |  Loss2: (0.0000) | Acc: (96.00%) (32327/33408)
Epoch: 166 | Batch_idx: 270 |  Loss: (0.0980) |  Loss2: (0.0000) | Acc: (96.00%) (33560/34688)
Epoch: 166 | Batch_idx: 280 |  Loss: (0.0979) |  Loss2: (0.0000) | Acc: (96.00%) (34798/35968)
Epoch: 166 | Batch_idx: 290 |  Loss: (0.0979) |  Loss2: (0.0000) | Acc: (96.00%) (36033/37248)
Epoch: 166 | Batch_idx: 300 |  Loss: (0.0979) |  Loss2: (0.0000) | Acc: (96.00%) (37270/38528)
Epoch: 166 | Batch_idx: 310 |  Loss: (0.0979) |  Loss2: (0.0000) | Acc: (96.00%) (38509/39808)
Epoch: 166 | Batch_idx: 320 |  Loss: (0.0979) |  Loss2: (0.0000) | Acc: (96.00%) (39747/41088)
Epoch: 166 | Batch_idx: 330 |  Loss: (0.0979) |  Loss2: (0.0000) | Acc: (96.00%) (40982/42368)
Epoch: 166 | Batch_idx: 340 |  Loss: (0.0977) |  Loss2: (0.0000) | Acc: (96.00%) (42227/43648)
Epoch: 166 | Batch_idx: 350 |  Loss: (0.0976) |  Loss2: (0.0000) | Acc: (96.00%) (43471/44928)
Epoch: 166 | Batch_idx: 360 |  Loss: (0.0972) |  Loss2: (0.0000) | Acc: (96.00%) (44722/46208)
Epoch: 166 | Batch_idx: 370 |  Loss: (0.0970) |  Loss2: (0.0000) | Acc: (96.00%) (45959/47488)
Epoch: 166 | Batch_idx: 380 |  Loss: (0.0969) |  Loss2: (0.0000) | Acc: (96.00%) (47202/48768)
Epoch: 166 | Batch_idx: 390 |  Loss: (0.0967) |  Loss2: (0.0000) | Acc: (96.00%) (48402/50000)
# TEST : Loss: (0.3855) | Acc: (88.00%) (8875/10000)
percent tensor([0.5660, 0.5742, 0.6126, 0.5972, 0.6108, 0.5713, 0.5881, 0.6034, 0.5769,
        0.5855, 0.5623, 0.6035, 0.5676, 0.5731, 0.5748, 0.5697],
       device='cuda:0') torch.Size([16])
percent tensor([0.5780, 0.5810, 0.5751, 0.5696, 0.5818, 0.5776, 0.5869, 0.5812, 0.5741,
        0.5789, 0.5794, 0.5838, 0.5763, 0.5761, 0.5844, 0.5784],
       device='cuda:0') torch.Size([16])
percent tensor([0.6109, 0.6243, 0.5694, 0.5507, 0.5548, 0.5801, 0.6070, 0.5669, 0.5968,
        0.6204, 0.6155, 0.5915, 0.6375, 0.6153, 0.6038, 0.6139],
       device='cuda:0') torch.Size([16])
percent tensor([0.6408, 0.6331, 0.6030, 0.6098, 0.6150, 0.6509, 0.6449, 0.6185, 0.6251,
        0.6310, 0.6370, 0.6242, 0.6331, 0.6382, 0.6506, 0.6404],
       device='cuda:0') torch.Size([16])
percent tensor([0.5295, 0.5002, 0.6046, 0.6419, 0.6194, 0.5750, 0.5524, 0.6182, 0.5805,
        0.5125, 0.5471, 0.5877, 0.4352, 0.6194, 0.5838, 0.5469],
       device='cuda:0') torch.Size([16])
percent tensor([0.5268, 0.6879, 0.6458, 0.6565, 0.6383, 0.7184, 0.6590, 0.5373, 0.6734,
        0.6534, 0.7236, 0.6789, 0.6706, 0.7223, 0.5253, 0.5188],
       device='cuda:0') torch.Size([16])
percent tensor([0.6803, 0.7241, 0.7029, 0.6328, 0.6488, 0.7222, 0.7212, 0.6168, 0.6887,
        0.7121, 0.7238, 0.6141, 0.7188, 0.7144, 0.5682, 0.6317],
       device='cuda:0') torch.Size([16])
percent tensor([0.9996, 0.9998, 0.9999, 0.9997, 0.9999, 0.9994, 0.9999, 0.9999, 0.9999,
        0.9999, 0.9999, 0.9998, 0.9996, 0.9998, 0.9997, 0.9993],
       device='cuda:0') torch.Size([16])
Epoch: 167 | Batch_idx: 0 |  Loss: (0.0933) |  Loss2: (0.0000) | Acc: (97.00%) (125/128)
Epoch: 167 | Batch_idx: 10 |  Loss: (0.0773) |  Loss2: (0.0000) | Acc: (97.00%) (1377/1408)
Epoch: 167 | Batch_idx: 20 |  Loss: (0.0919) |  Loss2: (0.0000) | Acc: (97.00%) (2610/2688)
Epoch: 167 | Batch_idx: 30 |  Loss: (0.0923) |  Loss2: (0.0000) | Acc: (97.00%) (3855/3968)
Epoch: 167 | Batch_idx: 40 |  Loss: (0.0937) |  Loss2: (0.0000) | Acc: (97.00%) (5096/5248)
Epoch: 167 | Batch_idx: 50 |  Loss: (0.0917) |  Loss2: (0.0000) | Acc: (97.00%) (6345/6528)
Epoch: 167 | Batch_idx: 60 |  Loss: (0.0898) |  Loss2: (0.0000) | Acc: (97.00%) (7598/7808)
Epoch: 167 | Batch_idx: 70 |  Loss: (0.0919) |  Loss2: (0.0000) | Acc: (97.00%) (8835/9088)
Epoch: 167 | Batch_idx: 80 |  Loss: (0.0932) |  Loss2: (0.0000) | Acc: (97.00%) (10069/10368)
Epoch: 167 | Batch_idx: 90 |  Loss: (0.0938) |  Loss2: (0.0000) | Acc: (97.00%) (11305/11648)
Epoch: 167 | Batch_idx: 100 |  Loss: (0.0940) |  Loss2: (0.0000) | Acc: (97.00%) (12547/12928)
Epoch: 167 | Batch_idx: 110 |  Loss: (0.0955) |  Loss2: (0.0000) | Acc: (97.00%) (13785/14208)
Epoch: 167 | Batch_idx: 120 |  Loss: (0.0948) |  Loss2: (0.0000) | Acc: (97.00%) (15024/15488)
Epoch: 167 | Batch_idx: 130 |  Loss: (0.0940) |  Loss2: (0.0000) | Acc: (97.00%) (16269/16768)
Epoch: 167 | Batch_idx: 140 |  Loss: (0.0936) |  Loss2: (0.0000) | Acc: (97.00%) (17511/18048)
Epoch: 167 | Batch_idx: 150 |  Loss: (0.0930) |  Loss2: (0.0000) | Acc: (97.00%) (18758/19328)
Epoch: 167 | Batch_idx: 160 |  Loss: (0.0932) |  Loss2: (0.0000) | Acc: (97.00%) (19993/20608)
Epoch: 167 | Batch_idx: 170 |  Loss: (0.0926) |  Loss2: (0.0000) | Acc: (97.00%) (21241/21888)
Epoch: 167 | Batch_idx: 180 |  Loss: (0.0922) |  Loss2: (0.0000) | Acc: (97.00%) (22485/23168)
Epoch: 167 | Batch_idx: 190 |  Loss: (0.0922) |  Loss2: (0.0000) | Acc: (97.00%) (23723/24448)
Epoch: 167 | Batch_idx: 200 |  Loss: (0.0928) |  Loss2: (0.0000) | Acc: (96.00%) (24956/25728)
Epoch: 167 | Batch_idx: 210 |  Loss: (0.0922) |  Loss2: (0.0000) | Acc: (97.00%) (26209/27008)
Epoch: 167 | Batch_idx: 220 |  Loss: (0.0918) |  Loss2: (0.0000) | Acc: (97.00%) (27456/28288)
Epoch: 167 | Batch_idx: 230 |  Loss: (0.0922) |  Loss2: (0.0000) | Acc: (97.00%) (28692/29568)
Epoch: 167 | Batch_idx: 240 |  Loss: (0.0928) |  Loss2: (0.0000) | Acc: (97.00%) (29931/30848)
Epoch: 167 | Batch_idx: 250 |  Loss: (0.0927) |  Loss2: (0.0000) | Acc: (97.00%) (31177/32128)
Epoch: 167 | Batch_idx: 260 |  Loss: (0.0928) |  Loss2: (0.0000) | Acc: (97.00%) (32419/33408)
Epoch: 167 | Batch_idx: 270 |  Loss: (0.0923) |  Loss2: (0.0000) | Acc: (97.00%) (33667/34688)
Epoch: 167 | Batch_idx: 280 |  Loss: (0.0920) |  Loss2: (0.0000) | Acc: (97.00%) (34915/35968)
Epoch: 167 | Batch_idx: 290 |  Loss: (0.0920) |  Loss2: (0.0000) | Acc: (97.00%) (36162/37248)
Epoch: 167 | Batch_idx: 300 |  Loss: (0.0924) |  Loss2: (0.0000) | Acc: (97.00%) (37402/38528)
Epoch: 167 | Batch_idx: 310 |  Loss: (0.0921) |  Loss2: (0.0000) | Acc: (97.00%) (38642/39808)
Epoch: 167 | Batch_idx: 320 |  Loss: (0.0925) |  Loss2: (0.0000) | Acc: (97.00%) (39887/41088)
Epoch: 167 | Batch_idx: 330 |  Loss: (0.0927) |  Loss2: (0.0000) | Acc: (97.00%) (41121/42368)
Epoch: 167 | Batch_idx: 340 |  Loss: (0.0927) |  Loss2: (0.0000) | Acc: (97.00%) (42366/43648)
Epoch: 167 | Batch_idx: 350 |  Loss: (0.0924) |  Loss2: (0.0000) | Acc: (97.00%) (43606/44928)
Epoch: 167 | Batch_idx: 360 |  Loss: (0.0921) |  Loss2: (0.0000) | Acc: (97.00%) (44849/46208)
Epoch: 167 | Batch_idx: 370 |  Loss: (0.0921) |  Loss2: (0.0000) | Acc: (97.00%) (46083/47488)
Epoch: 167 | Batch_idx: 380 |  Loss: (0.0921) |  Loss2: (0.0000) | Acc: (97.00%) (47330/48768)
Epoch: 167 | Batch_idx: 390 |  Loss: (0.0920) |  Loss2: (0.0000) | Acc: (97.00%) (48524/50000)
# TEST : Loss: (0.3836) | Acc: (88.00%) (8886/10000)
percent tensor([0.5678, 0.5763, 0.6147, 0.5993, 0.6133, 0.5735, 0.5903, 0.6057, 0.5790,
        0.5875, 0.5642, 0.6055, 0.5694, 0.5751, 0.5769, 0.5715],
       device='cuda:0') torch.Size([16])
percent tensor([0.5776, 0.5809, 0.5745, 0.5689, 0.5812, 0.5770, 0.5866, 0.5808, 0.5737,
        0.5786, 0.5791, 0.5832, 0.5760, 0.5761, 0.5840, 0.5779],
       device='cuda:0') torch.Size([16])
percent tensor([0.6136, 0.6274, 0.5716, 0.5525, 0.5568, 0.5813, 0.6096, 0.5691, 0.5992,
        0.6236, 0.6180, 0.5944, 0.6410, 0.6177, 0.6059, 0.6166],
       device='cuda:0') torch.Size([16])
percent tensor([0.6486, 0.6406, 0.6091, 0.6156, 0.6210, 0.6583, 0.6527, 0.6249, 0.6321,
        0.6388, 0.6447, 0.6318, 0.6412, 0.6457, 0.6586, 0.6480],
       device='cuda:0') torch.Size([16])
percent tensor([0.5395, 0.5115, 0.6091, 0.6446, 0.6248, 0.5818, 0.5624, 0.6243, 0.5873,
        0.5237, 0.5583, 0.5944, 0.4453, 0.6290, 0.5934, 0.5565],
       device='cuda:0') torch.Size([16])
percent tensor([0.5259, 0.6888, 0.6513, 0.6605, 0.6412, 0.7245, 0.6603, 0.5414, 0.6748,
        0.6503, 0.7268, 0.6805, 0.6691, 0.7272, 0.5269, 0.5205],
       device='cuda:0') torch.Size([16])
percent tensor([0.6817, 0.7241, 0.7077, 0.6400, 0.6515, 0.7250, 0.7234, 0.6212, 0.6894,
        0.7119, 0.7257, 0.6174, 0.7184, 0.7185, 0.5695, 0.6332],
       device='cuda:0') torch.Size([16])
percent tensor([0.9996, 0.9998, 0.9998, 0.9997, 0.9998, 0.9995, 0.9999, 0.9999, 0.9999,
        0.9999, 0.9999, 0.9998, 0.9996, 0.9998, 0.9997, 0.9993],
       device='cuda:0') torch.Size([16])
True Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=128, out_features=16, bias=False)
False Linear(in_features=16, out_features=2, bias=False)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=128, out_features=16, bias=False)
False Linear(in_features=16, out_features=2, bias=False)
True Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=256, out_features=32, bias=False)
False Linear(in_features=32, out_features=2, bias=False)
True Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=256, out_features=32, bias=False)
False Linear(in_features=32, out_features=2, bias=False)
True Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=512, out_features=64, bias=False)
False Linear(in_features=64, out_features=2, bias=False)
True Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=512, out_features=64, bias=False)
False Linear(in_features=64, out_features=2, bias=False)
True Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1024, out_features=128, bias=False)
False Linear(in_features=128, out_features=2, bias=False)
True Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1024, out_features=128, bias=False)
False Linear(in_features=128, out_features=2, bias=False)
True Linear(in_features=512, out_features=10, bias=True)
Epoch: 168 | Batch_idx: 0 |  Loss: (0.0913) |  Loss2: (0.0000) | Acc: (96.00%) (123/128)
Epoch: 168 | Batch_idx: 10 |  Loss: (0.0892) |  Loss2: (0.0000) | Acc: (96.00%) (1358/1408)
Epoch: 168 | Batch_idx: 20 |  Loss: (0.1005) |  Loss2: (0.0000) | Acc: (96.00%) (2586/2688)
Epoch: 168 | Batch_idx: 30 |  Loss: (0.1091) |  Loss2: (0.0000) | Acc: (95.00%) (3805/3968)
Epoch: 168 | Batch_idx: 40 |  Loss: (0.1089) |  Loss2: (0.0000) | Acc: (95.00%) (5033/5248)
Epoch: 168 | Batch_idx: 50 |  Loss: (0.1107) |  Loss2: (0.0000) | Acc: (95.00%) (6263/6528)
Epoch: 168 | Batch_idx: 60 |  Loss: (0.1093) |  Loss2: (0.0000) | Acc: (96.00%) (7496/7808)
Epoch: 168 | Batch_idx: 70 |  Loss: (0.1088) |  Loss2: (0.0000) | Acc: (96.00%) (8735/9088)
Epoch: 168 | Batch_idx: 80 |  Loss: (0.1071) |  Loss2: (0.0000) | Acc: (96.00%) (9976/10368)
Epoch: 168 | Batch_idx: 90 |  Loss: (0.1063) |  Loss2: (0.0000) | Acc: (96.00%) (11208/11648)
Epoch: 168 | Batch_idx: 100 |  Loss: (0.1064) |  Loss2: (0.0000) | Acc: (96.00%) (12447/12928)
Epoch: 168 | Batch_idx: 110 |  Loss: (0.1065) |  Loss2: (0.0000) | Acc: (96.00%) (13678/14208)
Epoch: 168 | Batch_idx: 120 |  Loss: (0.1077) |  Loss2: (0.0000) | Acc: (96.00%) (14904/15488)
Epoch: 168 | Batch_idx: 130 |  Loss: (0.1083) |  Loss2: (0.0000) | Acc: (96.00%) (16133/16768)
Epoch: 168 | Batch_idx: 140 |  Loss: (0.1075) |  Loss2: (0.0000) | Acc: (96.00%) (17372/18048)
Epoch: 168 | Batch_idx: 150 |  Loss: (0.1076) |  Loss2: (0.0000) | Acc: (96.00%) (18601/19328)
Epoch: 168 | Batch_idx: 160 |  Loss: (0.1082) |  Loss2: (0.0000) | Acc: (96.00%) (19836/20608)
Epoch: 168 | Batch_idx: 170 |  Loss: (0.1085) |  Loss2: (0.0000) | Acc: (96.00%) (21061/21888)
Epoch: 168 | Batch_idx: 180 |  Loss: (0.1086) |  Loss2: (0.0000) | Acc: (96.00%) (22292/23168)
Epoch: 168 | Batch_idx: 190 |  Loss: (0.1090) |  Loss2: (0.0000) | Acc: (96.00%) (23520/24448)
Epoch: 168 | Batch_idx: 200 |  Loss: (0.1092) |  Loss2: (0.0000) | Acc: (96.00%) (24753/25728)
Epoch: 168 | Batch_idx: 210 |  Loss: (0.1095) |  Loss2: (0.0000) | Acc: (96.00%) (25982/27008)
Epoch: 168 | Batch_idx: 220 |  Loss: (0.1102) |  Loss2: (0.0000) | Acc: (96.00%) (27196/28288)
Epoch: 168 | Batch_idx: 230 |  Loss: (0.1106) |  Loss2: (0.0000) | Acc: (96.00%) (28425/29568)
Epoch: 168 | Batch_idx: 240 |  Loss: (0.1113) |  Loss2: (0.0000) | Acc: (96.00%) (29645/30848)
Epoch: 168 | Batch_idx: 250 |  Loss: (0.1116) |  Loss2: (0.0000) | Acc: (96.00%) (30872/32128)
Epoch: 168 | Batch_idx: 260 |  Loss: (0.1118) |  Loss2: (0.0000) | Acc: (96.00%) (32110/33408)
Epoch: 168 | Batch_idx: 270 |  Loss: (0.1114) |  Loss2: (0.0000) | Acc: (96.00%) (33353/34688)
Epoch: 168 | Batch_idx: 280 |  Loss: (0.1124) |  Loss2: (0.0000) | Acc: (96.00%) (34574/35968)
Epoch: 168 | Batch_idx: 290 |  Loss: (0.1117) |  Loss2: (0.0000) | Acc: (96.00%) (35812/37248)
Epoch: 168 | Batch_idx: 300 |  Loss: (0.1116) |  Loss2: (0.0000) | Acc: (96.00%) (37043/38528)
Epoch: 168 | Batch_idx: 310 |  Loss: (0.1123) |  Loss2: (0.0000) | Acc: (96.00%) (38259/39808)
Epoch: 168 | Batch_idx: 320 |  Loss: (0.1130) |  Loss2: (0.0000) | Acc: (96.00%) (39479/41088)
Epoch: 168 | Batch_idx: 330 |  Loss: (0.1145) |  Loss2: (0.0000) | Acc: (96.00%) (40684/42368)
Epoch: 168 | Batch_idx: 340 |  Loss: (0.1147) |  Loss2: (0.0000) | Acc: (96.00%) (41914/43648)
Epoch: 168 | Batch_idx: 350 |  Loss: (0.1146) |  Loss2: (0.0000) | Acc: (96.00%) (43149/44928)
Epoch: 168 | Batch_idx: 360 |  Loss: (0.1144) |  Loss2: (0.0000) | Acc: (96.00%) (44375/46208)
Epoch: 168 | Batch_idx: 370 |  Loss: (0.1140) |  Loss2: (0.0000) | Acc: (96.00%) (45610/47488)
Epoch: 168 | Batch_idx: 380 |  Loss: (0.1144) |  Loss2: (0.0000) | Acc: (96.00%) (46831/48768)
Epoch: 168 | Batch_idx: 390 |  Loss: (0.1151) |  Loss2: (0.0000) | Acc: (96.00%) (48001/50000)
# TEST : Loss: (0.4423) | Acc: (87.00%) (8740/10000)
percent tensor([0.5682, 0.5772, 0.6120, 0.5991, 0.6112, 0.5736, 0.5898, 0.6049, 0.5785,
        0.5867, 0.5639, 0.6029, 0.5691, 0.5765, 0.5772, 0.5714],
       device='cuda:0') torch.Size([16])
percent tensor([0.5787, 0.5803, 0.5764, 0.5683, 0.5830, 0.5798, 0.5870, 0.5797, 0.5739,
        0.5788, 0.5798, 0.5839, 0.5762, 0.5742, 0.5841, 0.5783],
       device='cuda:0') torch.Size([16])
percent tensor([0.6155, 0.6226, 0.5786, 0.5569, 0.5603, 0.5846, 0.6049, 0.5693, 0.5993,
        0.6221, 0.6152, 0.5995, 0.6404, 0.6107, 0.6064, 0.6161],
       device='cuda:0') torch.Size([16])
percent tensor([0.6510, 0.6392, 0.6156, 0.6197, 0.6279, 0.6691, 0.6500, 0.6219, 0.6325,
        0.6380, 0.6429, 0.6321, 0.6405, 0.6412, 0.6609, 0.6468],
       device='cuda:0') torch.Size([16])
percent tensor([0.5340, 0.5027, 0.6131, 0.6430, 0.6374, 0.5861, 0.5590, 0.6286, 0.5936,
        0.5178, 0.5517, 0.5701, 0.4456, 0.6126, 0.5911, 0.5569],
       device='cuda:0') torch.Size([16])
percent tensor([0.5373, 0.6834, 0.6771, 0.6692, 0.6826, 0.7322, 0.6440, 0.5561, 0.6889,
        0.6436, 0.7251, 0.6801, 0.6996, 0.7166, 0.5175, 0.5135],
       device='cuda:0') torch.Size([16])
percent tensor([0.6825, 0.7162, 0.7185, 0.6550, 0.6642, 0.7330, 0.7079, 0.6211, 0.6883,
        0.6896, 0.7058, 0.6148, 0.7152, 0.6974, 0.5600, 0.6148],
       device='cuda:0') torch.Size([16])
percent tensor([0.9997, 0.9997, 0.9999, 0.9997, 0.9998, 0.9998, 0.9999, 0.9999, 0.9999,
        0.9999, 0.9999, 0.9997, 0.9997, 0.9997, 0.9998, 0.9995],
       device='cuda:0') torch.Size([16])
Epoch: 169 | Batch_idx: 0 |  Loss: (0.0635) |  Loss2: (0.0000) | Acc: (98.00%) (126/128)
Epoch: 169 | Batch_idx: 10 |  Loss: (0.0952) |  Loss2: (0.0000) | Acc: (96.00%) (1360/1408)
Epoch: 169 | Batch_idx: 20 |  Loss: (0.1000) |  Loss2: (0.0000) | Acc: (96.00%) (2593/2688)
Epoch: 169 | Batch_idx: 30 |  Loss: (0.1008) |  Loss2: (0.0000) | Acc: (96.00%) (3832/3968)
Epoch: 169 | Batch_idx: 40 |  Loss: (0.1024) |  Loss2: (0.0000) | Acc: (96.00%) (5066/5248)
Epoch: 169 | Batch_idx: 50 |  Loss: (0.1011) |  Loss2: (0.0000) | Acc: (96.00%) (6309/6528)
Epoch: 169 | Batch_idx: 60 |  Loss: (0.1008) |  Loss2: (0.0000) | Acc: (96.00%) (7543/7808)
Epoch: 169 | Batch_idx: 70 |  Loss: (0.0999) |  Loss2: (0.0000) | Acc: (96.00%) (8785/9088)
Epoch: 169 | Batch_idx: 80 |  Loss: (0.0983) |  Loss2: (0.0000) | Acc: (96.00%) (10030/10368)
Epoch: 169 | Batch_idx: 90 |  Loss: (0.0977) |  Loss2: (0.0000) | Acc: (96.00%) (11273/11648)
Epoch: 169 | Batch_idx: 100 |  Loss: (0.0964) |  Loss2: (0.0000) | Acc: (96.00%) (12511/12928)
Epoch: 169 | Batch_idx: 110 |  Loss: (0.0969) |  Loss2: (0.0000) | Acc: (96.00%) (13750/14208)
Epoch: 169 | Batch_idx: 120 |  Loss: (0.0962) |  Loss2: (0.0000) | Acc: (96.00%) (14987/15488)
Epoch: 169 | Batch_idx: 130 |  Loss: (0.0965) |  Loss2: (0.0000) | Acc: (96.00%) (16223/16768)
Epoch: 169 | Batch_idx: 140 |  Loss: (0.0969) |  Loss2: (0.0000) | Acc: (96.00%) (17465/18048)
Epoch: 169 | Batch_idx: 150 |  Loss: (0.0988) |  Loss2: (0.0000) | Acc: (96.00%) (18686/19328)
Epoch: 169 | Batch_idx: 160 |  Loss: (0.0981) |  Loss2: (0.0000) | Acc: (96.00%) (19930/20608)
Epoch: 169 | Batch_idx: 170 |  Loss: (0.0997) |  Loss2: (0.0000) | Acc: (96.00%) (21159/21888)
Epoch: 169 | Batch_idx: 180 |  Loss: (0.1001) |  Loss2: (0.0000) | Acc: (96.00%) (22394/23168)
Epoch: 169 | Batch_idx: 190 |  Loss: (0.1019) |  Loss2: (0.0000) | Acc: (96.00%) (23617/24448)
Epoch: 169 | Batch_idx: 200 |  Loss: (0.1029) |  Loss2: (0.0000) | Acc: (96.00%) (24842/25728)
Epoch: 169 | Batch_idx: 210 |  Loss: (0.1033) |  Loss2: (0.0000) | Acc: (96.00%) (26078/27008)
Epoch: 169 | Batch_idx: 220 |  Loss: (0.1025) |  Loss2: (0.0000) | Acc: (96.00%) (27315/28288)
Epoch: 169 | Batch_idx: 230 |  Loss: (0.1033) |  Loss2: (0.0000) | Acc: (96.00%) (28539/29568)
Epoch: 169 | Batch_idx: 240 |  Loss: (0.1030) |  Loss2: (0.0000) | Acc: (96.00%) (29774/30848)
Epoch: 169 | Batch_idx: 250 |  Loss: (0.1027) |  Loss2: (0.0000) | Acc: (96.00%) (31008/32128)
Epoch: 169 | Batch_idx: 260 |  Loss: (0.1039) |  Loss2: (0.0000) | Acc: (96.00%) (32235/33408)
Epoch: 169 | Batch_idx: 270 |  Loss: (0.1035) |  Loss2: (0.0000) | Acc: (96.00%) (33479/34688)
Epoch: 169 | Batch_idx: 280 |  Loss: (0.1034) |  Loss2: (0.0000) | Acc: (96.00%) (34713/35968)
Epoch: 169 | Batch_idx: 290 |  Loss: (0.1034) |  Loss2: (0.0000) | Acc: (96.00%) (35942/37248)
Epoch: 169 | Batch_idx: 300 |  Loss: (0.1033) |  Loss2: (0.0000) | Acc: (96.00%) (37178/38528)
Epoch: 169 | Batch_idx: 310 |  Loss: (0.1031) |  Loss2: (0.0000) | Acc: (96.00%) (38416/39808)
Epoch: 169 | Batch_idx: 320 |  Loss: (0.1040) |  Loss2: (0.0000) | Acc: (96.00%) (39638/41088)
Epoch: 169 | Batch_idx: 330 |  Loss: (0.1041) |  Loss2: (0.0000) | Acc: (96.00%) (40870/42368)
Epoch: 169 | Batch_idx: 340 |  Loss: (0.1044) |  Loss2: (0.0000) | Acc: (96.00%) (42093/43648)
Epoch: 169 | Batch_idx: 350 |  Loss: (0.1048) |  Loss2: (0.0000) | Acc: (96.00%) (43324/44928)
Epoch: 169 | Batch_idx: 360 |  Loss: (0.1055) |  Loss2: (0.0000) | Acc: (96.00%) (44551/46208)
Epoch: 169 | Batch_idx: 370 |  Loss: (0.1054) |  Loss2: (0.0000) | Acc: (96.00%) (45781/47488)
Epoch: 169 | Batch_idx: 380 |  Loss: (0.1055) |  Loss2: (0.0000) | Acc: (96.00%) (47015/48768)
Epoch: 169 | Batch_idx: 390 |  Loss: (0.1059) |  Loss2: (0.0000) | Acc: (96.00%) (48197/50000)
# TEST : Loss: (0.4438) | Acc: (87.00%) (8753/10000)
percent tensor([0.5676, 0.5792, 0.6073, 0.5986, 0.6082, 0.5728, 0.5900, 0.6048, 0.5785,
        0.5859, 0.5650, 0.6002, 0.5693, 0.5802, 0.5782, 0.5719],
       device='cuda:0') torch.Size([16])
percent tensor([0.5785, 0.5804, 0.5752, 0.5682, 0.5822, 0.5790, 0.5874, 0.5794, 0.5746,
        0.5787, 0.5797, 0.5844, 0.5764, 0.5745, 0.5840, 0.5786],
       device='cuda:0') torch.Size([16])
percent tensor([0.6161, 0.6234, 0.5851, 0.5589, 0.5636, 0.5862, 0.6058, 0.5711, 0.6011,
        0.6244, 0.6152, 0.6020, 0.6389, 0.6159, 0.6054, 0.6167],
       device='cuda:0') torch.Size([16])
percent tensor([0.6469, 0.6320, 0.6082, 0.6191, 0.6212, 0.6596, 0.6462, 0.6205, 0.6310,
        0.6337, 0.6412, 0.6289, 0.6359, 0.6363, 0.6529, 0.6457],
       device='cuda:0') torch.Size([16])
percent tensor([0.5371, 0.5020, 0.5937, 0.6197, 0.6238, 0.5753, 0.5640, 0.6211, 0.5949,
        0.5106, 0.5709, 0.5785, 0.4617, 0.6167, 0.5846, 0.5523],
       device='cuda:0') torch.Size([16])
percent tensor([0.5337, 0.6739, 0.6737, 0.6396, 0.6639, 0.7354, 0.6643, 0.5533, 0.6849,
        0.6212, 0.7399, 0.6908, 0.6922, 0.7129, 0.5139, 0.5073],
       device='cuda:0') torch.Size([16])
percent tensor([0.6911, 0.7209, 0.7144, 0.6389, 0.6703, 0.7366, 0.7226, 0.6235, 0.6897,
        0.6948, 0.7324, 0.6272, 0.7313, 0.6996, 0.5798, 0.6228],
       device='cuda:0') torch.Size([16])
percent tensor([0.9997, 0.9997, 0.9999, 0.9998, 0.9998, 0.9996, 0.9999, 0.9999, 0.9999,
        0.9999, 0.9999, 0.9997, 0.9996, 0.9998, 0.9997, 0.9993],
       device='cuda:0') torch.Size([16])
Epoch: 170 | Batch_idx: 0 |  Loss: (0.1089) |  Loss2: (0.0000) | Acc: (96.00%) (124/128)
Epoch: 170 | Batch_idx: 10 |  Loss: (0.1101) |  Loss2: (0.0000) | Acc: (95.00%) (1351/1408)
Epoch: 170 | Batch_idx: 20 |  Loss: (0.1079) |  Loss2: (0.0000) | Acc: (96.00%) (2584/2688)
Epoch: 170 | Batch_idx: 30 |  Loss: (0.1114) |  Loss2: (0.0000) | Acc: (96.00%) (3818/3968)
Epoch: 170 | Batch_idx: 40 |  Loss: (0.1056) |  Loss2: (0.0000) | Acc: (96.00%) (5059/5248)
Epoch: 170 | Batch_idx: 50 |  Loss: (0.1067) |  Loss2: (0.0000) | Acc: (96.00%) (6283/6528)
Epoch: 170 | Batch_idx: 60 |  Loss: (0.1058) |  Loss2: (0.0000) | Acc: (96.00%) (7524/7808)
Epoch: 170 | Batch_idx: 70 |  Loss: (0.1075) |  Loss2: (0.0000) | Acc: (96.00%) (8748/9088)
Epoch: 170 | Batch_idx: 80 |  Loss: (0.1075) |  Loss2: (0.0000) | Acc: (96.00%) (9981/10368)
Epoch: 170 | Batch_idx: 90 |  Loss: (0.1064) |  Loss2: (0.0000) | Acc: (96.00%) (11215/11648)
Epoch: 170 | Batch_idx: 100 |  Loss: (0.1042) |  Loss2: (0.0000) | Acc: (96.00%) (12462/12928)
Epoch: 170 | Batch_idx: 110 |  Loss: (0.1048) |  Loss2: (0.0000) | Acc: (96.00%) (13688/14208)
Epoch: 170 | Batch_idx: 120 |  Loss: (0.1029) |  Loss2: (0.0000) | Acc: (96.00%) (14937/15488)
Epoch: 170 | Batch_idx: 130 |  Loss: (0.1024) |  Loss2: (0.0000) | Acc: (96.00%) (16177/16768)
Epoch: 170 | Batch_idx: 140 |  Loss: (0.1019) |  Loss2: (0.0000) | Acc: (96.00%) (17418/18048)
Epoch: 170 | Batch_idx: 150 |  Loss: (0.1016) |  Loss2: (0.0000) | Acc: (96.00%) (18656/19328)
Epoch: 170 | Batch_idx: 160 |  Loss: (0.1039) |  Loss2: (0.0000) | Acc: (96.00%) (19880/20608)
Epoch: 170 | Batch_idx: 170 |  Loss: (0.1035) |  Loss2: (0.0000) | Acc: (96.00%) (21119/21888)
Epoch: 170 | Batch_idx: 180 |  Loss: (0.1040) |  Loss2: (0.0000) | Acc: (96.00%) (22345/23168)
Epoch: 170 | Batch_idx: 190 |  Loss: (0.1032) |  Loss2: (0.0000) | Acc: (96.00%) (23584/24448)
Epoch: 170 | Batch_idx: 200 |  Loss: (0.1033) |  Loss2: (0.0000) | Acc: (96.00%) (24820/25728)
Epoch: 170 | Batch_idx: 210 |  Loss: (0.1036) |  Loss2: (0.0000) | Acc: (96.00%) (26054/27008)
Epoch: 170 | Batch_idx: 220 |  Loss: (0.1035) |  Loss2: (0.0000) | Acc: (96.00%) (27290/28288)
Epoch: 170 | Batch_idx: 230 |  Loss: (0.1040) |  Loss2: (0.0000) | Acc: (96.00%) (28528/29568)
Epoch: 170 | Batch_idx: 240 |  Loss: (0.1043) |  Loss2: (0.0000) | Acc: (96.00%) (29756/30848)
Epoch: 170 | Batch_idx: 250 |  Loss: (0.1050) |  Loss2: (0.0000) | Acc: (96.00%) (30980/32128)
Epoch: 170 | Batch_idx: 260 |  Loss: (0.1055) |  Loss2: (0.0000) | Acc: (96.00%) (32210/33408)
Epoch: 170 | Batch_idx: 270 |  Loss: (0.1057) |  Loss2: (0.0000) | Acc: (96.00%) (33444/34688)
Epoch: 170 | Batch_idx: 280 |  Loss: (0.1055) |  Loss2: (0.0000) | Acc: (96.00%) (34679/35968)
Epoch: 170 | Batch_idx: 290 |  Loss: (0.1056) |  Loss2: (0.0000) | Acc: (96.00%) (35911/37248)
Epoch: 170 | Batch_idx: 300 |  Loss: (0.1056) |  Loss2: (0.0000) | Acc: (96.00%) (37144/38528)
Epoch: 170 | Batch_idx: 310 |  Loss: (0.1054) |  Loss2: (0.0000) | Acc: (96.00%) (38381/39808)
Epoch: 170 | Batch_idx: 320 |  Loss: (0.1051) |  Loss2: (0.0000) | Acc: (96.00%) (39614/41088)
Epoch: 170 | Batch_idx: 330 |  Loss: (0.1055) |  Loss2: (0.0000) | Acc: (96.00%) (40840/42368)
Epoch: 170 | Batch_idx: 340 |  Loss: (0.1055) |  Loss2: (0.0000) | Acc: (96.00%) (42073/43648)
Epoch: 170 | Batch_idx: 350 |  Loss: (0.1057) |  Loss2: (0.0000) | Acc: (96.00%) (43303/44928)
Epoch: 170 | Batch_idx: 360 |  Loss: (0.1058) |  Loss2: (0.0000) | Acc: (96.00%) (44526/46208)
Epoch: 170 | Batch_idx: 370 |  Loss: (0.1068) |  Loss2: (0.0000) | Acc: (96.00%) (45741/47488)
Epoch: 170 | Batch_idx: 380 |  Loss: (0.1072) |  Loss2: (0.0000) | Acc: (96.00%) (46967/48768)
Epoch: 170 | Batch_idx: 390 |  Loss: (0.1070) |  Loss2: (0.0000) | Acc: (96.00%) (48161/50000)
=> saving checkpoint 'drive/app/torch/save_Schedule/checkpoint_170.pth.tar'
# TEST : Loss: (0.4364) | Acc: (87.00%) (8780/10000)
percent tensor([0.5668, 0.5756, 0.6089, 0.5962, 0.6089, 0.5722, 0.5881, 0.6033, 0.5763,
        0.5849, 0.5625, 0.6007, 0.5677, 0.5744, 0.5761, 0.5698],
       device='cuda:0') torch.Size([16])
percent tensor([0.5777, 0.5801, 0.5738, 0.5672, 0.5806, 0.5774, 0.5858, 0.5795, 0.5739,
        0.5767, 0.5788, 0.5819, 0.5751, 0.5751, 0.5830, 0.5777],
       device='cuda:0') torch.Size([16])
percent tensor([0.6165, 0.6307, 0.5766, 0.5627, 0.5601, 0.5854, 0.6106, 0.5726, 0.6021,
        0.6287, 0.6187, 0.6008, 0.6429, 0.6220, 0.6102, 0.6208],
       device='cuda:0') torch.Size([16])
percent tensor([0.6512, 0.6399, 0.6114, 0.6216, 0.6229, 0.6621, 0.6525, 0.6273, 0.6375,
        0.6381, 0.6474, 0.6303, 0.6420, 0.6465, 0.6580, 0.6505],
       device='cuda:0') torch.Size([16])
percent tensor([0.5341, 0.4850, 0.5928, 0.6206, 0.6269, 0.5655, 0.5509, 0.6255, 0.5813,
        0.5030, 0.5628, 0.5661, 0.4438, 0.6076, 0.5702, 0.5424],
       device='cuda:0') torch.Size([16])
percent tensor([0.5474, 0.6877, 0.6622, 0.6806, 0.6736, 0.7157, 0.6617, 0.6039, 0.7067,
        0.6366, 0.7354, 0.6829, 0.7035, 0.7314, 0.5185, 0.5080],
       device='cuda:0') torch.Size([16])
percent tensor([0.6859, 0.7184, 0.6986, 0.6725, 0.6709, 0.7182, 0.7069, 0.6460, 0.6811,
        0.7037, 0.7037, 0.6284, 0.7194, 0.7058, 0.5662, 0.6145],
       device='cuda:0') torch.Size([16])
percent tensor([0.9997, 0.9997, 0.9998, 0.9996, 0.9998, 0.9997, 0.9998, 0.9999, 0.9999,
        0.9999, 0.9999, 0.9997, 0.9997, 0.9998, 0.9998, 0.9995],
       device='cuda:0') torch.Size([16])
Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 3, 3, 3]) tensor(189.7757, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(823.1816, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(843.9135, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([128, 64, 3, 3]) tensor(1524.6907, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([128, 64, 1, 1]) tensor(487.1886, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([128, 128, 3, 3]) tensor(2280.5393, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([256, 128, 3, 3]) tensor(4250.8755, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([256, 128, 1, 1]) tensor(1355.7441, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([256, 256, 3, 3]) tensor(6230.0396, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([512, 256, 3, 3]) tensor(11629.7461, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([512, 256, 1, 1]) tensor(3833.8406, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([512, 512, 3, 3]) tensor(16184.5156, device='cuda:0', grad_fn=<NormBackward0>)
Epoch: 171 | Batch_idx: 0 |  Loss: (0.0924) |  Loss2: (0.0000) | Acc: (96.00%) (123/128)
Epoch: 171 | Batch_idx: 10 |  Loss: (0.0927) |  Loss2: (0.0000) | Acc: (96.00%) (1363/1408)
Epoch: 171 | Batch_idx: 20 |  Loss: (0.0988) |  Loss2: (0.0000) | Acc: (96.00%) (2596/2688)
Epoch: 171 | Batch_idx: 30 |  Loss: (0.0909) |  Loss2: (0.0000) | Acc: (96.00%) (3842/3968)
Epoch: 171 | Batch_idx: 40 |  Loss: (0.0938) |  Loss2: (0.0000) | Acc: (96.00%) (5079/5248)
Epoch: 171 | Batch_idx: 50 |  Loss: (0.0980) |  Loss2: (0.0000) | Acc: (96.00%) (6300/6528)
Epoch: 171 | Batch_idx: 60 |  Loss: (0.0989) |  Loss2: (0.0000) | Acc: (96.00%) (7534/7808)
Epoch: 171 | Batch_idx: 70 |  Loss: (0.0962) |  Loss2: (0.0000) | Acc: (96.00%) (8784/9088)
Epoch: 171 | Batch_idx: 80 |  Loss: (0.0960) |  Loss2: (0.0000) | Acc: (96.00%) (10028/10368)
Epoch: 171 | Batch_idx: 90 |  Loss: (0.0973) |  Loss2: (0.0000) | Acc: (96.00%) (11263/11648)
Epoch: 171 | Batch_idx: 100 |  Loss: (0.0987) |  Loss2: (0.0000) | Acc: (96.00%) (12500/12928)
Epoch: 171 | Batch_idx: 110 |  Loss: (0.1003) |  Loss2: (0.0000) | Acc: (96.00%) (13732/14208)
Epoch: 171 | Batch_idx: 120 |  Loss: (0.1006) |  Loss2: (0.0000) | Acc: (96.00%) (14967/15488)
Epoch: 171 | Batch_idx: 130 |  Loss: (0.1011) |  Loss2: (0.0000) | Acc: (96.00%) (16200/16768)
Epoch: 171 | Batch_idx: 140 |  Loss: (0.1004) |  Loss2: (0.0000) | Acc: (96.00%) (17439/18048)
Epoch: 171 | Batch_idx: 150 |  Loss: (0.1014) |  Loss2: (0.0000) | Acc: (96.00%) (18662/19328)
Epoch: 171 | Batch_idx: 160 |  Loss: (0.1017) |  Loss2: (0.0000) | Acc: (96.00%) (19894/20608)
Epoch: 171 | Batch_idx: 170 |  Loss: (0.1013) |  Loss2: (0.0000) | Acc: (96.00%) (21137/21888)
Epoch: 171 | Batch_idx: 180 |  Loss: (0.1015) |  Loss2: (0.0000) | Acc: (96.00%) (22372/23168)
Epoch: 171 | Batch_idx: 190 |  Loss: (0.1010) |  Loss2: (0.0000) | Acc: (96.00%) (23616/24448)
Epoch: 171 | Batch_idx: 200 |  Loss: (0.1020) |  Loss2: (0.0000) | Acc: (96.00%) (24838/25728)
Epoch: 171 | Batch_idx: 210 |  Loss: (0.1023) |  Loss2: (0.0000) | Acc: (96.00%) (26070/27008)
Epoch: 171 | Batch_idx: 220 |  Loss: (0.1027) |  Loss2: (0.0000) | Acc: (96.00%) (27295/28288)
Epoch: 171 | Batch_idx: 230 |  Loss: (0.1032) |  Loss2: (0.0000) | Acc: (96.00%) (28525/29568)
Epoch: 171 | Batch_idx: 240 |  Loss: (0.1025) |  Loss2: (0.0000) | Acc: (96.00%) (29771/30848)
Epoch: 171 | Batch_idx: 250 |  Loss: (0.1028) |  Loss2: (0.0000) | Acc: (96.00%) (30996/32128)
Epoch: 171 | Batch_idx: 260 |  Loss: (0.1028) |  Loss2: (0.0000) | Acc: (96.00%) (32230/33408)
Epoch: 171 | Batch_idx: 270 |  Loss: (0.1030) |  Loss2: (0.0000) | Acc: (96.00%) (33461/34688)
Epoch: 171 | Batch_idx: 280 |  Loss: (0.1031) |  Loss2: (0.0000) | Acc: (96.00%) (34693/35968)
Epoch: 171 | Batch_idx: 290 |  Loss: (0.1031) |  Loss2: (0.0000) | Acc: (96.00%) (35926/37248)
Epoch: 171 | Batch_idx: 300 |  Loss: (0.1026) |  Loss2: (0.0000) | Acc: (96.00%) (37173/38528)
Epoch: 171 | Batch_idx: 310 |  Loss: (0.1029) |  Loss2: (0.0000) | Acc: (96.00%) (38407/39808)
Epoch: 171 | Batch_idx: 320 |  Loss: (0.1032) |  Loss2: (0.0000) | Acc: (96.00%) (39633/41088)
Epoch: 171 | Batch_idx: 330 |  Loss: (0.1031) |  Loss2: (0.0000) | Acc: (96.00%) (40867/42368)
Epoch: 171 | Batch_idx: 340 |  Loss: (0.1029) |  Loss2: (0.0000) | Acc: (96.00%) (42104/43648)
Epoch: 171 | Batch_idx: 350 |  Loss: (0.1037) |  Loss2: (0.0000) | Acc: (96.00%) (43324/44928)
Epoch: 171 | Batch_idx: 360 |  Loss: (0.1036) |  Loss2: (0.0000) | Acc: (96.00%) (44562/46208)
Epoch: 171 | Batch_idx: 370 |  Loss: (0.1048) |  Loss2: (0.0000) | Acc: (96.00%) (45775/47488)
Epoch: 171 | Batch_idx: 380 |  Loss: (0.1050) |  Loss2: (0.0000) | Acc: (96.00%) (47008/48768)
Epoch: 171 | Batch_idx: 390 |  Loss: (0.1047) |  Loss2: (0.0000) | Acc: (96.00%) (48208/50000)
# TEST : Loss: (0.4179) | Acc: (88.00%) (8820/10000)
percent tensor([0.5672, 0.5776, 0.6048, 0.5970, 0.6069, 0.5728, 0.5885, 0.6025, 0.5768,
        0.5847, 0.5635, 0.5985, 0.5681, 0.5780, 0.5776, 0.5711],
       device='cuda:0') torch.Size([16])
percent tensor([0.5786, 0.5804, 0.5753, 0.5696, 0.5817, 0.5781, 0.5861, 0.5810, 0.5743,
        0.5786, 0.5798, 0.5834, 0.5762, 0.5748, 0.5835, 0.5780],
       device='cuda:0') torch.Size([16])
percent tensor([0.6150, 0.6261, 0.5802, 0.5574, 0.5632, 0.5849, 0.6090, 0.5710, 0.5989,
        0.6250, 0.6167, 0.6008, 0.6394, 0.6130, 0.6076, 0.6182],
       device='cuda:0') torch.Size([16])
percent tensor([0.6485, 0.6381, 0.6115, 0.6215, 0.6240, 0.6611, 0.6493, 0.6271, 0.6376,
        0.6383, 0.6428, 0.6321, 0.6405, 0.6422, 0.6548, 0.6476],
       device='cuda:0') torch.Size([16])
percent tensor([0.5342, 0.5044, 0.5868, 0.6314, 0.6191, 0.5704, 0.5482, 0.6250, 0.5830,
        0.5203, 0.5528, 0.5694, 0.4505, 0.6128, 0.5766, 0.5502],
       device='cuda:0') torch.Size([16])
percent tensor([0.5577, 0.6901, 0.6651, 0.6524, 0.6634, 0.7325, 0.6546, 0.5774, 0.6923,
        0.6397, 0.7304, 0.6645, 0.6957, 0.6828, 0.5155, 0.5288],
       device='cuda:0') torch.Size([16])
percent tensor([0.7024, 0.7303, 0.7080, 0.6551, 0.6605, 0.7228, 0.7139, 0.6332, 0.6904,
        0.6966, 0.7183, 0.6168, 0.7294, 0.6872, 0.5808, 0.6243],
       device='cuda:0') torch.Size([16])
percent tensor([0.9998, 0.9997, 0.9998, 0.9997, 0.9997, 0.9998, 0.9999, 0.9999, 0.9999,
        0.9999, 0.9999, 0.9998, 0.9996, 0.9997, 0.9997, 0.9995],
       device='cuda:0') torch.Size([16])
Epoch: 172 | Batch_idx: 0 |  Loss: (0.0447) |  Loss2: (0.0000) | Acc: (99.00%) (127/128)
Epoch: 172 | Batch_idx: 10 |  Loss: (0.0773) |  Loss2: (0.0000) | Acc: (97.00%) (1376/1408)
Epoch: 172 | Batch_idx: 20 |  Loss: (0.0894) |  Loss2: (0.0000) | Acc: (97.00%) (2609/2688)
Epoch: 172 | Batch_idx: 30 |  Loss: (0.0940) |  Loss2: (0.0000) | Acc: (96.00%) (3843/3968)
Epoch: 172 | Batch_idx: 40 |  Loss: (0.0962) |  Loss2: (0.0000) | Acc: (96.00%) (5079/5248)
Epoch: 172 | Batch_idx: 50 |  Loss: (0.0965) |  Loss2: (0.0000) | Acc: (96.00%) (6314/6528)
Epoch: 172 | Batch_idx: 60 |  Loss: (0.0964) |  Loss2: (0.0000) | Acc: (96.00%) (7554/7808)
Epoch: 172 | Batch_idx: 70 |  Loss: (0.0965) |  Loss2: (0.0000) | Acc: (96.00%) (8794/9088)
Epoch: 172 | Batch_idx: 80 |  Loss: (0.0962) |  Loss2: (0.0000) | Acc: (96.00%) (10037/10368)
Epoch: 172 | Batch_idx: 90 |  Loss: (0.0944) |  Loss2: (0.0000) | Acc: (96.00%) (11281/11648)
Epoch: 172 | Batch_idx: 100 |  Loss: (0.0943) |  Loss2: (0.0000) | Acc: (96.00%) (12520/12928)
Epoch: 172 | Batch_idx: 110 |  Loss: (0.0949) |  Loss2: (0.0000) | Acc: (96.00%) (13748/14208)
Epoch: 172 | Batch_idx: 120 |  Loss: (0.0952) |  Loss2: (0.0000) | Acc: (96.00%) (14979/15488)
Epoch: 172 | Batch_idx: 130 |  Loss: (0.0967) |  Loss2: (0.0000) | Acc: (96.00%) (16205/16768)
Epoch: 172 | Batch_idx: 140 |  Loss: (0.0975) |  Loss2: (0.0000) | Acc: (96.00%) (17444/18048)
Epoch: 172 | Batch_idx: 150 |  Loss: (0.0972) |  Loss2: (0.0000) | Acc: (96.00%) (18678/19328)
Epoch: 172 | Batch_idx: 160 |  Loss: (0.0970) |  Loss2: (0.0000) | Acc: (96.00%) (19917/20608)
Epoch: 172 | Batch_idx: 170 |  Loss: (0.0967) |  Loss2: (0.0000) | Acc: (96.00%) (21159/21888)
Epoch: 172 | Batch_idx: 180 |  Loss: (0.0966) |  Loss2: (0.0000) | Acc: (96.00%) (22396/23168)
Epoch: 172 | Batch_idx: 190 |  Loss: (0.0969) |  Loss2: (0.0000) | Acc: (96.00%) (23631/24448)
Epoch: 172 | Batch_idx: 200 |  Loss: (0.0983) |  Loss2: (0.0000) | Acc: (96.00%) (24867/25728)
Epoch: 172 | Batch_idx: 210 |  Loss: (0.0984) |  Loss2: (0.0000) | Acc: (96.00%) (26099/27008)
Epoch: 172 | Batch_idx: 220 |  Loss: (0.0991) |  Loss2: (0.0000) | Acc: (96.00%) (27330/28288)
Epoch: 172 | Batch_idx: 230 |  Loss: (0.0993) |  Loss2: (0.0000) | Acc: (96.00%) (28563/29568)
Epoch: 172 | Batch_idx: 240 |  Loss: (0.0996) |  Loss2: (0.0000) | Acc: (96.00%) (29792/30848)
Epoch: 172 | Batch_idx: 250 |  Loss: (0.0996) |  Loss2: (0.0000) | Acc: (96.00%) (31031/32128)
Epoch: 172 | Batch_idx: 260 |  Loss: (0.1001) |  Loss2: (0.0000) | Acc: (96.00%) (32258/33408)
Epoch: 172 | Batch_idx: 270 |  Loss: (0.1000) |  Loss2: (0.0000) | Acc: (96.00%) (33501/34688)
Epoch: 172 | Batch_idx: 280 |  Loss: (0.1001) |  Loss2: (0.0000) | Acc: (96.00%) (34741/35968)
Epoch: 172 | Batch_idx: 290 |  Loss: (0.1005) |  Loss2: (0.0000) | Acc: (96.00%) (35968/37248)
Epoch: 172 | Batch_idx: 300 |  Loss: (0.1006) |  Loss2: (0.0000) | Acc: (96.00%) (37198/38528)
Epoch: 172 | Batch_idx: 310 |  Loss: (0.1008) |  Loss2: (0.0000) | Acc: (96.00%) (38429/39808)
Epoch: 172 | Batch_idx: 320 |  Loss: (0.1001) |  Loss2: (0.0000) | Acc: (96.00%) (39676/41088)
Epoch: 172 | Batch_idx: 330 |  Loss: (0.1004) |  Loss2: (0.0000) | Acc: (96.00%) (40908/42368)
Epoch: 172 | Batch_idx: 340 |  Loss: (0.1007) |  Loss2: (0.0000) | Acc: (96.00%) (42135/43648)
Epoch: 172 | Batch_idx: 350 |  Loss: (0.1005) |  Loss2: (0.0000) | Acc: (96.00%) (43374/44928)
Epoch: 172 | Batch_idx: 360 |  Loss: (0.1004) |  Loss2: (0.0000) | Acc: (96.00%) (44611/46208)
Epoch: 172 | Batch_idx: 370 |  Loss: (0.1004) |  Loss2: (0.0000) | Acc: (96.00%) (45838/47488)
Epoch: 172 | Batch_idx: 380 |  Loss: (0.1005) |  Loss2: (0.0000) | Acc: (96.00%) (47069/48768)
Epoch: 172 | Batch_idx: 390 |  Loss: (0.1009) |  Loss2: (0.0000) | Acc: (96.00%) (48251/50000)
# TEST : Loss: (0.4116) | Acc: (88.00%) (8836/10000)
percent tensor([0.5662, 0.5792, 0.6018, 0.5967, 0.6037, 0.5732, 0.5888, 0.6022, 0.5769,
        0.5848, 0.5638, 0.5962, 0.5681, 0.5824, 0.5778, 0.5714],
       device='cuda:0') torch.Size([16])
percent tensor([0.5775, 0.5789, 0.5757, 0.5681, 0.5826, 0.5768, 0.5856, 0.5805, 0.5729,
        0.5770, 0.5776, 0.5833, 0.5744, 0.5735, 0.5819, 0.5769],
       device='cuda:0') torch.Size([16])
percent tensor([0.6158, 0.6273, 0.5801, 0.5556, 0.5597, 0.5800, 0.6102, 0.5697, 0.6005,
        0.6272, 0.6163, 0.6018, 0.6406, 0.6177, 0.6050, 0.6167],
       device='cuda:0') torch.Size([16])
percent tensor([0.6487, 0.6369, 0.6118, 0.6168, 0.6250, 0.6570, 0.6498, 0.6247, 0.6358,
        0.6386, 0.6420, 0.6324, 0.6417, 0.6430, 0.6515, 0.6470],
       device='cuda:0') torch.Size([16])
percent tensor([0.5398, 0.4910, 0.6029, 0.6437, 0.6349, 0.5788, 0.5564, 0.6330, 0.6007,
        0.5141, 0.5559, 0.5707, 0.4542, 0.6160, 0.5846, 0.5578],
       device='cuda:0') torch.Size([16])
percent tensor([0.5254, 0.6820, 0.6548, 0.6399, 0.6710, 0.7154, 0.6395, 0.5692, 0.6941,
        0.6437, 0.7254, 0.6708, 0.6810, 0.7023, 0.4861, 0.4723],
       device='cuda:0') torch.Size([16])
percent tensor([0.6720, 0.7372, 0.7012, 0.6267, 0.6637, 0.7171, 0.7112, 0.6148, 0.6926,
        0.7054, 0.7300, 0.6241, 0.7191, 0.7119, 0.5629, 0.6189],
       device='cuda:0') torch.Size([16])
percent tensor([0.9997, 0.9998, 0.9998, 0.9997, 0.9997, 0.9996, 0.9999, 0.9999, 0.9999,
        0.9999, 0.9999, 0.9997, 0.9998, 0.9997, 0.9998, 0.9995],
       device='cuda:0') torch.Size([16])
Epoch: 173 | Batch_idx: 0 |  Loss: (0.1279) |  Loss2: (0.0000) | Acc: (95.00%) (122/128)
Epoch: 173 | Batch_idx: 10 |  Loss: (0.0909) |  Loss2: (0.0000) | Acc: (97.00%) (1368/1408)
Epoch: 173 | Batch_idx: 20 |  Loss: (0.0876) |  Loss2: (0.0000) | Acc: (97.00%) (2611/2688)
Epoch: 173 | Batch_idx: 30 |  Loss: (0.0889) |  Loss2: (0.0000) | Acc: (96.00%) (3848/3968)
Epoch: 173 | Batch_idx: 40 |  Loss: (0.0932) |  Loss2: (0.0000) | Acc: (96.00%) (5076/5248)
Epoch: 173 | Batch_idx: 50 |  Loss: (0.0936) |  Loss2: (0.0000) | Acc: (96.00%) (6314/6528)
Epoch: 173 | Batch_idx: 60 |  Loss: (0.0932) |  Loss2: (0.0000) | Acc: (96.00%) (7554/7808)
Epoch: 173 | Batch_idx: 70 |  Loss: (0.0966) |  Loss2: (0.0000) | Acc: (96.00%) (8789/9088)
Epoch: 173 | Batch_idx: 80 |  Loss: (0.0947) |  Loss2: (0.0000) | Acc: (96.00%) (10032/10368)
Epoch: 173 | Batch_idx: 90 |  Loss: (0.0958) |  Loss2: (0.0000) | Acc: (96.00%) (11267/11648)
Epoch: 173 | Batch_idx: 100 |  Loss: (0.0944) |  Loss2: (0.0000) | Acc: (96.00%) (12519/12928)
Epoch: 173 | Batch_idx: 110 |  Loss: (0.0926) |  Loss2: (0.0000) | Acc: (96.00%) (13769/14208)
Epoch: 173 | Batch_idx: 120 |  Loss: (0.0924) |  Loss2: (0.0000) | Acc: (96.00%) (15006/15488)
Epoch: 173 | Batch_idx: 130 |  Loss: (0.0931) |  Loss2: (0.0000) | Acc: (96.00%) (16238/16768)
Epoch: 173 | Batch_idx: 140 |  Loss: (0.0932) |  Loss2: (0.0000) | Acc: (96.00%) (17475/18048)
Epoch: 173 | Batch_idx: 150 |  Loss: (0.0946) |  Loss2: (0.0000) | Acc: (96.00%) (18708/19328)
Epoch: 173 | Batch_idx: 160 |  Loss: (0.0950) |  Loss2: (0.0000) | Acc: (96.00%) (19945/20608)
Epoch: 173 | Batch_idx: 170 |  Loss: (0.0956) |  Loss2: (0.0000) | Acc: (96.00%) (21182/21888)
Epoch: 173 | Batch_idx: 180 |  Loss: (0.0965) |  Loss2: (0.0000) | Acc: (96.00%) (22413/23168)
Epoch: 173 | Batch_idx: 190 |  Loss: (0.0969) |  Loss2: (0.0000) | Acc: (96.00%) (23650/24448)
Epoch: 173 | Batch_idx: 200 |  Loss: (0.0972) |  Loss2: (0.0000) | Acc: (96.00%) (24884/25728)
Epoch: 173 | Batch_idx: 210 |  Loss: (0.0972) |  Loss2: (0.0000) | Acc: (96.00%) (26122/27008)
Epoch: 173 | Batch_idx: 220 |  Loss: (0.0978) |  Loss2: (0.0000) | Acc: (96.00%) (27353/28288)
Epoch: 173 | Batch_idx: 230 |  Loss: (0.0983) |  Loss2: (0.0000) | Acc: (96.00%) (28586/29568)
Epoch: 173 | Batch_idx: 240 |  Loss: (0.0984) |  Loss2: (0.0000) | Acc: (96.00%) (29827/30848)
Epoch: 173 | Batch_idx: 250 |  Loss: (0.0986) |  Loss2: (0.0000) | Acc: (96.00%) (31053/32128)
Epoch: 173 | Batch_idx: 260 |  Loss: (0.0982) |  Loss2: (0.0000) | Acc: (96.00%) (32297/33408)
Epoch: 173 | Batch_idx: 270 |  Loss: (0.0975) |  Loss2: (0.0000) | Acc: (96.00%) (33547/34688)
Epoch: 173 | Batch_idx: 280 |  Loss: (0.0978) |  Loss2: (0.0000) | Acc: (96.00%) (34780/35968)
Epoch: 173 | Batch_idx: 290 |  Loss: (0.0979) |  Loss2: (0.0000) | Acc: (96.00%) (36026/37248)
Epoch: 173 | Batch_idx: 300 |  Loss: (0.0980) |  Loss2: (0.0000) | Acc: (96.00%) (37258/38528)
Epoch: 173 | Batch_idx: 310 |  Loss: (0.0977) |  Loss2: (0.0000) | Acc: (96.00%) (38505/39808)
Epoch: 173 | Batch_idx: 320 |  Loss: (0.0978) |  Loss2: (0.0000) | Acc: (96.00%) (39739/41088)
Epoch: 173 | Batch_idx: 330 |  Loss: (0.0981) |  Loss2: (0.0000) | Acc: (96.00%) (40970/42368)
Epoch: 173 | Batch_idx: 340 |  Loss: (0.0981) |  Loss2: (0.0000) | Acc: (96.00%) (42209/43648)
Epoch: 173 | Batch_idx: 350 |  Loss: (0.0981) |  Loss2: (0.0000) | Acc: (96.00%) (43448/44928)
Epoch: 173 | Batch_idx: 360 |  Loss: (0.0982) |  Loss2: (0.0000) | Acc: (96.00%) (44681/46208)
Epoch: 173 | Batch_idx: 370 |  Loss: (0.0983) |  Loss2: (0.0000) | Acc: (96.00%) (45919/47488)
Epoch: 173 | Batch_idx: 380 |  Loss: (0.0985) |  Loss2: (0.0000) | Acc: (96.00%) (47145/48768)
Epoch: 173 | Batch_idx: 390 |  Loss: (0.0985) |  Loss2: (0.0000) | Acc: (96.00%) (48342/50000)
# TEST : Loss: (0.4472) | Acc: (87.00%) (8774/10000)
percent tensor([0.5671, 0.5778, 0.6080, 0.5978, 0.6077, 0.5738, 0.5890, 0.6028, 0.5778,
        0.5854, 0.5645, 0.6000, 0.5680, 0.5782, 0.5774, 0.5714],
       device='cuda:0') torch.Size([16])
percent tensor([0.5786, 0.5820, 0.5749, 0.5690, 0.5817, 0.5782, 0.5871, 0.5796, 0.5754,
        0.5787, 0.5804, 0.5833, 0.5759, 0.5775, 0.5837, 0.5788],
       device='cuda:0') torch.Size([16])
percent tensor([0.6160, 0.6258, 0.5799, 0.5566, 0.5632, 0.5854, 0.6109, 0.5746, 0.6013,
        0.6261, 0.6169, 0.6014, 0.6418, 0.6211, 0.6086, 0.6192],
       device='cuda:0') torch.Size([16])
percent tensor([0.6499, 0.6439, 0.6147, 0.6193, 0.6249, 0.6638, 0.6537, 0.6242, 0.6394,
        0.6407, 0.6496, 0.6331, 0.6428, 0.6507, 0.6573, 0.6483],
       device='cuda:0') torch.Size([16])
percent tensor([0.5466, 0.5193, 0.5977, 0.6400, 0.6275, 0.5730, 0.5676, 0.6283, 0.5943,
        0.5247, 0.5633, 0.5741, 0.4642, 0.6225, 0.5922, 0.5587],
       device='cuda:0') torch.Size([16])
percent tensor([0.5345, 0.7130, 0.6688, 0.6667, 0.6807, 0.7234, 0.6861, 0.5640, 0.6805,
        0.6474, 0.7279, 0.6806, 0.6871, 0.7207, 0.5006, 0.5354],
       device='cuda:0') torch.Size([16])
percent tensor([0.6790, 0.7341, 0.6948, 0.6366, 0.6510, 0.7159, 0.7140, 0.6034, 0.6739,
        0.6863, 0.7183, 0.6377, 0.7150, 0.7140, 0.5611, 0.6344],
       device='cuda:0') torch.Size([16])
percent tensor([0.9996, 0.9996, 0.9998, 0.9997, 0.9998, 0.9995, 0.9999, 0.9999, 0.9999,
        0.9998, 0.9999, 0.9996, 0.9997, 0.9996, 0.9997, 0.9995],
       device='cuda:0') torch.Size([16])
Epoch: 174 | Batch_idx: 0 |  Loss: (0.0450) |  Loss2: (0.0000) | Acc: (99.00%) (127/128)
Epoch: 174 | Batch_idx: 10 |  Loss: (0.0770) |  Loss2: (0.0000) | Acc: (97.00%) (1373/1408)
Epoch: 174 | Batch_idx: 20 |  Loss: (0.0828) |  Loss2: (0.0000) | Acc: (97.00%) (2613/2688)
Epoch: 174 | Batch_idx: 30 |  Loss: (0.0874) |  Loss2: (0.0000) | Acc: (97.00%) (3852/3968)
Epoch: 174 | Batch_idx: 40 |  Loss: (0.0871) |  Loss2: (0.0000) | Acc: (97.00%) (5096/5248)
Epoch: 174 | Batch_idx: 50 |  Loss: (0.0851) |  Loss2: (0.0000) | Acc: (97.00%) (6349/6528)
Epoch: 174 | Batch_idx: 60 |  Loss: (0.0836) |  Loss2: (0.0000) | Acc: (97.00%) (7600/7808)
Epoch: 174 | Batch_idx: 70 |  Loss: (0.0856) |  Loss2: (0.0000) | Acc: (97.00%) (8840/9088)
Epoch: 174 | Batch_idx: 80 |  Loss: (0.0859) |  Loss2: (0.0000) | Acc: (97.00%) (10081/10368)
Epoch: 174 | Batch_idx: 90 |  Loss: (0.0853) |  Loss2: (0.0000) | Acc: (97.00%) (11322/11648)
Epoch: 174 | Batch_idx: 100 |  Loss: (0.0890) |  Loss2: (0.0000) | Acc: (97.00%) (12544/12928)
Epoch: 174 | Batch_idx: 110 |  Loss: (0.0894) |  Loss2: (0.0000) | Acc: (96.00%) (13780/14208)
Epoch: 174 | Batch_idx: 120 |  Loss: (0.0885) |  Loss2: (0.0000) | Acc: (97.00%) (15028/15488)
Epoch: 174 | Batch_idx: 130 |  Loss: (0.0889) |  Loss2: (0.0000) | Acc: (97.00%) (16268/16768)
Epoch: 174 | Batch_idx: 140 |  Loss: (0.0892) |  Loss2: (0.0000) | Acc: (97.00%) (17510/18048)
Epoch: 174 | Batch_idx: 150 |  Loss: (0.0907) |  Loss2: (0.0000) | Acc: (96.00%) (18744/19328)
Epoch: 174 | Batch_idx: 160 |  Loss: (0.0920) |  Loss2: (0.0000) | Acc: (96.00%) (19973/20608)
Epoch: 174 | Batch_idx: 170 |  Loss: (0.0931) |  Loss2: (0.0000) | Acc: (96.00%) (21206/21888)
Epoch: 174 | Batch_idx: 180 |  Loss: (0.0942) |  Loss2: (0.0000) | Acc: (96.00%) (22434/23168)
Epoch: 174 | Batch_idx: 190 |  Loss: (0.0940) |  Loss2: (0.0000) | Acc: (96.00%) (23672/24448)
Epoch: 174 | Batch_idx: 200 |  Loss: (0.0956) |  Loss2: (0.0000) | Acc: (96.00%) (24896/25728)
Epoch: 174 | Batch_idx: 210 |  Loss: (0.0952) |  Loss2: (0.0000) | Acc: (96.00%) (26137/27008)
Epoch: 174 | Batch_idx: 220 |  Loss: (0.0951) |  Loss2: (0.0000) | Acc: (96.00%) (27378/28288)
Epoch: 174 | Batch_idx: 230 |  Loss: (0.0960) |  Loss2: (0.0000) | Acc: (96.00%) (28608/29568)
Epoch: 174 | Batch_idx: 240 |  Loss: (0.0958) |  Loss2: (0.0000) | Acc: (96.00%) (29851/30848)
Epoch: 174 | Batch_idx: 250 |  Loss: (0.0963) |  Loss2: (0.0000) | Acc: (96.00%) (31080/32128)
Epoch: 174 | Batch_idx: 260 |  Loss: (0.0959) |  Loss2: (0.0000) | Acc: (96.00%) (32321/33408)
Epoch: 174 | Batch_idx: 270 |  Loss: (0.0960) |  Loss2: (0.0000) | Acc: (96.00%) (33556/34688)
Epoch: 174 | Batch_idx: 280 |  Loss: (0.0957) |  Loss2: (0.0000) | Acc: (96.00%) (34797/35968)
Epoch: 174 | Batch_idx: 290 |  Loss: (0.0959) |  Loss2: (0.0000) | Acc: (96.00%) (36026/37248)
Epoch: 174 | Batch_idx: 300 |  Loss: (0.0960) |  Loss2: (0.0000) | Acc: (96.00%) (37261/38528)
Epoch: 174 | Batch_idx: 310 |  Loss: (0.0961) |  Loss2: (0.0000) | Acc: (96.00%) (38503/39808)
Epoch: 174 | Batch_idx: 320 |  Loss: (0.0957) |  Loss2: (0.0000) | Acc: (96.00%) (39748/41088)
Epoch: 174 | Batch_idx: 330 |  Loss: (0.0957) |  Loss2: (0.0000) | Acc: (96.00%) (40987/42368)
Epoch: 174 | Batch_idx: 340 |  Loss: (0.0956) |  Loss2: (0.0000) | Acc: (96.00%) (42222/43648)
Epoch: 174 | Batch_idx: 350 |  Loss: (0.0956) |  Loss2: (0.0000) | Acc: (96.00%) (43456/44928)
Epoch: 174 | Batch_idx: 360 |  Loss: (0.0956) |  Loss2: (0.0000) | Acc: (96.00%) (44690/46208)
Epoch: 174 | Batch_idx: 370 |  Loss: (0.0958) |  Loss2: (0.0000) | Acc: (96.00%) (45925/47488)
Epoch: 174 | Batch_idx: 380 |  Loss: (0.0953) |  Loss2: (0.0000) | Acc: (96.00%) (47173/48768)
Epoch: 174 | Batch_idx: 390 |  Loss: (0.0955) |  Loss2: (0.0000) | Acc: (96.00%) (48359/50000)
# TEST : Loss: (0.4504) | Acc: (87.00%) (8763/10000)
percent tensor([0.5678, 0.5777, 0.6110, 0.5996, 0.6116, 0.5737, 0.5908, 0.6055, 0.5796,
        0.5870, 0.5640, 0.6033, 0.5692, 0.5782, 0.5777, 0.5724],
       device='cuda:0') torch.Size([16])
percent tensor([0.5779, 0.5813, 0.5769, 0.5711, 0.5829, 0.5780, 0.5867, 0.5814, 0.5736,
        0.5790, 0.5786, 0.5855, 0.5758, 0.5750, 0.5847, 0.5784],
       device='cuda:0') torch.Size([16])
percent tensor([0.6172, 0.6252, 0.5842, 0.5605, 0.5635, 0.5859, 0.6071, 0.5742, 0.5990,
        0.6252, 0.6172, 0.6018, 0.6419, 0.6093, 0.6077, 0.6191],
       device='cuda:0') torch.Size([16])
percent tensor([0.6504, 0.6394, 0.6148, 0.6229, 0.6268, 0.6616, 0.6500, 0.6249, 0.6361,
        0.6407, 0.6459, 0.6324, 0.6422, 0.6396, 0.6563, 0.6493],
       device='cuda:0') torch.Size([16])
percent tensor([0.5355, 0.5015, 0.5951, 0.6186, 0.6269, 0.5724, 0.5656, 0.6151, 0.5902,
        0.5054, 0.5573, 0.5686, 0.4508, 0.6244, 0.5819, 0.5507],
       device='cuda:0') torch.Size([16])
percent tensor([0.5466, 0.7010, 0.6854, 0.6700, 0.6789, 0.7266, 0.6572, 0.5943, 0.6941,
        0.6658, 0.7416, 0.6913, 0.7033, 0.7132, 0.5484, 0.5181],
       device='cuda:0') torch.Size([16])
percent tensor([0.6750, 0.7154, 0.7143, 0.6388, 0.6645, 0.7073, 0.7234, 0.6318, 0.6820,
        0.6890, 0.7040, 0.6165, 0.7073, 0.7066, 0.5594, 0.6164],
       device='cuda:0') torch.Size([16])
percent tensor([0.9996, 0.9998, 0.9999, 0.9998, 0.9996, 0.9994, 0.9999, 0.9999, 0.9999,
        0.9999, 0.9999, 0.9998, 0.9997, 0.9999, 0.9998, 0.9994],
       device='cuda:0') torch.Size([16])
False Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=128, out_features=16, bias=False)
True Linear(in_features=16, out_features=2, bias=False)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=128, out_features=16, bias=False)
True Linear(in_features=16, out_features=2, bias=False)
False Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=256, out_features=32, bias=False)
True Linear(in_features=32, out_features=2, bias=False)
False Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=256, out_features=32, bias=False)
True Linear(in_features=32, out_features=2, bias=False)
False Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=512, out_features=64, bias=False)
True Linear(in_features=64, out_features=2, bias=False)
False Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=512, out_features=64, bias=False)
True Linear(in_features=64, out_features=2, bias=False)
False Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1024, out_features=128, bias=False)
True Linear(in_features=128, out_features=2, bias=False)
False Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1024, out_features=128, bias=False)
True Linear(in_features=128, out_features=2, bias=False)
False Linear(in_features=512, out_features=10, bias=True)
Epoch: 175 | Batch_idx: 0 |  Loss: (0.1391) |  Loss2: (0.0000) | Acc: (96.00%) (123/128)
Epoch: 175 | Batch_idx: 10 |  Loss: (0.1010) |  Loss2: (0.0000) | Acc: (96.00%) (1364/1408)
Epoch: 175 | Batch_idx: 20 |  Loss: (0.1080) |  Loss2: (0.0000) | Acc: (96.00%) (2589/2688)
Epoch: 175 | Batch_idx: 30 |  Loss: (0.1060) |  Loss2: (0.0000) | Acc: (96.00%) (3827/3968)
Epoch: 175 | Batch_idx: 40 |  Loss: (0.1079) |  Loss2: (0.0000) | Acc: (96.00%) (5054/5248)
Epoch: 175 | Batch_idx: 50 |  Loss: (0.1133) |  Loss2: (0.0000) | Acc: (96.00%) (6272/6528)
Epoch: 175 | Batch_idx: 60 |  Loss: (0.1182) |  Loss2: (0.0000) | Acc: (95.00%) (7486/7808)
Epoch: 175 | Batch_idx: 70 |  Loss: (0.1181) |  Loss2: (0.0000) | Acc: (96.00%) (8727/9088)
Epoch: 175 | Batch_idx: 80 |  Loss: (0.1168) |  Loss2: (0.0000) | Acc: (96.00%) (9957/10368)
Epoch: 175 | Batch_idx: 90 |  Loss: (0.1189) |  Loss2: (0.0000) | Acc: (95.00%) (11178/11648)
Epoch: 175 | Batch_idx: 100 |  Loss: (0.1211) |  Loss2: (0.0000) | Acc: (95.00%) (12390/12928)
Epoch: 175 | Batch_idx: 110 |  Loss: (0.1212) |  Loss2: (0.0000) | Acc: (95.00%) (13616/14208)
Epoch: 175 | Batch_idx: 120 |  Loss: (0.1196) |  Loss2: (0.0000) | Acc: (95.00%) (14848/15488)
Epoch: 175 | Batch_idx: 130 |  Loss: (0.1199) |  Loss2: (0.0000) | Acc: (95.00%) (16076/16768)
Epoch: 175 | Batch_idx: 140 |  Loss: (0.1197) |  Loss2: (0.0000) | Acc: (95.00%) (17306/18048)
Epoch: 175 | Batch_idx: 150 |  Loss: (0.1188) |  Loss2: (0.0000) | Acc: (95.00%) (18536/19328)
Epoch: 175 | Batch_idx: 160 |  Loss: (0.1198) |  Loss2: (0.0000) | Acc: (95.00%) (19761/20608)
Epoch: 175 | Batch_idx: 170 |  Loss: (0.1191) |  Loss2: (0.0000) | Acc: (95.00%) (20993/21888)
Epoch: 175 | Batch_idx: 180 |  Loss: (0.1191) |  Loss2: (0.0000) | Acc: (95.00%) (22220/23168)
Epoch: 175 | Batch_idx: 190 |  Loss: (0.1189) |  Loss2: (0.0000) | Acc: (95.00%) (23446/24448)
Epoch: 175 | Batch_idx: 200 |  Loss: (0.1197) |  Loss2: (0.0000) | Acc: (95.00%) (24661/25728)
Epoch: 175 | Batch_idx: 210 |  Loss: (0.1196) |  Loss2: (0.0000) | Acc: (95.00%) (25896/27008)
Epoch: 175 | Batch_idx: 220 |  Loss: (0.1195) |  Loss2: (0.0000) | Acc: (95.00%) (27118/28288)
Epoch: 175 | Batch_idx: 230 |  Loss: (0.1188) |  Loss2: (0.0000) | Acc: (95.00%) (28351/29568)
Epoch: 175 | Batch_idx: 240 |  Loss: (0.1186) |  Loss2: (0.0000) | Acc: (95.00%) (29580/30848)
Epoch: 175 | Batch_idx: 250 |  Loss: (0.1184) |  Loss2: (0.0000) | Acc: (95.00%) (30808/32128)
Epoch: 175 | Batch_idx: 260 |  Loss: (0.1180) |  Loss2: (0.0000) | Acc: (95.00%) (32035/33408)
Epoch: 175 | Batch_idx: 270 |  Loss: (0.1171) |  Loss2: (0.0000) | Acc: (95.00%) (33273/34688)
Epoch: 175 | Batch_idx: 280 |  Loss: (0.1170) |  Loss2: (0.0000) | Acc: (95.00%) (34502/35968)
Epoch: 175 | Batch_idx: 290 |  Loss: (0.1170) |  Loss2: (0.0000) | Acc: (95.00%) (35730/37248)
Epoch: 175 | Batch_idx: 300 |  Loss: (0.1172) |  Loss2: (0.0000) | Acc: (95.00%) (36950/38528)
Epoch: 175 | Batch_idx: 310 |  Loss: (0.1164) |  Loss2: (0.0000) | Acc: (95.00%) (38188/39808)
Epoch: 175 | Batch_idx: 320 |  Loss: (0.1160) |  Loss2: (0.0000) | Acc: (95.00%) (39424/41088)
Epoch: 175 | Batch_idx: 330 |  Loss: (0.1159) |  Loss2: (0.0000) | Acc: (95.00%) (40652/42368)
Epoch: 175 | Batch_idx: 340 |  Loss: (0.1155) |  Loss2: (0.0000) | Acc: (95.00%) (41891/43648)
Epoch: 175 | Batch_idx: 350 |  Loss: (0.1150) |  Loss2: (0.0000) | Acc: (95.00%) (43122/44928)
Epoch: 175 | Batch_idx: 360 |  Loss: (0.1151) |  Loss2: (0.0000) | Acc: (95.00%) (44350/46208)
Epoch: 175 | Batch_idx: 370 |  Loss: (0.1152) |  Loss2: (0.0000) | Acc: (95.00%) (45571/47488)
Epoch: 175 | Batch_idx: 380 |  Loss: (0.1156) |  Loss2: (0.0000) | Acc: (95.00%) (46794/48768)
Epoch: 175 | Batch_idx: 390 |  Loss: (0.1152) |  Loss2: (0.0000) | Acc: (95.00%) (47985/50000)
=> saving checkpoint 'drive/app/torch/save_Schedule/checkpoint_175.pth.tar'
# TEST : Loss: (0.4300) | Acc: (88.00%) (8804/10000)
percent tensor([0.5633, 0.5734, 0.6060, 0.5949, 0.6068, 0.5697, 0.5864, 0.6002, 0.5756,
        0.5826, 0.5598, 0.5986, 0.5647, 0.5747, 0.5731, 0.5683],
       device='cuda:0') torch.Size([16])
percent tensor([0.5839, 0.5889, 0.5814, 0.5764, 0.5884, 0.5835, 0.5945, 0.5881, 0.5798,
        0.5860, 0.5856, 0.5913, 0.5827, 0.5828, 0.5919, 0.5847],
       device='cuda:0') torch.Size([16])
percent tensor([0.6200, 0.6244, 0.5820, 0.5626, 0.5644, 0.5877, 0.6072, 0.5760, 0.5980,
        0.6252, 0.6164, 0.6022, 0.6445, 0.6072, 0.6102, 0.6214],
       device='cuda:0') torch.Size([16])
percent tensor([0.6489, 0.6392, 0.6130, 0.6215, 0.6245, 0.6647, 0.6499, 0.6222, 0.6345,
        0.6395, 0.6445, 0.6305, 0.6420, 0.6398, 0.6570, 0.6493],
       device='cuda:0') torch.Size([16])
percent tensor([0.5535, 0.5128, 0.6327, 0.6585, 0.6550, 0.5955, 0.5813, 0.6496, 0.6161,
        0.5104, 0.5687, 0.5962, 0.4565, 0.6486, 0.6052, 0.5665],
       device='cuda:0') torch.Size([16])
percent tensor([0.5102, 0.6786, 0.6467, 0.6212, 0.6283, 0.7030, 0.6175, 0.5291, 0.6476,
        0.6330, 0.7127, 0.6280, 0.6711, 0.6874, 0.4804, 0.4815],
       device='cuda:0') torch.Size([16])
percent tensor([0.6955, 0.7255, 0.7149, 0.6359, 0.6566, 0.7205, 0.7332, 0.6231, 0.6960,
        0.6994, 0.7166, 0.6014, 0.7263, 0.7230, 0.5533, 0.6381],
       device='cuda:0') torch.Size([16])
percent tensor([0.9995, 0.9998, 0.9999, 0.9998, 0.9997, 0.9995, 0.9999, 0.9999, 0.9999,
        0.9998, 0.9999, 0.9998, 0.9996, 0.9999, 0.9997, 0.9994],
       device='cuda:0') torch.Size([16])
Epoch: 176 | Batch_idx: 0 |  Loss: (0.2580) |  Loss2: (0.0000) | Acc: (89.00%) (115/128)
Epoch: 176 | Batch_idx: 10 |  Loss: (0.1187) |  Loss2: (0.0000) | Acc: (95.00%) (1348/1408)
Epoch: 176 | Batch_idx: 20 |  Loss: (0.1222) |  Loss2: (0.0000) | Acc: (95.00%) (2566/2688)
Epoch: 176 | Batch_idx: 30 |  Loss: (0.1162) |  Loss2: (0.0000) | Acc: (95.00%) (3801/3968)
Epoch: 176 | Batch_idx: 40 |  Loss: (0.1150) |  Loss2: (0.0000) | Acc: (95.00%) (5031/5248)
Epoch: 176 | Batch_idx: 50 |  Loss: (0.1127) |  Loss2: (0.0000) | Acc: (96.00%) (6272/6528)
Epoch: 176 | Batch_idx: 60 |  Loss: (0.1087) |  Loss2: (0.0000) | Acc: (96.00%) (7505/7808)
Epoch: 176 | Batch_idx: 70 |  Loss: (0.1090) |  Loss2: (0.0000) | Acc: (96.00%) (8730/9088)
Epoch: 176 | Batch_idx: 80 |  Loss: (0.1076) |  Loss2: (0.0000) | Acc: (96.00%) (9970/10368)
Epoch: 176 | Batch_idx: 90 |  Loss: (0.1060) |  Loss2: (0.0000) | Acc: (96.00%) (11206/11648)
Epoch: 176 | Batch_idx: 100 |  Loss: (0.1038) |  Loss2: (0.0000) | Acc: (96.00%) (12450/12928)
Epoch: 176 | Batch_idx: 110 |  Loss: (0.1039) |  Loss2: (0.0000) | Acc: (96.00%) (13679/14208)
Epoch: 176 | Batch_idx: 120 |  Loss: (0.1030) |  Loss2: (0.0000) | Acc: (96.00%) (14924/15488)
Epoch: 176 | Batch_idx: 130 |  Loss: (0.1017) |  Loss2: (0.0000) | Acc: (96.00%) (16177/16768)
Epoch: 176 | Batch_idx: 140 |  Loss: (0.1021) |  Loss2: (0.0000) | Acc: (96.00%) (17405/18048)
Epoch: 176 | Batch_idx: 150 |  Loss: (0.1028) |  Loss2: (0.0000) | Acc: (96.00%) (18634/19328)
Epoch: 176 | Batch_idx: 160 |  Loss: (0.1030) |  Loss2: (0.0000) | Acc: (96.00%) (19872/20608)
Epoch: 176 | Batch_idx: 170 |  Loss: (0.1033) |  Loss2: (0.0000) | Acc: (96.00%) (21109/21888)
Epoch: 176 | Batch_idx: 180 |  Loss: (0.1043) |  Loss2: (0.0000) | Acc: (96.00%) (22328/23168)
Epoch: 176 | Batch_idx: 190 |  Loss: (0.1046) |  Loss2: (0.0000) | Acc: (96.00%) (23558/24448)
Epoch: 176 | Batch_idx: 200 |  Loss: (0.1031) |  Loss2: (0.0000) | Acc: (96.00%) (24804/25728)
Epoch: 176 | Batch_idx: 210 |  Loss: (0.1025) |  Loss2: (0.0000) | Acc: (96.00%) (26048/27008)
Epoch: 176 | Batch_idx: 220 |  Loss: (0.1034) |  Loss2: (0.0000) | Acc: (96.00%) (27277/28288)
Epoch: 176 | Batch_idx: 230 |  Loss: (0.1039) |  Loss2: (0.0000) | Acc: (96.00%) (28504/29568)
Epoch: 176 | Batch_idx: 240 |  Loss: (0.1044) |  Loss2: (0.0000) | Acc: (96.00%) (29737/30848)
Epoch: 176 | Batch_idx: 250 |  Loss: (0.1043) |  Loss2: (0.0000) | Acc: (96.00%) (30969/32128)
Epoch: 176 | Batch_idx: 260 |  Loss: (0.1043) |  Loss2: (0.0000) | Acc: (96.00%) (32202/33408)
Epoch: 176 | Batch_idx: 270 |  Loss: (0.1043) |  Loss2: (0.0000) | Acc: (96.00%) (33436/34688)
Epoch: 176 | Batch_idx: 280 |  Loss: (0.1044) |  Loss2: (0.0000) | Acc: (96.00%) (34671/35968)
Epoch: 176 | Batch_idx: 290 |  Loss: (0.1043) |  Loss2: (0.0000) | Acc: (96.00%) (35896/37248)
Epoch: 176 | Batch_idx: 300 |  Loss: (0.1049) |  Loss2: (0.0000) | Acc: (96.00%) (37125/38528)
Epoch: 176 | Batch_idx: 310 |  Loss: (0.1044) |  Loss2: (0.0000) | Acc: (96.00%) (38365/39808)
Epoch: 176 | Batch_idx: 320 |  Loss: (0.1044) |  Loss2: (0.0000) | Acc: (96.00%) (39600/41088)
Epoch: 176 | Batch_idx: 330 |  Loss: (0.1049) |  Loss2: (0.0000) | Acc: (96.00%) (40817/42368)
Epoch: 176 | Batch_idx: 340 |  Loss: (0.1042) |  Loss2: (0.0000) | Acc: (96.00%) (42058/43648)
Epoch: 176 | Batch_idx: 350 |  Loss: (0.1038) |  Loss2: (0.0000) | Acc: (96.00%) (43301/44928)
Epoch: 176 | Batch_idx: 360 |  Loss: (0.1035) |  Loss2: (0.0000) | Acc: (96.00%) (44545/46208)
Epoch: 176 | Batch_idx: 370 |  Loss: (0.1033) |  Loss2: (0.0000) | Acc: (96.00%) (45787/47488)
Epoch: 176 | Batch_idx: 380 |  Loss: (0.1035) |  Loss2: (0.0000) | Acc: (96.00%) (47021/48768)
Epoch: 176 | Batch_idx: 390 |  Loss: (0.1037) |  Loss2: (0.0000) | Acc: (96.00%) (48205/50000)
# TEST : Loss: (0.4159) | Acc: (88.00%) (8836/10000)
percent tensor([0.5604, 0.5716, 0.6028, 0.5929, 0.6036, 0.5668, 0.5840, 0.5982, 0.5730,
        0.5805, 0.5571, 0.5957, 0.5617, 0.5743, 0.5706, 0.5661],
       device='cuda:0') torch.Size([16])
percent tensor([0.5878, 0.5933, 0.5852, 0.5801, 0.5925, 0.5870, 0.5991, 0.5925, 0.5840,
        0.5903, 0.5898, 0.5956, 0.5868, 0.5875, 0.5959, 0.5887],
       device='cuda:0') torch.Size([16])
percent tensor([0.6203, 0.6255, 0.5809, 0.5603, 0.5626, 0.5861, 0.6083, 0.5759, 0.5965,
        0.6253, 0.6156, 0.6011, 0.6453, 0.6079, 0.6107, 0.6216],
       device='cuda:0') torch.Size([16])
percent tensor([0.6534, 0.6431, 0.6166, 0.6255, 0.6281, 0.6697, 0.6544, 0.6251, 0.6382,
        0.6442, 0.6490, 0.6340, 0.6462, 0.6446, 0.6610, 0.6542],
       device='cuda:0') torch.Size([16])
percent tensor([0.5493, 0.5072, 0.6358, 0.6645, 0.6579, 0.5927, 0.5748, 0.6526, 0.6169,
        0.5045, 0.5634, 0.6002, 0.4525, 0.6457, 0.6033, 0.5622],
       device='cuda:0') torch.Size([16])
percent tensor([0.5183, 0.6896, 0.6455, 0.6156, 0.6249, 0.7112, 0.6255, 0.5142, 0.6537,
        0.6450, 0.7238, 0.6238, 0.6866, 0.6987, 0.4760, 0.4930],
       device='cuda:0') torch.Size([16])
percent tensor([0.7039, 0.7324, 0.7165, 0.6359, 0.6580, 0.7265, 0.7362, 0.6223, 0.6991,
        0.7074, 0.7199, 0.5977, 0.7338, 0.7259, 0.5532, 0.6475],
       device='cuda:0') torch.Size([16])
percent tensor([0.9996, 0.9998, 0.9999, 0.9998, 0.9997, 0.9995, 0.9999, 0.9999, 0.9999,
        0.9998, 0.9999, 0.9998, 0.9996, 0.9999, 0.9997, 0.9994],
       device='cuda:0') torch.Size([16])
Epoch: 177 | Batch_idx: 0 |  Loss: (0.0983) |  Loss2: (0.0000) | Acc: (96.00%) (124/128)
Epoch: 177 | Batch_idx: 10 |  Loss: (0.0811) |  Loss2: (0.0000) | Acc: (97.00%) (1379/1408)
Epoch: 177 | Batch_idx: 20 |  Loss: (0.0875) |  Loss2: (0.0000) | Acc: (97.00%) (2618/2688)
Epoch: 177 | Batch_idx: 30 |  Loss: (0.0887) |  Loss2: (0.0000) | Acc: (97.00%) (3861/3968)
Epoch: 177 | Batch_idx: 40 |  Loss: (0.0898) |  Loss2: (0.0000) | Acc: (97.00%) (5103/5248)
Epoch: 177 | Batch_idx: 50 |  Loss: (0.0915) |  Loss2: (0.0000) | Acc: (97.00%) (6338/6528)
Epoch: 177 | Batch_idx: 60 |  Loss: (0.0916) |  Loss2: (0.0000) | Acc: (97.00%) (7578/7808)
Epoch: 177 | Batch_idx: 70 |  Loss: (0.0910) |  Loss2: (0.0000) | Acc: (97.00%) (8824/9088)
Epoch: 177 | Batch_idx: 80 |  Loss: (0.0907) |  Loss2: (0.0000) | Acc: (97.00%) (10063/10368)
Epoch: 177 | Batch_idx: 90 |  Loss: (0.0921) |  Loss2: (0.0000) | Acc: (97.00%) (11303/11648)
Epoch: 177 | Batch_idx: 100 |  Loss: (0.0908) |  Loss2: (0.0000) | Acc: (97.00%) (12549/12928)
Epoch: 177 | Batch_idx: 110 |  Loss: (0.0917) |  Loss2: (0.0000) | Acc: (97.00%) (13783/14208)
Epoch: 177 | Batch_idx: 120 |  Loss: (0.0910) |  Loss2: (0.0000) | Acc: (97.00%) (15024/15488)
Epoch: 177 | Batch_idx: 130 |  Loss: (0.0915) |  Loss2: (0.0000) | Acc: (96.00%) (16264/16768)
Epoch: 177 | Batch_idx: 140 |  Loss: (0.0928) |  Loss2: (0.0000) | Acc: (96.00%) (17488/18048)
Epoch: 177 | Batch_idx: 150 |  Loss: (0.0923) |  Loss2: (0.0000) | Acc: (96.00%) (18729/19328)
Epoch: 177 | Batch_idx: 160 |  Loss: (0.0925) |  Loss2: (0.0000) | Acc: (96.00%) (19966/20608)
Epoch: 177 | Batch_idx: 170 |  Loss: (0.0923) |  Loss2: (0.0000) | Acc: (96.00%) (21199/21888)
Epoch: 177 | Batch_idx: 180 |  Loss: (0.0925) |  Loss2: (0.0000) | Acc: (96.00%) (22437/23168)
Epoch: 177 | Batch_idx: 190 |  Loss: (0.0923) |  Loss2: (0.0000) | Acc: (96.00%) (23679/24448)
Epoch: 177 | Batch_idx: 200 |  Loss: (0.0919) |  Loss2: (0.0000) | Acc: (96.00%) (24929/25728)
Epoch: 177 | Batch_idx: 210 |  Loss: (0.0920) |  Loss2: (0.0000) | Acc: (96.00%) (26171/27008)
Epoch: 177 | Batch_idx: 220 |  Loss: (0.0919) |  Loss2: (0.0000) | Acc: (96.00%) (27411/28288)
Epoch: 177 | Batch_idx: 230 |  Loss: (0.0914) |  Loss2: (0.0000) | Acc: (96.00%) (28654/29568)
Epoch: 177 | Batch_idx: 240 |  Loss: (0.0917) |  Loss2: (0.0000) | Acc: (96.00%) (29892/30848)
Epoch: 177 | Batch_idx: 250 |  Loss: (0.0925) |  Loss2: (0.0000) | Acc: (96.00%) (31122/32128)
Epoch: 177 | Batch_idx: 260 |  Loss: (0.0933) |  Loss2: (0.0000) | Acc: (96.00%) (32357/33408)
Epoch: 177 | Batch_idx: 270 |  Loss: (0.0933) |  Loss2: (0.0000) | Acc: (96.00%) (33592/34688)
Epoch: 177 | Batch_idx: 280 |  Loss: (0.0930) |  Loss2: (0.0000) | Acc: (96.00%) (34838/35968)
Epoch: 177 | Batch_idx: 290 |  Loss: (0.0930) |  Loss2: (0.0000) | Acc: (96.00%) (36076/37248)
Epoch: 177 | Batch_idx: 300 |  Loss: (0.0926) |  Loss2: (0.0000) | Acc: (96.00%) (37323/38528)
Epoch: 177 | Batch_idx: 310 |  Loss: (0.0927) |  Loss2: (0.0000) | Acc: (96.00%) (38562/39808)
Epoch: 177 | Batch_idx: 320 |  Loss: (0.0934) |  Loss2: (0.0000) | Acc: (96.00%) (39794/41088)
Epoch: 177 | Batch_idx: 330 |  Loss: (0.0935) |  Loss2: (0.0000) | Acc: (96.00%) (41037/42368)
Epoch: 177 | Batch_idx: 340 |  Loss: (0.0935) |  Loss2: (0.0000) | Acc: (96.00%) (42276/43648)
Epoch: 177 | Batch_idx: 350 |  Loss: (0.0934) |  Loss2: (0.0000) | Acc: (96.00%) (43520/44928)
Epoch: 177 | Batch_idx: 360 |  Loss: (0.0938) |  Loss2: (0.0000) | Acc: (96.00%) (44751/46208)
Epoch: 177 | Batch_idx: 370 |  Loss: (0.0937) |  Loss2: (0.0000) | Acc: (96.00%) (45991/47488)
Epoch: 177 | Batch_idx: 380 |  Loss: (0.0940) |  Loss2: (0.0000) | Acc: (96.00%) (47222/48768)
Epoch: 177 | Batch_idx: 390 |  Loss: (0.0943) |  Loss2: (0.0000) | Acc: (96.00%) (48409/50000)
# TEST : Loss: (0.4117) | Acc: (88.00%) (8854/10000)
percent tensor([0.5627, 0.5758, 0.6052, 0.5959, 0.6067, 0.5690, 0.5877, 0.6020, 0.5762,
        0.5841, 0.5601, 0.5987, 0.5645, 0.5789, 0.5739, 0.5690],
       device='cuda:0') torch.Size([16])
percent tensor([0.5891, 0.5950, 0.5866, 0.5810, 0.5939, 0.5875, 0.6009, 0.5942, 0.5855,
        0.5921, 0.5913, 0.5975, 0.5885, 0.5891, 0.5973, 0.5900],
       device='cuda:0') torch.Size([16])
percent tensor([0.6227, 0.6279, 0.5829, 0.5631, 0.5643, 0.5883, 0.6106, 0.5779, 0.5977,
        0.6272, 0.6167, 0.6026, 0.6472, 0.6107, 0.6132, 0.6242],
       device='cuda:0') torch.Size([16])
percent tensor([0.6535, 0.6430, 0.6157, 0.6235, 0.6271, 0.6698, 0.6545, 0.6238, 0.6376,
        0.6445, 0.6489, 0.6331, 0.6465, 0.6441, 0.6606, 0.6544],
       device='cuda:0') torch.Size([16])
percent tensor([0.5590, 0.5165, 0.6449, 0.6752, 0.6665, 0.5984, 0.5857, 0.6613, 0.6290,
        0.5169, 0.5746, 0.6165, 0.4633, 0.6573, 0.6157, 0.5697],
       device='cuda:0') torch.Size([16])
percent tensor([0.5117, 0.6814, 0.6396, 0.6089, 0.6167, 0.7154, 0.6187, 0.5001, 0.6482,
        0.6394, 0.7221, 0.6104, 0.6827, 0.6980, 0.4575, 0.4888],
       device='cuda:0') torch.Size([16])
percent tensor([0.7100, 0.7353, 0.7212, 0.6402, 0.6599, 0.7380, 0.7370, 0.6240, 0.7046,
        0.7127, 0.7264, 0.5969, 0.7419, 0.7324, 0.5517, 0.6524],
       device='cuda:0') torch.Size([16])
percent tensor([0.9996, 0.9998, 0.9999, 0.9998, 0.9997, 0.9996, 0.9999, 0.9999, 0.9999,
        0.9999, 0.9999, 0.9998, 0.9996, 0.9999, 0.9997, 0.9994],
       device='cuda:0') torch.Size([16])
Epoch: 178 | Batch_idx: 0 |  Loss: (0.1116) |  Loss2: (0.0000) | Acc: (96.00%) (124/128)
Epoch: 178 | Batch_idx: 10 |  Loss: (0.1016) |  Loss2: (0.0000) | Acc: (96.00%) (1362/1408)
Epoch: 178 | Batch_idx: 20 |  Loss: (0.1025) |  Loss2: (0.0000) | Acc: (96.00%) (2599/2688)
Epoch: 178 | Batch_idx: 30 |  Loss: (0.0991) |  Loss2: (0.0000) | Acc: (96.00%) (3845/3968)
Epoch: 178 | Batch_idx: 40 |  Loss: (0.0969) |  Loss2: (0.0000) | Acc: (97.00%) (5095/5248)
Epoch: 178 | Batch_idx: 50 |  Loss: (0.0985) |  Loss2: (0.0000) | Acc: (96.00%) (6328/6528)
Epoch: 178 | Batch_idx: 60 |  Loss: (0.0948) |  Loss2: (0.0000) | Acc: (97.00%) (7574/7808)
Epoch: 178 | Batch_idx: 70 |  Loss: (0.0961) |  Loss2: (0.0000) | Acc: (96.00%) (8813/9088)
Epoch: 178 | Batch_idx: 80 |  Loss: (0.0957) |  Loss2: (0.0000) | Acc: (97.00%) (10058/10368)
Epoch: 178 | Batch_idx: 90 |  Loss: (0.0943) |  Loss2: (0.0000) | Acc: (97.00%) (11302/11648)
Epoch: 178 | Batch_idx: 100 |  Loss: (0.0933) |  Loss2: (0.0000) | Acc: (97.00%) (12544/12928)
Epoch: 178 | Batch_idx: 110 |  Loss: (0.0932) |  Loss2: (0.0000) | Acc: (96.00%) (13780/14208)
Epoch: 178 | Batch_idx: 120 |  Loss: (0.0930) |  Loss2: (0.0000) | Acc: (96.00%) (15015/15488)
Epoch: 178 | Batch_idx: 130 |  Loss: (0.0925) |  Loss2: (0.0000) | Acc: (96.00%) (16249/16768)
Epoch: 178 | Batch_idx: 140 |  Loss: (0.0924) |  Loss2: (0.0000) | Acc: (96.00%) (17484/18048)
Epoch: 178 | Batch_idx: 150 |  Loss: (0.0920) |  Loss2: (0.0000) | Acc: (96.00%) (18723/19328)
Epoch: 178 | Batch_idx: 160 |  Loss: (0.0922) |  Loss2: (0.0000) | Acc: (96.00%) (19967/20608)
Epoch: 178 | Batch_idx: 170 |  Loss: (0.0927) |  Loss2: (0.0000) | Acc: (96.00%) (21204/21888)
Epoch: 178 | Batch_idx: 180 |  Loss: (0.0919) |  Loss2: (0.0000) | Acc: (96.00%) (22447/23168)
Epoch: 178 | Batch_idx: 190 |  Loss: (0.0917) |  Loss2: (0.0000) | Acc: (96.00%) (23689/24448)
Epoch: 178 | Batch_idx: 200 |  Loss: (0.0918) |  Loss2: (0.0000) | Acc: (96.00%) (24930/25728)
Epoch: 178 | Batch_idx: 210 |  Loss: (0.0918) |  Loss2: (0.0000) | Acc: (96.00%) (26175/27008)
Epoch: 178 | Batch_idx: 220 |  Loss: (0.0918) |  Loss2: (0.0000) | Acc: (96.00%) (27413/28288)
Epoch: 178 | Batch_idx: 230 |  Loss: (0.0916) |  Loss2: (0.0000) | Acc: (96.00%) (28656/29568)
Epoch: 178 | Batch_idx: 240 |  Loss: (0.0921) |  Loss2: (0.0000) | Acc: (96.00%) (29891/30848)
Epoch: 178 | Batch_idx: 250 |  Loss: (0.0916) |  Loss2: (0.0000) | Acc: (96.00%) (31132/32128)
Epoch: 178 | Batch_idx: 260 |  Loss: (0.0924) |  Loss2: (0.0000) | Acc: (96.00%) (32361/33408)
Epoch: 178 | Batch_idx: 270 |  Loss: (0.0931) |  Loss2: (0.0000) | Acc: (96.00%) (33589/34688)
Epoch: 178 | Batch_idx: 280 |  Loss: (0.0931) |  Loss2: (0.0000) | Acc: (96.00%) (34827/35968)
Epoch: 178 | Batch_idx: 290 |  Loss: (0.0926) |  Loss2: (0.0000) | Acc: (96.00%) (36079/37248)
Epoch: 178 | Batch_idx: 300 |  Loss: (0.0926) |  Loss2: (0.0000) | Acc: (96.00%) (37319/38528)
Epoch: 178 | Batch_idx: 310 |  Loss: (0.0923) |  Loss2: (0.0000) | Acc: (96.00%) (38563/39808)
Epoch: 178 | Batch_idx: 320 |  Loss: (0.0916) |  Loss2: (0.0000) | Acc: (96.00%) (39817/41088)
Epoch: 178 | Batch_idx: 330 |  Loss: (0.0916) |  Loss2: (0.0000) | Acc: (96.00%) (41055/42368)
Epoch: 178 | Batch_idx: 340 |  Loss: (0.0915) |  Loss2: (0.0000) | Acc: (96.00%) (42297/43648)
Epoch: 178 | Batch_idx: 350 |  Loss: (0.0912) |  Loss2: (0.0000) | Acc: (96.00%) (43548/44928)
Epoch: 178 | Batch_idx: 360 |  Loss: (0.0920) |  Loss2: (0.0000) | Acc: (96.00%) (44773/46208)
Epoch: 178 | Batch_idx: 370 |  Loss: (0.0922) |  Loss2: (0.0000) | Acc: (96.00%) (46012/47488)
Epoch: 178 | Batch_idx: 380 |  Loss: (0.0920) |  Loss2: (0.0000) | Acc: (96.00%) (47253/48768)
Epoch: 178 | Batch_idx: 390 |  Loss: (0.0920) |  Loss2: (0.0000) | Acc: (96.00%) (48450/50000)
# TEST : Loss: (0.4054) | Acc: (88.00%) (8879/10000)
percent tensor([0.5600, 0.5735, 0.6020, 0.5935, 0.6034, 0.5665, 0.5850, 0.5997, 0.5736,
        0.5816, 0.5575, 0.5955, 0.5617, 0.5777, 0.5714, 0.5667],
       device='cuda:0') torch.Size([16])
percent tensor([0.5876, 0.5934, 0.5850, 0.5794, 0.5919, 0.5857, 0.5992, 0.5924, 0.5839,
        0.5906, 0.5898, 0.5957, 0.5869, 0.5878, 0.5954, 0.5884],
       device='cuda:0') torch.Size([16])
percent tensor([0.6178, 0.6237, 0.5776, 0.5580, 0.5599, 0.5827, 0.6070, 0.5745, 0.5931,
        0.6225, 0.6118, 0.5977, 0.6421, 0.6086, 0.6086, 0.6191],
       device='cuda:0') torch.Size([16])
percent tensor([0.6519, 0.6422, 0.6133, 0.6219, 0.6249, 0.6688, 0.6531, 0.6211, 0.6361,
        0.6438, 0.6483, 0.6312, 0.6454, 0.6446, 0.6587, 0.6535],
       device='cuda:0') torch.Size([16])
percent tensor([0.5524, 0.5158, 0.6377, 0.6691, 0.6612, 0.5887, 0.5781, 0.6561, 0.6234,
        0.5150, 0.5702, 0.6117, 0.4608, 0.6526, 0.6082, 0.5633],
       device='cuda:0') torch.Size([16])
percent tensor([0.5223, 0.6904, 0.6487, 0.6157, 0.6284, 0.7277, 0.6301, 0.5055, 0.6567,
        0.6478, 0.7285, 0.6147, 0.6903, 0.7066, 0.4673, 0.5044],
       device='cuda:0') torch.Size([16])
percent tensor([0.7211, 0.7444, 0.7296, 0.6447, 0.6680, 0.7435, 0.7454, 0.6309, 0.7117,
        0.7214, 0.7298, 0.5984, 0.7494, 0.7360, 0.5562, 0.6642],
       device='cuda:0') torch.Size([16])
percent tensor([0.9996, 0.9998, 0.9999, 0.9998, 0.9997, 0.9995, 0.9999, 0.9999, 0.9999,
        0.9999, 0.9999, 0.9998, 0.9997, 0.9999, 0.9997, 0.9994],
       device='cuda:0') torch.Size([16])
Epoch: 179 | Batch_idx: 0 |  Loss: (0.0938) |  Loss2: (0.0000) | Acc: (96.00%) (123/128)
Epoch: 179 | Batch_idx: 10 |  Loss: (0.0775) |  Loss2: (0.0000) | Acc: (97.00%) (1377/1408)
Epoch: 179 | Batch_idx: 20 |  Loss: (0.0868) |  Loss2: (0.0000) | Acc: (97.00%) (2623/2688)
Epoch: 179 | Batch_idx: 30 |  Loss: (0.0910) |  Loss2: (0.0000) | Acc: (97.00%) (3856/3968)
Epoch: 179 | Batch_idx: 40 |  Loss: (0.0910) |  Loss2: (0.0000) | Acc: (97.00%) (5095/5248)
Epoch: 179 | Batch_idx: 50 |  Loss: (0.0920) |  Loss2: (0.0000) | Acc: (97.00%) (6338/6528)
Epoch: 179 | Batch_idx: 60 |  Loss: (0.0898) |  Loss2: (0.0000) | Acc: (97.00%) (7585/7808)
Epoch: 179 | Batch_idx: 70 |  Loss: (0.0880) |  Loss2: (0.0000) | Acc: (97.00%) (8834/9088)
Epoch: 179 | Batch_idx: 80 |  Loss: (0.0899) |  Loss2: (0.0000) | Acc: (97.00%) (10068/10368)
Epoch: 179 | Batch_idx: 90 |  Loss: (0.0909) |  Loss2: (0.0000) | Acc: (97.00%) (11302/11648)
Epoch: 179 | Batch_idx: 100 |  Loss: (0.0913) |  Loss2: (0.0000) | Acc: (97.00%) (12541/12928)
Epoch: 179 | Batch_idx: 110 |  Loss: (0.0917) |  Loss2: (0.0000) | Acc: (96.00%) (13777/14208)
Epoch: 179 | Batch_idx: 120 |  Loss: (0.0920) |  Loss2: (0.0000) | Acc: (96.00%) (15021/15488)
Epoch: 179 | Batch_idx: 130 |  Loss: (0.0916) |  Loss2: (0.0000) | Acc: (96.00%) (16262/16768)
Epoch: 179 | Batch_idx: 140 |  Loss: (0.0906) |  Loss2: (0.0000) | Acc: (97.00%) (17508/18048)
Epoch: 179 | Batch_idx: 150 |  Loss: (0.0893) |  Loss2: (0.0000) | Acc: (97.00%) (18753/19328)
Epoch: 179 | Batch_idx: 160 |  Loss: (0.0898) |  Loss2: (0.0000) | Acc: (97.00%) (19991/20608)
Epoch: 179 | Batch_idx: 170 |  Loss: (0.0896) |  Loss2: (0.0000) | Acc: (96.00%) (21231/21888)
Epoch: 179 | Batch_idx: 180 |  Loss: (0.0893) |  Loss2: (0.0000) | Acc: (97.00%) (22474/23168)
Epoch: 179 | Batch_idx: 190 |  Loss: (0.0898) |  Loss2: (0.0000) | Acc: (97.00%) (23716/24448)
Epoch: 179 | Batch_idx: 200 |  Loss: (0.0900) |  Loss2: (0.0000) | Acc: (97.00%) (24959/25728)
Epoch: 179 | Batch_idx: 210 |  Loss: (0.0896) |  Loss2: (0.0000) | Acc: (97.00%) (26207/27008)
Epoch: 179 | Batch_idx: 220 |  Loss: (0.0899) |  Loss2: (0.0000) | Acc: (97.00%) (27442/28288)
Epoch: 179 | Batch_idx: 230 |  Loss: (0.0904) |  Loss2: (0.0000) | Acc: (96.00%) (28677/29568)
Epoch: 179 | Batch_idx: 240 |  Loss: (0.0908) |  Loss2: (0.0000) | Acc: (96.00%) (29910/30848)
Epoch: 179 | Batch_idx: 250 |  Loss: (0.0909) |  Loss2: (0.0000) | Acc: (96.00%) (31148/32128)
Epoch: 179 | Batch_idx: 260 |  Loss: (0.0914) |  Loss2: (0.0000) | Acc: (96.00%) (32381/33408)
Epoch: 179 | Batch_idx: 270 |  Loss: (0.0914) |  Loss2: (0.0000) | Acc: (96.00%) (33613/34688)
Epoch: 179 | Batch_idx: 280 |  Loss: (0.0911) |  Loss2: (0.0000) | Acc: (96.00%) (34861/35968)
Epoch: 179 | Batch_idx: 290 |  Loss: (0.0910) |  Loss2: (0.0000) | Acc: (96.00%) (36101/37248)
Epoch: 179 | Batch_idx: 300 |  Loss: (0.0909) |  Loss2: (0.0000) | Acc: (96.00%) (37340/38528)
Epoch: 179 | Batch_idx: 310 |  Loss: (0.0905) |  Loss2: (0.0000) | Acc: (96.00%) (38587/39808)
Epoch: 179 | Batch_idx: 320 |  Loss: (0.0900) |  Loss2: (0.0000) | Acc: (96.00%) (39834/41088)
Epoch: 179 | Batch_idx: 330 |  Loss: (0.0903) |  Loss2: (0.0000) | Acc: (96.00%) (41067/42368)
Epoch: 179 | Batch_idx: 340 |  Loss: (0.0901) |  Loss2: (0.0000) | Acc: (96.00%) (42313/43648)
Epoch: 179 | Batch_idx: 350 |  Loss: (0.0894) |  Loss2: (0.0000) | Acc: (96.00%) (43570/44928)
Epoch: 179 | Batch_idx: 360 |  Loss: (0.0894) |  Loss2: (0.0000) | Acc: (96.00%) (44814/46208)
Epoch: 179 | Batch_idx: 370 |  Loss: (0.0903) |  Loss2: (0.0000) | Acc: (96.00%) (46043/47488)
Epoch: 179 | Batch_idx: 380 |  Loss: (0.0903) |  Loss2: (0.0000) | Acc: (96.00%) (47286/48768)
Epoch: 179 | Batch_idx: 390 |  Loss: (0.0901) |  Loss2: (0.0000) | Acc: (96.00%) (48485/50000)
# TEST : Loss: (0.4036) | Acc: (88.00%) (8880/10000)
percent tensor([0.5573, 0.5714, 0.6000, 0.5915, 0.6013, 0.5636, 0.5828, 0.5978, 0.5712,
        0.5796, 0.5549, 0.5937, 0.5591, 0.5760, 0.5690, 0.5642],
       device='cuda:0') torch.Size([16])
percent tensor([0.5865, 0.5924, 0.5838, 0.5780, 0.5906, 0.5842, 0.5983, 0.5913, 0.5830,
        0.5898, 0.5889, 0.5948, 0.5860, 0.5869, 0.5943, 0.5873],
       device='cuda:0') torch.Size([16])
percent tensor([0.6165, 0.6209, 0.5755, 0.5562, 0.5571, 0.5806, 0.6049, 0.5727, 0.5907,
        0.6203, 0.6092, 0.5954, 0.6404, 0.6069, 0.6059, 0.6176],
       device='cuda:0') torch.Size([16])
percent tensor([0.6507, 0.6414, 0.6115, 0.6205, 0.6229, 0.6680, 0.6520, 0.6188, 0.6349,
        0.6436, 0.6480, 0.6301, 0.6447, 0.6440, 0.6572, 0.6526],
       device='cuda:0') torch.Size([16])
percent tensor([0.5515, 0.5156, 0.6406, 0.6732, 0.6639, 0.5873, 0.5769, 0.6586, 0.6251,
        0.5156, 0.5697, 0.6155, 0.4579, 0.6550, 0.6092, 0.5608],
       device='cuda:0') torch.Size([16])
percent tensor([0.5137, 0.6829, 0.6386, 0.6046, 0.6195, 0.7243, 0.6231, 0.4965, 0.6477,
        0.6406, 0.7228, 0.6013, 0.6846, 0.6991, 0.4546, 0.4966],
       device='cuda:0') torch.Size([16])
percent tensor([0.7143, 0.7369, 0.7196, 0.6344, 0.6579, 0.7400, 0.7377, 0.6201, 0.7031,
        0.7134, 0.7220, 0.5866, 0.7460, 0.7274, 0.5498, 0.6584],
       device='cuda:0') torch.Size([16])
percent tensor([0.9996, 0.9998, 0.9999, 0.9998, 0.9997, 0.9996, 0.9999, 0.9999, 0.9999,
        0.9999, 0.9999, 0.9998, 0.9997, 0.9999, 0.9998, 0.9994],
       device='cuda:0') torch.Size([16])
Epoch: 180 | Batch_idx: 0 |  Loss: (0.1222) |  Loss2: (0.0000) | Acc: (94.00%) (121/128)
Epoch: 180 | Batch_idx: 10 |  Loss: (0.0851) |  Loss2: (0.0000) | Acc: (97.00%) (1370/1408)
Epoch: 180 | Batch_idx: 20 |  Loss: (0.0875) |  Loss2: (0.0000) | Acc: (97.00%) (2610/2688)
Epoch: 180 | Batch_idx: 30 |  Loss: (0.0846) |  Loss2: (0.0000) | Acc: (97.00%) (3858/3968)
Epoch: 180 | Batch_idx: 40 |  Loss: (0.0817) |  Loss2: (0.0000) | Acc: (97.00%) (5106/5248)
Epoch: 180 | Batch_idx: 50 |  Loss: (0.0830) |  Loss2: (0.0000) | Acc: (97.00%) (6348/6528)
Epoch: 180 | Batch_idx: 60 |  Loss: (0.0828) |  Loss2: (0.0000) | Acc: (97.00%) (7590/7808)
Epoch: 180 | Batch_idx: 70 |  Loss: (0.0834) |  Loss2: (0.0000) | Acc: (97.00%) (8838/9088)
Epoch: 180 | Batch_idx: 80 |  Loss: (0.0845) |  Loss2: (0.0000) | Acc: (97.00%) (10077/10368)
Epoch: 180 | Batch_idx: 90 |  Loss: (0.0828) |  Loss2: (0.0000) | Acc: (97.00%) (11328/11648)
Epoch: 180 | Batch_idx: 100 |  Loss: (0.0824) |  Loss2: (0.0000) | Acc: (97.00%) (12575/12928)
Epoch: 180 | Batch_idx: 110 |  Loss: (0.0814) |  Loss2: (0.0000) | Acc: (97.00%) (13832/14208)
Epoch: 180 | Batch_idx: 120 |  Loss: (0.0818) |  Loss2: (0.0000) | Acc: (97.00%) (15073/15488)
Epoch: 180 | Batch_idx: 130 |  Loss: (0.0820) |  Loss2: (0.0000) | Acc: (97.00%) (16316/16768)
Epoch: 180 | Batch_idx: 140 |  Loss: (0.0807) |  Loss2: (0.0000) | Acc: (97.00%) (17573/18048)
Epoch: 180 | Batch_idx: 150 |  Loss: (0.0830) |  Loss2: (0.0000) | Acc: (97.00%) (18805/19328)
Epoch: 180 | Batch_idx: 160 |  Loss: (0.0834) |  Loss2: (0.0000) | Acc: (97.00%) (20054/20608)
Epoch: 180 | Batch_idx: 170 |  Loss: (0.0826) |  Loss2: (0.0000) | Acc: (97.00%) (21306/21888)
Epoch: 180 | Batch_idx: 180 |  Loss: (0.0835) |  Loss2: (0.0000) | Acc: (97.00%) (22549/23168)
Epoch: 180 | Batch_idx: 190 |  Loss: (0.0829) |  Loss2: (0.0000) | Acc: (97.00%) (23804/24448)
Epoch: 180 | Batch_idx: 200 |  Loss: (0.0835) |  Loss2: (0.0000) | Acc: (97.00%) (25040/25728)
Epoch: 180 | Batch_idx: 210 |  Loss: (0.0844) |  Loss2: (0.0000) | Acc: (97.00%) (26274/27008)
Epoch: 180 | Batch_idx: 220 |  Loss: (0.0848) |  Loss2: (0.0000) | Acc: (97.00%) (27520/28288)
Epoch: 180 | Batch_idx: 230 |  Loss: (0.0850) |  Loss2: (0.0000) | Acc: (97.00%) (28761/29568)
Epoch: 180 | Batch_idx: 240 |  Loss: (0.0849) |  Loss2: (0.0000) | Acc: (97.00%) (30010/30848)
Epoch: 180 | Batch_idx: 250 |  Loss: (0.0850) |  Loss2: (0.0000) | Acc: (97.00%) (31257/32128)
Epoch: 180 | Batch_idx: 260 |  Loss: (0.0844) |  Loss2: (0.0000) | Acc: (97.00%) (32506/33408)
Epoch: 180 | Batch_idx: 270 |  Loss: (0.0847) |  Loss2: (0.0000) | Acc: (97.00%) (33743/34688)
Epoch: 180 | Batch_idx: 280 |  Loss: (0.0847) |  Loss2: (0.0000) | Acc: (97.00%) (34991/35968)
Epoch: 180 | Batch_idx: 290 |  Loss: (0.0851) |  Loss2: (0.0000) | Acc: (97.00%) (36231/37248)
Epoch: 180 | Batch_idx: 300 |  Loss: (0.0850) |  Loss2: (0.0000) | Acc: (97.00%) (37481/38528)
Epoch: 180 | Batch_idx: 310 |  Loss: (0.0860) |  Loss2: (0.0000) | Acc: (97.00%) (38715/39808)
Epoch: 180 | Batch_idx: 320 |  Loss: (0.0860) |  Loss2: (0.0000) | Acc: (97.00%) (39962/41088)
Epoch: 180 | Batch_idx: 330 |  Loss: (0.0859) |  Loss2: (0.0000) | Acc: (97.00%) (41210/42368)
Epoch: 180 | Batch_idx: 340 |  Loss: (0.0860) |  Loss2: (0.0000) | Acc: (97.00%) (42445/43648)
Epoch: 180 | Batch_idx: 350 |  Loss: (0.0857) |  Loss2: (0.0000) | Acc: (97.00%) (43699/44928)
Epoch: 180 | Batch_idx: 360 |  Loss: (0.0856) |  Loss2: (0.0000) | Acc: (97.00%) (44948/46208)
Epoch: 180 | Batch_idx: 370 |  Loss: (0.0857) |  Loss2: (0.0000) | Acc: (97.00%) (46188/47488)
Epoch: 180 | Batch_idx: 380 |  Loss: (0.0856) |  Loss2: (0.0000) | Acc: (97.00%) (47436/48768)
Epoch: 180 | Batch_idx: 390 |  Loss: (0.0855) |  Loss2: (0.0000) | Acc: (97.00%) (48636/50000)
=> saving checkpoint 'drive/app/torch/save_Schedule/checkpoint_180.pth.tar'
# TEST : Loss: (0.3987) | Acc: (88.00%) (8886/10000)
percent tensor([0.5556, 0.5695, 0.5974, 0.5896, 0.5988, 0.5622, 0.5806, 0.5959, 0.5693,
        0.5775, 0.5532, 0.5910, 0.5572, 0.5748, 0.5672, 0.5627],
       device='cuda:0') torch.Size([16])
percent tensor([0.5830, 0.5885, 0.5804, 0.5743, 0.5867, 0.5806, 0.5943, 0.5875, 0.5793,
        0.5860, 0.5852, 0.5910, 0.5824, 0.5832, 0.5904, 0.5837],
       device='cuda:0') torch.Size([16])
percent tensor([0.6189, 0.6238, 0.5782, 0.5589, 0.5604, 0.5824, 0.6082, 0.5759, 0.5934,
        0.6231, 0.6118, 0.5985, 0.6429, 0.6097, 0.6091, 0.6197],
       device='cuda:0') torch.Size([16])
percent tensor([0.6514, 0.6422, 0.6115, 0.6204, 0.6229, 0.6692, 0.6526, 0.6183, 0.6352,
        0.6444, 0.6487, 0.6303, 0.6455, 0.6448, 0.6577, 0.6536],
       device='cuda:0') torch.Size([16])
percent tensor([0.5571, 0.5219, 0.6462, 0.6786, 0.6700, 0.5935, 0.5813, 0.6627, 0.6305,
        0.5227, 0.5774, 0.6207, 0.4640, 0.6603, 0.6143, 0.5673],
       device='cuda:0') torch.Size([16])
percent tensor([0.5262, 0.6930, 0.6507, 0.6167, 0.6336, 0.7338, 0.6363, 0.5100, 0.6567,
        0.6496, 0.7297, 0.6094, 0.6935, 0.7085, 0.4685, 0.5110],
       device='cuda:0') torch.Size([16])
percent tensor([0.7215, 0.7438, 0.7283, 0.6397, 0.6664, 0.7463, 0.7456, 0.6270, 0.7072,
        0.7197, 0.7256, 0.5866, 0.7521, 0.7303, 0.5499, 0.6667],
       device='cuda:0') torch.Size([16])
percent tensor([0.9996, 0.9998, 0.9999, 0.9998, 0.9997, 0.9996, 0.9999, 0.9999, 0.9999,
        0.9999, 0.9999, 0.9998, 0.9997, 0.9999, 0.9998, 0.9994],
       device='cuda:0') torch.Size([16])
Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 3, 3, 3]) tensor(189.9611, device='cuda:0')
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(823.6655, device='cuda:0')
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(844.6215, device='cuda:0')
Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([128, 64, 3, 3]) tensor(1522.3629, device='cuda:0')
Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([128, 64, 1, 1]) tensor(485.4235, device='cuda:0')
Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([128, 128, 3, 3]) tensor(2281.7239, device='cuda:0')
Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([256, 128, 3, 3]) tensor(4244.0474, device='cuda:0')
Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([256, 128, 1, 1]) tensor(1350.8365, device='cuda:0')
Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([256, 256, 3, 3]) tensor(6233.9971, device='cuda:0')
Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([512, 256, 3, 3]) tensor(11593.9131, device='cuda:0')
Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([512, 256, 1, 1]) tensor(3818.9685, device='cuda:0')
Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([512, 512, 3, 3]) tensor(16120.3174, device='cuda:0')
Epoch: 181 | Batch_idx: 0 |  Loss: (0.0520) |  Loss2: (0.0000) | Acc: (99.00%) (127/128)
Epoch: 181 | Batch_idx: 10 |  Loss: (0.0773) |  Loss2: (0.0000) | Acc: (97.00%) (1379/1408)
Epoch: 181 | Batch_idx: 20 |  Loss: (0.0832) |  Loss2: (0.0000) | Acc: (97.00%) (2621/2688)
Epoch: 181 | Batch_idx: 30 |  Loss: (0.0811) |  Loss2: (0.0000) | Acc: (97.00%) (3866/3968)
Epoch: 181 | Batch_idx: 40 |  Loss: (0.0827) |  Loss2: (0.0000) | Acc: (97.00%) (5106/5248)
Epoch: 181 | Batch_idx: 50 |  Loss: (0.0828) |  Loss2: (0.0000) | Acc: (97.00%) (6346/6528)
Epoch: 181 | Batch_idx: 60 |  Loss: (0.0818) |  Loss2: (0.0000) | Acc: (97.00%) (7599/7808)
Epoch: 181 | Batch_idx: 70 |  Loss: (0.0822) |  Loss2: (0.0000) | Acc: (97.00%) (8844/9088)
Epoch: 181 | Batch_idx: 80 |  Loss: (0.0822) |  Loss2: (0.0000) | Acc: (97.00%) (10088/10368)
Epoch: 181 | Batch_idx: 90 |  Loss: (0.0829) |  Loss2: (0.0000) | Acc: (97.00%) (11324/11648)
Epoch: 181 | Batch_idx: 100 |  Loss: (0.0828) |  Loss2: (0.0000) | Acc: (97.00%) (12572/12928)
Epoch: 181 | Batch_idx: 110 |  Loss: (0.0848) |  Loss2: (0.0000) | Acc: (97.00%) (13812/14208)
Epoch: 181 | Batch_idx: 120 |  Loss: (0.0851) |  Loss2: (0.0000) | Acc: (97.00%) (15057/15488)
Epoch: 181 | Batch_idx: 130 |  Loss: (0.0850) |  Loss2: (0.0000) | Acc: (97.00%) (16308/16768)
Epoch: 181 | Batch_idx: 140 |  Loss: (0.0848) |  Loss2: (0.0000) | Acc: (97.00%) (17557/18048)
Epoch: 181 | Batch_idx: 150 |  Loss: (0.0850) |  Loss2: (0.0000) | Acc: (97.00%) (18791/19328)
Epoch: 181 | Batch_idx: 160 |  Loss: (0.0847) |  Loss2: (0.0000) | Acc: (97.00%) (20040/20608)
Epoch: 181 | Batch_idx: 170 |  Loss: (0.0858) |  Loss2: (0.0000) | Acc: (97.00%) (21278/21888)
Epoch: 181 | Batch_idx: 180 |  Loss: (0.0858) |  Loss2: (0.0000) | Acc: (97.00%) (22518/23168)
Epoch: 181 | Batch_idx: 190 |  Loss: (0.0860) |  Loss2: (0.0000) | Acc: (97.00%) (23765/24448)
Epoch: 181 | Batch_idx: 200 |  Loss: (0.0855) |  Loss2: (0.0000) | Acc: (97.00%) (25018/25728)
Epoch: 181 | Batch_idx: 210 |  Loss: (0.0851) |  Loss2: (0.0000) | Acc: (97.00%) (26267/27008)
Epoch: 181 | Batch_idx: 220 |  Loss: (0.0857) |  Loss2: (0.0000) | Acc: (97.00%) (27503/28288)
Epoch: 181 | Batch_idx: 230 |  Loss: (0.0861) |  Loss2: (0.0000) | Acc: (97.00%) (28742/29568)
Epoch: 181 | Batch_idx: 240 |  Loss: (0.0858) |  Loss2: (0.0000) | Acc: (97.00%) (29990/30848)
Epoch: 181 | Batch_idx: 250 |  Loss: (0.0853) |  Loss2: (0.0000) | Acc: (97.00%) (31237/32128)
Epoch: 181 | Batch_idx: 260 |  Loss: (0.0852) |  Loss2: (0.0000) | Acc: (97.00%) (32483/33408)
Epoch: 181 | Batch_idx: 270 |  Loss: (0.0849) |  Loss2: (0.0000) | Acc: (97.00%) (33733/34688)
Epoch: 181 | Batch_idx: 280 |  Loss: (0.0852) |  Loss2: (0.0000) | Acc: (97.00%) (34969/35968)
Epoch: 181 | Batch_idx: 290 |  Loss: (0.0855) |  Loss2: (0.0000) | Acc: (97.00%) (36210/37248)
Epoch: 181 | Batch_idx: 300 |  Loss: (0.0855) |  Loss2: (0.0000) | Acc: (97.00%) (37453/38528)
Epoch: 181 | Batch_idx: 310 |  Loss: (0.0853) |  Loss2: (0.0000) | Acc: (97.00%) (38698/39808)
Epoch: 181 | Batch_idx: 320 |  Loss: (0.0853) |  Loss2: (0.0000) | Acc: (97.00%) (39942/41088)
Epoch: 181 | Batch_idx: 330 |  Loss: (0.0860) |  Loss2: (0.0000) | Acc: (97.00%) (41176/42368)
Epoch: 181 | Batch_idx: 340 |  Loss: (0.0860) |  Loss2: (0.0000) | Acc: (97.00%) (42419/43648)
Epoch: 181 | Batch_idx: 350 |  Loss: (0.0861) |  Loss2: (0.0000) | Acc: (97.00%) (43662/44928)
Epoch: 181 | Batch_idx: 360 |  Loss: (0.0864) |  Loss2: (0.0000) | Acc: (97.00%) (44894/46208)
Epoch: 181 | Batch_idx: 370 |  Loss: (0.0869) |  Loss2: (0.0000) | Acc: (97.00%) (46131/47488)
Epoch: 181 | Batch_idx: 380 |  Loss: (0.0868) |  Loss2: (0.0000) | Acc: (97.00%) (47371/48768)
Epoch: 181 | Batch_idx: 390 |  Loss: (0.0873) |  Loss2: (0.0000) | Acc: (97.00%) (48559/50000)
# TEST : Loss: (0.3967) | Acc: (88.00%) (8895/10000)
percent tensor([0.5566, 0.5713, 0.5986, 0.5910, 0.6002, 0.5636, 0.5821, 0.5975, 0.5706,
        0.5788, 0.5544, 0.5921, 0.5583, 0.5768, 0.5689, 0.5640],
       device='cuda:0') torch.Size([16])
percent tensor([0.5826, 0.5883, 0.5799, 0.5737, 0.5860, 0.5800, 0.5938, 0.5871, 0.5789,
        0.5858, 0.5851, 0.5907, 0.5823, 0.5827, 0.5902, 0.5833],
       device='cuda:0') torch.Size([16])
percent tensor([0.6208, 0.6257, 0.5793, 0.5604, 0.5607, 0.5847, 0.6095, 0.5763, 0.5936,
        0.6247, 0.6128, 0.5994, 0.6443, 0.6110, 0.6111, 0.6219],
       device='cuda:0') torch.Size([16])
percent tensor([0.6526, 0.6424, 0.6121, 0.6206, 0.6235, 0.6708, 0.6533, 0.6187, 0.6354,
        0.6448, 0.6491, 0.6306, 0.6461, 0.6448, 0.6586, 0.6548],
       device='cuda:0') torch.Size([16])
percent tensor([0.5551, 0.5197, 0.6437, 0.6759, 0.6674, 0.5907, 0.5783, 0.6593, 0.6274,
        0.5205, 0.5743, 0.6164, 0.4604, 0.6571, 0.6126, 0.5633],
       device='cuda:0') torch.Size([16])
percent tensor([0.5081, 0.6787, 0.6392, 0.5991, 0.6174, 0.7247, 0.6218, 0.4958, 0.6456,
        0.6362, 0.7195, 0.5969, 0.6810, 0.6963, 0.4513, 0.4947],
       device='cuda:0') torch.Size([16])
percent tensor([0.7186, 0.7422, 0.7285, 0.6372, 0.6655, 0.7476, 0.7445, 0.6278, 0.7053,
        0.7194, 0.7231, 0.5798, 0.7501, 0.7278, 0.5479, 0.6663],
       device='cuda:0') torch.Size([16])
percent tensor([0.9996, 0.9998, 0.9999, 0.9998, 0.9997, 0.9996, 0.9999, 0.9999, 0.9999,
        0.9999, 0.9999, 0.9998, 0.9997, 0.9999, 0.9998, 0.9994],
       device='cuda:0') torch.Size([16])
True Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=128, out_features=16, bias=False)
False Linear(in_features=16, out_features=2, bias=False)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=128, out_features=16, bias=False)
False Linear(in_features=16, out_features=2, bias=False)
True Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=256, out_features=32, bias=False)
False Linear(in_features=32, out_features=2, bias=False)
True Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=256, out_features=32, bias=False)
False Linear(in_features=32, out_features=2, bias=False)
True Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=512, out_features=64, bias=False)
False Linear(in_features=64, out_features=2, bias=False)
True Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=512, out_features=64, bias=False)
False Linear(in_features=64, out_features=2, bias=False)
True Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1024, out_features=128, bias=False)
False Linear(in_features=128, out_features=2, bias=False)
True Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1024, out_features=128, bias=False)
False Linear(in_features=128, out_features=2, bias=False)
True Linear(in_features=512, out_features=10, bias=True)
Epoch: 182 | Batch_idx: 0 |  Loss: (0.0876) |  Loss2: (0.0000) | Acc: (97.00%) (125/128)
Epoch: 182 | Batch_idx: 10 |  Loss: (0.0845) |  Loss2: (0.0000) | Acc: (97.00%) (1367/1408)
Epoch: 182 | Batch_idx: 20 |  Loss: (0.0881) |  Loss2: (0.0000) | Acc: (96.00%) (2602/2688)
Epoch: 182 | Batch_idx: 30 |  Loss: (0.0961) |  Loss2: (0.0000) | Acc: (96.00%) (3830/3968)
Epoch: 182 | Batch_idx: 40 |  Loss: (0.0968) |  Loss2: (0.0000) | Acc: (96.00%) (5059/5248)
Epoch: 182 | Batch_idx: 50 |  Loss: (0.0966) |  Loss2: (0.0000) | Acc: (96.00%) (6294/6528)
Epoch: 182 | Batch_idx: 60 |  Loss: (0.0973) |  Loss2: (0.0000) | Acc: (96.00%) (7534/7808)
Epoch: 182 | Batch_idx: 70 |  Loss: (0.0967) |  Loss2: (0.0000) | Acc: (96.00%) (8768/9088)
Epoch: 182 | Batch_idx: 80 |  Loss: (0.0957) |  Loss2: (0.0000) | Acc: (96.00%) (10006/10368)
Epoch: 182 | Batch_idx: 90 |  Loss: (0.0967) |  Loss2: (0.0000) | Acc: (96.00%) (11237/11648)
Epoch: 182 | Batch_idx: 100 |  Loss: (0.0952) |  Loss2: (0.0000) | Acc: (96.00%) (12478/12928)
Epoch: 182 | Batch_idx: 110 |  Loss: (0.0971) |  Loss2: (0.0000) | Acc: (96.00%) (13700/14208)
Epoch: 182 | Batch_idx: 120 |  Loss: (0.0968) |  Loss2: (0.0000) | Acc: (96.00%) (14932/15488)
Epoch: 182 | Batch_idx: 130 |  Loss: (0.0972) |  Loss2: (0.0000) | Acc: (96.00%) (16166/16768)
Epoch: 182 | Batch_idx: 140 |  Loss: (0.0980) |  Loss2: (0.0000) | Acc: (96.00%) (17399/18048)
Epoch: 182 | Batch_idx: 150 |  Loss: (0.1002) |  Loss2: (0.0000) | Acc: (96.00%) (18623/19328)
Epoch: 182 | Batch_idx: 160 |  Loss: (0.0997) |  Loss2: (0.0000) | Acc: (96.00%) (19867/20608)
Epoch: 182 | Batch_idx: 170 |  Loss: (0.0988) |  Loss2: (0.0000) | Acc: (96.00%) (21117/21888)
Epoch: 182 | Batch_idx: 180 |  Loss: (0.0987) |  Loss2: (0.0000) | Acc: (96.00%) (22357/23168)
Epoch: 182 | Batch_idx: 190 |  Loss: (0.0985) |  Loss2: (0.0000) | Acc: (96.00%) (23597/24448)
Epoch: 182 | Batch_idx: 200 |  Loss: (0.0993) |  Loss2: (0.0000) | Acc: (96.00%) (24829/25728)
Epoch: 182 | Batch_idx: 210 |  Loss: (0.0990) |  Loss2: (0.0000) | Acc: (96.00%) (26065/27008)
Epoch: 182 | Batch_idx: 220 |  Loss: (0.0987) |  Loss2: (0.0000) | Acc: (96.00%) (27302/28288)
Epoch: 182 | Batch_idx: 230 |  Loss: (0.0989) |  Loss2: (0.0000) | Acc: (96.00%) (28534/29568)
Epoch: 182 | Batch_idx: 240 |  Loss: (0.0997) |  Loss2: (0.0000) | Acc: (96.00%) (29758/30848)
Epoch: 182 | Batch_idx: 250 |  Loss: (0.0993) |  Loss2: (0.0000) | Acc: (96.00%) (31001/32128)
Epoch: 182 | Batch_idx: 260 |  Loss: (0.0992) |  Loss2: (0.0000) | Acc: (96.00%) (32235/33408)
Epoch: 182 | Batch_idx: 270 |  Loss: (0.0994) |  Loss2: (0.0000) | Acc: (96.00%) (33465/34688)
Epoch: 182 | Batch_idx: 280 |  Loss: (0.0992) |  Loss2: (0.0000) | Acc: (96.00%) (34701/35968)
Epoch: 182 | Batch_idx: 290 |  Loss: (0.0997) |  Loss2: (0.0000) | Acc: (96.00%) (35932/37248)
Epoch: 182 | Batch_idx: 300 |  Loss: (0.1003) |  Loss2: (0.0000) | Acc: (96.00%) (37153/38528)
Epoch: 182 | Batch_idx: 310 |  Loss: (0.1005) |  Loss2: (0.0000) | Acc: (96.00%) (38378/39808)
Epoch: 182 | Batch_idx: 320 |  Loss: (0.1005) |  Loss2: (0.0000) | Acc: (96.00%) (39620/41088)
Epoch: 182 | Batch_idx: 330 |  Loss: (0.1006) |  Loss2: (0.0000) | Acc: (96.00%) (40851/42368)
Epoch: 182 | Batch_idx: 340 |  Loss: (0.1010) |  Loss2: (0.0000) | Acc: (96.00%) (42085/43648)
Epoch: 182 | Batch_idx: 350 |  Loss: (0.1010) |  Loss2: (0.0000) | Acc: (96.00%) (43320/44928)
Epoch: 182 | Batch_idx: 360 |  Loss: (0.1013) |  Loss2: (0.0000) | Acc: (96.00%) (44549/46208)
Epoch: 182 | Batch_idx: 370 |  Loss: (0.1007) |  Loss2: (0.0000) | Acc: (96.00%) (45797/47488)
Epoch: 182 | Batch_idx: 380 |  Loss: (0.1011) |  Loss2: (0.0000) | Acc: (96.00%) (47023/48768)
Epoch: 182 | Batch_idx: 390 |  Loss: (0.1013) |  Loss2: (0.0000) | Acc: (96.00%) (48210/50000)
# TEST : Loss: (0.4176) | Acc: (88.00%) (8860/10000)
percent tensor([0.5573, 0.5694, 0.5985, 0.5895, 0.5998, 0.5642, 0.5804, 0.5965, 0.5700,
        0.5777, 0.5540, 0.5914, 0.5577, 0.5735, 0.5682, 0.5635],
       device='cuda:0') torch.Size([16])
percent tensor([0.5830, 0.5889, 0.5788, 0.5727, 0.5855, 0.5798, 0.5942, 0.5867, 0.5801,
        0.5857, 0.5864, 0.5891, 0.5825, 0.5844, 0.5898, 0.5837],
       device='cuda:0') torch.Size([16])
percent tensor([0.6201, 0.6274, 0.5703, 0.5579, 0.5555, 0.5851, 0.6117, 0.5717, 0.5939,
        0.6246, 0.6131, 0.5963, 0.6421, 0.6218, 0.6114, 0.6211],
       device='cuda:0') torch.Size([16])
percent tensor([0.6520, 0.6463, 0.6075, 0.6173, 0.6209, 0.6681, 0.6569, 0.6213, 0.6370,
        0.6458, 0.6497, 0.6287, 0.6475, 0.6544, 0.6594, 0.6528],
       device='cuda:0') torch.Size([16])
percent tensor([0.5487, 0.5032, 0.6521, 0.6853, 0.6732, 0.5757, 0.5841, 0.6679, 0.6206,
        0.5278, 0.5495, 0.6149, 0.4486, 0.6252, 0.6038, 0.5541],
       device='cuda:0') torch.Size([16])
percent tensor([0.5171, 0.6970, 0.6073, 0.6336, 0.5891, 0.7124, 0.6217, 0.4854, 0.6453,
        0.6269, 0.7137, 0.6222, 0.6829, 0.7262, 0.4831, 0.4824],
       device='cuda:0') torch.Size([16])
percent tensor([0.7238, 0.7549, 0.7180, 0.6408, 0.6444, 0.7506, 0.7466, 0.6299, 0.6890,
        0.7241, 0.7302, 0.6188, 0.7541, 0.7276, 0.5558, 0.6703],
       device='cuda:0') torch.Size([16])
percent tensor([0.9997, 0.9998, 0.9999, 0.9997, 0.9998, 0.9996, 1.0000, 0.9999, 0.9999,
        0.9999, 0.9999, 0.9998, 0.9998, 0.9998, 0.9998, 0.9995],
       device='cuda:0') torch.Size([16])
Epoch: 183 | Batch_idx: 0 |  Loss: (0.0995) |  Loss2: (0.0000) | Acc: (96.00%) (123/128)
Epoch: 183 | Batch_idx: 10 |  Loss: (0.1093) |  Loss2: (0.0000) | Acc: (96.00%) (1361/1408)
Epoch: 183 | Batch_idx: 20 |  Loss: (0.1062) |  Loss2: (0.0000) | Acc: (96.00%) (2597/2688)
Epoch: 183 | Batch_idx: 30 |  Loss: (0.1076) |  Loss2: (0.0000) | Acc: (96.00%) (3827/3968)
Epoch: 183 | Batch_idx: 40 |  Loss: (0.1004) |  Loss2: (0.0000) | Acc: (96.00%) (5076/5248)
Epoch: 183 | Batch_idx: 50 |  Loss: (0.0998) |  Loss2: (0.0000) | Acc: (96.00%) (6317/6528)
Epoch: 183 | Batch_idx: 60 |  Loss: (0.0979) |  Loss2: (0.0000) | Acc: (96.00%) (7562/7808)
Epoch: 183 | Batch_idx: 70 |  Loss: (0.0969) |  Loss2: (0.0000) | Acc: (96.00%) (8803/9088)
Epoch: 183 | Batch_idx: 80 |  Loss: (0.0973) |  Loss2: (0.0000) | Acc: (96.00%) (10035/10368)
Epoch: 183 | Batch_idx: 90 |  Loss: (0.0954) |  Loss2: (0.0000) | Acc: (96.00%) (11279/11648)
Epoch: 183 | Batch_idx: 100 |  Loss: (0.0943) |  Loss2: (0.0000) | Acc: (96.00%) (12524/12928)
Epoch: 183 | Batch_idx: 110 |  Loss: (0.0935) |  Loss2: (0.0000) | Acc: (96.00%) (13763/14208)
Epoch: 183 | Batch_idx: 120 |  Loss: (0.0936) |  Loss2: (0.0000) | Acc: (96.00%) (15001/15488)
Epoch: 183 | Batch_idx: 130 |  Loss: (0.0937) |  Loss2: (0.0000) | Acc: (96.00%) (16247/16768)
Epoch: 183 | Batch_idx: 140 |  Loss: (0.0938) |  Loss2: (0.0000) | Acc: (96.00%) (17485/18048)
Epoch: 183 | Batch_idx: 150 |  Loss: (0.0939) |  Loss2: (0.0000) | Acc: (96.00%) (18728/19328)
Epoch: 183 | Batch_idx: 160 |  Loss: (0.0920) |  Loss2: (0.0000) | Acc: (96.00%) (19979/20608)
Epoch: 183 | Batch_idx: 170 |  Loss: (0.0931) |  Loss2: (0.0000) | Acc: (96.00%) (21217/21888)
Epoch: 183 | Batch_idx: 180 |  Loss: (0.0926) |  Loss2: (0.0000) | Acc: (96.00%) (22457/23168)
Epoch: 183 | Batch_idx: 190 |  Loss: (0.0930) |  Loss2: (0.0000) | Acc: (96.00%) (23693/24448)
Epoch: 183 | Batch_idx: 200 |  Loss: (0.0926) |  Loss2: (0.0000) | Acc: (96.00%) (24939/25728)
Epoch: 183 | Batch_idx: 210 |  Loss: (0.0932) |  Loss2: (0.0000) | Acc: (96.00%) (26167/27008)
Epoch: 183 | Batch_idx: 220 |  Loss: (0.0933) |  Loss2: (0.0000) | Acc: (96.00%) (27410/28288)
Epoch: 183 | Batch_idx: 230 |  Loss: (0.0935) |  Loss2: (0.0000) | Acc: (96.00%) (28640/29568)
Epoch: 183 | Batch_idx: 240 |  Loss: (0.0935) |  Loss2: (0.0000) | Acc: (96.00%) (29873/30848)
Epoch: 183 | Batch_idx: 250 |  Loss: (0.0937) |  Loss2: (0.0000) | Acc: (96.00%) (31104/32128)
Epoch: 183 | Batch_idx: 260 |  Loss: (0.0940) |  Loss2: (0.0000) | Acc: (96.00%) (32334/33408)
Epoch: 183 | Batch_idx: 270 |  Loss: (0.0944) |  Loss2: (0.0000) | Acc: (96.00%) (33572/34688)
Epoch: 183 | Batch_idx: 280 |  Loss: (0.0942) |  Loss2: (0.0000) | Acc: (96.00%) (34817/35968)
Epoch: 183 | Batch_idx: 290 |  Loss: (0.0939) |  Loss2: (0.0000) | Acc: (96.00%) (36059/37248)
Epoch: 183 | Batch_idx: 300 |  Loss: (0.0939) |  Loss2: (0.0000) | Acc: (96.00%) (37301/38528)
Epoch: 183 | Batch_idx: 310 |  Loss: (0.0935) |  Loss2: (0.0000) | Acc: (96.00%) (38545/39808)
Epoch: 183 | Batch_idx: 320 |  Loss: (0.0931) |  Loss2: (0.0000) | Acc: (96.00%) (39789/41088)
Epoch: 183 | Batch_idx: 330 |  Loss: (0.0934) |  Loss2: (0.0000) | Acc: (96.00%) (41019/42368)
Epoch: 183 | Batch_idx: 340 |  Loss: (0.0932) |  Loss2: (0.0000) | Acc: (96.00%) (42262/43648)
Epoch: 183 | Batch_idx: 350 |  Loss: (0.0934) |  Loss2: (0.0000) | Acc: (96.00%) (43495/44928)
Epoch: 183 | Batch_idx: 360 |  Loss: (0.0934) |  Loss2: (0.0000) | Acc: (96.00%) (44734/46208)
Epoch: 183 | Batch_idx: 370 |  Loss: (0.0934) |  Loss2: (0.0000) | Acc: (96.00%) (45969/47488)
Epoch: 183 | Batch_idx: 380 |  Loss: (0.0935) |  Loss2: (0.0000) | Acc: (96.00%) (47201/48768)
Epoch: 183 | Batch_idx: 390 |  Loss: (0.0936) |  Loss2: (0.0000) | Acc: (96.00%) (48390/50000)
# TEST : Loss: (0.4479) | Acc: (87.00%) (8773/10000)
percent tensor([0.5581, 0.5680, 0.6003, 0.5912, 0.6016, 0.5649, 0.5800, 0.5974, 0.5692,
        0.5774, 0.5536, 0.5929, 0.5582, 0.5708, 0.5682, 0.5627],
       device='cuda:0') torch.Size([16])
percent tensor([0.5827, 0.5872, 0.5800, 0.5729, 0.5867, 0.5792, 0.5936, 0.5866, 0.5790,
        0.5850, 0.5846, 0.5917, 0.5818, 0.5818, 0.5888, 0.5827],
       device='cuda:0') torch.Size([16])
percent tensor([0.6226, 0.6268, 0.5857, 0.5600, 0.5615, 0.5838, 0.6133, 0.5764, 0.5992,
        0.6273, 0.6120, 0.6047, 0.6459, 0.6179, 0.6083, 0.6210],
       device='cuda:0') torch.Size([16])
percent tensor([0.6530, 0.6433, 0.6112, 0.6175, 0.6203, 0.6675, 0.6543, 0.6173, 0.6382,
        0.6445, 0.6503, 0.6334, 0.6487, 0.6483, 0.6552, 0.6530],
       device='cuda:0') torch.Size([16])
percent tensor([0.5468, 0.5234, 0.6261, 0.6611, 0.6598, 0.5907, 0.5822, 0.6460, 0.6227,
        0.5297, 0.5738, 0.6050, 0.4469, 0.6450, 0.6105, 0.5711],
       device='cuda:0') torch.Size([16])
percent tensor([0.5255, 0.6870, 0.6317, 0.6095, 0.6217, 0.7096, 0.6528, 0.5260, 0.6695,
        0.6526, 0.7274, 0.6296, 0.6877, 0.7140, 0.4625, 0.5114],
       device='cuda:0') torch.Size([16])
percent tensor([0.7245, 0.7482, 0.7260, 0.6433, 0.6641, 0.7428, 0.7437, 0.6450, 0.6851,
        0.7447, 0.7284, 0.6004, 0.7664, 0.7306, 0.5692, 0.6667],
       device='cuda:0') torch.Size([16])
percent tensor([0.9997, 0.9999, 0.9998, 0.9997, 0.9997, 0.9996, 0.9999, 0.9998, 0.9999,
        0.9999, 0.9999, 0.9996, 0.9998, 0.9999, 0.9998, 0.9995],
       device='cuda:0') torch.Size([16])
Epoch: 184 | Batch_idx: 0 |  Loss: (0.0601) |  Loss2: (0.0000) | Acc: (98.00%) (126/128)
Epoch: 184 | Batch_idx: 10 |  Loss: (0.0824) |  Loss2: (0.0000) | Acc: (96.00%) (1365/1408)
Epoch: 184 | Batch_idx: 20 |  Loss: (0.0890) |  Loss2: (0.0000) | Acc: (96.00%) (2604/2688)
Epoch: 184 | Batch_idx: 30 |  Loss: (0.0886) |  Loss2: (0.0000) | Acc: (96.00%) (3846/3968)
Epoch: 184 | Batch_idx: 40 |  Loss: (0.0925) |  Loss2: (0.0000) | Acc: (96.00%) (5078/5248)
Epoch: 184 | Batch_idx: 50 |  Loss: (0.0915) |  Loss2: (0.0000) | Acc: (96.00%) (6322/6528)
Epoch: 184 | Batch_idx: 60 |  Loss: (0.0917) |  Loss2: (0.0000) | Acc: (96.00%) (7560/7808)
Epoch: 184 | Batch_idx: 70 |  Loss: (0.0936) |  Loss2: (0.0000) | Acc: (96.00%) (8794/9088)
Epoch: 184 | Batch_idx: 80 |  Loss: (0.0911) |  Loss2: (0.0000) | Acc: (96.00%) (10044/10368)
Epoch: 184 | Batch_idx: 90 |  Loss: (0.0909) |  Loss2: (0.0000) | Acc: (96.00%) (11286/11648)
Epoch: 184 | Batch_idx: 100 |  Loss: (0.0908) |  Loss2: (0.0000) | Acc: (96.00%) (12523/12928)
Epoch: 184 | Batch_idx: 110 |  Loss: (0.0914) |  Loss2: (0.0000) | Acc: (96.00%) (13757/14208)
Epoch: 184 | Batch_idx: 120 |  Loss: (0.0909) |  Loss2: (0.0000) | Acc: (96.00%) (15001/15488)
Epoch: 184 | Batch_idx: 130 |  Loss: (0.0914) |  Loss2: (0.0000) | Acc: (96.00%) (16235/16768)
Epoch: 184 | Batch_idx: 140 |  Loss: (0.0911) |  Loss2: (0.0000) | Acc: (96.00%) (17484/18048)
Epoch: 184 | Batch_idx: 150 |  Loss: (0.0905) |  Loss2: (0.0000) | Acc: (96.00%) (18722/19328)
Epoch: 184 | Batch_idx: 160 |  Loss: (0.0899) |  Loss2: (0.0000) | Acc: (96.00%) (19964/20608)
Epoch: 184 | Batch_idx: 170 |  Loss: (0.0899) |  Loss2: (0.0000) | Acc: (96.00%) (21198/21888)
Epoch: 184 | Batch_idx: 180 |  Loss: (0.0906) |  Loss2: (0.0000) | Acc: (96.00%) (22431/23168)
Epoch: 184 | Batch_idx: 190 |  Loss: (0.0905) |  Loss2: (0.0000) | Acc: (96.00%) (23674/24448)
Epoch: 184 | Batch_idx: 200 |  Loss: (0.0907) |  Loss2: (0.0000) | Acc: (96.00%) (24911/25728)
Epoch: 184 | Batch_idx: 210 |  Loss: (0.0902) |  Loss2: (0.0000) | Acc: (96.00%) (26159/27008)
Epoch: 184 | Batch_idx: 220 |  Loss: (0.0898) |  Loss2: (0.0000) | Acc: (96.00%) (27403/28288)
Epoch: 184 | Batch_idx: 230 |  Loss: (0.0899) |  Loss2: (0.0000) | Acc: (96.00%) (28640/29568)
Epoch: 184 | Batch_idx: 240 |  Loss: (0.0894) |  Loss2: (0.0000) | Acc: (96.00%) (29888/30848)
Epoch: 184 | Batch_idx: 250 |  Loss: (0.0895) |  Loss2: (0.0000) | Acc: (96.00%) (31130/32128)
Epoch: 184 | Batch_idx: 260 |  Loss: (0.0890) |  Loss2: (0.0000) | Acc: (96.00%) (32381/33408)
Epoch: 184 | Batch_idx: 270 |  Loss: (0.0887) |  Loss2: (0.0000) | Acc: (96.00%) (33618/34688)
Epoch: 184 | Batch_idx: 280 |  Loss: (0.0890) |  Loss2: (0.0000) | Acc: (96.00%) (34860/35968)
Epoch: 184 | Batch_idx: 290 |  Loss: (0.0887) |  Loss2: (0.0000) | Acc: (96.00%) (36109/37248)
Epoch: 184 | Batch_idx: 300 |  Loss: (0.0894) |  Loss2: (0.0000) | Acc: (96.00%) (37345/38528)
Epoch: 184 | Batch_idx: 310 |  Loss: (0.0887) |  Loss2: (0.0000) | Acc: (96.00%) (38603/39808)
Epoch: 184 | Batch_idx: 320 |  Loss: (0.0890) |  Loss2: (0.0000) | Acc: (96.00%) (39840/41088)
Epoch: 184 | Batch_idx: 330 |  Loss: (0.0892) |  Loss2: (0.0000) | Acc: (96.00%) (41082/42368)
Epoch: 184 | Batch_idx: 340 |  Loss: (0.0894) |  Loss2: (0.0000) | Acc: (96.00%) (42322/43648)
Epoch: 184 | Batch_idx: 350 |  Loss: (0.0895) |  Loss2: (0.0000) | Acc: (96.00%) (43561/44928)
Epoch: 184 | Batch_idx: 360 |  Loss: (0.0899) |  Loss2: (0.0000) | Acc: (96.00%) (44800/46208)
Epoch: 184 | Batch_idx: 370 |  Loss: (0.0897) |  Loss2: (0.0000) | Acc: (96.00%) (46046/47488)
Epoch: 184 | Batch_idx: 380 |  Loss: (0.0896) |  Loss2: (0.0000) | Acc: (96.00%) (47288/48768)
Epoch: 184 | Batch_idx: 390 |  Loss: (0.0898) |  Loss2: (0.0000) | Acc: (96.00%) (48480/50000)
# TEST : Loss: (0.4151) | Acc: (88.00%) (8840/10000)
percent tensor([0.5564, 0.5700, 0.5953, 0.5902, 0.5978, 0.5645, 0.5792, 0.5957, 0.5682,
        0.5763, 0.5530, 0.5876, 0.5567, 0.5744, 0.5688, 0.5630],
       device='cuda:0') torch.Size([16])
percent tensor([0.5819, 0.5877, 0.5791, 0.5713, 0.5864, 0.5788, 0.5941, 0.5849, 0.5796,
        0.5849, 0.5851, 0.5900, 0.5814, 0.5832, 0.5884, 0.5829],
       device='cuda:0') torch.Size([16])
percent tensor([0.6268, 0.6314, 0.5863, 0.5642, 0.5638, 0.5888, 0.6161, 0.5830, 0.5994,
        0.6320, 0.6153, 0.6063, 0.6489, 0.6189, 0.6141, 0.6274],
       device='cuda:0') torch.Size([16])
percent tensor([0.6563, 0.6459, 0.6156, 0.6216, 0.6284, 0.6746, 0.6578, 0.6226, 0.6393,
        0.6464, 0.6489, 0.6332, 0.6492, 0.6537, 0.6595, 0.6566],
       device='cuda:0') torch.Size([16])
percent tensor([0.5327, 0.4921, 0.6355, 0.6635, 0.6664, 0.5783, 0.5644, 0.6474, 0.6010,
        0.5107, 0.5502, 0.5999, 0.4314, 0.6096, 0.5946, 0.5521],
       device='cuda:0') torch.Size([16])
percent tensor([0.5188, 0.6711, 0.6356, 0.6467, 0.6239, 0.7172, 0.6454, 0.5184, 0.6422,
        0.6180, 0.7082, 0.6048, 0.6795, 0.6972, 0.4699, 0.4959],
       device='cuda:0') torch.Size([16])
percent tensor([0.7134, 0.7477, 0.7385, 0.6615, 0.6674, 0.7372, 0.7351, 0.6547, 0.6821,
        0.7302, 0.7254, 0.6276, 0.7493, 0.7181, 0.5650, 0.6612],
       device='cuda:0') torch.Size([16])
percent tensor([0.9997, 0.9998, 0.9998, 0.9998, 0.9998, 0.9997, 0.9999, 0.9999, 0.9999,
        0.9999, 0.9999, 0.9996, 0.9996, 0.9998, 0.9998, 0.9994],
       device='cuda:0') torch.Size([16])
Epoch: 185 | Batch_idx: 0 |  Loss: (0.0885) |  Loss2: (0.0000) | Acc: (96.00%) (124/128)
Epoch: 185 | Batch_idx: 10 |  Loss: (0.0829) |  Loss2: (0.0000) | Acc: (97.00%) (1367/1408)
Epoch: 185 | Batch_idx: 20 |  Loss: (0.0820) |  Loss2: (0.0000) | Acc: (97.00%) (2610/2688)
Epoch: 185 | Batch_idx: 30 |  Loss: (0.0862) |  Loss2: (0.0000) | Acc: (96.00%) (3848/3968)
Epoch: 185 | Batch_idx: 40 |  Loss: (0.0839) |  Loss2: (0.0000) | Acc: (97.00%) (5098/5248)
Epoch: 185 | Batch_idx: 50 |  Loss: (0.0874) |  Loss2: (0.0000) | Acc: (96.00%) (6326/6528)
Epoch: 185 | Batch_idx: 60 |  Loss: (0.0885) |  Loss2: (0.0000) | Acc: (96.00%) (7558/7808)
Epoch: 185 | Batch_idx: 70 |  Loss: (0.0892) |  Loss2: (0.0000) | Acc: (96.00%) (8796/9088)
Epoch: 185 | Batch_idx: 80 |  Loss: (0.0869) |  Loss2: (0.0000) | Acc: (96.00%) (10048/10368)
Epoch: 185 | Batch_idx: 90 |  Loss: (0.0851) |  Loss2: (0.0000) | Acc: (97.00%) (11301/11648)
Epoch: 185 | Batch_idx: 100 |  Loss: (0.0856) |  Loss2: (0.0000) | Acc: (97.00%) (12546/12928)
Epoch: 185 | Batch_idx: 110 |  Loss: (0.0853) |  Loss2: (0.0000) | Acc: (97.00%) (13789/14208)
Epoch: 185 | Batch_idx: 120 |  Loss: (0.0843) |  Loss2: (0.0000) | Acc: (97.00%) (15038/15488)
Epoch: 185 | Batch_idx: 130 |  Loss: (0.0844) |  Loss2: (0.0000) | Acc: (97.00%) (16281/16768)
Epoch: 185 | Batch_idx: 140 |  Loss: (0.0856) |  Loss2: (0.0000) | Acc: (97.00%) (17520/18048)
Epoch: 185 | Batch_idx: 150 |  Loss: (0.0856) |  Loss2: (0.0000) | Acc: (97.00%) (18761/19328)
Epoch: 185 | Batch_idx: 160 |  Loss: (0.0854) |  Loss2: (0.0000) | Acc: (97.00%) (20009/20608)
Epoch: 185 | Batch_idx: 170 |  Loss: (0.0866) |  Loss2: (0.0000) | Acc: (97.00%) (21247/21888)
Epoch: 185 | Batch_idx: 180 |  Loss: (0.0858) |  Loss2: (0.0000) | Acc: (97.00%) (22501/23168)
Epoch: 185 | Batch_idx: 190 |  Loss: (0.0856) |  Loss2: (0.0000) | Acc: (97.00%) (23752/24448)
Epoch: 185 | Batch_idx: 200 |  Loss: (0.0851) |  Loss2: (0.0000) | Acc: (97.00%) (25003/25728)
Epoch: 185 | Batch_idx: 210 |  Loss: (0.0851) |  Loss2: (0.0000) | Acc: (97.00%) (26248/27008)
Epoch: 185 | Batch_idx: 220 |  Loss: (0.0852) |  Loss2: (0.0000) | Acc: (97.00%) (27491/28288)
Epoch: 185 | Batch_idx: 230 |  Loss: (0.0850) |  Loss2: (0.0000) | Acc: (97.00%) (28734/29568)
Epoch: 185 | Batch_idx: 240 |  Loss: (0.0853) |  Loss2: (0.0000) | Acc: (97.00%) (29979/30848)
Epoch: 185 | Batch_idx: 250 |  Loss: (0.0847) |  Loss2: (0.0000) | Acc: (97.00%) (31226/32128)
Epoch: 185 | Batch_idx: 260 |  Loss: (0.0854) |  Loss2: (0.0000) | Acc: (97.00%) (32460/33408)
Epoch: 185 | Batch_idx: 270 |  Loss: (0.0853) |  Loss2: (0.0000) | Acc: (97.00%) (33708/34688)
Epoch: 185 | Batch_idx: 280 |  Loss: (0.0853) |  Loss2: (0.0000) | Acc: (97.00%) (34950/35968)
Epoch: 185 | Batch_idx: 290 |  Loss: (0.0865) |  Loss2: (0.0000) | Acc: (97.00%) (36167/37248)
Epoch: 185 | Batch_idx: 300 |  Loss: (0.0864) |  Loss2: (0.0000) | Acc: (97.00%) (37415/38528)
Epoch: 185 | Batch_idx: 310 |  Loss: (0.0865) |  Loss2: (0.0000) | Acc: (97.00%) (38656/39808)
Epoch: 185 | Batch_idx: 320 |  Loss: (0.0873) |  Loss2: (0.0000) | Acc: (97.00%) (39890/41088)
Epoch: 185 | Batch_idx: 330 |  Loss: (0.0869) |  Loss2: (0.0000) | Acc: (97.00%) (41143/42368)
Epoch: 185 | Batch_idx: 340 |  Loss: (0.0866) |  Loss2: (0.0000) | Acc: (97.00%) (42391/43648)
Epoch: 185 | Batch_idx: 350 |  Loss: (0.0867) |  Loss2: (0.0000) | Acc: (97.00%) (43631/44928)
Epoch: 185 | Batch_idx: 360 |  Loss: (0.0866) |  Loss2: (0.0000) | Acc: (97.00%) (44870/46208)
Epoch: 185 | Batch_idx: 370 |  Loss: (0.0872) |  Loss2: (0.0000) | Acc: (97.00%) (46101/47488)
Epoch: 185 | Batch_idx: 380 |  Loss: (0.0872) |  Loss2: (0.0000) | Acc: (97.00%) (47342/48768)
Epoch: 185 | Batch_idx: 390 |  Loss: (0.0875) |  Loss2: (0.0000) | Acc: (97.00%) (48532/50000)
=> saving checkpoint 'drive/app/torch/save_Schedule/checkpoint_185.pth.tar'
# TEST : Loss: (0.4282) | Acc: (87.00%) (8773/10000)
percent tensor([0.5568, 0.5714, 0.5986, 0.5918, 0.5994, 0.5639, 0.5814, 0.5987, 0.5699,
        0.5786, 0.5548, 0.5911, 0.5583, 0.5765, 0.5690, 0.5641],
       device='cuda:0') torch.Size([16])
percent tensor([0.5829, 0.5876, 0.5809, 0.5741, 0.5874, 0.5799, 0.5943, 0.5871, 0.5800,
        0.5847, 0.5852, 0.5906, 0.5821, 0.5828, 0.5894, 0.5836],
       device='cuda:0') torch.Size([16])
percent tensor([0.6254, 0.6274, 0.5836, 0.5617, 0.5619, 0.5869, 0.6110, 0.5771, 0.5991,
        0.6298, 0.6152, 0.6046, 0.6479, 0.6155, 0.6114, 0.6244],
       device='cuda:0') torch.Size([16])
percent tensor([0.6547, 0.6445, 0.6116, 0.6202, 0.6239, 0.6734, 0.6532, 0.6202, 0.6403,
        0.6461, 0.6510, 0.6303, 0.6520, 0.6493, 0.6581, 0.6557],
       device='cuda:0') torch.Size([16])
percent tensor([0.5457, 0.5032, 0.6340, 0.6632, 0.6570, 0.5777, 0.5648, 0.6487, 0.6108,
        0.5222, 0.5665, 0.5929, 0.4451, 0.6349, 0.5957, 0.5629],
       device='cuda:0') torch.Size([16])
percent tensor([0.5106, 0.6915, 0.6200, 0.6264, 0.6080, 0.7018, 0.6451, 0.5048, 0.6689,
        0.6475, 0.7268, 0.6556, 0.6929, 0.7095, 0.4645, 0.4873],
       device='cuda:0') torch.Size([16])
percent tensor([0.7159, 0.7584, 0.7137, 0.6571, 0.6542, 0.7447, 0.7401, 0.6356, 0.7040,
        0.7420, 0.7357, 0.6434, 0.7648, 0.7308, 0.5749, 0.6648],
       device='cuda:0') torch.Size([16])
percent tensor([0.9997, 0.9997, 0.9999, 0.9998, 0.9999, 0.9997, 0.9999, 0.9999, 0.9999,
        0.9999, 0.9998, 0.9996, 0.9997, 0.9998, 0.9998, 0.9994],
       device='cuda:0') torch.Size([16])
Epoch: 186 | Batch_idx: 0 |  Loss: (0.0751) |  Loss2: (0.0000) | Acc: (97.00%) (125/128)
Epoch: 186 | Batch_idx: 10 |  Loss: (0.1028) |  Loss2: (0.0000) | Acc: (96.00%) (1363/1408)
Epoch: 186 | Batch_idx: 20 |  Loss: (0.0957) |  Loss2: (0.0000) | Acc: (96.00%) (2603/2688)
Epoch: 186 | Batch_idx: 30 |  Loss: (0.0986) |  Loss2: (0.0000) | Acc: (96.00%) (3839/3968)
Epoch: 186 | Batch_idx: 40 |  Loss: (0.0928) |  Loss2: (0.0000) | Acc: (96.00%) (5083/5248)
Epoch: 186 | Batch_idx: 50 |  Loss: (0.0879) |  Loss2: (0.0000) | Acc: (97.00%) (6333/6528)
Epoch: 186 | Batch_idx: 60 |  Loss: (0.0859) |  Loss2: (0.0000) | Acc: (97.00%) (7588/7808)
Epoch: 186 | Batch_idx: 70 |  Loss: (0.0859) |  Loss2: (0.0000) | Acc: (97.00%) (8829/9088)
Epoch: 186 | Batch_idx: 80 |  Loss: (0.0871) |  Loss2: (0.0000) | Acc: (97.00%) (10060/10368)
Epoch: 186 | Batch_idx: 90 |  Loss: (0.0876) |  Loss2: (0.0000) | Acc: (96.00%) (11297/11648)
Epoch: 186 | Batch_idx: 100 |  Loss: (0.0871) |  Loss2: (0.0000) | Acc: (97.00%) (12541/12928)
Epoch: 186 | Batch_idx: 110 |  Loss: (0.0851) |  Loss2: (0.0000) | Acc: (97.00%) (13795/14208)
Epoch: 186 | Batch_idx: 120 |  Loss: (0.0851) |  Loss2: (0.0000) | Acc: (97.00%) (15037/15488)
Epoch: 186 | Batch_idx: 130 |  Loss: (0.0860) |  Loss2: (0.0000) | Acc: (97.00%) (16273/16768)
Epoch: 186 | Batch_idx: 140 |  Loss: (0.0861) |  Loss2: (0.0000) | Acc: (97.00%) (17515/18048)
Epoch: 186 | Batch_idx: 150 |  Loss: (0.0852) |  Loss2: (0.0000) | Acc: (97.00%) (18769/19328)
Epoch: 186 | Batch_idx: 160 |  Loss: (0.0851) |  Loss2: (0.0000) | Acc: (97.00%) (20021/20608)
Epoch: 186 | Batch_idx: 170 |  Loss: (0.0850) |  Loss2: (0.0000) | Acc: (97.00%) (21265/21888)
Epoch: 186 | Batch_idx: 180 |  Loss: (0.0845) |  Loss2: (0.0000) | Acc: (97.00%) (22519/23168)
Epoch: 186 | Batch_idx: 190 |  Loss: (0.0835) |  Loss2: (0.0000) | Acc: (97.00%) (23770/24448)
Epoch: 186 | Batch_idx: 200 |  Loss: (0.0832) |  Loss2: (0.0000) | Acc: (97.00%) (25023/25728)
Epoch: 186 | Batch_idx: 210 |  Loss: (0.0831) |  Loss2: (0.0000) | Acc: (97.00%) (26265/27008)
Epoch: 186 | Batch_idx: 220 |  Loss: (0.0833) |  Loss2: (0.0000) | Acc: (97.00%) (27509/28288)
Epoch: 186 | Batch_idx: 230 |  Loss: (0.0839) |  Loss2: (0.0000) | Acc: (97.00%) (28745/29568)
Epoch: 186 | Batch_idx: 240 |  Loss: (0.0844) |  Loss2: (0.0000) | Acc: (97.00%) (29980/30848)
Epoch: 186 | Batch_idx: 250 |  Loss: (0.0849) |  Loss2: (0.0000) | Acc: (97.00%) (31221/32128)
Epoch: 186 | Batch_idx: 260 |  Loss: (0.0854) |  Loss2: (0.0000) | Acc: (97.00%) (32459/33408)
Epoch: 186 | Batch_idx: 270 |  Loss: (0.0855) |  Loss2: (0.0000) | Acc: (97.00%) (33704/34688)
Epoch: 186 | Batch_idx: 280 |  Loss: (0.0853) |  Loss2: (0.0000) | Acc: (97.00%) (34947/35968)
Epoch: 186 | Batch_idx: 290 |  Loss: (0.0852) |  Loss2: (0.0000) | Acc: (97.00%) (36191/37248)
Epoch: 186 | Batch_idx: 300 |  Loss: (0.0865) |  Loss2: (0.0000) | Acc: (97.00%) (37413/38528)
Epoch: 186 | Batch_idx: 310 |  Loss: (0.0864) |  Loss2: (0.0000) | Acc: (97.00%) (38658/39808)
Epoch: 186 | Batch_idx: 320 |  Loss: (0.0857) |  Loss2: (0.0000) | Acc: (97.00%) (39912/41088)
Epoch: 186 | Batch_idx: 330 |  Loss: (0.0855) |  Loss2: (0.0000) | Acc: (97.00%) (41159/42368)
Epoch: 186 | Batch_idx: 340 |  Loss: (0.0859) |  Loss2: (0.0000) | Acc: (97.00%) (42393/43648)
Epoch: 186 | Batch_idx: 350 |  Loss: (0.0856) |  Loss2: (0.0000) | Acc: (97.00%) (43643/44928)
Epoch: 186 | Batch_idx: 360 |  Loss: (0.0863) |  Loss2: (0.0000) | Acc: (97.00%) (44874/46208)
Epoch: 186 | Batch_idx: 370 |  Loss: (0.0861) |  Loss2: (0.0000) | Acc: (97.00%) (46119/47488)
Epoch: 186 | Batch_idx: 380 |  Loss: (0.0862) |  Loss2: (0.0000) | Acc: (97.00%) (47361/48768)
Epoch: 186 | Batch_idx: 390 |  Loss: (0.0861) |  Loss2: (0.0000) | Acc: (97.00%) (48556/50000)
# TEST : Loss: (0.4306) | Acc: (88.00%) (8818/10000)
percent tensor([0.5573, 0.5699, 0.5989, 0.5907, 0.6004, 0.5634, 0.5808, 0.5971, 0.5701,
        0.5777, 0.5536, 0.5916, 0.5585, 0.5743, 0.5682, 0.5629],
       device='cuda:0') torch.Size([16])
percent tensor([0.5823, 0.5866, 0.5788, 0.5730, 0.5853, 0.5808, 0.5928, 0.5857, 0.5781,
        0.5839, 0.5844, 0.5891, 0.5813, 0.5792, 0.5897, 0.5826],
       device='cuda:0') torch.Size([16])
percent tensor([0.6232, 0.6310, 0.5775, 0.5594, 0.5583, 0.5881, 0.6132, 0.5718, 0.5962,
        0.6272, 0.6167, 0.5978, 0.6466, 0.6209, 0.6141, 0.6233],
       device='cuda:0') torch.Size([16])
percent tensor([0.6527, 0.6428, 0.6099, 0.6184, 0.6197, 0.6755, 0.6517, 0.6190, 0.6356,
        0.6427, 0.6502, 0.6315, 0.6486, 0.6455, 0.6607, 0.6557],
       device='cuda:0') torch.Size([16])
percent tensor([0.5557, 0.5125, 0.6401, 0.6699, 0.6635, 0.5944, 0.5813, 0.6594, 0.6263,
        0.5245, 0.5597, 0.6117, 0.4495, 0.6470, 0.6153, 0.5703],
       device='cuda:0') torch.Size([16])
percent tensor([0.5292, 0.6855, 0.6507, 0.6162, 0.6538, 0.6871, 0.6606, 0.5308, 0.6834,
        0.6485, 0.7289, 0.6461, 0.6936, 0.7100, 0.4549, 0.4977],
       device='cuda:0') torch.Size([16])
percent tensor([0.7168, 0.7582, 0.7251, 0.6516, 0.6926, 0.7253, 0.7462, 0.6415, 0.7064,
        0.7428, 0.7340, 0.6239, 0.7574, 0.7247, 0.5567, 0.6630],
       device='cuda:0') torch.Size([16])
percent tensor([0.9997, 0.9997, 0.9998, 0.9998, 0.9998, 0.9997, 0.9999, 0.9999, 1.0000,
        0.9998, 0.9999, 0.9997, 0.9997, 0.9998, 0.9998, 0.9995],
       device='cuda:0') torch.Size([16])
Epoch: 187 | Batch_idx: 0 |  Loss: (0.0504) |  Loss2: (0.0000) | Acc: (99.00%) (127/128)
Epoch: 187 | Batch_idx: 10 |  Loss: (0.0682) |  Loss2: (0.0000) | Acc: (97.00%) (1375/1408)
Epoch: 187 | Batch_idx: 20 |  Loss: (0.0733) |  Loss2: (0.0000) | Acc: (97.00%) (2626/2688)
Epoch: 187 | Batch_idx: 30 |  Loss: (0.0750) |  Loss2: (0.0000) | Acc: (97.00%) (3872/3968)
Epoch: 187 | Batch_idx: 40 |  Loss: (0.0758) |  Loss2: (0.0000) | Acc: (97.00%) (5117/5248)
Epoch: 187 | Batch_idx: 50 |  Loss: (0.0780) |  Loss2: (0.0000) | Acc: (97.00%) (6355/6528)
Epoch: 187 | Batch_idx: 60 |  Loss: (0.0786) |  Loss2: (0.0000) | Acc: (97.00%) (7602/7808)
Epoch: 187 | Batch_idx: 70 |  Loss: (0.0798) |  Loss2: (0.0000) | Acc: (97.00%) (8840/9088)
Epoch: 187 | Batch_idx: 80 |  Loss: (0.0806) |  Loss2: (0.0000) | Acc: (97.00%) (10082/10368)
Epoch: 187 | Batch_idx: 90 |  Loss: (0.0808) |  Loss2: (0.0000) | Acc: (97.00%) (11322/11648)
Epoch: 187 | Batch_idx: 100 |  Loss: (0.0830) |  Loss2: (0.0000) | Acc: (97.00%) (12556/12928)
Epoch: 187 | Batch_idx: 110 |  Loss: (0.0830) |  Loss2: (0.0000) | Acc: (97.00%) (13798/14208)
Epoch: 187 | Batch_idx: 120 |  Loss: (0.0815) |  Loss2: (0.0000) | Acc: (97.00%) (15052/15488)
Epoch: 187 | Batch_idx: 130 |  Loss: (0.0820) |  Loss2: (0.0000) | Acc: (97.00%) (16295/16768)
Epoch: 187 | Batch_idx: 140 |  Loss: (0.0817) |  Loss2: (0.0000) | Acc: (97.00%) (17542/18048)
Epoch: 187 | Batch_idx: 150 |  Loss: (0.0822) |  Loss2: (0.0000) | Acc: (97.00%) (18787/19328)
Epoch: 187 | Batch_idx: 160 |  Loss: (0.0836) |  Loss2: (0.0000) | Acc: (97.00%) (20019/20608)
Epoch: 187 | Batch_idx: 170 |  Loss: (0.0830) |  Loss2: (0.0000) | Acc: (97.00%) (21263/21888)
Epoch: 187 | Batch_idx: 180 |  Loss: (0.0846) |  Loss2: (0.0000) | Acc: (97.00%) (22490/23168)
Epoch: 187 | Batch_idx: 190 |  Loss: (0.0849) |  Loss2: (0.0000) | Acc: (97.00%) (23733/24448)
Epoch: 187 | Batch_idx: 200 |  Loss: (0.0850) |  Loss2: (0.0000) | Acc: (97.00%) (24981/25728)
Epoch: 187 | Batch_idx: 210 |  Loss: (0.0858) |  Loss2: (0.0000) | Acc: (97.00%) (26207/27008)
Epoch: 187 | Batch_idx: 220 |  Loss: (0.0852) |  Loss2: (0.0000) | Acc: (97.00%) (27450/28288)
Epoch: 187 | Batch_idx: 230 |  Loss: (0.0850) |  Loss2: (0.0000) | Acc: (97.00%) (28694/29568)
Epoch: 187 | Batch_idx: 240 |  Loss: (0.0846) |  Loss2: (0.0000) | Acc: (97.00%) (29941/30848)
Epoch: 187 | Batch_idx: 250 |  Loss: (0.0844) |  Loss2: (0.0000) | Acc: (97.00%) (31182/32128)
Epoch: 187 | Batch_idx: 260 |  Loss: (0.0847) |  Loss2: (0.0000) | Acc: (97.00%) (32422/33408)
Epoch: 187 | Batch_idx: 270 |  Loss: (0.0854) |  Loss2: (0.0000) | Acc: (96.00%) (33647/34688)
Epoch: 187 | Batch_idx: 280 |  Loss: (0.0858) |  Loss2: (0.0000) | Acc: (96.00%) (34881/35968)
Epoch: 187 | Batch_idx: 290 |  Loss: (0.0854) |  Loss2: (0.0000) | Acc: (97.00%) (36134/37248)
Epoch: 187 | Batch_idx: 300 |  Loss: (0.0856) |  Loss2: (0.0000) | Acc: (97.00%) (37374/38528)
Epoch: 187 | Batch_idx: 310 |  Loss: (0.0853) |  Loss2: (0.0000) | Acc: (97.00%) (38622/39808)
Epoch: 187 | Batch_idx: 320 |  Loss: (0.0852) |  Loss2: (0.0000) | Acc: (97.00%) (39861/41088)
Epoch: 187 | Batch_idx: 330 |  Loss: (0.0851) |  Loss2: (0.0000) | Acc: (97.00%) (41108/42368)
Epoch: 187 | Batch_idx: 340 |  Loss: (0.0849) |  Loss2: (0.0000) | Acc: (97.00%) (42353/43648)
Epoch: 187 | Batch_idx: 350 |  Loss: (0.0851) |  Loss2: (0.0000) | Acc: (97.00%) (43590/44928)
Epoch: 187 | Batch_idx: 360 |  Loss: (0.0854) |  Loss2: (0.0000) | Acc: (97.00%) (44828/46208)
Epoch: 187 | Batch_idx: 370 |  Loss: (0.0854) |  Loss2: (0.0000) | Acc: (97.00%) (46072/47488)
Epoch: 187 | Batch_idx: 380 |  Loss: (0.0856) |  Loss2: (0.0000) | Acc: (97.00%) (47306/48768)
Epoch: 187 | Batch_idx: 390 |  Loss: (0.0863) |  Loss2: (0.0000) | Acc: (96.00%) (48492/50000)
# TEST : Loss: (0.4346) | Acc: (88.00%) (8838/10000)
percent tensor([0.5562, 0.5708, 0.5974, 0.5912, 0.5990, 0.5620, 0.5813, 0.5977, 0.5687,
        0.5787, 0.5530, 0.5918, 0.5574, 0.5763, 0.5685, 0.5634],
       device='cuda:0') torch.Size([16])
percent tensor([0.5825, 0.5881, 0.5799, 0.5741, 0.5867, 0.5799, 0.5939, 0.5864, 0.5779,
        0.5853, 0.5845, 0.5903, 0.5820, 0.5813, 0.5896, 0.5829],
       device='cuda:0') torch.Size([16])
percent tensor([0.6197, 0.6258, 0.5764, 0.5558, 0.5573, 0.5843, 0.6092, 0.5715, 0.5941,
        0.6212, 0.6101, 0.5931, 0.6413, 0.6140, 0.6090, 0.6174],
       device='cuda:0') torch.Size([16])
percent tensor([0.6499, 0.6429, 0.6072, 0.6159, 0.6204, 0.6721, 0.6521, 0.6173, 0.6330,
        0.6415, 0.6486, 0.6256, 0.6455, 0.6460, 0.6584, 0.6553],
       device='cuda:0') torch.Size([16])
percent tensor([0.5635, 0.5239, 0.6421, 0.6761, 0.6701, 0.5920, 0.5877, 0.6611, 0.6292,
        0.5341, 0.5876, 0.6227, 0.4621, 0.6517, 0.6217, 0.5766],
       device='cuda:0') torch.Size([16])
percent tensor([0.5468, 0.6649, 0.6546, 0.6370, 0.6615, 0.7173, 0.6584, 0.5396, 0.6547,
        0.6204, 0.7267, 0.6439, 0.6822, 0.6718, 0.4535, 0.4721],
       device='cuda:0') torch.Size([16])
percent tensor([0.7227, 0.7381, 0.7257, 0.6602, 0.6822, 0.7379, 0.7494, 0.6511, 0.7057,
        0.7240, 0.7446, 0.6449, 0.7656, 0.7215, 0.5599, 0.6469],
       device='cuda:0') torch.Size([16])
percent tensor([0.9996, 0.9998, 0.9999, 0.9998, 0.9998, 0.9997, 1.0000, 0.9999, 0.9999,
        0.9998, 0.9999, 0.9998, 0.9997, 0.9998, 0.9997, 0.9994],
       device='cuda:0') torch.Size([16])
Epoch: 188 | Batch_idx: 0 |  Loss: (0.0572) |  Loss2: (0.0000) | Acc: (96.00%) (123/128)
Epoch: 188 | Batch_idx: 10 |  Loss: (0.0787) |  Loss2: (0.0000) | Acc: (97.00%) (1371/1408)
Epoch: 188 | Batch_idx: 20 |  Loss: (0.0895) |  Loss2: (0.0000) | Acc: (97.00%) (2608/2688)
Epoch: 188 | Batch_idx: 30 |  Loss: (0.0818) |  Loss2: (0.0000) | Acc: (97.00%) (3857/3968)
Epoch: 188 | Batch_idx: 40 |  Loss: (0.0814) |  Loss2: (0.0000) | Acc: (97.00%) (5109/5248)
Epoch: 188 | Batch_idx: 50 |  Loss: (0.0802) |  Loss2: (0.0000) | Acc: (97.00%) (6356/6528)
Epoch: 188 | Batch_idx: 60 |  Loss: (0.0808) |  Loss2: (0.0000) | Acc: (97.00%) (7601/7808)
Epoch: 188 | Batch_idx: 70 |  Loss: (0.0808) |  Loss2: (0.0000) | Acc: (97.00%) (8847/9088)
Epoch: 188 | Batch_idx: 80 |  Loss: (0.0793) |  Loss2: (0.0000) | Acc: (97.00%) (10100/10368)
Epoch: 188 | Batch_idx: 90 |  Loss: (0.0794) |  Loss2: (0.0000) | Acc: (97.00%) (11345/11648)
Epoch: 188 | Batch_idx: 100 |  Loss: (0.0804) |  Loss2: (0.0000) | Acc: (97.00%) (12593/12928)
Epoch: 188 | Batch_idx: 110 |  Loss: (0.0799) |  Loss2: (0.0000) | Acc: (97.00%) (13842/14208)
Epoch: 188 | Batch_idx: 120 |  Loss: (0.0803) |  Loss2: (0.0000) | Acc: (97.00%) (15080/15488)
Epoch: 188 | Batch_idx: 130 |  Loss: (0.0804) |  Loss2: (0.0000) | Acc: (97.00%) (16329/16768)
Epoch: 188 | Batch_idx: 140 |  Loss: (0.0805) |  Loss2: (0.0000) | Acc: (97.00%) (17573/18048)
Epoch: 188 | Batch_idx: 150 |  Loss: (0.0796) |  Loss2: (0.0000) | Acc: (97.00%) (18829/19328)
Epoch: 188 | Batch_idx: 160 |  Loss: (0.0800) |  Loss2: (0.0000) | Acc: (97.00%) (20073/20608)
Epoch: 188 | Batch_idx: 170 |  Loss: (0.0795) |  Loss2: (0.0000) | Acc: (97.00%) (21320/21888)
Epoch: 188 | Batch_idx: 180 |  Loss: (0.0795) |  Loss2: (0.0000) | Acc: (97.00%) (22564/23168)
Epoch: 188 | Batch_idx: 190 |  Loss: (0.0799) |  Loss2: (0.0000) | Acc: (97.00%) (23801/24448)
Epoch: 188 | Batch_idx: 200 |  Loss: (0.0800) |  Loss2: (0.0000) | Acc: (97.00%) (25044/25728)
Epoch: 188 | Batch_idx: 210 |  Loss: (0.0800) |  Loss2: (0.0000) | Acc: (97.00%) (26289/27008)
Epoch: 188 | Batch_idx: 220 |  Loss: (0.0801) |  Loss2: (0.0000) | Acc: (97.00%) (27531/28288)
Epoch: 188 | Batch_idx: 230 |  Loss: (0.0798) |  Loss2: (0.0000) | Acc: (97.00%) (28782/29568)
Epoch: 188 | Batch_idx: 240 |  Loss: (0.0799) |  Loss2: (0.0000) | Acc: (97.00%) (30027/30848)
Epoch: 188 | Batch_idx: 250 |  Loss: (0.0801) |  Loss2: (0.0000) | Acc: (97.00%) (31270/32128)
Epoch: 188 | Batch_idx: 260 |  Loss: (0.0802) |  Loss2: (0.0000) | Acc: (97.00%) (32511/33408)
Epoch: 188 | Batch_idx: 270 |  Loss: (0.0804) |  Loss2: (0.0000) | Acc: (97.00%) (33754/34688)
Epoch: 188 | Batch_idx: 280 |  Loss: (0.0808) |  Loss2: (0.0000) | Acc: (97.00%) (34993/35968)
Epoch: 188 | Batch_idx: 290 |  Loss: (0.0813) |  Loss2: (0.0000) | Acc: (97.00%) (36222/37248)
Epoch: 188 | Batch_idx: 300 |  Loss: (0.0816) |  Loss2: (0.0000) | Acc: (97.00%) (37458/38528)
Epoch: 188 | Batch_idx: 310 |  Loss: (0.0815) |  Loss2: (0.0000) | Acc: (97.00%) (38702/39808)
Epoch: 188 | Batch_idx: 320 |  Loss: (0.0817) |  Loss2: (0.0000) | Acc: (97.00%) (39943/41088)
Epoch: 188 | Batch_idx: 330 |  Loss: (0.0819) |  Loss2: (0.0000) | Acc: (97.00%) (41187/42368)
Epoch: 188 | Batch_idx: 340 |  Loss: (0.0821) |  Loss2: (0.0000) | Acc: (97.00%) (42426/43648)
Epoch: 188 | Batch_idx: 350 |  Loss: (0.0830) |  Loss2: (0.0000) | Acc: (97.00%) (43652/44928)
Epoch: 188 | Batch_idx: 360 |  Loss: (0.0835) |  Loss2: (0.0000) | Acc: (97.00%) (44887/46208)
Epoch: 188 | Batch_idx: 370 |  Loss: (0.0839) |  Loss2: (0.0000) | Acc: (97.00%) (46122/47488)
Epoch: 188 | Batch_idx: 380 |  Loss: (0.0840) |  Loss2: (0.0000) | Acc: (97.00%) (47358/48768)
Epoch: 188 | Batch_idx: 390 |  Loss: (0.0839) |  Loss2: (0.0000) | Acc: (97.00%) (48560/50000)
# TEST : Loss: (0.4154) | Acc: (89.00%) (8903/10000)
percent tensor([0.5581, 0.5691, 0.6010, 0.5902, 0.6019, 0.5642, 0.5809, 0.5972, 0.5704,
        0.5781, 0.5542, 0.5932, 0.5587, 0.5722, 0.5683, 0.5631],
       device='cuda:0') torch.Size([16])
percent tensor([0.5823, 0.5873, 0.5792, 0.5732, 0.5868, 0.5799, 0.5937, 0.5855, 0.5787,
        0.5843, 0.5836, 0.5892, 0.5805, 0.5841, 0.5887, 0.5833],
       device='cuda:0') torch.Size([16])
percent tensor([0.6219, 0.6253, 0.5856, 0.5628, 0.5614, 0.5874, 0.6130, 0.5784, 0.5942,
        0.6257, 0.6132, 0.6009, 0.6431, 0.6140, 0.6127, 0.6227],
       device='cuda:0') torch.Size([16])
percent tensor([0.6533, 0.6425, 0.6081, 0.6189, 0.6224, 0.6763, 0.6522, 0.6156, 0.6340,
        0.6418, 0.6471, 0.6287, 0.6446, 0.6520, 0.6615, 0.6564],
       device='cuda:0') torch.Size([16])
percent tensor([0.5532, 0.5104, 0.6376, 0.6716, 0.6613, 0.5851, 0.5782, 0.6500, 0.6207,
        0.5323, 0.5589, 0.6099, 0.4508, 0.6281, 0.6114, 0.5686],
       device='cuda:0') torch.Size([16])
percent tensor([0.5341, 0.6793, 0.6314, 0.6419, 0.6270, 0.7156, 0.6640, 0.5226, 0.6825,
        0.6272, 0.7174, 0.6504, 0.7016, 0.7155, 0.4751, 0.5188],
       device='cuda:0') torch.Size([16])
percent tensor([0.7156, 0.7462, 0.7279, 0.6756, 0.6664, 0.7269, 0.7562, 0.6641, 0.7174,
        0.7270, 0.7357, 0.6504, 0.7579, 0.7205, 0.5570, 0.6535],
       device='cuda:0') torch.Size([16])
percent tensor([0.9995, 0.9998, 0.9999, 0.9999, 0.9997, 0.9995, 0.9999, 0.9999, 0.9999,
        0.9999, 0.9999, 0.9998, 0.9997, 0.9997, 0.9998, 0.9994],
       device='cuda:0') torch.Size([16])
False Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=128, out_features=16, bias=False)
True Linear(in_features=16, out_features=2, bias=False)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=128, out_features=16, bias=False)
True Linear(in_features=16, out_features=2, bias=False)
False Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=256, out_features=32, bias=False)
True Linear(in_features=32, out_features=2, bias=False)
False Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=256, out_features=32, bias=False)
True Linear(in_features=32, out_features=2, bias=False)
False Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=512, out_features=64, bias=False)
True Linear(in_features=64, out_features=2, bias=False)
False Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=512, out_features=64, bias=False)
True Linear(in_features=64, out_features=2, bias=False)
False Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1024, out_features=128, bias=False)
True Linear(in_features=128, out_features=2, bias=False)
False Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1024, out_features=128, bias=False)
True Linear(in_features=128, out_features=2, bias=False)
False Linear(in_features=512, out_features=10, bias=True)
Epoch: 189 | Batch_idx: 0 |  Loss: (0.0512) |  Loss2: (0.0000) | Acc: (99.00%) (127/128)
Epoch: 189 | Batch_idx: 10 |  Loss: (0.0663) |  Loss2: (0.0000) | Acc: (97.00%) (1378/1408)
Epoch: 189 | Batch_idx: 20 |  Loss: (0.0726) |  Loss2: (0.0000) | Acc: (97.00%) (2630/2688)
Epoch: 189 | Batch_idx: 30 |  Loss: (0.0784) |  Loss2: (0.0000) | Acc: (97.00%) (3872/3968)
Epoch: 189 | Batch_idx: 40 |  Loss: (0.0791) |  Loss2: (0.0000) | Acc: (97.00%) (5117/5248)
Epoch: 189 | Batch_idx: 50 |  Loss: (0.0802) |  Loss2: (0.0000) | Acc: (97.00%) (6359/6528)
Epoch: 189 | Batch_idx: 60 |  Loss: (0.0801) |  Loss2: (0.0000) | Acc: (97.00%) (7601/7808)
Epoch: 189 | Batch_idx: 70 |  Loss: (0.0824) |  Loss2: (0.0000) | Acc: (97.00%) (8835/9088)
Epoch: 189 | Batch_idx: 80 |  Loss: (0.0828) |  Loss2: (0.0000) | Acc: (97.00%) (10085/10368)
Epoch: 189 | Batch_idx: 90 |  Loss: (0.0839) |  Loss2: (0.0000) | Acc: (97.00%) (11314/11648)
Epoch: 189 | Batch_idx: 100 |  Loss: (0.0833) |  Loss2: (0.0000) | Acc: (97.00%) (12566/12928)
Epoch: 189 | Batch_idx: 110 |  Loss: (0.0831) |  Loss2: (0.0000) | Acc: (97.00%) (13813/14208)
Epoch: 189 | Batch_idx: 120 |  Loss: (0.0839) |  Loss2: (0.0000) | Acc: (97.00%) (15054/15488)
Epoch: 189 | Batch_idx: 130 |  Loss: (0.0840) |  Loss2: (0.0000) | Acc: (97.00%) (16297/16768)
Epoch: 189 | Batch_idx: 140 |  Loss: (0.0842) |  Loss2: (0.0000) | Acc: (97.00%) (17539/18048)
Epoch: 189 | Batch_idx: 150 |  Loss: (0.0844) |  Loss2: (0.0000) | Acc: (97.00%) (18785/19328)
Epoch: 189 | Batch_idx: 160 |  Loss: (0.0851) |  Loss2: (0.0000) | Acc: (97.00%) (20026/20608)
Epoch: 189 | Batch_idx: 170 |  Loss: (0.0857) |  Loss2: (0.0000) | Acc: (97.00%) (21258/21888)
Epoch: 189 | Batch_idx: 180 |  Loss: (0.0857) |  Loss2: (0.0000) | Acc: (97.00%) (22509/23168)
Epoch: 189 | Batch_idx: 190 |  Loss: (0.0859) |  Loss2: (0.0000) | Acc: (97.00%) (23752/24448)
Epoch: 189 | Batch_idx: 200 |  Loss: (0.0852) |  Loss2: (0.0000) | Acc: (97.00%) (25003/25728)
Epoch: 189 | Batch_idx: 210 |  Loss: (0.0850) |  Loss2: (0.0000) | Acc: (97.00%) (26247/27008)
Epoch: 189 | Batch_idx: 220 |  Loss: (0.0847) |  Loss2: (0.0000) | Acc: (97.00%) (27493/28288)
Epoch: 189 | Batch_idx: 230 |  Loss: (0.0856) |  Loss2: (0.0000) | Acc: (97.00%) (28723/29568)
Epoch: 189 | Batch_idx: 240 |  Loss: (0.0856) |  Loss2: (0.0000) | Acc: (97.00%) (29962/30848)
Epoch: 189 | Batch_idx: 250 |  Loss: (0.0854) |  Loss2: (0.0000) | Acc: (97.00%) (31208/32128)
Epoch: 189 | Batch_idx: 260 |  Loss: (0.0855) |  Loss2: (0.0000) | Acc: (97.00%) (32453/33408)
Epoch: 189 | Batch_idx: 270 |  Loss: (0.0855) |  Loss2: (0.0000) | Acc: (97.00%) (33694/34688)
Epoch: 189 | Batch_idx: 280 |  Loss: (0.0849) |  Loss2: (0.0000) | Acc: (97.00%) (34947/35968)
Epoch: 189 | Batch_idx: 290 |  Loss: (0.0845) |  Loss2: (0.0000) | Acc: (97.00%) (36195/37248)
Epoch: 189 | Batch_idx: 300 |  Loss: (0.0847) |  Loss2: (0.0000) | Acc: (97.00%) (37437/38528)
Epoch: 189 | Batch_idx: 310 |  Loss: (0.0843) |  Loss2: (0.0000) | Acc: (97.00%) (38692/39808)
Epoch: 189 | Batch_idx: 320 |  Loss: (0.0845) |  Loss2: (0.0000) | Acc: (97.00%) (39929/41088)
Epoch: 189 | Batch_idx: 330 |  Loss: (0.0843) |  Loss2: (0.0000) | Acc: (97.00%) (41173/42368)
Epoch: 189 | Batch_idx: 340 |  Loss: (0.0840) |  Loss2: (0.0000) | Acc: (97.00%) (42427/43648)
Epoch: 189 | Batch_idx: 350 |  Loss: (0.0839) |  Loss2: (0.0000) | Acc: (97.00%) (43670/44928)
Epoch: 189 | Batch_idx: 360 |  Loss: (0.0837) |  Loss2: (0.0000) | Acc: (97.00%) (44917/46208)
Epoch: 189 | Batch_idx: 370 |  Loss: (0.0836) |  Loss2: (0.0000) | Acc: (97.00%) (46167/47488)
Epoch: 189 | Batch_idx: 380 |  Loss: (0.0835) |  Loss2: (0.0000) | Acc: (97.00%) (47416/48768)
Epoch: 189 | Batch_idx: 390 |  Loss: (0.0842) |  Loss2: (0.0000) | Acc: (97.00%) (48597/50000)
# TEST : Loss: (0.4066) | Acc: (89.00%) (8908/10000)
percent tensor([0.5623, 0.5768, 0.6019, 0.5953, 0.6041, 0.5689, 0.5860, 0.6020, 0.5746,
        0.5831, 0.5594, 0.5955, 0.5636, 0.5807, 0.5751, 0.5682],
       device='cuda:0') torch.Size([16])
percent tensor([0.5708, 0.5739, 0.5687, 0.5612, 0.5748, 0.5690, 0.5799, 0.5726, 0.5667,
        0.5720, 0.5715, 0.5770, 0.5689, 0.5698, 0.5760, 0.5712],
       device='cuda:0') torch.Size([16])
percent tensor([0.6107, 0.6185, 0.5755, 0.5502, 0.5494, 0.5738, 0.6028, 0.5672, 0.5848,
        0.6186, 0.6060, 0.5932, 0.6358, 0.6046, 0.6000, 0.6118],
       device='cuda:0') torch.Size([16])
percent tensor([0.6698, 0.6569, 0.6260, 0.6328, 0.6404, 0.6923, 0.6673, 0.6301, 0.6496,
        0.6580, 0.6629, 0.6457, 0.6614, 0.6620, 0.6783, 0.6715],
       device='cuda:0') torch.Size([16])
percent tensor([0.5652, 0.5269, 0.6495, 0.6792, 0.6729, 0.6036, 0.5908, 0.6593, 0.6328,
        0.5476, 0.5776, 0.6180, 0.4651, 0.6403, 0.6252, 0.5901],
       device='cuda:0') torch.Size([16])
percent tensor([0.5288, 0.6681, 0.6364, 0.6349, 0.6336, 0.7065, 0.6668, 0.5347, 0.6753,
        0.6137, 0.7186, 0.6458, 0.7040, 0.7048, 0.4649, 0.5061],
       device='cuda:0') torch.Size([16])
percent tensor([0.7203, 0.7449, 0.7355, 0.6820, 0.6704, 0.7352, 0.7628, 0.6627, 0.7249,
        0.7279, 0.7469, 0.6497, 0.7702, 0.7341, 0.5526, 0.6551],
       device='cuda:0') torch.Size([16])
percent tensor([0.9996, 0.9998, 0.9999, 0.9999, 0.9997, 0.9996, 0.9999, 0.9999, 0.9999,
        0.9999, 0.9999, 0.9998, 0.9997, 0.9998, 0.9998, 0.9995],
       device='cuda:0') torch.Size([16])
Epoch: 190 | Batch_idx: 0 |  Loss: (0.0749) |  Loss2: (0.0000) | Acc: (98.00%) (126/128)
Epoch: 190 | Batch_idx: 10 |  Loss: (0.0709) |  Loss2: (0.0000) | Acc: (97.00%) (1375/1408)
Epoch: 190 | Batch_idx: 20 |  Loss: (0.0761) |  Loss2: (0.0000) | Acc: (97.00%) (2617/2688)
Epoch: 190 | Batch_idx: 30 |  Loss: (0.0796) |  Loss2: (0.0000) | Acc: (97.00%) (3866/3968)
Epoch: 190 | Batch_idx: 40 |  Loss: (0.0799) |  Loss2: (0.0000) | Acc: (97.00%) (5113/5248)
Epoch: 190 | Batch_idx: 50 |  Loss: (0.0782) |  Loss2: (0.0000) | Acc: (97.00%) (6367/6528)
Epoch: 190 | Batch_idx: 60 |  Loss: (0.0795) |  Loss2: (0.0000) | Acc: (97.00%) (7610/7808)
Epoch: 190 | Batch_idx: 70 |  Loss: (0.0780) |  Loss2: (0.0000) | Acc: (97.00%) (8866/9088)
Epoch: 190 | Batch_idx: 80 |  Loss: (0.0774) |  Loss2: (0.0000) | Acc: (97.00%) (10115/10368)
Epoch: 190 | Batch_idx: 90 |  Loss: (0.0768) |  Loss2: (0.0000) | Acc: (97.00%) (11365/11648)
Epoch: 190 | Batch_idx: 100 |  Loss: (0.0761) |  Loss2: (0.0000) | Acc: (97.00%) (12614/12928)
Epoch: 190 | Batch_idx: 110 |  Loss: (0.0762) |  Loss2: (0.0000) | Acc: (97.00%) (13858/14208)
Epoch: 190 | Batch_idx: 120 |  Loss: (0.0771) |  Loss2: (0.0000) | Acc: (97.00%) (15099/15488)
Epoch: 190 | Batch_idx: 130 |  Loss: (0.0778) |  Loss2: (0.0000) | Acc: (97.00%) (16335/16768)
Epoch: 190 | Batch_idx: 140 |  Loss: (0.0769) |  Loss2: (0.0000) | Acc: (97.00%) (17592/18048)
Epoch: 190 | Batch_idx: 150 |  Loss: (0.0770) |  Loss2: (0.0000) | Acc: (97.00%) (18842/19328)
Epoch: 190 | Batch_idx: 160 |  Loss: (0.0769) |  Loss2: (0.0000) | Acc: (97.00%) (20090/20608)
Epoch: 190 | Batch_idx: 170 |  Loss: (0.0771) |  Loss2: (0.0000) | Acc: (97.00%) (21331/21888)
Epoch: 190 | Batch_idx: 180 |  Loss: (0.0773) |  Loss2: (0.0000) | Acc: (97.00%) (22576/23168)
Epoch: 190 | Batch_idx: 190 |  Loss: (0.0779) |  Loss2: (0.0000) | Acc: (97.00%) (23817/24448)
Epoch: 190 | Batch_idx: 200 |  Loss: (0.0773) |  Loss2: (0.0000) | Acc: (97.00%) (25070/25728)
Epoch: 190 | Batch_idx: 210 |  Loss: (0.0773) |  Loss2: (0.0000) | Acc: (97.00%) (26316/27008)
Epoch: 190 | Batch_idx: 220 |  Loss: (0.0779) |  Loss2: (0.0000) | Acc: (97.00%) (27553/28288)
Epoch: 190 | Batch_idx: 230 |  Loss: (0.0787) |  Loss2: (0.0000) | Acc: (97.00%) (28788/29568)
Epoch: 190 | Batch_idx: 240 |  Loss: (0.0782) |  Loss2: (0.0000) | Acc: (97.00%) (30043/30848)
Epoch: 190 | Batch_idx: 250 |  Loss: (0.0776) |  Loss2: (0.0000) | Acc: (97.00%) (31302/32128)
Epoch: 190 | Batch_idx: 260 |  Loss: (0.0776) |  Loss2: (0.0000) | Acc: (97.00%) (32554/33408)
Epoch: 190 | Batch_idx: 270 |  Loss: (0.0778) |  Loss2: (0.0000) | Acc: (97.00%) (33799/34688)
Epoch: 190 | Batch_idx: 280 |  Loss: (0.0776) |  Loss2: (0.0000) | Acc: (97.00%) (35052/35968)
Epoch: 190 | Batch_idx: 290 |  Loss: (0.0779) |  Loss2: (0.0000) | Acc: (97.00%) (36296/37248)
Epoch: 190 | Batch_idx: 300 |  Loss: (0.0776) |  Loss2: (0.0000) | Acc: (97.00%) (37550/38528)
Epoch: 190 | Batch_idx: 310 |  Loss: (0.0772) |  Loss2: (0.0000) | Acc: (97.00%) (38807/39808)
Epoch: 190 | Batch_idx: 320 |  Loss: (0.0771) |  Loss2: (0.0000) | Acc: (97.00%) (40054/41088)
Epoch: 190 | Batch_idx: 330 |  Loss: (0.0778) |  Loss2: (0.0000) | Acc: (97.00%) (41294/42368)
Epoch: 190 | Batch_idx: 340 |  Loss: (0.0779) |  Loss2: (0.0000) | Acc: (97.00%) (42537/43648)
Epoch: 190 | Batch_idx: 350 |  Loss: (0.0780) |  Loss2: (0.0000) | Acc: (97.00%) (43784/44928)
Epoch: 190 | Batch_idx: 360 |  Loss: (0.0781) |  Loss2: (0.0000) | Acc: (97.00%) (45024/46208)
Epoch: 190 | Batch_idx: 370 |  Loss: (0.0779) |  Loss2: (0.0000) | Acc: (97.00%) (46271/47488)
Epoch: 190 | Batch_idx: 380 |  Loss: (0.0777) |  Loss2: (0.0000) | Acc: (97.00%) (47528/48768)
Epoch: 190 | Batch_idx: 390 |  Loss: (0.0778) |  Loss2: (0.0000) | Acc: (97.00%) (48728/50000)
=> saving checkpoint 'drive/app/torch/save_Schedule/checkpoint_190.pth.tar'
# TEST : Loss: (0.4011) | Acc: (89.00%) (8927/10000)
percent tensor([0.5655, 0.5806, 0.6055, 0.5990, 0.6080, 0.5721, 0.5898, 0.6060, 0.5781,
        0.5867, 0.5627, 0.5994, 0.5671, 0.5841, 0.5788, 0.5715],
       device='cuda:0') torch.Size([16])
percent tensor([0.5702, 0.5737, 0.5675, 0.5605, 0.5737, 0.5687, 0.5793, 0.5716, 0.5661,
        0.5717, 0.5713, 0.5762, 0.5686, 0.5694, 0.5756, 0.5708],
       device='cuda:0') torch.Size([16])
percent tensor([0.6164, 0.6276, 0.5795, 0.5530, 0.5516, 0.5781, 0.6084, 0.5700, 0.5907,
        0.6274, 0.6146, 0.5998, 0.6449, 0.6122, 0.6057, 0.6183],
       device='cuda:0') torch.Size([16])
percent tensor([0.6734, 0.6606, 0.6297, 0.6358, 0.6438, 0.6954, 0.6711, 0.6331, 0.6535,
        0.6628, 0.6670, 0.6495, 0.6654, 0.6657, 0.6817, 0.6751],
       device='cuda:0') torch.Size([16])
percent tensor([0.5556, 0.5159, 0.6397, 0.6673, 0.6630, 0.5973, 0.5793, 0.6488, 0.6216,
        0.5383, 0.5690, 0.6031, 0.4551, 0.6284, 0.6116, 0.5810],
       device='cuda:0') torch.Size([16])
percent tensor([0.5198, 0.6585, 0.6272, 0.6237, 0.6277, 0.7005, 0.6583, 0.5235, 0.6676,
        0.6030, 0.7112, 0.6398, 0.6959, 0.6933, 0.4588, 0.4956],
       device='cuda:0') torch.Size([16])
percent tensor([0.7258, 0.7500, 0.7430, 0.6898, 0.6804, 0.7376, 0.7699, 0.6705, 0.7337,
        0.7358, 0.7540, 0.6583, 0.7771, 0.7430, 0.5575, 0.6593],
       device='cuda:0') torch.Size([16])
percent tensor([0.9996, 0.9998, 0.9999, 0.9999, 0.9997, 0.9996, 0.9999, 0.9999, 0.9999,
        0.9999, 1.0000, 0.9998, 0.9997, 0.9998, 0.9998, 0.9995],
       device='cuda:0') torch.Size([16])
Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 3, 3, 3]) tensor(190.8019, device='cuda:0')
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(826.4598, device='cuda:0')
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(848.2629, device='cuda:0')
Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([128, 64, 3, 3]) tensor(1522.7427, device='cuda:0')
Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([128, 64, 1, 1]) tensor(483.8189, device='cuda:0')
Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([128, 128, 3, 3]) tensor(2290.8909, device='cuda:0')
Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([256, 128, 3, 3]) tensor(4245.0112, device='cuda:0')
Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([256, 128, 1, 1]) tensor(1346.0377, device='cuda:0')
Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([256, 256, 3, 3]) tensor(6257.9771, device='cuda:0')
Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([512, 256, 3, 3]) tensor(11564.3652, device='cuda:0')
Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([512, 256, 1, 1]) tensor(3804.2173, device='cuda:0')
Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([512, 512, 3, 3]) tensor(16055.8252, device='cuda:0')
Epoch: 191 | Batch_idx: 0 |  Loss: (0.1048) |  Loss2: (0.0000) | Acc: (96.00%) (123/128)
Epoch: 191 | Batch_idx: 10 |  Loss: (0.0805) |  Loss2: (0.0000) | Acc: (97.00%) (1374/1408)
Epoch: 191 | Batch_idx: 20 |  Loss: (0.0701) |  Loss2: (0.0000) | Acc: (97.00%) (2631/2688)
Epoch: 191 | Batch_idx: 30 |  Loss: (0.0726) |  Loss2: (0.0000) | Acc: (97.00%) (3881/3968)
Epoch: 191 | Batch_idx: 40 |  Loss: (0.0710) |  Loss2: (0.0000) | Acc: (97.00%) (5137/5248)
Epoch: 191 | Batch_idx: 50 |  Loss: (0.0738) |  Loss2: (0.0000) | Acc: (97.00%) (6380/6528)
Epoch: 191 | Batch_idx: 60 |  Loss: (0.0738) |  Loss2: (0.0000) | Acc: (97.00%) (7630/7808)
Epoch: 191 | Batch_idx: 70 |  Loss: (0.0759) |  Loss2: (0.0000) | Acc: (97.00%) (8869/9088)
Epoch: 191 | Batch_idx: 80 |  Loss: (0.0755) |  Loss2: (0.0000) | Acc: (97.00%) (10118/10368)
Epoch: 191 | Batch_idx: 90 |  Loss: (0.0755) |  Loss2: (0.0000) | Acc: (97.00%) (11364/11648)
Epoch: 191 | Batch_idx: 100 |  Loss: (0.0749) |  Loss2: (0.0000) | Acc: (97.00%) (12619/12928)
Epoch: 191 | Batch_idx: 110 |  Loss: (0.0760) |  Loss2: (0.0000) | Acc: (97.00%) (13862/14208)
Epoch: 191 | Batch_idx: 120 |  Loss: (0.0753) |  Loss2: (0.0000) | Acc: (97.00%) (15114/15488)
Epoch: 191 | Batch_idx: 130 |  Loss: (0.0749) |  Loss2: (0.0000) | Acc: (97.00%) (16370/16768)
Epoch: 191 | Batch_idx: 140 |  Loss: (0.0745) |  Loss2: (0.0000) | Acc: (97.00%) (17621/18048)
Epoch: 191 | Batch_idx: 150 |  Loss: (0.0750) |  Loss2: (0.0000) | Acc: (97.00%) (18873/19328)
Epoch: 191 | Batch_idx: 160 |  Loss: (0.0752) |  Loss2: (0.0000) | Acc: (97.00%) (20120/20608)
Epoch: 191 | Batch_idx: 170 |  Loss: (0.0748) |  Loss2: (0.0000) | Acc: (97.00%) (21369/21888)
Epoch: 191 | Batch_idx: 180 |  Loss: (0.0748) |  Loss2: (0.0000) | Acc: (97.00%) (22618/23168)
Epoch: 191 | Batch_idx: 190 |  Loss: (0.0752) |  Loss2: (0.0000) | Acc: (97.00%) (23863/24448)
Epoch: 191 | Batch_idx: 200 |  Loss: (0.0758) |  Loss2: (0.0000) | Acc: (97.00%) (25111/25728)
Epoch: 191 | Batch_idx: 210 |  Loss: (0.0763) |  Loss2: (0.0000) | Acc: (97.00%) (26348/27008)
Epoch: 191 | Batch_idx: 220 |  Loss: (0.0760) |  Loss2: (0.0000) | Acc: (97.00%) (27601/28288)
Epoch: 191 | Batch_idx: 230 |  Loss: (0.0767) |  Loss2: (0.0000) | Acc: (97.00%) (28835/29568)
Epoch: 191 | Batch_idx: 240 |  Loss: (0.0765) |  Loss2: (0.0000) | Acc: (97.00%) (30082/30848)
Epoch: 191 | Batch_idx: 250 |  Loss: (0.0760) |  Loss2: (0.0000) | Acc: (97.00%) (31337/32128)
Epoch: 191 | Batch_idx: 260 |  Loss: (0.0755) |  Loss2: (0.0000) | Acc: (97.00%) (32595/33408)
Epoch: 191 | Batch_idx: 270 |  Loss: (0.0754) |  Loss2: (0.0000) | Acc: (97.00%) (33852/34688)
Epoch: 191 | Batch_idx: 280 |  Loss: (0.0751) |  Loss2: (0.0000) | Acc: (97.00%) (35105/35968)
Epoch: 191 | Batch_idx: 290 |  Loss: (0.0746) |  Loss2: (0.0000) | Acc: (97.00%) (36365/37248)
Epoch: 191 | Batch_idx: 300 |  Loss: (0.0747) |  Loss2: (0.0000) | Acc: (97.00%) (37613/38528)
Epoch: 191 | Batch_idx: 310 |  Loss: (0.0746) |  Loss2: (0.0000) | Acc: (97.00%) (38864/39808)
Epoch: 191 | Batch_idx: 320 |  Loss: (0.0752) |  Loss2: (0.0000) | Acc: (97.00%) (40104/41088)
Epoch: 191 | Batch_idx: 330 |  Loss: (0.0751) |  Loss2: (0.0000) | Acc: (97.00%) (41352/42368)
Epoch: 191 | Batch_idx: 340 |  Loss: (0.0746) |  Loss2: (0.0000) | Acc: (97.00%) (42610/43648)
Epoch: 191 | Batch_idx: 350 |  Loss: (0.0742) |  Loss2: (0.0000) | Acc: (97.00%) (43870/44928)
Epoch: 191 | Batch_idx: 360 |  Loss: (0.0737) |  Loss2: (0.0000) | Acc: (97.00%) (45129/46208)
Epoch: 191 | Batch_idx: 370 |  Loss: (0.0736) |  Loss2: (0.0000) | Acc: (97.00%) (46382/47488)
Epoch: 191 | Batch_idx: 380 |  Loss: (0.0735) |  Loss2: (0.0000) | Acc: (97.00%) (47632/48768)
Epoch: 191 | Batch_idx: 390 |  Loss: (0.0733) |  Loss2: (0.0000) | Acc: (97.00%) (48833/50000)
# TEST : Loss: (0.3972) | Acc: (89.00%) (8933/10000)
percent tensor([0.5650, 0.5800, 0.6048, 0.5987, 0.6073, 0.5721, 0.5891, 0.6053, 0.5773,
        0.5860, 0.5621, 0.5987, 0.5665, 0.5832, 0.5786, 0.5712],
       device='cuda:0') torch.Size([16])
percent tensor([0.5692, 0.5732, 0.5660, 0.5595, 0.5722, 0.5679, 0.5783, 0.5701, 0.5651,
        0.5710, 0.5707, 0.5751, 0.5680, 0.5686, 0.5749, 0.5699],
       device='cuda:0') torch.Size([16])
percent tensor([0.6176, 0.6334, 0.5799, 0.5525, 0.5510, 0.5782, 0.6107, 0.5691, 0.5924,
        0.6327, 0.6198, 0.6029, 0.6497, 0.6150, 0.6077, 0.6208],
       device='cuda:0') torch.Size([16])
percent tensor([0.6684, 0.6568, 0.6254, 0.6309, 0.6384, 0.6905, 0.6666, 0.6279, 0.6491,
        0.6588, 0.6628, 0.6450, 0.6621, 0.6614, 0.6767, 0.6705],
       device='cuda:0') torch.Size([16])
percent tensor([0.5541, 0.5143, 0.6358, 0.6656, 0.6612, 0.5991, 0.5772, 0.6473, 0.6211,
        0.5385, 0.5686, 0.6001, 0.4542, 0.6270, 0.6078, 0.5825],
       device='cuda:0') torch.Size([16])
percent tensor([0.5393, 0.6720, 0.6389, 0.6351, 0.6440, 0.7141, 0.6730, 0.5375, 0.6778,
        0.6158, 0.7216, 0.6526, 0.7075, 0.7027, 0.4782, 0.5136],
       device='cuda:0') torch.Size([16])
percent tensor([0.7314, 0.7541, 0.7428, 0.6873, 0.6818, 0.7414, 0.7719, 0.6665, 0.7364,
        0.7427, 0.7589, 0.6521, 0.7814, 0.7475, 0.5506, 0.6632],
       device='cuda:0') torch.Size([16])
percent tensor([0.9996, 0.9998, 0.9999, 0.9999, 0.9997, 0.9996, 0.9999, 0.9999, 0.9999,
        0.9999, 0.9999, 0.9998, 0.9997, 0.9998, 0.9998, 0.9995],
       device='cuda:0') torch.Size([16])
Epoch: 192 | Batch_idx: 0 |  Loss: (0.0388) |  Loss2: (0.0000) | Acc: (100.00%) (128/128)
Epoch: 192 | Batch_idx: 10 |  Loss: (0.0641) |  Loss2: (0.0000) | Acc: (98.00%) (1384/1408)
Epoch: 192 | Batch_idx: 20 |  Loss: (0.0700) |  Loss2: (0.0000) | Acc: (97.00%) (2634/2688)
Epoch: 192 | Batch_idx: 30 |  Loss: (0.0730) |  Loss2: (0.0000) | Acc: (97.00%) (3882/3968)
Epoch: 192 | Batch_idx: 40 |  Loss: (0.0732) |  Loss2: (0.0000) | Acc: (97.00%) (5129/5248)
Epoch: 192 | Batch_idx: 50 |  Loss: (0.0731) |  Loss2: (0.0000) | Acc: (97.00%) (6381/6528)
Epoch: 192 | Batch_idx: 60 |  Loss: (0.0718) |  Loss2: (0.0000) | Acc: (97.00%) (7632/7808)
Epoch: 192 | Batch_idx: 70 |  Loss: (0.0714) |  Loss2: (0.0000) | Acc: (97.00%) (8884/9088)
Epoch: 192 | Batch_idx: 80 |  Loss: (0.0703) |  Loss2: (0.0000) | Acc: (97.00%) (10135/10368)
Epoch: 192 | Batch_idx: 90 |  Loss: (0.0695) |  Loss2: (0.0000) | Acc: (97.00%) (11389/11648)
Epoch: 192 | Batch_idx: 100 |  Loss: (0.0705) |  Loss2: (0.0000) | Acc: (97.00%) (12640/12928)
Epoch: 192 | Batch_idx: 110 |  Loss: (0.0713) |  Loss2: (0.0000) | Acc: (97.00%) (13887/14208)
Epoch: 192 | Batch_idx: 120 |  Loss: (0.0701) |  Loss2: (0.0000) | Acc: (97.00%) (15150/15488)
Epoch: 192 | Batch_idx: 130 |  Loss: (0.0695) |  Loss2: (0.0000) | Acc: (97.00%) (16411/16768)
Epoch: 192 | Batch_idx: 140 |  Loss: (0.0686) |  Loss2: (0.0000) | Acc: (97.00%) (17668/18048)
Epoch: 192 | Batch_idx: 150 |  Loss: (0.0691) |  Loss2: (0.0000) | Acc: (97.00%) (18913/19328)
Epoch: 192 | Batch_idx: 160 |  Loss: (0.0695) |  Loss2: (0.0000) | Acc: (97.00%) (20165/20608)
Epoch: 192 | Batch_idx: 170 |  Loss: (0.0700) |  Loss2: (0.0000) | Acc: (97.00%) (21408/21888)
Epoch: 192 | Batch_idx: 180 |  Loss: (0.0703) |  Loss2: (0.0000) | Acc: (97.00%) (22662/23168)
Epoch: 192 | Batch_idx: 190 |  Loss: (0.0705) |  Loss2: (0.0000) | Acc: (97.00%) (23914/24448)
Epoch: 192 | Batch_idx: 200 |  Loss: (0.0704) |  Loss2: (0.0000) | Acc: (97.00%) (25168/25728)
Epoch: 192 | Batch_idx: 210 |  Loss: (0.0710) |  Loss2: (0.0000) | Acc: (97.00%) (26412/27008)
Epoch: 192 | Batch_idx: 220 |  Loss: (0.0702) |  Loss2: (0.0000) | Acc: (97.00%) (27676/28288)
Epoch: 192 | Batch_idx: 230 |  Loss: (0.0705) |  Loss2: (0.0000) | Acc: (97.00%) (28921/29568)
Epoch: 192 | Batch_idx: 240 |  Loss: (0.0706) |  Loss2: (0.0000) | Acc: (97.00%) (30163/30848)
Epoch: 192 | Batch_idx: 250 |  Loss: (0.0703) |  Loss2: (0.0000) | Acc: (97.00%) (31416/32128)
Epoch: 192 | Batch_idx: 260 |  Loss: (0.0701) |  Loss2: (0.0000) | Acc: (97.00%) (32669/33408)
Epoch: 192 | Batch_idx: 270 |  Loss: (0.0693) |  Loss2: (0.0000) | Acc: (97.00%) (33927/34688)
Epoch: 192 | Batch_idx: 280 |  Loss: (0.0685) |  Loss2: (0.0000) | Acc: (97.00%) (35194/35968)
Epoch: 192 | Batch_idx: 290 |  Loss: (0.0691) |  Loss2: (0.0000) | Acc: (97.00%) (36435/37248)
Epoch: 192 | Batch_idx: 300 |  Loss: (0.0686) |  Loss2: (0.0000) | Acc: (97.00%) (37698/38528)
Epoch: 192 | Batch_idx: 310 |  Loss: (0.0688) |  Loss2: (0.0000) | Acc: (97.00%) (38947/39808)
Epoch: 192 | Batch_idx: 320 |  Loss: (0.0689) |  Loss2: (0.0000) | Acc: (97.00%) (40197/41088)
Epoch: 192 | Batch_idx: 330 |  Loss: (0.0689) |  Loss2: (0.0000) | Acc: (97.00%) (41440/42368)
Epoch: 192 | Batch_idx: 340 |  Loss: (0.0689) |  Loss2: (0.0000) | Acc: (97.00%) (42693/43648)
Epoch: 192 | Batch_idx: 350 |  Loss: (0.0685) |  Loss2: (0.0000) | Acc: (97.00%) (43957/44928)
Epoch: 192 | Batch_idx: 360 |  Loss: (0.0689) |  Loss2: (0.0000) | Acc: (97.00%) (45199/46208)
Epoch: 192 | Batch_idx: 370 |  Loss: (0.0689) |  Loss2: (0.0000) | Acc: (97.00%) (46447/47488)
Epoch: 192 | Batch_idx: 380 |  Loss: (0.0689) |  Loss2: (0.0000) | Acc: (97.00%) (47696/48768)
Epoch: 192 | Batch_idx: 390 |  Loss: (0.0693) |  Loss2: (0.0000) | Acc: (97.00%) (48897/50000)
# TEST : Loss: (0.3964) | Acc: (89.00%) (8934/10000)
percent tensor([0.5642, 0.5791, 0.6045, 0.5985, 0.6069, 0.5712, 0.5883, 0.6048, 0.5768,
        0.5854, 0.5614, 0.5984, 0.5659, 0.5823, 0.5778, 0.5703],
       device='cuda:0') torch.Size([16])
percent tensor([0.5691, 0.5733, 0.5657, 0.5597, 0.5719, 0.5680, 0.5781, 0.5699, 0.5651,
        0.5711, 0.5708, 0.5751, 0.5679, 0.5689, 0.5750, 0.5700],
       device='cuda:0') torch.Size([16])
percent tensor([0.6156, 0.6327, 0.5780, 0.5514, 0.5495, 0.5767, 0.6087, 0.5669, 0.5908,
        0.6319, 0.6189, 0.6015, 0.6482, 0.6146, 0.6057, 0.6194],
       device='cuda:0') torch.Size([16])
percent tensor([0.6706, 0.6591, 0.6276, 0.6327, 0.6404, 0.6929, 0.6689, 0.6300, 0.6514,
        0.6616, 0.6654, 0.6473, 0.6641, 0.6638, 0.6789, 0.6727],
       device='cuda:0') torch.Size([16])
percent tensor([0.5599, 0.5165, 0.6423, 0.6723, 0.6685, 0.6090, 0.5847, 0.6543, 0.6300,
        0.5423, 0.5738, 0.6081, 0.4574, 0.6316, 0.6150, 0.5881],
       device='cuda:0') torch.Size([16])
percent tensor([0.5432, 0.6759, 0.6424, 0.6371, 0.6491, 0.7184, 0.6774, 0.5445, 0.6806,
        0.6218, 0.7218, 0.6510, 0.7098, 0.7050, 0.4804, 0.5185],
       device='cuda:0') torch.Size([16])
percent tensor([0.7297, 0.7535, 0.7413, 0.6852, 0.6792, 0.7379, 0.7704, 0.6631, 0.7351,
        0.7431, 0.7578, 0.6512, 0.7813, 0.7466, 0.5476, 0.6615],
       device='cuda:0') torch.Size([16])
percent tensor([0.9997, 0.9998, 0.9999, 0.9999, 0.9998, 0.9996, 0.9999, 0.9999, 0.9999,
        0.9999, 1.0000, 0.9998, 0.9998, 0.9998, 0.9998, 0.9995],
       device='cuda:0') torch.Size([16])
Epoch: 193 | Batch_idx: 0 |  Loss: (0.0711) |  Loss2: (0.0000) | Acc: (97.00%) (125/128)
Epoch: 193 | Batch_idx: 10 |  Loss: (0.0696) |  Loss2: (0.0000) | Acc: (97.00%) (1377/1408)
Epoch: 193 | Batch_idx: 20 |  Loss: (0.0723) |  Loss2: (0.0000) | Acc: (97.00%) (2624/2688)
Epoch: 193 | Batch_idx: 30 |  Loss: (0.0720) |  Loss2: (0.0000) | Acc: (97.00%) (3879/3968)
Epoch: 193 | Batch_idx: 40 |  Loss: (0.0677) |  Loss2: (0.0000) | Acc: (98.00%) (5145/5248)
Epoch: 193 | Batch_idx: 50 |  Loss: (0.0677) |  Loss2: (0.0000) | Acc: (98.00%) (6400/6528)
Epoch: 193 | Batch_idx: 60 |  Loss: (0.0677) |  Loss2: (0.0000) | Acc: (98.00%) (7654/7808)
Epoch: 193 | Batch_idx: 70 |  Loss: (0.0691) |  Loss2: (0.0000) | Acc: (97.00%) (8898/9088)
Epoch: 193 | Batch_idx: 80 |  Loss: (0.0679) |  Loss2: (0.0000) | Acc: (97.00%) (10152/10368)
Epoch: 193 | Batch_idx: 90 |  Loss: (0.0672) |  Loss2: (0.0000) | Acc: (98.00%) (11417/11648)
Epoch: 193 | Batch_idx: 100 |  Loss: (0.0677) |  Loss2: (0.0000) | Acc: (97.00%) (12669/12928)
Epoch: 193 | Batch_idx: 110 |  Loss: (0.0681) |  Loss2: (0.0000) | Acc: (97.00%) (13915/14208)
Epoch: 193 | Batch_idx: 120 |  Loss: (0.0676) |  Loss2: (0.0000) | Acc: (97.00%) (15175/15488)
Epoch: 193 | Batch_idx: 130 |  Loss: (0.0680) |  Loss2: (0.0000) | Acc: (97.00%) (16428/16768)
Epoch: 193 | Batch_idx: 140 |  Loss: (0.0684) |  Loss2: (0.0000) | Acc: (97.00%) (17679/18048)
Epoch: 193 | Batch_idx: 150 |  Loss: (0.0681) |  Loss2: (0.0000) | Acc: (97.00%) (18935/19328)
Epoch: 193 | Batch_idx: 160 |  Loss: (0.0680) |  Loss2: (0.0000) | Acc: (97.00%) (20189/20608)
Epoch: 193 | Batch_idx: 170 |  Loss: (0.0678) |  Loss2: (0.0000) | Acc: (97.00%) (21444/21888)
Epoch: 193 | Batch_idx: 180 |  Loss: (0.0679) |  Loss2: (0.0000) | Acc: (97.00%) (22695/23168)
Epoch: 193 | Batch_idx: 190 |  Loss: (0.0676) |  Loss2: (0.0000) | Acc: (97.00%) (23952/24448)
Epoch: 193 | Batch_idx: 200 |  Loss: (0.0676) |  Loss2: (0.0000) | Acc: (97.00%) (25202/25728)
Epoch: 193 | Batch_idx: 210 |  Loss: (0.0672) |  Loss2: (0.0000) | Acc: (97.00%) (26461/27008)
Epoch: 193 | Batch_idx: 220 |  Loss: (0.0675) |  Loss2: (0.0000) | Acc: (97.00%) (27709/28288)
Epoch: 193 | Batch_idx: 230 |  Loss: (0.0674) |  Loss2: (0.0000) | Acc: (97.00%) (28968/29568)
Epoch: 193 | Batch_idx: 240 |  Loss: (0.0679) |  Loss2: (0.0000) | Acc: (97.00%) (30213/30848)
Epoch: 193 | Batch_idx: 250 |  Loss: (0.0686) |  Loss2: (0.0000) | Acc: (97.00%) (31460/32128)
Epoch: 193 | Batch_idx: 260 |  Loss: (0.0682) |  Loss2: (0.0000) | Acc: (97.00%) (32726/33408)
Epoch: 193 | Batch_idx: 270 |  Loss: (0.0685) |  Loss2: (0.0000) | Acc: (97.00%) (33973/34688)
Epoch: 193 | Batch_idx: 280 |  Loss: (0.0691) |  Loss2: (0.0000) | Acc: (97.00%) (35218/35968)
Epoch: 193 | Batch_idx: 290 |  Loss: (0.0688) |  Loss2: (0.0000) | Acc: (97.00%) (36476/37248)
Epoch: 193 | Batch_idx: 300 |  Loss: (0.0695) |  Loss2: (0.0000) | Acc: (97.00%) (37715/38528)
Epoch: 193 | Batch_idx: 310 |  Loss: (0.0692) |  Loss2: (0.0000) | Acc: (97.00%) (38975/39808)
Epoch: 193 | Batch_idx: 320 |  Loss: (0.0692) |  Loss2: (0.0000) | Acc: (97.00%) (40225/41088)
Epoch: 193 | Batch_idx: 330 |  Loss: (0.0689) |  Loss2: (0.0000) | Acc: (97.00%) (41482/42368)
Epoch: 193 | Batch_idx: 340 |  Loss: (0.0693) |  Loss2: (0.0000) | Acc: (97.00%) (42728/43648)
Epoch: 193 | Batch_idx: 350 |  Loss: (0.0691) |  Loss2: (0.0000) | Acc: (97.00%) (43984/44928)
Epoch: 193 | Batch_idx: 360 |  Loss: (0.0688) |  Loss2: (0.0000) | Acc: (97.00%) (45241/46208)
Epoch: 193 | Batch_idx: 370 |  Loss: (0.0684) |  Loss2: (0.0000) | Acc: (97.00%) (46503/47488)
Epoch: 193 | Batch_idx: 380 |  Loss: (0.0684) |  Loss2: (0.0000) | Acc: (97.00%) (47755/48768)
Epoch: 193 | Batch_idx: 390 |  Loss: (0.0687) |  Loss2: (0.0000) | Acc: (97.00%) (48953/50000)
# TEST : Loss: (0.3922) | Acc: (89.00%) (8938/10000)
percent tensor([0.5640, 0.5788, 0.6048, 0.5988, 0.6070, 0.5711, 0.5880, 0.6050, 0.5768,
        0.5853, 0.5611, 0.5985, 0.5658, 0.5822, 0.5777, 0.5702],
       device='cuda:0') torch.Size([16])
percent tensor([0.5696, 0.5741, 0.5660, 0.5603, 0.5724, 0.5688, 0.5787, 0.5703, 0.5657,
        0.5717, 0.5715, 0.5756, 0.5686, 0.5696, 0.5758, 0.5706],
       device='cuda:0') torch.Size([16])
percent tensor([0.6151, 0.6337, 0.5778, 0.5504, 0.5483, 0.5742, 0.6086, 0.5668, 0.5916,
        0.6334, 0.6203, 0.6024, 0.6496, 0.6162, 0.6045, 0.6192],
       device='cuda:0') torch.Size([16])
percent tensor([0.6636, 0.6525, 0.6214, 0.6259, 0.6334, 0.6861, 0.6617, 0.6229, 0.6446,
        0.6549, 0.6586, 0.6400, 0.6578, 0.6569, 0.6712, 0.6660],
       device='cuda:0') torch.Size([16])
percent tensor([0.5537, 0.5134, 0.6380, 0.6683, 0.6658, 0.6043, 0.5791, 0.6502, 0.6244,
        0.5373, 0.5688, 0.6022, 0.4514, 0.6264, 0.6096, 0.5841],
       device='cuda:0') torch.Size([16])
percent tensor([0.5348, 0.6709, 0.6323, 0.6257, 0.6404, 0.7129, 0.6714, 0.5355, 0.6736,
        0.6119, 0.7150, 0.6417, 0.7054, 0.6979, 0.4711, 0.5071],
       device='cuda:0') torch.Size([16])
percent tensor([0.7326, 0.7562, 0.7404, 0.6847, 0.6782, 0.7395, 0.7722, 0.6622, 0.7356,
        0.7458, 0.7600, 0.6524, 0.7846, 0.7491, 0.5491, 0.6640],
       device='cuda:0') torch.Size([16])
percent tensor([0.9997, 0.9998, 0.9999, 0.9999, 0.9998, 0.9996, 0.9999, 0.9999, 0.9999,
        0.9999, 1.0000, 0.9998, 0.9998, 0.9998, 0.9998, 0.9995],
       device='cuda:0') torch.Size([16])
Epoch: 194 | Batch_idx: 0 |  Loss: (0.0633) |  Loss2: (0.0000) | Acc: (98.00%) (126/128)
Epoch: 194 | Batch_idx: 10 |  Loss: (0.0635) |  Loss2: (0.0000) | Acc: (98.00%) (1380/1408)
Epoch: 194 | Batch_idx: 20 |  Loss: (0.0716) |  Loss2: (0.0000) | Acc: (97.00%) (2629/2688)
Epoch: 194 | Batch_idx: 30 |  Loss: (0.0695) |  Loss2: (0.0000) | Acc: (97.00%) (3883/3968)
Epoch: 194 | Batch_idx: 40 |  Loss: (0.0706) |  Loss2: (0.0000) | Acc: (97.00%) (5139/5248)
Epoch: 194 | Batch_idx: 50 |  Loss: (0.0703) |  Loss2: (0.0000) | Acc: (97.00%) (6393/6528)
Epoch: 194 | Batch_idx: 60 |  Loss: (0.0704) |  Loss2: (0.0000) | Acc: (97.00%) (7640/7808)
Epoch: 194 | Batch_idx: 70 |  Loss: (0.0696) |  Loss2: (0.0000) | Acc: (97.00%) (8897/9088)
Epoch: 194 | Batch_idx: 80 |  Loss: (0.0706) |  Loss2: (0.0000) | Acc: (97.00%) (10138/10368)
Epoch: 194 | Batch_idx: 90 |  Loss: (0.0701) |  Loss2: (0.0000) | Acc: (97.00%) (11392/11648)
Epoch: 194 | Batch_idx: 100 |  Loss: (0.0695) |  Loss2: (0.0000) | Acc: (97.00%) (12646/12928)
Epoch: 194 | Batch_idx: 110 |  Loss: (0.0684) |  Loss2: (0.0000) | Acc: (97.00%) (13905/14208)
Epoch: 194 | Batch_idx: 120 |  Loss: (0.0674) |  Loss2: (0.0000) | Acc: (97.00%) (15161/15488)
Epoch: 194 | Batch_idx: 130 |  Loss: (0.0681) |  Loss2: (0.0000) | Acc: (97.00%) (16406/16768)
Epoch: 194 | Batch_idx: 140 |  Loss: (0.0675) |  Loss2: (0.0000) | Acc: (97.00%) (17662/18048)
Epoch: 194 | Batch_idx: 150 |  Loss: (0.0678) |  Loss2: (0.0000) | Acc: (97.00%) (18912/19328)
Epoch: 194 | Batch_idx: 160 |  Loss: (0.0669) |  Loss2: (0.0000) | Acc: (97.00%) (20173/20608)
Epoch: 194 | Batch_idx: 170 |  Loss: (0.0671) |  Loss2: (0.0000) | Acc: (97.00%) (21426/21888)
Epoch: 194 | Batch_idx: 180 |  Loss: (0.0674) |  Loss2: (0.0000) | Acc: (97.00%) (22677/23168)
Epoch: 194 | Batch_idx: 190 |  Loss: (0.0677) |  Loss2: (0.0000) | Acc: (97.00%) (23929/24448)
Epoch: 194 | Batch_idx: 200 |  Loss: (0.0681) |  Loss2: (0.0000) | Acc: (97.00%) (25177/25728)
Epoch: 194 | Batch_idx: 210 |  Loss: (0.0682) |  Loss2: (0.0000) | Acc: (97.00%) (26432/27008)
Epoch: 194 | Batch_idx: 220 |  Loss: (0.0689) |  Loss2: (0.0000) | Acc: (97.00%) (27670/28288)
Epoch: 194 | Batch_idx: 230 |  Loss: (0.0689) |  Loss2: (0.0000) | Acc: (97.00%) (28931/29568)
Epoch: 194 | Batch_idx: 240 |  Loss: (0.0685) |  Loss2: (0.0000) | Acc: (97.00%) (30188/30848)
Epoch: 194 | Batch_idx: 250 |  Loss: (0.0684) |  Loss2: (0.0000) | Acc: (97.00%) (31442/32128)
Epoch: 194 | Batch_idx: 260 |  Loss: (0.0687) |  Loss2: (0.0000) | Acc: (97.00%) (32694/33408)
Epoch: 194 | Batch_idx: 270 |  Loss: (0.0685) |  Loss2: (0.0000) | Acc: (97.00%) (33950/34688)
Epoch: 194 | Batch_idx: 280 |  Loss: (0.0689) |  Loss2: (0.0000) | Acc: (97.00%) (35200/35968)
Epoch: 194 | Batch_idx: 290 |  Loss: (0.0691) |  Loss2: (0.0000) | Acc: (97.00%) (36448/37248)
Epoch: 194 | Batch_idx: 300 |  Loss: (0.0691) |  Loss2: (0.0000) | Acc: (97.00%) (37700/38528)
Epoch: 194 | Batch_idx: 310 |  Loss: (0.0693) |  Loss2: (0.0000) | Acc: (97.00%) (38949/39808)
Epoch: 194 | Batch_idx: 320 |  Loss: (0.0692) |  Loss2: (0.0000) | Acc: (97.00%) (40197/41088)
Epoch: 194 | Batch_idx: 330 |  Loss: (0.0691) |  Loss2: (0.0000) | Acc: (97.00%) (41450/42368)
Epoch: 194 | Batch_idx: 340 |  Loss: (0.0690) |  Loss2: (0.0000) | Acc: (97.00%) (42709/43648)
Epoch: 194 | Batch_idx: 350 |  Loss: (0.0691) |  Loss2: (0.0000) | Acc: (97.00%) (43960/44928)
Epoch: 194 | Batch_idx: 360 |  Loss: (0.0694) |  Loss2: (0.0000) | Acc: (97.00%) (45207/46208)
Epoch: 194 | Batch_idx: 370 |  Loss: (0.0696) |  Loss2: (0.0000) | Acc: (97.00%) (46457/47488)
Epoch: 194 | Batch_idx: 380 |  Loss: (0.0696) |  Loss2: (0.0000) | Acc: (97.00%) (47711/48768)
Epoch: 194 | Batch_idx: 390 |  Loss: (0.0696) |  Loss2: (0.0000) | Acc: (97.00%) (48920/50000)
# TEST : Loss: (0.3929) | Acc: (89.00%) (8943/10000)
percent tensor([0.5628, 0.5773, 0.6030, 0.5971, 0.6052, 0.5695, 0.5865, 0.6034, 0.5756,
        0.5838, 0.5600, 0.5967, 0.5646, 0.5810, 0.5761, 0.5687],
       device='cuda:0') torch.Size([16])
percent tensor([0.5707, 0.5755, 0.5670, 0.5615, 0.5733, 0.5699, 0.5799, 0.5714, 0.5668,
        0.5730, 0.5728, 0.5769, 0.5699, 0.5707, 0.5772, 0.5717],
       device='cuda:0') torch.Size([16])
percent tensor([0.6154, 0.6346, 0.5784, 0.5514, 0.5484, 0.5747, 0.6086, 0.5669, 0.5922,
        0.6342, 0.6207, 0.6031, 0.6508, 0.6163, 0.6044, 0.6198],
       device='cuda:0') torch.Size([16])
percent tensor([0.6699, 0.6586, 0.6275, 0.6307, 0.6390, 0.6922, 0.6677, 0.6282, 0.6501,
        0.6612, 0.6645, 0.6460, 0.6644, 0.6619, 0.6775, 0.6721],
       device='cuda:0') torch.Size([16])
percent tensor([0.5579, 0.5148, 0.6432, 0.6710, 0.6722, 0.6083, 0.5842, 0.6554, 0.6254,
        0.5396, 0.5687, 0.6039, 0.4534, 0.6260, 0.6129, 0.5875],
       device='cuda:0') torch.Size([16])
percent tensor([0.5271, 0.6669, 0.6261, 0.6178, 0.6347, 0.7107, 0.6653, 0.5308, 0.6689,
        0.6026, 0.7116, 0.6353, 0.6994, 0.6912, 0.4638, 0.4981],
       device='cuda:0') torch.Size([16])
percent tensor([0.7258, 0.7526, 0.7358, 0.6799, 0.6720, 0.7370, 0.7671, 0.6543, 0.7322,
        0.7408, 0.7598, 0.6474, 0.7831, 0.7481, 0.5448, 0.6581],
       device='cuda:0') torch.Size([16])
percent tensor([0.9997, 0.9998, 0.9999, 0.9999, 0.9998, 0.9996, 0.9999, 0.9999, 0.9999,
        0.9999, 1.0000, 0.9998, 0.9998, 0.9998, 0.9998, 0.9995],
       device='cuda:0') torch.Size([16])
Epoch: 195 | Batch_idx: 0 |  Loss: (0.0469) |  Loss2: (0.0000) | Acc: (98.00%) (126/128)
Epoch: 195 | Batch_idx: 10 |  Loss: (0.0697) |  Loss2: (0.0000) | Acc: (97.00%) (1378/1408)
Epoch: 195 | Batch_idx: 20 |  Loss: (0.0703) |  Loss2: (0.0000) | Acc: (97.00%) (2625/2688)
Epoch: 195 | Batch_idx: 30 |  Loss: (0.0703) |  Loss2: (0.0000) | Acc: (97.00%) (3876/3968)
Epoch: 195 | Batch_idx: 40 |  Loss: (0.0739) |  Loss2: (0.0000) | Acc: (97.00%) (5125/5248)
Epoch: 195 | Batch_idx: 50 |  Loss: (0.0710) |  Loss2: (0.0000) | Acc: (97.00%) (6386/6528)
Epoch: 195 | Batch_idx: 60 |  Loss: (0.0692) |  Loss2: (0.0000) | Acc: (97.00%) (7647/7808)
Epoch: 195 | Batch_idx: 70 |  Loss: (0.0713) |  Loss2: (0.0000) | Acc: (97.00%) (8883/9088)
Epoch: 195 | Batch_idx: 80 |  Loss: (0.0706) |  Loss2: (0.0000) | Acc: (97.00%) (10135/10368)
Epoch: 195 | Batch_idx: 90 |  Loss: (0.0706) |  Loss2: (0.0000) | Acc: (97.00%) (11386/11648)
Epoch: 195 | Batch_idx: 100 |  Loss: (0.0716) |  Loss2: (0.0000) | Acc: (97.00%) (12629/12928)
Epoch: 195 | Batch_idx: 110 |  Loss: (0.0711) |  Loss2: (0.0000) | Acc: (97.00%) (13884/14208)
Epoch: 195 | Batch_idx: 120 |  Loss: (0.0709) |  Loss2: (0.0000) | Acc: (97.00%) (15136/15488)
Epoch: 195 | Batch_idx: 130 |  Loss: (0.0706) |  Loss2: (0.0000) | Acc: (97.00%) (16388/16768)
Epoch: 195 | Batch_idx: 140 |  Loss: (0.0704) |  Loss2: (0.0000) | Acc: (97.00%) (17643/18048)
Epoch: 195 | Batch_idx: 150 |  Loss: (0.0707) |  Loss2: (0.0000) | Acc: (97.00%) (18899/19328)
Epoch: 195 | Batch_idx: 160 |  Loss: (0.0699) |  Loss2: (0.0000) | Acc: (97.00%) (20157/20608)
Epoch: 195 | Batch_idx: 170 |  Loss: (0.0695) |  Loss2: (0.0000) | Acc: (97.00%) (21411/21888)
Epoch: 195 | Batch_idx: 180 |  Loss: (0.0692) |  Loss2: (0.0000) | Acc: (97.00%) (22669/23168)
Epoch: 195 | Batch_idx: 190 |  Loss: (0.0686) |  Loss2: (0.0000) | Acc: (97.00%) (23928/24448)
Epoch: 195 | Batch_idx: 200 |  Loss: (0.0692) |  Loss2: (0.0000) | Acc: (97.00%) (25175/25728)
Epoch: 195 | Batch_idx: 210 |  Loss: (0.0691) |  Loss2: (0.0000) | Acc: (97.00%) (26429/27008)
Epoch: 195 | Batch_idx: 220 |  Loss: (0.0688) |  Loss2: (0.0000) | Acc: (97.00%) (27683/28288)
Epoch: 195 | Batch_idx: 230 |  Loss: (0.0687) |  Loss2: (0.0000) | Acc: (97.00%) (28936/29568)
Epoch: 195 | Batch_idx: 240 |  Loss: (0.0694) |  Loss2: (0.0000) | Acc: (97.00%) (30175/30848)
Epoch: 195 | Batch_idx: 250 |  Loss: (0.0692) |  Loss2: (0.0000) | Acc: (97.00%) (31424/32128)
Epoch: 195 | Batch_idx: 260 |  Loss: (0.0693) |  Loss2: (0.0000) | Acc: (97.00%) (32673/33408)
Epoch: 195 | Batch_idx: 270 |  Loss: (0.0688) |  Loss2: (0.0000) | Acc: (97.00%) (33934/34688)
Epoch: 195 | Batch_idx: 280 |  Loss: (0.0684) |  Loss2: (0.0000) | Acc: (97.00%) (35193/35968)
Epoch: 195 | Batch_idx: 290 |  Loss: (0.0685) |  Loss2: (0.0000) | Acc: (97.00%) (36451/37248)
Epoch: 195 | Batch_idx: 300 |  Loss: (0.0689) |  Loss2: (0.0000) | Acc: (97.00%) (37695/38528)
Epoch: 195 | Batch_idx: 310 |  Loss: (0.0686) |  Loss2: (0.0000) | Acc: (97.00%) (38954/39808)
Epoch: 195 | Batch_idx: 320 |  Loss: (0.0685) |  Loss2: (0.0000) | Acc: (97.00%) (40205/41088)
Epoch: 195 | Batch_idx: 330 |  Loss: (0.0684) |  Loss2: (0.0000) | Acc: (97.00%) (41460/42368)
Epoch: 195 | Batch_idx: 340 |  Loss: (0.0683) |  Loss2: (0.0000) | Acc: (97.00%) (42713/43648)
Epoch: 195 | Batch_idx: 350 |  Loss: (0.0680) |  Loss2: (0.0000) | Acc: (97.00%) (43971/44928)
Epoch: 195 | Batch_idx: 360 |  Loss: (0.0681) |  Loss2: (0.0000) | Acc: (97.00%) (45218/46208)
Epoch: 195 | Batch_idx: 370 |  Loss: (0.0677) |  Loss2: (0.0000) | Acc: (97.00%) (46477/47488)
Epoch: 195 | Batch_idx: 380 |  Loss: (0.0678) |  Loss2: (0.0000) | Acc: (97.00%) (47724/48768)
Epoch: 195 | Batch_idx: 390 |  Loss: (0.0677) |  Loss2: (0.0000) | Acc: (97.00%) (48930/50000)
=> saving checkpoint 'drive/app/torch/save_Schedule/checkpoint_195.pth.tar'
# TEST : Loss: (0.3937) | Acc: (89.00%) (8951/10000)
percent tensor([0.5629, 0.5777, 0.6049, 0.5989, 0.6066, 0.5696, 0.5872, 0.6050, 0.5760,
        0.5849, 0.5599, 0.5985, 0.5649, 0.5814, 0.5765, 0.5693],
       device='cuda:0') torch.Size([16])
percent tensor([0.5717, 0.5766, 0.5679, 0.5627, 0.5745, 0.5711, 0.5811, 0.5726, 0.5678,
        0.5742, 0.5740, 0.5780, 0.5710, 0.5719, 0.5783, 0.5728],
       device='cuda:0') torch.Size([16])
percent tensor([0.6163, 0.6363, 0.5797, 0.5523, 0.5488, 0.5740, 0.6102, 0.5679, 0.5936,
        0.6367, 0.6234, 0.6048, 0.6528, 0.6185, 0.6047, 0.6211],
       device='cuda:0') torch.Size([16])
percent tensor([0.6663, 0.6546, 0.6246, 0.6272, 0.6357, 0.6879, 0.6636, 0.6252, 0.6471,
        0.6580, 0.6613, 0.6425, 0.6614, 0.6578, 0.6728, 0.6682],
       device='cuda:0') torch.Size([16])
percent tensor([0.5490, 0.5060, 0.6360, 0.6659, 0.6645, 0.6002, 0.5748, 0.6490, 0.6189,
        0.5299, 0.5611, 0.5974, 0.4427, 0.6197, 0.6038, 0.5794],
       device='cuda:0') torch.Size([16])
percent tensor([0.5293, 0.6710, 0.6221, 0.6194, 0.6340, 0.7134, 0.6680, 0.5288, 0.6704,
        0.6068, 0.7129, 0.6336, 0.7032, 0.6910, 0.4679, 0.4989],
       device='cuda:0') torch.Size([16])
percent tensor([0.7276, 0.7549, 0.7305, 0.6783, 0.6696, 0.7385, 0.7719, 0.6526, 0.7323,
        0.7442, 0.7630, 0.6451, 0.7856, 0.7501, 0.5460, 0.6597],
       device='cuda:0') torch.Size([16])
percent tensor([0.9997, 0.9998, 0.9999, 0.9999, 0.9998, 0.9996, 0.9999, 0.9999, 0.9999,
        0.9999, 1.0000, 0.9998, 0.9998, 0.9998, 0.9998, 0.9995],
       device='cuda:0') torch.Size([16])
True Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=128, out_features=16, bias=False)
False Linear(in_features=16, out_features=2, bias=False)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=128, out_features=16, bias=False)
False Linear(in_features=16, out_features=2, bias=False)
True Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=256, out_features=32, bias=False)
False Linear(in_features=32, out_features=2, bias=False)
True Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=256, out_features=32, bias=False)
False Linear(in_features=32, out_features=2, bias=False)
True Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=512, out_features=64, bias=False)
False Linear(in_features=64, out_features=2, bias=False)
True Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=512, out_features=64, bias=False)
False Linear(in_features=64, out_features=2, bias=False)
True Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1024, out_features=128, bias=False)
False Linear(in_features=128, out_features=2, bias=False)
True Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1024, out_features=128, bias=False)
False Linear(in_features=128, out_features=2, bias=False)
True Linear(in_features=512, out_features=10, bias=True)
Epoch: 196 | Batch_idx: 0 |  Loss: (0.1186) |  Loss2: (0.0000) | Acc: (96.00%) (124/128)
Epoch: 196 | Batch_idx: 10 |  Loss: (0.0765) |  Loss2: (0.0000) | Acc: (97.00%) (1376/1408)
Epoch: 196 | Batch_idx: 20 |  Loss: (0.0703) |  Loss2: (0.0000) | Acc: (97.00%) (2631/2688)
Epoch: 196 | Batch_idx: 30 |  Loss: (0.0694) |  Loss2: (0.0000) | Acc: (97.00%) (3881/3968)
Epoch: 196 | Batch_idx: 40 |  Loss: (0.0722) |  Loss2: (0.0000) | Acc: (97.00%) (5126/5248)
Epoch: 196 | Batch_idx: 50 |  Loss: (0.0716) |  Loss2: (0.0000) | Acc: (97.00%) (6378/6528)
Epoch: 196 | Batch_idx: 60 |  Loss: (0.0718) |  Loss2: (0.0000) | Acc: (97.00%) (7629/7808)
Epoch: 196 | Batch_idx: 70 |  Loss: (0.0733) |  Loss2: (0.0000) | Acc: (97.00%) (8875/9088)
Epoch: 196 | Batch_idx: 80 |  Loss: (0.0739) |  Loss2: (0.0000) | Acc: (97.00%) (10122/10368)
Epoch: 196 | Batch_idx: 90 |  Loss: (0.0747) |  Loss2: (0.0000) | Acc: (97.00%) (11370/11648)
Epoch: 196 | Batch_idx: 100 |  Loss: (0.0736) |  Loss2: (0.0000) | Acc: (97.00%) (12623/12928)
Epoch: 196 | Batch_idx: 110 |  Loss: (0.0733) |  Loss2: (0.0000) | Acc: (97.00%) (13876/14208)
Epoch: 196 | Batch_idx: 120 |  Loss: (0.0750) |  Loss2: (0.0000) | Acc: (97.00%) (15113/15488)
Epoch: 196 | Batch_idx: 130 |  Loss: (0.0743) |  Loss2: (0.0000) | Acc: (97.00%) (16369/16768)
Epoch: 196 | Batch_idx: 140 |  Loss: (0.0736) |  Loss2: (0.0000) | Acc: (97.00%) (17626/18048)
Epoch: 196 | Batch_idx: 150 |  Loss: (0.0733) |  Loss2: (0.0000) | Acc: (97.00%) (18879/19328)
Epoch: 196 | Batch_idx: 160 |  Loss: (0.0738) |  Loss2: (0.0000) | Acc: (97.00%) (20120/20608)
Epoch: 196 | Batch_idx: 170 |  Loss: (0.0744) |  Loss2: (0.0000) | Acc: (97.00%) (21366/21888)
Epoch: 196 | Batch_idx: 180 |  Loss: (0.0747) |  Loss2: (0.0000) | Acc: (97.00%) (22613/23168)
Epoch: 196 | Batch_idx: 190 |  Loss: (0.0739) |  Loss2: (0.0000) | Acc: (97.00%) (23872/24448)
Epoch: 196 | Batch_idx: 200 |  Loss: (0.0747) |  Loss2: (0.0000) | Acc: (97.00%) (25109/25728)
Epoch: 196 | Batch_idx: 210 |  Loss: (0.0755) |  Loss2: (0.0000) | Acc: (97.00%) (26347/27008)
Epoch: 196 | Batch_idx: 220 |  Loss: (0.0775) |  Loss2: (0.0000) | Acc: (97.00%) (27579/28288)
Epoch: 196 | Batch_idx: 230 |  Loss: (0.0782) |  Loss2: (0.0000) | Acc: (97.00%) (28811/29568)
Epoch: 196 | Batch_idx: 240 |  Loss: (0.0795) |  Loss2: (0.0000) | Acc: (97.00%) (30038/30848)
Epoch: 196 | Batch_idx: 250 |  Loss: (0.0798) |  Loss2: (0.0000) | Acc: (97.00%) (31280/32128)
Epoch: 196 | Batch_idx: 260 |  Loss: (0.0801) |  Loss2: (0.0000) | Acc: (97.00%) (32520/33408)
Epoch: 196 | Batch_idx: 270 |  Loss: (0.0798) |  Loss2: (0.0000) | Acc: (97.00%) (33766/34688)
Epoch: 196 | Batch_idx: 280 |  Loss: (0.0797) |  Loss2: (0.0000) | Acc: (97.00%) (35010/35968)
Epoch: 196 | Batch_idx: 290 |  Loss: (0.0800) |  Loss2: (0.0000) | Acc: (97.00%) (36250/37248)
Epoch: 196 | Batch_idx: 300 |  Loss: (0.0801) |  Loss2: (0.0000) | Acc: (97.00%) (37494/38528)
Epoch: 196 | Batch_idx: 310 |  Loss: (0.0802) |  Loss2: (0.0000) | Acc: (97.00%) (38733/39808)
Epoch: 196 | Batch_idx: 320 |  Loss: (0.0802) |  Loss2: (0.0000) | Acc: (97.00%) (39977/41088)
Epoch: 196 | Batch_idx: 330 |  Loss: (0.0801) |  Loss2: (0.0000) | Acc: (97.00%) (41223/42368)
Epoch: 196 | Batch_idx: 340 |  Loss: (0.0807) |  Loss2: (0.0000) | Acc: (97.00%) (42457/43648)
Epoch: 196 | Batch_idx: 350 |  Loss: (0.0808) |  Loss2: (0.0000) | Acc: (97.00%) (43702/44928)
Epoch: 196 | Batch_idx: 360 |  Loss: (0.0812) |  Loss2: (0.0000) | Acc: (97.00%) (44939/46208)
Epoch: 196 | Batch_idx: 370 |  Loss: (0.0818) |  Loss2: (0.0000) | Acc: (97.00%) (46170/47488)
Epoch: 196 | Batch_idx: 380 |  Loss: (0.0819) |  Loss2: (0.0000) | Acc: (97.00%) (47412/48768)
Epoch: 196 | Batch_idx: 390 |  Loss: (0.0823) |  Loss2: (0.0000) | Acc: (97.00%) (48608/50000)
# TEST : Loss: (0.4276) | Acc: (88.00%) (8879/10000)
percent tensor([0.5614, 0.5773, 0.6038, 0.5978, 0.6060, 0.5688, 0.5866, 0.6047, 0.5765,
        0.5845, 0.5601, 0.5977, 0.5643, 0.5817, 0.5755, 0.5690],
       device='cuda:0') torch.Size([16])
percent tensor([0.5706, 0.5780, 0.5677, 0.5608, 0.5731, 0.5686, 0.5817, 0.5731, 0.5676,
        0.5754, 0.5745, 0.5791, 0.5711, 0.5724, 0.5782, 0.5716],
       device='cuda:0') torch.Size([16])
percent tensor([0.6161, 0.6396, 0.5804, 0.5578, 0.5512, 0.5795, 0.6110, 0.5667, 0.5994,
        0.6374, 0.6225, 0.6041, 0.6551, 0.6210, 0.6069, 0.6236],
       device='cuda:0') torch.Size([16])
percent tensor([0.6636, 0.6563, 0.6320, 0.6280, 0.6341, 0.6816, 0.6671, 0.6289, 0.6495,
        0.6615, 0.6636, 0.6465, 0.6623, 0.6583, 0.6690, 0.6663],
       device='cuda:0') torch.Size([16])
percent tensor([0.5491, 0.5101, 0.6203, 0.6667, 0.6639, 0.6069, 0.5738, 0.6458, 0.6033,
        0.5269, 0.5731, 0.5982, 0.4368, 0.6245, 0.6084, 0.5804],
       device='cuda:0') torch.Size([16])
percent tensor([0.5399, 0.6952, 0.6466, 0.6300, 0.6248, 0.7244, 0.6724, 0.5497, 0.6741,
        0.6367, 0.7235, 0.6517, 0.7093, 0.6989, 0.4843, 0.5037],
       device='cuda:0') torch.Size([16])
percent tensor([0.7374, 0.7807, 0.7297, 0.6646, 0.6685, 0.7599, 0.7586, 0.6459, 0.7286,
        0.7555, 0.7648, 0.6349, 0.7746, 0.7428, 0.5577, 0.6708],
       device='cuda:0') torch.Size([16])
percent tensor([0.9997, 0.9998, 0.9999, 0.9999, 0.9998, 0.9998, 0.9999, 1.0000, 0.9999,
        0.9998, 0.9999, 0.9998, 0.9997, 0.9997, 0.9999, 0.9994],
       device='cuda:0') torch.Size([16])
Epoch: 197 | Batch_idx: 0 |  Loss: (0.0652) |  Loss2: (0.0000) | Acc: (97.00%) (125/128)
Epoch: 197 | Batch_idx: 10 |  Loss: (0.0734) |  Loss2: (0.0000) | Acc: (97.00%) (1374/1408)
Epoch: 197 | Batch_idx: 20 |  Loss: (0.0782) |  Loss2: (0.0000) | Acc: (97.00%) (2614/2688)
Epoch: 197 | Batch_idx: 30 |  Loss: (0.0746) |  Loss2: (0.0000) | Acc: (97.00%) (3868/3968)
Epoch: 197 | Batch_idx: 40 |  Loss: (0.0765) |  Loss2: (0.0000) | Acc: (97.00%) (5117/5248)
Epoch: 197 | Batch_idx: 50 |  Loss: (0.0802) |  Loss2: (0.0000) | Acc: (97.00%) (6361/6528)
Epoch: 197 | Batch_idx: 60 |  Loss: (0.0785) |  Loss2: (0.0000) | Acc: (97.00%) (7608/7808)
Epoch: 197 | Batch_idx: 70 |  Loss: (0.0814) |  Loss2: (0.0000) | Acc: (97.00%) (8843/9088)
Epoch: 197 | Batch_idx: 80 |  Loss: (0.0812) |  Loss2: (0.0000) | Acc: (97.00%) (10091/10368)
Epoch: 197 | Batch_idx: 90 |  Loss: (0.0823) |  Loss2: (0.0000) | Acc: (97.00%) (11331/11648)
Epoch: 197 | Batch_idx: 100 |  Loss: (0.0834) |  Loss2: (0.0000) | Acc: (97.00%) (12567/12928)
Epoch: 197 | Batch_idx: 110 |  Loss: (0.0819) |  Loss2: (0.0000) | Acc: (97.00%) (13814/14208)
Epoch: 197 | Batch_idx: 120 |  Loss: (0.0811) |  Loss2: (0.0000) | Acc: (97.00%) (15066/15488)
Epoch: 197 | Batch_idx: 130 |  Loss: (0.0798) |  Loss2: (0.0000) | Acc: (97.00%) (16316/16768)
Epoch: 197 | Batch_idx: 140 |  Loss: (0.0788) |  Loss2: (0.0000) | Acc: (97.00%) (17568/18048)
Epoch: 197 | Batch_idx: 150 |  Loss: (0.0792) |  Loss2: (0.0000) | Acc: (97.00%) (18811/19328)
Epoch: 197 | Batch_idx: 160 |  Loss: (0.0792) |  Loss2: (0.0000) | Acc: (97.00%) (20058/20608)
Epoch: 197 | Batch_idx: 170 |  Loss: (0.0785) |  Loss2: (0.0000) | Acc: (97.00%) (21304/21888)
Epoch: 197 | Batch_idx: 180 |  Loss: (0.0793) |  Loss2: (0.0000) | Acc: (97.00%) (22545/23168)
Epoch: 197 | Batch_idx: 190 |  Loss: (0.0801) |  Loss2: (0.0000) | Acc: (97.00%) (23792/24448)
Epoch: 197 | Batch_idx: 200 |  Loss: (0.0803) |  Loss2: (0.0000) | Acc: (97.00%) (25034/25728)
Epoch: 197 | Batch_idx: 210 |  Loss: (0.0804) |  Loss2: (0.0000) | Acc: (97.00%) (26282/27008)
Epoch: 197 | Batch_idx: 220 |  Loss: (0.0804) |  Loss2: (0.0000) | Acc: (97.00%) (27533/28288)
Epoch: 197 | Batch_idx: 230 |  Loss: (0.0800) |  Loss2: (0.0000) | Acc: (97.00%) (28787/29568)
Epoch: 197 | Batch_idx: 240 |  Loss: (0.0793) |  Loss2: (0.0000) | Acc: (97.00%) (30042/30848)
Epoch: 197 | Batch_idx: 250 |  Loss: (0.0802) |  Loss2: (0.0000) | Acc: (97.00%) (31283/32128)
Epoch: 197 | Batch_idx: 260 |  Loss: (0.0804) |  Loss2: (0.0000) | Acc: (97.00%) (32527/33408)
Epoch: 197 | Batch_idx: 270 |  Loss: (0.0802) |  Loss2: (0.0000) | Acc: (97.00%) (33777/34688)
Epoch: 197 | Batch_idx: 280 |  Loss: (0.0801) |  Loss2: (0.0000) | Acc: (97.00%) (35019/35968)
Epoch: 197 | Batch_idx: 290 |  Loss: (0.0799) |  Loss2: (0.0000) | Acc: (97.00%) (36268/37248)
Epoch: 197 | Batch_idx: 300 |  Loss: (0.0800) |  Loss2: (0.0000) | Acc: (97.00%) (37510/38528)
Epoch: 197 | Batch_idx: 310 |  Loss: (0.0806) |  Loss2: (0.0000) | Acc: (97.00%) (38742/39808)
Epoch: 197 | Batch_idx: 320 |  Loss: (0.0803) |  Loss2: (0.0000) | Acc: (97.00%) (39997/41088)
Epoch: 197 | Batch_idx: 330 |  Loss: (0.0810) |  Loss2: (0.0000) | Acc: (97.00%) (41230/42368)
Epoch: 197 | Batch_idx: 340 |  Loss: (0.0812) |  Loss2: (0.0000) | Acc: (97.00%) (42472/43648)
Epoch: 197 | Batch_idx: 350 |  Loss: (0.0816) |  Loss2: (0.0000) | Acc: (97.00%) (43709/44928)
Epoch: 197 | Batch_idx: 360 |  Loss: (0.0813) |  Loss2: (0.0000) | Acc: (97.00%) (44956/46208)
Epoch: 197 | Batch_idx: 370 |  Loss: (0.0816) |  Loss2: (0.0000) | Acc: (97.00%) (46196/47488)
Epoch: 197 | Batch_idx: 380 |  Loss: (0.0816) |  Loss2: (0.0000) | Acc: (97.00%) (47441/48768)
Epoch: 197 | Batch_idx: 390 |  Loss: (0.0812) |  Loss2: (0.0000) | Acc: (97.00%) (48644/50000)
# TEST : Loss: (0.4593) | Acc: (87.00%) (8781/10000)
percent tensor([0.5610, 0.5753, 0.6035, 0.5961, 0.6051, 0.5687, 0.5858, 0.6028, 0.5749,
        0.5829, 0.5587, 0.5966, 0.5630, 0.5797, 0.5742, 0.5678],
       device='cuda:0') torch.Size([16])
percent tensor([0.5714, 0.5765, 0.5666, 0.5609, 0.5719, 0.5695, 0.5808, 0.5718, 0.5678,
        0.5740, 0.5746, 0.5773, 0.5715, 0.5719, 0.5777, 0.5724],
       device='cuda:0') torch.Size([16])
percent tensor([0.6186, 0.6427, 0.5765, 0.5574, 0.5499, 0.5772, 0.6128, 0.5707, 0.6005,
        0.6405, 0.6277, 0.6049, 0.6598, 0.6267, 0.6066, 0.6262],
       device='cuda:0') torch.Size([16])
percent tensor([0.6637, 0.6535, 0.6233, 0.6242, 0.6311, 0.6829, 0.6625, 0.6240, 0.6477,
        0.6572, 0.6650, 0.6414, 0.6605, 0.6585, 0.6645, 0.6669],
       device='cuda:0') torch.Size([16])
percent tensor([0.5396, 0.4918, 0.6233, 0.6758, 0.6565, 0.5986, 0.5533, 0.6441, 0.5937,
        0.5135, 0.5433, 0.5884, 0.4258, 0.6129, 0.5977, 0.5726],
       device='cuda:0') torch.Size([16])
percent tensor([0.5152, 0.6947, 0.6306, 0.6266, 0.6284, 0.7111, 0.6743, 0.5458, 0.6687,
        0.6326, 0.7136, 0.6358, 0.7014, 0.6944, 0.4645, 0.4991],
       device='cuda:0') torch.Size([16])
percent tensor([0.7353, 0.7789, 0.7227, 0.6599, 0.6762, 0.7642, 0.7815, 0.6598, 0.7316,
        0.7681, 0.7572, 0.6383, 0.7911, 0.7483, 0.5592, 0.6720],
       device='cuda:0') torch.Size([16])
percent tensor([0.9997, 0.9997, 0.9998, 0.9998, 0.9996, 0.9997, 0.9999, 0.9999, 0.9999,
        0.9999, 1.0000, 0.9998, 0.9998, 0.9998, 0.9998, 0.9994],
       device='cuda:0') torch.Size([16])
Epoch: 198 | Batch_idx: 0 |  Loss: (0.0910) |  Loss2: (0.0000) | Acc: (95.00%) (122/128)
Epoch: 198 | Batch_idx: 10 |  Loss: (0.0648) |  Loss2: (0.0000) | Acc: (97.00%) (1376/1408)
Epoch: 198 | Batch_idx: 20 |  Loss: (0.0622) |  Loss2: (0.0000) | Acc: (98.00%) (2638/2688)
Epoch: 198 | Batch_idx: 30 |  Loss: (0.0677) |  Loss2: (0.0000) | Acc: (98.00%) (3890/3968)
Epoch: 198 | Batch_idx: 40 |  Loss: (0.0670) |  Loss2: (0.0000) | Acc: (97.00%) (5143/5248)
Epoch: 198 | Batch_idx: 50 |  Loss: (0.0670) |  Loss2: (0.0000) | Acc: (97.00%) (6395/6528)
Epoch: 198 | Batch_idx: 60 |  Loss: (0.0660) |  Loss2: (0.0000) | Acc: (98.00%) (7652/7808)
Epoch: 198 | Batch_idx: 70 |  Loss: (0.0699) |  Loss2: (0.0000) | Acc: (97.00%) (8887/9088)
Epoch: 198 | Batch_idx: 80 |  Loss: (0.0723) |  Loss2: (0.0000) | Acc: (97.00%) (10121/10368)
Epoch: 198 | Batch_idx: 90 |  Loss: (0.0735) |  Loss2: (0.0000) | Acc: (97.00%) (11366/11648)
Epoch: 198 | Batch_idx: 100 |  Loss: (0.0740) |  Loss2: (0.0000) | Acc: (97.00%) (12613/12928)
Epoch: 198 | Batch_idx: 110 |  Loss: (0.0736) |  Loss2: (0.0000) | Acc: (97.00%) (13863/14208)
Epoch: 198 | Batch_idx: 120 |  Loss: (0.0741) |  Loss2: (0.0000) | Acc: (97.00%) (15116/15488)
Epoch: 198 | Batch_idx: 130 |  Loss: (0.0764) |  Loss2: (0.0000) | Acc: (97.00%) (16345/16768)
Epoch: 198 | Batch_idx: 140 |  Loss: (0.0753) |  Loss2: (0.0000) | Acc: (97.00%) (17601/18048)
Epoch: 198 | Batch_idx: 150 |  Loss: (0.0759) |  Loss2: (0.0000) | Acc: (97.00%) (18847/19328)
Epoch: 198 | Batch_idx: 160 |  Loss: (0.0760) |  Loss2: (0.0000) | Acc: (97.00%) (20093/20608)
Epoch: 198 | Batch_idx: 170 |  Loss: (0.0764) |  Loss2: (0.0000) | Acc: (97.00%) (21338/21888)
Epoch: 198 | Batch_idx: 180 |  Loss: (0.0762) |  Loss2: (0.0000) | Acc: (97.00%) (22586/23168)
Epoch: 198 | Batch_idx: 190 |  Loss: (0.0760) |  Loss2: (0.0000) | Acc: (97.00%) (23834/24448)
Epoch: 198 | Batch_idx: 200 |  Loss: (0.0759) |  Loss2: (0.0000) | Acc: (97.00%) (25087/25728)
Epoch: 198 | Batch_idx: 210 |  Loss: (0.0757) |  Loss2: (0.0000) | Acc: (97.00%) (26339/27008)
Epoch: 198 | Batch_idx: 220 |  Loss: (0.0753) |  Loss2: (0.0000) | Acc: (97.00%) (27591/28288)
Epoch: 198 | Batch_idx: 230 |  Loss: (0.0750) |  Loss2: (0.0000) | Acc: (97.00%) (28840/29568)
Epoch: 198 | Batch_idx: 240 |  Loss: (0.0758) |  Loss2: (0.0000) | Acc: (97.00%) (30079/30848)
Epoch: 198 | Batch_idx: 250 |  Loss: (0.0764) |  Loss2: (0.0000) | Acc: (97.00%) (31321/32128)
Epoch: 198 | Batch_idx: 260 |  Loss: (0.0767) |  Loss2: (0.0000) | Acc: (97.00%) (32564/33408)
Epoch: 198 | Batch_idx: 270 |  Loss: (0.0777) |  Loss2: (0.0000) | Acc: (97.00%) (33800/34688)
Epoch: 198 | Batch_idx: 280 |  Loss: (0.0778) |  Loss2: (0.0000) | Acc: (97.00%) (35048/35968)
Epoch: 198 | Batch_idx: 290 |  Loss: (0.0779) |  Loss2: (0.0000) | Acc: (97.00%) (36300/37248)
Epoch: 198 | Batch_idx: 300 |  Loss: (0.0790) |  Loss2: (0.0000) | Acc: (97.00%) (37528/38528)
Epoch: 198 | Batch_idx: 310 |  Loss: (0.0794) |  Loss2: (0.0000) | Acc: (97.00%) (38764/39808)
Epoch: 198 | Batch_idx: 320 |  Loss: (0.0795) |  Loss2: (0.0000) | Acc: (97.00%) (40011/41088)
Epoch: 198 | Batch_idx: 330 |  Loss: (0.0798) |  Loss2: (0.0000) | Acc: (97.00%) (41251/42368)
Epoch: 198 | Batch_idx: 340 |  Loss: (0.0796) |  Loss2: (0.0000) | Acc: (97.00%) (42502/43648)
Epoch: 198 | Batch_idx: 350 |  Loss: (0.0798) |  Loss2: (0.0000) | Acc: (97.00%) (43744/44928)
Epoch: 198 | Batch_idx: 360 |  Loss: (0.0795) |  Loss2: (0.0000) | Acc: (97.00%) (44997/46208)
Epoch: 198 | Batch_idx: 370 |  Loss: (0.0797) |  Loss2: (0.0000) | Acc: (97.00%) (46242/47488)
Epoch: 198 | Batch_idx: 380 |  Loss: (0.0799) |  Loss2: (0.0000) | Acc: (97.00%) (47479/48768)
Epoch: 198 | Batch_idx: 390 |  Loss: (0.0798) |  Loss2: (0.0000) | Acc: (97.00%) (48681/50000)
# TEST : Loss: (0.4535) | Acc: (87.00%) (8783/10000)
percent tensor([0.5613, 0.5781, 0.6000, 0.5960, 0.6026, 0.5698, 0.5864, 0.6031, 0.5753,
        0.5836, 0.5610, 0.5945, 0.5643, 0.5835, 0.5757, 0.5687],
       device='cuda:0') torch.Size([16])
percent tensor([0.5708, 0.5769, 0.5674, 0.5621, 0.5733, 0.5694, 0.5808, 0.5722, 0.5669,
        0.5744, 0.5741, 0.5783, 0.5710, 0.5721, 0.5783, 0.5720],
       device='cuda:0') torch.Size([16])
percent tensor([0.6108, 0.6374, 0.5680, 0.5524, 0.5412, 0.5732, 0.6070, 0.5653, 0.5950,
        0.6338, 0.6188, 0.5975, 0.6515, 0.6249, 0.6032, 0.6199],
       device='cuda:0') torch.Size([16])
percent tensor([0.6651, 0.6552, 0.6285, 0.6278, 0.6356, 0.6835, 0.6642, 0.6266, 0.6474,
        0.6573, 0.6641, 0.6451, 0.6603, 0.6600, 0.6672, 0.6692],
       device='cuda:0') torch.Size([16])
percent tensor([0.5627, 0.5125, 0.6408, 0.6661, 0.6689, 0.5967, 0.5841, 0.6581, 0.6143,
        0.5285, 0.5660, 0.5993, 0.4480, 0.6368, 0.6130, 0.5815],
       device='cuda:0') torch.Size([16])
percent tensor([0.5283, 0.6960, 0.6220, 0.6376, 0.6132, 0.7059, 0.6643, 0.5315, 0.6630,
        0.6427, 0.7110, 0.6368, 0.6852, 0.7134, 0.4899, 0.5088],
       device='cuda:0') torch.Size([16])
percent tensor([0.7298, 0.7730, 0.7281, 0.6751, 0.6888, 0.7508, 0.7716, 0.6501, 0.7150,
        0.7483, 0.7505, 0.6240, 0.7795, 0.7535, 0.5466, 0.6558],
       device='cuda:0') torch.Size([16])
percent tensor([0.9997, 0.9999, 0.9998, 0.9998, 0.9997, 0.9997, 0.9999, 0.9999, 0.9999,
        1.0000, 1.0000, 0.9996, 0.9999, 0.9997, 0.9999, 0.9994],
       device='cuda:0') torch.Size([16])
Epoch: 199 | Batch_idx: 0 |  Loss: (0.0677) |  Loss2: (0.0000) | Acc: (97.00%) (125/128)
Epoch: 199 | Batch_idx: 10 |  Loss: (0.0668) |  Loss2: (0.0000) | Acc: (97.00%) (1376/1408)
Epoch: 199 | Batch_idx: 20 |  Loss: (0.0738) |  Loss2: (0.0000) | Acc: (97.00%) (2622/2688)
Epoch: 199 | Batch_idx: 30 |  Loss: (0.0711) |  Loss2: (0.0000) | Acc: (97.00%) (3875/3968)
Epoch: 199 | Batch_idx: 40 |  Loss: (0.0744) |  Loss2: (0.0000) | Acc: (97.00%) (5119/5248)
Epoch: 199 | Batch_idx: 50 |  Loss: (0.0752) |  Loss2: (0.0000) | Acc: (97.00%) (6364/6528)
Epoch: 199 | Batch_idx: 60 |  Loss: (0.0750) |  Loss2: (0.0000) | Acc: (97.00%) (7617/7808)
Epoch: 199 | Batch_idx: 70 |  Loss: (0.0766) |  Loss2: (0.0000) | Acc: (97.00%) (8857/9088)
Epoch: 199 | Batch_idx: 80 |  Loss: (0.0772) |  Loss2: (0.0000) | Acc: (97.00%) (10100/10368)
Epoch: 199 | Batch_idx: 90 |  Loss: (0.0772) |  Loss2: (0.0000) | Acc: (97.00%) (11347/11648)
Epoch: 199 | Batch_idx: 100 |  Loss: (0.0761) |  Loss2: (0.0000) | Acc: (97.00%) (12597/12928)
Epoch: 199 | Batch_idx: 110 |  Loss: (0.0768) |  Loss2: (0.0000) | Acc: (97.00%) (13842/14208)
Epoch: 199 | Batch_idx: 120 |  Loss: (0.0759) |  Loss2: (0.0000) | Acc: (97.00%) (15090/15488)
Epoch: 199 | Batch_idx: 130 |  Loss: (0.0757) |  Loss2: (0.0000) | Acc: (97.00%) (16338/16768)
Epoch: 199 | Batch_idx: 140 |  Loss: (0.0755) |  Loss2: (0.0000) | Acc: (97.00%) (17588/18048)
Epoch: 199 | Batch_idx: 150 |  Loss: (0.0752) |  Loss2: (0.0000) | Acc: (97.00%) (18838/19328)
Epoch: 199 | Batch_idx: 160 |  Loss: (0.0748) |  Loss2: (0.0000) | Acc: (97.00%) (20094/20608)
Epoch: 199 | Batch_idx: 170 |  Loss: (0.0743) |  Loss2: (0.0000) | Acc: (97.00%) (21344/21888)
Epoch: 199 | Batch_idx: 180 |  Loss: (0.0738) |  Loss2: (0.0000) | Acc: (97.00%) (22598/23168)
Epoch: 199 | Batch_idx: 190 |  Loss: (0.0734) |  Loss2: (0.0000) | Acc: (97.00%) (23849/24448)
Epoch: 199 | Batch_idx: 200 |  Loss: (0.0743) |  Loss2: (0.0000) | Acc: (97.00%) (25089/25728)
Epoch: 199 | Batch_idx: 210 |  Loss: (0.0743) |  Loss2: (0.0000) | Acc: (97.00%) (26339/27008)
Epoch: 199 | Batch_idx: 220 |  Loss: (0.0745) |  Loss2: (0.0000) | Acc: (97.00%) (27586/28288)
Epoch: 199 | Batch_idx: 230 |  Loss: (0.0746) |  Loss2: (0.0000) | Acc: (97.00%) (28838/29568)
Epoch: 199 | Batch_idx: 240 |  Loss: (0.0751) |  Loss2: (0.0000) | Acc: (97.00%) (30076/30848)
Epoch: 199 | Batch_idx: 250 |  Loss: (0.0760) |  Loss2: (0.0000) | Acc: (97.00%) (31310/32128)
Epoch: 199 | Batch_idx: 260 |  Loss: (0.0758) |  Loss2: (0.0000) | Acc: (97.00%) (32558/33408)
Epoch: 199 | Batch_idx: 270 |  Loss: (0.0756) |  Loss2: (0.0000) | Acc: (97.00%) (33812/34688)
Epoch: 199 | Batch_idx: 280 |  Loss: (0.0762) |  Loss2: (0.0000) | Acc: (97.00%) (35047/35968)
Epoch: 199 | Batch_idx: 290 |  Loss: (0.0767) |  Loss2: (0.0000) | Acc: (97.00%) (36286/37248)
Epoch: 199 | Batch_idx: 300 |  Loss: (0.0773) |  Loss2: (0.0000) | Acc: (97.00%) (37518/38528)
Epoch: 199 | Batch_idx: 310 |  Loss: (0.0771) |  Loss2: (0.0000) | Acc: (97.00%) (38772/39808)
Epoch: 199 | Batch_idx: 320 |  Loss: (0.0776) |  Loss2: (0.0000) | Acc: (97.00%) (40011/41088)
Epoch: 199 | Batch_idx: 330 |  Loss: (0.0782) |  Loss2: (0.0000) | Acc: (97.00%) (41251/42368)
Epoch: 199 | Batch_idx: 340 |  Loss: (0.0783) |  Loss2: (0.0000) | Acc: (97.00%) (42500/43648)
Epoch: 199 | Batch_idx: 350 |  Loss: (0.0788) |  Loss2: (0.0000) | Acc: (97.00%) (43740/44928)
Epoch: 199 | Batch_idx: 360 |  Loss: (0.0787) |  Loss2: (0.0000) | Acc: (97.00%) (44989/46208)
Epoch: 199 | Batch_idx: 370 |  Loss: (0.0787) |  Loss2: (0.0000) | Acc: (97.00%) (46232/47488)
Epoch: 199 | Batch_idx: 380 |  Loss: (0.0785) |  Loss2: (0.0000) | Acc: (97.00%) (47484/48768)
Epoch: 199 | Batch_idx: 390 |  Loss: (0.0785) |  Loss2: (0.0000) | Acc: (97.00%) (48682/50000)
# TEST : Loss: (0.4113) | Acc: (88.00%) (8897/10000)
percent tensor([0.5616, 0.5761, 0.6004, 0.5956, 0.6032, 0.5703, 0.5845, 0.6027, 0.5746,
        0.5821, 0.5605, 0.5937, 0.5638, 0.5794, 0.5748, 0.5686],
       device='cuda:0') torch.Size([16])
percent tensor([0.5713, 0.5785, 0.5657, 0.5625, 0.5713, 0.5689, 0.5816, 0.5724, 0.5685,
        0.5753, 0.5756, 0.5779, 0.5720, 0.5743, 0.5787, 0.5729],
       device='cuda:0') torch.Size([16])
percent tensor([0.6138, 0.6331, 0.5712, 0.5490, 0.5438, 0.5744, 0.6059, 0.5633, 0.5954,
        0.6304, 0.6205, 0.6032, 0.6536, 0.6148, 0.6023, 0.6165],
       device='cuda:0') torch.Size([16])
percent tensor([0.6640, 0.6546, 0.6250, 0.6277, 0.6310, 0.6832, 0.6643, 0.6273, 0.6487,
        0.6552, 0.6646, 0.6430, 0.6593, 0.6604, 0.6669, 0.6661],
       device='cuda:0') torch.Size([16])
percent tensor([0.5653, 0.5150, 0.6486, 0.6716, 0.6751, 0.6171, 0.5801, 0.6560, 0.6309,
        0.5443, 0.5764, 0.6025, 0.4673, 0.6193, 0.6088, 0.5922],
       device='cuda:0') torch.Size([16])
percent tensor([0.5551, 0.7139, 0.6360, 0.6312, 0.6496, 0.7057, 0.6844, 0.5420, 0.6781,
        0.6507, 0.7267, 0.6416, 0.7166, 0.6955, 0.4972, 0.5251],
       device='cuda:0') torch.Size([16])
percent tensor([0.7403, 0.7747, 0.7068, 0.6617, 0.6621, 0.7418, 0.7504, 0.6450, 0.7284,
        0.7584, 0.7567, 0.6356, 0.7890, 0.7422, 0.5712, 0.6586],
       device='cuda:0') torch.Size([16])
percent tensor([0.9997, 0.9997, 0.9999, 0.9998, 0.9997, 0.9996, 0.9999, 0.9999, 0.9999,
        0.9999, 0.9999, 0.9997, 0.9998, 0.9997, 0.9999, 0.9992],
       device='cuda:0') torch.Size([16])
Epoch: 200 | Batch_idx: 0 |  Loss: (0.0657) |  Loss2: (0.0000) | Acc: (98.00%) (126/128)
Epoch: 200 | Batch_idx: 10 |  Loss: (0.0638) |  Loss2: (0.0000) | Acc: (98.00%) (1382/1408)
Epoch: 200 | Batch_idx: 20 |  Loss: (0.0662) |  Loss2: (0.0000) | Acc: (97.00%) (2634/2688)
Epoch: 200 | Batch_idx: 30 |  Loss: (0.0653) |  Loss2: (0.0000) | Acc: (97.00%) (3888/3968)
Epoch: 200 | Batch_idx: 40 |  Loss: (0.0658) |  Loss2: (0.0000) | Acc: (97.00%) (5135/5248)
Epoch: 200 | Batch_idx: 50 |  Loss: (0.0677) |  Loss2: (0.0000) | Acc: (97.00%) (6384/6528)
Epoch: 200 | Batch_idx: 60 |  Loss: (0.0701) |  Loss2: (0.0000) | Acc: (97.00%) (7633/7808)
Epoch: 200 | Batch_idx: 70 |  Loss: (0.0695) |  Loss2: (0.0000) | Acc: (97.00%) (8884/9088)
Epoch: 200 | Batch_idx: 80 |  Loss: (0.0687) |  Loss2: (0.0000) | Acc: (97.00%) (10137/10368)
Epoch: 200 | Batch_idx: 90 |  Loss: (0.0681) |  Loss2: (0.0000) | Acc: (97.00%) (11396/11648)
Epoch: 200 | Batch_idx: 100 |  Loss: (0.0687) |  Loss2: (0.0000) | Acc: (97.00%) (12638/12928)
Epoch: 200 | Batch_idx: 110 |  Loss: (0.0705) |  Loss2: (0.0000) | Acc: (97.00%) (13871/14208)
Epoch: 200 | Batch_idx: 120 |  Loss: (0.0706) |  Loss2: (0.0000) | Acc: (97.00%) (15112/15488)
Epoch: 200 | Batch_idx: 130 |  Loss: (0.0705) |  Loss2: (0.0000) | Acc: (97.00%) (16363/16768)
Epoch: 200 | Batch_idx: 140 |  Loss: (0.0709) |  Loss2: (0.0000) | Acc: (97.00%) (17610/18048)
Epoch: 200 | Batch_idx: 150 |  Loss: (0.0709) |  Loss2: (0.0000) | Acc: (97.00%) (18859/19328)
Epoch: 200 | Batch_idx: 160 |  Loss: (0.0712) |  Loss2: (0.0000) | Acc: (97.00%) (20107/20608)
Epoch: 200 | Batch_idx: 170 |  Loss: (0.0720) |  Loss2: (0.0000) | Acc: (97.00%) (21344/21888)
Epoch: 200 | Batch_idx: 180 |  Loss: (0.0721) |  Loss2: (0.0000) | Acc: (97.00%) (22598/23168)
Epoch: 200 | Batch_idx: 190 |  Loss: (0.0726) |  Loss2: (0.0000) | Acc: (97.00%) (23846/24448)
Epoch: 200 | Batch_idx: 200 |  Loss: (0.0726) |  Loss2: (0.0000) | Acc: (97.00%) (25096/25728)
Epoch: 200 | Batch_idx: 210 |  Loss: (0.0727) |  Loss2: (0.0000) | Acc: (97.00%) (26341/27008)
Epoch: 200 | Batch_idx: 220 |  Loss: (0.0728) |  Loss2: (0.0000) | Acc: (97.00%) (27581/28288)
Epoch: 200 | Batch_idx: 230 |  Loss: (0.0731) |  Loss2: (0.0000) | Acc: (97.00%) (28826/29568)
Epoch: 200 | Batch_idx: 240 |  Loss: (0.0737) |  Loss2: (0.0000) | Acc: (97.00%) (30064/30848)
Epoch: 200 | Batch_idx: 250 |  Loss: (0.0739) |  Loss2: (0.0000) | Acc: (97.00%) (31310/32128)
Epoch: 200 | Batch_idx: 260 |  Loss: (0.0739) |  Loss2: (0.0000) | Acc: (97.00%) (32558/33408)
Epoch: 200 | Batch_idx: 270 |  Loss: (0.0739) |  Loss2: (0.0000) | Acc: (97.00%) (33811/34688)
Epoch: 200 | Batch_idx: 280 |  Loss: (0.0738) |  Loss2: (0.0000) | Acc: (97.00%) (35057/35968)
Epoch: 200 | Batch_idx: 290 |  Loss: (0.0739) |  Loss2: (0.0000) | Acc: (97.00%) (36310/37248)
Epoch: 200 | Batch_idx: 300 |  Loss: (0.0740) |  Loss2: (0.0000) | Acc: (97.00%) (37554/38528)
Epoch: 200 | Batch_idx: 310 |  Loss: (0.0743) |  Loss2: (0.0000) | Acc: (97.00%) (38799/39808)
Epoch: 200 | Batch_idx: 320 |  Loss: (0.0744) |  Loss2: (0.0000) | Acc: (97.00%) (40045/41088)
Epoch: 200 | Batch_idx: 330 |  Loss: (0.0743) |  Loss2: (0.0000) | Acc: (97.00%) (41295/42368)
Epoch: 200 | Batch_idx: 340 |  Loss: (0.0740) |  Loss2: (0.0000) | Acc: (97.00%) (42550/43648)
Epoch: 200 | Batch_idx: 350 |  Loss: (0.0742) |  Loss2: (0.0000) | Acc: (97.00%) (43798/44928)
Epoch: 200 | Batch_idx: 360 |  Loss: (0.0739) |  Loss2: (0.0000) | Acc: (97.00%) (45049/46208)
Epoch: 200 | Batch_idx: 370 |  Loss: (0.0743) |  Loss2: (0.0000) | Acc: (97.00%) (46295/47488)
Epoch: 200 | Batch_idx: 380 |  Loss: (0.0742) |  Loss2: (0.0000) | Acc: (97.00%) (47546/48768)
Epoch: 200 | Batch_idx: 390 |  Loss: (0.0741) |  Loss2: (0.0000) | Acc: (97.00%) (48752/50000)
=> saving checkpoint 'drive/app/torch/save_Schedule/checkpoint_200.pth.tar'
# TEST : Loss: (0.4308) | Acc: (88.00%) (8826/10000)
percent tensor([0.5629, 0.5767, 0.6030, 0.5967, 0.6042, 0.5690, 0.5858, 0.6035, 0.5751,
        0.5835, 0.5603, 0.5964, 0.5645, 0.5809, 0.5749, 0.5690],
       device='cuda:0') torch.Size([16])
percent tensor([0.5742, 0.5798, 0.5694, 0.5646, 0.5751, 0.5726, 0.5841, 0.5747, 0.5703,
        0.5778, 0.5776, 0.5813, 0.5745, 0.5741, 0.5817, 0.5755],
       device='cuda:0') torch.Size([16])
percent tensor([0.6223, 0.6471, 0.5787, 0.5561, 0.5524, 0.5809, 0.6177, 0.5758, 0.6063,
        0.6441, 0.6329, 0.6119, 0.6626, 0.6303, 0.6133, 0.6282],
       device='cuda:0') torch.Size([16])
percent tensor([0.6757, 0.6643, 0.6342, 0.6383, 0.6435, 0.6961, 0.6740, 0.6382, 0.6565,
        0.6653, 0.6725, 0.6514, 0.6694, 0.6659, 0.6804, 0.6760],
       device='cuda:0') torch.Size([16])
percent tensor([0.5444, 0.4975, 0.6398, 0.6683, 0.6778, 0.6089, 0.5740, 0.6461, 0.6057,
        0.5204, 0.5507, 0.5911, 0.4362, 0.6284, 0.6040, 0.5667],
       device='cuda:0') torch.Size([16])
percent tensor([0.5491, 0.6942, 0.6346, 0.6390, 0.6240, 0.7161, 0.6500, 0.5444, 0.6449,
        0.6189, 0.7134, 0.6461, 0.6935, 0.6731, 0.4769, 0.4946],
       device='cuda:0') torch.Size([16])
percent tensor([0.7129, 0.7517, 0.7180, 0.6690, 0.6523, 0.7469, 0.7322, 0.6338, 0.7065,
        0.7253, 0.7501, 0.6366, 0.7606, 0.7339, 0.5491, 0.6336],
       device='cuda:0') torch.Size([16])
percent tensor([0.9997, 0.9997, 0.9999, 0.9999, 0.9996, 0.9998, 0.9999, 0.9999, 0.9999,
        0.9999, 0.9999, 0.9997, 0.9997, 0.9999, 0.9998, 0.9990],
       device='cuda:0') torch.Size([16])
Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 3, 3, 3]) tensor(191.1049, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(827.2502, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(849.7173, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([128, 64, 3, 3]) tensor(1521.2367, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([128, 64, 1, 1]) tensor(482.1770, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([128, 128, 3, 3]) tensor(2293.9084, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([256, 128, 3, 3]) tensor(4240.2598, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([256, 128, 1, 1]) tensor(1341.0902, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([256, 256, 3, 3]) tensor(6266.9160, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([512, 256, 3, 3]) tensor(11530.1094, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([512, 256, 1, 1]) tensor(3789.4016, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([512, 512, 3, 3]) tensor(15992.1592, device='cuda:0', grad_fn=<NormBackward0>)
Epoch: 201 | Batch_idx: 0 |  Loss: (0.0699) |  Loss2: (0.0000) | Acc: (97.00%) (125/128)
Epoch: 201 | Batch_idx: 10 |  Loss: (0.0624) |  Loss2: (0.0000) | Acc: (98.00%) (1382/1408)
Epoch: 201 | Batch_idx: 20 |  Loss: (0.0647) |  Loss2: (0.0000) | Acc: (97.00%) (2634/2688)
Epoch: 201 | Batch_idx: 30 |  Loss: (0.0631) |  Loss2: (0.0000) | Acc: (97.00%) (3887/3968)
Epoch: 201 | Batch_idx: 40 |  Loss: (0.0656) |  Loss2: (0.0000) | Acc: (97.00%) (5138/5248)
Epoch: 201 | Batch_idx: 50 |  Loss: (0.0683) |  Loss2: (0.0000) | Acc: (97.00%) (6384/6528)
Epoch: 201 | Batch_idx: 60 |  Loss: (0.0702) |  Loss2: (0.0000) | Acc: (97.00%) (7624/7808)
Epoch: 201 | Batch_idx: 70 |  Loss: (0.0707) |  Loss2: (0.0000) | Acc: (97.00%) (8870/9088)
Epoch: 201 | Batch_idx: 80 |  Loss: (0.0718) |  Loss2: (0.0000) | Acc: (97.00%) (10112/10368)
Epoch: 201 | Batch_idx: 90 |  Loss: (0.0715) |  Loss2: (0.0000) | Acc: (97.00%) (11364/11648)
Epoch: 201 | Batch_idx: 100 |  Loss: (0.0708) |  Loss2: (0.0000) | Acc: (97.00%) (12615/12928)
Epoch: 201 | Batch_idx: 110 |  Loss: (0.0708) |  Loss2: (0.0000) | Acc: (97.00%) (13862/14208)
Epoch: 201 | Batch_idx: 120 |  Loss: (0.0708) |  Loss2: (0.0000) | Acc: (97.00%) (15115/15488)
Epoch: 201 | Batch_idx: 130 |  Loss: (0.0709) |  Loss2: (0.0000) | Acc: (97.00%) (16370/16768)
Epoch: 201 | Batch_idx: 140 |  Loss: (0.0727) |  Loss2: (0.0000) | Acc: (97.00%) (17604/18048)
Epoch: 201 | Batch_idx: 150 |  Loss: (0.0728) |  Loss2: (0.0000) | Acc: (97.00%) (18847/19328)
Epoch: 201 | Batch_idx: 160 |  Loss: (0.0731) |  Loss2: (0.0000) | Acc: (97.00%) (20091/20608)
Epoch: 201 | Batch_idx: 170 |  Loss: (0.0726) |  Loss2: (0.0000) | Acc: (97.00%) (21349/21888)
Epoch: 201 | Batch_idx: 180 |  Loss: (0.0723) |  Loss2: (0.0000) | Acc: (97.00%) (22601/23168)
Epoch: 201 | Batch_idx: 190 |  Loss: (0.0727) |  Loss2: (0.0000) | Acc: (97.00%) (23850/24448)
Epoch: 201 | Batch_idx: 200 |  Loss: (0.0724) |  Loss2: (0.0000) | Acc: (97.00%) (25101/25728)
Epoch: 201 | Batch_idx: 210 |  Loss: (0.0722) |  Loss2: (0.0000) | Acc: (97.00%) (26348/27008)
Epoch: 201 | Batch_idx: 220 |  Loss: (0.0726) |  Loss2: (0.0000) | Acc: (97.00%) (27592/28288)
Epoch: 201 | Batch_idx: 230 |  Loss: (0.0730) |  Loss2: (0.0000) | Acc: (97.00%) (28838/29568)
Epoch: 201 | Batch_idx: 240 |  Loss: (0.0731) |  Loss2: (0.0000) | Acc: (97.00%) (30082/30848)
Epoch: 201 | Batch_idx: 250 |  Loss: (0.0730) |  Loss2: (0.0000) | Acc: (97.00%) (31328/32128)
Epoch: 201 | Batch_idx: 260 |  Loss: (0.0731) |  Loss2: (0.0000) | Acc: (97.00%) (32575/33408)
Epoch: 201 | Batch_idx: 270 |  Loss: (0.0725) |  Loss2: (0.0000) | Acc: (97.00%) (33833/34688)
Epoch: 201 | Batch_idx: 280 |  Loss: (0.0724) |  Loss2: (0.0000) | Acc: (97.00%) (35083/35968)
Epoch: 201 | Batch_idx: 290 |  Loss: (0.0719) |  Loss2: (0.0000) | Acc: (97.00%) (36342/37248)
Epoch: 201 | Batch_idx: 300 |  Loss: (0.0722) |  Loss2: (0.0000) | Acc: (97.00%) (37583/38528)
Epoch: 201 | Batch_idx: 310 |  Loss: (0.0725) |  Loss2: (0.0000) | Acc: (97.00%) (38823/39808)
Epoch: 201 | Batch_idx: 320 |  Loss: (0.0719) |  Loss2: (0.0000) | Acc: (97.00%) (40084/41088)
Epoch: 201 | Batch_idx: 330 |  Loss: (0.0726) |  Loss2: (0.0000) | Acc: (97.00%) (41323/42368)
Epoch: 201 | Batch_idx: 340 |  Loss: (0.0729) |  Loss2: (0.0000) | Acc: (97.00%) (42569/43648)
Epoch: 201 | Batch_idx: 350 |  Loss: (0.0730) |  Loss2: (0.0000) | Acc: (97.00%) (43815/44928)
Epoch: 201 | Batch_idx: 360 |  Loss: (0.0736) |  Loss2: (0.0000) | Acc: (97.00%) (45055/46208)
Epoch: 201 | Batch_idx: 370 |  Loss: (0.0735) |  Loss2: (0.0000) | Acc: (97.00%) (46302/47488)
Epoch: 201 | Batch_idx: 380 |  Loss: (0.0736) |  Loss2: (0.0000) | Acc: (97.00%) (47548/48768)
Epoch: 201 | Batch_idx: 390 |  Loss: (0.0741) |  Loss2: (0.0000) | Acc: (97.00%) (48741/50000)
# TEST : Loss: (0.4703) | Acc: (87.00%) (8797/10000)
percent tensor([0.5661, 0.5787, 0.6085, 0.5993, 0.6088, 0.5726, 0.5896, 0.6064, 0.5795,
        0.5866, 0.5636, 0.6017, 0.5682, 0.5817, 0.5778, 0.5711],
       device='cuda:0') torch.Size([16])
percent tensor([0.5759, 0.5814, 0.5711, 0.5660, 0.5769, 0.5733, 0.5857, 0.5769, 0.5715,
        0.5790, 0.5791, 0.5825, 0.5760, 0.5765, 0.5822, 0.5774],
       device='cuda:0') torch.Size([16])
percent tensor([0.6237, 0.6437, 0.5826, 0.5585, 0.5570, 0.5856, 0.6187, 0.5748, 0.6035,
        0.6445, 0.6296, 0.6100, 0.6604, 0.6272, 0.6147, 0.6308],
       device='cuda:0') torch.Size([16])
percent tensor([0.6737, 0.6624, 0.6375, 0.6354, 0.6437, 0.6881, 0.6759, 0.6381, 0.6565,
        0.6665, 0.6731, 0.6543, 0.6687, 0.6675, 0.6732, 0.6756],
       device='cuda:0') torch.Size([16])
percent tensor([0.5748, 0.5104, 0.6443, 0.6671, 0.6771, 0.6021, 0.5793, 0.6556, 0.6363,
        0.5302, 0.5901, 0.5953, 0.4667, 0.6330, 0.6147, 0.5826],
       device='cuda:0') torch.Size([16])
percent tensor([0.5432, 0.7079, 0.6627, 0.6536, 0.6483, 0.7334, 0.6611, 0.5516, 0.6845,
        0.6468, 0.7239, 0.6499, 0.7000, 0.7054, 0.5018, 0.4858],
       device='cuda:0') torch.Size([16])
percent tensor([0.7117, 0.7500, 0.7139, 0.6719, 0.6432, 0.7483, 0.7332, 0.6357, 0.6937,
        0.7308, 0.7265, 0.6158, 0.7573, 0.7318, 0.5450, 0.6362],
       device='cuda:0') torch.Size([16])
percent tensor([0.9998, 0.9998, 0.9999, 0.9999, 0.9995, 0.9998, 0.9999, 0.9999, 0.9999,
        0.9999, 0.9999, 0.9996, 0.9997, 0.9998, 0.9999, 0.9996],
       device='cuda:0') torch.Size([16])
Epoch: 202 | Batch_idx: 0 |  Loss: (0.0524) |  Loss2: (0.0000) | Acc: (98.00%) (126/128)
Epoch: 202 | Batch_idx: 10 |  Loss: (0.0674) |  Loss2: (0.0000) | Acc: (97.00%) (1376/1408)
Epoch: 202 | Batch_idx: 20 |  Loss: (0.0720) |  Loss2: (0.0000) | Acc: (97.00%) (2619/2688)
Epoch: 202 | Batch_idx: 30 |  Loss: (0.0725) |  Loss2: (0.0000) | Acc: (97.00%) (3869/3968)
Epoch: 202 | Batch_idx: 40 |  Loss: (0.0752) |  Loss2: (0.0000) | Acc: (97.00%) (5113/5248)
Epoch: 202 | Batch_idx: 50 |  Loss: (0.0703) |  Loss2: (0.0000) | Acc: (97.00%) (6375/6528)
Epoch: 202 | Batch_idx: 60 |  Loss: (0.0699) |  Loss2: (0.0000) | Acc: (97.00%) (7625/7808)
Epoch: 202 | Batch_idx: 70 |  Loss: (0.0734) |  Loss2: (0.0000) | Acc: (97.00%) (8862/9088)
Epoch: 202 | Batch_idx: 80 |  Loss: (0.0734) |  Loss2: (0.0000) | Acc: (97.00%) (10114/10368)
Epoch: 202 | Batch_idx: 90 |  Loss: (0.0729) |  Loss2: (0.0000) | Acc: (97.00%) (11368/11648)
Epoch: 202 | Batch_idx: 100 |  Loss: (0.0725) |  Loss2: (0.0000) | Acc: (97.00%) (12618/12928)
Epoch: 202 | Batch_idx: 110 |  Loss: (0.0725) |  Loss2: (0.0000) | Acc: (97.00%) (13868/14208)
Epoch: 202 | Batch_idx: 120 |  Loss: (0.0722) |  Loss2: (0.0000) | Acc: (97.00%) (15117/15488)
Epoch: 202 | Batch_idx: 130 |  Loss: (0.0724) |  Loss2: (0.0000) | Acc: (97.00%) (16367/16768)
Epoch: 202 | Batch_idx: 140 |  Loss: (0.0722) |  Loss2: (0.0000) | Acc: (97.00%) (17621/18048)
Epoch: 202 | Batch_idx: 150 |  Loss: (0.0725) |  Loss2: (0.0000) | Acc: (97.00%) (18866/19328)
Epoch: 202 | Batch_idx: 160 |  Loss: (0.0725) |  Loss2: (0.0000) | Acc: (97.00%) (20112/20608)
Epoch: 202 | Batch_idx: 170 |  Loss: (0.0721) |  Loss2: (0.0000) | Acc: (97.00%) (21365/21888)
Epoch: 202 | Batch_idx: 180 |  Loss: (0.0727) |  Loss2: (0.0000) | Acc: (97.00%) (22606/23168)
Epoch: 202 | Batch_idx: 190 |  Loss: (0.0728) |  Loss2: (0.0000) | Acc: (97.00%) (23851/24448)
Epoch: 202 | Batch_idx: 200 |  Loss: (0.0728) |  Loss2: (0.0000) | Acc: (97.00%) (25101/25728)
Epoch: 202 | Batch_idx: 210 |  Loss: (0.0718) |  Loss2: (0.0000) | Acc: (97.00%) (26361/27008)
Epoch: 202 | Batch_idx: 220 |  Loss: (0.0715) |  Loss2: (0.0000) | Acc: (97.00%) (27615/28288)
Epoch: 202 | Batch_idx: 230 |  Loss: (0.0708) |  Loss2: (0.0000) | Acc: (97.00%) (28876/29568)
Epoch: 202 | Batch_idx: 240 |  Loss: (0.0705) |  Loss2: (0.0000) | Acc: (97.00%) (30134/30848)
Epoch: 202 | Batch_idx: 250 |  Loss: (0.0705) |  Loss2: (0.0000) | Acc: (97.00%) (31382/32128)
Epoch: 202 | Batch_idx: 260 |  Loss: (0.0700) |  Loss2: (0.0000) | Acc: (97.00%) (32629/33408)
Epoch: 202 | Batch_idx: 270 |  Loss: (0.0700) |  Loss2: (0.0000) | Acc: (97.00%) (33877/34688)
Epoch: 202 | Batch_idx: 280 |  Loss: (0.0696) |  Loss2: (0.0000) | Acc: (97.00%) (35136/35968)
Epoch: 202 | Batch_idx: 290 |  Loss: (0.0697) |  Loss2: (0.0000) | Acc: (97.00%) (36386/37248)
Epoch: 202 | Batch_idx: 300 |  Loss: (0.0694) |  Loss2: (0.0000) | Acc: (97.00%) (37640/38528)
Epoch: 202 | Batch_idx: 310 |  Loss: (0.0696) |  Loss2: (0.0000) | Acc: (97.00%) (38888/39808)
Epoch: 202 | Batch_idx: 320 |  Loss: (0.0694) |  Loss2: (0.0000) | Acc: (97.00%) (40143/41088)
Epoch: 202 | Batch_idx: 330 |  Loss: (0.0694) |  Loss2: (0.0000) | Acc: (97.00%) (41389/42368)
Epoch: 202 | Batch_idx: 340 |  Loss: (0.0696) |  Loss2: (0.0000) | Acc: (97.00%) (42627/43648)
Epoch: 202 | Batch_idx: 350 |  Loss: (0.0695) |  Loss2: (0.0000) | Acc: (97.00%) (43878/44928)
Epoch: 202 | Batch_idx: 360 |  Loss: (0.0699) |  Loss2: (0.0000) | Acc: (97.00%) (45119/46208)
Epoch: 202 | Batch_idx: 370 |  Loss: (0.0699) |  Loss2: (0.0000) | Acc: (97.00%) (46370/47488)
Epoch: 202 | Batch_idx: 380 |  Loss: (0.0704) |  Loss2: (0.0000) | Acc: (97.00%) (47609/48768)
Epoch: 202 | Batch_idx: 390 |  Loss: (0.0710) |  Loss2: (0.0000) | Acc: (97.00%) (48799/50000)
# TEST : Loss: (0.4371) | Acc: (88.00%) (8847/10000)
percent tensor([0.5622, 0.5765, 0.6024, 0.5958, 0.6040, 0.5689, 0.5860, 0.6037, 0.5758,
        0.5833, 0.5613, 0.5957, 0.5644, 0.5800, 0.5753, 0.5688],
       device='cuda:0') torch.Size([16])
percent tensor([0.5767, 0.5814, 0.5716, 0.5682, 0.5775, 0.5744, 0.5845, 0.5776, 0.5719,
        0.5789, 0.5790, 0.5828, 0.5764, 0.5751, 0.5830, 0.5777],
       device='cuda:0') torch.Size([16])
percent tensor([0.6268, 0.6489, 0.5864, 0.5588, 0.5590, 0.5835, 0.6209, 0.5732, 0.6091,
        0.6490, 0.6356, 0.6160, 0.6686, 0.6297, 0.6167, 0.6308],
       device='cuda:0') torch.Size([16])
percent tensor([0.6733, 0.6625, 0.6362, 0.6367, 0.6446, 0.6857, 0.6725, 0.6390, 0.6541,
        0.6652, 0.6669, 0.6524, 0.6673, 0.6639, 0.6755, 0.6732],
       device='cuda:0') torch.Size([16])
percent tensor([0.5574, 0.5216, 0.6383, 0.6597, 0.6682, 0.5971, 0.5897, 0.6618, 0.6083,
        0.5331, 0.5647, 0.5873, 0.4397, 0.6317, 0.6065, 0.5851],
       device='cuda:0') torch.Size([16])
percent tensor([0.5395, 0.7236, 0.6491, 0.6411, 0.6387, 0.7180, 0.6865, 0.5765, 0.6782,
        0.6562, 0.7247, 0.6645, 0.7234, 0.7170, 0.5257, 0.5111],
       device='cuda:0') torch.Size([16])
percent tensor([0.7093, 0.7695, 0.7071, 0.6678, 0.6371, 0.7360, 0.7608, 0.6432, 0.7097,
        0.7410, 0.7495, 0.6229, 0.7608, 0.7493, 0.5539, 0.6314],
       device='cuda:0') torch.Size([16])
percent tensor([0.9997, 0.9998, 0.9999, 0.9998, 0.9998, 0.9998, 0.9999, 0.9999, 0.9999,
        0.9999, 0.9999, 0.9998, 0.9998, 0.9998, 0.9998, 0.9992],
       device='cuda:0') torch.Size([16])
Epoch: 203 | Batch_idx: 0 |  Loss: (0.0810) |  Loss2: (0.0000) | Acc: (97.00%) (125/128)
Epoch: 203 | Batch_idx: 10 |  Loss: (0.0715) |  Loss2: (0.0000) | Acc: (97.00%) (1372/1408)
Epoch: 203 | Batch_idx: 20 |  Loss: (0.0711) |  Loss2: (0.0000) | Acc: (97.00%) (2616/2688)
Epoch: 203 | Batch_idx: 30 |  Loss: (0.0704) |  Loss2: (0.0000) | Acc: (97.00%) (3867/3968)
Epoch: 203 | Batch_idx: 40 |  Loss: (0.0690) |  Loss2: (0.0000) | Acc: (97.00%) (5116/5248)
Epoch: 203 | Batch_idx: 50 |  Loss: (0.0691) |  Loss2: (0.0000) | Acc: (97.00%) (6366/6528)
Epoch: 203 | Batch_idx: 60 |  Loss: (0.0670) |  Loss2: (0.0000) | Acc: (97.00%) (7620/7808)
Epoch: 203 | Batch_idx: 70 |  Loss: (0.0683) |  Loss2: (0.0000) | Acc: (97.00%) (8863/9088)
Epoch: 203 | Batch_idx: 80 |  Loss: (0.0678) |  Loss2: (0.0000) | Acc: (97.00%) (10114/10368)
Epoch: 203 | Batch_idx: 90 |  Loss: (0.0673) |  Loss2: (0.0000) | Acc: (97.00%) (11368/11648)
Epoch: 203 | Batch_idx: 100 |  Loss: (0.0676) |  Loss2: (0.0000) | Acc: (97.00%) (12618/12928)
Epoch: 203 | Batch_idx: 110 |  Loss: (0.0689) |  Loss2: (0.0000) | Acc: (97.00%) (13858/14208)
Epoch: 203 | Batch_idx: 120 |  Loss: (0.0687) |  Loss2: (0.0000) | Acc: (97.00%) (15112/15488)
Epoch: 203 | Batch_idx: 130 |  Loss: (0.0694) |  Loss2: (0.0000) | Acc: (97.00%) (16360/16768)
Epoch: 203 | Batch_idx: 140 |  Loss: (0.0696) |  Loss2: (0.0000) | Acc: (97.00%) (17609/18048)
Epoch: 203 | Batch_idx: 150 |  Loss: (0.0700) |  Loss2: (0.0000) | Acc: (97.00%) (18857/19328)
Epoch: 203 | Batch_idx: 160 |  Loss: (0.0698) |  Loss2: (0.0000) | Acc: (97.00%) (20107/20608)
Epoch: 203 | Batch_idx: 170 |  Loss: (0.0697) |  Loss2: (0.0000) | Acc: (97.00%) (21354/21888)
Epoch: 203 | Batch_idx: 180 |  Loss: (0.0692) |  Loss2: (0.0000) | Acc: (97.00%) (22607/23168)
Epoch: 203 | Batch_idx: 190 |  Loss: (0.0697) |  Loss2: (0.0000) | Acc: (97.00%) (23854/24448)
Epoch: 203 | Batch_idx: 200 |  Loss: (0.0693) |  Loss2: (0.0000) | Acc: (97.00%) (25116/25728)
Epoch: 203 | Batch_idx: 210 |  Loss: (0.0688) |  Loss2: (0.0000) | Acc: (97.00%) (26371/27008)
Epoch: 203 | Batch_idx: 220 |  Loss: (0.0685) |  Loss2: (0.0000) | Acc: (97.00%) (27623/28288)
Epoch: 203 | Batch_idx: 230 |  Loss: (0.0681) |  Loss2: (0.0000) | Acc: (97.00%) (28877/29568)
Epoch: 203 | Batch_idx: 240 |  Loss: (0.0678) |  Loss2: (0.0000) | Acc: (97.00%) (30130/30848)
Epoch: 203 | Batch_idx: 250 |  Loss: (0.0678) |  Loss2: (0.0000) | Acc: (97.00%) (31384/32128)
Epoch: 203 | Batch_idx: 260 |  Loss: (0.0678) |  Loss2: (0.0000) | Acc: (97.00%) (32630/33408)
Epoch: 203 | Batch_idx: 270 |  Loss: (0.0677) |  Loss2: (0.0000) | Acc: (97.00%) (33883/34688)
Epoch: 203 | Batch_idx: 280 |  Loss: (0.0675) |  Loss2: (0.0000) | Acc: (97.00%) (35143/35968)
Epoch: 203 | Batch_idx: 290 |  Loss: (0.0674) |  Loss2: (0.0000) | Acc: (97.00%) (36394/37248)
Epoch: 203 | Batch_idx: 300 |  Loss: (0.0675) |  Loss2: (0.0000) | Acc: (97.00%) (37645/38528)
Epoch: 203 | Batch_idx: 310 |  Loss: (0.0673) |  Loss2: (0.0000) | Acc: (97.00%) (38898/39808)
Epoch: 203 | Batch_idx: 320 |  Loss: (0.0673) |  Loss2: (0.0000) | Acc: (97.00%) (40140/41088)
Epoch: 203 | Batch_idx: 330 |  Loss: (0.0672) |  Loss2: (0.0000) | Acc: (97.00%) (41397/42368)
Epoch: 203 | Batch_idx: 340 |  Loss: (0.0673) |  Loss2: (0.0000) | Acc: (97.00%) (42646/43648)
Epoch: 203 | Batch_idx: 350 |  Loss: (0.0675) |  Loss2: (0.0000) | Acc: (97.00%) (43892/44928)
Epoch: 203 | Batch_idx: 360 |  Loss: (0.0675) |  Loss2: (0.0000) | Acc: (97.00%) (45140/46208)
Epoch: 203 | Batch_idx: 370 |  Loss: (0.0678) |  Loss2: (0.0000) | Acc: (97.00%) (46384/47488)
Epoch: 203 | Batch_idx: 380 |  Loss: (0.0682) |  Loss2: (0.0000) | Acc: (97.00%) (47633/48768)
Epoch: 203 | Batch_idx: 390 |  Loss: (0.0687) |  Loss2: (0.0000) | Acc: (97.00%) (48831/50000)
# TEST : Loss: (0.4852) | Acc: (87.00%) (8752/10000)
percent tensor([0.5648, 0.5797, 0.6057, 0.5987, 0.6072, 0.5713, 0.5886, 0.6064, 0.5779,
        0.5857, 0.5628, 0.5988, 0.5666, 0.5827, 0.5781, 0.5706],
       device='cuda:0') torch.Size([16])
percent tensor([0.5746, 0.5810, 0.5707, 0.5659, 0.5765, 0.5726, 0.5852, 0.5771, 0.5709,
        0.5781, 0.5779, 0.5823, 0.5746, 0.5757, 0.5824, 0.5763],
       device='cuda:0') torch.Size([16])
percent tensor([0.6260, 0.6534, 0.5857, 0.5615, 0.5589, 0.5825, 0.6240, 0.5776, 0.6073,
        0.6519, 0.6345, 0.6107, 0.6670, 0.6356, 0.6176, 0.6338],
       device='cuda:0') torch.Size([16])
percent tensor([0.6771, 0.6686, 0.6408, 0.6385, 0.6481, 0.6851, 0.6803, 0.6441, 0.6589,
        0.6707, 0.6751, 0.6557, 0.6720, 0.6732, 0.6764, 0.6781],
       device='cuda:0') torch.Size([16])
percent tensor([0.5811, 0.5276, 0.6470, 0.6653, 0.6812, 0.6172, 0.5961, 0.6517, 0.6287,
        0.5496, 0.5818, 0.6050, 0.4766, 0.6387, 0.6211, 0.5909],
       device='cuda:0') torch.Size([16])
percent tensor([0.5361, 0.7041, 0.6579, 0.6499, 0.6468, 0.7391, 0.6749, 0.5709, 0.6875,
        0.6361, 0.7188, 0.6504, 0.6956, 0.7054, 0.4800, 0.5049],
       device='cuda:0') torch.Size([16])
percent tensor([0.7107, 0.7580, 0.7155, 0.6631, 0.6561, 0.7460, 0.7342, 0.6426, 0.7124,
        0.7193, 0.7381, 0.6431, 0.7542, 0.7217, 0.5509, 0.6191],
       device='cuda:0') torch.Size([16])
percent tensor([0.9998, 0.9998, 0.9999, 0.9999, 0.9998, 0.9997, 0.9999, 1.0000, 1.0000,
        0.9999, 1.0000, 0.9998, 0.9998, 0.9996, 0.9999, 0.9993],
       device='cuda:0') torch.Size([16])
Epoch: 204 | Batch_idx: 0 |  Loss: (0.0354) |  Loss2: (0.0000) | Acc: (98.00%) (126/128)
Epoch: 204 | Batch_idx: 10 |  Loss: (0.0703) |  Loss2: (0.0000) | Acc: (97.00%) (1377/1408)
Epoch: 204 | Batch_idx: 20 |  Loss: (0.0753) |  Loss2: (0.0000) | Acc: (97.00%) (2621/2688)
Epoch: 204 | Batch_idx: 30 |  Loss: (0.0677) |  Loss2: (0.0000) | Acc: (97.00%) (3878/3968)
Epoch: 204 | Batch_idx: 40 |  Loss: (0.0667) |  Loss2: (0.0000) | Acc: (97.00%) (5134/5248)
Epoch: 204 | Batch_idx: 50 |  Loss: (0.0646) |  Loss2: (0.0000) | Acc: (97.00%) (6396/6528)
Epoch: 204 | Batch_idx: 60 |  Loss: (0.0617) |  Loss2: (0.0000) | Acc: (98.00%) (7655/7808)
Epoch: 204 | Batch_idx: 70 |  Loss: (0.0616) |  Loss2: (0.0000) | Acc: (98.00%) (8909/9088)
Epoch: 204 | Batch_idx: 80 |  Loss: (0.0605) |  Loss2: (0.0000) | Acc: (98.00%) (10167/10368)
Epoch: 204 | Batch_idx: 90 |  Loss: (0.0598) |  Loss2: (0.0000) | Acc: (98.00%) (11425/11648)
Epoch: 204 | Batch_idx: 100 |  Loss: (0.0606) |  Loss2: (0.0000) | Acc: (98.00%) (12678/12928)
Epoch: 204 | Batch_idx: 110 |  Loss: (0.0600) |  Loss2: (0.0000) | Acc: (98.00%) (13939/14208)
Epoch: 204 | Batch_idx: 120 |  Loss: (0.0607) |  Loss2: (0.0000) | Acc: (98.00%) (15193/15488)
Epoch: 204 | Batch_idx: 130 |  Loss: (0.0603) |  Loss2: (0.0000) | Acc: (98.00%) (16451/16768)
Epoch: 204 | Batch_idx: 140 |  Loss: (0.0604) |  Loss2: (0.0000) | Acc: (98.00%) (17703/18048)
Epoch: 204 | Batch_idx: 150 |  Loss: (0.0611) |  Loss2: (0.0000) | Acc: (98.00%) (18947/19328)
Epoch: 204 | Batch_idx: 160 |  Loss: (0.0614) |  Loss2: (0.0000) | Acc: (97.00%) (20194/20608)
Epoch: 204 | Batch_idx: 170 |  Loss: (0.0618) |  Loss2: (0.0000) | Acc: (97.00%) (21446/21888)
Epoch: 204 | Batch_idx: 180 |  Loss: (0.0624) |  Loss2: (0.0000) | Acc: (97.00%) (22697/23168)
Epoch: 204 | Batch_idx: 190 |  Loss: (0.0621) |  Loss2: (0.0000) | Acc: (97.00%) (23951/24448)
Epoch: 204 | Batch_idx: 200 |  Loss: (0.0623) |  Loss2: (0.0000) | Acc: (97.00%) (25199/25728)
Epoch: 204 | Batch_idx: 210 |  Loss: (0.0622) |  Loss2: (0.0000) | Acc: (97.00%) (26447/27008)
Epoch: 204 | Batch_idx: 220 |  Loss: (0.0632) |  Loss2: (0.0000) | Acc: (97.00%) (27691/28288)
Epoch: 204 | Batch_idx: 230 |  Loss: (0.0641) |  Loss2: (0.0000) | Acc: (97.00%) (28933/29568)
Epoch: 204 | Batch_idx: 240 |  Loss: (0.0645) |  Loss2: (0.0000) | Acc: (97.00%) (30179/30848)
Epoch: 204 | Batch_idx: 250 |  Loss: (0.0644) |  Loss2: (0.0000) | Acc: (97.00%) (31432/32128)
Epoch: 204 | Batch_idx: 260 |  Loss: (0.0651) |  Loss2: (0.0000) | Acc: (97.00%) (32677/33408)
Epoch: 204 | Batch_idx: 270 |  Loss: (0.0654) |  Loss2: (0.0000) | Acc: (97.00%) (33925/34688)
Epoch: 204 | Batch_idx: 280 |  Loss: (0.0653) |  Loss2: (0.0000) | Acc: (97.00%) (35183/35968)
Epoch: 204 | Batch_idx: 290 |  Loss: (0.0651) |  Loss2: (0.0000) | Acc: (97.00%) (36439/37248)
Epoch: 204 | Batch_idx: 300 |  Loss: (0.0651) |  Loss2: (0.0000) | Acc: (97.00%) (37694/38528)
Epoch: 204 | Batch_idx: 310 |  Loss: (0.0655) |  Loss2: (0.0000) | Acc: (97.00%) (38936/39808)
Epoch: 204 | Batch_idx: 320 |  Loss: (0.0660) |  Loss2: (0.0000) | Acc: (97.00%) (40183/41088)
Epoch: 204 | Batch_idx: 330 |  Loss: (0.0664) |  Loss2: (0.0000) | Acc: (97.00%) (41432/42368)
Epoch: 204 | Batch_idx: 340 |  Loss: (0.0667) |  Loss2: (0.0000) | Acc: (97.00%) (42678/43648)
Epoch: 204 | Batch_idx: 350 |  Loss: (0.0671) |  Loss2: (0.0000) | Acc: (97.00%) (43923/44928)
Epoch: 204 | Batch_idx: 360 |  Loss: (0.0673) |  Loss2: (0.0000) | Acc: (97.00%) (45170/46208)
Epoch: 204 | Batch_idx: 370 |  Loss: (0.0674) |  Loss2: (0.0000) | Acc: (97.00%) (46417/47488)
Epoch: 204 | Batch_idx: 380 |  Loss: (0.0675) |  Loss2: (0.0000) | Acc: (97.00%) (47667/48768)
Epoch: 204 | Batch_idx: 390 |  Loss: (0.0673) |  Loss2: (0.0000) | Acc: (97.00%) (48872/50000)
# TEST : Loss: (0.4217) | Acc: (88.00%) (8899/10000)
percent tensor([0.5631, 0.5763, 0.6036, 0.5964, 0.6060, 0.5717, 0.5865, 0.6030, 0.5767,
        0.5832, 0.5616, 0.5964, 0.5648, 0.5794, 0.5765, 0.5697],
       device='cuda:0') torch.Size([16])
percent tensor([0.5784, 0.5820, 0.5764, 0.5701, 0.5810, 0.5766, 0.5870, 0.5798, 0.5741,
        0.5807, 0.5807, 0.5865, 0.5779, 0.5755, 0.5848, 0.5796],
       device='cuda:0') torch.Size([16])
percent tensor([0.6269, 0.6536, 0.5794, 0.5560, 0.5530, 0.5857, 0.6243, 0.5763, 0.6076,
        0.6508, 0.6365, 0.6115, 0.6678, 0.6345, 0.6207, 0.6339],
       device='cuda:0') torch.Size([16])
percent tensor([0.6823, 0.6715, 0.6466, 0.6446, 0.6499, 0.6924, 0.6827, 0.6458, 0.6637,
        0.6755, 0.6819, 0.6605, 0.6780, 0.6718, 0.6829, 0.6850],
       device='cuda:0') torch.Size([16])
percent tensor([0.5699, 0.5308, 0.6528, 0.6716, 0.6835, 0.6122, 0.6066, 0.6552, 0.6278,
        0.5527, 0.6069, 0.6051, 0.4675, 0.6627, 0.6242, 0.6023],
       device='cuda:0') torch.Size([16])
percent tensor([0.5581, 0.7073, 0.6595, 0.6597, 0.6507, 0.7240, 0.6911, 0.6043, 0.6924,
        0.6478, 0.7280, 0.6800, 0.7278, 0.7095, 0.5060, 0.5011],
       device='cuda:0') torch.Size([16])
percent tensor([0.6958, 0.7453, 0.7078, 0.6638, 0.6606, 0.7231, 0.7541, 0.6554, 0.6859,
        0.7214, 0.7203, 0.6212, 0.7621, 0.7312, 0.5553, 0.6306],
       device='cuda:0') torch.Size([16])
percent tensor([0.9998, 0.9998, 0.9999, 0.9998, 0.9997, 0.9997, 0.9999, 1.0000, 0.9999,
        0.9999, 1.0000, 0.9998, 0.9999, 0.9998, 0.9999, 0.9993],
       device='cuda:0') torch.Size([16])
Epoch: 205 | Batch_idx: 0 |  Loss: (0.0572) |  Loss2: (0.0000) | Acc: (98.00%) (126/128)
Epoch: 205 | Batch_idx: 10 |  Loss: (0.0793) |  Loss2: (0.0000) | Acc: (97.00%) (1373/1408)
Epoch: 205 | Batch_idx: 20 |  Loss: (0.0783) |  Loss2: (0.0000) | Acc: (97.00%) (2618/2688)
Epoch: 205 | Batch_idx: 30 |  Loss: (0.0773) |  Loss2: (0.0000) | Acc: (97.00%) (3866/3968)
Epoch: 205 | Batch_idx: 40 |  Loss: (0.0770) |  Loss2: (0.0000) | Acc: (97.00%) (5116/5248)
Epoch: 205 | Batch_idx: 50 |  Loss: (0.0749) |  Loss2: (0.0000) | Acc: (97.00%) (6369/6528)
Epoch: 205 | Batch_idx: 60 |  Loss: (0.0747) |  Loss2: (0.0000) | Acc: (97.00%) (7623/7808)
Epoch: 205 | Batch_idx: 70 |  Loss: (0.0745) |  Loss2: (0.0000) | Acc: (97.00%) (8873/9088)
Epoch: 205 | Batch_idx: 80 |  Loss: (0.0747) |  Loss2: (0.0000) | Acc: (97.00%) (10120/10368)
Epoch: 205 | Batch_idx: 90 |  Loss: (0.0759) |  Loss2: (0.0000) | Acc: (97.00%) (11358/11648)
Epoch: 205 | Batch_idx: 100 |  Loss: (0.0754) |  Loss2: (0.0000) | Acc: (97.00%) (12609/12928)
Epoch: 205 | Batch_idx: 110 |  Loss: (0.0746) |  Loss2: (0.0000) | Acc: (97.00%) (13860/14208)
Epoch: 205 | Batch_idx: 120 |  Loss: (0.0739) |  Loss2: (0.0000) | Acc: (97.00%) (15114/15488)
Epoch: 205 | Batch_idx: 130 |  Loss: (0.0737) |  Loss2: (0.0000) | Acc: (97.00%) (16365/16768)
Epoch: 205 | Batch_idx: 140 |  Loss: (0.0735) |  Loss2: (0.0000) | Acc: (97.00%) (17619/18048)
Epoch: 205 | Batch_idx: 150 |  Loss: (0.0744) |  Loss2: (0.0000) | Acc: (97.00%) (18866/19328)
Epoch: 205 | Batch_idx: 160 |  Loss: (0.0736) |  Loss2: (0.0000) | Acc: (97.00%) (20122/20608)
Epoch: 205 | Batch_idx: 170 |  Loss: (0.0732) |  Loss2: (0.0000) | Acc: (97.00%) (21369/21888)
Epoch: 205 | Batch_idx: 180 |  Loss: (0.0729) |  Loss2: (0.0000) | Acc: (97.00%) (22618/23168)
Epoch: 205 | Batch_idx: 190 |  Loss: (0.0723) |  Loss2: (0.0000) | Acc: (97.00%) (23874/24448)
Epoch: 205 | Batch_idx: 200 |  Loss: (0.0723) |  Loss2: (0.0000) | Acc: (97.00%) (25125/25728)
Epoch: 205 | Batch_idx: 210 |  Loss: (0.0722) |  Loss2: (0.0000) | Acc: (97.00%) (26376/27008)
Epoch: 205 | Batch_idx: 220 |  Loss: (0.0713) |  Loss2: (0.0000) | Acc: (97.00%) (27639/28288)
Epoch: 205 | Batch_idx: 230 |  Loss: (0.0710) |  Loss2: (0.0000) | Acc: (97.00%) (28895/29568)
Epoch: 205 | Batch_idx: 240 |  Loss: (0.0709) |  Loss2: (0.0000) | Acc: (97.00%) (30146/30848)
Epoch: 205 | Batch_idx: 250 |  Loss: (0.0709) |  Loss2: (0.0000) | Acc: (97.00%) (31391/32128)
Epoch: 205 | Batch_idx: 260 |  Loss: (0.0705) |  Loss2: (0.0000) | Acc: (97.00%) (32651/33408)
Epoch: 205 | Batch_idx: 270 |  Loss: (0.0704) |  Loss2: (0.0000) | Acc: (97.00%) (33905/34688)
Epoch: 205 | Batch_idx: 280 |  Loss: (0.0700) |  Loss2: (0.0000) | Acc: (97.00%) (35153/35968)
Epoch: 205 | Batch_idx: 290 |  Loss: (0.0698) |  Loss2: (0.0000) | Acc: (97.00%) (36405/37248)
Epoch: 205 | Batch_idx: 300 |  Loss: (0.0696) |  Loss2: (0.0000) | Acc: (97.00%) (37655/38528)
Epoch: 205 | Batch_idx: 310 |  Loss: (0.0698) |  Loss2: (0.0000) | Acc: (97.00%) (38898/39808)
Epoch: 205 | Batch_idx: 320 |  Loss: (0.0697) |  Loss2: (0.0000) | Acc: (97.00%) (40149/41088)
Epoch: 205 | Batch_idx: 330 |  Loss: (0.0701) |  Loss2: (0.0000) | Acc: (97.00%) (41385/42368)
Epoch: 205 | Batch_idx: 340 |  Loss: (0.0704) |  Loss2: (0.0000) | Acc: (97.00%) (42630/43648)
Epoch: 205 | Batch_idx: 350 |  Loss: (0.0701) |  Loss2: (0.0000) | Acc: (97.00%) (43889/44928)
Epoch: 205 | Batch_idx: 360 |  Loss: (0.0698) |  Loss2: (0.0000) | Acc: (97.00%) (45144/46208)
Epoch: 205 | Batch_idx: 370 |  Loss: (0.0699) |  Loss2: (0.0000) | Acc: (97.00%) (46391/47488)
Epoch: 205 | Batch_idx: 380 |  Loss: (0.0699) |  Loss2: (0.0000) | Acc: (97.00%) (47643/48768)
Epoch: 205 | Batch_idx: 390 |  Loss: (0.0697) |  Loss2: (0.0000) | Acc: (97.00%) (48849/50000)
=> saving checkpoint 'drive/app/torch/save_Schedule/checkpoint_205.pth.tar'
# TEST : Loss: (0.5042) | Acc: (87.00%) (8719/10000)
percent tensor([0.5665, 0.5808, 0.6059, 0.5996, 0.6085, 0.5742, 0.5907, 0.6055, 0.5776,
        0.5871, 0.5640, 0.5997, 0.5678, 0.5833, 0.5799, 0.5728],
       device='cuda:0') torch.Size([16])
percent tensor([0.5781, 0.5838, 0.5726, 0.5712, 0.5793, 0.5779, 0.5880, 0.5787, 0.5744,
        0.5806, 0.5804, 0.5845, 0.5778, 0.5804, 0.5858, 0.5804],
       device='cuda:0') torch.Size([16])
percent tensor([0.6267, 0.6548, 0.5811, 0.5494, 0.5557, 0.5774, 0.6277, 0.5787, 0.6113,
        0.6511, 0.6369, 0.6113, 0.6669, 0.6387, 0.6167, 0.6323],
       device='cuda:0') torch.Size([16])
percent tensor([0.6784, 0.6685, 0.6384, 0.6413, 0.6461, 0.6885, 0.6777, 0.6435, 0.6614,
        0.6706, 0.6769, 0.6568, 0.6747, 0.6689, 0.6792, 0.6784],
       device='cuda:0') torch.Size([16])
percent tensor([0.5782, 0.5161, 0.6300, 0.6642, 0.6794, 0.6283, 0.5840, 0.6494, 0.6142,
        0.5407, 0.5859, 0.5916, 0.4660, 0.6389, 0.6193, 0.5995],
       device='cuda:0') torch.Size([16])
percent tensor([0.5305, 0.6774, 0.6671, 0.6220, 0.6395, 0.7115, 0.6681, 0.5687, 0.6684,
        0.6094, 0.7049, 0.6574, 0.7163, 0.6840, 0.4546, 0.4666],
       device='cuda:0') torch.Size([16])
percent tensor([0.6932, 0.7354, 0.7156, 0.6691, 0.6457, 0.7335, 0.7507, 0.6531, 0.7007,
        0.7280, 0.7260, 0.6102, 0.7697, 0.7219, 0.5532, 0.6274],
       device='cuda:0') torch.Size([16])
percent tensor([0.9998, 0.9999, 0.9997, 0.9999, 0.9997, 0.9996, 0.9999, 0.9999, 0.9999,
        0.9999, 1.0000, 0.9997, 0.9999, 0.9998, 0.9998, 0.9993],
       device='cuda:0') torch.Size([16])
Epoch: 206 | Batch_idx: 0 |  Loss: (0.0433) |  Loss2: (0.0000) | Acc: (99.00%) (127/128)
Epoch: 206 | Batch_idx: 10 |  Loss: (0.0574) |  Loss2: (0.0000) | Acc: (98.00%) (1388/1408)
Epoch: 206 | Batch_idx: 20 |  Loss: (0.0497) |  Loss2: (0.0000) | Acc: (98.00%) (2656/2688)
Epoch: 206 | Batch_idx: 30 |  Loss: (0.0542) |  Loss2: (0.0000) | Acc: (98.00%) (3909/3968)
Epoch: 206 | Batch_idx: 40 |  Loss: (0.0556) |  Loss2: (0.0000) | Acc: (98.00%) (5169/5248)
Epoch: 206 | Batch_idx: 50 |  Loss: (0.0542) |  Loss2: (0.0000) | Acc: (98.00%) (6432/6528)
Epoch: 206 | Batch_idx: 60 |  Loss: (0.0540) |  Loss2: (0.0000) | Acc: (98.00%) (7689/7808)
Epoch: 206 | Batch_idx: 70 |  Loss: (0.0571) |  Loss2: (0.0000) | Acc: (98.00%) (8937/9088)
Epoch: 206 | Batch_idx: 80 |  Loss: (0.0580) |  Loss2: (0.0000) | Acc: (98.00%) (10190/10368)
Epoch: 206 | Batch_idx: 90 |  Loss: (0.0587) |  Loss2: (0.0000) | Acc: (98.00%) (11442/11648)
Epoch: 206 | Batch_idx: 100 |  Loss: (0.0592) |  Loss2: (0.0000) | Acc: (98.00%) (12692/12928)
Epoch: 206 | Batch_idx: 110 |  Loss: (0.0602) |  Loss2: (0.0000) | Acc: (98.00%) (13942/14208)
Epoch: 206 | Batch_idx: 120 |  Loss: (0.0619) |  Loss2: (0.0000) | Acc: (98.00%) (15190/15488)
Epoch: 206 | Batch_idx: 130 |  Loss: (0.0621) |  Loss2: (0.0000) | Acc: (98.00%) (16444/16768)
Epoch: 206 | Batch_idx: 140 |  Loss: (0.0625) |  Loss2: (0.0000) | Acc: (98.00%) (17698/18048)
Epoch: 206 | Batch_idx: 150 |  Loss: (0.0622) |  Loss2: (0.0000) | Acc: (98.00%) (18954/19328)
Epoch: 206 | Batch_idx: 160 |  Loss: (0.0628) |  Loss2: (0.0000) | Acc: (98.00%) (20200/20608)
Epoch: 206 | Batch_idx: 170 |  Loss: (0.0628) |  Loss2: (0.0000) | Acc: (98.00%) (21454/21888)
Epoch: 206 | Batch_idx: 180 |  Loss: (0.0636) |  Loss2: (0.0000) | Acc: (97.00%) (22700/23168)
Epoch: 206 | Batch_idx: 190 |  Loss: (0.0637) |  Loss2: (0.0000) | Acc: (97.00%) (23952/24448)
Epoch: 206 | Batch_idx: 200 |  Loss: (0.0635) |  Loss2: (0.0000) | Acc: (97.00%) (25209/25728)
Epoch: 206 | Batch_idx: 210 |  Loss: (0.0632) |  Loss2: (0.0000) | Acc: (97.00%) (26464/27008)
Epoch: 206 | Batch_idx: 220 |  Loss: (0.0631) |  Loss2: (0.0000) | Acc: (97.00%) (27719/28288)
Epoch: 206 | Batch_idx: 230 |  Loss: (0.0631) |  Loss2: (0.0000) | Acc: (97.00%) (28967/29568)
Epoch: 206 | Batch_idx: 240 |  Loss: (0.0628) |  Loss2: (0.0000) | Acc: (97.00%) (30225/30848)
Epoch: 206 | Batch_idx: 250 |  Loss: (0.0629) |  Loss2: (0.0000) | Acc: (97.00%) (31472/32128)
Epoch: 206 | Batch_idx: 260 |  Loss: (0.0631) |  Loss2: (0.0000) | Acc: (97.00%) (32725/33408)
Epoch: 206 | Batch_idx: 270 |  Loss: (0.0633) |  Loss2: (0.0000) | Acc: (97.00%) (33977/34688)
Epoch: 206 | Batch_idx: 280 |  Loss: (0.0637) |  Loss2: (0.0000) | Acc: (97.00%) (35233/35968)
Epoch: 206 | Batch_idx: 290 |  Loss: (0.0637) |  Loss2: (0.0000) | Acc: (97.00%) (36482/37248)
Epoch: 206 | Batch_idx: 300 |  Loss: (0.0635) |  Loss2: (0.0000) | Acc: (97.00%) (37740/38528)
Epoch: 206 | Batch_idx: 310 |  Loss: (0.0636) |  Loss2: (0.0000) | Acc: (97.00%) (38994/39808)
Epoch: 206 | Batch_idx: 320 |  Loss: (0.0638) |  Loss2: (0.0000) | Acc: (97.00%) (40239/41088)
Epoch: 206 | Batch_idx: 330 |  Loss: (0.0641) |  Loss2: (0.0000) | Acc: (97.00%) (41486/42368)
Epoch: 206 | Batch_idx: 340 |  Loss: (0.0640) |  Loss2: (0.0000) | Acc: (97.00%) (42739/43648)
Epoch: 206 | Batch_idx: 350 |  Loss: (0.0642) |  Loss2: (0.0000) | Acc: (97.00%) (43989/44928)
Epoch: 206 | Batch_idx: 360 |  Loss: (0.0645) |  Loss2: (0.0000) | Acc: (97.00%) (45239/46208)
Epoch: 206 | Batch_idx: 370 |  Loss: (0.0646) |  Loss2: (0.0000) | Acc: (97.00%) (46487/47488)
Epoch: 206 | Batch_idx: 380 |  Loss: (0.0648) |  Loss2: (0.0000) | Acc: (97.00%) (47742/48768)
Epoch: 206 | Batch_idx: 390 |  Loss: (0.0653) |  Loss2: (0.0000) | Acc: (97.00%) (48937/50000)
# TEST : Loss: (0.4570) | Acc: (88.00%) (8829/10000)
percent tensor([0.5671, 0.5824, 0.6062, 0.6013, 0.6089, 0.5746, 0.5910, 0.6077, 0.5795,
        0.5881, 0.5655, 0.5993, 0.5691, 0.5855, 0.5807, 0.5742],
       device='cuda:0') torch.Size([16])
percent tensor([0.5794, 0.5842, 0.5735, 0.5700, 0.5800, 0.5785, 0.5886, 0.5791, 0.5761,
        0.5812, 0.5822, 0.5855, 0.5786, 0.5811, 0.5857, 0.5811],
       device='cuda:0') torch.Size([16])
percent tensor([0.6270, 0.6465, 0.5859, 0.5607, 0.5568, 0.5812, 0.6212, 0.5803, 0.6091,
        0.6472, 0.6322, 0.6131, 0.6649, 0.6306, 0.6155, 0.6326],
       device='cuda:0') torch.Size([16])
percent tensor([0.6872, 0.6778, 0.6456, 0.6425, 0.6528, 0.6940, 0.6895, 0.6502, 0.6718,
        0.6789, 0.6843, 0.6659, 0.6848, 0.6803, 0.6858, 0.6848],
       device='cuda:0') torch.Size([16])
percent tensor([0.5689, 0.5061, 0.6339, 0.6643, 0.6806, 0.6145, 0.5786, 0.6517, 0.6080,
        0.5287, 0.5733, 0.5815, 0.4421, 0.6212, 0.6059, 0.5811],
       device='cuda:0') torch.Size([16])
percent tensor([0.5382, 0.7146, 0.6674, 0.6388, 0.6344, 0.7172, 0.6738, 0.5513, 0.6815,
        0.6411, 0.7180, 0.6696, 0.7278, 0.7029, 0.4905, 0.4998],
       device='cuda:0') torch.Size([16])
percent tensor([0.6922, 0.7489, 0.7139, 0.6484, 0.6384, 0.7261, 0.7203, 0.6317, 0.6713,
        0.7309, 0.7138, 0.6127, 0.7531, 0.7101, 0.5513, 0.6134],
       device='cuda:0') torch.Size([16])
percent tensor([0.9998, 0.9998, 0.9998, 0.9998, 0.9997, 0.9999, 0.9999, 0.9998, 0.9999,
        0.9999, 0.9999, 0.9997, 0.9998, 0.9998, 0.9998, 0.9994],
       device='cuda:0') torch.Size([16])
Epoch: 207 | Batch_idx: 0 |  Loss: (0.0557) |  Loss2: (0.0000) | Acc: (96.00%) (124/128)
Epoch: 207 | Batch_idx: 10 |  Loss: (0.0571) |  Loss2: (0.0000) | Acc: (98.00%) (1386/1408)
Epoch: 207 | Batch_idx: 20 |  Loss: (0.0619) |  Loss2: (0.0000) | Acc: (97.00%) (2634/2688)
Epoch: 207 | Batch_idx: 30 |  Loss: (0.0633) |  Loss2: (0.0000) | Acc: (97.00%) (3886/3968)
Epoch: 207 | Batch_idx: 40 |  Loss: (0.0613) |  Loss2: (0.0000) | Acc: (97.00%) (5142/5248)
Epoch: 207 | Batch_idx: 50 |  Loss: (0.0606) |  Loss2: (0.0000) | Acc: (98.00%) (6402/6528)
Epoch: 207 | Batch_idx: 60 |  Loss: (0.0621) |  Loss2: (0.0000) | Acc: (98.00%) (7654/7808)
Epoch: 207 | Batch_idx: 70 |  Loss: (0.0623) |  Loss2: (0.0000) | Acc: (98.00%) (8907/9088)
Epoch: 207 | Batch_idx: 80 |  Loss: (0.0608) |  Loss2: (0.0000) | Acc: (98.00%) (10168/10368)
Epoch: 207 | Batch_idx: 90 |  Loss: (0.0603) |  Loss2: (0.0000) | Acc: (98.00%) (11423/11648)
Epoch: 207 | Batch_idx: 100 |  Loss: (0.0610) |  Loss2: (0.0000) | Acc: (98.00%) (12671/12928)
Epoch: 207 | Batch_idx: 110 |  Loss: (0.0613) |  Loss2: (0.0000) | Acc: (97.00%) (13923/14208)
Epoch: 207 | Batch_idx: 120 |  Loss: (0.0625) |  Loss2: (0.0000) | Acc: (97.00%) (15172/15488)
Epoch: 207 | Batch_idx: 130 |  Loss: (0.0624) |  Loss2: (0.0000) | Acc: (97.00%) (16428/16768)
Epoch: 207 | Batch_idx: 140 |  Loss: (0.0628) |  Loss2: (0.0000) | Acc: (97.00%) (17679/18048)
Epoch: 207 | Batch_idx: 150 |  Loss: (0.0629) |  Loss2: (0.0000) | Acc: (97.00%) (18932/19328)
Epoch: 207 | Batch_idx: 160 |  Loss: (0.0623) |  Loss2: (0.0000) | Acc: (97.00%) (20193/20608)
Epoch: 207 | Batch_idx: 170 |  Loss: (0.0630) |  Loss2: (0.0000) | Acc: (97.00%) (21439/21888)
Epoch: 207 | Batch_idx: 180 |  Loss: (0.0627) |  Loss2: (0.0000) | Acc: (97.00%) (22692/23168)
Epoch: 207 | Batch_idx: 190 |  Loss: (0.0620) |  Loss2: (0.0000) | Acc: (97.00%) (23952/24448)
Epoch: 207 | Batch_idx: 200 |  Loss: (0.0622) |  Loss2: (0.0000) | Acc: (97.00%) (25202/25728)
Epoch: 207 | Batch_idx: 210 |  Loss: (0.0625) |  Loss2: (0.0000) | Acc: (97.00%) (26448/27008)
Epoch: 207 | Batch_idx: 220 |  Loss: (0.0617) |  Loss2: (0.0000) | Acc: (97.00%) (27711/28288)
Epoch: 207 | Batch_idx: 230 |  Loss: (0.0617) |  Loss2: (0.0000) | Acc: (97.00%) (28959/29568)
Epoch: 207 | Batch_idx: 240 |  Loss: (0.0624) |  Loss2: (0.0000) | Acc: (97.00%) (30200/30848)
Epoch: 207 | Batch_idx: 250 |  Loss: (0.0628) |  Loss2: (0.0000) | Acc: (97.00%) (31448/32128)
Epoch: 207 | Batch_idx: 260 |  Loss: (0.0632) |  Loss2: (0.0000) | Acc: (97.00%) (32702/33408)
Epoch: 207 | Batch_idx: 270 |  Loss: (0.0639) |  Loss2: (0.0000) | Acc: (97.00%) (33947/34688)
Epoch: 207 | Batch_idx: 280 |  Loss: (0.0642) |  Loss2: (0.0000) | Acc: (97.00%) (35202/35968)
Epoch: 207 | Batch_idx: 290 |  Loss: (0.0644) |  Loss2: (0.0000) | Acc: (97.00%) (36448/37248)
Epoch: 207 | Batch_idx: 300 |  Loss: (0.0647) |  Loss2: (0.0000) | Acc: (97.00%) (37700/38528)
Epoch: 207 | Batch_idx: 310 |  Loss: (0.0648) |  Loss2: (0.0000) | Acc: (97.00%) (38949/39808)
Epoch: 207 | Batch_idx: 320 |  Loss: (0.0654) |  Loss2: (0.0000) | Acc: (97.00%) (40198/41088)
Epoch: 207 | Batch_idx: 330 |  Loss: (0.0657) |  Loss2: (0.0000) | Acc: (97.00%) (41444/42368)
Epoch: 207 | Batch_idx: 340 |  Loss: (0.0660) |  Loss2: (0.0000) | Acc: (97.00%) (42683/43648)
Epoch: 207 | Batch_idx: 350 |  Loss: (0.0661) |  Loss2: (0.0000) | Acc: (97.00%) (43927/44928)
Epoch: 207 | Batch_idx: 360 |  Loss: (0.0661) |  Loss2: (0.0000) | Acc: (97.00%) (45184/46208)
Epoch: 207 | Batch_idx: 370 |  Loss: (0.0666) |  Loss2: (0.0000) | Acc: (97.00%) (46422/47488)
Epoch: 207 | Batch_idx: 380 |  Loss: (0.0665) |  Loss2: (0.0000) | Acc: (97.00%) (47672/48768)
Epoch: 207 | Batch_idx: 390 |  Loss: (0.0667) |  Loss2: (0.0000) | Acc: (97.00%) (48871/50000)
# TEST : Loss: (0.4437) | Acc: (88.00%) (8850/10000)
percent tensor([0.5690, 0.5846, 0.6100, 0.6048, 0.6114, 0.5768, 0.5936, 0.6110, 0.5813,
        0.5906, 0.5669, 0.6028, 0.5706, 0.5865, 0.5837, 0.5764],
       device='cuda:0') torch.Size([16])
percent tensor([0.5800, 0.5849, 0.5732, 0.5697, 0.5801, 0.5783, 0.5882, 0.5801, 0.5750,
        0.5817, 0.5818, 0.5845, 0.5788, 0.5790, 0.5865, 0.5819],
       device='cuda:0') torch.Size([16])
percent tensor([0.6285, 0.6467, 0.5841, 0.5606, 0.5603, 0.5865, 0.6217, 0.5742, 0.6081,
        0.6448, 0.6345, 0.6121, 0.6644, 0.6281, 0.6163, 0.6349],
       device='cuda:0') torch.Size([16])
percent tensor([0.6851, 0.6768, 0.6413, 0.6453, 0.6508, 0.6930, 0.6858, 0.6448, 0.6678,
        0.6783, 0.6823, 0.6623, 0.6832, 0.6776, 0.6868, 0.6864],
       device='cuda:0') torch.Size([16])
percent tensor([0.5777, 0.5217, 0.6473, 0.6741, 0.6800, 0.6150, 0.5894, 0.6583, 0.6396,
        0.5478, 0.5940, 0.6022, 0.4804, 0.6499, 0.6155, 0.5975],
       device='cuda:0') torch.Size([16])
percent tensor([0.5570, 0.7163, 0.6723, 0.6652, 0.6260, 0.7208, 0.6823, 0.5530, 0.7065,
        0.6533, 0.7507, 0.6736, 0.7385, 0.7216, 0.5085, 0.4857],
       device='cuda:0') torch.Size([16])
percent tensor([0.6894, 0.7496, 0.7023, 0.6531, 0.6295, 0.7217, 0.7362, 0.6475, 0.6976,
        0.7211, 0.7206, 0.6403, 0.7667, 0.7077, 0.5508, 0.6089],
       device='cuda:0') torch.Size([16])
percent tensor([0.9996, 0.9998, 0.9998, 0.9998, 0.9997, 0.9998, 0.9998, 0.9999, 1.0000,
        0.9999, 1.0000, 0.9997, 0.9999, 0.9997, 0.9999, 0.9993],
       device='cuda:0') torch.Size([16])
Epoch: 208 | Batch_idx: 0 |  Loss: (0.0440) |  Loss2: (0.0000) | Acc: (99.00%) (127/128)
Epoch: 208 | Batch_idx: 10 |  Loss: (0.0531) |  Loss2: (0.0000) | Acc: (98.00%) (1387/1408)
Epoch: 208 | Batch_idx: 20 |  Loss: (0.0562) |  Loss2: (0.0000) | Acc: (98.00%) (2638/2688)
Epoch: 208 | Batch_idx: 30 |  Loss: (0.0591) |  Loss2: (0.0000) | Acc: (98.00%) (3890/3968)
Epoch: 208 | Batch_idx: 40 |  Loss: (0.0601) |  Loss2: (0.0000) | Acc: (98.00%) (5144/5248)
Epoch: 208 | Batch_idx: 50 |  Loss: (0.0590) |  Loss2: (0.0000) | Acc: (98.00%) (6400/6528)
Epoch: 208 | Batch_idx: 60 |  Loss: (0.0621) |  Loss2: (0.0000) | Acc: (97.00%) (7645/7808)
Epoch: 208 | Batch_idx: 70 |  Loss: (0.0617) |  Loss2: (0.0000) | Acc: (97.00%) (8898/9088)
Epoch: 208 | Batch_idx: 80 |  Loss: (0.0624) |  Loss2: (0.0000) | Acc: (97.00%) (10148/10368)
Epoch: 208 | Batch_idx: 90 |  Loss: (0.0621) |  Loss2: (0.0000) | Acc: (97.00%) (11401/11648)
Epoch: 208 | Batch_idx: 100 |  Loss: (0.0620) |  Loss2: (0.0000) | Acc: (97.00%) (12654/12928)
Epoch: 208 | Batch_idx: 110 |  Loss: (0.0615) |  Loss2: (0.0000) | Acc: (97.00%) (13907/14208)
Epoch: 208 | Batch_idx: 120 |  Loss: (0.0609) |  Loss2: (0.0000) | Acc: (97.00%) (15169/15488)
Epoch: 208 | Batch_idx: 130 |  Loss: (0.0622) |  Loss2: (0.0000) | Acc: (97.00%) (16417/16768)
Epoch: 208 | Batch_idx: 140 |  Loss: (0.0611) |  Loss2: (0.0000) | Acc: (97.00%) (17679/18048)
Epoch: 208 | Batch_idx: 150 |  Loss: (0.0615) |  Loss2: (0.0000) | Acc: (97.00%) (18934/19328)
Epoch: 208 | Batch_idx: 160 |  Loss: (0.0615) |  Loss2: (0.0000) | Acc: (97.00%) (20189/20608)
Epoch: 208 | Batch_idx: 170 |  Loss: (0.0616) |  Loss2: (0.0000) | Acc: (97.00%) (21443/21888)
Epoch: 208 | Batch_idx: 180 |  Loss: (0.0619) |  Loss2: (0.0000) | Acc: (97.00%) (22690/23168)
Epoch: 208 | Batch_idx: 190 |  Loss: (0.0619) |  Loss2: (0.0000) | Acc: (97.00%) (23944/24448)
Epoch: 208 | Batch_idx: 200 |  Loss: (0.0622) |  Loss2: (0.0000) | Acc: (97.00%) (25187/25728)
Epoch: 208 | Batch_idx: 210 |  Loss: (0.0617) |  Loss2: (0.0000) | Acc: (97.00%) (26443/27008)
Epoch: 208 | Batch_idx: 220 |  Loss: (0.0621) |  Loss2: (0.0000) | Acc: (97.00%) (27695/28288)
Epoch: 208 | Batch_idx: 230 |  Loss: (0.0622) |  Loss2: (0.0000) | Acc: (97.00%) (28945/29568)
Epoch: 208 | Batch_idx: 240 |  Loss: (0.0622) |  Loss2: (0.0000) | Acc: (97.00%) (30201/30848)
Epoch: 208 | Batch_idx: 250 |  Loss: (0.0620) |  Loss2: (0.0000) | Acc: (97.00%) (31460/32128)
Epoch: 208 | Batch_idx: 260 |  Loss: (0.0616) |  Loss2: (0.0000) | Acc: (97.00%) (32719/33408)
Epoch: 208 | Batch_idx: 270 |  Loss: (0.0613) |  Loss2: (0.0000) | Acc: (97.00%) (33977/34688)
Epoch: 208 | Batch_idx: 280 |  Loss: (0.0611) |  Loss2: (0.0000) | Acc: (97.00%) (35233/35968)
Epoch: 208 | Batch_idx: 290 |  Loss: (0.0612) |  Loss2: (0.0000) | Acc: (97.00%) (36483/37248)
Epoch: 208 | Batch_idx: 300 |  Loss: (0.0612) |  Loss2: (0.0000) | Acc: (97.00%) (37736/38528)
Epoch: 208 | Batch_idx: 310 |  Loss: (0.0614) |  Loss2: (0.0000) | Acc: (97.00%) (38985/39808)
Epoch: 208 | Batch_idx: 320 |  Loss: (0.0614) |  Loss2: (0.0000) | Acc: (97.00%) (40232/41088)
Epoch: 208 | Batch_idx: 330 |  Loss: (0.0614) |  Loss2: (0.0000) | Acc: (97.00%) (41487/42368)
Epoch: 208 | Batch_idx: 340 |  Loss: (0.0609) |  Loss2: (0.0000) | Acc: (97.00%) (42749/43648)
Epoch: 208 | Batch_idx: 350 |  Loss: (0.0608) |  Loss2: (0.0000) | Acc: (97.00%) (44007/44928)
Epoch: 208 | Batch_idx: 360 |  Loss: (0.0608) |  Loss2: (0.0000) | Acc: (97.00%) (45260/46208)
Epoch: 208 | Batch_idx: 370 |  Loss: (0.0610) |  Loss2: (0.0000) | Acc: (97.00%) (46512/47488)
Epoch: 208 | Batch_idx: 380 |  Loss: (0.0611) |  Loss2: (0.0000) | Acc: (97.00%) (47762/48768)
Epoch: 208 | Batch_idx: 390 |  Loss: (0.0615) |  Loss2: (0.0000) | Acc: (97.00%) (48963/50000)
# TEST : Loss: (0.4634) | Acc: (87.00%) (8798/10000)
percent tensor([0.5687, 0.5823, 0.6093, 0.6022, 0.6120, 0.5765, 0.5926, 0.6083, 0.5813,
        0.5894, 0.5659, 0.6023, 0.5706, 0.5846, 0.5822, 0.5752],
       device='cuda:0') torch.Size([16])
percent tensor([0.5811, 0.5857, 0.5745, 0.5707, 0.5819, 0.5795, 0.5901, 0.5809, 0.5764,
        0.5825, 0.5839, 0.5871, 0.5806, 0.5801, 0.5879, 0.5826],
       device='cuda:0') torch.Size([16])
percent tensor([0.6311, 0.6544, 0.5911, 0.5613, 0.5623, 0.5847, 0.6272, 0.5822, 0.6121,
        0.6542, 0.6392, 0.6196, 0.6678, 0.6344, 0.6204, 0.6370],
       device='cuda:0') torch.Size([16])
percent tensor([0.6867, 0.6743, 0.6476, 0.6480, 0.6566, 0.6984, 0.6877, 0.6518, 0.6701,
        0.6767, 0.6816, 0.6657, 0.6819, 0.6753, 0.6881, 0.6866],
       device='cuda:0') torch.Size([16])
percent tensor([0.5703, 0.5222, 0.6399, 0.6664, 0.6793, 0.6205, 0.5887, 0.6486, 0.6277,
        0.5289, 0.5671, 0.5986, 0.4678, 0.6490, 0.6171, 0.5922],
       device='cuda:0') torch.Size([16])
percent tensor([0.5648, 0.7148, 0.6771, 0.6794, 0.6572, 0.7353, 0.6736, 0.5767, 0.7020,
        0.6411, 0.7463, 0.6649, 0.7251, 0.7136, 0.5171, 0.5020],
       device='cuda:0') torch.Size([16])
percent tensor([0.6870, 0.7393, 0.7074, 0.6451, 0.6430, 0.7285, 0.7361, 0.6320, 0.6720,
        0.7089, 0.7099, 0.5828, 0.7557, 0.7062, 0.5257, 0.6171],
       device='cuda:0') torch.Size([16])
percent tensor([0.9998, 0.9999, 0.9999, 0.9998, 0.9997, 0.9998, 0.9999, 0.9999, 0.9999,
        0.9999, 0.9999, 0.9998, 0.9998, 0.9997, 0.9999, 0.9994],
       device='cuda:0') torch.Size([16])
Epoch: 209 | Batch_idx: 0 |  Loss: (0.0519) |  Loss2: (0.0000) | Acc: (98.00%) (126/128)
Epoch: 209 | Batch_idx: 10 |  Loss: (0.0586) |  Loss2: (0.0000) | Acc: (97.00%) (1378/1408)
Epoch: 209 | Batch_idx: 20 |  Loss: (0.0599) |  Loss2: (0.0000) | Acc: (98.00%) (2637/2688)
Epoch: 209 | Batch_idx: 30 |  Loss: (0.0578) |  Loss2: (0.0000) | Acc: (98.00%) (3895/3968)
Epoch: 209 | Batch_idx: 40 |  Loss: (0.0584) |  Loss2: (0.0000) | Acc: (98.00%) (5152/5248)
Epoch: 209 | Batch_idx: 50 |  Loss: (0.0584) |  Loss2: (0.0000) | Acc: (98.00%) (6408/6528)
Epoch: 209 | Batch_idx: 60 |  Loss: (0.0584) |  Loss2: (0.0000) | Acc: (98.00%) (7663/7808)
Epoch: 209 | Batch_idx: 70 |  Loss: (0.0579) |  Loss2: (0.0000) | Acc: (98.00%) (8919/9088)
Epoch: 209 | Batch_idx: 80 |  Loss: (0.0567) |  Loss2: (0.0000) | Acc: (98.00%) (10183/10368)
Epoch: 209 | Batch_idx: 90 |  Loss: (0.0560) |  Loss2: (0.0000) | Acc: (98.00%) (11442/11648)
Epoch: 209 | Batch_idx: 100 |  Loss: (0.0561) |  Loss2: (0.0000) | Acc: (98.00%) (12699/12928)
Epoch: 209 | Batch_idx: 110 |  Loss: (0.0566) |  Loss2: (0.0000) | Acc: (98.00%) (13953/14208)
Epoch: 209 | Batch_idx: 120 |  Loss: (0.0555) |  Loss2: (0.0000) | Acc: (98.00%) (15218/15488)
Epoch: 209 | Batch_idx: 130 |  Loss: (0.0562) |  Loss2: (0.0000) | Acc: (98.00%) (16470/16768)
Epoch: 209 | Batch_idx: 140 |  Loss: (0.0554) |  Loss2: (0.0000) | Acc: (98.00%) (17737/18048)
Epoch: 209 | Batch_idx: 150 |  Loss: (0.0552) |  Loss2: (0.0000) | Acc: (98.00%) (18999/19328)
Epoch: 209 | Batch_idx: 160 |  Loss: (0.0558) |  Loss2: (0.0000) | Acc: (98.00%) (20250/20608)
Epoch: 209 | Batch_idx: 170 |  Loss: (0.0551) |  Loss2: (0.0000) | Acc: (98.00%) (21514/21888)
Epoch: 209 | Batch_idx: 180 |  Loss: (0.0556) |  Loss2: (0.0000) | Acc: (98.00%) (22765/23168)
Epoch: 209 | Batch_idx: 190 |  Loss: (0.0558) |  Loss2: (0.0000) | Acc: (98.00%) (24021/24448)
Epoch: 209 | Batch_idx: 200 |  Loss: (0.0555) |  Loss2: (0.0000) | Acc: (98.00%) (25287/25728)
Epoch: 209 | Batch_idx: 210 |  Loss: (0.0556) |  Loss2: (0.0000) | Acc: (98.00%) (26546/27008)
Epoch: 209 | Batch_idx: 220 |  Loss: (0.0566) |  Loss2: (0.0000) | Acc: (98.00%) (27789/28288)
Epoch: 209 | Batch_idx: 230 |  Loss: (0.0570) |  Loss2: (0.0000) | Acc: (98.00%) (29039/29568)
Epoch: 209 | Batch_idx: 240 |  Loss: (0.0574) |  Loss2: (0.0000) | Acc: (98.00%) (30293/30848)
Epoch: 209 | Batch_idx: 250 |  Loss: (0.0579) |  Loss2: (0.0000) | Acc: (98.00%) (31542/32128)
Epoch: 209 | Batch_idx: 260 |  Loss: (0.0583) |  Loss2: (0.0000) | Acc: (98.00%) (32789/33408)
Epoch: 209 | Batch_idx: 270 |  Loss: (0.0586) |  Loss2: (0.0000) | Acc: (98.00%) (34037/34688)
Epoch: 209 | Batch_idx: 280 |  Loss: (0.0588) |  Loss2: (0.0000) | Acc: (98.00%) (35288/35968)
Epoch: 209 | Batch_idx: 290 |  Loss: (0.0589) |  Loss2: (0.0000) | Acc: (98.00%) (36539/37248)
Epoch: 209 | Batch_idx: 300 |  Loss: (0.0592) |  Loss2: (0.0000) | Acc: (98.00%) (37788/38528)
Epoch: 209 | Batch_idx: 310 |  Loss: (0.0595) |  Loss2: (0.0000) | Acc: (98.00%) (39035/39808)
Epoch: 209 | Batch_idx: 320 |  Loss: (0.0596) |  Loss2: (0.0000) | Acc: (98.00%) (40291/41088)
Epoch: 209 | Batch_idx: 330 |  Loss: (0.0597) |  Loss2: (0.0000) | Acc: (98.00%) (41546/42368)
Epoch: 209 | Batch_idx: 340 |  Loss: (0.0596) |  Loss2: (0.0000) | Acc: (98.00%) (42801/43648)
Epoch: 209 | Batch_idx: 350 |  Loss: (0.0595) |  Loss2: (0.0000) | Acc: (98.00%) (44059/44928)
Epoch: 209 | Batch_idx: 360 |  Loss: (0.0594) |  Loss2: (0.0000) | Acc: (98.00%) (45320/46208)
Epoch: 209 | Batch_idx: 370 |  Loss: (0.0595) |  Loss2: (0.0000) | Acc: (98.00%) (46569/47488)
Epoch: 209 | Batch_idx: 380 |  Loss: (0.0599) |  Loss2: (0.0000) | Acc: (98.00%) (47818/48768)
Epoch: 209 | Batch_idx: 390 |  Loss: (0.0600) |  Loss2: (0.0000) | Acc: (98.00%) (49022/50000)
# TEST : Loss: (0.4452) | Acc: (88.00%) (8853/10000)
percent tensor([0.5689, 0.5796, 0.6096, 0.6006, 0.6124, 0.5764, 0.5916, 0.6075, 0.5818,
        0.5877, 0.5665, 0.6024, 0.5705, 0.5817, 0.5806, 0.5741],
       device='cuda:0') torch.Size([16])
percent tensor([0.5811, 0.5862, 0.5765, 0.5734, 0.5824, 0.5791, 0.5902, 0.5827, 0.5767,
        0.5828, 0.5830, 0.5875, 0.5803, 0.5810, 0.5882, 0.5820],
       device='cuda:0') torch.Size([16])
percent tensor([0.6389, 0.6598, 0.5892, 0.5579, 0.5641, 0.5890, 0.6324, 0.5838, 0.6181,
        0.6606, 0.6493, 0.6200, 0.6770, 0.6426, 0.6234, 0.6427],
       device='cuda:0') torch.Size([16])
percent tensor([0.6884, 0.6802, 0.6474, 0.6521, 0.6563, 0.7003, 0.6899, 0.6546, 0.6705,
        0.6803, 0.6838, 0.6641, 0.6854, 0.6801, 0.6896, 0.6887],
       device='cuda:0') torch.Size([16])
percent tensor([0.5728, 0.5142, 0.6390, 0.6627, 0.6754, 0.6141, 0.5829, 0.6497, 0.6211,
        0.5358, 0.5674, 0.5985, 0.4697, 0.6428, 0.6139, 0.5907],
       device='cuda:0') torch.Size([16])
percent tensor([0.5516, 0.7368, 0.6687, 0.6426, 0.6417, 0.7350, 0.6891, 0.5904, 0.7057,
        0.6773, 0.7509, 0.6739, 0.7441, 0.7404, 0.5198, 0.5032],
       device='cuda:0') torch.Size([16])
percent tensor([0.6975, 0.7533, 0.7216, 0.6517, 0.6557, 0.7378, 0.7379, 0.6484, 0.6841,
        0.7367, 0.7297, 0.6115, 0.7587, 0.7273, 0.5513, 0.6327],
       device='cuda:0') torch.Size([16])
percent tensor([0.9998, 0.9998, 0.9999, 0.9998, 0.9998, 0.9998, 0.9999, 0.9999, 0.9999,
        0.9999, 1.0000, 0.9998, 0.9999, 0.9997, 0.9998, 0.9994],
       device='cuda:0') torch.Size([16])
Epoch: 210 | Batch_idx: 0 |  Loss: (0.0435) |  Loss2: (0.0000) | Acc: (99.00%) (127/128)
Epoch: 210 | Batch_idx: 10 |  Loss: (0.0488) |  Loss2: (0.0000) | Acc: (98.00%) (1389/1408)
Epoch: 210 | Batch_idx: 20 |  Loss: (0.0542) |  Loss2: (0.0000) | Acc: (98.00%) (2641/2688)
Epoch: 210 | Batch_idx: 30 |  Loss: (0.0566) |  Loss2: (0.0000) | Acc: (98.00%) (3895/3968)
Epoch: 210 | Batch_idx: 40 |  Loss: (0.0557) |  Loss2: (0.0000) | Acc: (98.00%) (5152/5248)
Epoch: 210 | Batch_idx: 50 |  Loss: (0.0552) |  Loss2: (0.0000) | Acc: (98.00%) (6407/6528)
Epoch: 210 | Batch_idx: 60 |  Loss: (0.0538) |  Loss2: (0.0000) | Acc: (98.00%) (7671/7808)
Epoch: 210 | Batch_idx: 70 |  Loss: (0.0537) |  Loss2: (0.0000) | Acc: (98.00%) (8930/9088)
Epoch: 210 | Batch_idx: 80 |  Loss: (0.0541) |  Loss2: (0.0000) | Acc: (98.00%) (10183/10368)
Epoch: 210 | Batch_idx: 90 |  Loss: (0.0545) |  Loss2: (0.0000) | Acc: (98.00%) (11441/11648)
Epoch: 210 | Batch_idx: 100 |  Loss: (0.0551) |  Loss2: (0.0000) | Acc: (98.00%) (12690/12928)
Epoch: 210 | Batch_idx: 110 |  Loss: (0.0550) |  Loss2: (0.0000) | Acc: (98.00%) (13949/14208)
Epoch: 210 | Batch_idx: 120 |  Loss: (0.0553) |  Loss2: (0.0000) | Acc: (98.00%) (15204/15488)
Epoch: 210 | Batch_idx: 130 |  Loss: (0.0552) |  Loss2: (0.0000) | Acc: (98.00%) (16461/16768)
Epoch: 210 | Batch_idx: 140 |  Loss: (0.0545) |  Loss2: (0.0000) | Acc: (98.00%) (17722/18048)
Epoch: 210 | Batch_idx: 150 |  Loss: (0.0550) |  Loss2: (0.0000) | Acc: (98.00%) (18972/19328)
Epoch: 210 | Batch_idx: 160 |  Loss: (0.0550) |  Loss2: (0.0000) | Acc: (98.00%) (20230/20608)
Epoch: 210 | Batch_idx: 170 |  Loss: (0.0547) |  Loss2: (0.0000) | Acc: (98.00%) (21493/21888)
Epoch: 210 | Batch_idx: 180 |  Loss: (0.0551) |  Loss2: (0.0000) | Acc: (98.00%) (22746/23168)
Epoch: 210 | Batch_idx: 190 |  Loss: (0.0559) |  Loss2: (0.0000) | Acc: (98.00%) (23992/24448)
Epoch: 210 | Batch_idx: 200 |  Loss: (0.0558) |  Loss2: (0.0000) | Acc: (98.00%) (25248/25728)
Epoch: 210 | Batch_idx: 210 |  Loss: (0.0565) |  Loss2: (0.0000) | Acc: (98.00%) (26499/27008)
Epoch: 210 | Batch_idx: 220 |  Loss: (0.0565) |  Loss2: (0.0000) | Acc: (98.00%) (27758/28288)
Epoch: 210 | Batch_idx: 230 |  Loss: (0.0563) |  Loss2: (0.0000) | Acc: (98.00%) (29017/29568)
Epoch: 210 | Batch_idx: 240 |  Loss: (0.0562) |  Loss2: (0.0000) | Acc: (98.00%) (30270/30848)
Epoch: 210 | Batch_idx: 250 |  Loss: (0.0564) |  Loss2: (0.0000) | Acc: (98.00%) (31524/32128)
Epoch: 210 | Batch_idx: 260 |  Loss: (0.0570) |  Loss2: (0.0000) | Acc: (98.00%) (32762/33408)
Epoch: 210 | Batch_idx: 270 |  Loss: (0.0568) |  Loss2: (0.0000) | Acc: (98.00%) (34021/34688)
Epoch: 210 | Batch_idx: 280 |  Loss: (0.0566) |  Loss2: (0.0000) | Acc: (98.00%) (35284/35968)
Epoch: 210 | Batch_idx: 290 |  Loss: (0.0563) |  Loss2: (0.0000) | Acc: (98.00%) (36541/37248)
Epoch: 210 | Batch_idx: 300 |  Loss: (0.0563) |  Loss2: (0.0000) | Acc: (98.00%) (37796/38528)
Epoch: 210 | Batch_idx: 310 |  Loss: (0.0563) |  Loss2: (0.0000) | Acc: (98.00%) (39057/39808)
Epoch: 210 | Batch_idx: 320 |  Loss: (0.0561) |  Loss2: (0.0000) | Acc: (98.00%) (40316/41088)
Epoch: 210 | Batch_idx: 330 |  Loss: (0.0564) |  Loss2: (0.0000) | Acc: (98.00%) (41566/42368)
Epoch: 210 | Batch_idx: 340 |  Loss: (0.0565) |  Loss2: (0.0000) | Acc: (98.00%) (42816/43648)
Epoch: 210 | Batch_idx: 350 |  Loss: (0.0568) |  Loss2: (0.0000) | Acc: (98.00%) (44067/44928)
Epoch: 210 | Batch_idx: 360 |  Loss: (0.0567) |  Loss2: (0.0000) | Acc: (98.00%) (45331/46208)
Epoch: 210 | Batch_idx: 370 |  Loss: (0.0566) |  Loss2: (0.0000) | Acc: (98.00%) (46592/47488)
Epoch: 210 | Batch_idx: 380 |  Loss: (0.0568) |  Loss2: (0.0000) | Acc: (98.00%) (47846/48768)
Epoch: 210 | Batch_idx: 390 |  Loss: (0.0568) |  Loss2: (0.0000) | Acc: (98.00%) (49054/50000)
=> saving checkpoint 'drive/app/torch/save_Schedule/checkpoint_210.pth.tar'
# TEST : Loss: (0.4568) | Acc: (88.00%) (8823/10000)
percent tensor([0.5678, 0.5819, 0.6092, 0.6014, 0.6114, 0.5746, 0.5928, 0.6089, 0.5811,
        0.5888, 0.5662, 0.6022, 0.5697, 0.5843, 0.5809, 0.5745],
       device='cuda:0') torch.Size([16])
percent tensor([0.5816, 0.5849, 0.5760, 0.5724, 0.5833, 0.5809, 0.5896, 0.5816, 0.5772,
        0.5819, 0.5831, 0.5870, 0.5804, 0.5800, 0.5877, 0.5826],
       device='cuda:0') torch.Size([16])
percent tensor([0.6351, 0.6545, 0.5909, 0.5606, 0.5629, 0.5874, 0.6261, 0.5826, 0.6124,
        0.6546, 0.6410, 0.6215, 0.6725, 0.6310, 0.6205, 0.6372],
       device='cuda:0') torch.Size([16])
percent tensor([0.6921, 0.6801, 0.6506, 0.6523, 0.6610, 0.7077, 0.6909, 0.6555, 0.6722,
        0.6819, 0.6888, 0.6686, 0.6879, 0.6825, 0.6939, 0.6924],
       device='cuda:0') torch.Size([16])
percent tensor([0.5687, 0.5001, 0.6405, 0.6742, 0.6801, 0.6103, 0.5870, 0.6515, 0.6159,
        0.5335, 0.5697, 0.5833, 0.4583, 0.6380, 0.6053, 0.5929],
       device='cuda:0') torch.Size([16])
percent tensor([0.5674, 0.7361, 0.6843, 0.6666, 0.6581, 0.7473, 0.7128, 0.6178, 0.6960,
        0.6745, 0.7540, 0.7030, 0.7399, 0.7173, 0.5483, 0.5294],
       device='cuda:0') torch.Size([16])
percent tensor([0.7075, 0.7561, 0.7461, 0.6688, 0.6710, 0.7411, 0.7599, 0.6787, 0.7030,
        0.7436, 0.7361, 0.6468, 0.7577, 0.7262, 0.5744, 0.6427],
       device='cuda:0') torch.Size([16])
percent tensor([0.9998, 0.9998, 0.9999, 0.9999, 0.9998, 0.9998, 0.9999, 0.9999, 0.9999,
        1.0000, 1.0000, 0.9998, 0.9998, 0.9998, 0.9998, 0.9994],
       device='cuda:0') torch.Size([16])
Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 3, 3, 3]) tensor(192.1380, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(831.2601, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(854.6547, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([128, 64, 3, 3]) tensor(1523.0463, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([128, 64, 1, 1]) tensor(480.5002, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([128, 128, 3, 3]) tensor(2307.2007, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([256, 128, 3, 3]) tensor(4246.0708, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([256, 128, 1, 1]) tensor(1336.4854, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([256, 256, 3, 3]) tensor(6303.5049, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([512, 256, 3, 3]) tensor(11504.8066, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([512, 256, 1, 1]) tensor(3774.7124, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([512, 512, 3, 3]) tensor(15927.5322, device='cuda:0', grad_fn=<NormBackward0>)
Epoch: 211 | Batch_idx: 0 |  Loss: (0.0485) |  Loss2: (0.0000) | Acc: (96.00%) (124/128)
Epoch: 211 | Batch_idx: 10 |  Loss: (0.0507) |  Loss2: (0.0000) | Acc: (98.00%) (1383/1408)
Epoch: 211 | Batch_idx: 20 |  Loss: (0.0569) |  Loss2: (0.0000) | Acc: (98.00%) (2642/2688)
Epoch: 211 | Batch_idx: 30 |  Loss: (0.0572) |  Loss2: (0.0000) | Acc: (98.00%) (3897/3968)
Epoch: 211 | Batch_idx: 40 |  Loss: (0.0581) |  Loss2: (0.0000) | Acc: (98.00%) (5154/5248)
Epoch: 211 | Batch_idx: 50 |  Loss: (0.0576) |  Loss2: (0.0000) | Acc: (98.00%) (6405/6528)
Epoch: 211 | Batch_idx: 60 |  Loss: (0.0571) |  Loss2: (0.0000) | Acc: (98.00%) (7664/7808)
Epoch: 211 | Batch_idx: 70 |  Loss: (0.0586) |  Loss2: (0.0000) | Acc: (98.00%) (8915/9088)
Epoch: 211 | Batch_idx: 80 |  Loss: (0.0569) |  Loss2: (0.0000) | Acc: (98.00%) (10171/10368)
Epoch: 211 | Batch_idx: 90 |  Loss: (0.0569) |  Loss2: (0.0000) | Acc: (98.00%) (11429/11648)
Epoch: 211 | Batch_idx: 100 |  Loss: (0.0565) |  Loss2: (0.0000) | Acc: (98.00%) (12686/12928)
Epoch: 211 | Batch_idx: 110 |  Loss: (0.0566) |  Loss2: (0.0000) | Acc: (98.00%) (13941/14208)
Epoch: 211 | Batch_idx: 120 |  Loss: (0.0566) |  Loss2: (0.0000) | Acc: (98.00%) (15201/15488)
Epoch: 211 | Batch_idx: 130 |  Loss: (0.0558) |  Loss2: (0.0000) | Acc: (98.00%) (16463/16768)
Epoch: 211 | Batch_idx: 140 |  Loss: (0.0562) |  Loss2: (0.0000) | Acc: (98.00%) (17715/18048)
Epoch: 211 | Batch_idx: 150 |  Loss: (0.0566) |  Loss2: (0.0000) | Acc: (98.00%) (18970/19328)
Epoch: 211 | Batch_idx: 160 |  Loss: (0.0568) |  Loss2: (0.0000) | Acc: (98.00%) (20224/20608)
Epoch: 211 | Batch_idx: 170 |  Loss: (0.0569) |  Loss2: (0.0000) | Acc: (98.00%) (21477/21888)
Epoch: 211 | Batch_idx: 180 |  Loss: (0.0578) |  Loss2: (0.0000) | Acc: (98.00%) (22727/23168)
Epoch: 211 | Batch_idx: 190 |  Loss: (0.0570) |  Loss2: (0.0000) | Acc: (98.00%) (23993/24448)
Epoch: 211 | Batch_idx: 200 |  Loss: (0.0569) |  Loss2: (0.0000) | Acc: (98.00%) (25250/25728)
Epoch: 211 | Batch_idx: 210 |  Loss: (0.0567) |  Loss2: (0.0000) | Acc: (98.00%) (26508/27008)
Epoch: 211 | Batch_idx: 220 |  Loss: (0.0569) |  Loss2: (0.0000) | Acc: (98.00%) (27767/28288)
Epoch: 211 | Batch_idx: 230 |  Loss: (0.0574) |  Loss2: (0.0000) | Acc: (98.00%) (29016/29568)
Epoch: 211 | Batch_idx: 240 |  Loss: (0.0574) |  Loss2: (0.0000) | Acc: (98.00%) (30269/30848)
Epoch: 211 | Batch_idx: 250 |  Loss: (0.0577) |  Loss2: (0.0000) | Acc: (98.00%) (31519/32128)
Epoch: 211 | Batch_idx: 260 |  Loss: (0.0581) |  Loss2: (0.0000) | Acc: (98.00%) (32774/33408)
Epoch: 211 | Batch_idx: 270 |  Loss: (0.0578) |  Loss2: (0.0000) | Acc: (98.00%) (34035/34688)
Epoch: 211 | Batch_idx: 280 |  Loss: (0.0580) |  Loss2: (0.0000) | Acc: (98.00%) (35293/35968)
Epoch: 211 | Batch_idx: 290 |  Loss: (0.0580) |  Loss2: (0.0000) | Acc: (98.00%) (36544/37248)
Epoch: 211 | Batch_idx: 300 |  Loss: (0.0582) |  Loss2: (0.0000) | Acc: (98.00%) (37795/38528)
Epoch: 211 | Batch_idx: 310 |  Loss: (0.0581) |  Loss2: (0.0000) | Acc: (98.00%) (39053/39808)
Epoch: 211 | Batch_idx: 320 |  Loss: (0.0580) |  Loss2: (0.0000) | Acc: (98.00%) (40312/41088)
Epoch: 211 | Batch_idx: 330 |  Loss: (0.0577) |  Loss2: (0.0000) | Acc: (98.00%) (41567/42368)
Epoch: 211 | Batch_idx: 340 |  Loss: (0.0576) |  Loss2: (0.0000) | Acc: (98.00%) (42828/43648)
Epoch: 211 | Batch_idx: 350 |  Loss: (0.0572) |  Loss2: (0.0000) | Acc: (98.00%) (44086/44928)
Epoch: 211 | Batch_idx: 360 |  Loss: (0.0573) |  Loss2: (0.0000) | Acc: (98.00%) (45342/46208)
Epoch: 211 | Batch_idx: 370 |  Loss: (0.0575) |  Loss2: (0.0000) | Acc: (98.00%) (46589/47488)
Epoch: 211 | Batch_idx: 380 |  Loss: (0.0578) |  Loss2: (0.0000) | Acc: (98.00%) (47839/48768)
Epoch: 211 | Batch_idx: 390 |  Loss: (0.0580) |  Loss2: (0.0000) | Acc: (98.00%) (49042/50000)
# TEST : Loss: (0.4297) | Acc: (88.00%) (8894/10000)
percent tensor([0.5697, 0.5830, 0.6113, 0.6036, 0.6140, 0.5766, 0.5942, 0.6113, 0.5832,
        0.5902, 0.5678, 0.6040, 0.5716, 0.5852, 0.5830, 0.5762],
       device='cuda:0') torch.Size([16])
percent tensor([0.5821, 0.5866, 0.5740, 0.5702, 0.5810, 0.5800, 0.5910, 0.5808, 0.5780,
        0.5837, 0.5852, 0.5870, 0.5814, 0.5831, 0.5880, 0.5832],
       device='cuda:0') torch.Size([16])
percent tensor([0.6333, 0.6540, 0.5925, 0.5648, 0.5698, 0.5891, 0.6293, 0.5819, 0.6160,
        0.6520, 0.6373, 0.6202, 0.6720, 0.6348, 0.6222, 0.6366],
       device='cuda:0') torch.Size([16])
percent tensor([0.6885, 0.6789, 0.6436, 0.6487, 0.6528, 0.7026, 0.6894, 0.6516, 0.6713,
        0.6809, 0.6865, 0.6643, 0.6825, 0.6832, 0.6902, 0.6903],
       device='cuda:0') torch.Size([16])
percent tensor([0.5766, 0.5240, 0.6486, 0.6856, 0.6812, 0.6186, 0.5898, 0.6673, 0.6229,
        0.5556, 0.5901, 0.6026, 0.4654, 0.6473, 0.6188, 0.6137],
       device='cuda:0') torch.Size([16])
percent tensor([0.5556, 0.7273, 0.6967, 0.6543, 0.6406, 0.7557, 0.7061, 0.5935, 0.7119,
        0.6588, 0.7524, 0.6829, 0.7418, 0.7269, 0.5306, 0.5147],
       device='cuda:0') torch.Size([16])
percent tensor([0.6941, 0.7357, 0.7209, 0.6453, 0.6408, 0.7346, 0.7597, 0.6487, 0.6958,
        0.7201, 0.7369, 0.6209, 0.7622, 0.7329, 0.5371, 0.6323],
       device='cuda:0') torch.Size([16])
percent tensor([0.9998, 0.9998, 0.9999, 0.9998, 0.9998, 0.9996, 0.9999, 0.9999, 1.0000,
        0.9999, 1.0000, 0.9998, 0.9998, 0.9997, 0.9998, 0.9995],
       device='cuda:0') torch.Size([16])
Epoch: 212 | Batch_idx: 0 |  Loss: (0.0578) |  Loss2: (0.0000) | Acc: (97.00%) (125/128)
Epoch: 212 | Batch_idx: 10 |  Loss: (0.0488) |  Loss2: (0.0000) | Acc: (98.00%) (1387/1408)
Epoch: 212 | Batch_idx: 20 |  Loss: (0.0502) |  Loss2: (0.0000) | Acc: (98.00%) (2646/2688)
Epoch: 212 | Batch_idx: 30 |  Loss: (0.0537) |  Loss2: (0.0000) | Acc: (98.00%) (3902/3968)
Epoch: 212 | Batch_idx: 40 |  Loss: (0.0550) |  Loss2: (0.0000) | Acc: (98.00%) (5154/5248)
Epoch: 212 | Batch_idx: 50 |  Loss: (0.0550) |  Loss2: (0.0000) | Acc: (98.00%) (6410/6528)
Epoch: 212 | Batch_idx: 60 |  Loss: (0.0540) |  Loss2: (0.0000) | Acc: (98.00%) (7671/7808)
Epoch: 212 | Batch_idx: 70 |  Loss: (0.0532) |  Loss2: (0.0000) | Acc: (98.00%) (8932/9088)
Epoch: 212 | Batch_idx: 80 |  Loss: (0.0526) |  Loss2: (0.0000) | Acc: (98.00%) (10194/10368)
Epoch: 212 | Batch_idx: 90 |  Loss: (0.0523) |  Loss2: (0.0000) | Acc: (98.00%) (11455/11648)
Epoch: 212 | Batch_idx: 100 |  Loss: (0.0530) |  Loss2: (0.0000) | Acc: (98.00%) (12712/12928)
Epoch: 212 | Batch_idx: 110 |  Loss: (0.0540) |  Loss2: (0.0000) | Acc: (98.00%) (13965/14208)
Epoch: 212 | Batch_idx: 120 |  Loss: (0.0538) |  Loss2: (0.0000) | Acc: (98.00%) (15225/15488)
Epoch: 212 | Batch_idx: 130 |  Loss: (0.0530) |  Loss2: (0.0000) | Acc: (98.00%) (16486/16768)
Epoch: 212 | Batch_idx: 140 |  Loss: (0.0528) |  Loss2: (0.0000) | Acc: (98.00%) (17745/18048)
Epoch: 212 | Batch_idx: 150 |  Loss: (0.0527) |  Loss2: (0.0000) | Acc: (98.00%) (19002/19328)
Epoch: 212 | Batch_idx: 160 |  Loss: (0.0523) |  Loss2: (0.0000) | Acc: (98.00%) (20263/20608)
Epoch: 212 | Batch_idx: 170 |  Loss: (0.0522) |  Loss2: (0.0000) | Acc: (98.00%) (21520/21888)
Epoch: 212 | Batch_idx: 180 |  Loss: (0.0520) |  Loss2: (0.0000) | Acc: (98.00%) (22781/23168)
Epoch: 212 | Batch_idx: 190 |  Loss: (0.0521) |  Loss2: (0.0000) | Acc: (98.00%) (24042/24448)
Epoch: 212 | Batch_idx: 200 |  Loss: (0.0520) |  Loss2: (0.0000) | Acc: (98.00%) (25298/25728)
Epoch: 212 | Batch_idx: 210 |  Loss: (0.0527) |  Loss2: (0.0000) | Acc: (98.00%) (26550/27008)
Epoch: 212 | Batch_idx: 220 |  Loss: (0.0531) |  Loss2: (0.0000) | Acc: (98.00%) (27805/28288)
Epoch: 212 | Batch_idx: 230 |  Loss: (0.0531) |  Loss2: (0.0000) | Acc: (98.00%) (29063/29568)
Epoch: 212 | Batch_idx: 240 |  Loss: (0.0530) |  Loss2: (0.0000) | Acc: (98.00%) (30324/30848)
Epoch: 212 | Batch_idx: 250 |  Loss: (0.0533) |  Loss2: (0.0000) | Acc: (98.00%) (31578/32128)
Epoch: 212 | Batch_idx: 260 |  Loss: (0.0535) |  Loss2: (0.0000) | Acc: (98.00%) (32832/33408)
Epoch: 212 | Batch_idx: 270 |  Loss: (0.0529) |  Loss2: (0.0000) | Acc: (98.00%) (34099/34688)
Epoch: 212 | Batch_idx: 280 |  Loss: (0.0527) |  Loss2: (0.0000) | Acc: (98.00%) (35365/35968)
Epoch: 212 | Batch_idx: 290 |  Loss: (0.0525) |  Loss2: (0.0000) | Acc: (98.00%) (36624/37248)
Epoch: 212 | Batch_idx: 300 |  Loss: (0.0527) |  Loss2: (0.0000) | Acc: (98.00%) (37879/38528)
Epoch: 212 | Batch_idx: 310 |  Loss: (0.0529) |  Loss2: (0.0000) | Acc: (98.00%) (39133/39808)
Epoch: 212 | Batch_idx: 320 |  Loss: (0.0528) |  Loss2: (0.0000) | Acc: (98.00%) (40393/41088)
Epoch: 212 | Batch_idx: 330 |  Loss: (0.0529) |  Loss2: (0.0000) | Acc: (98.00%) (41653/42368)
Epoch: 212 | Batch_idx: 340 |  Loss: (0.0531) |  Loss2: (0.0000) | Acc: (98.00%) (42907/43648)
Epoch: 212 | Batch_idx: 350 |  Loss: (0.0533) |  Loss2: (0.0000) | Acc: (98.00%) (44162/44928)
Epoch: 212 | Batch_idx: 360 |  Loss: (0.0538) |  Loss2: (0.0000) | Acc: (98.00%) (45412/46208)
Epoch: 212 | Batch_idx: 370 |  Loss: (0.0537) |  Loss2: (0.0000) | Acc: (98.00%) (46669/47488)
Epoch: 212 | Batch_idx: 380 |  Loss: (0.0537) |  Loss2: (0.0000) | Acc: (98.00%) (47925/48768)
Epoch: 212 | Batch_idx: 390 |  Loss: (0.0539) |  Loss2: (0.0000) | Acc: (98.00%) (49137/50000)
# TEST : Loss: (0.4990) | Acc: (87.00%) (8774/10000)
percent tensor([0.5701, 0.5856, 0.6089, 0.6033, 0.6136, 0.5789, 0.5955, 0.6116, 0.5841,
        0.5914, 0.5696, 0.6034, 0.5728, 0.5878, 0.5852, 0.5775],
       device='cuda:0') torch.Size([16])
percent tensor([0.5829, 0.5891, 0.5761, 0.5746, 0.5845, 0.5809, 0.5930, 0.5837, 0.5791,
        0.5857, 0.5854, 0.5904, 0.5829, 0.5837, 0.5902, 0.5844],
       device='cuda:0') torch.Size([16])
percent tensor([0.6377, 0.6595, 0.6014, 0.5661, 0.5717, 0.5867, 0.6330, 0.5876, 0.6179,
        0.6596, 0.6444, 0.6269, 0.6762, 0.6392, 0.6240, 0.6414],
       device='cuda:0') torch.Size([16])
percent tensor([0.6903, 0.6844, 0.6518, 0.6556, 0.6608, 0.7000, 0.6961, 0.6573, 0.6745,
        0.6859, 0.6888, 0.6732, 0.6889, 0.6869, 0.6929, 0.6917],
       device='cuda:0') torch.Size([16])
percent tensor([0.5770, 0.5041, 0.6345, 0.6742, 0.6787, 0.6167, 0.5829, 0.6564, 0.6252,
        0.5268, 0.5837, 0.5914, 0.4544, 0.6470, 0.6082, 0.6035],
       device='cuda:0') torch.Size([16])
percent tensor([0.5563, 0.7116, 0.6793, 0.6515, 0.6322, 0.7278, 0.6943, 0.5583, 0.7067,
        0.6677, 0.7503, 0.7080, 0.7482, 0.7086, 0.5033, 0.4645],
       device='cuda:0') torch.Size([16])
percent tensor([0.6923, 0.7333, 0.7080, 0.6433, 0.6414, 0.7291, 0.7388, 0.6321, 0.6973,
        0.7217, 0.7231, 0.6179, 0.7642, 0.7160, 0.5413, 0.6131],
       device='cuda:0') torch.Size([16])
percent tensor([0.9997, 0.9999, 0.9999, 0.9998, 0.9998, 0.9997, 0.9999, 1.0000, 0.9999,
        1.0000, 1.0000, 0.9999, 0.9998, 0.9998, 0.9999, 0.9994],
       device='cuda:0') torch.Size([16])
Epoch: 213 | Batch_idx: 0 |  Loss: (0.0777) |  Loss2: (0.0000) | Acc: (97.00%) (125/128)
Epoch: 213 | Batch_idx: 10 |  Loss: (0.0568) |  Loss2: (0.0000) | Acc: (98.00%) (1383/1408)
Epoch: 213 | Batch_idx: 20 |  Loss: (0.0529) |  Loss2: (0.0000) | Acc: (98.00%) (2644/2688)
Epoch: 213 | Batch_idx: 30 |  Loss: (0.0552) |  Loss2: (0.0000) | Acc: (98.00%) (3901/3968)
Epoch: 213 | Batch_idx: 40 |  Loss: (0.0562) |  Loss2: (0.0000) | Acc: (98.00%) (5157/5248)
Epoch: 213 | Batch_idx: 50 |  Loss: (0.0542) |  Loss2: (0.0000) | Acc: (98.00%) (6420/6528)
Epoch: 213 | Batch_idx: 60 |  Loss: (0.0540) |  Loss2: (0.0000) | Acc: (98.00%) (7677/7808)
Epoch: 213 | Batch_idx: 70 |  Loss: (0.0525) |  Loss2: (0.0000) | Acc: (98.00%) (8943/9088)
Epoch: 213 | Batch_idx: 80 |  Loss: (0.0499) |  Loss2: (0.0000) | Acc: (98.00%) (10214/10368)
Epoch: 213 | Batch_idx: 90 |  Loss: (0.0502) |  Loss2: (0.0000) | Acc: (98.00%) (11474/11648)
Epoch: 213 | Batch_idx: 100 |  Loss: (0.0506) |  Loss2: (0.0000) | Acc: (98.00%) (12730/12928)
Epoch: 213 | Batch_idx: 110 |  Loss: (0.0504) |  Loss2: (0.0000) | Acc: (98.00%) (13993/14208)
Epoch: 213 | Batch_idx: 120 |  Loss: (0.0501) |  Loss2: (0.0000) | Acc: (98.00%) (15255/15488)
Epoch: 213 | Batch_idx: 130 |  Loss: (0.0514) |  Loss2: (0.0000) | Acc: (98.00%) (16502/16768)
Epoch: 213 | Batch_idx: 140 |  Loss: (0.0527) |  Loss2: (0.0000) | Acc: (98.00%) (17753/18048)
Epoch: 213 | Batch_idx: 150 |  Loss: (0.0527) |  Loss2: (0.0000) | Acc: (98.00%) (19009/19328)
Epoch: 213 | Batch_idx: 160 |  Loss: (0.0527) |  Loss2: (0.0000) | Acc: (98.00%) (20266/20608)
Epoch: 213 | Batch_idx: 170 |  Loss: (0.0526) |  Loss2: (0.0000) | Acc: (98.00%) (21524/21888)
Epoch: 213 | Batch_idx: 180 |  Loss: (0.0528) |  Loss2: (0.0000) | Acc: (98.00%) (22783/23168)
Epoch: 213 | Batch_idx: 190 |  Loss: (0.0525) |  Loss2: (0.0000) | Acc: (98.00%) (24045/24448)
Epoch: 213 | Batch_idx: 200 |  Loss: (0.0526) |  Loss2: (0.0000) | Acc: (98.00%) (25303/25728)
Epoch: 213 | Batch_idx: 210 |  Loss: (0.0527) |  Loss2: (0.0000) | Acc: (98.00%) (26556/27008)
Epoch: 213 | Batch_idx: 220 |  Loss: (0.0530) |  Loss2: (0.0000) | Acc: (98.00%) (27812/28288)
Epoch: 213 | Batch_idx: 230 |  Loss: (0.0529) |  Loss2: (0.0000) | Acc: (98.00%) (29065/29568)
Epoch: 213 | Batch_idx: 240 |  Loss: (0.0532) |  Loss2: (0.0000) | Acc: (98.00%) (30317/30848)
Epoch: 213 | Batch_idx: 250 |  Loss: (0.0537) |  Loss2: (0.0000) | Acc: (98.00%) (31569/32128)
Epoch: 213 | Batch_idx: 260 |  Loss: (0.0539) |  Loss2: (0.0000) | Acc: (98.00%) (32822/33408)
Epoch: 213 | Batch_idx: 270 |  Loss: (0.0538) |  Loss2: (0.0000) | Acc: (98.00%) (34081/34688)
Epoch: 213 | Batch_idx: 280 |  Loss: (0.0542) |  Loss2: (0.0000) | Acc: (98.00%) (35332/35968)
Epoch: 213 | Batch_idx: 290 |  Loss: (0.0542) |  Loss2: (0.0000) | Acc: (98.00%) (36592/37248)
Epoch: 213 | Batch_idx: 300 |  Loss: (0.0543) |  Loss2: (0.0000) | Acc: (98.00%) (37843/38528)
Epoch: 213 | Batch_idx: 310 |  Loss: (0.0544) |  Loss2: (0.0000) | Acc: (98.00%) (39100/39808)
Epoch: 213 | Batch_idx: 320 |  Loss: (0.0550) |  Loss2: (0.0000) | Acc: (98.00%) (40344/41088)
Epoch: 213 | Batch_idx: 330 |  Loss: (0.0552) |  Loss2: (0.0000) | Acc: (98.00%) (41597/42368)
Epoch: 213 | Batch_idx: 340 |  Loss: (0.0552) |  Loss2: (0.0000) | Acc: (98.00%) (42857/43648)
Epoch: 213 | Batch_idx: 350 |  Loss: (0.0556) |  Loss2: (0.0000) | Acc: (98.00%) (44111/44928)
Epoch: 213 | Batch_idx: 360 |  Loss: (0.0562) |  Loss2: (0.0000) | Acc: (98.00%) (45349/46208)
Epoch: 213 | Batch_idx: 370 |  Loss: (0.0566) |  Loss2: (0.0000) | Acc: (98.00%) (46595/47488)
Epoch: 213 | Batch_idx: 380 |  Loss: (0.0568) |  Loss2: (0.0000) | Acc: (98.00%) (47846/48768)
Epoch: 213 | Batch_idx: 390 |  Loss: (0.0571) |  Loss2: (0.0000) | Acc: (98.00%) (49044/50000)
# TEST : Loss: (0.4653) | Acc: (88.00%) (8834/10000)
percent tensor([0.5696, 0.5858, 0.6070, 0.6027, 0.6112, 0.5777, 0.5942, 0.6099, 0.5827,
        0.5899, 0.5688, 0.6005, 0.5718, 0.5882, 0.5843, 0.5768],
       device='cuda:0') torch.Size([16])
percent tensor([0.5829, 0.5879, 0.5756, 0.5739, 0.5834, 0.5821, 0.5922, 0.5829, 0.5779,
        0.5850, 0.5853, 0.5881, 0.5816, 0.5822, 0.5903, 0.5846],
       device='cuda:0') torch.Size([16])
percent tensor([0.6382, 0.6519, 0.6015, 0.5688, 0.5716, 0.5961, 0.6290, 0.5903, 0.6228,
        0.6566, 0.6440, 0.6255, 0.6756, 0.6369, 0.6233, 0.6435],
       device='cuda:0') torch.Size([16])
percent tensor([0.6925, 0.6837, 0.6502, 0.6515, 0.6597, 0.6998, 0.6943, 0.6571, 0.6723,
        0.6858, 0.6922, 0.6727, 0.6882, 0.6841, 0.6922, 0.6930],
       device='cuda:0') torch.Size([16])
percent tensor([0.5684, 0.5143, 0.6480, 0.6729, 0.6808, 0.6224, 0.5861, 0.6603, 0.6148,
        0.5279, 0.5764, 0.5860, 0.4446, 0.6485, 0.6080, 0.6022],
       device='cuda:0') torch.Size([16])
percent tensor([0.5471, 0.7213, 0.6847, 0.6396, 0.6404, 0.7589, 0.7027, 0.5814, 0.6927,
        0.6732, 0.7597, 0.6813, 0.7374, 0.7097, 0.5139, 0.5033],
       device='cuda:0') torch.Size([16])
percent tensor([0.6875, 0.7337, 0.7156, 0.6474, 0.6452, 0.7401, 0.7327, 0.6454, 0.6877,
        0.7127, 0.7083, 0.6181, 0.7380, 0.7026, 0.5425, 0.6086],
       device='cuda:0') torch.Size([16])
percent tensor([0.9998, 0.9998, 0.9998, 0.9999, 0.9997, 0.9998, 0.9999, 0.9999, 0.9999,
        0.9999, 1.0000, 0.9998, 0.9998, 0.9998, 0.9998, 0.9995],
       device='cuda:0') torch.Size([16])
Epoch: 214 | Batch_idx: 0 |  Loss: (0.1192) |  Loss2: (0.0000) | Acc: (94.00%) (121/128)
Epoch: 214 | Batch_idx: 10 |  Loss: (0.0649) |  Loss2: (0.0000) | Acc: (97.00%) (1377/1408)
Epoch: 214 | Batch_idx: 20 |  Loss: (0.0707) |  Loss2: (0.0000) | Acc: (97.00%) (2623/2688)
Epoch: 214 | Batch_idx: 30 |  Loss: (0.0673) |  Loss2: (0.0000) | Acc: (97.00%) (3876/3968)
Epoch: 214 | Batch_idx: 40 |  Loss: (0.0641) |  Loss2: (0.0000) | Acc: (97.00%) (5132/5248)
Epoch: 214 | Batch_idx: 50 |  Loss: (0.0636) |  Loss2: (0.0000) | Acc: (97.00%) (6387/6528)
Epoch: 214 | Batch_idx: 60 |  Loss: (0.0600) |  Loss2: (0.0000) | Acc: (97.00%) (7651/7808)
Epoch: 214 | Batch_idx: 70 |  Loss: (0.0606) |  Loss2: (0.0000) | Acc: (97.00%) (8904/9088)
Epoch: 214 | Batch_idx: 80 |  Loss: (0.0584) |  Loss2: (0.0000) | Acc: (98.00%) (10168/10368)
Epoch: 214 | Batch_idx: 90 |  Loss: (0.0583) |  Loss2: (0.0000) | Acc: (98.00%) (11418/11648)
Epoch: 214 | Batch_idx: 100 |  Loss: (0.0572) |  Loss2: (0.0000) | Acc: (98.00%) (12679/12928)
Epoch: 214 | Batch_idx: 110 |  Loss: (0.0554) |  Loss2: (0.0000) | Acc: (98.00%) (13945/14208)
Epoch: 214 | Batch_idx: 120 |  Loss: (0.0559) |  Loss2: (0.0000) | Acc: (98.00%) (15199/15488)
Epoch: 214 | Batch_idx: 130 |  Loss: (0.0571) |  Loss2: (0.0000) | Acc: (98.00%) (16444/16768)
Epoch: 214 | Batch_idx: 140 |  Loss: (0.0569) |  Loss2: (0.0000) | Acc: (98.00%) (17699/18048)
Epoch: 214 | Batch_idx: 150 |  Loss: (0.0565) |  Loss2: (0.0000) | Acc: (98.00%) (18959/19328)
Epoch: 214 | Batch_idx: 160 |  Loss: (0.0560) |  Loss2: (0.0000) | Acc: (98.00%) (20220/20608)
Epoch: 214 | Batch_idx: 170 |  Loss: (0.0556) |  Loss2: (0.0000) | Acc: (98.00%) (21481/21888)
Epoch: 214 | Batch_idx: 180 |  Loss: (0.0557) |  Loss2: (0.0000) | Acc: (98.00%) (22737/23168)
Epoch: 214 | Batch_idx: 190 |  Loss: (0.0555) |  Loss2: (0.0000) | Acc: (98.00%) (23998/24448)
Epoch: 214 | Batch_idx: 200 |  Loss: (0.0560) |  Loss2: (0.0000) | Acc: (98.00%) (25249/25728)
Epoch: 214 | Batch_idx: 210 |  Loss: (0.0561) |  Loss2: (0.0000) | Acc: (98.00%) (26504/27008)
Epoch: 214 | Batch_idx: 220 |  Loss: (0.0565) |  Loss2: (0.0000) | Acc: (98.00%) (27753/28288)
Epoch: 214 | Batch_idx: 230 |  Loss: (0.0563) |  Loss2: (0.0000) | Acc: (98.00%) (29010/29568)
Epoch: 214 | Batch_idx: 240 |  Loss: (0.0563) |  Loss2: (0.0000) | Acc: (98.00%) (30262/30848)
Epoch: 214 | Batch_idx: 250 |  Loss: (0.0565) |  Loss2: (0.0000) | Acc: (98.00%) (31511/32128)
Epoch: 214 | Batch_idx: 260 |  Loss: (0.0566) |  Loss2: (0.0000) | Acc: (98.00%) (32764/33408)
Epoch: 214 | Batch_idx: 270 |  Loss: (0.0566) |  Loss2: (0.0000) | Acc: (98.00%) (34018/34688)
Epoch: 214 | Batch_idx: 280 |  Loss: (0.0568) |  Loss2: (0.0000) | Acc: (98.00%) (35272/35968)
Epoch: 214 | Batch_idx: 290 |  Loss: (0.0572) |  Loss2: (0.0000) | Acc: (98.00%) (36522/37248)
Epoch: 214 | Batch_idx: 300 |  Loss: (0.0575) |  Loss2: (0.0000) | Acc: (98.00%) (37772/38528)
Epoch: 214 | Batch_idx: 310 |  Loss: (0.0575) |  Loss2: (0.0000) | Acc: (98.00%) (39031/39808)
Epoch: 214 | Batch_idx: 320 |  Loss: (0.0578) |  Loss2: (0.0000) | Acc: (98.00%) (40279/41088)
Epoch: 214 | Batch_idx: 330 |  Loss: (0.0578) |  Loss2: (0.0000) | Acc: (98.00%) (41526/42368)
Epoch: 214 | Batch_idx: 340 |  Loss: (0.0579) |  Loss2: (0.0000) | Acc: (98.00%) (42779/43648)
Epoch: 214 | Batch_idx: 350 |  Loss: (0.0578) |  Loss2: (0.0000) | Acc: (98.00%) (44039/44928)
Epoch: 214 | Batch_idx: 360 |  Loss: (0.0575) |  Loss2: (0.0000) | Acc: (98.00%) (45296/46208)
Epoch: 214 | Batch_idx: 370 |  Loss: (0.0575) |  Loss2: (0.0000) | Acc: (98.00%) (46554/47488)
Epoch: 214 | Batch_idx: 380 |  Loss: (0.0574) |  Loss2: (0.0000) | Acc: (98.00%) (47813/48768)
Epoch: 214 | Batch_idx: 390 |  Loss: (0.0575) |  Loss2: (0.0000) | Acc: (98.00%) (49021/50000)
# TEST : Loss: (0.4488) | Acc: (88.00%) (8848/10000)
percent tensor([0.5739, 0.5889, 0.6142, 0.6075, 0.6187, 0.5832, 0.5996, 0.6145, 0.5877,
        0.5951, 0.5728, 0.6077, 0.5766, 0.5904, 0.5888, 0.5808],
       device='cuda:0') torch.Size([16])
percent tensor([0.5820, 0.5867, 0.5752, 0.5737, 0.5827, 0.5810, 0.5910, 0.5817, 0.5770,
        0.5831, 0.5840, 0.5871, 0.5805, 0.5815, 0.5892, 0.5835],
       device='cuda:0') torch.Size([16])
percent tensor([0.6314, 0.6528, 0.5905, 0.5587, 0.5675, 0.5917, 0.6276, 0.5825, 0.6149,
        0.6518, 0.6390, 0.6176, 0.6709, 0.6356, 0.6249, 0.6358],
       device='cuda:0') torch.Size([16])
percent tensor([0.6884, 0.6784, 0.6493, 0.6518, 0.6571, 0.7015, 0.6889, 0.6544, 0.6702,
        0.6821, 0.6851, 0.6693, 0.6820, 0.6830, 0.6910, 0.6917],
       device='cuda:0') torch.Size([16])
percent tensor([0.5826, 0.5239, 0.6483, 0.6816, 0.6786, 0.6177, 0.5868, 0.6558, 0.6155,
        0.5614, 0.5926, 0.6040, 0.4694, 0.6343, 0.6191, 0.6085],
       device='cuda:0') torch.Size([16])
percent tensor([0.5441, 0.7185, 0.6711, 0.6526, 0.6374, 0.7398, 0.6959, 0.5969, 0.6855,
        0.6691, 0.7414, 0.6919, 0.7238, 0.7301, 0.5057, 0.4761],
       device='cuda:0') torch.Size([16])
percent tensor([0.6784, 0.7337, 0.7049, 0.6394, 0.6301, 0.7328, 0.7501, 0.6383, 0.6644,
        0.7299, 0.7149, 0.6210, 0.7391, 0.7176, 0.5306, 0.5881],
       device='cuda:0') torch.Size([16])
percent tensor([0.9998, 0.9998, 0.9999, 0.9999, 0.9999, 0.9997, 0.9999, 0.9999, 0.9999,
        0.9999, 1.0000, 0.9997, 0.9998, 0.9998, 0.9999, 0.9993],
       device='cuda:0') torch.Size([16])
Epoch: 215 | Batch_idx: 0 |  Loss: (0.0502) |  Loss2: (0.0000) | Acc: (98.00%) (126/128)
Epoch: 215 | Batch_idx: 10 |  Loss: (0.0519) |  Loss2: (0.0000) | Acc: (98.00%) (1381/1408)
Epoch: 215 | Batch_idx: 20 |  Loss: (0.0521) |  Loss2: (0.0000) | Acc: (98.00%) (2641/2688)
Epoch: 215 | Batch_idx: 30 |  Loss: (0.0518) |  Loss2: (0.0000) | Acc: (98.00%) (3901/3968)
Epoch: 215 | Batch_idx: 40 |  Loss: (0.0516) |  Loss2: (0.0000) | Acc: (98.00%) (5154/5248)
Epoch: 215 | Batch_idx: 50 |  Loss: (0.0511) |  Loss2: (0.0000) | Acc: (98.00%) (6414/6528)
Epoch: 215 | Batch_idx: 60 |  Loss: (0.0505) |  Loss2: (0.0000) | Acc: (98.00%) (7677/7808)
Epoch: 215 | Batch_idx: 70 |  Loss: (0.0509) |  Loss2: (0.0000) | Acc: (98.00%) (8940/9088)
Epoch: 215 | Batch_idx: 80 |  Loss: (0.0504) |  Loss2: (0.0000) | Acc: (98.00%) (10199/10368)
Epoch: 215 | Batch_idx: 90 |  Loss: (0.0514) |  Loss2: (0.0000) | Acc: (98.00%) (11456/11648)
Epoch: 215 | Batch_idx: 100 |  Loss: (0.0534) |  Loss2: (0.0000) | Acc: (98.00%) (12704/12928)
Epoch: 215 | Batch_idx: 110 |  Loss: (0.0533) |  Loss2: (0.0000) | Acc: (98.00%) (13967/14208)
Epoch: 215 | Batch_idx: 120 |  Loss: (0.0543) |  Loss2: (0.0000) | Acc: (98.00%) (15219/15488)
Epoch: 215 | Batch_idx: 130 |  Loss: (0.0535) |  Loss2: (0.0000) | Acc: (98.00%) (16482/16768)
Epoch: 215 | Batch_idx: 140 |  Loss: (0.0549) |  Loss2: (0.0000) | Acc: (98.00%) (17731/18048)
Epoch: 215 | Batch_idx: 150 |  Loss: (0.0547) |  Loss2: (0.0000) | Acc: (98.00%) (18991/19328)
Epoch: 215 | Batch_idx: 160 |  Loss: (0.0550) |  Loss2: (0.0000) | Acc: (98.00%) (20244/20608)
Epoch: 215 | Batch_idx: 170 |  Loss: (0.0554) |  Loss2: (0.0000) | Acc: (98.00%) (21497/21888)
Epoch: 215 | Batch_idx: 180 |  Loss: (0.0556) |  Loss2: (0.0000) | Acc: (98.00%) (22752/23168)
Epoch: 215 | Batch_idx: 190 |  Loss: (0.0556) |  Loss2: (0.0000) | Acc: (98.00%) (24005/24448)
Epoch: 215 | Batch_idx: 200 |  Loss: (0.0553) |  Loss2: (0.0000) | Acc: (98.00%) (25265/25728)
Epoch: 215 | Batch_idx: 210 |  Loss: (0.0547) |  Loss2: (0.0000) | Acc: (98.00%) (26525/27008)
Epoch: 215 | Batch_idx: 220 |  Loss: (0.0547) |  Loss2: (0.0000) | Acc: (98.00%) (27781/28288)
Epoch: 215 | Batch_idx: 230 |  Loss: (0.0550) |  Loss2: (0.0000) | Acc: (98.00%) (29035/29568)
Epoch: 215 | Batch_idx: 240 |  Loss: (0.0551) |  Loss2: (0.0000) | Acc: (98.00%) (30293/30848)
Epoch: 215 | Batch_idx: 250 |  Loss: (0.0552) |  Loss2: (0.0000) | Acc: (98.00%) (31547/32128)
Epoch: 215 | Batch_idx: 260 |  Loss: (0.0552) |  Loss2: (0.0000) | Acc: (98.00%) (32804/33408)
Epoch: 215 | Batch_idx: 270 |  Loss: (0.0558) |  Loss2: (0.0000) | Acc: (98.00%) (34056/34688)
Epoch: 215 | Batch_idx: 280 |  Loss: (0.0555) |  Loss2: (0.0000) | Acc: (98.00%) (35317/35968)
Epoch: 215 | Batch_idx: 290 |  Loss: (0.0559) |  Loss2: (0.0000) | Acc: (98.00%) (36564/37248)
Epoch: 215 | Batch_idx: 300 |  Loss: (0.0557) |  Loss2: (0.0000) | Acc: (98.00%) (37818/38528)
Epoch: 215 | Batch_idx: 310 |  Loss: (0.0558) |  Loss2: (0.0000) | Acc: (98.00%) (39072/39808)
Epoch: 215 | Batch_idx: 320 |  Loss: (0.0559) |  Loss2: (0.0000) | Acc: (98.00%) (40328/41088)
Epoch: 215 | Batch_idx: 330 |  Loss: (0.0562) |  Loss2: (0.0000) | Acc: (98.00%) (41574/42368)
Epoch: 215 | Batch_idx: 340 |  Loss: (0.0567) |  Loss2: (0.0000) | Acc: (98.00%) (42821/43648)
Epoch: 215 | Batch_idx: 350 |  Loss: (0.0569) |  Loss2: (0.0000) | Acc: (98.00%) (44079/44928)
Epoch: 215 | Batch_idx: 360 |  Loss: (0.0567) |  Loss2: (0.0000) | Acc: (98.00%) (45334/46208)
Epoch: 215 | Batch_idx: 370 |  Loss: (0.0566) |  Loss2: (0.0000) | Acc: (98.00%) (46594/47488)
Epoch: 215 | Batch_idx: 380 |  Loss: (0.0567) |  Loss2: (0.0000) | Acc: (98.00%) (47848/48768)
Epoch: 215 | Batch_idx: 390 |  Loss: (0.0568) |  Loss2: (0.0000) | Acc: (98.00%) (49054/50000)
=> saving checkpoint 'drive/app/torch/save_Schedule/checkpoint_215.pth.tar'
# TEST : Loss: (0.4520) | Acc: (88.00%) (8851/10000)
percent tensor([0.5754, 0.5888, 0.6164, 0.6093, 0.6193, 0.5845, 0.5995, 0.6153, 0.5881,
        0.5950, 0.5728, 0.6101, 0.5772, 0.5885, 0.5899, 0.5812],
       device='cuda:0') torch.Size([16])
percent tensor([0.5849, 0.5889, 0.5786, 0.5751, 0.5853, 0.5832, 0.5935, 0.5851, 0.5794,
        0.5851, 0.5871, 0.5902, 0.5841, 0.5824, 0.5914, 0.5859],
       device='cuda:0') torch.Size([16])
percent tensor([0.6386, 0.6602, 0.5998, 0.5681, 0.5733, 0.5978, 0.6317, 0.5840, 0.6182,
        0.6589, 0.6447, 0.6216, 0.6777, 0.6373, 0.6302, 0.6446],
       device='cuda:0') torch.Size([16])
percent tensor([0.6942, 0.6823, 0.6592, 0.6558, 0.6661, 0.7076, 0.6941, 0.6570, 0.6747,
        0.6855, 0.6895, 0.6740, 0.6874, 0.6849, 0.6939, 0.6974],
       device='cuda:0') torch.Size([16])
percent tensor([0.5756, 0.5164, 0.6468, 0.6764, 0.6863, 0.6244, 0.5883, 0.6527, 0.6219,
        0.5418, 0.5986, 0.6010, 0.4608, 0.6468, 0.6164, 0.6038],
       device='cuda:0') torch.Size([16])
percent tensor([0.5751, 0.7136, 0.7062, 0.6876, 0.6870, 0.7540, 0.6858, 0.5875, 0.7030,
        0.6893, 0.7563, 0.6897, 0.7406, 0.7246, 0.5244, 0.5106],
       device='cuda:0') torch.Size([16])
percent tensor([0.6951, 0.7415, 0.7239, 0.6627, 0.6623, 0.7332, 0.7139, 0.6536, 0.6745,
        0.7315, 0.7151, 0.6105, 0.7394, 0.6972, 0.5467, 0.6137],
       device='cuda:0') torch.Size([16])
percent tensor([0.9999, 0.9999, 0.9999, 0.9999, 0.9997, 0.9996, 0.9999, 1.0000, 0.9999,
        1.0000, 1.0000, 0.9998, 0.9997, 0.9998, 0.9999, 0.9994],
       device='cuda:0') torch.Size([16])
Epoch: 216 | Batch_idx: 0 |  Loss: (0.0778) |  Loss2: (0.0000) | Acc: (96.00%) (124/128)
Epoch: 216 | Batch_idx: 10 |  Loss: (0.0491) |  Loss2: (0.0000) | Acc: (98.00%) (1385/1408)
Epoch: 216 | Batch_idx: 20 |  Loss: (0.0564) |  Loss2: (0.0000) | Acc: (98.00%) (2637/2688)
Epoch: 216 | Batch_idx: 30 |  Loss: (0.0556) |  Loss2: (0.0000) | Acc: (98.00%) (3895/3968)
Epoch: 216 | Batch_idx: 40 |  Loss: (0.0597) |  Loss2: (0.0000) | Acc: (98.00%) (5145/5248)
Epoch: 216 | Batch_idx: 50 |  Loss: (0.0586) |  Loss2: (0.0000) | Acc: (98.00%) (6405/6528)
Epoch: 216 | Batch_idx: 60 |  Loss: (0.0588) |  Loss2: (0.0000) | Acc: (98.00%) (7659/7808)
Epoch: 216 | Batch_idx: 70 |  Loss: (0.0594) |  Loss2: (0.0000) | Acc: (98.00%) (8911/9088)
Epoch: 216 | Batch_idx: 80 |  Loss: (0.0581) |  Loss2: (0.0000) | Acc: (98.00%) (10175/10368)
Epoch: 216 | Batch_idx: 90 |  Loss: (0.0578) |  Loss2: (0.0000) | Acc: (98.00%) (11431/11648)
Epoch: 216 | Batch_idx: 100 |  Loss: (0.0580) |  Loss2: (0.0000) | Acc: (98.00%) (12686/12928)
Epoch: 216 | Batch_idx: 110 |  Loss: (0.0575) |  Loss2: (0.0000) | Acc: (98.00%) (13945/14208)
Epoch: 216 | Batch_idx: 120 |  Loss: (0.0567) |  Loss2: (0.0000) | Acc: (98.00%) (15206/15488)
Epoch: 216 | Batch_idx: 130 |  Loss: (0.0563) |  Loss2: (0.0000) | Acc: (98.00%) (16463/16768)
Epoch: 216 | Batch_idx: 140 |  Loss: (0.0567) |  Loss2: (0.0000) | Acc: (98.00%) (17712/18048)
Epoch: 216 | Batch_idx: 150 |  Loss: (0.0563) |  Loss2: (0.0000) | Acc: (98.00%) (18966/19328)
Epoch: 216 | Batch_idx: 160 |  Loss: (0.0562) |  Loss2: (0.0000) | Acc: (98.00%) (20224/20608)
Epoch: 216 | Batch_idx: 170 |  Loss: (0.0563) |  Loss2: (0.0000) | Acc: (98.00%) (21476/21888)
Epoch: 216 | Batch_idx: 180 |  Loss: (0.0563) |  Loss2: (0.0000) | Acc: (98.00%) (22731/23168)
Epoch: 216 | Batch_idx: 190 |  Loss: (0.0562) |  Loss2: (0.0000) | Acc: (98.00%) (23990/24448)
Epoch: 216 | Batch_idx: 200 |  Loss: (0.0555) |  Loss2: (0.0000) | Acc: (98.00%) (25250/25728)
Epoch: 216 | Batch_idx: 210 |  Loss: (0.0554) |  Loss2: (0.0000) | Acc: (98.00%) (26504/27008)
Epoch: 216 | Batch_idx: 220 |  Loss: (0.0559) |  Loss2: (0.0000) | Acc: (98.00%) (27750/28288)
Epoch: 216 | Batch_idx: 230 |  Loss: (0.0559) |  Loss2: (0.0000) | Acc: (98.00%) (29011/29568)
Epoch: 216 | Batch_idx: 240 |  Loss: (0.0561) |  Loss2: (0.0000) | Acc: (98.00%) (30266/30848)
Epoch: 216 | Batch_idx: 250 |  Loss: (0.0559) |  Loss2: (0.0000) | Acc: (98.00%) (31524/32128)
Epoch: 216 | Batch_idx: 260 |  Loss: (0.0567) |  Loss2: (0.0000) | Acc: (98.00%) (32770/33408)
Epoch: 216 | Batch_idx: 270 |  Loss: (0.0567) |  Loss2: (0.0000) | Acc: (98.00%) (34027/34688)
Epoch: 216 | Batch_idx: 280 |  Loss: (0.0565) |  Loss2: (0.0000) | Acc: (98.00%) (35285/35968)
Epoch: 216 | Batch_idx: 290 |  Loss: (0.0564) |  Loss2: (0.0000) | Acc: (98.00%) (36542/37248)
Epoch: 216 | Batch_idx: 300 |  Loss: (0.0566) |  Loss2: (0.0000) | Acc: (98.00%) (37795/38528)
Epoch: 216 | Batch_idx: 310 |  Loss: (0.0565) |  Loss2: (0.0000) | Acc: (98.00%) (39050/39808)
Epoch: 216 | Batch_idx: 320 |  Loss: (0.0566) |  Loss2: (0.0000) | Acc: (98.00%) (40305/41088)
Epoch: 216 | Batch_idx: 330 |  Loss: (0.0563) |  Loss2: (0.0000) | Acc: (98.00%) (41566/42368)
Epoch: 216 | Batch_idx: 340 |  Loss: (0.0558) |  Loss2: (0.0000) | Acc: (98.00%) (42831/43648)
Epoch: 216 | Batch_idx: 350 |  Loss: (0.0556) |  Loss2: (0.0000) | Acc: (98.00%) (44087/44928)
Epoch: 216 | Batch_idx: 360 |  Loss: (0.0554) |  Loss2: (0.0000) | Acc: (98.00%) (45344/46208)
Epoch: 216 | Batch_idx: 370 |  Loss: (0.0552) |  Loss2: (0.0000) | Acc: (98.00%) (46607/47488)
Epoch: 216 | Batch_idx: 380 |  Loss: (0.0551) |  Loss2: (0.0000) | Acc: (98.00%) (47869/48768)
Epoch: 216 | Batch_idx: 390 |  Loss: (0.0548) |  Loss2: (0.0000) | Acc: (98.00%) (49081/50000)
# TEST : Loss: (0.4264) | Acc: (89.00%) (8914/10000)
percent tensor([0.5742, 0.5894, 0.6141, 0.6081, 0.6186, 0.5841, 0.5999, 0.6151, 0.5873,
        0.5953, 0.5724, 0.6077, 0.5762, 0.5916, 0.5896, 0.5819],
       device='cuda:0') torch.Size([16])
percent tensor([0.5835, 0.5896, 0.5765, 0.5748, 0.5840, 0.5826, 0.5938, 0.5841, 0.5784,
        0.5851, 0.5861, 0.5885, 0.5831, 0.5845, 0.5916, 0.5856],
       device='cuda:0') torch.Size([16])
percent tensor([0.6400, 0.6584, 0.6013, 0.5675, 0.5767, 0.5951, 0.6350, 0.5900, 0.6235,
        0.6592, 0.6453, 0.6263, 0.6796, 0.6374, 0.6278, 0.6438],
       device='cuda:0') torch.Size([16])
percent tensor([0.6938, 0.6822, 0.6535, 0.6543, 0.6640, 0.7102, 0.6951, 0.6582, 0.6728,
        0.6848, 0.6866, 0.6720, 0.6865, 0.6855, 0.6965, 0.6987],
       device='cuda:0') torch.Size([16])
percent tensor([0.5760, 0.5216, 0.6493, 0.6883, 0.6823, 0.6163, 0.5938, 0.6644, 0.6179,
        0.5433, 0.5892, 0.5967, 0.4564, 0.6434, 0.6214, 0.6053],
       device='cuda:0') torch.Size([16])
percent tensor([0.5649, 0.7241, 0.6721, 0.6589, 0.6331, 0.7363, 0.6675, 0.5648, 0.7075,
        0.6797, 0.7613, 0.6774, 0.7497, 0.7374, 0.5001, 0.4833],
       device='cuda:0') torch.Size([16])
percent tensor([0.7000, 0.7597, 0.7110, 0.6525, 0.6366, 0.7243, 0.7400, 0.6433, 0.6887,
        0.7475, 0.7371, 0.6383, 0.7660, 0.7239, 0.5596, 0.6052],
       device='cuda:0') torch.Size([16])
percent tensor([0.9998, 0.9999, 0.9999, 0.9999, 0.9998, 0.9998, 0.9999, 0.9998, 0.9999,
        0.9999, 1.0000, 0.9998, 0.9998, 0.9998, 0.9999, 0.9995],
       device='cuda:0') torch.Size([16])
Epoch: 217 | Batch_idx: 0 |  Loss: (0.0421) |  Loss2: (0.0000) | Acc: (98.00%) (126/128)
Epoch: 217 | Batch_idx: 10 |  Loss: (0.0423) |  Loss2: (0.0000) | Acc: (98.00%) (1393/1408)
Epoch: 217 | Batch_idx: 20 |  Loss: (0.0429) |  Loss2: (0.0000) | Acc: (98.00%) (2657/2688)
Epoch: 217 | Batch_idx: 30 |  Loss: (0.0472) |  Loss2: (0.0000) | Acc: (98.00%) (3911/3968)
Epoch: 217 | Batch_idx: 40 |  Loss: (0.0467) |  Loss2: (0.0000) | Acc: (98.00%) (5168/5248)
Epoch: 217 | Batch_idx: 50 |  Loss: (0.0464) |  Loss2: (0.0000) | Acc: (98.00%) (6434/6528)
Epoch: 217 | Batch_idx: 60 |  Loss: (0.0464) |  Loss2: (0.0000) | Acc: (98.00%) (7694/7808)
Epoch: 217 | Batch_idx: 70 |  Loss: (0.0460) |  Loss2: (0.0000) | Acc: (98.00%) (8958/9088)
Epoch: 217 | Batch_idx: 80 |  Loss: (0.0463) |  Loss2: (0.0000) | Acc: (98.00%) (10221/10368)
Epoch: 217 | Batch_idx: 90 |  Loss: (0.0468) |  Loss2: (0.0000) | Acc: (98.00%) (11482/11648)
Epoch: 217 | Batch_idx: 100 |  Loss: (0.0468) |  Loss2: (0.0000) | Acc: (98.00%) (12745/12928)
Epoch: 217 | Batch_idx: 110 |  Loss: (0.0467) |  Loss2: (0.0000) | Acc: (98.00%) (14006/14208)
Epoch: 217 | Batch_idx: 120 |  Loss: (0.0460) |  Loss2: (0.0000) | Acc: (98.00%) (15271/15488)
Epoch: 217 | Batch_idx: 130 |  Loss: (0.0458) |  Loss2: (0.0000) | Acc: (98.00%) (16536/16768)
Epoch: 217 | Batch_idx: 140 |  Loss: (0.0458) |  Loss2: (0.0000) | Acc: (98.00%) (17797/18048)
Epoch: 217 | Batch_idx: 150 |  Loss: (0.0457) |  Loss2: (0.0000) | Acc: (98.00%) (19063/19328)
Epoch: 217 | Batch_idx: 160 |  Loss: (0.0465) |  Loss2: (0.0000) | Acc: (98.00%) (20317/20608)
Epoch: 217 | Batch_idx: 170 |  Loss: (0.0462) |  Loss2: (0.0000) | Acc: (98.00%) (21580/21888)
Epoch: 217 | Batch_idx: 180 |  Loss: (0.0460) |  Loss2: (0.0000) | Acc: (98.00%) (22844/23168)
Epoch: 217 | Batch_idx: 190 |  Loss: (0.0459) |  Loss2: (0.0000) | Acc: (98.00%) (24105/24448)
Epoch: 217 | Batch_idx: 200 |  Loss: (0.0461) |  Loss2: (0.0000) | Acc: (98.00%) (25364/25728)
Epoch: 217 | Batch_idx: 210 |  Loss: (0.0465) |  Loss2: (0.0000) | Acc: (98.00%) (26624/27008)
Epoch: 217 | Batch_idx: 220 |  Loss: (0.0466) |  Loss2: (0.0000) | Acc: (98.00%) (27882/28288)
Epoch: 217 | Batch_idx: 230 |  Loss: (0.0477) |  Loss2: (0.0000) | Acc: (98.00%) (29127/29568)
Epoch: 217 | Batch_idx: 240 |  Loss: (0.0478) |  Loss2: (0.0000) | Acc: (98.00%) (30386/30848)
Epoch: 217 | Batch_idx: 250 |  Loss: (0.0481) |  Loss2: (0.0000) | Acc: (98.00%) (31641/32128)
Epoch: 217 | Batch_idx: 260 |  Loss: (0.0489) |  Loss2: (0.0000) | Acc: (98.00%) (32887/33408)
Epoch: 217 | Batch_idx: 270 |  Loss: (0.0492) |  Loss2: (0.0000) | Acc: (98.00%) (34147/34688)
Epoch: 217 | Batch_idx: 280 |  Loss: (0.0493) |  Loss2: (0.0000) | Acc: (98.00%) (35401/35968)
Epoch: 217 | Batch_idx: 290 |  Loss: (0.0496) |  Loss2: (0.0000) | Acc: (98.00%) (36658/37248)
Epoch: 217 | Batch_idx: 300 |  Loss: (0.0499) |  Loss2: (0.0000) | Acc: (98.00%) (37915/38528)
Epoch: 217 | Batch_idx: 310 |  Loss: (0.0504) |  Loss2: (0.0000) | Acc: (98.00%) (39167/39808)
Epoch: 217 | Batch_idx: 320 |  Loss: (0.0509) |  Loss2: (0.0000) | Acc: (98.00%) (40421/41088)
Epoch: 217 | Batch_idx: 330 |  Loss: (0.0505) |  Loss2: (0.0000) | Acc: (98.00%) (41687/42368)
Epoch: 217 | Batch_idx: 340 |  Loss: (0.0511) |  Loss2: (0.0000) | Acc: (98.00%) (42935/43648)
Epoch: 217 | Batch_idx: 350 |  Loss: (0.0512) |  Loss2: (0.0000) | Acc: (98.00%) (44188/44928)
Epoch: 217 | Batch_idx: 360 |  Loss: (0.0511) |  Loss2: (0.0000) | Acc: (98.00%) (45448/46208)
Epoch: 217 | Batch_idx: 370 |  Loss: (0.0515) |  Loss2: (0.0000) | Acc: (98.00%) (46700/47488)
Epoch: 217 | Batch_idx: 380 |  Loss: (0.0520) |  Loss2: (0.0000) | Acc: (98.00%) (47953/48768)
Epoch: 217 | Batch_idx: 390 |  Loss: (0.0519) |  Loss2: (0.0000) | Acc: (98.00%) (49165/50000)
# TEST : Loss: (0.5182) | Acc: (87.00%) (8731/10000)
percent tensor([0.5805, 0.5944, 0.6255, 0.6156, 0.6286, 0.5908, 0.6062, 0.6225, 0.5931,
        0.6020, 0.5774, 0.6179, 0.5819, 0.5920, 0.5963, 0.5873],
       device='cuda:0') torch.Size([16])
percent tensor([0.5848, 0.5902, 0.5779, 0.5756, 0.5855, 0.5839, 0.5949, 0.5855, 0.5798,
        0.5868, 0.5881, 0.5906, 0.5839, 0.5853, 0.5926, 0.5865],
       device='cuda:0') torch.Size([16])
percent tensor([0.6364, 0.6550, 0.5937, 0.5631, 0.5665, 0.5939, 0.6319, 0.5858, 0.6193,
        0.6566, 0.6445, 0.6182, 0.6757, 0.6415, 0.6259, 0.6410],
       device='cuda:0') torch.Size([16])
percent tensor([0.6963, 0.6859, 0.6549, 0.6602, 0.6655, 0.7112, 0.6970, 0.6595, 0.6773,
        0.6893, 0.6910, 0.6748, 0.6902, 0.6910, 0.6967, 0.7011],
       device='cuda:0') torch.Size([16])
percent tensor([0.5936, 0.5342, 0.6629, 0.6961, 0.6943, 0.6378, 0.6065, 0.6656, 0.6382,
        0.5680, 0.6010, 0.6117, 0.4707, 0.6625, 0.6262, 0.6189],
       device='cuda:0') torch.Size([16])
percent tensor([0.5728, 0.7293, 0.6672, 0.6655, 0.6348, 0.7524, 0.6744, 0.5695, 0.6862,
        0.6877, 0.7589, 0.6575, 0.7289, 0.7233, 0.5214, 0.5252],
       device='cuda:0') torch.Size([16])
percent tensor([0.7111, 0.7635, 0.7163, 0.6343, 0.6314, 0.7319, 0.7509, 0.6616, 0.6779,
        0.7409, 0.7419, 0.6302, 0.7525, 0.7241, 0.5612, 0.6233],
       device='cuda:0') torch.Size([16])
percent tensor([0.9998, 0.9999, 0.9999, 0.9999, 0.9998, 0.9997, 1.0000, 0.9999, 0.9999,
        0.9999, 0.9999, 0.9998, 0.9998, 0.9998, 0.9998, 0.9992],
       device='cuda:0') torch.Size([16])
Epoch: 218 | Batch_idx: 0 |  Loss: (0.0591) |  Loss2: (0.0000) | Acc: (97.00%) (125/128)
Epoch: 218 | Batch_idx: 10 |  Loss: (0.0529) |  Loss2: (0.0000) | Acc: (98.00%) (1380/1408)
Epoch: 218 | Batch_idx: 20 |  Loss: (0.0551) |  Loss2: (0.0000) | Acc: (98.00%) (2636/2688)
Epoch: 218 | Batch_idx: 30 |  Loss: (0.0505) |  Loss2: (0.0000) | Acc: (98.00%) (3896/3968)
Epoch: 218 | Batch_idx: 40 |  Loss: (0.0500) |  Loss2: (0.0000) | Acc: (98.00%) (5154/5248)
Epoch: 218 | Batch_idx: 50 |  Loss: (0.0496) |  Loss2: (0.0000) | Acc: (98.00%) (6415/6528)
Epoch: 218 | Batch_idx: 60 |  Loss: (0.0523) |  Loss2: (0.0000) | Acc: (98.00%) (7672/7808)
Epoch: 218 | Batch_idx: 70 |  Loss: (0.0545) |  Loss2: (0.0000) | Acc: (98.00%) (8919/9088)
Epoch: 218 | Batch_idx: 80 |  Loss: (0.0547) |  Loss2: (0.0000) | Acc: (98.00%) (10176/10368)
Epoch: 218 | Batch_idx: 90 |  Loss: (0.0534) |  Loss2: (0.0000) | Acc: (98.00%) (11438/11648)
Epoch: 218 | Batch_idx: 100 |  Loss: (0.0541) |  Loss2: (0.0000) | Acc: (98.00%) (12693/12928)
Epoch: 218 | Batch_idx: 110 |  Loss: (0.0540) |  Loss2: (0.0000) | Acc: (98.00%) (13954/14208)
Epoch: 218 | Batch_idx: 120 |  Loss: (0.0537) |  Loss2: (0.0000) | Acc: (98.00%) (15217/15488)
Epoch: 218 | Batch_idx: 130 |  Loss: (0.0534) |  Loss2: (0.0000) | Acc: (98.00%) (16476/16768)
Epoch: 218 | Batch_idx: 140 |  Loss: (0.0530) |  Loss2: (0.0000) | Acc: (98.00%) (17739/18048)
Epoch: 218 | Batch_idx: 150 |  Loss: (0.0536) |  Loss2: (0.0000) | Acc: (98.00%) (18995/19328)
Epoch: 218 | Batch_idx: 160 |  Loss: (0.0543) |  Loss2: (0.0000) | Acc: (98.00%) (20249/20608)
Epoch: 218 | Batch_idx: 170 |  Loss: (0.0546) |  Loss2: (0.0000) | Acc: (98.00%) (21504/21888)
Epoch: 218 | Batch_idx: 180 |  Loss: (0.0555) |  Loss2: (0.0000) | Acc: (98.00%) (22750/23168)
Epoch: 218 | Batch_idx: 190 |  Loss: (0.0552) |  Loss2: (0.0000) | Acc: (98.00%) (24009/24448)
Epoch: 218 | Batch_idx: 200 |  Loss: (0.0549) |  Loss2: (0.0000) | Acc: (98.00%) (25270/25728)
Epoch: 218 | Batch_idx: 210 |  Loss: (0.0555) |  Loss2: (0.0000) | Acc: (98.00%) (26517/27008)
Epoch: 218 | Batch_idx: 220 |  Loss: (0.0552) |  Loss2: (0.0000) | Acc: (98.00%) (27773/28288)
Epoch: 218 | Batch_idx: 230 |  Loss: (0.0556) |  Loss2: (0.0000) | Acc: (98.00%) (29024/29568)
Epoch: 218 | Batch_idx: 240 |  Loss: (0.0557) |  Loss2: (0.0000) | Acc: (98.00%) (30281/30848)
Epoch: 218 | Batch_idx: 250 |  Loss: (0.0555) |  Loss2: (0.0000) | Acc: (98.00%) (31545/32128)
Epoch: 218 | Batch_idx: 260 |  Loss: (0.0553) |  Loss2: (0.0000) | Acc: (98.00%) (32807/33408)
Epoch: 218 | Batch_idx: 270 |  Loss: (0.0552) |  Loss2: (0.0000) | Acc: (98.00%) (34066/34688)
Epoch: 218 | Batch_idx: 280 |  Loss: (0.0552) |  Loss2: (0.0000) | Acc: (98.00%) (35325/35968)
Epoch: 218 | Batch_idx: 290 |  Loss: (0.0551) |  Loss2: (0.0000) | Acc: (98.00%) (36585/37248)
Epoch: 218 | Batch_idx: 300 |  Loss: (0.0551) |  Loss2: (0.0000) | Acc: (98.00%) (37835/38528)
Epoch: 218 | Batch_idx: 310 |  Loss: (0.0554) |  Loss2: (0.0000) | Acc: (98.00%) (39085/39808)
Epoch: 218 | Batch_idx: 320 |  Loss: (0.0555) |  Loss2: (0.0000) | Acc: (98.00%) (40340/41088)
Epoch: 218 | Batch_idx: 330 |  Loss: (0.0551) |  Loss2: (0.0000) | Acc: (98.00%) (41605/42368)
Epoch: 218 | Batch_idx: 340 |  Loss: (0.0549) |  Loss2: (0.0000) | Acc: (98.00%) (42867/43648)
Epoch: 218 | Batch_idx: 350 |  Loss: (0.0548) |  Loss2: (0.0000) | Acc: (98.00%) (44126/44928)
Epoch: 218 | Batch_idx: 360 |  Loss: (0.0547) |  Loss2: (0.0000) | Acc: (98.00%) (45383/46208)
Epoch: 218 | Batch_idx: 370 |  Loss: (0.0546) |  Loss2: (0.0000) | Acc: (98.00%) (46644/47488)
Epoch: 218 | Batch_idx: 380 |  Loss: (0.0546) |  Loss2: (0.0000) | Acc: (98.00%) (47899/48768)
Epoch: 218 | Batch_idx: 390 |  Loss: (0.0545) |  Loss2: (0.0000) | Acc: (98.00%) (49111/50000)
# TEST : Loss: (0.4300) | Acc: (89.00%) (8916/10000)
percent tensor([0.5783, 0.5921, 0.6183, 0.6122, 0.6213, 0.5895, 0.6023, 0.6183, 0.5899,
        0.5979, 0.5750, 0.6112, 0.5796, 0.5917, 0.5942, 0.5850],
       device='cuda:0') torch.Size([16])
percent tensor([0.5847, 0.5904, 0.5779, 0.5743, 0.5861, 0.5840, 0.5952, 0.5848, 0.5799,
        0.5866, 0.5880, 0.5908, 0.5844, 0.5846, 0.5926, 0.5857],
       device='cuda:0') torch.Size([16])
percent tensor([0.6466, 0.6638, 0.6210, 0.5774, 0.5874, 0.5974, 0.6429, 0.5978, 0.6312,
        0.6679, 0.6510, 0.6392, 0.6858, 0.6465, 0.6309, 0.6512],
       device='cuda:0') torch.Size([16])
percent tensor([0.6990, 0.6860, 0.6634, 0.6610, 0.6706, 0.7111, 0.6992, 0.6622, 0.6808,
        0.6897, 0.6923, 0.6819, 0.6936, 0.6881, 0.6997, 0.6997],
       device='cuda:0') torch.Size([16])
percent tensor([0.5807, 0.5241, 0.6528, 0.6922, 0.6826, 0.6361, 0.5985, 0.6644, 0.6341,
        0.5546, 0.5910, 0.6011, 0.4614, 0.6595, 0.6228, 0.6172],
       device='cuda:0') torch.Size([16])
percent tensor([0.5609, 0.7324, 0.7048, 0.6631, 0.6647, 0.7446, 0.7050, 0.5809, 0.6925,
        0.6799, 0.7509, 0.6608, 0.7250, 0.7244, 0.5028, 0.4938],
       device='cuda:0') torch.Size([16])
percent tensor([0.6738, 0.7610, 0.7215, 0.6356, 0.6440, 0.7285, 0.7473, 0.6567, 0.6828,
        0.7252, 0.7241, 0.6011, 0.7384, 0.7010, 0.5419, 0.6039],
       device='cuda:0') torch.Size([16])
percent tensor([0.9998, 0.9999, 0.9999, 0.9999, 0.9997, 0.9998, 0.9999, 0.9999, 0.9999,
        0.9999, 1.0000, 0.9998, 0.9998, 0.9996, 0.9999, 0.9993],
       device='cuda:0') torch.Size([16])
Epoch: 219 | Batch_idx: 0 |  Loss: (0.0515) |  Loss2: (0.0000) | Acc: (97.00%) (125/128)
Epoch: 219 | Batch_idx: 10 |  Loss: (0.0440) |  Loss2: (0.0000) | Acc: (98.00%) (1387/1408)
Epoch: 219 | Batch_idx: 20 |  Loss: (0.0442) |  Loss2: (0.0000) | Acc: (98.00%) (2649/2688)
Epoch: 219 | Batch_idx: 30 |  Loss: (0.0495) |  Loss2: (0.0000) | Acc: (98.00%) (3900/3968)
Epoch: 219 | Batch_idx: 40 |  Loss: (0.0506) |  Loss2: (0.0000) | Acc: (98.00%) (5158/5248)
Epoch: 219 | Batch_idx: 50 |  Loss: (0.0509) |  Loss2: (0.0000) | Acc: (98.00%) (6409/6528)
Epoch: 219 | Batch_idx: 60 |  Loss: (0.0501) |  Loss2: (0.0000) | Acc: (98.00%) (7669/7808)
Epoch: 219 | Batch_idx: 70 |  Loss: (0.0484) |  Loss2: (0.0000) | Acc: (98.00%) (8934/9088)
Epoch: 219 | Batch_idx: 80 |  Loss: (0.0482) |  Loss2: (0.0000) | Acc: (98.00%) (10197/10368)
Epoch: 219 | Batch_idx: 90 |  Loss: (0.0488) |  Loss2: (0.0000) | Acc: (98.00%) (11457/11648)
Epoch: 219 | Batch_idx: 100 |  Loss: (0.0482) |  Loss2: (0.0000) | Acc: (98.00%) (12719/12928)
Epoch: 219 | Batch_idx: 110 |  Loss: (0.0478) |  Loss2: (0.0000) | Acc: (98.00%) (13980/14208)
Epoch: 219 | Batch_idx: 120 |  Loss: (0.0486) |  Loss2: (0.0000) | Acc: (98.00%) (15233/15488)
Epoch: 219 | Batch_idx: 130 |  Loss: (0.0480) |  Loss2: (0.0000) | Acc: (98.00%) (16493/16768)
Epoch: 219 | Batch_idx: 140 |  Loss: (0.0480) |  Loss2: (0.0000) | Acc: (98.00%) (17752/18048)
Epoch: 219 | Batch_idx: 150 |  Loss: (0.0482) |  Loss2: (0.0000) | Acc: (98.00%) (19009/19328)
Epoch: 219 | Batch_idx: 160 |  Loss: (0.0479) |  Loss2: (0.0000) | Acc: (98.00%) (20273/20608)
Epoch: 219 | Batch_idx: 170 |  Loss: (0.0485) |  Loss2: (0.0000) | Acc: (98.00%) (21529/21888)
Epoch: 219 | Batch_idx: 180 |  Loss: (0.0482) |  Loss2: (0.0000) | Acc: (98.00%) (22792/23168)
Epoch: 219 | Batch_idx: 190 |  Loss: (0.0474) |  Loss2: (0.0000) | Acc: (98.00%) (24061/24448)
Epoch: 219 | Batch_idx: 200 |  Loss: (0.0480) |  Loss2: (0.0000) | Acc: (98.00%) (25315/25728)
Epoch: 219 | Batch_idx: 210 |  Loss: (0.0481) |  Loss2: (0.0000) | Acc: (98.00%) (26569/27008)
Epoch: 219 | Batch_idx: 220 |  Loss: (0.0485) |  Loss2: (0.0000) | Acc: (98.00%) (27830/28288)
Epoch: 219 | Batch_idx: 230 |  Loss: (0.0490) |  Loss2: (0.0000) | Acc: (98.00%) (29082/29568)
Epoch: 219 | Batch_idx: 240 |  Loss: (0.0489) |  Loss2: (0.0000) | Acc: (98.00%) (30340/30848)
Epoch: 219 | Batch_idx: 250 |  Loss: (0.0489) |  Loss2: (0.0000) | Acc: (98.00%) (31606/32128)
Epoch: 219 | Batch_idx: 260 |  Loss: (0.0495) |  Loss2: (0.0000) | Acc: (98.00%) (32858/33408)
Epoch: 219 | Batch_idx: 270 |  Loss: (0.0497) |  Loss2: (0.0000) | Acc: (98.00%) (34115/34688)
Epoch: 219 | Batch_idx: 280 |  Loss: (0.0504) |  Loss2: (0.0000) | Acc: (98.00%) (35362/35968)
Epoch: 219 | Batch_idx: 290 |  Loss: (0.0504) |  Loss2: (0.0000) | Acc: (98.00%) (36616/37248)
Epoch: 219 | Batch_idx: 300 |  Loss: (0.0505) |  Loss2: (0.0000) | Acc: (98.00%) (37869/38528)
Epoch: 219 | Batch_idx: 310 |  Loss: (0.0504) |  Loss2: (0.0000) | Acc: (98.00%) (39130/39808)
Epoch: 219 | Batch_idx: 320 |  Loss: (0.0504) |  Loss2: (0.0000) | Acc: (98.00%) (40388/41088)
Epoch: 219 | Batch_idx: 330 |  Loss: (0.0501) |  Loss2: (0.0000) | Acc: (98.00%) (41649/42368)
Epoch: 219 | Batch_idx: 340 |  Loss: (0.0502) |  Loss2: (0.0000) | Acc: (98.00%) (42910/43648)
Epoch: 219 | Batch_idx: 350 |  Loss: (0.0500) |  Loss2: (0.0000) | Acc: (98.00%) (44170/44928)
Epoch: 219 | Batch_idx: 360 |  Loss: (0.0500) |  Loss2: (0.0000) | Acc: (98.00%) (45429/46208)
Epoch: 219 | Batch_idx: 370 |  Loss: (0.0503) |  Loss2: (0.0000) | Acc: (98.00%) (46682/47488)
Epoch: 219 | Batch_idx: 380 |  Loss: (0.0502) |  Loss2: (0.0000) | Acc: (98.00%) (47943/48768)
Epoch: 219 | Batch_idx: 390 |  Loss: (0.0502) |  Loss2: (0.0000) | Acc: (98.00%) (49154/50000)
# TEST : Loss: (0.4483) | Acc: (88.00%) (8863/10000)
percent tensor([0.5790, 0.5917, 0.6214, 0.6119, 0.6246, 0.5892, 0.6040, 0.6188, 0.5919,
        0.5987, 0.5766, 0.6142, 0.5802, 0.5924, 0.5935, 0.5853],
       device='cuda:0') torch.Size([16])
percent tensor([0.5853, 0.5915, 0.5785, 0.5761, 0.5865, 0.5846, 0.5955, 0.5851, 0.5813,
        0.5869, 0.5889, 0.5911, 0.5845, 0.5856, 0.5935, 0.5863],
       device='cuda:0') torch.Size([16])
percent tensor([0.6464, 0.6660, 0.6114, 0.5753, 0.5841, 0.6001, 0.6429, 0.5954, 0.6283,
        0.6662, 0.6526, 0.6314, 0.6847, 0.6451, 0.6340, 0.6514],
       device='cuda:0') torch.Size([16])
percent tensor([0.6989, 0.6898, 0.6628, 0.6635, 0.6711, 0.7100, 0.7033, 0.6626, 0.6809,
        0.6932, 0.6963, 0.6809, 0.6933, 0.6938, 0.7014, 0.7018],
       device='cuda:0') torch.Size([16])
percent tensor([0.5842, 0.5146, 0.6546, 0.6943, 0.6848, 0.6405, 0.5840, 0.6626, 0.6276,
        0.5536, 0.5959, 0.6014, 0.4653, 0.6460, 0.6258, 0.6060],
       device='cuda:0') torch.Size([16])
percent tensor([0.5963, 0.7446, 0.7012, 0.6723, 0.6577, 0.7585, 0.7144, 0.5814, 0.7128,
        0.6965, 0.7786, 0.7042, 0.7565, 0.7487, 0.5254, 0.5278],
       device='cuda:0') torch.Size([16])
percent tensor([0.6966, 0.7510, 0.7154, 0.6369, 0.6290, 0.7312, 0.7282, 0.6375, 0.6874,
        0.7339, 0.7369, 0.6181, 0.7603, 0.7118, 0.5387, 0.5993],
       device='cuda:0') torch.Size([16])
percent tensor([0.9997, 0.9999, 0.9998, 0.9997, 0.9998, 0.9997, 0.9999, 0.9998, 0.9999,
        1.0000, 1.0000, 0.9997, 0.9999, 0.9997, 0.9999, 0.9993],
       device='cuda:0') torch.Size([16])
Epoch: 220 | Batch_idx: 0 |  Loss: (0.0386) |  Loss2: (0.0000) | Acc: (98.00%) (126/128)
Epoch: 220 | Batch_idx: 10 |  Loss: (0.0642) |  Loss2: (0.0000) | Acc: (98.00%) (1380/1408)
Epoch: 220 | Batch_idx: 20 |  Loss: (0.0560) |  Loss2: (0.0000) | Acc: (98.00%) (2640/2688)
Epoch: 220 | Batch_idx: 30 |  Loss: (0.0514) |  Loss2: (0.0000) | Acc: (98.00%) (3902/3968)
Epoch: 220 | Batch_idx: 40 |  Loss: (0.0509) |  Loss2: (0.0000) | Acc: (98.00%) (5163/5248)
Epoch: 220 | Batch_idx: 50 |  Loss: (0.0508) |  Loss2: (0.0000) | Acc: (98.00%) (6421/6528)
Epoch: 220 | Batch_idx: 60 |  Loss: (0.0498) |  Loss2: (0.0000) | Acc: (98.00%) (7688/7808)
Epoch: 220 | Batch_idx: 70 |  Loss: (0.0513) |  Loss2: (0.0000) | Acc: (98.00%) (8943/9088)
Epoch: 220 | Batch_idx: 80 |  Loss: (0.0509) |  Loss2: (0.0000) | Acc: (98.00%) (10201/10368)
Epoch: 220 | Batch_idx: 90 |  Loss: (0.0500) |  Loss2: (0.0000) | Acc: (98.00%) (11468/11648)
Epoch: 220 | Batch_idx: 100 |  Loss: (0.0489) |  Loss2: (0.0000) | Acc: (98.00%) (12734/12928)
Epoch: 220 | Batch_idx: 110 |  Loss: (0.0487) |  Loss2: (0.0000) | Acc: (98.00%) (13996/14208)
Epoch: 220 | Batch_idx: 120 |  Loss: (0.0498) |  Loss2: (0.0000) | Acc: (98.00%) (15248/15488)
Epoch: 220 | Batch_idx: 130 |  Loss: (0.0494) |  Loss2: (0.0000) | Acc: (98.00%) (16511/16768)
Epoch: 220 | Batch_idx: 140 |  Loss: (0.0492) |  Loss2: (0.0000) | Acc: (98.00%) (17772/18048)
Epoch: 220 | Batch_idx: 150 |  Loss: (0.0494) |  Loss2: (0.0000) | Acc: (98.00%) (19028/19328)
Epoch: 220 | Batch_idx: 160 |  Loss: (0.0490) |  Loss2: (0.0000) | Acc: (98.00%) (20289/20608)
Epoch: 220 | Batch_idx: 170 |  Loss: (0.0493) |  Loss2: (0.0000) | Acc: (98.00%) (21544/21888)
Epoch: 220 | Batch_idx: 180 |  Loss: (0.0488) |  Loss2: (0.0000) | Acc: (98.00%) (22804/23168)
Epoch: 220 | Batch_idx: 190 |  Loss: (0.0489) |  Loss2: (0.0000) | Acc: (98.00%) (24065/24448)
Epoch: 220 | Batch_idx: 200 |  Loss: (0.0493) |  Loss2: (0.0000) | Acc: (98.00%) (25322/25728)
Epoch: 220 | Batch_idx: 210 |  Loss: (0.0497) |  Loss2: (0.0000) | Acc: (98.00%) (26577/27008)
Epoch: 220 | Batch_idx: 220 |  Loss: (0.0496) |  Loss2: (0.0000) | Acc: (98.00%) (27839/28288)
Epoch: 220 | Batch_idx: 230 |  Loss: (0.0499) |  Loss2: (0.0000) | Acc: (98.00%) (29100/29568)
Epoch: 220 | Batch_idx: 240 |  Loss: (0.0502) |  Loss2: (0.0000) | Acc: (98.00%) (30352/30848)
Epoch: 220 | Batch_idx: 250 |  Loss: (0.0498) |  Loss2: (0.0000) | Acc: (98.00%) (31616/32128)
Epoch: 220 | Batch_idx: 260 |  Loss: (0.0494) |  Loss2: (0.0000) | Acc: (98.00%) (32880/33408)
Epoch: 220 | Batch_idx: 270 |  Loss: (0.0493) |  Loss2: (0.0000) | Acc: (98.00%) (34138/34688)
Epoch: 220 | Batch_idx: 280 |  Loss: (0.0498) |  Loss2: (0.0000) | Acc: (98.00%) (35389/35968)
Epoch: 220 | Batch_idx: 290 |  Loss: (0.0496) |  Loss2: (0.0000) | Acc: (98.00%) (36654/37248)
Epoch: 220 | Batch_idx: 300 |  Loss: (0.0492) |  Loss2: (0.0000) | Acc: (98.00%) (37921/38528)
Epoch: 220 | Batch_idx: 310 |  Loss: (0.0489) |  Loss2: (0.0000) | Acc: (98.00%) (39186/39808)
Epoch: 220 | Batch_idx: 320 |  Loss: (0.0488) |  Loss2: (0.0000) | Acc: (98.00%) (40447/41088)
Epoch: 220 | Batch_idx: 330 |  Loss: (0.0490) |  Loss2: (0.0000) | Acc: (98.00%) (41701/42368)
Epoch: 220 | Batch_idx: 340 |  Loss: (0.0493) |  Loss2: (0.0000) | Acc: (98.00%) (42949/43648)
Epoch: 220 | Batch_idx: 350 |  Loss: (0.0495) |  Loss2: (0.0000) | Acc: (98.00%) (44204/44928)
Epoch: 220 | Batch_idx: 360 |  Loss: (0.0495) |  Loss2: (0.0000) | Acc: (98.00%) (45461/46208)
Epoch: 220 | Batch_idx: 370 |  Loss: (0.0495) |  Loss2: (0.0000) | Acc: (98.00%) (46720/47488)
Epoch: 220 | Batch_idx: 380 |  Loss: (0.0497) |  Loss2: (0.0000) | Acc: (98.00%) (47978/48768)
Epoch: 220 | Batch_idx: 390 |  Loss: (0.0499) |  Loss2: (0.0000) | Acc: (98.00%) (49186/50000)
=> saving checkpoint 'drive/app/torch/save_Schedule/checkpoint_220.pth.tar'
# TEST : Loss: (0.4688) | Acc: (88.00%) (8878/10000)
percent tensor([0.5768, 0.5914, 0.6204, 0.6099, 0.6235, 0.5860, 0.6032, 0.6175, 0.5913,
        0.5978, 0.5761, 0.6128, 0.5791, 0.5920, 0.5918, 0.5834],
       device='cuda:0') torch.Size([16])
percent tensor([0.5857, 0.5904, 0.5805, 0.5755, 0.5878, 0.5834, 0.5954, 0.5867, 0.5813,
        0.5872, 0.5883, 0.5922, 0.5846, 0.5845, 0.5920, 0.5862],
       device='cuda:0') torch.Size([16])
percent tensor([0.6439, 0.6646, 0.6044, 0.5729, 0.5795, 0.6051, 0.6380, 0.5891, 0.6252,
        0.6631, 0.6504, 0.6314, 0.6824, 0.6432, 0.6347, 0.6479],
       device='cuda:0') torch.Size([16])
percent tensor([0.6968, 0.6876, 0.6575, 0.6564, 0.6676, 0.7095, 0.6982, 0.6604, 0.6794,
        0.6912, 0.6933, 0.6811, 0.6919, 0.6891, 0.6991, 0.6989],
       device='cuda:0') torch.Size([16])
percent tensor([0.5777, 0.5202, 0.6457, 0.6864, 0.6798, 0.6149, 0.5929, 0.6649, 0.6245,
        0.5368, 0.5861, 0.5816, 0.4498, 0.6585, 0.6208, 0.5994],
       device='cuda:0') torch.Size([16])
percent tensor([0.5594, 0.7331, 0.6762, 0.6409, 0.6146, 0.7465, 0.6991, 0.5730, 0.6959,
        0.6825, 0.7711, 0.6695, 0.7510, 0.7082, 0.4967, 0.4923],
       device='cuda:0') torch.Size([16])
percent tensor([0.6905, 0.7459, 0.7112, 0.6411, 0.6333, 0.7274, 0.7434, 0.6609, 0.6808,
        0.7168, 0.7351, 0.6286, 0.7583, 0.6956, 0.5375, 0.5985],
       device='cuda:0') torch.Size([16])
percent tensor([0.9998, 0.9999, 1.0000, 0.9999, 0.9998, 0.9998, 0.9999, 0.9999, 0.9999,
        0.9999, 0.9999, 0.9997, 0.9999, 0.9998, 0.9998, 0.9994],
       device='cuda:0') torch.Size([16])
Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 3, 3, 3]) tensor(193.1735, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(834.6865, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(858.1613, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([128, 64, 3, 3]) tensor(1524.2832, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([128, 64, 1, 1]) tensor(478.9214, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([128, 128, 3, 3]) tensor(2318.0471, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([256, 128, 3, 3]) tensor(4249.4585, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([256, 128, 1, 1]) tensor(1331.8026, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([256, 256, 3, 3]) tensor(6335.1494, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([512, 256, 3, 3]) tensor(11478.3662, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([512, 256, 1, 1]) tensor(3760.1577, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([512, 512, 3, 3]) tensor(15863.5879, device='cuda:0', grad_fn=<NormBackward0>)
Epoch: 221 | Batch_idx: 0 |  Loss: (0.0429) |  Loss2: (0.0000) | Acc: (98.00%) (126/128)
Epoch: 221 | Batch_idx: 10 |  Loss: (0.0448) |  Loss2: (0.0000) | Acc: (98.00%) (1388/1408)
Epoch: 221 | Batch_idx: 20 |  Loss: (0.0461) |  Loss2: (0.0000) | Acc: (98.00%) (2648/2688)
Epoch: 221 | Batch_idx: 30 |  Loss: (0.0464) |  Loss2: (0.0000) | Acc: (98.00%) (3909/3968)
Epoch: 221 | Batch_idx: 40 |  Loss: (0.0448) |  Loss2: (0.0000) | Acc: (98.00%) (5173/5248)
Epoch: 221 | Batch_idx: 50 |  Loss: (0.0442) |  Loss2: (0.0000) | Acc: (98.00%) (6441/6528)
Epoch: 221 | Batch_idx: 60 |  Loss: (0.0436) |  Loss2: (0.0000) | Acc: (98.00%) (7707/7808)
Epoch: 221 | Batch_idx: 70 |  Loss: (0.0432) |  Loss2: (0.0000) | Acc: (98.00%) (8968/9088)
Epoch: 221 | Batch_idx: 80 |  Loss: (0.0443) |  Loss2: (0.0000) | Acc: (98.00%) (10233/10368)
Epoch: 221 | Batch_idx: 90 |  Loss: (0.0439) |  Loss2: (0.0000) | Acc: (98.00%) (11496/11648)
Epoch: 221 | Batch_idx: 100 |  Loss: (0.0428) |  Loss2: (0.0000) | Acc: (98.00%) (12765/12928)
Epoch: 221 | Batch_idx: 110 |  Loss: (0.0431) |  Loss2: (0.0000) | Acc: (98.00%) (14026/14208)
Epoch: 221 | Batch_idx: 120 |  Loss: (0.0433) |  Loss2: (0.0000) | Acc: (98.00%) (15289/15488)
Epoch: 221 | Batch_idx: 130 |  Loss: (0.0442) |  Loss2: (0.0000) | Acc: (98.00%) (16542/16768)
Epoch: 221 | Batch_idx: 140 |  Loss: (0.0441) |  Loss2: (0.0000) | Acc: (98.00%) (17806/18048)
Epoch: 221 | Batch_idx: 150 |  Loss: (0.0443) |  Loss2: (0.0000) | Acc: (98.00%) (19067/19328)
Epoch: 221 | Batch_idx: 160 |  Loss: (0.0441) |  Loss2: (0.0000) | Acc: (98.00%) (20330/20608)
Epoch: 221 | Batch_idx: 170 |  Loss: (0.0440) |  Loss2: (0.0000) | Acc: (98.00%) (21594/21888)
Epoch: 221 | Batch_idx: 180 |  Loss: (0.0452) |  Loss2: (0.0000) | Acc: (98.00%) (22847/23168)
Epoch: 221 | Batch_idx: 190 |  Loss: (0.0447) |  Loss2: (0.0000) | Acc: (98.00%) (24115/24448)
Epoch: 221 | Batch_idx: 200 |  Loss: (0.0450) |  Loss2: (0.0000) | Acc: (98.00%) (25374/25728)
Epoch: 221 | Batch_idx: 210 |  Loss: (0.0451) |  Loss2: (0.0000) | Acc: (98.00%) (26629/27008)
Epoch: 221 | Batch_idx: 220 |  Loss: (0.0449) |  Loss2: (0.0000) | Acc: (98.00%) (27892/28288)
Epoch: 221 | Batch_idx: 230 |  Loss: (0.0450) |  Loss2: (0.0000) | Acc: (98.00%) (29154/29568)
Epoch: 221 | Batch_idx: 240 |  Loss: (0.0451) |  Loss2: (0.0000) | Acc: (98.00%) (30414/30848)
Epoch: 221 | Batch_idx: 250 |  Loss: (0.0453) |  Loss2: (0.0000) | Acc: (98.00%) (31675/32128)
Epoch: 221 | Batch_idx: 260 |  Loss: (0.0453) |  Loss2: (0.0000) | Acc: (98.00%) (32937/33408)
Epoch: 221 | Batch_idx: 270 |  Loss: (0.0454) |  Loss2: (0.0000) | Acc: (98.00%) (34193/34688)
Epoch: 221 | Batch_idx: 280 |  Loss: (0.0456) |  Loss2: (0.0000) | Acc: (98.00%) (35452/35968)
Epoch: 221 | Batch_idx: 290 |  Loss: (0.0459) |  Loss2: (0.0000) | Acc: (98.00%) (36711/37248)
Epoch: 221 | Batch_idx: 300 |  Loss: (0.0462) |  Loss2: (0.0000) | Acc: (98.00%) (37963/38528)
Epoch: 221 | Batch_idx: 310 |  Loss: (0.0467) |  Loss2: (0.0000) | Acc: (98.00%) (39213/39808)
Epoch: 221 | Batch_idx: 320 |  Loss: (0.0474) |  Loss2: (0.0000) | Acc: (98.00%) (40463/41088)
Epoch: 221 | Batch_idx: 330 |  Loss: (0.0477) |  Loss2: (0.0000) | Acc: (98.00%) (41718/42368)
Epoch: 221 | Batch_idx: 340 |  Loss: (0.0479) |  Loss2: (0.0000) | Acc: (98.00%) (42975/43648)
Epoch: 221 | Batch_idx: 350 |  Loss: (0.0482) |  Loss2: (0.0000) | Acc: (98.00%) (44232/44928)
Epoch: 221 | Batch_idx: 360 |  Loss: (0.0488) |  Loss2: (0.0000) | Acc: (98.00%) (45483/46208)
Epoch: 221 | Batch_idx: 370 |  Loss: (0.0487) |  Loss2: (0.0000) | Acc: (98.00%) (46746/47488)
Epoch: 221 | Batch_idx: 380 |  Loss: (0.0489) |  Loss2: (0.0000) | Acc: (98.00%) (48003/48768)
Epoch: 221 | Batch_idx: 390 |  Loss: (0.0488) |  Loss2: (0.0000) | Acc: (98.00%) (49214/50000)
# TEST : Loss: (0.4683) | Acc: (88.00%) (8840/10000)
percent tensor([0.5750, 0.5884, 0.6161, 0.6081, 0.6188, 0.5849, 0.5987, 0.6149, 0.5881,
        0.5945, 0.5736, 0.6075, 0.5768, 0.5879, 0.5896, 0.5810],
       device='cuda:0') torch.Size([16])
percent tensor([0.5866, 0.5922, 0.5804, 0.5774, 0.5879, 0.5852, 0.5962, 0.5873, 0.5810,
        0.5879, 0.5882, 0.5927, 0.5855, 0.5866, 0.5938, 0.5876],
       device='cuda:0') torch.Size([16])
percent tensor([0.6421, 0.6592, 0.6013, 0.5702, 0.5774, 0.5984, 0.6353, 0.5874, 0.6234,
        0.6611, 0.6497, 0.6269, 0.6784, 0.6384, 0.6310, 0.6481],
       device='cuda:0') torch.Size([16])
percent tensor([0.6995, 0.6927, 0.6580, 0.6593, 0.6690, 0.7091, 0.7027, 0.6625, 0.6792,
        0.6933, 0.6944, 0.6807, 0.6944, 0.6998, 0.7003, 0.7034],
       device='cuda:0') torch.Size([16])
percent tensor([0.5865, 0.5295, 0.6566, 0.6923, 0.6815, 0.6167, 0.5960, 0.6776, 0.6275,
        0.5554, 0.5980, 0.6120, 0.4599, 0.6559, 0.6285, 0.6081],
       device='cuda:0') torch.Size([16])
percent tensor([0.5593, 0.7299, 0.6605, 0.6141, 0.6272, 0.7311, 0.6803, 0.5735, 0.7107,
        0.6817, 0.7620, 0.6634, 0.7356, 0.7406, 0.5139, 0.4870],
       device='cuda:0') torch.Size([16])
percent tensor([0.6729, 0.7544, 0.7086, 0.6321, 0.6450, 0.7234, 0.7227, 0.6605, 0.6853,
        0.7335, 0.7334, 0.6121, 0.7450, 0.6990, 0.5376, 0.5909],
       device='cuda:0') torch.Size([16])
percent tensor([0.9998, 0.9999, 0.9999, 0.9999, 0.9998, 0.9997, 0.9999, 0.9999, 1.0000,
        0.9999, 0.9999, 0.9998, 0.9999, 0.9997, 0.9998, 0.9995],
       device='cuda:0') torch.Size([16])
Epoch: 222 | Batch_idx: 0 |  Loss: (0.0354) |  Loss2: (0.0000) | Acc: (100.00%) (128/128)
Epoch: 222 | Batch_idx: 10 |  Loss: (0.0466) |  Loss2: (0.0000) | Acc: (98.00%) (1390/1408)
Epoch: 222 | Batch_idx: 20 |  Loss: (0.0464) |  Loss2: (0.0000) | Acc: (98.00%) (2652/2688)
Epoch: 222 | Batch_idx: 30 |  Loss: (0.0433) |  Loss2: (0.0000) | Acc: (98.00%) (3917/3968)
Epoch: 222 | Batch_idx: 40 |  Loss: (0.0441) |  Loss2: (0.0000) | Acc: (98.00%) (5179/5248)
Epoch: 222 | Batch_idx: 50 |  Loss: (0.0427) |  Loss2: (0.0000) | Acc: (98.00%) (6445/6528)
Epoch: 222 | Batch_idx: 60 |  Loss: (0.0424) |  Loss2: (0.0000) | Acc: (98.00%) (7706/7808)
Epoch: 222 | Batch_idx: 70 |  Loss: (0.0428) |  Loss2: (0.0000) | Acc: (98.00%) (8969/9088)
Epoch: 222 | Batch_idx: 80 |  Loss: (0.0432) |  Loss2: (0.0000) | Acc: (98.00%) (10229/10368)
Epoch: 222 | Batch_idx: 90 |  Loss: (0.0424) |  Loss2: (0.0000) | Acc: (98.00%) (11496/11648)
Epoch: 222 | Batch_idx: 100 |  Loss: (0.0421) |  Loss2: (0.0000) | Acc: (98.00%) (12762/12928)
Epoch: 222 | Batch_idx: 110 |  Loss: (0.0424) |  Loss2: (0.0000) | Acc: (98.00%) (14023/14208)
Epoch: 222 | Batch_idx: 120 |  Loss: (0.0425) |  Loss2: (0.0000) | Acc: (98.00%) (15286/15488)
Epoch: 222 | Batch_idx: 130 |  Loss: (0.0434) |  Loss2: (0.0000) | Acc: (98.00%) (16541/16768)
Epoch: 222 | Batch_idx: 140 |  Loss: (0.0443) |  Loss2: (0.0000) | Acc: (98.00%) (17798/18048)
Epoch: 222 | Batch_idx: 150 |  Loss: (0.0450) |  Loss2: (0.0000) | Acc: (98.00%) (19048/19328)
Epoch: 222 | Batch_idx: 160 |  Loss: (0.0454) |  Loss2: (0.0000) | Acc: (98.00%) (20307/20608)
Epoch: 222 | Batch_idx: 170 |  Loss: (0.0452) |  Loss2: (0.0000) | Acc: (98.00%) (21573/21888)
Epoch: 222 | Batch_idx: 180 |  Loss: (0.0455) |  Loss2: (0.0000) | Acc: (98.00%) (22830/23168)
Epoch: 222 | Batch_idx: 190 |  Loss: (0.0451) |  Loss2: (0.0000) | Acc: (98.00%) (24093/24448)
Epoch: 222 | Batch_idx: 200 |  Loss: (0.0451) |  Loss2: (0.0000) | Acc: (98.00%) (25352/25728)
Epoch: 222 | Batch_idx: 210 |  Loss: (0.0452) |  Loss2: (0.0000) | Acc: (98.00%) (26611/27008)
Epoch: 222 | Batch_idx: 220 |  Loss: (0.0453) |  Loss2: (0.0000) | Acc: (98.00%) (27873/28288)
Epoch: 222 | Batch_idx: 230 |  Loss: (0.0456) |  Loss2: (0.0000) | Acc: (98.00%) (29132/29568)
Epoch: 222 | Batch_idx: 240 |  Loss: (0.0460) |  Loss2: (0.0000) | Acc: (98.00%) (30392/30848)
Epoch: 222 | Batch_idx: 250 |  Loss: (0.0463) |  Loss2: (0.0000) | Acc: (98.00%) (31644/32128)
Epoch: 222 | Batch_idx: 260 |  Loss: (0.0464) |  Loss2: (0.0000) | Acc: (98.00%) (32906/33408)
Epoch: 222 | Batch_idx: 270 |  Loss: (0.0463) |  Loss2: (0.0000) | Acc: (98.00%) (34166/34688)
Epoch: 222 | Batch_idx: 280 |  Loss: (0.0469) |  Loss2: (0.0000) | Acc: (98.00%) (35414/35968)
Epoch: 222 | Batch_idx: 290 |  Loss: (0.0467) |  Loss2: (0.0000) | Acc: (98.00%) (36674/37248)
Epoch: 222 | Batch_idx: 300 |  Loss: (0.0468) |  Loss2: (0.0000) | Acc: (98.00%) (37941/38528)
Epoch: 222 | Batch_idx: 310 |  Loss: (0.0472) |  Loss2: (0.0000) | Acc: (98.00%) (39195/39808)
Epoch: 222 | Batch_idx: 320 |  Loss: (0.0475) |  Loss2: (0.0000) | Acc: (98.00%) (40449/41088)
Epoch: 222 | Batch_idx: 330 |  Loss: (0.0477) |  Loss2: (0.0000) | Acc: (98.00%) (41707/42368)
Epoch: 222 | Batch_idx: 340 |  Loss: (0.0478) |  Loss2: (0.0000) | Acc: (98.00%) (42965/43648)
Epoch: 222 | Batch_idx: 350 |  Loss: (0.0481) |  Loss2: (0.0000) | Acc: (98.00%) (44214/44928)
Epoch: 222 | Batch_idx: 360 |  Loss: (0.0485) |  Loss2: (0.0000) | Acc: (98.00%) (45467/46208)
Epoch: 222 | Batch_idx: 370 |  Loss: (0.0486) |  Loss2: (0.0000) | Acc: (98.00%) (46727/47488)
Epoch: 222 | Batch_idx: 380 |  Loss: (0.0488) |  Loss2: (0.0000) | Acc: (98.00%) (47981/48768)
Epoch: 222 | Batch_idx: 390 |  Loss: (0.0488) |  Loss2: (0.0000) | Acc: (98.00%) (49191/50000)
# TEST : Loss: (0.4693) | Acc: (88.00%) (8810/10000)
percent tensor([0.5786, 0.5946, 0.6196, 0.6124, 0.6227, 0.5890, 0.6044, 0.6197, 0.5912,
        0.5994, 0.5782, 0.6121, 0.5802, 0.5946, 0.5951, 0.5859],
       device='cuda:0') torch.Size([16])
percent tensor([0.5869, 0.5920, 0.5817, 0.5777, 0.5890, 0.5855, 0.5964, 0.5888, 0.5809,
        0.5891, 0.5887, 0.5937, 0.5858, 0.5847, 0.5943, 0.5878],
       device='cuda:0') torch.Size([16])
percent tensor([0.6460, 0.6669, 0.6024, 0.5689, 0.5776, 0.5993, 0.6370, 0.5887, 0.6272,
        0.6688, 0.6552, 0.6337, 0.6889, 0.6387, 0.6345, 0.6501],
       device='cuda:0') torch.Size([16])
percent tensor([0.7028, 0.6968, 0.6624, 0.6603, 0.6712, 0.7159, 0.7060, 0.6652, 0.6827,
        0.6994, 0.7009, 0.6868, 0.7000, 0.6996, 0.7073, 0.7076],
       device='cuda:0') torch.Size([16])
percent tensor([0.5853, 0.5265, 0.6528, 0.6816, 0.6719, 0.6254, 0.6006, 0.6641, 0.6165,
        0.5479, 0.5904, 0.5816, 0.4509, 0.6438, 0.6301, 0.6205],
       device='cuda:0') torch.Size([16])
percent tensor([0.6009, 0.7572, 0.6920, 0.6706, 0.6477, 0.7313, 0.7039, 0.5935, 0.7215,
        0.7052, 0.7955, 0.6956, 0.7615, 0.7666, 0.5590, 0.5147],
       device='cuda:0') torch.Size([16])
percent tensor([0.6914, 0.7450, 0.7043, 0.6584, 0.6368, 0.7168, 0.7280, 0.6592, 0.6872,
        0.7219, 0.7379, 0.6043, 0.7516, 0.7288, 0.5269, 0.5949],
       device='cuda:0') torch.Size([16])
percent tensor([0.9998, 0.9998, 0.9999, 0.9999, 0.9998, 0.9997, 0.9999, 0.9999, 0.9999,
        1.0000, 0.9999, 0.9999, 0.9998, 0.9997, 0.9999, 0.9994],
       device='cuda:0') torch.Size([16])
Epoch: 223 | Batch_idx: 0 |  Loss: (0.0311) |  Loss2: (0.0000) | Acc: (98.00%) (126/128)
Epoch: 223 | Batch_idx: 10 |  Loss: (0.0371) |  Loss2: (0.0000) | Acc: (98.00%) (1393/1408)
Epoch: 223 | Batch_idx: 20 |  Loss: (0.0419) |  Loss2: (0.0000) | Acc: (98.00%) (2655/2688)
Epoch: 223 | Batch_idx: 30 |  Loss: (0.0401) |  Loss2: (0.0000) | Acc: (98.00%) (3922/3968)
Epoch: 223 | Batch_idx: 40 |  Loss: (0.0404) |  Loss2: (0.0000) | Acc: (98.00%) (5183/5248)
Epoch: 223 | Batch_idx: 50 |  Loss: (0.0426) |  Loss2: (0.0000) | Acc: (98.00%) (6438/6528)
Epoch: 223 | Batch_idx: 60 |  Loss: (0.0420) |  Loss2: (0.0000) | Acc: (98.00%) (7705/7808)
Epoch: 223 | Batch_idx: 70 |  Loss: (0.0429) |  Loss2: (0.0000) | Acc: (98.00%) (8967/9088)
Epoch: 223 | Batch_idx: 80 |  Loss: (0.0415) |  Loss2: (0.0000) | Acc: (98.00%) (10239/10368)
Epoch: 223 | Batch_idx: 90 |  Loss: (0.0423) |  Loss2: (0.0000) | Acc: (98.00%) (11500/11648)
Epoch: 223 | Batch_idx: 100 |  Loss: (0.0440) |  Loss2: (0.0000) | Acc: (98.00%) (12754/12928)
Epoch: 223 | Batch_idx: 110 |  Loss: (0.0445) |  Loss2: (0.0000) | Acc: (98.00%) (14013/14208)
Epoch: 223 | Batch_idx: 120 |  Loss: (0.0436) |  Loss2: (0.0000) | Acc: (98.00%) (15278/15488)
Epoch: 223 | Batch_idx: 130 |  Loss: (0.0434) |  Loss2: (0.0000) | Acc: (98.00%) (16542/16768)
Epoch: 223 | Batch_idx: 140 |  Loss: (0.0436) |  Loss2: (0.0000) | Acc: (98.00%) (17800/18048)
Epoch: 223 | Batch_idx: 150 |  Loss: (0.0437) |  Loss2: (0.0000) | Acc: (98.00%) (19057/19328)
Epoch: 223 | Batch_idx: 160 |  Loss: (0.0436) |  Loss2: (0.0000) | Acc: (98.00%) (20318/20608)
Epoch: 223 | Batch_idx: 170 |  Loss: (0.0439) |  Loss2: (0.0000) | Acc: (98.00%) (21583/21888)
Epoch: 223 | Batch_idx: 180 |  Loss: (0.0443) |  Loss2: (0.0000) | Acc: (98.00%) (22842/23168)
Epoch: 223 | Batch_idx: 190 |  Loss: (0.0448) |  Loss2: (0.0000) | Acc: (98.00%) (24096/24448)
Epoch: 223 | Batch_idx: 200 |  Loss: (0.0448) |  Loss2: (0.0000) | Acc: (98.00%) (25356/25728)
Epoch: 223 | Batch_idx: 210 |  Loss: (0.0449) |  Loss2: (0.0000) | Acc: (98.00%) (26621/27008)
Epoch: 223 | Batch_idx: 220 |  Loss: (0.0453) |  Loss2: (0.0000) | Acc: (98.00%) (27876/28288)
Epoch: 223 | Batch_idx: 230 |  Loss: (0.0451) |  Loss2: (0.0000) | Acc: (98.00%) (29138/29568)
Epoch: 223 | Batch_idx: 240 |  Loss: (0.0452) |  Loss2: (0.0000) | Acc: (98.00%) (30397/30848)
Epoch: 223 | Batch_idx: 250 |  Loss: (0.0458) |  Loss2: (0.0000) | Acc: (98.00%) (31654/32128)
Epoch: 223 | Batch_idx: 260 |  Loss: (0.0458) |  Loss2: (0.0000) | Acc: (98.00%) (32914/33408)
Epoch: 223 | Batch_idx: 270 |  Loss: (0.0460) |  Loss2: (0.0000) | Acc: (98.00%) (34170/34688)
Epoch: 223 | Batch_idx: 280 |  Loss: (0.0462) |  Loss2: (0.0000) | Acc: (98.00%) (35432/35968)
Epoch: 223 | Batch_idx: 290 |  Loss: (0.0467) |  Loss2: (0.0000) | Acc: (98.00%) (36683/37248)
Epoch: 223 | Batch_idx: 300 |  Loss: (0.0467) |  Loss2: (0.0000) | Acc: (98.00%) (37945/38528)
Epoch: 223 | Batch_idx: 310 |  Loss: (0.0467) |  Loss2: (0.0000) | Acc: (98.00%) (39206/39808)
Epoch: 223 | Batch_idx: 320 |  Loss: (0.0467) |  Loss2: (0.0000) | Acc: (98.00%) (40470/41088)
Epoch: 223 | Batch_idx: 330 |  Loss: (0.0467) |  Loss2: (0.0000) | Acc: (98.00%) (41729/42368)
Epoch: 223 | Batch_idx: 340 |  Loss: (0.0466) |  Loss2: (0.0000) | Acc: (98.00%) (42989/43648)
Epoch: 223 | Batch_idx: 350 |  Loss: (0.0468) |  Loss2: (0.0000) | Acc: (98.00%) (44251/44928)
Epoch: 223 | Batch_idx: 360 |  Loss: (0.0466) |  Loss2: (0.0000) | Acc: (98.00%) (45518/46208)
Epoch: 223 | Batch_idx: 370 |  Loss: (0.0467) |  Loss2: (0.0000) | Acc: (98.00%) (46778/47488)
Epoch: 223 | Batch_idx: 380 |  Loss: (0.0465) |  Loss2: (0.0000) | Acc: (98.00%) (48039/48768)
Epoch: 223 | Batch_idx: 390 |  Loss: (0.0465) |  Loss2: (0.0000) | Acc: (98.00%) (49254/50000)
# TEST : Loss: (0.4482) | Acc: (88.00%) (8889/10000)
percent tensor([0.5767, 0.5928, 0.6193, 0.6115, 0.6223, 0.5871, 0.6028, 0.6184, 0.5904,
        0.5976, 0.5760, 0.6118, 0.5789, 0.5930, 0.5935, 0.5842],
       device='cuda:0') torch.Size([16])
percent tensor([0.5848, 0.5896, 0.5797, 0.5767, 0.5876, 0.5845, 0.5942, 0.5871, 0.5792,
        0.5863, 0.5860, 0.5913, 0.5834, 0.5834, 0.5924, 0.5860],
       device='cuda:0') torch.Size([16])
percent tensor([0.6434, 0.6596, 0.6059, 0.5718, 0.5786, 0.5959, 0.6375, 0.5931, 0.6263,
        0.6633, 0.6500, 0.6311, 0.6845, 0.6412, 0.6302, 0.6460],
       device='cuda:0') torch.Size([16])
percent tensor([0.6986, 0.6874, 0.6572, 0.6612, 0.6671, 0.7094, 0.7004, 0.6652, 0.6809,
        0.6921, 0.6932, 0.6801, 0.6935, 0.6943, 0.7012, 0.7000],
       device='cuda:0') torch.Size([16])
percent tensor([0.5905, 0.5209, 0.6433, 0.6827, 0.6741, 0.6356, 0.5947, 0.6656, 0.6271,
        0.5444, 0.5912, 0.5983, 0.4588, 0.6564, 0.6348, 0.6234],
       device='cuda:0') torch.Size([16])
percent tensor([0.5673, 0.7462, 0.6860, 0.6860, 0.6557, 0.7428, 0.6999, 0.5945, 0.7005,
        0.6776, 0.7676, 0.6813, 0.7432, 0.7272, 0.5493, 0.5104],
       device='cuda:0') torch.Size([16])
percent tensor([0.6688, 0.7616, 0.7068, 0.6560, 0.6539, 0.7090, 0.7319, 0.6482, 0.6657,
        0.7279, 0.7238, 0.6052, 0.7468, 0.6963, 0.5377, 0.5911],
       device='cuda:0') torch.Size([16])
percent tensor([0.9998, 0.9999, 0.9999, 0.9999, 0.9997, 0.9995, 0.9999, 0.9999, 0.9999,
        1.0000, 1.0000, 0.9999, 0.9999, 0.9998, 0.9999, 0.9992],
       device='cuda:0') torch.Size([16])
Epoch: 224 | Batch_idx: 0 |  Loss: (0.0622) |  Loss2: (0.0000) | Acc: (97.00%) (125/128)
Epoch: 224 | Batch_idx: 10 |  Loss: (0.0418) |  Loss2: (0.0000) | Acc: (98.00%) (1386/1408)
Epoch: 224 | Batch_idx: 20 |  Loss: (0.0424) |  Loss2: (0.0000) | Acc: (98.00%) (2645/2688)
Epoch: 224 | Batch_idx: 30 |  Loss: (0.0452) |  Loss2: (0.0000) | Acc: (98.00%) (3904/3968)
Epoch: 224 | Batch_idx: 40 |  Loss: (0.0438) |  Loss2: (0.0000) | Acc: (98.00%) (5163/5248)
Epoch: 224 | Batch_idx: 50 |  Loss: (0.0433) |  Loss2: (0.0000) | Acc: (98.00%) (6426/6528)
Epoch: 224 | Batch_idx: 60 |  Loss: (0.0420) |  Loss2: (0.0000) | Acc: (98.00%) (7692/7808)
Epoch: 224 | Batch_idx: 70 |  Loss: (0.0434) |  Loss2: (0.0000) | Acc: (98.00%) (8952/9088)
Epoch: 224 | Batch_idx: 80 |  Loss: (0.0432) |  Loss2: (0.0000) | Acc: (98.00%) (10218/10368)
Epoch: 224 | Batch_idx: 90 |  Loss: (0.0429) |  Loss2: (0.0000) | Acc: (98.00%) (11480/11648)
Epoch: 224 | Batch_idx: 100 |  Loss: (0.0424) |  Loss2: (0.0000) | Acc: (98.00%) (12743/12928)
Epoch: 224 | Batch_idx: 110 |  Loss: (0.0420) |  Loss2: (0.0000) | Acc: (98.00%) (14012/14208)
Epoch: 224 | Batch_idx: 120 |  Loss: (0.0428) |  Loss2: (0.0000) | Acc: (98.00%) (15272/15488)
Epoch: 224 | Batch_idx: 130 |  Loss: (0.0424) |  Loss2: (0.0000) | Acc: (98.00%) (16537/16768)
Epoch: 224 | Batch_idx: 140 |  Loss: (0.0426) |  Loss2: (0.0000) | Acc: (98.00%) (17796/18048)
Epoch: 224 | Batch_idx: 150 |  Loss: (0.0430) |  Loss2: (0.0000) | Acc: (98.00%) (19058/19328)
Epoch: 224 | Batch_idx: 160 |  Loss: (0.0424) |  Loss2: (0.0000) | Acc: (98.00%) (20328/20608)
Epoch: 224 | Batch_idx: 170 |  Loss: (0.0428) |  Loss2: (0.0000) | Acc: (98.00%) (21586/21888)
Epoch: 224 | Batch_idx: 180 |  Loss: (0.0430) |  Loss2: (0.0000) | Acc: (98.00%) (22846/23168)
Epoch: 224 | Batch_idx: 190 |  Loss: (0.0426) |  Loss2: (0.0000) | Acc: (98.00%) (24117/24448)
Epoch: 224 | Batch_idx: 200 |  Loss: (0.0430) |  Loss2: (0.0000) | Acc: (98.00%) (25373/25728)
Epoch: 224 | Batch_idx: 210 |  Loss: (0.0429) |  Loss2: (0.0000) | Acc: (98.00%) (26634/27008)
Epoch: 224 | Batch_idx: 220 |  Loss: (0.0433) |  Loss2: (0.0000) | Acc: (98.00%) (27891/28288)
Epoch: 224 | Batch_idx: 230 |  Loss: (0.0430) |  Loss2: (0.0000) | Acc: (98.00%) (29157/29568)
Epoch: 224 | Batch_idx: 240 |  Loss: (0.0432) |  Loss2: (0.0000) | Acc: (98.00%) (30417/30848)
Epoch: 224 | Batch_idx: 250 |  Loss: (0.0428) |  Loss2: (0.0000) | Acc: (98.00%) (31686/32128)
Epoch: 224 | Batch_idx: 260 |  Loss: (0.0428) |  Loss2: (0.0000) | Acc: (98.00%) (32945/33408)
Epoch: 224 | Batch_idx: 270 |  Loss: (0.0428) |  Loss2: (0.0000) | Acc: (98.00%) (34211/34688)
Epoch: 224 | Batch_idx: 280 |  Loss: (0.0427) |  Loss2: (0.0000) | Acc: (98.00%) (35475/35968)
Epoch: 224 | Batch_idx: 290 |  Loss: (0.0433) |  Loss2: (0.0000) | Acc: (98.00%) (36733/37248)
Epoch: 224 | Batch_idx: 300 |  Loss: (0.0432) |  Loss2: (0.0000) | Acc: (98.00%) (37996/38528)
Epoch: 224 | Batch_idx: 310 |  Loss: (0.0433) |  Loss2: (0.0000) | Acc: (98.00%) (39257/39808)
Epoch: 224 | Batch_idx: 320 |  Loss: (0.0436) |  Loss2: (0.0000) | Acc: (98.00%) (40516/41088)
Epoch: 224 | Batch_idx: 330 |  Loss: (0.0434) |  Loss2: (0.0000) | Acc: (98.00%) (41779/42368)
Epoch: 224 | Batch_idx: 340 |  Loss: (0.0433) |  Loss2: (0.0000) | Acc: (98.00%) (43045/43648)
Epoch: 224 | Batch_idx: 350 |  Loss: (0.0434) |  Loss2: (0.0000) | Acc: (98.00%) (44312/44928)
Epoch: 224 | Batch_idx: 360 |  Loss: (0.0431) |  Loss2: (0.0000) | Acc: (98.00%) (45581/46208)
Epoch: 224 | Batch_idx: 370 |  Loss: (0.0430) |  Loss2: (0.0000) | Acc: (98.00%) (46844/47488)
Epoch: 224 | Batch_idx: 380 |  Loss: (0.0431) |  Loss2: (0.0000) | Acc: (98.00%) (48105/48768)
Epoch: 224 | Batch_idx: 390 |  Loss: (0.0432) |  Loss2: (0.0000) | Acc: (98.00%) (49319/50000)
# TEST : Loss: (0.4388) | Acc: (89.00%) (8926/10000)
percent tensor([0.5770, 0.5926, 0.6174, 0.6108, 0.6203, 0.5874, 0.6019, 0.6172, 0.5886,
        0.5972, 0.5746, 0.6102, 0.5784, 0.5932, 0.5932, 0.5845],
       device='cuda:0') torch.Size([16])
percent tensor([0.5844, 0.5887, 0.5780, 0.5764, 0.5866, 0.5849, 0.5933, 0.5854, 0.5787,
        0.5853, 0.5860, 0.5896, 0.5824, 0.5844, 0.5921, 0.5859],
       device='cuda:0') torch.Size([16])
percent tensor([0.6479, 0.6652, 0.6110, 0.5778, 0.5792, 0.6038, 0.6410, 0.5961, 0.6257,
        0.6687, 0.6519, 0.6328, 0.6852, 0.6442, 0.6363, 0.6533],
       device='cuda:0') torch.Size([16])
percent tensor([0.7017, 0.6936, 0.6621, 0.6658, 0.6739, 0.7127, 0.7055, 0.6687, 0.6840,
        0.6989, 0.6982, 0.6843, 0.6973, 0.6975, 0.7063, 0.7057],
       device='cuda:0') torch.Size([16])
percent tensor([0.5840, 0.5266, 0.6527, 0.6864, 0.6812, 0.6296, 0.5928, 0.6666, 0.6360,
        0.5447, 0.5940, 0.6049, 0.4732, 0.6522, 0.6258, 0.6087],
       device='cuda:0') torch.Size([16])
percent tensor([0.5859, 0.7392, 0.6887, 0.6831, 0.6603, 0.7793, 0.6889, 0.5941, 0.7110,
        0.6877, 0.7662, 0.6873, 0.7512, 0.7311, 0.5260, 0.5224],
       device='cuda:0') torch.Size([16])
percent tensor([0.6835, 0.7469, 0.7008, 0.6364, 0.6261, 0.7333, 0.7145, 0.6370, 0.6860,
        0.7179, 0.7305, 0.6092, 0.7498, 0.7212, 0.5288, 0.5860],
       device='cuda:0') torch.Size([16])
percent tensor([0.9998, 0.9999, 0.9999, 0.9998, 0.9997, 0.9998, 0.9999, 0.9999, 0.9999,
        0.9999, 1.0000, 0.9999, 0.9999, 0.9998, 0.9999, 0.9994],
       device='cuda:0') torch.Size([16])
Epoch: 225 | Batch_idx: 0 |  Loss: (0.0444) |  Loss2: (0.0000) | Acc: (99.00%) (127/128)
Epoch: 225 | Batch_idx: 10 |  Loss: (0.0343) |  Loss2: (0.0000) | Acc: (99.00%) (1395/1408)
Epoch: 225 | Batch_idx: 20 |  Loss: (0.0358) |  Loss2: (0.0000) | Acc: (99.00%) (2663/2688)
Epoch: 225 | Batch_idx: 30 |  Loss: (0.0357) |  Loss2: (0.0000) | Acc: (99.00%) (3929/3968)
Epoch: 225 | Batch_idx: 40 |  Loss: (0.0374) |  Loss2: (0.0000) | Acc: (98.00%) (5189/5248)
Epoch: 225 | Batch_idx: 50 |  Loss: (0.0368) |  Loss2: (0.0000) | Acc: (98.00%) (6454/6528)
Epoch: 225 | Batch_idx: 60 |  Loss: (0.0378) |  Loss2: (0.0000) | Acc: (98.00%) (7717/7808)
Epoch: 225 | Batch_idx: 70 |  Loss: (0.0399) |  Loss2: (0.0000) | Acc: (98.00%) (8975/9088)
Epoch: 225 | Batch_idx: 80 |  Loss: (0.0396) |  Loss2: (0.0000) | Acc: (98.00%) (10243/10368)
Epoch: 225 | Batch_idx: 90 |  Loss: (0.0393) |  Loss2: (0.0000) | Acc: (98.00%) (11511/11648)
Epoch: 225 | Batch_idx: 100 |  Loss: (0.0402) |  Loss2: (0.0000) | Acc: (98.00%) (12767/12928)
Epoch: 225 | Batch_idx: 110 |  Loss: (0.0399) |  Loss2: (0.0000) | Acc: (98.00%) (14035/14208)
Epoch: 225 | Batch_idx: 120 |  Loss: (0.0410) |  Loss2: (0.0000) | Acc: (98.00%) (15290/15488)
Epoch: 225 | Batch_idx: 130 |  Loss: (0.0407) |  Loss2: (0.0000) | Acc: (98.00%) (16553/16768)
Epoch: 225 | Batch_idx: 140 |  Loss: (0.0408) |  Loss2: (0.0000) | Acc: (98.00%) (17817/18048)
Epoch: 225 | Batch_idx: 150 |  Loss: (0.0412) |  Loss2: (0.0000) | Acc: (98.00%) (19072/19328)
Epoch: 225 | Batch_idx: 160 |  Loss: (0.0414) |  Loss2: (0.0000) | Acc: (98.00%) (20336/20608)
Epoch: 225 | Batch_idx: 170 |  Loss: (0.0414) |  Loss2: (0.0000) | Acc: (98.00%) (21602/21888)
Epoch: 225 | Batch_idx: 180 |  Loss: (0.0415) |  Loss2: (0.0000) | Acc: (98.00%) (22868/23168)
Epoch: 225 | Batch_idx: 190 |  Loss: (0.0419) |  Loss2: (0.0000) | Acc: (98.00%) (24126/24448)
Epoch: 225 | Batch_idx: 200 |  Loss: (0.0420) |  Loss2: (0.0000) | Acc: (98.00%) (25387/25728)
Epoch: 225 | Batch_idx: 210 |  Loss: (0.0422) |  Loss2: (0.0000) | Acc: (98.00%) (26644/27008)
Epoch: 225 | Batch_idx: 220 |  Loss: (0.0427) |  Loss2: (0.0000) | Acc: (98.00%) (27900/28288)
Epoch: 225 | Batch_idx: 230 |  Loss: (0.0431) |  Loss2: (0.0000) | Acc: (98.00%) (29159/29568)
Epoch: 225 | Batch_idx: 240 |  Loss: (0.0429) |  Loss2: (0.0000) | Acc: (98.00%) (30424/30848)
Epoch: 225 | Batch_idx: 250 |  Loss: (0.0435) |  Loss2: (0.0000) | Acc: (98.00%) (31677/32128)
Epoch: 225 | Batch_idx: 260 |  Loss: (0.0436) |  Loss2: (0.0000) | Acc: (98.00%) (32939/33408)
Epoch: 225 | Batch_idx: 270 |  Loss: (0.0440) |  Loss2: (0.0000) | Acc: (98.00%) (34194/34688)
Epoch: 225 | Batch_idx: 280 |  Loss: (0.0440) |  Loss2: (0.0000) | Acc: (98.00%) (35455/35968)
Epoch: 225 | Batch_idx: 290 |  Loss: (0.0443) |  Loss2: (0.0000) | Acc: (98.00%) (36712/37248)
Epoch: 225 | Batch_idx: 300 |  Loss: (0.0442) |  Loss2: (0.0000) | Acc: (98.00%) (37972/38528)
Epoch: 225 | Batch_idx: 310 |  Loss: (0.0441) |  Loss2: (0.0000) | Acc: (98.00%) (39234/39808)
Epoch: 225 | Batch_idx: 320 |  Loss: (0.0440) |  Loss2: (0.0000) | Acc: (98.00%) (40496/41088)
Epoch: 225 | Batch_idx: 330 |  Loss: (0.0444) |  Loss2: (0.0000) | Acc: (98.00%) (41752/42368)
Epoch: 225 | Batch_idx: 340 |  Loss: (0.0447) |  Loss2: (0.0000) | Acc: (98.00%) (43012/43648)
Epoch: 225 | Batch_idx: 350 |  Loss: (0.0448) |  Loss2: (0.0000) | Acc: (98.00%) (44270/44928)
Epoch: 225 | Batch_idx: 360 |  Loss: (0.0451) |  Loss2: (0.0000) | Acc: (98.00%) (45522/46208)
Epoch: 225 | Batch_idx: 370 |  Loss: (0.0449) |  Loss2: (0.0000) | Acc: (98.00%) (46783/47488)
Epoch: 225 | Batch_idx: 380 |  Loss: (0.0451) |  Loss2: (0.0000) | Acc: (98.00%) (48050/48768)
Epoch: 225 | Batch_idx: 390 |  Loss: (0.0452) |  Loss2: (0.0000) | Acc: (98.00%) (49261/50000)
=> saving checkpoint 'drive/app/torch/save_Schedule/checkpoint_225.pth.tar'
# TEST : Loss: (0.4375) | Acc: (89.00%) (8917/10000)
percent tensor([0.5790, 0.5970, 0.6176, 0.6127, 0.6231, 0.5896, 0.6061, 0.6198, 0.5928,
        0.6004, 0.5787, 0.6115, 0.5815, 0.5988, 0.5962, 0.5869],
       device='cuda:0') torch.Size([16])
percent tensor([0.5875, 0.5919, 0.5805, 0.5772, 0.5884, 0.5859, 0.5969, 0.5881, 0.5828,
        0.5880, 0.5897, 0.5923, 0.5866, 0.5872, 0.5943, 0.5883],
       device='cuda:0') torch.Size([16])
percent tensor([0.6504, 0.6683, 0.6084, 0.5811, 0.5798, 0.6069, 0.6422, 0.5948, 0.6295,
        0.6693, 0.6552, 0.6331, 0.6869, 0.6458, 0.6400, 0.6540],
       device='cuda:0') torch.Size([16])
percent tensor([0.7050, 0.6910, 0.6637, 0.6663, 0.6743, 0.7163, 0.7055, 0.6687, 0.6869,
        0.6966, 0.7008, 0.6845, 0.6985, 0.6972, 0.7058, 0.7064],
       device='cuda:0') torch.Size([16])
percent tensor([0.5802, 0.5141, 0.6526, 0.6865, 0.6762, 0.6321, 0.5926, 0.6634, 0.6382,
        0.5374, 0.5866, 0.6041, 0.4692, 0.6379, 0.6224, 0.6100],
       device='cuda:0') torch.Size([16])
percent tensor([0.5559, 0.7544, 0.6874, 0.6767, 0.6536, 0.7443, 0.6864, 0.5920, 0.7128,
        0.6956, 0.7667, 0.6763, 0.7397, 0.7422, 0.5285, 0.4990],
       device='cuda:0') torch.Size([16])
percent tensor([0.6702, 0.7537, 0.7214, 0.6539, 0.6507, 0.7126, 0.7202, 0.6601, 0.6910,
        0.7285, 0.7207, 0.6138, 0.7458, 0.7083, 0.5316, 0.5877],
       device='cuda:0') torch.Size([16])
percent tensor([0.9998, 0.9999, 0.9999, 0.9999, 0.9998, 0.9998, 0.9999, 0.9999, 0.9999,
        0.9999, 1.0000, 0.9999, 0.9999, 0.9998, 0.9999, 0.9993],
       device='cuda:0') torch.Size([16])
Epoch: 226 | Batch_idx: 0 |  Loss: (0.0394) |  Loss2: (0.0000) | Acc: (98.00%) (126/128)
Epoch: 226 | Batch_idx: 10 |  Loss: (0.0470) |  Loss2: (0.0000) | Acc: (98.00%) (1386/1408)
Epoch: 226 | Batch_idx: 20 |  Loss: (0.0463) |  Loss2: (0.0000) | Acc: (98.00%) (2650/2688)
Epoch: 226 | Batch_idx: 30 |  Loss: (0.0438) |  Loss2: (0.0000) | Acc: (98.00%) (3915/3968)
Epoch: 226 | Batch_idx: 40 |  Loss: (0.0436) |  Loss2: (0.0000) | Acc: (98.00%) (5177/5248)
Epoch: 226 | Batch_idx: 50 |  Loss: (0.0443) |  Loss2: (0.0000) | Acc: (98.00%) (6443/6528)
Epoch: 226 | Batch_idx: 60 |  Loss: (0.0446) |  Loss2: (0.0000) | Acc: (98.00%) (7706/7808)
Epoch: 226 | Batch_idx: 70 |  Loss: (0.0438) |  Loss2: (0.0000) | Acc: (98.00%) (8970/9088)
Epoch: 226 | Batch_idx: 80 |  Loss: (0.0443) |  Loss2: (0.0000) | Acc: (98.00%) (10230/10368)
Epoch: 226 | Batch_idx: 90 |  Loss: (0.0444) |  Loss2: (0.0000) | Acc: (98.00%) (11490/11648)
Epoch: 226 | Batch_idx: 100 |  Loss: (0.0434) |  Loss2: (0.0000) | Acc: (98.00%) (12761/12928)
Epoch: 226 | Batch_idx: 110 |  Loss: (0.0432) |  Loss2: (0.0000) | Acc: (98.00%) (14026/14208)
Epoch: 226 | Batch_idx: 120 |  Loss: (0.0432) |  Loss2: (0.0000) | Acc: (98.00%) (15288/15488)
Epoch: 226 | Batch_idx: 130 |  Loss: (0.0430) |  Loss2: (0.0000) | Acc: (98.00%) (16552/16768)
Epoch: 226 | Batch_idx: 140 |  Loss: (0.0428) |  Loss2: (0.0000) | Acc: (98.00%) (17815/18048)
Epoch: 226 | Batch_idx: 150 |  Loss: (0.0428) |  Loss2: (0.0000) | Acc: (98.00%) (19074/19328)
Epoch: 226 | Batch_idx: 160 |  Loss: (0.0421) |  Loss2: (0.0000) | Acc: (98.00%) (20343/20608)
Epoch: 226 | Batch_idx: 170 |  Loss: (0.0418) |  Loss2: (0.0000) | Acc: (98.00%) (21607/21888)
Epoch: 226 | Batch_idx: 180 |  Loss: (0.0414) |  Loss2: (0.0000) | Acc: (98.00%) (22876/23168)
Epoch: 226 | Batch_idx: 190 |  Loss: (0.0416) |  Loss2: (0.0000) | Acc: (98.00%) (24135/24448)
Epoch: 226 | Batch_idx: 200 |  Loss: (0.0416) |  Loss2: (0.0000) | Acc: (98.00%) (25400/25728)
Epoch: 226 | Batch_idx: 210 |  Loss: (0.0417) |  Loss2: (0.0000) | Acc: (98.00%) (26658/27008)
Epoch: 226 | Batch_idx: 220 |  Loss: (0.0420) |  Loss2: (0.0000) | Acc: (98.00%) (27922/28288)
Epoch: 226 | Batch_idx: 230 |  Loss: (0.0420) |  Loss2: (0.0000) | Acc: (98.00%) (29183/29568)
Epoch: 226 | Batch_idx: 240 |  Loss: (0.0423) |  Loss2: (0.0000) | Acc: (98.00%) (30439/30848)
Epoch: 226 | Batch_idx: 250 |  Loss: (0.0427) |  Loss2: (0.0000) | Acc: (98.00%) (31694/32128)
Epoch: 226 | Batch_idx: 260 |  Loss: (0.0431) |  Loss2: (0.0000) | Acc: (98.00%) (32948/33408)
Epoch: 226 | Batch_idx: 270 |  Loss: (0.0431) |  Loss2: (0.0000) | Acc: (98.00%) (34211/34688)
Epoch: 226 | Batch_idx: 280 |  Loss: (0.0429) |  Loss2: (0.0000) | Acc: (98.00%) (35476/35968)
Epoch: 226 | Batch_idx: 290 |  Loss: (0.0432) |  Loss2: (0.0000) | Acc: (98.00%) (36734/37248)
Epoch: 226 | Batch_idx: 300 |  Loss: (0.0433) |  Loss2: (0.0000) | Acc: (98.00%) (37993/38528)
Epoch: 226 | Batch_idx: 310 |  Loss: (0.0438) |  Loss2: (0.0000) | Acc: (98.00%) (39250/39808)
Epoch: 226 | Batch_idx: 320 |  Loss: (0.0441) |  Loss2: (0.0000) | Acc: (98.00%) (40510/41088)
Epoch: 226 | Batch_idx: 330 |  Loss: (0.0443) |  Loss2: (0.0000) | Acc: (98.00%) (41765/42368)
Epoch: 226 | Batch_idx: 340 |  Loss: (0.0443) |  Loss2: (0.0000) | Acc: (98.00%) (43028/43648)
Epoch: 226 | Batch_idx: 350 |  Loss: (0.0443) |  Loss2: (0.0000) | Acc: (98.00%) (44290/44928)
Epoch: 226 | Batch_idx: 360 |  Loss: (0.0443) |  Loss2: (0.0000) | Acc: (98.00%) (45557/46208)
Epoch: 226 | Batch_idx: 370 |  Loss: (0.0443) |  Loss2: (0.0000) | Acc: (98.00%) (46817/47488)
Epoch: 226 | Batch_idx: 380 |  Loss: (0.0442) |  Loss2: (0.0000) | Acc: (98.00%) (48078/48768)
Epoch: 226 | Batch_idx: 390 |  Loss: (0.0445) |  Loss2: (0.0000) | Acc: (98.00%) (49285/50000)
# TEST : Loss: (0.4601) | Acc: (88.00%) (8864/10000)
percent tensor([0.5779, 0.5899, 0.6236, 0.6132, 0.6264, 0.5878, 0.6030, 0.6189, 0.5904,
        0.5980, 0.5746, 0.6156, 0.5794, 0.5890, 0.5926, 0.5837],
       device='cuda:0') torch.Size([16])
percent tensor([0.5882, 0.5924, 0.5808, 0.5780, 0.5886, 0.5866, 0.5968, 0.5880, 0.5829,
        0.5890, 0.5897, 0.5935, 0.5871, 0.5866, 0.5950, 0.5891],
       device='cuda:0') torch.Size([16])
percent tensor([0.6439, 0.6657, 0.6006, 0.5696, 0.5786, 0.5990, 0.6387, 0.5927, 0.6237,
        0.6658, 0.6515, 0.6267, 0.6830, 0.6405, 0.6348, 0.6520],
       device='cuda:0') torch.Size([16])
percent tensor([0.7032, 0.6895, 0.6623, 0.6651, 0.6745, 0.7134, 0.7037, 0.6689, 0.6820,
        0.6959, 0.6968, 0.6826, 0.6951, 0.6927, 0.7044, 0.7037],
       device='cuda:0') torch.Size([16])
percent tensor([0.5967, 0.5206, 0.6624, 0.6853, 0.6852, 0.6347, 0.6003, 0.6709, 0.6343,
        0.5554, 0.5841, 0.6309, 0.4761, 0.6576, 0.6344, 0.6170],
       device='cuda:0') torch.Size([16])
percent tensor([0.5650, 0.7484, 0.7063, 0.6751, 0.6593, 0.7398, 0.6811, 0.6116, 0.7012,
        0.7040, 0.7688, 0.6896, 0.7411, 0.7444, 0.5339, 0.5121],
       device='cuda:0') torch.Size([16])
percent tensor([0.6782, 0.7436, 0.7421, 0.6642, 0.6391, 0.7146, 0.7279, 0.6631, 0.6812,
        0.7336, 0.7304, 0.6288, 0.7522, 0.7190, 0.5435, 0.5989],
       device='cuda:0') torch.Size([16])
percent tensor([0.9998, 0.9999, 0.9999, 0.9999, 0.9997, 0.9997, 0.9999, 0.9999, 1.0000,
        1.0000, 1.0000, 0.9999, 0.9999, 0.9999, 0.9999, 0.9993],
       device='cuda:0') torch.Size([16])
Epoch: 227 | Batch_idx: 0 |  Loss: (0.0221) |  Loss2: (0.0000) | Acc: (99.00%) (127/128)
Epoch: 227 | Batch_idx: 10 |  Loss: (0.0451) |  Loss2: (0.0000) | Acc: (98.00%) (1387/1408)
Epoch: 227 | Batch_idx: 20 |  Loss: (0.0470) |  Loss2: (0.0000) | Acc: (98.00%) (2648/2688)
Epoch: 227 | Batch_idx: 30 |  Loss: (0.0443) |  Loss2: (0.0000) | Acc: (98.00%) (3914/3968)
Epoch: 227 | Batch_idx: 40 |  Loss: (0.0428) |  Loss2: (0.0000) | Acc: (98.00%) (5181/5248)
Epoch: 227 | Batch_idx: 50 |  Loss: (0.0427) |  Loss2: (0.0000) | Acc: (98.00%) (6445/6528)
Epoch: 227 | Batch_idx: 60 |  Loss: (0.0405) |  Loss2: (0.0000) | Acc: (98.00%) (7714/7808)
Epoch: 227 | Batch_idx: 70 |  Loss: (0.0429) |  Loss2: (0.0000) | Acc: (98.00%) (8972/9088)
Epoch: 227 | Batch_idx: 80 |  Loss: (0.0432) |  Loss2: (0.0000) | Acc: (98.00%) (10233/10368)
Epoch: 227 | Batch_idx: 90 |  Loss: (0.0428) |  Loss2: (0.0000) | Acc: (98.00%) (11499/11648)
Epoch: 227 | Batch_idx: 100 |  Loss: (0.0416) |  Loss2: (0.0000) | Acc: (98.00%) (12767/12928)
Epoch: 227 | Batch_idx: 110 |  Loss: (0.0423) |  Loss2: (0.0000) | Acc: (98.00%) (14028/14208)
Epoch: 227 | Batch_idx: 120 |  Loss: (0.0423) |  Loss2: (0.0000) | Acc: (98.00%) (15292/15488)
Epoch: 227 | Batch_idx: 130 |  Loss: (0.0425) |  Loss2: (0.0000) | Acc: (98.00%) (16554/16768)
Epoch: 227 | Batch_idx: 140 |  Loss: (0.0420) |  Loss2: (0.0000) | Acc: (98.00%) (17820/18048)
Epoch: 227 | Batch_idx: 150 |  Loss: (0.0420) |  Loss2: (0.0000) | Acc: (98.00%) (19082/19328)
Epoch: 227 | Batch_idx: 160 |  Loss: (0.0422) |  Loss2: (0.0000) | Acc: (98.00%) (20344/20608)
Epoch: 227 | Batch_idx: 170 |  Loss: (0.0425) |  Loss2: (0.0000) | Acc: (98.00%) (21606/21888)
Epoch: 227 | Batch_idx: 180 |  Loss: (0.0428) |  Loss2: (0.0000) | Acc: (98.00%) (22865/23168)
Epoch: 227 | Batch_idx: 190 |  Loss: (0.0438) |  Loss2: (0.0000) | Acc: (98.00%) (24120/24448)
Epoch: 227 | Batch_idx: 200 |  Loss: (0.0436) |  Loss2: (0.0000) | Acc: (98.00%) (25384/25728)
Epoch: 227 | Batch_idx: 210 |  Loss: (0.0433) |  Loss2: (0.0000) | Acc: (98.00%) (26650/27008)
Epoch: 227 | Batch_idx: 220 |  Loss: (0.0434) |  Loss2: (0.0000) | Acc: (98.00%) (27913/28288)
Epoch: 227 | Batch_idx: 230 |  Loss: (0.0434) |  Loss2: (0.0000) | Acc: (98.00%) (29178/29568)
Epoch: 227 | Batch_idx: 240 |  Loss: (0.0434) |  Loss2: (0.0000) | Acc: (98.00%) (30439/30848)
Epoch: 227 | Batch_idx: 250 |  Loss: (0.0435) |  Loss2: (0.0000) | Acc: (98.00%) (31700/32128)
Epoch: 227 | Batch_idx: 260 |  Loss: (0.0439) |  Loss2: (0.0000) | Acc: (98.00%) (32955/33408)
Epoch: 227 | Batch_idx: 270 |  Loss: (0.0439) |  Loss2: (0.0000) | Acc: (98.00%) (34216/34688)
Epoch: 227 | Batch_idx: 280 |  Loss: (0.0439) |  Loss2: (0.0000) | Acc: (98.00%) (35479/35968)
Epoch: 227 | Batch_idx: 290 |  Loss: (0.0439) |  Loss2: (0.0000) | Acc: (98.00%) (36740/37248)
Epoch: 227 | Batch_idx: 300 |  Loss: (0.0436) |  Loss2: (0.0000) | Acc: (98.00%) (38011/38528)
Epoch: 227 | Batch_idx: 310 |  Loss: (0.0434) |  Loss2: (0.0000) | Acc: (98.00%) (39275/39808)
Epoch: 227 | Batch_idx: 320 |  Loss: (0.0436) |  Loss2: (0.0000) | Acc: (98.00%) (40535/41088)
Epoch: 227 | Batch_idx: 330 |  Loss: (0.0436) |  Loss2: (0.0000) | Acc: (98.00%) (41799/42368)
Epoch: 227 | Batch_idx: 340 |  Loss: (0.0438) |  Loss2: (0.0000) | Acc: (98.00%) (43066/43648)
Epoch: 227 | Batch_idx: 350 |  Loss: (0.0434) |  Loss2: (0.0000) | Acc: (98.00%) (44336/44928)
Epoch: 227 | Batch_idx: 360 |  Loss: (0.0433) |  Loss2: (0.0000) | Acc: (98.00%) (45600/46208)
Epoch: 227 | Batch_idx: 370 |  Loss: (0.0431) |  Loss2: (0.0000) | Acc: (98.00%) (46867/47488)
Epoch: 227 | Batch_idx: 380 |  Loss: (0.0429) |  Loss2: (0.0000) | Acc: (98.00%) (48133/48768)
Epoch: 227 | Batch_idx: 390 |  Loss: (0.0429) |  Loss2: (0.0000) | Acc: (98.00%) (49348/50000)
# TEST : Loss: (0.4428) | Acc: (89.00%) (8914/10000)
percent tensor([0.5792, 0.5945, 0.6204, 0.6133, 0.6234, 0.5887, 0.6052, 0.6202, 0.5914,
        0.5998, 0.5769, 0.6127, 0.5800, 0.5956, 0.5945, 0.5866],
       device='cuda:0') torch.Size([16])
percent tensor([0.5893, 0.5943, 0.5831, 0.5798, 0.5914, 0.5877, 0.5993, 0.5906, 0.5846,
        0.5908, 0.5908, 0.5952, 0.5881, 0.5892, 0.5963, 0.5902],
       device='cuda:0') torch.Size([16])
percent tensor([0.6463, 0.6589, 0.6126, 0.5783, 0.5854, 0.6048, 0.6357, 0.5913, 0.6249,
        0.6630, 0.6463, 0.6322, 0.6851, 0.6360, 0.6339, 0.6515],
       device='cuda:0') torch.Size([16])
percent tensor([0.7042, 0.6943, 0.6645, 0.6652, 0.6763, 0.7167, 0.7066, 0.6681, 0.6854,
        0.6998, 0.6987, 0.6851, 0.7011, 0.6985, 0.7055, 0.7080],
       device='cuda:0') torch.Size([16])
percent tensor([0.5953, 0.5295, 0.6585, 0.6813, 0.6748, 0.6255, 0.6025, 0.6657, 0.6278,
        0.5554, 0.5904, 0.6048, 0.4673, 0.6490, 0.6414, 0.6192],
       device='cuda:0') torch.Size([16])
percent tensor([0.5658, 0.7526, 0.7172, 0.6696, 0.6610, 0.7575, 0.7008, 0.5795, 0.7158,
        0.7014, 0.7725, 0.7030, 0.7592, 0.7603, 0.5338, 0.5164],
       device='cuda:0') torch.Size([16])
percent tensor([0.6843, 0.7505, 0.7305, 0.6452, 0.6388, 0.7359, 0.7342, 0.6627, 0.6795,
        0.7301, 0.7257, 0.6150, 0.7463, 0.7089, 0.5419, 0.6002],
       device='cuda:0') torch.Size([16])
percent tensor([0.9998, 0.9999, 0.9999, 0.9998, 0.9998, 0.9998, 0.9999, 0.9999, 0.9999,
        1.0000, 1.0000, 0.9999, 0.9999, 0.9998, 0.9999, 0.9995],
       device='cuda:0') torch.Size([16])
Epoch: 228 | Batch_idx: 0 |  Loss: (0.0294) |  Loss2: (0.0000) | Acc: (98.00%) (126/128)
Epoch: 228 | Batch_idx: 10 |  Loss: (0.0387) |  Loss2: (0.0000) | Acc: (98.00%) (1390/1408)
Epoch: 228 | Batch_idx: 20 |  Loss: (0.0392) |  Loss2: (0.0000) | Acc: (98.00%) (2655/2688)
Epoch: 228 | Batch_idx: 30 |  Loss: (0.0406) |  Loss2: (0.0000) | Acc: (98.00%) (3916/3968)
Epoch: 228 | Batch_idx: 40 |  Loss: (0.0387) |  Loss2: (0.0000) | Acc: (98.00%) (5187/5248)
Epoch: 228 | Batch_idx: 50 |  Loss: (0.0381) |  Loss2: (0.0000) | Acc: (98.00%) (6455/6528)
Epoch: 228 | Batch_idx: 60 |  Loss: (0.0368) |  Loss2: (0.0000) | Acc: (98.00%) (7724/7808)
Epoch: 228 | Batch_idx: 70 |  Loss: (0.0362) |  Loss2: (0.0000) | Acc: (98.00%) (8992/9088)
Epoch: 228 | Batch_idx: 80 |  Loss: (0.0365) |  Loss2: (0.0000) | Acc: (98.00%) (10254/10368)
Epoch: 228 | Batch_idx: 90 |  Loss: (0.0364) |  Loss2: (0.0000) | Acc: (98.00%) (11521/11648)
Epoch: 228 | Batch_idx: 100 |  Loss: (0.0357) |  Loss2: (0.0000) | Acc: (98.00%) (12790/12928)
Epoch: 228 | Batch_idx: 110 |  Loss: (0.0355) |  Loss2: (0.0000) | Acc: (98.00%) (14056/14208)
Epoch: 228 | Batch_idx: 120 |  Loss: (0.0354) |  Loss2: (0.0000) | Acc: (98.00%) (15325/15488)
Epoch: 228 | Batch_idx: 130 |  Loss: (0.0354) |  Loss2: (0.0000) | Acc: (98.00%) (16593/16768)
Epoch: 228 | Batch_idx: 140 |  Loss: (0.0355) |  Loss2: (0.0000) | Acc: (98.00%) (17858/18048)
Epoch: 228 | Batch_idx: 150 |  Loss: (0.0351) |  Loss2: (0.0000) | Acc: (98.00%) (19128/19328)
Epoch: 228 | Batch_idx: 160 |  Loss: (0.0357) |  Loss2: (0.0000) | Acc: (98.00%) (20389/20608)
Epoch: 228 | Batch_idx: 170 |  Loss: (0.0354) |  Loss2: (0.0000) | Acc: (98.00%) (21657/21888)
Epoch: 228 | Batch_idx: 180 |  Loss: (0.0354) |  Loss2: (0.0000) | Acc: (98.00%) (22925/23168)
Epoch: 228 | Batch_idx: 190 |  Loss: (0.0358) |  Loss2: (0.0000) | Acc: (98.00%) (24180/24448)
Epoch: 228 | Batch_idx: 200 |  Loss: (0.0353) |  Loss2: (0.0000) | Acc: (98.00%) (25452/25728)
Epoch: 228 | Batch_idx: 210 |  Loss: (0.0356) |  Loss2: (0.0000) | Acc: (98.00%) (26711/27008)
Epoch: 228 | Batch_idx: 220 |  Loss: (0.0362) |  Loss2: (0.0000) | Acc: (98.00%) (27974/28288)
Epoch: 228 | Batch_idx: 230 |  Loss: (0.0367) |  Loss2: (0.0000) | Acc: (98.00%) (29236/29568)
Epoch: 228 | Batch_idx: 240 |  Loss: (0.0371) |  Loss2: (0.0000) | Acc: (98.00%) (30496/30848)
Epoch: 228 | Batch_idx: 250 |  Loss: (0.0372) |  Loss2: (0.0000) | Acc: (98.00%) (31763/32128)
Epoch: 228 | Batch_idx: 260 |  Loss: (0.0379) |  Loss2: (0.0000) | Acc: (98.00%) (33021/33408)
Epoch: 228 | Batch_idx: 270 |  Loss: (0.0379) |  Loss2: (0.0000) | Acc: (98.00%) (34284/34688)
Epoch: 228 | Batch_idx: 280 |  Loss: (0.0381) |  Loss2: (0.0000) | Acc: (98.00%) (35550/35968)
Epoch: 228 | Batch_idx: 290 |  Loss: (0.0384) |  Loss2: (0.0000) | Acc: (98.00%) (36803/37248)
Epoch: 228 | Batch_idx: 300 |  Loss: (0.0388) |  Loss2: (0.0000) | Acc: (98.00%) (38058/38528)
Epoch: 228 | Batch_idx: 310 |  Loss: (0.0389) |  Loss2: (0.0000) | Acc: (98.00%) (39321/39808)
Epoch: 228 | Batch_idx: 320 |  Loss: (0.0391) |  Loss2: (0.0000) | Acc: (98.00%) (40579/41088)
Epoch: 228 | Batch_idx: 330 |  Loss: (0.0393) |  Loss2: (0.0000) | Acc: (98.00%) (41838/42368)
Epoch: 228 | Batch_idx: 340 |  Loss: (0.0397) |  Loss2: (0.0000) | Acc: (98.00%) (43094/43648)
Epoch: 228 | Batch_idx: 350 |  Loss: (0.0400) |  Loss2: (0.0000) | Acc: (98.00%) (44354/44928)
Epoch: 228 | Batch_idx: 360 |  Loss: (0.0401) |  Loss2: (0.0000) | Acc: (98.00%) (45612/46208)
Epoch: 228 | Batch_idx: 370 |  Loss: (0.0399) |  Loss2: (0.0000) | Acc: (98.00%) (46875/47488)
Epoch: 228 | Batch_idx: 380 |  Loss: (0.0400) |  Loss2: (0.0000) | Acc: (98.00%) (48135/48768)
Epoch: 228 | Batch_idx: 390 |  Loss: (0.0402) |  Loss2: (0.0000) | Acc: (98.00%) (49349/50000)
# TEST : Loss: (0.4406) | Acc: (88.00%) (8881/10000)
percent tensor([0.5769, 0.5931, 0.6168, 0.6129, 0.6213, 0.5881, 0.6025, 0.6183, 0.5884,
        0.5979, 0.5745, 0.6096, 0.5783, 0.5943, 0.5937, 0.5850],
       device='cuda:0') torch.Size([16])
percent tensor([0.5884, 0.5927, 0.5827, 0.5788, 0.5904, 0.5879, 0.5973, 0.5893, 0.5833,
        0.5891, 0.5899, 0.5942, 0.5871, 0.5860, 0.5959, 0.5893],
       device='cuda:0') torch.Size([16])
percent tensor([0.6474, 0.6680, 0.6079, 0.5787, 0.5797, 0.6079, 0.6424, 0.5977, 0.6258,
        0.6662, 0.6504, 0.6324, 0.6870, 0.6472, 0.6386, 0.6549],
       device='cuda:0') torch.Size([16])
percent tensor([0.7041, 0.6952, 0.6643, 0.6659, 0.6740, 0.7170, 0.7044, 0.6677, 0.6849,
        0.6980, 0.7002, 0.6848, 0.7001, 0.6983, 0.7062, 0.7085],
       device='cuda:0') torch.Size([16])
percent tensor([0.5951, 0.5306, 0.6539, 0.6933, 0.6881, 0.6484, 0.6036, 0.6652, 0.6449,
        0.5563, 0.5995, 0.6085, 0.4751, 0.6613, 0.6378, 0.6225],
       device='cuda:0') torch.Size([16])
percent tensor([0.5628, 0.7308, 0.6981, 0.6687, 0.6588, 0.7414, 0.6920, 0.5631, 0.7128,
        0.6752, 0.7525, 0.6836, 0.7555, 0.7529, 0.4934, 0.5086],
       device='cuda:0') torch.Size([16])
percent tensor([0.6812, 0.7335, 0.7093, 0.6215, 0.6388, 0.7272, 0.7242, 0.6431, 0.6808,
        0.7160, 0.7033, 0.5947, 0.7458, 0.7077, 0.5280, 0.5845],
       device='cuda:0') torch.Size([16])
percent tensor([0.9998, 0.9999, 0.9999, 0.9998, 0.9997, 0.9998, 0.9999, 0.9999, 1.0000,
        0.9999, 1.0000, 0.9998, 0.9999, 0.9998, 0.9999, 0.9994],
       device='cuda:0') torch.Size([16])
Epoch: 229 | Batch_idx: 0 |  Loss: (0.0391) |  Loss2: (0.0000) | Acc: (97.00%) (125/128)
Epoch: 229 | Batch_idx: 10 |  Loss: (0.0395) |  Loss2: (0.0000) | Acc: (98.00%) (1390/1408)
Epoch: 229 | Batch_idx: 20 |  Loss: (0.0363) |  Loss2: (0.0000) | Acc: (98.00%) (2656/2688)
Epoch: 229 | Batch_idx: 30 |  Loss: (0.0405) |  Loss2: (0.0000) | Acc: (98.00%) (3916/3968)
Epoch: 229 | Batch_idx: 40 |  Loss: (0.0401) |  Loss2: (0.0000) | Acc: (98.00%) (5183/5248)
Epoch: 229 | Batch_idx: 50 |  Loss: (0.0391) |  Loss2: (0.0000) | Acc: (98.00%) (6451/6528)
Epoch: 229 | Batch_idx: 60 |  Loss: (0.0372) |  Loss2: (0.0000) | Acc: (98.00%) (7720/7808)
Epoch: 229 | Batch_idx: 70 |  Loss: (0.0372) |  Loss2: (0.0000) | Acc: (98.00%) (8988/9088)
Epoch: 229 | Batch_idx: 80 |  Loss: (0.0375) |  Loss2: (0.0000) | Acc: (98.00%) (10253/10368)
Epoch: 229 | Batch_idx: 90 |  Loss: (0.0369) |  Loss2: (0.0000) | Acc: (98.00%) (11520/11648)
Epoch: 229 | Batch_idx: 100 |  Loss: (0.0374) |  Loss2: (0.0000) | Acc: (98.00%) (12779/12928)
Epoch: 229 | Batch_idx: 110 |  Loss: (0.0371) |  Loss2: (0.0000) | Acc: (98.00%) (14045/14208)
Epoch: 229 | Batch_idx: 120 |  Loss: (0.0370) |  Loss2: (0.0000) | Acc: (98.00%) (15312/15488)
Epoch: 229 | Batch_idx: 130 |  Loss: (0.0366) |  Loss2: (0.0000) | Acc: (98.00%) (16579/16768)
Epoch: 229 | Batch_idx: 140 |  Loss: (0.0363) |  Loss2: (0.0000) | Acc: (98.00%) (17847/18048)
Epoch: 229 | Batch_idx: 150 |  Loss: (0.0363) |  Loss2: (0.0000) | Acc: (98.00%) (19116/19328)
Epoch: 229 | Batch_idx: 160 |  Loss: (0.0360) |  Loss2: (0.0000) | Acc: (98.00%) (20382/20608)
Epoch: 229 | Batch_idx: 170 |  Loss: (0.0357) |  Loss2: (0.0000) | Acc: (98.00%) (21650/21888)
Epoch: 229 | Batch_idx: 180 |  Loss: (0.0361) |  Loss2: (0.0000) | Acc: (98.00%) (22912/23168)
Epoch: 229 | Batch_idx: 190 |  Loss: (0.0361) |  Loss2: (0.0000) | Acc: (98.00%) (24182/24448)
Epoch: 229 | Batch_idx: 200 |  Loss: (0.0363) |  Loss2: (0.0000) | Acc: (98.00%) (25446/25728)
Epoch: 229 | Batch_idx: 210 |  Loss: (0.0365) |  Loss2: (0.0000) | Acc: (98.00%) (26708/27008)
Epoch: 229 | Batch_idx: 220 |  Loss: (0.0364) |  Loss2: (0.0000) | Acc: (98.00%) (27973/28288)
Epoch: 229 | Batch_idx: 230 |  Loss: (0.0363) |  Loss2: (0.0000) | Acc: (98.00%) (29237/29568)
Epoch: 229 | Batch_idx: 240 |  Loss: (0.0365) |  Loss2: (0.0000) | Acc: (98.00%) (30502/30848)
Epoch: 229 | Batch_idx: 250 |  Loss: (0.0368) |  Loss2: (0.0000) | Acc: (98.00%) (31763/32128)
Epoch: 229 | Batch_idx: 260 |  Loss: (0.0368) |  Loss2: (0.0000) | Acc: (98.00%) (33028/33408)
Epoch: 229 | Batch_idx: 270 |  Loss: (0.0368) |  Loss2: (0.0000) | Acc: (98.00%) (34293/34688)
Epoch: 229 | Batch_idx: 280 |  Loss: (0.0366) |  Loss2: (0.0000) | Acc: (98.00%) (35563/35968)
Epoch: 229 | Batch_idx: 290 |  Loss: (0.0368) |  Loss2: (0.0000) | Acc: (98.00%) (36825/37248)
Epoch: 229 | Batch_idx: 300 |  Loss: (0.0371) |  Loss2: (0.0000) | Acc: (98.00%) (38088/38528)
Epoch: 229 | Batch_idx: 310 |  Loss: (0.0370) |  Loss2: (0.0000) | Acc: (98.00%) (39353/39808)
Epoch: 229 | Batch_idx: 320 |  Loss: (0.0372) |  Loss2: (0.0000) | Acc: (98.00%) (40616/41088)
Epoch: 229 | Batch_idx: 330 |  Loss: (0.0374) |  Loss2: (0.0000) | Acc: (98.00%) (41880/42368)
Epoch: 229 | Batch_idx: 340 |  Loss: (0.0375) |  Loss2: (0.0000) | Acc: (98.00%) (43145/43648)
Epoch: 229 | Batch_idx: 350 |  Loss: (0.0376) |  Loss2: (0.0000) | Acc: (98.00%) (44405/44928)
Epoch: 229 | Batch_idx: 360 |  Loss: (0.0377) |  Loss2: (0.0000) | Acc: (98.00%) (45674/46208)
Epoch: 229 | Batch_idx: 370 |  Loss: (0.0379) |  Loss2: (0.0000) | Acc: (98.00%) (46935/47488)
Epoch: 229 | Batch_idx: 380 |  Loss: (0.0378) |  Loss2: (0.0000) | Acc: (98.00%) (48199/48768)
Epoch: 229 | Batch_idx: 390 |  Loss: (0.0379) |  Loss2: (0.0000) | Acc: (98.00%) (49413/50000)
# TEST : Loss: (0.5037) | Acc: (87.00%) (8781/10000)
percent tensor([0.5779, 0.5922, 0.6165, 0.6106, 0.6199, 0.5882, 0.6025, 0.6171, 0.5899,
        0.5973, 0.5768, 0.6098, 0.5788, 0.5940, 0.5932, 0.5857],
       device='cuda:0') torch.Size([16])
percent tensor([0.5893, 0.5931, 0.5852, 0.5801, 0.5925, 0.5887, 0.5989, 0.5912, 0.5844,
        0.5908, 0.5906, 0.5959, 0.5878, 0.5876, 0.5959, 0.5897],
       device='cuda:0') torch.Size([16])
percent tensor([0.6476, 0.6623, 0.6098, 0.5784, 0.5851, 0.6092, 0.6412, 0.5952, 0.6250,
        0.6649, 0.6481, 0.6293, 0.6854, 0.6427, 0.6348, 0.6523],
       device='cuda:0') torch.Size([16])
percent tensor([0.7073, 0.6996, 0.6666, 0.6708, 0.6790, 0.7189, 0.7089, 0.6721, 0.6879,
        0.7043, 0.7042, 0.6878, 0.7029, 0.7021, 0.7079, 0.7117],
       device='cuda:0') torch.Size([16])
percent tensor([0.5759, 0.5207, 0.6507, 0.6902, 0.6806, 0.6299, 0.5935, 0.6583, 0.6285,
        0.5491, 0.5938, 0.5915, 0.4565, 0.6527, 0.6251, 0.6207],
       device='cuda:0') torch.Size([16])
percent tensor([0.5546, 0.7136, 0.6946, 0.6627, 0.6447, 0.7436, 0.6922, 0.6052, 0.7030,
        0.6630, 0.7568, 0.6612, 0.7329, 0.7227, 0.5074, 0.4699],
       device='cuda:0') torch.Size([16])
percent tensor([0.6736, 0.7267, 0.7207, 0.6315, 0.6335, 0.7312, 0.7296, 0.6674, 0.6808,
        0.7155, 0.7240, 0.5945, 0.7369, 0.7022, 0.5419, 0.5808],
       device='cuda:0') torch.Size([16])
percent tensor([0.9998, 0.9999, 0.9999, 0.9997, 0.9997, 0.9998, 0.9999, 0.9999, 0.9999,
        0.9999, 1.0000, 0.9998, 0.9999, 0.9998, 0.9998, 0.9994],
       device='cuda:0') torch.Size([16])
Epoch: 230 | Batch_idx: 0 |  Loss: (0.0327) |  Loss2: (0.0000) | Acc: (99.00%) (127/128)
Epoch: 230 | Batch_idx: 10 |  Loss: (0.0400) |  Loss2: (0.0000) | Acc: (98.00%) (1389/1408)
Epoch: 230 | Batch_idx: 20 |  Loss: (0.0471) |  Loss2: (0.0000) | Acc: (98.00%) (2646/2688)
Epoch: 230 | Batch_idx: 30 |  Loss: (0.0454) |  Loss2: (0.0000) | Acc: (98.00%) (3907/3968)
Epoch: 230 | Batch_idx: 40 |  Loss: (0.0458) |  Loss2: (0.0000) | Acc: (98.00%) (5166/5248)
Epoch: 230 | Batch_idx: 50 |  Loss: (0.0450) |  Loss2: (0.0000) | Acc: (98.00%) (6430/6528)
Epoch: 230 | Batch_idx: 60 |  Loss: (0.0437) |  Loss2: (0.0000) | Acc: (98.00%) (7695/7808)
Epoch: 230 | Batch_idx: 70 |  Loss: (0.0420) |  Loss2: (0.0000) | Acc: (98.00%) (8964/9088)
Epoch: 230 | Batch_idx: 80 |  Loss: (0.0412) |  Loss2: (0.0000) | Acc: (98.00%) (10232/10368)
Epoch: 230 | Batch_idx: 90 |  Loss: (0.0397) |  Loss2: (0.0000) | Acc: (98.00%) (11502/11648)
Epoch: 230 | Batch_idx: 100 |  Loss: (0.0396) |  Loss2: (0.0000) | Acc: (98.00%) (12766/12928)
Epoch: 230 | Batch_idx: 110 |  Loss: (0.0391) |  Loss2: (0.0000) | Acc: (98.00%) (14034/14208)
Epoch: 230 | Batch_idx: 120 |  Loss: (0.0389) |  Loss2: (0.0000) | Acc: (98.00%) (15300/15488)
Epoch: 230 | Batch_idx: 130 |  Loss: (0.0389) |  Loss2: (0.0000) | Acc: (98.00%) (16565/16768)
Epoch: 230 | Batch_idx: 140 |  Loss: (0.0391) |  Loss2: (0.0000) | Acc: (98.00%) (17826/18048)
Epoch: 230 | Batch_idx: 150 |  Loss: (0.0383) |  Loss2: (0.0000) | Acc: (98.00%) (19099/19328)
Epoch: 230 | Batch_idx: 160 |  Loss: (0.0384) |  Loss2: (0.0000) | Acc: (98.00%) (20363/20608)
Epoch: 230 | Batch_idx: 170 |  Loss: (0.0381) |  Loss2: (0.0000) | Acc: (98.00%) (21629/21888)
Epoch: 230 | Batch_idx: 180 |  Loss: (0.0377) |  Loss2: (0.0000) | Acc: (98.00%) (22897/23168)
Epoch: 230 | Batch_idx: 190 |  Loss: (0.0378) |  Loss2: (0.0000) | Acc: (98.00%) (24161/24448)
Epoch: 230 | Batch_idx: 200 |  Loss: (0.0382) |  Loss2: (0.0000) | Acc: (98.00%) (25422/25728)
Epoch: 230 | Batch_idx: 210 |  Loss: (0.0380) |  Loss2: (0.0000) | Acc: (98.00%) (26691/27008)
Epoch: 230 | Batch_idx: 220 |  Loss: (0.0379) |  Loss2: (0.0000) | Acc: (98.00%) (27953/28288)
Epoch: 230 | Batch_idx: 230 |  Loss: (0.0376) |  Loss2: (0.0000) | Acc: (98.00%) (29221/29568)
Epoch: 230 | Batch_idx: 240 |  Loss: (0.0373) |  Loss2: (0.0000) | Acc: (98.00%) (30486/30848)
Epoch: 230 | Batch_idx: 250 |  Loss: (0.0373) |  Loss2: (0.0000) | Acc: (98.00%) (31753/32128)
Epoch: 230 | Batch_idx: 260 |  Loss: (0.0376) |  Loss2: (0.0000) | Acc: (98.00%) (33017/33408)
Epoch: 230 | Batch_idx: 270 |  Loss: (0.0376) |  Loss2: (0.0000) | Acc: (98.00%) (34282/34688)
Epoch: 230 | Batch_idx: 280 |  Loss: (0.0380) |  Loss2: (0.0000) | Acc: (98.00%) (35540/35968)
Epoch: 230 | Batch_idx: 290 |  Loss: (0.0384) |  Loss2: (0.0000) | Acc: (98.00%) (36800/37248)
Epoch: 230 | Batch_idx: 300 |  Loss: (0.0385) |  Loss2: (0.0000) | Acc: (98.00%) (38064/38528)
Epoch: 230 | Batch_idx: 310 |  Loss: (0.0390) |  Loss2: (0.0000) | Acc: (98.00%) (39318/39808)
Epoch: 230 | Batch_idx: 320 |  Loss: (0.0393) |  Loss2: (0.0000) | Acc: (98.00%) (40578/41088)
Epoch: 230 | Batch_idx: 330 |  Loss: (0.0395) |  Loss2: (0.0000) | Acc: (98.00%) (41842/42368)
Epoch: 230 | Batch_idx: 340 |  Loss: (0.0394) |  Loss2: (0.0000) | Acc: (98.00%) (43109/43648)
Epoch: 230 | Batch_idx: 350 |  Loss: (0.0395) |  Loss2: (0.0000) | Acc: (98.00%) (44372/44928)
Epoch: 230 | Batch_idx: 360 |  Loss: (0.0396) |  Loss2: (0.0000) | Acc: (98.00%) (45632/46208)
Epoch: 230 | Batch_idx: 370 |  Loss: (0.0395) |  Loss2: (0.0000) | Acc: (98.00%) (46898/47488)
Epoch: 230 | Batch_idx: 380 |  Loss: (0.0397) |  Loss2: (0.0000) | Acc: (98.00%) (48154/48768)
Epoch: 230 | Batch_idx: 390 |  Loss: (0.0398) |  Loss2: (0.0000) | Acc: (98.00%) (49367/50000)
=> saving checkpoint 'drive/app/torch/save_Schedule/checkpoint_230.pth.tar'
# TEST : Loss: (0.4533) | Acc: (89.00%) (8905/10000)
percent tensor([0.5803, 0.5938, 0.6237, 0.6139, 0.6261, 0.5900, 0.6060, 0.6203, 0.5926,
        0.6003, 0.5775, 0.6163, 0.5806, 0.5951, 0.5951, 0.5870],
       device='cuda:0') torch.Size([16])
percent tensor([0.5884, 0.5939, 0.5828, 0.5795, 0.5902, 0.5875, 0.5986, 0.5902, 0.5832,
        0.5899, 0.5902, 0.5943, 0.5869, 0.5877, 0.5964, 0.5891],
       device='cuda:0') torch.Size([16])
percent tensor([0.6469, 0.6677, 0.6053, 0.5746, 0.5800, 0.6028, 0.6403, 0.5932, 0.6227,
        0.6664, 0.6510, 0.6317, 0.6862, 0.6401, 0.6372, 0.6515],
       device='cuda:0') torch.Size([16])
percent tensor([0.7051, 0.6978, 0.6695, 0.6722, 0.6785, 0.7192, 0.7080, 0.6722, 0.6854,
        0.7005, 0.7007, 0.6856, 0.6978, 0.7020, 0.7103, 0.7118],
       device='cuda:0') torch.Size([16])
percent tensor([0.5844, 0.5179, 0.6629, 0.6931, 0.6845, 0.6406, 0.5991, 0.6669, 0.6266,
        0.5558, 0.5940, 0.6034, 0.4696, 0.6405, 0.6205, 0.6151],
       device='cuda:0') torch.Size([16])
percent tensor([0.5671, 0.7466, 0.7149, 0.6812, 0.6611, 0.7446, 0.7084, 0.6055, 0.7411,
        0.6885, 0.7867, 0.7075, 0.7762, 0.7554, 0.5289, 0.5033],
       device='cuda:0') torch.Size([16])
percent tensor([0.6799, 0.7418, 0.7372, 0.6486, 0.6485, 0.7362, 0.7351, 0.6608, 0.7149,
        0.7345, 0.7352, 0.6314, 0.7611, 0.7181, 0.5337, 0.5909],
       device='cuda:0') torch.Size([16])
percent tensor([0.9998, 0.9999, 0.9999, 0.9999, 0.9997, 0.9997, 0.9999, 1.0000, 1.0000,
        1.0000, 1.0000, 0.9999, 0.9999, 0.9998, 0.9999, 0.9994],
       device='cuda:0') torch.Size([16])
Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 3, 3, 3]) tensor(193.7624, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(836.9158, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(861.0412, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([128, 64, 3, 3]) tensor(1524.8354, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([128, 64, 1, 1]) tensor(477.2711, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([128, 128, 3, 3]) tensor(2326.3960, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([256, 128, 3, 3]) tensor(4250.1211, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([256, 128, 1, 1]) tensor(1327.1104, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([256, 256, 3, 3]) tensor(6359.3320, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([512, 256, 3, 3]) tensor(11449.1807, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([512, 256, 1, 1]) tensor(3745.5544, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([512, 512, 3, 3]) tensor(15799.6074, device='cuda:0', grad_fn=<NormBackward0>)
Epoch: 231 | Batch_idx: 0 |  Loss: (0.0344) |  Loss2: (0.0000) | Acc: (99.00%) (127/128)
Epoch: 231 | Batch_idx: 10 |  Loss: (0.0292) |  Loss2: (0.0000) | Acc: (99.00%) (1396/1408)
Epoch: 231 | Batch_idx: 20 |  Loss: (0.0425) |  Loss2: (0.0000) | Acc: (98.00%) (2650/2688)
Epoch: 231 | Batch_idx: 30 |  Loss: (0.0435) |  Loss2: (0.0000) | Acc: (98.00%) (3911/3968)
Epoch: 231 | Batch_idx: 40 |  Loss: (0.0399) |  Loss2: (0.0000) | Acc: (98.00%) (5179/5248)
Epoch: 231 | Batch_idx: 50 |  Loss: (0.0392) |  Loss2: (0.0000) | Acc: (98.00%) (6444/6528)
Epoch: 231 | Batch_idx: 60 |  Loss: (0.0385) |  Loss2: (0.0000) | Acc: (98.00%) (7713/7808)
Epoch: 231 | Batch_idx: 70 |  Loss: (0.0400) |  Loss2: (0.0000) | Acc: (98.00%) (8970/9088)
Epoch: 231 | Batch_idx: 80 |  Loss: (0.0406) |  Loss2: (0.0000) | Acc: (98.00%) (10228/10368)
Epoch: 231 | Batch_idx: 90 |  Loss: (0.0404) |  Loss2: (0.0000) | Acc: (98.00%) (11493/11648)
Epoch: 231 | Batch_idx: 100 |  Loss: (0.0418) |  Loss2: (0.0000) | Acc: (98.00%) (12751/12928)
Epoch: 231 | Batch_idx: 110 |  Loss: (0.0419) |  Loss2: (0.0000) | Acc: (98.00%) (14015/14208)
Epoch: 231 | Batch_idx: 120 |  Loss: (0.0413) |  Loss2: (0.0000) | Acc: (98.00%) (15280/15488)
Epoch: 231 | Batch_idx: 130 |  Loss: (0.0421) |  Loss2: (0.0000) | Acc: (98.00%) (16536/16768)
Epoch: 231 | Batch_idx: 140 |  Loss: (0.0423) |  Loss2: (0.0000) | Acc: (98.00%) (17796/18048)
Epoch: 231 | Batch_idx: 150 |  Loss: (0.0423) |  Loss2: (0.0000) | Acc: (98.00%) (19059/19328)
Epoch: 231 | Batch_idx: 160 |  Loss: (0.0418) |  Loss2: (0.0000) | Acc: (98.00%) (20330/20608)
Epoch: 231 | Batch_idx: 170 |  Loss: (0.0417) |  Loss2: (0.0000) | Acc: (98.00%) (21591/21888)
Epoch: 231 | Batch_idx: 180 |  Loss: (0.0415) |  Loss2: (0.0000) | Acc: (98.00%) (22859/23168)
Epoch: 231 | Batch_idx: 190 |  Loss: (0.0421) |  Loss2: (0.0000) | Acc: (98.00%) (24113/24448)
Epoch: 231 | Batch_idx: 200 |  Loss: (0.0425) |  Loss2: (0.0000) | Acc: (98.00%) (25369/25728)
Epoch: 231 | Batch_idx: 210 |  Loss: (0.0430) |  Loss2: (0.0000) | Acc: (98.00%) (26627/27008)
Epoch: 231 | Batch_idx: 220 |  Loss: (0.0430) |  Loss2: (0.0000) | Acc: (98.00%) (27887/28288)
Epoch: 231 | Batch_idx: 230 |  Loss: (0.0428) |  Loss2: (0.0000) | Acc: (98.00%) (29153/29568)
Epoch: 231 | Batch_idx: 240 |  Loss: (0.0430) |  Loss2: (0.0000) | Acc: (98.00%) (30416/30848)
Epoch: 231 | Batch_idx: 250 |  Loss: (0.0427) |  Loss2: (0.0000) | Acc: (98.00%) (31680/32128)
Epoch: 231 | Batch_idx: 260 |  Loss: (0.0427) |  Loss2: (0.0000) | Acc: (98.00%) (32945/33408)
Epoch: 231 | Batch_idx: 270 |  Loss: (0.0430) |  Loss2: (0.0000) | Acc: (98.00%) (34204/34688)
Epoch: 231 | Batch_idx: 280 |  Loss: (0.0430) |  Loss2: (0.0000) | Acc: (98.00%) (35468/35968)
Epoch: 231 | Batch_idx: 290 |  Loss: (0.0437) |  Loss2: (0.0000) | Acc: (98.00%) (36717/37248)
Epoch: 231 | Batch_idx: 300 |  Loss: (0.0437) |  Loss2: (0.0000) | Acc: (98.00%) (37981/38528)
Epoch: 231 | Batch_idx: 310 |  Loss: (0.0438) |  Loss2: (0.0000) | Acc: (98.00%) (39241/39808)
Epoch: 231 | Batch_idx: 320 |  Loss: (0.0435) |  Loss2: (0.0000) | Acc: (98.00%) (40510/41088)
Epoch: 231 | Batch_idx: 330 |  Loss: (0.0436) |  Loss2: (0.0000) | Acc: (98.00%) (41773/42368)
Epoch: 231 | Batch_idx: 340 |  Loss: (0.0436) |  Loss2: (0.0000) | Acc: (98.00%) (43039/43648)
Epoch: 231 | Batch_idx: 350 |  Loss: (0.0437) |  Loss2: (0.0000) | Acc: (98.00%) (44306/44928)
Epoch: 231 | Batch_idx: 360 |  Loss: (0.0437) |  Loss2: (0.0000) | Acc: (98.00%) (45567/46208)
Epoch: 231 | Batch_idx: 370 |  Loss: (0.0436) |  Loss2: (0.0000) | Acc: (98.00%) (46825/47488)
Epoch: 231 | Batch_idx: 380 |  Loss: (0.0436) |  Loss2: (0.0000) | Acc: (98.00%) (48088/48768)
Epoch: 231 | Batch_idx: 390 |  Loss: (0.0437) |  Loss2: (0.0000) | Acc: (98.00%) (49304/50000)
# TEST : Loss: (0.4562) | Acc: (88.00%) (8876/10000)
percent tensor([0.5803, 0.5956, 0.6204, 0.6138, 0.6244, 0.5903, 0.6055, 0.6208, 0.5924,
        0.6000, 0.5786, 0.6128, 0.5817, 0.5963, 0.5959, 0.5877],
       device='cuda:0') torch.Size([16])
percent tensor([0.5879, 0.5922, 0.5821, 0.5778, 0.5897, 0.5872, 0.5973, 0.5894, 0.5832,
        0.5886, 0.5894, 0.5932, 0.5866, 0.5873, 0.5953, 0.5890],
       device='cuda:0') torch.Size([16])
percent tensor([0.6535, 0.6736, 0.6125, 0.5793, 0.5837, 0.6103, 0.6493, 0.5989, 0.6320,
        0.6719, 0.6579, 0.6356, 0.6937, 0.6481, 0.6426, 0.6598],
       device='cuda:0') torch.Size([16])
percent tensor([0.7108, 0.6990, 0.6657, 0.6679, 0.6771, 0.7225, 0.7122, 0.6733, 0.6898,
        0.7011, 0.7029, 0.6862, 0.7046, 0.7024, 0.7112, 0.7144],
       device='cuda:0') torch.Size([16])
percent tensor([0.5664, 0.5139, 0.6440, 0.6802, 0.6747, 0.6267, 0.5891, 0.6554, 0.6218,
        0.5430, 0.5722, 0.5959, 0.4562, 0.6464, 0.6131, 0.6097],
       device='cuda:0') torch.Size([16])
percent tensor([0.5657, 0.7463, 0.7159, 0.6520, 0.6405, 0.7377, 0.6986, 0.5846, 0.7258,
        0.7082, 0.7804, 0.6867, 0.7624, 0.7508, 0.4912, 0.4875],
       device='cuda:0') torch.Size([16])
percent tensor([0.6749, 0.7475, 0.7415, 0.6527, 0.6452, 0.7232, 0.7378, 0.6648, 0.6894,
        0.7501, 0.7444, 0.6248, 0.7560, 0.7124, 0.5311, 0.5840],
       device='cuda:0') torch.Size([16])
percent tensor([0.9998, 0.9999, 0.9999, 0.9999, 0.9998, 0.9998, 0.9999, 0.9999, 0.9999,
        1.0000, 1.0000, 0.9998, 0.9999, 0.9997, 0.9998, 0.9993],
       device='cuda:0') torch.Size([16])
Epoch: 232 | Batch_idx: 0 |  Loss: (0.0195) |  Loss2: (0.0000) | Acc: (100.00%) (128/128)
Epoch: 232 | Batch_idx: 10 |  Loss: (0.0372) |  Loss2: (0.0000) | Acc: (98.00%) (1389/1408)
Epoch: 232 | Batch_idx: 20 |  Loss: (0.0401) |  Loss2: (0.0000) | Acc: (98.00%) (2652/2688)
Epoch: 232 | Batch_idx: 30 |  Loss: (0.0388) |  Loss2: (0.0000) | Acc: (98.00%) (3917/3968)
Epoch: 232 | Batch_idx: 40 |  Loss: (0.0377) |  Loss2: (0.0000) | Acc: (98.00%) (5183/5248)
Epoch: 232 | Batch_idx: 50 |  Loss: (0.0365) |  Loss2: (0.0000) | Acc: (98.00%) (6452/6528)
Epoch: 232 | Batch_idx: 60 |  Loss: (0.0377) |  Loss2: (0.0000) | Acc: (98.00%) (7711/7808)
Epoch: 232 | Batch_idx: 70 |  Loss: (0.0386) |  Loss2: (0.0000) | Acc: (98.00%) (8968/9088)
Epoch: 232 | Batch_idx: 80 |  Loss: (0.0378) |  Loss2: (0.0000) | Acc: (98.00%) (10239/10368)
Epoch: 232 | Batch_idx: 90 |  Loss: (0.0387) |  Loss2: (0.0000) | Acc: (98.00%) (11498/11648)
Epoch: 232 | Batch_idx: 100 |  Loss: (0.0393) |  Loss2: (0.0000) | Acc: (98.00%) (12757/12928)
Epoch: 232 | Batch_idx: 110 |  Loss: (0.0384) |  Loss2: (0.0000) | Acc: (98.00%) (14026/14208)
Epoch: 232 | Batch_idx: 120 |  Loss: (0.0386) |  Loss2: (0.0000) | Acc: (98.00%) (15287/15488)
Epoch: 232 | Batch_idx: 130 |  Loss: (0.0390) |  Loss2: (0.0000) | Acc: (98.00%) (16546/16768)
Epoch: 232 | Batch_idx: 140 |  Loss: (0.0391) |  Loss2: (0.0000) | Acc: (98.00%) (17812/18048)
Epoch: 232 | Batch_idx: 150 |  Loss: (0.0389) |  Loss2: (0.0000) | Acc: (98.00%) (19075/19328)
Epoch: 232 | Batch_idx: 160 |  Loss: (0.0390) |  Loss2: (0.0000) | Acc: (98.00%) (20338/20608)
Epoch: 232 | Batch_idx: 170 |  Loss: (0.0392) |  Loss2: (0.0000) | Acc: (98.00%) (21599/21888)
Epoch: 232 | Batch_idx: 180 |  Loss: (0.0393) |  Loss2: (0.0000) | Acc: (98.00%) (22866/23168)
Epoch: 232 | Batch_idx: 190 |  Loss: (0.0396) |  Loss2: (0.0000) | Acc: (98.00%) (24128/24448)
Epoch: 232 | Batch_idx: 200 |  Loss: (0.0403) |  Loss2: (0.0000) | Acc: (98.00%) (25385/25728)
Epoch: 232 | Batch_idx: 210 |  Loss: (0.0401) |  Loss2: (0.0000) | Acc: (98.00%) (26652/27008)
Epoch: 232 | Batch_idx: 220 |  Loss: (0.0400) |  Loss2: (0.0000) | Acc: (98.00%) (27919/28288)
Epoch: 232 | Batch_idx: 230 |  Loss: (0.0397) |  Loss2: (0.0000) | Acc: (98.00%) (29184/29568)
Epoch: 232 | Batch_idx: 240 |  Loss: (0.0398) |  Loss2: (0.0000) | Acc: (98.00%) (30451/30848)
Epoch: 232 | Batch_idx: 250 |  Loss: (0.0397) |  Loss2: (0.0000) | Acc: (98.00%) (31714/32128)
Epoch: 232 | Batch_idx: 260 |  Loss: (0.0399) |  Loss2: (0.0000) | Acc: (98.00%) (32974/33408)
Epoch: 232 | Batch_idx: 270 |  Loss: (0.0401) |  Loss2: (0.0000) | Acc: (98.00%) (34232/34688)
Epoch: 232 | Batch_idx: 280 |  Loss: (0.0404) |  Loss2: (0.0000) | Acc: (98.00%) (35492/35968)
Epoch: 232 | Batch_idx: 290 |  Loss: (0.0404) |  Loss2: (0.0000) | Acc: (98.00%) (36760/37248)
Epoch: 232 | Batch_idx: 300 |  Loss: (0.0408) |  Loss2: (0.0000) | Acc: (98.00%) (38020/38528)
Epoch: 232 | Batch_idx: 310 |  Loss: (0.0410) |  Loss2: (0.0000) | Acc: (98.00%) (39284/39808)
Epoch: 232 | Batch_idx: 320 |  Loss: (0.0409) |  Loss2: (0.0000) | Acc: (98.00%) (40547/41088)
Epoch: 232 | Batch_idx: 330 |  Loss: (0.0410) |  Loss2: (0.0000) | Acc: (98.00%) (41810/42368)
Epoch: 232 | Batch_idx: 340 |  Loss: (0.0411) |  Loss2: (0.0000) | Acc: (98.00%) (43073/43648)
Epoch: 232 | Batch_idx: 350 |  Loss: (0.0412) |  Loss2: (0.0000) | Acc: (98.00%) (44335/44928)
Epoch: 232 | Batch_idx: 360 |  Loss: (0.0410) |  Loss2: (0.0000) | Acc: (98.00%) (45606/46208)
Epoch: 232 | Batch_idx: 370 |  Loss: (0.0410) |  Loss2: (0.0000) | Acc: (98.00%) (46870/47488)
Epoch: 232 | Batch_idx: 380 |  Loss: (0.0410) |  Loss2: (0.0000) | Acc: (98.00%) (48133/48768)
Epoch: 232 | Batch_idx: 390 |  Loss: (0.0409) |  Loss2: (0.0000) | Acc: (98.00%) (49351/50000)
# TEST : Loss: (0.4480) | Acc: (88.00%) (8891/10000)
percent tensor([0.5782, 0.5914, 0.6187, 0.6121, 0.6217, 0.5876, 0.6015, 0.6179, 0.5894,
        0.5973, 0.5754, 0.6114, 0.5797, 0.5903, 0.5930, 0.5847],
       device='cuda:0') torch.Size([16])
percent tensor([0.5868, 0.5904, 0.5818, 0.5774, 0.5885, 0.5858, 0.5953, 0.5885, 0.5804,
        0.5871, 0.5876, 0.5929, 0.5850, 0.5822, 0.5938, 0.5869],
       device='cuda:0') torch.Size([16])
percent tensor([0.6520, 0.6725, 0.6034, 0.5773, 0.5766, 0.6064, 0.6451, 0.5932, 0.6306,
        0.6708, 0.6605, 0.6310, 0.6920, 0.6486, 0.6397, 0.6566],
       device='cuda:0') torch.Size([16])
percent tensor([0.7070, 0.6993, 0.6664, 0.6665, 0.6771, 0.7175, 0.7092, 0.6711, 0.6866,
        0.7008, 0.7023, 0.6854, 0.7020, 0.6989, 0.7080, 0.7103],
       device='cuda:0') torch.Size([16])
percent tensor([0.5797, 0.5111, 0.6471, 0.6812, 0.6865, 0.6383, 0.5904, 0.6547, 0.6224,
        0.5458, 0.5693, 0.6039, 0.4627, 0.6475, 0.6212, 0.6195],
       device='cuda:0') torch.Size([16])
percent tensor([0.5437, 0.7647, 0.6825, 0.6339, 0.6325, 0.7328, 0.6997, 0.5918, 0.7167,
        0.6944, 0.7884, 0.6858, 0.7582, 0.7420, 0.5087, 0.4795],
       device='cuda:0') torch.Size([16])
percent tensor([0.6696, 0.7388, 0.7233, 0.6319, 0.6286, 0.7258, 0.7130, 0.6427, 0.6751,
        0.7418, 0.7293, 0.6032, 0.7463, 0.7091, 0.5264, 0.5803],
       device='cuda:0') torch.Size([16])
percent tensor([0.9998, 0.9999, 0.9999, 0.9998, 0.9998, 0.9999, 0.9999, 0.9999, 0.9999,
        1.0000, 1.0000, 0.9998, 0.9999, 0.9998, 0.9999, 0.9993],
       device='cuda:0') torch.Size([16])
Epoch: 233 | Batch_idx: 0 |  Loss: (0.0412) |  Loss2: (0.0000) | Acc: (97.00%) (125/128)
Epoch: 233 | Batch_idx: 10 |  Loss: (0.0349) |  Loss2: (0.0000) | Acc: (99.00%) (1394/1408)
Epoch: 233 | Batch_idx: 20 |  Loss: (0.0387) |  Loss2: (0.0000) | Acc: (98.00%) (2657/2688)
Epoch: 233 | Batch_idx: 30 |  Loss: (0.0393) |  Loss2: (0.0000) | Acc: (98.00%) (3919/3968)
Epoch: 233 | Batch_idx: 40 |  Loss: (0.0378) |  Loss2: (0.0000) | Acc: (98.00%) (5185/5248)
Epoch: 233 | Batch_idx: 50 |  Loss: (0.0380) |  Loss2: (0.0000) | Acc: (98.00%) (6447/6528)
Epoch: 233 | Batch_idx: 60 |  Loss: (0.0369) |  Loss2: (0.0000) | Acc: (98.00%) (7710/7808)
Epoch: 233 | Batch_idx: 70 |  Loss: (0.0371) |  Loss2: (0.0000) | Acc: (98.00%) (8971/9088)
Epoch: 233 | Batch_idx: 80 |  Loss: (0.0365) |  Loss2: (0.0000) | Acc: (98.00%) (10238/10368)
Epoch: 233 | Batch_idx: 90 |  Loss: (0.0359) |  Loss2: (0.0000) | Acc: (98.00%) (11506/11648)
Epoch: 233 | Batch_idx: 100 |  Loss: (0.0362) |  Loss2: (0.0000) | Acc: (98.00%) (12770/12928)
Epoch: 233 | Batch_idx: 110 |  Loss: (0.0367) |  Loss2: (0.0000) | Acc: (98.00%) (14033/14208)
Epoch: 233 | Batch_idx: 120 |  Loss: (0.0374) |  Loss2: (0.0000) | Acc: (98.00%) (15298/15488)
Epoch: 233 | Batch_idx: 130 |  Loss: (0.0375) |  Loss2: (0.0000) | Acc: (98.00%) (16559/16768)
Epoch: 233 | Batch_idx: 140 |  Loss: (0.0382) |  Loss2: (0.0000) | Acc: (98.00%) (17818/18048)
Epoch: 233 | Batch_idx: 150 |  Loss: (0.0377) |  Loss2: (0.0000) | Acc: (98.00%) (19085/19328)
Epoch: 233 | Batch_idx: 160 |  Loss: (0.0376) |  Loss2: (0.0000) | Acc: (98.00%) (20353/20608)
Epoch: 233 | Batch_idx: 170 |  Loss: (0.0379) |  Loss2: (0.0000) | Acc: (98.00%) (21618/21888)
Epoch: 233 | Batch_idx: 180 |  Loss: (0.0379) |  Loss2: (0.0000) | Acc: (98.00%) (22882/23168)
Epoch: 233 | Batch_idx: 190 |  Loss: (0.0380) |  Loss2: (0.0000) | Acc: (98.00%) (24148/24448)
Epoch: 233 | Batch_idx: 200 |  Loss: (0.0383) |  Loss2: (0.0000) | Acc: (98.00%) (25410/25728)
Epoch: 233 | Batch_idx: 210 |  Loss: (0.0381) |  Loss2: (0.0000) | Acc: (98.00%) (26676/27008)
Epoch: 233 | Batch_idx: 220 |  Loss: (0.0382) |  Loss2: (0.0000) | Acc: (98.00%) (27940/28288)
Epoch: 233 | Batch_idx: 230 |  Loss: (0.0383) |  Loss2: (0.0000) | Acc: (98.00%) (29200/29568)
Epoch: 233 | Batch_idx: 240 |  Loss: (0.0384) |  Loss2: (0.0000) | Acc: (98.00%) (30465/30848)
Epoch: 233 | Batch_idx: 250 |  Loss: (0.0384) |  Loss2: (0.0000) | Acc: (98.00%) (31732/32128)
Epoch: 233 | Batch_idx: 260 |  Loss: (0.0386) |  Loss2: (0.0000) | Acc: (98.00%) (32992/33408)
Epoch: 233 | Batch_idx: 270 |  Loss: (0.0387) |  Loss2: (0.0000) | Acc: (98.00%) (34259/34688)
Epoch: 233 | Batch_idx: 280 |  Loss: (0.0389) |  Loss2: (0.0000) | Acc: (98.00%) (35516/35968)
Epoch: 233 | Batch_idx: 290 |  Loss: (0.0389) |  Loss2: (0.0000) | Acc: (98.00%) (36781/37248)
Epoch: 233 | Batch_idx: 300 |  Loss: (0.0389) |  Loss2: (0.0000) | Acc: (98.00%) (38046/38528)
Epoch: 233 | Batch_idx: 310 |  Loss: (0.0390) |  Loss2: (0.0000) | Acc: (98.00%) (39307/39808)
Epoch: 233 | Batch_idx: 320 |  Loss: (0.0395) |  Loss2: (0.0000) | Acc: (98.00%) (40559/41088)
Epoch: 233 | Batch_idx: 330 |  Loss: (0.0398) |  Loss2: (0.0000) | Acc: (98.00%) (41818/42368)
Epoch: 233 | Batch_idx: 340 |  Loss: (0.0401) |  Loss2: (0.0000) | Acc: (98.00%) (43075/43648)
Epoch: 233 | Batch_idx: 350 |  Loss: (0.0403) |  Loss2: (0.0000) | Acc: (98.00%) (44332/44928)
Epoch: 233 | Batch_idx: 360 |  Loss: (0.0400) |  Loss2: (0.0000) | Acc: (98.00%) (45601/46208)
Epoch: 233 | Batch_idx: 370 |  Loss: (0.0403) |  Loss2: (0.0000) | Acc: (98.00%) (46859/47488)
Epoch: 233 | Batch_idx: 380 |  Loss: (0.0408) |  Loss2: (0.0000) | Acc: (98.00%) (48111/48768)
Epoch: 233 | Batch_idx: 390 |  Loss: (0.0408) |  Loss2: (0.0000) | Acc: (98.00%) (49328/50000)
# TEST : Loss: (0.4975) | Acc: (87.00%) (8796/10000)
percent tensor([0.5816, 0.5940, 0.6229, 0.6146, 0.6265, 0.5912, 0.6050, 0.6224, 0.5937,
        0.6011, 0.5792, 0.6158, 0.5832, 0.5931, 0.5955, 0.5884],
       device='cuda:0') torch.Size([16])
percent tensor([0.5866, 0.5912, 0.5798, 0.5787, 0.5880, 0.5864, 0.5957, 0.5896, 0.5807,
        0.5876, 0.5881, 0.5912, 0.5848, 0.5857, 0.5948, 0.5885],
       device='cuda:0') torch.Size([16])
percent tensor([0.6450, 0.6700, 0.5969, 0.5666, 0.5732, 0.6004, 0.6425, 0.5864, 0.6293,
        0.6689, 0.6544, 0.6273, 0.6862, 0.6482, 0.6347, 0.6516],
       device='cuda:0') torch.Size([16])
percent tensor([0.7102, 0.7043, 0.6623, 0.6704, 0.6792, 0.7272, 0.7131, 0.6744, 0.6906,
        0.7050, 0.7082, 0.6853, 0.7062, 0.7072, 0.7166, 0.7168],
       device='cuda:0') torch.Size([16])
percent tensor([0.6031, 0.5348, 0.6653, 0.6895, 0.6887, 0.6361, 0.6061, 0.6661, 0.6256,
        0.5583, 0.5949, 0.6160, 0.4824, 0.6413, 0.6391, 0.6306],
       device='cuda:0') torch.Size([16])
percent tensor([0.5818, 0.7602, 0.6739, 0.6768, 0.6337, 0.7437, 0.7021, 0.5832, 0.7405,
        0.7067, 0.7970, 0.7071, 0.7783, 0.7640, 0.5346, 0.5003],
       device='cuda:0') torch.Size([16])
percent tensor([0.6633, 0.7232, 0.7039, 0.6503, 0.6111, 0.7062, 0.7100, 0.6388, 0.6814,
        0.7190, 0.7305, 0.6189, 0.7456, 0.7196, 0.5124, 0.5719],
       device='cuda:0') torch.Size([16])
percent tensor([0.9998, 0.9999, 0.9999, 0.9999, 0.9997, 0.9998, 0.9999, 1.0000, 0.9999,
        1.0000, 1.0000, 0.9999, 0.9999, 0.9998, 0.9999, 0.9993],
       device='cuda:0') torch.Size([16])
Epoch: 234 | Batch_idx: 0 |  Loss: (0.0505) |  Loss2: (0.0000) | Acc: (98.00%) (126/128)
Epoch: 234 | Batch_idx: 10 |  Loss: (0.0432) |  Loss2: (0.0000) | Acc: (98.00%) (1389/1408)
Epoch: 234 | Batch_idx: 20 |  Loss: (0.0366) |  Loss2: (0.0000) | Acc: (98.00%) (2658/2688)
Epoch: 234 | Batch_idx: 30 |  Loss: (0.0397) |  Loss2: (0.0000) | Acc: (98.00%) (3919/3968)
Epoch: 234 | Batch_idx: 40 |  Loss: (0.0385) |  Loss2: (0.0000) | Acc: (98.00%) (5191/5248)
Epoch: 234 | Batch_idx: 50 |  Loss: (0.0389) |  Loss2: (0.0000) | Acc: (98.00%) (6451/6528)
Epoch: 234 | Batch_idx: 60 |  Loss: (0.0393) |  Loss2: (0.0000) | Acc: (98.00%) (7713/7808)
Epoch: 234 | Batch_idx: 70 |  Loss: (0.0399) |  Loss2: (0.0000) | Acc: (98.00%) (8979/9088)
Epoch: 234 | Batch_idx: 80 |  Loss: (0.0397) |  Loss2: (0.0000) | Acc: (98.00%) (10240/10368)
Epoch: 234 | Batch_idx: 90 |  Loss: (0.0391) |  Loss2: (0.0000) | Acc: (98.00%) (11508/11648)
Epoch: 234 | Batch_idx: 100 |  Loss: (0.0390) |  Loss2: (0.0000) | Acc: (98.00%) (12773/12928)
Epoch: 234 | Batch_idx: 110 |  Loss: (0.0402) |  Loss2: (0.0000) | Acc: (98.00%) (14033/14208)
Epoch: 234 | Batch_idx: 120 |  Loss: (0.0406) |  Loss2: (0.0000) | Acc: (98.00%) (15292/15488)
Epoch: 234 | Batch_idx: 130 |  Loss: (0.0403) |  Loss2: (0.0000) | Acc: (98.00%) (16558/16768)
Epoch: 234 | Batch_idx: 140 |  Loss: (0.0407) |  Loss2: (0.0000) | Acc: (98.00%) (17818/18048)
Epoch: 234 | Batch_idx: 150 |  Loss: (0.0407) |  Loss2: (0.0000) | Acc: (98.00%) (19083/19328)
Epoch: 234 | Batch_idx: 160 |  Loss: (0.0406) |  Loss2: (0.0000) | Acc: (98.00%) (20345/20608)
Epoch: 234 | Batch_idx: 170 |  Loss: (0.0403) |  Loss2: (0.0000) | Acc: (98.00%) (21615/21888)
Epoch: 234 | Batch_idx: 180 |  Loss: (0.0400) |  Loss2: (0.0000) | Acc: (98.00%) (22878/23168)
Epoch: 234 | Batch_idx: 190 |  Loss: (0.0399) |  Loss2: (0.0000) | Acc: (98.00%) (24140/24448)
Epoch: 234 | Batch_idx: 200 |  Loss: (0.0398) |  Loss2: (0.0000) | Acc: (98.00%) (25404/25728)
Epoch: 234 | Batch_idx: 210 |  Loss: (0.0399) |  Loss2: (0.0000) | Acc: (98.00%) (26668/27008)
Epoch: 234 | Batch_idx: 220 |  Loss: (0.0403) |  Loss2: (0.0000) | Acc: (98.00%) (27926/28288)
Epoch: 234 | Batch_idx: 230 |  Loss: (0.0406) |  Loss2: (0.0000) | Acc: (98.00%) (29182/29568)
Epoch: 234 | Batch_idx: 240 |  Loss: (0.0409) |  Loss2: (0.0000) | Acc: (98.00%) (30442/30848)
Epoch: 234 | Batch_idx: 250 |  Loss: (0.0410) |  Loss2: (0.0000) | Acc: (98.00%) (31705/32128)
Epoch: 234 | Batch_idx: 260 |  Loss: (0.0410) |  Loss2: (0.0000) | Acc: (98.00%) (32967/33408)
Epoch: 234 | Batch_idx: 270 |  Loss: (0.0411) |  Loss2: (0.0000) | Acc: (98.00%) (34230/34688)
Epoch: 234 | Batch_idx: 280 |  Loss: (0.0408) |  Loss2: (0.0000) | Acc: (98.00%) (35496/35968)
Epoch: 234 | Batch_idx: 290 |  Loss: (0.0407) |  Loss2: (0.0000) | Acc: (98.00%) (36763/37248)
Epoch: 234 | Batch_idx: 300 |  Loss: (0.0404) |  Loss2: (0.0000) | Acc: (98.00%) (38031/38528)
Epoch: 234 | Batch_idx: 310 |  Loss: (0.0405) |  Loss2: (0.0000) | Acc: (98.00%) (39295/39808)
Epoch: 234 | Batch_idx: 320 |  Loss: (0.0408) |  Loss2: (0.0000) | Acc: (98.00%) (40553/41088)
Epoch: 234 | Batch_idx: 330 |  Loss: (0.0409) |  Loss2: (0.0000) | Acc: (98.00%) (41812/42368)
Epoch: 234 | Batch_idx: 340 |  Loss: (0.0413) |  Loss2: (0.0000) | Acc: (98.00%) (43063/43648)
Epoch: 234 | Batch_idx: 350 |  Loss: (0.0413) |  Loss2: (0.0000) | Acc: (98.00%) (44325/44928)
Epoch: 234 | Batch_idx: 360 |  Loss: (0.0412) |  Loss2: (0.0000) | Acc: (98.00%) (45593/46208)
Epoch: 234 | Batch_idx: 370 |  Loss: (0.0413) |  Loss2: (0.0000) | Acc: (98.00%) (46858/47488)
Epoch: 234 | Batch_idx: 380 |  Loss: (0.0411) |  Loss2: (0.0000) | Acc: (98.00%) (48122/48768)
Epoch: 234 | Batch_idx: 390 |  Loss: (0.0411) |  Loss2: (0.0000) | Acc: (98.00%) (49342/50000)
# TEST : Loss: (0.4243) | Acc: (89.00%) (8944/10000)
percent tensor([0.5801, 0.5917, 0.6225, 0.6131, 0.6255, 0.5903, 0.6041, 0.6186, 0.5916,
        0.5987, 0.5772, 0.6151, 0.5811, 0.5911, 0.5941, 0.5860],
       device='cuda:0') torch.Size([16])
percent tensor([0.5879, 0.5924, 0.5813, 0.5790, 0.5891, 0.5862, 0.5969, 0.5894, 0.5824,
        0.5886, 0.5894, 0.5925, 0.5865, 0.5860, 0.5947, 0.5893],
       device='cuda:0') torch.Size([16])
percent tensor([0.6502, 0.6674, 0.6112, 0.5784, 0.5837, 0.6021, 0.6413, 0.5938, 0.6296,
        0.6695, 0.6530, 0.6361, 0.6885, 0.6434, 0.6351, 0.6521],
       device='cuda:0') torch.Size([16])
percent tensor([0.7151, 0.7053, 0.6749, 0.6755, 0.6848, 0.7240, 0.7156, 0.6782, 0.6953,
        0.7095, 0.7096, 0.6951, 0.7101, 0.7074, 0.7156, 0.7192],
       device='cuda:0') torch.Size([16])
percent tensor([0.6039, 0.5387, 0.6554, 0.6975, 0.6896, 0.6500, 0.6104, 0.6674, 0.6307,
        0.5595, 0.6038, 0.6218, 0.4766, 0.6717, 0.6426, 0.6387],
       device='cuda:0') torch.Size([16])
percent tensor([0.5783, 0.7436, 0.6833, 0.6671, 0.6358, 0.7441, 0.7038, 0.5732, 0.7197,
        0.6886, 0.7770, 0.6780, 0.7579, 0.7277, 0.5093, 0.4845],
       device='cuda:0') torch.Size([16])
percent tensor([0.6774, 0.7316, 0.7167, 0.6273, 0.6211, 0.7225, 0.7300, 0.6442, 0.6586,
        0.7233, 0.7267, 0.5924, 0.7395, 0.6977, 0.5210, 0.5787],
       device='cuda:0') torch.Size([16])
percent tensor([0.9998, 0.9999, 0.9999, 0.9998, 0.9997, 0.9999, 0.9999, 0.9999, 0.9999,
        1.0000, 1.0000, 0.9999, 0.9999, 0.9998, 0.9999, 0.9995],
       device='cuda:0') torch.Size([16])
Epoch: 235 | Batch_idx: 0 |  Loss: (0.0095) |  Loss2: (0.0000) | Acc: (100.00%) (128/128)
Epoch: 235 | Batch_idx: 10 |  Loss: (0.0295) |  Loss2: (0.0000) | Acc: (99.00%) (1394/1408)
Epoch: 235 | Batch_idx: 20 |  Loss: (0.0356) |  Loss2: (0.0000) | Acc: (98.00%) (2656/2688)
Epoch: 235 | Batch_idx: 30 |  Loss: (0.0363) |  Loss2: (0.0000) | Acc: (98.00%) (3920/3968)
Epoch: 235 | Batch_idx: 40 |  Loss: (0.0365) |  Loss2: (0.0000) | Acc: (98.00%) (5183/5248)
Epoch: 235 | Batch_idx: 50 |  Loss: (0.0349) |  Loss2: (0.0000) | Acc: (98.00%) (6451/6528)
Epoch: 235 | Batch_idx: 60 |  Loss: (0.0358) |  Loss2: (0.0000) | Acc: (98.00%) (7716/7808)
Epoch: 235 | Batch_idx: 70 |  Loss: (0.0360) |  Loss2: (0.0000) | Acc: (98.00%) (8978/9088)
Epoch: 235 | Batch_idx: 80 |  Loss: (0.0359) |  Loss2: (0.0000) | Acc: (98.00%) (10241/10368)
Epoch: 235 | Batch_idx: 90 |  Loss: (0.0364) |  Loss2: (0.0000) | Acc: (98.00%) (11504/11648)
Epoch: 235 | Batch_idx: 100 |  Loss: (0.0372) |  Loss2: (0.0000) | Acc: (98.00%) (12768/12928)
Epoch: 235 | Batch_idx: 110 |  Loss: (0.0368) |  Loss2: (0.0000) | Acc: (98.00%) (14034/14208)
Epoch: 235 | Batch_idx: 120 |  Loss: (0.0369) |  Loss2: (0.0000) | Acc: (98.00%) (15297/15488)
Epoch: 235 | Batch_idx: 130 |  Loss: (0.0371) |  Loss2: (0.0000) | Acc: (98.00%) (16559/16768)
Epoch: 235 | Batch_idx: 140 |  Loss: (0.0370) |  Loss2: (0.0000) | Acc: (98.00%) (17829/18048)
Epoch: 235 | Batch_idx: 150 |  Loss: (0.0368) |  Loss2: (0.0000) | Acc: (98.00%) (19095/19328)
Epoch: 235 | Batch_idx: 160 |  Loss: (0.0367) |  Loss2: (0.0000) | Acc: (98.00%) (20361/20608)
Epoch: 235 | Batch_idx: 170 |  Loss: (0.0373) |  Loss2: (0.0000) | Acc: (98.00%) (21619/21888)
Epoch: 235 | Batch_idx: 180 |  Loss: (0.0373) |  Loss2: (0.0000) | Acc: (98.00%) (22883/23168)
Epoch: 235 | Batch_idx: 190 |  Loss: (0.0370) |  Loss2: (0.0000) | Acc: (98.00%) (24154/24448)
Epoch: 235 | Batch_idx: 200 |  Loss: (0.0367) |  Loss2: (0.0000) | Acc: (98.00%) (25419/25728)
Epoch: 235 | Batch_idx: 210 |  Loss: (0.0367) |  Loss2: (0.0000) | Acc: (98.00%) (26682/27008)
Epoch: 235 | Batch_idx: 220 |  Loss: (0.0370) |  Loss2: (0.0000) | Acc: (98.00%) (27944/28288)
Epoch: 235 | Batch_idx: 230 |  Loss: (0.0370) |  Loss2: (0.0000) | Acc: (98.00%) (29204/29568)
Epoch: 235 | Batch_idx: 240 |  Loss: (0.0376) |  Loss2: (0.0000) | Acc: (98.00%) (30461/30848)
Epoch: 235 | Batch_idx: 250 |  Loss: (0.0382) |  Loss2: (0.0000) | Acc: (98.00%) (31722/32128)
Epoch: 235 | Batch_idx: 260 |  Loss: (0.0379) |  Loss2: (0.0000) | Acc: (98.00%) (32986/33408)
Epoch: 235 | Batch_idx: 270 |  Loss: (0.0380) |  Loss2: (0.0000) | Acc: (98.00%) (34250/34688)
Epoch: 235 | Batch_idx: 280 |  Loss: (0.0378) |  Loss2: (0.0000) | Acc: (98.00%) (35521/35968)
Epoch: 235 | Batch_idx: 290 |  Loss: (0.0376) |  Loss2: (0.0000) | Acc: (98.00%) (36792/37248)
Epoch: 235 | Batch_idx: 300 |  Loss: (0.0377) |  Loss2: (0.0000) | Acc: (98.00%) (38054/38528)
Epoch: 235 | Batch_idx: 310 |  Loss: (0.0381) |  Loss2: (0.0000) | Acc: (98.00%) (39316/39808)
Epoch: 235 | Batch_idx: 320 |  Loss: (0.0381) |  Loss2: (0.0000) | Acc: (98.00%) (40581/41088)
Epoch: 235 | Batch_idx: 330 |  Loss: (0.0383) |  Loss2: (0.0000) | Acc: (98.00%) (41845/42368)
Epoch: 235 | Batch_idx: 340 |  Loss: (0.0383) |  Loss2: (0.0000) | Acc: (98.00%) (43104/43648)
Epoch: 235 | Batch_idx: 350 |  Loss: (0.0384) |  Loss2: (0.0000) | Acc: (98.00%) (44365/44928)
Epoch: 235 | Batch_idx: 360 |  Loss: (0.0386) |  Loss2: (0.0000) | Acc: (98.00%) (45624/46208)
Epoch: 235 | Batch_idx: 370 |  Loss: (0.0387) |  Loss2: (0.0000) | Acc: (98.00%) (46889/47488)
Epoch: 235 | Batch_idx: 380 |  Loss: (0.0384) |  Loss2: (0.0000) | Acc: (98.00%) (48159/48768)
Epoch: 235 | Batch_idx: 390 |  Loss: (0.0385) |  Loss2: (0.0000) | Acc: (98.00%) (49370/50000)
=> saving checkpoint 'drive/app/torch/save_Schedule/checkpoint_235.pth.tar'
# TEST : Loss: (0.4752) | Acc: (88.00%) (8892/10000)
percent tensor([0.5814, 0.5953, 0.6235, 0.6159, 0.6273, 0.5922, 0.6063, 0.6212, 0.5928,
        0.6009, 0.5784, 0.6166, 0.5827, 0.5943, 0.5969, 0.5882],
       device='cuda:0') torch.Size([16])
percent tensor([0.5890, 0.5933, 0.5831, 0.5799, 0.5907, 0.5872, 0.5985, 0.5912, 0.5830,
        0.5897, 0.5898, 0.5943, 0.5875, 0.5872, 0.5960, 0.5903],
       device='cuda:0') torch.Size([16])
percent tensor([0.6535, 0.6725, 0.6152, 0.5809, 0.5858, 0.6068, 0.6468, 0.5975, 0.6300,
        0.6749, 0.6566, 0.6416, 0.6922, 0.6464, 0.6393, 0.6567],
       device='cuda:0') torch.Size([16])
percent tensor([0.7154, 0.7009, 0.6741, 0.6752, 0.6804, 0.7285, 0.7152, 0.6776, 0.6958,
        0.7077, 0.7091, 0.6974, 0.7101, 0.7076, 0.7168, 0.7194],
       device='cuda:0') torch.Size([16])
percent tensor([0.5851, 0.5310, 0.6456, 0.6885, 0.6846, 0.6434, 0.5952, 0.6558, 0.6378,
        0.5594, 0.6015, 0.6129, 0.4742, 0.6722, 0.6389, 0.6251],
       device='cuda:0') torch.Size([16])
percent tensor([0.5720, 0.7499, 0.7005, 0.6654, 0.6351, 0.7375, 0.7005, 0.5521, 0.7290,
        0.6975, 0.7815, 0.7087, 0.7668, 0.7503, 0.4940, 0.4650],
       device='cuda:0') torch.Size([16])
percent tensor([0.6850, 0.7523, 0.7362, 0.6654, 0.6291, 0.7370, 0.7307, 0.6522, 0.6886,
        0.7415, 0.7310, 0.6186, 0.7536, 0.7018, 0.5261, 0.5770],
       device='cuda:0') torch.Size([16])
percent tensor([0.9999, 0.9999, 0.9999, 0.9999, 0.9997, 0.9998, 0.9999, 0.9999, 0.9999,
        0.9999, 1.0000, 0.9998, 0.9998, 0.9998, 0.9999, 0.9994],
       device='cuda:0') torch.Size([16])
Epoch: 236 | Batch_idx: 0 |  Loss: (0.0342) |  Loss2: (0.0000) | Acc: (97.00%) (125/128)
Epoch: 236 | Batch_idx: 10 |  Loss: (0.0363) |  Loss2: (0.0000) | Acc: (98.00%) (1393/1408)
Epoch: 236 | Batch_idx: 20 |  Loss: (0.0355) |  Loss2: (0.0000) | Acc: (98.00%) (2656/2688)
Epoch: 236 | Batch_idx: 30 |  Loss: (0.0343) |  Loss2: (0.0000) | Acc: (98.00%) (3925/3968)
Epoch: 236 | Batch_idx: 40 |  Loss: (0.0345) |  Loss2: (0.0000) | Acc: (98.00%) (5190/5248)
Epoch: 236 | Batch_idx: 50 |  Loss: (0.0342) |  Loss2: (0.0000) | Acc: (98.00%) (6457/6528)
Epoch: 236 | Batch_idx: 60 |  Loss: (0.0340) |  Loss2: (0.0000) | Acc: (98.00%) (7721/7808)
Epoch: 236 | Batch_idx: 70 |  Loss: (0.0347) |  Loss2: (0.0000) | Acc: (98.00%) (8983/9088)
Epoch: 236 | Batch_idx: 80 |  Loss: (0.0348) |  Loss2: (0.0000) | Acc: (98.00%) (10245/10368)
Epoch: 236 | Batch_idx: 90 |  Loss: (0.0364) |  Loss2: (0.0000) | Acc: (98.00%) (11504/11648)
Epoch: 236 | Batch_idx: 100 |  Loss: (0.0367) |  Loss2: (0.0000) | Acc: (98.00%) (12771/12928)
Epoch: 236 | Batch_idx: 110 |  Loss: (0.0374) |  Loss2: (0.0000) | Acc: (98.00%) (14033/14208)
Epoch: 236 | Batch_idx: 120 |  Loss: (0.0375) |  Loss2: (0.0000) | Acc: (98.00%) (15297/15488)
Epoch: 236 | Batch_idx: 130 |  Loss: (0.0381) |  Loss2: (0.0000) | Acc: (98.00%) (16559/16768)
Epoch: 236 | Batch_idx: 140 |  Loss: (0.0381) |  Loss2: (0.0000) | Acc: (98.00%) (17826/18048)
Epoch: 236 | Batch_idx: 150 |  Loss: (0.0381) |  Loss2: (0.0000) | Acc: (98.00%) (19091/19328)
Epoch: 236 | Batch_idx: 160 |  Loss: (0.0380) |  Loss2: (0.0000) | Acc: (98.00%) (20359/20608)
Epoch: 236 | Batch_idx: 170 |  Loss: (0.0376) |  Loss2: (0.0000) | Acc: (98.00%) (21629/21888)
Epoch: 236 | Batch_idx: 180 |  Loss: (0.0371) |  Loss2: (0.0000) | Acc: (98.00%) (22898/23168)
Epoch: 236 | Batch_idx: 190 |  Loss: (0.0367) |  Loss2: (0.0000) | Acc: (98.00%) (24164/24448)
Epoch: 236 | Batch_idx: 200 |  Loss: (0.0370) |  Loss2: (0.0000) | Acc: (98.00%) (25422/25728)
Epoch: 236 | Batch_idx: 210 |  Loss: (0.0376) |  Loss2: (0.0000) | Acc: (98.00%) (26675/27008)
Epoch: 236 | Batch_idx: 220 |  Loss: (0.0374) |  Loss2: (0.0000) | Acc: (98.00%) (27943/28288)
Epoch: 236 | Batch_idx: 230 |  Loss: (0.0374) |  Loss2: (0.0000) | Acc: (98.00%) (29207/29568)
Epoch: 236 | Batch_idx: 240 |  Loss: (0.0370) |  Loss2: (0.0000) | Acc: (98.00%) (30476/30848)
Epoch: 236 | Batch_idx: 250 |  Loss: (0.0371) |  Loss2: (0.0000) | Acc: (98.00%) (31739/32128)
Epoch: 236 | Batch_idx: 260 |  Loss: (0.0371) |  Loss2: (0.0000) | Acc: (98.00%) (33002/33408)
Epoch: 236 | Batch_idx: 270 |  Loss: (0.0369) |  Loss2: (0.0000) | Acc: (98.00%) (34273/34688)
Epoch: 236 | Batch_idx: 280 |  Loss: (0.0368) |  Loss2: (0.0000) | Acc: (98.00%) (35540/35968)
Epoch: 236 | Batch_idx: 290 |  Loss: (0.0370) |  Loss2: (0.0000) | Acc: (98.00%) (36799/37248)
Epoch: 236 | Batch_idx: 300 |  Loss: (0.0370) |  Loss2: (0.0000) | Acc: (98.00%) (38063/38528)
Epoch: 236 | Batch_idx: 310 |  Loss: (0.0375) |  Loss2: (0.0000) | Acc: (98.00%) (39321/39808)
Epoch: 236 | Batch_idx: 320 |  Loss: (0.0373) |  Loss2: (0.0000) | Acc: (98.00%) (40589/41088)
Epoch: 236 | Batch_idx: 330 |  Loss: (0.0372) |  Loss2: (0.0000) | Acc: (98.00%) (41851/42368)
Epoch: 236 | Batch_idx: 340 |  Loss: (0.0373) |  Loss2: (0.0000) | Acc: (98.00%) (43114/43648)
Epoch: 236 | Batch_idx: 350 |  Loss: (0.0372) |  Loss2: (0.0000) | Acc: (98.00%) (44382/44928)
Epoch: 236 | Batch_idx: 360 |  Loss: (0.0369) |  Loss2: (0.0000) | Acc: (98.00%) (45653/46208)
Epoch: 236 | Batch_idx: 370 |  Loss: (0.0368) |  Loss2: (0.0000) | Acc: (98.00%) (46925/47488)
Epoch: 236 | Batch_idx: 380 |  Loss: (0.0366) |  Loss2: (0.0000) | Acc: (98.00%) (48196/48768)
Epoch: 236 | Batch_idx: 390 |  Loss: (0.0365) |  Loss2: (0.0000) | Acc: (98.00%) (49417/50000)
# TEST : Loss: (0.4394) | Acc: (89.00%) (8927/10000)
percent tensor([0.5794, 0.5944, 0.6195, 0.6136, 0.6224, 0.5891, 0.6036, 0.6185, 0.5907,
        0.5991, 0.5768, 0.6119, 0.5807, 0.5946, 0.5947, 0.5864],
       device='cuda:0') torch.Size([16])
percent tensor([0.5892, 0.5916, 0.5850, 0.5802, 0.5924, 0.5880, 0.5979, 0.5911, 0.5832,
        0.5897, 0.5897, 0.5956, 0.5872, 0.5854, 0.5957, 0.5905],
       device='cuda:0') torch.Size([16])
percent tensor([0.6503, 0.6707, 0.6091, 0.5769, 0.5795, 0.6060, 0.6437, 0.5975, 0.6307,
        0.6746, 0.6575, 0.6378, 0.6905, 0.6466, 0.6392, 0.6544],
       device='cuda:0') torch.Size([16])
percent tensor([0.7110, 0.6964, 0.6724, 0.6760, 0.6836, 0.7260, 0.7101, 0.6765, 0.6914,
        0.7047, 0.7050, 0.6935, 0.7041, 0.7000, 0.7127, 0.7144],
       device='cuda:0') torch.Size([16])
percent tensor([0.5872, 0.5343, 0.6537, 0.6863, 0.6931, 0.6369, 0.6054, 0.6652, 0.6310,
        0.5478, 0.5925, 0.6000, 0.4722, 0.6653, 0.6395, 0.6226],
       device='cuda:0') torch.Size([16])
percent tensor([0.5493, 0.7252, 0.6912, 0.6742, 0.6295, 0.7244, 0.6852, 0.5636, 0.7177,
        0.6895, 0.7709, 0.6882, 0.7531, 0.7377, 0.4887, 0.4619],
       device='cuda:0') torch.Size([16])
percent tensor([0.6633, 0.7274, 0.7231, 0.6509, 0.6191, 0.7228, 0.7317, 0.6432, 0.6754,
        0.7307, 0.7245, 0.5973, 0.7501, 0.7074, 0.5158, 0.5788],
       device='cuda:0') torch.Size([16])
percent tensor([0.9997, 0.9999, 0.9999, 0.9998, 0.9997, 0.9998, 0.9999, 0.9999, 1.0000,
        1.0000, 1.0000, 0.9999, 0.9999, 0.9998, 0.9999, 0.9992],
       device='cuda:0') torch.Size([16])
Epoch: 237 | Batch_idx: 0 |  Loss: (0.0417) |  Loss2: (0.0000) | Acc: (98.00%) (126/128)
Epoch: 237 | Batch_idx: 10 |  Loss: (0.0347) |  Loss2: (0.0000) | Acc: (99.00%) (1396/1408)
Epoch: 237 | Batch_idx: 20 |  Loss: (0.0372) |  Loss2: (0.0000) | Acc: (98.00%) (2658/2688)
Epoch: 237 | Batch_idx: 30 |  Loss: (0.0397) |  Loss2: (0.0000) | Acc: (98.00%) (3917/3968)
Epoch: 237 | Batch_idx: 40 |  Loss: (0.0415) |  Loss2: (0.0000) | Acc: (98.00%) (5177/5248)
Epoch: 237 | Batch_idx: 50 |  Loss: (0.0404) |  Loss2: (0.0000) | Acc: (98.00%) (6446/6528)
Epoch: 237 | Batch_idx: 60 |  Loss: (0.0410) |  Loss2: (0.0000) | Acc: (98.00%) (7711/7808)
Epoch: 237 | Batch_idx: 70 |  Loss: (0.0400) |  Loss2: (0.0000) | Acc: (98.00%) (8979/9088)
Epoch: 237 | Batch_idx: 80 |  Loss: (0.0399) |  Loss2: (0.0000) | Acc: (98.00%) (10235/10368)
Epoch: 237 | Batch_idx: 90 |  Loss: (0.0391) |  Loss2: (0.0000) | Acc: (98.00%) (11503/11648)
Epoch: 237 | Batch_idx: 100 |  Loss: (0.0394) |  Loss2: (0.0000) | Acc: (98.00%) (12764/12928)
Epoch: 237 | Batch_idx: 110 |  Loss: (0.0392) |  Loss2: (0.0000) | Acc: (98.00%) (14027/14208)
Epoch: 237 | Batch_idx: 120 |  Loss: (0.0394) |  Loss2: (0.0000) | Acc: (98.00%) (15288/15488)
Epoch: 237 | Batch_idx: 130 |  Loss: (0.0389) |  Loss2: (0.0000) | Acc: (98.00%) (16555/16768)
Epoch: 237 | Batch_idx: 140 |  Loss: (0.0388) |  Loss2: (0.0000) | Acc: (98.00%) (17820/18048)
Epoch: 237 | Batch_idx: 150 |  Loss: (0.0388) |  Loss2: (0.0000) | Acc: (98.00%) (19085/19328)
Epoch: 237 | Batch_idx: 160 |  Loss: (0.0387) |  Loss2: (0.0000) | Acc: (98.00%) (20350/20608)
Epoch: 237 | Batch_idx: 170 |  Loss: (0.0396) |  Loss2: (0.0000) | Acc: (98.00%) (21605/21888)
Epoch: 237 | Batch_idx: 180 |  Loss: (0.0394) |  Loss2: (0.0000) | Acc: (98.00%) (22871/23168)
Epoch: 237 | Batch_idx: 190 |  Loss: (0.0393) |  Loss2: (0.0000) | Acc: (98.00%) (24133/24448)
Epoch: 237 | Batch_idx: 200 |  Loss: (0.0393) |  Loss2: (0.0000) | Acc: (98.00%) (25396/25728)
Epoch: 237 | Batch_idx: 210 |  Loss: (0.0391) |  Loss2: (0.0000) | Acc: (98.00%) (26662/27008)
Epoch: 237 | Batch_idx: 220 |  Loss: (0.0389) |  Loss2: (0.0000) | Acc: (98.00%) (27927/28288)
Epoch: 237 | Batch_idx: 230 |  Loss: (0.0387) |  Loss2: (0.0000) | Acc: (98.00%) (29190/29568)
Epoch: 237 | Batch_idx: 240 |  Loss: (0.0391) |  Loss2: (0.0000) | Acc: (98.00%) (30449/30848)
Epoch: 237 | Batch_idx: 250 |  Loss: (0.0395) |  Loss2: (0.0000) | Acc: (98.00%) (31704/32128)
Epoch: 237 | Batch_idx: 260 |  Loss: (0.0398) |  Loss2: (0.0000) | Acc: (98.00%) (32965/33408)
Epoch: 237 | Batch_idx: 270 |  Loss: (0.0398) |  Loss2: (0.0000) | Acc: (98.00%) (34232/34688)
Epoch: 237 | Batch_idx: 280 |  Loss: (0.0395) |  Loss2: (0.0000) | Acc: (98.00%) (35500/35968)
Epoch: 237 | Batch_idx: 290 |  Loss: (0.0394) |  Loss2: (0.0000) | Acc: (98.00%) (36766/37248)
Epoch: 237 | Batch_idx: 300 |  Loss: (0.0393) |  Loss2: (0.0000) | Acc: (98.00%) (38032/38528)
Epoch: 237 | Batch_idx: 310 |  Loss: (0.0390) |  Loss2: (0.0000) | Acc: (98.00%) (39301/39808)
Epoch: 237 | Batch_idx: 320 |  Loss: (0.0388) |  Loss2: (0.0000) | Acc: (98.00%) (40569/41088)
Epoch: 237 | Batch_idx: 330 |  Loss: (0.0389) |  Loss2: (0.0000) | Acc: (98.00%) (41832/42368)
Epoch: 237 | Batch_idx: 340 |  Loss: (0.0391) |  Loss2: (0.0000) | Acc: (98.00%) (43089/43648)
Epoch: 237 | Batch_idx: 350 |  Loss: (0.0390) |  Loss2: (0.0000) | Acc: (98.00%) (44351/44928)
Epoch: 237 | Batch_idx: 360 |  Loss: (0.0391) |  Loss2: (0.0000) | Acc: (98.00%) (45613/46208)
Epoch: 237 | Batch_idx: 370 |  Loss: (0.0392) |  Loss2: (0.0000) | Acc: (98.00%) (46879/47488)
Epoch: 237 | Batch_idx: 380 |  Loss: (0.0393) |  Loss2: (0.0000) | Acc: (98.00%) (48143/48768)
Epoch: 237 | Batch_idx: 390 |  Loss: (0.0394) |  Loss2: (0.0000) | Acc: (98.00%) (49359/50000)
# TEST : Loss: (0.4863) | Acc: (88.00%) (8871/10000)
percent tensor([0.5808, 0.5938, 0.6203, 0.6132, 0.6252, 0.5914, 0.6050, 0.6187, 0.5929,
        0.5996, 0.5787, 0.6139, 0.5825, 0.5925, 0.5961, 0.5869],
       device='cuda:0') torch.Size([16])
percent tensor([0.5882, 0.5918, 0.5825, 0.5792, 0.5898, 0.5864, 0.5967, 0.5906, 0.5822,
        0.5887, 0.5889, 0.5935, 0.5869, 0.5855, 0.5949, 0.5896],
       device='cuda:0') torch.Size([16])
percent tensor([0.6551, 0.6684, 0.6092, 0.5793, 0.5819, 0.6106, 0.6438, 0.5963, 0.6311,
        0.6745, 0.6585, 0.6386, 0.6930, 0.6480, 0.6405, 0.6572],
       device='cuda:0') torch.Size([16])
percent tensor([0.7079, 0.6960, 0.6641, 0.6646, 0.6742, 0.7172, 0.7072, 0.6708, 0.6871,
        0.7041, 0.7048, 0.6911, 0.7028, 0.6982, 0.7069, 0.7111],
       device='cuda:0') torch.Size([16])
percent tensor([0.5881, 0.5453, 0.6465, 0.6711, 0.6880, 0.6291, 0.6127, 0.6570, 0.6386,
        0.5634, 0.6047, 0.6162, 0.4744, 0.6672, 0.6406, 0.6228],
       device='cuda:0') torch.Size([16])
percent tensor([0.5728, 0.7444, 0.7031, 0.6668, 0.6552, 0.7502, 0.7134, 0.5938, 0.7178,
        0.7201, 0.7840, 0.7156, 0.7471, 0.7389, 0.5341, 0.4916],
       device='cuda:0') torch.Size([16])
percent tensor([0.6815, 0.7523, 0.7313, 0.6509, 0.6405, 0.7418, 0.7338, 0.6496, 0.6854,
        0.7449, 0.7355, 0.5942, 0.7496, 0.7121, 0.5199, 0.5868],
       device='cuda:0') torch.Size([16])
percent tensor([0.9998, 0.9999, 0.9999, 0.9998, 0.9997, 0.9999, 0.9999, 1.0000, 0.9999,
        1.0000, 1.0000, 0.9999, 0.9999, 0.9999, 1.0000, 0.9994],
       device='cuda:0') torch.Size([16])
Epoch: 238 | Batch_idx: 0 |  Loss: (0.0080) |  Loss2: (0.0000) | Acc: (100.00%) (128/128)
Epoch: 238 | Batch_idx: 10 |  Loss: (0.0313) |  Loss2: (0.0000) | Acc: (98.00%) (1392/1408)
Epoch: 238 | Batch_idx: 20 |  Loss: (0.0335) |  Loss2: (0.0000) | Acc: (98.00%) (2657/2688)
Epoch: 238 | Batch_idx: 30 |  Loss: (0.0364) |  Loss2: (0.0000) | Acc: (98.00%) (3921/3968)
Epoch: 238 | Batch_idx: 40 |  Loss: (0.0379) |  Loss2: (0.0000) | Acc: (98.00%) (5178/5248)
Epoch: 238 | Batch_idx: 50 |  Loss: (0.0361) |  Loss2: (0.0000) | Acc: (98.00%) (6449/6528)
Epoch: 238 | Batch_idx: 60 |  Loss: (0.0367) |  Loss2: (0.0000) | Acc: (98.00%) (7715/7808)
Epoch: 238 | Batch_idx: 70 |  Loss: (0.0370) |  Loss2: (0.0000) | Acc: (98.00%) (8976/9088)
Epoch: 238 | Batch_idx: 80 |  Loss: (0.0364) |  Loss2: (0.0000) | Acc: (98.00%) (10244/10368)
Epoch: 238 | Batch_idx: 90 |  Loss: (0.0348) |  Loss2: (0.0000) | Acc: (98.00%) (11514/11648)
Epoch: 238 | Batch_idx: 100 |  Loss: (0.0357) |  Loss2: (0.0000) | Acc: (98.00%) (12777/12928)
Epoch: 238 | Batch_idx: 110 |  Loss: (0.0360) |  Loss2: (0.0000) | Acc: (98.00%) (14041/14208)
Epoch: 238 | Batch_idx: 120 |  Loss: (0.0366) |  Loss2: (0.0000) | Acc: (98.00%) (15303/15488)
Epoch: 238 | Batch_idx: 130 |  Loss: (0.0369) |  Loss2: (0.0000) | Acc: (98.00%) (16563/16768)
Epoch: 238 | Batch_idx: 140 |  Loss: (0.0367) |  Loss2: (0.0000) | Acc: (98.00%) (17829/18048)
Epoch: 238 | Batch_idx: 150 |  Loss: (0.0361) |  Loss2: (0.0000) | Acc: (98.00%) (19097/19328)
Epoch: 238 | Batch_idx: 160 |  Loss: (0.0363) |  Loss2: (0.0000) | Acc: (98.00%) (20361/20608)
Epoch: 238 | Batch_idx: 170 |  Loss: (0.0363) |  Loss2: (0.0000) | Acc: (98.00%) (21628/21888)
Epoch: 238 | Batch_idx: 180 |  Loss: (0.0361) |  Loss2: (0.0000) | Acc: (98.00%) (22895/23168)
Epoch: 238 | Batch_idx: 190 |  Loss: (0.0361) |  Loss2: (0.0000) | Acc: (98.00%) (24161/24448)
Epoch: 238 | Batch_idx: 200 |  Loss: (0.0363) |  Loss2: (0.0000) | Acc: (98.00%) (25424/25728)
Epoch: 238 | Batch_idx: 210 |  Loss: (0.0361) |  Loss2: (0.0000) | Acc: (98.00%) (26692/27008)
Epoch: 238 | Batch_idx: 220 |  Loss: (0.0366) |  Loss2: (0.0000) | Acc: (98.00%) (27954/28288)
Epoch: 238 | Batch_idx: 230 |  Loss: (0.0368) |  Loss2: (0.0000) | Acc: (98.00%) (29220/29568)
Epoch: 238 | Batch_idx: 240 |  Loss: (0.0371) |  Loss2: (0.0000) | Acc: (98.00%) (30476/30848)
Epoch: 238 | Batch_idx: 250 |  Loss: (0.0371) |  Loss2: (0.0000) | Acc: (98.00%) (31743/32128)
Epoch: 238 | Batch_idx: 260 |  Loss: (0.0366) |  Loss2: (0.0000) | Acc: (98.00%) (33017/33408)
Epoch: 238 | Batch_idx: 270 |  Loss: (0.0367) |  Loss2: (0.0000) | Acc: (98.00%) (34284/34688)
Epoch: 238 | Batch_idx: 280 |  Loss: (0.0370) |  Loss2: (0.0000) | Acc: (98.00%) (35543/35968)
Epoch: 238 | Batch_idx: 290 |  Loss: (0.0367) |  Loss2: (0.0000) | Acc: (98.00%) (36810/37248)
Epoch: 238 | Batch_idx: 300 |  Loss: (0.0365) |  Loss2: (0.0000) | Acc: (98.00%) (38078/38528)
Epoch: 238 | Batch_idx: 310 |  Loss: (0.0362) |  Loss2: (0.0000) | Acc: (98.00%) (39349/39808)
Epoch: 238 | Batch_idx: 320 |  Loss: (0.0364) |  Loss2: (0.0000) | Acc: (98.00%) (40607/41088)
Epoch: 238 | Batch_idx: 330 |  Loss: (0.0367) |  Loss2: (0.0000) | Acc: (98.00%) (41868/42368)
Epoch: 238 | Batch_idx: 340 |  Loss: (0.0368) |  Loss2: (0.0000) | Acc: (98.00%) (43132/43648)
Epoch: 238 | Batch_idx: 350 |  Loss: (0.0367) |  Loss2: (0.0000) | Acc: (98.00%) (44402/44928)
Epoch: 238 | Batch_idx: 360 |  Loss: (0.0369) |  Loss2: (0.0000) | Acc: (98.00%) (45663/46208)
Epoch: 238 | Batch_idx: 370 |  Loss: (0.0369) |  Loss2: (0.0000) | Acc: (98.00%) (46926/47488)
Epoch: 238 | Batch_idx: 380 |  Loss: (0.0373) |  Loss2: (0.0000) | Acc: (98.00%) (48187/48768)
Epoch: 238 | Batch_idx: 390 |  Loss: (0.0376) |  Loss2: (0.0000) | Acc: (98.00%) (49401/50000)
# TEST : Loss: (0.4904) | Acc: (88.00%) (8836/10000)
percent tensor([0.5820, 0.5951, 0.6223, 0.6145, 0.6264, 0.5932, 0.6062, 0.6203, 0.5945,
        0.6003, 0.5806, 0.6147, 0.5834, 0.5931, 0.5976, 0.5886],
       device='cuda:0') torch.Size([16])
percent tensor([0.5899, 0.5944, 0.5848, 0.5805, 0.5913, 0.5879, 0.5996, 0.5924, 0.5844,
        0.5910, 0.5910, 0.5974, 0.5890, 0.5879, 0.5969, 0.5907],
       device='cuda:0') torch.Size([16])
percent tensor([0.6544, 0.6764, 0.6144, 0.5897, 0.5932, 0.6077, 0.6516, 0.6045, 0.6314,
        0.6807, 0.6614, 0.6449, 0.6957, 0.6544, 0.6463, 0.6610],
       device='cuda:0') torch.Size([16])
percent tensor([0.7121, 0.7005, 0.6721, 0.6688, 0.6794, 0.7190, 0.7109, 0.6738, 0.6919,
        0.7069, 0.7082, 0.6916, 0.7075, 0.7064, 0.7109, 0.7149],
       device='cuda:0') torch.Size([16])
percent tensor([0.5969, 0.5316, 0.6489, 0.6842, 0.6789, 0.6325, 0.6065, 0.6549, 0.6425,
        0.5482, 0.5941, 0.5971, 0.4715, 0.6616, 0.6317, 0.6265],
       device='cuda:0') torch.Size([16])
percent tensor([0.5432, 0.7490, 0.6597, 0.6437, 0.6176, 0.7233, 0.7128, 0.5694, 0.7037,
        0.6923, 0.7836, 0.6857, 0.7381, 0.7643, 0.4935, 0.4479],
       device='cuda:0') torch.Size([16])
percent tensor([0.6672, 0.7386, 0.6892, 0.6402, 0.6025, 0.7335, 0.7563, 0.6474, 0.6643,
        0.7240, 0.7268, 0.5827, 0.7416, 0.7147, 0.5207, 0.5699],
       device='cuda:0') torch.Size([16])
percent tensor([0.9998, 0.9999, 0.9999, 0.9999, 0.9998, 0.9998, 0.9999, 0.9999, 1.0000,
        1.0000, 1.0000, 0.9999, 0.9999, 0.9998, 0.9999, 0.9992],
       device='cuda:0') torch.Size([16])
Epoch: 239 | Batch_idx: 0 |  Loss: (0.0398) |  Loss2: (0.0000) | Acc: (98.00%) (126/128)
Epoch: 239 | Batch_idx: 10 |  Loss: (0.0409) |  Loss2: (0.0000) | Acc: (98.00%) (1389/1408)
Epoch: 239 | Batch_idx: 20 |  Loss: (0.0409) |  Loss2: (0.0000) | Acc: (98.00%) (2649/2688)
Epoch: 239 | Batch_idx: 30 |  Loss: (0.0420) |  Loss2: (0.0000) | Acc: (98.00%) (3910/3968)
Epoch: 239 | Batch_idx: 40 |  Loss: (0.0403) |  Loss2: (0.0000) | Acc: (98.00%) (5173/5248)
Epoch: 239 | Batch_idx: 50 |  Loss: (0.0391) |  Loss2: (0.0000) | Acc: (98.00%) (6442/6528)
Epoch: 239 | Batch_idx: 60 |  Loss: (0.0387) |  Loss2: (0.0000) | Acc: (98.00%) (7707/7808)
Epoch: 239 | Batch_idx: 70 |  Loss: (0.0380) |  Loss2: (0.0000) | Acc: (98.00%) (8973/9088)
Epoch: 239 | Batch_idx: 80 |  Loss: (0.0381) |  Loss2: (0.0000) | Acc: (98.00%) (10234/10368)
Epoch: 239 | Batch_idx: 90 |  Loss: (0.0380) |  Loss2: (0.0000) | Acc: (98.00%) (11502/11648)
Epoch: 239 | Batch_idx: 100 |  Loss: (0.0382) |  Loss2: (0.0000) | Acc: (98.00%) (12768/12928)
Epoch: 239 | Batch_idx: 110 |  Loss: (0.0383) |  Loss2: (0.0000) | Acc: (98.00%) (14030/14208)
Epoch: 239 | Batch_idx: 120 |  Loss: (0.0376) |  Loss2: (0.0000) | Acc: (98.00%) (15300/15488)
Epoch: 239 | Batch_idx: 130 |  Loss: (0.0373) |  Loss2: (0.0000) | Acc: (98.00%) (16564/16768)
Epoch: 239 | Batch_idx: 140 |  Loss: (0.0375) |  Loss2: (0.0000) | Acc: (98.00%) (17828/18048)
Epoch: 239 | Batch_idx: 150 |  Loss: (0.0381) |  Loss2: (0.0000) | Acc: (98.00%) (19093/19328)
Epoch: 239 | Batch_idx: 160 |  Loss: (0.0381) |  Loss2: (0.0000) | Acc: (98.00%) (20361/20608)
Epoch: 239 | Batch_idx: 170 |  Loss: (0.0373) |  Loss2: (0.0000) | Acc: (98.00%) (21636/21888)
Epoch: 239 | Batch_idx: 180 |  Loss: (0.0373) |  Loss2: (0.0000) | Acc: (98.00%) (22900/23168)
Epoch: 239 | Batch_idx: 190 |  Loss: (0.0378) |  Loss2: (0.0000) | Acc: (98.00%) (24164/24448)
Epoch: 239 | Batch_idx: 200 |  Loss: (0.0381) |  Loss2: (0.0000) | Acc: (98.00%) (25424/25728)
Epoch: 239 | Batch_idx: 210 |  Loss: (0.0380) |  Loss2: (0.0000) | Acc: (98.00%) (26692/27008)
Epoch: 239 | Batch_idx: 220 |  Loss: (0.0376) |  Loss2: (0.0000) | Acc: (98.00%) (27962/28288)
Epoch: 239 | Batch_idx: 230 |  Loss: (0.0375) |  Loss2: (0.0000) | Acc: (98.00%) (29230/29568)
Epoch: 239 | Batch_idx: 240 |  Loss: (0.0374) |  Loss2: (0.0000) | Acc: (98.00%) (30496/30848)
Epoch: 239 | Batch_idx: 250 |  Loss: (0.0373) |  Loss2: (0.0000) | Acc: (98.00%) (31766/32128)
Epoch: 239 | Batch_idx: 260 |  Loss: (0.0373) |  Loss2: (0.0000) | Acc: (98.00%) (33035/33408)
Epoch: 239 | Batch_idx: 270 |  Loss: (0.0374) |  Loss2: (0.0000) | Acc: (98.00%) (34301/34688)
Epoch: 239 | Batch_idx: 280 |  Loss: (0.0371) |  Loss2: (0.0000) | Acc: (98.00%) (35572/35968)
Epoch: 239 | Batch_idx: 290 |  Loss: (0.0367) |  Loss2: (0.0000) | Acc: (98.00%) (36844/37248)
Epoch: 239 | Batch_idx: 300 |  Loss: (0.0367) |  Loss2: (0.0000) | Acc: (98.00%) (38111/38528)
Epoch: 239 | Batch_idx: 310 |  Loss: (0.0366) |  Loss2: (0.0000) | Acc: (98.00%) (39375/39808)
Epoch: 239 | Batch_idx: 320 |  Loss: (0.0363) |  Loss2: (0.0000) | Acc: (98.00%) (40645/41088)
Epoch: 239 | Batch_idx: 330 |  Loss: (0.0365) |  Loss2: (0.0000) | Acc: (98.00%) (41908/42368)
Epoch: 239 | Batch_idx: 340 |  Loss: (0.0367) |  Loss2: (0.0000) | Acc: (98.00%) (43168/43648)
Epoch: 239 | Batch_idx: 350 |  Loss: (0.0367) |  Loss2: (0.0000) | Acc: (98.00%) (44431/44928)
Epoch: 239 | Batch_idx: 360 |  Loss: (0.0366) |  Loss2: (0.0000) | Acc: (98.00%) (45697/46208)
Epoch: 239 | Batch_idx: 370 |  Loss: (0.0370) |  Loss2: (0.0000) | Acc: (98.00%) (46956/47488)
Epoch: 239 | Batch_idx: 380 |  Loss: (0.0371) |  Loss2: (0.0000) | Acc: (98.00%) (48222/48768)
Epoch: 239 | Batch_idx: 390 |  Loss: (0.0369) |  Loss2: (0.0000) | Acc: (98.00%) (49444/50000)
# TEST : Loss: (0.4638) | Acc: (89.00%) (8919/10000)
percent tensor([0.5816, 0.5926, 0.6235, 0.6134, 0.6263, 0.5916, 0.6046, 0.6207, 0.5932,
        0.5998, 0.5790, 0.6155, 0.5828, 0.5899, 0.5957, 0.5873],
       device='cuda:0') torch.Size([16])
percent tensor([0.5894, 0.5946, 0.5838, 0.5807, 0.5915, 0.5884, 0.5992, 0.5929, 0.5844,
        0.5906, 0.5907, 0.5956, 0.5882, 0.5882, 0.5972, 0.5905],
       device='cuda:0') torch.Size([16])
percent tensor([0.6503, 0.6699, 0.6082, 0.5781, 0.5834, 0.6116, 0.6437, 0.5973, 0.6297,
        0.6707, 0.6544, 0.6370, 0.6895, 0.6462, 0.6414, 0.6571],
       device='cuda:0') torch.Size([16])
percent tensor([0.7107, 0.6974, 0.6684, 0.6684, 0.6775, 0.7230, 0.7077, 0.6718, 0.6897,
        0.7012, 0.7035, 0.6879, 0.7047, 0.7024, 0.7108, 0.7132],
       device='cuda:0') torch.Size([16])
percent tensor([0.5869, 0.5144, 0.6536, 0.6909, 0.6885, 0.6290, 0.6051, 0.6635, 0.6387,
        0.5587, 0.6017, 0.6078, 0.4764, 0.6585, 0.6245, 0.6213],
       device='cuda:0') torch.Size([16])
percent tensor([0.5534, 0.7521, 0.6893, 0.6449, 0.6343, 0.7473, 0.7133, 0.5672, 0.7118,
        0.7009, 0.7853, 0.7034, 0.7539, 0.7419, 0.5147, 0.4776],
       device='cuda:0') torch.Size([16])
percent tensor([0.6658, 0.7609, 0.7265, 0.6257, 0.6245, 0.7342, 0.7460, 0.6557, 0.6774,
        0.7366, 0.7329, 0.6164, 0.7617, 0.6958, 0.5269, 0.5781],
       device='cuda:0') torch.Size([16])
percent tensor([0.9997, 0.9999, 0.9999, 0.9999, 0.9998, 0.9998, 1.0000, 0.9999, 1.0000,
        1.0000, 1.0000, 0.9999, 0.9999, 0.9998, 0.9999, 0.9993],
       device='cuda:0') torch.Size([16])
Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 3, 3, 3]) tensor(194.3087, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(838.9305, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(863.1492, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([128, 64, 3, 3]) tensor(1524.8961, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([128, 64, 1, 1]) tensor(475.8475, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([128, 128, 3, 3]) tensor(2332.9912, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([256, 128, 3, 3]) tensor(4251.0244, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([256, 128, 1, 1]) tensor(1322.8395, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([256, 256, 3, 3]) tensor(6379.1118, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([512, 256, 3, 3]) tensor(11422.7432, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([512, 256, 1, 1]) tensor(3732.4929, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([512, 512, 3, 3]) tensor(15742.9717, device='cuda:0', grad_fn=<NormBackward0>)
6 hours 11 mins 25 secs for training