Using downloaded and verified file: drive/app/cifar10/cifar-10-python.tar.gz
USE 1 GPUs!
Epoch: 0 | Batch_idx: 0 |  Loss: (2.3265) |  Loss2: (0.0000) | Acc: (10.00%) (13/128)
Epoch: 0 | Batch_idx: 10 |  Loss: (2.3162) |  Loss2: (0.0000) | Acc: (8.00%) (122/1408)
Epoch: 0 | Batch_idx: 20 |  Loss: (2.3072) |  Loss2: (0.0000) | Acc: (9.00%) (254/2688)
Epoch: 0 | Batch_idx: 30 |  Loss: (2.3000) |  Loss2: (0.0000) | Acc: (10.00%) (436/3968)
Epoch: 0 | Batch_idx: 40 |  Loss: (2.2913) |  Loss2: (0.0000) | Acc: (12.00%) (651/5248)
Epoch: 0 | Batch_idx: 50 |  Loss: (2.2851) |  Loss2: (0.0000) | Acc: (13.00%) (884/6528)
Epoch: 0 | Batch_idx: 60 |  Loss: (2.2768) |  Loss2: (0.0000) | Acc: (14.00%) (1122/7808)
Epoch: 0 | Batch_idx: 70 |  Loss: (2.2685) |  Loss2: (0.0000) | Acc: (15.00%) (1369/9088)
Epoch: 0 | Batch_idx: 80 |  Loss: (2.2606) |  Loss2: (0.0000) | Acc: (15.00%) (1633/10368)
Epoch: 0 | Batch_idx: 90 |  Loss: (2.2540) |  Loss2: (0.0000) | Acc: (16.00%) (1907/11648)
Epoch: 0 | Batch_idx: 100 |  Loss: (2.2471) |  Loss2: (0.0000) | Acc: (16.00%) (2187/12928)
Epoch: 0 | Batch_idx: 110 |  Loss: (2.2391) |  Loss2: (0.0000) | Acc: (17.00%) (2474/14208)
Epoch: 0 | Batch_idx: 120 |  Loss: (2.2310) |  Loss2: (0.0000) | Acc: (17.00%) (2783/15488)
Epoch: 0 | Batch_idx: 130 |  Loss: (2.2235) |  Loss2: (0.0000) | Acc: (18.00%) (3067/16768)
Epoch: 0 | Batch_idx: 140 |  Loss: (2.2153) |  Loss2: (0.0000) | Acc: (18.00%) (3391/18048)
Epoch: 0 | Batch_idx: 150 |  Loss: (2.2074) |  Loss2: (0.0000) | Acc: (19.00%) (3698/19328)
Epoch: 0 | Batch_idx: 160 |  Loss: (2.1997) |  Loss2: (0.0000) | Acc: (19.00%) (4040/20608)
Epoch: 0 | Batch_idx: 170 |  Loss: (2.1926) |  Loss2: (0.0000) | Acc: (19.00%) (4366/21888)
Epoch: 0 | Batch_idx: 180 |  Loss: (2.1843) |  Loss2: (0.0000) | Acc: (20.00%) (4745/23168)
Epoch: 0 | Batch_idx: 190 |  Loss: (2.1778) |  Loss2: (0.0000) | Acc: (20.00%) (5087/24448)
Epoch: 0 | Batch_idx: 200 |  Loss: (2.1706) |  Loss2: (0.0000) | Acc: (21.00%) (5416/25728)
Epoch: 0 | Batch_idx: 210 |  Loss: (2.1633) |  Loss2: (0.0000) | Acc: (21.00%) (5751/27008)
Epoch: 0 | Batch_idx: 220 |  Loss: (2.1563) |  Loss2: (0.0000) | Acc: (21.00%) (6102/28288)
Epoch: 0 | Batch_idx: 230 |  Loss: (2.1487) |  Loss2: (0.0000) | Acc: (21.00%) (6454/29568)
Epoch: 0 | Batch_idx: 240 |  Loss: (2.1420) |  Loss2: (0.0000) | Acc: (22.00%) (6802/30848)
Epoch: 0 | Batch_idx: 250 |  Loss: (2.1348) |  Loss2: (0.0000) | Acc: (22.00%) (7157/32128)
Epoch: 0 | Batch_idx: 260 |  Loss: (2.1282) |  Loss2: (0.0000) | Acc: (22.00%) (7517/33408)
Epoch: 0 | Batch_idx: 270 |  Loss: (2.1220) |  Loss2: (0.0000) | Acc: (22.00%) (7867/34688)
Epoch: 0 | Batch_idx: 280 |  Loss: (2.1151) |  Loss2: (0.0000) | Acc: (22.00%) (8262/35968)
Epoch: 0 | Batch_idx: 290 |  Loss: (2.1090) |  Loss2: (0.0000) | Acc: (23.00%) (8625/37248)
Epoch: 0 | Batch_idx: 300 |  Loss: (2.1025) |  Loss2: (0.0000) | Acc: (23.00%) (9008/38528)
Epoch: 0 | Batch_idx: 310 |  Loss: (2.0969) |  Loss2: (0.0000) | Acc: (23.00%) (9370/39808)
Epoch: 0 | Batch_idx: 320 |  Loss: (2.0912) |  Loss2: (0.0000) | Acc: (23.00%) (9760/41088)
Epoch: 0 | Batch_idx: 330 |  Loss: (2.0855) |  Loss2: (0.0000) | Acc: (24.00%) (10180/42368)
Epoch: 0 | Batch_idx: 340 |  Loss: (2.0794) |  Loss2: (0.0000) | Acc: (24.00%) (10586/43648)
Epoch: 0 | Batch_idx: 350 |  Loss: (2.0735) |  Loss2: (0.0000) | Acc: (24.00%) (10999/44928)
Epoch: 0 | Batch_idx: 360 |  Loss: (2.0682) |  Loss2: (0.0000) | Acc: (24.00%) (11407/46208)
Epoch: 0 | Batch_idx: 370 |  Loss: (2.0629) |  Loss2: (0.0000) | Acc: (24.00%) (11800/47488)
Epoch: 0 | Batch_idx: 380 |  Loss: (2.0574) |  Loss2: (0.0000) | Acc: (25.00%) (12235/48768)
Epoch: 0 | Batch_idx: 390 |  Loss: (2.0520) |  Loss2: (0.0000) | Acc: (25.00%) (12635/50000)
/usr/local/lib/python3.6/dist-packages/torch/serialization.py:241: UserWarning: Couldn't retrieve source code for container of type ResNet. It won't be checked for correctness upon loading.
  "type " + obj.__name__ + ". It won't be checked "
/usr/local/lib/python3.6/dist-packages/torch/serialization.py:241: UserWarning: Couldn't retrieve source code for container of type BasicBlock. It won't be checked for correctness upon loading.
  "type " + obj.__name__ + ". It won't be checked "
/usr/local/lib/python3.6/dist-packages/torch/serialization.py:241: UserWarning: Couldn't retrieve source code for container of type _Gate. It won't be checked for correctness upon loading.
  "type " + obj.__name__ + ". It won't be checked "
=> saving checkpoint 'drive/app/torch/save_Schedule/checkpoint_000.pth.tar'
# TEST : Loss: (1.8824) | Acc: (30.00%) (3019/10000)
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 3, 3, 3]) tensor(165.4020, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(771.3843, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(767.2808, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([128, 64, 3, 3]) tensor(1533.5006, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([128, 64, 1, 1]) tensor(504.2889, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([128, 128, 3, 3]) tensor(2172.6570, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([256, 128, 3, 3]) tensor(4337.0679, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([256, 128, 1, 1]) tensor(1439.0046, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([256, 256, 3, 3]) tensor(6139.4072, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([512, 256, 3, 3]) tensor(12281.9971, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([512, 256, 1, 1]) tensor(4097.0649, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([512, 512, 3, 3]) tensor(17377.4062, device='cuda:0', grad_fn=<NormBackward0>)
Epoch: 1 | Batch_idx: 0 |  Loss: (1.8689) |  Loss2: (0.0000) | Acc: (28.00%) (36/128)
Epoch: 1 | Batch_idx: 10 |  Loss: (1.8221) |  Loss2: (0.0000) | Acc: (33.00%) (473/1408)
Epoch: 1 | Batch_idx: 20 |  Loss: (1.8206) |  Loss2: (0.0000) | Acc: (33.00%) (891/2688)
Epoch: 1 | Batch_idx: 30 |  Loss: (1.8126) |  Loss2: (0.0000) | Acc: (33.00%) (1327/3968)
Epoch: 1 | Batch_idx: 40 |  Loss: (1.8145) |  Loss2: (0.0000) | Acc: (33.00%) (1781/5248)
Epoch: 1 | Batch_idx: 50 |  Loss: (1.8122) |  Loss2: (0.0000) | Acc: (34.00%) (2228/6528)
Epoch: 1 | Batch_idx: 60 |  Loss: (1.8110) |  Loss2: (0.0000) | Acc: (33.00%) (2638/7808)
Epoch: 1 | Batch_idx: 70 |  Loss: (1.8111) |  Loss2: (0.0000) | Acc: (33.00%) (3062/9088)
Epoch: 1 | Batch_idx: 80 |  Loss: (1.8061) |  Loss2: (0.0000) | Acc: (33.00%) (3503/10368)
Epoch: 1 | Batch_idx: 90 |  Loss: (1.8043) |  Loss2: (0.0000) | Acc: (33.00%) (3953/11648)
Epoch: 1 | Batch_idx: 100 |  Loss: (1.7966) |  Loss2: (0.0000) | Acc: (34.00%) (4456/12928)
Epoch: 1 | Batch_idx: 110 |  Loss: (1.7915) |  Loss2: (0.0000) | Acc: (34.00%) (4930/14208)
Epoch: 1 | Batch_idx: 120 |  Loss: (1.7888) |  Loss2: (0.0000) | Acc: (34.00%) (5385/15488)
Epoch: 1 | Batch_idx: 130 |  Loss: (1.7844) |  Loss2: (0.0000) | Acc: (35.00%) (5884/16768)
Epoch: 1 | Batch_idx: 140 |  Loss: (1.7833) |  Loss2: (0.0000) | Acc: (35.00%) (6332/18048)
Epoch: 1 | Batch_idx: 150 |  Loss: (1.7788) |  Loss2: (0.0000) | Acc: (35.00%) (6803/19328)
Epoch: 1 | Batch_idx: 160 |  Loss: (1.7756) |  Loss2: (0.0000) | Acc: (35.00%) (7263/20608)
Epoch: 1 | Batch_idx: 170 |  Loss: (1.7719) |  Loss2: (0.0000) | Acc: (35.00%) (7746/21888)
Epoch: 1 | Batch_idx: 180 |  Loss: (1.7696) |  Loss2: (0.0000) | Acc: (35.00%) (8249/23168)
Epoch: 1 | Batch_idx: 190 |  Loss: (1.7681) |  Loss2: (0.0000) | Acc: (35.00%) (8711/24448)
Epoch: 1 | Batch_idx: 200 |  Loss: (1.7643) |  Loss2: (0.0000) | Acc: (35.00%) (9192/25728)
Epoch: 1 | Batch_idx: 210 |  Loss: (1.7623) |  Loss2: (0.0000) | Acc: (35.00%) (9681/27008)
Epoch: 1 | Batch_idx: 220 |  Loss: (1.7605) |  Loss2: (0.0000) | Acc: (35.00%) (10129/28288)
Epoch: 1 | Batch_idx: 230 |  Loss: (1.7574) |  Loss2: (0.0000) | Acc: (35.00%) (10629/29568)
Epoch: 1 | Batch_idx: 240 |  Loss: (1.7544) |  Loss2: (0.0000) | Acc: (36.00%) (11120/30848)
Epoch: 1 | Batch_idx: 250 |  Loss: (1.7512) |  Loss2: (0.0000) | Acc: (36.00%) (11582/32128)
Epoch: 1 | Batch_idx: 260 |  Loss: (1.7491) |  Loss2: (0.0000) | Acc: (36.00%) (12067/33408)
Epoch: 1 | Batch_idx: 270 |  Loss: (1.7454) |  Loss2: (0.0000) | Acc: (36.00%) (12560/34688)
Epoch: 1 | Batch_idx: 280 |  Loss: (1.7426) |  Loss2: (0.0000) | Acc: (36.00%) (13043/35968)
Epoch: 1 | Batch_idx: 290 |  Loss: (1.7405) |  Loss2: (0.0000) | Acc: (36.00%) (13538/37248)
Epoch: 1 | Batch_idx: 300 |  Loss: (1.7376) |  Loss2: (0.0000) | Acc: (36.00%) (14035/38528)
Epoch: 1 | Batch_idx: 310 |  Loss: (1.7341) |  Loss2: (0.0000) | Acc: (36.00%) (14558/39808)
Epoch: 1 | Batch_idx: 320 |  Loss: (1.7310) |  Loss2: (0.0000) | Acc: (36.00%) (15057/41088)
Epoch: 1 | Batch_idx: 330 |  Loss: (1.7284) |  Loss2: (0.0000) | Acc: (36.00%) (15572/42368)
Epoch: 1 | Batch_idx: 340 |  Loss: (1.7256) |  Loss2: (0.0000) | Acc: (36.00%) (16068/43648)
Epoch: 1 | Batch_idx: 350 |  Loss: (1.7221) |  Loss2: (0.0000) | Acc: (36.00%) (16591/44928)
Epoch: 1 | Batch_idx: 360 |  Loss: (1.7193) |  Loss2: (0.0000) | Acc: (37.00%) (17104/46208)
Epoch: 1 | Batch_idx: 370 |  Loss: (1.7169) |  Loss2: (0.0000) | Acc: (37.00%) (17609/47488)
Epoch: 1 | Batch_idx: 380 |  Loss: (1.7146) |  Loss2: (0.0000) | Acc: (37.00%) (18105/48768)
Epoch: 1 | Batch_idx: 390 |  Loss: (1.7120) |  Loss2: (0.0000) | Acc: (37.00%) (18620/50000)
# TEST : Loss: (1.5763) | Acc: (40.00%) (4080/10000)
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
Epoch: 2 | Batch_idx: 0 |  Loss: (1.5545) |  Loss2: (0.0000) | Acc: (40.00%) (52/128)
Epoch: 2 | Batch_idx: 10 |  Loss: (1.5770) |  Loss2: (0.0000) | Acc: (41.00%) (588/1408)
Epoch: 2 | Batch_idx: 20 |  Loss: (1.5829) |  Loss2: (0.0000) | Acc: (42.00%) (1155/2688)
Epoch: 2 | Batch_idx: 30 |  Loss: (1.5850) |  Loss2: (0.0000) | Acc: (42.00%) (1667/3968)
Epoch: 2 | Batch_idx: 40 |  Loss: (1.5821) |  Loss2: (0.0000) | Acc: (42.00%) (2242/5248)
Epoch: 2 | Batch_idx: 50 |  Loss: (1.5842) |  Loss2: (0.0000) | Acc: (42.00%) (2767/6528)
Epoch: 2 | Batch_idx: 60 |  Loss: (1.5810) |  Loss2: (0.0000) | Acc: (42.00%) (3304/7808)
Epoch: 2 | Batch_idx: 70 |  Loss: (1.5807) |  Loss2: (0.0000) | Acc: (42.00%) (3848/9088)
Epoch: 2 | Batch_idx: 80 |  Loss: (1.5761) |  Loss2: (0.0000) | Acc: (42.00%) (4421/10368)
Epoch: 2 | Batch_idx: 90 |  Loss: (1.5737) |  Loss2: (0.0000) | Acc: (42.00%) (4963/11648)
Epoch: 2 | Batch_idx: 100 |  Loss: (1.5739) |  Loss2: (0.0000) | Acc: (42.00%) (5480/12928)
Epoch: 2 | Batch_idx: 110 |  Loss: (1.5740) |  Loss2: (0.0000) | Acc: (42.00%) (6013/14208)
Epoch: 2 | Batch_idx: 120 |  Loss: (1.5732) |  Loss2: (0.0000) | Acc: (42.00%) (6550/15488)
Epoch: 2 | Batch_idx: 130 |  Loss: (1.5723) |  Loss2: (0.0000) | Acc: (42.00%) (7107/16768)
Epoch: 2 | Batch_idx: 140 |  Loss: (1.5705) |  Loss2: (0.0000) | Acc: (42.00%) (7637/18048)
Epoch: 2 | Batch_idx: 150 |  Loss: (1.5705) |  Loss2: (0.0000) | Acc: (42.00%) (8159/19328)
Epoch: 2 | Batch_idx: 160 |  Loss: (1.5697) |  Loss2: (0.0000) | Acc: (42.00%) (8702/20608)
Epoch: 2 | Batch_idx: 170 |  Loss: (1.5702) |  Loss2: (0.0000) | Acc: (42.00%) (9241/21888)
Epoch: 2 | Batch_idx: 180 |  Loss: (1.5680) |  Loss2: (0.0000) | Acc: (42.00%) (9785/23168)
Epoch: 2 | Batch_idx: 190 |  Loss: (1.5676) |  Loss2: (0.0000) | Acc: (42.00%) (10324/24448)
Epoch: 2 | Batch_idx: 200 |  Loss: (1.5647) |  Loss2: (0.0000) | Acc: (42.00%) (10872/25728)
Epoch: 2 | Batch_idx: 210 |  Loss: (1.5628) |  Loss2: (0.0000) | Acc: (42.00%) (11438/27008)
Epoch: 2 | Batch_idx: 220 |  Loss: (1.5600) |  Loss2: (0.0000) | Acc: (42.00%) (12008/28288)
Epoch: 2 | Batch_idx: 230 |  Loss: (1.5571) |  Loss2: (0.0000) | Acc: (42.00%) (12589/29568)
Epoch: 2 | Batch_idx: 240 |  Loss: (1.5545) |  Loss2: (0.0000) | Acc: (42.00%) (13181/30848)
Epoch: 2 | Batch_idx: 250 |  Loss: (1.5526) |  Loss2: (0.0000) | Acc: (42.00%) (13768/32128)
Epoch: 2 | Batch_idx: 260 |  Loss: (1.5509) |  Loss2: (0.0000) | Acc: (42.00%) (14355/33408)
Epoch: 2 | Batch_idx: 270 |  Loss: (1.5500) |  Loss2: (0.0000) | Acc: (43.00%) (14931/34688)
Epoch: 2 | Batch_idx: 280 |  Loss: (1.5481) |  Loss2: (0.0000) | Acc: (43.00%) (15508/35968)
Epoch: 2 | Batch_idx: 290 |  Loss: (1.5445) |  Loss2: (0.0000) | Acc: (43.00%) (16106/37248)
Epoch: 2 | Batch_idx: 300 |  Loss: (1.5424) |  Loss2: (0.0000) | Acc: (43.00%) (16698/38528)
Epoch: 2 | Batch_idx: 310 |  Loss: (1.5395) |  Loss2: (0.0000) | Acc: (43.00%) (17305/39808)
Epoch: 2 | Batch_idx: 320 |  Loss: (1.5374) |  Loss2: (0.0000) | Acc: (43.00%) (17891/41088)
Epoch: 2 | Batch_idx: 330 |  Loss: (1.5346) |  Loss2: (0.0000) | Acc: (43.00%) (18526/42368)
Epoch: 2 | Batch_idx: 340 |  Loss: (1.5333) |  Loss2: (0.0000) | Acc: (43.00%) (19071/43648)
Epoch: 2 | Batch_idx: 350 |  Loss: (1.5317) |  Loss2: (0.0000) | Acc: (43.00%) (19642/44928)
Epoch: 2 | Batch_idx: 360 |  Loss: (1.5306) |  Loss2: (0.0000) | Acc: (43.00%) (20199/46208)
Epoch: 2 | Batch_idx: 370 |  Loss: (1.5289) |  Loss2: (0.0000) | Acc: (43.00%) (20803/47488)
Epoch: 2 | Batch_idx: 380 |  Loss: (1.5258) |  Loss2: (0.0000) | Acc: (43.00%) (21440/48768)
Epoch: 2 | Batch_idx: 390 |  Loss: (1.5236) |  Loss2: (0.0000) | Acc: (44.00%) (22025/50000)
# TEST : Loss: (1.5723) | Acc: (41.00%) (4194/10000)
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
Epoch: 3 | Batch_idx: 0 |  Loss: (1.4658) |  Loss2: (0.0000) | Acc: (46.00%) (60/128)
Epoch: 3 | Batch_idx: 10 |  Loss: (1.4309) |  Loss2: (0.0000) | Acc: (46.00%) (656/1408)
Epoch: 3 | Batch_idx: 20 |  Loss: (1.4383) |  Loss2: (0.0000) | Acc: (46.00%) (1251/2688)
Epoch: 3 | Batch_idx: 30 |  Loss: (1.4302) |  Loss2: (0.0000) | Acc: (46.00%) (1858/3968)
Epoch: 3 | Batch_idx: 40 |  Loss: (1.4225) |  Loss2: (0.0000) | Acc: (47.00%) (2482/5248)
Epoch: 3 | Batch_idx: 50 |  Loss: (1.4149) |  Loss2: (0.0000) | Acc: (48.00%) (3139/6528)
Epoch: 3 | Batch_idx: 60 |  Loss: (1.4158) |  Loss2: (0.0000) | Acc: (48.00%) (3774/7808)
Epoch: 3 | Batch_idx: 70 |  Loss: (1.4117) |  Loss2: (0.0000) | Acc: (48.00%) (4403/9088)
Epoch: 3 | Batch_idx: 80 |  Loss: (1.4127) |  Loss2: (0.0000) | Acc: (48.00%) (5008/10368)
Epoch: 3 | Batch_idx: 90 |  Loss: (1.4117) |  Loss2: (0.0000) | Acc: (48.00%) (5618/11648)
Epoch: 3 | Batch_idx: 100 |  Loss: (1.4150) |  Loss2: (0.0000) | Acc: (48.00%) (6211/12928)
Epoch: 3 | Batch_idx: 110 |  Loss: (1.4094) |  Loss2: (0.0000) | Acc: (48.00%) (6865/14208)
Epoch: 3 | Batch_idx: 120 |  Loss: (1.4099) |  Loss2: (0.0000) | Acc: (48.00%) (7503/15488)
Epoch: 3 | Batch_idx: 130 |  Loss: (1.4126) |  Loss2: (0.0000) | Acc: (48.00%) (8125/16768)
Epoch: 3 | Batch_idx: 140 |  Loss: (1.4122) |  Loss2: (0.0000) | Acc: (48.00%) (8735/18048)
Epoch: 3 | Batch_idx: 150 |  Loss: (1.4084) |  Loss2: (0.0000) | Acc: (48.00%) (9372/19328)
Epoch: 3 | Batch_idx: 160 |  Loss: (1.4055) |  Loss2: (0.0000) | Acc: (48.00%) (10010/20608)
Epoch: 3 | Batch_idx: 170 |  Loss: (1.4024) |  Loss2: (0.0000) | Acc: (48.00%) (10683/21888)
Epoch: 3 | Batch_idx: 180 |  Loss: (1.4031) |  Loss2: (0.0000) | Acc: (48.00%) (11309/23168)
Epoch: 3 | Batch_idx: 190 |  Loss: (1.4025) |  Loss2: (0.0000) | Acc: (48.00%) (11962/24448)
Epoch: 3 | Batch_idx: 200 |  Loss: (1.4002) |  Loss2: (0.0000) | Acc: (49.00%) (12607/25728)
Epoch: 3 | Batch_idx: 210 |  Loss: (1.3975) |  Loss2: (0.0000) | Acc: (49.00%) (13271/27008)
Epoch: 3 | Batch_idx: 220 |  Loss: (1.3951) |  Loss2: (0.0000) | Acc: (49.00%) (13911/28288)
Epoch: 3 | Batch_idx: 230 |  Loss: (1.3926) |  Loss2: (0.0000) | Acc: (49.00%) (14568/29568)
Epoch: 3 | Batch_idx: 240 |  Loss: (1.3910) |  Loss2: (0.0000) | Acc: (49.00%) (15211/30848)
Epoch: 3 | Batch_idx: 250 |  Loss: (1.3890) |  Loss2: (0.0000) | Acc: (49.00%) (15863/32128)
Epoch: 3 | Batch_idx: 260 |  Loss: (1.3878) |  Loss2: (0.0000) | Acc: (49.00%) (16534/33408)
Epoch: 3 | Batch_idx: 270 |  Loss: (1.3863) |  Loss2: (0.0000) | Acc: (49.00%) (17202/34688)
Epoch: 3 | Batch_idx: 280 |  Loss: (1.3860) |  Loss2: (0.0000) | Acc: (49.00%) (17846/35968)
Epoch: 3 | Batch_idx: 290 |  Loss: (1.3842) |  Loss2: (0.0000) | Acc: (49.00%) (18512/37248)
Epoch: 3 | Batch_idx: 300 |  Loss: (1.3839) |  Loss2: (0.0000) | Acc: (49.00%) (19185/38528)
Epoch: 3 | Batch_idx: 310 |  Loss: (1.3821) |  Loss2: (0.0000) | Acc: (49.00%) (19858/39808)
Epoch: 3 | Batch_idx: 320 |  Loss: (1.3803) |  Loss2: (0.0000) | Acc: (49.00%) (20538/41088)
Epoch: 3 | Batch_idx: 330 |  Loss: (1.3776) |  Loss2: (0.0000) | Acc: (50.00%) (21225/42368)
Epoch: 3 | Batch_idx: 340 |  Loss: (1.3763) |  Loss2: (0.0000) | Acc: (50.00%) (21881/43648)
Epoch: 3 | Batch_idx: 350 |  Loss: (1.3744) |  Loss2: (0.0000) | Acc: (50.00%) (22544/44928)
Epoch: 3 | Batch_idx: 360 |  Loss: (1.3743) |  Loss2: (0.0000) | Acc: (50.00%) (23183/46208)
Epoch: 3 | Batch_idx: 370 |  Loss: (1.3716) |  Loss2: (0.0000) | Acc: (50.00%) (23884/47488)
Epoch: 3 | Batch_idx: 380 |  Loss: (1.3702) |  Loss2: (0.0000) | Acc: (50.00%) (24573/48768)
Epoch: 3 | Batch_idx: 390 |  Loss: (1.3688) |  Loss2: (0.0000) | Acc: (50.00%) (25230/50000)
# TEST : Loss: (1.2958) | Acc: (53.00%) (5326/10000)
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
Epoch: 4 | Batch_idx: 0 |  Loss: (1.3361) |  Loss2: (0.0000) | Acc: (53.00%) (68/128)
Epoch: 4 | Batch_idx: 10 |  Loss: (1.2563) |  Loss2: (0.0000) | Acc: (57.00%) (805/1408)
Epoch: 4 | Batch_idx: 20 |  Loss: (1.2717) |  Loss2: (0.0000) | Acc: (55.00%) (1493/2688)
Epoch: 4 | Batch_idx: 30 |  Loss: (1.2747) |  Loss2: (0.0000) | Acc: (55.00%) (2195/3968)
Epoch: 4 | Batch_idx: 40 |  Loss: (1.2783) |  Loss2: (0.0000) | Acc: (54.00%) (2883/5248)
Epoch: 4 | Batch_idx: 50 |  Loss: (1.2802) |  Loss2: (0.0000) | Acc: (54.00%) (3586/6528)
Epoch: 4 | Batch_idx: 60 |  Loss: (1.2771) |  Loss2: (0.0000) | Acc: (54.00%) (4283/7808)
Epoch: 4 | Batch_idx: 70 |  Loss: (1.2745) |  Loss2: (0.0000) | Acc: (54.00%) (4994/9088)
Epoch: 4 | Batch_idx: 80 |  Loss: (1.2778) |  Loss2: (0.0000) | Acc: (54.00%) (5697/10368)
Epoch: 4 | Batch_idx: 90 |  Loss: (1.2750) |  Loss2: (0.0000) | Acc: (55.00%) (6433/11648)
Epoch: 4 | Batch_idx: 100 |  Loss: (1.2737) |  Loss2: (0.0000) | Acc: (55.00%) (7142/12928)
Epoch: 4 | Batch_idx: 110 |  Loss: (1.2716) |  Loss2: (0.0000) | Acc: (55.00%) (7844/14208)
Epoch: 4 | Batch_idx: 120 |  Loss: (1.2703) |  Loss2: (0.0000) | Acc: (55.00%) (8556/15488)
Epoch: 4 | Batch_idx: 130 |  Loss: (1.2695) |  Loss2: (0.0000) | Acc: (55.00%) (9269/16768)
Epoch: 4 | Batch_idx: 140 |  Loss: (1.2713) |  Loss2: (0.0000) | Acc: (55.00%) (9965/18048)
Epoch: 4 | Batch_idx: 150 |  Loss: (1.2689) |  Loss2: (0.0000) | Acc: (55.00%) (10699/19328)
Epoch: 4 | Batch_idx: 160 |  Loss: (1.2659) |  Loss2: (0.0000) | Acc: (55.00%) (11405/20608)
Epoch: 4 | Batch_idx: 170 |  Loss: (1.2610) |  Loss2: (0.0000) | Acc: (55.00%) (12133/21888)
Epoch: 4 | Batch_idx: 180 |  Loss: (1.2596) |  Loss2: (0.0000) | Acc: (55.00%) (12855/23168)
Epoch: 4 | Batch_idx: 190 |  Loss: (1.2608) |  Loss2: (0.0000) | Acc: (55.00%) (13560/24448)
Epoch: 4 | Batch_idx: 200 |  Loss: (1.2601) |  Loss2: (0.0000) | Acc: (55.00%) (14279/25728)
Epoch: 4 | Batch_idx: 210 |  Loss: (1.2575) |  Loss2: (0.0000) | Acc: (55.00%) (15011/27008)
Epoch: 4 | Batch_idx: 220 |  Loss: (1.2584) |  Loss2: (0.0000) | Acc: (55.00%) (15714/28288)
Epoch: 4 | Batch_idx: 230 |  Loss: (1.2550) |  Loss2: (0.0000) | Acc: (55.00%) (16446/29568)
Epoch: 4 | Batch_idx: 240 |  Loss: (1.2520) |  Loss2: (0.0000) | Acc: (55.00%) (17177/30848)
Epoch: 4 | Batch_idx: 250 |  Loss: (1.2511) |  Loss2: (0.0000) | Acc: (55.00%) (17876/32128)
Epoch: 4 | Batch_idx: 260 |  Loss: (1.2512) |  Loss2: (0.0000) | Acc: (55.00%) (18580/33408)
Epoch: 4 | Batch_idx: 270 |  Loss: (1.2504) |  Loss2: (0.0000) | Acc: (55.00%) (19290/34688)
Epoch: 4 | Batch_idx: 280 |  Loss: (1.2506) |  Loss2: (0.0000) | Acc: (55.00%) (19989/35968)
Epoch: 4 | Batch_idx: 290 |  Loss: (1.2498) |  Loss2: (0.0000) | Acc: (55.00%) (20701/37248)
Epoch: 4 | Batch_idx: 300 |  Loss: (1.2479) |  Loss2: (0.0000) | Acc: (55.00%) (21447/38528)
Epoch: 4 | Batch_idx: 310 |  Loss: (1.2469) |  Loss2: (0.0000) | Acc: (55.00%) (22155/39808)
Epoch: 4 | Batch_idx: 320 |  Loss: (1.2458) |  Loss2: (0.0000) | Acc: (55.00%) (22864/41088)
Epoch: 4 | Batch_idx: 330 |  Loss: (1.2452) |  Loss2: (0.0000) | Acc: (55.00%) (23586/42368)
Epoch: 4 | Batch_idx: 340 |  Loss: (1.2433) |  Loss2: (0.0000) | Acc: (55.00%) (24340/43648)
Epoch: 4 | Batch_idx: 350 |  Loss: (1.2439) |  Loss2: (0.0000) | Acc: (55.00%) (25056/44928)
Epoch: 4 | Batch_idx: 360 |  Loss: (1.2417) |  Loss2: (0.0000) | Acc: (55.00%) (25800/46208)
Epoch: 4 | Batch_idx: 370 |  Loss: (1.2418) |  Loss2: (0.0000) | Acc: (55.00%) (26523/47488)
Epoch: 4 | Batch_idx: 380 |  Loss: (1.2401) |  Loss2: (0.0000) | Acc: (55.00%) (27234/48768)
Epoch: 4 | Batch_idx: 390 |  Loss: (1.2399) |  Loss2: (0.0000) | Acc: (55.00%) (27936/50000)
# TEST : Loss: (1.1606) | Acc: (57.00%) (5772/10000)
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
Epoch: 5 | Batch_idx: 0 |  Loss: (1.2390) |  Loss2: (0.0000) | Acc: (55.00%) (71/128)
Epoch: 5 | Batch_idx: 10 |  Loss: (1.1898) |  Loss2: (0.0000) | Acc: (57.00%) (804/1408)
Epoch: 5 | Batch_idx: 20 |  Loss: (1.2029) |  Loss2: (0.0000) | Acc: (57.00%) (1557/2688)
Epoch: 5 | Batch_idx: 30 |  Loss: (1.2073) |  Loss2: (0.0000) | Acc: (57.00%) (2289/3968)
Epoch: 5 | Batch_idx: 40 |  Loss: (1.1950) |  Loss2: (0.0000) | Acc: (58.00%) (3061/5248)
Epoch: 5 | Batch_idx: 50 |  Loss: (1.1916) |  Loss2: (0.0000) | Acc: (58.00%) (3815/6528)
Epoch: 5 | Batch_idx: 60 |  Loss: (1.1805) |  Loss2: (0.0000) | Acc: (59.00%) (4610/7808)
Epoch: 5 | Batch_idx: 70 |  Loss: (1.1740) |  Loss2: (0.0000) | Acc: (59.00%) (5369/9088)
Epoch: 5 | Batch_idx: 80 |  Loss: (1.1739) |  Loss2: (0.0000) | Acc: (58.00%) (6107/10368)
Epoch: 5 | Batch_idx: 90 |  Loss: (1.1709) |  Loss2: (0.0000) | Acc: (59.00%) (6874/11648)
Epoch: 5 | Batch_idx: 100 |  Loss: (1.1652) |  Loss2: (0.0000) | Acc: (59.00%) (7658/12928)
Epoch: 5 | Batch_idx: 110 |  Loss: (1.1626) |  Loss2: (0.0000) | Acc: (59.00%) (8427/14208)
Epoch: 5 | Batch_idx: 120 |  Loss: (1.1622) |  Loss2: (0.0000) | Acc: (59.00%) (9188/15488)
Epoch: 5 | Batch_idx: 130 |  Loss: (1.1628) |  Loss2: (0.0000) | Acc: (59.00%) (9940/16768)
Epoch: 5 | Batch_idx: 140 |  Loss: (1.1593) |  Loss2: (0.0000) | Acc: (59.00%) (10729/18048)
Epoch: 5 | Batch_idx: 150 |  Loss: (1.1601) |  Loss2: (0.0000) | Acc: (59.00%) (11481/19328)
Epoch: 5 | Batch_idx: 160 |  Loss: (1.1605) |  Loss2: (0.0000) | Acc: (59.00%) (12212/20608)
Epoch: 5 | Batch_idx: 170 |  Loss: (1.1579) |  Loss2: (0.0000) | Acc: (59.00%) (13007/21888)
Epoch: 5 | Batch_idx: 180 |  Loss: (1.1579) |  Loss2: (0.0000) | Acc: (59.00%) (13756/23168)
Epoch: 5 | Batch_idx: 190 |  Loss: (1.1568) |  Loss2: (0.0000) | Acc: (59.00%) (14507/24448)
Epoch: 5 | Batch_idx: 200 |  Loss: (1.1559) |  Loss2: (0.0000) | Acc: (59.00%) (15276/25728)
Epoch: 5 | Batch_idx: 210 |  Loss: (1.1534) |  Loss2: (0.0000) | Acc: (59.00%) (16058/27008)
Epoch: 5 | Batch_idx: 220 |  Loss: (1.1526) |  Loss2: (0.0000) | Acc: (59.00%) (16819/28288)
Epoch: 5 | Batch_idx: 230 |  Loss: (1.1521) |  Loss2: (0.0000) | Acc: (59.00%) (17565/29568)
Epoch: 5 | Batch_idx: 240 |  Loss: (1.1504) |  Loss2: (0.0000) | Acc: (59.00%) (18349/30848)
Epoch: 5 | Batch_idx: 250 |  Loss: (1.1495) |  Loss2: (0.0000) | Acc: (59.00%) (19126/32128)
Epoch: 5 | Batch_idx: 260 |  Loss: (1.1482) |  Loss2: (0.0000) | Acc: (59.00%) (19895/33408)
Epoch: 5 | Batch_idx: 270 |  Loss: (1.1465) |  Loss2: (0.0000) | Acc: (59.00%) (20686/34688)
Epoch: 5 | Batch_idx: 280 |  Loss: (1.1459) |  Loss2: (0.0000) | Acc: (59.00%) (21449/35968)
Epoch: 5 | Batch_idx: 290 |  Loss: (1.1474) |  Loss2: (0.0000) | Acc: (59.00%) (22179/37248)
Epoch: 5 | Batch_idx: 300 |  Loss: (1.1474) |  Loss2: (0.0000) | Acc: (59.00%) (22936/38528)
Epoch: 5 | Batch_idx: 310 |  Loss: (1.1455) |  Loss2: (0.0000) | Acc: (59.00%) (23707/39808)
Epoch: 5 | Batch_idx: 320 |  Loss: (1.1424) |  Loss2: (0.0000) | Acc: (59.00%) (24526/41088)
Epoch: 5 | Batch_idx: 330 |  Loss: (1.1413) |  Loss2: (0.0000) | Acc: (59.00%) (25273/42368)
Epoch: 5 | Batch_idx: 340 |  Loss: (1.1404) |  Loss2: (0.0000) | Acc: (59.00%) (26066/43648)
Epoch: 5 | Batch_idx: 350 |  Loss: (1.1385) |  Loss2: (0.0000) | Acc: (59.00%) (26863/44928)
Epoch: 5 | Batch_idx: 360 |  Loss: (1.1356) |  Loss2: (0.0000) | Acc: (59.00%) (27668/46208)
Epoch: 5 | Batch_idx: 370 |  Loss: (1.1338) |  Loss2: (0.0000) | Acc: (59.00%) (28456/47488)
Epoch: 5 | Batch_idx: 380 |  Loss: (1.1333) |  Loss2: (0.0000) | Acc: (59.00%) (29244/48768)
Epoch: 5 | Batch_idx: 390 |  Loss: (1.1326) |  Loss2: (0.0000) | Acc: (60.00%) (30003/50000)
=> saving checkpoint 'drive/app/torch/save_Schedule/checkpoint_005.pth.tar'
# TEST : Loss: (1.1167) | Acc: (59.00%) (5942/10000)
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
Epoch: 6 | Batch_idx: 0 |  Loss: (1.1835) |  Loss2: (0.0000) | Acc: (56.00%) (72/128)
Epoch: 6 | Batch_idx: 10 |  Loss: (1.1028) |  Loss2: (0.0000) | Acc: (60.00%) (853/1408)
Epoch: 6 | Batch_idx: 20 |  Loss: (1.0801) |  Loss2: (0.0000) | Acc: (61.00%) (1643/2688)
Epoch: 6 | Batch_idx: 30 |  Loss: (1.0713) |  Loss2: (0.0000) | Acc: (61.00%) (2456/3968)
Epoch: 6 | Batch_idx: 40 |  Loss: (1.0646) |  Loss2: (0.0000) | Acc: (61.00%) (3251/5248)
Epoch: 6 | Batch_idx: 50 |  Loss: (1.0719) |  Loss2: (0.0000) | Acc: (62.00%) (4058/6528)
Epoch: 6 | Batch_idx: 60 |  Loss: (1.0752) |  Loss2: (0.0000) | Acc: (62.00%) (4843/7808)
Epoch: 6 | Batch_idx: 70 |  Loss: (1.0727) |  Loss2: (0.0000) | Acc: (62.00%) (5661/9088)
Epoch: 6 | Batch_idx: 80 |  Loss: (1.0761) |  Loss2: (0.0000) | Acc: (62.00%) (6441/10368)
Epoch: 6 | Batch_idx: 90 |  Loss: (1.0787) |  Loss2: (0.0000) | Acc: (61.00%) (7197/11648)
Epoch: 6 | Batch_idx: 100 |  Loss: (1.0763) |  Loss2: (0.0000) | Acc: (61.00%) (7987/12928)
Epoch: 6 | Batch_idx: 110 |  Loss: (1.0739) |  Loss2: (0.0000) | Acc: (61.00%) (8786/14208)
Epoch: 6 | Batch_idx: 120 |  Loss: (1.0707) |  Loss2: (0.0000) | Acc: (62.00%) (9615/15488)
Epoch: 6 | Batch_idx: 130 |  Loss: (1.0716) |  Loss2: (0.0000) | Acc: (62.00%) (10399/16768)
Epoch: 6 | Batch_idx: 140 |  Loss: (1.0697) |  Loss2: (0.0000) | Acc: (62.00%) (11222/18048)
Epoch: 6 | Batch_idx: 150 |  Loss: (1.0680) |  Loss2: (0.0000) | Acc: (62.00%) (12025/19328)
Epoch: 6 | Batch_idx: 160 |  Loss: (1.0666) |  Loss2: (0.0000) | Acc: (62.00%) (12842/20608)
Epoch: 6 | Batch_idx: 170 |  Loss: (1.0621) |  Loss2: (0.0000) | Acc: (62.00%) (13680/21888)
Epoch: 6 | Batch_idx: 180 |  Loss: (1.0593) |  Loss2: (0.0000) | Acc: (62.00%) (14503/23168)
Epoch: 6 | Batch_idx: 190 |  Loss: (1.0593) |  Loss2: (0.0000) | Acc: (62.00%) (15307/24448)
Epoch: 6 | Batch_idx: 200 |  Loss: (1.0568) |  Loss2: (0.0000) | Acc: (62.00%) (16108/25728)
Epoch: 6 | Batch_idx: 210 |  Loss: (1.0581) |  Loss2: (0.0000) | Acc: (62.00%) (16900/27008)
Epoch: 6 | Batch_idx: 220 |  Loss: (1.0606) |  Loss2: (0.0000) | Acc: (62.00%) (17674/28288)
Epoch: 6 | Batch_idx: 230 |  Loss: (1.0604) |  Loss2: (0.0000) | Acc: (62.00%) (18476/29568)
Epoch: 6 | Batch_idx: 240 |  Loss: (1.0591) |  Loss2: (0.0000) | Acc: (62.00%) (19301/30848)
Epoch: 6 | Batch_idx: 250 |  Loss: (1.0568) |  Loss2: (0.0000) | Acc: (62.00%) (20122/32128)
Epoch: 6 | Batch_idx: 260 |  Loss: (1.0557) |  Loss2: (0.0000) | Acc: (62.00%) (20920/33408)
Epoch: 6 | Batch_idx: 270 |  Loss: (1.0566) |  Loss2: (0.0000) | Acc: (62.00%) (21707/34688)
Epoch: 6 | Batch_idx: 280 |  Loss: (1.0559) |  Loss2: (0.0000) | Acc: (62.00%) (22521/35968)
Epoch: 6 | Batch_idx: 290 |  Loss: (1.0544) |  Loss2: (0.0000) | Acc: (62.00%) (23329/37248)
Epoch: 6 | Batch_idx: 300 |  Loss: (1.0528) |  Loss2: (0.0000) | Acc: (62.00%) (24146/38528)
Epoch: 6 | Batch_idx: 310 |  Loss: (1.0514) |  Loss2: (0.0000) | Acc: (62.00%) (24974/39808)
Epoch: 6 | Batch_idx: 320 |  Loss: (1.0515) |  Loss2: (0.0000) | Acc: (62.00%) (25796/41088)
Epoch: 6 | Batch_idx: 330 |  Loss: (1.0498) |  Loss2: (0.0000) | Acc: (62.00%) (26645/42368)
Epoch: 6 | Batch_idx: 340 |  Loss: (1.0494) |  Loss2: (0.0000) | Acc: (62.00%) (27464/43648)
Epoch: 6 | Batch_idx: 350 |  Loss: (1.0490) |  Loss2: (0.0000) | Acc: (62.00%) (28282/44928)
Epoch: 6 | Batch_idx: 360 |  Loss: (1.0471) |  Loss2: (0.0000) | Acc: (63.00%) (29137/46208)
Epoch: 6 | Batch_idx: 370 |  Loss: (1.0466) |  Loss2: (0.0000) | Acc: (63.00%) (29947/47488)
Epoch: 6 | Batch_idx: 380 |  Loss: (1.0459) |  Loss2: (0.0000) | Acc: (63.00%) (30776/48768)
Epoch: 6 | Batch_idx: 390 |  Loss: (1.0453) |  Loss2: (0.0000) | Acc: (63.00%) (31547/50000)
# TEST : Loss: (1.1475) | Acc: (58.00%) (5861/10000)
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
Epoch: 7 | Batch_idx: 0 |  Loss: (1.0257) |  Loss2: (0.0000) | Acc: (64.00%) (82/128)
Epoch: 7 | Batch_idx: 10 |  Loss: (1.0045) |  Loss2: (0.0000) | Acc: (63.00%) (893/1408)
Epoch: 7 | Batch_idx: 20 |  Loss: (1.0084) |  Loss2: (0.0000) | Acc: (63.00%) (1705/2688)
Epoch: 7 | Batch_idx: 30 |  Loss: (1.0084) |  Loss2: (0.0000) | Acc: (63.00%) (2533/3968)
Epoch: 7 | Batch_idx: 40 |  Loss: (1.0031) |  Loss2: (0.0000) | Acc: (63.00%) (3352/5248)
Epoch: 7 | Batch_idx: 50 |  Loss: (1.0018) |  Loss2: (0.0000) | Acc: (64.00%) (4178/6528)
Epoch: 7 | Batch_idx: 60 |  Loss: (1.0051) |  Loss2: (0.0000) | Acc: (63.00%) (4989/7808)
Epoch: 7 | Batch_idx: 70 |  Loss: (1.0121) |  Loss2: (0.0000) | Acc: (63.00%) (5812/9088)
Epoch: 7 | Batch_idx: 80 |  Loss: (1.0090) |  Loss2: (0.0000) | Acc: (64.00%) (6645/10368)
Epoch: 7 | Batch_idx: 90 |  Loss: (1.0124) |  Loss2: (0.0000) | Acc: (64.00%) (7459/11648)
Epoch: 7 | Batch_idx: 100 |  Loss: (1.0103) |  Loss2: (0.0000) | Acc: (64.00%) (8301/12928)
Epoch: 7 | Batch_idx: 110 |  Loss: (1.0065) |  Loss2: (0.0000) | Acc: (64.00%) (9137/14208)
Epoch: 7 | Batch_idx: 120 |  Loss: (1.0014) |  Loss2: (0.0000) | Acc: (64.00%) (9998/15488)
Epoch: 7 | Batch_idx: 130 |  Loss: (1.0003) |  Loss2: (0.0000) | Acc: (64.00%) (10813/16768)
Epoch: 7 | Batch_idx: 140 |  Loss: (1.0049) |  Loss2: (0.0000) | Acc: (64.00%) (11601/18048)
Epoch: 7 | Batch_idx: 150 |  Loss: (1.0080) |  Loss2: (0.0000) | Acc: (64.00%) (12401/19328)
Epoch: 7 | Batch_idx: 160 |  Loss: (1.0068) |  Loss2: (0.0000) | Acc: (64.00%) (13236/20608)
Epoch: 7 | Batch_idx: 170 |  Loss: (1.0054) |  Loss2: (0.0000) | Acc: (64.00%) (14079/21888)
Epoch: 7 | Batch_idx: 180 |  Loss: (1.0037) |  Loss2: (0.0000) | Acc: (64.00%) (14913/23168)
Epoch: 7 | Batch_idx: 190 |  Loss: (1.0026) |  Loss2: (0.0000) | Acc: (64.00%) (15752/24448)
Epoch: 7 | Batch_idx: 200 |  Loss: (1.0034) |  Loss2: (0.0000) | Acc: (64.00%) (16574/25728)
Epoch: 7 | Batch_idx: 210 |  Loss: (1.0028) |  Loss2: (0.0000) | Acc: (64.00%) (17395/27008)
Epoch: 7 | Batch_idx: 220 |  Loss: (1.0019) |  Loss2: (0.0000) | Acc: (64.00%) (18252/28288)
Epoch: 7 | Batch_idx: 230 |  Loss: (1.0003) |  Loss2: (0.0000) | Acc: (64.00%) (19088/29568)
Epoch: 7 | Batch_idx: 240 |  Loss: (0.9988) |  Loss2: (0.0000) | Acc: (64.00%) (19937/30848)
Epoch: 7 | Batch_idx: 250 |  Loss: (0.9977) |  Loss2: (0.0000) | Acc: (64.00%) (20786/32128)
Epoch: 7 | Batch_idx: 260 |  Loss: (0.9954) |  Loss2: (0.0000) | Acc: (64.00%) (21639/33408)
Epoch: 7 | Batch_idx: 270 |  Loss: (0.9932) |  Loss2: (0.0000) | Acc: (64.00%) (22518/34688)
Epoch: 7 | Batch_idx: 280 |  Loss: (0.9924) |  Loss2: (0.0000) | Acc: (64.00%) (23365/35968)
Epoch: 7 | Batch_idx: 290 |  Loss: (0.9912) |  Loss2: (0.0000) | Acc: (65.00%) (24217/37248)
Epoch: 7 | Batch_idx: 300 |  Loss: (0.9891) |  Loss2: (0.0000) | Acc: (65.00%) (25075/38528)
Epoch: 7 | Batch_idx: 310 |  Loss: (0.9877) |  Loss2: (0.0000) | Acc: (65.00%) (25913/39808)
Epoch: 7 | Batch_idx: 320 |  Loss: (0.9870) |  Loss2: (0.0000) | Acc: (65.00%) (26743/41088)
Epoch: 7 | Batch_idx: 330 |  Loss: (0.9857) |  Loss2: (0.0000) | Acc: (65.00%) (27586/42368)
Epoch: 7 | Batch_idx: 340 |  Loss: (0.9849) |  Loss2: (0.0000) | Acc: (65.00%) (28427/43648)
Epoch: 7 | Batch_idx: 350 |  Loss: (0.9852) |  Loss2: (0.0000) | Acc: (65.00%) (29260/44928)
Epoch: 7 | Batch_idx: 360 |  Loss: (0.9851) |  Loss2: (0.0000) | Acc: (65.00%) (30103/46208)
Epoch: 7 | Batch_idx: 370 |  Loss: (0.9836) |  Loss2: (0.0000) | Acc: (65.00%) (30965/47488)
Epoch: 7 | Batch_idx: 380 |  Loss: (0.9820) |  Loss2: (0.0000) | Acc: (65.00%) (31827/48768)
Epoch: 7 | Batch_idx: 390 |  Loss: (0.9806) |  Loss2: (0.0000) | Acc: (65.00%) (32662/50000)
# TEST : Loss: (1.0761) | Acc: (62.00%) (6208/10000)
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
Epoch: 8 | Batch_idx: 0 |  Loss: (0.8904) |  Loss2: (0.0000) | Acc: (68.00%) (88/128)
Epoch: 8 | Batch_idx: 10 |  Loss: (0.9223) |  Loss2: (0.0000) | Acc: (65.00%) (929/1408)
Epoch: 8 | Batch_idx: 20 |  Loss: (0.9269) |  Loss2: (0.0000) | Acc: (66.00%) (1786/2688)
Epoch: 8 | Batch_idx: 30 |  Loss: (0.9393) |  Loss2: (0.0000) | Acc: (66.00%) (2637/3968)
Epoch: 8 | Batch_idx: 40 |  Loss: (0.9344) |  Loss2: (0.0000) | Acc: (66.00%) (3503/5248)
Epoch: 8 | Batch_idx: 50 |  Loss: (0.9437) |  Loss2: (0.0000) | Acc: (66.00%) (4338/6528)
Epoch: 8 | Batch_idx: 60 |  Loss: (0.9401) |  Loss2: (0.0000) | Acc: (66.00%) (5216/7808)
Epoch: 8 | Batch_idx: 70 |  Loss: (0.9388) |  Loss2: (0.0000) | Acc: (66.00%) (6062/9088)
Epoch: 8 | Batch_idx: 80 |  Loss: (0.9369) |  Loss2: (0.0000) | Acc: (66.00%) (6925/10368)
Epoch: 8 | Batch_idx: 90 |  Loss: (0.9332) |  Loss2: (0.0000) | Acc: (66.00%) (7782/11648)
Epoch: 8 | Batch_idx: 100 |  Loss: (0.9344) |  Loss2: (0.0000) | Acc: (66.00%) (8635/12928)
Epoch: 8 | Batch_idx: 110 |  Loss: (0.9348) |  Loss2: (0.0000) | Acc: (66.00%) (9490/14208)
Epoch: 8 | Batch_idx: 120 |  Loss: (0.9356) |  Loss2: (0.0000) | Acc: (66.00%) (10336/15488)
Epoch: 8 | Batch_idx: 130 |  Loss: (0.9347) |  Loss2: (0.0000) | Acc: (66.00%) (11175/16768)
Epoch: 8 | Batch_idx: 140 |  Loss: (0.9340) |  Loss2: (0.0000) | Acc: (66.00%) (12036/18048)
Epoch: 8 | Batch_idx: 150 |  Loss: (0.9336) |  Loss2: (0.0000) | Acc: (66.00%) (12904/19328)
Epoch: 8 | Batch_idx: 160 |  Loss: (0.9332) |  Loss2: (0.0000) | Acc: (66.00%) (13760/20608)
Epoch: 8 | Batch_idx: 170 |  Loss: (0.9328) |  Loss2: (0.0000) | Acc: (66.00%) (14623/21888)
Epoch: 8 | Batch_idx: 180 |  Loss: (0.9311) |  Loss2: (0.0000) | Acc: (66.00%) (15479/23168)
Epoch: 8 | Batch_idx: 190 |  Loss: (0.9334) |  Loss2: (0.0000) | Acc: (66.00%) (16316/24448)
Epoch: 8 | Batch_idx: 200 |  Loss: (0.9327) |  Loss2: (0.0000) | Acc: (66.00%) (17170/25728)
Epoch: 8 | Batch_idx: 210 |  Loss: (0.9309) |  Loss2: (0.0000) | Acc: (66.00%) (18056/27008)
Epoch: 8 | Batch_idx: 220 |  Loss: (0.9304) |  Loss2: (0.0000) | Acc: (66.00%) (18926/28288)
Epoch: 8 | Batch_idx: 230 |  Loss: (0.9291) |  Loss2: (0.0000) | Acc: (67.00%) (19814/29568)
Epoch: 8 | Batch_idx: 240 |  Loss: (0.9294) |  Loss2: (0.0000) | Acc: (66.00%) (20668/30848)
Epoch: 8 | Batch_idx: 250 |  Loss: (0.9293) |  Loss2: (0.0000) | Acc: (66.00%) (21524/32128)
Epoch: 8 | Batch_idx: 260 |  Loss: (0.9291) |  Loss2: (0.0000) | Acc: (67.00%) (22395/33408)
Epoch: 8 | Batch_idx: 270 |  Loss: (0.9294) |  Loss2: (0.0000) | Acc: (67.00%) (23241/34688)
Epoch: 8 | Batch_idx: 280 |  Loss: (0.9292) |  Loss2: (0.0000) | Acc: (67.00%) (24101/35968)
Epoch: 8 | Batch_idx: 290 |  Loss: (0.9296) |  Loss2: (0.0000) | Acc: (66.00%) (24945/37248)
Epoch: 8 | Batch_idx: 300 |  Loss: (0.9285) |  Loss2: (0.0000) | Acc: (67.00%) (25819/38528)
Epoch: 8 | Batch_idx: 310 |  Loss: (0.9289) |  Loss2: (0.0000) | Acc: (66.00%) (26662/39808)
Epoch: 8 | Batch_idx: 320 |  Loss: (0.9275) |  Loss2: (0.0000) | Acc: (67.00%) (27532/41088)
Epoch: 8 | Batch_idx: 330 |  Loss: (0.9272) |  Loss2: (0.0000) | Acc: (67.00%) (28401/42368)
Epoch: 8 | Batch_idx: 340 |  Loss: (0.9265) |  Loss2: (0.0000) | Acc: (67.00%) (29264/43648)
Epoch: 8 | Batch_idx: 350 |  Loss: (0.9260) |  Loss2: (0.0000) | Acc: (67.00%) (30131/44928)
Epoch: 8 | Batch_idx: 360 |  Loss: (0.9251) |  Loss2: (0.0000) | Acc: (67.00%) (30989/46208)
Epoch: 8 | Batch_idx: 370 |  Loss: (0.9251) |  Loss2: (0.0000) | Acc: (67.00%) (31843/47488)
Epoch: 8 | Batch_idx: 380 |  Loss: (0.9245) |  Loss2: (0.0000) | Acc: (67.00%) (32723/48768)
Epoch: 8 | Batch_idx: 390 |  Loss: (0.9245) |  Loss2: (0.0000) | Acc: (67.00%) (33571/50000)
# TEST : Loss: (0.9825) | Acc: (64.00%) (6487/10000)
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
False Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=128, out_features=16, bias=False)
True Linear(in_features=16, out_features=2, bias=False)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=128, out_features=16, bias=False)
True Linear(in_features=16, out_features=2, bias=False)
False Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=256, out_features=32, bias=False)
True Linear(in_features=32, out_features=2, bias=False)
False Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=256, out_features=32, bias=False)
True Linear(in_features=32, out_features=2, bias=False)
False Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=512, out_features=64, bias=False)
True Linear(in_features=64, out_features=2, bias=False)
False Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=512, out_features=64, bias=False)
True Linear(in_features=64, out_features=2, bias=False)
False Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1024, out_features=128, bias=False)
True Linear(in_features=128, out_features=2, bias=False)
False Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1024, out_features=128, bias=False)
True Linear(in_features=128, out_features=2, bias=False)
False Linear(in_features=512, out_features=10, bias=True)
Epoch: 9 | Batch_idx: 0 |  Loss: (0.9153) |  Loss2: (0.0000) | Acc: (69.00%) (89/128)
Epoch: 9 | Batch_idx: 10 |  Loss: (0.9763) |  Loss2: (0.0000) | Acc: (65.00%) (921/1408)
Epoch: 9 | Batch_idx: 20 |  Loss: (1.0108) |  Loss2: (0.0000) | Acc: (63.00%) (1719/2688)
Epoch: 9 | Batch_idx: 30 |  Loss: (1.0296) |  Loss2: (0.0000) | Acc: (63.00%) (2518/3968)
Epoch: 9 | Batch_idx: 40 |  Loss: (1.0496) |  Loss2: (0.0000) | Acc: (62.00%) (3298/5248)
Epoch: 9 | Batch_idx: 50 |  Loss: (1.0585) |  Loss2: (0.0000) | Acc: (62.00%) (4095/6528)
Epoch: 9 | Batch_idx: 60 |  Loss: (1.0625) |  Loss2: (0.0000) | Acc: (62.00%) (4875/7808)
Epoch: 9 | Batch_idx: 70 |  Loss: (1.0636) |  Loss2: (0.0000) | Acc: (62.00%) (5667/9088)
Epoch: 9 | Batch_idx: 80 |  Loss: (1.0598) |  Loss2: (0.0000) | Acc: (62.00%) (6475/10368)
Epoch: 9 | Batch_idx: 90 |  Loss: (1.0555) |  Loss2: (0.0000) | Acc: (62.00%) (7312/11648)
Epoch: 9 | Batch_idx: 100 |  Loss: (1.0521) |  Loss2: (0.0000) | Acc: (62.00%) (8125/12928)
Epoch: 9 | Batch_idx: 110 |  Loss: (1.0505) |  Loss2: (0.0000) | Acc: (62.00%) (8942/14208)
Epoch: 9 | Batch_idx: 120 |  Loss: (1.0469) |  Loss2: (0.0000) | Acc: (62.00%) (9752/15488)
Epoch: 9 | Batch_idx: 130 |  Loss: (1.0439) |  Loss2: (0.0000) | Acc: (63.00%) (10578/16768)
Epoch: 9 | Batch_idx: 140 |  Loss: (1.0447) |  Loss2: (0.0000) | Acc: (63.00%) (11394/18048)
Epoch: 9 | Batch_idx: 150 |  Loss: (1.0411) |  Loss2: (0.0000) | Acc: (63.00%) (12253/19328)
Epoch: 9 | Batch_idx: 160 |  Loss: (1.0403) |  Loss2: (0.0000) | Acc: (63.00%) (13074/20608)
Epoch: 9 | Batch_idx: 170 |  Loss: (1.0358) |  Loss2: (0.0000) | Acc: (63.00%) (13919/21888)
Epoch: 9 | Batch_idx: 180 |  Loss: (1.0366) |  Loss2: (0.0000) | Acc: (63.00%) (14730/23168)
Epoch: 9 | Batch_idx: 190 |  Loss: (1.0320) |  Loss2: (0.0000) | Acc: (63.00%) (15580/24448)
Epoch: 9 | Batch_idx: 200 |  Loss: (1.0304) |  Loss2: (0.0000) | Acc: (63.00%) (16407/25728)
Epoch: 9 | Batch_idx: 210 |  Loss: (1.0289) |  Loss2: (0.0000) | Acc: (63.00%) (17229/27008)
Epoch: 9 | Batch_idx: 220 |  Loss: (1.0279) |  Loss2: (0.0000) | Acc: (63.00%) (18050/28288)
Epoch: 9 | Batch_idx: 230 |  Loss: (1.0243) |  Loss2: (0.0000) | Acc: (64.00%) (18932/29568)
Epoch: 9 | Batch_idx: 240 |  Loss: (1.0218) |  Loss2: (0.0000) | Acc: (64.00%) (19778/30848)
Epoch: 9 | Batch_idx: 250 |  Loss: (1.0185) |  Loss2: (0.0000) | Acc: (64.00%) (20638/32128)
Epoch: 9 | Batch_idx: 260 |  Loss: (1.0157) |  Loss2: (0.0000) | Acc: (64.00%) (21485/33408)
Epoch: 9 | Batch_idx: 270 |  Loss: (1.0138) |  Loss2: (0.0000) | Acc: (64.00%) (22316/34688)
Epoch: 9 | Batch_idx: 280 |  Loss: (1.0127) |  Loss2: (0.0000) | Acc: (64.00%) (23139/35968)
Epoch: 9 | Batch_idx: 290 |  Loss: (1.0111) |  Loss2: (0.0000) | Acc: (64.00%) (23973/37248)
Epoch: 9 | Batch_idx: 300 |  Loss: (1.0115) |  Loss2: (0.0000) | Acc: (64.00%) (24786/38528)
Epoch: 9 | Batch_idx: 310 |  Loss: (1.0097) |  Loss2: (0.0000) | Acc: (64.00%) (25627/39808)
Epoch: 9 | Batch_idx: 320 |  Loss: (1.0073) |  Loss2: (0.0000) | Acc: (64.00%) (26467/41088)
Epoch: 9 | Batch_idx: 330 |  Loss: (1.0049) |  Loss2: (0.0000) | Acc: (64.00%) (27339/42368)
Epoch: 9 | Batch_idx: 340 |  Loss: (1.0041) |  Loss2: (0.0000) | Acc: (64.00%) (28184/43648)
Epoch: 9 | Batch_idx: 350 |  Loss: (1.0021) |  Loss2: (0.0000) | Acc: (64.00%) (29043/44928)
Epoch: 9 | Batch_idx: 360 |  Loss: (1.0008) |  Loss2: (0.0000) | Acc: (64.00%) (29889/46208)
Epoch: 9 | Batch_idx: 370 |  Loss: (0.9992) |  Loss2: (0.0000) | Acc: (64.00%) (30730/47488)
Epoch: 9 | Batch_idx: 380 |  Loss: (0.9993) |  Loss2: (0.0000) | Acc: (64.00%) (31553/48768)
Epoch: 9 | Batch_idx: 390 |  Loss: (0.9990) |  Loss2: (0.0000) | Acc: (64.00%) (32360/50000)
# TEST : Loss: (0.9763) | Acc: (65.00%) (6574/10000)
percent tensor([0.4970, 0.4944, 0.4904, 0.4925, 0.4919, 0.4981, 0.4936, 0.4916, 0.4951,
        0.4933, 0.4963, 0.4907, 0.4953, 0.4958, 0.4953, 0.4954],
       device='cuda:0') torch.Size([16])
percent tensor([0.4973, 0.4959, 0.4972, 0.4976, 0.4967, 0.4977, 0.4962, 0.4967, 0.4967,
        0.4957, 0.4965, 0.4961, 0.4963, 0.4970, 0.4967, 0.4967],
       device='cuda:0') torch.Size([16])
percent tensor([0.5006, 0.4987, 0.4966, 0.4979, 0.4968, 0.5028, 0.4979, 0.4973, 0.4984,
        0.4978, 0.4994, 0.4959, 0.4994, 0.4997, 0.4998, 0.5002],
       device='cuda:0') torch.Size([16])
percent tensor([0.5062, 0.5079, 0.5052, 0.5039, 0.5054, 0.5069, 0.5079, 0.5050, 0.5066,
        0.5075, 0.5080, 0.5069, 0.5074, 0.5080, 0.5066, 0.5067],
       device='cuda:0') torch.Size([16])
percent tensor([0.4969, 0.4982, 0.4727, 0.4687, 0.4765, 0.4898, 0.4934, 0.4705, 0.4963,
        0.4963, 0.4993, 0.4848, 0.4996, 0.4985, 0.4914, 0.4948],
       device='cuda:0') torch.Size([16])
percent tensor([0.5045, 0.5045, 0.5030, 0.5030, 0.5030, 0.5052, 0.5032, 0.5034, 0.5036,
        0.5049, 0.5045, 0.5033, 0.5046, 0.5044, 0.5039, 0.5042],
       device='cuda:0') torch.Size([16])
percent tensor([0.5052, 0.5030, 0.5024, 0.5012, 0.5016, 0.5086, 0.5013, 0.5030, 0.5029,
        0.5012, 0.5027, 0.5028, 0.5054, 0.5032, 0.5037, 0.5048],
       device='cuda:0') torch.Size([16])
percent tensor([0.5552, 0.5261, 0.5322, 0.5300, 0.5302, 0.5595, 0.5338, 0.5468, 0.5416,
        0.5417, 0.5446, 0.5302, 0.5547, 0.5393, 0.5397, 0.5722],
       device='cuda:0') torch.Size([16])
Epoch: 10 | Batch_idx: 0 |  Loss: (0.9134) |  Loss2: (0.0000) | Acc: (67.00%) (86/128)
Epoch: 10 | Batch_idx: 10 |  Loss: (0.9268) |  Loss2: (0.0000) | Acc: (67.00%) (954/1408)
Epoch: 10 | Batch_idx: 20 |  Loss: (0.9223) |  Loss2: (0.0000) | Acc: (68.00%) (1828/2688)
Epoch: 10 | Batch_idx: 30 |  Loss: (0.9230) |  Loss2: (0.0000) | Acc: (67.00%) (2689/3968)
Epoch: 10 | Batch_idx: 40 |  Loss: (0.9233) |  Loss2: (0.0000) | Acc: (67.00%) (3555/5248)
Epoch: 10 | Batch_idx: 50 |  Loss: (0.9319) |  Loss2: (0.0000) | Acc: (67.00%) (4410/6528)
Epoch: 10 | Batch_idx: 60 |  Loss: (0.9286) |  Loss2: (0.0000) | Acc: (67.00%) (5255/7808)
Epoch: 10 | Batch_idx: 70 |  Loss: (0.9351) |  Loss2: (0.0000) | Acc: (67.00%) (6089/9088)
Epoch: 10 | Batch_idx: 80 |  Loss: (0.9315) |  Loss2: (0.0000) | Acc: (67.00%) (6969/10368)
Epoch: 10 | Batch_idx: 90 |  Loss: (0.9321) |  Loss2: (0.0000) | Acc: (67.00%) (7813/11648)
Epoch: 10 | Batch_idx: 100 |  Loss: (0.9373) |  Loss2: (0.0000) | Acc: (66.00%) (8652/12928)
Epoch: 10 | Batch_idx: 110 |  Loss: (0.9385) |  Loss2: (0.0000) | Acc: (66.00%) (9500/14208)
Epoch: 10 | Batch_idx: 120 |  Loss: (0.9361) |  Loss2: (0.0000) | Acc: (66.00%) (10361/15488)
Epoch: 10 | Batch_idx: 130 |  Loss: (0.9380) |  Loss2: (0.0000) | Acc: (66.00%) (11206/16768)
Epoch: 10 | Batch_idx: 140 |  Loss: (0.9363) |  Loss2: (0.0000) | Acc: (66.00%) (12070/18048)
Epoch: 10 | Batch_idx: 150 |  Loss: (0.9393) |  Loss2: (0.0000) | Acc: (66.00%) (12911/19328)
Epoch: 10 | Batch_idx: 160 |  Loss: (0.9403) |  Loss2: (0.0000) | Acc: (66.00%) (13753/20608)
Epoch: 10 | Batch_idx: 170 |  Loss: (0.9376) |  Loss2: (0.0000) | Acc: (66.00%) (14648/21888)
Epoch: 10 | Batch_idx: 180 |  Loss: (0.9369) |  Loss2: (0.0000) | Acc: (66.00%) (15507/23168)
Epoch: 10 | Batch_idx: 190 |  Loss: (0.9377) |  Loss2: (0.0000) | Acc: (66.00%) (16342/24448)
Epoch: 10 | Batch_idx: 200 |  Loss: (0.9359) |  Loss2: (0.0000) | Acc: (66.00%) (17213/25728)
Epoch: 10 | Batch_idx: 210 |  Loss: (0.9338) |  Loss2: (0.0000) | Acc: (67.00%) (18104/27008)
Epoch: 10 | Batch_idx: 220 |  Loss: (0.9319) |  Loss2: (0.0000) | Acc: (67.00%) (18978/28288)
Epoch: 10 | Batch_idx: 230 |  Loss: (0.9339) |  Loss2: (0.0000) | Acc: (67.00%) (19821/29568)
Epoch: 10 | Batch_idx: 240 |  Loss: (0.9338) |  Loss2: (0.0000) | Acc: (67.00%) (20681/30848)
Epoch: 10 | Batch_idx: 250 |  Loss: (0.9332) |  Loss2: (0.0000) | Acc: (67.00%) (21548/32128)
Epoch: 10 | Batch_idx: 260 |  Loss: (0.9326) |  Loss2: (0.0000) | Acc: (67.00%) (22408/33408)
Epoch: 10 | Batch_idx: 270 |  Loss: (0.9321) |  Loss2: (0.0000) | Acc: (67.00%) (23263/34688)
Epoch: 10 | Batch_idx: 280 |  Loss: (0.9336) |  Loss2: (0.0000) | Acc: (67.00%) (24106/35968)
Epoch: 10 | Batch_idx: 290 |  Loss: (0.9312) |  Loss2: (0.0000) | Acc: (67.00%) (24984/37248)
Epoch: 10 | Batch_idx: 300 |  Loss: (0.9311) |  Loss2: (0.0000) | Acc: (67.00%) (25829/38528)
Epoch: 10 | Batch_idx: 310 |  Loss: (0.9305) |  Loss2: (0.0000) | Acc: (67.00%) (26697/39808)
Epoch: 10 | Batch_idx: 320 |  Loss: (0.9314) |  Loss2: (0.0000) | Acc: (66.00%) (27523/41088)
Epoch: 10 | Batch_idx: 330 |  Loss: (0.9306) |  Loss2: (0.0000) | Acc: (67.00%) (28396/42368)
Epoch: 10 | Batch_idx: 340 |  Loss: (0.9310) |  Loss2: (0.0000) | Acc: (67.00%) (29278/43648)
Epoch: 10 | Batch_idx: 350 |  Loss: (0.9301) |  Loss2: (0.0000) | Acc: (67.00%) (30180/44928)
Epoch: 10 | Batch_idx: 360 |  Loss: (0.9291) |  Loss2: (0.0000) | Acc: (67.00%) (31034/46208)
Epoch: 10 | Batch_idx: 370 |  Loss: (0.9274) |  Loss2: (0.0000) | Acc: (67.00%) (31914/47488)
Epoch: 10 | Batch_idx: 380 |  Loss: (0.9273) |  Loss2: (0.0000) | Acc: (67.00%) (32772/48768)
Epoch: 10 | Batch_idx: 390 |  Loss: (0.9275) |  Loss2: (0.0000) | Acc: (67.00%) (33603/50000)
=> saving checkpoint 'drive/app/torch/save_Schedule/checkpoint_010.pth.tar'
# TEST : Loss: (0.9349) | Acc: (67.00%) (6736/10000)
percent tensor([0.4965, 0.4931, 0.4873, 0.4903, 0.4895, 0.4983, 0.4920, 0.4890, 0.4941,
        0.4914, 0.4958, 0.4877, 0.4941, 0.4951, 0.4944, 0.4945],
       device='cuda:0') torch.Size([16])
percent tensor([0.4982, 0.4961, 0.4980, 0.4987, 0.4973, 0.4989, 0.4964, 0.4976, 0.4974,
        0.4958, 0.4971, 0.4963, 0.4965, 0.4978, 0.4973, 0.4977],
       device='cuda:0') torch.Size([16])
percent tensor([0.5057, 0.5025, 0.4992, 0.5027, 0.4992, 0.5122, 0.5013, 0.5007, 0.5011,
        0.5006, 0.5030, 0.4988, 0.5029, 0.5045, 0.5052, 0.5053],
       device='cuda:0') torch.Size([16])
percent tensor([0.5078, 0.5101, 0.5066, 0.5056, 0.5069, 0.5087, 0.5102, 0.5068, 0.5086,
        0.5096, 0.5102, 0.5087, 0.5092, 0.5108, 0.5081, 0.5088],
       device='cuda:0') torch.Size([16])
percent tensor([0.4943, 0.4972, 0.4483, 0.4428, 0.4555, 0.4836, 0.4893, 0.4484, 0.4931,
        0.4947, 0.4989, 0.4725, 0.4989, 0.4975, 0.4865, 0.4926],
       device='cuda:0') torch.Size([16])
percent tensor([0.5069, 0.5072, 0.5039, 0.5042, 0.5045, 0.5076, 0.5052, 0.5052, 0.5056,
        0.5079, 0.5071, 0.5051, 0.5073, 0.5070, 0.5061, 0.5067],
       device='cuda:0') torch.Size([16])
percent tensor([0.5098, 0.5083, 0.5072, 0.5053, 0.5070, 0.5152, 0.5045, 0.5093, 0.5081,
        0.5065, 0.5089, 0.5089, 0.5136, 0.5084, 0.5080, 0.5092],
       device='cuda:0') torch.Size([16])
percent tensor([0.6512, 0.5910, 0.6118, 0.6062, 0.6099, 0.6639, 0.6054, 0.6472, 0.6248,
        0.6355, 0.6370, 0.6022, 0.6547, 0.6192, 0.6203, 0.6826],
       device='cuda:0') torch.Size([16])
Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 3, 3, 3]) tensor(168.0039, device='cuda:0')
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(783.1852, device='cuda:0')
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(775.2946, device='cuda:0')
Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([128, 64, 3, 3]) tensor(1532.4907, device='cuda:0')
Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([128, 64, 1, 1]) tensor(502.8860, device='cuda:0')
Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([128, 128, 3, 3]) tensor(2172.5200, device='cuda:0')
Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([256, 128, 3, 3]) tensor(4319.5405, device='cuda:0')
Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([256, 128, 1, 1]) tensor(1433.1996, device='cuda:0')
Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([256, 256, 3, 3]) tensor(6108.6211, device='cuda:0')
Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([512, 256, 3, 3]) tensor(12221.9307, device='cuda:0')
Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([512, 256, 1, 1]) tensor(4079.2346, device='cuda:0')
Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([512, 512, 3, 3]) tensor(17278.1113, device='cuda:0')
Epoch: 11 | Batch_idx: 0 |  Loss: (1.0256) |  Loss2: (0.0000) | Acc: (62.00%) (80/128)
Epoch: 11 | Batch_idx: 10 |  Loss: (0.9272) |  Loss2: (0.0000) | Acc: (66.00%) (938/1408)
Epoch: 11 | Batch_idx: 20 |  Loss: (0.9341) |  Loss2: (0.0000) | Acc: (66.00%) (1798/2688)
Epoch: 11 | Batch_idx: 30 |  Loss: (0.9290) |  Loss2: (0.0000) | Acc: (67.00%) (2665/3968)
Epoch: 11 | Batch_idx: 40 |  Loss: (0.9226) |  Loss2: (0.0000) | Acc: (67.00%) (3526/5248)
Epoch: 11 | Batch_idx: 50 |  Loss: (0.9195) |  Loss2: (0.0000) | Acc: (67.00%) (4390/6528)
Epoch: 11 | Batch_idx: 60 |  Loss: (0.9208) |  Loss2: (0.0000) | Acc: (67.00%) (5253/7808)
Epoch: 11 | Batch_idx: 70 |  Loss: (0.9190) |  Loss2: (0.0000) | Acc: (67.00%) (6116/9088)
Epoch: 11 | Batch_idx: 80 |  Loss: (0.9157) |  Loss2: (0.0000) | Acc: (67.00%) (6987/10368)
Epoch: 11 | Batch_idx: 90 |  Loss: (0.9152) |  Loss2: (0.0000) | Acc: (67.00%) (7856/11648)
Epoch: 11 | Batch_idx: 100 |  Loss: (0.9157) |  Loss2: (0.0000) | Acc: (67.00%) (8722/12928)
Epoch: 11 | Batch_idx: 110 |  Loss: (0.9092) |  Loss2: (0.0000) | Acc: (67.00%) (9619/14208)
Epoch: 11 | Batch_idx: 120 |  Loss: (0.9081) |  Loss2: (0.0000) | Acc: (67.00%) (10496/15488)
Epoch: 11 | Batch_idx: 130 |  Loss: (0.9070) |  Loss2: (0.0000) | Acc: (67.00%) (11393/16768)
Epoch: 11 | Batch_idx: 140 |  Loss: (0.9046) |  Loss2: (0.0000) | Acc: (67.00%) (12269/18048)
Epoch: 11 | Batch_idx: 150 |  Loss: (0.9078) |  Loss2: (0.0000) | Acc: (67.00%) (13125/19328)
Epoch: 11 | Batch_idx: 160 |  Loss: (0.9067) |  Loss2: (0.0000) | Acc: (68.00%) (14026/20608)
Epoch: 11 | Batch_idx: 170 |  Loss: (0.9057) |  Loss2: (0.0000) | Acc: (68.00%) (14899/21888)
Epoch: 11 | Batch_idx: 180 |  Loss: (0.9067) |  Loss2: (0.0000) | Acc: (67.00%) (15752/23168)
Epoch: 11 | Batch_idx: 190 |  Loss: (0.9073) |  Loss2: (0.0000) | Acc: (68.00%) (16635/24448)
Epoch: 11 | Batch_idx: 200 |  Loss: (0.9059) |  Loss2: (0.0000) | Acc: (68.00%) (17515/25728)
Epoch: 11 | Batch_idx: 210 |  Loss: (0.9041) |  Loss2: (0.0000) | Acc: (68.00%) (18401/27008)
Epoch: 11 | Batch_idx: 220 |  Loss: (0.9048) |  Loss2: (0.0000) | Acc: (68.00%) (19257/28288)
Epoch: 11 | Batch_idx: 230 |  Loss: (0.9046) |  Loss2: (0.0000) | Acc: (68.00%) (20130/29568)
Epoch: 11 | Batch_idx: 240 |  Loss: (0.9054) |  Loss2: (0.0000) | Acc: (68.00%) (20987/30848)
Epoch: 11 | Batch_idx: 250 |  Loss: (0.9042) |  Loss2: (0.0000) | Acc: (68.00%) (21871/32128)
Epoch: 11 | Batch_idx: 260 |  Loss: (0.9034) |  Loss2: (0.0000) | Acc: (68.00%) (22763/33408)
Epoch: 11 | Batch_idx: 270 |  Loss: (0.9046) |  Loss2: (0.0000) | Acc: (68.00%) (23611/34688)
Epoch: 11 | Batch_idx: 280 |  Loss: (0.9039) |  Loss2: (0.0000) | Acc: (68.00%) (24496/35968)
Epoch: 11 | Batch_idx: 290 |  Loss: (0.9035) |  Loss2: (0.0000) | Acc: (68.00%) (25383/37248)
Epoch: 11 | Batch_idx: 300 |  Loss: (0.9026) |  Loss2: (0.0000) | Acc: (68.00%) (26253/38528)
Epoch: 11 | Batch_idx: 310 |  Loss: (0.9028) |  Loss2: (0.0000) | Acc: (68.00%) (27135/39808)
Epoch: 11 | Batch_idx: 320 |  Loss: (0.9028) |  Loss2: (0.0000) | Acc: (68.00%) (27994/41088)
Epoch: 11 | Batch_idx: 330 |  Loss: (0.9048) |  Loss2: (0.0000) | Acc: (68.00%) (28838/42368)
Epoch: 11 | Batch_idx: 340 |  Loss: (0.9045) |  Loss2: (0.0000) | Acc: (68.00%) (29705/43648)
Epoch: 11 | Batch_idx: 350 |  Loss: (0.9031) |  Loss2: (0.0000) | Acc: (68.00%) (30585/44928)
Epoch: 11 | Batch_idx: 360 |  Loss: (0.9039) |  Loss2: (0.0000) | Acc: (68.00%) (31443/46208)
Epoch: 11 | Batch_idx: 370 |  Loss: (0.9036) |  Loss2: (0.0000) | Acc: (68.00%) (32319/47488)
Epoch: 11 | Batch_idx: 380 |  Loss: (0.9037) |  Loss2: (0.0000) | Acc: (68.00%) (33189/48768)
Epoch: 11 | Batch_idx: 390 |  Loss: (0.9032) |  Loss2: (0.0000) | Acc: (68.00%) (34048/50000)
# TEST : Loss: (0.9222) | Acc: (67.00%) (6782/10000)
percent tensor([0.4964, 0.4925, 0.4850, 0.4889, 0.4878, 0.4987, 0.4911, 0.4873, 0.4934,
        0.4902, 0.4958, 0.4856, 0.4934, 0.4949, 0.4942, 0.4942],
       device='cuda:0') torch.Size([16])
percent tensor([0.4987, 0.4960, 0.4984, 0.4994, 0.4974, 0.4996, 0.4963, 0.4980, 0.4975,
        0.4954, 0.4973, 0.4961, 0.4964, 0.4983, 0.4975, 0.4981],
       device='cuda:0') torch.Size([16])
percent tensor([0.5099, 0.5059, 0.5019, 0.5072, 0.5014, 0.5198, 0.5045, 0.5041, 0.5038,
        0.5033, 0.5062, 0.5014, 0.5059, 0.5090, 0.5095, 0.5098],
       device='cuda:0') torch.Size([16])
percent tensor([0.5095, 0.5124, 0.5085, 0.5075, 0.5089, 0.5105, 0.5127, 0.5089, 0.5108,
        0.5118, 0.5124, 0.5105, 0.5109, 0.5138, 0.5097, 0.5110],
       device='cuda:0') torch.Size([16])
percent tensor([0.4943, 0.4969, 0.4407, 0.4351, 0.4510, 0.4839, 0.4900, 0.4443, 0.4913,
        0.4943, 0.4984, 0.4682, 0.4975, 0.4966, 0.4869, 0.4935],
       device='cuda:0') torch.Size([16])
percent tensor([0.5079, 0.5084, 0.5041, 0.5048, 0.5051, 0.5089, 0.5060, 0.5061, 0.5063,
        0.5090, 0.5079, 0.5055, 0.5082, 0.5081, 0.5072, 0.5079],
       device='cuda:0') torch.Size([16])
percent tensor([0.5088, 0.5102, 0.5085, 0.5061, 0.5089, 0.5151, 0.5043, 0.5110, 0.5095,
        0.5074, 0.5102, 0.5105, 0.5150, 0.5084, 0.5086, 0.5080],
       device='cuda:0') torch.Size([16])
percent tensor([0.7053, 0.6443, 0.6722, 0.6653, 0.6731, 0.7247, 0.6516, 0.7133, 0.6834,
        0.7056, 0.7067, 0.6585, 0.7208, 0.6728, 0.6738, 0.7351],
       device='cuda:0') torch.Size([16])
Epoch: 12 | Batch_idx: 0 |  Loss: (0.9893) |  Loss2: (0.0000) | Acc: (64.00%) (83/128)
Epoch: 12 | Batch_idx: 10 |  Loss: (0.9181) |  Loss2: (0.0000) | Acc: (67.00%) (956/1408)
Epoch: 12 | Batch_idx: 20 |  Loss: (0.8817) |  Loss2: (0.0000) | Acc: (68.00%) (1850/2688)
Epoch: 12 | Batch_idx: 30 |  Loss: (0.8952) |  Loss2: (0.0000) | Acc: (68.00%) (2702/3968)
Epoch: 12 | Batch_idx: 40 |  Loss: (0.9076) |  Loss2: (0.0000) | Acc: (67.00%) (3544/5248)
Epoch: 12 | Batch_idx: 50 |  Loss: (0.9086) |  Loss2: (0.0000) | Acc: (67.00%) (4420/6528)
Epoch: 12 | Batch_idx: 60 |  Loss: (0.8986) |  Loss2: (0.0000) | Acc: (68.00%) (5316/7808)
Epoch: 12 | Batch_idx: 70 |  Loss: (0.9014) |  Loss2: (0.0000) | Acc: (67.00%) (6178/9088)
Epoch: 12 | Batch_idx: 80 |  Loss: (0.8977) |  Loss2: (0.0000) | Acc: (68.00%) (7061/10368)
Epoch: 12 | Batch_idx: 90 |  Loss: (0.9033) |  Loss2: (0.0000) | Acc: (67.00%) (7886/11648)
Epoch: 12 | Batch_idx: 100 |  Loss: (0.9025) |  Loss2: (0.0000) | Acc: (67.00%) (8758/12928)
Epoch: 12 | Batch_idx: 110 |  Loss: (0.9061) |  Loss2: (0.0000) | Acc: (67.00%) (9609/14208)
Epoch: 12 | Batch_idx: 120 |  Loss: (0.9073) |  Loss2: (0.0000) | Acc: (67.00%) (10472/15488)
Epoch: 12 | Batch_idx: 130 |  Loss: (0.9077) |  Loss2: (0.0000) | Acc: (67.00%) (11330/16768)
Epoch: 12 | Batch_idx: 140 |  Loss: (0.9019) |  Loss2: (0.0000) | Acc: (67.00%) (12229/18048)
Epoch: 12 | Batch_idx: 150 |  Loss: (0.8992) |  Loss2: (0.0000) | Acc: (67.00%) (13098/19328)
Epoch: 12 | Batch_idx: 160 |  Loss: (0.8967) |  Loss2: (0.0000) | Acc: (67.00%) (13996/20608)
Epoch: 12 | Batch_idx: 170 |  Loss: (0.8971) |  Loss2: (0.0000) | Acc: (67.00%) (14877/21888)
Epoch: 12 | Batch_idx: 180 |  Loss: (0.8980) |  Loss2: (0.0000) | Acc: (68.00%) (15757/23168)
Epoch: 12 | Batch_idx: 190 |  Loss: (0.8977) |  Loss2: (0.0000) | Acc: (68.00%) (16643/24448)
Epoch: 12 | Batch_idx: 200 |  Loss: (0.8957) |  Loss2: (0.0000) | Acc: (68.00%) (17509/25728)
Epoch: 12 | Batch_idx: 210 |  Loss: (0.8932) |  Loss2: (0.0000) | Acc: (68.00%) (18397/27008)
Epoch: 12 | Batch_idx: 220 |  Loss: (0.8925) |  Loss2: (0.0000) | Acc: (68.00%) (19275/28288)
Epoch: 12 | Batch_idx: 230 |  Loss: (0.8924) |  Loss2: (0.0000) | Acc: (68.00%) (20146/29568)
Epoch: 12 | Batch_idx: 240 |  Loss: (0.8909) |  Loss2: (0.0000) | Acc: (68.00%) (21047/30848)
Epoch: 12 | Batch_idx: 250 |  Loss: (0.8903) |  Loss2: (0.0000) | Acc: (68.00%) (21944/32128)
Epoch: 12 | Batch_idx: 260 |  Loss: (0.8890) |  Loss2: (0.0000) | Acc: (68.00%) (22832/33408)
Epoch: 12 | Batch_idx: 270 |  Loss: (0.8898) |  Loss2: (0.0000) | Acc: (68.00%) (23705/34688)
Epoch: 12 | Batch_idx: 280 |  Loss: (0.8917) |  Loss2: (0.0000) | Acc: (68.00%) (24554/35968)
Epoch: 12 | Batch_idx: 290 |  Loss: (0.8916) |  Loss2: (0.0000) | Acc: (68.00%) (25438/37248)
Epoch: 12 | Batch_idx: 300 |  Loss: (0.8912) |  Loss2: (0.0000) | Acc: (68.00%) (26310/38528)
Epoch: 12 | Batch_idx: 310 |  Loss: (0.8910) |  Loss2: (0.0000) | Acc: (68.00%) (27187/39808)
Epoch: 12 | Batch_idx: 320 |  Loss: (0.8913) |  Loss2: (0.0000) | Acc: (68.00%) (28053/41088)
Epoch: 12 | Batch_idx: 330 |  Loss: (0.8917) |  Loss2: (0.0000) | Acc: (68.00%) (28914/42368)
Epoch: 12 | Batch_idx: 340 |  Loss: (0.8909) |  Loss2: (0.0000) | Acc: (68.00%) (29798/43648)
Epoch: 12 | Batch_idx: 350 |  Loss: (0.8899) |  Loss2: (0.0000) | Acc: (68.00%) (30677/44928)
Epoch: 12 | Batch_idx: 360 |  Loss: (0.8903) |  Loss2: (0.0000) | Acc: (68.00%) (31554/46208)
Epoch: 12 | Batch_idx: 370 |  Loss: (0.8897) |  Loss2: (0.0000) | Acc: (68.00%) (32439/47488)
Epoch: 12 | Batch_idx: 380 |  Loss: (0.8904) |  Loss2: (0.0000) | Acc: (68.00%) (33305/48768)
Epoch: 12 | Batch_idx: 390 |  Loss: (0.8895) |  Loss2: (0.0000) | Acc: (68.00%) (34138/50000)
# TEST : Loss: (0.9129) | Acc: (68.00%) (6838/10000)
percent tensor([0.4961, 0.4919, 0.4832, 0.4879, 0.4864, 0.4990, 0.4903, 0.4861, 0.4926,
        0.4893, 0.4956, 0.4839, 0.4927, 0.4946, 0.4940, 0.4939],
       device='cuda:0') torch.Size([16])
percent tensor([0.4996, 0.4966, 0.4992, 0.5004, 0.4979, 0.5008, 0.4968, 0.4990, 0.4982,
        0.4958, 0.4980, 0.4964, 0.4968, 0.4993, 0.4983, 0.4992],
       device='cuda:0') torch.Size([16])
percent tensor([0.5127, 0.5083, 0.5039, 0.5108, 0.5031, 0.5242, 0.5070, 0.5067, 0.5060,
        0.5054, 0.5086, 0.5033, 0.5081, 0.5127, 0.5122, 0.5129],
       device='cuda:0') torch.Size([16])
percent tensor([0.5117, 0.5151, 0.5104, 0.5097, 0.5110, 0.5127, 0.5156, 0.5111, 0.5134,
        0.5143, 0.5152, 0.5126, 0.5132, 0.5172, 0.5116, 0.5136],
       device='cuda:0') torch.Size([16])
percent tensor([0.4943, 0.4964, 0.4429, 0.4383, 0.4551, 0.4851, 0.4922, 0.4494, 0.4908,
        0.4942, 0.4976, 0.4688, 0.4959, 0.4959, 0.4889, 0.4949],
       device='cuda:0') torch.Size([16])
percent tensor([0.5076, 0.5082, 0.5035, 0.5049, 0.5050, 0.5090, 0.5058, 0.5063, 0.5057,
        0.5085, 0.5071, 0.5047, 0.5075, 0.5080, 0.5072, 0.5080],
       device='cuda:0') torch.Size([16])
percent tensor([0.5085, 0.5122, 0.5100, 0.5077, 0.5113, 0.5150, 0.5050, 0.5134, 0.5111,
        0.5094, 0.5123, 0.5123, 0.5169, 0.5097, 0.5092, 0.5078],
       device='cuda:0') torch.Size([16])
percent tensor([0.7326, 0.6785, 0.7091, 0.7020, 0.7100, 0.7597, 0.6812, 0.7581, 0.7134,
        0.7446, 0.7458, 0.6888, 0.7545, 0.7037, 0.7109, 0.7622],
       device='cuda:0') torch.Size([16])
Epoch: 13 | Batch_idx: 0 |  Loss: (1.0072) |  Loss2: (0.0000) | Acc: (64.00%) (82/128)
Epoch: 13 | Batch_idx: 10 |  Loss: (0.9459) |  Loss2: (0.0000) | Acc: (66.00%) (932/1408)
Epoch: 13 | Batch_idx: 20 |  Loss: (0.9172) |  Loss2: (0.0000) | Acc: (66.00%) (1793/2688)
Epoch: 13 | Batch_idx: 30 |  Loss: (0.9228) |  Loss2: (0.0000) | Acc: (66.00%) (2654/3968)
Epoch: 13 | Batch_idx: 40 |  Loss: (0.9110) |  Loss2: (0.0000) | Acc: (67.00%) (3544/5248)
Epoch: 13 | Batch_idx: 50 |  Loss: (0.9139) |  Loss2: (0.0000) | Acc: (67.00%) (4403/6528)
Epoch: 13 | Batch_idx: 60 |  Loss: (0.9112) |  Loss2: (0.0000) | Acc: (67.00%) (5271/7808)
Epoch: 13 | Batch_idx: 70 |  Loss: (0.9057) |  Loss2: (0.0000) | Acc: (67.00%) (6151/9088)
Epoch: 13 | Batch_idx: 80 |  Loss: (0.9009) |  Loss2: (0.0000) | Acc: (67.00%) (7041/10368)
Epoch: 13 | Batch_idx: 90 |  Loss: (0.8992) |  Loss2: (0.0000) | Acc: (67.00%) (7914/11648)
Epoch: 13 | Batch_idx: 100 |  Loss: (0.8918) |  Loss2: (0.0000) | Acc: (68.00%) (8829/12928)
Epoch: 13 | Batch_idx: 110 |  Loss: (0.8930) |  Loss2: (0.0000) | Acc: (68.00%) (9676/14208)
Epoch: 13 | Batch_idx: 120 |  Loss: (0.8910) |  Loss2: (0.0000) | Acc: (68.00%) (10571/15488)
Epoch: 13 | Batch_idx: 130 |  Loss: (0.8929) |  Loss2: (0.0000) | Acc: (68.00%) (11435/16768)
Epoch: 13 | Batch_idx: 140 |  Loss: (0.8941) |  Loss2: (0.0000) | Acc: (68.00%) (12306/18048)
Epoch: 13 | Batch_idx: 150 |  Loss: (0.8944) |  Loss2: (0.0000) | Acc: (68.00%) (13166/19328)
Epoch: 13 | Batch_idx: 160 |  Loss: (0.8934) |  Loss2: (0.0000) | Acc: (68.00%) (14063/20608)
Epoch: 13 | Batch_idx: 170 |  Loss: (0.8935) |  Loss2: (0.0000) | Acc: (68.00%) (14929/21888)
Epoch: 13 | Batch_idx: 180 |  Loss: (0.8907) |  Loss2: (0.0000) | Acc: (68.00%) (15822/23168)
Epoch: 13 | Batch_idx: 190 |  Loss: (0.8873) |  Loss2: (0.0000) | Acc: (68.00%) (16719/24448)
Epoch: 13 | Batch_idx: 200 |  Loss: (0.8840) |  Loss2: (0.0000) | Acc: (68.00%) (17630/25728)
Epoch: 13 | Batch_idx: 210 |  Loss: (0.8853) |  Loss2: (0.0000) | Acc: (68.00%) (18513/27008)
Epoch: 13 | Batch_idx: 220 |  Loss: (0.8852) |  Loss2: (0.0000) | Acc: (68.00%) (19369/28288)
Epoch: 13 | Batch_idx: 230 |  Loss: (0.8862) |  Loss2: (0.0000) | Acc: (68.00%) (20246/29568)
Epoch: 13 | Batch_idx: 240 |  Loss: (0.8854) |  Loss2: (0.0000) | Acc: (68.00%) (21146/30848)
Epoch: 13 | Batch_idx: 250 |  Loss: (0.8851) |  Loss2: (0.0000) | Acc: (68.00%) (22007/32128)
Epoch: 13 | Batch_idx: 260 |  Loss: (0.8871) |  Loss2: (0.0000) | Acc: (68.00%) (22867/33408)
Epoch: 13 | Batch_idx: 270 |  Loss: (0.8875) |  Loss2: (0.0000) | Acc: (68.00%) (23724/34688)
Epoch: 13 | Batch_idx: 280 |  Loss: (0.8877) |  Loss2: (0.0000) | Acc: (68.00%) (24581/35968)
Epoch: 13 | Batch_idx: 290 |  Loss: (0.8866) |  Loss2: (0.0000) | Acc: (68.00%) (25497/37248)
Epoch: 13 | Batch_idx: 300 |  Loss: (0.8860) |  Loss2: (0.0000) | Acc: (68.00%) (26384/38528)
Epoch: 13 | Batch_idx: 310 |  Loss: (0.8861) |  Loss2: (0.0000) | Acc: (68.00%) (27273/39808)
Epoch: 13 | Batch_idx: 320 |  Loss: (0.8854) |  Loss2: (0.0000) | Acc: (68.00%) (28176/41088)
Epoch: 13 | Batch_idx: 330 |  Loss: (0.8851) |  Loss2: (0.0000) | Acc: (68.00%) (29052/42368)
Epoch: 13 | Batch_idx: 340 |  Loss: (0.8851) |  Loss2: (0.0000) | Acc: (68.00%) (29934/43648)
Epoch: 13 | Batch_idx: 350 |  Loss: (0.8844) |  Loss2: (0.0000) | Acc: (68.00%) (30825/44928)
Epoch: 13 | Batch_idx: 360 |  Loss: (0.8847) |  Loss2: (0.0000) | Acc: (68.00%) (31683/46208)
Epoch: 13 | Batch_idx: 370 |  Loss: (0.8860) |  Loss2: (0.0000) | Acc: (68.00%) (32544/47488)
Epoch: 13 | Batch_idx: 380 |  Loss: (0.8863) |  Loss2: (0.0000) | Acc: (68.00%) (33402/48768)
Epoch: 13 | Batch_idx: 390 |  Loss: (0.8865) |  Loss2: (0.0000) | Acc: (68.00%) (34258/50000)
# TEST : Loss: (0.9067) | Acc: (68.00%) (6847/10000)
percent tensor([0.4962, 0.4922, 0.4830, 0.4882, 0.4862, 0.4996, 0.4903, 0.4861, 0.4926,
        0.4893, 0.4959, 0.4836, 0.4926, 0.4949, 0.4945, 0.4942],
       device='cuda:0') torch.Size([16])
percent tensor([0.5006, 0.4973, 0.4999, 0.5014, 0.4985, 0.5020, 0.4973, 0.4999, 0.4989,
        0.4962, 0.4988, 0.4966, 0.4973, 0.5004, 0.4991, 0.5002],
       device='cuda:0') torch.Size([16])
percent tensor([0.5148, 0.5101, 0.5061, 0.5134, 0.5046, 0.5271, 0.5088, 0.5087, 0.5077,
        0.5073, 0.5105, 0.5056, 0.5103, 0.5153, 0.5138, 0.5155],
       device='cuda:0') torch.Size([16])
percent tensor([0.5137, 0.5175, 0.5126, 0.5122, 0.5134, 0.5147, 0.5185, 0.5136, 0.5162,
        0.5168, 0.5177, 0.5149, 0.5152, 0.5207, 0.5135, 0.5161],
       device='cuda:0') torch.Size([16])
percent tensor([0.4925, 0.4948, 0.4426, 0.4378, 0.4564, 0.4843, 0.4929, 0.4509, 0.4891,
        0.4930, 0.4955, 0.4678, 0.4931, 0.4937, 0.4886, 0.4944],
       device='cuda:0') torch.Size([16])
percent tensor([0.5060, 0.5066, 0.5018, 0.5037, 0.5038, 0.5077, 0.5045, 0.5050, 0.5041,
        0.5065, 0.5050, 0.5030, 0.5055, 0.5066, 0.5060, 0.5068],
       device='cuda:0') torch.Size([16])
percent tensor([0.5060, 0.5136, 0.5112, 0.5082, 0.5131, 0.5124, 0.5050, 0.5151, 0.5118,
        0.5101, 0.5135, 0.5137, 0.5172, 0.5094, 0.5094, 0.5053],
       device='cuda:0') torch.Size([16])
percent tensor([0.7282, 0.6847, 0.7142, 0.7097, 0.7177, 0.7641, 0.6821, 0.7637, 0.7158,
        0.7504, 0.7548, 0.6947, 0.7577, 0.7049, 0.7109, 0.7565],
       device='cuda:0') torch.Size([16])
Epoch: 14 | Batch_idx: 0 |  Loss: (1.0296) |  Loss2: (0.0000) | Acc: (60.00%) (77/128)
Epoch: 14 | Batch_idx: 10 |  Loss: (0.8618) |  Loss2: (0.0000) | Acc: (67.00%) (955/1408)
Epoch: 14 | Batch_idx: 20 |  Loss: (0.9138) |  Loss2: (0.0000) | Acc: (66.00%) (1791/2688)
Epoch: 14 | Batch_idx: 30 |  Loss: (0.8981) |  Loss2: (0.0000) | Acc: (67.00%) (2682/3968)
Epoch: 14 | Batch_idx: 40 |  Loss: (0.8836) |  Loss2: (0.0000) | Acc: (68.00%) (3570/5248)
Epoch: 14 | Batch_idx: 50 |  Loss: (0.8799) |  Loss2: (0.0000) | Acc: (68.00%) (4441/6528)
Epoch: 14 | Batch_idx: 60 |  Loss: (0.8785) |  Loss2: (0.0000) | Acc: (68.00%) (5312/7808)
Epoch: 14 | Batch_idx: 70 |  Loss: (0.8766) |  Loss2: (0.0000) | Acc: (68.00%) (6201/9088)
Epoch: 14 | Batch_idx: 80 |  Loss: (0.8769) |  Loss2: (0.0000) | Acc: (68.00%) (7064/10368)
Epoch: 14 | Batch_idx: 90 |  Loss: (0.8773) |  Loss2: (0.0000) | Acc: (68.00%) (7950/11648)
Epoch: 14 | Batch_idx: 100 |  Loss: (0.8777) |  Loss2: (0.0000) | Acc: (68.00%) (8845/12928)
Epoch: 14 | Batch_idx: 110 |  Loss: (0.8725) |  Loss2: (0.0000) | Acc: (68.00%) (9743/14208)
Epoch: 14 | Batch_idx: 120 |  Loss: (0.8712) |  Loss2: (0.0000) | Acc: (68.00%) (10626/15488)
Epoch: 14 | Batch_idx: 130 |  Loss: (0.8711) |  Loss2: (0.0000) | Acc: (68.00%) (11522/16768)
Epoch: 14 | Batch_idx: 140 |  Loss: (0.8728) |  Loss2: (0.0000) | Acc: (68.00%) (12404/18048)
Epoch: 14 | Batch_idx: 150 |  Loss: (0.8704) |  Loss2: (0.0000) | Acc: (68.00%) (13292/19328)
Epoch: 14 | Batch_idx: 160 |  Loss: (0.8701) |  Loss2: (0.0000) | Acc: (68.00%) (14186/20608)
Epoch: 14 | Batch_idx: 170 |  Loss: (0.8707) |  Loss2: (0.0000) | Acc: (68.00%) (15075/21888)
Epoch: 14 | Batch_idx: 180 |  Loss: (0.8736) |  Loss2: (0.0000) | Acc: (68.00%) (15954/23168)
Epoch: 14 | Batch_idx: 190 |  Loss: (0.8724) |  Loss2: (0.0000) | Acc: (68.00%) (16845/24448)
Epoch: 14 | Batch_idx: 200 |  Loss: (0.8747) |  Loss2: (0.0000) | Acc: (68.00%) (17700/25728)
Epoch: 14 | Batch_idx: 210 |  Loss: (0.8734) |  Loss2: (0.0000) | Acc: (68.00%) (18600/27008)
Epoch: 14 | Batch_idx: 220 |  Loss: (0.8728) |  Loss2: (0.0000) | Acc: (68.00%) (19498/28288)
Epoch: 14 | Batch_idx: 230 |  Loss: (0.8724) |  Loss2: (0.0000) | Acc: (68.00%) (20395/29568)
Epoch: 14 | Batch_idx: 240 |  Loss: (0.8743) |  Loss2: (0.0000) | Acc: (68.00%) (21258/30848)
Epoch: 14 | Batch_idx: 250 |  Loss: (0.8737) |  Loss2: (0.0000) | Acc: (68.00%) (22144/32128)
Epoch: 14 | Batch_idx: 260 |  Loss: (0.8739) |  Loss2: (0.0000) | Acc: (68.00%) (23009/33408)
Epoch: 14 | Batch_idx: 270 |  Loss: (0.8740) |  Loss2: (0.0000) | Acc: (68.00%) (23873/34688)
Epoch: 14 | Batch_idx: 280 |  Loss: (0.8749) |  Loss2: (0.0000) | Acc: (68.00%) (24762/35968)
Epoch: 14 | Batch_idx: 290 |  Loss: (0.8760) |  Loss2: (0.0000) | Acc: (68.00%) (25609/37248)
Epoch: 14 | Batch_idx: 300 |  Loss: (0.8767) |  Loss2: (0.0000) | Acc: (68.00%) (26477/38528)
Epoch: 14 | Batch_idx: 310 |  Loss: (0.8778) |  Loss2: (0.0000) | Acc: (68.00%) (27321/39808)
Epoch: 14 | Batch_idx: 320 |  Loss: (0.8787) |  Loss2: (0.0000) | Acc: (68.00%) (28191/41088)
Epoch: 14 | Batch_idx: 330 |  Loss: (0.8786) |  Loss2: (0.0000) | Acc: (68.00%) (29077/42368)
Epoch: 14 | Batch_idx: 340 |  Loss: (0.8795) |  Loss2: (0.0000) | Acc: (68.00%) (29930/43648)
Epoch: 14 | Batch_idx: 350 |  Loss: (0.8795) |  Loss2: (0.0000) | Acc: (68.00%) (30814/44928)
Epoch: 14 | Batch_idx: 360 |  Loss: (0.8801) |  Loss2: (0.0000) | Acc: (68.00%) (31683/46208)
Epoch: 14 | Batch_idx: 370 |  Loss: (0.8797) |  Loss2: (0.0000) | Acc: (68.00%) (32575/47488)
Epoch: 14 | Batch_idx: 380 |  Loss: (0.8794) |  Loss2: (0.0000) | Acc: (68.00%) (33457/48768)
Epoch: 14 | Batch_idx: 390 |  Loss: (0.8797) |  Loss2: (0.0000) | Acc: (68.00%) (34299/50000)
# TEST : Loss: (0.9013) | Acc: (68.00%) (6873/10000)
percent tensor([0.4965, 0.4927, 0.4832, 0.4887, 0.4864, 0.5002, 0.4907, 0.4865, 0.4928,
        0.4896, 0.4964, 0.4838, 0.4929, 0.4954, 0.4952, 0.4948],
       device='cuda:0') torch.Size([16])
percent tensor([0.5017, 0.4982, 0.5010, 0.5024, 0.4994, 0.5033, 0.4981, 0.5012, 0.4998,
        0.4969, 0.4997, 0.4973, 0.4980, 0.5016, 0.5000, 0.5014],
       device='cuda:0') torch.Size([16])
percent tensor([0.5147, 0.5109, 0.5069, 0.5136, 0.5050, 0.5265, 0.5097, 0.5096, 0.5082,
        0.5084, 0.5107, 0.5067, 0.5107, 0.5164, 0.5133, 0.5162],
       device='cuda:0') torch.Size([16])
percent tensor([0.5157, 0.5199, 0.5145, 0.5144, 0.5155, 0.5168, 0.5211, 0.5159, 0.5185,
        0.5191, 0.5200, 0.5167, 0.5171, 0.5239, 0.5152, 0.5186],
       device='cuda:0') torch.Size([16])
percent tensor([0.4928, 0.4941, 0.4429, 0.4385, 0.4584, 0.4863, 0.4941, 0.4528, 0.4888,
        0.4929, 0.4950, 0.4677, 0.4919, 0.4930, 0.4898, 0.4954],
       device='cuda:0') torch.Size([16])
percent tensor([0.5045, 0.5049, 0.5002, 0.5026, 0.5026, 0.5067, 0.5032, 0.5039, 0.5025,
        0.5044, 0.5028, 0.5011, 0.5036, 0.5051, 0.5048, 0.5058],
       device='cuda:0') torch.Size([16])
percent tensor([0.5056, 0.5151, 0.5143, 0.5113, 0.5171, 0.5126, 0.5058, 0.5192, 0.5128,
        0.5120, 0.5150, 0.5158, 0.5176, 0.5099, 0.5101, 0.5051],
       device='cuda:0') torch.Size([16])
percent tensor([0.7378, 0.6985, 0.7313, 0.7256, 0.7359, 0.7809, 0.6921, 0.7796, 0.7269,
        0.7671, 0.7728, 0.7072, 0.7681, 0.7169, 0.7195, 0.7627],
       device='cuda:0') torch.Size([16])
Epoch: 15 | Batch_idx: 0 |  Loss: (0.9243) |  Loss2: (0.0000) | Acc: (64.00%) (82/128)
Epoch: 15 | Batch_idx: 10 |  Loss: (0.9023) |  Loss2: (0.0000) | Acc: (66.00%) (940/1408)
Epoch: 15 | Batch_idx: 20 |  Loss: (0.8675) |  Loss2: (0.0000) | Acc: (68.00%) (1845/2688)
Epoch: 15 | Batch_idx: 30 |  Loss: (0.8811) |  Loss2: (0.0000) | Acc: (68.00%) (2706/3968)
Epoch: 15 | Batch_idx: 40 |  Loss: (0.8767) |  Loss2: (0.0000) | Acc: (68.00%) (3613/5248)
Epoch: 15 | Batch_idx: 50 |  Loss: (0.8830) |  Loss2: (0.0000) | Acc: (68.00%) (4479/6528)
Epoch: 15 | Batch_idx: 60 |  Loss: (0.8799) |  Loss2: (0.0000) | Acc: (68.00%) (5363/7808)
Epoch: 15 | Batch_idx: 70 |  Loss: (0.8823) |  Loss2: (0.0000) | Acc: (68.00%) (6222/9088)
Epoch: 15 | Batch_idx: 80 |  Loss: (0.8746) |  Loss2: (0.0000) | Acc: (68.00%) (7127/10368)
Epoch: 15 | Batch_idx: 90 |  Loss: (0.8751) |  Loss2: (0.0000) | Acc: (68.00%) (8011/11648)
Epoch: 15 | Batch_idx: 100 |  Loss: (0.8770) |  Loss2: (0.0000) | Acc: (68.00%) (8891/12928)
Epoch: 15 | Batch_idx: 110 |  Loss: (0.8783) |  Loss2: (0.0000) | Acc: (68.00%) (9755/14208)
Epoch: 15 | Batch_idx: 120 |  Loss: (0.8743) |  Loss2: (0.0000) | Acc: (68.00%) (10670/15488)
Epoch: 15 | Batch_idx: 130 |  Loss: (0.8740) |  Loss2: (0.0000) | Acc: (68.00%) (11562/16768)
Epoch: 15 | Batch_idx: 140 |  Loss: (0.8727) |  Loss2: (0.0000) | Acc: (68.00%) (12431/18048)
Epoch: 15 | Batch_idx: 150 |  Loss: (0.8724) |  Loss2: (0.0000) | Acc: (68.00%) (13317/19328)
Epoch: 15 | Batch_idx: 160 |  Loss: (0.8738) |  Loss2: (0.0000) | Acc: (68.00%) (14193/20608)
Epoch: 15 | Batch_idx: 170 |  Loss: (0.8754) |  Loss2: (0.0000) | Acc: (68.00%) (15073/21888)
Epoch: 15 | Batch_idx: 180 |  Loss: (0.8748) |  Loss2: (0.0000) | Acc: (68.00%) (15980/23168)
Epoch: 15 | Batch_idx: 190 |  Loss: (0.8760) |  Loss2: (0.0000) | Acc: (68.00%) (16830/24448)
Epoch: 15 | Batch_idx: 200 |  Loss: (0.8770) |  Loss2: (0.0000) | Acc: (68.00%) (17698/25728)
Epoch: 15 | Batch_idx: 210 |  Loss: (0.8769) |  Loss2: (0.0000) | Acc: (68.00%) (18589/27008)
Epoch: 15 | Batch_idx: 220 |  Loss: (0.8770) |  Loss2: (0.0000) | Acc: (68.00%) (19469/28288)
Epoch: 15 | Batch_idx: 230 |  Loss: (0.8784) |  Loss2: (0.0000) | Acc: (68.00%) (20350/29568)
Epoch: 15 | Batch_idx: 240 |  Loss: (0.8759) |  Loss2: (0.0000) | Acc: (68.00%) (21251/30848)
Epoch: 15 | Batch_idx: 250 |  Loss: (0.8752) |  Loss2: (0.0000) | Acc: (68.00%) (22148/32128)
Epoch: 15 | Batch_idx: 260 |  Loss: (0.8749) |  Loss2: (0.0000) | Acc: (68.00%) (23023/33408)
Epoch: 15 | Batch_idx: 270 |  Loss: (0.8737) |  Loss2: (0.0000) | Acc: (68.00%) (23929/34688)
Epoch: 15 | Batch_idx: 280 |  Loss: (0.8745) |  Loss2: (0.0000) | Acc: (68.00%) (24800/35968)
Epoch: 15 | Batch_idx: 290 |  Loss: (0.8747) |  Loss2: (0.0000) | Acc: (68.00%) (25667/37248)
Epoch: 15 | Batch_idx: 300 |  Loss: (0.8740) |  Loss2: (0.0000) | Acc: (68.00%) (26550/38528)
Epoch: 15 | Batch_idx: 310 |  Loss: (0.8739) |  Loss2: (0.0000) | Acc: (68.00%) (27448/39808)
Epoch: 15 | Batch_idx: 320 |  Loss: (0.8738) |  Loss2: (0.0000) | Acc: (68.00%) (28324/41088)
Epoch: 15 | Batch_idx: 330 |  Loss: (0.8743) |  Loss2: (0.0000) | Acc: (68.00%) (29213/42368)
Epoch: 15 | Batch_idx: 340 |  Loss: (0.8735) |  Loss2: (0.0000) | Acc: (69.00%) (30132/43648)
Epoch: 15 | Batch_idx: 350 |  Loss: (0.8733) |  Loss2: (0.0000) | Acc: (69.00%) (31019/44928)
Epoch: 15 | Batch_idx: 360 |  Loss: (0.8712) |  Loss2: (0.0000) | Acc: (69.00%) (31947/46208)
Epoch: 15 | Batch_idx: 370 |  Loss: (0.8720) |  Loss2: (0.0000) | Acc: (69.00%) (32808/47488)
Epoch: 15 | Batch_idx: 380 |  Loss: (0.8724) |  Loss2: (0.0000) | Acc: (69.00%) (33669/48768)
Epoch: 15 | Batch_idx: 390 |  Loss: (0.8747) |  Loss2: (0.0000) | Acc: (68.00%) (34491/50000)
=> saving checkpoint 'drive/app/torch/save_Schedule/checkpoint_015.pth.tar'
# TEST : Loss: (0.8997) | Acc: (68.00%) (6892/10000)
percent tensor([0.4962, 0.4924, 0.4822, 0.4884, 0.4854, 0.5004, 0.4901, 0.4859, 0.4922,
        0.4890, 0.4962, 0.4827, 0.4924, 0.4951, 0.4951, 0.4948],
       device='cuda:0') torch.Size([16])
percent tensor([0.5025, 0.4988, 0.5015, 0.5033, 0.4999, 0.5044, 0.4986, 0.5021, 0.5004,
        0.4973, 0.5003, 0.4975, 0.4985, 0.5025, 0.5008, 0.5023],
       device='cuda:0') torch.Size([16])
percent tensor([0.5149, 0.5116, 0.5071, 0.5140, 0.5047, 0.5267, 0.5102, 0.5099, 0.5084,
        0.5090, 0.5110, 0.5072, 0.5113, 0.5177, 0.5130, 0.5172],
       device='cuda:0') torch.Size([16])
percent tensor([0.5184, 0.5229, 0.5172, 0.5176, 0.5187, 0.5196, 0.5246, 0.5192, 0.5217,
        0.5220, 0.5230, 0.5194, 0.5195, 0.5280, 0.5177, 0.5217],
       device='cuda:0') torch.Size([16])
percent tensor([0.4936, 0.4945, 0.4465, 0.4427, 0.4639, 0.4875, 0.4975, 0.4581, 0.4895,
        0.4939, 0.4952, 0.4694, 0.4907, 0.4933, 0.4923, 0.4975],
       device='cuda:0') torch.Size([16])
percent tensor([0.5038, 0.5040, 0.4994, 0.5026, 0.5022, 0.5065, 0.5026, 0.5036, 0.5016,
        0.5032, 0.5014, 0.4999, 0.5025, 0.5045, 0.5042, 0.5056],
       device='cuda:0') torch.Size([16])
percent tensor([0.5026, 0.5147, 0.5143, 0.5111, 0.5176, 0.5096, 0.5047, 0.5191, 0.5122,
        0.5111, 0.5139, 0.5153, 0.5156, 0.5085, 0.5088, 0.5024],
       device='cuda:0') torch.Size([16])
percent tensor([0.7472, 0.7132, 0.7480, 0.7427, 0.7541, 0.7931, 0.7019, 0.7979, 0.7393,
        0.7836, 0.7882, 0.7222, 0.7798, 0.7285, 0.7339, 0.7680],
       device='cuda:0') torch.Size([16])
Epoch: 16 | Batch_idx: 0 |  Loss: (0.7905) |  Loss2: (0.0000) | Acc: (71.00%) (92/128)
Epoch: 16 | Batch_idx: 10 |  Loss: (0.8418) |  Loss2: (0.0000) | Acc: (69.00%) (977/1408)
Epoch: 16 | Batch_idx: 20 |  Loss: (0.8554) |  Loss2: (0.0000) | Acc: (68.00%) (1854/2688)
Epoch: 16 | Batch_idx: 30 |  Loss: (0.8631) |  Loss2: (0.0000) | Acc: (68.00%) (2726/3968)
Epoch: 16 | Batch_idx: 40 |  Loss: (0.8632) |  Loss2: (0.0000) | Acc: (68.00%) (3609/5248)
Epoch: 16 | Batch_idx: 50 |  Loss: (0.8620) |  Loss2: (0.0000) | Acc: (68.00%) (4484/6528)
Epoch: 16 | Batch_idx: 60 |  Loss: (0.8598) |  Loss2: (0.0000) | Acc: (68.00%) (5377/7808)
Epoch: 16 | Batch_idx: 70 |  Loss: (0.8714) |  Loss2: (0.0000) | Acc: (68.00%) (6238/9088)
Epoch: 16 | Batch_idx: 80 |  Loss: (0.8656) |  Loss2: (0.0000) | Acc: (68.00%) (7127/10368)
Epoch: 16 | Batch_idx: 90 |  Loss: (0.8652) |  Loss2: (0.0000) | Acc: (68.00%) (8008/11648)
Epoch: 16 | Batch_idx: 100 |  Loss: (0.8659) |  Loss2: (0.0000) | Acc: (68.00%) (8898/12928)
Epoch: 16 | Batch_idx: 110 |  Loss: (0.8621) |  Loss2: (0.0000) | Acc: (69.00%) (9807/14208)
Epoch: 16 | Batch_idx: 120 |  Loss: (0.8617) |  Loss2: (0.0000) | Acc: (69.00%) (10709/15488)
Epoch: 16 | Batch_idx: 130 |  Loss: (0.8671) |  Loss2: (0.0000) | Acc: (69.00%) (11575/16768)
Epoch: 16 | Batch_idx: 140 |  Loss: (0.8687) |  Loss2: (0.0000) | Acc: (69.00%) (12455/18048)
Epoch: 16 | Batch_idx: 150 |  Loss: (0.8700) |  Loss2: (0.0000) | Acc: (68.00%) (13327/19328)
Epoch: 16 | Batch_idx: 160 |  Loss: (0.8694) |  Loss2: (0.0000) | Acc: (69.00%) (14222/20608)
Epoch: 16 | Batch_idx: 170 |  Loss: (0.8701) |  Loss2: (0.0000) | Acc: (69.00%) (15117/21888)
Epoch: 16 | Batch_idx: 180 |  Loss: (0.8713) |  Loss2: (0.0000) | Acc: (69.00%) (15992/23168)
Epoch: 16 | Batch_idx: 190 |  Loss: (0.8707) |  Loss2: (0.0000) | Acc: (69.00%) (16887/24448)
Epoch: 16 | Batch_idx: 200 |  Loss: (0.8694) |  Loss2: (0.0000) | Acc: (69.00%) (17789/25728)
Epoch: 16 | Batch_idx: 210 |  Loss: (0.8704) |  Loss2: (0.0000) | Acc: (69.00%) (18678/27008)
Epoch: 16 | Batch_idx: 220 |  Loss: (0.8691) |  Loss2: (0.0000) | Acc: (69.00%) (19561/28288)
Epoch: 16 | Batch_idx: 230 |  Loss: (0.8704) |  Loss2: (0.0000) | Acc: (69.00%) (20429/29568)
Epoch: 16 | Batch_idx: 240 |  Loss: (0.8702) |  Loss2: (0.0000) | Acc: (69.00%) (21317/30848)
Epoch: 16 | Batch_idx: 250 |  Loss: (0.8697) |  Loss2: (0.0000) | Acc: (69.00%) (22211/32128)
Epoch: 16 | Batch_idx: 260 |  Loss: (0.8701) |  Loss2: (0.0000) | Acc: (69.00%) (23092/33408)
Epoch: 16 | Batch_idx: 270 |  Loss: (0.8699) |  Loss2: (0.0000) | Acc: (69.00%) (23972/34688)
Epoch: 16 | Batch_idx: 280 |  Loss: (0.8701) |  Loss2: (0.0000) | Acc: (69.00%) (24850/35968)
Epoch: 16 | Batch_idx: 290 |  Loss: (0.8712) |  Loss2: (0.0000) | Acc: (69.00%) (25718/37248)
Epoch: 16 | Batch_idx: 300 |  Loss: (0.8723) |  Loss2: (0.0000) | Acc: (69.00%) (26604/38528)
Epoch: 16 | Batch_idx: 310 |  Loss: (0.8731) |  Loss2: (0.0000) | Acc: (69.00%) (27473/39808)
Epoch: 16 | Batch_idx: 320 |  Loss: (0.8727) |  Loss2: (0.0000) | Acc: (69.00%) (28366/41088)
Epoch: 16 | Batch_idx: 330 |  Loss: (0.8728) |  Loss2: (0.0000) | Acc: (69.00%) (29257/42368)
Epoch: 16 | Batch_idx: 340 |  Loss: (0.8725) |  Loss2: (0.0000) | Acc: (69.00%) (30142/43648)
Epoch: 16 | Batch_idx: 350 |  Loss: (0.8719) |  Loss2: (0.0000) | Acc: (69.00%) (31038/44928)
Epoch: 16 | Batch_idx: 360 |  Loss: (0.8711) |  Loss2: (0.0000) | Acc: (69.00%) (31921/46208)
Epoch: 16 | Batch_idx: 370 |  Loss: (0.8737) |  Loss2: (0.0000) | Acc: (69.00%) (32776/47488)
Epoch: 16 | Batch_idx: 380 |  Loss: (0.8726) |  Loss2: (0.0000) | Acc: (69.00%) (33686/48768)
Epoch: 16 | Batch_idx: 390 |  Loss: (0.8722) |  Loss2: (0.0000) | Acc: (69.00%) (34541/50000)
# TEST : Loss: (0.8876) | Acc: (68.00%) (6899/10000)
percent tensor([0.4978, 0.4942, 0.4839, 0.4902, 0.4871, 0.5023, 0.4920, 0.4879, 0.4939,
        0.4908, 0.4981, 0.4845, 0.4938, 0.4969, 0.4971, 0.4967],
       device='cuda:0') torch.Size([16])
percent tensor([0.5040, 0.5003, 0.5028, 0.5047, 0.5012, 0.5060, 0.4999, 0.5038, 0.5018,
        0.4986, 0.5018, 0.4985, 0.4997, 0.5043, 0.5023, 0.5040],
       device='cuda:0') torch.Size([16])
percent tensor([0.5165, 0.5141, 0.5082, 0.5147, 0.5051, 0.5277, 0.5123, 0.5108, 0.5102,
        0.5114, 0.5135, 0.5093, 0.5136, 0.5206, 0.5138, 0.5198],
       device='cuda:0') torch.Size([16])
percent tensor([0.5204, 0.5254, 0.5199, 0.5205, 0.5216, 0.5216, 0.5276, 0.5223, 0.5244,
        0.5246, 0.5255, 0.5216, 0.5215, 0.5314, 0.5195, 0.5242],
       device='cuda:0') torch.Size([16])
percent tensor([0.4922, 0.4931, 0.4436, 0.4394, 0.4626, 0.4859, 0.4972, 0.4566, 0.4882,
        0.4928, 0.4940, 0.4663, 0.4885, 0.4924, 0.4911, 0.4973],
       device='cuda:0') torch.Size([16])
percent tensor([0.5022, 0.5026, 0.4978, 0.5013, 0.5009, 0.5053, 0.5015, 0.5026, 0.5003,
        0.5014, 0.4996, 0.4981, 0.5009, 0.5034, 0.5029, 0.5044],
       device='cuda:0') torch.Size([16])
percent tensor([0.4994, 0.5149, 0.5148, 0.5112, 0.5185, 0.5055, 0.5043, 0.5196, 0.5120,
        0.5111, 0.5140, 0.5150, 0.5143, 0.5074, 0.5076, 0.4991],
       device='cuda:0') torch.Size([16])
percent tensor([0.7439, 0.7159, 0.7545, 0.7490, 0.7576, 0.7979, 0.6998, 0.7982, 0.7400,
        0.7835, 0.7915, 0.7225, 0.7790, 0.7272, 0.7290, 0.7597],
       device='cuda:0') torch.Size([16])
Epoch: 17 | Batch_idx: 0 |  Loss: (0.9261) |  Loss2: (0.0000) | Acc: (67.00%) (87/128)
Epoch: 17 | Batch_idx: 10 |  Loss: (0.8620) |  Loss2: (0.0000) | Acc: (69.00%) (975/1408)
Epoch: 17 | Batch_idx: 20 |  Loss: (0.8645) |  Loss2: (0.0000) | Acc: (68.00%) (1840/2688)
Epoch: 17 | Batch_idx: 30 |  Loss: (0.8704) |  Loss2: (0.0000) | Acc: (68.00%) (2724/3968)
Epoch: 17 | Batch_idx: 40 |  Loss: (0.8694) |  Loss2: (0.0000) | Acc: (68.00%) (3615/5248)
Epoch: 17 | Batch_idx: 50 |  Loss: (0.8655) |  Loss2: (0.0000) | Acc: (68.00%) (4483/6528)
Epoch: 17 | Batch_idx: 60 |  Loss: (0.8680) |  Loss2: (0.0000) | Acc: (68.00%) (5352/7808)
Epoch: 17 | Batch_idx: 70 |  Loss: (0.8581) |  Loss2: (0.0000) | Acc: (68.00%) (6270/9088)
Epoch: 17 | Batch_idx: 80 |  Loss: (0.8590) |  Loss2: (0.0000) | Acc: (69.00%) (7156/10368)
Epoch: 17 | Batch_idx: 90 |  Loss: (0.8578) |  Loss2: (0.0000) | Acc: (69.00%) (8063/11648)
Epoch: 17 | Batch_idx: 100 |  Loss: (0.8581) |  Loss2: (0.0000) | Acc: (69.00%) (8937/12928)
Epoch: 17 | Batch_idx: 110 |  Loss: (0.8596) |  Loss2: (0.0000) | Acc: (69.00%) (9813/14208)
Epoch: 17 | Batch_idx: 120 |  Loss: (0.8568) |  Loss2: (0.0000) | Acc: (69.00%) (10709/15488)
Epoch: 17 | Batch_idx: 130 |  Loss: (0.8594) |  Loss2: (0.0000) | Acc: (69.00%) (11574/16768)
Epoch: 17 | Batch_idx: 140 |  Loss: (0.8617) |  Loss2: (0.0000) | Acc: (69.00%) (12465/18048)
Epoch: 17 | Batch_idx: 150 |  Loss: (0.8611) |  Loss2: (0.0000) | Acc: (69.00%) (13358/19328)
Epoch: 17 | Batch_idx: 160 |  Loss: (0.8604) |  Loss2: (0.0000) | Acc: (69.00%) (14248/20608)
Epoch: 17 | Batch_idx: 170 |  Loss: (0.8617) |  Loss2: (0.0000) | Acc: (69.00%) (15124/21888)
Epoch: 17 | Batch_idx: 180 |  Loss: (0.8591) |  Loss2: (0.0000) | Acc: (69.00%) (16036/23168)
Epoch: 17 | Batch_idx: 190 |  Loss: (0.8605) |  Loss2: (0.0000) | Acc: (69.00%) (16919/24448)
Epoch: 17 | Batch_idx: 200 |  Loss: (0.8603) |  Loss2: (0.0000) | Acc: (69.00%) (17789/25728)
Epoch: 17 | Batch_idx: 210 |  Loss: (0.8601) |  Loss2: (0.0000) | Acc: (69.00%) (18675/27008)
Epoch: 17 | Batch_idx: 220 |  Loss: (0.8600) |  Loss2: (0.0000) | Acc: (69.00%) (19562/28288)
Epoch: 17 | Batch_idx: 230 |  Loss: (0.8586) |  Loss2: (0.0000) | Acc: (69.00%) (20457/29568)
Epoch: 17 | Batch_idx: 240 |  Loss: (0.8599) |  Loss2: (0.0000) | Acc: (69.00%) (21321/30848)
Epoch: 17 | Batch_idx: 250 |  Loss: (0.8592) |  Loss2: (0.0000) | Acc: (69.00%) (22230/32128)
Epoch: 17 | Batch_idx: 260 |  Loss: (0.8597) |  Loss2: (0.0000) | Acc: (69.00%) (23112/33408)
Epoch: 17 | Batch_idx: 270 |  Loss: (0.8606) |  Loss2: (0.0000) | Acc: (69.00%) (23970/34688)
Epoch: 17 | Batch_idx: 280 |  Loss: (0.8608) |  Loss2: (0.0000) | Acc: (69.00%) (24852/35968)
Epoch: 17 | Batch_idx: 290 |  Loss: (0.8608) |  Loss2: (0.0000) | Acc: (69.00%) (25746/37248)
Epoch: 17 | Batch_idx: 300 |  Loss: (0.8612) |  Loss2: (0.0000) | Acc: (69.00%) (26639/38528)
Epoch: 17 | Batch_idx: 310 |  Loss: (0.8624) |  Loss2: (0.0000) | Acc: (69.00%) (27495/39808)
Epoch: 17 | Batch_idx: 320 |  Loss: (0.8619) |  Loss2: (0.0000) | Acc: (69.00%) (28398/41088)
Epoch: 17 | Batch_idx: 330 |  Loss: (0.8627) |  Loss2: (0.0000) | Acc: (69.00%) (29272/42368)
Epoch: 17 | Batch_idx: 340 |  Loss: (0.8629) |  Loss2: (0.0000) | Acc: (69.00%) (30127/43648)
Epoch: 17 | Batch_idx: 350 |  Loss: (0.8640) |  Loss2: (0.0000) | Acc: (68.00%) (30991/44928)
Epoch: 17 | Batch_idx: 360 |  Loss: (0.8634) |  Loss2: (0.0000) | Acc: (69.00%) (31884/46208)
Epoch: 17 | Batch_idx: 370 |  Loss: (0.8640) |  Loss2: (0.0000) | Acc: (68.00%) (32755/47488)
Epoch: 17 | Batch_idx: 380 |  Loss: (0.8647) |  Loss2: (0.0000) | Acc: (68.00%) (33630/48768)
Epoch: 17 | Batch_idx: 390 |  Loss: (0.8656) |  Loss2: (0.0000) | Acc: (68.00%) (34462/50000)
# TEST : Loss: (0.8923) | Acc: (69.00%) (6903/10000)
percent tensor([0.4979, 0.4943, 0.4832, 0.4901, 0.4865, 0.5028, 0.4918, 0.4876, 0.4936,
        0.4906, 0.4983, 0.4838, 0.4937, 0.4971, 0.4974, 0.4970],
       device='cuda:0') torch.Size([16])
percent tensor([0.5055, 0.5017, 0.5042, 0.5062, 0.5024, 0.5079, 0.5012, 0.5056, 0.5032,
        0.4998, 0.5033, 0.4995, 0.5009, 0.5060, 0.5038, 0.5057],
       device='cuda:0') torch.Size([16])
percent tensor([0.5168, 0.5143, 0.5082, 0.5143, 0.5045, 0.5278, 0.5123, 0.5107, 0.5103,
        0.5114, 0.5141, 0.5094, 0.5140, 0.5216, 0.5132, 0.5207],
       device='cuda:0') torch.Size([16])
percent tensor([0.5220, 0.5273, 0.5217, 0.5226, 0.5236, 0.5233, 0.5299, 0.5245, 0.5266,
        0.5264, 0.5275, 0.5228, 0.5230, 0.5344, 0.5207, 0.5262],
       device='cuda:0') torch.Size([16])
percent tensor([0.4941, 0.4931, 0.4408, 0.4380, 0.4619, 0.4877, 0.4977, 0.4560, 0.4880,
        0.4925, 0.4949, 0.4634, 0.4889, 0.4931, 0.4920, 0.4993],
       device='cuda:0') torch.Size([16])
percent tensor([0.5005, 0.5005, 0.4960, 0.5003, 0.4995, 0.5045, 0.4997, 0.5011, 0.4985,
        0.4989, 0.4973, 0.4956, 0.4986, 0.5019, 0.5010, 0.5030],
       device='cuda:0') torch.Size([16])
percent tensor([0.4968, 0.5149, 0.5156, 0.5124, 0.5198, 0.5033, 0.5041, 0.5208, 0.5122,
        0.5111, 0.5138, 0.5149, 0.5132, 0.5067, 0.5072, 0.4969],
       device='cuda:0') torch.Size([16])
percent tensor([0.7510, 0.7252, 0.7690, 0.7625, 0.7686, 0.8068, 0.7103, 0.8138, 0.7486,
        0.7949, 0.8042, 0.7298, 0.7882, 0.7377, 0.7413, 0.7651],
       device='cuda:0') torch.Size([16])
True Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=128, out_features=16, bias=False)
False Linear(in_features=16, out_features=2, bias=False)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=128, out_features=16, bias=False)
False Linear(in_features=16, out_features=2, bias=False)
True Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=256, out_features=32, bias=False)
False Linear(in_features=32, out_features=2, bias=False)
True Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=256, out_features=32, bias=False)
False Linear(in_features=32, out_features=2, bias=False)
True Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=512, out_features=64, bias=False)
False Linear(in_features=64, out_features=2, bias=False)
True Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=512, out_features=64, bias=False)
False Linear(in_features=64, out_features=2, bias=False)
True Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1024, out_features=128, bias=False)
False Linear(in_features=128, out_features=2, bias=False)
True Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1024, out_features=128, bias=False)
False Linear(in_features=128, out_features=2, bias=False)
True Linear(in_features=512, out_features=10, bias=True)
Epoch: 18 | Batch_idx: 0 |  Loss: (1.0133) |  Loss2: (0.0000) | Acc: (61.00%) (79/128)
Epoch: 18 | Batch_idx: 10 |  Loss: (0.8919) |  Loss2: (0.0000) | Acc: (67.00%) (948/1408)
Epoch: 18 | Batch_idx: 20 |  Loss: (0.8905) |  Loss2: (0.0000) | Acc: (67.00%) (1806/2688)
Epoch: 18 | Batch_idx: 30 |  Loss: (0.8966) |  Loss2: (0.0000) | Acc: (67.00%) (2672/3968)
Epoch: 18 | Batch_idx: 40 |  Loss: (0.9028) |  Loss2: (0.0000) | Acc: (67.00%) (3541/5248)
Epoch: 18 | Batch_idx: 50 |  Loss: (0.9024) |  Loss2: (0.0000) | Acc: (67.00%) (4414/6528)
Epoch: 18 | Batch_idx: 60 |  Loss: (0.9005) |  Loss2: (0.0000) | Acc: (67.00%) (5286/7808)
Epoch: 18 | Batch_idx: 70 |  Loss: (0.8985) |  Loss2: (0.0000) | Acc: (67.00%) (6161/9088)
Epoch: 18 | Batch_idx: 80 |  Loss: (0.9011) |  Loss2: (0.0000) | Acc: (67.00%) (7003/10368)
Epoch: 18 | Batch_idx: 90 |  Loss: (0.9020) |  Loss2: (0.0000) | Acc: (67.00%) (7855/11648)
Epoch: 18 | Batch_idx: 100 |  Loss: (0.9057) |  Loss2: (0.0000) | Acc: (67.00%) (8709/12928)
Epoch: 18 | Batch_idx: 110 |  Loss: (0.9007) |  Loss2: (0.0000) | Acc: (67.00%) (9605/14208)
Epoch: 18 | Batch_idx: 120 |  Loss: (0.9035) |  Loss2: (0.0000) | Acc: (67.00%) (10470/15488)
Epoch: 18 | Batch_idx: 130 |  Loss: (0.9017) |  Loss2: (0.0000) | Acc: (67.00%) (11336/16768)
Epoch: 18 | Batch_idx: 140 |  Loss: (0.8971) |  Loss2: (0.0000) | Acc: (67.00%) (12228/18048)
Epoch: 18 | Batch_idx: 150 |  Loss: (0.8948) |  Loss2: (0.0000) | Acc: (67.00%) (13102/19328)
Epoch: 18 | Batch_idx: 160 |  Loss: (0.8961) |  Loss2: (0.0000) | Acc: (67.00%) (13987/20608)
Epoch: 18 | Batch_idx: 170 |  Loss: (0.8946) |  Loss2: (0.0000) | Acc: (67.00%) (14867/21888)
Epoch: 18 | Batch_idx: 180 |  Loss: (0.8921) |  Loss2: (0.0000) | Acc: (67.00%) (15735/23168)
Epoch: 18 | Batch_idx: 190 |  Loss: (0.8901) |  Loss2: (0.0000) | Acc: (67.00%) (16620/24448)
Epoch: 18 | Batch_idx: 200 |  Loss: (0.8869) |  Loss2: (0.0000) | Acc: (68.00%) (17522/25728)
Epoch: 18 | Batch_idx: 210 |  Loss: (0.8853) |  Loss2: (0.0000) | Acc: (68.00%) (18417/27008)
Epoch: 18 | Batch_idx: 220 |  Loss: (0.8841) |  Loss2: (0.0000) | Acc: (68.00%) (19289/28288)
Epoch: 18 | Batch_idx: 230 |  Loss: (0.8847) |  Loss2: (0.0000) | Acc: (68.00%) (20157/29568)
Epoch: 18 | Batch_idx: 240 |  Loss: (0.8836) |  Loss2: (0.0000) | Acc: (68.00%) (21040/30848)
Epoch: 18 | Batch_idx: 250 |  Loss: (0.8814) |  Loss2: (0.0000) | Acc: (68.00%) (21946/32128)
Epoch: 18 | Batch_idx: 260 |  Loss: (0.8826) |  Loss2: (0.0000) | Acc: (68.00%) (22810/33408)
Epoch: 18 | Batch_idx: 270 |  Loss: (0.8811) |  Loss2: (0.0000) | Acc: (68.00%) (23704/34688)
Epoch: 18 | Batch_idx: 280 |  Loss: (0.8810) |  Loss2: (0.0000) | Acc: (68.00%) (24575/35968)
Epoch: 18 | Batch_idx: 290 |  Loss: (0.8799) |  Loss2: (0.0000) | Acc: (68.00%) (25457/37248)
Epoch: 18 | Batch_idx: 300 |  Loss: (0.8783) |  Loss2: (0.0000) | Acc: (68.00%) (26353/38528)
Epoch: 18 | Batch_idx: 310 |  Loss: (0.8779) |  Loss2: (0.0000) | Acc: (68.00%) (27246/39808)
Epoch: 18 | Batch_idx: 320 |  Loss: (0.8773) |  Loss2: (0.0000) | Acc: (68.00%) (28118/41088)
Epoch: 18 | Batch_idx: 330 |  Loss: (0.8763) |  Loss2: (0.0000) | Acc: (68.00%) (29008/42368)
Epoch: 18 | Batch_idx: 340 |  Loss: (0.8750) |  Loss2: (0.0000) | Acc: (68.00%) (29909/43648)
Epoch: 18 | Batch_idx: 350 |  Loss: (0.8741) |  Loss2: (0.0000) | Acc: (68.00%) (30782/44928)
Epoch: 18 | Batch_idx: 360 |  Loss: (0.8716) |  Loss2: (0.0000) | Acc: (68.00%) (31698/46208)
Epoch: 18 | Batch_idx: 370 |  Loss: (0.8718) |  Loss2: (0.0000) | Acc: (68.00%) (32580/47488)
Epoch: 18 | Batch_idx: 380 |  Loss: (0.8723) |  Loss2: (0.0000) | Acc: (68.00%) (33460/48768)
Epoch: 18 | Batch_idx: 390 |  Loss: (0.8722) |  Loss2: (0.0000) | Acc: (68.00%) (34295/50000)
# TEST : Loss: (0.9845) | Acc: (66.00%) (6686/10000)
percent tensor([0.4982, 0.4935, 0.4859, 0.4905, 0.4886, 0.5037, 0.4922, 0.4885, 0.4940,
        0.4909, 0.4981, 0.4861, 0.4936, 0.4960, 0.4969, 0.4968],
       device='cuda:0') torch.Size([16])
percent tensor([0.5045, 0.5008, 0.5031, 0.5047, 0.5022, 0.5073, 0.5014, 0.5048, 0.5030,
        0.4998, 0.5031, 0.4995, 0.5002, 0.5059, 0.5029, 0.5053],
       device='cuda:0') torch.Size([16])
percent tensor([0.5164, 0.5138, 0.5091, 0.5135, 0.5054, 0.5245, 0.5121, 0.5111, 0.5099,
        0.5120, 0.5129, 0.5103, 0.5142, 0.5191, 0.5124, 0.5196],
       device='cuda:0') torch.Size([16])
percent tensor([0.5215, 0.5261, 0.5240, 0.5239, 0.5246, 0.5208, 0.5290, 0.5249, 0.5272,
        0.5260, 0.5270, 0.5243, 0.5218, 0.5350, 0.5194, 0.5245],
       device='cuda:0') torch.Size([16])
percent tensor([0.4908, 0.4919, 0.4458, 0.4462, 0.4666, 0.4845, 0.4956, 0.4605, 0.4874,
        0.4918, 0.4936, 0.4592, 0.4848, 0.4977, 0.4854, 0.4972],
       device='cuda:0') torch.Size([16])
percent tensor([0.4995, 0.5003, 0.4958, 0.4994, 0.5005, 0.5041, 0.5000, 0.5012, 0.4984,
        0.4980, 0.4970, 0.4948, 0.4969, 0.5025, 0.5003, 0.5029],
       device='cuda:0') torch.Size([16])
percent tensor([0.4982, 0.5178, 0.5151, 0.5128, 0.5180, 0.5094, 0.5051, 0.5220, 0.5160,
        0.5122, 0.5131, 0.5148, 0.5202, 0.5048, 0.5117, 0.4990],
       device='cuda:0') torch.Size([16])
percent tensor([0.7549, 0.7335, 0.7878, 0.7848, 0.7782, 0.8250, 0.7147, 0.8338, 0.7686,
        0.7927, 0.7856, 0.7791, 0.8118, 0.7077, 0.7494, 0.7725],
       device='cuda:0') torch.Size([16])
Epoch: 19 | Batch_idx: 0 |  Loss: (0.8061) |  Loss2: (0.0000) | Acc: (69.00%) (89/128)
Epoch: 19 | Batch_idx: 10 |  Loss: (0.8214) |  Loss2: (0.0000) | Acc: (69.00%) (978/1408)
Epoch: 19 | Batch_idx: 20 |  Loss: (0.8240) |  Loss2: (0.0000) | Acc: (70.00%) (1898/2688)
Epoch: 19 | Batch_idx: 30 |  Loss: (0.8275) |  Loss2: (0.0000) | Acc: (71.00%) (2818/3968)
Epoch: 19 | Batch_idx: 40 |  Loss: (0.8234) |  Loss2: (0.0000) | Acc: (70.00%) (3722/5248)
Epoch: 19 | Batch_idx: 50 |  Loss: (0.8297) |  Loss2: (0.0000) | Acc: (70.00%) (4633/6528)
Epoch: 19 | Batch_idx: 60 |  Loss: (0.8252) |  Loss2: (0.0000) | Acc: (71.00%) (5554/7808)
Epoch: 19 | Batch_idx: 70 |  Loss: (0.8243) |  Loss2: (0.0000) | Acc: (71.00%) (6465/9088)
Epoch: 19 | Batch_idx: 80 |  Loss: (0.8244) |  Loss2: (0.0000) | Acc: (70.00%) (7360/10368)
Epoch: 19 | Batch_idx: 90 |  Loss: (0.8240) |  Loss2: (0.0000) | Acc: (71.00%) (8277/11648)
Epoch: 19 | Batch_idx: 100 |  Loss: (0.8257) |  Loss2: (0.0000) | Acc: (71.00%) (9190/12928)
Epoch: 19 | Batch_idx: 110 |  Loss: (0.8231) |  Loss2: (0.0000) | Acc: (71.00%) (10116/14208)
Epoch: 19 | Batch_idx: 120 |  Loss: (0.8219) |  Loss2: (0.0000) | Acc: (71.00%) (11026/15488)
Epoch: 19 | Batch_idx: 130 |  Loss: (0.8217) |  Loss2: (0.0000) | Acc: (71.00%) (11922/16768)
Epoch: 19 | Batch_idx: 140 |  Loss: (0.8225) |  Loss2: (0.0000) | Acc: (71.00%) (12835/18048)
Epoch: 19 | Batch_idx: 150 |  Loss: (0.8216) |  Loss2: (0.0000) | Acc: (71.00%) (13748/19328)
Epoch: 19 | Batch_idx: 160 |  Loss: (0.8184) |  Loss2: (0.0000) | Acc: (71.00%) (14671/20608)
Epoch: 19 | Batch_idx: 170 |  Loss: (0.8164) |  Loss2: (0.0000) | Acc: (71.00%) (15604/21888)
Epoch: 19 | Batch_idx: 180 |  Loss: (0.8182) |  Loss2: (0.0000) | Acc: (71.00%) (16473/23168)
Epoch: 19 | Batch_idx: 190 |  Loss: (0.8204) |  Loss2: (0.0000) | Acc: (70.00%) (17356/24448)
Epoch: 19 | Batch_idx: 200 |  Loss: (0.8196) |  Loss2: (0.0000) | Acc: (71.00%) (18269/25728)
Epoch: 19 | Batch_idx: 210 |  Loss: (0.8196) |  Loss2: (0.0000) | Acc: (71.00%) (19176/27008)
Epoch: 19 | Batch_idx: 220 |  Loss: (0.8174) |  Loss2: (0.0000) | Acc: (71.00%) (20113/28288)
Epoch: 19 | Batch_idx: 230 |  Loss: (0.8178) |  Loss2: (0.0000) | Acc: (71.00%) (21013/29568)
Epoch: 19 | Batch_idx: 240 |  Loss: (0.8203) |  Loss2: (0.0000) | Acc: (71.00%) (21905/30848)
Epoch: 19 | Batch_idx: 250 |  Loss: (0.8196) |  Loss2: (0.0000) | Acc: (71.00%) (22827/32128)
Epoch: 19 | Batch_idx: 260 |  Loss: (0.8191) |  Loss2: (0.0000) | Acc: (71.00%) (23733/33408)
Epoch: 19 | Batch_idx: 270 |  Loss: (0.8205) |  Loss2: (0.0000) | Acc: (70.00%) (24622/34688)
Epoch: 19 | Batch_idx: 280 |  Loss: (0.8203) |  Loss2: (0.0000) | Acc: (70.00%) (25537/35968)
Epoch: 19 | Batch_idx: 290 |  Loss: (0.8196) |  Loss2: (0.0000) | Acc: (71.00%) (26459/37248)
Epoch: 19 | Batch_idx: 300 |  Loss: (0.8185) |  Loss2: (0.0000) | Acc: (71.00%) (27379/38528)
Epoch: 19 | Batch_idx: 310 |  Loss: (0.8181) |  Loss2: (0.0000) | Acc: (71.00%) (28304/39808)
Epoch: 19 | Batch_idx: 320 |  Loss: (0.8168) |  Loss2: (0.0000) | Acc: (71.00%) (29236/41088)
Epoch: 19 | Batch_idx: 330 |  Loss: (0.8168) |  Loss2: (0.0000) | Acc: (71.00%) (30159/42368)
Epoch: 19 | Batch_idx: 340 |  Loss: (0.8168) |  Loss2: (0.0000) | Acc: (71.00%) (31077/43648)
Epoch: 19 | Batch_idx: 350 |  Loss: (0.8162) |  Loss2: (0.0000) | Acc: (71.00%) (31978/44928)
Epoch: 19 | Batch_idx: 360 |  Loss: (0.8160) |  Loss2: (0.0000) | Acc: (71.00%) (32884/46208)
Epoch: 19 | Batch_idx: 370 |  Loss: (0.8159) |  Loss2: (0.0000) | Acc: (71.00%) (33794/47488)
Epoch: 19 | Batch_idx: 380 |  Loss: (0.8146) |  Loss2: (0.0000) | Acc: (71.00%) (34738/48768)
Epoch: 19 | Batch_idx: 390 |  Loss: (0.8147) |  Loss2: (0.0000) | Acc: (71.00%) (35607/50000)
# TEST : Loss: (0.8390) | Acc: (69.00%) (6996/10000)
percent tensor([0.4986, 0.4939, 0.4866, 0.4913, 0.4889, 0.5037, 0.4924, 0.4887, 0.4938,
        0.4912, 0.4983, 0.4866, 0.4938, 0.4959, 0.4974, 0.4968],
       device='cuda:0') torch.Size([16])
percent tensor([0.5048, 0.5004, 0.5047, 0.5066, 0.5037, 0.5075, 0.5015, 0.5048, 0.5028,
        0.5001, 0.5027, 0.5011, 0.4999, 0.5053, 0.5033, 0.5050],
       device='cuda:0') torch.Size([16])
percent tensor([0.5165, 0.5135, 0.5150, 0.5171, 0.5090, 0.5252, 0.5111, 0.5128, 0.5105,
        0.5124, 0.5132, 0.5163, 0.5151, 0.5173, 0.5137, 0.5190],
       device='cuda:0') torch.Size([16])
percent tensor([0.5216, 0.5268, 0.5249, 0.5231, 0.5255, 0.5225, 0.5283, 0.5239, 0.5274,
        0.5268, 0.5270, 0.5257, 0.5225, 0.5366, 0.5201, 0.5248],
       device='cuda:0') torch.Size([16])
percent tensor([0.4906, 0.4909, 0.4492, 0.4470, 0.4675, 0.4856, 0.4927, 0.4602, 0.4859,
        0.4912, 0.4915, 0.4619, 0.4846, 0.4950, 0.4874, 0.4950],
       device='cuda:0') torch.Size([16])
percent tensor([0.5001, 0.5002, 0.4976, 0.4997, 0.4995, 0.5053, 0.4990, 0.4998, 0.4984,
        0.4983, 0.4970, 0.4965, 0.4983, 0.5016, 0.5010, 0.5027],
       device='cuda:0') torch.Size([16])
percent tensor([0.5001, 0.5187, 0.5174, 0.5131, 0.5151, 0.5059, 0.5047, 0.5195, 0.5181,
        0.5133, 0.5184, 0.5168, 0.5226, 0.5117, 0.5070, 0.4978],
       device='cuda:0') torch.Size([16])
percent tensor([0.7706, 0.7407, 0.7696, 0.7956, 0.7767, 0.8318, 0.7225, 0.8011, 0.7675,
        0.7851, 0.7836, 0.7549, 0.8057, 0.7224, 0.7158, 0.7704],
       device='cuda:0') torch.Size([16])
Epoch: 20 | Batch_idx: 0 |  Loss: (0.7510) |  Loss2: (0.0000) | Acc: (74.00%) (95/128)
Epoch: 20 | Batch_idx: 10 |  Loss: (0.7900) |  Loss2: (0.0000) | Acc: (72.00%) (1020/1408)
Epoch: 20 | Batch_idx: 20 |  Loss: (0.7735) |  Loss2: (0.0000) | Acc: (72.00%) (1951/2688)
Epoch: 20 | Batch_idx: 30 |  Loss: (0.7713) |  Loss2: (0.0000) | Acc: (72.00%) (2878/3968)
Epoch: 20 | Batch_idx: 40 |  Loss: (0.7724) |  Loss2: (0.0000) | Acc: (72.00%) (3812/5248)
Epoch: 20 | Batch_idx: 50 |  Loss: (0.7634) |  Loss2: (0.0000) | Acc: (72.00%) (4757/6528)
Epoch: 20 | Batch_idx: 60 |  Loss: (0.7631) |  Loss2: (0.0000) | Acc: (72.00%) (5698/7808)
Epoch: 20 | Batch_idx: 70 |  Loss: (0.7668) |  Loss2: (0.0000) | Acc: (72.00%) (6627/9088)
Epoch: 20 | Batch_idx: 80 |  Loss: (0.7716) |  Loss2: (0.0000) | Acc: (72.00%) (7543/10368)
Epoch: 20 | Batch_idx: 90 |  Loss: (0.7731) |  Loss2: (0.0000) | Acc: (72.00%) (8476/11648)
Epoch: 20 | Batch_idx: 100 |  Loss: (0.7732) |  Loss2: (0.0000) | Acc: (72.00%) (9395/12928)
Epoch: 20 | Batch_idx: 110 |  Loss: (0.7782) |  Loss2: (0.0000) | Acc: (72.00%) (10284/14208)
Epoch: 20 | Batch_idx: 120 |  Loss: (0.7818) |  Loss2: (0.0000) | Acc: (72.00%) (11197/15488)
Epoch: 20 | Batch_idx: 130 |  Loss: (0.7812) |  Loss2: (0.0000) | Acc: (72.00%) (12125/16768)
Epoch: 20 | Batch_idx: 140 |  Loss: (0.7767) |  Loss2: (0.0000) | Acc: (72.00%) (13087/18048)
Epoch: 20 | Batch_idx: 150 |  Loss: (0.7737) |  Loss2: (0.0000) | Acc: (72.00%) (14025/19328)
Epoch: 20 | Batch_idx: 160 |  Loss: (0.7755) |  Loss2: (0.0000) | Acc: (72.00%) (14951/20608)
Epoch: 20 | Batch_idx: 170 |  Loss: (0.7772) |  Loss2: (0.0000) | Acc: (72.00%) (15858/21888)
Epoch: 20 | Batch_idx: 180 |  Loss: (0.7743) |  Loss2: (0.0000) | Acc: (72.00%) (16814/23168)
Epoch: 20 | Batch_idx: 190 |  Loss: (0.7766) |  Loss2: (0.0000) | Acc: (72.00%) (17734/24448)
Epoch: 20 | Batch_idx: 200 |  Loss: (0.7761) |  Loss2: (0.0000) | Acc: (72.00%) (18669/25728)
Epoch: 20 | Batch_idx: 210 |  Loss: (0.7755) |  Loss2: (0.0000) | Acc: (72.00%) (19608/27008)
Epoch: 20 | Batch_idx: 220 |  Loss: (0.7748) |  Loss2: (0.0000) | Acc: (72.00%) (20544/28288)
Epoch: 20 | Batch_idx: 230 |  Loss: (0.7729) |  Loss2: (0.0000) | Acc: (72.00%) (21498/29568)
Epoch: 20 | Batch_idx: 240 |  Loss: (0.7737) |  Loss2: (0.0000) | Acc: (72.00%) (22419/30848)
Epoch: 20 | Batch_idx: 250 |  Loss: (0.7722) |  Loss2: (0.0000) | Acc: (72.00%) (23385/32128)
Epoch: 20 | Batch_idx: 260 |  Loss: (0.7715) |  Loss2: (0.0000) | Acc: (72.00%) (24324/33408)
Epoch: 20 | Batch_idx: 270 |  Loss: (0.7709) |  Loss2: (0.0000) | Acc: (72.00%) (25259/34688)
Epoch: 20 | Batch_idx: 280 |  Loss: (0.7701) |  Loss2: (0.0000) | Acc: (72.00%) (26199/35968)
Epoch: 20 | Batch_idx: 290 |  Loss: (0.7687) |  Loss2: (0.0000) | Acc: (72.00%) (27145/37248)
Epoch: 20 | Batch_idx: 300 |  Loss: (0.7684) |  Loss2: (0.0000) | Acc: (72.00%) (28089/38528)
Epoch: 20 | Batch_idx: 310 |  Loss: (0.7688) |  Loss2: (0.0000) | Acc: (72.00%) (29007/39808)
Epoch: 20 | Batch_idx: 320 |  Loss: (0.7676) |  Loss2: (0.0000) | Acc: (72.00%) (29953/41088)
Epoch: 20 | Batch_idx: 330 |  Loss: (0.7667) |  Loss2: (0.0000) | Acc: (72.00%) (30911/42368)
Epoch: 20 | Batch_idx: 340 |  Loss: (0.7683) |  Loss2: (0.0000) | Acc: (72.00%) (31807/43648)
Epoch: 20 | Batch_idx: 350 |  Loss: (0.7684) |  Loss2: (0.0000) | Acc: (72.00%) (32750/44928)
Epoch: 20 | Batch_idx: 360 |  Loss: (0.7682) |  Loss2: (0.0000) | Acc: (72.00%) (33690/46208)
Epoch: 20 | Batch_idx: 370 |  Loss: (0.7680) |  Loss2: (0.0000) | Acc: (72.00%) (34644/47488)
Epoch: 20 | Batch_idx: 380 |  Loss: (0.7681) |  Loss2: (0.0000) | Acc: (72.00%) (35600/48768)
Epoch: 20 | Batch_idx: 390 |  Loss: (0.7683) |  Loss2: (0.0000) | Acc: (72.00%) (36496/50000)
=> saving checkpoint 'drive/app/torch/save_Schedule/checkpoint_020.pth.tar'
# TEST : Loss: (0.7846) | Acc: (72.00%) (7256/10000)
percent tensor([0.4982, 0.4935, 0.4874, 0.4912, 0.4898, 0.5036, 0.4925, 0.4890, 0.4945,
        0.4916, 0.4984, 0.4875, 0.4937, 0.4957, 0.4971, 0.4967],
       device='cuda:0') torch.Size([16])
percent tensor([0.5050, 0.5005, 0.5043, 0.5060, 0.5033, 0.5074, 0.5017, 0.5053, 0.5031,
        0.5002, 0.5030, 0.5006, 0.5000, 0.5054, 0.5034, 0.5050],
       device='cuda:0') torch.Size([16])
percent tensor([0.5171, 0.5136, 0.5110, 0.5142, 0.5077, 0.5263, 0.5131, 0.5108, 0.5131,
        0.5124, 0.5153, 0.5133, 0.5157, 0.5222, 0.5131, 0.5193],
       device='cuda:0') torch.Size([16])
percent tensor([0.5228, 0.5267, 0.5270, 0.5211, 0.5256, 0.5211, 0.5302, 0.5243, 0.5302,
        0.5267, 0.5293, 0.5260, 0.5240, 0.5395, 0.5191, 0.5247],
       device='cuda:0') torch.Size([16])
percent tensor([0.4911, 0.4916, 0.4585, 0.4447, 0.4737, 0.4840, 0.4951, 0.4609, 0.4900,
        0.4919, 0.4925, 0.4648, 0.4856, 0.4979, 0.4832, 0.4950],
       device='cuda:0') torch.Size([16])
percent tensor([0.4996, 0.5002, 0.4981, 0.4980, 0.4995, 0.5054, 0.4990, 0.5000, 0.4997,
        0.4985, 0.4979, 0.4955, 0.4983, 0.5020, 0.5000, 0.5018],
       device='cuda:0') torch.Size([16])
percent tensor([0.4995, 0.5167, 0.5161, 0.5116, 0.5178, 0.5102, 0.5072, 0.5203, 0.5155,
        0.5120, 0.5128, 0.5115, 0.5207, 0.5052, 0.5104, 0.4976],
       device='cuda:0') torch.Size([16])
percent tensor([0.7596, 0.7366, 0.7785, 0.7831, 0.7889, 0.7851, 0.7346, 0.8092, 0.7575,
        0.7821, 0.7710, 0.7629, 0.7937, 0.7125, 0.7378, 0.7451],
       device='cuda:0') torch.Size([16])
Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 3, 3, 3]) tensor(169.3381, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(786.8986, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(778.2915, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([128, 64, 3, 3]) tensor(1530.8339, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([128, 64, 1, 1]) tensor(501.2016, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([128, 128, 3, 3]) tensor(2174.5574, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([256, 128, 3, 3]) tensor(4305.8052, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([256, 128, 1, 1]) tensor(1427.7812, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([256, 256, 3, 3]) tensor(6090.8735, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([512, 256, 3, 3]) tensor(12173.8145, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([512, 256, 1, 1]) tensor(4063.2114, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([512, 512, 3, 3]) tensor(17206.5078, device='cuda:0', grad_fn=<NormBackward0>)
Epoch: 21 | Batch_idx: 0 |  Loss: (0.7800) |  Loss2: (0.0000) | Acc: (73.00%) (94/128)
Epoch: 21 | Batch_idx: 10 |  Loss: (0.7684) |  Loss2: (0.0000) | Acc: (73.00%) (1041/1408)
Epoch: 21 | Batch_idx: 20 |  Loss: (0.7810) |  Loss2: (0.0000) | Acc: (72.00%) (1962/2688)
Epoch: 21 | Batch_idx: 30 |  Loss: (0.7716) |  Loss2: (0.0000) | Acc: (73.00%) (2900/3968)
Epoch: 21 | Batch_idx: 40 |  Loss: (0.7643) |  Loss2: (0.0000) | Acc: (73.00%) (3855/5248)
Epoch: 21 | Batch_idx: 50 |  Loss: (0.7611) |  Loss2: (0.0000) | Acc: (73.00%) (4810/6528)
Epoch: 21 | Batch_idx: 60 |  Loss: (0.7592) |  Loss2: (0.0000) | Acc: (73.00%) (5755/7808)
Epoch: 21 | Batch_idx: 70 |  Loss: (0.7554) |  Loss2: (0.0000) | Acc: (73.00%) (6701/9088)
Epoch: 21 | Batch_idx: 80 |  Loss: (0.7482) |  Loss2: (0.0000) | Acc: (73.00%) (7665/10368)
Epoch: 21 | Batch_idx: 90 |  Loss: (0.7518) |  Loss2: (0.0000) | Acc: (73.00%) (8579/11648)
Epoch: 21 | Batch_idx: 100 |  Loss: (0.7516) |  Loss2: (0.0000) | Acc: (73.00%) (9531/12928)
Epoch: 21 | Batch_idx: 110 |  Loss: (0.7478) |  Loss2: (0.0000) | Acc: (73.00%) (10506/14208)
Epoch: 21 | Batch_idx: 120 |  Loss: (0.7442) |  Loss2: (0.0000) | Acc: (74.00%) (11477/15488)
Epoch: 21 | Batch_idx: 130 |  Loss: (0.7401) |  Loss2: (0.0000) | Acc: (74.00%) (12448/16768)
Epoch: 21 | Batch_idx: 140 |  Loss: (0.7376) |  Loss2: (0.0000) | Acc: (74.00%) (13409/18048)
Epoch: 21 | Batch_idx: 150 |  Loss: (0.7371) |  Loss2: (0.0000) | Acc: (74.00%) (14342/19328)
Epoch: 21 | Batch_idx: 160 |  Loss: (0.7351) |  Loss2: (0.0000) | Acc: (74.00%) (15310/20608)
Epoch: 21 | Batch_idx: 170 |  Loss: (0.7346) |  Loss2: (0.0000) | Acc: (74.00%) (16273/21888)
Epoch: 21 | Batch_idx: 180 |  Loss: (0.7327) |  Loss2: (0.0000) | Acc: (74.00%) (17236/23168)
Epoch: 21 | Batch_idx: 190 |  Loss: (0.7332) |  Loss2: (0.0000) | Acc: (74.00%) (18171/24448)
Epoch: 21 | Batch_idx: 200 |  Loss: (0.7355) |  Loss2: (0.0000) | Acc: (74.00%) (19097/25728)
Epoch: 21 | Batch_idx: 210 |  Loss: (0.7358) |  Loss2: (0.0000) | Acc: (74.00%) (20044/27008)
Epoch: 21 | Batch_idx: 220 |  Loss: (0.7360) |  Loss2: (0.0000) | Acc: (74.00%) (21003/28288)
Epoch: 21 | Batch_idx: 230 |  Loss: (0.7367) |  Loss2: (0.0000) | Acc: (74.00%) (21947/29568)
Epoch: 21 | Batch_idx: 240 |  Loss: (0.7361) |  Loss2: (0.0000) | Acc: (74.00%) (22888/30848)
Epoch: 21 | Batch_idx: 250 |  Loss: (0.7372) |  Loss2: (0.0000) | Acc: (74.00%) (23829/32128)
Epoch: 21 | Batch_idx: 260 |  Loss: (0.7373) |  Loss2: (0.0000) | Acc: (74.00%) (24769/33408)
Epoch: 21 | Batch_idx: 270 |  Loss: (0.7365) |  Loss2: (0.0000) | Acc: (74.00%) (25729/34688)
Epoch: 21 | Batch_idx: 280 |  Loss: (0.7356) |  Loss2: (0.0000) | Acc: (74.00%) (26703/35968)
Epoch: 21 | Batch_idx: 290 |  Loss: (0.7352) |  Loss2: (0.0000) | Acc: (74.00%) (27658/37248)
Epoch: 21 | Batch_idx: 300 |  Loss: (0.7353) |  Loss2: (0.0000) | Acc: (74.00%) (28593/38528)
Epoch: 21 | Batch_idx: 310 |  Loss: (0.7339) |  Loss2: (0.0000) | Acc: (74.00%) (29551/39808)
Epoch: 21 | Batch_idx: 320 |  Loss: (0.7329) |  Loss2: (0.0000) | Acc: (74.00%) (30515/41088)
Epoch: 21 | Batch_idx: 330 |  Loss: (0.7319) |  Loss2: (0.0000) | Acc: (74.00%) (31483/42368)
Epoch: 21 | Batch_idx: 340 |  Loss: (0.7323) |  Loss2: (0.0000) | Acc: (74.00%) (32440/43648)
Epoch: 21 | Batch_idx: 350 |  Loss: (0.7323) |  Loss2: (0.0000) | Acc: (74.00%) (33392/44928)
Epoch: 21 | Batch_idx: 360 |  Loss: (0.7318) |  Loss2: (0.0000) | Acc: (74.00%) (34347/46208)
Epoch: 21 | Batch_idx: 370 |  Loss: (0.7311) |  Loss2: (0.0000) | Acc: (74.00%) (35313/47488)
Epoch: 21 | Batch_idx: 380 |  Loss: (0.7315) |  Loss2: (0.0000) | Acc: (74.00%) (36245/48768)
Epoch: 21 | Batch_idx: 390 |  Loss: (0.7304) |  Loss2: (0.0000) | Acc: (74.00%) (37186/50000)
# TEST : Loss: (0.8216) | Acc: (71.00%) (7161/10000)
percent tensor([0.4977, 0.4940, 0.4867, 0.4915, 0.4888, 0.5031, 0.4924, 0.4890, 0.4940,
        0.4914, 0.4983, 0.4865, 0.4932, 0.4971, 0.4971, 0.4970],
       device='cuda:0') torch.Size([16])
percent tensor([0.5049, 0.5018, 0.5037, 0.5063, 0.5030, 0.5071, 0.5023, 0.5058, 0.5046,
        0.5009, 0.5043, 0.4997, 0.5009, 0.5076, 0.5038, 0.5055],
       device='cuda:0') torch.Size([16])
percent tensor([0.5176, 0.5138, 0.5132, 0.5175, 0.5093, 0.5253, 0.5128, 0.5140, 0.5117,
        0.5137, 0.5143, 0.5149, 0.5158, 0.5213, 0.5142, 0.5202],
       device='cuda:0') torch.Size([16])
percent tensor([0.5225, 0.5274, 0.5233, 0.5214, 0.5244, 0.5207, 0.5283, 0.5248, 0.5286,
        0.5273, 0.5291, 0.5245, 0.5237, 0.5363, 0.5209, 0.5257],
       device='cuda:0') torch.Size([16])
percent tensor([0.4948, 0.4964, 0.4547, 0.4531, 0.4736, 0.4910, 0.4973, 0.4631, 0.4904,
        0.4968, 0.4945, 0.4683, 0.4908, 0.5011, 0.4871, 0.4975],
       device='cuda:0') torch.Size([16])
percent tensor([0.5008, 0.5015, 0.4987, 0.4997, 0.5011, 0.5059, 0.5003, 0.5012, 0.5016,
        0.5001, 0.4987, 0.4975, 0.4994, 0.5027, 0.5016, 0.5029],
       device='cuda:0') torch.Size([16])
percent tensor([0.4985, 0.5179, 0.5191, 0.5141, 0.5176, 0.5077, 0.5060, 0.5214, 0.5163,
        0.5152, 0.5152, 0.5166, 0.5197, 0.5073, 0.5097, 0.4975],
       device='cuda:0') torch.Size([16])
percent tensor([0.7660, 0.7451, 0.7550, 0.7744, 0.7638, 0.8398, 0.7254, 0.8077, 0.7543,
        0.7905, 0.7862, 0.7623, 0.7942, 0.7146, 0.7351, 0.7926],
       device='cuda:0') torch.Size([16])
Epoch: 22 | Batch_idx: 0 |  Loss: (0.5516) |  Loss2: (0.0000) | Acc: (82.00%) (105/128)
Epoch: 22 | Batch_idx: 10 |  Loss: (0.7223) |  Loss2: (0.0000) | Acc: (75.00%) (1059/1408)
Epoch: 22 | Batch_idx: 20 |  Loss: (0.7157) |  Loss2: (0.0000) | Acc: (75.00%) (2029/2688)
Epoch: 22 | Batch_idx: 30 |  Loss: (0.7190) |  Loss2: (0.0000) | Acc: (74.00%) (2967/3968)
Epoch: 22 | Batch_idx: 40 |  Loss: (0.7081) |  Loss2: (0.0000) | Acc: (75.00%) (3945/5248)
Epoch: 22 | Batch_idx: 50 |  Loss: (0.7030) |  Loss2: (0.0000) | Acc: (75.00%) (4930/6528)
Epoch: 22 | Batch_idx: 60 |  Loss: (0.7066) |  Loss2: (0.0000) | Acc: (75.00%) (5883/7808)
Epoch: 22 | Batch_idx: 70 |  Loss: (0.7015) |  Loss2: (0.0000) | Acc: (75.00%) (6883/9088)
Epoch: 22 | Batch_idx: 80 |  Loss: (0.6990) |  Loss2: (0.0000) | Acc: (75.00%) (7849/10368)
Epoch: 22 | Batch_idx: 90 |  Loss: (0.7004) |  Loss2: (0.0000) | Acc: (75.00%) (8808/11648)
Epoch: 22 | Batch_idx: 100 |  Loss: (0.7020) |  Loss2: (0.0000) | Acc: (75.00%) (9760/12928)
Epoch: 22 | Batch_idx: 110 |  Loss: (0.7027) |  Loss2: (0.0000) | Acc: (75.00%) (10694/14208)
Epoch: 22 | Batch_idx: 120 |  Loss: (0.7028) |  Loss2: (0.0000) | Acc: (75.00%) (11658/15488)
Epoch: 22 | Batch_idx: 130 |  Loss: (0.7032) |  Loss2: (0.0000) | Acc: (75.00%) (12626/16768)
Epoch: 22 | Batch_idx: 140 |  Loss: (0.6994) |  Loss2: (0.0000) | Acc: (75.00%) (13612/18048)
Epoch: 22 | Batch_idx: 150 |  Loss: (0.6991) |  Loss2: (0.0000) | Acc: (75.00%) (14582/19328)
Epoch: 22 | Batch_idx: 160 |  Loss: (0.6987) |  Loss2: (0.0000) | Acc: (75.00%) (15551/20608)
Epoch: 22 | Batch_idx: 170 |  Loss: (0.6984) |  Loss2: (0.0000) | Acc: (75.00%) (16527/21888)
Epoch: 22 | Batch_idx: 180 |  Loss: (0.7012) |  Loss2: (0.0000) | Acc: (75.00%) (17469/23168)
Epoch: 22 | Batch_idx: 190 |  Loss: (0.7019) |  Loss2: (0.0000) | Acc: (75.00%) (18415/24448)
Epoch: 22 | Batch_idx: 200 |  Loss: (0.7014) |  Loss2: (0.0000) | Acc: (75.00%) (19381/25728)
Epoch: 22 | Batch_idx: 210 |  Loss: (0.7029) |  Loss2: (0.0000) | Acc: (75.00%) (20323/27008)
Epoch: 22 | Batch_idx: 220 |  Loss: (0.7034) |  Loss2: (0.0000) | Acc: (75.00%) (21289/28288)
Epoch: 22 | Batch_idx: 230 |  Loss: (0.7025) |  Loss2: (0.0000) | Acc: (75.00%) (22262/29568)
Epoch: 22 | Batch_idx: 240 |  Loss: (0.7019) |  Loss2: (0.0000) | Acc: (75.00%) (23244/30848)
Epoch: 22 | Batch_idx: 250 |  Loss: (0.7010) |  Loss2: (0.0000) | Acc: (75.00%) (24212/32128)
Epoch: 22 | Batch_idx: 260 |  Loss: (0.7001) |  Loss2: (0.0000) | Acc: (75.00%) (25196/33408)
Epoch: 22 | Batch_idx: 270 |  Loss: (0.6988) |  Loss2: (0.0000) | Acc: (75.00%) (26170/34688)
Epoch: 22 | Batch_idx: 280 |  Loss: (0.6974) |  Loss2: (0.0000) | Acc: (75.00%) (27143/35968)
Epoch: 22 | Batch_idx: 290 |  Loss: (0.6969) |  Loss2: (0.0000) | Acc: (75.00%) (28121/37248)
Epoch: 22 | Batch_idx: 300 |  Loss: (0.6959) |  Loss2: (0.0000) | Acc: (75.00%) (29098/38528)
Epoch: 22 | Batch_idx: 310 |  Loss: (0.6951) |  Loss2: (0.0000) | Acc: (75.00%) (30084/39808)
Epoch: 22 | Batch_idx: 320 |  Loss: (0.6942) |  Loss2: (0.0000) | Acc: (75.00%) (31078/41088)
Epoch: 22 | Batch_idx: 330 |  Loss: (0.6939) |  Loss2: (0.0000) | Acc: (75.00%) (32060/42368)
Epoch: 22 | Batch_idx: 340 |  Loss: (0.6931) |  Loss2: (0.0000) | Acc: (75.00%) (33049/43648)
Epoch: 22 | Batch_idx: 350 |  Loss: (0.6929) |  Loss2: (0.0000) | Acc: (75.00%) (34033/44928)
Epoch: 22 | Batch_idx: 360 |  Loss: (0.6921) |  Loss2: (0.0000) | Acc: (75.00%) (35016/46208)
Epoch: 22 | Batch_idx: 370 |  Loss: (0.6914) |  Loss2: (0.0000) | Acc: (75.00%) (36007/47488)
Epoch: 22 | Batch_idx: 380 |  Loss: (0.6916) |  Loss2: (0.0000) | Acc: (75.00%) (36973/48768)
Epoch: 22 | Batch_idx: 390 |  Loss: (0.6916) |  Loss2: (0.0000) | Acc: (75.00%) (37881/50000)
# TEST : Loss: (0.6973) | Acc: (75.00%) (7572/10000)
percent tensor([0.4979, 0.4941, 0.4876, 0.4925, 0.4894, 0.5037, 0.4925, 0.4895, 0.4946,
        0.4917, 0.4986, 0.4875, 0.4935, 0.4970, 0.4976, 0.4971],
       device='cuda:0') torch.Size([16])
percent tensor([0.5054, 0.5013, 0.5047, 0.5057, 0.5042, 0.5066, 0.5029, 0.5056, 0.5054,
        0.5014, 0.5045, 0.5016, 0.5012, 0.5073, 0.5035, 0.5049],
       device='cuda:0') torch.Size([16])
percent tensor([0.5177, 0.5149, 0.5126, 0.5183, 0.5086, 0.5251, 0.5128, 0.5128, 0.5135,
        0.5137, 0.5155, 0.5148, 0.5165, 0.5226, 0.5144, 0.5194],
       device='cuda:0') torch.Size([16])
percent tensor([0.5235, 0.5288, 0.5236, 0.5226, 0.5245, 0.5219, 0.5297, 0.5239, 0.5301,
        0.5288, 0.5306, 0.5256, 0.5250, 0.5413, 0.5211, 0.5258],
       device='cuda:0') torch.Size([16])
percent tensor([0.4928, 0.4963, 0.4551, 0.4530, 0.4745, 0.4893, 0.4943, 0.4621, 0.4885,
        0.4958, 0.4914, 0.4679, 0.4900, 0.5012, 0.4868, 0.4956],
       device='cuda:0') torch.Size([16])
percent tensor([0.5010, 0.5009, 0.4985, 0.4990, 0.5010, 0.5074, 0.4998, 0.5007, 0.5017,
        0.4994, 0.4983, 0.4968, 0.4988, 0.5033, 0.5008, 0.5027],
       device='cuda:0') torch.Size([16])
percent tensor([0.4983, 0.5139, 0.5157, 0.5106, 0.5146, 0.5082, 0.5050, 0.5177, 0.5149,
        0.5106, 0.5139, 0.5117, 0.5156, 0.5089, 0.5059, 0.4972],
       device='cuda:0') torch.Size([16])
percent tensor([0.7641, 0.7428, 0.7600, 0.7675, 0.7631, 0.8138, 0.7366, 0.8131, 0.7637,
        0.7896, 0.8017, 0.7566, 0.7968, 0.7149, 0.7283, 0.7900],
       device='cuda:0') torch.Size([16])
Epoch: 23 | Batch_idx: 0 |  Loss: (0.8122) |  Loss2: (0.0000) | Acc: (70.00%) (90/128)
Epoch: 23 | Batch_idx: 10 |  Loss: (0.6857) |  Loss2: (0.0000) | Acc: (75.00%) (1066/1408)
Epoch: 23 | Batch_idx: 20 |  Loss: (0.6759) |  Loss2: (0.0000) | Acc: (76.00%) (2059/2688)
Epoch: 23 | Batch_idx: 30 |  Loss: (0.6749) |  Loss2: (0.0000) | Acc: (76.00%) (3028/3968)
Epoch: 23 | Batch_idx: 40 |  Loss: (0.6755) |  Loss2: (0.0000) | Acc: (76.00%) (4024/5248)
Epoch: 23 | Batch_idx: 50 |  Loss: (0.6690) |  Loss2: (0.0000) | Acc: (76.00%) (5005/6528)
Epoch: 23 | Batch_idx: 60 |  Loss: (0.6619) |  Loss2: (0.0000) | Acc: (76.00%) (5997/7808)
Epoch: 23 | Batch_idx: 70 |  Loss: (0.6621) |  Loss2: (0.0000) | Acc: (76.00%) (6975/9088)
Epoch: 23 | Batch_idx: 80 |  Loss: (0.6637) |  Loss2: (0.0000) | Acc: (76.00%) (7943/10368)
Epoch: 23 | Batch_idx: 90 |  Loss: (0.6600) |  Loss2: (0.0000) | Acc: (76.00%) (8940/11648)
Epoch: 23 | Batch_idx: 100 |  Loss: (0.6629) |  Loss2: (0.0000) | Acc: (76.00%) (9910/12928)
Epoch: 23 | Batch_idx: 110 |  Loss: (0.6601) |  Loss2: (0.0000) | Acc: (76.00%) (10927/14208)
Epoch: 23 | Batch_idx: 120 |  Loss: (0.6581) |  Loss2: (0.0000) | Acc: (76.00%) (11909/15488)
Epoch: 23 | Batch_idx: 130 |  Loss: (0.6581) |  Loss2: (0.0000) | Acc: (76.00%) (12898/16768)
Epoch: 23 | Batch_idx: 140 |  Loss: (0.6609) |  Loss2: (0.0000) | Acc: (76.00%) (13868/18048)
Epoch: 23 | Batch_idx: 150 |  Loss: (0.6621) |  Loss2: (0.0000) | Acc: (76.00%) (14839/19328)
Epoch: 23 | Batch_idx: 160 |  Loss: (0.6628) |  Loss2: (0.0000) | Acc: (76.00%) (15831/20608)
Epoch: 23 | Batch_idx: 170 |  Loss: (0.6626) |  Loss2: (0.0000) | Acc: (76.00%) (16821/21888)
Epoch: 23 | Batch_idx: 180 |  Loss: (0.6627) |  Loss2: (0.0000) | Acc: (76.00%) (17798/23168)
Epoch: 23 | Batch_idx: 190 |  Loss: (0.6616) |  Loss2: (0.0000) | Acc: (76.00%) (18785/24448)
Epoch: 23 | Batch_idx: 200 |  Loss: (0.6608) |  Loss2: (0.0000) | Acc: (76.00%) (19775/25728)
Epoch: 23 | Batch_idx: 210 |  Loss: (0.6605) |  Loss2: (0.0000) | Acc: (76.00%) (20768/27008)
Epoch: 23 | Batch_idx: 220 |  Loss: (0.6599) |  Loss2: (0.0000) | Acc: (76.00%) (21762/28288)
Epoch: 23 | Batch_idx: 230 |  Loss: (0.6587) |  Loss2: (0.0000) | Acc: (76.00%) (22763/29568)
Epoch: 23 | Batch_idx: 240 |  Loss: (0.6614) |  Loss2: (0.0000) | Acc: (76.00%) (23734/30848)
Epoch: 23 | Batch_idx: 250 |  Loss: (0.6600) |  Loss2: (0.0000) | Acc: (77.00%) (24739/32128)
Epoch: 23 | Batch_idx: 260 |  Loss: (0.6600) |  Loss2: (0.0000) | Acc: (76.00%) (25723/33408)
Epoch: 23 | Batch_idx: 270 |  Loss: (0.6602) |  Loss2: (0.0000) | Acc: (76.00%) (26708/34688)
Epoch: 23 | Batch_idx: 280 |  Loss: (0.6595) |  Loss2: (0.0000) | Acc: (76.00%) (27693/35968)
Epoch: 23 | Batch_idx: 290 |  Loss: (0.6624) |  Loss2: (0.0000) | Acc: (76.00%) (28642/37248)
Epoch: 23 | Batch_idx: 300 |  Loss: (0.6611) |  Loss2: (0.0000) | Acc: (76.00%) (29654/38528)
Epoch: 23 | Batch_idx: 310 |  Loss: (0.6612) |  Loss2: (0.0000) | Acc: (76.00%) (30638/39808)
Epoch: 23 | Batch_idx: 320 |  Loss: (0.6612) |  Loss2: (0.0000) | Acc: (76.00%) (31621/41088)
Epoch: 23 | Batch_idx: 330 |  Loss: (0.6616) |  Loss2: (0.0000) | Acc: (76.00%) (32610/42368)
Epoch: 23 | Batch_idx: 340 |  Loss: (0.6613) |  Loss2: (0.0000) | Acc: (77.00%) (33612/43648)
Epoch: 23 | Batch_idx: 350 |  Loss: (0.6609) |  Loss2: (0.0000) | Acc: (77.00%) (34598/44928)
Epoch: 23 | Batch_idx: 360 |  Loss: (0.6597) |  Loss2: (0.0000) | Acc: (77.00%) (35608/46208)
Epoch: 23 | Batch_idx: 370 |  Loss: (0.6599) |  Loss2: (0.0000) | Acc: (77.00%) (36585/47488)
Epoch: 23 | Batch_idx: 380 |  Loss: (0.6600) |  Loss2: (0.0000) | Acc: (77.00%) (37563/48768)
Epoch: 23 | Batch_idx: 390 |  Loss: (0.6608) |  Loss2: (0.0000) | Acc: (76.00%) (38473/50000)
# TEST : Loss: (0.7307) | Acc: (75.00%) (7522/10000)
percent tensor([0.4981, 0.4937, 0.4879, 0.4930, 0.4893, 0.5032, 0.4920, 0.4897, 0.4941,
        0.4916, 0.4984, 0.4872, 0.4936, 0.4961, 0.4973, 0.4971],
       device='cuda:0') torch.Size([16])
percent tensor([0.5056, 0.5008, 0.5038, 0.5060, 0.5030, 0.5069, 0.5018, 0.5052, 0.5047,
        0.5008, 0.5040, 0.4998, 0.5009, 0.5065, 0.5032, 0.5049],
       device='cuda:0') torch.Size([16])
percent tensor([0.5179, 0.5145, 0.5143, 0.5196, 0.5092, 0.5246, 0.5137, 0.5134, 0.5124,
        0.5152, 0.5155, 0.5170, 0.5166, 0.5212, 0.5140, 0.5202],
       device='cuda:0') torch.Size([16])
percent tensor([0.5229, 0.5280, 0.5263, 0.5226, 0.5250, 0.5197, 0.5301, 0.5246, 0.5301,
        0.5282, 0.5303, 0.5269, 0.5248, 0.5399, 0.5204, 0.5245],
       device='cuda:0') torch.Size([16])
percent tensor([0.4939, 0.4954, 0.4714, 0.4548, 0.4804, 0.4877, 0.4974, 0.4670, 0.4915,
        0.4963, 0.4938, 0.4786, 0.4901, 0.4991, 0.4839, 0.4955],
       device='cuda:0') torch.Size([16])
percent tensor([0.4992, 0.5008, 0.4985, 0.4985, 0.5000, 0.5061, 0.4987, 0.5007, 0.5000,
        0.4990, 0.4974, 0.4968, 0.4981, 0.5016, 0.4997, 0.5022],
       device='cuda:0') torch.Size([16])
percent tensor([0.4995, 0.5159, 0.5187, 0.5118, 0.5169, 0.5097, 0.5082, 0.5207, 0.5149,
        0.5111, 0.5134, 0.5186, 0.5175, 0.5077, 0.5116, 0.4986],
       device='cuda:0') torch.Size([16])
percent tensor([0.7658, 0.7313, 0.7744, 0.7819, 0.7845, 0.7851, 0.7419, 0.8002, 0.7715,
        0.7700, 0.7827, 0.7607, 0.7746, 0.7136, 0.7439, 0.7721],
       device='cuda:0') torch.Size([16])
Epoch: 24 | Batch_idx: 0 |  Loss: (0.5872) |  Loss2: (0.0000) | Acc: (80.00%) (103/128)
Epoch: 24 | Batch_idx: 10 |  Loss: (0.5987) |  Loss2: (0.0000) | Acc: (79.00%) (1121/1408)
Epoch: 24 | Batch_idx: 20 |  Loss: (0.6320) |  Loss2: (0.0000) | Acc: (78.00%) (2118/2688)
Epoch: 24 | Batch_idx: 30 |  Loss: (0.6197) |  Loss2: (0.0000) | Acc: (79.00%) (3143/3968)
Epoch: 24 | Batch_idx: 40 |  Loss: (0.6176) |  Loss2: (0.0000) | Acc: (79.00%) (4151/5248)
Epoch: 24 | Batch_idx: 50 |  Loss: (0.6229) |  Loss2: (0.0000) | Acc: (78.00%) (5152/6528)
Epoch: 24 | Batch_idx: 60 |  Loss: (0.6216) |  Loss2: (0.0000) | Acc: (78.00%) (6153/7808)
Epoch: 24 | Batch_idx: 70 |  Loss: (0.6243) |  Loss2: (0.0000) | Acc: (78.00%) (7140/9088)
Epoch: 24 | Batch_idx: 80 |  Loss: (0.6280) |  Loss2: (0.0000) | Acc: (78.00%) (8143/10368)
Epoch: 24 | Batch_idx: 90 |  Loss: (0.6276) |  Loss2: (0.0000) | Acc: (78.00%) (9140/11648)
Epoch: 24 | Batch_idx: 100 |  Loss: (0.6252) |  Loss2: (0.0000) | Acc: (78.00%) (10152/12928)
Epoch: 24 | Batch_idx: 110 |  Loss: (0.6278) |  Loss2: (0.0000) | Acc: (78.00%) (11142/14208)
Epoch: 24 | Batch_idx: 120 |  Loss: (0.6268) |  Loss2: (0.0000) | Acc: (78.00%) (12159/15488)
Epoch: 24 | Batch_idx: 130 |  Loss: (0.6249) |  Loss2: (0.0000) | Acc: (78.00%) (13178/16768)
Epoch: 24 | Batch_idx: 140 |  Loss: (0.6260) |  Loss2: (0.0000) | Acc: (78.00%) (14185/18048)
Epoch: 24 | Batch_idx: 150 |  Loss: (0.6281) |  Loss2: (0.0000) | Acc: (78.00%) (15172/19328)
Epoch: 24 | Batch_idx: 160 |  Loss: (0.6265) |  Loss2: (0.0000) | Acc: (78.00%) (16193/20608)
Epoch: 24 | Batch_idx: 170 |  Loss: (0.6272) |  Loss2: (0.0000) | Acc: (78.00%) (17200/21888)
Epoch: 24 | Batch_idx: 180 |  Loss: (0.6293) |  Loss2: (0.0000) | Acc: (78.00%) (18198/23168)
Epoch: 24 | Batch_idx: 190 |  Loss: (0.6325) |  Loss2: (0.0000) | Acc: (78.00%) (19165/24448)
Epoch: 24 | Batch_idx: 200 |  Loss: (0.6326) |  Loss2: (0.0000) | Acc: (78.00%) (20170/25728)
Epoch: 24 | Batch_idx: 210 |  Loss: (0.6339) |  Loss2: (0.0000) | Acc: (78.00%) (21159/27008)
Epoch: 24 | Batch_idx: 220 |  Loss: (0.6349) |  Loss2: (0.0000) | Acc: (78.00%) (22143/28288)
Epoch: 24 | Batch_idx: 230 |  Loss: (0.6340) |  Loss2: (0.0000) | Acc: (78.00%) (23143/29568)
Epoch: 24 | Batch_idx: 240 |  Loss: (0.6329) |  Loss2: (0.0000) | Acc: (78.00%) (24168/30848)
Epoch: 24 | Batch_idx: 250 |  Loss: (0.6341) |  Loss2: (0.0000) | Acc: (78.00%) (25156/32128)
Epoch: 24 | Batch_idx: 260 |  Loss: (0.6345) |  Loss2: (0.0000) | Acc: (78.00%) (26132/33408)
Epoch: 24 | Batch_idx: 270 |  Loss: (0.6336) |  Loss2: (0.0000) | Acc: (78.00%) (27139/34688)
Epoch: 24 | Batch_idx: 280 |  Loss: (0.6333) |  Loss2: (0.0000) | Acc: (78.00%) (28125/35968)
Epoch: 24 | Batch_idx: 290 |  Loss: (0.6327) |  Loss2: (0.0000) | Acc: (78.00%) (29134/37248)
Epoch: 24 | Batch_idx: 300 |  Loss: (0.6329) |  Loss2: (0.0000) | Acc: (78.00%) (30125/38528)
Epoch: 24 | Batch_idx: 310 |  Loss: (0.6326) |  Loss2: (0.0000) | Acc: (78.00%) (31119/39808)
Epoch: 24 | Batch_idx: 320 |  Loss: (0.6322) |  Loss2: (0.0000) | Acc: (78.00%) (32129/41088)
Epoch: 24 | Batch_idx: 330 |  Loss: (0.6316) |  Loss2: (0.0000) | Acc: (78.00%) (33125/42368)
Epoch: 24 | Batch_idx: 340 |  Loss: (0.6322) |  Loss2: (0.0000) | Acc: (78.00%) (34111/43648)
Epoch: 24 | Batch_idx: 350 |  Loss: (0.6325) |  Loss2: (0.0000) | Acc: (78.00%) (35114/44928)
Epoch: 24 | Batch_idx: 360 |  Loss: (0.6329) |  Loss2: (0.0000) | Acc: (78.00%) (36111/46208)
Epoch: 24 | Batch_idx: 370 |  Loss: (0.6333) |  Loss2: (0.0000) | Acc: (78.00%) (37104/47488)
Epoch: 24 | Batch_idx: 380 |  Loss: (0.6344) |  Loss2: (0.0000) | Acc: (78.00%) (38084/48768)
Epoch: 24 | Batch_idx: 390 |  Loss: (0.6345) |  Loss2: (0.0000) | Acc: (78.00%) (39040/50000)
# TEST : Loss: (0.6737) | Acc: (76.00%) (7682/10000)
percent tensor([0.4981, 0.4938, 0.4887, 0.4927, 0.4904, 0.5033, 0.4929, 0.4901, 0.4951,
        0.4919, 0.4989, 0.4885, 0.4938, 0.4970, 0.4972, 0.4972],
       device='cuda:0') torch.Size([16])
percent tensor([0.5052, 0.5008, 0.5043, 0.5055, 0.5035, 0.5070, 0.5020, 0.5053, 0.5044,
        0.5007, 0.5035, 0.5008, 0.5006, 0.5063, 0.5034, 0.5046],
       device='cuda:0') torch.Size([16])
percent tensor([0.5173, 0.5140, 0.5127, 0.5170, 0.5081, 0.5234, 0.5129, 0.5120, 0.5122,
        0.5133, 0.5155, 0.5152, 0.5159, 0.5209, 0.5139, 0.5191],
       device='cuda:0') torch.Size([16])
percent tensor([0.5232, 0.5275, 0.5244, 0.5223, 0.5232, 0.5185, 0.5288, 0.5233, 0.5290,
        0.5279, 0.5297, 0.5269, 0.5240, 0.5380, 0.5210, 0.5242],
       device='cuda:0') torch.Size([16])
percent tensor([0.4958, 0.4968, 0.4643, 0.4546, 0.4758, 0.4913, 0.4945, 0.4659, 0.4939,
        0.4989, 0.4936, 0.4691, 0.4916, 0.4986, 0.4850, 0.4978],
       device='cuda:0') torch.Size([16])
percent tensor([0.4998, 0.5012, 0.4984, 0.4980, 0.5006, 0.5057, 0.4988, 0.5009, 0.5004,
        0.4996, 0.4981, 0.4968, 0.4991, 0.5027, 0.5005, 0.5022],
       device='cuda:0') torch.Size([16])
percent tensor([0.5011, 0.5163, 0.5188, 0.5129, 0.5170, 0.5117, 0.5074, 0.5180, 0.5165,
        0.5127, 0.5173, 0.5150, 0.5187, 0.5074, 0.5126, 0.4988],
       device='cuda:0') torch.Size([16])
percent tensor([0.7619, 0.7459, 0.7538, 0.7784, 0.7655, 0.7835, 0.7565, 0.7858, 0.7835,
        0.8035, 0.8110, 0.7637, 0.8138, 0.7275, 0.7428, 0.7833],
       device='cuda:0') torch.Size([16])
Epoch: 25 | Batch_idx: 0 |  Loss: (0.5674) |  Loss2: (0.0000) | Acc: (81.00%) (104/128)
Epoch: 25 | Batch_idx: 10 |  Loss: (0.5903) |  Loss2: (0.0000) | Acc: (79.00%) (1122/1408)
Epoch: 25 | Batch_idx: 20 |  Loss: (0.5873) |  Loss2: (0.0000) | Acc: (79.00%) (2144/2688)
Epoch: 25 | Batch_idx: 30 |  Loss: (0.6010) |  Loss2: (0.0000) | Acc: (78.00%) (3133/3968)
Epoch: 25 | Batch_idx: 40 |  Loss: (0.5948) |  Loss2: (0.0000) | Acc: (79.00%) (4155/5248)
Epoch: 25 | Batch_idx: 50 |  Loss: (0.5957) |  Loss2: (0.0000) | Acc: (79.00%) (5176/6528)
Epoch: 25 | Batch_idx: 60 |  Loss: (0.5949) |  Loss2: (0.0000) | Acc: (79.00%) (6190/7808)
Epoch: 25 | Batch_idx: 70 |  Loss: (0.5955) |  Loss2: (0.0000) | Acc: (79.00%) (7207/9088)
Epoch: 25 | Batch_idx: 80 |  Loss: (0.5913) |  Loss2: (0.0000) | Acc: (79.00%) (8242/10368)
Epoch: 25 | Batch_idx: 90 |  Loss: (0.5924) |  Loss2: (0.0000) | Acc: (79.00%) (9251/11648)
Epoch: 25 | Batch_idx: 100 |  Loss: (0.5984) |  Loss2: (0.0000) | Acc: (79.00%) (10247/12928)
Epoch: 25 | Batch_idx: 110 |  Loss: (0.6015) |  Loss2: (0.0000) | Acc: (79.00%) (11248/14208)
Epoch: 25 | Batch_idx: 120 |  Loss: (0.6011) |  Loss2: (0.0000) | Acc: (79.00%) (12253/15488)
Epoch: 25 | Batch_idx: 130 |  Loss: (0.6021) |  Loss2: (0.0000) | Acc: (79.00%) (13260/16768)
Epoch: 25 | Batch_idx: 140 |  Loss: (0.6034) |  Loss2: (0.0000) | Acc: (79.00%) (14268/18048)
Epoch: 25 | Batch_idx: 150 |  Loss: (0.6019) |  Loss2: (0.0000) | Acc: (79.00%) (15295/19328)
Epoch: 25 | Batch_idx: 160 |  Loss: (0.6015) |  Loss2: (0.0000) | Acc: (79.00%) (16307/20608)
Epoch: 25 | Batch_idx: 170 |  Loss: (0.6045) |  Loss2: (0.0000) | Acc: (79.00%) (17297/21888)
Epoch: 25 | Batch_idx: 180 |  Loss: (0.6043) |  Loss2: (0.0000) | Acc: (78.00%) (18298/23168)
Epoch: 25 | Batch_idx: 190 |  Loss: (0.6035) |  Loss2: (0.0000) | Acc: (79.00%) (19324/24448)
Epoch: 25 | Batch_idx: 200 |  Loss: (0.6041) |  Loss2: (0.0000) | Acc: (79.00%) (20337/25728)
Epoch: 25 | Batch_idx: 210 |  Loss: (0.6034) |  Loss2: (0.0000) | Acc: (79.00%) (21353/27008)
Epoch: 25 | Batch_idx: 220 |  Loss: (0.6046) |  Loss2: (0.0000) | Acc: (79.00%) (22356/28288)
Epoch: 25 | Batch_idx: 230 |  Loss: (0.6038) |  Loss2: (0.0000) | Acc: (79.00%) (23377/29568)
Epoch: 25 | Batch_idx: 240 |  Loss: (0.6056) |  Loss2: (0.0000) | Acc: (78.00%) (24359/30848)
Epoch: 25 | Batch_idx: 250 |  Loss: (0.6047) |  Loss2: (0.0000) | Acc: (78.00%) (25372/32128)
Epoch: 25 | Batch_idx: 260 |  Loss: (0.6038) |  Loss2: (0.0000) | Acc: (79.00%) (26398/33408)
Epoch: 25 | Batch_idx: 270 |  Loss: (0.6032) |  Loss2: (0.0000) | Acc: (79.00%) (27412/34688)
Epoch: 25 | Batch_idx: 280 |  Loss: (0.6025) |  Loss2: (0.0000) | Acc: (79.00%) (28448/35968)
Epoch: 25 | Batch_idx: 290 |  Loss: (0.6022) |  Loss2: (0.0000) | Acc: (79.00%) (29471/37248)
Epoch: 25 | Batch_idx: 300 |  Loss: (0.6027) |  Loss2: (0.0000) | Acc: (79.00%) (30473/38528)
Epoch: 25 | Batch_idx: 310 |  Loss: (0.6027) |  Loss2: (0.0000) | Acc: (79.00%) (31493/39808)
Epoch: 25 | Batch_idx: 320 |  Loss: (0.6029) |  Loss2: (0.0000) | Acc: (79.00%) (32498/41088)
Epoch: 25 | Batch_idx: 330 |  Loss: (0.6031) |  Loss2: (0.0000) | Acc: (79.00%) (33494/42368)
Epoch: 25 | Batch_idx: 340 |  Loss: (0.6039) |  Loss2: (0.0000) | Acc: (79.00%) (34503/43648)
Epoch: 25 | Batch_idx: 350 |  Loss: (0.6046) |  Loss2: (0.0000) | Acc: (79.00%) (35498/44928)
Epoch: 25 | Batch_idx: 360 |  Loss: (0.6048) |  Loss2: (0.0000) | Acc: (79.00%) (36507/46208)
Epoch: 25 | Batch_idx: 370 |  Loss: (0.6049) |  Loss2: (0.0000) | Acc: (79.00%) (37526/47488)
Epoch: 25 | Batch_idx: 380 |  Loss: (0.6037) |  Loss2: (0.0000) | Acc: (79.00%) (38565/48768)
Epoch: 25 | Batch_idx: 390 |  Loss: (0.6027) |  Loss2: (0.0000) | Acc: (79.00%) (39545/50000)
=> saving checkpoint 'drive/app/torch/save_Schedule/checkpoint_025.pth.tar'
# TEST : Loss: (0.6204) | Acc: (78.00%) (7867/10000)
percent tensor([0.4981, 0.4938, 0.4886, 0.4925, 0.4900, 0.5036, 0.4925, 0.4899, 0.4952,
        0.4918, 0.4990, 0.4880, 0.4937, 0.4968, 0.4972, 0.4971],
       device='cuda:0') torch.Size([16])
percent tensor([0.5053, 0.5008, 0.5053, 0.5054, 0.5050, 0.5066, 0.5024, 0.5059, 0.5055,
        0.5010, 0.5043, 0.5013, 0.5012, 0.5056, 0.5032, 0.5045],
       device='cuda:0') torch.Size([16])
percent tensor([0.5179, 0.5138, 0.5159, 0.5200, 0.5108, 0.5265, 0.5121, 0.5134, 0.5131,
        0.5133, 0.5163, 0.5171, 0.5164, 0.5201, 0.5148, 0.5195],
       device='cuda:0') torch.Size([16])
percent tensor([0.5226, 0.5273, 0.5240, 0.5225, 0.5230, 0.5210, 0.5284, 0.5245, 0.5282,
        0.5274, 0.5291, 0.5260, 0.5238, 0.5385, 0.5212, 0.5250],
       device='cuda:0') torch.Size([16])
percent tensor([0.4923, 0.4954, 0.4677, 0.4604, 0.4749, 0.4847, 0.4943, 0.4654, 0.4888,
        0.4975, 0.4920, 0.4757, 0.4918, 0.4996, 0.4835, 0.4935],
       device='cuda:0') torch.Size([16])
percent tensor([0.4988, 0.4984, 0.4980, 0.4984, 0.5008, 0.5055, 0.4989, 0.5006, 0.4996,
        0.4983, 0.4972, 0.4959, 0.4980, 0.5011, 0.4996, 0.5017],
       device='cuda:0') torch.Size([16])
percent tensor([0.4981, 0.5129, 0.5168, 0.5108, 0.5154, 0.5097, 0.5072, 0.5161, 0.5147,
        0.5106, 0.5143, 0.5143, 0.5144, 0.5083, 0.5079, 0.4978],
       device='cuda:0') torch.Size([16])
percent tensor([0.7695, 0.7359, 0.7566, 0.7845, 0.7635, 0.7835, 0.7442, 0.8044, 0.7864,
        0.7707, 0.8075, 0.7561, 0.7790, 0.7199, 0.7385, 0.7747],
       device='cuda:0') torch.Size([16])
Epoch: 26 | Batch_idx: 0 |  Loss: (0.6761) |  Loss2: (0.0000) | Acc: (75.00%) (97/128)
Epoch: 26 | Batch_idx: 10 |  Loss: (0.5900) |  Loss2: (0.0000) | Acc: (79.00%) (1126/1408)
Epoch: 26 | Batch_idx: 20 |  Loss: (0.5901) |  Loss2: (0.0000) | Acc: (79.00%) (2143/2688)
Epoch: 26 | Batch_idx: 30 |  Loss: (0.5879) |  Loss2: (0.0000) | Acc: (80.00%) (3182/3968)
Epoch: 26 | Batch_idx: 40 |  Loss: (0.5867) |  Loss2: (0.0000) | Acc: (80.00%) (4201/5248)
Epoch: 26 | Batch_idx: 50 |  Loss: (0.5908) |  Loss2: (0.0000) | Acc: (79.00%) (5206/6528)
Epoch: 26 | Batch_idx: 60 |  Loss: (0.5878) |  Loss2: (0.0000) | Acc: (79.00%) (6225/7808)
Epoch: 26 | Batch_idx: 70 |  Loss: (0.5864) |  Loss2: (0.0000) | Acc: (79.00%) (7248/9088)
Epoch: 26 | Batch_idx: 80 |  Loss: (0.5865) |  Loss2: (0.0000) | Acc: (79.00%) (8268/10368)
Epoch: 26 | Batch_idx: 90 |  Loss: (0.5880) |  Loss2: (0.0000) | Acc: (79.00%) (9284/11648)
Epoch: 26 | Batch_idx: 100 |  Loss: (0.5872) |  Loss2: (0.0000) | Acc: (79.00%) (10295/12928)
Epoch: 26 | Batch_idx: 110 |  Loss: (0.5848) |  Loss2: (0.0000) | Acc: (79.00%) (11327/14208)
Epoch: 26 | Batch_idx: 120 |  Loss: (0.5850) |  Loss2: (0.0000) | Acc: (79.00%) (12349/15488)
Epoch: 26 | Batch_idx: 130 |  Loss: (0.5837) |  Loss2: (0.0000) | Acc: (79.00%) (13384/16768)
Epoch: 26 | Batch_idx: 140 |  Loss: (0.5842) |  Loss2: (0.0000) | Acc: (79.00%) (14401/18048)
Epoch: 26 | Batch_idx: 150 |  Loss: (0.5830) |  Loss2: (0.0000) | Acc: (79.00%) (15430/19328)
Epoch: 26 | Batch_idx: 160 |  Loss: (0.5824) |  Loss2: (0.0000) | Acc: (79.00%) (16476/20608)
Epoch: 26 | Batch_idx: 170 |  Loss: (0.5817) |  Loss2: (0.0000) | Acc: (80.00%) (17516/21888)
Epoch: 26 | Batch_idx: 180 |  Loss: (0.5808) |  Loss2: (0.0000) | Acc: (80.00%) (18546/23168)
Epoch: 26 | Batch_idx: 190 |  Loss: (0.5801) |  Loss2: (0.0000) | Acc: (80.00%) (19581/24448)
Epoch: 26 | Batch_idx: 200 |  Loss: (0.5802) |  Loss2: (0.0000) | Acc: (80.00%) (20613/25728)
Epoch: 26 | Batch_idx: 210 |  Loss: (0.5792) |  Loss2: (0.0000) | Acc: (80.00%) (21642/27008)
Epoch: 26 | Batch_idx: 220 |  Loss: (0.5777) |  Loss2: (0.0000) | Acc: (80.00%) (22675/28288)
Epoch: 26 | Batch_idx: 230 |  Loss: (0.5788) |  Loss2: (0.0000) | Acc: (80.00%) (23707/29568)
Epoch: 26 | Batch_idx: 240 |  Loss: (0.5795) |  Loss2: (0.0000) | Acc: (80.00%) (24740/30848)
Epoch: 26 | Batch_idx: 250 |  Loss: (0.5784) |  Loss2: (0.0000) | Acc: (80.00%) (25788/32128)
Epoch: 26 | Batch_idx: 260 |  Loss: (0.5793) |  Loss2: (0.0000) | Acc: (80.00%) (26797/33408)
Epoch: 26 | Batch_idx: 270 |  Loss: (0.5783) |  Loss2: (0.0000) | Acc: (80.00%) (27826/34688)
Epoch: 26 | Batch_idx: 280 |  Loss: (0.5786) |  Loss2: (0.0000) | Acc: (80.00%) (28848/35968)
Epoch: 26 | Batch_idx: 290 |  Loss: (0.5788) |  Loss2: (0.0000) | Acc: (80.00%) (29871/37248)
Epoch: 26 | Batch_idx: 300 |  Loss: (0.5770) |  Loss2: (0.0000) | Acc: (80.00%) (30924/38528)
Epoch: 26 | Batch_idx: 310 |  Loss: (0.5779) |  Loss2: (0.0000) | Acc: (80.00%) (31939/39808)
Epoch: 26 | Batch_idx: 320 |  Loss: (0.5774) |  Loss2: (0.0000) | Acc: (80.00%) (32981/41088)
Epoch: 26 | Batch_idx: 330 |  Loss: (0.5772) |  Loss2: (0.0000) | Acc: (80.00%) (34017/42368)
Epoch: 26 | Batch_idx: 340 |  Loss: (0.5771) |  Loss2: (0.0000) | Acc: (80.00%) (35045/43648)
Epoch: 26 | Batch_idx: 350 |  Loss: (0.5775) |  Loss2: (0.0000) | Acc: (80.00%) (36068/44928)
Epoch: 26 | Batch_idx: 360 |  Loss: (0.5784) |  Loss2: (0.0000) | Acc: (80.00%) (37081/46208)
Epoch: 26 | Batch_idx: 370 |  Loss: (0.5774) |  Loss2: (0.0000) | Acc: (80.00%) (38127/47488)
Epoch: 26 | Batch_idx: 380 |  Loss: (0.5769) |  Loss2: (0.0000) | Acc: (80.00%) (39164/48768)
Epoch: 26 | Batch_idx: 390 |  Loss: (0.5787) |  Loss2: (0.0000) | Acc: (80.00%) (40115/50000)
# TEST : Loss: (0.6081) | Acc: (78.00%) (7896/10000)
percent tensor([0.4979, 0.4941, 0.4887, 0.4932, 0.4902, 0.5032, 0.4928, 0.4910, 0.4953,
        0.4924, 0.4988, 0.4883, 0.4939, 0.4975, 0.4974, 0.4976],
       device='cuda:0') torch.Size([16])
percent tensor([0.5053, 0.5018, 0.5041, 0.5050, 0.5037, 0.5064, 0.5028, 0.5058, 0.5056,
        0.5016, 0.5045, 0.5006, 0.5013, 0.5075, 0.5033, 0.5051],
       device='cuda:0') torch.Size([16])
percent tensor([0.5181, 0.5153, 0.5137, 0.5207, 0.5099, 0.5249, 0.5141, 0.5140, 0.5138,
        0.5153, 0.5173, 0.5168, 0.5162, 0.5231, 0.5154, 0.5208],
       device='cuda:0') torch.Size([16])
percent tensor([0.5233, 0.5277, 0.5239, 0.5243, 0.5239, 0.5207, 0.5291, 0.5254, 0.5294,
        0.5279, 0.5298, 0.5270, 0.5235, 0.5412, 0.5216, 0.5256],
       device='cuda:0') torch.Size([16])
percent tensor([0.4925, 0.4949, 0.4689, 0.4580, 0.4783, 0.4861, 0.4959, 0.4682, 0.4927,
        0.4982, 0.4910, 0.4776, 0.4909, 0.5015, 0.4818, 0.4934],
       device='cuda:0') torch.Size([16])
percent tensor([0.4988, 0.4988, 0.4994, 0.4989, 0.5016, 0.5044, 0.4987, 0.5021, 0.4995,
        0.4990, 0.4964, 0.4970, 0.4977, 0.5015, 0.4990, 0.5024],
       device='cuda:0') torch.Size([16])
percent tensor([0.4980, 0.5121, 0.5189, 0.5120, 0.5169, 0.5139, 0.5061, 0.5171, 0.5149,
        0.5093, 0.5121, 0.5136, 0.5151, 0.5087, 0.5085, 0.4976],
       device='cuda:0') torch.Size([16])
percent tensor([0.7535, 0.7415, 0.7728, 0.7884, 0.7766, 0.7635, 0.7497, 0.8069, 0.7736,
        0.7921, 0.7997, 0.7469, 0.7937, 0.7361, 0.7412, 0.7680],
       device='cuda:0') torch.Size([16])
False Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=128, out_features=16, bias=False)
True Linear(in_features=16, out_features=2, bias=False)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=128, out_features=16, bias=False)
True Linear(in_features=16, out_features=2, bias=False)
False Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=256, out_features=32, bias=False)
True Linear(in_features=32, out_features=2, bias=False)
False Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=256, out_features=32, bias=False)
True Linear(in_features=32, out_features=2, bias=False)
False Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=512, out_features=64, bias=False)
True Linear(in_features=64, out_features=2, bias=False)
False Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=512, out_features=64, bias=False)
True Linear(in_features=64, out_features=2, bias=False)
False Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1024, out_features=128, bias=False)
True Linear(in_features=128, out_features=2, bias=False)
False Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1024, out_features=128, bias=False)
True Linear(in_features=128, out_features=2, bias=False)
False Linear(in_features=512, out_features=10, bias=True)
Epoch: 27 | Batch_idx: 0 |  Loss: (0.4711) |  Loss2: (0.0000) | Acc: (85.00%) (110/128)
Epoch: 27 | Batch_idx: 10 |  Loss: (0.6630) |  Loss2: (0.0000) | Acc: (76.00%) (1081/1408)
Epoch: 27 | Batch_idx: 20 |  Loss: (0.7218) |  Loss2: (0.0000) | Acc: (74.00%) (2003/2688)
Epoch: 27 | Batch_idx: 30 |  Loss: (0.7555) |  Loss2: (0.0000) | Acc: (73.00%) (2923/3968)
Epoch: 27 | Batch_idx: 40 |  Loss: (0.7647) |  Loss2: (0.0000) | Acc: (73.00%) (3845/5248)
Epoch: 27 | Batch_idx: 50 |  Loss: (0.7659) |  Loss2: (0.0000) | Acc: (73.00%) (4782/6528)
Epoch: 27 | Batch_idx: 60 |  Loss: (0.7673) |  Loss2: (0.0000) | Acc: (73.00%) (5729/7808)
Epoch: 27 | Batch_idx: 70 |  Loss: (0.7649) |  Loss2: (0.0000) | Acc: (73.00%) (6673/9088)
Epoch: 27 | Batch_idx: 80 |  Loss: (0.7592) |  Loss2: (0.0000) | Acc: (73.00%) (7628/10368)
Epoch: 27 | Batch_idx: 90 |  Loss: (0.7482) |  Loss2: (0.0000) | Acc: (73.00%) (8609/11648)
Epoch: 27 | Batch_idx: 100 |  Loss: (0.7455) |  Loss2: (0.0000) | Acc: (73.00%) (9557/12928)
Epoch: 27 | Batch_idx: 110 |  Loss: (0.7452) |  Loss2: (0.0000) | Acc: (73.00%) (10493/14208)
Epoch: 27 | Batch_idx: 120 |  Loss: (0.7368) |  Loss2: (0.0000) | Acc: (74.00%) (11489/15488)
Epoch: 27 | Batch_idx: 130 |  Loss: (0.7350) |  Loss2: (0.0000) | Acc: (74.00%) (12443/16768)
Epoch: 27 | Batch_idx: 140 |  Loss: (0.7300) |  Loss2: (0.0000) | Acc: (74.00%) (13439/18048)
Epoch: 27 | Batch_idx: 150 |  Loss: (0.7274) |  Loss2: (0.0000) | Acc: (74.00%) (14422/19328)
Epoch: 27 | Batch_idx: 160 |  Loss: (0.7229) |  Loss2: (0.0000) | Acc: (74.00%) (15400/20608)
Epoch: 27 | Batch_idx: 170 |  Loss: (0.7183) |  Loss2: (0.0000) | Acc: (74.00%) (16405/21888)
Epoch: 27 | Batch_idx: 180 |  Loss: (0.7164) |  Loss2: (0.0000) | Acc: (75.00%) (17387/23168)
Epoch: 27 | Batch_idx: 190 |  Loss: (0.7150) |  Loss2: (0.0000) | Acc: (75.00%) (18362/24448)
Epoch: 27 | Batch_idx: 200 |  Loss: (0.7122) |  Loss2: (0.0000) | Acc: (75.00%) (19337/25728)
Epoch: 27 | Batch_idx: 210 |  Loss: (0.7085) |  Loss2: (0.0000) | Acc: (75.00%) (20331/27008)
Epoch: 27 | Batch_idx: 220 |  Loss: (0.7059) |  Loss2: (0.0000) | Acc: (75.00%) (21313/28288)
Epoch: 27 | Batch_idx: 230 |  Loss: (0.7021) |  Loss2: (0.0000) | Acc: (75.00%) (22315/29568)
Epoch: 27 | Batch_idx: 240 |  Loss: (0.6980) |  Loss2: (0.0000) | Acc: (75.00%) (23322/30848)
Epoch: 27 | Batch_idx: 250 |  Loss: (0.6961) |  Loss2: (0.0000) | Acc: (75.00%) (24295/32128)
Epoch: 27 | Batch_idx: 260 |  Loss: (0.6950) |  Loss2: (0.0000) | Acc: (75.00%) (25275/33408)
Epoch: 27 | Batch_idx: 270 |  Loss: (0.6925) |  Loss2: (0.0000) | Acc: (75.00%) (26292/34688)
Epoch: 27 | Batch_idx: 280 |  Loss: (0.6899) |  Loss2: (0.0000) | Acc: (75.00%) (27312/35968)
Epoch: 27 | Batch_idx: 290 |  Loss: (0.6875) |  Loss2: (0.0000) | Acc: (76.00%) (28320/37248)
Epoch: 27 | Batch_idx: 300 |  Loss: (0.6861) |  Loss2: (0.0000) | Acc: (76.00%) (29313/38528)
Epoch: 27 | Batch_idx: 310 |  Loss: (0.6850) |  Loss2: (0.0000) | Acc: (76.00%) (30302/39808)
Epoch: 27 | Batch_idx: 320 |  Loss: (0.6836) |  Loss2: (0.0000) | Acc: (76.00%) (31300/41088)
Epoch: 27 | Batch_idx: 330 |  Loss: (0.6824) |  Loss2: (0.0000) | Acc: (76.00%) (32283/42368)
Epoch: 27 | Batch_idx: 340 |  Loss: (0.6802) |  Loss2: (0.0000) | Acc: (76.00%) (33283/43648)
Epoch: 27 | Batch_idx: 350 |  Loss: (0.6780) |  Loss2: (0.0000) | Acc: (76.00%) (34292/44928)
Epoch: 27 | Batch_idx: 360 |  Loss: (0.6775) |  Loss2: (0.0000) | Acc: (76.00%) (35293/46208)
Epoch: 27 | Batch_idx: 370 |  Loss: (0.6777) |  Loss2: (0.0000) | Acc: (76.00%) (36278/47488)
Epoch: 27 | Batch_idx: 380 |  Loss: (0.6758) |  Loss2: (0.0000) | Acc: (76.00%) (37288/48768)
Epoch: 27 | Batch_idx: 390 |  Loss: (0.6739) |  Loss2: (0.0000) | Acc: (76.00%) (38260/50000)
# TEST : Loss: (0.6564) | Acc: (77.00%) (7757/10000)
percent tensor([0.4920, 0.4871, 0.4809, 0.4863, 0.4819, 0.4963, 0.4848, 0.4833, 0.4879,
        0.4847, 0.4915, 0.4799, 0.4880, 0.4899, 0.4897, 0.4910],
       device='cuda:0') torch.Size([16])
percent tensor([0.5074, 0.5049, 0.5077, 0.5090, 0.5076, 0.5076, 0.5059, 0.5102, 0.5083,
        0.5052, 0.5069, 0.5043, 0.5041, 0.5095, 0.5060, 0.5077],
       device='cuda:0') torch.Size([16])
percent tensor([0.4932, 0.4960, 0.5046, 0.5017, 0.4988, 0.4921, 0.4970, 0.5006, 0.4972,
        0.4989, 0.4920, 0.5062, 0.4980, 0.5023, 0.4897, 0.4973],
       device='cuda:0') torch.Size([16])
percent tensor([0.5375, 0.5443, 0.5402, 0.5365, 0.5396, 0.5314, 0.5460, 0.5397, 0.5460,
        0.5463, 0.5470, 0.5469, 0.5422, 0.5560, 0.5351, 0.5398],
       device='cuda:0') torch.Size([16])
percent tensor([0.5038, 0.5070, 0.4612, 0.4449, 0.4612, 0.4913, 0.4990, 0.4518, 0.5026,
        0.5095, 0.5109, 0.4801, 0.5081, 0.5128, 0.4807, 0.5004],
       device='cuda:0') torch.Size([16])
percent tensor([0.4968, 0.4974, 0.4981, 0.4974, 0.5004, 0.5010, 0.4980, 0.5019, 0.4966,
        0.4974, 0.4936, 0.4954, 0.4944, 0.4983, 0.4972, 0.4999],
       device='cuda:0') torch.Size([16])
percent tensor([0.5089, 0.5264, 0.5368, 0.5262, 0.5384, 0.5220, 0.5203, 0.5423, 0.5223,
        0.5239, 0.5251, 0.5294, 0.5237, 0.5174, 0.5203, 0.5054],
       device='cuda:0') torch.Size([16])
percent tensor([0.8336, 0.8032, 0.8178, 0.8434, 0.8051, 0.8343, 0.7999, 0.8444, 0.8549,
        0.8657, 0.8793, 0.8031, 0.8674, 0.8209, 0.7913, 0.8460],
       device='cuda:0') torch.Size([16])
Epoch: 28 | Batch_idx: 0 |  Loss: (0.5921) |  Loss2: (0.0000) | Acc: (80.00%) (103/128)
Epoch: 28 | Batch_idx: 10 |  Loss: (0.6052) |  Loss2: (0.0000) | Acc: (80.00%) (1127/1408)
Epoch: 28 | Batch_idx: 20 |  Loss: (0.6053) |  Loss2: (0.0000) | Acc: (79.00%) (2142/2688)
Epoch: 28 | Batch_idx: 30 |  Loss: (0.6069) |  Loss2: (0.0000) | Acc: (79.00%) (3146/3968)
Epoch: 28 | Batch_idx: 40 |  Loss: (0.6065) |  Loss2: (0.0000) | Acc: (79.00%) (4148/5248)
Epoch: 28 | Batch_idx: 50 |  Loss: (0.6038) |  Loss2: (0.0000) | Acc: (79.00%) (5165/6528)
Epoch: 28 | Batch_idx: 60 |  Loss: (0.6061) |  Loss2: (0.0000) | Acc: (79.00%) (6176/7808)
Epoch: 28 | Batch_idx: 70 |  Loss: (0.5963) |  Loss2: (0.0000) | Acc: (79.00%) (7212/9088)
Epoch: 28 | Batch_idx: 80 |  Loss: (0.5981) |  Loss2: (0.0000) | Acc: (79.00%) (8231/10368)
Epoch: 28 | Batch_idx: 90 |  Loss: (0.5977) |  Loss2: (0.0000) | Acc: (79.00%) (9232/11648)
Epoch: 28 | Batch_idx: 100 |  Loss: (0.5948) |  Loss2: (0.0000) | Acc: (79.00%) (10245/12928)
Epoch: 28 | Batch_idx: 110 |  Loss: (0.5908) |  Loss2: (0.0000) | Acc: (79.00%) (11295/14208)
Epoch: 28 | Batch_idx: 120 |  Loss: (0.5977) |  Loss2: (0.0000) | Acc: (79.00%) (12279/15488)
Epoch: 28 | Batch_idx: 130 |  Loss: (0.5984) |  Loss2: (0.0000) | Acc: (79.00%) (13308/16768)
Epoch: 28 | Batch_idx: 140 |  Loss: (0.6004) |  Loss2: (0.0000) | Acc: (79.00%) (14305/18048)
Epoch: 28 | Batch_idx: 150 |  Loss: (0.6012) |  Loss2: (0.0000) | Acc: (79.00%) (15300/19328)
Epoch: 28 | Batch_idx: 160 |  Loss: (0.6001) |  Loss2: (0.0000) | Acc: (79.00%) (16331/20608)
Epoch: 28 | Batch_idx: 170 |  Loss: (0.5974) |  Loss2: (0.0000) | Acc: (79.00%) (17349/21888)
Epoch: 28 | Batch_idx: 180 |  Loss: (0.5962) |  Loss2: (0.0000) | Acc: (79.00%) (18372/23168)
Epoch: 28 | Batch_idx: 190 |  Loss: (0.5952) |  Loss2: (0.0000) | Acc: (79.00%) (19389/24448)
Epoch: 28 | Batch_idx: 200 |  Loss: (0.5958) |  Loss2: (0.0000) | Acc: (79.00%) (20409/25728)
Epoch: 28 | Batch_idx: 210 |  Loss: (0.5962) |  Loss2: (0.0000) | Acc: (79.00%) (21418/27008)
Epoch: 28 | Batch_idx: 220 |  Loss: (0.5985) |  Loss2: (0.0000) | Acc: (79.00%) (22422/28288)
Epoch: 28 | Batch_idx: 230 |  Loss: (0.5987) |  Loss2: (0.0000) | Acc: (79.00%) (23431/29568)
Epoch: 28 | Batch_idx: 240 |  Loss: (0.6001) |  Loss2: (0.0000) | Acc: (79.00%) (24449/30848)
Epoch: 28 | Batch_idx: 250 |  Loss: (0.5983) |  Loss2: (0.0000) | Acc: (79.00%) (25473/32128)
Epoch: 28 | Batch_idx: 260 |  Loss: (0.5980) |  Loss2: (0.0000) | Acc: (79.00%) (26513/33408)
Epoch: 28 | Batch_idx: 270 |  Loss: (0.5968) |  Loss2: (0.0000) | Acc: (79.00%) (27549/34688)
Epoch: 28 | Batch_idx: 280 |  Loss: (0.5971) |  Loss2: (0.0000) | Acc: (79.00%) (28566/35968)
Epoch: 28 | Batch_idx: 290 |  Loss: (0.5970) |  Loss2: (0.0000) | Acc: (79.00%) (29587/37248)
Epoch: 28 | Batch_idx: 300 |  Loss: (0.5962) |  Loss2: (0.0000) | Acc: (79.00%) (30605/38528)
Epoch: 28 | Batch_idx: 310 |  Loss: (0.5949) |  Loss2: (0.0000) | Acc: (79.00%) (31626/39808)
Epoch: 28 | Batch_idx: 320 |  Loss: (0.5955) |  Loss2: (0.0000) | Acc: (79.00%) (32647/41088)
Epoch: 28 | Batch_idx: 330 |  Loss: (0.5956) |  Loss2: (0.0000) | Acc: (79.00%) (33668/42368)
Epoch: 28 | Batch_idx: 340 |  Loss: (0.5963) |  Loss2: (0.0000) | Acc: (79.00%) (34674/43648)
Epoch: 28 | Batch_idx: 350 |  Loss: (0.5954) |  Loss2: (0.0000) | Acc: (79.00%) (35688/44928)
Epoch: 28 | Batch_idx: 360 |  Loss: (0.5963) |  Loss2: (0.0000) | Acc: (79.00%) (36684/46208)
Epoch: 28 | Batch_idx: 370 |  Loss: (0.5964) |  Loss2: (0.0000) | Acc: (79.00%) (37689/47488)
Epoch: 28 | Batch_idx: 380 |  Loss: (0.5961) |  Loss2: (0.0000) | Acc: (79.00%) (38698/48768)
Epoch: 28 | Batch_idx: 390 |  Loss: (0.5968) |  Loss2: (0.0000) | Acc: (79.00%) (39657/50000)
# TEST : Loss: (0.6321) | Acc: (78.00%) (7878/10000)
percent tensor([0.4912, 0.4857, 0.4796, 0.4844, 0.4807, 0.4953, 0.4836, 0.4816, 0.4870,
        0.4833, 0.4905, 0.4786, 0.4870, 0.4887, 0.4881, 0.4897],
       device='cuda:0') torch.Size([16])
percent tensor([0.5069, 0.5043, 0.5083, 0.5090, 0.5079, 0.5069, 0.5056, 0.5105, 0.5085,
        0.5049, 0.5064, 0.5045, 0.5036, 0.5095, 0.5052, 0.5071],
       device='cuda:0') torch.Size([16])
percent tensor([0.4873, 0.4936, 0.5038, 0.4994, 0.4981, 0.4828, 0.4952, 0.4999, 0.4949,
        0.4973, 0.4868, 0.5062, 0.4940, 0.5016, 0.4832, 0.4926],
       device='cuda:0') torch.Size([16])
percent tensor([0.5374, 0.5451, 0.5397, 0.5359, 0.5389, 0.5305, 0.5462, 0.5389, 0.5472,
        0.5470, 0.5479, 0.5468, 0.5431, 0.5577, 0.5342, 0.5398],
       device='cuda:0') torch.Size([16])
percent tensor([0.5136, 0.5142, 0.4598, 0.4522, 0.4572, 0.5007, 0.5023, 0.4488, 0.5119,
        0.5168, 0.5243, 0.4811, 0.5173, 0.5223, 0.4816, 0.5094],
       device='cuda:0') torch.Size([16])
percent tensor([0.4990, 0.5003, 0.4997, 0.4990, 0.5029, 0.5030, 0.5010, 0.5049, 0.4986,
        0.5002, 0.4960, 0.4973, 0.4960, 0.5007, 0.4994, 0.5023],
       device='cuda:0') torch.Size([16])
percent tensor([0.5186, 0.5400, 0.5531, 0.5412, 0.5603, 0.5333, 0.5322, 0.5685, 0.5300,
        0.5366, 0.5346, 0.5436, 0.5324, 0.5246, 0.5320, 0.5153],
       device='cuda:0') torch.Size([16])
percent tensor([0.8851, 0.8518, 0.8693, 0.8950, 0.8572, 0.8843, 0.8541, 0.8970, 0.9012,
        0.9110, 0.9215, 0.8605, 0.9126, 0.8699, 0.8440, 0.8956],
       device='cuda:0') torch.Size([16])
Epoch: 29 | Batch_idx: 0 |  Loss: (0.6193) |  Loss2: (0.0000) | Acc: (81.00%) (104/128)
Epoch: 29 | Batch_idx: 10 |  Loss: (0.6059) |  Loss2: (0.0000) | Acc: (78.00%) (1112/1408)
Epoch: 29 | Batch_idx: 20 |  Loss: (0.5705) |  Loss2: (0.0000) | Acc: (79.00%) (2148/2688)
Epoch: 29 | Batch_idx: 30 |  Loss: (0.5719) |  Loss2: (0.0000) | Acc: (79.00%) (3169/3968)
Epoch: 29 | Batch_idx: 40 |  Loss: (0.5751) |  Loss2: (0.0000) | Acc: (79.00%) (4195/5248)
Epoch: 29 | Batch_idx: 50 |  Loss: (0.5788) |  Loss2: (0.0000) | Acc: (79.00%) (5204/6528)
Epoch: 29 | Batch_idx: 60 |  Loss: (0.5805) |  Loss2: (0.0000) | Acc: (79.00%) (6235/7808)
Epoch: 29 | Batch_idx: 70 |  Loss: (0.5825) |  Loss2: (0.0000) | Acc: (79.00%) (7244/9088)
Epoch: 29 | Batch_idx: 80 |  Loss: (0.5832) |  Loss2: (0.0000) | Acc: (79.00%) (8250/10368)
Epoch: 29 | Batch_idx: 90 |  Loss: (0.5824) |  Loss2: (0.0000) | Acc: (79.00%) (9274/11648)
Epoch: 29 | Batch_idx: 100 |  Loss: (0.5828) |  Loss2: (0.0000) | Acc: (79.00%) (10280/12928)
Epoch: 29 | Batch_idx: 110 |  Loss: (0.5861) |  Loss2: (0.0000) | Acc: (79.00%) (11295/14208)
Epoch: 29 | Batch_idx: 120 |  Loss: (0.5828) |  Loss2: (0.0000) | Acc: (79.00%) (12327/15488)
Epoch: 29 | Batch_idx: 130 |  Loss: (0.5807) |  Loss2: (0.0000) | Acc: (79.00%) (13355/16768)
Epoch: 29 | Batch_idx: 140 |  Loss: (0.5789) |  Loss2: (0.0000) | Acc: (79.00%) (14405/18048)
Epoch: 29 | Batch_idx: 150 |  Loss: (0.5798) |  Loss2: (0.0000) | Acc: (79.00%) (15421/19328)
Epoch: 29 | Batch_idx: 160 |  Loss: (0.5783) |  Loss2: (0.0000) | Acc: (79.00%) (16453/20608)
Epoch: 29 | Batch_idx: 170 |  Loss: (0.5798) |  Loss2: (0.0000) | Acc: (79.00%) (17458/21888)
Epoch: 29 | Batch_idx: 180 |  Loss: (0.5804) |  Loss2: (0.0000) | Acc: (79.00%) (18465/23168)
Epoch: 29 | Batch_idx: 190 |  Loss: (0.5805) |  Loss2: (0.0000) | Acc: (79.00%) (19473/24448)
Epoch: 29 | Batch_idx: 200 |  Loss: (0.5789) |  Loss2: (0.0000) | Acc: (79.00%) (20490/25728)
Epoch: 29 | Batch_idx: 210 |  Loss: (0.5787) |  Loss2: (0.0000) | Acc: (79.00%) (21494/27008)
Epoch: 29 | Batch_idx: 220 |  Loss: (0.5774) |  Loss2: (0.0000) | Acc: (79.00%) (22531/28288)
Epoch: 29 | Batch_idx: 230 |  Loss: (0.5771) |  Loss2: (0.0000) | Acc: (79.00%) (23553/29568)
Epoch: 29 | Batch_idx: 240 |  Loss: (0.5760) |  Loss2: (0.0000) | Acc: (79.00%) (24597/30848)
Epoch: 29 | Batch_idx: 250 |  Loss: (0.5777) |  Loss2: (0.0000) | Acc: (79.00%) (25607/32128)
Epoch: 29 | Batch_idx: 260 |  Loss: (0.5785) |  Loss2: (0.0000) | Acc: (79.00%) (26619/33408)
Epoch: 29 | Batch_idx: 270 |  Loss: (0.5780) |  Loss2: (0.0000) | Acc: (79.00%) (27652/34688)
Epoch: 29 | Batch_idx: 280 |  Loss: (0.5780) |  Loss2: (0.0000) | Acc: (79.00%) (28670/35968)
Epoch: 29 | Batch_idx: 290 |  Loss: (0.5789) |  Loss2: (0.0000) | Acc: (79.00%) (29673/37248)
Epoch: 29 | Batch_idx: 300 |  Loss: (0.5791) |  Loss2: (0.0000) | Acc: (79.00%) (30684/38528)
Epoch: 29 | Batch_idx: 310 |  Loss: (0.5795) |  Loss2: (0.0000) | Acc: (79.00%) (31690/39808)
Epoch: 29 | Batch_idx: 320 |  Loss: (0.5804) |  Loss2: (0.0000) | Acc: (79.00%) (32705/41088)
Epoch: 29 | Batch_idx: 330 |  Loss: (0.5798) |  Loss2: (0.0000) | Acc: (79.00%) (33726/42368)
Epoch: 29 | Batch_idx: 340 |  Loss: (0.5807) |  Loss2: (0.0000) | Acc: (79.00%) (34742/43648)
Epoch: 29 | Batch_idx: 350 |  Loss: (0.5809) |  Loss2: (0.0000) | Acc: (79.00%) (35763/44928)
Epoch: 29 | Batch_idx: 360 |  Loss: (0.5806) |  Loss2: (0.0000) | Acc: (79.00%) (36790/46208)
Epoch: 29 | Batch_idx: 370 |  Loss: (0.5791) |  Loss2: (0.0000) | Acc: (79.00%) (37840/47488)
Epoch: 29 | Batch_idx: 380 |  Loss: (0.5809) |  Loss2: (0.0000) | Acc: (79.00%) (38839/48768)
Epoch: 29 | Batch_idx: 390 |  Loss: (0.5813) |  Loss2: (0.0000) | Acc: (79.00%) (39818/50000)
# TEST : Loss: (0.6191) | Acc: (79.00%) (7923/10000)
percent tensor([0.4921, 0.4866, 0.4808, 0.4848, 0.4819, 0.4962, 0.4847, 0.4824, 0.4880,
        0.4843, 0.4914, 0.4798, 0.4877, 0.4896, 0.4890, 0.4904],
       device='cuda:0') torch.Size([16])
percent tensor([0.5076, 0.5048, 0.5094, 0.5097, 0.5091, 0.5074, 0.5063, 0.5115, 0.5093,
        0.5055, 0.5070, 0.5053, 0.5041, 0.5102, 0.5057, 0.5078],
       device='cuda:0') torch.Size([16])
percent tensor([0.4881, 0.4967, 0.5051, 0.5002, 0.4996, 0.4813, 0.4975, 0.5014, 0.4969,
        0.5000, 0.4882, 0.5086, 0.4954, 0.5052, 0.4833, 0.4940],
       device='cuda:0') torch.Size([16])
percent tensor([0.5376, 0.5462, 0.5393, 0.5349, 0.5382, 0.5302, 0.5465, 0.5382, 0.5478,
        0.5481, 0.5491, 0.5471, 0.5443, 0.5585, 0.5339, 0.5404],
       device='cuda:0') torch.Size([16])
percent tensor([0.5200, 0.5184, 0.4656, 0.4652, 0.4613, 0.5079, 0.5069, 0.4530, 0.5191,
        0.5216, 0.5321, 0.4856, 0.5223, 0.5285, 0.4839, 0.5161],
       device='cuda:0') torch.Size([16])
percent tensor([0.5014, 0.5033, 0.5019, 0.5012, 0.5057, 0.5054, 0.5039, 0.5078, 0.5007,
        0.5033, 0.4985, 0.4995, 0.4982, 0.5029, 0.5019, 0.5050],
       device='cuda:0') torch.Size([16])
percent tensor([0.5260, 0.5495, 0.5643, 0.5513, 0.5754, 0.5441, 0.5394, 0.5837, 0.5372,
        0.5459, 0.5424, 0.5509, 0.5393, 0.5318, 0.5396, 0.5220],
       device='cuda:0') torch.Size([16])
percent tensor([0.9044, 0.8721, 0.8929, 0.9137, 0.8796, 0.9056, 0.8755, 0.9175, 0.9194,
        0.9268, 0.9379, 0.8850, 0.9290, 0.8893, 0.8676, 0.9131],
       device='cuda:0') torch.Size([16])
Epoch: 30 | Batch_idx: 0 |  Loss: (0.4984) |  Loss2: (0.0000) | Acc: (82.00%) (106/128)
Epoch: 30 | Batch_idx: 10 |  Loss: (0.5809) |  Loss2: (0.0000) | Acc: (79.00%) (1114/1408)
Epoch: 30 | Batch_idx: 20 |  Loss: (0.5764) |  Loss2: (0.0000) | Acc: (78.00%) (2123/2688)
Epoch: 30 | Batch_idx: 30 |  Loss: (0.5705) |  Loss2: (0.0000) | Acc: (79.00%) (3150/3968)
Epoch: 30 | Batch_idx: 40 |  Loss: (0.5722) |  Loss2: (0.0000) | Acc: (79.00%) (4163/5248)
Epoch: 30 | Batch_idx: 50 |  Loss: (0.5693) |  Loss2: (0.0000) | Acc: (79.00%) (5206/6528)
Epoch: 30 | Batch_idx: 60 |  Loss: (0.5708) |  Loss2: (0.0000) | Acc: (79.00%) (6227/7808)
Epoch: 30 | Batch_idx: 70 |  Loss: (0.5660) |  Loss2: (0.0000) | Acc: (79.00%) (7268/9088)
Epoch: 30 | Batch_idx: 80 |  Loss: (0.5682) |  Loss2: (0.0000) | Acc: (79.00%) (8281/10368)
Epoch: 30 | Batch_idx: 90 |  Loss: (0.5712) |  Loss2: (0.0000) | Acc: (79.00%) (9296/11648)
Epoch: 30 | Batch_idx: 100 |  Loss: (0.5748) |  Loss2: (0.0000) | Acc: (79.00%) (10326/12928)
Epoch: 30 | Batch_idx: 110 |  Loss: (0.5756) |  Loss2: (0.0000) | Acc: (79.00%) (11351/14208)
Epoch: 30 | Batch_idx: 120 |  Loss: (0.5762) |  Loss2: (0.0000) | Acc: (79.00%) (12378/15488)
Epoch: 30 | Batch_idx: 130 |  Loss: (0.5746) |  Loss2: (0.0000) | Acc: (79.00%) (13408/16768)
Epoch: 30 | Batch_idx: 140 |  Loss: (0.5744) |  Loss2: (0.0000) | Acc: (79.00%) (14429/18048)
Epoch: 30 | Batch_idx: 150 |  Loss: (0.5725) |  Loss2: (0.0000) | Acc: (80.00%) (15468/19328)
Epoch: 30 | Batch_idx: 160 |  Loss: (0.5726) |  Loss2: (0.0000) | Acc: (80.00%) (16501/20608)
Epoch: 30 | Batch_idx: 170 |  Loss: (0.5757) |  Loss2: (0.0000) | Acc: (79.00%) (17500/21888)
Epoch: 30 | Batch_idx: 180 |  Loss: (0.5742) |  Loss2: (0.0000) | Acc: (79.00%) (18527/23168)
Epoch: 30 | Batch_idx: 190 |  Loss: (0.5761) |  Loss2: (0.0000) | Acc: (79.00%) (19529/24448)
Epoch: 30 | Batch_idx: 200 |  Loss: (0.5762) |  Loss2: (0.0000) | Acc: (79.00%) (20550/25728)
Epoch: 30 | Batch_idx: 210 |  Loss: (0.5726) |  Loss2: (0.0000) | Acc: (79.00%) (21588/27008)
Epoch: 30 | Batch_idx: 220 |  Loss: (0.5732) |  Loss2: (0.0000) | Acc: (79.00%) (22621/28288)
Epoch: 30 | Batch_idx: 230 |  Loss: (0.5722) |  Loss2: (0.0000) | Acc: (79.00%) (23652/29568)
Epoch: 30 | Batch_idx: 240 |  Loss: (0.5721) |  Loss2: (0.0000) | Acc: (80.00%) (24681/30848)
Epoch: 30 | Batch_idx: 250 |  Loss: (0.5709) |  Loss2: (0.0000) | Acc: (80.00%) (25717/32128)
Epoch: 30 | Batch_idx: 260 |  Loss: (0.5692) |  Loss2: (0.0000) | Acc: (80.00%) (26756/33408)
Epoch: 30 | Batch_idx: 270 |  Loss: (0.5698) |  Loss2: (0.0000) | Acc: (80.00%) (27773/34688)
Epoch: 30 | Batch_idx: 280 |  Loss: (0.5707) |  Loss2: (0.0000) | Acc: (80.00%) (28791/35968)
Epoch: 30 | Batch_idx: 290 |  Loss: (0.5703) |  Loss2: (0.0000) | Acc: (80.00%) (29826/37248)
Epoch: 30 | Batch_idx: 300 |  Loss: (0.5695) |  Loss2: (0.0000) | Acc: (80.00%) (30865/38528)
Epoch: 30 | Batch_idx: 310 |  Loss: (0.5699) |  Loss2: (0.0000) | Acc: (80.00%) (31879/39808)
Epoch: 30 | Batch_idx: 320 |  Loss: (0.5707) |  Loss2: (0.0000) | Acc: (80.00%) (32899/41088)
Epoch: 30 | Batch_idx: 330 |  Loss: (0.5703) |  Loss2: (0.0000) | Acc: (80.00%) (33927/42368)
Epoch: 30 | Batch_idx: 340 |  Loss: (0.5716) |  Loss2: (0.0000) | Acc: (80.00%) (34936/43648)
Epoch: 30 | Batch_idx: 350 |  Loss: (0.5722) |  Loss2: (0.0000) | Acc: (80.00%) (35950/44928)
Epoch: 30 | Batch_idx: 360 |  Loss: (0.5723) |  Loss2: (0.0000) | Acc: (80.00%) (36968/46208)
Epoch: 30 | Batch_idx: 370 |  Loss: (0.5716) |  Loss2: (0.0000) | Acc: (80.00%) (38023/47488)
Epoch: 30 | Batch_idx: 380 |  Loss: (0.5721) |  Loss2: (0.0000) | Acc: (80.00%) (39026/48768)
Epoch: 30 | Batch_idx: 390 |  Loss: (0.5733) |  Loss2: (0.0000) | Acc: (79.00%) (39997/50000)
=> saving checkpoint 'drive/app/torch/save_Schedule/checkpoint_030.pth.tar'
# TEST : Loss: (0.6151) | Acc: (79.00%) (7949/10000)
percent tensor([0.4931, 0.4874, 0.4817, 0.4851, 0.4830, 0.4972, 0.4857, 0.4831, 0.4891,
        0.4852, 0.4925, 0.4807, 0.4885, 0.4905, 0.4897, 0.4910],
       device='cuda:0') torch.Size([16])
percent tensor([0.5081, 0.5050, 0.5104, 0.5104, 0.5101, 0.5078, 0.5067, 0.5124, 0.5100,
        0.5058, 0.5073, 0.5060, 0.5042, 0.5106, 0.5059, 0.5082],
       device='cuda:0') torch.Size([16])
percent tensor([0.4888, 0.4988, 0.5068, 0.5019, 0.5018, 0.4808, 0.4995, 0.5034, 0.4985,
        0.5022, 0.4890, 0.5110, 0.4960, 0.5081, 0.4837, 0.4948],
       device='cuda:0') torch.Size([16])
percent tensor([0.5375, 0.5461, 0.5393, 0.5343, 0.5381, 0.5299, 0.5464, 0.5379, 0.5482,
        0.5484, 0.5494, 0.5473, 0.5446, 0.5588, 0.5334, 0.5403],
       device='cuda:0') torch.Size([16])
percent tensor([0.5237, 0.5210, 0.4678, 0.4729, 0.4625, 0.5124, 0.5077, 0.4544, 0.5237,
        0.5252, 0.5378, 0.4868, 0.5264, 0.5334, 0.4830, 0.5204],
       device='cuda:0') torch.Size([16])
percent tensor([0.5030, 0.5051, 0.5037, 0.5028, 0.5080, 0.5070, 0.5058, 0.5103, 0.5022,
        0.5052, 0.4998, 0.5009, 0.4991, 0.5043, 0.5036, 0.5069],
       device='cuda:0') torch.Size([16])
percent tensor([0.5294, 0.5561, 0.5748, 0.5610, 0.5900, 0.5515, 0.5449, 0.6006, 0.5400,
        0.5516, 0.5438, 0.5575, 0.5396, 0.5340, 0.5473, 0.5273],
       device='cuda:0') torch.Size([16])
percent tensor([0.9118, 0.8811, 0.9075, 0.9246, 0.8984, 0.9151, 0.8879, 0.9309, 0.9259,
        0.9334, 0.9425, 0.9018, 0.9352, 0.8968, 0.8812, 0.9218],
       device='cuda:0') torch.Size([16])
Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 3, 3, 3]) tensor(172.2638, device='cuda:0')
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(794.8255, device='cuda:0')
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(784.0958, device='cuda:0')
Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([128, 64, 3, 3]) tensor(1532.0627, device='cuda:0')
Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([128, 64, 1, 1]) tensor(499.8434, device='cuda:0')
Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([128, 128, 3, 3]) tensor(2186.9956, device='cuda:0')
Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([256, 128, 3, 3]) tensor(4298.2100, device='cuda:0')
Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([256, 128, 1, 1]) tensor(1422.7400, device='cuda:0')
Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([256, 256, 3, 3]) tensor(6085.0215, device='cuda:0')
Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([512, 256, 3, 3]) tensor(12125.2383, device='cuda:0')
Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([512, 256, 1, 1]) tensor(4046.9253, device='cuda:0')
Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([512, 512, 3, 3]) tensor(17127.1094, device='cuda:0')
Epoch: 31 | Batch_idx: 0 |  Loss: (0.5191) |  Loss2: (0.0000) | Acc: (82.00%) (105/128)
Epoch: 31 | Batch_idx: 10 |  Loss: (0.5619) |  Loss2: (0.0000) | Acc: (80.00%) (1132/1408)
Epoch: 31 | Batch_idx: 20 |  Loss: (0.5407) |  Loss2: (0.0000) | Acc: (80.00%) (2168/2688)
Epoch: 31 | Batch_idx: 30 |  Loss: (0.5587) |  Loss2: (0.0000) | Acc: (79.00%) (3169/3968)
Epoch: 31 | Batch_idx: 40 |  Loss: (0.5613) |  Loss2: (0.0000) | Acc: (80.00%) (4201/5248)
Epoch: 31 | Batch_idx: 50 |  Loss: (0.5655) |  Loss2: (0.0000) | Acc: (79.00%) (5213/6528)
Epoch: 31 | Batch_idx: 60 |  Loss: (0.5690) |  Loss2: (0.0000) | Acc: (79.00%) (6211/7808)
Epoch: 31 | Batch_idx: 70 |  Loss: (0.5688) |  Loss2: (0.0000) | Acc: (79.00%) (7233/9088)
Epoch: 31 | Batch_idx: 80 |  Loss: (0.5725) |  Loss2: (0.0000) | Acc: (79.00%) (8249/10368)
Epoch: 31 | Batch_idx: 90 |  Loss: (0.5764) |  Loss2: (0.0000) | Acc: (79.00%) (9247/11648)
Epoch: 31 | Batch_idx: 100 |  Loss: (0.5714) |  Loss2: (0.0000) | Acc: (79.00%) (10287/12928)
Epoch: 31 | Batch_idx: 110 |  Loss: (0.5660) |  Loss2: (0.0000) | Acc: (79.00%) (11343/14208)
Epoch: 31 | Batch_idx: 120 |  Loss: (0.5655) |  Loss2: (0.0000) | Acc: (79.00%) (12360/15488)
Epoch: 31 | Batch_idx: 130 |  Loss: (0.5619) |  Loss2: (0.0000) | Acc: (79.00%) (13408/16768)
Epoch: 31 | Batch_idx: 140 |  Loss: (0.5633) |  Loss2: (0.0000) | Acc: (79.00%) (14417/18048)
Epoch: 31 | Batch_idx: 150 |  Loss: (0.5614) |  Loss2: (0.0000) | Acc: (80.00%) (15466/19328)
Epoch: 31 | Batch_idx: 160 |  Loss: (0.5610) |  Loss2: (0.0000) | Acc: (80.00%) (16495/20608)
Epoch: 31 | Batch_idx: 170 |  Loss: (0.5641) |  Loss2: (0.0000) | Acc: (79.00%) (17505/21888)
Epoch: 31 | Batch_idx: 180 |  Loss: (0.5633) |  Loss2: (0.0000) | Acc: (80.00%) (18546/23168)
Epoch: 31 | Batch_idx: 190 |  Loss: (0.5629) |  Loss2: (0.0000) | Acc: (80.00%) (19590/24448)
Epoch: 31 | Batch_idx: 200 |  Loss: (0.5645) |  Loss2: (0.0000) | Acc: (80.00%) (20612/25728)
Epoch: 31 | Batch_idx: 210 |  Loss: (0.5655) |  Loss2: (0.0000) | Acc: (80.00%) (21635/27008)
Epoch: 31 | Batch_idx: 220 |  Loss: (0.5669) |  Loss2: (0.0000) | Acc: (80.00%) (22653/28288)
Epoch: 31 | Batch_idx: 230 |  Loss: (0.5670) |  Loss2: (0.0000) | Acc: (80.00%) (23687/29568)
Epoch: 31 | Batch_idx: 240 |  Loss: (0.5688) |  Loss2: (0.0000) | Acc: (80.00%) (24700/30848)
Epoch: 31 | Batch_idx: 250 |  Loss: (0.5696) |  Loss2: (0.0000) | Acc: (80.00%) (25724/32128)
Epoch: 31 | Batch_idx: 260 |  Loss: (0.5686) |  Loss2: (0.0000) | Acc: (80.00%) (26763/33408)
Epoch: 31 | Batch_idx: 270 |  Loss: (0.5674) |  Loss2: (0.0000) | Acc: (80.00%) (27811/34688)
Epoch: 31 | Batch_idx: 280 |  Loss: (0.5651) |  Loss2: (0.0000) | Acc: (80.00%) (28866/35968)
Epoch: 31 | Batch_idx: 290 |  Loss: (0.5641) |  Loss2: (0.0000) | Acc: (80.00%) (29897/37248)
Epoch: 31 | Batch_idx: 300 |  Loss: (0.5634) |  Loss2: (0.0000) | Acc: (80.00%) (30941/38528)
Epoch: 31 | Batch_idx: 310 |  Loss: (0.5636) |  Loss2: (0.0000) | Acc: (80.00%) (31968/39808)
Epoch: 31 | Batch_idx: 320 |  Loss: (0.5645) |  Loss2: (0.0000) | Acc: (80.00%) (32975/41088)
Epoch: 31 | Batch_idx: 330 |  Loss: (0.5639) |  Loss2: (0.0000) | Acc: (80.00%) (34018/42368)
Epoch: 31 | Batch_idx: 340 |  Loss: (0.5638) |  Loss2: (0.0000) | Acc: (80.00%) (35046/43648)
Epoch: 31 | Batch_idx: 350 |  Loss: (0.5634) |  Loss2: (0.0000) | Acc: (80.00%) (36071/44928)
Epoch: 31 | Batch_idx: 360 |  Loss: (0.5639) |  Loss2: (0.0000) | Acc: (80.00%) (37082/46208)
Epoch: 31 | Batch_idx: 370 |  Loss: (0.5639) |  Loss2: (0.0000) | Acc: (80.00%) (38122/47488)
Epoch: 31 | Batch_idx: 380 |  Loss: (0.5645) |  Loss2: (0.0000) | Acc: (80.00%) (39141/48768)
Epoch: 31 | Batch_idx: 390 |  Loss: (0.5639) |  Loss2: (0.0000) | Acc: (80.00%) (40140/50000)
# TEST : Loss: (0.6083) | Acc: (79.00%) (7962/10000)
percent tensor([0.4909, 0.4846, 0.4785, 0.4818, 0.4799, 0.4951, 0.4828, 0.4798, 0.4866,
        0.4822, 0.4901, 0.4774, 0.4861, 0.4880, 0.4869, 0.4886],
       device='cuda:0') torch.Size([16])
percent tensor([0.5078, 0.5045, 0.5105, 0.5101, 0.5099, 0.5076, 0.5063, 0.5122, 0.5097,
        0.5053, 0.5068, 0.5056, 0.5038, 0.5103, 0.5054, 0.5078],
       device='cuda:0') torch.Size([16])
percent tensor([0.4928, 0.5032, 0.5094, 0.5049, 0.5044, 0.4835, 0.5030, 0.5060, 0.5017,
        0.5060, 0.4928, 0.5142, 0.4994, 0.5125, 0.4869, 0.4988],
       device='cuda:0') torch.Size([16])
percent tensor([0.5371, 0.5461, 0.5378, 0.5322, 0.5358, 0.5291, 0.5453, 0.5358, 0.5477,
        0.5483, 0.5494, 0.5460, 0.5452, 0.5583, 0.5321, 0.5400],
       device='cuda:0') torch.Size([16])
percent tensor([0.5263, 0.5231, 0.4691, 0.4776, 0.4634, 0.5151, 0.5107, 0.4555, 0.5270,
        0.5284, 0.5428, 0.4875, 0.5285, 0.5379, 0.4810, 0.5243],
       device='cuda:0') torch.Size([16])
percent tensor([0.5034, 0.5057, 0.5043, 0.5034, 0.5089, 0.5076, 0.5063, 0.5111, 0.5027,
        0.5057, 0.5001, 0.5014, 0.4992, 0.5047, 0.5041, 0.5075],
       device='cuda:0') torch.Size([16])
percent tensor([0.5314, 0.5604, 0.5796, 0.5646, 0.5977, 0.5584, 0.5463, 0.6074, 0.5441,
        0.5559, 0.5470, 0.5603, 0.5417, 0.5376, 0.5502, 0.5289],
       device='cuda:0') torch.Size([16])
percent tensor([0.9205, 0.8922, 0.9203, 0.9346, 0.9108, 0.9270, 0.8977, 0.9408, 0.9352,
        0.9420, 0.9516, 0.9144, 0.9433, 0.9057, 0.8938, 0.9292],
       device='cuda:0') torch.Size([16])
Epoch: 32 | Batch_idx: 0 |  Loss: (0.4954) |  Loss2: (0.0000) | Acc: (85.00%) (109/128)
Epoch: 32 | Batch_idx: 10 |  Loss: (0.5457) |  Loss2: (0.0000) | Acc: (81.00%) (1147/1408)
Epoch: 32 | Batch_idx: 20 |  Loss: (0.5628) |  Loss2: (0.0000) | Acc: (80.00%) (2175/2688)
Epoch: 32 | Batch_idx: 30 |  Loss: (0.5595) |  Loss2: (0.0000) | Acc: (80.00%) (3205/3968)
Epoch: 32 | Batch_idx: 40 |  Loss: (0.5562) |  Loss2: (0.0000) | Acc: (81.00%) (4251/5248)
Epoch: 32 | Batch_idx: 50 |  Loss: (0.5555) |  Loss2: (0.0000) | Acc: (80.00%) (5268/6528)
Epoch: 32 | Batch_idx: 60 |  Loss: (0.5558) |  Loss2: (0.0000) | Acc: (80.00%) (6305/7808)
Epoch: 32 | Batch_idx: 70 |  Loss: (0.5542) |  Loss2: (0.0000) | Acc: (80.00%) (7345/9088)
Epoch: 32 | Batch_idx: 80 |  Loss: (0.5528) |  Loss2: (0.0000) | Acc: (80.00%) (8385/10368)
Epoch: 32 | Batch_idx: 90 |  Loss: (0.5548) |  Loss2: (0.0000) | Acc: (80.00%) (9410/11648)
Epoch: 32 | Batch_idx: 100 |  Loss: (0.5574) |  Loss2: (0.0000) | Acc: (80.00%) (10431/12928)
Epoch: 32 | Batch_idx: 110 |  Loss: (0.5588) |  Loss2: (0.0000) | Acc: (80.00%) (11461/14208)
Epoch: 32 | Batch_idx: 120 |  Loss: (0.5606) |  Loss2: (0.0000) | Acc: (80.00%) (12488/15488)
Epoch: 32 | Batch_idx: 130 |  Loss: (0.5601) |  Loss2: (0.0000) | Acc: (80.00%) (13524/16768)
Epoch: 32 | Batch_idx: 140 |  Loss: (0.5613) |  Loss2: (0.0000) | Acc: (80.00%) (14540/18048)
Epoch: 32 | Batch_idx: 150 |  Loss: (0.5633) |  Loss2: (0.0000) | Acc: (80.00%) (15558/19328)
Epoch: 32 | Batch_idx: 160 |  Loss: (0.5611) |  Loss2: (0.0000) | Acc: (80.00%) (16593/20608)
Epoch: 32 | Batch_idx: 170 |  Loss: (0.5629) |  Loss2: (0.0000) | Acc: (80.00%) (17608/21888)
Epoch: 32 | Batch_idx: 180 |  Loss: (0.5624) |  Loss2: (0.0000) | Acc: (80.00%) (18631/23168)
Epoch: 32 | Batch_idx: 190 |  Loss: (0.5613) |  Loss2: (0.0000) | Acc: (80.00%) (19676/24448)
Epoch: 32 | Batch_idx: 200 |  Loss: (0.5616) |  Loss2: (0.0000) | Acc: (80.00%) (20708/25728)
Epoch: 32 | Batch_idx: 210 |  Loss: (0.5621) |  Loss2: (0.0000) | Acc: (80.00%) (21746/27008)
Epoch: 32 | Batch_idx: 220 |  Loss: (0.5630) |  Loss2: (0.0000) | Acc: (80.00%) (22757/28288)
Epoch: 32 | Batch_idx: 230 |  Loss: (0.5639) |  Loss2: (0.0000) | Acc: (80.00%) (23788/29568)
Epoch: 32 | Batch_idx: 240 |  Loss: (0.5634) |  Loss2: (0.0000) | Acc: (80.00%) (24815/30848)
Epoch: 32 | Batch_idx: 250 |  Loss: (0.5636) |  Loss2: (0.0000) | Acc: (80.00%) (25843/32128)
Epoch: 32 | Batch_idx: 260 |  Loss: (0.5635) |  Loss2: (0.0000) | Acc: (80.00%) (26876/33408)
Epoch: 32 | Batch_idx: 270 |  Loss: (0.5629) |  Loss2: (0.0000) | Acc: (80.00%) (27919/34688)
Epoch: 32 | Batch_idx: 280 |  Loss: (0.5622) |  Loss2: (0.0000) | Acc: (80.00%) (28964/35968)
Epoch: 32 | Batch_idx: 290 |  Loss: (0.5622) |  Loss2: (0.0000) | Acc: (80.00%) (29985/37248)
Epoch: 32 | Batch_idx: 300 |  Loss: (0.5619) |  Loss2: (0.0000) | Acc: (80.00%) (31031/38528)
Epoch: 32 | Batch_idx: 310 |  Loss: (0.5628) |  Loss2: (0.0000) | Acc: (80.00%) (32046/39808)
Epoch: 32 | Batch_idx: 320 |  Loss: (0.5634) |  Loss2: (0.0000) | Acc: (80.00%) (33065/41088)
Epoch: 32 | Batch_idx: 330 |  Loss: (0.5646) |  Loss2: (0.0000) | Acc: (80.00%) (34075/42368)
Epoch: 32 | Batch_idx: 340 |  Loss: (0.5649) |  Loss2: (0.0000) | Acc: (80.00%) (35113/43648)
Epoch: 32 | Batch_idx: 350 |  Loss: (0.5655) |  Loss2: (0.0000) | Acc: (80.00%) (36144/44928)
Epoch: 32 | Batch_idx: 360 |  Loss: (0.5644) |  Loss2: (0.0000) | Acc: (80.00%) (37186/46208)
Epoch: 32 | Batch_idx: 370 |  Loss: (0.5639) |  Loss2: (0.0000) | Acc: (80.00%) (38218/47488)
Epoch: 32 | Batch_idx: 380 |  Loss: (0.5634) |  Loss2: (0.0000) | Acc: (80.00%) (39260/48768)
Epoch: 32 | Batch_idx: 390 |  Loss: (0.5629) |  Loss2: (0.0000) | Acc: (80.00%) (40254/50000)
# TEST : Loss: (0.6021) | Acc: (79.00%) (7972/10000)
percent tensor([0.4908, 0.4843, 0.4781, 0.4809, 0.4796, 0.4952, 0.4826, 0.4792, 0.4865,
        0.4818, 0.4900, 0.4770, 0.4858, 0.4878, 0.4866, 0.4882],
       device='cuda:0') torch.Size([16])
percent tensor([0.5078, 0.5041, 0.5110, 0.5102, 0.5103, 0.5076, 0.5061, 0.5123, 0.5097,
        0.5051, 0.5066, 0.5057, 0.5035, 0.5102, 0.5052, 0.5076],
       device='cuda:0') torch.Size([16])
percent tensor([0.4914, 0.5022, 0.5065, 0.5025, 0.5019, 0.4826, 0.5017, 0.5038, 0.5001,
        0.5044, 0.4915, 0.5114, 0.4976, 0.5124, 0.4854, 0.4973],
       device='cuda:0') torch.Size([16])
percent tensor([0.5386, 0.5485, 0.5383, 0.5325, 0.5365, 0.5303, 0.5471, 0.5366, 0.5492,
        0.5506, 0.5515, 0.5476, 0.5473, 0.5604, 0.5338, 0.5417],
       device='cuda:0') torch.Size([16])
percent tensor([0.5287, 0.5240, 0.4717, 0.4845, 0.4648, 0.5177, 0.5109, 0.4580, 0.5293,
        0.5302, 0.5464, 0.4885, 0.5299, 0.5403, 0.4795, 0.5271],
       device='cuda:0') torch.Size([16])
percent tensor([0.5042, 0.5065, 0.5052, 0.5043, 0.5103, 0.5089, 0.5072, 0.5124, 0.5033,
        0.5065, 0.5006, 0.5020, 0.4995, 0.5053, 0.5049, 0.5085],
       device='cuda:0') torch.Size([16])
percent tensor([0.5285, 0.5592, 0.5828, 0.5672, 0.6035, 0.5609, 0.5444, 0.6115, 0.5432,
        0.5550, 0.5441, 0.5596, 0.5372, 0.5361, 0.5496, 0.5270],
       device='cuda:0') torch.Size([16])
percent tensor([0.9187, 0.8907, 0.9234, 0.9364, 0.9141, 0.9291, 0.8968, 0.9430, 0.9349,
        0.9414, 0.9498, 0.9176, 0.9426, 0.9028, 0.8941, 0.9295],
       device='cuda:0') torch.Size([16])
Epoch: 33 | Batch_idx: 0 |  Loss: (0.4889) |  Loss2: (0.0000) | Acc: (83.00%) (107/128)
Epoch: 33 | Batch_idx: 10 |  Loss: (0.5954) |  Loss2: (0.0000) | Acc: (79.00%) (1122/1408)
Epoch: 33 | Batch_idx: 20 |  Loss: (0.5704) |  Loss2: (0.0000) | Acc: (81.00%) (2181/2688)
Epoch: 33 | Batch_idx: 30 |  Loss: (0.5784) |  Loss2: (0.0000) | Acc: (80.00%) (3200/3968)
Epoch: 33 | Batch_idx: 40 |  Loss: (0.5751) |  Loss2: (0.0000) | Acc: (80.00%) (4224/5248)
Epoch: 33 | Batch_idx: 50 |  Loss: (0.5697) |  Loss2: (0.0000) | Acc: (80.00%) (5251/6528)
Epoch: 33 | Batch_idx: 60 |  Loss: (0.5704) |  Loss2: (0.0000) | Acc: (80.00%) (6272/7808)
Epoch: 33 | Batch_idx: 70 |  Loss: (0.5626) |  Loss2: (0.0000) | Acc: (80.00%) (7326/9088)
Epoch: 33 | Batch_idx: 80 |  Loss: (0.5617) |  Loss2: (0.0000) | Acc: (80.00%) (8363/10368)
Epoch: 33 | Batch_idx: 90 |  Loss: (0.5620) |  Loss2: (0.0000) | Acc: (80.00%) (9393/11648)
Epoch: 33 | Batch_idx: 100 |  Loss: (0.5636) |  Loss2: (0.0000) | Acc: (80.00%) (10404/12928)
Epoch: 33 | Batch_idx: 110 |  Loss: (0.5624) |  Loss2: (0.0000) | Acc: (80.00%) (11442/14208)
Epoch: 33 | Batch_idx: 120 |  Loss: (0.5617) |  Loss2: (0.0000) | Acc: (80.00%) (12487/15488)
Epoch: 33 | Batch_idx: 130 |  Loss: (0.5616) |  Loss2: (0.0000) | Acc: (80.00%) (13524/16768)
Epoch: 33 | Batch_idx: 140 |  Loss: (0.5590) |  Loss2: (0.0000) | Acc: (80.00%) (14562/18048)
Epoch: 33 | Batch_idx: 150 |  Loss: (0.5576) |  Loss2: (0.0000) | Acc: (80.00%) (15603/19328)
Epoch: 33 | Batch_idx: 160 |  Loss: (0.5565) |  Loss2: (0.0000) | Acc: (80.00%) (16638/20608)
Epoch: 33 | Batch_idx: 170 |  Loss: (0.5562) |  Loss2: (0.0000) | Acc: (80.00%) (17673/21888)
Epoch: 33 | Batch_idx: 180 |  Loss: (0.5569) |  Loss2: (0.0000) | Acc: (80.00%) (18707/23168)
Epoch: 33 | Batch_idx: 190 |  Loss: (0.5585) |  Loss2: (0.0000) | Acc: (80.00%) (19739/24448)
Epoch: 33 | Batch_idx: 200 |  Loss: (0.5562) |  Loss2: (0.0000) | Acc: (80.00%) (20792/25728)
Epoch: 33 | Batch_idx: 210 |  Loss: (0.5570) |  Loss2: (0.0000) | Acc: (80.00%) (21824/27008)
Epoch: 33 | Batch_idx: 220 |  Loss: (0.5586) |  Loss2: (0.0000) | Acc: (80.00%) (22849/28288)
Epoch: 33 | Batch_idx: 230 |  Loss: (0.5592) |  Loss2: (0.0000) | Acc: (80.00%) (23864/29568)
Epoch: 33 | Batch_idx: 240 |  Loss: (0.5588) |  Loss2: (0.0000) | Acc: (80.00%) (24895/30848)
Epoch: 33 | Batch_idx: 250 |  Loss: (0.5579) |  Loss2: (0.0000) | Acc: (80.00%) (25946/32128)
Epoch: 33 | Batch_idx: 260 |  Loss: (0.5576) |  Loss2: (0.0000) | Acc: (80.00%) (26984/33408)
Epoch: 33 | Batch_idx: 270 |  Loss: (0.5587) |  Loss2: (0.0000) | Acc: (80.00%) (28008/34688)
Epoch: 33 | Batch_idx: 280 |  Loss: (0.5584) |  Loss2: (0.0000) | Acc: (80.00%) (29043/35968)
Epoch: 33 | Batch_idx: 290 |  Loss: (0.5585) |  Loss2: (0.0000) | Acc: (80.00%) (30075/37248)
Epoch: 33 | Batch_idx: 300 |  Loss: (0.5573) |  Loss2: (0.0000) | Acc: (80.00%) (31117/38528)
Epoch: 33 | Batch_idx: 310 |  Loss: (0.5561) |  Loss2: (0.0000) | Acc: (80.00%) (32153/39808)
Epoch: 33 | Batch_idx: 320 |  Loss: (0.5562) |  Loss2: (0.0000) | Acc: (80.00%) (33183/41088)
Epoch: 33 | Batch_idx: 330 |  Loss: (0.5563) |  Loss2: (0.0000) | Acc: (80.00%) (34216/42368)
Epoch: 33 | Batch_idx: 340 |  Loss: (0.5558) |  Loss2: (0.0000) | Acc: (80.00%) (35244/43648)
Epoch: 33 | Batch_idx: 350 |  Loss: (0.5553) |  Loss2: (0.0000) | Acc: (80.00%) (36300/44928)
Epoch: 33 | Batch_idx: 360 |  Loss: (0.5538) |  Loss2: (0.0000) | Acc: (80.00%) (37365/46208)
Epoch: 33 | Batch_idx: 370 |  Loss: (0.5547) |  Loss2: (0.0000) | Acc: (80.00%) (38392/47488)
Epoch: 33 | Batch_idx: 380 |  Loss: (0.5541) |  Loss2: (0.0000) | Acc: (80.00%) (39430/48768)
Epoch: 33 | Batch_idx: 390 |  Loss: (0.5554) |  Loss2: (0.0000) | Acc: (80.00%) (40393/50000)
# TEST : Loss: (0.5966) | Acc: (79.00%) (7979/10000)
percent tensor([0.4925, 0.4859, 0.4801, 0.4823, 0.4816, 0.4971, 0.4844, 0.4809, 0.4883,
        0.4836, 0.4918, 0.4789, 0.4873, 0.4894, 0.4884, 0.4897],
       device='cuda:0') torch.Size([16])
percent tensor([0.5080, 0.5040, 0.5115, 0.5106, 0.5109, 0.5079, 0.5062, 0.5127, 0.5100,
        0.5051, 0.5065, 0.5059, 0.5035, 0.5102, 0.5053, 0.5077],
       device='cuda:0') torch.Size([16])
percent tensor([0.4951, 0.5054, 0.5086, 0.5051, 0.5045, 0.4867, 0.5045, 0.5063, 0.5028,
        0.5072, 0.4945, 0.5136, 0.5001, 0.5158, 0.4888, 0.5007],
       device='cuda:0') torch.Size([16])
percent tensor([0.5370, 0.5470, 0.5360, 0.5296, 0.5337, 0.5288, 0.5450, 0.5337, 0.5477,
        0.5493, 0.5502, 0.5456, 0.5464, 0.5588, 0.5317, 0.5401],
       device='cuda:0') torch.Size([16])
percent tensor([0.5255, 0.5218, 0.4687, 0.4817, 0.4623, 0.5149, 0.5079, 0.4556, 0.5284,
        0.5287, 0.5449, 0.4852, 0.5276, 0.5394, 0.4751, 0.5247],
       device='cuda:0') torch.Size([16])
percent tensor([0.5053, 0.5076, 0.5063, 0.5055, 0.5119, 0.5103, 0.5082, 0.5141, 0.5045,
        0.5076, 0.5013, 0.5026, 0.5003, 0.5063, 0.5057, 0.5099],
       device='cuda:0') torch.Size([16])
percent tensor([0.5296, 0.5618, 0.5886, 0.5724, 0.6107, 0.5675, 0.5453, 0.6194, 0.5458,
        0.5578, 0.5448, 0.5621, 0.5367, 0.5382, 0.5521, 0.5290],
       device='cuda:0') torch.Size([16])
percent tensor([0.9268, 0.9007, 0.9343, 0.9455, 0.9267, 0.9375, 0.9051, 0.9520, 0.9410,
        0.9479, 0.9549, 0.9292, 0.9481, 0.9097, 0.9069, 0.9359],
       device='cuda:0') torch.Size([16])
Epoch: 34 | Batch_idx: 0 |  Loss: (0.5378) |  Loss2: (0.0000) | Acc: (78.00%) (101/128)
Epoch: 34 | Batch_idx: 10 |  Loss: (0.5490) |  Loss2: (0.0000) | Acc: (80.00%) (1131/1408)
Epoch: 34 | Batch_idx: 20 |  Loss: (0.5482) |  Loss2: (0.0000) | Acc: (80.00%) (2163/2688)
Epoch: 34 | Batch_idx: 30 |  Loss: (0.5447) |  Loss2: (0.0000) | Acc: (80.00%) (3203/3968)
Epoch: 34 | Batch_idx: 40 |  Loss: (0.5399) |  Loss2: (0.0000) | Acc: (81.00%) (4258/5248)
Epoch: 34 | Batch_idx: 50 |  Loss: (0.5363) |  Loss2: (0.0000) | Acc: (81.00%) (5322/6528)
Epoch: 34 | Batch_idx: 60 |  Loss: (0.5331) |  Loss2: (0.0000) | Acc: (81.00%) (6366/7808)
Epoch: 34 | Batch_idx: 70 |  Loss: (0.5382) |  Loss2: (0.0000) | Acc: (81.00%) (7382/9088)
Epoch: 34 | Batch_idx: 80 |  Loss: (0.5404) |  Loss2: (0.0000) | Acc: (81.00%) (8413/10368)
Epoch: 34 | Batch_idx: 90 |  Loss: (0.5410) |  Loss2: (0.0000) | Acc: (81.00%) (9445/11648)
Epoch: 34 | Batch_idx: 100 |  Loss: (0.5429) |  Loss2: (0.0000) | Acc: (80.00%) (10468/12928)
Epoch: 34 | Batch_idx: 110 |  Loss: (0.5415) |  Loss2: (0.0000) | Acc: (81.00%) (11532/14208)
Epoch: 34 | Batch_idx: 120 |  Loss: (0.5429) |  Loss2: (0.0000) | Acc: (81.00%) (12558/15488)
Epoch: 34 | Batch_idx: 130 |  Loss: (0.5480) |  Loss2: (0.0000) | Acc: (80.00%) (13557/16768)
Epoch: 34 | Batch_idx: 140 |  Loss: (0.5481) |  Loss2: (0.0000) | Acc: (80.00%) (14601/18048)
Epoch: 34 | Batch_idx: 150 |  Loss: (0.5470) |  Loss2: (0.0000) | Acc: (80.00%) (15646/19328)
Epoch: 34 | Batch_idx: 160 |  Loss: (0.5470) |  Loss2: (0.0000) | Acc: (80.00%) (16678/20608)
Epoch: 34 | Batch_idx: 170 |  Loss: (0.5482) |  Loss2: (0.0000) | Acc: (80.00%) (17712/21888)
Epoch: 34 | Batch_idx: 180 |  Loss: (0.5481) |  Loss2: (0.0000) | Acc: (80.00%) (18757/23168)
Epoch: 34 | Batch_idx: 190 |  Loss: (0.5478) |  Loss2: (0.0000) | Acc: (80.00%) (19784/24448)
Epoch: 34 | Batch_idx: 200 |  Loss: (0.5478) |  Loss2: (0.0000) | Acc: (80.00%) (20807/25728)
Epoch: 34 | Batch_idx: 210 |  Loss: (0.5499) |  Loss2: (0.0000) | Acc: (80.00%) (21818/27008)
Epoch: 34 | Batch_idx: 220 |  Loss: (0.5501) |  Loss2: (0.0000) | Acc: (80.00%) (22863/28288)
Epoch: 34 | Batch_idx: 230 |  Loss: (0.5491) |  Loss2: (0.0000) | Acc: (80.00%) (23901/29568)
Epoch: 34 | Batch_idx: 240 |  Loss: (0.5500) |  Loss2: (0.0000) | Acc: (80.00%) (24915/30848)
Epoch: 34 | Batch_idx: 250 |  Loss: (0.5497) |  Loss2: (0.0000) | Acc: (80.00%) (25958/32128)
Epoch: 34 | Batch_idx: 260 |  Loss: (0.5507) |  Loss2: (0.0000) | Acc: (80.00%) (26991/33408)
Epoch: 34 | Batch_idx: 270 |  Loss: (0.5518) |  Loss2: (0.0000) | Acc: (80.00%) (28005/34688)
Epoch: 34 | Batch_idx: 280 |  Loss: (0.5516) |  Loss2: (0.0000) | Acc: (80.00%) (29054/35968)
Epoch: 34 | Batch_idx: 290 |  Loss: (0.5516) |  Loss2: (0.0000) | Acc: (80.00%) (30078/37248)
Epoch: 34 | Batch_idx: 300 |  Loss: (0.5498) |  Loss2: (0.0000) | Acc: (80.00%) (31134/38528)
Epoch: 34 | Batch_idx: 310 |  Loss: (0.5508) |  Loss2: (0.0000) | Acc: (80.00%) (32159/39808)
Epoch: 34 | Batch_idx: 320 |  Loss: (0.5497) |  Loss2: (0.0000) | Acc: (80.00%) (33203/41088)
Epoch: 34 | Batch_idx: 330 |  Loss: (0.5492) |  Loss2: (0.0000) | Acc: (80.00%) (34255/42368)
Epoch: 34 | Batch_idx: 340 |  Loss: (0.5503) |  Loss2: (0.0000) | Acc: (80.00%) (35270/43648)
Epoch: 34 | Batch_idx: 350 |  Loss: (0.5508) |  Loss2: (0.0000) | Acc: (80.00%) (36309/44928)
Epoch: 34 | Batch_idx: 360 |  Loss: (0.5513) |  Loss2: (0.0000) | Acc: (80.00%) (37342/46208)
Epoch: 34 | Batch_idx: 370 |  Loss: (0.5520) |  Loss2: (0.0000) | Acc: (80.00%) (38368/47488)
Epoch: 34 | Batch_idx: 380 |  Loss: (0.5534) |  Loss2: (0.0000) | Acc: (80.00%) (39381/48768)
Epoch: 34 | Batch_idx: 390 |  Loss: (0.5529) |  Loss2: (0.0000) | Acc: (80.00%) (40384/50000)
# TEST : Loss: (0.6014) | Acc: (79.00%) (7977/10000)
percent tensor([0.4925, 0.4857, 0.4794, 0.4814, 0.4812, 0.4972, 0.4842, 0.4802, 0.4882,
        0.4832, 0.4918, 0.4783, 0.4870, 0.4894, 0.4881, 0.4894],
       device='cuda:0') torch.Size([16])
percent tensor([0.5080, 0.5036, 0.5120, 0.5108, 0.5113, 0.5078, 0.5061, 0.5131, 0.5100,
        0.5048, 0.5063, 0.5060, 0.5032, 0.5104, 0.5051, 0.5076],
       device='cuda:0') torch.Size([16])
percent tensor([0.4960, 0.5069, 0.5087, 0.5055, 0.5050, 0.4871, 0.5058, 0.5065, 0.5035,
        0.5087, 0.4958, 0.5142, 0.5008, 0.5183, 0.4892, 0.5017],
       device='cuda:0') torch.Size([16])
percent tensor([0.5409, 0.5515, 0.5391, 0.5320, 0.5368, 0.5322, 0.5494, 0.5368, 0.5514,
        0.5538, 0.5551, 0.5496, 0.5510, 0.5629, 0.5354, 0.5443],
       device='cuda:0') torch.Size([16])
percent tensor([0.5239, 0.5190, 0.4662, 0.4834, 0.4606, 0.5151, 0.5060, 0.4544, 0.5271,
        0.5252, 0.5437, 0.4815, 0.5250, 0.5380, 0.4738, 0.5239],
       device='cuda:0') torch.Size([16])
percent tensor([0.5052, 0.5075, 0.5062, 0.5053, 0.5123, 0.5108, 0.5081, 0.5143, 0.5046,
        0.5077, 0.5011, 0.5026, 0.4999, 0.5065, 0.5054, 0.5099],
       device='cuda:0') torch.Size([16])
percent tensor([0.5265, 0.5599, 0.5877, 0.5716, 0.6117, 0.5704, 0.5416, 0.6185, 0.5453,
        0.5574, 0.5423, 0.5597, 0.5328, 0.5362, 0.5495, 0.5258],
       device='cuda:0') torch.Size([16])
percent tensor([0.9298, 0.9040, 0.9429, 0.9523, 0.9346, 0.9425, 0.9115, 0.9591, 0.9459,
        0.9512, 0.9589, 0.9379, 0.9519, 0.9117, 0.9129, 0.9409],
       device='cuda:0') torch.Size([16])
Epoch: 35 | Batch_idx: 0 |  Loss: (0.5036) |  Loss2: (0.0000) | Acc: (80.00%) (103/128)
Epoch: 35 | Batch_idx: 10 |  Loss: (0.5282) |  Loss2: (0.0000) | Acc: (82.00%) (1156/1408)
Epoch: 35 | Batch_idx: 20 |  Loss: (0.5268) |  Loss2: (0.0000) | Acc: (81.00%) (2193/2688)
Epoch: 35 | Batch_idx: 30 |  Loss: (0.5337) |  Loss2: (0.0000) | Acc: (80.00%) (3209/3968)
Epoch: 35 | Batch_idx: 40 |  Loss: (0.5440) |  Loss2: (0.0000) | Acc: (80.00%) (4226/5248)
Epoch: 35 | Batch_idx: 50 |  Loss: (0.5444) |  Loss2: (0.0000) | Acc: (80.00%) (5267/6528)
Epoch: 35 | Batch_idx: 60 |  Loss: (0.5495) |  Loss2: (0.0000) | Acc: (80.00%) (6298/7808)
Epoch: 35 | Batch_idx: 70 |  Loss: (0.5586) |  Loss2: (0.0000) | Acc: (80.00%) (7303/9088)
Epoch: 35 | Batch_idx: 80 |  Loss: (0.5535) |  Loss2: (0.0000) | Acc: (80.00%) (8347/10368)
Epoch: 35 | Batch_idx: 90 |  Loss: (0.5554) |  Loss2: (0.0000) | Acc: (80.00%) (9370/11648)
Epoch: 35 | Batch_idx: 100 |  Loss: (0.5550) |  Loss2: (0.0000) | Acc: (80.00%) (10398/12928)
Epoch: 35 | Batch_idx: 110 |  Loss: (0.5583) |  Loss2: (0.0000) | Acc: (80.00%) (11415/14208)
Epoch: 35 | Batch_idx: 120 |  Loss: (0.5597) |  Loss2: (0.0000) | Acc: (80.00%) (12440/15488)
Epoch: 35 | Batch_idx: 130 |  Loss: (0.5572) |  Loss2: (0.0000) | Acc: (80.00%) (13483/16768)
Epoch: 35 | Batch_idx: 140 |  Loss: (0.5580) |  Loss2: (0.0000) | Acc: (80.00%) (14522/18048)
Epoch: 35 | Batch_idx: 150 |  Loss: (0.5584) |  Loss2: (0.0000) | Acc: (80.00%) (15563/19328)
Epoch: 35 | Batch_idx: 160 |  Loss: (0.5561) |  Loss2: (0.0000) | Acc: (80.00%) (16608/20608)
Epoch: 35 | Batch_idx: 170 |  Loss: (0.5567) |  Loss2: (0.0000) | Acc: (80.00%) (17636/21888)
Epoch: 35 | Batch_idx: 180 |  Loss: (0.5565) |  Loss2: (0.0000) | Acc: (80.00%) (18671/23168)
Epoch: 35 | Batch_idx: 190 |  Loss: (0.5574) |  Loss2: (0.0000) | Acc: (80.00%) (19706/24448)
Epoch: 35 | Batch_idx: 200 |  Loss: (0.5579) |  Loss2: (0.0000) | Acc: (80.00%) (20727/25728)
Epoch: 35 | Batch_idx: 210 |  Loss: (0.5578) |  Loss2: (0.0000) | Acc: (80.00%) (21776/27008)
Epoch: 35 | Batch_idx: 220 |  Loss: (0.5580) |  Loss2: (0.0000) | Acc: (80.00%) (22808/28288)
Epoch: 35 | Batch_idx: 230 |  Loss: (0.5581) |  Loss2: (0.0000) | Acc: (80.00%) (23839/29568)
Epoch: 35 | Batch_idx: 240 |  Loss: (0.5584) |  Loss2: (0.0000) | Acc: (80.00%) (24870/30848)
Epoch: 35 | Batch_idx: 250 |  Loss: (0.5587) |  Loss2: (0.0000) | Acc: (80.00%) (25880/32128)
Epoch: 35 | Batch_idx: 260 |  Loss: (0.5585) |  Loss2: (0.0000) | Acc: (80.00%) (26915/33408)
Epoch: 35 | Batch_idx: 270 |  Loss: (0.5587) |  Loss2: (0.0000) | Acc: (80.00%) (27935/34688)
Epoch: 35 | Batch_idx: 280 |  Loss: (0.5588) |  Loss2: (0.0000) | Acc: (80.00%) (28974/35968)
Epoch: 35 | Batch_idx: 290 |  Loss: (0.5600) |  Loss2: (0.0000) | Acc: (80.00%) (29984/37248)
Epoch: 35 | Batch_idx: 300 |  Loss: (0.5608) |  Loss2: (0.0000) | Acc: (80.00%) (31002/38528)
Epoch: 35 | Batch_idx: 310 |  Loss: (0.5602) |  Loss2: (0.0000) | Acc: (80.00%) (32035/39808)
Epoch: 35 | Batch_idx: 320 |  Loss: (0.5609) |  Loss2: (0.0000) | Acc: (80.00%) (33049/41088)
Epoch: 35 | Batch_idx: 330 |  Loss: (0.5593) |  Loss2: (0.0000) | Acc: (80.00%) (34101/42368)
Epoch: 35 | Batch_idx: 340 |  Loss: (0.5592) |  Loss2: (0.0000) | Acc: (80.00%) (35132/43648)
Epoch: 35 | Batch_idx: 350 |  Loss: (0.5578) |  Loss2: (0.0000) | Acc: (80.00%) (36194/44928)
Epoch: 35 | Batch_idx: 360 |  Loss: (0.5571) |  Loss2: (0.0000) | Acc: (80.00%) (37237/46208)
Epoch: 35 | Batch_idx: 370 |  Loss: (0.5563) |  Loss2: (0.0000) | Acc: (80.00%) (38286/47488)
Epoch: 35 | Batch_idx: 380 |  Loss: (0.5554) |  Loss2: (0.0000) | Acc: (80.00%) (39323/48768)
Epoch: 35 | Batch_idx: 390 |  Loss: (0.5555) |  Loss2: (0.0000) | Acc: (80.00%) (40310/50000)
=> saving checkpoint 'drive/app/torch/save_Schedule/checkpoint_035.pth.tar'
# TEST : Loss: (0.5944) | Acc: (79.00%) (7994/10000)
percent tensor([0.4924, 0.4854, 0.4791, 0.4806, 0.4808, 0.4974, 0.4840, 0.4796, 0.4881,
        0.4829, 0.4917, 0.4779, 0.4867, 0.4892, 0.4879, 0.4892],
       device='cuda:0') torch.Size([16])
percent tensor([0.5090, 0.5046, 0.5133, 0.5118, 0.5126, 0.5086, 0.5072, 0.5146, 0.5111,
        0.5058, 0.5072, 0.5070, 0.5040, 0.5113, 0.5060, 0.5086],
       device='cuda:0') torch.Size([16])
percent tensor([0.4950, 0.5057, 0.5078, 0.5045, 0.5036, 0.4871, 0.5045, 0.5059, 0.5023,
        0.5074, 0.4941, 0.5126, 0.4992, 0.5179, 0.4885, 0.5006],
       device='cuda:0') torch.Size([16])
percent tensor([0.5402, 0.5513, 0.5377, 0.5301, 0.5350, 0.5313, 0.5484, 0.5353, 0.5506,
        0.5538, 0.5546, 0.5487, 0.5508, 0.5621, 0.5346, 0.5436],
       device='cuda:0') torch.Size([16])
percent tensor([0.5294, 0.5227, 0.4731, 0.4937, 0.4661, 0.5204, 0.5109, 0.4608, 0.5314,
        0.5289, 0.5482, 0.4858, 0.5297, 0.5417, 0.4777, 0.5289],
       device='cuda:0') torch.Size([16])
percent tensor([0.5050, 0.5068, 0.5061, 0.5054, 0.5124, 0.5113, 0.5074, 0.5139, 0.5044,
        0.5070, 0.5002, 0.5018, 0.4991, 0.5062, 0.5048, 0.5097],
       device='cuda:0') torch.Size([16])
percent tensor([0.5214, 0.5527, 0.5868, 0.5704, 0.6117, 0.5725, 0.5341, 0.6134, 0.5424,
        0.5516, 0.5362, 0.5530, 0.5259, 0.5325, 0.5425, 0.5212],
       device='cuda:0') torch.Size([16])
percent tensor([0.9304, 0.9026, 0.9463, 0.9542, 0.9365, 0.9465, 0.9109, 0.9603, 0.9463,
        0.9500, 0.9580, 0.9401, 0.9511, 0.9103, 0.9146, 0.9434],
       device='cuda:0') torch.Size([16])
True Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=128, out_features=16, bias=False)
False Linear(in_features=16, out_features=2, bias=False)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=128, out_features=16, bias=False)
False Linear(in_features=16, out_features=2, bias=False)
True Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=256, out_features=32, bias=False)
False Linear(in_features=32, out_features=2, bias=False)
True Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=256, out_features=32, bias=False)
False Linear(in_features=32, out_features=2, bias=False)
True Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=512, out_features=64, bias=False)
False Linear(in_features=64, out_features=2, bias=False)
True Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=512, out_features=64, bias=False)
False Linear(in_features=64, out_features=2, bias=False)
True Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1024, out_features=128, bias=False)
False Linear(in_features=128, out_features=2, bias=False)
True Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1024, out_features=128, bias=False)
False Linear(in_features=128, out_features=2, bias=False)
True Linear(in_features=512, out_features=10, bias=True)
Epoch: 36 | Batch_idx: 0 |  Loss: (0.4910) |  Loss2: (0.0000) | Acc: (82.00%) (105/128)
Epoch: 36 | Batch_idx: 10 |  Loss: (0.5695) |  Loss2: (0.0000) | Acc: (79.00%) (1121/1408)
Epoch: 36 | Batch_idx: 20 |  Loss: (0.5753) |  Loss2: (0.0000) | Acc: (79.00%) (2134/2688)
Epoch: 36 | Batch_idx: 30 |  Loss: (0.5939) |  Loss2: (0.0000) | Acc: (78.00%) (3125/3968)
Epoch: 36 | Batch_idx: 40 |  Loss: (0.5891) |  Loss2: (0.0000) | Acc: (79.00%) (4151/5248)
Epoch: 36 | Batch_idx: 50 |  Loss: (0.5959) |  Loss2: (0.0000) | Acc: (78.00%) (5140/6528)
Epoch: 36 | Batch_idx: 60 |  Loss: (0.5888) |  Loss2: (0.0000) | Acc: (78.00%) (6164/7808)
Epoch: 36 | Batch_idx: 70 |  Loss: (0.5806) |  Loss2: (0.0000) | Acc: (79.00%) (7197/9088)
Epoch: 36 | Batch_idx: 80 |  Loss: (0.5821) |  Loss2: (0.0000) | Acc: (79.00%) (8213/10368)
Epoch: 36 | Batch_idx: 90 |  Loss: (0.5820) |  Loss2: (0.0000) | Acc: (79.00%) (9229/11648)
Epoch: 36 | Batch_idx: 100 |  Loss: (0.5807) |  Loss2: (0.0000) | Acc: (79.00%) (10259/12928)
Epoch: 36 | Batch_idx: 110 |  Loss: (0.5764) |  Loss2: (0.0000) | Acc: (79.00%) (11312/14208)
Epoch: 36 | Batch_idx: 120 |  Loss: (0.5795) |  Loss2: (0.0000) | Acc: (79.00%) (12329/15488)
Epoch: 36 | Batch_idx: 130 |  Loss: (0.5748) |  Loss2: (0.0000) | Acc: (79.00%) (13377/16768)
Epoch: 36 | Batch_idx: 140 |  Loss: (0.5711) |  Loss2: (0.0000) | Acc: (79.00%) (14431/18048)
Epoch: 36 | Batch_idx: 150 |  Loss: (0.5671) |  Loss2: (0.0000) | Acc: (80.00%) (15488/19328)
Epoch: 36 | Batch_idx: 160 |  Loss: (0.5666) |  Loss2: (0.0000) | Acc: (80.00%) (16525/20608)
Epoch: 36 | Batch_idx: 170 |  Loss: (0.5659) |  Loss2: (0.0000) | Acc: (80.00%) (17570/21888)
Epoch: 36 | Batch_idx: 180 |  Loss: (0.5646) |  Loss2: (0.0000) | Acc: (80.00%) (18619/23168)
Epoch: 36 | Batch_idx: 190 |  Loss: (0.5647) |  Loss2: (0.0000) | Acc: (80.00%) (19639/24448)
Epoch: 36 | Batch_idx: 200 |  Loss: (0.5653) |  Loss2: (0.0000) | Acc: (80.00%) (20652/25728)
Epoch: 36 | Batch_idx: 210 |  Loss: (0.5660) |  Loss2: (0.0000) | Acc: (80.00%) (21664/27008)
Epoch: 36 | Batch_idx: 220 |  Loss: (0.5675) |  Loss2: (0.0000) | Acc: (80.00%) (22680/28288)
Epoch: 36 | Batch_idx: 230 |  Loss: (0.5671) |  Loss2: (0.0000) | Acc: (80.00%) (23712/29568)
Epoch: 36 | Batch_idx: 240 |  Loss: (0.5672) |  Loss2: (0.0000) | Acc: (80.00%) (24730/30848)
Epoch: 36 | Batch_idx: 250 |  Loss: (0.5670) |  Loss2: (0.0000) | Acc: (80.00%) (25746/32128)
Epoch: 36 | Batch_idx: 260 |  Loss: (0.5666) |  Loss2: (0.0000) | Acc: (80.00%) (26789/33408)
Epoch: 36 | Batch_idx: 270 |  Loss: (0.5676) |  Loss2: (0.0000) | Acc: (80.00%) (27813/34688)
Epoch: 36 | Batch_idx: 280 |  Loss: (0.5702) |  Loss2: (0.0000) | Acc: (80.00%) (28831/35968)
Epoch: 36 | Batch_idx: 290 |  Loss: (0.5696) |  Loss2: (0.0000) | Acc: (80.00%) (29875/37248)
Epoch: 36 | Batch_idx: 300 |  Loss: (0.5690) |  Loss2: (0.0000) | Acc: (80.00%) (30904/38528)
Epoch: 36 | Batch_idx: 310 |  Loss: (0.5691) |  Loss2: (0.0000) | Acc: (80.00%) (31919/39808)
Epoch: 36 | Batch_idx: 320 |  Loss: (0.5680) |  Loss2: (0.0000) | Acc: (80.00%) (32965/41088)
Epoch: 36 | Batch_idx: 330 |  Loss: (0.5676) |  Loss2: (0.0000) | Acc: (80.00%) (33999/42368)
Epoch: 36 | Batch_idx: 340 |  Loss: (0.5670) |  Loss2: (0.0000) | Acc: (80.00%) (35031/43648)
Epoch: 36 | Batch_idx: 350 |  Loss: (0.5675) |  Loss2: (0.0000) | Acc: (80.00%) (36044/44928)
Epoch: 36 | Batch_idx: 360 |  Loss: (0.5667) |  Loss2: (0.0000) | Acc: (80.00%) (37078/46208)
Epoch: 36 | Batch_idx: 370 |  Loss: (0.5669) |  Loss2: (0.0000) | Acc: (80.00%) (38093/47488)
Epoch: 36 | Batch_idx: 380 |  Loss: (0.5664) |  Loss2: (0.0000) | Acc: (80.00%) (39142/48768)
Epoch: 36 | Batch_idx: 390 |  Loss: (0.5669) |  Loss2: (0.0000) | Acc: (80.00%) (40111/50000)
# TEST : Loss: (0.6066) | Acc: (79.00%) (7929/10000)
percent tensor([0.4925, 0.4862, 0.4789, 0.4816, 0.4813, 0.4987, 0.4845, 0.4798, 0.4886,
        0.4839, 0.4926, 0.4782, 0.4867, 0.4910, 0.4893, 0.4901],
       device='cuda:0') torch.Size([16])
percent tensor([0.5093, 0.5039, 0.5132, 0.5123, 0.5119, 0.5109, 0.5065, 0.5146, 0.5110,
        0.5050, 0.5075, 0.5066, 0.5033, 0.5102, 0.5068, 0.5084],
       device='cuda:0') torch.Size([16])
percent tensor([0.4960, 0.5061, 0.5021, 0.5033, 0.4977, 0.4877, 0.5028, 0.5084, 0.5029,
        0.5067, 0.4983, 0.5048, 0.5004, 0.5150, 0.4914, 0.5033],
       device='cuda:0') torch.Size([16])
percent tensor([0.5414, 0.5531, 0.5371, 0.5312, 0.5348, 0.5329, 0.5503, 0.5384, 0.5503,
        0.5536, 0.5555, 0.5438, 0.5500, 0.5627, 0.5367, 0.5461],
       device='cuda:0') torch.Size([16])
percent tensor([0.5289, 0.5245, 0.4746, 0.4970, 0.4691, 0.5233, 0.5111, 0.4646, 0.5347,
        0.5303, 0.5470, 0.4819, 0.5273, 0.5455, 0.4829, 0.5316],
       device='cuda:0') torch.Size([16])
percent tensor([0.5049, 0.5079, 0.5039, 0.5034, 0.5108, 0.5140, 0.5076, 0.5129, 0.5069,
        0.5070, 0.5014, 0.5010, 0.5021, 0.5067, 0.5052, 0.5113],
       device='cuda:0') torch.Size([16])
percent tensor([0.5206, 0.5558, 0.5761, 0.5696, 0.5948, 0.5777, 0.5253, 0.6046, 0.5533,
        0.5563, 0.5374, 0.5432, 0.5366, 0.5372, 0.5460, 0.5298],
       device='cuda:0') torch.Size([16])
percent tensor([0.9291, 0.9057, 0.9464, 0.9570, 0.9328, 0.9461, 0.9060, 0.9591, 0.9467,
        0.9448, 0.9515, 0.9464, 0.9578, 0.9091, 0.9212, 0.9244],
       device='cuda:0') torch.Size([16])
Epoch: 37 | Batch_idx: 0 |  Loss: (0.5383) |  Loss2: (0.0000) | Acc: (80.00%) (103/128)
Epoch: 37 | Batch_idx: 10 |  Loss: (0.5507) |  Loss2: (0.0000) | Acc: (80.00%) (1136/1408)
Epoch: 37 | Batch_idx: 20 |  Loss: (0.5392) |  Loss2: (0.0000) | Acc: (81.00%) (2187/2688)
Epoch: 37 | Batch_idx: 30 |  Loss: (0.5484) |  Loss2: (0.0000) | Acc: (81.00%) (3222/3968)
Epoch: 37 | Batch_idx: 40 |  Loss: (0.5407) |  Loss2: (0.0000) | Acc: (81.00%) (4261/5248)
Epoch: 37 | Batch_idx: 50 |  Loss: (0.5343) |  Loss2: (0.0000) | Acc: (81.00%) (5297/6528)
Epoch: 37 | Batch_idx: 60 |  Loss: (0.5370) |  Loss2: (0.0000) | Acc: (81.00%) (6327/7808)
Epoch: 37 | Batch_idx: 70 |  Loss: (0.5393) |  Loss2: (0.0000) | Acc: (80.00%) (7352/9088)
Epoch: 37 | Batch_idx: 80 |  Loss: (0.5365) |  Loss2: (0.0000) | Acc: (81.00%) (8415/10368)
Epoch: 37 | Batch_idx: 90 |  Loss: (0.5350) |  Loss2: (0.0000) | Acc: (81.00%) (9467/11648)
Epoch: 37 | Batch_idx: 100 |  Loss: (0.5331) |  Loss2: (0.0000) | Acc: (81.00%) (10518/12928)
Epoch: 37 | Batch_idx: 110 |  Loss: (0.5298) |  Loss2: (0.0000) | Acc: (81.00%) (11570/14208)
Epoch: 37 | Batch_idx: 120 |  Loss: (0.5342) |  Loss2: (0.0000) | Acc: (81.00%) (12581/15488)
Epoch: 37 | Batch_idx: 130 |  Loss: (0.5382) |  Loss2: (0.0000) | Acc: (81.00%) (13613/16768)
Epoch: 37 | Batch_idx: 140 |  Loss: (0.5373) |  Loss2: (0.0000) | Acc: (81.00%) (14679/18048)
Epoch: 37 | Batch_idx: 150 |  Loss: (0.5363) |  Loss2: (0.0000) | Acc: (81.00%) (15735/19328)
Epoch: 37 | Batch_idx: 160 |  Loss: (0.5364) |  Loss2: (0.0000) | Acc: (81.00%) (16784/20608)
Epoch: 37 | Batch_idx: 170 |  Loss: (0.5364) |  Loss2: (0.0000) | Acc: (81.00%) (17836/21888)
Epoch: 37 | Batch_idx: 180 |  Loss: (0.5369) |  Loss2: (0.0000) | Acc: (81.00%) (18865/23168)
Epoch: 37 | Batch_idx: 190 |  Loss: (0.5371) |  Loss2: (0.0000) | Acc: (81.00%) (19910/24448)
Epoch: 37 | Batch_idx: 200 |  Loss: (0.5381) |  Loss2: (0.0000) | Acc: (81.00%) (20936/25728)
Epoch: 37 | Batch_idx: 210 |  Loss: (0.5380) |  Loss2: (0.0000) | Acc: (81.00%) (21967/27008)
Epoch: 37 | Batch_idx: 220 |  Loss: (0.5388) |  Loss2: (0.0000) | Acc: (81.00%) (23000/28288)
Epoch: 37 | Batch_idx: 230 |  Loss: (0.5390) |  Loss2: (0.0000) | Acc: (81.00%) (24049/29568)
Epoch: 37 | Batch_idx: 240 |  Loss: (0.5372) |  Loss2: (0.0000) | Acc: (81.00%) (25110/30848)
Epoch: 37 | Batch_idx: 250 |  Loss: (0.5360) |  Loss2: (0.0000) | Acc: (81.00%) (26166/32128)
Epoch: 37 | Batch_idx: 260 |  Loss: (0.5363) |  Loss2: (0.0000) | Acc: (81.00%) (27215/33408)
Epoch: 37 | Batch_idx: 270 |  Loss: (0.5360) |  Loss2: (0.0000) | Acc: (81.00%) (28265/34688)
Epoch: 37 | Batch_idx: 280 |  Loss: (0.5363) |  Loss2: (0.0000) | Acc: (81.00%) (29289/35968)
Epoch: 37 | Batch_idx: 290 |  Loss: (0.5366) |  Loss2: (0.0000) | Acc: (81.00%) (30328/37248)
Epoch: 37 | Batch_idx: 300 |  Loss: (0.5366) |  Loss2: (0.0000) | Acc: (81.00%) (31364/38528)
Epoch: 37 | Batch_idx: 310 |  Loss: (0.5359) |  Loss2: (0.0000) | Acc: (81.00%) (32417/39808)
Epoch: 37 | Batch_idx: 320 |  Loss: (0.5360) |  Loss2: (0.0000) | Acc: (81.00%) (33444/41088)
Epoch: 37 | Batch_idx: 330 |  Loss: (0.5363) |  Loss2: (0.0000) | Acc: (81.00%) (34481/42368)
Epoch: 37 | Batch_idx: 340 |  Loss: (0.5374) |  Loss2: (0.0000) | Acc: (81.00%) (35497/43648)
Epoch: 37 | Batch_idx: 350 |  Loss: (0.5365) |  Loss2: (0.0000) | Acc: (81.00%) (36567/44928)
Epoch: 37 | Batch_idx: 360 |  Loss: (0.5356) |  Loss2: (0.0000) | Acc: (81.00%) (37624/46208)
Epoch: 37 | Batch_idx: 370 |  Loss: (0.5354) |  Loss2: (0.0000) | Acc: (81.00%) (38675/47488)
Epoch: 37 | Batch_idx: 380 |  Loss: (0.5360) |  Loss2: (0.0000) | Acc: (81.00%) (39728/48768)
Epoch: 37 | Batch_idx: 390 |  Loss: (0.5354) |  Loss2: (0.0000) | Acc: (81.00%) (40747/50000)
# TEST : Loss: (0.5675) | Acc: (80.00%) (8088/10000)
percent tensor([0.4930, 0.4849, 0.4818, 0.4825, 0.4831, 0.4991, 0.4846, 0.4807, 0.4888,
        0.4841, 0.4920, 0.4803, 0.4870, 0.4881, 0.4890, 0.4900],
       device='cuda:0') torch.Size([16])
percent tensor([0.5097, 0.5035, 0.5152, 0.5136, 0.5131, 0.5104, 0.5069, 0.5152, 0.5106,
        0.5056, 0.5072, 0.5080, 0.5036, 0.5093, 0.5068, 0.5092],
       device='cuda:0') torch.Size([16])
percent tensor([0.4963, 0.5086, 0.5051, 0.5075, 0.5013, 0.4913, 0.5051, 0.5074, 0.5018,
        0.5091, 0.4964, 0.5086, 0.4996, 0.5188, 0.4935, 0.5036],
       device='cuda:0') torch.Size([16])
percent tensor([0.5405, 0.5537, 0.5391, 0.5314, 0.5345, 0.5351, 0.5506, 0.5373, 0.5502,
        0.5539, 0.5554, 0.5478, 0.5504, 0.5636, 0.5367, 0.5458],
       device='cuda:0') torch.Size([16])
percent tensor([0.5278, 0.5260, 0.4950, 0.5045, 0.4789, 0.5249, 0.5171, 0.4701, 0.5378,
        0.5288, 0.5471, 0.5004, 0.5293, 0.5446, 0.4797, 0.5287],
       device='cuda:0') torch.Size([16])
percent tensor([0.5054, 0.5088, 0.5045, 0.5034, 0.5105, 0.5153, 0.5067, 0.5104, 0.5052,
        0.5090, 0.5025, 0.5011, 0.5019, 0.5092, 0.5059, 0.5118],
       device='cuda:0') torch.Size([16])
percent tensor([0.5195, 0.5548, 0.5798, 0.5705, 0.6001, 0.5791, 0.5276, 0.5940, 0.5446,
        0.5502, 0.5315, 0.5395, 0.5229, 0.5354, 0.5527, 0.5283],
       device='cuda:0') torch.Size([16])
percent tensor([0.9453, 0.8985, 0.9377, 0.9532, 0.9297, 0.9430, 0.9208, 0.9589, 0.9413,
        0.9295, 0.9567, 0.9414, 0.9493, 0.9001, 0.9355, 0.9439],
       device='cuda:0') torch.Size([16])
Epoch: 38 | Batch_idx: 0 |  Loss: (0.4832) |  Loss2: (0.0000) | Acc: (84.00%) (108/128)
Epoch: 38 | Batch_idx: 10 |  Loss: (0.5336) |  Loss2: (0.0000) | Acc: (82.00%) (1155/1408)
Epoch: 38 | Batch_idx: 20 |  Loss: (0.5170) |  Loss2: (0.0000) | Acc: (82.00%) (2213/2688)
Epoch: 38 | Batch_idx: 30 |  Loss: (0.4985) |  Loss2: (0.0000) | Acc: (82.00%) (3287/3968)
Epoch: 38 | Batch_idx: 40 |  Loss: (0.5068) |  Loss2: (0.0000) | Acc: (82.00%) (4337/5248)
Epoch: 38 | Batch_idx: 50 |  Loss: (0.5034) |  Loss2: (0.0000) | Acc: (82.00%) (5397/6528)
Epoch: 38 | Batch_idx: 60 |  Loss: (0.5022) |  Loss2: (0.0000) | Acc: (82.00%) (6457/7808)
Epoch: 38 | Batch_idx: 70 |  Loss: (0.5046) |  Loss2: (0.0000) | Acc: (82.00%) (7513/9088)
Epoch: 38 | Batch_idx: 80 |  Loss: (0.5065) |  Loss2: (0.0000) | Acc: (82.00%) (8556/10368)
Epoch: 38 | Batch_idx: 90 |  Loss: (0.5156) |  Loss2: (0.0000) | Acc: (82.00%) (9572/11648)
Epoch: 38 | Batch_idx: 100 |  Loss: (0.5156) |  Loss2: (0.0000) | Acc: (82.00%) (10634/12928)
Epoch: 38 | Batch_idx: 110 |  Loss: (0.5150) |  Loss2: (0.0000) | Acc: (82.00%) (11684/14208)
Epoch: 38 | Batch_idx: 120 |  Loss: (0.5159) |  Loss2: (0.0000) | Acc: (82.00%) (12743/15488)
Epoch: 38 | Batch_idx: 130 |  Loss: (0.5141) |  Loss2: (0.0000) | Acc: (82.00%) (13793/16768)
Epoch: 38 | Batch_idx: 140 |  Loss: (0.5175) |  Loss2: (0.0000) | Acc: (82.00%) (14815/18048)
Epoch: 38 | Batch_idx: 150 |  Loss: (0.5191) |  Loss2: (0.0000) | Acc: (82.00%) (15858/19328)
Epoch: 38 | Batch_idx: 160 |  Loss: (0.5207) |  Loss2: (0.0000) | Acc: (82.00%) (16902/20608)
Epoch: 38 | Batch_idx: 170 |  Loss: (0.5191) |  Loss2: (0.0000) | Acc: (82.00%) (17966/21888)
Epoch: 38 | Batch_idx: 180 |  Loss: (0.5176) |  Loss2: (0.0000) | Acc: (82.00%) (19021/23168)
Epoch: 38 | Batch_idx: 190 |  Loss: (0.5180) |  Loss2: (0.0000) | Acc: (82.00%) (20067/24448)
Epoch: 38 | Batch_idx: 200 |  Loss: (0.5182) |  Loss2: (0.0000) | Acc: (82.00%) (21128/25728)
Epoch: 38 | Batch_idx: 210 |  Loss: (0.5172) |  Loss2: (0.0000) | Acc: (82.00%) (22196/27008)
Epoch: 38 | Batch_idx: 220 |  Loss: (0.5177) |  Loss2: (0.0000) | Acc: (82.00%) (23237/28288)
Epoch: 38 | Batch_idx: 230 |  Loss: (0.5186) |  Loss2: (0.0000) | Acc: (82.00%) (24272/29568)
Epoch: 38 | Batch_idx: 240 |  Loss: (0.5177) |  Loss2: (0.0000) | Acc: (82.00%) (25342/30848)
Epoch: 38 | Batch_idx: 250 |  Loss: (0.5178) |  Loss2: (0.0000) | Acc: (82.00%) (26395/32128)
Epoch: 38 | Batch_idx: 260 |  Loss: (0.5177) |  Loss2: (0.0000) | Acc: (82.00%) (27446/33408)
Epoch: 38 | Batch_idx: 270 |  Loss: (0.5181) |  Loss2: (0.0000) | Acc: (82.00%) (28494/34688)
Epoch: 38 | Batch_idx: 280 |  Loss: (0.5174) |  Loss2: (0.0000) | Acc: (82.00%) (29555/35968)
Epoch: 38 | Batch_idx: 290 |  Loss: (0.5158) |  Loss2: (0.0000) | Acc: (82.00%) (30631/37248)
Epoch: 38 | Batch_idx: 300 |  Loss: (0.5153) |  Loss2: (0.0000) | Acc: (82.00%) (31683/38528)
Epoch: 38 | Batch_idx: 310 |  Loss: (0.5161) |  Loss2: (0.0000) | Acc: (82.00%) (32715/39808)
Epoch: 38 | Batch_idx: 320 |  Loss: (0.5161) |  Loss2: (0.0000) | Acc: (82.00%) (33774/41088)
Epoch: 38 | Batch_idx: 330 |  Loss: (0.5146) |  Loss2: (0.0000) | Acc: (82.00%) (34855/42368)
Epoch: 38 | Batch_idx: 340 |  Loss: (0.5148) |  Loss2: (0.0000) | Acc: (82.00%) (35910/43648)
Epoch: 38 | Batch_idx: 350 |  Loss: (0.5164) |  Loss2: (0.0000) | Acc: (82.00%) (36937/44928)
Epoch: 38 | Batch_idx: 360 |  Loss: (0.5161) |  Loss2: (0.0000) | Acc: (82.00%) (37996/46208)
Epoch: 38 | Batch_idx: 370 |  Loss: (0.5151) |  Loss2: (0.0000) | Acc: (82.00%) (39080/47488)
Epoch: 38 | Batch_idx: 380 |  Loss: (0.5160) |  Loss2: (0.0000) | Acc: (82.00%) (40121/48768)
Epoch: 38 | Batch_idx: 390 |  Loss: (0.5160) |  Loss2: (0.0000) | Acc: (82.00%) (41122/50000)
# TEST : Loss: (0.6692) | Acc: (77.00%) (7784/10000)
percent tensor([0.4932, 0.4851, 0.4824, 0.4828, 0.4838, 0.4993, 0.4849, 0.4812, 0.4892,
        0.4842, 0.4920, 0.4808, 0.4868, 0.4891, 0.4888, 0.4900],
       device='cuda:0') torch.Size([16])
percent tensor([0.5100, 0.5047, 0.5147, 0.5122, 0.5131, 0.5104, 0.5081, 0.5147, 0.5114,
        0.5068, 0.5085, 0.5092, 0.5041, 0.5113, 0.5068, 0.5091],
       device='cuda:0') torch.Size([16])
percent tensor([0.4973, 0.5090, 0.5036, 0.5058, 0.5017, 0.4904, 0.5062, 0.5090, 0.5051,
        0.5082, 0.4997, 0.5065, 0.5008, 0.5195, 0.4922, 0.5035],
       device='cuda:0') torch.Size([16])
percent tensor([0.5409, 0.5540, 0.5380, 0.5301, 0.5353, 0.5322, 0.5515, 0.5359, 0.5513,
        0.5540, 0.5557, 0.5447, 0.5502, 0.5619, 0.5366, 0.5443],
       device='cuda:0') torch.Size([16])
percent tensor([0.5277, 0.5200, 0.4910, 0.5000, 0.4815, 0.5213, 0.5103, 0.4668, 0.5373,
        0.5274, 0.5469, 0.4930, 0.5288, 0.5411, 0.4730, 0.5262],
       device='cuda:0') torch.Size([16])
percent tensor([0.5045, 0.5090, 0.5043, 0.5023, 0.5104, 0.5124, 0.5079, 0.5126, 0.5066,
        0.5076, 0.5018, 0.5015, 0.5015, 0.5103, 0.5058, 0.5121],
       device='cuda:0') torch.Size([16])
percent tensor([0.5202, 0.5646, 0.5766, 0.5616, 0.5911, 0.5820, 0.5264, 0.5940, 0.5504,
        0.5549, 0.5348, 0.5411, 0.5363, 0.5442, 0.5505, 0.5329],
       device='cuda:0') torch.Size([16])
percent tensor([0.9388, 0.9089, 0.9231, 0.9539, 0.9342, 0.9497, 0.9095, 0.9553, 0.9403,
        0.9418, 0.9601, 0.9199, 0.9513, 0.8983, 0.9424, 0.9486],
       device='cuda:0') torch.Size([16])
Epoch: 39 | Batch_idx: 0 |  Loss: (0.6310) |  Loss2: (0.0000) | Acc: (78.00%) (100/128)
Epoch: 39 | Batch_idx: 10 |  Loss: (0.4832) |  Loss2: (0.0000) | Acc: (83.00%) (1180/1408)
Epoch: 39 | Batch_idx: 20 |  Loss: (0.4761) |  Loss2: (0.0000) | Acc: (83.00%) (2257/2688)
Epoch: 39 | Batch_idx: 30 |  Loss: (0.4841) |  Loss2: (0.0000) | Acc: (83.00%) (3322/3968)
Epoch: 39 | Batch_idx: 40 |  Loss: (0.4823) |  Loss2: (0.0000) | Acc: (83.00%) (4389/5248)
Epoch: 39 | Batch_idx: 50 |  Loss: (0.4870) |  Loss2: (0.0000) | Acc: (83.00%) (5457/6528)
Epoch: 39 | Batch_idx: 60 |  Loss: (0.4876) |  Loss2: (0.0000) | Acc: (83.00%) (6522/7808)
Epoch: 39 | Batch_idx: 70 |  Loss: (0.4878) |  Loss2: (0.0000) | Acc: (83.00%) (7586/9088)
Epoch: 39 | Batch_idx: 80 |  Loss: (0.4938) |  Loss2: (0.0000) | Acc: (83.00%) (8630/10368)
Epoch: 39 | Batch_idx: 90 |  Loss: (0.4933) |  Loss2: (0.0000) | Acc: (83.00%) (9699/11648)
Epoch: 39 | Batch_idx: 100 |  Loss: (0.4940) |  Loss2: (0.0000) | Acc: (83.00%) (10752/12928)
Epoch: 39 | Batch_idx: 110 |  Loss: (0.4938) |  Loss2: (0.0000) | Acc: (83.00%) (11809/14208)
Epoch: 39 | Batch_idx: 120 |  Loss: (0.4945) |  Loss2: (0.0000) | Acc: (83.00%) (12874/15488)
Epoch: 39 | Batch_idx: 130 |  Loss: (0.4951) |  Loss2: (0.0000) | Acc: (83.00%) (13932/16768)
Epoch: 39 | Batch_idx: 140 |  Loss: (0.4950) |  Loss2: (0.0000) | Acc: (83.00%) (14998/18048)
Epoch: 39 | Batch_idx: 150 |  Loss: (0.4958) |  Loss2: (0.0000) | Acc: (83.00%) (16045/19328)
Epoch: 39 | Batch_idx: 160 |  Loss: (0.4961) |  Loss2: (0.0000) | Acc: (82.00%) (17088/20608)
Epoch: 39 | Batch_idx: 170 |  Loss: (0.4962) |  Loss2: (0.0000) | Acc: (82.00%) (18160/21888)
Epoch: 39 | Batch_idx: 180 |  Loss: (0.4958) |  Loss2: (0.0000) | Acc: (82.00%) (19219/23168)
Epoch: 39 | Batch_idx: 190 |  Loss: (0.4953) |  Loss2: (0.0000) | Acc: (82.00%) (20277/24448)
Epoch: 39 | Batch_idx: 200 |  Loss: (0.4969) |  Loss2: (0.0000) | Acc: (82.00%) (21325/25728)
Epoch: 39 | Batch_idx: 210 |  Loss: (0.4961) |  Loss2: (0.0000) | Acc: (82.00%) (22399/27008)
Epoch: 39 | Batch_idx: 220 |  Loss: (0.4973) |  Loss2: (0.0000) | Acc: (82.00%) (23434/28288)
Epoch: 39 | Batch_idx: 230 |  Loss: (0.4994) |  Loss2: (0.0000) | Acc: (82.00%) (24472/29568)
Epoch: 39 | Batch_idx: 240 |  Loss: (0.5001) |  Loss2: (0.0000) | Acc: (82.00%) (25511/30848)
Epoch: 39 | Batch_idx: 250 |  Loss: (0.4990) |  Loss2: (0.0000) | Acc: (82.00%) (26583/32128)
Epoch: 39 | Batch_idx: 260 |  Loss: (0.4992) |  Loss2: (0.0000) | Acc: (82.00%) (27639/33408)
Epoch: 39 | Batch_idx: 270 |  Loss: (0.5007) |  Loss2: (0.0000) | Acc: (82.00%) (28683/34688)
Epoch: 39 | Batch_idx: 280 |  Loss: (0.4993) |  Loss2: (0.0000) | Acc: (82.00%) (29749/35968)
Epoch: 39 | Batch_idx: 290 |  Loss: (0.4992) |  Loss2: (0.0000) | Acc: (82.00%) (30801/37248)
Epoch: 39 | Batch_idx: 300 |  Loss: (0.4991) |  Loss2: (0.0000) | Acc: (82.00%) (31877/38528)
Epoch: 39 | Batch_idx: 310 |  Loss: (0.4999) |  Loss2: (0.0000) | Acc: (82.00%) (32926/39808)
Epoch: 39 | Batch_idx: 320 |  Loss: (0.4984) |  Loss2: (0.0000) | Acc: (82.00%) (34024/41088)
Epoch: 39 | Batch_idx: 330 |  Loss: (0.4979) |  Loss2: (0.0000) | Acc: (82.00%) (35093/42368)
Epoch: 39 | Batch_idx: 340 |  Loss: (0.4976) |  Loss2: (0.0000) | Acc: (82.00%) (36157/43648)
Epoch: 39 | Batch_idx: 350 |  Loss: (0.4966) |  Loss2: (0.0000) | Acc: (82.00%) (37237/44928)
Epoch: 39 | Batch_idx: 360 |  Loss: (0.4955) |  Loss2: (0.0000) | Acc: (82.00%) (38319/46208)
Epoch: 39 | Batch_idx: 370 |  Loss: (0.4965) |  Loss2: (0.0000) | Acc: (82.00%) (39373/47488)
Epoch: 39 | Batch_idx: 380 |  Loss: (0.4971) |  Loss2: (0.0000) | Acc: (82.00%) (40424/48768)
Epoch: 39 | Batch_idx: 390 |  Loss: (0.4966) |  Loss2: (0.0000) | Acc: (82.00%) (41460/50000)
# TEST : Loss: (0.7384) | Acc: (76.00%) (7602/10000)
percent tensor([0.4921, 0.4863, 0.4785, 0.4822, 0.4806, 0.4989, 0.4837, 0.4805, 0.4885,
        0.4832, 0.4922, 0.4774, 0.4862, 0.4911, 0.4893, 0.4899],
       device='cuda:0') torch.Size([16])
percent tensor([0.5093, 0.5036, 0.5157, 0.5119, 0.5138, 0.5102, 0.5074, 0.5141, 0.5107,
        0.5059, 0.5072, 0.5089, 0.5033, 0.5092, 0.5064, 0.5081],
       device='cuda:0') torch.Size([16])
percent tensor([0.4977, 0.5096, 0.5057, 0.5084, 0.5031, 0.4915, 0.5080, 0.5095, 0.5043,
        0.5113, 0.4993, 0.5095, 0.4996, 0.5228, 0.4941, 0.5064],
       device='cuda:0') torch.Size([16])
percent tensor([0.5427, 0.5568, 0.5390, 0.5355, 0.5367, 0.5360, 0.5547, 0.5377, 0.5541,
        0.5582, 0.5591, 0.5508, 0.5536, 0.5687, 0.5388, 0.5488],
       device='cuda:0') torch.Size([16])
percent tensor([0.5281, 0.5271, 0.4844, 0.5061, 0.4736, 0.5223, 0.5185, 0.4657, 0.5406,
        0.5319, 0.5487, 0.4961, 0.5320, 0.5482, 0.4853, 0.5306],
       device='cuda:0') torch.Size([16])
percent tensor([0.5064, 0.5082, 0.5043, 0.5037, 0.5116, 0.5149, 0.5089, 0.5119, 0.5065,
        0.5070, 0.5038, 0.5027, 0.5030, 0.5093, 0.5071, 0.5123],
       device='cuda:0') torch.Size([16])
percent tensor([0.5236, 0.5655, 0.5782, 0.5674, 0.5996, 0.5809, 0.5368, 0.6018, 0.5522,
        0.5539, 0.5439, 0.5437, 0.5379, 0.5527, 0.5514, 0.5329],
       device='cuda:0') torch.Size([16])
percent tensor([0.9163, 0.9132, 0.9256, 0.9425, 0.9268, 0.9419, 0.9040, 0.9448, 0.9287,
        0.9280, 0.9472, 0.9128, 0.9267, 0.8874, 0.9261, 0.9157],
       device='cuda:0') torch.Size([16])
Epoch: 40 | Batch_idx: 0 |  Loss: (0.4298) |  Loss2: (0.0000) | Acc: (87.00%) (112/128)
Epoch: 40 | Batch_idx: 10 |  Loss: (0.4865) |  Loss2: (0.0000) | Acc: (82.00%) (1161/1408)
Epoch: 40 | Batch_idx: 20 |  Loss: (0.4818) |  Loss2: (0.0000) | Acc: (82.00%) (2216/2688)
Epoch: 40 | Batch_idx: 30 |  Loss: (0.4710) |  Loss2: (0.0000) | Acc: (83.00%) (3302/3968)
Epoch: 40 | Batch_idx: 40 |  Loss: (0.4702) |  Loss2: (0.0000) | Acc: (83.00%) (4371/5248)
Epoch: 40 | Batch_idx: 50 |  Loss: (0.4749) |  Loss2: (0.0000) | Acc: (83.00%) (5429/6528)
Epoch: 40 | Batch_idx: 60 |  Loss: (0.4796) |  Loss2: (0.0000) | Acc: (82.00%) (6476/7808)
Epoch: 40 | Batch_idx: 70 |  Loss: (0.4792) |  Loss2: (0.0000) | Acc: (82.00%) (7543/9088)
Epoch: 40 | Batch_idx: 80 |  Loss: (0.4824) |  Loss2: (0.0000) | Acc: (82.00%) (8601/10368)
Epoch: 40 | Batch_idx: 90 |  Loss: (0.4872) |  Loss2: (0.0000) | Acc: (82.00%) (9644/11648)
Epoch: 40 | Batch_idx: 100 |  Loss: (0.4868) |  Loss2: (0.0000) | Acc: (82.00%) (10716/12928)
Epoch: 40 | Batch_idx: 110 |  Loss: (0.4863) |  Loss2: (0.0000) | Acc: (82.00%) (11774/14208)
Epoch: 40 | Batch_idx: 120 |  Loss: (0.4844) |  Loss2: (0.0000) | Acc: (82.00%) (12849/15488)
Epoch: 40 | Batch_idx: 130 |  Loss: (0.4836) |  Loss2: (0.0000) | Acc: (82.00%) (13907/16768)
Epoch: 40 | Batch_idx: 140 |  Loss: (0.4842) |  Loss2: (0.0000) | Acc: (82.00%) (14973/18048)
Epoch: 40 | Batch_idx: 150 |  Loss: (0.4878) |  Loss2: (0.0000) | Acc: (82.00%) (16017/19328)
Epoch: 40 | Batch_idx: 160 |  Loss: (0.4863) |  Loss2: (0.0000) | Acc: (82.00%) (17099/20608)
Epoch: 40 | Batch_idx: 170 |  Loss: (0.4863) |  Loss2: (0.0000) | Acc: (82.00%) (18161/21888)
Epoch: 40 | Batch_idx: 180 |  Loss: (0.4856) |  Loss2: (0.0000) | Acc: (82.00%) (19228/23168)
Epoch: 40 | Batch_idx: 190 |  Loss: (0.4859) |  Loss2: (0.0000) | Acc: (83.00%) (20293/24448)
Epoch: 40 | Batch_idx: 200 |  Loss: (0.4868) |  Loss2: (0.0000) | Acc: (82.00%) (21354/25728)
Epoch: 40 | Batch_idx: 210 |  Loss: (0.4876) |  Loss2: (0.0000) | Acc: (82.00%) (22413/27008)
Epoch: 40 | Batch_idx: 220 |  Loss: (0.4871) |  Loss2: (0.0000) | Acc: (83.00%) (23485/28288)
Epoch: 40 | Batch_idx: 230 |  Loss: (0.4860) |  Loss2: (0.0000) | Acc: (83.00%) (24553/29568)
Epoch: 40 | Batch_idx: 240 |  Loss: (0.4862) |  Loss2: (0.0000) | Acc: (83.00%) (25614/30848)
Epoch: 40 | Batch_idx: 250 |  Loss: (0.4854) |  Loss2: (0.0000) | Acc: (83.00%) (26685/32128)
Epoch: 40 | Batch_idx: 260 |  Loss: (0.4848) |  Loss2: (0.0000) | Acc: (83.00%) (27757/33408)
Epoch: 40 | Batch_idx: 270 |  Loss: (0.4854) |  Loss2: (0.0000) | Acc: (83.00%) (28821/34688)
Epoch: 40 | Batch_idx: 280 |  Loss: (0.4863) |  Loss2: (0.0000) | Acc: (83.00%) (29867/35968)
Epoch: 40 | Batch_idx: 290 |  Loss: (0.4875) |  Loss2: (0.0000) | Acc: (83.00%) (30925/37248)
Epoch: 40 | Batch_idx: 300 |  Loss: (0.4871) |  Loss2: (0.0000) | Acc: (83.00%) (31991/38528)
Epoch: 40 | Batch_idx: 310 |  Loss: (0.4866) |  Loss2: (0.0000) | Acc: (83.00%) (33066/39808)
Epoch: 40 | Batch_idx: 320 |  Loss: (0.4868) |  Loss2: (0.0000) | Acc: (83.00%) (34117/41088)
Epoch: 40 | Batch_idx: 330 |  Loss: (0.4854) |  Loss2: (0.0000) | Acc: (83.00%) (35201/42368)
Epoch: 40 | Batch_idx: 340 |  Loss: (0.4850) |  Loss2: (0.0000) | Acc: (83.00%) (36258/43648)
Epoch: 40 | Batch_idx: 350 |  Loss: (0.4843) |  Loss2: (0.0000) | Acc: (83.00%) (37338/44928)
Epoch: 40 | Batch_idx: 360 |  Loss: (0.4839) |  Loss2: (0.0000) | Acc: (83.00%) (38411/46208)
Epoch: 40 | Batch_idx: 370 |  Loss: (0.4841) |  Loss2: (0.0000) | Acc: (83.00%) (39482/47488)
Epoch: 40 | Batch_idx: 380 |  Loss: (0.4832) |  Loss2: (0.0000) | Acc: (83.00%) (40565/48768)
Epoch: 40 | Batch_idx: 390 |  Loss: (0.4829) |  Loss2: (0.0000) | Acc: (83.00%) (41601/50000)
=> saving checkpoint 'drive/app/torch/save_Schedule/checkpoint_040.pth.tar'
# TEST : Loss: (0.6427) | Acc: (78.00%) (7877/10000)
percent tensor([0.4928, 0.4852, 0.4813, 0.4821, 0.4829, 0.4995, 0.4848, 0.4810, 0.4891,
        0.4840, 0.4925, 0.4803, 0.4867, 0.4897, 0.4891, 0.4900],
       device='cuda:0') torch.Size([16])
percent tensor([0.5095, 0.5044, 0.5142, 0.5129, 0.5124, 0.5109, 0.5077, 0.5144, 0.5115,
        0.5063, 0.5081, 0.5084, 0.5043, 0.5104, 0.5074, 0.5091],
       device='cuda:0') torch.Size([16])
percent tensor([0.4965, 0.5078, 0.5019, 0.5056, 0.5004, 0.4911, 0.5041, 0.5067, 0.5034,
        0.5076, 0.4981, 0.5063, 0.4993, 0.5192, 0.4922, 0.5039],
       device='cuda:0') torch.Size([16])
percent tensor([0.5410, 0.5533, 0.5365, 0.5288, 0.5345, 0.5324, 0.5511, 0.5370, 0.5511,
        0.5537, 0.5558, 0.5440, 0.5501, 0.5620, 0.5362, 0.5449],
       device='cuda:0') torch.Size([16])
percent tensor([0.5273, 0.5203, 0.4892, 0.4957, 0.4762, 0.5189, 0.5144, 0.4689, 0.5367,
        0.5278, 0.5471, 0.4925, 0.5276, 0.5425, 0.4743, 0.5256],
       device='cuda:0') torch.Size([16])
percent tensor([0.5065, 0.5080, 0.5027, 0.5026, 0.5105, 0.5141, 0.5083, 0.5103, 0.5074,
        0.5072, 0.5036, 0.5005, 0.5032, 0.5102, 0.5067, 0.5121],
       device='cuda:0') torch.Size([16])
percent tensor([0.5276, 0.5515, 0.5696, 0.5678, 0.5933, 0.5833, 0.5284, 0.5883, 0.5555,
        0.5545, 0.5403, 0.5382, 0.5347, 0.5502, 0.5413, 0.5344],
       device='cuda:0') torch.Size([16])
percent tensor([0.9417, 0.9095, 0.9408, 0.9549, 0.9317, 0.9585, 0.9107, 0.9543, 0.9494,
        0.9524, 0.9631, 0.9428, 0.9568, 0.8944, 0.9471, 0.9493],
       device='cuda:0') torch.Size([16])
Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 3, 3, 3]) tensor(174.6527, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(800.0566, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(788.4173, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([128, 64, 3, 3]) tensor(1531.7363, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([128, 64, 1, 1]) tensor(498.2580, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([128, 128, 3, 3]) tensor(2199.0796, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([256, 128, 3, 3]) tensor(4292.8657, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([256, 128, 1, 1]) tensor(1417.9093, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([256, 256, 3, 3]) tensor(6086.9443, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([512, 256, 3, 3]) tensor(12083.7939, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([512, 256, 1, 1]) tensor(4031.1804, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([512, 512, 3, 3]) tensor(17058.8184, device='cuda:0', grad_fn=<NormBackward0>)
Epoch: 41 | Batch_idx: 0 |  Loss: (0.4318) |  Loss2: (0.0000) | Acc: (86.00%) (111/128)
Epoch: 41 | Batch_idx: 10 |  Loss: (0.4846) |  Loss2: (0.0000) | Acc: (83.00%) (1172/1408)
Epoch: 41 | Batch_idx: 20 |  Loss: (0.4563) |  Loss2: (0.0000) | Acc: (84.00%) (2268/2688)
Epoch: 41 | Batch_idx: 30 |  Loss: (0.4540) |  Loss2: (0.0000) | Acc: (84.00%) (3350/3968)
Epoch: 41 | Batch_idx: 40 |  Loss: (0.4516) |  Loss2: (0.0000) | Acc: (84.00%) (4444/5248)
Epoch: 41 | Batch_idx: 50 |  Loss: (0.4419) |  Loss2: (0.0000) | Acc: (84.00%) (5541/6528)
Epoch: 41 | Batch_idx: 60 |  Loss: (0.4455) |  Loss2: (0.0000) | Acc: (84.00%) (6606/7808)
Epoch: 41 | Batch_idx: 70 |  Loss: (0.4468) |  Loss2: (0.0000) | Acc: (84.00%) (7683/9088)
Epoch: 41 | Batch_idx: 80 |  Loss: (0.4510) |  Loss2: (0.0000) | Acc: (84.00%) (8752/10368)
Epoch: 41 | Batch_idx: 90 |  Loss: (0.4530) |  Loss2: (0.0000) | Acc: (84.00%) (9834/11648)
Epoch: 41 | Batch_idx: 100 |  Loss: (0.4543) |  Loss2: (0.0000) | Acc: (84.00%) (10920/12928)
Epoch: 41 | Batch_idx: 110 |  Loss: (0.4552) |  Loss2: (0.0000) | Acc: (84.00%) (11997/14208)
Epoch: 41 | Batch_idx: 120 |  Loss: (0.4569) |  Loss2: (0.0000) | Acc: (84.00%) (13060/15488)
Epoch: 41 | Batch_idx: 130 |  Loss: (0.4603) |  Loss2: (0.0000) | Acc: (84.00%) (14107/16768)
Epoch: 41 | Batch_idx: 140 |  Loss: (0.4587) |  Loss2: (0.0000) | Acc: (84.00%) (15194/18048)
Epoch: 41 | Batch_idx: 150 |  Loss: (0.4577) |  Loss2: (0.0000) | Acc: (84.00%) (16281/19328)
Epoch: 41 | Batch_idx: 160 |  Loss: (0.4568) |  Loss2: (0.0000) | Acc: (84.00%) (17366/20608)
Epoch: 41 | Batch_idx: 170 |  Loss: (0.4568) |  Loss2: (0.0000) | Acc: (84.00%) (18447/21888)
Epoch: 41 | Batch_idx: 180 |  Loss: (0.4565) |  Loss2: (0.0000) | Acc: (84.00%) (19527/23168)
Epoch: 41 | Batch_idx: 190 |  Loss: (0.4583) |  Loss2: (0.0000) | Acc: (84.00%) (20586/24448)
Epoch: 41 | Batch_idx: 200 |  Loss: (0.4584) |  Loss2: (0.0000) | Acc: (84.00%) (21661/25728)
Epoch: 41 | Batch_idx: 210 |  Loss: (0.4580) |  Loss2: (0.0000) | Acc: (84.00%) (22760/27008)
Epoch: 41 | Batch_idx: 220 |  Loss: (0.4576) |  Loss2: (0.0000) | Acc: (84.00%) (23839/28288)
Epoch: 41 | Batch_idx: 230 |  Loss: (0.4575) |  Loss2: (0.0000) | Acc: (84.00%) (24928/29568)
Epoch: 41 | Batch_idx: 240 |  Loss: (0.4588) |  Loss2: (0.0000) | Acc: (84.00%) (25981/30848)
Epoch: 41 | Batch_idx: 250 |  Loss: (0.4585) |  Loss2: (0.0000) | Acc: (84.00%) (27063/32128)
Epoch: 41 | Batch_idx: 260 |  Loss: (0.4585) |  Loss2: (0.0000) | Acc: (84.00%) (28132/33408)
Epoch: 41 | Batch_idx: 270 |  Loss: (0.4574) |  Loss2: (0.0000) | Acc: (84.00%) (29225/34688)
Epoch: 41 | Batch_idx: 280 |  Loss: (0.4573) |  Loss2: (0.0000) | Acc: (84.00%) (30301/35968)
Epoch: 41 | Batch_idx: 290 |  Loss: (0.4575) |  Loss2: (0.0000) | Acc: (84.00%) (31387/37248)
Epoch: 41 | Batch_idx: 300 |  Loss: (0.4582) |  Loss2: (0.0000) | Acc: (84.00%) (32446/38528)
Epoch: 41 | Batch_idx: 310 |  Loss: (0.4592) |  Loss2: (0.0000) | Acc: (84.00%) (33511/39808)
Epoch: 41 | Batch_idx: 320 |  Loss: (0.4602) |  Loss2: (0.0000) | Acc: (84.00%) (34570/41088)
Epoch: 41 | Batch_idx: 330 |  Loss: (0.4613) |  Loss2: (0.0000) | Acc: (84.00%) (35630/42368)
Epoch: 41 | Batch_idx: 340 |  Loss: (0.4605) |  Loss2: (0.0000) | Acc: (84.00%) (36712/43648)
Epoch: 41 | Batch_idx: 350 |  Loss: (0.4600) |  Loss2: (0.0000) | Acc: (84.00%) (37795/44928)
Epoch: 41 | Batch_idx: 360 |  Loss: (0.4617) |  Loss2: (0.0000) | Acc: (84.00%) (38845/46208)
Epoch: 41 | Batch_idx: 370 |  Loss: (0.4615) |  Loss2: (0.0000) | Acc: (84.00%) (39921/47488)
Epoch: 41 | Batch_idx: 380 |  Loss: (0.4616) |  Loss2: (0.0000) | Acc: (84.00%) (40997/48768)
Epoch: 41 | Batch_idx: 390 |  Loss: (0.4626) |  Loss2: (0.0000) | Acc: (84.00%) (42029/50000)
# TEST : Loss: (0.6137) | Acc: (80.00%) (8033/10000)
percent tensor([0.4932, 0.4857, 0.4807, 0.4823, 0.4823, 0.4991, 0.4846, 0.4814, 0.4898,
        0.4840, 0.4929, 0.4794, 0.4873, 0.4904, 0.4889, 0.4902],
       device='cuda:0') torch.Size([16])
percent tensor([0.5093, 0.5033, 0.5143, 0.5120, 0.5129, 0.5103, 0.5067, 0.5131, 0.5106,
        0.5052, 0.5074, 0.5080, 0.5037, 0.5084, 0.5062, 0.5081],
       device='cuda:0') torch.Size([16])
percent tensor([0.4978, 0.5068, 0.5067, 0.5076, 0.5030, 0.4933, 0.5050, 0.5051, 0.5003,
        0.5080, 0.4965, 0.5089, 0.4986, 0.5156, 0.4919, 0.5043],
       device='cuda:0') torch.Size([16])
percent tensor([0.5423, 0.5562, 0.5381, 0.5373, 0.5368, 0.5372, 0.5522, 0.5370, 0.5513,
        0.5551, 0.5579, 0.5477, 0.5526, 0.5632, 0.5395, 0.5479],
       device='cuda:0') torch.Size([16])
percent tensor([0.5259, 0.5277, 0.4759, 0.5084, 0.4665, 0.5227, 0.5159, 0.4645, 0.5351,
        0.5303, 0.5482, 0.4936, 0.5295, 0.5476, 0.4871, 0.5270],
       device='cuda:0') torch.Size([16])
percent tensor([0.5066, 0.5052, 0.5047, 0.5036, 0.5111, 0.5142, 0.5068, 0.5099, 0.5043,
        0.5054, 0.5025, 0.5007, 0.5028, 0.5061, 0.5052, 0.5107],
       device='cuda:0') torch.Size([16])
percent tensor([0.5235, 0.5382, 0.5804, 0.5673, 0.5987, 0.5842, 0.5217, 0.5886, 0.5462,
        0.5395, 0.5409, 0.5439, 0.5269, 0.5450, 0.5390, 0.5257],
       device='cuda:0') torch.Size([16])
percent tensor([0.9298, 0.9013, 0.9468, 0.9550, 0.9479, 0.9529, 0.9194, 0.9635, 0.9496,
        0.9367, 0.9563, 0.9203, 0.9459, 0.8963, 0.9334, 0.9417],
       device='cuda:0') torch.Size([16])
Epoch: 42 | Batch_idx: 0 |  Loss: (0.5057) |  Loss2: (0.0000) | Acc: (79.00%) (102/128)
Epoch: 42 | Batch_idx: 10 |  Loss: (0.4499) |  Loss2: (0.0000) | Acc: (85.00%) (1199/1408)
Epoch: 42 | Batch_idx: 20 |  Loss: (0.4437) |  Loss2: (0.0000) | Acc: (85.00%) (2303/2688)
Epoch: 42 | Batch_idx: 30 |  Loss: (0.4549) |  Loss2: (0.0000) | Acc: (85.00%) (3376/3968)
Epoch: 42 | Batch_idx: 40 |  Loss: (0.4398) |  Loss2: (0.0000) | Acc: (85.00%) (4479/5248)
Epoch: 42 | Batch_idx: 50 |  Loss: (0.4416) |  Loss2: (0.0000) | Acc: (85.00%) (5565/6528)
Epoch: 42 | Batch_idx: 60 |  Loss: (0.4487) |  Loss2: (0.0000) | Acc: (84.00%) (6624/7808)
Epoch: 42 | Batch_idx: 70 |  Loss: (0.4492) |  Loss2: (0.0000) | Acc: (84.00%) (7701/9088)
Epoch: 42 | Batch_idx: 80 |  Loss: (0.4459) |  Loss2: (0.0000) | Acc: (84.00%) (8794/10368)
Epoch: 42 | Batch_idx: 90 |  Loss: (0.4514) |  Loss2: (0.0000) | Acc: (84.00%) (9853/11648)
Epoch: 42 | Batch_idx: 100 |  Loss: (0.4477) |  Loss2: (0.0000) | Acc: (84.00%) (10953/12928)
Epoch: 42 | Batch_idx: 110 |  Loss: (0.4479) |  Loss2: (0.0000) | Acc: (84.00%) (12035/14208)
Epoch: 42 | Batch_idx: 120 |  Loss: (0.4466) |  Loss2: (0.0000) | Acc: (84.00%) (13123/15488)
Epoch: 42 | Batch_idx: 130 |  Loss: (0.4485) |  Loss2: (0.0000) | Acc: (84.00%) (14189/16768)
Epoch: 42 | Batch_idx: 140 |  Loss: (0.4484) |  Loss2: (0.0000) | Acc: (84.00%) (15282/18048)
Epoch: 42 | Batch_idx: 150 |  Loss: (0.4485) |  Loss2: (0.0000) | Acc: (84.00%) (16370/19328)
Epoch: 42 | Batch_idx: 160 |  Loss: (0.4498) |  Loss2: (0.0000) | Acc: (84.00%) (17453/20608)
Epoch: 42 | Batch_idx: 170 |  Loss: (0.4505) |  Loss2: (0.0000) | Acc: (84.00%) (18533/21888)
Epoch: 42 | Batch_idx: 180 |  Loss: (0.4496) |  Loss2: (0.0000) | Acc: (84.00%) (19615/23168)
Epoch: 42 | Batch_idx: 190 |  Loss: (0.4512) |  Loss2: (0.0000) | Acc: (84.00%) (20693/24448)
Epoch: 42 | Batch_idx: 200 |  Loss: (0.4482) |  Loss2: (0.0000) | Acc: (84.00%) (21795/25728)
Epoch: 42 | Batch_idx: 210 |  Loss: (0.4497) |  Loss2: (0.0000) | Acc: (84.00%) (22852/27008)
Epoch: 42 | Batch_idx: 220 |  Loss: (0.4487) |  Loss2: (0.0000) | Acc: (84.00%) (23954/28288)
Epoch: 42 | Batch_idx: 230 |  Loss: (0.4481) |  Loss2: (0.0000) | Acc: (84.00%) (25048/29568)
Epoch: 42 | Batch_idx: 240 |  Loss: (0.4489) |  Loss2: (0.0000) | Acc: (84.00%) (26112/30848)
Epoch: 42 | Batch_idx: 250 |  Loss: (0.4502) |  Loss2: (0.0000) | Acc: (84.00%) (27180/32128)
Epoch: 42 | Batch_idx: 260 |  Loss: (0.4487) |  Loss2: (0.0000) | Acc: (84.00%) (28283/33408)
Epoch: 42 | Batch_idx: 270 |  Loss: (0.4491) |  Loss2: (0.0000) | Acc: (84.00%) (29360/34688)
Epoch: 42 | Batch_idx: 280 |  Loss: (0.4500) |  Loss2: (0.0000) | Acc: (84.00%) (30416/35968)
Epoch: 42 | Batch_idx: 290 |  Loss: (0.4507) |  Loss2: (0.0000) | Acc: (84.00%) (31496/37248)
Epoch: 42 | Batch_idx: 300 |  Loss: (0.4493) |  Loss2: (0.0000) | Acc: (84.00%) (32606/38528)
Epoch: 42 | Batch_idx: 310 |  Loss: (0.4506) |  Loss2: (0.0000) | Acc: (84.00%) (33662/39808)
Epoch: 42 | Batch_idx: 320 |  Loss: (0.4505) |  Loss2: (0.0000) | Acc: (84.00%) (34740/41088)
Epoch: 42 | Batch_idx: 330 |  Loss: (0.4499) |  Loss2: (0.0000) | Acc: (84.00%) (35828/42368)
Epoch: 42 | Batch_idx: 340 |  Loss: (0.4489) |  Loss2: (0.0000) | Acc: (84.00%) (36919/43648)
Epoch: 42 | Batch_idx: 350 |  Loss: (0.4491) |  Loss2: (0.0000) | Acc: (84.00%) (37991/44928)
Epoch: 42 | Batch_idx: 360 |  Loss: (0.4492) |  Loss2: (0.0000) | Acc: (84.00%) (39080/46208)
Epoch: 42 | Batch_idx: 370 |  Loss: (0.4491) |  Loss2: (0.0000) | Acc: (84.00%) (40161/47488)
Epoch: 42 | Batch_idx: 380 |  Loss: (0.4499) |  Loss2: (0.0000) | Acc: (84.00%) (41227/48768)
Epoch: 42 | Batch_idx: 390 |  Loss: (0.4491) |  Loss2: (0.0000) | Acc: (84.00%) (42282/50000)
# TEST : Loss: (0.5624) | Acc: (81.00%) (8165/10000)
percent tensor([0.4933, 0.4856, 0.4808, 0.4828, 0.4827, 0.4996, 0.4848, 0.4813, 0.4895,
        0.4842, 0.4930, 0.4802, 0.4874, 0.4892, 0.4896, 0.4904],
       device='cuda:0') torch.Size([16])
percent tensor([0.5087, 0.5046, 0.5134, 0.5120, 0.5122, 0.5095, 0.5077, 0.5133, 0.5117,
        0.5055, 0.5083, 0.5074, 0.5040, 0.5126, 0.5067, 0.5091],
       device='cuda:0') torch.Size([16])
percent tensor([0.4949, 0.5068, 0.4993, 0.5056, 0.4964, 0.4904, 0.5009, 0.5061, 0.5000,
        0.5072, 0.4972, 0.5021, 0.4974, 0.5158, 0.4916, 0.5029],
       device='cuda:0') torch.Size([16])
percent tensor([0.5401, 0.5546, 0.5327, 0.5316, 0.5320, 0.5352, 0.5475, 0.5355, 0.5507,
        0.5533, 0.5560, 0.5400, 0.5508, 0.5611, 0.5378, 0.5463],
       device='cuda:0') torch.Size([16])
percent tensor([0.5240, 0.5212, 0.4824, 0.4952, 0.4679, 0.5195, 0.5055, 0.4607, 0.5321,
        0.5267, 0.5451, 0.4933, 0.5274, 0.5428, 0.4766, 0.5255],
       device='cuda:0') torch.Size([16])
percent tensor([0.5058, 0.5042, 0.5017, 0.5037, 0.5085, 0.5153, 0.5035, 0.5080, 0.5061,
        0.5048, 0.5011, 0.4987, 0.5032, 0.5086, 0.5038, 0.5111],
       device='cuda:0') torch.Size([16])
percent tensor([0.5253, 0.5420, 0.5693, 0.5653, 0.5866, 0.5882, 0.5234, 0.5864, 0.5565,
        0.5458, 0.5439, 0.5428, 0.5294, 0.5477, 0.5414, 0.5292],
       device='cuda:0') torch.Size([16])
percent tensor([0.9269, 0.9265, 0.9359, 0.9566, 0.9331, 0.9529, 0.9170, 0.9646, 0.9581,
        0.9467, 0.9657, 0.9506, 0.9485, 0.8986, 0.9427, 0.9513],
       device='cuda:0') torch.Size([16])
Epoch: 43 | Batch_idx: 0 |  Loss: (0.4174) |  Loss2: (0.0000) | Acc: (85.00%) (109/128)
Epoch: 43 | Batch_idx: 10 |  Loss: (0.4043) |  Loss2: (0.0000) | Acc: (86.00%) (1214/1408)
Epoch: 43 | Batch_idx: 20 |  Loss: (0.4080) |  Loss2: (0.0000) | Acc: (85.00%) (2310/2688)
Epoch: 43 | Batch_idx: 30 |  Loss: (0.4185) |  Loss2: (0.0000) | Acc: (85.00%) (3382/3968)
Epoch: 43 | Batch_idx: 40 |  Loss: (0.4227) |  Loss2: (0.0000) | Acc: (85.00%) (4467/5248)
Epoch: 43 | Batch_idx: 50 |  Loss: (0.4201) |  Loss2: (0.0000) | Acc: (85.00%) (5570/6528)
Epoch: 43 | Batch_idx: 60 |  Loss: (0.4222) |  Loss2: (0.0000) | Acc: (85.00%) (6671/7808)
Epoch: 43 | Batch_idx: 70 |  Loss: (0.4243) |  Loss2: (0.0000) | Acc: (85.00%) (7743/9088)
Epoch: 43 | Batch_idx: 80 |  Loss: (0.4251) |  Loss2: (0.0000) | Acc: (85.00%) (8826/10368)
Epoch: 43 | Batch_idx: 90 |  Loss: (0.4218) |  Loss2: (0.0000) | Acc: (85.00%) (9922/11648)
Epoch: 43 | Batch_idx: 100 |  Loss: (0.4255) |  Loss2: (0.0000) | Acc: (85.00%) (10990/12928)
Epoch: 43 | Batch_idx: 110 |  Loss: (0.4248) |  Loss2: (0.0000) | Acc: (85.00%) (12093/14208)
Epoch: 43 | Batch_idx: 120 |  Loss: (0.4262) |  Loss2: (0.0000) | Acc: (85.00%) (13179/15488)
Epoch: 43 | Batch_idx: 130 |  Loss: (0.4265) |  Loss2: (0.0000) | Acc: (85.00%) (14274/16768)
Epoch: 43 | Batch_idx: 140 |  Loss: (0.4287) |  Loss2: (0.0000) | Acc: (85.00%) (15347/18048)
Epoch: 43 | Batch_idx: 150 |  Loss: (0.4300) |  Loss2: (0.0000) | Acc: (84.00%) (16423/19328)
Epoch: 43 | Batch_idx: 160 |  Loss: (0.4303) |  Loss2: (0.0000) | Acc: (84.00%) (17515/20608)
Epoch: 43 | Batch_idx: 170 |  Loss: (0.4296) |  Loss2: (0.0000) | Acc: (84.00%) (18595/21888)
Epoch: 43 | Batch_idx: 180 |  Loss: (0.4307) |  Loss2: (0.0000) | Acc: (84.00%) (19666/23168)
Epoch: 43 | Batch_idx: 190 |  Loss: (0.4312) |  Loss2: (0.0000) | Acc: (84.00%) (20740/24448)
Epoch: 43 | Batch_idx: 200 |  Loss: (0.4321) |  Loss2: (0.0000) | Acc: (84.00%) (21803/25728)
Epoch: 43 | Batch_idx: 210 |  Loss: (0.4319) |  Loss2: (0.0000) | Acc: (84.00%) (22897/27008)
Epoch: 43 | Batch_idx: 220 |  Loss: (0.4317) |  Loss2: (0.0000) | Acc: (84.00%) (24001/28288)
Epoch: 43 | Batch_idx: 230 |  Loss: (0.4316) |  Loss2: (0.0000) | Acc: (84.00%) (25090/29568)
Epoch: 43 | Batch_idx: 240 |  Loss: (0.4319) |  Loss2: (0.0000) | Acc: (84.00%) (26171/30848)
Epoch: 43 | Batch_idx: 250 |  Loss: (0.4335) |  Loss2: (0.0000) | Acc: (84.00%) (27239/32128)
Epoch: 43 | Batch_idx: 260 |  Loss: (0.4343) |  Loss2: (0.0000) | Acc: (84.00%) (28318/33408)
Epoch: 43 | Batch_idx: 270 |  Loss: (0.4346) |  Loss2: (0.0000) | Acc: (84.00%) (29395/34688)
Epoch: 43 | Batch_idx: 280 |  Loss: (0.4340) |  Loss2: (0.0000) | Acc: (84.00%) (30485/35968)
Epoch: 43 | Batch_idx: 290 |  Loss: (0.4331) |  Loss2: (0.0000) | Acc: (84.00%) (31568/37248)
Epoch: 43 | Batch_idx: 300 |  Loss: (0.4333) |  Loss2: (0.0000) | Acc: (84.00%) (32665/38528)
Epoch: 43 | Batch_idx: 310 |  Loss: (0.4344) |  Loss2: (0.0000) | Acc: (84.00%) (33735/39808)
Epoch: 43 | Batch_idx: 320 |  Loss: (0.4341) |  Loss2: (0.0000) | Acc: (84.00%) (34830/41088)
Epoch: 43 | Batch_idx: 330 |  Loss: (0.4370) |  Loss2: (0.0000) | Acc: (84.00%) (35899/42368)
Epoch: 43 | Batch_idx: 340 |  Loss: (0.4371) |  Loss2: (0.0000) | Acc: (84.00%) (36987/43648)
Epoch: 43 | Batch_idx: 350 |  Loss: (0.4368) |  Loss2: (0.0000) | Acc: (84.00%) (38088/44928)
Epoch: 43 | Batch_idx: 360 |  Loss: (0.4375) |  Loss2: (0.0000) | Acc: (84.00%) (39171/46208)
Epoch: 43 | Batch_idx: 370 |  Loss: (0.4363) |  Loss2: (0.0000) | Acc: (84.00%) (40276/47488)
Epoch: 43 | Batch_idx: 380 |  Loss: (0.4363) |  Loss2: (0.0000) | Acc: (84.00%) (41361/48768)
Epoch: 43 | Batch_idx: 390 |  Loss: (0.4363) |  Loss2: (0.0000) | Acc: (84.00%) (42411/50000)
# TEST : Loss: (0.6105) | Acc: (79.00%) (7967/10000)
percent tensor([0.4929, 0.4857, 0.4813, 0.4832, 0.4833, 0.5001, 0.4847, 0.4814, 0.4897,
        0.4840, 0.4925, 0.4803, 0.4870, 0.4901, 0.4896, 0.4903],
       device='cuda:0') torch.Size([16])
percent tensor([0.5095, 0.5038, 0.5119, 0.5103, 0.5115, 0.5104, 0.5069, 0.5127, 0.5124,
        0.5050, 0.5090, 0.5057, 0.5039, 0.5111, 0.5061, 0.5086],
       device='cuda:0') torch.Size([16])
percent tensor([0.4967, 0.5078, 0.5001, 0.5032, 0.4991, 0.4925, 0.5041, 0.5040, 0.5060,
        0.5073, 0.5010, 0.5044, 0.4994, 0.5213, 0.4925, 0.5039],
       device='cuda:0') torch.Size([16])
percent tensor([0.5397, 0.5556, 0.5355, 0.5334, 0.5343, 0.5343, 0.5518, 0.5370, 0.5519,
        0.5556, 0.5581, 0.5451, 0.5529, 0.5650, 0.5384, 0.5468],
       device='cuda:0') torch.Size([16])
percent tensor([0.5218, 0.5218, 0.4865, 0.4984, 0.4708, 0.5181, 0.5132, 0.4615, 0.5356,
        0.5279, 0.5456, 0.5005, 0.5243, 0.5446, 0.4809, 0.5238],
       device='cuda:0') torch.Size([16])
percent tensor([0.5056, 0.5042, 0.5028, 0.5037, 0.5095, 0.5148, 0.5058, 0.5081, 0.5079,
        0.5038, 0.5016, 0.4987, 0.5019, 0.5077, 0.5054, 0.5110],
       device='cuda:0') torch.Size([16])
percent tensor([0.5212, 0.5404, 0.5626, 0.5576, 0.5825, 0.5856, 0.5193, 0.5676, 0.5539,
        0.5352, 0.5387, 0.5319, 0.5282, 0.5484, 0.5386, 0.5242],
       device='cuda:0') torch.Size([16])
percent tensor([0.9348, 0.9439, 0.9365, 0.9519, 0.9439, 0.9537, 0.9281, 0.9529, 0.9508,
        0.9507, 0.9618, 0.9340, 0.9563, 0.9167, 0.9490, 0.9602],
       device='cuda:0') torch.Size([16])
Epoch: 44 | Batch_idx: 0 |  Loss: (0.4787) |  Loss2: (0.0000) | Acc: (83.00%) (107/128)
Epoch: 44 | Batch_idx: 10 |  Loss: (0.4375) |  Loss2: (0.0000) | Acc: (85.00%) (1209/1408)
Epoch: 44 | Batch_idx: 20 |  Loss: (0.4316) |  Loss2: (0.0000) | Acc: (86.00%) (2313/2688)
Epoch: 44 | Batch_idx: 30 |  Loss: (0.4329) |  Loss2: (0.0000) | Acc: (85.00%) (3399/3968)
Epoch: 44 | Batch_idx: 40 |  Loss: (0.4322) |  Loss2: (0.0000) | Acc: (85.00%) (4487/5248)
Epoch: 44 | Batch_idx: 50 |  Loss: (0.4294) |  Loss2: (0.0000) | Acc: (85.00%) (5573/6528)
Epoch: 44 | Batch_idx: 60 |  Loss: (0.4233) |  Loss2: (0.0000) | Acc: (85.00%) (6687/7808)
Epoch: 44 | Batch_idx: 70 |  Loss: (0.4180) |  Loss2: (0.0000) | Acc: (85.00%) (7800/9088)
Epoch: 44 | Batch_idx: 80 |  Loss: (0.4181) |  Loss2: (0.0000) | Acc: (85.00%) (8905/10368)
Epoch: 44 | Batch_idx: 90 |  Loss: (0.4230) |  Loss2: (0.0000) | Acc: (85.00%) (9986/11648)
Epoch: 44 | Batch_idx: 100 |  Loss: (0.4191) |  Loss2: (0.0000) | Acc: (85.00%) (11087/12928)
Epoch: 44 | Batch_idx: 110 |  Loss: (0.4195) |  Loss2: (0.0000) | Acc: (85.00%) (12183/14208)
Epoch: 44 | Batch_idx: 120 |  Loss: (0.4227) |  Loss2: (0.0000) | Acc: (85.00%) (13273/15488)
Epoch: 44 | Batch_idx: 130 |  Loss: (0.4244) |  Loss2: (0.0000) | Acc: (85.00%) (14363/16768)
Epoch: 44 | Batch_idx: 140 |  Loss: (0.4271) |  Loss2: (0.0000) | Acc: (85.00%) (15433/18048)
Epoch: 44 | Batch_idx: 150 |  Loss: (0.4247) |  Loss2: (0.0000) | Acc: (85.00%) (16534/19328)
Epoch: 44 | Batch_idx: 160 |  Loss: (0.4274) |  Loss2: (0.0000) | Acc: (85.00%) (17601/20608)
Epoch: 44 | Batch_idx: 170 |  Loss: (0.4313) |  Loss2: (0.0000) | Acc: (85.00%) (18656/21888)
Epoch: 44 | Batch_idx: 180 |  Loss: (0.4320) |  Loss2: (0.0000) | Acc: (85.00%) (19730/23168)
Epoch: 44 | Batch_idx: 190 |  Loss: (0.4307) |  Loss2: (0.0000) | Acc: (85.00%) (20821/24448)
Epoch: 44 | Batch_idx: 200 |  Loss: (0.4291) |  Loss2: (0.0000) | Acc: (85.00%) (21930/25728)
Epoch: 44 | Batch_idx: 210 |  Loss: (0.4277) |  Loss2: (0.0000) | Acc: (85.00%) (23032/27008)
Epoch: 44 | Batch_idx: 220 |  Loss: (0.4276) |  Loss2: (0.0000) | Acc: (85.00%) (24120/28288)
Epoch: 44 | Batch_idx: 230 |  Loss: (0.4265) |  Loss2: (0.0000) | Acc: (85.00%) (25216/29568)
Epoch: 44 | Batch_idx: 240 |  Loss: (0.4270) |  Loss2: (0.0000) | Acc: (85.00%) (26296/30848)
Epoch: 44 | Batch_idx: 250 |  Loss: (0.4281) |  Loss2: (0.0000) | Acc: (85.00%) (27368/32128)
Epoch: 44 | Batch_idx: 260 |  Loss: (0.4286) |  Loss2: (0.0000) | Acc: (85.00%) (28444/33408)
Epoch: 44 | Batch_idx: 270 |  Loss: (0.4279) |  Loss2: (0.0000) | Acc: (85.00%) (29542/34688)
Epoch: 44 | Batch_idx: 280 |  Loss: (0.4279) |  Loss2: (0.0000) | Acc: (85.00%) (30635/35968)
Epoch: 44 | Batch_idx: 290 |  Loss: (0.4289) |  Loss2: (0.0000) | Acc: (85.00%) (31714/37248)
Epoch: 44 | Batch_idx: 300 |  Loss: (0.4291) |  Loss2: (0.0000) | Acc: (85.00%) (32797/38528)
Epoch: 44 | Batch_idx: 310 |  Loss: (0.4304) |  Loss2: (0.0000) | Acc: (85.00%) (33877/39808)
Epoch: 44 | Batch_idx: 320 |  Loss: (0.4288) |  Loss2: (0.0000) | Acc: (85.00%) (34983/41088)
Epoch: 44 | Batch_idx: 330 |  Loss: (0.4294) |  Loss2: (0.0000) | Acc: (85.00%) (36069/42368)
Epoch: 44 | Batch_idx: 340 |  Loss: (0.4292) |  Loss2: (0.0000) | Acc: (85.00%) (37162/43648)
Epoch: 44 | Batch_idx: 350 |  Loss: (0.4306) |  Loss2: (0.0000) | Acc: (85.00%) (38233/44928)
Epoch: 44 | Batch_idx: 360 |  Loss: (0.4302) |  Loss2: (0.0000) | Acc: (85.00%) (39328/46208)
Epoch: 44 | Batch_idx: 370 |  Loss: (0.4292) |  Loss2: (0.0000) | Acc: (85.00%) (40451/47488)
Epoch: 44 | Batch_idx: 380 |  Loss: (0.4296) |  Loss2: (0.0000) | Acc: (85.00%) (41531/48768)
Epoch: 44 | Batch_idx: 390 |  Loss: (0.4291) |  Loss2: (0.0000) | Acc: (85.00%) (42590/50000)
# TEST : Loss: (0.5168) | Acc: (82.00%) (8274/10000)
percent tensor([0.4933, 0.4857, 0.4803, 0.4826, 0.4824, 0.5003, 0.4847, 0.4810, 0.4894,
        0.4838, 0.4929, 0.4798, 0.4872, 0.4900, 0.4896, 0.4904],
       device='cuda:0') torch.Size([16])
percent tensor([0.5095, 0.5047, 0.5144, 0.5109, 0.5133, 0.5095, 0.5084, 0.5143, 0.5127,
        0.5064, 0.5086, 0.5090, 0.5047, 0.5117, 0.5066, 0.5086],
       device='cuda:0') torch.Size([16])
percent tensor([0.4988, 0.5084, 0.5063, 0.5061, 0.5024, 0.4905, 0.5041, 0.5074, 0.5042,
        0.5096, 0.5006, 0.5085, 0.5001, 0.5183, 0.4924, 0.5044],
       device='cuda:0') torch.Size([16])
percent tensor([0.5412, 0.5553, 0.5381, 0.5337, 0.5352, 0.5347, 0.5511, 0.5365, 0.5510,
        0.5554, 0.5571, 0.5465, 0.5530, 0.5613, 0.5398, 0.5459],
       device='cuda:0') torch.Size([16])
percent tensor([0.5231, 0.5224, 0.4918, 0.5095, 0.4759, 0.5187, 0.5146, 0.4636, 0.5337,
        0.5291, 0.5443, 0.5025, 0.5260, 0.5453, 0.4822, 0.5260],
       device='cuda:0') torch.Size([16])
percent tensor([0.5061, 0.5062, 0.5044, 0.5033, 0.5105, 0.5134, 0.5058, 0.5111, 0.5076,
        0.5048, 0.5029, 0.5008, 0.5033, 0.5092, 0.5060, 0.5120],
       device='cuda:0') torch.Size([16])
percent tensor([0.5248, 0.5480, 0.5756, 0.5627, 0.5895, 0.5873, 0.5260, 0.5882, 0.5486,
        0.5392, 0.5407, 0.5426, 0.5260, 0.5471, 0.5503, 0.5312],
       device='cuda:0') torch.Size([16])
percent tensor([0.9154, 0.9085, 0.9179, 0.9454, 0.9275, 0.9437, 0.9138, 0.9451, 0.9513,
        0.9338, 0.9531, 0.9360, 0.9379, 0.8919, 0.9246, 0.9338],
       device='cuda:0') torch.Size([16])
False Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=128, out_features=16, bias=False)
True Linear(in_features=16, out_features=2, bias=False)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=128, out_features=16, bias=False)
True Linear(in_features=16, out_features=2, bias=False)
False Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=256, out_features=32, bias=False)
True Linear(in_features=32, out_features=2, bias=False)
False Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=256, out_features=32, bias=False)
True Linear(in_features=32, out_features=2, bias=False)
False Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=512, out_features=64, bias=False)
True Linear(in_features=64, out_features=2, bias=False)
False Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=512, out_features=64, bias=False)
True Linear(in_features=64, out_features=2, bias=False)
False Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1024, out_features=128, bias=False)
True Linear(in_features=128, out_features=2, bias=False)
False Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1024, out_features=128, bias=False)
True Linear(in_features=128, out_features=2, bias=False)
False Linear(in_features=512, out_features=10, bias=True)
Epoch: 45 | Batch_idx: 0 |  Loss: (0.4150) |  Loss2: (0.0000) | Acc: (84.00%) (108/128)
Epoch: 45 | Batch_idx: 10 |  Loss: (0.4563) |  Loss2: (0.0000) | Acc: (85.00%) (1199/1408)
Epoch: 45 | Batch_idx: 20 |  Loss: (0.4604) |  Loss2: (0.0000) | Acc: (84.00%) (2279/2688)
Epoch: 45 | Batch_idx: 30 |  Loss: (0.4721) |  Loss2: (0.0000) | Acc: (84.00%) (3345/3968)
Epoch: 45 | Batch_idx: 40 |  Loss: (0.4979) |  Loss2: (0.0000) | Acc: (83.00%) (4376/5248)
Epoch: 45 | Batch_idx: 50 |  Loss: (0.5095) |  Loss2: (0.0000) | Acc: (83.00%) (5425/6528)
Epoch: 45 | Batch_idx: 60 |  Loss: (0.5136) |  Loss2: (0.0000) | Acc: (82.00%) (6454/7808)
Epoch: 45 | Batch_idx: 70 |  Loss: (0.5134) |  Loss2: (0.0000) | Acc: (82.00%) (7492/9088)
Epoch: 45 | Batch_idx: 80 |  Loss: (0.5112) |  Loss2: (0.0000) | Acc: (82.00%) (8546/10368)
Epoch: 45 | Batch_idx: 90 |  Loss: (0.5069) |  Loss2: (0.0000) | Acc: (82.00%) (9616/11648)
Epoch: 45 | Batch_idx: 100 |  Loss: (0.5050) |  Loss2: (0.0000) | Acc: (82.00%) (10695/12928)
Epoch: 45 | Batch_idx: 110 |  Loss: (0.5015) |  Loss2: (0.0000) | Acc: (82.00%) (11771/14208)
Epoch: 45 | Batch_idx: 120 |  Loss: (0.4990) |  Loss2: (0.0000) | Acc: (82.00%) (12833/15488)
Epoch: 45 | Batch_idx: 130 |  Loss: (0.4971) |  Loss2: (0.0000) | Acc: (82.00%) (13899/16768)
Epoch: 45 | Batch_idx: 140 |  Loss: (0.4938) |  Loss2: (0.0000) | Acc: (82.00%) (14978/18048)
Epoch: 45 | Batch_idx: 150 |  Loss: (0.4912) |  Loss2: (0.0000) | Acc: (83.00%) (16058/19328)
Epoch: 45 | Batch_idx: 160 |  Loss: (0.4898) |  Loss2: (0.0000) | Acc: (83.00%) (17131/20608)
Epoch: 45 | Batch_idx: 170 |  Loss: (0.4900) |  Loss2: (0.0000) | Acc: (83.00%) (18195/21888)
Epoch: 45 | Batch_idx: 180 |  Loss: (0.4881) |  Loss2: (0.0000) | Acc: (83.00%) (19272/23168)
Epoch: 45 | Batch_idx: 190 |  Loss: (0.4856) |  Loss2: (0.0000) | Acc: (83.00%) (20355/24448)
Epoch: 45 | Batch_idx: 200 |  Loss: (0.4832) |  Loss2: (0.0000) | Acc: (83.00%) (21452/25728)
Epoch: 45 | Batch_idx: 210 |  Loss: (0.4827) |  Loss2: (0.0000) | Acc: (83.00%) (22530/27008)
Epoch: 45 | Batch_idx: 220 |  Loss: (0.4807) |  Loss2: (0.0000) | Acc: (83.00%) (23612/28288)
Epoch: 45 | Batch_idx: 230 |  Loss: (0.4807) |  Loss2: (0.0000) | Acc: (83.00%) (24679/29568)
Epoch: 45 | Batch_idx: 240 |  Loss: (0.4797) |  Loss2: (0.0000) | Acc: (83.00%) (25763/30848)
Epoch: 45 | Batch_idx: 250 |  Loss: (0.4784) |  Loss2: (0.0000) | Acc: (83.00%) (26846/32128)
Epoch: 45 | Batch_idx: 260 |  Loss: (0.4765) |  Loss2: (0.0000) | Acc: (83.00%) (27933/33408)
Epoch: 45 | Batch_idx: 270 |  Loss: (0.4739) |  Loss2: (0.0000) | Acc: (83.00%) (29031/34688)
Epoch: 45 | Batch_idx: 280 |  Loss: (0.4732) |  Loss2: (0.0000) | Acc: (83.00%) (30111/35968)
Epoch: 45 | Batch_idx: 290 |  Loss: (0.4726) |  Loss2: (0.0000) | Acc: (83.00%) (31178/37248)
Epoch: 45 | Batch_idx: 300 |  Loss: (0.4712) |  Loss2: (0.0000) | Acc: (83.00%) (32250/38528)
Epoch: 45 | Batch_idx: 310 |  Loss: (0.4708) |  Loss2: (0.0000) | Acc: (83.00%) (33332/39808)
Epoch: 45 | Batch_idx: 320 |  Loss: (0.4696) |  Loss2: (0.0000) | Acc: (83.00%) (34412/41088)
Epoch: 45 | Batch_idx: 330 |  Loss: (0.4691) |  Loss2: (0.0000) | Acc: (83.00%) (35486/42368)
Epoch: 45 | Batch_idx: 340 |  Loss: (0.4675) |  Loss2: (0.0000) | Acc: (83.00%) (36597/43648)
Epoch: 45 | Batch_idx: 350 |  Loss: (0.4679) |  Loss2: (0.0000) | Acc: (83.00%) (37671/44928)
Epoch: 45 | Batch_idx: 360 |  Loss: (0.4674) |  Loss2: (0.0000) | Acc: (83.00%) (38763/46208)
Epoch: 45 | Batch_idx: 370 |  Loss: (0.4666) |  Loss2: (0.0000) | Acc: (83.00%) (39845/47488)
Epoch: 45 | Batch_idx: 380 |  Loss: (0.4662) |  Loss2: (0.0000) | Acc: (83.00%) (40922/48768)
Epoch: 45 | Batch_idx: 390 |  Loss: (0.4652) |  Loss2: (0.0000) | Acc: (83.00%) (41969/50000)
=> saving checkpoint 'drive/app/torch/save_Schedule/checkpoint_045.pth.tar'
# TEST : Loss: (0.5261) | Acc: (82.00%) (8234/10000)
percent tensor([0.4922, 0.4840, 0.4812, 0.4824, 0.4826, 0.4980, 0.4836, 0.4817, 0.4884,
        0.4833, 0.4907, 0.4799, 0.4864, 0.4884, 0.4877, 0.4896],
       device='cuda:0') torch.Size([16])
percent tensor([0.5161, 0.5120, 0.5206, 0.5190, 0.5207, 0.5158, 0.5154, 0.5230, 0.5204,
        0.5135, 0.5162, 0.5148, 0.5108, 0.5192, 0.5140, 0.5160],
       device='cuda:0') torch.Size([16])
percent tensor([0.5111, 0.5162, 0.5144, 0.5220, 0.5136, 0.5068, 0.5150, 0.5211, 0.5158,
        0.5192, 0.5129, 0.5145, 0.5074, 0.5296, 0.5063, 0.5173],
       device='cuda:0') torch.Size([16])
percent tensor([0.5653, 0.5825, 0.5626, 0.5553, 0.5619, 0.5587, 0.5816, 0.5622, 0.5777,
        0.5846, 0.5870, 0.5736, 0.5767, 0.5943, 0.5668, 0.5743],
       device='cuda:0') torch.Size([16])
percent tensor([0.5183, 0.5297, 0.4507, 0.4569, 0.4234, 0.5200, 0.5088, 0.4048, 0.5211,
        0.5369, 0.5528, 0.4761, 0.5320, 0.5521, 0.4674, 0.5259],
       device='cuda:0') torch.Size([16])
percent tensor([0.5119, 0.5120, 0.5094, 0.5096, 0.5196, 0.5183, 0.5129, 0.5207, 0.5139,
        0.5112, 0.5055, 0.5030, 0.5072, 0.5125, 0.5113, 0.5190],
       device='cuda:0') torch.Size([16])
percent tensor([0.5378, 0.5662, 0.6072, 0.5944, 0.6287, 0.6062, 0.5435, 0.6418, 0.5677,
        0.5512, 0.5448, 0.5713, 0.5308, 0.5507, 0.5645, 0.5436],
       device='cuda:0') torch.Size([16])
percent tensor([0.9485, 0.9419, 0.9536, 0.9680, 0.9521, 0.9703, 0.9439, 0.9603, 0.9723,
        0.9589, 0.9719, 0.9623, 0.9645, 0.9256, 0.9534, 0.9578],
       device='cuda:0') torch.Size([16])
Epoch: 46 | Batch_idx: 0 |  Loss: (0.5766) |  Loss2: (0.0000) | Acc: (77.00%) (99/128)
Epoch: 46 | Batch_idx: 10 |  Loss: (0.4296) |  Loss2: (0.0000) | Acc: (84.00%) (1195/1408)
Epoch: 46 | Batch_idx: 20 |  Loss: (0.4385) |  Loss2: (0.0000) | Acc: (85.00%) (2285/2688)
Epoch: 46 | Batch_idx: 30 |  Loss: (0.4323) |  Loss2: (0.0000) | Acc: (85.00%) (3381/3968)
Epoch: 46 | Batch_idx: 40 |  Loss: (0.4370) |  Loss2: (0.0000) | Acc: (85.00%) (4461/5248)
Epoch: 46 | Batch_idx: 50 |  Loss: (0.4375) |  Loss2: (0.0000) | Acc: (84.00%) (5529/6528)
Epoch: 46 | Batch_idx: 60 |  Loss: (0.4356) |  Loss2: (0.0000) | Acc: (84.00%) (6621/7808)
Epoch: 46 | Batch_idx: 70 |  Loss: (0.4290) |  Loss2: (0.0000) | Acc: (85.00%) (7733/9088)
Epoch: 46 | Batch_idx: 80 |  Loss: (0.4303) |  Loss2: (0.0000) | Acc: (85.00%) (8814/10368)
Epoch: 46 | Batch_idx: 90 |  Loss: (0.4299) |  Loss2: (0.0000) | Acc: (85.00%) (9903/11648)
Epoch: 46 | Batch_idx: 100 |  Loss: (0.4254) |  Loss2: (0.0000) | Acc: (85.00%) (11009/12928)
Epoch: 46 | Batch_idx: 110 |  Loss: (0.4268) |  Loss2: (0.0000) | Acc: (85.00%) (12091/14208)
Epoch: 46 | Batch_idx: 120 |  Loss: (0.4272) |  Loss2: (0.0000) | Acc: (85.00%) (13175/15488)
Epoch: 46 | Batch_idx: 130 |  Loss: (0.4276) |  Loss2: (0.0000) | Acc: (85.00%) (14264/16768)
Epoch: 46 | Batch_idx: 140 |  Loss: (0.4243) |  Loss2: (0.0000) | Acc: (85.00%) (15370/18048)
Epoch: 46 | Batch_idx: 150 |  Loss: (0.4257) |  Loss2: (0.0000) | Acc: (85.00%) (16458/19328)
Epoch: 46 | Batch_idx: 160 |  Loss: (0.4270) |  Loss2: (0.0000) | Acc: (85.00%) (17531/20608)
Epoch: 46 | Batch_idx: 170 |  Loss: (0.4299) |  Loss2: (0.0000) | Acc: (84.00%) (18599/21888)
Epoch: 46 | Batch_idx: 180 |  Loss: (0.4308) |  Loss2: (0.0000) | Acc: (84.00%) (19668/23168)
Epoch: 46 | Batch_idx: 190 |  Loss: (0.4309) |  Loss2: (0.0000) | Acc: (84.00%) (20754/24448)
Epoch: 46 | Batch_idx: 200 |  Loss: (0.4314) |  Loss2: (0.0000) | Acc: (84.00%) (21832/25728)
Epoch: 46 | Batch_idx: 210 |  Loss: (0.4321) |  Loss2: (0.0000) | Acc: (84.00%) (22907/27008)
Epoch: 46 | Batch_idx: 220 |  Loss: (0.4325) |  Loss2: (0.0000) | Acc: (84.00%) (23990/28288)
Epoch: 46 | Batch_idx: 230 |  Loss: (0.4307) |  Loss2: (0.0000) | Acc: (84.00%) (25093/29568)
Epoch: 46 | Batch_idx: 240 |  Loss: (0.4295) |  Loss2: (0.0000) | Acc: (84.00%) (26177/30848)
Epoch: 46 | Batch_idx: 250 |  Loss: (0.4283) |  Loss2: (0.0000) | Acc: (84.00%) (27294/32128)
Epoch: 46 | Batch_idx: 260 |  Loss: (0.4280) |  Loss2: (0.0000) | Acc: (84.00%) (28384/33408)
Epoch: 46 | Batch_idx: 270 |  Loss: (0.4281) |  Loss2: (0.0000) | Acc: (84.00%) (29474/34688)
Epoch: 46 | Batch_idx: 280 |  Loss: (0.4282) |  Loss2: (0.0000) | Acc: (84.00%) (30562/35968)
Epoch: 46 | Batch_idx: 290 |  Loss: (0.4281) |  Loss2: (0.0000) | Acc: (84.00%) (31658/37248)
Epoch: 46 | Batch_idx: 300 |  Loss: (0.4268) |  Loss2: (0.0000) | Acc: (85.00%) (32765/38528)
Epoch: 46 | Batch_idx: 310 |  Loss: (0.4262) |  Loss2: (0.0000) | Acc: (85.00%) (33870/39808)
Epoch: 46 | Batch_idx: 320 |  Loss: (0.4260) |  Loss2: (0.0000) | Acc: (85.00%) (34965/41088)
Epoch: 46 | Batch_idx: 330 |  Loss: (0.4256) |  Loss2: (0.0000) | Acc: (85.00%) (36063/42368)
Epoch: 46 | Batch_idx: 340 |  Loss: (0.4257) |  Loss2: (0.0000) | Acc: (85.00%) (37154/43648)
Epoch: 46 | Batch_idx: 350 |  Loss: (0.4251) |  Loss2: (0.0000) | Acc: (85.00%) (38251/44928)
Epoch: 46 | Batch_idx: 360 |  Loss: (0.4252) |  Loss2: (0.0000) | Acc: (85.00%) (39330/46208)
Epoch: 46 | Batch_idx: 370 |  Loss: (0.4260) |  Loss2: (0.0000) | Acc: (85.00%) (40405/47488)
Epoch: 46 | Batch_idx: 380 |  Loss: (0.4256) |  Loss2: (0.0000) | Acc: (85.00%) (41504/48768)
Epoch: 46 | Batch_idx: 390 |  Loss: (0.4244) |  Loss2: (0.0000) | Acc: (85.00%) (42572/50000)
# TEST : Loss: (0.4991) | Acc: (83.00%) (8342/10000)
percent tensor([0.4896, 0.4807, 0.4794, 0.4802, 0.4804, 0.4955, 0.4806, 0.4793, 0.4855,
        0.4804, 0.4876, 0.4775, 0.4835, 0.4852, 0.4846, 0.4870],
       device='cuda:0') torch.Size([16])
percent tensor([0.5163, 0.5114, 0.5214, 0.5203, 0.5212, 0.5165, 0.5152, 0.5236, 0.5202,
        0.5132, 0.5159, 0.5149, 0.5102, 0.5189, 0.5142, 0.5162],
       device='cuda:0') torch.Size([16])
percent tensor([0.5183, 0.5190, 0.5212, 0.5312, 0.5209, 0.5168, 0.5200, 0.5281, 0.5205,
        0.5227, 0.5178, 0.5188, 0.5104, 0.5343, 0.5141, 0.5238],
       device='cuda:0') torch.Size([16])
percent tensor([0.5685, 0.5846, 0.5661, 0.5583, 0.5650, 0.5618, 0.5838, 0.5649, 0.5806,
        0.5878, 0.5906, 0.5763, 0.5792, 0.5964, 0.5695, 0.5777],
       device='cuda:0') torch.Size([16])
percent tensor([0.5151, 0.5274, 0.4401, 0.4437, 0.4149, 0.5220, 0.5107, 0.3916, 0.5246,
        0.5365, 0.5573, 0.4694, 0.5287, 0.5543, 0.4637, 0.5267],
       device='cuda:0') torch.Size([16])
percent tensor([0.5243, 0.5238, 0.5217, 0.5223, 0.5347, 0.5311, 0.5256, 0.5370, 0.5247,
        0.5236, 0.5151, 0.5116, 0.5183, 0.5221, 0.5235, 0.5336],
       device='cuda:0') torch.Size([16])
percent tensor([0.5424, 0.5723, 0.6258, 0.6113, 0.6538, 0.6226, 0.5505, 0.6673, 0.5737,
        0.5552, 0.5463, 0.5763, 0.5320, 0.5509, 0.5710, 0.5549],
       device='cuda:0') torch.Size([16])
percent tensor([0.9672, 0.9594, 0.9703, 0.9791, 0.9677, 0.9795, 0.9624, 0.9759, 0.9825,
        0.9724, 0.9822, 0.9745, 0.9767, 0.9488, 0.9684, 0.9733],
       device='cuda:0') torch.Size([16])
Epoch: 47 | Batch_idx: 0 |  Loss: (0.4499) |  Loss2: (0.0000) | Acc: (82.00%) (106/128)
Epoch: 47 | Batch_idx: 10 |  Loss: (0.4190) |  Loss2: (0.0000) | Acc: (85.00%) (1207/1408)
Epoch: 47 | Batch_idx: 20 |  Loss: (0.4173) |  Loss2: (0.0000) | Acc: (85.00%) (2300/2688)
Epoch: 47 | Batch_idx: 30 |  Loss: (0.4105) |  Loss2: (0.0000) | Acc: (85.00%) (3410/3968)
Epoch: 47 | Batch_idx: 40 |  Loss: (0.4211) |  Loss2: (0.0000) | Acc: (85.00%) (4492/5248)
Epoch: 47 | Batch_idx: 50 |  Loss: (0.4184) |  Loss2: (0.0000) | Acc: (85.00%) (5590/6528)
Epoch: 47 | Batch_idx: 60 |  Loss: (0.4125) |  Loss2: (0.0000) | Acc: (86.00%) (6716/7808)
Epoch: 47 | Batch_idx: 70 |  Loss: (0.4162) |  Loss2: (0.0000) | Acc: (85.00%) (7804/9088)
Epoch: 47 | Batch_idx: 80 |  Loss: (0.4191) |  Loss2: (0.0000) | Acc: (85.00%) (8896/10368)
Epoch: 47 | Batch_idx: 90 |  Loss: (0.4173) |  Loss2: (0.0000) | Acc: (85.00%) (9992/11648)
Epoch: 47 | Batch_idx: 100 |  Loss: (0.4152) |  Loss2: (0.0000) | Acc: (85.00%) (11105/12928)
Epoch: 47 | Batch_idx: 110 |  Loss: (0.4177) |  Loss2: (0.0000) | Acc: (85.00%) (12203/14208)
Epoch: 47 | Batch_idx: 120 |  Loss: (0.4165) |  Loss2: (0.0000) | Acc: (85.00%) (13301/15488)
Epoch: 47 | Batch_idx: 130 |  Loss: (0.4180) |  Loss2: (0.0000) | Acc: (85.00%) (14390/16768)
Epoch: 47 | Batch_idx: 140 |  Loss: (0.4162) |  Loss2: (0.0000) | Acc: (85.00%) (15493/18048)
Epoch: 47 | Batch_idx: 150 |  Loss: (0.4170) |  Loss2: (0.0000) | Acc: (85.00%) (16585/19328)
Epoch: 47 | Batch_idx: 160 |  Loss: (0.4169) |  Loss2: (0.0000) | Acc: (85.00%) (17677/20608)
Epoch: 47 | Batch_idx: 170 |  Loss: (0.4179) |  Loss2: (0.0000) | Acc: (85.00%) (18756/21888)
Epoch: 47 | Batch_idx: 180 |  Loss: (0.4168) |  Loss2: (0.0000) | Acc: (85.00%) (19859/23168)
Epoch: 47 | Batch_idx: 190 |  Loss: (0.4181) |  Loss2: (0.0000) | Acc: (85.00%) (20944/24448)
Epoch: 47 | Batch_idx: 200 |  Loss: (0.4168) |  Loss2: (0.0000) | Acc: (85.00%) (22060/25728)
Epoch: 47 | Batch_idx: 210 |  Loss: (0.4166) |  Loss2: (0.0000) | Acc: (85.00%) (23160/27008)
Epoch: 47 | Batch_idx: 220 |  Loss: (0.4157) |  Loss2: (0.0000) | Acc: (85.00%) (24260/28288)
Epoch: 47 | Batch_idx: 230 |  Loss: (0.4154) |  Loss2: (0.0000) | Acc: (85.00%) (25358/29568)
Epoch: 47 | Batch_idx: 240 |  Loss: (0.4145) |  Loss2: (0.0000) | Acc: (85.00%) (26469/30848)
Epoch: 47 | Batch_idx: 250 |  Loss: (0.4153) |  Loss2: (0.0000) | Acc: (85.00%) (27555/32128)
Epoch: 47 | Batch_idx: 260 |  Loss: (0.4143) |  Loss2: (0.0000) | Acc: (85.00%) (28649/33408)
Epoch: 47 | Batch_idx: 270 |  Loss: (0.4141) |  Loss2: (0.0000) | Acc: (85.00%) (29767/34688)
Epoch: 47 | Batch_idx: 280 |  Loss: (0.4137) |  Loss2: (0.0000) | Acc: (85.00%) (30862/35968)
Epoch: 47 | Batch_idx: 290 |  Loss: (0.4121) |  Loss2: (0.0000) | Acc: (85.00%) (31979/37248)
Epoch: 47 | Batch_idx: 300 |  Loss: (0.4111) |  Loss2: (0.0000) | Acc: (85.00%) (33087/38528)
Epoch: 47 | Batch_idx: 310 |  Loss: (0.4113) |  Loss2: (0.0000) | Acc: (85.00%) (34194/39808)
Epoch: 47 | Batch_idx: 320 |  Loss: (0.4117) |  Loss2: (0.0000) | Acc: (85.00%) (35290/41088)
Epoch: 47 | Batch_idx: 330 |  Loss: (0.4117) |  Loss2: (0.0000) | Acc: (85.00%) (36376/42368)
Epoch: 47 | Batch_idx: 340 |  Loss: (0.4127) |  Loss2: (0.0000) | Acc: (85.00%) (37458/43648)
Epoch: 47 | Batch_idx: 350 |  Loss: (0.4121) |  Loss2: (0.0000) | Acc: (85.00%) (38567/44928)
Epoch: 47 | Batch_idx: 360 |  Loss: (0.4122) |  Loss2: (0.0000) | Acc: (85.00%) (39656/46208)
Epoch: 47 | Batch_idx: 370 |  Loss: (0.4111) |  Loss2: (0.0000) | Acc: (85.00%) (40771/47488)
Epoch: 47 | Batch_idx: 380 |  Loss: (0.4123) |  Loss2: (0.0000) | Acc: (85.00%) (41855/48768)
Epoch: 47 | Batch_idx: 390 |  Loss: (0.4121) |  Loss2: (0.0000) | Acc: (85.00%) (42903/50000)
# TEST : Loss: (0.4910) | Acc: (83.00%) (8333/10000)
percent tensor([0.4901, 0.4809, 0.4812, 0.4815, 0.4819, 0.4960, 0.4813, 0.4806, 0.4861,
        0.4811, 0.4878, 0.4788, 0.4839, 0.4853, 0.4850, 0.4876],
       device='cuda:0') torch.Size([16])
percent tensor([0.5169, 0.5115, 0.5225, 0.5219, 0.5221, 0.5172, 0.5155, 0.5249, 0.5208,
        0.5136, 0.5163, 0.5155, 0.5102, 0.5194, 0.5147, 0.5169],
       device='cuda:0') torch.Size([16])
percent tensor([0.5189, 0.5162, 0.5214, 0.5334, 0.5218, 0.5202, 0.5187, 0.5289, 0.5191,
        0.5199, 0.5161, 0.5169, 0.5080, 0.5334, 0.5147, 0.5242],
       device='cuda:0') torch.Size([16])
percent tensor([0.5699, 0.5851, 0.5688, 0.5611, 0.5673, 0.5635, 0.5848, 0.5665, 0.5821,
        0.5887, 0.5922, 0.5781, 0.5798, 0.5972, 0.5707, 0.5792],
       device='cuda:0') torch.Size([16])
percent tensor([0.5177, 0.5271, 0.4425, 0.4468, 0.4173, 0.5290, 0.5110, 0.3884, 0.5297,
        0.5364, 0.5616, 0.4715, 0.5293, 0.5567, 0.4660, 0.5302],
       device='cuda:0') torch.Size([16])
percent tensor([0.5304, 0.5295, 0.5280, 0.5290, 0.5432, 0.5382, 0.5320, 0.5458, 0.5303,
        0.5295, 0.5193, 0.5153, 0.5233, 0.5270, 0.5293, 0.5413],
       device='cuda:0') torch.Size([16])
percent tensor([0.5440, 0.5770, 0.6372, 0.6211, 0.6712, 0.6368, 0.5544, 0.6827, 0.5779,
        0.5593, 0.5483, 0.5776, 0.5335, 0.5526, 0.5741, 0.5620],
       device='cuda:0') torch.Size([16])
percent tensor([0.9767, 0.9704, 0.9799, 0.9855, 0.9775, 0.9844, 0.9733, 0.9850, 0.9887,
        0.9818, 0.9886, 0.9826, 0.9844, 0.9624, 0.9783, 0.9799],
       device='cuda:0') torch.Size([16])
Epoch: 48 | Batch_idx: 0 |  Loss: (0.4951) |  Loss2: (0.0000) | Acc: (82.00%) (105/128)
Epoch: 48 | Batch_idx: 10 |  Loss: (0.4058) |  Loss2: (0.0000) | Acc: (85.00%) (1207/1408)
Epoch: 48 | Batch_idx: 20 |  Loss: (0.3904) |  Loss2: (0.0000) | Acc: (86.00%) (2318/2688)
Epoch: 48 | Batch_idx: 30 |  Loss: (0.4002) |  Loss2: (0.0000) | Acc: (86.00%) (3427/3968)
Epoch: 48 | Batch_idx: 40 |  Loss: (0.3945) |  Loss2: (0.0000) | Acc: (86.00%) (4539/5248)
Epoch: 48 | Batch_idx: 50 |  Loss: (0.3999) |  Loss2: (0.0000) | Acc: (86.00%) (5636/6528)
Epoch: 48 | Batch_idx: 60 |  Loss: (0.4063) |  Loss2: (0.0000) | Acc: (86.00%) (6728/7808)
Epoch: 48 | Batch_idx: 70 |  Loss: (0.4058) |  Loss2: (0.0000) | Acc: (86.00%) (7831/9088)
Epoch: 48 | Batch_idx: 80 |  Loss: (0.4059) |  Loss2: (0.0000) | Acc: (86.00%) (8927/10368)
Epoch: 48 | Batch_idx: 90 |  Loss: (0.4076) |  Loss2: (0.0000) | Acc: (85.00%) (10016/11648)
Epoch: 48 | Batch_idx: 100 |  Loss: (0.4090) |  Loss2: (0.0000) | Acc: (85.00%) (11106/12928)
Epoch: 48 | Batch_idx: 110 |  Loss: (0.4133) |  Loss2: (0.0000) | Acc: (85.00%) (12180/14208)
Epoch: 48 | Batch_idx: 120 |  Loss: (0.4112) |  Loss2: (0.0000) | Acc: (85.00%) (13291/15488)
Epoch: 48 | Batch_idx: 130 |  Loss: (0.4084) |  Loss2: (0.0000) | Acc: (85.00%) (14412/16768)
Epoch: 48 | Batch_idx: 140 |  Loss: (0.4084) |  Loss2: (0.0000) | Acc: (85.00%) (15508/18048)
Epoch: 48 | Batch_idx: 150 |  Loss: (0.4071) |  Loss2: (0.0000) | Acc: (85.00%) (16602/19328)
Epoch: 48 | Batch_idx: 160 |  Loss: (0.4056) |  Loss2: (0.0000) | Acc: (85.00%) (17716/20608)
Epoch: 48 | Batch_idx: 170 |  Loss: (0.4061) |  Loss2: (0.0000) | Acc: (85.00%) (18816/21888)
Epoch: 48 | Batch_idx: 180 |  Loss: (0.4065) |  Loss2: (0.0000) | Acc: (85.00%) (19902/23168)
Epoch: 48 | Batch_idx: 190 |  Loss: (0.4044) |  Loss2: (0.0000) | Acc: (85.00%) (21019/24448)
Epoch: 48 | Batch_idx: 200 |  Loss: (0.4061) |  Loss2: (0.0000) | Acc: (85.00%) (22099/25728)
Epoch: 48 | Batch_idx: 210 |  Loss: (0.4079) |  Loss2: (0.0000) | Acc: (85.00%) (23171/27008)
Epoch: 48 | Batch_idx: 220 |  Loss: (0.4079) |  Loss2: (0.0000) | Acc: (85.00%) (24278/28288)
Epoch: 48 | Batch_idx: 230 |  Loss: (0.4091) |  Loss2: (0.0000) | Acc: (85.00%) (25374/29568)
Epoch: 48 | Batch_idx: 240 |  Loss: (0.4096) |  Loss2: (0.0000) | Acc: (85.00%) (26470/30848)
Epoch: 48 | Batch_idx: 250 |  Loss: (0.4110) |  Loss2: (0.0000) | Acc: (85.00%) (27552/32128)
Epoch: 48 | Batch_idx: 260 |  Loss: (0.4096) |  Loss2: (0.0000) | Acc: (85.00%) (28677/33408)
Epoch: 48 | Batch_idx: 270 |  Loss: (0.4086) |  Loss2: (0.0000) | Acc: (85.00%) (29793/34688)
Epoch: 48 | Batch_idx: 280 |  Loss: (0.4079) |  Loss2: (0.0000) | Acc: (85.00%) (30892/35968)
Epoch: 48 | Batch_idx: 290 |  Loss: (0.4075) |  Loss2: (0.0000) | Acc: (85.00%) (32004/37248)
Epoch: 48 | Batch_idx: 300 |  Loss: (0.4070) |  Loss2: (0.0000) | Acc: (85.00%) (33116/38528)
Epoch: 48 | Batch_idx: 310 |  Loss: (0.4077) |  Loss2: (0.0000) | Acc: (85.00%) (34206/39808)
Epoch: 48 | Batch_idx: 320 |  Loss: (0.4078) |  Loss2: (0.0000) | Acc: (85.00%) (35302/41088)
Epoch: 48 | Batch_idx: 330 |  Loss: (0.4089) |  Loss2: (0.0000) | Acc: (85.00%) (36374/42368)
Epoch: 48 | Batch_idx: 340 |  Loss: (0.4091) |  Loss2: (0.0000) | Acc: (85.00%) (37458/43648)
Epoch: 48 | Batch_idx: 350 |  Loss: (0.4086) |  Loss2: (0.0000) | Acc: (85.00%) (38568/44928)
Epoch: 48 | Batch_idx: 360 |  Loss: (0.4093) |  Loss2: (0.0000) | Acc: (85.00%) (39663/46208)
Epoch: 48 | Batch_idx: 370 |  Loss: (0.4091) |  Loss2: (0.0000) | Acc: (85.00%) (40766/47488)
Epoch: 48 | Batch_idx: 380 |  Loss: (0.4082) |  Loss2: (0.0000) | Acc: (85.00%) (41882/48768)
Epoch: 48 | Batch_idx: 390 |  Loss: (0.4074) |  Loss2: (0.0000) | Acc: (85.00%) (42944/50000)
# TEST : Loss: (0.4841) | Acc: (83.00%) (8387/10000)
percent tensor([0.4904, 0.4810, 0.4822, 0.4819, 0.4828, 0.4963, 0.4817, 0.4812, 0.4863,
        0.4816, 0.4879, 0.4797, 0.4840, 0.4852, 0.4852, 0.4879],
       device='cuda:0') torch.Size([16])
percent tensor([0.5162, 0.5105, 0.5222, 0.5217, 0.5216, 0.5168, 0.5147, 0.5245, 0.5201,
        0.5127, 0.5155, 0.5148, 0.5093, 0.5187, 0.5140, 0.5163],
       device='cuda:0') torch.Size([16])
percent tensor([0.5219, 0.5175, 0.5236, 0.5376, 0.5249, 0.5244, 0.5213, 0.5321, 0.5210,
        0.5213, 0.5183, 0.5184, 0.5089, 0.5360, 0.5182, 0.5268],
       device='cuda:0') torch.Size([16])
percent tensor([0.5655, 0.5796, 0.5652, 0.5575, 0.5631, 0.5595, 0.5792, 0.5620, 0.5777,
        0.5837, 0.5873, 0.5735, 0.5750, 0.5922, 0.5653, 0.5743],
       device='cuda:0') torch.Size([16])
percent tensor([0.5214, 0.5258, 0.4494, 0.4559, 0.4236, 0.5347, 0.5116, 0.3928, 0.5337,
        0.5360, 0.5653, 0.4797, 0.5296, 0.5587, 0.4738, 0.5332],
       device='cuda:0') torch.Size([16])
percent tensor([0.5356, 0.5335, 0.5339, 0.5354, 0.5511, 0.5441, 0.5373, 0.5538, 0.5349,
        0.5337, 0.5222, 0.5180, 0.5266, 0.5306, 0.5336, 0.5475],
       device='cuda:0') torch.Size([16])
percent tensor([0.5368, 0.5692, 0.6366, 0.6219, 0.6754, 0.6414, 0.5483, 0.6814, 0.5743,
        0.5492, 0.5428, 0.5662, 0.5272, 0.5466, 0.5637, 0.5576],
       device='cuda:0') torch.Size([16])
percent tensor([0.9824, 0.9764, 0.9844, 0.9885, 0.9822, 0.9877, 0.9787, 0.9889, 0.9914,
        0.9857, 0.9914, 0.9861, 0.9884, 0.9704, 0.9827, 0.9850],
       device='cuda:0') torch.Size([16])
Epoch: 49 | Batch_idx: 0 |  Loss: (0.2965) |  Loss2: (0.0000) | Acc: (91.00%) (117/128)
Epoch: 49 | Batch_idx: 10 |  Loss: (0.4336) |  Loss2: (0.0000) | Acc: (84.00%) (1194/1408)
Epoch: 49 | Batch_idx: 20 |  Loss: (0.4120) |  Loss2: (0.0000) | Acc: (86.00%) (2321/2688)
Epoch: 49 | Batch_idx: 30 |  Loss: (0.4214) |  Loss2: (0.0000) | Acc: (85.00%) (3396/3968)
Epoch: 49 | Batch_idx: 40 |  Loss: (0.4147) |  Loss2: (0.0000) | Acc: (85.00%) (4503/5248)
Epoch: 49 | Batch_idx: 50 |  Loss: (0.4101) |  Loss2: (0.0000) | Acc: (85.00%) (5608/6528)
Epoch: 49 | Batch_idx: 60 |  Loss: (0.4030) |  Loss2: (0.0000) | Acc: (86.00%) (6727/7808)
Epoch: 49 | Batch_idx: 70 |  Loss: (0.3974) |  Loss2: (0.0000) | Acc: (86.00%) (7859/9088)
Epoch: 49 | Batch_idx: 80 |  Loss: (0.3988) |  Loss2: (0.0000) | Acc: (86.00%) (8967/10368)
Epoch: 49 | Batch_idx: 90 |  Loss: (0.3935) |  Loss2: (0.0000) | Acc: (86.00%) (10090/11648)
Epoch: 49 | Batch_idx: 100 |  Loss: (0.3921) |  Loss2: (0.0000) | Acc: (86.00%) (11205/12928)
Epoch: 49 | Batch_idx: 110 |  Loss: (0.3949) |  Loss2: (0.0000) | Acc: (86.00%) (12294/14208)
Epoch: 49 | Batch_idx: 120 |  Loss: (0.3942) |  Loss2: (0.0000) | Acc: (86.00%) (13390/15488)
Epoch: 49 | Batch_idx: 130 |  Loss: (0.3955) |  Loss2: (0.0000) | Acc: (86.00%) (14492/16768)
Epoch: 49 | Batch_idx: 140 |  Loss: (0.3967) |  Loss2: (0.0000) | Acc: (86.00%) (15592/18048)
Epoch: 49 | Batch_idx: 150 |  Loss: (0.3948) |  Loss2: (0.0000) | Acc: (86.00%) (16706/19328)
Epoch: 49 | Batch_idx: 160 |  Loss: (0.3959) |  Loss2: (0.0000) | Acc: (86.00%) (17795/20608)
Epoch: 49 | Batch_idx: 170 |  Loss: (0.3972) |  Loss2: (0.0000) | Acc: (86.00%) (18886/21888)
Epoch: 49 | Batch_idx: 180 |  Loss: (0.3972) |  Loss2: (0.0000) | Acc: (86.00%) (19979/23168)
Epoch: 49 | Batch_idx: 190 |  Loss: (0.3982) |  Loss2: (0.0000) | Acc: (86.00%) (21079/24448)
Epoch: 49 | Batch_idx: 200 |  Loss: (0.3989) |  Loss2: (0.0000) | Acc: (86.00%) (22187/25728)
Epoch: 49 | Batch_idx: 210 |  Loss: (0.4004) |  Loss2: (0.0000) | Acc: (86.00%) (23274/27008)
Epoch: 49 | Batch_idx: 220 |  Loss: (0.4018) |  Loss2: (0.0000) | Acc: (86.00%) (24372/28288)
Epoch: 49 | Batch_idx: 230 |  Loss: (0.4019) |  Loss2: (0.0000) | Acc: (86.00%) (25478/29568)
Epoch: 49 | Batch_idx: 240 |  Loss: (0.4010) |  Loss2: (0.0000) | Acc: (86.00%) (26582/30848)
Epoch: 49 | Batch_idx: 250 |  Loss: (0.4000) |  Loss2: (0.0000) | Acc: (86.00%) (27697/32128)
Epoch: 49 | Batch_idx: 260 |  Loss: (0.3989) |  Loss2: (0.0000) | Acc: (86.00%) (28811/33408)
Epoch: 49 | Batch_idx: 270 |  Loss: (0.3992) |  Loss2: (0.0000) | Acc: (86.00%) (29902/34688)
Epoch: 49 | Batch_idx: 280 |  Loss: (0.3994) |  Loss2: (0.0000) | Acc: (86.00%) (31003/35968)
Epoch: 49 | Batch_idx: 290 |  Loss: (0.3986) |  Loss2: (0.0000) | Acc: (86.00%) (32109/37248)
Epoch: 49 | Batch_idx: 300 |  Loss: (0.3996) |  Loss2: (0.0000) | Acc: (86.00%) (33188/38528)
Epoch: 49 | Batch_idx: 310 |  Loss: (0.3997) |  Loss2: (0.0000) | Acc: (86.00%) (34291/39808)
Epoch: 49 | Batch_idx: 320 |  Loss: (0.3988) |  Loss2: (0.0000) | Acc: (86.00%) (35409/41088)
Epoch: 49 | Batch_idx: 330 |  Loss: (0.3997) |  Loss2: (0.0000) | Acc: (86.00%) (36500/42368)
Epoch: 49 | Batch_idx: 340 |  Loss: (0.4004) |  Loss2: (0.0000) | Acc: (86.00%) (37587/43648)
Epoch: 49 | Batch_idx: 350 |  Loss: (0.4008) |  Loss2: (0.0000) | Acc: (86.00%) (38683/44928)
Epoch: 49 | Batch_idx: 360 |  Loss: (0.4010) |  Loss2: (0.0000) | Acc: (86.00%) (39787/46208)
Epoch: 49 | Batch_idx: 370 |  Loss: (0.4017) |  Loss2: (0.0000) | Acc: (86.00%) (40885/47488)
Epoch: 49 | Batch_idx: 380 |  Loss: (0.4028) |  Loss2: (0.0000) | Acc: (86.00%) (41959/48768)
Epoch: 49 | Batch_idx: 390 |  Loss: (0.4028) |  Loss2: (0.0000) | Acc: (86.00%) (43015/50000)
# TEST : Loss: (0.4819) | Acc: (84.00%) (8400/10000)
percent tensor([0.4897, 0.4798, 0.4819, 0.4812, 0.4823, 0.4958, 0.4807, 0.4805, 0.4854,
        0.4806, 0.4869, 0.4790, 0.4830, 0.4840, 0.4843, 0.4871],
       device='cuda:0') torch.Size([16])
percent tensor([0.5150, 0.5090, 0.5212, 0.5210, 0.5207, 0.5159, 0.5134, 0.5235, 0.5189,
        0.5113, 0.5141, 0.5135, 0.5077, 0.5176, 0.5128, 0.5151],
       device='cuda:0') torch.Size([16])
percent tensor([0.5201, 0.5149, 0.5215, 0.5367, 0.5235, 0.5234, 0.5195, 0.5310, 0.5187,
        0.5186, 0.5159, 0.5154, 0.5057, 0.5351, 0.5167, 0.5252],
       device='cuda:0') torch.Size([16])
percent tensor([0.5664, 0.5802, 0.5670, 0.5591, 0.5645, 0.5603, 0.5798, 0.5629, 0.5792,
        0.5845, 0.5886, 0.5747, 0.5757, 0.5935, 0.5659, 0.5752],
       device='cuda:0') torch.Size([16])
percent tensor([0.5239, 0.5258, 0.4550, 0.4632, 0.4284, 0.5384, 0.5131, 0.3948, 0.5371,
        0.5361, 0.5692, 0.4851, 0.5297, 0.5606, 0.4785, 0.5361],
       device='cuda:0') torch.Size([16])
percent tensor([0.5381, 0.5359, 0.5369, 0.5388, 0.5560, 0.5478, 0.5403, 0.5588, 0.5372,
        0.5358, 0.5234, 0.5193, 0.5285, 0.5322, 0.5362, 0.5514],
       device='cuda:0') torch.Size([16])
percent tensor([0.5271, 0.5612, 0.6334, 0.6190, 0.6777, 0.6412, 0.5413, 0.6836, 0.5656,
        0.5391, 0.5344, 0.5563, 0.5187, 0.5361, 0.5553, 0.5520],
       device='cuda:0') torch.Size([16])
percent tensor([0.9865, 0.9808, 0.9877, 0.9906, 0.9856, 0.9900, 0.9827, 0.9914, 0.9936,
        0.9887, 0.9935, 0.9886, 0.9913, 0.9759, 0.9861, 0.9880],
       device='cuda:0') torch.Size([16])
Epoch: 50 | Batch_idx: 0 |  Loss: (0.3897) |  Loss2: (0.0000) | Acc: (85.00%) (109/128)
Epoch: 50 | Batch_idx: 10 |  Loss: (0.3674) |  Loss2: (0.0000) | Acc: (87.00%) (1228/1408)
Epoch: 50 | Batch_idx: 20 |  Loss: (0.3617) |  Loss2: (0.0000) | Acc: (87.00%) (2352/2688)
Epoch: 50 | Batch_idx: 30 |  Loss: (0.3755) |  Loss2: (0.0000) | Acc: (86.00%) (3448/3968)
Epoch: 50 | Batch_idx: 40 |  Loss: (0.3847) |  Loss2: (0.0000) | Acc: (86.00%) (4536/5248)
Epoch: 50 | Batch_idx: 50 |  Loss: (0.3826) |  Loss2: (0.0000) | Acc: (86.00%) (5653/6528)
Epoch: 50 | Batch_idx: 60 |  Loss: (0.3872) |  Loss2: (0.0000) | Acc: (86.00%) (6752/7808)
Epoch: 50 | Batch_idx: 70 |  Loss: (0.3863) |  Loss2: (0.0000) | Acc: (86.00%) (7884/9088)
Epoch: 50 | Batch_idx: 80 |  Loss: (0.3869) |  Loss2: (0.0000) | Acc: (86.00%) (8980/10368)
Epoch: 50 | Batch_idx: 90 |  Loss: (0.3908) |  Loss2: (0.0000) | Acc: (86.00%) (10068/11648)
Epoch: 50 | Batch_idx: 100 |  Loss: (0.3915) |  Loss2: (0.0000) | Acc: (86.00%) (11178/12928)
Epoch: 50 | Batch_idx: 110 |  Loss: (0.3942) |  Loss2: (0.0000) | Acc: (86.00%) (12263/14208)
Epoch: 50 | Batch_idx: 120 |  Loss: (0.3949) |  Loss2: (0.0000) | Acc: (86.00%) (13364/15488)
Epoch: 50 | Batch_idx: 130 |  Loss: (0.3942) |  Loss2: (0.0000) | Acc: (86.00%) (14475/16768)
Epoch: 50 | Batch_idx: 140 |  Loss: (0.3997) |  Loss2: (0.0000) | Acc: (86.00%) (15552/18048)
Epoch: 50 | Batch_idx: 150 |  Loss: (0.3972) |  Loss2: (0.0000) | Acc: (86.00%) (16686/19328)
Epoch: 50 | Batch_idx: 160 |  Loss: (0.3969) |  Loss2: (0.0000) | Acc: (86.00%) (17798/20608)
Epoch: 50 | Batch_idx: 170 |  Loss: (0.3955) |  Loss2: (0.0000) | Acc: (86.00%) (18910/21888)
Epoch: 50 | Batch_idx: 180 |  Loss: (0.3975) |  Loss2: (0.0000) | Acc: (86.00%) (20010/23168)
Epoch: 50 | Batch_idx: 190 |  Loss: (0.3980) |  Loss2: (0.0000) | Acc: (86.00%) (21098/24448)
Epoch: 50 | Batch_idx: 200 |  Loss: (0.3984) |  Loss2: (0.0000) | Acc: (86.00%) (22186/25728)
Epoch: 50 | Batch_idx: 210 |  Loss: (0.3983) |  Loss2: (0.0000) | Acc: (86.00%) (23295/27008)
Epoch: 50 | Batch_idx: 220 |  Loss: (0.3987) |  Loss2: (0.0000) | Acc: (86.00%) (24405/28288)
Epoch: 50 | Batch_idx: 230 |  Loss: (0.3974) |  Loss2: (0.0000) | Acc: (86.00%) (25510/29568)
Epoch: 50 | Batch_idx: 240 |  Loss: (0.3978) |  Loss2: (0.0000) | Acc: (86.00%) (26603/30848)
Epoch: 50 | Batch_idx: 250 |  Loss: (0.3977) |  Loss2: (0.0000) | Acc: (86.00%) (27699/32128)
Epoch: 50 | Batch_idx: 260 |  Loss: (0.3998) |  Loss2: (0.0000) | Acc: (86.00%) (28785/33408)
Epoch: 50 | Batch_idx: 270 |  Loss: (0.4004) |  Loss2: (0.0000) | Acc: (86.00%) (29881/34688)
Epoch: 50 | Batch_idx: 280 |  Loss: (0.4024) |  Loss2: (0.0000) | Acc: (86.00%) (30965/35968)
Epoch: 50 | Batch_idx: 290 |  Loss: (0.4017) |  Loss2: (0.0000) | Acc: (86.00%) (32079/37248)
Epoch: 50 | Batch_idx: 300 |  Loss: (0.4010) |  Loss2: (0.0000) | Acc: (86.00%) (33206/38528)
Epoch: 50 | Batch_idx: 310 |  Loss: (0.4016) |  Loss2: (0.0000) | Acc: (86.00%) (34301/39808)
Epoch: 50 | Batch_idx: 320 |  Loss: (0.4017) |  Loss2: (0.0000) | Acc: (86.00%) (35416/41088)
Epoch: 50 | Batch_idx: 330 |  Loss: (0.4018) |  Loss2: (0.0000) | Acc: (86.00%) (36515/42368)
Epoch: 50 | Batch_idx: 340 |  Loss: (0.4005) |  Loss2: (0.0000) | Acc: (86.00%) (37638/43648)
Epoch: 50 | Batch_idx: 350 |  Loss: (0.3998) |  Loss2: (0.0000) | Acc: (86.00%) (38747/44928)
Epoch: 50 | Batch_idx: 360 |  Loss: (0.4000) |  Loss2: (0.0000) | Acc: (86.00%) (39844/46208)
Epoch: 50 | Batch_idx: 370 |  Loss: (0.4004) |  Loss2: (0.0000) | Acc: (86.00%) (40941/47488)
Epoch: 50 | Batch_idx: 380 |  Loss: (0.4004) |  Loss2: (0.0000) | Acc: (86.00%) (42035/48768)
Epoch: 50 | Batch_idx: 390 |  Loss: (0.4002) |  Loss2: (0.0000) | Acc: (86.00%) (43099/50000)
=> saving checkpoint 'drive/app/torch/save_Schedule/checkpoint_050.pth.tar'
# TEST : Loss: (0.4779) | Acc: (84.00%) (8424/10000)
percent tensor([0.4917, 0.4818, 0.4847, 0.4833, 0.4850, 0.4978, 0.4832, 0.4830, 0.4876,
        0.4830, 0.4890, 0.4819, 0.4849, 0.4859, 0.4863, 0.4891],
       device='cuda:0') torch.Size([16])
percent tensor([0.5152, 0.5089, 0.5216, 0.5213, 0.5211, 0.5160, 0.5134, 0.5238, 0.5191,
        0.5114, 0.5141, 0.5137, 0.5077, 0.5177, 0.5128, 0.5152],
       device='cuda:0') torch.Size([16])
percent tensor([0.5232, 0.5163, 0.5236, 0.5401, 0.5261, 0.5267, 0.5218, 0.5332, 0.5206,
        0.5201, 0.5181, 0.5167, 0.5069, 0.5376, 0.5192, 0.5276],
       device='cuda:0') torch.Size([16])
percent tensor([0.5689, 0.5823, 0.5694, 0.5612, 0.5668, 0.5624, 0.5820, 0.5651, 0.5817,
        0.5868, 0.5914, 0.5772, 0.5779, 0.5960, 0.5678, 0.5774],
       device='cuda:0') torch.Size([16])
percent tensor([0.5254, 0.5265, 0.4543, 0.4668, 0.4325, 0.5430, 0.5145, 0.3971, 0.5397,
        0.5368, 0.5728, 0.4870, 0.5317, 0.5627, 0.4825, 0.5382],
       device='cuda:0') torch.Size([16])
percent tensor([0.5374, 0.5341, 0.5369, 0.5388, 0.5573, 0.5480, 0.5390, 0.5591, 0.5365,
        0.5340, 0.5209, 0.5166, 0.5265, 0.5305, 0.5341, 0.5506],
       device='cuda:0') torch.Size([16])
percent tensor([0.5339, 0.5742, 0.6398, 0.6232, 0.6836, 0.6518, 0.5485, 0.6839, 0.5785,
        0.5509, 0.5459, 0.5599, 0.5327, 0.5487, 0.5588, 0.5569],
       device='cuda:0') torch.Size([16])
percent tensor([0.9886, 0.9841, 0.9901, 0.9923, 0.9887, 0.9912, 0.9856, 0.9933, 0.9948,
        0.9909, 0.9948, 0.9911, 0.9927, 0.9801, 0.9886, 0.9898],
       device='cuda:0') torch.Size([16])
Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 3, 3, 3]) tensor(176.1206, device='cuda:0')
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(803.0204, device='cuda:0')
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(790.8943, device='cuda:0')
Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([128, 64, 3, 3]) tensor(1530.0568, device='cuda:0')
Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([128, 64, 1, 1]) tensor(496.6133, device='cuda:0')
Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([128, 128, 3, 3]) tensor(2205.1997, device='cuda:0')
Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([256, 128, 3, 3]) tensor(4285.6533, device='cuda:0')
Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([256, 128, 1, 1]) tensor(1412.8724, device='cuda:0')
Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([256, 256, 3, 3]) tensor(6084.8179, device='cuda:0')
Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([512, 256, 3, 3]) tensor(12041.3174, device='cuda:0')
Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([512, 256, 1, 1]) tensor(4015.4907, device='cuda:0')
Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([512, 512, 3, 3]) tensor(16989.5371, device='cuda:0')
Epoch: 51 | Batch_idx: 0 |  Loss: (0.3442) |  Loss2: (0.0000) | Acc: (89.00%) (115/128)
Epoch: 51 | Batch_idx: 10 |  Loss: (0.3662) |  Loss2: (0.0000) | Acc: (87.00%) (1232/1408)
Epoch: 51 | Batch_idx: 20 |  Loss: (0.3834) |  Loss2: (0.0000) | Acc: (86.00%) (2325/2688)
Epoch: 51 | Batch_idx: 30 |  Loss: (0.3788) |  Loss2: (0.0000) | Acc: (86.00%) (3430/3968)
Epoch: 51 | Batch_idx: 40 |  Loss: (0.3837) |  Loss2: (0.0000) | Acc: (86.00%) (4528/5248)
Epoch: 51 | Batch_idx: 50 |  Loss: (0.3883) |  Loss2: (0.0000) | Acc: (86.00%) (5626/6528)
Epoch: 51 | Batch_idx: 60 |  Loss: (0.3872) |  Loss2: (0.0000) | Acc: (86.00%) (6745/7808)
Epoch: 51 | Batch_idx: 70 |  Loss: (0.3879) |  Loss2: (0.0000) | Acc: (86.00%) (7848/9088)
Epoch: 51 | Batch_idx: 80 |  Loss: (0.3909) |  Loss2: (0.0000) | Acc: (86.00%) (8959/10368)
Epoch: 51 | Batch_idx: 90 |  Loss: (0.3889) |  Loss2: (0.0000) | Acc: (86.00%) (10086/11648)
Epoch: 51 | Batch_idx: 100 |  Loss: (0.3883) |  Loss2: (0.0000) | Acc: (86.00%) (11198/12928)
Epoch: 51 | Batch_idx: 110 |  Loss: (0.3902) |  Loss2: (0.0000) | Acc: (86.00%) (12310/14208)
Epoch: 51 | Batch_idx: 120 |  Loss: (0.3862) |  Loss2: (0.0000) | Acc: (86.00%) (13448/15488)
Epoch: 51 | Batch_idx: 130 |  Loss: (0.3882) |  Loss2: (0.0000) | Acc: (86.00%) (14550/16768)
Epoch: 51 | Batch_idx: 140 |  Loss: (0.3892) |  Loss2: (0.0000) | Acc: (86.00%) (15660/18048)
Epoch: 51 | Batch_idx: 150 |  Loss: (0.3911) |  Loss2: (0.0000) | Acc: (86.00%) (16761/19328)
Epoch: 51 | Batch_idx: 160 |  Loss: (0.3906) |  Loss2: (0.0000) | Acc: (86.00%) (17861/20608)
Epoch: 51 | Batch_idx: 170 |  Loss: (0.3906) |  Loss2: (0.0000) | Acc: (86.00%) (18969/21888)
Epoch: 51 | Batch_idx: 180 |  Loss: (0.3919) |  Loss2: (0.0000) | Acc: (86.00%) (20058/23168)
Epoch: 51 | Batch_idx: 190 |  Loss: (0.3904) |  Loss2: (0.0000) | Acc: (86.00%) (21189/24448)
Epoch: 51 | Batch_idx: 200 |  Loss: (0.3888) |  Loss2: (0.0000) | Acc: (86.00%) (22306/25728)
Epoch: 51 | Batch_idx: 210 |  Loss: (0.3915) |  Loss2: (0.0000) | Acc: (86.00%) (23392/27008)
Epoch: 51 | Batch_idx: 220 |  Loss: (0.3920) |  Loss2: (0.0000) | Acc: (86.00%) (24484/28288)
Epoch: 51 | Batch_idx: 230 |  Loss: (0.3936) |  Loss2: (0.0000) | Acc: (86.00%) (25582/29568)
Epoch: 51 | Batch_idx: 240 |  Loss: (0.3935) |  Loss2: (0.0000) | Acc: (86.00%) (26681/30848)
Epoch: 51 | Batch_idx: 250 |  Loss: (0.3937) |  Loss2: (0.0000) | Acc: (86.00%) (27791/32128)
Epoch: 51 | Batch_idx: 260 |  Loss: (0.3932) |  Loss2: (0.0000) | Acc: (86.00%) (28903/33408)
Epoch: 51 | Batch_idx: 270 |  Loss: (0.3929) |  Loss2: (0.0000) | Acc: (86.00%) (30013/34688)
Epoch: 51 | Batch_idx: 280 |  Loss: (0.3942) |  Loss2: (0.0000) | Acc: (86.00%) (31111/35968)
Epoch: 51 | Batch_idx: 290 |  Loss: (0.3951) |  Loss2: (0.0000) | Acc: (86.00%) (32212/37248)
Epoch: 51 | Batch_idx: 300 |  Loss: (0.3947) |  Loss2: (0.0000) | Acc: (86.00%) (33317/38528)
Epoch: 51 | Batch_idx: 310 |  Loss: (0.3938) |  Loss2: (0.0000) | Acc: (86.00%) (34439/39808)
Epoch: 51 | Batch_idx: 320 |  Loss: (0.3933) |  Loss2: (0.0000) | Acc: (86.00%) (35549/41088)
Epoch: 51 | Batch_idx: 330 |  Loss: (0.3933) |  Loss2: (0.0000) | Acc: (86.00%) (36667/42368)
Epoch: 51 | Batch_idx: 340 |  Loss: (0.3927) |  Loss2: (0.0000) | Acc: (86.00%) (37776/43648)
Epoch: 51 | Batch_idx: 350 |  Loss: (0.3930) |  Loss2: (0.0000) | Acc: (86.00%) (38872/44928)
Epoch: 51 | Batch_idx: 360 |  Loss: (0.3932) |  Loss2: (0.0000) | Acc: (86.00%) (39975/46208)
Epoch: 51 | Batch_idx: 370 |  Loss: (0.3935) |  Loss2: (0.0000) | Acc: (86.00%) (41069/47488)
Epoch: 51 | Batch_idx: 380 |  Loss: (0.3940) |  Loss2: (0.0000) | Acc: (86.00%) (42172/48768)
Epoch: 51 | Batch_idx: 390 |  Loss: (0.3942) |  Loss2: (0.0000) | Acc: (86.00%) (43219/50000)
# TEST : Loss: (0.4757) | Acc: (84.00%) (8409/10000)
percent tensor([0.4924, 0.4827, 0.4863, 0.4845, 0.4864, 0.4986, 0.4842, 0.4843, 0.4884,
        0.4841, 0.4897, 0.4833, 0.4857, 0.4865, 0.4873, 0.4899],
       device='cuda:0') torch.Size([16])
percent tensor([0.5146, 0.5083, 0.5211, 0.5208, 0.5206, 0.5156, 0.5128, 0.5232, 0.5186,
        0.5107, 0.5136, 0.5130, 0.5070, 0.5172, 0.5123, 0.5147],
       device='cuda:0') torch.Size([16])
percent tensor([0.5209, 0.5137, 0.5220, 0.5385, 0.5247, 0.5246, 0.5198, 0.5322, 0.5185,
        0.5174, 0.5155, 0.5142, 0.5040, 0.5355, 0.5171, 0.5254],
       device='cuda:0') torch.Size([16])
percent tensor([0.5641, 0.5773, 0.5653, 0.5571, 0.5621, 0.5580, 0.5767, 0.5601, 0.5774,
        0.5819, 0.5866, 0.5724, 0.5732, 0.5913, 0.5626, 0.5724],
       device='cuda:0') torch.Size([16])
percent tensor([0.5245, 0.5244, 0.4543, 0.4701, 0.4337, 0.5456, 0.5121, 0.3942, 0.5409,
        0.5355, 0.5747, 0.4867, 0.5305, 0.5643, 0.4826, 0.5377],
       device='cuda:0') torch.Size([16])
percent tensor([0.5366, 0.5327, 0.5368, 0.5387, 0.5589, 0.5487, 0.5382, 0.5597, 0.5358,
        0.5323, 0.5187, 0.5141, 0.5245, 0.5289, 0.5326, 0.5506],
       device='cuda:0') torch.Size([16])
percent tensor([0.5349, 0.5753, 0.6426, 0.6259, 0.6894, 0.6612, 0.5476, 0.6838, 0.5821,
        0.5496, 0.5495, 0.5563, 0.5357, 0.5514, 0.5564, 0.5581],
       device='cuda:0') torch.Size([16])
percent tensor([0.9911, 0.9870, 0.9919, 0.9936, 0.9908, 0.9927, 0.9882, 0.9947, 0.9961,
        0.9928, 0.9960, 0.9923, 0.9945, 0.9839, 0.9907, 0.9918],
       device='cuda:0') torch.Size([16])
Epoch: 52 | Batch_idx: 0 |  Loss: (0.3159) |  Loss2: (0.0000) | Acc: (92.00%) (118/128)
Epoch: 52 | Batch_idx: 10 |  Loss: (0.3842) |  Loss2: (0.0000) | Acc: (86.00%) (1217/1408)
Epoch: 52 | Batch_idx: 20 |  Loss: (0.3970) |  Loss2: (0.0000) | Acc: (86.00%) (2325/2688)
Epoch: 52 | Batch_idx: 30 |  Loss: (0.3859) |  Loss2: (0.0000) | Acc: (86.00%) (3451/3968)
Epoch: 52 | Batch_idx: 40 |  Loss: (0.3841) |  Loss2: (0.0000) | Acc: (86.00%) (4560/5248)
Epoch: 52 | Batch_idx: 50 |  Loss: (0.3917) |  Loss2: (0.0000) | Acc: (86.00%) (5637/6528)
Epoch: 52 | Batch_idx: 60 |  Loss: (0.3897) |  Loss2: (0.0000) | Acc: (86.00%) (6743/7808)
Epoch: 52 | Batch_idx: 70 |  Loss: (0.3908) |  Loss2: (0.0000) | Acc: (86.00%) (7848/9088)
Epoch: 52 | Batch_idx: 80 |  Loss: (0.3958) |  Loss2: (0.0000) | Acc: (86.00%) (8953/10368)
Epoch: 52 | Batch_idx: 90 |  Loss: (0.3926) |  Loss2: (0.0000) | Acc: (86.00%) (10065/11648)
Epoch: 52 | Batch_idx: 100 |  Loss: (0.3971) |  Loss2: (0.0000) | Acc: (86.00%) (11154/12928)
Epoch: 52 | Batch_idx: 110 |  Loss: (0.3961) |  Loss2: (0.0000) | Acc: (86.00%) (12262/14208)
Epoch: 52 | Batch_idx: 120 |  Loss: (0.3953) |  Loss2: (0.0000) | Acc: (86.00%) (13376/15488)
Epoch: 52 | Batch_idx: 130 |  Loss: (0.3958) |  Loss2: (0.0000) | Acc: (86.00%) (14465/16768)
Epoch: 52 | Batch_idx: 140 |  Loss: (0.3958) |  Loss2: (0.0000) | Acc: (86.00%) (15566/18048)
Epoch: 52 | Batch_idx: 150 |  Loss: (0.3960) |  Loss2: (0.0000) | Acc: (86.00%) (16672/19328)
Epoch: 52 | Batch_idx: 160 |  Loss: (0.3990) |  Loss2: (0.0000) | Acc: (86.00%) (17757/20608)
Epoch: 52 | Batch_idx: 170 |  Loss: (0.3997) |  Loss2: (0.0000) | Acc: (86.00%) (18848/21888)
Epoch: 52 | Batch_idx: 180 |  Loss: (0.3985) |  Loss2: (0.0000) | Acc: (86.00%) (19959/23168)
Epoch: 52 | Batch_idx: 190 |  Loss: (0.3961) |  Loss2: (0.0000) | Acc: (86.00%) (21085/24448)
Epoch: 52 | Batch_idx: 200 |  Loss: (0.3933) |  Loss2: (0.0000) | Acc: (86.00%) (22224/25728)
Epoch: 52 | Batch_idx: 210 |  Loss: (0.3937) |  Loss2: (0.0000) | Acc: (86.00%) (23329/27008)
Epoch: 52 | Batch_idx: 220 |  Loss: (0.3944) |  Loss2: (0.0000) | Acc: (86.00%) (24418/28288)
Epoch: 52 | Batch_idx: 230 |  Loss: (0.3948) |  Loss2: (0.0000) | Acc: (86.00%) (25525/29568)
Epoch: 52 | Batch_idx: 240 |  Loss: (0.3947) |  Loss2: (0.0000) | Acc: (86.00%) (26630/30848)
Epoch: 52 | Batch_idx: 250 |  Loss: (0.3936) |  Loss2: (0.0000) | Acc: (86.00%) (27740/32128)
Epoch: 52 | Batch_idx: 260 |  Loss: (0.3939) |  Loss2: (0.0000) | Acc: (86.00%) (28837/33408)
Epoch: 52 | Batch_idx: 270 |  Loss: (0.3933) |  Loss2: (0.0000) | Acc: (86.00%) (29934/34688)
Epoch: 52 | Batch_idx: 280 |  Loss: (0.3929) |  Loss2: (0.0000) | Acc: (86.00%) (31030/35968)
Epoch: 52 | Batch_idx: 290 |  Loss: (0.3916) |  Loss2: (0.0000) | Acc: (86.00%) (32148/37248)
Epoch: 52 | Batch_idx: 300 |  Loss: (0.3916) |  Loss2: (0.0000) | Acc: (86.00%) (33253/38528)
Epoch: 52 | Batch_idx: 310 |  Loss: (0.3909) |  Loss2: (0.0000) | Acc: (86.00%) (34361/39808)
Epoch: 52 | Batch_idx: 320 |  Loss: (0.3921) |  Loss2: (0.0000) | Acc: (86.00%) (35457/41088)
Epoch: 52 | Batch_idx: 330 |  Loss: (0.3934) |  Loss2: (0.0000) | Acc: (86.00%) (36538/42368)
Epoch: 52 | Batch_idx: 340 |  Loss: (0.3924) |  Loss2: (0.0000) | Acc: (86.00%) (37663/43648)
Epoch: 52 | Batch_idx: 350 |  Loss: (0.3920) |  Loss2: (0.0000) | Acc: (86.00%) (38769/44928)
Epoch: 52 | Batch_idx: 360 |  Loss: (0.3918) |  Loss2: (0.0000) | Acc: (86.00%) (39885/46208)
Epoch: 52 | Batch_idx: 370 |  Loss: (0.3918) |  Loss2: (0.0000) | Acc: (86.00%) (40994/47488)
Epoch: 52 | Batch_idx: 380 |  Loss: (0.3911) |  Loss2: (0.0000) | Acc: (86.00%) (42126/48768)
Epoch: 52 | Batch_idx: 390 |  Loss: (0.3912) |  Loss2: (0.0000) | Acc: (86.00%) (43176/50000)
# TEST : Loss: (0.4754) | Acc: (84.00%) (8412/10000)
percent tensor([0.4925, 0.4826, 0.4869, 0.4847, 0.4870, 0.4988, 0.4843, 0.4846, 0.4886,
        0.4842, 0.4897, 0.4838, 0.4856, 0.4864, 0.4873, 0.4900],
       device='cuda:0') torch.Size([16])
percent tensor([0.5132, 0.5065, 0.5198, 0.5197, 0.5192, 0.5142, 0.5112, 0.5217, 0.5172,
        0.5091, 0.5121, 0.5115, 0.5053, 0.5159, 0.5107, 0.5132],
       device='cuda:0') torch.Size([16])
percent tensor([0.5229, 0.5154, 0.5230, 0.5406, 0.5256, 0.5266, 0.5215, 0.5331, 0.5196,
        0.5192, 0.5172, 0.5157, 0.5054, 0.5379, 0.5190, 0.5276],
       device='cuda:0') torch.Size([16])
percent tensor([0.5661, 0.5793, 0.5675, 0.5586, 0.5638, 0.5592, 0.5788, 0.5616, 0.5793,
        0.5841, 0.5890, 0.5747, 0.5752, 0.5932, 0.5643, 0.5739],
       device='cuda:0') torch.Size([16])
percent tensor([0.5303, 0.5311, 0.4586, 0.4724, 0.4350, 0.5505, 0.5173, 0.3962, 0.5452,
        0.5414, 0.5812, 0.4896, 0.5368, 0.5690, 0.4875, 0.5427],
       device='cuda:0') torch.Size([16])
percent tensor([0.5381, 0.5338, 0.5384, 0.5404, 0.5620, 0.5513, 0.5395, 0.5627, 0.5374,
        0.5339, 0.5192, 0.5143, 0.5256, 0.5302, 0.5335, 0.5531],
       device='cuda:0') torch.Size([16])
percent tensor([0.5312, 0.5723, 0.6354, 0.6177, 0.6839, 0.6631, 0.5431, 0.6742, 0.5796,
        0.5476, 0.5503, 0.5472, 0.5372, 0.5482, 0.5471, 0.5532],
       device='cuda:0') torch.Size([16])
percent tensor([0.9925, 0.9888, 0.9934, 0.9946, 0.9925, 0.9932, 0.9900, 0.9957, 0.9968,
        0.9939, 0.9967, 0.9936, 0.9953, 0.9862, 0.9921, 0.9930],
       device='cuda:0') torch.Size([16])
Epoch: 53 | Batch_idx: 0 |  Loss: (0.4055) |  Loss2: (0.0000) | Acc: (85.00%) (110/128)
Epoch: 53 | Batch_idx: 10 |  Loss: (0.4129) |  Loss2: (0.0000) | Acc: (86.00%) (1211/1408)
Epoch: 53 | Batch_idx: 20 |  Loss: (0.4220) |  Loss2: (0.0000) | Acc: (85.00%) (2304/2688)
Epoch: 53 | Batch_idx: 30 |  Loss: (0.4061) |  Loss2: (0.0000) | Acc: (86.00%) (3416/3968)
Epoch: 53 | Batch_idx: 40 |  Loss: (0.4078) |  Loss2: (0.0000) | Acc: (86.00%) (4517/5248)
Epoch: 53 | Batch_idx: 50 |  Loss: (0.3990) |  Loss2: (0.0000) | Acc: (86.00%) (5633/6528)
Epoch: 53 | Batch_idx: 60 |  Loss: (0.3952) |  Loss2: (0.0000) | Acc: (86.00%) (6747/7808)
Epoch: 53 | Batch_idx: 70 |  Loss: (0.3914) |  Loss2: (0.0000) | Acc: (86.00%) (7863/9088)
Epoch: 53 | Batch_idx: 80 |  Loss: (0.3972) |  Loss2: (0.0000) | Acc: (86.00%) (8944/10368)
Epoch: 53 | Batch_idx: 90 |  Loss: (0.3946) |  Loss2: (0.0000) | Acc: (86.00%) (10074/11648)
Epoch: 53 | Batch_idx: 100 |  Loss: (0.3939) |  Loss2: (0.0000) | Acc: (86.00%) (11167/12928)
Epoch: 53 | Batch_idx: 110 |  Loss: (0.3936) |  Loss2: (0.0000) | Acc: (86.00%) (12278/14208)
Epoch: 53 | Batch_idx: 120 |  Loss: (0.3926) |  Loss2: (0.0000) | Acc: (86.00%) (13396/15488)
Epoch: 53 | Batch_idx: 130 |  Loss: (0.3901) |  Loss2: (0.0000) | Acc: (86.00%) (14510/16768)
Epoch: 53 | Batch_idx: 140 |  Loss: (0.3897) |  Loss2: (0.0000) | Acc: (86.00%) (15614/18048)
Epoch: 53 | Batch_idx: 150 |  Loss: (0.3895) |  Loss2: (0.0000) | Acc: (86.00%) (16719/19328)
Epoch: 53 | Batch_idx: 160 |  Loss: (0.3898) |  Loss2: (0.0000) | Acc: (86.00%) (17820/20608)
Epoch: 53 | Batch_idx: 170 |  Loss: (0.3894) |  Loss2: (0.0000) | Acc: (86.00%) (18936/21888)
Epoch: 53 | Batch_idx: 180 |  Loss: (0.3901) |  Loss2: (0.0000) | Acc: (86.00%) (20050/23168)
Epoch: 53 | Batch_idx: 190 |  Loss: (0.3890) |  Loss2: (0.0000) | Acc: (86.00%) (21163/24448)
Epoch: 53 | Batch_idx: 200 |  Loss: (0.3896) |  Loss2: (0.0000) | Acc: (86.00%) (22275/25728)
Epoch: 53 | Batch_idx: 210 |  Loss: (0.3905) |  Loss2: (0.0000) | Acc: (86.00%) (23373/27008)
Epoch: 53 | Batch_idx: 220 |  Loss: (0.3879) |  Loss2: (0.0000) | Acc: (86.00%) (24517/28288)
Epoch: 53 | Batch_idx: 230 |  Loss: (0.3880) |  Loss2: (0.0000) | Acc: (86.00%) (25622/29568)
Epoch: 53 | Batch_idx: 240 |  Loss: (0.3868) |  Loss2: (0.0000) | Acc: (86.00%) (26751/30848)
Epoch: 53 | Batch_idx: 250 |  Loss: (0.3865) |  Loss2: (0.0000) | Acc: (86.00%) (27861/32128)
Epoch: 53 | Batch_idx: 260 |  Loss: (0.3886) |  Loss2: (0.0000) | Acc: (86.00%) (28956/33408)
Epoch: 53 | Batch_idx: 270 |  Loss: (0.3895) |  Loss2: (0.0000) | Acc: (86.00%) (30047/34688)
Epoch: 53 | Batch_idx: 280 |  Loss: (0.3899) |  Loss2: (0.0000) | Acc: (86.00%) (31143/35968)
Epoch: 53 | Batch_idx: 290 |  Loss: (0.3894) |  Loss2: (0.0000) | Acc: (86.00%) (32253/37248)
Epoch: 53 | Batch_idx: 300 |  Loss: (0.3906) |  Loss2: (0.0000) | Acc: (86.00%) (33343/38528)
Epoch: 53 | Batch_idx: 310 |  Loss: (0.3912) |  Loss2: (0.0000) | Acc: (86.00%) (34446/39808)
Epoch: 53 | Batch_idx: 320 |  Loss: (0.3906) |  Loss2: (0.0000) | Acc: (86.00%) (35557/41088)
Epoch: 53 | Batch_idx: 330 |  Loss: (0.3901) |  Loss2: (0.0000) | Acc: (86.00%) (36668/42368)
Epoch: 53 | Batch_idx: 340 |  Loss: (0.3911) |  Loss2: (0.0000) | Acc: (86.00%) (37758/43648)
Epoch: 53 | Batch_idx: 350 |  Loss: (0.3919) |  Loss2: (0.0000) | Acc: (86.00%) (38849/44928)
Epoch: 53 | Batch_idx: 360 |  Loss: (0.3920) |  Loss2: (0.0000) | Acc: (86.00%) (39957/46208)
Epoch: 53 | Batch_idx: 370 |  Loss: (0.3915) |  Loss2: (0.0000) | Acc: (86.00%) (41053/47488)
Epoch: 53 | Batch_idx: 380 |  Loss: (0.3923) |  Loss2: (0.0000) | Acc: (86.00%) (42149/48768)
Epoch: 53 | Batch_idx: 390 |  Loss: (0.3928) |  Loss2: (0.0000) | Acc: (86.00%) (43212/50000)
# TEST : Loss: (0.4743) | Acc: (84.00%) (8440/10000)
percent tensor([0.4945, 0.4847, 0.4895, 0.4867, 0.4896, 0.5008, 0.4867, 0.4870, 0.4907,
        0.4866, 0.4918, 0.4864, 0.4875, 0.4883, 0.4894, 0.4919],
       device='cuda:0') torch.Size([16])
percent tensor([0.5135, 0.5067, 0.5201, 0.5199, 0.5195, 0.5146, 0.5115, 0.5220, 0.5175,
        0.5094, 0.5123, 0.5118, 0.5055, 0.5163, 0.5109, 0.5135],
       device='cuda:0') torch.Size([16])
percent tensor([0.5207, 0.5131, 0.5212, 0.5389, 0.5240, 0.5241, 0.5196, 0.5315, 0.5176,
        0.5170, 0.5151, 0.5139, 0.5034, 0.5353, 0.5171, 0.5253],
       device='cuda:0') torch.Size([16])
percent tensor([0.5679, 0.5805, 0.5691, 0.5600, 0.5651, 0.5607, 0.5801, 0.5627, 0.5812,
        0.5855, 0.5906, 0.5763, 0.5769, 0.5951, 0.5655, 0.5752],
       device='cuda:0') torch.Size([16])
percent tensor([0.5360, 0.5326, 0.4677, 0.4866, 0.4464, 0.5569, 0.5209, 0.4059, 0.5506,
        0.5421, 0.5846, 0.4981, 0.5394, 0.5730, 0.4969, 0.5474],
       device='cuda:0') torch.Size([16])
percent tensor([0.5410, 0.5367, 0.5414, 0.5437, 0.5662, 0.5541, 0.5427, 0.5668, 0.5401,
        0.5364, 0.5211, 0.5159, 0.5280, 0.5326, 0.5359, 0.5564],
       device='cuda:0') torch.Size([16])
percent tensor([0.5327, 0.5723, 0.6364, 0.6204, 0.6865, 0.6694, 0.5425, 0.6730, 0.5831,
        0.5465, 0.5544, 0.5450, 0.5416, 0.5520, 0.5437, 0.5535],
       device='cuda:0') torch.Size([16])
percent tensor([0.9936, 0.9903, 0.9944, 0.9952, 0.9936, 0.9943, 0.9912, 0.9964, 0.9974,
        0.9949, 0.9973, 0.9945, 0.9962, 0.9881, 0.9930, 0.9940],
       device='cuda:0') torch.Size([16])
True Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=128, out_features=16, bias=False)
False Linear(in_features=16, out_features=2, bias=False)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=128, out_features=16, bias=False)
False Linear(in_features=16, out_features=2, bias=False)
True Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=256, out_features=32, bias=False)
False Linear(in_features=32, out_features=2, bias=False)
True Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=256, out_features=32, bias=False)
False Linear(in_features=32, out_features=2, bias=False)
True Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=512, out_features=64, bias=False)
False Linear(in_features=64, out_features=2, bias=False)
True Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=512, out_features=64, bias=False)
False Linear(in_features=64, out_features=2, bias=False)
True Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1024, out_features=128, bias=False)
False Linear(in_features=128, out_features=2, bias=False)
True Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1024, out_features=128, bias=False)
False Linear(in_features=128, out_features=2, bias=False)
True Linear(in_features=512, out_features=10, bias=True)
Epoch: 54 | Batch_idx: 0 |  Loss: (0.4625) |  Loss2: (0.0000) | Acc: (84.00%) (108/128)
Epoch: 54 | Batch_idx: 10 |  Loss: (0.3959) |  Loss2: (0.0000) | Acc: (86.00%) (1216/1408)
Epoch: 54 | Batch_idx: 20 |  Loss: (0.4058) |  Loss2: (0.0000) | Acc: (85.00%) (2300/2688)
Epoch: 54 | Batch_idx: 30 |  Loss: (0.3967) |  Loss2: (0.0000) | Acc: (86.00%) (3419/3968)
Epoch: 54 | Batch_idx: 40 |  Loss: (0.4154) |  Loss2: (0.0000) | Acc: (85.00%) (4490/5248)
Epoch: 54 | Batch_idx: 50 |  Loss: (0.4214) |  Loss2: (0.0000) | Acc: (85.00%) (5574/6528)
Epoch: 54 | Batch_idx: 60 |  Loss: (0.4229) |  Loss2: (0.0000) | Acc: (85.00%) (6658/7808)
Epoch: 54 | Batch_idx: 70 |  Loss: (0.4208) |  Loss2: (0.0000) | Acc: (85.00%) (7755/9088)
Epoch: 54 | Batch_idx: 80 |  Loss: (0.4208) |  Loss2: (0.0000) | Acc: (85.00%) (8840/10368)
Epoch: 54 | Batch_idx: 90 |  Loss: (0.4219) |  Loss2: (0.0000) | Acc: (85.00%) (9934/11648)
Epoch: 54 | Batch_idx: 100 |  Loss: (0.4247) |  Loss2: (0.0000) | Acc: (85.00%) (11012/12928)
Epoch: 54 | Batch_idx: 110 |  Loss: (0.4243) |  Loss2: (0.0000) | Acc: (85.00%) (12107/14208)
Epoch: 54 | Batch_idx: 120 |  Loss: (0.4249) |  Loss2: (0.0000) | Acc: (85.00%) (13190/15488)
Epoch: 54 | Batch_idx: 130 |  Loss: (0.4233) |  Loss2: (0.0000) | Acc: (85.00%) (14284/16768)
Epoch: 54 | Batch_idx: 140 |  Loss: (0.4208) |  Loss2: (0.0000) | Acc: (85.00%) (15388/18048)
Epoch: 54 | Batch_idx: 150 |  Loss: (0.4211) |  Loss2: (0.0000) | Acc: (85.00%) (16482/19328)
Epoch: 54 | Batch_idx: 160 |  Loss: (0.4213) |  Loss2: (0.0000) | Acc: (85.00%) (17570/20608)
Epoch: 54 | Batch_idx: 170 |  Loss: (0.4217) |  Loss2: (0.0000) | Acc: (85.00%) (18665/21888)
Epoch: 54 | Batch_idx: 180 |  Loss: (0.4226) |  Loss2: (0.0000) | Acc: (85.00%) (19750/23168)
Epoch: 54 | Batch_idx: 190 |  Loss: (0.4225) |  Loss2: (0.0000) | Acc: (85.00%) (20844/24448)
Epoch: 54 | Batch_idx: 200 |  Loss: (0.4217) |  Loss2: (0.0000) | Acc: (85.00%) (21943/25728)
Epoch: 54 | Batch_idx: 210 |  Loss: (0.4214) |  Loss2: (0.0000) | Acc: (85.00%) (23027/27008)
Epoch: 54 | Batch_idx: 220 |  Loss: (0.4224) |  Loss2: (0.0000) | Acc: (85.00%) (24100/28288)
Epoch: 54 | Batch_idx: 230 |  Loss: (0.4234) |  Loss2: (0.0000) | Acc: (85.00%) (25186/29568)
Epoch: 54 | Batch_idx: 240 |  Loss: (0.4228) |  Loss2: (0.0000) | Acc: (85.00%) (26285/30848)
Epoch: 54 | Batch_idx: 250 |  Loss: (0.4220) |  Loss2: (0.0000) | Acc: (85.00%) (27384/32128)
Epoch: 54 | Batch_idx: 260 |  Loss: (0.4202) |  Loss2: (0.0000) | Acc: (85.00%) (28499/33408)
Epoch: 54 | Batch_idx: 270 |  Loss: (0.4191) |  Loss2: (0.0000) | Acc: (85.00%) (29613/34688)
Epoch: 54 | Batch_idx: 280 |  Loss: (0.4197) |  Loss2: (0.0000) | Acc: (85.00%) (30698/35968)
Epoch: 54 | Batch_idx: 290 |  Loss: (0.4199) |  Loss2: (0.0000) | Acc: (85.00%) (31778/37248)
Epoch: 54 | Batch_idx: 300 |  Loss: (0.4204) |  Loss2: (0.0000) | Acc: (85.00%) (32858/38528)
Epoch: 54 | Batch_idx: 310 |  Loss: (0.4202) |  Loss2: (0.0000) | Acc: (85.00%) (33950/39808)
Epoch: 54 | Batch_idx: 320 |  Loss: (0.4194) |  Loss2: (0.0000) | Acc: (85.00%) (35045/41088)
Epoch: 54 | Batch_idx: 330 |  Loss: (0.4199) |  Loss2: (0.0000) | Acc: (85.00%) (36119/42368)
Epoch: 54 | Batch_idx: 340 |  Loss: (0.4204) |  Loss2: (0.0000) | Acc: (85.00%) (37221/43648)
Epoch: 54 | Batch_idx: 350 |  Loss: (0.4192) |  Loss2: (0.0000) | Acc: (85.00%) (38325/44928)
Epoch: 54 | Batch_idx: 360 |  Loss: (0.4187) |  Loss2: (0.0000) | Acc: (85.00%) (39432/46208)
Epoch: 54 | Batch_idx: 370 |  Loss: (0.4194) |  Loss2: (0.0000) | Acc: (85.00%) (40522/47488)
Epoch: 54 | Batch_idx: 380 |  Loss: (0.4186) |  Loss2: (0.0000) | Acc: (85.00%) (41638/48768)
Epoch: 54 | Batch_idx: 390 |  Loss: (0.4177) |  Loss2: (0.0000) | Acc: (85.00%) (42710/50000)
# TEST : Loss: (0.5784) | Acc: (80.00%) (8095/10000)
percent tensor([0.4939, 0.4848, 0.4899, 0.4865, 0.4896, 0.5003, 0.4872, 0.4870, 0.4912,
        0.4867, 0.4922, 0.4867, 0.4872, 0.4889, 0.4895, 0.4913],
       device='cuda:0') torch.Size([16])
percent tensor([0.5134, 0.5061, 0.5172, 0.5208, 0.5174, 0.5146, 0.5101, 0.5216, 0.5175,
        0.5083, 0.5123, 0.5090, 0.5055, 0.5161, 0.5106, 0.5139],
       device='cuda:0') torch.Size([16])
percent tensor([0.5194, 0.5106, 0.5148, 0.5371, 0.5210, 0.5267, 0.5186, 0.5262, 0.5155,
        0.5144, 0.5124, 0.5115, 0.5016, 0.5351, 0.5165, 0.5252],
       device='cuda:0') torch.Size([16])
percent tensor([0.5686, 0.5836, 0.5679, 0.5616, 0.5614, 0.5602, 0.5805, 0.5648, 0.5845,
        0.5875, 0.5928, 0.5776, 0.5798, 0.5983, 0.5669, 0.5762],
       device='cuda:0') torch.Size([16])
percent tensor([0.5390, 0.5418, 0.4846, 0.5084, 0.4717, 0.5569, 0.5239, 0.4287, 0.5604,
        0.5426, 0.5846, 0.5060, 0.5479, 0.5705, 0.5075, 0.5528],
       device='cuda:0') torch.Size([16])
percent tensor([0.5413, 0.5402, 0.5384, 0.5422, 0.5580, 0.5537, 0.5428, 0.5638, 0.5421,
        0.5393, 0.5280, 0.5183, 0.5331, 0.5397, 0.5324, 0.5542],
       device='cuda:0') torch.Size([16])
percent tensor([0.5346, 0.6004, 0.6365, 0.6155, 0.6788, 0.6727, 0.5500, 0.6708, 0.6073,
        0.5741, 0.5727, 0.5604, 0.5752, 0.5799, 0.5435, 0.5548],
       device='cuda:0') torch.Size([16])
percent tensor([0.9919, 0.9932, 0.9912, 0.9922, 0.9931, 0.9945, 0.9887, 0.9972, 0.9963,
        0.9965, 0.9965, 0.9962, 0.9976, 0.9884, 0.9941, 0.9919],
       device='cuda:0') torch.Size([16])
Epoch: 55 | Batch_idx: 0 |  Loss: (0.3771) |  Loss2: (0.0000) | Acc: (89.00%) (114/128)
Epoch: 55 | Batch_idx: 10 |  Loss: (0.3545) |  Loss2: (0.0000) | Acc: (87.00%) (1238/1408)
Epoch: 55 | Batch_idx: 20 |  Loss: (0.3834) |  Loss2: (0.0000) | Acc: (86.00%) (2333/2688)
Epoch: 55 | Batch_idx: 30 |  Loss: (0.3903) |  Loss2: (0.0000) | Acc: (86.00%) (3427/3968)
Epoch: 55 | Batch_idx: 40 |  Loss: (0.3905) |  Loss2: (0.0000) | Acc: (86.00%) (4523/5248)
Epoch: 55 | Batch_idx: 50 |  Loss: (0.3952) |  Loss2: (0.0000) | Acc: (85.00%) (5608/6528)
Epoch: 55 | Batch_idx: 60 |  Loss: (0.3962) |  Loss2: (0.0000) | Acc: (85.00%) (6703/7808)
Epoch: 55 | Batch_idx: 70 |  Loss: (0.4024) |  Loss2: (0.0000) | Acc: (85.00%) (7780/9088)
Epoch: 55 | Batch_idx: 80 |  Loss: (0.4024) |  Loss2: (0.0000) | Acc: (85.00%) (8873/10368)
Epoch: 55 | Batch_idx: 90 |  Loss: (0.4014) |  Loss2: (0.0000) | Acc: (85.00%) (9968/11648)
Epoch: 55 | Batch_idx: 100 |  Loss: (0.4069) |  Loss2: (0.0000) | Acc: (85.00%) (11042/12928)
Epoch: 55 | Batch_idx: 110 |  Loss: (0.4054) |  Loss2: (0.0000) | Acc: (85.00%) (12153/14208)
Epoch: 55 | Batch_idx: 120 |  Loss: (0.4050) |  Loss2: (0.0000) | Acc: (85.00%) (13257/15488)
Epoch: 55 | Batch_idx: 130 |  Loss: (0.4058) |  Loss2: (0.0000) | Acc: (85.00%) (14353/16768)
Epoch: 55 | Batch_idx: 140 |  Loss: (0.4061) |  Loss2: (0.0000) | Acc: (85.00%) (15465/18048)
Epoch: 55 | Batch_idx: 150 |  Loss: (0.4072) |  Loss2: (0.0000) | Acc: (85.00%) (16567/19328)
Epoch: 55 | Batch_idx: 160 |  Loss: (0.4083) |  Loss2: (0.0000) | Acc: (85.00%) (17662/20608)
Epoch: 55 | Batch_idx: 170 |  Loss: (0.4064) |  Loss2: (0.0000) | Acc: (85.00%) (18775/21888)
Epoch: 55 | Batch_idx: 180 |  Loss: (0.4042) |  Loss2: (0.0000) | Acc: (85.00%) (19884/23168)
Epoch: 55 | Batch_idx: 190 |  Loss: (0.4051) |  Loss2: (0.0000) | Acc: (85.00%) (20982/24448)
Epoch: 55 | Batch_idx: 200 |  Loss: (0.4048) |  Loss2: (0.0000) | Acc: (85.00%) (22082/25728)
Epoch: 55 | Batch_idx: 210 |  Loss: (0.4041) |  Loss2: (0.0000) | Acc: (85.00%) (23183/27008)
Epoch: 55 | Batch_idx: 220 |  Loss: (0.4040) |  Loss2: (0.0000) | Acc: (85.00%) (24281/28288)
Epoch: 55 | Batch_idx: 230 |  Loss: (0.4051) |  Loss2: (0.0000) | Acc: (85.00%) (25371/29568)
Epoch: 55 | Batch_idx: 240 |  Loss: (0.4063) |  Loss2: (0.0000) | Acc: (85.00%) (26453/30848)
Epoch: 55 | Batch_idx: 250 |  Loss: (0.4066) |  Loss2: (0.0000) | Acc: (85.00%) (27558/32128)
Epoch: 55 | Batch_idx: 260 |  Loss: (0.4067) |  Loss2: (0.0000) | Acc: (85.00%) (28648/33408)
Epoch: 55 | Batch_idx: 270 |  Loss: (0.4065) |  Loss2: (0.0000) | Acc: (85.00%) (29750/34688)
Epoch: 55 | Batch_idx: 280 |  Loss: (0.4059) |  Loss2: (0.0000) | Acc: (85.00%) (30859/35968)
Epoch: 55 | Batch_idx: 290 |  Loss: (0.4064) |  Loss2: (0.0000) | Acc: (85.00%) (31951/37248)
Epoch: 55 | Batch_idx: 300 |  Loss: (0.4057) |  Loss2: (0.0000) | Acc: (85.00%) (33060/38528)
Epoch: 55 | Batch_idx: 310 |  Loss: (0.4052) |  Loss2: (0.0000) | Acc: (85.00%) (34162/39808)
Epoch: 55 | Batch_idx: 320 |  Loss: (0.4053) |  Loss2: (0.0000) | Acc: (85.00%) (35255/41088)
Epoch: 55 | Batch_idx: 330 |  Loss: (0.4039) |  Loss2: (0.0000) | Acc: (85.00%) (36370/42368)
Epoch: 55 | Batch_idx: 340 |  Loss: (0.4048) |  Loss2: (0.0000) | Acc: (85.00%) (37460/43648)
Epoch: 55 | Batch_idx: 350 |  Loss: (0.4041) |  Loss2: (0.0000) | Acc: (85.00%) (38567/44928)
Epoch: 55 | Batch_idx: 360 |  Loss: (0.4034) |  Loss2: (0.0000) | Acc: (85.00%) (39680/46208)
Epoch: 55 | Batch_idx: 370 |  Loss: (0.4031) |  Loss2: (0.0000) | Acc: (85.00%) (40785/47488)
Epoch: 55 | Batch_idx: 380 |  Loss: (0.4038) |  Loss2: (0.0000) | Acc: (85.00%) (41869/48768)
Epoch: 55 | Batch_idx: 390 |  Loss: (0.4035) |  Loss2: (0.0000) | Acc: (85.00%) (42950/50000)
=> saving checkpoint 'drive/app/torch/save_Schedule/checkpoint_055.pth.tar'
# TEST : Loss: (0.5459) | Acc: (82.00%) (8216/10000)
percent tensor([0.4945, 0.4840, 0.4913, 0.4868, 0.4909, 0.5004, 0.4869, 0.4869, 0.4919,
        0.4865, 0.4925, 0.4877, 0.4873, 0.4880, 0.4892, 0.4913],
       device='cuda:0') torch.Size([16])
percent tensor([0.5153, 0.5050, 0.5220, 0.5224, 0.5212, 0.5168, 0.5113, 0.5225, 0.5184,
        0.5090, 0.5129, 0.5124, 0.5059, 0.5149, 0.5112, 0.5141],
       device='cuda:0') torch.Size([16])
percent tensor([0.5215, 0.5104, 0.5279, 0.5399, 0.5314, 0.5303, 0.5207, 0.5310, 0.5170,
        0.5152, 0.5124, 0.5167, 0.5005, 0.5347, 0.5170, 0.5249],
       device='cuda:0') torch.Size([16])
percent tensor([0.5664, 0.5854, 0.5635, 0.5603, 0.5611, 0.5598, 0.5811, 0.5645, 0.5808,
        0.5872, 0.5895, 0.5747, 0.5772, 0.5976, 0.5645, 0.5767],
       device='cuda:0') torch.Size([16])
percent tensor([0.5264, 0.5309, 0.4378, 0.4855, 0.4271, 0.5481, 0.5136, 0.4061, 0.5466,
        0.5316, 0.5759, 0.4892, 0.5334, 0.5651, 0.4858, 0.5401],
       device='cuda:0') torch.Size([16])
percent tensor([0.5433, 0.5324, 0.5445, 0.5440, 0.5660, 0.5590, 0.5456, 0.5619, 0.5389,
        0.5368, 0.5256, 0.5232, 0.5251, 0.5357, 0.5365, 0.5524],
       device='cuda:0') torch.Size([16])
percent tensor([0.5259, 0.5589, 0.6387, 0.6144, 0.6911, 0.6631, 0.5399, 0.6535, 0.5867,
        0.5644, 0.5632, 0.5608, 0.5391, 0.5690, 0.5471, 0.5444],
       device='cuda:0') torch.Size([16])
percent tensor([0.9929, 0.9928, 0.9934, 0.9961, 0.9950, 0.9923, 0.9909, 0.9974, 0.9956,
        0.9946, 0.9955, 0.9947, 0.9957, 0.9905, 0.9937, 0.9947],
       device='cuda:0') torch.Size([16])
Epoch: 56 | Batch_idx: 0 |  Loss: (0.4150) |  Loss2: (0.0000) | Acc: (85.00%) (109/128)
Epoch: 56 | Batch_idx: 10 |  Loss: (0.3889) |  Loss2: (0.0000) | Acc: (85.00%) (1210/1408)
Epoch: 56 | Batch_idx: 20 |  Loss: (0.3653) |  Loss2: (0.0000) | Acc: (87.00%) (2347/2688)
Epoch: 56 | Batch_idx: 30 |  Loss: (0.3786) |  Loss2: (0.0000) | Acc: (86.00%) (3445/3968)
Epoch: 56 | Batch_idx: 40 |  Loss: (0.3851) |  Loss2: (0.0000) | Acc: (86.00%) (4541/5248)
Epoch: 56 | Batch_idx: 50 |  Loss: (0.3806) |  Loss2: (0.0000) | Acc: (86.00%) (5666/6528)
Epoch: 56 | Batch_idx: 60 |  Loss: (0.3833) |  Loss2: (0.0000) | Acc: (86.00%) (6762/7808)
Epoch: 56 | Batch_idx: 70 |  Loss: (0.3810) |  Loss2: (0.0000) | Acc: (86.00%) (7872/9088)
Epoch: 56 | Batch_idx: 80 |  Loss: (0.3799) |  Loss2: (0.0000) | Acc: (86.00%) (8991/10368)
Epoch: 56 | Batch_idx: 90 |  Loss: (0.3830) |  Loss2: (0.0000) | Acc: (86.00%) (10073/11648)
Epoch: 56 | Batch_idx: 100 |  Loss: (0.3822) |  Loss2: (0.0000) | Acc: (86.00%) (11177/12928)
Epoch: 56 | Batch_idx: 110 |  Loss: (0.3862) |  Loss2: (0.0000) | Acc: (86.00%) (12270/14208)
Epoch: 56 | Batch_idx: 120 |  Loss: (0.3856) |  Loss2: (0.0000) | Acc: (86.00%) (13390/15488)
Epoch: 56 | Batch_idx: 130 |  Loss: (0.3843) |  Loss2: (0.0000) | Acc: (86.00%) (14509/16768)
Epoch: 56 | Batch_idx: 140 |  Loss: (0.3827) |  Loss2: (0.0000) | Acc: (86.00%) (15621/18048)
Epoch: 56 | Batch_idx: 150 |  Loss: (0.3843) |  Loss2: (0.0000) | Acc: (86.00%) (16721/19328)
Epoch: 56 | Batch_idx: 160 |  Loss: (0.3864) |  Loss2: (0.0000) | Acc: (86.00%) (17823/20608)
Epoch: 56 | Batch_idx: 170 |  Loss: (0.3858) |  Loss2: (0.0000) | Acc: (86.00%) (18953/21888)
Epoch: 56 | Batch_idx: 180 |  Loss: (0.3872) |  Loss2: (0.0000) | Acc: (86.00%) (20051/23168)
Epoch: 56 | Batch_idx: 190 |  Loss: (0.3893) |  Loss2: (0.0000) | Acc: (86.00%) (21144/24448)
Epoch: 56 | Batch_idx: 200 |  Loss: (0.3882) |  Loss2: (0.0000) | Acc: (86.00%) (22275/25728)
Epoch: 56 | Batch_idx: 210 |  Loss: (0.3877) |  Loss2: (0.0000) | Acc: (86.00%) (23387/27008)
Epoch: 56 | Batch_idx: 220 |  Loss: (0.3879) |  Loss2: (0.0000) | Acc: (86.00%) (24486/28288)
Epoch: 56 | Batch_idx: 230 |  Loss: (0.3879) |  Loss2: (0.0000) | Acc: (86.00%) (25592/29568)
Epoch: 56 | Batch_idx: 240 |  Loss: (0.3877) |  Loss2: (0.0000) | Acc: (86.00%) (26703/30848)
Epoch: 56 | Batch_idx: 250 |  Loss: (0.3873) |  Loss2: (0.0000) | Acc: (86.00%) (27814/32128)
Epoch: 56 | Batch_idx: 260 |  Loss: (0.3881) |  Loss2: (0.0000) | Acc: (86.00%) (28916/33408)
Epoch: 56 | Batch_idx: 270 |  Loss: (0.3891) |  Loss2: (0.0000) | Acc: (86.00%) (30009/34688)
Epoch: 56 | Batch_idx: 280 |  Loss: (0.3882) |  Loss2: (0.0000) | Acc: (86.00%) (31126/35968)
Epoch: 56 | Batch_idx: 290 |  Loss: (0.3890) |  Loss2: (0.0000) | Acc: (86.00%) (32229/37248)
Epoch: 56 | Batch_idx: 300 |  Loss: (0.3883) |  Loss2: (0.0000) | Acc: (86.00%) (33348/38528)
Epoch: 56 | Batch_idx: 310 |  Loss: (0.3880) |  Loss2: (0.0000) | Acc: (86.00%) (34463/39808)
Epoch: 56 | Batch_idx: 320 |  Loss: (0.3875) |  Loss2: (0.0000) | Acc: (86.00%) (35574/41088)
Epoch: 56 | Batch_idx: 330 |  Loss: (0.3869) |  Loss2: (0.0000) | Acc: (86.00%) (36689/42368)
Epoch: 56 | Batch_idx: 340 |  Loss: (0.3873) |  Loss2: (0.0000) | Acc: (86.00%) (37785/43648)
Epoch: 56 | Batch_idx: 350 |  Loss: (0.3884) |  Loss2: (0.0000) | Acc: (86.00%) (38876/44928)
Epoch: 56 | Batch_idx: 360 |  Loss: (0.3885) |  Loss2: (0.0000) | Acc: (86.00%) (39967/46208)
Epoch: 56 | Batch_idx: 370 |  Loss: (0.3886) |  Loss2: (0.0000) | Acc: (86.00%) (41077/47488)
Epoch: 56 | Batch_idx: 380 |  Loss: (0.3886) |  Loss2: (0.0000) | Acc: (86.00%) (42189/48768)
Epoch: 56 | Batch_idx: 390 |  Loss: (0.3899) |  Loss2: (0.0000) | Acc: (86.00%) (43229/50000)
# TEST : Loss: (0.6089) | Acc: (80.00%) (8016/10000)
percent tensor([0.4941, 0.4855, 0.4887, 0.4869, 0.4884, 0.5008, 0.4864, 0.4864, 0.4917,
        0.4859, 0.4922, 0.4849, 0.4872, 0.4904, 0.4899, 0.4916],
       device='cuda:0') torch.Size([16])
percent tensor([0.5146, 0.5076, 0.5215, 0.5229, 0.5204, 0.5163, 0.5131, 0.5243, 0.5187,
        0.5105, 0.5133, 0.5128, 0.5062, 0.5206, 0.5121, 0.5155],
       device='cuda:0') torch.Size([16])
percent tensor([0.5198, 0.5106, 0.5266, 0.5404, 0.5308, 0.5308, 0.5219, 0.5312, 0.5169,
        0.5163, 0.5121, 0.5201, 0.5010, 0.5395, 0.5189, 0.5243],
       device='cuda:0') torch.Size([16])
percent tensor([0.5679, 0.5838, 0.5704, 0.5645, 0.5651, 0.5615, 0.5797, 0.5652, 0.5826,
        0.5874, 0.5889, 0.5770, 0.5793, 0.5960, 0.5650, 0.5761],
       device='cuda:0') torch.Size([16])
percent tensor([0.5376, 0.5439, 0.4597, 0.4864, 0.4422, 0.5502, 0.5209, 0.4131, 0.5528,
        0.5399, 0.5783, 0.4960, 0.5403, 0.5708, 0.4941, 0.5484],
       device='cuda:0') torch.Size([16])
percent tensor([0.5420, 0.5336, 0.5441, 0.5466, 0.5663, 0.5588, 0.5473, 0.5665, 0.5402,
        0.5372, 0.5248, 0.5210, 0.5293, 0.5351, 0.5371, 0.5528],
       device='cuda:0') torch.Size([16])
percent tensor([0.5458, 0.5751, 0.6450, 0.6153, 0.6902, 0.6777, 0.5676, 0.6602, 0.5931,
        0.5651, 0.5797, 0.5633, 0.5642, 0.5575, 0.5532, 0.5528],
       device='cuda:0') torch.Size([16])
percent tensor([0.9917, 0.9941, 0.9938, 0.9947, 0.9932, 0.9952, 0.9909, 0.9965, 0.9974,
        0.9962, 0.9980, 0.9939, 0.9979, 0.9934, 0.9951, 0.9947],
       device='cuda:0') torch.Size([16])
Epoch: 57 | Batch_idx: 0 |  Loss: (0.3481) |  Loss2: (0.0000) | Acc: (87.00%) (112/128)
Epoch: 57 | Batch_idx: 10 |  Loss: (0.3501) |  Loss2: (0.0000) | Acc: (87.00%) (1237/1408)
Epoch: 57 | Batch_idx: 20 |  Loss: (0.3559) |  Loss2: (0.0000) | Acc: (87.00%) (2358/2688)
Epoch: 57 | Batch_idx: 30 |  Loss: (0.3581) |  Loss2: (0.0000) | Acc: (87.00%) (3479/3968)
Epoch: 57 | Batch_idx: 40 |  Loss: (0.3643) |  Loss2: (0.0000) | Acc: (87.00%) (4593/5248)
Epoch: 57 | Batch_idx: 50 |  Loss: (0.3722) |  Loss2: (0.0000) | Acc: (87.00%) (5683/6528)
Epoch: 57 | Batch_idx: 60 |  Loss: (0.3744) |  Loss2: (0.0000) | Acc: (86.00%) (6780/7808)
Epoch: 57 | Batch_idx: 70 |  Loss: (0.3791) |  Loss2: (0.0000) | Acc: (86.00%) (7885/9088)
Epoch: 57 | Batch_idx: 80 |  Loss: (0.3763) |  Loss2: (0.0000) | Acc: (86.00%) (9014/10368)
Epoch: 57 | Batch_idx: 90 |  Loss: (0.3769) |  Loss2: (0.0000) | Acc: (86.00%) (10132/11648)
Epoch: 57 | Batch_idx: 100 |  Loss: (0.3787) |  Loss2: (0.0000) | Acc: (86.00%) (11232/12928)
Epoch: 57 | Batch_idx: 110 |  Loss: (0.3763) |  Loss2: (0.0000) | Acc: (87.00%) (12362/14208)
Epoch: 57 | Batch_idx: 120 |  Loss: (0.3755) |  Loss2: (0.0000) | Acc: (87.00%) (13477/15488)
Epoch: 57 | Batch_idx: 130 |  Loss: (0.3746) |  Loss2: (0.0000) | Acc: (87.00%) (14610/16768)
Epoch: 57 | Batch_idx: 140 |  Loss: (0.3722) |  Loss2: (0.0000) | Acc: (87.00%) (15743/18048)
Epoch: 57 | Batch_idx: 150 |  Loss: (0.3715) |  Loss2: (0.0000) | Acc: (87.00%) (16862/19328)
Epoch: 57 | Batch_idx: 160 |  Loss: (0.3715) |  Loss2: (0.0000) | Acc: (87.00%) (17989/20608)
Epoch: 57 | Batch_idx: 170 |  Loss: (0.3732) |  Loss2: (0.0000) | Acc: (87.00%) (19094/21888)
Epoch: 57 | Batch_idx: 180 |  Loss: (0.3726) |  Loss2: (0.0000) | Acc: (87.00%) (20221/23168)
Epoch: 57 | Batch_idx: 190 |  Loss: (0.3725) |  Loss2: (0.0000) | Acc: (87.00%) (21337/24448)
Epoch: 57 | Batch_idx: 200 |  Loss: (0.3729) |  Loss2: (0.0000) | Acc: (87.00%) (22449/25728)
Epoch: 57 | Batch_idx: 210 |  Loss: (0.3749) |  Loss2: (0.0000) | Acc: (87.00%) (23543/27008)
Epoch: 57 | Batch_idx: 220 |  Loss: (0.3763) |  Loss2: (0.0000) | Acc: (87.00%) (24643/28288)
Epoch: 57 | Batch_idx: 230 |  Loss: (0.3760) |  Loss2: (0.0000) | Acc: (87.00%) (25757/29568)
Epoch: 57 | Batch_idx: 240 |  Loss: (0.3757) |  Loss2: (0.0000) | Acc: (87.00%) (26871/30848)
Epoch: 57 | Batch_idx: 250 |  Loss: (0.3754) |  Loss2: (0.0000) | Acc: (87.00%) (27982/32128)
Epoch: 57 | Batch_idx: 260 |  Loss: (0.3771) |  Loss2: (0.0000) | Acc: (87.00%) (29083/33408)
Epoch: 57 | Batch_idx: 270 |  Loss: (0.3783) |  Loss2: (0.0000) | Acc: (87.00%) (30199/34688)
Epoch: 57 | Batch_idx: 280 |  Loss: (0.3795) |  Loss2: (0.0000) | Acc: (87.00%) (31295/35968)
Epoch: 57 | Batch_idx: 290 |  Loss: (0.3812) |  Loss2: (0.0000) | Acc: (86.00%) (32381/37248)
Epoch: 57 | Batch_idx: 300 |  Loss: (0.3825) |  Loss2: (0.0000) | Acc: (86.00%) (33471/38528)
Epoch: 57 | Batch_idx: 310 |  Loss: (0.3833) |  Loss2: (0.0000) | Acc: (86.00%) (34572/39808)
Epoch: 57 | Batch_idx: 320 |  Loss: (0.3824) |  Loss2: (0.0000) | Acc: (86.00%) (35691/41088)
Epoch: 57 | Batch_idx: 330 |  Loss: (0.3822) |  Loss2: (0.0000) | Acc: (86.00%) (36801/42368)
Epoch: 57 | Batch_idx: 340 |  Loss: (0.3814) |  Loss2: (0.0000) | Acc: (86.00%) (37928/43648)
Epoch: 57 | Batch_idx: 350 |  Loss: (0.3812) |  Loss2: (0.0000) | Acc: (86.00%) (39046/44928)
Epoch: 57 | Batch_idx: 360 |  Loss: (0.3813) |  Loss2: (0.0000) | Acc: (86.00%) (40163/46208)
Epoch: 57 | Batch_idx: 370 |  Loss: (0.3810) |  Loss2: (0.0000) | Acc: (86.00%) (41278/47488)
Epoch: 57 | Batch_idx: 380 |  Loss: (0.3813) |  Loss2: (0.0000) | Acc: (86.00%) (42381/48768)
Epoch: 57 | Batch_idx: 390 |  Loss: (0.3808) |  Loss2: (0.0000) | Acc: (86.00%) (43464/50000)
# TEST : Loss: (0.5381) | Acc: (82.00%) (8242/10000)
percent tensor([0.4931, 0.4848, 0.4888, 0.4860, 0.4886, 0.5003, 0.4867, 0.4862, 0.4914,
        0.4859, 0.4925, 0.4858, 0.4867, 0.4900, 0.4895, 0.4913],
       device='cuda:0') torch.Size([16])
percent tensor([0.5140, 0.5058, 0.5206, 0.5208, 0.5194, 0.5141, 0.5111, 0.5222, 0.5170,
        0.5086, 0.5117, 0.5115, 0.5052, 0.5178, 0.5103, 0.5136],
       device='cuda:0') torch.Size([16])
percent tensor([0.5206, 0.5095, 0.5279, 0.5369, 0.5315, 0.5256, 0.5201, 0.5323, 0.5173,
        0.5139, 0.5139, 0.5195, 0.5009, 0.5348, 0.5157, 0.5235],
       device='cuda:0') torch.Size([16])
percent tensor([0.5642, 0.5834, 0.5640, 0.5572, 0.5594, 0.5573, 0.5782, 0.5620, 0.5816,
        0.5864, 0.5912, 0.5764, 0.5772, 0.5967, 0.5632, 0.5735],
       device='cuda:0') torch.Size([16])
percent tensor([0.5244, 0.5380, 0.4645, 0.4926, 0.4480, 0.5495, 0.5179, 0.4169, 0.5520,
        0.5378, 0.5761, 0.5074, 0.5379, 0.5696, 0.4989, 0.5411],
       device='cuda:0') torch.Size([16])
percent tensor([0.5401, 0.5314, 0.5402, 0.5447, 0.5615, 0.5556, 0.5449, 0.5649, 0.5392,
        0.5321, 0.5228, 0.5201, 0.5266, 0.5361, 0.5364, 0.5510],
       device='cuda:0') torch.Size([16])
percent tensor([0.5198, 0.5546, 0.6261, 0.6147, 0.6637, 0.6693, 0.5434, 0.6539, 0.5938,
        0.5541, 0.5520, 0.5513, 0.5415, 0.5650, 0.5395, 0.5386],
       device='cuda:0') torch.Size([16])
percent tensor([0.9931, 0.9924, 0.9931, 0.9949, 0.9919, 0.9939, 0.9907, 0.9972, 0.9962,
        0.9965, 0.9966, 0.9965, 0.9960, 0.9896, 0.9946, 0.9918],
       device='cuda:0') torch.Size([16])
Epoch: 58 | Batch_idx: 0 |  Loss: (0.3888) |  Loss2: (0.0000) | Acc: (86.00%) (111/128)
Epoch: 58 | Batch_idx: 10 |  Loss: (0.3704) |  Loss2: (0.0000) | Acc: (86.00%) (1223/1408)
Epoch: 58 | Batch_idx: 20 |  Loss: (0.3609) |  Loss2: (0.0000) | Acc: (87.00%) (2350/2688)
Epoch: 58 | Batch_idx: 30 |  Loss: (0.3541) |  Loss2: (0.0000) | Acc: (87.00%) (3484/3968)
Epoch: 58 | Batch_idx: 40 |  Loss: (0.3729) |  Loss2: (0.0000) | Acc: (87.00%) (4574/5248)
Epoch: 58 | Batch_idx: 50 |  Loss: (0.3739) |  Loss2: (0.0000) | Acc: (87.00%) (5691/6528)
Epoch: 58 | Batch_idx: 60 |  Loss: (0.3684) |  Loss2: (0.0000) | Acc: (87.00%) (6819/7808)
Epoch: 58 | Batch_idx: 70 |  Loss: (0.3695) |  Loss2: (0.0000) | Acc: (87.00%) (7933/9088)
Epoch: 58 | Batch_idx: 80 |  Loss: (0.3646) |  Loss2: (0.0000) | Acc: (87.00%) (9068/10368)
Epoch: 58 | Batch_idx: 90 |  Loss: (0.3682) |  Loss2: (0.0000) | Acc: (87.00%) (10172/11648)
Epoch: 58 | Batch_idx: 100 |  Loss: (0.3642) |  Loss2: (0.0000) | Acc: (87.00%) (11307/12928)
Epoch: 58 | Batch_idx: 110 |  Loss: (0.3637) |  Loss2: (0.0000) | Acc: (87.00%) (12429/14208)
Epoch: 58 | Batch_idx: 120 |  Loss: (0.3649) |  Loss2: (0.0000) | Acc: (87.00%) (13544/15488)
Epoch: 58 | Batch_idx: 130 |  Loss: (0.3650) |  Loss2: (0.0000) | Acc: (87.00%) (14667/16768)
Epoch: 58 | Batch_idx: 140 |  Loss: (0.3673) |  Loss2: (0.0000) | Acc: (87.00%) (15768/18048)
Epoch: 58 | Batch_idx: 150 |  Loss: (0.3681) |  Loss2: (0.0000) | Acc: (87.00%) (16881/19328)
Epoch: 58 | Batch_idx: 160 |  Loss: (0.3685) |  Loss2: (0.0000) | Acc: (87.00%) (17991/20608)
Epoch: 58 | Batch_idx: 170 |  Loss: (0.3670) |  Loss2: (0.0000) | Acc: (87.00%) (19117/21888)
Epoch: 58 | Batch_idx: 180 |  Loss: (0.3672) |  Loss2: (0.0000) | Acc: (87.00%) (20236/23168)
Epoch: 58 | Batch_idx: 190 |  Loss: (0.3673) |  Loss2: (0.0000) | Acc: (87.00%) (21345/24448)
Epoch: 58 | Batch_idx: 200 |  Loss: (0.3664) |  Loss2: (0.0000) | Acc: (87.00%) (22476/25728)
Epoch: 58 | Batch_idx: 210 |  Loss: (0.3653) |  Loss2: (0.0000) | Acc: (87.00%) (23609/27008)
Epoch: 58 | Batch_idx: 220 |  Loss: (0.3656) |  Loss2: (0.0000) | Acc: (87.00%) (24727/28288)
Epoch: 58 | Batch_idx: 230 |  Loss: (0.3659) |  Loss2: (0.0000) | Acc: (87.00%) (25842/29568)
Epoch: 58 | Batch_idx: 240 |  Loss: (0.3642) |  Loss2: (0.0000) | Acc: (87.00%) (26972/30848)
Epoch: 58 | Batch_idx: 250 |  Loss: (0.3646) |  Loss2: (0.0000) | Acc: (87.00%) (28087/32128)
Epoch: 58 | Batch_idx: 260 |  Loss: (0.3651) |  Loss2: (0.0000) | Acc: (87.00%) (29202/33408)
Epoch: 58 | Batch_idx: 270 |  Loss: (0.3647) |  Loss2: (0.0000) | Acc: (87.00%) (30324/34688)
Epoch: 58 | Batch_idx: 280 |  Loss: (0.3651) |  Loss2: (0.0000) | Acc: (87.00%) (31436/35968)
Epoch: 58 | Batch_idx: 290 |  Loss: (0.3657) |  Loss2: (0.0000) | Acc: (87.00%) (32546/37248)
Epoch: 58 | Batch_idx: 300 |  Loss: (0.3656) |  Loss2: (0.0000) | Acc: (87.00%) (33661/38528)
Epoch: 58 | Batch_idx: 310 |  Loss: (0.3660) |  Loss2: (0.0000) | Acc: (87.00%) (34766/39808)
Epoch: 58 | Batch_idx: 320 |  Loss: (0.3669) |  Loss2: (0.0000) | Acc: (87.00%) (35874/41088)
Epoch: 58 | Batch_idx: 330 |  Loss: (0.3677) |  Loss2: (0.0000) | Acc: (87.00%) (36973/42368)
Epoch: 58 | Batch_idx: 340 |  Loss: (0.3678) |  Loss2: (0.0000) | Acc: (87.00%) (38092/43648)
Epoch: 58 | Batch_idx: 350 |  Loss: (0.3690) |  Loss2: (0.0000) | Acc: (87.00%) (39205/44928)
Epoch: 58 | Batch_idx: 360 |  Loss: (0.3695) |  Loss2: (0.0000) | Acc: (87.00%) (40308/46208)
Epoch: 58 | Batch_idx: 370 |  Loss: (0.3697) |  Loss2: (0.0000) | Acc: (87.00%) (41420/47488)
Epoch: 58 | Batch_idx: 380 |  Loss: (0.3696) |  Loss2: (0.0000) | Acc: (87.00%) (42539/48768)
Epoch: 58 | Batch_idx: 390 |  Loss: (0.3703) |  Loss2: (0.0000) | Acc: (87.00%) (43611/50000)
# TEST : Loss: (0.4967) | Acc: (83.00%) (8324/10000)
percent tensor([0.4939, 0.4844, 0.4899, 0.4874, 0.4895, 0.5009, 0.4864, 0.4868, 0.4904,
        0.4862, 0.4915, 0.4864, 0.4865, 0.4882, 0.4898, 0.4915],
       device='cuda:0') torch.Size([16])
percent tensor([0.5166, 0.5079, 0.5224, 0.5232, 0.5224, 0.5186, 0.5132, 0.5249, 0.5206,
        0.5105, 0.5147, 0.5139, 0.5082, 0.5189, 0.5133, 0.5164],
       device='cuda:0') torch.Size([16])
percent tensor([0.5217, 0.5097, 0.5247, 0.5388, 0.5292, 0.5342, 0.5214, 0.5310, 0.5165,
        0.5148, 0.5133, 0.5181, 0.5015, 0.5342, 0.5189, 0.5274],
       device='cuda:0') torch.Size([16])
percent tensor([0.5672, 0.5827, 0.5634, 0.5638, 0.5611, 0.5600, 0.5778, 0.5625, 0.5791,
        0.5843, 0.5905, 0.5743, 0.5780, 0.5920, 0.5643, 0.5757],
       device='cuda:0') torch.Size([16])
percent tensor([0.5271, 0.5441, 0.4416, 0.4918, 0.4343, 0.5507, 0.5182, 0.4084, 0.5403,
        0.5346, 0.5751, 0.4788, 0.5418, 0.5682, 0.4953, 0.5482],
       device='cuda:0') torch.Size([16])
percent tensor([0.5395, 0.5297, 0.5436, 0.5441, 0.5670, 0.5553, 0.5446, 0.5609, 0.5441,
        0.5353, 0.5256, 0.5232, 0.5301, 0.5360, 0.5348, 0.5509],
       device='cuda:0') torch.Size([16])
percent tensor([0.5256, 0.5552, 0.6448, 0.6286, 0.6836, 0.6654, 0.5581, 0.6454, 0.5977,
        0.5494, 0.5724, 0.5766, 0.5511, 0.5710, 0.5483, 0.5501],
       device='cuda:0') torch.Size([16])
percent tensor([0.9936, 0.9919, 0.9929, 0.9955, 0.9939, 0.9955, 0.9920, 0.9979, 0.9934,
        0.9926, 0.9947, 0.9942, 0.9941, 0.9868, 0.9947, 0.9942],
       device='cuda:0') torch.Size([16])
Epoch: 59 | Batch_idx: 0 |  Loss: (0.4240) |  Loss2: (0.0000) | Acc: (83.00%) (107/128)
Epoch: 59 | Batch_idx: 10 |  Loss: (0.3639) |  Loss2: (0.0000) | Acc: (87.00%) (1230/1408)
Epoch: 59 | Batch_idx: 20 |  Loss: (0.3572) |  Loss2: (0.0000) | Acc: (87.00%) (2363/2688)
Epoch: 59 | Batch_idx: 30 |  Loss: (0.3507) |  Loss2: (0.0000) | Acc: (88.00%) (3503/3968)
Epoch: 59 | Batch_idx: 40 |  Loss: (0.3493) |  Loss2: (0.0000) | Acc: (88.00%) (4637/5248)
Epoch: 59 | Batch_idx: 50 |  Loss: (0.3546) |  Loss2: (0.0000) | Acc: (88.00%) (5756/6528)
Epoch: 59 | Batch_idx: 60 |  Loss: (0.3509) |  Loss2: (0.0000) | Acc: (88.00%) (6882/7808)
Epoch: 59 | Batch_idx: 70 |  Loss: (0.3498) |  Loss2: (0.0000) | Acc: (87.00%) (7993/9088)
Epoch: 59 | Batch_idx: 80 |  Loss: (0.3507) |  Loss2: (0.0000) | Acc: (87.00%) (9115/10368)
Epoch: 59 | Batch_idx: 90 |  Loss: (0.3558) |  Loss2: (0.0000) | Acc: (87.00%) (10226/11648)
Epoch: 59 | Batch_idx: 100 |  Loss: (0.3566) |  Loss2: (0.0000) | Acc: (87.00%) (11339/12928)
Epoch: 59 | Batch_idx: 110 |  Loss: (0.3559) |  Loss2: (0.0000) | Acc: (87.00%) (12464/14208)
Epoch: 59 | Batch_idx: 120 |  Loss: (0.3548) |  Loss2: (0.0000) | Acc: (87.00%) (13592/15488)
Epoch: 59 | Batch_idx: 130 |  Loss: (0.3542) |  Loss2: (0.0000) | Acc: (87.00%) (14710/16768)
Epoch: 59 | Batch_idx: 140 |  Loss: (0.3549) |  Loss2: (0.0000) | Acc: (87.00%) (15829/18048)
Epoch: 59 | Batch_idx: 150 |  Loss: (0.3549) |  Loss2: (0.0000) | Acc: (87.00%) (16944/19328)
Epoch: 59 | Batch_idx: 160 |  Loss: (0.3547) |  Loss2: (0.0000) | Acc: (87.00%) (18066/20608)
Epoch: 59 | Batch_idx: 170 |  Loss: (0.3551) |  Loss2: (0.0000) | Acc: (87.00%) (19181/21888)
Epoch: 59 | Batch_idx: 180 |  Loss: (0.3562) |  Loss2: (0.0000) | Acc: (87.00%) (20293/23168)
Epoch: 59 | Batch_idx: 190 |  Loss: (0.3540) |  Loss2: (0.0000) | Acc: (87.00%) (21435/24448)
Epoch: 59 | Batch_idx: 200 |  Loss: (0.3560) |  Loss2: (0.0000) | Acc: (87.00%) (22552/25728)
Epoch: 59 | Batch_idx: 210 |  Loss: (0.3576) |  Loss2: (0.0000) | Acc: (87.00%) (23665/27008)
Epoch: 59 | Batch_idx: 220 |  Loss: (0.3581) |  Loss2: (0.0000) | Acc: (87.00%) (24789/28288)
Epoch: 59 | Batch_idx: 230 |  Loss: (0.3593) |  Loss2: (0.0000) | Acc: (87.00%) (25901/29568)
Epoch: 59 | Batch_idx: 240 |  Loss: (0.3596) |  Loss2: (0.0000) | Acc: (87.00%) (27026/30848)
Epoch: 59 | Batch_idx: 250 |  Loss: (0.3589) |  Loss2: (0.0000) | Acc: (87.00%) (28153/32128)
Epoch: 59 | Batch_idx: 260 |  Loss: (0.3587) |  Loss2: (0.0000) | Acc: (87.00%) (29278/33408)
Epoch: 59 | Batch_idx: 270 |  Loss: (0.3596) |  Loss2: (0.0000) | Acc: (87.00%) (30381/34688)
Epoch: 59 | Batch_idx: 280 |  Loss: (0.3601) |  Loss2: (0.0000) | Acc: (87.00%) (31487/35968)
Epoch: 59 | Batch_idx: 290 |  Loss: (0.3595) |  Loss2: (0.0000) | Acc: (87.00%) (32616/37248)
Epoch: 59 | Batch_idx: 300 |  Loss: (0.3598) |  Loss2: (0.0000) | Acc: (87.00%) (33732/38528)
Epoch: 59 | Batch_idx: 310 |  Loss: (0.3590) |  Loss2: (0.0000) | Acc: (87.00%) (34869/39808)
Epoch: 59 | Batch_idx: 320 |  Loss: (0.3585) |  Loss2: (0.0000) | Acc: (87.00%) (36002/41088)
Epoch: 59 | Batch_idx: 330 |  Loss: (0.3591) |  Loss2: (0.0000) | Acc: (87.00%) (37111/42368)
Epoch: 59 | Batch_idx: 340 |  Loss: (0.3593) |  Loss2: (0.0000) | Acc: (87.00%) (38225/43648)
Epoch: 59 | Batch_idx: 350 |  Loss: (0.3591) |  Loss2: (0.0000) | Acc: (87.00%) (39343/44928)
Epoch: 59 | Batch_idx: 360 |  Loss: (0.3601) |  Loss2: (0.0000) | Acc: (87.00%) (40448/46208)
Epoch: 59 | Batch_idx: 370 |  Loss: (0.3602) |  Loss2: (0.0000) | Acc: (87.00%) (41571/47488)
Epoch: 59 | Batch_idx: 380 |  Loss: (0.3596) |  Loss2: (0.0000) | Acc: (87.00%) (42688/48768)
Epoch: 59 | Batch_idx: 390 |  Loss: (0.3592) |  Loss2: (0.0000) | Acc: (87.00%) (43778/50000)
# TEST : Loss: (0.4861) | Acc: (83.00%) (8352/10000)
percent tensor([0.4941, 0.4849, 0.4896, 0.4870, 0.4892, 0.5010, 0.4866, 0.4867, 0.4908,
        0.4859, 0.4918, 0.4859, 0.4867, 0.4892, 0.4899, 0.4916],
       device='cuda:0') torch.Size([16])
percent tensor([0.5159, 0.5076, 0.5211, 0.5221, 0.5206, 0.5166, 0.5127, 0.5239, 0.5207,
        0.5104, 0.5146, 0.5129, 0.5076, 0.5197, 0.5120, 0.5161],
       device='cuda:0') torch.Size([16])
percent tensor([0.5233, 0.5138, 0.5224, 0.5379, 0.5289, 0.5342, 0.5220, 0.5304, 0.5191,
        0.5180, 0.5171, 0.5178, 0.5033, 0.5387, 0.5205, 0.5296],
       device='cuda:0') torch.Size([16])
percent tensor([0.5683, 0.5838, 0.5692, 0.5632, 0.5642, 0.5593, 0.5798, 0.5631, 0.5807,
        0.5884, 0.5930, 0.5779, 0.5786, 0.5939, 0.5647, 0.5773],
       device='cuda:0') torch.Size([16])
percent tensor([0.5339, 0.5386, 0.4771, 0.5080, 0.4631, 0.5572, 0.5238, 0.4274, 0.5480,
        0.5342, 0.5792, 0.5030, 0.5396, 0.5713, 0.5082, 0.5514],
       device='cuda:0') torch.Size([16])
percent tensor([0.5383, 0.5378, 0.5386, 0.5426, 0.5634, 0.5560, 0.5466, 0.5622, 0.5385,
        0.5400, 0.5232, 0.5182, 0.5264, 0.5392, 0.5371, 0.5555],
       device='cuda:0') torch.Size([16])
percent tensor([0.5214, 0.5855, 0.6379, 0.6137, 0.6785, 0.6696, 0.5709, 0.6598, 0.5724,
        0.5648, 0.5629, 0.5578, 0.5537, 0.5760, 0.5494, 0.5482],
       device='cuda:0') torch.Size([16])
percent tensor([0.9949, 0.9934, 0.9911, 0.9952, 0.9933, 0.9948, 0.9900, 0.9964, 0.9959,
        0.9932, 0.9962, 0.9941, 0.9967, 0.9906, 0.9944, 0.9933],
       device='cuda:0') torch.Size([16])
Epoch: 60 | Batch_idx: 0 |  Loss: (0.3213) |  Loss2: (0.0000) | Acc: (88.00%) (113/128)
Epoch: 60 | Batch_idx: 10 |  Loss: (0.3351) |  Loss2: (0.0000) | Acc: (88.00%) (1250/1408)
Epoch: 60 | Batch_idx: 20 |  Loss: (0.3511) |  Loss2: (0.0000) | Acc: (87.00%) (2365/2688)
Epoch: 60 | Batch_idx: 30 |  Loss: (0.3376) |  Loss2: (0.0000) | Acc: (88.00%) (3504/3968)
Epoch: 60 | Batch_idx: 40 |  Loss: (0.3411) |  Loss2: (0.0000) | Acc: (88.00%) (4634/5248)
Epoch: 60 | Batch_idx: 50 |  Loss: (0.3356) |  Loss2: (0.0000) | Acc: (88.00%) (5777/6528)
Epoch: 60 | Batch_idx: 60 |  Loss: (0.3387) |  Loss2: (0.0000) | Acc: (88.00%) (6901/7808)
Epoch: 60 | Batch_idx: 70 |  Loss: (0.3379) |  Loss2: (0.0000) | Acc: (88.00%) (8029/9088)
Epoch: 60 | Batch_idx: 80 |  Loss: (0.3409) |  Loss2: (0.0000) | Acc: (88.00%) (9160/10368)
Epoch: 60 | Batch_idx: 90 |  Loss: (0.3459) |  Loss2: (0.0000) | Acc: (88.00%) (10262/11648)
Epoch: 60 | Batch_idx: 100 |  Loss: (0.3418) |  Loss2: (0.0000) | Acc: (88.00%) (11408/12928)
Epoch: 60 | Batch_idx: 110 |  Loss: (0.3429) |  Loss2: (0.0000) | Acc: (88.00%) (12524/14208)
Epoch: 60 | Batch_idx: 120 |  Loss: (0.3438) |  Loss2: (0.0000) | Acc: (88.00%) (13652/15488)
Epoch: 60 | Batch_idx: 130 |  Loss: (0.3457) |  Loss2: (0.0000) | Acc: (88.00%) (14771/16768)
Epoch: 60 | Batch_idx: 140 |  Loss: (0.3463) |  Loss2: (0.0000) | Acc: (88.00%) (15898/18048)
Epoch: 60 | Batch_idx: 150 |  Loss: (0.3462) |  Loss2: (0.0000) | Acc: (88.00%) (17012/19328)
Epoch: 60 | Batch_idx: 160 |  Loss: (0.3467) |  Loss2: (0.0000) | Acc: (88.00%) (18139/20608)
Epoch: 60 | Batch_idx: 170 |  Loss: (0.3491) |  Loss2: (0.0000) | Acc: (87.00%) (19254/21888)
Epoch: 60 | Batch_idx: 180 |  Loss: (0.3476) |  Loss2: (0.0000) | Acc: (88.00%) (20392/23168)
Epoch: 60 | Batch_idx: 190 |  Loss: (0.3483) |  Loss2: (0.0000) | Acc: (87.00%) (21508/24448)
Epoch: 60 | Batch_idx: 200 |  Loss: (0.3488) |  Loss2: (0.0000) | Acc: (87.00%) (22636/25728)
Epoch: 60 | Batch_idx: 210 |  Loss: (0.3478) |  Loss2: (0.0000) | Acc: (87.00%) (23767/27008)
Epoch: 60 | Batch_idx: 220 |  Loss: (0.3477) |  Loss2: (0.0000) | Acc: (87.00%) (24885/28288)
Epoch: 60 | Batch_idx: 230 |  Loss: (0.3501) |  Loss2: (0.0000) | Acc: (87.00%) (25989/29568)
Epoch: 60 | Batch_idx: 240 |  Loss: (0.3498) |  Loss2: (0.0000) | Acc: (87.00%) (27129/30848)
Epoch: 60 | Batch_idx: 250 |  Loss: (0.3497) |  Loss2: (0.0000) | Acc: (87.00%) (28264/32128)
Epoch: 60 | Batch_idx: 260 |  Loss: (0.3514) |  Loss2: (0.0000) | Acc: (87.00%) (29363/33408)
Epoch: 60 | Batch_idx: 270 |  Loss: (0.3508) |  Loss2: (0.0000) | Acc: (87.00%) (30506/34688)
Epoch: 60 | Batch_idx: 280 |  Loss: (0.3509) |  Loss2: (0.0000) | Acc: (87.00%) (31621/35968)
Epoch: 60 | Batch_idx: 290 |  Loss: (0.3492) |  Loss2: (0.0000) | Acc: (87.00%) (32769/37248)
Epoch: 60 | Batch_idx: 300 |  Loss: (0.3497) |  Loss2: (0.0000) | Acc: (87.00%) (33875/38528)
Epoch: 60 | Batch_idx: 310 |  Loss: (0.3491) |  Loss2: (0.0000) | Acc: (87.00%) (35008/39808)
Epoch: 60 | Batch_idx: 320 |  Loss: (0.3492) |  Loss2: (0.0000) | Acc: (87.00%) (36128/41088)
Epoch: 60 | Batch_idx: 330 |  Loss: (0.3500) |  Loss2: (0.0000) | Acc: (87.00%) (37233/42368)
Epoch: 60 | Batch_idx: 340 |  Loss: (0.3503) |  Loss2: (0.0000) | Acc: (87.00%) (38350/43648)
Epoch: 60 | Batch_idx: 350 |  Loss: (0.3515) |  Loss2: (0.0000) | Acc: (87.00%) (39465/44928)
Epoch: 60 | Batch_idx: 360 |  Loss: (0.3519) |  Loss2: (0.0000) | Acc: (87.00%) (40579/46208)
Epoch: 60 | Batch_idx: 370 |  Loss: (0.3511) |  Loss2: (0.0000) | Acc: (87.00%) (41716/47488)
Epoch: 60 | Batch_idx: 380 |  Loss: (0.3510) |  Loss2: (0.0000) | Acc: (87.00%) (42846/48768)
Epoch: 60 | Batch_idx: 390 |  Loss: (0.3511) |  Loss2: (0.0000) | Acc: (87.00%) (43920/50000)
=> saving checkpoint 'drive/app/torch/save_Schedule/checkpoint_060.pth.tar'
# TEST : Loss: (0.4769) | Acc: (84.00%) (8424/10000)
percent tensor([0.4937, 0.4860, 0.4871, 0.4866, 0.4872, 0.5008, 0.4869, 0.4857, 0.4915,
        0.4858, 0.4927, 0.4845, 0.4867, 0.4924, 0.4902, 0.4916],
       device='cuda:0') torch.Size([16])
percent tensor([0.5159, 0.5067, 0.5200, 0.5226, 0.5198, 0.5179, 0.5116, 0.5221, 0.5198,
        0.5087, 0.5136, 0.5114, 0.5067, 0.5201, 0.5121, 0.5160],
       device='cuda:0') torch.Size([16])
percent tensor([0.5224, 0.5128, 0.5212, 0.5415, 0.5271, 0.5346, 0.5200, 0.5305, 0.5186,
        0.5150, 0.5169, 0.5155, 0.5009, 0.5382, 0.5215, 0.5286],
       device='cuda:0') torch.Size([16])
percent tensor([0.5681, 0.5841, 0.5657, 0.5630, 0.5604, 0.5617, 0.5779, 0.5635, 0.5785,
        0.5875, 0.5908, 0.5742, 0.5785, 0.5936, 0.5669, 0.5773],
       device='cuda:0') torch.Size([16])
percent tensor([0.5255, 0.5380, 0.4612, 0.4938, 0.4337, 0.5471, 0.5086, 0.4195, 0.5399,
        0.5332, 0.5705, 0.4854, 0.5331, 0.5686, 0.4977, 0.5439],
       device='cuda:0') torch.Size([16])
percent tensor([0.5442, 0.5409, 0.5407, 0.5442, 0.5640, 0.5618, 0.5450, 0.5609, 0.5439,
        0.5399, 0.5289, 0.5190, 0.5324, 0.5401, 0.5373, 0.5558],
       device='cuda:0') torch.Size([16])
percent tensor([0.5306, 0.5796, 0.6431, 0.6233, 0.6816, 0.6739, 0.5560, 0.6519, 0.6017,
        0.5700, 0.5762, 0.5708, 0.5631, 0.5679, 0.5599, 0.5530],
       device='cuda:0') torch.Size([16])
percent tensor([0.9932, 0.9923, 0.9927, 0.9955, 0.9929, 0.9933, 0.9923, 0.9971, 0.9960,
        0.9959, 0.9977, 0.9951, 0.9973, 0.9901, 0.9965, 0.9955],
       device='cuda:0') torch.Size([16])
Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 3, 3, 3]) tensor(178.9721, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(809.5657, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(798.0244, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([128, 64, 3, 3]) tensor(1531.9241, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([128, 64, 1, 1]) tensor(495.3651, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([128, 128, 3, 3]) tensor(2222.6963, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([256, 128, 3, 3]) tensor(4285.8691, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([256, 128, 1, 1]) tensor(1408.4109, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([256, 256, 3, 3]) tensor(6104.0088, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([512, 256, 3, 3]) tensor(12006.1553, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([512, 256, 1, 1]) tensor(4000.0261, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([512, 512, 3, 3]) tensor(16922.2148, device='cuda:0', grad_fn=<NormBackward0>)
Epoch: 61 | Batch_idx: 0 |  Loss: (0.3367) |  Loss2: (0.0000) | Acc: (87.00%) (112/128)
Epoch: 61 | Batch_idx: 10 |  Loss: (0.3080) |  Loss2: (0.0000) | Acc: (89.00%) (1258/1408)
Epoch: 61 | Batch_idx: 20 |  Loss: (0.3244) |  Loss2: (0.0000) | Acc: (88.00%) (2381/2688)
Epoch: 61 | Batch_idx: 30 |  Loss: (0.3199) |  Loss2: (0.0000) | Acc: (88.00%) (3520/3968)
Epoch: 61 | Batch_idx: 40 |  Loss: (0.3243) |  Loss2: (0.0000) | Acc: (88.00%) (4649/5248)
Epoch: 61 | Batch_idx: 50 |  Loss: (0.3330) |  Loss2: (0.0000) | Acc: (88.00%) (5773/6528)
Epoch: 61 | Batch_idx: 60 |  Loss: (0.3354) |  Loss2: (0.0000) | Acc: (88.00%) (6893/7808)
Epoch: 61 | Batch_idx: 70 |  Loss: (0.3356) |  Loss2: (0.0000) | Acc: (88.00%) (8009/9088)
Epoch: 61 | Batch_idx: 80 |  Loss: (0.3381) |  Loss2: (0.0000) | Acc: (87.00%) (9120/10368)
Epoch: 61 | Batch_idx: 90 |  Loss: (0.3362) |  Loss2: (0.0000) | Acc: (88.00%) (10256/11648)
Epoch: 61 | Batch_idx: 100 |  Loss: (0.3334) |  Loss2: (0.0000) | Acc: (88.00%) (11404/12928)
Epoch: 61 | Batch_idx: 110 |  Loss: (0.3370) |  Loss2: (0.0000) | Acc: (88.00%) (12530/14208)
Epoch: 61 | Batch_idx: 120 |  Loss: (0.3362) |  Loss2: (0.0000) | Acc: (88.00%) (13671/15488)
Epoch: 61 | Batch_idx: 130 |  Loss: (0.3368) |  Loss2: (0.0000) | Acc: (88.00%) (14802/16768)
Epoch: 61 | Batch_idx: 140 |  Loss: (0.3370) |  Loss2: (0.0000) | Acc: (88.00%) (15928/18048)
Epoch: 61 | Batch_idx: 150 |  Loss: (0.3389) |  Loss2: (0.0000) | Acc: (88.00%) (17037/19328)
Epoch: 61 | Batch_idx: 160 |  Loss: (0.3397) |  Loss2: (0.0000) | Acc: (88.00%) (18154/20608)
Epoch: 61 | Batch_idx: 170 |  Loss: (0.3408) |  Loss2: (0.0000) | Acc: (88.00%) (19281/21888)
Epoch: 61 | Batch_idx: 180 |  Loss: (0.3411) |  Loss2: (0.0000) | Acc: (88.00%) (20405/23168)
Epoch: 61 | Batch_idx: 190 |  Loss: (0.3408) |  Loss2: (0.0000) | Acc: (88.00%) (21540/24448)
Epoch: 61 | Batch_idx: 200 |  Loss: (0.3414) |  Loss2: (0.0000) | Acc: (88.00%) (22657/25728)
Epoch: 61 | Batch_idx: 210 |  Loss: (0.3425) |  Loss2: (0.0000) | Acc: (88.00%) (23783/27008)
Epoch: 61 | Batch_idx: 220 |  Loss: (0.3431) |  Loss2: (0.0000) | Acc: (88.00%) (24903/28288)
Epoch: 61 | Batch_idx: 230 |  Loss: (0.3428) |  Loss2: (0.0000) | Acc: (88.00%) (26031/29568)
Epoch: 61 | Batch_idx: 240 |  Loss: (0.3420) |  Loss2: (0.0000) | Acc: (88.00%) (27173/30848)
Epoch: 61 | Batch_idx: 250 |  Loss: (0.3423) |  Loss2: (0.0000) | Acc: (88.00%) (28303/32128)
Epoch: 61 | Batch_idx: 260 |  Loss: (0.3430) |  Loss2: (0.0000) | Acc: (88.00%) (29422/33408)
Epoch: 61 | Batch_idx: 270 |  Loss: (0.3426) |  Loss2: (0.0000) | Acc: (88.00%) (30547/34688)
Epoch: 61 | Batch_idx: 280 |  Loss: (0.3426) |  Loss2: (0.0000) | Acc: (88.00%) (31673/35968)
Epoch: 61 | Batch_idx: 290 |  Loss: (0.3422) |  Loss2: (0.0000) | Acc: (88.00%) (32808/37248)
Epoch: 61 | Batch_idx: 300 |  Loss: (0.3427) |  Loss2: (0.0000) | Acc: (88.00%) (33927/38528)
Epoch: 61 | Batch_idx: 310 |  Loss: (0.3440) |  Loss2: (0.0000) | Acc: (87.00%) (35026/39808)
Epoch: 61 | Batch_idx: 320 |  Loss: (0.3438) |  Loss2: (0.0000) | Acc: (88.00%) (36172/41088)
Epoch: 61 | Batch_idx: 330 |  Loss: (0.3444) |  Loss2: (0.0000) | Acc: (88.00%) (37291/42368)
Epoch: 61 | Batch_idx: 340 |  Loss: (0.3452) |  Loss2: (0.0000) | Acc: (88.00%) (38415/43648)
Epoch: 61 | Batch_idx: 350 |  Loss: (0.3456) |  Loss2: (0.0000) | Acc: (88.00%) (39538/44928)
Epoch: 61 | Batch_idx: 360 |  Loss: (0.3454) |  Loss2: (0.0000) | Acc: (88.00%) (40671/46208)
Epoch: 61 | Batch_idx: 370 |  Loss: (0.3448) |  Loss2: (0.0000) | Acc: (88.00%) (41806/47488)
Epoch: 61 | Batch_idx: 380 |  Loss: (0.3453) |  Loss2: (0.0000) | Acc: (88.00%) (42916/48768)
Epoch: 61 | Batch_idx: 390 |  Loss: (0.3441) |  Loss2: (0.0000) | Acc: (88.00%) (44018/50000)
# TEST : Loss: (0.5000) | Acc: (83.00%) (8334/10000)
percent tensor([0.4937, 0.4846, 0.4891, 0.4869, 0.4886, 0.5006, 0.4865, 0.4859, 0.4906,
        0.4858, 0.4919, 0.4860, 0.4867, 0.4894, 0.4896, 0.4911],
       device='cuda:0') torch.Size([16])
percent tensor([0.5157, 0.5073, 0.5217, 0.5228, 0.5210, 0.5172, 0.5119, 0.5232, 0.5197,
        0.5096, 0.5136, 0.5128, 0.5071, 0.5194, 0.5123, 0.5151],
       device='cuda:0') torch.Size([16])
percent tensor([0.5243, 0.5126, 0.5283, 0.5420, 0.5321, 0.5346, 0.5227, 0.5354, 0.5204,
        0.5193, 0.5172, 0.5229, 0.5021, 0.5408, 0.5221, 0.5290],
       device='cuda:0') torch.Size([16])
percent tensor([0.5674, 0.5845, 0.5665, 0.5665, 0.5622, 0.5623, 0.5796, 0.5644, 0.5808,
        0.5880, 0.5900, 0.5773, 0.5774, 0.5969, 0.5661, 0.5763],
       device='cuda:0') torch.Size([16])
percent tensor([0.5273, 0.5420, 0.4603, 0.5105, 0.4462, 0.5584, 0.5171, 0.4259, 0.5448,
        0.5369, 0.5702, 0.4928, 0.5333, 0.5710, 0.5064, 0.5488],
       device='cuda:0') torch.Size([16])
percent tensor([0.5398, 0.5364, 0.5406, 0.5406, 0.5638, 0.5591, 0.5424, 0.5597, 0.5424,
        0.5377, 0.5287, 0.5197, 0.5312, 0.5385, 0.5334, 0.5540],
       device='cuda:0') torch.Size([16])
percent tensor([0.5189, 0.5698, 0.6297, 0.6055, 0.6759, 0.6711, 0.5434, 0.6331, 0.5752,
        0.5538, 0.5605, 0.5621, 0.5518, 0.5555, 0.5478, 0.5410],
       device='cuda:0') torch.Size([16])
percent tensor([0.9929, 0.9926, 0.9929, 0.9951, 0.9915, 0.9948, 0.9896, 0.9978, 0.9957,
        0.9921, 0.9954, 0.9917, 0.9966, 0.9892, 0.9960, 0.9952],
       device='cuda:0') torch.Size([16])
Epoch: 62 | Batch_idx: 0 |  Loss: (0.3612) |  Loss2: (0.0000) | Acc: (89.00%) (115/128)
Epoch: 62 | Batch_idx: 10 |  Loss: (0.3262) |  Loss2: (0.0000) | Acc: (88.00%) (1253/1408)
Epoch: 62 | Batch_idx: 20 |  Loss: (0.3200) |  Loss2: (0.0000) | Acc: (89.00%) (2407/2688)
Epoch: 62 | Batch_idx: 30 |  Loss: (0.3151) |  Loss2: (0.0000) | Acc: (89.00%) (3551/3968)
Epoch: 62 | Batch_idx: 40 |  Loss: (0.3171) |  Loss2: (0.0000) | Acc: (89.00%) (4697/5248)
Epoch: 62 | Batch_idx: 50 |  Loss: (0.3202) |  Loss2: (0.0000) | Acc: (89.00%) (5825/6528)
Epoch: 62 | Batch_idx: 60 |  Loss: (0.3210) |  Loss2: (0.0000) | Acc: (89.00%) (6964/7808)
Epoch: 62 | Batch_idx: 70 |  Loss: (0.3190) |  Loss2: (0.0000) | Acc: (89.00%) (8114/9088)
Epoch: 62 | Batch_idx: 80 |  Loss: (0.3225) |  Loss2: (0.0000) | Acc: (89.00%) (9239/10368)
Epoch: 62 | Batch_idx: 90 |  Loss: (0.3230) |  Loss2: (0.0000) | Acc: (89.00%) (10373/11648)
Epoch: 62 | Batch_idx: 100 |  Loss: (0.3247) |  Loss2: (0.0000) | Acc: (88.00%) (11500/12928)
Epoch: 62 | Batch_idx: 110 |  Loss: (0.3244) |  Loss2: (0.0000) | Acc: (88.00%) (12641/14208)
Epoch: 62 | Batch_idx: 120 |  Loss: (0.3283) |  Loss2: (0.0000) | Acc: (88.00%) (13767/15488)
Epoch: 62 | Batch_idx: 130 |  Loss: (0.3288) |  Loss2: (0.0000) | Acc: (88.00%) (14906/16768)
Epoch: 62 | Batch_idx: 140 |  Loss: (0.3298) |  Loss2: (0.0000) | Acc: (88.00%) (16036/18048)
Epoch: 62 | Batch_idx: 150 |  Loss: (0.3293) |  Loss2: (0.0000) | Acc: (88.00%) (17178/19328)
Epoch: 62 | Batch_idx: 160 |  Loss: (0.3319) |  Loss2: (0.0000) | Acc: (88.00%) (18303/20608)
Epoch: 62 | Batch_idx: 170 |  Loss: (0.3301) |  Loss2: (0.0000) | Acc: (88.00%) (19442/21888)
Epoch: 62 | Batch_idx: 180 |  Loss: (0.3302) |  Loss2: (0.0000) | Acc: (88.00%) (20570/23168)
Epoch: 62 | Batch_idx: 190 |  Loss: (0.3298) |  Loss2: (0.0000) | Acc: (88.00%) (21700/24448)
Epoch: 62 | Batch_idx: 200 |  Loss: (0.3298) |  Loss2: (0.0000) | Acc: (88.00%) (22825/25728)
Epoch: 62 | Batch_idx: 210 |  Loss: (0.3302) |  Loss2: (0.0000) | Acc: (88.00%) (23955/27008)
Epoch: 62 | Batch_idx: 220 |  Loss: (0.3306) |  Loss2: (0.0000) | Acc: (88.00%) (25083/28288)
Epoch: 62 | Batch_idx: 230 |  Loss: (0.3313) |  Loss2: (0.0000) | Acc: (88.00%) (26201/29568)
Epoch: 62 | Batch_idx: 240 |  Loss: (0.3306) |  Loss2: (0.0000) | Acc: (88.00%) (27352/30848)
Epoch: 62 | Batch_idx: 250 |  Loss: (0.3300) |  Loss2: (0.0000) | Acc: (88.00%) (28507/32128)
Epoch: 62 | Batch_idx: 260 |  Loss: (0.3308) |  Loss2: (0.0000) | Acc: (88.00%) (29635/33408)
Epoch: 62 | Batch_idx: 270 |  Loss: (0.3308) |  Loss2: (0.0000) | Acc: (88.00%) (30769/34688)
Epoch: 62 | Batch_idx: 280 |  Loss: (0.3320) |  Loss2: (0.0000) | Acc: (88.00%) (31903/35968)
Epoch: 62 | Batch_idx: 290 |  Loss: (0.3308) |  Loss2: (0.0000) | Acc: (88.00%) (33038/37248)
Epoch: 62 | Batch_idx: 300 |  Loss: (0.3314) |  Loss2: (0.0000) | Acc: (88.00%) (34157/38528)
Epoch: 62 | Batch_idx: 310 |  Loss: (0.3327) |  Loss2: (0.0000) | Acc: (88.00%) (35262/39808)
Epoch: 62 | Batch_idx: 320 |  Loss: (0.3330) |  Loss2: (0.0000) | Acc: (88.00%) (36388/41088)
Epoch: 62 | Batch_idx: 330 |  Loss: (0.3336) |  Loss2: (0.0000) | Acc: (88.00%) (37512/42368)
Epoch: 62 | Batch_idx: 340 |  Loss: (0.3328) |  Loss2: (0.0000) | Acc: (88.00%) (38661/43648)
Epoch: 62 | Batch_idx: 350 |  Loss: (0.3322) |  Loss2: (0.0000) | Acc: (88.00%) (39792/44928)
Epoch: 62 | Batch_idx: 360 |  Loss: (0.3322) |  Loss2: (0.0000) | Acc: (88.00%) (40927/46208)
Epoch: 62 | Batch_idx: 370 |  Loss: (0.3314) |  Loss2: (0.0000) | Acc: (88.00%) (42082/47488)
Epoch: 62 | Batch_idx: 380 |  Loss: (0.3307) |  Loss2: (0.0000) | Acc: (88.00%) (43224/48768)
Epoch: 62 | Batch_idx: 390 |  Loss: (0.3318) |  Loss2: (0.0000) | Acc: (88.00%) (44294/50000)
# TEST : Loss: (0.4652) | Acc: (84.00%) (8465/10000)
percent tensor([0.4939, 0.4849, 0.4895, 0.4874, 0.4893, 0.5009, 0.4869, 0.4865, 0.4907,
        0.4861, 0.4920, 0.4863, 0.4867, 0.4894, 0.4899, 0.4916],
       device='cuda:0') torch.Size([16])
percent tensor([0.5137, 0.5058, 0.5201, 0.5205, 0.5188, 0.5144, 0.5106, 0.5222, 0.5179,
        0.5087, 0.5124, 0.5111, 0.5052, 0.5179, 0.5106, 0.5133],
       device='cuda:0') torch.Size([16])
percent tensor([0.5191, 0.5071, 0.5277, 0.5404, 0.5319, 0.5300, 0.5191, 0.5309, 0.5146,
        0.5143, 0.5116, 0.5197, 0.4979, 0.5333, 0.5181, 0.5235],
       device='cuda:0') torch.Size([16])
percent tensor([0.5662, 0.5813, 0.5654, 0.5643, 0.5609, 0.5626, 0.5781, 0.5623, 0.5807,
        0.5864, 0.5895, 0.5744, 0.5770, 0.5969, 0.5634, 0.5755],
       device='cuda:0') torch.Size([16])
percent tensor([0.5270, 0.5350, 0.4580, 0.5045, 0.4453, 0.5552, 0.5141, 0.4206, 0.5458,
        0.5354, 0.5717, 0.4933, 0.5316, 0.5659, 0.5045, 0.5461],
       device='cuda:0') torch.Size([16])
percent tensor([0.5382, 0.5328, 0.5394, 0.5396, 0.5609, 0.5550, 0.5420, 0.5588, 0.5391,
        0.5336, 0.5281, 0.5193, 0.5278, 0.5378, 0.5313, 0.5528],
       device='cuda:0') torch.Size([16])
percent tensor([0.5278, 0.5518, 0.6418, 0.6092, 0.6715, 0.6666, 0.5452, 0.6494, 0.5755,
        0.5510, 0.5680, 0.5642, 0.5447, 0.5756, 0.5478, 0.5520],
       device='cuda:0') torch.Size([16])
percent tensor([0.9942, 0.9933, 0.9926, 0.9960, 0.9909, 0.9955, 0.9910, 0.9975, 0.9960,
        0.9944, 0.9955, 0.9939, 0.9973, 0.9914, 0.9950, 0.9947],
       device='cuda:0') torch.Size([16])
False Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=128, out_features=16, bias=False)
True Linear(in_features=16, out_features=2, bias=False)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=128, out_features=16, bias=False)
True Linear(in_features=16, out_features=2, bias=False)
False Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=256, out_features=32, bias=False)
True Linear(in_features=32, out_features=2, bias=False)
False Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=256, out_features=32, bias=False)
True Linear(in_features=32, out_features=2, bias=False)
False Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=512, out_features=64, bias=False)
True Linear(in_features=64, out_features=2, bias=False)
False Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=512, out_features=64, bias=False)
True Linear(in_features=64, out_features=2, bias=False)
False Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1024, out_features=128, bias=False)
True Linear(in_features=128, out_features=2, bias=False)
False Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1024, out_features=128, bias=False)
True Linear(in_features=128, out_features=2, bias=False)
False Linear(in_features=512, out_features=10, bias=True)
Epoch: 63 | Batch_idx: 0 |  Loss: (0.3242) |  Loss2: (0.0000) | Acc: (89.00%) (115/128)
Epoch: 63 | Batch_idx: 10 |  Loss: (0.3725) |  Loss2: (0.0000) | Acc: (86.00%) (1220/1408)
Epoch: 63 | Batch_idx: 20 |  Loss: (0.3689) |  Loss2: (0.0000) | Acc: (86.00%) (2335/2688)
Epoch: 63 | Batch_idx: 30 |  Loss: (0.3732) |  Loss2: (0.0000) | Acc: (86.00%) (3446/3968)
Epoch: 63 | Batch_idx: 40 |  Loss: (0.3704) |  Loss2: (0.0000) | Acc: (86.00%) (4556/5248)
Epoch: 63 | Batch_idx: 50 |  Loss: (0.3751) |  Loss2: (0.0000) | Acc: (86.00%) (5653/6528)
Epoch: 63 | Batch_idx: 60 |  Loss: (0.3752) |  Loss2: (0.0000) | Acc: (86.00%) (6773/7808)
Epoch: 63 | Batch_idx: 70 |  Loss: (0.3828) |  Loss2: (0.0000) | Acc: (86.00%) (7870/9088)
Epoch: 63 | Batch_idx: 80 |  Loss: (0.3841) |  Loss2: (0.0000) | Acc: (86.00%) (8973/10368)
Epoch: 63 | Batch_idx: 90 |  Loss: (0.3838) |  Loss2: (0.0000) | Acc: (86.00%) (10077/11648)
Epoch: 63 | Batch_idx: 100 |  Loss: (0.3831) |  Loss2: (0.0000) | Acc: (86.00%) (11188/12928)
Epoch: 63 | Batch_idx: 110 |  Loss: (0.3818) |  Loss2: (0.0000) | Acc: (86.00%) (12313/14208)
Epoch: 63 | Batch_idx: 120 |  Loss: (0.3819) |  Loss2: (0.0000) | Acc: (86.00%) (13434/15488)
Epoch: 63 | Batch_idx: 130 |  Loss: (0.3841) |  Loss2: (0.0000) | Acc: (86.00%) (14535/16768)
Epoch: 63 | Batch_idx: 140 |  Loss: (0.3839) |  Loss2: (0.0000) | Acc: (86.00%) (15653/18048)
Epoch: 63 | Batch_idx: 150 |  Loss: (0.3835) |  Loss2: (0.0000) | Acc: (86.00%) (16771/19328)
Epoch: 63 | Batch_idx: 160 |  Loss: (0.3837) |  Loss2: (0.0000) | Acc: (86.00%) (17877/20608)
Epoch: 63 | Batch_idx: 170 |  Loss: (0.3827) |  Loss2: (0.0000) | Acc: (86.00%) (18987/21888)
Epoch: 63 | Batch_idx: 180 |  Loss: (0.3827) |  Loss2: (0.0000) | Acc: (86.00%) (20101/23168)
Epoch: 63 | Batch_idx: 190 |  Loss: (0.3828) |  Loss2: (0.0000) | Acc: (86.00%) (21209/24448)
Epoch: 63 | Batch_idx: 200 |  Loss: (0.3827) |  Loss2: (0.0000) | Acc: (86.00%) (22315/25728)
Epoch: 63 | Batch_idx: 210 |  Loss: (0.3823) |  Loss2: (0.0000) | Acc: (86.00%) (23431/27008)
Epoch: 63 | Batch_idx: 220 |  Loss: (0.3820) |  Loss2: (0.0000) | Acc: (86.00%) (24535/28288)
Epoch: 63 | Batch_idx: 230 |  Loss: (0.3798) |  Loss2: (0.0000) | Acc: (86.00%) (25679/29568)
Epoch: 63 | Batch_idx: 240 |  Loss: (0.3792) |  Loss2: (0.0000) | Acc: (86.00%) (26804/30848)
Epoch: 63 | Batch_idx: 250 |  Loss: (0.3778) |  Loss2: (0.0000) | Acc: (86.00%) (27929/32128)
Epoch: 63 | Batch_idx: 260 |  Loss: (0.3764) |  Loss2: (0.0000) | Acc: (86.00%) (29062/33408)
Epoch: 63 | Batch_idx: 270 |  Loss: (0.3766) |  Loss2: (0.0000) | Acc: (86.00%) (30175/34688)
Epoch: 63 | Batch_idx: 280 |  Loss: (0.3772) |  Loss2: (0.0000) | Acc: (86.00%) (31273/35968)
Epoch: 63 | Batch_idx: 290 |  Loss: (0.3764) |  Loss2: (0.0000) | Acc: (86.00%) (32403/37248)
Epoch: 63 | Batch_idx: 300 |  Loss: (0.3770) |  Loss2: (0.0000) | Acc: (86.00%) (33509/38528)
Epoch: 63 | Batch_idx: 310 |  Loss: (0.3760) |  Loss2: (0.0000) | Acc: (87.00%) (34636/39808)
Epoch: 63 | Batch_idx: 320 |  Loss: (0.3757) |  Loss2: (0.0000) | Acc: (87.00%) (35747/41088)
Epoch: 63 | Batch_idx: 330 |  Loss: (0.3757) |  Loss2: (0.0000) | Acc: (86.00%) (36859/42368)
Epoch: 63 | Batch_idx: 340 |  Loss: (0.3751) |  Loss2: (0.0000) | Acc: (87.00%) (37977/43648)
Epoch: 63 | Batch_idx: 350 |  Loss: (0.3741) |  Loss2: (0.0000) | Acc: (87.00%) (39096/44928)
Epoch: 63 | Batch_idx: 360 |  Loss: (0.3746) |  Loss2: (0.0000) | Acc: (86.00%) (40195/46208)
Epoch: 63 | Batch_idx: 370 |  Loss: (0.3738) |  Loss2: (0.0000) | Acc: (87.00%) (41321/47488)
Epoch: 63 | Batch_idx: 380 |  Loss: (0.3738) |  Loss2: (0.0000) | Acc: (87.00%) (42436/48768)
Epoch: 63 | Batch_idx: 390 |  Loss: (0.3736) |  Loss2: (0.0000) | Acc: (87.00%) (43511/50000)
# TEST : Loss: (0.4780) | Acc: (84.00%) (8426/10000)
percent tensor([0.5024, 0.4951, 0.5004, 0.4968, 0.5011, 0.5083, 0.4981, 0.4977, 0.5011,
        0.4973, 0.5017, 0.4983, 0.4962, 0.4991, 0.4992, 0.5004],
       device='cuda:0') torch.Size([16])
percent tensor([0.5130, 0.5053, 0.5167, 0.5184, 0.5162, 0.5145, 0.5091, 0.5190, 0.5163,
        0.5076, 0.5122, 0.5083, 0.5053, 0.5158, 0.5097, 0.5130],
       device='cuda:0') torch.Size([16])
percent tensor([0.5229, 0.5166, 0.5331, 0.5449, 0.5373, 0.5297, 0.5264, 0.5364, 0.5184,
        0.5235, 0.5170, 0.5254, 0.5043, 0.5379, 0.5217, 0.5297],
       device='cuda:0') torch.Size([16])
percent tensor([0.5916, 0.6070, 0.5886, 0.5841, 0.5838, 0.5857, 0.6036, 0.5840, 0.6035,
        0.6125, 0.6170, 0.5988, 0.6034, 0.6175, 0.5877, 0.6004],
       device='cuda:0') torch.Size([16])
percent tensor([0.5323, 0.5451, 0.4540, 0.5133, 0.4493, 0.5665, 0.5151, 0.4170, 0.5586,
        0.5417, 0.5846, 0.5024, 0.5460, 0.5814, 0.5092, 0.5542],
       device='cuda:0') torch.Size([16])
percent tensor([0.5624, 0.5583, 0.5626, 0.5665, 0.5870, 0.5801, 0.5683, 0.5896, 0.5592,
        0.5598, 0.5490, 0.5406, 0.5503, 0.5570, 0.5580, 0.5809],
       device='cuda:0') torch.Size([16])
percent tensor([0.5530, 0.5911, 0.6848, 0.6554, 0.7176, 0.6850, 0.5795, 0.6994, 0.6106,
        0.5962, 0.6035, 0.6011, 0.5795, 0.6079, 0.5695, 0.5745],
       device='cuda:0') torch.Size([16])
percent tensor([0.9934, 0.9920, 0.9926, 0.9961, 0.9904, 0.9940, 0.9895, 0.9976, 0.9962,
        0.9939, 0.9965, 0.9940, 0.9962, 0.9914, 0.9946, 0.9937],
       device='cuda:0') torch.Size([16])
Epoch: 64 | Batch_idx: 0 |  Loss: (0.2993) |  Loss2: (0.0000) | Acc: (89.00%) (114/128)
Epoch: 64 | Batch_idx: 10 |  Loss: (0.3577) |  Loss2: (0.0000) | Acc: (87.00%) (1230/1408)
Epoch: 64 | Batch_idx: 20 |  Loss: (0.3452) |  Loss2: (0.0000) | Acc: (88.00%) (2366/2688)
Epoch: 64 | Batch_idx: 30 |  Loss: (0.3370) |  Loss2: (0.0000) | Acc: (88.00%) (3516/3968)
Epoch: 64 | Batch_idx: 40 |  Loss: (0.3467) |  Loss2: (0.0000) | Acc: (88.00%) (4619/5248)
Epoch: 64 | Batch_idx: 50 |  Loss: (0.3471) |  Loss2: (0.0000) | Acc: (87.00%) (5738/6528)
Epoch: 64 | Batch_idx: 60 |  Loss: (0.3486) |  Loss2: (0.0000) | Acc: (87.00%) (6854/7808)
Epoch: 64 | Batch_idx: 70 |  Loss: (0.3494) |  Loss2: (0.0000) | Acc: (87.00%) (7976/9088)
Epoch: 64 | Batch_idx: 80 |  Loss: (0.3523) |  Loss2: (0.0000) | Acc: (87.00%) (9085/10368)
Epoch: 64 | Batch_idx: 90 |  Loss: (0.3501) |  Loss2: (0.0000) | Acc: (87.00%) (10204/11648)
Epoch: 64 | Batch_idx: 100 |  Loss: (0.3505) |  Loss2: (0.0000) | Acc: (87.00%) (11321/12928)
Epoch: 64 | Batch_idx: 110 |  Loss: (0.3514) |  Loss2: (0.0000) | Acc: (87.00%) (12452/14208)
Epoch: 64 | Batch_idx: 120 |  Loss: (0.3495) |  Loss2: (0.0000) | Acc: (87.00%) (13590/15488)
Epoch: 64 | Batch_idx: 130 |  Loss: (0.3474) |  Loss2: (0.0000) | Acc: (87.00%) (14728/16768)
Epoch: 64 | Batch_idx: 140 |  Loss: (0.3457) |  Loss2: (0.0000) | Acc: (87.00%) (15869/18048)
Epoch: 64 | Batch_idx: 150 |  Loss: (0.3486) |  Loss2: (0.0000) | Acc: (87.00%) (16976/19328)
Epoch: 64 | Batch_idx: 160 |  Loss: (0.3501) |  Loss2: (0.0000) | Acc: (87.00%) (18095/20608)
Epoch: 64 | Batch_idx: 170 |  Loss: (0.3504) |  Loss2: (0.0000) | Acc: (87.00%) (19227/21888)
Epoch: 64 | Batch_idx: 180 |  Loss: (0.3491) |  Loss2: (0.0000) | Acc: (87.00%) (20364/23168)
Epoch: 64 | Batch_idx: 190 |  Loss: (0.3492) |  Loss2: (0.0000) | Acc: (87.00%) (21492/24448)
Epoch: 64 | Batch_idx: 200 |  Loss: (0.3478) |  Loss2: (0.0000) | Acc: (87.00%) (22627/25728)
Epoch: 64 | Batch_idx: 210 |  Loss: (0.3477) |  Loss2: (0.0000) | Acc: (87.00%) (23748/27008)
Epoch: 64 | Batch_idx: 220 |  Loss: (0.3462) |  Loss2: (0.0000) | Acc: (87.00%) (24891/28288)
Epoch: 64 | Batch_idx: 230 |  Loss: (0.3464) |  Loss2: (0.0000) | Acc: (87.00%) (26012/29568)
Epoch: 64 | Batch_idx: 240 |  Loss: (0.3464) |  Loss2: (0.0000) | Acc: (87.00%) (27136/30848)
Epoch: 64 | Batch_idx: 250 |  Loss: (0.3462) |  Loss2: (0.0000) | Acc: (87.00%) (28259/32128)
Epoch: 64 | Batch_idx: 260 |  Loss: (0.3474) |  Loss2: (0.0000) | Acc: (87.00%) (29368/33408)
Epoch: 64 | Batch_idx: 270 |  Loss: (0.3470) |  Loss2: (0.0000) | Acc: (87.00%) (30488/34688)
Epoch: 64 | Batch_idx: 280 |  Loss: (0.3470) |  Loss2: (0.0000) | Acc: (87.00%) (31610/35968)
Epoch: 64 | Batch_idx: 290 |  Loss: (0.3459) |  Loss2: (0.0000) | Acc: (87.00%) (32758/37248)
Epoch: 64 | Batch_idx: 300 |  Loss: (0.3455) |  Loss2: (0.0000) | Acc: (87.00%) (33890/38528)
Epoch: 64 | Batch_idx: 310 |  Loss: (0.3444) |  Loss2: (0.0000) | Acc: (88.00%) (35040/39808)
Epoch: 64 | Batch_idx: 320 |  Loss: (0.3449) |  Loss2: (0.0000) | Acc: (88.00%) (36165/41088)
Epoch: 64 | Batch_idx: 330 |  Loss: (0.3442) |  Loss2: (0.0000) | Acc: (88.00%) (37303/42368)
Epoch: 64 | Batch_idx: 340 |  Loss: (0.3445) |  Loss2: (0.0000) | Acc: (88.00%) (38419/43648)
Epoch: 64 | Batch_idx: 350 |  Loss: (0.3437) |  Loss2: (0.0000) | Acc: (88.00%) (39550/44928)
Epoch: 64 | Batch_idx: 360 |  Loss: (0.3439) |  Loss2: (0.0000) | Acc: (88.00%) (40675/46208)
Epoch: 64 | Batch_idx: 370 |  Loss: (0.3455) |  Loss2: (0.0000) | Acc: (87.00%) (41778/47488)
Epoch: 64 | Batch_idx: 380 |  Loss: (0.3461) |  Loss2: (0.0000) | Acc: (87.00%) (42906/48768)
Epoch: 64 | Batch_idx: 390 |  Loss: (0.3459) |  Loss2: (0.0000) | Acc: (88.00%) (44001/50000)
# TEST : Loss: (0.4577) | Acc: (84.00%) (8496/10000)
percent tensor([0.5051, 0.4979, 0.5036, 0.4993, 0.5047, 0.5107, 0.5013, 0.5008, 0.5041,
        0.5004, 0.5047, 0.5019, 0.4989, 0.5019, 0.5018, 0.5031],
       device='cuda:0') torch.Size([16])
percent tensor([0.5113, 0.5042, 0.5153, 0.5166, 0.5148, 0.5131, 0.5077, 0.5173, 0.5146,
        0.5063, 0.5107, 0.5068, 0.5040, 0.5145, 0.5083, 0.5116],
       device='cuda:0') torch.Size([16])
percent tensor([0.5197, 0.5167, 0.5324, 0.5436, 0.5381, 0.5225, 0.5259, 0.5394, 0.5177,
        0.5227, 0.5143, 0.5240, 0.5028, 0.5383, 0.5182, 0.5274],
       device='cuda:0') torch.Size([16])
percent tensor([0.5959, 0.6118, 0.5911, 0.5882, 0.5866, 0.5900, 0.6081, 0.5879, 0.6071,
        0.6165, 0.6211, 0.6027, 0.6074, 0.6222, 0.5929, 0.6049],
       device='cuda:0') torch.Size([16])
percent tensor([0.5348, 0.5506, 0.4472, 0.5211, 0.4486, 0.5758, 0.5143, 0.4083, 0.5668,
        0.5438, 0.5914, 0.5024, 0.5521, 0.5908, 0.5155, 0.5582],
       device='cuda:0') torch.Size([16])
percent tensor([0.5810, 0.5781, 0.5807, 0.5851, 0.6080, 0.5984, 0.5887, 0.6136, 0.5770,
        0.5781, 0.5651, 0.5564, 0.5687, 0.5737, 0.5772, 0.6014],
       device='cuda:0') torch.Size([16])
percent tensor([0.5516, 0.6013, 0.7018, 0.6693, 0.7408, 0.6913, 0.5899, 0.7231, 0.6172,
        0.6013, 0.6069, 0.6124, 0.5839, 0.6110, 0.5785, 0.5766],
       device='cuda:0') torch.Size([16])
percent tensor([0.9939, 0.9927, 0.9940, 0.9963, 0.9919, 0.9934, 0.9901, 0.9980, 0.9965,
        0.9946, 0.9967, 0.9947, 0.9967, 0.9917, 0.9951, 0.9940],
       device='cuda:0') torch.Size([16])
Epoch: 65 | Batch_idx: 0 |  Loss: (0.2926) |  Loss2: (0.0000) | Acc: (92.00%) (119/128)
Epoch: 65 | Batch_idx: 10 |  Loss: (0.2967) |  Loss2: (0.0000) | Acc: (90.00%) (1276/1408)
Epoch: 65 | Batch_idx: 20 |  Loss: (0.3105) |  Loss2: (0.0000) | Acc: (89.00%) (2403/2688)
Epoch: 65 | Batch_idx: 30 |  Loss: (0.3334) |  Loss2: (0.0000) | Acc: (88.00%) (3519/3968)
Epoch: 65 | Batch_idx: 40 |  Loss: (0.3404) |  Loss2: (0.0000) | Acc: (88.00%) (4625/5248)
Epoch: 65 | Batch_idx: 50 |  Loss: (0.3404) |  Loss2: (0.0000) | Acc: (87.00%) (5741/6528)
Epoch: 65 | Batch_idx: 60 |  Loss: (0.3404) |  Loss2: (0.0000) | Acc: (88.00%) (6879/7808)
Epoch: 65 | Batch_idx: 70 |  Loss: (0.3366) |  Loss2: (0.0000) | Acc: (88.00%) (8015/9088)
Epoch: 65 | Batch_idx: 80 |  Loss: (0.3356) |  Loss2: (0.0000) | Acc: (88.00%) (9140/10368)
Epoch: 65 | Batch_idx: 90 |  Loss: (0.3343) |  Loss2: (0.0000) | Acc: (88.00%) (10278/11648)
Epoch: 65 | Batch_idx: 100 |  Loss: (0.3372) |  Loss2: (0.0000) | Acc: (88.00%) (11394/12928)
Epoch: 65 | Batch_idx: 110 |  Loss: (0.3383) |  Loss2: (0.0000) | Acc: (88.00%) (12515/14208)
Epoch: 65 | Batch_idx: 120 |  Loss: (0.3380) |  Loss2: (0.0000) | Acc: (88.00%) (13641/15488)
Epoch: 65 | Batch_idx: 130 |  Loss: (0.3404) |  Loss2: (0.0000) | Acc: (88.00%) (14760/16768)
Epoch: 65 | Batch_idx: 140 |  Loss: (0.3397) |  Loss2: (0.0000) | Acc: (88.00%) (15903/18048)
Epoch: 65 | Batch_idx: 150 |  Loss: (0.3400) |  Loss2: (0.0000) | Acc: (88.00%) (17044/19328)
Epoch: 65 | Batch_idx: 160 |  Loss: (0.3393) |  Loss2: (0.0000) | Acc: (88.00%) (18177/20608)
Epoch: 65 | Batch_idx: 170 |  Loss: (0.3382) |  Loss2: (0.0000) | Acc: (88.00%) (19316/21888)
Epoch: 65 | Batch_idx: 180 |  Loss: (0.3388) |  Loss2: (0.0000) | Acc: (88.00%) (20445/23168)
Epoch: 65 | Batch_idx: 190 |  Loss: (0.3381) |  Loss2: (0.0000) | Acc: (88.00%) (21581/24448)
Epoch: 65 | Batch_idx: 200 |  Loss: (0.3387) |  Loss2: (0.0000) | Acc: (88.00%) (22705/25728)
Epoch: 65 | Batch_idx: 210 |  Loss: (0.3385) |  Loss2: (0.0000) | Acc: (88.00%) (23839/27008)
Epoch: 65 | Batch_idx: 220 |  Loss: (0.3373) |  Loss2: (0.0000) | Acc: (88.00%) (24978/28288)
Epoch: 65 | Batch_idx: 230 |  Loss: (0.3368) |  Loss2: (0.0000) | Acc: (88.00%) (26121/29568)
Epoch: 65 | Batch_idx: 240 |  Loss: (0.3358) |  Loss2: (0.0000) | Acc: (88.00%) (27259/30848)
Epoch: 65 | Batch_idx: 250 |  Loss: (0.3363) |  Loss2: (0.0000) | Acc: (88.00%) (28376/32128)
Epoch: 65 | Batch_idx: 260 |  Loss: (0.3356) |  Loss2: (0.0000) | Acc: (88.00%) (29518/33408)
Epoch: 65 | Batch_idx: 270 |  Loss: (0.3362) |  Loss2: (0.0000) | Acc: (88.00%) (30645/34688)
Epoch: 65 | Batch_idx: 280 |  Loss: (0.3357) |  Loss2: (0.0000) | Acc: (88.00%) (31790/35968)
Epoch: 65 | Batch_idx: 290 |  Loss: (0.3353) |  Loss2: (0.0000) | Acc: (88.00%) (32918/37248)
Epoch: 65 | Batch_idx: 300 |  Loss: (0.3347) |  Loss2: (0.0000) | Acc: (88.00%) (34057/38528)
Epoch: 65 | Batch_idx: 310 |  Loss: (0.3346) |  Loss2: (0.0000) | Acc: (88.00%) (35193/39808)
Epoch: 65 | Batch_idx: 320 |  Loss: (0.3353) |  Loss2: (0.0000) | Acc: (88.00%) (36312/41088)
Epoch: 65 | Batch_idx: 330 |  Loss: (0.3354) |  Loss2: (0.0000) | Acc: (88.00%) (37439/42368)
Epoch: 65 | Batch_idx: 340 |  Loss: (0.3352) |  Loss2: (0.0000) | Acc: (88.00%) (38589/43648)
Epoch: 65 | Batch_idx: 350 |  Loss: (0.3348) |  Loss2: (0.0000) | Acc: (88.00%) (39723/44928)
Epoch: 65 | Batch_idx: 360 |  Loss: (0.3339) |  Loss2: (0.0000) | Acc: (88.00%) (40869/46208)
Epoch: 65 | Batch_idx: 370 |  Loss: (0.3336) |  Loss2: (0.0000) | Acc: (88.00%) (42005/47488)
Epoch: 65 | Batch_idx: 380 |  Loss: (0.3325) |  Loss2: (0.0000) | Acc: (88.00%) (43159/48768)
Epoch: 65 | Batch_idx: 390 |  Loss: (0.3320) |  Loss2: (0.0000) | Acc: (88.00%) (44248/50000)
=> saving checkpoint 'drive/app/torch/save_Schedule/checkpoint_065.pth.tar'
# TEST : Loss: (0.4451) | Acc: (85.00%) (8523/10000)
percent tensor([0.5065, 0.4991, 0.5054, 0.5006, 0.5066, 0.5120, 0.5030, 0.5022, 0.5057,
        0.5020, 0.5062, 0.5038, 0.5002, 0.5033, 0.5031, 0.5044],
       device='cuda:0') torch.Size([16])
percent tensor([0.5117, 0.5047, 0.5154, 0.5166, 0.5150, 0.5133, 0.5081, 0.5175, 0.5151,
        0.5067, 0.5113, 0.5070, 0.5044, 0.5152, 0.5086, 0.5119],
       device='cuda:0') torch.Size([16])
percent tensor([0.5202, 0.5199, 0.5345, 0.5454, 0.5413, 0.5192, 0.5287, 0.5440, 0.5203,
        0.5254, 0.5158, 0.5257, 0.5036, 0.5432, 0.5180, 0.5286],
       device='cuda:0') torch.Size([16])
percent tensor([0.5992, 0.6153, 0.5931, 0.5909, 0.5888, 0.5936, 0.6112, 0.5904, 0.6098,
        0.6195, 0.6245, 0.6055, 0.6107, 0.6252, 0.5967, 0.6085],
       device='cuda:0') torch.Size([16])
percent tensor([0.5440, 0.5619, 0.4502, 0.5328, 0.4575, 0.5865, 0.5238, 0.4124, 0.5793,
        0.5551, 0.6067, 0.5112, 0.5635, 0.6033, 0.5309, 0.5677],
       device='cuda:0') torch.Size([16])
percent tensor([0.5842, 0.5811, 0.5852, 0.5892, 0.6141, 0.6030, 0.5928, 0.6196, 0.5801,
        0.5808, 0.5663, 0.5582, 0.5709, 0.5756, 0.5801, 0.6059],
       device='cuda:0') torch.Size([16])
percent tensor([0.5347, 0.5830, 0.6976, 0.6645, 0.7427, 0.6870, 0.5743, 0.7133, 0.6055,
        0.5831, 0.5911, 0.6018, 0.5686, 0.5967, 0.5598, 0.5607],
       device='cuda:0') torch.Size([16])
percent tensor([0.9949, 0.9934, 0.9946, 0.9964, 0.9925, 0.9938, 0.9916, 0.9981, 0.9969,
        0.9950, 0.9972, 0.9950, 0.9970, 0.9927, 0.9954, 0.9950],
       device='cuda:0') torch.Size([16])
Epoch: 66 | Batch_idx: 0 |  Loss: (0.3459) |  Loss2: (0.0000) | Acc: (86.00%) (111/128)
Epoch: 66 | Batch_idx: 10 |  Loss: (0.2893) |  Loss2: (0.0000) | Acc: (89.00%) (1264/1408)
Epoch: 66 | Batch_idx: 20 |  Loss: (0.3182) |  Loss2: (0.0000) | Acc: (88.00%) (2386/2688)
Epoch: 66 | Batch_idx: 30 |  Loss: (0.3134) |  Loss2: (0.0000) | Acc: (89.00%) (3535/3968)
Epoch: 66 | Batch_idx: 40 |  Loss: (0.3155) |  Loss2: (0.0000) | Acc: (88.00%) (4665/5248)
Epoch: 66 | Batch_idx: 50 |  Loss: (0.3178) |  Loss2: (0.0000) | Acc: (88.00%) (5804/6528)
Epoch: 66 | Batch_idx: 60 |  Loss: (0.3256) |  Loss2: (0.0000) | Acc: (88.00%) (6914/7808)
Epoch: 66 | Batch_idx: 70 |  Loss: (0.3281) |  Loss2: (0.0000) | Acc: (88.00%) (8031/9088)
Epoch: 66 | Batch_idx: 80 |  Loss: (0.3299) |  Loss2: (0.0000) | Acc: (88.00%) (9147/10368)
Epoch: 66 | Batch_idx: 90 |  Loss: (0.3309) |  Loss2: (0.0000) | Acc: (88.00%) (10274/11648)
Epoch: 66 | Batch_idx: 100 |  Loss: (0.3321) |  Loss2: (0.0000) | Acc: (88.00%) (11392/12928)
Epoch: 66 | Batch_idx: 110 |  Loss: (0.3306) |  Loss2: (0.0000) | Acc: (88.00%) (12532/14208)
Epoch: 66 | Batch_idx: 120 |  Loss: (0.3300) |  Loss2: (0.0000) | Acc: (88.00%) (13676/15488)
Epoch: 66 | Batch_idx: 130 |  Loss: (0.3299) |  Loss2: (0.0000) | Acc: (88.00%) (14821/16768)
Epoch: 66 | Batch_idx: 140 |  Loss: (0.3287) |  Loss2: (0.0000) | Acc: (88.00%) (15957/18048)
Epoch: 66 | Batch_idx: 150 |  Loss: (0.3292) |  Loss2: (0.0000) | Acc: (88.00%) (17080/19328)
Epoch: 66 | Batch_idx: 160 |  Loss: (0.3318) |  Loss2: (0.0000) | Acc: (88.00%) (18202/20608)
Epoch: 66 | Batch_idx: 170 |  Loss: (0.3337) |  Loss2: (0.0000) | Acc: (88.00%) (19321/21888)
Epoch: 66 | Batch_idx: 180 |  Loss: (0.3342) |  Loss2: (0.0000) | Acc: (88.00%) (20447/23168)
Epoch: 66 | Batch_idx: 190 |  Loss: (0.3337) |  Loss2: (0.0000) | Acc: (88.00%) (21598/24448)
Epoch: 66 | Batch_idx: 200 |  Loss: (0.3330) |  Loss2: (0.0000) | Acc: (88.00%) (22740/25728)
Epoch: 66 | Batch_idx: 210 |  Loss: (0.3330) |  Loss2: (0.0000) | Acc: (88.00%) (23864/27008)
Epoch: 66 | Batch_idx: 220 |  Loss: (0.3316) |  Loss2: (0.0000) | Acc: (88.00%) (25005/28288)
Epoch: 66 | Batch_idx: 230 |  Loss: (0.3321) |  Loss2: (0.0000) | Acc: (88.00%) (26142/29568)
Epoch: 66 | Batch_idx: 240 |  Loss: (0.3318) |  Loss2: (0.0000) | Acc: (88.00%) (27284/30848)
Epoch: 66 | Batch_idx: 250 |  Loss: (0.3317) |  Loss2: (0.0000) | Acc: (88.00%) (28417/32128)
Epoch: 66 | Batch_idx: 260 |  Loss: (0.3306) |  Loss2: (0.0000) | Acc: (88.00%) (29562/33408)
Epoch: 66 | Batch_idx: 270 |  Loss: (0.3298) |  Loss2: (0.0000) | Acc: (88.00%) (30711/34688)
Epoch: 66 | Batch_idx: 280 |  Loss: (0.3292) |  Loss2: (0.0000) | Acc: (88.00%) (31853/35968)
Epoch: 66 | Batch_idx: 290 |  Loss: (0.3293) |  Loss2: (0.0000) | Acc: (88.00%) (32985/37248)
Epoch: 66 | Batch_idx: 300 |  Loss: (0.3284) |  Loss2: (0.0000) | Acc: (88.00%) (34139/38528)
Epoch: 66 | Batch_idx: 310 |  Loss: (0.3279) |  Loss2: (0.0000) | Acc: (88.00%) (35289/39808)
Epoch: 66 | Batch_idx: 320 |  Loss: (0.3271) |  Loss2: (0.0000) | Acc: (88.00%) (36437/41088)
Epoch: 66 | Batch_idx: 330 |  Loss: (0.3259) |  Loss2: (0.0000) | Acc: (88.00%) (37588/42368)
Epoch: 66 | Batch_idx: 340 |  Loss: (0.3254) |  Loss2: (0.0000) | Acc: (88.00%) (38732/43648)
Epoch: 66 | Batch_idx: 350 |  Loss: (0.3242) |  Loss2: (0.0000) | Acc: (88.00%) (39894/44928)
Epoch: 66 | Batch_idx: 360 |  Loss: (0.3238) |  Loss2: (0.0000) | Acc: (88.00%) (41045/46208)
Epoch: 66 | Batch_idx: 370 |  Loss: (0.3237) |  Loss2: (0.0000) | Acc: (88.00%) (42180/47488)
Epoch: 66 | Batch_idx: 380 |  Loss: (0.3242) |  Loss2: (0.0000) | Acc: (88.00%) (43313/48768)
Epoch: 66 | Batch_idx: 390 |  Loss: (0.3240) |  Loss2: (0.0000) | Acc: (88.00%) (44404/50000)
# TEST : Loss: (0.4377) | Acc: (85.00%) (8541/10000)
percent tensor([0.5072, 0.4995, 0.5062, 0.5010, 0.5074, 0.5129, 0.5037, 0.5028, 0.5064,
        0.5025, 0.5069, 0.5046, 0.5006, 0.5040, 0.5036, 0.5050],
       device='cuda:0') torch.Size([16])
percent tensor([0.5121, 0.5053, 0.5160, 0.5171, 0.5156, 0.5137, 0.5086, 0.5182, 0.5157,
        0.5072, 0.5118, 0.5074, 0.5048, 0.5160, 0.5090, 0.5125],
       device='cuda:0') torch.Size([16])
percent tensor([0.5182, 0.5178, 0.5332, 0.5449, 0.5399, 0.5156, 0.5262, 0.5436, 0.5192,
        0.5226, 0.5133, 0.5233, 0.5009, 0.5437, 0.5143, 0.5267],
       device='cuda:0') torch.Size([16])
percent tensor([0.6003, 0.6159, 0.5933, 0.5913, 0.5891, 0.5948, 0.6117, 0.5913, 0.6101,
        0.6198, 0.6251, 0.6059, 0.6112, 0.6257, 0.5975, 0.6097],
       device='cuda:0') torch.Size([16])
percent tensor([0.5368, 0.5579, 0.4392, 0.5221, 0.4447, 0.5809, 0.5099, 0.3952, 0.5761,
        0.5507, 0.6060, 0.5014, 0.5588, 0.6019, 0.5203, 0.5589],
       device='cuda:0') torch.Size([16])
percent tensor([0.5875, 0.5850, 0.5889, 0.5928, 0.6189, 0.6070, 0.5962, 0.6251, 0.5834,
        0.5837, 0.5679, 0.5599, 0.5732, 0.5780, 0.5828, 0.6094],
       device='cuda:0') torch.Size([16])
percent tensor([0.5246, 0.5811, 0.7019, 0.6661, 0.7502, 0.6894, 0.5698, 0.7186, 0.6000,
        0.5777, 0.5837, 0.5995, 0.5625, 0.5898, 0.5570, 0.5531],
       device='cuda:0') torch.Size([16])
percent tensor([0.9954, 0.9942, 0.9954, 0.9968, 0.9936, 0.9942, 0.9924, 0.9985, 0.9972,
        0.9955, 0.9974, 0.9957, 0.9973, 0.9933, 0.9960, 0.9955],
       device='cuda:0') torch.Size([16])
Epoch: 67 | Batch_idx: 0 |  Loss: (0.3179) |  Loss2: (0.0000) | Acc: (85.00%) (110/128)
Epoch: 67 | Batch_idx: 10 |  Loss: (0.3131) |  Loss2: (0.0000) | Acc: (89.00%) (1266/1408)
Epoch: 67 | Batch_idx: 20 |  Loss: (0.2978) |  Loss2: (0.0000) | Acc: (90.00%) (2426/2688)
Epoch: 67 | Batch_idx: 30 |  Loss: (0.3161) |  Loss2: (0.0000) | Acc: (89.00%) (3553/3968)
Epoch: 67 | Batch_idx: 40 |  Loss: (0.3139) |  Loss2: (0.0000) | Acc: (89.00%) (4694/5248)
Epoch: 67 | Batch_idx: 50 |  Loss: (0.3151) |  Loss2: (0.0000) | Acc: (89.00%) (5844/6528)
Epoch: 67 | Batch_idx: 60 |  Loss: (0.3177) |  Loss2: (0.0000) | Acc: (89.00%) (6977/7808)
Epoch: 67 | Batch_idx: 70 |  Loss: (0.3143) |  Loss2: (0.0000) | Acc: (89.00%) (8136/9088)
Epoch: 67 | Batch_idx: 80 |  Loss: (0.3141) |  Loss2: (0.0000) | Acc: (89.00%) (9288/10368)
Epoch: 67 | Batch_idx: 90 |  Loss: (0.3169) |  Loss2: (0.0000) | Acc: (89.00%) (10421/11648)
Epoch: 67 | Batch_idx: 100 |  Loss: (0.3202) |  Loss2: (0.0000) | Acc: (89.00%) (11539/12928)
Epoch: 67 | Batch_idx: 110 |  Loss: (0.3221) |  Loss2: (0.0000) | Acc: (89.00%) (12661/14208)
Epoch: 67 | Batch_idx: 120 |  Loss: (0.3264) |  Loss2: (0.0000) | Acc: (88.00%) (13764/15488)
Epoch: 67 | Batch_idx: 130 |  Loss: (0.3280) |  Loss2: (0.0000) | Acc: (88.00%) (14887/16768)
Epoch: 67 | Batch_idx: 140 |  Loss: (0.3269) |  Loss2: (0.0000) | Acc: (88.00%) (16025/18048)
Epoch: 67 | Batch_idx: 150 |  Loss: (0.3270) |  Loss2: (0.0000) | Acc: (88.00%) (17154/19328)
Epoch: 67 | Batch_idx: 160 |  Loss: (0.3257) |  Loss2: (0.0000) | Acc: (88.00%) (18272/20608)
Epoch: 67 | Batch_idx: 170 |  Loss: (0.3246) |  Loss2: (0.0000) | Acc: (88.00%) (19427/21888)
Epoch: 67 | Batch_idx: 180 |  Loss: (0.3240) |  Loss2: (0.0000) | Acc: (88.00%) (20565/23168)
Epoch: 67 | Batch_idx: 190 |  Loss: (0.3232) |  Loss2: (0.0000) | Acc: (88.00%) (21704/24448)
Epoch: 67 | Batch_idx: 200 |  Loss: (0.3217) |  Loss2: (0.0000) | Acc: (88.00%) (22856/25728)
Epoch: 67 | Batch_idx: 210 |  Loss: (0.3226) |  Loss2: (0.0000) | Acc: (88.00%) (23975/27008)
Epoch: 67 | Batch_idx: 220 |  Loss: (0.3225) |  Loss2: (0.0000) | Acc: (88.00%) (25124/28288)
Epoch: 67 | Batch_idx: 230 |  Loss: (0.3222) |  Loss2: (0.0000) | Acc: (88.00%) (26267/29568)
Epoch: 67 | Batch_idx: 240 |  Loss: (0.3207) |  Loss2: (0.0000) | Acc: (88.00%) (27422/30848)
Epoch: 67 | Batch_idx: 250 |  Loss: (0.3207) |  Loss2: (0.0000) | Acc: (88.00%) (28549/32128)
Epoch: 67 | Batch_idx: 260 |  Loss: (0.3197) |  Loss2: (0.0000) | Acc: (88.00%) (29702/33408)
Epoch: 67 | Batch_idx: 270 |  Loss: (0.3194) |  Loss2: (0.0000) | Acc: (88.00%) (30848/34688)
Epoch: 67 | Batch_idx: 280 |  Loss: (0.3193) |  Loss2: (0.0000) | Acc: (88.00%) (31982/35968)
Epoch: 67 | Batch_idx: 290 |  Loss: (0.3201) |  Loss2: (0.0000) | Acc: (88.00%) (33111/37248)
Epoch: 67 | Batch_idx: 300 |  Loss: (0.3201) |  Loss2: (0.0000) | Acc: (88.00%) (34256/38528)
Epoch: 67 | Batch_idx: 310 |  Loss: (0.3202) |  Loss2: (0.0000) | Acc: (88.00%) (35397/39808)
Epoch: 67 | Batch_idx: 320 |  Loss: (0.3199) |  Loss2: (0.0000) | Acc: (88.00%) (36543/41088)
Epoch: 67 | Batch_idx: 330 |  Loss: (0.3200) |  Loss2: (0.0000) | Acc: (88.00%) (37680/42368)
Epoch: 67 | Batch_idx: 340 |  Loss: (0.3196) |  Loss2: (0.0000) | Acc: (88.00%) (38814/43648)
Epoch: 67 | Batch_idx: 350 |  Loss: (0.3197) |  Loss2: (0.0000) | Acc: (88.00%) (39960/44928)
Epoch: 67 | Batch_idx: 360 |  Loss: (0.3203) |  Loss2: (0.0000) | Acc: (88.00%) (41085/46208)
Epoch: 67 | Batch_idx: 370 |  Loss: (0.3215) |  Loss2: (0.0000) | Acc: (88.00%) (42205/47488)
Epoch: 67 | Batch_idx: 380 |  Loss: (0.3215) |  Loss2: (0.0000) | Acc: (88.00%) (43341/48768)
Epoch: 67 | Batch_idx: 390 |  Loss: (0.3211) |  Loss2: (0.0000) | Acc: (88.00%) (44445/50000)
# TEST : Loss: (0.4293) | Acc: (85.00%) (8559/10000)
percent tensor([0.5074, 0.4994, 0.5065, 0.5010, 0.5077, 0.5133, 0.5037, 0.5027, 0.5066,
        0.5025, 0.5071, 0.5047, 0.5006, 0.5039, 0.5036, 0.5051],
       device='cuda:0') torch.Size([16])
percent tensor([0.5123, 0.5056, 0.5162, 0.5174, 0.5158, 0.5138, 0.5089, 0.5185, 0.5161,
        0.5076, 0.5122, 0.5077, 0.5051, 0.5165, 0.5092, 0.5128],
       device='cuda:0') torch.Size([16])
percent tensor([0.5193, 0.5205, 0.5355, 0.5471, 0.5429, 0.5149, 0.5288, 0.5472, 0.5216,
        0.5249, 0.5149, 0.5252, 0.5017, 0.5482, 0.5150, 0.5282],
       device='cuda:0') torch.Size([16])
percent tensor([0.6001, 0.6157, 0.5928, 0.5914, 0.5885, 0.5950, 0.6111, 0.5911, 0.6095,
        0.6190, 0.6245, 0.6051, 0.6109, 0.6252, 0.5975, 0.6095],
       device='cuda:0') torch.Size([16])
percent tensor([0.5359, 0.5598, 0.4338, 0.5180, 0.4407, 0.5780, 0.5070, 0.3863, 0.5795,
        0.5547, 0.6123, 0.4984, 0.5595, 0.6068, 0.5170, 0.5573],
       device='cuda:0') torch.Size([16])
percent tensor([0.5877, 0.5839, 0.5898, 0.5934, 0.6205, 0.6078, 0.5963, 0.6263, 0.5836,
        0.5829, 0.5665, 0.5595, 0.5718, 0.5773, 0.5820, 0.6096],
       device='cuda:0') torch.Size([16])
percent tensor([0.5248, 0.5783, 0.7128, 0.6757, 0.7618, 0.6961, 0.5722, 0.7267, 0.6035,
        0.5779, 0.5851, 0.6088, 0.5617, 0.5905, 0.5561, 0.5534],
       device='cuda:0') torch.Size([16])
percent tensor([0.9961, 0.9951, 0.9960, 0.9972, 0.9943, 0.9950, 0.9934, 0.9986, 0.9976,
        0.9962, 0.9978, 0.9964, 0.9977, 0.9944, 0.9966, 0.9962],
       device='cuda:0') torch.Size([16])
Epoch: 68 | Batch_idx: 0 |  Loss: (0.3227) |  Loss2: (0.0000) | Acc: (87.00%) (112/128)
Epoch: 68 | Batch_idx: 10 |  Loss: (0.3039) |  Loss2: (0.0000) | Acc: (90.00%) (1268/1408)
Epoch: 68 | Batch_idx: 20 |  Loss: (0.3080) |  Loss2: (0.0000) | Acc: (89.00%) (2414/2688)
Epoch: 68 | Batch_idx: 30 |  Loss: (0.3042) |  Loss2: (0.0000) | Acc: (89.00%) (3560/3968)
Epoch: 68 | Batch_idx: 40 |  Loss: (0.3033) |  Loss2: (0.0000) | Acc: (89.00%) (4709/5248)
Epoch: 68 | Batch_idx: 50 |  Loss: (0.3039) |  Loss2: (0.0000) | Acc: (89.00%) (5850/6528)
Epoch: 68 | Batch_idx: 60 |  Loss: (0.3068) |  Loss2: (0.0000) | Acc: (89.00%) (6987/7808)
Epoch: 68 | Batch_idx: 70 |  Loss: (0.3086) |  Loss2: (0.0000) | Acc: (89.00%) (8122/9088)
Epoch: 68 | Batch_idx: 80 |  Loss: (0.3026) |  Loss2: (0.0000) | Acc: (89.00%) (9299/10368)
Epoch: 68 | Batch_idx: 90 |  Loss: (0.3071) |  Loss2: (0.0000) | Acc: (89.00%) (10435/11648)
Epoch: 68 | Batch_idx: 100 |  Loss: (0.3119) |  Loss2: (0.0000) | Acc: (89.00%) (11567/12928)
Epoch: 68 | Batch_idx: 110 |  Loss: (0.3110) |  Loss2: (0.0000) | Acc: (89.00%) (12719/14208)
Epoch: 68 | Batch_idx: 120 |  Loss: (0.3118) |  Loss2: (0.0000) | Acc: (89.00%) (13866/15488)
Epoch: 68 | Batch_idx: 130 |  Loss: (0.3119) |  Loss2: (0.0000) | Acc: (89.00%) (15000/16768)
Epoch: 68 | Batch_idx: 140 |  Loss: (0.3122) |  Loss2: (0.0000) | Acc: (89.00%) (16145/18048)
Epoch: 68 | Batch_idx: 150 |  Loss: (0.3127) |  Loss2: (0.0000) | Acc: (89.00%) (17288/19328)
Epoch: 68 | Batch_idx: 160 |  Loss: (0.3108) |  Loss2: (0.0000) | Acc: (89.00%) (18445/20608)
Epoch: 68 | Batch_idx: 170 |  Loss: (0.3109) |  Loss2: (0.0000) | Acc: (89.00%) (19586/21888)
Epoch: 68 | Batch_idx: 180 |  Loss: (0.3104) |  Loss2: (0.0000) | Acc: (89.00%) (20736/23168)
Epoch: 68 | Batch_idx: 190 |  Loss: (0.3103) |  Loss2: (0.0000) | Acc: (89.00%) (21880/24448)
Epoch: 68 | Batch_idx: 200 |  Loss: (0.3131) |  Loss2: (0.0000) | Acc: (89.00%) (23009/25728)
Epoch: 68 | Batch_idx: 210 |  Loss: (0.3128) |  Loss2: (0.0000) | Acc: (89.00%) (24144/27008)
Epoch: 68 | Batch_idx: 220 |  Loss: (0.3126) |  Loss2: (0.0000) | Acc: (89.00%) (25286/28288)
Epoch: 68 | Batch_idx: 230 |  Loss: (0.3142) |  Loss2: (0.0000) | Acc: (89.00%) (26404/29568)
Epoch: 68 | Batch_idx: 240 |  Loss: (0.3154) |  Loss2: (0.0000) | Acc: (89.00%) (27534/30848)
Epoch: 68 | Batch_idx: 250 |  Loss: (0.3174) |  Loss2: (0.0000) | Acc: (89.00%) (28660/32128)
Epoch: 68 | Batch_idx: 260 |  Loss: (0.3169) |  Loss2: (0.0000) | Acc: (89.00%) (29798/33408)
Epoch: 68 | Batch_idx: 270 |  Loss: (0.3164) |  Loss2: (0.0000) | Acc: (89.00%) (30932/34688)
Epoch: 68 | Batch_idx: 280 |  Loss: (0.3154) |  Loss2: (0.0000) | Acc: (89.00%) (32080/35968)
Epoch: 68 | Batch_idx: 290 |  Loss: (0.3152) |  Loss2: (0.0000) | Acc: (89.00%) (33222/37248)
Epoch: 68 | Batch_idx: 300 |  Loss: (0.3159) |  Loss2: (0.0000) | Acc: (89.00%) (34350/38528)
Epoch: 68 | Batch_idx: 310 |  Loss: (0.3160) |  Loss2: (0.0000) | Acc: (89.00%) (35489/39808)
Epoch: 68 | Batch_idx: 320 |  Loss: (0.3157) |  Loss2: (0.0000) | Acc: (89.00%) (36634/41088)
Epoch: 68 | Batch_idx: 330 |  Loss: (0.3157) |  Loss2: (0.0000) | Acc: (89.00%) (37773/42368)
Epoch: 68 | Batch_idx: 340 |  Loss: (0.3149) |  Loss2: (0.0000) | Acc: (89.00%) (38924/43648)
Epoch: 68 | Batch_idx: 350 |  Loss: (0.3154) |  Loss2: (0.0000) | Acc: (89.00%) (40066/44928)
Epoch: 68 | Batch_idx: 360 |  Loss: (0.3154) |  Loss2: (0.0000) | Acc: (89.00%) (41210/46208)
Epoch: 68 | Batch_idx: 370 |  Loss: (0.3155) |  Loss2: (0.0000) | Acc: (89.00%) (42356/47488)
Epoch: 68 | Batch_idx: 380 |  Loss: (0.3162) |  Loss2: (0.0000) | Acc: (89.00%) (43479/48768)
Epoch: 68 | Batch_idx: 390 |  Loss: (0.3162) |  Loss2: (0.0000) | Acc: (89.00%) (44587/50000)
# TEST : Loss: (0.4273) | Acc: (85.00%) (8575/10000)
percent tensor([0.5087, 0.5005, 0.5081, 0.5022, 0.5095, 0.5145, 0.5053, 0.5041, 0.5081,
        0.5039, 0.5084, 0.5065, 0.5018, 0.5051, 0.5048, 0.5063],
       device='cuda:0') torch.Size([16])
percent tensor([0.5138, 0.5072, 0.5178, 0.5189, 0.5175, 0.5152, 0.5105, 0.5202, 0.5177,
        0.5092, 0.5137, 0.5091, 0.5065, 0.5181, 0.5107, 0.5143],
       device='cuda:0') torch.Size([16])
percent tensor([0.5192, 0.5190, 0.5362, 0.5480, 0.5444, 0.5144, 0.5287, 0.5492, 0.5220,
        0.5236, 0.5135, 0.5242, 0.4996, 0.5494, 0.5142, 0.5280],
       device='cuda:0') torch.Size([16])
percent tensor([0.6007, 0.6160, 0.5934, 0.5923, 0.5892, 0.5959, 0.6116, 0.5918, 0.6100,
        0.6196, 0.6246, 0.6061, 0.6111, 0.6258, 0.5983, 0.6101],
       device='cuda:0') torch.Size([16])
percent tensor([0.5353, 0.5609, 0.4337, 0.5189, 0.4428, 0.5764, 0.5064, 0.3836, 0.5822,
        0.5567, 0.6154, 0.4988, 0.5605, 0.6105, 0.5167, 0.5570],
       device='cuda:0') torch.Size([16])
percent tensor([0.5865, 0.5829, 0.5902, 0.5937, 0.6218, 0.6079, 0.5956, 0.6278, 0.5827,
        0.5813, 0.5643, 0.5582, 0.5702, 0.5757, 0.5807, 0.6097],
       device='cuda:0') torch.Size([16])
percent tensor([0.5249, 0.5798, 0.7197, 0.6824, 0.7680, 0.7040, 0.5746, 0.7315, 0.6065,
        0.5761, 0.5890, 0.6157, 0.5647, 0.5928, 0.5569, 0.5553],
       device='cuda:0') torch.Size([16])
percent tensor([0.9965, 0.9955, 0.9965, 0.9975, 0.9949, 0.9956, 0.9941, 0.9989, 0.9979,
        0.9965, 0.9980, 0.9969, 0.9980, 0.9948, 0.9968, 0.9966],
       device='cuda:0') torch.Size([16])
Epoch: 69 | Batch_idx: 0 |  Loss: (0.2943) |  Loss2: (0.0000) | Acc: (90.00%) (116/128)
Epoch: 69 | Batch_idx: 10 |  Loss: (0.3078) |  Loss2: (0.0000) | Acc: (89.00%) (1260/1408)
Epoch: 69 | Batch_idx: 20 |  Loss: (0.3179) |  Loss2: (0.0000) | Acc: (89.00%) (2399/2688)
Epoch: 69 | Batch_idx: 30 |  Loss: (0.3255) |  Loss2: (0.0000) | Acc: (88.00%) (3521/3968)
Epoch: 69 | Batch_idx: 40 |  Loss: (0.3159) |  Loss2: (0.0000) | Acc: (88.00%) (4667/5248)
Epoch: 69 | Batch_idx: 50 |  Loss: (0.3200) |  Loss2: (0.0000) | Acc: (88.00%) (5800/6528)
Epoch: 69 | Batch_idx: 60 |  Loss: (0.3206) |  Loss2: (0.0000) | Acc: (88.00%) (6934/7808)
Epoch: 69 | Batch_idx: 70 |  Loss: (0.3155) |  Loss2: (0.0000) | Acc: (88.00%) (8072/9088)
Epoch: 69 | Batch_idx: 80 |  Loss: (0.3113) |  Loss2: (0.0000) | Acc: (88.00%) (9224/10368)
Epoch: 69 | Batch_idx: 90 |  Loss: (0.3128) |  Loss2: (0.0000) | Acc: (88.00%) (10359/11648)
Epoch: 69 | Batch_idx: 100 |  Loss: (0.3156) |  Loss2: (0.0000) | Acc: (88.00%) (11485/12928)
Epoch: 69 | Batch_idx: 110 |  Loss: (0.3151) |  Loss2: (0.0000) | Acc: (88.00%) (12631/14208)
Epoch: 69 | Batch_idx: 120 |  Loss: (0.3158) |  Loss2: (0.0000) | Acc: (88.00%) (13771/15488)
Epoch: 69 | Batch_idx: 130 |  Loss: (0.3151) |  Loss2: (0.0000) | Acc: (88.00%) (14914/16768)
Epoch: 69 | Batch_idx: 140 |  Loss: (0.3158) |  Loss2: (0.0000) | Acc: (88.00%) (16050/18048)
Epoch: 69 | Batch_idx: 150 |  Loss: (0.3144) |  Loss2: (0.0000) | Acc: (89.00%) (17204/19328)
Epoch: 69 | Batch_idx: 160 |  Loss: (0.3148) |  Loss2: (0.0000) | Acc: (88.00%) (18335/20608)
Epoch: 69 | Batch_idx: 170 |  Loss: (0.3141) |  Loss2: (0.0000) | Acc: (89.00%) (19486/21888)
Epoch: 69 | Batch_idx: 180 |  Loss: (0.3133) |  Loss2: (0.0000) | Acc: (89.00%) (20641/23168)
Epoch: 69 | Batch_idx: 190 |  Loss: (0.3130) |  Loss2: (0.0000) | Acc: (89.00%) (21794/24448)
Epoch: 69 | Batch_idx: 200 |  Loss: (0.3127) |  Loss2: (0.0000) | Acc: (89.00%) (22936/25728)
Epoch: 69 | Batch_idx: 210 |  Loss: (0.3137) |  Loss2: (0.0000) | Acc: (89.00%) (24075/27008)
Epoch: 69 | Batch_idx: 220 |  Loss: (0.3142) |  Loss2: (0.0000) | Acc: (89.00%) (25208/28288)
Epoch: 69 | Batch_idx: 230 |  Loss: (0.3169) |  Loss2: (0.0000) | Acc: (88.00%) (26311/29568)
Epoch: 69 | Batch_idx: 240 |  Loss: (0.3175) |  Loss2: (0.0000) | Acc: (88.00%) (27450/30848)
Epoch: 69 | Batch_idx: 250 |  Loss: (0.3181) |  Loss2: (0.0000) | Acc: (88.00%) (28580/32128)
Epoch: 69 | Batch_idx: 260 |  Loss: (0.3179) |  Loss2: (0.0000) | Acc: (88.00%) (29732/33408)
Epoch: 69 | Batch_idx: 270 |  Loss: (0.3174) |  Loss2: (0.0000) | Acc: (89.00%) (30880/34688)
Epoch: 69 | Batch_idx: 280 |  Loss: (0.3176) |  Loss2: (0.0000) | Acc: (89.00%) (32015/35968)
Epoch: 69 | Batch_idx: 290 |  Loss: (0.3164) |  Loss2: (0.0000) | Acc: (89.00%) (33176/37248)
Epoch: 69 | Batch_idx: 300 |  Loss: (0.3155) |  Loss2: (0.0000) | Acc: (89.00%) (34335/38528)
Epoch: 69 | Batch_idx: 310 |  Loss: (0.3158) |  Loss2: (0.0000) | Acc: (89.00%) (35477/39808)
Epoch: 69 | Batch_idx: 320 |  Loss: (0.3147) |  Loss2: (0.0000) | Acc: (89.00%) (36641/41088)
Epoch: 69 | Batch_idx: 330 |  Loss: (0.3144) |  Loss2: (0.0000) | Acc: (89.00%) (37787/42368)
Epoch: 69 | Batch_idx: 340 |  Loss: (0.3154) |  Loss2: (0.0000) | Acc: (89.00%) (38907/43648)
Epoch: 69 | Batch_idx: 350 |  Loss: (0.3148) |  Loss2: (0.0000) | Acc: (89.00%) (40057/44928)
Epoch: 69 | Batch_idx: 360 |  Loss: (0.3144) |  Loss2: (0.0000) | Acc: (89.00%) (41207/46208)
Epoch: 69 | Batch_idx: 370 |  Loss: (0.3154) |  Loss2: (0.0000) | Acc: (89.00%) (42326/47488)
Epoch: 69 | Batch_idx: 380 |  Loss: (0.3160) |  Loss2: (0.0000) | Acc: (89.00%) (43465/48768)
Epoch: 69 | Batch_idx: 390 |  Loss: (0.3150) |  Loss2: (0.0000) | Acc: (89.00%) (44578/50000)
# TEST : Loss: (0.4254) | Acc: (85.00%) (8571/10000)
percent tensor([0.5078, 0.4994, 0.5072, 0.5011, 0.5084, 0.5138, 0.5042, 0.5028, 0.5070,
        0.5028, 0.5075, 0.5053, 0.5008, 0.5041, 0.5036, 0.5054],
       device='cuda:0') torch.Size([16])
percent tensor([0.5135, 0.5070, 0.5175, 0.5186, 0.5170, 0.5148, 0.5102, 0.5198, 0.5172,
        0.5091, 0.5134, 0.5089, 0.5063, 0.5179, 0.5104, 0.5141],
       device='cuda:0') torch.Size([16])
percent tensor([0.5174, 0.5164, 0.5360, 0.5478, 0.5440, 0.5132, 0.5267, 0.5488, 0.5203,
        0.5210, 0.5110, 0.5227, 0.4967, 0.5482, 0.5121, 0.5262],
       device='cuda:0') torch.Size([16])
percent tensor([0.6030, 0.6180, 0.5957, 0.5948, 0.5913, 0.5986, 0.6135, 0.5943, 0.6120,
        0.6213, 0.6264, 0.6083, 0.6132, 0.6273, 0.6007, 0.6126],
       device='cuda:0') torch.Size([16])
percent tensor([0.5393, 0.5646, 0.4386, 0.5251, 0.4470, 0.5787, 0.5095, 0.3861, 0.5868,
        0.5606, 0.6211, 0.5028, 0.5642, 0.6140, 0.5182, 0.5602],
       device='cuda:0') torch.Size([16])
percent tensor([0.5867, 0.5830, 0.5909, 0.5940, 0.6230, 0.6089, 0.5959, 0.6292, 0.5825,
        0.5814, 0.5638, 0.5579, 0.5697, 0.5754, 0.5804, 0.6106],
       device='cuda:0') torch.Size([16])
percent tensor([0.5229, 0.5804, 0.7196, 0.6802, 0.7666, 0.7088, 0.5722, 0.7260, 0.6059,
        0.5747, 0.5892, 0.6182, 0.5683, 0.5946, 0.5546, 0.5534],
       device='cuda:0') torch.Size([16])
percent tensor([0.9967, 0.9960, 0.9969, 0.9977, 0.9956, 0.9957, 0.9945, 0.9990, 0.9981,
        0.9967, 0.9982, 0.9973, 0.9982, 0.9953, 0.9971, 0.9967],
       device='cuda:0') torch.Size([16])
Epoch: 70 | Batch_idx: 0 |  Loss: (0.2552) |  Loss2: (0.0000) | Acc: (92.00%) (118/128)
Epoch: 70 | Batch_idx: 10 |  Loss: (0.3005) |  Loss2: (0.0000) | Acc: (90.00%) (1272/1408)
Epoch: 70 | Batch_idx: 20 |  Loss: (0.3110) |  Loss2: (0.0000) | Acc: (89.00%) (2416/2688)
Epoch: 70 | Batch_idx: 30 |  Loss: (0.3180) |  Loss2: (0.0000) | Acc: (89.00%) (3565/3968)
Epoch: 70 | Batch_idx: 40 |  Loss: (0.3202) |  Loss2: (0.0000) | Acc: (89.00%) (4708/5248)
Epoch: 70 | Batch_idx: 50 |  Loss: (0.3218) |  Loss2: (0.0000) | Acc: (89.00%) (5840/6528)
Epoch: 70 | Batch_idx: 60 |  Loss: (0.3177) |  Loss2: (0.0000) | Acc: (89.00%) (6988/7808)
Epoch: 70 | Batch_idx: 70 |  Loss: (0.3129) |  Loss2: (0.0000) | Acc: (89.00%) (8140/9088)
Epoch: 70 | Batch_idx: 80 |  Loss: (0.3143) |  Loss2: (0.0000) | Acc: (89.00%) (9276/10368)
Epoch: 70 | Batch_idx: 90 |  Loss: (0.3148) |  Loss2: (0.0000) | Acc: (89.00%) (10421/11648)
Epoch: 70 | Batch_idx: 100 |  Loss: (0.3124) |  Loss2: (0.0000) | Acc: (89.00%) (11571/12928)
Epoch: 70 | Batch_idx: 110 |  Loss: (0.3091) |  Loss2: (0.0000) | Acc: (89.00%) (12730/14208)
Epoch: 70 | Batch_idx: 120 |  Loss: (0.3091) |  Loss2: (0.0000) | Acc: (89.00%) (13870/15488)
Epoch: 70 | Batch_idx: 130 |  Loss: (0.3102) |  Loss2: (0.0000) | Acc: (89.00%) (15003/16768)
Epoch: 70 | Batch_idx: 140 |  Loss: (0.3118) |  Loss2: (0.0000) | Acc: (89.00%) (16142/18048)
Epoch: 70 | Batch_idx: 150 |  Loss: (0.3096) |  Loss2: (0.0000) | Acc: (89.00%) (17297/19328)
Epoch: 70 | Batch_idx: 160 |  Loss: (0.3104) |  Loss2: (0.0000) | Acc: (89.00%) (18434/20608)
Epoch: 70 | Batch_idx: 170 |  Loss: (0.3094) |  Loss2: (0.0000) | Acc: (89.00%) (19589/21888)
Epoch: 70 | Batch_idx: 180 |  Loss: (0.3084) |  Loss2: (0.0000) | Acc: (89.00%) (20740/23168)
Epoch: 70 | Batch_idx: 190 |  Loss: (0.3090) |  Loss2: (0.0000) | Acc: (89.00%) (21878/24448)
Epoch: 70 | Batch_idx: 200 |  Loss: (0.3083) |  Loss2: (0.0000) | Acc: (89.00%) (23022/25728)
Epoch: 70 | Batch_idx: 210 |  Loss: (0.3102) |  Loss2: (0.0000) | Acc: (89.00%) (24152/27008)
Epoch: 70 | Batch_idx: 220 |  Loss: (0.3098) |  Loss2: (0.0000) | Acc: (89.00%) (25297/28288)
Epoch: 70 | Batch_idx: 230 |  Loss: (0.3093) |  Loss2: (0.0000) | Acc: (89.00%) (26436/29568)
Epoch: 70 | Batch_idx: 240 |  Loss: (0.3091) |  Loss2: (0.0000) | Acc: (89.00%) (27577/30848)
Epoch: 70 | Batch_idx: 250 |  Loss: (0.3102) |  Loss2: (0.0000) | Acc: (89.00%) (28708/32128)
Epoch: 70 | Batch_idx: 260 |  Loss: (0.3106) |  Loss2: (0.0000) | Acc: (89.00%) (29841/33408)
Epoch: 70 | Batch_idx: 270 |  Loss: (0.3109) |  Loss2: (0.0000) | Acc: (89.00%) (30979/34688)
Epoch: 70 | Batch_idx: 280 |  Loss: (0.3104) |  Loss2: (0.0000) | Acc: (89.00%) (32131/35968)
Epoch: 70 | Batch_idx: 290 |  Loss: (0.3108) |  Loss2: (0.0000) | Acc: (89.00%) (33271/37248)
Epoch: 70 | Batch_idx: 300 |  Loss: (0.3107) |  Loss2: (0.0000) | Acc: (89.00%) (34417/38528)
Epoch: 70 | Batch_idx: 310 |  Loss: (0.3102) |  Loss2: (0.0000) | Acc: (89.00%) (35573/39808)
Epoch: 70 | Batch_idx: 320 |  Loss: (0.3103) |  Loss2: (0.0000) | Acc: (89.00%) (36718/41088)
Epoch: 70 | Batch_idx: 330 |  Loss: (0.3094) |  Loss2: (0.0000) | Acc: (89.00%) (37879/42368)
Epoch: 70 | Batch_idx: 340 |  Loss: (0.3095) |  Loss2: (0.0000) | Acc: (89.00%) (39024/43648)
Epoch: 70 | Batch_idx: 350 |  Loss: (0.3102) |  Loss2: (0.0000) | Acc: (89.00%) (40169/44928)
Epoch: 70 | Batch_idx: 360 |  Loss: (0.3105) |  Loss2: (0.0000) | Acc: (89.00%) (41303/46208)
Epoch: 70 | Batch_idx: 370 |  Loss: (0.3112) |  Loss2: (0.0000) | Acc: (89.00%) (42444/47488)
Epoch: 70 | Batch_idx: 380 |  Loss: (0.3108) |  Loss2: (0.0000) | Acc: (89.00%) (43596/48768)
Epoch: 70 | Batch_idx: 390 |  Loss: (0.3111) |  Loss2: (0.0000) | Acc: (89.00%) (44693/50000)
=> saving checkpoint 'drive/app/torch/save_Schedule/checkpoint_070.pth.tar'
# TEST : Loss: (0.4209) | Acc: (85.00%) (8595/10000)
percent tensor([0.5080, 0.4991, 0.5073, 0.5009, 0.5085, 0.5140, 0.5041, 0.5027, 0.5071,
        0.5026, 0.5076, 0.5053, 0.5007, 0.5040, 0.5035, 0.5054],
       device='cuda:0') torch.Size([16])
percent tensor([0.5130, 0.5066, 0.5170, 0.5181, 0.5165, 0.5144, 0.5097, 0.5193, 0.5169,
        0.5086, 0.5130, 0.5084, 0.5058, 0.5176, 0.5099, 0.5137],
       device='cuda:0') torch.Size([16])
percent tensor([0.5184, 0.5181, 0.5359, 0.5480, 0.5440, 0.5147, 0.5270, 0.5483, 0.5209,
        0.5221, 0.5120, 0.5237, 0.4982, 0.5487, 0.5127, 0.5277],
       device='cuda:0') torch.Size([16])
percent tensor([0.6049, 0.6199, 0.5965, 0.5956, 0.5922, 0.6003, 0.6152, 0.5954, 0.6134,
        0.6231, 0.6284, 0.6095, 0.6151, 0.6291, 0.6025, 0.6145],
       device='cuda:0') torch.Size([16])
percent tensor([0.5408, 0.5693, 0.4346, 0.5193, 0.4448, 0.5762, 0.5135, 0.3819, 0.5909,
        0.5665, 0.6291, 0.5032, 0.5687, 0.6212, 0.5193, 0.5607],
       device='cuda:0') torch.Size([16])
percent tensor([0.5801, 0.5762, 0.5858, 0.5881, 0.6179, 0.6035, 0.5894, 0.6241, 0.5766,
        0.5745, 0.5566, 0.5516, 0.5623, 0.5686, 0.5735, 0.6042],
       device='cuda:0') torch.Size([16])
percent tensor([0.5128, 0.5700, 0.7181, 0.6784, 0.7650, 0.7042, 0.5648, 0.7231, 0.5970,
        0.5652, 0.5806, 0.6148, 0.5554, 0.5859, 0.5483, 0.5427],
       device='cuda:0') torch.Size([16])
percent tensor([0.9971, 0.9962, 0.9973, 0.9979, 0.9960, 0.9960, 0.9951, 0.9991, 0.9983,
        0.9969, 0.9982, 0.9975, 0.9983, 0.9953, 0.9974, 0.9970],
       device='cuda:0') torch.Size([16])
Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 3, 3, 3]) tensor(179.2396, device='cuda:0')
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(808.8354, device='cuda:0')
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(797.5502, device='cuda:0')
Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([128, 64, 3, 3]) tensor(1528.1301, device='cuda:0')
Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([128, 64, 1, 1]) tensor(493.6024, device='cuda:0')
Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([128, 128, 3, 3]) tensor(2221.2495, device='cuda:0')
Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([256, 128, 3, 3]) tensor(4273.6641, device='cuda:0')
Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([256, 128, 1, 1]) tensor(1403.1454, device='cuda:0')
Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([256, 256, 3, 3]) tensor(6092.6050, device='cuda:0')
Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([512, 256, 3, 3]) tensor(11962.8916, device='cuda:0')
Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([512, 256, 1, 1]) tensor(3984.5139, device='cuda:0')
Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([512, 512, 3, 3]) tensor(16855.4316, device='cuda:0')
Epoch: 71 | Batch_idx: 0 |  Loss: (0.1655) |  Loss2: (0.0000) | Acc: (93.00%) (120/128)
Epoch: 71 | Batch_idx: 10 |  Loss: (0.3038) |  Loss2: (0.0000) | Acc: (89.00%) (1258/1408)
Epoch: 71 | Batch_idx: 20 |  Loss: (0.3142) |  Loss2: (0.0000) | Acc: (89.00%) (2401/2688)
Epoch: 71 | Batch_idx: 30 |  Loss: (0.3172) |  Loss2: (0.0000) | Acc: (89.00%) (3540/3968)
Epoch: 71 | Batch_idx: 40 |  Loss: (0.3173) |  Loss2: (0.0000) | Acc: (89.00%) (4680/5248)
Epoch: 71 | Batch_idx: 50 |  Loss: (0.3182) |  Loss2: (0.0000) | Acc: (89.00%) (5827/6528)
Epoch: 71 | Batch_idx: 60 |  Loss: (0.3156) |  Loss2: (0.0000) | Acc: (89.00%) (6974/7808)
Epoch: 71 | Batch_idx: 70 |  Loss: (0.3175) |  Loss2: (0.0000) | Acc: (89.00%) (8118/9088)
Epoch: 71 | Batch_idx: 80 |  Loss: (0.3178) |  Loss2: (0.0000) | Acc: (89.00%) (9269/10368)
Epoch: 71 | Batch_idx: 90 |  Loss: (0.3163) |  Loss2: (0.0000) | Acc: (89.00%) (10408/11648)
Epoch: 71 | Batch_idx: 100 |  Loss: (0.3164) |  Loss2: (0.0000) | Acc: (89.00%) (11547/12928)
Epoch: 71 | Batch_idx: 110 |  Loss: (0.3149) |  Loss2: (0.0000) | Acc: (89.00%) (12694/14208)
Epoch: 71 | Batch_idx: 120 |  Loss: (0.3154) |  Loss2: (0.0000) | Acc: (89.00%) (13821/15488)
Epoch: 71 | Batch_idx: 130 |  Loss: (0.3150) |  Loss2: (0.0000) | Acc: (89.00%) (14959/16768)
Epoch: 71 | Batch_idx: 140 |  Loss: (0.3141) |  Loss2: (0.0000) | Acc: (89.00%) (16098/18048)
Epoch: 71 | Batch_idx: 150 |  Loss: (0.3148) |  Loss2: (0.0000) | Acc: (89.00%) (17244/19328)
Epoch: 71 | Batch_idx: 160 |  Loss: (0.3158) |  Loss2: (0.0000) | Acc: (89.00%) (18384/20608)
Epoch: 71 | Batch_idx: 170 |  Loss: (0.3154) |  Loss2: (0.0000) | Acc: (89.00%) (19533/21888)
Epoch: 71 | Batch_idx: 180 |  Loss: (0.3143) |  Loss2: (0.0000) | Acc: (89.00%) (20674/23168)
Epoch: 71 | Batch_idx: 190 |  Loss: (0.3136) |  Loss2: (0.0000) | Acc: (89.00%) (21818/24448)
Epoch: 71 | Batch_idx: 200 |  Loss: (0.3146) |  Loss2: (0.0000) | Acc: (89.00%) (22953/25728)
Epoch: 71 | Batch_idx: 210 |  Loss: (0.3163) |  Loss2: (0.0000) | Acc: (89.00%) (24081/27008)
Epoch: 71 | Batch_idx: 220 |  Loss: (0.3172) |  Loss2: (0.0000) | Acc: (89.00%) (25207/28288)
Epoch: 71 | Batch_idx: 230 |  Loss: (0.3168) |  Loss2: (0.0000) | Acc: (89.00%) (26354/29568)
Epoch: 71 | Batch_idx: 240 |  Loss: (0.3171) |  Loss2: (0.0000) | Acc: (89.00%) (27489/30848)
Epoch: 71 | Batch_idx: 250 |  Loss: (0.3152) |  Loss2: (0.0000) | Acc: (89.00%) (28655/32128)
Epoch: 71 | Batch_idx: 260 |  Loss: (0.3146) |  Loss2: (0.0000) | Acc: (89.00%) (29805/33408)
Epoch: 71 | Batch_idx: 270 |  Loss: (0.3142) |  Loss2: (0.0000) | Acc: (89.00%) (30953/34688)
Epoch: 71 | Batch_idx: 280 |  Loss: (0.3132) |  Loss2: (0.0000) | Acc: (89.00%) (32095/35968)
Epoch: 71 | Batch_idx: 290 |  Loss: (0.3124) |  Loss2: (0.0000) | Acc: (89.00%) (33241/37248)
Epoch: 71 | Batch_idx: 300 |  Loss: (0.3130) |  Loss2: (0.0000) | Acc: (89.00%) (34380/38528)
Epoch: 71 | Batch_idx: 310 |  Loss: (0.3117) |  Loss2: (0.0000) | Acc: (89.00%) (35550/39808)
Epoch: 71 | Batch_idx: 320 |  Loss: (0.3111) |  Loss2: (0.0000) | Acc: (89.00%) (36704/41088)
Epoch: 71 | Batch_idx: 330 |  Loss: (0.3109) |  Loss2: (0.0000) | Acc: (89.00%) (37853/42368)
Epoch: 71 | Batch_idx: 340 |  Loss: (0.3115) |  Loss2: (0.0000) | Acc: (89.00%) (38987/43648)
Epoch: 71 | Batch_idx: 350 |  Loss: (0.3114) |  Loss2: (0.0000) | Acc: (89.00%) (40128/44928)
Epoch: 71 | Batch_idx: 360 |  Loss: (0.3119) |  Loss2: (0.0000) | Acc: (89.00%) (41263/46208)
Epoch: 71 | Batch_idx: 370 |  Loss: (0.3118) |  Loss2: (0.0000) | Acc: (89.00%) (42396/47488)
Epoch: 71 | Batch_idx: 380 |  Loss: (0.3115) |  Loss2: (0.0000) | Acc: (89.00%) (43540/48768)
Epoch: 71 | Batch_idx: 390 |  Loss: (0.3110) |  Loss2: (0.0000) | Acc: (89.00%) (44660/50000)
# TEST : Loss: (0.4206) | Acc: (85.00%) (8585/10000)
percent tensor([0.5069, 0.4975, 0.5060, 0.4995, 0.5070, 0.5134, 0.5026, 0.5009, 0.5058,
        0.5010, 0.5064, 0.5037, 0.4993, 0.5025, 0.5021, 0.5043],
       device='cuda:0') torch.Size([16])
percent tensor([0.5136, 0.5070, 0.5175, 0.5187, 0.5170, 0.5150, 0.5102, 0.5198, 0.5174,
        0.5091, 0.5136, 0.5088, 0.5062, 0.5182, 0.5104, 0.5143],
       device='cuda:0') torch.Size([16])
percent tensor([0.5212, 0.5187, 0.5406, 0.5528, 0.5492, 0.5184, 0.5295, 0.5533, 0.5239,
        0.5234, 0.5138, 0.5261, 0.4981, 0.5526, 0.5152, 0.5304],
       device='cuda:0') torch.Size([16])
percent tensor([0.6025, 0.6166, 0.5945, 0.5933, 0.5902, 0.5983, 0.6121, 0.5936, 0.6106,
        0.6198, 0.6249, 0.6069, 0.6120, 0.6255, 0.6001, 0.6117],
       device='cuda:0') torch.Size([16])
percent tensor([0.5412, 0.5661, 0.4340, 0.5174, 0.4443, 0.5755, 0.5105, 0.3820, 0.5886,
        0.5636, 0.6263, 0.5006, 0.5653, 0.6177, 0.5186, 0.5583],
       device='cuda:0') torch.Size([16])
percent tensor([0.5819, 0.5779, 0.5877, 0.5895, 0.6201, 0.6056, 0.5909, 0.6269, 0.5778,
        0.5759, 0.5572, 0.5525, 0.5638, 0.5692, 0.5753, 0.6066],
       device='cuda:0') torch.Size([16])
percent tensor([0.5143, 0.5748, 0.7174, 0.6758, 0.7630, 0.7057, 0.5651, 0.7196, 0.5995,
        0.5655, 0.5854, 0.6162, 0.5640, 0.5872, 0.5487, 0.5417],
       device='cuda:0') torch.Size([16])
percent tensor([0.9975, 0.9967, 0.9975, 0.9982, 0.9964, 0.9964, 0.9956, 0.9992, 0.9985,
        0.9973, 0.9985, 0.9978, 0.9986, 0.9961, 0.9977, 0.9974],
       device='cuda:0') torch.Size([16])
True Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=128, out_features=16, bias=False)
False Linear(in_features=16, out_features=2, bias=False)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=128, out_features=16, bias=False)
False Linear(in_features=16, out_features=2, bias=False)
True Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=256, out_features=32, bias=False)
False Linear(in_features=32, out_features=2, bias=False)
True Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=256, out_features=32, bias=False)
False Linear(in_features=32, out_features=2, bias=False)
True Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=512, out_features=64, bias=False)
False Linear(in_features=64, out_features=2, bias=False)
True Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=512, out_features=64, bias=False)
False Linear(in_features=64, out_features=2, bias=False)
True Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1024, out_features=128, bias=False)
False Linear(in_features=128, out_features=2, bias=False)
True Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1024, out_features=128, bias=False)
False Linear(in_features=128, out_features=2, bias=False)
True Linear(in_features=512, out_features=10, bias=True)
Epoch: 72 | Batch_idx: 0 |  Loss: (0.2962) |  Loss2: (0.0000) | Acc: (90.00%) (116/128)
Epoch: 72 | Batch_idx: 10 |  Loss: (0.3253) |  Loss2: (0.0000) | Acc: (89.00%) (1255/1408)
Epoch: 72 | Batch_idx: 20 |  Loss: (0.3151) |  Loss2: (0.0000) | Acc: (89.00%) (2413/2688)
Epoch: 72 | Batch_idx: 30 |  Loss: (0.3214) |  Loss2: (0.0000) | Acc: (89.00%) (3554/3968)
Epoch: 72 | Batch_idx: 40 |  Loss: (0.3250) |  Loss2: (0.0000) | Acc: (89.00%) (4680/5248)
Epoch: 72 | Batch_idx: 50 |  Loss: (0.3268) |  Loss2: (0.0000) | Acc: (89.00%) (5819/6528)
Epoch: 72 | Batch_idx: 60 |  Loss: (0.3237) |  Loss2: (0.0000) | Acc: (89.00%) (6959/7808)
Epoch: 72 | Batch_idx: 70 |  Loss: (0.3223) |  Loss2: (0.0000) | Acc: (89.00%) (8112/9088)
Epoch: 72 | Batch_idx: 80 |  Loss: (0.3217) |  Loss2: (0.0000) | Acc: (89.00%) (9259/10368)
Epoch: 72 | Batch_idx: 90 |  Loss: (0.3217) |  Loss2: (0.0000) | Acc: (89.00%) (10393/11648)
Epoch: 72 | Batch_idx: 100 |  Loss: (0.3253) |  Loss2: (0.0000) | Acc: (89.00%) (11508/12928)
Epoch: 72 | Batch_idx: 110 |  Loss: (0.3244) |  Loss2: (0.0000) | Acc: (88.00%) (12645/14208)
Epoch: 72 | Batch_idx: 120 |  Loss: (0.3286) |  Loss2: (0.0000) | Acc: (88.00%) (13762/15488)
Epoch: 72 | Batch_idx: 130 |  Loss: (0.3294) |  Loss2: (0.0000) | Acc: (88.00%) (14888/16768)
Epoch: 72 | Batch_idx: 140 |  Loss: (0.3309) |  Loss2: (0.0000) | Acc: (88.00%) (16012/18048)
Epoch: 72 | Batch_idx: 150 |  Loss: (0.3308) |  Loss2: (0.0000) | Acc: (88.00%) (17155/19328)
Epoch: 72 | Batch_idx: 160 |  Loss: (0.3318) |  Loss2: (0.0000) | Acc: (88.00%) (18287/20608)
Epoch: 72 | Batch_idx: 170 |  Loss: (0.3301) |  Loss2: (0.0000) | Acc: (88.00%) (19433/21888)
Epoch: 72 | Batch_idx: 180 |  Loss: (0.3284) |  Loss2: (0.0000) | Acc: (88.00%) (20582/23168)
Epoch: 72 | Batch_idx: 190 |  Loss: (0.3302) |  Loss2: (0.0000) | Acc: (88.00%) (21696/24448)
Epoch: 72 | Batch_idx: 200 |  Loss: (0.3310) |  Loss2: (0.0000) | Acc: (88.00%) (22823/25728)
Epoch: 72 | Batch_idx: 210 |  Loss: (0.3314) |  Loss2: (0.0000) | Acc: (88.00%) (23950/27008)
Epoch: 72 | Batch_idx: 220 |  Loss: (0.3321) |  Loss2: (0.0000) | Acc: (88.00%) (25064/28288)
Epoch: 72 | Batch_idx: 230 |  Loss: (0.3326) |  Loss2: (0.0000) | Acc: (88.00%) (26193/29568)
Epoch: 72 | Batch_idx: 240 |  Loss: (0.3329) |  Loss2: (0.0000) | Acc: (88.00%) (27315/30848)
Epoch: 72 | Batch_idx: 250 |  Loss: (0.3330) |  Loss2: (0.0000) | Acc: (88.00%) (28451/32128)
Epoch: 72 | Batch_idx: 260 |  Loss: (0.3332) |  Loss2: (0.0000) | Acc: (88.00%) (29577/33408)
Epoch: 72 | Batch_idx: 270 |  Loss: (0.3340) |  Loss2: (0.0000) | Acc: (88.00%) (30701/34688)
Epoch: 72 | Batch_idx: 280 |  Loss: (0.3337) |  Loss2: (0.0000) | Acc: (88.00%) (31837/35968)
Epoch: 72 | Batch_idx: 290 |  Loss: (0.3335) |  Loss2: (0.0000) | Acc: (88.00%) (32962/37248)
Epoch: 72 | Batch_idx: 300 |  Loss: (0.3334) |  Loss2: (0.0000) | Acc: (88.00%) (34092/38528)
Epoch: 72 | Batch_idx: 310 |  Loss: (0.3327) |  Loss2: (0.0000) | Acc: (88.00%) (35242/39808)
Epoch: 72 | Batch_idx: 320 |  Loss: (0.3326) |  Loss2: (0.0000) | Acc: (88.00%) (36376/41088)
Epoch: 72 | Batch_idx: 330 |  Loss: (0.3327) |  Loss2: (0.0000) | Acc: (88.00%) (37500/42368)
Epoch: 72 | Batch_idx: 340 |  Loss: (0.3319) |  Loss2: (0.0000) | Acc: (88.00%) (38643/43648)
Epoch: 72 | Batch_idx: 350 |  Loss: (0.3316) |  Loss2: (0.0000) | Acc: (88.00%) (39781/44928)
Epoch: 72 | Batch_idx: 360 |  Loss: (0.3321) |  Loss2: (0.0000) | Acc: (88.00%) (40910/46208)
Epoch: 72 | Batch_idx: 370 |  Loss: (0.3324) |  Loss2: (0.0000) | Acc: (88.00%) (42032/47488)
Epoch: 72 | Batch_idx: 380 |  Loss: (0.3325) |  Loss2: (0.0000) | Acc: (88.00%) (43159/48768)
Epoch: 72 | Batch_idx: 390 |  Loss: (0.3313) |  Loss2: (0.0000) | Acc: (88.00%) (44274/50000)
# TEST : Loss: (0.5145) | Acc: (83.00%) (8366/10000)
percent tensor([0.5071, 0.4972, 0.5064, 0.4995, 0.5072, 0.5133, 0.5025, 0.5006, 0.5061,
        0.5010, 0.5069, 0.5039, 0.4993, 0.5027, 0.5020, 0.5046],
       device='cuda:0') torch.Size([16])
percent tensor([0.5134, 0.5060, 0.5170, 0.5179, 0.5177, 0.5141, 0.5101, 0.5190, 0.5179,
        0.5087, 0.5129, 0.5092, 0.5064, 0.5183, 0.5094, 0.5138],
       device='cuda:0') torch.Size([16])
percent tensor([0.5211, 0.5200, 0.5307, 0.5429, 0.5444, 0.5156, 0.5300, 0.5471, 0.5295,
        0.5238, 0.5191, 0.5208, 0.5005, 0.5603, 0.5135, 0.5300],
       device='cuda:0') torch.Size([16])
percent tensor([0.6038, 0.6190, 0.5907, 0.5862, 0.5874, 0.5943, 0.6141, 0.5925, 0.6119,
        0.6209, 0.6240, 0.6083, 0.6146, 0.6282, 0.5998, 0.6110],
       device='cuda:0') torch.Size([16])
percent tensor([0.5384, 0.5484, 0.4354, 0.5094, 0.4514, 0.5694, 0.5136, 0.3907, 0.5925,
        0.5482, 0.6191, 0.5023, 0.5689, 0.6129, 0.4986, 0.5515],
       device='cuda:0') torch.Size([16])
percent tensor([0.5929, 0.5798, 0.5855, 0.5860, 0.6172, 0.6104, 0.5927, 0.6203, 0.5764,
        0.5793, 0.5624, 0.5528, 0.5637, 0.5683, 0.5779, 0.6141],
       device='cuda:0') torch.Size([16])
percent tensor([0.5142, 0.5776, 0.7005, 0.6851, 0.7556, 0.7160, 0.5612, 0.7023, 0.6081,
        0.5553, 0.5775, 0.6236, 0.5704, 0.5732, 0.5434, 0.5433],
       device='cuda:0') torch.Size([16])
percent tensor([0.9982, 0.9969, 0.9982, 0.9988, 0.9974, 0.9964, 0.9965, 0.9993, 0.9987,
        0.9977, 0.9987, 0.9984, 0.9987, 0.9973, 0.9985, 0.9983],
       device='cuda:0') torch.Size([16])
Epoch: 73 | Batch_idx: 0 |  Loss: (0.3527) |  Loss2: (0.0000) | Acc: (86.00%) (111/128)
Epoch: 73 | Batch_idx: 10 |  Loss: (0.3192) |  Loss2: (0.0000) | Acc: (88.00%) (1246/1408)
Epoch: 73 | Batch_idx: 20 |  Loss: (0.3167) |  Loss2: (0.0000) | Acc: (88.00%) (2382/2688)
Epoch: 73 | Batch_idx: 30 |  Loss: (0.3126) |  Loss2: (0.0000) | Acc: (88.00%) (3527/3968)
Epoch: 73 | Batch_idx: 40 |  Loss: (0.3202) |  Loss2: (0.0000) | Acc: (88.00%) (4652/5248)
Epoch: 73 | Batch_idx: 50 |  Loss: (0.3204) |  Loss2: (0.0000) | Acc: (88.00%) (5784/6528)
Epoch: 73 | Batch_idx: 60 |  Loss: (0.3192) |  Loss2: (0.0000) | Acc: (88.00%) (6942/7808)
Epoch: 73 | Batch_idx: 70 |  Loss: (0.3136) |  Loss2: (0.0000) | Acc: (89.00%) (8099/9088)
Epoch: 73 | Batch_idx: 80 |  Loss: (0.3156) |  Loss2: (0.0000) | Acc: (89.00%) (9229/10368)
Epoch: 73 | Batch_idx: 90 |  Loss: (0.3123) |  Loss2: (0.0000) | Acc: (89.00%) (10384/11648)
Epoch: 73 | Batch_idx: 100 |  Loss: (0.3124) |  Loss2: (0.0000) | Acc: (89.00%) (11531/12928)
Epoch: 73 | Batch_idx: 110 |  Loss: (0.3129) |  Loss2: (0.0000) | Acc: (89.00%) (12659/14208)
Epoch: 73 | Batch_idx: 120 |  Loss: (0.3132) |  Loss2: (0.0000) | Acc: (89.00%) (13800/15488)
Epoch: 73 | Batch_idx: 130 |  Loss: (0.3146) |  Loss2: (0.0000) | Acc: (89.00%) (14928/16768)
Epoch: 73 | Batch_idx: 140 |  Loss: (0.3145) |  Loss2: (0.0000) | Acc: (89.00%) (16073/18048)
Epoch: 73 | Batch_idx: 150 |  Loss: (0.3145) |  Loss2: (0.0000) | Acc: (89.00%) (17211/19328)
Epoch: 73 | Batch_idx: 160 |  Loss: (0.3164) |  Loss2: (0.0000) | Acc: (88.00%) (18336/20608)
Epoch: 73 | Batch_idx: 170 |  Loss: (0.3165) |  Loss2: (0.0000) | Acc: (88.00%) (19476/21888)
Epoch: 73 | Batch_idx: 180 |  Loss: (0.3190) |  Loss2: (0.0000) | Acc: (88.00%) (20592/23168)
Epoch: 73 | Batch_idx: 190 |  Loss: (0.3185) |  Loss2: (0.0000) | Acc: (88.00%) (21736/24448)
Epoch: 73 | Batch_idx: 200 |  Loss: (0.3183) |  Loss2: (0.0000) | Acc: (88.00%) (22876/25728)
Epoch: 73 | Batch_idx: 210 |  Loss: (0.3179) |  Loss2: (0.0000) | Acc: (88.00%) (24011/27008)
Epoch: 73 | Batch_idx: 220 |  Loss: (0.3174) |  Loss2: (0.0000) | Acc: (88.00%) (25157/28288)
Epoch: 73 | Batch_idx: 230 |  Loss: (0.3178) |  Loss2: (0.0000) | Acc: (88.00%) (26290/29568)
Epoch: 73 | Batch_idx: 240 |  Loss: (0.3184) |  Loss2: (0.0000) | Acc: (88.00%) (27419/30848)
Epoch: 73 | Batch_idx: 250 |  Loss: (0.3186) |  Loss2: (0.0000) | Acc: (88.00%) (28542/32128)
Epoch: 73 | Batch_idx: 260 |  Loss: (0.3194) |  Loss2: (0.0000) | Acc: (88.00%) (29674/33408)
Epoch: 73 | Batch_idx: 270 |  Loss: (0.3198) |  Loss2: (0.0000) | Acc: (88.00%) (30807/34688)
Epoch: 73 | Batch_idx: 280 |  Loss: (0.3197) |  Loss2: (0.0000) | Acc: (88.00%) (31942/35968)
Epoch: 73 | Batch_idx: 290 |  Loss: (0.3198) |  Loss2: (0.0000) | Acc: (88.00%) (33075/37248)
Epoch: 73 | Batch_idx: 300 |  Loss: (0.3218) |  Loss2: (0.0000) | Acc: (88.00%) (34195/38528)
Epoch: 73 | Batch_idx: 310 |  Loss: (0.3210) |  Loss2: (0.0000) | Acc: (88.00%) (35345/39808)
Epoch: 73 | Batch_idx: 320 |  Loss: (0.3208) |  Loss2: (0.0000) | Acc: (88.00%) (36481/41088)
Epoch: 73 | Batch_idx: 330 |  Loss: (0.3206) |  Loss2: (0.0000) | Acc: (88.00%) (37626/42368)
Epoch: 73 | Batch_idx: 340 |  Loss: (0.3219) |  Loss2: (0.0000) | Acc: (88.00%) (38751/43648)
Epoch: 73 | Batch_idx: 350 |  Loss: (0.3219) |  Loss2: (0.0000) | Acc: (88.00%) (39888/44928)
Epoch: 73 | Batch_idx: 360 |  Loss: (0.3209) |  Loss2: (0.0000) | Acc: (88.00%) (41044/46208)
Epoch: 73 | Batch_idx: 370 |  Loss: (0.3211) |  Loss2: (0.0000) | Acc: (88.00%) (42169/47488)
Epoch: 73 | Batch_idx: 380 |  Loss: (0.3203) |  Loss2: (0.0000) | Acc: (88.00%) (43325/48768)
Epoch: 73 | Batch_idx: 390 |  Loss: (0.3200) |  Loss2: (0.0000) | Acc: (88.00%) (44419/50000)
# TEST : Loss: (0.4971) | Acc: (84.00%) (8410/10000)
percent tensor([0.5063, 0.4969, 0.5061, 0.4998, 0.5068, 0.5131, 0.5016, 0.5010, 0.5057,
        0.5003, 0.5064, 0.5030, 0.4988, 0.5019, 0.5018, 0.5040],
       device='cuda:0') torch.Size([16])
percent tensor([0.5131, 0.5064, 0.5160, 0.5181, 0.5168, 0.5139, 0.5103, 0.5186, 0.5179,
        0.5083, 0.5129, 0.5088, 0.5059, 0.5190, 0.5093, 0.5142],
       device='cuda:0') torch.Size([16])
percent tensor([0.5207, 0.5189, 0.5306, 0.5420, 0.5420, 0.5163, 0.5315, 0.5467, 0.5305,
        0.5237, 0.5200, 0.5226, 0.4998, 0.5587, 0.5120, 0.5299],
       device='cuda:0') torch.Size([16])
percent tensor([0.6020, 0.6189, 0.5942, 0.5922, 0.5895, 0.5907, 0.6141, 0.5921, 0.6124,
        0.6213, 0.6248, 0.6096, 0.6137, 0.6304, 0.5968, 0.6096],
       device='cuda:0') torch.Size([16])
percent tensor([0.5377, 0.5518, 0.4563, 0.5301, 0.4717, 0.5588, 0.5213, 0.3944, 0.5993,
        0.5551, 0.6261, 0.5026, 0.5613, 0.6086, 0.4963, 0.5529],
       device='cuda:0') torch.Size([16])
percent tensor([0.5869, 0.5805, 0.5882, 0.5871, 0.6205, 0.6036, 0.5956, 0.6283, 0.5744,
        0.5772, 0.5621, 0.5568, 0.5658, 0.5690, 0.5792, 0.6127],
       device='cuda:0') torch.Size([16])
percent tensor([0.4922, 0.5592, 0.7146, 0.6640, 0.7556, 0.6966, 0.5587, 0.7171, 0.5582,
        0.5254, 0.5786, 0.6009, 0.5318, 0.5783, 0.5448, 0.5346],
       device='cuda:0') torch.Size([16])
percent tensor([0.9981, 0.9961, 0.9983, 0.9976, 0.9968, 0.9977, 0.9970, 0.9993, 0.9980,
        0.9966, 0.9979, 0.9977, 0.9982, 0.9954, 0.9976, 0.9976],
       device='cuda:0') torch.Size([16])
Epoch: 74 | Batch_idx: 0 |  Loss: (0.4956) |  Loss2: (0.0000) | Acc: (82.00%) (105/128)
Epoch: 74 | Batch_idx: 10 |  Loss: (0.3370) |  Loss2: (0.0000) | Acc: (88.00%) (1244/1408)
Epoch: 74 | Batch_idx: 20 |  Loss: (0.3126) |  Loss2: (0.0000) | Acc: (88.00%) (2391/2688)
Epoch: 74 | Batch_idx: 30 |  Loss: (0.3121) |  Loss2: (0.0000) | Acc: (88.00%) (3523/3968)
Epoch: 74 | Batch_idx: 40 |  Loss: (0.3155) |  Loss2: (0.0000) | Acc: (88.00%) (4660/5248)
Epoch: 74 | Batch_idx: 50 |  Loss: (0.3081) |  Loss2: (0.0000) | Acc: (89.00%) (5829/6528)
Epoch: 74 | Batch_idx: 60 |  Loss: (0.3063) |  Loss2: (0.0000) | Acc: (89.00%) (6971/7808)
Epoch: 74 | Batch_idx: 70 |  Loss: (0.3080) |  Loss2: (0.0000) | Acc: (89.00%) (8109/9088)
Epoch: 74 | Batch_idx: 80 |  Loss: (0.3044) |  Loss2: (0.0000) | Acc: (89.00%) (9266/10368)
Epoch: 74 | Batch_idx: 90 |  Loss: (0.3051) |  Loss2: (0.0000) | Acc: (89.00%) (10402/11648)
Epoch: 74 | Batch_idx: 100 |  Loss: (0.3053) |  Loss2: (0.0000) | Acc: (89.00%) (11540/12928)
Epoch: 74 | Batch_idx: 110 |  Loss: (0.3070) |  Loss2: (0.0000) | Acc: (89.00%) (12663/14208)
Epoch: 74 | Batch_idx: 120 |  Loss: (0.3064) |  Loss2: (0.0000) | Acc: (89.00%) (13818/15488)
Epoch: 74 | Batch_idx: 130 |  Loss: (0.3057) |  Loss2: (0.0000) | Acc: (89.00%) (14959/16768)
Epoch: 74 | Batch_idx: 140 |  Loss: (0.3054) |  Loss2: (0.0000) | Acc: (89.00%) (16102/18048)
Epoch: 74 | Batch_idx: 150 |  Loss: (0.3061) |  Loss2: (0.0000) | Acc: (89.00%) (17241/19328)
Epoch: 74 | Batch_idx: 160 |  Loss: (0.3067) |  Loss2: (0.0000) | Acc: (89.00%) (18382/20608)
Epoch: 74 | Batch_idx: 170 |  Loss: (0.3088) |  Loss2: (0.0000) | Acc: (89.00%) (19501/21888)
Epoch: 74 | Batch_idx: 180 |  Loss: (0.3090) |  Loss2: (0.0000) | Acc: (89.00%) (20646/23168)
Epoch: 74 | Batch_idx: 190 |  Loss: (0.3087) |  Loss2: (0.0000) | Acc: (89.00%) (21788/24448)
Epoch: 74 | Batch_idx: 200 |  Loss: (0.3076) |  Loss2: (0.0000) | Acc: (89.00%) (22942/25728)
Epoch: 74 | Batch_idx: 210 |  Loss: (0.3088) |  Loss2: (0.0000) | Acc: (89.00%) (24077/27008)
Epoch: 74 | Batch_idx: 220 |  Loss: (0.3088) |  Loss2: (0.0000) | Acc: (89.00%) (25229/28288)
Epoch: 74 | Batch_idx: 230 |  Loss: (0.3088) |  Loss2: (0.0000) | Acc: (89.00%) (26377/29568)
Epoch: 74 | Batch_idx: 240 |  Loss: (0.3089) |  Loss2: (0.0000) | Acc: (89.00%) (27526/30848)
Epoch: 74 | Batch_idx: 250 |  Loss: (0.3089) |  Loss2: (0.0000) | Acc: (89.00%) (28673/32128)
Epoch: 74 | Batch_idx: 260 |  Loss: (0.3103) |  Loss2: (0.0000) | Acc: (89.00%) (29797/33408)
Epoch: 74 | Batch_idx: 270 |  Loss: (0.3092) |  Loss2: (0.0000) | Acc: (89.00%) (30956/34688)
Epoch: 74 | Batch_idx: 280 |  Loss: (0.3091) |  Loss2: (0.0000) | Acc: (89.00%) (32095/35968)
Epoch: 74 | Batch_idx: 290 |  Loss: (0.3094) |  Loss2: (0.0000) | Acc: (89.00%) (33240/37248)
Epoch: 74 | Batch_idx: 300 |  Loss: (0.3083) |  Loss2: (0.0000) | Acc: (89.00%) (34396/38528)
Epoch: 74 | Batch_idx: 310 |  Loss: (0.3081) |  Loss2: (0.0000) | Acc: (89.00%) (35550/39808)
Epoch: 74 | Batch_idx: 320 |  Loss: (0.3084) |  Loss2: (0.0000) | Acc: (89.00%) (36684/41088)
Epoch: 74 | Batch_idx: 330 |  Loss: (0.3089) |  Loss2: (0.0000) | Acc: (89.00%) (37814/42368)
Epoch: 74 | Batch_idx: 340 |  Loss: (0.3089) |  Loss2: (0.0000) | Acc: (89.00%) (38958/43648)
Epoch: 74 | Batch_idx: 350 |  Loss: (0.3090) |  Loss2: (0.0000) | Acc: (89.00%) (40112/44928)
Epoch: 74 | Batch_idx: 360 |  Loss: (0.3089) |  Loss2: (0.0000) | Acc: (89.00%) (41261/46208)
Epoch: 74 | Batch_idx: 370 |  Loss: (0.3085) |  Loss2: (0.0000) | Acc: (89.00%) (42409/47488)
Epoch: 74 | Batch_idx: 380 |  Loss: (0.3097) |  Loss2: (0.0000) | Acc: (89.00%) (43525/48768)
Epoch: 74 | Batch_idx: 390 |  Loss: (0.3094) |  Loss2: (0.0000) | Acc: (89.00%) (44638/50000)
# TEST : Loss: (0.4780) | Acc: (84.00%) (8427/10000)
percent tensor([0.5066, 0.4982, 0.5063, 0.4998, 0.5064, 0.5138, 0.5024, 0.5011, 0.5055,
        0.5011, 0.5068, 0.5032, 0.4991, 0.5032, 0.5029, 0.5046],
       device='cuda:0') torch.Size([16])
percent tensor([0.5122, 0.5056, 0.5169, 0.5163, 0.5163, 0.5131, 0.5095, 0.5187, 0.5165,
        0.5079, 0.5129, 0.5082, 0.5052, 0.5166, 0.5086, 0.5131],
       device='cuda:0') torch.Size([16])
percent tensor([0.5176, 0.5171, 0.5383, 0.5449, 0.5466, 0.5120, 0.5269, 0.5516, 0.5243,
        0.5215, 0.5155, 0.5247, 0.4968, 0.5531, 0.5122, 0.5267],
       device='cuda:0') torch.Size([16])
percent tensor([0.6036, 0.6186, 0.5958, 0.5926, 0.5902, 0.5952, 0.6101, 0.5951, 0.6111,
        0.6193, 0.6264, 0.6064, 0.6144, 0.6241, 0.6000, 0.6134],
       device='cuda:0') torch.Size([16])
percent tensor([0.5500, 0.5664, 0.4507, 0.5244, 0.4610, 0.5719, 0.5257, 0.4047, 0.6005,
        0.5630, 0.6392, 0.5110, 0.5735, 0.6148, 0.5181, 0.5654],
       device='cuda:0') torch.Size([16])
percent tensor([0.5773, 0.5729, 0.5937, 0.5862, 0.6205, 0.5894, 0.5864, 0.6224, 0.5728,
        0.5769, 0.5573, 0.5568, 0.5590, 0.5655, 0.5694, 0.6024],
       device='cuda:0') torch.Size([16])
percent tensor([0.4977, 0.5696, 0.7097, 0.6611, 0.7475, 0.6912, 0.5590, 0.6919, 0.5918,
        0.5729, 0.5824, 0.6323, 0.5600, 0.5880, 0.5388, 0.5288],
       device='cuda:0') torch.Size([16])
percent tensor([0.9986, 0.9965, 0.9977, 0.9978, 0.9964, 0.9984, 0.9960, 0.9990, 0.9988,
        0.9971, 0.9980, 0.9979, 0.9982, 0.9954, 0.9978, 0.9973],
       device='cuda:0') torch.Size([16])
Epoch: 75 | Batch_idx: 0 |  Loss: (0.3102) |  Loss2: (0.0000) | Acc: (90.00%) (116/128)
Epoch: 75 | Batch_idx: 10 |  Loss: (0.2839) |  Loss2: (0.0000) | Acc: (90.00%) (1281/1408)
Epoch: 75 | Batch_idx: 20 |  Loss: (0.2916) |  Loss2: (0.0000) | Acc: (90.00%) (2423/2688)
Epoch: 75 | Batch_idx: 30 |  Loss: (0.2893) |  Loss2: (0.0000) | Acc: (89.00%) (3568/3968)
Epoch: 75 | Batch_idx: 40 |  Loss: (0.2860) |  Loss2: (0.0000) | Acc: (90.00%) (4730/5248)
Epoch: 75 | Batch_idx: 50 |  Loss: (0.2868) |  Loss2: (0.0000) | Acc: (90.00%) (5880/6528)
Epoch: 75 | Batch_idx: 60 |  Loss: (0.2849) |  Loss2: (0.0000) | Acc: (90.00%) (7038/7808)
Epoch: 75 | Batch_idx: 70 |  Loss: (0.2879) |  Loss2: (0.0000) | Acc: (89.00%) (8175/9088)
Epoch: 75 | Batch_idx: 80 |  Loss: (0.2908) |  Loss2: (0.0000) | Acc: (89.00%) (9309/10368)
Epoch: 75 | Batch_idx: 90 |  Loss: (0.2945) |  Loss2: (0.0000) | Acc: (89.00%) (10457/11648)
Epoch: 75 | Batch_idx: 100 |  Loss: (0.2978) |  Loss2: (0.0000) | Acc: (89.00%) (11589/12928)
Epoch: 75 | Batch_idx: 110 |  Loss: (0.2966) |  Loss2: (0.0000) | Acc: (89.00%) (12750/14208)
Epoch: 75 | Batch_idx: 120 |  Loss: (0.3018) |  Loss2: (0.0000) | Acc: (89.00%) (13871/15488)
Epoch: 75 | Batch_idx: 130 |  Loss: (0.3027) |  Loss2: (0.0000) | Acc: (89.00%) (15012/16768)
Epoch: 75 | Batch_idx: 140 |  Loss: (0.3003) |  Loss2: (0.0000) | Acc: (89.00%) (16176/18048)
Epoch: 75 | Batch_idx: 150 |  Loss: (0.2976) |  Loss2: (0.0000) | Acc: (89.00%) (17342/19328)
Epoch: 75 | Batch_idx: 160 |  Loss: (0.2987) |  Loss2: (0.0000) | Acc: (89.00%) (18478/20608)
Epoch: 75 | Batch_idx: 170 |  Loss: (0.2979) |  Loss2: (0.0000) | Acc: (89.00%) (19635/21888)
Epoch: 75 | Batch_idx: 180 |  Loss: (0.2989) |  Loss2: (0.0000) | Acc: (89.00%) (20778/23168)
Epoch: 75 | Batch_idx: 190 |  Loss: (0.3024) |  Loss2: (0.0000) | Acc: (89.00%) (21896/24448)
Epoch: 75 | Batch_idx: 200 |  Loss: (0.3025) |  Loss2: (0.0000) | Acc: (89.00%) (23043/25728)
Epoch: 75 | Batch_idx: 210 |  Loss: (0.3032) |  Loss2: (0.0000) | Acc: (89.00%) (24177/27008)
Epoch: 75 | Batch_idx: 220 |  Loss: (0.3034) |  Loss2: (0.0000) | Acc: (89.00%) (25326/28288)
Epoch: 75 | Batch_idx: 230 |  Loss: (0.3041) |  Loss2: (0.0000) | Acc: (89.00%) (26478/29568)
Epoch: 75 | Batch_idx: 240 |  Loss: (0.3042) |  Loss2: (0.0000) | Acc: (89.00%) (27614/30848)
Epoch: 75 | Batch_idx: 250 |  Loss: (0.3042) |  Loss2: (0.0000) | Acc: (89.00%) (28760/32128)
Epoch: 75 | Batch_idx: 260 |  Loss: (0.3054) |  Loss2: (0.0000) | Acc: (89.00%) (29890/33408)
Epoch: 75 | Batch_idx: 270 |  Loss: (0.3054) |  Loss2: (0.0000) | Acc: (89.00%) (31037/34688)
Epoch: 75 | Batch_idx: 280 |  Loss: (0.3059) |  Loss2: (0.0000) | Acc: (89.00%) (32166/35968)
Epoch: 75 | Batch_idx: 290 |  Loss: (0.3059) |  Loss2: (0.0000) | Acc: (89.00%) (33325/37248)
Epoch: 75 | Batch_idx: 300 |  Loss: (0.3058) |  Loss2: (0.0000) | Acc: (89.00%) (34483/38528)
Epoch: 75 | Batch_idx: 310 |  Loss: (0.3055) |  Loss2: (0.0000) | Acc: (89.00%) (35633/39808)
Epoch: 75 | Batch_idx: 320 |  Loss: (0.3044) |  Loss2: (0.0000) | Acc: (89.00%) (36796/41088)
Epoch: 75 | Batch_idx: 330 |  Loss: (0.3044) |  Loss2: (0.0000) | Acc: (89.00%) (37930/42368)
Epoch: 75 | Batch_idx: 340 |  Loss: (0.3043) |  Loss2: (0.0000) | Acc: (89.00%) (39090/43648)
Epoch: 75 | Batch_idx: 350 |  Loss: (0.3042) |  Loss2: (0.0000) | Acc: (89.00%) (40243/44928)
Epoch: 75 | Batch_idx: 360 |  Loss: (0.3041) |  Loss2: (0.0000) | Acc: (89.00%) (41387/46208)
Epoch: 75 | Batch_idx: 370 |  Loss: (0.3039) |  Loss2: (0.0000) | Acc: (89.00%) (42531/47488)
Epoch: 75 | Batch_idx: 380 |  Loss: (0.3043) |  Loss2: (0.0000) | Acc: (89.00%) (43674/48768)
Epoch: 75 | Batch_idx: 390 |  Loss: (0.3045) |  Loss2: (0.0000) | Acc: (89.00%) (44771/50000)
=> saving checkpoint 'drive/app/torch/save_Schedule/checkpoint_075.pth.tar'
# TEST : Loss: (0.4421) | Acc: (85.00%) (8553/10000)
percent tensor([0.5065, 0.4976, 0.5051, 0.5003, 0.5055, 0.5131, 0.5021, 0.5008, 0.5058,
        0.5004, 0.5063, 0.5024, 0.4988, 0.5037, 0.5023, 0.5044],
       device='cuda:0') torch.Size([16])
percent tensor([0.5145, 0.5071, 0.5182, 0.5180, 0.5177, 0.5148, 0.5111, 0.5199, 0.5184,
        0.5094, 0.5136, 0.5104, 0.5073, 0.5184, 0.5103, 0.5146],
       device='cuda:0') torch.Size([16])
percent tensor([0.5225, 0.5228, 0.5286, 0.5461, 0.5437, 0.5208, 0.5332, 0.5463, 0.5320,
        0.5251, 0.5204, 0.5223, 0.5002, 0.5652, 0.5164, 0.5340],
       device='cuda:0') torch.Size([16])
percent tensor([0.6038, 0.6217, 0.5943, 0.5922, 0.5889, 0.5992, 0.6162, 0.5935, 0.6111,
        0.6235, 0.6259, 0.6090, 0.6132, 0.6329, 0.6014, 0.6139],
       device='cuda:0') torch.Size([16])
percent tensor([0.5504, 0.5586, 0.4726, 0.5304, 0.4710, 0.5778, 0.5275, 0.4104, 0.5941,
        0.5675, 0.6258, 0.5268, 0.5651, 0.6204, 0.5130, 0.5670],
       device='cuda:0') torch.Size([16])
percent tensor([0.5876, 0.5793, 0.5857, 0.5870, 0.6227, 0.6007, 0.5952, 0.6244, 0.5849,
        0.5762, 0.5620, 0.5579, 0.5721, 0.5698, 0.5758, 0.6087],
       device='cuda:0') torch.Size([16])
percent tensor([0.5232, 0.5881, 0.7061, 0.6733, 0.7559, 0.7032, 0.5970, 0.7171, 0.6187,
        0.5711, 0.6172, 0.6135, 0.5735, 0.5976, 0.5502, 0.5555],
       device='cuda:0') torch.Size([16])
percent tensor([0.9975, 0.9944, 0.9974, 0.9983, 0.9972, 0.9964, 0.9960, 0.9990, 0.9986,
        0.9970, 0.9987, 0.9982, 0.9978, 0.9951, 0.9969, 0.9964],
       device='cuda:0') torch.Size([16])
Epoch: 76 | Batch_idx: 0 |  Loss: (0.3723) |  Loss2: (0.0000) | Acc: (86.00%) (111/128)
Epoch: 76 | Batch_idx: 10 |  Loss: (0.2972) |  Loss2: (0.0000) | Acc: (88.00%) (1249/1408)
Epoch: 76 | Batch_idx: 20 |  Loss: (0.2771) |  Loss2: (0.0000) | Acc: (89.00%) (2418/2688)
Epoch: 76 | Batch_idx: 30 |  Loss: (0.2817) |  Loss2: (0.0000) | Acc: (90.00%) (3577/3968)
Epoch: 76 | Batch_idx: 40 |  Loss: (0.2977) |  Loss2: (0.0000) | Acc: (89.00%) (4701/5248)
Epoch: 76 | Batch_idx: 50 |  Loss: (0.2940) |  Loss2: (0.0000) | Acc: (89.00%) (5856/6528)
Epoch: 76 | Batch_idx: 60 |  Loss: (0.2936) |  Loss2: (0.0000) | Acc: (89.00%) (7007/7808)
Epoch: 76 | Batch_idx: 70 |  Loss: (0.2950) |  Loss2: (0.0000) | Acc: (89.00%) (8154/9088)
Epoch: 76 | Batch_idx: 80 |  Loss: (0.2960) |  Loss2: (0.0000) | Acc: (89.00%) (9304/10368)
Epoch: 76 | Batch_idx: 90 |  Loss: (0.2932) |  Loss2: (0.0000) | Acc: (89.00%) (10471/11648)
Epoch: 76 | Batch_idx: 100 |  Loss: (0.2923) |  Loss2: (0.0000) | Acc: (89.00%) (11629/12928)
Epoch: 76 | Batch_idx: 110 |  Loss: (0.2914) |  Loss2: (0.0000) | Acc: (90.00%) (12791/14208)
Epoch: 76 | Batch_idx: 120 |  Loss: (0.2921) |  Loss2: (0.0000) | Acc: (89.00%) (13932/15488)
Epoch: 76 | Batch_idx: 130 |  Loss: (0.2897) |  Loss2: (0.0000) | Acc: (90.00%) (15096/16768)
Epoch: 76 | Batch_idx: 140 |  Loss: (0.2900) |  Loss2: (0.0000) | Acc: (90.00%) (16259/18048)
Epoch: 76 | Batch_idx: 150 |  Loss: (0.2921) |  Loss2: (0.0000) | Acc: (90.00%) (17401/19328)
Epoch: 76 | Batch_idx: 160 |  Loss: (0.2917) |  Loss2: (0.0000) | Acc: (90.00%) (18576/20608)
Epoch: 76 | Batch_idx: 170 |  Loss: (0.2919) |  Loss2: (0.0000) | Acc: (90.00%) (19736/21888)
Epoch: 76 | Batch_idx: 180 |  Loss: (0.2919) |  Loss2: (0.0000) | Acc: (90.00%) (20887/23168)
Epoch: 76 | Batch_idx: 190 |  Loss: (0.2911) |  Loss2: (0.0000) | Acc: (90.00%) (22060/24448)
Epoch: 76 | Batch_idx: 200 |  Loss: (0.2914) |  Loss2: (0.0000) | Acc: (90.00%) (23206/25728)
Epoch: 76 | Batch_idx: 210 |  Loss: (0.2945) |  Loss2: (0.0000) | Acc: (90.00%) (24326/27008)
Epoch: 76 | Batch_idx: 220 |  Loss: (0.2946) |  Loss2: (0.0000) | Acc: (90.00%) (25468/28288)
Epoch: 76 | Batch_idx: 230 |  Loss: (0.2950) |  Loss2: (0.0000) | Acc: (90.00%) (26615/29568)
Epoch: 76 | Batch_idx: 240 |  Loss: (0.2950) |  Loss2: (0.0000) | Acc: (90.00%) (27769/30848)
Epoch: 76 | Batch_idx: 250 |  Loss: (0.2958) |  Loss2: (0.0000) | Acc: (89.00%) (28908/32128)
Epoch: 76 | Batch_idx: 260 |  Loss: (0.2956) |  Loss2: (0.0000) | Acc: (89.00%) (30062/33408)
Epoch: 76 | Batch_idx: 270 |  Loss: (0.2961) |  Loss2: (0.0000) | Acc: (89.00%) (31211/34688)
Epoch: 76 | Batch_idx: 280 |  Loss: (0.2958) |  Loss2: (0.0000) | Acc: (90.00%) (32372/35968)
Epoch: 76 | Batch_idx: 290 |  Loss: (0.2952) |  Loss2: (0.0000) | Acc: (89.00%) (33516/37248)
Epoch: 76 | Batch_idx: 300 |  Loss: (0.2944) |  Loss2: (0.0000) | Acc: (89.00%) (34667/38528)
Epoch: 76 | Batch_idx: 310 |  Loss: (0.2938) |  Loss2: (0.0000) | Acc: (90.00%) (35834/39808)
Epoch: 76 | Batch_idx: 320 |  Loss: (0.2934) |  Loss2: (0.0000) | Acc: (90.00%) (36992/41088)
Epoch: 76 | Batch_idx: 330 |  Loss: (0.2923) |  Loss2: (0.0000) | Acc: (90.00%) (38156/42368)
Epoch: 76 | Batch_idx: 340 |  Loss: (0.2937) |  Loss2: (0.0000) | Acc: (90.00%) (39297/43648)
Epoch: 76 | Batch_idx: 350 |  Loss: (0.2938) |  Loss2: (0.0000) | Acc: (90.00%) (40444/44928)
Epoch: 76 | Batch_idx: 360 |  Loss: (0.2948) |  Loss2: (0.0000) | Acc: (89.00%) (41584/46208)
Epoch: 76 | Batch_idx: 370 |  Loss: (0.2942) |  Loss2: (0.0000) | Acc: (89.00%) (42734/47488)
Epoch: 76 | Batch_idx: 380 |  Loss: (0.2955) |  Loss2: (0.0000) | Acc: (89.00%) (43866/48768)
Epoch: 76 | Batch_idx: 390 |  Loss: (0.2956) |  Loss2: (0.0000) | Acc: (89.00%) (44977/50000)
# TEST : Loss: (0.4735) | Acc: (84.00%) (8463/10000)
percent tensor([0.5062, 0.4978, 0.5061, 0.4997, 0.5065, 0.5135, 0.5024, 0.5006, 0.5050,
        0.5002, 0.5063, 0.5032, 0.4984, 0.5031, 0.5026, 0.5042],
       device='cuda:0') torch.Size([16])
percent tensor([0.5135, 0.5069, 0.5189, 0.5180, 0.5186, 0.5154, 0.5106, 0.5198, 0.5172,
        0.5095, 0.5133, 0.5108, 0.5068, 0.5171, 0.5101, 0.5144],
       device='cuda:0') torch.Size([16])
percent tensor([0.5187, 0.5177, 0.5483, 0.5494, 0.5564, 0.5179, 0.5301, 0.5528, 0.5244,
        0.5243, 0.5129, 0.5325, 0.4981, 0.5500, 0.5148, 0.5273],
       device='cuda:0') torch.Size([16])
percent tensor([0.6004, 0.6166, 0.5937, 0.5880, 0.5895, 0.5953, 0.6116, 0.5934, 0.6128,
        0.6185, 0.6225, 0.6053, 0.6105, 0.6276, 0.5982, 0.6104],
       device='cuda:0') torch.Size([16])
percent tensor([0.5448, 0.5616, 0.4377, 0.5108, 0.4545, 0.5704, 0.5291, 0.4023, 0.6021,
        0.5616, 0.6241, 0.5049, 0.5621, 0.6148, 0.5112, 0.5647],
       device='cuda:0') torch.Size([16])
percent tensor([0.5889, 0.5813, 0.5974, 0.5876, 0.6224, 0.6006, 0.5937, 0.6213, 0.5792,
        0.5791, 0.5586, 0.5627, 0.5693, 0.5713, 0.5769, 0.6024],
       device='cuda:0') torch.Size([16])
percent tensor([0.5248, 0.5955, 0.6999, 0.6610, 0.7513, 0.7126, 0.5813, 0.7102, 0.6213,
        0.5706, 0.6104, 0.6011, 0.5866, 0.6071, 0.5583, 0.5522],
       device='cuda:0') torch.Size([16])
percent tensor([0.9974, 0.9962, 0.9975, 0.9979, 0.9954, 0.9975, 0.9959, 0.9992, 0.9987,
        0.9972, 0.9990, 0.9978, 0.9980, 0.9955, 0.9979, 0.9971],
       device='cuda:0') torch.Size([16])
Epoch: 77 | Batch_idx: 0 |  Loss: (0.2860) |  Loss2: (0.0000) | Acc: (89.00%) (114/128)
Epoch: 77 | Batch_idx: 10 |  Loss: (0.2789) |  Loss2: (0.0000) | Acc: (89.00%) (1265/1408)
Epoch: 77 | Batch_idx: 20 |  Loss: (0.2718) |  Loss2: (0.0000) | Acc: (90.00%) (2427/2688)
Epoch: 77 | Batch_idx: 30 |  Loss: (0.2808) |  Loss2: (0.0000) | Acc: (89.00%) (3568/3968)
Epoch: 77 | Batch_idx: 40 |  Loss: (0.2836) |  Loss2: (0.0000) | Acc: (90.00%) (4729/5248)
Epoch: 77 | Batch_idx: 50 |  Loss: (0.2812) |  Loss2: (0.0000) | Acc: (90.00%) (5885/6528)
Epoch: 77 | Batch_idx: 60 |  Loss: (0.2849) |  Loss2: (0.0000) | Acc: (89.00%) (7023/7808)
Epoch: 77 | Batch_idx: 70 |  Loss: (0.2852) |  Loss2: (0.0000) | Acc: (90.00%) (8180/9088)
Epoch: 77 | Batch_idx: 80 |  Loss: (0.2812) |  Loss2: (0.0000) | Acc: (90.00%) (9350/10368)
Epoch: 77 | Batch_idx: 90 |  Loss: (0.2830) |  Loss2: (0.0000) | Acc: (90.00%) (10502/11648)
Epoch: 77 | Batch_idx: 100 |  Loss: (0.2815) |  Loss2: (0.0000) | Acc: (90.00%) (11662/12928)
Epoch: 77 | Batch_idx: 110 |  Loss: (0.2826) |  Loss2: (0.0000) | Acc: (90.00%) (12816/14208)
Epoch: 77 | Batch_idx: 120 |  Loss: (0.2839) |  Loss2: (0.0000) | Acc: (90.00%) (13957/15488)
Epoch: 77 | Batch_idx: 130 |  Loss: (0.2840) |  Loss2: (0.0000) | Acc: (90.00%) (15109/16768)
Epoch: 77 | Batch_idx: 140 |  Loss: (0.2865) |  Loss2: (0.0000) | Acc: (90.00%) (16257/18048)
Epoch: 77 | Batch_idx: 150 |  Loss: (0.2882) |  Loss2: (0.0000) | Acc: (90.00%) (17399/19328)
Epoch: 77 | Batch_idx: 160 |  Loss: (0.2880) |  Loss2: (0.0000) | Acc: (90.00%) (18556/20608)
Epoch: 77 | Batch_idx: 170 |  Loss: (0.2864) |  Loss2: (0.0000) | Acc: (90.00%) (19719/21888)
Epoch: 77 | Batch_idx: 180 |  Loss: (0.2849) |  Loss2: (0.0000) | Acc: (90.00%) (20881/23168)
Epoch: 77 | Batch_idx: 190 |  Loss: (0.2866) |  Loss2: (0.0000) | Acc: (90.00%) (22014/24448)
Epoch: 77 | Batch_idx: 200 |  Loss: (0.2877) |  Loss2: (0.0000) | Acc: (90.00%) (23164/25728)
Epoch: 77 | Batch_idx: 210 |  Loss: (0.2856) |  Loss2: (0.0000) | Acc: (90.00%) (24338/27008)
Epoch: 77 | Batch_idx: 220 |  Loss: (0.2869) |  Loss2: (0.0000) | Acc: (90.00%) (25473/28288)
Epoch: 77 | Batch_idx: 230 |  Loss: (0.2877) |  Loss2: (0.0000) | Acc: (90.00%) (26619/29568)
Epoch: 77 | Batch_idx: 240 |  Loss: (0.2874) |  Loss2: (0.0000) | Acc: (90.00%) (27774/30848)
Epoch: 77 | Batch_idx: 250 |  Loss: (0.2873) |  Loss2: (0.0000) | Acc: (90.00%) (28924/32128)
Epoch: 77 | Batch_idx: 260 |  Loss: (0.2885) |  Loss2: (0.0000) | Acc: (89.00%) (30057/33408)
Epoch: 77 | Batch_idx: 270 |  Loss: (0.2893) |  Loss2: (0.0000) | Acc: (89.00%) (31191/34688)
Epoch: 77 | Batch_idx: 280 |  Loss: (0.2895) |  Loss2: (0.0000) | Acc: (89.00%) (32345/35968)
Epoch: 77 | Batch_idx: 290 |  Loss: (0.2901) |  Loss2: (0.0000) | Acc: (89.00%) (33488/37248)
Epoch: 77 | Batch_idx: 300 |  Loss: (0.2899) |  Loss2: (0.0000) | Acc: (89.00%) (34652/38528)
Epoch: 77 | Batch_idx: 310 |  Loss: (0.2898) |  Loss2: (0.0000) | Acc: (89.00%) (35809/39808)
Epoch: 77 | Batch_idx: 320 |  Loss: (0.2904) |  Loss2: (0.0000) | Acc: (89.00%) (36955/41088)
Epoch: 77 | Batch_idx: 330 |  Loss: (0.2904) |  Loss2: (0.0000) | Acc: (89.00%) (38106/42368)
Epoch: 77 | Batch_idx: 340 |  Loss: (0.2896) |  Loss2: (0.0000) | Acc: (89.00%) (39266/43648)
Epoch: 77 | Batch_idx: 350 |  Loss: (0.2896) |  Loss2: (0.0000) | Acc: (89.00%) (40411/44928)
Epoch: 77 | Batch_idx: 360 |  Loss: (0.2889) |  Loss2: (0.0000) | Acc: (89.00%) (41577/46208)
Epoch: 77 | Batch_idx: 370 |  Loss: (0.2884) |  Loss2: (0.0000) | Acc: (89.00%) (42736/47488)
Epoch: 77 | Batch_idx: 380 |  Loss: (0.2884) |  Loss2: (0.0000) | Acc: (89.00%) (43889/48768)
Epoch: 77 | Batch_idx: 390 |  Loss: (0.2891) |  Loss2: (0.0000) | Acc: (89.00%) (44980/50000)
# TEST : Loss: (0.4569) | Acc: (84.00%) (8493/10000)
percent tensor([0.5066, 0.4978, 0.5041, 0.4995, 0.5046, 0.5134, 0.5017, 0.5005, 0.5055,
        0.5004, 0.5068, 0.5013, 0.4990, 0.5034, 0.5026, 0.5049],
       device='cuda:0') torch.Size([16])
percent tensor([0.5132, 0.5069, 0.5152, 0.5168, 0.5159, 0.5141, 0.5104, 0.5191, 0.5169,
        0.5083, 0.5130, 0.5077, 0.5057, 0.5176, 0.5097, 0.5142],
       device='cuda:0') torch.Size([16])
percent tensor([0.5178, 0.5219, 0.5238, 0.5430, 0.5388, 0.5132, 0.5353, 0.5497, 0.5276,
        0.5250, 0.5187, 0.5231, 0.4981, 0.5651, 0.5150, 0.5307],
       device='cuda:0') torch.Size([16])
percent tensor([0.6027, 0.6169, 0.5963, 0.5931, 0.5915, 0.5948, 0.6160, 0.5922, 0.6113,
        0.6198, 0.6241, 0.6118, 0.6127, 0.6276, 0.5987, 0.6118],
       device='cuda:0') torch.Size([16])
percent tensor([0.5406, 0.5566, 0.4700, 0.5346, 0.4697, 0.5678, 0.5271, 0.4039, 0.5897,
        0.5591, 0.6210, 0.5170, 0.5596, 0.6092, 0.5058, 0.5597],
       device='cuda:0') torch.Size([16])
percent tensor([0.5881, 0.5831, 0.5916, 0.5849, 0.6241, 0.6000, 0.5945, 0.6281, 0.5847,
        0.5796, 0.5614, 0.5554, 0.5741, 0.5756, 0.5776, 0.6092],
       device='cuda:0') torch.Size([16])
percent tensor([0.5144, 0.5733, 0.7243, 0.6577, 0.7637, 0.7176, 0.5730, 0.7204, 0.6264,
        0.5590, 0.5967, 0.5982, 0.5723, 0.5689, 0.5601, 0.5491],
       device='cuda:0') torch.Size([16])
percent tensor([0.9978, 0.9955, 0.9986, 0.9983, 0.9981, 0.9979, 0.9971, 0.9990, 0.9978,
        0.9977, 0.9988, 0.9974, 0.9983, 0.9952, 0.9977, 0.9979],
       device='cuda:0') torch.Size([16])
Epoch: 78 | Batch_idx: 0 |  Loss: (0.2568) |  Loss2: (0.0000) | Acc: (89.00%) (115/128)
Epoch: 78 | Batch_idx: 10 |  Loss: (0.2582) |  Loss2: (0.0000) | Acc: (90.00%) (1272/1408)
Epoch: 78 | Batch_idx: 20 |  Loss: (0.2650) |  Loss2: (0.0000) | Acc: (90.00%) (2430/2688)
Epoch: 78 | Batch_idx: 30 |  Loss: (0.2696) |  Loss2: (0.0000) | Acc: (90.00%) (3591/3968)
Epoch: 78 | Batch_idx: 40 |  Loss: (0.2770) |  Loss2: (0.0000) | Acc: (90.00%) (4735/5248)
Epoch: 78 | Batch_idx: 50 |  Loss: (0.2762) |  Loss2: (0.0000) | Acc: (90.00%) (5884/6528)
Epoch: 78 | Batch_idx: 60 |  Loss: (0.2806) |  Loss2: (0.0000) | Acc: (90.00%) (7029/7808)
Epoch: 78 | Batch_idx: 70 |  Loss: (0.2805) |  Loss2: (0.0000) | Acc: (89.00%) (8179/9088)
Epoch: 78 | Batch_idx: 80 |  Loss: (0.2812) |  Loss2: (0.0000) | Acc: (90.00%) (9343/10368)
Epoch: 78 | Batch_idx: 90 |  Loss: (0.2800) |  Loss2: (0.0000) | Acc: (90.00%) (10505/11648)
Epoch: 78 | Batch_idx: 100 |  Loss: (0.2786) |  Loss2: (0.0000) | Acc: (90.00%) (11675/12928)
Epoch: 78 | Batch_idx: 110 |  Loss: (0.2779) |  Loss2: (0.0000) | Acc: (90.00%) (12827/14208)
Epoch: 78 | Batch_idx: 120 |  Loss: (0.2800) |  Loss2: (0.0000) | Acc: (90.00%) (13981/15488)
Epoch: 78 | Batch_idx: 130 |  Loss: (0.2802) |  Loss2: (0.0000) | Acc: (90.00%) (15141/16768)
Epoch: 78 | Batch_idx: 140 |  Loss: (0.2787) |  Loss2: (0.0000) | Acc: (90.00%) (16310/18048)
Epoch: 78 | Batch_idx: 150 |  Loss: (0.2775) |  Loss2: (0.0000) | Acc: (90.00%) (17473/19328)
Epoch: 78 | Batch_idx: 160 |  Loss: (0.2781) |  Loss2: (0.0000) | Acc: (90.00%) (18618/20608)
Epoch: 78 | Batch_idx: 170 |  Loss: (0.2795) |  Loss2: (0.0000) | Acc: (90.00%) (19758/21888)
Epoch: 78 | Batch_idx: 180 |  Loss: (0.2814) |  Loss2: (0.0000) | Acc: (90.00%) (20904/23168)
Epoch: 78 | Batch_idx: 190 |  Loss: (0.2813) |  Loss2: (0.0000) | Acc: (90.00%) (22054/24448)
Epoch: 78 | Batch_idx: 200 |  Loss: (0.2826) |  Loss2: (0.0000) | Acc: (90.00%) (23194/25728)
Epoch: 78 | Batch_idx: 210 |  Loss: (0.2830) |  Loss2: (0.0000) | Acc: (90.00%) (24348/27008)
Epoch: 78 | Batch_idx: 220 |  Loss: (0.2836) |  Loss2: (0.0000) | Acc: (90.00%) (25497/28288)
Epoch: 78 | Batch_idx: 230 |  Loss: (0.2842) |  Loss2: (0.0000) | Acc: (90.00%) (26650/29568)
Epoch: 78 | Batch_idx: 240 |  Loss: (0.2829) |  Loss2: (0.0000) | Acc: (90.00%) (27821/30848)
Epoch: 78 | Batch_idx: 250 |  Loss: (0.2831) |  Loss2: (0.0000) | Acc: (90.00%) (28979/32128)
Epoch: 78 | Batch_idx: 260 |  Loss: (0.2829) |  Loss2: (0.0000) | Acc: (90.00%) (30127/33408)
Epoch: 78 | Batch_idx: 270 |  Loss: (0.2833) |  Loss2: (0.0000) | Acc: (90.00%) (31274/34688)
Epoch: 78 | Batch_idx: 280 |  Loss: (0.2831) |  Loss2: (0.0000) | Acc: (90.00%) (32427/35968)
Epoch: 78 | Batch_idx: 290 |  Loss: (0.2841) |  Loss2: (0.0000) | Acc: (90.00%) (33567/37248)
Epoch: 78 | Batch_idx: 300 |  Loss: (0.2838) |  Loss2: (0.0000) | Acc: (90.00%) (34725/38528)
Epoch: 78 | Batch_idx: 310 |  Loss: (0.2841) |  Loss2: (0.0000) | Acc: (90.00%) (35879/39808)
Epoch: 78 | Batch_idx: 320 |  Loss: (0.2845) |  Loss2: (0.0000) | Acc: (90.00%) (37036/41088)
Epoch: 78 | Batch_idx: 330 |  Loss: (0.2840) |  Loss2: (0.0000) | Acc: (90.00%) (38192/42368)
Epoch: 78 | Batch_idx: 340 |  Loss: (0.2843) |  Loss2: (0.0000) | Acc: (90.00%) (39338/43648)
Epoch: 78 | Batch_idx: 350 |  Loss: (0.2844) |  Loss2: (0.0000) | Acc: (90.00%) (40485/44928)
Epoch: 78 | Batch_idx: 360 |  Loss: (0.2847) |  Loss2: (0.0000) | Acc: (90.00%) (41636/46208)
Epoch: 78 | Batch_idx: 370 |  Loss: (0.2861) |  Loss2: (0.0000) | Acc: (90.00%) (42759/47488)
Epoch: 78 | Batch_idx: 380 |  Loss: (0.2846) |  Loss2: (0.0000) | Acc: (90.00%) (43931/48768)
Epoch: 78 | Batch_idx: 390 |  Loss: (0.2848) |  Loss2: (0.0000) | Acc: (90.00%) (45046/50000)
# TEST : Loss: (0.5401) | Acc: (83.00%) (8341/10000)
percent tensor([0.5075, 0.4977, 0.5056, 0.4998, 0.5067, 0.5143, 0.5024, 0.5002, 0.5056,
        0.5009, 0.5068, 0.5030, 0.4997, 0.5027, 0.5029, 0.5052],
       device='cuda:0') torch.Size([16])
percent tensor([0.5135, 0.5061, 0.5167, 0.5174, 0.5170, 0.5152, 0.5099, 0.5187, 0.5166,
        0.5088, 0.5129, 0.5092, 0.5060, 0.5168, 0.5098, 0.5141],
       device='cuda:0') torch.Size([16])
percent tensor([0.5218, 0.5180, 0.5298, 0.5479, 0.5454, 0.5244, 0.5293, 0.5478, 0.5245,
        0.5219, 0.5161, 0.5223, 0.4976, 0.5557, 0.5178, 0.5319],
       device='cuda:0') torch.Size([16])
percent tensor([0.6008, 0.6200, 0.5930, 0.5896, 0.5896, 0.5972, 0.6149, 0.5913, 0.6095,
        0.6231, 0.6203, 0.6083, 0.6100, 0.6289, 0.6008, 0.6108],
       device='cuda:0') torch.Size([16])
percent tensor([0.5381, 0.5576, 0.4621, 0.5262, 0.4627, 0.5644, 0.5278, 0.4082, 0.5901,
        0.5644, 0.6132, 0.5222, 0.5589, 0.6127, 0.5121, 0.5515],
       device='cuda:0') torch.Size([16])
percent tensor([0.5898, 0.5793, 0.5856, 0.5867, 0.6219, 0.6092, 0.5907, 0.6209, 0.5755,
        0.5763, 0.5639, 0.5509, 0.5621, 0.5732, 0.5759, 0.6128],
       device='cuda:0') torch.Size([16])
percent tensor([0.5138, 0.5847, 0.6816, 0.6425, 0.7476, 0.6952, 0.5619, 0.6875, 0.6160,
        0.5531, 0.5966, 0.5853, 0.5668, 0.6036, 0.5361, 0.5307],
       device='cuda:0') torch.Size([16])
percent tensor([0.9981, 0.9970, 0.9972, 0.9984, 0.9976, 0.9964, 0.9962, 0.9985, 0.9990,
        0.9982, 0.9989, 0.9983, 0.9992, 0.9959, 0.9985, 0.9980],
       device='cuda:0') torch.Size([16])
Epoch: 79 | Batch_idx: 0 |  Loss: (0.1547) |  Loss2: (0.0000) | Acc: (95.00%) (122/128)
Epoch: 79 | Batch_idx: 10 |  Loss: (0.2491) |  Loss2: (0.0000) | Acc: (91.00%) (1293/1408)
Epoch: 79 | Batch_idx: 20 |  Loss: (0.2616) |  Loss2: (0.0000) | Acc: (90.00%) (2444/2688)
Epoch: 79 | Batch_idx: 30 |  Loss: (0.2526) |  Loss2: (0.0000) | Acc: (91.00%) (3625/3968)
Epoch: 79 | Batch_idx: 40 |  Loss: (0.2494) |  Loss2: (0.0000) | Acc: (91.00%) (4796/5248)
Epoch: 79 | Batch_idx: 50 |  Loss: (0.2536) |  Loss2: (0.0000) | Acc: (91.00%) (5957/6528)
Epoch: 79 | Batch_idx: 60 |  Loss: (0.2577) |  Loss2: (0.0000) | Acc: (91.00%) (7124/7808)
Epoch: 79 | Batch_idx: 70 |  Loss: (0.2670) |  Loss2: (0.0000) | Acc: (90.00%) (8260/9088)
Epoch: 79 | Batch_idx: 80 |  Loss: (0.2713) |  Loss2: (0.0000) | Acc: (90.00%) (9409/10368)
Epoch: 79 | Batch_idx: 90 |  Loss: (0.2739) |  Loss2: (0.0000) | Acc: (90.00%) (10550/11648)
Epoch: 79 | Batch_idx: 100 |  Loss: (0.2738) |  Loss2: (0.0000) | Acc: (90.00%) (11715/12928)
Epoch: 79 | Batch_idx: 110 |  Loss: (0.2759) |  Loss2: (0.0000) | Acc: (90.00%) (12865/14208)
Epoch: 79 | Batch_idx: 120 |  Loss: (0.2779) |  Loss2: (0.0000) | Acc: (90.00%) (14016/15488)
Epoch: 79 | Batch_idx: 130 |  Loss: (0.2797) |  Loss2: (0.0000) | Acc: (90.00%) (15156/16768)
Epoch: 79 | Batch_idx: 140 |  Loss: (0.2805) |  Loss2: (0.0000) | Acc: (90.00%) (16301/18048)
Epoch: 79 | Batch_idx: 150 |  Loss: (0.2806) |  Loss2: (0.0000) | Acc: (90.00%) (17452/19328)
Epoch: 79 | Batch_idx: 160 |  Loss: (0.2807) |  Loss2: (0.0000) | Acc: (90.00%) (18606/20608)
Epoch: 79 | Batch_idx: 170 |  Loss: (0.2805) |  Loss2: (0.0000) | Acc: (90.00%) (19766/21888)
Epoch: 79 | Batch_idx: 180 |  Loss: (0.2810) |  Loss2: (0.0000) | Acc: (90.00%) (20918/23168)
Epoch: 79 | Batch_idx: 190 |  Loss: (0.2802) |  Loss2: (0.0000) | Acc: (90.00%) (22084/24448)
Epoch: 79 | Batch_idx: 200 |  Loss: (0.2800) |  Loss2: (0.0000) | Acc: (90.00%) (23237/25728)
Epoch: 79 | Batch_idx: 210 |  Loss: (0.2798) |  Loss2: (0.0000) | Acc: (90.00%) (24401/27008)
Epoch: 79 | Batch_idx: 220 |  Loss: (0.2812) |  Loss2: (0.0000) | Acc: (90.00%) (25537/28288)
Epoch: 79 | Batch_idx: 230 |  Loss: (0.2807) |  Loss2: (0.0000) | Acc: (90.00%) (26692/29568)
Epoch: 79 | Batch_idx: 240 |  Loss: (0.2807) |  Loss2: (0.0000) | Acc: (90.00%) (27849/30848)
Epoch: 79 | Batch_idx: 250 |  Loss: (0.2822) |  Loss2: (0.0000) | Acc: (90.00%) (28987/32128)
Epoch: 79 | Batch_idx: 260 |  Loss: (0.2817) |  Loss2: (0.0000) | Acc: (90.00%) (30151/33408)
Epoch: 79 | Batch_idx: 270 |  Loss: (0.2818) |  Loss2: (0.0000) | Acc: (90.00%) (31306/34688)
Epoch: 79 | Batch_idx: 280 |  Loss: (0.2814) |  Loss2: (0.0000) | Acc: (90.00%) (32484/35968)
Epoch: 79 | Batch_idx: 290 |  Loss: (0.2819) |  Loss2: (0.0000) | Acc: (90.00%) (33623/37248)
Epoch: 79 | Batch_idx: 300 |  Loss: (0.2810) |  Loss2: (0.0000) | Acc: (90.00%) (34787/38528)
Epoch: 79 | Batch_idx: 310 |  Loss: (0.2813) |  Loss2: (0.0000) | Acc: (90.00%) (35942/39808)
Epoch: 79 | Batch_idx: 320 |  Loss: (0.2806) |  Loss2: (0.0000) | Acc: (90.00%) (37109/41088)
Epoch: 79 | Batch_idx: 330 |  Loss: (0.2818) |  Loss2: (0.0000) | Acc: (90.00%) (38246/42368)
Epoch: 79 | Batch_idx: 340 |  Loss: (0.2825) |  Loss2: (0.0000) | Acc: (90.00%) (39390/43648)
Epoch: 79 | Batch_idx: 350 |  Loss: (0.2827) |  Loss2: (0.0000) | Acc: (90.00%) (40535/44928)
Epoch: 79 | Batch_idx: 360 |  Loss: (0.2829) |  Loss2: (0.0000) | Acc: (90.00%) (41692/46208)
Epoch: 79 | Batch_idx: 370 |  Loss: (0.2822) |  Loss2: (0.0000) | Acc: (90.00%) (42852/47488)
Epoch: 79 | Batch_idx: 380 |  Loss: (0.2819) |  Loss2: (0.0000) | Acc: (90.00%) (44010/48768)
Epoch: 79 | Batch_idx: 390 |  Loss: (0.2819) |  Loss2: (0.0000) | Acc: (90.00%) (45125/50000)
# TEST : Loss: (0.4657) | Acc: (84.00%) (8499/10000)
percent tensor([0.5063, 0.4971, 0.5065, 0.4994, 0.5080, 0.5132, 0.5030, 0.5004, 0.5059,
        0.5010, 0.5066, 0.5046, 0.4988, 0.5027, 0.5022, 0.5041],
       device='cuda:0') torch.Size([16])
percent tensor([0.5141, 0.5054, 0.5189, 0.5182, 0.5186, 0.5152, 0.5101, 0.5206, 0.5178,
        0.5085, 0.5127, 0.5108, 0.5066, 0.5159, 0.5097, 0.5138],
       device='cuda:0') torch.Size([16])
percent tensor([0.5223, 0.5141, 0.5400, 0.5516, 0.5496, 0.5239, 0.5267, 0.5530, 0.5299,
        0.5216, 0.5126, 0.5270, 0.4989, 0.5487, 0.5159, 0.5303],
       device='cuda:0') torch.Size([16])
percent tensor([0.6023, 0.6167, 0.5932, 0.5902, 0.5901, 0.5962, 0.6114, 0.5911, 0.6100,
        0.6204, 0.6226, 0.6068, 0.6115, 0.6215, 0.5991, 0.6108],
       device='cuda:0') torch.Size([16])
percent tensor([0.5416, 0.5584, 0.4483, 0.5305, 0.4587, 0.5714, 0.5253, 0.4056, 0.5888,
        0.5588, 0.6217, 0.5080, 0.5636, 0.6016, 0.5119, 0.5522],
       device='cuda:0') torch.Size([16])
percent tensor([0.5843, 0.5724, 0.5927, 0.5888, 0.6208, 0.6004, 0.5867, 0.6173, 0.5805,
        0.5776, 0.5568, 0.5556, 0.5670, 0.5703, 0.5741, 0.6061],
       device='cuda:0') torch.Size([16])
percent tensor([0.5181, 0.5896, 0.6954, 0.6544, 0.7587, 0.6844, 0.5707, 0.6999, 0.6236,
        0.5764, 0.6111, 0.6197, 0.5775, 0.6013, 0.5608, 0.5264],
       device='cuda:0') torch.Size([16])
percent tensor([0.9973, 0.9978, 0.9979, 0.9980, 0.9974, 0.9970, 0.9954, 0.9989, 0.9981,
        0.9976, 0.9991, 0.9984, 0.9979, 0.9942, 0.9986, 0.9969],
       device='cuda:0') torch.Size([16])
Epoch: 80 | Batch_idx: 0 |  Loss: (0.2223) |  Loss2: (0.0000) | Acc: (93.00%) (120/128)
Epoch: 80 | Batch_idx: 10 |  Loss: (0.2528) |  Loss2: (0.0000) | Acc: (91.00%) (1292/1408)
Epoch: 80 | Batch_idx: 20 |  Loss: (0.2655) |  Loss2: (0.0000) | Acc: (90.00%) (2427/2688)
Epoch: 80 | Batch_idx: 30 |  Loss: (0.2789) |  Loss2: (0.0000) | Acc: (89.00%) (3569/3968)
Epoch: 80 | Batch_idx: 40 |  Loss: (0.2813) |  Loss2: (0.0000) | Acc: (89.00%) (4719/5248)
Epoch: 80 | Batch_idx: 50 |  Loss: (0.2851) |  Loss2: (0.0000) | Acc: (89.00%) (5858/6528)
Epoch: 80 | Batch_idx: 60 |  Loss: (0.2815) |  Loss2: (0.0000) | Acc: (89.00%) (7019/7808)
Epoch: 80 | Batch_idx: 70 |  Loss: (0.2795) |  Loss2: (0.0000) | Acc: (90.00%) (8183/9088)
Epoch: 80 | Batch_idx: 80 |  Loss: (0.2809) |  Loss2: (0.0000) | Acc: (90.00%) (9336/10368)
Epoch: 80 | Batch_idx: 90 |  Loss: (0.2763) |  Loss2: (0.0000) | Acc: (90.00%) (10507/11648)
Epoch: 80 | Batch_idx: 100 |  Loss: (0.2758) |  Loss2: (0.0000) | Acc: (90.00%) (11671/12928)
Epoch: 80 | Batch_idx: 110 |  Loss: (0.2782) |  Loss2: (0.0000) | Acc: (90.00%) (12808/14208)
Epoch: 80 | Batch_idx: 120 |  Loss: (0.2771) |  Loss2: (0.0000) | Acc: (90.00%) (13971/15488)
Epoch: 80 | Batch_idx: 130 |  Loss: (0.2762) |  Loss2: (0.0000) | Acc: (90.00%) (15142/16768)
Epoch: 80 | Batch_idx: 140 |  Loss: (0.2758) |  Loss2: (0.0000) | Acc: (90.00%) (16301/18048)
Epoch: 80 | Batch_idx: 150 |  Loss: (0.2758) |  Loss2: (0.0000) | Acc: (90.00%) (17453/19328)
Epoch: 80 | Batch_idx: 160 |  Loss: (0.2752) |  Loss2: (0.0000) | Acc: (90.00%) (18625/20608)
Epoch: 80 | Batch_idx: 170 |  Loss: (0.2742) |  Loss2: (0.0000) | Acc: (90.00%) (19795/21888)
Epoch: 80 | Batch_idx: 180 |  Loss: (0.2741) |  Loss2: (0.0000) | Acc: (90.00%) (20954/23168)
Epoch: 80 | Batch_idx: 190 |  Loss: (0.2725) |  Loss2: (0.0000) | Acc: (90.00%) (22131/24448)
Epoch: 80 | Batch_idx: 200 |  Loss: (0.2731) |  Loss2: (0.0000) | Acc: (90.00%) (23265/25728)
Epoch: 80 | Batch_idx: 210 |  Loss: (0.2728) |  Loss2: (0.0000) | Acc: (90.00%) (24424/27008)
Epoch: 80 | Batch_idx: 220 |  Loss: (0.2718) |  Loss2: (0.0000) | Acc: (90.00%) (25590/28288)
Epoch: 80 | Batch_idx: 230 |  Loss: (0.2699) |  Loss2: (0.0000) | Acc: (90.00%) (26772/29568)
Epoch: 80 | Batch_idx: 240 |  Loss: (0.2687) |  Loss2: (0.0000) | Acc: (90.00%) (27945/30848)
Epoch: 80 | Batch_idx: 250 |  Loss: (0.2695) |  Loss2: (0.0000) | Acc: (90.00%) (29096/32128)
Epoch: 80 | Batch_idx: 260 |  Loss: (0.2679) |  Loss2: (0.0000) | Acc: (90.00%) (30280/33408)
Epoch: 80 | Batch_idx: 270 |  Loss: (0.2677) |  Loss2: (0.0000) | Acc: (90.00%) (31447/34688)
Epoch: 80 | Batch_idx: 280 |  Loss: (0.2682) |  Loss2: (0.0000) | Acc: (90.00%) (32606/35968)
Epoch: 80 | Batch_idx: 290 |  Loss: (0.2675) |  Loss2: (0.0000) | Acc: (90.00%) (33787/37248)
Epoch: 80 | Batch_idx: 300 |  Loss: (0.2689) |  Loss2: (0.0000) | Acc: (90.00%) (34938/38528)
Epoch: 80 | Batch_idx: 310 |  Loss: (0.2693) |  Loss2: (0.0000) | Acc: (90.00%) (36097/39808)
Epoch: 80 | Batch_idx: 320 |  Loss: (0.2707) |  Loss2: (0.0000) | Acc: (90.00%) (37234/41088)
Epoch: 80 | Batch_idx: 330 |  Loss: (0.2711) |  Loss2: (0.0000) | Acc: (90.00%) (38385/42368)
Epoch: 80 | Batch_idx: 340 |  Loss: (0.2711) |  Loss2: (0.0000) | Acc: (90.00%) (39549/43648)
Epoch: 80 | Batch_idx: 350 |  Loss: (0.2713) |  Loss2: (0.0000) | Acc: (90.00%) (40709/44928)
Epoch: 80 | Batch_idx: 360 |  Loss: (0.2714) |  Loss2: (0.0000) | Acc: (90.00%) (41874/46208)
Epoch: 80 | Batch_idx: 370 |  Loss: (0.2712) |  Loss2: (0.0000) | Acc: (90.00%) (43036/47488)
Epoch: 80 | Batch_idx: 380 |  Loss: (0.2710) |  Loss2: (0.0000) | Acc: (90.00%) (44202/48768)
Epoch: 80 | Batch_idx: 390 |  Loss: (0.2716) |  Loss2: (0.0000) | Acc: (90.00%) (45312/50000)
=> saving checkpoint 'drive/app/torch/save_Schedule/checkpoint_080.pth.tar'
# TEST : Loss: (0.4558) | Acc: (85.00%) (8546/10000)
percent tensor([0.5067, 0.4959, 0.5054, 0.5000, 0.5068, 0.5130, 0.5011, 0.5003, 0.5054,
        0.4999, 0.5061, 0.5022, 0.4991, 0.5006, 0.5014, 0.5045],
       device='cuda:0') torch.Size([16])
percent tensor([0.5140, 0.5082, 0.5166, 0.5183, 0.5176, 0.5146, 0.5121, 0.5200, 0.5172,
        0.5107, 0.5138, 0.5106, 0.5066, 0.5214, 0.5107, 0.5153],
       device='cuda:0') torch.Size([16])
percent tensor([0.5249, 0.5202, 0.5379, 0.5515, 0.5487, 0.5183, 0.5341, 0.5516, 0.5327,
        0.5281, 0.5205, 0.5292, 0.5010, 0.5651, 0.5159, 0.5337],
       device='cuda:0') torch.Size([16])
percent tensor([0.6012, 0.6119, 0.5956, 0.5906, 0.5927, 0.5933, 0.6087, 0.5914, 0.6110,
        0.6174, 0.6220, 0.6066, 0.6099, 0.6163, 0.5957, 0.6084],
       device='cuda:0') torch.Size([16])
percent tensor([0.5414, 0.5590, 0.4549, 0.5259, 0.4687, 0.5691, 0.5136, 0.4089, 0.5978,
        0.5647, 0.6240, 0.5086, 0.5686, 0.6000, 0.5081, 0.5585],
       device='cuda:0') torch.Size([16])
percent tensor([0.5924, 0.5857, 0.5880, 0.5854, 0.6166, 0.6061, 0.5985, 0.6160, 0.5804,
        0.5891, 0.5660, 0.5556, 0.5703, 0.5828, 0.5802, 0.6131],
       device='cuda:0') torch.Size([16])
percent tensor([0.5362, 0.6110, 0.7063, 0.6341, 0.7506, 0.6977, 0.6066, 0.6979, 0.6171,
        0.6131, 0.6355, 0.6042, 0.6030, 0.5906, 0.5661, 0.5504],
       device='cuda:0') torch.Size([16])
percent tensor([0.9976, 0.9975, 0.9983, 0.9975, 0.9982, 0.9978, 0.9966, 0.9990, 0.9989,
        0.9968, 0.9992, 0.9982, 0.9990, 0.9944, 0.9971, 0.9977],
       device='cuda:0') torch.Size([16])
False Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=128, out_features=16, bias=False)
True Linear(in_features=16, out_features=2, bias=False)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=128, out_features=16, bias=False)
True Linear(in_features=16, out_features=2, bias=False)
False Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=256, out_features=32, bias=False)
True Linear(in_features=32, out_features=2, bias=False)
False Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=256, out_features=32, bias=False)
True Linear(in_features=32, out_features=2, bias=False)
False Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=512, out_features=64, bias=False)
True Linear(in_features=64, out_features=2, bias=False)
False Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=512, out_features=64, bias=False)
True Linear(in_features=64, out_features=2, bias=False)
False Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1024, out_features=128, bias=False)
True Linear(in_features=128, out_features=2, bias=False)
False Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1024, out_features=128, bias=False)
True Linear(in_features=128, out_features=2, bias=False)
False Linear(in_features=512, out_features=10, bias=True)
Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 3, 3, 3]) tensor(182.3483, device='cuda:0')
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(817.4620, device='cuda:0')
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(805.8051, device='cuda:0')
Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([128, 64, 3, 3]) tensor(1531.0823, device='cuda:0')
Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([128, 64, 1, 1]) tensor(492.2448, device='cuda:0')
Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([128, 128, 3, 3]) tensor(2244.6714, device='cuda:0')
Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([256, 128, 3, 3]) tensor(4280.8535, device='cuda:0')
Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([256, 128, 1, 1]) tensor(1398.9514, device='cuda:0')
Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([256, 256, 3, 3]) tensor(6127.4619, device='cuda:0')
Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([512, 256, 3, 3]) tensor(11933.5488, device='cuda:0')
Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([512, 256, 1, 1]) tensor(3969.2107, device='cuda:0')
Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([512, 512, 3, 3]) tensor(16787.2578, device='cuda:0')
Epoch: 81 | Batch_idx: 0 |  Loss: (0.3042) |  Loss2: (0.0000) | Acc: (88.00%) (113/128)
Epoch: 81 | Batch_idx: 10 |  Loss: (0.3029) |  Loss2: (0.0000) | Acc: (89.00%) (1254/1408)
Epoch: 81 | Batch_idx: 20 |  Loss: (0.3128) |  Loss2: (0.0000) | Acc: (88.00%) (2385/2688)
Epoch: 81 | Batch_idx: 30 |  Loss: (0.3069) |  Loss2: (0.0000) | Acc: (89.00%) (3533/3968)
Epoch: 81 | Batch_idx: 40 |  Loss: (0.3070) |  Loss2: (0.0000) | Acc: (89.00%) (4693/5248)
Epoch: 81 | Batch_idx: 50 |  Loss: (0.3105) |  Loss2: (0.0000) | Acc: (89.00%) (5838/6528)
Epoch: 81 | Batch_idx: 60 |  Loss: (0.3214) |  Loss2: (0.0000) | Acc: (89.00%) (6954/7808)
Epoch: 81 | Batch_idx: 70 |  Loss: (0.3234) |  Loss2: (0.0000) | Acc: (88.00%) (8078/9088)
Epoch: 81 | Batch_idx: 80 |  Loss: (0.3243) |  Loss2: (0.0000) | Acc: (88.00%) (9204/10368)
Epoch: 81 | Batch_idx: 90 |  Loss: (0.3225) |  Loss2: (0.0000) | Acc: (88.00%) (10350/11648)
Epoch: 81 | Batch_idx: 100 |  Loss: (0.3217) |  Loss2: (0.0000) | Acc: (88.00%) (11485/12928)
Epoch: 81 | Batch_idx: 110 |  Loss: (0.3217) |  Loss2: (0.0000) | Acc: (88.00%) (12618/14208)
Epoch: 81 | Batch_idx: 120 |  Loss: (0.3226) |  Loss2: (0.0000) | Acc: (88.00%) (13754/15488)
Epoch: 81 | Batch_idx: 130 |  Loss: (0.3261) |  Loss2: (0.0000) | Acc: (88.00%) (14861/16768)
Epoch: 81 | Batch_idx: 140 |  Loss: (0.3244) |  Loss2: (0.0000) | Acc: (88.00%) (16018/18048)
Epoch: 81 | Batch_idx: 150 |  Loss: (0.3255) |  Loss2: (0.0000) | Acc: (88.00%) (17151/19328)
Epoch: 81 | Batch_idx: 160 |  Loss: (0.3271) |  Loss2: (0.0000) | Acc: (88.00%) (18267/20608)
Epoch: 81 | Batch_idx: 170 |  Loss: (0.3250) |  Loss2: (0.0000) | Acc: (88.00%) (19418/21888)
Epoch: 81 | Batch_idx: 180 |  Loss: (0.3250) |  Loss2: (0.0000) | Acc: (88.00%) (20562/23168)
Epoch: 81 | Batch_idx: 190 |  Loss: (0.3254) |  Loss2: (0.0000) | Acc: (88.00%) (21697/24448)
Epoch: 81 | Batch_idx: 200 |  Loss: (0.3237) |  Loss2: (0.0000) | Acc: (88.00%) (22835/25728)
Epoch: 81 | Batch_idx: 210 |  Loss: (0.3217) |  Loss2: (0.0000) | Acc: (88.00%) (23990/27008)
Epoch: 81 | Batch_idx: 220 |  Loss: (0.3208) |  Loss2: (0.0000) | Acc: (88.00%) (25128/28288)
Epoch: 81 | Batch_idx: 230 |  Loss: (0.3206) |  Loss2: (0.0000) | Acc: (88.00%) (26263/29568)
Epoch: 81 | Batch_idx: 240 |  Loss: (0.3181) |  Loss2: (0.0000) | Acc: (88.00%) (27423/30848)
Epoch: 81 | Batch_idx: 250 |  Loss: (0.3175) |  Loss2: (0.0000) | Acc: (88.00%) (28564/32128)
Epoch: 81 | Batch_idx: 260 |  Loss: (0.3173) |  Loss2: (0.0000) | Acc: (88.00%) (29701/33408)
Epoch: 81 | Batch_idx: 270 |  Loss: (0.3173) |  Loss2: (0.0000) | Acc: (88.00%) (30839/34688)
Epoch: 81 | Batch_idx: 280 |  Loss: (0.3171) |  Loss2: (0.0000) | Acc: (88.00%) (31976/35968)
Epoch: 81 | Batch_idx: 290 |  Loss: (0.3169) |  Loss2: (0.0000) | Acc: (88.00%) (33121/37248)
Epoch: 81 | Batch_idx: 300 |  Loss: (0.3162) |  Loss2: (0.0000) | Acc: (88.00%) (34269/38528)
Epoch: 81 | Batch_idx: 310 |  Loss: (0.3152) |  Loss2: (0.0000) | Acc: (88.00%) (35418/39808)
Epoch: 81 | Batch_idx: 320 |  Loss: (0.3151) |  Loss2: (0.0000) | Acc: (89.00%) (36572/41088)
Epoch: 81 | Batch_idx: 330 |  Loss: (0.3146) |  Loss2: (0.0000) | Acc: (89.00%) (37724/42368)
Epoch: 81 | Batch_idx: 340 |  Loss: (0.3142) |  Loss2: (0.0000) | Acc: (89.00%) (38873/43648)
Epoch: 81 | Batch_idx: 350 |  Loss: (0.3140) |  Loss2: (0.0000) | Acc: (89.00%) (40025/44928)
Epoch: 81 | Batch_idx: 360 |  Loss: (0.3130) |  Loss2: (0.0000) | Acc: (89.00%) (41174/46208)
Epoch: 81 | Batch_idx: 370 |  Loss: (0.3125) |  Loss2: (0.0000) | Acc: (89.00%) (42323/47488)
Epoch: 81 | Batch_idx: 380 |  Loss: (0.3125) |  Loss2: (0.0000) | Acc: (89.00%) (43465/48768)
Epoch: 81 | Batch_idx: 390 |  Loss: (0.3117) |  Loss2: (0.0000) | Acc: (89.00%) (44580/50000)
# TEST : Loss: (0.4357) | Acc: (85.00%) (8587/10000)
percent tensor([0.5131, 0.5029, 0.5114, 0.5070, 0.5134, 0.5182, 0.5082, 0.5077, 0.5126,
        0.5072, 0.5132, 0.5091, 0.5059, 0.5079, 0.5086, 0.5114],
       device='cuda:0') torch.Size([16])
percent tensor([0.5057, 0.4990, 0.5098, 0.5100, 0.5097, 0.5070, 0.5027, 0.5107, 0.5090,
        0.5024, 0.5051, 0.5035, 0.4984, 0.5119, 0.5016, 0.5065],
       device='cuda:0') torch.Size([16])
percent tensor([0.5497, 0.5456, 0.5597, 0.5738, 0.5705, 0.5411, 0.5544, 0.5661, 0.5570,
        0.5578, 0.5495, 0.5557, 0.5278, 0.5892, 0.5391, 0.5598],
       device='cuda:0') torch.Size([16])
percent tensor([0.5651, 0.5777, 0.5605, 0.5592, 0.5561, 0.5582, 0.5709, 0.5563, 0.5763,
        0.5823, 0.5839, 0.5704, 0.5753, 0.5832, 0.5601, 0.5718],
       device='cuda:0') torch.Size([16])
percent tensor([0.5405, 0.5906, 0.4191, 0.5193, 0.4242, 0.5788, 0.5227, 0.3529, 0.6213,
        0.5939, 0.6581, 0.5135, 0.6031, 0.6366, 0.5093, 0.5629],
       device='cuda:0') torch.Size([16])
percent tensor([0.5796, 0.5679, 0.5827, 0.5826, 0.6125, 0.5954, 0.5882, 0.6163, 0.5643,
        0.5743, 0.5472, 0.5457, 0.5453, 0.5638, 0.5727, 0.5995],
       device='cuda:0') torch.Size([16])
percent tensor([0.4978, 0.5549, 0.6473, 0.6002, 0.7129, 0.6825, 0.5574, 0.6571, 0.5721,
        0.5446, 0.5969, 0.5341, 0.5538, 0.5453, 0.5217, 0.5289],
       device='cuda:0') torch.Size([16])
percent tensor([0.9979, 0.9973, 0.9983, 0.9982, 0.9978, 0.9970, 0.9966, 0.9992, 0.9988,
        0.9964, 0.9991, 0.9983, 0.9989, 0.9942, 0.9972, 0.9981],
       device='cuda:0') torch.Size([16])
Epoch: 82 | Batch_idx: 0 |  Loss: (0.4086) |  Loss2: (0.0000) | Acc: (85.00%) (110/128)
Epoch: 82 | Batch_idx: 10 |  Loss: (0.2796) |  Loss2: (0.0000) | Acc: (90.00%) (1272/1408)
Epoch: 82 | Batch_idx: 20 |  Loss: (0.2904) |  Loss2: (0.0000) | Acc: (90.00%) (2426/2688)
Epoch: 82 | Batch_idx: 30 |  Loss: (0.2869) |  Loss2: (0.0000) | Acc: (89.00%) (3566/3968)
Epoch: 82 | Batch_idx: 40 |  Loss: (0.2893) |  Loss2: (0.0000) | Acc: (89.00%) (4711/5248)
Epoch: 82 | Batch_idx: 50 |  Loss: (0.2862) |  Loss2: (0.0000) | Acc: (89.00%) (5864/6528)
Epoch: 82 | Batch_idx: 60 |  Loss: (0.2881) |  Loss2: (0.0000) | Acc: (89.00%) (7013/7808)
Epoch: 82 | Batch_idx: 70 |  Loss: (0.2896) |  Loss2: (0.0000) | Acc: (89.00%) (8170/9088)
Epoch: 82 | Batch_idx: 80 |  Loss: (0.2906) |  Loss2: (0.0000) | Acc: (89.00%) (9317/10368)
Epoch: 82 | Batch_idx: 90 |  Loss: (0.2908) |  Loss2: (0.0000) | Acc: (89.00%) (10470/11648)
Epoch: 82 | Batch_idx: 100 |  Loss: (0.2896) |  Loss2: (0.0000) | Acc: (89.00%) (11621/12928)
Epoch: 82 | Batch_idx: 110 |  Loss: (0.2915) |  Loss2: (0.0000) | Acc: (89.00%) (12771/14208)
Epoch: 82 | Batch_idx: 120 |  Loss: (0.2895) |  Loss2: (0.0000) | Acc: (89.00%) (13933/15488)
Epoch: 82 | Batch_idx: 130 |  Loss: (0.2859) |  Loss2: (0.0000) | Acc: (90.00%) (15103/16768)
Epoch: 82 | Batch_idx: 140 |  Loss: (0.2866) |  Loss2: (0.0000) | Acc: (90.00%) (16247/18048)
Epoch: 82 | Batch_idx: 150 |  Loss: (0.2847) |  Loss2: (0.0000) | Acc: (90.00%) (17419/19328)
Epoch: 82 | Batch_idx: 160 |  Loss: (0.2845) |  Loss2: (0.0000) | Acc: (90.00%) (18577/20608)
Epoch: 82 | Batch_idx: 170 |  Loss: (0.2850) |  Loss2: (0.0000) | Acc: (90.00%) (19729/21888)
Epoch: 82 | Batch_idx: 180 |  Loss: (0.2844) |  Loss2: (0.0000) | Acc: (90.00%) (20888/23168)
Epoch: 82 | Batch_idx: 190 |  Loss: (0.2844) |  Loss2: (0.0000) | Acc: (90.00%) (22048/24448)
Epoch: 82 | Batch_idx: 200 |  Loss: (0.2838) |  Loss2: (0.0000) | Acc: (90.00%) (23216/25728)
Epoch: 82 | Batch_idx: 210 |  Loss: (0.2834) |  Loss2: (0.0000) | Acc: (90.00%) (24383/27008)
Epoch: 82 | Batch_idx: 220 |  Loss: (0.2833) |  Loss2: (0.0000) | Acc: (90.00%) (25536/28288)
Epoch: 82 | Batch_idx: 230 |  Loss: (0.2828) |  Loss2: (0.0000) | Acc: (90.00%) (26704/29568)
Epoch: 82 | Batch_idx: 240 |  Loss: (0.2838) |  Loss2: (0.0000) | Acc: (90.00%) (27857/30848)
Epoch: 82 | Batch_idx: 250 |  Loss: (0.2828) |  Loss2: (0.0000) | Acc: (90.00%) (29030/32128)
Epoch: 82 | Batch_idx: 260 |  Loss: (0.2823) |  Loss2: (0.0000) | Acc: (90.00%) (30193/33408)
Epoch: 82 | Batch_idx: 270 |  Loss: (0.2817) |  Loss2: (0.0000) | Acc: (90.00%) (31365/34688)
Epoch: 82 | Batch_idx: 280 |  Loss: (0.2809) |  Loss2: (0.0000) | Acc: (90.00%) (32530/35968)
Epoch: 82 | Batch_idx: 290 |  Loss: (0.2817) |  Loss2: (0.0000) | Acc: (90.00%) (33676/37248)
Epoch: 82 | Batch_idx: 300 |  Loss: (0.2815) |  Loss2: (0.0000) | Acc: (90.00%) (34838/38528)
Epoch: 82 | Batch_idx: 310 |  Loss: (0.2805) |  Loss2: (0.0000) | Acc: (90.00%) (36002/39808)
Epoch: 82 | Batch_idx: 320 |  Loss: (0.2794) |  Loss2: (0.0000) | Acc: (90.00%) (37177/41088)
Epoch: 82 | Batch_idx: 330 |  Loss: (0.2796) |  Loss2: (0.0000) | Acc: (90.00%) (38326/42368)
Epoch: 82 | Batch_idx: 340 |  Loss: (0.2798) |  Loss2: (0.0000) | Acc: (90.00%) (39473/43648)
Epoch: 82 | Batch_idx: 350 |  Loss: (0.2794) |  Loss2: (0.0000) | Acc: (90.00%) (40633/44928)
Epoch: 82 | Batch_idx: 360 |  Loss: (0.2793) |  Loss2: (0.0000) | Acc: (90.00%) (41799/46208)
Epoch: 82 | Batch_idx: 370 |  Loss: (0.2786) |  Loss2: (0.0000) | Acc: (90.00%) (42972/47488)
Epoch: 82 | Batch_idx: 380 |  Loss: (0.2790) |  Loss2: (0.0000) | Acc: (90.00%) (44122/48768)
Epoch: 82 | Batch_idx: 390 |  Loss: (0.2791) |  Loss2: (0.0000) | Acc: (90.00%) (45233/50000)
# TEST : Loss: (0.4173) | Acc: (86.00%) (8674/10000)
percent tensor([0.5118, 0.5009, 0.5090, 0.5055, 0.5109, 0.5174, 0.5059, 0.5055, 0.5109,
        0.5049, 0.5115, 0.5064, 0.5043, 0.5063, 0.5071, 0.5100],
       device='cuda:0') torch.Size([16])
percent tensor([0.5050, 0.4982, 0.5089, 0.5091, 0.5084, 0.5064, 0.5017, 0.5093, 0.5083,
        0.5018, 0.5047, 0.5028, 0.4981, 0.5106, 0.5007, 0.5057],
       device='cuda:0') torch.Size([16])
percent tensor([0.5571, 0.5498, 0.5644, 0.5791, 0.5737, 0.5506, 0.5583, 0.5672, 0.5627,
        0.5625, 0.5576, 0.5604, 0.5337, 0.5947, 0.5441, 0.5675],
       device='cuda:0') torch.Size([16])
percent tensor([0.5694, 0.5833, 0.5650, 0.5630, 0.5602, 0.5621, 0.5764, 0.5596, 0.5811,
        0.5881, 0.5900, 0.5761, 0.5806, 0.5892, 0.5648, 0.5765],
       device='cuda:0') torch.Size([16])
percent tensor([0.5523, 0.6136, 0.4252, 0.5287, 0.4330, 0.5861, 0.5461, 0.3522, 0.6402,
        0.6152, 0.6800, 0.5358, 0.6243, 0.6602, 0.5243, 0.5753],
       device='cuda:0') torch.Size([16])
percent tensor([0.5755, 0.5609, 0.5823, 0.5824, 0.6135, 0.5921, 0.5847, 0.6181, 0.5599,
        0.5683, 0.5409, 0.5403, 0.5353, 0.5575, 0.5694, 0.5972],
       device='cuda:0') torch.Size([16])
percent tensor([0.5067, 0.5603, 0.6486, 0.6025, 0.7111, 0.7027, 0.5641, 0.6534, 0.5861,
        0.5405, 0.6052, 0.5277, 0.5630, 0.5556, 0.5226, 0.5428],
       device='cuda:0') torch.Size([16])
percent tensor([0.9981, 0.9975, 0.9983, 0.9983, 0.9978, 0.9970, 0.9971, 0.9992, 0.9990,
        0.9968, 0.9992, 0.9983, 0.9991, 0.9951, 0.9974, 0.9983],
       device='cuda:0') torch.Size([16])
Epoch: 83 | Batch_idx: 0 |  Loss: (0.2112) |  Loss2: (0.0000) | Acc: (92.00%) (119/128)
Epoch: 83 | Batch_idx: 10 |  Loss: (0.2543) |  Loss2: (0.0000) | Acc: (91.00%) (1287/1408)
Epoch: 83 | Batch_idx: 20 |  Loss: (0.2636) |  Loss2: (0.0000) | Acc: (90.00%) (2445/2688)
Epoch: 83 | Batch_idx: 30 |  Loss: (0.2677) |  Loss2: (0.0000) | Acc: (90.00%) (3602/3968)
Epoch: 83 | Batch_idx: 40 |  Loss: (0.2664) |  Loss2: (0.0000) | Acc: (90.00%) (4764/5248)
Epoch: 83 | Batch_idx: 50 |  Loss: (0.2667) |  Loss2: (0.0000) | Acc: (90.00%) (5917/6528)
Epoch: 83 | Batch_idx: 60 |  Loss: (0.2660) |  Loss2: (0.0000) | Acc: (90.00%) (7087/7808)
Epoch: 83 | Batch_idx: 70 |  Loss: (0.2705) |  Loss2: (0.0000) | Acc: (90.00%) (8230/9088)
Epoch: 83 | Batch_idx: 80 |  Loss: (0.2698) |  Loss2: (0.0000) | Acc: (90.00%) (9392/10368)
Epoch: 83 | Batch_idx: 90 |  Loss: (0.2678) |  Loss2: (0.0000) | Acc: (90.00%) (10562/11648)
Epoch: 83 | Batch_idx: 100 |  Loss: (0.2679) |  Loss2: (0.0000) | Acc: (90.00%) (11728/12928)
Epoch: 83 | Batch_idx: 110 |  Loss: (0.2675) |  Loss2: (0.0000) | Acc: (90.00%) (12897/14208)
Epoch: 83 | Batch_idx: 120 |  Loss: (0.2700) |  Loss2: (0.0000) | Acc: (90.00%) (14057/15488)
Epoch: 83 | Batch_idx: 130 |  Loss: (0.2695) |  Loss2: (0.0000) | Acc: (90.00%) (15219/16768)
Epoch: 83 | Batch_idx: 140 |  Loss: (0.2684) |  Loss2: (0.0000) | Acc: (90.00%) (16395/18048)
Epoch: 83 | Batch_idx: 150 |  Loss: (0.2705) |  Loss2: (0.0000) | Acc: (90.00%) (17537/19328)
Epoch: 83 | Batch_idx: 160 |  Loss: (0.2694) |  Loss2: (0.0000) | Acc: (90.00%) (18712/20608)
Epoch: 83 | Batch_idx: 170 |  Loss: (0.2694) |  Loss2: (0.0000) | Acc: (90.00%) (19873/21888)
Epoch: 83 | Batch_idx: 180 |  Loss: (0.2689) |  Loss2: (0.0000) | Acc: (90.00%) (21038/23168)
Epoch: 83 | Batch_idx: 190 |  Loss: (0.2675) |  Loss2: (0.0000) | Acc: (90.00%) (22214/24448)
Epoch: 83 | Batch_idx: 200 |  Loss: (0.2670) |  Loss2: (0.0000) | Acc: (90.00%) (23376/25728)
Epoch: 83 | Batch_idx: 210 |  Loss: (0.2669) |  Loss2: (0.0000) | Acc: (90.00%) (24539/27008)
Epoch: 83 | Batch_idx: 220 |  Loss: (0.2670) |  Loss2: (0.0000) | Acc: (90.00%) (25703/28288)
Epoch: 83 | Batch_idx: 230 |  Loss: (0.2667) |  Loss2: (0.0000) | Acc: (90.00%) (26869/29568)
Epoch: 83 | Batch_idx: 240 |  Loss: (0.2669) |  Loss2: (0.0000) | Acc: (90.00%) (28023/30848)
Epoch: 83 | Batch_idx: 250 |  Loss: (0.2679) |  Loss2: (0.0000) | Acc: (90.00%) (29173/32128)
Epoch: 83 | Batch_idx: 260 |  Loss: (0.2675) |  Loss2: (0.0000) | Acc: (90.00%) (30349/33408)
Epoch: 83 | Batch_idx: 270 |  Loss: (0.2665) |  Loss2: (0.0000) | Acc: (90.00%) (31532/34688)
Epoch: 83 | Batch_idx: 280 |  Loss: (0.2669) |  Loss2: (0.0000) | Acc: (90.00%) (32706/35968)
Epoch: 83 | Batch_idx: 290 |  Loss: (0.2665) |  Loss2: (0.0000) | Acc: (90.00%) (33864/37248)
Epoch: 83 | Batch_idx: 300 |  Loss: (0.2679) |  Loss2: (0.0000) | Acc: (90.00%) (34999/38528)
Epoch: 83 | Batch_idx: 310 |  Loss: (0.2681) |  Loss2: (0.0000) | Acc: (90.00%) (36163/39808)
Epoch: 83 | Batch_idx: 320 |  Loss: (0.2678) |  Loss2: (0.0000) | Acc: (90.00%) (37333/41088)
Epoch: 83 | Batch_idx: 330 |  Loss: (0.2665) |  Loss2: (0.0000) | Acc: (90.00%) (38511/42368)
Epoch: 83 | Batch_idx: 340 |  Loss: (0.2661) |  Loss2: (0.0000) | Acc: (90.00%) (39674/43648)
Epoch: 83 | Batch_idx: 350 |  Loss: (0.2658) |  Loss2: (0.0000) | Acc: (90.00%) (40839/44928)
Epoch: 83 | Batch_idx: 360 |  Loss: (0.2665) |  Loss2: (0.0000) | Acc: (90.00%) (41995/46208)
Epoch: 83 | Batch_idx: 370 |  Loss: (0.2670) |  Loss2: (0.0000) | Acc: (90.00%) (43150/47488)
Epoch: 83 | Batch_idx: 380 |  Loss: (0.2669) |  Loss2: (0.0000) | Acc: (90.00%) (44322/48768)
Epoch: 83 | Batch_idx: 390 |  Loss: (0.2660) |  Loss2: (0.0000) | Acc: (90.00%) (45457/50000)
# TEST : Loss: (0.4087) | Acc: (86.00%) (8691/10000)
percent tensor([0.5132, 0.5020, 0.5100, 0.5065, 0.5120, 0.5185, 0.5071, 0.5066, 0.5121,
        0.5059, 0.5130, 0.5073, 0.5055, 0.5075, 0.5085, 0.5114],
       device='cuda:0') torch.Size([16])
percent tensor([0.5047, 0.4979, 0.5085, 0.5085, 0.5077, 0.5060, 0.5013, 0.5087, 0.5080,
        0.5015, 0.5045, 0.5025, 0.4979, 0.5099, 0.5002, 0.5054],
       device='cuda:0') torch.Size([16])
percent tensor([0.5540, 0.5467, 0.5597, 0.5739, 0.5678, 0.5467, 0.5545, 0.5621, 0.5580,
        0.5589, 0.5545, 0.5567, 0.5312, 0.5901, 0.5401, 0.5643],
       device='cuda:0') torch.Size([16])
percent tensor([0.5745, 0.5889, 0.5700, 0.5676, 0.5651, 0.5669, 0.5821, 0.5639, 0.5858,
        0.5940, 0.5956, 0.5819, 0.5859, 0.5949, 0.5699, 0.5819],
       device='cuda:0') torch.Size([16])
percent tensor([0.5431, 0.6103, 0.4198, 0.5264, 0.4296, 0.5789, 0.5400, 0.3419, 0.6366,
        0.6099, 0.6750, 0.5322, 0.6187, 0.6588, 0.5163, 0.5664],
       device='cuda:0') torch.Size([16])
percent tensor([0.5786, 0.5619, 0.5873, 0.5880, 0.6197, 0.5948, 0.5886, 0.6254, 0.5623,
        0.5698, 0.5420, 0.5419, 0.5342, 0.5592, 0.5730, 0.6009],
       device='cuda:0') torch.Size([16])
percent tensor([0.5095, 0.5639, 0.6508, 0.6073, 0.7099, 0.7179, 0.5640, 0.6525, 0.5919,
        0.5380, 0.6108, 0.5214, 0.5669, 0.5593, 0.5225, 0.5502],
       device='cuda:0') torch.Size([16])
percent tensor([0.9984, 0.9978, 0.9986, 0.9985, 0.9982, 0.9974, 0.9976, 0.9993, 0.9991,
        0.9972, 0.9993, 0.9985, 0.9992, 0.9957, 0.9977, 0.9986],
       device='cuda:0') torch.Size([16])
Epoch: 84 | Batch_idx: 0 |  Loss: (0.2739) |  Loss2: (0.0000) | Acc: (90.00%) (116/128)
Epoch: 84 | Batch_idx: 10 |  Loss: (0.2473) |  Loss2: (0.0000) | Acc: (91.00%) (1287/1408)
Epoch: 84 | Batch_idx: 20 |  Loss: (0.2511) |  Loss2: (0.0000) | Acc: (91.00%) (2452/2688)
Epoch: 84 | Batch_idx: 30 |  Loss: (0.2540) |  Loss2: (0.0000) | Acc: (91.00%) (3619/3968)
Epoch: 84 | Batch_idx: 40 |  Loss: (0.2523) |  Loss2: (0.0000) | Acc: (91.00%) (4795/5248)
Epoch: 84 | Batch_idx: 50 |  Loss: (0.2652) |  Loss2: (0.0000) | Acc: (90.00%) (5937/6528)
Epoch: 84 | Batch_idx: 60 |  Loss: (0.2672) |  Loss2: (0.0000) | Acc: (90.00%) (7093/7808)
Epoch: 84 | Batch_idx: 70 |  Loss: (0.2650) |  Loss2: (0.0000) | Acc: (90.00%) (8264/9088)
Epoch: 84 | Batch_idx: 80 |  Loss: (0.2594) |  Loss2: (0.0000) | Acc: (91.00%) (9444/10368)
Epoch: 84 | Batch_idx: 90 |  Loss: (0.2580) |  Loss2: (0.0000) | Acc: (91.00%) (10615/11648)
Epoch: 84 | Batch_idx: 100 |  Loss: (0.2594) |  Loss2: (0.0000) | Acc: (91.00%) (11769/12928)
Epoch: 84 | Batch_idx: 110 |  Loss: (0.2606) |  Loss2: (0.0000) | Acc: (90.00%) (12929/14208)
Epoch: 84 | Batch_idx: 120 |  Loss: (0.2608) |  Loss2: (0.0000) | Acc: (90.00%) (14089/15488)
Epoch: 84 | Batch_idx: 130 |  Loss: (0.2596) |  Loss2: (0.0000) | Acc: (91.00%) (15268/16768)
Epoch: 84 | Batch_idx: 140 |  Loss: (0.2602) |  Loss2: (0.0000) | Acc: (90.00%) (16422/18048)
Epoch: 84 | Batch_idx: 150 |  Loss: (0.2594) |  Loss2: (0.0000) | Acc: (91.00%) (17603/19328)
Epoch: 84 | Batch_idx: 160 |  Loss: (0.2614) |  Loss2: (0.0000) | Acc: (91.00%) (18757/20608)
Epoch: 84 | Batch_idx: 170 |  Loss: (0.2600) |  Loss2: (0.0000) | Acc: (91.00%) (19929/21888)
Epoch: 84 | Batch_idx: 180 |  Loss: (0.2605) |  Loss2: (0.0000) | Acc: (91.00%) (21092/23168)
Epoch: 84 | Batch_idx: 190 |  Loss: (0.2599) |  Loss2: (0.0000) | Acc: (91.00%) (22256/24448)
Epoch: 84 | Batch_idx: 200 |  Loss: (0.2584) |  Loss2: (0.0000) | Acc: (91.00%) (23435/25728)
Epoch: 84 | Batch_idx: 210 |  Loss: (0.2596) |  Loss2: (0.0000) | Acc: (91.00%) (24596/27008)
Epoch: 84 | Batch_idx: 220 |  Loss: (0.2601) |  Loss2: (0.0000) | Acc: (91.00%) (25754/28288)
Epoch: 84 | Batch_idx: 230 |  Loss: (0.2597) |  Loss2: (0.0000) | Acc: (91.00%) (26917/29568)
Epoch: 84 | Batch_idx: 240 |  Loss: (0.2590) |  Loss2: (0.0000) | Acc: (91.00%) (28099/30848)
Epoch: 84 | Batch_idx: 250 |  Loss: (0.2584) |  Loss2: (0.0000) | Acc: (91.00%) (29287/32128)
Epoch: 84 | Batch_idx: 260 |  Loss: (0.2584) |  Loss2: (0.0000) | Acc: (91.00%) (30463/33408)
Epoch: 84 | Batch_idx: 270 |  Loss: (0.2586) |  Loss2: (0.0000) | Acc: (91.00%) (31624/34688)
Epoch: 84 | Batch_idx: 280 |  Loss: (0.2601) |  Loss2: (0.0000) | Acc: (91.00%) (32767/35968)
Epoch: 84 | Batch_idx: 290 |  Loss: (0.2590) |  Loss2: (0.0000) | Acc: (91.00%) (33951/37248)
Epoch: 84 | Batch_idx: 300 |  Loss: (0.2589) |  Loss2: (0.0000) | Acc: (91.00%) (35128/38528)
Epoch: 84 | Batch_idx: 310 |  Loss: (0.2592) |  Loss2: (0.0000) | Acc: (91.00%) (36282/39808)
Epoch: 84 | Batch_idx: 320 |  Loss: (0.2592) |  Loss2: (0.0000) | Acc: (91.00%) (37452/41088)
Epoch: 84 | Batch_idx: 330 |  Loss: (0.2591) |  Loss2: (0.0000) | Acc: (91.00%) (38620/42368)
Epoch: 84 | Batch_idx: 340 |  Loss: (0.2595) |  Loss2: (0.0000) | Acc: (91.00%) (39785/43648)
Epoch: 84 | Batch_idx: 350 |  Loss: (0.2594) |  Loss2: (0.0000) | Acc: (91.00%) (40954/44928)
Epoch: 84 | Batch_idx: 360 |  Loss: (0.2591) |  Loss2: (0.0000) | Acc: (91.00%) (42131/46208)
Epoch: 84 | Batch_idx: 370 |  Loss: (0.2585) |  Loss2: (0.0000) | Acc: (91.00%) (43300/47488)
Epoch: 84 | Batch_idx: 380 |  Loss: (0.2582) |  Loss2: (0.0000) | Acc: (91.00%) (44462/48768)
Epoch: 84 | Batch_idx: 390 |  Loss: (0.2580) |  Loss2: (0.0000) | Acc: (91.00%) (45589/50000)
# TEST : Loss: (0.4046) | Acc: (87.00%) (8703/10000)
percent tensor([0.5136, 0.5020, 0.5096, 0.5067, 0.5117, 0.5188, 0.5070, 0.5066, 0.5123,
        0.5058, 0.5135, 0.5070, 0.5057, 0.5076, 0.5088, 0.5118],
       device='cuda:0') torch.Size([16])
percent tensor([0.5059, 0.4993, 0.5095, 0.5096, 0.5085, 0.5070, 0.5025, 0.5098, 0.5093,
        0.5029, 0.5059, 0.5037, 0.4994, 0.5110, 0.5014, 0.5067],
       device='cuda:0') torch.Size([16])
percent tensor([0.5548, 0.5435, 0.5600, 0.5745, 0.5680, 0.5490, 0.5532, 0.5614, 0.5571,
        0.5559, 0.5532, 0.5557, 0.5296, 0.5881, 0.5399, 0.5640],
       device='cuda:0') torch.Size([16])
percent tensor([0.5794, 0.5943, 0.5752, 0.5723, 0.5700, 0.5709, 0.5878, 0.5685, 0.5911,
        0.5998, 0.6018, 0.5879, 0.5913, 0.6002, 0.5748, 0.5869],
       device='cuda:0') torch.Size([16])
percent tensor([0.5480, 0.6145, 0.4264, 0.5293, 0.4360, 0.5804, 0.5466, 0.3451, 0.6396,
        0.6116, 0.6772, 0.5388, 0.6215, 0.6604, 0.5191, 0.5699],
       device='cuda:0') torch.Size([16])
percent tensor([0.5855, 0.5687, 0.5957, 0.5968, 0.6294, 0.6001, 0.5971, 0.6363, 0.5687,
        0.5771, 0.5489, 0.5492, 0.5389, 0.5662, 0.5811, 0.6092],
       device='cuda:0') torch.Size([16])
percent tensor([0.5162, 0.5733, 0.6505, 0.6076, 0.7042, 0.7296, 0.5686, 0.6472, 0.6040,
        0.5415, 0.6238, 0.5219, 0.5801, 0.5732, 0.5240, 0.5569],
       device='cuda:0') torch.Size([16])
percent tensor([0.9985, 0.9979, 0.9988, 0.9986, 0.9984, 0.9975, 0.9980, 0.9994, 0.9992,
        0.9974, 0.9994, 0.9986, 0.9993, 0.9960, 0.9980, 0.9987],
       device='cuda:0') torch.Size([16])
Epoch: 85 | Batch_idx: 0 |  Loss: (0.2010) |  Loss2: (0.0000) | Acc: (94.00%) (121/128)
Epoch: 85 | Batch_idx: 10 |  Loss: (0.2502) |  Loss2: (0.0000) | Acc: (91.00%) (1293/1408)
Epoch: 85 | Batch_idx: 20 |  Loss: (0.2744) |  Loss2: (0.0000) | Acc: (90.00%) (2445/2688)
Epoch: 85 | Batch_idx: 30 |  Loss: (0.2691) |  Loss2: (0.0000) | Acc: (91.00%) (3616/3968)
Epoch: 85 | Batch_idx: 40 |  Loss: (0.2647) |  Loss2: (0.0000) | Acc: (91.00%) (4792/5248)
Epoch: 85 | Batch_idx: 50 |  Loss: (0.2649) |  Loss2: (0.0000) | Acc: (91.00%) (5958/6528)
Epoch: 85 | Batch_idx: 60 |  Loss: (0.2659) |  Loss2: (0.0000) | Acc: (91.00%) (7123/7808)
Epoch: 85 | Batch_idx: 70 |  Loss: (0.2647) |  Loss2: (0.0000) | Acc: (91.00%) (8296/9088)
Epoch: 85 | Batch_idx: 80 |  Loss: (0.2612) |  Loss2: (0.0000) | Acc: (91.00%) (9472/10368)
Epoch: 85 | Batch_idx: 90 |  Loss: (0.2630) |  Loss2: (0.0000) | Acc: (91.00%) (10632/11648)
Epoch: 85 | Batch_idx: 100 |  Loss: (0.2611) |  Loss2: (0.0000) | Acc: (91.00%) (11801/12928)
Epoch: 85 | Batch_idx: 110 |  Loss: (0.2619) |  Loss2: (0.0000) | Acc: (91.00%) (12953/14208)
Epoch: 85 | Batch_idx: 120 |  Loss: (0.2626) |  Loss2: (0.0000) | Acc: (91.00%) (14122/15488)
Epoch: 85 | Batch_idx: 130 |  Loss: (0.2600) |  Loss2: (0.0000) | Acc: (91.00%) (15299/16768)
Epoch: 85 | Batch_idx: 140 |  Loss: (0.2602) |  Loss2: (0.0000) | Acc: (91.00%) (16461/18048)
Epoch: 85 | Batch_idx: 150 |  Loss: (0.2600) |  Loss2: (0.0000) | Acc: (91.00%) (17638/19328)
Epoch: 85 | Batch_idx: 160 |  Loss: (0.2589) |  Loss2: (0.0000) | Acc: (91.00%) (18814/20608)
Epoch: 85 | Batch_idx: 170 |  Loss: (0.2588) |  Loss2: (0.0000) | Acc: (91.00%) (19976/21888)
Epoch: 85 | Batch_idx: 180 |  Loss: (0.2595) |  Loss2: (0.0000) | Acc: (91.00%) (21130/23168)
Epoch: 85 | Batch_idx: 190 |  Loss: (0.2584) |  Loss2: (0.0000) | Acc: (91.00%) (22306/24448)
Epoch: 85 | Batch_idx: 200 |  Loss: (0.2584) |  Loss2: (0.0000) | Acc: (91.00%) (23480/25728)
Epoch: 85 | Batch_idx: 210 |  Loss: (0.2588) |  Loss2: (0.0000) | Acc: (91.00%) (24645/27008)
Epoch: 85 | Batch_idx: 220 |  Loss: (0.2576) |  Loss2: (0.0000) | Acc: (91.00%) (25829/28288)
Epoch: 85 | Batch_idx: 230 |  Loss: (0.2582) |  Loss2: (0.0000) | Acc: (91.00%) (27002/29568)
Epoch: 85 | Batch_idx: 240 |  Loss: (0.2575) |  Loss2: (0.0000) | Acc: (91.00%) (28186/30848)
Epoch: 85 | Batch_idx: 250 |  Loss: (0.2567) |  Loss2: (0.0000) | Acc: (91.00%) (29363/32128)
Epoch: 85 | Batch_idx: 260 |  Loss: (0.2566) |  Loss2: (0.0000) | Acc: (91.00%) (30531/33408)
Epoch: 85 | Batch_idx: 270 |  Loss: (0.2577) |  Loss2: (0.0000) | Acc: (91.00%) (31692/34688)
Epoch: 85 | Batch_idx: 280 |  Loss: (0.2577) |  Loss2: (0.0000) | Acc: (91.00%) (32852/35968)
Epoch: 85 | Batch_idx: 290 |  Loss: (0.2571) |  Loss2: (0.0000) | Acc: (91.00%) (34027/37248)
Epoch: 85 | Batch_idx: 300 |  Loss: (0.2568) |  Loss2: (0.0000) | Acc: (91.00%) (35210/38528)
Epoch: 85 | Batch_idx: 310 |  Loss: (0.2567) |  Loss2: (0.0000) | Acc: (91.00%) (36364/39808)
Epoch: 85 | Batch_idx: 320 |  Loss: (0.2564) |  Loss2: (0.0000) | Acc: (91.00%) (37536/41088)
Epoch: 85 | Batch_idx: 330 |  Loss: (0.2564) |  Loss2: (0.0000) | Acc: (91.00%) (38702/42368)
Epoch: 85 | Batch_idx: 340 |  Loss: (0.2565) |  Loss2: (0.0000) | Acc: (91.00%) (39868/43648)
Epoch: 85 | Batch_idx: 350 |  Loss: (0.2558) |  Loss2: (0.0000) | Acc: (91.00%) (41043/44928)
Epoch: 85 | Batch_idx: 360 |  Loss: (0.2562) |  Loss2: (0.0000) | Acc: (91.00%) (42209/46208)
Epoch: 85 | Batch_idx: 370 |  Loss: (0.2562) |  Loss2: (0.0000) | Acc: (91.00%) (43375/47488)
Epoch: 85 | Batch_idx: 380 |  Loss: (0.2559) |  Loss2: (0.0000) | Acc: (91.00%) (44544/48768)
Epoch: 85 | Batch_idx: 390 |  Loss: (0.2560) |  Loss2: (0.0000) | Acc: (91.00%) (45670/50000)
=> saving checkpoint 'drive/app/torch/save_Schedule/checkpoint_085.pth.tar'
# TEST : Loss: (0.3983) | Acc: (87.00%) (8712/10000)
percent tensor([0.5132, 0.5014, 0.5089, 0.5064, 0.5110, 0.5187, 0.5063, 0.5059, 0.5118,
        0.5050, 0.5131, 0.5061, 0.5052, 0.5072, 0.5084, 0.5114],
       device='cuda:0') torch.Size([16])
percent tensor([0.5067, 0.5001, 0.5101, 0.5102, 0.5091, 0.5076, 0.5032, 0.5105, 0.5100,
        0.5038, 0.5068, 0.5045, 0.5004, 0.5116, 0.5022, 0.5075],
       device='cuda:0') torch.Size([16])
percent tensor([0.5525, 0.5404, 0.5587, 0.5719, 0.5659, 0.5462, 0.5504, 0.5597, 0.5543,
        0.5532, 0.5506, 0.5539, 0.5273, 0.5844, 0.5369, 0.5617],
       device='cuda:0') torch.Size([16])
percent tensor([0.5818, 0.5973, 0.5780, 0.5742, 0.5726, 0.5734, 0.5908, 0.5704, 0.5936,
        0.6029, 0.6050, 0.5912, 0.5942, 0.6030, 0.5776, 0.5896],
       device='cuda:0') torch.Size([16])
percent tensor([0.5449, 0.6129, 0.4277, 0.5256, 0.4351, 0.5760, 0.5475, 0.3412, 0.6379,
        0.6100, 0.6741, 0.5407, 0.6180, 0.6588, 0.5162, 0.5664],
       device='cuda:0') torch.Size([16])
percent tensor([0.5844, 0.5667, 0.5958, 0.5973, 0.6305, 0.5997, 0.5963, 0.6367, 0.5676,
        0.5757, 0.5475, 0.5481, 0.5361, 0.5648, 0.5808, 0.6077],
       device='cuda:0') torch.Size([16])
percent tensor([0.5177, 0.5773, 0.6492, 0.6098, 0.7005, 0.7351, 0.5662, 0.6434, 0.6115,
        0.5442, 0.6281, 0.5213, 0.5869, 0.5791, 0.5253, 0.5564],
       device='cuda:0') torch.Size([16])
percent tensor([0.9986, 0.9980, 0.9989, 0.9987, 0.9985, 0.9977, 0.9981, 0.9995, 0.9993,
        0.9975, 0.9994, 0.9987, 0.9993, 0.9963, 0.9982, 0.9987],
       device='cuda:0') torch.Size([16])
Epoch: 86 | Batch_idx: 0 |  Loss: (0.2652) |  Loss2: (0.0000) | Acc: (90.00%) (116/128)
Epoch: 86 | Batch_idx: 10 |  Loss: (0.2525) |  Loss2: (0.0000) | Acc: (91.00%) (1286/1408)
Epoch: 86 | Batch_idx: 20 |  Loss: (0.2638) |  Loss2: (0.0000) | Acc: (91.00%) (2448/2688)
Epoch: 86 | Batch_idx: 30 |  Loss: (0.2554) |  Loss2: (0.0000) | Acc: (91.00%) (3615/3968)
Epoch: 86 | Batch_idx: 40 |  Loss: (0.2567) |  Loss2: (0.0000) | Acc: (91.00%) (4789/5248)
Epoch: 86 | Batch_idx: 50 |  Loss: (0.2589) |  Loss2: (0.0000) | Acc: (91.00%) (5949/6528)
Epoch: 86 | Batch_idx: 60 |  Loss: (0.2620) |  Loss2: (0.0000) | Acc: (91.00%) (7118/7808)
Epoch: 86 | Batch_idx: 70 |  Loss: (0.2606) |  Loss2: (0.0000) | Acc: (91.00%) (8282/9088)
Epoch: 86 | Batch_idx: 80 |  Loss: (0.2591) |  Loss2: (0.0000) | Acc: (91.00%) (9455/10368)
Epoch: 86 | Batch_idx: 90 |  Loss: (0.2567) |  Loss2: (0.0000) | Acc: (91.00%) (10633/11648)
Epoch: 86 | Batch_idx: 100 |  Loss: (0.2564) |  Loss2: (0.0000) | Acc: (91.00%) (11801/12928)
Epoch: 86 | Batch_idx: 110 |  Loss: (0.2551) |  Loss2: (0.0000) | Acc: (91.00%) (12975/14208)
Epoch: 86 | Batch_idx: 120 |  Loss: (0.2561) |  Loss2: (0.0000) | Acc: (91.00%) (14135/15488)
Epoch: 86 | Batch_idx: 130 |  Loss: (0.2553) |  Loss2: (0.0000) | Acc: (91.00%) (15307/16768)
Epoch: 86 | Batch_idx: 140 |  Loss: (0.2538) |  Loss2: (0.0000) | Acc: (91.00%) (16476/18048)
Epoch: 86 | Batch_idx: 150 |  Loss: (0.2537) |  Loss2: (0.0000) | Acc: (91.00%) (17645/19328)
Epoch: 86 | Batch_idx: 160 |  Loss: (0.2550) |  Loss2: (0.0000) | Acc: (91.00%) (18811/20608)
Epoch: 86 | Batch_idx: 170 |  Loss: (0.2555) |  Loss2: (0.0000) | Acc: (91.00%) (19968/21888)
Epoch: 86 | Batch_idx: 180 |  Loss: (0.2559) |  Loss2: (0.0000) | Acc: (91.00%) (21136/23168)
Epoch: 86 | Batch_idx: 190 |  Loss: (0.2566) |  Loss2: (0.0000) | Acc: (91.00%) (22304/24448)
Epoch: 86 | Batch_idx: 200 |  Loss: (0.2555) |  Loss2: (0.0000) | Acc: (91.00%) (23486/25728)
Epoch: 86 | Batch_idx: 210 |  Loss: (0.2558) |  Loss2: (0.0000) | Acc: (91.00%) (24656/27008)
Epoch: 86 | Batch_idx: 220 |  Loss: (0.2551) |  Loss2: (0.0000) | Acc: (91.00%) (25835/28288)
Epoch: 86 | Batch_idx: 230 |  Loss: (0.2577) |  Loss2: (0.0000) | Acc: (91.00%) (26971/29568)
Epoch: 86 | Batch_idx: 240 |  Loss: (0.2571) |  Loss2: (0.0000) | Acc: (91.00%) (28146/30848)
Epoch: 86 | Batch_idx: 250 |  Loss: (0.2564) |  Loss2: (0.0000) | Acc: (91.00%) (29323/32128)
Epoch: 86 | Batch_idx: 260 |  Loss: (0.2571) |  Loss2: (0.0000) | Acc: (91.00%) (30481/33408)
Epoch: 86 | Batch_idx: 270 |  Loss: (0.2579) |  Loss2: (0.0000) | Acc: (91.00%) (31626/34688)
Epoch: 86 | Batch_idx: 280 |  Loss: (0.2577) |  Loss2: (0.0000) | Acc: (91.00%) (32787/35968)
Epoch: 86 | Batch_idx: 290 |  Loss: (0.2564) |  Loss2: (0.0000) | Acc: (91.00%) (33981/37248)
Epoch: 86 | Batch_idx: 300 |  Loss: (0.2559) |  Loss2: (0.0000) | Acc: (91.00%) (35164/38528)
Epoch: 86 | Batch_idx: 310 |  Loss: (0.2564) |  Loss2: (0.0000) | Acc: (91.00%) (36326/39808)
Epoch: 86 | Batch_idx: 320 |  Loss: (0.2553) |  Loss2: (0.0000) | Acc: (91.00%) (37508/41088)
Epoch: 86 | Batch_idx: 330 |  Loss: (0.2540) |  Loss2: (0.0000) | Acc: (91.00%) (38694/42368)
Epoch: 86 | Batch_idx: 340 |  Loss: (0.2537) |  Loss2: (0.0000) | Acc: (91.00%) (39869/43648)
Epoch: 86 | Batch_idx: 350 |  Loss: (0.2538) |  Loss2: (0.0000) | Acc: (91.00%) (41031/44928)
Epoch: 86 | Batch_idx: 360 |  Loss: (0.2526) |  Loss2: (0.0000) | Acc: (91.00%) (42224/46208)
Epoch: 86 | Batch_idx: 370 |  Loss: (0.2525) |  Loss2: (0.0000) | Acc: (91.00%) (43398/47488)
Epoch: 86 | Batch_idx: 380 |  Loss: (0.2531) |  Loss2: (0.0000) | Acc: (91.00%) (44562/48768)
Epoch: 86 | Batch_idx: 390 |  Loss: (0.2539) |  Loss2: (0.0000) | Acc: (91.00%) (45672/50000)
# TEST : Loss: (0.3982) | Acc: (87.00%) (8704/10000)
percent tensor([0.5133, 0.5012, 0.5084, 0.5063, 0.5106, 0.5191, 0.5060, 0.5056, 0.5118,
        0.5047, 0.5134, 0.5056, 0.5052, 0.5069, 0.5086, 0.5115],
       device='cuda:0') torch.Size([16])
percent tensor([0.5082, 0.5019, 0.5113, 0.5115, 0.5103, 0.5088, 0.5048, 0.5118, 0.5116,
        0.5054, 0.5086, 0.5060, 0.5022, 0.5130, 0.5038, 0.5091],
       device='cuda:0') torch.Size([16])
percent tensor([0.5561, 0.5434, 0.5603, 0.5741, 0.5675, 0.5503, 0.5531, 0.5606, 0.5573,
        0.5558, 0.5546, 0.5566, 0.5310, 0.5871, 0.5405, 0.5651],
       device='cuda:0') torch.Size([16])
percent tensor([0.5840, 0.5997, 0.5800, 0.5761, 0.5744, 0.5750, 0.5933, 0.5723, 0.5961,
        0.6056, 0.6077, 0.5937, 0.5969, 0.6052, 0.5796, 0.5916],
       device='cuda:0') torch.Size([16])
percent tensor([0.5451, 0.6140, 0.4282, 0.5241, 0.4392, 0.5731, 0.5525, 0.3459, 0.6356,
        0.6114, 0.6728, 0.5418, 0.6150, 0.6568, 0.5180, 0.5680],
       device='cuda:0') torch.Size([16])
percent tensor([0.5835, 0.5650, 0.5974, 0.5985, 0.6333, 0.5985, 0.5964, 0.6405, 0.5657,
        0.5746, 0.5462, 0.5482, 0.5321, 0.5630, 0.5809, 0.6080],
       device='cuda:0') torch.Size([16])
percent tensor([0.5100, 0.5684, 0.6501, 0.6087, 0.7025, 0.7295, 0.5634, 0.6491, 0.6025,
        0.5359, 0.6201, 0.5193, 0.5753, 0.5689, 0.5213, 0.5522],
       device='cuda:0') torch.Size([16])
percent tensor([0.9987, 0.9982, 0.9991, 0.9989, 0.9987, 0.9979, 0.9983, 0.9996, 0.9994,
        0.9979, 0.9994, 0.9989, 0.9994, 0.9966, 0.9984, 0.9988],
       device='cuda:0') torch.Size([16])
Epoch: 87 | Batch_idx: 0 |  Loss: (0.2347) |  Loss2: (0.0000) | Acc: (91.00%) (117/128)
Epoch: 87 | Batch_idx: 10 |  Loss: (0.2673) |  Loss2: (0.0000) | Acc: (90.00%) (1271/1408)
Epoch: 87 | Batch_idx: 20 |  Loss: (0.2602) |  Loss2: (0.0000) | Acc: (90.00%) (2433/2688)
Epoch: 87 | Batch_idx: 30 |  Loss: (0.2610) |  Loss2: (0.0000) | Acc: (90.00%) (3590/3968)
Epoch: 87 | Batch_idx: 40 |  Loss: (0.2550) |  Loss2: (0.0000) | Acc: (90.00%) (4770/5248)
Epoch: 87 | Batch_idx: 50 |  Loss: (0.2532) |  Loss2: (0.0000) | Acc: (91.00%) (5943/6528)
Epoch: 87 | Batch_idx: 60 |  Loss: (0.2563) |  Loss2: (0.0000) | Acc: (91.00%) (7106/7808)
Epoch: 87 | Batch_idx: 70 |  Loss: (0.2524) |  Loss2: (0.0000) | Acc: (91.00%) (8295/9088)
Epoch: 87 | Batch_idx: 80 |  Loss: (0.2521) |  Loss2: (0.0000) | Acc: (91.00%) (9467/10368)
Epoch: 87 | Batch_idx: 90 |  Loss: (0.2543) |  Loss2: (0.0000) | Acc: (91.00%) (10622/11648)
Epoch: 87 | Batch_idx: 100 |  Loss: (0.2555) |  Loss2: (0.0000) | Acc: (91.00%) (11777/12928)
Epoch: 87 | Batch_idx: 110 |  Loss: (0.2546) |  Loss2: (0.0000) | Acc: (91.00%) (12950/14208)
Epoch: 87 | Batch_idx: 120 |  Loss: (0.2535) |  Loss2: (0.0000) | Acc: (91.00%) (14128/15488)
Epoch: 87 | Batch_idx: 130 |  Loss: (0.2521) |  Loss2: (0.0000) | Acc: (91.00%) (15307/16768)
Epoch: 87 | Batch_idx: 140 |  Loss: (0.2509) |  Loss2: (0.0000) | Acc: (91.00%) (16499/18048)
Epoch: 87 | Batch_idx: 150 |  Loss: (0.2492) |  Loss2: (0.0000) | Acc: (91.00%) (17679/19328)
Epoch: 87 | Batch_idx: 160 |  Loss: (0.2515) |  Loss2: (0.0000) | Acc: (91.00%) (18832/20608)
Epoch: 87 | Batch_idx: 170 |  Loss: (0.2520) |  Loss2: (0.0000) | Acc: (91.00%) (20001/21888)
Epoch: 87 | Batch_idx: 180 |  Loss: (0.2523) |  Loss2: (0.0000) | Acc: (91.00%) (21170/23168)
Epoch: 87 | Batch_idx: 190 |  Loss: (0.2526) |  Loss2: (0.0000) | Acc: (91.00%) (22341/24448)
Epoch: 87 | Batch_idx: 200 |  Loss: (0.2523) |  Loss2: (0.0000) | Acc: (91.00%) (23507/25728)
Epoch: 87 | Batch_idx: 210 |  Loss: (0.2529) |  Loss2: (0.0000) | Acc: (91.00%) (24677/27008)
Epoch: 87 | Batch_idx: 220 |  Loss: (0.2524) |  Loss2: (0.0000) | Acc: (91.00%) (25855/28288)
Epoch: 87 | Batch_idx: 230 |  Loss: (0.2531) |  Loss2: (0.0000) | Acc: (91.00%) (27017/29568)
Epoch: 87 | Batch_idx: 240 |  Loss: (0.2528) |  Loss2: (0.0000) | Acc: (91.00%) (28191/30848)
Epoch: 87 | Batch_idx: 250 |  Loss: (0.2537) |  Loss2: (0.0000) | Acc: (91.00%) (29352/32128)
Epoch: 87 | Batch_idx: 260 |  Loss: (0.2536) |  Loss2: (0.0000) | Acc: (91.00%) (30523/33408)
Epoch: 87 | Batch_idx: 270 |  Loss: (0.2529) |  Loss2: (0.0000) | Acc: (91.00%) (31700/34688)
Epoch: 87 | Batch_idx: 280 |  Loss: (0.2512) |  Loss2: (0.0000) | Acc: (91.00%) (32881/35968)
Epoch: 87 | Batch_idx: 290 |  Loss: (0.2515) |  Loss2: (0.0000) | Acc: (91.00%) (34039/37248)
Epoch: 87 | Batch_idx: 300 |  Loss: (0.2511) |  Loss2: (0.0000) | Acc: (91.00%) (35215/38528)
Epoch: 87 | Batch_idx: 310 |  Loss: (0.2500) |  Loss2: (0.0000) | Acc: (91.00%) (36408/39808)
Epoch: 87 | Batch_idx: 320 |  Loss: (0.2500) |  Loss2: (0.0000) | Acc: (91.00%) (37578/41088)
Epoch: 87 | Batch_idx: 330 |  Loss: (0.2505) |  Loss2: (0.0000) | Acc: (91.00%) (38741/42368)
Epoch: 87 | Batch_idx: 340 |  Loss: (0.2511) |  Loss2: (0.0000) | Acc: (91.00%) (39899/43648)
Epoch: 87 | Batch_idx: 350 |  Loss: (0.2507) |  Loss2: (0.0000) | Acc: (91.00%) (41082/44928)
Epoch: 87 | Batch_idx: 360 |  Loss: (0.2502) |  Loss2: (0.0000) | Acc: (91.00%) (42254/46208)
Epoch: 87 | Batch_idx: 370 |  Loss: (0.2501) |  Loss2: (0.0000) | Acc: (91.00%) (43424/47488)
Epoch: 87 | Batch_idx: 380 |  Loss: (0.2503) |  Loss2: (0.0000) | Acc: (91.00%) (44588/48768)
Epoch: 87 | Batch_idx: 390 |  Loss: (0.2508) |  Loss2: (0.0000) | Acc: (91.00%) (45707/50000)
# TEST : Loss: (0.3940) | Acc: (87.00%) (8724/10000)
percent tensor([0.5155, 0.5039, 0.5108, 0.5089, 0.5132, 0.5207, 0.5087, 0.5083, 0.5142,
        0.5073, 0.5159, 0.5082, 0.5076, 0.5096, 0.5112, 0.5139],
       device='cuda:0') torch.Size([16])
percent tensor([0.5090, 0.5029, 0.5119, 0.5122, 0.5109, 0.5095, 0.5056, 0.5125, 0.5124,
        0.5064, 0.5094, 0.5068, 0.5032, 0.5137, 0.5046, 0.5098],
       device='cuda:0') torch.Size([16])
percent tensor([0.5545, 0.5423, 0.5586, 0.5720, 0.5658, 0.5483, 0.5518, 0.5596, 0.5561,
        0.5543, 0.5531, 0.5553, 0.5297, 0.5860, 0.5391, 0.5636],
       device='cuda:0') torch.Size([16])
percent tensor([0.5849, 0.6006, 0.5816, 0.5775, 0.5758, 0.5758, 0.5943, 0.5734, 0.5967,
        0.6066, 0.6088, 0.5952, 0.5977, 0.6058, 0.5807, 0.5927],
       device='cuda:0') torch.Size([16])
percent tensor([0.5492, 0.6101, 0.4347, 0.5296, 0.4492, 0.5776, 0.5552, 0.3530, 0.6324,
        0.6085, 0.6686, 0.5407, 0.6092, 0.6537, 0.5178, 0.5727],
       device='cuda:0') torch.Size([16])
percent tensor([0.5841, 0.5644, 0.5986, 0.5997, 0.6355, 0.6000, 0.5969, 0.6415, 0.5662,
        0.5744, 0.5466, 0.5485, 0.5314, 0.5635, 0.5817, 0.6087],
       device='cuda:0') torch.Size([16])
percent tensor([0.5153, 0.5752, 0.6554, 0.6155, 0.7055, 0.7348, 0.5651, 0.6509, 0.6122,
        0.5439, 0.6283, 0.5285, 0.5853, 0.5778, 0.5262, 0.5541],
       device='cuda:0') torch.Size([16])
percent tensor([0.9988, 0.9984, 0.9991, 0.9989, 0.9988, 0.9979, 0.9985, 0.9996, 0.9995,
        0.9980, 0.9995, 0.9990, 0.9995, 0.9970, 0.9985, 0.9989],
       device='cuda:0') torch.Size([16])
Epoch: 88 | Batch_idx: 0 |  Loss: (0.2312) |  Loss2: (0.0000) | Acc: (92.00%) (118/128)
Epoch: 88 | Batch_idx: 10 |  Loss: (0.2511) |  Loss2: (0.0000) | Acc: (90.00%) (1280/1408)
Epoch: 88 | Batch_idx: 20 |  Loss: (0.2510) |  Loss2: (0.0000) | Acc: (90.00%) (2446/2688)
Epoch: 88 | Batch_idx: 30 |  Loss: (0.2538) |  Loss2: (0.0000) | Acc: (91.00%) (3613/3968)
Epoch: 88 | Batch_idx: 40 |  Loss: (0.2571) |  Loss2: (0.0000) | Acc: (91.00%) (4780/5248)
Epoch: 88 | Batch_idx: 50 |  Loss: (0.2583) |  Loss2: (0.0000) | Acc: (91.00%) (5946/6528)
Epoch: 88 | Batch_idx: 60 |  Loss: (0.2515) |  Loss2: (0.0000) | Acc: (91.00%) (7141/7808)
Epoch: 88 | Batch_idx: 70 |  Loss: (0.2526) |  Loss2: (0.0000) | Acc: (91.00%) (8312/9088)
Epoch: 88 | Batch_idx: 80 |  Loss: (0.2504) |  Loss2: (0.0000) | Acc: (91.00%) (9503/10368)
Epoch: 88 | Batch_idx: 90 |  Loss: (0.2511) |  Loss2: (0.0000) | Acc: (91.00%) (10670/11648)
Epoch: 88 | Batch_idx: 100 |  Loss: (0.2493) |  Loss2: (0.0000) | Acc: (91.00%) (11849/12928)
Epoch: 88 | Batch_idx: 110 |  Loss: (0.2485) |  Loss2: (0.0000) | Acc: (91.00%) (13026/14208)
Epoch: 88 | Batch_idx: 120 |  Loss: (0.2467) |  Loss2: (0.0000) | Acc: (91.00%) (14211/15488)
Epoch: 88 | Batch_idx: 130 |  Loss: (0.2464) |  Loss2: (0.0000) | Acc: (91.00%) (15386/16768)
Epoch: 88 | Batch_idx: 140 |  Loss: (0.2476) |  Loss2: (0.0000) | Acc: (91.00%) (16550/18048)
Epoch: 88 | Batch_idx: 150 |  Loss: (0.2475) |  Loss2: (0.0000) | Acc: (91.00%) (17722/19328)
Epoch: 88 | Batch_idx: 160 |  Loss: (0.2456) |  Loss2: (0.0000) | Acc: (91.00%) (18899/20608)
Epoch: 88 | Batch_idx: 170 |  Loss: (0.2469) |  Loss2: (0.0000) | Acc: (91.00%) (20059/21888)
Epoch: 88 | Batch_idx: 180 |  Loss: (0.2458) |  Loss2: (0.0000) | Acc: (91.00%) (21252/23168)
Epoch: 88 | Batch_idx: 190 |  Loss: (0.2458) |  Loss2: (0.0000) | Acc: (91.00%) (22420/24448)
Epoch: 88 | Batch_idx: 200 |  Loss: (0.2470) |  Loss2: (0.0000) | Acc: (91.00%) (23586/25728)
Epoch: 88 | Batch_idx: 210 |  Loss: (0.2479) |  Loss2: (0.0000) | Acc: (91.00%) (24753/27008)
Epoch: 88 | Batch_idx: 220 |  Loss: (0.2487) |  Loss2: (0.0000) | Acc: (91.00%) (25911/28288)
Epoch: 88 | Batch_idx: 230 |  Loss: (0.2508) |  Loss2: (0.0000) | Acc: (91.00%) (27059/29568)
Epoch: 88 | Batch_idx: 240 |  Loss: (0.2511) |  Loss2: (0.0000) | Acc: (91.00%) (28216/30848)
Epoch: 88 | Batch_idx: 250 |  Loss: (0.2504) |  Loss2: (0.0000) | Acc: (91.00%) (29393/32128)
Epoch: 88 | Batch_idx: 260 |  Loss: (0.2496) |  Loss2: (0.0000) | Acc: (91.00%) (30569/33408)
Epoch: 88 | Batch_idx: 270 |  Loss: (0.2500) |  Loss2: (0.0000) | Acc: (91.00%) (31731/34688)
Epoch: 88 | Batch_idx: 280 |  Loss: (0.2489) |  Loss2: (0.0000) | Acc: (91.00%) (32922/35968)
Epoch: 88 | Batch_idx: 290 |  Loss: (0.2480) |  Loss2: (0.0000) | Acc: (91.00%) (34102/37248)
Epoch: 88 | Batch_idx: 300 |  Loss: (0.2473) |  Loss2: (0.0000) | Acc: (91.00%) (35289/38528)
Epoch: 88 | Batch_idx: 310 |  Loss: (0.2470) |  Loss2: (0.0000) | Acc: (91.00%) (36452/39808)
Epoch: 88 | Batch_idx: 320 |  Loss: (0.2478) |  Loss2: (0.0000) | Acc: (91.00%) (37618/41088)
Epoch: 88 | Batch_idx: 330 |  Loss: (0.2480) |  Loss2: (0.0000) | Acc: (91.00%) (38787/42368)
Epoch: 88 | Batch_idx: 340 |  Loss: (0.2480) |  Loss2: (0.0000) | Acc: (91.00%) (39957/43648)
Epoch: 88 | Batch_idx: 350 |  Loss: (0.2481) |  Loss2: (0.0000) | Acc: (91.00%) (41133/44928)
Epoch: 88 | Batch_idx: 360 |  Loss: (0.2475) |  Loss2: (0.0000) | Acc: (91.00%) (42310/46208)
Epoch: 88 | Batch_idx: 370 |  Loss: (0.2475) |  Loss2: (0.0000) | Acc: (91.00%) (43473/47488)
Epoch: 88 | Batch_idx: 380 |  Loss: (0.2475) |  Loss2: (0.0000) | Acc: (91.00%) (44641/48768)
Epoch: 88 | Batch_idx: 390 |  Loss: (0.2471) |  Loss2: (0.0000) | Acc: (91.00%) (45782/50000)
# TEST : Loss: (0.3932) | Acc: (87.00%) (8729/10000)
percent tensor([0.5154, 0.5037, 0.5105, 0.5087, 0.5129, 0.5206, 0.5084, 0.5081, 0.5141,
        0.5070, 0.5158, 0.5078, 0.5075, 0.5092, 0.5111, 0.5137],
       device='cuda:0') torch.Size([16])
percent tensor([0.5094, 0.5035, 0.5123, 0.5126, 0.5112, 0.5098, 0.5061, 0.5130, 0.5128,
        0.5069, 0.5099, 0.5072, 0.5038, 0.5141, 0.5051, 0.5103],
       device='cuda:0') torch.Size([16])
percent tensor([0.5523, 0.5395, 0.5574, 0.5706, 0.5643, 0.5451, 0.5496, 0.5589, 0.5541,
        0.5518, 0.5503, 0.5531, 0.5267, 0.5839, 0.5363, 0.5611],
       device='cuda:0') torch.Size([16])
percent tensor([0.5856, 0.6012, 0.5827, 0.5779, 0.5764, 0.5765, 0.5952, 0.5737, 0.5974,
        0.6073, 0.6093, 0.5963, 0.5983, 0.6065, 0.5814, 0.5931],
       device='cuda:0') torch.Size([16])
percent tensor([0.5502, 0.6058, 0.4356, 0.5330, 0.4475, 0.5788, 0.5531, 0.3504, 0.6297,
        0.6024, 0.6627, 0.5397, 0.6040, 0.6511, 0.5154, 0.5728],
       device='cuda:0') torch.Size([16])
percent tensor([0.5816, 0.5623, 0.5976, 0.5989, 0.6345, 0.5987, 0.5953, 0.6403, 0.5642,
        0.5722, 0.5448, 0.5469, 0.5283, 0.5623, 0.5803, 0.6059],
       device='cuda:0') torch.Size([16])
percent tensor([0.5200, 0.5852, 0.6575, 0.6176, 0.7024, 0.7411, 0.5669, 0.6481, 0.6192,
        0.5497, 0.6368, 0.5338, 0.5943, 0.5908, 0.5330, 0.5566],
       device='cuda:0') torch.Size([16])
percent tensor([0.9990, 0.9985, 0.9991, 0.9989, 0.9988, 0.9980, 0.9986, 0.9996, 0.9995,
        0.9982, 0.9995, 0.9990, 0.9995, 0.9973, 0.9986, 0.9991],
       device='cuda:0') torch.Size([16])
Epoch: 89 | Batch_idx: 0 |  Loss: (0.2260) |  Loss2: (0.0000) | Acc: (93.00%) (120/128)
Epoch: 89 | Batch_idx: 10 |  Loss: (0.2538) |  Loss2: (0.0000) | Acc: (91.00%) (1291/1408)
Epoch: 89 | Batch_idx: 20 |  Loss: (0.2511) |  Loss2: (0.0000) | Acc: (91.00%) (2465/2688)
Epoch: 89 | Batch_idx: 30 |  Loss: (0.2550) |  Loss2: (0.0000) | Acc: (91.00%) (3624/3968)
Epoch: 89 | Batch_idx: 40 |  Loss: (0.2547) |  Loss2: (0.0000) | Acc: (91.00%) (4791/5248)
Epoch: 89 | Batch_idx: 50 |  Loss: (0.2541) |  Loss2: (0.0000) | Acc: (91.00%) (5961/6528)
Epoch: 89 | Batch_idx: 60 |  Loss: (0.2464) |  Loss2: (0.0000) | Acc: (91.00%) (7162/7808)
Epoch: 89 | Batch_idx: 70 |  Loss: (0.2458) |  Loss2: (0.0000) | Acc: (91.00%) (8336/9088)
Epoch: 89 | Batch_idx: 80 |  Loss: (0.2475) |  Loss2: (0.0000) | Acc: (91.00%) (9503/10368)
Epoch: 89 | Batch_idx: 90 |  Loss: (0.2443) |  Loss2: (0.0000) | Acc: (91.00%) (10690/11648)
Epoch: 89 | Batch_idx: 100 |  Loss: (0.2462) |  Loss2: (0.0000) | Acc: (91.00%) (11852/12928)
Epoch: 89 | Batch_idx: 110 |  Loss: (0.2460) |  Loss2: (0.0000) | Acc: (91.00%) (13023/14208)
Epoch: 89 | Batch_idx: 120 |  Loss: (0.2466) |  Loss2: (0.0000) | Acc: (91.00%) (14209/15488)
Epoch: 89 | Batch_idx: 130 |  Loss: (0.2459) |  Loss2: (0.0000) | Acc: (91.00%) (15384/16768)
Epoch: 89 | Batch_idx: 140 |  Loss: (0.2466) |  Loss2: (0.0000) | Acc: (91.00%) (16559/18048)
Epoch: 89 | Batch_idx: 150 |  Loss: (0.2460) |  Loss2: (0.0000) | Acc: (91.00%) (17731/19328)
Epoch: 89 | Batch_idx: 160 |  Loss: (0.2447) |  Loss2: (0.0000) | Acc: (91.00%) (18917/20608)
Epoch: 89 | Batch_idx: 170 |  Loss: (0.2447) |  Loss2: (0.0000) | Acc: (91.00%) (20088/21888)
Epoch: 89 | Batch_idx: 180 |  Loss: (0.2469) |  Loss2: (0.0000) | Acc: (91.00%) (21246/23168)
Epoch: 89 | Batch_idx: 190 |  Loss: (0.2475) |  Loss2: (0.0000) | Acc: (91.00%) (22414/24448)
Epoch: 89 | Batch_idx: 200 |  Loss: (0.2491) |  Loss2: (0.0000) | Acc: (91.00%) (23566/25728)
Epoch: 89 | Batch_idx: 210 |  Loss: (0.2493) |  Loss2: (0.0000) | Acc: (91.00%) (24742/27008)
Epoch: 89 | Batch_idx: 220 |  Loss: (0.2481) |  Loss2: (0.0000) | Acc: (91.00%) (25932/28288)
Epoch: 89 | Batch_idx: 230 |  Loss: (0.2486) |  Loss2: (0.0000) | Acc: (91.00%) (27093/29568)
Epoch: 89 | Batch_idx: 240 |  Loss: (0.2482) |  Loss2: (0.0000) | Acc: (91.00%) (28272/30848)
Epoch: 89 | Batch_idx: 250 |  Loss: (0.2470) |  Loss2: (0.0000) | Acc: (91.00%) (29455/32128)
Epoch: 89 | Batch_idx: 260 |  Loss: (0.2478) |  Loss2: (0.0000) | Acc: (91.00%) (30617/33408)
Epoch: 89 | Batch_idx: 270 |  Loss: (0.2471) |  Loss2: (0.0000) | Acc: (91.00%) (31803/34688)
Epoch: 89 | Batch_idx: 280 |  Loss: (0.2474) |  Loss2: (0.0000) | Acc: (91.00%) (32970/35968)
Epoch: 89 | Batch_idx: 290 |  Loss: (0.2475) |  Loss2: (0.0000) | Acc: (91.00%) (34144/37248)
Epoch: 89 | Batch_idx: 300 |  Loss: (0.2470) |  Loss2: (0.0000) | Acc: (91.00%) (35321/38528)
Epoch: 89 | Batch_idx: 310 |  Loss: (0.2469) |  Loss2: (0.0000) | Acc: (91.00%) (36501/39808)
Epoch: 89 | Batch_idx: 320 |  Loss: (0.2469) |  Loss2: (0.0000) | Acc: (91.00%) (37673/41088)
Epoch: 89 | Batch_idx: 330 |  Loss: (0.2472) |  Loss2: (0.0000) | Acc: (91.00%) (38837/42368)
Epoch: 89 | Batch_idx: 340 |  Loss: (0.2472) |  Loss2: (0.0000) | Acc: (91.00%) (40022/43648)
Epoch: 89 | Batch_idx: 350 |  Loss: (0.2476) |  Loss2: (0.0000) | Acc: (91.00%) (41201/44928)
Epoch: 89 | Batch_idx: 360 |  Loss: (0.2480) |  Loss2: (0.0000) | Acc: (91.00%) (42360/46208)
Epoch: 89 | Batch_idx: 370 |  Loss: (0.2474) |  Loss2: (0.0000) | Acc: (91.00%) (43541/47488)
Epoch: 89 | Batch_idx: 380 |  Loss: (0.2479) |  Loss2: (0.0000) | Acc: (91.00%) (44705/48768)
Epoch: 89 | Batch_idx: 390 |  Loss: (0.2487) |  Loss2: (0.0000) | Acc: (91.00%) (45822/50000)
# TEST : Loss: (0.3913) | Acc: (87.00%) (8728/10000)
percent tensor([0.5159, 0.5040, 0.5107, 0.5093, 0.5131, 0.5210, 0.5087, 0.5085, 0.5145,
        0.5073, 0.5164, 0.5081, 0.5080, 0.5096, 0.5115, 0.5142],
       device='cuda:0') torch.Size([16])
percent tensor([0.5097, 0.5037, 0.5125, 0.5130, 0.5113, 0.5100, 0.5063, 0.5133, 0.5131,
        0.5072, 0.5102, 0.5075, 0.5041, 0.5143, 0.5053, 0.5106],
       device='cuda:0') torch.Size([16])
percent tensor([0.5559, 0.5420, 0.5592, 0.5741, 0.5667, 0.5486, 0.5522, 0.5615, 0.5574,
        0.5541, 0.5536, 0.5555, 0.5292, 0.5877, 0.5394, 0.5644],
       device='cuda:0') torch.Size([16])
percent tensor([0.5868, 0.6023, 0.5836, 0.5790, 0.5773, 0.5775, 0.5963, 0.5747, 0.5987,
        0.6086, 0.6109, 0.5976, 0.5998, 0.6075, 0.5824, 0.5943],
       device='cuda:0') torch.Size([16])
percent tensor([0.5535, 0.6125, 0.4374, 0.5314, 0.4510, 0.5777, 0.5594, 0.3541, 0.6333,
        0.6095, 0.6669, 0.5454, 0.6103, 0.6545, 0.5207, 0.5773],
       device='cuda:0') torch.Size([16])
percent tensor([0.5864, 0.5686, 0.6032, 0.6048, 0.6400, 0.6022, 0.6012, 0.6467, 0.5697,
        0.5783, 0.5506, 0.5536, 0.5330, 0.5678, 0.5859, 0.6115],
       device='cuda:0') torch.Size([16])
percent tensor([0.5185, 0.5866, 0.6586, 0.6155, 0.7012, 0.7411, 0.5687, 0.6456, 0.6206,
        0.5506, 0.6397, 0.5321, 0.5963, 0.5925, 0.5313, 0.5560],
       device='cuda:0') torch.Size([16])
percent tensor([0.9990, 0.9986, 0.9993, 0.9990, 0.9989, 0.9982, 0.9987, 0.9997, 0.9996,
        0.9983, 0.9996, 0.9991, 0.9996, 0.9974, 0.9988, 0.9990],
       device='cuda:0') torch.Size([16])
True Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=128, out_features=16, bias=False)
False Linear(in_features=16, out_features=2, bias=False)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=128, out_features=16, bias=False)
False Linear(in_features=16, out_features=2, bias=False)
True Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=256, out_features=32, bias=False)
False Linear(in_features=32, out_features=2, bias=False)
True Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=256, out_features=32, bias=False)
False Linear(in_features=32, out_features=2, bias=False)
True Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=512, out_features=64, bias=False)
False Linear(in_features=64, out_features=2, bias=False)
True Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=512, out_features=64, bias=False)
False Linear(in_features=64, out_features=2, bias=False)
True Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1024, out_features=128, bias=False)
False Linear(in_features=128, out_features=2, bias=False)
True Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1024, out_features=128, bias=False)
False Linear(in_features=128, out_features=2, bias=False)
True Linear(in_features=512, out_features=10, bias=True)
Epoch: 90 | Batch_idx: 0 |  Loss: (0.1650) |  Loss2: (0.0000) | Acc: (95.00%) (122/128)
Epoch: 90 | Batch_idx: 10 |  Loss: (0.2285) |  Loss2: (0.0000) | Acc: (91.00%) (1287/1408)
Epoch: 90 | Batch_idx: 20 |  Loss: (0.2395) |  Loss2: (0.0000) | Acc: (91.00%) (2453/2688)
Epoch: 90 | Batch_idx: 30 |  Loss: (0.2577) |  Loss2: (0.0000) | Acc: (91.00%) (3613/3968)
Epoch: 90 | Batch_idx: 40 |  Loss: (0.2556) |  Loss2: (0.0000) | Acc: (91.00%) (4778/5248)
Epoch: 90 | Batch_idx: 50 |  Loss: (0.2599) |  Loss2: (0.0000) | Acc: (90.00%) (5934/6528)
Epoch: 90 | Batch_idx: 60 |  Loss: (0.2587) |  Loss2: (0.0000) | Acc: (90.00%) (7099/7808)
Epoch: 90 | Batch_idx: 70 |  Loss: (0.2680) |  Loss2: (0.0000) | Acc: (90.00%) (8232/9088)
Epoch: 90 | Batch_idx: 80 |  Loss: (0.2672) |  Loss2: (0.0000) | Acc: (90.00%) (9408/10368)
Epoch: 90 | Batch_idx: 90 |  Loss: (0.2677) |  Loss2: (0.0000) | Acc: (90.00%) (10564/11648)
Epoch: 90 | Batch_idx: 100 |  Loss: (0.2669) |  Loss2: (0.0000) | Acc: (90.00%) (11724/12928)
Epoch: 90 | Batch_idx: 110 |  Loss: (0.2660) |  Loss2: (0.0000) | Acc: (90.00%) (12895/14208)
Epoch: 90 | Batch_idx: 120 |  Loss: (0.2660) |  Loss2: (0.0000) | Acc: (90.00%) (14063/15488)
Epoch: 90 | Batch_idx: 130 |  Loss: (0.2657) |  Loss2: (0.0000) | Acc: (90.00%) (15226/16768)
Epoch: 90 | Batch_idx: 140 |  Loss: (0.2654) |  Loss2: (0.0000) | Acc: (90.00%) (16396/18048)
Epoch: 90 | Batch_idx: 150 |  Loss: (0.2657) |  Loss2: (0.0000) | Acc: (90.00%) (17550/19328)
Epoch: 90 | Batch_idx: 160 |  Loss: (0.2661) |  Loss2: (0.0000) | Acc: (90.00%) (18708/20608)
Epoch: 90 | Batch_idx: 170 |  Loss: (0.2671) |  Loss2: (0.0000) | Acc: (90.00%) (19865/21888)
Epoch: 90 | Batch_idx: 180 |  Loss: (0.2678) |  Loss2: (0.0000) | Acc: (90.00%) (21020/23168)
Epoch: 90 | Batch_idx: 190 |  Loss: (0.2672) |  Loss2: (0.0000) | Acc: (90.00%) (22187/24448)
Epoch: 90 | Batch_idx: 200 |  Loss: (0.2667) |  Loss2: (0.0000) | Acc: (90.00%) (23356/25728)
Epoch: 90 | Batch_idx: 210 |  Loss: (0.2674) |  Loss2: (0.0000) | Acc: (90.00%) (24519/27008)
Epoch: 90 | Batch_idx: 220 |  Loss: (0.2671) |  Loss2: (0.0000) | Acc: (90.00%) (25688/28288)
Epoch: 90 | Batch_idx: 230 |  Loss: (0.2660) |  Loss2: (0.0000) | Acc: (90.00%) (26857/29568)
Epoch: 90 | Batch_idx: 240 |  Loss: (0.2651) |  Loss2: (0.0000) | Acc: (90.00%) (28035/30848)
Epoch: 90 | Batch_idx: 250 |  Loss: (0.2652) |  Loss2: (0.0000) | Acc: (90.00%) (29204/32128)
Epoch: 90 | Batch_idx: 260 |  Loss: (0.2655) |  Loss2: (0.0000) | Acc: (90.00%) (30361/33408)
Epoch: 90 | Batch_idx: 270 |  Loss: (0.2660) |  Loss2: (0.0000) | Acc: (90.00%) (31509/34688)
Epoch: 90 | Batch_idx: 280 |  Loss: (0.2668) |  Loss2: (0.0000) | Acc: (90.00%) (32664/35968)
Epoch: 90 | Batch_idx: 290 |  Loss: (0.2679) |  Loss2: (0.0000) | Acc: (90.00%) (33810/37248)
Epoch: 90 | Batch_idx: 300 |  Loss: (0.2687) |  Loss2: (0.0000) | Acc: (90.00%) (34957/38528)
Epoch: 90 | Batch_idx: 310 |  Loss: (0.2692) |  Loss2: (0.0000) | Acc: (90.00%) (36103/39808)
Epoch: 90 | Batch_idx: 320 |  Loss: (0.2695) |  Loss2: (0.0000) | Acc: (90.00%) (37265/41088)
Epoch: 90 | Batch_idx: 330 |  Loss: (0.2698) |  Loss2: (0.0000) | Acc: (90.00%) (38419/42368)
Epoch: 90 | Batch_idx: 340 |  Loss: (0.2703) |  Loss2: (0.0000) | Acc: (90.00%) (39574/43648)
Epoch: 90 | Batch_idx: 350 |  Loss: (0.2712) |  Loss2: (0.0000) | Acc: (90.00%) (40713/44928)
Epoch: 90 | Batch_idx: 360 |  Loss: (0.2713) |  Loss2: (0.0000) | Acc: (90.00%) (41873/46208)
Epoch: 90 | Batch_idx: 370 |  Loss: (0.2714) |  Loss2: (0.0000) | Acc: (90.00%) (43039/47488)
Epoch: 90 | Batch_idx: 380 |  Loss: (0.2709) |  Loss2: (0.0000) | Acc: (90.00%) (44214/48768)
Epoch: 90 | Batch_idx: 390 |  Loss: (0.2711) |  Loss2: (0.0000) | Acc: (90.00%) (45325/50000)
=> saving checkpoint 'drive/app/torch/save_Schedule/checkpoint_090.pth.tar'
# TEST : Loss: (0.4412) | Acc: (85.00%) (8540/10000)
percent tensor([0.5151, 0.5045, 0.5088, 0.5079, 0.5115, 0.5215, 0.5085, 0.5069, 0.5134,
        0.5063, 0.5157, 0.5065, 0.5067, 0.5107, 0.5118, 0.5132],
       device='cuda:0') torch.Size([16])
percent tensor([0.5099, 0.5028, 0.5136, 0.5131, 0.5114, 0.5100, 0.5059, 0.5134, 0.5137,
        0.5064, 0.5104, 0.5074, 0.5042, 0.5135, 0.5051, 0.5104],
       device='cuda:0') torch.Size([16])
percent tensor([0.5517, 0.5378, 0.5611, 0.5721, 0.5653, 0.5460, 0.5493, 0.5620, 0.5568,
        0.5467, 0.5503, 0.5525, 0.5246, 0.5850, 0.5368, 0.5595],
       device='cuda:0') torch.Size([16])
percent tensor([0.5873, 0.6032, 0.5806, 0.5770, 0.5751, 0.5803, 0.5957, 0.5755, 0.5986,
        0.6077, 0.6122, 0.5945, 0.5991, 0.6083, 0.5836, 0.5977],
       device='cuda:0') torch.Size([16])
percent tensor([0.5617, 0.5905, 0.4262, 0.5149, 0.4521, 0.5719, 0.5582, 0.3596, 0.6269,
        0.5881, 0.6606, 0.5140, 0.5840, 0.6485, 0.4998, 0.5837],
       device='cuda:0') torch.Size([16])
percent tensor([0.5792, 0.5490, 0.6103, 0.6022, 0.6401, 0.5901, 0.5878, 0.6370, 0.5696,
        0.5611, 0.5429, 0.5573, 0.5288, 0.5561, 0.5780, 0.5971],
       device='cuda:0') torch.Size([16])
percent tensor([0.5119, 0.5646, 0.6563, 0.6213, 0.7036, 0.7396, 0.5355, 0.6386, 0.5939,
        0.5270, 0.6116, 0.5356, 0.5741, 0.5619, 0.5359, 0.5470],
       device='cuda:0') torch.Size([16])
percent tensor([0.9993, 0.9987, 0.9989, 0.9989, 0.9984, 0.9991, 0.9982, 0.9993, 0.9994,
        0.9989, 0.9994, 0.9991, 0.9992, 0.9979, 0.9989, 0.9993],
       device='cuda:0') torch.Size([16])
Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 3, 3, 3]) tensor(182.0933, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(815.5195, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(803.8458, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([128, 64, 3, 3]) tensor(1526.1525, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([128, 64, 1, 1]) tensor(490.3595, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([128, 128, 3, 3]) tensor(2239.2769, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([256, 128, 3, 3]) tensor(4266.9556, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([256, 128, 1, 1]) tensor(1393.5890, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([256, 256, 3, 3]) tensor(6110.1143, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([512, 256, 3, 3]) tensor(11888.9521, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([512, 256, 1, 1]) tensor(3953.7742, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([512, 512, 3, 3]) tensor(16721.5801, device='cuda:0', grad_fn=<NormBackward0>)
Epoch: 91 | Batch_idx: 0 |  Loss: (0.3184) |  Loss2: (0.0000) | Acc: (88.00%) (113/128)
Epoch: 91 | Batch_idx: 10 |  Loss: (0.2585) |  Loss2: (0.0000) | Acc: (91.00%) (1292/1408)
Epoch: 91 | Batch_idx: 20 |  Loss: (0.2616) |  Loss2: (0.0000) | Acc: (91.00%) (2460/2688)
Epoch: 91 | Batch_idx: 30 |  Loss: (0.2639) |  Loss2: (0.0000) | Acc: (91.00%) (3616/3968)
Epoch: 91 | Batch_idx: 40 |  Loss: (0.2637) |  Loss2: (0.0000) | Acc: (91.00%) (4784/5248)
Epoch: 91 | Batch_idx: 50 |  Loss: (0.2699) |  Loss2: (0.0000) | Acc: (90.00%) (5927/6528)
Epoch: 91 | Batch_idx: 60 |  Loss: (0.2662) |  Loss2: (0.0000) | Acc: (90.00%) (7097/7808)
Epoch: 91 | Batch_idx: 70 |  Loss: (0.2643) |  Loss2: (0.0000) | Acc: (90.00%) (8268/9088)
Epoch: 91 | Batch_idx: 80 |  Loss: (0.2661) |  Loss2: (0.0000) | Acc: (90.00%) (9429/10368)
Epoch: 91 | Batch_idx: 90 |  Loss: (0.2703) |  Loss2: (0.0000) | Acc: (90.00%) (10575/11648)
Epoch: 91 | Batch_idx: 100 |  Loss: (0.2708) |  Loss2: (0.0000) | Acc: (90.00%) (11731/12928)
Epoch: 91 | Batch_idx: 110 |  Loss: (0.2684) |  Loss2: (0.0000) | Acc: (90.00%) (12899/14208)
Epoch: 91 | Batch_idx: 120 |  Loss: (0.2684) |  Loss2: (0.0000) | Acc: (90.00%) (14060/15488)
Epoch: 91 | Batch_idx: 130 |  Loss: (0.2688) |  Loss2: (0.0000) | Acc: (90.00%) (15221/16768)
Epoch: 91 | Batch_idx: 140 |  Loss: (0.2689) |  Loss2: (0.0000) | Acc: (90.00%) (16376/18048)
Epoch: 91 | Batch_idx: 150 |  Loss: (0.2686) |  Loss2: (0.0000) | Acc: (90.00%) (17537/19328)
Epoch: 91 | Batch_idx: 160 |  Loss: (0.2666) |  Loss2: (0.0000) | Acc: (90.00%) (18709/20608)
Epoch: 91 | Batch_idx: 170 |  Loss: (0.2648) |  Loss2: (0.0000) | Acc: (90.00%) (19894/21888)
Epoch: 91 | Batch_idx: 180 |  Loss: (0.2641) |  Loss2: (0.0000) | Acc: (90.00%) (21068/23168)
Epoch: 91 | Batch_idx: 190 |  Loss: (0.2645) |  Loss2: (0.0000) | Acc: (90.00%) (22228/24448)
Epoch: 91 | Batch_idx: 200 |  Loss: (0.2632) |  Loss2: (0.0000) | Acc: (91.00%) (23413/25728)
Epoch: 91 | Batch_idx: 210 |  Loss: (0.2636) |  Loss2: (0.0000) | Acc: (90.00%) (24569/27008)
Epoch: 91 | Batch_idx: 220 |  Loss: (0.2623) |  Loss2: (0.0000) | Acc: (91.00%) (25743/28288)
Epoch: 91 | Batch_idx: 230 |  Loss: (0.2620) |  Loss2: (0.0000) | Acc: (91.00%) (26912/29568)
Epoch: 91 | Batch_idx: 240 |  Loss: (0.2627) |  Loss2: (0.0000) | Acc: (90.00%) (28060/30848)
Epoch: 91 | Batch_idx: 250 |  Loss: (0.2625) |  Loss2: (0.0000) | Acc: (90.00%) (29233/32128)
Epoch: 91 | Batch_idx: 260 |  Loss: (0.2631) |  Loss2: (0.0000) | Acc: (90.00%) (30386/33408)
Epoch: 91 | Batch_idx: 270 |  Loss: (0.2630) |  Loss2: (0.0000) | Acc: (90.00%) (31543/34688)
Epoch: 91 | Batch_idx: 280 |  Loss: (0.2624) |  Loss2: (0.0000) | Acc: (90.00%) (32705/35968)
Epoch: 91 | Batch_idx: 290 |  Loss: (0.2630) |  Loss2: (0.0000) | Acc: (90.00%) (33848/37248)
Epoch: 91 | Batch_idx: 300 |  Loss: (0.2642) |  Loss2: (0.0000) | Acc: (90.00%) (34991/38528)
Epoch: 91 | Batch_idx: 310 |  Loss: (0.2644) |  Loss2: (0.0000) | Acc: (90.00%) (36149/39808)
Epoch: 91 | Batch_idx: 320 |  Loss: (0.2651) |  Loss2: (0.0000) | Acc: (90.00%) (37306/41088)
Epoch: 91 | Batch_idx: 330 |  Loss: (0.2648) |  Loss2: (0.0000) | Acc: (90.00%) (38463/42368)
Epoch: 91 | Batch_idx: 340 |  Loss: (0.2650) |  Loss2: (0.0000) | Acc: (90.00%) (39635/43648)
Epoch: 91 | Batch_idx: 350 |  Loss: (0.2649) |  Loss2: (0.0000) | Acc: (90.00%) (40795/44928)
Epoch: 91 | Batch_idx: 360 |  Loss: (0.2646) |  Loss2: (0.0000) | Acc: (90.00%) (41955/46208)
Epoch: 91 | Batch_idx: 370 |  Loss: (0.2643) |  Loss2: (0.0000) | Acc: (90.00%) (43125/47488)
Epoch: 91 | Batch_idx: 380 |  Loss: (0.2641) |  Loss2: (0.0000) | Acc: (90.00%) (44290/48768)
Epoch: 91 | Batch_idx: 390 |  Loss: (0.2637) |  Loss2: (0.0000) | Acc: (90.00%) (45405/50000)
# TEST : Loss: (0.4316) | Acc: (86.00%) (8609/10000)
percent tensor([0.5163, 0.5054, 0.5099, 0.5085, 0.5126, 0.5225, 0.5092, 0.5080, 0.5139,
        0.5076, 0.5164, 0.5084, 0.5074, 0.5103, 0.5128, 0.5138],
       device='cuda:0') torch.Size([16])
percent tensor([0.5090, 0.5032, 0.5117, 0.5115, 0.5101, 0.5089, 0.5059, 0.5127, 0.5141,
        0.5067, 0.5115, 0.5061, 0.5042, 0.5136, 0.5047, 0.5104],
       device='cuda:0') torch.Size([16])
percent tensor([0.5538, 0.5396, 0.5529, 0.5686, 0.5620, 0.5515, 0.5484, 0.5614, 0.5541,
        0.5471, 0.5495, 0.5475, 0.5245, 0.5817, 0.5395, 0.5614],
       device='cuda:0') torch.Size([16])
percent tensor([0.5863, 0.6034, 0.5807, 0.5796, 0.5758, 0.5804, 0.5950, 0.5760, 0.5970,
        0.6074, 0.6129, 0.5933, 0.5970, 0.6107, 0.5812, 0.5951],
       device='cuda:0') torch.Size([16])
percent tensor([0.5707, 0.6186, 0.4547, 0.5535, 0.4584, 0.5854, 0.5676, 0.3674, 0.6306,
        0.6110, 0.6716, 0.5511, 0.6120, 0.6567, 0.5280, 0.5948],
       device='cuda:0') torch.Size([16])
percent tensor([0.5857, 0.5676, 0.6071, 0.6068, 0.6405, 0.5988, 0.5972, 0.6472, 0.5818,
        0.5753, 0.5552, 0.5615, 0.5441, 0.5561, 0.5909, 0.6097],
       device='cuda:0') torch.Size([16])
percent tensor([0.5142, 0.5617, 0.6773, 0.6211, 0.7188, 0.7246, 0.5635, 0.6549, 0.6160,
        0.5150, 0.6285, 0.5409, 0.5906, 0.5852, 0.5206, 0.5613],
       device='cuda:0') torch.Size([16])
percent tensor([0.9991, 0.9987, 0.9983, 0.9986, 0.9985, 0.9980, 0.9982, 0.9996, 0.9993,
        0.9988, 0.9996, 0.9990, 0.9994, 0.9978, 0.9986, 0.9989],
       device='cuda:0') torch.Size([16])
Epoch: 92 | Batch_idx: 0 |  Loss: (0.4049) |  Loss2: (0.0000) | Acc: (83.00%) (107/128)
Epoch: 92 | Batch_idx: 10 |  Loss: (0.2667) |  Loss2: (0.0000) | Acc: (91.00%) (1285/1408)
Epoch: 92 | Batch_idx: 20 |  Loss: (0.2526) |  Loss2: (0.0000) | Acc: (91.00%) (2468/2688)
Epoch: 92 | Batch_idx: 30 |  Loss: (0.2466) |  Loss2: (0.0000) | Acc: (91.00%) (3641/3968)
Epoch: 92 | Batch_idx: 40 |  Loss: (0.2485) |  Loss2: (0.0000) | Acc: (91.00%) (4803/5248)
Epoch: 92 | Batch_idx: 50 |  Loss: (0.2461) |  Loss2: (0.0000) | Acc: (91.00%) (5975/6528)
Epoch: 92 | Batch_idx: 60 |  Loss: (0.2458) |  Loss2: (0.0000) | Acc: (91.00%) (7152/7808)
Epoch: 92 | Batch_idx: 70 |  Loss: (0.2514) |  Loss2: (0.0000) | Acc: (91.00%) (8300/9088)
Epoch: 92 | Batch_idx: 80 |  Loss: (0.2567) |  Loss2: (0.0000) | Acc: (91.00%) (9456/10368)
Epoch: 92 | Batch_idx: 90 |  Loss: (0.2549) |  Loss2: (0.0000) | Acc: (91.00%) (10633/11648)
Epoch: 92 | Batch_idx: 100 |  Loss: (0.2573) |  Loss2: (0.0000) | Acc: (91.00%) (11791/12928)
Epoch: 92 | Batch_idx: 110 |  Loss: (0.2572) |  Loss2: (0.0000) | Acc: (91.00%) (12955/14208)
Epoch: 92 | Batch_idx: 120 |  Loss: (0.2580) |  Loss2: (0.0000) | Acc: (91.00%) (14109/15488)
Epoch: 92 | Batch_idx: 130 |  Loss: (0.2573) |  Loss2: (0.0000) | Acc: (91.00%) (15272/16768)
Epoch: 92 | Batch_idx: 140 |  Loss: (0.2583) |  Loss2: (0.0000) | Acc: (90.00%) (16421/18048)
Epoch: 92 | Batch_idx: 150 |  Loss: (0.2557) |  Loss2: (0.0000) | Acc: (91.00%) (17592/19328)
Epoch: 92 | Batch_idx: 160 |  Loss: (0.2565) |  Loss2: (0.0000) | Acc: (90.00%) (18747/20608)
Epoch: 92 | Batch_idx: 170 |  Loss: (0.2546) |  Loss2: (0.0000) | Acc: (91.00%) (19924/21888)
Epoch: 92 | Batch_idx: 180 |  Loss: (0.2559) |  Loss2: (0.0000) | Acc: (90.00%) (21067/23168)
Epoch: 92 | Batch_idx: 190 |  Loss: (0.2544) |  Loss2: (0.0000) | Acc: (91.00%) (22253/24448)
Epoch: 92 | Batch_idx: 200 |  Loss: (0.2559) |  Loss2: (0.0000) | Acc: (90.00%) (23408/25728)
Epoch: 92 | Batch_idx: 210 |  Loss: (0.2555) |  Loss2: (0.0000) | Acc: (91.00%) (24590/27008)
Epoch: 92 | Batch_idx: 220 |  Loss: (0.2571) |  Loss2: (0.0000) | Acc: (91.00%) (25747/28288)
Epoch: 92 | Batch_idx: 230 |  Loss: (0.2554) |  Loss2: (0.0000) | Acc: (91.00%) (26939/29568)
Epoch: 92 | Batch_idx: 240 |  Loss: (0.2548) |  Loss2: (0.0000) | Acc: (91.00%) (28110/30848)
Epoch: 92 | Batch_idx: 250 |  Loss: (0.2539) |  Loss2: (0.0000) | Acc: (91.00%) (29299/32128)
Epoch: 92 | Batch_idx: 260 |  Loss: (0.2548) |  Loss2: (0.0000) | Acc: (91.00%) (30457/33408)
Epoch: 92 | Batch_idx: 270 |  Loss: (0.2556) |  Loss2: (0.0000) | Acc: (91.00%) (31610/34688)
Epoch: 92 | Batch_idx: 280 |  Loss: (0.2567) |  Loss2: (0.0000) | Acc: (91.00%) (32764/35968)
Epoch: 92 | Batch_idx: 290 |  Loss: (0.2554) |  Loss2: (0.0000) | Acc: (91.00%) (33955/37248)
Epoch: 92 | Batch_idx: 300 |  Loss: (0.2572) |  Loss2: (0.0000) | Acc: (91.00%) (35087/38528)
Epoch: 92 | Batch_idx: 310 |  Loss: (0.2576) |  Loss2: (0.0000) | Acc: (91.00%) (36255/39808)
Epoch: 92 | Batch_idx: 320 |  Loss: (0.2567) |  Loss2: (0.0000) | Acc: (91.00%) (37441/41088)
Epoch: 92 | Batch_idx: 330 |  Loss: (0.2568) |  Loss2: (0.0000) | Acc: (91.00%) (38602/42368)
Epoch: 92 | Batch_idx: 340 |  Loss: (0.2575) |  Loss2: (0.0000) | Acc: (91.00%) (39755/43648)
Epoch: 92 | Batch_idx: 350 |  Loss: (0.2577) |  Loss2: (0.0000) | Acc: (91.00%) (40913/44928)
Epoch: 92 | Batch_idx: 360 |  Loss: (0.2583) |  Loss2: (0.0000) | Acc: (91.00%) (42073/46208)
Epoch: 92 | Batch_idx: 370 |  Loss: (0.2585) |  Loss2: (0.0000) | Acc: (91.00%) (43227/47488)
Epoch: 92 | Batch_idx: 380 |  Loss: (0.2592) |  Loss2: (0.0000) | Acc: (91.00%) (44384/48768)
Epoch: 92 | Batch_idx: 390 |  Loss: (0.2588) |  Loss2: (0.0000) | Acc: (91.00%) (45510/50000)
# TEST : Loss: (0.4610) | Acc: (85.00%) (8505/10000)
percent tensor([0.5152, 0.5056, 0.5096, 0.5086, 0.5121, 0.5223, 0.5087, 0.5082, 0.5137,
        0.5070, 0.5162, 0.5075, 0.5070, 0.5105, 0.5129, 0.5139],
       device='cuda:0') torch.Size([16])
percent tensor([0.5100, 0.5037, 0.5137, 0.5132, 0.5111, 0.5102, 0.5068, 0.5139, 0.5149,
        0.5071, 0.5118, 0.5074, 0.5053, 0.5142, 0.5055, 0.5112],
       device='cuda:0') torch.Size([16])
percent tensor([0.5580, 0.5412, 0.5597, 0.5763, 0.5662, 0.5542, 0.5543, 0.5651, 0.5593,
        0.5504, 0.5535, 0.5533, 0.5301, 0.5858, 0.5425, 0.5655],
       device='cuda:0') torch.Size([16])
percent tensor([0.5897, 0.6037, 0.5819, 0.5790, 0.5770, 0.5817, 0.5963, 0.5743, 0.5984,
        0.6079, 0.6141, 0.5979, 0.6021, 0.6106, 0.5824, 0.5974],
       device='cuda:0') torch.Size([16])
percent tensor([0.5728, 0.6098, 0.4481, 0.5320, 0.4598, 0.5760, 0.5602, 0.3666, 0.6276,
        0.6109, 0.6651, 0.5603, 0.6104, 0.6506, 0.5156, 0.5859],
       device='cuda:0') torch.Size([16])
percent tensor([0.5836, 0.5694, 0.6147, 0.6106, 0.6422, 0.6031, 0.5953, 0.6449, 0.5814,
        0.5764, 0.5508, 0.5602, 0.5378, 0.5594, 0.5845, 0.6085],
       device='cuda:0') torch.Size([16])
percent tensor([0.5188, 0.5777, 0.6924, 0.6354, 0.7173, 0.7283, 0.5386, 0.6713, 0.5998,
        0.5331, 0.6233, 0.5480, 0.5606, 0.5760, 0.5305, 0.5500],
       device='cuda:0') torch.Size([16])
percent tensor([0.9987, 0.9987, 0.9992, 0.9991, 0.9987, 0.9988, 0.9980, 0.9997, 0.9995,
        0.9992, 0.9997, 0.9990, 0.9995, 0.9979, 0.9989, 0.9988],
       device='cuda:0') torch.Size([16])
Epoch: 93 | Batch_idx: 0 |  Loss: (0.2230) |  Loss2: (0.0000) | Acc: (92.00%) (119/128)
Epoch: 93 | Batch_idx: 10 |  Loss: (0.2470) |  Loss2: (0.0000) | Acc: (90.00%) (1277/1408)
Epoch: 93 | Batch_idx: 20 |  Loss: (0.2384) |  Loss2: (0.0000) | Acc: (91.00%) (2463/2688)
Epoch: 93 | Batch_idx: 30 |  Loss: (0.2517) |  Loss2: (0.0000) | Acc: (91.00%) (3628/3968)
Epoch: 93 | Batch_idx: 40 |  Loss: (0.2570) |  Loss2: (0.0000) | Acc: (91.00%) (4783/5248)
Epoch: 93 | Batch_idx: 50 |  Loss: (0.2513) |  Loss2: (0.0000) | Acc: (91.00%) (5966/6528)
Epoch: 93 | Batch_idx: 60 |  Loss: (0.2504) |  Loss2: (0.0000) | Acc: (91.00%) (7137/7808)
Epoch: 93 | Batch_idx: 70 |  Loss: (0.2472) |  Loss2: (0.0000) | Acc: (91.00%) (8321/9088)
Epoch: 93 | Batch_idx: 80 |  Loss: (0.2460) |  Loss2: (0.0000) | Acc: (91.00%) (9494/10368)
Epoch: 93 | Batch_idx: 90 |  Loss: (0.2449) |  Loss2: (0.0000) | Acc: (91.00%) (10664/11648)
Epoch: 93 | Batch_idx: 100 |  Loss: (0.2460) |  Loss2: (0.0000) | Acc: (91.00%) (11833/12928)
Epoch: 93 | Batch_idx: 110 |  Loss: (0.2486) |  Loss2: (0.0000) | Acc: (91.00%) (12988/14208)
Epoch: 93 | Batch_idx: 120 |  Loss: (0.2487) |  Loss2: (0.0000) | Acc: (91.00%) (14167/15488)
Epoch: 93 | Batch_idx: 130 |  Loss: (0.2474) |  Loss2: (0.0000) | Acc: (91.00%) (15352/16768)
Epoch: 93 | Batch_idx: 140 |  Loss: (0.2455) |  Loss2: (0.0000) | Acc: (91.00%) (16523/18048)
Epoch: 93 | Batch_idx: 150 |  Loss: (0.2434) |  Loss2: (0.0000) | Acc: (91.00%) (17704/19328)
Epoch: 93 | Batch_idx: 160 |  Loss: (0.2445) |  Loss2: (0.0000) | Acc: (91.00%) (18874/20608)
Epoch: 93 | Batch_idx: 170 |  Loss: (0.2440) |  Loss2: (0.0000) | Acc: (91.00%) (20052/21888)
Epoch: 93 | Batch_idx: 180 |  Loss: (0.2435) |  Loss2: (0.0000) | Acc: (91.00%) (21231/23168)
Epoch: 93 | Batch_idx: 190 |  Loss: (0.2421) |  Loss2: (0.0000) | Acc: (91.00%) (22420/24448)
Epoch: 93 | Batch_idx: 200 |  Loss: (0.2418) |  Loss2: (0.0000) | Acc: (91.00%) (23594/25728)
Epoch: 93 | Batch_idx: 210 |  Loss: (0.2411) |  Loss2: (0.0000) | Acc: (91.00%) (24778/27008)
Epoch: 93 | Batch_idx: 220 |  Loss: (0.2415) |  Loss2: (0.0000) | Acc: (91.00%) (25955/28288)
Epoch: 93 | Batch_idx: 230 |  Loss: (0.2423) |  Loss2: (0.0000) | Acc: (91.00%) (27137/29568)
Epoch: 93 | Batch_idx: 240 |  Loss: (0.2435) |  Loss2: (0.0000) | Acc: (91.00%) (28292/30848)
Epoch: 93 | Batch_idx: 250 |  Loss: (0.2423) |  Loss2: (0.0000) | Acc: (91.00%) (29475/32128)
Epoch: 93 | Batch_idx: 260 |  Loss: (0.2431) |  Loss2: (0.0000) | Acc: (91.00%) (30636/33408)
Epoch: 93 | Batch_idx: 270 |  Loss: (0.2429) |  Loss2: (0.0000) | Acc: (91.00%) (31809/34688)
Epoch: 93 | Batch_idx: 280 |  Loss: (0.2448) |  Loss2: (0.0000) | Acc: (91.00%) (32953/35968)
Epoch: 93 | Batch_idx: 290 |  Loss: (0.2456) |  Loss2: (0.0000) | Acc: (91.00%) (34116/37248)
Epoch: 93 | Batch_idx: 300 |  Loss: (0.2462) |  Loss2: (0.0000) | Acc: (91.00%) (35288/38528)
Epoch: 93 | Batch_idx: 310 |  Loss: (0.2468) |  Loss2: (0.0000) | Acc: (91.00%) (36453/39808)
Epoch: 93 | Batch_idx: 320 |  Loss: (0.2465) |  Loss2: (0.0000) | Acc: (91.00%) (37635/41088)
Epoch: 93 | Batch_idx: 330 |  Loss: (0.2475) |  Loss2: (0.0000) | Acc: (91.00%) (38783/42368)
Epoch: 93 | Batch_idx: 340 |  Loss: (0.2475) |  Loss2: (0.0000) | Acc: (91.00%) (39951/43648)
Epoch: 93 | Batch_idx: 350 |  Loss: (0.2484) |  Loss2: (0.0000) | Acc: (91.00%) (41121/44928)
Epoch: 93 | Batch_idx: 360 |  Loss: (0.2493) |  Loss2: (0.0000) | Acc: (91.00%) (42273/46208)
Epoch: 93 | Batch_idx: 370 |  Loss: (0.2493) |  Loss2: (0.0000) | Acc: (91.00%) (43453/47488)
Epoch: 93 | Batch_idx: 380 |  Loss: (0.2495) |  Loss2: (0.0000) | Acc: (91.00%) (44613/48768)
Epoch: 93 | Batch_idx: 390 |  Loss: (0.2503) |  Loss2: (0.0000) | Acc: (91.00%) (45734/50000)
# TEST : Loss: (0.4487) | Acc: (85.00%) (8566/10000)
percent tensor([0.5145, 0.5057, 0.5096, 0.5072, 0.5118, 0.5218, 0.5093, 0.5068, 0.5131,
        0.5065, 0.5156, 0.5072, 0.5061, 0.5120, 0.5125, 0.5132],
       device='cuda:0') torch.Size([16])
percent tensor([0.5084, 0.5026, 0.5125, 0.5113, 0.5103, 0.5090, 0.5050, 0.5123, 0.5133,
        0.5060, 0.5101, 0.5060, 0.5033, 0.5118, 0.5048, 0.5096],
       device='cuda:0') torch.Size([16])
percent tensor([0.5531, 0.5322, 0.5572, 0.5728, 0.5636, 0.5514, 0.5442, 0.5622, 0.5542,
        0.5457, 0.5494, 0.5494, 0.5233, 0.5734, 0.5395, 0.5595],
       device='cuda:0') torch.Size([16])
percent tensor([0.5845, 0.6018, 0.5799, 0.5778, 0.5750, 0.5796, 0.5945, 0.5738, 0.5961,
        0.6064, 0.6110, 0.5936, 0.5963, 0.6084, 0.5834, 0.5948],
       device='cuda:0') torch.Size([16])
percent tensor([0.5375, 0.5829, 0.4553, 0.5601, 0.4538, 0.5770, 0.5543, 0.3734, 0.6178,
        0.5820, 0.6467, 0.5294, 0.5732, 0.6515, 0.5123, 0.5627],
       device='cuda:0') torch.Size([16])
percent tensor([0.5897, 0.5680, 0.6120, 0.6068, 0.6405, 0.6000, 0.5879, 0.6459, 0.5869,
        0.5771, 0.5530, 0.5606, 0.5388, 0.5609, 0.5910, 0.6074],
       device='cuda:0') torch.Size([16])
percent tensor([0.5039, 0.5754, 0.6819, 0.5980, 0.7065, 0.7241, 0.5337, 0.6523, 0.5885,
        0.5399, 0.5959, 0.5509, 0.5627, 0.5914, 0.5150, 0.5373],
       device='cuda:0') torch.Size([16])
percent tensor([0.9988, 0.9984, 0.9987, 0.9987, 0.9985, 0.9979, 0.9986, 0.9996, 0.9993,
        0.9992, 0.9995, 0.9989, 0.9993, 0.9981, 0.9990, 0.9992],
       device='cuda:0') torch.Size([16])
Epoch: 94 | Batch_idx: 0 |  Loss: (0.3945) |  Loss2: (0.0000) | Acc: (86.00%) (111/128)
Epoch: 94 | Batch_idx: 10 |  Loss: (0.2658) |  Loss2: (0.0000) | Acc: (89.00%) (1265/1408)
Epoch: 94 | Batch_idx: 20 |  Loss: (0.2573) |  Loss2: (0.0000) | Acc: (90.00%) (2432/2688)
Epoch: 94 | Batch_idx: 30 |  Loss: (0.2457) |  Loss2: (0.0000) | Acc: (91.00%) (3614/3968)
Epoch: 94 | Batch_idx: 40 |  Loss: (0.2422) |  Loss2: (0.0000) | Acc: (91.00%) (4786/5248)
Epoch: 94 | Batch_idx: 50 |  Loss: (0.2357) |  Loss2: (0.0000) | Acc: (91.00%) (5983/6528)
Epoch: 94 | Batch_idx: 60 |  Loss: (0.2346) |  Loss2: (0.0000) | Acc: (91.00%) (7167/7808)
Epoch: 94 | Batch_idx: 70 |  Loss: (0.2383) |  Loss2: (0.0000) | Acc: (91.00%) (8327/9088)
Epoch: 94 | Batch_idx: 80 |  Loss: (0.2372) |  Loss2: (0.0000) | Acc: (91.00%) (9491/10368)
Epoch: 94 | Batch_idx: 90 |  Loss: (0.2374) |  Loss2: (0.0000) | Acc: (91.00%) (10666/11648)
Epoch: 94 | Batch_idx: 100 |  Loss: (0.2344) |  Loss2: (0.0000) | Acc: (91.00%) (11858/12928)
Epoch: 94 | Batch_idx: 110 |  Loss: (0.2359) |  Loss2: (0.0000) | Acc: (91.00%) (13026/14208)
Epoch: 94 | Batch_idx: 120 |  Loss: (0.2373) |  Loss2: (0.0000) | Acc: (91.00%) (14190/15488)
Epoch: 94 | Batch_idx: 130 |  Loss: (0.2385) |  Loss2: (0.0000) | Acc: (91.00%) (15360/16768)
Epoch: 94 | Batch_idx: 140 |  Loss: (0.2397) |  Loss2: (0.0000) | Acc: (91.00%) (16519/18048)
Epoch: 94 | Batch_idx: 150 |  Loss: (0.2403) |  Loss2: (0.0000) | Acc: (91.00%) (17685/19328)
Epoch: 94 | Batch_idx: 160 |  Loss: (0.2425) |  Loss2: (0.0000) | Acc: (91.00%) (18843/20608)
Epoch: 94 | Batch_idx: 170 |  Loss: (0.2434) |  Loss2: (0.0000) | Acc: (91.00%) (20006/21888)
Epoch: 94 | Batch_idx: 180 |  Loss: (0.2444) |  Loss2: (0.0000) | Acc: (91.00%) (21165/23168)
Epoch: 94 | Batch_idx: 190 |  Loss: (0.2433) |  Loss2: (0.0000) | Acc: (91.00%) (22352/24448)
Epoch: 94 | Batch_idx: 200 |  Loss: (0.2437) |  Loss2: (0.0000) | Acc: (91.00%) (23528/25728)
Epoch: 94 | Batch_idx: 210 |  Loss: (0.2433) |  Loss2: (0.0000) | Acc: (91.00%) (24696/27008)
Epoch: 94 | Batch_idx: 220 |  Loss: (0.2437) |  Loss2: (0.0000) | Acc: (91.00%) (25874/28288)
Epoch: 94 | Batch_idx: 230 |  Loss: (0.2437) |  Loss2: (0.0000) | Acc: (91.00%) (27045/29568)
Epoch: 94 | Batch_idx: 240 |  Loss: (0.2438) |  Loss2: (0.0000) | Acc: (91.00%) (28221/30848)
Epoch: 94 | Batch_idx: 250 |  Loss: (0.2435) |  Loss2: (0.0000) | Acc: (91.00%) (29399/32128)
Epoch: 94 | Batch_idx: 260 |  Loss: (0.2428) |  Loss2: (0.0000) | Acc: (91.00%) (30571/33408)
Epoch: 94 | Batch_idx: 270 |  Loss: (0.2434) |  Loss2: (0.0000) | Acc: (91.00%) (31737/34688)
Epoch: 94 | Batch_idx: 280 |  Loss: (0.2437) |  Loss2: (0.0000) | Acc: (91.00%) (32901/35968)
Epoch: 94 | Batch_idx: 290 |  Loss: (0.2444) |  Loss2: (0.0000) | Acc: (91.00%) (34065/37248)
Epoch: 94 | Batch_idx: 300 |  Loss: (0.2438) |  Loss2: (0.0000) | Acc: (91.00%) (35241/38528)
Epoch: 94 | Batch_idx: 310 |  Loss: (0.2447) |  Loss2: (0.0000) | Acc: (91.00%) (36399/39808)
Epoch: 94 | Batch_idx: 320 |  Loss: (0.2442) |  Loss2: (0.0000) | Acc: (91.00%) (37575/41088)
Epoch: 94 | Batch_idx: 330 |  Loss: (0.2443) |  Loss2: (0.0000) | Acc: (91.00%) (38740/42368)
Epoch: 94 | Batch_idx: 340 |  Loss: (0.2445) |  Loss2: (0.0000) | Acc: (91.00%) (39907/43648)
Epoch: 94 | Batch_idx: 350 |  Loss: (0.2446) |  Loss2: (0.0000) | Acc: (91.00%) (41076/44928)
Epoch: 94 | Batch_idx: 360 |  Loss: (0.2439) |  Loss2: (0.0000) | Acc: (91.00%) (42255/46208)
Epoch: 94 | Batch_idx: 370 |  Loss: (0.2436) |  Loss2: (0.0000) | Acc: (91.00%) (43431/47488)
Epoch: 94 | Batch_idx: 380 |  Loss: (0.2433) |  Loss2: (0.0000) | Acc: (91.00%) (44607/48768)
Epoch: 94 | Batch_idx: 390 |  Loss: (0.2425) |  Loss2: (0.0000) | Acc: (91.00%) (45739/50000)
# TEST : Loss: (0.4328) | Acc: (86.00%) (8630/10000)
percent tensor([0.5144, 0.5061, 0.5085, 0.5079, 0.5118, 0.5215, 0.5096, 0.5079, 0.5136,
        0.5069, 0.5160, 0.5070, 0.5066, 0.5132, 0.5125, 0.5136],
       device='cuda:0') torch.Size([16])
percent tensor([0.5091, 0.5042, 0.5113, 0.5119, 0.5100, 0.5101, 0.5064, 0.5130, 0.5142,
        0.5069, 0.5117, 0.5054, 0.5040, 0.5148, 0.5055, 0.5109],
       device='cuda:0') torch.Size([16])
percent tensor([0.5502, 0.5384, 0.5477, 0.5705, 0.5596, 0.5501, 0.5488, 0.5615, 0.5530,
        0.5454, 0.5508, 0.5457, 0.5229, 0.5824, 0.5405, 0.5610],
       device='cuda:0') torch.Size([16])
percent tensor([0.5856, 0.6009, 0.5858, 0.5823, 0.5800, 0.5782, 0.5943, 0.5749, 0.5987,
        0.6068, 0.6099, 0.5999, 0.5986, 0.6062, 0.5837, 0.5940],
       device='cuda:0') torch.Size([16])
percent tensor([0.5478, 0.5923, 0.4779, 0.5618, 0.4817, 0.5681, 0.5491, 0.3804, 0.6238,
        0.5886, 0.6452, 0.5553, 0.5838, 0.6374, 0.5155, 0.5635],
       device='cuda:0') torch.Size([16])
percent tensor([0.5865, 0.5745, 0.6012, 0.6016, 0.6372, 0.6068, 0.5978, 0.6380, 0.5807,
        0.5782, 0.5588, 0.5462, 0.5369, 0.5745, 0.5844, 0.6099],
       device='cuda:0') torch.Size([16])
percent tensor([0.5216, 0.5991, 0.6905, 0.6167, 0.7223, 0.7301, 0.5915, 0.6612, 0.6267,
        0.5524, 0.6554, 0.5387, 0.5806, 0.5794, 0.5370, 0.5437],
       device='cuda:0') torch.Size([16])
percent tensor([0.9993, 0.9985, 0.9994, 0.9992, 0.9989, 0.9990, 0.9978, 0.9995, 0.9993,
        0.9990, 0.9997, 0.9995, 0.9994, 0.9972, 0.9989, 0.9987],
       device='cuda:0') torch.Size([16])
Epoch: 95 | Batch_idx: 0 |  Loss: (0.2824) |  Loss2: (0.0000) | Acc: (92.00%) (118/128)
Epoch: 95 | Batch_idx: 10 |  Loss: (0.2364) |  Loss2: (0.0000) | Acc: (92.00%) (1306/1408)
Epoch: 95 | Batch_idx: 20 |  Loss: (0.2202) |  Loss2: (0.0000) | Acc: (92.00%) (2486/2688)
Epoch: 95 | Batch_idx: 30 |  Loss: (0.2246) |  Loss2: (0.0000) | Acc: (92.00%) (3664/3968)
Epoch: 95 | Batch_idx: 40 |  Loss: (0.2299) |  Loss2: (0.0000) | Acc: (92.00%) (4839/5248)
Epoch: 95 | Batch_idx: 50 |  Loss: (0.2301) |  Loss2: (0.0000) | Acc: (92.00%) (6020/6528)
Epoch: 95 | Batch_idx: 60 |  Loss: (0.2322) |  Loss2: (0.0000) | Acc: (91.00%) (7181/7808)
Epoch: 95 | Batch_idx: 70 |  Loss: (0.2292) |  Loss2: (0.0000) | Acc: (92.00%) (8369/9088)
Epoch: 95 | Batch_idx: 80 |  Loss: (0.2300) |  Loss2: (0.0000) | Acc: (92.00%) (9540/10368)
Epoch: 95 | Batch_idx: 90 |  Loss: (0.2282) |  Loss2: (0.0000) | Acc: (92.00%) (10732/11648)
Epoch: 95 | Batch_idx: 100 |  Loss: (0.2290) |  Loss2: (0.0000) | Acc: (92.00%) (11910/12928)
Epoch: 95 | Batch_idx: 110 |  Loss: (0.2292) |  Loss2: (0.0000) | Acc: (92.00%) (13098/14208)
Epoch: 95 | Batch_idx: 120 |  Loss: (0.2293) |  Loss2: (0.0000) | Acc: (92.00%) (14270/15488)
Epoch: 95 | Batch_idx: 130 |  Loss: (0.2303) |  Loss2: (0.0000) | Acc: (92.00%) (15450/16768)
Epoch: 95 | Batch_idx: 140 |  Loss: (0.2295) |  Loss2: (0.0000) | Acc: (92.00%) (16638/18048)
Epoch: 95 | Batch_idx: 150 |  Loss: (0.2285) |  Loss2: (0.0000) | Acc: (92.00%) (17821/19328)
Epoch: 95 | Batch_idx: 160 |  Loss: (0.2263) |  Loss2: (0.0000) | Acc: (92.00%) (19017/20608)
Epoch: 95 | Batch_idx: 170 |  Loss: (0.2261) |  Loss2: (0.0000) | Acc: (92.00%) (20201/21888)
Epoch: 95 | Batch_idx: 180 |  Loss: (0.2270) |  Loss2: (0.0000) | Acc: (92.00%) (21361/23168)
Epoch: 95 | Batch_idx: 190 |  Loss: (0.2271) |  Loss2: (0.0000) | Acc: (92.00%) (22539/24448)
Epoch: 95 | Batch_idx: 200 |  Loss: (0.2290) |  Loss2: (0.0000) | Acc: (92.00%) (23695/25728)
Epoch: 95 | Batch_idx: 210 |  Loss: (0.2302) |  Loss2: (0.0000) | Acc: (92.00%) (24862/27008)
Epoch: 95 | Batch_idx: 220 |  Loss: (0.2304) |  Loss2: (0.0000) | Acc: (92.00%) (26043/28288)
Epoch: 95 | Batch_idx: 230 |  Loss: (0.2312) |  Loss2: (0.0000) | Acc: (92.00%) (27206/29568)
Epoch: 95 | Batch_idx: 240 |  Loss: (0.2311) |  Loss2: (0.0000) | Acc: (92.00%) (28382/30848)
Epoch: 95 | Batch_idx: 250 |  Loss: (0.2315) |  Loss2: (0.0000) | Acc: (91.00%) (29545/32128)
Epoch: 95 | Batch_idx: 260 |  Loss: (0.2315) |  Loss2: (0.0000) | Acc: (91.00%) (30725/33408)
Epoch: 95 | Batch_idx: 270 |  Loss: (0.2322) |  Loss2: (0.0000) | Acc: (91.00%) (31890/34688)
Epoch: 95 | Batch_idx: 280 |  Loss: (0.2325) |  Loss2: (0.0000) | Acc: (91.00%) (33061/35968)
Epoch: 95 | Batch_idx: 290 |  Loss: (0.2332) |  Loss2: (0.0000) | Acc: (91.00%) (34232/37248)
Epoch: 95 | Batch_idx: 300 |  Loss: (0.2334) |  Loss2: (0.0000) | Acc: (91.00%) (35405/38528)
Epoch: 95 | Batch_idx: 310 |  Loss: (0.2341) |  Loss2: (0.0000) | Acc: (91.00%) (36572/39808)
Epoch: 95 | Batch_idx: 320 |  Loss: (0.2341) |  Loss2: (0.0000) | Acc: (91.00%) (37750/41088)
Epoch: 95 | Batch_idx: 330 |  Loss: (0.2349) |  Loss2: (0.0000) | Acc: (91.00%) (38913/42368)
Epoch: 95 | Batch_idx: 340 |  Loss: (0.2361) |  Loss2: (0.0000) | Acc: (91.00%) (40070/43648)
Epoch: 95 | Batch_idx: 350 |  Loss: (0.2370) |  Loss2: (0.0000) | Acc: (91.00%) (41221/44928)
Epoch: 95 | Batch_idx: 360 |  Loss: (0.2370) |  Loss2: (0.0000) | Acc: (91.00%) (42400/46208)
Epoch: 95 | Batch_idx: 370 |  Loss: (0.2375) |  Loss2: (0.0000) | Acc: (91.00%) (43567/47488)
Epoch: 95 | Batch_idx: 380 |  Loss: (0.2371) |  Loss2: (0.0000) | Acc: (91.00%) (44755/48768)
Epoch: 95 | Batch_idx: 390 |  Loss: (0.2369) |  Loss2: (0.0000) | Acc: (91.00%) (45891/50000)
=> saving checkpoint 'drive/app/torch/save_Schedule/checkpoint_095.pth.tar'
# TEST : Loss: (0.4394) | Acc: (85.00%) (8581/10000)
percent tensor([0.5148, 0.5058, 0.5097, 0.5080, 0.5127, 0.5222, 0.5095, 0.5081, 0.5135,
        0.5075, 0.5157, 0.5082, 0.5068, 0.5118, 0.5124, 0.5132],
       device='cuda:0') torch.Size([16])
percent tensor([0.5109, 0.5043, 0.5118, 0.5125, 0.5104, 0.5116, 0.5070, 0.5130, 0.5151,
        0.5073, 0.5130, 0.5062, 0.5055, 0.5160, 0.5058, 0.5122],
       device='cuda:0') torch.Size([16])
percent tensor([0.5541, 0.5387, 0.5543, 0.5735, 0.5628, 0.5523, 0.5510, 0.5624, 0.5562,
        0.5468, 0.5509, 0.5504, 0.5246, 0.5856, 0.5396, 0.5613],
       device='cuda:0') torch.Size([16])
percent tensor([0.5889, 0.6021, 0.5849, 0.5790, 0.5775, 0.5808, 0.5959, 0.5767, 0.6003,
        0.6074, 0.6138, 0.5989, 0.6011, 0.6112, 0.5825, 0.5950],
       device='cuda:0') torch.Size([16])
percent tensor([0.5702, 0.6054, 0.4676, 0.5418, 0.4754, 0.5715, 0.5537, 0.3799, 0.6331,
        0.6067, 0.6616, 0.5514, 0.6069, 0.6454, 0.5143, 0.5746],
       device='cuda:0') torch.Size([16])
percent tensor([0.5852, 0.5666, 0.5999, 0.6006, 0.6388, 0.6046, 0.5960, 0.6317, 0.5784,
        0.5700, 0.5546, 0.5499, 0.5272, 0.5734, 0.5839, 0.6113],
       device='cuda:0') torch.Size([16])
percent tensor([0.5154, 0.5653, 0.6941, 0.6340, 0.7208, 0.7309, 0.5633, 0.6450, 0.6049,
        0.5521, 0.6405, 0.5656, 0.5643, 0.5973, 0.5350, 0.5564],
       device='cuda:0') torch.Size([16])
percent tensor([0.9989, 0.9987, 0.9992, 0.9992, 0.9988, 0.9981, 0.9979, 0.9995, 0.9995,
        0.9985, 0.9996, 0.9995, 0.9994, 0.9975, 0.9984, 0.9984],
       device='cuda:0') torch.Size([16])
Epoch: 96 | Batch_idx: 0 |  Loss: (0.3559) |  Loss2: (0.0000) | Acc: (91.00%) (117/128)
Epoch: 96 | Batch_idx: 10 |  Loss: (0.2413) |  Loss2: (0.0000) | Acc: (91.00%) (1295/1408)
Epoch: 96 | Batch_idx: 20 |  Loss: (0.2340) |  Loss2: (0.0000) | Acc: (91.00%) (2472/2688)
Epoch: 96 | Batch_idx: 30 |  Loss: (0.2361) |  Loss2: (0.0000) | Acc: (91.00%) (3644/3968)
Epoch: 96 | Batch_idx: 40 |  Loss: (0.2329) |  Loss2: (0.0000) | Acc: (92.00%) (4834/5248)
Epoch: 96 | Batch_idx: 50 |  Loss: (0.2287) |  Loss2: (0.0000) | Acc: (92.00%) (6010/6528)
Epoch: 96 | Batch_idx: 60 |  Loss: (0.2269) |  Loss2: (0.0000) | Acc: (92.00%) (7202/7808)
Epoch: 96 | Batch_idx: 70 |  Loss: (0.2259) |  Loss2: (0.0000) | Acc: (92.00%) (8385/9088)
Epoch: 96 | Batch_idx: 80 |  Loss: (0.2243) |  Loss2: (0.0000) | Acc: (92.00%) (9570/10368)
Epoch: 96 | Batch_idx: 90 |  Loss: (0.2226) |  Loss2: (0.0000) | Acc: (92.00%) (10744/11648)
Epoch: 96 | Batch_idx: 100 |  Loss: (0.2233) |  Loss2: (0.0000) | Acc: (92.00%) (11916/12928)
Epoch: 96 | Batch_idx: 110 |  Loss: (0.2250) |  Loss2: (0.0000) | Acc: (92.00%) (13091/14208)
Epoch: 96 | Batch_idx: 120 |  Loss: (0.2242) |  Loss2: (0.0000) | Acc: (92.00%) (14275/15488)
Epoch: 96 | Batch_idx: 130 |  Loss: (0.2248) |  Loss2: (0.0000) | Acc: (92.00%) (15455/16768)
Epoch: 96 | Batch_idx: 140 |  Loss: (0.2250) |  Loss2: (0.0000) | Acc: (92.00%) (16639/18048)
Epoch: 96 | Batch_idx: 150 |  Loss: (0.2258) |  Loss2: (0.0000) | Acc: (92.00%) (17811/19328)
Epoch: 96 | Batch_idx: 160 |  Loss: (0.2258) |  Loss2: (0.0000) | Acc: (92.00%) (18995/20608)
Epoch: 96 | Batch_idx: 170 |  Loss: (0.2286) |  Loss2: (0.0000) | Acc: (92.00%) (20149/21888)
Epoch: 96 | Batch_idx: 180 |  Loss: (0.2285) |  Loss2: (0.0000) | Acc: (92.00%) (21328/23168)
Epoch: 96 | Batch_idx: 190 |  Loss: (0.2279) |  Loss2: (0.0000) | Acc: (92.00%) (22518/24448)
Epoch: 96 | Batch_idx: 200 |  Loss: (0.2280) |  Loss2: (0.0000) | Acc: (92.00%) (23693/25728)
Epoch: 96 | Batch_idx: 210 |  Loss: (0.2275) |  Loss2: (0.0000) | Acc: (92.00%) (24881/27008)
Epoch: 96 | Batch_idx: 220 |  Loss: (0.2283) |  Loss2: (0.0000) | Acc: (92.00%) (26054/28288)
Epoch: 96 | Batch_idx: 230 |  Loss: (0.2289) |  Loss2: (0.0000) | Acc: (92.00%) (27232/29568)
Epoch: 96 | Batch_idx: 240 |  Loss: (0.2292) |  Loss2: (0.0000) | Acc: (92.00%) (28406/30848)
Epoch: 96 | Batch_idx: 250 |  Loss: (0.2290) |  Loss2: (0.0000) | Acc: (92.00%) (29583/32128)
Epoch: 96 | Batch_idx: 260 |  Loss: (0.2301) |  Loss2: (0.0000) | Acc: (92.00%) (30750/33408)
Epoch: 96 | Batch_idx: 270 |  Loss: (0.2299) |  Loss2: (0.0000) | Acc: (92.00%) (31938/34688)
Epoch: 96 | Batch_idx: 280 |  Loss: (0.2308) |  Loss2: (0.0000) | Acc: (92.00%) (33109/35968)
Epoch: 96 | Batch_idx: 290 |  Loss: (0.2312) |  Loss2: (0.0000) | Acc: (92.00%) (34276/37248)
Epoch: 96 | Batch_idx: 300 |  Loss: (0.2316) |  Loss2: (0.0000) | Acc: (92.00%) (35449/38528)
Epoch: 96 | Batch_idx: 310 |  Loss: (0.2315) |  Loss2: (0.0000) | Acc: (91.00%) (36622/39808)
Epoch: 96 | Batch_idx: 320 |  Loss: (0.2314) |  Loss2: (0.0000) | Acc: (91.00%) (37793/41088)
Epoch: 96 | Batch_idx: 330 |  Loss: (0.2311) |  Loss2: (0.0000) | Acc: (91.00%) (38975/42368)
Epoch: 96 | Batch_idx: 340 |  Loss: (0.2313) |  Loss2: (0.0000) | Acc: (91.00%) (40150/43648)
Epoch: 96 | Batch_idx: 350 |  Loss: (0.2315) |  Loss2: (0.0000) | Acc: (91.00%) (41329/44928)
Epoch: 96 | Batch_idx: 360 |  Loss: (0.2316) |  Loss2: (0.0000) | Acc: (91.00%) (42511/46208)
Epoch: 96 | Batch_idx: 370 |  Loss: (0.2322) |  Loss2: (0.0000) | Acc: (91.00%) (43678/47488)
Epoch: 96 | Batch_idx: 380 |  Loss: (0.2326) |  Loss2: (0.0000) | Acc: (91.00%) (44849/48768)
Epoch: 96 | Batch_idx: 390 |  Loss: (0.2323) |  Loss2: (0.0000) | Acc: (91.00%) (45986/50000)
# TEST : Loss: (0.4143) | Acc: (86.00%) (8648/10000)
percent tensor([0.5148, 0.5051, 0.5106, 0.5074, 0.5133, 0.5209, 0.5095, 0.5085, 0.5142,
        0.5076, 0.5162, 0.5092, 0.5071, 0.5111, 0.5117, 0.5131],
       device='cuda:0') torch.Size([16])
percent tensor([0.5101, 0.5037, 0.5133, 0.5132, 0.5114, 0.5096, 0.5066, 0.5146, 0.5142,
        0.5071, 0.5113, 0.5074, 0.5049, 0.5152, 0.5052, 0.5113],
       device='cuda:0') torch.Size([16])
percent tensor([0.5522, 0.5390, 0.5542, 0.5695, 0.5634, 0.5493, 0.5525, 0.5621, 0.5525,
        0.5472, 0.5516, 0.5516, 0.5233, 0.5857, 0.5386, 0.5609],
       device='cuda:0') torch.Size([16])
percent tensor([0.5878, 0.6021, 0.5848, 0.5790, 0.5777, 0.5766, 0.5978, 0.5755, 0.5999,
        0.6095, 0.6125, 0.5999, 0.6019, 0.6086, 0.5813, 0.5938],
       device='cuda:0') torch.Size([16])
percent tensor([0.5759, 0.6075, 0.4723, 0.5528, 0.4829, 0.5769, 0.5686, 0.3903, 0.6256,
        0.6041, 0.6624, 0.5507, 0.6027, 0.6459, 0.5225, 0.5749],
       device='cuda:0') torch.Size([16])
percent tensor([0.5844, 0.5620, 0.6046, 0.5990, 0.6364, 0.6050, 0.5898, 0.6381, 0.5755,
        0.5694, 0.5520, 0.5528, 0.5309, 0.5575, 0.5838, 0.6074],
       device='cuda:0') torch.Size([16])
percent tensor([0.5107, 0.5678, 0.6588, 0.6183, 0.7159, 0.7246, 0.5241, 0.6496, 0.6012,
        0.5354, 0.6109, 0.5312, 0.5782, 0.5606, 0.5362, 0.5311],
       device='cuda:0') torch.Size([16])
percent tensor([0.9992, 0.9988, 0.9991, 0.9990, 0.9983, 0.9986, 0.9987, 0.9993, 0.9994,
        0.9986, 0.9994, 0.9992, 0.9991, 0.9971, 0.9989, 0.9987],
       device='cuda:0') torch.Size([16])
Epoch: 97 | Batch_idx: 0 |  Loss: (0.2334) |  Loss2: (0.0000) | Acc: (92.00%) (118/128)
Epoch: 97 | Batch_idx: 10 |  Loss: (0.2280) |  Loss2: (0.0000) | Acc: (92.00%) (1303/1408)
Epoch: 97 | Batch_idx: 20 |  Loss: (0.2196) |  Loss2: (0.0000) | Acc: (92.00%) (2497/2688)
Epoch: 97 | Batch_idx: 30 |  Loss: (0.2092) |  Loss2: (0.0000) | Acc: (93.00%) (3694/3968)
Epoch: 97 | Batch_idx: 40 |  Loss: (0.2041) |  Loss2: (0.0000) | Acc: (93.00%) (4897/5248)
Epoch: 97 | Batch_idx: 50 |  Loss: (0.2072) |  Loss2: (0.0000) | Acc: (93.00%) (6076/6528)
Epoch: 97 | Batch_idx: 60 |  Loss: (0.2079) |  Loss2: (0.0000) | Acc: (93.00%) (7268/7808)
Epoch: 97 | Batch_idx: 70 |  Loss: (0.2125) |  Loss2: (0.0000) | Acc: (92.00%) (8436/9088)
Epoch: 97 | Batch_idx: 80 |  Loss: (0.2147) |  Loss2: (0.0000) | Acc: (92.00%) (9613/10368)
Epoch: 97 | Batch_idx: 90 |  Loss: (0.2136) |  Loss2: (0.0000) | Acc: (92.00%) (10808/11648)
Epoch: 97 | Batch_idx: 100 |  Loss: (0.2117) |  Loss2: (0.0000) | Acc: (92.00%) (12007/12928)
Epoch: 97 | Batch_idx: 110 |  Loss: (0.2119) |  Loss2: (0.0000) | Acc: (92.00%) (13193/14208)
Epoch: 97 | Batch_idx: 120 |  Loss: (0.2128) |  Loss2: (0.0000) | Acc: (92.00%) (14385/15488)
Epoch: 97 | Batch_idx: 130 |  Loss: (0.2134) |  Loss2: (0.0000) | Acc: (92.00%) (15564/16768)
Epoch: 97 | Batch_idx: 140 |  Loss: (0.2144) |  Loss2: (0.0000) | Acc: (92.00%) (16746/18048)
Epoch: 97 | Batch_idx: 150 |  Loss: (0.2160) |  Loss2: (0.0000) | Acc: (92.00%) (17920/19328)
Epoch: 97 | Batch_idx: 160 |  Loss: (0.2153) |  Loss2: (0.0000) | Acc: (92.00%) (19107/20608)
Epoch: 97 | Batch_idx: 170 |  Loss: (0.2143) |  Loss2: (0.0000) | Acc: (92.00%) (20294/21888)
Epoch: 97 | Batch_idx: 180 |  Loss: (0.2148) |  Loss2: (0.0000) | Acc: (92.00%) (21472/23168)
Epoch: 97 | Batch_idx: 190 |  Loss: (0.2146) |  Loss2: (0.0000) | Acc: (92.00%) (22654/24448)
Epoch: 97 | Batch_idx: 200 |  Loss: (0.2146) |  Loss2: (0.0000) | Acc: (92.00%) (23846/25728)
Epoch: 97 | Batch_idx: 210 |  Loss: (0.2140) |  Loss2: (0.0000) | Acc: (92.00%) (25028/27008)
Epoch: 97 | Batch_idx: 220 |  Loss: (0.2142) |  Loss2: (0.0000) | Acc: (92.00%) (26214/28288)
Epoch: 97 | Batch_idx: 230 |  Loss: (0.2141) |  Loss2: (0.0000) | Acc: (92.00%) (27409/29568)
Epoch: 97 | Batch_idx: 240 |  Loss: (0.2142) |  Loss2: (0.0000) | Acc: (92.00%) (28600/30848)
Epoch: 97 | Batch_idx: 250 |  Loss: (0.2157) |  Loss2: (0.0000) | Acc: (92.00%) (29763/32128)
Epoch: 97 | Batch_idx: 260 |  Loss: (0.2156) |  Loss2: (0.0000) | Acc: (92.00%) (30951/33408)
Epoch: 97 | Batch_idx: 270 |  Loss: (0.2165) |  Loss2: (0.0000) | Acc: (92.00%) (32115/34688)
Epoch: 97 | Batch_idx: 280 |  Loss: (0.2170) |  Loss2: (0.0000) | Acc: (92.00%) (33293/35968)
Epoch: 97 | Batch_idx: 290 |  Loss: (0.2180) |  Loss2: (0.0000) | Acc: (92.00%) (34473/37248)
Epoch: 97 | Batch_idx: 300 |  Loss: (0.2182) |  Loss2: (0.0000) | Acc: (92.00%) (35657/38528)
Epoch: 97 | Batch_idx: 310 |  Loss: (0.2192) |  Loss2: (0.0000) | Acc: (92.00%) (36829/39808)
Epoch: 97 | Batch_idx: 320 |  Loss: (0.2198) |  Loss2: (0.0000) | Acc: (92.00%) (38006/41088)
Epoch: 97 | Batch_idx: 330 |  Loss: (0.2202) |  Loss2: (0.0000) | Acc: (92.00%) (39188/42368)
Epoch: 97 | Batch_idx: 340 |  Loss: (0.2211) |  Loss2: (0.0000) | Acc: (92.00%) (40361/43648)
Epoch: 97 | Batch_idx: 350 |  Loss: (0.2223) |  Loss2: (0.0000) | Acc: (92.00%) (41524/44928)
Epoch: 97 | Batch_idx: 360 |  Loss: (0.2228) |  Loss2: (0.0000) | Acc: (92.00%) (42697/46208)
Epoch: 97 | Batch_idx: 370 |  Loss: (0.2232) |  Loss2: (0.0000) | Acc: (92.00%) (43867/47488)
Epoch: 97 | Batch_idx: 380 |  Loss: (0.2238) |  Loss2: (0.0000) | Acc: (92.00%) (45037/48768)
Epoch: 97 | Batch_idx: 390 |  Loss: (0.2233) |  Loss2: (0.0000) | Acc: (92.00%) (46182/50000)
# TEST : Loss: (0.4545) | Acc: (85.00%) (8547/10000)
percent tensor([0.5151, 0.5048, 0.5090, 0.5080, 0.5119, 0.5214, 0.5084, 0.5075, 0.5134,
        0.5066, 0.5159, 0.5071, 0.5070, 0.5103, 0.5120, 0.5134],
       device='cuda:0') torch.Size([16])
percent tensor([0.5104, 0.5051, 0.5130, 0.5142, 0.5114, 0.5104, 0.5077, 0.5146, 0.5151,
        0.5079, 0.5120, 0.5081, 0.5055, 0.5171, 0.5065, 0.5123],
       device='cuda:0') torch.Size([16])
percent tensor([0.5514, 0.5375, 0.5549, 0.5726, 0.5618, 0.5477, 0.5507, 0.5639, 0.5572,
        0.5465, 0.5494, 0.5503, 0.5228, 0.5847, 0.5402, 0.5579],
       device='cuda:0') torch.Size([16])
percent tensor([0.5880, 0.6028, 0.5852, 0.5782, 0.5783, 0.5818, 0.5935, 0.5743, 0.5988,
        0.6080, 0.6121, 0.5984, 0.6003, 0.6071, 0.5825, 0.5966],
       device='cuda:0') torch.Size([16])
percent tensor([0.5720, 0.6158, 0.4713, 0.5342, 0.4727, 0.5823, 0.5713, 0.3904, 0.6338,
        0.6085, 0.6701, 0.5459, 0.6040, 0.6572, 0.5277, 0.5828],
       device='cuda:0') torch.Size([16])
percent tensor([0.5838, 0.5730, 0.6055, 0.6019, 0.6336, 0.5997, 0.5971, 0.6338, 0.5779,
        0.5759, 0.5566, 0.5514, 0.5416, 0.5730, 0.5824, 0.6080],
       device='cuda:0') torch.Size([16])
percent tensor([0.5215, 0.5702, 0.6864, 0.6099, 0.7175, 0.7359, 0.5620, 0.6604, 0.5788,
        0.5353, 0.6292, 0.5601, 0.5583, 0.5792, 0.5504, 0.5447],
       device='cuda:0') torch.Size([16])
percent tensor([0.9993, 0.9986, 0.9992, 0.9994, 0.9989, 0.9994, 0.9983, 0.9997, 0.9995,
        0.9987, 0.9996, 0.9993, 0.9992, 0.9987, 0.9994, 0.9992],
       device='cuda:0') torch.Size([16])
Epoch: 98 | Batch_idx: 0 |  Loss: (0.2042) |  Loss2: (0.0000) | Acc: (92.00%) (119/128)
Epoch: 98 | Batch_idx: 10 |  Loss: (0.2243) |  Loss2: (0.0000) | Acc: (92.00%) (1296/1408)
Epoch: 98 | Batch_idx: 20 |  Loss: (0.2300) |  Loss2: (0.0000) | Acc: (91.00%) (2456/2688)
Epoch: 98 | Batch_idx: 30 |  Loss: (0.2375) |  Loss2: (0.0000) | Acc: (91.00%) (3631/3968)
Epoch: 98 | Batch_idx: 40 |  Loss: (0.2372) |  Loss2: (0.0000) | Acc: (91.00%) (4805/5248)
Epoch: 98 | Batch_idx: 50 |  Loss: (0.2299) |  Loss2: (0.0000) | Acc: (91.00%) (5997/6528)
Epoch: 98 | Batch_idx: 60 |  Loss: (0.2253) |  Loss2: (0.0000) | Acc: (92.00%) (7192/7808)
Epoch: 98 | Batch_idx: 70 |  Loss: (0.2225) |  Loss2: (0.0000) | Acc: (92.00%) (8385/9088)
Epoch: 98 | Batch_idx: 80 |  Loss: (0.2218) |  Loss2: (0.0000) | Acc: (92.00%) (9568/10368)
Epoch: 98 | Batch_idx: 90 |  Loss: (0.2220) |  Loss2: (0.0000) | Acc: (92.00%) (10757/11648)
Epoch: 98 | Batch_idx: 100 |  Loss: (0.2238) |  Loss2: (0.0000) | Acc: (92.00%) (11920/12928)
Epoch: 98 | Batch_idx: 110 |  Loss: (0.2231) |  Loss2: (0.0000) | Acc: (92.00%) (13111/14208)
Epoch: 98 | Batch_idx: 120 |  Loss: (0.2192) |  Loss2: (0.0000) | Acc: (92.00%) (14315/15488)
Epoch: 98 | Batch_idx: 130 |  Loss: (0.2178) |  Loss2: (0.0000) | Acc: (92.00%) (15503/16768)
Epoch: 98 | Batch_idx: 140 |  Loss: (0.2185) |  Loss2: (0.0000) | Acc: (92.00%) (16693/18048)
Epoch: 98 | Batch_idx: 150 |  Loss: (0.2195) |  Loss2: (0.0000) | Acc: (92.00%) (17864/19328)
Epoch: 98 | Batch_idx: 160 |  Loss: (0.2206) |  Loss2: (0.0000) | Acc: (92.00%) (19049/20608)
Epoch: 98 | Batch_idx: 170 |  Loss: (0.2210) |  Loss2: (0.0000) | Acc: (92.00%) (20231/21888)
Epoch: 98 | Batch_idx: 180 |  Loss: (0.2221) |  Loss2: (0.0000) | Acc: (92.00%) (21397/23168)
Epoch: 98 | Batch_idx: 190 |  Loss: (0.2247) |  Loss2: (0.0000) | Acc: (92.00%) (22547/24448)
Epoch: 98 | Batch_idx: 200 |  Loss: (0.2236) |  Loss2: (0.0000) | Acc: (92.00%) (23738/25728)
Epoch: 98 | Batch_idx: 210 |  Loss: (0.2233) |  Loss2: (0.0000) | Acc: (92.00%) (24921/27008)
Epoch: 98 | Batch_idx: 220 |  Loss: (0.2234) |  Loss2: (0.0000) | Acc: (92.00%) (26108/28288)
Epoch: 98 | Batch_idx: 230 |  Loss: (0.2248) |  Loss2: (0.0000) | Acc: (92.00%) (27271/29568)
Epoch: 98 | Batch_idx: 240 |  Loss: (0.2252) |  Loss2: (0.0000) | Acc: (92.00%) (28459/30848)
Epoch: 98 | Batch_idx: 250 |  Loss: (0.2253) |  Loss2: (0.0000) | Acc: (92.00%) (29631/32128)
Epoch: 98 | Batch_idx: 260 |  Loss: (0.2260) |  Loss2: (0.0000) | Acc: (92.00%) (30803/33408)
Epoch: 98 | Batch_idx: 270 |  Loss: (0.2270) |  Loss2: (0.0000) | Acc: (92.00%) (31964/34688)
Epoch: 98 | Batch_idx: 280 |  Loss: (0.2272) |  Loss2: (0.0000) | Acc: (92.00%) (33143/35968)
Epoch: 98 | Batch_idx: 290 |  Loss: (0.2269) |  Loss2: (0.0000) | Acc: (92.00%) (34320/37248)
Epoch: 98 | Batch_idx: 300 |  Loss: (0.2269) |  Loss2: (0.0000) | Acc: (92.00%) (35488/38528)
Epoch: 98 | Batch_idx: 310 |  Loss: (0.2268) |  Loss2: (0.0000) | Acc: (92.00%) (36665/39808)
Epoch: 98 | Batch_idx: 320 |  Loss: (0.2275) |  Loss2: (0.0000) | Acc: (92.00%) (37833/41088)
Epoch: 98 | Batch_idx: 330 |  Loss: (0.2280) |  Loss2: (0.0000) | Acc: (92.00%) (39004/42368)
Epoch: 98 | Batch_idx: 340 |  Loss: (0.2271) |  Loss2: (0.0000) | Acc: (92.00%) (40194/43648)
Epoch: 98 | Batch_idx: 350 |  Loss: (0.2267) |  Loss2: (0.0000) | Acc: (92.00%) (41380/44928)
Epoch: 98 | Batch_idx: 360 |  Loss: (0.2264) |  Loss2: (0.0000) | Acc: (92.00%) (42572/46208)
Epoch: 98 | Batch_idx: 370 |  Loss: (0.2263) |  Loss2: (0.0000) | Acc: (92.00%) (43761/47488)
Epoch: 98 | Batch_idx: 380 |  Loss: (0.2268) |  Loss2: (0.0000) | Acc: (92.00%) (44939/48768)
Epoch: 98 | Batch_idx: 390 |  Loss: (0.2268) |  Loss2: (0.0000) | Acc: (92.00%) (46073/50000)
# TEST : Loss: (0.4229) | Acc: (86.00%) (8652/10000)
percent tensor([0.5145, 0.5057, 0.5098, 0.5079, 0.5125, 0.5214, 0.5092, 0.5078, 0.5136,
        0.5073, 0.5156, 0.5078, 0.5066, 0.5109, 0.5123, 0.5135],
       device='cuda:0') torch.Size([16])
percent tensor([0.5098, 0.5054, 0.5121, 0.5133, 0.5102, 0.5099, 0.5069, 0.5141, 0.5142,
        0.5081, 0.5122, 0.5055, 0.5046, 0.5157, 0.5064, 0.5121],
       device='cuda:0') torch.Size([16])
percent tensor([0.5484, 0.5384, 0.5582, 0.5780, 0.5634, 0.5488, 0.5475, 0.5656, 0.5522,
        0.5483, 0.5485, 0.5452, 0.5182, 0.5833, 0.5401, 0.5610],
       device='cuda:0') torch.Size([16])
percent tensor([0.5890, 0.6035, 0.5820, 0.5742, 0.5776, 0.5815, 0.5941, 0.5724, 0.5997,
        0.6091, 0.6149, 0.5940, 0.5990, 0.6065, 0.5829, 0.5974],
       device='cuda:0') torch.Size([16])
percent tensor([0.5757, 0.6171, 0.4582, 0.5374, 0.4792, 0.5766, 0.5679, 0.3881, 0.6373,
        0.6084, 0.6643, 0.5500, 0.6063, 0.6529, 0.5402, 0.5866],
       device='cuda:0') torch.Size([16])
percent tensor([0.5911, 0.5735, 0.6097, 0.6078, 0.6412, 0.6024, 0.5991, 0.6394, 0.5830,
        0.5854, 0.5610, 0.5503, 0.5397, 0.5776, 0.5829, 0.6158],
       device='cuda:0') torch.Size([16])
percent tensor([0.5187, 0.5739, 0.6910, 0.6152, 0.7093, 0.7093, 0.5937, 0.6518, 0.6228,
        0.5543, 0.6388, 0.5751, 0.5846, 0.5919, 0.5358, 0.5455],
       device='cuda:0') torch.Size([16])
percent tensor([0.9990, 0.9981, 0.9990, 0.9992, 0.9990, 0.9988, 0.9987, 0.9994, 0.9995,
        0.9983, 0.9997, 0.9993, 0.9994, 0.9973, 0.9981, 0.9988],
       device='cuda:0') torch.Size([16])
False Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=128, out_features=16, bias=False)
True Linear(in_features=16, out_features=2, bias=False)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=128, out_features=16, bias=False)
True Linear(in_features=16, out_features=2, bias=False)
False Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=256, out_features=32, bias=False)
True Linear(in_features=32, out_features=2, bias=False)
False Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=256, out_features=32, bias=False)
True Linear(in_features=32, out_features=2, bias=False)
False Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=512, out_features=64, bias=False)
True Linear(in_features=64, out_features=2, bias=False)
False Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=512, out_features=64, bias=False)
True Linear(in_features=64, out_features=2, bias=False)
False Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1024, out_features=128, bias=False)
True Linear(in_features=128, out_features=2, bias=False)
False Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1024, out_features=128, bias=False)
True Linear(in_features=128, out_features=2, bias=False)
False Linear(in_features=512, out_features=10, bias=True)
Epoch: 99 | Batch_idx: 0 |  Loss: (0.1579) |  Loss2: (0.0000) | Acc: (96.00%) (123/128)
Epoch: 99 | Batch_idx: 10 |  Loss: (0.2210) |  Loss2: (0.0000) | Acc: (92.00%) (1300/1408)
Epoch: 99 | Batch_idx: 20 |  Loss: (0.2434) |  Loss2: (0.0000) | Acc: (91.00%) (2450/2688)
Epoch: 99 | Batch_idx: 30 |  Loss: (0.2624) |  Loss2: (0.0000) | Acc: (90.00%) (3599/3968)
Epoch: 99 | Batch_idx: 40 |  Loss: (0.2648) |  Loss2: (0.0000) | Acc: (90.00%) (4751/5248)
Epoch: 99 | Batch_idx: 50 |  Loss: (0.2676) |  Loss2: (0.0000) | Acc: (90.00%) (5911/6528)
Epoch: 99 | Batch_idx: 60 |  Loss: (0.2728) |  Loss2: (0.0000) | Acc: (90.00%) (7052/7808)
Epoch: 99 | Batch_idx: 70 |  Loss: (0.2707) |  Loss2: (0.0000) | Acc: (90.00%) (8217/9088)
Epoch: 99 | Batch_idx: 80 |  Loss: (0.2710) |  Loss2: (0.0000) | Acc: (90.00%) (9370/10368)
Epoch: 99 | Batch_idx: 90 |  Loss: (0.2716) |  Loss2: (0.0000) | Acc: (90.00%) (10513/11648)
Epoch: 99 | Batch_idx: 100 |  Loss: (0.2736) |  Loss2: (0.0000) | Acc: (90.00%) (11647/12928)
Epoch: 99 | Batch_idx: 110 |  Loss: (0.2727) |  Loss2: (0.0000) | Acc: (90.00%) (12813/14208)
Epoch: 99 | Batch_idx: 120 |  Loss: (0.2718) |  Loss2: (0.0000) | Acc: (90.00%) (13975/15488)
Epoch: 99 | Batch_idx: 130 |  Loss: (0.2697) |  Loss2: (0.0000) | Acc: (90.00%) (15150/16768)
Epoch: 99 | Batch_idx: 140 |  Loss: (0.2688) |  Loss2: (0.0000) | Acc: (90.00%) (16313/18048)
Epoch: 99 | Batch_idx: 150 |  Loss: (0.2684) |  Loss2: (0.0000) | Acc: (90.00%) (17467/19328)
Epoch: 99 | Batch_idx: 160 |  Loss: (0.2677) |  Loss2: (0.0000) | Acc: (90.00%) (18636/20608)
Epoch: 99 | Batch_idx: 170 |  Loss: (0.2686) |  Loss2: (0.0000) | Acc: (90.00%) (19796/21888)
Epoch: 99 | Batch_idx: 180 |  Loss: (0.2682) |  Loss2: (0.0000) | Acc: (90.00%) (20952/23168)
Epoch: 99 | Batch_idx: 190 |  Loss: (0.2683) |  Loss2: (0.0000) | Acc: (90.00%) (22111/24448)
Epoch: 99 | Batch_idx: 200 |  Loss: (0.2680) |  Loss2: (0.0000) | Acc: (90.00%) (23285/25728)
Epoch: 99 | Batch_idx: 210 |  Loss: (0.2692) |  Loss2: (0.0000) | Acc: (90.00%) (24429/27008)
Epoch: 99 | Batch_idx: 220 |  Loss: (0.2689) |  Loss2: (0.0000) | Acc: (90.00%) (25586/28288)
Epoch: 99 | Batch_idx: 230 |  Loss: (0.2676) |  Loss2: (0.0000) | Acc: (90.00%) (26757/29568)
Epoch: 99 | Batch_idx: 240 |  Loss: (0.2667) |  Loss2: (0.0000) | Acc: (90.00%) (27923/30848)
Epoch: 99 | Batch_idx: 250 |  Loss: (0.2649) |  Loss2: (0.0000) | Acc: (90.00%) (29100/32128)
Epoch: 99 | Batch_idx: 260 |  Loss: (0.2640) |  Loss2: (0.0000) | Acc: (90.00%) (30266/33408)
Epoch: 99 | Batch_idx: 270 |  Loss: (0.2635) |  Loss2: (0.0000) | Acc: (90.00%) (31438/34688)
Epoch: 99 | Batch_idx: 280 |  Loss: (0.2637) |  Loss2: (0.0000) | Acc: (90.00%) (32594/35968)
Epoch: 99 | Batch_idx: 290 |  Loss: (0.2635) |  Loss2: (0.0000) | Acc: (90.00%) (33760/37248)
Epoch: 99 | Batch_idx: 300 |  Loss: (0.2628) |  Loss2: (0.0000) | Acc: (90.00%) (34934/38528)
Epoch: 99 | Batch_idx: 310 |  Loss: (0.2619) |  Loss2: (0.0000) | Acc: (90.00%) (36101/39808)
Epoch: 99 | Batch_idx: 320 |  Loss: (0.2620) |  Loss2: (0.0000) | Acc: (90.00%) (37266/41088)
Epoch: 99 | Batch_idx: 330 |  Loss: (0.2613) |  Loss2: (0.0000) | Acc: (90.00%) (38447/42368)
Epoch: 99 | Batch_idx: 340 |  Loss: (0.2602) |  Loss2: (0.0000) | Acc: (90.00%) (39618/43648)
Epoch: 99 | Batch_idx: 350 |  Loss: (0.2591) |  Loss2: (0.0000) | Acc: (90.00%) (40794/44928)
Epoch: 99 | Batch_idx: 360 |  Loss: (0.2586) |  Loss2: (0.0000) | Acc: (90.00%) (41970/46208)
Epoch: 99 | Batch_idx: 370 |  Loss: (0.2574) |  Loss2: (0.0000) | Acc: (90.00%) (43152/47488)
Epoch: 99 | Batch_idx: 380 |  Loss: (0.2572) |  Loss2: (0.0000) | Acc: (90.00%) (44324/48768)
Epoch: 99 | Batch_idx: 390 |  Loss: (0.2567) |  Loss2: (0.0000) | Acc: (90.00%) (45450/50000)
# TEST : Loss: (0.4187) | Acc: (86.00%) (8658/10000)
percent tensor([0.5175, 0.5100, 0.5116, 0.5111, 0.5154, 0.5248, 0.5130, 0.5103, 0.5170,
        0.5109, 0.5193, 0.5104, 0.5101, 0.5151, 0.5162, 0.5170],
       device='cuda:0') torch.Size([16])
percent tensor([0.5109, 0.5070, 0.5133, 0.5147, 0.5119, 0.5105, 0.5086, 0.5149, 0.5146,
        0.5102, 0.5131, 0.5082, 0.5062, 0.5161, 0.5078, 0.5128],
       device='cuda:0') torch.Size([16])
percent tensor([0.5592, 0.5516, 0.5704, 0.5833, 0.5777, 0.5600, 0.5613, 0.5717, 0.5616,
        0.5632, 0.5599, 0.5618, 0.5303, 0.5922, 0.5525, 0.5696],
       device='cuda:0') torch.Size([16])
percent tensor([0.6049, 0.6202, 0.5959, 0.5842, 0.5933, 0.5976, 0.6115, 0.5851, 0.6172,
        0.6263, 0.6331, 0.6106, 0.6156, 0.6224, 0.5984, 0.6131],
       device='cuda:0') torch.Size([16])
percent tensor([0.5661, 0.6211, 0.4266, 0.5196, 0.4654, 0.5803, 0.5655, 0.3882, 0.6416,
        0.5986, 0.6571, 0.5335, 0.6036, 0.6602, 0.5384, 0.5816],
       device='cuda:0') torch.Size([16])
percent tensor([0.6038, 0.5848, 0.6250, 0.6208, 0.6566, 0.6154, 0.6106, 0.6505, 0.5852,
        0.5991, 0.5664, 0.5707, 0.5551, 0.5785, 0.5987, 0.6263],
       device='cuda:0') torch.Size([16])
percent tensor([0.5276, 0.5972, 0.6770, 0.6065, 0.6897, 0.7008, 0.5846, 0.6316, 0.6414,
        0.5742, 0.6596, 0.5814, 0.6280, 0.6243, 0.5295, 0.5229],
       device='cuda:0') torch.Size([16])
percent tensor([0.9990, 0.9987, 0.9990, 0.9989, 0.9986, 0.9991, 0.9986, 0.9991, 0.9997,
        0.9988, 0.9998, 0.9994, 0.9996, 0.9984, 0.9984, 0.9987],
       device='cuda:0') torch.Size([16])
Epoch: 100 | Batch_idx: 0 |  Loss: (0.2424) |  Loss2: (0.0000) | Acc: (91.00%) (117/128)
Epoch: 100 | Batch_idx: 10 |  Loss: (0.2536) |  Loss2: (0.0000) | Acc: (91.00%) (1284/1408)
Epoch: 100 | Batch_idx: 20 |  Loss: (0.2476) |  Loss2: (0.0000) | Acc: (91.00%) (2455/2688)
Epoch: 100 | Batch_idx: 30 |  Loss: (0.2482) |  Loss2: (0.0000) | Acc: (91.00%) (3619/3968)
Epoch: 100 | Batch_idx: 40 |  Loss: (0.2404) |  Loss2: (0.0000) | Acc: (91.00%) (4797/5248)
Epoch: 100 | Batch_idx: 50 |  Loss: (0.2377) |  Loss2: (0.0000) | Acc: (91.00%) (5977/6528)
Epoch: 100 | Batch_idx: 60 |  Loss: (0.2337) |  Loss2: (0.0000) | Acc: (91.00%) (7169/7808)
Epoch: 100 | Batch_idx: 70 |  Loss: (0.2351) |  Loss2: (0.0000) | Acc: (91.00%) (8344/9088)
Epoch: 100 | Batch_idx: 80 |  Loss: (0.2385) |  Loss2: (0.0000) | Acc: (91.00%) (9514/10368)
Epoch: 100 | Batch_idx: 90 |  Loss: (0.2343) |  Loss2: (0.0000) | Acc: (91.00%) (10713/11648)
Epoch: 100 | Batch_idx: 100 |  Loss: (0.2335) |  Loss2: (0.0000) | Acc: (91.00%) (11893/12928)
Epoch: 100 | Batch_idx: 110 |  Loss: (0.2351) |  Loss2: (0.0000) | Acc: (91.00%) (13055/14208)
Epoch: 100 | Batch_idx: 120 |  Loss: (0.2331) |  Loss2: (0.0000) | Acc: (91.00%) (14242/15488)
Epoch: 100 | Batch_idx: 130 |  Loss: (0.2327) |  Loss2: (0.0000) | Acc: (91.00%) (15423/16768)
Epoch: 100 | Batch_idx: 140 |  Loss: (0.2332) |  Loss2: (0.0000) | Acc: (91.00%) (16600/18048)
Epoch: 100 | Batch_idx: 150 |  Loss: (0.2350) |  Loss2: (0.0000) | Acc: (91.00%) (17764/19328)
Epoch: 100 | Batch_idx: 160 |  Loss: (0.2348) |  Loss2: (0.0000) | Acc: (91.00%) (18948/20608)
Epoch: 100 | Batch_idx: 170 |  Loss: (0.2344) |  Loss2: (0.0000) | Acc: (91.00%) (20121/21888)
Epoch: 100 | Batch_idx: 180 |  Loss: (0.2341) |  Loss2: (0.0000) | Acc: (91.00%) (21295/23168)
Epoch: 100 | Batch_idx: 190 |  Loss: (0.2339) |  Loss2: (0.0000) | Acc: (91.00%) (22470/24448)
Epoch: 100 | Batch_idx: 200 |  Loss: (0.2335) |  Loss2: (0.0000) | Acc: (91.00%) (23651/25728)
Epoch: 100 | Batch_idx: 210 |  Loss: (0.2339) |  Loss2: (0.0000) | Acc: (91.00%) (24823/27008)
Epoch: 100 | Batch_idx: 220 |  Loss: (0.2336) |  Loss2: (0.0000) | Acc: (91.00%) (26000/28288)
Epoch: 100 | Batch_idx: 230 |  Loss: (0.2352) |  Loss2: (0.0000) | Acc: (91.00%) (27160/29568)
Epoch: 100 | Batch_idx: 240 |  Loss: (0.2347) |  Loss2: (0.0000) | Acc: (91.00%) (28338/30848)
Epoch: 100 | Batch_idx: 250 |  Loss: (0.2359) |  Loss2: (0.0000) | Acc: (91.00%) (29501/32128)
Epoch: 100 | Batch_idx: 260 |  Loss: (0.2359) |  Loss2: (0.0000) | Acc: (91.00%) (30680/33408)
Epoch: 100 | Batch_idx: 270 |  Loss: (0.2358) |  Loss2: (0.0000) | Acc: (91.00%) (31853/34688)
Epoch: 100 | Batch_idx: 280 |  Loss: (0.2349) |  Loss2: (0.0000) | Acc: (91.00%) (33036/35968)
Epoch: 100 | Batch_idx: 290 |  Loss: (0.2347) |  Loss2: (0.0000) | Acc: (91.00%) (34207/37248)
Epoch: 100 | Batch_idx: 300 |  Loss: (0.2344) |  Loss2: (0.0000) | Acc: (91.00%) (35393/38528)
Epoch: 100 | Batch_idx: 310 |  Loss: (0.2342) |  Loss2: (0.0000) | Acc: (91.00%) (36579/39808)
Epoch: 100 | Batch_idx: 320 |  Loss: (0.2338) |  Loss2: (0.0000) | Acc: (91.00%) (37765/41088)
Epoch: 100 | Batch_idx: 330 |  Loss: (0.2334) |  Loss2: (0.0000) | Acc: (91.00%) (38949/42368)
Epoch: 100 | Batch_idx: 340 |  Loss: (0.2330) |  Loss2: (0.0000) | Acc: (91.00%) (40134/43648)
Epoch: 100 | Batch_idx: 350 |  Loss: (0.2330) |  Loss2: (0.0000) | Acc: (91.00%) (41313/44928)
Epoch: 100 | Batch_idx: 360 |  Loss: (0.2321) |  Loss2: (0.0000) | Acc: (91.00%) (42496/46208)
Epoch: 100 | Batch_idx: 370 |  Loss: (0.2319) |  Loss2: (0.0000) | Acc: (91.00%) (43670/47488)
Epoch: 100 | Batch_idx: 380 |  Loss: (0.2320) |  Loss2: (0.0000) | Acc: (91.00%) (44837/48768)
Epoch: 100 | Batch_idx: 390 |  Loss: (0.2319) |  Loss2: (0.0000) | Acc: (91.00%) (45968/50000)
=> saving checkpoint 'drive/app/torch/save_Schedule/checkpoint_100.pth.tar'
# TEST : Loss: (0.4023) | Acc: (86.00%) (8692/10000)
percent tensor([0.5179, 0.5098, 0.5119, 0.5113, 0.5161, 0.5253, 0.5132, 0.5104, 0.5175,
        0.5111, 0.5195, 0.5109, 0.5104, 0.5152, 0.5161, 0.5171],
       device='cuda:0') torch.Size([16])
percent tensor([0.5123, 0.5088, 0.5145, 0.5161, 0.5132, 0.5113, 0.5104, 0.5165, 0.5160,
        0.5121, 0.5147, 0.5098, 0.5079, 0.5177, 0.5091, 0.5141],
       device='cuda:0') torch.Size([16])
percent tensor([0.5626, 0.5547, 0.5712, 0.5845, 0.5811, 0.5619, 0.5658, 0.5751, 0.5649,
        0.5669, 0.5634, 0.5634, 0.5328, 0.5979, 0.5560, 0.5725],
       device='cuda:0') torch.Size([16])
percent tensor([0.6053, 0.6203, 0.5965, 0.5855, 0.5935, 0.5978, 0.6117, 0.5854, 0.6181,
        0.6270, 0.6337, 0.6114, 0.6161, 0.6235, 0.5982, 0.6135],
       device='cuda:0') torch.Size([16])
percent tensor([0.5766, 0.6271, 0.4304, 0.5329, 0.4721, 0.5973, 0.5712, 0.3934, 0.6463,
        0.6026, 0.6614, 0.5367, 0.6097, 0.6675, 0.5471, 0.5935],
       device='cuda:0') torch.Size([16])
percent tensor([0.6030, 0.5876, 0.6243, 0.6208, 0.6570, 0.6158, 0.6128, 0.6517, 0.5849,
        0.6007, 0.5668, 0.5709, 0.5542, 0.5811, 0.6007, 0.6274],
       device='cuda:0') torch.Size([16])
percent tensor([0.5265, 0.6060, 0.6716, 0.6025, 0.6827, 0.7016, 0.5884, 0.6202, 0.6513,
        0.5796, 0.6669, 0.5829, 0.6418, 0.6347, 0.5259, 0.5157],
       device='cuda:0') torch.Size([16])
percent tensor([0.9990, 0.9987, 0.9991, 0.9989, 0.9985, 0.9990, 0.9986, 0.9991, 0.9997,
        0.9988, 0.9998, 0.9995, 0.9997, 0.9984, 0.9985, 0.9987],
       device='cuda:0') torch.Size([16])
Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 3, 3, 3]) tensor(184.4820, device='cuda:0')
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(822.0465, device='cuda:0')
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(810.2313, device='cuda:0')
Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([128, 64, 3, 3]) tensor(1528.7494, device='cuda:0')
Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([128, 64, 1, 1]) tensor(488.9413, device='cuda:0')
Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([128, 128, 3, 3]) tensor(2257.5774, device='cuda:0')
Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([256, 128, 3, 3]) tensor(4272.3320, device='cuda:0')
Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([256, 128, 1, 1]) tensor(1388.9406, device='cuda:0')
Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([256, 256, 3, 3]) tensor(6140.0503, device='cuda:0')
Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([512, 256, 3, 3]) tensor(11858.5674, device='cuda:0')
Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([512, 256, 1, 1]) tensor(3938.4702, device='cuda:0')
Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([512, 512, 3, 3]) tensor(16653.8770, device='cuda:0')
Epoch: 101 | Batch_idx: 0 |  Loss: (0.2531) |  Loss2: (0.0000) | Acc: (93.00%) (120/128)
Epoch: 101 | Batch_idx: 10 |  Loss: (0.2233) |  Loss2: (0.0000) | Acc: (92.00%) (1302/1408)
Epoch: 101 | Batch_idx: 20 |  Loss: (0.2311) |  Loss2: (0.0000) | Acc: (91.00%) (2472/2688)
Epoch: 101 | Batch_idx: 30 |  Loss: (0.2294) |  Loss2: (0.0000) | Acc: (91.00%) (3644/3968)
Epoch: 101 | Batch_idx: 40 |  Loss: (0.2345) |  Loss2: (0.0000) | Acc: (91.00%) (4815/5248)
Epoch: 101 | Batch_idx: 50 |  Loss: (0.2373) |  Loss2: (0.0000) | Acc: (91.00%) (5987/6528)
Epoch: 101 | Batch_idx: 60 |  Loss: (0.2389) |  Loss2: (0.0000) | Acc: (91.00%) (7162/7808)
Epoch: 101 | Batch_idx: 70 |  Loss: (0.2386) |  Loss2: (0.0000) | Acc: (91.00%) (8327/9088)
Epoch: 101 | Batch_idx: 80 |  Loss: (0.2373) |  Loss2: (0.0000) | Acc: (91.00%) (9502/10368)
Epoch: 101 | Batch_idx: 90 |  Loss: (0.2337) |  Loss2: (0.0000) | Acc: (91.00%) (10689/11648)
Epoch: 101 | Batch_idx: 100 |  Loss: (0.2370) |  Loss2: (0.0000) | Acc: (91.00%) (11853/12928)
Epoch: 101 | Batch_idx: 110 |  Loss: (0.2378) |  Loss2: (0.0000) | Acc: (91.00%) (13032/14208)
Epoch: 101 | Batch_idx: 120 |  Loss: (0.2389) |  Loss2: (0.0000) | Acc: (91.00%) (14202/15488)
Epoch: 101 | Batch_idx: 130 |  Loss: (0.2348) |  Loss2: (0.0000) | Acc: (91.00%) (15408/16768)
Epoch: 101 | Batch_idx: 140 |  Loss: (0.2353) |  Loss2: (0.0000) | Acc: (91.00%) (16577/18048)
Epoch: 101 | Batch_idx: 150 |  Loss: (0.2359) |  Loss2: (0.0000) | Acc: (91.00%) (17749/19328)
Epoch: 101 | Batch_idx: 160 |  Loss: (0.2353) |  Loss2: (0.0000) | Acc: (91.00%) (18929/20608)
Epoch: 101 | Batch_idx: 170 |  Loss: (0.2330) |  Loss2: (0.0000) | Acc: (91.00%) (20125/21888)
Epoch: 101 | Batch_idx: 180 |  Loss: (0.2327) |  Loss2: (0.0000) | Acc: (91.00%) (21296/23168)
Epoch: 101 | Batch_idx: 190 |  Loss: (0.2320) |  Loss2: (0.0000) | Acc: (91.00%) (22482/24448)
Epoch: 101 | Batch_idx: 200 |  Loss: (0.2306) |  Loss2: (0.0000) | Acc: (91.00%) (23667/25728)
Epoch: 101 | Batch_idx: 210 |  Loss: (0.2299) |  Loss2: (0.0000) | Acc: (91.00%) (24841/27008)
Epoch: 101 | Batch_idx: 220 |  Loss: (0.2298) |  Loss2: (0.0000) | Acc: (91.00%) (26019/28288)
Epoch: 101 | Batch_idx: 230 |  Loss: (0.2300) |  Loss2: (0.0000) | Acc: (91.00%) (27188/29568)
Epoch: 101 | Batch_idx: 240 |  Loss: (0.2295) |  Loss2: (0.0000) | Acc: (91.00%) (28368/30848)
Epoch: 101 | Batch_idx: 250 |  Loss: (0.2290) |  Loss2: (0.0000) | Acc: (91.00%) (29548/32128)
Epoch: 101 | Batch_idx: 260 |  Loss: (0.2287) |  Loss2: (0.0000) | Acc: (91.00%) (30730/33408)
Epoch: 101 | Batch_idx: 270 |  Loss: (0.2276) |  Loss2: (0.0000) | Acc: (92.00%) (31927/34688)
Epoch: 101 | Batch_idx: 280 |  Loss: (0.2263) |  Loss2: (0.0000) | Acc: (92.00%) (33120/35968)
Epoch: 101 | Batch_idx: 290 |  Loss: (0.2261) |  Loss2: (0.0000) | Acc: (92.00%) (34303/37248)
Epoch: 101 | Batch_idx: 300 |  Loss: (0.2265) |  Loss2: (0.0000) | Acc: (92.00%) (35477/38528)
Epoch: 101 | Batch_idx: 310 |  Loss: (0.2258) |  Loss2: (0.0000) | Acc: (92.00%) (36668/39808)
Epoch: 101 | Batch_idx: 320 |  Loss: (0.2259) |  Loss2: (0.0000) | Acc: (92.00%) (37842/41088)
Epoch: 101 | Batch_idx: 330 |  Loss: (0.2261) |  Loss2: (0.0000) | Acc: (92.00%) (39012/42368)
Epoch: 101 | Batch_idx: 340 |  Loss: (0.2261) |  Loss2: (0.0000) | Acc: (92.00%) (40198/43648)
Epoch: 101 | Batch_idx: 350 |  Loss: (0.2259) |  Loss2: (0.0000) | Acc: (92.00%) (41384/44928)
Epoch: 101 | Batch_idx: 360 |  Loss: (0.2250) |  Loss2: (0.0000) | Acc: (92.00%) (42582/46208)
Epoch: 101 | Batch_idx: 370 |  Loss: (0.2248) |  Loss2: (0.0000) | Acc: (92.00%) (43756/47488)
Epoch: 101 | Batch_idx: 380 |  Loss: (0.2249) |  Loss2: (0.0000) | Acc: (92.00%) (44929/48768)
Epoch: 101 | Batch_idx: 390 |  Loss: (0.2248) |  Loss2: (0.0000) | Acc: (92.00%) (46076/50000)
# TEST : Loss: (0.3913) | Acc: (87.00%) (8724/10000)
percent tensor([0.5172, 0.5083, 0.5112, 0.5100, 0.5155, 0.5248, 0.5120, 0.5091, 0.5169,
        0.5098, 0.5184, 0.5099, 0.5094, 0.5138, 0.5147, 0.5160],
       device='cuda:0') torch.Size([16])
percent tensor([0.5123, 0.5088, 0.5146, 0.5160, 0.5131, 0.5110, 0.5105, 0.5166, 0.5160,
        0.5122, 0.5147, 0.5100, 0.5079, 0.5173, 0.5089, 0.5139],
       device='cuda:0') torch.Size([16])
percent tensor([0.5583, 0.5486, 0.5670, 0.5804, 0.5770, 0.5575, 0.5608, 0.5715, 0.5608,
        0.5613, 0.5581, 0.5580, 0.5271, 0.5934, 0.5509, 0.5674],
       device='cuda:0') torch.Size([16])
percent tensor([0.6038, 0.6190, 0.5950, 0.5841, 0.5913, 0.5960, 0.6101, 0.5834, 0.6172,
        0.6258, 0.6326, 0.6105, 0.6152, 0.6229, 0.5963, 0.6117],
       device='cuda:0') torch.Size([16])
percent tensor([0.5727, 0.6231, 0.4292, 0.5370, 0.4740, 0.5990, 0.5687, 0.3946, 0.6450,
        0.5968, 0.6593, 0.5316, 0.6019, 0.6702, 0.5461, 0.5907],
       device='cuda:0') torch.Size([16])
percent tensor([0.5953, 0.5813, 0.6172, 0.6147, 0.6502, 0.6094, 0.6065, 0.6447, 0.5778,
        0.5939, 0.5607, 0.5644, 0.5455, 0.5756, 0.5952, 0.6199],
       device='cuda:0') torch.Size([16])
percent tensor([0.5206, 0.6038, 0.6713, 0.6063, 0.6873, 0.7029, 0.5879, 0.6195, 0.6465,
        0.5748, 0.6622, 0.5772, 0.6335, 0.6339, 0.5193, 0.5103],
       device='cuda:0') torch.Size([16])
percent tensor([0.9991, 0.9987, 0.9991, 0.9990, 0.9986, 0.9991, 0.9987, 0.9991, 0.9997,
        0.9989, 0.9998, 0.9994, 0.9997, 0.9984, 0.9986, 0.9987],
       device='cuda:0') torch.Size([16])
Epoch: 102 | Batch_idx: 0 |  Loss: (0.1873) |  Loss2: (0.0000) | Acc: (92.00%) (119/128)
Epoch: 102 | Batch_idx: 10 |  Loss: (0.2321) |  Loss2: (0.0000) | Acc: (92.00%) (1301/1408)
Epoch: 102 | Batch_idx: 20 |  Loss: (0.2185) |  Loss2: (0.0000) | Acc: (93.00%) (2502/2688)
Epoch: 102 | Batch_idx: 30 |  Loss: (0.2172) |  Loss2: (0.0000) | Acc: (92.00%) (3688/3968)
Epoch: 102 | Batch_idx: 40 |  Loss: (0.2143) |  Loss2: (0.0000) | Acc: (93.00%) (4882/5248)
Epoch: 102 | Batch_idx: 50 |  Loss: (0.2173) |  Loss2: (0.0000) | Acc: (92.00%) (6058/6528)
Epoch: 102 | Batch_idx: 60 |  Loss: (0.2215) |  Loss2: (0.0000) | Acc: (92.00%) (7226/7808)
Epoch: 102 | Batch_idx: 70 |  Loss: (0.2232) |  Loss2: (0.0000) | Acc: (92.00%) (8389/9088)
Epoch: 102 | Batch_idx: 80 |  Loss: (0.2235) |  Loss2: (0.0000) | Acc: (92.00%) (9565/10368)
Epoch: 102 | Batch_idx: 90 |  Loss: (0.2195) |  Loss2: (0.0000) | Acc: (92.00%) (10772/11648)
Epoch: 102 | Batch_idx: 100 |  Loss: (0.2198) |  Loss2: (0.0000) | Acc: (92.00%) (11954/12928)
Epoch: 102 | Batch_idx: 110 |  Loss: (0.2194) |  Loss2: (0.0000) | Acc: (92.00%) (13142/14208)
Epoch: 102 | Batch_idx: 120 |  Loss: (0.2192) |  Loss2: (0.0000) | Acc: (92.00%) (14330/15488)
Epoch: 102 | Batch_idx: 130 |  Loss: (0.2209) |  Loss2: (0.0000) | Acc: (92.00%) (15501/16768)
Epoch: 102 | Batch_idx: 140 |  Loss: (0.2219) |  Loss2: (0.0000) | Acc: (92.00%) (16678/18048)
Epoch: 102 | Batch_idx: 150 |  Loss: (0.2206) |  Loss2: (0.0000) | Acc: (92.00%) (17866/19328)
Epoch: 102 | Batch_idx: 160 |  Loss: (0.2207) |  Loss2: (0.0000) | Acc: (92.00%) (19049/20608)
Epoch: 102 | Batch_idx: 170 |  Loss: (0.2211) |  Loss2: (0.0000) | Acc: (92.00%) (20228/21888)
Epoch: 102 | Batch_idx: 180 |  Loss: (0.2217) |  Loss2: (0.0000) | Acc: (92.00%) (21404/23168)
Epoch: 102 | Batch_idx: 190 |  Loss: (0.2210) |  Loss2: (0.0000) | Acc: (92.00%) (22595/24448)
Epoch: 102 | Batch_idx: 200 |  Loss: (0.2213) |  Loss2: (0.0000) | Acc: (92.00%) (23766/25728)
Epoch: 102 | Batch_idx: 210 |  Loss: (0.2218) |  Loss2: (0.0000) | Acc: (92.00%) (24938/27008)
Epoch: 102 | Batch_idx: 220 |  Loss: (0.2213) |  Loss2: (0.0000) | Acc: (92.00%) (26124/28288)
Epoch: 102 | Batch_idx: 230 |  Loss: (0.2200) |  Loss2: (0.0000) | Acc: (92.00%) (27323/29568)
Epoch: 102 | Batch_idx: 240 |  Loss: (0.2194) |  Loss2: (0.0000) | Acc: (92.00%) (28514/30848)
Epoch: 102 | Batch_idx: 250 |  Loss: (0.2191) |  Loss2: (0.0000) | Acc: (92.00%) (29703/32128)
Epoch: 102 | Batch_idx: 260 |  Loss: (0.2189) |  Loss2: (0.0000) | Acc: (92.00%) (30894/33408)
Epoch: 102 | Batch_idx: 270 |  Loss: (0.2193) |  Loss2: (0.0000) | Acc: (92.00%) (32067/34688)
Epoch: 102 | Batch_idx: 280 |  Loss: (0.2191) |  Loss2: (0.0000) | Acc: (92.00%) (33247/35968)
Epoch: 102 | Batch_idx: 290 |  Loss: (0.2192) |  Loss2: (0.0000) | Acc: (92.00%) (34426/37248)
Epoch: 102 | Batch_idx: 300 |  Loss: (0.2188) |  Loss2: (0.0000) | Acc: (92.00%) (35609/38528)
Epoch: 102 | Batch_idx: 310 |  Loss: (0.2181) |  Loss2: (0.0000) | Acc: (92.00%) (36807/39808)
Epoch: 102 | Batch_idx: 320 |  Loss: (0.2183) |  Loss2: (0.0000) | Acc: (92.00%) (37990/41088)
Epoch: 102 | Batch_idx: 330 |  Loss: (0.2190) |  Loss2: (0.0000) | Acc: (92.00%) (39167/42368)
Epoch: 102 | Batch_idx: 340 |  Loss: (0.2188) |  Loss2: (0.0000) | Acc: (92.00%) (40356/43648)
Epoch: 102 | Batch_idx: 350 |  Loss: (0.2188) |  Loss2: (0.0000) | Acc: (92.00%) (41539/44928)
Epoch: 102 | Batch_idx: 360 |  Loss: (0.2184) |  Loss2: (0.0000) | Acc: (92.00%) (42722/46208)
Epoch: 102 | Batch_idx: 370 |  Loss: (0.2186) |  Loss2: (0.0000) | Acc: (92.00%) (43906/47488)
Epoch: 102 | Batch_idx: 380 |  Loss: (0.2184) |  Loss2: (0.0000) | Acc: (92.00%) (45093/48768)
Epoch: 102 | Batch_idx: 390 |  Loss: (0.2182) |  Loss2: (0.0000) | Acc: (92.00%) (46233/50000)
# TEST : Loss: (0.3852) | Acc: (87.00%) (8747/10000)
percent tensor([0.5177, 0.5081, 0.5120, 0.5104, 0.5164, 0.5253, 0.5123, 0.5096, 0.5175,
        0.5100, 0.5186, 0.5106, 0.5098, 0.5138, 0.5145, 0.5161],
       device='cuda:0') torch.Size([16])
percent tensor([0.5134, 0.5100, 0.5156, 0.5173, 0.5143, 0.5117, 0.5117, 0.5178, 0.5172,
        0.5136, 0.5160, 0.5112, 0.5091, 0.5187, 0.5100, 0.5150],
       device='cuda:0') torch.Size([16])
percent tensor([0.5556, 0.5437, 0.5646, 0.5771, 0.5764, 0.5543, 0.5588, 0.5703, 0.5584,
        0.5577, 0.5543, 0.5548, 0.5226, 0.5919, 0.5471, 0.5639],
       device='cuda:0') torch.Size([16])
percent tensor([0.6018, 0.6179, 0.5932, 0.5829, 0.5890, 0.5941, 0.6084, 0.5816, 0.6161,
        0.6250, 0.6318, 0.6093, 0.6143, 0.6220, 0.5944, 0.6099],
       device='cuda:0') torch.Size([16])
percent tensor([0.5654, 0.6262, 0.4185, 0.5250, 0.4637, 0.5844, 0.5651, 0.3886, 0.6420,
        0.5974, 0.6618, 0.5260, 0.6027, 0.6718, 0.5423, 0.5846],
       device='cuda:0') torch.Size([16])
percent tensor([0.5971, 0.5841, 0.6184, 0.6160, 0.6525, 0.6116, 0.6087, 0.6476, 0.5799,
        0.5962, 0.5618, 0.5667, 0.5464, 0.5767, 0.5981, 0.6221],
       device='cuda:0') torch.Size([16])
percent tensor([0.5253, 0.6060, 0.6813, 0.6159, 0.6977, 0.7118, 0.5930, 0.6265, 0.6539,
        0.5787, 0.6699, 0.5821, 0.6403, 0.6346, 0.5177, 0.5134],
       device='cuda:0') torch.Size([16])
percent tensor([0.9991, 0.9987, 0.9992, 0.9990, 0.9986, 0.9992, 0.9987, 0.9992, 0.9997,
        0.9989, 0.9998, 0.9995, 0.9997, 0.9985, 0.9987, 0.9988],
       device='cuda:0') torch.Size([16])
Epoch: 103 | Batch_idx: 0 |  Loss: (0.2360) |  Loss2: (0.0000) | Acc: (92.00%) (118/128)
Epoch: 103 | Batch_idx: 10 |  Loss: (0.2338) |  Loss2: (0.0000) | Acc: (91.00%) (1285/1408)
Epoch: 103 | Batch_idx: 20 |  Loss: (0.2348) |  Loss2: (0.0000) | Acc: (91.00%) (2457/2688)
Epoch: 103 | Batch_idx: 30 |  Loss: (0.2369) |  Loss2: (0.0000) | Acc: (91.00%) (3640/3968)
Epoch: 103 | Batch_idx: 40 |  Loss: (0.2292) |  Loss2: (0.0000) | Acc: (91.00%) (4828/5248)
Epoch: 103 | Batch_idx: 50 |  Loss: (0.2253) |  Loss2: (0.0000) | Acc: (92.00%) (6018/6528)
Epoch: 103 | Batch_idx: 60 |  Loss: (0.2223) |  Loss2: (0.0000) | Acc: (92.00%) (7207/7808)
Epoch: 103 | Batch_idx: 70 |  Loss: (0.2183) |  Loss2: (0.0000) | Acc: (92.00%) (8402/9088)
Epoch: 103 | Batch_idx: 80 |  Loss: (0.2161) |  Loss2: (0.0000) | Acc: (92.00%) (9583/10368)
Epoch: 103 | Batch_idx: 90 |  Loss: (0.2150) |  Loss2: (0.0000) | Acc: (92.00%) (10771/11648)
Epoch: 103 | Batch_idx: 100 |  Loss: (0.2148) |  Loss2: (0.0000) | Acc: (92.00%) (11961/12928)
Epoch: 103 | Batch_idx: 110 |  Loss: (0.2142) |  Loss2: (0.0000) | Acc: (92.00%) (13147/14208)
Epoch: 103 | Batch_idx: 120 |  Loss: (0.2141) |  Loss2: (0.0000) | Acc: (92.00%) (14331/15488)
Epoch: 103 | Batch_idx: 130 |  Loss: (0.2114) |  Loss2: (0.0000) | Acc: (92.00%) (15537/16768)
Epoch: 103 | Batch_idx: 140 |  Loss: (0.2119) |  Loss2: (0.0000) | Acc: (92.00%) (16723/18048)
Epoch: 103 | Batch_idx: 150 |  Loss: (0.2122) |  Loss2: (0.0000) | Acc: (92.00%) (17913/19328)
Epoch: 103 | Batch_idx: 160 |  Loss: (0.2102) |  Loss2: (0.0000) | Acc: (92.00%) (19116/20608)
Epoch: 103 | Batch_idx: 170 |  Loss: (0.2107) |  Loss2: (0.0000) | Acc: (92.00%) (20296/21888)
Epoch: 103 | Batch_idx: 180 |  Loss: (0.2102) |  Loss2: (0.0000) | Acc: (92.00%) (21490/23168)
Epoch: 103 | Batch_idx: 190 |  Loss: (0.2096) |  Loss2: (0.0000) | Acc: (92.00%) (22684/24448)
Epoch: 103 | Batch_idx: 200 |  Loss: (0.2101) |  Loss2: (0.0000) | Acc: (92.00%) (23869/25728)
Epoch: 103 | Batch_idx: 210 |  Loss: (0.2100) |  Loss2: (0.0000) | Acc: (92.00%) (25053/27008)
Epoch: 103 | Batch_idx: 220 |  Loss: (0.2106) |  Loss2: (0.0000) | Acc: (92.00%) (26240/28288)
Epoch: 103 | Batch_idx: 230 |  Loss: (0.2111) |  Loss2: (0.0000) | Acc: (92.00%) (27417/29568)
Epoch: 103 | Batch_idx: 240 |  Loss: (0.2118) |  Loss2: (0.0000) | Acc: (92.00%) (28600/30848)
Epoch: 103 | Batch_idx: 250 |  Loss: (0.2115) |  Loss2: (0.0000) | Acc: (92.00%) (29784/32128)
Epoch: 103 | Batch_idx: 260 |  Loss: (0.2120) |  Loss2: (0.0000) | Acc: (92.00%) (30967/33408)
Epoch: 103 | Batch_idx: 270 |  Loss: (0.2121) |  Loss2: (0.0000) | Acc: (92.00%) (32149/34688)
Epoch: 103 | Batch_idx: 280 |  Loss: (0.2127) |  Loss2: (0.0000) | Acc: (92.00%) (33334/35968)
Epoch: 103 | Batch_idx: 290 |  Loss: (0.2131) |  Loss2: (0.0000) | Acc: (92.00%) (34506/37248)
Epoch: 103 | Batch_idx: 300 |  Loss: (0.2131) |  Loss2: (0.0000) | Acc: (92.00%) (35701/38528)
Epoch: 103 | Batch_idx: 310 |  Loss: (0.2136) |  Loss2: (0.0000) | Acc: (92.00%) (36871/39808)
Epoch: 103 | Batch_idx: 320 |  Loss: (0.2132) |  Loss2: (0.0000) | Acc: (92.00%) (38055/41088)
Epoch: 103 | Batch_idx: 330 |  Loss: (0.2138) |  Loss2: (0.0000) | Acc: (92.00%) (39230/42368)
Epoch: 103 | Batch_idx: 340 |  Loss: (0.2144) |  Loss2: (0.0000) | Acc: (92.00%) (40405/43648)
Epoch: 103 | Batch_idx: 350 |  Loss: (0.2143) |  Loss2: (0.0000) | Acc: (92.00%) (41589/44928)
Epoch: 103 | Batch_idx: 360 |  Loss: (0.2148) |  Loss2: (0.0000) | Acc: (92.00%) (42759/46208)
Epoch: 103 | Batch_idx: 370 |  Loss: (0.2151) |  Loss2: (0.0000) | Acc: (92.00%) (43936/47488)
Epoch: 103 | Batch_idx: 380 |  Loss: (0.2148) |  Loss2: (0.0000) | Acc: (92.00%) (45125/48768)
Epoch: 103 | Batch_idx: 390 |  Loss: (0.2141) |  Loss2: (0.0000) | Acc: (92.00%) (46277/50000)
# TEST : Loss: (0.3847) | Acc: (87.00%) (8740/10000)
percent tensor([0.5189, 0.5091, 0.5133, 0.5113, 0.5179, 0.5264, 0.5136, 0.5106, 0.5189,
        0.5113, 0.5199, 0.5120, 0.5110, 0.5149, 0.5155, 0.5172],
       device='cuda:0') torch.Size([16])
percent tensor([0.5142, 0.5105, 0.5166, 0.5179, 0.5151, 0.5122, 0.5124, 0.5186, 0.5181,
        0.5143, 0.5168, 0.5120, 0.5097, 0.5192, 0.5105, 0.5157],
       device='cuda:0') torch.Size([16])
percent tensor([0.5574, 0.5430, 0.5672, 0.5800, 0.5792, 0.5565, 0.5602, 0.5733, 0.5599,
        0.5576, 0.5547, 0.5562, 0.5218, 0.5938, 0.5485, 0.5649],
       device='cuda:0') torch.Size([16])
percent tensor([0.6065, 0.6226, 0.5978, 0.5870, 0.5932, 0.5984, 0.6135, 0.5859, 0.6216,
        0.6301, 0.6376, 0.6145, 0.6196, 0.6276, 0.5988, 0.6149],
       device='cuda:0') torch.Size([16])
percent tensor([0.5672, 0.6260, 0.4227, 0.5299, 0.4691, 0.5896, 0.5679, 0.3922, 0.6437,
        0.5989, 0.6631, 0.5295, 0.6017, 0.6733, 0.5451, 0.5862],
       device='cuda:0') torch.Size([16])
percent tensor([0.5981, 0.5860, 0.6202, 0.6172, 0.6544, 0.6127, 0.6102, 0.6491, 0.5819,
        0.5977, 0.5630, 0.5677, 0.5472, 0.5780, 0.5998, 0.6234],
       device='cuda:0') torch.Size([16])
percent tensor([0.5173, 0.5985, 0.6782, 0.6120, 0.6961, 0.7086, 0.5840, 0.6216, 0.6453,
        0.5704, 0.6617, 0.5733, 0.6318, 0.6271, 0.5088, 0.5069],
       device='cuda:0') torch.Size([16])
percent tensor([0.9992, 0.9988, 0.9993, 0.9991, 0.9988, 0.9993, 0.9989, 0.9992, 0.9997,
        0.9990, 0.9998, 0.9995, 0.9997, 0.9985, 0.9987, 0.9988],
       device='cuda:0') torch.Size([16])
Epoch: 104 | Batch_idx: 0 |  Loss: (0.2053) |  Loss2: (0.0000) | Acc: (92.00%) (118/128)
Epoch: 104 | Batch_idx: 10 |  Loss: (0.1837) |  Loss2: (0.0000) | Acc: (93.00%) (1315/1408)
Epoch: 104 | Batch_idx: 20 |  Loss: (0.1962) |  Loss2: (0.0000) | Acc: (93.00%) (2511/2688)
Epoch: 104 | Batch_idx: 30 |  Loss: (0.2016) |  Loss2: (0.0000) | Acc: (93.00%) (3694/3968)
Epoch: 104 | Batch_idx: 40 |  Loss: (0.2055) |  Loss2: (0.0000) | Acc: (93.00%) (4886/5248)
Epoch: 104 | Batch_idx: 50 |  Loss: (0.2148) |  Loss2: (0.0000) | Acc: (92.00%) (6051/6528)
Epoch: 104 | Batch_idx: 60 |  Loss: (0.2150) |  Loss2: (0.0000) | Acc: (92.00%) (7238/7808)
Epoch: 104 | Batch_idx: 70 |  Loss: (0.2156) |  Loss2: (0.0000) | Acc: (92.00%) (8421/9088)
Epoch: 104 | Batch_idx: 80 |  Loss: (0.2174) |  Loss2: (0.0000) | Acc: (92.00%) (9596/10368)
Epoch: 104 | Batch_idx: 90 |  Loss: (0.2142) |  Loss2: (0.0000) | Acc: (92.00%) (10795/11648)
Epoch: 104 | Batch_idx: 100 |  Loss: (0.2135) |  Loss2: (0.0000) | Acc: (92.00%) (11981/12928)
Epoch: 104 | Batch_idx: 110 |  Loss: (0.2122) |  Loss2: (0.0000) | Acc: (92.00%) (13179/14208)
Epoch: 104 | Batch_idx: 120 |  Loss: (0.2136) |  Loss2: (0.0000) | Acc: (92.00%) (14356/15488)
Epoch: 104 | Batch_idx: 130 |  Loss: (0.2138) |  Loss2: (0.0000) | Acc: (92.00%) (15544/16768)
Epoch: 104 | Batch_idx: 140 |  Loss: (0.2140) |  Loss2: (0.0000) | Acc: (92.00%) (16721/18048)
Epoch: 104 | Batch_idx: 150 |  Loss: (0.2149) |  Loss2: (0.0000) | Acc: (92.00%) (17908/19328)
Epoch: 104 | Batch_idx: 160 |  Loss: (0.2140) |  Loss2: (0.0000) | Acc: (92.00%) (19102/20608)
Epoch: 104 | Batch_idx: 170 |  Loss: (0.2124) |  Loss2: (0.0000) | Acc: (92.00%) (20295/21888)
Epoch: 104 | Batch_idx: 180 |  Loss: (0.2121) |  Loss2: (0.0000) | Acc: (92.00%) (21484/23168)
Epoch: 104 | Batch_idx: 190 |  Loss: (0.2124) |  Loss2: (0.0000) | Acc: (92.00%) (22671/24448)
Epoch: 104 | Batch_idx: 200 |  Loss: (0.2124) |  Loss2: (0.0000) | Acc: (92.00%) (23859/25728)
Epoch: 104 | Batch_idx: 210 |  Loss: (0.2112) |  Loss2: (0.0000) | Acc: (92.00%) (25057/27008)
Epoch: 104 | Batch_idx: 220 |  Loss: (0.2118) |  Loss2: (0.0000) | Acc: (92.00%) (26232/28288)
Epoch: 104 | Batch_idx: 230 |  Loss: (0.2123) |  Loss2: (0.0000) | Acc: (92.00%) (27417/29568)
Epoch: 104 | Batch_idx: 240 |  Loss: (0.2125) |  Loss2: (0.0000) | Acc: (92.00%) (28608/30848)
Epoch: 104 | Batch_idx: 250 |  Loss: (0.2127) |  Loss2: (0.0000) | Acc: (92.00%) (29782/32128)
Epoch: 104 | Batch_idx: 260 |  Loss: (0.2125) |  Loss2: (0.0000) | Acc: (92.00%) (30977/33408)
Epoch: 104 | Batch_idx: 270 |  Loss: (0.2118) |  Loss2: (0.0000) | Acc: (92.00%) (32180/34688)
Epoch: 104 | Batch_idx: 280 |  Loss: (0.2111) |  Loss2: (0.0000) | Acc: (92.00%) (33373/35968)
Epoch: 104 | Batch_idx: 290 |  Loss: (0.2104) |  Loss2: (0.0000) | Acc: (92.00%) (34557/37248)
Epoch: 104 | Batch_idx: 300 |  Loss: (0.2104) |  Loss2: (0.0000) | Acc: (92.00%) (35752/38528)
Epoch: 104 | Batch_idx: 310 |  Loss: (0.2110) |  Loss2: (0.0000) | Acc: (92.00%) (36935/39808)
Epoch: 104 | Batch_idx: 320 |  Loss: (0.2111) |  Loss2: (0.0000) | Acc: (92.00%) (38127/41088)
Epoch: 104 | Batch_idx: 330 |  Loss: (0.2113) |  Loss2: (0.0000) | Acc: (92.00%) (39311/42368)
Epoch: 104 | Batch_idx: 340 |  Loss: (0.2114) |  Loss2: (0.0000) | Acc: (92.00%) (40500/43648)
Epoch: 104 | Batch_idx: 350 |  Loss: (0.2108) |  Loss2: (0.0000) | Acc: (92.00%) (41691/44928)
Epoch: 104 | Batch_idx: 360 |  Loss: (0.2116) |  Loss2: (0.0000) | Acc: (92.00%) (42858/46208)
Epoch: 104 | Batch_idx: 370 |  Loss: (0.2118) |  Loss2: (0.0000) | Acc: (92.00%) (44041/47488)
Epoch: 104 | Batch_idx: 380 |  Loss: (0.2114) |  Loss2: (0.0000) | Acc: (92.00%) (45233/48768)
Epoch: 104 | Batch_idx: 390 |  Loss: (0.2114) |  Loss2: (0.0000) | Acc: (92.00%) (46384/50000)
# TEST : Loss: (0.3805) | Acc: (87.00%) (8756/10000)
percent tensor([0.5207, 0.5107, 0.5153, 0.5127, 0.5202, 0.5278, 0.5155, 0.5125, 0.5209,
        0.5131, 0.5218, 0.5141, 0.5128, 0.5164, 0.5171, 0.5188],
       device='cuda:0') torch.Size([16])
percent tensor([0.5143, 0.5107, 0.5166, 0.5179, 0.5151, 0.5121, 0.5126, 0.5187, 0.5183,
        0.5146, 0.5171, 0.5122, 0.5099, 0.5193, 0.5105, 0.5158],
       device='cuda:0') torch.Size([16])
percent tensor([0.5587, 0.5438, 0.5682, 0.5808, 0.5808, 0.5576, 0.5614, 0.5747, 0.5613,
        0.5590, 0.5560, 0.5576, 0.5222, 0.5961, 0.5493, 0.5661],
       device='cuda:0') torch.Size([16])
percent tensor([0.6013, 0.6178, 0.5925, 0.5824, 0.5874, 0.5932, 0.6082, 0.5804, 0.6167,
        0.6250, 0.6324, 0.6095, 0.6148, 0.6231, 0.5933, 0.6094],
       device='cuda:0') torch.Size([16])
percent tensor([0.5624, 0.6237, 0.4173, 0.5276, 0.4644, 0.5892, 0.5621, 0.3871, 0.6400,
        0.5906, 0.6598, 0.5226, 0.5967, 0.6741, 0.5408, 0.5807],
       device='cuda:0') torch.Size([16])
percent tensor([0.5992, 0.5875, 0.6209, 0.6172, 0.6549, 0.6130, 0.6114, 0.6496, 0.5829,
        0.5988, 0.5646, 0.5691, 0.5482, 0.5788, 0.6016, 0.6243],
       device='cuda:0') torch.Size([16])
percent tensor([0.5112, 0.5871, 0.6837, 0.6179, 0.7036, 0.7091, 0.5827, 0.6271, 0.6415,
        0.5662, 0.6589, 0.5741, 0.6210, 0.6212, 0.5064, 0.5060],
       device='cuda:0') torch.Size([16])
percent tensor([0.9993, 0.9988, 0.9993, 0.9991, 0.9988, 0.9993, 0.9989, 0.9993, 0.9997,
        0.9990, 0.9998, 0.9995, 0.9997, 0.9986, 0.9988, 0.9989],
       device='cuda:0') torch.Size([16])
Epoch: 105 | Batch_idx: 0 |  Loss: (0.1733) |  Loss2: (0.0000) | Acc: (95.00%) (122/128)
Epoch: 105 | Batch_idx: 10 |  Loss: (0.2059) |  Loss2: (0.0000) | Acc: (93.00%) (1314/1408)
Epoch: 105 | Batch_idx: 20 |  Loss: (0.2104) |  Loss2: (0.0000) | Acc: (92.00%) (2491/2688)
Epoch: 105 | Batch_idx: 30 |  Loss: (0.2020) |  Loss2: (0.0000) | Acc: (93.00%) (3694/3968)
Epoch: 105 | Batch_idx: 40 |  Loss: (0.2110) |  Loss2: (0.0000) | Acc: (92.00%) (4875/5248)
Epoch: 105 | Batch_idx: 50 |  Loss: (0.2124) |  Loss2: (0.0000) | Acc: (92.00%) (6057/6528)
Epoch: 105 | Batch_idx: 60 |  Loss: (0.2104) |  Loss2: (0.0000) | Acc: (92.00%) (7253/7808)
Epoch: 105 | Batch_idx: 70 |  Loss: (0.2093) |  Loss2: (0.0000) | Acc: (92.00%) (8441/9088)
Epoch: 105 | Batch_idx: 80 |  Loss: (0.2093) |  Loss2: (0.0000) | Acc: (92.00%) (9622/10368)
Epoch: 105 | Batch_idx: 90 |  Loss: (0.2099) |  Loss2: (0.0000) | Acc: (92.00%) (10807/11648)
Epoch: 105 | Batch_idx: 100 |  Loss: (0.2108) |  Loss2: (0.0000) | Acc: (92.00%) (11986/12928)
Epoch: 105 | Batch_idx: 110 |  Loss: (0.2093) |  Loss2: (0.0000) | Acc: (92.00%) (13178/14208)
Epoch: 105 | Batch_idx: 120 |  Loss: (0.2090) |  Loss2: (0.0000) | Acc: (92.00%) (14360/15488)
Epoch: 105 | Batch_idx: 130 |  Loss: (0.2064) |  Loss2: (0.0000) | Acc: (92.00%) (15567/16768)
Epoch: 105 | Batch_idx: 140 |  Loss: (0.2063) |  Loss2: (0.0000) | Acc: (92.00%) (16746/18048)
Epoch: 105 | Batch_idx: 150 |  Loss: (0.2073) |  Loss2: (0.0000) | Acc: (92.00%) (17932/19328)
Epoch: 105 | Batch_idx: 160 |  Loss: (0.2078) |  Loss2: (0.0000) | Acc: (92.00%) (19118/20608)
Epoch: 105 | Batch_idx: 170 |  Loss: (0.2090) |  Loss2: (0.0000) | Acc: (92.00%) (20301/21888)
Epoch: 105 | Batch_idx: 180 |  Loss: (0.2078) |  Loss2: (0.0000) | Acc: (92.00%) (21504/23168)
Epoch: 105 | Batch_idx: 190 |  Loss: (0.2095) |  Loss2: (0.0000) | Acc: (92.00%) (22675/24448)
Epoch: 105 | Batch_idx: 200 |  Loss: (0.2092) |  Loss2: (0.0000) | Acc: (92.00%) (23873/25728)
Epoch: 105 | Batch_idx: 210 |  Loss: (0.2089) |  Loss2: (0.0000) | Acc: (92.00%) (25068/27008)
Epoch: 105 | Batch_idx: 220 |  Loss: (0.2081) |  Loss2: (0.0000) | Acc: (92.00%) (26260/28288)
Epoch: 105 | Batch_idx: 230 |  Loss: (0.2085) |  Loss2: (0.0000) | Acc: (92.00%) (27449/29568)
Epoch: 105 | Batch_idx: 240 |  Loss: (0.2086) |  Loss2: (0.0000) | Acc: (92.00%) (28634/30848)
Epoch: 105 | Batch_idx: 250 |  Loss: (0.2080) |  Loss2: (0.0000) | Acc: (92.00%) (29825/32128)
Epoch: 105 | Batch_idx: 260 |  Loss: (0.2084) |  Loss2: (0.0000) | Acc: (92.00%) (31004/33408)
Epoch: 105 | Batch_idx: 270 |  Loss: (0.2082) |  Loss2: (0.0000) | Acc: (92.00%) (32191/34688)
Epoch: 105 | Batch_idx: 280 |  Loss: (0.2084) |  Loss2: (0.0000) | Acc: (92.00%) (33385/35968)
Epoch: 105 | Batch_idx: 290 |  Loss: (0.2073) |  Loss2: (0.0000) | Acc: (92.00%) (34582/37248)
Epoch: 105 | Batch_idx: 300 |  Loss: (0.2076) |  Loss2: (0.0000) | Acc: (92.00%) (35762/38528)
Epoch: 105 | Batch_idx: 310 |  Loss: (0.2073) |  Loss2: (0.0000) | Acc: (92.00%) (36968/39808)
Epoch: 105 | Batch_idx: 320 |  Loss: (0.2073) |  Loss2: (0.0000) | Acc: (92.00%) (38154/41088)
Epoch: 105 | Batch_idx: 330 |  Loss: (0.2074) |  Loss2: (0.0000) | Acc: (92.00%) (39347/42368)
Epoch: 105 | Batch_idx: 340 |  Loss: (0.2080) |  Loss2: (0.0000) | Acc: (92.00%) (40528/43648)
Epoch: 105 | Batch_idx: 350 |  Loss: (0.2074) |  Loss2: (0.0000) | Acc: (92.00%) (41731/44928)
Epoch: 105 | Batch_idx: 360 |  Loss: (0.2076) |  Loss2: (0.0000) | Acc: (92.00%) (42913/46208)
Epoch: 105 | Batch_idx: 370 |  Loss: (0.2071) |  Loss2: (0.0000) | Acc: (92.00%) (44112/47488)
Epoch: 105 | Batch_idx: 380 |  Loss: (0.2075) |  Loss2: (0.0000) | Acc: (92.00%) (45299/48768)
Epoch: 105 | Batch_idx: 390 |  Loss: (0.2082) |  Loss2: (0.0000) | Acc: (92.00%) (46442/50000)
=> saving checkpoint 'drive/app/torch/save_Schedule/checkpoint_105.pth.tar'
# TEST : Loss: (0.3778) | Acc: (87.00%) (8757/10000)
percent tensor([0.5194, 0.5087, 0.5137, 0.5112, 0.5187, 0.5266, 0.5136, 0.5106, 0.5196,
        0.5112, 0.5202, 0.5123, 0.5113, 0.5146, 0.5152, 0.5171],
       device='cuda:0') torch.Size([16])
percent tensor([0.5140, 0.5105, 0.5165, 0.5176, 0.5149, 0.5117, 0.5124, 0.5186, 0.5181,
        0.5145, 0.5169, 0.5121, 0.5097, 0.5191, 0.5102, 0.5155],
       device='cuda:0') torch.Size([16])
percent tensor([0.5620, 0.5447, 0.5722, 0.5843, 0.5852, 0.5615, 0.5645, 0.5784, 0.5640,
        0.5603, 0.5579, 0.5608, 0.5233, 0.5991, 0.5522, 0.5686],
       device='cuda:0') torch.Size([16])
percent tensor([0.6013, 0.6181, 0.5925, 0.5824, 0.5871, 0.5927, 0.6085, 0.5798, 0.6169,
        0.6255, 0.6330, 0.6099, 0.6155, 0.6233, 0.5932, 0.6093],
       device='cuda:0') torch.Size([16])
percent tensor([0.5631, 0.6250, 0.4200, 0.5299, 0.4662, 0.5874, 0.5656, 0.3894, 0.6396,
        0.5957, 0.6628, 0.5259, 0.5953, 0.6728, 0.5426, 0.5835],
       device='cuda:0') torch.Size([16])
percent tensor([0.5982, 0.5881, 0.6199, 0.6160, 0.6548, 0.6126, 0.6120, 0.6499, 0.5825,
        0.5994, 0.5646, 0.5687, 0.5472, 0.5799, 0.6017, 0.6249],
       device='cuda:0') torch.Size([16])
percent tensor([0.5061, 0.5778, 0.6788, 0.6124, 0.7014, 0.7073, 0.5760, 0.6236, 0.6348,
        0.5588, 0.6521, 0.5660, 0.6139, 0.6123, 0.4998, 0.5032],
       device='cuda:0') torch.Size([16])
percent tensor([0.9993, 0.9989, 0.9994, 0.9992, 0.9989, 0.9994, 0.9990, 0.9993, 0.9997,
        0.9991, 0.9998, 0.9995, 0.9997, 0.9986, 0.9989, 0.9990],
       device='cuda:0') torch.Size([16])
Epoch: 106 | Batch_idx: 0 |  Loss: (0.1594) |  Loss2: (0.0000) | Acc: (92.00%) (119/128)
Epoch: 106 | Batch_idx: 10 |  Loss: (0.1781) |  Loss2: (0.0000) | Acc: (93.00%) (1317/1408)
Epoch: 106 | Batch_idx: 20 |  Loss: (0.1960) |  Loss2: (0.0000) | Acc: (93.00%) (2507/2688)
Epoch: 106 | Batch_idx: 30 |  Loss: (0.1960) |  Loss2: (0.0000) | Acc: (93.00%) (3701/3968)
Epoch: 106 | Batch_idx: 40 |  Loss: (0.1988) |  Loss2: (0.0000) | Acc: (93.00%) (4891/5248)
Epoch: 106 | Batch_idx: 50 |  Loss: (0.1966) |  Loss2: (0.0000) | Acc: (93.00%) (6088/6528)
Epoch: 106 | Batch_idx: 60 |  Loss: (0.1991) |  Loss2: (0.0000) | Acc: (93.00%) (7282/7808)
Epoch: 106 | Batch_idx: 70 |  Loss: (0.1996) |  Loss2: (0.0000) | Acc: (93.00%) (8474/9088)
Epoch: 106 | Batch_idx: 80 |  Loss: (0.2011) |  Loss2: (0.0000) | Acc: (93.00%) (9666/10368)
Epoch: 106 | Batch_idx: 90 |  Loss: (0.2015) |  Loss2: (0.0000) | Acc: (93.00%) (10859/11648)
Epoch: 106 | Batch_idx: 100 |  Loss: (0.2042) |  Loss2: (0.0000) | Acc: (93.00%) (12040/12928)
Epoch: 106 | Batch_idx: 110 |  Loss: (0.2054) |  Loss2: (0.0000) | Acc: (93.00%) (13229/14208)
Epoch: 106 | Batch_idx: 120 |  Loss: (0.2059) |  Loss2: (0.0000) | Acc: (93.00%) (14409/15488)
Epoch: 106 | Batch_idx: 130 |  Loss: (0.2052) |  Loss2: (0.0000) | Acc: (93.00%) (15612/16768)
Epoch: 106 | Batch_idx: 140 |  Loss: (0.2052) |  Loss2: (0.0000) | Acc: (93.00%) (16805/18048)
Epoch: 106 | Batch_idx: 150 |  Loss: (0.2050) |  Loss2: (0.0000) | Acc: (93.00%) (17990/19328)
Epoch: 106 | Batch_idx: 160 |  Loss: (0.2080) |  Loss2: (0.0000) | Acc: (92.00%) (19150/20608)
Epoch: 106 | Batch_idx: 170 |  Loss: (0.2077) |  Loss2: (0.0000) | Acc: (92.00%) (20343/21888)
Epoch: 106 | Batch_idx: 180 |  Loss: (0.2085) |  Loss2: (0.0000) | Acc: (92.00%) (21534/23168)
Epoch: 106 | Batch_idx: 190 |  Loss: (0.2098) |  Loss2: (0.0000) | Acc: (92.00%) (22711/24448)
Epoch: 106 | Batch_idx: 200 |  Loss: (0.2098) |  Loss2: (0.0000) | Acc: (92.00%) (23889/25728)
Epoch: 106 | Batch_idx: 210 |  Loss: (0.2086) |  Loss2: (0.0000) | Acc: (92.00%) (25093/27008)
Epoch: 106 | Batch_idx: 220 |  Loss: (0.2089) |  Loss2: (0.0000) | Acc: (92.00%) (26279/28288)
Epoch: 106 | Batch_idx: 230 |  Loss: (0.2094) |  Loss2: (0.0000) | Acc: (92.00%) (27463/29568)
Epoch: 106 | Batch_idx: 240 |  Loss: (0.2093) |  Loss2: (0.0000) | Acc: (92.00%) (28642/30848)
Epoch: 106 | Batch_idx: 250 |  Loss: (0.2106) |  Loss2: (0.0000) | Acc: (92.00%) (29807/32128)
Epoch: 106 | Batch_idx: 260 |  Loss: (0.2106) |  Loss2: (0.0000) | Acc: (92.00%) (30999/33408)
Epoch: 106 | Batch_idx: 270 |  Loss: (0.2102) |  Loss2: (0.0000) | Acc: (92.00%) (32198/34688)
Epoch: 106 | Batch_idx: 280 |  Loss: (0.2099) |  Loss2: (0.0000) | Acc: (92.00%) (33390/35968)
Epoch: 106 | Batch_idx: 290 |  Loss: (0.2096) |  Loss2: (0.0000) | Acc: (92.00%) (34587/37248)
Epoch: 106 | Batch_idx: 300 |  Loss: (0.2094) |  Loss2: (0.0000) | Acc: (92.00%) (35787/38528)
Epoch: 106 | Batch_idx: 310 |  Loss: (0.2104) |  Loss2: (0.0000) | Acc: (92.00%) (36968/39808)
Epoch: 106 | Batch_idx: 320 |  Loss: (0.2098) |  Loss2: (0.0000) | Acc: (92.00%) (38158/41088)
Epoch: 106 | Batch_idx: 330 |  Loss: (0.2095) |  Loss2: (0.0000) | Acc: (92.00%) (39354/42368)
Epoch: 106 | Batch_idx: 340 |  Loss: (0.2096) |  Loss2: (0.0000) | Acc: (92.00%) (40540/43648)
Epoch: 106 | Batch_idx: 350 |  Loss: (0.2096) |  Loss2: (0.0000) | Acc: (92.00%) (41732/44928)
Epoch: 106 | Batch_idx: 360 |  Loss: (0.2100) |  Loss2: (0.0000) | Acc: (92.00%) (42913/46208)
Epoch: 106 | Batch_idx: 370 |  Loss: (0.2097) |  Loss2: (0.0000) | Acc: (92.00%) (44107/47488)
Epoch: 106 | Batch_idx: 380 |  Loss: (0.2097) |  Loss2: (0.0000) | Acc: (92.00%) (45300/48768)
Epoch: 106 | Batch_idx: 390 |  Loss: (0.2097) |  Loss2: (0.0000) | Acc: (92.00%) (46449/50000)
# TEST : Loss: (0.3778) | Acc: (87.00%) (8766/10000)
percent tensor([0.5208, 0.5098, 0.5152, 0.5123, 0.5203, 0.5278, 0.5151, 0.5119, 0.5211,
        0.5126, 0.5216, 0.5139, 0.5127, 0.5158, 0.5164, 0.5184],
       device='cuda:0') torch.Size([16])
percent tensor([0.5145, 0.5109, 0.5169, 0.5179, 0.5153, 0.5120, 0.5128, 0.5188, 0.5185,
        0.5150, 0.5174, 0.5126, 0.5102, 0.5194, 0.5106, 0.5159],
       device='cuda:0') torch.Size([16])
percent tensor([0.5623, 0.5442, 0.5708, 0.5840, 0.5827, 0.5613, 0.5638, 0.5762, 0.5640,
        0.5598, 0.5580, 0.5602, 0.5230, 0.6000, 0.5515, 0.5684],
       device='cuda:0') torch.Size([16])
percent tensor([0.6047, 0.6213, 0.5951, 0.5848, 0.5894, 0.5956, 0.6116, 0.5823, 0.6202,
        0.6287, 0.6366, 0.6131, 0.6192, 0.6264, 0.5961, 0.6129],
       device='cuda:0') torch.Size([16])
percent tensor([0.5646, 0.6221, 0.4224, 0.5283, 0.4669, 0.5892, 0.5652, 0.3908, 0.6370,
        0.5937, 0.6595, 0.5259, 0.5934, 0.6691, 0.5422, 0.5834],
       device='cuda:0') torch.Size([16])
percent tensor([0.5944, 0.5846, 0.6175, 0.6135, 0.6522, 0.6100, 0.6083, 0.6474, 0.5801,
        0.5956, 0.5608, 0.5665, 0.5430, 0.5773, 0.5985, 0.6210],
       device='cuda:0') torch.Size([16])
percent tensor([0.5124, 0.5854, 0.6889, 0.6233, 0.7112, 0.7157, 0.5854, 0.6345, 0.6416,
        0.5671, 0.6593, 0.5725, 0.6196, 0.6159, 0.5054, 0.5092],
       device='cuda:0') torch.Size([16])
percent tensor([0.9994, 0.9990, 0.9994, 0.9993, 0.9990, 0.9995, 0.9991, 0.9994, 0.9998,
        0.9992, 0.9999, 0.9996, 0.9997, 0.9987, 0.9989, 0.9991],
       device='cuda:0') torch.Size([16])
Epoch: 107 | Batch_idx: 0 |  Loss: (0.3080) |  Loss2: (0.0000) | Acc: (89.00%) (115/128)
Epoch: 107 | Batch_idx: 10 |  Loss: (0.1944) |  Loss2: (0.0000) | Acc: (93.00%) (1318/1408)
Epoch: 107 | Batch_idx: 20 |  Loss: (0.2068) |  Loss2: (0.0000) | Acc: (93.00%) (2502/2688)
Epoch: 107 | Batch_idx: 30 |  Loss: (0.2051) |  Loss2: (0.0000) | Acc: (93.00%) (3694/3968)
Epoch: 107 | Batch_idx: 40 |  Loss: (0.2012) |  Loss2: (0.0000) | Acc: (93.00%) (4897/5248)
Epoch: 107 | Batch_idx: 50 |  Loss: (0.1987) |  Loss2: (0.0000) | Acc: (93.00%) (6104/6528)
Epoch: 107 | Batch_idx: 60 |  Loss: (0.1966) |  Loss2: (0.0000) | Acc: (93.00%) (7304/7808)
Epoch: 107 | Batch_idx: 70 |  Loss: (0.1978) |  Loss2: (0.0000) | Acc: (93.00%) (8493/9088)
Epoch: 107 | Batch_idx: 80 |  Loss: (0.2005) |  Loss2: (0.0000) | Acc: (93.00%) (9669/10368)
Epoch: 107 | Batch_idx: 90 |  Loss: (0.2013) |  Loss2: (0.0000) | Acc: (93.00%) (10856/11648)
Epoch: 107 | Batch_idx: 100 |  Loss: (0.2017) |  Loss2: (0.0000) | Acc: (93.00%) (12048/12928)
Epoch: 107 | Batch_idx: 110 |  Loss: (0.2014) |  Loss2: (0.0000) | Acc: (93.00%) (13239/14208)
Epoch: 107 | Batch_idx: 120 |  Loss: (0.2028) |  Loss2: (0.0000) | Acc: (93.00%) (14416/15488)
Epoch: 107 | Batch_idx: 130 |  Loss: (0.2027) |  Loss2: (0.0000) | Acc: (93.00%) (15604/16768)
Epoch: 107 | Batch_idx: 140 |  Loss: (0.2019) |  Loss2: (0.0000) | Acc: (93.00%) (16814/18048)
Epoch: 107 | Batch_idx: 150 |  Loss: (0.2025) |  Loss2: (0.0000) | Acc: (93.00%) (18008/19328)
Epoch: 107 | Batch_idx: 160 |  Loss: (0.2033) |  Loss2: (0.0000) | Acc: (93.00%) (19198/20608)
Epoch: 107 | Batch_idx: 170 |  Loss: (0.2039) |  Loss2: (0.0000) | Acc: (93.00%) (20390/21888)
Epoch: 107 | Batch_idx: 180 |  Loss: (0.2049) |  Loss2: (0.0000) | Acc: (93.00%) (21565/23168)
Epoch: 107 | Batch_idx: 190 |  Loss: (0.2048) |  Loss2: (0.0000) | Acc: (93.00%) (22757/24448)
Epoch: 107 | Batch_idx: 200 |  Loss: (0.2044) |  Loss2: (0.0000) | Acc: (93.00%) (23947/25728)
Epoch: 107 | Batch_idx: 210 |  Loss: (0.2046) |  Loss2: (0.0000) | Acc: (93.00%) (25143/27008)
Epoch: 107 | Batch_idx: 220 |  Loss: (0.2052) |  Loss2: (0.0000) | Acc: (93.00%) (26334/28288)
Epoch: 107 | Batch_idx: 230 |  Loss: (0.2048) |  Loss2: (0.0000) | Acc: (93.00%) (27524/29568)
Epoch: 107 | Batch_idx: 240 |  Loss: (0.2050) |  Loss2: (0.0000) | Acc: (93.00%) (28715/30848)
Epoch: 107 | Batch_idx: 250 |  Loss: (0.2060) |  Loss2: (0.0000) | Acc: (93.00%) (29892/32128)
Epoch: 107 | Batch_idx: 260 |  Loss: (0.2064) |  Loss2: (0.0000) | Acc: (93.00%) (31079/33408)
Epoch: 107 | Batch_idx: 270 |  Loss: (0.2064) |  Loss2: (0.0000) | Acc: (93.00%) (32263/34688)
Epoch: 107 | Batch_idx: 280 |  Loss: (0.2060) |  Loss2: (0.0000) | Acc: (93.00%) (33458/35968)
Epoch: 107 | Batch_idx: 290 |  Loss: (0.2050) |  Loss2: (0.0000) | Acc: (93.00%) (34654/37248)
Epoch: 107 | Batch_idx: 300 |  Loss: (0.2058) |  Loss2: (0.0000) | Acc: (93.00%) (35832/38528)
Epoch: 107 | Batch_idx: 310 |  Loss: (0.2058) |  Loss2: (0.0000) | Acc: (92.00%) (37019/39808)
Epoch: 107 | Batch_idx: 320 |  Loss: (0.2053) |  Loss2: (0.0000) | Acc: (93.00%) (38215/41088)
Epoch: 107 | Batch_idx: 330 |  Loss: (0.2055) |  Loss2: (0.0000) | Acc: (92.00%) (39401/42368)
Epoch: 107 | Batch_idx: 340 |  Loss: (0.2060) |  Loss2: (0.0000) | Acc: (92.00%) (40585/43648)
Epoch: 107 | Batch_idx: 350 |  Loss: (0.2064) |  Loss2: (0.0000) | Acc: (92.00%) (41762/44928)
Epoch: 107 | Batch_idx: 360 |  Loss: (0.2060) |  Loss2: (0.0000) | Acc: (92.00%) (42955/46208)
Epoch: 107 | Batch_idx: 370 |  Loss: (0.2059) |  Loss2: (0.0000) | Acc: (92.00%) (44148/47488)
Epoch: 107 | Batch_idx: 380 |  Loss: (0.2063) |  Loss2: (0.0000) | Acc: (92.00%) (45331/48768)
Epoch: 107 | Batch_idx: 390 |  Loss: (0.2065) |  Loss2: (0.0000) | Acc: (92.00%) (46463/50000)
# TEST : Loss: (0.3748) | Acc: (87.00%) (8758/10000)
percent tensor([0.5203, 0.5087, 0.5148, 0.5113, 0.5200, 0.5272, 0.5143, 0.5109, 0.5207,
        0.5117, 0.5209, 0.5134, 0.5120, 0.5147, 0.5153, 0.5175],
       device='cuda:0') torch.Size([16])
percent tensor([0.5145, 0.5109, 0.5167, 0.5176, 0.5150, 0.5118, 0.5128, 0.5187, 0.5185,
        0.5150, 0.5174, 0.5124, 0.5102, 0.5193, 0.5104, 0.5158],
       device='cuda:0') torch.Size([16])
percent tensor([0.5626, 0.5449, 0.5709, 0.5830, 0.5838, 0.5613, 0.5651, 0.5765, 0.5642,
        0.5608, 0.5587, 0.5610, 0.5230, 0.6005, 0.5522, 0.5685],
       device='cuda:0') torch.Size([16])
percent tensor([0.6016, 0.6181, 0.5925, 0.5823, 0.5866, 0.5927, 0.6087, 0.5793, 0.6172,
        0.6255, 0.6332, 0.6103, 0.6160, 0.6238, 0.5928, 0.6096],
       device='cuda:0') torch.Size([16])
percent tensor([0.5693, 0.6242, 0.4258, 0.5351, 0.4713, 0.5951, 0.5712, 0.3914, 0.6406,
        0.6001, 0.6650, 0.5321, 0.5921, 0.6715, 0.5474, 0.5897],
       device='cuda:0') torch.Size([16])
percent tensor([0.5969, 0.5880, 0.6197, 0.6141, 0.6541, 0.6122, 0.6107, 0.6485, 0.5826,
        0.5997, 0.5641, 0.5684, 0.5467, 0.5800, 0.6013, 0.6237],
       device='cuda:0') torch.Size([16])
percent tensor([0.5091, 0.5797, 0.6916, 0.6238, 0.7131, 0.7203, 0.5826, 0.6355, 0.6402,
        0.5613, 0.6582, 0.5685, 0.6172, 0.6163, 0.5015, 0.5075],
       device='cuda:0') torch.Size([16])
percent tensor([0.9994, 0.9990, 0.9994, 0.9993, 0.9990, 0.9994, 0.9991, 0.9994, 0.9997,
        0.9992, 0.9999, 0.9996, 0.9997, 0.9987, 0.9990, 0.9991],
       device='cuda:0') torch.Size([16])
True Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=128, out_features=16, bias=False)
False Linear(in_features=16, out_features=2, bias=False)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=128, out_features=16, bias=False)
False Linear(in_features=16, out_features=2, bias=False)
True Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=256, out_features=32, bias=False)
False Linear(in_features=32, out_features=2, bias=False)
True Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=256, out_features=32, bias=False)
False Linear(in_features=32, out_features=2, bias=False)
True Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=512, out_features=64, bias=False)
False Linear(in_features=64, out_features=2, bias=False)
True Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=512, out_features=64, bias=False)
False Linear(in_features=64, out_features=2, bias=False)
True Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1024, out_features=128, bias=False)
False Linear(in_features=128, out_features=2, bias=False)
True Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1024, out_features=128, bias=False)
False Linear(in_features=128, out_features=2, bias=False)
True Linear(in_features=512, out_features=10, bias=True)
Epoch: 108 | Batch_idx: 0 |  Loss: (0.1638) |  Loss2: (0.0000) | Acc: (94.00%) (121/128)
Epoch: 108 | Batch_idx: 10 |  Loss: (0.2024) |  Loss2: (0.0000) | Acc: (93.00%) (1316/1408)
Epoch: 108 | Batch_idx: 20 |  Loss: (0.2082) |  Loss2: (0.0000) | Acc: (92.00%) (2496/2688)
Epoch: 108 | Batch_idx: 30 |  Loss: (0.2141) |  Loss2: (0.0000) | Acc: (92.00%) (3673/3968)
Epoch: 108 | Batch_idx: 40 |  Loss: (0.2115) |  Loss2: (0.0000) | Acc: (92.00%) (4870/5248)
Epoch: 108 | Batch_idx: 50 |  Loss: (0.2154) |  Loss2: (0.0000) | Acc: (92.00%) (6046/6528)
Epoch: 108 | Batch_idx: 60 |  Loss: (0.2138) |  Loss2: (0.0000) | Acc: (92.00%) (7242/7808)
Epoch: 108 | Batch_idx: 70 |  Loss: (0.2148) |  Loss2: (0.0000) | Acc: (92.00%) (8424/9088)
Epoch: 108 | Batch_idx: 80 |  Loss: (0.2156) |  Loss2: (0.0000) | Acc: (92.00%) (9609/10368)
Epoch: 108 | Batch_idx: 90 |  Loss: (0.2175) |  Loss2: (0.0000) | Acc: (92.00%) (10780/11648)
Epoch: 108 | Batch_idx: 100 |  Loss: (0.2175) |  Loss2: (0.0000) | Acc: (92.00%) (11958/12928)
Epoch: 108 | Batch_idx: 110 |  Loss: (0.2196) |  Loss2: (0.0000) | Acc: (92.00%) (13133/14208)
Epoch: 108 | Batch_idx: 120 |  Loss: (0.2210) |  Loss2: (0.0000) | Acc: (92.00%) (14313/15488)
Epoch: 108 | Batch_idx: 130 |  Loss: (0.2197) |  Loss2: (0.0000) | Acc: (92.00%) (15503/16768)
Epoch: 108 | Batch_idx: 140 |  Loss: (0.2178) |  Loss2: (0.0000) | Acc: (92.00%) (16693/18048)
Epoch: 108 | Batch_idx: 150 |  Loss: (0.2185) |  Loss2: (0.0000) | Acc: (92.00%) (17875/19328)
Epoch: 108 | Batch_idx: 160 |  Loss: (0.2201) |  Loss2: (0.0000) | Acc: (92.00%) (19046/20608)
Epoch: 108 | Batch_idx: 170 |  Loss: (0.2220) |  Loss2: (0.0000) | Acc: (92.00%) (20209/21888)
Epoch: 108 | Batch_idx: 180 |  Loss: (0.2213) |  Loss2: (0.0000) | Acc: (92.00%) (21405/23168)
Epoch: 108 | Batch_idx: 190 |  Loss: (0.2221) |  Loss2: (0.0000) | Acc: (92.00%) (22578/24448)
Epoch: 108 | Batch_idx: 200 |  Loss: (0.2224) |  Loss2: (0.0000) | Acc: (92.00%) (23755/25728)
Epoch: 108 | Batch_idx: 210 |  Loss: (0.2224) |  Loss2: (0.0000) | Acc: (92.00%) (24942/27008)
Epoch: 108 | Batch_idx: 220 |  Loss: (0.2224) |  Loss2: (0.0000) | Acc: (92.00%) (26130/28288)
Epoch: 108 | Batch_idx: 230 |  Loss: (0.2230) |  Loss2: (0.0000) | Acc: (92.00%) (27298/29568)
Epoch: 108 | Batch_idx: 240 |  Loss: (0.2230) |  Loss2: (0.0000) | Acc: (92.00%) (28475/30848)
Epoch: 108 | Batch_idx: 250 |  Loss: (0.2231) |  Loss2: (0.0000) | Acc: (92.00%) (29659/32128)
Epoch: 108 | Batch_idx: 260 |  Loss: (0.2237) |  Loss2: (0.0000) | Acc: (92.00%) (30831/33408)
Epoch: 108 | Batch_idx: 270 |  Loss: (0.2235) |  Loss2: (0.0000) | Acc: (92.00%) (32012/34688)
Epoch: 108 | Batch_idx: 280 |  Loss: (0.2236) |  Loss2: (0.0000) | Acc: (92.00%) (33197/35968)
Epoch: 108 | Batch_idx: 290 |  Loss: (0.2227) |  Loss2: (0.0000) | Acc: (92.00%) (34390/37248)
Epoch: 108 | Batch_idx: 300 |  Loss: (0.2224) |  Loss2: (0.0000) | Acc: (92.00%) (35583/38528)
Epoch: 108 | Batch_idx: 310 |  Loss: (0.2218) |  Loss2: (0.0000) | Acc: (92.00%) (36775/39808)
Epoch: 108 | Batch_idx: 320 |  Loss: (0.2224) |  Loss2: (0.0000) | Acc: (92.00%) (37947/41088)
Epoch: 108 | Batch_idx: 330 |  Loss: (0.2231) |  Loss2: (0.0000) | Acc: (92.00%) (39118/42368)
Epoch: 108 | Batch_idx: 340 |  Loss: (0.2233) |  Loss2: (0.0000) | Acc: (92.00%) (40293/43648)
Epoch: 108 | Batch_idx: 350 |  Loss: (0.2228) |  Loss2: (0.0000) | Acc: (92.00%) (41496/44928)
Epoch: 108 | Batch_idx: 360 |  Loss: (0.2226) |  Loss2: (0.0000) | Acc: (92.00%) (42680/46208)
Epoch: 108 | Batch_idx: 370 |  Loss: (0.2225) |  Loss2: (0.0000) | Acc: (92.00%) (43858/47488)
Epoch: 108 | Batch_idx: 380 |  Loss: (0.2231) |  Loss2: (0.0000) | Acc: (92.00%) (45020/48768)
Epoch: 108 | Batch_idx: 390 |  Loss: (0.2231) |  Loss2: (0.0000) | Acc: (92.00%) (46155/50000)
# TEST : Loss: (0.4883) | Acc: (84.00%) (8474/10000)
percent tensor([0.5199, 0.5084, 0.5143, 0.5102, 0.5185, 0.5258, 0.5143, 0.5111, 0.5215,
        0.5114, 0.5225, 0.5132, 0.5124, 0.5157, 0.5149, 0.5168],
       device='cuda:0') torch.Size([16])
percent tensor([0.5155, 0.5104, 0.5165, 0.5178, 0.5148, 0.5124, 0.5129, 0.5189, 0.5194,
        0.5145, 0.5177, 0.5123, 0.5113, 0.5200, 0.5103, 0.5166],
       device='cuda:0') torch.Size([16])
percent tensor([0.5691, 0.5448, 0.5617, 0.5817, 0.5760, 0.5623, 0.5660, 0.5776, 0.5693,
        0.5558, 0.5611, 0.5564, 0.5285, 0.6025, 0.5530, 0.5707],
       device='cuda:0') torch.Size([16])
percent tensor([0.5960, 0.6119, 0.5974, 0.5861, 0.5860, 0.5887, 0.6044, 0.5794, 0.6081,
        0.6209, 0.6224, 0.6126, 0.6097, 0.6155, 0.5888, 0.6029],
       device='cuda:0') torch.Size([16])
percent tensor([0.5415, 0.6057, 0.4627, 0.5315, 0.4783, 0.5850, 0.5613, 0.3859, 0.6088,
        0.5962, 0.6436, 0.5425, 0.5723, 0.6499, 0.5164, 0.5733],
       device='cuda:0') torch.Size([16])
percent tensor([0.6072, 0.6026, 0.6212, 0.6126, 0.6568, 0.6155, 0.6174, 0.6524, 0.6163,
        0.6022, 0.5774, 0.5678, 0.5647, 0.6016, 0.6029, 0.6249],
       device='cuda:0') torch.Size([16])
percent tensor([0.5274, 0.6030, 0.7120, 0.6286, 0.7355, 0.7385, 0.5964, 0.6652, 0.6648,
        0.5777, 0.6850, 0.5679, 0.6334, 0.5931, 0.5400, 0.5460],
       device='cuda:0') torch.Size([16])
percent tensor([0.9990, 0.9989, 0.9995, 0.9995, 0.9992, 0.9986, 0.9986, 0.9996, 0.9994,
        0.9992, 0.9997, 0.9995, 0.9997, 0.9986, 0.9996, 0.9992],
       device='cuda:0') torch.Size([16])
Epoch: 109 | Batch_idx: 0 |  Loss: (0.2890) |  Loss2: (0.0000) | Acc: (91.00%) (117/128)
Epoch: 109 | Batch_idx: 10 |  Loss: (0.2562) |  Loss2: (0.0000) | Acc: (90.00%) (1279/1408)
Epoch: 109 | Batch_idx: 20 |  Loss: (0.2327) |  Loss2: (0.0000) | Acc: (91.00%) (2470/2688)
Epoch: 109 | Batch_idx: 30 |  Loss: (0.2264) |  Loss2: (0.0000) | Acc: (91.00%) (3650/3968)
Epoch: 109 | Batch_idx: 40 |  Loss: (0.2225) |  Loss2: (0.0000) | Acc: (92.00%) (4837/5248)
Epoch: 109 | Batch_idx: 50 |  Loss: (0.2218) |  Loss2: (0.0000) | Acc: (92.00%) (6019/6528)
Epoch: 109 | Batch_idx: 60 |  Loss: (0.2189) |  Loss2: (0.0000) | Acc: (92.00%) (7205/7808)
Epoch: 109 | Batch_idx: 70 |  Loss: (0.2167) |  Loss2: (0.0000) | Acc: (92.00%) (8404/9088)
Epoch: 109 | Batch_idx: 80 |  Loss: (0.2116) |  Loss2: (0.0000) | Acc: (92.00%) (9603/10368)
Epoch: 109 | Batch_idx: 90 |  Loss: (0.2117) |  Loss2: (0.0000) | Acc: (92.00%) (10789/11648)
Epoch: 109 | Batch_idx: 100 |  Loss: (0.2110) |  Loss2: (0.0000) | Acc: (92.00%) (11984/12928)
Epoch: 109 | Batch_idx: 110 |  Loss: (0.2104) |  Loss2: (0.0000) | Acc: (92.00%) (13174/14208)
Epoch: 109 | Batch_idx: 120 |  Loss: (0.2094) |  Loss2: (0.0000) | Acc: (92.00%) (14367/15488)
Epoch: 109 | Batch_idx: 130 |  Loss: (0.2079) |  Loss2: (0.0000) | Acc: (92.00%) (15559/16768)
Epoch: 109 | Batch_idx: 140 |  Loss: (0.2081) |  Loss2: (0.0000) | Acc: (92.00%) (16745/18048)
Epoch: 109 | Batch_idx: 150 |  Loss: (0.2085) |  Loss2: (0.0000) | Acc: (92.00%) (17924/19328)
Epoch: 109 | Batch_idx: 160 |  Loss: (0.2092) |  Loss2: (0.0000) | Acc: (92.00%) (19106/20608)
Epoch: 109 | Batch_idx: 170 |  Loss: (0.2092) |  Loss2: (0.0000) | Acc: (92.00%) (20293/21888)
Epoch: 109 | Batch_idx: 180 |  Loss: (0.2108) |  Loss2: (0.0000) | Acc: (92.00%) (21459/23168)
Epoch: 109 | Batch_idx: 190 |  Loss: (0.2101) |  Loss2: (0.0000) | Acc: (92.00%) (22646/24448)
Epoch: 109 | Batch_idx: 200 |  Loss: (0.2111) |  Loss2: (0.0000) | Acc: (92.00%) (23829/25728)
Epoch: 109 | Batch_idx: 210 |  Loss: (0.2107) |  Loss2: (0.0000) | Acc: (92.00%) (25020/27008)
Epoch: 109 | Batch_idx: 220 |  Loss: (0.2103) |  Loss2: (0.0000) | Acc: (92.00%) (26216/28288)
Epoch: 109 | Batch_idx: 230 |  Loss: (0.2099) |  Loss2: (0.0000) | Acc: (92.00%) (27413/29568)
Epoch: 109 | Batch_idx: 240 |  Loss: (0.2093) |  Loss2: (0.0000) | Acc: (92.00%) (28603/30848)
Epoch: 109 | Batch_idx: 250 |  Loss: (0.2105) |  Loss2: (0.0000) | Acc: (92.00%) (29781/32128)
Epoch: 109 | Batch_idx: 260 |  Loss: (0.2088) |  Loss2: (0.0000) | Acc: (92.00%) (30984/33408)
Epoch: 109 | Batch_idx: 270 |  Loss: (0.2099) |  Loss2: (0.0000) | Acc: (92.00%) (32165/34688)
Epoch: 109 | Batch_idx: 280 |  Loss: (0.2099) |  Loss2: (0.0000) | Acc: (92.00%) (33361/35968)
Epoch: 109 | Batch_idx: 290 |  Loss: (0.2106) |  Loss2: (0.0000) | Acc: (92.00%) (34547/37248)
Epoch: 109 | Batch_idx: 300 |  Loss: (0.2111) |  Loss2: (0.0000) | Acc: (92.00%) (35718/38528)
Epoch: 109 | Batch_idx: 310 |  Loss: (0.2117) |  Loss2: (0.0000) | Acc: (92.00%) (36896/39808)
Epoch: 109 | Batch_idx: 320 |  Loss: (0.2119) |  Loss2: (0.0000) | Acc: (92.00%) (38083/41088)
Epoch: 109 | Batch_idx: 330 |  Loss: (0.2112) |  Loss2: (0.0000) | Acc: (92.00%) (39280/42368)
Epoch: 109 | Batch_idx: 340 |  Loss: (0.2115) |  Loss2: (0.0000) | Acc: (92.00%) (40447/43648)
Epoch: 109 | Batch_idx: 350 |  Loss: (0.2115) |  Loss2: (0.0000) | Acc: (92.00%) (41633/44928)
Epoch: 109 | Batch_idx: 360 |  Loss: (0.2116) |  Loss2: (0.0000) | Acc: (92.00%) (42819/46208)
Epoch: 109 | Batch_idx: 370 |  Loss: (0.2129) |  Loss2: (0.0000) | Acc: (92.00%) (43992/47488)
Epoch: 109 | Batch_idx: 380 |  Loss: (0.2133) |  Loss2: (0.0000) | Acc: (92.00%) (45169/48768)
Epoch: 109 | Batch_idx: 390 |  Loss: (0.2137) |  Loss2: (0.0000) | Acc: (92.00%) (46308/50000)
# TEST : Loss: (0.4184) | Acc: (86.00%) (8670/10000)
percent tensor([0.5198, 0.5084, 0.5155, 0.5110, 0.5192, 0.5262, 0.5141, 0.5119, 0.5208,
        0.5117, 0.5222, 0.5138, 0.5118, 0.5146, 0.5159, 0.5171],
       device='cuda:0') torch.Size([16])
percent tensor([0.5142, 0.5098, 0.5164, 0.5172, 0.5147, 0.5119, 0.5126, 0.5185, 0.5173,
        0.5140, 0.5164, 0.5122, 0.5098, 0.5194, 0.5099, 0.5160],
       device='cuda:0') torch.Size([16])
percent tensor([0.5627, 0.5504, 0.5531, 0.5760, 0.5715, 0.5587, 0.5706, 0.5741, 0.5677,
        0.5544, 0.5621, 0.5523, 0.5241, 0.6099, 0.5539, 0.5702],
       device='cuda:0') torch.Size([16])
percent tensor([0.5995, 0.6196, 0.5916, 0.5888, 0.5821, 0.5933, 0.6086, 0.5784, 0.6138,
        0.6245, 0.6307, 0.6101, 0.6175, 0.6272, 0.5945, 0.6102],
       device='cuda:0') torch.Size([16])
percent tensor([0.5780, 0.6226, 0.4732, 0.5599, 0.4923, 0.6199, 0.5794, 0.4037, 0.6430,
        0.6078, 0.6745, 0.5506, 0.5989, 0.6597, 0.5526, 0.6118],
       device='cuda:0') torch.Size([16])
percent tensor([0.5862, 0.5909, 0.6130, 0.6052, 0.6485, 0.6034, 0.6122, 0.6525, 0.5836,
        0.5996, 0.5677, 0.5670, 0.5499, 0.5878, 0.5987, 0.6125],
       device='cuda:0') torch.Size([16])
percent tensor([0.4939, 0.5851, 0.7052, 0.6092, 0.7314, 0.7411, 0.5620, 0.6628, 0.6031,
        0.5749, 0.6446, 0.5601, 0.6154, 0.5901, 0.5152, 0.5140],
       device='cuda:0') torch.Size([16])
percent tensor([0.9994, 0.9991, 0.9994, 0.9992, 0.9989, 0.9995, 0.9990, 0.9996, 0.9998,
        0.9994, 0.9999, 0.9997, 0.9998, 0.9990, 0.9991, 0.9991],
       device='cuda:0') torch.Size([16])
Epoch: 110 | Batch_idx: 0 |  Loss: (0.1859) |  Loss2: (0.0000) | Acc: (95.00%) (122/128)
Epoch: 110 | Batch_idx: 10 |  Loss: (0.2333) |  Loss2: (0.0000) | Acc: (92.00%) (1296/1408)
Epoch: 110 | Batch_idx: 20 |  Loss: (0.2194) |  Loss2: (0.0000) | Acc: (92.00%) (2479/2688)
Epoch: 110 | Batch_idx: 30 |  Loss: (0.2196) |  Loss2: (0.0000) | Acc: (92.00%) (3662/3968)
Epoch: 110 | Batch_idx: 40 |  Loss: (0.2214) |  Loss2: (0.0000) | Acc: (92.00%) (4845/5248)
Epoch: 110 | Batch_idx: 50 |  Loss: (0.2138) |  Loss2: (0.0000) | Acc: (92.00%) (6047/6528)
Epoch: 110 | Batch_idx: 60 |  Loss: (0.2198) |  Loss2: (0.0000) | Acc: (92.00%) (7217/7808)
Epoch: 110 | Batch_idx: 70 |  Loss: (0.2155) |  Loss2: (0.0000) | Acc: (92.00%) (8422/9088)
Epoch: 110 | Batch_idx: 80 |  Loss: (0.2147) |  Loss2: (0.0000) | Acc: (92.00%) (9616/10368)
Epoch: 110 | Batch_idx: 90 |  Loss: (0.2131) |  Loss2: (0.0000) | Acc: (92.00%) (10820/11648)
Epoch: 110 | Batch_idx: 100 |  Loss: (0.2127) |  Loss2: (0.0000) | Acc: (92.00%) (12001/12928)
Epoch: 110 | Batch_idx: 110 |  Loss: (0.2120) |  Loss2: (0.0000) | Acc: (92.00%) (13197/14208)
Epoch: 110 | Batch_idx: 120 |  Loss: (0.2117) |  Loss2: (0.0000) | Acc: (92.00%) (14396/15488)
Epoch: 110 | Batch_idx: 130 |  Loss: (0.2133) |  Loss2: (0.0000) | Acc: (92.00%) (15573/16768)
Epoch: 110 | Batch_idx: 140 |  Loss: (0.2144) |  Loss2: (0.0000) | Acc: (92.00%) (16749/18048)
Epoch: 110 | Batch_idx: 150 |  Loss: (0.2150) |  Loss2: (0.0000) | Acc: (92.00%) (17937/19328)
Epoch: 110 | Batch_idx: 160 |  Loss: (0.2154) |  Loss2: (0.0000) | Acc: (92.00%) (19111/20608)
Epoch: 110 | Batch_idx: 170 |  Loss: (0.2160) |  Loss2: (0.0000) | Acc: (92.00%) (20297/21888)
Epoch: 110 | Batch_idx: 180 |  Loss: (0.2167) |  Loss2: (0.0000) | Acc: (92.00%) (21463/23168)
Epoch: 110 | Batch_idx: 190 |  Loss: (0.2164) |  Loss2: (0.0000) | Acc: (92.00%) (22646/24448)
Epoch: 110 | Batch_idx: 200 |  Loss: (0.2154) |  Loss2: (0.0000) | Acc: (92.00%) (23839/25728)
Epoch: 110 | Batch_idx: 210 |  Loss: (0.2144) |  Loss2: (0.0000) | Acc: (92.00%) (25033/27008)
Epoch: 110 | Batch_idx: 220 |  Loss: (0.2144) |  Loss2: (0.0000) | Acc: (92.00%) (26215/28288)
Epoch: 110 | Batch_idx: 230 |  Loss: (0.2145) |  Loss2: (0.0000) | Acc: (92.00%) (27403/29568)
Epoch: 110 | Batch_idx: 240 |  Loss: (0.2150) |  Loss2: (0.0000) | Acc: (92.00%) (28581/30848)
Epoch: 110 | Batch_idx: 250 |  Loss: (0.2152) |  Loss2: (0.0000) | Acc: (92.00%) (29770/32128)
Epoch: 110 | Batch_idx: 260 |  Loss: (0.2153) |  Loss2: (0.0000) | Acc: (92.00%) (30958/33408)
Epoch: 110 | Batch_idx: 270 |  Loss: (0.2151) |  Loss2: (0.0000) | Acc: (92.00%) (32145/34688)
Epoch: 110 | Batch_idx: 280 |  Loss: (0.2151) |  Loss2: (0.0000) | Acc: (92.00%) (33334/35968)
Epoch: 110 | Batch_idx: 290 |  Loss: (0.2146) |  Loss2: (0.0000) | Acc: (92.00%) (34515/37248)
Epoch: 110 | Batch_idx: 300 |  Loss: (0.2152) |  Loss2: (0.0000) | Acc: (92.00%) (35685/38528)
Epoch: 110 | Batch_idx: 310 |  Loss: (0.2155) |  Loss2: (0.0000) | Acc: (92.00%) (36865/39808)
Epoch: 110 | Batch_idx: 320 |  Loss: (0.2148) |  Loss2: (0.0000) | Acc: (92.00%) (38064/41088)
Epoch: 110 | Batch_idx: 330 |  Loss: (0.2146) |  Loss2: (0.0000) | Acc: (92.00%) (39251/42368)
Epoch: 110 | Batch_idx: 340 |  Loss: (0.2149) |  Loss2: (0.0000) | Acc: (92.00%) (40431/43648)
Epoch: 110 | Batch_idx: 350 |  Loss: (0.2147) |  Loss2: (0.0000) | Acc: (92.00%) (41620/44928)
Epoch: 110 | Batch_idx: 360 |  Loss: (0.2150) |  Loss2: (0.0000) | Acc: (92.00%) (42811/46208)
Epoch: 110 | Batch_idx: 370 |  Loss: (0.2149) |  Loss2: (0.0000) | Acc: (92.00%) (44003/47488)
Epoch: 110 | Batch_idx: 380 |  Loss: (0.2154) |  Loss2: (0.0000) | Acc: (92.00%) (45187/48768)
Epoch: 110 | Batch_idx: 390 |  Loss: (0.2150) |  Loss2: (0.0000) | Acc: (92.00%) (46333/50000)
=> saving checkpoint 'drive/app/torch/save_Schedule/checkpoint_110.pth.tar'
# TEST : Loss: (0.3977) | Acc: (87.00%) (8709/10000)
percent tensor([0.5204, 0.5088, 0.5175, 0.5113, 0.5221, 0.5268, 0.5159, 0.5124, 0.5218,
        0.5126, 0.5220, 0.5167, 0.5122, 0.5160, 0.5157, 0.5170],
       device='cuda:0') torch.Size([16])
percent tensor([0.5150, 0.5100, 0.5183, 0.5183, 0.5157, 0.5114, 0.5129, 0.5198, 0.5187,
        0.5148, 0.5170, 0.5145, 0.5111, 0.5200, 0.5101, 0.5161],
       device='cuda:0') torch.Size([16])
percent tensor([0.5644, 0.5444, 0.5708, 0.5832, 0.5810, 0.5555, 0.5675, 0.5795, 0.5627,
        0.5574, 0.5536, 0.5654, 0.5261, 0.6014, 0.5501, 0.5700],
       device='cuda:0') torch.Size([16])
percent tensor([0.5981, 0.6184, 0.5919, 0.5831, 0.5829, 0.5892, 0.6099, 0.5803, 0.6132,
        0.6244, 0.6298, 0.6106, 0.6152, 0.6243, 0.5928, 0.6048],
       device='cuda:0') torch.Size([16])
percent tensor([0.5579, 0.6156, 0.4466, 0.5362, 0.4849, 0.5800, 0.5714, 0.3895, 0.6380,
        0.5943, 0.6597, 0.5423, 0.5927, 0.6516, 0.5394, 0.5754],
       device='cuda:0') torch.Size([16])
percent tensor([0.5870, 0.5850, 0.6179, 0.6132, 0.6481, 0.6127, 0.6020, 0.6465, 0.5761,
        0.5923, 0.5601, 0.5735, 0.5468, 0.5776, 0.5984, 0.6178],
       device='cuda:0') torch.Size([16])
percent tensor([0.4984, 0.5930, 0.6876, 0.6497, 0.7356, 0.7519, 0.5506, 0.6372, 0.6443,
        0.5677, 0.6578, 0.5546, 0.6266, 0.5946, 0.5224, 0.4998],
       device='cuda:0') torch.Size([16])
percent tensor([0.9994, 0.9988, 0.9993, 0.9994, 0.9991, 0.9987, 0.9991, 0.9995, 0.9997,
        0.9990, 0.9994, 0.9995, 0.9995, 0.9984, 0.9989, 0.9993],
       device='cuda:0') torch.Size([16])
Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 3, 3, 3]) tensor(184.8193, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(822.3266, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(810.5692, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([128, 64, 3, 3]) tensor(1526.0576, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([128, 64, 1, 1]) tensor(487.2092, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([128, 128, 3, 3]) tensor(2258.4812, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([256, 128, 3, 3]) tensor(4263.6885, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([256, 128, 1, 1]) tensor(1383.8915, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([256, 256, 3, 3]) tensor(6136.3491, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([512, 256, 3, 3]) tensor(11818.1113, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([512, 256, 1, 1]) tensor(3923.2134, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([512, 512, 3, 3]) tensor(16587.8281, device='cuda:0', grad_fn=<NormBackward0>)
Epoch: 111 | Batch_idx: 0 |  Loss: (0.1782) |  Loss2: (0.0000) | Acc: (93.00%) (120/128)
Epoch: 111 | Batch_idx: 10 |  Loss: (0.2028) |  Loss2: (0.0000) | Acc: (93.00%) (1315/1408)
Epoch: 111 | Batch_idx: 20 |  Loss: (0.2003) |  Loss2: (0.0000) | Acc: (93.00%) (2504/2688)
Epoch: 111 | Batch_idx: 30 |  Loss: (0.2036) |  Loss2: (0.0000) | Acc: (93.00%) (3694/3968)
Epoch: 111 | Batch_idx: 40 |  Loss: (0.2041) |  Loss2: (0.0000) | Acc: (92.00%) (4876/5248)
Epoch: 111 | Batch_idx: 50 |  Loss: (0.2074) |  Loss2: (0.0000) | Acc: (92.00%) (6056/6528)
Epoch: 111 | Batch_idx: 60 |  Loss: (0.2024) |  Loss2: (0.0000) | Acc: (92.00%) (7259/7808)
Epoch: 111 | Batch_idx: 70 |  Loss: (0.2050) |  Loss2: (0.0000) | Acc: (92.00%) (8439/9088)
Epoch: 111 | Batch_idx: 80 |  Loss: (0.2047) |  Loss2: (0.0000) | Acc: (92.00%) (9633/10368)
Epoch: 111 | Batch_idx: 90 |  Loss: (0.2043) |  Loss2: (0.0000) | Acc: (92.00%) (10826/11648)
Epoch: 111 | Batch_idx: 100 |  Loss: (0.2061) |  Loss2: (0.0000) | Acc: (92.00%) (12006/12928)
Epoch: 111 | Batch_idx: 110 |  Loss: (0.2060) |  Loss2: (0.0000) | Acc: (92.00%) (13194/14208)
Epoch: 111 | Batch_idx: 120 |  Loss: (0.2049) |  Loss2: (0.0000) | Acc: (92.00%) (14391/15488)
Epoch: 111 | Batch_idx: 130 |  Loss: (0.2044) |  Loss2: (0.0000) | Acc: (92.00%) (15591/16768)
Epoch: 111 | Batch_idx: 140 |  Loss: (0.2036) |  Loss2: (0.0000) | Acc: (93.00%) (16789/18048)
Epoch: 111 | Batch_idx: 150 |  Loss: (0.2033) |  Loss2: (0.0000) | Acc: (92.00%) (17973/19328)
Epoch: 111 | Batch_idx: 160 |  Loss: (0.2037) |  Loss2: (0.0000) | Acc: (92.00%) (19162/20608)
Epoch: 111 | Batch_idx: 170 |  Loss: (0.2039) |  Loss2: (0.0000) | Acc: (92.00%) (20355/21888)
Epoch: 111 | Batch_idx: 180 |  Loss: (0.2034) |  Loss2: (0.0000) | Acc: (92.00%) (21539/23168)
Epoch: 111 | Batch_idx: 190 |  Loss: (0.2045) |  Loss2: (0.0000) | Acc: (92.00%) (22728/24448)
Epoch: 111 | Batch_idx: 200 |  Loss: (0.2041) |  Loss2: (0.0000) | Acc: (92.00%) (23911/25728)
Epoch: 111 | Batch_idx: 210 |  Loss: (0.2036) |  Loss2: (0.0000) | Acc: (92.00%) (25110/27008)
Epoch: 111 | Batch_idx: 220 |  Loss: (0.2035) |  Loss2: (0.0000) | Acc: (92.00%) (26303/28288)
Epoch: 111 | Batch_idx: 230 |  Loss: (0.2028) |  Loss2: (0.0000) | Acc: (93.00%) (27501/29568)
Epoch: 111 | Batch_idx: 240 |  Loss: (0.2025) |  Loss2: (0.0000) | Acc: (92.00%) (28685/30848)
Epoch: 111 | Batch_idx: 250 |  Loss: (0.2027) |  Loss2: (0.0000) | Acc: (92.00%) (29859/32128)
Epoch: 111 | Batch_idx: 260 |  Loss: (0.2032) |  Loss2: (0.0000) | Acc: (92.00%) (31040/33408)
Epoch: 111 | Batch_idx: 270 |  Loss: (0.2035) |  Loss2: (0.0000) | Acc: (92.00%) (32224/34688)
Epoch: 111 | Batch_idx: 280 |  Loss: (0.2039) |  Loss2: (0.0000) | Acc: (92.00%) (33410/35968)
Epoch: 111 | Batch_idx: 290 |  Loss: (0.2046) |  Loss2: (0.0000) | Acc: (92.00%) (34588/37248)
Epoch: 111 | Batch_idx: 300 |  Loss: (0.2051) |  Loss2: (0.0000) | Acc: (92.00%) (35775/38528)
Epoch: 111 | Batch_idx: 310 |  Loss: (0.2056) |  Loss2: (0.0000) | Acc: (92.00%) (36961/39808)
Epoch: 111 | Batch_idx: 320 |  Loss: (0.2055) |  Loss2: (0.0000) | Acc: (92.00%) (38147/41088)
Epoch: 111 | Batch_idx: 330 |  Loss: (0.2058) |  Loss2: (0.0000) | Acc: (92.00%) (39327/42368)
Epoch: 111 | Batch_idx: 340 |  Loss: (0.2060) |  Loss2: (0.0000) | Acc: (92.00%) (40510/43648)
Epoch: 111 | Batch_idx: 350 |  Loss: (0.2061) |  Loss2: (0.0000) | Acc: (92.00%) (41686/44928)
Epoch: 111 | Batch_idx: 360 |  Loss: (0.2064) |  Loss2: (0.0000) | Acc: (92.00%) (42875/46208)
Epoch: 111 | Batch_idx: 370 |  Loss: (0.2060) |  Loss2: (0.0000) | Acc: (92.00%) (44072/47488)
Epoch: 111 | Batch_idx: 380 |  Loss: (0.2064) |  Loss2: (0.0000) | Acc: (92.00%) (45251/48768)
Epoch: 111 | Batch_idx: 390 |  Loss: (0.2062) |  Loss2: (0.0000) | Acc: (92.00%) (46393/50000)
# TEST : Loss: (0.4774) | Acc: (85.00%) (8506/10000)
percent tensor([0.5203, 0.5082, 0.5175, 0.5103, 0.5209, 0.5265, 0.5148, 0.5119, 0.5212,
        0.5121, 0.5217, 0.5156, 0.5116, 0.5148, 0.5153, 0.5169],
       device='cuda:0') torch.Size([16])
percent tensor([0.5151, 0.5111, 0.5167, 0.5171, 0.5145, 0.5113, 0.5131, 0.5194, 0.5199,
        0.5149, 0.5180, 0.5127, 0.5111, 0.5212, 0.5101, 0.5163],
       device='cuda:0') torch.Size([16])
percent tensor([0.5655, 0.5469, 0.5673, 0.5859, 0.5799, 0.5545, 0.5690, 0.5788, 0.5753,
        0.5567, 0.5619, 0.5615, 0.5290, 0.6079, 0.5520, 0.5706],
       device='cuda:0') torch.Size([16])
percent tensor([0.6017, 0.6195, 0.5948, 0.5900, 0.5865, 0.5946, 0.6104, 0.5824, 0.6141,
        0.6259, 0.6327, 0.6121, 0.6208, 0.6239, 0.5957, 0.6122],
       device='cuda:0') torch.Size([16])
percent tensor([0.5841, 0.6109, 0.4662, 0.5746, 0.5030, 0.6236, 0.5750, 0.4064, 0.6337,
        0.5985, 0.6655, 0.5608, 0.5964, 0.6568, 0.5550, 0.6057],
       device='cuda:0') torch.Size([16])
percent tensor([0.5829, 0.5800, 0.6127, 0.6082, 0.6474, 0.6022, 0.6056, 0.6438, 0.5872,
        0.5858, 0.5520, 0.5637, 0.5329, 0.5837, 0.5959, 0.6092],
       device='cuda:0') torch.Size([16])
percent tensor([0.4953, 0.5617, 0.6900, 0.6423, 0.7255, 0.7532, 0.5405, 0.6293, 0.6009,
        0.5412, 0.6407, 0.5681, 0.5739, 0.5589, 0.5245, 0.4927],
       device='cuda:0') torch.Size([16])
percent tensor([0.9994, 0.9990, 0.9992, 0.9995, 0.9988, 0.9993, 0.9992, 0.9996, 0.9996,
        0.9992, 0.9995, 0.9993, 0.9994, 0.9987, 0.9992, 0.9993],
       device='cuda:0') torch.Size([16])
Epoch: 112 | Batch_idx: 0 |  Loss: (0.1417) |  Loss2: (0.0000) | Acc: (94.00%) (121/128)
Epoch: 112 | Batch_idx: 10 |  Loss: (0.1965) |  Loss2: (0.0000) | Acc: (92.00%) (1307/1408)
Epoch: 112 | Batch_idx: 20 |  Loss: (0.1981) |  Loss2: (0.0000) | Acc: (93.00%) (2500/2688)
Epoch: 112 | Batch_idx: 30 |  Loss: (0.1842) |  Loss2: (0.0000) | Acc: (93.00%) (3715/3968)
Epoch: 112 | Batch_idx: 40 |  Loss: (0.1866) |  Loss2: (0.0000) | Acc: (93.00%) (4916/5248)
Epoch: 112 | Batch_idx: 50 |  Loss: (0.1905) |  Loss2: (0.0000) | Acc: (93.00%) (6097/6528)
Epoch: 112 | Batch_idx: 60 |  Loss: (0.1911) |  Loss2: (0.0000) | Acc: (93.00%) (7287/7808)
Epoch: 112 | Batch_idx: 70 |  Loss: (0.1898) |  Loss2: (0.0000) | Acc: (93.00%) (8486/9088)
Epoch: 112 | Batch_idx: 80 |  Loss: (0.1906) |  Loss2: (0.0000) | Acc: (93.00%) (9688/10368)
Epoch: 112 | Batch_idx: 90 |  Loss: (0.1928) |  Loss2: (0.0000) | Acc: (93.00%) (10881/11648)
Epoch: 112 | Batch_idx: 100 |  Loss: (0.1933) |  Loss2: (0.0000) | Acc: (93.00%) (12074/12928)
Epoch: 112 | Batch_idx: 110 |  Loss: (0.1937) |  Loss2: (0.0000) | Acc: (93.00%) (13263/14208)
Epoch: 112 | Batch_idx: 120 |  Loss: (0.1940) |  Loss2: (0.0000) | Acc: (93.00%) (14461/15488)
Epoch: 112 | Batch_idx: 130 |  Loss: (0.1947) |  Loss2: (0.0000) | Acc: (93.00%) (15656/16768)
Epoch: 112 | Batch_idx: 140 |  Loss: (0.1941) |  Loss2: (0.0000) | Acc: (93.00%) (16858/18048)
Epoch: 112 | Batch_idx: 150 |  Loss: (0.1956) |  Loss2: (0.0000) | Acc: (93.00%) (18046/19328)
Epoch: 112 | Batch_idx: 160 |  Loss: (0.1973) |  Loss2: (0.0000) | Acc: (93.00%) (19224/20608)
Epoch: 112 | Batch_idx: 170 |  Loss: (0.1978) |  Loss2: (0.0000) | Acc: (93.00%) (20414/21888)
Epoch: 112 | Batch_idx: 180 |  Loss: (0.1987) |  Loss2: (0.0000) | Acc: (93.00%) (21597/23168)
Epoch: 112 | Batch_idx: 190 |  Loss: (0.1994) |  Loss2: (0.0000) | Acc: (93.00%) (22769/24448)
Epoch: 112 | Batch_idx: 200 |  Loss: (0.2010) |  Loss2: (0.0000) | Acc: (93.00%) (23948/25728)
Epoch: 112 | Batch_idx: 210 |  Loss: (0.2015) |  Loss2: (0.0000) | Acc: (93.00%) (25128/27008)
Epoch: 112 | Batch_idx: 220 |  Loss: (0.2011) |  Loss2: (0.0000) | Acc: (93.00%) (26321/28288)
Epoch: 112 | Batch_idx: 230 |  Loss: (0.2017) |  Loss2: (0.0000) | Acc: (93.00%) (27503/29568)
Epoch: 112 | Batch_idx: 240 |  Loss: (0.2012) |  Loss2: (0.0000) | Acc: (93.00%) (28705/30848)
Epoch: 112 | Batch_idx: 250 |  Loss: (0.2004) |  Loss2: (0.0000) | Acc: (93.00%) (29902/32128)
Epoch: 112 | Batch_idx: 260 |  Loss: (0.1995) |  Loss2: (0.0000) | Acc: (93.00%) (31106/33408)
Epoch: 112 | Batch_idx: 270 |  Loss: (0.1998) |  Loss2: (0.0000) | Acc: (93.00%) (32290/34688)
Epoch: 112 | Batch_idx: 280 |  Loss: (0.2003) |  Loss2: (0.0000) | Acc: (93.00%) (33468/35968)
Epoch: 112 | Batch_idx: 290 |  Loss: (0.2006) |  Loss2: (0.0000) | Acc: (93.00%) (34652/37248)
Epoch: 112 | Batch_idx: 300 |  Loss: (0.2004) |  Loss2: (0.0000) | Acc: (93.00%) (35844/38528)
Epoch: 112 | Batch_idx: 310 |  Loss: (0.2002) |  Loss2: (0.0000) | Acc: (93.00%) (37041/39808)
Epoch: 112 | Batch_idx: 320 |  Loss: (0.2002) |  Loss2: (0.0000) | Acc: (93.00%) (38229/41088)
Epoch: 112 | Batch_idx: 330 |  Loss: (0.2005) |  Loss2: (0.0000) | Acc: (92.00%) (39401/42368)
Epoch: 112 | Batch_idx: 340 |  Loss: (0.2008) |  Loss2: (0.0000) | Acc: (92.00%) (40589/43648)
Epoch: 112 | Batch_idx: 350 |  Loss: (0.2008) |  Loss2: (0.0000) | Acc: (92.00%) (41775/44928)
Epoch: 112 | Batch_idx: 360 |  Loss: (0.2009) |  Loss2: (0.0000) | Acc: (92.00%) (42957/46208)
Epoch: 112 | Batch_idx: 370 |  Loss: (0.2009) |  Loss2: (0.0000) | Acc: (92.00%) (44148/47488)
Epoch: 112 | Batch_idx: 380 |  Loss: (0.2005) |  Loss2: (0.0000) | Acc: (92.00%) (45346/48768)
Epoch: 112 | Batch_idx: 390 |  Loss: (0.2003) |  Loss2: (0.0000) | Acc: (92.00%) (46495/50000)
# TEST : Loss: (0.4659) | Acc: (85.00%) (8558/10000)
percent tensor([0.5200, 0.5093, 0.5155, 0.5105, 0.5200, 0.5279, 0.5154, 0.5115, 0.5215,
        0.5117, 0.5222, 0.5143, 0.5115, 0.5177, 0.5159, 0.5170],
       device='cuda:0') torch.Size([16])
percent tensor([0.5151, 0.5108, 0.5179, 0.5177, 0.5155, 0.5113, 0.5126, 0.5195, 0.5199,
        0.5148, 0.5182, 0.5134, 0.5114, 0.5202, 0.5104, 0.5164],
       device='cuda:0') torch.Size([16])
percent tensor([0.5699, 0.5495, 0.5707, 0.5789, 0.5851, 0.5652, 0.5701, 0.5797, 0.5737,
        0.5609, 0.5653, 0.5637, 0.5286, 0.6053, 0.5548, 0.5754],
       device='cuda:0') torch.Size([16])
percent tensor([0.5965, 0.6167, 0.5938, 0.5917, 0.5852, 0.5942, 0.6072, 0.5789, 0.6126,
        0.6241, 0.6297, 0.6111, 0.6138, 0.6247, 0.5945, 0.6067],
       device='cuda:0') torch.Size([16])
percent tensor([0.5506, 0.6103, 0.4528, 0.5616, 0.4680, 0.6064, 0.5458, 0.3768, 0.6365,
        0.6061, 0.6694, 0.5424, 0.5911, 0.6454, 0.5372, 0.5776],
       device='cuda:0') torch.Size([16])
percent tensor([0.6002, 0.5953, 0.6194, 0.6145, 0.6519, 0.6115, 0.6139, 0.6505, 0.5951,
        0.5998, 0.5748, 0.5775, 0.5495, 0.5869, 0.6066, 0.6198],
       device='cuda:0') torch.Size([16])
percent tensor([0.5262, 0.6047, 0.7088, 0.6443, 0.7364, 0.7498, 0.5602, 0.6565, 0.6472,
        0.5699, 0.6474, 0.5882, 0.6101, 0.6121, 0.5325, 0.5047],
       device='cuda:0') torch.Size([16])
percent tensor([0.9994, 0.9990, 0.9993, 0.9991, 0.9990, 0.9987, 0.9991, 0.9997, 0.9994,
        0.9994, 0.9997, 0.9996, 0.9996, 0.9988, 0.9994, 0.9995],
       device='cuda:0') torch.Size([16])
Epoch: 113 | Batch_idx: 0 |  Loss: (0.0823) |  Loss2: (0.0000) | Acc: (98.00%) (126/128)
Epoch: 113 | Batch_idx: 10 |  Loss: (0.1791) |  Loss2: (0.0000) | Acc: (94.00%) (1327/1408)
Epoch: 113 | Batch_idx: 20 |  Loss: (0.1836) |  Loss2: (0.0000) | Acc: (93.00%) (2516/2688)
Epoch: 113 | Batch_idx: 30 |  Loss: (0.1779) |  Loss2: (0.0000) | Acc: (93.00%) (3728/3968)
Epoch: 113 | Batch_idx: 40 |  Loss: (0.1854) |  Loss2: (0.0000) | Acc: (93.00%) (4918/5248)
Epoch: 113 | Batch_idx: 50 |  Loss: (0.1862) |  Loss2: (0.0000) | Acc: (93.00%) (6113/6528)
Epoch: 113 | Batch_idx: 60 |  Loss: (0.1840) |  Loss2: (0.0000) | Acc: (93.00%) (7314/7808)
Epoch: 113 | Batch_idx: 70 |  Loss: (0.1846) |  Loss2: (0.0000) | Acc: (93.00%) (8510/9088)
Epoch: 113 | Batch_idx: 80 |  Loss: (0.1844) |  Loss2: (0.0000) | Acc: (93.00%) (9708/10368)
Epoch: 113 | Batch_idx: 90 |  Loss: (0.1860) |  Loss2: (0.0000) | Acc: (93.00%) (10899/11648)
Epoch: 113 | Batch_idx: 100 |  Loss: (0.1875) |  Loss2: (0.0000) | Acc: (93.00%) (12089/12928)
Epoch: 113 | Batch_idx: 110 |  Loss: (0.1894) |  Loss2: (0.0000) | Acc: (93.00%) (13280/14208)
Epoch: 113 | Batch_idx: 120 |  Loss: (0.1906) |  Loss2: (0.0000) | Acc: (93.00%) (14471/15488)
Epoch: 113 | Batch_idx: 130 |  Loss: (0.1910) |  Loss2: (0.0000) | Acc: (93.00%) (15663/16768)
Epoch: 113 | Batch_idx: 140 |  Loss: (0.1917) |  Loss2: (0.0000) | Acc: (93.00%) (16851/18048)
Epoch: 113 | Batch_idx: 150 |  Loss: (0.1928) |  Loss2: (0.0000) | Acc: (93.00%) (18038/19328)
Epoch: 113 | Batch_idx: 160 |  Loss: (0.1927) |  Loss2: (0.0000) | Acc: (93.00%) (19229/20608)
Epoch: 113 | Batch_idx: 170 |  Loss: (0.1928) |  Loss2: (0.0000) | Acc: (93.00%) (20423/21888)
Epoch: 113 | Batch_idx: 180 |  Loss: (0.1918) |  Loss2: (0.0000) | Acc: (93.00%) (21628/23168)
Epoch: 113 | Batch_idx: 190 |  Loss: (0.1935) |  Loss2: (0.0000) | Acc: (93.00%) (22808/24448)
Epoch: 113 | Batch_idx: 200 |  Loss: (0.1943) |  Loss2: (0.0000) | Acc: (93.00%) (23990/25728)
Epoch: 113 | Batch_idx: 210 |  Loss: (0.1943) |  Loss2: (0.0000) | Acc: (93.00%) (25180/27008)
Epoch: 113 | Batch_idx: 220 |  Loss: (0.1935) |  Loss2: (0.0000) | Acc: (93.00%) (26388/28288)
Epoch: 113 | Batch_idx: 230 |  Loss: (0.1932) |  Loss2: (0.0000) | Acc: (93.00%) (27587/29568)
Epoch: 113 | Batch_idx: 240 |  Loss: (0.1934) |  Loss2: (0.0000) | Acc: (93.00%) (28775/30848)
Epoch: 113 | Batch_idx: 250 |  Loss: (0.1947) |  Loss2: (0.0000) | Acc: (93.00%) (29956/32128)
Epoch: 113 | Batch_idx: 260 |  Loss: (0.1948) |  Loss2: (0.0000) | Acc: (93.00%) (31150/33408)
Epoch: 113 | Batch_idx: 270 |  Loss: (0.1957) |  Loss2: (0.0000) | Acc: (93.00%) (32335/34688)
Epoch: 113 | Batch_idx: 280 |  Loss: (0.1955) |  Loss2: (0.0000) | Acc: (93.00%) (33527/35968)
Epoch: 113 | Batch_idx: 290 |  Loss: (0.1958) |  Loss2: (0.0000) | Acc: (93.00%) (34711/37248)
Epoch: 113 | Batch_idx: 300 |  Loss: (0.1969) |  Loss2: (0.0000) | Acc: (93.00%) (35880/38528)
Epoch: 113 | Batch_idx: 310 |  Loss: (0.1974) |  Loss2: (0.0000) | Acc: (93.00%) (37062/39808)
Epoch: 113 | Batch_idx: 320 |  Loss: (0.1973) |  Loss2: (0.0000) | Acc: (93.00%) (38262/41088)
Epoch: 113 | Batch_idx: 330 |  Loss: (0.1966) |  Loss2: (0.0000) | Acc: (93.00%) (39464/42368)
Epoch: 113 | Batch_idx: 340 |  Loss: (0.1965) |  Loss2: (0.0000) | Acc: (93.00%) (40658/43648)
Epoch: 113 | Batch_idx: 350 |  Loss: (0.1964) |  Loss2: (0.0000) | Acc: (93.00%) (41854/44928)
Epoch: 113 | Batch_idx: 360 |  Loss: (0.1970) |  Loss2: (0.0000) | Acc: (93.00%) (43038/46208)
Epoch: 113 | Batch_idx: 370 |  Loss: (0.1974) |  Loss2: (0.0000) | Acc: (93.00%) (44222/47488)
Epoch: 113 | Batch_idx: 380 |  Loss: (0.1978) |  Loss2: (0.0000) | Acc: (93.00%) (45409/48768)
Epoch: 113 | Batch_idx: 390 |  Loss: (0.1988) |  Loss2: (0.0000) | Acc: (93.00%) (46549/50000)
# TEST : Loss: (0.4033) | Acc: (87.00%) (8720/10000)
percent tensor([0.5208, 0.5093, 0.5142, 0.5084, 0.5184, 0.5270, 0.5146, 0.5113, 0.5222,
        0.5112, 0.5234, 0.5132, 0.5126, 0.5162, 0.5155, 0.5166],
       device='cuda:0') torch.Size([16])
percent tensor([0.5154, 0.5103, 0.5171, 0.5161, 0.5154, 0.5115, 0.5125, 0.5198, 0.5200,
        0.5146, 0.5185, 0.5136, 0.5122, 0.5187, 0.5102, 0.5161],
       device='cuda:0') torch.Size([16])
percent tensor([0.5664, 0.5432, 0.5600, 0.5757, 0.5749, 0.5618, 0.5635, 0.5747, 0.5692,
        0.5549, 0.5637, 0.5598, 0.5289, 0.5953, 0.5510, 0.5705],
       device='cuda:0') torch.Size([16])
percent tensor([0.5995, 0.6203, 0.5904, 0.5831, 0.5824, 0.5959, 0.6113, 0.5797, 0.6132,
        0.6263, 0.6300, 0.6109, 0.6168, 0.6309, 0.5943, 0.6096],
       device='cuda:0') torch.Size([16])
percent tensor([0.5714, 0.6211, 0.4728, 0.5596, 0.4817, 0.5949, 0.5737, 0.3875, 0.6335,
        0.6126, 0.6707, 0.5501, 0.6074, 0.6582, 0.5458, 0.5874],
       device='cuda:0') torch.Size([16])
percent tensor([0.5994, 0.5883, 0.6024, 0.6089, 0.6462, 0.6117, 0.6068, 0.6501, 0.5989,
        0.5914, 0.5716, 0.5655, 0.5604, 0.5878, 0.5999, 0.6205],
       device='cuda:0') torch.Size([16])
percent tensor([0.4968, 0.6002, 0.6868, 0.6284, 0.7206, 0.7328, 0.5437, 0.6428, 0.6365,
        0.5612, 0.6422, 0.5627, 0.6035, 0.6387, 0.5229, 0.5072],
       device='cuda:0') torch.Size([16])
percent tensor([0.9993, 0.9987, 0.9996, 0.9995, 0.9991, 0.9982, 0.9991, 0.9997, 0.9996,
        0.9991, 0.9996, 0.9996, 0.9995, 0.9980, 0.9994, 0.9990],
       device='cuda:0') torch.Size([16])
Epoch: 114 | Batch_idx: 0 |  Loss: (0.2102) |  Loss2: (0.0000) | Acc: (91.00%) (117/128)
Epoch: 114 | Batch_idx: 10 |  Loss: (0.1691) |  Loss2: (0.0000) | Acc: (93.00%) (1323/1408)
Epoch: 114 | Batch_idx: 20 |  Loss: (0.1759) |  Loss2: (0.0000) | Acc: (93.00%) (2526/2688)
Epoch: 114 | Batch_idx: 30 |  Loss: (0.1803) |  Loss2: (0.0000) | Acc: (93.00%) (3720/3968)
Epoch: 114 | Batch_idx: 40 |  Loss: (0.1734) |  Loss2: (0.0000) | Acc: (94.00%) (4936/5248)
Epoch: 114 | Batch_idx: 50 |  Loss: (0.1737) |  Loss2: (0.0000) | Acc: (94.00%) (6138/6528)
Epoch: 114 | Batch_idx: 60 |  Loss: (0.1751) |  Loss2: (0.0000) | Acc: (93.00%) (7337/7808)
Epoch: 114 | Batch_idx: 70 |  Loss: (0.1796) |  Loss2: (0.0000) | Acc: (93.00%) (8521/9088)
Epoch: 114 | Batch_idx: 80 |  Loss: (0.1833) |  Loss2: (0.0000) | Acc: (93.00%) (9707/10368)
Epoch: 114 | Batch_idx: 90 |  Loss: (0.1843) |  Loss2: (0.0000) | Acc: (93.00%) (10897/11648)
Epoch: 114 | Batch_idx: 100 |  Loss: (0.1878) |  Loss2: (0.0000) | Acc: (93.00%) (12093/12928)
Epoch: 114 | Batch_idx: 110 |  Loss: (0.1877) |  Loss2: (0.0000) | Acc: (93.00%) (13297/14208)
Epoch: 114 | Batch_idx: 120 |  Loss: (0.1897) |  Loss2: (0.0000) | Acc: (93.00%) (14478/15488)
Epoch: 114 | Batch_idx: 130 |  Loss: (0.1891) |  Loss2: (0.0000) | Acc: (93.00%) (15675/16768)
Epoch: 114 | Batch_idx: 140 |  Loss: (0.1903) |  Loss2: (0.0000) | Acc: (93.00%) (16866/18048)
Epoch: 114 | Batch_idx: 150 |  Loss: (0.1904) |  Loss2: (0.0000) | Acc: (93.00%) (18070/19328)
Epoch: 114 | Batch_idx: 160 |  Loss: (0.1899) |  Loss2: (0.0000) | Acc: (93.00%) (19271/20608)
Epoch: 114 | Batch_idx: 170 |  Loss: (0.1897) |  Loss2: (0.0000) | Acc: (93.00%) (20471/21888)
Epoch: 114 | Batch_idx: 180 |  Loss: (0.1921) |  Loss2: (0.0000) | Acc: (93.00%) (21648/23168)
Epoch: 114 | Batch_idx: 190 |  Loss: (0.1927) |  Loss2: (0.0000) | Acc: (93.00%) (22840/24448)
Epoch: 114 | Batch_idx: 200 |  Loss: (0.1928) |  Loss2: (0.0000) | Acc: (93.00%) (24028/25728)
Epoch: 114 | Batch_idx: 210 |  Loss: (0.1928) |  Loss2: (0.0000) | Acc: (93.00%) (25214/27008)
Epoch: 114 | Batch_idx: 220 |  Loss: (0.1929) |  Loss2: (0.0000) | Acc: (93.00%) (26416/28288)
Epoch: 114 | Batch_idx: 230 |  Loss: (0.1928) |  Loss2: (0.0000) | Acc: (93.00%) (27615/29568)
Epoch: 114 | Batch_idx: 240 |  Loss: (0.1926) |  Loss2: (0.0000) | Acc: (93.00%) (28814/30848)
Epoch: 114 | Batch_idx: 250 |  Loss: (0.1926) |  Loss2: (0.0000) | Acc: (93.00%) (29998/32128)
Epoch: 114 | Batch_idx: 260 |  Loss: (0.1926) |  Loss2: (0.0000) | Acc: (93.00%) (31200/33408)
Epoch: 114 | Batch_idx: 270 |  Loss: (0.1923) |  Loss2: (0.0000) | Acc: (93.00%) (32400/34688)
Epoch: 114 | Batch_idx: 280 |  Loss: (0.1922) |  Loss2: (0.0000) | Acc: (93.00%) (33604/35968)
Epoch: 114 | Batch_idx: 290 |  Loss: (0.1924) |  Loss2: (0.0000) | Acc: (93.00%) (34793/37248)
Epoch: 114 | Batch_idx: 300 |  Loss: (0.1933) |  Loss2: (0.0000) | Acc: (93.00%) (35972/38528)
Epoch: 114 | Batch_idx: 310 |  Loss: (0.1929) |  Loss2: (0.0000) | Acc: (93.00%) (37172/39808)
Epoch: 114 | Batch_idx: 320 |  Loss: (0.1927) |  Loss2: (0.0000) | Acc: (93.00%) (38370/41088)
Epoch: 114 | Batch_idx: 330 |  Loss: (0.1922) |  Loss2: (0.0000) | Acc: (93.00%) (39579/42368)
Epoch: 114 | Batch_idx: 340 |  Loss: (0.1925) |  Loss2: (0.0000) | Acc: (93.00%) (40765/43648)
Epoch: 114 | Batch_idx: 350 |  Loss: (0.1928) |  Loss2: (0.0000) | Acc: (93.00%) (41956/44928)
Epoch: 114 | Batch_idx: 360 |  Loss: (0.1934) |  Loss2: (0.0000) | Acc: (93.00%) (43142/46208)
Epoch: 114 | Batch_idx: 370 |  Loss: (0.1934) |  Loss2: (0.0000) | Acc: (93.00%) (44349/47488)
Epoch: 114 | Batch_idx: 380 |  Loss: (0.1936) |  Loss2: (0.0000) | Acc: (93.00%) (45544/48768)
Epoch: 114 | Batch_idx: 390 |  Loss: (0.1933) |  Loss2: (0.0000) | Acc: (93.00%) (46700/50000)
# TEST : Loss: (0.4323) | Acc: (86.00%) (8654/10000)
percent tensor([0.5207, 0.5092, 0.5144, 0.5109, 0.5192, 0.5269, 0.5152, 0.5119, 0.5220,
        0.5117, 0.5228, 0.5134, 0.5125, 0.5176, 0.5160, 0.5170],
       device='cuda:0') torch.Size([16])
percent tensor([0.5169, 0.5104, 0.5194, 0.5170, 0.5164, 0.5114, 0.5137, 0.5201, 0.5217,
        0.5154, 0.5191, 0.5150, 0.5129, 0.5192, 0.5098, 0.5164],
       device='cuda:0') torch.Size([16])
percent tensor([0.5676, 0.5465, 0.5701, 0.5842, 0.5836, 0.5651, 0.5686, 0.5811, 0.5744,
        0.5556, 0.5657, 0.5624, 0.5295, 0.6044, 0.5518, 0.5724],
       device='cuda:0') torch.Size([16])
percent tensor([0.6002, 0.6191, 0.5975, 0.5909, 0.5886, 0.5929, 0.6106, 0.5817, 0.6166,
        0.6256, 0.6320, 0.6162, 0.6179, 0.6257, 0.5935, 0.6064],
       device='cuda:0') torch.Size([16])
percent tensor([0.5860, 0.6293, 0.4889, 0.5717, 0.5149, 0.6198, 0.5795, 0.3934, 0.6586,
        0.6221, 0.6767, 0.5769, 0.6214, 0.6546, 0.5490, 0.6032],
       device='cuda:0') torch.Size([16])
percent tensor([0.5974, 0.5902, 0.6109, 0.6069, 0.6524, 0.6062, 0.6175, 0.6467, 0.6010,
        0.5969, 0.5848, 0.5700, 0.5560, 0.5956, 0.5982, 0.6176],
       device='cuda:0') torch.Size([16])
percent tensor([0.5021, 0.5902, 0.6803, 0.5922, 0.7307, 0.7277, 0.5589, 0.6436, 0.6628,
        0.5817, 0.6480, 0.5729, 0.6261, 0.6023, 0.5114, 0.5007],
       device='cuda:0') torch.Size([16])
percent tensor([0.9993, 0.9990, 0.9996, 0.9993, 0.9994, 0.9986, 0.9991, 0.9997, 0.9997,
        0.9988, 0.9997, 0.9997, 0.9997, 0.9983, 0.9992, 0.9990],
       device='cuda:0') torch.Size([16])
Epoch: 115 | Batch_idx: 0 |  Loss: (0.1364) |  Loss2: (0.0000) | Acc: (94.00%) (121/128)
Epoch: 115 | Batch_idx: 10 |  Loss: (0.1949) |  Loss2: (0.0000) | Acc: (91.00%) (1292/1408)
Epoch: 115 | Batch_idx: 20 |  Loss: (0.1846) |  Loss2: (0.0000) | Acc: (92.00%) (2493/2688)
Epoch: 115 | Batch_idx: 30 |  Loss: (0.1797) |  Loss2: (0.0000) | Acc: (93.00%) (3698/3968)
Epoch: 115 | Batch_idx: 40 |  Loss: (0.1887) |  Loss2: (0.0000) | Acc: (92.00%) (4878/5248)
Epoch: 115 | Batch_idx: 50 |  Loss: (0.1847) |  Loss2: (0.0000) | Acc: (93.00%) (6087/6528)
Epoch: 115 | Batch_idx: 60 |  Loss: (0.1844) |  Loss2: (0.0000) | Acc: (93.00%) (7290/7808)
Epoch: 115 | Batch_idx: 70 |  Loss: (0.1827) |  Loss2: (0.0000) | Acc: (93.00%) (8491/9088)
Epoch: 115 | Batch_idx: 80 |  Loss: (0.1838) |  Loss2: (0.0000) | Acc: (93.00%) (9679/10368)
Epoch: 115 | Batch_idx: 90 |  Loss: (0.1841) |  Loss2: (0.0000) | Acc: (93.00%) (10872/11648)
Epoch: 115 | Batch_idx: 100 |  Loss: (0.1871) |  Loss2: (0.0000) | Acc: (93.00%) (12070/12928)
Epoch: 115 | Batch_idx: 110 |  Loss: (0.1858) |  Loss2: (0.0000) | Acc: (93.00%) (13269/14208)
Epoch: 115 | Batch_idx: 120 |  Loss: (0.1848) |  Loss2: (0.0000) | Acc: (93.00%) (14472/15488)
Epoch: 115 | Batch_idx: 130 |  Loss: (0.1868) |  Loss2: (0.0000) | Acc: (93.00%) (15656/16768)
Epoch: 115 | Batch_idx: 140 |  Loss: (0.1892) |  Loss2: (0.0000) | Acc: (93.00%) (16842/18048)
Epoch: 115 | Batch_idx: 150 |  Loss: (0.1899) |  Loss2: (0.0000) | Acc: (93.00%) (18024/19328)
Epoch: 115 | Batch_idx: 160 |  Loss: (0.1884) |  Loss2: (0.0000) | Acc: (93.00%) (19228/20608)
Epoch: 115 | Batch_idx: 170 |  Loss: (0.1905) |  Loss2: (0.0000) | Acc: (93.00%) (20409/21888)
Epoch: 115 | Batch_idx: 180 |  Loss: (0.1903) |  Loss2: (0.0000) | Acc: (93.00%) (21603/23168)
Epoch: 115 | Batch_idx: 190 |  Loss: (0.1898) |  Loss2: (0.0000) | Acc: (93.00%) (22801/24448)
Epoch: 115 | Batch_idx: 200 |  Loss: (0.1899) |  Loss2: (0.0000) | Acc: (93.00%) (23995/25728)
Epoch: 115 | Batch_idx: 210 |  Loss: (0.1904) |  Loss2: (0.0000) | Acc: (93.00%) (25188/27008)
Epoch: 115 | Batch_idx: 220 |  Loss: (0.1907) |  Loss2: (0.0000) | Acc: (93.00%) (26386/28288)
Epoch: 115 | Batch_idx: 230 |  Loss: (0.1900) |  Loss2: (0.0000) | Acc: (93.00%) (27583/29568)
Epoch: 115 | Batch_idx: 240 |  Loss: (0.1905) |  Loss2: (0.0000) | Acc: (93.00%) (28776/30848)
Epoch: 115 | Batch_idx: 250 |  Loss: (0.1905) |  Loss2: (0.0000) | Acc: (93.00%) (29968/32128)
Epoch: 115 | Batch_idx: 260 |  Loss: (0.1900) |  Loss2: (0.0000) | Acc: (93.00%) (31175/33408)
Epoch: 115 | Batch_idx: 270 |  Loss: (0.1892) |  Loss2: (0.0000) | Acc: (93.00%) (32377/34688)
Epoch: 115 | Batch_idx: 280 |  Loss: (0.1900) |  Loss2: (0.0000) | Acc: (93.00%) (33564/35968)
Epoch: 115 | Batch_idx: 290 |  Loss: (0.1896) |  Loss2: (0.0000) | Acc: (93.00%) (34765/37248)
Epoch: 115 | Batch_idx: 300 |  Loss: (0.1896) |  Loss2: (0.0000) | Acc: (93.00%) (35957/38528)
Epoch: 115 | Batch_idx: 310 |  Loss: (0.1892) |  Loss2: (0.0000) | Acc: (93.00%) (37158/39808)
Epoch: 115 | Batch_idx: 320 |  Loss: (0.1884) |  Loss2: (0.0000) | Acc: (93.00%) (38363/41088)
Epoch: 115 | Batch_idx: 330 |  Loss: (0.1881) |  Loss2: (0.0000) | Acc: (93.00%) (39577/42368)
Epoch: 115 | Batch_idx: 340 |  Loss: (0.1885) |  Loss2: (0.0000) | Acc: (93.00%) (40766/43648)
Epoch: 115 | Batch_idx: 350 |  Loss: (0.1882) |  Loss2: (0.0000) | Acc: (93.00%) (41964/44928)
Epoch: 115 | Batch_idx: 360 |  Loss: (0.1885) |  Loss2: (0.0000) | Acc: (93.00%) (43158/46208)
Epoch: 115 | Batch_idx: 370 |  Loss: (0.1878) |  Loss2: (0.0000) | Acc: (93.00%) (44368/47488)
Epoch: 115 | Batch_idx: 380 |  Loss: (0.1881) |  Loss2: (0.0000) | Acc: (93.00%) (45558/48768)
Epoch: 115 | Batch_idx: 390 |  Loss: (0.1881) |  Loss2: (0.0000) | Acc: (93.00%) (46706/50000)
=> saving checkpoint 'drive/app/torch/save_Schedule/checkpoint_115.pth.tar'
# TEST : Loss: (0.4513) | Acc: (86.00%) (8628/10000)
percent tensor([0.5205, 0.5086, 0.5145, 0.5092, 0.5191, 0.5259, 0.5145, 0.5109, 0.5221,
        0.5112, 0.5229, 0.5132, 0.5121, 0.5161, 0.5151, 0.5159],
       device='cuda:0') torch.Size([16])
percent tensor([0.5154, 0.5108, 0.5179, 0.5166, 0.5156, 0.5116, 0.5132, 0.5198, 0.5212,
        0.5150, 0.5189, 0.5136, 0.5117, 0.5209, 0.5100, 0.5163],
       device='cuda:0') torch.Size([16])
percent tensor([0.5687, 0.5456, 0.5693, 0.5824, 0.5795, 0.5631, 0.5662, 0.5811, 0.5701,
        0.5594, 0.5627, 0.5611, 0.5277, 0.6011, 0.5515, 0.5723],
       device='cuda:0') torch.Size([16])
percent tensor([0.5993, 0.6202, 0.5940, 0.5867, 0.5841, 0.5942, 0.6116, 0.5789, 0.6143,
        0.6279, 0.6306, 0.6130, 0.6169, 0.6277, 0.5945, 0.6092],
       device='cuda:0') torch.Size([16])
percent tensor([0.5710, 0.6329, 0.4575, 0.5577, 0.4817, 0.5991, 0.5874, 0.3841, 0.6409,
        0.6247, 0.6701, 0.5540, 0.6050, 0.6667, 0.5513, 0.5965],
       device='cuda:0') torch.Size([16])
percent tensor([0.5996, 0.5878, 0.6126, 0.6062, 0.6535, 0.6103, 0.6136, 0.6493, 0.5979,
        0.5941, 0.5737, 0.5684, 0.5530, 0.5869, 0.5992, 0.6166],
       device='cuda:0') torch.Size([16])
percent tensor([0.5035, 0.5830, 0.6974, 0.6309, 0.7311, 0.7229, 0.5560, 0.6401, 0.6304,
        0.5571, 0.6550, 0.5580, 0.6053, 0.5922, 0.5214, 0.5104],
       device='cuda:0') torch.Size([16])
percent tensor([0.9993, 0.9989, 0.9996, 0.9992, 0.9989, 0.9982, 0.9990, 0.9997, 0.9994,
        0.9990, 0.9997, 0.9996, 0.9993, 0.9980, 0.9992, 0.9989],
       device='cuda:0') torch.Size([16])
Epoch: 116 | Batch_idx: 0 |  Loss: (0.2092) |  Loss2: (0.0000) | Acc: (93.00%) (120/128)
Epoch: 116 | Batch_idx: 10 |  Loss: (0.1971) |  Loss2: (0.0000) | Acc: (93.00%) (1321/1408)
Epoch: 116 | Batch_idx: 20 |  Loss: (0.1990) |  Loss2: (0.0000) | Acc: (93.00%) (2504/2688)
Epoch: 116 | Batch_idx: 30 |  Loss: (0.2013) |  Loss2: (0.0000) | Acc: (93.00%) (3696/3968)
Epoch: 116 | Batch_idx: 40 |  Loss: (0.1945) |  Loss2: (0.0000) | Acc: (93.00%) (4909/5248)
Epoch: 116 | Batch_idx: 50 |  Loss: (0.1906) |  Loss2: (0.0000) | Acc: (93.00%) (6112/6528)
Epoch: 116 | Batch_idx: 60 |  Loss: (0.1911) |  Loss2: (0.0000) | Acc: (93.00%) (7303/7808)
Epoch: 116 | Batch_idx: 70 |  Loss: (0.1894) |  Loss2: (0.0000) | Acc: (93.00%) (8515/9088)
Epoch: 116 | Batch_idx: 80 |  Loss: (0.1870) |  Loss2: (0.0000) | Acc: (93.00%) (9722/10368)
Epoch: 116 | Batch_idx: 90 |  Loss: (0.1857) |  Loss2: (0.0000) | Acc: (93.00%) (10914/11648)
Epoch: 116 | Batch_idx: 100 |  Loss: (0.1835) |  Loss2: (0.0000) | Acc: (93.00%) (12124/12928)
Epoch: 116 | Batch_idx: 110 |  Loss: (0.1837) |  Loss2: (0.0000) | Acc: (93.00%) (13332/14208)
Epoch: 116 | Batch_idx: 120 |  Loss: (0.1822) |  Loss2: (0.0000) | Acc: (93.00%) (14540/15488)
Epoch: 116 | Batch_idx: 130 |  Loss: (0.1829) |  Loss2: (0.0000) | Acc: (93.00%) (15734/16768)
Epoch: 116 | Batch_idx: 140 |  Loss: (0.1822) |  Loss2: (0.0000) | Acc: (93.00%) (16936/18048)
Epoch: 116 | Batch_idx: 150 |  Loss: (0.1819) |  Loss2: (0.0000) | Acc: (93.00%) (18132/19328)
Epoch: 116 | Batch_idx: 160 |  Loss: (0.1822) |  Loss2: (0.0000) | Acc: (93.00%) (19321/20608)
Epoch: 116 | Batch_idx: 170 |  Loss: (0.1833) |  Loss2: (0.0000) | Acc: (93.00%) (20508/21888)
Epoch: 116 | Batch_idx: 180 |  Loss: (0.1831) |  Loss2: (0.0000) | Acc: (93.00%) (21705/23168)
Epoch: 116 | Batch_idx: 190 |  Loss: (0.1831) |  Loss2: (0.0000) | Acc: (93.00%) (22912/24448)
Epoch: 116 | Batch_idx: 200 |  Loss: (0.1843) |  Loss2: (0.0000) | Acc: (93.00%) (24103/25728)
Epoch: 116 | Batch_idx: 210 |  Loss: (0.1837) |  Loss2: (0.0000) | Acc: (93.00%) (25313/27008)
Epoch: 116 | Batch_idx: 220 |  Loss: (0.1848) |  Loss2: (0.0000) | Acc: (93.00%) (26503/28288)
Epoch: 116 | Batch_idx: 230 |  Loss: (0.1847) |  Loss2: (0.0000) | Acc: (93.00%) (27700/29568)
Epoch: 116 | Batch_idx: 240 |  Loss: (0.1857) |  Loss2: (0.0000) | Acc: (93.00%) (28889/30848)
Epoch: 116 | Batch_idx: 250 |  Loss: (0.1854) |  Loss2: (0.0000) | Acc: (93.00%) (30089/32128)
Epoch: 116 | Batch_idx: 260 |  Loss: (0.1855) |  Loss2: (0.0000) | Acc: (93.00%) (31278/33408)
Epoch: 116 | Batch_idx: 270 |  Loss: (0.1847) |  Loss2: (0.0000) | Acc: (93.00%) (32492/34688)
Epoch: 116 | Batch_idx: 280 |  Loss: (0.1849) |  Loss2: (0.0000) | Acc: (93.00%) (33687/35968)
Epoch: 116 | Batch_idx: 290 |  Loss: (0.1846) |  Loss2: (0.0000) | Acc: (93.00%) (34889/37248)
Epoch: 116 | Batch_idx: 300 |  Loss: (0.1846) |  Loss2: (0.0000) | Acc: (93.00%) (36080/38528)
Epoch: 116 | Batch_idx: 310 |  Loss: (0.1851) |  Loss2: (0.0000) | Acc: (93.00%) (37266/39808)
Epoch: 116 | Batch_idx: 320 |  Loss: (0.1854) |  Loss2: (0.0000) | Acc: (93.00%) (38457/41088)
Epoch: 116 | Batch_idx: 330 |  Loss: (0.1865) |  Loss2: (0.0000) | Acc: (93.00%) (39634/42368)
Epoch: 116 | Batch_idx: 340 |  Loss: (0.1868) |  Loss2: (0.0000) | Acc: (93.00%) (40832/43648)
Epoch: 116 | Batch_idx: 350 |  Loss: (0.1875) |  Loss2: (0.0000) | Acc: (93.00%) (42013/44928)
Epoch: 116 | Batch_idx: 360 |  Loss: (0.1879) |  Loss2: (0.0000) | Acc: (93.00%) (43197/46208)
Epoch: 116 | Batch_idx: 370 |  Loss: (0.1881) |  Loss2: (0.0000) | Acc: (93.00%) (44389/47488)
Epoch: 116 | Batch_idx: 380 |  Loss: (0.1883) |  Loss2: (0.0000) | Acc: (93.00%) (45582/48768)
Epoch: 116 | Batch_idx: 390 |  Loss: (0.1884) |  Loss2: (0.0000) | Acc: (93.00%) (46738/50000)
# TEST : Loss: (0.4683) | Acc: (85.00%) (8562/10000)
percent tensor([0.5199, 0.5092, 0.5129, 0.5101, 0.5173, 0.5264, 0.5138, 0.5114, 0.5212,
        0.5109, 0.5228, 0.5114, 0.5119, 0.5165, 0.5156, 0.5172],
       device='cuda:0') torch.Size([16])
percent tensor([0.5155, 0.5099, 0.5184, 0.5166, 0.5161, 0.5127, 0.5131, 0.5188, 0.5201,
        0.5144, 0.5188, 0.5144, 0.5119, 0.5185, 0.5103, 0.5157],
       device='cuda:0') torch.Size([16])
percent tensor([0.5688, 0.5438, 0.5736, 0.5817, 0.5844, 0.5649, 0.5661, 0.5789, 0.5704,
        0.5543, 0.5600, 0.5684, 0.5274, 0.5934, 0.5511, 0.5682],
       device='cuda:0') torch.Size([16])
percent tensor([0.5958, 0.6129, 0.5988, 0.5889, 0.5880, 0.5922, 0.6058, 0.5814, 0.6115,
        0.6222, 0.6265, 0.6162, 0.6128, 0.6211, 0.5898, 0.6046],
       device='cuda:0') torch.Size([16])
percent tensor([0.5619, 0.6083, 0.4866, 0.5677, 0.5068, 0.6085, 0.5662, 0.3989, 0.6335,
        0.5923, 0.6550, 0.5793, 0.5930, 0.6483, 0.5296, 0.5725],
       device='cuda:0') torch.Size([16])
percent tensor([0.5957, 0.5902, 0.6261, 0.6147, 0.6559, 0.6149, 0.6178, 0.6497, 0.5963,
        0.5918, 0.5684, 0.5735, 0.5477, 0.5823, 0.5987, 0.6164],
       device='cuda:0') torch.Size([16])
percent tensor([0.5258, 0.5799, 0.6980, 0.5992, 0.7253, 0.7293, 0.5655, 0.6426, 0.6191,
        0.5640, 0.6776, 0.5490, 0.5855, 0.6114, 0.5204, 0.5013],
       device='cuda:0') torch.Size([16])
percent tensor([0.9993, 0.9991, 0.9996, 0.9993, 0.9993, 0.9985, 0.9987, 0.9997, 0.9997,
        0.9991, 0.9997, 0.9995, 0.9994, 0.9985, 0.9993, 0.9992],
       device='cuda:0') torch.Size([16])
False Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=128, out_features=16, bias=False)
True Linear(in_features=16, out_features=2, bias=False)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=128, out_features=16, bias=False)
True Linear(in_features=16, out_features=2, bias=False)
False Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=256, out_features=32, bias=False)
True Linear(in_features=32, out_features=2, bias=False)
False Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=256, out_features=32, bias=False)
True Linear(in_features=32, out_features=2, bias=False)
False Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=512, out_features=64, bias=False)
True Linear(in_features=64, out_features=2, bias=False)
False Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=512, out_features=64, bias=False)
True Linear(in_features=64, out_features=2, bias=False)
False Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1024, out_features=128, bias=False)
True Linear(in_features=128, out_features=2, bias=False)
False Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1024, out_features=128, bias=False)
True Linear(in_features=128, out_features=2, bias=False)
False Linear(in_features=512, out_features=10, bias=True)
Epoch: 117 | Batch_idx: 0 |  Loss: (0.1211) |  Loss2: (0.0000) | Acc: (96.00%) (124/128)
Epoch: 117 | Batch_idx: 10 |  Loss: (0.1858) |  Loss2: (0.0000) | Acc: (94.00%) (1324/1408)
Epoch: 117 | Batch_idx: 20 |  Loss: (0.2052) |  Loss2: (0.0000) | Acc: (93.00%) (2507/2688)
Epoch: 117 | Batch_idx: 30 |  Loss: (0.2082) |  Loss2: (0.0000) | Acc: (92.00%) (3687/3968)
Epoch: 117 | Batch_idx: 40 |  Loss: (0.2175) |  Loss2: (0.0000) | Acc: (92.00%) (4852/5248)
Epoch: 117 | Batch_idx: 50 |  Loss: (0.2257) |  Loss2: (0.0000) | Acc: (92.00%) (6016/6528)
Epoch: 117 | Batch_idx: 60 |  Loss: (0.2279) |  Loss2: (0.0000) | Acc: (92.00%) (7187/7808)
Epoch: 117 | Batch_idx: 70 |  Loss: (0.2291) |  Loss2: (0.0000) | Acc: (92.00%) (8367/9088)
Epoch: 117 | Batch_idx: 80 |  Loss: (0.2307) |  Loss2: (0.0000) | Acc: (91.00%) (9538/10368)
Epoch: 117 | Batch_idx: 90 |  Loss: (0.2298) |  Loss2: (0.0000) | Acc: (91.00%) (10709/11648)
Epoch: 117 | Batch_idx: 100 |  Loss: (0.2287) |  Loss2: (0.0000) | Acc: (91.00%) (11882/12928)
Epoch: 117 | Batch_idx: 110 |  Loss: (0.2276) |  Loss2: (0.0000) | Acc: (91.00%) (13051/14208)
Epoch: 117 | Batch_idx: 120 |  Loss: (0.2275) |  Loss2: (0.0000) | Acc: (91.00%) (14226/15488)
Epoch: 117 | Batch_idx: 130 |  Loss: (0.2267) |  Loss2: (0.0000) | Acc: (91.00%) (15410/16768)
Epoch: 117 | Batch_idx: 140 |  Loss: (0.2266) |  Loss2: (0.0000) | Acc: (91.00%) (16578/18048)
Epoch: 117 | Batch_idx: 150 |  Loss: (0.2246) |  Loss2: (0.0000) | Acc: (91.00%) (17780/19328)
Epoch: 117 | Batch_idx: 160 |  Loss: (0.2243) |  Loss2: (0.0000) | Acc: (91.00%) (18948/20608)
Epoch: 117 | Batch_idx: 170 |  Loss: (0.2240) |  Loss2: (0.0000) | Acc: (91.00%) (20124/21888)
Epoch: 117 | Batch_idx: 180 |  Loss: (0.2248) |  Loss2: (0.0000) | Acc: (91.00%) (21288/23168)
Epoch: 117 | Batch_idx: 190 |  Loss: (0.2235) |  Loss2: (0.0000) | Acc: (91.00%) (22473/24448)
Epoch: 117 | Batch_idx: 200 |  Loss: (0.2221) |  Loss2: (0.0000) | Acc: (91.00%) (23667/25728)
Epoch: 117 | Batch_idx: 210 |  Loss: (0.2215) |  Loss2: (0.0000) | Acc: (92.00%) (24848/27008)
Epoch: 117 | Batch_idx: 220 |  Loss: (0.2212) |  Loss2: (0.0000) | Acc: (92.00%) (26034/28288)
Epoch: 117 | Batch_idx: 230 |  Loss: (0.2202) |  Loss2: (0.0000) | Acc: (92.00%) (27229/29568)
Epoch: 117 | Batch_idx: 240 |  Loss: (0.2212) |  Loss2: (0.0000) | Acc: (92.00%) (28403/30848)
Epoch: 117 | Batch_idx: 250 |  Loss: (0.2210) |  Loss2: (0.0000) | Acc: (92.00%) (29582/32128)
Epoch: 117 | Batch_idx: 260 |  Loss: (0.2205) |  Loss2: (0.0000) | Acc: (92.00%) (30768/33408)
Epoch: 117 | Batch_idx: 270 |  Loss: (0.2191) |  Loss2: (0.0000) | Acc: (92.00%) (31963/34688)
Epoch: 117 | Batch_idx: 280 |  Loss: (0.2182) |  Loss2: (0.0000) | Acc: (92.00%) (33154/35968)
Epoch: 117 | Batch_idx: 290 |  Loss: (0.2171) |  Loss2: (0.0000) | Acc: (92.00%) (34350/37248)
Epoch: 117 | Batch_idx: 300 |  Loss: (0.2174) |  Loss2: (0.0000) | Acc: (92.00%) (35539/38528)
Epoch: 117 | Batch_idx: 310 |  Loss: (0.2170) |  Loss2: (0.0000) | Acc: (92.00%) (36721/39808)
Epoch: 117 | Batch_idx: 320 |  Loss: (0.2164) |  Loss2: (0.0000) | Acc: (92.00%) (37916/41088)
Epoch: 117 | Batch_idx: 330 |  Loss: (0.2155) |  Loss2: (0.0000) | Acc: (92.00%) (39122/42368)
Epoch: 117 | Batch_idx: 340 |  Loss: (0.2154) |  Loss2: (0.0000) | Acc: (92.00%) (40305/43648)
Epoch: 117 | Batch_idx: 350 |  Loss: (0.2148) |  Loss2: (0.0000) | Acc: (92.00%) (41496/44928)
Epoch: 117 | Batch_idx: 360 |  Loss: (0.2142) |  Loss2: (0.0000) | Acc: (92.00%) (42687/46208)
Epoch: 117 | Batch_idx: 370 |  Loss: (0.2136) |  Loss2: (0.0000) | Acc: (92.00%) (43885/47488)
Epoch: 117 | Batch_idx: 380 |  Loss: (0.2131) |  Loss2: (0.0000) | Acc: (92.00%) (45074/48768)
Epoch: 117 | Batch_idx: 390 |  Loss: (0.2126) |  Loss2: (0.0000) | Acc: (92.00%) (46224/50000)
# TEST : Loss: (0.4009) | Acc: (87.00%) (8719/10000)
percent tensor([0.5251, 0.5155, 0.5203, 0.5165, 0.5251, 0.5302, 0.5207, 0.5188, 0.5270,
        0.5178, 0.5286, 0.5188, 0.5180, 0.5215, 0.5215, 0.5225],
       device='cuda:0') torch.Size([16])
percent tensor([0.5063, 0.5005, 0.5107, 0.5081, 0.5069, 0.5040, 0.5038, 0.5094, 0.5110,
        0.5051, 0.5089, 0.5062, 0.5027, 0.5100, 0.5006, 0.5063],
       device='cuda:0') torch.Size([16])
percent tensor([0.5720, 0.5578, 0.5706, 0.5771, 0.5817, 0.5646, 0.5742, 0.5746, 0.5745,
        0.5656, 0.5695, 0.5721, 0.5385, 0.6035, 0.5558, 0.5744],
       device='cuda:0') torch.Size([16])
percent tensor([0.5899, 0.6077, 0.5888, 0.5800, 0.5793, 0.5845, 0.5996, 0.5756, 0.6044,
        0.6153, 0.6201, 0.6076, 0.6082, 0.6144, 0.5847, 0.5988],
       device='cuda:0') torch.Size([16])
percent tensor([0.6004, 0.6724, 0.4851, 0.5734, 0.5086, 0.6383, 0.6040, 0.3869, 0.6719,
        0.6488, 0.7060, 0.6015, 0.6636, 0.6955, 0.5616, 0.6232],
       device='cuda:0') torch.Size([16])
percent tensor([0.5969, 0.5930, 0.6312, 0.6183, 0.6592, 0.6144, 0.6244, 0.6533, 0.6067,
        0.5993, 0.5727, 0.5728, 0.5523, 0.5886, 0.6006, 0.6176],
       device='cuda:0') torch.Size([16])
percent tensor([0.4981, 0.5429, 0.7135, 0.6228, 0.7591, 0.7285, 0.5521, 0.6591, 0.6479,
        0.5358, 0.6695, 0.5399, 0.5528, 0.5966, 0.5041, 0.4798],
       device='cuda:0') torch.Size([16])
percent tensor([0.9993, 0.9989, 0.9995, 0.9990, 0.9992, 0.9989, 0.9986, 0.9995, 0.9998,
        0.9990, 0.9998, 0.9995, 0.9995, 0.9984, 0.9992, 0.9991],
       device='cuda:0') torch.Size([16])
Epoch: 118 | Batch_idx: 0 |  Loss: (0.1940) |  Loss2: (0.0000) | Acc: (95.00%) (122/128)
Epoch: 118 | Batch_idx: 10 |  Loss: (0.1666) |  Loss2: (0.0000) | Acc: (94.00%) (1334/1408)
Epoch: 118 | Batch_idx: 20 |  Loss: (0.1800) |  Loss2: (0.0000) | Acc: (93.00%) (2526/2688)
Epoch: 118 | Batch_idx: 30 |  Loss: (0.1769) |  Loss2: (0.0000) | Acc: (94.00%) (3733/3968)
Epoch: 118 | Batch_idx: 40 |  Loss: (0.1822) |  Loss2: (0.0000) | Acc: (93.00%) (4917/5248)
Epoch: 118 | Batch_idx: 50 |  Loss: (0.1873) |  Loss2: (0.0000) | Acc: (93.00%) (6102/6528)
Epoch: 118 | Batch_idx: 60 |  Loss: (0.1909) |  Loss2: (0.0000) | Acc: (93.00%) (7297/7808)
Epoch: 118 | Batch_idx: 70 |  Loss: (0.1909) |  Loss2: (0.0000) | Acc: (93.00%) (8496/9088)
Epoch: 118 | Batch_idx: 80 |  Loss: (0.1874) |  Loss2: (0.0000) | Acc: (93.00%) (9708/10368)
Epoch: 118 | Batch_idx: 90 |  Loss: (0.1885) |  Loss2: (0.0000) | Acc: (93.00%) (10895/11648)
Epoch: 118 | Batch_idx: 100 |  Loss: (0.1888) |  Loss2: (0.0000) | Acc: (93.00%) (12088/12928)
Epoch: 118 | Batch_idx: 110 |  Loss: (0.1911) |  Loss2: (0.0000) | Acc: (93.00%) (13273/14208)
Epoch: 118 | Batch_idx: 120 |  Loss: (0.1932) |  Loss2: (0.0000) | Acc: (93.00%) (14456/15488)
Epoch: 118 | Batch_idx: 130 |  Loss: (0.1934) |  Loss2: (0.0000) | Acc: (93.00%) (15650/16768)
Epoch: 118 | Batch_idx: 140 |  Loss: (0.1942) |  Loss2: (0.0000) | Acc: (93.00%) (16835/18048)
Epoch: 118 | Batch_idx: 150 |  Loss: (0.1933) |  Loss2: (0.0000) | Acc: (93.00%) (18034/19328)
Epoch: 118 | Batch_idx: 160 |  Loss: (0.1943) |  Loss2: (0.0000) | Acc: (93.00%) (19228/20608)
Epoch: 118 | Batch_idx: 170 |  Loss: (0.1924) |  Loss2: (0.0000) | Acc: (93.00%) (20429/21888)
Epoch: 118 | Batch_idx: 180 |  Loss: (0.1923) |  Loss2: (0.0000) | Acc: (93.00%) (21629/23168)
Epoch: 118 | Batch_idx: 190 |  Loss: (0.1929) |  Loss2: (0.0000) | Acc: (93.00%) (22814/24448)
Epoch: 118 | Batch_idx: 200 |  Loss: (0.1927) |  Loss2: (0.0000) | Acc: (93.00%) (24000/25728)
Epoch: 118 | Batch_idx: 210 |  Loss: (0.1938) |  Loss2: (0.0000) | Acc: (93.00%) (25190/27008)
Epoch: 118 | Batch_idx: 220 |  Loss: (0.1929) |  Loss2: (0.0000) | Acc: (93.00%) (26392/28288)
Epoch: 118 | Batch_idx: 230 |  Loss: (0.1926) |  Loss2: (0.0000) | Acc: (93.00%) (27593/29568)
Epoch: 118 | Batch_idx: 240 |  Loss: (0.1927) |  Loss2: (0.0000) | Acc: (93.00%) (28791/30848)
Epoch: 118 | Batch_idx: 250 |  Loss: (0.1915) |  Loss2: (0.0000) | Acc: (93.00%) (30005/32128)
Epoch: 118 | Batch_idx: 260 |  Loss: (0.1926) |  Loss2: (0.0000) | Acc: (93.00%) (31174/33408)
Epoch: 118 | Batch_idx: 270 |  Loss: (0.1930) |  Loss2: (0.0000) | Acc: (93.00%) (32364/34688)
Epoch: 118 | Batch_idx: 280 |  Loss: (0.1935) |  Loss2: (0.0000) | Acc: (93.00%) (33553/35968)
Epoch: 118 | Batch_idx: 290 |  Loss: (0.1936) |  Loss2: (0.0000) | Acc: (93.00%) (34742/37248)
Epoch: 118 | Batch_idx: 300 |  Loss: (0.1931) |  Loss2: (0.0000) | Acc: (93.00%) (35948/38528)
Epoch: 118 | Batch_idx: 310 |  Loss: (0.1928) |  Loss2: (0.0000) | Acc: (93.00%) (37153/39808)
Epoch: 118 | Batch_idx: 320 |  Loss: (0.1926) |  Loss2: (0.0000) | Acc: (93.00%) (38349/41088)
Epoch: 118 | Batch_idx: 330 |  Loss: (0.1931) |  Loss2: (0.0000) | Acc: (93.00%) (39537/42368)
Epoch: 118 | Batch_idx: 340 |  Loss: (0.1936) |  Loss2: (0.0000) | Acc: (93.00%) (40728/43648)
Epoch: 118 | Batch_idx: 350 |  Loss: (0.1935) |  Loss2: (0.0000) | Acc: (93.00%) (41922/44928)
Epoch: 118 | Batch_idx: 360 |  Loss: (0.1935) |  Loss2: (0.0000) | Acc: (93.00%) (43118/46208)
Epoch: 118 | Batch_idx: 370 |  Loss: (0.1928) |  Loss2: (0.0000) | Acc: (93.00%) (44322/47488)
Epoch: 118 | Batch_idx: 380 |  Loss: (0.1920) |  Loss2: (0.0000) | Acc: (93.00%) (45525/48768)
Epoch: 118 | Batch_idx: 390 |  Loss: (0.1914) |  Loss2: (0.0000) | Acc: (93.00%) (46688/50000)
# TEST : Loss: (0.3873) | Acc: (87.00%) (8749/10000)
percent tensor([0.5214, 0.5113, 0.5176, 0.5131, 0.5218, 0.5270, 0.5166, 0.5153, 0.5233,
        0.5138, 0.5244, 0.5153, 0.5141, 0.5172, 0.5174, 0.5184],
       device='cuda:0') torch.Size([16])
percent tensor([0.5015, 0.4955, 0.5064, 0.5039, 0.5022, 0.4998, 0.4989, 0.5048, 0.5064,
        0.5001, 0.5041, 0.5016, 0.4978, 0.5056, 0.4957, 0.5015],
       device='cuda:0') torch.Size([16])
percent tensor([0.5642, 0.5553, 0.5612, 0.5670, 0.5726, 0.5545, 0.5697, 0.5666, 0.5672,
        0.5623, 0.5643, 0.5653, 0.5334, 0.6018, 0.5484, 0.5681],
       device='cuda:0') torch.Size([16])
percent tensor([0.5942, 0.6125, 0.5922, 0.5827, 0.5835, 0.5879, 0.6047, 0.5799, 0.6086,
        0.6200, 0.6243, 0.6123, 0.6133, 0.6189, 0.5896, 0.6028],
       device='cuda:0') torch.Size([16])
percent tensor([0.5966, 0.6753, 0.4793, 0.5743, 0.5059, 0.6404, 0.5978, 0.3660, 0.6784,
        0.6492, 0.7134, 0.6012, 0.6657, 0.7016, 0.5526, 0.6201],
       device='cuda:0') torch.Size([16])
percent tensor([0.6027, 0.6023, 0.6357, 0.6246, 0.6651, 0.6190, 0.6323, 0.6592, 0.6143,
        0.6087, 0.5811, 0.5785, 0.5611, 0.5985, 0.6074, 0.6238],
       device='cuda:0') torch.Size([16])
percent tensor([0.4982, 0.5426, 0.7262, 0.6380, 0.7743, 0.7397, 0.5631, 0.6775, 0.6570,
        0.5356, 0.6739, 0.5450, 0.5539, 0.5962, 0.5119, 0.4801],
       device='cuda:0') torch.Size([16])
percent tensor([0.9993, 0.9989, 0.9995, 0.9990, 0.9992, 0.9989, 0.9986, 0.9995, 0.9998,
        0.9990, 0.9998, 0.9995, 0.9995, 0.9983, 0.9992, 0.9990],
       device='cuda:0') torch.Size([16])
Epoch: 119 | Batch_idx: 0 |  Loss: (0.1218) |  Loss2: (0.0000) | Acc: (96.00%) (124/128)
Epoch: 119 | Batch_idx: 10 |  Loss: (0.1884) |  Loss2: (0.0000) | Acc: (93.00%) (1316/1408)
Epoch: 119 | Batch_idx: 20 |  Loss: (0.1970) |  Loss2: (0.0000) | Acc: (92.00%) (2497/2688)
Epoch: 119 | Batch_idx: 30 |  Loss: (0.1948) |  Loss2: (0.0000) | Acc: (93.00%) (3693/3968)
Epoch: 119 | Batch_idx: 40 |  Loss: (0.1985) |  Loss2: (0.0000) | Acc: (92.00%) (4880/5248)
Epoch: 119 | Batch_idx: 50 |  Loss: (0.1957) |  Loss2: (0.0000) | Acc: (93.00%) (6075/6528)
Epoch: 119 | Batch_idx: 60 |  Loss: (0.1916) |  Loss2: (0.0000) | Acc: (93.00%) (7278/7808)
Epoch: 119 | Batch_idx: 70 |  Loss: (0.1923) |  Loss2: (0.0000) | Acc: (93.00%) (8465/9088)
Epoch: 119 | Batch_idx: 80 |  Loss: (0.1900) |  Loss2: (0.0000) | Acc: (93.00%) (9678/10368)
Epoch: 119 | Batch_idx: 90 |  Loss: (0.1895) |  Loss2: (0.0000) | Acc: (93.00%) (10872/11648)
Epoch: 119 | Batch_idx: 100 |  Loss: (0.1889) |  Loss2: (0.0000) | Acc: (93.00%) (12067/12928)
Epoch: 119 | Batch_idx: 110 |  Loss: (0.1890) |  Loss2: (0.0000) | Acc: (93.00%) (13260/14208)
Epoch: 119 | Batch_idx: 120 |  Loss: (0.1886) |  Loss2: (0.0000) | Acc: (93.00%) (14459/15488)
Epoch: 119 | Batch_idx: 130 |  Loss: (0.1875) |  Loss2: (0.0000) | Acc: (93.00%) (15664/16768)
Epoch: 119 | Batch_idx: 140 |  Loss: (0.1883) |  Loss2: (0.0000) | Acc: (93.00%) (16853/18048)
Epoch: 119 | Batch_idx: 150 |  Loss: (0.1875) |  Loss2: (0.0000) | Acc: (93.00%) (18056/19328)
Epoch: 119 | Batch_idx: 160 |  Loss: (0.1855) |  Loss2: (0.0000) | Acc: (93.00%) (19278/20608)
Epoch: 119 | Batch_idx: 170 |  Loss: (0.1842) |  Loss2: (0.0000) | Acc: (93.00%) (20479/21888)
Epoch: 119 | Batch_idx: 180 |  Loss: (0.1841) |  Loss2: (0.0000) | Acc: (93.00%) (21678/23168)
Epoch: 119 | Batch_idx: 190 |  Loss: (0.1841) |  Loss2: (0.0000) | Acc: (93.00%) (22876/24448)
Epoch: 119 | Batch_idx: 200 |  Loss: (0.1839) |  Loss2: (0.0000) | Acc: (93.00%) (24075/25728)
Epoch: 119 | Batch_idx: 210 |  Loss: (0.1843) |  Loss2: (0.0000) | Acc: (93.00%) (25265/27008)
Epoch: 119 | Batch_idx: 220 |  Loss: (0.1841) |  Loss2: (0.0000) | Acc: (93.00%) (26468/28288)
Epoch: 119 | Batch_idx: 230 |  Loss: (0.1836) |  Loss2: (0.0000) | Acc: (93.00%) (27674/29568)
Epoch: 119 | Batch_idx: 240 |  Loss: (0.1822) |  Loss2: (0.0000) | Acc: (93.00%) (28892/30848)
Epoch: 119 | Batch_idx: 250 |  Loss: (0.1828) |  Loss2: (0.0000) | Acc: (93.00%) (30078/32128)
Epoch: 119 | Batch_idx: 260 |  Loss: (0.1826) |  Loss2: (0.0000) | Acc: (93.00%) (31278/33408)
Epoch: 119 | Batch_idx: 270 |  Loss: (0.1822) |  Loss2: (0.0000) | Acc: (93.00%) (32476/34688)
Epoch: 119 | Batch_idx: 280 |  Loss: (0.1815) |  Loss2: (0.0000) | Acc: (93.00%) (33681/35968)
Epoch: 119 | Batch_idx: 290 |  Loss: (0.1815) |  Loss2: (0.0000) | Acc: (93.00%) (34880/37248)
Epoch: 119 | Batch_idx: 300 |  Loss: (0.1807) |  Loss2: (0.0000) | Acc: (93.00%) (36095/38528)
Epoch: 119 | Batch_idx: 310 |  Loss: (0.1804) |  Loss2: (0.0000) | Acc: (93.00%) (37304/39808)
Epoch: 119 | Batch_idx: 320 |  Loss: (0.1801) |  Loss2: (0.0000) | Acc: (93.00%) (38506/41088)
Epoch: 119 | Batch_idx: 330 |  Loss: (0.1801) |  Loss2: (0.0000) | Acc: (93.00%) (39706/42368)
Epoch: 119 | Batch_idx: 340 |  Loss: (0.1803) |  Loss2: (0.0000) | Acc: (93.00%) (40900/43648)
Epoch: 119 | Batch_idx: 350 |  Loss: (0.1792) |  Loss2: (0.0000) | Acc: (93.00%) (42120/44928)
Epoch: 119 | Batch_idx: 360 |  Loss: (0.1795) |  Loss2: (0.0000) | Acc: (93.00%) (43316/46208)
Epoch: 119 | Batch_idx: 370 |  Loss: (0.1797) |  Loss2: (0.0000) | Acc: (93.00%) (44510/47488)
Epoch: 119 | Batch_idx: 380 |  Loss: (0.1793) |  Loss2: (0.0000) | Acc: (93.00%) (45712/48768)
Epoch: 119 | Batch_idx: 390 |  Loss: (0.1796) |  Loss2: (0.0000) | Acc: (93.00%) (46860/50000)
# TEST : Loss: (0.3814) | Acc: (87.00%) (8781/10000)
percent tensor([0.5200, 0.5099, 0.5172, 0.5125, 0.5211, 0.5257, 0.5154, 0.5145, 0.5220,
        0.5126, 0.5227, 0.5146, 0.5128, 0.5157, 0.5160, 0.5170],
       device='cuda:0') torch.Size([16])
percent tensor([0.5003, 0.4942, 0.5053, 0.5028, 0.5010, 0.4987, 0.4976, 0.5035, 0.5052,
        0.4988, 0.5028, 0.5005, 0.4965, 0.5045, 0.4944, 0.5003],
       device='cuda:0') torch.Size([16])
percent tensor([0.5618, 0.5543, 0.5567, 0.5622, 0.5693, 0.5521, 0.5679, 0.5627, 0.5635,
        0.5608, 0.5621, 0.5622, 0.5313, 0.6004, 0.5465, 0.5661],
       device='cuda:0') torch.Size([16])
percent tensor([0.5977, 0.6162, 0.5948, 0.5853, 0.5863, 0.5906, 0.6083, 0.5827, 0.6122,
        0.6235, 0.6284, 0.6159, 0.6176, 0.6220, 0.5933, 0.6061],
       device='cuda:0') torch.Size([16])
percent tensor([0.6037, 0.6737, 0.4875, 0.5859, 0.5108, 0.6482, 0.5990, 0.3657, 0.6820,
        0.6475, 0.7130, 0.6073, 0.6656, 0.7001, 0.5566, 0.6237],
       device='cuda:0') torch.Size([16])
percent tensor([0.5960, 0.5950, 0.6301, 0.6190, 0.6607, 0.6143, 0.6252, 0.6531, 0.6080,
        0.6022, 0.5737, 0.5705, 0.5535, 0.5928, 0.5998, 0.6161],
       device='cuda:0') torch.Size([16])
percent tensor([0.5034, 0.5504, 0.7388, 0.6521, 0.7885, 0.7527, 0.5708, 0.6915, 0.6677,
        0.5444, 0.6861, 0.5540, 0.5654, 0.6073, 0.5192, 0.4826],
       device='cuda:0') torch.Size([16])
percent tensor([0.9993, 0.9989, 0.9995, 0.9991, 0.9993, 0.9990, 0.9987, 0.9995, 0.9998,
        0.9991, 0.9998, 0.9996, 0.9996, 0.9986, 0.9992, 0.9991],
       device='cuda:0') torch.Size([16])
Epoch: 120 | Batch_idx: 0 |  Loss: (0.2166) |  Loss2: (0.0000) | Acc: (91.00%) (117/128)
Epoch: 120 | Batch_idx: 10 |  Loss: (0.1754) |  Loss2: (0.0000) | Acc: (94.00%) (1328/1408)
Epoch: 120 | Batch_idx: 20 |  Loss: (0.1810) |  Loss2: (0.0000) | Acc: (93.00%) (2521/2688)
Epoch: 120 | Batch_idx: 30 |  Loss: (0.1804) |  Loss2: (0.0000) | Acc: (93.00%) (3723/3968)
Epoch: 120 | Batch_idx: 40 |  Loss: (0.1796) |  Loss2: (0.0000) | Acc: (93.00%) (4922/5248)
Epoch: 120 | Batch_idx: 50 |  Loss: (0.1729) |  Loss2: (0.0000) | Acc: (93.00%) (6133/6528)
Epoch: 120 | Batch_idx: 60 |  Loss: (0.1734) |  Loss2: (0.0000) | Acc: (93.00%) (7336/7808)
Epoch: 120 | Batch_idx: 70 |  Loss: (0.1765) |  Loss2: (0.0000) | Acc: (93.00%) (8532/9088)
Epoch: 120 | Batch_idx: 80 |  Loss: (0.1774) |  Loss2: (0.0000) | Acc: (93.00%) (9726/10368)
Epoch: 120 | Batch_idx: 90 |  Loss: (0.1763) |  Loss2: (0.0000) | Acc: (93.00%) (10945/11648)
Epoch: 120 | Batch_idx: 100 |  Loss: (0.1776) |  Loss2: (0.0000) | Acc: (93.00%) (12145/12928)
Epoch: 120 | Batch_idx: 110 |  Loss: (0.1774) |  Loss2: (0.0000) | Acc: (93.00%) (13344/14208)
Epoch: 120 | Batch_idx: 120 |  Loss: (0.1748) |  Loss2: (0.0000) | Acc: (93.00%) (14558/15488)
Epoch: 120 | Batch_idx: 130 |  Loss: (0.1754) |  Loss2: (0.0000) | Acc: (93.00%) (15757/16768)
Epoch: 120 | Batch_idx: 140 |  Loss: (0.1764) |  Loss2: (0.0000) | Acc: (93.00%) (16959/18048)
Epoch: 120 | Batch_idx: 150 |  Loss: (0.1768) |  Loss2: (0.0000) | Acc: (93.00%) (18163/19328)
Epoch: 120 | Batch_idx: 160 |  Loss: (0.1780) |  Loss2: (0.0000) | Acc: (93.00%) (19355/20608)
Epoch: 120 | Batch_idx: 170 |  Loss: (0.1760) |  Loss2: (0.0000) | Acc: (93.00%) (20566/21888)
Epoch: 120 | Batch_idx: 180 |  Loss: (0.1756) |  Loss2: (0.0000) | Acc: (93.00%) (21771/23168)
Epoch: 120 | Batch_idx: 190 |  Loss: (0.1753) |  Loss2: (0.0000) | Acc: (93.00%) (22975/24448)
Epoch: 120 | Batch_idx: 200 |  Loss: (0.1748) |  Loss2: (0.0000) | Acc: (93.00%) (24170/25728)
Epoch: 120 | Batch_idx: 210 |  Loss: (0.1756) |  Loss2: (0.0000) | Acc: (93.00%) (25369/27008)
Epoch: 120 | Batch_idx: 220 |  Loss: (0.1752) |  Loss2: (0.0000) | Acc: (93.00%) (26585/28288)
Epoch: 120 | Batch_idx: 230 |  Loss: (0.1752) |  Loss2: (0.0000) | Acc: (93.00%) (27789/29568)
Epoch: 120 | Batch_idx: 240 |  Loss: (0.1757) |  Loss2: (0.0000) | Acc: (93.00%) (28982/30848)
Epoch: 120 | Batch_idx: 250 |  Loss: (0.1760) |  Loss2: (0.0000) | Acc: (93.00%) (30177/32128)
Epoch: 120 | Batch_idx: 260 |  Loss: (0.1760) |  Loss2: (0.0000) | Acc: (93.00%) (31381/33408)
Epoch: 120 | Batch_idx: 270 |  Loss: (0.1757) |  Loss2: (0.0000) | Acc: (93.00%) (32588/34688)
Epoch: 120 | Batch_idx: 280 |  Loss: (0.1765) |  Loss2: (0.0000) | Acc: (93.00%) (33780/35968)
Epoch: 120 | Batch_idx: 290 |  Loss: (0.1760) |  Loss2: (0.0000) | Acc: (93.00%) (34993/37248)
Epoch: 120 | Batch_idx: 300 |  Loss: (0.1771) |  Loss2: (0.0000) | Acc: (93.00%) (36179/38528)
Epoch: 120 | Batch_idx: 310 |  Loss: (0.1780) |  Loss2: (0.0000) | Acc: (93.00%) (37372/39808)
Epoch: 120 | Batch_idx: 320 |  Loss: (0.1775) |  Loss2: (0.0000) | Acc: (93.00%) (38578/41088)
Epoch: 120 | Batch_idx: 330 |  Loss: (0.1779) |  Loss2: (0.0000) | Acc: (93.00%) (39775/42368)
Epoch: 120 | Batch_idx: 340 |  Loss: (0.1775) |  Loss2: (0.0000) | Acc: (93.00%) (40976/43648)
Epoch: 120 | Batch_idx: 350 |  Loss: (0.1780) |  Loss2: (0.0000) | Acc: (93.00%) (42165/44928)
Epoch: 120 | Batch_idx: 360 |  Loss: (0.1781) |  Loss2: (0.0000) | Acc: (93.00%) (43364/46208)
Epoch: 120 | Batch_idx: 370 |  Loss: (0.1785) |  Loss2: (0.0000) | Acc: (93.00%) (44558/47488)
Epoch: 120 | Batch_idx: 380 |  Loss: (0.1786) |  Loss2: (0.0000) | Acc: (93.00%) (45755/48768)
Epoch: 120 | Batch_idx: 390 |  Loss: (0.1784) |  Loss2: (0.0000) | Acc: (93.00%) (46917/50000)
=> saving checkpoint 'drive/app/torch/save_Schedule/checkpoint_120.pth.tar'
# TEST : Loss: (0.3768) | Acc: (87.00%) (8783/10000)
percent tensor([0.5177, 0.5075, 0.5153, 0.5102, 0.5188, 0.5236, 0.5130, 0.5122, 0.5197,
        0.5101, 0.5202, 0.5123, 0.5106, 0.5133, 0.5136, 0.5146],
       device='cuda:0') torch.Size([16])
percent tensor([0.5011, 0.4952, 0.5061, 0.5036, 0.5017, 0.4994, 0.4986, 0.5044, 0.5061,
        0.4997, 0.5037, 0.5013, 0.4974, 0.5056, 0.4952, 0.5011],
       device='cuda:0') torch.Size([16])
percent tensor([0.5617, 0.5535, 0.5560, 0.5605, 0.5684, 0.5529, 0.5674, 0.5618, 0.5614,
        0.5596, 0.5610, 0.5605, 0.5299, 0.5996, 0.5464, 0.5665],
       device='cuda:0') torch.Size([16])
percent tensor([0.5977, 0.6170, 0.5946, 0.5853, 0.5860, 0.5900, 0.6088, 0.5826, 0.6121,
        0.6243, 0.6291, 0.6165, 0.6183, 0.6227, 0.5935, 0.6064],
       device='cuda:0') torch.Size([16])
percent tensor([0.6117, 0.6769, 0.4939, 0.5942, 0.5213, 0.6543, 0.6073, 0.3700, 0.6868,
        0.6520, 0.7171, 0.6127, 0.6697, 0.7022, 0.5670, 0.6316],
       device='cuda:0') torch.Size([16])
percent tensor([0.6009, 0.6011, 0.6340, 0.6222, 0.6646, 0.6180, 0.6303, 0.6572, 0.6134,
        0.6079, 0.5782, 0.5738, 0.5601, 0.5975, 0.6036, 0.6208],
       device='cuda:0') torch.Size([16])
percent tensor([0.4962, 0.5427, 0.7355, 0.6498, 0.7897, 0.7508, 0.5673, 0.6902, 0.6620,
        0.5391, 0.6827, 0.5496, 0.5610, 0.6011, 0.5158, 0.4786],
       device='cuda:0') torch.Size([16])
percent tensor([0.9993, 0.9990, 0.9996, 0.9991, 0.9993, 0.9990, 0.9988, 0.9996, 0.9998,
        0.9992, 0.9998, 0.9996, 0.9995, 0.9986, 0.9992, 0.9991],
       device='cuda:0') torch.Size([16])
Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 3, 3, 3]) tensor(186.1669, device='cuda:0')
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(825.8563, device='cuda:0')
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(814.2532, device='cuda:0')
Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([128, 64, 3, 3]) tensor(1527.0076, device='cuda:0')
Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([128, 64, 1, 1]) tensor(485.5478, device='cuda:0')
Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([128, 128, 3, 3]) tensor(2269.9839, device='cuda:0')
Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([256, 128, 3, 3]) tensor(4264.1582, device='cuda:0')
Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([256, 128, 1, 1]) tensor(1379.1434, device='cuda:0')
Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([256, 256, 3, 3]) tensor(6154.6309, device='cuda:0')
Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([512, 256, 3, 3]) tensor(11784.7578, device='cuda:0')
Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([512, 256, 1, 1]) tensor(3908.0435, device='cuda:0')
Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([512, 512, 3, 3]) tensor(16521.6523, device='cuda:0')
Epoch: 121 | Batch_idx: 0 |  Loss: (0.2155) |  Loss2: (0.0000) | Acc: (95.00%) (122/128)
Epoch: 121 | Batch_idx: 10 |  Loss: (0.1761) |  Loss2: (0.0000) | Acc: (94.00%) (1326/1408)
Epoch: 121 | Batch_idx: 20 |  Loss: (0.1810) |  Loss2: (0.0000) | Acc: (93.00%) (2519/2688)
Epoch: 121 | Batch_idx: 30 |  Loss: (0.1730) |  Loss2: (0.0000) | Acc: (94.00%) (3732/3968)
Epoch: 121 | Batch_idx: 40 |  Loss: (0.1747) |  Loss2: (0.0000) | Acc: (93.00%) (4927/5248)
Epoch: 121 | Batch_idx: 50 |  Loss: (0.1741) |  Loss2: (0.0000) | Acc: (93.00%) (6135/6528)
Epoch: 121 | Batch_idx: 60 |  Loss: (0.1789) |  Loss2: (0.0000) | Acc: (93.00%) (7328/7808)
Epoch: 121 | Batch_idx: 70 |  Loss: (0.1807) |  Loss2: (0.0000) | Acc: (93.00%) (8525/9088)
Epoch: 121 | Batch_idx: 80 |  Loss: (0.1789) |  Loss2: (0.0000) | Acc: (93.00%) (9731/10368)
Epoch: 121 | Batch_idx: 90 |  Loss: (0.1753) |  Loss2: (0.0000) | Acc: (94.00%) (10953/11648)
Epoch: 121 | Batch_idx: 100 |  Loss: (0.1776) |  Loss2: (0.0000) | Acc: (93.00%) (12138/12928)
Epoch: 121 | Batch_idx: 110 |  Loss: (0.1759) |  Loss2: (0.0000) | Acc: (93.00%) (13350/14208)
Epoch: 121 | Batch_idx: 120 |  Loss: (0.1747) |  Loss2: (0.0000) | Acc: (94.00%) (14564/15488)
Epoch: 121 | Batch_idx: 130 |  Loss: (0.1749) |  Loss2: (0.0000) | Acc: (94.00%) (15764/16768)
Epoch: 121 | Batch_idx: 140 |  Loss: (0.1764) |  Loss2: (0.0000) | Acc: (93.00%) (16952/18048)
Epoch: 121 | Batch_idx: 150 |  Loss: (0.1779) |  Loss2: (0.0000) | Acc: (93.00%) (18142/19328)
Epoch: 121 | Batch_idx: 160 |  Loss: (0.1785) |  Loss2: (0.0000) | Acc: (93.00%) (19336/20608)
Epoch: 121 | Batch_idx: 170 |  Loss: (0.1768) |  Loss2: (0.0000) | Acc: (93.00%) (20547/21888)
Epoch: 121 | Batch_idx: 180 |  Loss: (0.1776) |  Loss2: (0.0000) | Acc: (93.00%) (21740/23168)
Epoch: 121 | Batch_idx: 190 |  Loss: (0.1766) |  Loss2: (0.0000) | Acc: (93.00%) (22959/24448)
Epoch: 121 | Batch_idx: 200 |  Loss: (0.1755) |  Loss2: (0.0000) | Acc: (93.00%) (24171/25728)
Epoch: 121 | Batch_idx: 210 |  Loss: (0.1751) |  Loss2: (0.0000) | Acc: (93.00%) (25373/27008)
Epoch: 121 | Batch_idx: 220 |  Loss: (0.1744) |  Loss2: (0.0000) | Acc: (93.00%) (26583/28288)
Epoch: 121 | Batch_idx: 230 |  Loss: (0.1736) |  Loss2: (0.0000) | Acc: (94.00%) (27794/29568)
Epoch: 121 | Batch_idx: 240 |  Loss: (0.1731) |  Loss2: (0.0000) | Acc: (93.00%) (28996/30848)
Epoch: 121 | Batch_idx: 250 |  Loss: (0.1737) |  Loss2: (0.0000) | Acc: (93.00%) (30191/32128)
Epoch: 121 | Batch_idx: 260 |  Loss: (0.1738) |  Loss2: (0.0000) | Acc: (93.00%) (31392/33408)
Epoch: 121 | Batch_idx: 270 |  Loss: (0.1737) |  Loss2: (0.0000) | Acc: (93.00%) (32599/34688)
Epoch: 121 | Batch_idx: 280 |  Loss: (0.1743) |  Loss2: (0.0000) | Acc: (93.00%) (33798/35968)
Epoch: 121 | Batch_idx: 290 |  Loss: (0.1741) |  Loss2: (0.0000) | Acc: (93.00%) (35005/37248)
Epoch: 121 | Batch_idx: 300 |  Loss: (0.1743) |  Loss2: (0.0000) | Acc: (93.00%) (36206/38528)
Epoch: 121 | Batch_idx: 310 |  Loss: (0.1746) |  Loss2: (0.0000) | Acc: (93.00%) (37397/39808)
Epoch: 121 | Batch_idx: 320 |  Loss: (0.1749) |  Loss2: (0.0000) | Acc: (93.00%) (38600/41088)
Epoch: 121 | Batch_idx: 330 |  Loss: (0.1742) |  Loss2: (0.0000) | Acc: (93.00%) (39816/42368)
Epoch: 121 | Batch_idx: 340 |  Loss: (0.1743) |  Loss2: (0.0000) | Acc: (93.00%) (41025/43648)
Epoch: 121 | Batch_idx: 350 |  Loss: (0.1746) |  Loss2: (0.0000) | Acc: (93.00%) (42221/44928)
Epoch: 121 | Batch_idx: 360 |  Loss: (0.1742) |  Loss2: (0.0000) | Acc: (93.00%) (43429/46208)
Epoch: 121 | Batch_idx: 370 |  Loss: (0.1742) |  Loss2: (0.0000) | Acc: (93.00%) (44632/47488)
Epoch: 121 | Batch_idx: 380 |  Loss: (0.1739) |  Loss2: (0.0000) | Acc: (94.00%) (45849/48768)
Epoch: 121 | Batch_idx: 390 |  Loss: (0.1736) |  Loss2: (0.0000) | Acc: (94.00%) (47015/50000)
# TEST : Loss: (0.3751) | Acc: (87.00%) (8799/10000)
percent tensor([0.5201, 0.5101, 0.5188, 0.5130, 0.5225, 0.5255, 0.5160, 0.5155, 0.5224,
        0.5131, 0.5227, 0.5158, 0.5131, 0.5158, 0.5161, 0.5169],
       device='cuda:0') torch.Size([16])
percent tensor([0.5013, 0.4953, 0.5065, 0.5039, 0.5021, 0.4996, 0.4988, 0.5048, 0.5065,
        0.4999, 0.5039, 0.5016, 0.4975, 0.5060, 0.4953, 0.5013],
       device='cuda:0') torch.Size([16])
percent tensor([0.5588, 0.5485, 0.5541, 0.5581, 0.5671, 0.5520, 0.5638, 0.5605, 0.5580,
        0.5553, 0.5568, 0.5571, 0.5253, 0.5967, 0.5430, 0.5642],
       device='cuda:0') torch.Size([16])
percent tensor([0.5943, 0.6140, 0.5918, 0.5825, 0.5829, 0.5865, 0.6057, 0.5802, 0.6092,
        0.6212, 0.6259, 0.6139, 0.6154, 0.6196, 0.5904, 0.6025],
       device='cuda:0') torch.Size([16])
percent tensor([0.6071, 0.6728, 0.4879, 0.5858, 0.5148, 0.6477, 0.6001, 0.3607, 0.6857,
        0.6473, 0.7156, 0.6056, 0.6674, 0.7004, 0.5568, 0.6252],
       device='cuda:0') torch.Size([16])
percent tensor([0.5995, 0.6003, 0.6315, 0.6189, 0.6632, 0.6158, 0.6285, 0.6548, 0.6129,
        0.6076, 0.5773, 0.5714, 0.5593, 0.5962, 0.6008, 0.6179],
       device='cuda:0') torch.Size([16])
percent tensor([0.5068, 0.5537, 0.7394, 0.6524, 0.7934, 0.7554, 0.5759, 0.6950, 0.6718,
        0.5520, 0.6949, 0.5565, 0.5769, 0.6095, 0.5232, 0.4806],
       device='cuda:0') torch.Size([16])
percent tensor([0.9994, 0.9990, 0.9996, 0.9991, 0.9993, 0.9991, 0.9988, 0.9996, 0.9998,
        0.9992, 0.9999, 0.9996, 0.9996, 0.9987, 0.9993, 0.9992],
       device='cuda:0') torch.Size([16])
Epoch: 122 | Batch_idx: 0 |  Loss: (0.1555) |  Loss2: (0.0000) | Acc: (95.00%) (122/128)
Epoch: 122 | Batch_idx: 10 |  Loss: (0.1634) |  Loss2: (0.0000) | Acc: (94.00%) (1335/1408)
Epoch: 122 | Batch_idx: 20 |  Loss: (0.1553) |  Loss2: (0.0000) | Acc: (94.00%) (2553/2688)
Epoch: 122 | Batch_idx: 30 |  Loss: (0.1571) |  Loss2: (0.0000) | Acc: (94.00%) (3761/3968)
Epoch: 122 | Batch_idx: 40 |  Loss: (0.1660) |  Loss2: (0.0000) | Acc: (94.00%) (4948/5248)
Epoch: 122 | Batch_idx: 50 |  Loss: (0.1657) |  Loss2: (0.0000) | Acc: (94.00%) (6157/6528)
Epoch: 122 | Batch_idx: 60 |  Loss: (0.1695) |  Loss2: (0.0000) | Acc: (94.00%) (7364/7808)
Epoch: 122 | Batch_idx: 70 |  Loss: (0.1707) |  Loss2: (0.0000) | Acc: (94.00%) (8560/9088)
Epoch: 122 | Batch_idx: 80 |  Loss: (0.1707) |  Loss2: (0.0000) | Acc: (94.00%) (9770/10368)
Epoch: 122 | Batch_idx: 90 |  Loss: (0.1716) |  Loss2: (0.0000) | Acc: (94.00%) (10973/11648)
Epoch: 122 | Batch_idx: 100 |  Loss: (0.1725) |  Loss2: (0.0000) | Acc: (94.00%) (12173/12928)
Epoch: 122 | Batch_idx: 110 |  Loss: (0.1725) |  Loss2: (0.0000) | Acc: (94.00%) (13384/14208)
Epoch: 122 | Batch_idx: 120 |  Loss: (0.1724) |  Loss2: (0.0000) | Acc: (94.00%) (14585/15488)
Epoch: 122 | Batch_idx: 130 |  Loss: (0.1709) |  Loss2: (0.0000) | Acc: (94.00%) (15792/16768)
Epoch: 122 | Batch_idx: 140 |  Loss: (0.1702) |  Loss2: (0.0000) | Acc: (94.00%) (16998/18048)
Epoch: 122 | Batch_idx: 150 |  Loss: (0.1702) |  Loss2: (0.0000) | Acc: (94.00%) (18209/19328)
Epoch: 122 | Batch_idx: 160 |  Loss: (0.1685) |  Loss2: (0.0000) | Acc: (94.00%) (19425/20608)
Epoch: 122 | Batch_idx: 170 |  Loss: (0.1688) |  Loss2: (0.0000) | Acc: (94.00%) (20636/21888)
Epoch: 122 | Batch_idx: 180 |  Loss: (0.1694) |  Loss2: (0.0000) | Acc: (94.00%) (21839/23168)
Epoch: 122 | Batch_idx: 190 |  Loss: (0.1699) |  Loss2: (0.0000) | Acc: (94.00%) (23045/24448)
Epoch: 122 | Batch_idx: 200 |  Loss: (0.1706) |  Loss2: (0.0000) | Acc: (94.00%) (24244/25728)
Epoch: 122 | Batch_idx: 210 |  Loss: (0.1697) |  Loss2: (0.0000) | Acc: (94.00%) (25457/27008)
Epoch: 122 | Batch_idx: 220 |  Loss: (0.1697) |  Loss2: (0.0000) | Acc: (94.00%) (26659/28288)
Epoch: 122 | Batch_idx: 230 |  Loss: (0.1698) |  Loss2: (0.0000) | Acc: (94.00%) (27870/29568)
Epoch: 122 | Batch_idx: 240 |  Loss: (0.1693) |  Loss2: (0.0000) | Acc: (94.00%) (29086/30848)
Epoch: 122 | Batch_idx: 250 |  Loss: (0.1687) |  Loss2: (0.0000) | Acc: (94.00%) (30299/32128)
Epoch: 122 | Batch_idx: 260 |  Loss: (0.1696) |  Loss2: (0.0000) | Acc: (94.00%) (31489/33408)
Epoch: 122 | Batch_idx: 270 |  Loss: (0.1689) |  Loss2: (0.0000) | Acc: (94.00%) (32704/34688)
Epoch: 122 | Batch_idx: 280 |  Loss: (0.1685) |  Loss2: (0.0000) | Acc: (94.00%) (33920/35968)
Epoch: 122 | Batch_idx: 290 |  Loss: (0.1675) |  Loss2: (0.0000) | Acc: (94.00%) (35142/37248)
Epoch: 122 | Batch_idx: 300 |  Loss: (0.1683) |  Loss2: (0.0000) | Acc: (94.00%) (36334/38528)
Epoch: 122 | Batch_idx: 310 |  Loss: (0.1687) |  Loss2: (0.0000) | Acc: (94.00%) (37538/39808)
Epoch: 122 | Batch_idx: 320 |  Loss: (0.1688) |  Loss2: (0.0000) | Acc: (94.00%) (38750/41088)
Epoch: 122 | Batch_idx: 330 |  Loss: (0.1690) |  Loss2: (0.0000) | Acc: (94.00%) (39957/42368)
Epoch: 122 | Batch_idx: 340 |  Loss: (0.1690) |  Loss2: (0.0000) | Acc: (94.00%) (41162/43648)
Epoch: 122 | Batch_idx: 350 |  Loss: (0.1696) |  Loss2: (0.0000) | Acc: (94.00%) (42349/44928)
Epoch: 122 | Batch_idx: 360 |  Loss: (0.1698) |  Loss2: (0.0000) | Acc: (94.00%) (43544/46208)
Epoch: 122 | Batch_idx: 370 |  Loss: (0.1693) |  Loss2: (0.0000) | Acc: (94.00%) (44755/47488)
Epoch: 122 | Batch_idx: 380 |  Loss: (0.1687) |  Loss2: (0.0000) | Acc: (94.00%) (45979/48768)
Epoch: 122 | Batch_idx: 390 |  Loss: (0.1690) |  Loss2: (0.0000) | Acc: (94.00%) (47138/50000)
# TEST : Loss: (0.3735) | Acc: (88.00%) (8807/10000)
percent tensor([0.5197, 0.5094, 0.5188, 0.5126, 0.5222, 0.5253, 0.5155, 0.5151, 0.5220,
        0.5125, 0.5221, 0.5155, 0.5125, 0.5151, 0.5155, 0.5164],
       device='cuda:0') torch.Size([16])
percent tensor([0.5010, 0.4946, 0.5063, 0.5037, 0.5017, 0.4994, 0.4983, 0.5045, 0.5062,
        0.4993, 0.5035, 0.5012, 0.4968, 0.5058, 0.4947, 0.5009],
       device='cuda:0') torch.Size([16])
percent tensor([0.5651, 0.5511, 0.5589, 0.5645, 0.5718, 0.5605, 0.5675, 0.5642, 0.5616,
        0.5582, 0.5613, 0.5612, 0.5278, 0.6005, 0.5490, 0.5699],
       device='cuda:0') torch.Size([16])
percent tensor([0.6008, 0.6204, 0.5984, 0.5888, 0.5893, 0.5922, 0.6126, 0.5865, 0.6164,
        0.6281, 0.6335, 0.6214, 0.6222, 0.6265, 0.5968, 0.6090],
       device='cuda:0') torch.Size([16])
percent tensor([0.6068, 0.6703, 0.4925, 0.5868, 0.5205, 0.6462, 0.6014, 0.3624, 0.6875,
        0.6443, 0.7134, 0.6063, 0.6649, 0.6964, 0.5575, 0.6235],
       device='cuda:0') torch.Size([16])
percent tensor([0.5984, 0.5986, 0.6301, 0.6179, 0.6621, 0.6148, 0.6265, 0.6534, 0.6111,
        0.6061, 0.5766, 0.5694, 0.5584, 0.5952, 0.5992, 0.6167],
       device='cuda:0') torch.Size([16])
percent tensor([0.4964, 0.5495, 0.7372, 0.6499, 0.7954, 0.7495, 0.5723, 0.6952, 0.6633,
        0.5483, 0.6899, 0.5513, 0.5688, 0.6009, 0.5208, 0.4757],
       device='cuda:0') torch.Size([16])
percent tensor([0.9994, 0.9990, 0.9996, 0.9992, 0.9994, 0.9991, 0.9989, 0.9996, 0.9998,
        0.9992, 0.9999, 0.9996, 0.9996, 0.9987, 0.9993, 0.9992],
       device='cuda:0') torch.Size([16])
Epoch: 123 | Batch_idx: 0 |  Loss: (0.2797) |  Loss2: (0.0000) | Acc: (89.00%) (114/128)
Epoch: 123 | Batch_idx: 10 |  Loss: (0.1827) |  Loss2: (0.0000) | Acc: (93.00%) (1321/1408)
Epoch: 123 | Batch_idx: 20 |  Loss: (0.1739) |  Loss2: (0.0000) | Acc: (94.00%) (2529/2688)
Epoch: 123 | Batch_idx: 30 |  Loss: (0.1777) |  Loss2: (0.0000) | Acc: (93.00%) (3729/3968)
Epoch: 123 | Batch_idx: 40 |  Loss: (0.1697) |  Loss2: (0.0000) | Acc: (94.00%) (4953/5248)
Epoch: 123 | Batch_idx: 50 |  Loss: (0.1762) |  Loss2: (0.0000) | Acc: (94.00%) (6149/6528)
Epoch: 123 | Batch_idx: 60 |  Loss: (0.1765) |  Loss2: (0.0000) | Acc: (94.00%) (7352/7808)
Epoch: 123 | Batch_idx: 70 |  Loss: (0.1753) |  Loss2: (0.0000) | Acc: (94.00%) (8551/9088)
Epoch: 123 | Batch_idx: 80 |  Loss: (0.1752) |  Loss2: (0.0000) | Acc: (94.00%) (9756/10368)
Epoch: 123 | Batch_idx: 90 |  Loss: (0.1773) |  Loss2: (0.0000) | Acc: (93.00%) (10946/11648)
Epoch: 123 | Batch_idx: 100 |  Loss: (0.1769) |  Loss2: (0.0000) | Acc: (94.00%) (12156/12928)
Epoch: 123 | Batch_idx: 110 |  Loss: (0.1762) |  Loss2: (0.0000) | Acc: (94.00%) (13359/14208)
Epoch: 123 | Batch_idx: 120 |  Loss: (0.1765) |  Loss2: (0.0000) | Acc: (94.00%) (14567/15488)
Epoch: 123 | Batch_idx: 130 |  Loss: (0.1748) |  Loss2: (0.0000) | Acc: (94.00%) (15784/16768)
Epoch: 123 | Batch_idx: 140 |  Loss: (0.1725) |  Loss2: (0.0000) | Acc: (94.00%) (17001/18048)
Epoch: 123 | Batch_idx: 150 |  Loss: (0.1742) |  Loss2: (0.0000) | Acc: (94.00%) (18191/19328)
Epoch: 123 | Batch_idx: 160 |  Loss: (0.1740) |  Loss2: (0.0000) | Acc: (94.00%) (19395/20608)
Epoch: 123 | Batch_idx: 170 |  Loss: (0.1727) |  Loss2: (0.0000) | Acc: (94.00%) (20604/21888)
Epoch: 123 | Batch_idx: 180 |  Loss: (0.1732) |  Loss2: (0.0000) | Acc: (94.00%) (21819/23168)
Epoch: 123 | Batch_idx: 190 |  Loss: (0.1729) |  Loss2: (0.0000) | Acc: (94.00%) (23022/24448)
Epoch: 123 | Batch_idx: 200 |  Loss: (0.1725) |  Loss2: (0.0000) | Acc: (94.00%) (24228/25728)
Epoch: 123 | Batch_idx: 210 |  Loss: (0.1731) |  Loss2: (0.0000) | Acc: (94.00%) (25427/27008)
Epoch: 123 | Batch_idx: 220 |  Loss: (0.1729) |  Loss2: (0.0000) | Acc: (94.00%) (26631/28288)
Epoch: 123 | Batch_idx: 230 |  Loss: (0.1725) |  Loss2: (0.0000) | Acc: (94.00%) (27839/29568)
Epoch: 123 | Batch_idx: 240 |  Loss: (0.1719) |  Loss2: (0.0000) | Acc: (94.00%) (29054/30848)
Epoch: 123 | Batch_idx: 250 |  Loss: (0.1733) |  Loss2: (0.0000) | Acc: (94.00%) (30235/32128)
Epoch: 123 | Batch_idx: 260 |  Loss: (0.1729) |  Loss2: (0.0000) | Acc: (94.00%) (31436/33408)
Epoch: 123 | Batch_idx: 270 |  Loss: (0.1730) |  Loss2: (0.0000) | Acc: (94.00%) (32639/34688)
Epoch: 123 | Batch_idx: 280 |  Loss: (0.1725) |  Loss2: (0.0000) | Acc: (94.00%) (33851/35968)
Epoch: 123 | Batch_idx: 290 |  Loss: (0.1725) |  Loss2: (0.0000) | Acc: (94.00%) (35051/37248)
Epoch: 123 | Batch_idx: 300 |  Loss: (0.1728) |  Loss2: (0.0000) | Acc: (94.00%) (36260/38528)
Epoch: 123 | Batch_idx: 310 |  Loss: (0.1720) |  Loss2: (0.0000) | Acc: (94.00%) (37479/39808)
Epoch: 123 | Batch_idx: 320 |  Loss: (0.1725) |  Loss2: (0.0000) | Acc: (94.00%) (38670/41088)
Epoch: 123 | Batch_idx: 330 |  Loss: (0.1728) |  Loss2: (0.0000) | Acc: (94.00%) (39862/42368)
Epoch: 123 | Batch_idx: 340 |  Loss: (0.1725) |  Loss2: (0.0000) | Acc: (94.00%) (41073/43648)
Epoch: 123 | Batch_idx: 350 |  Loss: (0.1718) |  Loss2: (0.0000) | Acc: (94.00%) (42288/44928)
Epoch: 123 | Batch_idx: 360 |  Loss: (0.1719) |  Loss2: (0.0000) | Acc: (94.00%) (43493/46208)
Epoch: 123 | Batch_idx: 370 |  Loss: (0.1719) |  Loss2: (0.0000) | Acc: (94.00%) (44697/47488)
Epoch: 123 | Batch_idx: 380 |  Loss: (0.1717) |  Loss2: (0.0000) | Acc: (94.00%) (45903/48768)
Epoch: 123 | Batch_idx: 390 |  Loss: (0.1715) |  Loss2: (0.0000) | Acc: (94.00%) (47073/50000)
# TEST : Loss: (0.3725) | Acc: (88.00%) (8818/10000)
percent tensor([0.5183, 0.5076, 0.5179, 0.5112, 0.5210, 0.5242, 0.5139, 0.5137, 0.5205,
        0.5109, 0.5204, 0.5141, 0.5109, 0.5135, 0.5138, 0.5149],
       device='cuda:0') torch.Size([16])
percent tensor([0.5011, 0.4948, 0.5065, 0.5039, 0.5018, 0.4996, 0.4985, 0.5046, 0.5065,
        0.4996, 0.5038, 0.5015, 0.4971, 0.5061, 0.4949, 0.5011],
       device='cuda:0') torch.Size([16])
percent tensor([0.5652, 0.5517, 0.5599, 0.5652, 0.5728, 0.5615, 0.5684, 0.5648, 0.5624,
        0.5597, 0.5626, 0.5628, 0.5276, 0.6026, 0.5492, 0.5709],
       device='cuda:0') torch.Size([16])
percent tensor([0.6024, 0.6220, 0.6003, 0.5905, 0.5910, 0.5937, 0.6141, 0.5881, 0.6181,
        0.6298, 0.6351, 0.6233, 0.6240, 0.6283, 0.5985, 0.6105],
       device='cuda:0') torch.Size([16])
percent tensor([0.5975, 0.6638, 0.4847, 0.5783, 0.5082, 0.6346, 0.5895, 0.3527, 0.6762,
        0.6358, 0.7044, 0.5964, 0.6569, 0.6868, 0.5454, 0.6109],
       device='cuda:0') torch.Size([16])
percent tensor([0.6025, 0.6033, 0.6327, 0.6196, 0.6646, 0.6178, 0.6303, 0.6562, 0.6150,
        0.6106, 0.5804, 0.5726, 0.5632, 0.5991, 0.6021, 0.6205],
       device='cuda:0') torch.Size([16])
percent tensor([0.4990, 0.5551, 0.7413, 0.6556, 0.7978, 0.7552, 0.5789, 0.6982, 0.6689,
        0.5537, 0.6948, 0.5568, 0.5760, 0.6045, 0.5251, 0.4784],
       device='cuda:0') torch.Size([16])
percent tensor([0.9994, 0.9990, 0.9996, 0.9992, 0.9994, 0.9992, 0.9990, 0.9996, 0.9998,
        0.9992, 0.9999, 0.9996, 0.9996, 0.9987, 0.9994, 0.9993],
       device='cuda:0') torch.Size([16])
Epoch: 124 | Batch_idx: 0 |  Loss: (0.1619) |  Loss2: (0.0000) | Acc: (96.00%) (123/128)
Epoch: 124 | Batch_idx: 10 |  Loss: (0.1784) |  Loss2: (0.0000) | Acc: (94.00%) (1326/1408)
Epoch: 124 | Batch_idx: 20 |  Loss: (0.1646) |  Loss2: (0.0000) | Acc: (94.00%) (2539/2688)
Epoch: 124 | Batch_idx: 30 |  Loss: (0.1570) |  Loss2: (0.0000) | Acc: (94.00%) (3762/3968)
Epoch: 124 | Batch_idx: 40 |  Loss: (0.1579) |  Loss2: (0.0000) | Acc: (94.00%) (4972/5248)
Epoch: 124 | Batch_idx: 50 |  Loss: (0.1623) |  Loss2: (0.0000) | Acc: (94.00%) (6169/6528)
Epoch: 124 | Batch_idx: 60 |  Loss: (0.1620) |  Loss2: (0.0000) | Acc: (94.00%) (7384/7808)
Epoch: 124 | Batch_idx: 70 |  Loss: (0.1623) |  Loss2: (0.0000) | Acc: (94.00%) (8588/9088)
Epoch: 124 | Batch_idx: 80 |  Loss: (0.1627) |  Loss2: (0.0000) | Acc: (94.00%) (9796/10368)
Epoch: 124 | Batch_idx: 90 |  Loss: (0.1609) |  Loss2: (0.0000) | Acc: (94.00%) (11015/11648)
Epoch: 124 | Batch_idx: 100 |  Loss: (0.1617) |  Loss2: (0.0000) | Acc: (94.00%) (12228/12928)
Epoch: 124 | Batch_idx: 110 |  Loss: (0.1643) |  Loss2: (0.0000) | Acc: (94.00%) (13414/14208)
Epoch: 124 | Batch_idx: 120 |  Loss: (0.1648) |  Loss2: (0.0000) | Acc: (94.00%) (14618/15488)
Epoch: 124 | Batch_idx: 130 |  Loss: (0.1637) |  Loss2: (0.0000) | Acc: (94.00%) (15835/16768)
Epoch: 124 | Batch_idx: 140 |  Loss: (0.1631) |  Loss2: (0.0000) | Acc: (94.00%) (17047/18048)
Epoch: 124 | Batch_idx: 150 |  Loss: (0.1633) |  Loss2: (0.0000) | Acc: (94.00%) (18261/19328)
Epoch: 124 | Batch_idx: 160 |  Loss: (0.1639) |  Loss2: (0.0000) | Acc: (94.00%) (19460/20608)
Epoch: 124 | Batch_idx: 170 |  Loss: (0.1632) |  Loss2: (0.0000) | Acc: (94.00%) (20673/21888)
Epoch: 124 | Batch_idx: 180 |  Loss: (0.1641) |  Loss2: (0.0000) | Acc: (94.00%) (21871/23168)
Epoch: 124 | Batch_idx: 190 |  Loss: (0.1643) |  Loss2: (0.0000) | Acc: (94.00%) (23083/24448)
Epoch: 124 | Batch_idx: 200 |  Loss: (0.1648) |  Loss2: (0.0000) | Acc: (94.00%) (24284/25728)
Epoch: 124 | Batch_idx: 210 |  Loss: (0.1657) |  Loss2: (0.0000) | Acc: (94.00%) (25483/27008)
Epoch: 124 | Batch_idx: 220 |  Loss: (0.1669) |  Loss2: (0.0000) | Acc: (94.00%) (26694/28288)
Epoch: 124 | Batch_idx: 230 |  Loss: (0.1668) |  Loss2: (0.0000) | Acc: (94.00%) (27908/29568)
Epoch: 124 | Batch_idx: 240 |  Loss: (0.1661) |  Loss2: (0.0000) | Acc: (94.00%) (29120/30848)
Epoch: 124 | Batch_idx: 250 |  Loss: (0.1654) |  Loss2: (0.0000) | Acc: (94.00%) (30335/32128)
Epoch: 124 | Batch_idx: 260 |  Loss: (0.1645) |  Loss2: (0.0000) | Acc: (94.00%) (31553/33408)
Epoch: 124 | Batch_idx: 270 |  Loss: (0.1645) |  Loss2: (0.0000) | Acc: (94.00%) (32756/34688)
Epoch: 124 | Batch_idx: 280 |  Loss: (0.1646) |  Loss2: (0.0000) | Acc: (94.00%) (33966/35968)
Epoch: 124 | Batch_idx: 290 |  Loss: (0.1645) |  Loss2: (0.0000) | Acc: (94.00%) (35178/37248)
Epoch: 124 | Batch_idx: 300 |  Loss: (0.1647) |  Loss2: (0.0000) | Acc: (94.00%) (36391/38528)
Epoch: 124 | Batch_idx: 310 |  Loss: (0.1648) |  Loss2: (0.0000) | Acc: (94.00%) (37593/39808)
Epoch: 124 | Batch_idx: 320 |  Loss: (0.1652) |  Loss2: (0.0000) | Acc: (94.00%) (38790/41088)
Epoch: 124 | Batch_idx: 330 |  Loss: (0.1649) |  Loss2: (0.0000) | Acc: (94.00%) (40005/42368)
Epoch: 124 | Batch_idx: 340 |  Loss: (0.1649) |  Loss2: (0.0000) | Acc: (94.00%) (41209/43648)
Epoch: 124 | Batch_idx: 350 |  Loss: (0.1646) |  Loss2: (0.0000) | Acc: (94.00%) (42418/44928)
Epoch: 124 | Batch_idx: 360 |  Loss: (0.1646) |  Loss2: (0.0000) | Acc: (94.00%) (43631/46208)
Epoch: 124 | Batch_idx: 370 |  Loss: (0.1643) |  Loss2: (0.0000) | Acc: (94.00%) (44844/47488)
Epoch: 124 | Batch_idx: 380 |  Loss: (0.1638) |  Loss2: (0.0000) | Acc: (94.00%) (46066/48768)
Epoch: 124 | Batch_idx: 390 |  Loss: (0.1638) |  Loss2: (0.0000) | Acc: (94.00%) (47236/50000)
# TEST : Loss: (0.3692) | Acc: (88.00%) (8829/10000)
percent tensor([0.5197, 0.5094, 0.5199, 0.5131, 0.5231, 0.5253, 0.5157, 0.5157, 0.5221,
        0.5127, 0.5218, 0.5162, 0.5125, 0.5152, 0.5155, 0.5164],
       device='cuda:0') torch.Size([16])
percent tensor([0.5012, 0.4948, 0.5067, 0.5042, 0.5020, 0.4997, 0.4986, 0.5049, 0.5067,
        0.4996, 0.5038, 0.5016, 0.4970, 0.5064, 0.4949, 0.5012],
       device='cuda:0') torch.Size([16])
percent tensor([0.5638, 0.5518, 0.5583, 0.5630, 0.5709, 0.5595, 0.5681, 0.5635, 0.5615,
        0.5594, 0.5615, 0.5615, 0.5262, 0.6040, 0.5475, 0.5698],
       device='cuda:0') torch.Size([16])
percent tensor([0.5974, 0.6171, 0.5955, 0.5861, 0.5861, 0.5891, 0.6089, 0.5832, 0.6130,
        0.6246, 0.6300, 0.6186, 0.6189, 0.6232, 0.5936, 0.6053],
       device='cuda:0') torch.Size([16])
percent tensor([0.6100, 0.6696, 0.4912, 0.5832, 0.5211, 0.6383, 0.6033, 0.3660, 0.6844,
        0.6416, 0.7103, 0.6024, 0.6646, 0.6911, 0.5589, 0.6246],
       device='cuda:0') torch.Size([16])
percent tensor([0.6026, 0.6043, 0.6338, 0.6206, 0.6669, 0.6188, 0.6317, 0.6586, 0.6167,
        0.6117, 0.5809, 0.5726, 0.5641, 0.5998, 0.6018, 0.6215],
       device='cuda:0') torch.Size([16])
percent tensor([0.5008, 0.5542, 0.7349, 0.6502, 0.7956, 0.7552, 0.5780, 0.6955, 0.6682,
        0.5553, 0.6957, 0.5512, 0.5776, 0.6078, 0.5240, 0.4778],
       device='cuda:0') torch.Size([16])
percent tensor([0.9995, 0.9991, 0.9997, 0.9992, 0.9994, 0.9993, 0.9990, 0.9997, 0.9999,
        0.9993, 0.9999, 0.9997, 0.9996, 0.9987, 0.9994, 0.9993],
       device='cuda:0') torch.Size([16])
Epoch: 125 | Batch_idx: 0 |  Loss: (0.2708) |  Loss2: (0.0000) | Acc: (92.00%) (118/128)
Epoch: 125 | Batch_idx: 10 |  Loss: (0.1599) |  Loss2: (0.0000) | Acc: (94.00%) (1335/1408)
Epoch: 125 | Batch_idx: 20 |  Loss: (0.1557) |  Loss2: (0.0000) | Acc: (95.00%) (2554/2688)
Epoch: 125 | Batch_idx: 30 |  Loss: (0.1605) |  Loss2: (0.0000) | Acc: (94.00%) (3762/3968)
Epoch: 125 | Batch_idx: 40 |  Loss: (0.1665) |  Loss2: (0.0000) | Acc: (94.00%) (4961/5248)
Epoch: 125 | Batch_idx: 50 |  Loss: (0.1651) |  Loss2: (0.0000) | Acc: (94.00%) (6168/6528)
Epoch: 125 | Batch_idx: 60 |  Loss: (0.1649) |  Loss2: (0.0000) | Acc: (94.00%) (7381/7808)
Epoch: 125 | Batch_idx: 70 |  Loss: (0.1628) |  Loss2: (0.0000) | Acc: (94.00%) (8590/9088)
Epoch: 125 | Batch_idx: 80 |  Loss: (0.1642) |  Loss2: (0.0000) | Acc: (94.00%) (9798/10368)
Epoch: 125 | Batch_idx: 90 |  Loss: (0.1635) |  Loss2: (0.0000) | Acc: (94.00%) (11012/11648)
Epoch: 125 | Batch_idx: 100 |  Loss: (0.1643) |  Loss2: (0.0000) | Acc: (94.00%) (12218/12928)
Epoch: 125 | Batch_idx: 110 |  Loss: (0.1642) |  Loss2: (0.0000) | Acc: (94.00%) (13431/14208)
Epoch: 125 | Batch_idx: 120 |  Loss: (0.1652) |  Loss2: (0.0000) | Acc: (94.00%) (14631/15488)
Epoch: 125 | Batch_idx: 130 |  Loss: (0.1635) |  Loss2: (0.0000) | Acc: (94.00%) (15849/16768)
Epoch: 125 | Batch_idx: 140 |  Loss: (0.1634) |  Loss2: (0.0000) | Acc: (94.00%) (17051/18048)
Epoch: 125 | Batch_idx: 150 |  Loss: (0.1639) |  Loss2: (0.0000) | Acc: (94.00%) (18260/19328)
Epoch: 125 | Batch_idx: 160 |  Loss: (0.1632) |  Loss2: (0.0000) | Acc: (94.00%) (19469/20608)
Epoch: 125 | Batch_idx: 170 |  Loss: (0.1639) |  Loss2: (0.0000) | Acc: (94.00%) (20677/21888)
Epoch: 125 | Batch_idx: 180 |  Loss: (0.1623) |  Loss2: (0.0000) | Acc: (94.00%) (21904/23168)
Epoch: 125 | Batch_idx: 190 |  Loss: (0.1628) |  Loss2: (0.0000) | Acc: (94.00%) (23103/24448)
Epoch: 125 | Batch_idx: 200 |  Loss: (0.1630) |  Loss2: (0.0000) | Acc: (94.00%) (24314/25728)
Epoch: 125 | Batch_idx: 210 |  Loss: (0.1645) |  Loss2: (0.0000) | Acc: (94.00%) (25508/27008)
Epoch: 125 | Batch_idx: 220 |  Loss: (0.1649) |  Loss2: (0.0000) | Acc: (94.00%) (26714/28288)
Epoch: 125 | Batch_idx: 230 |  Loss: (0.1644) |  Loss2: (0.0000) | Acc: (94.00%) (27930/29568)
Epoch: 125 | Batch_idx: 240 |  Loss: (0.1638) |  Loss2: (0.0000) | Acc: (94.00%) (29147/30848)
Epoch: 125 | Batch_idx: 250 |  Loss: (0.1644) |  Loss2: (0.0000) | Acc: (94.00%) (30349/32128)
Epoch: 125 | Batch_idx: 260 |  Loss: (0.1655) |  Loss2: (0.0000) | Acc: (94.00%) (31553/33408)
Epoch: 125 | Batch_idx: 270 |  Loss: (0.1658) |  Loss2: (0.0000) | Acc: (94.00%) (32759/34688)
Epoch: 125 | Batch_idx: 280 |  Loss: (0.1656) |  Loss2: (0.0000) | Acc: (94.00%) (33969/35968)
Epoch: 125 | Batch_idx: 290 |  Loss: (0.1657) |  Loss2: (0.0000) | Acc: (94.00%) (35177/37248)
Epoch: 125 | Batch_idx: 300 |  Loss: (0.1662) |  Loss2: (0.0000) | Acc: (94.00%) (36380/38528)
Epoch: 125 | Batch_idx: 310 |  Loss: (0.1669) |  Loss2: (0.0000) | Acc: (94.00%) (37575/39808)
Epoch: 125 | Batch_idx: 320 |  Loss: (0.1672) |  Loss2: (0.0000) | Acc: (94.00%) (38785/41088)
Epoch: 125 | Batch_idx: 330 |  Loss: (0.1670) |  Loss2: (0.0000) | Acc: (94.00%) (39993/42368)
Epoch: 125 | Batch_idx: 340 |  Loss: (0.1665) |  Loss2: (0.0000) | Acc: (94.00%) (41203/43648)
Epoch: 125 | Batch_idx: 350 |  Loss: (0.1661) |  Loss2: (0.0000) | Acc: (94.00%) (42421/44928)
Epoch: 125 | Batch_idx: 360 |  Loss: (0.1658) |  Loss2: (0.0000) | Acc: (94.00%) (43632/46208)
Epoch: 125 | Batch_idx: 370 |  Loss: (0.1657) |  Loss2: (0.0000) | Acc: (94.00%) (44849/47488)
Epoch: 125 | Batch_idx: 380 |  Loss: (0.1660) |  Loss2: (0.0000) | Acc: (94.00%) (46060/48768)
Epoch: 125 | Batch_idx: 390 |  Loss: (0.1660) |  Loss2: (0.0000) | Acc: (94.00%) (47224/50000)
=> saving checkpoint 'drive/app/torch/save_Schedule/checkpoint_125.pth.tar'
# TEST : Loss: (0.3690) | Acc: (88.00%) (8826/10000)
percent tensor([0.5177, 0.5069, 0.5182, 0.5113, 0.5211, 0.5238, 0.5134, 0.5136, 0.5199,
        0.5103, 0.5195, 0.5140, 0.5102, 0.5130, 0.5133, 0.5143],
       device='cuda:0') torch.Size([16])
percent tensor([0.5020, 0.4956, 0.5074, 0.5048, 0.5027, 0.5003, 0.4994, 0.5056, 0.5075,
        0.5005, 0.5047, 0.5024, 0.4978, 0.5072, 0.4957, 0.5019],
       device='cuda:0') torch.Size([16])
percent tensor([0.5584, 0.5465, 0.5534, 0.5580, 0.5657, 0.5544, 0.5630, 0.5578, 0.5555,
        0.5544, 0.5562, 0.5566, 0.5205, 0.5993, 0.5420, 0.5652],
       device='cuda:0') torch.Size([16])
percent tensor([0.5986, 0.6185, 0.5969, 0.5874, 0.5872, 0.5903, 0.6104, 0.5845, 0.6146,
        0.6261, 0.6316, 0.6203, 0.6206, 0.6249, 0.5951, 0.6065],
       device='cuda:0') torch.Size([16])
percent tensor([0.6065, 0.6655, 0.4910, 0.5875, 0.5187, 0.6405, 0.5967, 0.3644, 0.6831,
        0.6362, 0.7069, 0.5980, 0.6596, 0.6888, 0.5537, 0.6223],
       device='cuda:0') torch.Size([16])
percent tensor([0.6061, 0.6075, 0.6363, 0.6232, 0.6701, 0.6219, 0.6344, 0.6608, 0.6197,
        0.6150, 0.5839, 0.5751, 0.5678, 0.6028, 0.6037, 0.6246],
       device='cuda:0') torch.Size([16])
percent tensor([0.4967, 0.5490, 0.7291, 0.6400, 0.7909, 0.7546, 0.5714, 0.6892, 0.6623,
        0.5517, 0.6945, 0.5454, 0.5781, 0.6040, 0.5213, 0.4723],
       device='cuda:0') torch.Size([16])
percent tensor([0.9995, 0.9991, 0.9997, 0.9993, 0.9995, 0.9992, 0.9991, 0.9997, 0.9999,
        0.9993, 0.9999, 0.9997, 0.9996, 0.9988, 0.9994, 0.9993],
       device='cuda:0') torch.Size([16])
True Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=128, out_features=16, bias=False)
False Linear(in_features=16, out_features=2, bias=False)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=128, out_features=16, bias=False)
False Linear(in_features=16, out_features=2, bias=False)
True Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=256, out_features=32, bias=False)
False Linear(in_features=32, out_features=2, bias=False)
True Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=256, out_features=32, bias=False)
False Linear(in_features=32, out_features=2, bias=False)
True Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=512, out_features=64, bias=False)
False Linear(in_features=64, out_features=2, bias=False)
True Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=512, out_features=64, bias=False)
False Linear(in_features=64, out_features=2, bias=False)
True Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1024, out_features=128, bias=False)
False Linear(in_features=128, out_features=2, bias=False)
True Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1024, out_features=128, bias=False)
False Linear(in_features=128, out_features=2, bias=False)
True Linear(in_features=512, out_features=10, bias=True)
Epoch: 126 | Batch_idx: 0 |  Loss: (0.2038) |  Loss2: (0.0000) | Acc: (92.00%) (118/128)
Epoch: 126 | Batch_idx: 10 |  Loss: (0.1772) |  Loss2: (0.0000) | Acc: (93.00%) (1315/1408)
Epoch: 126 | Batch_idx: 20 |  Loss: (0.1869) |  Loss2: (0.0000) | Acc: (93.00%) (2508/2688)
Epoch: 126 | Batch_idx: 30 |  Loss: (0.1811) |  Loss2: (0.0000) | Acc: (93.00%) (3708/3968)
Epoch: 126 | Batch_idx: 40 |  Loss: (0.1821) |  Loss2: (0.0000) | Acc: (93.00%) (4910/5248)
Epoch: 126 | Batch_idx: 50 |  Loss: (0.1863) |  Loss2: (0.0000) | Acc: (93.00%) (6098/6528)
Epoch: 126 | Batch_idx: 60 |  Loss: (0.1873) |  Loss2: (0.0000) | Acc: (93.00%) (7300/7808)
Epoch: 126 | Batch_idx: 70 |  Loss: (0.1857) |  Loss2: (0.0000) | Acc: (93.00%) (8504/9088)
Epoch: 126 | Batch_idx: 80 |  Loss: (0.1852) |  Loss2: (0.0000) | Acc: (93.00%) (9712/10368)
Epoch: 126 | Batch_idx: 90 |  Loss: (0.1844) |  Loss2: (0.0000) | Acc: (93.00%) (10911/11648)
Epoch: 126 | Batch_idx: 100 |  Loss: (0.1828) |  Loss2: (0.0000) | Acc: (93.00%) (12103/12928)
Epoch: 126 | Batch_idx: 110 |  Loss: (0.1835) |  Loss2: (0.0000) | Acc: (93.00%) (13304/14208)
Epoch: 126 | Batch_idx: 120 |  Loss: (0.1841) |  Loss2: (0.0000) | Acc: (93.00%) (14504/15488)
Epoch: 126 | Batch_idx: 130 |  Loss: (0.1842) |  Loss2: (0.0000) | Acc: (93.00%) (15701/16768)
Epoch: 126 | Batch_idx: 140 |  Loss: (0.1854) |  Loss2: (0.0000) | Acc: (93.00%) (16891/18048)
Epoch: 126 | Batch_idx: 150 |  Loss: (0.1877) |  Loss2: (0.0000) | Acc: (93.00%) (18073/19328)
Epoch: 126 | Batch_idx: 160 |  Loss: (0.1854) |  Loss2: (0.0000) | Acc: (93.00%) (19286/20608)
Epoch: 126 | Batch_idx: 170 |  Loss: (0.1860) |  Loss2: (0.0000) | Acc: (93.00%) (20477/21888)
Epoch: 126 | Batch_idx: 180 |  Loss: (0.1858) |  Loss2: (0.0000) | Acc: (93.00%) (21672/23168)
Epoch: 126 | Batch_idx: 190 |  Loss: (0.1850) |  Loss2: (0.0000) | Acc: (93.00%) (22879/24448)
Epoch: 126 | Batch_idx: 200 |  Loss: (0.1861) |  Loss2: (0.0000) | Acc: (93.00%) (24057/25728)
Epoch: 126 | Batch_idx: 210 |  Loss: (0.1848) |  Loss2: (0.0000) | Acc: (93.00%) (25270/27008)
Epoch: 126 | Batch_idx: 220 |  Loss: (0.1839) |  Loss2: (0.0000) | Acc: (93.00%) (26480/28288)
Epoch: 126 | Batch_idx: 230 |  Loss: (0.1842) |  Loss2: (0.0000) | Acc: (93.00%) (27670/29568)
Epoch: 126 | Batch_idx: 240 |  Loss: (0.1840) |  Loss2: (0.0000) | Acc: (93.00%) (28866/30848)
Epoch: 126 | Batch_idx: 250 |  Loss: (0.1836) |  Loss2: (0.0000) | Acc: (93.00%) (30074/32128)
Epoch: 126 | Batch_idx: 260 |  Loss: (0.1831) |  Loss2: (0.0000) | Acc: (93.00%) (31273/33408)
Epoch: 126 | Batch_idx: 270 |  Loss: (0.1822) |  Loss2: (0.0000) | Acc: (93.00%) (32489/34688)
Epoch: 126 | Batch_idx: 280 |  Loss: (0.1825) |  Loss2: (0.0000) | Acc: (93.00%) (33681/35968)
Epoch: 126 | Batch_idx: 290 |  Loss: (0.1828) |  Loss2: (0.0000) | Acc: (93.00%) (34869/37248)
Epoch: 126 | Batch_idx: 300 |  Loss: (0.1833) |  Loss2: (0.0000) | Acc: (93.00%) (36062/38528)
Epoch: 126 | Batch_idx: 310 |  Loss: (0.1841) |  Loss2: (0.0000) | Acc: (93.00%) (37239/39808)
Epoch: 126 | Batch_idx: 320 |  Loss: (0.1844) |  Loss2: (0.0000) | Acc: (93.00%) (38427/41088)
Epoch: 126 | Batch_idx: 330 |  Loss: (0.1832) |  Loss2: (0.0000) | Acc: (93.00%) (39640/42368)
Epoch: 126 | Batch_idx: 340 |  Loss: (0.1836) |  Loss2: (0.0000) | Acc: (93.00%) (40832/43648)
Epoch: 126 | Batch_idx: 350 |  Loss: (0.1844) |  Loss2: (0.0000) | Acc: (93.00%) (42027/44928)
Epoch: 126 | Batch_idx: 360 |  Loss: (0.1844) |  Loss2: (0.0000) | Acc: (93.00%) (43220/46208)
Epoch: 126 | Batch_idx: 370 |  Loss: (0.1844) |  Loss2: (0.0000) | Acc: (93.00%) (44426/47488)
Epoch: 126 | Batch_idx: 380 |  Loss: (0.1847) |  Loss2: (0.0000) | Acc: (93.00%) (45622/48768)
Epoch: 126 | Batch_idx: 390 |  Loss: (0.1842) |  Loss2: (0.0000) | Acc: (93.00%) (46786/50000)
# TEST : Loss: (0.4036) | Acc: (87.00%) (8741/10000)
percent tensor([0.5179, 0.5068, 0.5196, 0.5119, 0.5223, 0.5242, 0.5141, 0.5143, 0.5207,
        0.5104, 0.5194, 0.5154, 0.5100, 0.5137, 0.5135, 0.5146],
       device='cuda:0') torch.Size([16])
percent tensor([0.5015, 0.4957, 0.5044, 0.5042, 0.5007, 0.4995, 0.4985, 0.5045, 0.5071,
        0.5002, 0.5046, 0.4998, 0.4968, 0.5069, 0.4958, 0.5022],
       device='cuda:0') torch.Size([16])
percent tensor([0.5582, 0.5532, 0.5482, 0.5593, 0.5620, 0.5490, 0.5646, 0.5620, 0.5574,
        0.5610, 0.5597, 0.5518, 0.5225, 0.6010, 0.5454, 0.5694],
       device='cuda:0') torch.Size([16])
percent tensor([0.5984, 0.6189, 0.5935, 0.5882, 0.5853, 0.5934, 0.6097, 0.5824, 0.6120,
        0.6235, 0.6305, 0.6156, 0.6173, 0.6233, 0.5957, 0.6064],
       device='cuda:0') torch.Size([16])
percent tensor([0.6044, 0.6485, 0.4897, 0.5904, 0.5220, 0.6663, 0.6005, 0.3539, 0.6719,
        0.6219, 0.6914, 0.5948, 0.6405, 0.6735, 0.5610, 0.6125],
       device='cuda:0') torch.Size([16])
percent tensor([0.6085, 0.6136, 0.6366, 0.6215, 0.6618, 0.6098, 0.6295, 0.6599, 0.6222,
        0.6211, 0.5924, 0.5825, 0.5719, 0.6030, 0.6064, 0.6200],
       device='cuda:0') torch.Size([16])
percent tensor([0.4813, 0.5593, 0.7310, 0.6758, 0.7910, 0.7421, 0.6025, 0.7014, 0.6375,
        0.5414, 0.6570, 0.5719, 0.5642, 0.5889, 0.5268, 0.4926],
       device='cuda:0') torch.Size([16])
percent tensor([0.9995, 0.9990, 0.9997, 0.9996, 0.9992, 0.9992, 0.9991, 0.9996, 0.9997,
        0.9993, 0.9998, 0.9998, 0.9997, 0.9987, 0.9994, 0.9995],
       device='cuda:0') torch.Size([16])
Epoch: 127 | Batch_idx: 0 |  Loss: (0.2008) |  Loss2: (0.0000) | Acc: (96.00%) (123/128)
Epoch: 127 | Batch_idx: 10 |  Loss: (0.1647) |  Loss2: (0.0000) | Acc: (94.00%) (1329/1408)
Epoch: 127 | Batch_idx: 20 |  Loss: (0.1693) |  Loss2: (0.0000) | Acc: (94.00%) (2535/2688)
Epoch: 127 | Batch_idx: 30 |  Loss: (0.1707) |  Loss2: (0.0000) | Acc: (94.00%) (3739/3968)
Epoch: 127 | Batch_idx: 40 |  Loss: (0.1703) |  Loss2: (0.0000) | Acc: (94.00%) (4940/5248)
Epoch: 127 | Batch_idx: 50 |  Loss: (0.1695) |  Loss2: (0.0000) | Acc: (94.00%) (6159/6528)
Epoch: 127 | Batch_idx: 60 |  Loss: (0.1724) |  Loss2: (0.0000) | Acc: (94.00%) (7359/7808)
Epoch: 127 | Batch_idx: 70 |  Loss: (0.1736) |  Loss2: (0.0000) | Acc: (94.00%) (8562/9088)
Epoch: 127 | Batch_idx: 80 |  Loss: (0.1752) |  Loss2: (0.0000) | Acc: (94.00%) (9765/10368)
Epoch: 127 | Batch_idx: 90 |  Loss: (0.1748) |  Loss2: (0.0000) | Acc: (94.00%) (10973/11648)
Epoch: 127 | Batch_idx: 100 |  Loss: (0.1734) |  Loss2: (0.0000) | Acc: (94.00%) (12183/12928)
Epoch: 127 | Batch_idx: 110 |  Loss: (0.1738) |  Loss2: (0.0000) | Acc: (94.00%) (13384/14208)
Epoch: 127 | Batch_idx: 120 |  Loss: (0.1723) |  Loss2: (0.0000) | Acc: (94.00%) (14600/15488)
Epoch: 127 | Batch_idx: 130 |  Loss: (0.1734) |  Loss2: (0.0000) | Acc: (94.00%) (15799/16768)
Epoch: 127 | Batch_idx: 140 |  Loss: (0.1742) |  Loss2: (0.0000) | Acc: (94.00%) (16990/18048)
Epoch: 127 | Batch_idx: 150 |  Loss: (0.1745) |  Loss2: (0.0000) | Acc: (94.00%) (18192/19328)
Epoch: 127 | Batch_idx: 160 |  Loss: (0.1726) |  Loss2: (0.0000) | Acc: (94.00%) (19422/20608)
Epoch: 127 | Batch_idx: 170 |  Loss: (0.1723) |  Loss2: (0.0000) | Acc: (94.00%) (20638/21888)
Epoch: 127 | Batch_idx: 180 |  Loss: (0.1728) |  Loss2: (0.0000) | Acc: (94.00%) (21832/23168)
Epoch: 127 | Batch_idx: 190 |  Loss: (0.1738) |  Loss2: (0.0000) | Acc: (94.00%) (23016/24448)
Epoch: 127 | Batch_idx: 200 |  Loss: (0.1731) |  Loss2: (0.0000) | Acc: (94.00%) (24229/25728)
Epoch: 127 | Batch_idx: 210 |  Loss: (0.1727) |  Loss2: (0.0000) | Acc: (94.00%) (25435/27008)
Epoch: 127 | Batch_idx: 220 |  Loss: (0.1737) |  Loss2: (0.0000) | Acc: (94.00%) (26620/28288)
Epoch: 127 | Batch_idx: 230 |  Loss: (0.1739) |  Loss2: (0.0000) | Acc: (94.00%) (27825/29568)
Epoch: 127 | Batch_idx: 240 |  Loss: (0.1741) |  Loss2: (0.0000) | Acc: (94.00%) (29025/30848)
Epoch: 127 | Batch_idx: 250 |  Loss: (0.1749) |  Loss2: (0.0000) | Acc: (94.00%) (30216/32128)
Epoch: 127 | Batch_idx: 260 |  Loss: (0.1753) |  Loss2: (0.0000) | Acc: (94.00%) (31418/33408)
Epoch: 127 | Batch_idx: 270 |  Loss: (0.1756) |  Loss2: (0.0000) | Acc: (94.00%) (32621/34688)
Epoch: 127 | Batch_idx: 280 |  Loss: (0.1765) |  Loss2: (0.0000) | Acc: (94.00%) (33810/35968)
Epoch: 127 | Batch_idx: 290 |  Loss: (0.1774) |  Loss2: (0.0000) | Acc: (93.00%) (35003/37248)
Epoch: 127 | Batch_idx: 300 |  Loss: (0.1783) |  Loss2: (0.0000) | Acc: (93.00%) (36190/38528)
Epoch: 127 | Batch_idx: 310 |  Loss: (0.1793) |  Loss2: (0.0000) | Acc: (93.00%) (37375/39808)
Epoch: 127 | Batch_idx: 320 |  Loss: (0.1796) |  Loss2: (0.0000) | Acc: (93.00%) (38571/41088)
Epoch: 127 | Batch_idx: 330 |  Loss: (0.1794) |  Loss2: (0.0000) | Acc: (93.00%) (39779/42368)
Epoch: 127 | Batch_idx: 340 |  Loss: (0.1804) |  Loss2: (0.0000) | Acc: (93.00%) (40964/43648)
Epoch: 127 | Batch_idx: 350 |  Loss: (0.1810) |  Loss2: (0.0000) | Acc: (93.00%) (42157/44928)
Epoch: 127 | Batch_idx: 360 |  Loss: (0.1808) |  Loss2: (0.0000) | Acc: (93.00%) (43359/46208)
Epoch: 127 | Batch_idx: 370 |  Loss: (0.1808) |  Loss2: (0.0000) | Acc: (93.00%) (44562/47488)
Epoch: 127 | Batch_idx: 380 |  Loss: (0.1808) |  Loss2: (0.0000) | Acc: (93.00%) (45763/48768)
Epoch: 127 | Batch_idx: 390 |  Loss: (0.1817) |  Loss2: (0.0000) | Acc: (93.00%) (46907/50000)
# TEST : Loss: (0.3925) | Acc: (87.00%) (8767/10000)
percent tensor([0.5191, 0.5070, 0.5216, 0.5123, 0.5238, 0.5248, 0.5146, 0.5151, 0.5211,
        0.5115, 0.5202, 0.5175, 0.5109, 0.5128, 0.5142, 0.5154],
       device='cuda:0') torch.Size([16])
percent tensor([0.5020, 0.4955, 0.5051, 0.5048, 0.5016, 0.5003, 0.4986, 0.5052, 0.5078,
        0.4999, 0.5048, 0.5002, 0.4973, 0.5076, 0.4958, 0.5032],
       device='cuda:0') torch.Size([16])
percent tensor([0.5608, 0.5478, 0.5460, 0.5637, 0.5613, 0.5579, 0.5655, 0.5584, 0.5599,
        0.5553, 0.5612, 0.5509, 0.5227, 0.6063, 0.5463, 0.5730],
       device='cuda:0') torch.Size([16])
percent tensor([0.6022, 0.6244, 0.5950, 0.5864, 0.5855, 0.5932, 0.6142, 0.5833, 0.6208,
        0.6275, 0.6368, 0.6185, 0.6237, 0.6284, 0.5963, 0.6097],
       device='cuda:0') torch.Size([16])
percent tensor([0.6079, 0.6680, 0.4661, 0.5873, 0.4997, 0.6397, 0.6029, 0.3722, 0.6858,
        0.6394, 0.7158, 0.5761, 0.6755, 0.6794, 0.5617, 0.6207],
       device='cuda:0') torch.Size([16])
percent tensor([0.6045, 0.5930, 0.6287, 0.6187, 0.6616, 0.6123, 0.6261, 0.6544, 0.6105,
        0.6065, 0.5840, 0.5757, 0.5607, 0.6012, 0.6061, 0.6198],
       device='cuda:0') torch.Size([16])
percent tensor([0.4753, 0.5547, 0.7081, 0.6549, 0.7771, 0.7261, 0.5691, 0.6859, 0.6011,
        0.5461, 0.6591, 0.5414, 0.5861, 0.5688, 0.5366, 0.4811],
       device='cuda:0') torch.Size([16])
percent tensor([0.9996, 0.9993, 0.9995, 0.9994, 0.9990, 0.9993, 0.9992, 0.9997, 0.9998,
        0.9996, 0.9999, 0.9996, 0.9998, 0.9987, 0.9991, 0.9993],
       device='cuda:0') torch.Size([16])
Epoch: 128 | Batch_idx: 0 |  Loss: (0.1755) |  Loss2: (0.0000) | Acc: (92.00%) (118/128)
Epoch: 128 | Batch_idx: 10 |  Loss: (0.1564) |  Loss2: (0.0000) | Acc: (95.00%) (1341/1408)
Epoch: 128 | Batch_idx: 20 |  Loss: (0.1659) |  Loss2: (0.0000) | Acc: (94.00%) (2548/2688)
Epoch: 128 | Batch_idx: 30 |  Loss: (0.1630) |  Loss2: (0.0000) | Acc: (94.00%) (3766/3968)
Epoch: 128 | Batch_idx: 40 |  Loss: (0.1578) |  Loss2: (0.0000) | Acc: (95.00%) (4986/5248)
Epoch: 128 | Batch_idx: 50 |  Loss: (0.1559) |  Loss2: (0.0000) | Acc: (95.00%) (6204/6528)
Epoch: 128 | Batch_idx: 60 |  Loss: (0.1594) |  Loss2: (0.0000) | Acc: (94.00%) (7403/7808)
Epoch: 128 | Batch_idx: 70 |  Loss: (0.1611) |  Loss2: (0.0000) | Acc: (94.00%) (8603/9088)
Epoch: 128 | Batch_idx: 80 |  Loss: (0.1597) |  Loss2: (0.0000) | Acc: (94.00%) (9823/10368)
Epoch: 128 | Batch_idx: 90 |  Loss: (0.1644) |  Loss2: (0.0000) | Acc: (94.00%) (11007/11648)
Epoch: 128 | Batch_idx: 100 |  Loss: (0.1649) |  Loss2: (0.0000) | Acc: (94.00%) (12211/12928)
Epoch: 128 | Batch_idx: 110 |  Loss: (0.1669) |  Loss2: (0.0000) | Acc: (94.00%) (13405/14208)
Epoch: 128 | Batch_idx: 120 |  Loss: (0.1669) |  Loss2: (0.0000) | Acc: (94.00%) (14609/15488)
Epoch: 128 | Batch_idx: 130 |  Loss: (0.1674) |  Loss2: (0.0000) | Acc: (94.00%) (15810/16768)
Epoch: 128 | Batch_idx: 140 |  Loss: (0.1665) |  Loss2: (0.0000) | Acc: (94.00%) (17025/18048)
Epoch: 128 | Batch_idx: 150 |  Loss: (0.1656) |  Loss2: (0.0000) | Acc: (94.00%) (18236/19328)
Epoch: 128 | Batch_idx: 160 |  Loss: (0.1654) |  Loss2: (0.0000) | Acc: (94.00%) (19442/20608)
Epoch: 128 | Batch_idx: 170 |  Loss: (0.1665) |  Loss2: (0.0000) | Acc: (94.00%) (20641/21888)
Epoch: 128 | Batch_idx: 180 |  Loss: (0.1661) |  Loss2: (0.0000) | Acc: (94.00%) (21850/23168)
Epoch: 128 | Batch_idx: 190 |  Loss: (0.1665) |  Loss2: (0.0000) | Acc: (94.00%) (23047/24448)
Epoch: 128 | Batch_idx: 200 |  Loss: (0.1667) |  Loss2: (0.0000) | Acc: (94.00%) (24258/25728)
Epoch: 128 | Batch_idx: 210 |  Loss: (0.1665) |  Loss2: (0.0000) | Acc: (94.00%) (25467/27008)
Epoch: 128 | Batch_idx: 220 |  Loss: (0.1678) |  Loss2: (0.0000) | Acc: (94.00%) (26660/28288)
Epoch: 128 | Batch_idx: 230 |  Loss: (0.1684) |  Loss2: (0.0000) | Acc: (94.00%) (27855/29568)
Epoch: 128 | Batch_idx: 240 |  Loss: (0.1687) |  Loss2: (0.0000) | Acc: (94.00%) (29062/30848)
Epoch: 128 | Batch_idx: 250 |  Loss: (0.1691) |  Loss2: (0.0000) | Acc: (94.00%) (30258/32128)
Epoch: 128 | Batch_idx: 260 |  Loss: (0.1691) |  Loss2: (0.0000) | Acc: (94.00%) (31469/33408)
Epoch: 128 | Batch_idx: 270 |  Loss: (0.1697) |  Loss2: (0.0000) | Acc: (94.00%) (32669/34688)
Epoch: 128 | Batch_idx: 280 |  Loss: (0.1705) |  Loss2: (0.0000) | Acc: (94.00%) (33861/35968)
Epoch: 128 | Batch_idx: 290 |  Loss: (0.1709) |  Loss2: (0.0000) | Acc: (94.00%) (35052/37248)
Epoch: 128 | Batch_idx: 300 |  Loss: (0.1718) |  Loss2: (0.0000) | Acc: (94.00%) (36251/38528)
Epoch: 128 | Batch_idx: 310 |  Loss: (0.1720) |  Loss2: (0.0000) | Acc: (94.00%) (37457/39808)
Epoch: 128 | Batch_idx: 320 |  Loss: (0.1728) |  Loss2: (0.0000) | Acc: (94.00%) (38644/41088)
Epoch: 128 | Batch_idx: 330 |  Loss: (0.1734) |  Loss2: (0.0000) | Acc: (94.00%) (39838/42368)
Epoch: 128 | Batch_idx: 340 |  Loss: (0.1736) |  Loss2: (0.0000) | Acc: (94.00%) (41032/43648)
Epoch: 128 | Batch_idx: 350 |  Loss: (0.1736) |  Loss2: (0.0000) | Acc: (94.00%) (42233/44928)
Epoch: 128 | Batch_idx: 360 |  Loss: (0.1742) |  Loss2: (0.0000) | Acc: (93.00%) (43427/46208)
Epoch: 128 | Batch_idx: 370 |  Loss: (0.1742) |  Loss2: (0.0000) | Acc: (93.00%) (44625/47488)
Epoch: 128 | Batch_idx: 380 |  Loss: (0.1740) |  Loss2: (0.0000) | Acc: (93.00%) (45827/48768)
Epoch: 128 | Batch_idx: 390 |  Loss: (0.1741) |  Loss2: (0.0000) | Acc: (93.00%) (46984/50000)
# TEST : Loss: (0.4076) | Acc: (87.00%) (8719/10000)
percent tensor([0.5191, 0.5075, 0.5204, 0.5123, 0.5239, 0.5259, 0.5158, 0.5147, 0.5210,
        0.5116, 0.5201, 0.5172, 0.5111, 0.5152, 0.5144, 0.5155],
       device='cuda:0') torch.Size([16])
percent tensor([0.5020, 0.4961, 0.5069, 0.5047, 0.5024, 0.5001, 0.4997, 0.5056, 0.5075,
        0.5015, 0.5053, 0.5024, 0.4975, 0.5085, 0.4960, 0.5027],
       device='cuda:0') torch.Size([16])
percent tensor([0.5647, 0.5453, 0.5629, 0.5685, 0.5732, 0.5672, 0.5622, 0.5672, 0.5561,
        0.5582, 0.5582, 0.5580, 0.5232, 0.5968, 0.5474, 0.5720],
       device='cuda:0') torch.Size([16])
percent tensor([0.6010, 0.6203, 0.5990, 0.5890, 0.5869, 0.5949, 0.6112, 0.5838, 0.6167,
        0.6259, 0.6318, 0.6179, 0.6213, 0.6254, 0.5953, 0.6077],
       device='cuda:0') torch.Size([16])
percent tensor([0.6057, 0.6565, 0.4698, 0.5820, 0.4913, 0.6372, 0.6027, 0.3620, 0.6830,
        0.6349, 0.7098, 0.5772, 0.6513, 0.6941, 0.5536, 0.6132],
       device='cuda:0') torch.Size([16])
percent tensor([0.6105, 0.6033, 0.6341, 0.6197, 0.6710, 0.6139, 0.6284, 0.6578, 0.6135,
        0.6118, 0.5895, 0.5781, 0.5756, 0.5960, 0.6053, 0.6200],
       device='cuda:0') torch.Size([16])
percent tensor([0.4967, 0.5466, 0.7283, 0.6627, 0.7878, 0.7359, 0.5668, 0.6965, 0.6530,
        0.5215, 0.6656, 0.5641, 0.5751, 0.5777, 0.5334, 0.4791],
       device='cuda:0') torch.Size([16])
percent tensor([0.9995, 0.9991, 0.9996, 0.9997, 0.9992, 0.9995, 0.9993, 0.9997, 0.9998,
        0.9996, 0.9999, 0.9997, 0.9995, 0.9985, 0.9990, 0.9993],
       device='cuda:0') torch.Size([16])
Epoch: 129 | Batch_idx: 0 |  Loss: (0.1384) |  Loss2: (0.0000) | Acc: (96.00%) (123/128)
Epoch: 129 | Batch_idx: 10 |  Loss: (0.1647) |  Loss2: (0.0000) | Acc: (94.00%) (1337/1408)
Epoch: 129 | Batch_idx: 20 |  Loss: (0.1712) |  Loss2: (0.0000) | Acc: (94.00%) (2540/2688)
Epoch: 129 | Batch_idx: 30 |  Loss: (0.1673) |  Loss2: (0.0000) | Acc: (94.00%) (3747/3968)
Epoch: 129 | Batch_idx: 40 |  Loss: (0.1680) |  Loss2: (0.0000) | Acc: (94.00%) (4945/5248)
Epoch: 129 | Batch_idx: 50 |  Loss: (0.1725) |  Loss2: (0.0000) | Acc: (94.00%) (6138/6528)
Epoch: 129 | Batch_idx: 60 |  Loss: (0.1696) |  Loss2: (0.0000) | Acc: (94.00%) (7351/7808)
Epoch: 129 | Batch_idx: 70 |  Loss: (0.1695) |  Loss2: (0.0000) | Acc: (94.00%) (8556/9088)
Epoch: 129 | Batch_idx: 80 |  Loss: (0.1663) |  Loss2: (0.0000) | Acc: (94.00%) (9769/10368)
Epoch: 129 | Batch_idx: 90 |  Loss: (0.1648) |  Loss2: (0.0000) | Acc: (94.00%) (10981/11648)
Epoch: 129 | Batch_idx: 100 |  Loss: (0.1660) |  Loss2: (0.0000) | Acc: (94.00%) (12181/12928)
Epoch: 129 | Batch_idx: 110 |  Loss: (0.1652) |  Loss2: (0.0000) | Acc: (94.00%) (13397/14208)
Epoch: 129 | Batch_idx: 120 |  Loss: (0.1646) |  Loss2: (0.0000) | Acc: (94.00%) (14608/15488)
Epoch: 129 | Batch_idx: 130 |  Loss: (0.1661) |  Loss2: (0.0000) | Acc: (94.00%) (15803/16768)
Epoch: 129 | Batch_idx: 140 |  Loss: (0.1657) |  Loss2: (0.0000) | Acc: (94.00%) (17016/18048)
Epoch: 129 | Batch_idx: 150 |  Loss: (0.1668) |  Loss2: (0.0000) | Acc: (94.00%) (18208/19328)
Epoch: 129 | Batch_idx: 160 |  Loss: (0.1673) |  Loss2: (0.0000) | Acc: (94.00%) (19406/20608)
Epoch: 129 | Batch_idx: 170 |  Loss: (0.1671) |  Loss2: (0.0000) | Acc: (94.00%) (20607/21888)
Epoch: 129 | Batch_idx: 180 |  Loss: (0.1674) |  Loss2: (0.0000) | Acc: (94.00%) (21797/23168)
Epoch: 129 | Batch_idx: 190 |  Loss: (0.1686) |  Loss2: (0.0000) | Acc: (94.00%) (22999/24448)
Epoch: 129 | Batch_idx: 200 |  Loss: (0.1688) |  Loss2: (0.0000) | Acc: (94.00%) (24198/25728)
Epoch: 129 | Batch_idx: 210 |  Loss: (0.1703) |  Loss2: (0.0000) | Acc: (93.00%) (25386/27008)
Epoch: 129 | Batch_idx: 220 |  Loss: (0.1724) |  Loss2: (0.0000) | Acc: (93.00%) (26567/28288)
Epoch: 129 | Batch_idx: 230 |  Loss: (0.1720) |  Loss2: (0.0000) | Acc: (93.00%) (27765/29568)
Epoch: 129 | Batch_idx: 240 |  Loss: (0.1711) |  Loss2: (0.0000) | Acc: (93.00%) (28972/30848)
Epoch: 129 | Batch_idx: 250 |  Loss: (0.1719) |  Loss2: (0.0000) | Acc: (93.00%) (30166/32128)
Epoch: 129 | Batch_idx: 260 |  Loss: (0.1724) |  Loss2: (0.0000) | Acc: (93.00%) (31358/33408)
Epoch: 129 | Batch_idx: 270 |  Loss: (0.1731) |  Loss2: (0.0000) | Acc: (93.00%) (32547/34688)
Epoch: 129 | Batch_idx: 280 |  Loss: (0.1724) |  Loss2: (0.0000) | Acc: (93.00%) (33759/35968)
Epoch: 129 | Batch_idx: 290 |  Loss: (0.1722) |  Loss2: (0.0000) | Acc: (93.00%) (34970/37248)
Epoch: 129 | Batch_idx: 300 |  Loss: (0.1720) |  Loss2: (0.0000) | Acc: (93.00%) (36181/38528)
Epoch: 129 | Batch_idx: 310 |  Loss: (0.1719) |  Loss2: (0.0000) | Acc: (93.00%) (37393/39808)
Epoch: 129 | Batch_idx: 320 |  Loss: (0.1719) |  Loss2: (0.0000) | Acc: (93.00%) (38599/41088)
Epoch: 129 | Batch_idx: 330 |  Loss: (0.1717) |  Loss2: (0.0000) | Acc: (93.00%) (39800/42368)
Epoch: 129 | Batch_idx: 340 |  Loss: (0.1717) |  Loss2: (0.0000) | Acc: (93.00%) (41004/43648)
Epoch: 129 | Batch_idx: 350 |  Loss: (0.1710) |  Loss2: (0.0000) | Acc: (93.00%) (42217/44928)
Epoch: 129 | Batch_idx: 360 |  Loss: (0.1717) |  Loss2: (0.0000) | Acc: (93.00%) (43412/46208)
Epoch: 129 | Batch_idx: 370 |  Loss: (0.1719) |  Loss2: (0.0000) | Acc: (93.00%) (44607/47488)
Epoch: 129 | Batch_idx: 380 |  Loss: (0.1728) |  Loss2: (0.0000) | Acc: (93.00%) (45798/48768)
Epoch: 129 | Batch_idx: 390 |  Loss: (0.1728) |  Loss2: (0.0000) | Acc: (93.00%) (46963/50000)
# TEST : Loss: (0.3949) | Acc: (87.00%) (8756/10000)
percent tensor([0.5194, 0.5073, 0.5204, 0.5126, 0.5236, 0.5256, 0.5152, 0.5150, 0.5213,
        0.5117, 0.5200, 0.5169, 0.5112, 0.5147, 0.5138, 0.5160],
       device='cuda:0') torch.Size([16])
percent tensor([0.5022, 0.4955, 0.5056, 0.5047, 0.5017, 0.5008, 0.4986, 0.5060, 0.5069,
        0.5003, 0.5051, 0.5011, 0.4972, 0.5064, 0.4964, 0.5030],
       device='cuda:0') torch.Size([16])
percent tensor([0.5582, 0.5499, 0.5509, 0.5686, 0.5604, 0.5565, 0.5628, 0.5672, 0.5578,
        0.5567, 0.5594, 0.5505, 0.5216, 0.6039, 0.5482, 0.5712],
       device='cuda:0') torch.Size([16])
percent tensor([0.5965, 0.6205, 0.5967, 0.5859, 0.5853, 0.5899, 0.6103, 0.5821, 0.6146,
        0.6244, 0.6301, 0.6176, 0.6190, 0.6227, 0.5935, 0.6056],
       device='cuda:0') torch.Size([16])
percent tensor([0.6075, 0.6766, 0.4928, 0.5676, 0.5111, 0.6396, 0.6136, 0.3740, 0.6878,
        0.6460, 0.7074, 0.5822, 0.6675, 0.6995, 0.5542, 0.6174],
       device='cuda:0') torch.Size([16])
percent tensor([0.6148, 0.6121, 0.6321, 0.6218, 0.6692, 0.6151, 0.6396, 0.6594, 0.6183,
        0.6186, 0.5888, 0.5854, 0.5819, 0.6042, 0.6130, 0.6311],
       device='cuda:0') torch.Size([16])
percent tensor([0.5112, 0.5824, 0.7469, 0.6603, 0.7959, 0.7206, 0.6000, 0.7113, 0.6776,
        0.5991, 0.6741, 0.6146, 0.6206, 0.6182, 0.5372, 0.4919],
       device='cuda:0') torch.Size([16])
percent tensor([0.9995, 0.9994, 0.9997, 0.9993, 0.9992, 0.9994, 0.9995, 0.9997, 0.9999,
        0.9996, 0.9999, 0.9998, 0.9998, 0.9989, 0.9996, 0.9994],
       device='cuda:0') torch.Size([16])
Epoch: 130 | Batch_idx: 0 |  Loss: (0.1354) |  Loss2: (0.0000) | Acc: (96.00%) (124/128)
Epoch: 130 | Batch_idx: 10 |  Loss: (0.1762) |  Loss2: (0.0000) | Acc: (94.00%) (1334/1408)
Epoch: 130 | Batch_idx: 20 |  Loss: (0.1574) |  Loss2: (0.0000) | Acc: (94.00%) (2553/2688)
Epoch: 130 | Batch_idx: 30 |  Loss: (0.1511) |  Loss2: (0.0000) | Acc: (94.00%) (3764/3968)
Epoch: 130 | Batch_idx: 40 |  Loss: (0.1492) |  Loss2: (0.0000) | Acc: (94.00%) (4983/5248)
Epoch: 130 | Batch_idx: 50 |  Loss: (0.1518) |  Loss2: (0.0000) | Acc: (94.00%) (6196/6528)
Epoch: 130 | Batch_idx: 60 |  Loss: (0.1501) |  Loss2: (0.0000) | Acc: (94.00%) (7414/7808)
Epoch: 130 | Batch_idx: 70 |  Loss: (0.1530) |  Loss2: (0.0000) | Acc: (94.00%) (8617/9088)
Epoch: 130 | Batch_idx: 80 |  Loss: (0.1541) |  Loss2: (0.0000) | Acc: (94.00%) (9835/10368)
Epoch: 130 | Batch_idx: 90 |  Loss: (0.1551) |  Loss2: (0.0000) | Acc: (94.00%) (11043/11648)
Epoch: 130 | Batch_idx: 100 |  Loss: (0.1552) |  Loss2: (0.0000) | Acc: (94.00%) (12254/12928)
Epoch: 130 | Batch_idx: 110 |  Loss: (0.1570) |  Loss2: (0.0000) | Acc: (94.00%) (13464/14208)
Epoch: 130 | Batch_idx: 120 |  Loss: (0.1582) |  Loss2: (0.0000) | Acc: (94.00%) (14675/15488)
Epoch: 130 | Batch_idx: 130 |  Loss: (0.1585) |  Loss2: (0.0000) | Acc: (94.00%) (15888/16768)
Epoch: 130 | Batch_idx: 140 |  Loss: (0.1591) |  Loss2: (0.0000) | Acc: (94.00%) (17096/18048)
Epoch: 130 | Batch_idx: 150 |  Loss: (0.1592) |  Loss2: (0.0000) | Acc: (94.00%) (18302/19328)
Epoch: 130 | Batch_idx: 160 |  Loss: (0.1606) |  Loss2: (0.0000) | Acc: (94.00%) (19502/20608)
Epoch: 130 | Batch_idx: 170 |  Loss: (0.1587) |  Loss2: (0.0000) | Acc: (94.00%) (20728/21888)
Epoch: 130 | Batch_idx: 180 |  Loss: (0.1595) |  Loss2: (0.0000) | Acc: (94.00%) (21927/23168)
Epoch: 130 | Batch_idx: 190 |  Loss: (0.1590) |  Loss2: (0.0000) | Acc: (94.00%) (23140/24448)
Epoch: 130 | Batch_idx: 200 |  Loss: (0.1590) |  Loss2: (0.0000) | Acc: (94.00%) (24347/25728)
Epoch: 130 | Batch_idx: 210 |  Loss: (0.1594) |  Loss2: (0.0000) | Acc: (94.00%) (25548/27008)
Epoch: 130 | Batch_idx: 220 |  Loss: (0.1596) |  Loss2: (0.0000) | Acc: (94.00%) (26756/28288)
Epoch: 130 | Batch_idx: 230 |  Loss: (0.1597) |  Loss2: (0.0000) | Acc: (94.00%) (27970/29568)
Epoch: 130 | Batch_idx: 240 |  Loss: (0.1598) |  Loss2: (0.0000) | Acc: (94.00%) (29184/30848)
Epoch: 130 | Batch_idx: 250 |  Loss: (0.1604) |  Loss2: (0.0000) | Acc: (94.00%) (30389/32128)
Epoch: 130 | Batch_idx: 260 |  Loss: (0.1607) |  Loss2: (0.0000) | Acc: (94.00%) (31587/33408)
Epoch: 130 | Batch_idx: 270 |  Loss: (0.1602) |  Loss2: (0.0000) | Acc: (94.00%) (32807/34688)
Epoch: 130 | Batch_idx: 280 |  Loss: (0.1604) |  Loss2: (0.0000) | Acc: (94.00%) (34011/35968)
Epoch: 130 | Batch_idx: 290 |  Loss: (0.1607) |  Loss2: (0.0000) | Acc: (94.00%) (35213/37248)
Epoch: 130 | Batch_idx: 300 |  Loss: (0.1605) |  Loss2: (0.0000) | Acc: (94.00%) (36420/38528)
Epoch: 130 | Batch_idx: 310 |  Loss: (0.1607) |  Loss2: (0.0000) | Acc: (94.00%) (37628/39808)
Epoch: 130 | Batch_idx: 320 |  Loss: (0.1605) |  Loss2: (0.0000) | Acc: (94.00%) (38834/41088)
Epoch: 130 | Batch_idx: 330 |  Loss: (0.1607) |  Loss2: (0.0000) | Acc: (94.00%) (40042/42368)
Epoch: 130 | Batch_idx: 340 |  Loss: (0.1611) |  Loss2: (0.0000) | Acc: (94.00%) (41240/43648)
Epoch: 130 | Batch_idx: 350 |  Loss: (0.1614) |  Loss2: (0.0000) | Acc: (94.00%) (42452/44928)
Epoch: 130 | Batch_idx: 360 |  Loss: (0.1620) |  Loss2: (0.0000) | Acc: (94.00%) (43648/46208)
Epoch: 130 | Batch_idx: 370 |  Loss: (0.1626) |  Loss2: (0.0000) | Acc: (94.00%) (44838/47488)
Epoch: 130 | Batch_idx: 380 |  Loss: (0.1634) |  Loss2: (0.0000) | Acc: (94.00%) (46029/48768)
Epoch: 130 | Batch_idx: 390 |  Loss: (0.1633) |  Loss2: (0.0000) | Acc: (94.00%) (47193/50000)
=> saving checkpoint 'drive/app/torch/save_Schedule/checkpoint_130.pth.tar'
# TEST : Loss: (0.4115) | Acc: (87.00%) (8737/10000)
percent tensor([0.5188, 0.5071, 0.5214, 0.5131, 0.5241, 0.5244, 0.5152, 0.5153, 0.5206,
        0.5118, 0.5190, 0.5176, 0.5107, 0.5137, 0.5140, 0.5152],
       device='cuda:0') torch.Size([16])
percent tensor([0.5011, 0.4956, 0.5061, 0.5048, 0.5023, 0.5001, 0.4989, 0.5053, 0.5070,
        0.5007, 0.5045, 0.5012, 0.4967, 0.5077, 0.4960, 0.5023],
       device='cuda:0') torch.Size([16])
percent tensor([0.5565, 0.5444, 0.5571, 0.5663, 0.5660, 0.5515, 0.5606, 0.5624, 0.5586,
        0.5555, 0.5560, 0.5540, 0.5199, 0.5968, 0.5426, 0.5644],
       device='cuda:0') torch.Size([16])
percent tensor([0.5957, 0.6219, 0.5950, 0.5871, 0.5837, 0.5885, 0.6120, 0.5829, 0.6154,
        0.6264, 0.6327, 0.6148, 0.6182, 0.6274, 0.5947, 0.6076],
       device='cuda:0') torch.Size([16])
percent tensor([0.5835, 0.6551, 0.4656, 0.5741, 0.4914, 0.6122, 0.5990, 0.3831, 0.6801,
        0.6248, 0.7007, 0.5559, 0.6449, 0.7002, 0.5276, 0.6085],
       device='cuda:0') torch.Size([16])
percent tensor([0.6067, 0.6001, 0.6343, 0.6260, 0.6685, 0.6182, 0.6300, 0.6575, 0.6112,
        0.6060, 0.5795, 0.5853, 0.5734, 0.6017, 0.6111, 0.6193],
       device='cuda:0') torch.Size([16])
percent tensor([0.4698, 0.5589, 0.7299, 0.6543, 0.7757, 0.7489, 0.5670, 0.6824, 0.6071,
        0.5306, 0.6563, 0.5870, 0.5482, 0.5779, 0.5386, 0.4914],
       device='cuda:0') torch.Size([16])
percent tensor([0.9995, 0.9994, 0.9997, 0.9993, 0.9992, 0.9994, 0.9992, 0.9998, 0.9996,
        0.9992, 0.9998, 0.9997, 0.9992, 0.9984, 0.9995, 0.9993],
       device='cuda:0') torch.Size([16])
Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 3, 3, 3]) tensor(187.1063, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(828.1176, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(816.5372, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([128, 64, 3, 3]) tensor(1526.0837, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([128, 64, 1, 1]) tensor(484.1359, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([128, 128, 3, 3]) tensor(2277.8044, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([256, 128, 3, 3]) tensor(4262.9497, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([256, 128, 1, 1]) tensor(1374.3722, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([256, 256, 3, 3]) tensor(6166.3745, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([512, 256, 3, 3]) tensor(11750.2051, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([512, 256, 1, 1]) tensor(3892.9475, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([512, 512, 3, 3]) tensor(16455.9121, device='cuda:0', grad_fn=<NormBackward0>)
Epoch: 131 | Batch_idx: 0 |  Loss: (0.1202) |  Loss2: (0.0000) | Acc: (97.00%) (125/128)
Epoch: 131 | Batch_idx: 10 |  Loss: (0.1465) |  Loss2: (0.0000) | Acc: (95.00%) (1338/1408)
Epoch: 131 | Batch_idx: 20 |  Loss: (0.1515) |  Loss2: (0.0000) | Acc: (94.00%) (2547/2688)
Epoch: 131 | Batch_idx: 30 |  Loss: (0.1479) |  Loss2: (0.0000) | Acc: (94.00%) (3768/3968)
Epoch: 131 | Batch_idx: 40 |  Loss: (0.1472) |  Loss2: (0.0000) | Acc: (95.00%) (4992/5248)
Epoch: 131 | Batch_idx: 50 |  Loss: (0.1477) |  Loss2: (0.0000) | Acc: (95.00%) (6206/6528)
Epoch: 131 | Batch_idx: 60 |  Loss: (0.1492) |  Loss2: (0.0000) | Acc: (95.00%) (7420/7808)
Epoch: 131 | Batch_idx: 70 |  Loss: (0.1495) |  Loss2: (0.0000) | Acc: (94.00%) (8632/9088)
Epoch: 131 | Batch_idx: 80 |  Loss: (0.1502) |  Loss2: (0.0000) | Acc: (94.00%) (9838/10368)
Epoch: 131 | Batch_idx: 90 |  Loss: (0.1533) |  Loss2: (0.0000) | Acc: (94.00%) (11042/11648)
Epoch: 131 | Batch_idx: 100 |  Loss: (0.1532) |  Loss2: (0.0000) | Acc: (94.00%) (12255/12928)
Epoch: 131 | Batch_idx: 110 |  Loss: (0.1534) |  Loss2: (0.0000) | Acc: (94.00%) (13469/14208)
Epoch: 131 | Batch_idx: 120 |  Loss: (0.1530) |  Loss2: (0.0000) | Acc: (94.00%) (14688/15488)
Epoch: 131 | Batch_idx: 130 |  Loss: (0.1532) |  Loss2: (0.0000) | Acc: (94.00%) (15907/16768)
Epoch: 131 | Batch_idx: 140 |  Loss: (0.1526) |  Loss2: (0.0000) | Acc: (94.00%) (17122/18048)
Epoch: 131 | Batch_idx: 150 |  Loss: (0.1539) |  Loss2: (0.0000) | Acc: (94.00%) (18324/19328)
Epoch: 131 | Batch_idx: 160 |  Loss: (0.1550) |  Loss2: (0.0000) | Acc: (94.00%) (19530/20608)
Epoch: 131 | Batch_idx: 170 |  Loss: (0.1561) |  Loss2: (0.0000) | Acc: (94.00%) (20721/21888)
Epoch: 131 | Batch_idx: 180 |  Loss: (0.1569) |  Loss2: (0.0000) | Acc: (94.00%) (21920/23168)
Epoch: 131 | Batch_idx: 190 |  Loss: (0.1567) |  Loss2: (0.0000) | Acc: (94.00%) (23130/24448)
Epoch: 131 | Batch_idx: 200 |  Loss: (0.1575) |  Loss2: (0.0000) | Acc: (94.00%) (24334/25728)
Epoch: 131 | Batch_idx: 210 |  Loss: (0.1571) |  Loss2: (0.0000) | Acc: (94.00%) (25546/27008)
Epoch: 131 | Batch_idx: 220 |  Loss: (0.1560) |  Loss2: (0.0000) | Acc: (94.00%) (26767/28288)
Epoch: 131 | Batch_idx: 230 |  Loss: (0.1557) |  Loss2: (0.0000) | Acc: (94.00%) (27979/29568)
Epoch: 131 | Batch_idx: 240 |  Loss: (0.1567) |  Loss2: (0.0000) | Acc: (94.00%) (29177/30848)
Epoch: 131 | Batch_idx: 250 |  Loss: (0.1568) |  Loss2: (0.0000) | Acc: (94.00%) (30386/32128)
Epoch: 131 | Batch_idx: 260 |  Loss: (0.1568) |  Loss2: (0.0000) | Acc: (94.00%) (31595/33408)
Epoch: 131 | Batch_idx: 270 |  Loss: (0.1567) |  Loss2: (0.0000) | Acc: (94.00%) (32819/34688)
Epoch: 131 | Batch_idx: 280 |  Loss: (0.1569) |  Loss2: (0.0000) | Acc: (94.00%) (34034/35968)
Epoch: 131 | Batch_idx: 290 |  Loss: (0.1566) |  Loss2: (0.0000) | Acc: (94.00%) (35255/37248)
Epoch: 131 | Batch_idx: 300 |  Loss: (0.1576) |  Loss2: (0.0000) | Acc: (94.00%) (36451/38528)
Epoch: 131 | Batch_idx: 310 |  Loss: (0.1589) |  Loss2: (0.0000) | Acc: (94.00%) (37646/39808)
Epoch: 131 | Batch_idx: 320 |  Loss: (0.1594) |  Loss2: (0.0000) | Acc: (94.00%) (38849/41088)
Epoch: 131 | Batch_idx: 330 |  Loss: (0.1597) |  Loss2: (0.0000) | Acc: (94.00%) (40048/42368)
Epoch: 131 | Batch_idx: 340 |  Loss: (0.1595) |  Loss2: (0.0000) | Acc: (94.00%) (41267/43648)
Epoch: 131 | Batch_idx: 350 |  Loss: (0.1603) |  Loss2: (0.0000) | Acc: (94.00%) (42460/44928)
Epoch: 131 | Batch_idx: 360 |  Loss: (0.1609) |  Loss2: (0.0000) | Acc: (94.00%) (43659/46208)
Epoch: 131 | Batch_idx: 370 |  Loss: (0.1616) |  Loss2: (0.0000) | Acc: (94.00%) (44863/47488)
Epoch: 131 | Batch_idx: 380 |  Loss: (0.1618) |  Loss2: (0.0000) | Acc: (94.00%) (46073/48768)
Epoch: 131 | Batch_idx: 390 |  Loss: (0.1620) |  Loss2: (0.0000) | Acc: (94.00%) (47227/50000)
# TEST : Loss: (0.4110) | Acc: (87.00%) (8745/10000)
percent tensor([0.5185, 0.5071, 0.5210, 0.5124, 0.5228, 0.5234, 0.5149, 0.5153, 0.5213,
        0.5117, 0.5198, 0.5168, 0.5109, 0.5138, 0.5134, 0.5152],
       device='cuda:0') torch.Size([16])
percent tensor([0.5012, 0.4953, 0.5056, 0.5042, 0.5017, 0.5003, 0.4982, 0.5045, 0.5070,
        0.4999, 0.5047, 0.5004, 0.4963, 0.5067, 0.4958, 0.5021],
       device='cuda:0') torch.Size([16])
percent tensor([0.5557, 0.5443, 0.5520, 0.5610, 0.5630, 0.5515, 0.5624, 0.5618, 0.5558,
        0.5554, 0.5562, 0.5550, 0.5185, 0.5965, 0.5441, 0.5658],
       device='cuda:0') torch.Size([16])
percent tensor([0.5974, 0.6184, 0.6003, 0.5937, 0.5878, 0.5903, 0.6115, 0.5848, 0.6135,
        0.6251, 0.6306, 0.6180, 0.6164, 0.6250, 0.5949, 0.6069],
       device='cuda:0') torch.Size([16])
percent tensor([0.6060, 0.6641, 0.4804, 0.5864, 0.5012, 0.6502, 0.6042, 0.3802, 0.6704,
        0.6400, 0.7086, 0.5721, 0.6541, 0.6959, 0.5625, 0.6282],
       device='cuda:0') torch.Size([16])
percent tensor([0.6066, 0.6008, 0.6348, 0.6202, 0.6729, 0.6095, 0.6301, 0.6592, 0.6152,
        0.6088, 0.5899, 0.5822, 0.5770, 0.5955, 0.6035, 0.6180],
       device='cuda:0') torch.Size([16])
percent tensor([0.5089, 0.5662, 0.7383, 0.6453, 0.7896, 0.7412, 0.5837, 0.7008, 0.6298,
        0.5598, 0.7049, 0.5573, 0.6076, 0.5825, 0.5413, 0.5085],
       device='cuda:0') torch.Size([16])
percent tensor([0.9995, 0.9994, 0.9997, 0.9992, 0.9997, 0.9993, 0.9996, 0.9997, 0.9997,
        0.9995, 0.9999, 0.9996, 0.9998, 0.9985, 0.9992, 0.9992],
       device='cuda:0') torch.Size([16])
Epoch: 132 | Batch_idx: 0 |  Loss: (0.0864) |  Loss2: (0.0000) | Acc: (97.00%) (125/128)
Epoch: 132 | Batch_idx: 10 |  Loss: (0.1265) |  Loss2: (0.0000) | Acc: (95.00%) (1351/1408)
Epoch: 132 | Batch_idx: 20 |  Loss: (0.1519) |  Loss2: (0.0000) | Acc: (95.00%) (2556/2688)
Epoch: 132 | Batch_idx: 30 |  Loss: (0.1537) |  Loss2: (0.0000) | Acc: (94.00%) (3769/3968)
Epoch: 132 | Batch_idx: 40 |  Loss: (0.1567) |  Loss2: (0.0000) | Acc: (94.00%) (4977/5248)
Epoch: 132 | Batch_idx: 50 |  Loss: (0.1532) |  Loss2: (0.0000) | Acc: (94.00%) (6199/6528)
Epoch: 132 | Batch_idx: 60 |  Loss: (0.1525) |  Loss2: (0.0000) | Acc: (94.00%) (7417/7808)
Epoch: 132 | Batch_idx: 70 |  Loss: (0.1527) |  Loss2: (0.0000) | Acc: (94.00%) (8626/9088)
Epoch: 132 | Batch_idx: 80 |  Loss: (0.1561) |  Loss2: (0.0000) | Acc: (94.00%) (9820/10368)
Epoch: 132 | Batch_idx: 90 |  Loss: (0.1580) |  Loss2: (0.0000) | Acc: (94.00%) (11023/11648)
Epoch: 132 | Batch_idx: 100 |  Loss: (0.1585) |  Loss2: (0.0000) | Acc: (94.00%) (12241/12928)
Epoch: 132 | Batch_idx: 110 |  Loss: (0.1586) |  Loss2: (0.0000) | Acc: (94.00%) (13452/14208)
Epoch: 132 | Batch_idx: 120 |  Loss: (0.1570) |  Loss2: (0.0000) | Acc: (94.00%) (14672/15488)
Epoch: 132 | Batch_idx: 130 |  Loss: (0.1552) |  Loss2: (0.0000) | Acc: (94.00%) (15889/16768)
Epoch: 132 | Batch_idx: 140 |  Loss: (0.1543) |  Loss2: (0.0000) | Acc: (94.00%) (17102/18048)
Epoch: 132 | Batch_idx: 150 |  Loss: (0.1553) |  Loss2: (0.0000) | Acc: (94.00%) (18311/19328)
Epoch: 132 | Batch_idx: 160 |  Loss: (0.1549) |  Loss2: (0.0000) | Acc: (94.00%) (19525/20608)
Epoch: 132 | Batch_idx: 170 |  Loss: (0.1566) |  Loss2: (0.0000) | Acc: (94.00%) (20724/21888)
Epoch: 132 | Batch_idx: 180 |  Loss: (0.1575) |  Loss2: (0.0000) | Acc: (94.00%) (21924/23168)
Epoch: 132 | Batch_idx: 190 |  Loss: (0.1579) |  Loss2: (0.0000) | Acc: (94.00%) (23130/24448)
Epoch: 132 | Batch_idx: 200 |  Loss: (0.1565) |  Loss2: (0.0000) | Acc: (94.00%) (24360/25728)
Epoch: 132 | Batch_idx: 210 |  Loss: (0.1558) |  Loss2: (0.0000) | Acc: (94.00%) (25585/27008)
Epoch: 132 | Batch_idx: 220 |  Loss: (0.1566) |  Loss2: (0.0000) | Acc: (94.00%) (26786/28288)
Epoch: 132 | Batch_idx: 230 |  Loss: (0.1567) |  Loss2: (0.0000) | Acc: (94.00%) (27995/29568)
Epoch: 132 | Batch_idx: 240 |  Loss: (0.1563) |  Loss2: (0.0000) | Acc: (94.00%) (29208/30848)
Epoch: 132 | Batch_idx: 250 |  Loss: (0.1556) |  Loss2: (0.0000) | Acc: (94.00%) (30430/32128)
Epoch: 132 | Batch_idx: 260 |  Loss: (0.1554) |  Loss2: (0.0000) | Acc: (94.00%) (31641/33408)
Epoch: 132 | Batch_idx: 270 |  Loss: (0.1558) |  Loss2: (0.0000) | Acc: (94.00%) (32849/34688)
Epoch: 132 | Batch_idx: 280 |  Loss: (0.1560) |  Loss2: (0.0000) | Acc: (94.00%) (34056/35968)
Epoch: 132 | Batch_idx: 290 |  Loss: (0.1571) |  Loss2: (0.0000) | Acc: (94.00%) (35253/37248)
Epoch: 132 | Batch_idx: 300 |  Loss: (0.1579) |  Loss2: (0.0000) | Acc: (94.00%) (36454/38528)
Epoch: 132 | Batch_idx: 310 |  Loss: (0.1584) |  Loss2: (0.0000) | Acc: (94.00%) (37665/39808)
Epoch: 132 | Batch_idx: 320 |  Loss: (0.1576) |  Loss2: (0.0000) | Acc: (94.00%) (38886/41088)
Epoch: 132 | Batch_idx: 330 |  Loss: (0.1577) |  Loss2: (0.0000) | Acc: (94.00%) (40093/42368)
Epoch: 132 | Batch_idx: 340 |  Loss: (0.1578) |  Loss2: (0.0000) | Acc: (94.00%) (41301/43648)
Epoch: 132 | Batch_idx: 350 |  Loss: (0.1576) |  Loss2: (0.0000) | Acc: (94.00%) (42520/44928)
Epoch: 132 | Batch_idx: 360 |  Loss: (0.1580) |  Loss2: (0.0000) | Acc: (94.00%) (43719/46208)
Epoch: 132 | Batch_idx: 370 |  Loss: (0.1585) |  Loss2: (0.0000) | Acc: (94.00%) (44924/47488)
Epoch: 132 | Batch_idx: 380 |  Loss: (0.1584) |  Loss2: (0.0000) | Acc: (94.00%) (46135/48768)
Epoch: 132 | Batch_idx: 390 |  Loss: (0.1587) |  Loss2: (0.0000) | Acc: (94.00%) (47298/50000)
# TEST : Loss: (0.3974) | Acc: (87.00%) (8785/10000)
percent tensor([0.5187, 0.5062, 0.5213, 0.5133, 0.5241, 0.5240, 0.5145, 0.5150, 0.5205,
        0.5113, 0.5191, 0.5175, 0.5106, 0.5121, 0.5133, 0.5149],
       device='cuda:0') torch.Size([16])
percent tensor([0.5023, 0.4964, 0.5069, 0.5053, 0.5024, 0.5014, 0.4998, 0.5057, 0.5072,
        0.5015, 0.5054, 0.5016, 0.4974, 0.5082, 0.4968, 0.5034],
       device='cuda:0') torch.Size([16])
percent tensor([0.5596, 0.5491, 0.5606, 0.5653, 0.5697, 0.5572, 0.5677, 0.5636, 0.5590,
        0.5611, 0.5605, 0.5585, 0.5207, 0.6032, 0.5489, 0.5701],
       device='cuda:0') torch.Size([16])
percent tensor([0.5936, 0.6158, 0.5911, 0.5849, 0.5832, 0.5835, 0.6073, 0.5770, 0.6115,
        0.6210, 0.6270, 0.6124, 0.6160, 0.6217, 0.5890, 0.6009],
       device='cuda:0') torch.Size([16])
percent tensor([0.5744, 0.6464, 0.4519, 0.5576, 0.4949, 0.6284, 0.5717, 0.3521, 0.6533,
        0.6126, 0.6860, 0.5441, 0.6335, 0.6696, 0.5251, 0.5837],
       device='cuda:0') torch.Size([16])
percent tensor([0.6253, 0.6242, 0.6373, 0.6262, 0.6698, 0.6218, 0.6431, 0.6612, 0.6282,
        0.6253, 0.6048, 0.5928, 0.5880, 0.6207, 0.6205, 0.6378],
       device='cuda:0') torch.Size([16])
percent tensor([0.5229, 0.6084, 0.7373, 0.6587, 0.7813, 0.7498, 0.5906, 0.7024, 0.6712,
        0.5742, 0.6788, 0.5810, 0.6346, 0.6062, 0.5663, 0.5270],
       device='cuda:0') torch.Size([16])
percent tensor([0.9994, 0.9993, 0.9996, 0.9994, 0.9991, 0.9993, 0.9993, 0.9997, 0.9996,
        0.9994, 0.9998, 0.9997, 0.9997, 0.9985, 0.9991, 0.9991],
       device='cuda:0') torch.Size([16])
Epoch: 133 | Batch_idx: 0 |  Loss: (0.1304) |  Loss2: (0.0000) | Acc: (96.00%) (123/128)
Epoch: 133 | Batch_idx: 10 |  Loss: (0.1321) |  Loss2: (0.0000) | Acc: (96.00%) (1355/1408)
Epoch: 133 | Batch_idx: 20 |  Loss: (0.1415) |  Loss2: (0.0000) | Acc: (95.00%) (2566/2688)
Epoch: 133 | Batch_idx: 30 |  Loss: (0.1436) |  Loss2: (0.0000) | Acc: (95.00%) (3782/3968)
Epoch: 133 | Batch_idx: 40 |  Loss: (0.1385) |  Loss2: (0.0000) | Acc: (95.00%) (5019/5248)
Epoch: 133 | Batch_idx: 50 |  Loss: (0.1470) |  Loss2: (0.0000) | Acc: (95.00%) (6214/6528)
Epoch: 133 | Batch_idx: 60 |  Loss: (0.1476) |  Loss2: (0.0000) | Acc: (95.00%) (7431/7808)
Epoch: 133 | Batch_idx: 70 |  Loss: (0.1481) |  Loss2: (0.0000) | Acc: (95.00%) (8640/9088)
Epoch: 133 | Batch_idx: 80 |  Loss: (0.1488) |  Loss2: (0.0000) | Acc: (94.00%) (9848/10368)
Epoch: 133 | Batch_idx: 90 |  Loss: (0.1489) |  Loss2: (0.0000) | Acc: (95.00%) (11066/11648)
Epoch: 133 | Batch_idx: 100 |  Loss: (0.1478) |  Loss2: (0.0000) | Acc: (95.00%) (12289/12928)
Epoch: 133 | Batch_idx: 110 |  Loss: (0.1486) |  Loss2: (0.0000) | Acc: (95.00%) (13504/14208)
Epoch: 133 | Batch_idx: 120 |  Loss: (0.1501) |  Loss2: (0.0000) | Acc: (94.00%) (14710/15488)
Epoch: 133 | Batch_idx: 130 |  Loss: (0.1504) |  Loss2: (0.0000) | Acc: (94.00%) (15922/16768)
Epoch: 133 | Batch_idx: 140 |  Loss: (0.1503) |  Loss2: (0.0000) | Acc: (94.00%) (17137/18048)
Epoch: 133 | Batch_idx: 150 |  Loss: (0.1505) |  Loss2: (0.0000) | Acc: (94.00%) (18348/19328)
Epoch: 133 | Batch_idx: 160 |  Loss: (0.1503) |  Loss2: (0.0000) | Acc: (94.00%) (19570/20608)
Epoch: 133 | Batch_idx: 170 |  Loss: (0.1508) |  Loss2: (0.0000) | Acc: (94.00%) (20781/21888)
Epoch: 133 | Batch_idx: 180 |  Loss: (0.1510) |  Loss2: (0.0000) | Acc: (94.00%) (21995/23168)
Epoch: 133 | Batch_idx: 190 |  Loss: (0.1503) |  Loss2: (0.0000) | Acc: (94.00%) (23210/24448)
Epoch: 133 | Batch_idx: 200 |  Loss: (0.1497) |  Loss2: (0.0000) | Acc: (94.00%) (24423/25728)
Epoch: 133 | Batch_idx: 210 |  Loss: (0.1501) |  Loss2: (0.0000) | Acc: (94.00%) (25636/27008)
Epoch: 133 | Batch_idx: 220 |  Loss: (0.1492) |  Loss2: (0.0000) | Acc: (94.00%) (26862/28288)
Epoch: 133 | Batch_idx: 230 |  Loss: (0.1491) |  Loss2: (0.0000) | Acc: (94.00%) (28070/29568)
Epoch: 133 | Batch_idx: 240 |  Loss: (0.1496) |  Loss2: (0.0000) | Acc: (94.00%) (29280/30848)
Epoch: 133 | Batch_idx: 250 |  Loss: (0.1498) |  Loss2: (0.0000) | Acc: (94.00%) (30499/32128)
Epoch: 133 | Batch_idx: 260 |  Loss: (0.1496) |  Loss2: (0.0000) | Acc: (94.00%) (31712/33408)
Epoch: 133 | Batch_idx: 270 |  Loss: (0.1504) |  Loss2: (0.0000) | Acc: (94.00%) (32916/34688)
Epoch: 133 | Batch_idx: 280 |  Loss: (0.1506) |  Loss2: (0.0000) | Acc: (94.00%) (34121/35968)
Epoch: 133 | Batch_idx: 290 |  Loss: (0.1512) |  Loss2: (0.0000) | Acc: (94.00%) (35325/37248)
Epoch: 133 | Batch_idx: 300 |  Loss: (0.1510) |  Loss2: (0.0000) | Acc: (94.00%) (36542/38528)
Epoch: 133 | Batch_idx: 310 |  Loss: (0.1514) |  Loss2: (0.0000) | Acc: (94.00%) (37741/39808)
Epoch: 133 | Batch_idx: 320 |  Loss: (0.1514) |  Loss2: (0.0000) | Acc: (94.00%) (38954/41088)
Epoch: 133 | Batch_idx: 330 |  Loss: (0.1517) |  Loss2: (0.0000) | Acc: (94.00%) (40165/42368)
Epoch: 133 | Batch_idx: 340 |  Loss: (0.1513) |  Loss2: (0.0000) | Acc: (94.00%) (41381/43648)
Epoch: 133 | Batch_idx: 350 |  Loss: (0.1511) |  Loss2: (0.0000) | Acc: (94.00%) (42597/44928)
Epoch: 133 | Batch_idx: 360 |  Loss: (0.1515) |  Loss2: (0.0000) | Acc: (94.00%) (43800/46208)
Epoch: 133 | Batch_idx: 370 |  Loss: (0.1516) |  Loss2: (0.0000) | Acc: (94.00%) (45008/47488)
Epoch: 133 | Batch_idx: 380 |  Loss: (0.1515) |  Loss2: (0.0000) | Acc: (94.00%) (46221/48768)
Epoch: 133 | Batch_idx: 390 |  Loss: (0.1512) |  Loss2: (0.0000) | Acc: (94.00%) (47395/50000)
# TEST : Loss: (0.3937) | Acc: (87.00%) (8782/10000)
percent tensor([0.5191, 0.5070, 0.5208, 0.5135, 0.5233, 0.5246, 0.5146, 0.5148, 0.5205,
        0.5112, 0.5194, 0.5167, 0.5108, 0.5131, 0.5140, 0.5153],
       device='cuda:0') torch.Size([16])
percent tensor([0.5024, 0.4964, 0.5068, 0.5057, 0.5025, 0.5015, 0.4995, 0.5060, 0.5082,
        0.5016, 0.5060, 0.5020, 0.4976, 0.5090, 0.4966, 0.5038],
       device='cuda:0') torch.Size([16])
percent tensor([0.5612, 0.5482, 0.5628, 0.5652, 0.5709, 0.5542, 0.5647, 0.5669, 0.5608,
        0.5598, 0.5601, 0.5581, 0.5237, 0.5981, 0.5458, 0.5695],
       device='cuda:0') torch.Size([16])
percent tensor([0.5973, 0.6204, 0.5967, 0.5944, 0.5844, 0.5866, 0.6093, 0.5853, 0.6174,
        0.6251, 0.6338, 0.6161, 0.6179, 0.6293, 0.5943, 0.6067],
       device='cuda:0') torch.Size([16])
percent tensor([0.6063, 0.6541, 0.4897, 0.5949, 0.5237, 0.6331, 0.6069, 0.3884, 0.6862,
        0.6340, 0.7039, 0.5846, 0.6431, 0.6923, 0.5572, 0.6190],
       device='cuda:0') torch.Size([16])
percent tensor([0.6123, 0.6134, 0.6355, 0.6204, 0.6688, 0.6206, 0.6307, 0.6546, 0.6111,
        0.6150, 0.5885, 0.5906, 0.5735, 0.6004, 0.6094, 0.6265],
       device='cuda:0') torch.Size([16])
percent tensor([0.4968, 0.5535, 0.7410, 0.6644, 0.7919, 0.7569, 0.5673, 0.6716, 0.6304,
        0.5384, 0.6589, 0.5707, 0.5928, 0.5753, 0.5396, 0.4914],
       device='cuda:0') torch.Size([16])
percent tensor([0.9996, 0.9993, 0.9996, 0.9993, 0.9994, 0.9994, 0.9993, 0.9997, 0.9998,
        0.9994, 0.9998, 0.9996, 0.9998, 0.9987, 0.9993, 0.9991],
       device='cuda:0') torch.Size([16])
Epoch: 134 | Batch_idx: 0 |  Loss: (0.1088) |  Loss2: (0.0000) | Acc: (98.00%) (126/128)
Epoch: 134 | Batch_idx: 10 |  Loss: (0.1495) |  Loss2: (0.0000) | Acc: (95.00%) (1339/1408)
Epoch: 134 | Batch_idx: 20 |  Loss: (0.1407) |  Loss2: (0.0000) | Acc: (95.00%) (2554/2688)
Epoch: 134 | Batch_idx: 30 |  Loss: (0.1436) |  Loss2: (0.0000) | Acc: (94.00%) (3766/3968)
Epoch: 134 | Batch_idx: 40 |  Loss: (0.1414) |  Loss2: (0.0000) | Acc: (95.00%) (4991/5248)
Epoch: 134 | Batch_idx: 50 |  Loss: (0.1445) |  Loss2: (0.0000) | Acc: (95.00%) (6203/6528)
Epoch: 134 | Batch_idx: 60 |  Loss: (0.1474) |  Loss2: (0.0000) | Acc: (94.00%) (7410/7808)
Epoch: 134 | Batch_idx: 70 |  Loss: (0.1509) |  Loss2: (0.0000) | Acc: (94.00%) (8611/9088)
Epoch: 134 | Batch_idx: 80 |  Loss: (0.1498) |  Loss2: (0.0000) | Acc: (94.00%) (9821/10368)
Epoch: 134 | Batch_idx: 90 |  Loss: (0.1496) |  Loss2: (0.0000) | Acc: (94.00%) (11035/11648)
Epoch: 134 | Batch_idx: 100 |  Loss: (0.1516) |  Loss2: (0.0000) | Acc: (94.00%) (12244/12928)
Epoch: 134 | Batch_idx: 110 |  Loss: (0.1518) |  Loss2: (0.0000) | Acc: (94.00%) (13455/14208)
Epoch: 134 | Batch_idx: 120 |  Loss: (0.1502) |  Loss2: (0.0000) | Acc: (94.00%) (14671/15488)
Epoch: 134 | Batch_idx: 130 |  Loss: (0.1504) |  Loss2: (0.0000) | Acc: (94.00%) (15880/16768)
Epoch: 134 | Batch_idx: 140 |  Loss: (0.1509) |  Loss2: (0.0000) | Acc: (94.00%) (17093/18048)
Epoch: 134 | Batch_idx: 150 |  Loss: (0.1519) |  Loss2: (0.0000) | Acc: (94.00%) (18292/19328)
Epoch: 134 | Batch_idx: 160 |  Loss: (0.1508) |  Loss2: (0.0000) | Acc: (94.00%) (19513/20608)
Epoch: 134 | Batch_idx: 170 |  Loss: (0.1514) |  Loss2: (0.0000) | Acc: (94.00%) (20725/21888)
Epoch: 134 | Batch_idx: 180 |  Loss: (0.1507) |  Loss2: (0.0000) | Acc: (94.00%) (21949/23168)
Epoch: 134 | Batch_idx: 190 |  Loss: (0.1509) |  Loss2: (0.0000) | Acc: (94.00%) (23163/24448)
Epoch: 134 | Batch_idx: 200 |  Loss: (0.1505) |  Loss2: (0.0000) | Acc: (94.00%) (24387/25728)
Epoch: 134 | Batch_idx: 210 |  Loss: (0.1504) |  Loss2: (0.0000) | Acc: (94.00%) (25601/27008)
Epoch: 134 | Batch_idx: 220 |  Loss: (0.1503) |  Loss2: (0.0000) | Acc: (94.00%) (26814/28288)
Epoch: 134 | Batch_idx: 230 |  Loss: (0.1497) |  Loss2: (0.0000) | Acc: (94.00%) (28036/29568)
Epoch: 134 | Batch_idx: 240 |  Loss: (0.1504) |  Loss2: (0.0000) | Acc: (94.00%) (29243/30848)
Epoch: 134 | Batch_idx: 250 |  Loss: (0.1503) |  Loss2: (0.0000) | Acc: (94.00%) (30458/32128)
Epoch: 134 | Batch_idx: 260 |  Loss: (0.1512) |  Loss2: (0.0000) | Acc: (94.00%) (31662/33408)
Epoch: 134 | Batch_idx: 270 |  Loss: (0.1516) |  Loss2: (0.0000) | Acc: (94.00%) (32868/34688)
Epoch: 134 | Batch_idx: 280 |  Loss: (0.1521) |  Loss2: (0.0000) | Acc: (94.00%) (34069/35968)
Epoch: 134 | Batch_idx: 290 |  Loss: (0.1521) |  Loss2: (0.0000) | Acc: (94.00%) (35273/37248)
Epoch: 134 | Batch_idx: 300 |  Loss: (0.1513) |  Loss2: (0.0000) | Acc: (94.00%) (36494/38528)
Epoch: 134 | Batch_idx: 310 |  Loss: (0.1517) |  Loss2: (0.0000) | Acc: (94.00%) (37699/39808)
Epoch: 134 | Batch_idx: 320 |  Loss: (0.1520) |  Loss2: (0.0000) | Acc: (94.00%) (38897/41088)
Epoch: 134 | Batch_idx: 330 |  Loss: (0.1521) |  Loss2: (0.0000) | Acc: (94.00%) (40108/42368)
Epoch: 134 | Batch_idx: 340 |  Loss: (0.1522) |  Loss2: (0.0000) | Acc: (94.00%) (41319/43648)
Epoch: 134 | Batch_idx: 350 |  Loss: (0.1521) |  Loss2: (0.0000) | Acc: (94.00%) (42538/44928)
Epoch: 134 | Batch_idx: 360 |  Loss: (0.1523) |  Loss2: (0.0000) | Acc: (94.00%) (43743/46208)
Epoch: 134 | Batch_idx: 370 |  Loss: (0.1521) |  Loss2: (0.0000) | Acc: (94.00%) (44956/47488)
Epoch: 134 | Batch_idx: 380 |  Loss: (0.1523) |  Loss2: (0.0000) | Acc: (94.00%) (46161/48768)
Epoch: 134 | Batch_idx: 390 |  Loss: (0.1526) |  Loss2: (0.0000) | Acc: (94.00%) (47316/50000)
# TEST : Loss: (0.4389) | Acc: (86.00%) (8699/10000)
percent tensor([0.5188, 0.5079, 0.5199, 0.5124, 0.5225, 0.5242, 0.5151, 0.5152, 0.5213,
        0.5115, 0.5201, 0.5161, 0.5108, 0.5152, 0.5140, 0.5157],
       device='cuda:0') torch.Size([16])
percent tensor([0.5024, 0.4948, 0.5070, 0.5051, 0.5031, 0.5015, 0.4984, 0.5052, 0.5072,
        0.5005, 0.5048, 0.5018, 0.4970, 0.5050, 0.4963, 0.5035],
       device='cuda:0') torch.Size([16])
percent tensor([0.5601, 0.5427, 0.5616, 0.5669, 0.5708, 0.5608, 0.5635, 0.5661, 0.5595,
        0.5550, 0.5578, 0.5587, 0.5198, 0.5979, 0.5461, 0.5681],
       device='cuda:0') torch.Size([16])
percent tensor([0.5961, 0.6188, 0.5962, 0.5902, 0.5837, 0.5885, 0.6113, 0.5822, 0.6133,
        0.6268, 0.6310, 0.6154, 0.6166, 0.6246, 0.5948, 0.6073],
       device='cuda:0') torch.Size([16])
percent tensor([0.5735, 0.6559, 0.4645, 0.5997, 0.5008, 0.6343, 0.5905, 0.3579, 0.6653,
        0.6291, 0.6979, 0.5646, 0.6362, 0.6848, 0.5440, 0.5969],
       device='cuda:0') torch.Size([16])
percent tensor([0.6130, 0.5905, 0.6309, 0.6168, 0.6637, 0.6233, 0.6201, 0.6506, 0.6140,
        0.5985, 0.5843, 0.5800, 0.5717, 0.5995, 0.6095, 0.6198],
       device='cuda:0') torch.Size([16])
percent tensor([0.4861, 0.5516, 0.7324, 0.6696, 0.7894, 0.7398, 0.5583, 0.6600, 0.6172,
        0.5432, 0.6662, 0.5817, 0.5880, 0.5405, 0.5353, 0.4868],
       device='cuda:0') torch.Size([16])
percent tensor([0.9995, 0.9997, 0.9998, 0.9995, 0.9995, 0.9992, 0.9996, 0.9997, 0.9998,
        0.9997, 0.9999, 0.9997, 0.9996, 0.9992, 0.9996, 0.9990],
       device='cuda:0') torch.Size([16])
False Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=128, out_features=16, bias=False)
True Linear(in_features=16, out_features=2, bias=False)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=128, out_features=16, bias=False)
True Linear(in_features=16, out_features=2, bias=False)
False Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=256, out_features=32, bias=False)
True Linear(in_features=32, out_features=2, bias=False)
False Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=256, out_features=32, bias=False)
True Linear(in_features=32, out_features=2, bias=False)
False Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=512, out_features=64, bias=False)
True Linear(in_features=64, out_features=2, bias=False)
False Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=512, out_features=64, bias=False)
True Linear(in_features=64, out_features=2, bias=False)
False Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1024, out_features=128, bias=False)
True Linear(in_features=128, out_features=2, bias=False)
False Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1024, out_features=128, bias=False)
True Linear(in_features=128, out_features=2, bias=False)
False Linear(in_features=512, out_features=10, bias=True)
Epoch: 135 | Batch_idx: 0 |  Loss: (0.1328) |  Loss2: (0.0000) | Acc: (95.00%) (122/128)
Epoch: 135 | Batch_idx: 10 |  Loss: (0.1517) |  Loss2: (0.0000) | Acc: (94.00%) (1327/1408)
Epoch: 135 | Batch_idx: 20 |  Loss: (0.1759) |  Loss2: (0.0000) | Acc: (93.00%) (2513/2688)
Epoch: 135 | Batch_idx: 30 |  Loss: (0.1827) |  Loss2: (0.0000) | Acc: (93.00%) (3710/3968)
Epoch: 135 | Batch_idx: 40 |  Loss: (0.1978) |  Loss2: (0.0000) | Acc: (92.00%) (4877/5248)
Epoch: 135 | Batch_idx: 50 |  Loss: (0.1992) |  Loss2: (0.0000) | Acc: (92.00%) (6061/6528)
Epoch: 135 | Batch_idx: 60 |  Loss: (0.2016) |  Loss2: (0.0000) | Acc: (92.00%) (7246/7808)
Epoch: 135 | Batch_idx: 70 |  Loss: (0.1992) |  Loss2: (0.0000) | Acc: (93.00%) (8452/9088)
Epoch: 135 | Batch_idx: 80 |  Loss: (0.1993) |  Loss2: (0.0000) | Acc: (92.00%) (9641/10368)
Epoch: 135 | Batch_idx: 90 |  Loss: (0.2027) |  Loss2: (0.0000) | Acc: (92.00%) (10809/11648)
Epoch: 135 | Batch_idx: 100 |  Loss: (0.2011) |  Loss2: (0.0000) | Acc: (92.00%) (12004/12928)
Epoch: 135 | Batch_idx: 110 |  Loss: (0.2048) |  Loss2: (0.0000) | Acc: (92.00%) (13171/14208)
Epoch: 135 | Batch_idx: 120 |  Loss: (0.2054) |  Loss2: (0.0000) | Acc: (92.00%) (14354/15488)
Epoch: 135 | Batch_idx: 130 |  Loss: (0.2070) |  Loss2: (0.0000) | Acc: (92.00%) (15539/16768)
Epoch: 135 | Batch_idx: 140 |  Loss: (0.2077) |  Loss2: (0.0000) | Acc: (92.00%) (16731/18048)
Epoch: 135 | Batch_idx: 150 |  Loss: (0.2090) |  Loss2: (0.0000) | Acc: (92.00%) (17905/19328)
Epoch: 135 | Batch_idx: 160 |  Loss: (0.2093) |  Loss2: (0.0000) | Acc: (92.00%) (19087/20608)
Epoch: 135 | Batch_idx: 170 |  Loss: (0.2059) |  Loss2: (0.0000) | Acc: (92.00%) (20298/21888)
Epoch: 135 | Batch_idx: 180 |  Loss: (0.2050) |  Loss2: (0.0000) | Acc: (92.00%) (21493/23168)
Epoch: 135 | Batch_idx: 190 |  Loss: (0.2040) |  Loss2: (0.0000) | Acc: (92.00%) (22680/24448)
Epoch: 135 | Batch_idx: 200 |  Loss: (0.2046) |  Loss2: (0.0000) | Acc: (92.00%) (23862/25728)
Epoch: 135 | Batch_idx: 210 |  Loss: (0.2033) |  Loss2: (0.0000) | Acc: (92.00%) (25064/27008)
Epoch: 135 | Batch_idx: 220 |  Loss: (0.2021) |  Loss2: (0.0000) | Acc: (92.00%) (26268/28288)
Epoch: 135 | Batch_idx: 230 |  Loss: (0.2015) |  Loss2: (0.0000) | Acc: (92.00%) (27463/29568)
Epoch: 135 | Batch_idx: 240 |  Loss: (0.2017) |  Loss2: (0.0000) | Acc: (92.00%) (28657/30848)
Epoch: 135 | Batch_idx: 250 |  Loss: (0.2010) |  Loss2: (0.0000) | Acc: (92.00%) (29852/32128)
Epoch: 135 | Batch_idx: 260 |  Loss: (0.2014) |  Loss2: (0.0000) | Acc: (92.00%) (31038/33408)
Epoch: 135 | Batch_idx: 270 |  Loss: (0.2012) |  Loss2: (0.0000) | Acc: (92.00%) (32228/34688)
Epoch: 135 | Batch_idx: 280 |  Loss: (0.2010) |  Loss2: (0.0000) | Acc: (92.00%) (33427/35968)
Epoch: 135 | Batch_idx: 290 |  Loss: (0.2009) |  Loss2: (0.0000) | Acc: (92.00%) (34609/37248)
Epoch: 135 | Batch_idx: 300 |  Loss: (0.2002) |  Loss2: (0.0000) | Acc: (92.00%) (35810/38528)
Epoch: 135 | Batch_idx: 310 |  Loss: (0.1991) |  Loss2: (0.0000) | Acc: (92.00%) (37017/39808)
Epoch: 135 | Batch_idx: 320 |  Loss: (0.1984) |  Loss2: (0.0000) | Acc: (92.00%) (38211/41088)
Epoch: 135 | Batch_idx: 330 |  Loss: (0.1967) |  Loss2: (0.0000) | Acc: (93.00%) (39428/42368)
Epoch: 135 | Batch_idx: 340 |  Loss: (0.1955) |  Loss2: (0.0000) | Acc: (93.00%) (40635/43648)
Epoch: 135 | Batch_idx: 350 |  Loss: (0.1952) |  Loss2: (0.0000) | Acc: (93.00%) (41832/44928)
Epoch: 135 | Batch_idx: 360 |  Loss: (0.1942) |  Loss2: (0.0000) | Acc: (93.00%) (43046/46208)
Epoch: 135 | Batch_idx: 370 |  Loss: (0.1942) |  Loss2: (0.0000) | Acc: (93.00%) (44236/47488)
Epoch: 135 | Batch_idx: 380 |  Loss: (0.1943) |  Loss2: (0.0000) | Acc: (93.00%) (45425/48768)
Epoch: 135 | Batch_idx: 390 |  Loss: (0.1936) |  Loss2: (0.0000) | Acc: (93.00%) (46583/50000)
=> saving checkpoint 'drive/app/torch/save_Schedule/checkpoint_135.pth.tar'
# TEST : Loss: (0.4412) | Acc: (86.00%) (8675/10000)
percent tensor([0.5110, 0.4981, 0.5133, 0.5045, 0.5143, 0.5194, 0.5058, 0.5056, 0.5119,
        0.5021, 0.5108, 0.5077, 0.5024, 0.5052, 0.5057, 0.5069],
       device='cuda:0') torch.Size([16])
percent tensor([0.5068, 0.4993, 0.5110, 0.5093, 0.5069, 0.5051, 0.5026, 0.5091, 0.5107,
        0.5046, 0.5085, 0.5062, 0.5018, 0.5091, 0.5006, 0.5080],
       device='cuda:0') torch.Size([16])
percent tensor([0.5596, 0.5478, 0.5604, 0.5660, 0.5694, 0.5539, 0.5675, 0.5617, 0.5584,
        0.5599, 0.5594, 0.5604, 0.5220, 0.6053, 0.5452, 0.5664],
       device='cuda:0') torch.Size([16])
percent tensor([0.6135, 0.6366, 0.6119, 0.6068, 0.6003, 0.6051, 0.6285, 0.5995, 0.6300,
        0.6450, 0.6478, 0.6308, 0.6331, 0.6420, 0.6124, 0.6264],
       device='cuda:0') torch.Size([16])
percent tensor([0.5424, 0.6489, 0.4217, 0.5576, 0.4420, 0.5484, 0.5845, 0.3200, 0.6571,
        0.6401, 0.7007, 0.5689, 0.6186, 0.6950, 0.5030, 0.5624],
       device='cuda:0') torch.Size([16])
percent tensor([0.5920, 0.5619, 0.6088, 0.5956, 0.6378, 0.6064, 0.5890, 0.6258, 0.5881,
        0.5691, 0.5569, 0.5554, 0.5528, 0.5725, 0.5810, 0.5966],
       device='cuda:0') torch.Size([16])
percent tensor([0.5225, 0.5576, 0.6924, 0.6529, 0.7636, 0.7584, 0.5381, 0.6327, 0.6084,
        0.5329, 0.6607, 0.5620, 0.6128, 0.5442, 0.5136, 0.5041],
       device='cuda:0') torch.Size([16])
percent tensor([0.9995, 0.9996, 0.9998, 0.9995, 0.9995, 0.9993, 0.9996, 0.9998, 0.9998,
        0.9996, 0.9999, 0.9998, 0.9996, 0.9991, 0.9997, 0.9988],
       device='cuda:0') torch.Size([16])
Epoch: 136 | Batch_idx: 0 |  Loss: (0.1301) |  Loss2: (0.0000) | Acc: (95.00%) (122/128)
Epoch: 136 | Batch_idx: 10 |  Loss: (0.1695) |  Loss2: (0.0000) | Acc: (93.00%) (1321/1408)
Epoch: 136 | Batch_idx: 20 |  Loss: (0.1645) |  Loss2: (0.0000) | Acc: (94.00%) (2529/2688)
Epoch: 136 | Batch_idx: 30 |  Loss: (0.1679) |  Loss2: (0.0000) | Acc: (94.00%) (3734/3968)
Epoch: 136 | Batch_idx: 40 |  Loss: (0.1709) |  Loss2: (0.0000) | Acc: (93.00%) (4931/5248)
Epoch: 136 | Batch_idx: 50 |  Loss: (0.1738) |  Loss2: (0.0000) | Acc: (93.00%) (6132/6528)
Epoch: 136 | Batch_idx: 60 |  Loss: (0.1771) |  Loss2: (0.0000) | Acc: (93.00%) (7324/7808)
Epoch: 136 | Batch_idx: 70 |  Loss: (0.1755) |  Loss2: (0.0000) | Acc: (93.00%) (8529/9088)
Epoch: 136 | Batch_idx: 80 |  Loss: (0.1752) |  Loss2: (0.0000) | Acc: (93.00%) (9737/10368)
Epoch: 136 | Batch_idx: 90 |  Loss: (0.1757) |  Loss2: (0.0000) | Acc: (93.00%) (10936/11648)
Epoch: 136 | Batch_idx: 100 |  Loss: (0.1746) |  Loss2: (0.0000) | Acc: (93.00%) (12148/12928)
Epoch: 136 | Batch_idx: 110 |  Loss: (0.1773) |  Loss2: (0.0000) | Acc: (93.00%) (13340/14208)
Epoch: 136 | Batch_idx: 120 |  Loss: (0.1776) |  Loss2: (0.0000) | Acc: (93.00%) (14540/15488)
Epoch: 136 | Batch_idx: 130 |  Loss: (0.1760) |  Loss2: (0.0000) | Acc: (93.00%) (15750/16768)
Epoch: 136 | Batch_idx: 140 |  Loss: (0.1749) |  Loss2: (0.0000) | Acc: (93.00%) (16955/18048)
Epoch: 136 | Batch_idx: 150 |  Loss: (0.1726) |  Loss2: (0.0000) | Acc: (94.00%) (18175/19328)
Epoch: 136 | Batch_idx: 160 |  Loss: (0.1739) |  Loss2: (0.0000) | Acc: (94.00%) (19375/20608)
Epoch: 136 | Batch_idx: 170 |  Loss: (0.1737) |  Loss2: (0.0000) | Acc: (93.00%) (20574/21888)
Epoch: 136 | Batch_idx: 180 |  Loss: (0.1748) |  Loss2: (0.0000) | Acc: (93.00%) (21766/23168)
Epoch: 136 | Batch_idx: 190 |  Loss: (0.1737) |  Loss2: (0.0000) | Acc: (93.00%) (22976/24448)
Epoch: 136 | Batch_idx: 200 |  Loss: (0.1737) |  Loss2: (0.0000) | Acc: (93.00%) (24182/25728)
Epoch: 136 | Batch_idx: 210 |  Loss: (0.1749) |  Loss2: (0.0000) | Acc: (93.00%) (25378/27008)
Epoch: 136 | Batch_idx: 220 |  Loss: (0.1742) |  Loss2: (0.0000) | Acc: (94.00%) (26594/28288)
Epoch: 136 | Batch_idx: 230 |  Loss: (0.1736) |  Loss2: (0.0000) | Acc: (94.00%) (27809/29568)
Epoch: 136 | Batch_idx: 240 |  Loss: (0.1732) |  Loss2: (0.0000) | Acc: (94.00%) (29018/30848)
Epoch: 136 | Batch_idx: 250 |  Loss: (0.1734) |  Loss2: (0.0000) | Acc: (94.00%) (30217/32128)
Epoch: 136 | Batch_idx: 260 |  Loss: (0.1737) |  Loss2: (0.0000) | Acc: (94.00%) (31408/33408)
Epoch: 136 | Batch_idx: 270 |  Loss: (0.1735) |  Loss2: (0.0000) | Acc: (94.00%) (32613/34688)
Epoch: 136 | Batch_idx: 280 |  Loss: (0.1734) |  Loss2: (0.0000) | Acc: (94.00%) (33820/35968)
Epoch: 136 | Batch_idx: 290 |  Loss: (0.1731) |  Loss2: (0.0000) | Acc: (94.00%) (35025/37248)
Epoch: 136 | Batch_idx: 300 |  Loss: (0.1734) |  Loss2: (0.0000) | Acc: (93.00%) (36216/38528)
Epoch: 136 | Batch_idx: 310 |  Loss: (0.1732) |  Loss2: (0.0000) | Acc: (93.00%) (37412/39808)
Epoch: 136 | Batch_idx: 320 |  Loss: (0.1730) |  Loss2: (0.0000) | Acc: (93.00%) (38617/41088)
Epoch: 136 | Batch_idx: 330 |  Loss: (0.1720) |  Loss2: (0.0000) | Acc: (94.00%) (39831/42368)
Epoch: 136 | Batch_idx: 340 |  Loss: (0.1717) |  Loss2: (0.0000) | Acc: (94.00%) (41043/43648)
Epoch: 136 | Batch_idx: 350 |  Loss: (0.1714) |  Loss2: (0.0000) | Acc: (94.00%) (42252/44928)
Epoch: 136 | Batch_idx: 360 |  Loss: (0.1708) |  Loss2: (0.0000) | Acc: (94.00%) (43468/46208)
Epoch: 136 | Batch_idx: 370 |  Loss: (0.1712) |  Loss2: (0.0000) | Acc: (94.00%) (44669/47488)
Epoch: 136 | Batch_idx: 380 |  Loss: (0.1711) |  Loss2: (0.0000) | Acc: (94.00%) (45873/48768)
Epoch: 136 | Batch_idx: 390 |  Loss: (0.1706) |  Loss2: (0.0000) | Acc: (94.00%) (47038/50000)
# TEST : Loss: (0.4179) | Acc: (87.00%) (8732/10000)
percent tensor([0.5119, 0.4990, 0.5141, 0.5058, 0.5153, 0.5211, 0.5067, 0.5065, 0.5126,
        0.5027, 0.5117, 0.5083, 0.5030, 0.5061, 0.5072, 0.5080],
       device='cuda:0') torch.Size([16])
percent tensor([0.5076, 0.5005, 0.5107, 0.5096, 0.5072, 0.5059, 0.5035, 0.5097, 0.5114,
        0.5052, 0.5094, 0.5063, 0.5025, 0.5106, 0.5018, 0.5088],
       device='cuda:0') torch.Size([16])
percent tensor([0.5568, 0.5499, 0.5566, 0.5642, 0.5662, 0.5496, 0.5685, 0.5601, 0.5572,
        0.5608, 0.5590, 0.5585, 0.5198, 0.6110, 0.5432, 0.5651],
       device='cuda:0') torch.Size([16])
percent tensor([0.6179, 0.6402, 0.6154, 0.6104, 0.6046, 0.6107, 0.6315, 0.6038, 0.6342,
        0.6472, 0.6509, 0.6329, 0.6370, 0.6461, 0.6167, 0.6305],
       device='cuda:0') torch.Size([16])
percent tensor([0.5526, 0.6615, 0.4254, 0.5609, 0.4389, 0.5471, 0.5946, 0.3180, 0.6594,
        0.6539, 0.7099, 0.5727, 0.6286, 0.7052, 0.5070, 0.5742],
       device='cuda:0') torch.Size([16])
percent tensor([0.5973, 0.5682, 0.6131, 0.6021, 0.6430, 0.6145, 0.5960, 0.6320, 0.5937,
        0.5737, 0.5618, 0.5595, 0.5578, 0.5779, 0.5870, 0.6039],
       device='cuda:0') torch.Size([16])
percent tensor([0.5402, 0.5716, 0.6801, 0.6432, 0.7515, 0.7667, 0.5485, 0.6192, 0.6213,
        0.5403, 0.6727, 0.5538, 0.6400, 0.5559, 0.5150, 0.5168],
       device='cuda:0') torch.Size([16])
percent tensor([0.9995, 0.9995, 0.9998, 0.9995, 0.9995, 0.9993, 0.9996, 0.9997, 0.9998,
        0.9996, 0.9999, 0.9998, 0.9996, 0.9991, 0.9996, 0.9990],
       device='cuda:0') torch.Size([16])
Epoch: 137 | Batch_idx: 0 |  Loss: (0.0736) |  Loss2: (0.0000) | Acc: (99.00%) (127/128)
Epoch: 137 | Batch_idx: 10 |  Loss: (0.1587) |  Loss2: (0.0000) | Acc: (94.00%) (1334/1408)
Epoch: 137 | Batch_idx: 20 |  Loss: (0.1580) |  Loss2: (0.0000) | Acc: (94.00%) (2540/2688)
Epoch: 137 | Batch_idx: 30 |  Loss: (0.1563) |  Loss2: (0.0000) | Acc: (94.00%) (3751/3968)
Epoch: 137 | Batch_idx: 40 |  Loss: (0.1592) |  Loss2: (0.0000) | Acc: (94.00%) (4958/5248)
Epoch: 137 | Batch_idx: 50 |  Loss: (0.1679) |  Loss2: (0.0000) | Acc: (94.00%) (6146/6528)
Epoch: 137 | Batch_idx: 60 |  Loss: (0.1653) |  Loss2: (0.0000) | Acc: (94.00%) (7357/7808)
Epoch: 137 | Batch_idx: 70 |  Loss: (0.1625) |  Loss2: (0.0000) | Acc: (94.00%) (8567/9088)
Epoch: 137 | Batch_idx: 80 |  Loss: (0.1638) |  Loss2: (0.0000) | Acc: (94.00%) (9769/10368)
Epoch: 137 | Batch_idx: 90 |  Loss: (0.1623) |  Loss2: (0.0000) | Acc: (94.00%) (10989/11648)
Epoch: 137 | Batch_idx: 100 |  Loss: (0.1599) |  Loss2: (0.0000) | Acc: (94.00%) (12204/12928)
Epoch: 137 | Batch_idx: 110 |  Loss: (0.1588) |  Loss2: (0.0000) | Acc: (94.00%) (13426/14208)
Epoch: 137 | Batch_idx: 120 |  Loss: (0.1591) |  Loss2: (0.0000) | Acc: (94.00%) (14633/15488)
Epoch: 137 | Batch_idx: 130 |  Loss: (0.1582) |  Loss2: (0.0000) | Acc: (94.00%) (15844/16768)
Epoch: 137 | Batch_idx: 140 |  Loss: (0.1606) |  Loss2: (0.0000) | Acc: (94.00%) (17036/18048)
Epoch: 137 | Batch_idx: 150 |  Loss: (0.1604) |  Loss2: (0.0000) | Acc: (94.00%) (18246/19328)
Epoch: 137 | Batch_idx: 160 |  Loss: (0.1599) |  Loss2: (0.0000) | Acc: (94.00%) (19454/20608)
Epoch: 137 | Batch_idx: 170 |  Loss: (0.1596) |  Loss2: (0.0000) | Acc: (94.00%) (20663/21888)
Epoch: 137 | Batch_idx: 180 |  Loss: (0.1592) |  Loss2: (0.0000) | Acc: (94.00%) (21883/23168)
Epoch: 137 | Batch_idx: 190 |  Loss: (0.1591) |  Loss2: (0.0000) | Acc: (94.00%) (23095/24448)
Epoch: 137 | Batch_idx: 200 |  Loss: (0.1589) |  Loss2: (0.0000) | Acc: (94.00%) (24314/25728)
Epoch: 137 | Batch_idx: 210 |  Loss: (0.1594) |  Loss2: (0.0000) | Acc: (94.00%) (25514/27008)
Epoch: 137 | Batch_idx: 220 |  Loss: (0.1606) |  Loss2: (0.0000) | Acc: (94.00%) (26715/28288)
Epoch: 137 | Batch_idx: 230 |  Loss: (0.1609) |  Loss2: (0.0000) | Acc: (94.00%) (27931/29568)
Epoch: 137 | Batch_idx: 240 |  Loss: (0.1605) |  Loss2: (0.0000) | Acc: (94.00%) (29149/30848)
Epoch: 137 | Batch_idx: 250 |  Loss: (0.1604) |  Loss2: (0.0000) | Acc: (94.00%) (30357/32128)
Epoch: 137 | Batch_idx: 260 |  Loss: (0.1609) |  Loss2: (0.0000) | Acc: (94.00%) (31561/33408)
Epoch: 137 | Batch_idx: 270 |  Loss: (0.1603) |  Loss2: (0.0000) | Acc: (94.00%) (32782/34688)
Epoch: 137 | Batch_idx: 280 |  Loss: (0.1609) |  Loss2: (0.0000) | Acc: (94.00%) (33982/35968)
Epoch: 137 | Batch_idx: 290 |  Loss: (0.1609) |  Loss2: (0.0000) | Acc: (94.00%) (35184/37248)
Epoch: 137 | Batch_idx: 300 |  Loss: (0.1611) |  Loss2: (0.0000) | Acc: (94.00%) (36392/38528)
Epoch: 137 | Batch_idx: 310 |  Loss: (0.1603) |  Loss2: (0.0000) | Acc: (94.00%) (37614/39808)
Epoch: 137 | Batch_idx: 320 |  Loss: (0.1599) |  Loss2: (0.0000) | Acc: (94.00%) (38831/41088)
Epoch: 137 | Batch_idx: 330 |  Loss: (0.1595) |  Loss2: (0.0000) | Acc: (94.00%) (40047/42368)
Epoch: 137 | Batch_idx: 340 |  Loss: (0.1592) |  Loss2: (0.0000) | Acc: (94.00%) (41266/43648)
Epoch: 137 | Batch_idx: 350 |  Loss: (0.1593) |  Loss2: (0.0000) | Acc: (94.00%) (42474/44928)
Epoch: 137 | Batch_idx: 360 |  Loss: (0.1585) |  Loss2: (0.0000) | Acc: (94.00%) (43702/46208)
Epoch: 137 | Batch_idx: 370 |  Loss: (0.1585) |  Loss2: (0.0000) | Acc: (94.00%) (44909/47488)
Epoch: 137 | Batch_idx: 380 |  Loss: (0.1585) |  Loss2: (0.0000) | Acc: (94.00%) (46114/48768)
Epoch: 137 | Batch_idx: 390 |  Loss: (0.1586) |  Loss2: (0.0000) | Acc: (94.00%) (47281/50000)
# TEST : Loss: (0.4059) | Acc: (87.00%) (8790/10000)
percent tensor([0.5151, 0.5029, 0.5179, 0.5096, 0.5194, 0.5242, 0.5104, 0.5104, 0.5161,
        0.5063, 0.5152, 0.5121, 0.5063, 0.5093, 0.5112, 0.5114],
       device='cuda:0') torch.Size([16])
percent tensor([0.5093, 0.5026, 0.5116, 0.5109, 0.5086, 0.5075, 0.5054, 0.5113, 0.5131,
        0.5069, 0.5112, 0.5074, 0.5042, 0.5128, 0.5038, 0.5105],
       device='cuda:0') torch.Size([16])
percent tensor([0.5513, 0.5446, 0.5510, 0.5595, 0.5598, 0.5452, 0.5634, 0.5544, 0.5513,
        0.5549, 0.5523, 0.5531, 0.5143, 0.6064, 0.5379, 0.5601],
       device='cuda:0') torch.Size([16])
percent tensor([0.6204, 0.6427, 0.6175, 0.6128, 0.6069, 0.6144, 0.6334, 0.6060, 0.6369,
        0.6488, 0.6531, 0.6345, 0.6396, 0.6493, 0.6192, 0.6330],
       device='cuda:0') torch.Size([16])
percent tensor([0.5666, 0.6719, 0.4347, 0.5729, 0.4446, 0.5557, 0.6089, 0.3227, 0.6673,
        0.6645, 0.7188, 0.5833, 0.6367, 0.7166, 0.5164, 0.5909],
       device='cuda:0') torch.Size([16])
percent tensor([0.6046, 0.5747, 0.6189, 0.6095, 0.6508, 0.6240, 0.6043, 0.6399, 0.6004,
        0.5800, 0.5678, 0.5638, 0.5634, 0.5844, 0.5930, 0.6130],
       device='cuda:0') torch.Size([16])
percent tensor([0.5447, 0.5686, 0.6679, 0.6320, 0.7434, 0.7743, 0.5451, 0.6064, 0.6225,
        0.5384, 0.6741, 0.5405, 0.6481, 0.5578, 0.5086, 0.5210],
       device='cuda:0') torch.Size([16])
percent tensor([0.9995, 0.9995, 0.9998, 0.9995, 0.9994, 0.9993, 0.9995, 0.9997, 0.9998,
        0.9996, 0.9999, 0.9997, 0.9996, 0.9990, 0.9996, 0.9990],
       device='cuda:0') torch.Size([16])
Epoch: 138 | Batch_idx: 0 |  Loss: (0.1272) |  Loss2: (0.0000) | Acc: (95.00%) (122/128)
Epoch: 138 | Batch_idx: 10 |  Loss: (0.1510) |  Loss2: (0.0000) | Acc: (95.00%) (1342/1408)
Epoch: 138 | Batch_idx: 20 |  Loss: (0.1539) |  Loss2: (0.0000) | Acc: (94.00%) (2552/2688)
Epoch: 138 | Batch_idx: 30 |  Loss: (0.1564) |  Loss2: (0.0000) | Acc: (94.00%) (3756/3968)
Epoch: 138 | Batch_idx: 40 |  Loss: (0.1535) |  Loss2: (0.0000) | Acc: (94.00%) (4977/5248)
Epoch: 138 | Batch_idx: 50 |  Loss: (0.1513) |  Loss2: (0.0000) | Acc: (94.00%) (6191/6528)
Epoch: 138 | Batch_idx: 60 |  Loss: (0.1541) |  Loss2: (0.0000) | Acc: (94.00%) (7392/7808)
Epoch: 138 | Batch_idx: 70 |  Loss: (0.1538) |  Loss2: (0.0000) | Acc: (94.00%) (8613/9088)
Epoch: 138 | Batch_idx: 80 |  Loss: (0.1534) |  Loss2: (0.0000) | Acc: (94.00%) (9826/10368)
Epoch: 138 | Batch_idx: 90 |  Loss: (0.1535) |  Loss2: (0.0000) | Acc: (94.00%) (11037/11648)
Epoch: 138 | Batch_idx: 100 |  Loss: (0.1522) |  Loss2: (0.0000) | Acc: (94.00%) (12260/12928)
Epoch: 138 | Batch_idx: 110 |  Loss: (0.1508) |  Loss2: (0.0000) | Acc: (94.00%) (13483/14208)
Epoch: 138 | Batch_idx: 120 |  Loss: (0.1488) |  Loss2: (0.0000) | Acc: (94.00%) (14702/15488)
Epoch: 138 | Batch_idx: 130 |  Loss: (0.1497) |  Loss2: (0.0000) | Acc: (94.00%) (15907/16768)
Epoch: 138 | Batch_idx: 140 |  Loss: (0.1511) |  Loss2: (0.0000) | Acc: (94.00%) (17114/18048)
Epoch: 138 | Batch_idx: 150 |  Loss: (0.1514) |  Loss2: (0.0000) | Acc: (94.00%) (18331/19328)
Epoch: 138 | Batch_idx: 160 |  Loss: (0.1522) |  Loss2: (0.0000) | Acc: (94.00%) (19536/20608)
Epoch: 138 | Batch_idx: 170 |  Loss: (0.1516) |  Loss2: (0.0000) | Acc: (94.00%) (20754/21888)
Epoch: 138 | Batch_idx: 180 |  Loss: (0.1512) |  Loss2: (0.0000) | Acc: (94.00%) (21966/23168)
Epoch: 138 | Batch_idx: 190 |  Loss: (0.1512) |  Loss2: (0.0000) | Acc: (94.00%) (23176/24448)
Epoch: 138 | Batch_idx: 200 |  Loss: (0.1506) |  Loss2: (0.0000) | Acc: (94.00%) (24401/25728)
Epoch: 138 | Batch_idx: 210 |  Loss: (0.1507) |  Loss2: (0.0000) | Acc: (94.00%) (25613/27008)
Epoch: 138 | Batch_idx: 220 |  Loss: (0.1517) |  Loss2: (0.0000) | Acc: (94.00%) (26816/28288)
Epoch: 138 | Batch_idx: 230 |  Loss: (0.1519) |  Loss2: (0.0000) | Acc: (94.00%) (28023/29568)
Epoch: 138 | Batch_idx: 240 |  Loss: (0.1521) |  Loss2: (0.0000) | Acc: (94.00%) (29231/30848)
Epoch: 138 | Batch_idx: 250 |  Loss: (0.1519) |  Loss2: (0.0000) | Acc: (94.00%) (30445/32128)
Epoch: 138 | Batch_idx: 260 |  Loss: (0.1521) |  Loss2: (0.0000) | Acc: (94.00%) (31655/33408)
Epoch: 138 | Batch_idx: 270 |  Loss: (0.1525) |  Loss2: (0.0000) | Acc: (94.00%) (32863/34688)
Epoch: 138 | Batch_idx: 280 |  Loss: (0.1523) |  Loss2: (0.0000) | Acc: (94.00%) (34080/35968)
Epoch: 138 | Batch_idx: 290 |  Loss: (0.1520) |  Loss2: (0.0000) | Acc: (94.00%) (35296/37248)
Epoch: 138 | Batch_idx: 300 |  Loss: (0.1521) |  Loss2: (0.0000) | Acc: (94.00%) (36514/38528)
Epoch: 138 | Batch_idx: 310 |  Loss: (0.1529) |  Loss2: (0.0000) | Acc: (94.00%) (37704/39808)
Epoch: 138 | Batch_idx: 320 |  Loss: (0.1531) |  Loss2: (0.0000) | Acc: (94.00%) (38919/41088)
Epoch: 138 | Batch_idx: 330 |  Loss: (0.1530) |  Loss2: (0.0000) | Acc: (94.00%) (40138/42368)
Epoch: 138 | Batch_idx: 340 |  Loss: (0.1534) |  Loss2: (0.0000) | Acc: (94.00%) (41343/43648)
Epoch: 138 | Batch_idx: 350 |  Loss: (0.1536) |  Loss2: (0.0000) | Acc: (94.00%) (42551/44928)
Epoch: 138 | Batch_idx: 360 |  Loss: (0.1532) |  Loss2: (0.0000) | Acc: (94.00%) (43762/46208)
Epoch: 138 | Batch_idx: 370 |  Loss: (0.1530) |  Loss2: (0.0000) | Acc: (94.00%) (44973/47488)
Epoch: 138 | Batch_idx: 380 |  Loss: (0.1526) |  Loss2: (0.0000) | Acc: (94.00%) (46192/48768)
Epoch: 138 | Batch_idx: 390 |  Loss: (0.1530) |  Loss2: (0.0000) | Acc: (94.00%) (47356/50000)
# TEST : Loss: (0.3989) | Acc: (88.00%) (8800/10000)
percent tensor([0.5161, 0.5037, 0.5190, 0.5108, 0.5206, 0.5256, 0.5113, 0.5115, 0.5171,
        0.5071, 0.5162, 0.5130, 0.5070, 0.5102, 0.5124, 0.5123],
       device='cuda:0') torch.Size([16])
percent tensor([0.5102, 0.5036, 0.5120, 0.5116, 0.5093, 0.5086, 0.5063, 0.5121, 0.5140,
        0.5076, 0.5122, 0.5078, 0.5050, 0.5142, 0.5049, 0.5114],
       device='cuda:0') torch.Size([16])
percent tensor([0.5510, 0.5450, 0.5516, 0.5598, 0.5613, 0.5450, 0.5653, 0.5560, 0.5526,
        0.5552, 0.5526, 0.5535, 0.5132, 0.6095, 0.5384, 0.5603],
       device='cuda:0') torch.Size([16])
percent tensor([0.6219, 0.6442, 0.6188, 0.6138, 0.6084, 0.6165, 0.6345, 0.6077, 0.6386,
        0.6497, 0.6542, 0.6353, 0.6411, 0.6515, 0.6205, 0.6343],
       device='cuda:0') torch.Size([16])
percent tensor([0.5748, 0.6758, 0.4401, 0.5790, 0.4499, 0.5664, 0.6169, 0.3274, 0.6691,
        0.6699, 0.7215, 0.5857, 0.6392, 0.7215, 0.5209, 0.6050],
       device='cuda:0') torch.Size([16])
percent tensor([0.6057, 0.5754, 0.6205, 0.6113, 0.6534, 0.6273, 0.6050, 0.6433, 0.6002,
        0.5801, 0.5665, 0.5630, 0.5637, 0.5832, 0.5935, 0.6155],
       device='cuda:0') torch.Size([16])
percent tensor([0.5545, 0.5741, 0.6667, 0.6267, 0.7417, 0.7735, 0.5515, 0.6129, 0.6269,
        0.5442, 0.6736, 0.5404, 0.6560, 0.5549, 0.5141, 0.5255],
       device='cuda:0') torch.Size([16])
percent tensor([0.9995, 0.9995, 0.9998, 0.9995, 0.9994, 0.9993, 0.9995, 0.9998, 0.9998,
        0.9996, 0.9998, 0.9997, 0.9997, 0.9991, 0.9996, 0.9991],
       device='cuda:0') torch.Size([16])
Epoch: 139 | Batch_idx: 0 |  Loss: (0.1731) |  Loss2: (0.0000) | Acc: (93.00%) (120/128)
Epoch: 139 | Batch_idx: 10 |  Loss: (0.1629) |  Loss2: (0.0000) | Acc: (94.00%) (1331/1408)
Epoch: 139 | Batch_idx: 20 |  Loss: (0.1712) |  Loss2: (0.0000) | Acc: (93.00%) (2516/2688)
Epoch: 139 | Batch_idx: 30 |  Loss: (0.1604) |  Loss2: (0.0000) | Acc: (93.00%) (3729/3968)
Epoch: 139 | Batch_idx: 40 |  Loss: (0.1641) |  Loss2: (0.0000) | Acc: (94.00%) (4938/5248)
Epoch: 139 | Batch_idx: 50 |  Loss: (0.1620) |  Loss2: (0.0000) | Acc: (94.00%) (6143/6528)
Epoch: 139 | Batch_idx: 60 |  Loss: (0.1635) |  Loss2: (0.0000) | Acc: (94.00%) (7343/7808)
Epoch: 139 | Batch_idx: 70 |  Loss: (0.1631) |  Loss2: (0.0000) | Acc: (94.00%) (8559/9088)
Epoch: 139 | Batch_idx: 80 |  Loss: (0.1608) |  Loss2: (0.0000) | Acc: (94.00%) (9775/10368)
Epoch: 139 | Batch_idx: 90 |  Loss: (0.1616) |  Loss2: (0.0000) | Acc: (94.00%) (10978/11648)
Epoch: 139 | Batch_idx: 100 |  Loss: (0.1589) |  Loss2: (0.0000) | Acc: (94.00%) (12198/12928)
Epoch: 139 | Batch_idx: 110 |  Loss: (0.1585) |  Loss2: (0.0000) | Acc: (94.00%) (13403/14208)
Epoch: 139 | Batch_idx: 120 |  Loss: (0.1568) |  Loss2: (0.0000) | Acc: (94.00%) (14622/15488)
Epoch: 139 | Batch_idx: 130 |  Loss: (0.1572) |  Loss2: (0.0000) | Acc: (94.00%) (15828/16768)
Epoch: 139 | Batch_idx: 140 |  Loss: (0.1552) |  Loss2: (0.0000) | Acc: (94.00%) (17052/18048)
Epoch: 139 | Batch_idx: 150 |  Loss: (0.1545) |  Loss2: (0.0000) | Acc: (94.00%) (18263/19328)
Epoch: 139 | Batch_idx: 160 |  Loss: (0.1552) |  Loss2: (0.0000) | Acc: (94.00%) (19473/20608)
Epoch: 139 | Batch_idx: 170 |  Loss: (0.1553) |  Loss2: (0.0000) | Acc: (94.00%) (20685/21888)
Epoch: 139 | Batch_idx: 180 |  Loss: (0.1552) |  Loss2: (0.0000) | Acc: (94.00%) (21893/23168)
Epoch: 139 | Batch_idx: 190 |  Loss: (0.1543) |  Loss2: (0.0000) | Acc: (94.00%) (23113/24448)
Epoch: 139 | Batch_idx: 200 |  Loss: (0.1536) |  Loss2: (0.0000) | Acc: (94.00%) (24340/25728)
Epoch: 139 | Batch_idx: 210 |  Loss: (0.1541) |  Loss2: (0.0000) | Acc: (94.00%) (25540/27008)
Epoch: 139 | Batch_idx: 220 |  Loss: (0.1540) |  Loss2: (0.0000) | Acc: (94.00%) (26760/28288)
Epoch: 139 | Batch_idx: 230 |  Loss: (0.1522) |  Loss2: (0.0000) | Acc: (94.00%) (27993/29568)
Epoch: 139 | Batch_idx: 240 |  Loss: (0.1513) |  Loss2: (0.0000) | Acc: (94.00%) (29217/30848)
Epoch: 139 | Batch_idx: 250 |  Loss: (0.1509) |  Loss2: (0.0000) | Acc: (94.00%) (30432/32128)
Epoch: 139 | Batch_idx: 260 |  Loss: (0.1505) |  Loss2: (0.0000) | Acc: (94.00%) (31655/33408)
Epoch: 139 | Batch_idx: 270 |  Loss: (0.1511) |  Loss2: (0.0000) | Acc: (94.00%) (32866/34688)
Epoch: 139 | Batch_idx: 280 |  Loss: (0.1513) |  Loss2: (0.0000) | Acc: (94.00%) (34078/35968)
Epoch: 139 | Batch_idx: 290 |  Loss: (0.1512) |  Loss2: (0.0000) | Acc: (94.00%) (35292/37248)
Epoch: 139 | Batch_idx: 300 |  Loss: (0.1510) |  Loss2: (0.0000) | Acc: (94.00%) (36520/38528)
Epoch: 139 | Batch_idx: 310 |  Loss: (0.1510) |  Loss2: (0.0000) | Acc: (94.00%) (37730/39808)
Epoch: 139 | Batch_idx: 320 |  Loss: (0.1509) |  Loss2: (0.0000) | Acc: (94.00%) (38946/41088)
Epoch: 139 | Batch_idx: 330 |  Loss: (0.1507) |  Loss2: (0.0000) | Acc: (94.00%) (40166/42368)
Epoch: 139 | Batch_idx: 340 |  Loss: (0.1504) |  Loss2: (0.0000) | Acc: (94.00%) (41388/43648)
Epoch: 139 | Batch_idx: 350 |  Loss: (0.1496) |  Loss2: (0.0000) | Acc: (94.00%) (42619/44928)
Epoch: 139 | Batch_idx: 360 |  Loss: (0.1495) |  Loss2: (0.0000) | Acc: (94.00%) (43832/46208)
Epoch: 139 | Batch_idx: 370 |  Loss: (0.1494) |  Loss2: (0.0000) | Acc: (94.00%) (45048/47488)
Epoch: 139 | Batch_idx: 380 |  Loss: (0.1493) |  Loss2: (0.0000) | Acc: (94.00%) (46260/48768)
Epoch: 139 | Batch_idx: 390 |  Loss: (0.1487) |  Loss2: (0.0000) | Acc: (94.00%) (47440/50000)
# TEST : Loss: (0.3966) | Acc: (88.00%) (8813/10000)
percent tensor([0.5169, 0.5044, 0.5197, 0.5117, 0.5213, 0.5268, 0.5121, 0.5122, 0.5178,
        0.5077, 0.5171, 0.5136, 0.5077, 0.5109, 0.5134, 0.5131],
       device='cuda:0') torch.Size([16])
percent tensor([0.5106, 0.5044, 0.5120, 0.5117, 0.5095, 0.5092, 0.5068, 0.5124, 0.5143,
        0.5080, 0.5127, 0.5078, 0.5053, 0.5150, 0.5056, 0.5119],
       device='cuda:0') torch.Size([16])
percent tensor([0.5465, 0.5432, 0.5477, 0.5563, 0.5584, 0.5392, 0.5637, 0.5542, 0.5494,
        0.5526, 0.5491, 0.5508, 0.5103, 0.6063, 0.5352, 0.5559],
       device='cuda:0') torch.Size([16])
percent tensor([0.6209, 0.6429, 0.6182, 0.6132, 0.6079, 0.6165, 0.6329, 0.6070, 0.6381,
        0.6479, 0.6529, 0.6338, 0.6398, 0.6510, 0.6188, 0.6333],
       device='cuda:0') torch.Size([16])
percent tensor([0.5823, 0.6815, 0.4434, 0.5829, 0.4575, 0.5763, 0.6229, 0.3319, 0.6688,
        0.6736, 0.7231, 0.5851, 0.6449, 0.7235, 0.5296, 0.6158],
       device='cuda:0') torch.Size([16])
percent tensor([0.6105, 0.5806, 0.6250, 0.6168, 0.6590, 0.6341, 0.6105, 0.6489, 0.6051,
        0.5840, 0.5710, 0.5671, 0.5677, 0.5881, 0.5976, 0.6208],
       device='cuda:0') torch.Size([16])
percent tensor([0.5587, 0.5745, 0.6695, 0.6250, 0.7450, 0.7794, 0.5542, 0.6143, 0.6325,
        0.5447, 0.6752, 0.5419, 0.6567, 0.5557, 0.5177, 0.5266],
       device='cuda:0') torch.Size([16])
percent tensor([0.9996, 0.9995, 0.9998, 0.9995, 0.9994, 0.9993, 0.9995, 0.9998, 0.9998,
        0.9995, 0.9999, 0.9998, 0.9997, 0.9990, 0.9996, 0.9992],
       device='cuda:0') torch.Size([16])
Epoch: 140 | Batch_idx: 0 |  Loss: (0.1590) |  Loss2: (0.0000) | Acc: (92.00%) (119/128)
Epoch: 140 | Batch_idx: 10 |  Loss: (0.1403) |  Loss2: (0.0000) | Acc: (95.00%) (1346/1408)
Epoch: 140 | Batch_idx: 20 |  Loss: (0.1443) |  Loss2: (0.0000) | Acc: (95.00%) (2559/2688)
Epoch: 140 | Batch_idx: 30 |  Loss: (0.1445) |  Loss2: (0.0000) | Acc: (95.00%) (3773/3968)
Epoch: 140 | Batch_idx: 40 |  Loss: (0.1506) |  Loss2: (0.0000) | Acc: (94.00%) (4980/5248)
Epoch: 140 | Batch_idx: 50 |  Loss: (0.1504) |  Loss2: (0.0000) | Acc: (94.00%) (6198/6528)
Epoch: 140 | Batch_idx: 60 |  Loss: (0.1515) |  Loss2: (0.0000) | Acc: (94.00%) (7404/7808)
Epoch: 140 | Batch_idx: 70 |  Loss: (0.1511) |  Loss2: (0.0000) | Acc: (94.00%) (8626/9088)
Epoch: 140 | Batch_idx: 80 |  Loss: (0.1517) |  Loss2: (0.0000) | Acc: (94.00%) (9838/10368)
Epoch: 140 | Batch_idx: 90 |  Loss: (0.1494) |  Loss2: (0.0000) | Acc: (94.00%) (11060/11648)
Epoch: 140 | Batch_idx: 100 |  Loss: (0.1487) |  Loss2: (0.0000) | Acc: (94.00%) (12273/12928)
Epoch: 140 | Batch_idx: 110 |  Loss: (0.1481) |  Loss2: (0.0000) | Acc: (94.00%) (13483/14208)
Epoch: 140 | Batch_idx: 120 |  Loss: (0.1477) |  Loss2: (0.0000) | Acc: (94.00%) (14703/15488)
Epoch: 140 | Batch_idx: 130 |  Loss: (0.1471) |  Loss2: (0.0000) | Acc: (94.00%) (15924/16768)
Epoch: 140 | Batch_idx: 140 |  Loss: (0.1471) |  Loss2: (0.0000) | Acc: (94.00%) (17144/18048)
Epoch: 140 | Batch_idx: 150 |  Loss: (0.1471) |  Loss2: (0.0000) | Acc: (94.00%) (18360/19328)
Epoch: 140 | Batch_idx: 160 |  Loss: (0.1479) |  Loss2: (0.0000) | Acc: (94.00%) (19571/20608)
Epoch: 140 | Batch_idx: 170 |  Loss: (0.1479) |  Loss2: (0.0000) | Acc: (94.00%) (20784/21888)
Epoch: 140 | Batch_idx: 180 |  Loss: (0.1477) |  Loss2: (0.0000) | Acc: (94.00%) (22004/23168)
Epoch: 140 | Batch_idx: 190 |  Loss: (0.1485) |  Loss2: (0.0000) | Acc: (94.00%) (23211/24448)
Epoch: 140 | Batch_idx: 200 |  Loss: (0.1483) |  Loss2: (0.0000) | Acc: (94.00%) (24428/25728)
Epoch: 140 | Batch_idx: 210 |  Loss: (0.1472) |  Loss2: (0.0000) | Acc: (94.00%) (25655/27008)
Epoch: 140 | Batch_idx: 220 |  Loss: (0.1478) |  Loss2: (0.0000) | Acc: (94.00%) (26862/28288)
Epoch: 140 | Batch_idx: 230 |  Loss: (0.1478) |  Loss2: (0.0000) | Acc: (94.00%) (28070/29568)
Epoch: 140 | Batch_idx: 240 |  Loss: (0.1478) |  Loss2: (0.0000) | Acc: (94.00%) (29286/30848)
Epoch: 140 | Batch_idx: 250 |  Loss: (0.1473) |  Loss2: (0.0000) | Acc: (94.00%) (30505/32128)
Epoch: 140 | Batch_idx: 260 |  Loss: (0.1474) |  Loss2: (0.0000) | Acc: (94.00%) (31721/33408)
Epoch: 140 | Batch_idx: 270 |  Loss: (0.1481) |  Loss2: (0.0000) | Acc: (94.00%) (32922/34688)
Epoch: 140 | Batch_idx: 280 |  Loss: (0.1479) |  Loss2: (0.0000) | Acc: (94.00%) (34132/35968)
Epoch: 140 | Batch_idx: 290 |  Loss: (0.1476) |  Loss2: (0.0000) | Acc: (94.00%) (35350/37248)
Epoch: 140 | Batch_idx: 300 |  Loss: (0.1476) |  Loss2: (0.0000) | Acc: (94.00%) (36568/38528)
Epoch: 140 | Batch_idx: 310 |  Loss: (0.1469) |  Loss2: (0.0000) | Acc: (94.00%) (37796/39808)
Epoch: 140 | Batch_idx: 320 |  Loss: (0.1471) |  Loss2: (0.0000) | Acc: (94.00%) (39013/41088)
Epoch: 140 | Batch_idx: 330 |  Loss: (0.1472) |  Loss2: (0.0000) | Acc: (94.00%) (40224/42368)
Epoch: 140 | Batch_idx: 340 |  Loss: (0.1474) |  Loss2: (0.0000) | Acc: (94.00%) (41433/43648)
Epoch: 140 | Batch_idx: 350 |  Loss: (0.1469) |  Loss2: (0.0000) | Acc: (94.00%) (42660/44928)
Epoch: 140 | Batch_idx: 360 |  Loss: (0.1464) |  Loss2: (0.0000) | Acc: (94.00%) (43881/46208)
Epoch: 140 | Batch_idx: 370 |  Loss: (0.1467) |  Loss2: (0.0000) | Acc: (94.00%) (45087/47488)
Epoch: 140 | Batch_idx: 380 |  Loss: (0.1467) |  Loss2: (0.0000) | Acc: (94.00%) (46302/48768)
Epoch: 140 | Batch_idx: 390 |  Loss: (0.1473) |  Loss2: (0.0000) | Acc: (94.00%) (47466/50000)
=> saving checkpoint 'drive/app/torch/save_Schedule/checkpoint_140.pth.tar'
# TEST : Loss: (0.3924) | Acc: (88.00%) (8821/10000)
percent tensor([0.5169, 0.5047, 0.5197, 0.5121, 0.5213, 0.5273, 0.5121, 0.5125, 0.5176,
        0.5077, 0.5171, 0.5135, 0.5076, 0.5111, 0.5140, 0.5134],
       device='cuda:0') torch.Size([16])
percent tensor([0.5104, 0.5043, 0.5115, 0.5112, 0.5090, 0.5093, 0.5066, 0.5120, 0.5142,
        0.5077, 0.5127, 0.5073, 0.5051, 0.5154, 0.5055, 0.5117],
       device='cuda:0') torch.Size([16])
percent tensor([0.5532, 0.5478, 0.5507, 0.5608, 0.5614, 0.5489, 0.5687, 0.5563, 0.5539,
        0.5564, 0.5560, 0.5543, 0.5152, 0.6123, 0.5420, 0.5628],
       device='cuda:0') torch.Size([16])
percent tensor([0.6149, 0.6371, 0.6137, 0.6080, 0.6031, 0.6110, 0.6270, 0.6027, 0.6330,
        0.6416, 0.6469, 0.6280, 0.6342, 0.6457, 0.6129, 0.6270],
       device='cuda:0') torch.Size([16])
percent tensor([0.5735, 0.6780, 0.4426, 0.5796, 0.4544, 0.5698, 0.6181, 0.3299, 0.6621,
        0.6710, 0.7200, 0.5818, 0.6380, 0.7195, 0.5226, 0.6095],
       device='cuda:0') torch.Size([16])
percent tensor([0.6075, 0.5785, 0.6229, 0.6153, 0.6578, 0.6323, 0.6068, 0.6470, 0.6022,
        0.5820, 0.5683, 0.5646, 0.5646, 0.5852, 0.5937, 0.6188],
       device='cuda:0') torch.Size([16])
percent tensor([0.5579, 0.5716, 0.6679, 0.6212, 0.7434, 0.7750, 0.5563, 0.6153, 0.6310,
        0.5436, 0.6717, 0.5421, 0.6531, 0.5539, 0.5164, 0.5275],
       device='cuda:0') torch.Size([16])
percent tensor([0.9996, 0.9995, 0.9998, 0.9995, 0.9995, 0.9993, 0.9995, 0.9998, 0.9998,
        0.9996, 0.9999, 0.9998, 0.9997, 0.9990, 0.9996, 0.9992],
       device='cuda:0') torch.Size([16])
Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 3, 3, 3]) tensor(187.4879, device='cuda:0')
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(828.9075, device='cuda:0')
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(817.1609, device='cuda:0')
Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([128, 64, 3, 3]) tensor(1524.3884, device='cuda:0')
Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([128, 64, 1, 1]) tensor(482.3765, device='cuda:0')
Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([128, 128, 3, 3]) tensor(2281.3972, device='cuda:0')
Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([256, 128, 3, 3]) tensor(4258.0659, device='cuda:0')
Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([256, 128, 1, 1]) tensor(1369.4375, device='cuda:0')
Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([256, 256, 3, 3]) tensor(6171.0747, device='cuda:0')
Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([512, 256, 3, 3]) tensor(11713.2520, device='cuda:0')
Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([512, 256, 1, 1]) tensor(3877.8770, device='cuda:0')
Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([512, 512, 3, 3]) tensor(16390.4414, device='cuda:0')
Epoch: 141 | Batch_idx: 0 |  Loss: (0.1716) |  Loss2: (0.0000) | Acc: (92.00%) (119/128)
Epoch: 141 | Batch_idx: 10 |  Loss: (0.1636) |  Loss2: (0.0000) | Acc: (94.00%) (1329/1408)
Epoch: 141 | Batch_idx: 20 |  Loss: (0.1596) |  Loss2: (0.0000) | Acc: (94.00%) (2547/2688)
Epoch: 141 | Batch_idx: 30 |  Loss: (0.1495) |  Loss2: (0.0000) | Acc: (94.00%) (3768/3968)
Epoch: 141 | Batch_idx: 40 |  Loss: (0.1490) |  Loss2: (0.0000) | Acc: (94.00%) (4983/5248)
Epoch: 141 | Batch_idx: 50 |  Loss: (0.1532) |  Loss2: (0.0000) | Acc: (94.00%) (6195/6528)
Epoch: 141 | Batch_idx: 60 |  Loss: (0.1511) |  Loss2: (0.0000) | Acc: (94.00%) (7403/7808)
Epoch: 141 | Batch_idx: 70 |  Loss: (0.1509) |  Loss2: (0.0000) | Acc: (94.00%) (8623/9088)
Epoch: 141 | Batch_idx: 80 |  Loss: (0.1512) |  Loss2: (0.0000) | Acc: (94.00%) (9834/10368)
Epoch: 141 | Batch_idx: 90 |  Loss: (0.1498) |  Loss2: (0.0000) | Acc: (94.00%) (11053/11648)
Epoch: 141 | Batch_idx: 100 |  Loss: (0.1501) |  Loss2: (0.0000) | Acc: (94.00%) (12272/12928)
Epoch: 141 | Batch_idx: 110 |  Loss: (0.1482) |  Loss2: (0.0000) | Acc: (95.00%) (13501/14208)
Epoch: 141 | Batch_idx: 120 |  Loss: (0.1479) |  Loss2: (0.0000) | Acc: (95.00%) (14717/15488)
Epoch: 141 | Batch_idx: 130 |  Loss: (0.1478) |  Loss2: (0.0000) | Acc: (95.00%) (15940/16768)
Epoch: 141 | Batch_idx: 140 |  Loss: (0.1477) |  Loss2: (0.0000) | Acc: (95.00%) (17157/18048)
Epoch: 141 | Batch_idx: 150 |  Loss: (0.1471) |  Loss2: (0.0000) | Acc: (95.00%) (18381/19328)
Epoch: 141 | Batch_idx: 160 |  Loss: (0.1461) |  Loss2: (0.0000) | Acc: (95.00%) (19602/20608)
Epoch: 141 | Batch_idx: 170 |  Loss: (0.1452) |  Loss2: (0.0000) | Acc: (95.00%) (20829/21888)
Epoch: 141 | Batch_idx: 180 |  Loss: (0.1439) |  Loss2: (0.0000) | Acc: (95.00%) (22056/23168)
Epoch: 141 | Batch_idx: 190 |  Loss: (0.1439) |  Loss2: (0.0000) | Acc: (95.00%) (23274/24448)
Epoch: 141 | Batch_idx: 200 |  Loss: (0.1433) |  Loss2: (0.0000) | Acc: (95.00%) (24503/25728)
Epoch: 141 | Batch_idx: 210 |  Loss: (0.1423) |  Loss2: (0.0000) | Acc: (95.00%) (25736/27008)
Epoch: 141 | Batch_idx: 220 |  Loss: (0.1420) |  Loss2: (0.0000) | Acc: (95.00%) (26949/28288)
Epoch: 141 | Batch_idx: 230 |  Loss: (0.1429) |  Loss2: (0.0000) | Acc: (95.00%) (28154/29568)
Epoch: 141 | Batch_idx: 240 |  Loss: (0.1428) |  Loss2: (0.0000) | Acc: (95.00%) (29377/30848)
Epoch: 141 | Batch_idx: 250 |  Loss: (0.1432) |  Loss2: (0.0000) | Acc: (95.00%) (30589/32128)
Epoch: 141 | Batch_idx: 260 |  Loss: (0.1433) |  Loss2: (0.0000) | Acc: (95.00%) (31803/33408)
Epoch: 141 | Batch_idx: 270 |  Loss: (0.1426) |  Loss2: (0.0000) | Acc: (95.00%) (33033/34688)
Epoch: 141 | Batch_idx: 280 |  Loss: (0.1423) |  Loss2: (0.0000) | Acc: (95.00%) (34252/35968)
Epoch: 141 | Batch_idx: 290 |  Loss: (0.1419) |  Loss2: (0.0000) | Acc: (95.00%) (35482/37248)
Epoch: 141 | Batch_idx: 300 |  Loss: (0.1421) |  Loss2: (0.0000) | Acc: (95.00%) (36696/38528)
Epoch: 141 | Batch_idx: 310 |  Loss: (0.1421) |  Loss2: (0.0000) | Acc: (95.00%) (37916/39808)
Epoch: 141 | Batch_idx: 320 |  Loss: (0.1423) |  Loss2: (0.0000) | Acc: (95.00%) (39128/41088)
Epoch: 141 | Batch_idx: 330 |  Loss: (0.1427) |  Loss2: (0.0000) | Acc: (95.00%) (40345/42368)
Epoch: 141 | Batch_idx: 340 |  Loss: (0.1427) |  Loss2: (0.0000) | Acc: (95.00%) (41566/43648)
Epoch: 141 | Batch_idx: 350 |  Loss: (0.1421) |  Loss2: (0.0000) | Acc: (95.00%) (42796/44928)
Epoch: 141 | Batch_idx: 360 |  Loss: (0.1420) |  Loss2: (0.0000) | Acc: (95.00%) (44012/46208)
Epoch: 141 | Batch_idx: 370 |  Loss: (0.1423) |  Loss2: (0.0000) | Acc: (95.00%) (45223/47488)
Epoch: 141 | Batch_idx: 380 |  Loss: (0.1425) |  Loss2: (0.0000) | Acc: (95.00%) (46439/48768)
Epoch: 141 | Batch_idx: 390 |  Loss: (0.1429) |  Loss2: (0.0000) | Acc: (95.00%) (47608/50000)
# TEST : Loss: (0.3893) | Acc: (88.00%) (8824/10000)
percent tensor([0.5167, 0.5043, 0.5192, 0.5120, 0.5210, 0.5276, 0.5117, 0.5120, 0.5171,
        0.5071, 0.5168, 0.5129, 0.5071, 0.5106, 0.5140, 0.5132],
       device='cuda:0') torch.Size([16])
percent tensor([0.5106, 0.5045, 0.5112, 0.5111, 0.5089, 0.5095, 0.5067, 0.5120, 0.5142,
        0.5077, 0.5129, 0.5071, 0.5050, 0.5156, 0.5057, 0.5119],
       device='cuda:0') torch.Size([16])
percent tensor([0.5515, 0.5459, 0.5517, 0.5595, 0.5617, 0.5459, 0.5682, 0.5585, 0.5531,
        0.5548, 0.5531, 0.5546, 0.5135, 0.6098, 0.5405, 0.5613],
       device='cuda:0') torch.Size([16])
percent tensor([0.6185, 0.6414, 0.6174, 0.6122, 0.6068, 0.6149, 0.6309, 0.6063, 0.6373,
        0.6457, 0.6512, 0.6315, 0.6384, 0.6505, 0.6168, 0.6309],
       device='cuda:0') torch.Size([16])
percent tensor([0.5906, 0.6895, 0.4619, 0.5976, 0.4715, 0.5855, 0.6329, 0.3429, 0.6722,
        0.6819, 0.7293, 0.5946, 0.6472, 0.7281, 0.5359, 0.6256],
       device='cuda:0') torch.Size([16])
percent tensor([0.6129, 0.5839, 0.6297, 0.6222, 0.6659, 0.6395, 0.6132, 0.6543, 0.6075,
        0.5877, 0.5719, 0.5691, 0.5702, 0.5897, 0.5991, 0.6263],
       device='cuda:0') torch.Size([16])
percent tensor([0.5703, 0.5850, 0.6830, 0.6349, 0.7582, 0.7841, 0.5726, 0.6337, 0.6477,
        0.5584, 0.6832, 0.5572, 0.6664, 0.5670, 0.5288, 0.5381],
       device='cuda:0') torch.Size([16])
percent tensor([0.9996, 0.9996, 0.9998, 0.9996, 0.9994, 0.9993, 0.9996, 0.9998, 0.9998,
        0.9996, 0.9999, 0.9998, 0.9997, 0.9991, 0.9996, 0.9992],
       device='cuda:0') torch.Size([16])
Epoch: 142 | Batch_idx: 0 |  Loss: (0.0956) |  Loss2: (0.0000) | Acc: (96.00%) (124/128)
Epoch: 142 | Batch_idx: 10 |  Loss: (0.1295) |  Loss2: (0.0000) | Acc: (95.00%) (1342/1408)
Epoch: 142 | Batch_idx: 20 |  Loss: (0.1348) |  Loss2: (0.0000) | Acc: (95.00%) (2565/2688)
Epoch: 142 | Batch_idx: 30 |  Loss: (0.1312) |  Loss2: (0.0000) | Acc: (95.00%) (3797/3968)
Epoch: 142 | Batch_idx: 40 |  Loss: (0.1305) |  Loss2: (0.0000) | Acc: (95.00%) (5021/5248)
Epoch: 142 | Batch_idx: 50 |  Loss: (0.1313) |  Loss2: (0.0000) | Acc: (95.00%) (6242/6528)
Epoch: 142 | Batch_idx: 60 |  Loss: (0.1308) |  Loss2: (0.0000) | Acc: (95.00%) (7470/7808)
Epoch: 142 | Batch_idx: 70 |  Loss: (0.1330) |  Loss2: (0.0000) | Acc: (95.00%) (8686/9088)
Epoch: 142 | Batch_idx: 80 |  Loss: (0.1338) |  Loss2: (0.0000) | Acc: (95.00%) (9903/10368)
Epoch: 142 | Batch_idx: 90 |  Loss: (0.1358) |  Loss2: (0.0000) | Acc: (95.00%) (11109/11648)
Epoch: 142 | Batch_idx: 100 |  Loss: (0.1360) |  Loss2: (0.0000) | Acc: (95.00%) (12325/12928)
Epoch: 142 | Batch_idx: 110 |  Loss: (0.1373) |  Loss2: (0.0000) | Acc: (95.00%) (13535/14208)
Epoch: 142 | Batch_idx: 120 |  Loss: (0.1379) |  Loss2: (0.0000) | Acc: (95.00%) (14757/15488)
Epoch: 142 | Batch_idx: 130 |  Loss: (0.1395) |  Loss2: (0.0000) | Acc: (95.00%) (15967/16768)
Epoch: 142 | Batch_idx: 140 |  Loss: (0.1406) |  Loss2: (0.0000) | Acc: (95.00%) (17173/18048)
Epoch: 142 | Batch_idx: 150 |  Loss: (0.1407) |  Loss2: (0.0000) | Acc: (95.00%) (18396/19328)
Epoch: 142 | Batch_idx: 160 |  Loss: (0.1413) |  Loss2: (0.0000) | Acc: (95.00%) (19610/20608)
Epoch: 142 | Batch_idx: 170 |  Loss: (0.1422) |  Loss2: (0.0000) | Acc: (95.00%) (20825/21888)
Epoch: 142 | Batch_idx: 180 |  Loss: (0.1417) |  Loss2: (0.0000) | Acc: (95.00%) (22051/23168)
Epoch: 142 | Batch_idx: 190 |  Loss: (0.1418) |  Loss2: (0.0000) | Acc: (95.00%) (23274/24448)
Epoch: 142 | Batch_idx: 200 |  Loss: (0.1414) |  Loss2: (0.0000) | Acc: (95.00%) (24499/25728)
Epoch: 142 | Batch_idx: 210 |  Loss: (0.1417) |  Loss2: (0.0000) | Acc: (95.00%) (25707/27008)
Epoch: 142 | Batch_idx: 220 |  Loss: (0.1420) |  Loss2: (0.0000) | Acc: (95.00%) (26925/28288)
Epoch: 142 | Batch_idx: 230 |  Loss: (0.1423) |  Loss2: (0.0000) | Acc: (95.00%) (28144/29568)
Epoch: 142 | Batch_idx: 240 |  Loss: (0.1426) |  Loss2: (0.0000) | Acc: (95.00%) (29362/30848)
Epoch: 142 | Batch_idx: 250 |  Loss: (0.1428) |  Loss2: (0.0000) | Acc: (95.00%) (30577/32128)
Epoch: 142 | Batch_idx: 260 |  Loss: (0.1424) |  Loss2: (0.0000) | Acc: (95.00%) (31798/33408)
Epoch: 142 | Batch_idx: 270 |  Loss: (0.1414) |  Loss2: (0.0000) | Acc: (95.00%) (33030/34688)
Epoch: 142 | Batch_idx: 280 |  Loss: (0.1417) |  Loss2: (0.0000) | Acc: (95.00%) (34246/35968)
Epoch: 142 | Batch_idx: 290 |  Loss: (0.1418) |  Loss2: (0.0000) | Acc: (95.00%) (35460/37248)
Epoch: 142 | Batch_idx: 300 |  Loss: (0.1421) |  Loss2: (0.0000) | Acc: (95.00%) (36675/38528)
Epoch: 142 | Batch_idx: 310 |  Loss: (0.1423) |  Loss2: (0.0000) | Acc: (95.00%) (37894/39808)
Epoch: 142 | Batch_idx: 320 |  Loss: (0.1428) |  Loss2: (0.0000) | Acc: (95.00%) (39106/41088)
Epoch: 142 | Batch_idx: 330 |  Loss: (0.1426) |  Loss2: (0.0000) | Acc: (95.00%) (40327/42368)
Epoch: 142 | Batch_idx: 340 |  Loss: (0.1423) |  Loss2: (0.0000) | Acc: (95.00%) (41553/43648)
Epoch: 142 | Batch_idx: 350 |  Loss: (0.1427) |  Loss2: (0.0000) | Acc: (95.00%) (42762/44928)
Epoch: 142 | Batch_idx: 360 |  Loss: (0.1430) |  Loss2: (0.0000) | Acc: (95.00%) (43977/46208)
Epoch: 142 | Batch_idx: 370 |  Loss: (0.1429) |  Loss2: (0.0000) | Acc: (95.00%) (45196/47488)
Epoch: 142 | Batch_idx: 380 |  Loss: (0.1425) |  Loss2: (0.0000) | Acc: (95.00%) (46431/48768)
Epoch: 142 | Batch_idx: 390 |  Loss: (0.1426) |  Loss2: (0.0000) | Acc: (95.00%) (47605/50000)
# TEST : Loss: (0.3859) | Acc: (88.00%) (8831/10000)
percent tensor([0.5182, 0.5061, 0.5213, 0.5141, 0.5231, 0.5291, 0.5135, 0.5141, 0.5186,
        0.5090, 0.5184, 0.5150, 0.5086, 0.5122, 0.5159, 0.5149],
       device='cuda:0') torch.Size([16])
percent tensor([0.5105, 0.5045, 0.5107, 0.5108, 0.5085, 0.5095, 0.5067, 0.5117, 0.5143,
        0.5075, 0.5130, 0.5066, 0.5048, 0.5161, 0.5057, 0.5118],
       device='cuda:0') torch.Size([16])
percent tensor([0.5460, 0.5401, 0.5464, 0.5543, 0.5568, 0.5414, 0.5634, 0.5537, 0.5483,
        0.5486, 0.5478, 0.5488, 0.5078, 0.6054, 0.5352, 0.5557],
       device='cuda:0') torch.Size([16])
percent tensor([0.6170, 0.6400, 0.6162, 0.6109, 0.6057, 0.6142, 0.6293, 0.6052, 0.6364,
        0.6442, 0.6499, 0.6302, 0.6371, 0.6498, 0.6152, 0.6296],
       device='cuda:0') torch.Size([16])
percent tensor([0.5948, 0.6846, 0.4654, 0.6016, 0.4776, 0.5944, 0.6330, 0.3463, 0.6710,
        0.6758, 0.7237, 0.5912, 0.6429, 0.7249, 0.5394, 0.6289],
       device='cuda:0') torch.Size([16])
percent tensor([0.6173, 0.5901, 0.6338, 0.6272, 0.6723, 0.6452, 0.6180, 0.6595, 0.6122,
        0.5939, 0.5769, 0.5739, 0.5761, 0.5940, 0.6028, 0.6311],
       device='cuda:0') torch.Size([16])
percent tensor([0.5646, 0.5794, 0.6751, 0.6206, 0.7515, 0.7848, 0.5583, 0.6216, 0.6411,
        0.5540, 0.6799, 0.5477, 0.6656, 0.5564, 0.5174, 0.5308],
       device='cuda:0') torch.Size([16])
percent tensor([0.9996, 0.9995, 0.9998, 0.9996, 0.9995, 0.9993, 0.9995, 0.9998, 0.9998,
        0.9996, 0.9999, 0.9998, 0.9997, 0.9990, 0.9996, 0.9992],
       device='cuda:0') torch.Size([16])
Epoch: 143 | Batch_idx: 0 |  Loss: (0.1498) |  Loss2: (0.0000) | Acc: (93.00%) (120/128)
Epoch: 143 | Batch_idx: 10 |  Loss: (0.1458) |  Loss2: (0.0000) | Acc: (94.00%) (1333/1408)
Epoch: 143 | Batch_idx: 20 |  Loss: (0.1376) |  Loss2: (0.0000) | Acc: (95.00%) (2558/2688)
Epoch: 143 | Batch_idx: 30 |  Loss: (0.1311) |  Loss2: (0.0000) | Acc: (95.00%) (3783/3968)
Epoch: 143 | Batch_idx: 40 |  Loss: (0.1350) |  Loss2: (0.0000) | Acc: (95.00%) (5000/5248)
Epoch: 143 | Batch_idx: 50 |  Loss: (0.1378) |  Loss2: (0.0000) | Acc: (95.00%) (6219/6528)
Epoch: 143 | Batch_idx: 60 |  Loss: (0.1408) |  Loss2: (0.0000) | Acc: (95.00%) (7437/7808)
Epoch: 143 | Batch_idx: 70 |  Loss: (0.1395) |  Loss2: (0.0000) | Acc: (95.00%) (8663/9088)
Epoch: 143 | Batch_idx: 80 |  Loss: (0.1405) |  Loss2: (0.0000) | Acc: (95.00%) (9878/10368)
Epoch: 143 | Batch_idx: 90 |  Loss: (0.1388) |  Loss2: (0.0000) | Acc: (95.00%) (11100/11648)
Epoch: 143 | Batch_idx: 100 |  Loss: (0.1386) |  Loss2: (0.0000) | Acc: (95.00%) (12324/12928)
Epoch: 143 | Batch_idx: 110 |  Loss: (0.1382) |  Loss2: (0.0000) | Acc: (95.00%) (13547/14208)
Epoch: 143 | Batch_idx: 120 |  Loss: (0.1373) |  Loss2: (0.0000) | Acc: (95.00%) (14773/15488)
Epoch: 143 | Batch_idx: 130 |  Loss: (0.1375) |  Loss2: (0.0000) | Acc: (95.00%) (15994/16768)
Epoch: 143 | Batch_idx: 140 |  Loss: (0.1372) |  Loss2: (0.0000) | Acc: (95.00%) (17213/18048)
Epoch: 143 | Batch_idx: 150 |  Loss: (0.1391) |  Loss2: (0.0000) | Acc: (95.00%) (18422/19328)
Epoch: 143 | Batch_idx: 160 |  Loss: (0.1401) |  Loss2: (0.0000) | Acc: (95.00%) (19631/20608)
Epoch: 143 | Batch_idx: 170 |  Loss: (0.1413) |  Loss2: (0.0000) | Acc: (95.00%) (20836/21888)
Epoch: 143 | Batch_idx: 180 |  Loss: (0.1419) |  Loss2: (0.0000) | Acc: (95.00%) (22050/23168)
Epoch: 143 | Batch_idx: 190 |  Loss: (0.1412) |  Loss2: (0.0000) | Acc: (95.00%) (23269/24448)
Epoch: 143 | Batch_idx: 200 |  Loss: (0.1405) |  Loss2: (0.0000) | Acc: (95.00%) (24494/25728)
Epoch: 143 | Batch_idx: 210 |  Loss: (0.1401) |  Loss2: (0.0000) | Acc: (95.00%) (25716/27008)
Epoch: 143 | Batch_idx: 220 |  Loss: (0.1403) |  Loss2: (0.0000) | Acc: (95.00%) (26931/28288)
Epoch: 143 | Batch_idx: 230 |  Loss: (0.1404) |  Loss2: (0.0000) | Acc: (95.00%) (28152/29568)
Epoch: 143 | Batch_idx: 240 |  Loss: (0.1399) |  Loss2: (0.0000) | Acc: (95.00%) (29376/30848)
Epoch: 143 | Batch_idx: 250 |  Loss: (0.1410) |  Loss2: (0.0000) | Acc: (95.00%) (30585/32128)
Epoch: 143 | Batch_idx: 260 |  Loss: (0.1403) |  Loss2: (0.0000) | Acc: (95.00%) (31812/33408)
Epoch: 143 | Batch_idx: 270 |  Loss: (0.1400) |  Loss2: (0.0000) | Acc: (95.00%) (33042/34688)
Epoch: 143 | Batch_idx: 280 |  Loss: (0.1401) |  Loss2: (0.0000) | Acc: (95.00%) (34254/35968)
Epoch: 143 | Batch_idx: 290 |  Loss: (0.1403) |  Loss2: (0.0000) | Acc: (95.00%) (35474/37248)
Epoch: 143 | Batch_idx: 300 |  Loss: (0.1396) |  Loss2: (0.0000) | Acc: (95.00%) (36704/38528)
Epoch: 143 | Batch_idx: 310 |  Loss: (0.1404) |  Loss2: (0.0000) | Acc: (95.00%) (37915/39808)
Epoch: 143 | Batch_idx: 320 |  Loss: (0.1406) |  Loss2: (0.0000) | Acc: (95.00%) (39134/41088)
Epoch: 143 | Batch_idx: 330 |  Loss: (0.1407) |  Loss2: (0.0000) | Acc: (95.00%) (40347/42368)
Epoch: 143 | Batch_idx: 340 |  Loss: (0.1407) |  Loss2: (0.0000) | Acc: (95.00%) (41565/43648)
Epoch: 143 | Batch_idx: 350 |  Loss: (0.1401) |  Loss2: (0.0000) | Acc: (95.00%) (42800/44928)
Epoch: 143 | Batch_idx: 360 |  Loss: (0.1405) |  Loss2: (0.0000) | Acc: (95.00%) (44010/46208)
Epoch: 143 | Batch_idx: 370 |  Loss: (0.1403) |  Loss2: (0.0000) | Acc: (95.00%) (45230/47488)
Epoch: 143 | Batch_idx: 380 |  Loss: (0.1408) |  Loss2: (0.0000) | Acc: (95.00%) (46445/48768)
Epoch: 143 | Batch_idx: 390 |  Loss: (0.1406) |  Loss2: (0.0000) | Acc: (95.00%) (47616/50000)
# TEST : Loss: (0.3850) | Acc: (88.00%) (8831/10000)
percent tensor([0.5185, 0.5064, 0.5215, 0.5146, 0.5232, 0.5299, 0.5137, 0.5143, 0.5188,
        0.5091, 0.5188, 0.5151, 0.5088, 0.5124, 0.5164, 0.5153],
       device='cuda:0') torch.Size([16])
percent tensor([0.5109, 0.5049, 0.5110, 0.5111, 0.5088, 0.5100, 0.5071, 0.5121, 0.5146,
        0.5079, 0.5134, 0.5068, 0.5051, 0.5166, 0.5062, 0.5123],
       device='cuda:0') torch.Size([16])
percent tensor([0.5481, 0.5439, 0.5481, 0.5554, 0.5583, 0.5422, 0.5663, 0.5564, 0.5509,
        0.5521, 0.5510, 0.5514, 0.5113, 0.6076, 0.5379, 0.5584],
       device='cuda:0') torch.Size([16])
percent tensor([0.6160, 0.6392, 0.6154, 0.6104, 0.6045, 0.6134, 0.6282, 0.6041, 0.6361,
        0.6430, 0.6490, 0.6293, 0.6364, 0.6496, 0.6138, 0.6287],
       device='cuda:0') torch.Size([16])
percent tensor([0.5886, 0.6825, 0.4621, 0.5957, 0.4746, 0.5905, 0.6280, 0.3433, 0.6674,
        0.6743, 0.7210, 0.5868, 0.6406, 0.7242, 0.5359, 0.6242],
       device='cuda:0') torch.Size([16])
percent tensor([0.6205, 0.5930, 0.6385, 0.6306, 0.6765, 0.6488, 0.6210, 0.6637, 0.6143,
        0.5956, 0.5789, 0.5764, 0.5778, 0.5964, 0.6062, 0.6339],
       device='cuda:0') torch.Size([16])
percent tensor([0.5648, 0.5794, 0.6794, 0.6263, 0.7557, 0.7854, 0.5604, 0.6252, 0.6405,
        0.5527, 0.6806, 0.5501, 0.6610, 0.5581, 0.5234, 0.5269],
       device='cuda:0') torch.Size([16])
percent tensor([0.9996, 0.9996, 0.9998, 0.9996, 0.9995, 0.9994, 0.9995, 0.9998, 0.9998,
        0.9996, 0.9999, 0.9998, 0.9997, 0.9991, 0.9996, 0.9993],
       device='cuda:0') torch.Size([16])
True Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=128, out_features=16, bias=False)
False Linear(in_features=16, out_features=2, bias=False)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=128, out_features=16, bias=False)
False Linear(in_features=16, out_features=2, bias=False)
True Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=256, out_features=32, bias=False)
False Linear(in_features=32, out_features=2, bias=False)
True Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=256, out_features=32, bias=False)
False Linear(in_features=32, out_features=2, bias=False)
True Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=512, out_features=64, bias=False)
False Linear(in_features=64, out_features=2, bias=False)
True Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=512, out_features=64, bias=False)
False Linear(in_features=64, out_features=2, bias=False)
True Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1024, out_features=128, bias=False)
False Linear(in_features=128, out_features=2, bias=False)
True Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1024, out_features=128, bias=False)
False Linear(in_features=128, out_features=2, bias=False)
True Linear(in_features=512, out_features=10, bias=True)
Epoch: 144 | Batch_idx: 0 |  Loss: (0.1127) |  Loss2: (0.0000) | Acc: (96.00%) (123/128)
Epoch: 144 | Batch_idx: 10 |  Loss: (0.1289) |  Loss2: (0.0000) | Acc: (95.00%) (1344/1408)
Epoch: 144 | Batch_idx: 20 |  Loss: (0.1324) |  Loss2: (0.0000) | Acc: (95.00%) (2565/2688)
Epoch: 144 | Batch_idx: 30 |  Loss: (0.1455) |  Loss2: (0.0000) | Acc: (94.00%) (3756/3968)
Epoch: 144 | Batch_idx: 40 |  Loss: (0.1455) |  Loss2: (0.0000) | Acc: (94.00%) (4967/5248)
Epoch: 144 | Batch_idx: 50 |  Loss: (0.1482) |  Loss2: (0.0000) | Acc: (94.00%) (6170/6528)
Epoch: 144 | Batch_idx: 60 |  Loss: (0.1503) |  Loss2: (0.0000) | Acc: (94.00%) (7371/7808)
Epoch: 144 | Batch_idx: 70 |  Loss: (0.1489) |  Loss2: (0.0000) | Acc: (94.00%) (8581/9088)
Epoch: 144 | Batch_idx: 80 |  Loss: (0.1483) |  Loss2: (0.0000) | Acc: (94.00%) (9799/10368)
Epoch: 144 | Batch_idx: 90 |  Loss: (0.1468) |  Loss2: (0.0000) | Acc: (94.00%) (11020/11648)
Epoch: 144 | Batch_idx: 100 |  Loss: (0.1497) |  Loss2: (0.0000) | Acc: (94.00%) (12212/12928)
Epoch: 144 | Batch_idx: 110 |  Loss: (0.1500) |  Loss2: (0.0000) | Acc: (94.00%) (13425/14208)
Epoch: 144 | Batch_idx: 120 |  Loss: (0.1493) |  Loss2: (0.0000) | Acc: (94.00%) (14644/15488)
Epoch: 144 | Batch_idx: 130 |  Loss: (0.1498) |  Loss2: (0.0000) | Acc: (94.00%) (15853/16768)
Epoch: 144 | Batch_idx: 140 |  Loss: (0.1502) |  Loss2: (0.0000) | Acc: (94.00%) (17062/18048)
Epoch: 144 | Batch_idx: 150 |  Loss: (0.1491) |  Loss2: (0.0000) | Acc: (94.00%) (18278/19328)
Epoch: 144 | Batch_idx: 160 |  Loss: (0.1488) |  Loss2: (0.0000) | Acc: (94.00%) (19495/20608)
Epoch: 144 | Batch_idx: 170 |  Loss: (0.1497) |  Loss2: (0.0000) | Acc: (94.00%) (20708/21888)
Epoch: 144 | Batch_idx: 180 |  Loss: (0.1503) |  Loss2: (0.0000) | Acc: (94.00%) (21915/23168)
Epoch: 144 | Batch_idx: 190 |  Loss: (0.1513) |  Loss2: (0.0000) | Acc: (94.00%) (23108/24448)
Epoch: 144 | Batch_idx: 200 |  Loss: (0.1510) |  Loss2: (0.0000) | Acc: (94.00%) (24322/25728)
Epoch: 144 | Batch_idx: 210 |  Loss: (0.1513) |  Loss2: (0.0000) | Acc: (94.00%) (25533/27008)
Epoch: 144 | Batch_idx: 220 |  Loss: (0.1516) |  Loss2: (0.0000) | Acc: (94.00%) (26746/28288)
Epoch: 144 | Batch_idx: 230 |  Loss: (0.1511) |  Loss2: (0.0000) | Acc: (94.00%) (27966/29568)
Epoch: 144 | Batch_idx: 240 |  Loss: (0.1527) |  Loss2: (0.0000) | Acc: (94.00%) (29157/30848)
Epoch: 144 | Batch_idx: 250 |  Loss: (0.1530) |  Loss2: (0.0000) | Acc: (94.00%) (30372/32128)
Epoch: 144 | Batch_idx: 260 |  Loss: (0.1533) |  Loss2: (0.0000) | Acc: (94.00%) (31578/33408)
Epoch: 144 | Batch_idx: 270 |  Loss: (0.1534) |  Loss2: (0.0000) | Acc: (94.00%) (32782/34688)
Epoch: 144 | Batch_idx: 280 |  Loss: (0.1538) |  Loss2: (0.0000) | Acc: (94.00%) (33987/35968)
Epoch: 144 | Batch_idx: 290 |  Loss: (0.1546) |  Loss2: (0.0000) | Acc: (94.00%) (35181/37248)
Epoch: 144 | Batch_idx: 300 |  Loss: (0.1551) |  Loss2: (0.0000) | Acc: (94.00%) (36387/38528)
Epoch: 144 | Batch_idx: 310 |  Loss: (0.1557) |  Loss2: (0.0000) | Acc: (94.00%) (37594/39808)
Epoch: 144 | Batch_idx: 320 |  Loss: (0.1555) |  Loss2: (0.0000) | Acc: (94.00%) (38813/41088)
Epoch: 144 | Batch_idx: 330 |  Loss: (0.1558) |  Loss2: (0.0000) | Acc: (94.00%) (40021/42368)
Epoch: 144 | Batch_idx: 340 |  Loss: (0.1556) |  Loss2: (0.0000) | Acc: (94.00%) (41232/43648)
Epoch: 144 | Batch_idx: 350 |  Loss: (0.1551) |  Loss2: (0.0000) | Acc: (94.00%) (42452/44928)
Epoch: 144 | Batch_idx: 360 |  Loss: (0.1552) |  Loss2: (0.0000) | Acc: (94.00%) (43661/46208)
Epoch: 144 | Batch_idx: 370 |  Loss: (0.1548) |  Loss2: (0.0000) | Acc: (94.00%) (44883/47488)
Epoch: 144 | Batch_idx: 380 |  Loss: (0.1553) |  Loss2: (0.0000) | Acc: (94.00%) (46081/48768)
Epoch: 144 | Batch_idx: 390 |  Loss: (0.1557) |  Loss2: (0.0000) | Acc: (94.00%) (47238/50000)
# TEST : Loss: (0.3991) | Acc: (87.00%) (8788/10000)
percent tensor([0.5192, 0.5043, 0.5243, 0.5160, 0.5256, 0.5309, 0.5128, 0.5151, 0.5182,
        0.5088, 0.5182, 0.5175, 0.5088, 0.5083, 0.5161, 0.5152],
       device='cuda:0') torch.Size([16])
percent tensor([0.5102, 0.5055, 0.5120, 0.5109, 0.5094, 0.5094, 0.5079, 0.5132, 0.5157,
        0.5083, 0.5136, 0.5066, 0.5046, 0.5185, 0.5062, 0.5117],
       device='cuda:0') torch.Size([16])
percent tensor([0.5495, 0.5466, 0.5597, 0.5565, 0.5642, 0.5363, 0.5668, 0.5640, 0.5535,
        0.5551, 0.5510, 0.5546, 0.5119, 0.5994, 0.5383, 0.5584],
       device='cuda:0') torch.Size([16])
percent tensor([0.6200, 0.6432, 0.6207, 0.6134, 0.6075, 0.6159, 0.6279, 0.6089, 0.6387,
        0.6446, 0.6541, 0.6305, 0.6412, 0.6486, 0.6157, 0.6311],
       device='cuda:0') torch.Size([16])
percent tensor([0.5998, 0.6814, 0.4761, 0.5868, 0.4972, 0.6152, 0.6192, 0.3705, 0.6673,
        0.6644, 0.7220, 0.6083, 0.6510, 0.6954, 0.5413, 0.6134],
       device='cuda:0') torch.Size([16])
percent tensor([0.6204, 0.5969, 0.6505, 0.6291, 0.6817, 0.6403, 0.6245, 0.6608, 0.6160,
        0.6046, 0.5807, 0.5787, 0.5716, 0.5987, 0.6064, 0.6289],
       device='cuda:0') torch.Size([16])
percent tensor([0.5410, 0.5701, 0.6729, 0.6069, 0.7256, 0.7706, 0.5551, 0.6145, 0.6484,
        0.5535, 0.6734, 0.5612, 0.6432, 0.5814, 0.5294, 0.4964],
       device='cuda:0') torch.Size([16])
percent tensor([0.9996, 0.9997, 0.9997, 0.9996, 0.9995, 0.9994, 0.9996, 0.9998, 0.9998,
        0.9994, 0.9999, 0.9997, 0.9997, 0.9989, 0.9994, 0.9991],
       device='cuda:0') torch.Size([16])
Epoch: 145 | Batch_idx: 0 |  Loss: (0.1404) |  Loss2: (0.0000) | Acc: (95.00%) (122/128)
Epoch: 145 | Batch_idx: 10 |  Loss: (0.1724) |  Loss2: (0.0000) | Acc: (94.00%) (1330/1408)
Epoch: 145 | Batch_idx: 20 |  Loss: (0.1565) |  Loss2: (0.0000) | Acc: (94.00%) (2549/2688)
Epoch: 145 | Batch_idx: 30 |  Loss: (0.1493) |  Loss2: (0.0000) | Acc: (95.00%) (3775/3968)
Epoch: 145 | Batch_idx: 40 |  Loss: (0.1449) |  Loss2: (0.0000) | Acc: (95.00%) (4997/5248)
Epoch: 145 | Batch_idx: 50 |  Loss: (0.1387) |  Loss2: (0.0000) | Acc: (95.00%) (6226/6528)
Epoch: 145 | Batch_idx: 60 |  Loss: (0.1400) |  Loss2: (0.0000) | Acc: (95.00%) (7446/7808)
Epoch: 145 | Batch_idx: 70 |  Loss: (0.1417) |  Loss2: (0.0000) | Acc: (95.00%) (8652/9088)
Epoch: 145 | Batch_idx: 80 |  Loss: (0.1441) |  Loss2: (0.0000) | Acc: (95.00%) (9864/10368)
Epoch: 145 | Batch_idx: 90 |  Loss: (0.1422) |  Loss2: (0.0000) | Acc: (95.00%) (11087/11648)
Epoch: 145 | Batch_idx: 100 |  Loss: (0.1401) |  Loss2: (0.0000) | Acc: (95.00%) (12314/12928)
Epoch: 145 | Batch_idx: 110 |  Loss: (0.1403) |  Loss2: (0.0000) | Acc: (95.00%) (13535/14208)
Epoch: 145 | Batch_idx: 120 |  Loss: (0.1417) |  Loss2: (0.0000) | Acc: (95.00%) (14741/15488)
Epoch: 145 | Batch_idx: 130 |  Loss: (0.1420) |  Loss2: (0.0000) | Acc: (95.00%) (15952/16768)
Epoch: 145 | Batch_idx: 140 |  Loss: (0.1434) |  Loss2: (0.0000) | Acc: (95.00%) (17157/18048)
Epoch: 145 | Batch_idx: 150 |  Loss: (0.1440) |  Loss2: (0.0000) | Acc: (95.00%) (18369/19328)
Epoch: 145 | Batch_idx: 160 |  Loss: (0.1453) |  Loss2: (0.0000) | Acc: (95.00%) (19578/20608)
Epoch: 145 | Batch_idx: 170 |  Loss: (0.1453) |  Loss2: (0.0000) | Acc: (95.00%) (20800/21888)
Epoch: 145 | Batch_idx: 180 |  Loss: (0.1456) |  Loss2: (0.0000) | Acc: (94.00%) (22000/23168)
Epoch: 145 | Batch_idx: 190 |  Loss: (0.1471) |  Loss2: (0.0000) | Acc: (94.00%) (23214/24448)
Epoch: 145 | Batch_idx: 200 |  Loss: (0.1470) |  Loss2: (0.0000) | Acc: (94.00%) (24434/25728)
Epoch: 145 | Batch_idx: 210 |  Loss: (0.1477) |  Loss2: (0.0000) | Acc: (94.00%) (25647/27008)
Epoch: 145 | Batch_idx: 220 |  Loss: (0.1469) |  Loss2: (0.0000) | Acc: (94.00%) (26871/28288)
Epoch: 145 | Batch_idx: 230 |  Loss: (0.1465) |  Loss2: (0.0000) | Acc: (95.00%) (28096/29568)
Epoch: 145 | Batch_idx: 240 |  Loss: (0.1467) |  Loss2: (0.0000) | Acc: (95.00%) (29312/30848)
Epoch: 145 | Batch_idx: 250 |  Loss: (0.1471) |  Loss2: (0.0000) | Acc: (95.00%) (30524/32128)
Epoch: 145 | Batch_idx: 260 |  Loss: (0.1466) |  Loss2: (0.0000) | Acc: (95.00%) (31744/33408)
Epoch: 145 | Batch_idx: 270 |  Loss: (0.1482) |  Loss2: (0.0000) | Acc: (94.00%) (32945/34688)
Epoch: 145 | Batch_idx: 280 |  Loss: (0.1486) |  Loss2: (0.0000) | Acc: (94.00%) (34152/35968)
Epoch: 145 | Batch_idx: 290 |  Loss: (0.1478) |  Loss2: (0.0000) | Acc: (94.00%) (35372/37248)
Epoch: 145 | Batch_idx: 300 |  Loss: (0.1475) |  Loss2: (0.0000) | Acc: (94.00%) (36589/38528)
Epoch: 145 | Batch_idx: 310 |  Loss: (0.1473) |  Loss2: (0.0000) | Acc: (94.00%) (37806/39808)
Epoch: 145 | Batch_idx: 320 |  Loss: (0.1478) |  Loss2: (0.0000) | Acc: (94.00%) (39015/41088)
Epoch: 145 | Batch_idx: 330 |  Loss: (0.1478) |  Loss2: (0.0000) | Acc: (94.00%) (40222/42368)
Epoch: 145 | Batch_idx: 340 |  Loss: (0.1478) |  Loss2: (0.0000) | Acc: (94.00%) (41432/43648)
Epoch: 145 | Batch_idx: 350 |  Loss: (0.1485) |  Loss2: (0.0000) | Acc: (94.00%) (42632/44928)
Epoch: 145 | Batch_idx: 360 |  Loss: (0.1492) |  Loss2: (0.0000) | Acc: (94.00%) (43826/46208)
Epoch: 145 | Batch_idx: 370 |  Loss: (0.1488) |  Loss2: (0.0000) | Acc: (94.00%) (45042/47488)
Epoch: 145 | Batch_idx: 380 |  Loss: (0.1494) |  Loss2: (0.0000) | Acc: (94.00%) (46246/48768)
Epoch: 145 | Batch_idx: 390 |  Loss: (0.1504) |  Loss2: (0.0000) | Acc: (94.00%) (47390/50000)
=> saving checkpoint 'drive/app/torch/save_Schedule/checkpoint_145.pth.tar'
# TEST : Loss: (0.4519) | Acc: (86.00%) (8651/10000)
percent tensor([0.5185, 0.5076, 0.5195, 0.5154, 0.5221, 0.5302, 0.5139, 0.5154, 0.5200,
        0.5093, 0.5201, 0.5129, 0.5095, 0.5151, 0.5175, 0.5169],
       device='cuda:0') torch.Size([16])
percent tensor([0.5113, 0.5062, 0.5115, 0.5102, 0.5097, 0.5106, 0.5080, 0.5121, 0.5161,
        0.5083, 0.5145, 0.5062, 0.5058, 0.5181, 0.5065, 0.5123],
       device='cuda:0') torch.Size([16])
percent tensor([0.5516, 0.5480, 0.5432, 0.5569, 0.5555, 0.5367, 0.5634, 0.5602, 0.5575,
        0.5534, 0.5564, 0.5423, 0.5130, 0.6074, 0.5394, 0.5640],
       device='cuda:0') torch.Size([16])
percent tensor([0.6157, 0.6361, 0.6162, 0.6096, 0.6037, 0.6153, 0.6258, 0.6029, 0.6339,
        0.6367, 0.6444, 0.6255, 0.6336, 0.6480, 0.6120, 0.6229],
       device='cuda:0') torch.Size([16])
percent tensor([0.5959, 0.6693, 0.4910, 0.5867, 0.4899, 0.6115, 0.6160, 0.3599, 0.6616,
        0.6470, 0.7028, 0.5881, 0.6356, 0.6902, 0.5395, 0.6225],
       device='cuda:0') torch.Size([16])
percent tensor([0.6175, 0.6071, 0.6477, 0.6299, 0.6862, 0.6378, 0.6399, 0.6677, 0.6237,
        0.6094, 0.5857, 0.5823, 0.5780, 0.5928, 0.6086, 0.6283],
       device='cuda:0') torch.Size([16])
percent tensor([0.5550, 0.6060, 0.7040, 0.6366, 0.7662, 0.7764, 0.6332, 0.6319, 0.6733,
        0.5703, 0.7026, 0.5667, 0.6529, 0.6125, 0.5454, 0.5334],
       device='cuda:0') torch.Size([16])
percent tensor([0.9996, 0.9993, 0.9999, 0.9997, 0.9996, 0.9994, 0.9995, 0.9999, 0.9996,
        0.9997, 0.9999, 0.9999, 0.9997, 0.9992, 0.9996, 0.9994],
       device='cuda:0') torch.Size([16])
Epoch: 146 | Batch_idx: 0 |  Loss: (0.1054) |  Loss2: (0.0000) | Acc: (99.00%) (127/128)
Epoch: 146 | Batch_idx: 10 |  Loss: (0.1254) |  Loss2: (0.0000) | Acc: (95.00%) (1347/1408)
Epoch: 146 | Batch_idx: 20 |  Loss: (0.1336) |  Loss2: (0.0000) | Acc: (95.00%) (2562/2688)
Epoch: 146 | Batch_idx: 30 |  Loss: (0.1298) |  Loss2: (0.0000) | Acc: (95.00%) (3788/3968)
Epoch: 146 | Batch_idx: 40 |  Loss: (0.1325) |  Loss2: (0.0000) | Acc: (95.00%) (5004/5248)
Epoch: 146 | Batch_idx: 50 |  Loss: (0.1401) |  Loss2: (0.0000) | Acc: (95.00%) (6207/6528)
Epoch: 146 | Batch_idx: 60 |  Loss: (0.1384) |  Loss2: (0.0000) | Acc: (95.00%) (7436/7808)
Epoch: 146 | Batch_idx: 70 |  Loss: (0.1422) |  Loss2: (0.0000) | Acc: (95.00%) (8639/9088)
Epoch: 146 | Batch_idx: 80 |  Loss: (0.1429) |  Loss2: (0.0000) | Acc: (95.00%) (9862/10368)
Epoch: 146 | Batch_idx: 90 |  Loss: (0.1447) |  Loss2: (0.0000) | Acc: (95.00%) (11067/11648)
Epoch: 146 | Batch_idx: 100 |  Loss: (0.1447) |  Loss2: (0.0000) | Acc: (94.00%) (12281/12928)
Epoch: 146 | Batch_idx: 110 |  Loss: (0.1433) |  Loss2: (0.0000) | Acc: (95.00%) (13499/14208)
Epoch: 146 | Batch_idx: 120 |  Loss: (0.1425) |  Loss2: (0.0000) | Acc: (95.00%) (14717/15488)
Epoch: 146 | Batch_idx: 130 |  Loss: (0.1414) |  Loss2: (0.0000) | Acc: (95.00%) (15939/16768)
Epoch: 146 | Batch_idx: 140 |  Loss: (0.1402) |  Loss2: (0.0000) | Acc: (95.00%) (17164/18048)
Epoch: 146 | Batch_idx: 150 |  Loss: (0.1408) |  Loss2: (0.0000) | Acc: (95.00%) (18379/19328)
Epoch: 146 | Batch_idx: 160 |  Loss: (0.1412) |  Loss2: (0.0000) | Acc: (95.00%) (19588/20608)
Epoch: 146 | Batch_idx: 170 |  Loss: (0.1414) |  Loss2: (0.0000) | Acc: (95.00%) (20808/21888)
Epoch: 146 | Batch_idx: 180 |  Loss: (0.1409) |  Loss2: (0.0000) | Acc: (95.00%) (22023/23168)
Epoch: 146 | Batch_idx: 190 |  Loss: (0.1414) |  Loss2: (0.0000) | Acc: (95.00%) (23231/24448)
Epoch: 146 | Batch_idx: 200 |  Loss: (0.1416) |  Loss2: (0.0000) | Acc: (95.00%) (24447/25728)
Epoch: 146 | Batch_idx: 210 |  Loss: (0.1431) |  Loss2: (0.0000) | Acc: (94.00%) (25642/27008)
Epoch: 146 | Batch_idx: 220 |  Loss: (0.1439) |  Loss2: (0.0000) | Acc: (94.00%) (26853/28288)
Epoch: 146 | Batch_idx: 230 |  Loss: (0.1450) |  Loss2: (0.0000) | Acc: (94.00%) (28056/29568)
Epoch: 146 | Batch_idx: 240 |  Loss: (0.1455) |  Loss2: (0.0000) | Acc: (94.00%) (29269/30848)
Epoch: 146 | Batch_idx: 250 |  Loss: (0.1461) |  Loss2: (0.0000) | Acc: (94.00%) (30482/32128)
Epoch: 146 | Batch_idx: 260 |  Loss: (0.1460) |  Loss2: (0.0000) | Acc: (94.00%) (31695/33408)
Epoch: 146 | Batch_idx: 270 |  Loss: (0.1457) |  Loss2: (0.0000) | Acc: (94.00%) (32924/34688)
Epoch: 146 | Batch_idx: 280 |  Loss: (0.1460) |  Loss2: (0.0000) | Acc: (94.00%) (34138/35968)
Epoch: 146 | Batch_idx: 290 |  Loss: (0.1457) |  Loss2: (0.0000) | Acc: (94.00%) (35362/37248)
Epoch: 146 | Batch_idx: 300 |  Loss: (0.1454) |  Loss2: (0.0000) | Acc: (94.00%) (36577/38528)
Epoch: 146 | Batch_idx: 310 |  Loss: (0.1459) |  Loss2: (0.0000) | Acc: (94.00%) (37781/39808)
Epoch: 146 | Batch_idx: 320 |  Loss: (0.1461) |  Loss2: (0.0000) | Acc: (94.00%) (38996/41088)
Epoch: 146 | Batch_idx: 330 |  Loss: (0.1466) |  Loss2: (0.0000) | Acc: (94.00%) (40197/42368)
Epoch: 146 | Batch_idx: 340 |  Loss: (0.1471) |  Loss2: (0.0000) | Acc: (94.00%) (41394/43648)
Epoch: 146 | Batch_idx: 350 |  Loss: (0.1466) |  Loss2: (0.0000) | Acc: (94.00%) (42620/44928)
Epoch: 146 | Batch_idx: 360 |  Loss: (0.1469) |  Loss2: (0.0000) | Acc: (94.00%) (43834/46208)
Epoch: 146 | Batch_idx: 370 |  Loss: (0.1473) |  Loss2: (0.0000) | Acc: (94.00%) (45044/47488)
Epoch: 146 | Batch_idx: 380 |  Loss: (0.1479) |  Loss2: (0.0000) | Acc: (94.00%) (46246/48768)
Epoch: 146 | Batch_idx: 390 |  Loss: (0.1471) |  Loss2: (0.0000) | Acc: (94.00%) (47423/50000)
# TEST : Loss: (0.4211) | Acc: (87.00%) (8725/10000)
percent tensor([0.5189, 0.5056, 0.5227, 0.5168, 0.5252, 0.5296, 0.5127, 0.5155, 0.5187,
        0.5092, 0.5183, 0.5162, 0.5091, 0.5095, 0.5165, 0.5156],
       device='cuda:0') torch.Size([16])
percent tensor([0.5097, 0.5069, 0.5106, 0.5109, 0.5088, 0.5096, 0.5089, 0.5125, 0.5150,
        0.5091, 0.5138, 0.5074, 0.5048, 0.5217, 0.5069, 0.5117],
       device='cuda:0') torch.Size([16])
percent tensor([0.5510, 0.5480, 0.5469, 0.5667, 0.5535, 0.5429, 0.5656, 0.5589, 0.5499,
        0.5572, 0.5513, 0.5496, 0.5151, 0.6072, 0.5436, 0.5658],
       device='cuda:0') torch.Size([16])
percent tensor([0.6190, 0.6391, 0.6195, 0.6123, 0.6092, 0.6164, 0.6296, 0.6066, 0.6408,
        0.6418, 0.6507, 0.6293, 0.6390, 0.6487, 0.6139, 0.6275],
       device='cuda:0') torch.Size([16])
percent tensor([0.5865, 0.6794, 0.4644, 0.5645, 0.4899, 0.6079, 0.6183, 0.3613, 0.6834,
        0.6567, 0.7162, 0.5742, 0.6434, 0.7145, 0.5482, 0.6215],
       device='cuda:0') torch.Size([16])
percent tensor([0.6106, 0.6017, 0.6443, 0.6314, 0.6796, 0.6333, 0.6337, 0.6575, 0.6105,
        0.6104, 0.5736, 0.5796, 0.5704, 0.5900, 0.6049, 0.6267],
       device='cuda:0') torch.Size([16])
percent tensor([0.5364, 0.5963, 0.6977, 0.6521, 0.7668, 0.7382, 0.5686, 0.6283, 0.6263,
        0.5765, 0.6705, 0.5609, 0.6669, 0.5934, 0.5312, 0.4913],
       device='cuda:0') torch.Size([16])
percent tensor([0.9996, 0.9996, 0.9997, 0.9995, 0.9995, 0.9990, 0.9996, 0.9995, 0.9998,
        0.9997, 0.9999, 0.9998, 0.9998, 0.9992, 0.9995, 0.9992],
       device='cuda:0') torch.Size([16])
Epoch: 147 | Batch_idx: 0 |  Loss: (0.1656) |  Loss2: (0.0000) | Acc: (95.00%) (122/128)
Epoch: 147 | Batch_idx: 10 |  Loss: (0.1577) |  Loss2: (0.0000) | Acc: (95.00%) (1340/1408)
Epoch: 147 | Batch_idx: 20 |  Loss: (0.1488) |  Loss2: (0.0000) | Acc: (95.00%) (2557/2688)
Epoch: 147 | Batch_idx: 30 |  Loss: (0.1445) |  Loss2: (0.0000) | Acc: (95.00%) (3782/3968)
Epoch: 147 | Batch_idx: 40 |  Loss: (0.1383) |  Loss2: (0.0000) | Acc: (95.00%) (5007/5248)
Epoch: 147 | Batch_idx: 50 |  Loss: (0.1412) |  Loss2: (0.0000) | Acc: (95.00%) (6216/6528)
Epoch: 147 | Batch_idx: 60 |  Loss: (0.1381) |  Loss2: (0.0000) | Acc: (95.00%) (7441/7808)
Epoch: 147 | Batch_idx: 70 |  Loss: (0.1363) |  Loss2: (0.0000) | Acc: (95.00%) (8665/9088)
Epoch: 147 | Batch_idx: 80 |  Loss: (0.1374) |  Loss2: (0.0000) | Acc: (95.00%) (9879/10368)
Epoch: 147 | Batch_idx: 90 |  Loss: (0.1396) |  Loss2: (0.0000) | Acc: (95.00%) (11094/11648)
Epoch: 147 | Batch_idx: 100 |  Loss: (0.1381) |  Loss2: (0.0000) | Acc: (95.00%) (12327/12928)
Epoch: 147 | Batch_idx: 110 |  Loss: (0.1382) |  Loss2: (0.0000) | Acc: (95.00%) (13537/14208)
Epoch: 147 | Batch_idx: 120 |  Loss: (0.1392) |  Loss2: (0.0000) | Acc: (95.00%) (14755/15488)
Epoch: 147 | Batch_idx: 130 |  Loss: (0.1391) |  Loss2: (0.0000) | Acc: (95.00%) (15972/16768)
Epoch: 147 | Batch_idx: 140 |  Loss: (0.1392) |  Loss2: (0.0000) | Acc: (95.00%) (17180/18048)
Epoch: 147 | Batch_idx: 150 |  Loss: (0.1396) |  Loss2: (0.0000) | Acc: (95.00%) (18396/19328)
Epoch: 147 | Batch_idx: 160 |  Loss: (0.1393) |  Loss2: (0.0000) | Acc: (95.00%) (19619/20608)
Epoch: 147 | Batch_idx: 170 |  Loss: (0.1385) |  Loss2: (0.0000) | Acc: (95.00%) (20841/21888)
Epoch: 147 | Batch_idx: 180 |  Loss: (0.1386) |  Loss2: (0.0000) | Acc: (95.00%) (22064/23168)
Epoch: 147 | Batch_idx: 190 |  Loss: (0.1381) |  Loss2: (0.0000) | Acc: (95.00%) (23289/24448)
Epoch: 147 | Batch_idx: 200 |  Loss: (0.1383) |  Loss2: (0.0000) | Acc: (95.00%) (24511/25728)
Epoch: 147 | Batch_idx: 210 |  Loss: (0.1379) |  Loss2: (0.0000) | Acc: (95.00%) (25741/27008)
Epoch: 147 | Batch_idx: 220 |  Loss: (0.1383) |  Loss2: (0.0000) | Acc: (95.00%) (26957/28288)
Epoch: 147 | Batch_idx: 230 |  Loss: (0.1390) |  Loss2: (0.0000) | Acc: (95.00%) (28162/29568)
Epoch: 147 | Batch_idx: 240 |  Loss: (0.1401) |  Loss2: (0.0000) | Acc: (95.00%) (29371/30848)
Epoch: 147 | Batch_idx: 250 |  Loss: (0.1399) |  Loss2: (0.0000) | Acc: (95.00%) (30587/32128)
Epoch: 147 | Batch_idx: 260 |  Loss: (0.1401) |  Loss2: (0.0000) | Acc: (95.00%) (31813/33408)
Epoch: 147 | Batch_idx: 270 |  Loss: (0.1406) |  Loss2: (0.0000) | Acc: (95.00%) (33034/34688)
Epoch: 147 | Batch_idx: 280 |  Loss: (0.1417) |  Loss2: (0.0000) | Acc: (95.00%) (34235/35968)
Epoch: 147 | Batch_idx: 290 |  Loss: (0.1416) |  Loss2: (0.0000) | Acc: (95.00%) (35455/37248)
Epoch: 147 | Batch_idx: 300 |  Loss: (0.1415) |  Loss2: (0.0000) | Acc: (95.00%) (36682/38528)
Epoch: 147 | Batch_idx: 310 |  Loss: (0.1414) |  Loss2: (0.0000) | Acc: (95.00%) (37895/39808)
Epoch: 147 | Batch_idx: 320 |  Loss: (0.1408) |  Loss2: (0.0000) | Acc: (95.00%) (39119/41088)
Epoch: 147 | Batch_idx: 330 |  Loss: (0.1412) |  Loss2: (0.0000) | Acc: (95.00%) (40334/42368)
Epoch: 147 | Batch_idx: 340 |  Loss: (0.1415) |  Loss2: (0.0000) | Acc: (95.00%) (41547/43648)
Epoch: 147 | Batch_idx: 350 |  Loss: (0.1417) |  Loss2: (0.0000) | Acc: (95.00%) (42770/44928)
Epoch: 147 | Batch_idx: 360 |  Loss: (0.1415) |  Loss2: (0.0000) | Acc: (95.00%) (43989/46208)
Epoch: 147 | Batch_idx: 370 |  Loss: (0.1418) |  Loss2: (0.0000) | Acc: (95.00%) (45195/47488)
Epoch: 147 | Batch_idx: 380 |  Loss: (0.1419) |  Loss2: (0.0000) | Acc: (95.00%) (46408/48768)
Epoch: 147 | Batch_idx: 390 |  Loss: (0.1420) |  Loss2: (0.0000) | Acc: (95.00%) (47580/50000)
# TEST : Loss: (0.4095) | Acc: (87.00%) (8775/10000)
percent tensor([0.5189, 0.5065, 0.5223, 0.5158, 0.5245, 0.5302, 0.5136, 0.5148, 0.5189,
        0.5095, 0.5189, 0.5155, 0.5091, 0.5114, 0.5169, 0.5159],
       device='cuda:0') torch.Size([16])
percent tensor([0.5102, 0.5058, 0.5117, 0.5103, 0.5098, 0.5086, 0.5077, 0.5127, 0.5167,
        0.5087, 0.5146, 0.5070, 0.5056, 0.5194, 0.5059, 0.5113],
       device='cuda:0') torch.Size([16])
percent tensor([0.5495, 0.5468, 0.5464, 0.5664, 0.5608, 0.5410, 0.5660, 0.5599, 0.5598,
        0.5557, 0.5548, 0.5529, 0.5134, 0.6112, 0.5399, 0.5630],
       device='cuda:0') torch.Size([16])
percent tensor([0.6167, 0.6375, 0.6171, 0.6083, 0.6094, 0.6168, 0.6294, 0.6033, 0.6366,
        0.6407, 0.6493, 0.6298, 0.6362, 0.6491, 0.6144, 0.6264],
       device='cuda:0') torch.Size([16])
percent tensor([0.5905, 0.6640, 0.4868, 0.5903, 0.4924, 0.6189, 0.6131, 0.3568, 0.6645,
        0.6517, 0.7033, 0.5862, 0.6490, 0.6931, 0.5323, 0.6143],
       device='cuda:0') torch.Size([16])
percent tensor([0.6240, 0.6257, 0.6373, 0.6307, 0.6800, 0.6372, 0.6435, 0.6654, 0.6254,
        0.6219, 0.5933, 0.5789, 0.5855, 0.6126, 0.6152, 0.6312],
       device='cuda:0') torch.Size([16])
percent tensor([0.5183, 0.6175, 0.6833, 0.5943, 0.7462, 0.7345, 0.6138, 0.6213, 0.6329,
        0.5846, 0.6717, 0.5318, 0.6611, 0.5792, 0.5258, 0.5051],
       device='cuda:0') torch.Size([16])
percent tensor([0.9996, 0.9996, 0.9998, 0.9997, 0.9995, 0.9992, 0.9995, 0.9998, 0.9996,
        0.9997, 0.9999, 0.9998, 0.9998, 0.9989, 0.9994, 0.9995],
       device='cuda:0') torch.Size([16])
Epoch: 148 | Batch_idx: 0 |  Loss: (0.1008) |  Loss2: (0.0000) | Acc: (96.00%) (124/128)
Epoch: 148 | Batch_idx: 10 |  Loss: (0.1345) |  Loss2: (0.0000) | Acc: (95.00%) (1349/1408)
Epoch: 148 | Batch_idx: 20 |  Loss: (0.1384) |  Loss2: (0.0000) | Acc: (95.00%) (2567/2688)
Epoch: 148 | Batch_idx: 30 |  Loss: (0.1287) |  Loss2: (0.0000) | Acc: (95.00%) (3800/3968)
Epoch: 148 | Batch_idx: 40 |  Loss: (0.1333) |  Loss2: (0.0000) | Acc: (95.00%) (5019/5248)
Epoch: 148 | Batch_idx: 50 |  Loss: (0.1288) |  Loss2: (0.0000) | Acc: (95.00%) (6251/6528)
Epoch: 148 | Batch_idx: 60 |  Loss: (0.1331) |  Loss2: (0.0000) | Acc: (95.00%) (7460/7808)
Epoch: 148 | Batch_idx: 70 |  Loss: (0.1305) |  Loss2: (0.0000) | Acc: (95.00%) (8690/9088)
Epoch: 148 | Batch_idx: 80 |  Loss: (0.1314) |  Loss2: (0.0000) | Acc: (95.00%) (9908/10368)
Epoch: 148 | Batch_idx: 90 |  Loss: (0.1319) |  Loss2: (0.0000) | Acc: (95.00%) (11125/11648)
Epoch: 148 | Batch_idx: 100 |  Loss: (0.1337) |  Loss2: (0.0000) | Acc: (95.00%) (12336/12928)
Epoch: 148 | Batch_idx: 110 |  Loss: (0.1340) |  Loss2: (0.0000) | Acc: (95.00%) (13554/14208)
Epoch: 148 | Batch_idx: 120 |  Loss: (0.1341) |  Loss2: (0.0000) | Acc: (95.00%) (14782/15488)
Epoch: 148 | Batch_idx: 130 |  Loss: (0.1351) |  Loss2: (0.0000) | Acc: (95.00%) (15998/16768)
Epoch: 148 | Batch_idx: 140 |  Loss: (0.1364) |  Loss2: (0.0000) | Acc: (95.00%) (17209/18048)
Epoch: 148 | Batch_idx: 150 |  Loss: (0.1370) |  Loss2: (0.0000) | Acc: (95.00%) (18420/19328)
Epoch: 148 | Batch_idx: 160 |  Loss: (0.1374) |  Loss2: (0.0000) | Acc: (95.00%) (19636/20608)
Epoch: 148 | Batch_idx: 170 |  Loss: (0.1379) |  Loss2: (0.0000) | Acc: (95.00%) (20848/21888)
Epoch: 148 | Batch_idx: 180 |  Loss: (0.1364) |  Loss2: (0.0000) | Acc: (95.00%) (22091/23168)
Epoch: 148 | Batch_idx: 190 |  Loss: (0.1362) |  Loss2: (0.0000) | Acc: (95.00%) (23312/24448)
Epoch: 148 | Batch_idx: 200 |  Loss: (0.1369) |  Loss2: (0.0000) | Acc: (95.00%) (24528/25728)
Epoch: 148 | Batch_idx: 210 |  Loss: (0.1369) |  Loss2: (0.0000) | Acc: (95.00%) (25741/27008)
Epoch: 148 | Batch_idx: 220 |  Loss: (0.1374) |  Loss2: (0.0000) | Acc: (95.00%) (26955/28288)
Epoch: 148 | Batch_idx: 230 |  Loss: (0.1391) |  Loss2: (0.0000) | Acc: (95.00%) (28169/29568)
Epoch: 148 | Batch_idx: 240 |  Loss: (0.1385) |  Loss2: (0.0000) | Acc: (95.00%) (29400/30848)
Epoch: 148 | Batch_idx: 250 |  Loss: (0.1395) |  Loss2: (0.0000) | Acc: (95.00%) (30608/32128)
Epoch: 148 | Batch_idx: 260 |  Loss: (0.1399) |  Loss2: (0.0000) | Acc: (95.00%) (31823/33408)
Epoch: 148 | Batch_idx: 270 |  Loss: (0.1396) |  Loss2: (0.0000) | Acc: (95.00%) (33049/34688)
Epoch: 148 | Batch_idx: 280 |  Loss: (0.1398) |  Loss2: (0.0000) | Acc: (95.00%) (34261/35968)
Epoch: 148 | Batch_idx: 290 |  Loss: (0.1404) |  Loss2: (0.0000) | Acc: (95.00%) (35468/37248)
Epoch: 148 | Batch_idx: 300 |  Loss: (0.1404) |  Loss2: (0.0000) | Acc: (95.00%) (36684/38528)
Epoch: 148 | Batch_idx: 310 |  Loss: (0.1404) |  Loss2: (0.0000) | Acc: (95.00%) (37904/39808)
Epoch: 148 | Batch_idx: 320 |  Loss: (0.1403) |  Loss2: (0.0000) | Acc: (95.00%) (39130/41088)
Epoch: 148 | Batch_idx: 330 |  Loss: (0.1398) |  Loss2: (0.0000) | Acc: (95.00%) (40358/42368)
Epoch: 148 | Batch_idx: 340 |  Loss: (0.1399) |  Loss2: (0.0000) | Acc: (95.00%) (41578/43648)
Epoch: 148 | Batch_idx: 350 |  Loss: (0.1393) |  Loss2: (0.0000) | Acc: (95.00%) (42804/44928)
Epoch: 148 | Batch_idx: 360 |  Loss: (0.1391) |  Loss2: (0.0000) | Acc: (95.00%) (44027/46208)
Epoch: 148 | Batch_idx: 370 |  Loss: (0.1393) |  Loss2: (0.0000) | Acc: (95.00%) (45238/47488)
Epoch: 148 | Batch_idx: 380 |  Loss: (0.1396) |  Loss2: (0.0000) | Acc: (95.00%) (46447/48768)
Epoch: 148 | Batch_idx: 390 |  Loss: (0.1389) |  Loss2: (0.0000) | Acc: (95.00%) (47631/50000)
# TEST : Loss: (0.4029) | Acc: (88.00%) (8821/10000)
percent tensor([0.5182, 0.5062, 0.5218, 0.5155, 0.5237, 0.5287, 0.5132, 0.5151, 0.5181,
        0.5093, 0.5184, 0.5155, 0.5088, 0.5116, 0.5161, 0.5159],
       device='cuda:0') torch.Size([16])
percent tensor([0.5113, 0.5052, 0.5094, 0.5096, 0.5084, 0.5112, 0.5074, 0.5119, 0.5163,
        0.5077, 0.5148, 0.5048, 0.5057, 0.5189, 0.5062, 0.5121],
       device='cuda:0') torch.Size([16])
percent tensor([0.5578, 0.5461, 0.5563, 0.5654, 0.5650, 0.5484, 0.5668, 0.5651, 0.5597,
        0.5544, 0.5565, 0.5566, 0.5173, 0.6050, 0.5419, 0.5674],
       device='cuda:0') torch.Size([16])
percent tensor([0.6157, 0.6326, 0.6208, 0.6108, 0.6099, 0.6113, 0.6253, 0.6070, 0.6319,
        0.6349, 0.6453, 0.6287, 0.6326, 0.6409, 0.6084, 0.6235],
       device='cuda:0') torch.Size([16])
percent tensor([0.5873, 0.6658, 0.4833, 0.5997, 0.4921, 0.5994, 0.6155, 0.3697, 0.6581,
        0.6537, 0.7093, 0.5934, 0.6467, 0.6924, 0.5267, 0.6098],
       device='cuda:0') torch.Size([16])
percent tensor([0.6156, 0.6170, 0.6444, 0.6287, 0.6846, 0.6365, 0.6294, 0.6595, 0.6217,
        0.6164, 0.5877, 0.5753, 0.5743, 0.5999, 0.6065, 0.6288],
       device='cuda:0') torch.Size([16])
percent tensor([0.5235, 0.6255, 0.7082, 0.6303, 0.7466, 0.7439, 0.5806, 0.6393, 0.6501,
        0.5737, 0.6788, 0.5831, 0.6551, 0.5818, 0.5400, 0.5034],
       device='cuda:0') torch.Size([16])
percent tensor([0.9996, 0.9995, 0.9998, 0.9997, 0.9994, 0.9993, 0.9995, 0.9997, 0.9998,
        0.9998, 0.9999, 0.9998, 0.9998, 0.9992, 0.9997, 0.9994],
       device='cuda:0') torch.Size([16])
Epoch: 149 | Batch_idx: 0 |  Loss: (0.0800) |  Loss2: (0.0000) | Acc: (96.00%) (124/128)
Epoch: 149 | Batch_idx: 10 |  Loss: (0.1375) |  Loss2: (0.0000) | Acc: (95.00%) (1339/1408)
Epoch: 149 | Batch_idx: 20 |  Loss: (0.1341) |  Loss2: (0.0000) | Acc: (95.00%) (2557/2688)
Epoch: 149 | Batch_idx: 30 |  Loss: (0.1338) |  Loss2: (0.0000) | Acc: (94.00%) (3769/3968)
Epoch: 149 | Batch_idx: 40 |  Loss: (0.1335) |  Loss2: (0.0000) | Acc: (95.00%) (4991/5248)
Epoch: 149 | Batch_idx: 50 |  Loss: (0.1343) |  Loss2: (0.0000) | Acc: (95.00%) (6213/6528)
Epoch: 149 | Batch_idx: 60 |  Loss: (0.1346) |  Loss2: (0.0000) | Acc: (95.00%) (7432/7808)
Epoch: 149 | Batch_idx: 70 |  Loss: (0.1351) |  Loss2: (0.0000) | Acc: (95.00%) (8653/9088)
Epoch: 149 | Batch_idx: 80 |  Loss: (0.1346) |  Loss2: (0.0000) | Acc: (95.00%) (9879/10368)
Epoch: 149 | Batch_idx: 90 |  Loss: (0.1315) |  Loss2: (0.0000) | Acc: (95.00%) (11111/11648)
Epoch: 149 | Batch_idx: 100 |  Loss: (0.1312) |  Loss2: (0.0000) | Acc: (95.00%) (12340/12928)
Epoch: 149 | Batch_idx: 110 |  Loss: (0.1340) |  Loss2: (0.0000) | Acc: (95.00%) (13555/14208)
Epoch: 149 | Batch_idx: 120 |  Loss: (0.1339) |  Loss2: (0.0000) | Acc: (95.00%) (14778/15488)
Epoch: 149 | Batch_idx: 130 |  Loss: (0.1334) |  Loss2: (0.0000) | Acc: (95.00%) (15998/16768)
Epoch: 149 | Batch_idx: 140 |  Loss: (0.1344) |  Loss2: (0.0000) | Acc: (95.00%) (17221/18048)
Epoch: 149 | Batch_idx: 150 |  Loss: (0.1345) |  Loss2: (0.0000) | Acc: (95.00%) (18442/19328)
Epoch: 149 | Batch_idx: 160 |  Loss: (0.1342) |  Loss2: (0.0000) | Acc: (95.00%) (19667/20608)
Epoch: 149 | Batch_idx: 170 |  Loss: (0.1347) |  Loss2: (0.0000) | Acc: (95.00%) (20877/21888)
Epoch: 149 | Batch_idx: 180 |  Loss: (0.1342) |  Loss2: (0.0000) | Acc: (95.00%) (22110/23168)
Epoch: 149 | Batch_idx: 190 |  Loss: (0.1344) |  Loss2: (0.0000) | Acc: (95.00%) (23331/24448)
Epoch: 149 | Batch_idx: 200 |  Loss: (0.1338) |  Loss2: (0.0000) | Acc: (95.00%) (24555/25728)
Epoch: 149 | Batch_idx: 210 |  Loss: (0.1334) |  Loss2: (0.0000) | Acc: (95.00%) (25785/27008)
Epoch: 149 | Batch_idx: 220 |  Loss: (0.1326) |  Loss2: (0.0000) | Acc: (95.00%) (27019/28288)
Epoch: 149 | Batch_idx: 230 |  Loss: (0.1329) |  Loss2: (0.0000) | Acc: (95.00%) (28239/29568)
Epoch: 149 | Batch_idx: 240 |  Loss: (0.1334) |  Loss2: (0.0000) | Acc: (95.00%) (29452/30848)
Epoch: 149 | Batch_idx: 250 |  Loss: (0.1349) |  Loss2: (0.0000) | Acc: (95.00%) (30651/32128)
Epoch: 149 | Batch_idx: 260 |  Loss: (0.1347) |  Loss2: (0.0000) | Acc: (95.00%) (31878/33408)
Epoch: 149 | Batch_idx: 270 |  Loss: (0.1352) |  Loss2: (0.0000) | Acc: (95.00%) (33079/34688)
Epoch: 149 | Batch_idx: 280 |  Loss: (0.1348) |  Loss2: (0.0000) | Acc: (95.00%) (34306/35968)
Epoch: 149 | Batch_idx: 290 |  Loss: (0.1347) |  Loss2: (0.0000) | Acc: (95.00%) (35524/37248)
Epoch: 149 | Batch_idx: 300 |  Loss: (0.1349) |  Loss2: (0.0000) | Acc: (95.00%) (36745/38528)
Epoch: 149 | Batch_idx: 310 |  Loss: (0.1356) |  Loss2: (0.0000) | Acc: (95.00%) (37959/39808)
Epoch: 149 | Batch_idx: 320 |  Loss: (0.1352) |  Loss2: (0.0000) | Acc: (95.00%) (39186/41088)
Epoch: 149 | Batch_idx: 330 |  Loss: (0.1356) |  Loss2: (0.0000) | Acc: (95.00%) (40405/42368)
Epoch: 149 | Batch_idx: 340 |  Loss: (0.1367) |  Loss2: (0.0000) | Acc: (95.00%) (41607/43648)
Epoch: 149 | Batch_idx: 350 |  Loss: (0.1370) |  Loss2: (0.0000) | Acc: (95.00%) (42823/44928)
Epoch: 149 | Batch_idx: 360 |  Loss: (0.1369) |  Loss2: (0.0000) | Acc: (95.00%) (44043/46208)
Epoch: 149 | Batch_idx: 370 |  Loss: (0.1365) |  Loss2: (0.0000) | Acc: (95.00%) (45272/47488)
Epoch: 149 | Batch_idx: 380 |  Loss: (0.1368) |  Loss2: (0.0000) | Acc: (95.00%) (46484/48768)
Epoch: 149 | Batch_idx: 390 |  Loss: (0.1365) |  Loss2: (0.0000) | Acc: (95.00%) (47671/50000)
# TEST : Loss: (0.3988) | Acc: (87.00%) (8779/10000)
percent tensor([0.5194, 0.5061, 0.5214, 0.5154, 0.5248, 0.5291, 0.5137, 0.5149, 0.5192,
        0.5095, 0.5187, 0.5158, 0.5099, 0.5104, 0.5162, 0.5160],
       device='cuda:0') torch.Size([16])
percent tensor([0.5109, 0.5055, 0.5106, 0.5108, 0.5092, 0.5096, 0.5078, 0.5129, 0.5166,
        0.5085, 0.5146, 0.5061, 0.5057, 0.5192, 0.5059, 0.5119],
       device='cuda:0') torch.Size([16])
percent tensor([0.5559, 0.5508, 0.5441, 0.5685, 0.5571, 0.5463, 0.5703, 0.5667, 0.5638,
        0.5576, 0.5605, 0.5497, 0.5199, 0.6159, 0.5434, 0.5697],
       device='cuda:0') torch.Size([16])
percent tensor([0.6159, 0.6389, 0.6152, 0.6092, 0.6079, 0.6107, 0.6293, 0.6070, 0.6376,
        0.6423, 0.6513, 0.6296, 0.6391, 0.6479, 0.6131, 0.6274],
       device='cuda:0') torch.Size([16])
percent tensor([0.5947, 0.6766, 0.5042, 0.5953, 0.5167, 0.6248, 0.6311, 0.3787, 0.6729,
        0.6663, 0.7133, 0.5941, 0.6540, 0.7064, 0.5547, 0.6291],
       device='cuda:0') torch.Size([16])
percent tensor([0.6208, 0.6040, 0.6346, 0.6234, 0.6755, 0.6424, 0.6320, 0.6587, 0.6131,
        0.6040, 0.5776, 0.5675, 0.5727, 0.5900, 0.6086, 0.6301],
       device='cuda:0') torch.Size([16])
percent tensor([0.5476, 0.5877, 0.6967, 0.6153, 0.7402, 0.7525, 0.5841, 0.6033, 0.6271,
        0.5688, 0.7007, 0.5468, 0.6673, 0.5960, 0.5349, 0.4982],
       device='cuda:0') torch.Size([16])
percent tensor([0.9997, 0.9996, 0.9997, 0.9995, 0.9996, 0.9992, 0.9996, 0.9997, 0.9997,
        0.9996, 0.9999, 0.9997, 0.9998, 0.9988, 0.9994, 0.9993],
       device='cuda:0') torch.Size([16])
Epoch: 150 | Batch_idx: 0 |  Loss: (0.1406) |  Loss2: (0.0000) | Acc: (96.00%) (124/128)
Epoch: 150 | Batch_idx: 10 |  Loss: (0.1179) |  Loss2: (0.0000) | Acc: (96.00%) (1354/1408)
Epoch: 150 | Batch_idx: 20 |  Loss: (0.1239) |  Loss2: (0.0000) | Acc: (96.00%) (2586/2688)
Epoch: 150 | Batch_idx: 30 |  Loss: (0.1244) |  Loss2: (0.0000) | Acc: (95.00%) (3807/3968)
Epoch: 150 | Batch_idx: 40 |  Loss: (0.1273) |  Loss2: (0.0000) | Acc: (95.00%) (5022/5248)
Epoch: 150 | Batch_idx: 50 |  Loss: (0.1287) |  Loss2: (0.0000) | Acc: (95.00%) (6239/6528)
Epoch: 150 | Batch_idx: 60 |  Loss: (0.1267) |  Loss2: (0.0000) | Acc: (95.00%) (7476/7808)
Epoch: 150 | Batch_idx: 70 |  Loss: (0.1241) |  Loss2: (0.0000) | Acc: (95.00%) (8712/9088)
Epoch: 150 | Batch_idx: 80 |  Loss: (0.1218) |  Loss2: (0.0000) | Acc: (95.00%) (9945/10368)
Epoch: 150 | Batch_idx: 90 |  Loss: (0.1223) |  Loss2: (0.0000) | Acc: (95.00%) (11168/11648)
Epoch: 150 | Batch_idx: 100 |  Loss: (0.1252) |  Loss2: (0.0000) | Acc: (95.00%) (12387/12928)
Epoch: 150 | Batch_idx: 110 |  Loss: (0.1264) |  Loss2: (0.0000) | Acc: (95.00%) (13600/14208)
Epoch: 150 | Batch_idx: 120 |  Loss: (0.1267) |  Loss2: (0.0000) | Acc: (95.00%) (14829/15488)
Epoch: 150 | Batch_idx: 130 |  Loss: (0.1252) |  Loss2: (0.0000) | Acc: (95.00%) (16065/16768)
Epoch: 150 | Batch_idx: 140 |  Loss: (0.1259) |  Loss2: (0.0000) | Acc: (95.00%) (17283/18048)
Epoch: 150 | Batch_idx: 150 |  Loss: (0.1249) |  Loss2: (0.0000) | Acc: (95.00%) (18509/19328)
Epoch: 150 | Batch_idx: 160 |  Loss: (0.1254) |  Loss2: (0.0000) | Acc: (95.00%) (19729/20608)
Epoch: 150 | Batch_idx: 170 |  Loss: (0.1267) |  Loss2: (0.0000) | Acc: (95.00%) (20948/21888)
Epoch: 150 | Batch_idx: 180 |  Loss: (0.1269) |  Loss2: (0.0000) | Acc: (95.00%) (22168/23168)
Epoch: 150 | Batch_idx: 190 |  Loss: (0.1277) |  Loss2: (0.0000) | Acc: (95.00%) (23384/24448)
Epoch: 150 | Batch_idx: 200 |  Loss: (0.1279) |  Loss2: (0.0000) | Acc: (95.00%) (24603/25728)
Epoch: 150 | Batch_idx: 210 |  Loss: (0.1292) |  Loss2: (0.0000) | Acc: (95.00%) (25810/27008)
Epoch: 150 | Batch_idx: 220 |  Loss: (0.1311) |  Loss2: (0.0000) | Acc: (95.00%) (27010/28288)
Epoch: 150 | Batch_idx: 230 |  Loss: (0.1307) |  Loss2: (0.0000) | Acc: (95.00%) (28240/29568)
Epoch: 150 | Batch_idx: 240 |  Loss: (0.1308) |  Loss2: (0.0000) | Acc: (95.00%) (29455/30848)
Epoch: 150 | Batch_idx: 250 |  Loss: (0.1303) |  Loss2: (0.0000) | Acc: (95.00%) (30681/32128)
Epoch: 150 | Batch_idx: 260 |  Loss: (0.1299) |  Loss2: (0.0000) | Acc: (95.00%) (31904/33408)
Epoch: 150 | Batch_idx: 270 |  Loss: (0.1301) |  Loss2: (0.0000) | Acc: (95.00%) (33124/34688)
Epoch: 150 | Batch_idx: 280 |  Loss: (0.1306) |  Loss2: (0.0000) | Acc: (95.00%) (34336/35968)
Epoch: 150 | Batch_idx: 290 |  Loss: (0.1308) |  Loss2: (0.0000) | Acc: (95.00%) (35557/37248)
Epoch: 150 | Batch_idx: 300 |  Loss: (0.1304) |  Loss2: (0.0000) | Acc: (95.00%) (36783/38528)
Epoch: 150 | Batch_idx: 310 |  Loss: (0.1304) |  Loss2: (0.0000) | Acc: (95.00%) (38005/39808)
Epoch: 150 | Batch_idx: 320 |  Loss: (0.1313) |  Loss2: (0.0000) | Acc: (95.00%) (39211/41088)
Epoch: 150 | Batch_idx: 330 |  Loss: (0.1317) |  Loss2: (0.0000) | Acc: (95.00%) (40427/42368)
Epoch: 150 | Batch_idx: 340 |  Loss: (0.1319) |  Loss2: (0.0000) | Acc: (95.00%) (41648/43648)
Epoch: 150 | Batch_idx: 350 |  Loss: (0.1316) |  Loss2: (0.0000) | Acc: (95.00%) (42873/44928)
Epoch: 150 | Batch_idx: 360 |  Loss: (0.1318) |  Loss2: (0.0000) | Acc: (95.00%) (44094/46208)
Epoch: 150 | Batch_idx: 370 |  Loss: (0.1326) |  Loss2: (0.0000) | Acc: (95.00%) (45294/47488)
Epoch: 150 | Batch_idx: 380 |  Loss: (0.1332) |  Loss2: (0.0000) | Acc: (95.00%) (46498/48768)
Epoch: 150 | Batch_idx: 390 |  Loss: (0.1335) |  Loss2: (0.0000) | Acc: (95.00%) (47669/50000)
=> saving checkpoint 'drive/app/torch/save_Schedule/checkpoint_150.pth.tar'
# TEST : Loss: (0.4228) | Acc: (87.00%) (8730/10000)
percent tensor([0.5191, 0.5070, 0.5221, 0.5163, 0.5248, 0.5299, 0.5141, 0.5153, 0.5192,
        0.5096, 0.5193, 0.5161, 0.5095, 0.5120, 0.5170, 0.5162],
       device='cuda:0') torch.Size([16])
percent tensor([0.5099, 0.5062, 0.5111, 0.5100, 0.5094, 0.5094, 0.5087, 0.5129, 0.5162,
        0.5088, 0.5146, 0.5068, 0.5054, 0.5205, 0.5059, 0.5116],
       device='cuda:0') torch.Size([16])
percent tensor([0.5521, 0.5456, 0.5487, 0.5593, 0.5582, 0.5476, 0.5656, 0.5569, 0.5538,
        0.5522, 0.5516, 0.5524, 0.5145, 0.6091, 0.5410, 0.5644],
       device='cuda:0') torch.Size([16])
percent tensor([0.6175, 0.6390, 0.6157, 0.6126, 0.6076, 0.6184, 0.6283, 0.6061, 0.6361,
        0.6423, 0.6515, 0.6297, 0.6382, 0.6478, 0.6172, 0.6307],
       device='cuda:0') torch.Size([16])
percent tensor([0.5985, 0.6924, 0.4997, 0.6001, 0.5064, 0.6152, 0.6341, 0.3929, 0.6849,
        0.6716, 0.7268, 0.5899, 0.6659, 0.6995, 0.5720, 0.6379],
       device='cuda:0') torch.Size([16])
percent tensor([0.6143, 0.6038, 0.6434, 0.6217, 0.6802, 0.6390, 0.6422, 0.6588, 0.6152,
        0.6040, 0.5785, 0.5738, 0.5718, 0.6035, 0.6003, 0.6275],
       device='cuda:0') torch.Size([16])
percent tensor([0.5229, 0.5873, 0.6983, 0.6144, 0.7435, 0.7315, 0.6018, 0.6250, 0.6386,
        0.5679, 0.6912, 0.5473, 0.6504, 0.6111, 0.5200, 0.4803],
       device='cuda:0') torch.Size([16])
percent tensor([0.9997, 0.9997, 0.9996, 0.9995, 0.9996, 0.9992, 0.9995, 0.9997, 0.9997,
        0.9997, 0.9999, 0.9998, 0.9997, 0.9991, 0.9994, 0.9993],
       device='cuda:0') torch.Size([16])
Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 3, 3, 3]) tensor(188.7818, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(832.8298, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(821.3906, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([128, 64, 3, 3]) tensor(1525.4329, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([128, 64, 1, 1]) tensor(480.7602, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([128, 128, 3, 3]) tensor(2294.7158, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([256, 128, 3, 3]) tensor(4261.9019, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([256, 128, 1, 1]) tensor(1364.6140, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([256, 256, 3, 3]) tensor(6197.6611, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([512, 256, 3, 3]) tensor(11683.4199, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([512, 256, 1, 1]) tensor(3862.9033, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([512, 512, 3, 3]) tensor(16324.8730, device='cuda:0', grad_fn=<NormBackward0>)
Epoch: 151 | Batch_idx: 0 |  Loss: (0.1273) |  Loss2: (0.0000) | Acc: (95.00%) (122/128)
Epoch: 151 | Batch_idx: 10 |  Loss: (0.1264) |  Loss2: (0.0000) | Acc: (95.00%) (1345/1408)
Epoch: 151 | Batch_idx: 20 |  Loss: (0.1191) |  Loss2: (0.0000) | Acc: (96.00%) (2584/2688)
Epoch: 151 | Batch_idx: 30 |  Loss: (0.1225) |  Loss2: (0.0000) | Acc: (96.00%) (3813/3968)
Epoch: 151 | Batch_idx: 40 |  Loss: (0.1234) |  Loss2: (0.0000) | Acc: (96.00%) (5047/5248)
Epoch: 151 | Batch_idx: 50 |  Loss: (0.1236) |  Loss2: (0.0000) | Acc: (96.00%) (6279/6528)
Epoch: 151 | Batch_idx: 60 |  Loss: (0.1287) |  Loss2: (0.0000) | Acc: (96.00%) (7497/7808)
Epoch: 151 | Batch_idx: 70 |  Loss: (0.1281) |  Loss2: (0.0000) | Acc: (96.00%) (8726/9088)
Epoch: 151 | Batch_idx: 80 |  Loss: (0.1294) |  Loss2: (0.0000) | Acc: (95.00%) (9945/10368)
Epoch: 151 | Batch_idx: 90 |  Loss: (0.1274) |  Loss2: (0.0000) | Acc: (95.00%) (11178/11648)
Epoch: 151 | Batch_idx: 100 |  Loss: (0.1252) |  Loss2: (0.0000) | Acc: (96.00%) (12413/12928)
Epoch: 151 | Batch_idx: 110 |  Loss: (0.1259) |  Loss2: (0.0000) | Acc: (95.00%) (13639/14208)
Epoch: 151 | Batch_idx: 120 |  Loss: (0.1268) |  Loss2: (0.0000) | Acc: (95.00%) (14852/15488)
Epoch: 151 | Batch_idx: 130 |  Loss: (0.1258) |  Loss2: (0.0000) | Acc: (95.00%) (16077/16768)
Epoch: 151 | Batch_idx: 140 |  Loss: (0.1254) |  Loss2: (0.0000) | Acc: (95.00%) (17306/18048)
Epoch: 151 | Batch_idx: 150 |  Loss: (0.1247) |  Loss2: (0.0000) | Acc: (95.00%) (18535/19328)
Epoch: 151 | Batch_idx: 160 |  Loss: (0.1263) |  Loss2: (0.0000) | Acc: (95.00%) (19751/20608)
Epoch: 151 | Batch_idx: 170 |  Loss: (0.1262) |  Loss2: (0.0000) | Acc: (95.00%) (20975/21888)
Epoch: 151 | Batch_idx: 180 |  Loss: (0.1259) |  Loss2: (0.0000) | Acc: (95.00%) (22199/23168)
Epoch: 151 | Batch_idx: 190 |  Loss: (0.1265) |  Loss2: (0.0000) | Acc: (95.00%) (23415/24448)
Epoch: 151 | Batch_idx: 200 |  Loss: (0.1261) |  Loss2: (0.0000) | Acc: (95.00%) (24642/25728)
Epoch: 151 | Batch_idx: 210 |  Loss: (0.1264) |  Loss2: (0.0000) | Acc: (95.00%) (25871/27008)
Epoch: 151 | Batch_idx: 220 |  Loss: (0.1259) |  Loss2: (0.0000) | Acc: (95.00%) (27096/28288)
Epoch: 151 | Batch_idx: 230 |  Loss: (0.1269) |  Loss2: (0.0000) | Acc: (95.00%) (28306/29568)
Epoch: 151 | Batch_idx: 240 |  Loss: (0.1278) |  Loss2: (0.0000) | Acc: (95.00%) (29515/30848)
Epoch: 151 | Batch_idx: 250 |  Loss: (0.1281) |  Loss2: (0.0000) | Acc: (95.00%) (30738/32128)
Epoch: 151 | Batch_idx: 260 |  Loss: (0.1287) |  Loss2: (0.0000) | Acc: (95.00%) (31951/33408)
Epoch: 151 | Batch_idx: 270 |  Loss: (0.1302) |  Loss2: (0.0000) | Acc: (95.00%) (33155/34688)
Epoch: 151 | Batch_idx: 280 |  Loss: (0.1306) |  Loss2: (0.0000) | Acc: (95.00%) (34358/35968)
Epoch: 151 | Batch_idx: 290 |  Loss: (0.1305) |  Loss2: (0.0000) | Acc: (95.00%) (35575/37248)
Epoch: 151 | Batch_idx: 300 |  Loss: (0.1310) |  Loss2: (0.0000) | Acc: (95.00%) (36785/38528)
Epoch: 151 | Batch_idx: 310 |  Loss: (0.1305) |  Loss2: (0.0000) | Acc: (95.00%) (38012/39808)
Epoch: 151 | Batch_idx: 320 |  Loss: (0.1317) |  Loss2: (0.0000) | Acc: (95.00%) (39224/41088)
Epoch: 151 | Batch_idx: 330 |  Loss: (0.1314) |  Loss2: (0.0000) | Acc: (95.00%) (40451/42368)
Epoch: 151 | Batch_idx: 340 |  Loss: (0.1312) |  Loss2: (0.0000) | Acc: (95.00%) (41675/43648)
Epoch: 151 | Batch_idx: 350 |  Loss: (0.1311) |  Loss2: (0.0000) | Acc: (95.00%) (42902/44928)
Epoch: 151 | Batch_idx: 360 |  Loss: (0.1315) |  Loss2: (0.0000) | Acc: (95.00%) (44115/46208)
Epoch: 151 | Batch_idx: 370 |  Loss: (0.1318) |  Loss2: (0.0000) | Acc: (95.00%) (45331/47488)
Epoch: 151 | Batch_idx: 380 |  Loss: (0.1313) |  Loss2: (0.0000) | Acc: (95.00%) (46562/48768)
Epoch: 151 | Batch_idx: 390 |  Loss: (0.1314) |  Loss2: (0.0000) | Acc: (95.00%) (47734/50000)
# TEST : Loss: (0.4546) | Acc: (86.00%) (8681/10000)
percent tensor([0.5190, 0.5056, 0.5218, 0.5164, 0.5240, 0.5291, 0.5129, 0.5157, 0.5189,
        0.5092, 0.5189, 0.5159, 0.5094, 0.5101, 0.5164, 0.5160],
       device='cuda:0') torch.Size([16])
percent tensor([0.5106, 0.5053, 0.5098, 0.5093, 0.5089, 0.5100, 0.5075, 0.5122, 0.5160,
        0.5078, 0.5137, 0.5051, 0.5052, 0.5186, 0.5057, 0.5116],
       device='cuda:0') torch.Size([16])
percent tensor([0.5515, 0.5491, 0.5419, 0.5640, 0.5531, 0.5477, 0.5682, 0.5614, 0.5545,
        0.5540, 0.5547, 0.5496, 0.5156, 0.6150, 0.5426, 0.5672],
       device='cuda:0') torch.Size([16])
percent tensor([0.6157, 0.6343, 0.6153, 0.6162, 0.6066, 0.6131, 0.6240, 0.6043, 0.6329,
        0.6376, 0.6445, 0.6272, 0.6328, 0.6455, 0.6119, 0.6259],
       device='cuda:0') torch.Size([16])
percent tensor([0.5754, 0.6630, 0.5216, 0.6096, 0.5161, 0.6040, 0.6163, 0.3809, 0.6721,
        0.6361, 0.7040, 0.5841, 0.6433, 0.6831, 0.5416, 0.6071],
       device='cuda:0') torch.Size([16])
percent tensor([0.6140, 0.6121, 0.6341, 0.6178, 0.6780, 0.6407, 0.6376, 0.6569, 0.6177,
        0.6079, 0.5846, 0.5706, 0.5786, 0.6009, 0.6051, 0.6292],
       device='cuda:0') torch.Size([16])
percent tensor([0.4984, 0.5786, 0.6745, 0.5860, 0.7489, 0.7368, 0.5822, 0.6112, 0.5991,
        0.5349, 0.6531, 0.5231, 0.6073, 0.5609, 0.5308, 0.4869],
       device='cuda:0') torch.Size([16])
percent tensor([0.9997, 0.9994, 0.9998, 0.9998, 0.9994, 0.9993, 0.9996, 0.9998, 0.9995,
        0.9997, 0.9998, 0.9999, 0.9997, 0.9992, 0.9995, 0.9995],
       device='cuda:0') torch.Size([16])
Epoch: 152 | Batch_idx: 0 |  Loss: (0.1668) |  Loss2: (0.0000) | Acc: (95.00%) (122/128)
Epoch: 152 | Batch_idx: 10 |  Loss: (0.1223) |  Loss2: (0.0000) | Acc: (95.00%) (1346/1408)
Epoch: 152 | Batch_idx: 20 |  Loss: (0.1143) |  Loss2: (0.0000) | Acc: (95.00%) (2575/2688)
Epoch: 152 | Batch_idx: 30 |  Loss: (0.1161) |  Loss2: (0.0000) | Acc: (95.00%) (3808/3968)
Epoch: 152 | Batch_idx: 40 |  Loss: (0.1145) |  Loss2: (0.0000) | Acc: (96.00%) (5046/5248)
Epoch: 152 | Batch_idx: 50 |  Loss: (0.1130) |  Loss2: (0.0000) | Acc: (96.00%) (6275/6528)
Epoch: 152 | Batch_idx: 60 |  Loss: (0.1136) |  Loss2: (0.0000) | Acc: (96.00%) (7501/7808)
Epoch: 152 | Batch_idx: 70 |  Loss: (0.1126) |  Loss2: (0.0000) | Acc: (96.00%) (8734/9088)
Epoch: 152 | Batch_idx: 80 |  Loss: (0.1141) |  Loss2: (0.0000) | Acc: (96.00%) (9956/10368)
Epoch: 152 | Batch_idx: 90 |  Loss: (0.1128) |  Loss2: (0.0000) | Acc: (96.00%) (11191/11648)
Epoch: 152 | Batch_idx: 100 |  Loss: (0.1123) |  Loss2: (0.0000) | Acc: (96.00%) (12429/12928)
Epoch: 152 | Batch_idx: 110 |  Loss: (0.1136) |  Loss2: (0.0000) | Acc: (96.00%) (13660/14208)
Epoch: 152 | Batch_idx: 120 |  Loss: (0.1129) |  Loss2: (0.0000) | Acc: (96.00%) (14895/15488)
Epoch: 152 | Batch_idx: 130 |  Loss: (0.1141) |  Loss2: (0.0000) | Acc: (96.00%) (16114/16768)
Epoch: 152 | Batch_idx: 140 |  Loss: (0.1150) |  Loss2: (0.0000) | Acc: (96.00%) (17338/18048)
Epoch: 152 | Batch_idx: 150 |  Loss: (0.1159) |  Loss2: (0.0000) | Acc: (96.00%) (18555/19328)
Epoch: 152 | Batch_idx: 160 |  Loss: (0.1161) |  Loss2: (0.0000) | Acc: (95.00%) (19783/20608)
Epoch: 152 | Batch_idx: 170 |  Loss: (0.1178) |  Loss2: (0.0000) | Acc: (95.00%) (21002/21888)
Epoch: 152 | Batch_idx: 180 |  Loss: (0.1181) |  Loss2: (0.0000) | Acc: (95.00%) (22227/23168)
Epoch: 152 | Batch_idx: 190 |  Loss: (0.1178) |  Loss2: (0.0000) | Acc: (95.00%) (23460/24448)
Epoch: 152 | Batch_idx: 200 |  Loss: (0.1183) |  Loss2: (0.0000) | Acc: (95.00%) (24687/25728)
Epoch: 152 | Batch_idx: 210 |  Loss: (0.1184) |  Loss2: (0.0000) | Acc: (95.00%) (25906/27008)
Epoch: 152 | Batch_idx: 220 |  Loss: (0.1191) |  Loss2: (0.0000) | Acc: (95.00%) (27138/28288)
Epoch: 152 | Batch_idx: 230 |  Loss: (0.1196) |  Loss2: (0.0000) | Acc: (95.00%) (28368/29568)
Epoch: 152 | Batch_idx: 240 |  Loss: (0.1208) |  Loss2: (0.0000) | Acc: (95.00%) (29578/30848)
Epoch: 152 | Batch_idx: 250 |  Loss: (0.1217) |  Loss2: (0.0000) | Acc: (95.00%) (30798/32128)
Epoch: 152 | Batch_idx: 260 |  Loss: (0.1216) |  Loss2: (0.0000) | Acc: (95.00%) (32025/33408)
Epoch: 152 | Batch_idx: 270 |  Loss: (0.1221) |  Loss2: (0.0000) | Acc: (95.00%) (33245/34688)
Epoch: 152 | Batch_idx: 280 |  Loss: (0.1226) |  Loss2: (0.0000) | Acc: (95.00%) (34468/35968)
Epoch: 152 | Batch_idx: 290 |  Loss: (0.1227) |  Loss2: (0.0000) | Acc: (95.00%) (35695/37248)
Epoch: 152 | Batch_idx: 300 |  Loss: (0.1227) |  Loss2: (0.0000) | Acc: (95.00%) (36910/38528)
Epoch: 152 | Batch_idx: 310 |  Loss: (0.1235) |  Loss2: (0.0000) | Acc: (95.00%) (38132/39808)
Epoch: 152 | Batch_idx: 320 |  Loss: (0.1236) |  Loss2: (0.0000) | Acc: (95.00%) (39356/41088)
Epoch: 152 | Batch_idx: 330 |  Loss: (0.1233) |  Loss2: (0.0000) | Acc: (95.00%) (40584/42368)
Epoch: 152 | Batch_idx: 340 |  Loss: (0.1237) |  Loss2: (0.0000) | Acc: (95.00%) (41803/43648)
Epoch: 152 | Batch_idx: 350 |  Loss: (0.1239) |  Loss2: (0.0000) | Acc: (95.00%) (43032/44928)
Epoch: 152 | Batch_idx: 360 |  Loss: (0.1242) |  Loss2: (0.0000) | Acc: (95.00%) (44252/46208)
Epoch: 152 | Batch_idx: 370 |  Loss: (0.1239) |  Loss2: (0.0000) | Acc: (95.00%) (45476/47488)
Epoch: 152 | Batch_idx: 380 |  Loss: (0.1246) |  Loss2: (0.0000) | Acc: (95.00%) (46682/48768)
Epoch: 152 | Batch_idx: 390 |  Loss: (0.1245) |  Loss2: (0.0000) | Acc: (95.00%) (47864/50000)
# TEST : Loss: (0.4215) | Acc: (87.00%) (8768/10000)
percent tensor([0.5189, 0.5065, 0.5221, 0.5164, 0.5239, 0.5306, 0.5134, 0.5150, 0.5177,
        0.5089, 0.5181, 0.5153, 0.5089, 0.5112, 0.5172, 0.5159],
       device='cuda:0') torch.Size([16])
percent tensor([0.5107, 0.5058, 0.5109, 0.5104, 0.5088, 0.5100, 0.5074, 0.5126, 0.5168,
        0.5082, 0.5149, 0.5052, 0.5055, 0.5196, 0.5060, 0.5116],
       device='cuda:0') torch.Size([16])
percent tensor([0.5524, 0.5452, 0.5502, 0.5626, 0.5644, 0.5477, 0.5656, 0.5629, 0.5570,
        0.5531, 0.5545, 0.5510, 0.5169, 0.6029, 0.5410, 0.5648],
       device='cuda:0') torch.Size([16])
percent tensor([0.6132, 0.6342, 0.6132, 0.6065, 0.6048, 0.6116, 0.6214, 0.6021, 0.6344,
        0.6343, 0.6463, 0.6217, 0.6338, 0.6428, 0.6085, 0.6225],
       device='cuda:0') torch.Size([16])
percent tensor([0.6002, 0.6867, 0.4853, 0.5820, 0.4866, 0.6239, 0.6209, 0.3515, 0.6821,
        0.6587, 0.7194, 0.6019, 0.6644, 0.7015, 0.5570, 0.6134],
       device='cuda:0') torch.Size([16])
percent tensor([0.6175, 0.6100, 0.6372, 0.6212, 0.6802, 0.6352, 0.6331, 0.6524, 0.6244,
        0.6057, 0.5844, 0.5750, 0.5740, 0.5923, 0.6006, 0.6252],
       device='cuda:0') torch.Size([16])
percent tensor([0.5218, 0.5742, 0.7145, 0.6097, 0.7515, 0.7421, 0.5914, 0.6153, 0.6643,
        0.5543, 0.6743, 0.5880, 0.6392, 0.5634, 0.5226, 0.4837],
       device='cuda:0') torch.Size([16])
percent tensor([0.9997, 0.9995, 0.9996, 0.9995, 0.9994, 0.9995, 0.9994, 0.9997, 0.9998,
        0.9997, 0.9999, 0.9997, 0.9999, 0.9989, 0.9991, 0.9993],
       device='cuda:0') torch.Size([16])
False Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=128, out_features=16, bias=False)
True Linear(in_features=16, out_features=2, bias=False)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=128, out_features=16, bias=False)
True Linear(in_features=16, out_features=2, bias=False)
False Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=256, out_features=32, bias=False)
True Linear(in_features=32, out_features=2, bias=False)
False Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=256, out_features=32, bias=False)
True Linear(in_features=32, out_features=2, bias=False)
False Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=512, out_features=64, bias=False)
True Linear(in_features=64, out_features=2, bias=False)
False Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=512, out_features=64, bias=False)
True Linear(in_features=64, out_features=2, bias=False)
False Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1024, out_features=128, bias=False)
True Linear(in_features=128, out_features=2, bias=False)
False Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1024, out_features=128, bias=False)
True Linear(in_features=128, out_features=2, bias=False)
False Linear(in_features=512, out_features=10, bias=True)
Epoch: 153 | Batch_idx: 0 |  Loss: (0.1127) |  Loss2: (0.0000) | Acc: (95.00%) (122/128)
Epoch: 153 | Batch_idx: 10 |  Loss: (0.1119) |  Loss2: (0.0000) | Acc: (95.00%) (1351/1408)
Epoch: 153 | Batch_idx: 20 |  Loss: (0.1191) |  Loss2: (0.0000) | Acc: (96.00%) (2586/2688)
Epoch: 153 | Batch_idx: 30 |  Loss: (0.1343) |  Loss2: (0.0000) | Acc: (95.00%) (3799/3968)
Epoch: 153 | Batch_idx: 40 |  Loss: (0.1371) |  Loss2: (0.0000) | Acc: (95.00%) (5008/5248)
Epoch: 153 | Batch_idx: 50 |  Loss: (0.1411) |  Loss2: (0.0000) | Acc: (95.00%) (6219/6528)
Epoch: 153 | Batch_idx: 60 |  Loss: (0.1435) |  Loss2: (0.0000) | Acc: (95.00%) (7434/7808)
Epoch: 153 | Batch_idx: 70 |  Loss: (0.1427) |  Loss2: (0.0000) | Acc: (95.00%) (8653/9088)
Epoch: 153 | Batch_idx: 80 |  Loss: (0.1459) |  Loss2: (0.0000) | Acc: (95.00%) (9860/10368)
Epoch: 153 | Batch_idx: 90 |  Loss: (0.1485) |  Loss2: (0.0000) | Acc: (94.00%) (11062/11648)
Epoch: 153 | Batch_idx: 100 |  Loss: (0.1493) |  Loss2: (0.0000) | Acc: (94.00%) (12268/12928)
Epoch: 153 | Batch_idx: 110 |  Loss: (0.1500) |  Loss2: (0.0000) | Acc: (94.00%) (13478/14208)
Epoch: 153 | Batch_idx: 120 |  Loss: (0.1488) |  Loss2: (0.0000) | Acc: (94.00%) (14700/15488)
Epoch: 153 | Batch_idx: 130 |  Loss: (0.1473) |  Loss2: (0.0000) | Acc: (94.00%) (15924/16768)
Epoch: 153 | Batch_idx: 140 |  Loss: (0.1466) |  Loss2: (0.0000) | Acc: (94.00%) (17138/18048)
Epoch: 153 | Batch_idx: 150 |  Loss: (0.1465) |  Loss2: (0.0000) | Acc: (94.00%) (18357/19328)
Epoch: 153 | Batch_idx: 160 |  Loss: (0.1469) |  Loss2: (0.0000) | Acc: (94.00%) (19570/20608)
Epoch: 153 | Batch_idx: 170 |  Loss: (0.1465) |  Loss2: (0.0000) | Acc: (94.00%) (20788/21888)
Epoch: 153 | Batch_idx: 180 |  Loss: (0.1471) |  Loss2: (0.0000) | Acc: (94.00%) (22003/23168)
Epoch: 153 | Batch_idx: 190 |  Loss: (0.1459) |  Loss2: (0.0000) | Acc: (95.00%) (23227/24448)
Epoch: 153 | Batch_idx: 200 |  Loss: (0.1460) |  Loss2: (0.0000) | Acc: (94.00%) (24441/25728)
Epoch: 153 | Batch_idx: 210 |  Loss: (0.1464) |  Loss2: (0.0000) | Acc: (94.00%) (25650/27008)
Epoch: 153 | Batch_idx: 220 |  Loss: (0.1472) |  Loss2: (0.0000) | Acc: (94.00%) (26841/28288)
Epoch: 153 | Batch_idx: 230 |  Loss: (0.1478) |  Loss2: (0.0000) | Acc: (94.00%) (28049/29568)
Epoch: 153 | Batch_idx: 240 |  Loss: (0.1470) |  Loss2: (0.0000) | Acc: (94.00%) (29271/30848)
Epoch: 153 | Batch_idx: 250 |  Loss: (0.1466) |  Loss2: (0.0000) | Acc: (94.00%) (30484/32128)
Epoch: 153 | Batch_idx: 260 |  Loss: (0.1463) |  Loss2: (0.0000) | Acc: (94.00%) (31697/33408)
Epoch: 153 | Batch_idx: 270 |  Loss: (0.1461) |  Loss2: (0.0000) | Acc: (94.00%) (32913/34688)
Epoch: 153 | Batch_idx: 280 |  Loss: (0.1459) |  Loss2: (0.0000) | Acc: (94.00%) (34128/35968)
Epoch: 153 | Batch_idx: 290 |  Loss: (0.1457) |  Loss2: (0.0000) | Acc: (94.00%) (35342/37248)
Epoch: 153 | Batch_idx: 300 |  Loss: (0.1453) |  Loss2: (0.0000) | Acc: (94.00%) (36563/38528)
Epoch: 153 | Batch_idx: 310 |  Loss: (0.1444) |  Loss2: (0.0000) | Acc: (94.00%) (37790/39808)
Epoch: 153 | Batch_idx: 320 |  Loss: (0.1440) |  Loss2: (0.0000) | Acc: (94.00%) (39011/41088)
Epoch: 153 | Batch_idx: 330 |  Loss: (0.1438) |  Loss2: (0.0000) | Acc: (94.00%) (40224/42368)
Epoch: 153 | Batch_idx: 340 |  Loss: (0.1436) |  Loss2: (0.0000) | Acc: (94.00%) (41449/43648)
Epoch: 153 | Batch_idx: 350 |  Loss: (0.1430) |  Loss2: (0.0000) | Acc: (94.00%) (42679/44928)
Epoch: 153 | Batch_idx: 360 |  Loss: (0.1428) |  Loss2: (0.0000) | Acc: (95.00%) (43898/46208)
Epoch: 153 | Batch_idx: 370 |  Loss: (0.1426) |  Loss2: (0.0000) | Acc: (95.00%) (45115/47488)
Epoch: 153 | Batch_idx: 380 |  Loss: (0.1423) |  Loss2: (0.0000) | Acc: (95.00%) (46338/48768)
Epoch: 153 | Batch_idx: 390 |  Loss: (0.1421) |  Loss2: (0.0000) | Acc: (95.00%) (47508/50000)
# TEST : Loss: (0.3938) | Acc: (88.00%) (8808/10000)
percent tensor([0.5166, 0.5054, 0.5173, 0.5130, 0.5194, 0.5287, 0.5110, 0.5118, 0.5154,
        0.5063, 0.5163, 0.5111, 0.5071, 0.5100, 0.5153, 0.5136],
       device='cuda:0') torch.Size([16])
percent tensor([0.5091, 0.5033, 0.5079, 0.5083, 0.5065, 0.5085, 0.5047, 0.5105, 0.5147,
        0.5054, 0.5127, 0.5021, 0.5038, 0.5164, 0.5040, 0.5097],
       device='cuda:0') torch.Size([16])
percent tensor([0.5735, 0.5596, 0.5616, 0.5809, 0.5791, 0.5736, 0.5804, 0.5809, 0.5728,
        0.5636, 0.5714, 0.5621, 0.5307, 0.6208, 0.5630, 0.5843],
       device='cuda:0') torch.Size([16])
percent tensor([0.6120, 0.6314, 0.6087, 0.6032, 0.5998, 0.6121, 0.6175, 0.5966, 0.6305,
        0.6309, 0.6447, 0.6162, 0.6306, 0.6403, 0.6061, 0.6225],
       device='cuda:0') torch.Size([16])
percent tensor([0.6225, 0.7108, 0.4998, 0.5989, 0.4933, 0.6569, 0.6349, 0.3445, 0.7001,
        0.6829, 0.7396, 0.6074, 0.6922, 0.7324, 0.5594, 0.6438],
       device='cuda:0') torch.Size([16])
percent tensor([0.6041, 0.5887, 0.6269, 0.6091, 0.6698, 0.6223, 0.6152, 0.6427, 0.6154,
        0.5837, 0.5679, 0.5554, 0.5556, 0.5728, 0.5842, 0.6105],
       device='cuda:0') torch.Size([16])
percent tensor([0.5311, 0.5613, 0.7166, 0.6235, 0.7542, 0.7322, 0.6123, 0.6443, 0.6732,
        0.5367, 0.6500, 0.5745, 0.5995, 0.5580, 0.5305, 0.4943],
       device='cuda:0') torch.Size([16])
percent tensor([0.9996, 0.9996, 0.9998, 0.9997, 0.9996, 0.9995, 0.9993, 0.9998, 0.9997,
        0.9997, 0.9999, 0.9997, 0.9998, 0.9989, 0.9993, 0.9994],
       device='cuda:0') torch.Size([16])
Epoch: 154 | Batch_idx: 0 |  Loss: (0.0878) |  Loss2: (0.0000) | Acc: (96.00%) (124/128)
Epoch: 154 | Batch_idx: 10 |  Loss: (0.1392) |  Loss2: (0.0000) | Acc: (95.00%) (1338/1408)
Epoch: 154 | Batch_idx: 20 |  Loss: (0.1435) |  Loss2: (0.0000) | Acc: (95.00%) (2559/2688)
Epoch: 154 | Batch_idx: 30 |  Loss: (0.1361) |  Loss2: (0.0000) | Acc: (95.00%) (3784/3968)
Epoch: 154 | Batch_idx: 40 |  Loss: (0.1376) |  Loss2: (0.0000) | Acc: (95.00%) (5008/5248)
Epoch: 154 | Batch_idx: 50 |  Loss: (0.1356) |  Loss2: (0.0000) | Acc: (95.00%) (6231/6528)
Epoch: 154 | Batch_idx: 60 |  Loss: (0.1318) |  Loss2: (0.0000) | Acc: (95.00%) (7461/7808)
Epoch: 154 | Batch_idx: 70 |  Loss: (0.1318) |  Loss2: (0.0000) | Acc: (95.00%) (8686/9088)
Epoch: 154 | Batch_idx: 80 |  Loss: (0.1332) |  Loss2: (0.0000) | Acc: (95.00%) (9901/10368)
Epoch: 154 | Batch_idx: 90 |  Loss: (0.1334) |  Loss2: (0.0000) | Acc: (95.00%) (11121/11648)
Epoch: 154 | Batch_idx: 100 |  Loss: (0.1307) |  Loss2: (0.0000) | Acc: (95.00%) (12360/12928)
Epoch: 154 | Batch_idx: 110 |  Loss: (0.1306) |  Loss2: (0.0000) | Acc: (95.00%) (13578/14208)
Epoch: 154 | Batch_idx: 120 |  Loss: (0.1321) |  Loss2: (0.0000) | Acc: (95.00%) (14789/15488)
Epoch: 154 | Batch_idx: 130 |  Loss: (0.1318) |  Loss2: (0.0000) | Acc: (95.00%) (16011/16768)
Epoch: 154 | Batch_idx: 140 |  Loss: (0.1314) |  Loss2: (0.0000) | Acc: (95.00%) (17226/18048)
Epoch: 154 | Batch_idx: 150 |  Loss: (0.1323) |  Loss2: (0.0000) | Acc: (95.00%) (18441/19328)
Epoch: 154 | Batch_idx: 160 |  Loss: (0.1316) |  Loss2: (0.0000) | Acc: (95.00%) (19666/20608)
Epoch: 154 | Batch_idx: 170 |  Loss: (0.1313) |  Loss2: (0.0000) | Acc: (95.00%) (20904/21888)
Epoch: 154 | Batch_idx: 180 |  Loss: (0.1304) |  Loss2: (0.0000) | Acc: (95.00%) (22133/23168)
Epoch: 154 | Batch_idx: 190 |  Loss: (0.1295) |  Loss2: (0.0000) | Acc: (95.00%) (23360/24448)
Epoch: 154 | Batch_idx: 200 |  Loss: (0.1294) |  Loss2: (0.0000) | Acc: (95.00%) (24586/25728)
Epoch: 154 | Batch_idx: 210 |  Loss: (0.1284) |  Loss2: (0.0000) | Acc: (95.00%) (25814/27008)
Epoch: 154 | Batch_idx: 220 |  Loss: (0.1286) |  Loss2: (0.0000) | Acc: (95.00%) (27027/28288)
Epoch: 154 | Batch_idx: 230 |  Loss: (0.1289) |  Loss2: (0.0000) | Acc: (95.00%) (28251/29568)
Epoch: 154 | Batch_idx: 240 |  Loss: (0.1285) |  Loss2: (0.0000) | Acc: (95.00%) (29473/30848)
Epoch: 154 | Batch_idx: 250 |  Loss: (0.1285) |  Loss2: (0.0000) | Acc: (95.00%) (30700/32128)
Epoch: 154 | Batch_idx: 260 |  Loss: (0.1289) |  Loss2: (0.0000) | Acc: (95.00%) (31922/33408)
Epoch: 154 | Batch_idx: 270 |  Loss: (0.1283) |  Loss2: (0.0000) | Acc: (95.00%) (33149/34688)
Epoch: 154 | Batch_idx: 280 |  Loss: (0.1279) |  Loss2: (0.0000) | Acc: (95.00%) (34382/35968)
Epoch: 154 | Batch_idx: 290 |  Loss: (0.1280) |  Loss2: (0.0000) | Acc: (95.00%) (35605/37248)
Epoch: 154 | Batch_idx: 300 |  Loss: (0.1281) |  Loss2: (0.0000) | Acc: (95.00%) (36819/38528)
Epoch: 154 | Batch_idx: 310 |  Loss: (0.1279) |  Loss2: (0.0000) | Acc: (95.00%) (38040/39808)
Epoch: 154 | Batch_idx: 320 |  Loss: (0.1275) |  Loss2: (0.0000) | Acc: (95.00%) (39267/41088)
Epoch: 154 | Batch_idx: 330 |  Loss: (0.1281) |  Loss2: (0.0000) | Acc: (95.00%) (40480/42368)
Epoch: 154 | Batch_idx: 340 |  Loss: (0.1278) |  Loss2: (0.0000) | Acc: (95.00%) (41706/43648)
Epoch: 154 | Batch_idx: 350 |  Loss: (0.1274) |  Loss2: (0.0000) | Acc: (95.00%) (42937/44928)
Epoch: 154 | Batch_idx: 360 |  Loss: (0.1273) |  Loss2: (0.0000) | Acc: (95.00%) (44161/46208)
Epoch: 154 | Batch_idx: 370 |  Loss: (0.1273) |  Loss2: (0.0000) | Acc: (95.00%) (45385/47488)
Epoch: 154 | Batch_idx: 380 |  Loss: (0.1267) |  Loss2: (0.0000) | Acc: (95.00%) (46614/48768)
Epoch: 154 | Batch_idx: 390 |  Loss: (0.1268) |  Loss2: (0.0000) | Acc: (95.00%) (47791/50000)
# TEST : Loss: (0.3820) | Acc: (88.00%) (8842/10000)
percent tensor([0.5163, 0.5057, 0.5167, 0.5125, 0.5190, 0.5278, 0.5110, 0.5116, 0.5154,
        0.5064, 0.5162, 0.5108, 0.5072, 0.5102, 0.5151, 0.5133],
       device='cuda:0') torch.Size([16])
percent tensor([0.5094, 0.5037, 0.5080, 0.5085, 0.5067, 0.5089, 0.5050, 0.5106, 0.5145,
        0.5056, 0.5127, 0.5023, 0.5040, 0.5162, 0.5045, 0.5101],
       device='cuda:0') torch.Size([16])
percent tensor([0.5822, 0.5676, 0.5674, 0.5868, 0.5862, 0.5832, 0.5893, 0.5858, 0.5786,
        0.5706, 0.5787, 0.5679, 0.5365, 0.6300, 0.5731, 0.5924],
       device='cuda:0') torch.Size([16])
percent tensor([0.6135, 0.6323, 0.6102, 0.6040, 0.6008, 0.6138, 0.6183, 0.5971, 0.6318,
        0.6318, 0.6458, 0.6169, 0.6318, 0.6411, 0.6068, 0.6243],
       device='cuda:0') torch.Size([16])
percent tensor([0.6184, 0.7033, 0.5072, 0.6078, 0.5004, 0.6652, 0.6255, 0.3436, 0.7032,
        0.6743, 0.7407, 0.6064, 0.6899, 0.7280, 0.5501, 0.6409],
       device='cuda:0') torch.Size([16])
percent tensor([0.5962, 0.5797, 0.6231, 0.6031, 0.6663, 0.6157, 0.6077, 0.6387, 0.6061,
        0.5757, 0.5581, 0.5482, 0.5440, 0.5645, 0.5774, 0.6034],
       device='cuda:0') torch.Size([16])
percent tensor([0.5363, 0.5639, 0.7184, 0.6326, 0.7533, 0.7312, 0.6148, 0.6510, 0.6649,
        0.5397, 0.6468, 0.5807, 0.5993, 0.5600, 0.5373, 0.4999],
       device='cuda:0') torch.Size([16])
percent tensor([0.9997, 0.9996, 0.9998, 0.9997, 0.9996, 0.9995, 0.9994, 0.9998, 0.9997,
        0.9997, 0.9999, 0.9997, 0.9998, 0.9990, 0.9993, 0.9994],
       device='cuda:0') torch.Size([16])
Epoch: 155 | Batch_idx: 0 |  Loss: (0.1564) |  Loss2: (0.0000) | Acc: (92.00%) (119/128)
Epoch: 155 | Batch_idx: 10 |  Loss: (0.1179) |  Loss2: (0.0000) | Acc: (95.00%) (1348/1408)
Epoch: 155 | Batch_idx: 20 |  Loss: (0.1127) |  Loss2: (0.0000) | Acc: (95.00%) (2580/2688)
Epoch: 155 | Batch_idx: 30 |  Loss: (0.1167) |  Loss2: (0.0000) | Acc: (95.00%) (3803/3968)
Epoch: 155 | Batch_idx: 40 |  Loss: (0.1173) |  Loss2: (0.0000) | Acc: (95.00%) (5029/5248)
Epoch: 155 | Batch_idx: 50 |  Loss: (0.1151) |  Loss2: (0.0000) | Acc: (96.00%) (6269/6528)
Epoch: 155 | Batch_idx: 60 |  Loss: (0.1154) |  Loss2: (0.0000) | Acc: (96.00%) (7498/7808)
Epoch: 155 | Batch_idx: 70 |  Loss: (0.1185) |  Loss2: (0.0000) | Acc: (95.00%) (8718/9088)
Epoch: 155 | Batch_idx: 80 |  Loss: (0.1183) |  Loss2: (0.0000) | Acc: (95.00%) (9949/10368)
Epoch: 155 | Batch_idx: 90 |  Loss: (0.1184) |  Loss2: (0.0000) | Acc: (95.00%) (11180/11648)
Epoch: 155 | Batch_idx: 100 |  Loss: (0.1178) |  Loss2: (0.0000) | Acc: (96.00%) (12411/12928)
Epoch: 155 | Batch_idx: 110 |  Loss: (0.1169) |  Loss2: (0.0000) | Acc: (96.00%) (13647/14208)
Epoch: 155 | Batch_idx: 120 |  Loss: (0.1173) |  Loss2: (0.0000) | Acc: (96.00%) (14869/15488)
Epoch: 155 | Batch_idx: 130 |  Loss: (0.1172) |  Loss2: (0.0000) | Acc: (95.00%) (16096/16768)
Epoch: 155 | Batch_idx: 140 |  Loss: (0.1178) |  Loss2: (0.0000) | Acc: (95.00%) (17315/18048)
Epoch: 155 | Batch_idx: 150 |  Loss: (0.1184) |  Loss2: (0.0000) | Acc: (95.00%) (18538/19328)
Epoch: 155 | Batch_idx: 160 |  Loss: (0.1181) |  Loss2: (0.0000) | Acc: (95.00%) (19769/20608)
Epoch: 155 | Batch_idx: 170 |  Loss: (0.1200) |  Loss2: (0.0000) | Acc: (95.00%) (20984/21888)
Epoch: 155 | Batch_idx: 180 |  Loss: (0.1195) |  Loss2: (0.0000) | Acc: (95.00%) (22210/23168)
Epoch: 155 | Batch_idx: 190 |  Loss: (0.1205) |  Loss2: (0.0000) | Acc: (95.00%) (23430/24448)
Epoch: 155 | Batch_idx: 200 |  Loss: (0.1199) |  Loss2: (0.0000) | Acc: (95.00%) (24665/25728)
Epoch: 155 | Batch_idx: 210 |  Loss: (0.1196) |  Loss2: (0.0000) | Acc: (95.00%) (25900/27008)
Epoch: 155 | Batch_idx: 220 |  Loss: (0.1192) |  Loss2: (0.0000) | Acc: (95.00%) (27128/28288)
Epoch: 155 | Batch_idx: 230 |  Loss: (0.1194) |  Loss2: (0.0000) | Acc: (95.00%) (28349/29568)
Epoch: 155 | Batch_idx: 240 |  Loss: (0.1192) |  Loss2: (0.0000) | Acc: (95.00%) (29573/30848)
Epoch: 155 | Batch_idx: 250 |  Loss: (0.1196) |  Loss2: (0.0000) | Acc: (95.00%) (30796/32128)
Epoch: 155 | Batch_idx: 260 |  Loss: (0.1191) |  Loss2: (0.0000) | Acc: (95.00%) (32028/33408)
Epoch: 155 | Batch_idx: 270 |  Loss: (0.1183) |  Loss2: (0.0000) | Acc: (95.00%) (33270/34688)
Epoch: 155 | Batch_idx: 280 |  Loss: (0.1186) |  Loss2: (0.0000) | Acc: (95.00%) (34487/35968)
Epoch: 155 | Batch_idx: 290 |  Loss: (0.1186) |  Loss2: (0.0000) | Acc: (95.00%) (35716/37248)
Epoch: 155 | Batch_idx: 300 |  Loss: (0.1185) |  Loss2: (0.0000) | Acc: (95.00%) (36947/38528)
Epoch: 155 | Batch_idx: 310 |  Loss: (0.1184) |  Loss2: (0.0000) | Acc: (95.00%) (38176/39808)
Epoch: 155 | Batch_idx: 320 |  Loss: (0.1182) |  Loss2: (0.0000) | Acc: (95.00%) (39413/41088)
Epoch: 155 | Batch_idx: 330 |  Loss: (0.1180) |  Loss2: (0.0000) | Acc: (95.00%) (40649/42368)
Epoch: 155 | Batch_idx: 340 |  Loss: (0.1183) |  Loss2: (0.0000) | Acc: (95.00%) (41871/43648)
Epoch: 155 | Batch_idx: 350 |  Loss: (0.1184) |  Loss2: (0.0000) | Acc: (95.00%) (43092/44928)
Epoch: 155 | Batch_idx: 360 |  Loss: (0.1187) |  Loss2: (0.0000) | Acc: (95.00%) (44311/46208)
Epoch: 155 | Batch_idx: 370 |  Loss: (0.1190) |  Loss2: (0.0000) | Acc: (95.00%) (45532/47488)
Epoch: 155 | Batch_idx: 380 |  Loss: (0.1186) |  Loss2: (0.0000) | Acc: (95.00%) (46765/48768)
Epoch: 155 | Batch_idx: 390 |  Loss: (0.1187) |  Loss2: (0.0000) | Acc: (95.00%) (47947/50000)
=> saving checkpoint 'drive/app/torch/save_Schedule/checkpoint_155.pth.tar'
# TEST : Loss: (0.3812) | Acc: (88.00%) (8857/10000)
percent tensor([0.5169, 0.5067, 0.5178, 0.5133, 0.5202, 0.5281, 0.5122, 0.5127, 0.5164,
        0.5074, 0.5169, 0.5120, 0.5081, 0.5109, 0.5159, 0.5139],
       device='cuda:0') torch.Size([16])
percent tensor([0.5089, 0.5031, 0.5077, 0.5079, 0.5064, 0.5084, 0.5045, 0.5100, 0.5138,
        0.5051, 0.5119, 0.5020, 0.5035, 0.5154, 0.5039, 0.5094],
       device='cuda:0') torch.Size([16])
percent tensor([0.5670, 0.5535, 0.5538, 0.5716, 0.5723, 0.5689, 0.5762, 0.5715, 0.5635,
        0.5558, 0.5626, 0.5537, 0.5229, 0.6162, 0.5586, 0.5772],
       device='cuda:0') torch.Size([16])
percent tensor([0.6132, 0.6318, 0.6108, 0.6038, 0.6016, 0.6145, 0.6179, 0.5973, 0.6311,
        0.6317, 0.6448, 0.6169, 0.6316, 0.6406, 0.6066, 0.6244],
       device='cuda:0') torch.Size([16])
percent tensor([0.6079, 0.6968, 0.5044, 0.6007, 0.5002, 0.6536, 0.6173, 0.3480, 0.6975,
        0.6648, 0.7342, 0.6023, 0.6846, 0.7201, 0.5442, 0.6293],
       device='cuda:0') torch.Size([16])
percent tensor([0.6061, 0.5901, 0.6296, 0.6098, 0.6740, 0.6224, 0.6177, 0.6463, 0.6153,
        0.5869, 0.5677, 0.5565, 0.5546, 0.5741, 0.5859, 0.6123],
       device='cuda:0') torch.Size([16])
percent tensor([0.5546, 0.5752, 0.7239, 0.6430, 0.7520, 0.7442, 0.6239, 0.6535, 0.6793,
        0.5488, 0.6621, 0.5930, 0.6195, 0.5761, 0.5454, 0.5103],
       device='cuda:0') torch.Size([16])
percent tensor([0.9996, 0.9996, 0.9998, 0.9997, 0.9996, 0.9995, 0.9994, 0.9998, 0.9997,
        0.9997, 0.9999, 0.9997, 0.9998, 0.9990, 0.9994, 0.9994],
       device='cuda:0') torch.Size([16])
Epoch: 156 | Batch_idx: 0 |  Loss: (0.0785) |  Loss2: (0.0000) | Acc: (98.00%) (126/128)
Epoch: 156 | Batch_idx: 10 |  Loss: (0.1431) |  Loss2: (0.0000) | Acc: (95.00%) (1338/1408)
Epoch: 156 | Batch_idx: 20 |  Loss: (0.1330) |  Loss2: (0.0000) | Acc: (95.00%) (2570/2688)
Epoch: 156 | Batch_idx: 30 |  Loss: (0.1309) |  Loss2: (0.0000) | Acc: (95.00%) (3796/3968)
Epoch: 156 | Batch_idx: 40 |  Loss: (0.1247) |  Loss2: (0.0000) | Acc: (95.00%) (5028/5248)
Epoch: 156 | Batch_idx: 50 |  Loss: (0.1324) |  Loss2: (0.0000) | Acc: (95.00%) (6232/6528)
Epoch: 156 | Batch_idx: 60 |  Loss: (0.1281) |  Loss2: (0.0000) | Acc: (95.00%) (7466/7808)
Epoch: 156 | Batch_idx: 70 |  Loss: (0.1259) |  Loss2: (0.0000) | Acc: (95.00%) (8697/9088)
Epoch: 156 | Batch_idx: 80 |  Loss: (0.1240) |  Loss2: (0.0000) | Acc: (95.00%) (9929/10368)
Epoch: 156 | Batch_idx: 90 |  Loss: (0.1254) |  Loss2: (0.0000) | Acc: (95.00%) (11157/11648)
Epoch: 156 | Batch_idx: 100 |  Loss: (0.1237) |  Loss2: (0.0000) | Acc: (95.00%) (12393/12928)
Epoch: 156 | Batch_idx: 110 |  Loss: (0.1228) |  Loss2: (0.0000) | Acc: (95.00%) (13631/14208)
Epoch: 156 | Batch_idx: 120 |  Loss: (0.1214) |  Loss2: (0.0000) | Acc: (95.00%) (14866/15488)
Epoch: 156 | Batch_idx: 130 |  Loss: (0.1216) |  Loss2: (0.0000) | Acc: (95.00%) (16088/16768)
Epoch: 156 | Batch_idx: 140 |  Loss: (0.1210) |  Loss2: (0.0000) | Acc: (95.00%) (17320/18048)
Epoch: 156 | Batch_idx: 150 |  Loss: (0.1215) |  Loss2: (0.0000) | Acc: (95.00%) (18546/19328)
Epoch: 156 | Batch_idx: 160 |  Loss: (0.1206) |  Loss2: (0.0000) | Acc: (95.00%) (19776/20608)
Epoch: 156 | Batch_idx: 170 |  Loss: (0.1201) |  Loss2: (0.0000) | Acc: (95.00%) (21010/21888)
Epoch: 156 | Batch_idx: 180 |  Loss: (0.1191) |  Loss2: (0.0000) | Acc: (96.00%) (22249/23168)
Epoch: 156 | Batch_idx: 190 |  Loss: (0.1190) |  Loss2: (0.0000) | Acc: (96.00%) (23474/24448)
Epoch: 156 | Batch_idx: 200 |  Loss: (0.1184) |  Loss2: (0.0000) | Acc: (96.00%) (24710/25728)
Epoch: 156 | Batch_idx: 210 |  Loss: (0.1183) |  Loss2: (0.0000) | Acc: (96.00%) (25941/27008)
Epoch: 156 | Batch_idx: 220 |  Loss: (0.1183) |  Loss2: (0.0000) | Acc: (96.00%) (27170/28288)
Epoch: 156 | Batch_idx: 230 |  Loss: (0.1180) |  Loss2: (0.0000) | Acc: (96.00%) (28403/29568)
Epoch: 156 | Batch_idx: 240 |  Loss: (0.1170) |  Loss2: (0.0000) | Acc: (96.00%) (29646/30848)
Epoch: 156 | Batch_idx: 250 |  Loss: (0.1171) |  Loss2: (0.0000) | Acc: (96.00%) (30874/32128)
Epoch: 156 | Batch_idx: 260 |  Loss: (0.1168) |  Loss2: (0.0000) | Acc: (96.00%) (32103/33408)
Epoch: 156 | Batch_idx: 270 |  Loss: (0.1164) |  Loss2: (0.0000) | Acc: (96.00%) (33343/34688)
Epoch: 156 | Batch_idx: 280 |  Loss: (0.1161) |  Loss2: (0.0000) | Acc: (96.00%) (34573/35968)
Epoch: 156 | Batch_idx: 290 |  Loss: (0.1156) |  Loss2: (0.0000) | Acc: (96.00%) (35815/37248)
Epoch: 156 | Batch_idx: 300 |  Loss: (0.1157) |  Loss2: (0.0000) | Acc: (96.00%) (37041/38528)
Epoch: 156 | Batch_idx: 310 |  Loss: (0.1153) |  Loss2: (0.0000) | Acc: (96.00%) (38273/39808)
Epoch: 156 | Batch_idx: 320 |  Loss: (0.1160) |  Loss2: (0.0000) | Acc: (96.00%) (39490/41088)
Epoch: 156 | Batch_idx: 330 |  Loss: (0.1162) |  Loss2: (0.0000) | Acc: (96.00%) (40720/42368)
Epoch: 156 | Batch_idx: 340 |  Loss: (0.1163) |  Loss2: (0.0000) | Acc: (96.00%) (41937/43648)
Epoch: 156 | Batch_idx: 350 |  Loss: (0.1167) |  Loss2: (0.0000) | Acc: (96.00%) (43156/44928)
Epoch: 156 | Batch_idx: 360 |  Loss: (0.1170) |  Loss2: (0.0000) | Acc: (96.00%) (44378/46208)
Epoch: 156 | Batch_idx: 370 |  Loss: (0.1167) |  Loss2: (0.0000) | Acc: (96.00%) (45616/47488)
Epoch: 156 | Batch_idx: 380 |  Loss: (0.1170) |  Loss2: (0.0000) | Acc: (96.00%) (46836/48768)
Epoch: 156 | Batch_idx: 390 |  Loss: (0.1170) |  Loss2: (0.0000) | Acc: (96.00%) (48013/50000)
# TEST : Loss: (0.3761) | Acc: (88.00%) (8871/10000)
percent tensor([0.5157, 0.5057, 0.5166, 0.5121, 0.5190, 0.5269, 0.5110, 0.5117, 0.5153,
        0.5064, 0.5158, 0.5110, 0.5071, 0.5098, 0.5148, 0.5127],
       device='cuda:0') torch.Size([16])
percent tensor([0.5092, 0.5031, 0.5084, 0.5084, 0.5070, 0.5089, 0.5047, 0.5105, 0.5140,
        0.5052, 0.5119, 0.5024, 0.5036, 0.5155, 0.5042, 0.5097],
       device='cuda:0') torch.Size([16])
percent tensor([0.5660, 0.5513, 0.5541, 0.5715, 0.5736, 0.5695, 0.5762, 0.5726, 0.5628,
        0.5533, 0.5605, 0.5528, 0.5202, 0.6159, 0.5588, 0.5760],
       device='cuda:0') torch.Size([16])
percent tensor([0.6128, 0.6305, 0.6104, 0.6035, 0.6008, 0.6143, 0.6168, 0.5966, 0.6303,
        0.6306, 0.6436, 0.6160, 0.6308, 0.6398, 0.6058, 0.6239],
       device='cuda:0') torch.Size([16])
percent tensor([0.6106, 0.6955, 0.5075, 0.5998, 0.5036, 0.6533, 0.6199, 0.3511, 0.6989,
        0.6658, 0.7349, 0.6028, 0.6853, 0.7187, 0.5466, 0.6281],
       device='cuda:0') torch.Size([16])
percent tensor([0.6059, 0.5908, 0.6300, 0.6095, 0.6746, 0.6221, 0.6180, 0.6471, 0.6151,
        0.5879, 0.5677, 0.5578, 0.5555, 0.5736, 0.5867, 0.6131],
       device='cuda:0') torch.Size([16])
percent tensor([0.5643, 0.5860, 0.7307, 0.6515, 0.7556, 0.7505, 0.6314, 0.6617, 0.6851,
        0.5603, 0.6713, 0.6042, 0.6325, 0.5855, 0.5521, 0.5186],
       device='cuda:0') torch.Size([16])
percent tensor([0.9997, 0.9996, 0.9998, 0.9997, 0.9996, 0.9995, 0.9994, 0.9998, 0.9998,
        0.9997, 0.9999, 0.9997, 0.9998, 0.9991, 0.9994, 0.9994],
       device='cuda:0') torch.Size([16])
Epoch: 157 | Batch_idx: 0 |  Loss: (0.1078) |  Loss2: (0.0000) | Acc: (95.00%) (122/128)
Epoch: 157 | Batch_idx: 10 |  Loss: (0.1118) |  Loss2: (0.0000) | Acc: (96.00%) (1355/1408)
Epoch: 157 | Batch_idx: 20 |  Loss: (0.1093) |  Loss2: (0.0000) | Acc: (96.00%) (2588/2688)
Epoch: 157 | Batch_idx: 30 |  Loss: (0.1095) |  Loss2: (0.0000) | Acc: (96.00%) (3826/3968)
Epoch: 157 | Batch_idx: 40 |  Loss: (0.1123) |  Loss2: (0.0000) | Acc: (96.00%) (5053/5248)
Epoch: 157 | Batch_idx: 50 |  Loss: (0.1109) |  Loss2: (0.0000) | Acc: (96.00%) (6291/6528)
Epoch: 157 | Batch_idx: 60 |  Loss: (0.1087) |  Loss2: (0.0000) | Acc: (96.00%) (7533/7808)
Epoch: 157 | Batch_idx: 70 |  Loss: (0.1112) |  Loss2: (0.0000) | Acc: (96.00%) (8754/9088)
Epoch: 157 | Batch_idx: 80 |  Loss: (0.1101) |  Loss2: (0.0000) | Acc: (96.00%) (9988/10368)
Epoch: 157 | Batch_idx: 90 |  Loss: (0.1118) |  Loss2: (0.0000) | Acc: (96.00%) (11212/11648)
Epoch: 157 | Batch_idx: 100 |  Loss: (0.1113) |  Loss2: (0.0000) | Acc: (96.00%) (12442/12928)
Epoch: 157 | Batch_idx: 110 |  Loss: (0.1108) |  Loss2: (0.0000) | Acc: (96.00%) (13672/14208)
Epoch: 157 | Batch_idx: 120 |  Loss: (0.1099) |  Loss2: (0.0000) | Acc: (96.00%) (14912/15488)
Epoch: 157 | Batch_idx: 130 |  Loss: (0.1111) |  Loss2: (0.0000) | Acc: (96.00%) (16139/16768)
Epoch: 157 | Batch_idx: 140 |  Loss: (0.1120) |  Loss2: (0.0000) | Acc: (96.00%) (17372/18048)
Epoch: 157 | Batch_idx: 150 |  Loss: (0.1122) |  Loss2: (0.0000) | Acc: (96.00%) (18610/19328)
Epoch: 157 | Batch_idx: 160 |  Loss: (0.1123) |  Loss2: (0.0000) | Acc: (96.00%) (19830/20608)
Epoch: 157 | Batch_idx: 170 |  Loss: (0.1126) |  Loss2: (0.0000) | Acc: (96.00%) (21060/21888)
Epoch: 157 | Batch_idx: 180 |  Loss: (0.1131) |  Loss2: (0.0000) | Acc: (96.00%) (22288/23168)
Epoch: 157 | Batch_idx: 190 |  Loss: (0.1128) |  Loss2: (0.0000) | Acc: (96.00%) (23530/24448)
Epoch: 157 | Batch_idx: 200 |  Loss: (0.1118) |  Loss2: (0.0000) | Acc: (96.00%) (24766/25728)
Epoch: 157 | Batch_idx: 210 |  Loss: (0.1122) |  Loss2: (0.0000) | Acc: (96.00%) (25998/27008)
Epoch: 157 | Batch_idx: 220 |  Loss: (0.1123) |  Loss2: (0.0000) | Acc: (96.00%) (27226/28288)
Epoch: 157 | Batch_idx: 230 |  Loss: (0.1123) |  Loss2: (0.0000) | Acc: (96.00%) (28460/29568)
Epoch: 157 | Batch_idx: 240 |  Loss: (0.1119) |  Loss2: (0.0000) | Acc: (96.00%) (29701/30848)
Epoch: 157 | Batch_idx: 250 |  Loss: (0.1121) |  Loss2: (0.0000) | Acc: (96.00%) (30925/32128)
Epoch: 157 | Batch_idx: 260 |  Loss: (0.1117) |  Loss2: (0.0000) | Acc: (96.00%) (32164/33408)
Epoch: 157 | Batch_idx: 270 |  Loss: (0.1117) |  Loss2: (0.0000) | Acc: (96.00%) (33396/34688)
Epoch: 157 | Batch_idx: 280 |  Loss: (0.1121) |  Loss2: (0.0000) | Acc: (96.00%) (34616/35968)
Epoch: 157 | Batch_idx: 290 |  Loss: (0.1127) |  Loss2: (0.0000) | Acc: (96.00%) (35837/37248)
Epoch: 157 | Batch_idx: 300 |  Loss: (0.1131) |  Loss2: (0.0000) | Acc: (96.00%) (37060/38528)
Epoch: 157 | Batch_idx: 310 |  Loss: (0.1131) |  Loss2: (0.0000) | Acc: (96.00%) (38292/39808)
Epoch: 157 | Batch_idx: 320 |  Loss: (0.1135) |  Loss2: (0.0000) | Acc: (96.00%) (39512/41088)
Epoch: 157 | Batch_idx: 330 |  Loss: (0.1134) |  Loss2: (0.0000) | Acc: (96.00%) (40742/42368)
Epoch: 157 | Batch_idx: 340 |  Loss: (0.1135) |  Loss2: (0.0000) | Acc: (96.00%) (41967/43648)
Epoch: 157 | Batch_idx: 350 |  Loss: (0.1135) |  Loss2: (0.0000) | Acc: (96.00%) (43199/44928)
Epoch: 157 | Batch_idx: 360 |  Loss: (0.1130) |  Loss2: (0.0000) | Acc: (96.00%) (44439/46208)
Epoch: 157 | Batch_idx: 370 |  Loss: (0.1132) |  Loss2: (0.0000) | Acc: (96.00%) (45664/47488)
Epoch: 157 | Batch_idx: 380 |  Loss: (0.1132) |  Loss2: (0.0000) | Acc: (96.00%) (46893/48768)
Epoch: 157 | Batch_idx: 390 |  Loss: (0.1129) |  Loss2: (0.0000) | Acc: (96.00%) (48085/50000)
# TEST : Loss: (0.3730) | Acc: (88.00%) (8881/10000)
percent tensor([0.5152, 0.5055, 0.5162, 0.5116, 0.5186, 0.5262, 0.5108, 0.5114, 0.5152,
        0.5062, 0.5154, 0.5107, 0.5069, 0.5095, 0.5142, 0.5121],
       device='cuda:0') torch.Size([16])
percent tensor([0.5091, 0.5030, 0.5082, 0.5083, 0.5069, 0.5089, 0.5046, 0.5103, 0.5137,
        0.5050, 0.5116, 0.5023, 0.5035, 0.5151, 0.5041, 0.5095],
       device='cuda:0') torch.Size([16])
percent tensor([0.5671, 0.5521, 0.5531, 0.5709, 0.5739, 0.5696, 0.5779, 0.5727, 0.5639,
        0.5536, 0.5614, 0.5520, 0.5209, 0.6179, 0.5602, 0.5766],
       device='cuda:0') torch.Size([16])
percent tensor([0.6101, 0.6282, 0.6086, 0.6013, 0.5987, 0.6118, 0.6145, 0.5943, 0.6279,
        0.6283, 0.6408, 0.6140, 0.6282, 0.6376, 0.6032, 0.6213],
       device='cuda:0') torch.Size([16])
percent tensor([0.6111, 0.6941, 0.5140, 0.6054, 0.5104, 0.6568, 0.6205, 0.3585, 0.7041,
        0.6665, 0.7354, 0.6070, 0.6855, 0.7242, 0.5494, 0.6289],
       device='cuda:0') torch.Size([16])
percent tensor([0.6156, 0.6027, 0.6382, 0.6162, 0.6826, 0.6297, 0.6287, 0.6550, 0.6231,
        0.5997, 0.5773, 0.5654, 0.5657, 0.5826, 0.5955, 0.6240],
       device='cuda:0') torch.Size([16])
percent tensor([0.5600, 0.5787, 0.7288, 0.6531, 0.7545, 0.7468, 0.6258, 0.6603, 0.6756,
        0.5507, 0.6645, 0.5988, 0.6228, 0.5750, 0.5480, 0.5181],
       device='cuda:0') torch.Size([16])
percent tensor([0.9997, 0.9996, 0.9998, 0.9997, 0.9996, 0.9994, 0.9994, 0.9998, 0.9998,
        0.9997, 0.9999, 0.9997, 0.9998, 0.9990, 0.9994, 0.9994],
       device='cuda:0') torch.Size([16])
Epoch: 158 | Batch_idx: 0 |  Loss: (0.0776) |  Loss2: (0.0000) | Acc: (97.00%) (125/128)
Epoch: 158 | Batch_idx: 10 |  Loss: (0.0970) |  Loss2: (0.0000) | Acc: (96.00%) (1361/1408)
Epoch: 158 | Batch_idx: 20 |  Loss: (0.0995) |  Loss2: (0.0000) | Acc: (96.00%) (2606/2688)
Epoch: 158 | Batch_idx: 30 |  Loss: (0.1012) |  Loss2: (0.0000) | Acc: (96.00%) (3838/3968)
Epoch: 158 | Batch_idx: 40 |  Loss: (0.1053) |  Loss2: (0.0000) | Acc: (96.00%) (5069/5248)
Epoch: 158 | Batch_idx: 50 |  Loss: (0.1068) |  Loss2: (0.0000) | Acc: (96.00%) (6306/6528)
Epoch: 158 | Batch_idx: 60 |  Loss: (0.1058) |  Loss2: (0.0000) | Acc: (96.00%) (7544/7808)
Epoch: 158 | Batch_idx: 70 |  Loss: (0.1080) |  Loss2: (0.0000) | Acc: (96.00%) (8778/9088)
Epoch: 158 | Batch_idx: 80 |  Loss: (0.1088) |  Loss2: (0.0000) | Acc: (96.00%) (10011/10368)
Epoch: 158 | Batch_idx: 90 |  Loss: (0.1084) |  Loss2: (0.0000) | Acc: (96.00%) (11244/11648)
Epoch: 158 | Batch_idx: 100 |  Loss: (0.1100) |  Loss2: (0.0000) | Acc: (96.00%) (12474/12928)
Epoch: 158 | Batch_idx: 110 |  Loss: (0.1097) |  Loss2: (0.0000) | Acc: (96.00%) (13716/14208)
Epoch: 158 | Batch_idx: 120 |  Loss: (0.1097) |  Loss2: (0.0000) | Acc: (96.00%) (14946/15488)
Epoch: 158 | Batch_idx: 130 |  Loss: (0.1108) |  Loss2: (0.0000) | Acc: (96.00%) (16168/16768)
Epoch: 158 | Batch_idx: 140 |  Loss: (0.1099) |  Loss2: (0.0000) | Acc: (96.00%) (17405/18048)
Epoch: 158 | Batch_idx: 150 |  Loss: (0.1103) |  Loss2: (0.0000) | Acc: (96.00%) (18634/19328)
Epoch: 158 | Batch_idx: 160 |  Loss: (0.1104) |  Loss2: (0.0000) | Acc: (96.00%) (19865/20608)
Epoch: 158 | Batch_idx: 170 |  Loss: (0.1102) |  Loss2: (0.0000) | Acc: (96.00%) (21104/21888)
Epoch: 158 | Batch_idx: 180 |  Loss: (0.1098) |  Loss2: (0.0000) | Acc: (96.00%) (22344/23168)
Epoch: 158 | Batch_idx: 190 |  Loss: (0.1109) |  Loss2: (0.0000) | Acc: (96.00%) (23576/24448)
Epoch: 158 | Batch_idx: 200 |  Loss: (0.1109) |  Loss2: (0.0000) | Acc: (96.00%) (24816/25728)
Epoch: 158 | Batch_idx: 210 |  Loss: (0.1103) |  Loss2: (0.0000) | Acc: (96.00%) (26056/27008)
Epoch: 158 | Batch_idx: 220 |  Loss: (0.1113) |  Loss2: (0.0000) | Acc: (96.00%) (27275/28288)
Epoch: 158 | Batch_idx: 230 |  Loss: (0.1106) |  Loss2: (0.0000) | Acc: (96.00%) (28515/29568)
Epoch: 158 | Batch_idx: 240 |  Loss: (0.1102) |  Loss2: (0.0000) | Acc: (96.00%) (29754/30848)
Epoch: 158 | Batch_idx: 250 |  Loss: (0.1102) |  Loss2: (0.0000) | Acc: (96.00%) (30990/32128)
Epoch: 158 | Batch_idx: 260 |  Loss: (0.1103) |  Loss2: (0.0000) | Acc: (96.00%) (32213/33408)
Epoch: 158 | Batch_idx: 270 |  Loss: (0.1100) |  Loss2: (0.0000) | Acc: (96.00%) (33452/34688)
Epoch: 158 | Batch_idx: 280 |  Loss: (0.1096) |  Loss2: (0.0000) | Acc: (96.00%) (34685/35968)
Epoch: 158 | Batch_idx: 290 |  Loss: (0.1092) |  Loss2: (0.0000) | Acc: (96.00%) (35924/37248)
Epoch: 158 | Batch_idx: 300 |  Loss: (0.1092) |  Loss2: (0.0000) | Acc: (96.00%) (37159/38528)
Epoch: 158 | Batch_idx: 310 |  Loss: (0.1094) |  Loss2: (0.0000) | Acc: (96.00%) (38388/39808)
Epoch: 158 | Batch_idx: 320 |  Loss: (0.1097) |  Loss2: (0.0000) | Acc: (96.00%) (39609/41088)
Epoch: 158 | Batch_idx: 330 |  Loss: (0.1102) |  Loss2: (0.0000) | Acc: (96.00%) (40835/42368)
Epoch: 158 | Batch_idx: 340 |  Loss: (0.1100) |  Loss2: (0.0000) | Acc: (96.00%) (42074/43648)
Epoch: 158 | Batch_idx: 350 |  Loss: (0.1096) |  Loss2: (0.0000) | Acc: (96.00%) (43312/44928)
Epoch: 158 | Batch_idx: 360 |  Loss: (0.1094) |  Loss2: (0.0000) | Acc: (96.00%) (44550/46208)
Epoch: 158 | Batch_idx: 370 |  Loss: (0.1092) |  Loss2: (0.0000) | Acc: (96.00%) (45783/47488)
Epoch: 158 | Batch_idx: 380 |  Loss: (0.1091) |  Loss2: (0.0000) | Acc: (96.00%) (47018/48768)
Epoch: 158 | Batch_idx: 390 |  Loss: (0.1093) |  Loss2: (0.0000) | Acc: (96.00%) (48208/50000)
# TEST : Loss: (0.3704) | Acc: (88.00%) (8888/10000)
percent tensor([0.5150, 0.5053, 0.5162, 0.5114, 0.5185, 0.5259, 0.5107, 0.5113, 0.5151,
        0.5060, 0.5152, 0.5106, 0.5069, 0.5092, 0.5140, 0.5119],
       device='cuda:0') torch.Size([16])
percent tensor([0.5078, 0.5017, 0.5073, 0.5071, 0.5058, 0.5078, 0.5034, 0.5089, 0.5124,
        0.5037, 0.5102, 0.5014, 0.5023, 0.5138, 0.5029, 0.5083],
       device='cuda:0') torch.Size([16])
percent tensor([0.5681, 0.5547, 0.5541, 0.5714, 0.5751, 0.5700, 0.5803, 0.5739, 0.5654,
        0.5555, 0.5632, 0.5540, 0.5231, 0.6201, 0.5617, 0.5777],
       device='cuda:0') torch.Size([16])
percent tensor([0.6139, 0.6320, 0.6126, 0.6052, 0.6023, 0.6161, 0.6182, 0.5980, 0.6318,
        0.6325, 0.6450, 0.6180, 0.6324, 0.6418, 0.6068, 0.6256],
       device='cuda:0') torch.Size([16])
percent tensor([0.6020, 0.6912, 0.5077, 0.5959, 0.5064, 0.6430, 0.6142, 0.3557, 0.6973,
        0.6634, 0.7340, 0.5998, 0.6833, 0.7165, 0.5403, 0.6182],
       device='cuda:0') torch.Size([16])
percent tensor([0.6160, 0.6039, 0.6383, 0.6155, 0.6821, 0.6281, 0.6299, 0.6555, 0.6245,
        0.6007, 0.5785, 0.5671, 0.5669, 0.5828, 0.5967, 0.6232],
       device='cuda:0') torch.Size([16])
percent tensor([0.5652, 0.5824, 0.7335, 0.6584, 0.7541, 0.7553, 0.6304, 0.6594, 0.6861,
        0.5562, 0.6730, 0.6069, 0.6317, 0.5829, 0.5525, 0.5201],
       device='cuda:0') torch.Size([16])
percent tensor([0.9997, 0.9996, 0.9998, 0.9997, 0.9996, 0.9995, 0.9995, 0.9998, 0.9998,
        0.9997, 0.9999, 0.9998, 0.9998, 0.9990, 0.9995, 0.9994],
       device='cuda:0') torch.Size([16])
Epoch: 159 | Batch_idx: 0 |  Loss: (0.0797) |  Loss2: (0.0000) | Acc: (97.00%) (125/128)
Epoch: 159 | Batch_idx: 10 |  Loss: (0.1099) |  Loss2: (0.0000) | Acc: (96.00%) (1358/1408)
Epoch: 159 | Batch_idx: 20 |  Loss: (0.1204) |  Loss2: (0.0000) | Acc: (95.00%) (2575/2688)
Epoch: 159 | Batch_idx: 30 |  Loss: (0.1163) |  Loss2: (0.0000) | Acc: (96.00%) (3812/3968)
Epoch: 159 | Batch_idx: 40 |  Loss: (0.1158) |  Loss2: (0.0000) | Acc: (96.00%) (5048/5248)
Epoch: 159 | Batch_idx: 50 |  Loss: (0.1178) |  Loss2: (0.0000) | Acc: (96.00%) (6272/6528)
Epoch: 159 | Batch_idx: 60 |  Loss: (0.1178) |  Loss2: (0.0000) | Acc: (96.00%) (7496/7808)
Epoch: 159 | Batch_idx: 70 |  Loss: (0.1168) |  Loss2: (0.0000) | Acc: (96.00%) (8729/9088)
Epoch: 159 | Batch_idx: 80 |  Loss: (0.1134) |  Loss2: (0.0000) | Acc: (96.00%) (9978/10368)
Epoch: 159 | Batch_idx: 90 |  Loss: (0.1139) |  Loss2: (0.0000) | Acc: (96.00%) (11209/11648)
Epoch: 159 | Batch_idx: 100 |  Loss: (0.1134) |  Loss2: (0.0000) | Acc: (96.00%) (12441/12928)
Epoch: 159 | Batch_idx: 110 |  Loss: (0.1139) |  Loss2: (0.0000) | Acc: (96.00%) (13667/14208)
Epoch: 159 | Batch_idx: 120 |  Loss: (0.1124) |  Loss2: (0.0000) | Acc: (96.00%) (14910/15488)
Epoch: 159 | Batch_idx: 130 |  Loss: (0.1113) |  Loss2: (0.0000) | Acc: (96.00%) (16147/16768)
Epoch: 159 | Batch_idx: 140 |  Loss: (0.1106) |  Loss2: (0.0000) | Acc: (96.00%) (17382/18048)
Epoch: 159 | Batch_idx: 150 |  Loss: (0.1096) |  Loss2: (0.0000) | Acc: (96.00%) (18624/19328)
Epoch: 159 | Batch_idx: 160 |  Loss: (0.1102) |  Loss2: (0.0000) | Acc: (96.00%) (19858/20608)
Epoch: 159 | Batch_idx: 170 |  Loss: (0.1098) |  Loss2: (0.0000) | Acc: (96.00%) (21105/21888)
Epoch: 159 | Batch_idx: 180 |  Loss: (0.1092) |  Loss2: (0.0000) | Acc: (96.00%) (22345/23168)
Epoch: 159 | Batch_idx: 190 |  Loss: (0.1095) |  Loss2: (0.0000) | Acc: (96.00%) (23578/24448)
Epoch: 159 | Batch_idx: 200 |  Loss: (0.1091) |  Loss2: (0.0000) | Acc: (96.00%) (24817/25728)
Epoch: 159 | Batch_idx: 210 |  Loss: (0.1094) |  Loss2: (0.0000) | Acc: (96.00%) (26052/27008)
Epoch: 159 | Batch_idx: 220 |  Loss: (0.1095) |  Loss2: (0.0000) | Acc: (96.00%) (27285/28288)
Epoch: 159 | Batch_idx: 230 |  Loss: (0.1099) |  Loss2: (0.0000) | Acc: (96.00%) (28514/29568)
Epoch: 159 | Batch_idx: 240 |  Loss: (0.1101) |  Loss2: (0.0000) | Acc: (96.00%) (29742/30848)
Epoch: 159 | Batch_idx: 250 |  Loss: (0.1097) |  Loss2: (0.0000) | Acc: (96.00%) (30980/32128)
Epoch: 159 | Batch_idx: 260 |  Loss: (0.1095) |  Loss2: (0.0000) | Acc: (96.00%) (32214/33408)
Epoch: 159 | Batch_idx: 270 |  Loss: (0.1091) |  Loss2: (0.0000) | Acc: (96.00%) (33455/34688)
Epoch: 159 | Batch_idx: 280 |  Loss: (0.1093) |  Loss2: (0.0000) | Acc: (96.00%) (34684/35968)
Epoch: 159 | Batch_idx: 290 |  Loss: (0.1090) |  Loss2: (0.0000) | Acc: (96.00%) (35920/37248)
Epoch: 159 | Batch_idx: 300 |  Loss: (0.1088) |  Loss2: (0.0000) | Acc: (96.00%) (37153/38528)
Epoch: 159 | Batch_idx: 310 |  Loss: (0.1095) |  Loss2: (0.0000) | Acc: (96.00%) (38370/39808)
Epoch: 159 | Batch_idx: 320 |  Loss: (0.1095) |  Loss2: (0.0000) | Acc: (96.00%) (39602/41088)
Epoch: 159 | Batch_idx: 330 |  Loss: (0.1092) |  Loss2: (0.0000) | Acc: (96.00%) (40837/42368)
Epoch: 159 | Batch_idx: 340 |  Loss: (0.1089) |  Loss2: (0.0000) | Acc: (96.00%) (42075/43648)
Epoch: 159 | Batch_idx: 350 |  Loss: (0.1086) |  Loss2: (0.0000) | Acc: (96.00%) (43316/44928)
Epoch: 159 | Batch_idx: 360 |  Loss: (0.1086) |  Loss2: (0.0000) | Acc: (96.00%) (44548/46208)
Epoch: 159 | Batch_idx: 370 |  Loss: (0.1086) |  Loss2: (0.0000) | Acc: (96.00%) (45781/47488)
Epoch: 159 | Batch_idx: 380 |  Loss: (0.1086) |  Loss2: (0.0000) | Acc: (96.00%) (47020/48768)
Epoch: 159 | Batch_idx: 390 |  Loss: (0.1087) |  Loss2: (0.0000) | Acc: (96.00%) (48206/50000)
# TEST : Loss: (0.3677) | Acc: (88.00%) (8893/10000)
percent tensor([0.5155, 0.5062, 0.5168, 0.5120, 0.5193, 0.5261, 0.5115, 0.5121, 0.5158,
        0.5069, 0.5158, 0.5115, 0.5074, 0.5099, 0.5147, 0.5124],
       device='cuda:0') torch.Size([16])
percent tensor([0.5083, 0.5022, 0.5074, 0.5073, 0.5061, 0.5083, 0.5039, 0.5092, 0.5126,
        0.5041, 0.5106, 0.5017, 0.5026, 0.5143, 0.5034, 0.5087],
       device='cuda:0') torch.Size([16])
percent tensor([0.5669, 0.5518, 0.5534, 0.5710, 0.5746, 0.5697, 0.5791, 0.5734, 0.5638,
        0.5523, 0.5610, 0.5521, 0.5202, 0.6193, 0.5609, 0.5764],
       device='cuda:0') torch.Size([16])
percent tensor([0.6124, 0.6302, 0.6117, 0.6043, 0.6015, 0.6150, 0.6168, 0.5973, 0.6307,
        0.6308, 0.6431, 0.6167, 0.6309, 0.6403, 0.6054, 0.6242],
       device='cuda:0') torch.Size([16])
percent tensor([0.6057, 0.6907, 0.5174, 0.6057, 0.5131, 0.6499, 0.6192, 0.3615, 0.7041,
        0.6691, 0.7381, 0.6099, 0.6833, 0.7219, 0.5470, 0.6215],
       device='cuda:0') torch.Size([16])
percent tensor([0.6163, 0.6058, 0.6394, 0.6159, 0.6839, 0.6290, 0.6305, 0.6570, 0.6251,
        0.6027, 0.5789, 0.5660, 0.5676, 0.5828, 0.5972, 0.6250],
       device='cuda:0') torch.Size([16])
percent tensor([0.5542, 0.5785, 0.7285, 0.6488, 0.7467, 0.7489, 0.6177, 0.6517, 0.6770,
        0.5479, 0.6667, 0.5981, 0.6271, 0.5702, 0.5469, 0.5072],
       device='cuda:0') torch.Size([16])
percent tensor([0.9997, 0.9996, 0.9998, 0.9997, 0.9996, 0.9994, 0.9995, 0.9998, 0.9998,
        0.9997, 0.9999, 0.9997, 0.9998, 0.9991, 0.9995, 0.9994],
       device='cuda:0') torch.Size([16])
Epoch: 160 | Batch_idx: 0 |  Loss: (0.0700) |  Loss2: (0.0000) | Acc: (97.00%) (125/128)
Epoch: 160 | Batch_idx: 10 |  Loss: (0.0961) |  Loss2: (0.0000) | Acc: (96.00%) (1358/1408)
Epoch: 160 | Batch_idx: 20 |  Loss: (0.1023) |  Loss2: (0.0000) | Acc: (96.00%) (2589/2688)
Epoch: 160 | Batch_idx: 30 |  Loss: (0.1035) |  Loss2: (0.0000) | Acc: (96.00%) (3814/3968)
Epoch: 160 | Batch_idx: 40 |  Loss: (0.1028) |  Loss2: (0.0000) | Acc: (96.00%) (5052/5248)
Epoch: 160 | Batch_idx: 50 |  Loss: (0.1049) |  Loss2: (0.0000) | Acc: (96.00%) (6281/6528)
Epoch: 160 | Batch_idx: 60 |  Loss: (0.1074) |  Loss2: (0.0000) | Acc: (96.00%) (7511/7808)
Epoch: 160 | Batch_idx: 70 |  Loss: (0.1077) |  Loss2: (0.0000) | Acc: (96.00%) (8744/9088)
Epoch: 160 | Batch_idx: 80 |  Loss: (0.1072) |  Loss2: (0.0000) | Acc: (96.00%) (9980/10368)
Epoch: 160 | Batch_idx: 90 |  Loss: (0.1065) |  Loss2: (0.0000) | Acc: (96.00%) (11220/11648)
Epoch: 160 | Batch_idx: 100 |  Loss: (0.1062) |  Loss2: (0.0000) | Acc: (96.00%) (12458/12928)
Epoch: 160 | Batch_idx: 110 |  Loss: (0.1086) |  Loss2: (0.0000) | Acc: (96.00%) (13674/14208)
Epoch: 160 | Batch_idx: 120 |  Loss: (0.1085) |  Loss2: (0.0000) | Acc: (96.00%) (14907/15488)
Epoch: 160 | Batch_idx: 130 |  Loss: (0.1079) |  Loss2: (0.0000) | Acc: (96.00%) (16145/16768)
Epoch: 160 | Batch_idx: 140 |  Loss: (0.1072) |  Loss2: (0.0000) | Acc: (96.00%) (17384/18048)
Epoch: 160 | Batch_idx: 150 |  Loss: (0.1061) |  Loss2: (0.0000) | Acc: (96.00%) (18626/19328)
Epoch: 160 | Batch_idx: 160 |  Loss: (0.1065) |  Loss2: (0.0000) | Acc: (96.00%) (19851/20608)
Epoch: 160 | Batch_idx: 170 |  Loss: (0.1073) |  Loss2: (0.0000) | Acc: (96.00%) (21077/21888)
Epoch: 160 | Batch_idx: 180 |  Loss: (0.1066) |  Loss2: (0.0000) | Acc: (96.00%) (22322/23168)
Epoch: 160 | Batch_idx: 190 |  Loss: (0.1066) |  Loss2: (0.0000) | Acc: (96.00%) (23546/24448)
Epoch: 160 | Batch_idx: 200 |  Loss: (0.1079) |  Loss2: (0.0000) | Acc: (96.00%) (24771/25728)
Epoch: 160 | Batch_idx: 210 |  Loss: (0.1080) |  Loss2: (0.0000) | Acc: (96.00%) (26006/27008)
Epoch: 160 | Batch_idx: 220 |  Loss: (0.1077) |  Loss2: (0.0000) | Acc: (96.00%) (27242/28288)
Epoch: 160 | Batch_idx: 230 |  Loss: (0.1077) |  Loss2: (0.0000) | Acc: (96.00%) (28476/29568)
Epoch: 160 | Batch_idx: 240 |  Loss: (0.1082) |  Loss2: (0.0000) | Acc: (96.00%) (29704/30848)
Epoch: 160 | Batch_idx: 250 |  Loss: (0.1087) |  Loss2: (0.0000) | Acc: (96.00%) (30933/32128)
Epoch: 160 | Batch_idx: 260 |  Loss: (0.1089) |  Loss2: (0.0000) | Acc: (96.00%) (32167/33408)
Epoch: 160 | Batch_idx: 270 |  Loss: (0.1087) |  Loss2: (0.0000) | Acc: (96.00%) (33404/34688)
Epoch: 160 | Batch_idx: 280 |  Loss: (0.1086) |  Loss2: (0.0000) | Acc: (96.00%) (34639/35968)
Epoch: 160 | Batch_idx: 290 |  Loss: (0.1087) |  Loss2: (0.0000) | Acc: (96.00%) (35870/37248)
Epoch: 160 | Batch_idx: 300 |  Loss: (0.1085) |  Loss2: (0.0000) | Acc: (96.00%) (37109/38528)
Epoch: 160 | Batch_idx: 310 |  Loss: (0.1083) |  Loss2: (0.0000) | Acc: (96.00%) (38348/39808)
Epoch: 160 | Batch_idx: 320 |  Loss: (0.1090) |  Loss2: (0.0000) | Acc: (96.00%) (39558/41088)
Epoch: 160 | Batch_idx: 330 |  Loss: (0.1089) |  Loss2: (0.0000) | Acc: (96.00%) (40799/42368)
Epoch: 160 | Batch_idx: 340 |  Loss: (0.1085) |  Loss2: (0.0000) | Acc: (96.00%) (42038/43648)
Epoch: 160 | Batch_idx: 350 |  Loss: (0.1086) |  Loss2: (0.0000) | Acc: (96.00%) (43275/44928)
Epoch: 160 | Batch_idx: 360 |  Loss: (0.1084) |  Loss2: (0.0000) | Acc: (96.00%) (44515/46208)
Epoch: 160 | Batch_idx: 370 |  Loss: (0.1085) |  Loss2: (0.0000) | Acc: (96.00%) (45747/47488)
Epoch: 160 | Batch_idx: 380 |  Loss: (0.1088) |  Loss2: (0.0000) | Acc: (96.00%) (46977/48768)
Epoch: 160 | Batch_idx: 390 |  Loss: (0.1095) |  Loss2: (0.0000) | Acc: (96.00%) (48151/50000)
=> saving checkpoint 'drive/app/torch/save_Schedule/checkpoint_160.pth.tar'
# TEST : Loss: (0.3681) | Acc: (88.00%) (8892/10000)
percent tensor([0.5155, 0.5065, 0.5172, 0.5122, 0.5198, 0.5258, 0.5119, 0.5126, 0.5161,
        0.5073, 0.5160, 0.5120, 0.5078, 0.5100, 0.5148, 0.5124],
       device='cuda:0') torch.Size([16])
percent tensor([0.5085, 0.5024, 0.5077, 0.5074, 0.5063, 0.5085, 0.5042, 0.5095, 0.5128,
        0.5044, 0.5107, 0.5020, 0.5030, 0.5144, 0.5036, 0.5089],
       device='cuda:0') torch.Size([16])
percent tensor([0.5664, 0.5507, 0.5543, 0.5710, 0.5741, 0.5691, 0.5790, 0.5729, 0.5646,
        0.5520, 0.5611, 0.5528, 0.5202, 0.6198, 0.5600, 0.5758],
       device='cuda:0') torch.Size([16])
percent tensor([0.6145, 0.6329, 0.6136, 0.6060, 0.6033, 0.6173, 0.6191, 0.5987, 0.6330,
        0.6334, 0.6457, 0.6190, 0.6337, 0.6431, 0.6077, 0.6266],
       device='cuda:0') torch.Size([16])
percent tensor([0.5953, 0.6882, 0.5112, 0.6020, 0.5094, 0.6388, 0.6156, 0.3581, 0.7010,
        0.6637, 0.7355, 0.6075, 0.6801, 0.7211, 0.5416, 0.6133],
       device='cuda:0') torch.Size([16])
percent tensor([0.6239, 0.6145, 0.6444, 0.6217, 0.6904, 0.6355, 0.6397, 0.6637, 0.6324,
        0.6118, 0.5866, 0.5727, 0.5765, 0.5899, 0.6056, 0.6327],
       device='cuda:0') torch.Size([16])
percent tensor([0.5572, 0.5809, 0.7344, 0.6554, 0.7512, 0.7549, 0.6208, 0.6538, 0.6820,
        0.5512, 0.6728, 0.6039, 0.6330, 0.5708, 0.5489, 0.5078],
       device='cuda:0') torch.Size([16])
percent tensor([0.9997, 0.9996, 0.9998, 0.9997, 0.9996, 0.9995, 0.9995, 0.9998, 0.9998,
        0.9997, 0.9999, 0.9998, 0.9998, 0.9991, 0.9995, 0.9994],
       device='cuda:0') torch.Size([16])
Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 3, 3, 3]) tensor(188.7100, device='cuda:0')
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(831.6414, device='cuda:0')
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(820.1465, device='cuda:0')
Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([128, 64, 3, 3]) tensor(1521.4985, device='cuda:0')
Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([128, 64, 1, 1]) tensor(478.9918, device='cuda:0')
Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([128, 128, 3, 3]) tensor(2291.5588, device='cuda:0')
Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([256, 128, 3, 3]) tensor(4250.9683, device='cuda:0')
Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([256, 128, 1, 1]) tensor(1359.4484, device='cuda:0')
Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([256, 256, 3, 3]) tensor(6187.6821, device='cuda:0')
Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([512, 256, 3, 3]) tensor(11642.2832, device='cuda:0')
Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([512, 256, 1, 1]) tensor(3847.8606, device='cuda:0')
Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([512, 512, 3, 3]) tensor(16260.5986, device='cuda:0')
Epoch: 161 | Batch_idx: 0 |  Loss: (0.1611) |  Loss2: (0.0000) | Acc: (93.00%) (120/128)
Epoch: 161 | Batch_idx: 10 |  Loss: (0.1121) |  Loss2: (0.0000) | Acc: (96.00%) (1353/1408)
Epoch: 161 | Batch_idx: 20 |  Loss: (0.1117) |  Loss2: (0.0000) | Acc: (96.00%) (2590/2688)
Epoch: 161 | Batch_idx: 30 |  Loss: (0.1035) |  Loss2: (0.0000) | Acc: (96.00%) (3833/3968)
Epoch: 161 | Batch_idx: 40 |  Loss: (0.1091) |  Loss2: (0.0000) | Acc: (96.00%) (5060/5248)
Epoch: 161 | Batch_idx: 50 |  Loss: (0.1079) |  Loss2: (0.0000) | Acc: (96.00%) (6290/6528)
Epoch: 161 | Batch_idx: 60 |  Loss: (0.1060) |  Loss2: (0.0000) | Acc: (96.00%) (7533/7808)
Epoch: 161 | Batch_idx: 70 |  Loss: (0.1057) |  Loss2: (0.0000) | Acc: (96.00%) (8770/9088)
Epoch: 161 | Batch_idx: 80 |  Loss: (0.1050) |  Loss2: (0.0000) | Acc: (96.00%) (10008/10368)
Epoch: 161 | Batch_idx: 90 |  Loss: (0.1057) |  Loss2: (0.0000) | Acc: (96.00%) (11241/11648)
Epoch: 161 | Batch_idx: 100 |  Loss: (0.1053) |  Loss2: (0.0000) | Acc: (96.00%) (12474/12928)
Epoch: 161 | Batch_idx: 110 |  Loss: (0.1038) |  Loss2: (0.0000) | Acc: (96.00%) (13726/14208)
Epoch: 161 | Batch_idx: 120 |  Loss: (0.1064) |  Loss2: (0.0000) | Acc: (96.00%) (14944/15488)
Epoch: 161 | Batch_idx: 130 |  Loss: (0.1067) |  Loss2: (0.0000) | Acc: (96.00%) (16176/16768)
Epoch: 161 | Batch_idx: 140 |  Loss: (0.1066) |  Loss2: (0.0000) | Acc: (96.00%) (17411/18048)
Epoch: 161 | Batch_idx: 150 |  Loss: (0.1074) |  Loss2: (0.0000) | Acc: (96.00%) (18641/19328)
Epoch: 161 | Batch_idx: 160 |  Loss: (0.1072) |  Loss2: (0.0000) | Acc: (96.00%) (19883/20608)
Epoch: 161 | Batch_idx: 170 |  Loss: (0.1079) |  Loss2: (0.0000) | Acc: (96.00%) (21109/21888)
Epoch: 161 | Batch_idx: 180 |  Loss: (0.1081) |  Loss2: (0.0000) | Acc: (96.00%) (22337/23168)
Epoch: 161 | Batch_idx: 190 |  Loss: (0.1081) |  Loss2: (0.0000) | Acc: (96.00%) (23576/24448)
Epoch: 161 | Batch_idx: 200 |  Loss: (0.1079) |  Loss2: (0.0000) | Acc: (96.00%) (24817/25728)
Epoch: 161 | Batch_idx: 210 |  Loss: (0.1082) |  Loss2: (0.0000) | Acc: (96.00%) (26048/27008)
Epoch: 161 | Batch_idx: 220 |  Loss: (0.1087) |  Loss2: (0.0000) | Acc: (96.00%) (27272/28288)
Epoch: 161 | Batch_idx: 230 |  Loss: (0.1087) |  Loss2: (0.0000) | Acc: (96.00%) (28507/29568)
Epoch: 161 | Batch_idx: 240 |  Loss: (0.1088) |  Loss2: (0.0000) | Acc: (96.00%) (29744/30848)
Epoch: 161 | Batch_idx: 250 |  Loss: (0.1088) |  Loss2: (0.0000) | Acc: (96.00%) (30976/32128)
Epoch: 161 | Batch_idx: 260 |  Loss: (0.1089) |  Loss2: (0.0000) | Acc: (96.00%) (32205/33408)
Epoch: 161 | Batch_idx: 270 |  Loss: (0.1080) |  Loss2: (0.0000) | Acc: (96.00%) (33454/34688)
Epoch: 161 | Batch_idx: 280 |  Loss: (0.1081) |  Loss2: (0.0000) | Acc: (96.00%) (34685/35968)
Epoch: 161 | Batch_idx: 290 |  Loss: (0.1087) |  Loss2: (0.0000) | Acc: (96.00%) (35908/37248)
Epoch: 161 | Batch_idx: 300 |  Loss: (0.1092) |  Loss2: (0.0000) | Acc: (96.00%) (37139/38528)
Epoch: 161 | Batch_idx: 310 |  Loss: (0.1089) |  Loss2: (0.0000) | Acc: (96.00%) (38379/39808)
Epoch: 161 | Batch_idx: 320 |  Loss: (0.1087) |  Loss2: (0.0000) | Acc: (96.00%) (39607/41088)
Epoch: 161 | Batch_idx: 330 |  Loss: (0.1091) |  Loss2: (0.0000) | Acc: (96.00%) (40834/42368)
Epoch: 161 | Batch_idx: 340 |  Loss: (0.1086) |  Loss2: (0.0000) | Acc: (96.00%) (42077/43648)
Epoch: 161 | Batch_idx: 350 |  Loss: (0.1088) |  Loss2: (0.0000) | Acc: (96.00%) (43309/44928)
Epoch: 161 | Batch_idx: 360 |  Loss: (0.1087) |  Loss2: (0.0000) | Acc: (96.00%) (44539/46208)
Epoch: 161 | Batch_idx: 370 |  Loss: (0.1091) |  Loss2: (0.0000) | Acc: (96.00%) (45764/47488)
Epoch: 161 | Batch_idx: 380 |  Loss: (0.1092) |  Loss2: (0.0000) | Acc: (96.00%) (46998/48768)
Epoch: 161 | Batch_idx: 390 |  Loss: (0.1094) |  Loss2: (0.0000) | Acc: (96.00%) (48179/50000)
# TEST : Loss: (0.3673) | Acc: (89.00%) (8904/10000)
percent tensor([0.5148, 0.5058, 0.5162, 0.5113, 0.5188, 0.5252, 0.5111, 0.5117, 0.5153,
        0.5064, 0.5152, 0.5110, 0.5071, 0.5094, 0.5140, 0.5117],
       device='cuda:0') torch.Size([16])
percent tensor([0.5091, 0.5033, 0.5082, 0.5079, 0.5069, 0.5091, 0.5050, 0.5101, 0.5134,
        0.5052, 0.5114, 0.5027, 0.5038, 0.5150, 0.5045, 0.5095],
       device='cuda:0') torch.Size([16])
percent tensor([0.5605, 0.5443, 0.5498, 0.5670, 0.5696, 0.5635, 0.5737, 0.5690, 0.5588,
        0.5453, 0.5545, 0.5471, 0.5147, 0.6123, 0.5547, 0.5697],
       device='cuda:0') torch.Size([16])
percent tensor([0.6157, 0.6341, 0.6145, 0.6069, 0.6042, 0.6186, 0.6202, 0.5997, 0.6338,
        0.6346, 0.6467, 0.6201, 0.6349, 0.6443, 0.6089, 0.6279],
       device='cuda:0') torch.Size([16])
percent tensor([0.5987, 0.6867, 0.5140, 0.6031, 0.5077, 0.6416, 0.6136, 0.3630, 0.6962,
        0.6606, 0.7322, 0.6072, 0.6797, 0.7159, 0.5436, 0.6126],
       device='cuda:0') torch.Size([16])
percent tensor([0.6173, 0.6077, 0.6381, 0.6151, 0.6838, 0.6293, 0.6331, 0.6581, 0.6259,
        0.6044, 0.5796, 0.5654, 0.5688, 0.5828, 0.5980, 0.6257],
       device='cuda:0') torch.Size([16])
percent tensor([0.5595, 0.5913, 0.7368, 0.6593, 0.7518, 0.7576, 0.6265, 0.6540, 0.6881,
        0.5596, 0.6750, 0.6085, 0.6374, 0.5782, 0.5545, 0.5118],
       device='cuda:0') torch.Size([16])
percent tensor([0.9997, 0.9996, 0.9998, 0.9997, 0.9996, 0.9995, 0.9995, 0.9998, 0.9998,
        0.9998, 0.9999, 0.9998, 0.9998, 0.9991, 0.9995, 0.9994],
       device='cuda:0') torch.Size([16])
True Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=128, out_features=16, bias=False)
False Linear(in_features=16, out_features=2, bias=False)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=128, out_features=16, bias=False)
False Linear(in_features=16, out_features=2, bias=False)
True Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=256, out_features=32, bias=False)
False Linear(in_features=32, out_features=2, bias=False)
True Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=256, out_features=32, bias=False)
False Linear(in_features=32, out_features=2, bias=False)
True Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=512, out_features=64, bias=False)
False Linear(in_features=64, out_features=2, bias=False)
True Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=512, out_features=64, bias=False)
False Linear(in_features=64, out_features=2, bias=False)
True Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1024, out_features=128, bias=False)
False Linear(in_features=128, out_features=2, bias=False)
True Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1024, out_features=128, bias=False)
False Linear(in_features=128, out_features=2, bias=False)
True Linear(in_features=512, out_features=10, bias=True)
Epoch: 162 | Batch_idx: 0 |  Loss: (0.0973) |  Loss2: (0.0000) | Acc: (96.00%) (123/128)
Epoch: 162 | Batch_idx: 10 |  Loss: (0.1087) |  Loss2: (0.0000) | Acc: (96.00%) (1353/1408)
Epoch: 162 | Batch_idx: 20 |  Loss: (0.1129) |  Loss2: (0.0000) | Acc: (95.00%) (2580/2688)
Epoch: 162 | Batch_idx: 30 |  Loss: (0.1098) |  Loss2: (0.0000) | Acc: (96.00%) (3817/3968)
Epoch: 162 | Batch_idx: 40 |  Loss: (0.1124) |  Loss2: (0.0000) | Acc: (96.00%) (5046/5248)
Epoch: 162 | Batch_idx: 50 |  Loss: (0.1164) |  Loss2: (0.0000) | Acc: (96.00%) (6269/6528)
Epoch: 162 | Batch_idx: 60 |  Loss: (0.1194) |  Loss2: (0.0000) | Acc: (95.00%) (7483/7808)
Epoch: 162 | Batch_idx: 70 |  Loss: (0.1209) |  Loss2: (0.0000) | Acc: (95.00%) (8700/9088)
Epoch: 162 | Batch_idx: 80 |  Loss: (0.1216) |  Loss2: (0.0000) | Acc: (95.00%) (9929/10368)
Epoch: 162 | Batch_idx: 90 |  Loss: (0.1211) |  Loss2: (0.0000) | Acc: (95.00%) (11158/11648)
Epoch: 162 | Batch_idx: 100 |  Loss: (0.1220) |  Loss2: (0.0000) | Acc: (95.00%) (12377/12928)
Epoch: 162 | Batch_idx: 110 |  Loss: (0.1228) |  Loss2: (0.0000) | Acc: (95.00%) (13598/14208)
Epoch: 162 | Batch_idx: 120 |  Loss: (0.1232) |  Loss2: (0.0000) | Acc: (95.00%) (14819/15488)
Epoch: 162 | Batch_idx: 130 |  Loss: (0.1229) |  Loss2: (0.0000) | Acc: (95.00%) (16041/16768)
Epoch: 162 | Batch_idx: 140 |  Loss: (0.1215) |  Loss2: (0.0000) | Acc: (95.00%) (17277/18048)
Epoch: 162 | Batch_idx: 150 |  Loss: (0.1211) |  Loss2: (0.0000) | Acc: (95.00%) (18509/19328)
Epoch: 162 | Batch_idx: 160 |  Loss: (0.1210) |  Loss2: (0.0000) | Acc: (95.00%) (19730/20608)
Epoch: 162 | Batch_idx: 170 |  Loss: (0.1223) |  Loss2: (0.0000) | Acc: (95.00%) (20940/21888)
Epoch: 162 | Batch_idx: 180 |  Loss: (0.1221) |  Loss2: (0.0000) | Acc: (95.00%) (22170/23168)
Epoch: 162 | Batch_idx: 190 |  Loss: (0.1222) |  Loss2: (0.0000) | Acc: (95.00%) (23402/24448)
Epoch: 162 | Batch_idx: 200 |  Loss: (0.1213) |  Loss2: (0.0000) | Acc: (95.00%) (24639/25728)
Epoch: 162 | Batch_idx: 210 |  Loss: (0.1214) |  Loss2: (0.0000) | Acc: (95.00%) (25868/27008)
Epoch: 162 | Batch_idx: 220 |  Loss: (0.1214) |  Loss2: (0.0000) | Acc: (95.00%) (27089/28288)
Epoch: 162 | Batch_idx: 230 |  Loss: (0.1207) |  Loss2: (0.0000) | Acc: (95.00%) (28320/29568)
Epoch: 162 | Batch_idx: 240 |  Loss: (0.1200) |  Loss2: (0.0000) | Acc: (95.00%) (29559/30848)
Epoch: 162 | Batch_idx: 250 |  Loss: (0.1198) |  Loss2: (0.0000) | Acc: (95.00%) (30788/32128)
Epoch: 162 | Batch_idx: 260 |  Loss: (0.1197) |  Loss2: (0.0000) | Acc: (95.00%) (32012/33408)
Epoch: 162 | Batch_idx: 270 |  Loss: (0.1204) |  Loss2: (0.0000) | Acc: (95.00%) (33224/34688)
Epoch: 162 | Batch_idx: 280 |  Loss: (0.1205) |  Loss2: (0.0000) | Acc: (95.00%) (34455/35968)
Epoch: 162 | Batch_idx: 290 |  Loss: (0.1214) |  Loss2: (0.0000) | Acc: (95.00%) (35669/37248)
Epoch: 162 | Batch_idx: 300 |  Loss: (0.1210) |  Loss2: (0.0000) | Acc: (95.00%) (36898/38528)
Epoch: 162 | Batch_idx: 310 |  Loss: (0.1219) |  Loss2: (0.0000) | Acc: (95.00%) (38111/39808)
Epoch: 162 | Batch_idx: 320 |  Loss: (0.1223) |  Loss2: (0.0000) | Acc: (95.00%) (39332/41088)
Epoch: 162 | Batch_idx: 330 |  Loss: (0.1223) |  Loss2: (0.0000) | Acc: (95.00%) (40560/42368)
Epoch: 162 | Batch_idx: 340 |  Loss: (0.1223) |  Loss2: (0.0000) | Acc: (95.00%) (41794/43648)
Epoch: 162 | Batch_idx: 350 |  Loss: (0.1220) |  Loss2: (0.0000) | Acc: (95.00%) (43023/44928)
Epoch: 162 | Batch_idx: 360 |  Loss: (0.1222) |  Loss2: (0.0000) | Acc: (95.00%) (44238/46208)
Epoch: 162 | Batch_idx: 370 |  Loss: (0.1224) |  Loss2: (0.0000) | Acc: (95.00%) (45462/47488)
Epoch: 162 | Batch_idx: 380 |  Loss: (0.1222) |  Loss2: (0.0000) | Acc: (95.00%) (46693/48768)
Epoch: 162 | Batch_idx: 390 |  Loss: (0.1224) |  Loss2: (0.0000) | Acc: (95.00%) (47865/50000)
# TEST : Loss: (0.4275) | Acc: (87.00%) (8784/10000)
percent tensor([0.5159, 0.5053, 0.5189, 0.5122, 0.5217, 0.5254, 0.5119, 0.5124, 0.5168,
        0.5077, 0.5160, 0.5136, 0.5080, 0.5087, 0.5138, 0.5122],
       device='cuda:0') torch.Size([16])
percent tensor([0.5086, 0.5037, 0.5094, 0.5085, 0.5078, 0.5091, 0.5062, 0.5106, 0.5128,
        0.5063, 0.5109, 0.5053, 0.5035, 0.5170, 0.5048, 0.5098],
       device='cuda:0') torch.Size([16])
percent tensor([0.5625, 0.5354, 0.5642, 0.5763, 0.5808, 0.5636, 0.5707, 0.5751, 0.5582,
        0.5466, 0.5504, 0.5605, 0.5161, 0.5967, 0.5541, 0.5685],
       device='cuda:0') torch.Size([16])
percent tensor([0.6143, 0.6347, 0.6142, 0.6087, 0.6046, 0.6197, 0.6219, 0.6030, 0.6321,
        0.6372, 0.6449, 0.6234, 0.6333, 0.6421, 0.6113, 0.6294],
       device='cuda:0') torch.Size([16])
percent tensor([0.6030, 0.6815, 0.5256, 0.5962, 0.5222, 0.6325, 0.6148, 0.3893, 0.6995,
        0.6663, 0.7335, 0.6084, 0.6865, 0.7037, 0.5368, 0.6115],
       device='cuda:0') torch.Size([16])
percent tensor([0.6087, 0.6001, 0.6425, 0.6175, 0.6791, 0.6332, 0.6323, 0.6583, 0.6133,
        0.6037, 0.5759, 0.5764, 0.5634, 0.5912, 0.5977, 0.6256],
       device='cuda:0') torch.Size([16])
percent tensor([0.5400, 0.5774, 0.7158, 0.6519, 0.7489, 0.7580, 0.5962, 0.6239, 0.6296,
        0.5728, 0.6894, 0.5849, 0.6331, 0.5785, 0.5322, 0.5196],
       device='cuda:0') torch.Size([16])
percent tensor([0.9998, 0.9997, 0.9996, 0.9997, 0.9995, 0.9993, 0.9995, 0.9998, 0.9999,
        0.9997, 0.9999, 0.9998, 0.9998, 0.9993, 0.9995, 0.9993],
       device='cuda:0') torch.Size([16])
Epoch: 163 | Batch_idx: 0 |  Loss: (0.1120) |  Loss2: (0.0000) | Acc: (96.00%) (123/128)
Epoch: 163 | Batch_idx: 10 |  Loss: (0.1197) |  Loss2: (0.0000) | Acc: (96.00%) (1353/1408)
Epoch: 163 | Batch_idx: 20 |  Loss: (0.1233) |  Loss2: (0.0000) | Acc: (96.00%) (2582/2688)
Epoch: 163 | Batch_idx: 30 |  Loss: (0.1244) |  Loss2: (0.0000) | Acc: (95.00%) (3806/3968)
Epoch: 163 | Batch_idx: 40 |  Loss: (0.1306) |  Loss2: (0.0000) | Acc: (95.00%) (5016/5248)
Epoch: 163 | Batch_idx: 50 |  Loss: (0.1297) |  Loss2: (0.0000) | Acc: (95.00%) (6235/6528)
Epoch: 163 | Batch_idx: 60 |  Loss: (0.1286) |  Loss2: (0.0000) | Acc: (95.00%) (7462/7808)
Epoch: 163 | Batch_idx: 70 |  Loss: (0.1283) |  Loss2: (0.0000) | Acc: (95.00%) (8691/9088)
Epoch: 163 | Batch_idx: 80 |  Loss: (0.1280) |  Loss2: (0.0000) | Acc: (95.00%) (9922/10368)
Epoch: 163 | Batch_idx: 90 |  Loss: (0.1259) |  Loss2: (0.0000) | Acc: (95.00%) (11158/11648)
Epoch: 163 | Batch_idx: 100 |  Loss: (0.1246) |  Loss2: (0.0000) | Acc: (95.00%) (12397/12928)
Epoch: 163 | Batch_idx: 110 |  Loss: (0.1220) |  Loss2: (0.0000) | Acc: (95.00%) (13632/14208)
Epoch: 163 | Batch_idx: 120 |  Loss: (0.1238) |  Loss2: (0.0000) | Acc: (95.00%) (14852/15488)
Epoch: 163 | Batch_idx: 130 |  Loss: (0.1230) |  Loss2: (0.0000) | Acc: (95.00%) (16083/16768)
Epoch: 163 | Batch_idx: 140 |  Loss: (0.1220) |  Loss2: (0.0000) | Acc: (95.00%) (17319/18048)
Epoch: 163 | Batch_idx: 150 |  Loss: (0.1224) |  Loss2: (0.0000) | Acc: (95.00%) (18547/19328)
Epoch: 163 | Batch_idx: 160 |  Loss: (0.1212) |  Loss2: (0.0000) | Acc: (95.00%) (19781/20608)
Epoch: 163 | Batch_idx: 170 |  Loss: (0.1198) |  Loss2: (0.0000) | Acc: (96.00%) (21014/21888)
Epoch: 163 | Batch_idx: 180 |  Loss: (0.1210) |  Loss2: (0.0000) | Acc: (95.00%) (22223/23168)
Epoch: 163 | Batch_idx: 190 |  Loss: (0.1214) |  Loss2: (0.0000) | Acc: (95.00%) (23445/24448)
Epoch: 163 | Batch_idx: 200 |  Loss: (0.1212) |  Loss2: (0.0000) | Acc: (95.00%) (24669/25728)
Epoch: 163 | Batch_idx: 210 |  Loss: (0.1209) |  Loss2: (0.0000) | Acc: (95.00%) (25901/27008)
Epoch: 163 | Batch_idx: 220 |  Loss: (0.1207) |  Loss2: (0.0000) | Acc: (95.00%) (27132/28288)
Epoch: 163 | Batch_idx: 230 |  Loss: (0.1206) |  Loss2: (0.0000) | Acc: (95.00%) (28357/29568)
Epoch: 163 | Batch_idx: 240 |  Loss: (0.1209) |  Loss2: (0.0000) | Acc: (95.00%) (29584/30848)
Epoch: 163 | Batch_idx: 250 |  Loss: (0.1213) |  Loss2: (0.0000) | Acc: (95.00%) (30811/32128)
Epoch: 163 | Batch_idx: 260 |  Loss: (0.1210) |  Loss2: (0.0000) | Acc: (95.00%) (32042/33408)
Epoch: 163 | Batch_idx: 270 |  Loss: (0.1216) |  Loss2: (0.0000) | Acc: (95.00%) (33261/34688)
Epoch: 163 | Batch_idx: 280 |  Loss: (0.1216) |  Loss2: (0.0000) | Acc: (95.00%) (34484/35968)
Epoch: 163 | Batch_idx: 290 |  Loss: (0.1222) |  Loss2: (0.0000) | Acc: (95.00%) (35697/37248)
Epoch: 163 | Batch_idx: 300 |  Loss: (0.1228) |  Loss2: (0.0000) | Acc: (95.00%) (36908/38528)
Epoch: 163 | Batch_idx: 310 |  Loss: (0.1228) |  Loss2: (0.0000) | Acc: (95.00%) (38129/39808)
Epoch: 163 | Batch_idx: 320 |  Loss: (0.1228) |  Loss2: (0.0000) | Acc: (95.00%) (39352/41088)
Epoch: 163 | Batch_idx: 330 |  Loss: (0.1228) |  Loss2: (0.0000) | Acc: (95.00%) (40578/42368)
Epoch: 163 | Batch_idx: 340 |  Loss: (0.1228) |  Loss2: (0.0000) | Acc: (95.00%) (41810/43648)
Epoch: 163 | Batch_idx: 350 |  Loss: (0.1231) |  Loss2: (0.0000) | Acc: (95.00%) (43035/44928)
Epoch: 163 | Batch_idx: 360 |  Loss: (0.1232) |  Loss2: (0.0000) | Acc: (95.00%) (44259/46208)
Epoch: 163 | Batch_idx: 370 |  Loss: (0.1229) |  Loss2: (0.0000) | Acc: (95.00%) (45490/47488)
Epoch: 163 | Batch_idx: 380 |  Loss: (0.1234) |  Loss2: (0.0000) | Acc: (95.00%) (46698/48768)
Epoch: 163 | Batch_idx: 390 |  Loss: (0.1236) |  Loss2: (0.0000) | Acc: (95.00%) (47876/50000)
# TEST : Loss: (0.4448) | Acc: (87.00%) (8724/10000)
percent tensor([0.5151, 0.5055, 0.5161, 0.5115, 0.5199, 0.5259, 0.5117, 0.5115, 0.5164,
        0.5071, 0.5162, 0.5116, 0.5072, 0.5104, 0.5139, 0.5122],
       device='cuda:0') torch.Size([16])
percent tensor([0.5095, 0.5048, 0.5072, 0.5078, 0.5061, 0.5088, 0.5063, 0.5104, 0.5126,
        0.5063, 0.5117, 0.5034, 0.5041, 0.5175, 0.5050, 0.5106],
       device='cuda:0') torch.Size([16])
percent tensor([0.5654, 0.5414, 0.5642, 0.5690, 0.5760, 0.5672, 0.5758, 0.5738, 0.5599,
        0.5509, 0.5566, 0.5578, 0.5155, 0.6084, 0.5563, 0.5740],
       device='cuda:0') torch.Size([16])
percent tensor([0.6127, 0.6312, 0.6137, 0.6062, 0.6020, 0.6158, 0.6195, 0.6015, 0.6307,
        0.6330, 0.6411, 0.6212, 0.6310, 0.6431, 0.6075, 0.6240],
       device='cuda:0') torch.Size([16])
percent tensor([0.5812, 0.6795, 0.5102, 0.6152, 0.5154, 0.6430, 0.6105, 0.3872, 0.6798,
        0.6536, 0.7189, 0.5947, 0.6536, 0.7142, 0.5534, 0.5995],
       device='cuda:0') torch.Size([16])
percent tensor([0.6109, 0.5995, 0.6345, 0.6159, 0.6764, 0.6323, 0.6253, 0.6569, 0.6200,
        0.6079, 0.5776, 0.5689, 0.5630, 0.5870, 0.5917, 0.6293],
       device='cuda:0') torch.Size([16])
percent tensor([0.5464, 0.5806, 0.7001, 0.6200, 0.7430, 0.7635, 0.6208, 0.6331, 0.6639,
        0.5892, 0.7008, 0.5880, 0.6183, 0.5960, 0.5583, 0.5241],
       device='cuda:0') torch.Size([16])
percent tensor([0.9998, 0.9997, 0.9997, 0.9998, 0.9993, 0.9991, 0.9997, 0.9998, 0.9998,
        0.9999, 1.0000, 0.9998, 0.9998, 0.9994, 0.9996, 0.9995],
       device='cuda:0') torch.Size([16])
Epoch: 164 | Batch_idx: 0 |  Loss: (0.1336) |  Loss2: (0.0000) | Acc: (96.00%) (124/128)
Epoch: 164 | Batch_idx: 10 |  Loss: (0.1236) |  Loss2: (0.0000) | Acc: (95.00%) (1350/1408)
Epoch: 164 | Batch_idx: 20 |  Loss: (0.1205) |  Loss2: (0.0000) | Acc: (96.00%) (2583/2688)
Epoch: 164 | Batch_idx: 30 |  Loss: (0.1271) |  Loss2: (0.0000) | Acc: (95.00%) (3804/3968)
Epoch: 164 | Batch_idx: 40 |  Loss: (0.1252) |  Loss2: (0.0000) | Acc: (95.00%) (5027/5248)
Epoch: 164 | Batch_idx: 50 |  Loss: (0.1242) |  Loss2: (0.0000) | Acc: (95.00%) (6259/6528)
Epoch: 164 | Batch_idx: 60 |  Loss: (0.1237) |  Loss2: (0.0000) | Acc: (95.00%) (7487/7808)
Epoch: 164 | Batch_idx: 70 |  Loss: (0.1223) |  Loss2: (0.0000) | Acc: (95.00%) (8715/9088)
Epoch: 164 | Batch_idx: 80 |  Loss: (0.1225) |  Loss2: (0.0000) | Acc: (95.00%) (9935/10368)
Epoch: 164 | Batch_idx: 90 |  Loss: (0.1210) |  Loss2: (0.0000) | Acc: (95.00%) (11170/11648)
Epoch: 164 | Batch_idx: 100 |  Loss: (0.1172) |  Loss2: (0.0000) | Acc: (96.00%) (12417/12928)
Epoch: 164 | Batch_idx: 110 |  Loss: (0.1182) |  Loss2: (0.0000) | Acc: (96.00%) (13644/14208)
Epoch: 164 | Batch_idx: 120 |  Loss: (0.1174) |  Loss2: (0.0000) | Acc: (96.00%) (14885/15488)
Epoch: 164 | Batch_idx: 130 |  Loss: (0.1179) |  Loss2: (0.0000) | Acc: (96.00%) (16107/16768)
Epoch: 164 | Batch_idx: 140 |  Loss: (0.1180) |  Loss2: (0.0000) | Acc: (96.00%) (17335/18048)
Epoch: 164 | Batch_idx: 150 |  Loss: (0.1175) |  Loss2: (0.0000) | Acc: (96.00%) (18568/19328)
Epoch: 164 | Batch_idx: 160 |  Loss: (0.1177) |  Loss2: (0.0000) | Acc: (96.00%) (19799/20608)
Epoch: 164 | Batch_idx: 170 |  Loss: (0.1173) |  Loss2: (0.0000) | Acc: (96.00%) (21035/21888)
Epoch: 164 | Batch_idx: 180 |  Loss: (0.1171) |  Loss2: (0.0000) | Acc: (96.00%) (22266/23168)
Epoch: 164 | Batch_idx: 190 |  Loss: (0.1166) |  Loss2: (0.0000) | Acc: (96.00%) (23504/24448)
Epoch: 164 | Batch_idx: 200 |  Loss: (0.1157) |  Loss2: (0.0000) | Acc: (96.00%) (24742/25728)
Epoch: 164 | Batch_idx: 210 |  Loss: (0.1155) |  Loss2: (0.0000) | Acc: (96.00%) (25969/27008)
Epoch: 164 | Batch_idx: 220 |  Loss: (0.1150) |  Loss2: (0.0000) | Acc: (96.00%) (27210/28288)
Epoch: 164 | Batch_idx: 230 |  Loss: (0.1154) |  Loss2: (0.0000) | Acc: (96.00%) (28436/29568)
Epoch: 164 | Batch_idx: 240 |  Loss: (0.1153) |  Loss2: (0.0000) | Acc: (96.00%) (29670/30848)
Epoch: 164 | Batch_idx: 250 |  Loss: (0.1156) |  Loss2: (0.0000) | Acc: (96.00%) (30892/32128)
Epoch: 164 | Batch_idx: 260 |  Loss: (0.1162) |  Loss2: (0.0000) | Acc: (96.00%) (32112/33408)
Epoch: 164 | Batch_idx: 270 |  Loss: (0.1160) |  Loss2: (0.0000) | Acc: (96.00%) (33340/34688)
Epoch: 164 | Batch_idx: 280 |  Loss: (0.1160) |  Loss2: (0.0000) | Acc: (96.00%) (34561/35968)
Epoch: 164 | Batch_idx: 290 |  Loss: (0.1159) |  Loss2: (0.0000) | Acc: (96.00%) (35789/37248)
Epoch: 164 | Batch_idx: 300 |  Loss: (0.1161) |  Loss2: (0.0000) | Acc: (96.00%) (37013/38528)
Epoch: 164 | Batch_idx: 310 |  Loss: (0.1166) |  Loss2: (0.0000) | Acc: (96.00%) (38240/39808)
Epoch: 164 | Batch_idx: 320 |  Loss: (0.1173) |  Loss2: (0.0000) | Acc: (96.00%) (39458/41088)
Epoch: 164 | Batch_idx: 330 |  Loss: (0.1174) |  Loss2: (0.0000) | Acc: (96.00%) (40683/42368)
Epoch: 164 | Batch_idx: 340 |  Loss: (0.1172) |  Loss2: (0.0000) | Acc: (96.00%) (41918/43648)
Epoch: 164 | Batch_idx: 350 |  Loss: (0.1174) |  Loss2: (0.0000) | Acc: (96.00%) (43138/44928)
Epoch: 164 | Batch_idx: 360 |  Loss: (0.1174) |  Loss2: (0.0000) | Acc: (96.00%) (44368/46208)
Epoch: 164 | Batch_idx: 370 |  Loss: (0.1179) |  Loss2: (0.0000) | Acc: (95.00%) (45585/47488)
Epoch: 164 | Batch_idx: 380 |  Loss: (0.1175) |  Loss2: (0.0000) | Acc: (96.00%) (46823/48768)
Epoch: 164 | Batch_idx: 390 |  Loss: (0.1182) |  Loss2: (0.0000) | Acc: (95.00%) (47990/50000)
# TEST : Loss: (0.4344) | Acc: (87.00%) (8759/10000)
percent tensor([0.5139, 0.5057, 0.5170, 0.5115, 0.5196, 0.5237, 0.5118, 0.5123, 0.5163,
        0.5073, 0.5158, 0.5121, 0.5067, 0.5102, 0.5134, 0.5117],
       device='cuda:0') torch.Size([16])
percent tensor([0.5085, 0.5034, 0.5098, 0.5078, 0.5078, 0.5092, 0.5054, 0.5105, 0.5121,
        0.5060, 0.5106, 0.5050, 0.5025, 0.5144, 0.5045, 0.5095],
       device='cuda:0') torch.Size([16])
percent tensor([0.5599, 0.5456, 0.5600, 0.5695, 0.5753, 0.5656, 0.5759, 0.5736, 0.5666,
        0.5488, 0.5593, 0.5558, 0.5135, 0.6117, 0.5575, 0.5706],
       device='cuda:0') torch.Size([16])
percent tensor([0.6125, 0.6333, 0.6132, 0.6116, 0.6039, 0.6133, 0.6222, 0.6037, 0.6309,
        0.6368, 0.6419, 0.6255, 0.6336, 0.6423, 0.6084, 0.6257],
       device='cuda:0') torch.Size([16])
percent tensor([0.5899, 0.6731, 0.5105, 0.6211, 0.5183, 0.6341, 0.6029, 0.3883, 0.6686,
        0.6348, 0.7011, 0.5813, 0.6724, 0.6983, 0.5522, 0.6036],
       device='cuda:0') torch.Size([16])
percent tensor([0.6230, 0.6174, 0.6376, 0.6195, 0.6745, 0.6405, 0.6370, 0.6615, 0.6300,
        0.6193, 0.5980, 0.5697, 0.5730, 0.6087, 0.6030, 0.6320],
       device='cuda:0') torch.Size([16])
percent tensor([0.5778, 0.6212, 0.7312, 0.6619, 0.7653, 0.7336, 0.6348, 0.6288, 0.7063,
        0.6337, 0.7184, 0.6057, 0.6551, 0.6312, 0.5792, 0.5232],
       device='cuda:0') torch.Size([16])
percent tensor([0.9997, 0.9996, 0.9997, 0.9998, 0.9996, 0.9994, 0.9995, 0.9998, 0.9997,
        0.9998, 1.0000, 0.9997, 0.9999, 0.9989, 0.9996, 0.9994],
       device='cuda:0') torch.Size([16])
Epoch: 165 | Batch_idx: 0 |  Loss: (0.1718) |  Loss2: (0.0000) | Acc: (92.00%) (119/128)
Epoch: 165 | Batch_idx: 10 |  Loss: (0.1302) |  Loss2: (0.0000) | Acc: (95.00%) (1346/1408)
Epoch: 165 | Batch_idx: 20 |  Loss: (0.1109) |  Loss2: (0.0000) | Acc: (96.00%) (2596/2688)
Epoch: 165 | Batch_idx: 30 |  Loss: (0.1040) |  Loss2: (0.0000) | Acc: (96.00%) (3839/3968)
Epoch: 165 | Batch_idx: 40 |  Loss: (0.1047) |  Loss2: (0.0000) | Acc: (96.00%) (5069/5248)
Epoch: 165 | Batch_idx: 50 |  Loss: (0.1031) |  Loss2: (0.0000) | Acc: (96.00%) (6313/6528)
Epoch: 165 | Batch_idx: 60 |  Loss: (0.1059) |  Loss2: (0.0000) | Acc: (96.00%) (7537/7808)
Epoch: 165 | Batch_idx: 70 |  Loss: (0.1081) |  Loss2: (0.0000) | Acc: (96.00%) (8763/9088)
Epoch: 165 | Batch_idx: 80 |  Loss: (0.1072) |  Loss2: (0.0000) | Acc: (96.00%) (10005/10368)
Epoch: 165 | Batch_idx: 90 |  Loss: (0.1079) |  Loss2: (0.0000) | Acc: (96.00%) (11238/11648)
Epoch: 165 | Batch_idx: 100 |  Loss: (0.1073) |  Loss2: (0.0000) | Acc: (96.00%) (12471/12928)
Epoch: 165 | Batch_idx: 110 |  Loss: (0.1082) |  Loss2: (0.0000) | Acc: (96.00%) (13690/14208)
Epoch: 165 | Batch_idx: 120 |  Loss: (0.1092) |  Loss2: (0.0000) | Acc: (96.00%) (14915/15488)
Epoch: 165 | Batch_idx: 130 |  Loss: (0.1091) |  Loss2: (0.0000) | Acc: (96.00%) (16154/16768)
Epoch: 165 | Batch_idx: 140 |  Loss: (0.1089) |  Loss2: (0.0000) | Acc: (96.00%) (17387/18048)
Epoch: 165 | Batch_idx: 150 |  Loss: (0.1104) |  Loss2: (0.0000) | Acc: (96.00%) (18611/19328)
Epoch: 165 | Batch_idx: 160 |  Loss: (0.1103) |  Loss2: (0.0000) | Acc: (96.00%) (19843/20608)
Epoch: 165 | Batch_idx: 170 |  Loss: (0.1122) |  Loss2: (0.0000) | Acc: (96.00%) (21055/21888)
Epoch: 165 | Batch_idx: 180 |  Loss: (0.1122) |  Loss2: (0.0000) | Acc: (96.00%) (22277/23168)
Epoch: 165 | Batch_idx: 190 |  Loss: (0.1122) |  Loss2: (0.0000) | Acc: (96.00%) (23510/24448)
Epoch: 165 | Batch_idx: 200 |  Loss: (0.1123) |  Loss2: (0.0000) | Acc: (96.00%) (24733/25728)
Epoch: 165 | Batch_idx: 210 |  Loss: (0.1135) |  Loss2: (0.0000) | Acc: (96.00%) (25954/27008)
Epoch: 165 | Batch_idx: 220 |  Loss: (0.1142) |  Loss2: (0.0000) | Acc: (96.00%) (27177/28288)
Epoch: 165 | Batch_idx: 230 |  Loss: (0.1140) |  Loss2: (0.0000) | Acc: (96.00%) (28410/29568)
Epoch: 165 | Batch_idx: 240 |  Loss: (0.1147) |  Loss2: (0.0000) | Acc: (96.00%) (29632/30848)
Epoch: 165 | Batch_idx: 250 |  Loss: (0.1148) |  Loss2: (0.0000) | Acc: (96.00%) (30864/32128)
Epoch: 165 | Batch_idx: 260 |  Loss: (0.1149) |  Loss2: (0.0000) | Acc: (96.00%) (32093/33408)
Epoch: 165 | Batch_idx: 270 |  Loss: (0.1145) |  Loss2: (0.0000) | Acc: (96.00%) (33327/34688)
Epoch: 165 | Batch_idx: 280 |  Loss: (0.1163) |  Loss2: (0.0000) | Acc: (96.00%) (34542/35968)
Epoch: 165 | Batch_idx: 290 |  Loss: (0.1161) |  Loss2: (0.0000) | Acc: (96.00%) (35771/37248)
Epoch: 165 | Batch_idx: 300 |  Loss: (0.1167) |  Loss2: (0.0000) | Acc: (96.00%) (36987/38528)
Epoch: 165 | Batch_idx: 310 |  Loss: (0.1165) |  Loss2: (0.0000) | Acc: (96.00%) (38218/39808)
Epoch: 165 | Batch_idx: 320 |  Loss: (0.1172) |  Loss2: (0.0000) | Acc: (95.00%) (39434/41088)
Epoch: 165 | Batch_idx: 330 |  Loss: (0.1176) |  Loss2: (0.0000) | Acc: (95.00%) (40655/42368)
Epoch: 165 | Batch_idx: 340 |  Loss: (0.1179) |  Loss2: (0.0000) | Acc: (95.00%) (41885/43648)
Epoch: 165 | Batch_idx: 350 |  Loss: (0.1181) |  Loss2: (0.0000) | Acc: (95.00%) (43106/44928)
Epoch: 165 | Batch_idx: 360 |  Loss: (0.1182) |  Loss2: (0.0000) | Acc: (95.00%) (44324/46208)
Epoch: 165 | Batch_idx: 370 |  Loss: (0.1182) |  Loss2: (0.0000) | Acc: (95.00%) (45553/47488)
Epoch: 165 | Batch_idx: 380 |  Loss: (0.1182) |  Loss2: (0.0000) | Acc: (95.00%) (46783/48768)
Epoch: 165 | Batch_idx: 390 |  Loss: (0.1188) |  Loss2: (0.0000) | Acc: (95.00%) (47955/50000)
=> saving checkpoint 'drive/app/torch/save_Schedule/checkpoint_165.pth.tar'
# TEST : Loss: (0.4272) | Acc: (87.00%) (8791/10000)
percent tensor([0.5154, 0.5060, 0.5169, 0.5127, 0.5199, 0.5244, 0.5120, 0.5127, 0.5168,
        0.5075, 0.5162, 0.5123, 0.5077, 0.5110, 0.5137, 0.5122],
       device='cuda:0') torch.Size([16])
percent tensor([0.5099, 0.5035, 0.5086, 0.5078, 0.5079, 0.5102, 0.5061, 0.5097, 0.5129,
        0.5058, 0.5119, 0.5048, 0.5041, 0.5152, 0.5053, 0.5102],
       device='cuda:0') torch.Size([16])
percent tensor([0.5656, 0.5480, 0.5577, 0.5772, 0.5760, 0.5709, 0.5816, 0.5722, 0.5666,
        0.5522, 0.5622, 0.5596, 0.5186, 0.6204, 0.5594, 0.5780],
       device='cuda:0') torch.Size([16])
percent tensor([0.6174, 0.6324, 0.6147, 0.6141, 0.6063, 0.6185, 0.6231, 0.6043, 0.6314,
        0.6355, 0.6444, 0.6245, 0.6338, 0.6410, 0.6109, 0.6286],
       device='cuda:0') torch.Size([16])
percent tensor([0.5919, 0.6737, 0.5198, 0.6200, 0.5202, 0.6403, 0.6046, 0.3959, 0.6890,
        0.6437, 0.7198, 0.5823, 0.6801, 0.6966, 0.5382, 0.6089],
       device='cuda:0') torch.Size([16])
percent tensor([0.6088, 0.6094, 0.6383, 0.6158, 0.6735, 0.6251, 0.6280, 0.6556, 0.6163,
        0.6044, 0.5765, 0.5700, 0.5686, 0.6038, 0.5963, 0.6213],
       device='cuda:0') torch.Size([16])
percent tensor([0.5507, 0.5976, 0.7376, 0.6657, 0.7680, 0.7342, 0.5876, 0.6412, 0.6488,
        0.5885, 0.6920, 0.6019, 0.6322, 0.5883, 0.5632, 0.5053],
       device='cuda:0') torch.Size([16])
percent tensor([0.9998, 0.9996, 0.9998, 0.9998, 0.9995, 0.9995, 0.9996, 0.9998, 0.9996,
        0.9998, 0.9999, 0.9998, 0.9999, 0.9989, 0.9995, 0.9995],
       device='cuda:0') torch.Size([16])
Epoch: 166 | Batch_idx: 0 |  Loss: (0.0758) |  Loss2: (0.0000) | Acc: (97.00%) (125/128)
Epoch: 166 | Batch_idx: 10 |  Loss: (0.1023) |  Loss2: (0.0000) | Acc: (96.00%) (1362/1408)
Epoch: 166 | Batch_idx: 20 |  Loss: (0.1107) |  Loss2: (0.0000) | Acc: (96.00%) (2590/2688)
Epoch: 166 | Batch_idx: 30 |  Loss: (0.1152) |  Loss2: (0.0000) | Acc: (96.00%) (3817/3968)
Epoch: 166 | Batch_idx: 40 |  Loss: (0.1123) |  Loss2: (0.0000) | Acc: (96.00%) (5050/5248)
Epoch: 166 | Batch_idx: 50 |  Loss: (0.1146) |  Loss2: (0.0000) | Acc: (96.00%) (6273/6528)
Epoch: 166 | Batch_idx: 60 |  Loss: (0.1138) |  Loss2: (0.0000) | Acc: (96.00%) (7503/7808)
Epoch: 166 | Batch_idx: 70 |  Loss: (0.1117) |  Loss2: (0.0000) | Acc: (96.00%) (8742/9088)
Epoch: 166 | Batch_idx: 80 |  Loss: (0.1082) |  Loss2: (0.0000) | Acc: (96.00%) (9980/10368)
Epoch: 166 | Batch_idx: 90 |  Loss: (0.1094) |  Loss2: (0.0000) | Acc: (96.00%) (11211/11648)
Epoch: 166 | Batch_idx: 100 |  Loss: (0.1077) |  Loss2: (0.0000) | Acc: (96.00%) (12448/12928)
Epoch: 166 | Batch_idx: 110 |  Loss: (0.1073) |  Loss2: (0.0000) | Acc: (96.00%) (13682/14208)
Epoch: 166 | Batch_idx: 120 |  Loss: (0.1077) |  Loss2: (0.0000) | Acc: (96.00%) (14911/15488)
Epoch: 166 | Batch_idx: 130 |  Loss: (0.1083) |  Loss2: (0.0000) | Acc: (96.00%) (16137/16768)
Epoch: 166 | Batch_idx: 140 |  Loss: (0.1084) |  Loss2: (0.0000) | Acc: (96.00%) (17370/18048)
Epoch: 166 | Batch_idx: 150 |  Loss: (0.1090) |  Loss2: (0.0000) | Acc: (96.00%) (18597/19328)
Epoch: 166 | Batch_idx: 160 |  Loss: (0.1094) |  Loss2: (0.0000) | Acc: (96.00%) (19830/20608)
Epoch: 166 | Batch_idx: 170 |  Loss: (0.1094) |  Loss2: (0.0000) | Acc: (96.00%) (21062/21888)
Epoch: 166 | Batch_idx: 180 |  Loss: (0.1095) |  Loss2: (0.0000) | Acc: (96.00%) (22301/23168)
Epoch: 166 | Batch_idx: 190 |  Loss: (0.1097) |  Loss2: (0.0000) | Acc: (96.00%) (23534/24448)
Epoch: 166 | Batch_idx: 200 |  Loss: (0.1089) |  Loss2: (0.0000) | Acc: (96.00%) (24777/25728)
Epoch: 166 | Batch_idx: 210 |  Loss: (0.1085) |  Loss2: (0.0000) | Acc: (96.00%) (26007/27008)
Epoch: 166 | Batch_idx: 220 |  Loss: (0.1083) |  Loss2: (0.0000) | Acc: (96.00%) (27248/28288)
Epoch: 166 | Batch_idx: 230 |  Loss: (0.1083) |  Loss2: (0.0000) | Acc: (96.00%) (28483/29568)
Epoch: 166 | Batch_idx: 240 |  Loss: (0.1085) |  Loss2: (0.0000) | Acc: (96.00%) (29720/30848)
Epoch: 166 | Batch_idx: 250 |  Loss: (0.1088) |  Loss2: (0.0000) | Acc: (96.00%) (30940/32128)
Epoch: 166 | Batch_idx: 260 |  Loss: (0.1085) |  Loss2: (0.0000) | Acc: (96.00%) (32177/33408)
Epoch: 166 | Batch_idx: 270 |  Loss: (0.1087) |  Loss2: (0.0000) | Acc: (96.00%) (33412/34688)
Epoch: 166 | Batch_idx: 280 |  Loss: (0.1092) |  Loss2: (0.0000) | Acc: (96.00%) (34638/35968)
Epoch: 166 | Batch_idx: 290 |  Loss: (0.1094) |  Loss2: (0.0000) | Acc: (96.00%) (35865/37248)
Epoch: 166 | Batch_idx: 300 |  Loss: (0.1096) |  Loss2: (0.0000) | Acc: (96.00%) (37089/38528)
Epoch: 166 | Batch_idx: 310 |  Loss: (0.1104) |  Loss2: (0.0000) | Acc: (96.00%) (38308/39808)
Epoch: 166 | Batch_idx: 320 |  Loss: (0.1101) |  Loss2: (0.0000) | Acc: (96.00%) (39538/41088)
Epoch: 166 | Batch_idx: 330 |  Loss: (0.1103) |  Loss2: (0.0000) | Acc: (96.00%) (40763/42368)
Epoch: 166 | Batch_idx: 340 |  Loss: (0.1103) |  Loss2: (0.0000) | Acc: (96.00%) (41994/43648)
Epoch: 166 | Batch_idx: 350 |  Loss: (0.1102) |  Loss2: (0.0000) | Acc: (96.00%) (43221/44928)
Epoch: 166 | Batch_idx: 360 |  Loss: (0.1109) |  Loss2: (0.0000) | Acc: (96.00%) (44439/46208)
Epoch: 166 | Batch_idx: 370 |  Loss: (0.1110) |  Loss2: (0.0000) | Acc: (96.00%) (45676/47488)
Epoch: 166 | Batch_idx: 380 |  Loss: (0.1112) |  Loss2: (0.0000) | Acc: (96.00%) (46904/48768)
Epoch: 166 | Batch_idx: 390 |  Loss: (0.1107) |  Loss2: (0.0000) | Acc: (96.00%) (48103/50000)
# TEST : Loss: (0.4123) | Acc: (87.00%) (8777/10000)
percent tensor([0.5152, 0.5058, 0.5157, 0.5121, 0.5184, 0.5245, 0.5115, 0.5124, 0.5163,
        0.5070, 0.5164, 0.5109, 0.5078, 0.5111, 0.5137, 0.5125],
       device='cuda:0') torch.Size([16])
percent tensor([0.5094, 0.5040, 0.5096, 0.5084, 0.5084, 0.5096, 0.5063, 0.5102, 0.5133,
        0.5059, 0.5111, 0.5054, 0.5041, 0.5163, 0.5047, 0.5098],
       device='cuda:0') torch.Size([16])
percent tensor([0.5610, 0.5410, 0.5585, 0.5747, 0.5742, 0.5594, 0.5742, 0.5728, 0.5663,
        0.5486, 0.5566, 0.5604, 0.5189, 0.6132, 0.5513, 0.5708],
       device='cuda:0') torch.Size([16])
percent tensor([0.6146, 0.6347, 0.6137, 0.6126, 0.6019, 0.6183, 0.6214, 0.6029, 0.6284,
        0.6351, 0.6432, 0.6247, 0.6332, 0.6437, 0.6119, 0.6254],
       device='cuda:0') torch.Size([16])
percent tensor([0.5932, 0.6799, 0.5383, 0.6190, 0.5396, 0.6337, 0.6209, 0.3888, 0.6864,
        0.6586, 0.7271, 0.5967, 0.6732, 0.6919, 0.5482, 0.6132],
       device='cuda:0') torch.Size([16])
percent tensor([0.6125, 0.6097, 0.6400, 0.6178, 0.6775, 0.6339, 0.6351, 0.6650, 0.6219,
        0.6049, 0.5753, 0.5697, 0.5702, 0.5980, 0.6049, 0.6257],
       device='cuda:0') torch.Size([16])
percent tensor([0.5446, 0.5875, 0.7302, 0.6511, 0.7586, 0.7582, 0.5840, 0.6457, 0.6448,
        0.5869, 0.6914, 0.5637, 0.6260, 0.5911, 0.5759, 0.5130],
       device='cuda:0') torch.Size([16])
percent tensor([0.9997, 0.9995, 0.9998, 0.9998, 0.9996, 0.9994, 0.9996, 0.9997, 0.9998,
        0.9999, 0.9999, 0.9998, 0.9998, 0.9991, 0.9997, 0.9994],
       device='cuda:0') torch.Size([16])
Epoch: 167 | Batch_idx: 0 |  Loss: (0.0670) |  Loss2: (0.0000) | Acc: (98.00%) (126/128)
Epoch: 167 | Batch_idx: 10 |  Loss: (0.1098) |  Loss2: (0.0000) | Acc: (96.00%) (1358/1408)
Epoch: 167 | Batch_idx: 20 |  Loss: (0.1043) |  Loss2: (0.0000) | Acc: (96.00%) (2588/2688)
Epoch: 167 | Batch_idx: 30 |  Loss: (0.0999) |  Loss2: (0.0000) | Acc: (96.00%) (3832/3968)
Epoch: 167 | Batch_idx: 40 |  Loss: (0.0978) |  Loss2: (0.0000) | Acc: (96.00%) (5074/5248)
Epoch: 167 | Batch_idx: 50 |  Loss: (0.1031) |  Loss2: (0.0000) | Acc: (96.00%) (6303/6528)
Epoch: 167 | Batch_idx: 60 |  Loss: (0.1005) |  Loss2: (0.0000) | Acc: (96.00%) (7548/7808)
Epoch: 167 | Batch_idx: 70 |  Loss: (0.1006) |  Loss2: (0.0000) | Acc: (96.00%) (8781/9088)
Epoch: 167 | Batch_idx: 80 |  Loss: (0.0998) |  Loss2: (0.0000) | Acc: (96.00%) (10017/10368)
Epoch: 167 | Batch_idx: 90 |  Loss: (0.1015) |  Loss2: (0.0000) | Acc: (96.00%) (11244/11648)
Epoch: 167 | Batch_idx: 100 |  Loss: (0.1010) |  Loss2: (0.0000) | Acc: (96.00%) (12482/12928)
Epoch: 167 | Batch_idx: 110 |  Loss: (0.1002) |  Loss2: (0.0000) | Acc: (96.00%) (13721/14208)
Epoch: 167 | Batch_idx: 120 |  Loss: (0.1009) |  Loss2: (0.0000) | Acc: (96.00%) (14938/15488)
Epoch: 167 | Batch_idx: 130 |  Loss: (0.1011) |  Loss2: (0.0000) | Acc: (96.00%) (16169/16768)
Epoch: 167 | Batch_idx: 140 |  Loss: (0.1015) |  Loss2: (0.0000) | Acc: (96.00%) (17402/18048)
Epoch: 167 | Batch_idx: 150 |  Loss: (0.1014) |  Loss2: (0.0000) | Acc: (96.00%) (18639/19328)
Epoch: 167 | Batch_idx: 160 |  Loss: (0.1026) |  Loss2: (0.0000) | Acc: (96.00%) (19869/20608)
Epoch: 167 | Batch_idx: 170 |  Loss: (0.1032) |  Loss2: (0.0000) | Acc: (96.00%) (21104/21888)
Epoch: 167 | Batch_idx: 180 |  Loss: (0.1035) |  Loss2: (0.0000) | Acc: (96.00%) (22333/23168)
Epoch: 167 | Batch_idx: 190 |  Loss: (0.1033) |  Loss2: (0.0000) | Acc: (96.00%) (23566/24448)
Epoch: 167 | Batch_idx: 200 |  Loss: (0.1035) |  Loss2: (0.0000) | Acc: (96.00%) (24798/25728)
Epoch: 167 | Batch_idx: 210 |  Loss: (0.1039) |  Loss2: (0.0000) | Acc: (96.00%) (26030/27008)
Epoch: 167 | Batch_idx: 220 |  Loss: (0.1039) |  Loss2: (0.0000) | Acc: (96.00%) (27266/28288)
Epoch: 167 | Batch_idx: 230 |  Loss: (0.1050) |  Loss2: (0.0000) | Acc: (96.00%) (28480/29568)
Epoch: 167 | Batch_idx: 240 |  Loss: (0.1048) |  Loss2: (0.0000) | Acc: (96.00%) (29716/30848)
Epoch: 167 | Batch_idx: 250 |  Loss: (0.1048) |  Loss2: (0.0000) | Acc: (96.00%) (30948/32128)
Epoch: 167 | Batch_idx: 260 |  Loss: (0.1049) |  Loss2: (0.0000) | Acc: (96.00%) (32190/33408)
Epoch: 167 | Batch_idx: 270 |  Loss: (0.1048) |  Loss2: (0.0000) | Acc: (96.00%) (33430/34688)
Epoch: 167 | Batch_idx: 280 |  Loss: (0.1057) |  Loss2: (0.0000) | Acc: (96.00%) (34649/35968)
Epoch: 167 | Batch_idx: 290 |  Loss: (0.1058) |  Loss2: (0.0000) | Acc: (96.00%) (35886/37248)
Epoch: 167 | Batch_idx: 300 |  Loss: (0.1065) |  Loss2: (0.0000) | Acc: (96.00%) (37111/38528)
Epoch: 167 | Batch_idx: 310 |  Loss: (0.1067) |  Loss2: (0.0000) | Acc: (96.00%) (38335/39808)
Epoch: 167 | Batch_idx: 320 |  Loss: (0.1069) |  Loss2: (0.0000) | Acc: (96.00%) (39561/41088)
Epoch: 167 | Batch_idx: 330 |  Loss: (0.1071) |  Loss2: (0.0000) | Acc: (96.00%) (40796/42368)
Epoch: 167 | Batch_idx: 340 |  Loss: (0.1078) |  Loss2: (0.0000) | Acc: (96.00%) (42022/43648)
Epoch: 167 | Batch_idx: 350 |  Loss: (0.1089) |  Loss2: (0.0000) | Acc: (96.00%) (43238/44928)
Epoch: 167 | Batch_idx: 360 |  Loss: (0.1090) |  Loss2: (0.0000) | Acc: (96.00%) (44461/46208)
Epoch: 167 | Batch_idx: 370 |  Loss: (0.1096) |  Loss2: (0.0000) | Acc: (96.00%) (45680/47488)
Epoch: 167 | Batch_idx: 380 |  Loss: (0.1098) |  Loss2: (0.0000) | Acc: (96.00%) (46911/48768)
Epoch: 167 | Batch_idx: 390 |  Loss: (0.1103) |  Loss2: (0.0000) | Acc: (96.00%) (48085/50000)
# TEST : Loss: (0.4325) | Acc: (87.00%) (8771/10000)
percent tensor([0.5153, 0.5064, 0.5151, 0.5119, 0.5182, 0.5244, 0.5117, 0.5123, 0.5167,
        0.5072, 0.5174, 0.5105, 0.5079, 0.5117, 0.5141, 0.5134],
       device='cuda:0') torch.Size([16])
percent tensor([0.5089, 0.5040, 0.5070, 0.5075, 0.5064, 0.5102, 0.5057, 0.5100, 0.5121,
        0.5055, 0.5116, 0.5023, 0.5035, 0.5159, 0.5053, 0.5107],
       device='cuda:0') torch.Size([16])
percent tensor([0.5611, 0.5404, 0.5546, 0.5746, 0.5720, 0.5660, 0.5725, 0.5685, 0.5597,
        0.5457, 0.5561, 0.5545, 0.5155, 0.6066, 0.5549, 0.5756],
       device='cuda:0') torch.Size([16])
percent tensor([0.6142, 0.6339, 0.6181, 0.6157, 0.6070, 0.6186, 0.6235, 0.6053, 0.6353,
        0.6370, 0.6448, 0.6286, 0.6359, 0.6478, 0.6113, 0.6279],
       device='cuda:0') torch.Size([16])
percent tensor([0.5986, 0.6853, 0.5613, 0.6347, 0.5596, 0.6436, 0.6359, 0.4086, 0.7100,
        0.6637, 0.7338, 0.6259, 0.6807, 0.7092, 0.5675, 0.6164],
       device='cuda:0') torch.Size([16])
percent tensor([0.6088, 0.6068, 0.6267, 0.6171, 0.6708, 0.6244, 0.6258, 0.6589, 0.6116,
        0.6084, 0.5782, 0.5602, 0.5678, 0.5928, 0.5988, 0.6259],
       device='cuda:0') torch.Size([16])
percent tensor([0.5390, 0.6044, 0.7084, 0.6196, 0.7243, 0.7319, 0.5954, 0.6354, 0.6308,
        0.6120, 0.6973, 0.5742, 0.6529, 0.6009, 0.5744, 0.5098],
       device='cuda:0') torch.Size([16])
percent tensor([0.9998, 0.9996, 0.9997, 0.9997, 0.9995, 0.9990, 0.9997, 0.9997, 0.9997,
        0.9998, 1.0000, 0.9998, 0.9998, 0.9992, 0.9996, 0.9994],
       device='cuda:0') torch.Size([16])
Epoch: 168 | Batch_idx: 0 |  Loss: (0.1075) |  Loss2: (0.0000) | Acc: (96.00%) (123/128)
Epoch: 168 | Batch_idx: 10 |  Loss: (0.1142) |  Loss2: (0.0000) | Acc: (95.00%) (1348/1408)
Epoch: 168 | Batch_idx: 20 |  Loss: (0.1084) |  Loss2: (0.0000) | Acc: (96.00%) (2586/2688)
Epoch: 168 | Batch_idx: 30 |  Loss: (0.1093) |  Loss2: (0.0000) | Acc: (96.00%) (3816/3968)
Epoch: 168 | Batch_idx: 40 |  Loss: (0.1087) |  Loss2: (0.0000) | Acc: (96.00%) (5047/5248)
Epoch: 168 | Batch_idx: 50 |  Loss: (0.1039) |  Loss2: (0.0000) | Acc: (96.00%) (6297/6528)
Epoch: 168 | Batch_idx: 60 |  Loss: (0.1062) |  Loss2: (0.0000) | Acc: (96.00%) (7522/7808)
Epoch: 168 | Batch_idx: 70 |  Loss: (0.1051) |  Loss2: (0.0000) | Acc: (96.00%) (8760/9088)
Epoch: 168 | Batch_idx: 80 |  Loss: (0.1058) |  Loss2: (0.0000) | Acc: (96.00%) (9986/10368)
Epoch: 168 | Batch_idx: 90 |  Loss: (0.1066) |  Loss2: (0.0000) | Acc: (96.00%) (11216/11648)
Epoch: 168 | Batch_idx: 100 |  Loss: (0.1084) |  Loss2: (0.0000) | Acc: (96.00%) (12443/12928)
Epoch: 168 | Batch_idx: 110 |  Loss: (0.1083) |  Loss2: (0.0000) | Acc: (96.00%) (13676/14208)
Epoch: 168 | Batch_idx: 120 |  Loss: (0.1074) |  Loss2: (0.0000) | Acc: (96.00%) (14910/15488)
Epoch: 168 | Batch_idx: 130 |  Loss: (0.1087) |  Loss2: (0.0000) | Acc: (96.00%) (16133/16768)
Epoch: 168 | Batch_idx: 140 |  Loss: (0.1088) |  Loss2: (0.0000) | Acc: (96.00%) (17367/18048)
Epoch: 168 | Batch_idx: 150 |  Loss: (0.1078) |  Loss2: (0.0000) | Acc: (96.00%) (18606/19328)
Epoch: 168 | Batch_idx: 160 |  Loss: (0.1078) |  Loss2: (0.0000) | Acc: (96.00%) (19837/20608)
Epoch: 168 | Batch_idx: 170 |  Loss: (0.1086) |  Loss2: (0.0000) | Acc: (96.00%) (21070/21888)
Epoch: 168 | Batch_idx: 180 |  Loss: (0.1081) |  Loss2: (0.0000) | Acc: (96.00%) (22300/23168)
Epoch: 168 | Batch_idx: 190 |  Loss: (0.1092) |  Loss2: (0.0000) | Acc: (96.00%) (23523/24448)
Epoch: 168 | Batch_idx: 200 |  Loss: (0.1089) |  Loss2: (0.0000) | Acc: (96.00%) (24752/25728)
Epoch: 168 | Batch_idx: 210 |  Loss: (0.1094) |  Loss2: (0.0000) | Acc: (96.00%) (25981/27008)
Epoch: 168 | Batch_idx: 220 |  Loss: (0.1089) |  Loss2: (0.0000) | Acc: (96.00%) (27217/28288)
Epoch: 168 | Batch_idx: 230 |  Loss: (0.1092) |  Loss2: (0.0000) | Acc: (96.00%) (28446/29568)
Epoch: 168 | Batch_idx: 240 |  Loss: (0.1088) |  Loss2: (0.0000) | Acc: (96.00%) (29682/30848)
Epoch: 168 | Batch_idx: 250 |  Loss: (0.1091) |  Loss2: (0.0000) | Acc: (96.00%) (30913/32128)
Epoch: 168 | Batch_idx: 260 |  Loss: (0.1091) |  Loss2: (0.0000) | Acc: (96.00%) (32145/33408)
Epoch: 168 | Batch_idx: 270 |  Loss: (0.1093) |  Loss2: (0.0000) | Acc: (96.00%) (33367/34688)
Epoch: 168 | Batch_idx: 280 |  Loss: (0.1086) |  Loss2: (0.0000) | Acc: (96.00%) (34612/35968)
Epoch: 168 | Batch_idx: 290 |  Loss: (0.1084) |  Loss2: (0.0000) | Acc: (96.00%) (35850/37248)
Epoch: 168 | Batch_idx: 300 |  Loss: (0.1086) |  Loss2: (0.0000) | Acc: (96.00%) (37087/38528)
Epoch: 168 | Batch_idx: 310 |  Loss: (0.1085) |  Loss2: (0.0000) | Acc: (96.00%) (38318/39808)
Epoch: 168 | Batch_idx: 320 |  Loss: (0.1086) |  Loss2: (0.0000) | Acc: (96.00%) (39553/41088)
Epoch: 168 | Batch_idx: 330 |  Loss: (0.1087) |  Loss2: (0.0000) | Acc: (96.00%) (40781/42368)
Epoch: 168 | Batch_idx: 340 |  Loss: (0.1092) |  Loss2: (0.0000) | Acc: (96.00%) (42004/43648)
Epoch: 168 | Batch_idx: 350 |  Loss: (0.1097) |  Loss2: (0.0000) | Acc: (96.00%) (43222/44928)
Epoch: 168 | Batch_idx: 360 |  Loss: (0.1096) |  Loss2: (0.0000) | Acc: (96.00%) (44455/46208)
Epoch: 168 | Batch_idx: 370 |  Loss: (0.1097) |  Loss2: (0.0000) | Acc: (96.00%) (45689/47488)
Epoch: 168 | Batch_idx: 380 |  Loss: (0.1098) |  Loss2: (0.0000) | Acc: (96.00%) (46913/48768)
Epoch: 168 | Batch_idx: 390 |  Loss: (0.1109) |  Loss2: (0.0000) | Acc: (96.00%) (48082/50000)
# TEST : Loss: (0.5001) | Acc: (86.00%) (8638/10000)
percent tensor([0.5159, 0.5064, 0.5176, 0.5121, 0.5209, 0.5252, 0.5124, 0.5130, 0.5174,
        0.5079, 0.5172, 0.5130, 0.5084, 0.5095, 0.5143, 0.5129],
       device='cuda:0') torch.Size([16])
percent tensor([0.5096, 0.5043, 0.5093, 0.5084, 0.5081, 0.5105, 0.5064, 0.5116, 0.5133,
        0.5065, 0.5121, 0.5046, 0.5036, 0.5168, 0.5056, 0.5110],
       device='cuda:0') torch.Size([16])
percent tensor([0.5676, 0.5478, 0.5583, 0.5750, 0.5770, 0.5707, 0.5820, 0.5764, 0.5719,
        0.5540, 0.5646, 0.5568, 0.5200, 0.6217, 0.5594, 0.5784],
       device='cuda:0') torch.Size([16])
percent tensor([0.6158, 0.6337, 0.6161, 0.6105, 0.6054, 0.6203, 0.6219, 0.6018, 0.6293,
        0.6370, 0.6455, 0.6269, 0.6332, 0.6436, 0.6107, 0.6278],
       device='cuda:0') torch.Size([16])
percent tensor([0.5800, 0.6659, 0.5310, 0.6037, 0.5258, 0.6284, 0.6070, 0.3828, 0.6824,
        0.6411, 0.7213, 0.5920, 0.6644, 0.6902, 0.5330, 0.6025],
       device='cuda:0') torch.Size([16])
percent tensor([0.6270, 0.6242, 0.6423, 0.6234, 0.6807, 0.6390, 0.6437, 0.6589, 0.6256,
        0.6222, 0.5925, 0.5771, 0.5793, 0.6025, 0.6163, 0.6305],
       device='cuda:0') torch.Size([16])
percent tensor([0.5446, 0.6080, 0.7250, 0.6557, 0.7457, 0.7465, 0.6051, 0.6333, 0.6455,
        0.6015, 0.6921, 0.5809, 0.6344, 0.5782, 0.5770, 0.5154],
       device='cuda:0') torch.Size([16])
percent tensor([0.9998, 0.9997, 0.9998, 0.9999, 0.9997, 0.9993, 0.9998, 0.9997, 0.9999,
        0.9999, 1.0000, 0.9999, 0.9999, 0.9986, 0.9997, 0.9993],
       device='cuda:0') torch.Size([16])
Epoch: 169 | Batch_idx: 0 |  Loss: (0.1139) |  Loss2: (0.0000) | Acc: (95.00%) (122/128)
Epoch: 169 | Batch_idx: 10 |  Loss: (0.1177) |  Loss2: (0.0000) | Acc: (95.00%) (1345/1408)
Epoch: 169 | Batch_idx: 20 |  Loss: (0.1138) |  Loss2: (0.0000) | Acc: (95.00%) (2572/2688)
Epoch: 169 | Batch_idx: 30 |  Loss: (0.1170) |  Loss2: (0.0000) | Acc: (95.00%) (3796/3968)
Epoch: 169 | Batch_idx: 40 |  Loss: (0.1120) |  Loss2: (0.0000) | Acc: (95.00%) (5035/5248)
Epoch: 169 | Batch_idx: 50 |  Loss: (0.1091) |  Loss2: (0.0000) | Acc: (96.00%) (6276/6528)
Epoch: 169 | Batch_idx: 60 |  Loss: (0.1084) |  Loss2: (0.0000) | Acc: (96.00%) (7510/7808)
Epoch: 169 | Batch_idx: 70 |  Loss: (0.1088) |  Loss2: (0.0000) | Acc: (96.00%) (8743/9088)
Epoch: 169 | Batch_idx: 80 |  Loss: (0.1109) |  Loss2: (0.0000) | Acc: (96.00%) (9966/10368)
Epoch: 169 | Batch_idx: 90 |  Loss: (0.1081) |  Loss2: (0.0000) | Acc: (96.00%) (11213/11648)
Epoch: 169 | Batch_idx: 100 |  Loss: (0.1087) |  Loss2: (0.0000) | Acc: (96.00%) (12446/12928)
Epoch: 169 | Batch_idx: 110 |  Loss: (0.1096) |  Loss2: (0.0000) | Acc: (96.00%) (13669/14208)
Epoch: 169 | Batch_idx: 120 |  Loss: (0.1104) |  Loss2: (0.0000) | Acc: (96.00%) (14899/15488)
Epoch: 169 | Batch_idx: 130 |  Loss: (0.1106) |  Loss2: (0.0000) | Acc: (96.00%) (16127/16768)
Epoch: 169 | Batch_idx: 140 |  Loss: (0.1102) |  Loss2: (0.0000) | Acc: (96.00%) (17355/18048)
Epoch: 169 | Batch_idx: 150 |  Loss: (0.1098) |  Loss2: (0.0000) | Acc: (96.00%) (18587/19328)
Epoch: 169 | Batch_idx: 160 |  Loss: (0.1099) |  Loss2: (0.0000) | Acc: (96.00%) (19817/20608)
Epoch: 169 | Batch_idx: 170 |  Loss: (0.1096) |  Loss2: (0.0000) | Acc: (96.00%) (21059/21888)
Epoch: 169 | Batch_idx: 180 |  Loss: (0.1094) |  Loss2: (0.0000) | Acc: (96.00%) (22295/23168)
Epoch: 169 | Batch_idx: 190 |  Loss: (0.1088) |  Loss2: (0.0000) | Acc: (96.00%) (23526/24448)
Epoch: 169 | Batch_idx: 200 |  Loss: (0.1084) |  Loss2: (0.0000) | Acc: (96.00%) (24755/25728)
Epoch: 169 | Batch_idx: 210 |  Loss: (0.1087) |  Loss2: (0.0000) | Acc: (96.00%) (25987/27008)
Epoch: 169 | Batch_idx: 220 |  Loss: (0.1088) |  Loss2: (0.0000) | Acc: (96.00%) (27224/28288)
Epoch: 169 | Batch_idx: 230 |  Loss: (0.1091) |  Loss2: (0.0000) | Acc: (96.00%) (28465/29568)
Epoch: 169 | Batch_idx: 240 |  Loss: (0.1084) |  Loss2: (0.0000) | Acc: (96.00%) (29710/30848)
Epoch: 169 | Batch_idx: 250 |  Loss: (0.1080) |  Loss2: (0.0000) | Acc: (96.00%) (30945/32128)
Epoch: 169 | Batch_idx: 260 |  Loss: (0.1083) |  Loss2: (0.0000) | Acc: (96.00%) (32167/33408)
Epoch: 169 | Batch_idx: 270 |  Loss: (0.1085) |  Loss2: (0.0000) | Acc: (96.00%) (33399/34688)
Epoch: 169 | Batch_idx: 280 |  Loss: (0.1080) |  Loss2: (0.0000) | Acc: (96.00%) (34644/35968)
Epoch: 169 | Batch_idx: 290 |  Loss: (0.1082) |  Loss2: (0.0000) | Acc: (96.00%) (35880/37248)
Epoch: 169 | Batch_idx: 300 |  Loss: (0.1082) |  Loss2: (0.0000) | Acc: (96.00%) (37107/38528)
Epoch: 169 | Batch_idx: 310 |  Loss: (0.1084) |  Loss2: (0.0000) | Acc: (96.00%) (38341/39808)
Epoch: 169 | Batch_idx: 320 |  Loss: (0.1087) |  Loss2: (0.0000) | Acc: (96.00%) (39571/41088)
Epoch: 169 | Batch_idx: 330 |  Loss: (0.1084) |  Loss2: (0.0000) | Acc: (96.00%) (40799/42368)
Epoch: 169 | Batch_idx: 340 |  Loss: (0.1086) |  Loss2: (0.0000) | Acc: (96.00%) (42023/43648)
Epoch: 169 | Batch_idx: 350 |  Loss: (0.1090) |  Loss2: (0.0000) | Acc: (96.00%) (43247/44928)
Epoch: 169 | Batch_idx: 360 |  Loss: (0.1088) |  Loss2: (0.0000) | Acc: (96.00%) (44479/46208)
Epoch: 169 | Batch_idx: 370 |  Loss: (0.1089) |  Loss2: (0.0000) | Acc: (96.00%) (45704/47488)
Epoch: 169 | Batch_idx: 380 |  Loss: (0.1087) |  Loss2: (0.0000) | Acc: (96.00%) (46934/48768)
Epoch: 169 | Batch_idx: 390 |  Loss: (0.1087) |  Loss2: (0.0000) | Acc: (96.00%) (48124/50000)
# TEST : Loss: (0.4083) | Acc: (88.00%) (8834/10000)
percent tensor([0.5142, 0.5061, 0.5167, 0.5115, 0.5191, 0.5241, 0.5117, 0.5125, 0.5165,
        0.5070, 0.5164, 0.5112, 0.5071, 0.5111, 0.5135, 0.5123],
       device='cuda:0') torch.Size([16])
percent tensor([0.5092, 0.5038, 0.5085, 0.5085, 0.5069, 0.5105, 0.5054, 0.5109, 0.5120,
        0.5060, 0.5109, 0.5041, 0.5033, 0.5158, 0.5054, 0.5108],
       device='cuda:0') torch.Size([16])
percent tensor([0.5612, 0.5427, 0.5583, 0.5705, 0.5739, 0.5653, 0.5747, 0.5728, 0.5621,
        0.5464, 0.5539, 0.5562, 0.5139, 0.6103, 0.5540, 0.5730],
       device='cuda:0') torch.Size([16])
percent tensor([0.6129, 0.6297, 0.6168, 0.6131, 0.6060, 0.6176, 0.6188, 0.6030, 0.6311,
        0.6347, 0.6429, 0.6255, 0.6332, 0.6401, 0.6104, 0.6260],
       device='cuda:0') torch.Size([16])
percent tensor([0.5934, 0.6715, 0.5252, 0.6062, 0.5316, 0.6245, 0.6206, 0.3880, 0.7095,
        0.6523, 0.7318, 0.5858, 0.6687, 0.7231, 0.5475, 0.6069],
       device='cuda:0') torch.Size([16])
percent tensor([0.6214, 0.6127, 0.6431, 0.6209, 0.6803, 0.6357, 0.6278, 0.6613, 0.6144,
        0.6136, 0.5797, 0.5701, 0.5719, 0.5904, 0.6011, 0.6282],
       device='cuda:0') torch.Size([16])
percent tensor([0.5322, 0.5853, 0.7259, 0.6232, 0.7422, 0.7321, 0.6061, 0.6410, 0.6502,
        0.5905, 0.6771, 0.5724, 0.6352, 0.5624, 0.5524, 0.5207],
       device='cuda:0') torch.Size([16])
percent tensor([0.9997, 0.9995, 0.9998, 0.9997, 0.9997, 0.9989, 0.9996, 0.9997, 0.9998,
        0.9997, 0.9999, 0.9998, 0.9998, 0.9993, 0.9995, 0.9992],
       device='cuda:0') torch.Size([16])
Epoch: 170 | Batch_idx: 0 |  Loss: (0.0788) |  Loss2: (0.0000) | Acc: (98.00%) (126/128)
Epoch: 170 | Batch_idx: 10 |  Loss: (0.0873) |  Loss2: (0.0000) | Acc: (97.00%) (1371/1408)
Epoch: 170 | Batch_idx: 20 |  Loss: (0.0915) |  Loss2: (0.0000) | Acc: (97.00%) (2615/2688)
Epoch: 170 | Batch_idx: 30 |  Loss: (0.0911) |  Loss2: (0.0000) | Acc: (97.00%) (3852/3968)
Epoch: 170 | Batch_idx: 40 |  Loss: (0.0906) |  Loss2: (0.0000) | Acc: (96.00%) (5089/5248)
Epoch: 170 | Batch_idx: 50 |  Loss: (0.0936) |  Loss2: (0.0000) | Acc: (96.00%) (6318/6528)
Epoch: 170 | Batch_idx: 60 |  Loss: (0.0965) |  Loss2: (0.0000) | Acc: (96.00%) (7548/7808)
Epoch: 170 | Batch_idx: 70 |  Loss: (0.0976) |  Loss2: (0.0000) | Acc: (96.00%) (8782/9088)
Epoch: 170 | Batch_idx: 80 |  Loss: (0.0986) |  Loss2: (0.0000) | Acc: (96.00%) (10023/10368)
Epoch: 170 | Batch_idx: 90 |  Loss: (0.0977) |  Loss2: (0.0000) | Acc: (96.00%) (11270/11648)
Epoch: 170 | Batch_idx: 100 |  Loss: (0.0962) |  Loss2: (0.0000) | Acc: (96.00%) (12515/12928)
Epoch: 170 | Batch_idx: 110 |  Loss: (0.0965) |  Loss2: (0.0000) | Acc: (96.00%) (13742/14208)
Epoch: 170 | Batch_idx: 120 |  Loss: (0.0970) |  Loss2: (0.0000) | Acc: (96.00%) (14980/15488)
Epoch: 170 | Batch_idx: 130 |  Loss: (0.0961) |  Loss2: (0.0000) | Acc: (96.00%) (16223/16768)
Epoch: 170 | Batch_idx: 140 |  Loss: (0.0961) |  Loss2: (0.0000) | Acc: (96.00%) (17465/18048)
Epoch: 170 | Batch_idx: 150 |  Loss: (0.0960) |  Loss2: (0.0000) | Acc: (96.00%) (18706/19328)
Epoch: 170 | Batch_idx: 160 |  Loss: (0.0954) |  Loss2: (0.0000) | Acc: (96.00%) (19947/20608)
Epoch: 170 | Batch_idx: 170 |  Loss: (0.0979) |  Loss2: (0.0000) | Acc: (96.00%) (21156/21888)
Epoch: 170 | Batch_idx: 180 |  Loss: (0.0988) |  Loss2: (0.0000) | Acc: (96.00%) (22389/23168)
Epoch: 170 | Batch_idx: 190 |  Loss: (0.0988) |  Loss2: (0.0000) | Acc: (96.00%) (23623/24448)
Epoch: 170 | Batch_idx: 200 |  Loss: (0.0990) |  Loss2: (0.0000) | Acc: (96.00%) (24857/25728)
Epoch: 170 | Batch_idx: 210 |  Loss: (0.0989) |  Loss2: (0.0000) | Acc: (96.00%) (26099/27008)
Epoch: 170 | Batch_idx: 220 |  Loss: (0.0988) |  Loss2: (0.0000) | Acc: (96.00%) (27342/28288)
Epoch: 170 | Batch_idx: 230 |  Loss: (0.0992) |  Loss2: (0.0000) | Acc: (96.00%) (28576/29568)
Epoch: 170 | Batch_idx: 240 |  Loss: (0.0997) |  Loss2: (0.0000) | Acc: (96.00%) (29802/30848)
Epoch: 170 | Batch_idx: 250 |  Loss: (0.0999) |  Loss2: (0.0000) | Acc: (96.00%) (31041/32128)
Epoch: 170 | Batch_idx: 260 |  Loss: (0.1001) |  Loss2: (0.0000) | Acc: (96.00%) (32277/33408)
Epoch: 170 | Batch_idx: 270 |  Loss: (0.1003) |  Loss2: (0.0000) | Acc: (96.00%) (33506/34688)
Epoch: 170 | Batch_idx: 280 |  Loss: (0.1006) |  Loss2: (0.0000) | Acc: (96.00%) (34733/35968)
Epoch: 170 | Batch_idx: 290 |  Loss: (0.1015) |  Loss2: (0.0000) | Acc: (96.00%) (35957/37248)
Epoch: 170 | Batch_idx: 300 |  Loss: (0.1017) |  Loss2: (0.0000) | Acc: (96.00%) (37191/38528)
Epoch: 170 | Batch_idx: 310 |  Loss: (0.1020) |  Loss2: (0.0000) | Acc: (96.00%) (38425/39808)
Epoch: 170 | Batch_idx: 320 |  Loss: (0.1018) |  Loss2: (0.0000) | Acc: (96.00%) (39660/41088)
Epoch: 170 | Batch_idx: 330 |  Loss: (0.1020) |  Loss2: (0.0000) | Acc: (96.00%) (40897/42368)
Epoch: 170 | Batch_idx: 340 |  Loss: (0.1019) |  Loss2: (0.0000) | Acc: (96.00%) (42136/43648)
Epoch: 170 | Batch_idx: 350 |  Loss: (0.1016) |  Loss2: (0.0000) | Acc: (96.00%) (43376/44928)
Epoch: 170 | Batch_idx: 360 |  Loss: (0.1025) |  Loss2: (0.0000) | Acc: (96.00%) (44594/46208)
Epoch: 170 | Batch_idx: 370 |  Loss: (0.1024) |  Loss2: (0.0000) | Acc: (96.00%) (45828/47488)
Epoch: 170 | Batch_idx: 380 |  Loss: (0.1026) |  Loss2: (0.0000) | Acc: (96.00%) (47059/48768)
Epoch: 170 | Batch_idx: 390 |  Loss: (0.1024) |  Loss2: (0.0000) | Acc: (96.00%) (48251/50000)
=> saving checkpoint 'drive/app/torch/save_Schedule/checkpoint_170.pth.tar'
# TEST : Loss: (0.3972) | Acc: (88.00%) (8846/10000)
percent tensor([0.5158, 0.5061, 0.5170, 0.5118, 0.5195, 0.5246, 0.5121, 0.5129, 0.5167,
        0.5077, 0.5170, 0.5120, 0.5083, 0.5098, 0.5143, 0.5129],
       device='cuda:0') torch.Size([16])
percent tensor([0.5086, 0.5030, 0.5104, 0.5085, 0.5084, 0.5086, 0.5056, 0.5107, 0.5115,
        0.5064, 0.5106, 0.5062, 0.5032, 0.5142, 0.5047, 0.5097],
       device='cuda:0') torch.Size([16])
percent tensor([0.5611, 0.5355, 0.5762, 0.5765, 0.5842, 0.5584, 0.5712, 0.5776, 0.5579,
        0.5485, 0.5486, 0.5668, 0.5147, 0.5940, 0.5507, 0.5688],
       device='cuda:0') torch.Size([16])
percent tensor([0.6152, 0.6322, 0.6144, 0.6091, 0.6027, 0.6198, 0.6207, 0.6044, 0.6318,
        0.6361, 0.6446, 0.6240, 0.6335, 0.6409, 0.6110, 0.6264],
       device='cuda:0') torch.Size([16])
percent tensor([0.5914, 0.6790, 0.5187, 0.6176, 0.5218, 0.6571, 0.6101, 0.3818, 0.7169,
        0.6663, 0.7424, 0.6029, 0.6721, 0.7302, 0.5589, 0.6118],
       device='cuda:0') torch.Size([16])
percent tensor([0.6144, 0.5974, 0.6464, 0.6206, 0.6783, 0.6273, 0.6257, 0.6562, 0.6112,
        0.6101, 0.5658, 0.5808, 0.5661, 0.5849, 0.5984, 0.6224],
       device='cuda:0') torch.Size([16])
percent tensor([0.5317, 0.5910, 0.7130, 0.6519, 0.7323, 0.7428, 0.5668, 0.6285, 0.6343,
        0.5669, 0.6626, 0.5785, 0.6326, 0.5807, 0.5669, 0.4942],
       device='cuda:0') torch.Size([16])
percent tensor([0.9997, 0.9997, 0.9997, 0.9996, 0.9997, 0.9993, 0.9996, 0.9996, 0.9997,
        0.9997, 0.9999, 0.9997, 0.9998, 0.9991, 0.9996, 0.9993],
       device='cuda:0') torch.Size([16])
False Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=128, out_features=16, bias=False)
True Linear(in_features=16, out_features=2, bias=False)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=128, out_features=16, bias=False)
True Linear(in_features=16, out_features=2, bias=False)
False Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=256, out_features=32, bias=False)
True Linear(in_features=32, out_features=2, bias=False)
False Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=256, out_features=32, bias=False)
True Linear(in_features=32, out_features=2, bias=False)
False Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=512, out_features=64, bias=False)
True Linear(in_features=64, out_features=2, bias=False)
False Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=512, out_features=64, bias=False)
True Linear(in_features=64, out_features=2, bias=False)
False Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1024, out_features=128, bias=False)
True Linear(in_features=128, out_features=2, bias=False)
False Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1024, out_features=128, bias=False)
True Linear(in_features=128, out_features=2, bias=False)
False Linear(in_features=512, out_features=10, bias=True)
Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 3, 3, 3]) tensor(190.3076, device='cuda:0')
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(836.4739, device='cuda:0')
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(826.2052, device='cuda:0')
Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([128, 64, 3, 3]) tensor(1524.0522, device='cuda:0')
Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([128, 64, 1, 1]) tensor(477.6049, device='cuda:0')
Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([128, 128, 3, 3]) tensor(2308.1499, device='cuda:0')
Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([256, 128, 3, 3]) tensor(4259.9189, device='cuda:0')
Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([256, 128, 1, 1]) tensor(1354.9872, device='cuda:0')
Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([256, 256, 3, 3]) tensor(6225.2354, device='cuda:0')
Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([512, 256, 3, 3]) tensor(11616.7520, device='cuda:0')
Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([512, 256, 1, 1]) tensor(3833.0859, device='cuda:0')
Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([512, 512, 3, 3]) tensor(16194.4932, device='cuda:0')
Epoch: 171 | Batch_idx: 0 |  Loss: (0.0735) |  Loss2: (0.0000) | Acc: (99.00%) (127/128)
Epoch: 171 | Batch_idx: 10 |  Loss: (0.0847) |  Loss2: (0.0000) | Acc: (97.00%) (1375/1408)
Epoch: 171 | Batch_idx: 20 |  Loss: (0.1115) |  Loss2: (0.0000) | Acc: (96.00%) (2587/2688)
Epoch: 171 | Batch_idx: 30 |  Loss: (0.1195) |  Loss2: (0.0000) | Acc: (96.00%) (3812/3968)
Epoch: 171 | Batch_idx: 40 |  Loss: (0.1221) |  Loss2: (0.0000) | Acc: (96.00%) (5039/5248)
Epoch: 171 | Batch_idx: 50 |  Loss: (0.1226) |  Loss2: (0.0000) | Acc: (95.00%) (6261/6528)
Epoch: 171 | Batch_idx: 60 |  Loss: (0.1243) |  Loss2: (0.0000) | Acc: (95.00%) (7480/7808)
Epoch: 171 | Batch_idx: 70 |  Loss: (0.1274) |  Loss2: (0.0000) | Acc: (95.00%) (8690/9088)
Epoch: 171 | Batch_idx: 80 |  Loss: (0.1325) |  Loss2: (0.0000) | Acc: (95.00%) (9899/10368)
Epoch: 171 | Batch_idx: 90 |  Loss: (0.1324) |  Loss2: (0.0000) | Acc: (95.00%) (11125/11648)
Epoch: 171 | Batch_idx: 100 |  Loss: (0.1321) |  Loss2: (0.0000) | Acc: (95.00%) (12342/12928)
Epoch: 171 | Batch_idx: 110 |  Loss: (0.1330) |  Loss2: (0.0000) | Acc: (95.00%) (13554/14208)
Epoch: 171 | Batch_idx: 120 |  Loss: (0.1320) |  Loss2: (0.0000) | Acc: (95.00%) (14778/15488)
Epoch: 171 | Batch_idx: 130 |  Loss: (0.1325) |  Loss2: (0.0000) | Acc: (95.00%) (15997/16768)
Epoch: 171 | Batch_idx: 140 |  Loss: (0.1312) |  Loss2: (0.0000) | Acc: (95.00%) (17234/18048)
Epoch: 171 | Batch_idx: 150 |  Loss: (0.1319) |  Loss2: (0.0000) | Acc: (95.00%) (18451/19328)
Epoch: 171 | Batch_idx: 160 |  Loss: (0.1312) |  Loss2: (0.0000) | Acc: (95.00%) (19675/20608)
Epoch: 171 | Batch_idx: 170 |  Loss: (0.1303) |  Loss2: (0.0000) | Acc: (95.00%) (20897/21888)
Epoch: 171 | Batch_idx: 180 |  Loss: (0.1298) |  Loss2: (0.0000) | Acc: (95.00%) (22122/23168)
Epoch: 171 | Batch_idx: 190 |  Loss: (0.1292) |  Loss2: (0.0000) | Acc: (95.00%) (23354/24448)
Epoch: 171 | Batch_idx: 200 |  Loss: (0.1281) |  Loss2: (0.0000) | Acc: (95.00%) (24583/25728)
Epoch: 171 | Batch_idx: 210 |  Loss: (0.1275) |  Loss2: (0.0000) | Acc: (95.00%) (25810/27008)
Epoch: 171 | Batch_idx: 220 |  Loss: (0.1276) |  Loss2: (0.0000) | Acc: (95.00%) (27032/28288)
Epoch: 171 | Batch_idx: 230 |  Loss: (0.1271) |  Loss2: (0.0000) | Acc: (95.00%) (28253/29568)
Epoch: 171 | Batch_idx: 240 |  Loss: (0.1268) |  Loss2: (0.0000) | Acc: (95.00%) (29481/30848)
Epoch: 171 | Batch_idx: 250 |  Loss: (0.1264) |  Loss2: (0.0000) | Acc: (95.00%) (30711/32128)
Epoch: 171 | Batch_idx: 260 |  Loss: (0.1260) |  Loss2: (0.0000) | Acc: (95.00%) (31940/33408)
Epoch: 171 | Batch_idx: 270 |  Loss: (0.1261) |  Loss2: (0.0000) | Acc: (95.00%) (33159/34688)
Epoch: 171 | Batch_idx: 280 |  Loss: (0.1258) |  Loss2: (0.0000) | Acc: (95.00%) (34387/35968)
Epoch: 171 | Batch_idx: 290 |  Loss: (0.1253) |  Loss2: (0.0000) | Acc: (95.00%) (35620/37248)
Epoch: 171 | Batch_idx: 300 |  Loss: (0.1250) |  Loss2: (0.0000) | Acc: (95.00%) (36849/38528)
Epoch: 171 | Batch_idx: 310 |  Loss: (0.1246) |  Loss2: (0.0000) | Acc: (95.00%) (38077/39808)
Epoch: 171 | Batch_idx: 320 |  Loss: (0.1246) |  Loss2: (0.0000) | Acc: (95.00%) (39307/41088)
Epoch: 171 | Batch_idx: 330 |  Loss: (0.1243) |  Loss2: (0.0000) | Acc: (95.00%) (40532/42368)
Epoch: 171 | Batch_idx: 340 |  Loss: (0.1239) |  Loss2: (0.0000) | Acc: (95.00%) (41757/43648)
Epoch: 171 | Batch_idx: 350 |  Loss: (0.1238) |  Loss2: (0.0000) | Acc: (95.00%) (42992/44928)
Epoch: 171 | Batch_idx: 360 |  Loss: (0.1231) |  Loss2: (0.0000) | Acc: (95.00%) (44228/46208)
Epoch: 171 | Batch_idx: 370 |  Loss: (0.1234) |  Loss2: (0.0000) | Acc: (95.00%) (45449/47488)
Epoch: 171 | Batch_idx: 380 |  Loss: (0.1230) |  Loss2: (0.0000) | Acc: (95.00%) (46684/48768)
Epoch: 171 | Batch_idx: 390 |  Loss: (0.1226) |  Loss2: (0.0000) | Acc: (95.00%) (47869/50000)
# TEST : Loss: (0.3971) | Acc: (88.00%) (8844/10000)
percent tensor([0.5216, 0.5138, 0.5244, 0.5182, 0.5271, 0.5296, 0.5198, 0.5200, 0.5231,
        0.5150, 0.5234, 0.5195, 0.5147, 0.5165, 0.5212, 0.5191],
       device='cuda:0') torch.Size([16])
percent tensor([0.5048, 0.4983, 0.5069, 0.5046, 0.5038, 0.5049, 0.5012, 0.5056, 0.5079,
        0.5021, 0.5068, 0.5025, 0.4998, 0.5097, 0.5002, 0.5054],
       device='cuda:0') torch.Size([16])
percent tensor([0.5666, 0.5443, 0.5791, 0.5855, 0.5867, 0.5726, 0.5759, 0.5747, 0.5650,
        0.5575, 0.5599, 0.5746, 0.5213, 0.6111, 0.5573, 0.5769],
       device='cuda:0') torch.Size([16])
percent tensor([0.6349, 0.6547, 0.6315, 0.6268, 0.6207, 0.6374, 0.6431, 0.6218, 0.6536,
        0.6598, 0.6686, 0.6443, 0.6563, 0.6647, 0.6302, 0.6481],
       device='cuda:0') torch.Size([16])
percent tensor([0.6031, 0.7048, 0.5370, 0.6500, 0.5385, 0.6759, 0.6204, 0.3958, 0.7285,
        0.6883, 0.7622, 0.6197, 0.6962, 0.7383, 0.5483, 0.6415],
       device='cuda:0') torch.Size([16])
percent tensor([0.6267, 0.6159, 0.6594, 0.6353, 0.6922, 0.6430, 0.6448, 0.6687, 0.6327,
        0.6254, 0.5837, 0.5978, 0.5866, 0.6003, 0.6143, 0.6423],
       device='cuda:0') torch.Size([16])
percent tensor([0.5482, 0.6096, 0.7473, 0.6817, 0.7575, 0.7547, 0.6172, 0.6625, 0.6711,
        0.6050, 0.7040, 0.6258, 0.6568, 0.5908, 0.5974, 0.5065],
       device='cuda:0') torch.Size([16])
percent tensor([0.9997, 0.9996, 0.9996, 0.9996, 0.9996, 0.9991, 0.9996, 0.9996, 0.9997,
        0.9997, 0.9999, 0.9996, 0.9998, 0.9988, 0.9996, 0.9993],
       device='cuda:0') torch.Size([16])
Epoch: 172 | Batch_idx: 0 |  Loss: (0.0628) |  Loss2: (0.0000) | Acc: (97.00%) (125/128)
Epoch: 172 | Batch_idx: 10 |  Loss: (0.1058) |  Loss2: (0.0000) | Acc: (96.00%) (1357/1408)
Epoch: 172 | Batch_idx: 20 |  Loss: (0.1109) |  Loss2: (0.0000) | Acc: (96.00%) (2583/2688)
Epoch: 172 | Batch_idx: 30 |  Loss: (0.1119) |  Loss2: (0.0000) | Acc: (96.00%) (3812/3968)
Epoch: 172 | Batch_idx: 40 |  Loss: (0.1100) |  Loss2: (0.0000) | Acc: (96.00%) (5043/5248)
Epoch: 172 | Batch_idx: 50 |  Loss: (0.1064) |  Loss2: (0.0000) | Acc: (96.00%) (6280/6528)
Epoch: 172 | Batch_idx: 60 |  Loss: (0.1072) |  Loss2: (0.0000) | Acc: (96.00%) (7515/7808)
Epoch: 172 | Batch_idx: 70 |  Loss: (0.1084) |  Loss2: (0.0000) | Acc: (96.00%) (8733/9088)
Epoch: 172 | Batch_idx: 80 |  Loss: (0.1084) |  Loss2: (0.0000) | Acc: (96.00%) (9969/10368)
Epoch: 172 | Batch_idx: 90 |  Loss: (0.1099) |  Loss2: (0.0000) | Acc: (96.00%) (11190/11648)
Epoch: 172 | Batch_idx: 100 |  Loss: (0.1105) |  Loss2: (0.0000) | Acc: (96.00%) (12419/12928)
Epoch: 172 | Batch_idx: 110 |  Loss: (0.1082) |  Loss2: (0.0000) | Acc: (96.00%) (13661/14208)
Epoch: 172 | Batch_idx: 120 |  Loss: (0.1081) |  Loss2: (0.0000) | Acc: (96.00%) (14890/15488)
Epoch: 172 | Batch_idx: 130 |  Loss: (0.1080) |  Loss2: (0.0000) | Acc: (96.00%) (16124/16768)
Epoch: 172 | Batch_idx: 140 |  Loss: (0.1090) |  Loss2: (0.0000) | Acc: (96.00%) (17349/18048)
Epoch: 172 | Batch_idx: 150 |  Loss: (0.1084) |  Loss2: (0.0000) | Acc: (96.00%) (18589/19328)
Epoch: 172 | Batch_idx: 160 |  Loss: (0.1089) |  Loss2: (0.0000) | Acc: (96.00%) (19818/20608)
Epoch: 172 | Batch_idx: 170 |  Loss: (0.1083) |  Loss2: (0.0000) | Acc: (96.00%) (21057/21888)
Epoch: 172 | Batch_idx: 180 |  Loss: (0.1075) |  Loss2: (0.0000) | Acc: (96.00%) (22291/23168)
Epoch: 172 | Batch_idx: 190 |  Loss: (0.1074) |  Loss2: (0.0000) | Acc: (96.00%) (23518/24448)
Epoch: 172 | Batch_idx: 200 |  Loss: (0.1069) |  Loss2: (0.0000) | Acc: (96.00%) (24754/25728)
Epoch: 172 | Batch_idx: 210 |  Loss: (0.1070) |  Loss2: (0.0000) | Acc: (96.00%) (25985/27008)
Epoch: 172 | Batch_idx: 220 |  Loss: (0.1074) |  Loss2: (0.0000) | Acc: (96.00%) (27212/28288)
Epoch: 172 | Batch_idx: 230 |  Loss: (0.1073) |  Loss2: (0.0000) | Acc: (96.00%) (28445/29568)
Epoch: 172 | Batch_idx: 240 |  Loss: (0.1067) |  Loss2: (0.0000) | Acc: (96.00%) (29681/30848)
Epoch: 172 | Batch_idx: 250 |  Loss: (0.1064) |  Loss2: (0.0000) | Acc: (96.00%) (30918/32128)
Epoch: 172 | Batch_idx: 260 |  Loss: (0.1068) |  Loss2: (0.0000) | Acc: (96.00%) (32139/33408)
Epoch: 172 | Batch_idx: 270 |  Loss: (0.1067) |  Loss2: (0.0000) | Acc: (96.00%) (33370/34688)
Epoch: 172 | Batch_idx: 280 |  Loss: (0.1068) |  Loss2: (0.0000) | Acc: (96.00%) (34595/35968)
Epoch: 172 | Batch_idx: 290 |  Loss: (0.1070) |  Loss2: (0.0000) | Acc: (96.00%) (35824/37248)
Epoch: 172 | Batch_idx: 300 |  Loss: (0.1066) |  Loss2: (0.0000) | Acc: (96.00%) (37065/38528)
Epoch: 172 | Batch_idx: 310 |  Loss: (0.1061) |  Loss2: (0.0000) | Acc: (96.00%) (38304/39808)
Epoch: 172 | Batch_idx: 320 |  Loss: (0.1061) |  Loss2: (0.0000) | Acc: (96.00%) (39537/41088)
Epoch: 172 | Batch_idx: 330 |  Loss: (0.1057) |  Loss2: (0.0000) | Acc: (96.00%) (40780/42368)
Epoch: 172 | Batch_idx: 340 |  Loss: (0.1059) |  Loss2: (0.0000) | Acc: (96.00%) (42011/43648)
Epoch: 172 | Batch_idx: 350 |  Loss: (0.1053) |  Loss2: (0.0000) | Acc: (96.00%) (43257/44928)
Epoch: 172 | Batch_idx: 360 |  Loss: (0.1046) |  Loss2: (0.0000) | Acc: (96.00%) (44498/46208)
Epoch: 172 | Batch_idx: 370 |  Loss: (0.1043) |  Loss2: (0.0000) | Acc: (96.00%) (45741/47488)
Epoch: 172 | Batch_idx: 380 |  Loss: (0.1045) |  Loss2: (0.0000) | Acc: (96.00%) (46973/48768)
Epoch: 172 | Batch_idx: 390 |  Loss: (0.1048) |  Loss2: (0.0000) | Acc: (96.00%) (48160/50000)
# TEST : Loss: (0.3926) | Acc: (88.00%) (8853/10000)
percent tensor([0.5247, 0.5174, 0.5284, 0.5214, 0.5314, 0.5325, 0.5236, 0.5236, 0.5265,
        0.5186, 0.5267, 0.5234, 0.5179, 0.5194, 0.5246, 0.5222],
       device='cuda:0') torch.Size([16])
percent tensor([0.5025, 0.4959, 0.5047, 0.5027, 0.5015, 0.5029, 0.4988, 0.5034, 0.5058,
        0.4997, 0.5046, 0.5003, 0.4973, 0.5078, 0.4978, 0.5033],
       device='cuda:0') torch.Size([16])
percent tensor([0.5657, 0.5460, 0.5764, 0.5871, 0.5841, 0.5757, 0.5743, 0.5713, 0.5649,
        0.5585, 0.5609, 0.5740, 0.5211, 0.6150, 0.5570, 0.5776],
       device='cuda:0') torch.Size([16])
percent tensor([0.6357, 0.6558, 0.6337, 0.6284, 0.6224, 0.6376, 0.6443, 0.6225, 0.6560,
        0.6616, 0.6709, 0.6466, 0.6576, 0.6667, 0.6299, 0.6491],
       device='cuda:0') torch.Size([16])
percent tensor([0.5856, 0.7008, 0.5248, 0.6464, 0.5267, 0.6703, 0.6025, 0.3739, 0.7192,
        0.6796, 0.7544, 0.6117, 0.6861, 0.7265, 0.5298, 0.6328],
       device='cuda:0') torch.Size([16])
percent tensor([0.6323, 0.6268, 0.6610, 0.6397, 0.6957, 0.6484, 0.6523, 0.6736, 0.6394,
        0.6321, 0.5911, 0.6011, 0.5945, 0.6094, 0.6208, 0.6504],
       device='cuda:0') torch.Size([16])
percent tensor([0.5414, 0.6021, 0.7514, 0.6820, 0.7608, 0.7537, 0.6255, 0.6691, 0.6710,
        0.6027, 0.7075, 0.6305, 0.6459, 0.5858, 0.6014, 0.5016],
       device='cuda:0') torch.Size([16])
percent tensor([0.9997, 0.9996, 0.9997, 0.9997, 0.9996, 0.9990, 0.9996, 0.9996, 0.9998,
        0.9998, 0.9999, 0.9997, 0.9998, 0.9987, 0.9997, 0.9993],
       device='cuda:0') torch.Size([16])
Epoch: 173 | Batch_idx: 0 |  Loss: (0.1009) |  Loss2: (0.0000) | Acc: (96.00%) (123/128)
Epoch: 173 | Batch_idx: 10 |  Loss: (0.1063) |  Loss2: (0.0000) | Acc: (96.00%) (1356/1408)
Epoch: 173 | Batch_idx: 20 |  Loss: (0.1142) |  Loss2: (0.0000) | Acc: (95.00%) (2577/2688)
Epoch: 173 | Batch_idx: 30 |  Loss: (0.1102) |  Loss2: (0.0000) | Acc: (95.00%) (3806/3968)
Epoch: 173 | Batch_idx: 40 |  Loss: (0.1077) |  Loss2: (0.0000) | Acc: (96.00%) (5044/5248)
Epoch: 173 | Batch_idx: 50 |  Loss: (0.1076) |  Loss2: (0.0000) | Acc: (96.00%) (6270/6528)
Epoch: 173 | Batch_idx: 60 |  Loss: (0.1065) |  Loss2: (0.0000) | Acc: (96.00%) (7506/7808)
Epoch: 173 | Batch_idx: 70 |  Loss: (0.1046) |  Loss2: (0.0000) | Acc: (96.00%) (8753/9088)
Epoch: 173 | Batch_idx: 80 |  Loss: (0.1048) |  Loss2: (0.0000) | Acc: (96.00%) (9985/10368)
Epoch: 173 | Batch_idx: 90 |  Loss: (0.1036) |  Loss2: (0.0000) | Acc: (96.00%) (11224/11648)
Epoch: 173 | Batch_idx: 100 |  Loss: (0.1042) |  Loss2: (0.0000) | Acc: (96.00%) (12452/12928)
Epoch: 173 | Batch_idx: 110 |  Loss: (0.1048) |  Loss2: (0.0000) | Acc: (96.00%) (13686/14208)
Epoch: 173 | Batch_idx: 120 |  Loss: (0.1042) |  Loss2: (0.0000) | Acc: (96.00%) (14914/15488)
Epoch: 173 | Batch_idx: 130 |  Loss: (0.1047) |  Loss2: (0.0000) | Acc: (96.00%) (16145/16768)
Epoch: 173 | Batch_idx: 140 |  Loss: (0.1048) |  Loss2: (0.0000) | Acc: (96.00%) (17381/18048)
Epoch: 173 | Batch_idx: 150 |  Loss: (0.1055) |  Loss2: (0.0000) | Acc: (96.00%) (18611/19328)
Epoch: 173 | Batch_idx: 160 |  Loss: (0.1043) |  Loss2: (0.0000) | Acc: (96.00%) (19854/20608)
Epoch: 173 | Batch_idx: 170 |  Loss: (0.1029) |  Loss2: (0.0000) | Acc: (96.00%) (21108/21888)
Epoch: 173 | Batch_idx: 180 |  Loss: (0.1024) |  Loss2: (0.0000) | Acc: (96.00%) (22348/23168)
Epoch: 173 | Batch_idx: 190 |  Loss: (0.1009) |  Loss2: (0.0000) | Acc: (96.00%) (23599/24448)
Epoch: 173 | Batch_idx: 200 |  Loss: (0.1003) |  Loss2: (0.0000) | Acc: (96.00%) (24837/25728)
Epoch: 173 | Batch_idx: 210 |  Loss: (0.0996) |  Loss2: (0.0000) | Acc: (96.00%) (26079/27008)
Epoch: 173 | Batch_idx: 220 |  Loss: (0.1000) |  Loss2: (0.0000) | Acc: (96.00%) (27313/28288)
Epoch: 173 | Batch_idx: 230 |  Loss: (0.0999) |  Loss2: (0.0000) | Acc: (96.00%) (28550/29568)
Epoch: 173 | Batch_idx: 240 |  Loss: (0.0998) |  Loss2: (0.0000) | Acc: (96.00%) (29791/30848)
Epoch: 173 | Batch_idx: 250 |  Loss: (0.0996) |  Loss2: (0.0000) | Acc: (96.00%) (31025/32128)
Epoch: 173 | Batch_idx: 260 |  Loss: (0.0995) |  Loss2: (0.0000) | Acc: (96.00%) (32263/33408)
Epoch: 173 | Batch_idx: 270 |  Loss: (0.0992) |  Loss2: (0.0000) | Acc: (96.00%) (33503/34688)
Epoch: 173 | Batch_idx: 280 |  Loss: (0.0997) |  Loss2: (0.0000) | Acc: (96.00%) (34738/35968)
Epoch: 173 | Batch_idx: 290 |  Loss: (0.1000) |  Loss2: (0.0000) | Acc: (96.00%) (35967/37248)
Epoch: 173 | Batch_idx: 300 |  Loss: (0.0998) |  Loss2: (0.0000) | Acc: (96.00%) (37205/38528)
Epoch: 173 | Batch_idx: 310 |  Loss: (0.0994) |  Loss2: (0.0000) | Acc: (96.00%) (38446/39808)
Epoch: 173 | Batch_idx: 320 |  Loss: (0.0994) |  Loss2: (0.0000) | Acc: (96.00%) (39685/41088)
Epoch: 173 | Batch_idx: 330 |  Loss: (0.0996) |  Loss2: (0.0000) | Acc: (96.00%) (40923/42368)
Epoch: 173 | Batch_idx: 340 |  Loss: (0.0995) |  Loss2: (0.0000) | Acc: (96.00%) (42155/43648)
Epoch: 173 | Batch_idx: 350 |  Loss: (0.0996) |  Loss2: (0.0000) | Acc: (96.00%) (43391/44928)
Epoch: 173 | Batch_idx: 360 |  Loss: (0.0993) |  Loss2: (0.0000) | Acc: (96.00%) (44635/46208)
Epoch: 173 | Batch_idx: 370 |  Loss: (0.0998) |  Loss2: (0.0000) | Acc: (96.00%) (45861/47488)
Epoch: 173 | Batch_idx: 380 |  Loss: (0.0999) |  Loss2: (0.0000) | Acc: (96.00%) (47097/48768)
Epoch: 173 | Batch_idx: 390 |  Loss: (0.1003) |  Loss2: (0.0000) | Acc: (96.00%) (48283/50000)
# TEST : Loss: (0.3851) | Acc: (88.00%) (8865/10000)
percent tensor([0.5230, 0.5154, 0.5266, 0.5196, 0.5295, 0.5309, 0.5216, 0.5216, 0.5248,
        0.5167, 0.5249, 0.5215, 0.5162, 0.5177, 0.5226, 0.5203],
       device='cuda:0') torch.Size([16])
percent tensor([0.5030, 0.4964, 0.5053, 0.5036, 0.5021, 0.5032, 0.4994, 0.5041, 0.5065,
        0.5004, 0.5053, 0.5008, 0.4979, 0.5086, 0.4981, 0.5040],
       device='cuda:0') torch.Size([16])
percent tensor([0.5642, 0.5444, 0.5767, 0.5882, 0.5819, 0.5767, 0.5717, 0.5690, 0.5648,
        0.5574, 0.5604, 0.5728, 0.5186, 0.6175, 0.5549, 0.5777],
       device='cuda:0') torch.Size([16])
percent tensor([0.6335, 0.6544, 0.6325, 0.6276, 0.6209, 0.6347, 0.6427, 0.6204, 0.6555,
        0.6605, 0.6698, 0.6455, 0.6569, 0.6652, 0.6272, 0.6473],
       device='cuda:0') torch.Size([16])
percent tensor([0.5751, 0.7002, 0.5118, 0.6465, 0.5183, 0.6644, 0.5980, 0.3634, 0.7150,
        0.6769, 0.7498, 0.6111, 0.6818, 0.7215, 0.5252, 0.6299],
       device='cuda:0') torch.Size([16])
percent tensor([0.6284, 0.6264, 0.6560, 0.6353, 0.6913, 0.6456, 0.6493, 0.6682, 0.6356,
        0.6299, 0.5881, 0.5974, 0.5930, 0.6067, 0.6170, 0.6475],
       device='cuda:0') torch.Size([16])
percent tensor([0.5288, 0.5919, 0.7507, 0.6814, 0.7641, 0.7514, 0.6216, 0.6729, 0.6591,
        0.5951, 0.7002, 0.6247, 0.6396, 0.5708, 0.5978, 0.4936],
       device='cuda:0') torch.Size([16])
percent tensor([0.9997, 0.9996, 0.9997, 0.9997, 0.9996, 0.9991, 0.9996, 0.9996, 0.9998,
        0.9998, 0.9999, 0.9997, 0.9998, 0.9987, 0.9997, 0.9993],
       device='cuda:0') torch.Size([16])
Epoch: 174 | Batch_idx: 0 |  Loss: (0.1251) |  Loss2: (0.0000) | Acc: (96.00%) (124/128)
Epoch: 174 | Batch_idx: 10 |  Loss: (0.0913) |  Loss2: (0.0000) | Acc: (96.00%) (1364/1408)
Epoch: 174 | Batch_idx: 20 |  Loss: (0.0913) |  Loss2: (0.0000) | Acc: (96.00%) (2601/2688)
Epoch: 174 | Batch_idx: 30 |  Loss: (0.0938) |  Loss2: (0.0000) | Acc: (96.00%) (3843/3968)
Epoch: 174 | Batch_idx: 40 |  Loss: (0.0877) |  Loss2: (0.0000) | Acc: (97.00%) (5096/5248)
Epoch: 174 | Batch_idx: 50 |  Loss: (0.0886) |  Loss2: (0.0000) | Acc: (97.00%) (6341/6528)
Epoch: 174 | Batch_idx: 60 |  Loss: (0.0927) |  Loss2: (0.0000) | Acc: (96.00%) (7567/7808)
Epoch: 174 | Batch_idx: 70 |  Loss: (0.0918) |  Loss2: (0.0000) | Acc: (96.00%) (8814/9088)
Epoch: 174 | Batch_idx: 80 |  Loss: (0.0935) |  Loss2: (0.0000) | Acc: (96.00%) (10042/10368)
Epoch: 174 | Batch_idx: 90 |  Loss: (0.0949) |  Loss2: (0.0000) | Acc: (96.00%) (11280/11648)
Epoch: 174 | Batch_idx: 100 |  Loss: (0.0940) |  Loss2: (0.0000) | Acc: (96.00%) (12527/12928)
Epoch: 174 | Batch_idx: 110 |  Loss: (0.0944) |  Loss2: (0.0000) | Acc: (96.00%) (13766/14208)
Epoch: 174 | Batch_idx: 120 |  Loss: (0.0943) |  Loss2: (0.0000) | Acc: (96.00%) (15008/15488)
Epoch: 174 | Batch_idx: 130 |  Loss: (0.0949) |  Loss2: (0.0000) | Acc: (96.00%) (16246/16768)
Epoch: 174 | Batch_idx: 140 |  Loss: (0.0965) |  Loss2: (0.0000) | Acc: (96.00%) (17478/18048)
Epoch: 174 | Batch_idx: 150 |  Loss: (0.0970) |  Loss2: (0.0000) | Acc: (96.00%) (18708/19328)
Epoch: 174 | Batch_idx: 160 |  Loss: (0.0973) |  Loss2: (0.0000) | Acc: (96.00%) (19942/20608)
Epoch: 174 | Batch_idx: 170 |  Loss: (0.0963) |  Loss2: (0.0000) | Acc: (96.00%) (21191/21888)
Epoch: 174 | Batch_idx: 180 |  Loss: (0.0958) |  Loss2: (0.0000) | Acc: (96.00%) (22435/23168)
Epoch: 174 | Batch_idx: 190 |  Loss: (0.0955) |  Loss2: (0.0000) | Acc: (96.00%) (23675/24448)
Epoch: 174 | Batch_idx: 200 |  Loss: (0.0953) |  Loss2: (0.0000) | Acc: (96.00%) (24917/25728)
Epoch: 174 | Batch_idx: 210 |  Loss: (0.0957) |  Loss2: (0.0000) | Acc: (96.00%) (26157/27008)
Epoch: 174 | Batch_idx: 220 |  Loss: (0.0950) |  Loss2: (0.0000) | Acc: (96.00%) (27405/28288)
Epoch: 174 | Batch_idx: 230 |  Loss: (0.0950) |  Loss2: (0.0000) | Acc: (96.00%) (28644/29568)
Epoch: 174 | Batch_idx: 240 |  Loss: (0.0946) |  Loss2: (0.0000) | Acc: (96.00%) (29883/30848)
Epoch: 174 | Batch_idx: 250 |  Loss: (0.0947) |  Loss2: (0.0000) | Acc: (96.00%) (31124/32128)
Epoch: 174 | Batch_idx: 260 |  Loss: (0.0949) |  Loss2: (0.0000) | Acc: (96.00%) (32366/33408)
Epoch: 174 | Batch_idx: 270 |  Loss: (0.0948) |  Loss2: (0.0000) | Acc: (96.00%) (33609/34688)
Epoch: 174 | Batch_idx: 280 |  Loss: (0.0947) |  Loss2: (0.0000) | Acc: (96.00%) (34845/35968)
Epoch: 174 | Batch_idx: 290 |  Loss: (0.0951) |  Loss2: (0.0000) | Acc: (96.00%) (36080/37248)
Epoch: 174 | Batch_idx: 300 |  Loss: (0.0948) |  Loss2: (0.0000) | Acc: (96.00%) (37319/38528)
Epoch: 174 | Batch_idx: 310 |  Loss: (0.0946) |  Loss2: (0.0000) | Acc: (96.00%) (38563/39808)
Epoch: 174 | Batch_idx: 320 |  Loss: (0.0947) |  Loss2: (0.0000) | Acc: (96.00%) (39796/41088)
Epoch: 174 | Batch_idx: 330 |  Loss: (0.0946) |  Loss2: (0.0000) | Acc: (96.00%) (41037/42368)
Epoch: 174 | Batch_idx: 340 |  Loss: (0.0945) |  Loss2: (0.0000) | Acc: (96.00%) (42280/43648)
Epoch: 174 | Batch_idx: 350 |  Loss: (0.0948) |  Loss2: (0.0000) | Acc: (96.00%) (43504/44928)
Epoch: 174 | Batch_idx: 360 |  Loss: (0.0954) |  Loss2: (0.0000) | Acc: (96.00%) (44733/46208)
Epoch: 174 | Batch_idx: 370 |  Loss: (0.0952) |  Loss2: (0.0000) | Acc: (96.00%) (45975/47488)
Epoch: 174 | Batch_idx: 380 |  Loss: (0.0951) |  Loss2: (0.0000) | Acc: (96.00%) (47214/48768)
Epoch: 174 | Batch_idx: 390 |  Loss: (0.0951) |  Loss2: (0.0000) | Acc: (96.00%) (48407/50000)
# TEST : Loss: (0.3787) | Acc: (88.00%) (8888/10000)
percent tensor([0.5246, 0.5175, 0.5283, 0.5212, 0.5316, 0.5323, 0.5237, 0.5235, 0.5267,
        0.5187, 0.5268, 0.5234, 0.5180, 0.5198, 0.5244, 0.5221],
       device='cuda:0') torch.Size([16])
percent tensor([0.5019, 0.4952, 0.5045, 0.5028, 0.5011, 0.5023, 0.4982, 0.5032, 0.5056,
        0.4993, 0.5042, 0.4999, 0.4967, 0.5076, 0.4970, 0.5031],
       device='cuda:0') torch.Size([16])
percent tensor([0.5653, 0.5457, 0.5780, 0.5914, 0.5832, 0.5801, 0.5728, 0.5703, 0.5670,
        0.5591, 0.5623, 0.5747, 0.5193, 0.6210, 0.5564, 0.5803],
       device='cuda:0') torch.Size([16])
percent tensor([0.6276, 0.6490, 0.6277, 0.6226, 0.6157, 0.6292, 0.6368, 0.6152, 0.6504,
        0.6554, 0.6644, 0.6408, 0.6515, 0.6603, 0.6210, 0.6415],
       device='cuda:0') torch.Size([16])
percent tensor([0.5789, 0.7071, 0.5125, 0.6482, 0.5174, 0.6685, 0.6018, 0.3614, 0.7188,
        0.6839, 0.7541, 0.6172, 0.6871, 0.7256, 0.5314, 0.6321],
       device='cuda:0') torch.Size([16])
percent tensor([0.6225, 0.6242, 0.6508, 0.6311, 0.6859, 0.6406, 0.6446, 0.6636, 0.6328,
        0.6262, 0.5838, 0.5924, 0.5900, 0.6025, 0.6114, 0.6429],
       device='cuda:0') torch.Size([16])
percent tensor([0.5333, 0.5985, 0.7588, 0.6887, 0.7747, 0.7582, 0.6347, 0.6878, 0.6659,
        0.5970, 0.7037, 0.6303, 0.6359, 0.5724, 0.6098, 0.4978],
       device='cuda:0') torch.Size([16])
percent tensor([0.9997, 0.9996, 0.9997, 0.9996, 0.9996, 0.9991, 0.9996, 0.9996, 0.9998,
        0.9998, 0.9999, 0.9997, 0.9998, 0.9987, 0.9997, 0.9993],
       device='cuda:0') torch.Size([16])
Epoch: 175 | Batch_idx: 0 |  Loss: (0.1156) |  Loss2: (0.0000) | Acc: (97.00%) (125/128)
Epoch: 175 | Batch_idx: 10 |  Loss: (0.0827) |  Loss2: (0.0000) | Acc: (97.00%) (1369/1408)
Epoch: 175 | Batch_idx: 20 |  Loss: (0.0843) |  Loss2: (0.0000) | Acc: (97.00%) (2613/2688)
Epoch: 175 | Batch_idx: 30 |  Loss: (0.0859) |  Loss2: (0.0000) | Acc: (97.00%) (3853/3968)
Epoch: 175 | Batch_idx: 40 |  Loss: (0.0899) |  Loss2: (0.0000) | Acc: (96.00%) (5081/5248)
Epoch: 175 | Batch_idx: 50 |  Loss: (0.0920) |  Loss2: (0.0000) | Acc: (96.00%) (6323/6528)
Epoch: 175 | Batch_idx: 60 |  Loss: (0.0946) |  Loss2: (0.0000) | Acc: (96.00%) (7557/7808)
Epoch: 175 | Batch_idx: 70 |  Loss: (0.0954) |  Loss2: (0.0000) | Acc: (96.00%) (8786/9088)
Epoch: 175 | Batch_idx: 80 |  Loss: (0.0943) |  Loss2: (0.0000) | Acc: (96.00%) (10033/10368)
Epoch: 175 | Batch_idx: 90 |  Loss: (0.0938) |  Loss2: (0.0000) | Acc: (96.00%) (11272/11648)
Epoch: 175 | Batch_idx: 100 |  Loss: (0.0939) |  Loss2: (0.0000) | Acc: (96.00%) (12506/12928)
Epoch: 175 | Batch_idx: 110 |  Loss: (0.0943) |  Loss2: (0.0000) | Acc: (96.00%) (13744/14208)
Epoch: 175 | Batch_idx: 120 |  Loss: (0.0937) |  Loss2: (0.0000) | Acc: (96.00%) (14991/15488)
Epoch: 175 | Batch_idx: 130 |  Loss: (0.0941) |  Loss2: (0.0000) | Acc: (96.00%) (16228/16768)
Epoch: 175 | Batch_idx: 140 |  Loss: (0.0937) |  Loss2: (0.0000) | Acc: (96.00%) (17472/18048)
Epoch: 175 | Batch_idx: 150 |  Loss: (0.0935) |  Loss2: (0.0000) | Acc: (96.00%) (18716/19328)
Epoch: 175 | Batch_idx: 160 |  Loss: (0.0934) |  Loss2: (0.0000) | Acc: (96.00%) (19953/20608)
Epoch: 175 | Batch_idx: 170 |  Loss: (0.0933) |  Loss2: (0.0000) | Acc: (96.00%) (21193/21888)
Epoch: 175 | Batch_idx: 180 |  Loss: (0.0926) |  Loss2: (0.0000) | Acc: (96.00%) (22437/23168)
Epoch: 175 | Batch_idx: 190 |  Loss: (0.0922) |  Loss2: (0.0000) | Acc: (96.00%) (23681/24448)
Epoch: 175 | Batch_idx: 200 |  Loss: (0.0924) |  Loss2: (0.0000) | Acc: (96.00%) (24918/25728)
Epoch: 175 | Batch_idx: 210 |  Loss: (0.0924) |  Loss2: (0.0000) | Acc: (96.00%) (26155/27008)
Epoch: 175 | Batch_idx: 220 |  Loss: (0.0922) |  Loss2: (0.0000) | Acc: (96.00%) (27403/28288)
Epoch: 175 | Batch_idx: 230 |  Loss: (0.0916) |  Loss2: (0.0000) | Acc: (96.00%) (28652/29568)
Epoch: 175 | Batch_idx: 240 |  Loss: (0.0912) |  Loss2: (0.0000) | Acc: (96.00%) (29901/30848)
Epoch: 175 | Batch_idx: 250 |  Loss: (0.0919) |  Loss2: (0.0000) | Acc: (96.00%) (31140/32128)
Epoch: 175 | Batch_idx: 260 |  Loss: (0.0916) |  Loss2: (0.0000) | Acc: (96.00%) (32383/33408)
Epoch: 175 | Batch_idx: 270 |  Loss: (0.0917) |  Loss2: (0.0000) | Acc: (96.00%) (33625/34688)
Epoch: 175 | Batch_idx: 280 |  Loss: (0.0921) |  Loss2: (0.0000) | Acc: (96.00%) (34860/35968)
Epoch: 175 | Batch_idx: 290 |  Loss: (0.0919) |  Loss2: (0.0000) | Acc: (96.00%) (36097/37248)
Epoch: 175 | Batch_idx: 300 |  Loss: (0.0918) |  Loss2: (0.0000) | Acc: (96.00%) (37340/38528)
Epoch: 175 | Batch_idx: 310 |  Loss: (0.0912) |  Loss2: (0.0000) | Acc: (96.00%) (38587/39808)
Epoch: 175 | Batch_idx: 320 |  Loss: (0.0910) |  Loss2: (0.0000) | Acc: (96.00%) (39830/41088)
Epoch: 175 | Batch_idx: 330 |  Loss: (0.0909) |  Loss2: (0.0000) | Acc: (96.00%) (41070/42368)
Epoch: 175 | Batch_idx: 340 |  Loss: (0.0913) |  Loss2: (0.0000) | Acc: (96.00%) (42305/43648)
Epoch: 175 | Batch_idx: 350 |  Loss: (0.0915) |  Loss2: (0.0000) | Acc: (96.00%) (43546/44928)
Epoch: 175 | Batch_idx: 360 |  Loss: (0.0910) |  Loss2: (0.0000) | Acc: (96.00%) (44798/46208)
Epoch: 175 | Batch_idx: 370 |  Loss: (0.0909) |  Loss2: (0.0000) | Acc: (96.00%) (46040/47488)
Epoch: 175 | Batch_idx: 380 |  Loss: (0.0909) |  Loss2: (0.0000) | Acc: (96.00%) (47280/48768)
Epoch: 175 | Batch_idx: 390 |  Loss: (0.0917) |  Loss2: (0.0000) | Acc: (96.00%) (48460/50000)
=> saving checkpoint 'drive/app/torch/save_Schedule/checkpoint_175.pth.tar'
# TEST : Loss: (0.3783) | Acc: (88.00%) (8885/10000)
percent tensor([0.5239, 0.5166, 0.5275, 0.5205, 0.5308, 0.5314, 0.5228, 0.5227, 0.5261,
        0.5179, 0.5259, 0.5226, 0.5174, 0.5191, 0.5234, 0.5213],
       device='cuda:0') torch.Size([16])
percent tensor([0.5025, 0.4958, 0.5051, 0.5035, 0.5017, 0.5027, 0.4988, 0.5039, 0.5063,
        0.4999, 0.5048, 0.5004, 0.4974, 0.5083, 0.4975, 0.5036],
       device='cuda:0') torch.Size([16])
percent tensor([0.5605, 0.5415, 0.5736, 0.5867, 0.5787, 0.5758, 0.5680, 0.5659, 0.5629,
        0.5546, 0.5573, 0.5702, 0.5155, 0.6164, 0.5513, 0.5758],
       device='cuda:0') torch.Size([16])
percent tensor([0.6286, 0.6508, 0.6292, 0.6236, 0.6169, 0.6296, 0.6383, 0.6166, 0.6525,
        0.6575, 0.6664, 0.6423, 0.6534, 0.6620, 0.6218, 0.6426],
       device='cuda:0') torch.Size([16])
percent tensor([0.5954, 0.7189, 0.5255, 0.6576, 0.5322, 0.6750, 0.6183, 0.3830, 0.7262,
        0.6950, 0.7585, 0.6304, 0.6984, 0.7286, 0.5494, 0.6457],
       device='cuda:0') torch.Size([16])
percent tensor([0.6198, 0.6237, 0.6494, 0.6298, 0.6852, 0.6388, 0.6425, 0.6627, 0.6310,
        0.6244, 0.5804, 0.5902, 0.5890, 0.5996, 0.6083, 0.6412],
       device='cuda:0') torch.Size([16])
percent tensor([0.5327, 0.6023, 0.7593, 0.6888, 0.7762, 0.7568, 0.6391, 0.6925, 0.6671,
        0.5999, 0.7054, 0.6301, 0.6383, 0.5768, 0.6135, 0.4995],
       device='cuda:0') torch.Size([16])
percent tensor([0.9997, 0.9996, 0.9997, 0.9997, 0.9996, 0.9991, 0.9996, 0.9997, 0.9998,
        0.9998, 0.9999, 0.9997, 0.9998, 0.9987, 0.9997, 0.9993],
       device='cuda:0') torch.Size([16])
Epoch: 176 | Batch_idx: 0 |  Loss: (0.1075) |  Loss2: (0.0000) | Acc: (96.00%) (124/128)
Epoch: 176 | Batch_idx: 10 |  Loss: (0.0947) |  Loss2: (0.0000) | Acc: (96.00%) (1363/1408)
Epoch: 176 | Batch_idx: 20 |  Loss: (0.0833) |  Loss2: (0.0000) | Acc: (97.00%) (2616/2688)
Epoch: 176 | Batch_idx: 30 |  Loss: (0.0855) |  Loss2: (0.0000) | Acc: (97.00%) (3853/3968)
Epoch: 176 | Batch_idx: 40 |  Loss: (0.0830) |  Loss2: (0.0000) | Acc: (97.00%) (5098/5248)
Epoch: 176 | Batch_idx: 50 |  Loss: (0.0828) |  Loss2: (0.0000) | Acc: (97.00%) (6344/6528)
Epoch: 176 | Batch_idx: 60 |  Loss: (0.0827) |  Loss2: (0.0000) | Acc: (97.00%) (7586/7808)
Epoch: 176 | Batch_idx: 70 |  Loss: (0.0835) |  Loss2: (0.0000) | Acc: (97.00%) (8827/9088)
Epoch: 176 | Batch_idx: 80 |  Loss: (0.0856) |  Loss2: (0.0000) | Acc: (97.00%) (10059/10368)
Epoch: 176 | Batch_idx: 90 |  Loss: (0.0869) |  Loss2: (0.0000) | Acc: (96.00%) (11296/11648)
Epoch: 176 | Batch_idx: 100 |  Loss: (0.0875) |  Loss2: (0.0000) | Acc: (96.00%) (12536/12928)
Epoch: 176 | Batch_idx: 110 |  Loss: (0.0889) |  Loss2: (0.0000) | Acc: (96.00%) (13771/14208)
Epoch: 176 | Batch_idx: 120 |  Loss: (0.0884) |  Loss2: (0.0000) | Acc: (96.00%) (15017/15488)
Epoch: 176 | Batch_idx: 130 |  Loss: (0.0893) |  Loss2: (0.0000) | Acc: (96.00%) (16251/16768)
Epoch: 176 | Batch_idx: 140 |  Loss: (0.0884) |  Loss2: (0.0000) | Acc: (96.00%) (17502/18048)
Epoch: 176 | Batch_idx: 150 |  Loss: (0.0896) |  Loss2: (0.0000) | Acc: (96.00%) (18735/19328)
Epoch: 176 | Batch_idx: 160 |  Loss: (0.0893) |  Loss2: (0.0000) | Acc: (96.00%) (19980/20608)
Epoch: 176 | Batch_idx: 170 |  Loss: (0.0889) |  Loss2: (0.0000) | Acc: (96.00%) (21221/21888)
Epoch: 176 | Batch_idx: 180 |  Loss: (0.0891) |  Loss2: (0.0000) | Acc: (96.00%) (22463/23168)
Epoch: 176 | Batch_idx: 190 |  Loss: (0.0893) |  Loss2: (0.0000) | Acc: (96.00%) (23699/24448)
Epoch: 176 | Batch_idx: 200 |  Loss: (0.0896) |  Loss2: (0.0000) | Acc: (96.00%) (24929/25728)
Epoch: 176 | Batch_idx: 210 |  Loss: (0.0906) |  Loss2: (0.0000) | Acc: (96.00%) (26161/27008)
Epoch: 176 | Batch_idx: 220 |  Loss: (0.0902) |  Loss2: (0.0000) | Acc: (96.00%) (27405/28288)
Epoch: 176 | Batch_idx: 230 |  Loss: (0.0903) |  Loss2: (0.0000) | Acc: (96.00%) (28643/29568)
Epoch: 176 | Batch_idx: 240 |  Loss: (0.0907) |  Loss2: (0.0000) | Acc: (96.00%) (29877/30848)
Epoch: 176 | Batch_idx: 250 |  Loss: (0.0904) |  Loss2: (0.0000) | Acc: (96.00%) (31114/32128)
Epoch: 176 | Batch_idx: 260 |  Loss: (0.0904) |  Loss2: (0.0000) | Acc: (96.00%) (32353/33408)
Epoch: 176 | Batch_idx: 270 |  Loss: (0.0906) |  Loss2: (0.0000) | Acc: (96.00%) (33589/34688)
Epoch: 176 | Batch_idx: 280 |  Loss: (0.0905) |  Loss2: (0.0000) | Acc: (96.00%) (34832/35968)
Epoch: 176 | Batch_idx: 290 |  Loss: (0.0912) |  Loss2: (0.0000) | Acc: (96.00%) (36058/37248)
Epoch: 176 | Batch_idx: 300 |  Loss: (0.0913) |  Loss2: (0.0000) | Acc: (96.00%) (37298/38528)
Epoch: 176 | Batch_idx: 310 |  Loss: (0.0913) |  Loss2: (0.0000) | Acc: (96.00%) (38538/39808)
Epoch: 176 | Batch_idx: 320 |  Loss: (0.0913) |  Loss2: (0.0000) | Acc: (96.00%) (39783/41088)
Epoch: 176 | Batch_idx: 330 |  Loss: (0.0909) |  Loss2: (0.0000) | Acc: (96.00%) (41033/42368)
Epoch: 176 | Batch_idx: 340 |  Loss: (0.0906) |  Loss2: (0.0000) | Acc: (96.00%) (42279/43648)
Epoch: 176 | Batch_idx: 350 |  Loss: (0.0904) |  Loss2: (0.0000) | Acc: (96.00%) (43522/44928)
Epoch: 176 | Batch_idx: 360 |  Loss: (0.0908) |  Loss2: (0.0000) | Acc: (96.00%) (44748/46208)
Epoch: 176 | Batch_idx: 370 |  Loss: (0.0906) |  Loss2: (0.0000) | Acc: (96.00%) (45993/47488)
Epoch: 176 | Batch_idx: 380 |  Loss: (0.0905) |  Loss2: (0.0000) | Acc: (96.00%) (47232/48768)
Epoch: 176 | Batch_idx: 390 |  Loss: (0.0904) |  Loss2: (0.0000) | Acc: (96.00%) (48432/50000)
# TEST : Loss: (0.3752) | Acc: (88.00%) (8889/10000)
percent tensor([0.5222, 0.5147, 0.5258, 0.5187, 0.5289, 0.5297, 0.5209, 0.5210, 0.5244,
        0.5160, 0.5242, 0.5207, 0.5156, 0.5173, 0.5215, 0.5195],
       device='cuda:0') torch.Size([16])
percent tensor([0.5019, 0.4950, 0.5045, 0.5030, 0.5010, 0.5020, 0.4981, 0.5033, 0.5057,
        0.4993, 0.5042, 0.4997, 0.4967, 0.5079, 0.4966, 0.5031],
       device='cuda:0') torch.Size([16])
percent tensor([0.5616, 0.5435, 0.5744, 0.5876, 0.5793, 0.5771, 0.5691, 0.5663, 0.5643,
        0.5566, 0.5598, 0.5718, 0.5172, 0.6190, 0.5524, 0.5771],
       device='cuda:0') torch.Size([16])
percent tensor([0.6273, 0.6498, 0.6295, 0.6238, 0.6168, 0.6284, 0.6374, 0.6161, 0.6531,
        0.6570, 0.6662, 0.6419, 0.6529, 0.6623, 0.6203, 0.6416],
       device='cuda:0') torch.Size([16])
percent tensor([0.5876, 0.7140, 0.5186, 0.6549, 0.5271, 0.6737, 0.6108, 0.3784, 0.7210,
        0.6883, 0.7526, 0.6243, 0.6886, 0.7227, 0.5454, 0.6401],
       device='cuda:0') torch.Size([16])
percent tensor([0.6239, 0.6290, 0.6528, 0.6340, 0.6895, 0.6437, 0.6481, 0.6671, 0.6350,
        0.6293, 0.5854, 0.5958, 0.5946, 0.6034, 0.6132, 0.6469],
       device='cuda:0') torch.Size([16])
percent tensor([0.5272, 0.5975, 0.7662, 0.6931, 0.7823, 0.7611, 0.6395, 0.6999, 0.6639,
        0.5933, 0.7032, 0.6313, 0.6322, 0.5674, 0.6152, 0.4962],
       device='cuda:0') torch.Size([16])
percent tensor([0.9997, 0.9996, 0.9997, 0.9996, 0.9996, 0.9991, 0.9996, 0.9997, 0.9998,
        0.9998, 0.9999, 0.9997, 0.9998, 0.9987, 0.9997, 0.9993],
       device='cuda:0') torch.Size([16])
Epoch: 177 | Batch_idx: 0 |  Loss: (0.1260) |  Loss2: (0.0000) | Acc: (94.00%) (121/128)
Epoch: 177 | Batch_idx: 10 |  Loss: (0.0974) |  Loss2: (0.0000) | Acc: (96.00%) (1360/1408)
Epoch: 177 | Batch_idx: 20 |  Loss: (0.0962) |  Loss2: (0.0000) | Acc: (96.00%) (2600/2688)
Epoch: 177 | Batch_idx: 30 |  Loss: (0.0908) |  Loss2: (0.0000) | Acc: (97.00%) (3849/3968)
Epoch: 177 | Batch_idx: 40 |  Loss: (0.0930) |  Loss2: (0.0000) | Acc: (96.00%) (5087/5248)
Epoch: 177 | Batch_idx: 50 |  Loss: (0.0923) |  Loss2: (0.0000) | Acc: (96.00%) (6328/6528)
Epoch: 177 | Batch_idx: 60 |  Loss: (0.0946) |  Loss2: (0.0000) | Acc: (96.00%) (7563/7808)
Epoch: 177 | Batch_idx: 70 |  Loss: (0.0949) |  Loss2: (0.0000) | Acc: (96.00%) (8798/9088)
Epoch: 177 | Batch_idx: 80 |  Loss: (0.0949) |  Loss2: (0.0000) | Acc: (96.00%) (10039/10368)
Epoch: 177 | Batch_idx: 90 |  Loss: (0.0942) |  Loss2: (0.0000) | Acc: (96.00%) (11281/11648)
Epoch: 177 | Batch_idx: 100 |  Loss: (0.0931) |  Loss2: (0.0000) | Acc: (96.00%) (12529/12928)
Epoch: 177 | Batch_idx: 110 |  Loss: (0.0930) |  Loss2: (0.0000) | Acc: (96.00%) (13764/14208)
Epoch: 177 | Batch_idx: 120 |  Loss: (0.0928) |  Loss2: (0.0000) | Acc: (96.00%) (15014/15488)
Epoch: 177 | Batch_idx: 130 |  Loss: (0.0921) |  Loss2: (0.0000) | Acc: (96.00%) (16260/16768)
Epoch: 177 | Batch_idx: 140 |  Loss: (0.0930) |  Loss2: (0.0000) | Acc: (96.00%) (17497/18048)
Epoch: 177 | Batch_idx: 150 |  Loss: (0.0919) |  Loss2: (0.0000) | Acc: (97.00%) (18750/19328)
Epoch: 177 | Batch_idx: 160 |  Loss: (0.0924) |  Loss2: (0.0000) | Acc: (96.00%) (19988/20608)
Epoch: 177 | Batch_idx: 170 |  Loss: (0.0927) |  Loss2: (0.0000) | Acc: (96.00%) (21231/21888)
Epoch: 177 | Batch_idx: 180 |  Loss: (0.0924) |  Loss2: (0.0000) | Acc: (97.00%) (22475/23168)
Epoch: 177 | Batch_idx: 190 |  Loss: (0.0928) |  Loss2: (0.0000) | Acc: (96.00%) (23706/24448)
Epoch: 177 | Batch_idx: 200 |  Loss: (0.0928) |  Loss2: (0.0000) | Acc: (96.00%) (24944/25728)
Epoch: 177 | Batch_idx: 210 |  Loss: (0.0929) |  Loss2: (0.0000) | Acc: (96.00%) (26185/27008)
Epoch: 177 | Batch_idx: 220 |  Loss: (0.0928) |  Loss2: (0.0000) | Acc: (96.00%) (27433/28288)
Epoch: 177 | Batch_idx: 230 |  Loss: (0.0926) |  Loss2: (0.0000) | Acc: (97.00%) (28684/29568)
Epoch: 177 | Batch_idx: 240 |  Loss: (0.0919) |  Loss2: (0.0000) | Acc: (97.00%) (29938/30848)
Epoch: 177 | Batch_idx: 250 |  Loss: (0.0913) |  Loss2: (0.0000) | Acc: (97.00%) (31184/32128)
Epoch: 177 | Batch_idx: 260 |  Loss: (0.0910) |  Loss2: (0.0000) | Acc: (97.00%) (32430/33408)
Epoch: 177 | Batch_idx: 270 |  Loss: (0.0911) |  Loss2: (0.0000) | Acc: (97.00%) (33672/34688)
Epoch: 177 | Batch_idx: 280 |  Loss: (0.0911) |  Loss2: (0.0000) | Acc: (97.00%) (34916/35968)
Epoch: 177 | Batch_idx: 290 |  Loss: (0.0913) |  Loss2: (0.0000) | Acc: (97.00%) (36152/37248)
Epoch: 177 | Batch_idx: 300 |  Loss: (0.0919) |  Loss2: (0.0000) | Acc: (97.00%) (37385/38528)
Epoch: 177 | Batch_idx: 310 |  Loss: (0.0913) |  Loss2: (0.0000) | Acc: (97.00%) (38642/39808)
Epoch: 177 | Batch_idx: 320 |  Loss: (0.0914) |  Loss2: (0.0000) | Acc: (97.00%) (39877/41088)
Epoch: 177 | Batch_idx: 330 |  Loss: (0.0916) |  Loss2: (0.0000) | Acc: (97.00%) (41116/42368)
Epoch: 177 | Batch_idx: 340 |  Loss: (0.0917) |  Loss2: (0.0000) | Acc: (97.00%) (42357/43648)
Epoch: 177 | Batch_idx: 350 |  Loss: (0.0913) |  Loss2: (0.0000) | Acc: (97.00%) (43602/44928)
Epoch: 177 | Batch_idx: 360 |  Loss: (0.0909) |  Loss2: (0.0000) | Acc: (97.00%) (44857/46208)
Epoch: 177 | Batch_idx: 370 |  Loss: (0.0905) |  Loss2: (0.0000) | Acc: (97.00%) (46105/47488)
Epoch: 177 | Batch_idx: 380 |  Loss: (0.0900) |  Loss2: (0.0000) | Acc: (97.00%) (47356/48768)
Epoch: 177 | Batch_idx: 390 |  Loss: (0.0898) |  Loss2: (0.0000) | Acc: (97.00%) (48558/50000)
# TEST : Loss: (0.3722) | Acc: (88.00%) (8886/10000)
percent tensor([0.5220, 0.5144, 0.5258, 0.5187, 0.5289, 0.5294, 0.5206, 0.5210, 0.5244,
        0.5160, 0.5239, 0.5207, 0.5156, 0.5172, 0.5211, 0.5194],
       device='cuda:0') torch.Size([16])
percent tensor([0.5018, 0.4948, 0.5046, 0.5032, 0.5009, 0.5019, 0.4980, 0.5034, 0.5057,
        0.4991, 0.5040, 0.4997, 0.4966, 0.5078, 0.4964, 0.5030],
       device='cuda:0') torch.Size([16])
percent tensor([0.5617, 0.5431, 0.5746, 0.5888, 0.5796, 0.5791, 0.5686, 0.5663, 0.5648,
        0.5561, 0.5596, 0.5715, 0.5170, 0.6193, 0.5527, 0.5777],
       device='cuda:0') torch.Size([16])
percent tensor([0.6287, 0.6517, 0.6318, 0.6259, 0.6184, 0.6295, 0.6393, 0.6180, 0.6552,
        0.6593, 0.6686, 0.6444, 0.6546, 0.6646, 0.6216, 0.6432],
       device='cuda:0') torch.Size([16])
percent tensor([0.5896, 0.7179, 0.5160, 0.6497, 0.5291, 0.6672, 0.6173, 0.3825, 0.7212,
        0.6915, 0.7510, 0.6256, 0.6916, 0.7243, 0.5503, 0.6412],
       device='cuda:0') torch.Size([16])
percent tensor([0.6162, 0.6224, 0.6449, 0.6261, 0.6823, 0.6363, 0.6410, 0.6605, 0.6280,
        0.6223, 0.5783, 0.5878, 0.5883, 0.5962, 0.6048, 0.6397],
       device='cuda:0') torch.Size([16])
percent tensor([0.5250, 0.6025, 0.7632, 0.6912, 0.7814, 0.7618, 0.6401, 0.6999, 0.6624,
        0.5978, 0.7028, 0.6292, 0.6322, 0.5684, 0.6178, 0.4965],
       device='cuda:0') torch.Size([16])
percent tensor([0.9997, 0.9996, 0.9997, 0.9997, 0.9996, 0.9991, 0.9996, 0.9997, 0.9998,
        0.9998, 0.9999, 0.9997, 0.9998, 0.9988, 0.9997, 0.9993],
       device='cuda:0') torch.Size([16])
Epoch: 178 | Batch_idx: 0 |  Loss: (0.0896) |  Loss2: (0.0000) | Acc: (95.00%) (122/128)
Epoch: 178 | Batch_idx: 10 |  Loss: (0.0966) |  Loss2: (0.0000) | Acc: (96.00%) (1356/1408)
Epoch: 178 | Batch_idx: 20 |  Loss: (0.0933) |  Loss2: (0.0000) | Acc: (96.00%) (2599/2688)
Epoch: 178 | Batch_idx: 30 |  Loss: (0.0962) |  Loss2: (0.0000) | Acc: (96.00%) (3841/3968)
Epoch: 178 | Batch_idx: 40 |  Loss: (0.0930) |  Loss2: (0.0000) | Acc: (96.00%) (5089/5248)
Epoch: 178 | Batch_idx: 50 |  Loss: (0.0923) |  Loss2: (0.0000) | Acc: (96.00%) (6330/6528)
Epoch: 178 | Batch_idx: 60 |  Loss: (0.0925) |  Loss2: (0.0000) | Acc: (96.00%) (7573/7808)
Epoch: 178 | Batch_idx: 70 |  Loss: (0.0918) |  Loss2: (0.0000) | Acc: (97.00%) (8816/9088)
Epoch: 178 | Batch_idx: 80 |  Loss: (0.0919) |  Loss2: (0.0000) | Acc: (97.00%) (10063/10368)
Epoch: 178 | Batch_idx: 90 |  Loss: (0.0937) |  Loss2: (0.0000) | Acc: (96.00%) (11288/11648)
Epoch: 178 | Batch_idx: 100 |  Loss: (0.0934) |  Loss2: (0.0000) | Acc: (96.00%) (12530/12928)
Epoch: 178 | Batch_idx: 110 |  Loss: (0.0932) |  Loss2: (0.0000) | Acc: (96.00%) (13765/14208)
Epoch: 178 | Batch_idx: 120 |  Loss: (0.0923) |  Loss2: (0.0000) | Acc: (96.00%) (15017/15488)
Epoch: 178 | Batch_idx: 130 |  Loss: (0.0925) |  Loss2: (0.0000) | Acc: (96.00%) (16258/16768)
Epoch: 178 | Batch_idx: 140 |  Loss: (0.0922) |  Loss2: (0.0000) | Acc: (96.00%) (17497/18048)
Epoch: 178 | Batch_idx: 150 |  Loss: (0.0919) |  Loss2: (0.0000) | Acc: (96.00%) (18742/19328)
Epoch: 178 | Batch_idx: 160 |  Loss: (0.0923) |  Loss2: (0.0000) | Acc: (96.00%) (19978/20608)
Epoch: 178 | Batch_idx: 170 |  Loss: (0.0927) |  Loss2: (0.0000) | Acc: (96.00%) (21213/21888)
Epoch: 178 | Batch_idx: 180 |  Loss: (0.0924) |  Loss2: (0.0000) | Acc: (96.00%) (22452/23168)
Epoch: 178 | Batch_idx: 190 |  Loss: (0.0923) |  Loss2: (0.0000) | Acc: (96.00%) (23694/24448)
Epoch: 178 | Batch_idx: 200 |  Loss: (0.0924) |  Loss2: (0.0000) | Acc: (96.00%) (24933/25728)
Epoch: 178 | Batch_idx: 210 |  Loss: (0.0921) |  Loss2: (0.0000) | Acc: (96.00%) (26176/27008)
Epoch: 178 | Batch_idx: 220 |  Loss: (0.0915) |  Loss2: (0.0000) | Acc: (96.00%) (27432/28288)
Epoch: 178 | Batch_idx: 230 |  Loss: (0.0910) |  Loss2: (0.0000) | Acc: (96.00%) (28678/29568)
Epoch: 178 | Batch_idx: 240 |  Loss: (0.0911) |  Loss2: (0.0000) | Acc: (96.00%) (29916/30848)
Epoch: 178 | Batch_idx: 250 |  Loss: (0.0912) |  Loss2: (0.0000) | Acc: (96.00%) (31158/32128)
Epoch: 178 | Batch_idx: 260 |  Loss: (0.0916) |  Loss2: (0.0000) | Acc: (96.00%) (32390/33408)
Epoch: 178 | Batch_idx: 270 |  Loss: (0.0915) |  Loss2: (0.0000) | Acc: (96.00%) (33640/34688)
Epoch: 178 | Batch_idx: 280 |  Loss: (0.0915) |  Loss2: (0.0000) | Acc: (96.00%) (34879/35968)
Epoch: 178 | Batch_idx: 290 |  Loss: (0.0909) |  Loss2: (0.0000) | Acc: (96.00%) (36130/37248)
Epoch: 178 | Batch_idx: 300 |  Loss: (0.0908) |  Loss2: (0.0000) | Acc: (96.00%) (37369/38528)
Epoch: 178 | Batch_idx: 310 |  Loss: (0.0908) |  Loss2: (0.0000) | Acc: (96.00%) (38612/39808)
Epoch: 178 | Batch_idx: 320 |  Loss: (0.0912) |  Loss2: (0.0000) | Acc: (96.00%) (39845/41088)
Epoch: 178 | Batch_idx: 330 |  Loss: (0.0910) |  Loss2: (0.0000) | Acc: (96.00%) (41085/42368)
Epoch: 178 | Batch_idx: 340 |  Loss: (0.0910) |  Loss2: (0.0000) | Acc: (96.00%) (42330/43648)
Epoch: 178 | Batch_idx: 350 |  Loss: (0.0908) |  Loss2: (0.0000) | Acc: (96.00%) (43574/44928)
Epoch: 178 | Batch_idx: 360 |  Loss: (0.0905) |  Loss2: (0.0000) | Acc: (96.00%) (44819/46208)
Epoch: 178 | Batch_idx: 370 |  Loss: (0.0903) |  Loss2: (0.0000) | Acc: (97.00%) (46065/47488)
Epoch: 178 | Batch_idx: 380 |  Loss: (0.0907) |  Loss2: (0.0000) | Acc: (96.00%) (47302/48768)
Epoch: 178 | Batch_idx: 390 |  Loss: (0.0905) |  Loss2: (0.0000) | Acc: (97.00%) (48500/50000)
# TEST : Loss: (0.3731) | Acc: (88.00%) (8897/10000)
percent tensor([0.5209, 0.5134, 0.5244, 0.5174, 0.5274, 0.5283, 0.5194, 0.5196, 0.5234,
        0.5148, 0.5229, 0.5194, 0.5146, 0.5164, 0.5199, 0.5183],
       device='cuda:0') torch.Size([16])
percent tensor([0.5030, 0.4962, 0.5058, 0.5043, 0.5021, 0.5030, 0.4993, 0.5048, 0.5069,
        0.5005, 0.5052, 0.5009, 0.4978, 0.5090, 0.4977, 0.5042],
       device='cuda:0') torch.Size([16])
percent tensor([0.5641, 0.5440, 0.5798, 0.5936, 0.5856, 0.5822, 0.5720, 0.5730, 0.5674,
        0.5576, 0.5607, 0.5751, 0.5171, 0.6213, 0.5564, 0.5799],
       device='cuda:0') torch.Size([16])
percent tensor([0.6266, 0.6503, 0.6291, 0.6229, 0.6155, 0.6271, 0.6371, 0.6150, 0.6536,
        0.6578, 0.6671, 0.6423, 0.6533, 0.6628, 0.6189, 0.6412],
       device='cuda:0') torch.Size([16])
percent tensor([0.5826, 0.7122, 0.5085, 0.6420, 0.5213, 0.6613, 0.6088, 0.3719, 0.7165,
        0.6839, 0.7431, 0.6158, 0.6861, 0.7211, 0.5397, 0.6326],
       device='cuda:0') torch.Size([16])
percent tensor([0.6197, 0.6281, 0.6478, 0.6296, 0.6851, 0.6395, 0.6449, 0.6630, 0.6331,
        0.6271, 0.5826, 0.5918, 0.5943, 0.6014, 0.6089, 0.6442],
       device='cuda:0') torch.Size([16])
percent tensor([0.5224, 0.6012, 0.7585, 0.6877, 0.7764, 0.7615, 0.6346, 0.6923, 0.6583,
        0.5982, 0.7021, 0.6282, 0.6300, 0.5672, 0.6121, 0.4925],
       device='cuda:0') torch.Size([16])
percent tensor([0.9997, 0.9996, 0.9997, 0.9997, 0.9997, 0.9992, 0.9996, 0.9997, 0.9998,
        0.9998, 0.9999, 0.9997, 0.9999, 0.9988, 0.9997, 0.9993],
       device='cuda:0') torch.Size([16])
Epoch: 179 | Batch_idx: 0 |  Loss: (0.0894) |  Loss2: (0.0000) | Acc: (96.00%) (124/128)
Epoch: 179 | Batch_idx: 10 |  Loss: (0.0858) |  Loss2: (0.0000) | Acc: (97.00%) (1367/1408)
Epoch: 179 | Batch_idx: 20 |  Loss: (0.0901) |  Loss2: (0.0000) | Acc: (97.00%) (2609/2688)
Epoch: 179 | Batch_idx: 30 |  Loss: (0.0891) |  Loss2: (0.0000) | Acc: (96.00%) (3846/3968)
Epoch: 179 | Batch_idx: 40 |  Loss: (0.0883) |  Loss2: (0.0000) | Acc: (96.00%) (5086/5248)
Epoch: 179 | Batch_idx: 50 |  Loss: (0.0901) |  Loss2: (0.0000) | Acc: (97.00%) (6334/6528)
Epoch: 179 | Batch_idx: 60 |  Loss: (0.0907) |  Loss2: (0.0000) | Acc: (97.00%) (7574/7808)
Epoch: 179 | Batch_idx: 70 |  Loss: (0.0882) |  Loss2: (0.0000) | Acc: (97.00%) (8825/9088)
Epoch: 179 | Batch_idx: 80 |  Loss: (0.0869) |  Loss2: (0.0000) | Acc: (97.00%) (10069/10368)
Epoch: 179 | Batch_idx: 90 |  Loss: (0.0853) |  Loss2: (0.0000) | Acc: (97.00%) (11314/11648)
Epoch: 179 | Batch_idx: 100 |  Loss: (0.0859) |  Loss2: (0.0000) | Acc: (97.00%) (12560/12928)
Epoch: 179 | Batch_idx: 110 |  Loss: (0.0852) |  Loss2: (0.0000) | Acc: (97.00%) (13814/14208)
Epoch: 179 | Batch_idx: 120 |  Loss: (0.0844) |  Loss2: (0.0000) | Acc: (97.00%) (15064/15488)
Epoch: 179 | Batch_idx: 130 |  Loss: (0.0846) |  Loss2: (0.0000) | Acc: (97.00%) (16311/16768)
Epoch: 179 | Batch_idx: 140 |  Loss: (0.0850) |  Loss2: (0.0000) | Acc: (97.00%) (17550/18048)
Epoch: 179 | Batch_idx: 150 |  Loss: (0.0855) |  Loss2: (0.0000) | Acc: (97.00%) (18793/19328)
Epoch: 179 | Batch_idx: 160 |  Loss: (0.0855) |  Loss2: (0.0000) | Acc: (97.00%) (20044/20608)
Epoch: 179 | Batch_idx: 170 |  Loss: (0.0860) |  Loss2: (0.0000) | Acc: (97.00%) (21285/21888)
Epoch: 179 | Batch_idx: 180 |  Loss: (0.0863) |  Loss2: (0.0000) | Acc: (97.00%) (22521/23168)
Epoch: 179 | Batch_idx: 190 |  Loss: (0.0861) |  Loss2: (0.0000) | Acc: (97.00%) (23768/24448)
Epoch: 179 | Batch_idx: 200 |  Loss: (0.0858) |  Loss2: (0.0000) | Acc: (97.00%) (25013/25728)
Epoch: 179 | Batch_idx: 210 |  Loss: (0.0853) |  Loss2: (0.0000) | Acc: (97.00%) (26263/27008)
Epoch: 179 | Batch_idx: 220 |  Loss: (0.0858) |  Loss2: (0.0000) | Acc: (97.00%) (27509/28288)
Epoch: 179 | Batch_idx: 230 |  Loss: (0.0862) |  Loss2: (0.0000) | Acc: (97.00%) (28748/29568)
Epoch: 179 | Batch_idx: 240 |  Loss: (0.0866) |  Loss2: (0.0000) | Acc: (97.00%) (29986/30848)
Epoch: 179 | Batch_idx: 250 |  Loss: (0.0875) |  Loss2: (0.0000) | Acc: (97.00%) (31218/32128)
Epoch: 179 | Batch_idx: 260 |  Loss: (0.0875) |  Loss2: (0.0000) | Acc: (97.00%) (32463/33408)
Epoch: 179 | Batch_idx: 270 |  Loss: (0.0873) |  Loss2: (0.0000) | Acc: (97.00%) (33708/34688)
Epoch: 179 | Batch_idx: 280 |  Loss: (0.0875) |  Loss2: (0.0000) | Acc: (97.00%) (34946/35968)
Epoch: 179 | Batch_idx: 290 |  Loss: (0.0872) |  Loss2: (0.0000) | Acc: (97.00%) (36191/37248)
Epoch: 179 | Batch_idx: 300 |  Loss: (0.0871) |  Loss2: (0.0000) | Acc: (97.00%) (37439/38528)
Epoch: 179 | Batch_idx: 310 |  Loss: (0.0868) |  Loss2: (0.0000) | Acc: (97.00%) (38683/39808)
Epoch: 179 | Batch_idx: 320 |  Loss: (0.0866) |  Loss2: (0.0000) | Acc: (97.00%) (39930/41088)
Epoch: 179 | Batch_idx: 330 |  Loss: (0.0868) |  Loss2: (0.0000) | Acc: (97.00%) (41169/42368)
Epoch: 179 | Batch_idx: 340 |  Loss: (0.0868) |  Loss2: (0.0000) | Acc: (97.00%) (42418/43648)
Epoch: 179 | Batch_idx: 350 |  Loss: (0.0870) |  Loss2: (0.0000) | Acc: (97.00%) (43663/44928)
Epoch: 179 | Batch_idx: 360 |  Loss: (0.0871) |  Loss2: (0.0000) | Acc: (97.00%) (44908/46208)
Epoch: 179 | Batch_idx: 370 |  Loss: (0.0866) |  Loss2: (0.0000) | Acc: (97.00%) (46161/47488)
Epoch: 179 | Batch_idx: 380 |  Loss: (0.0865) |  Loss2: (0.0000) | Acc: (97.00%) (47405/48768)
Epoch: 179 | Batch_idx: 390 |  Loss: (0.0866) |  Loss2: (0.0000) | Acc: (97.00%) (48599/50000)
# TEST : Loss: (0.3727) | Acc: (88.00%) (8890/10000)
percent tensor([0.5220, 0.5149, 0.5256, 0.5186, 0.5290, 0.5293, 0.5209, 0.5209, 0.5248,
        0.5162, 0.5242, 0.5208, 0.5157, 0.5178, 0.5212, 0.5193],
       device='cuda:0') torch.Size([16])
percent tensor([0.5041, 0.4974, 0.5066, 0.5054, 0.5032, 0.5039, 0.5004, 0.5060, 0.5079,
        0.5017, 0.5064, 0.5019, 0.4990, 0.5101, 0.4989, 0.5054],
       device='cuda:0') torch.Size([16])
percent tensor([0.5590, 0.5391, 0.5750, 0.5900, 0.5804, 0.5783, 0.5668, 0.5681, 0.5631,
        0.5526, 0.5558, 0.5700, 0.5121, 0.6177, 0.5513, 0.5755],
       device='cuda:0') torch.Size([16])
percent tensor([0.6222, 0.6464, 0.6261, 0.6195, 0.6123, 0.6229, 0.6332, 0.6114, 0.6499,
        0.6538, 0.6628, 0.6389, 0.6490, 0.6588, 0.6150, 0.6362],
       device='cuda:0') torch.Size([16])
percent tensor([0.5829, 0.7138, 0.5113, 0.6454, 0.5243, 0.6587, 0.6116, 0.3780, 0.7190,
        0.6854, 0.7426, 0.6200, 0.6868, 0.7218, 0.5447, 0.6314],
       device='cuda:0') torch.Size([16])
percent tensor([0.6271, 0.6374, 0.6552, 0.6375, 0.6934, 0.6464, 0.6543, 0.6701, 0.6421,
        0.6359, 0.5909, 0.5998, 0.6036, 0.6099, 0.6168, 0.6532],
       device='cuda:0') torch.Size([16])
percent tensor([0.5306, 0.6139, 0.7581, 0.6853, 0.7743, 0.7637, 0.6455, 0.6943, 0.6671,
        0.6072, 0.7084, 0.6299, 0.6445, 0.5745, 0.6183, 0.4999],
       device='cuda:0') torch.Size([16])
percent tensor([0.9998, 0.9996, 0.9997, 0.9997, 0.9996, 0.9992, 0.9997, 0.9997, 0.9998,
        0.9998, 0.9999, 0.9997, 0.9999, 0.9989, 0.9997, 0.9993],
       device='cuda:0') torch.Size([16])
True Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=128, out_features=16, bias=False)
False Linear(in_features=16, out_features=2, bias=False)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=128, out_features=16, bias=False)
False Linear(in_features=16, out_features=2, bias=False)
True Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=256, out_features=32, bias=False)
False Linear(in_features=32, out_features=2, bias=False)
True Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=256, out_features=32, bias=False)
False Linear(in_features=32, out_features=2, bias=False)
True Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=512, out_features=64, bias=False)
False Linear(in_features=64, out_features=2, bias=False)
True Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=512, out_features=64, bias=False)
False Linear(in_features=64, out_features=2, bias=False)
True Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1024, out_features=128, bias=False)
False Linear(in_features=128, out_features=2, bias=False)
True Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1024, out_features=128, bias=False)
False Linear(in_features=128, out_features=2, bias=False)
True Linear(in_features=512, out_features=10, bias=True)
Epoch: 180 | Batch_idx: 0 |  Loss: (0.0946) |  Loss2: (0.0000) | Acc: (96.00%) (123/128)
Epoch: 180 | Batch_idx: 10 |  Loss: (0.0891) |  Loss2: (0.0000) | Acc: (96.00%) (1360/1408)
Epoch: 180 | Batch_idx: 20 |  Loss: (0.0988) |  Loss2: (0.0000) | Acc: (96.00%) (2596/2688)
Epoch: 180 | Batch_idx: 30 |  Loss: (0.0968) |  Loss2: (0.0000) | Acc: (96.00%) (3831/3968)
Epoch: 180 | Batch_idx: 40 |  Loss: (0.0960) |  Loss2: (0.0000) | Acc: (96.00%) (5077/5248)
Epoch: 180 | Batch_idx: 50 |  Loss: (0.1001) |  Loss2: (0.0000) | Acc: (96.00%) (6308/6528)
Epoch: 180 | Batch_idx: 60 |  Loss: (0.1004) |  Loss2: (0.0000) | Acc: (96.00%) (7542/7808)
Epoch: 180 | Batch_idx: 70 |  Loss: (0.1009) |  Loss2: (0.0000) | Acc: (96.00%) (8782/9088)
Epoch: 180 | Batch_idx: 80 |  Loss: (0.1005) |  Loss2: (0.0000) | Acc: (96.00%) (10014/10368)
Epoch: 180 | Batch_idx: 90 |  Loss: (0.1020) |  Loss2: (0.0000) | Acc: (96.00%) (11236/11648)
Epoch: 180 | Batch_idx: 100 |  Loss: (0.1028) |  Loss2: (0.0000) | Acc: (96.00%) (12469/12928)
Epoch: 180 | Batch_idx: 110 |  Loss: (0.1027) |  Loss2: (0.0000) | Acc: (96.00%) (13704/14208)
Epoch: 180 | Batch_idx: 120 |  Loss: (0.1022) |  Loss2: (0.0000) | Acc: (96.00%) (14945/15488)
Epoch: 180 | Batch_idx: 130 |  Loss: (0.1011) |  Loss2: (0.0000) | Acc: (96.00%) (16189/16768)
Epoch: 180 | Batch_idx: 140 |  Loss: (0.1011) |  Loss2: (0.0000) | Acc: (96.00%) (17428/18048)
Epoch: 180 | Batch_idx: 150 |  Loss: (0.1004) |  Loss2: (0.0000) | Acc: (96.00%) (18662/19328)
Epoch: 180 | Batch_idx: 160 |  Loss: (0.0994) |  Loss2: (0.0000) | Acc: (96.00%) (19912/20608)
Epoch: 180 | Batch_idx: 170 |  Loss: (0.1001) |  Loss2: (0.0000) | Acc: (96.00%) (21137/21888)
Epoch: 180 | Batch_idx: 180 |  Loss: (0.0996) |  Loss2: (0.0000) | Acc: (96.00%) (22377/23168)
Epoch: 180 | Batch_idx: 190 |  Loss: (0.1004) |  Loss2: (0.0000) | Acc: (96.00%) (23605/24448)
Epoch: 180 | Batch_idx: 200 |  Loss: (0.1005) |  Loss2: (0.0000) | Acc: (96.00%) (24840/25728)
Epoch: 180 | Batch_idx: 210 |  Loss: (0.1018) |  Loss2: (0.0000) | Acc: (96.00%) (26068/27008)
Epoch: 180 | Batch_idx: 220 |  Loss: (0.1020) |  Loss2: (0.0000) | Acc: (96.00%) (27301/28288)
Epoch: 180 | Batch_idx: 230 |  Loss: (0.1027) |  Loss2: (0.0000) | Acc: (96.00%) (28528/29568)
Epoch: 180 | Batch_idx: 240 |  Loss: (0.1031) |  Loss2: (0.0000) | Acc: (96.00%) (29752/30848)
Epoch: 180 | Batch_idx: 250 |  Loss: (0.1030) |  Loss2: (0.0000) | Acc: (96.00%) (30989/32128)
Epoch: 180 | Batch_idx: 260 |  Loss: (0.1031) |  Loss2: (0.0000) | Acc: (96.00%) (32225/33408)
Epoch: 180 | Batch_idx: 270 |  Loss: (0.1032) |  Loss2: (0.0000) | Acc: (96.00%) (33456/34688)
Epoch: 180 | Batch_idx: 280 |  Loss: (0.1041) |  Loss2: (0.0000) | Acc: (96.00%) (34676/35968)
Epoch: 180 | Batch_idx: 290 |  Loss: (0.1045) |  Loss2: (0.0000) | Acc: (96.00%) (35908/37248)
Epoch: 180 | Batch_idx: 300 |  Loss: (0.1042) |  Loss2: (0.0000) | Acc: (96.00%) (37147/38528)
Epoch: 180 | Batch_idx: 310 |  Loss: (0.1044) |  Loss2: (0.0000) | Acc: (96.00%) (38382/39808)
Epoch: 180 | Batch_idx: 320 |  Loss: (0.1038) |  Loss2: (0.0000) | Acc: (96.00%) (39626/41088)
Epoch: 180 | Batch_idx: 330 |  Loss: (0.1043) |  Loss2: (0.0000) | Acc: (96.00%) (40852/42368)
Epoch: 180 | Batch_idx: 340 |  Loss: (0.1045) |  Loss2: (0.0000) | Acc: (96.00%) (42087/43648)
Epoch: 180 | Batch_idx: 350 |  Loss: (0.1048) |  Loss2: (0.0000) | Acc: (96.00%) (43318/44928)
Epoch: 180 | Batch_idx: 360 |  Loss: (0.1054) |  Loss2: (0.0000) | Acc: (96.00%) (44539/46208)
Epoch: 180 | Batch_idx: 370 |  Loss: (0.1056) |  Loss2: (0.0000) | Acc: (96.00%) (45767/47488)
Epoch: 180 | Batch_idx: 380 |  Loss: (0.1061) |  Loss2: (0.0000) | Acc: (96.00%) (46983/48768)
Epoch: 180 | Batch_idx: 390 |  Loss: (0.1057) |  Loss2: (0.0000) | Acc: (96.00%) (48180/50000)
=> saving checkpoint 'drive/app/torch/save_Schedule/checkpoint_180.pth.tar'
# TEST : Loss: (0.4191) | Acc: (88.00%) (8811/10000)
percent tensor([0.5217, 0.5152, 0.5251, 0.5194, 0.5294, 0.5283, 0.5213, 0.5218, 0.5253,
        0.5167, 0.5241, 0.5207, 0.5158, 0.5192, 0.5208, 0.5195],
       device='cuda:0') torch.Size([16])
percent tensor([0.5040, 0.4986, 0.5040, 0.5054, 0.5028, 0.5044, 0.5009, 0.5050, 0.5086,
        0.5012, 0.5072, 0.4993, 0.4985, 0.5129, 0.4993, 0.5059],
       device='cuda:0') torch.Size([16])
percent tensor([0.5577, 0.5439, 0.5570, 0.5886, 0.5732, 0.5769, 0.5691, 0.5637, 0.5668,
        0.5494, 0.5619, 0.5546, 0.5117, 0.6280, 0.5509, 0.5791],
       device='cuda:0') torch.Size([16])
percent tensor([0.6221, 0.6469, 0.6209, 0.6170, 0.6134, 0.6209, 0.6331, 0.6096, 0.6504,
        0.6530, 0.6628, 0.6371, 0.6494, 0.6631, 0.6139, 0.6372],
       device='cuda:0') torch.Size([16])
percent tensor([0.5929, 0.7005, 0.4804, 0.6174, 0.5351, 0.6718, 0.6229, 0.3742, 0.7047,
        0.6654, 0.7288, 0.5669, 0.6688, 0.7174, 0.5511, 0.6460],
       device='cuda:0') torch.Size([16])
percent tensor([0.6344, 0.6467, 0.6495, 0.6357, 0.6924, 0.6439, 0.6623, 0.6739, 0.6535,
        0.6381, 0.6056, 0.5917, 0.6114, 0.6141, 0.6178, 0.6486],
       device='cuda:0') torch.Size([16])
percent tensor([0.5526, 0.6051, 0.7477, 0.6771, 0.7822, 0.7658, 0.6425, 0.6772, 0.7094,
        0.5729, 0.7470, 0.5974, 0.6382, 0.5778, 0.6276, 0.5129],
       device='cuda:0') torch.Size([16])
percent tensor([0.9997, 0.9996, 0.9998, 0.9997, 0.9994, 0.9989, 0.9996, 0.9997, 0.9998,
        0.9998, 0.9999, 0.9999, 0.9999, 0.9994, 0.9996, 0.9992],
       device='cuda:0') torch.Size([16])
Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 3, 3, 3]) tensor(189.8348, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(834.1465, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(823.8743, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([128, 64, 3, 3]) tensor(1519.1028, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([128, 64, 1, 1]) tensor(475.8228, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([128, 128, 3, 3]) tensor(2302.1987, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([256, 128, 3, 3]) tensor(4245.9331, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([256, 128, 1, 1]) tensor(1349.7991, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([256, 256, 3, 3]) tensor(6208.3887, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([512, 256, 3, 3]) tensor(11573.7959, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([512, 256, 1, 1]) tensor(3818.1531, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([512, 512, 3, 3]) tensor(16131.1064, device='cuda:0', grad_fn=<NormBackward0>)
Epoch: 181 | Batch_idx: 0 |  Loss: (0.0388) |  Loss2: (0.0000) | Acc: (99.00%) (127/128)
Epoch: 181 | Batch_idx: 10 |  Loss: (0.0965) |  Loss2: (0.0000) | Acc: (96.00%) (1357/1408)
Epoch: 181 | Batch_idx: 20 |  Loss: (0.0941) |  Loss2: (0.0000) | Acc: (96.00%) (2600/2688)
Epoch: 181 | Batch_idx: 30 |  Loss: (0.0948) |  Loss2: (0.0000) | Acc: (96.00%) (3841/3968)
Epoch: 181 | Batch_idx: 40 |  Loss: (0.0940) |  Loss2: (0.0000) | Acc: (96.00%) (5081/5248)
Epoch: 181 | Batch_idx: 50 |  Loss: (0.0981) |  Loss2: (0.0000) | Acc: (96.00%) (6307/6528)
Epoch: 181 | Batch_idx: 60 |  Loss: (0.0984) |  Loss2: (0.0000) | Acc: (96.00%) (7546/7808)
Epoch: 181 | Batch_idx: 70 |  Loss: (0.1032) |  Loss2: (0.0000) | Acc: (96.00%) (8761/9088)
Epoch: 181 | Batch_idx: 80 |  Loss: (0.1041) |  Loss2: (0.0000) | Acc: (96.00%) (9987/10368)
Epoch: 181 | Batch_idx: 90 |  Loss: (0.1034) |  Loss2: (0.0000) | Acc: (96.00%) (11227/11648)
Epoch: 181 | Batch_idx: 100 |  Loss: (0.1025) |  Loss2: (0.0000) | Acc: (96.00%) (12467/12928)
Epoch: 181 | Batch_idx: 110 |  Loss: (0.1052) |  Loss2: (0.0000) | Acc: (96.00%) (13681/14208)
Epoch: 181 | Batch_idx: 120 |  Loss: (0.1055) |  Loss2: (0.0000) | Acc: (96.00%) (14910/15488)
Epoch: 181 | Batch_idx: 130 |  Loss: (0.1060) |  Loss2: (0.0000) | Acc: (96.00%) (16144/16768)
Epoch: 181 | Batch_idx: 140 |  Loss: (0.1058) |  Loss2: (0.0000) | Acc: (96.00%) (17380/18048)
Epoch: 181 | Batch_idx: 150 |  Loss: (0.1054) |  Loss2: (0.0000) | Acc: (96.00%) (18606/19328)
Epoch: 181 | Batch_idx: 160 |  Loss: (0.1038) |  Loss2: (0.0000) | Acc: (96.00%) (19853/20608)
Epoch: 181 | Batch_idx: 170 |  Loss: (0.1039) |  Loss2: (0.0000) | Acc: (96.00%) (21084/21888)
Epoch: 181 | Batch_idx: 180 |  Loss: (0.1049) |  Loss2: (0.0000) | Acc: (96.00%) (22311/23168)
Epoch: 181 | Batch_idx: 190 |  Loss: (0.1047) |  Loss2: (0.0000) | Acc: (96.00%) (23543/24448)
Epoch: 181 | Batch_idx: 200 |  Loss: (0.1044) |  Loss2: (0.0000) | Acc: (96.00%) (24781/25728)
Epoch: 181 | Batch_idx: 210 |  Loss: (0.1057) |  Loss2: (0.0000) | Acc: (96.00%) (26001/27008)
Epoch: 181 | Batch_idx: 220 |  Loss: (0.1062) |  Loss2: (0.0000) | Acc: (96.00%) (27223/28288)
Epoch: 181 | Batch_idx: 230 |  Loss: (0.1068) |  Loss2: (0.0000) | Acc: (96.00%) (28449/29568)
Epoch: 181 | Batch_idx: 240 |  Loss: (0.1060) |  Loss2: (0.0000) | Acc: (96.00%) (29693/30848)
Epoch: 181 | Batch_idx: 250 |  Loss: (0.1060) |  Loss2: (0.0000) | Acc: (96.00%) (30918/32128)
Epoch: 181 | Batch_idx: 260 |  Loss: (0.1058) |  Loss2: (0.0000) | Acc: (96.00%) (32153/33408)
Epoch: 181 | Batch_idx: 270 |  Loss: (0.1054) |  Loss2: (0.0000) | Acc: (96.00%) (33396/34688)
Epoch: 181 | Batch_idx: 280 |  Loss: (0.1053) |  Loss2: (0.0000) | Acc: (96.00%) (34634/35968)
Epoch: 181 | Batch_idx: 290 |  Loss: (0.1055) |  Loss2: (0.0000) | Acc: (96.00%) (35870/37248)
Epoch: 181 | Batch_idx: 300 |  Loss: (0.1051) |  Loss2: (0.0000) | Acc: (96.00%) (37110/38528)
Epoch: 181 | Batch_idx: 310 |  Loss: (0.1044) |  Loss2: (0.0000) | Acc: (96.00%) (38355/39808)
Epoch: 181 | Batch_idx: 320 |  Loss: (0.1040) |  Loss2: (0.0000) | Acc: (96.00%) (39597/41088)
Epoch: 181 | Batch_idx: 330 |  Loss: (0.1044) |  Loss2: (0.0000) | Acc: (96.00%) (40828/42368)
Epoch: 181 | Batch_idx: 340 |  Loss: (0.1050) |  Loss2: (0.0000) | Acc: (96.00%) (42060/43648)
Epoch: 181 | Batch_idx: 350 |  Loss: (0.1048) |  Loss2: (0.0000) | Acc: (96.00%) (43297/44928)
Epoch: 181 | Batch_idx: 360 |  Loss: (0.1047) |  Loss2: (0.0000) | Acc: (96.00%) (44528/46208)
Epoch: 181 | Batch_idx: 370 |  Loss: (0.1050) |  Loss2: (0.0000) | Acc: (96.00%) (45756/47488)
Epoch: 181 | Batch_idx: 380 |  Loss: (0.1049) |  Loss2: (0.0000) | Acc: (96.00%) (46987/48768)
Epoch: 181 | Batch_idx: 390 |  Loss: (0.1047) |  Loss2: (0.0000) | Acc: (96.00%) (48170/50000)
# TEST : Loss: (0.4181) | Acc: (88.00%) (8801/10000)
percent tensor([0.5215, 0.5151, 0.5253, 0.5188, 0.5284, 0.5274, 0.5206, 0.5219, 0.5254,
        0.5166, 0.5244, 0.5207, 0.5157, 0.5187, 0.5204, 0.5192],
       device='cuda:0') torch.Size([16])
percent tensor([0.5033, 0.4972, 0.5051, 0.5045, 0.5026, 0.5040, 0.4999, 0.5052, 0.5078,
        0.5003, 0.5057, 0.4993, 0.4976, 0.5097, 0.4984, 0.5053],
       device='cuda:0') torch.Size([16])
percent tensor([0.5595, 0.5430, 0.5621, 0.5855, 0.5737, 0.5744, 0.5691, 0.5657, 0.5727,
        0.5502, 0.5672, 0.5577, 0.5163, 0.6203, 0.5504, 0.5800],
       device='cuda:0') torch.Size([16])
percent tensor([0.6204, 0.6455, 0.6287, 0.6220, 0.6135, 0.6245, 0.6332, 0.6108, 0.6478,
        0.6506, 0.6595, 0.6379, 0.6445, 0.6584, 0.6150, 0.6370],
       device='cuda:0') torch.Size([16])
percent tensor([0.5942, 0.6961, 0.5251, 0.6284, 0.5469, 0.6695, 0.6276, 0.3886, 0.7059,
        0.6713, 0.7364, 0.6068, 0.6785, 0.7084, 0.5345, 0.6312],
       device='cuda:0') torch.Size([16])
percent tensor([0.6333, 0.6361, 0.6485, 0.6332, 0.6906, 0.6462, 0.6572, 0.6676, 0.6469,
        0.6311, 0.6033, 0.5934, 0.6072, 0.6146, 0.6153, 0.6480],
       device='cuda:0') torch.Size([16])
percent tensor([0.5154, 0.6010, 0.7364, 0.6662, 0.7644, 0.7270, 0.6477, 0.6700, 0.6788,
        0.5962, 0.7088, 0.6254, 0.6251, 0.5708, 0.5881, 0.4959],
       device='cuda:0') torch.Size([16])
percent tensor([0.9998, 0.9997, 0.9998, 0.9997, 0.9996, 0.9991, 0.9997, 0.9997, 0.9999,
        0.9998, 1.0000, 0.9999, 0.9999, 0.9995, 0.9996, 0.9994],
       device='cuda:0') torch.Size([16])
Epoch: 182 | Batch_idx: 0 |  Loss: (0.1117) |  Loss2: (0.0000) | Acc: (95.00%) (122/128)
Epoch: 182 | Batch_idx: 10 |  Loss: (0.1085) |  Loss2: (0.0000) | Acc: (96.00%) (1352/1408)
Epoch: 182 | Batch_idx: 20 |  Loss: (0.1035) |  Loss2: (0.0000) | Acc: (96.00%) (2590/2688)
Epoch: 182 | Batch_idx: 30 |  Loss: (0.1033) |  Loss2: (0.0000) | Acc: (96.00%) (3820/3968)
Epoch: 182 | Batch_idx: 40 |  Loss: (0.1022) |  Loss2: (0.0000) | Acc: (96.00%) (5054/5248)
Epoch: 182 | Batch_idx: 50 |  Loss: (0.0996) |  Loss2: (0.0000) | Acc: (96.00%) (6300/6528)
Epoch: 182 | Batch_idx: 60 |  Loss: (0.1012) |  Loss2: (0.0000) | Acc: (96.00%) (7532/7808)
Epoch: 182 | Batch_idx: 70 |  Loss: (0.1012) |  Loss2: (0.0000) | Acc: (96.00%) (8768/9088)
Epoch: 182 | Batch_idx: 80 |  Loss: (0.1002) |  Loss2: (0.0000) | Acc: (96.00%) (10007/10368)
Epoch: 182 | Batch_idx: 90 |  Loss: (0.0992) |  Loss2: (0.0000) | Acc: (96.00%) (11245/11648)
Epoch: 182 | Batch_idx: 100 |  Loss: (0.0976) |  Loss2: (0.0000) | Acc: (96.00%) (12491/12928)
Epoch: 182 | Batch_idx: 110 |  Loss: (0.0984) |  Loss2: (0.0000) | Acc: (96.00%) (13725/14208)
Epoch: 182 | Batch_idx: 120 |  Loss: (0.0985) |  Loss2: (0.0000) | Acc: (96.00%) (14961/15488)
Epoch: 182 | Batch_idx: 130 |  Loss: (0.0986) |  Loss2: (0.0000) | Acc: (96.00%) (16204/16768)
Epoch: 182 | Batch_idx: 140 |  Loss: (0.0989) |  Loss2: (0.0000) | Acc: (96.00%) (17440/18048)
Epoch: 182 | Batch_idx: 150 |  Loss: (0.0995) |  Loss2: (0.0000) | Acc: (96.00%) (18673/19328)
Epoch: 182 | Batch_idx: 160 |  Loss: (0.0999) |  Loss2: (0.0000) | Acc: (96.00%) (19907/20608)
Epoch: 182 | Batch_idx: 170 |  Loss: (0.0994) |  Loss2: (0.0000) | Acc: (96.00%) (21145/21888)
Epoch: 182 | Batch_idx: 180 |  Loss: (0.0987) |  Loss2: (0.0000) | Acc: (96.00%) (22385/23168)
Epoch: 182 | Batch_idx: 190 |  Loss: (0.0991) |  Loss2: (0.0000) | Acc: (96.00%) (23626/24448)
Epoch: 182 | Batch_idx: 200 |  Loss: (0.0994) |  Loss2: (0.0000) | Acc: (96.00%) (24858/25728)
Epoch: 182 | Batch_idx: 210 |  Loss: (0.0981) |  Loss2: (0.0000) | Acc: (96.00%) (26115/27008)
Epoch: 182 | Batch_idx: 220 |  Loss: (0.0976) |  Loss2: (0.0000) | Acc: (96.00%) (27354/28288)
Epoch: 182 | Batch_idx: 230 |  Loss: (0.0974) |  Loss2: (0.0000) | Acc: (96.00%) (28593/29568)
Epoch: 182 | Batch_idx: 240 |  Loss: (0.0975) |  Loss2: (0.0000) | Acc: (96.00%) (29826/30848)
Epoch: 182 | Batch_idx: 250 |  Loss: (0.0978) |  Loss2: (0.0000) | Acc: (96.00%) (31065/32128)
Epoch: 182 | Batch_idx: 260 |  Loss: (0.0982) |  Loss2: (0.0000) | Acc: (96.00%) (32297/33408)
Epoch: 182 | Batch_idx: 270 |  Loss: (0.0985) |  Loss2: (0.0000) | Acc: (96.00%) (33531/34688)
Epoch: 182 | Batch_idx: 280 |  Loss: (0.0981) |  Loss2: (0.0000) | Acc: (96.00%) (34776/35968)
Epoch: 182 | Batch_idx: 290 |  Loss: (0.0980) |  Loss2: (0.0000) | Acc: (96.00%) (36017/37248)
Epoch: 182 | Batch_idx: 300 |  Loss: (0.0981) |  Loss2: (0.0000) | Acc: (96.00%) (37250/38528)
Epoch: 182 | Batch_idx: 310 |  Loss: (0.0985) |  Loss2: (0.0000) | Acc: (96.00%) (38477/39808)
Epoch: 182 | Batch_idx: 320 |  Loss: (0.0987) |  Loss2: (0.0000) | Acc: (96.00%) (39717/41088)
Epoch: 182 | Batch_idx: 330 |  Loss: (0.0990) |  Loss2: (0.0000) | Acc: (96.00%) (40947/42368)
Epoch: 182 | Batch_idx: 340 |  Loss: (0.0987) |  Loss2: (0.0000) | Acc: (96.00%) (42191/43648)
Epoch: 182 | Batch_idx: 350 |  Loss: (0.0984) |  Loss2: (0.0000) | Acc: (96.00%) (43428/44928)
Epoch: 182 | Batch_idx: 360 |  Loss: (0.0990) |  Loss2: (0.0000) | Acc: (96.00%) (44654/46208)
Epoch: 182 | Batch_idx: 370 |  Loss: (0.0988) |  Loss2: (0.0000) | Acc: (96.00%) (45892/47488)
Epoch: 182 | Batch_idx: 380 |  Loss: (0.0991) |  Loss2: (0.0000) | Acc: (96.00%) (47115/48768)
Epoch: 182 | Batch_idx: 390 |  Loss: (0.0988) |  Loss2: (0.0000) | Acc: (96.00%) (48303/50000)
# TEST : Loss: (0.4191) | Acc: (88.00%) (8806/10000)
percent tensor([0.5216, 0.5153, 0.5241, 0.5183, 0.5284, 0.5288, 0.5210, 0.5211, 0.5251,
        0.5162, 0.5245, 0.5201, 0.5157, 0.5187, 0.5208, 0.5192],
       device='cuda:0') torch.Size([16])
percent tensor([0.5035, 0.4980, 0.5047, 0.5045, 0.5031, 0.5030, 0.5004, 0.5051, 0.5078,
        0.5011, 0.5066, 0.4998, 0.4979, 0.5100, 0.4984, 0.5055],
       device='cuda:0') torch.Size([16])
percent tensor([0.5538, 0.5403, 0.5578, 0.5780, 0.5701, 0.5687, 0.5666, 0.5608, 0.5644,
        0.5493, 0.5589, 0.5557, 0.5100, 0.6167, 0.5482, 0.5768],
       device='cuda:0') torch.Size([16])
percent tensor([0.6194, 0.6454, 0.6285, 0.6262, 0.6164, 0.6248, 0.6331, 0.6116, 0.6481,
        0.6504, 0.6573, 0.6374, 0.6445, 0.6607, 0.6167, 0.6340],
       device='cuda:0') torch.Size([16])
percent tensor([0.5908, 0.6988, 0.5048, 0.6445, 0.5284, 0.6599, 0.6004, 0.3917, 0.6951,
        0.6566, 0.7373, 0.5887, 0.6763, 0.7200, 0.5450, 0.6137],
       device='cuda:0') torch.Size([16])
percent tensor([0.6302, 0.6383, 0.6515, 0.6383, 0.6943, 0.6489, 0.6560, 0.6732, 0.6400,
        0.6344, 0.5949, 0.5930, 0.6034, 0.6171, 0.6181, 0.6462],
       device='cuda:0') torch.Size([16])
percent tensor([0.5745, 0.6386, 0.7643, 0.6845, 0.7840, 0.7922, 0.6561, 0.6874, 0.6811,
        0.5862, 0.7250, 0.6384, 0.6694, 0.6146, 0.6227, 0.5122],
       device='cuda:0') torch.Size([16])
percent tensor([0.9998, 0.9997, 0.9998, 0.9998, 0.9997, 0.9996, 0.9998, 0.9998, 0.9998,
        0.9999, 0.9999, 0.9998, 0.9999, 0.9995, 0.9996, 0.9994],
       device='cuda:0') torch.Size([16])
Epoch: 183 | Batch_idx: 0 |  Loss: (0.0655) |  Loss2: (0.0000) | Acc: (97.00%) (125/128)
Epoch: 183 | Batch_idx: 10 |  Loss: (0.0810) |  Loss2: (0.0000) | Acc: (97.00%) (1369/1408)
Epoch: 183 | Batch_idx: 20 |  Loss: (0.0850) |  Loss2: (0.0000) | Acc: (97.00%) (2616/2688)
Epoch: 183 | Batch_idx: 30 |  Loss: (0.0930) |  Loss2: (0.0000) | Acc: (96.00%) (3842/3968)
Epoch: 183 | Batch_idx: 40 |  Loss: (0.0914) |  Loss2: (0.0000) | Acc: (97.00%) (5092/5248)
Epoch: 183 | Batch_idx: 50 |  Loss: (0.0940) |  Loss2: (0.0000) | Acc: (96.00%) (6324/6528)
Epoch: 183 | Batch_idx: 60 |  Loss: (0.0979) |  Loss2: (0.0000) | Acc: (96.00%) (7552/7808)
Epoch: 183 | Batch_idx: 70 |  Loss: (0.0973) |  Loss2: (0.0000) | Acc: (96.00%) (8792/9088)
Epoch: 183 | Batch_idx: 80 |  Loss: (0.0994) |  Loss2: (0.0000) | Acc: (96.00%) (10020/10368)
Epoch: 183 | Batch_idx: 90 |  Loss: (0.0996) |  Loss2: (0.0000) | Acc: (96.00%) (11251/11648)
Epoch: 183 | Batch_idx: 100 |  Loss: (0.0989) |  Loss2: (0.0000) | Acc: (96.00%) (12489/12928)
Epoch: 183 | Batch_idx: 110 |  Loss: (0.0980) |  Loss2: (0.0000) | Acc: (96.00%) (13732/14208)
Epoch: 183 | Batch_idx: 120 |  Loss: (0.0988) |  Loss2: (0.0000) | Acc: (96.00%) (14956/15488)
Epoch: 183 | Batch_idx: 130 |  Loss: (0.0985) |  Loss2: (0.0000) | Acc: (96.00%) (16192/16768)
Epoch: 183 | Batch_idx: 140 |  Loss: (0.0983) |  Loss2: (0.0000) | Acc: (96.00%) (17419/18048)
Epoch: 183 | Batch_idx: 150 |  Loss: (0.0984) |  Loss2: (0.0000) | Acc: (96.00%) (18652/19328)
Epoch: 183 | Batch_idx: 160 |  Loss: (0.0988) |  Loss2: (0.0000) | Acc: (96.00%) (19890/20608)
Epoch: 183 | Batch_idx: 170 |  Loss: (0.0982) |  Loss2: (0.0000) | Acc: (96.00%) (21125/21888)
Epoch: 183 | Batch_idx: 180 |  Loss: (0.0987) |  Loss2: (0.0000) | Acc: (96.00%) (22361/23168)
Epoch: 183 | Batch_idx: 190 |  Loss: (0.0985) |  Loss2: (0.0000) | Acc: (96.00%) (23596/24448)
Epoch: 183 | Batch_idx: 200 |  Loss: (0.0998) |  Loss2: (0.0000) | Acc: (96.00%) (24825/25728)
Epoch: 183 | Batch_idx: 210 |  Loss: (0.0994) |  Loss2: (0.0000) | Acc: (96.00%) (26062/27008)
Epoch: 183 | Batch_idx: 220 |  Loss: (0.1004) |  Loss2: (0.0000) | Acc: (96.00%) (27290/28288)
Epoch: 183 | Batch_idx: 230 |  Loss: (0.1005) |  Loss2: (0.0000) | Acc: (96.00%) (28527/29568)
Epoch: 183 | Batch_idx: 240 |  Loss: (0.1008) |  Loss2: (0.0000) | Acc: (96.00%) (29761/30848)
Epoch: 183 | Batch_idx: 250 |  Loss: (0.1004) |  Loss2: (0.0000) | Acc: (96.00%) (31006/32128)
Epoch: 183 | Batch_idx: 260 |  Loss: (0.1003) |  Loss2: (0.0000) | Acc: (96.00%) (32249/33408)
Epoch: 183 | Batch_idx: 270 |  Loss: (0.1003) |  Loss2: (0.0000) | Acc: (96.00%) (33482/34688)
Epoch: 183 | Batch_idx: 280 |  Loss: (0.0997) |  Loss2: (0.0000) | Acc: (96.00%) (34727/35968)
Epoch: 183 | Batch_idx: 290 |  Loss: (0.0994) |  Loss2: (0.0000) | Acc: (96.00%) (35971/37248)
Epoch: 183 | Batch_idx: 300 |  Loss: (0.0995) |  Loss2: (0.0000) | Acc: (96.00%) (37207/38528)
Epoch: 183 | Batch_idx: 310 |  Loss: (0.0996) |  Loss2: (0.0000) | Acc: (96.00%) (38441/39808)
Epoch: 183 | Batch_idx: 320 |  Loss: (0.0993) |  Loss2: (0.0000) | Acc: (96.00%) (39687/41088)
Epoch: 183 | Batch_idx: 330 |  Loss: (0.0991) |  Loss2: (0.0000) | Acc: (96.00%) (40930/42368)
Epoch: 183 | Batch_idx: 340 |  Loss: (0.0988) |  Loss2: (0.0000) | Acc: (96.00%) (42172/43648)
Epoch: 183 | Batch_idx: 350 |  Loss: (0.0985) |  Loss2: (0.0000) | Acc: (96.00%) (43412/44928)
Epoch: 183 | Batch_idx: 360 |  Loss: (0.0985) |  Loss2: (0.0000) | Acc: (96.00%) (44648/46208)
Epoch: 183 | Batch_idx: 370 |  Loss: (0.0983) |  Loss2: (0.0000) | Acc: (96.00%) (45886/47488)
Epoch: 183 | Batch_idx: 380 |  Loss: (0.0985) |  Loss2: (0.0000) | Acc: (96.00%) (47126/48768)
Epoch: 183 | Batch_idx: 390 |  Loss: (0.0985) |  Loss2: (0.0000) | Acc: (96.00%) (48316/50000)
# TEST : Loss: (0.4410) | Acc: (87.00%) (8782/10000)
percent tensor([0.5214, 0.5147, 0.5244, 0.5189, 0.5292, 0.5287, 0.5203, 0.5205, 0.5245,
        0.5155, 0.5231, 0.5199, 0.5151, 0.5179, 0.5205, 0.5186],
       device='cuda:0') torch.Size([16])
percent tensor([0.5035, 0.4983, 0.5056, 0.5042, 0.5029, 0.5031, 0.5008, 0.5053, 0.5085,
        0.5018, 0.5069, 0.5009, 0.4982, 0.5115, 0.4984, 0.5054],
       device='cuda:0') torch.Size([16])
percent tensor([0.5553, 0.5423, 0.5666, 0.5796, 0.5762, 0.5674, 0.5723, 0.5683, 0.5695,
        0.5541, 0.5555, 0.5626, 0.5139, 0.6226, 0.5469, 0.5751],
       device='cuda:0') torch.Size([16])
percent tensor([0.6207, 0.6447, 0.6302, 0.6248, 0.6207, 0.6292, 0.6316, 0.6110, 0.6486,
        0.6508, 0.6570, 0.6381, 0.6451, 0.6556, 0.6160, 0.6355],
       device='cuda:0') torch.Size([16])
percent tensor([0.6071, 0.7094, 0.5169, 0.6418, 0.5307, 0.6693, 0.6329, 0.3894, 0.7047,
        0.6731, 0.7482, 0.6174, 0.6995, 0.7219, 0.5576, 0.6448],
       device='cuda:0') torch.Size([16])
percent tensor([0.6346, 0.6423, 0.6532, 0.6382, 0.6961, 0.6453, 0.6527, 0.6655, 0.6451,
        0.6420, 0.6045, 0.5917, 0.6076, 0.6176, 0.6103, 0.6502],
       device='cuda:0') torch.Size([16])
percent tensor([0.5620, 0.6233, 0.7687, 0.6901, 0.7847, 0.7888, 0.6223, 0.6892, 0.6583,
        0.5918, 0.7070, 0.6067, 0.6593, 0.5621, 0.6252, 0.5125],
       device='cuda:0') torch.Size([16])
percent tensor([0.9997, 0.9997, 0.9998, 0.9998, 0.9997, 0.9996, 0.9996, 0.9997, 0.9997,
        0.9998, 0.9999, 0.9998, 0.9999, 0.9992, 0.9996, 0.9993],
       device='cuda:0') torch.Size([16])
Epoch: 184 | Batch_idx: 0 |  Loss: (0.0447) |  Loss2: (0.0000) | Acc: (99.00%) (127/128)
Epoch: 184 | Batch_idx: 10 |  Loss: (0.0813) |  Loss2: (0.0000) | Acc: (97.00%) (1369/1408)
Epoch: 184 | Batch_idx: 20 |  Loss: (0.0889) |  Loss2: (0.0000) | Acc: (97.00%) (2611/2688)
Epoch: 184 | Batch_idx: 30 |  Loss: (0.0894) |  Loss2: (0.0000) | Acc: (97.00%) (3849/3968)
Epoch: 184 | Batch_idx: 40 |  Loss: (0.0919) |  Loss2: (0.0000) | Acc: (96.00%) (5082/5248)
Epoch: 184 | Batch_idx: 50 |  Loss: (0.0947) |  Loss2: (0.0000) | Acc: (96.00%) (6312/6528)
Epoch: 184 | Batch_idx: 60 |  Loss: (0.0975) |  Loss2: (0.0000) | Acc: (96.00%) (7544/7808)
Epoch: 184 | Batch_idx: 70 |  Loss: (0.0984) |  Loss2: (0.0000) | Acc: (96.00%) (8774/9088)
Epoch: 184 | Batch_idx: 80 |  Loss: (0.0977) |  Loss2: (0.0000) | Acc: (96.00%) (10013/10368)
Epoch: 184 | Batch_idx: 90 |  Loss: (0.0980) |  Loss2: (0.0000) | Acc: (96.00%) (11255/11648)
Epoch: 184 | Batch_idx: 100 |  Loss: (0.0983) |  Loss2: (0.0000) | Acc: (96.00%) (12491/12928)
Epoch: 184 | Batch_idx: 110 |  Loss: (0.0981) |  Loss2: (0.0000) | Acc: (96.00%) (13734/14208)
Epoch: 184 | Batch_idx: 120 |  Loss: (0.0973) |  Loss2: (0.0000) | Acc: (96.00%) (14971/15488)
Epoch: 184 | Batch_idx: 130 |  Loss: (0.0969) |  Loss2: (0.0000) | Acc: (96.00%) (16216/16768)
Epoch: 184 | Batch_idx: 140 |  Loss: (0.0963) |  Loss2: (0.0000) | Acc: (96.00%) (17464/18048)
Epoch: 184 | Batch_idx: 150 |  Loss: (0.0964) |  Loss2: (0.0000) | Acc: (96.00%) (18706/19328)
Epoch: 184 | Batch_idx: 160 |  Loss: (0.0967) |  Loss2: (0.0000) | Acc: (96.00%) (19942/20608)
Epoch: 184 | Batch_idx: 170 |  Loss: (0.0966) |  Loss2: (0.0000) | Acc: (96.00%) (21173/21888)
Epoch: 184 | Batch_idx: 180 |  Loss: (0.0959) |  Loss2: (0.0000) | Acc: (96.00%) (22415/23168)
Epoch: 184 | Batch_idx: 190 |  Loss: (0.0956) |  Loss2: (0.0000) | Acc: (96.00%) (23659/24448)
Epoch: 184 | Batch_idx: 200 |  Loss: (0.0961) |  Loss2: (0.0000) | Acc: (96.00%) (24892/25728)
Epoch: 184 | Batch_idx: 210 |  Loss: (0.0957) |  Loss2: (0.0000) | Acc: (96.00%) (26132/27008)
Epoch: 184 | Batch_idx: 220 |  Loss: (0.0957) |  Loss2: (0.0000) | Acc: (96.00%) (27378/28288)
Epoch: 184 | Batch_idx: 230 |  Loss: (0.0954) |  Loss2: (0.0000) | Acc: (96.00%) (28620/29568)
Epoch: 184 | Batch_idx: 240 |  Loss: (0.0953) |  Loss2: (0.0000) | Acc: (96.00%) (29856/30848)
Epoch: 184 | Batch_idx: 250 |  Loss: (0.0957) |  Loss2: (0.0000) | Acc: (96.00%) (31094/32128)
Epoch: 184 | Batch_idx: 260 |  Loss: (0.0962) |  Loss2: (0.0000) | Acc: (96.00%) (32324/33408)
Epoch: 184 | Batch_idx: 270 |  Loss: (0.0958) |  Loss2: (0.0000) | Acc: (96.00%) (33563/34688)
Epoch: 184 | Batch_idx: 280 |  Loss: (0.0960) |  Loss2: (0.0000) | Acc: (96.00%) (34799/35968)
Epoch: 184 | Batch_idx: 290 |  Loss: (0.0965) |  Loss2: (0.0000) | Acc: (96.00%) (36028/37248)
Epoch: 184 | Batch_idx: 300 |  Loss: (0.0965) |  Loss2: (0.0000) | Acc: (96.00%) (37266/38528)
Epoch: 184 | Batch_idx: 310 |  Loss: (0.0967) |  Loss2: (0.0000) | Acc: (96.00%) (38497/39808)
Epoch: 184 | Batch_idx: 320 |  Loss: (0.0970) |  Loss2: (0.0000) | Acc: (96.00%) (39729/41088)
Epoch: 184 | Batch_idx: 330 |  Loss: (0.0977) |  Loss2: (0.0000) | Acc: (96.00%) (40954/42368)
Epoch: 184 | Batch_idx: 340 |  Loss: (0.0976) |  Loss2: (0.0000) | Acc: (96.00%) (42188/43648)
Epoch: 184 | Batch_idx: 350 |  Loss: (0.0974) |  Loss2: (0.0000) | Acc: (96.00%) (43433/44928)
Epoch: 184 | Batch_idx: 360 |  Loss: (0.0971) |  Loss2: (0.0000) | Acc: (96.00%) (44669/46208)
Epoch: 184 | Batch_idx: 370 |  Loss: (0.0972) |  Loss2: (0.0000) | Acc: (96.00%) (45909/47488)
Epoch: 184 | Batch_idx: 380 |  Loss: (0.0970) |  Loss2: (0.0000) | Acc: (96.00%) (47153/48768)
Epoch: 184 | Batch_idx: 390 |  Loss: (0.0971) |  Loss2: (0.0000) | Acc: (96.00%) (48341/50000)
# TEST : Loss: (0.4465) | Acc: (87.00%) (8752/10000)
percent tensor([0.5215, 0.5153, 0.5246, 0.5183, 0.5277, 0.5292, 0.5206, 0.5212, 0.5259,
        0.5160, 0.5248, 0.5195, 0.5158, 0.5198, 0.5207, 0.5193],
       device='cuda:0') torch.Size([16])
percent tensor([0.5035, 0.4978, 0.5033, 0.5040, 0.5016, 0.5032, 0.4997, 0.5043, 0.5075,
        0.5005, 0.5058, 0.4988, 0.4977, 0.5109, 0.4981, 0.5053],
       device='cuda:0') torch.Size([16])
percent tensor([0.5553, 0.5396, 0.5532, 0.5833, 0.5691, 0.5722, 0.5669, 0.5614, 0.5651,
        0.5487, 0.5548, 0.5555, 0.5146, 0.6173, 0.5479, 0.5758],
       device='cuda:0') torch.Size([16])
percent tensor([0.6204, 0.6445, 0.6343, 0.6208, 0.6200, 0.6256, 0.6331, 0.6139, 0.6519,
        0.6518, 0.6545, 0.6412, 0.6462, 0.6599, 0.6126, 0.6334],
       device='cuda:0') torch.Size([16])
percent tensor([0.5830, 0.7067, 0.5371, 0.6121, 0.5457, 0.6299, 0.6287, 0.3904, 0.7109,
        0.6832, 0.7414, 0.6283, 0.6819, 0.7139, 0.5402, 0.6027],
       device='cuda:0') torch.Size([16])
percent tensor([0.6319, 0.6417, 0.6494, 0.6386, 0.7026, 0.6460, 0.6526, 0.6661, 0.6413,
        0.6378, 0.6046, 0.5884, 0.6064, 0.6162, 0.6159, 0.6575],
       device='cuda:0') torch.Size([16])
percent tensor([0.5324, 0.5920, 0.7627, 0.6456, 0.7739, 0.7615, 0.6269, 0.6770, 0.5972,
        0.5654, 0.6876, 0.6111, 0.5786, 0.5665, 0.6211, 0.5060],
       device='cuda:0') torch.Size([16])
percent tensor([0.9998, 0.9996, 0.9998, 0.9997, 0.9997, 0.9997, 0.9997, 0.9997, 0.9998,
        0.9998, 0.9999, 0.9999, 0.9999, 0.9992, 0.9996, 0.9991],
       device='cuda:0') torch.Size([16])
Epoch: 185 | Batch_idx: 0 |  Loss: (0.1072) |  Loss2: (0.0000) | Acc: (95.00%) (122/128)
Epoch: 185 | Batch_idx: 10 |  Loss: (0.1065) |  Loss2: (0.0000) | Acc: (96.00%) (1355/1408)
Epoch: 185 | Batch_idx: 20 |  Loss: (0.0974) |  Loss2: (0.0000) | Acc: (96.00%) (2592/2688)
Epoch: 185 | Batch_idx: 30 |  Loss: (0.0887) |  Loss2: (0.0000) | Acc: (96.00%) (3845/3968)
Epoch: 185 | Batch_idx: 40 |  Loss: (0.0893) |  Loss2: (0.0000) | Acc: (97.00%) (5093/5248)
Epoch: 185 | Batch_idx: 50 |  Loss: (0.0905) |  Loss2: (0.0000) | Acc: (96.00%) (6329/6528)
Epoch: 185 | Batch_idx: 60 |  Loss: (0.0885) |  Loss2: (0.0000) | Acc: (97.00%) (7574/7808)
Epoch: 185 | Batch_idx: 70 |  Loss: (0.0890) |  Loss2: (0.0000) | Acc: (96.00%) (8815/9088)
Epoch: 185 | Batch_idx: 80 |  Loss: (0.0882) |  Loss2: (0.0000) | Acc: (97.00%) (10061/10368)
Epoch: 185 | Batch_idx: 90 |  Loss: (0.0891) |  Loss2: (0.0000) | Acc: (97.00%) (11300/11648)
Epoch: 185 | Batch_idx: 100 |  Loss: (0.0891) |  Loss2: (0.0000) | Acc: (97.00%) (12545/12928)
Epoch: 185 | Batch_idx: 110 |  Loss: (0.0897) |  Loss2: (0.0000) | Acc: (97.00%) (13786/14208)
Epoch: 185 | Batch_idx: 120 |  Loss: (0.0908) |  Loss2: (0.0000) | Acc: (97.00%) (15026/15488)
Epoch: 185 | Batch_idx: 130 |  Loss: (0.0908) |  Loss2: (0.0000) | Acc: (96.00%) (16261/16768)
Epoch: 185 | Batch_idx: 140 |  Loss: (0.0905) |  Loss2: (0.0000) | Acc: (96.00%) (17497/18048)
Epoch: 185 | Batch_idx: 150 |  Loss: (0.0909) |  Loss2: (0.0000) | Acc: (96.00%) (18737/19328)
Epoch: 185 | Batch_idx: 160 |  Loss: (0.0898) |  Loss2: (0.0000) | Acc: (96.00%) (19988/20608)
Epoch: 185 | Batch_idx: 170 |  Loss: (0.0901) |  Loss2: (0.0000) | Acc: (96.00%) (21225/21888)
Epoch: 185 | Batch_idx: 180 |  Loss: (0.0903) |  Loss2: (0.0000) | Acc: (96.00%) (22466/23168)
Epoch: 185 | Batch_idx: 190 |  Loss: (0.0909) |  Loss2: (0.0000) | Acc: (96.00%) (23699/24448)
Epoch: 185 | Batch_idx: 200 |  Loss: (0.0905) |  Loss2: (0.0000) | Acc: (96.00%) (24938/25728)
Epoch: 185 | Batch_idx: 210 |  Loss: (0.0904) |  Loss2: (0.0000) | Acc: (96.00%) (26177/27008)
Epoch: 185 | Batch_idx: 220 |  Loss: (0.0909) |  Loss2: (0.0000) | Acc: (96.00%) (27403/28288)
Epoch: 185 | Batch_idx: 230 |  Loss: (0.0912) |  Loss2: (0.0000) | Acc: (96.00%) (28641/29568)
Epoch: 185 | Batch_idx: 240 |  Loss: (0.0920) |  Loss2: (0.0000) | Acc: (96.00%) (29874/30848)
Epoch: 185 | Batch_idx: 250 |  Loss: (0.0922) |  Loss2: (0.0000) | Acc: (96.00%) (31110/32128)
Epoch: 185 | Batch_idx: 260 |  Loss: (0.0926) |  Loss2: (0.0000) | Acc: (96.00%) (32347/33408)
Epoch: 185 | Batch_idx: 270 |  Loss: (0.0922) |  Loss2: (0.0000) | Acc: (96.00%) (33591/34688)
Epoch: 185 | Batch_idx: 280 |  Loss: (0.0924) |  Loss2: (0.0000) | Acc: (96.00%) (34833/35968)
Epoch: 185 | Batch_idx: 290 |  Loss: (0.0930) |  Loss2: (0.0000) | Acc: (96.00%) (36071/37248)
Epoch: 185 | Batch_idx: 300 |  Loss: (0.0927) |  Loss2: (0.0000) | Acc: (96.00%) (37317/38528)
Epoch: 185 | Batch_idx: 310 |  Loss: (0.0927) |  Loss2: (0.0000) | Acc: (96.00%) (38556/39808)
Epoch: 185 | Batch_idx: 320 |  Loss: (0.0933) |  Loss2: (0.0000) | Acc: (96.00%) (39786/41088)
Epoch: 185 | Batch_idx: 330 |  Loss: (0.0937) |  Loss2: (0.0000) | Acc: (96.00%) (41025/42368)
Epoch: 185 | Batch_idx: 340 |  Loss: (0.0944) |  Loss2: (0.0000) | Acc: (96.00%) (42252/43648)
Epoch: 185 | Batch_idx: 350 |  Loss: (0.0940) |  Loss2: (0.0000) | Acc: (96.00%) (43495/44928)
Epoch: 185 | Batch_idx: 360 |  Loss: (0.0939) |  Loss2: (0.0000) | Acc: (96.00%) (44733/46208)
Epoch: 185 | Batch_idx: 370 |  Loss: (0.0935) |  Loss2: (0.0000) | Acc: (96.00%) (45979/47488)
Epoch: 185 | Batch_idx: 380 |  Loss: (0.0937) |  Loss2: (0.0000) | Acc: (96.00%) (47221/48768)
Epoch: 185 | Batch_idx: 390 |  Loss: (0.0938) |  Loss2: (0.0000) | Acc: (96.00%) (48415/50000)
=> saving checkpoint 'drive/app/torch/save_Schedule/checkpoint_185.pth.tar'
# TEST : Loss: (0.4065) | Acc: (88.00%) (8851/10000)
percent tensor([0.5211, 0.5156, 0.5247, 0.5187, 0.5281, 0.5280, 0.5210, 0.5219, 0.5254,
        0.5164, 0.5242, 0.5204, 0.5156, 0.5204, 0.5205, 0.5194],
       device='cuda:0') torch.Size([16])
percent tensor([0.5039, 0.4983, 0.5056, 0.5045, 0.5030, 0.5046, 0.5004, 0.5060, 0.5081,
        0.5017, 0.5070, 0.5006, 0.4984, 0.5101, 0.4989, 0.5058],
       device='cuda:0') torch.Size([16])
percent tensor([0.5567, 0.5405, 0.5673, 0.5762, 0.5765, 0.5696, 0.5695, 0.5669, 0.5663,
        0.5516, 0.5576, 0.5650, 0.5150, 0.6170, 0.5442, 0.5770],
       device='cuda:0') torch.Size([16])
percent tensor([0.6215, 0.6484, 0.6295, 0.6192, 0.6192, 0.6248, 0.6356, 0.6116, 0.6504,
        0.6540, 0.6605, 0.6412, 0.6498, 0.6591, 0.6159, 0.6349],
       device='cuda:0') torch.Size([16])
percent tensor([0.5937, 0.7131, 0.5300, 0.6370, 0.5603, 0.6596, 0.6432, 0.4009, 0.7165,
        0.6809, 0.7338, 0.6371, 0.6911, 0.7194, 0.5575, 0.6366],
       device='cuda:0') torch.Size([16])
percent tensor([0.6371, 0.6503, 0.6529, 0.6355, 0.6999, 0.6452, 0.6631, 0.6738, 0.6440,
        0.6403, 0.6144, 0.6036, 0.6034, 0.6100, 0.6210, 0.6539],
       device='cuda:0') torch.Size([16])
percent tensor([0.5283, 0.6104, 0.7372, 0.6398, 0.7793, 0.7530, 0.6432, 0.6662, 0.6327,
        0.5725, 0.6939, 0.5795, 0.6161, 0.5724, 0.5981, 0.4926],
       device='cuda:0') torch.Size([16])
percent tensor([0.9998, 0.9995, 0.9997, 0.9997, 0.9997, 0.9994, 0.9997, 0.9997, 0.9997,
        0.9997, 1.0000, 0.9997, 0.9998, 0.9991, 0.9996, 0.9992],
       device='cuda:0') torch.Size([16])
Epoch: 186 | Batch_idx: 0 |  Loss: (0.0523) |  Loss2: (0.0000) | Acc: (98.00%) (126/128)
Epoch: 186 | Batch_idx: 10 |  Loss: (0.0822) |  Loss2: (0.0000) | Acc: (97.00%) (1370/1408)
Epoch: 186 | Batch_idx: 20 |  Loss: (0.0829) |  Loss2: (0.0000) | Acc: (97.00%) (2620/2688)
Epoch: 186 | Batch_idx: 30 |  Loss: (0.0788) |  Loss2: (0.0000) | Acc: (97.00%) (3871/3968)
Epoch: 186 | Batch_idx: 40 |  Loss: (0.0792) |  Loss2: (0.0000) | Acc: (97.00%) (5115/5248)
Epoch: 186 | Batch_idx: 50 |  Loss: (0.0773) |  Loss2: (0.0000) | Acc: (97.00%) (6368/6528)
Epoch: 186 | Batch_idx: 60 |  Loss: (0.0784) |  Loss2: (0.0000) | Acc: (97.00%) (7606/7808)
Epoch: 186 | Batch_idx: 70 |  Loss: (0.0796) |  Loss2: (0.0000) | Acc: (97.00%) (8844/9088)
Epoch: 186 | Batch_idx: 80 |  Loss: (0.0801) |  Loss2: (0.0000) | Acc: (97.00%) (10081/10368)
Epoch: 186 | Batch_idx: 90 |  Loss: (0.0811) |  Loss2: (0.0000) | Acc: (97.00%) (11325/11648)
Epoch: 186 | Batch_idx: 100 |  Loss: (0.0817) |  Loss2: (0.0000) | Acc: (97.00%) (12568/12928)
Epoch: 186 | Batch_idx: 110 |  Loss: (0.0828) |  Loss2: (0.0000) | Acc: (97.00%) (13815/14208)
Epoch: 186 | Batch_idx: 120 |  Loss: (0.0848) |  Loss2: (0.0000) | Acc: (97.00%) (15052/15488)
Epoch: 186 | Batch_idx: 130 |  Loss: (0.0845) |  Loss2: (0.0000) | Acc: (97.00%) (16293/16768)
Epoch: 186 | Batch_idx: 140 |  Loss: (0.0836) |  Loss2: (0.0000) | Acc: (97.00%) (17549/18048)
Epoch: 186 | Batch_idx: 150 |  Loss: (0.0849) |  Loss2: (0.0000) | Acc: (97.00%) (18786/19328)
Epoch: 186 | Batch_idx: 160 |  Loss: (0.0852) |  Loss2: (0.0000) | Acc: (97.00%) (20028/20608)
Epoch: 186 | Batch_idx: 170 |  Loss: (0.0850) |  Loss2: (0.0000) | Acc: (97.00%) (21271/21888)
Epoch: 186 | Batch_idx: 180 |  Loss: (0.0850) |  Loss2: (0.0000) | Acc: (97.00%) (22508/23168)
Epoch: 186 | Batch_idx: 190 |  Loss: (0.0858) |  Loss2: (0.0000) | Acc: (97.00%) (23737/24448)
Epoch: 186 | Batch_idx: 200 |  Loss: (0.0865) |  Loss2: (0.0000) | Acc: (97.00%) (24972/25728)
Epoch: 186 | Batch_idx: 210 |  Loss: (0.0864) |  Loss2: (0.0000) | Acc: (97.00%) (26218/27008)
Epoch: 186 | Batch_idx: 220 |  Loss: (0.0878) |  Loss2: (0.0000) | Acc: (97.00%) (27444/28288)
Epoch: 186 | Batch_idx: 230 |  Loss: (0.0875) |  Loss2: (0.0000) | Acc: (97.00%) (28688/29568)
Epoch: 186 | Batch_idx: 240 |  Loss: (0.0879) |  Loss2: (0.0000) | Acc: (96.00%) (29921/30848)
Epoch: 186 | Batch_idx: 250 |  Loss: (0.0878) |  Loss2: (0.0000) | Acc: (97.00%) (31165/32128)
Epoch: 186 | Batch_idx: 260 |  Loss: (0.0891) |  Loss2: (0.0000) | Acc: (96.00%) (32386/33408)
Epoch: 186 | Batch_idx: 270 |  Loss: (0.0890) |  Loss2: (0.0000) | Acc: (96.00%) (33631/34688)
Epoch: 186 | Batch_idx: 280 |  Loss: (0.0902) |  Loss2: (0.0000) | Acc: (96.00%) (34857/35968)
Epoch: 186 | Batch_idx: 290 |  Loss: (0.0900) |  Loss2: (0.0000) | Acc: (96.00%) (36099/37248)
Epoch: 186 | Batch_idx: 300 |  Loss: (0.0899) |  Loss2: (0.0000) | Acc: (96.00%) (37335/38528)
Epoch: 186 | Batch_idx: 310 |  Loss: (0.0899) |  Loss2: (0.0000) | Acc: (96.00%) (38575/39808)
Epoch: 186 | Batch_idx: 320 |  Loss: (0.0898) |  Loss2: (0.0000) | Acc: (96.00%) (39813/41088)
Epoch: 186 | Batch_idx: 330 |  Loss: (0.0903) |  Loss2: (0.0000) | Acc: (96.00%) (41048/42368)
Epoch: 186 | Batch_idx: 340 |  Loss: (0.0909) |  Loss2: (0.0000) | Acc: (96.00%) (42284/43648)
Epoch: 186 | Batch_idx: 350 |  Loss: (0.0908) |  Loss2: (0.0000) | Acc: (96.00%) (43523/44928)
Epoch: 186 | Batch_idx: 360 |  Loss: (0.0915) |  Loss2: (0.0000) | Acc: (96.00%) (44750/46208)
Epoch: 186 | Batch_idx: 370 |  Loss: (0.0919) |  Loss2: (0.0000) | Acc: (96.00%) (45976/47488)
Epoch: 186 | Batch_idx: 380 |  Loss: (0.0917) |  Loss2: (0.0000) | Acc: (96.00%) (47223/48768)
Epoch: 186 | Batch_idx: 390 |  Loss: (0.0920) |  Loss2: (0.0000) | Acc: (96.00%) (48410/50000)
# TEST : Loss: (0.4773) | Acc: (87.00%) (8703/10000)
percent tensor([0.5220, 0.5144, 0.5252, 0.5185, 0.5292, 0.5286, 0.5207, 0.5216, 0.5252,
        0.5164, 0.5244, 0.5215, 0.5159, 0.5175, 0.5205, 0.5191],
       device='cuda:0') torch.Size([16])
percent tensor([0.5036, 0.4993, 0.5036, 0.5039, 0.5018, 0.5041, 0.5012, 0.5045, 0.5082,
        0.5020, 0.5074, 0.4995, 0.4985, 0.5127, 0.4993, 0.5059],
       device='cuda:0') torch.Size([16])
percent tensor([0.5530, 0.5460, 0.5576, 0.5759, 0.5701, 0.5705, 0.5698, 0.5617, 0.5660,
        0.5506, 0.5600, 0.5557, 0.5120, 0.6251, 0.5514, 0.5758],
       device='cuda:0') torch.Size([16])
percent tensor([0.6204, 0.6462, 0.6311, 0.6228, 0.6199, 0.6272, 0.6331, 0.6141, 0.6527,
        0.6522, 0.6578, 0.6425, 0.6473, 0.6585, 0.6171, 0.6351],
       device='cuda:0') torch.Size([16])
percent tensor([0.5989, 0.6863, 0.5217, 0.6235, 0.5464, 0.6605, 0.6222, 0.3977, 0.6976,
        0.6503, 0.7242, 0.6118, 0.6664, 0.7082, 0.5550, 0.6333],
       device='cuda:0') torch.Size([16])
percent tensor([0.6295, 0.6457, 0.6474, 0.6314, 0.6898, 0.6462, 0.6579, 0.6669, 0.6525,
        0.6388, 0.6065, 0.5887, 0.6084, 0.6145, 0.6169, 0.6490],
       device='cuda:0') torch.Size([16])
percent tensor([0.5627, 0.6053, 0.7702, 0.6835, 0.7893, 0.7702, 0.6450, 0.6861, 0.6750,
        0.5932, 0.7064, 0.6206, 0.6413, 0.5658, 0.6218, 0.5152],
       device='cuda:0') torch.Size([16])
percent tensor([0.9998, 0.9996, 0.9998, 0.9996, 0.9996, 0.9990, 0.9996, 0.9996, 0.9996,
        0.9997, 0.9999, 0.9999, 0.9999, 0.9990, 0.9995, 0.9993],
       device='cuda:0') torch.Size([16])
Epoch: 187 | Batch_idx: 0 |  Loss: (0.0821) |  Loss2: (0.0000) | Acc: (97.00%) (125/128)
Epoch: 187 | Batch_idx: 10 |  Loss: (0.0792) |  Loss2: (0.0000) | Acc: (97.00%) (1369/1408)
Epoch: 187 | Batch_idx: 20 |  Loss: (0.0864) |  Loss2: (0.0000) | Acc: (96.00%) (2605/2688)
Epoch: 187 | Batch_idx: 30 |  Loss: (0.0873) |  Loss2: (0.0000) | Acc: (96.00%) (3846/3968)
Epoch: 187 | Batch_idx: 40 |  Loss: (0.0869) |  Loss2: (0.0000) | Acc: (96.00%) (5090/5248)
Epoch: 187 | Batch_idx: 50 |  Loss: (0.0849) |  Loss2: (0.0000) | Acc: (97.00%) (6335/6528)
Epoch: 187 | Batch_idx: 60 |  Loss: (0.0842) |  Loss2: (0.0000) | Acc: (97.00%) (7575/7808)
Epoch: 187 | Batch_idx: 70 |  Loss: (0.0856) |  Loss2: (0.0000) | Acc: (96.00%) (8815/9088)
Epoch: 187 | Batch_idx: 80 |  Loss: (0.0850) |  Loss2: (0.0000) | Acc: (97.00%) (10058/10368)
Epoch: 187 | Batch_idx: 90 |  Loss: (0.0869) |  Loss2: (0.0000) | Acc: (96.00%) (11294/11648)
Epoch: 187 | Batch_idx: 100 |  Loss: (0.0864) |  Loss2: (0.0000) | Acc: (96.00%) (12538/12928)
Epoch: 187 | Batch_idx: 110 |  Loss: (0.0864) |  Loss2: (0.0000) | Acc: (96.00%) (13775/14208)
Epoch: 187 | Batch_idx: 120 |  Loss: (0.0869) |  Loss2: (0.0000) | Acc: (96.00%) (15014/15488)
Epoch: 187 | Batch_idx: 130 |  Loss: (0.0889) |  Loss2: (0.0000) | Acc: (96.00%) (16240/16768)
Epoch: 187 | Batch_idx: 140 |  Loss: (0.0891) |  Loss2: (0.0000) | Acc: (96.00%) (17481/18048)
Epoch: 187 | Batch_idx: 150 |  Loss: (0.0902) |  Loss2: (0.0000) | Acc: (96.00%) (18713/19328)
Epoch: 187 | Batch_idx: 160 |  Loss: (0.0887) |  Loss2: (0.0000) | Acc: (96.00%) (19968/20608)
Epoch: 187 | Batch_idx: 170 |  Loss: (0.0887) |  Loss2: (0.0000) | Acc: (96.00%) (21215/21888)
Epoch: 187 | Batch_idx: 180 |  Loss: (0.0890) |  Loss2: (0.0000) | Acc: (96.00%) (22457/23168)
Epoch: 187 | Batch_idx: 190 |  Loss: (0.0898) |  Loss2: (0.0000) | Acc: (96.00%) (23692/24448)
Epoch: 187 | Batch_idx: 200 |  Loss: (0.0892) |  Loss2: (0.0000) | Acc: (96.00%) (24937/25728)
Epoch: 187 | Batch_idx: 210 |  Loss: (0.0893) |  Loss2: (0.0000) | Acc: (96.00%) (26175/27008)
Epoch: 187 | Batch_idx: 220 |  Loss: (0.0887) |  Loss2: (0.0000) | Acc: (96.00%) (27425/28288)
Epoch: 187 | Batch_idx: 230 |  Loss: (0.0886) |  Loss2: (0.0000) | Acc: (96.00%) (28666/29568)
Epoch: 187 | Batch_idx: 240 |  Loss: (0.0885) |  Loss2: (0.0000) | Acc: (96.00%) (29909/30848)
Epoch: 187 | Batch_idx: 250 |  Loss: (0.0878) |  Loss2: (0.0000) | Acc: (96.00%) (31161/32128)
Epoch: 187 | Batch_idx: 260 |  Loss: (0.0883) |  Loss2: (0.0000) | Acc: (96.00%) (32394/33408)
Epoch: 187 | Batch_idx: 270 |  Loss: (0.0883) |  Loss2: (0.0000) | Acc: (96.00%) (33633/34688)
Epoch: 187 | Batch_idx: 280 |  Loss: (0.0887) |  Loss2: (0.0000) | Acc: (96.00%) (34869/35968)
Epoch: 187 | Batch_idx: 290 |  Loss: (0.0884) |  Loss2: (0.0000) | Acc: (96.00%) (36115/37248)
Epoch: 187 | Batch_idx: 300 |  Loss: (0.0889) |  Loss2: (0.0000) | Acc: (96.00%) (37350/38528)
Epoch: 187 | Batch_idx: 310 |  Loss: (0.0886) |  Loss2: (0.0000) | Acc: (96.00%) (38606/39808)
Epoch: 187 | Batch_idx: 320 |  Loss: (0.0888) |  Loss2: (0.0000) | Acc: (96.00%) (39838/41088)
Epoch: 187 | Batch_idx: 330 |  Loss: (0.0894) |  Loss2: (0.0000) | Acc: (96.00%) (41066/42368)
Epoch: 187 | Batch_idx: 340 |  Loss: (0.0895) |  Loss2: (0.0000) | Acc: (96.00%) (42303/43648)
Epoch: 187 | Batch_idx: 350 |  Loss: (0.0898) |  Loss2: (0.0000) | Acc: (96.00%) (43543/44928)
Epoch: 187 | Batch_idx: 360 |  Loss: (0.0902) |  Loss2: (0.0000) | Acc: (96.00%) (44774/46208)
Epoch: 187 | Batch_idx: 370 |  Loss: (0.0903) |  Loss2: (0.0000) | Acc: (96.00%) (46010/47488)
Epoch: 187 | Batch_idx: 380 |  Loss: (0.0900) |  Loss2: (0.0000) | Acc: (96.00%) (47257/48768)
Epoch: 187 | Batch_idx: 390 |  Loss: (0.0902) |  Loss2: (0.0000) | Acc: (96.00%) (48448/50000)
# TEST : Loss: (0.4028) | Acc: (88.00%) (8855/10000)
percent tensor([0.5225, 0.5145, 0.5247, 0.5194, 0.5290, 0.5294, 0.5204, 0.5214, 0.5249,
        0.5164, 0.5239, 0.5213, 0.5162, 0.5168, 0.5206, 0.5195],
       device='cuda:0') torch.Size([16])
percent tensor([0.5036, 0.4984, 0.5039, 0.5046, 0.5020, 0.5045, 0.5003, 0.5047, 0.5085,
        0.5009, 0.5070, 0.4994, 0.4982, 0.5111, 0.4990, 0.5053],
       device='cuda:0') torch.Size([16])
percent tensor([0.5576, 0.5454, 0.5569, 0.5883, 0.5721, 0.5769, 0.5699, 0.5677, 0.5719,
        0.5520, 0.5617, 0.5561, 0.5174, 0.6221, 0.5537, 0.5833],
       device='cuda:0') torch.Size([16])
percent tensor([0.6168, 0.6408, 0.6240, 0.6197, 0.6111, 0.6201, 0.6262, 0.6103, 0.6463,
        0.6457, 0.6539, 0.6341, 0.6440, 0.6507, 0.6105, 0.6284],
       device='cuda:0') torch.Size([16])
percent tensor([0.5833, 0.6861, 0.5245, 0.6254, 0.5465, 0.6431, 0.6046, 0.4055, 0.6875,
        0.6430, 0.7104, 0.5877, 0.6573, 0.6975, 0.5413, 0.6088],
       device='cuda:0') torch.Size([16])
percent tensor([0.6345, 0.6530, 0.6449, 0.6342, 0.6896, 0.6498, 0.6608, 0.6714, 0.6480,
        0.6396, 0.6098, 0.5894, 0.6110, 0.6283, 0.6184, 0.6591],
       device='cuda:0') torch.Size([16])
percent tensor([0.5640, 0.6270, 0.7618, 0.6821, 0.7730, 0.7720, 0.6617, 0.6758, 0.6965,
        0.5868, 0.7261, 0.6113, 0.6474, 0.6312, 0.6115, 0.5172],
       device='cuda:0') torch.Size([16])
percent tensor([0.9998, 0.9996, 0.9998, 0.9998, 0.9996, 0.9995, 0.9996, 0.9996, 0.9997,
        0.9998, 0.9999, 0.9999, 0.9998, 0.9992, 0.9997, 0.9994],
       device='cuda:0') torch.Size([16])
Epoch: 188 | Batch_idx: 0 |  Loss: (0.0736) |  Loss2: (0.0000) | Acc: (96.00%) (124/128)
Epoch: 188 | Batch_idx: 10 |  Loss: (0.0795) |  Loss2: (0.0000) | Acc: (97.00%) (1371/1408)
Epoch: 188 | Batch_idx: 20 |  Loss: (0.0860) |  Loss2: (0.0000) | Acc: (97.00%) (2614/2688)
Epoch: 188 | Batch_idx: 30 |  Loss: (0.0832) |  Loss2: (0.0000) | Acc: (97.00%) (3857/3968)
Epoch: 188 | Batch_idx: 40 |  Loss: (0.0823) |  Loss2: (0.0000) | Acc: (97.00%) (5101/5248)
Epoch: 188 | Batch_idx: 50 |  Loss: (0.0799) |  Loss2: (0.0000) | Acc: (97.00%) (6350/6528)
Epoch: 188 | Batch_idx: 60 |  Loss: (0.0794) |  Loss2: (0.0000) | Acc: (97.00%) (7597/7808)
Epoch: 188 | Batch_idx: 70 |  Loss: (0.0828) |  Loss2: (0.0000) | Acc: (97.00%) (8831/9088)
Epoch: 188 | Batch_idx: 80 |  Loss: (0.0831) |  Loss2: (0.0000) | Acc: (97.00%) (10071/10368)
Epoch: 188 | Batch_idx: 90 |  Loss: (0.0818) |  Loss2: (0.0000) | Acc: (97.00%) (11318/11648)
Epoch: 188 | Batch_idx: 100 |  Loss: (0.0816) |  Loss2: (0.0000) | Acc: (97.00%) (12560/12928)
Epoch: 188 | Batch_idx: 110 |  Loss: (0.0823) |  Loss2: (0.0000) | Acc: (97.00%) (13796/14208)
Epoch: 188 | Batch_idx: 120 |  Loss: (0.0831) |  Loss2: (0.0000) | Acc: (97.00%) (15034/15488)
Epoch: 188 | Batch_idx: 130 |  Loss: (0.0834) |  Loss2: (0.0000) | Acc: (97.00%) (16270/16768)
Epoch: 188 | Batch_idx: 140 |  Loss: (0.0847) |  Loss2: (0.0000) | Acc: (96.00%) (17503/18048)
Epoch: 188 | Batch_idx: 150 |  Loss: (0.0849) |  Loss2: (0.0000) | Acc: (96.00%) (18743/19328)
Epoch: 188 | Batch_idx: 160 |  Loss: (0.0846) |  Loss2: (0.0000) | Acc: (97.00%) (19990/20608)
Epoch: 188 | Batch_idx: 170 |  Loss: (0.0847) |  Loss2: (0.0000) | Acc: (97.00%) (21239/21888)
Epoch: 188 | Batch_idx: 180 |  Loss: (0.0851) |  Loss2: (0.0000) | Acc: (97.00%) (22476/23168)
Epoch: 188 | Batch_idx: 190 |  Loss: (0.0845) |  Loss2: (0.0000) | Acc: (97.00%) (23728/24448)
Epoch: 188 | Batch_idx: 200 |  Loss: (0.0849) |  Loss2: (0.0000) | Acc: (97.00%) (24964/25728)
Epoch: 188 | Batch_idx: 210 |  Loss: (0.0850) |  Loss2: (0.0000) | Acc: (97.00%) (26206/27008)
Epoch: 188 | Batch_idx: 220 |  Loss: (0.0855) |  Loss2: (0.0000) | Acc: (97.00%) (27443/28288)
Epoch: 188 | Batch_idx: 230 |  Loss: (0.0855) |  Loss2: (0.0000) | Acc: (97.00%) (28689/29568)
Epoch: 188 | Batch_idx: 240 |  Loss: (0.0849) |  Loss2: (0.0000) | Acc: (97.00%) (29938/30848)
Epoch: 188 | Batch_idx: 250 |  Loss: (0.0849) |  Loss2: (0.0000) | Acc: (97.00%) (31182/32128)
Epoch: 188 | Batch_idx: 260 |  Loss: (0.0848) |  Loss2: (0.0000) | Acc: (97.00%) (32428/33408)
Epoch: 188 | Batch_idx: 270 |  Loss: (0.0847) |  Loss2: (0.0000) | Acc: (97.00%) (33672/34688)
Epoch: 188 | Batch_idx: 280 |  Loss: (0.0847) |  Loss2: (0.0000) | Acc: (97.00%) (34921/35968)
Epoch: 188 | Batch_idx: 290 |  Loss: (0.0851) |  Loss2: (0.0000) | Acc: (97.00%) (36161/37248)
Epoch: 188 | Batch_idx: 300 |  Loss: (0.0851) |  Loss2: (0.0000) | Acc: (97.00%) (37398/38528)
Epoch: 188 | Batch_idx: 310 |  Loss: (0.0852) |  Loss2: (0.0000) | Acc: (97.00%) (38639/39808)
Epoch: 188 | Batch_idx: 320 |  Loss: (0.0853) |  Loss2: (0.0000) | Acc: (97.00%) (39879/41088)
Epoch: 188 | Batch_idx: 330 |  Loss: (0.0855) |  Loss2: (0.0000) | Acc: (97.00%) (41118/42368)
Epoch: 188 | Batch_idx: 340 |  Loss: (0.0860) |  Loss2: (0.0000) | Acc: (97.00%) (42352/43648)
Epoch: 188 | Batch_idx: 350 |  Loss: (0.0860) |  Loss2: (0.0000) | Acc: (97.00%) (43598/44928)
Epoch: 188 | Batch_idx: 360 |  Loss: (0.0860) |  Loss2: (0.0000) | Acc: (97.00%) (44843/46208)
Epoch: 188 | Batch_idx: 370 |  Loss: (0.0855) |  Loss2: (0.0000) | Acc: (97.00%) (46098/47488)
Epoch: 188 | Batch_idx: 380 |  Loss: (0.0858) |  Loss2: (0.0000) | Acc: (97.00%) (47330/48768)
Epoch: 188 | Batch_idx: 390 |  Loss: (0.0858) |  Loss2: (0.0000) | Acc: (97.00%) (48529/50000)
# TEST : Loss: (0.4433) | Acc: (88.00%) (8804/10000)
percent tensor([0.5215, 0.5153, 0.5253, 0.5202, 0.5291, 0.5284, 0.5208, 0.5220, 0.5247,
        0.5169, 0.5236, 0.5212, 0.5157, 0.5182, 0.5212, 0.5192],
       device='cuda:0') torch.Size([16])
percent tensor([0.5039, 0.4985, 0.5046, 0.5053, 0.5027, 0.5039, 0.5005, 0.5049, 0.5081,
        0.5018, 0.5065, 0.4999, 0.4976, 0.5113, 0.4986, 0.5058],
       device='cuda:0') torch.Size([16])
percent tensor([0.5584, 0.5473, 0.5594, 0.5936, 0.5737, 0.5720, 0.5719, 0.5692, 0.5696,
        0.5532, 0.5584, 0.5588, 0.5165, 0.6295, 0.5519, 0.5824],
       device='cuda:0') torch.Size([16])
percent tensor([0.6228, 0.6506, 0.6276, 0.6176, 0.6142, 0.6213, 0.6342, 0.6124, 0.6550,
        0.6555, 0.6607, 0.6390, 0.6508, 0.6634, 0.6158, 0.6367],
       device='cuda:0') torch.Size([16])
percent tensor([0.6084, 0.7114, 0.5106, 0.6286, 0.5489, 0.6771, 0.6287, 0.3969, 0.7070,
        0.6647, 0.7367, 0.6020, 0.6860, 0.7229, 0.5748, 0.6464],
       device='cuda:0') torch.Size([16])
percent tensor([0.6366, 0.6398, 0.6538, 0.6376, 0.6900, 0.6478, 0.6568, 0.6701, 0.6401,
        0.6389, 0.6032, 0.5901, 0.5988, 0.6195, 0.6240, 0.6552],
       device='cuda:0') torch.Size([16])
percent tensor([0.5420, 0.6030, 0.7796, 0.6678, 0.7733, 0.7682, 0.6468, 0.6850, 0.6635,
        0.5845, 0.7086, 0.6002, 0.6414, 0.6004, 0.6496, 0.5010],
       device='cuda:0') torch.Size([16])
percent tensor([0.9998, 0.9994, 0.9998, 0.9996, 0.9997, 0.9995, 0.9997, 0.9996, 0.9997,
        0.9997, 0.9999, 0.9998, 0.9998, 0.9989, 0.9997, 0.9994],
       device='cuda:0') torch.Size([16])
False Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=128, out_features=16, bias=False)
True Linear(in_features=16, out_features=2, bias=False)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=128, out_features=16, bias=False)
True Linear(in_features=16, out_features=2, bias=False)
False Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=256, out_features=32, bias=False)
True Linear(in_features=32, out_features=2, bias=False)
False Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=256, out_features=32, bias=False)
True Linear(in_features=32, out_features=2, bias=False)
False Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=512, out_features=64, bias=False)
True Linear(in_features=64, out_features=2, bias=False)
False Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=512, out_features=64, bias=False)
True Linear(in_features=64, out_features=2, bias=False)
False Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1024, out_features=128, bias=False)
True Linear(in_features=128, out_features=2, bias=False)
False Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1024, out_features=128, bias=False)
True Linear(in_features=128, out_features=2, bias=False)
False Linear(in_features=512, out_features=10, bias=True)
Epoch: 189 | Batch_idx: 0 |  Loss: (0.0549) |  Loss2: (0.0000) | Acc: (98.00%) (126/128)
Epoch: 189 | Batch_idx: 10 |  Loss: (0.0973) |  Loss2: (0.0000) | Acc: (96.00%) (1353/1408)
Epoch: 189 | Batch_idx: 20 |  Loss: (0.1204) |  Loss2: (0.0000) | Acc: (95.00%) (2567/2688)
Epoch: 189 | Batch_idx: 30 |  Loss: (0.1317) |  Loss2: (0.0000) | Acc: (95.00%) (3774/3968)
Epoch: 189 | Batch_idx: 40 |  Loss: (0.1284) |  Loss2: (0.0000) | Acc: (95.00%) (4997/5248)
Epoch: 189 | Batch_idx: 50 |  Loss: (0.1310) |  Loss2: (0.0000) | Acc: (95.00%) (6218/6528)
Epoch: 189 | Batch_idx: 60 |  Loss: (0.1342) |  Loss2: (0.0000) | Acc: (95.00%) (7436/7808)
Epoch: 189 | Batch_idx: 70 |  Loss: (0.1368) |  Loss2: (0.0000) | Acc: (95.00%) (8647/9088)
Epoch: 189 | Batch_idx: 80 |  Loss: (0.1402) |  Loss2: (0.0000) | Acc: (95.00%) (9850/10368)
Epoch: 189 | Batch_idx: 90 |  Loss: (0.1383) |  Loss2: (0.0000) | Acc: (95.00%) (11083/11648)
Epoch: 189 | Batch_idx: 100 |  Loss: (0.1368) |  Loss2: (0.0000) | Acc: (95.00%) (12307/12928)
Epoch: 189 | Batch_idx: 110 |  Loss: (0.1363) |  Loss2: (0.0000) | Acc: (95.00%) (13527/14208)
Epoch: 189 | Batch_idx: 120 |  Loss: (0.1349) |  Loss2: (0.0000) | Acc: (95.00%) (14751/15488)
Epoch: 189 | Batch_idx: 130 |  Loss: (0.1336) |  Loss2: (0.0000) | Acc: (95.00%) (15987/16768)
Epoch: 189 | Batch_idx: 140 |  Loss: (0.1331) |  Loss2: (0.0000) | Acc: (95.00%) (17208/18048)
Epoch: 189 | Batch_idx: 150 |  Loss: (0.1329) |  Loss2: (0.0000) | Acc: (95.00%) (18422/19328)
Epoch: 189 | Batch_idx: 160 |  Loss: (0.1323) |  Loss2: (0.0000) | Acc: (95.00%) (19655/20608)
Epoch: 189 | Batch_idx: 170 |  Loss: (0.1312) |  Loss2: (0.0000) | Acc: (95.00%) (20881/21888)
Epoch: 189 | Batch_idx: 180 |  Loss: (0.1311) |  Loss2: (0.0000) | Acc: (95.00%) (22094/23168)
Epoch: 189 | Batch_idx: 190 |  Loss: (0.1306) |  Loss2: (0.0000) | Acc: (95.00%) (23318/24448)
Epoch: 189 | Batch_idx: 200 |  Loss: (0.1298) |  Loss2: (0.0000) | Acc: (95.00%) (24543/25728)
Epoch: 189 | Batch_idx: 210 |  Loss: (0.1293) |  Loss2: (0.0000) | Acc: (95.00%) (25770/27008)
Epoch: 189 | Batch_idx: 220 |  Loss: (0.1292) |  Loss2: (0.0000) | Acc: (95.00%) (26997/28288)
Epoch: 189 | Batch_idx: 230 |  Loss: (0.1282) |  Loss2: (0.0000) | Acc: (95.00%) (28230/29568)
Epoch: 189 | Batch_idx: 240 |  Loss: (0.1281) |  Loss2: (0.0000) | Acc: (95.00%) (29456/30848)
Epoch: 189 | Batch_idx: 250 |  Loss: (0.1271) |  Loss2: (0.0000) | Acc: (95.00%) (30687/32128)
Epoch: 189 | Batch_idx: 260 |  Loss: (0.1262) |  Loss2: (0.0000) | Acc: (95.00%) (31925/33408)
Epoch: 189 | Batch_idx: 270 |  Loss: (0.1254) |  Loss2: (0.0000) | Acc: (95.00%) (33153/34688)
Epoch: 189 | Batch_idx: 280 |  Loss: (0.1247) |  Loss2: (0.0000) | Acc: (95.00%) (34384/35968)
Epoch: 189 | Batch_idx: 290 |  Loss: (0.1242) |  Loss2: (0.0000) | Acc: (95.00%) (35617/37248)
Epoch: 189 | Batch_idx: 300 |  Loss: (0.1241) |  Loss2: (0.0000) | Acc: (95.00%) (36847/38528)
Epoch: 189 | Batch_idx: 310 |  Loss: (0.1238) |  Loss2: (0.0000) | Acc: (95.00%) (38073/39808)
Epoch: 189 | Batch_idx: 320 |  Loss: (0.1238) |  Loss2: (0.0000) | Acc: (95.00%) (39290/41088)
Epoch: 189 | Batch_idx: 330 |  Loss: (0.1232) |  Loss2: (0.0000) | Acc: (95.00%) (40521/42368)
Epoch: 189 | Batch_idx: 340 |  Loss: (0.1229) |  Loss2: (0.0000) | Acc: (95.00%) (41751/43648)
Epoch: 189 | Batch_idx: 350 |  Loss: (0.1225) |  Loss2: (0.0000) | Acc: (95.00%) (42979/44928)
Epoch: 189 | Batch_idx: 360 |  Loss: (0.1217) |  Loss2: (0.0000) | Acc: (95.00%) (44217/46208)
Epoch: 189 | Batch_idx: 370 |  Loss: (0.1210) |  Loss2: (0.0000) | Acc: (95.00%) (45453/47488)
Epoch: 189 | Batch_idx: 380 |  Loss: (0.1206) |  Loss2: (0.0000) | Acc: (95.00%) (46688/48768)
Epoch: 189 | Batch_idx: 390 |  Loss: (0.1199) |  Loss2: (0.0000) | Acc: (95.00%) (47884/50000)
# TEST : Loss: (0.4237) | Acc: (88.00%) (8836/10000)
percent tensor([0.5211, 0.5145, 0.5232, 0.5198, 0.5273, 0.5285, 0.5195, 0.5208, 0.5241,
        0.5161, 0.5234, 0.5195, 0.5152, 0.5183, 0.5208, 0.5188],
       device='cuda:0') torch.Size([16])
percent tensor([0.5050, 0.4994, 0.5048, 0.5056, 0.5029, 0.5048, 0.5008, 0.5059, 0.5090,
        0.5021, 0.5071, 0.4996, 0.4984, 0.5124, 0.4993, 0.5068],
       device='cuda:0') torch.Size([16])
percent tensor([0.5720, 0.5526, 0.5757, 0.6173, 0.5950, 0.5932, 0.5825, 0.5971, 0.5837,
        0.5593, 0.5658, 0.5666, 0.5200, 0.6450, 0.5685, 0.5960],
       device='cuda:0') torch.Size([16])
percent tensor([0.6171, 0.6486, 0.6167, 0.6113, 0.6036, 0.6198, 0.6300, 0.6075, 0.6511,
        0.6523, 0.6583, 0.6308, 0.6463, 0.6608, 0.6133, 0.6340],
       device='cuda:0') torch.Size([16])
percent tensor([0.6017, 0.6983, 0.5226, 0.6140, 0.5662, 0.6577, 0.6327, 0.4151, 0.6956,
        0.6629, 0.7260, 0.6032, 0.6664, 0.7171, 0.5748, 0.6357],
       device='cuda:0') torch.Size([16])
percent tensor([0.6575, 0.6655, 0.6633, 0.6533, 0.7008, 0.6654, 0.6735, 0.6888, 0.6657,
        0.6617, 0.6292, 0.6086, 0.6250, 0.6515, 0.6456, 0.6756],
       device='cuda:0') torch.Size([16])
percent tensor([0.6025, 0.6423, 0.7777, 0.6841, 0.7646, 0.7890, 0.6669, 0.6794, 0.6969,
        0.6085, 0.7325, 0.6251, 0.6786, 0.6545, 0.6478, 0.5349],
       device='cuda:0') torch.Size([16])
percent tensor([0.9998, 0.9995, 0.9998, 0.9995, 0.9995, 0.9994, 0.9997, 0.9997, 0.9998,
        0.9997, 0.9999, 0.9999, 0.9999, 0.9992, 0.9997, 0.9994],
       device='cuda:0') torch.Size([16])
Epoch: 190 | Batch_idx: 0 |  Loss: (0.1077) |  Loss2: (0.0000) | Acc: (95.00%) (122/128)
Epoch: 190 | Batch_idx: 10 |  Loss: (0.1068) |  Loss2: (0.0000) | Acc: (96.00%) (1353/1408)
Epoch: 190 | Batch_idx: 20 |  Loss: (0.1052) |  Loss2: (0.0000) | Acc: (96.00%) (2584/2688)
Epoch: 190 | Batch_idx: 30 |  Loss: (0.1034) |  Loss2: (0.0000) | Acc: (96.00%) (3813/3968)
Epoch: 190 | Batch_idx: 40 |  Loss: (0.0994) |  Loss2: (0.0000) | Acc: (96.00%) (5051/5248)
Epoch: 190 | Batch_idx: 50 |  Loss: (0.0994) |  Loss2: (0.0000) | Acc: (96.00%) (6292/6528)
Epoch: 190 | Batch_idx: 60 |  Loss: (0.0996) |  Loss2: (0.0000) | Acc: (96.00%) (7524/7808)
Epoch: 190 | Batch_idx: 70 |  Loss: (0.0984) |  Loss2: (0.0000) | Acc: (96.00%) (8766/9088)
Epoch: 190 | Batch_idx: 80 |  Loss: (0.0983) |  Loss2: (0.0000) | Acc: (96.00%) (10002/10368)
Epoch: 190 | Batch_idx: 90 |  Loss: (0.0991) |  Loss2: (0.0000) | Acc: (96.00%) (11231/11648)
Epoch: 190 | Batch_idx: 100 |  Loss: (0.0992) |  Loss2: (0.0000) | Acc: (96.00%) (12463/12928)
Epoch: 190 | Batch_idx: 110 |  Loss: (0.0979) |  Loss2: (0.0000) | Acc: (96.00%) (13707/14208)
Epoch: 190 | Batch_idx: 120 |  Loss: (0.0974) |  Loss2: (0.0000) | Acc: (96.00%) (14945/15488)
Epoch: 190 | Batch_idx: 130 |  Loss: (0.0967) |  Loss2: (0.0000) | Acc: (96.00%) (16189/16768)
Epoch: 190 | Batch_idx: 140 |  Loss: (0.0964) |  Loss2: (0.0000) | Acc: (96.00%) (17429/18048)
Epoch: 190 | Batch_idx: 150 |  Loss: (0.0962) |  Loss2: (0.0000) | Acc: (96.00%) (18672/19328)
Epoch: 190 | Batch_idx: 160 |  Loss: (0.0958) |  Loss2: (0.0000) | Acc: (96.00%) (19910/20608)
Epoch: 190 | Batch_idx: 170 |  Loss: (0.0958) |  Loss2: (0.0000) | Acc: (96.00%) (21140/21888)
Epoch: 190 | Batch_idx: 180 |  Loss: (0.0955) |  Loss2: (0.0000) | Acc: (96.00%) (22376/23168)
Epoch: 190 | Batch_idx: 190 |  Loss: (0.0960) |  Loss2: (0.0000) | Acc: (96.00%) (23614/24448)
Epoch: 190 | Batch_idx: 200 |  Loss: (0.0953) |  Loss2: (0.0000) | Acc: (96.00%) (24861/25728)
Epoch: 190 | Batch_idx: 210 |  Loss: (0.0949) |  Loss2: (0.0000) | Acc: (96.00%) (26108/27008)
Epoch: 190 | Batch_idx: 220 |  Loss: (0.0945) |  Loss2: (0.0000) | Acc: (96.00%) (27351/28288)
Epoch: 190 | Batch_idx: 230 |  Loss: (0.0955) |  Loss2: (0.0000) | Acc: (96.00%) (28580/29568)
Epoch: 190 | Batch_idx: 240 |  Loss: (0.0959) |  Loss2: (0.0000) | Acc: (96.00%) (29819/30848)
Epoch: 190 | Batch_idx: 250 |  Loss: (0.0958) |  Loss2: (0.0000) | Acc: (96.00%) (31057/32128)
Epoch: 190 | Batch_idx: 260 |  Loss: (0.0960) |  Loss2: (0.0000) | Acc: (96.00%) (32292/33408)
Epoch: 190 | Batch_idx: 270 |  Loss: (0.0968) |  Loss2: (0.0000) | Acc: (96.00%) (33516/34688)
Epoch: 190 | Batch_idx: 280 |  Loss: (0.0967) |  Loss2: (0.0000) | Acc: (96.00%) (34757/35968)
Epoch: 190 | Batch_idx: 290 |  Loss: (0.0969) |  Loss2: (0.0000) | Acc: (96.00%) (35990/37248)
Epoch: 190 | Batch_idx: 300 |  Loss: (0.0968) |  Loss2: (0.0000) | Acc: (96.00%) (37230/38528)
Epoch: 190 | Batch_idx: 310 |  Loss: (0.0969) |  Loss2: (0.0000) | Acc: (96.00%) (38467/39808)
Epoch: 190 | Batch_idx: 320 |  Loss: (0.0964) |  Loss2: (0.0000) | Acc: (96.00%) (39715/41088)
Epoch: 190 | Batch_idx: 330 |  Loss: (0.0963) |  Loss2: (0.0000) | Acc: (96.00%) (40954/42368)
Epoch: 190 | Batch_idx: 340 |  Loss: (0.0959) |  Loss2: (0.0000) | Acc: (96.00%) (42200/43648)
Epoch: 190 | Batch_idx: 350 |  Loss: (0.0957) |  Loss2: (0.0000) | Acc: (96.00%) (43440/44928)
Epoch: 190 | Batch_idx: 360 |  Loss: (0.0958) |  Loss2: (0.0000) | Acc: (96.00%) (44670/46208)
Epoch: 190 | Batch_idx: 370 |  Loss: (0.0956) |  Loss2: (0.0000) | Acc: (96.00%) (45905/47488)
Epoch: 190 | Batch_idx: 380 |  Loss: (0.0959) |  Loss2: (0.0000) | Acc: (96.00%) (47137/48768)
Epoch: 190 | Batch_idx: 390 |  Loss: (0.0962) |  Loss2: (0.0000) | Acc: (96.00%) (48320/50000)
=> saving checkpoint 'drive/app/torch/save_Schedule/checkpoint_190.pth.tar'
# TEST : Loss: (0.4081) | Acc: (88.00%) (8853/10000)
percent tensor([0.5213, 0.5143, 0.5230, 0.5200, 0.5273, 0.5288, 0.5193, 0.5208, 0.5246,
        0.5160, 0.5237, 0.5194, 0.5153, 0.5189, 0.5207, 0.5189],
       device='cuda:0') torch.Size([16])
percent tensor([0.5046, 0.4986, 0.5044, 0.5051, 0.5025, 0.5043, 0.5000, 0.5053, 0.5085,
        0.5013, 0.5065, 0.4989, 0.4976, 0.5119, 0.4987, 0.5062],
       device='cuda:0') torch.Size([16])
percent tensor([0.5704, 0.5484, 0.5757, 0.6149, 0.5962, 0.5913, 0.5809, 0.5980, 0.5817,
        0.5545, 0.5593, 0.5634, 0.5154, 0.6442, 0.5657, 0.5922],
       device='cuda:0') torch.Size([16])
percent tensor([0.6242, 0.6559, 0.6238, 0.6185, 0.6104, 0.6281, 0.6373, 0.6136, 0.6591,
        0.6599, 0.6668, 0.6380, 0.6543, 0.6683, 0.6206, 0.6425],
       device='cuda:0') torch.Size([16])
percent tensor([0.6095, 0.7087, 0.5248, 0.6123, 0.5623, 0.6625, 0.6394, 0.4168, 0.7012,
        0.6767, 0.7401, 0.6071, 0.6745, 0.7253, 0.5797, 0.6441],
       device='cuda:0') torch.Size([16])
percent tensor([0.6674, 0.6744, 0.6726, 0.6618, 0.7102, 0.6737, 0.6823, 0.6954, 0.6753,
        0.6706, 0.6383, 0.6187, 0.6374, 0.6603, 0.6543, 0.6841],
       device='cuda:0') torch.Size([16])
percent tensor([0.5957, 0.6233, 0.7672, 0.6792, 0.7545, 0.7839, 0.6478, 0.6643, 0.6837,
        0.5908, 0.7190, 0.6125, 0.6719, 0.6419, 0.6267, 0.5274],
       device='cuda:0') torch.Size([16])
percent tensor([0.9998, 0.9995, 0.9998, 0.9995, 0.9996, 0.9994, 0.9997, 0.9997, 0.9998,
        0.9997, 0.9999, 0.9998, 0.9999, 0.9992, 0.9996, 0.9994],
       device='cuda:0') torch.Size([16])
Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 3, 3, 3]) tensor(190.9416, device='cuda:0')
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(837.8971, device='cuda:0')
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(827.7043, device='cuda:0')
Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([128, 64, 3, 3]) tensor(1520.3427, device='cuda:0')
Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([128, 64, 1, 1]) tensor(474.2098, device='cuda:0')
Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([128, 128, 3, 3]) tensor(2315.1199, device='cuda:0')
Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([256, 128, 3, 3]) tensor(4251.1445, device='cuda:0')
Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([256, 128, 1, 1]) tensor(1345.1569, device='cuda:0')
Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([256, 256, 3, 3]) tensor(6239.2148, device='cuda:0')
Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([512, 256, 3, 3]) tensor(11546.4258, device='cuda:0')
Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([512, 256, 1, 1]) tensor(3803.3940, device='cuda:0')
Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([512, 512, 3, 3]) tensor(16066.5732, device='cuda:0')
Epoch: 191 | Batch_idx: 0 |  Loss: (0.0464) |  Loss2: (0.0000) | Acc: (99.00%) (127/128)
Epoch: 191 | Batch_idx: 10 |  Loss: (0.0722) |  Loss2: (0.0000) | Acc: (98.00%) (1381/1408)
Epoch: 191 | Batch_idx: 20 |  Loss: (0.0821) |  Loss2: (0.0000) | Acc: (97.00%) (2617/2688)
Epoch: 191 | Batch_idx: 30 |  Loss: (0.0886) |  Loss2: (0.0000) | Acc: (97.00%) (3854/3968)
Epoch: 191 | Batch_idx: 40 |  Loss: (0.0847) |  Loss2: (0.0000) | Acc: (97.00%) (5101/5248)
Epoch: 191 | Batch_idx: 50 |  Loss: (0.0832) |  Loss2: (0.0000) | Acc: (97.00%) (6348/6528)
Epoch: 191 | Batch_idx: 60 |  Loss: (0.0846) |  Loss2: (0.0000) | Acc: (97.00%) (7582/7808)
Epoch: 191 | Batch_idx: 70 |  Loss: (0.0861) |  Loss2: (0.0000) | Acc: (97.00%) (8818/9088)
Epoch: 191 | Batch_idx: 80 |  Loss: (0.0869) |  Loss2: (0.0000) | Acc: (96.00%) (10056/10368)
Epoch: 191 | Batch_idx: 90 |  Loss: (0.0906) |  Loss2: (0.0000) | Acc: (96.00%) (11286/11648)
Epoch: 191 | Batch_idx: 100 |  Loss: (0.0909) |  Loss2: (0.0000) | Acc: (96.00%) (12523/12928)
Epoch: 191 | Batch_idx: 110 |  Loss: (0.0909) |  Loss2: (0.0000) | Acc: (96.00%) (13758/14208)
Epoch: 191 | Batch_idx: 120 |  Loss: (0.0908) |  Loss2: (0.0000) | Acc: (96.00%) (14994/15488)
Epoch: 191 | Batch_idx: 130 |  Loss: (0.0911) |  Loss2: (0.0000) | Acc: (96.00%) (16232/16768)
Epoch: 191 | Batch_idx: 140 |  Loss: (0.0914) |  Loss2: (0.0000) | Acc: (96.00%) (17473/18048)
Epoch: 191 | Batch_idx: 150 |  Loss: (0.0912) |  Loss2: (0.0000) | Acc: (96.00%) (18722/19328)
Epoch: 191 | Batch_idx: 160 |  Loss: (0.0917) |  Loss2: (0.0000) | Acc: (96.00%) (19959/20608)
Epoch: 191 | Batch_idx: 170 |  Loss: (0.0920) |  Loss2: (0.0000) | Acc: (96.00%) (21200/21888)
Epoch: 191 | Batch_idx: 180 |  Loss: (0.0915) |  Loss2: (0.0000) | Acc: (96.00%) (22440/23168)
Epoch: 191 | Batch_idx: 190 |  Loss: (0.0920) |  Loss2: (0.0000) | Acc: (96.00%) (23672/24448)
Epoch: 191 | Batch_idx: 200 |  Loss: (0.0912) |  Loss2: (0.0000) | Acc: (96.00%) (24917/25728)
Epoch: 191 | Batch_idx: 210 |  Loss: (0.0909) |  Loss2: (0.0000) | Acc: (96.00%) (26162/27008)
Epoch: 191 | Batch_idx: 220 |  Loss: (0.0914) |  Loss2: (0.0000) | Acc: (96.00%) (27384/28288)
Epoch: 191 | Batch_idx: 230 |  Loss: (0.0910) |  Loss2: (0.0000) | Acc: (96.00%) (28628/29568)
Epoch: 191 | Batch_idx: 240 |  Loss: (0.0913) |  Loss2: (0.0000) | Acc: (96.00%) (29856/30848)
Epoch: 191 | Batch_idx: 250 |  Loss: (0.0910) |  Loss2: (0.0000) | Acc: (96.00%) (31102/32128)
Epoch: 191 | Batch_idx: 260 |  Loss: (0.0903) |  Loss2: (0.0000) | Acc: (96.00%) (32355/33408)
Epoch: 191 | Batch_idx: 270 |  Loss: (0.0905) |  Loss2: (0.0000) | Acc: (96.00%) (33594/34688)
Epoch: 191 | Batch_idx: 280 |  Loss: (0.0903) |  Loss2: (0.0000) | Acc: (96.00%) (34840/35968)
Epoch: 191 | Batch_idx: 290 |  Loss: (0.0904) |  Loss2: (0.0000) | Acc: (96.00%) (36081/37248)
Epoch: 191 | Batch_idx: 300 |  Loss: (0.0900) |  Loss2: (0.0000) | Acc: (96.00%) (37326/38528)
Epoch: 191 | Batch_idx: 310 |  Loss: (0.0900) |  Loss2: (0.0000) | Acc: (96.00%) (38559/39808)
Epoch: 191 | Batch_idx: 320 |  Loss: (0.0897) |  Loss2: (0.0000) | Acc: (96.00%) (39804/41088)
Epoch: 191 | Batch_idx: 330 |  Loss: (0.0899) |  Loss2: (0.0000) | Acc: (96.00%) (41045/42368)
Epoch: 191 | Batch_idx: 340 |  Loss: (0.0902) |  Loss2: (0.0000) | Acc: (96.00%) (42280/43648)
Epoch: 191 | Batch_idx: 350 |  Loss: (0.0902) |  Loss2: (0.0000) | Acc: (96.00%) (43522/44928)
Epoch: 191 | Batch_idx: 360 |  Loss: (0.0903) |  Loss2: (0.0000) | Acc: (96.00%) (44755/46208)
Epoch: 191 | Batch_idx: 370 |  Loss: (0.0904) |  Loss2: (0.0000) | Acc: (96.00%) (45994/47488)
Epoch: 191 | Batch_idx: 380 |  Loss: (0.0902) |  Loss2: (0.0000) | Acc: (96.00%) (47238/48768)
Epoch: 191 | Batch_idx: 390 |  Loss: (0.0903) |  Loss2: (0.0000) | Acc: (96.00%) (48430/50000)
# TEST : Loss: (0.4024) | Acc: (88.00%) (8877/10000)
percent tensor([0.5216, 0.5145, 0.5233, 0.5204, 0.5275, 0.5294, 0.5194, 0.5212, 0.5251,
        0.5162, 0.5241, 0.5195, 0.5154, 0.5194, 0.5211, 0.5192],
       device='cuda:0') torch.Size([16])
percent tensor([0.5030, 0.4967, 0.5030, 0.5035, 0.5008, 0.5030, 0.4982, 0.5036, 0.5069,
        0.4994, 0.5048, 0.4972, 0.4956, 0.5106, 0.4969, 0.5046],
       device='cuda:0') torch.Size([16])
percent tensor([0.5640, 0.5420, 0.5679, 0.6052, 0.5887, 0.5847, 0.5734, 0.5904, 0.5749,
        0.5465, 0.5508, 0.5536, 0.5077, 0.6392, 0.5581, 0.5847],
       device='cuda:0') torch.Size([16])
percent tensor([0.6223, 0.6530, 0.6224, 0.6172, 0.6083, 0.6271, 0.6348, 0.6116, 0.6566,
        0.6570, 0.6644, 0.6361, 0.6517, 0.6657, 0.6182, 0.6411],
       device='cuda:0') torch.Size([16])
percent tensor([0.6190, 0.7090, 0.5383, 0.6235, 0.5701, 0.6723, 0.6439, 0.4277, 0.7063,
        0.6812, 0.7446, 0.6132, 0.6759, 0.7293, 0.5866, 0.6532],
       device='cuda:0') torch.Size([16])
percent tensor([0.6701, 0.6748, 0.6764, 0.6656, 0.7143, 0.6768, 0.6835, 0.6975, 0.6786,
        0.6716, 0.6407, 0.6214, 0.6400, 0.6622, 0.6562, 0.6852],
       device='cuda:0') torch.Size([16])
percent tensor([0.6083, 0.6277, 0.7657, 0.6814, 0.7535, 0.7880, 0.6453, 0.6634, 0.6877,
        0.6009, 0.7228, 0.6169, 0.6826, 0.6486, 0.6258, 0.5333],
       device='cuda:0') torch.Size([16])
percent tensor([0.9998, 0.9995, 0.9998, 0.9995, 0.9996, 0.9994, 0.9997, 0.9997, 0.9998,
        0.9997, 0.9999, 0.9998, 0.9999, 0.9993, 0.9996, 0.9994],
       device='cuda:0') torch.Size([16])
Epoch: 192 | Batch_idx: 0 |  Loss: (0.0648) |  Loss2: (0.0000) | Acc: (97.00%) (125/128)
Epoch: 192 | Batch_idx: 10 |  Loss: (0.0837) |  Loss2: (0.0000) | Acc: (97.00%) (1373/1408)
Epoch: 192 | Batch_idx: 20 |  Loss: (0.0840) |  Loss2: (0.0000) | Acc: (97.00%) (2619/2688)
Epoch: 192 | Batch_idx: 30 |  Loss: (0.0836) |  Loss2: (0.0000) | Acc: (97.00%) (3863/3968)
Epoch: 192 | Batch_idx: 40 |  Loss: (0.0826) |  Loss2: (0.0000) | Acc: (97.00%) (5105/5248)
Epoch: 192 | Batch_idx: 50 |  Loss: (0.0871) |  Loss2: (0.0000) | Acc: (97.00%) (6336/6528)
Epoch: 192 | Batch_idx: 60 |  Loss: (0.0883) |  Loss2: (0.0000) | Acc: (96.00%) (7573/7808)
Epoch: 192 | Batch_idx: 70 |  Loss: (0.0898) |  Loss2: (0.0000) | Acc: (96.00%) (8811/9088)
Epoch: 192 | Batch_idx: 80 |  Loss: (0.0906) |  Loss2: (0.0000) | Acc: (96.00%) (10047/10368)
Epoch: 192 | Batch_idx: 90 |  Loss: (0.0911) |  Loss2: (0.0000) | Acc: (96.00%) (11282/11648)
Epoch: 192 | Batch_idx: 100 |  Loss: (0.0909) |  Loss2: (0.0000) | Acc: (96.00%) (12525/12928)
Epoch: 192 | Batch_idx: 110 |  Loss: (0.0898) |  Loss2: (0.0000) | Acc: (96.00%) (13775/14208)
Epoch: 192 | Batch_idx: 120 |  Loss: (0.0893) |  Loss2: (0.0000) | Acc: (97.00%) (15026/15488)
Epoch: 192 | Batch_idx: 130 |  Loss: (0.0883) |  Loss2: (0.0000) | Acc: (97.00%) (16274/16768)
Epoch: 192 | Batch_idx: 140 |  Loss: (0.0886) |  Loss2: (0.0000) | Acc: (97.00%) (17519/18048)
Epoch: 192 | Batch_idx: 150 |  Loss: (0.0879) |  Loss2: (0.0000) | Acc: (97.00%) (18764/19328)
Epoch: 192 | Batch_idx: 160 |  Loss: (0.0880) |  Loss2: (0.0000) | Acc: (97.00%) (20005/20608)
Epoch: 192 | Batch_idx: 170 |  Loss: (0.0874) |  Loss2: (0.0000) | Acc: (97.00%) (21246/21888)
Epoch: 192 | Batch_idx: 180 |  Loss: (0.0868) |  Loss2: (0.0000) | Acc: (97.00%) (22496/23168)
Epoch: 192 | Batch_idx: 190 |  Loss: (0.0871) |  Loss2: (0.0000) | Acc: (97.00%) (23739/24448)
Epoch: 192 | Batch_idx: 200 |  Loss: (0.0877) |  Loss2: (0.0000) | Acc: (97.00%) (24977/25728)
Epoch: 192 | Batch_idx: 210 |  Loss: (0.0873) |  Loss2: (0.0000) | Acc: (97.00%) (26222/27008)
Epoch: 192 | Batch_idx: 220 |  Loss: (0.0877) |  Loss2: (0.0000) | Acc: (97.00%) (27451/28288)
Epoch: 192 | Batch_idx: 230 |  Loss: (0.0873) |  Loss2: (0.0000) | Acc: (97.00%) (28695/29568)
Epoch: 192 | Batch_idx: 240 |  Loss: (0.0871) |  Loss2: (0.0000) | Acc: (97.00%) (29939/30848)
Epoch: 192 | Batch_idx: 250 |  Loss: (0.0873) |  Loss2: (0.0000) | Acc: (97.00%) (31176/32128)
Epoch: 192 | Batch_idx: 260 |  Loss: (0.0872) |  Loss2: (0.0000) | Acc: (97.00%) (32416/33408)
Epoch: 192 | Batch_idx: 270 |  Loss: (0.0871) |  Loss2: (0.0000) | Acc: (97.00%) (33656/34688)
Epoch: 192 | Batch_idx: 280 |  Loss: (0.0871) |  Loss2: (0.0000) | Acc: (97.00%) (34901/35968)
Epoch: 192 | Batch_idx: 290 |  Loss: (0.0873) |  Loss2: (0.0000) | Acc: (97.00%) (36137/37248)
Epoch: 192 | Batch_idx: 300 |  Loss: (0.0873) |  Loss2: (0.0000) | Acc: (97.00%) (37383/38528)
Epoch: 192 | Batch_idx: 310 |  Loss: (0.0870) |  Loss2: (0.0000) | Acc: (97.00%) (38629/39808)
Epoch: 192 | Batch_idx: 320 |  Loss: (0.0869) |  Loss2: (0.0000) | Acc: (97.00%) (39867/41088)
Epoch: 192 | Batch_idx: 330 |  Loss: (0.0868) |  Loss2: (0.0000) | Acc: (97.00%) (41115/42368)
Epoch: 192 | Batch_idx: 340 |  Loss: (0.0866) |  Loss2: (0.0000) | Acc: (97.00%) (42357/43648)
Epoch: 192 | Batch_idx: 350 |  Loss: (0.0870) |  Loss2: (0.0000) | Acc: (97.00%) (43594/44928)
Epoch: 192 | Batch_idx: 360 |  Loss: (0.0868) |  Loss2: (0.0000) | Acc: (97.00%) (44835/46208)
Epoch: 192 | Batch_idx: 370 |  Loss: (0.0868) |  Loss2: (0.0000) | Acc: (97.00%) (46081/47488)
Epoch: 192 | Batch_idx: 380 |  Loss: (0.0867) |  Loss2: (0.0000) | Acc: (97.00%) (47326/48768)
Epoch: 192 | Batch_idx: 390 |  Loss: (0.0868) |  Loss2: (0.0000) | Acc: (97.00%) (48527/50000)
# TEST : Loss: (0.3954) | Acc: (88.00%) (8866/10000)
percent tensor([0.5221, 0.5148, 0.5235, 0.5209, 0.5278, 0.5299, 0.5197, 0.5215, 0.5257,
        0.5165, 0.5246, 0.5198, 0.5158, 0.5202, 0.5214, 0.5195],
       device='cuda:0') torch.Size([16])
percent tensor([0.5032, 0.4969, 0.5031, 0.5036, 0.5008, 0.5032, 0.4983, 0.5037, 0.5070,
        0.4996, 0.5049, 0.4973, 0.4957, 0.5109, 0.4970, 0.5048],
       device='cuda:0') torch.Size([16])
percent tensor([0.5652, 0.5453, 0.5678, 0.6031, 0.5883, 0.5832, 0.5758, 0.5915, 0.5754,
        0.5483, 0.5514, 0.5546, 0.5097, 0.6410, 0.5592, 0.5846],
       device='cuda:0') torch.Size([16])
percent tensor([0.6199, 0.6500, 0.6206, 0.6155, 0.6062, 0.6252, 0.6323, 0.6094, 0.6541,
        0.6541, 0.6617, 0.6343, 0.6489, 0.6633, 0.6156, 0.6388],
       device='cuda:0') torch.Size([16])
percent tensor([0.6182, 0.7058, 0.5397, 0.6254, 0.5701, 0.6705, 0.6433, 0.4283, 0.7083,
        0.6800, 0.7460, 0.6142, 0.6746, 0.7293, 0.5867, 0.6541],
       device='cuda:0') torch.Size([16])
percent tensor([0.6643, 0.6690, 0.6709, 0.6604, 0.7091, 0.6725, 0.6774, 0.6914, 0.6740,
        0.6649, 0.6354, 0.6154, 0.6351, 0.6571, 0.6508, 0.6787],
       device='cuda:0') torch.Size([16])
percent tensor([0.5949, 0.6199, 0.7590, 0.6737, 0.7517, 0.7828, 0.6355, 0.6575, 0.6824,
        0.5914, 0.7092, 0.6025, 0.6741, 0.6351, 0.6144, 0.5236],
       device='cuda:0') torch.Size([16])
percent tensor([0.9998, 0.9995, 0.9998, 0.9996, 0.9996, 0.9995, 0.9997, 0.9996, 0.9998,
        0.9997, 0.9999, 0.9998, 0.9999, 0.9993, 0.9996, 0.9994],
       device='cuda:0') torch.Size([16])
Epoch: 193 | Batch_idx: 0 |  Loss: (0.0851) |  Loss2: (0.0000) | Acc: (96.00%) (124/128)
Epoch: 193 | Batch_idx: 10 |  Loss: (0.0795) |  Loss2: (0.0000) | Acc: (97.00%) (1371/1408)
Epoch: 193 | Batch_idx: 20 |  Loss: (0.0857) |  Loss2: (0.0000) | Acc: (97.00%) (2615/2688)
Epoch: 193 | Batch_idx: 30 |  Loss: (0.0901) |  Loss2: (0.0000) | Acc: (97.00%) (3853/3968)
Epoch: 193 | Batch_idx: 40 |  Loss: (0.0889) |  Loss2: (0.0000) | Acc: (97.00%) (5094/5248)
Epoch: 193 | Batch_idx: 50 |  Loss: (0.0879) |  Loss2: (0.0000) | Acc: (97.00%) (6335/6528)
Epoch: 193 | Batch_idx: 60 |  Loss: (0.0854) |  Loss2: (0.0000) | Acc: (97.00%) (7587/7808)
Epoch: 193 | Batch_idx: 70 |  Loss: (0.0873) |  Loss2: (0.0000) | Acc: (97.00%) (8823/9088)
Epoch: 193 | Batch_idx: 80 |  Loss: (0.0875) |  Loss2: (0.0000) | Acc: (97.00%) (10064/10368)
Epoch: 193 | Batch_idx: 90 |  Loss: (0.0861) |  Loss2: (0.0000) | Acc: (97.00%) (11311/11648)
Epoch: 193 | Batch_idx: 100 |  Loss: (0.0881) |  Loss2: (0.0000) | Acc: (97.00%) (12547/12928)
Epoch: 193 | Batch_idx: 110 |  Loss: (0.0885) |  Loss2: (0.0000) | Acc: (96.00%) (13780/14208)
Epoch: 193 | Batch_idx: 120 |  Loss: (0.0879) |  Loss2: (0.0000) | Acc: (97.00%) (15029/15488)
Epoch: 193 | Batch_idx: 130 |  Loss: (0.0876) |  Loss2: (0.0000) | Acc: (97.00%) (16270/16768)
Epoch: 193 | Batch_idx: 140 |  Loss: (0.0862) |  Loss2: (0.0000) | Acc: (97.00%) (17521/18048)
Epoch: 193 | Batch_idx: 150 |  Loss: (0.0853) |  Loss2: (0.0000) | Acc: (97.00%) (18771/19328)
Epoch: 193 | Batch_idx: 160 |  Loss: (0.0846) |  Loss2: (0.0000) | Acc: (97.00%) (20018/20608)
Epoch: 193 | Batch_idx: 170 |  Loss: (0.0842) |  Loss2: (0.0000) | Acc: (97.00%) (21257/21888)
Epoch: 193 | Batch_idx: 180 |  Loss: (0.0845) |  Loss2: (0.0000) | Acc: (97.00%) (22498/23168)
Epoch: 193 | Batch_idx: 190 |  Loss: (0.0846) |  Loss2: (0.0000) | Acc: (97.00%) (23741/24448)
Epoch: 193 | Batch_idx: 200 |  Loss: (0.0843) |  Loss2: (0.0000) | Acc: (97.00%) (24985/25728)
Epoch: 193 | Batch_idx: 210 |  Loss: (0.0842) |  Loss2: (0.0000) | Acc: (97.00%) (26225/27008)
Epoch: 193 | Batch_idx: 220 |  Loss: (0.0842) |  Loss2: (0.0000) | Acc: (97.00%) (27467/28288)
Epoch: 193 | Batch_idx: 230 |  Loss: (0.0841) |  Loss2: (0.0000) | Acc: (97.00%) (28705/29568)
Epoch: 193 | Batch_idx: 240 |  Loss: (0.0841) |  Loss2: (0.0000) | Acc: (97.00%) (29948/30848)
Epoch: 193 | Batch_idx: 250 |  Loss: (0.0840) |  Loss2: (0.0000) | Acc: (97.00%) (31198/32128)
Epoch: 193 | Batch_idx: 260 |  Loss: (0.0844) |  Loss2: (0.0000) | Acc: (97.00%) (32439/33408)
Epoch: 193 | Batch_idx: 270 |  Loss: (0.0847) |  Loss2: (0.0000) | Acc: (97.00%) (33674/34688)
Epoch: 193 | Batch_idx: 280 |  Loss: (0.0842) |  Loss2: (0.0000) | Acc: (97.00%) (34929/35968)
Epoch: 193 | Batch_idx: 290 |  Loss: (0.0838) |  Loss2: (0.0000) | Acc: (97.00%) (36182/37248)
Epoch: 193 | Batch_idx: 300 |  Loss: (0.0840) |  Loss2: (0.0000) | Acc: (97.00%) (37424/38528)
Epoch: 193 | Batch_idx: 310 |  Loss: (0.0839) |  Loss2: (0.0000) | Acc: (97.00%) (38668/39808)
Epoch: 193 | Batch_idx: 320 |  Loss: (0.0837) |  Loss2: (0.0000) | Acc: (97.00%) (39916/41088)
Epoch: 193 | Batch_idx: 330 |  Loss: (0.0833) |  Loss2: (0.0000) | Acc: (97.00%) (41169/42368)
Epoch: 193 | Batch_idx: 340 |  Loss: (0.0836) |  Loss2: (0.0000) | Acc: (97.00%) (42410/43648)
Epoch: 193 | Batch_idx: 350 |  Loss: (0.0836) |  Loss2: (0.0000) | Acc: (97.00%) (43653/44928)
Epoch: 193 | Batch_idx: 360 |  Loss: (0.0838) |  Loss2: (0.0000) | Acc: (97.00%) (44896/46208)
Epoch: 193 | Batch_idx: 370 |  Loss: (0.0836) |  Loss2: (0.0000) | Acc: (97.00%) (46144/47488)
Epoch: 193 | Batch_idx: 380 |  Loss: (0.0837) |  Loss2: (0.0000) | Acc: (97.00%) (47391/48768)
Epoch: 193 | Batch_idx: 390 |  Loss: (0.0836) |  Loss2: (0.0000) | Acc: (97.00%) (48592/50000)
# TEST : Loss: (0.3916) | Acc: (88.00%) (8884/10000)
percent tensor([0.5225, 0.5150, 0.5240, 0.5216, 0.5284, 0.5305, 0.5200, 0.5222, 0.5262,
        0.5169, 0.5250, 0.5203, 0.5161, 0.5206, 0.5219, 0.5199],
       device='cuda:0') torch.Size([16])
percent tensor([0.5014, 0.4950, 0.5012, 0.5019, 0.4990, 0.5016, 0.4964, 0.5016, 0.5054,
        0.4976, 0.5032, 0.4953, 0.4938, 0.5094, 0.4951, 0.5030],
       device='cuda:0') torch.Size([16])
percent tensor([0.5642, 0.5463, 0.5654, 0.6005, 0.5857, 0.5807, 0.5758, 0.5898, 0.5754,
        0.5486, 0.5515, 0.5544, 0.5118, 0.6397, 0.5582, 0.5833],
       device='cuda:0') torch.Size([16])
percent tensor([0.6216, 0.6515, 0.6231, 0.6181, 0.6082, 0.6270, 0.6341, 0.6117, 0.6565,
        0.6557, 0.6643, 0.6360, 0.6507, 0.6649, 0.6172, 0.6410],
       device='cuda:0') torch.Size([16])
percent tensor([0.6207, 0.7076, 0.5392, 0.6298, 0.5716, 0.6751, 0.6459, 0.4264, 0.7130,
        0.6809, 0.7499, 0.6135, 0.6739, 0.7377, 0.5887, 0.6588],
       device='cuda:0') torch.Size([16])
percent tensor([0.6543, 0.6578, 0.6622, 0.6523, 0.7018, 0.6644, 0.6670, 0.6820, 0.6650,
        0.6547, 0.6248, 0.6076, 0.6251, 0.6466, 0.6400, 0.6686],
       device='cuda:0') torch.Size([16])
percent tensor([0.5909, 0.6126, 0.7635, 0.6716, 0.7529, 0.7844, 0.6268, 0.6544, 0.6774,
        0.5856, 0.7034, 0.6021, 0.6703, 0.6223, 0.6057, 0.5184],
       device='cuda:0') torch.Size([16])
percent tensor([0.9998, 0.9996, 0.9998, 0.9996, 0.9996, 0.9995, 0.9997, 0.9997, 0.9998,
        0.9997, 0.9999, 0.9998, 0.9999, 0.9993, 0.9996, 0.9994],
       device='cuda:0') torch.Size([16])
Epoch: 194 | Batch_idx: 0 |  Loss: (0.0782) |  Loss2: (0.0000) | Acc: (97.00%) (125/128)
Epoch: 194 | Batch_idx: 10 |  Loss: (0.0862) |  Loss2: (0.0000) | Acc: (96.00%) (1364/1408)
Epoch: 194 | Batch_idx: 20 |  Loss: (0.0860) |  Loss2: (0.0000) | Acc: (96.00%) (2605/2688)
Epoch: 194 | Batch_idx: 30 |  Loss: (0.0826) |  Loss2: (0.0000) | Acc: (97.00%) (3857/3968)
Epoch: 194 | Batch_idx: 40 |  Loss: (0.0840) |  Loss2: (0.0000) | Acc: (97.00%) (5102/5248)
Epoch: 194 | Batch_idx: 50 |  Loss: (0.0823) |  Loss2: (0.0000) | Acc: (97.00%) (6348/6528)
Epoch: 194 | Batch_idx: 60 |  Loss: (0.0844) |  Loss2: (0.0000) | Acc: (97.00%) (7587/7808)
Epoch: 194 | Batch_idx: 70 |  Loss: (0.0849) |  Loss2: (0.0000) | Acc: (97.00%) (8827/9088)
Epoch: 194 | Batch_idx: 80 |  Loss: (0.0838) |  Loss2: (0.0000) | Acc: (97.00%) (10079/10368)
Epoch: 194 | Batch_idx: 90 |  Loss: (0.0818) |  Loss2: (0.0000) | Acc: (97.00%) (11331/11648)
Epoch: 194 | Batch_idx: 100 |  Loss: (0.0816) |  Loss2: (0.0000) | Acc: (97.00%) (12578/12928)
Epoch: 194 | Batch_idx: 110 |  Loss: (0.0836) |  Loss2: (0.0000) | Acc: (97.00%) (13810/14208)
Epoch: 194 | Batch_idx: 120 |  Loss: (0.0849) |  Loss2: (0.0000) | Acc: (97.00%) (15039/15488)
Epoch: 194 | Batch_idx: 130 |  Loss: (0.0860) |  Loss2: (0.0000) | Acc: (97.00%) (16276/16768)
Epoch: 194 | Batch_idx: 140 |  Loss: (0.0861) |  Loss2: (0.0000) | Acc: (97.00%) (17517/18048)
Epoch: 194 | Batch_idx: 150 |  Loss: (0.0860) |  Loss2: (0.0000) | Acc: (97.00%) (18762/19328)
Epoch: 194 | Batch_idx: 160 |  Loss: (0.0855) |  Loss2: (0.0000) | Acc: (97.00%) (20015/20608)
Epoch: 194 | Batch_idx: 170 |  Loss: (0.0858) |  Loss2: (0.0000) | Acc: (97.00%) (21264/21888)
Epoch: 194 | Batch_idx: 180 |  Loss: (0.0852) |  Loss2: (0.0000) | Acc: (97.00%) (22515/23168)
Epoch: 194 | Batch_idx: 190 |  Loss: (0.0845) |  Loss2: (0.0000) | Acc: (97.00%) (23766/24448)
Epoch: 194 | Batch_idx: 200 |  Loss: (0.0849) |  Loss2: (0.0000) | Acc: (97.00%) (25001/25728)
Epoch: 194 | Batch_idx: 210 |  Loss: (0.0843) |  Loss2: (0.0000) | Acc: (97.00%) (26245/27008)
Epoch: 194 | Batch_idx: 220 |  Loss: (0.0840) |  Loss2: (0.0000) | Acc: (97.00%) (27492/28288)
Epoch: 194 | Batch_idx: 230 |  Loss: (0.0843) |  Loss2: (0.0000) | Acc: (97.00%) (28729/29568)
Epoch: 194 | Batch_idx: 240 |  Loss: (0.0842) |  Loss2: (0.0000) | Acc: (97.00%) (29975/30848)
Epoch: 194 | Batch_idx: 250 |  Loss: (0.0841) |  Loss2: (0.0000) | Acc: (97.00%) (31215/32128)
Epoch: 194 | Batch_idx: 260 |  Loss: (0.0839) |  Loss2: (0.0000) | Acc: (97.00%) (32462/33408)
Epoch: 194 | Batch_idx: 270 |  Loss: (0.0836) |  Loss2: (0.0000) | Acc: (97.00%) (33716/34688)
Epoch: 194 | Batch_idx: 280 |  Loss: (0.0837) |  Loss2: (0.0000) | Acc: (97.00%) (34959/35968)
Epoch: 194 | Batch_idx: 290 |  Loss: (0.0835) |  Loss2: (0.0000) | Acc: (97.00%) (36209/37248)
Epoch: 194 | Batch_idx: 300 |  Loss: (0.0831) |  Loss2: (0.0000) | Acc: (97.00%) (37462/38528)
Epoch: 194 | Batch_idx: 310 |  Loss: (0.0829) |  Loss2: (0.0000) | Acc: (97.00%) (38712/39808)
Epoch: 194 | Batch_idx: 320 |  Loss: (0.0831) |  Loss2: (0.0000) | Acc: (97.00%) (39954/41088)
Epoch: 194 | Batch_idx: 330 |  Loss: (0.0832) |  Loss2: (0.0000) | Acc: (97.00%) (41194/42368)
Epoch: 194 | Batch_idx: 340 |  Loss: (0.0836) |  Loss2: (0.0000) | Acc: (97.00%) (42422/43648)
Epoch: 194 | Batch_idx: 350 |  Loss: (0.0838) |  Loss2: (0.0000) | Acc: (97.00%) (43662/44928)
Epoch: 194 | Batch_idx: 360 |  Loss: (0.0841) |  Loss2: (0.0000) | Acc: (97.00%) (44900/46208)
Epoch: 194 | Batch_idx: 370 |  Loss: (0.0841) |  Loss2: (0.0000) | Acc: (97.00%) (46142/47488)
Epoch: 194 | Batch_idx: 380 |  Loss: (0.0840) |  Loss2: (0.0000) | Acc: (97.00%) (47392/48768)
Epoch: 194 | Batch_idx: 390 |  Loss: (0.0841) |  Loss2: (0.0000) | Acc: (97.00%) (48585/50000)
# TEST : Loss: (0.3880) | Acc: (88.00%) (8886/10000)
percent tensor([0.5231, 0.5156, 0.5244, 0.5222, 0.5290, 0.5311, 0.5205, 0.5228, 0.5270,
        0.5174, 0.5256, 0.5207, 0.5166, 0.5215, 0.5225, 0.5204],
       device='cuda:0') torch.Size([16])
percent tensor([0.5018, 0.4952, 0.5016, 0.5024, 0.4993, 0.5020, 0.4966, 0.5020, 0.5057,
        0.4979, 0.5035, 0.4956, 0.4939, 0.5097, 0.4953, 0.5033],
       device='cuda:0') torch.Size([16])
percent tensor([0.5647, 0.5477, 0.5669, 0.5997, 0.5860, 0.5801, 0.5762, 0.5904, 0.5767,
        0.5500, 0.5521, 0.5566, 0.5138, 0.6394, 0.5582, 0.5831],
       device='cuda:0') torch.Size([16])
percent tensor([0.6222, 0.6522, 0.6234, 0.6190, 0.6090, 0.6282, 0.6348, 0.6119, 0.6575,
        0.6562, 0.6652, 0.6365, 0.6512, 0.6661, 0.6181, 0.6419],
       device='cuda:0') torch.Size([16])
percent tensor([0.6223, 0.7072, 0.5406, 0.6324, 0.5721, 0.6775, 0.6461, 0.4286, 0.7136,
        0.6815, 0.7530, 0.6148, 0.6737, 0.7360, 0.5908, 0.6602],
       device='cuda:0') torch.Size([16])
percent tensor([0.6537, 0.6567, 0.6625, 0.6524, 0.7026, 0.6651, 0.6661, 0.6816, 0.6647,
        0.6531, 0.6229, 0.6065, 0.6246, 0.6466, 0.6394, 0.6674],
       device='cuda:0') torch.Size([16])
percent tensor([0.6057, 0.6287, 0.7723, 0.6798, 0.7625, 0.7919, 0.6413, 0.6633, 0.6923,
        0.6002, 0.7158, 0.6158, 0.6892, 0.6383, 0.6144, 0.5269],
       device='cuda:0') torch.Size([16])
percent tensor([0.9998, 0.9996, 0.9998, 0.9996, 0.9996, 0.9995, 0.9997, 0.9997, 0.9998,
        0.9997, 0.9999, 0.9998, 0.9999, 0.9994, 0.9996, 0.9994],
       device='cuda:0') torch.Size([16])
Epoch: 195 | Batch_idx: 0 |  Loss: (0.1182) |  Loss2: (0.0000) | Acc: (96.00%) (123/128)
Epoch: 195 | Batch_idx: 10 |  Loss: (0.0956) |  Loss2: (0.0000) | Acc: (96.00%) (1359/1408)
Epoch: 195 | Batch_idx: 20 |  Loss: (0.0885) |  Loss2: (0.0000) | Acc: (97.00%) (2609/2688)
Epoch: 195 | Batch_idx: 30 |  Loss: (0.0901) |  Loss2: (0.0000) | Acc: (96.00%) (3846/3968)
Epoch: 195 | Batch_idx: 40 |  Loss: (0.0875) |  Loss2: (0.0000) | Acc: (97.00%) (5093/5248)
Epoch: 195 | Batch_idx: 50 |  Loss: (0.0861) |  Loss2: (0.0000) | Acc: (97.00%) (6342/6528)
Epoch: 195 | Batch_idx: 60 |  Loss: (0.0867) |  Loss2: (0.0000) | Acc: (97.00%) (7582/7808)
Epoch: 195 | Batch_idx: 70 |  Loss: (0.0860) |  Loss2: (0.0000) | Acc: (97.00%) (8830/9088)
Epoch: 195 | Batch_idx: 80 |  Loss: (0.0851) |  Loss2: (0.0000) | Acc: (97.00%) (10071/10368)
Epoch: 195 | Batch_idx: 90 |  Loss: (0.0832) |  Loss2: (0.0000) | Acc: (97.00%) (11325/11648)
Epoch: 195 | Batch_idx: 100 |  Loss: (0.0837) |  Loss2: (0.0000) | Acc: (97.00%) (12565/12928)
Epoch: 195 | Batch_idx: 110 |  Loss: (0.0840) |  Loss2: (0.0000) | Acc: (97.00%) (13801/14208)
Epoch: 195 | Batch_idx: 120 |  Loss: (0.0849) |  Loss2: (0.0000) | Acc: (97.00%) (15035/15488)
Epoch: 195 | Batch_idx: 130 |  Loss: (0.0829) |  Loss2: (0.0000) | Acc: (97.00%) (16290/16768)
Epoch: 195 | Batch_idx: 140 |  Loss: (0.0832) |  Loss2: (0.0000) | Acc: (97.00%) (17531/18048)
Epoch: 195 | Batch_idx: 150 |  Loss: (0.0836) |  Loss2: (0.0000) | Acc: (97.00%) (18770/19328)
Epoch: 195 | Batch_idx: 160 |  Loss: (0.0826) |  Loss2: (0.0000) | Acc: (97.00%) (20021/20608)
Epoch: 195 | Batch_idx: 170 |  Loss: (0.0825) |  Loss2: (0.0000) | Acc: (97.00%) (21270/21888)
Epoch: 195 | Batch_idx: 180 |  Loss: (0.0823) |  Loss2: (0.0000) | Acc: (97.00%) (22517/23168)
Epoch: 195 | Batch_idx: 190 |  Loss: (0.0814) |  Loss2: (0.0000) | Acc: (97.00%) (23770/24448)
Epoch: 195 | Batch_idx: 200 |  Loss: (0.0818) |  Loss2: (0.0000) | Acc: (97.00%) (25006/25728)
Epoch: 195 | Batch_idx: 210 |  Loss: (0.0816) |  Loss2: (0.0000) | Acc: (97.00%) (26255/27008)
Epoch: 195 | Batch_idx: 220 |  Loss: (0.0815) |  Loss2: (0.0000) | Acc: (97.00%) (27498/28288)
Epoch: 195 | Batch_idx: 230 |  Loss: (0.0822) |  Loss2: (0.0000) | Acc: (97.00%) (28725/29568)
Epoch: 195 | Batch_idx: 240 |  Loss: (0.0821) |  Loss2: (0.0000) | Acc: (97.00%) (29970/30848)
Epoch: 195 | Batch_idx: 250 |  Loss: (0.0819) |  Loss2: (0.0000) | Acc: (97.00%) (31219/32128)
Epoch: 195 | Batch_idx: 260 |  Loss: (0.0820) |  Loss2: (0.0000) | Acc: (97.00%) (32465/33408)
Epoch: 195 | Batch_idx: 270 |  Loss: (0.0816) |  Loss2: (0.0000) | Acc: (97.00%) (33711/34688)
Epoch: 195 | Batch_idx: 280 |  Loss: (0.0813) |  Loss2: (0.0000) | Acc: (97.00%) (34959/35968)
Epoch: 195 | Batch_idx: 290 |  Loss: (0.0811) |  Loss2: (0.0000) | Acc: (97.00%) (36207/37248)
Epoch: 195 | Batch_idx: 300 |  Loss: (0.0816) |  Loss2: (0.0000) | Acc: (97.00%) (37448/38528)
Epoch: 195 | Batch_idx: 310 |  Loss: (0.0816) |  Loss2: (0.0000) | Acc: (97.00%) (38690/39808)
Epoch: 195 | Batch_idx: 320 |  Loss: (0.0816) |  Loss2: (0.0000) | Acc: (97.00%) (39935/41088)
Epoch: 195 | Batch_idx: 330 |  Loss: (0.0815) |  Loss2: (0.0000) | Acc: (97.00%) (41180/42368)
Epoch: 195 | Batch_idx: 340 |  Loss: (0.0814) |  Loss2: (0.0000) | Acc: (97.00%) (42426/43648)
Epoch: 195 | Batch_idx: 350 |  Loss: (0.0811) |  Loss2: (0.0000) | Acc: (97.00%) (43685/44928)
Epoch: 195 | Batch_idx: 360 |  Loss: (0.0809) |  Loss2: (0.0000) | Acc: (97.00%) (44933/46208)
Epoch: 195 | Batch_idx: 370 |  Loss: (0.0805) |  Loss2: (0.0000) | Acc: (97.00%) (46187/47488)
Epoch: 195 | Batch_idx: 380 |  Loss: (0.0810) |  Loss2: (0.0000) | Acc: (97.00%) (47415/48768)
Epoch: 195 | Batch_idx: 390 |  Loss: (0.0812) |  Loss2: (0.0000) | Acc: (97.00%) (48616/50000)
=> saving checkpoint 'drive/app/torch/save_Schedule/checkpoint_195.pth.tar'
# TEST : Loss: (0.3881) | Acc: (88.00%) (8892/10000)
percent tensor([0.5225, 0.5146, 0.5237, 0.5215, 0.5282, 0.5308, 0.5196, 0.5220, 0.5264,
        0.5165, 0.5249, 0.5198, 0.5158, 0.5209, 0.5217, 0.5196],
       device='cuda:0') torch.Size([16])
percent tensor([0.5029, 0.4963, 0.5026, 0.5032, 0.5001, 0.5030, 0.4976, 0.5031, 0.5067,
        0.4990, 0.5046, 0.4965, 0.4949, 0.5110, 0.4964, 0.5044],
       device='cuda:0') torch.Size([16])
percent tensor([0.5605, 0.5440, 0.5626, 0.5957, 0.5813, 0.5768, 0.5716, 0.5863, 0.5716,
        0.5458, 0.5470, 0.5522, 0.5087, 0.6365, 0.5539, 0.5793],
       device='cuda:0') torch.Size([16])
percent tensor([0.6219, 0.6516, 0.6231, 0.6177, 0.6087, 0.6283, 0.6345, 0.6111, 0.6570,
        0.6556, 0.6645, 0.6362, 0.6509, 0.6657, 0.6175, 0.6414],
       device='cuda:0') torch.Size([16])
percent tensor([0.6076, 0.6958, 0.5271, 0.6164, 0.5584, 0.6608, 0.6334, 0.4144, 0.7031,
        0.6693, 0.7430, 0.6003, 0.6609, 0.7263, 0.5758, 0.6437],
       device='cuda:0') torch.Size([16])
percent tensor([0.6645, 0.6685, 0.6716, 0.6626, 0.7122, 0.6749, 0.6778, 0.6908, 0.6767,
        0.6645, 0.6359, 0.6181, 0.6375, 0.6587, 0.6509, 0.6784],
       device='cuda:0') torch.Size([16])
percent tensor([0.5913, 0.6185, 0.7604, 0.6668, 0.7518, 0.7865, 0.6249, 0.6466, 0.6814,
        0.5923, 0.7040, 0.6020, 0.6806, 0.6276, 0.5992, 0.5147],
       device='cuda:0') torch.Size([16])
percent tensor([0.9998, 0.9996, 0.9998, 0.9996, 0.9997, 0.9995, 0.9997, 0.9997, 0.9998,
        0.9997, 0.9999, 0.9998, 0.9999, 0.9993, 0.9996, 0.9994],
       device='cuda:0') torch.Size([16])
Epoch: 196 | Batch_idx: 0 |  Loss: (0.1006) |  Loss2: (0.0000) | Acc: (96.00%) (124/128)
Epoch: 196 | Batch_idx: 10 |  Loss: (0.0775) |  Loss2: (0.0000) | Acc: (97.00%) (1370/1408)
Epoch: 196 | Batch_idx: 20 |  Loss: (0.0746) |  Loss2: (0.0000) | Acc: (97.00%) (2625/2688)
Epoch: 196 | Batch_idx: 30 |  Loss: (0.0740) |  Loss2: (0.0000) | Acc: (97.00%) (3874/3968)
Epoch: 196 | Batch_idx: 40 |  Loss: (0.0753) |  Loss2: (0.0000) | Acc: (97.00%) (5115/5248)
Epoch: 196 | Batch_idx: 50 |  Loss: (0.0769) |  Loss2: (0.0000) | Acc: (97.00%) (6359/6528)
Epoch: 196 | Batch_idx: 60 |  Loss: (0.0771) |  Loss2: (0.0000) | Acc: (97.00%) (7607/7808)
Epoch: 196 | Batch_idx: 70 |  Loss: (0.0772) |  Loss2: (0.0000) | Acc: (97.00%) (8853/9088)
Epoch: 196 | Batch_idx: 80 |  Loss: (0.0788) |  Loss2: (0.0000) | Acc: (97.00%) (10094/10368)
Epoch: 196 | Batch_idx: 90 |  Loss: (0.0776) |  Loss2: (0.0000) | Acc: (97.00%) (11346/11648)
Epoch: 196 | Batch_idx: 100 |  Loss: (0.0782) |  Loss2: (0.0000) | Acc: (97.00%) (12593/12928)
Epoch: 196 | Batch_idx: 110 |  Loss: (0.0785) |  Loss2: (0.0000) | Acc: (97.00%) (13841/14208)
Epoch: 196 | Batch_idx: 120 |  Loss: (0.0803) |  Loss2: (0.0000) | Acc: (97.00%) (15075/15488)
Epoch: 196 | Batch_idx: 130 |  Loss: (0.0801) |  Loss2: (0.0000) | Acc: (97.00%) (16317/16768)
Epoch: 196 | Batch_idx: 140 |  Loss: (0.0804) |  Loss2: (0.0000) | Acc: (97.00%) (17564/18048)
Epoch: 196 | Batch_idx: 150 |  Loss: (0.0797) |  Loss2: (0.0000) | Acc: (97.00%) (18818/19328)
Epoch: 196 | Batch_idx: 160 |  Loss: (0.0796) |  Loss2: (0.0000) | Acc: (97.00%) (20064/20608)
Epoch: 196 | Batch_idx: 170 |  Loss: (0.0794) |  Loss2: (0.0000) | Acc: (97.00%) (21309/21888)
Epoch: 196 | Batch_idx: 180 |  Loss: (0.0797) |  Loss2: (0.0000) | Acc: (97.00%) (22555/23168)
Epoch: 196 | Batch_idx: 190 |  Loss: (0.0795) |  Loss2: (0.0000) | Acc: (97.00%) (23806/24448)
Epoch: 196 | Batch_idx: 200 |  Loss: (0.0794) |  Loss2: (0.0000) | Acc: (97.00%) (25051/25728)
Epoch: 196 | Batch_idx: 210 |  Loss: (0.0795) |  Loss2: (0.0000) | Acc: (97.00%) (26304/27008)
Epoch: 196 | Batch_idx: 220 |  Loss: (0.0794) |  Loss2: (0.0000) | Acc: (97.00%) (27551/28288)
Epoch: 196 | Batch_idx: 230 |  Loss: (0.0791) |  Loss2: (0.0000) | Acc: (97.00%) (28806/29568)
Epoch: 196 | Batch_idx: 240 |  Loss: (0.0792) |  Loss2: (0.0000) | Acc: (97.00%) (30051/30848)
Epoch: 196 | Batch_idx: 250 |  Loss: (0.0795) |  Loss2: (0.0000) | Acc: (97.00%) (31294/32128)
Epoch: 196 | Batch_idx: 260 |  Loss: (0.0792) |  Loss2: (0.0000) | Acc: (97.00%) (32545/33408)
Epoch: 196 | Batch_idx: 270 |  Loss: (0.0793) |  Loss2: (0.0000) | Acc: (97.00%) (33793/34688)
Epoch: 196 | Batch_idx: 280 |  Loss: (0.0794) |  Loss2: (0.0000) | Acc: (97.00%) (35040/35968)
Epoch: 196 | Batch_idx: 290 |  Loss: (0.0793) |  Loss2: (0.0000) | Acc: (97.00%) (36288/37248)
Epoch: 196 | Batch_idx: 300 |  Loss: (0.0793) |  Loss2: (0.0000) | Acc: (97.00%) (37534/38528)
Epoch: 196 | Batch_idx: 310 |  Loss: (0.0783) |  Loss2: (0.0000) | Acc: (97.00%) (38800/39808)
Epoch: 196 | Batch_idx: 320 |  Loss: (0.0785) |  Loss2: (0.0000) | Acc: (97.00%) (40040/41088)
Epoch: 196 | Batch_idx: 330 |  Loss: (0.0784) |  Loss2: (0.0000) | Acc: (97.00%) (41285/42368)
Epoch: 196 | Batch_idx: 340 |  Loss: (0.0781) |  Loss2: (0.0000) | Acc: (97.00%) (42541/43648)
Epoch: 196 | Batch_idx: 350 |  Loss: (0.0780) |  Loss2: (0.0000) | Acc: (97.00%) (43792/44928)
Epoch: 196 | Batch_idx: 360 |  Loss: (0.0778) |  Loss2: (0.0000) | Acc: (97.00%) (45046/46208)
Epoch: 196 | Batch_idx: 370 |  Loss: (0.0778) |  Loss2: (0.0000) | Acc: (97.00%) (46296/47488)
Epoch: 196 | Batch_idx: 380 |  Loss: (0.0775) |  Loss2: (0.0000) | Acc: (97.00%) (47551/48768)
Epoch: 196 | Batch_idx: 390 |  Loss: (0.0777) |  Loss2: (0.0000) | Acc: (97.00%) (48744/50000)
# TEST : Loss: (0.3881) | Acc: (88.00%) (8897/10000)
percent tensor([0.5226, 0.5145, 0.5239, 0.5217, 0.5283, 0.5308, 0.5195, 0.5223, 0.5266,
        0.5165, 0.5249, 0.5198, 0.5158, 0.5211, 0.5216, 0.5196],
       device='cuda:0') torch.Size([16])
percent tensor([0.5011, 0.4942, 0.5007, 0.5015, 0.4982, 0.5014, 0.4957, 0.5011, 0.5049,
        0.4969, 0.5028, 0.4945, 0.4928, 0.5094, 0.4944, 0.5026],
       device='cuda:0') torch.Size([16])
percent tensor([0.5659, 0.5510, 0.5656, 0.5991, 0.5854, 0.5811, 0.5772, 0.5903, 0.5768,
        0.5520, 0.5533, 0.5569, 0.5144, 0.6422, 0.5599, 0.5846],
       device='cuda:0') torch.Size([16])
percent tensor([0.6236, 0.6524, 0.6249, 0.6201, 0.6105, 0.6299, 0.6360, 0.6129, 0.6587,
        0.6569, 0.6663, 0.6378, 0.6522, 0.6670, 0.6190, 0.6433],
       device='cuda:0') torch.Size([16])
percent tensor([0.6069, 0.7012, 0.5232, 0.6101, 0.5540, 0.6597, 0.6357, 0.4086, 0.7071,
        0.6745, 0.7485, 0.5996, 0.6663, 0.7315, 0.5757, 0.6441],
       device='cuda:0') torch.Size([16])
percent tensor([0.6613, 0.6652, 0.6695, 0.6601, 0.7101, 0.6728, 0.6744, 0.6883, 0.6741,
        0.6607, 0.6322, 0.6157, 0.6346, 0.6545, 0.6481, 0.6750],
       device='cuda:0') torch.Size([16])
percent tensor([0.6031, 0.6250, 0.7714, 0.6802, 0.7617, 0.7939, 0.6354, 0.6571, 0.6911,
        0.6000, 0.7132, 0.6183, 0.6910, 0.6321, 0.6059, 0.5222],
       device='cuda:0') torch.Size([16])
percent tensor([0.9998, 0.9996, 0.9998, 0.9996, 0.9997, 0.9996, 0.9997, 0.9997, 0.9998,
        0.9997, 0.9999, 0.9998, 0.9999, 0.9994, 0.9996, 0.9994],
       device='cuda:0') torch.Size([16])
Epoch: 197 | Batch_idx: 0 |  Loss: (0.0496) |  Loss2: (0.0000) | Acc: (98.00%) (126/128)
Epoch: 197 | Batch_idx: 10 |  Loss: (0.0606) |  Loss2: (0.0000) | Acc: (98.00%) (1381/1408)
Epoch: 197 | Batch_idx: 20 |  Loss: (0.0725) |  Loss2: (0.0000) | Acc: (97.00%) (2623/2688)
Epoch: 197 | Batch_idx: 30 |  Loss: (0.0773) |  Loss2: (0.0000) | Acc: (97.00%) (3862/3968)
Epoch: 197 | Batch_idx: 40 |  Loss: (0.0746) |  Loss2: (0.0000) | Acc: (97.00%) (5121/5248)
Epoch: 197 | Batch_idx: 50 |  Loss: (0.0748) |  Loss2: (0.0000) | Acc: (97.00%) (6368/6528)
Epoch: 197 | Batch_idx: 60 |  Loss: (0.0762) |  Loss2: (0.0000) | Acc: (97.00%) (7613/7808)
Epoch: 197 | Batch_idx: 70 |  Loss: (0.0779) |  Loss2: (0.0000) | Acc: (97.00%) (8856/9088)
Epoch: 197 | Batch_idx: 80 |  Loss: (0.0768) |  Loss2: (0.0000) | Acc: (97.00%) (10108/10368)
Epoch: 197 | Batch_idx: 90 |  Loss: (0.0766) |  Loss2: (0.0000) | Acc: (97.00%) (11359/11648)
Epoch: 197 | Batch_idx: 100 |  Loss: (0.0787) |  Loss2: (0.0000) | Acc: (97.00%) (12594/12928)
Epoch: 197 | Batch_idx: 110 |  Loss: (0.0790) |  Loss2: (0.0000) | Acc: (97.00%) (13844/14208)
Epoch: 197 | Batch_idx: 120 |  Loss: (0.0788) |  Loss2: (0.0000) | Acc: (97.00%) (15087/15488)
Epoch: 197 | Batch_idx: 130 |  Loss: (0.0780) |  Loss2: (0.0000) | Acc: (97.00%) (16341/16768)
Epoch: 197 | Batch_idx: 140 |  Loss: (0.0787) |  Loss2: (0.0000) | Acc: (97.00%) (17580/18048)
Epoch: 197 | Batch_idx: 150 |  Loss: (0.0791) |  Loss2: (0.0000) | Acc: (97.00%) (18824/19328)
Epoch: 197 | Batch_idx: 160 |  Loss: (0.0782) |  Loss2: (0.0000) | Acc: (97.00%) (20076/20608)
Epoch: 197 | Batch_idx: 170 |  Loss: (0.0781) |  Loss2: (0.0000) | Acc: (97.00%) (21321/21888)
Epoch: 197 | Batch_idx: 180 |  Loss: (0.0783) |  Loss2: (0.0000) | Acc: (97.00%) (22566/23168)
Epoch: 197 | Batch_idx: 190 |  Loss: (0.0783) |  Loss2: (0.0000) | Acc: (97.00%) (23815/24448)
Epoch: 197 | Batch_idx: 200 |  Loss: (0.0784) |  Loss2: (0.0000) | Acc: (97.00%) (25060/25728)
Epoch: 197 | Batch_idx: 210 |  Loss: (0.0779) |  Loss2: (0.0000) | Acc: (97.00%) (26309/27008)
Epoch: 197 | Batch_idx: 220 |  Loss: (0.0774) |  Loss2: (0.0000) | Acc: (97.00%) (27561/28288)
Epoch: 197 | Batch_idx: 230 |  Loss: (0.0774) |  Loss2: (0.0000) | Acc: (97.00%) (28808/29568)
Epoch: 197 | Batch_idx: 240 |  Loss: (0.0770) |  Loss2: (0.0000) | Acc: (97.00%) (30058/30848)
Epoch: 197 | Batch_idx: 250 |  Loss: (0.0766) |  Loss2: (0.0000) | Acc: (97.00%) (31310/32128)
Epoch: 197 | Batch_idx: 260 |  Loss: (0.0763) |  Loss2: (0.0000) | Acc: (97.00%) (32564/33408)
Epoch: 197 | Batch_idx: 270 |  Loss: (0.0766) |  Loss2: (0.0000) | Acc: (97.00%) (33810/34688)
Epoch: 197 | Batch_idx: 280 |  Loss: (0.0769) |  Loss2: (0.0000) | Acc: (97.00%) (35052/35968)
Epoch: 197 | Batch_idx: 290 |  Loss: (0.0768) |  Loss2: (0.0000) | Acc: (97.00%) (36294/37248)
Epoch: 197 | Batch_idx: 300 |  Loss: (0.0767) |  Loss2: (0.0000) | Acc: (97.00%) (37545/38528)
Epoch: 197 | Batch_idx: 310 |  Loss: (0.0764) |  Loss2: (0.0000) | Acc: (97.00%) (38801/39808)
Epoch: 197 | Batch_idx: 320 |  Loss: (0.0764) |  Loss2: (0.0000) | Acc: (97.00%) (40044/41088)
Epoch: 197 | Batch_idx: 330 |  Loss: (0.0762) |  Loss2: (0.0000) | Acc: (97.00%) (41294/42368)
Epoch: 197 | Batch_idx: 340 |  Loss: (0.0762) |  Loss2: (0.0000) | Acc: (97.00%) (42545/43648)
Epoch: 197 | Batch_idx: 350 |  Loss: (0.0765) |  Loss2: (0.0000) | Acc: (97.00%) (43790/44928)
Epoch: 197 | Batch_idx: 360 |  Loss: (0.0762) |  Loss2: (0.0000) | Acc: (97.00%) (45044/46208)
Epoch: 197 | Batch_idx: 370 |  Loss: (0.0761) |  Loss2: (0.0000) | Acc: (97.00%) (46294/47488)
Epoch: 197 | Batch_idx: 380 |  Loss: (0.0762) |  Loss2: (0.0000) | Acc: (97.00%) (47538/48768)
Epoch: 197 | Batch_idx: 390 |  Loss: (0.0762) |  Loss2: (0.0000) | Acc: (97.00%) (48736/50000)
# TEST : Loss: (0.3850) | Acc: (89.00%) (8909/10000)
percent tensor([0.5225, 0.5141, 0.5239, 0.5218, 0.5283, 0.5308, 0.5193, 0.5222, 0.5266,
        0.5163, 0.5247, 0.5198, 0.5155, 0.5211, 0.5214, 0.5195],
       device='cuda:0') torch.Size([16])
percent tensor([0.5024, 0.4955, 0.5019, 0.5028, 0.4995, 0.5028, 0.4969, 0.5024, 0.5061,
        0.4981, 0.5040, 0.4956, 0.4940, 0.5107, 0.4957, 0.5039],
       device='cuda:0') torch.Size([16])
percent tensor([0.5619, 0.5452, 0.5610, 0.5944, 0.5797, 0.5776, 0.5715, 0.5859, 0.5711,
        0.5458, 0.5467, 0.5514, 0.5095, 0.6360, 0.5553, 0.5801],
       device='cuda:0') torch.Size([16])
percent tensor([0.6178, 0.6466, 0.6193, 0.6146, 0.6051, 0.6240, 0.6299, 0.6072, 0.6525,
        0.6509, 0.6600, 0.6321, 0.6462, 0.6607, 0.6131, 0.6372],
       device='cuda:0') torch.Size([16])
percent tensor([0.6196, 0.7113, 0.5407, 0.6263, 0.5677, 0.6685, 0.6473, 0.4213, 0.7200,
        0.6851, 0.7591, 0.6119, 0.6766, 0.7424, 0.5844, 0.6540],
       device='cuda:0') torch.Size([16])
percent tensor([0.6640, 0.6690, 0.6730, 0.6635, 0.7140, 0.6751, 0.6781, 0.6909, 0.6773,
        0.6649, 0.6348, 0.6183, 0.6382, 0.6580, 0.6503, 0.6777],
       device='cuda:0') torch.Size([16])
percent tensor([0.5956, 0.6298, 0.7657, 0.6695, 0.7574, 0.7846, 0.6329, 0.6566, 0.6891,
        0.6004, 0.7079, 0.6095, 0.6919, 0.6227, 0.6020, 0.5184],
       device='cuda:0') torch.Size([16])
percent tensor([0.9998, 0.9996, 0.9998, 0.9996, 0.9997, 0.9996, 0.9997, 0.9997, 0.9998,
        0.9997, 0.9999, 0.9998, 0.9999, 0.9994, 0.9996, 0.9995],
       device='cuda:0') torch.Size([16])
True Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=128, out_features=16, bias=False)
False Linear(in_features=16, out_features=2, bias=False)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=128, out_features=16, bias=False)
False Linear(in_features=16, out_features=2, bias=False)
True Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=256, out_features=32, bias=False)
False Linear(in_features=32, out_features=2, bias=False)
True Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=256, out_features=32, bias=False)
False Linear(in_features=32, out_features=2, bias=False)
True Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=512, out_features=64, bias=False)
False Linear(in_features=64, out_features=2, bias=False)
True Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=512, out_features=64, bias=False)
False Linear(in_features=64, out_features=2, bias=False)
True Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1024, out_features=128, bias=False)
False Linear(in_features=128, out_features=2, bias=False)
True Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1024, out_features=128, bias=False)
False Linear(in_features=128, out_features=2, bias=False)
True Linear(in_features=512, out_features=10, bias=True)
Epoch: 198 | Batch_idx: 0 |  Loss: (0.1098) |  Loss2: (0.0000) | Acc: (94.00%) (121/128)
Epoch: 198 | Batch_idx: 10 |  Loss: (0.0848) |  Loss2: (0.0000) | Acc: (97.00%) (1367/1408)
Epoch: 198 | Batch_idx: 20 |  Loss: (0.0849) |  Loss2: (0.0000) | Acc: (96.00%) (2606/2688)
Epoch: 198 | Batch_idx: 30 |  Loss: (0.0919) |  Loss2: (0.0000) | Acc: (96.00%) (3842/3968)
Epoch: 198 | Batch_idx: 40 |  Loss: (0.0897) |  Loss2: (0.0000) | Acc: (96.00%) (5086/5248)
Epoch: 198 | Batch_idx: 50 |  Loss: (0.0876) |  Loss2: (0.0000) | Acc: (97.00%) (6336/6528)
Epoch: 198 | Batch_idx: 60 |  Loss: (0.0850) |  Loss2: (0.0000) | Acc: (97.00%) (7594/7808)
Epoch: 198 | Batch_idx: 70 |  Loss: (0.0887) |  Loss2: (0.0000) | Acc: (97.00%) (8827/9088)
Epoch: 198 | Batch_idx: 80 |  Loss: (0.0890) |  Loss2: (0.0000) | Acc: (97.00%) (10071/10368)
Epoch: 198 | Batch_idx: 90 |  Loss: (0.0917) |  Loss2: (0.0000) | Acc: (97.00%) (11301/11648)
Epoch: 198 | Batch_idx: 100 |  Loss: (0.0923) |  Loss2: (0.0000) | Acc: (96.00%) (12540/12928)
Epoch: 198 | Batch_idx: 110 |  Loss: (0.0926) |  Loss2: (0.0000) | Acc: (96.00%) (13775/14208)
Epoch: 198 | Batch_idx: 120 |  Loss: (0.0923) |  Loss2: (0.0000) | Acc: (96.00%) (15018/15488)
Epoch: 198 | Batch_idx: 130 |  Loss: (0.0929) |  Loss2: (0.0000) | Acc: (96.00%) (16255/16768)
Epoch: 198 | Batch_idx: 140 |  Loss: (0.0930) |  Loss2: (0.0000) | Acc: (96.00%) (17489/18048)
Epoch: 198 | Batch_idx: 150 |  Loss: (0.0938) |  Loss2: (0.0000) | Acc: (96.00%) (18722/19328)
Epoch: 198 | Batch_idx: 160 |  Loss: (0.0930) |  Loss2: (0.0000) | Acc: (96.00%) (19968/20608)
Epoch: 198 | Batch_idx: 170 |  Loss: (0.0932) |  Loss2: (0.0000) | Acc: (96.00%) (21208/21888)
Epoch: 198 | Batch_idx: 180 |  Loss: (0.0925) |  Loss2: (0.0000) | Acc: (96.00%) (22464/23168)
Epoch: 198 | Batch_idx: 190 |  Loss: (0.0933) |  Loss2: (0.0000) | Acc: (96.00%) (23701/24448)
Epoch: 198 | Batch_idx: 200 |  Loss: (0.0929) |  Loss2: (0.0000) | Acc: (96.00%) (24940/25728)
Epoch: 198 | Batch_idx: 210 |  Loss: (0.0926) |  Loss2: (0.0000) | Acc: (96.00%) (26180/27008)
Epoch: 198 | Batch_idx: 220 |  Loss: (0.0926) |  Loss2: (0.0000) | Acc: (96.00%) (27413/28288)
Epoch: 198 | Batch_idx: 230 |  Loss: (0.0919) |  Loss2: (0.0000) | Acc: (96.00%) (28663/29568)
Epoch: 198 | Batch_idx: 240 |  Loss: (0.0924) |  Loss2: (0.0000) | Acc: (96.00%) (29899/30848)
Epoch: 198 | Batch_idx: 250 |  Loss: (0.0917) |  Loss2: (0.0000) | Acc: (96.00%) (31152/32128)
Epoch: 198 | Batch_idx: 260 |  Loss: (0.0919) |  Loss2: (0.0000) | Acc: (96.00%) (32391/33408)
Epoch: 198 | Batch_idx: 270 |  Loss: (0.0919) |  Loss2: (0.0000) | Acc: (96.00%) (33628/34688)
Epoch: 198 | Batch_idx: 280 |  Loss: (0.0921) |  Loss2: (0.0000) | Acc: (96.00%) (34868/35968)
Epoch: 198 | Batch_idx: 290 |  Loss: (0.0919) |  Loss2: (0.0000) | Acc: (96.00%) (36105/37248)
Epoch: 198 | Batch_idx: 300 |  Loss: (0.0915) |  Loss2: (0.0000) | Acc: (96.00%) (37351/38528)
Epoch: 198 | Batch_idx: 310 |  Loss: (0.0918) |  Loss2: (0.0000) | Acc: (96.00%) (38583/39808)
Epoch: 198 | Batch_idx: 320 |  Loss: (0.0917) |  Loss2: (0.0000) | Acc: (96.00%) (39832/41088)
Epoch: 198 | Batch_idx: 330 |  Loss: (0.0916) |  Loss2: (0.0000) | Acc: (96.00%) (41070/42368)
Epoch: 198 | Batch_idx: 340 |  Loss: (0.0916) |  Loss2: (0.0000) | Acc: (96.00%) (42309/43648)
Epoch: 198 | Batch_idx: 350 |  Loss: (0.0921) |  Loss2: (0.0000) | Acc: (96.00%) (43543/44928)
Epoch: 198 | Batch_idx: 360 |  Loss: (0.0921) |  Loss2: (0.0000) | Acc: (96.00%) (44784/46208)
Epoch: 198 | Batch_idx: 370 |  Loss: (0.0923) |  Loss2: (0.0000) | Acc: (96.00%) (46019/47488)
Epoch: 198 | Batch_idx: 380 |  Loss: (0.0926) |  Loss2: (0.0000) | Acc: (96.00%) (47254/48768)
Epoch: 198 | Batch_idx: 390 |  Loss: (0.0923) |  Loss2: (0.0000) | Acc: (96.00%) (48455/50000)
# TEST : Loss: (0.4170) | Acc: (88.00%) (8860/10000)
percent tensor([0.5215, 0.5133, 0.5263, 0.5212, 0.5307, 0.5296, 0.5196, 0.5228, 0.5270,
        0.5159, 0.5242, 0.5216, 0.5145, 0.5198, 0.5203, 0.5186],
       device='cuda:0') torch.Size([16])
percent tensor([0.5017, 0.4950, 0.5036, 0.5035, 0.5001, 0.5023, 0.4978, 0.5033, 0.5052,
        0.4985, 0.5031, 0.4976, 0.4934, 0.5115, 0.4957, 0.5032],
       device='cuda:0') torch.Size([16])
percent tensor([0.5603, 0.5452, 0.5757, 0.5951, 0.5860, 0.5714, 0.5761, 0.5877, 0.5698,
        0.5526, 0.5500, 0.5634, 0.5091, 0.6329, 0.5527, 0.5803],
       device='cuda:0') torch.Size([16])
percent tensor([0.6168, 0.6472, 0.6220, 0.6126, 0.6114, 0.6183, 0.6353, 0.6084, 0.6530,
        0.6533, 0.6586, 0.6403, 0.6514, 0.6630, 0.6103, 0.6339],
       device='cuda:0') torch.Size([16])
percent tensor([0.6267, 0.7070, 0.5279, 0.6095, 0.5559, 0.6796, 0.6549, 0.4149, 0.7244,
        0.6897, 0.7548, 0.6133, 0.7043, 0.7282, 0.5931, 0.6472],
       device='cuda:0') torch.Size([16])
percent tensor([0.6641, 0.6693, 0.6689, 0.6558, 0.7189, 0.6801, 0.6846, 0.6864, 0.6683,
        0.6645, 0.6352, 0.6218, 0.6339, 0.6548, 0.6425, 0.6777],
       device='cuda:0') torch.Size([16])
percent tensor([0.6061, 0.6290, 0.7252, 0.6597, 0.7475, 0.8080, 0.6323, 0.6461, 0.6721,
        0.5997, 0.7062, 0.6106, 0.6833, 0.6361, 0.6053, 0.5423],
       device='cuda:0') torch.Size([16])
percent tensor([0.9998, 0.9995, 0.9996, 0.9997, 0.9997, 0.9997, 0.9997, 0.9996, 0.9996,
        0.9997, 0.9999, 0.9998, 0.9998, 0.9995, 0.9995, 0.9996],
       device='cuda:0') torch.Size([16])
Epoch: 199 | Batch_idx: 0 |  Loss: (0.0610) |  Loss2: (0.0000) | Acc: (97.00%) (125/128)
Epoch: 199 | Batch_idx: 10 |  Loss: (0.0808) |  Loss2: (0.0000) | Acc: (96.00%) (1365/1408)
Epoch: 199 | Batch_idx: 20 |  Loss: (0.0833) |  Loss2: (0.0000) | Acc: (96.00%) (2604/2688)
Epoch: 199 | Batch_idx: 30 |  Loss: (0.0804) |  Loss2: (0.0000) | Acc: (97.00%) (3849/3968)
Epoch: 199 | Batch_idx: 40 |  Loss: (0.0787) |  Loss2: (0.0000) | Acc: (97.00%) (5098/5248)
Epoch: 199 | Batch_idx: 50 |  Loss: (0.0788) |  Loss2: (0.0000) | Acc: (97.00%) (6352/6528)
Epoch: 199 | Batch_idx: 60 |  Loss: (0.0818) |  Loss2: (0.0000) | Acc: (97.00%) (7594/7808)
Epoch: 199 | Batch_idx: 70 |  Loss: (0.0828) |  Loss2: (0.0000) | Acc: (97.00%) (8835/9088)
Epoch: 199 | Batch_idx: 80 |  Loss: (0.0828) |  Loss2: (0.0000) | Acc: (97.00%) (10074/10368)
Epoch: 199 | Batch_idx: 90 |  Loss: (0.0832) |  Loss2: (0.0000) | Acc: (97.00%) (11319/11648)
Epoch: 199 | Batch_idx: 100 |  Loss: (0.0822) |  Loss2: (0.0000) | Acc: (97.00%) (12568/12928)
Epoch: 199 | Batch_idx: 110 |  Loss: (0.0817) |  Loss2: (0.0000) | Acc: (97.00%) (13815/14208)
Epoch: 199 | Batch_idx: 120 |  Loss: (0.0809) |  Loss2: (0.0000) | Acc: (97.00%) (15065/15488)
Epoch: 199 | Batch_idx: 130 |  Loss: (0.0800) |  Loss2: (0.0000) | Acc: (97.00%) (16315/16768)
Epoch: 199 | Batch_idx: 140 |  Loss: (0.0810) |  Loss2: (0.0000) | Acc: (97.00%) (17556/18048)
Epoch: 199 | Batch_idx: 150 |  Loss: (0.0808) |  Loss2: (0.0000) | Acc: (97.00%) (18798/19328)
Epoch: 199 | Batch_idx: 160 |  Loss: (0.0808) |  Loss2: (0.0000) | Acc: (97.00%) (20041/20608)
Epoch: 199 | Batch_idx: 170 |  Loss: (0.0807) |  Loss2: (0.0000) | Acc: (97.00%) (21287/21888)
Epoch: 199 | Batch_idx: 180 |  Loss: (0.0803) |  Loss2: (0.0000) | Acc: (97.00%) (22535/23168)
Epoch: 199 | Batch_idx: 190 |  Loss: (0.0798) |  Loss2: (0.0000) | Acc: (97.00%) (23787/24448)
Epoch: 199 | Batch_idx: 200 |  Loss: (0.0806) |  Loss2: (0.0000) | Acc: (97.00%) (25022/25728)
Epoch: 199 | Batch_idx: 210 |  Loss: (0.0808) |  Loss2: (0.0000) | Acc: (97.00%) (26262/27008)
Epoch: 199 | Batch_idx: 220 |  Loss: (0.0812) |  Loss2: (0.0000) | Acc: (97.00%) (27504/28288)
Epoch: 199 | Batch_idx: 230 |  Loss: (0.0819) |  Loss2: (0.0000) | Acc: (97.00%) (28738/29568)
Epoch: 199 | Batch_idx: 240 |  Loss: (0.0816) |  Loss2: (0.0000) | Acc: (97.00%) (29985/30848)
Epoch: 199 | Batch_idx: 250 |  Loss: (0.0818) |  Loss2: (0.0000) | Acc: (97.00%) (31228/32128)
Epoch: 199 | Batch_idx: 260 |  Loss: (0.0823) |  Loss2: (0.0000) | Acc: (97.00%) (32467/33408)
Epoch: 199 | Batch_idx: 270 |  Loss: (0.0828) |  Loss2: (0.0000) | Acc: (97.00%) (33701/34688)
Epoch: 199 | Batch_idx: 280 |  Loss: (0.0833) |  Loss2: (0.0000) | Acc: (97.00%) (34939/35968)
Epoch: 199 | Batch_idx: 290 |  Loss: (0.0833) |  Loss2: (0.0000) | Acc: (97.00%) (36178/37248)
Epoch: 199 | Batch_idx: 300 |  Loss: (0.0837) |  Loss2: (0.0000) | Acc: (97.00%) (37414/38528)
Epoch: 199 | Batch_idx: 310 |  Loss: (0.0841) |  Loss2: (0.0000) | Acc: (97.00%) (38645/39808)
Epoch: 199 | Batch_idx: 320 |  Loss: (0.0838) |  Loss2: (0.0000) | Acc: (97.00%) (39894/41088)
Epoch: 199 | Batch_idx: 330 |  Loss: (0.0846) |  Loss2: (0.0000) | Acc: (97.00%) (41129/42368)
Epoch: 199 | Batch_idx: 340 |  Loss: (0.0853) |  Loss2: (0.0000) | Acc: (97.00%) (42358/43648)
Epoch: 199 | Batch_idx: 350 |  Loss: (0.0855) |  Loss2: (0.0000) | Acc: (97.00%) (43597/44928)
Epoch: 199 | Batch_idx: 360 |  Loss: (0.0855) |  Loss2: (0.0000) | Acc: (97.00%) (44832/46208)
Epoch: 199 | Batch_idx: 370 |  Loss: (0.0857) |  Loss2: (0.0000) | Acc: (97.00%) (46072/47488)
Epoch: 199 | Batch_idx: 380 |  Loss: (0.0859) |  Loss2: (0.0000) | Acc: (97.00%) (47309/48768)
Epoch: 199 | Batch_idx: 390 |  Loss: (0.0858) |  Loss2: (0.0000) | Acc: (97.00%) (48509/50000)
# TEST : Loss: (0.4256) | Acc: (88.00%) (8857/10000)
percent tensor([0.5212, 0.5137, 0.5236, 0.5194, 0.5282, 0.5284, 0.5194, 0.5217, 0.5273,
        0.5156, 0.5245, 0.5195, 0.5147, 0.5224, 0.5191, 0.5185],
       device='cuda:0') torch.Size([16])
percent tensor([0.5015, 0.4953, 0.5011, 0.5029, 0.4991, 0.5024, 0.4971, 0.5033, 0.5056,
        0.4976, 0.5040, 0.4954, 0.4939, 0.5115, 0.4956, 0.5035],
       device='cuda:0') torch.Size([16])
percent tensor([0.5652, 0.5389, 0.5794, 0.5920, 0.5870, 0.5725, 0.5747, 0.5864, 0.5689,
        0.5486, 0.5521, 0.5656, 0.5103, 0.6232, 0.5525, 0.5800],
       device='cuda:0') torch.Size([16])
percent tensor([0.6194, 0.6428, 0.6253, 0.6167, 0.6122, 0.6254, 0.6311, 0.6056, 0.6515,
        0.6473, 0.6591, 0.6357, 0.6464, 0.6597, 0.6091, 0.6369],
       device='cuda:0') torch.Size([16])
percent tensor([0.6182, 0.6966, 0.5476, 0.6494, 0.5746, 0.6905, 0.6549, 0.4208, 0.7178,
        0.6672, 0.7426, 0.6157, 0.6868, 0.7185, 0.5910, 0.6525],
       device='cuda:0') torch.Size([16])
percent tensor([0.6688, 0.6694, 0.6661, 0.6561, 0.7154, 0.6663, 0.6793, 0.6811, 0.6731,
        0.6620, 0.6467, 0.6165, 0.6424, 0.6503, 0.6373, 0.6822],
       device='cuda:0') torch.Size([16])
percent tensor([0.5909, 0.6194, 0.7460, 0.6624, 0.7667, 0.7803, 0.6589, 0.6617, 0.6687,
        0.6136, 0.7334, 0.6409, 0.6828, 0.6081, 0.5731, 0.5330],
       device='cuda:0') torch.Size([16])
percent tensor([0.9999, 0.9996, 0.9998, 0.9998, 0.9996, 0.9999, 0.9997, 0.9996, 0.9997,
        0.9997, 1.0000, 0.9999, 0.9999, 0.9993, 0.9996, 0.9994],
       device='cuda:0') torch.Size([16])
Epoch: 200 | Batch_idx: 0 |  Loss: (0.0643) |  Loss2: (0.0000) | Acc: (96.00%) (124/128)
Epoch: 200 | Batch_idx: 10 |  Loss: (0.0898) |  Loss2: (0.0000) | Acc: (96.00%) (1360/1408)
Epoch: 200 | Batch_idx: 20 |  Loss: (0.0831) |  Loss2: (0.0000) | Acc: (96.00%) (2606/2688)
Epoch: 200 | Batch_idx: 30 |  Loss: (0.0865) |  Loss2: (0.0000) | Acc: (96.00%) (3841/3968)
Epoch: 200 | Batch_idx: 40 |  Loss: (0.0854) |  Loss2: (0.0000) | Acc: (96.00%) (5088/5248)
Epoch: 200 | Batch_idx: 50 |  Loss: (0.0858) |  Loss2: (0.0000) | Acc: (96.00%) (6331/6528)
Epoch: 200 | Batch_idx: 60 |  Loss: (0.0840) |  Loss2: (0.0000) | Acc: (97.00%) (7581/7808)
Epoch: 200 | Batch_idx: 70 |  Loss: (0.0845) |  Loss2: (0.0000) | Acc: (97.00%) (8817/9088)
Epoch: 200 | Batch_idx: 80 |  Loss: (0.0829) |  Loss2: (0.0000) | Acc: (97.00%) (10067/10368)
Epoch: 200 | Batch_idx: 90 |  Loss: (0.0826) |  Loss2: (0.0000) | Acc: (97.00%) (11314/11648)
Epoch: 200 | Batch_idx: 100 |  Loss: (0.0816) |  Loss2: (0.0000) | Acc: (97.00%) (12566/12928)
Epoch: 200 | Batch_idx: 110 |  Loss: (0.0816) |  Loss2: (0.0000) | Acc: (97.00%) (13814/14208)
Epoch: 200 | Batch_idx: 120 |  Loss: (0.0811) |  Loss2: (0.0000) | Acc: (97.00%) (15067/15488)
Epoch: 200 | Batch_idx: 130 |  Loss: (0.0813) |  Loss2: (0.0000) | Acc: (97.00%) (16302/16768)
Epoch: 200 | Batch_idx: 140 |  Loss: (0.0806) |  Loss2: (0.0000) | Acc: (97.00%) (17552/18048)
Epoch: 200 | Batch_idx: 150 |  Loss: (0.0802) |  Loss2: (0.0000) | Acc: (97.00%) (18805/19328)
Epoch: 200 | Batch_idx: 160 |  Loss: (0.0793) |  Loss2: (0.0000) | Acc: (97.00%) (20057/20608)
Epoch: 200 | Batch_idx: 170 |  Loss: (0.0795) |  Loss2: (0.0000) | Acc: (97.00%) (21300/21888)
Epoch: 200 | Batch_idx: 180 |  Loss: (0.0800) |  Loss2: (0.0000) | Acc: (97.00%) (22542/23168)
Epoch: 200 | Batch_idx: 190 |  Loss: (0.0801) |  Loss2: (0.0000) | Acc: (97.00%) (23787/24448)
Epoch: 200 | Batch_idx: 200 |  Loss: (0.0799) |  Loss2: (0.0000) | Acc: (97.00%) (25034/25728)
Epoch: 200 | Batch_idx: 210 |  Loss: (0.0806) |  Loss2: (0.0000) | Acc: (97.00%) (26268/27008)
Epoch: 200 | Batch_idx: 220 |  Loss: (0.0816) |  Loss2: (0.0000) | Acc: (97.00%) (27498/28288)
Epoch: 200 | Batch_idx: 230 |  Loss: (0.0814) |  Loss2: (0.0000) | Acc: (97.00%) (28748/29568)
Epoch: 200 | Batch_idx: 240 |  Loss: (0.0814) |  Loss2: (0.0000) | Acc: (97.00%) (29994/30848)
Epoch: 200 | Batch_idx: 250 |  Loss: (0.0825) |  Loss2: (0.0000) | Acc: (97.00%) (31228/32128)
Epoch: 200 | Batch_idx: 260 |  Loss: (0.0824) |  Loss2: (0.0000) | Acc: (97.00%) (32476/33408)
Epoch: 200 | Batch_idx: 270 |  Loss: (0.0834) |  Loss2: (0.0000) | Acc: (97.00%) (33709/34688)
Epoch: 200 | Batch_idx: 280 |  Loss: (0.0839) |  Loss2: (0.0000) | Acc: (97.00%) (34948/35968)
Epoch: 200 | Batch_idx: 290 |  Loss: (0.0840) |  Loss2: (0.0000) | Acc: (97.00%) (36194/37248)
Epoch: 200 | Batch_idx: 300 |  Loss: (0.0844) |  Loss2: (0.0000) | Acc: (97.00%) (37431/38528)
Epoch: 200 | Batch_idx: 310 |  Loss: (0.0844) |  Loss2: (0.0000) | Acc: (97.00%) (38681/39808)
Epoch: 200 | Batch_idx: 320 |  Loss: (0.0842) |  Loss2: (0.0000) | Acc: (97.00%) (39933/41088)
Epoch: 200 | Batch_idx: 330 |  Loss: (0.0844) |  Loss2: (0.0000) | Acc: (97.00%) (41177/42368)
Epoch: 200 | Batch_idx: 340 |  Loss: (0.0853) |  Loss2: (0.0000) | Acc: (97.00%) (42412/43648)
Epoch: 200 | Batch_idx: 350 |  Loss: (0.0851) |  Loss2: (0.0000) | Acc: (97.00%) (43662/44928)
Epoch: 200 | Batch_idx: 360 |  Loss: (0.0847) |  Loss2: (0.0000) | Acc: (97.00%) (44906/46208)
Epoch: 200 | Batch_idx: 370 |  Loss: (0.0848) |  Loss2: (0.0000) | Acc: (97.00%) (46149/47488)
Epoch: 200 | Batch_idx: 380 |  Loss: (0.0848) |  Loss2: (0.0000) | Acc: (97.00%) (47388/48768)
Epoch: 200 | Batch_idx: 390 |  Loss: (0.0851) |  Loss2: (0.0000) | Acc: (97.00%) (48579/50000)
=> saving checkpoint 'drive/app/torch/save_Schedule/checkpoint_200.pth.tar'
# TEST : Loss: (0.4476) | Acc: (87.00%) (8767/10000)
percent tensor([0.5219, 0.5134, 0.5259, 0.5204, 0.5298, 0.5287, 0.5196, 0.5226, 0.5269,
        0.5158, 0.5241, 0.5212, 0.5149, 0.5209, 0.5196, 0.5185],
       device='cuda:0') torch.Size([16])
percent tensor([0.5027, 0.4960, 0.5025, 0.5033, 0.5002, 0.5035, 0.4984, 0.5034, 0.5060,
        0.4990, 0.5047, 0.4972, 0.4952, 0.5109, 0.4968, 0.5042],
       device='cuda:0') torch.Size([16])
percent tensor([0.5643, 0.5469, 0.5812, 0.5982, 0.5902, 0.5739, 0.5816, 0.5877, 0.5689,
        0.5545, 0.5494, 0.5698, 0.5107, 0.6334, 0.5588, 0.5808],
       device='cuda:0') torch.Size([16])
percent tensor([0.6233, 0.6488, 0.6287, 0.6193, 0.6151, 0.6254, 0.6378, 0.6102, 0.6545,
        0.6549, 0.6647, 0.6439, 0.6530, 0.6655, 0.6147, 0.6408],
       device='cuda:0') torch.Size([16])
percent tensor([0.6206, 0.7029, 0.5384, 0.6245, 0.5554, 0.6702, 0.6597, 0.4229, 0.7304,
        0.6780, 0.7655, 0.6362, 0.6910, 0.7287, 0.5805, 0.6475],
       device='cuda:0') torch.Size([16])
percent tensor([0.6582, 0.6659, 0.6658, 0.6593, 0.7148, 0.6765, 0.6821, 0.6838, 0.6620,
        0.6531, 0.6233, 0.6204, 0.6341, 0.6533, 0.6440, 0.6836],
       device='cuda:0') torch.Size([16])
percent tensor([0.5724, 0.6114, 0.7237, 0.6550, 0.7577, 0.7788, 0.6151, 0.6262, 0.6418,
        0.5793, 0.6709, 0.6002, 0.6826, 0.5756, 0.5419, 0.5082],
       device='cuda:0') torch.Size([16])
percent tensor([0.9998, 0.9996, 0.9997, 0.9997, 0.9997, 0.9997, 0.9997, 0.9995, 0.9998,
        0.9997, 0.9999, 0.9998, 0.9999, 0.9991, 0.9997, 0.9993],
       device='cuda:0') torch.Size([16])
Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 3, 3, 3]) tensor(190.8052, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(837.0682, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(826.9224, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([128, 64, 3, 3]) tensor(1517.0503, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([128, 64, 1, 1]) tensor(472.5158, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([128, 128, 3, 3]) tensor(2314.1392, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([256, 128, 3, 3]) tensor(4242.8408, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([256, 128, 1, 1]) tensor(1340.0870, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([256, 256, 3, 3]) tensor(6234.8662, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([512, 256, 3, 3]) tensor(11507.9434, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([512, 256, 1, 1]) tensor(3788.6575, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([512, 512, 3, 3]) tensor(16003.4551, device='cuda:0', grad_fn=<NormBackward0>)
Epoch: 201 | Batch_idx: 0 |  Loss: (0.0659) |  Loss2: (0.0000) | Acc: (98.00%) (126/128)
Epoch: 201 | Batch_idx: 10 |  Loss: (0.0721) |  Loss2: (0.0000) | Acc: (97.00%) (1373/1408)
Epoch: 201 | Batch_idx: 20 |  Loss: (0.0729) |  Loss2: (0.0000) | Acc: (97.00%) (2618/2688)
Epoch: 201 | Batch_idx: 30 |  Loss: (0.0763) |  Loss2: (0.0000) | Acc: (97.00%) (3864/3968)
Epoch: 201 | Batch_idx: 40 |  Loss: (0.0790) |  Loss2: (0.0000) | Acc: (97.00%) (5105/5248)
Epoch: 201 | Batch_idx: 50 |  Loss: (0.0783) |  Loss2: (0.0000) | Acc: (97.00%) (6355/6528)
Epoch: 201 | Batch_idx: 60 |  Loss: (0.0788) |  Loss2: (0.0000) | Acc: (97.00%) (7601/7808)
Epoch: 201 | Batch_idx: 70 |  Loss: (0.0797) |  Loss2: (0.0000) | Acc: (97.00%) (8840/9088)
Epoch: 201 | Batch_idx: 80 |  Loss: (0.0784) |  Loss2: (0.0000) | Acc: (97.00%) (10096/10368)
Epoch: 201 | Batch_idx: 90 |  Loss: (0.0787) |  Loss2: (0.0000) | Acc: (97.00%) (11344/11648)
Epoch: 201 | Batch_idx: 100 |  Loss: (0.0776) |  Loss2: (0.0000) | Acc: (97.00%) (12597/12928)
Epoch: 201 | Batch_idx: 110 |  Loss: (0.0777) |  Loss2: (0.0000) | Acc: (97.00%) (13844/14208)
Epoch: 201 | Batch_idx: 120 |  Loss: (0.0776) |  Loss2: (0.0000) | Acc: (97.00%) (15093/15488)
Epoch: 201 | Batch_idx: 130 |  Loss: (0.0774) |  Loss2: (0.0000) | Acc: (97.00%) (16339/16768)
Epoch: 201 | Batch_idx: 140 |  Loss: (0.0765) |  Loss2: (0.0000) | Acc: (97.00%) (17591/18048)
Epoch: 201 | Batch_idx: 150 |  Loss: (0.0768) |  Loss2: (0.0000) | Acc: (97.00%) (18832/19328)
Epoch: 201 | Batch_idx: 160 |  Loss: (0.0768) |  Loss2: (0.0000) | Acc: (97.00%) (20080/20608)
Epoch: 201 | Batch_idx: 170 |  Loss: (0.0770) |  Loss2: (0.0000) | Acc: (97.00%) (21321/21888)
Epoch: 201 | Batch_idx: 180 |  Loss: (0.0766) |  Loss2: (0.0000) | Acc: (97.00%) (22574/23168)
Epoch: 201 | Batch_idx: 190 |  Loss: (0.0764) |  Loss2: (0.0000) | Acc: (97.00%) (23822/24448)
Epoch: 201 | Batch_idx: 200 |  Loss: (0.0764) |  Loss2: (0.0000) | Acc: (97.00%) (25071/25728)
Epoch: 201 | Batch_idx: 210 |  Loss: (0.0776) |  Loss2: (0.0000) | Acc: (97.00%) (26305/27008)
Epoch: 201 | Batch_idx: 220 |  Loss: (0.0777) |  Loss2: (0.0000) | Acc: (97.00%) (27553/28288)
Epoch: 201 | Batch_idx: 230 |  Loss: (0.0785) |  Loss2: (0.0000) | Acc: (97.00%) (28782/29568)
Epoch: 201 | Batch_idx: 240 |  Loss: (0.0792) |  Loss2: (0.0000) | Acc: (97.00%) (30017/30848)
Epoch: 201 | Batch_idx: 250 |  Loss: (0.0795) |  Loss2: (0.0000) | Acc: (97.00%) (31256/32128)
Epoch: 201 | Batch_idx: 260 |  Loss: (0.0794) |  Loss2: (0.0000) | Acc: (97.00%) (32507/33408)
Epoch: 201 | Batch_idx: 270 |  Loss: (0.0791) |  Loss2: (0.0000) | Acc: (97.00%) (33757/34688)
Epoch: 201 | Batch_idx: 280 |  Loss: (0.0799) |  Loss2: (0.0000) | Acc: (97.00%) (34992/35968)
Epoch: 201 | Batch_idx: 290 |  Loss: (0.0804) |  Loss2: (0.0000) | Acc: (97.00%) (36228/37248)
Epoch: 201 | Batch_idx: 300 |  Loss: (0.0807) |  Loss2: (0.0000) | Acc: (97.00%) (37467/38528)
Epoch: 201 | Batch_idx: 310 |  Loss: (0.0806) |  Loss2: (0.0000) | Acc: (97.00%) (38718/39808)
Epoch: 201 | Batch_idx: 320 |  Loss: (0.0800) |  Loss2: (0.0000) | Acc: (97.00%) (39970/41088)
Epoch: 201 | Batch_idx: 330 |  Loss: (0.0800) |  Loss2: (0.0000) | Acc: (97.00%) (41216/42368)
Epoch: 201 | Batch_idx: 340 |  Loss: (0.0801) |  Loss2: (0.0000) | Acc: (97.00%) (42457/43648)
Epoch: 201 | Batch_idx: 350 |  Loss: (0.0798) |  Loss2: (0.0000) | Acc: (97.00%) (43710/44928)
Epoch: 201 | Batch_idx: 360 |  Loss: (0.0796) |  Loss2: (0.0000) | Acc: (97.00%) (44962/46208)
Epoch: 201 | Batch_idx: 370 |  Loss: (0.0795) |  Loss2: (0.0000) | Acc: (97.00%) (46210/47488)
Epoch: 201 | Batch_idx: 380 |  Loss: (0.0794) |  Loss2: (0.0000) | Acc: (97.00%) (47460/48768)
Epoch: 201 | Batch_idx: 390 |  Loss: (0.0791) |  Loss2: (0.0000) | Acc: (97.00%) (48662/50000)
# TEST : Loss: (0.4140) | Acc: (88.00%) (8872/10000)
percent tensor([0.5237, 0.5147, 0.5271, 0.5209, 0.5322, 0.5308, 0.5214, 0.5229, 0.5284,
        0.5172, 0.5252, 0.5233, 0.5162, 0.5211, 0.5212, 0.5196],
       device='cuda:0') torch.Size([16])
percent tensor([0.5037, 0.4965, 0.5041, 0.5038, 0.5013, 0.5043, 0.4993, 0.5039, 0.5074,
        0.4998, 0.5053, 0.4985, 0.4961, 0.5107, 0.4979, 0.5044],
       device='cuda:0') torch.Size([16])
percent tensor([0.5678, 0.5466, 0.5736, 0.5928, 0.5868, 0.5804, 0.5776, 0.5854, 0.5740,
        0.5506, 0.5554, 0.5631, 0.5147, 0.6259, 0.5571, 0.5809],
       device='cuda:0') torch.Size([16])
percent tensor([0.6225, 0.6457, 0.6329, 0.6242, 0.6197, 0.6264, 0.6397, 0.6156, 0.6537,
        0.6541, 0.6618, 0.6477, 0.6496, 0.6626, 0.6171, 0.6387],
       device='cuda:0') torch.Size([16])
percent tensor([0.6126, 0.6922, 0.5633, 0.6403, 0.5605, 0.6610, 0.6536, 0.4263, 0.7262,
        0.6773, 0.7617, 0.6367, 0.6789, 0.7425, 0.5658, 0.6369],
       device='cuda:0') torch.Size([16])
percent tensor([0.6681, 0.6740, 0.6768, 0.6655, 0.7220, 0.6803, 0.6833, 0.6923, 0.6803,
        0.6673, 0.6427, 0.6248, 0.6497, 0.6536, 0.6472, 0.6855],
       device='cuda:0') torch.Size([16])
percent tensor([0.5678, 0.6036, 0.7467, 0.6728, 0.7710, 0.7860, 0.6120, 0.6658, 0.6663,
        0.5899, 0.6745, 0.6195, 0.6733, 0.5720, 0.5717, 0.5332],
       device='cuda:0') torch.Size([16])
percent tensor([0.9998, 0.9997, 0.9997, 0.9998, 0.9998, 0.9998, 0.9996, 0.9996, 0.9997,
        0.9997, 1.0000, 0.9998, 0.9999, 0.9995, 0.9997, 0.9995],
       device='cuda:0') torch.Size([16])
Epoch: 202 | Batch_idx: 0 |  Loss: (0.0636) |  Loss2: (0.0000) | Acc: (97.00%) (125/128)
Epoch: 202 | Batch_idx: 10 |  Loss: (0.0643) |  Loss2: (0.0000) | Acc: (98.00%) (1382/1408)
Epoch: 202 | Batch_idx: 20 |  Loss: (0.0736) |  Loss2: (0.0000) | Acc: (97.00%) (2627/2688)
Epoch: 202 | Batch_idx: 30 |  Loss: (0.0730) |  Loss2: (0.0000) | Acc: (97.00%) (3877/3968)
Epoch: 202 | Batch_idx: 40 |  Loss: (0.0743) |  Loss2: (0.0000) | Acc: (97.00%) (5123/5248)
Epoch: 202 | Batch_idx: 50 |  Loss: (0.0779) |  Loss2: (0.0000) | Acc: (97.00%) (6359/6528)
Epoch: 202 | Batch_idx: 60 |  Loss: (0.0781) |  Loss2: (0.0000) | Acc: (97.00%) (7608/7808)
Epoch: 202 | Batch_idx: 70 |  Loss: (0.0779) |  Loss2: (0.0000) | Acc: (97.00%) (8849/9088)
Epoch: 202 | Batch_idx: 80 |  Loss: (0.0772) |  Loss2: (0.0000) | Acc: (97.00%) (10100/10368)
Epoch: 202 | Batch_idx: 90 |  Loss: (0.0763) |  Loss2: (0.0000) | Acc: (97.00%) (11354/11648)
Epoch: 202 | Batch_idx: 100 |  Loss: (0.0770) |  Loss2: (0.0000) | Acc: (97.00%) (12604/12928)
Epoch: 202 | Batch_idx: 110 |  Loss: (0.0762) |  Loss2: (0.0000) | Acc: (97.00%) (13849/14208)
Epoch: 202 | Batch_idx: 120 |  Loss: (0.0755) |  Loss2: (0.0000) | Acc: (97.00%) (15101/15488)
Epoch: 202 | Batch_idx: 130 |  Loss: (0.0767) |  Loss2: (0.0000) | Acc: (97.00%) (16344/16768)
Epoch: 202 | Batch_idx: 140 |  Loss: (0.0763) |  Loss2: (0.0000) | Acc: (97.00%) (17590/18048)
Epoch: 202 | Batch_idx: 150 |  Loss: (0.0760) |  Loss2: (0.0000) | Acc: (97.00%) (18844/19328)
Epoch: 202 | Batch_idx: 160 |  Loss: (0.0761) |  Loss2: (0.0000) | Acc: (97.00%) (20092/20608)
Epoch: 202 | Batch_idx: 170 |  Loss: (0.0757) |  Loss2: (0.0000) | Acc: (97.00%) (21336/21888)
Epoch: 202 | Batch_idx: 180 |  Loss: (0.0761) |  Loss2: (0.0000) | Acc: (97.00%) (22583/23168)
Epoch: 202 | Batch_idx: 190 |  Loss: (0.0769) |  Loss2: (0.0000) | Acc: (97.00%) (23818/24448)
Epoch: 202 | Batch_idx: 200 |  Loss: (0.0783) |  Loss2: (0.0000) | Acc: (97.00%) (25054/25728)
Epoch: 202 | Batch_idx: 210 |  Loss: (0.0786) |  Loss2: (0.0000) | Acc: (97.00%) (26299/27008)
Epoch: 202 | Batch_idx: 220 |  Loss: (0.0791) |  Loss2: (0.0000) | Acc: (97.00%) (27538/28288)
Epoch: 202 | Batch_idx: 230 |  Loss: (0.0794) |  Loss2: (0.0000) | Acc: (97.00%) (28776/29568)
Epoch: 202 | Batch_idx: 240 |  Loss: (0.0801) |  Loss2: (0.0000) | Acc: (97.00%) (30006/30848)
Epoch: 202 | Batch_idx: 250 |  Loss: (0.0802) |  Loss2: (0.0000) | Acc: (97.00%) (31255/32128)
Epoch: 202 | Batch_idx: 260 |  Loss: (0.0805) |  Loss2: (0.0000) | Acc: (97.00%) (32500/33408)
Epoch: 202 | Batch_idx: 270 |  Loss: (0.0804) |  Loss2: (0.0000) | Acc: (97.00%) (33749/34688)
Epoch: 202 | Batch_idx: 280 |  Loss: (0.0809) |  Loss2: (0.0000) | Acc: (97.00%) (34988/35968)
Epoch: 202 | Batch_idx: 290 |  Loss: (0.0809) |  Loss2: (0.0000) | Acc: (97.00%) (36235/37248)
Epoch: 202 | Batch_idx: 300 |  Loss: (0.0807) |  Loss2: (0.0000) | Acc: (97.00%) (37480/38528)
Epoch: 202 | Batch_idx: 310 |  Loss: (0.0805) |  Loss2: (0.0000) | Acc: (97.00%) (38733/39808)
Epoch: 202 | Batch_idx: 320 |  Loss: (0.0803) |  Loss2: (0.0000) | Acc: (97.00%) (39978/41088)
Epoch: 202 | Batch_idx: 330 |  Loss: (0.0807) |  Loss2: (0.0000) | Acc: (97.00%) (41216/42368)
Epoch: 202 | Batch_idx: 340 |  Loss: (0.0808) |  Loss2: (0.0000) | Acc: (97.00%) (42458/43648)
Epoch: 202 | Batch_idx: 350 |  Loss: (0.0813) |  Loss2: (0.0000) | Acc: (97.00%) (43691/44928)
Epoch: 202 | Batch_idx: 360 |  Loss: (0.0815) |  Loss2: (0.0000) | Acc: (97.00%) (44937/46208)
Epoch: 202 | Batch_idx: 370 |  Loss: (0.0815) |  Loss2: (0.0000) | Acc: (97.00%) (46177/47488)
Epoch: 202 | Batch_idx: 380 |  Loss: (0.0817) |  Loss2: (0.0000) | Acc: (97.00%) (47415/48768)
Epoch: 202 | Batch_idx: 390 |  Loss: (0.0817) |  Loss2: (0.0000) | Acc: (97.00%) (48612/50000)
# TEST : Loss: (0.4158) | Acc: (88.00%) (8842/10000)
percent tensor([0.5236, 0.5155, 0.5275, 0.5216, 0.5316, 0.5300, 0.5214, 0.5240, 0.5280,
        0.5176, 0.5253, 0.5227, 0.5160, 0.5225, 0.5211, 0.5204],
       device='cuda:0') torch.Size([16])
percent tensor([0.5035, 0.4965, 0.5041, 0.5039, 0.5014, 0.5045, 0.4994, 0.5040, 0.5070,
        0.4995, 0.5051, 0.4982, 0.4956, 0.5104, 0.4980, 0.5046],
       device='cuda:0') torch.Size([16])
percent tensor([0.5689, 0.5441, 0.5755, 0.5958, 0.5868, 0.5792, 0.5759, 0.5861, 0.5774,
        0.5518, 0.5589, 0.5633, 0.5168, 0.6214, 0.5587, 0.5812],
       device='cuda:0') torch.Size([16])
percent tensor([0.6262, 0.6522, 0.6250, 0.6262, 0.6160, 0.6311, 0.6444, 0.6146, 0.6568,
        0.6586, 0.6666, 0.6456, 0.6536, 0.6747, 0.6224, 0.6460],
       device='cuda:0') torch.Size([16])
percent tensor([0.6291, 0.7063, 0.5673, 0.6619, 0.5748, 0.6672, 0.6676, 0.4227, 0.7306,
        0.6855, 0.7493, 0.6416, 0.6979, 0.7323, 0.5832, 0.6571],
       device='cuda:0') torch.Size([16])
percent tensor([0.6757, 0.6813, 0.6810, 0.6756, 0.7260, 0.6847, 0.6957, 0.7013, 0.6941,
        0.6742, 0.6578, 0.6315, 0.6503, 0.6663, 0.6590, 0.6911],
       device='cuda:0') torch.Size([16])
percent tensor([0.5769, 0.6301, 0.7561, 0.6625, 0.7607, 0.7644, 0.6376, 0.6574, 0.6804,
        0.6082, 0.7378, 0.6323, 0.6601, 0.6463, 0.5789, 0.5175],
       device='cuda:0') torch.Size([16])
percent tensor([0.9997, 0.9996, 0.9997, 0.9998, 0.9997, 0.9997, 0.9995, 0.9995, 0.9998,
        0.9996, 0.9999, 0.9998, 0.9999, 0.9993, 0.9997, 0.9993],
       device='cuda:0') torch.Size([16])
Epoch: 203 | Batch_idx: 0 |  Loss: (0.0790) |  Loss2: (0.0000) | Acc: (96.00%) (123/128)
Epoch: 203 | Batch_idx: 10 |  Loss: (0.0715) |  Loss2: (0.0000) | Acc: (97.00%) (1374/1408)
Epoch: 203 | Batch_idx: 20 |  Loss: (0.0751) |  Loss2: (0.0000) | Acc: (97.00%) (2621/2688)
Epoch: 203 | Batch_idx: 30 |  Loss: (0.0749) |  Loss2: (0.0000) | Acc: (97.00%) (3868/3968)
Epoch: 203 | Batch_idx: 40 |  Loss: (0.0727) |  Loss2: (0.0000) | Acc: (97.00%) (5121/5248)
Epoch: 203 | Batch_idx: 50 |  Loss: (0.0733) |  Loss2: (0.0000) | Acc: (97.00%) (6372/6528)
Epoch: 203 | Batch_idx: 60 |  Loss: (0.0727) |  Loss2: (0.0000) | Acc: (97.00%) (7624/7808)
Epoch: 203 | Batch_idx: 70 |  Loss: (0.0719) |  Loss2: (0.0000) | Acc: (97.00%) (8882/9088)
Epoch: 203 | Batch_idx: 80 |  Loss: (0.0714) |  Loss2: (0.0000) | Acc: (97.00%) (10135/10368)
Epoch: 203 | Batch_idx: 90 |  Loss: (0.0727) |  Loss2: (0.0000) | Acc: (97.00%) (11372/11648)
Epoch: 203 | Batch_idx: 100 |  Loss: (0.0718) |  Loss2: (0.0000) | Acc: (97.00%) (12626/12928)
Epoch: 203 | Batch_idx: 110 |  Loss: (0.0713) |  Loss2: (0.0000) | Acc: (97.00%) (13882/14208)
Epoch: 203 | Batch_idx: 120 |  Loss: (0.0718) |  Loss2: (0.0000) | Acc: (97.00%) (15126/15488)
Epoch: 203 | Batch_idx: 130 |  Loss: (0.0710) |  Loss2: (0.0000) | Acc: (97.00%) (16376/16768)
Epoch: 203 | Batch_idx: 140 |  Loss: (0.0705) |  Loss2: (0.0000) | Acc: (97.00%) (17632/18048)
Epoch: 203 | Batch_idx: 150 |  Loss: (0.0712) |  Loss2: (0.0000) | Acc: (97.00%) (18874/19328)
Epoch: 203 | Batch_idx: 160 |  Loss: (0.0706) |  Loss2: (0.0000) | Acc: (97.00%) (20129/20608)
Epoch: 203 | Batch_idx: 170 |  Loss: (0.0714) |  Loss2: (0.0000) | Acc: (97.00%) (21372/21888)
Epoch: 203 | Batch_idx: 180 |  Loss: (0.0718) |  Loss2: (0.0000) | Acc: (97.00%) (22620/23168)
Epoch: 203 | Batch_idx: 190 |  Loss: (0.0709) |  Loss2: (0.0000) | Acc: (97.00%) (23881/24448)
Epoch: 203 | Batch_idx: 200 |  Loss: (0.0715) |  Loss2: (0.0000) | Acc: (97.00%) (25122/25728)
Epoch: 203 | Batch_idx: 210 |  Loss: (0.0720) |  Loss2: (0.0000) | Acc: (97.00%) (26363/27008)
Epoch: 203 | Batch_idx: 220 |  Loss: (0.0727) |  Loss2: (0.0000) | Acc: (97.00%) (27604/28288)
Epoch: 203 | Batch_idx: 230 |  Loss: (0.0727) |  Loss2: (0.0000) | Acc: (97.00%) (28850/29568)
Epoch: 203 | Batch_idx: 240 |  Loss: (0.0733) |  Loss2: (0.0000) | Acc: (97.00%) (30094/30848)
Epoch: 203 | Batch_idx: 250 |  Loss: (0.0734) |  Loss2: (0.0000) | Acc: (97.00%) (31338/32128)
Epoch: 203 | Batch_idx: 260 |  Loss: (0.0740) |  Loss2: (0.0000) | Acc: (97.00%) (32574/33408)
Epoch: 203 | Batch_idx: 270 |  Loss: (0.0742) |  Loss2: (0.0000) | Acc: (97.00%) (33820/34688)
Epoch: 203 | Batch_idx: 280 |  Loss: (0.0747) |  Loss2: (0.0000) | Acc: (97.00%) (35062/35968)
Epoch: 203 | Batch_idx: 290 |  Loss: (0.0750) |  Loss2: (0.0000) | Acc: (97.00%) (36298/37248)
Epoch: 203 | Batch_idx: 300 |  Loss: (0.0747) |  Loss2: (0.0000) | Acc: (97.00%) (37552/38528)
Epoch: 203 | Batch_idx: 310 |  Loss: (0.0741) |  Loss2: (0.0000) | Acc: (97.00%) (38812/39808)
Epoch: 203 | Batch_idx: 320 |  Loss: (0.0736) |  Loss2: (0.0000) | Acc: (97.00%) (40070/41088)
Epoch: 203 | Batch_idx: 330 |  Loss: (0.0730) |  Loss2: (0.0000) | Acc: (97.00%) (41327/42368)
Epoch: 203 | Batch_idx: 340 |  Loss: (0.0732) |  Loss2: (0.0000) | Acc: (97.00%) (42572/43648)
Epoch: 203 | Batch_idx: 350 |  Loss: (0.0731) |  Loss2: (0.0000) | Acc: (97.00%) (43821/44928)
Epoch: 203 | Batch_idx: 360 |  Loss: (0.0737) |  Loss2: (0.0000) | Acc: (97.00%) (45062/46208)
Epoch: 203 | Batch_idx: 370 |  Loss: (0.0744) |  Loss2: (0.0000) | Acc: (97.00%) (46286/47488)
Epoch: 203 | Batch_idx: 380 |  Loss: (0.0745) |  Loss2: (0.0000) | Acc: (97.00%) (47537/48768)
Epoch: 203 | Batch_idx: 390 |  Loss: (0.0745) |  Loss2: (0.0000) | Acc: (97.00%) (48741/50000)
# TEST : Loss: (0.4122) | Acc: (88.00%) (8854/10000)
percent tensor([0.5245, 0.5172, 0.5282, 0.5218, 0.5326, 0.5315, 0.5239, 0.5261, 0.5309,
        0.5195, 0.5278, 0.5242, 0.5178, 0.5262, 0.5224, 0.5217],
       device='cuda:0') torch.Size([16])
percent tensor([0.5041, 0.4979, 0.5030, 0.5051, 0.5008, 0.5052, 0.4995, 0.5037, 0.5071,
        0.5002, 0.5062, 0.4977, 0.4964, 0.5129, 0.4989, 0.5060],
       device='cuda:0') torch.Size([16])
percent tensor([0.5742, 0.5500, 0.5745, 0.5962, 0.5910, 0.5852, 0.5837, 0.5789, 0.5777,
        0.5590, 0.5615, 0.5724, 0.5203, 0.6336, 0.5644, 0.5868],
       device='cuda:0') torch.Size([16])
percent tensor([0.6260, 0.6532, 0.6356, 0.6238, 0.6197, 0.6268, 0.6433, 0.6164, 0.6584,
        0.6631, 0.6679, 0.6512, 0.6544, 0.6723, 0.6192, 0.6441],
       device='cuda:0') torch.Size([16])
percent tensor([0.6211, 0.7207, 0.5424, 0.6354, 0.5533, 0.6627, 0.6593, 0.4360, 0.7279,
        0.7042, 0.7626, 0.6378, 0.7058, 0.7316, 0.5908, 0.6589],
       device='cuda:0') torch.Size([16])
percent tensor([0.6708, 0.6694, 0.6841, 0.6749, 0.7263, 0.6818, 0.6943, 0.7022, 0.6838,
        0.6633, 0.6433, 0.6361, 0.6487, 0.6543, 0.6467, 0.6907],
       device='cuda:0') torch.Size([16])
percent tensor([0.5568, 0.5982, 0.7475, 0.6331, 0.7587, 0.7672, 0.6018, 0.6649, 0.6333,
        0.5639, 0.7010, 0.5951, 0.6359, 0.5699, 0.5301, 0.4975],
       device='cuda:0') torch.Size([16])
percent tensor([0.9998, 0.9996, 0.9998, 0.9998, 0.9996, 0.9997, 0.9996, 0.9998, 0.9998,
        0.9997, 0.9999, 0.9998, 0.9999, 0.9990, 0.9997, 0.9993],
       device='cuda:0') torch.Size([16])
Epoch: 204 | Batch_idx: 0 |  Loss: (0.1041) |  Loss2: (0.0000) | Acc: (98.00%) (126/128)
Epoch: 204 | Batch_idx: 10 |  Loss: (0.0743) |  Loss2: (0.0000) | Acc: (97.00%) (1379/1408)
Epoch: 204 | Batch_idx: 20 |  Loss: (0.0665) |  Loss2: (0.0000) | Acc: (98.00%) (2641/2688)
Epoch: 204 | Batch_idx: 30 |  Loss: (0.0672) |  Loss2: (0.0000) | Acc: (98.00%) (3893/3968)
Epoch: 204 | Batch_idx: 40 |  Loss: (0.0678) |  Loss2: (0.0000) | Acc: (98.00%) (5145/5248)
Epoch: 204 | Batch_idx: 50 |  Loss: (0.0688) |  Loss2: (0.0000) | Acc: (97.00%) (6392/6528)
Epoch: 204 | Batch_idx: 60 |  Loss: (0.0694) |  Loss2: (0.0000) | Acc: (97.00%) (7639/7808)
Epoch: 204 | Batch_idx: 70 |  Loss: (0.0697) |  Loss2: (0.0000) | Acc: (97.00%) (8886/9088)
Epoch: 204 | Batch_idx: 80 |  Loss: (0.0696) |  Loss2: (0.0000) | Acc: (97.00%) (10141/10368)
Epoch: 204 | Batch_idx: 90 |  Loss: (0.0679) |  Loss2: (0.0000) | Acc: (97.00%) (11401/11648)
Epoch: 204 | Batch_idx: 100 |  Loss: (0.0684) |  Loss2: (0.0000) | Acc: (97.00%) (12651/12928)
Epoch: 204 | Batch_idx: 110 |  Loss: (0.0688) |  Loss2: (0.0000) | Acc: (97.00%) (13899/14208)
Epoch: 204 | Batch_idx: 120 |  Loss: (0.0687) |  Loss2: (0.0000) | Acc: (97.00%) (15152/15488)
Epoch: 204 | Batch_idx: 130 |  Loss: (0.0689) |  Loss2: (0.0000) | Acc: (97.00%) (16402/16768)
Epoch: 204 | Batch_idx: 140 |  Loss: (0.0692) |  Loss2: (0.0000) | Acc: (97.00%) (17652/18048)
Epoch: 204 | Batch_idx: 150 |  Loss: (0.0698) |  Loss2: (0.0000) | Acc: (97.00%) (18902/19328)
Epoch: 204 | Batch_idx: 160 |  Loss: (0.0699) |  Loss2: (0.0000) | Acc: (97.00%) (20156/20608)
Epoch: 204 | Batch_idx: 170 |  Loss: (0.0703) |  Loss2: (0.0000) | Acc: (97.00%) (21410/21888)
Epoch: 204 | Batch_idx: 180 |  Loss: (0.0718) |  Loss2: (0.0000) | Acc: (97.00%) (22646/23168)
Epoch: 204 | Batch_idx: 190 |  Loss: (0.0720) |  Loss2: (0.0000) | Acc: (97.00%) (23892/24448)
Epoch: 204 | Batch_idx: 200 |  Loss: (0.0716) |  Loss2: (0.0000) | Acc: (97.00%) (25152/25728)
Epoch: 204 | Batch_idx: 210 |  Loss: (0.0716) |  Loss2: (0.0000) | Acc: (97.00%) (26401/27008)
Epoch: 204 | Batch_idx: 220 |  Loss: (0.0708) |  Loss2: (0.0000) | Acc: (97.00%) (27658/28288)
Epoch: 204 | Batch_idx: 230 |  Loss: (0.0714) |  Loss2: (0.0000) | Acc: (97.00%) (28899/29568)
Epoch: 204 | Batch_idx: 240 |  Loss: (0.0716) |  Loss2: (0.0000) | Acc: (97.00%) (30148/30848)
Epoch: 204 | Batch_idx: 250 |  Loss: (0.0715) |  Loss2: (0.0000) | Acc: (97.00%) (31400/32128)
Epoch: 204 | Batch_idx: 260 |  Loss: (0.0719) |  Loss2: (0.0000) | Acc: (97.00%) (32644/33408)
Epoch: 204 | Batch_idx: 270 |  Loss: (0.0717) |  Loss2: (0.0000) | Acc: (97.00%) (33897/34688)
Epoch: 204 | Batch_idx: 280 |  Loss: (0.0723) |  Loss2: (0.0000) | Acc: (97.00%) (35139/35968)
Epoch: 204 | Batch_idx: 290 |  Loss: (0.0727) |  Loss2: (0.0000) | Acc: (97.00%) (36385/37248)
Epoch: 204 | Batch_idx: 300 |  Loss: (0.0730) |  Loss2: (0.0000) | Acc: (97.00%) (37628/38528)
Epoch: 204 | Batch_idx: 310 |  Loss: (0.0726) |  Loss2: (0.0000) | Acc: (97.00%) (38889/39808)
Epoch: 204 | Batch_idx: 320 |  Loss: (0.0729) |  Loss2: (0.0000) | Acc: (97.00%) (40127/41088)
Epoch: 204 | Batch_idx: 330 |  Loss: (0.0735) |  Loss2: (0.0000) | Acc: (97.00%) (41372/42368)
Epoch: 204 | Batch_idx: 340 |  Loss: (0.0738) |  Loss2: (0.0000) | Acc: (97.00%) (42605/43648)
Epoch: 204 | Batch_idx: 350 |  Loss: (0.0738) |  Loss2: (0.0000) | Acc: (97.00%) (43852/44928)
Epoch: 204 | Batch_idx: 360 |  Loss: (0.0734) |  Loss2: (0.0000) | Acc: (97.00%) (45102/46208)
Epoch: 204 | Batch_idx: 370 |  Loss: (0.0738) |  Loss2: (0.0000) | Acc: (97.00%) (46342/47488)
Epoch: 204 | Batch_idx: 380 |  Loss: (0.0740) |  Loss2: (0.0000) | Acc: (97.00%) (47585/48768)
Epoch: 204 | Batch_idx: 390 |  Loss: (0.0740) |  Loss2: (0.0000) | Acc: (97.00%) (48781/50000)
# TEST : Loss: (0.4046) | Acc: (88.00%) (8895/10000)
percent tensor([0.5258, 0.5174, 0.5308, 0.5239, 0.5355, 0.5324, 0.5245, 0.5272, 0.5312,
        0.5199, 0.5277, 0.5261, 0.5183, 0.5246, 0.5234, 0.5224],
       device='cuda:0') torch.Size([16])
percent tensor([0.5048, 0.4983, 0.5031, 0.5037, 0.5011, 0.5058, 0.5005, 0.5041, 0.5076,
        0.5011, 0.5070, 0.4984, 0.4972, 0.5123, 0.4994, 0.5060],
       device='cuda:0') torch.Size([16])
percent tensor([0.5695, 0.5498, 0.5765, 0.5934, 0.5887, 0.5843, 0.5818, 0.5842, 0.5766,
        0.5518, 0.5595, 0.5661, 0.5191, 0.6349, 0.5615, 0.5858],
       device='cuda:0') torch.Size([16])
percent tensor([0.6339, 0.6648, 0.6355, 0.6295, 0.6276, 0.6362, 0.6508, 0.6228, 0.6676,
        0.6710, 0.6816, 0.6553, 0.6653, 0.6789, 0.6300, 0.6537],
       device='cuda:0') torch.Size([16])
percent tensor([0.6304, 0.7256, 0.5251, 0.6526, 0.5505, 0.6651, 0.6587, 0.4235, 0.7314,
        0.6887, 0.7646, 0.6260, 0.7103, 0.7399, 0.5999, 0.6504],
       device='cuda:0') torch.Size([16])
percent tensor([0.6740, 0.6783, 0.6838, 0.6746, 0.7303, 0.6823, 0.6979, 0.6982, 0.6868,
        0.6734, 0.6500, 0.6402, 0.6624, 0.6578, 0.6503, 0.6921],
       device='cuda:0') torch.Size([16])
percent tensor([0.6176, 0.6535, 0.7600, 0.6632, 0.7823, 0.7707, 0.6481, 0.6715, 0.6817,
        0.6411, 0.7266, 0.6546, 0.6835, 0.5928, 0.5863, 0.5324],
       device='cuda:0') torch.Size([16])
percent tensor([0.9998, 0.9997, 0.9998, 0.9999, 0.9998, 0.9998, 0.9997, 0.9997, 0.9998,
        0.9998, 1.0000, 0.9999, 0.9999, 0.9991, 0.9998, 0.9995],
       device='cuda:0') torch.Size([16])
Epoch: 205 | Batch_idx: 0 |  Loss: (0.0679) |  Loss2: (0.0000) | Acc: (97.00%) (125/128)
Epoch: 205 | Batch_idx: 10 |  Loss: (0.0757) |  Loss2: (0.0000) | Acc: (97.00%) (1374/1408)
Epoch: 205 | Batch_idx: 20 |  Loss: (0.0745) |  Loss2: (0.0000) | Acc: (97.00%) (2623/2688)
Epoch: 205 | Batch_idx: 30 |  Loss: (0.0792) |  Loss2: (0.0000) | Acc: (97.00%) (3863/3968)
Epoch: 205 | Batch_idx: 40 |  Loss: (0.0762) |  Loss2: (0.0000) | Acc: (97.00%) (5114/5248)
Epoch: 205 | Batch_idx: 50 |  Loss: (0.0732) |  Loss2: (0.0000) | Acc: (97.00%) (6376/6528)
Epoch: 205 | Batch_idx: 60 |  Loss: (0.0734) |  Loss2: (0.0000) | Acc: (97.00%) (7628/7808)
Epoch: 205 | Batch_idx: 70 |  Loss: (0.0731) |  Loss2: (0.0000) | Acc: (97.00%) (8881/9088)
Epoch: 205 | Batch_idx: 80 |  Loss: (0.0722) |  Loss2: (0.0000) | Acc: (97.00%) (10137/10368)
Epoch: 205 | Batch_idx: 90 |  Loss: (0.0728) |  Loss2: (0.0000) | Acc: (97.00%) (11385/11648)
Epoch: 205 | Batch_idx: 100 |  Loss: (0.0739) |  Loss2: (0.0000) | Acc: (97.00%) (12628/12928)
Epoch: 205 | Batch_idx: 110 |  Loss: (0.0741) |  Loss2: (0.0000) | Acc: (97.00%) (13873/14208)
Epoch: 205 | Batch_idx: 120 |  Loss: (0.0737) |  Loss2: (0.0000) | Acc: (97.00%) (15124/15488)
Epoch: 205 | Batch_idx: 130 |  Loss: (0.0725) |  Loss2: (0.0000) | Acc: (97.00%) (16383/16768)
Epoch: 205 | Batch_idx: 140 |  Loss: (0.0723) |  Loss2: (0.0000) | Acc: (97.00%) (17636/18048)
Epoch: 205 | Batch_idx: 150 |  Loss: (0.0721) |  Loss2: (0.0000) | Acc: (97.00%) (18882/19328)
Epoch: 205 | Batch_idx: 160 |  Loss: (0.0725) |  Loss2: (0.0000) | Acc: (97.00%) (20128/20608)
Epoch: 205 | Batch_idx: 170 |  Loss: (0.0724) |  Loss2: (0.0000) | Acc: (97.00%) (21378/21888)
Epoch: 205 | Batch_idx: 180 |  Loss: (0.0727) |  Loss2: (0.0000) | Acc: (97.00%) (22626/23168)
Epoch: 205 | Batch_idx: 190 |  Loss: (0.0724) |  Loss2: (0.0000) | Acc: (97.00%) (23881/24448)
Epoch: 205 | Batch_idx: 200 |  Loss: (0.0724) |  Loss2: (0.0000) | Acc: (97.00%) (25126/25728)
Epoch: 205 | Batch_idx: 210 |  Loss: (0.0725) |  Loss2: (0.0000) | Acc: (97.00%) (26375/27008)
Epoch: 205 | Batch_idx: 220 |  Loss: (0.0715) |  Loss2: (0.0000) | Acc: (97.00%) (27633/28288)
Epoch: 205 | Batch_idx: 230 |  Loss: (0.0716) |  Loss2: (0.0000) | Acc: (97.00%) (28878/29568)
Epoch: 205 | Batch_idx: 240 |  Loss: (0.0713) |  Loss2: (0.0000) | Acc: (97.00%) (30136/30848)
Epoch: 205 | Batch_idx: 250 |  Loss: (0.0716) |  Loss2: (0.0000) | Acc: (97.00%) (31379/32128)
Epoch: 205 | Batch_idx: 260 |  Loss: (0.0716) |  Loss2: (0.0000) | Acc: (97.00%) (32630/33408)
Epoch: 205 | Batch_idx: 270 |  Loss: (0.0715) |  Loss2: (0.0000) | Acc: (97.00%) (33873/34688)
Epoch: 205 | Batch_idx: 280 |  Loss: (0.0712) |  Loss2: (0.0000) | Acc: (97.00%) (35129/35968)
Epoch: 205 | Batch_idx: 290 |  Loss: (0.0713) |  Loss2: (0.0000) | Acc: (97.00%) (36378/37248)
Epoch: 205 | Batch_idx: 300 |  Loss: (0.0712) |  Loss2: (0.0000) | Acc: (97.00%) (37630/38528)
Epoch: 205 | Batch_idx: 310 |  Loss: (0.0713) |  Loss2: (0.0000) | Acc: (97.00%) (38880/39808)
Epoch: 205 | Batch_idx: 320 |  Loss: (0.0711) |  Loss2: (0.0000) | Acc: (97.00%) (40132/41088)
Epoch: 205 | Batch_idx: 330 |  Loss: (0.0714) |  Loss2: (0.0000) | Acc: (97.00%) (41378/42368)
Epoch: 205 | Batch_idx: 340 |  Loss: (0.0714) |  Loss2: (0.0000) | Acc: (97.00%) (42624/43648)
Epoch: 205 | Batch_idx: 350 |  Loss: (0.0713) |  Loss2: (0.0000) | Acc: (97.00%) (43882/44928)
Epoch: 205 | Batch_idx: 360 |  Loss: (0.0712) |  Loss2: (0.0000) | Acc: (97.00%) (45133/46208)
Epoch: 205 | Batch_idx: 370 |  Loss: (0.0713) |  Loss2: (0.0000) | Acc: (97.00%) (46383/47488)
Epoch: 205 | Batch_idx: 380 |  Loss: (0.0711) |  Loss2: (0.0000) | Acc: (97.00%) (47631/48768)
Epoch: 205 | Batch_idx: 390 |  Loss: (0.0717) |  Loss2: (0.0000) | Acc: (97.00%) (48825/50000)
=> saving checkpoint 'drive/app/torch/save_Schedule/checkpoint_205.pth.tar'
# TEST : Loss: (0.4272) | Acc: (88.00%) (8837/10000)
percent tensor([0.5254, 0.5190, 0.5293, 0.5236, 0.5337, 0.5322, 0.5249, 0.5277, 0.5318,
        0.5204, 0.5288, 0.5245, 0.5188, 0.5281, 0.5238, 0.5229],
       device='cuda:0') torch.Size([16])
percent tensor([0.5057, 0.4984, 0.5057, 0.5052, 0.5033, 0.5063, 0.5009, 0.5061, 0.5091,
        0.5018, 0.5079, 0.5006, 0.4981, 0.5119, 0.5000, 0.5071],
       device='cuda:0') torch.Size([16])
percent tensor([0.5708, 0.5541, 0.5896, 0.6014, 0.6021, 0.5792, 0.5850, 0.5924, 0.5834,
        0.5640, 0.5654, 0.5811, 0.5210, 0.6361, 0.5651, 0.5882],
       device='cuda:0') torch.Size([16])
percent tensor([0.6340, 0.6586, 0.6388, 0.6352, 0.6269, 0.6390, 0.6473, 0.6249, 0.6633,
        0.6647, 0.6768, 0.6530, 0.6605, 0.6748, 0.6279, 0.6523],
       device='cuda:0') torch.Size([16])
percent tensor([0.6256, 0.7050, 0.5564, 0.6591, 0.5633, 0.6863, 0.6373, 0.4125, 0.7175,
        0.6803, 0.7399, 0.6311, 0.6849, 0.7297, 0.5788, 0.6412],
       device='cuda:0') torch.Size([16])
percent tensor([0.6770, 0.6803, 0.6906, 0.6800, 0.7316, 0.6855, 0.7051, 0.6988, 0.6905,
        0.6771, 0.6555, 0.6485, 0.6575, 0.6741, 0.6581, 0.6978],
       device='cuda:0') torch.Size([16])
percent tensor([0.5777, 0.6403, 0.7559, 0.6451, 0.7718, 0.7647, 0.6353, 0.6519, 0.6540,
        0.6050, 0.6949, 0.6211, 0.6592, 0.5917, 0.5779, 0.5301],
       device='cuda:0') torch.Size([16])
percent tensor([0.9998, 0.9997, 0.9999, 0.9998, 0.9998, 0.9998, 0.9998, 0.9994, 0.9997,
        0.9997, 1.0000, 0.9998, 0.9999, 0.9987, 0.9997, 0.9994],
       device='cuda:0') torch.Size([16])
Epoch: 206 | Batch_idx: 0 |  Loss: (0.0729) |  Loss2: (0.0000) | Acc: (97.00%) (125/128)
Epoch: 206 | Batch_idx: 10 |  Loss: (0.0803) |  Loss2: (0.0000) | Acc: (97.00%) (1369/1408)
Epoch: 206 | Batch_idx: 20 |  Loss: (0.0763) |  Loss2: (0.0000) | Acc: (97.00%) (2622/2688)
Epoch: 206 | Batch_idx: 30 |  Loss: (0.0747) |  Loss2: (0.0000) | Acc: (97.00%) (3873/3968)
Epoch: 206 | Batch_idx: 40 |  Loss: (0.0712) |  Loss2: (0.0000) | Acc: (97.00%) (5124/5248)
Epoch: 206 | Batch_idx: 50 |  Loss: (0.0719) |  Loss2: (0.0000) | Acc: (97.00%) (6368/6528)
Epoch: 206 | Batch_idx: 60 |  Loss: (0.0707) |  Loss2: (0.0000) | Acc: (97.00%) (7620/7808)
Epoch: 206 | Batch_idx: 70 |  Loss: (0.0725) |  Loss2: (0.0000) | Acc: (97.00%) (8876/9088)
Epoch: 206 | Batch_idx: 80 |  Loss: (0.0750) |  Loss2: (0.0000) | Acc: (97.00%) (10116/10368)
Epoch: 206 | Batch_idx: 90 |  Loss: (0.0743) |  Loss2: (0.0000) | Acc: (97.00%) (11371/11648)
Epoch: 206 | Batch_idx: 100 |  Loss: (0.0743) |  Loss2: (0.0000) | Acc: (97.00%) (12619/12928)
Epoch: 206 | Batch_idx: 110 |  Loss: (0.0738) |  Loss2: (0.0000) | Acc: (97.00%) (13873/14208)
Epoch: 206 | Batch_idx: 120 |  Loss: (0.0741) |  Loss2: (0.0000) | Acc: (97.00%) (15119/15488)
Epoch: 206 | Batch_idx: 130 |  Loss: (0.0739) |  Loss2: (0.0000) | Acc: (97.00%) (16365/16768)
Epoch: 206 | Batch_idx: 140 |  Loss: (0.0728) |  Loss2: (0.0000) | Acc: (97.00%) (17623/18048)
Epoch: 206 | Batch_idx: 150 |  Loss: (0.0727) |  Loss2: (0.0000) | Acc: (97.00%) (18870/19328)
Epoch: 206 | Batch_idx: 160 |  Loss: (0.0729) |  Loss2: (0.0000) | Acc: (97.00%) (20119/20608)
Epoch: 206 | Batch_idx: 170 |  Loss: (0.0721) |  Loss2: (0.0000) | Acc: (97.00%) (21377/21888)
Epoch: 206 | Batch_idx: 180 |  Loss: (0.0724) |  Loss2: (0.0000) | Acc: (97.00%) (22622/23168)
Epoch: 206 | Batch_idx: 190 |  Loss: (0.0725) |  Loss2: (0.0000) | Acc: (97.00%) (23876/24448)
Epoch: 206 | Batch_idx: 200 |  Loss: (0.0722) |  Loss2: (0.0000) | Acc: (97.00%) (25129/25728)
Epoch: 206 | Batch_idx: 210 |  Loss: (0.0715) |  Loss2: (0.0000) | Acc: (97.00%) (26386/27008)
Epoch: 206 | Batch_idx: 220 |  Loss: (0.0718) |  Loss2: (0.0000) | Acc: (97.00%) (27631/28288)
Epoch: 206 | Batch_idx: 230 |  Loss: (0.0719) |  Loss2: (0.0000) | Acc: (97.00%) (28881/29568)
Epoch: 206 | Batch_idx: 240 |  Loss: (0.0715) |  Loss2: (0.0000) | Acc: (97.00%) (30137/30848)
Epoch: 206 | Batch_idx: 250 |  Loss: (0.0719) |  Loss2: (0.0000) | Acc: (97.00%) (31379/32128)
Epoch: 206 | Batch_idx: 260 |  Loss: (0.0717) |  Loss2: (0.0000) | Acc: (97.00%) (32626/33408)
Epoch: 206 | Batch_idx: 270 |  Loss: (0.0720) |  Loss2: (0.0000) | Acc: (97.00%) (33865/34688)
Epoch: 206 | Batch_idx: 280 |  Loss: (0.0723) |  Loss2: (0.0000) | Acc: (97.00%) (35105/35968)
Epoch: 206 | Batch_idx: 290 |  Loss: (0.0727) |  Loss2: (0.0000) | Acc: (97.00%) (36348/37248)
Epoch: 206 | Batch_idx: 300 |  Loss: (0.0731) |  Loss2: (0.0000) | Acc: (97.00%) (37591/38528)
Epoch: 206 | Batch_idx: 310 |  Loss: (0.0731) |  Loss2: (0.0000) | Acc: (97.00%) (38837/39808)
Epoch: 206 | Batch_idx: 320 |  Loss: (0.0731) |  Loss2: (0.0000) | Acc: (97.00%) (40089/41088)
Epoch: 206 | Batch_idx: 330 |  Loss: (0.0732) |  Loss2: (0.0000) | Acc: (97.00%) (41337/42368)
Epoch: 206 | Batch_idx: 340 |  Loss: (0.0733) |  Loss2: (0.0000) | Acc: (97.00%) (42588/43648)
Epoch: 206 | Batch_idx: 350 |  Loss: (0.0732) |  Loss2: (0.0000) | Acc: (97.00%) (43836/44928)
Epoch: 206 | Batch_idx: 360 |  Loss: (0.0730) |  Loss2: (0.0000) | Acc: (97.00%) (45092/46208)
Epoch: 206 | Batch_idx: 370 |  Loss: (0.0728) |  Loss2: (0.0000) | Acc: (97.00%) (46344/47488)
Epoch: 206 | Batch_idx: 380 |  Loss: (0.0726) |  Loss2: (0.0000) | Acc: (97.00%) (47594/48768)
Epoch: 206 | Batch_idx: 390 |  Loss: (0.0725) |  Loss2: (0.0000) | Acc: (97.00%) (48794/50000)
# TEST : Loss: (0.4090) | Acc: (88.00%) (8896/10000)
percent tensor([0.5283, 0.5201, 0.5319, 0.5261, 0.5368, 0.5354, 0.5265, 0.5294, 0.5332,
        0.5225, 0.5308, 0.5274, 0.5209, 0.5268, 0.5261, 0.5250],
       device='cuda:0') torch.Size([16])
percent tensor([0.5054, 0.4988, 0.5049, 0.5051, 0.5028, 0.5066, 0.5009, 0.5055, 0.5082,
        0.5017, 0.5073, 0.4998, 0.4979, 0.5131, 0.5002, 0.5070],
       device='cuda:0') torch.Size([16])
percent tensor([0.5784, 0.5508, 0.5843, 0.5987, 0.5991, 0.5961, 0.5821, 0.5872, 0.5811,
        0.5598, 0.5691, 0.5769, 0.5239, 0.6280, 0.5682, 0.5915],
       device='cuda:0') torch.Size([16])
percent tensor([0.6384, 0.6649, 0.6424, 0.6395, 0.6317, 0.6415, 0.6531, 0.6280, 0.6692,
        0.6706, 0.6809, 0.6603, 0.6678, 0.6779, 0.6332, 0.6559],
       device='cuda:0') torch.Size([16])
percent tensor([0.6282, 0.7228, 0.5438, 0.6683, 0.5572, 0.6733, 0.6581, 0.4280, 0.7352,
        0.6891, 0.7525, 0.6321, 0.7080, 0.7456, 0.5931, 0.6547],
       device='cuda:0') torch.Size([16])
percent tensor([0.6797, 0.6864, 0.6972, 0.6848, 0.7390, 0.7004, 0.7037, 0.7054, 0.6949,
        0.6768, 0.6468, 0.6441, 0.6634, 0.6632, 0.6629, 0.7015],
       device='cuda:0') torch.Size([16])
percent tensor([0.5611, 0.6343, 0.7669, 0.6570, 0.7670, 0.7740, 0.6164, 0.6651, 0.6645,
        0.5977, 0.7068, 0.6160, 0.6361, 0.5951, 0.5672, 0.4997],
       device='cuda:0') torch.Size([16])
percent tensor([0.9998, 0.9998, 0.9999, 0.9999, 0.9998, 0.9998, 0.9998, 0.9997, 0.9999,
        0.9998, 0.9999, 0.9998, 0.9999, 0.9993, 0.9997, 0.9996],
       device='cuda:0') torch.Size([16])
Epoch: 207 | Batch_idx: 0 |  Loss: (0.0299) |  Loss2: (0.0000) | Acc: (98.00%) (126/128)
Epoch: 207 | Batch_idx: 10 |  Loss: (0.0624) |  Loss2: (0.0000) | Acc: (98.00%) (1385/1408)
Epoch: 207 | Batch_idx: 20 |  Loss: (0.0687) |  Loss2: (0.0000) | Acc: (97.00%) (2627/2688)
Epoch: 207 | Batch_idx: 30 |  Loss: (0.0658) |  Loss2: (0.0000) | Acc: (97.00%) (3883/3968)
Epoch: 207 | Batch_idx: 40 |  Loss: (0.0668) |  Loss2: (0.0000) | Acc: (97.00%) (5132/5248)
Epoch: 207 | Batch_idx: 50 |  Loss: (0.0657) |  Loss2: (0.0000) | Acc: (97.00%) (6383/6528)
Epoch: 207 | Batch_idx: 60 |  Loss: (0.0661) |  Loss2: (0.0000) | Acc: (97.00%) (7635/7808)
Epoch: 207 | Batch_idx: 70 |  Loss: (0.0657) |  Loss2: (0.0000) | Acc: (97.00%) (8885/9088)
Epoch: 207 | Batch_idx: 80 |  Loss: (0.0659) |  Loss2: (0.0000) | Acc: (97.00%) (10138/10368)
Epoch: 207 | Batch_idx: 90 |  Loss: (0.0662) |  Loss2: (0.0000) | Acc: (97.00%) (11387/11648)
Epoch: 207 | Batch_idx: 100 |  Loss: (0.0665) |  Loss2: (0.0000) | Acc: (97.00%) (12636/12928)
Epoch: 207 | Batch_idx: 110 |  Loss: (0.0667) |  Loss2: (0.0000) | Acc: (97.00%) (13883/14208)
Epoch: 207 | Batch_idx: 120 |  Loss: (0.0674) |  Loss2: (0.0000) | Acc: (97.00%) (15130/15488)
Epoch: 207 | Batch_idx: 130 |  Loss: (0.0663) |  Loss2: (0.0000) | Acc: (97.00%) (16388/16768)
Epoch: 207 | Batch_idx: 140 |  Loss: (0.0674) |  Loss2: (0.0000) | Acc: (97.00%) (17622/18048)
Epoch: 207 | Batch_idx: 150 |  Loss: (0.0675) |  Loss2: (0.0000) | Acc: (97.00%) (18876/19328)
Epoch: 207 | Batch_idx: 160 |  Loss: (0.0664) |  Loss2: (0.0000) | Acc: (97.00%) (20134/20608)
Epoch: 207 | Batch_idx: 170 |  Loss: (0.0670) |  Loss2: (0.0000) | Acc: (97.00%) (21382/21888)
Epoch: 207 | Batch_idx: 180 |  Loss: (0.0674) |  Loss2: (0.0000) | Acc: (97.00%) (22627/23168)
Epoch: 207 | Batch_idx: 190 |  Loss: (0.0673) |  Loss2: (0.0000) | Acc: (97.00%) (23879/24448)
Epoch: 207 | Batch_idx: 200 |  Loss: (0.0670) |  Loss2: (0.0000) | Acc: (97.00%) (25136/25728)
Epoch: 207 | Batch_idx: 210 |  Loss: (0.0674) |  Loss2: (0.0000) | Acc: (97.00%) (26378/27008)
Epoch: 207 | Batch_idx: 220 |  Loss: (0.0681) |  Loss2: (0.0000) | Acc: (97.00%) (27622/28288)
Epoch: 207 | Batch_idx: 230 |  Loss: (0.0688) |  Loss2: (0.0000) | Acc: (97.00%) (28861/29568)
Epoch: 207 | Batch_idx: 240 |  Loss: (0.0695) |  Loss2: (0.0000) | Acc: (97.00%) (30103/30848)
Epoch: 207 | Batch_idx: 250 |  Loss: (0.0691) |  Loss2: (0.0000) | Acc: (97.00%) (31360/32128)
Epoch: 207 | Batch_idx: 260 |  Loss: (0.0693) |  Loss2: (0.0000) | Acc: (97.00%) (32609/33408)
Epoch: 207 | Batch_idx: 270 |  Loss: (0.0691) |  Loss2: (0.0000) | Acc: (97.00%) (33858/34688)
Epoch: 207 | Batch_idx: 280 |  Loss: (0.0692) |  Loss2: (0.0000) | Acc: (97.00%) (35105/35968)
Epoch: 207 | Batch_idx: 290 |  Loss: (0.0694) |  Loss2: (0.0000) | Acc: (97.00%) (36348/37248)
Epoch: 207 | Batch_idx: 300 |  Loss: (0.0697) |  Loss2: (0.0000) | Acc: (97.00%) (37594/38528)
Epoch: 207 | Batch_idx: 310 |  Loss: (0.0699) |  Loss2: (0.0000) | Acc: (97.00%) (38832/39808)
Epoch: 207 | Batch_idx: 320 |  Loss: (0.0699) |  Loss2: (0.0000) | Acc: (97.00%) (40084/41088)
Epoch: 207 | Batch_idx: 330 |  Loss: (0.0708) |  Loss2: (0.0000) | Acc: (97.00%) (41319/42368)
Epoch: 207 | Batch_idx: 340 |  Loss: (0.0707) |  Loss2: (0.0000) | Acc: (97.00%) (42571/43648)
Epoch: 207 | Batch_idx: 350 |  Loss: (0.0706) |  Loss2: (0.0000) | Acc: (97.00%) (43823/44928)
Epoch: 207 | Batch_idx: 360 |  Loss: (0.0706) |  Loss2: (0.0000) | Acc: (97.00%) (45072/46208)
Epoch: 207 | Batch_idx: 370 |  Loss: (0.0710) |  Loss2: (0.0000) | Acc: (97.00%) (46316/47488)
Epoch: 207 | Batch_idx: 380 |  Loss: (0.0712) |  Loss2: (0.0000) | Acc: (97.00%) (47565/48768)
Epoch: 207 | Batch_idx: 390 |  Loss: (0.0713) |  Loss2: (0.0000) | Acc: (97.00%) (48764/50000)
# TEST : Loss: (0.4488) | Acc: (87.00%) (8777/10000)
percent tensor([0.5265, 0.5201, 0.5292, 0.5261, 0.5344, 0.5350, 0.5260, 0.5287, 0.5316,
        0.5214, 0.5293, 0.5246, 0.5195, 0.5288, 0.5255, 0.5249],
       device='cuda:0') torch.Size([16])
percent tensor([0.5054, 0.4998, 0.5065, 0.5061, 0.5043, 0.5064, 0.5017, 0.5070, 0.5095,
        0.5028, 0.5084, 0.5017, 0.4984, 0.5142, 0.5007, 0.5074],
       device='cuda:0') torch.Size([16])
percent tensor([0.5756, 0.5579, 0.5900, 0.6052, 0.6024, 0.5858, 0.5903, 0.6001, 0.5866,
        0.5637, 0.5702, 0.5836, 0.5251, 0.6404, 0.5679, 0.5924],
       device='cuda:0') torch.Size([16])
percent tensor([0.6356, 0.6621, 0.6408, 0.6366, 0.6290, 0.6432, 0.6508, 0.6242, 0.6667,
        0.6670, 0.6806, 0.6539, 0.6658, 0.6776, 0.6319, 0.6534],
       device='cuda:0') torch.Size([16])
percent tensor([0.6208, 0.7211, 0.5368, 0.6509, 0.5355, 0.6645, 0.6516, 0.4107, 0.7268,
        0.6922, 0.7592, 0.6129, 0.6997, 0.7368, 0.5913, 0.6517],
       device='cuda:0') torch.Size([16])
percent tensor([0.6952, 0.7068, 0.6996, 0.6926, 0.7414, 0.7072, 0.7205, 0.7168, 0.7080,
        0.6995, 0.6779, 0.6526, 0.6826, 0.6860, 0.6802, 0.7147],
       device='cuda:0') torch.Size([16])
percent tensor([0.5494, 0.6355, 0.7526, 0.6449, 0.7440, 0.7659, 0.6374, 0.6473, 0.6499,
        0.5902, 0.6926, 0.6088, 0.6574, 0.5580, 0.5707, 0.4890],
       device='cuda:0') torch.Size([16])
percent tensor([0.9998, 0.9997, 0.9998, 0.9997, 0.9998, 0.9998, 0.9999, 0.9996, 0.9997,
        0.9998, 0.9999, 0.9998, 0.9999, 0.9993, 0.9996, 0.9994],
       device='cuda:0') torch.Size([16])
Epoch: 208 | Batch_idx: 0 |  Loss: (0.0496) |  Loss2: (0.0000) | Acc: (99.00%) (127/128)
Epoch: 208 | Batch_idx: 10 |  Loss: (0.0687) |  Loss2: (0.0000) | Acc: (98.00%) (1380/1408)
Epoch: 208 | Batch_idx: 20 |  Loss: (0.0714) |  Loss2: (0.0000) | Acc: (97.00%) (2627/2688)
Epoch: 208 | Batch_idx: 30 |  Loss: (0.0720) |  Loss2: (0.0000) | Acc: (97.00%) (3875/3968)
Epoch: 208 | Batch_idx: 40 |  Loss: (0.0812) |  Loss2: (0.0000) | Acc: (97.00%) (5105/5248)
Epoch: 208 | Batch_idx: 50 |  Loss: (0.0794) |  Loss2: (0.0000) | Acc: (97.00%) (6354/6528)
Epoch: 208 | Batch_idx: 60 |  Loss: (0.0774) |  Loss2: (0.0000) | Acc: (97.00%) (7600/7808)
Epoch: 208 | Batch_idx: 70 |  Loss: (0.0773) |  Loss2: (0.0000) | Acc: (97.00%) (8845/9088)
Epoch: 208 | Batch_idx: 80 |  Loss: (0.0753) |  Loss2: (0.0000) | Acc: (97.00%) (10103/10368)
Epoch: 208 | Batch_idx: 90 |  Loss: (0.0746) |  Loss2: (0.0000) | Acc: (97.00%) (11350/11648)
Epoch: 208 | Batch_idx: 100 |  Loss: (0.0742) |  Loss2: (0.0000) | Acc: (97.00%) (12597/12928)
Epoch: 208 | Batch_idx: 110 |  Loss: (0.0743) |  Loss2: (0.0000) | Acc: (97.00%) (13845/14208)
Epoch: 208 | Batch_idx: 120 |  Loss: (0.0741) |  Loss2: (0.0000) | Acc: (97.00%) (15093/15488)
Epoch: 208 | Batch_idx: 130 |  Loss: (0.0735) |  Loss2: (0.0000) | Acc: (97.00%) (16345/16768)
Epoch: 208 | Batch_idx: 140 |  Loss: (0.0737) |  Loss2: (0.0000) | Acc: (97.00%) (17595/18048)
Epoch: 208 | Batch_idx: 150 |  Loss: (0.0729) |  Loss2: (0.0000) | Acc: (97.00%) (18849/19328)
Epoch: 208 | Batch_idx: 160 |  Loss: (0.0729) |  Loss2: (0.0000) | Acc: (97.00%) (20103/20608)
Epoch: 208 | Batch_idx: 170 |  Loss: (0.0727) |  Loss2: (0.0000) | Acc: (97.00%) (21354/21888)
Epoch: 208 | Batch_idx: 180 |  Loss: (0.0725) |  Loss2: (0.0000) | Acc: (97.00%) (22610/23168)
Epoch: 208 | Batch_idx: 190 |  Loss: (0.0730) |  Loss2: (0.0000) | Acc: (97.00%) (23856/24448)
Epoch: 208 | Batch_idx: 200 |  Loss: (0.0732) |  Loss2: (0.0000) | Acc: (97.00%) (25105/25728)
Epoch: 208 | Batch_idx: 210 |  Loss: (0.0729) |  Loss2: (0.0000) | Acc: (97.00%) (26358/27008)
Epoch: 208 | Batch_idx: 220 |  Loss: (0.0730) |  Loss2: (0.0000) | Acc: (97.00%) (27604/28288)
Epoch: 208 | Batch_idx: 230 |  Loss: (0.0731) |  Loss2: (0.0000) | Acc: (97.00%) (28855/29568)
Epoch: 208 | Batch_idx: 240 |  Loss: (0.0733) |  Loss2: (0.0000) | Acc: (97.00%) (30099/30848)
Epoch: 208 | Batch_idx: 250 |  Loss: (0.0739) |  Loss2: (0.0000) | Acc: (97.00%) (31344/32128)
Epoch: 208 | Batch_idx: 260 |  Loss: (0.0734) |  Loss2: (0.0000) | Acc: (97.00%) (32600/33408)
Epoch: 208 | Batch_idx: 270 |  Loss: (0.0728) |  Loss2: (0.0000) | Acc: (97.00%) (33853/34688)
Epoch: 208 | Batch_idx: 280 |  Loss: (0.0730) |  Loss2: (0.0000) | Acc: (97.00%) (35102/35968)
Epoch: 208 | Batch_idx: 290 |  Loss: (0.0730) |  Loss2: (0.0000) | Acc: (97.00%) (36350/37248)
Epoch: 208 | Batch_idx: 300 |  Loss: (0.0735) |  Loss2: (0.0000) | Acc: (97.00%) (37591/38528)
Epoch: 208 | Batch_idx: 310 |  Loss: (0.0736) |  Loss2: (0.0000) | Acc: (97.00%) (38841/39808)
Epoch: 208 | Batch_idx: 320 |  Loss: (0.0735) |  Loss2: (0.0000) | Acc: (97.00%) (40093/41088)
Epoch: 208 | Batch_idx: 330 |  Loss: (0.0736) |  Loss2: (0.0000) | Acc: (97.00%) (41342/42368)
Epoch: 208 | Batch_idx: 340 |  Loss: (0.0736) |  Loss2: (0.0000) | Acc: (97.00%) (42590/43648)
Epoch: 208 | Batch_idx: 350 |  Loss: (0.0732) |  Loss2: (0.0000) | Acc: (97.00%) (43840/44928)
Epoch: 208 | Batch_idx: 360 |  Loss: (0.0731) |  Loss2: (0.0000) | Acc: (97.00%) (45092/46208)
Epoch: 208 | Batch_idx: 370 |  Loss: (0.0731) |  Loss2: (0.0000) | Acc: (97.00%) (46340/47488)
Epoch: 208 | Batch_idx: 380 |  Loss: (0.0729) |  Loss2: (0.0000) | Acc: (97.00%) (47592/48768)
Epoch: 208 | Batch_idx: 390 |  Loss: (0.0729) |  Loss2: (0.0000) | Acc: (97.00%) (48793/50000)
# TEST : Loss: (0.4142) | Acc: (88.00%) (8890/10000)
percent tensor([0.5282, 0.5209, 0.5328, 0.5271, 0.5379, 0.5347, 0.5277, 0.5306, 0.5340,
        0.5230, 0.5310, 0.5285, 0.5210, 0.5291, 0.5263, 0.5258],
       device='cuda:0') torch.Size([16])
percent tensor([0.5055, 0.4993, 0.5059, 0.5052, 0.5038, 0.5070, 0.5018, 0.5059, 0.5085,
        0.5025, 0.5081, 0.5010, 0.4984, 0.5137, 0.5006, 0.5073],
       device='cuda:0') torch.Size([16])
percent tensor([0.5750, 0.5513, 0.5869, 0.6039, 0.5972, 0.5879, 0.5886, 0.5932, 0.5835,
        0.5611, 0.5692, 0.5809, 0.5235, 0.6417, 0.5654, 0.5925],
       device='cuda:0') torch.Size([16])
percent tensor([0.6457, 0.6647, 0.6500, 0.6384, 0.6354, 0.6492, 0.6535, 0.6317, 0.6748,
        0.6763, 0.6863, 0.6621, 0.6727, 0.6826, 0.6351, 0.6619],
       device='cuda:0') torch.Size([16])
percent tensor([0.6330, 0.7059, 0.5546, 0.6519, 0.5623, 0.6763, 0.6479, 0.4309, 0.7291,
        0.6794, 0.7477, 0.6266, 0.7050, 0.7279, 0.5763, 0.6552],
       device='cuda:0') torch.Size([16])
percent tensor([0.6899, 0.6968, 0.6931, 0.6906, 0.7370, 0.7010, 0.7107, 0.7081, 0.7018,
        0.6883, 0.6597, 0.6456, 0.6702, 0.6870, 0.6711, 0.7056],
       device='cuda:0') torch.Size([16])
percent tensor([0.5984, 0.6590, 0.7486, 0.6718, 0.7778, 0.7807, 0.6201, 0.6575, 0.6512,
        0.6088, 0.7077, 0.5921, 0.6646, 0.5811, 0.5951, 0.5015],
       device='cuda:0') torch.Size([16])
percent tensor([0.9998, 0.9998, 0.9998, 0.9999, 0.9997, 0.9998, 0.9997, 0.9996, 0.9997,
        0.9998, 1.0000, 0.9999, 0.9999, 0.9992, 0.9996, 0.9994],
       device='cuda:0') torch.Size([16])
Epoch: 209 | Batch_idx: 0 |  Loss: (0.0547) |  Loss2: (0.0000) | Acc: (97.00%) (125/128)
Epoch: 209 | Batch_idx: 10 |  Loss: (0.0559) |  Loss2: (0.0000) | Acc: (98.00%) (1382/1408)
Epoch: 209 | Batch_idx: 20 |  Loss: (0.0563) |  Loss2: (0.0000) | Acc: (98.00%) (2641/2688)
Epoch: 209 | Batch_idx: 30 |  Loss: (0.0568) |  Loss2: (0.0000) | Acc: (98.00%) (3900/3968)
Epoch: 209 | Batch_idx: 40 |  Loss: (0.0582) |  Loss2: (0.0000) | Acc: (98.00%) (5157/5248)
Epoch: 209 | Batch_idx: 50 |  Loss: (0.0597) |  Loss2: (0.0000) | Acc: (98.00%) (6411/6528)
Epoch: 209 | Batch_idx: 60 |  Loss: (0.0608) |  Loss2: (0.0000) | Acc: (98.00%) (7663/7808)
Epoch: 209 | Batch_idx: 70 |  Loss: (0.0604) |  Loss2: (0.0000) | Acc: (98.00%) (8921/9088)
Epoch: 209 | Batch_idx: 80 |  Loss: (0.0602) |  Loss2: (0.0000) | Acc: (98.00%) (10179/10368)
Epoch: 209 | Batch_idx: 90 |  Loss: (0.0611) |  Loss2: (0.0000) | Acc: (98.00%) (11428/11648)
Epoch: 209 | Batch_idx: 100 |  Loss: (0.0616) |  Loss2: (0.0000) | Acc: (98.00%) (12679/12928)
Epoch: 209 | Batch_idx: 110 |  Loss: (0.0610) |  Loss2: (0.0000) | Acc: (98.00%) (13938/14208)
Epoch: 209 | Batch_idx: 120 |  Loss: (0.0599) |  Loss2: (0.0000) | Acc: (98.00%) (15199/15488)
Epoch: 209 | Batch_idx: 130 |  Loss: (0.0591) |  Loss2: (0.0000) | Acc: (98.00%) (16462/16768)
Epoch: 209 | Batch_idx: 140 |  Loss: (0.0590) |  Loss2: (0.0000) | Acc: (98.00%) (17722/18048)
Epoch: 209 | Batch_idx: 150 |  Loss: (0.0611) |  Loss2: (0.0000) | Acc: (98.00%) (18968/19328)
Epoch: 209 | Batch_idx: 160 |  Loss: (0.0624) |  Loss2: (0.0000) | Acc: (98.00%) (20213/20608)
Epoch: 209 | Batch_idx: 170 |  Loss: (0.0625) |  Loss2: (0.0000) | Acc: (98.00%) (21467/21888)
Epoch: 209 | Batch_idx: 180 |  Loss: (0.0632) |  Loss2: (0.0000) | Acc: (98.00%) (22715/23168)
Epoch: 209 | Batch_idx: 190 |  Loss: (0.0640) |  Loss2: (0.0000) | Acc: (98.00%) (23961/24448)
Epoch: 209 | Batch_idx: 200 |  Loss: (0.0643) |  Loss2: (0.0000) | Acc: (97.00%) (25209/25728)
Epoch: 209 | Batch_idx: 210 |  Loss: (0.0645) |  Loss2: (0.0000) | Acc: (97.00%) (26460/27008)
Epoch: 209 | Batch_idx: 220 |  Loss: (0.0646) |  Loss2: (0.0000) | Acc: (97.00%) (27710/28288)
Epoch: 209 | Batch_idx: 230 |  Loss: (0.0658) |  Loss2: (0.0000) | Acc: (97.00%) (28946/29568)
Epoch: 209 | Batch_idx: 240 |  Loss: (0.0657) |  Loss2: (0.0000) | Acc: (97.00%) (30198/30848)
Epoch: 209 | Batch_idx: 250 |  Loss: (0.0664) |  Loss2: (0.0000) | Acc: (97.00%) (31435/32128)
Epoch: 209 | Batch_idx: 260 |  Loss: (0.0666) |  Loss2: (0.0000) | Acc: (97.00%) (32681/33408)
Epoch: 209 | Batch_idx: 270 |  Loss: (0.0668) |  Loss2: (0.0000) | Acc: (97.00%) (33933/34688)
Epoch: 209 | Batch_idx: 280 |  Loss: (0.0668) |  Loss2: (0.0000) | Acc: (97.00%) (35182/35968)
Epoch: 209 | Batch_idx: 290 |  Loss: (0.0667) |  Loss2: (0.0000) | Acc: (97.00%) (36436/37248)
Epoch: 209 | Batch_idx: 300 |  Loss: (0.0668) |  Loss2: (0.0000) | Acc: (97.00%) (37689/38528)
Epoch: 209 | Batch_idx: 310 |  Loss: (0.0669) |  Loss2: (0.0000) | Acc: (97.00%) (38937/39808)
Epoch: 209 | Batch_idx: 320 |  Loss: (0.0672) |  Loss2: (0.0000) | Acc: (97.00%) (40181/41088)
Epoch: 209 | Batch_idx: 330 |  Loss: (0.0675) |  Loss2: (0.0000) | Acc: (97.00%) (41423/42368)
Epoch: 209 | Batch_idx: 340 |  Loss: (0.0678) |  Loss2: (0.0000) | Acc: (97.00%) (42666/43648)
Epoch: 209 | Batch_idx: 350 |  Loss: (0.0685) |  Loss2: (0.0000) | Acc: (97.00%) (43904/44928)
Epoch: 209 | Batch_idx: 360 |  Loss: (0.0689) |  Loss2: (0.0000) | Acc: (97.00%) (45147/46208)
Epoch: 209 | Batch_idx: 370 |  Loss: (0.0689) |  Loss2: (0.0000) | Acc: (97.00%) (46398/47488)
Epoch: 209 | Batch_idx: 380 |  Loss: (0.0691) |  Loss2: (0.0000) | Acc: (97.00%) (47646/48768)
Epoch: 209 | Batch_idx: 390 |  Loss: (0.0688) |  Loss2: (0.0000) | Acc: (97.00%) (48852/50000)
# TEST : Loss: (0.4180) | Acc: (88.00%) (8887/10000)
percent tensor([0.5278, 0.5196, 0.5286, 0.5250, 0.5340, 0.5353, 0.5254, 0.5277, 0.5324,
        0.5207, 0.5299, 0.5246, 0.5204, 0.5278, 0.5254, 0.5246],
       device='cuda:0') torch.Size([16])
percent tensor([0.5068, 0.5002, 0.5073, 0.5062, 0.5048, 0.5075, 0.5026, 0.5076, 0.5102,
        0.5037, 0.5094, 0.5019, 0.4994, 0.5147, 0.5012, 0.5081],
       device='cuda:0') torch.Size([16])
percent tensor([0.5786, 0.5544, 0.5833, 0.5984, 0.5960, 0.5913, 0.5849, 0.5954, 0.5872,
        0.5627, 0.5722, 0.5787, 0.5268, 0.6381, 0.5670, 0.5934],
       device='cuda:0') torch.Size([16])
percent tensor([0.6486, 0.6663, 0.6507, 0.6484, 0.6380, 0.6548, 0.6570, 0.6324, 0.6718,
        0.6749, 0.6874, 0.6631, 0.6720, 0.6803, 0.6396, 0.6649],
       device='cuda:0') torch.Size([16])
percent tensor([0.6372, 0.7129, 0.5571, 0.6581, 0.5607, 0.6873, 0.6653, 0.4176, 0.7203,
        0.6837, 0.7572, 0.6372, 0.7006, 0.7470, 0.5888, 0.6646],
       device='cuda:0') torch.Size([16])
percent tensor([0.6945, 0.7031, 0.6978, 0.6897, 0.7357, 0.7057, 0.7108, 0.7094, 0.7105,
        0.6943, 0.6696, 0.6484, 0.6751, 0.6893, 0.6721, 0.7123],
       device='cuda:0') torch.Size([16])
percent tensor([0.5652, 0.6347, 0.7532, 0.6563, 0.7494, 0.7776, 0.6485, 0.6618, 0.6714,
        0.5875, 0.6977, 0.5944, 0.6566, 0.5576, 0.5783, 0.5228],
       device='cuda:0') torch.Size([16])
percent tensor([0.9998, 0.9997, 0.9998, 0.9998, 0.9997, 0.9996, 0.9998, 0.9996, 0.9997,
        0.9998, 1.0000, 0.9998, 1.0000, 0.9992, 0.9996, 0.9995],
       device='cuda:0') torch.Size([16])
Epoch: 210 | Batch_idx: 0 |  Loss: (0.0994) |  Loss2: (0.0000) | Acc: (97.00%) (125/128)
Epoch: 210 | Batch_idx: 10 |  Loss: (0.0645) |  Loss2: (0.0000) | Acc: (97.00%) (1379/1408)
Epoch: 210 | Batch_idx: 20 |  Loss: (0.0646) |  Loss2: (0.0000) | Acc: (98.00%) (2635/2688)
Epoch: 210 | Batch_idx: 30 |  Loss: (0.0606) |  Loss2: (0.0000) | Acc: (98.00%) (3893/3968)
Epoch: 210 | Batch_idx: 40 |  Loss: (0.0631) |  Loss2: (0.0000) | Acc: (97.00%) (5139/5248)
Epoch: 210 | Batch_idx: 50 |  Loss: (0.0644) |  Loss2: (0.0000) | Acc: (97.00%) (6387/6528)
Epoch: 210 | Batch_idx: 60 |  Loss: (0.0676) |  Loss2: (0.0000) | Acc: (97.00%) (7632/7808)
Epoch: 210 | Batch_idx: 70 |  Loss: (0.0668) |  Loss2: (0.0000) | Acc: (97.00%) (8885/9088)
Epoch: 210 | Batch_idx: 80 |  Loss: (0.0691) |  Loss2: (0.0000) | Acc: (97.00%) (10128/10368)
Epoch: 210 | Batch_idx: 90 |  Loss: (0.0703) |  Loss2: (0.0000) | Acc: (97.00%) (11370/11648)
Epoch: 210 | Batch_idx: 100 |  Loss: (0.0699) |  Loss2: (0.0000) | Acc: (97.00%) (12623/12928)
Epoch: 210 | Batch_idx: 110 |  Loss: (0.0710) |  Loss2: (0.0000) | Acc: (97.00%) (13872/14208)
Epoch: 210 | Batch_idx: 120 |  Loss: (0.0702) |  Loss2: (0.0000) | Acc: (97.00%) (15123/15488)
Epoch: 210 | Batch_idx: 130 |  Loss: (0.0704) |  Loss2: (0.0000) | Acc: (97.00%) (16367/16768)
Epoch: 210 | Batch_idx: 140 |  Loss: (0.0702) |  Loss2: (0.0000) | Acc: (97.00%) (17619/18048)
Epoch: 210 | Batch_idx: 150 |  Loss: (0.0707) |  Loss2: (0.0000) | Acc: (97.00%) (18868/19328)
Epoch: 210 | Batch_idx: 160 |  Loss: (0.0700) |  Loss2: (0.0000) | Acc: (97.00%) (20122/20608)
Epoch: 210 | Batch_idx: 170 |  Loss: (0.0692) |  Loss2: (0.0000) | Acc: (97.00%) (21378/21888)
Epoch: 210 | Batch_idx: 180 |  Loss: (0.0690) |  Loss2: (0.0000) | Acc: (97.00%) (22634/23168)
Epoch: 210 | Batch_idx: 190 |  Loss: (0.0684) |  Loss2: (0.0000) | Acc: (97.00%) (23894/24448)
Epoch: 210 | Batch_idx: 200 |  Loss: (0.0686) |  Loss2: (0.0000) | Acc: (97.00%) (25143/25728)
Epoch: 210 | Batch_idx: 210 |  Loss: (0.0684) |  Loss2: (0.0000) | Acc: (97.00%) (26399/27008)
Epoch: 210 | Batch_idx: 220 |  Loss: (0.0682) |  Loss2: (0.0000) | Acc: (97.00%) (27657/28288)
Epoch: 210 | Batch_idx: 230 |  Loss: (0.0680) |  Loss2: (0.0000) | Acc: (97.00%) (28904/29568)
Epoch: 210 | Batch_idx: 240 |  Loss: (0.0682) |  Loss2: (0.0000) | Acc: (97.00%) (30153/30848)
Epoch: 210 | Batch_idx: 250 |  Loss: (0.0685) |  Loss2: (0.0000) | Acc: (97.00%) (31402/32128)
Epoch: 210 | Batch_idx: 260 |  Loss: (0.0683) |  Loss2: (0.0000) | Acc: (97.00%) (32656/33408)
Epoch: 210 | Batch_idx: 270 |  Loss: (0.0687) |  Loss2: (0.0000) | Acc: (97.00%) (33903/34688)
Epoch: 210 | Batch_idx: 280 |  Loss: (0.0688) |  Loss2: (0.0000) | Acc: (97.00%) (35152/35968)
Epoch: 210 | Batch_idx: 290 |  Loss: (0.0691) |  Loss2: (0.0000) | Acc: (97.00%) (36396/37248)
Epoch: 210 | Batch_idx: 300 |  Loss: (0.0700) |  Loss2: (0.0000) | Acc: (97.00%) (37635/38528)
Epoch: 210 | Batch_idx: 310 |  Loss: (0.0700) |  Loss2: (0.0000) | Acc: (97.00%) (38886/39808)
Epoch: 210 | Batch_idx: 320 |  Loss: (0.0704) |  Loss2: (0.0000) | Acc: (97.00%) (40124/41088)
Epoch: 210 | Batch_idx: 330 |  Loss: (0.0704) |  Loss2: (0.0000) | Acc: (97.00%) (41377/42368)
Epoch: 210 | Batch_idx: 340 |  Loss: (0.0706) |  Loss2: (0.0000) | Acc: (97.00%) (42621/43648)
Epoch: 210 | Batch_idx: 350 |  Loss: (0.0707) |  Loss2: (0.0000) | Acc: (97.00%) (43867/44928)
Epoch: 210 | Batch_idx: 360 |  Loss: (0.0710) |  Loss2: (0.0000) | Acc: (97.00%) (45112/46208)
Epoch: 210 | Batch_idx: 370 |  Loss: (0.0711) |  Loss2: (0.0000) | Acc: (97.00%) (46361/47488)
Epoch: 210 | Batch_idx: 380 |  Loss: (0.0712) |  Loss2: (0.0000) | Acc: (97.00%) (47608/48768)
Epoch: 210 | Batch_idx: 390 |  Loss: (0.0709) |  Loss2: (0.0000) | Acc: (97.00%) (48816/50000)
=> saving checkpoint 'drive/app/torch/save_Schedule/checkpoint_210.pth.tar'
# TEST : Loss: (0.4166) | Acc: (88.00%) (8860/10000)
percent tensor([0.5278, 0.5195, 0.5316, 0.5259, 0.5364, 0.5346, 0.5262, 0.5291, 0.5336,
        0.5220, 0.5303, 0.5272, 0.5204, 0.5275, 0.5249, 0.5248],
       device='cuda:0') torch.Size([16])
percent tensor([0.5068, 0.5006, 0.5062, 0.5061, 0.5046, 0.5076, 0.5030, 0.5070, 0.5109,
        0.5039, 0.5091, 0.5011, 0.4998, 0.5144, 0.5013, 0.5084],
       device='cuda:0') torch.Size([16])
percent tensor([0.5790, 0.5524, 0.5860, 0.6019, 0.6000, 0.5905, 0.5867, 0.5953, 0.5897,
        0.5643, 0.5682, 0.5787, 0.5271, 0.6366, 0.5675, 0.5935],
       device='cuda:0') torch.Size([16])
percent tensor([0.6430, 0.6659, 0.6535, 0.6437, 0.6381, 0.6427, 0.6595, 0.6302, 0.6742,
        0.6765, 0.6856, 0.6677, 0.6681, 0.6828, 0.6332, 0.6570],
       device='cuda:0') torch.Size([16])
percent tensor([0.6294, 0.7134, 0.5750, 0.6602, 0.5668, 0.6688, 0.6621, 0.4222, 0.7325,
        0.6944, 0.7644, 0.6483, 0.7057, 0.7434, 0.5790, 0.6501],
       device='cuda:0') torch.Size([16])
percent tensor([0.6939, 0.6962, 0.6970, 0.6890, 0.7399, 0.7045, 0.7111, 0.7103, 0.7019,
        0.6868, 0.6636, 0.6498, 0.6673, 0.6837, 0.6752, 0.7100],
       device='cuda:0') torch.Size([16])
percent tensor([0.5683, 0.6176, 0.7614, 0.6670, 0.7456, 0.7482, 0.6320, 0.6519, 0.6806,
        0.6132, 0.7040, 0.6082, 0.6337, 0.5978, 0.5842, 0.4855],
       device='cuda:0') torch.Size([16])
percent tensor([0.9998, 0.9996, 0.9998, 0.9998, 0.9997, 0.9998, 0.9998, 0.9997, 0.9997,
        0.9997, 0.9999, 0.9998, 0.9999, 0.9989, 0.9997, 0.9994],
       device='cuda:0') torch.Size([16])
Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 3, 3, 3]) tensor(191.8955, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(841.4550, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(831.1242, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([128, 64, 3, 3]) tensor(1519.2882, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([128, 64, 1, 1]) tensor(471.1355, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([128, 128, 3, 3]) tensor(2329.3086, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([256, 128, 3, 3]) tensor(4252.0688, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([256, 128, 1, 1]) tensor(1335.4698, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([256, 256, 3, 3]) tensor(6274.1812, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([512, 256, 3, 3]) tensor(11482.5635, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([512, 256, 1, 1]) tensor(3774.1877, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([512, 512, 3, 3]) tensor(15938.8896, device='cuda:0', grad_fn=<NormBackward0>)
Epoch: 211 | Batch_idx: 0 |  Loss: (0.0372) |  Loss2: (0.0000) | Acc: (99.00%) (127/128)
Epoch: 211 | Batch_idx: 10 |  Loss: (0.0657) |  Loss2: (0.0000) | Acc: (98.00%) (1381/1408)
Epoch: 211 | Batch_idx: 20 |  Loss: (0.0619) |  Loss2: (0.0000) | Acc: (98.00%) (2638/2688)
Epoch: 211 | Batch_idx: 30 |  Loss: (0.0644) |  Loss2: (0.0000) | Acc: (97.00%) (3888/3968)
Epoch: 211 | Batch_idx: 40 |  Loss: (0.0625) |  Loss2: (0.0000) | Acc: (98.00%) (5147/5248)
Epoch: 211 | Batch_idx: 50 |  Loss: (0.0641) |  Loss2: (0.0000) | Acc: (97.00%) (6393/6528)
Epoch: 211 | Batch_idx: 60 |  Loss: (0.0632) |  Loss2: (0.0000) | Acc: (97.00%) (7644/7808)
Epoch: 211 | Batch_idx: 70 |  Loss: (0.0618) |  Loss2: (0.0000) | Acc: (98.00%) (8908/9088)
Epoch: 211 | Batch_idx: 80 |  Loss: (0.0614) |  Loss2: (0.0000) | Acc: (98.00%) (10166/10368)
Epoch: 211 | Batch_idx: 90 |  Loss: (0.0611) |  Loss2: (0.0000) | Acc: (98.00%) (11423/11648)
Epoch: 211 | Batch_idx: 100 |  Loss: (0.0619) |  Loss2: (0.0000) | Acc: (98.00%) (12675/12928)
Epoch: 211 | Batch_idx: 110 |  Loss: (0.0625) |  Loss2: (0.0000) | Acc: (98.00%) (13924/14208)
Epoch: 211 | Batch_idx: 120 |  Loss: (0.0630) |  Loss2: (0.0000) | Acc: (97.00%) (15177/15488)
Epoch: 211 | Batch_idx: 130 |  Loss: (0.0627) |  Loss2: (0.0000) | Acc: (98.00%) (16438/16768)
Epoch: 211 | Batch_idx: 140 |  Loss: (0.0635) |  Loss2: (0.0000) | Acc: (97.00%) (17680/18048)
Epoch: 211 | Batch_idx: 150 |  Loss: (0.0629) |  Loss2: (0.0000) | Acc: (97.00%) (18940/19328)
Epoch: 211 | Batch_idx: 160 |  Loss: (0.0624) |  Loss2: (0.0000) | Acc: (98.00%) (20196/20608)
Epoch: 211 | Batch_idx: 170 |  Loss: (0.0624) |  Loss2: (0.0000) | Acc: (97.00%) (21446/21888)
Epoch: 211 | Batch_idx: 180 |  Loss: (0.0618) |  Loss2: (0.0000) | Acc: (98.00%) (22706/23168)
Epoch: 211 | Batch_idx: 190 |  Loss: (0.0618) |  Loss2: (0.0000) | Acc: (98.00%) (23965/24448)
Epoch: 211 | Batch_idx: 200 |  Loss: (0.0617) |  Loss2: (0.0000) | Acc: (98.00%) (25220/25728)
Epoch: 211 | Batch_idx: 210 |  Loss: (0.0621) |  Loss2: (0.0000) | Acc: (97.00%) (26467/27008)
Epoch: 211 | Batch_idx: 220 |  Loss: (0.0622) |  Loss2: (0.0000) | Acc: (97.00%) (27717/28288)
Epoch: 211 | Batch_idx: 230 |  Loss: (0.0614) |  Loss2: (0.0000) | Acc: (98.00%) (28984/29568)
Epoch: 211 | Batch_idx: 240 |  Loss: (0.0609) |  Loss2: (0.0000) | Acc: (98.00%) (30244/30848)
Epoch: 211 | Batch_idx: 250 |  Loss: (0.0615) |  Loss2: (0.0000) | Acc: (98.00%) (31494/32128)
Epoch: 211 | Batch_idx: 260 |  Loss: (0.0619) |  Loss2: (0.0000) | Acc: (97.00%) (32739/33408)
Epoch: 211 | Batch_idx: 270 |  Loss: (0.0620) |  Loss2: (0.0000) | Acc: (97.00%) (33988/34688)
Epoch: 211 | Batch_idx: 280 |  Loss: (0.0618) |  Loss2: (0.0000) | Acc: (97.00%) (35247/35968)
Epoch: 211 | Batch_idx: 290 |  Loss: (0.0615) |  Loss2: (0.0000) | Acc: (98.00%) (36506/37248)
Epoch: 211 | Batch_idx: 300 |  Loss: (0.0616) |  Loss2: (0.0000) | Acc: (98.00%) (37762/38528)
Epoch: 211 | Batch_idx: 310 |  Loss: (0.0621) |  Loss2: (0.0000) | Acc: (97.00%) (39004/39808)
Epoch: 211 | Batch_idx: 320 |  Loss: (0.0625) |  Loss2: (0.0000) | Acc: (97.00%) (40251/41088)
Epoch: 211 | Batch_idx: 330 |  Loss: (0.0624) |  Loss2: (0.0000) | Acc: (97.00%) (41513/42368)
Epoch: 211 | Batch_idx: 340 |  Loss: (0.0625) |  Loss2: (0.0000) | Acc: (97.00%) (42765/43648)
Epoch: 211 | Batch_idx: 350 |  Loss: (0.0630) |  Loss2: (0.0000) | Acc: (97.00%) (44005/44928)
Epoch: 211 | Batch_idx: 360 |  Loss: (0.0630) |  Loss2: (0.0000) | Acc: (97.00%) (45261/46208)
Epoch: 211 | Batch_idx: 370 |  Loss: (0.0629) |  Loss2: (0.0000) | Acc: (97.00%) (46519/47488)
Epoch: 211 | Batch_idx: 380 |  Loss: (0.0628) |  Loss2: (0.0000) | Acc: (97.00%) (47776/48768)
Epoch: 211 | Batch_idx: 390 |  Loss: (0.0626) |  Loss2: (0.0000) | Acc: (97.00%) (48988/50000)
# TEST : Loss: (0.4240) | Acc: (88.00%) (8859/10000)
percent tensor([0.5291, 0.5212, 0.5331, 0.5275, 0.5381, 0.5353, 0.5281, 0.5310, 0.5350,
        0.5238, 0.5316, 0.5291, 0.5219, 0.5298, 0.5268, 0.5262],
       device='cuda:0') torch.Size([16])
percent tensor([0.5076, 0.5026, 0.5079, 0.5070, 0.5056, 0.5072, 0.5045, 0.5093, 0.5115,
        0.5056, 0.5103, 0.5027, 0.5007, 0.5165, 0.5025, 0.5092],
       device='cuda:0') torch.Size([16])
percent tensor([0.5769, 0.5523, 0.5855, 0.6056, 0.5960, 0.5868, 0.5854, 0.5984, 0.5856,
        0.5631, 0.5676, 0.5792, 0.5251, 0.6378, 0.5670, 0.5946],
       device='cuda:0') torch.Size([16])
percent tensor([0.6435, 0.6685, 0.6481, 0.6423, 0.6351, 0.6408, 0.6595, 0.6341, 0.6758,
        0.6767, 0.6833, 0.6652, 0.6702, 0.6873, 0.6363, 0.6592],
       device='cuda:0') torch.Size([16])
percent tensor([0.6277, 0.7097, 0.5822, 0.6725, 0.5784, 0.6777, 0.6653, 0.4399, 0.7429,
        0.7017, 0.7550, 0.6541, 0.6977, 0.7396, 0.5891, 0.6681],
       device='cuda:0') torch.Size([16])
percent tensor([0.6852, 0.6983, 0.6907, 0.6878, 0.7329, 0.7039, 0.7051, 0.7091, 0.7000,
        0.6954, 0.6567, 0.6402, 0.6718, 0.6787, 0.6694, 0.7105],
       device='cuda:0') torch.Size([16])
percent tensor([0.5669, 0.6370, 0.7479, 0.6605, 0.7398, 0.7930, 0.6516, 0.6699, 0.6614,
        0.6071, 0.7051, 0.5838, 0.6487, 0.5852, 0.6100, 0.5119],
       device='cuda:0') torch.Size([16])
percent tensor([0.9998, 0.9996, 0.9999, 0.9999, 0.9998, 0.9999, 0.9998, 0.9997, 0.9998,
        0.9998, 1.0000, 0.9999, 0.9999, 0.9992, 0.9996, 0.9996],
       device='cuda:0') torch.Size([16])
Epoch: 212 | Batch_idx: 0 |  Loss: (0.0610) |  Loss2: (0.0000) | Acc: (97.00%) (125/128)
Epoch: 212 | Batch_idx: 10 |  Loss: (0.0548) |  Loss2: (0.0000) | Acc: (98.00%) (1384/1408)
Epoch: 212 | Batch_idx: 20 |  Loss: (0.0593) |  Loss2: (0.0000) | Acc: (97.00%) (2633/2688)
Epoch: 212 | Batch_idx: 30 |  Loss: (0.0630) |  Loss2: (0.0000) | Acc: (97.00%) (3877/3968)
Epoch: 212 | Batch_idx: 40 |  Loss: (0.0609) |  Loss2: (0.0000) | Acc: (97.00%) (5136/5248)
Epoch: 212 | Batch_idx: 50 |  Loss: (0.0607) |  Loss2: (0.0000) | Acc: (97.00%) (6395/6528)
Epoch: 212 | Batch_idx: 60 |  Loss: (0.0594) |  Loss2: (0.0000) | Acc: (98.00%) (7652/7808)
Epoch: 212 | Batch_idx: 70 |  Loss: (0.0585) |  Loss2: (0.0000) | Acc: (98.00%) (8915/9088)
Epoch: 212 | Batch_idx: 80 |  Loss: (0.0599) |  Loss2: (0.0000) | Acc: (98.00%) (10166/10368)
Epoch: 212 | Batch_idx: 90 |  Loss: (0.0615) |  Loss2: (0.0000) | Acc: (97.00%) (11415/11648)
Epoch: 212 | Batch_idx: 100 |  Loss: (0.0623) |  Loss2: (0.0000) | Acc: (97.00%) (12669/12928)
Epoch: 212 | Batch_idx: 110 |  Loss: (0.0614) |  Loss2: (0.0000) | Acc: (98.00%) (13932/14208)
Epoch: 212 | Batch_idx: 120 |  Loss: (0.0618) |  Loss2: (0.0000) | Acc: (98.00%) (15185/15488)
Epoch: 212 | Batch_idx: 130 |  Loss: (0.0610) |  Loss2: (0.0000) | Acc: (98.00%) (16445/16768)
Epoch: 212 | Batch_idx: 140 |  Loss: (0.0605) |  Loss2: (0.0000) | Acc: (98.00%) (17698/18048)
Epoch: 212 | Batch_idx: 150 |  Loss: (0.0601) |  Loss2: (0.0000) | Acc: (98.00%) (18955/19328)
Epoch: 212 | Batch_idx: 160 |  Loss: (0.0606) |  Loss2: (0.0000) | Acc: (98.00%) (20210/20608)
Epoch: 212 | Batch_idx: 170 |  Loss: (0.0610) |  Loss2: (0.0000) | Acc: (98.00%) (21460/21888)
Epoch: 212 | Batch_idx: 180 |  Loss: (0.0608) |  Loss2: (0.0000) | Acc: (98.00%) (22713/23168)
Epoch: 212 | Batch_idx: 190 |  Loss: (0.0606) |  Loss2: (0.0000) | Acc: (98.00%) (23971/24448)
Epoch: 212 | Batch_idx: 200 |  Loss: (0.0607) |  Loss2: (0.0000) | Acc: (98.00%) (25222/25728)
Epoch: 212 | Batch_idx: 210 |  Loss: (0.0609) |  Loss2: (0.0000) | Acc: (98.00%) (26474/27008)
Epoch: 212 | Batch_idx: 220 |  Loss: (0.0608) |  Loss2: (0.0000) | Acc: (98.00%) (27728/28288)
Epoch: 212 | Batch_idx: 230 |  Loss: (0.0608) |  Loss2: (0.0000) | Acc: (98.00%) (28978/29568)
Epoch: 212 | Batch_idx: 240 |  Loss: (0.0611) |  Loss2: (0.0000) | Acc: (97.00%) (30223/30848)
Epoch: 212 | Batch_idx: 250 |  Loss: (0.0611) |  Loss2: (0.0000) | Acc: (97.00%) (31478/32128)
Epoch: 212 | Batch_idx: 260 |  Loss: (0.0615) |  Loss2: (0.0000) | Acc: (97.00%) (32724/33408)
Epoch: 212 | Batch_idx: 270 |  Loss: (0.0610) |  Loss2: (0.0000) | Acc: (97.00%) (33987/34688)
Epoch: 212 | Batch_idx: 280 |  Loss: (0.0611) |  Loss2: (0.0000) | Acc: (97.00%) (35245/35968)
Epoch: 212 | Batch_idx: 290 |  Loss: (0.0610) |  Loss2: (0.0000) | Acc: (97.00%) (36502/37248)
Epoch: 212 | Batch_idx: 300 |  Loss: (0.0607) |  Loss2: (0.0000) | Acc: (98.00%) (37766/38528)
Epoch: 212 | Batch_idx: 310 |  Loss: (0.0608) |  Loss2: (0.0000) | Acc: (98.00%) (39025/39808)
Epoch: 212 | Batch_idx: 320 |  Loss: (0.0606) |  Loss2: (0.0000) | Acc: (98.00%) (40278/41088)
Epoch: 212 | Batch_idx: 330 |  Loss: (0.0606) |  Loss2: (0.0000) | Acc: (98.00%) (41536/42368)
Epoch: 212 | Batch_idx: 340 |  Loss: (0.0611) |  Loss2: (0.0000) | Acc: (98.00%) (42785/43648)
Epoch: 212 | Batch_idx: 350 |  Loss: (0.0610) |  Loss2: (0.0000) | Acc: (98.00%) (44035/44928)
Epoch: 212 | Batch_idx: 360 |  Loss: (0.0613) |  Loss2: (0.0000) | Acc: (97.00%) (45281/46208)
Epoch: 212 | Batch_idx: 370 |  Loss: (0.0615) |  Loss2: (0.0000) | Acc: (97.00%) (46533/47488)
Epoch: 212 | Batch_idx: 380 |  Loss: (0.0619) |  Loss2: (0.0000) | Acc: (97.00%) (47779/48768)
Epoch: 212 | Batch_idx: 390 |  Loss: (0.0621) |  Loss2: (0.0000) | Acc: (97.00%) (48974/50000)
# TEST : Loss: (0.4528) | Acc: (88.00%) (8802/10000)
percent tensor([0.5291, 0.5227, 0.5335, 0.5288, 0.5381, 0.5361, 0.5290, 0.5326, 0.5350,
        0.5250, 0.5324, 0.5293, 0.5219, 0.5315, 0.5280, 0.5273],
       device='cuda:0') torch.Size([16])
percent tensor([0.5071, 0.5018, 0.5067, 0.5072, 0.5051, 0.5082, 0.5038, 0.5077, 0.5103,
        0.5044, 0.5097, 0.5014, 0.4995, 0.5155, 0.5026, 0.5086],
       device='cuda:0') torch.Size([16])
percent tensor([0.5766, 0.5531, 0.5784, 0.6001, 0.5959, 0.5901, 0.5868, 0.5918, 0.5838,
        0.5601, 0.5682, 0.5745, 0.5227, 0.6368, 0.5698, 0.5930],
       device='cuda:0') torch.Size([16])
percent tensor([0.6459, 0.6707, 0.6542, 0.6509, 0.6386, 0.6505, 0.6608, 0.6318, 0.6735,
        0.6781, 0.6881, 0.6689, 0.6725, 0.6850, 0.6413, 0.6633],
       device='cuda:0') torch.Size([16])
percent tensor([0.6287, 0.7144, 0.5611, 0.6643, 0.5560, 0.6892, 0.6533, 0.4186, 0.7315,
        0.6967, 0.7630, 0.6361, 0.6935, 0.7366, 0.6008, 0.6495],
       device='cuda:0') torch.Size([16])
percent tensor([0.6904, 0.7032, 0.6959, 0.6908, 0.7404, 0.7126, 0.7081, 0.7115, 0.6967,
        0.7006, 0.6647, 0.6414, 0.6658, 0.6833, 0.6718, 0.7172],
       device='cuda:0') torch.Size([16])
percent tensor([0.5549, 0.6312, 0.7577, 0.6705, 0.7510, 0.7755, 0.6321, 0.6550, 0.6261,
        0.6103, 0.7208, 0.6381, 0.6203, 0.6098, 0.6053, 0.5049],
       device='cuda:0') torch.Size([16])
percent tensor([0.9998, 0.9996, 1.0000, 0.9998, 0.9998, 0.9996, 0.9998, 0.9999, 0.9997,
        0.9999, 0.9999, 0.9999, 0.9998, 0.9991, 0.9998, 0.9995],
       device='cuda:0') torch.Size([16])
Epoch: 213 | Batch_idx: 0 |  Loss: (0.0964) |  Loss2: (0.0000) | Acc: (97.00%) (125/128)
Epoch: 213 | Batch_idx: 10 |  Loss: (0.0569) |  Loss2: (0.0000) | Acc: (98.00%) (1387/1408)
Epoch: 213 | Batch_idx: 20 |  Loss: (0.0617) |  Loss2: (0.0000) | Acc: (98.00%) (2639/2688)
Epoch: 213 | Batch_idx: 30 |  Loss: (0.0621) |  Loss2: (0.0000) | Acc: (98.00%) (3892/3968)
Epoch: 213 | Batch_idx: 40 |  Loss: (0.0598) |  Loss2: (0.0000) | Acc: (98.00%) (5152/5248)
Epoch: 213 | Batch_idx: 50 |  Loss: (0.0587) |  Loss2: (0.0000) | Acc: (98.00%) (6408/6528)
Epoch: 213 | Batch_idx: 60 |  Loss: (0.0583) |  Loss2: (0.0000) | Acc: (98.00%) (7658/7808)
Epoch: 213 | Batch_idx: 70 |  Loss: (0.0590) |  Loss2: (0.0000) | Acc: (98.00%) (8912/9088)
Epoch: 213 | Batch_idx: 80 |  Loss: (0.0596) |  Loss2: (0.0000) | Acc: (98.00%) (10164/10368)
Epoch: 213 | Batch_idx: 90 |  Loss: (0.0587) |  Loss2: (0.0000) | Acc: (98.00%) (11427/11648)
Epoch: 213 | Batch_idx: 100 |  Loss: (0.0604) |  Loss2: (0.0000) | Acc: (98.00%) (12674/12928)
Epoch: 213 | Batch_idx: 110 |  Loss: (0.0606) |  Loss2: (0.0000) | Acc: (98.00%) (13927/14208)
Epoch: 213 | Batch_idx: 120 |  Loss: (0.0598) |  Loss2: (0.0000) | Acc: (98.00%) (15186/15488)
Epoch: 213 | Batch_idx: 130 |  Loss: (0.0599) |  Loss2: (0.0000) | Acc: (98.00%) (16449/16768)
Epoch: 213 | Batch_idx: 140 |  Loss: (0.0595) |  Loss2: (0.0000) | Acc: (98.00%) (17708/18048)
Epoch: 213 | Batch_idx: 150 |  Loss: (0.0601) |  Loss2: (0.0000) | Acc: (98.00%) (18962/19328)
Epoch: 213 | Batch_idx: 160 |  Loss: (0.0599) |  Loss2: (0.0000) | Acc: (98.00%) (20217/20608)
Epoch: 213 | Batch_idx: 170 |  Loss: (0.0603) |  Loss2: (0.0000) | Acc: (98.00%) (21464/21888)
Epoch: 213 | Batch_idx: 180 |  Loss: (0.0608) |  Loss2: (0.0000) | Acc: (98.00%) (22714/23168)
Epoch: 213 | Batch_idx: 190 |  Loss: (0.0611) |  Loss2: (0.0000) | Acc: (98.00%) (23962/24448)
Epoch: 213 | Batch_idx: 200 |  Loss: (0.0612) |  Loss2: (0.0000) | Acc: (97.00%) (25211/25728)
Epoch: 213 | Batch_idx: 210 |  Loss: (0.0620) |  Loss2: (0.0000) | Acc: (97.00%) (26451/27008)
Epoch: 213 | Batch_idx: 220 |  Loss: (0.0620) |  Loss2: (0.0000) | Acc: (97.00%) (27703/28288)
Epoch: 213 | Batch_idx: 230 |  Loss: (0.0620) |  Loss2: (0.0000) | Acc: (97.00%) (28958/29568)
Epoch: 213 | Batch_idx: 240 |  Loss: (0.0623) |  Loss2: (0.0000) | Acc: (97.00%) (30208/30848)
Epoch: 213 | Batch_idx: 250 |  Loss: (0.0623) |  Loss2: (0.0000) | Acc: (97.00%) (31462/32128)
Epoch: 213 | Batch_idx: 260 |  Loss: (0.0617) |  Loss2: (0.0000) | Acc: (97.00%) (32722/33408)
Epoch: 213 | Batch_idx: 270 |  Loss: (0.0616) |  Loss2: (0.0000) | Acc: (97.00%) (33972/34688)
Epoch: 213 | Batch_idx: 280 |  Loss: (0.0618) |  Loss2: (0.0000) | Acc: (97.00%) (35220/35968)
Epoch: 213 | Batch_idx: 290 |  Loss: (0.0615) |  Loss2: (0.0000) | Acc: (97.00%) (36478/37248)
Epoch: 213 | Batch_idx: 300 |  Loss: (0.0613) |  Loss2: (0.0000) | Acc: (97.00%) (37736/38528)
Epoch: 213 | Batch_idx: 310 |  Loss: (0.0619) |  Loss2: (0.0000) | Acc: (97.00%) (38980/39808)
Epoch: 213 | Batch_idx: 320 |  Loss: (0.0619) |  Loss2: (0.0000) | Acc: (97.00%) (40230/41088)
Epoch: 213 | Batch_idx: 330 |  Loss: (0.0618) |  Loss2: (0.0000) | Acc: (97.00%) (41482/42368)
Epoch: 213 | Batch_idx: 340 |  Loss: (0.0620) |  Loss2: (0.0000) | Acc: (97.00%) (42731/43648)
Epoch: 213 | Batch_idx: 350 |  Loss: (0.0621) |  Loss2: (0.0000) | Acc: (97.00%) (43989/44928)
Epoch: 213 | Batch_idx: 360 |  Loss: (0.0623) |  Loss2: (0.0000) | Acc: (97.00%) (45236/46208)
Epoch: 213 | Batch_idx: 370 |  Loss: (0.0626) |  Loss2: (0.0000) | Acc: (97.00%) (46482/47488)
Epoch: 213 | Batch_idx: 380 |  Loss: (0.0631) |  Loss2: (0.0000) | Acc: (97.00%) (47725/48768)
Epoch: 213 | Batch_idx: 390 |  Loss: (0.0634) |  Loss2: (0.0000) | Acc: (97.00%) (48926/50000)
# TEST : Loss: (0.4520) | Acc: (88.00%) (8801/10000)
percent tensor([0.5297, 0.5231, 0.5358, 0.5294, 0.5412, 0.5367, 0.5306, 0.5331, 0.5362,
        0.5256, 0.5327, 0.5320, 0.5226, 0.5325, 0.5283, 0.5276],
       device='cuda:0') torch.Size([16])
percent tensor([0.5083, 0.5020, 0.5091, 0.5088, 0.5070, 0.5098, 0.5043, 0.5098, 0.5113,
        0.5050, 0.5104, 0.5037, 0.5004, 0.5151, 0.5035, 0.5097],
       device='cuda:0') torch.Size([16])
percent tensor([0.5792, 0.5538, 0.5944, 0.6061, 0.6057, 0.5943, 0.5905, 0.5999, 0.5868,
        0.5619, 0.5679, 0.5825, 0.5267, 0.6406, 0.5711, 0.5939],
       device='cuda:0') torch.Size([16])
percent tensor([0.6423, 0.6642, 0.6526, 0.6448, 0.6352, 0.6471, 0.6565, 0.6311, 0.6701,
        0.6733, 0.6820, 0.6644, 0.6701, 0.6783, 0.6359, 0.6605],
       device='cuda:0') torch.Size([16])
percent tensor([0.6194, 0.7049, 0.5629, 0.6720, 0.5589, 0.6814, 0.6568, 0.4148, 0.7190,
        0.6806, 0.7497, 0.6393, 0.6946, 0.7315, 0.5845, 0.6556],
       device='cuda:0') torch.Size([16])
percent tensor([0.6936, 0.7048, 0.7076, 0.6958, 0.7408, 0.7078, 0.7147, 0.7079, 0.7067,
        0.6970, 0.6697, 0.6580, 0.6710, 0.6893, 0.6742, 0.7093],
       device='cuda:0') torch.Size([16])
percent tensor([0.5386, 0.6169, 0.7316, 0.6374, 0.7447, 0.7719, 0.6294, 0.6277, 0.6638,
        0.5992, 0.6993, 0.6250, 0.6647, 0.5691, 0.5783, 0.5073],
       device='cuda:0') torch.Size([16])
percent tensor([0.9998, 0.9997, 0.9998, 0.9998, 0.9998, 0.9997, 0.9998, 0.9997, 0.9999,
        0.9999, 1.0000, 0.9999, 0.9999, 0.9992, 0.9998, 0.9994],
       device='cuda:0') torch.Size([16])
Epoch: 214 | Batch_idx: 0 |  Loss: (0.0916) |  Loss2: (0.0000) | Acc: (96.00%) (124/128)
Epoch: 214 | Batch_idx: 10 |  Loss: (0.0566) |  Loss2: (0.0000) | Acc: (98.00%) (1380/1408)
Epoch: 214 | Batch_idx: 20 |  Loss: (0.0594) |  Loss2: (0.0000) | Acc: (97.00%) (2633/2688)
Epoch: 214 | Batch_idx: 30 |  Loss: (0.0625) |  Loss2: (0.0000) | Acc: (97.00%) (3884/3968)
Epoch: 214 | Batch_idx: 40 |  Loss: (0.0628) |  Loss2: (0.0000) | Acc: (97.00%) (5138/5248)
Epoch: 214 | Batch_idx: 50 |  Loss: (0.0630) |  Loss2: (0.0000) | Acc: (97.00%) (6387/6528)
Epoch: 214 | Batch_idx: 60 |  Loss: (0.0646) |  Loss2: (0.0000) | Acc: (97.00%) (7628/7808)
Epoch: 214 | Batch_idx: 70 |  Loss: (0.0639) |  Loss2: (0.0000) | Acc: (97.00%) (8885/9088)
Epoch: 214 | Batch_idx: 80 |  Loss: (0.0647) |  Loss2: (0.0000) | Acc: (97.00%) (10139/10368)
Epoch: 214 | Batch_idx: 90 |  Loss: (0.0636) |  Loss2: (0.0000) | Acc: (97.00%) (11399/11648)
Epoch: 214 | Batch_idx: 100 |  Loss: (0.0631) |  Loss2: (0.0000) | Acc: (97.00%) (12655/12928)
Epoch: 214 | Batch_idx: 110 |  Loss: (0.0632) |  Loss2: (0.0000) | Acc: (97.00%) (13913/14208)
Epoch: 214 | Batch_idx: 120 |  Loss: (0.0632) |  Loss2: (0.0000) | Acc: (97.00%) (15168/15488)
Epoch: 214 | Batch_idx: 130 |  Loss: (0.0622) |  Loss2: (0.0000) | Acc: (97.00%) (16427/16768)
Epoch: 214 | Batch_idx: 140 |  Loss: (0.0616) |  Loss2: (0.0000) | Acc: (97.00%) (17684/18048)
Epoch: 214 | Batch_idx: 150 |  Loss: (0.0610) |  Loss2: (0.0000) | Acc: (98.00%) (18945/19328)
Epoch: 214 | Batch_idx: 160 |  Loss: (0.0615) |  Loss2: (0.0000) | Acc: (97.00%) (20194/20608)
Epoch: 214 | Batch_idx: 170 |  Loss: (0.0618) |  Loss2: (0.0000) | Acc: (97.00%) (21446/21888)
Epoch: 214 | Batch_idx: 180 |  Loss: (0.0621) |  Loss2: (0.0000) | Acc: (97.00%) (22694/23168)
Epoch: 214 | Batch_idx: 190 |  Loss: (0.0615) |  Loss2: (0.0000) | Acc: (97.00%) (23953/24448)
Epoch: 214 | Batch_idx: 200 |  Loss: (0.0606) |  Loss2: (0.0000) | Acc: (98.00%) (25214/25728)
Epoch: 214 | Batch_idx: 210 |  Loss: (0.0606) |  Loss2: (0.0000) | Acc: (97.00%) (26465/27008)
Epoch: 214 | Batch_idx: 220 |  Loss: (0.0611) |  Loss2: (0.0000) | Acc: (97.00%) (27709/28288)
Epoch: 214 | Batch_idx: 230 |  Loss: (0.0606) |  Loss2: (0.0000) | Acc: (97.00%) (28971/29568)
Epoch: 214 | Batch_idx: 240 |  Loss: (0.0604) |  Loss2: (0.0000) | Acc: (97.00%) (30227/30848)
Epoch: 214 | Batch_idx: 250 |  Loss: (0.0606) |  Loss2: (0.0000) | Acc: (97.00%) (31475/32128)
Epoch: 214 | Batch_idx: 260 |  Loss: (0.0607) |  Loss2: (0.0000) | Acc: (97.00%) (32725/33408)
Epoch: 214 | Batch_idx: 270 |  Loss: (0.0611) |  Loss2: (0.0000) | Acc: (97.00%) (33980/34688)
Epoch: 214 | Batch_idx: 280 |  Loss: (0.0610) |  Loss2: (0.0000) | Acc: (97.00%) (35236/35968)
Epoch: 214 | Batch_idx: 290 |  Loss: (0.0611) |  Loss2: (0.0000) | Acc: (97.00%) (36489/37248)
Epoch: 214 | Batch_idx: 300 |  Loss: (0.0609) |  Loss2: (0.0000) | Acc: (97.00%) (37750/38528)
Epoch: 214 | Batch_idx: 310 |  Loss: (0.0618) |  Loss2: (0.0000) | Acc: (97.00%) (38985/39808)
Epoch: 214 | Batch_idx: 320 |  Loss: (0.0619) |  Loss2: (0.0000) | Acc: (97.00%) (40237/41088)
Epoch: 214 | Batch_idx: 330 |  Loss: (0.0624) |  Loss2: (0.0000) | Acc: (97.00%) (41486/42368)
Epoch: 214 | Batch_idx: 340 |  Loss: (0.0626) |  Loss2: (0.0000) | Acc: (97.00%) (42735/43648)
Epoch: 214 | Batch_idx: 350 |  Loss: (0.0625) |  Loss2: (0.0000) | Acc: (97.00%) (43992/44928)
Epoch: 214 | Batch_idx: 360 |  Loss: (0.0631) |  Loss2: (0.0000) | Acc: (97.00%) (45237/46208)
Epoch: 214 | Batch_idx: 370 |  Loss: (0.0633) |  Loss2: (0.0000) | Acc: (97.00%) (46486/47488)
Epoch: 214 | Batch_idx: 380 |  Loss: (0.0633) |  Loss2: (0.0000) | Acc: (97.00%) (47742/48768)
Epoch: 214 | Batch_idx: 390 |  Loss: (0.0635) |  Loss2: (0.0000) | Acc: (97.00%) (48943/50000)
# TEST : Loss: (0.4303) | Acc: (88.00%) (8861/10000)
percent tensor([0.5303, 0.5231, 0.5333, 0.5284, 0.5384, 0.5373, 0.5293, 0.5326, 0.5354,
        0.5250, 0.5331, 0.5293, 0.5231, 0.5313, 0.5288, 0.5276],
       device='cuda:0') torch.Size([16])
percent tensor([0.5089, 0.5026, 0.5082, 0.5086, 0.5068, 0.5092, 0.5050, 0.5096, 0.5122,
        0.5051, 0.5112, 0.5030, 0.5017, 0.5163, 0.5034, 0.5104],
       device='cuda:0') torch.Size([16])
percent tensor([0.5868, 0.5560, 0.5938, 0.6134, 0.6056, 0.5970, 0.5907, 0.6072, 0.5928,
        0.5649, 0.5724, 0.5806, 0.5324, 0.6436, 0.5708, 0.6014],
       device='cuda:0') torch.Size([16])
percent tensor([0.6441, 0.6615, 0.6494, 0.6391, 0.6310, 0.6455, 0.6529, 0.6305, 0.6745,
        0.6706, 0.6859, 0.6609, 0.6733, 0.6801, 0.6329, 0.6559],
       device='cuda:0') torch.Size([16])
percent tensor([0.6216, 0.6941, 0.5585, 0.6352, 0.5645, 0.6783, 0.6546, 0.4109, 0.7350,
        0.6771, 0.7557, 0.6380, 0.6992, 0.7259, 0.5639, 0.6374],
       device='cuda:0') torch.Size([16])
percent tensor([0.6898, 0.6950, 0.6914, 0.6857, 0.7329, 0.7014, 0.7090, 0.7045, 0.6914,
        0.6874, 0.6621, 0.6479, 0.6622, 0.6835, 0.6677, 0.7108],
       device='cuda:0') torch.Size([16])
percent tensor([0.5484, 0.6092, 0.7199, 0.6255, 0.7187, 0.7631, 0.6479, 0.6123, 0.6220,
        0.5785, 0.6708, 0.5769, 0.6588, 0.5485, 0.5529, 0.4977],
       device='cuda:0') torch.Size([16])
percent tensor([0.9999, 0.9998, 0.9999, 0.9997, 0.9997, 0.9997, 0.9999, 0.9996, 0.9999,
        0.9999, 1.0000, 0.9998, 1.0000, 0.9992, 0.9998, 0.9996],
       device='cuda:0') torch.Size([16])
Epoch: 215 | Batch_idx: 0 |  Loss: (0.0435) |  Loss2: (0.0000) | Acc: (98.00%) (126/128)
Epoch: 215 | Batch_idx: 10 |  Loss: (0.0522) |  Loss2: (0.0000) | Acc: (98.00%) (1386/1408)
Epoch: 215 | Batch_idx: 20 |  Loss: (0.0504) |  Loss2: (0.0000) | Acc: (98.00%) (2647/2688)
Epoch: 215 | Batch_idx: 30 |  Loss: (0.0499) |  Loss2: (0.0000) | Acc: (98.00%) (3910/3968)
Epoch: 215 | Batch_idx: 40 |  Loss: (0.0479) |  Loss2: (0.0000) | Acc: (98.00%) (5174/5248)
Epoch: 215 | Batch_idx: 50 |  Loss: (0.0477) |  Loss2: (0.0000) | Acc: (98.00%) (6437/6528)
Epoch: 215 | Batch_idx: 60 |  Loss: (0.0494) |  Loss2: (0.0000) | Acc: (98.00%) (7689/7808)
Epoch: 215 | Batch_idx: 70 |  Loss: (0.0512) |  Loss2: (0.0000) | Acc: (98.00%) (8945/9088)
Epoch: 215 | Batch_idx: 80 |  Loss: (0.0510) |  Loss2: (0.0000) | Acc: (98.00%) (10205/10368)
Epoch: 215 | Batch_idx: 90 |  Loss: (0.0507) |  Loss2: (0.0000) | Acc: (98.00%) (11463/11648)
Epoch: 215 | Batch_idx: 100 |  Loss: (0.0519) |  Loss2: (0.0000) | Acc: (98.00%) (12717/12928)
Epoch: 215 | Batch_idx: 110 |  Loss: (0.0521) |  Loss2: (0.0000) | Acc: (98.00%) (13975/14208)
Epoch: 215 | Batch_idx: 120 |  Loss: (0.0531) |  Loss2: (0.0000) | Acc: (98.00%) (15229/15488)
Epoch: 215 | Batch_idx: 130 |  Loss: (0.0538) |  Loss2: (0.0000) | Acc: (98.00%) (16479/16768)
Epoch: 215 | Batch_idx: 140 |  Loss: (0.0543) |  Loss2: (0.0000) | Acc: (98.00%) (17730/18048)
Epoch: 215 | Batch_idx: 150 |  Loss: (0.0543) |  Loss2: (0.0000) | Acc: (98.00%) (18990/19328)
Epoch: 215 | Batch_idx: 160 |  Loss: (0.0546) |  Loss2: (0.0000) | Acc: (98.00%) (20247/20608)
Epoch: 215 | Batch_idx: 170 |  Loss: (0.0542) |  Loss2: (0.0000) | Acc: (98.00%) (21506/21888)
Epoch: 215 | Batch_idx: 180 |  Loss: (0.0537) |  Loss2: (0.0000) | Acc: (98.00%) (22771/23168)
Epoch: 215 | Batch_idx: 190 |  Loss: (0.0546) |  Loss2: (0.0000) | Acc: (98.00%) (24026/24448)
Epoch: 215 | Batch_idx: 200 |  Loss: (0.0547) |  Loss2: (0.0000) | Acc: (98.00%) (25282/25728)
Epoch: 215 | Batch_idx: 210 |  Loss: (0.0547) |  Loss2: (0.0000) | Acc: (98.00%) (26539/27008)
Epoch: 215 | Batch_idx: 220 |  Loss: (0.0545) |  Loss2: (0.0000) | Acc: (98.00%) (27796/28288)
Epoch: 215 | Batch_idx: 230 |  Loss: (0.0542) |  Loss2: (0.0000) | Acc: (98.00%) (29056/29568)
Epoch: 215 | Batch_idx: 240 |  Loss: (0.0546) |  Loss2: (0.0000) | Acc: (98.00%) (30310/30848)
Epoch: 215 | Batch_idx: 250 |  Loss: (0.0549) |  Loss2: (0.0000) | Acc: (98.00%) (31562/32128)
Epoch: 215 | Batch_idx: 260 |  Loss: (0.0551) |  Loss2: (0.0000) | Acc: (98.00%) (32819/33408)
Epoch: 215 | Batch_idx: 270 |  Loss: (0.0560) |  Loss2: (0.0000) | Acc: (98.00%) (34059/34688)
Epoch: 215 | Batch_idx: 280 |  Loss: (0.0564) |  Loss2: (0.0000) | Acc: (98.00%) (35302/35968)
Epoch: 215 | Batch_idx: 290 |  Loss: (0.0570) |  Loss2: (0.0000) | Acc: (98.00%) (36543/37248)
Epoch: 215 | Batch_idx: 300 |  Loss: (0.0582) |  Loss2: (0.0000) | Acc: (98.00%) (37783/38528)
Epoch: 215 | Batch_idx: 310 |  Loss: (0.0580) |  Loss2: (0.0000) | Acc: (98.00%) (39047/39808)
Epoch: 215 | Batch_idx: 320 |  Loss: (0.0581) |  Loss2: (0.0000) | Acc: (98.00%) (40299/41088)
Epoch: 215 | Batch_idx: 330 |  Loss: (0.0579) |  Loss2: (0.0000) | Acc: (98.00%) (41559/42368)
Epoch: 215 | Batch_idx: 340 |  Loss: (0.0583) |  Loss2: (0.0000) | Acc: (98.00%) (42807/43648)
Epoch: 215 | Batch_idx: 350 |  Loss: (0.0581) |  Loss2: (0.0000) | Acc: (98.00%) (44065/44928)
Epoch: 215 | Batch_idx: 360 |  Loss: (0.0583) |  Loss2: (0.0000) | Acc: (98.00%) (45316/46208)
Epoch: 215 | Batch_idx: 370 |  Loss: (0.0589) |  Loss2: (0.0000) | Acc: (98.00%) (46562/47488)
Epoch: 215 | Batch_idx: 380 |  Loss: (0.0587) |  Loss2: (0.0000) | Acc: (98.00%) (47820/48768)
Epoch: 215 | Batch_idx: 390 |  Loss: (0.0587) |  Loss2: (0.0000) | Acc: (98.00%) (49032/50000)
=> saving checkpoint 'drive/app/torch/save_Schedule/checkpoint_215.pth.tar'
# TEST : Loss: (0.4560) | Acc: (88.00%) (8814/10000)
percent tensor([0.5305, 0.5215, 0.5372, 0.5300, 0.5407, 0.5371, 0.5295, 0.5331, 0.5348,
        0.5251, 0.5322, 0.5324, 0.5225, 0.5291, 0.5282, 0.5270],
       device='cuda:0') torch.Size([16])
percent tensor([0.5093, 0.5028, 0.5096, 0.5083, 0.5073, 0.5103, 0.5055, 0.5095, 0.5124,
        0.5058, 0.5115, 0.5042, 0.5020, 0.5157, 0.5039, 0.5105],
       device='cuda:0') torch.Size([16])
percent tensor([0.5846, 0.5521, 0.5940, 0.6079, 0.6061, 0.5982, 0.5878, 0.5928, 0.5848,
        0.5646, 0.5681, 0.5874, 0.5298, 0.6339, 0.5711, 0.5962],
       device='cuda:0') torch.Size([16])
percent tensor([0.6520, 0.6720, 0.6490, 0.6428, 0.6350, 0.6538, 0.6584, 0.6342, 0.6779,
        0.6802, 0.6946, 0.6640, 0.6784, 0.6870, 0.6400, 0.6673],
       device='cuda:0') torch.Size([16])
percent tensor([0.6242, 0.7083, 0.5483, 0.6320, 0.5381, 0.6757, 0.6564, 0.4248, 0.7363,
        0.6941, 0.7673, 0.6342, 0.7092, 0.7341, 0.5803, 0.6415],
       device='cuda:0') torch.Size([16])
percent tensor([0.7048, 0.7147, 0.7112, 0.7036, 0.7476, 0.7129, 0.7195, 0.7262, 0.7053,
        0.7053, 0.6796, 0.6675, 0.6824, 0.6857, 0.6859, 0.7181],
       device='cuda:0') torch.Size([16])
percent tensor([0.5222, 0.6405, 0.7311, 0.6388, 0.7563, 0.7427, 0.6079, 0.6345, 0.6536,
        0.5828, 0.7050, 0.5951, 0.6389, 0.5509, 0.5911, 0.4891],
       device='cuda:0') torch.Size([16])
percent tensor([0.9998, 0.9997, 0.9998, 0.9998, 0.9997, 0.9998, 0.9998, 0.9995, 0.9998,
        0.9998, 1.0000, 0.9998, 0.9999, 0.9990, 0.9997, 0.9995],
       device='cuda:0') torch.Size([16])
Epoch: 216 | Batch_idx: 0 |  Loss: (0.0468) |  Loss2: (0.0000) | Acc: (99.00%) (127/128)
Epoch: 216 | Batch_idx: 10 |  Loss: (0.0642) |  Loss2: (0.0000) | Acc: (98.00%) (1382/1408)
Epoch: 216 | Batch_idx: 20 |  Loss: (0.0723) |  Loss2: (0.0000) | Acc: (97.00%) (2626/2688)
Epoch: 216 | Batch_idx: 30 |  Loss: (0.0687) |  Loss2: (0.0000) | Acc: (97.00%) (3879/3968)
Epoch: 216 | Batch_idx: 40 |  Loss: (0.0665) |  Loss2: (0.0000) | Acc: (97.00%) (5133/5248)
Epoch: 216 | Batch_idx: 50 |  Loss: (0.0656) |  Loss2: (0.0000) | Acc: (97.00%) (6387/6528)
Epoch: 216 | Batch_idx: 60 |  Loss: (0.0642) |  Loss2: (0.0000) | Acc: (97.00%) (7642/7808)
Epoch: 216 | Batch_idx: 70 |  Loss: (0.0651) |  Loss2: (0.0000) | Acc: (97.00%) (8889/9088)
Epoch: 216 | Batch_idx: 80 |  Loss: (0.0643) |  Loss2: (0.0000) | Acc: (97.00%) (10146/10368)
Epoch: 216 | Batch_idx: 90 |  Loss: (0.0638) |  Loss2: (0.0000) | Acc: (97.00%) (11401/11648)
Epoch: 216 | Batch_idx: 100 |  Loss: (0.0643) |  Loss2: (0.0000) | Acc: (97.00%) (12656/12928)
Epoch: 216 | Batch_idx: 110 |  Loss: (0.0642) |  Loss2: (0.0000) | Acc: (97.00%) (13906/14208)
Epoch: 216 | Batch_idx: 120 |  Loss: (0.0646) |  Loss2: (0.0000) | Acc: (97.00%) (15155/15488)
Epoch: 216 | Batch_idx: 130 |  Loss: (0.0631) |  Loss2: (0.0000) | Acc: (97.00%) (16423/16768)
Epoch: 216 | Batch_idx: 140 |  Loss: (0.0624) |  Loss2: (0.0000) | Acc: (97.00%) (17682/18048)
Epoch: 216 | Batch_idx: 150 |  Loss: (0.0628) |  Loss2: (0.0000) | Acc: (97.00%) (18932/19328)
Epoch: 216 | Batch_idx: 160 |  Loss: (0.0628) |  Loss2: (0.0000) | Acc: (97.00%) (20189/20608)
Epoch: 216 | Batch_idx: 170 |  Loss: (0.0620) |  Loss2: (0.0000) | Acc: (97.00%) (21449/21888)
Epoch: 216 | Batch_idx: 180 |  Loss: (0.0617) |  Loss2: (0.0000) | Acc: (97.00%) (22702/23168)
Epoch: 216 | Batch_idx: 190 |  Loss: (0.0611) |  Loss2: (0.0000) | Acc: (98.00%) (23967/24448)
Epoch: 216 | Batch_idx: 200 |  Loss: (0.0615) |  Loss2: (0.0000) | Acc: (98.00%) (25215/25728)
Epoch: 216 | Batch_idx: 210 |  Loss: (0.0613) |  Loss2: (0.0000) | Acc: (98.00%) (26469/27008)
Epoch: 216 | Batch_idx: 220 |  Loss: (0.0616) |  Loss2: (0.0000) | Acc: (97.00%) (27718/28288)
Epoch: 216 | Batch_idx: 230 |  Loss: (0.0611) |  Loss2: (0.0000) | Acc: (97.00%) (28973/29568)
Epoch: 216 | Batch_idx: 240 |  Loss: (0.0610) |  Loss2: (0.0000) | Acc: (97.00%) (30224/30848)
Epoch: 216 | Batch_idx: 250 |  Loss: (0.0610) |  Loss2: (0.0000) | Acc: (97.00%) (31477/32128)
Epoch: 216 | Batch_idx: 260 |  Loss: (0.0611) |  Loss2: (0.0000) | Acc: (97.00%) (32732/33408)
Epoch: 216 | Batch_idx: 270 |  Loss: (0.0611) |  Loss2: (0.0000) | Acc: (97.00%) (33985/34688)
Epoch: 216 | Batch_idx: 280 |  Loss: (0.0609) |  Loss2: (0.0000) | Acc: (97.00%) (35244/35968)
Epoch: 216 | Batch_idx: 290 |  Loss: (0.0614) |  Loss2: (0.0000) | Acc: (97.00%) (36488/37248)
Epoch: 216 | Batch_idx: 300 |  Loss: (0.0613) |  Loss2: (0.0000) | Acc: (97.00%) (37744/38528)
Epoch: 216 | Batch_idx: 310 |  Loss: (0.0612) |  Loss2: (0.0000) | Acc: (97.00%) (38998/39808)
Epoch: 216 | Batch_idx: 320 |  Loss: (0.0612) |  Loss2: (0.0000) | Acc: (97.00%) (40249/41088)
Epoch: 216 | Batch_idx: 330 |  Loss: (0.0609) |  Loss2: (0.0000) | Acc: (97.00%) (41511/42368)
Epoch: 216 | Batch_idx: 340 |  Loss: (0.0604) |  Loss2: (0.0000) | Acc: (97.00%) (42773/43648)
Epoch: 216 | Batch_idx: 350 |  Loss: (0.0602) |  Loss2: (0.0000) | Acc: (97.00%) (44027/44928)
Epoch: 216 | Batch_idx: 360 |  Loss: (0.0606) |  Loss2: (0.0000) | Acc: (97.00%) (45276/46208)
Epoch: 216 | Batch_idx: 370 |  Loss: (0.0603) |  Loss2: (0.0000) | Acc: (97.00%) (46533/47488)
Epoch: 216 | Batch_idx: 380 |  Loss: (0.0605) |  Loss2: (0.0000) | Acc: (97.00%) (47788/48768)
Epoch: 216 | Batch_idx: 390 |  Loss: (0.0603) |  Loss2: (0.0000) | Acc: (98.00%) (49001/50000)
# TEST : Loss: (0.4168) | Acc: (88.00%) (8880/10000)
percent tensor([0.5324, 0.5233, 0.5360, 0.5299, 0.5418, 0.5395, 0.5310, 0.5327, 0.5362,
        0.5260, 0.5340, 0.5322, 0.5240, 0.5294, 0.5304, 0.5287],
       device='cuda:0') torch.Size([16])
percent tensor([0.5091, 0.5034, 0.5076, 0.5076, 0.5061, 0.5105, 0.5057, 0.5095, 0.5129,
        0.5061, 0.5119, 0.5026, 0.5016, 0.5176, 0.5040, 0.5110],
       device='cuda:0') torch.Size([16])
percent tensor([0.5782, 0.5580, 0.5808, 0.5995, 0.5941, 0.5943, 0.5907, 0.5990, 0.5901,
        0.5642, 0.5717, 0.5737, 0.5278, 0.6467, 0.5679, 0.5960],
       device='cuda:0') torch.Size([16])
percent tensor([0.6499, 0.6677, 0.6503, 0.6442, 0.6400, 0.6562, 0.6589, 0.6360, 0.6744,
        0.6786, 0.6901, 0.6613, 0.6706, 0.6863, 0.6407, 0.6665],
       device='cuda:0') torch.Size([16])
percent tensor([0.6439, 0.7111, 0.5444, 0.6487, 0.5480, 0.7000, 0.6548, 0.4159, 0.7274,
        0.6920, 0.7575, 0.6175, 0.7071, 0.7388, 0.6042, 0.6623],
       device='cuda:0') torch.Size([16])
percent tensor([0.6990, 0.7122, 0.7033, 0.6989, 0.7497, 0.7118, 0.7192, 0.7132, 0.7090,
        0.7025, 0.6771, 0.6604, 0.6786, 0.6909, 0.6773, 0.7178],
       device='cuda:0') torch.Size([16])
percent tensor([0.5501, 0.6317, 0.7377, 0.6461, 0.7584, 0.7588, 0.6318, 0.6362, 0.6760,
        0.6130, 0.7264, 0.6036, 0.6469, 0.6151, 0.5794, 0.4803],
       device='cuda:0') torch.Size([16])
percent tensor([0.9998, 0.9997, 0.9999, 0.9999, 0.9997, 0.9998, 0.9997, 0.9995, 0.9998,
        0.9998, 1.0000, 0.9999, 0.9999, 0.9989, 0.9997, 0.9995],
       device='cuda:0') torch.Size([16])
Epoch: 217 | Batch_idx: 0 |  Loss: (0.0638) |  Loss2: (0.0000) | Acc: (97.00%) (125/128)
Epoch: 217 | Batch_idx: 10 |  Loss: (0.0601) |  Loss2: (0.0000) | Acc: (98.00%) (1381/1408)
Epoch: 217 | Batch_idx: 20 |  Loss: (0.0566) |  Loss2: (0.0000) | Acc: (98.00%) (2640/2688)
Epoch: 217 | Batch_idx: 30 |  Loss: (0.0540) |  Loss2: (0.0000) | Acc: (98.00%) (3897/3968)
Epoch: 217 | Batch_idx: 40 |  Loss: (0.0546) |  Loss2: (0.0000) | Acc: (98.00%) (5154/5248)
Epoch: 217 | Batch_idx: 50 |  Loss: (0.0557) |  Loss2: (0.0000) | Acc: (98.00%) (6408/6528)
Epoch: 217 | Batch_idx: 60 |  Loss: (0.0555) |  Loss2: (0.0000) | Acc: (98.00%) (7664/7808)
Epoch: 217 | Batch_idx: 70 |  Loss: (0.0580) |  Loss2: (0.0000) | Acc: (98.00%) (8907/9088)
Epoch: 217 | Batch_idx: 80 |  Loss: (0.0565) |  Loss2: (0.0000) | Acc: (98.00%) (10169/10368)
Epoch: 217 | Batch_idx: 90 |  Loss: (0.0556) |  Loss2: (0.0000) | Acc: (98.00%) (11434/11648)
Epoch: 217 | Batch_idx: 100 |  Loss: (0.0557) |  Loss2: (0.0000) | Acc: (98.00%) (12691/12928)
Epoch: 217 | Batch_idx: 110 |  Loss: (0.0562) |  Loss2: (0.0000) | Acc: (98.00%) (13945/14208)
Epoch: 217 | Batch_idx: 120 |  Loss: (0.0566) |  Loss2: (0.0000) | Acc: (98.00%) (15199/15488)
Epoch: 217 | Batch_idx: 130 |  Loss: (0.0574) |  Loss2: (0.0000) | Acc: (98.00%) (16454/16768)
Epoch: 217 | Batch_idx: 140 |  Loss: (0.0567) |  Loss2: (0.0000) | Acc: (98.00%) (17717/18048)
Epoch: 217 | Batch_idx: 150 |  Loss: (0.0559) |  Loss2: (0.0000) | Acc: (98.00%) (18986/19328)
Epoch: 217 | Batch_idx: 160 |  Loss: (0.0561) |  Loss2: (0.0000) | Acc: (98.00%) (20241/20608)
Epoch: 217 | Batch_idx: 170 |  Loss: (0.0566) |  Loss2: (0.0000) | Acc: (98.00%) (21491/21888)
Epoch: 217 | Batch_idx: 180 |  Loss: (0.0568) |  Loss2: (0.0000) | Acc: (98.00%) (22745/23168)
Epoch: 217 | Batch_idx: 190 |  Loss: (0.0570) |  Loss2: (0.0000) | Acc: (98.00%) (24000/24448)
Epoch: 217 | Batch_idx: 200 |  Loss: (0.0573) |  Loss2: (0.0000) | Acc: (98.00%) (25256/25728)
Epoch: 217 | Batch_idx: 210 |  Loss: (0.0570) |  Loss2: (0.0000) | Acc: (98.00%) (26519/27008)
Epoch: 217 | Batch_idx: 220 |  Loss: (0.0572) |  Loss2: (0.0000) | Acc: (98.00%) (27768/28288)
Epoch: 217 | Batch_idx: 230 |  Loss: (0.0580) |  Loss2: (0.0000) | Acc: (98.00%) (29014/29568)
Epoch: 217 | Batch_idx: 240 |  Loss: (0.0582) |  Loss2: (0.0000) | Acc: (98.00%) (30264/30848)
Epoch: 217 | Batch_idx: 250 |  Loss: (0.0585) |  Loss2: (0.0000) | Acc: (98.00%) (31514/32128)
Epoch: 217 | Batch_idx: 260 |  Loss: (0.0586) |  Loss2: (0.0000) | Acc: (98.00%) (32768/33408)
Epoch: 217 | Batch_idx: 270 |  Loss: (0.0585) |  Loss2: (0.0000) | Acc: (98.00%) (34023/34688)
Epoch: 217 | Batch_idx: 280 |  Loss: (0.0586) |  Loss2: (0.0000) | Acc: (98.00%) (35274/35968)
Epoch: 217 | Batch_idx: 290 |  Loss: (0.0589) |  Loss2: (0.0000) | Acc: (98.00%) (36525/37248)
Epoch: 217 | Batch_idx: 300 |  Loss: (0.0587) |  Loss2: (0.0000) | Acc: (98.00%) (37779/38528)
Epoch: 217 | Batch_idx: 310 |  Loss: (0.0590) |  Loss2: (0.0000) | Acc: (98.00%) (39029/39808)
Epoch: 217 | Batch_idx: 320 |  Loss: (0.0588) |  Loss2: (0.0000) | Acc: (98.00%) (40286/41088)
Epoch: 217 | Batch_idx: 330 |  Loss: (0.0594) |  Loss2: (0.0000) | Acc: (98.00%) (41533/42368)
Epoch: 217 | Batch_idx: 340 |  Loss: (0.0593) |  Loss2: (0.0000) | Acc: (98.00%) (42788/43648)
Epoch: 217 | Batch_idx: 350 |  Loss: (0.0595) |  Loss2: (0.0000) | Acc: (98.00%) (44045/44928)
Epoch: 217 | Batch_idx: 360 |  Loss: (0.0594) |  Loss2: (0.0000) | Acc: (98.00%) (45299/46208)
Epoch: 217 | Batch_idx: 370 |  Loss: (0.0594) |  Loss2: (0.0000) | Acc: (98.00%) (46553/47488)
Epoch: 217 | Batch_idx: 380 |  Loss: (0.0589) |  Loss2: (0.0000) | Acc: (98.00%) (47816/48768)
Epoch: 217 | Batch_idx: 390 |  Loss: (0.0587) |  Loss2: (0.0000) | Acc: (98.00%) (49027/50000)
# TEST : Loss: (0.4242) | Acc: (88.00%) (8890/10000)
percent tensor([0.5319, 0.5237, 0.5353, 0.5304, 0.5407, 0.5386, 0.5306, 0.5330, 0.5363,
        0.5261, 0.5340, 0.5315, 0.5242, 0.5308, 0.5301, 0.5287],
       device='cuda:0') torch.Size([16])
percent tensor([0.5097, 0.5039, 0.5096, 0.5091, 0.5073, 0.5118, 0.5063, 0.5102, 0.5124,
        0.5068, 0.5115, 0.5041, 0.5018, 0.5186, 0.5050, 0.5118],
       device='cuda:0') torch.Size([16])
percent tensor([0.5820, 0.5523, 0.5969, 0.6073, 0.6043, 0.5963, 0.5909, 0.6010, 0.5879,
        0.5664, 0.5685, 0.5882, 0.5287, 0.6328, 0.5685, 0.5973],
       device='cuda:0') torch.Size([16])
percent tensor([0.6434, 0.6721, 0.6517, 0.6472, 0.6371, 0.6475, 0.6577, 0.6364, 0.6712,
        0.6790, 0.6866, 0.6658, 0.6699, 0.6841, 0.6389, 0.6646],
       device='cuda:0') torch.Size([16])
percent tensor([0.6316, 0.7270, 0.5506, 0.6828, 0.5479, 0.6728, 0.6697, 0.4440, 0.7403,
        0.7060, 0.7694, 0.6468, 0.7030, 0.7552, 0.6038, 0.6568],
       device='cuda:0') torch.Size([16])
percent tensor([0.6951, 0.7124, 0.7058, 0.7064, 0.7388, 0.7066, 0.7176, 0.7146, 0.7005,
        0.6971, 0.6671, 0.6628, 0.6768, 0.6810, 0.6741, 0.7175],
       device='cuda:0') torch.Size([16])
percent tensor([0.5841, 0.6201, 0.7563, 0.6790, 0.7642, 0.7813, 0.5848, 0.6355, 0.6399,
        0.5876, 0.7040, 0.6024, 0.6516, 0.5523, 0.5700, 0.4936],
       device='cuda:0') torch.Size([16])
percent tensor([0.9998, 0.9998, 0.9999, 0.9999, 0.9995, 0.9997, 0.9997, 0.9996, 0.9999,
        0.9998, 1.0000, 0.9998, 0.9999, 0.9993, 0.9997, 0.9995],
       device='cuda:0') torch.Size([16])
Epoch: 218 | Batch_idx: 0 |  Loss: (0.0087) |  Loss2: (0.0000) | Acc: (100.00%) (128/128)
Epoch: 218 | Batch_idx: 10 |  Loss: (0.0473) |  Loss2: (0.0000) | Acc: (98.00%) (1385/1408)
Epoch: 218 | Batch_idx: 20 |  Loss: (0.0520) |  Loss2: (0.0000) | Acc: (98.00%) (2642/2688)
Epoch: 218 | Batch_idx: 30 |  Loss: (0.0551) |  Loss2: (0.0000) | Acc: (98.00%) (3893/3968)
Epoch: 218 | Batch_idx: 40 |  Loss: (0.0581) |  Loss2: (0.0000) | Acc: (98.00%) (5147/5248)
Epoch: 218 | Batch_idx: 50 |  Loss: (0.0590) |  Loss2: (0.0000) | Acc: (98.00%) (6400/6528)
Epoch: 218 | Batch_idx: 60 |  Loss: (0.0593) |  Loss2: (0.0000) | Acc: (97.00%) (7651/7808)
Epoch: 218 | Batch_idx: 70 |  Loss: (0.0585) |  Loss2: (0.0000) | Acc: (98.00%) (8912/9088)
Epoch: 218 | Batch_idx: 80 |  Loss: (0.0576) |  Loss2: (0.0000) | Acc: (98.00%) (10172/10368)
Epoch: 218 | Batch_idx: 90 |  Loss: (0.0564) |  Loss2: (0.0000) | Acc: (98.00%) (11431/11648)
Epoch: 218 | Batch_idx: 100 |  Loss: (0.0566) |  Loss2: (0.0000) | Acc: (98.00%) (12687/12928)
Epoch: 218 | Batch_idx: 110 |  Loss: (0.0564) |  Loss2: (0.0000) | Acc: (98.00%) (13940/14208)
Epoch: 218 | Batch_idx: 120 |  Loss: (0.0572) |  Loss2: (0.0000) | Acc: (98.00%) (15195/15488)
Epoch: 218 | Batch_idx: 130 |  Loss: (0.0570) |  Loss2: (0.0000) | Acc: (98.00%) (16455/16768)
Epoch: 218 | Batch_idx: 140 |  Loss: (0.0561) |  Loss2: (0.0000) | Acc: (98.00%) (17725/18048)
Epoch: 218 | Batch_idx: 150 |  Loss: (0.0560) |  Loss2: (0.0000) | Acc: (98.00%) (18984/19328)
Epoch: 218 | Batch_idx: 160 |  Loss: (0.0553) |  Loss2: (0.0000) | Acc: (98.00%) (20246/20608)
Epoch: 218 | Batch_idx: 170 |  Loss: (0.0549) |  Loss2: (0.0000) | Acc: (98.00%) (21506/21888)
Epoch: 218 | Batch_idx: 180 |  Loss: (0.0551) |  Loss2: (0.0000) | Acc: (98.00%) (22761/23168)
Epoch: 218 | Batch_idx: 190 |  Loss: (0.0551) |  Loss2: (0.0000) | Acc: (98.00%) (24012/24448)
Epoch: 218 | Batch_idx: 200 |  Loss: (0.0554) |  Loss2: (0.0000) | Acc: (98.00%) (25265/25728)
Epoch: 218 | Batch_idx: 210 |  Loss: (0.0554) |  Loss2: (0.0000) | Acc: (98.00%) (26522/27008)
Epoch: 218 | Batch_idx: 220 |  Loss: (0.0551) |  Loss2: (0.0000) | Acc: (98.00%) (27780/28288)
Epoch: 218 | Batch_idx: 230 |  Loss: (0.0548) |  Loss2: (0.0000) | Acc: (98.00%) (29044/29568)
Epoch: 218 | Batch_idx: 240 |  Loss: (0.0553) |  Loss2: (0.0000) | Acc: (98.00%) (30294/30848)
Epoch: 218 | Batch_idx: 250 |  Loss: (0.0556) |  Loss2: (0.0000) | Acc: (98.00%) (31551/32128)
Epoch: 218 | Batch_idx: 260 |  Loss: (0.0556) |  Loss2: (0.0000) | Acc: (98.00%) (32808/33408)
Epoch: 218 | Batch_idx: 270 |  Loss: (0.0556) |  Loss2: (0.0000) | Acc: (98.00%) (34062/34688)
Epoch: 218 | Batch_idx: 280 |  Loss: (0.0559) |  Loss2: (0.0000) | Acc: (98.00%) (35316/35968)
Epoch: 218 | Batch_idx: 290 |  Loss: (0.0556) |  Loss2: (0.0000) | Acc: (98.00%) (36578/37248)
Epoch: 218 | Batch_idx: 300 |  Loss: (0.0560) |  Loss2: (0.0000) | Acc: (98.00%) (37833/38528)
Epoch: 218 | Batch_idx: 310 |  Loss: (0.0555) |  Loss2: (0.0000) | Acc: (98.00%) (39097/39808)
Epoch: 218 | Batch_idx: 320 |  Loss: (0.0555) |  Loss2: (0.0000) | Acc: (98.00%) (40357/41088)
Epoch: 218 | Batch_idx: 330 |  Loss: (0.0556) |  Loss2: (0.0000) | Acc: (98.00%) (41610/42368)
Epoch: 218 | Batch_idx: 340 |  Loss: (0.0557) |  Loss2: (0.0000) | Acc: (98.00%) (42869/43648)
Epoch: 218 | Batch_idx: 350 |  Loss: (0.0558) |  Loss2: (0.0000) | Acc: (98.00%) (44124/44928)
Epoch: 218 | Batch_idx: 360 |  Loss: (0.0562) |  Loss2: (0.0000) | Acc: (98.00%) (45371/46208)
Epoch: 218 | Batch_idx: 370 |  Loss: (0.0562) |  Loss2: (0.0000) | Acc: (98.00%) (46628/47488)
Epoch: 218 | Batch_idx: 380 |  Loss: (0.0562) |  Loss2: (0.0000) | Acc: (98.00%) (47885/48768)
Epoch: 218 | Batch_idx: 390 |  Loss: (0.0559) |  Loss2: (0.0000) | Acc: (98.00%) (49100/50000)
# TEST : Loss: (0.4310) | Acc: (88.00%) (8838/10000)
percent tensor([0.5304, 0.5239, 0.5350, 0.5299, 0.5394, 0.5358, 0.5304, 0.5338, 0.5360,
        0.5264, 0.5334, 0.5306, 0.5233, 0.5318, 0.5292, 0.5286],
       device='cuda:0') torch.Size([16])
percent tensor([0.5109, 0.5053, 0.5098, 0.5102, 0.5081, 0.5120, 0.5079, 0.5112, 0.5141,
        0.5077, 0.5131, 0.5048, 0.5035, 0.5196, 0.5060, 0.5124],
       device='cuda:0') torch.Size([16])
percent tensor([0.5823, 0.5553, 0.5882, 0.6069, 0.6032, 0.5965, 0.5927, 0.6003, 0.5896,
        0.5669, 0.5727, 0.5845, 0.5294, 0.6438, 0.5722, 0.5993],
       device='cuda:0') torch.Size([16])
percent tensor([0.6495, 0.6753, 0.6548, 0.6424, 0.6394, 0.6502, 0.6631, 0.6397, 0.6789,
        0.6852, 0.6930, 0.6691, 0.6756, 0.6911, 0.6412, 0.6680],
       device='cuda:0') torch.Size([16])
percent tensor([0.6168, 0.7109, 0.5692, 0.6444, 0.5657, 0.6657, 0.6586, 0.4158, 0.7341,
        0.7004, 0.7588, 0.6376, 0.7029, 0.7311, 0.5783, 0.6377],
       device='cuda:0') torch.Size([16])
percent tensor([0.6977, 0.7120, 0.7021, 0.6998, 0.7444, 0.7142, 0.7276, 0.7113, 0.7098,
        0.6988, 0.6713, 0.6571, 0.6819, 0.7003, 0.6789, 0.7204],
       device='cuda:0') torch.Size([16])
percent tensor([0.5319, 0.5893, 0.7373, 0.6590, 0.7451, 0.7664, 0.6219, 0.6227, 0.6259,
        0.5729, 0.6775, 0.6161, 0.6612, 0.5453, 0.5594, 0.5002],
       device='cuda:0') torch.Size([16])
percent tensor([0.9998, 0.9997, 0.9999, 0.9999, 0.9998, 0.9998, 0.9998, 0.9996, 0.9997,
        0.9998, 0.9999, 0.9999, 0.9999, 0.9993, 0.9996, 0.9994],
       device='cuda:0') torch.Size([16])
Epoch: 219 | Batch_idx: 0 |  Loss: (0.0905) |  Loss2: (0.0000) | Acc: (95.00%) (122/128)
Epoch: 219 | Batch_idx: 10 |  Loss: (0.0576) |  Loss2: (0.0000) | Acc: (97.00%) (1379/1408)
Epoch: 219 | Batch_idx: 20 |  Loss: (0.0571) |  Loss2: (0.0000) | Acc: (97.00%) (2633/2688)
Epoch: 219 | Batch_idx: 30 |  Loss: (0.0546) |  Loss2: (0.0000) | Acc: (97.00%) (3886/3968)
Epoch: 219 | Batch_idx: 40 |  Loss: (0.0508) |  Loss2: (0.0000) | Acc: (98.00%) (5153/5248)
Epoch: 219 | Batch_idx: 50 |  Loss: (0.0506) |  Loss2: (0.0000) | Acc: (98.00%) (6409/6528)
Epoch: 219 | Batch_idx: 60 |  Loss: (0.0501) |  Loss2: (0.0000) | Acc: (98.00%) (7672/7808)
Epoch: 219 | Batch_idx: 70 |  Loss: (0.0503) |  Loss2: (0.0000) | Acc: (98.00%) (8928/9088)
Epoch: 219 | Batch_idx: 80 |  Loss: (0.0510) |  Loss2: (0.0000) | Acc: (98.00%) (10187/10368)
Epoch: 219 | Batch_idx: 90 |  Loss: (0.0534) |  Loss2: (0.0000) | Acc: (98.00%) (11433/11648)
Epoch: 219 | Batch_idx: 100 |  Loss: (0.0534) |  Loss2: (0.0000) | Acc: (98.00%) (12691/12928)
Epoch: 219 | Batch_idx: 110 |  Loss: (0.0544) |  Loss2: (0.0000) | Acc: (98.00%) (13943/14208)
Epoch: 219 | Batch_idx: 120 |  Loss: (0.0549) |  Loss2: (0.0000) | Acc: (98.00%) (15202/15488)
Epoch: 219 | Batch_idx: 130 |  Loss: (0.0552) |  Loss2: (0.0000) | Acc: (98.00%) (16453/16768)
Epoch: 219 | Batch_idx: 140 |  Loss: (0.0559) |  Loss2: (0.0000) | Acc: (98.00%) (17698/18048)
Epoch: 219 | Batch_idx: 150 |  Loss: (0.0566) |  Loss2: (0.0000) | Acc: (98.00%) (18952/19328)
Epoch: 219 | Batch_idx: 160 |  Loss: (0.0568) |  Loss2: (0.0000) | Acc: (98.00%) (20204/20608)
Epoch: 219 | Batch_idx: 170 |  Loss: (0.0576) |  Loss2: (0.0000) | Acc: (98.00%) (21455/21888)
Epoch: 219 | Batch_idx: 180 |  Loss: (0.0578) |  Loss2: (0.0000) | Acc: (98.00%) (22707/23168)
Epoch: 219 | Batch_idx: 190 |  Loss: (0.0582) |  Loss2: (0.0000) | Acc: (97.00%) (23956/24448)
Epoch: 219 | Batch_idx: 200 |  Loss: (0.0581) |  Loss2: (0.0000) | Acc: (97.00%) (25209/25728)
Epoch: 219 | Batch_idx: 210 |  Loss: (0.0580) |  Loss2: (0.0000) | Acc: (97.00%) (26467/27008)
Epoch: 219 | Batch_idx: 220 |  Loss: (0.0585) |  Loss2: (0.0000) | Acc: (97.00%) (27715/28288)
Epoch: 219 | Batch_idx: 230 |  Loss: (0.0584) |  Loss2: (0.0000) | Acc: (97.00%) (28972/29568)
Epoch: 219 | Batch_idx: 240 |  Loss: (0.0584) |  Loss2: (0.0000) | Acc: (97.00%) (30231/30848)
Epoch: 219 | Batch_idx: 250 |  Loss: (0.0584) |  Loss2: (0.0000) | Acc: (98.00%) (31489/32128)
Epoch: 219 | Batch_idx: 260 |  Loss: (0.0583) |  Loss2: (0.0000) | Acc: (98.00%) (32742/33408)
Epoch: 219 | Batch_idx: 270 |  Loss: (0.0583) |  Loss2: (0.0000) | Acc: (98.00%) (33996/34688)
Epoch: 219 | Batch_idx: 280 |  Loss: (0.0583) |  Loss2: (0.0000) | Acc: (98.00%) (35253/35968)
Epoch: 219 | Batch_idx: 290 |  Loss: (0.0582) |  Loss2: (0.0000) | Acc: (98.00%) (36511/37248)
Epoch: 219 | Batch_idx: 300 |  Loss: (0.0576) |  Loss2: (0.0000) | Acc: (98.00%) (37777/38528)
Epoch: 219 | Batch_idx: 310 |  Loss: (0.0575) |  Loss2: (0.0000) | Acc: (98.00%) (39028/39808)
Epoch: 219 | Batch_idx: 320 |  Loss: (0.0572) |  Loss2: (0.0000) | Acc: (98.00%) (40289/41088)
Epoch: 219 | Batch_idx: 330 |  Loss: (0.0575) |  Loss2: (0.0000) | Acc: (98.00%) (41542/42368)
Epoch: 219 | Batch_idx: 340 |  Loss: (0.0576) |  Loss2: (0.0000) | Acc: (98.00%) (42795/43648)
Epoch: 219 | Batch_idx: 350 |  Loss: (0.0579) |  Loss2: (0.0000) | Acc: (98.00%) (44047/44928)
Epoch: 219 | Batch_idx: 360 |  Loss: (0.0583) |  Loss2: (0.0000) | Acc: (98.00%) (45299/46208)
Epoch: 219 | Batch_idx: 370 |  Loss: (0.0585) |  Loss2: (0.0000) | Acc: (98.00%) (46545/47488)
Epoch: 219 | Batch_idx: 380 |  Loss: (0.0585) |  Loss2: (0.0000) | Acc: (98.00%) (47801/48768)
Epoch: 219 | Batch_idx: 390 |  Loss: (0.0587) |  Loss2: (0.0000) | Acc: (98.00%) (49007/50000)
# TEST : Loss: (0.4499) | Acc: (88.00%) (8818/10000)
percent tensor([0.5330, 0.5259, 0.5383, 0.5328, 0.5435, 0.5386, 0.5331, 0.5355, 0.5376,
        0.5287, 0.5351, 0.5341, 0.5256, 0.5331, 0.5315, 0.5304],
       device='cuda:0') torch.Size([16])
percent tensor([0.5090, 0.5042, 0.5095, 0.5084, 0.5081, 0.5102, 0.5066, 0.5112, 0.5126,
        0.5069, 0.5115, 0.5050, 0.5018, 0.5179, 0.5050, 0.5107],
       device='cuda:0') torch.Size([16])
percent tensor([0.5785, 0.5503, 0.5875, 0.6026, 0.6011, 0.5965, 0.5887, 0.5969, 0.5867,
        0.5618, 0.5664, 0.5812, 0.5255, 0.6374, 0.5699, 0.5949],
       device='cuda:0') torch.Size([16])
percent tensor([0.6499, 0.6778, 0.6571, 0.6508, 0.6432, 0.6481, 0.6661, 0.6419, 0.6827,
        0.6855, 0.6948, 0.6727, 0.6794, 0.6936, 0.6444, 0.6697],
       device='cuda:0') torch.Size([16])
percent tensor([0.6328, 0.7218, 0.5566, 0.6601, 0.5641, 0.6692, 0.6761, 0.4468, 0.7483,
        0.7008, 0.7732, 0.6450, 0.7096, 0.7469, 0.5912, 0.6636],
       device='cuda:0') torch.Size([16])
percent tensor([0.6965, 0.7081, 0.7090, 0.7059, 0.7478, 0.7151, 0.7198, 0.7195, 0.7134,
        0.6986, 0.6726, 0.6640, 0.6810, 0.6822, 0.6836, 0.7214],
       device='cuda:0') torch.Size([16])
percent tensor([0.5593, 0.5960, 0.7617, 0.6514, 0.7240, 0.7783, 0.6116, 0.6425, 0.6266,
        0.5719, 0.7060, 0.5974, 0.6379, 0.5386, 0.5643, 0.4833],
       device='cuda:0') torch.Size([16])
percent tensor([0.9999, 0.9997, 0.9999, 0.9999, 0.9997, 0.9997, 0.9998, 0.9996, 0.9999,
        0.9999, 1.0000, 0.9999, 0.9999, 0.9992, 0.9997, 0.9994],
       device='cuda:0') torch.Size([16])
Epoch: 220 | Batch_idx: 0 |  Loss: (0.0414) |  Loss2: (0.0000) | Acc: (99.00%) (127/128)
Epoch: 220 | Batch_idx: 10 |  Loss: (0.0559) |  Loss2: (0.0000) | Acc: (98.00%) (1386/1408)
Epoch: 220 | Batch_idx: 20 |  Loss: (0.0567) |  Loss2: (0.0000) | Acc: (98.00%) (2639/2688)
Epoch: 220 | Batch_idx: 30 |  Loss: (0.0534) |  Loss2: (0.0000) | Acc: (98.00%) (3898/3968)
Epoch: 220 | Batch_idx: 40 |  Loss: (0.0501) |  Loss2: (0.0000) | Acc: (98.00%) (5162/5248)
Epoch: 220 | Batch_idx: 50 |  Loss: (0.0507) |  Loss2: (0.0000) | Acc: (98.00%) (6420/6528)
Epoch: 220 | Batch_idx: 60 |  Loss: (0.0479) |  Loss2: (0.0000) | Acc: (98.00%) (7688/7808)
Epoch: 220 | Batch_idx: 70 |  Loss: (0.0492) |  Loss2: (0.0000) | Acc: (98.00%) (8940/9088)
Epoch: 220 | Batch_idx: 80 |  Loss: (0.0494) |  Loss2: (0.0000) | Acc: (98.00%) (10199/10368)
Epoch: 220 | Batch_idx: 90 |  Loss: (0.0491) |  Loss2: (0.0000) | Acc: (98.00%) (11459/11648)
Epoch: 220 | Batch_idx: 100 |  Loss: (0.0494) |  Loss2: (0.0000) | Acc: (98.00%) (12716/12928)
Epoch: 220 | Batch_idx: 110 |  Loss: (0.0489) |  Loss2: (0.0000) | Acc: (98.00%) (13984/14208)
Epoch: 220 | Batch_idx: 120 |  Loss: (0.0493) |  Loss2: (0.0000) | Acc: (98.00%) (15248/15488)
Epoch: 220 | Batch_idx: 130 |  Loss: (0.0500) |  Loss2: (0.0000) | Acc: (98.00%) (16502/16768)
Epoch: 220 | Batch_idx: 140 |  Loss: (0.0501) |  Loss2: (0.0000) | Acc: (98.00%) (17763/18048)
Epoch: 220 | Batch_idx: 150 |  Loss: (0.0508) |  Loss2: (0.0000) | Acc: (98.00%) (19020/19328)
Epoch: 220 | Batch_idx: 160 |  Loss: (0.0512) |  Loss2: (0.0000) | Acc: (98.00%) (20276/20608)
Epoch: 220 | Batch_idx: 170 |  Loss: (0.0508) |  Loss2: (0.0000) | Acc: (98.00%) (21537/21888)
Epoch: 220 | Batch_idx: 180 |  Loss: (0.0511) |  Loss2: (0.0000) | Acc: (98.00%) (22792/23168)
Epoch: 220 | Batch_idx: 190 |  Loss: (0.0515) |  Loss2: (0.0000) | Acc: (98.00%) (24047/24448)
Epoch: 220 | Batch_idx: 200 |  Loss: (0.0515) |  Loss2: (0.0000) | Acc: (98.00%) (25307/25728)
Epoch: 220 | Batch_idx: 210 |  Loss: (0.0521) |  Loss2: (0.0000) | Acc: (98.00%) (26559/27008)
Epoch: 220 | Batch_idx: 220 |  Loss: (0.0522) |  Loss2: (0.0000) | Acc: (98.00%) (27818/28288)
Epoch: 220 | Batch_idx: 230 |  Loss: (0.0522) |  Loss2: (0.0000) | Acc: (98.00%) (29076/29568)
Epoch: 220 | Batch_idx: 240 |  Loss: (0.0517) |  Loss2: (0.0000) | Acc: (98.00%) (30340/30848)
Epoch: 220 | Batch_idx: 250 |  Loss: (0.0522) |  Loss2: (0.0000) | Acc: (98.00%) (31590/32128)
Epoch: 220 | Batch_idx: 260 |  Loss: (0.0529) |  Loss2: (0.0000) | Acc: (98.00%) (32837/33408)
Epoch: 220 | Batch_idx: 270 |  Loss: (0.0534) |  Loss2: (0.0000) | Acc: (98.00%) (34089/34688)
Epoch: 220 | Batch_idx: 280 |  Loss: (0.0532) |  Loss2: (0.0000) | Acc: (98.00%) (35351/35968)
Epoch: 220 | Batch_idx: 290 |  Loss: (0.0529) |  Loss2: (0.0000) | Acc: (98.00%) (36612/37248)
Epoch: 220 | Batch_idx: 300 |  Loss: (0.0528) |  Loss2: (0.0000) | Acc: (98.00%) (37874/38528)
Epoch: 220 | Batch_idx: 310 |  Loss: (0.0531) |  Loss2: (0.0000) | Acc: (98.00%) (39127/39808)
Epoch: 220 | Batch_idx: 320 |  Loss: (0.0532) |  Loss2: (0.0000) | Acc: (98.00%) (40384/41088)
Epoch: 220 | Batch_idx: 330 |  Loss: (0.0531) |  Loss2: (0.0000) | Acc: (98.00%) (41643/42368)
Epoch: 220 | Batch_idx: 340 |  Loss: (0.0532) |  Loss2: (0.0000) | Acc: (98.00%) (42903/43648)
Epoch: 220 | Batch_idx: 350 |  Loss: (0.0534) |  Loss2: (0.0000) | Acc: (98.00%) (44154/44928)
Epoch: 220 | Batch_idx: 360 |  Loss: (0.0534) |  Loss2: (0.0000) | Acc: (98.00%) (45407/46208)
Epoch: 220 | Batch_idx: 370 |  Loss: (0.0535) |  Loss2: (0.0000) | Acc: (98.00%) (46663/47488)
Epoch: 220 | Batch_idx: 380 |  Loss: (0.0537) |  Loss2: (0.0000) | Acc: (98.00%) (47915/48768)
Epoch: 220 | Batch_idx: 390 |  Loss: (0.0536) |  Loss2: (0.0000) | Acc: (98.00%) (49129/50000)
=> saving checkpoint 'drive/app/torch/save_Schedule/checkpoint_220.pth.tar'
# TEST : Loss: (0.4397) | Acc: (88.00%) (8856/10000)
percent tensor([0.5312, 0.5240, 0.5366, 0.5318, 0.5416, 0.5371, 0.5312, 0.5345, 0.5370,
        0.5268, 0.5338, 0.5323, 0.5241, 0.5315, 0.5300, 0.5292],
       device='cuda:0') torch.Size([16])
percent tensor([0.5116, 0.5065, 0.5102, 0.5099, 0.5083, 0.5106, 0.5083, 0.5122, 0.5151,
        0.5091, 0.5139, 0.5058, 0.5047, 0.5190, 0.5062, 0.5126],
       device='cuda:0') torch.Size([16])
percent tensor([0.5763, 0.5558, 0.5927, 0.6062, 0.6021, 0.5881, 0.5901, 0.5981, 0.5887,
        0.5640, 0.5662, 0.5812, 0.5252, 0.6427, 0.5672, 0.5927],
       device='cuda:0') torch.Size([16])
percent tensor([0.6492, 0.6727, 0.6564, 0.6468, 0.6404, 0.6477, 0.6622, 0.6381, 0.6798,
        0.6830, 0.6912, 0.6709, 0.6754, 0.6867, 0.6397, 0.6650],
       device='cuda:0') torch.Size([16])
percent tensor([0.6114, 0.6910, 0.5516, 0.6455, 0.5684, 0.6780, 0.6516, 0.4187, 0.7205,
        0.6808, 0.7431, 0.6394, 0.6713, 0.7256, 0.5746, 0.6347],
       device='cuda:0') torch.Size([16])
percent tensor([0.6993, 0.7152, 0.7084, 0.7004, 0.7447, 0.7110, 0.7230, 0.7176, 0.7171,
        0.7046, 0.6761, 0.6565, 0.6839, 0.6946, 0.6801, 0.7220],
       device='cuda:0') torch.Size([16])
percent tensor([0.5487, 0.6017, 0.7441, 0.6237, 0.7493, 0.7693, 0.6332, 0.6307, 0.6852,
        0.5975, 0.6987, 0.6060, 0.6457, 0.5250, 0.5835, 0.4975],
       device='cuda:0') torch.Size([16])
percent tensor([0.9998, 0.9996, 0.9999, 0.9999, 0.9997, 0.9997, 0.9997, 0.9997, 0.9998,
        0.9998, 0.9999, 0.9998, 0.9999, 0.9989, 0.9997, 0.9995],
       device='cuda:0') torch.Size([16])
Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 3, 3, 3]) tensor(192.9885, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(845.1915, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(834.9500, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([128, 64, 3, 3]) tensor(1520.6958, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([128, 64, 1, 1]) tensor(469.6446, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([128, 128, 3, 3]) tensor(2341.8308, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([256, 128, 3, 3]) tensor(4258.2988, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([256, 128, 1, 1]) tensor(1330.9023, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([256, 256, 3, 3]) tensor(6306.9722, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([512, 256, 3, 3]) tensor(11455.7969, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([512, 256, 1, 1]) tensor(3759.6824, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([512, 512, 3, 3]) tensor(15874.4561, device='cuda:0', grad_fn=<NormBackward0>)
Epoch: 221 | Batch_idx: 0 |  Loss: (0.0503) |  Loss2: (0.0000) | Acc: (97.00%) (125/128)
Epoch: 221 | Batch_idx: 10 |  Loss: (0.0566) |  Loss2: (0.0000) | Acc: (98.00%) (1385/1408)
Epoch: 221 | Batch_idx: 20 |  Loss: (0.0513) |  Loss2: (0.0000) | Acc: (98.00%) (2651/2688)
Epoch: 221 | Batch_idx: 30 |  Loss: (0.0494) |  Loss2: (0.0000) | Acc: (98.00%) (3915/3968)
Epoch: 221 | Batch_idx: 40 |  Loss: (0.0520) |  Loss2: (0.0000) | Acc: (98.00%) (5172/5248)
Epoch: 221 | Batch_idx: 50 |  Loss: (0.0519) |  Loss2: (0.0000) | Acc: (98.00%) (6431/6528)
Epoch: 221 | Batch_idx: 60 |  Loss: (0.0530) |  Loss2: (0.0000) | Acc: (98.00%) (7688/7808)
Epoch: 221 | Batch_idx: 70 |  Loss: (0.0516) |  Loss2: (0.0000) | Acc: (98.00%) (8952/9088)
Epoch: 221 | Batch_idx: 80 |  Loss: (0.0515) |  Loss2: (0.0000) | Acc: (98.00%) (10213/10368)
Epoch: 221 | Batch_idx: 90 |  Loss: (0.0507) |  Loss2: (0.0000) | Acc: (98.00%) (11479/11648)
Epoch: 221 | Batch_idx: 100 |  Loss: (0.0502) |  Loss2: (0.0000) | Acc: (98.00%) (12742/12928)
Epoch: 221 | Batch_idx: 110 |  Loss: (0.0501) |  Loss2: (0.0000) | Acc: (98.00%) (14000/14208)
Epoch: 221 | Batch_idx: 120 |  Loss: (0.0503) |  Loss2: (0.0000) | Acc: (98.00%) (15259/15488)
Epoch: 221 | Batch_idx: 130 |  Loss: (0.0506) |  Loss2: (0.0000) | Acc: (98.00%) (16516/16768)
Epoch: 221 | Batch_idx: 140 |  Loss: (0.0508) |  Loss2: (0.0000) | Acc: (98.00%) (17769/18048)
Epoch: 221 | Batch_idx: 150 |  Loss: (0.0515) |  Loss2: (0.0000) | Acc: (98.00%) (19020/19328)
Epoch: 221 | Batch_idx: 160 |  Loss: (0.0518) |  Loss2: (0.0000) | Acc: (98.00%) (20273/20608)
Epoch: 221 | Batch_idx: 170 |  Loss: (0.0523) |  Loss2: (0.0000) | Acc: (98.00%) (21523/21888)
Epoch: 221 | Batch_idx: 180 |  Loss: (0.0521) |  Loss2: (0.0000) | Acc: (98.00%) (22782/23168)
Epoch: 221 | Batch_idx: 190 |  Loss: (0.0523) |  Loss2: (0.0000) | Acc: (98.00%) (24043/24448)
Epoch: 221 | Batch_idx: 200 |  Loss: (0.0521) |  Loss2: (0.0000) | Acc: (98.00%) (25304/25728)
Epoch: 221 | Batch_idx: 210 |  Loss: (0.0521) |  Loss2: (0.0000) | Acc: (98.00%) (26562/27008)
Epoch: 221 | Batch_idx: 220 |  Loss: (0.0518) |  Loss2: (0.0000) | Acc: (98.00%) (27819/28288)
Epoch: 221 | Batch_idx: 230 |  Loss: (0.0513) |  Loss2: (0.0000) | Acc: (98.00%) (29082/29568)
Epoch: 221 | Batch_idx: 240 |  Loss: (0.0509) |  Loss2: (0.0000) | Acc: (98.00%) (30349/30848)
Epoch: 221 | Batch_idx: 250 |  Loss: (0.0505) |  Loss2: (0.0000) | Acc: (98.00%) (31615/32128)
Epoch: 221 | Batch_idx: 260 |  Loss: (0.0503) |  Loss2: (0.0000) | Acc: (98.00%) (32878/33408)
Epoch: 221 | Batch_idx: 270 |  Loss: (0.0505) |  Loss2: (0.0000) | Acc: (98.00%) (34137/34688)
Epoch: 221 | Batch_idx: 280 |  Loss: (0.0507) |  Loss2: (0.0000) | Acc: (98.00%) (35387/35968)
Epoch: 221 | Batch_idx: 290 |  Loss: (0.0512) |  Loss2: (0.0000) | Acc: (98.00%) (36633/37248)
Epoch: 221 | Batch_idx: 300 |  Loss: (0.0506) |  Loss2: (0.0000) | Acc: (98.00%) (37902/38528)
Epoch: 221 | Batch_idx: 310 |  Loss: (0.0510) |  Loss2: (0.0000) | Acc: (98.00%) (39159/39808)
Epoch: 221 | Batch_idx: 320 |  Loss: (0.0509) |  Loss2: (0.0000) | Acc: (98.00%) (40419/41088)
Epoch: 221 | Batch_idx: 330 |  Loss: (0.0510) |  Loss2: (0.0000) | Acc: (98.00%) (41674/42368)
Epoch: 221 | Batch_idx: 340 |  Loss: (0.0513) |  Loss2: (0.0000) | Acc: (98.00%) (42926/43648)
Epoch: 221 | Batch_idx: 350 |  Loss: (0.0515) |  Loss2: (0.0000) | Acc: (98.00%) (44189/44928)
Epoch: 221 | Batch_idx: 360 |  Loss: (0.0520) |  Loss2: (0.0000) | Acc: (98.00%) (45443/46208)
Epoch: 221 | Batch_idx: 370 |  Loss: (0.0522) |  Loss2: (0.0000) | Acc: (98.00%) (46699/47488)
Epoch: 221 | Batch_idx: 380 |  Loss: (0.0519) |  Loss2: (0.0000) | Acc: (98.00%) (47962/48768)
Epoch: 221 | Batch_idx: 390 |  Loss: (0.0521) |  Loss2: (0.0000) | Acc: (98.00%) (49166/50000)
# TEST : Loss: (0.4459) | Acc: (88.00%) (8873/10000)
percent tensor([0.5333, 0.5255, 0.5383, 0.5329, 0.5435, 0.5395, 0.5324, 0.5352, 0.5383,
        0.5280, 0.5352, 0.5339, 0.5257, 0.5319, 0.5315, 0.5305],
       device='cuda:0') torch.Size([16])
percent tensor([0.5109, 0.5049, 0.5112, 0.5101, 0.5095, 0.5111, 0.5076, 0.5123, 0.5144,
        0.5081, 0.5131, 0.5062, 0.5040, 0.5179, 0.5057, 0.5122],
       device='cuda:0') torch.Size([16])
percent tensor([0.5838, 0.5583, 0.5961, 0.6138, 0.6060, 0.6053, 0.5899, 0.6017, 0.5920,
        0.5678, 0.5731, 0.5852, 0.5311, 0.6390, 0.5750, 0.6023],
       device='cuda:0') torch.Size([16])
percent tensor([0.6468, 0.6730, 0.6524, 0.6472, 0.6395, 0.6500, 0.6607, 0.6374, 0.6770,
        0.6848, 0.6927, 0.6679, 0.6735, 0.6848, 0.6405, 0.6663],
       device='cuda:0') torch.Size([16])
percent tensor([0.6312, 0.7202, 0.5579, 0.6508, 0.5646, 0.6776, 0.6700, 0.4402, 0.7377,
        0.6995, 0.7623, 0.6285, 0.6990, 0.7494, 0.5967, 0.6544],
       device='cuda:0') torch.Size([16])
percent tensor([0.7054, 0.7132, 0.7198, 0.7080, 0.7547, 0.7180, 0.7269, 0.7204, 0.7133,
        0.7015, 0.6721, 0.6688, 0.6818, 0.6927, 0.6844, 0.7240],
       device='cuda:0') torch.Size([16])
percent tensor([0.5336, 0.6157, 0.7688, 0.6421, 0.7732, 0.7437, 0.6250, 0.6405, 0.6209,
        0.5728, 0.6656, 0.5847, 0.6422, 0.5023, 0.5973, 0.4828],
       device='cuda:0') torch.Size([16])
percent tensor([0.9998, 0.9998, 0.9999, 0.9999, 0.9998, 0.9998, 0.9999, 0.9998, 0.9998,
        0.9998, 1.0000, 0.9999, 0.9999, 0.9993, 0.9998, 0.9994],
       device='cuda:0') torch.Size([16])
Epoch: 222 | Batch_idx: 0 |  Loss: (0.0447) |  Loss2: (0.0000) | Acc: (98.00%) (126/128)
Epoch: 222 | Batch_idx: 10 |  Loss: (0.0440) |  Loss2: (0.0000) | Acc: (98.00%) (1385/1408)
Epoch: 222 | Batch_idx: 20 |  Loss: (0.0465) |  Loss2: (0.0000) | Acc: (98.00%) (2649/2688)
Epoch: 222 | Batch_idx: 30 |  Loss: (0.0472) |  Loss2: (0.0000) | Acc: (98.00%) (3908/3968)
Epoch: 222 | Batch_idx: 40 |  Loss: (0.0510) |  Loss2: (0.0000) | Acc: (98.00%) (5162/5248)
Epoch: 222 | Batch_idx: 50 |  Loss: (0.0514) |  Loss2: (0.0000) | Acc: (98.00%) (6424/6528)
Epoch: 222 | Batch_idx: 60 |  Loss: (0.0521) |  Loss2: (0.0000) | Acc: (98.00%) (7682/7808)
Epoch: 222 | Batch_idx: 70 |  Loss: (0.0525) |  Loss2: (0.0000) | Acc: (98.00%) (8938/9088)
Epoch: 222 | Batch_idx: 80 |  Loss: (0.0531) |  Loss2: (0.0000) | Acc: (98.00%) (10190/10368)
Epoch: 222 | Batch_idx: 90 |  Loss: (0.0533) |  Loss2: (0.0000) | Acc: (98.00%) (11449/11648)
Epoch: 222 | Batch_idx: 100 |  Loss: (0.0534) |  Loss2: (0.0000) | Acc: (98.00%) (12712/12928)
Epoch: 222 | Batch_idx: 110 |  Loss: (0.0537) |  Loss2: (0.0000) | Acc: (98.00%) (13969/14208)
Epoch: 222 | Batch_idx: 120 |  Loss: (0.0530) |  Loss2: (0.0000) | Acc: (98.00%) (15228/15488)
Epoch: 222 | Batch_idx: 130 |  Loss: (0.0523) |  Loss2: (0.0000) | Acc: (98.00%) (16490/16768)
Epoch: 222 | Batch_idx: 140 |  Loss: (0.0518) |  Loss2: (0.0000) | Acc: (98.00%) (17753/18048)
Epoch: 222 | Batch_idx: 150 |  Loss: (0.0529) |  Loss2: (0.0000) | Acc: (98.00%) (19004/19328)
Epoch: 222 | Batch_idx: 160 |  Loss: (0.0522) |  Loss2: (0.0000) | Acc: (98.00%) (20268/20608)
Epoch: 222 | Batch_idx: 170 |  Loss: (0.0520) |  Loss2: (0.0000) | Acc: (98.00%) (21528/21888)
Epoch: 222 | Batch_idx: 180 |  Loss: (0.0516) |  Loss2: (0.0000) | Acc: (98.00%) (22789/23168)
Epoch: 222 | Batch_idx: 190 |  Loss: (0.0516) |  Loss2: (0.0000) | Acc: (98.00%) (24045/24448)
Epoch: 222 | Batch_idx: 200 |  Loss: (0.0518) |  Loss2: (0.0000) | Acc: (98.00%) (25300/25728)
Epoch: 222 | Batch_idx: 210 |  Loss: (0.0517) |  Loss2: (0.0000) | Acc: (98.00%) (26557/27008)
Epoch: 222 | Batch_idx: 220 |  Loss: (0.0519) |  Loss2: (0.0000) | Acc: (98.00%) (27815/28288)
Epoch: 222 | Batch_idx: 230 |  Loss: (0.0521) |  Loss2: (0.0000) | Acc: (98.00%) (29072/29568)
Epoch: 222 | Batch_idx: 240 |  Loss: (0.0519) |  Loss2: (0.0000) | Acc: (98.00%) (30327/30848)
Epoch: 222 | Batch_idx: 250 |  Loss: (0.0521) |  Loss2: (0.0000) | Acc: (98.00%) (31588/32128)
Epoch: 222 | Batch_idx: 260 |  Loss: (0.0520) |  Loss2: (0.0000) | Acc: (98.00%) (32847/33408)
Epoch: 222 | Batch_idx: 270 |  Loss: (0.0520) |  Loss2: (0.0000) | Acc: (98.00%) (34103/34688)
Epoch: 222 | Batch_idx: 280 |  Loss: (0.0518) |  Loss2: (0.0000) | Acc: (98.00%) (35366/35968)
Epoch: 222 | Batch_idx: 290 |  Loss: (0.0519) |  Loss2: (0.0000) | Acc: (98.00%) (36618/37248)
Epoch: 222 | Batch_idx: 300 |  Loss: (0.0519) |  Loss2: (0.0000) | Acc: (98.00%) (37877/38528)
Epoch: 222 | Batch_idx: 310 |  Loss: (0.0520) |  Loss2: (0.0000) | Acc: (98.00%) (39128/39808)
Epoch: 222 | Batch_idx: 320 |  Loss: (0.0525) |  Loss2: (0.0000) | Acc: (98.00%) (40379/41088)
Epoch: 222 | Batch_idx: 330 |  Loss: (0.0524) |  Loss2: (0.0000) | Acc: (98.00%) (41641/42368)
Epoch: 222 | Batch_idx: 340 |  Loss: (0.0526) |  Loss2: (0.0000) | Acc: (98.00%) (42894/43648)
Epoch: 222 | Batch_idx: 350 |  Loss: (0.0527) |  Loss2: (0.0000) | Acc: (98.00%) (44149/44928)
Epoch: 222 | Batch_idx: 360 |  Loss: (0.0526) |  Loss2: (0.0000) | Acc: (98.00%) (45411/46208)
Epoch: 222 | Batch_idx: 370 |  Loss: (0.0527) |  Loss2: (0.0000) | Acc: (98.00%) (46667/47488)
Epoch: 222 | Batch_idx: 380 |  Loss: (0.0530) |  Loss2: (0.0000) | Acc: (98.00%) (47921/48768)
Epoch: 222 | Batch_idx: 390 |  Loss: (0.0532) |  Loss2: (0.0000) | Acc: (98.00%) (49132/50000)
# TEST : Loss: (0.5030) | Acc: (88.00%) (8811/10000)
percent tensor([0.5330, 0.5271, 0.5379, 0.5323, 0.5426, 0.5385, 0.5332, 0.5365, 0.5387,
        0.5291, 0.5361, 0.5338, 0.5259, 0.5342, 0.5324, 0.5310],
       device='cuda:0') torch.Size([16])
percent tensor([0.5103, 0.5040, 0.5104, 0.5101, 0.5087, 0.5109, 0.5072, 0.5126, 0.5143,
        0.5077, 0.5125, 0.5056, 0.5031, 0.5180, 0.5053, 0.5119],
       device='cuda:0') torch.Size([16])
percent tensor([0.5827, 0.5499, 0.6003, 0.6094, 0.6124, 0.5936, 0.5876, 0.6035, 0.5940,
        0.5665, 0.5699, 0.5890, 0.5280, 0.6339, 0.5671, 0.5952],
       device='cuda:0') torch.Size([16])
percent tensor([0.6525, 0.6772, 0.6586, 0.6432, 0.6437, 0.6556, 0.6653, 0.6393, 0.6850,
        0.6889, 0.6985, 0.6750, 0.6806, 0.6921, 0.6450, 0.6694],
       device='cuda:0') torch.Size([16])
percent tensor([0.6288, 0.7101, 0.5541, 0.6360, 0.5668, 0.6946, 0.6684, 0.4178, 0.7483,
        0.6976, 0.7712, 0.6284, 0.6991, 0.7507, 0.5913, 0.6554],
       device='cuda:0') torch.Size([16])
percent tensor([0.7084, 0.7179, 0.7189, 0.7128, 0.7570, 0.7266, 0.7285, 0.7245, 0.7143,
        0.7043, 0.6799, 0.6691, 0.6908, 0.6978, 0.6890, 0.7245],
       device='cuda:0') torch.Size([16])
percent tensor([0.5653, 0.6468, 0.7523, 0.6319, 0.7636, 0.7563, 0.6818, 0.6637, 0.6682,
        0.6157, 0.7069, 0.6250, 0.6425, 0.5719, 0.6087, 0.4902],
       device='cuda:0') torch.Size([16])
percent tensor([0.9999, 0.9998, 0.9999, 0.9999, 0.9998, 0.9999, 0.9999, 0.9998, 0.9999,
        0.9999, 1.0000, 0.9999, 1.0000, 0.9986, 0.9998, 0.9995],
       device='cuda:0') torch.Size([16])
Epoch: 223 | Batch_idx: 0 |  Loss: (0.0425) |  Loss2: (0.0000) | Acc: (97.00%) (125/128)
Epoch: 223 | Batch_idx: 10 |  Loss: (0.0613) |  Loss2: (0.0000) | Acc: (97.00%) (1377/1408)
Epoch: 223 | Batch_idx: 20 |  Loss: (0.0548) |  Loss2: (0.0000) | Acc: (98.00%) (2638/2688)
Epoch: 223 | Batch_idx: 30 |  Loss: (0.0529) |  Loss2: (0.0000) | Acc: (98.00%) (3900/3968)
Epoch: 223 | Batch_idx: 40 |  Loss: (0.0520) |  Loss2: (0.0000) | Acc: (98.00%) (5161/5248)
Epoch: 223 | Batch_idx: 50 |  Loss: (0.0508) |  Loss2: (0.0000) | Acc: (98.00%) (6423/6528)
Epoch: 223 | Batch_idx: 60 |  Loss: (0.0499) |  Loss2: (0.0000) | Acc: (98.00%) (7685/7808)
Epoch: 223 | Batch_idx: 70 |  Loss: (0.0495) |  Loss2: (0.0000) | Acc: (98.00%) (8945/9088)
Epoch: 223 | Batch_idx: 80 |  Loss: (0.0498) |  Loss2: (0.0000) | Acc: (98.00%) (10203/10368)
Epoch: 223 | Batch_idx: 90 |  Loss: (0.0495) |  Loss2: (0.0000) | Acc: (98.00%) (11465/11648)
Epoch: 223 | Batch_idx: 100 |  Loss: (0.0488) |  Loss2: (0.0000) | Acc: (98.00%) (12727/12928)
Epoch: 223 | Batch_idx: 110 |  Loss: (0.0484) |  Loss2: (0.0000) | Acc: (98.00%) (13988/14208)
Epoch: 223 | Batch_idx: 120 |  Loss: (0.0489) |  Loss2: (0.0000) | Acc: (98.00%) (15247/15488)
Epoch: 223 | Batch_idx: 130 |  Loss: (0.0495) |  Loss2: (0.0000) | Acc: (98.00%) (16500/16768)
Epoch: 223 | Batch_idx: 140 |  Loss: (0.0489) |  Loss2: (0.0000) | Acc: (98.00%) (17761/18048)
Epoch: 223 | Batch_idx: 150 |  Loss: (0.0497) |  Loss2: (0.0000) | Acc: (98.00%) (19014/19328)
Epoch: 223 | Batch_idx: 160 |  Loss: (0.0500) |  Loss2: (0.0000) | Acc: (98.00%) (20272/20608)
Epoch: 223 | Batch_idx: 170 |  Loss: (0.0500) |  Loss2: (0.0000) | Acc: (98.00%) (21532/21888)
Epoch: 223 | Batch_idx: 180 |  Loss: (0.0500) |  Loss2: (0.0000) | Acc: (98.00%) (22796/23168)
Epoch: 223 | Batch_idx: 190 |  Loss: (0.0498) |  Loss2: (0.0000) | Acc: (98.00%) (24057/24448)
Epoch: 223 | Batch_idx: 200 |  Loss: (0.0499) |  Loss2: (0.0000) | Acc: (98.00%) (25317/25728)
Epoch: 223 | Batch_idx: 210 |  Loss: (0.0499) |  Loss2: (0.0000) | Acc: (98.00%) (26579/27008)
Epoch: 223 | Batch_idx: 220 |  Loss: (0.0496) |  Loss2: (0.0000) | Acc: (98.00%) (27839/28288)
Epoch: 223 | Batch_idx: 230 |  Loss: (0.0500) |  Loss2: (0.0000) | Acc: (98.00%) (29091/29568)
Epoch: 223 | Batch_idx: 240 |  Loss: (0.0500) |  Loss2: (0.0000) | Acc: (98.00%) (30352/30848)
Epoch: 223 | Batch_idx: 250 |  Loss: (0.0498) |  Loss2: (0.0000) | Acc: (98.00%) (31612/32128)
Epoch: 223 | Batch_idx: 260 |  Loss: (0.0500) |  Loss2: (0.0000) | Acc: (98.00%) (32864/33408)
Epoch: 223 | Batch_idx: 270 |  Loss: (0.0499) |  Loss2: (0.0000) | Acc: (98.00%) (34125/34688)
Epoch: 223 | Batch_idx: 280 |  Loss: (0.0500) |  Loss2: (0.0000) | Acc: (98.00%) (35381/35968)
Epoch: 223 | Batch_idx: 290 |  Loss: (0.0500) |  Loss2: (0.0000) | Acc: (98.00%) (36640/37248)
Epoch: 223 | Batch_idx: 300 |  Loss: (0.0501) |  Loss2: (0.0000) | Acc: (98.00%) (37897/38528)
Epoch: 223 | Batch_idx: 310 |  Loss: (0.0503) |  Loss2: (0.0000) | Acc: (98.00%) (39150/39808)
Epoch: 223 | Batch_idx: 320 |  Loss: (0.0505) |  Loss2: (0.0000) | Acc: (98.00%) (40409/41088)
Epoch: 223 | Batch_idx: 330 |  Loss: (0.0505) |  Loss2: (0.0000) | Acc: (98.00%) (41669/42368)
Epoch: 223 | Batch_idx: 340 |  Loss: (0.0510) |  Loss2: (0.0000) | Acc: (98.00%) (42919/43648)
Epoch: 223 | Batch_idx: 350 |  Loss: (0.0511) |  Loss2: (0.0000) | Acc: (98.00%) (44173/44928)
Epoch: 223 | Batch_idx: 360 |  Loss: (0.0510) |  Loss2: (0.0000) | Acc: (98.00%) (45436/46208)
Epoch: 223 | Batch_idx: 370 |  Loss: (0.0514) |  Loss2: (0.0000) | Acc: (98.00%) (46683/47488)
Epoch: 223 | Batch_idx: 380 |  Loss: (0.0515) |  Loss2: (0.0000) | Acc: (98.00%) (47940/48768)
Epoch: 223 | Batch_idx: 390 |  Loss: (0.0513) |  Loss2: (0.0000) | Acc: (98.00%) (49153/50000)
# TEST : Loss: (0.4366) | Acc: (88.00%) (8837/10000)
percent tensor([0.5341, 0.5266, 0.5398, 0.5339, 0.5450, 0.5400, 0.5338, 0.5369, 0.5384,
        0.5290, 0.5357, 0.5355, 0.5261, 0.5331, 0.5325, 0.5312],
       device='cuda:0') torch.Size([16])
percent tensor([0.5104, 0.5050, 0.5101, 0.5101, 0.5093, 0.5115, 0.5077, 0.5115, 0.5142,
        0.5081, 0.5132, 0.5056, 0.5035, 0.5196, 0.5059, 0.5119],
       device='cuda:0') torch.Size([16])
percent tensor([0.5794, 0.5550, 0.5991, 0.6105, 0.6096, 0.5897, 0.5936, 0.6037, 0.5952,
        0.5697, 0.5721, 0.5889, 0.5305, 0.6467, 0.5676, 0.5955],
       device='cuda:0') torch.Size([16])
percent tensor([0.6526, 0.6794, 0.6547, 0.6458, 0.6402, 0.6523, 0.6670, 0.6408, 0.6859,
        0.6868, 0.7014, 0.6715, 0.6853, 0.6932, 0.6469, 0.6698],
       device='cuda:0') torch.Size([16])
percent tensor([0.6419, 0.7360, 0.5422, 0.6636, 0.5516, 0.6970, 0.6674, 0.4233, 0.7444,
        0.7104, 0.7804, 0.6375, 0.7320, 0.7424, 0.6143, 0.6778],
       device='cuda:0') torch.Size([16])
percent tensor([0.7037, 0.7205, 0.7112, 0.7103, 0.7513, 0.7152, 0.7322, 0.7213, 0.7106,
        0.7112, 0.6795, 0.6728, 0.6918, 0.6919, 0.6863, 0.7305],
       device='cuda:0') torch.Size([16])
percent tensor([0.5377, 0.6193, 0.7388, 0.6300, 0.7569, 0.7470, 0.6326, 0.6179, 0.6609,
        0.5895, 0.7171, 0.6075, 0.6660, 0.5589, 0.5972, 0.4807],
       device='cuda:0') torch.Size([16])
percent tensor([0.9998, 0.9997, 0.9999, 0.9999, 0.9998, 0.9999, 0.9999, 0.9997, 0.9998,
        0.9998, 1.0000, 0.9998, 0.9999, 0.9991, 0.9997, 0.9994],
       device='cuda:0') torch.Size([16])
Epoch: 224 | Batch_idx: 0 |  Loss: (0.0620) |  Loss2: (0.0000) | Acc: (98.00%) (126/128)
Epoch: 224 | Batch_idx: 10 |  Loss: (0.0430) |  Loss2: (0.0000) | Acc: (98.00%) (1389/1408)
Epoch: 224 | Batch_idx: 20 |  Loss: (0.0457) |  Loss2: (0.0000) | Acc: (98.00%) (2648/2688)
Epoch: 224 | Batch_idx: 30 |  Loss: (0.0478) |  Loss2: (0.0000) | Acc: (98.00%) (3903/3968)
Epoch: 224 | Batch_idx: 40 |  Loss: (0.0493) |  Loss2: (0.0000) | Acc: (98.00%) (5157/5248)
Epoch: 224 | Batch_idx: 50 |  Loss: (0.0489) |  Loss2: (0.0000) | Acc: (98.00%) (6423/6528)
Epoch: 224 | Batch_idx: 60 |  Loss: (0.0492) |  Loss2: (0.0000) | Acc: (98.00%) (7684/7808)
Epoch: 224 | Batch_idx: 70 |  Loss: (0.0488) |  Loss2: (0.0000) | Acc: (98.00%) (8942/9088)
Epoch: 224 | Batch_idx: 80 |  Loss: (0.0490) |  Loss2: (0.0000) | Acc: (98.00%) (10202/10368)
Epoch: 224 | Batch_idx: 90 |  Loss: (0.0494) |  Loss2: (0.0000) | Acc: (98.00%) (11459/11648)
Epoch: 224 | Batch_idx: 100 |  Loss: (0.0482) |  Loss2: (0.0000) | Acc: (98.00%) (12725/12928)
Epoch: 224 | Batch_idx: 110 |  Loss: (0.0478) |  Loss2: (0.0000) | Acc: (98.00%) (13991/14208)
Epoch: 224 | Batch_idx: 120 |  Loss: (0.0493) |  Loss2: (0.0000) | Acc: (98.00%) (15244/15488)
Epoch: 224 | Batch_idx: 130 |  Loss: (0.0490) |  Loss2: (0.0000) | Acc: (98.00%) (16507/16768)
Epoch: 224 | Batch_idx: 140 |  Loss: (0.0485) |  Loss2: (0.0000) | Acc: (98.00%) (17771/18048)
Epoch: 224 | Batch_idx: 150 |  Loss: (0.0484) |  Loss2: (0.0000) | Acc: (98.00%) (19031/19328)
Epoch: 224 | Batch_idx: 160 |  Loss: (0.0486) |  Loss2: (0.0000) | Acc: (98.00%) (20287/20608)
Epoch: 224 | Batch_idx: 170 |  Loss: (0.0488) |  Loss2: (0.0000) | Acc: (98.00%) (21544/21888)
Epoch: 224 | Batch_idx: 180 |  Loss: (0.0490) |  Loss2: (0.0000) | Acc: (98.00%) (22799/23168)
Epoch: 224 | Batch_idx: 190 |  Loss: (0.0492) |  Loss2: (0.0000) | Acc: (98.00%) (24055/24448)
Epoch: 224 | Batch_idx: 200 |  Loss: (0.0495) |  Loss2: (0.0000) | Acc: (98.00%) (25314/25728)
Epoch: 224 | Batch_idx: 210 |  Loss: (0.0498) |  Loss2: (0.0000) | Acc: (98.00%) (26573/27008)
Epoch: 224 | Batch_idx: 220 |  Loss: (0.0496) |  Loss2: (0.0000) | Acc: (98.00%) (27832/28288)
Epoch: 224 | Batch_idx: 230 |  Loss: (0.0498) |  Loss2: (0.0000) | Acc: (98.00%) (29092/29568)
Epoch: 224 | Batch_idx: 240 |  Loss: (0.0499) |  Loss2: (0.0000) | Acc: (98.00%) (30353/30848)
Epoch: 224 | Batch_idx: 250 |  Loss: (0.0496) |  Loss2: (0.0000) | Acc: (98.00%) (31616/32128)
Epoch: 224 | Batch_idx: 260 |  Loss: (0.0494) |  Loss2: (0.0000) | Acc: (98.00%) (32883/33408)
Epoch: 224 | Batch_idx: 270 |  Loss: (0.0496) |  Loss2: (0.0000) | Acc: (98.00%) (34146/34688)
Epoch: 224 | Batch_idx: 280 |  Loss: (0.0498) |  Loss2: (0.0000) | Acc: (98.00%) (35405/35968)
Epoch: 224 | Batch_idx: 290 |  Loss: (0.0502) |  Loss2: (0.0000) | Acc: (98.00%) (36654/37248)
Epoch: 224 | Batch_idx: 300 |  Loss: (0.0498) |  Loss2: (0.0000) | Acc: (98.00%) (37920/38528)
Epoch: 224 | Batch_idx: 310 |  Loss: (0.0495) |  Loss2: (0.0000) | Acc: (98.00%) (39184/39808)
Epoch: 224 | Batch_idx: 320 |  Loss: (0.0498) |  Loss2: (0.0000) | Acc: (98.00%) (40441/41088)
Epoch: 224 | Batch_idx: 330 |  Loss: (0.0499) |  Loss2: (0.0000) | Acc: (98.00%) (41701/42368)
Epoch: 224 | Batch_idx: 340 |  Loss: (0.0497) |  Loss2: (0.0000) | Acc: (98.00%) (42965/43648)
Epoch: 224 | Batch_idx: 350 |  Loss: (0.0497) |  Loss2: (0.0000) | Acc: (98.00%) (44218/44928)
Epoch: 224 | Batch_idx: 360 |  Loss: (0.0498) |  Loss2: (0.0000) | Acc: (98.00%) (45478/46208)
Epoch: 224 | Batch_idx: 370 |  Loss: (0.0498) |  Loss2: (0.0000) | Acc: (98.00%) (46738/47488)
Epoch: 224 | Batch_idx: 380 |  Loss: (0.0497) |  Loss2: (0.0000) | Acc: (98.00%) (48003/48768)
Epoch: 224 | Batch_idx: 390 |  Loss: (0.0500) |  Loss2: (0.0000) | Acc: (98.00%) (49208/50000)
# TEST : Loss: (0.4482) | Acc: (88.00%) (8833/10000)
percent tensor([0.5339, 0.5266, 0.5396, 0.5339, 0.5448, 0.5389, 0.5337, 0.5370, 0.5395,
        0.5294, 0.5364, 0.5354, 0.5266, 0.5341, 0.5322, 0.5312],
       device='cuda:0') torch.Size([16])
percent tensor([0.5117, 0.5056, 0.5119, 0.5116, 0.5109, 0.5126, 0.5082, 0.5132, 0.5149,
        0.5087, 0.5134, 0.5064, 0.5042, 0.5194, 0.5070, 0.5131],
       device='cuda:0') torch.Size([16])
percent tensor([0.5803, 0.5480, 0.5970, 0.6082, 0.6095, 0.5916, 0.5845, 0.6023, 0.5884,
        0.5642, 0.5653, 0.5823, 0.5250, 0.6348, 0.5660, 0.5962],
       device='cuda:0') torch.Size([16])
percent tensor([0.6527, 0.6810, 0.6579, 0.6533, 0.6440, 0.6521, 0.6681, 0.6431, 0.6845,
        0.6891, 0.6992, 0.6752, 0.6826, 0.6935, 0.6484, 0.6715],
       device='cuda:0') torch.Size([16])
percent tensor([0.6322, 0.7323, 0.5470, 0.6526, 0.5505, 0.6782, 0.6775, 0.4228, 0.7516,
        0.7037, 0.7770, 0.6338, 0.7218, 0.7635, 0.5980, 0.6637],
       device='cuda:0') torch.Size([16])
percent tensor([0.7048, 0.7199, 0.7150, 0.7155, 0.7542, 0.7246, 0.7238, 0.7230, 0.7177,
        0.7098, 0.6784, 0.6736, 0.6943, 0.6905, 0.6877, 0.7285],
       device='cuda:0') torch.Size([16])
percent tensor([0.5646, 0.6417, 0.7307, 0.6369, 0.7504, 0.7662, 0.6019, 0.6064, 0.6677,
        0.5848, 0.6873, 0.6058, 0.6634, 0.5530, 0.5874, 0.4917],
       device='cuda:0') torch.Size([16])
percent tensor([0.9999, 0.9997, 0.9998, 0.9998, 0.9998, 0.9997, 0.9998, 0.9995, 0.9998,
        0.9999, 1.0000, 0.9998, 0.9999, 0.9990, 0.9997, 0.9994],
       device='cuda:0') torch.Size([16])
Epoch: 225 | Batch_idx: 0 |  Loss: (0.0531) |  Loss2: (0.0000) | Acc: (99.00%) (127/128)
Epoch: 225 | Batch_idx: 10 |  Loss: (0.0578) |  Loss2: (0.0000) | Acc: (98.00%) (1384/1408)
Epoch: 225 | Batch_idx: 20 |  Loss: (0.0530) |  Loss2: (0.0000) | Acc: (98.00%) (2645/2688)
Epoch: 225 | Batch_idx: 30 |  Loss: (0.0538) |  Loss2: (0.0000) | Acc: (98.00%) (3897/3968)
Epoch: 225 | Batch_idx: 40 |  Loss: (0.0525) |  Loss2: (0.0000) | Acc: (98.00%) (5155/5248)
Epoch: 225 | Batch_idx: 50 |  Loss: (0.0511) |  Loss2: (0.0000) | Acc: (98.00%) (6415/6528)
Epoch: 225 | Batch_idx: 60 |  Loss: (0.0512) |  Loss2: (0.0000) | Acc: (98.00%) (7673/7808)
Epoch: 225 | Batch_idx: 70 |  Loss: (0.0494) |  Loss2: (0.0000) | Acc: (98.00%) (8935/9088)
Epoch: 225 | Batch_idx: 80 |  Loss: (0.0489) |  Loss2: (0.0000) | Acc: (98.00%) (10201/10368)
Epoch: 225 | Batch_idx: 90 |  Loss: (0.0482) |  Loss2: (0.0000) | Acc: (98.00%) (11467/11648)
Epoch: 225 | Batch_idx: 100 |  Loss: (0.0472) |  Loss2: (0.0000) | Acc: (98.00%) (12732/12928)
Epoch: 225 | Batch_idx: 110 |  Loss: (0.0470) |  Loss2: (0.0000) | Acc: (98.00%) (13993/14208)
Epoch: 225 | Batch_idx: 120 |  Loss: (0.0478) |  Loss2: (0.0000) | Acc: (98.00%) (15247/15488)
Epoch: 225 | Batch_idx: 130 |  Loss: (0.0477) |  Loss2: (0.0000) | Acc: (98.00%) (16506/16768)
Epoch: 225 | Batch_idx: 140 |  Loss: (0.0476) |  Loss2: (0.0000) | Acc: (98.00%) (17766/18048)
Epoch: 225 | Batch_idx: 150 |  Loss: (0.0474) |  Loss2: (0.0000) | Acc: (98.00%) (19030/19328)
Epoch: 225 | Batch_idx: 160 |  Loss: (0.0477) |  Loss2: (0.0000) | Acc: (98.00%) (20289/20608)
Epoch: 225 | Batch_idx: 170 |  Loss: (0.0478) |  Loss2: (0.0000) | Acc: (98.00%) (21550/21888)
Epoch: 225 | Batch_idx: 180 |  Loss: (0.0480) |  Loss2: (0.0000) | Acc: (98.00%) (22807/23168)
Epoch: 225 | Batch_idx: 190 |  Loss: (0.0484) |  Loss2: (0.0000) | Acc: (98.00%) (24063/24448)
Epoch: 225 | Batch_idx: 200 |  Loss: (0.0478) |  Loss2: (0.0000) | Acc: (98.00%) (25333/25728)
Epoch: 225 | Batch_idx: 210 |  Loss: (0.0480) |  Loss2: (0.0000) | Acc: (98.00%) (26594/27008)
Epoch: 225 | Batch_idx: 220 |  Loss: (0.0479) |  Loss2: (0.0000) | Acc: (98.00%) (27853/28288)
Epoch: 225 | Batch_idx: 230 |  Loss: (0.0487) |  Loss2: (0.0000) | Acc: (98.00%) (29099/29568)
Epoch: 225 | Batch_idx: 240 |  Loss: (0.0484) |  Loss2: (0.0000) | Acc: (98.00%) (30360/30848)
Epoch: 225 | Batch_idx: 250 |  Loss: (0.0484) |  Loss2: (0.0000) | Acc: (98.00%) (31619/32128)
Epoch: 225 | Batch_idx: 260 |  Loss: (0.0477) |  Loss2: (0.0000) | Acc: (98.00%) (32891/33408)
Epoch: 225 | Batch_idx: 270 |  Loss: (0.0478) |  Loss2: (0.0000) | Acc: (98.00%) (34150/34688)
Epoch: 225 | Batch_idx: 280 |  Loss: (0.0480) |  Loss2: (0.0000) | Acc: (98.00%) (35408/35968)
Epoch: 225 | Batch_idx: 290 |  Loss: (0.0478) |  Loss2: (0.0000) | Acc: (98.00%) (36670/37248)
Epoch: 225 | Batch_idx: 300 |  Loss: (0.0480) |  Loss2: (0.0000) | Acc: (98.00%) (37931/38528)
Epoch: 225 | Batch_idx: 310 |  Loss: (0.0487) |  Loss2: (0.0000) | Acc: (98.00%) (39179/39808)
Epoch: 225 | Batch_idx: 320 |  Loss: (0.0489) |  Loss2: (0.0000) | Acc: (98.00%) (40432/41088)
Epoch: 225 | Batch_idx: 330 |  Loss: (0.0487) |  Loss2: (0.0000) | Acc: (98.00%) (41694/42368)
Epoch: 225 | Batch_idx: 340 |  Loss: (0.0491) |  Loss2: (0.0000) | Acc: (98.00%) (42951/43648)
Epoch: 225 | Batch_idx: 350 |  Loss: (0.0490) |  Loss2: (0.0000) | Acc: (98.00%) (44211/44928)
Epoch: 225 | Batch_idx: 360 |  Loss: (0.0490) |  Loss2: (0.0000) | Acc: (98.00%) (45473/46208)
Epoch: 225 | Batch_idx: 370 |  Loss: (0.0487) |  Loss2: (0.0000) | Acc: (98.00%) (46737/47488)
Epoch: 225 | Batch_idx: 380 |  Loss: (0.0485) |  Loss2: (0.0000) | Acc: (98.00%) (48004/48768)
Epoch: 225 | Batch_idx: 390 |  Loss: (0.0486) |  Loss2: (0.0000) | Acc: (98.00%) (49213/50000)
=> saving checkpoint 'drive/app/torch/save_Schedule/checkpoint_225.pth.tar'
# TEST : Loss: (0.4382) | Acc: (88.00%) (8878/10000)
percent tensor([0.5351, 0.5277, 0.5410, 0.5351, 0.5460, 0.5408, 0.5352, 0.5389, 0.5402,
        0.5305, 0.5377, 0.5369, 0.5276, 0.5352, 0.5336, 0.5328],
       device='cuda:0') torch.Size([16])
percent tensor([0.5127, 0.5059, 0.5119, 0.5120, 0.5105, 0.5135, 0.5087, 0.5136, 0.5158,
        0.5092, 0.5146, 0.5073, 0.5057, 0.5188, 0.5079, 0.5139],
       device='cuda:0') torch.Size([16])
percent tensor([0.5856, 0.5579, 0.5936, 0.6104, 0.6063, 0.5990, 0.5925, 0.6008, 0.5908,
        0.5689, 0.5736, 0.5856, 0.5330, 0.6388, 0.5759, 0.6003],
       device='cuda:0') torch.Size([16])
percent tensor([0.6584, 0.6786, 0.6614, 0.6501, 0.6466, 0.6573, 0.6668, 0.6422, 0.6866,
        0.6902, 0.7033, 0.6763, 0.6854, 0.6952, 0.6482, 0.6759],
       device='cuda:0') torch.Size([16])
percent tensor([0.6331, 0.7316, 0.5587, 0.6463, 0.5572, 0.6774, 0.6718, 0.4296, 0.7374,
        0.7119, 0.7748, 0.6467, 0.7242, 0.7635, 0.5901, 0.6641],
       device='cuda:0') torch.Size([16])
percent tensor([0.7072, 0.7157, 0.7162, 0.7108, 0.7528, 0.7219, 0.7257, 0.7244, 0.7181,
        0.7093, 0.6827, 0.6758, 0.6872, 0.6982, 0.6900, 0.7272],
       device='cuda:0') torch.Size([16])
percent tensor([0.5765, 0.6665, 0.7667, 0.6705, 0.7809, 0.7622, 0.6299, 0.6757, 0.7051,
        0.6132, 0.7090, 0.6304, 0.6672, 0.5612, 0.6281, 0.4986],
       device='cuda:0') torch.Size([16])
percent tensor([0.9998, 0.9998, 0.9999, 0.9998, 0.9998, 0.9998, 0.9998, 0.9997, 0.9999,
        0.9998, 1.0000, 0.9998, 1.0000, 0.9992, 0.9998, 0.9995],
       device='cuda:0') torch.Size([16])
Epoch: 226 | Batch_idx: 0 |  Loss: (0.0476) |  Loss2: (0.0000) | Acc: (97.00%) (125/128)
Epoch: 226 | Batch_idx: 10 |  Loss: (0.0445) |  Loss2: (0.0000) | Acc: (98.00%) (1385/1408)
Epoch: 226 | Batch_idx: 20 |  Loss: (0.0464) |  Loss2: (0.0000) | Acc: (98.00%) (2641/2688)
Epoch: 226 | Batch_idx: 30 |  Loss: (0.0473) |  Loss2: (0.0000) | Acc: (98.00%) (3898/3968)
Epoch: 226 | Batch_idx: 40 |  Loss: (0.0487) |  Loss2: (0.0000) | Acc: (98.00%) (5152/5248)
Epoch: 226 | Batch_idx: 50 |  Loss: (0.0507) |  Loss2: (0.0000) | Acc: (98.00%) (6404/6528)
Epoch: 226 | Batch_idx: 60 |  Loss: (0.0517) |  Loss2: (0.0000) | Acc: (98.00%) (7662/7808)
Epoch: 226 | Batch_idx: 70 |  Loss: (0.0503) |  Loss2: (0.0000) | Acc: (98.00%) (8926/9088)
Epoch: 226 | Batch_idx: 80 |  Loss: (0.0495) |  Loss2: (0.0000) | Acc: (98.00%) (10189/10368)
Epoch: 226 | Batch_idx: 90 |  Loss: (0.0478) |  Loss2: (0.0000) | Acc: (98.00%) (11456/11648)
Epoch: 226 | Batch_idx: 100 |  Loss: (0.0475) |  Loss2: (0.0000) | Acc: (98.00%) (12721/12928)
Epoch: 226 | Batch_idx: 110 |  Loss: (0.0471) |  Loss2: (0.0000) | Acc: (98.00%) (13983/14208)
Epoch: 226 | Batch_idx: 120 |  Loss: (0.0473) |  Loss2: (0.0000) | Acc: (98.00%) (15247/15488)
Epoch: 226 | Batch_idx: 130 |  Loss: (0.0472) |  Loss2: (0.0000) | Acc: (98.00%) (16506/16768)
Epoch: 226 | Batch_idx: 140 |  Loss: (0.0475) |  Loss2: (0.0000) | Acc: (98.00%) (17765/18048)
Epoch: 226 | Batch_idx: 150 |  Loss: (0.0478) |  Loss2: (0.0000) | Acc: (98.00%) (19019/19328)
Epoch: 226 | Batch_idx: 160 |  Loss: (0.0480) |  Loss2: (0.0000) | Acc: (98.00%) (20274/20608)
Epoch: 226 | Batch_idx: 170 |  Loss: (0.0480) |  Loss2: (0.0000) | Acc: (98.00%) (21532/21888)
Epoch: 226 | Batch_idx: 180 |  Loss: (0.0476) |  Loss2: (0.0000) | Acc: (98.00%) (22795/23168)
Epoch: 226 | Batch_idx: 190 |  Loss: (0.0480) |  Loss2: (0.0000) | Acc: (98.00%) (24054/24448)
Epoch: 226 | Batch_idx: 200 |  Loss: (0.0487) |  Loss2: (0.0000) | Acc: (98.00%) (25308/25728)
Epoch: 226 | Batch_idx: 210 |  Loss: (0.0492) |  Loss2: (0.0000) | Acc: (98.00%) (26561/27008)
Epoch: 226 | Batch_idx: 220 |  Loss: (0.0489) |  Loss2: (0.0000) | Acc: (98.00%) (27826/28288)
Epoch: 226 | Batch_idx: 230 |  Loss: (0.0493) |  Loss2: (0.0000) | Acc: (98.00%) (29085/29568)
Epoch: 226 | Batch_idx: 240 |  Loss: (0.0491) |  Loss2: (0.0000) | Acc: (98.00%) (30346/30848)
Epoch: 226 | Batch_idx: 250 |  Loss: (0.0489) |  Loss2: (0.0000) | Acc: (98.00%) (31608/32128)
Epoch: 226 | Batch_idx: 260 |  Loss: (0.0490) |  Loss2: (0.0000) | Acc: (98.00%) (32867/33408)
Epoch: 226 | Batch_idx: 270 |  Loss: (0.0492) |  Loss2: (0.0000) | Acc: (98.00%) (34123/34688)
Epoch: 226 | Batch_idx: 280 |  Loss: (0.0490) |  Loss2: (0.0000) | Acc: (98.00%) (35388/35968)
Epoch: 226 | Batch_idx: 290 |  Loss: (0.0491) |  Loss2: (0.0000) | Acc: (98.00%) (36646/37248)
Epoch: 226 | Batch_idx: 300 |  Loss: (0.0491) |  Loss2: (0.0000) | Acc: (98.00%) (37902/38528)
Epoch: 226 | Batch_idx: 310 |  Loss: (0.0488) |  Loss2: (0.0000) | Acc: (98.00%) (39168/39808)
Epoch: 226 | Batch_idx: 320 |  Loss: (0.0488) |  Loss2: (0.0000) | Acc: (98.00%) (40427/41088)
Epoch: 226 | Batch_idx: 330 |  Loss: (0.0489) |  Loss2: (0.0000) | Acc: (98.00%) (41684/42368)
Epoch: 226 | Batch_idx: 340 |  Loss: (0.0490) |  Loss2: (0.0000) | Acc: (98.00%) (42944/43648)
Epoch: 226 | Batch_idx: 350 |  Loss: (0.0489) |  Loss2: (0.0000) | Acc: (98.00%) (44202/44928)
Epoch: 226 | Batch_idx: 360 |  Loss: (0.0492) |  Loss2: (0.0000) | Acc: (98.00%) (45459/46208)
Epoch: 226 | Batch_idx: 370 |  Loss: (0.0492) |  Loss2: (0.0000) | Acc: (98.00%) (46716/47488)
Epoch: 226 | Batch_idx: 380 |  Loss: (0.0496) |  Loss2: (0.0000) | Acc: (98.00%) (47970/48768)
Epoch: 226 | Batch_idx: 390 |  Loss: (0.0497) |  Loss2: (0.0000) | Acc: (98.00%) (49174/50000)
# TEST : Loss: (0.4512) | Acc: (88.00%) (8889/10000)
percent tensor([0.5331, 0.5263, 0.5383, 0.5336, 0.5438, 0.5406, 0.5334, 0.5359, 0.5381,
        0.5285, 0.5356, 0.5342, 0.5255, 0.5348, 0.5324, 0.5311],
       device='cuda:0') torch.Size([16])
percent tensor([0.5121, 0.5064, 0.5103, 0.5108, 0.5100, 0.5127, 0.5086, 0.5125, 0.5148,
        0.5087, 0.5141, 0.5061, 0.5044, 0.5196, 0.5074, 0.5131],
       device='cuda:0') torch.Size([16])
percent tensor([0.5798, 0.5549, 0.5963, 0.6038, 0.6072, 0.5897, 0.5909, 0.6060, 0.5892,
        0.5650, 0.5679, 0.5824, 0.5246, 0.6384, 0.5714, 0.5934],
       device='cuda:0') torch.Size([16])
percent tensor([0.6546, 0.6768, 0.6651, 0.6592, 0.6517, 0.6631, 0.6684, 0.6443, 0.6865,
        0.6860, 0.6983, 0.6798, 0.6832, 0.6892, 0.6511, 0.6715],
       device='cuda:0') torch.Size([16])
percent tensor([0.6268, 0.7137, 0.5807, 0.6729, 0.5690, 0.6930, 0.6684, 0.4166, 0.7430,
        0.6998, 0.7743, 0.6502, 0.7104, 0.7511, 0.5779, 0.6571],
       device='cuda:0') torch.Size([16])
percent tensor([0.7088, 0.7277, 0.7258, 0.7178, 0.7592, 0.7203, 0.7363, 0.7323, 0.7232,
        0.7179, 0.6899, 0.6776, 0.6937, 0.7054, 0.6952, 0.7301],
       device='cuda:0') torch.Size([16])
percent tensor([0.5395, 0.6427, 0.7467, 0.6752, 0.7639, 0.7672, 0.6396, 0.6153, 0.6462,
        0.6196, 0.6981, 0.6416, 0.6704, 0.5537, 0.6102, 0.4970],
       device='cuda:0') torch.Size([16])
percent tensor([0.9998, 0.9997, 0.9999, 0.9999, 0.9998, 0.9998, 0.9999, 0.9998, 0.9999,
        0.9999, 1.0000, 0.9999, 0.9999, 0.9991, 0.9999, 0.9996],
       device='cuda:0') torch.Size([16])
Epoch: 227 | Batch_idx: 0 |  Loss: (0.0189) |  Loss2: (0.0000) | Acc: (100.00%) (128/128)
Epoch: 227 | Batch_idx: 10 |  Loss: (0.0425) |  Loss2: (0.0000) | Acc: (98.00%) (1389/1408)
Epoch: 227 | Batch_idx: 20 |  Loss: (0.0415) |  Loss2: (0.0000) | Acc: (98.00%) (2651/2688)
Epoch: 227 | Batch_idx: 30 |  Loss: (0.0440) |  Loss2: (0.0000) | Acc: (98.00%) (3908/3968)
Epoch: 227 | Batch_idx: 40 |  Loss: (0.0454) |  Loss2: (0.0000) | Acc: (98.00%) (5169/5248)
Epoch: 227 | Batch_idx: 50 |  Loss: (0.0465) |  Loss2: (0.0000) | Acc: (98.00%) (6428/6528)
Epoch: 227 | Batch_idx: 60 |  Loss: (0.0457) |  Loss2: (0.0000) | Acc: (98.00%) (7695/7808)
Epoch: 227 | Batch_idx: 70 |  Loss: (0.0459) |  Loss2: (0.0000) | Acc: (98.00%) (8960/9088)
Epoch: 227 | Batch_idx: 80 |  Loss: (0.0451) |  Loss2: (0.0000) | Acc: (98.00%) (10225/10368)
Epoch: 227 | Batch_idx: 90 |  Loss: (0.0441) |  Loss2: (0.0000) | Acc: (98.00%) (11495/11648)
Epoch: 227 | Batch_idx: 100 |  Loss: (0.0454) |  Loss2: (0.0000) | Acc: (98.00%) (12750/12928)
Epoch: 227 | Batch_idx: 110 |  Loss: (0.0453) |  Loss2: (0.0000) | Acc: (98.00%) (14013/14208)
Epoch: 227 | Batch_idx: 120 |  Loss: (0.0471) |  Loss2: (0.0000) | Acc: (98.00%) (15257/15488)
Epoch: 227 | Batch_idx: 130 |  Loss: (0.0454) |  Loss2: (0.0000) | Acc: (98.00%) (16529/16768)
Epoch: 227 | Batch_idx: 140 |  Loss: (0.0453) |  Loss2: (0.0000) | Acc: (98.00%) (17790/18048)
Epoch: 227 | Batch_idx: 150 |  Loss: (0.0451) |  Loss2: (0.0000) | Acc: (98.00%) (19052/19328)
Epoch: 227 | Batch_idx: 160 |  Loss: (0.0451) |  Loss2: (0.0000) | Acc: (98.00%) (20314/20608)
Epoch: 227 | Batch_idx: 170 |  Loss: (0.0449) |  Loss2: (0.0000) | Acc: (98.00%) (21575/21888)
Epoch: 227 | Batch_idx: 180 |  Loss: (0.0450) |  Loss2: (0.0000) | Acc: (98.00%) (22834/23168)
Epoch: 227 | Batch_idx: 190 |  Loss: (0.0448) |  Loss2: (0.0000) | Acc: (98.00%) (24099/24448)
Epoch: 227 | Batch_idx: 200 |  Loss: (0.0448) |  Loss2: (0.0000) | Acc: (98.00%) (25360/25728)
Epoch: 227 | Batch_idx: 210 |  Loss: (0.0450) |  Loss2: (0.0000) | Acc: (98.00%) (26619/27008)
Epoch: 227 | Batch_idx: 220 |  Loss: (0.0457) |  Loss2: (0.0000) | Acc: (98.00%) (27870/28288)
Epoch: 227 | Batch_idx: 230 |  Loss: (0.0454) |  Loss2: (0.0000) | Acc: (98.00%) (29133/29568)
Epoch: 227 | Batch_idx: 240 |  Loss: (0.0457) |  Loss2: (0.0000) | Acc: (98.00%) (30391/30848)
Epoch: 227 | Batch_idx: 250 |  Loss: (0.0458) |  Loss2: (0.0000) | Acc: (98.00%) (31649/32128)
Epoch: 227 | Batch_idx: 260 |  Loss: (0.0459) |  Loss2: (0.0000) | Acc: (98.00%) (32915/33408)
Epoch: 227 | Batch_idx: 270 |  Loss: (0.0457) |  Loss2: (0.0000) | Acc: (98.00%) (34174/34688)
Epoch: 227 | Batch_idx: 280 |  Loss: (0.0459) |  Loss2: (0.0000) | Acc: (98.00%) (35435/35968)
Epoch: 227 | Batch_idx: 290 |  Loss: (0.0461) |  Loss2: (0.0000) | Acc: (98.00%) (36690/37248)
Epoch: 227 | Batch_idx: 300 |  Loss: (0.0457) |  Loss2: (0.0000) | Acc: (98.00%) (37960/38528)
Epoch: 227 | Batch_idx: 310 |  Loss: (0.0459) |  Loss2: (0.0000) | Acc: (98.00%) (39216/39808)
Epoch: 227 | Batch_idx: 320 |  Loss: (0.0458) |  Loss2: (0.0000) | Acc: (98.00%) (40482/41088)
Epoch: 227 | Batch_idx: 330 |  Loss: (0.0459) |  Loss2: (0.0000) | Acc: (98.00%) (41740/42368)
Epoch: 227 | Batch_idx: 340 |  Loss: (0.0460) |  Loss2: (0.0000) | Acc: (98.00%) (42996/43648)
Epoch: 227 | Batch_idx: 350 |  Loss: (0.0461) |  Loss2: (0.0000) | Acc: (98.00%) (44255/44928)
Epoch: 227 | Batch_idx: 360 |  Loss: (0.0458) |  Loss2: (0.0000) | Acc: (98.00%) (45518/46208)
Epoch: 227 | Batch_idx: 370 |  Loss: (0.0459) |  Loss2: (0.0000) | Acc: (98.00%) (46775/47488)
Epoch: 227 | Batch_idx: 380 |  Loss: (0.0457) |  Loss2: (0.0000) | Acc: (98.00%) (48038/48768)
Epoch: 227 | Batch_idx: 390 |  Loss: (0.0458) |  Loss2: (0.0000) | Acc: (98.00%) (49251/50000)
# TEST : Loss: (0.4879) | Acc: (88.00%) (8804/10000)
percent tensor([0.5373, 0.5297, 0.5430, 0.5366, 0.5489, 0.5434, 0.5375, 0.5401, 0.5421,
        0.5327, 0.5396, 0.5387, 0.5296, 0.5363, 0.5357, 0.5346],
       device='cuda:0') torch.Size([16])
percent tensor([0.5124, 0.5070, 0.5107, 0.5111, 0.5098, 0.5132, 0.5091, 0.5132, 0.5153,
        0.5094, 0.5148, 0.5072, 0.5058, 0.5197, 0.5080, 0.5137],
       device='cuda:0') torch.Size([16])
percent tensor([0.5849, 0.5568, 0.6076, 0.6130, 0.6156, 0.5945, 0.5959, 0.6116, 0.5949,
        0.5702, 0.5739, 0.5919, 0.5318, 0.6410, 0.5723, 0.6013],
       device='cuda:0') torch.Size([16])
percent tensor([0.6521, 0.6803, 0.6586, 0.6489, 0.6456, 0.6553, 0.6695, 0.6455, 0.6850,
        0.6895, 0.7021, 0.6749, 0.6823, 0.6937, 0.6481, 0.6720],
       device='cuda:0') torch.Size([16])
percent tensor([0.6178, 0.7257, 0.5459, 0.6505, 0.5591, 0.6713, 0.6617, 0.4263, 0.7547,
        0.7054, 0.7792, 0.6346, 0.7247, 0.7568, 0.5727, 0.6527],
       device='cuda:0') torch.Size([16])
percent tensor([0.7111, 0.7252, 0.7257, 0.7214, 0.7606, 0.7285, 0.7347, 0.7327, 0.7201,
        0.7165, 0.6791, 0.6839, 0.6931, 0.7061, 0.6953, 0.7306],
       device='cuda:0') torch.Size([16])
percent tensor([0.5477, 0.5940, 0.7501, 0.6410, 0.7667, 0.7679, 0.6335, 0.6080, 0.6619,
        0.6021, 0.6804, 0.6004, 0.6458, 0.5731, 0.5682, 0.4770],
       device='cuda:0') torch.Size([16])
percent tensor([0.9998, 0.9998, 0.9999, 0.9999, 0.9997, 0.9998, 0.9998, 0.9998, 0.9999,
        0.9998, 1.0000, 0.9999, 0.9999, 0.9993, 0.9998, 0.9996],
       device='cuda:0') torch.Size([16])
Epoch: 228 | Batch_idx: 0 |  Loss: (0.0370) |  Loss2: (0.0000) | Acc: (99.00%) (127/128)
Epoch: 228 | Batch_idx: 10 |  Loss: (0.0286) |  Loss2: (0.0000) | Acc: (99.00%) (1398/1408)
Epoch: 228 | Batch_idx: 20 |  Loss: (0.0298) |  Loss2: (0.0000) | Acc: (99.00%) (2666/2688)
Epoch: 228 | Batch_idx: 30 |  Loss: (0.0331) |  Loss2: (0.0000) | Acc: (98.00%) (3928/3968)
Epoch: 228 | Batch_idx: 40 |  Loss: (0.0359) |  Loss2: (0.0000) | Acc: (98.00%) (5190/5248)
Epoch: 228 | Batch_idx: 50 |  Loss: (0.0367) |  Loss2: (0.0000) | Acc: (98.00%) (6453/6528)
Epoch: 228 | Batch_idx: 60 |  Loss: (0.0362) |  Loss2: (0.0000) | Acc: (98.00%) (7720/7808)
Epoch: 228 | Batch_idx: 70 |  Loss: (0.0372) |  Loss2: (0.0000) | Acc: (98.00%) (8983/9088)
Epoch: 228 | Batch_idx: 80 |  Loss: (0.0381) |  Loss2: (0.0000) | Acc: (98.00%) (10245/10368)
Epoch: 228 | Batch_idx: 90 |  Loss: (0.0392) |  Loss2: (0.0000) | Acc: (98.00%) (11505/11648)
Epoch: 228 | Batch_idx: 100 |  Loss: (0.0392) |  Loss2: (0.0000) | Acc: (98.00%) (12769/12928)
Epoch: 228 | Batch_idx: 110 |  Loss: (0.0399) |  Loss2: (0.0000) | Acc: (98.00%) (14031/14208)
Epoch: 228 | Batch_idx: 120 |  Loss: (0.0400) |  Loss2: (0.0000) | Acc: (98.00%) (15295/15488)
Epoch: 228 | Batch_idx: 130 |  Loss: (0.0414) |  Loss2: (0.0000) | Acc: (98.00%) (16549/16768)
Epoch: 228 | Batch_idx: 140 |  Loss: (0.0419) |  Loss2: (0.0000) | Acc: (98.00%) (17806/18048)
Epoch: 228 | Batch_idx: 150 |  Loss: (0.0419) |  Loss2: (0.0000) | Acc: (98.00%) (19070/19328)
Epoch: 228 | Batch_idx: 160 |  Loss: (0.0421) |  Loss2: (0.0000) | Acc: (98.00%) (20330/20608)
Epoch: 228 | Batch_idx: 170 |  Loss: (0.0421) |  Loss2: (0.0000) | Acc: (98.00%) (21593/21888)
Epoch: 228 | Batch_idx: 180 |  Loss: (0.0425) |  Loss2: (0.0000) | Acc: (98.00%) (22855/23168)
Epoch: 228 | Batch_idx: 190 |  Loss: (0.0429) |  Loss2: (0.0000) | Acc: (98.00%) (24113/24448)
Epoch: 228 | Batch_idx: 200 |  Loss: (0.0428) |  Loss2: (0.0000) | Acc: (98.00%) (25378/25728)
Epoch: 228 | Batch_idx: 210 |  Loss: (0.0426) |  Loss2: (0.0000) | Acc: (98.00%) (26638/27008)
Epoch: 228 | Batch_idx: 220 |  Loss: (0.0430) |  Loss2: (0.0000) | Acc: (98.00%) (27899/28288)
Epoch: 228 | Batch_idx: 230 |  Loss: (0.0429) |  Loss2: (0.0000) | Acc: (98.00%) (29163/29568)
Epoch: 228 | Batch_idx: 240 |  Loss: (0.0430) |  Loss2: (0.0000) | Acc: (98.00%) (30422/30848)
Epoch: 228 | Batch_idx: 250 |  Loss: (0.0432) |  Loss2: (0.0000) | Acc: (98.00%) (31684/32128)
Epoch: 228 | Batch_idx: 260 |  Loss: (0.0433) |  Loss2: (0.0000) | Acc: (98.00%) (32944/33408)
Epoch: 228 | Batch_idx: 270 |  Loss: (0.0437) |  Loss2: (0.0000) | Acc: (98.00%) (34197/34688)
Epoch: 228 | Batch_idx: 280 |  Loss: (0.0438) |  Loss2: (0.0000) | Acc: (98.00%) (35458/35968)
Epoch: 228 | Batch_idx: 290 |  Loss: (0.0441) |  Loss2: (0.0000) | Acc: (98.00%) (36714/37248)
Epoch: 228 | Batch_idx: 300 |  Loss: (0.0444) |  Loss2: (0.0000) | Acc: (98.00%) (37969/38528)
Epoch: 228 | Batch_idx: 310 |  Loss: (0.0446) |  Loss2: (0.0000) | Acc: (98.00%) (39224/39808)
Epoch: 228 | Batch_idx: 320 |  Loss: (0.0451) |  Loss2: (0.0000) | Acc: (98.00%) (40476/41088)
Epoch: 228 | Batch_idx: 330 |  Loss: (0.0451) |  Loss2: (0.0000) | Acc: (98.00%) (41735/42368)
Epoch: 228 | Batch_idx: 340 |  Loss: (0.0453) |  Loss2: (0.0000) | Acc: (98.00%) (42991/43648)
Epoch: 228 | Batch_idx: 350 |  Loss: (0.0453) |  Loss2: (0.0000) | Acc: (98.00%) (44253/44928)
Epoch: 228 | Batch_idx: 360 |  Loss: (0.0454) |  Loss2: (0.0000) | Acc: (98.00%) (45513/46208)
Epoch: 228 | Batch_idx: 370 |  Loss: (0.0457) |  Loss2: (0.0000) | Acc: (98.00%) (46765/47488)
Epoch: 228 | Batch_idx: 380 |  Loss: (0.0461) |  Loss2: (0.0000) | Acc: (98.00%) (48018/48768)
Epoch: 228 | Batch_idx: 390 |  Loss: (0.0463) |  Loss2: (0.0000) | Acc: (98.00%) (49224/50000)
# TEST : Loss: (0.4387) | Acc: (88.00%) (8896/10000)
percent tensor([0.5356, 0.5295, 0.5395, 0.5346, 0.5446, 0.5413, 0.5357, 0.5386, 0.5416,
        0.5310, 0.5392, 0.5350, 0.5287, 0.5373, 0.5344, 0.5336],
       device='cuda:0') torch.Size([16])
percent tensor([0.5141, 0.5090, 0.5119, 0.5133, 0.5109, 0.5151, 0.5102, 0.5144, 0.5171,
        0.5108, 0.5167, 0.5073, 0.5068, 0.5227, 0.5098, 0.5159],
       device='cuda:0') torch.Size([16])
percent tensor([0.5866, 0.5612, 0.5958, 0.6106, 0.6110, 0.5927, 0.5951, 0.6101, 0.5949,
        0.5729, 0.5744, 0.5866, 0.5314, 0.6461, 0.5763, 0.6015],
       device='cuda:0') torch.Size([16])
percent tensor([0.6491, 0.6697, 0.6560, 0.6475, 0.6447, 0.6530, 0.6607, 0.6388, 0.6815,
        0.6819, 0.6956, 0.6713, 0.6746, 0.6869, 0.6417, 0.6666],
       device='cuda:0') torch.Size([16])
percent tensor([0.6159, 0.7107, 0.5493, 0.6337, 0.5617, 0.6801, 0.6621, 0.4129, 0.7433,
        0.6924, 0.7712, 0.6421, 0.6987, 0.7536, 0.5817, 0.6438],
       device='cuda:0') torch.Size([16])
percent tensor([0.7116, 0.7252, 0.7222, 0.7111, 0.7599, 0.7204, 0.7362, 0.7247, 0.7240,
        0.7227, 0.6871, 0.6737, 0.6910, 0.7064, 0.6904, 0.7292],
       device='cuda:0') torch.Size([16])
percent tensor([0.5580, 0.6108, 0.7498, 0.6139, 0.7425, 0.7672, 0.6566, 0.6288, 0.6398,
        0.5979, 0.6848, 0.6052, 0.6487, 0.5155, 0.5944, 0.4931],
       device='cuda:0') torch.Size([16])
percent tensor([0.9997, 0.9997, 0.9999, 0.9998, 0.9997, 0.9998, 0.9998, 0.9996, 0.9998,
        0.9997, 0.9999, 0.9998, 0.9999, 0.9992, 0.9998, 0.9995],
       device='cuda:0') torch.Size([16])
Epoch: 229 | Batch_idx: 0 |  Loss: (0.0399) |  Loss2: (0.0000) | Acc: (99.00%) (127/128)
Epoch: 229 | Batch_idx: 10 |  Loss: (0.0579) |  Loss2: (0.0000) | Acc: (97.00%) (1379/1408)
Epoch: 229 | Batch_idx: 20 |  Loss: (0.0529) |  Loss2: (0.0000) | Acc: (98.00%) (2637/2688)
Epoch: 229 | Batch_idx: 30 |  Loss: (0.0488) |  Loss2: (0.0000) | Acc: (98.00%) (3902/3968)
Epoch: 229 | Batch_idx: 40 |  Loss: (0.0457) |  Loss2: (0.0000) | Acc: (98.00%) (5166/5248)
Epoch: 229 | Batch_idx: 50 |  Loss: (0.0457) |  Loss2: (0.0000) | Acc: (98.00%) (6426/6528)
Epoch: 229 | Batch_idx: 60 |  Loss: (0.0467) |  Loss2: (0.0000) | Acc: (98.00%) (7682/7808)
Epoch: 229 | Batch_idx: 70 |  Loss: (0.0468) |  Loss2: (0.0000) | Acc: (98.00%) (8944/9088)
Epoch: 229 | Batch_idx: 80 |  Loss: (0.0483) |  Loss2: (0.0000) | Acc: (98.00%) (10199/10368)
Epoch: 229 | Batch_idx: 90 |  Loss: (0.0487) |  Loss2: (0.0000) | Acc: (98.00%) (11459/11648)
Epoch: 229 | Batch_idx: 100 |  Loss: (0.0487) |  Loss2: (0.0000) | Acc: (98.00%) (12721/12928)
Epoch: 229 | Batch_idx: 110 |  Loss: (0.0484) |  Loss2: (0.0000) | Acc: (98.00%) (13978/14208)
Epoch: 229 | Batch_idx: 120 |  Loss: (0.0478) |  Loss2: (0.0000) | Acc: (98.00%) (15245/15488)
Epoch: 229 | Batch_idx: 130 |  Loss: (0.0477) |  Loss2: (0.0000) | Acc: (98.00%) (16508/16768)
Epoch: 229 | Batch_idx: 140 |  Loss: (0.0472) |  Loss2: (0.0000) | Acc: (98.00%) (17772/18048)
Epoch: 229 | Batch_idx: 150 |  Loss: (0.0469) |  Loss2: (0.0000) | Acc: (98.00%) (19033/19328)
Epoch: 229 | Batch_idx: 160 |  Loss: (0.0471) |  Loss2: (0.0000) | Acc: (98.00%) (20294/20608)
Epoch: 229 | Batch_idx: 170 |  Loss: (0.0473) |  Loss2: (0.0000) | Acc: (98.00%) (21552/21888)
Epoch: 229 | Batch_idx: 180 |  Loss: (0.0469) |  Loss2: (0.0000) | Acc: (98.00%) (22814/23168)
Epoch: 229 | Batch_idx: 190 |  Loss: (0.0461) |  Loss2: (0.0000) | Acc: (98.00%) (24085/24448)
Epoch: 229 | Batch_idx: 200 |  Loss: (0.0461) |  Loss2: (0.0000) | Acc: (98.00%) (25347/25728)
Epoch: 229 | Batch_idx: 210 |  Loss: (0.0461) |  Loss2: (0.0000) | Acc: (98.00%) (26610/27008)
Epoch: 229 | Batch_idx: 220 |  Loss: (0.0460) |  Loss2: (0.0000) | Acc: (98.00%) (27870/28288)
Epoch: 229 | Batch_idx: 230 |  Loss: (0.0463) |  Loss2: (0.0000) | Acc: (98.00%) (29124/29568)
Epoch: 229 | Batch_idx: 240 |  Loss: (0.0460) |  Loss2: (0.0000) | Acc: (98.00%) (30388/30848)
Epoch: 229 | Batch_idx: 250 |  Loss: (0.0466) |  Loss2: (0.0000) | Acc: (98.00%) (31645/32128)
Epoch: 229 | Batch_idx: 260 |  Loss: (0.0468) |  Loss2: (0.0000) | Acc: (98.00%) (32902/33408)
Epoch: 229 | Batch_idx: 270 |  Loss: (0.0468) |  Loss2: (0.0000) | Acc: (98.00%) (34161/34688)
Epoch: 229 | Batch_idx: 280 |  Loss: (0.0472) |  Loss2: (0.0000) | Acc: (98.00%) (35417/35968)
Epoch: 229 | Batch_idx: 290 |  Loss: (0.0474) |  Loss2: (0.0000) | Acc: (98.00%) (36674/37248)
Epoch: 229 | Batch_idx: 300 |  Loss: (0.0477) |  Loss2: (0.0000) | Acc: (98.00%) (37924/38528)
Epoch: 229 | Batch_idx: 310 |  Loss: (0.0478) |  Loss2: (0.0000) | Acc: (98.00%) (39185/39808)
Epoch: 229 | Batch_idx: 320 |  Loss: (0.0476) |  Loss2: (0.0000) | Acc: (98.00%) (40449/41088)
Epoch: 229 | Batch_idx: 330 |  Loss: (0.0474) |  Loss2: (0.0000) | Acc: (98.00%) (41711/42368)
Epoch: 229 | Batch_idx: 340 |  Loss: (0.0476) |  Loss2: (0.0000) | Acc: (98.00%) (42966/43648)
Epoch: 229 | Batch_idx: 350 |  Loss: (0.0477) |  Loss2: (0.0000) | Acc: (98.00%) (44224/44928)
Epoch: 229 | Batch_idx: 360 |  Loss: (0.0477) |  Loss2: (0.0000) | Acc: (98.00%) (45482/46208)
Epoch: 229 | Batch_idx: 370 |  Loss: (0.0476) |  Loss2: (0.0000) | Acc: (98.00%) (46746/47488)
Epoch: 229 | Batch_idx: 380 |  Loss: (0.0476) |  Loss2: (0.0000) | Acc: (98.00%) (48006/48768)
Epoch: 229 | Batch_idx: 390 |  Loss: (0.0475) |  Loss2: (0.0000) | Acc: (98.00%) (49219/50000)
# TEST : Loss: (0.4261) | Acc: (89.00%) (8904/10000)
percent tensor([0.5372, 0.5297, 0.5428, 0.5368, 0.5488, 0.5431, 0.5373, 0.5408, 0.5425,
        0.5329, 0.5400, 0.5393, 0.5298, 0.5356, 0.5359, 0.5344],
       device='cuda:0') torch.Size([16])
percent tensor([0.5142, 0.5080, 0.5104, 0.5126, 0.5097, 0.5149, 0.5096, 0.5133, 0.5161,
        0.5102, 0.5161, 0.5058, 0.5066, 0.5204, 0.5092, 0.5159],
       device='cuda:0') torch.Size([16])
percent tensor([0.5867, 0.5696, 0.5967, 0.6157, 0.6109, 0.6017, 0.6029, 0.6102, 0.5941,
        0.5756, 0.5782, 0.5885, 0.5341, 0.6548, 0.5807, 0.6088],
       device='cuda:0') torch.Size([16])
percent tensor([0.6567, 0.6793, 0.6640, 0.6537, 0.6520, 0.6576, 0.6691, 0.6412, 0.6910,
        0.6903, 0.7020, 0.6796, 0.6843, 0.6926, 0.6475, 0.6723],
       device='cuda:0') torch.Size([16])
percent tensor([0.6384, 0.7306, 0.5648, 0.6437, 0.5792, 0.6815, 0.6771, 0.4352, 0.7673,
        0.7091, 0.7809, 0.6557, 0.7247, 0.7557, 0.5948, 0.6571],
       device='cuda:0') torch.Size([16])
percent tensor([0.7094, 0.7212, 0.7235, 0.7027, 0.7563, 0.7295, 0.7305, 0.7243, 0.7235,
        0.7139, 0.6895, 0.6705, 0.6927, 0.7096, 0.6920, 0.7248],
       device='cuda:0') torch.Size([16])
percent tensor([0.5625, 0.6377, 0.7606, 0.6659, 0.7578, 0.7817, 0.6555, 0.6525, 0.6776,
        0.5907, 0.6956, 0.6304, 0.6640, 0.5315, 0.5841, 0.4853],
       device='cuda:0') torch.Size([16])
percent tensor([0.9998, 0.9998, 0.9998, 0.9998, 0.9998, 0.9997, 0.9999, 0.9996, 0.9998,
        0.9998, 1.0000, 0.9998, 0.9999, 0.9990, 0.9997, 0.9995],
       device='cuda:0') torch.Size([16])
Epoch: 230 | Batch_idx: 0 |  Loss: (0.0353) |  Loss2: (0.0000) | Acc: (98.00%) (126/128)
Epoch: 230 | Batch_idx: 10 |  Loss: (0.0394) |  Loss2: (0.0000) | Acc: (98.00%) (1390/1408)
Epoch: 230 | Batch_idx: 20 |  Loss: (0.0423) |  Loss2: (0.0000) | Acc: (98.00%) (2651/2688)
Epoch: 230 | Batch_idx: 30 |  Loss: (0.0388) |  Loss2: (0.0000) | Acc: (98.00%) (3918/3968)
Epoch: 230 | Batch_idx: 40 |  Loss: (0.0392) |  Loss2: (0.0000) | Acc: (98.00%) (5179/5248)
Epoch: 230 | Batch_idx: 50 |  Loss: (0.0411) |  Loss2: (0.0000) | Acc: (98.00%) (6443/6528)
Epoch: 230 | Batch_idx: 60 |  Loss: (0.0416) |  Loss2: (0.0000) | Acc: (98.00%) (7704/7808)
Epoch: 230 | Batch_idx: 70 |  Loss: (0.0426) |  Loss2: (0.0000) | Acc: (98.00%) (8965/9088)
Epoch: 230 | Batch_idx: 80 |  Loss: (0.0423) |  Loss2: (0.0000) | Acc: (98.00%) (10230/10368)
Epoch: 230 | Batch_idx: 90 |  Loss: (0.0430) |  Loss2: (0.0000) | Acc: (98.00%) (11491/11648)
Epoch: 230 | Batch_idx: 100 |  Loss: (0.0432) |  Loss2: (0.0000) | Acc: (98.00%) (12754/12928)
Epoch: 230 | Batch_idx: 110 |  Loss: (0.0434) |  Loss2: (0.0000) | Acc: (98.00%) (14016/14208)
Epoch: 230 | Batch_idx: 120 |  Loss: (0.0428) |  Loss2: (0.0000) | Acc: (98.00%) (15285/15488)
Epoch: 230 | Batch_idx: 130 |  Loss: (0.0428) |  Loss2: (0.0000) | Acc: (98.00%) (16548/16768)
Epoch: 230 | Batch_idx: 140 |  Loss: (0.0433) |  Loss2: (0.0000) | Acc: (98.00%) (17806/18048)
Epoch: 230 | Batch_idx: 150 |  Loss: (0.0429) |  Loss2: (0.0000) | Acc: (98.00%) (19075/19328)
Epoch: 230 | Batch_idx: 160 |  Loss: (0.0433) |  Loss2: (0.0000) | Acc: (98.00%) (20331/20608)
Epoch: 230 | Batch_idx: 170 |  Loss: (0.0443) |  Loss2: (0.0000) | Acc: (98.00%) (21582/21888)
Epoch: 230 | Batch_idx: 180 |  Loss: (0.0444) |  Loss2: (0.0000) | Acc: (98.00%) (22843/23168)
Epoch: 230 | Batch_idx: 190 |  Loss: (0.0442) |  Loss2: (0.0000) | Acc: (98.00%) (24104/24448)
Epoch: 230 | Batch_idx: 200 |  Loss: (0.0445) |  Loss2: (0.0000) | Acc: (98.00%) (25361/25728)
Epoch: 230 | Batch_idx: 210 |  Loss: (0.0442) |  Loss2: (0.0000) | Acc: (98.00%) (26626/27008)
Epoch: 230 | Batch_idx: 220 |  Loss: (0.0441) |  Loss2: (0.0000) | Acc: (98.00%) (27889/28288)
Epoch: 230 | Batch_idx: 230 |  Loss: (0.0446) |  Loss2: (0.0000) | Acc: (98.00%) (29146/29568)
Epoch: 230 | Batch_idx: 240 |  Loss: (0.0448) |  Loss2: (0.0000) | Acc: (98.00%) (30407/30848)
Epoch: 230 | Batch_idx: 250 |  Loss: (0.0449) |  Loss2: (0.0000) | Acc: (98.00%) (31668/32128)
Epoch: 230 | Batch_idx: 260 |  Loss: (0.0449) |  Loss2: (0.0000) | Acc: (98.00%) (32926/33408)
Epoch: 230 | Batch_idx: 270 |  Loss: (0.0448) |  Loss2: (0.0000) | Acc: (98.00%) (34193/34688)
Epoch: 230 | Batch_idx: 280 |  Loss: (0.0451) |  Loss2: (0.0000) | Acc: (98.00%) (35448/35968)
Epoch: 230 | Batch_idx: 290 |  Loss: (0.0449) |  Loss2: (0.0000) | Acc: (98.00%) (36709/37248)
Epoch: 230 | Batch_idx: 300 |  Loss: (0.0450) |  Loss2: (0.0000) | Acc: (98.00%) (37966/38528)
Epoch: 230 | Batch_idx: 310 |  Loss: (0.0453) |  Loss2: (0.0000) | Acc: (98.00%) (39224/39808)
Epoch: 230 | Batch_idx: 320 |  Loss: (0.0457) |  Loss2: (0.0000) | Acc: (98.00%) (40474/41088)
Epoch: 230 | Batch_idx: 330 |  Loss: (0.0454) |  Loss2: (0.0000) | Acc: (98.00%) (41741/42368)
Epoch: 230 | Batch_idx: 340 |  Loss: (0.0454) |  Loss2: (0.0000) | Acc: (98.00%) (43003/43648)
Epoch: 230 | Batch_idx: 350 |  Loss: (0.0458) |  Loss2: (0.0000) | Acc: (98.00%) (44259/44928)
Epoch: 230 | Batch_idx: 360 |  Loss: (0.0459) |  Loss2: (0.0000) | Acc: (98.00%) (45515/46208)
Epoch: 230 | Batch_idx: 370 |  Loss: (0.0461) |  Loss2: (0.0000) | Acc: (98.00%) (46771/47488)
Epoch: 230 | Batch_idx: 380 |  Loss: (0.0458) |  Loss2: (0.0000) | Acc: (98.00%) (48032/48768)
Epoch: 230 | Batch_idx: 390 |  Loss: (0.0461) |  Loss2: (0.0000) | Acc: (98.00%) (49239/50000)
=> saving checkpoint 'drive/app/torch/save_Schedule/checkpoint_230.pth.tar'
# TEST : Loss: (0.4688) | Acc: (87.00%) (8793/10000)
percent tensor([0.5378, 0.5328, 0.5426, 0.5379, 0.5487, 0.5434, 0.5395, 0.5425, 0.5429,
        0.5344, 0.5405, 0.5392, 0.5305, 0.5408, 0.5379, 0.5364],
       device='cuda:0') torch.Size([16])
percent tensor([0.5136, 0.5077, 0.5112, 0.5124, 0.5102, 0.5144, 0.5097, 0.5142, 0.5170,
        0.5098, 0.5164, 0.5065, 0.5066, 0.5211, 0.5089, 0.5155],
       device='cuda:0') torch.Size([16])
percent tensor([0.5891, 0.5604, 0.5974, 0.6222, 0.6123, 0.6015, 0.5977, 0.6116, 0.5945,
        0.5743, 0.5765, 0.5897, 0.5327, 0.6498, 0.5781, 0.6092],
       device='cuda:0') torch.Size([16])
percent tensor([0.6599, 0.6805, 0.6624, 0.6550, 0.6516, 0.6572, 0.6740, 0.6468, 0.6939,
        0.6915, 0.7063, 0.6818, 0.6901, 0.7001, 0.6508, 0.6755],
       device='cuda:0') torch.Size([16])
percent tensor([0.6287, 0.7149, 0.5827, 0.6501, 0.5851, 0.6879, 0.6736, 0.4344, 0.7538,
        0.6916, 0.7729, 0.6647, 0.7095, 0.7345, 0.5867, 0.6542],
       device='cuda:0') torch.Size([16])
percent tensor([0.7150, 0.7191, 0.7257, 0.7129, 0.7672, 0.7245, 0.7362, 0.7250, 0.7259,
        0.7145, 0.6934, 0.6740, 0.6974, 0.6969, 0.6903, 0.7358],
       device='cuda:0') torch.Size([16])
percent tensor([0.5498, 0.5941, 0.7514, 0.6283, 0.7463, 0.7621, 0.6614, 0.6328, 0.6729,
        0.5647, 0.7040, 0.5862, 0.6602, 0.5168, 0.5685, 0.4779],
       device='cuda:0') torch.Size([16])
percent tensor([0.9998, 0.9998, 0.9999, 0.9998, 0.9999, 0.9996, 0.9998, 0.9996, 0.9998,
        0.9998, 1.0000, 0.9998, 0.9999, 0.9992, 0.9996, 0.9994],
       device='cuda:0') torch.Size([16])
Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 3, 3, 3]) tensor(193.8027, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(847.7010, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(837.4603, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([128, 64, 3, 3]) tensor(1521.0942, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([128, 64, 1, 1]) tensor(468.1338, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([128, 128, 3, 3]) tensor(2351.5591, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([256, 128, 3, 3]) tensor(4262.3149, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([256, 128, 1, 1]) tensor(1326.2512, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([256, 256, 3, 3]) tensor(6334.0610, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([512, 256, 3, 3]) tensor(11427.7207, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([512, 256, 1, 1]) tensor(3745.1804, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([512, 512, 3, 3]) tensor(15810.5459, device='cuda:0', grad_fn=<NormBackward0>)
Epoch: 231 | Batch_idx: 0 |  Loss: (0.0376) |  Loss2: (0.0000) | Acc: (98.00%) (126/128)
Epoch: 231 | Batch_idx: 10 |  Loss: (0.0453) |  Loss2: (0.0000) | Acc: (98.00%) (1389/1408)
Epoch: 231 | Batch_idx: 20 |  Loss: (0.0497) |  Loss2: (0.0000) | Acc: (98.00%) (2644/2688)
Epoch: 231 | Batch_idx: 30 |  Loss: (0.0491) |  Loss2: (0.0000) | Acc: (98.00%) (3901/3968)
Epoch: 231 | Batch_idx: 40 |  Loss: (0.0474) |  Loss2: (0.0000) | Acc: (98.00%) (5163/5248)
Epoch: 231 | Batch_idx: 50 |  Loss: (0.0459) |  Loss2: (0.0000) | Acc: (98.00%) (6425/6528)
Epoch: 231 | Batch_idx: 60 |  Loss: (0.0450) |  Loss2: (0.0000) | Acc: (98.00%) (7688/7808)
Epoch: 231 | Batch_idx: 70 |  Loss: (0.0470) |  Loss2: (0.0000) | Acc: (98.00%) (8943/9088)
Epoch: 231 | Batch_idx: 80 |  Loss: (0.0451) |  Loss2: (0.0000) | Acc: (98.00%) (10207/10368)
Epoch: 231 | Batch_idx: 90 |  Loss: (0.0451) |  Loss2: (0.0000) | Acc: (98.00%) (11465/11648)
Epoch: 231 | Batch_idx: 100 |  Loss: (0.0443) |  Loss2: (0.0000) | Acc: (98.00%) (12729/12928)
Epoch: 231 | Batch_idx: 110 |  Loss: (0.0434) |  Loss2: (0.0000) | Acc: (98.00%) (13997/14208)
Epoch: 231 | Batch_idx: 120 |  Loss: (0.0438) |  Loss2: (0.0000) | Acc: (98.00%) (15261/15488)
Epoch: 231 | Batch_idx: 130 |  Loss: (0.0431) |  Loss2: (0.0000) | Acc: (98.00%) (16527/16768)
Epoch: 231 | Batch_idx: 140 |  Loss: (0.0429) |  Loss2: (0.0000) | Acc: (98.00%) (17788/18048)
Epoch: 231 | Batch_idx: 150 |  Loss: (0.0435) |  Loss2: (0.0000) | Acc: (98.00%) (19048/19328)
Epoch: 231 | Batch_idx: 160 |  Loss: (0.0439) |  Loss2: (0.0000) | Acc: (98.00%) (20307/20608)
Epoch: 231 | Batch_idx: 170 |  Loss: (0.0442) |  Loss2: (0.0000) | Acc: (98.00%) (21568/21888)
Epoch: 231 | Batch_idx: 180 |  Loss: (0.0443) |  Loss2: (0.0000) | Acc: (98.00%) (22832/23168)
Epoch: 231 | Batch_idx: 190 |  Loss: (0.0447) |  Loss2: (0.0000) | Acc: (98.00%) (24091/24448)
Epoch: 231 | Batch_idx: 200 |  Loss: (0.0448) |  Loss2: (0.0000) | Acc: (98.00%) (25352/25728)
Epoch: 231 | Batch_idx: 210 |  Loss: (0.0451) |  Loss2: (0.0000) | Acc: (98.00%) (26609/27008)
Epoch: 231 | Batch_idx: 220 |  Loss: (0.0450) |  Loss2: (0.0000) | Acc: (98.00%) (27872/28288)
Epoch: 231 | Batch_idx: 230 |  Loss: (0.0445) |  Loss2: (0.0000) | Acc: (98.00%) (29138/29568)
Epoch: 231 | Batch_idx: 240 |  Loss: (0.0445) |  Loss2: (0.0000) | Acc: (98.00%) (30399/30848)
Epoch: 231 | Batch_idx: 250 |  Loss: (0.0446) |  Loss2: (0.0000) | Acc: (98.00%) (31664/32128)
Epoch: 231 | Batch_idx: 260 |  Loss: (0.0443) |  Loss2: (0.0000) | Acc: (98.00%) (32933/33408)
Epoch: 231 | Batch_idx: 270 |  Loss: (0.0445) |  Loss2: (0.0000) | Acc: (98.00%) (34194/34688)
Epoch: 231 | Batch_idx: 280 |  Loss: (0.0442) |  Loss2: (0.0000) | Acc: (98.00%) (35462/35968)
Epoch: 231 | Batch_idx: 290 |  Loss: (0.0443) |  Loss2: (0.0000) | Acc: (98.00%) (36722/37248)
Epoch: 231 | Batch_idx: 300 |  Loss: (0.0450) |  Loss2: (0.0000) | Acc: (98.00%) (37976/38528)
Epoch: 231 | Batch_idx: 310 |  Loss: (0.0448) |  Loss2: (0.0000) | Acc: (98.00%) (39245/39808)
Epoch: 231 | Batch_idx: 320 |  Loss: (0.0447) |  Loss2: (0.0000) | Acc: (98.00%) (40509/41088)
Epoch: 231 | Batch_idx: 330 |  Loss: (0.0452) |  Loss2: (0.0000) | Acc: (98.00%) (41765/42368)
Epoch: 231 | Batch_idx: 340 |  Loss: (0.0454) |  Loss2: (0.0000) | Acc: (98.00%) (43025/43648)
Epoch: 231 | Batch_idx: 350 |  Loss: (0.0454) |  Loss2: (0.0000) | Acc: (98.00%) (44283/44928)
Epoch: 231 | Batch_idx: 360 |  Loss: (0.0458) |  Loss2: (0.0000) | Acc: (98.00%) (45539/46208)
Epoch: 231 | Batch_idx: 370 |  Loss: (0.0457) |  Loss2: (0.0000) | Acc: (98.00%) (46799/47488)
Epoch: 231 | Batch_idx: 380 |  Loss: (0.0457) |  Loss2: (0.0000) | Acc: (98.00%) (48061/48768)
Epoch: 231 | Batch_idx: 390 |  Loss: (0.0456) |  Loss2: (0.0000) | Acc: (98.00%) (49274/50000)
# TEST : Loss: (0.4487) | Acc: (89.00%) (8901/10000)
percent tensor([0.5375, 0.5314, 0.5439, 0.5385, 0.5495, 0.5439, 0.5384, 0.5427, 0.5428,
        0.5338, 0.5405, 0.5393, 0.5301, 0.5385, 0.5374, 0.5358],
       device='cuda:0') torch.Size([16])
percent tensor([0.5132, 0.5071, 0.5114, 0.5122, 0.5104, 0.5144, 0.5095, 0.5135, 0.5155,
        0.5095, 0.5154, 0.5074, 0.5060, 0.5207, 0.5090, 0.5151],
       device='cuda:0') torch.Size([16])
percent tensor([0.5832, 0.5584, 0.6037, 0.6142, 0.6159, 0.5895, 0.5954, 0.6086, 0.5927,
        0.5716, 0.5727, 0.5901, 0.5300, 0.6388, 0.5730, 0.6021],
       device='cuda:0') torch.Size([16])
percent tensor([0.6598, 0.6830, 0.6637, 0.6570, 0.6506, 0.6632, 0.6722, 0.6483, 0.6908,
        0.6915, 0.7053, 0.6808, 0.6880, 0.6964, 0.6545, 0.6758],
       device='cuda:0') torch.Size([16])
percent tensor([0.6340, 0.7133, 0.5704, 0.6569, 0.5741, 0.7036, 0.6539, 0.4367, 0.7451,
        0.6942, 0.7645, 0.6511, 0.7097, 0.7388, 0.5950, 0.6666],
       device='cuda:0') torch.Size([16])
percent tensor([0.7079, 0.7240, 0.7169, 0.7094, 0.7569, 0.7224, 0.7310, 0.7230, 0.7180,
        0.7138, 0.6806, 0.6667, 0.6924, 0.6991, 0.6897, 0.7296],
       device='cuda:0') torch.Size([16])
percent tensor([0.5373, 0.6389, 0.7303, 0.6277, 0.7517, 0.7709, 0.6517, 0.6177, 0.6505,
        0.5971, 0.6755, 0.6072, 0.6608, 0.5299, 0.5687, 0.4759],
       device='cuda:0') torch.Size([16])
percent tensor([0.9998, 0.9998, 0.9998, 0.9998, 0.9998, 0.9998, 0.9998, 0.9998, 0.9999,
        0.9999, 1.0000, 0.9998, 0.9999, 0.9992, 0.9998, 0.9995],
       device='cuda:0') torch.Size([16])
Epoch: 232 | Batch_idx: 0 |  Loss: (0.0751) |  Loss2: (0.0000) | Acc: (98.00%) (126/128)
Epoch: 232 | Batch_idx: 10 |  Loss: (0.0529) |  Loss2: (0.0000) | Acc: (98.00%) (1382/1408)
Epoch: 232 | Batch_idx: 20 |  Loss: (0.0464) |  Loss2: (0.0000) | Acc: (98.00%) (2648/2688)
Epoch: 232 | Batch_idx: 30 |  Loss: (0.0457) |  Loss2: (0.0000) | Acc: (98.00%) (3908/3968)
Epoch: 232 | Batch_idx: 40 |  Loss: (0.0442) |  Loss2: (0.0000) | Acc: (98.00%) (5171/5248)
Epoch: 232 | Batch_idx: 50 |  Loss: (0.0444) |  Loss2: (0.0000) | Acc: (98.00%) (6435/6528)
Epoch: 232 | Batch_idx: 60 |  Loss: (0.0450) |  Loss2: (0.0000) | Acc: (98.00%) (7693/7808)
Epoch: 232 | Batch_idx: 70 |  Loss: (0.0440) |  Loss2: (0.0000) | Acc: (98.00%) (8957/9088)
Epoch: 232 | Batch_idx: 80 |  Loss: (0.0433) |  Loss2: (0.0000) | Acc: (98.00%) (10223/10368)
Epoch: 232 | Batch_idx: 90 |  Loss: (0.0437) |  Loss2: (0.0000) | Acc: (98.00%) (11484/11648)
Epoch: 232 | Batch_idx: 100 |  Loss: (0.0446) |  Loss2: (0.0000) | Acc: (98.00%) (12737/12928)
Epoch: 232 | Batch_idx: 110 |  Loss: (0.0446) |  Loss2: (0.0000) | Acc: (98.00%) (14000/14208)
Epoch: 232 | Batch_idx: 120 |  Loss: (0.0449) |  Loss2: (0.0000) | Acc: (98.00%) (15252/15488)
Epoch: 232 | Batch_idx: 130 |  Loss: (0.0451) |  Loss2: (0.0000) | Acc: (98.00%) (16516/16768)
Epoch: 232 | Batch_idx: 140 |  Loss: (0.0450) |  Loss2: (0.0000) | Acc: (98.00%) (17776/18048)
Epoch: 232 | Batch_idx: 150 |  Loss: (0.0444) |  Loss2: (0.0000) | Acc: (98.00%) (19041/19328)
Epoch: 232 | Batch_idx: 160 |  Loss: (0.0453) |  Loss2: (0.0000) | Acc: (98.00%) (20294/20608)
Epoch: 232 | Batch_idx: 170 |  Loss: (0.0444) |  Loss2: (0.0000) | Acc: (98.00%) (21563/21888)
Epoch: 232 | Batch_idx: 180 |  Loss: (0.0441) |  Loss2: (0.0000) | Acc: (98.00%) (22827/23168)
Epoch: 232 | Batch_idx: 190 |  Loss: (0.0441) |  Loss2: (0.0000) | Acc: (98.00%) (24090/24448)
Epoch: 232 | Batch_idx: 200 |  Loss: (0.0444) |  Loss2: (0.0000) | Acc: (98.00%) (25345/25728)
Epoch: 232 | Batch_idx: 210 |  Loss: (0.0444) |  Loss2: (0.0000) | Acc: (98.00%) (26606/27008)
Epoch: 232 | Batch_idx: 220 |  Loss: (0.0448) |  Loss2: (0.0000) | Acc: (98.00%) (27867/28288)
Epoch: 232 | Batch_idx: 230 |  Loss: (0.0453) |  Loss2: (0.0000) | Acc: (98.00%) (29123/29568)
Epoch: 232 | Batch_idx: 240 |  Loss: (0.0458) |  Loss2: (0.0000) | Acc: (98.00%) (30380/30848)
Epoch: 232 | Batch_idx: 250 |  Loss: (0.0457) |  Loss2: (0.0000) | Acc: (98.00%) (31639/32128)
Epoch: 232 | Batch_idx: 260 |  Loss: (0.0454) |  Loss2: (0.0000) | Acc: (98.00%) (32901/33408)
Epoch: 232 | Batch_idx: 270 |  Loss: (0.0454) |  Loss2: (0.0000) | Acc: (98.00%) (34161/34688)
Epoch: 232 | Batch_idx: 280 |  Loss: (0.0450) |  Loss2: (0.0000) | Acc: (98.00%) (35426/35968)
Epoch: 232 | Batch_idx: 290 |  Loss: (0.0451) |  Loss2: (0.0000) | Acc: (98.00%) (36687/37248)
Epoch: 232 | Batch_idx: 300 |  Loss: (0.0449) |  Loss2: (0.0000) | Acc: (98.00%) (37950/38528)
Epoch: 232 | Batch_idx: 310 |  Loss: (0.0448) |  Loss2: (0.0000) | Acc: (98.00%) (39210/39808)
Epoch: 232 | Batch_idx: 320 |  Loss: (0.0451) |  Loss2: (0.0000) | Acc: (98.00%) (40470/41088)
Epoch: 232 | Batch_idx: 330 |  Loss: (0.0452) |  Loss2: (0.0000) | Acc: (98.00%) (41729/42368)
Epoch: 232 | Batch_idx: 340 |  Loss: (0.0451) |  Loss2: (0.0000) | Acc: (98.00%) (42991/43648)
Epoch: 232 | Batch_idx: 350 |  Loss: (0.0454) |  Loss2: (0.0000) | Acc: (98.00%) (44251/44928)
Epoch: 232 | Batch_idx: 360 |  Loss: (0.0453) |  Loss2: (0.0000) | Acc: (98.00%) (45515/46208)
Epoch: 232 | Batch_idx: 370 |  Loss: (0.0455) |  Loss2: (0.0000) | Acc: (98.00%) (46773/47488)
Epoch: 232 | Batch_idx: 380 |  Loss: (0.0455) |  Loss2: (0.0000) | Acc: (98.00%) (48035/48768)
Epoch: 232 | Batch_idx: 390 |  Loss: (0.0456) |  Loss2: (0.0000) | Acc: (98.00%) (49243/50000)
# TEST : Loss: (0.4889) | Acc: (87.00%) (8725/10000)
percent tensor([0.5382, 0.5307, 0.5429, 0.5374, 0.5488, 0.5445, 0.5376, 0.5418, 0.5431,
        0.5332, 0.5408, 0.5386, 0.5304, 0.5372, 0.5372, 0.5356],
       device='cuda:0') torch.Size([16])
percent tensor([0.5135, 0.5079, 0.5104, 0.5123, 0.5107, 0.5153, 0.5098, 0.5127, 0.5157,
        0.5095, 0.5155, 0.5063, 0.5054, 0.5218, 0.5095, 0.5154],
       device='cuda:0') torch.Size([16])
percent tensor([0.5865, 0.5559, 0.6051, 0.6150, 0.6184, 0.5998, 0.5974, 0.6081, 0.5947,
        0.5709, 0.5733, 0.5909, 0.5295, 0.6401, 0.5764, 0.6028],
       device='cuda:0') torch.Size([16])
percent tensor([0.6593, 0.6826, 0.6646, 0.6568, 0.6509, 0.6633, 0.6721, 0.6478, 0.6915,
        0.6930, 0.7035, 0.6796, 0.6845, 0.7001, 0.6553, 0.6771],
       device='cuda:0') torch.Size([16])
percent tensor([0.6308, 0.7128, 0.5696, 0.6793, 0.5630, 0.6828, 0.6609, 0.4292, 0.7514,
        0.6946, 0.7682, 0.6618, 0.7104, 0.7402, 0.5853, 0.6581],
       device='cuda:0') torch.Size([16])
percent tensor([0.7065, 0.7187, 0.7239, 0.7157, 0.7575, 0.7253, 0.7266, 0.7212, 0.7185,
        0.7133, 0.6813, 0.6724, 0.6883, 0.7054, 0.6865, 0.7313],
       device='cuda:0') torch.Size([16])
percent tensor([0.4984, 0.5901, 0.7219, 0.6506, 0.7309, 0.7458, 0.6225, 0.5646, 0.6458,
        0.5435, 0.6861, 0.5921, 0.6139, 0.4864, 0.5713, 0.4637],
       device='cuda:0') torch.Size([16])
percent tensor([0.9998, 0.9998, 0.9998, 0.9998, 0.9997, 0.9997, 0.9997, 0.9997, 0.9997,
        0.9998, 0.9999, 0.9999, 0.9998, 0.9993, 0.9998, 0.9995],
       device='cuda:0') torch.Size([16])
Epoch: 233 | Batch_idx: 0 |  Loss: (0.0272) |  Loss2: (0.0000) | Acc: (99.00%) (127/128)
Epoch: 233 | Batch_idx: 10 |  Loss: (0.0407) |  Loss2: (0.0000) | Acc: (99.00%) (1394/1408)
Epoch: 233 | Batch_idx: 20 |  Loss: (0.0425) |  Loss2: (0.0000) | Acc: (98.00%) (2651/2688)
Epoch: 233 | Batch_idx: 30 |  Loss: (0.0447) |  Loss2: (0.0000) | Acc: (98.00%) (3906/3968)
Epoch: 233 | Batch_idx: 40 |  Loss: (0.0435) |  Loss2: (0.0000) | Acc: (98.00%) (5175/5248)
Epoch: 233 | Batch_idx: 50 |  Loss: (0.0430) |  Loss2: (0.0000) | Acc: (98.00%) (6434/6528)
Epoch: 233 | Batch_idx: 60 |  Loss: (0.0429) |  Loss2: (0.0000) | Acc: (98.00%) (7696/7808)
Epoch: 233 | Batch_idx: 70 |  Loss: (0.0431) |  Loss2: (0.0000) | Acc: (98.00%) (8957/9088)
Epoch: 233 | Batch_idx: 80 |  Loss: (0.0430) |  Loss2: (0.0000) | Acc: (98.00%) (10216/10368)
Epoch: 233 | Batch_idx: 90 |  Loss: (0.0437) |  Loss2: (0.0000) | Acc: (98.00%) (11476/11648)
Epoch: 233 | Batch_idx: 100 |  Loss: (0.0438) |  Loss2: (0.0000) | Acc: (98.00%) (12740/12928)
Epoch: 233 | Batch_idx: 110 |  Loss: (0.0446) |  Loss2: (0.0000) | Acc: (98.00%) (13998/14208)
Epoch: 233 | Batch_idx: 120 |  Loss: (0.0443) |  Loss2: (0.0000) | Acc: (98.00%) (15263/15488)
Epoch: 233 | Batch_idx: 130 |  Loss: (0.0435) |  Loss2: (0.0000) | Acc: (98.00%) (16533/16768)
Epoch: 233 | Batch_idx: 140 |  Loss: (0.0442) |  Loss2: (0.0000) | Acc: (98.00%) (17789/18048)
Epoch: 233 | Batch_idx: 150 |  Loss: (0.0443) |  Loss2: (0.0000) | Acc: (98.00%) (19049/19328)
Epoch: 233 | Batch_idx: 160 |  Loss: (0.0439) |  Loss2: (0.0000) | Acc: (98.00%) (20315/20608)
Epoch: 233 | Batch_idx: 170 |  Loss: (0.0443) |  Loss2: (0.0000) | Acc: (98.00%) (21579/21888)
Epoch: 233 | Batch_idx: 180 |  Loss: (0.0435) |  Loss2: (0.0000) | Acc: (98.00%) (22846/23168)
Epoch: 233 | Batch_idx: 190 |  Loss: (0.0433) |  Loss2: (0.0000) | Acc: (98.00%) (24110/24448)
Epoch: 233 | Batch_idx: 200 |  Loss: (0.0432) |  Loss2: (0.0000) | Acc: (98.00%) (25373/25728)
Epoch: 233 | Batch_idx: 210 |  Loss: (0.0434) |  Loss2: (0.0000) | Acc: (98.00%) (26635/27008)
Epoch: 233 | Batch_idx: 220 |  Loss: (0.0433) |  Loss2: (0.0000) | Acc: (98.00%) (27899/28288)
Epoch: 233 | Batch_idx: 230 |  Loss: (0.0431) |  Loss2: (0.0000) | Acc: (98.00%) (29162/29568)
Epoch: 233 | Batch_idx: 240 |  Loss: (0.0429) |  Loss2: (0.0000) | Acc: (98.00%) (30426/30848)
Epoch: 233 | Batch_idx: 250 |  Loss: (0.0427) |  Loss2: (0.0000) | Acc: (98.00%) (31691/32128)
Epoch: 233 | Batch_idx: 260 |  Loss: (0.0429) |  Loss2: (0.0000) | Acc: (98.00%) (32951/33408)
Epoch: 233 | Batch_idx: 270 |  Loss: (0.0430) |  Loss2: (0.0000) | Acc: (98.00%) (34212/34688)
Epoch: 233 | Batch_idx: 280 |  Loss: (0.0430) |  Loss2: (0.0000) | Acc: (98.00%) (35475/35968)
Epoch: 233 | Batch_idx: 290 |  Loss: (0.0428) |  Loss2: (0.0000) | Acc: (98.00%) (36743/37248)
Epoch: 233 | Batch_idx: 300 |  Loss: (0.0428) |  Loss2: (0.0000) | Acc: (98.00%) (38001/38528)
Epoch: 233 | Batch_idx: 310 |  Loss: (0.0426) |  Loss2: (0.0000) | Acc: (98.00%) (39265/39808)
Epoch: 233 | Batch_idx: 320 |  Loss: (0.0425) |  Loss2: (0.0000) | Acc: (98.00%) (40529/41088)
Epoch: 233 | Batch_idx: 330 |  Loss: (0.0426) |  Loss2: (0.0000) | Acc: (98.00%) (41788/42368)
Epoch: 233 | Batch_idx: 340 |  Loss: (0.0426) |  Loss2: (0.0000) | Acc: (98.00%) (43051/43648)
Epoch: 233 | Batch_idx: 350 |  Loss: (0.0427) |  Loss2: (0.0000) | Acc: (98.00%) (44311/44928)
Epoch: 233 | Batch_idx: 360 |  Loss: (0.0425) |  Loss2: (0.0000) | Acc: (98.00%) (45573/46208)
Epoch: 233 | Batch_idx: 370 |  Loss: (0.0427) |  Loss2: (0.0000) | Acc: (98.00%) (46830/47488)
Epoch: 233 | Batch_idx: 380 |  Loss: (0.0427) |  Loss2: (0.0000) | Acc: (98.00%) (48090/48768)
Epoch: 233 | Batch_idx: 390 |  Loss: (0.0426) |  Loss2: (0.0000) | Acc: (98.00%) (49308/50000)
# TEST : Loss: (0.4430) | Acc: (88.00%) (8882/10000)
percent tensor([0.5363, 0.5304, 0.5415, 0.5373, 0.5473, 0.5424, 0.5372, 0.5416, 0.5423,
        0.5323, 0.5395, 0.5373, 0.5291, 0.5387, 0.5359, 0.5343],
       device='cuda:0') torch.Size([16])
percent tensor([0.5138, 0.5072, 0.5123, 0.5123, 0.5114, 0.5148, 0.5097, 0.5137, 0.5162,
        0.5096, 0.5156, 0.5075, 0.5060, 0.5203, 0.5091, 0.5152],
       device='cuda:0') torch.Size([16])
percent tensor([0.5857, 0.5591, 0.6026, 0.6131, 0.6183, 0.5968, 0.5960, 0.6077, 0.5958,
        0.5720, 0.5735, 0.5934, 0.5318, 0.6373, 0.5748, 0.6039],
       device='cuda:0') torch.Size([16])
percent tensor([0.6565, 0.6802, 0.6593, 0.6562, 0.6472, 0.6590, 0.6698, 0.6434, 0.6884,
        0.6903, 0.6996, 0.6776, 0.6839, 0.6942, 0.6511, 0.6740],
       device='cuda:0') torch.Size([16])
percent tensor([0.6316, 0.7228, 0.5789, 0.6608, 0.5665, 0.6865, 0.6679, 0.4298, 0.7511,
        0.7079, 0.7806, 0.6610, 0.7224, 0.7535, 0.5928, 0.6551],
       device='cuda:0') torch.Size([16])
percent tensor([0.7133, 0.7236, 0.7301, 0.7192, 0.7616, 0.7281, 0.7313, 0.7262, 0.7203,
        0.7139, 0.6813, 0.6799, 0.6960, 0.7051, 0.6947, 0.7283],
       device='cuda:0') torch.Size([16])
percent tensor([0.5595, 0.6043, 0.7533, 0.6644, 0.7635, 0.7410, 0.6085, 0.6206, 0.6639,
        0.5886, 0.6990, 0.5954, 0.6600, 0.5018, 0.5851, 0.4780],
       device='cuda:0') torch.Size([16])
percent tensor([0.9999, 0.9998, 0.9999, 0.9999, 0.9998, 0.9997, 0.9997, 0.9996, 0.9999,
        0.9999, 1.0000, 0.9999, 0.9999, 0.9991, 0.9997, 0.9995],
       device='cuda:0') torch.Size([16])
Epoch: 234 | Batch_idx: 0 |  Loss: (0.0519) |  Loss2: (0.0000) | Acc: (99.00%) (127/128)
Epoch: 234 | Batch_idx: 10 |  Loss: (0.0475) |  Loss2: (0.0000) | Acc: (98.00%) (1384/1408)
Epoch: 234 | Batch_idx: 20 |  Loss: (0.0433) |  Loss2: (0.0000) | Acc: (98.00%) (2645/2688)
Epoch: 234 | Batch_idx: 30 |  Loss: (0.0410) |  Loss2: (0.0000) | Acc: (98.00%) (3912/3968)
Epoch: 234 | Batch_idx: 40 |  Loss: (0.0389) |  Loss2: (0.0000) | Acc: (98.00%) (5180/5248)
Epoch: 234 | Batch_idx: 50 |  Loss: (0.0389) |  Loss2: (0.0000) | Acc: (98.00%) (6443/6528)
Epoch: 234 | Batch_idx: 60 |  Loss: (0.0403) |  Loss2: (0.0000) | Acc: (98.00%) (7701/7808)
Epoch: 234 | Batch_idx: 70 |  Loss: (0.0407) |  Loss2: (0.0000) | Acc: (98.00%) (8959/9088)
Epoch: 234 | Batch_idx: 80 |  Loss: (0.0402) |  Loss2: (0.0000) | Acc: (98.00%) (10224/10368)
Epoch: 234 | Batch_idx: 90 |  Loss: (0.0401) |  Loss2: (0.0000) | Acc: (98.00%) (11486/11648)
Epoch: 234 | Batch_idx: 100 |  Loss: (0.0397) |  Loss2: (0.0000) | Acc: (98.00%) (12755/12928)
Epoch: 234 | Batch_idx: 110 |  Loss: (0.0388) |  Loss2: (0.0000) | Acc: (98.00%) (14024/14208)
Epoch: 234 | Batch_idx: 120 |  Loss: (0.0382) |  Loss2: (0.0000) | Acc: (98.00%) (15292/15488)
Epoch: 234 | Batch_idx: 130 |  Loss: (0.0380) |  Loss2: (0.0000) | Acc: (98.00%) (16559/16768)
Epoch: 234 | Batch_idx: 140 |  Loss: (0.0382) |  Loss2: (0.0000) | Acc: (98.00%) (17817/18048)
Epoch: 234 | Batch_idx: 150 |  Loss: (0.0376) |  Loss2: (0.0000) | Acc: (98.00%) (19088/19328)
Epoch: 234 | Batch_idx: 160 |  Loss: (0.0377) |  Loss2: (0.0000) | Acc: (98.00%) (20352/20608)
Epoch: 234 | Batch_idx: 170 |  Loss: (0.0375) |  Loss2: (0.0000) | Acc: (98.00%) (21619/21888)
Epoch: 234 | Batch_idx: 180 |  Loss: (0.0373) |  Loss2: (0.0000) | Acc: (98.00%) (22889/23168)
Epoch: 234 | Batch_idx: 190 |  Loss: (0.0375) |  Loss2: (0.0000) | Acc: (98.00%) (24152/24448)
Epoch: 234 | Batch_idx: 200 |  Loss: (0.0374) |  Loss2: (0.0000) | Acc: (98.00%) (25416/25728)
Epoch: 234 | Batch_idx: 210 |  Loss: (0.0374) |  Loss2: (0.0000) | Acc: (98.00%) (26684/27008)
Epoch: 234 | Batch_idx: 220 |  Loss: (0.0372) |  Loss2: (0.0000) | Acc: (98.00%) (27948/28288)
Epoch: 234 | Batch_idx: 230 |  Loss: (0.0370) |  Loss2: (0.0000) | Acc: (98.00%) (29216/29568)
Epoch: 234 | Batch_idx: 240 |  Loss: (0.0378) |  Loss2: (0.0000) | Acc: (98.00%) (30475/30848)
Epoch: 234 | Batch_idx: 250 |  Loss: (0.0378) |  Loss2: (0.0000) | Acc: (98.00%) (31733/32128)
Epoch: 234 | Batch_idx: 260 |  Loss: (0.0380) |  Loss2: (0.0000) | Acc: (98.00%) (32992/33408)
Epoch: 234 | Batch_idx: 270 |  Loss: (0.0378) |  Loss2: (0.0000) | Acc: (98.00%) (34265/34688)
Epoch: 234 | Batch_idx: 280 |  Loss: (0.0379) |  Loss2: (0.0000) | Acc: (98.00%) (35527/35968)
Epoch: 234 | Batch_idx: 290 |  Loss: (0.0385) |  Loss2: (0.0000) | Acc: (98.00%) (36787/37248)
Epoch: 234 | Batch_idx: 300 |  Loss: (0.0390) |  Loss2: (0.0000) | Acc: (98.00%) (38045/38528)
Epoch: 234 | Batch_idx: 310 |  Loss: (0.0393) |  Loss2: (0.0000) | Acc: (98.00%) (39303/39808)
Epoch: 234 | Batch_idx: 320 |  Loss: (0.0392) |  Loss2: (0.0000) | Acc: (98.00%) (40573/41088)
Epoch: 234 | Batch_idx: 330 |  Loss: (0.0395) |  Loss2: (0.0000) | Acc: (98.00%) (41828/42368)
Epoch: 234 | Batch_idx: 340 |  Loss: (0.0397) |  Loss2: (0.0000) | Acc: (98.00%) (43090/43648)
Epoch: 234 | Batch_idx: 350 |  Loss: (0.0401) |  Loss2: (0.0000) | Acc: (98.00%) (44345/44928)
Epoch: 234 | Batch_idx: 360 |  Loss: (0.0401) |  Loss2: (0.0000) | Acc: (98.00%) (45610/46208)
Epoch: 234 | Batch_idx: 370 |  Loss: (0.0402) |  Loss2: (0.0000) | Acc: (98.00%) (46871/47488)
Epoch: 234 | Batch_idx: 380 |  Loss: (0.0403) |  Loss2: (0.0000) | Acc: (98.00%) (48132/48768)
Epoch: 234 | Batch_idx: 390 |  Loss: (0.0403) |  Loss2: (0.0000) | Acc: (98.00%) (49343/50000)
# TEST : Loss: (0.4456) | Acc: (88.00%) (8884/10000)
percent tensor([0.5375, 0.5302, 0.5432, 0.5372, 0.5490, 0.5435, 0.5376, 0.5416, 0.5424,
        0.5334, 0.5402, 0.5392, 0.5301, 0.5365, 0.5362, 0.5348],
       device='cuda:0') torch.Size([16])
percent tensor([0.5144, 0.5072, 0.5137, 0.5131, 0.5127, 0.5147, 0.5103, 0.5141, 0.5161,
        0.5102, 0.5158, 0.5091, 0.5069, 0.5195, 0.5092, 0.5153],
       device='cuda:0') torch.Size([16])
percent tensor([0.5868, 0.5634, 0.6076, 0.6163, 0.6215, 0.6067, 0.6006, 0.6126, 0.5938,
        0.5717, 0.5754, 0.5962, 0.5323, 0.6453, 0.5819, 0.6082],
       device='cuda:0') torch.Size([16])
percent tensor([0.6543, 0.6818, 0.6575, 0.6519, 0.6443, 0.6569, 0.6706, 0.6436, 0.6862,
        0.6884, 0.6992, 0.6747, 0.6839, 0.6946, 0.6502, 0.6728],
       device='cuda:0') torch.Size([16])
percent tensor([0.6174, 0.7222, 0.5432, 0.6496, 0.5622, 0.6780, 0.6654, 0.4284, 0.7444,
        0.6915, 0.7637, 0.6228, 0.7081, 0.7531, 0.5922, 0.6475],
       device='cuda:0') torch.Size([16])
percent tensor([0.7106, 0.7237, 0.7312, 0.7244, 0.7646, 0.7257, 0.7272, 0.7291, 0.7218,
        0.7176, 0.6830, 0.6844, 0.6953, 0.7062, 0.6902, 0.7287],
       device='cuda:0') torch.Size([16])
percent tensor([0.5331, 0.6112, 0.7360, 0.6653, 0.7649, 0.7400, 0.5966, 0.5852, 0.6668,
        0.5848, 0.6900, 0.6046, 0.6371, 0.4935, 0.5607, 0.4642],
       device='cuda:0') torch.Size([16])
percent tensor([0.9999, 0.9997, 0.9998, 0.9998, 0.9997, 0.9998, 0.9998, 0.9997, 0.9999,
        0.9998, 0.9999, 0.9999, 0.9998, 0.9994, 0.9997, 0.9996],
       device='cuda:0') torch.Size([16])
Epoch: 235 | Batch_idx: 0 |  Loss: (0.0487) |  Loss2: (0.0000) | Acc: (98.00%) (126/128)
Epoch: 235 | Batch_idx: 10 |  Loss: (0.0421) |  Loss2: (0.0000) | Acc: (98.00%) (1388/1408)
Epoch: 235 | Batch_idx: 20 |  Loss: (0.0411) |  Loss2: (0.0000) | Acc: (98.00%) (2650/2688)
Epoch: 235 | Batch_idx: 30 |  Loss: (0.0402) |  Loss2: (0.0000) | Acc: (98.00%) (3913/3968)
Epoch: 235 | Batch_idx: 40 |  Loss: (0.0429) |  Loss2: (0.0000) | Acc: (98.00%) (5170/5248)
Epoch: 235 | Batch_idx: 50 |  Loss: (0.0419) |  Loss2: (0.0000) | Acc: (98.00%) (6438/6528)
Epoch: 235 | Batch_idx: 60 |  Loss: (0.0427) |  Loss2: (0.0000) | Acc: (98.00%) (7703/7808)
Epoch: 235 | Batch_idx: 70 |  Loss: (0.0424) |  Loss2: (0.0000) | Acc: (98.00%) (8965/9088)
Epoch: 235 | Batch_idx: 80 |  Loss: (0.0413) |  Loss2: (0.0000) | Acc: (98.00%) (10233/10368)
Epoch: 235 | Batch_idx: 90 |  Loss: (0.0409) |  Loss2: (0.0000) | Acc: (98.00%) (11497/11648)
Epoch: 235 | Batch_idx: 100 |  Loss: (0.0403) |  Loss2: (0.0000) | Acc: (98.00%) (12764/12928)
Epoch: 235 | Batch_idx: 110 |  Loss: (0.0393) |  Loss2: (0.0000) | Acc: (98.00%) (14033/14208)
Epoch: 235 | Batch_idx: 120 |  Loss: (0.0394) |  Loss2: (0.0000) | Acc: (98.00%) (15297/15488)
Epoch: 235 | Batch_idx: 130 |  Loss: (0.0402) |  Loss2: (0.0000) | Acc: (98.00%) (16554/16768)
Epoch: 235 | Batch_idx: 140 |  Loss: (0.0410) |  Loss2: (0.0000) | Acc: (98.00%) (17813/18048)
Epoch: 235 | Batch_idx: 150 |  Loss: (0.0417) |  Loss2: (0.0000) | Acc: (98.00%) (19074/19328)
Epoch: 235 | Batch_idx: 160 |  Loss: (0.0418) |  Loss2: (0.0000) | Acc: (98.00%) (20332/20608)
Epoch: 235 | Batch_idx: 170 |  Loss: (0.0415) |  Loss2: (0.0000) | Acc: (98.00%) (21595/21888)
Epoch: 235 | Batch_idx: 180 |  Loss: (0.0416) |  Loss2: (0.0000) | Acc: (98.00%) (22860/23168)
Epoch: 235 | Batch_idx: 190 |  Loss: (0.0416) |  Loss2: (0.0000) | Acc: (98.00%) (24120/24448)
Epoch: 235 | Batch_idx: 200 |  Loss: (0.0418) |  Loss2: (0.0000) | Acc: (98.00%) (25379/25728)
Epoch: 235 | Batch_idx: 210 |  Loss: (0.0419) |  Loss2: (0.0000) | Acc: (98.00%) (26643/27008)
Epoch: 235 | Batch_idx: 220 |  Loss: (0.0418) |  Loss2: (0.0000) | Acc: (98.00%) (27908/28288)
Epoch: 235 | Batch_idx: 230 |  Loss: (0.0415) |  Loss2: (0.0000) | Acc: (98.00%) (29177/29568)
Epoch: 235 | Batch_idx: 240 |  Loss: (0.0409) |  Loss2: (0.0000) | Acc: (98.00%) (30451/30848)
Epoch: 235 | Batch_idx: 250 |  Loss: (0.0404) |  Loss2: (0.0000) | Acc: (98.00%) (31721/32128)
Epoch: 235 | Batch_idx: 260 |  Loss: (0.0402) |  Loss2: (0.0000) | Acc: (98.00%) (32988/33408)
Epoch: 235 | Batch_idx: 270 |  Loss: (0.0409) |  Loss2: (0.0000) | Acc: (98.00%) (34243/34688)
Epoch: 235 | Batch_idx: 280 |  Loss: (0.0410) |  Loss2: (0.0000) | Acc: (98.00%) (35504/35968)
Epoch: 235 | Batch_idx: 290 |  Loss: (0.0411) |  Loss2: (0.0000) | Acc: (98.00%) (36767/37248)
Epoch: 235 | Batch_idx: 300 |  Loss: (0.0413) |  Loss2: (0.0000) | Acc: (98.00%) (38027/38528)
Epoch: 235 | Batch_idx: 310 |  Loss: (0.0410) |  Loss2: (0.0000) | Acc: (98.00%) (39295/39808)
Epoch: 235 | Batch_idx: 320 |  Loss: (0.0412) |  Loss2: (0.0000) | Acc: (98.00%) (40556/41088)
Epoch: 235 | Batch_idx: 330 |  Loss: (0.0414) |  Loss2: (0.0000) | Acc: (98.00%) (41814/42368)
Epoch: 235 | Batch_idx: 340 |  Loss: (0.0414) |  Loss2: (0.0000) | Acc: (98.00%) (43074/43648)
Epoch: 235 | Batch_idx: 350 |  Loss: (0.0417) |  Loss2: (0.0000) | Acc: (98.00%) (44330/44928)
Epoch: 235 | Batch_idx: 360 |  Loss: (0.0417) |  Loss2: (0.0000) | Acc: (98.00%) (45593/46208)
Epoch: 235 | Batch_idx: 370 |  Loss: (0.0418) |  Loss2: (0.0000) | Acc: (98.00%) (46850/47488)
Epoch: 235 | Batch_idx: 380 |  Loss: (0.0418) |  Loss2: (0.0000) | Acc: (98.00%) (48112/48768)
Epoch: 235 | Batch_idx: 390 |  Loss: (0.0421) |  Loss2: (0.0000) | Acc: (98.00%) (49321/50000)
=> saving checkpoint 'drive/app/torch/save_Schedule/checkpoint_235.pth.tar'
# TEST : Loss: (0.4281) | Acc: (89.00%) (8924/10000)
percent tensor([0.5379, 0.5310, 0.5430, 0.5385, 0.5487, 0.5440, 0.5382, 0.5419, 0.5423,
        0.5334, 0.5404, 0.5391, 0.5300, 0.5384, 0.5370, 0.5359],
       device='cuda:0') torch.Size([16])
percent tensor([0.5143, 0.5088, 0.5125, 0.5136, 0.5118, 0.5154, 0.5111, 0.5146, 0.5173,
        0.5107, 0.5163, 0.5078, 0.5070, 0.5226, 0.5101, 0.5163],
       device='cuda:0') torch.Size([16])
percent tensor([0.5938, 0.5676, 0.5989, 0.6192, 0.6145, 0.6015, 0.6022, 0.6126, 0.5997,
        0.5777, 0.5800, 0.5937, 0.5402, 0.6500, 0.5819, 0.6121],
       device='cuda:0') torch.Size([16])
percent tensor([0.6612, 0.6798, 0.6651, 0.6613, 0.6517, 0.6632, 0.6718, 0.6490, 0.6909,
        0.6907, 0.7024, 0.6790, 0.6876, 0.6969, 0.6540, 0.6783],
       device='cuda:0') torch.Size([16])
percent tensor([0.6427, 0.7142, 0.5739, 0.6546, 0.5878, 0.7122, 0.6685, 0.4226, 0.7502,
        0.6949, 0.7783, 0.6492, 0.7142, 0.7406, 0.5973, 0.6588],
       device='cuda:0') torch.Size([16])
percent tensor([0.7121, 0.7300, 0.7236, 0.7236, 0.7618, 0.7241, 0.7349, 0.7327, 0.7195,
        0.7186, 0.6846, 0.6826, 0.6940, 0.7138, 0.6954, 0.7341],
       device='cuda:0') torch.Size([16])
percent tensor([0.5547, 0.6200, 0.7228, 0.6542, 0.7459, 0.7619, 0.6381, 0.6020, 0.6596,
        0.5929, 0.7005, 0.5808, 0.6483, 0.5082, 0.5676, 0.4757],
       device='cuda:0') torch.Size([16])
percent tensor([0.9999, 0.9998, 0.9999, 0.9998, 0.9998, 0.9998, 0.9998, 0.9998, 0.9998,
        0.9999, 1.0000, 0.9999, 0.9999, 0.9992, 0.9998, 0.9995],
       device='cuda:0') torch.Size([16])
Epoch: 236 | Batch_idx: 0 |  Loss: (0.0643) |  Loss2: (0.0000) | Acc: (96.00%) (124/128)
Epoch: 236 | Batch_idx: 10 |  Loss: (0.0366) |  Loss2: (0.0000) | Acc: (99.00%) (1395/1408)
Epoch: 236 | Batch_idx: 20 |  Loss: (0.0375) |  Loss2: (0.0000) | Acc: (99.00%) (2663/2688)
Epoch: 236 | Batch_idx: 30 |  Loss: (0.0364) |  Loss2: (0.0000) | Acc: (99.00%) (3933/3968)
Epoch: 236 | Batch_idx: 40 |  Loss: (0.0381) |  Loss2: (0.0000) | Acc: (98.00%) (5194/5248)
Epoch: 236 | Batch_idx: 50 |  Loss: (0.0387) |  Loss2: (0.0000) | Acc: (98.00%) (6454/6528)
Epoch: 236 | Batch_idx: 60 |  Loss: (0.0377) |  Loss2: (0.0000) | Acc: (98.00%) (7725/7808)
Epoch: 236 | Batch_idx: 70 |  Loss: (0.0378) |  Loss2: (0.0000) | Acc: (98.00%) (8988/9088)
Epoch: 236 | Batch_idx: 80 |  Loss: (0.0394) |  Loss2: (0.0000) | Acc: (98.00%) (10247/10368)
Epoch: 236 | Batch_idx: 90 |  Loss: (0.0401) |  Loss2: (0.0000) | Acc: (98.00%) (11505/11648)
Epoch: 236 | Batch_idx: 100 |  Loss: (0.0397) |  Loss2: (0.0000) | Acc: (98.00%) (12771/12928)
Epoch: 236 | Batch_idx: 110 |  Loss: (0.0400) |  Loss2: (0.0000) | Acc: (98.00%) (14029/14208)
Epoch: 236 | Batch_idx: 120 |  Loss: (0.0397) |  Loss2: (0.0000) | Acc: (98.00%) (15293/15488)
Epoch: 236 | Batch_idx: 130 |  Loss: (0.0397) |  Loss2: (0.0000) | Acc: (98.00%) (16555/16768)
Epoch: 236 | Batch_idx: 140 |  Loss: (0.0399) |  Loss2: (0.0000) | Acc: (98.00%) (17824/18048)
Epoch: 236 | Batch_idx: 150 |  Loss: (0.0397) |  Loss2: (0.0000) | Acc: (98.00%) (19092/19328)
Epoch: 236 | Batch_idx: 160 |  Loss: (0.0398) |  Loss2: (0.0000) | Acc: (98.00%) (20351/20608)
Epoch: 236 | Batch_idx: 170 |  Loss: (0.0409) |  Loss2: (0.0000) | Acc: (98.00%) (21613/21888)
Epoch: 236 | Batch_idx: 180 |  Loss: (0.0409) |  Loss2: (0.0000) | Acc: (98.00%) (22877/23168)
Epoch: 236 | Batch_idx: 190 |  Loss: (0.0406) |  Loss2: (0.0000) | Acc: (98.00%) (24144/24448)
Epoch: 236 | Batch_idx: 200 |  Loss: (0.0405) |  Loss2: (0.0000) | Acc: (98.00%) (25407/25728)
Epoch: 236 | Batch_idx: 210 |  Loss: (0.0409) |  Loss2: (0.0000) | Acc: (98.00%) (26661/27008)
Epoch: 236 | Batch_idx: 220 |  Loss: (0.0413) |  Loss2: (0.0000) | Acc: (98.00%) (27917/28288)
Epoch: 236 | Batch_idx: 230 |  Loss: (0.0416) |  Loss2: (0.0000) | Acc: (98.00%) (29174/29568)
Epoch: 236 | Batch_idx: 240 |  Loss: (0.0417) |  Loss2: (0.0000) | Acc: (98.00%) (30438/30848)
Epoch: 236 | Batch_idx: 250 |  Loss: (0.0415) |  Loss2: (0.0000) | Acc: (98.00%) (31704/32128)
Epoch: 236 | Batch_idx: 260 |  Loss: (0.0413) |  Loss2: (0.0000) | Acc: (98.00%) (32968/33408)
Epoch: 236 | Batch_idx: 270 |  Loss: (0.0411) |  Loss2: (0.0000) | Acc: (98.00%) (34233/34688)
Epoch: 236 | Batch_idx: 280 |  Loss: (0.0409) |  Loss2: (0.0000) | Acc: (98.00%) (35502/35968)
Epoch: 236 | Batch_idx: 290 |  Loss: (0.0408) |  Loss2: (0.0000) | Acc: (98.00%) (36769/37248)
Epoch: 236 | Batch_idx: 300 |  Loss: (0.0409) |  Loss2: (0.0000) | Acc: (98.00%) (38030/38528)
Epoch: 236 | Batch_idx: 310 |  Loss: (0.0407) |  Loss2: (0.0000) | Acc: (98.00%) (39294/39808)
Epoch: 236 | Batch_idx: 320 |  Loss: (0.0412) |  Loss2: (0.0000) | Acc: (98.00%) (40552/41088)
Epoch: 236 | Batch_idx: 330 |  Loss: (0.0412) |  Loss2: (0.0000) | Acc: (98.00%) (41815/42368)
Epoch: 236 | Batch_idx: 340 |  Loss: (0.0410) |  Loss2: (0.0000) | Acc: (98.00%) (43081/43648)
Epoch: 236 | Batch_idx: 350 |  Loss: (0.0406) |  Loss2: (0.0000) | Acc: (98.00%) (44350/44928)
Epoch: 236 | Batch_idx: 360 |  Loss: (0.0407) |  Loss2: (0.0000) | Acc: (98.00%) (45613/46208)
Epoch: 236 | Batch_idx: 370 |  Loss: (0.0405) |  Loss2: (0.0000) | Acc: (98.00%) (46878/47488)
Epoch: 236 | Batch_idx: 380 |  Loss: (0.0405) |  Loss2: (0.0000) | Acc: (98.00%) (48130/48768)
Epoch: 236 | Batch_idx: 390 |  Loss: (0.0406) |  Loss2: (0.0000) | Acc: (98.00%) (49346/50000)
# TEST : Loss: (0.4346) | Acc: (89.00%) (8924/10000)
percent tensor([0.5384, 0.5321, 0.5424, 0.5376, 0.5489, 0.5456, 0.5391, 0.5415, 0.5437,
        0.5334, 0.5418, 0.5385, 0.5307, 0.5406, 0.5379, 0.5366],
       device='cuda:0') torch.Size([16])
percent tensor([0.5142, 0.5085, 0.5115, 0.5124, 0.5101, 0.5151, 0.5102, 0.5140, 0.5168,
        0.5103, 0.5166, 0.5069, 0.5071, 0.5220, 0.5096, 0.5161],
       device='cuda:0') torch.Size([16])
percent tensor([0.5871, 0.5561, 0.6097, 0.6171, 0.6177, 0.6032, 0.5942, 0.6109, 0.5943,
        0.5712, 0.5707, 0.5949, 0.5332, 0.6359, 0.5747, 0.6050],
       device='cuda:0') torch.Size([16])
percent tensor([0.6606, 0.6829, 0.6705, 0.6615, 0.6531, 0.6649, 0.6732, 0.6494, 0.6912,
        0.6915, 0.7025, 0.6844, 0.6869, 0.6982, 0.6536, 0.6781],
       device='cuda:0') torch.Size([16])
percent tensor([0.6445, 0.7261, 0.5818, 0.6671, 0.5783, 0.6868, 0.6842, 0.4415, 0.7597,
        0.7039, 0.7820, 0.6799, 0.7223, 0.7565, 0.5996, 0.6483],
       device='cuda:0') torch.Size([16])
percent tensor([0.7149, 0.7205, 0.7324, 0.7220, 0.7649, 0.7246, 0.7371, 0.7331, 0.7231,
        0.7203, 0.6876, 0.6841, 0.6937, 0.7073, 0.6930, 0.7303],
       device='cuda:0') torch.Size([16])
percent tensor([0.5649, 0.6495, 0.7649, 0.6290, 0.7601, 0.7737, 0.6471, 0.6182, 0.6593,
        0.6248, 0.7223, 0.6065, 0.6465, 0.5353, 0.5640, 0.4872],
       device='cuda:0') torch.Size([16])
percent tensor([0.9998, 0.9998, 0.9999, 0.9999, 0.9997, 0.9999, 0.9999, 0.9998, 0.9999,
        0.9999, 1.0000, 0.9999, 0.9999, 0.9991, 0.9998, 0.9995],
       device='cuda:0') torch.Size([16])
Epoch: 237 | Batch_idx: 0 |  Loss: (0.0444) |  Loss2: (0.0000) | Acc: (98.00%) (126/128)
Epoch: 237 | Batch_idx: 10 |  Loss: (0.0347) |  Loss2: (0.0000) | Acc: (98.00%) (1393/1408)
Epoch: 237 | Batch_idx: 20 |  Loss: (0.0330) |  Loss2: (0.0000) | Acc: (98.00%) (2661/2688)
Epoch: 237 | Batch_idx: 30 |  Loss: (0.0343) |  Loss2: (0.0000) | Acc: (98.00%) (3924/3968)
Epoch: 237 | Batch_idx: 40 |  Loss: (0.0353) |  Loss2: (0.0000) | Acc: (98.00%) (5188/5248)
Epoch: 237 | Batch_idx: 50 |  Loss: (0.0336) |  Loss2: (0.0000) | Acc: (98.00%) (6462/6528)
Epoch: 237 | Batch_idx: 60 |  Loss: (0.0343) |  Loss2: (0.0000) | Acc: (98.00%) (7726/7808)
Epoch: 237 | Batch_idx: 70 |  Loss: (0.0340) |  Loss2: (0.0000) | Acc: (98.00%) (8994/9088)
Epoch: 237 | Batch_idx: 80 |  Loss: (0.0339) |  Loss2: (0.0000) | Acc: (98.00%) (10261/10368)
Epoch: 237 | Batch_idx: 90 |  Loss: (0.0341) |  Loss2: (0.0000) | Acc: (98.00%) (11527/11648)
Epoch: 237 | Batch_idx: 100 |  Loss: (0.0347) |  Loss2: (0.0000) | Acc: (98.00%) (12790/12928)
Epoch: 237 | Batch_idx: 110 |  Loss: (0.0355) |  Loss2: (0.0000) | Acc: (98.00%) (14052/14208)
Epoch: 237 | Batch_idx: 120 |  Loss: (0.0361) |  Loss2: (0.0000) | Acc: (98.00%) (15311/15488)
Epoch: 237 | Batch_idx: 130 |  Loss: (0.0365) |  Loss2: (0.0000) | Acc: (98.00%) (16571/16768)
Epoch: 237 | Batch_idx: 140 |  Loss: (0.0367) |  Loss2: (0.0000) | Acc: (98.00%) (17836/18048)
Epoch: 237 | Batch_idx: 150 |  Loss: (0.0364) |  Loss2: (0.0000) | Acc: (98.00%) (19105/19328)
Epoch: 237 | Batch_idx: 160 |  Loss: (0.0362) |  Loss2: (0.0000) | Acc: (98.00%) (20370/20608)
Epoch: 237 | Batch_idx: 170 |  Loss: (0.0367) |  Loss2: (0.0000) | Acc: (98.00%) (21628/21888)
Epoch: 237 | Batch_idx: 180 |  Loss: (0.0369) |  Loss2: (0.0000) | Acc: (98.00%) (22893/23168)
Epoch: 237 | Batch_idx: 190 |  Loss: (0.0366) |  Loss2: (0.0000) | Acc: (98.00%) (24161/24448)
Epoch: 237 | Batch_idx: 200 |  Loss: (0.0369) |  Loss2: (0.0000) | Acc: (98.00%) (25423/25728)
Epoch: 237 | Batch_idx: 210 |  Loss: (0.0371) |  Loss2: (0.0000) | Acc: (98.00%) (26684/27008)
Epoch: 237 | Batch_idx: 220 |  Loss: (0.0378) |  Loss2: (0.0000) | Acc: (98.00%) (27942/28288)
Epoch: 237 | Batch_idx: 230 |  Loss: (0.0379) |  Loss2: (0.0000) | Acc: (98.00%) (29206/29568)
Epoch: 237 | Batch_idx: 240 |  Loss: (0.0378) |  Loss2: (0.0000) | Acc: (98.00%) (30467/30848)
Epoch: 237 | Batch_idx: 250 |  Loss: (0.0388) |  Loss2: (0.0000) | Acc: (98.00%) (31719/32128)
Epoch: 237 | Batch_idx: 260 |  Loss: (0.0387) |  Loss2: (0.0000) | Acc: (98.00%) (32983/33408)
Epoch: 237 | Batch_idx: 270 |  Loss: (0.0390) |  Loss2: (0.0000) | Acc: (98.00%) (34243/34688)
Epoch: 237 | Batch_idx: 280 |  Loss: (0.0391) |  Loss2: (0.0000) | Acc: (98.00%) (35503/35968)
Epoch: 237 | Batch_idx: 290 |  Loss: (0.0395) |  Loss2: (0.0000) | Acc: (98.00%) (36758/37248)
Epoch: 237 | Batch_idx: 300 |  Loss: (0.0399) |  Loss2: (0.0000) | Acc: (98.00%) (38016/38528)
Epoch: 237 | Batch_idx: 310 |  Loss: (0.0402) |  Loss2: (0.0000) | Acc: (98.00%) (39276/39808)
Epoch: 237 | Batch_idx: 320 |  Loss: (0.0406) |  Loss2: (0.0000) | Acc: (98.00%) (40533/41088)
Epoch: 237 | Batch_idx: 330 |  Loss: (0.0407) |  Loss2: (0.0000) | Acc: (98.00%) (41797/42368)
Epoch: 237 | Batch_idx: 340 |  Loss: (0.0408) |  Loss2: (0.0000) | Acc: (98.00%) (43057/43648)
Epoch: 237 | Batch_idx: 350 |  Loss: (0.0409) |  Loss2: (0.0000) | Acc: (98.00%) (44318/44928)
Epoch: 237 | Batch_idx: 360 |  Loss: (0.0412) |  Loss2: (0.0000) | Acc: (98.00%) (45573/46208)
Epoch: 237 | Batch_idx: 370 |  Loss: (0.0413) |  Loss2: (0.0000) | Acc: (98.00%) (46836/47488)
Epoch: 237 | Batch_idx: 380 |  Loss: (0.0414) |  Loss2: (0.0000) | Acc: (98.00%) (48096/48768)
Epoch: 237 | Batch_idx: 390 |  Loss: (0.0413) |  Loss2: (0.0000) | Acc: (98.00%) (49315/50000)
# TEST : Loss: (0.4427) | Acc: (88.00%) (8856/10000)
percent tensor([0.5369, 0.5302, 0.5421, 0.5377, 0.5478, 0.5437, 0.5369, 0.5409, 0.5420,
        0.5319, 0.5399, 0.5374, 0.5293, 0.5381, 0.5365, 0.5352],
       device='cuda:0') torch.Size([16])
percent tensor([0.5137, 0.5077, 0.5128, 0.5136, 0.5118, 0.5156, 0.5103, 0.5144, 0.5162,
        0.5101, 0.5154, 0.5077, 0.5067, 0.5213, 0.5096, 0.5159],
       device='cuda:0') torch.Size([16])
percent tensor([0.5849, 0.5582, 0.6088, 0.6185, 0.6191, 0.6030, 0.5928, 0.6099, 0.5896,
        0.5708, 0.5685, 0.5956, 0.5319, 0.6362, 0.5744, 0.6046],
       device='cuda:0') torch.Size([16])
percent tensor([0.6618, 0.6871, 0.6647, 0.6647, 0.6523, 0.6700, 0.6726, 0.6479, 0.6915,
        0.6942, 0.7058, 0.6807, 0.6909, 0.6991, 0.6590, 0.6809],
       device='cuda:0') torch.Size([16])
percent tensor([0.6420, 0.7230, 0.5461, 0.6489, 0.5695, 0.6919, 0.6752, 0.4225, 0.7590,
        0.6940, 0.7831, 0.6401, 0.7107, 0.7554, 0.5924, 0.6588],
       device='cuda:0') torch.Size([16])
percent tensor([0.7157, 0.7218, 0.7379, 0.7251, 0.7676, 0.7284, 0.7401, 0.7357, 0.7196,
        0.7175, 0.6811, 0.6931, 0.6999, 0.7116, 0.6995, 0.7358],
       device='cuda:0') torch.Size([16])
percent tensor([0.5471, 0.6023, 0.7525, 0.6392, 0.7649, 0.7429, 0.6544, 0.6193, 0.6338,
        0.5950, 0.6772, 0.6141, 0.6188, 0.5273, 0.5719, 0.4801],
       device='cuda:0') torch.Size([16])
percent tensor([0.9998, 0.9998, 0.9999, 0.9999, 0.9997, 0.9998, 0.9997, 0.9997, 0.9998,
        0.9998, 1.0000, 0.9999, 0.9999, 0.9989, 0.9999, 0.9994],
       device='cuda:0') torch.Size([16])
Epoch: 238 | Batch_idx: 0 |  Loss: (0.0239) |  Loss2: (0.0000) | Acc: (99.00%) (127/128)
Epoch: 238 | Batch_idx: 10 |  Loss: (0.0274) |  Loss2: (0.0000) | Acc: (99.00%) (1397/1408)
Epoch: 238 | Batch_idx: 20 |  Loss: (0.0336) |  Loss2: (0.0000) | Acc: (98.00%) (2659/2688)
Epoch: 238 | Batch_idx: 30 |  Loss: (0.0312) |  Loss2: (0.0000) | Acc: (99.00%) (3930/3968)
Epoch: 238 | Batch_idx: 40 |  Loss: (0.0301) |  Loss2: (0.0000) | Acc: (99.00%) (5199/5248)
Epoch: 238 | Batch_idx: 50 |  Loss: (0.0319) |  Loss2: (0.0000) | Acc: (98.00%) (6461/6528)
Epoch: 238 | Batch_idx: 60 |  Loss: (0.0319) |  Loss2: (0.0000) | Acc: (99.00%) (7731/7808)
Epoch: 238 | Batch_idx: 70 |  Loss: (0.0329) |  Loss2: (0.0000) | Acc: (98.00%) (8993/9088)
Epoch: 238 | Batch_idx: 80 |  Loss: (0.0327) |  Loss2: (0.0000) | Acc: (98.00%) (10259/10368)
Epoch: 238 | Batch_idx: 90 |  Loss: (0.0332) |  Loss2: (0.0000) | Acc: (98.00%) (11525/11648)
Epoch: 238 | Batch_idx: 100 |  Loss: (0.0340) |  Loss2: (0.0000) | Acc: (98.00%) (12788/12928)
Epoch: 238 | Batch_idx: 110 |  Loss: (0.0351) |  Loss2: (0.0000) | Acc: (98.00%) (14049/14208)
Epoch: 238 | Batch_idx: 120 |  Loss: (0.0358) |  Loss2: (0.0000) | Acc: (98.00%) (15312/15488)
Epoch: 238 | Batch_idx: 130 |  Loss: (0.0357) |  Loss2: (0.0000) | Acc: (98.00%) (16584/16768)
Epoch: 238 | Batch_idx: 140 |  Loss: (0.0361) |  Loss2: (0.0000) | Acc: (98.00%) (17845/18048)
Epoch: 238 | Batch_idx: 150 |  Loss: (0.0364) |  Loss2: (0.0000) | Acc: (98.00%) (19112/19328)
Epoch: 238 | Batch_idx: 160 |  Loss: (0.0368) |  Loss2: (0.0000) | Acc: (98.00%) (20374/20608)
Epoch: 238 | Batch_idx: 170 |  Loss: (0.0369) |  Loss2: (0.0000) | Acc: (98.00%) (21639/21888)
Epoch: 238 | Batch_idx: 180 |  Loss: (0.0369) |  Loss2: (0.0000) | Acc: (98.00%) (22904/23168)
Epoch: 238 | Batch_idx: 190 |  Loss: (0.0366) |  Loss2: (0.0000) | Acc: (98.00%) (24171/24448)
Epoch: 238 | Batch_idx: 200 |  Loss: (0.0365) |  Loss2: (0.0000) | Acc: (98.00%) (25438/25728)
Epoch: 238 | Batch_idx: 210 |  Loss: (0.0363) |  Loss2: (0.0000) | Acc: (98.00%) (26708/27008)
Epoch: 238 | Batch_idx: 220 |  Loss: (0.0364) |  Loss2: (0.0000) | Acc: (98.00%) (27973/28288)
Epoch: 238 | Batch_idx: 230 |  Loss: (0.0365) |  Loss2: (0.0000) | Acc: (98.00%) (29238/29568)
Epoch: 238 | Batch_idx: 240 |  Loss: (0.0365) |  Loss2: (0.0000) | Acc: (98.00%) (30503/30848)
Epoch: 238 | Batch_idx: 250 |  Loss: (0.0364) |  Loss2: (0.0000) | Acc: (98.00%) (31770/32128)
Epoch: 238 | Batch_idx: 260 |  Loss: (0.0362) |  Loss2: (0.0000) | Acc: (98.00%) (33040/33408)
Epoch: 238 | Batch_idx: 270 |  Loss: (0.0361) |  Loss2: (0.0000) | Acc: (98.00%) (34308/34688)
Epoch: 238 | Batch_idx: 280 |  Loss: (0.0360) |  Loss2: (0.0000) | Acc: (98.00%) (35575/35968)
Epoch: 238 | Batch_idx: 290 |  Loss: (0.0359) |  Loss2: (0.0000) | Acc: (98.00%) (36842/37248)
Epoch: 238 | Batch_idx: 300 |  Loss: (0.0357) |  Loss2: (0.0000) | Acc: (98.00%) (38110/38528)
Epoch: 238 | Batch_idx: 310 |  Loss: (0.0358) |  Loss2: (0.0000) | Acc: (98.00%) (39372/39808)
Epoch: 238 | Batch_idx: 320 |  Loss: (0.0357) |  Loss2: (0.0000) | Acc: (98.00%) (40641/41088)
Epoch: 238 | Batch_idx: 330 |  Loss: (0.0356) |  Loss2: (0.0000) | Acc: (98.00%) (41908/42368)
Epoch: 238 | Batch_idx: 340 |  Loss: (0.0360) |  Loss2: (0.0000) | Acc: (98.00%) (43164/43648)
Epoch: 238 | Batch_idx: 350 |  Loss: (0.0361) |  Loss2: (0.0000) | Acc: (98.00%) (44422/44928)
Epoch: 238 | Batch_idx: 360 |  Loss: (0.0360) |  Loss2: (0.0000) | Acc: (98.00%) (45690/46208)
Epoch: 238 | Batch_idx: 370 |  Loss: (0.0364) |  Loss2: (0.0000) | Acc: (98.00%) (46946/47488)
Epoch: 238 | Batch_idx: 380 |  Loss: (0.0367) |  Loss2: (0.0000) | Acc: (98.00%) (48204/48768)
Epoch: 238 | Batch_idx: 390 |  Loss: (0.0367) |  Loss2: (0.0000) | Acc: (98.00%) (49424/50000)
# TEST : Loss: (0.4966) | Acc: (87.00%) (8782/10000)
percent tensor([0.5366, 0.5310, 0.5411, 0.5375, 0.5477, 0.5441, 0.5378, 0.5403, 0.5420,
        0.5323, 0.5398, 0.5367, 0.5291, 0.5391, 0.5370, 0.5354],
       device='cuda:0') torch.Size([16])
percent tensor([0.5150, 0.5089, 0.5153, 0.5152, 0.5134, 0.5165, 0.5109, 0.5159, 0.5172,
        0.5114, 0.5164, 0.5094, 0.5074, 0.5215, 0.5105, 0.5170],
       device='cuda:0') torch.Size([16])
percent tensor([0.5854, 0.5628, 0.6041, 0.6175, 0.6183, 0.6014, 0.5977, 0.6118, 0.5965,
        0.5736, 0.5757, 0.5932, 0.5338, 0.6481, 0.5766, 0.6059],
       device='cuda:0') torch.Size([16])
percent tensor([0.6652, 0.6883, 0.6648, 0.6640, 0.6539, 0.6750, 0.6770, 0.6491, 0.6927,
        0.6970, 0.7070, 0.6810, 0.6911, 0.7020, 0.6626, 0.6835],
       device='cuda:0') torch.Size([16])
percent tensor([0.6319, 0.7294, 0.5655, 0.6405, 0.5604, 0.6902, 0.6643, 0.4126, 0.7534,
        0.7048, 0.7750, 0.6345, 0.7096, 0.7642, 0.6007, 0.6561],
       device='cuda:0') torch.Size([16])
percent tensor([0.7222, 0.7317, 0.7398, 0.7226, 0.7672, 0.7343, 0.7404, 0.7370, 0.7332,
        0.7312, 0.6895, 0.6942, 0.7043, 0.7175, 0.7053, 0.7362],
       device='cuda:0') torch.Size([16])
percent tensor([0.5569, 0.6400, 0.7594, 0.6393, 0.7551, 0.7627, 0.6070, 0.6099, 0.6506,
        0.6211, 0.7114, 0.5668, 0.6649, 0.5421, 0.5853, 0.4695],
       device='cuda:0') torch.Size([16])
percent tensor([0.9998, 0.9998, 0.9999, 0.9998, 0.9998, 0.9998, 0.9999, 0.9997, 0.9999,
        0.9999, 1.0000, 0.9998, 0.9999, 0.9991, 0.9998, 0.9995],
       device='cuda:0') torch.Size([16])
Epoch: 239 | Batch_idx: 0 |  Loss: (0.0597) |  Loss2: (0.0000) | Acc: (97.00%) (125/128)
Epoch: 239 | Batch_idx: 10 |  Loss: (0.0327) |  Loss2: (0.0000) | Acc: (99.00%) (1394/1408)
Epoch: 239 | Batch_idx: 20 |  Loss: (0.0391) |  Loss2: (0.0000) | Acc: (98.00%) (2654/2688)
Epoch: 239 | Batch_idx: 30 |  Loss: (0.0346) |  Loss2: (0.0000) | Acc: (98.00%) (3922/3968)
Epoch: 239 | Batch_idx: 40 |  Loss: (0.0340) |  Loss2: (0.0000) | Acc: (98.00%) (5185/5248)
Epoch: 239 | Batch_idx: 50 |  Loss: (0.0337) |  Loss2: (0.0000) | Acc: (98.00%) (6457/6528)
Epoch: 239 | Batch_idx: 60 |  Loss: (0.0333) |  Loss2: (0.0000) | Acc: (98.00%) (7719/7808)
Epoch: 239 | Batch_idx: 70 |  Loss: (0.0353) |  Loss2: (0.0000) | Acc: (98.00%) (8977/9088)
Epoch: 239 | Batch_idx: 80 |  Loss: (0.0363) |  Loss2: (0.0000) | Acc: (98.00%) (10236/10368)
Epoch: 239 | Batch_idx: 90 |  Loss: (0.0353) |  Loss2: (0.0000) | Acc: (98.00%) (11507/11648)
Epoch: 239 | Batch_idx: 100 |  Loss: (0.0362) |  Loss2: (0.0000) | Acc: (98.00%) (12768/12928)
Epoch: 239 | Batch_idx: 110 |  Loss: (0.0377) |  Loss2: (0.0000) | Acc: (98.00%) (14023/14208)
Epoch: 239 | Batch_idx: 120 |  Loss: (0.0400) |  Loss2: (0.0000) | Acc: (98.00%) (15268/15488)
Epoch: 239 | Batch_idx: 130 |  Loss: (0.0398) |  Loss2: (0.0000) | Acc: (98.00%) (16537/16768)
Epoch: 239 | Batch_idx: 140 |  Loss: (0.0398) |  Loss2: (0.0000) | Acc: (98.00%) (17801/18048)
Epoch: 239 | Batch_idx: 150 |  Loss: (0.0398) |  Loss2: (0.0000) | Acc: (98.00%) (19064/19328)
Epoch: 239 | Batch_idx: 160 |  Loss: (0.0398) |  Loss2: (0.0000) | Acc: (98.00%) (20329/20608)
Epoch: 239 | Batch_idx: 170 |  Loss: (0.0398) |  Loss2: (0.0000) | Acc: (98.00%) (21594/21888)
Epoch: 239 | Batch_idx: 180 |  Loss: (0.0394) |  Loss2: (0.0000) | Acc: (98.00%) (22866/23168)
Epoch: 239 | Batch_idx: 190 |  Loss: (0.0393) |  Loss2: (0.0000) | Acc: (98.00%) (24128/24448)
Epoch: 239 | Batch_idx: 200 |  Loss: (0.0391) |  Loss2: (0.0000) | Acc: (98.00%) (25390/25728)
Epoch: 239 | Batch_idx: 210 |  Loss: (0.0389) |  Loss2: (0.0000) | Acc: (98.00%) (26657/27008)
Epoch: 239 | Batch_idx: 220 |  Loss: (0.0393) |  Loss2: (0.0000) | Acc: (98.00%) (27915/28288)
Epoch: 239 | Batch_idx: 230 |  Loss: (0.0398) |  Loss2: (0.0000) | Acc: (98.00%) (29173/29568)
Epoch: 239 | Batch_idx: 240 |  Loss: (0.0400) |  Loss2: (0.0000) | Acc: (98.00%) (30433/30848)
Epoch: 239 | Batch_idx: 250 |  Loss: (0.0402) |  Loss2: (0.0000) | Acc: (98.00%) (31693/32128)
Epoch: 239 | Batch_idx: 260 |  Loss: (0.0405) |  Loss2: (0.0000) | Acc: (98.00%) (32953/33408)
Epoch: 239 | Batch_idx: 270 |  Loss: (0.0404) |  Loss2: (0.0000) | Acc: (98.00%) (34223/34688)
Epoch: 239 | Batch_idx: 280 |  Loss: (0.0409) |  Loss2: (0.0000) | Acc: (98.00%) (35479/35968)
Epoch: 239 | Batch_idx: 290 |  Loss: (0.0408) |  Loss2: (0.0000) | Acc: (98.00%) (36747/37248)
Epoch: 239 | Batch_idx: 300 |  Loss: (0.0407) |  Loss2: (0.0000) | Acc: (98.00%) (38007/38528)
Epoch: 239 | Batch_idx: 310 |  Loss: (0.0405) |  Loss2: (0.0000) | Acc: (98.00%) (39274/39808)
Epoch: 239 | Batch_idx: 320 |  Loss: (0.0404) |  Loss2: (0.0000) | Acc: (98.00%) (40539/41088)
Epoch: 239 | Batch_idx: 330 |  Loss: (0.0402) |  Loss2: (0.0000) | Acc: (98.00%) (41804/42368)
Epoch: 239 | Batch_idx: 340 |  Loss: (0.0403) |  Loss2: (0.0000) | Acc: (98.00%) (43064/43648)
Epoch: 239 | Batch_idx: 350 |  Loss: (0.0404) |  Loss2: (0.0000) | Acc: (98.00%) (44326/44928)
Epoch: 239 | Batch_idx: 360 |  Loss: (0.0404) |  Loss2: (0.0000) | Acc: (98.00%) (45590/46208)
Epoch: 239 | Batch_idx: 370 |  Loss: (0.0403) |  Loss2: (0.0000) | Acc: (98.00%) (46858/47488)
Epoch: 239 | Batch_idx: 380 |  Loss: (0.0403) |  Loss2: (0.0000) | Acc: (98.00%) (48123/48768)
Epoch: 239 | Batch_idx: 390 |  Loss: (0.0405) |  Loss2: (0.0000) | Acc: (98.00%) (49340/50000)
# TEST : Loss: (0.4196) | Acc: (89.00%) (8937/10000)
percent tensor([0.5373, 0.5299, 0.5432, 0.5383, 0.5495, 0.5439, 0.5377, 0.5410, 0.5420,
        0.5330, 0.5398, 0.5400, 0.5296, 0.5367, 0.5365, 0.5353],
       device='cuda:0') torch.Size([16])
percent tensor([0.5146, 0.5088, 0.5121, 0.5135, 0.5114, 0.5146, 0.5113, 0.5155, 0.5166,
        0.5111, 0.5163, 0.5076, 0.5073, 0.5221, 0.5098, 0.5165],
       device='cuda:0') torch.Size([16])
percent tensor([0.5807, 0.5545, 0.5976, 0.6099, 0.6078, 0.5947, 0.5890, 0.6052, 0.5880,
        0.5644, 0.5704, 0.5846, 0.5287, 0.6394, 0.5690, 0.6024],
       device='cuda:0') torch.Size([16])
percent tensor([0.6616, 0.6854, 0.6644, 0.6647, 0.6525, 0.6666, 0.6749, 0.6495, 0.6925,
        0.6939, 0.7041, 0.6813, 0.6877, 0.7038, 0.6571, 0.6782],
       device='cuda:0') torch.Size([16])
percent tensor([0.6283, 0.7239, 0.5496, 0.6673, 0.5627, 0.6954, 0.6661, 0.4119, 0.7541,
        0.6952, 0.7727, 0.6483, 0.7091, 0.7507, 0.5945, 0.6573],
       device='cuda:0') torch.Size([16])
percent tensor([0.7121, 0.7277, 0.7212, 0.7177, 0.7565, 0.7319, 0.7358, 0.7240, 0.7193,
        0.7224, 0.6787, 0.6893, 0.6936, 0.7125, 0.6957, 0.7286],
       device='cuda:0') torch.Size([16])
percent tensor([0.5452, 0.6338, 0.7366, 0.6536, 0.7456, 0.7452, 0.6665, 0.6156, 0.6452,
        0.5951, 0.6766, 0.5952, 0.6702, 0.5505, 0.5898, 0.4595],
       device='cuda:0') torch.Size([16])
percent tensor([0.9998, 0.9997, 0.9999, 0.9998, 0.9997, 0.9998, 0.9999, 0.9997, 0.9999,
        0.9998, 1.0000, 0.9998, 0.9999, 0.9991, 0.9998, 0.9997],
       device='cuda:0') torch.Size([16])
Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 3, 3, 3]) tensor(194.2886, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(849.2162, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(839.6602, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([128, 64, 3, 3]) tensor(1520.8281, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([128, 64, 1, 1]) tensor(466.7635, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([128, 128, 3, 3]) tensor(2359.4226, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([256, 128, 3, 3]) tensor(4264.1572, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([256, 128, 1, 1]) tensor(1321.9188, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([256, 256, 3, 3]) tensor(6354.9585, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([512, 256, 3, 3]) tensor(11401.1777, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([512, 256, 1, 1]) tensor(3732.2864, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([512, 512, 3, 3]) tensor(15753.5693, device='cuda:0', grad_fn=<NormBackward0>)
6 hours 13 mins 24 secs for training