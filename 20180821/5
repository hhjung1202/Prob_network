Files already downloaded and verified
USE 1 GPUs!
Epoch: 0 | Batch_idx: 0 |  Loss: (2.3069) |  Loss2: (0.0000) | Acc: (7.00%) (9/128)
Epoch: 0 | Batch_idx: 10 |  Loss: (2.2958) |  Loss2: (0.0000) | Acc: (10.00%) (152/1408)
Epoch: 0 | Batch_idx: 20 |  Loss: (2.2895) |  Loss2: (0.0000) | Acc: (11.00%) (309/2688)
Epoch: 0 | Batch_idx: 30 |  Loss: (2.2812) |  Loss2: (0.0000) | Acc: (13.00%) (532/3968)
Epoch: 0 | Batch_idx: 40 |  Loss: (2.2720) |  Loss2: (0.0000) | Acc: (15.00%) (789/5248)
Epoch: 0 | Batch_idx: 50 |  Loss: (2.2614) |  Loss2: (0.0000) | Acc: (16.00%) (1051/6528)
Epoch: 0 | Batch_idx: 60 |  Loss: (2.2512) |  Loss2: (0.0000) | Acc: (16.00%) (1318/7808)
Epoch: 0 | Batch_idx: 70 |  Loss: (2.2411) |  Loss2: (0.0000) | Acc: (17.00%) (1585/9088)
Epoch: 0 | Batch_idx: 80 |  Loss: (2.2305) |  Loss2: (0.0000) | Acc: (17.00%) (1866/10368)
Epoch: 0 | Batch_idx: 90 |  Loss: (2.2226) |  Loss2: (0.0000) | Acc: (18.00%) (2113/11648)
Epoch: 0 | Batch_idx: 100 |  Loss: (2.2125) |  Loss2: (0.0000) | Acc: (18.00%) (2431/12928)
Epoch: 0 | Batch_idx: 110 |  Loss: (2.2023) |  Loss2: (0.0000) | Acc: (19.00%) (2731/14208)
Epoch: 0 | Batch_idx: 120 |  Loss: (2.1936) |  Loss2: (0.0000) | Acc: (19.00%) (3017/15488)
Epoch: 0 | Batch_idx: 130 |  Loss: (2.1841) |  Loss2: (0.0000) | Acc: (19.00%) (3330/16768)
Epoch: 0 | Batch_idx: 140 |  Loss: (2.1749) |  Loss2: (0.0000) | Acc: (20.00%) (3650/18048)
Epoch: 0 | Batch_idx: 150 |  Loss: (2.1678) |  Loss2: (0.0000) | Acc: (20.00%) (3946/19328)
Epoch: 0 | Batch_idx: 160 |  Loss: (2.1590) |  Loss2: (0.0000) | Acc: (20.00%) (4299/20608)
Epoch: 0 | Batch_idx: 170 |  Loss: (2.1523) |  Loss2: (0.0000) | Acc: (21.00%) (4614/21888)
Epoch: 0 | Batch_idx: 180 |  Loss: (2.1443) |  Loss2: (0.0000) | Acc: (21.00%) (4939/23168)
Epoch: 0 | Batch_idx: 190 |  Loss: (2.1376) |  Loss2: (0.0000) | Acc: (21.00%) (5274/24448)
Epoch: 0 | Batch_idx: 200 |  Loss: (2.1299) |  Loss2: (0.0000) | Acc: (21.00%) (5644/25728)
Epoch: 0 | Batch_idx: 210 |  Loss: (2.1225) |  Loss2: (0.0000) | Acc: (22.00%) (6003/27008)
Epoch: 0 | Batch_idx: 220 |  Loss: (2.1151) |  Loss2: (0.0000) | Acc: (22.00%) (6365/28288)
Epoch: 0 | Batch_idx: 230 |  Loss: (2.1089) |  Loss2: (0.0000) | Acc: (22.00%) (6711/29568)
Epoch: 0 | Batch_idx: 240 |  Loss: (2.1018) |  Loss2: (0.0000) | Acc: (22.00%) (7050/30848)
Epoch: 0 | Batch_idx: 250 |  Loss: (2.0952) |  Loss2: (0.0000) | Acc: (23.00%) (7397/32128)
Epoch: 0 | Batch_idx: 260 |  Loss: (2.0887) |  Loss2: (0.0000) | Acc: (23.00%) (7764/33408)
Epoch: 0 | Batch_idx: 270 |  Loss: (2.0821) |  Loss2: (0.0000) | Acc: (23.00%) (8136/34688)
Epoch: 0 | Batch_idx: 280 |  Loss: (2.0760) |  Loss2: (0.0000) | Acc: (23.00%) (8522/35968)
Epoch: 0 | Batch_idx: 290 |  Loss: (2.0693) |  Loss2: (0.0000) | Acc: (23.00%) (8913/37248)
Epoch: 0 | Batch_idx: 300 |  Loss: (2.0636) |  Loss2: (0.0000) | Acc: (24.00%) (9292/38528)
Epoch: 0 | Batch_idx: 310 |  Loss: (2.0578) |  Loss2: (0.0000) | Acc: (24.00%) (9687/39808)
Epoch: 0 | Batch_idx: 320 |  Loss: (2.0529) |  Loss2: (0.0000) | Acc: (24.00%) (10070/41088)
Epoch: 0 | Batch_idx: 330 |  Loss: (2.0472) |  Loss2: (0.0000) | Acc: (24.00%) (10475/42368)
Epoch: 0 | Batch_idx: 340 |  Loss: (2.0419) |  Loss2: (0.0000) | Acc: (24.00%) (10882/43648)
Epoch: 0 | Batch_idx: 350 |  Loss: (2.0366) |  Loss2: (0.0000) | Acc: (25.00%) (11277/44928)
Epoch: 0 | Batch_idx: 360 |  Loss: (2.0323) |  Loss2: (0.0000) | Acc: (25.00%) (11630/46208)
Epoch: 0 | Batch_idx: 370 |  Loss: (2.0268) |  Loss2: (0.0000) | Acc: (25.00%) (12054/47488)
Epoch: 0 | Batch_idx: 380 |  Loss: (2.0221) |  Loss2: (0.0000) | Acc: (25.00%) (12454/48768)
Epoch: 0 | Batch_idx: 390 |  Loss: (2.0171) |  Loss2: (0.0000) | Acc: (25.00%) (12862/50000)
/usr/local/lib/python3.6/dist-packages/torch/serialization.py:241: UserWarning: Couldn't retrieve source code for container of type ResNet. It won't be checked for correctness upon loading.
  "type " + obj.__name__ + ". It won't be checked "
/usr/local/lib/python3.6/dist-packages/torch/serialization.py:241: UserWarning: Couldn't retrieve source code for container of type BasicBlock. It won't be checked for correctness upon loading.
  "type " + obj.__name__ + ". It won't be checked "
/usr/local/lib/python3.6/dist-packages/torch/serialization.py:241: UserWarning: Couldn't retrieve source code for container of type _Gate. It won't be checked for correctness upon loading.
  "type " + obj.__name__ + ". It won't be checked "
=> saving checkpoint 'drive/app/torch/save_Routing_Gate_2/checkpoint_000.pth.tar'
# TEST : Loss: (1.8127) | Acc: (33.00%) (3346/10000)
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 3, 3, 3]) tensor(165.2569, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(767.8077, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(767.6323, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([128, 64, 3, 3]) tensor(1536.7427, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([128, 64, 1, 1]) tensor(511.4583, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([128, 128, 3, 3]) tensor(2174.6094, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([256, 128, 3, 3]) tensor(4343.5195, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([256, 128, 1, 1]) tensor(1446.2219, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([256, 256, 3, 3]) tensor(6132.0479, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([512, 256, 3, 3]) tensor(12282.8164, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([512, 256, 1, 1]) tensor(4097.6948, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([512, 512, 3, 3]) tensor(17361.8203, device='cuda:0', grad_fn=<NormBackward0>)
Epoch: 1 | Batch_idx: 0 |  Loss: (1.8328) |  Loss2: (0.0000) | Acc: (28.00%) (37/128)
Epoch: 1 | Batch_idx: 10 |  Loss: (1.8218) |  Loss2: (0.0000) | Acc: (34.00%) (482/1408)
Epoch: 1 | Batch_idx: 20 |  Loss: (1.8219) |  Loss2: (0.0000) | Acc: (33.00%) (888/2688)
Epoch: 1 | Batch_idx: 30 |  Loss: (1.8191) |  Loss2: (0.0000) | Acc: (32.00%) (1304/3968)
Epoch: 1 | Batch_idx: 40 |  Loss: (1.8170) |  Loss2: (0.0000) | Acc: (32.00%) (1714/5248)
Epoch: 1 | Batch_idx: 50 |  Loss: (1.8100) |  Loss2: (0.0000) | Acc: (32.00%) (2134/6528)
Epoch: 1 | Batch_idx: 60 |  Loss: (1.8067) |  Loss2: (0.0000) | Acc: (33.00%) (2607/7808)
Epoch: 1 | Batch_idx: 70 |  Loss: (1.8020) |  Loss2: (0.0000) | Acc: (33.00%) (3053/9088)
Epoch: 1 | Batch_idx: 80 |  Loss: (1.7992) |  Loss2: (0.0000) | Acc: (33.00%) (3484/10368)
Epoch: 1 | Batch_idx: 90 |  Loss: (1.7971) |  Loss2: (0.0000) | Acc: (33.00%) (3923/11648)
Epoch: 1 | Batch_idx: 100 |  Loss: (1.7965) |  Loss2: (0.0000) | Acc: (33.00%) (4382/12928)
Epoch: 1 | Batch_idx: 110 |  Loss: (1.7926) |  Loss2: (0.0000) | Acc: (34.00%) (4857/14208)
Epoch: 1 | Batch_idx: 120 |  Loss: (1.7876) |  Loss2: (0.0000) | Acc: (34.00%) (5340/15488)
Epoch: 1 | Batch_idx: 130 |  Loss: (1.7844) |  Loss2: (0.0000) | Acc: (34.00%) (5811/16768)
Epoch: 1 | Batch_idx: 140 |  Loss: (1.7823) |  Loss2: (0.0000) | Acc: (34.00%) (6277/18048)
Epoch: 1 | Batch_idx: 150 |  Loss: (1.7810) |  Loss2: (0.0000) | Acc: (34.00%) (6706/19328)
Epoch: 1 | Batch_idx: 160 |  Loss: (1.7782) |  Loss2: (0.0000) | Acc: (34.00%) (7140/20608)
Epoch: 1 | Batch_idx: 170 |  Loss: (1.7751) |  Loss2: (0.0000) | Acc: (34.00%) (7616/21888)
Epoch: 1 | Batch_idx: 180 |  Loss: (1.7729) |  Loss2: (0.0000) | Acc: (34.00%) (8075/23168)
Epoch: 1 | Batch_idx: 190 |  Loss: (1.7687) |  Loss2: (0.0000) | Acc: (34.00%) (8553/24448)
Epoch: 1 | Batch_idx: 200 |  Loss: (1.7651) |  Loss2: (0.0000) | Acc: (35.00%) (9006/25728)
Epoch: 1 | Batch_idx: 210 |  Loss: (1.7616) |  Loss2: (0.0000) | Acc: (35.00%) (9470/27008)
Epoch: 1 | Batch_idx: 220 |  Loss: (1.7595) |  Loss2: (0.0000) | Acc: (35.00%) (9930/28288)
Epoch: 1 | Batch_idx: 230 |  Loss: (1.7566) |  Loss2: (0.0000) | Acc: (35.00%) (10393/29568)
Epoch: 1 | Batch_idx: 240 |  Loss: (1.7539) |  Loss2: (0.0000) | Acc: (35.00%) (10860/30848)
Epoch: 1 | Batch_idx: 250 |  Loss: (1.7509) |  Loss2: (0.0000) | Acc: (35.00%) (11347/32128)
Epoch: 1 | Batch_idx: 260 |  Loss: (1.7472) |  Loss2: (0.0000) | Acc: (35.00%) (11845/33408)
Epoch: 1 | Batch_idx: 270 |  Loss: (1.7454) |  Loss2: (0.0000) | Acc: (35.00%) (12317/34688)
Epoch: 1 | Batch_idx: 280 |  Loss: (1.7419) |  Loss2: (0.0000) | Acc: (35.00%) (12852/35968)
Epoch: 1 | Batch_idx: 290 |  Loss: (1.7405) |  Loss2: (0.0000) | Acc: (35.00%) (13302/37248)
Epoch: 1 | Batch_idx: 300 |  Loss: (1.7382) |  Loss2: (0.0000) | Acc: (35.00%) (13783/38528)
Epoch: 1 | Batch_idx: 310 |  Loss: (1.7373) |  Loss2: (0.0000) | Acc: (35.00%) (14219/39808)
Epoch: 1 | Batch_idx: 320 |  Loss: (1.7345) |  Loss2: (0.0000) | Acc: (35.00%) (14719/41088)
Epoch: 1 | Batch_idx: 330 |  Loss: (1.7319) |  Loss2: (0.0000) | Acc: (35.00%) (15225/42368)
Epoch: 1 | Batch_idx: 340 |  Loss: (1.7297) |  Loss2: (0.0000) | Acc: (35.00%) (15709/43648)
Epoch: 1 | Batch_idx: 350 |  Loss: (1.7274) |  Loss2: (0.0000) | Acc: (36.00%) (16207/44928)
Epoch: 1 | Batch_idx: 360 |  Loss: (1.7251) |  Loss2: (0.0000) | Acc: (36.00%) (16708/46208)
Epoch: 1 | Batch_idx: 370 |  Loss: (1.7223) |  Loss2: (0.0000) | Acc: (36.00%) (17234/47488)
Epoch: 1 | Batch_idx: 380 |  Loss: (1.7192) |  Loss2: (0.0000) | Acc: (36.00%) (17769/48768)
Epoch: 1 | Batch_idx: 390 |  Loss: (1.7166) |  Loss2: (0.0000) | Acc: (36.00%) (18260/50000)
# TEST : Loss: (1.6386) | Acc: (38.00%) (3835/10000)
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
Epoch: 2 | Batch_idx: 0 |  Loss: (1.6897) |  Loss2: (0.0000) | Acc: (40.00%) (52/128)
Epoch: 2 | Batch_idx: 10 |  Loss: (1.6188) |  Loss2: (0.0000) | Acc: (41.00%) (581/1408)
Epoch: 2 | Batch_idx: 20 |  Loss: (1.6231) |  Loss2: (0.0000) | Acc: (40.00%) (1089/2688)
Epoch: 2 | Batch_idx: 30 |  Loss: (1.6224) |  Loss2: (0.0000) | Acc: (40.00%) (1609/3968)
Epoch: 2 | Batch_idx: 40 |  Loss: (1.6223) |  Loss2: (0.0000) | Acc: (40.00%) (2122/5248)
Epoch: 2 | Batch_idx: 50 |  Loss: (1.6191) |  Loss2: (0.0000) | Acc: (40.00%) (2650/6528)
Epoch: 2 | Batch_idx: 60 |  Loss: (1.6157) |  Loss2: (0.0000) | Acc: (40.00%) (3183/7808)
Epoch: 2 | Batch_idx: 70 |  Loss: (1.6160) |  Loss2: (0.0000) | Acc: (40.00%) (3691/9088)
Epoch: 2 | Batch_idx: 80 |  Loss: (1.6159) |  Loss2: (0.0000) | Acc: (40.00%) (4204/10368)
Epoch: 2 | Batch_idx: 90 |  Loss: (1.6141) |  Loss2: (0.0000) | Acc: (40.00%) (4745/11648)
Epoch: 2 | Batch_idx: 100 |  Loss: (1.6106) |  Loss2: (0.0000) | Acc: (40.00%) (5264/12928)
Epoch: 2 | Batch_idx: 110 |  Loss: (1.6037) |  Loss2: (0.0000) | Acc: (40.00%) (5822/14208)
Epoch: 2 | Batch_idx: 120 |  Loss: (1.5987) |  Loss2: (0.0000) | Acc: (41.00%) (6351/15488)
Epoch: 2 | Batch_idx: 130 |  Loss: (1.5959) |  Loss2: (0.0000) | Acc: (40.00%) (6870/16768)
Epoch: 2 | Batch_idx: 140 |  Loss: (1.5903) |  Loss2: (0.0000) | Acc: (41.00%) (7421/18048)
Epoch: 2 | Batch_idx: 150 |  Loss: (1.5868) |  Loss2: (0.0000) | Acc: (41.00%) (7967/19328)
Epoch: 2 | Batch_idx: 160 |  Loss: (1.5843) |  Loss2: (0.0000) | Acc: (41.00%) (8519/20608)
Epoch: 2 | Batch_idx: 170 |  Loss: (1.5810) |  Loss2: (0.0000) | Acc: (41.00%) (9069/21888)
Epoch: 2 | Batch_idx: 180 |  Loss: (1.5795) |  Loss2: (0.0000) | Acc: (41.00%) (9631/23168)
Epoch: 2 | Batch_idx: 190 |  Loss: (1.5780) |  Loss2: (0.0000) | Acc: (41.00%) (10165/24448)
Epoch: 2 | Batch_idx: 200 |  Loss: (1.5766) |  Loss2: (0.0000) | Acc: (41.00%) (10719/25728)
Epoch: 2 | Batch_idx: 210 |  Loss: (1.5737) |  Loss2: (0.0000) | Acc: (41.00%) (11304/27008)
Epoch: 2 | Batch_idx: 220 |  Loss: (1.5721) |  Loss2: (0.0000) | Acc: (41.00%) (11832/28288)
Epoch: 2 | Batch_idx: 230 |  Loss: (1.5692) |  Loss2: (0.0000) | Acc: (41.00%) (12402/29568)
Epoch: 2 | Batch_idx: 240 |  Loss: (1.5670) |  Loss2: (0.0000) | Acc: (41.00%) (12943/30848)
Epoch: 2 | Batch_idx: 250 |  Loss: (1.5666) |  Loss2: (0.0000) | Acc: (42.00%) (13506/32128)
Epoch: 2 | Batch_idx: 260 |  Loss: (1.5646) |  Loss2: (0.0000) | Acc: (42.00%) (14080/33408)
Epoch: 2 | Batch_idx: 270 |  Loss: (1.5619) |  Loss2: (0.0000) | Acc: (42.00%) (14641/34688)
Epoch: 2 | Batch_idx: 280 |  Loss: (1.5592) |  Loss2: (0.0000) | Acc: (42.00%) (15228/35968)
Epoch: 2 | Batch_idx: 290 |  Loss: (1.5568) |  Loss2: (0.0000) | Acc: (42.00%) (15796/37248)
Epoch: 2 | Batch_idx: 300 |  Loss: (1.5551) |  Loss2: (0.0000) | Acc: (42.00%) (16380/38528)
Epoch: 2 | Batch_idx: 310 |  Loss: (1.5547) |  Loss2: (0.0000) | Acc: (42.00%) (16924/39808)
Epoch: 2 | Batch_idx: 320 |  Loss: (1.5526) |  Loss2: (0.0000) | Acc: (42.00%) (17504/41088)
Epoch: 2 | Batch_idx: 330 |  Loss: (1.5501) |  Loss2: (0.0000) | Acc: (42.00%) (18100/42368)
Epoch: 2 | Batch_idx: 340 |  Loss: (1.5476) |  Loss2: (0.0000) | Acc: (42.00%) (18689/43648)
Epoch: 2 | Batch_idx: 350 |  Loss: (1.5466) |  Loss2: (0.0000) | Acc: (42.00%) (19234/44928)
Epoch: 2 | Batch_idx: 360 |  Loss: (1.5442) |  Loss2: (0.0000) | Acc: (42.00%) (19837/46208)
Epoch: 2 | Batch_idx: 370 |  Loss: (1.5410) |  Loss2: (0.0000) | Acc: (43.00%) (20457/47488)
Epoch: 2 | Batch_idx: 380 |  Loss: (1.5387) |  Loss2: (0.0000) | Acc: (43.00%) (21061/48768)
Epoch: 2 | Batch_idx: 390 |  Loss: (1.5368) |  Loss2: (0.0000) | Acc: (43.00%) (21639/50000)
# TEST : Loss: (1.4323) | Acc: (47.00%) (4701/10000)
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
Epoch: 3 | Batch_idx: 0 |  Loss: (1.3696) |  Loss2: (0.0000) | Acc: (52.00%) (67/128)
Epoch: 3 | Batch_idx: 10 |  Loss: (1.4428) |  Loss2: (0.0000) | Acc: (46.00%) (657/1408)
Epoch: 3 | Batch_idx: 20 |  Loss: (1.4362) |  Loss2: (0.0000) | Acc: (46.00%) (1254/2688)
Epoch: 3 | Batch_idx: 30 |  Loss: (1.4206) |  Loss2: (0.0000) | Acc: (47.00%) (1896/3968)
Epoch: 3 | Batch_idx: 40 |  Loss: (1.4233) |  Loss2: (0.0000) | Acc: (47.00%) (2508/5248)
Epoch: 3 | Batch_idx: 50 |  Loss: (1.4312) |  Loss2: (0.0000) | Acc: (47.00%) (3123/6528)
Epoch: 3 | Batch_idx: 60 |  Loss: (1.4288) |  Loss2: (0.0000) | Acc: (47.00%) (3718/7808)
Epoch: 3 | Batch_idx: 70 |  Loss: (1.4264) |  Loss2: (0.0000) | Acc: (47.00%) (4334/9088)
Epoch: 3 | Batch_idx: 80 |  Loss: (1.4244) |  Loss2: (0.0000) | Acc: (47.00%) (4939/10368)
Epoch: 3 | Batch_idx: 90 |  Loss: (1.4208) |  Loss2: (0.0000) | Acc: (47.00%) (5569/11648)
Epoch: 3 | Batch_idx: 100 |  Loss: (1.4232) |  Loss2: (0.0000) | Acc: (47.00%) (6160/12928)
Epoch: 3 | Batch_idx: 110 |  Loss: (1.4237) |  Loss2: (0.0000) | Acc: (47.00%) (6781/14208)
Epoch: 3 | Batch_idx: 120 |  Loss: (1.4240) |  Loss2: (0.0000) | Acc: (47.00%) (7408/15488)
Epoch: 3 | Batch_idx: 130 |  Loss: (1.4191) |  Loss2: (0.0000) | Acc: (48.00%) (8063/16768)
Epoch: 3 | Batch_idx: 140 |  Loss: (1.4197) |  Loss2: (0.0000) | Acc: (48.00%) (8680/18048)
Epoch: 3 | Batch_idx: 150 |  Loss: (1.4198) |  Loss2: (0.0000) | Acc: (48.00%) (9313/19328)
Epoch: 3 | Batch_idx: 160 |  Loss: (1.4166) |  Loss2: (0.0000) | Acc: (48.00%) (9958/20608)
Epoch: 3 | Batch_idx: 170 |  Loss: (1.4144) |  Loss2: (0.0000) | Acc: (48.00%) (10601/21888)
Epoch: 3 | Batch_idx: 180 |  Loss: (1.4118) |  Loss2: (0.0000) | Acc: (48.00%) (11270/23168)
Epoch: 3 | Batch_idx: 190 |  Loss: (1.4117) |  Loss2: (0.0000) | Acc: (48.00%) (11904/24448)
Epoch: 3 | Batch_idx: 200 |  Loss: (1.4119) |  Loss2: (0.0000) | Acc: (48.00%) (12511/25728)
Epoch: 3 | Batch_idx: 210 |  Loss: (1.4105) |  Loss2: (0.0000) | Acc: (48.00%) (13146/27008)
Epoch: 3 | Batch_idx: 220 |  Loss: (1.4081) |  Loss2: (0.0000) | Acc: (48.00%) (13796/28288)
Epoch: 3 | Batch_idx: 230 |  Loss: (1.4058) |  Loss2: (0.0000) | Acc: (48.00%) (14459/29568)
Epoch: 3 | Batch_idx: 240 |  Loss: (1.4060) |  Loss2: (0.0000) | Acc: (48.00%) (15087/30848)
Epoch: 3 | Batch_idx: 250 |  Loss: (1.4041) |  Loss2: (0.0000) | Acc: (48.00%) (15738/32128)
Epoch: 3 | Batch_idx: 260 |  Loss: (1.4031) |  Loss2: (0.0000) | Acc: (49.00%) (16377/33408)
Epoch: 3 | Batch_idx: 270 |  Loss: (1.4024) |  Loss2: (0.0000) | Acc: (49.00%) (17015/34688)
Epoch: 3 | Batch_idx: 280 |  Loss: (1.4001) |  Loss2: (0.0000) | Acc: (49.00%) (17675/35968)
Epoch: 3 | Batch_idx: 290 |  Loss: (1.4002) |  Loss2: (0.0000) | Acc: (49.00%) (18295/37248)
Epoch: 3 | Batch_idx: 300 |  Loss: (1.3985) |  Loss2: (0.0000) | Acc: (49.00%) (18944/38528)
Epoch: 3 | Batch_idx: 310 |  Loss: (1.3968) |  Loss2: (0.0000) | Acc: (49.00%) (19615/39808)
Epoch: 3 | Batch_idx: 320 |  Loss: (1.3953) |  Loss2: (0.0000) | Acc: (49.00%) (20269/41088)
Epoch: 3 | Batch_idx: 330 |  Loss: (1.3960) |  Loss2: (0.0000) | Acc: (49.00%) (20902/42368)
Epoch: 3 | Batch_idx: 340 |  Loss: (1.3926) |  Loss2: (0.0000) | Acc: (49.00%) (21593/43648)
Epoch: 3 | Batch_idx: 350 |  Loss: (1.3906) |  Loss2: (0.0000) | Acc: (49.00%) (22264/44928)
Epoch: 3 | Batch_idx: 360 |  Loss: (1.3887) |  Loss2: (0.0000) | Acc: (49.00%) (22940/46208)
Epoch: 3 | Batch_idx: 370 |  Loss: (1.3868) |  Loss2: (0.0000) | Acc: (49.00%) (23598/47488)
Epoch: 3 | Batch_idx: 380 |  Loss: (1.3858) |  Loss2: (0.0000) | Acc: (49.00%) (24255/48768)
Epoch: 3 | Batch_idx: 390 |  Loss: (1.3834) |  Loss2: (0.0000) | Acc: (49.00%) (24920/50000)
# TEST : Loss: (1.2884) | Acc: (52.00%) (5216/10000)
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
Epoch: 4 | Batch_idx: 0 |  Loss: (1.4718) |  Loss2: (0.0000) | Acc: (46.00%) (59/128)
Epoch: 4 | Batch_idx: 10 |  Loss: (1.3121) |  Loss2: (0.0000) | Acc: (55.00%) (776/1408)
Epoch: 4 | Batch_idx: 20 |  Loss: (1.3126) |  Loss2: (0.0000) | Acc: (53.00%) (1432/2688)
Epoch: 4 | Batch_idx: 30 |  Loss: (1.3099) |  Loss2: (0.0000) | Acc: (53.00%) (2128/3968)
Epoch: 4 | Batch_idx: 40 |  Loss: (1.3043) |  Loss2: (0.0000) | Acc: (54.00%) (2838/5248)
Epoch: 4 | Batch_idx: 50 |  Loss: (1.2983) |  Loss2: (0.0000) | Acc: (54.00%) (3532/6528)
Epoch: 4 | Batch_idx: 60 |  Loss: (1.3023) |  Loss2: (0.0000) | Acc: (53.00%) (4194/7808)
Epoch: 4 | Batch_idx: 70 |  Loss: (1.3009) |  Loss2: (0.0000) | Acc: (53.00%) (4871/9088)
Epoch: 4 | Batch_idx: 80 |  Loss: (1.3008) |  Loss2: (0.0000) | Acc: (53.00%) (5549/10368)
Epoch: 4 | Batch_idx: 90 |  Loss: (1.2999) |  Loss2: (0.0000) | Acc: (53.00%) (6234/11648)
Epoch: 4 | Batch_idx: 100 |  Loss: (1.2960) |  Loss2: (0.0000) | Acc: (53.00%) (6937/12928)
Epoch: 4 | Batch_idx: 110 |  Loss: (1.2940) |  Loss2: (0.0000) | Acc: (53.00%) (7640/14208)
Epoch: 4 | Batch_idx: 120 |  Loss: (1.2919) |  Loss2: (0.0000) | Acc: (53.00%) (8321/15488)
Epoch: 4 | Batch_idx: 130 |  Loss: (1.2900) |  Loss2: (0.0000) | Acc: (53.00%) (9017/16768)
Epoch: 4 | Batch_idx: 140 |  Loss: (1.2870) |  Loss2: (0.0000) | Acc: (53.00%) (9721/18048)
Epoch: 4 | Batch_idx: 150 |  Loss: (1.2875) |  Loss2: (0.0000) | Acc: (53.00%) (10406/19328)
Epoch: 4 | Batch_idx: 160 |  Loss: (1.2836) |  Loss2: (0.0000) | Acc: (54.00%) (11154/20608)
Epoch: 4 | Batch_idx: 170 |  Loss: (1.2843) |  Loss2: (0.0000) | Acc: (54.00%) (11850/21888)
Epoch: 4 | Batch_idx: 180 |  Loss: (1.2835) |  Loss2: (0.0000) | Acc: (54.00%) (12542/23168)
Epoch: 4 | Batch_idx: 190 |  Loss: (1.2798) |  Loss2: (0.0000) | Acc: (54.00%) (13287/24448)
Epoch: 4 | Batch_idx: 200 |  Loss: (1.2777) |  Loss2: (0.0000) | Acc: (54.00%) (14027/25728)
Epoch: 4 | Batch_idx: 210 |  Loss: (1.2737) |  Loss2: (0.0000) | Acc: (54.00%) (14765/27008)
Epoch: 4 | Batch_idx: 220 |  Loss: (1.2722) |  Loss2: (0.0000) | Acc: (54.00%) (15460/28288)
Epoch: 4 | Batch_idx: 230 |  Loss: (1.2699) |  Loss2: (0.0000) | Acc: (54.00%) (16199/29568)
Epoch: 4 | Batch_idx: 240 |  Loss: (1.2700) |  Loss2: (0.0000) | Acc: (54.00%) (16916/30848)
Epoch: 4 | Batch_idx: 250 |  Loss: (1.2669) |  Loss2: (0.0000) | Acc: (54.00%) (17664/32128)
Epoch: 4 | Batch_idx: 260 |  Loss: (1.2638) |  Loss2: (0.0000) | Acc: (55.00%) (18395/33408)
Epoch: 4 | Batch_idx: 270 |  Loss: (1.2624) |  Loss2: (0.0000) | Acc: (55.00%) (19106/34688)
Epoch: 4 | Batch_idx: 280 |  Loss: (1.2609) |  Loss2: (0.0000) | Acc: (55.00%) (19850/35968)
Epoch: 4 | Batch_idx: 290 |  Loss: (1.2604) |  Loss2: (0.0000) | Acc: (55.00%) (20556/37248)
Epoch: 4 | Batch_idx: 300 |  Loss: (1.2594) |  Loss2: (0.0000) | Acc: (55.00%) (21285/38528)
Epoch: 4 | Batch_idx: 310 |  Loss: (1.2573) |  Loss2: (0.0000) | Acc: (55.00%) (22023/39808)
Epoch: 4 | Batch_idx: 320 |  Loss: (1.2555) |  Loss2: (0.0000) | Acc: (55.00%) (22771/41088)
Epoch: 4 | Batch_idx: 330 |  Loss: (1.2544) |  Loss2: (0.0000) | Acc: (55.00%) (23503/42368)
Epoch: 4 | Batch_idx: 340 |  Loss: (1.2520) |  Loss2: (0.0000) | Acc: (55.00%) (24235/43648)
Epoch: 4 | Batch_idx: 350 |  Loss: (1.2503) |  Loss2: (0.0000) | Acc: (55.00%) (24983/44928)
Epoch: 4 | Batch_idx: 360 |  Loss: (1.2489) |  Loss2: (0.0000) | Acc: (55.00%) (25705/46208)
Epoch: 4 | Batch_idx: 370 |  Loss: (1.2479) |  Loss2: (0.0000) | Acc: (55.00%) (26437/47488)
Epoch: 4 | Batch_idx: 380 |  Loss: (1.2472) |  Loss2: (0.0000) | Acc: (55.00%) (27139/48768)
Epoch: 4 | Batch_idx: 390 |  Loss: (1.2461) |  Loss2: (0.0000) | Acc: (55.00%) (27836/50000)
# TEST : Loss: (1.2107) | Acc: (56.00%) (5654/10000)
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
False Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=128, out_features=16, bias=False)
True Linear(in_features=16, out_features=2, bias=False)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=128, out_features=16, bias=False)
True Linear(in_features=16, out_features=2, bias=False)
False Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=256, out_features=32, bias=False)
True Linear(in_features=32, out_features=2, bias=False)
False Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=256, out_features=32, bias=False)
True Linear(in_features=32, out_features=2, bias=False)
False Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=512, out_features=64, bias=False)
True Linear(in_features=64, out_features=2, bias=False)
False Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=512, out_features=64, bias=False)
True Linear(in_features=64, out_features=2, bias=False)
False Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1024, out_features=128, bias=False)
True Linear(in_features=128, out_features=2, bias=False)
False Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1024, out_features=128, bias=False)
True Linear(in_features=128, out_features=2, bias=False)
False Linear(in_features=512, out_features=10, bias=True)
Epoch: 5 | Batch_idx: 0 |  Loss: (1.2129) |  Loss2: (0.0000) | Acc: (55.00%) (71/128)
Epoch: 5 | Batch_idx: 10 |  Loss: (1.2047) |  Loss2: (0.0000) | Acc: (57.00%) (803/1408)
Epoch: 5 | Batch_idx: 20 |  Loss: (1.2339) |  Loss2: (0.0000) | Acc: (56.00%) (1510/2688)
Epoch: 5 | Batch_idx: 30 |  Loss: (1.2518) |  Loss2: (0.0000) | Acc: (55.00%) (2184/3968)
Epoch: 5 | Batch_idx: 40 |  Loss: (1.2493) |  Loss2: (0.0000) | Acc: (54.00%) (2880/5248)
Epoch: 5 | Batch_idx: 50 |  Loss: (1.2504) |  Loss2: (0.0000) | Acc: (54.00%) (3583/6528)
Epoch: 5 | Batch_idx: 60 |  Loss: (1.2634) |  Loss2: (0.0000) | Acc: (54.00%) (4238/7808)
Epoch: 5 | Batch_idx: 70 |  Loss: (1.2689) |  Loss2: (0.0000) | Acc: (54.00%) (4922/9088)
Epoch: 5 | Batch_idx: 80 |  Loss: (1.2737) |  Loss2: (0.0000) | Acc: (53.00%) (5595/10368)
Epoch: 5 | Batch_idx: 90 |  Loss: (1.2674) |  Loss2: (0.0000) | Acc: (54.00%) (6306/11648)
Epoch: 5 | Batch_idx: 100 |  Loss: (1.2725) |  Loss2: (0.0000) | Acc: (53.00%) (6981/12928)
Epoch: 5 | Batch_idx: 110 |  Loss: (1.2669) |  Loss2: (0.0000) | Acc: (54.00%) (7707/14208)
Epoch: 5 | Batch_idx: 120 |  Loss: (1.2677) |  Loss2: (0.0000) | Acc: (54.00%) (8394/15488)
Epoch: 5 | Batch_idx: 130 |  Loss: (1.2656) |  Loss2: (0.0000) | Acc: (54.00%) (9108/16768)
Epoch: 5 | Batch_idx: 140 |  Loss: (1.2661) |  Loss2: (0.0000) | Acc: (54.00%) (9799/18048)
Epoch: 5 | Batch_idx: 150 |  Loss: (1.2645) |  Loss2: (0.0000) | Acc: (54.00%) (10519/19328)
Epoch: 5 | Batch_idx: 160 |  Loss: (1.2658) |  Loss2: (0.0000) | Acc: (54.00%) (11202/20608)
Epoch: 5 | Batch_idx: 170 |  Loss: (1.2640) |  Loss2: (0.0000) | Acc: (54.00%) (11896/21888)
Epoch: 5 | Batch_idx: 180 |  Loss: (1.2645) |  Loss2: (0.0000) | Acc: (54.00%) (12588/23168)
Epoch: 5 | Batch_idx: 190 |  Loss: (1.2624) |  Loss2: (0.0000) | Acc: (54.00%) (13308/24448)
Epoch: 5 | Batch_idx: 200 |  Loss: (1.2618) |  Loss2: (0.0000) | Acc: (54.00%) (14010/25728)
Epoch: 5 | Batch_idx: 210 |  Loss: (1.2623) |  Loss2: (0.0000) | Acc: (54.00%) (14711/27008)
Epoch: 5 | Batch_idx: 220 |  Loss: (1.2613) |  Loss2: (0.0000) | Acc: (54.00%) (15419/28288)
Epoch: 5 | Batch_idx: 230 |  Loss: (1.2592) |  Loss2: (0.0000) | Acc: (54.00%) (16161/29568)
Epoch: 5 | Batch_idx: 240 |  Loss: (1.2570) |  Loss2: (0.0000) | Acc: (54.00%) (16896/30848)
Epoch: 5 | Batch_idx: 250 |  Loss: (1.2536) |  Loss2: (0.0000) | Acc: (54.00%) (17624/32128)
Epoch: 5 | Batch_idx: 260 |  Loss: (1.2506) |  Loss2: (0.0000) | Acc: (54.00%) (18352/33408)
Epoch: 5 | Batch_idx: 270 |  Loss: (1.2493) |  Loss2: (0.0000) | Acc: (54.00%) (19050/34688)
Epoch: 5 | Batch_idx: 280 |  Loss: (1.2489) |  Loss2: (0.0000) | Acc: (54.00%) (19752/35968)
Epoch: 5 | Batch_idx: 290 |  Loss: (1.2477) |  Loss2: (0.0000) | Acc: (54.00%) (20485/37248)
Epoch: 5 | Batch_idx: 300 |  Loss: (1.2472) |  Loss2: (0.0000) | Acc: (54.00%) (21170/38528)
Epoch: 5 | Batch_idx: 310 |  Loss: (1.2483) |  Loss2: (0.0000) | Acc: (54.00%) (21847/39808)
Epoch: 5 | Batch_idx: 320 |  Loss: (1.2467) |  Loss2: (0.0000) | Acc: (54.00%) (22558/41088)
Epoch: 5 | Batch_idx: 330 |  Loss: (1.2461) |  Loss2: (0.0000) | Acc: (54.00%) (23278/42368)
Epoch: 5 | Batch_idx: 340 |  Loss: (1.2443) |  Loss2: (0.0000) | Acc: (55.00%) (24016/43648)
Epoch: 5 | Batch_idx: 350 |  Loss: (1.2432) |  Loss2: (0.0000) | Acc: (55.00%) (24744/44928)
Epoch: 5 | Batch_idx: 360 |  Loss: (1.2420) |  Loss2: (0.0000) | Acc: (55.00%) (25473/46208)
Epoch: 5 | Batch_idx: 370 |  Loss: (1.2413) |  Loss2: (0.0000) | Acc: (55.00%) (26201/47488)
Epoch: 5 | Batch_idx: 380 |  Loss: (1.2416) |  Loss2: (0.0000) | Acc: (55.00%) (26896/48768)
Epoch: 5 | Batch_idx: 390 |  Loss: (1.2415) |  Loss2: (0.0000) | Acc: (55.00%) (27554/50000)
=> saving checkpoint 'drive/app/torch/save_Routing_Gate_2/checkpoint_005.pth.tar'
# TEST : Loss: (1.1860) | Acc: (56.00%) (5660/10000)
percent tensor([0.4990, 0.4971, 0.4974, 0.4981, 0.4974, 0.4996, 0.4972, 0.4977, 0.4981,
        0.4974, 0.4986, 0.4973, 0.4985, 0.4962, 0.4984, 0.4987],
       device='cuda:0') torch.Size([16])
percent tensor([0.5048, 0.5057, 0.5044, 0.5047, 0.5055, 0.5052, 0.5057, 0.5053, 0.5058,
        0.5050, 0.5052, 0.5041, 0.5049, 0.5059, 0.5051, 0.5048],
       device='cuda:0') torch.Size([16])
percent tensor([0.4857, 0.4878, 0.4884, 0.4811, 0.4878, 0.4772, 0.4892, 0.4881, 0.4906,
        0.4899, 0.4892, 0.4909, 0.4885, 0.4873, 0.4847, 0.4850],
       device='cuda:0') torch.Size([16])
percent tensor([0.5005, 0.5010, 0.5160, 0.5085, 0.5140, 0.5017, 0.5066, 0.5141, 0.5035,
        0.5040, 0.4985, 0.5122, 0.4993, 0.4983, 0.5030, 0.5019],
       device='cuda:0') torch.Size([16])
percent tensor([0.5029, 0.4989, 0.5104, 0.5081, 0.5129, 0.5097, 0.5046, 0.5108, 0.5027,
        0.5011, 0.5003, 0.5082, 0.4988, 0.4971, 0.5048, 0.5025],
       device='cuda:0') torch.Size([16])
percent tensor([0.4924, 0.4925, 0.5246, 0.5113, 0.5223, 0.4955, 0.5033, 0.5215, 0.4972,
        0.4955, 0.4902, 0.5140, 0.4887, 0.4890, 0.4988, 0.4949],
       device='cuda:0') torch.Size([16])
percent tensor([0.5169, 0.5092, 0.5218, 0.5211, 0.5220, 0.5272, 0.5115, 0.5214, 0.5103,
        0.5141, 0.5111, 0.5171, 0.5109, 0.5072, 0.5143, 0.5211],
       device='cuda:0') torch.Size([16])
percent tensor([0.6205, 0.5990, 0.6399, 0.6099, 0.6413, 0.6661, 0.6101, 0.6823, 0.6089,
        0.6255, 0.5962, 0.6076, 0.6119, 0.6033, 0.6216, 0.7076],
       device='cuda:0') torch.Size([16])
Epoch: 6 | Batch_idx: 0 |  Loss: (1.2113) |  Loss2: (0.0000) | Acc: (60.00%) (77/128)
Epoch: 6 | Batch_idx: 10 |  Loss: (1.2106) |  Loss2: (0.0000) | Acc: (57.00%) (808/1408)
Epoch: 6 | Batch_idx: 20 |  Loss: (1.2114) |  Loss2: (0.0000) | Acc: (56.00%) (1531/2688)
Epoch: 6 | Batch_idx: 30 |  Loss: (1.2212) |  Loss2: (0.0000) | Acc: (56.00%) (2242/3968)
Epoch: 6 | Batch_idx: 40 |  Loss: (1.2044) |  Loss2: (0.0000) | Acc: (57.00%) (3000/5248)
Epoch: 6 | Batch_idx: 50 |  Loss: (1.1998) |  Loss2: (0.0000) | Acc: (56.00%) (3705/6528)
Epoch: 6 | Batch_idx: 60 |  Loss: (1.2080) |  Loss2: (0.0000) | Acc: (55.00%) (4369/7808)
Epoch: 6 | Batch_idx: 70 |  Loss: (1.2141) |  Loss2: (0.0000) | Acc: (55.00%) (5071/9088)
Epoch: 6 | Batch_idx: 80 |  Loss: (1.2138) |  Loss2: (0.0000) | Acc: (55.00%) (5794/10368)
Epoch: 6 | Batch_idx: 90 |  Loss: (1.2127) |  Loss2: (0.0000) | Acc: (55.00%) (6516/11648)
Epoch: 6 | Batch_idx: 100 |  Loss: (1.2081) |  Loss2: (0.0000) | Acc: (56.00%) (7249/12928)
Epoch: 6 | Batch_idx: 110 |  Loss: (1.2040) |  Loss2: (0.0000) | Acc: (56.00%) (7982/14208)
Epoch: 6 | Batch_idx: 120 |  Loss: (1.2070) |  Loss2: (0.0000) | Acc: (56.00%) (8683/15488)
Epoch: 6 | Batch_idx: 130 |  Loss: (1.2038) |  Loss2: (0.0000) | Acc: (56.00%) (9433/16768)
Epoch: 6 | Batch_idx: 140 |  Loss: (1.2022) |  Loss2: (0.0000) | Acc: (56.00%) (10165/18048)
Epoch: 6 | Batch_idx: 150 |  Loss: (1.2032) |  Loss2: (0.0000) | Acc: (56.00%) (10881/19328)
Epoch: 6 | Batch_idx: 160 |  Loss: (1.2011) |  Loss2: (0.0000) | Acc: (56.00%) (11607/20608)
Epoch: 6 | Batch_idx: 170 |  Loss: (1.1999) |  Loss2: (0.0000) | Acc: (56.00%) (12344/21888)
Epoch: 6 | Batch_idx: 180 |  Loss: (1.2008) |  Loss2: (0.0000) | Acc: (56.00%) (13071/23168)
Epoch: 6 | Batch_idx: 190 |  Loss: (1.2001) |  Loss2: (0.0000) | Acc: (56.00%) (13803/24448)
Epoch: 6 | Batch_idx: 200 |  Loss: (1.1998) |  Loss2: (0.0000) | Acc: (56.00%) (14537/25728)
Epoch: 6 | Batch_idx: 210 |  Loss: (1.2002) |  Loss2: (0.0000) | Acc: (56.00%) (15258/27008)
Epoch: 6 | Batch_idx: 220 |  Loss: (1.2010) |  Loss2: (0.0000) | Acc: (56.00%) (15994/28288)
Epoch: 6 | Batch_idx: 230 |  Loss: (1.2001) |  Loss2: (0.0000) | Acc: (56.00%) (16733/29568)
Epoch: 6 | Batch_idx: 240 |  Loss: (1.2005) |  Loss2: (0.0000) | Acc: (56.00%) (17452/30848)
Epoch: 6 | Batch_idx: 250 |  Loss: (1.1990) |  Loss2: (0.0000) | Acc: (56.00%) (18188/32128)
Epoch: 6 | Batch_idx: 260 |  Loss: (1.1999) |  Loss2: (0.0000) | Acc: (56.00%) (18912/33408)
Epoch: 6 | Batch_idx: 270 |  Loss: (1.1991) |  Loss2: (0.0000) | Acc: (56.00%) (19647/34688)
Epoch: 6 | Batch_idx: 280 |  Loss: (1.1987) |  Loss2: (0.0000) | Acc: (56.00%) (20387/35968)
Epoch: 6 | Batch_idx: 290 |  Loss: (1.1967) |  Loss2: (0.0000) | Acc: (56.00%) (21133/37248)
Epoch: 6 | Batch_idx: 300 |  Loss: (1.1949) |  Loss2: (0.0000) | Acc: (56.00%) (21887/38528)
Epoch: 6 | Batch_idx: 310 |  Loss: (1.1950) |  Loss2: (0.0000) | Acc: (56.00%) (22599/39808)
Epoch: 6 | Batch_idx: 320 |  Loss: (1.1943) |  Loss2: (0.0000) | Acc: (56.00%) (23314/41088)
Epoch: 6 | Batch_idx: 330 |  Loss: (1.1938) |  Loss2: (0.0000) | Acc: (56.00%) (24058/42368)
Epoch: 6 | Batch_idx: 340 |  Loss: (1.1937) |  Loss2: (0.0000) | Acc: (56.00%) (24791/43648)
Epoch: 6 | Batch_idx: 350 |  Loss: (1.1923) |  Loss2: (0.0000) | Acc: (56.00%) (25548/44928)
Epoch: 6 | Batch_idx: 360 |  Loss: (1.1907) |  Loss2: (0.0000) | Acc: (56.00%) (26297/46208)
Epoch: 6 | Batch_idx: 370 |  Loss: (1.1895) |  Loss2: (0.0000) | Acc: (56.00%) (27059/47488)
Epoch: 6 | Batch_idx: 380 |  Loss: (1.1879) |  Loss2: (0.0000) | Acc: (56.00%) (27784/48768)
Epoch: 6 | Batch_idx: 390 |  Loss: (1.1878) |  Loss2: (0.0000) | Acc: (56.00%) (28480/50000)
# TEST : Loss: (1.1599) | Acc: (57.00%) (5768/10000)
percent tensor([0.5033, 0.5000, 0.5006, 0.4999, 0.5011, 0.5044, 0.5012, 0.5004, 0.5028,
        0.5007, 0.5029, 0.5010, 0.5023, 0.4988, 0.5021, 0.5023],
       device='cuda:0') torch.Size([16])
percent tensor([0.5059, 0.5073, 0.5011, 0.5042, 0.5037, 0.5077, 0.5058, 0.5037, 0.5064,
        0.5045, 0.5065, 0.5009, 0.5058, 0.5085, 0.5064, 0.5061],
       device='cuda:0') torch.Size([16])
percent tensor([0.4735, 0.4778, 0.4792, 0.4656, 0.4781, 0.4579, 0.4804, 0.4786, 0.4829,
        0.4815, 0.4806, 0.4829, 0.4791, 0.4759, 0.4720, 0.4722],
       device='cuda:0') torch.Size([16])
percent tensor([0.5018, 0.5025, 0.5256, 0.5140, 0.5232, 0.5044, 0.5117, 0.5229, 0.5070,
        0.5077, 0.4990, 0.5205, 0.5000, 0.4986, 0.5057, 0.5043],
       device='cuda:0') torch.Size([16])
percent tensor([0.5065, 0.4995, 0.5171, 0.5148, 0.5217, 0.5184, 0.5084, 0.5187, 0.5049,
        0.5029, 0.5011, 0.5135, 0.4990, 0.4975, 0.5101, 0.5059],
       device='cuda:0') torch.Size([16])
percent tensor([0.4839, 0.4832, 0.5324, 0.5138, 0.5294, 0.4911, 0.5009, 0.5252, 0.4919,
        0.4880, 0.4799, 0.5187, 0.4770, 0.4794, 0.4905, 0.4864],
       device='cuda:0') torch.Size([16])
percent tensor([0.5279, 0.5153, 0.5307, 0.5321, 0.5303, 0.5440, 0.5183, 0.5272, 0.5177,
        0.5233, 0.5193, 0.5270, 0.5186, 0.5140, 0.5196, 0.5325],
       device='cuda:0') torch.Size([16])
percent tensor([0.7200, 0.6884, 0.7631, 0.7170, 0.7750, 0.7832, 0.7075, 0.8216, 0.7057,
        0.7328, 0.6874, 0.7080, 0.7067, 0.6964, 0.7281, 0.8397],
       device='cuda:0') torch.Size([16])
Epoch: 7 | Batch_idx: 0 |  Loss: (1.3710) |  Loss2: (0.0000) | Acc: (48.00%) (62/128)
Epoch: 7 | Batch_idx: 10 |  Loss: (1.1888) |  Loss2: (0.0000) | Acc: (57.00%) (808/1408)
Epoch: 7 | Batch_idx: 20 |  Loss: (1.1954) |  Loss2: (0.0000) | Acc: (57.00%) (1541/2688)
Epoch: 7 | Batch_idx: 30 |  Loss: (1.1861) |  Loss2: (0.0000) | Acc: (57.00%) (2291/3968)
Epoch: 7 | Batch_idx: 40 |  Loss: (1.1832) |  Loss2: (0.0000) | Acc: (57.00%) (3032/5248)
Epoch: 7 | Batch_idx: 50 |  Loss: (1.1859) |  Loss2: (0.0000) | Acc: (57.00%) (3734/6528)
Epoch: 7 | Batch_idx: 60 |  Loss: (1.1792) |  Loss2: (0.0000) | Acc: (57.00%) (4481/7808)
Epoch: 7 | Batch_idx: 70 |  Loss: (1.1765) |  Loss2: (0.0000) | Acc: (57.00%) (5231/9088)
Epoch: 7 | Batch_idx: 80 |  Loss: (1.1811) |  Loss2: (0.0000) | Acc: (57.00%) (5944/10368)
Epoch: 7 | Batch_idx: 90 |  Loss: (1.1808) |  Loss2: (0.0000) | Acc: (57.00%) (6674/11648)
Epoch: 7 | Batch_idx: 100 |  Loss: (1.1811) |  Loss2: (0.0000) | Acc: (57.00%) (7428/12928)
Epoch: 7 | Batch_idx: 110 |  Loss: (1.1833) |  Loss2: (0.0000) | Acc: (57.00%) (8138/14208)
Epoch: 7 | Batch_idx: 120 |  Loss: (1.1795) |  Loss2: (0.0000) | Acc: (57.00%) (8889/15488)
Epoch: 7 | Batch_idx: 130 |  Loss: (1.1772) |  Loss2: (0.0000) | Acc: (57.00%) (9644/16768)
Epoch: 7 | Batch_idx: 140 |  Loss: (1.1762) |  Loss2: (0.0000) | Acc: (57.00%) (10390/18048)
Epoch: 7 | Batch_idx: 150 |  Loss: (1.1754) |  Loss2: (0.0000) | Acc: (57.00%) (11139/19328)
Epoch: 7 | Batch_idx: 160 |  Loss: (1.1747) |  Loss2: (0.0000) | Acc: (57.00%) (11870/20608)
Epoch: 7 | Batch_idx: 170 |  Loss: (1.1737) |  Loss2: (0.0000) | Acc: (57.00%) (12624/21888)
Epoch: 7 | Batch_idx: 180 |  Loss: (1.1745) |  Loss2: (0.0000) | Acc: (57.00%) (13358/23168)
Epoch: 7 | Batch_idx: 190 |  Loss: (1.1704) |  Loss2: (0.0000) | Acc: (57.00%) (14115/24448)
Epoch: 7 | Batch_idx: 200 |  Loss: (1.1707) |  Loss2: (0.0000) | Acc: (57.00%) (14837/25728)
Epoch: 7 | Batch_idx: 210 |  Loss: (1.1724) |  Loss2: (0.0000) | Acc: (57.00%) (15573/27008)
Epoch: 7 | Batch_idx: 220 |  Loss: (1.1710) |  Loss2: (0.0000) | Acc: (57.00%) (16323/28288)
Epoch: 7 | Batch_idx: 230 |  Loss: (1.1700) |  Loss2: (0.0000) | Acc: (57.00%) (17065/29568)
Epoch: 7 | Batch_idx: 240 |  Loss: (1.1680) |  Loss2: (0.0000) | Acc: (57.00%) (17829/30848)
Epoch: 7 | Batch_idx: 250 |  Loss: (1.1671) |  Loss2: (0.0000) | Acc: (57.00%) (18560/32128)
Epoch: 7 | Batch_idx: 260 |  Loss: (1.1656) |  Loss2: (0.0000) | Acc: (57.00%) (19302/33408)
Epoch: 7 | Batch_idx: 270 |  Loss: (1.1655) |  Loss2: (0.0000) | Acc: (57.00%) (20040/34688)
Epoch: 7 | Batch_idx: 280 |  Loss: (1.1637) |  Loss2: (0.0000) | Acc: (57.00%) (20809/35968)
Epoch: 7 | Batch_idx: 290 |  Loss: (1.1645) |  Loss2: (0.0000) | Acc: (57.00%) (21553/37248)
Epoch: 7 | Batch_idx: 300 |  Loss: (1.1644) |  Loss2: (0.0000) | Acc: (57.00%) (22303/38528)
Epoch: 7 | Batch_idx: 310 |  Loss: (1.1645) |  Loss2: (0.0000) | Acc: (57.00%) (23044/39808)
Epoch: 7 | Batch_idx: 320 |  Loss: (1.1646) |  Loss2: (0.0000) | Acc: (57.00%) (23781/41088)
Epoch: 7 | Batch_idx: 330 |  Loss: (1.1643) |  Loss2: (0.0000) | Acc: (57.00%) (24530/42368)
Epoch: 7 | Batch_idx: 340 |  Loss: (1.1652) |  Loss2: (0.0000) | Acc: (57.00%) (25267/43648)
Epoch: 7 | Batch_idx: 350 |  Loss: (1.1663) |  Loss2: (0.0000) | Acc: (57.00%) (26003/44928)
Epoch: 7 | Batch_idx: 360 |  Loss: (1.1657) |  Loss2: (0.0000) | Acc: (57.00%) (26744/46208)
Epoch: 7 | Batch_idx: 370 |  Loss: (1.1659) |  Loss2: (0.0000) | Acc: (57.00%) (27475/47488)
Epoch: 7 | Batch_idx: 380 |  Loss: (1.1660) |  Loss2: (0.0000) | Acc: (57.00%) (28197/48768)
Epoch: 7 | Batch_idx: 390 |  Loss: (1.1660) |  Loss2: (0.0000) | Acc: (57.00%) (28925/50000)
# TEST : Loss: (1.1494) | Acc: (58.00%) (5810/10000)
percent tensor([0.5067, 0.5023, 0.5035, 0.5014, 0.5043, 0.5081, 0.5044, 0.5026, 0.5065,
        0.5033, 0.5063, 0.5042, 0.5053, 0.5007, 0.5050, 0.5050],
       device='cuda:0') torch.Size([16])
percent tensor([0.5057, 0.5075, 0.4956, 0.5019, 0.4997, 0.5085, 0.5041, 0.5000, 0.5052,
        0.5023, 0.5065, 0.4956, 0.5053, 0.5098, 0.5062, 0.5059],
       device='cuda:0') torch.Size([16])
percent tensor([0.4675, 0.4733, 0.4761, 0.4577, 0.4743, 0.4475, 0.4770, 0.4753, 0.4802,
        0.4784, 0.4774, 0.4802, 0.4754, 0.4697, 0.4661, 0.4657],
       device='cuda:0') torch.Size([16])
percent tensor([0.5052, 0.5062, 0.5319, 0.5185, 0.5301, 0.5089, 0.5172, 0.5295, 0.5116,
        0.5124, 0.5026, 0.5269, 0.5031, 0.5018, 0.5099, 0.5084],
       device='cuda:0') torch.Size([16])
percent tensor([0.5103, 0.5018, 0.5200, 0.5194, 0.5264, 0.5246, 0.5120, 0.5232, 0.5078,
        0.5053, 0.5035, 0.5161, 0.5010, 0.5007, 0.5145, 0.5090],
       device='cuda:0') torch.Size([16])
percent tensor([0.4772, 0.4760, 0.5318, 0.5125, 0.5283, 0.4879, 0.4975, 0.5202, 0.4878,
        0.4819, 0.4724, 0.5187, 0.4685, 0.4740, 0.4804, 0.4790],
       device='cuda:0') torch.Size([16])
percent tensor([0.5357, 0.5198, 0.5348, 0.5394, 0.5337, 0.5543, 0.5227, 0.5282, 0.5227,
        0.5301, 0.5251, 0.5331, 0.5244, 0.5195, 0.5213, 0.5405],
       device='cuda:0') torch.Size([16])
percent tensor([0.7674, 0.7272, 0.8255, 0.7768, 0.8393, 0.8393, 0.7496, 0.8792, 0.7490,
        0.7823, 0.7243, 0.7582, 0.7464, 0.7360, 0.7829, 0.8868],
       device='cuda:0') torch.Size([16])
Epoch: 8 | Batch_idx: 0 |  Loss: (0.9648) |  Loss2: (0.0000) | Acc: (64.00%) (83/128)
Epoch: 8 | Batch_idx: 10 |  Loss: (1.1909) |  Loss2: (0.0000) | Acc: (57.00%) (803/1408)
Epoch: 8 | Batch_idx: 20 |  Loss: (1.1868) |  Loss2: (0.0000) | Acc: (57.00%) (1533/2688)
Epoch: 8 | Batch_idx: 30 |  Loss: (1.1694) |  Loss2: (0.0000) | Acc: (57.00%) (2299/3968)
Epoch: 8 | Batch_idx: 40 |  Loss: (1.1633) |  Loss2: (0.0000) | Acc: (58.00%) (3049/5248)
Epoch: 8 | Batch_idx: 50 |  Loss: (1.1626) |  Loss2: (0.0000) | Acc: (57.00%) (3770/6528)
Epoch: 8 | Batch_idx: 60 |  Loss: (1.1599) |  Loss2: (0.0000) | Acc: (57.00%) (4516/7808)
Epoch: 8 | Batch_idx: 70 |  Loss: (1.1523) |  Loss2: (0.0000) | Acc: (58.00%) (5294/9088)
Epoch: 8 | Batch_idx: 80 |  Loss: (1.1568) |  Loss2: (0.0000) | Acc: (58.00%) (6038/10368)
Epoch: 8 | Batch_idx: 90 |  Loss: (1.1587) |  Loss2: (0.0000) | Acc: (58.00%) (6777/11648)
Epoch: 8 | Batch_idx: 100 |  Loss: (1.1625) |  Loss2: (0.0000) | Acc: (57.00%) (7492/12928)
Epoch: 8 | Batch_idx: 110 |  Loss: (1.1638) |  Loss2: (0.0000) | Acc: (57.00%) (8215/14208)
Epoch: 8 | Batch_idx: 120 |  Loss: (1.1671) |  Loss2: (0.0000) | Acc: (57.00%) (8932/15488)
Epoch: 8 | Batch_idx: 130 |  Loss: (1.1668) |  Loss2: (0.0000) | Acc: (57.00%) (9680/16768)
Epoch: 8 | Batch_idx: 140 |  Loss: (1.1685) |  Loss2: (0.0000) | Acc: (57.00%) (10412/18048)
Epoch: 8 | Batch_idx: 150 |  Loss: (1.1657) |  Loss2: (0.0000) | Acc: (57.00%) (11172/19328)
Epoch: 8 | Batch_idx: 160 |  Loss: (1.1642) |  Loss2: (0.0000) | Acc: (57.00%) (11950/20608)
Epoch: 8 | Batch_idx: 170 |  Loss: (1.1607) |  Loss2: (0.0000) | Acc: (58.00%) (12738/21888)
Epoch: 8 | Batch_idx: 180 |  Loss: (1.1598) |  Loss2: (0.0000) | Acc: (58.00%) (13498/23168)
Epoch: 8 | Batch_idx: 190 |  Loss: (1.1591) |  Loss2: (0.0000) | Acc: (58.00%) (14250/24448)
Epoch: 8 | Batch_idx: 200 |  Loss: (1.1575) |  Loss2: (0.0000) | Acc: (58.00%) (15001/25728)
Epoch: 8 | Batch_idx: 210 |  Loss: (1.1567) |  Loss2: (0.0000) | Acc: (58.00%) (15754/27008)
Epoch: 8 | Batch_idx: 220 |  Loss: (1.1561) |  Loss2: (0.0000) | Acc: (58.00%) (16496/28288)
Epoch: 8 | Batch_idx: 230 |  Loss: (1.1573) |  Loss2: (0.0000) | Acc: (58.00%) (17214/29568)
Epoch: 8 | Batch_idx: 240 |  Loss: (1.1573) |  Loss2: (0.0000) | Acc: (58.00%) (17973/30848)
Epoch: 8 | Batch_idx: 250 |  Loss: (1.1562) |  Loss2: (0.0000) | Acc: (58.00%) (18750/32128)
Epoch: 8 | Batch_idx: 260 |  Loss: (1.1579) |  Loss2: (0.0000) | Acc: (58.00%) (19465/33408)
Epoch: 8 | Batch_idx: 270 |  Loss: (1.1578) |  Loss2: (0.0000) | Acc: (58.00%) (20215/34688)
Epoch: 8 | Batch_idx: 280 |  Loss: (1.1591) |  Loss2: (0.0000) | Acc: (58.00%) (20952/35968)
Epoch: 8 | Batch_idx: 290 |  Loss: (1.1582) |  Loss2: (0.0000) | Acc: (58.00%) (21683/37248)
Epoch: 8 | Batch_idx: 300 |  Loss: (1.1578) |  Loss2: (0.0000) | Acc: (58.00%) (22432/38528)
Epoch: 8 | Batch_idx: 310 |  Loss: (1.1586) |  Loss2: (0.0000) | Acc: (58.00%) (23145/39808)
Epoch: 8 | Batch_idx: 320 |  Loss: (1.1575) |  Loss2: (0.0000) | Acc: (58.00%) (23899/41088)
Epoch: 8 | Batch_idx: 330 |  Loss: (1.1572) |  Loss2: (0.0000) | Acc: (58.00%) (24636/42368)
Epoch: 8 | Batch_idx: 340 |  Loss: (1.1573) |  Loss2: (0.0000) | Acc: (58.00%) (25360/43648)
Epoch: 8 | Batch_idx: 350 |  Loss: (1.1571) |  Loss2: (0.0000) | Acc: (58.00%) (26091/44928)
Epoch: 8 | Batch_idx: 360 |  Loss: (1.1565) |  Loss2: (0.0000) | Acc: (58.00%) (26844/46208)
Epoch: 8 | Batch_idx: 370 |  Loss: (1.1575) |  Loss2: (0.0000) | Acc: (58.00%) (27553/47488)
Epoch: 8 | Batch_idx: 380 |  Loss: (1.1567) |  Loss2: (0.0000) | Acc: (58.00%) (28309/48768)
Epoch: 8 | Batch_idx: 390 |  Loss: (1.1566) |  Loss2: (0.0000) | Acc: (58.00%) (29026/50000)
# TEST : Loss: (1.1441) | Acc: (58.00%) (5852/10000)
percent tensor([0.5095, 0.5043, 0.5054, 0.5025, 0.5068, 0.5111, 0.5071, 0.5043, 0.5095,
        0.5055, 0.5091, 0.5066, 0.5078, 0.5026, 0.5074, 0.5072],
       device='cuda:0') torch.Size([16])
percent tensor([0.5052, 0.5073, 0.4903, 0.4996, 0.4957, 0.5088, 0.5022, 0.4963, 0.5036,
        0.5000, 0.5062, 0.4905, 0.5045, 0.5105, 0.5057, 0.5055],
       device='cuda:0') torch.Size([16])
percent tensor([0.4657, 0.4727, 0.4775, 0.4552, 0.4750, 0.4427, 0.4774, 0.4764, 0.4809,
        0.4790, 0.4774, 0.4815, 0.4755, 0.4675, 0.4646, 0.4636],
       device='cuda:0') torch.Size([16])
percent tensor([0.5071, 0.5084, 0.5349, 0.5207, 0.5337, 0.5115, 0.5203, 0.5328, 0.5144,
        0.5153, 0.5048, 0.5298, 0.5050, 0.5040, 0.5120, 0.5108],
       device='cuda:0') torch.Size([16])
percent tensor([0.5109, 0.5029, 0.5206, 0.5210, 0.5267, 0.5251, 0.5129, 0.5242, 0.5091,
        0.5060, 0.5040, 0.5157, 0.5016, 0.5032, 0.5149, 0.5088],
       device='cuda:0') torch.Size([16])
percent tensor([0.4700, 0.4686, 0.5254, 0.5085, 0.5213, 0.4834, 0.4913, 0.5083, 0.4828,
        0.4751, 0.4652, 0.5146, 0.4612, 0.4686, 0.4674, 0.4707],
       device='cuda:0') torch.Size([16])
percent tensor([0.5393, 0.5209, 0.5408, 0.5464, 0.5394, 0.5602, 0.5256, 0.5338, 0.5237,
        0.5335, 0.5266, 0.5384, 0.5253, 0.5203, 0.5229, 0.5464],
       device='cuda:0') torch.Size([16])
percent tensor([0.7918, 0.7482, 0.8590, 0.8129, 0.8741, 0.8685, 0.7762, 0.9056, 0.7661,
        0.8061, 0.7413, 0.7856, 0.7660, 0.7553, 0.8129, 0.9069],
       device='cuda:0') torch.Size([16])
Epoch: 9 | Batch_idx: 0 |  Loss: (1.1416) |  Loss2: (0.0000) | Acc: (62.00%) (80/128)
Epoch: 9 | Batch_idx: 10 |  Loss: (1.1626) |  Loss2: (0.0000) | Acc: (58.00%) (827/1408)
Epoch: 9 | Batch_idx: 20 |  Loss: (1.1566) |  Loss2: (0.0000) | Acc: (57.00%) (1558/2688)
Epoch: 9 | Batch_idx: 30 |  Loss: (1.1536) |  Loss2: (0.0000) | Acc: (58.00%) (2306/3968)
Epoch: 9 | Batch_idx: 40 |  Loss: (1.1356) |  Loss2: (0.0000) | Acc: (58.00%) (3079/5248)
Epoch: 9 | Batch_idx: 50 |  Loss: (1.1400) |  Loss2: (0.0000) | Acc: (58.00%) (3849/6528)
Epoch: 9 | Batch_idx: 60 |  Loss: (1.1480) |  Loss2: (0.0000) | Acc: (58.00%) (4594/7808)
Epoch: 9 | Batch_idx: 70 |  Loss: (1.1477) |  Loss2: (0.0000) | Acc: (58.00%) (5337/9088)
Epoch: 9 | Batch_idx: 80 |  Loss: (1.1449) |  Loss2: (0.0000) | Acc: (58.00%) (6093/10368)
Epoch: 9 | Batch_idx: 90 |  Loss: (1.1535) |  Loss2: (0.0000) | Acc: (58.00%) (6819/11648)
Epoch: 9 | Batch_idx: 100 |  Loss: (1.1515) |  Loss2: (0.0000) | Acc: (58.00%) (7591/12928)
Epoch: 9 | Batch_idx: 110 |  Loss: (1.1466) |  Loss2: (0.0000) | Acc: (58.00%) (8355/14208)
Epoch: 9 | Batch_idx: 120 |  Loss: (1.1479) |  Loss2: (0.0000) | Acc: (58.00%) (9096/15488)
Epoch: 9 | Batch_idx: 130 |  Loss: (1.1469) |  Loss2: (0.0000) | Acc: (58.00%) (9832/16768)
Epoch: 9 | Batch_idx: 140 |  Loss: (1.1459) |  Loss2: (0.0000) | Acc: (58.00%) (10595/18048)
Epoch: 9 | Batch_idx: 150 |  Loss: (1.1463) |  Loss2: (0.0000) | Acc: (58.00%) (11342/19328)
Epoch: 9 | Batch_idx: 160 |  Loss: (1.1461) |  Loss2: (0.0000) | Acc: (58.00%) (12081/20608)
Epoch: 9 | Batch_idx: 170 |  Loss: (1.1497) |  Loss2: (0.0000) | Acc: (58.00%) (12796/21888)
Epoch: 9 | Batch_idx: 180 |  Loss: (1.1534) |  Loss2: (0.0000) | Acc: (58.00%) (13523/23168)
Epoch: 9 | Batch_idx: 190 |  Loss: (1.1522) |  Loss2: (0.0000) | Acc: (58.00%) (14283/24448)
Epoch: 9 | Batch_idx: 200 |  Loss: (1.1517) |  Loss2: (0.0000) | Acc: (58.00%) (15035/25728)
Epoch: 9 | Batch_idx: 210 |  Loss: (1.1515) |  Loss2: (0.0000) | Acc: (58.00%) (15783/27008)
Epoch: 9 | Batch_idx: 220 |  Loss: (1.1517) |  Loss2: (0.0000) | Acc: (58.00%) (16520/28288)
Epoch: 9 | Batch_idx: 230 |  Loss: (1.1506) |  Loss2: (0.0000) | Acc: (58.00%) (17280/29568)
Epoch: 9 | Batch_idx: 240 |  Loss: (1.1523) |  Loss2: (0.0000) | Acc: (58.00%) (18023/30848)
Epoch: 9 | Batch_idx: 250 |  Loss: (1.1520) |  Loss2: (0.0000) | Acc: (58.00%) (18783/32128)
Epoch: 9 | Batch_idx: 260 |  Loss: (1.1510) |  Loss2: (0.0000) | Acc: (58.00%) (19548/33408)
Epoch: 9 | Batch_idx: 270 |  Loss: (1.1516) |  Loss2: (0.0000) | Acc: (58.00%) (20307/34688)
Epoch: 9 | Batch_idx: 280 |  Loss: (1.1531) |  Loss2: (0.0000) | Acc: (58.00%) (21043/35968)
Epoch: 9 | Batch_idx: 290 |  Loss: (1.1517) |  Loss2: (0.0000) | Acc: (58.00%) (21812/37248)
Epoch: 9 | Batch_idx: 300 |  Loss: (1.1523) |  Loss2: (0.0000) | Acc: (58.00%) (22531/38528)
Epoch: 9 | Batch_idx: 310 |  Loss: (1.1508) |  Loss2: (0.0000) | Acc: (58.00%) (23291/39808)
Epoch: 9 | Batch_idx: 320 |  Loss: (1.1508) |  Loss2: (0.0000) | Acc: (58.00%) (24042/41088)
Epoch: 9 | Batch_idx: 330 |  Loss: (1.1518) |  Loss2: (0.0000) | Acc: (58.00%) (24788/42368)
Epoch: 9 | Batch_idx: 340 |  Loss: (1.1507) |  Loss2: (0.0000) | Acc: (58.00%) (25552/43648)
Epoch: 9 | Batch_idx: 350 |  Loss: (1.1498) |  Loss2: (0.0000) | Acc: (58.00%) (26313/44928)
Epoch: 9 | Batch_idx: 360 |  Loss: (1.1495) |  Loss2: (0.0000) | Acc: (58.00%) (27067/46208)
Epoch: 9 | Batch_idx: 370 |  Loss: (1.1503) |  Loss2: (0.0000) | Acc: (58.00%) (27798/47488)
Epoch: 9 | Batch_idx: 380 |  Loss: (1.1504) |  Loss2: (0.0000) | Acc: (58.00%) (28522/48768)
Epoch: 9 | Batch_idx: 390 |  Loss: (1.1503) |  Loss2: (0.0000) | Acc: (58.00%) (29247/50000)
# TEST : Loss: (1.1363) | Acc: (58.00%) (5876/10000)
percent tensor([0.5115, 0.5058, 0.5062, 0.5030, 0.5081, 0.5138, 0.5089, 0.5050, 0.5114,
        0.5068, 0.5111, 0.5076, 0.5095, 0.5040, 0.5092, 0.5089],
       device='cuda:0') torch.Size([16])
percent tensor([0.5044, 0.5069, 0.4843, 0.4966, 0.4910, 0.5086, 0.4998, 0.4917, 0.5017,
        0.4974, 0.5056, 0.4849, 0.5035, 0.5110, 0.5047, 0.5046],
       device='cuda:0') torch.Size([16])
percent tensor([0.4632, 0.4716, 0.4756, 0.4516, 0.4730, 0.4374, 0.4763, 0.4754, 0.4799,
        0.4783, 0.4768, 0.4797, 0.4746, 0.4650, 0.4624, 0.4611],
       device='cuda:0') torch.Size([16])
percent tensor([0.5119, 0.5131, 0.5394, 0.5252, 0.5393, 0.5174, 0.5256, 0.5385, 0.5192,
        0.5203, 0.5094, 0.5348, 0.5092, 0.5087, 0.5169, 0.5162],
       device='cuda:0') torch.Size([16])
percent tensor([0.5144, 0.5063, 0.5226, 0.5247, 0.5287, 0.5287, 0.5159, 0.5268, 0.5125,
        0.5091, 0.5070, 0.5172, 0.5048, 0.5085, 0.5177, 0.5117],
       device='cuda:0') torch.Size([16])
percent tensor([0.4640, 0.4611, 0.5187, 0.5038, 0.5137, 0.4810, 0.4853, 0.4959, 0.4776,
        0.4683, 0.4575, 0.5110, 0.4540, 0.4640, 0.4545, 0.4635],
       device='cuda:0') torch.Size([16])
percent tensor([0.5405, 0.5206, 0.5451, 0.5527, 0.5452, 0.5609, 0.5273, 0.5386, 0.5219,
        0.5355, 0.5253, 0.5419, 0.5233, 0.5200, 0.5231, 0.5498],
       device='cuda:0') torch.Size([16])
percent tensor([0.8130, 0.7605, 0.8864, 0.8453, 0.9014, 0.8944, 0.7905, 0.9279, 0.7781,
        0.8236, 0.7508, 0.8095, 0.7774, 0.7696, 0.8388, 0.9200],
       device='cuda:0') torch.Size([16])
True Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=128, out_features=16, bias=False)
False Linear(in_features=16, out_features=2, bias=False)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=128, out_features=16, bias=False)
False Linear(in_features=16, out_features=2, bias=False)
True Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=256, out_features=32, bias=False)
False Linear(in_features=32, out_features=2, bias=False)
True Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=256, out_features=32, bias=False)
False Linear(in_features=32, out_features=2, bias=False)
True Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=512, out_features=64, bias=False)
False Linear(in_features=64, out_features=2, bias=False)
True Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=512, out_features=64, bias=False)
False Linear(in_features=64, out_features=2, bias=False)
True Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1024, out_features=128, bias=False)
False Linear(in_features=128, out_features=2, bias=False)
True Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1024, out_features=128, bias=False)
False Linear(in_features=128, out_features=2, bias=False)
True Linear(in_features=512, out_features=10, bias=True)
Epoch: 10 | Batch_idx: 0 |  Loss: (1.0930) |  Loss2: (0.0000) | Acc: (61.00%) (79/128)
Epoch: 10 | Batch_idx: 10 |  Loss: (1.1400) |  Loss2: (0.0000) | Acc: (58.00%) (821/1408)
Epoch: 10 | Batch_idx: 20 |  Loss: (1.1487) |  Loss2: (0.0000) | Acc: (58.00%) (1583/2688)
Epoch: 10 | Batch_idx: 30 |  Loss: (1.1566) |  Loss2: (0.0000) | Acc: (58.00%) (2315/3968)
Epoch: 10 | Batch_idx: 40 |  Loss: (1.1661) |  Loss2: (0.0000) | Acc: (58.00%) (3051/5248)
Epoch: 10 | Batch_idx: 50 |  Loss: (1.1675) |  Loss2: (0.0000) | Acc: (57.00%) (3786/6528)
Epoch: 10 | Batch_idx: 60 |  Loss: (1.1618) |  Loss2: (0.0000) | Acc: (58.00%) (4546/7808)
Epoch: 10 | Batch_idx: 70 |  Loss: (1.1703) |  Loss2: (0.0000) | Acc: (57.00%) (5263/9088)
Epoch: 10 | Batch_idx: 80 |  Loss: (1.1694) |  Loss2: (0.0000) | Acc: (57.00%) (6013/10368)
Epoch: 10 | Batch_idx: 90 |  Loss: (1.1659) |  Loss2: (0.0000) | Acc: (58.00%) (6762/11648)
Epoch: 10 | Batch_idx: 100 |  Loss: (1.1623) |  Loss2: (0.0000) | Acc: (58.00%) (7519/12928)
Epoch: 10 | Batch_idx: 110 |  Loss: (1.1591) |  Loss2: (0.0000) | Acc: (58.00%) (8272/14208)
Epoch: 10 | Batch_idx: 120 |  Loss: (1.1561) |  Loss2: (0.0000) | Acc: (58.00%) (9036/15488)
Epoch: 10 | Batch_idx: 130 |  Loss: (1.1528) |  Loss2: (0.0000) | Acc: (58.00%) (9801/16768)
Epoch: 10 | Batch_idx: 140 |  Loss: (1.1528) |  Loss2: (0.0000) | Acc: (58.00%) (10546/18048)
Epoch: 10 | Batch_idx: 150 |  Loss: (1.1491) |  Loss2: (0.0000) | Acc: (58.00%) (11314/19328)
Epoch: 10 | Batch_idx: 160 |  Loss: (1.1471) |  Loss2: (0.0000) | Acc: (58.00%) (12097/20608)
Epoch: 10 | Batch_idx: 170 |  Loss: (1.1477) |  Loss2: (0.0000) | Acc: (58.00%) (12845/21888)
Epoch: 10 | Batch_idx: 180 |  Loss: (1.1466) |  Loss2: (0.0000) | Acc: (58.00%) (13626/23168)
Epoch: 10 | Batch_idx: 190 |  Loss: (1.1426) |  Loss2: (0.0000) | Acc: (58.00%) (14409/24448)
Epoch: 10 | Batch_idx: 200 |  Loss: (1.1429) |  Loss2: (0.0000) | Acc: (58.00%) (15150/25728)
Epoch: 10 | Batch_idx: 210 |  Loss: (1.1445) |  Loss2: (0.0000) | Acc: (58.00%) (15865/27008)
Epoch: 10 | Batch_idx: 220 |  Loss: (1.1421) |  Loss2: (0.0000) | Acc: (58.00%) (16635/28288)
Epoch: 10 | Batch_idx: 230 |  Loss: (1.1408) |  Loss2: (0.0000) | Acc: (58.00%) (17406/29568)
Epoch: 10 | Batch_idx: 240 |  Loss: (1.1374) |  Loss2: (0.0000) | Acc: (58.00%) (18190/30848)
Epoch: 10 | Batch_idx: 250 |  Loss: (1.1349) |  Loss2: (0.0000) | Acc: (59.00%) (18982/32128)
Epoch: 10 | Batch_idx: 260 |  Loss: (1.1337) |  Loss2: (0.0000) | Acc: (59.00%) (19749/33408)
Epoch: 10 | Batch_idx: 270 |  Loss: (1.1294) |  Loss2: (0.0000) | Acc: (59.00%) (20554/34688)
Epoch: 10 | Batch_idx: 280 |  Loss: (1.1289) |  Loss2: (0.0000) | Acc: (59.00%) (21319/35968)
Epoch: 10 | Batch_idx: 290 |  Loss: (1.1287) |  Loss2: (0.0000) | Acc: (59.00%) (22093/37248)
Epoch: 10 | Batch_idx: 300 |  Loss: (1.1284) |  Loss2: (0.0000) | Acc: (59.00%) (22875/38528)
Epoch: 10 | Batch_idx: 310 |  Loss: (1.1259) |  Loss2: (0.0000) | Acc: (59.00%) (23675/39808)
Epoch: 10 | Batch_idx: 320 |  Loss: (1.1246) |  Loss2: (0.0000) | Acc: (59.00%) (24450/41088)
Epoch: 10 | Batch_idx: 330 |  Loss: (1.1230) |  Loss2: (0.0000) | Acc: (59.00%) (25238/42368)
Epoch: 10 | Batch_idx: 340 |  Loss: (1.1220) |  Loss2: (0.0000) | Acc: (59.00%) (26026/43648)
Epoch: 10 | Batch_idx: 350 |  Loss: (1.1211) |  Loss2: (0.0000) | Acc: (59.00%) (26811/44928)
Epoch: 10 | Batch_idx: 360 |  Loss: (1.1195) |  Loss2: (0.0000) | Acc: (59.00%) (27616/46208)
Epoch: 10 | Batch_idx: 370 |  Loss: (1.1177) |  Loss2: (0.0000) | Acc: (59.00%) (28435/47488)
Epoch: 10 | Batch_idx: 380 |  Loss: (1.1149) |  Loss2: (0.0000) | Acc: (59.00%) (29244/48768)
Epoch: 10 | Batch_idx: 390 |  Loss: (1.1130) |  Loss2: (0.0000) | Acc: (60.00%) (30024/50000)
=> saving checkpoint 'drive/app/torch/save_Routing_Gate_2/checkpoint_010.pth.tar'
# TEST : Loss: (1.1021) | Acc: (60.00%) (6048/10000)
percent tensor([0.5105, 0.5047, 0.5054, 0.5020, 0.5076, 0.5127, 0.5079, 0.5041, 0.5101,
        0.5061, 0.5097, 0.5066, 0.5082, 0.5033, 0.5082, 0.5077],
       device='cuda:0') torch.Size([16])
percent tensor([0.5025, 0.5065, 0.4872, 0.4949, 0.4920, 0.5067, 0.5004, 0.4930, 0.5011,
        0.4982, 0.5044, 0.4873, 0.5022, 0.5098, 0.5038, 0.5026],
       device='cuda:0') torch.Size([16])
percent tensor([0.4677, 0.4744, 0.4852, 0.4643, 0.4787, 0.4434, 0.4801, 0.4829, 0.4819,
        0.4820, 0.4777, 0.4875, 0.4786, 0.4681, 0.4657, 0.4662],
       device='cuda:0') torch.Size([16])
percent tensor([0.5129, 0.5149, 0.5323, 0.5246, 0.5356, 0.5200, 0.5253, 0.5323, 0.5184,
        0.5194, 0.5108, 0.5283, 0.5089, 0.5113, 0.5198, 0.5174],
       device='cuda:0') torch.Size([16])
percent tensor([0.5149, 0.5074, 0.5161, 0.5219, 0.5220, 0.5266, 0.5147, 0.5216, 0.5130,
        0.5085, 0.5099, 0.5139, 0.5051, 0.5118, 0.5201, 0.5130],
       device='cuda:0') torch.Size([16])
percent tensor([0.4613, 0.4561, 0.4922, 0.4921, 0.4916, 0.4720, 0.4754, 0.4716, 0.4678,
        0.4637, 0.4556, 0.4855, 0.4479, 0.4717, 0.4509, 0.4591],
       device='cuda:0') torch.Size([16])
percent tensor([0.5411, 0.5173, 0.5447, 0.5498, 0.5407, 0.5537, 0.5254, 0.5353, 0.5200,
        0.5317, 0.5267, 0.5409, 0.5214, 0.5216, 0.5191, 0.5450],
       device='cuda:0') torch.Size([16])
percent tensor([0.8485, 0.7574, 0.8652, 0.8465, 0.8830, 0.8725, 0.8151, 0.9098, 0.7503,
        0.8080, 0.7521, 0.8274, 0.7709, 0.7775, 0.8550, 0.9058],
       device='cuda:0') torch.Size([16])
Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 3, 3, 3]) tensor(165.6237, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(773.3801, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(771.8487, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([128, 64, 3, 3]) tensor(1532.0988, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([128, 64, 1, 1]) tensor(509.7633, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([128, 128, 3, 3]) tensor(2169.8901, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([256, 128, 3, 3]) tensor(4325.3931, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([256, 128, 1, 1]) tensor(1440.4258, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([256, 256, 3, 3]) tensor(6102.1694, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([512, 256, 3, 3]) tensor(12228.8633, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([512, 256, 1, 1]) tensor(4080.6956, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([512, 512, 3, 3]) tensor(17274.5703, device='cuda:0', grad_fn=<NormBackward0>)
Epoch: 11 | Batch_idx: 0 |  Loss: (0.9936) |  Loss2: (0.0000) | Acc: (64.00%) (83/128)
Epoch: 11 | Batch_idx: 10 |  Loss: (1.0209) |  Loss2: (0.0000) | Acc: (63.00%) (894/1408)
Epoch: 11 | Batch_idx: 20 |  Loss: (1.0349) |  Loss2: (0.0000) | Acc: (62.00%) (1686/2688)
Epoch: 11 | Batch_idx: 30 |  Loss: (1.0338) |  Loss2: (0.0000) | Acc: (63.00%) (2511/3968)
Epoch: 11 | Batch_idx: 40 |  Loss: (1.0345) |  Loss2: (0.0000) | Acc: (63.00%) (3315/5248)
Epoch: 11 | Batch_idx: 50 |  Loss: (1.0367) |  Loss2: (0.0000) | Acc: (62.00%) (4097/6528)
Epoch: 11 | Batch_idx: 60 |  Loss: (1.0358) |  Loss2: (0.0000) | Acc: (62.00%) (4893/7808)
Epoch: 11 | Batch_idx: 70 |  Loss: (1.0388) |  Loss2: (0.0000) | Acc: (62.00%) (5684/9088)
Epoch: 11 | Batch_idx: 80 |  Loss: (1.0362) |  Loss2: (0.0000) | Acc: (62.00%) (6504/10368)
Epoch: 11 | Batch_idx: 90 |  Loss: (1.0277) |  Loss2: (0.0000) | Acc: (63.00%) (7353/11648)
Epoch: 11 | Batch_idx: 100 |  Loss: (1.0289) |  Loss2: (0.0000) | Acc: (63.00%) (8155/12928)
Epoch: 11 | Batch_idx: 110 |  Loss: (1.0321) |  Loss2: (0.0000) | Acc: (63.00%) (8955/14208)
Epoch: 11 | Batch_idx: 120 |  Loss: (1.0308) |  Loss2: (0.0000) | Acc: (62.00%) (9756/15488)
Epoch: 11 | Batch_idx: 130 |  Loss: (1.0309) |  Loss2: (0.0000) | Acc: (63.00%) (10572/16768)
Epoch: 11 | Batch_idx: 140 |  Loss: (1.0313) |  Loss2: (0.0000) | Acc: (62.00%) (11362/18048)
Epoch: 11 | Batch_idx: 150 |  Loss: (1.0349) |  Loss2: (0.0000) | Acc: (62.00%) (12142/19328)
Epoch: 11 | Batch_idx: 160 |  Loss: (1.0366) |  Loss2: (0.0000) | Acc: (62.00%) (12939/20608)
Epoch: 11 | Batch_idx: 170 |  Loss: (1.0365) |  Loss2: (0.0000) | Acc: (62.00%) (13760/21888)
Epoch: 11 | Batch_idx: 180 |  Loss: (1.0364) |  Loss2: (0.0000) | Acc: (62.00%) (14578/23168)
Epoch: 11 | Batch_idx: 190 |  Loss: (1.0368) |  Loss2: (0.0000) | Acc: (62.00%) (15383/24448)
Epoch: 11 | Batch_idx: 200 |  Loss: (1.0365) |  Loss2: (0.0000) | Acc: (62.00%) (16208/25728)
Epoch: 11 | Batch_idx: 210 |  Loss: (1.0355) |  Loss2: (0.0000) | Acc: (62.00%) (17011/27008)
Epoch: 11 | Batch_idx: 220 |  Loss: (1.0345) |  Loss2: (0.0000) | Acc: (62.00%) (17805/28288)
Epoch: 11 | Batch_idx: 230 |  Loss: (1.0315) |  Loss2: (0.0000) | Acc: (63.00%) (18664/29568)
Epoch: 11 | Batch_idx: 240 |  Loss: (1.0308) |  Loss2: (0.0000) | Acc: (63.00%) (19466/30848)
Epoch: 11 | Batch_idx: 250 |  Loss: (1.0290) |  Loss2: (0.0000) | Acc: (63.00%) (20276/32128)
Epoch: 11 | Batch_idx: 260 |  Loss: (1.0304) |  Loss2: (0.0000) | Acc: (63.00%) (21088/33408)
Epoch: 11 | Batch_idx: 270 |  Loss: (1.0296) |  Loss2: (0.0000) | Acc: (63.00%) (21904/34688)
Epoch: 11 | Batch_idx: 280 |  Loss: (1.0291) |  Loss2: (0.0000) | Acc: (63.00%) (22716/35968)
Epoch: 11 | Batch_idx: 290 |  Loss: (1.0282) |  Loss2: (0.0000) | Acc: (63.00%) (23536/37248)
Epoch: 11 | Batch_idx: 300 |  Loss: (1.0266) |  Loss2: (0.0000) | Acc: (63.00%) (24365/38528)
Epoch: 11 | Batch_idx: 310 |  Loss: (1.0265) |  Loss2: (0.0000) | Acc: (63.00%) (25183/39808)
Epoch: 11 | Batch_idx: 320 |  Loss: (1.0244) |  Loss2: (0.0000) | Acc: (63.00%) (26032/41088)
Epoch: 11 | Batch_idx: 330 |  Loss: (1.0218) |  Loss2: (0.0000) | Acc: (63.00%) (26902/42368)
Epoch: 11 | Batch_idx: 340 |  Loss: (1.0201) |  Loss2: (0.0000) | Acc: (63.00%) (27747/43648)
Epoch: 11 | Batch_idx: 350 |  Loss: (1.0182) |  Loss2: (0.0000) | Acc: (63.00%) (28601/44928)
Epoch: 11 | Batch_idx: 360 |  Loss: (1.0170) |  Loss2: (0.0000) | Acc: (63.00%) (29427/46208)
Epoch: 11 | Batch_idx: 370 |  Loss: (1.0169) |  Loss2: (0.0000) | Acc: (63.00%) (30222/47488)
Epoch: 11 | Batch_idx: 380 |  Loss: (1.0169) |  Loss2: (0.0000) | Acc: (63.00%) (31046/48768)
Epoch: 11 | Batch_idx: 390 |  Loss: (1.0157) |  Loss2: (0.0000) | Acc: (63.00%) (31850/50000)
# TEST : Loss: (1.0663) | Acc: (62.00%) (6208/10000)
percent tensor([0.5105, 0.5052, 0.5065, 0.5020, 0.5078, 0.5132, 0.5083, 0.5049, 0.5099,
        0.5063, 0.5097, 0.5072, 0.5079, 0.5032, 0.5085, 0.5076],
       device='cuda:0') torch.Size([16])
percent tensor([0.5029, 0.5070, 0.4882, 0.4946, 0.4930, 0.5066, 0.5013, 0.4937, 0.5020,
        0.4983, 0.5046, 0.4888, 0.5022, 0.5111, 0.5038, 0.5025],
       device='cuda:0') torch.Size([16])
percent tensor([0.4664, 0.4753, 0.4762, 0.4595, 0.4720, 0.4385, 0.4791, 0.4753, 0.4800,
        0.4813, 0.4784, 0.4820, 0.4788, 0.4687, 0.4641, 0.4660],
       device='cuda:0') torch.Size([16])
percent tensor([0.5149, 0.5155, 0.5346, 0.5256, 0.5366, 0.5243, 0.5260, 0.5331, 0.5199,
        0.5203, 0.5123, 0.5292, 0.5107, 0.5128, 0.5210, 0.5183],
       device='cuda:0') torch.Size([16])
percent tensor([0.5163, 0.5078, 0.5221, 0.5251, 0.5274, 0.5267, 0.5162, 0.5254, 0.5155,
        0.5103, 0.5110, 0.5172, 0.5068, 0.5114, 0.5197, 0.5142],
       device='cuda:0') torch.Size([16])
percent tensor([0.4644, 0.4634, 0.5018, 0.4952, 0.5056, 0.4719, 0.4892, 0.4750, 0.4773,
        0.4690, 0.4578, 0.4911, 0.4491, 0.4804, 0.4513, 0.4637],
       device='cuda:0') torch.Size([16])
percent tensor([0.5469, 0.5236, 0.5426, 0.5571, 0.5468, 0.5606, 0.5338, 0.5368, 0.5241,
        0.5350, 0.5336, 0.5426, 0.5285, 0.5262, 0.5253, 0.5507],
       device='cuda:0') torch.Size([16])
percent tensor([0.8893, 0.7728, 0.8852, 0.8624, 0.8861, 0.9004, 0.8511, 0.9250, 0.7527,
        0.8062, 0.7684, 0.8504, 0.8108, 0.8226, 0.8819, 0.9060],
       device='cuda:0') torch.Size([16])
Epoch: 12 | Batch_idx: 0 |  Loss: (0.9732) |  Loss2: (0.0000) | Acc: (63.00%) (81/128)
Epoch: 12 | Batch_idx: 10 |  Loss: (0.9741) |  Loss2: (0.0000) | Acc: (65.00%) (917/1408)
Epoch: 12 | Batch_idx: 20 |  Loss: (0.9822) |  Loss2: (0.0000) | Acc: (64.00%) (1739/2688)
Epoch: 12 | Batch_idx: 30 |  Loss: (0.9604) |  Loss2: (0.0000) | Acc: (65.00%) (2609/3968)
Epoch: 12 | Batch_idx: 40 |  Loss: (0.9535) |  Loss2: (0.0000) | Acc: (66.00%) (3473/5248)
Epoch: 12 | Batch_idx: 50 |  Loss: (0.9534) |  Loss2: (0.0000) | Acc: (66.00%) (4328/6528)
Epoch: 12 | Batch_idx: 60 |  Loss: (0.9595) |  Loss2: (0.0000) | Acc: (66.00%) (5169/7808)
Epoch: 12 | Batch_idx: 70 |  Loss: (0.9617) |  Loss2: (0.0000) | Acc: (66.00%) (6013/9088)
Epoch: 12 | Batch_idx: 80 |  Loss: (0.9646) |  Loss2: (0.0000) | Acc: (65.00%) (6838/10368)
Epoch: 12 | Batch_idx: 90 |  Loss: (0.9689) |  Loss2: (0.0000) | Acc: (65.00%) (7633/11648)
Epoch: 12 | Batch_idx: 100 |  Loss: (0.9704) |  Loss2: (0.0000) | Acc: (65.00%) (8473/12928)
Epoch: 12 | Batch_idx: 110 |  Loss: (0.9694) |  Loss2: (0.0000) | Acc: (65.00%) (9308/14208)
Epoch: 12 | Batch_idx: 120 |  Loss: (0.9670) |  Loss2: (0.0000) | Acc: (65.00%) (10138/15488)
Epoch: 12 | Batch_idx: 130 |  Loss: (0.9696) |  Loss2: (0.0000) | Acc: (65.00%) (10965/16768)
Epoch: 12 | Batch_idx: 140 |  Loss: (0.9695) |  Loss2: (0.0000) | Acc: (65.00%) (11813/18048)
Epoch: 12 | Batch_idx: 150 |  Loss: (0.9698) |  Loss2: (0.0000) | Acc: (65.00%) (12649/19328)
Epoch: 12 | Batch_idx: 160 |  Loss: (0.9690) |  Loss2: (0.0000) | Acc: (65.00%) (13500/20608)
Epoch: 12 | Batch_idx: 170 |  Loss: (0.9697) |  Loss2: (0.0000) | Acc: (65.00%) (14322/21888)
Epoch: 12 | Batch_idx: 180 |  Loss: (0.9652) |  Loss2: (0.0000) | Acc: (65.00%) (15209/23168)
Epoch: 12 | Batch_idx: 190 |  Loss: (0.9622) |  Loss2: (0.0000) | Acc: (65.00%) (16098/24448)
Epoch: 12 | Batch_idx: 200 |  Loss: (0.9612) |  Loss2: (0.0000) | Acc: (65.00%) (16942/25728)
Epoch: 12 | Batch_idx: 210 |  Loss: (0.9601) |  Loss2: (0.0000) | Acc: (65.00%) (17798/27008)
Epoch: 12 | Batch_idx: 220 |  Loss: (0.9601) |  Loss2: (0.0000) | Acc: (65.00%) (18639/28288)
Epoch: 12 | Batch_idx: 230 |  Loss: (0.9575) |  Loss2: (0.0000) | Acc: (66.00%) (19523/29568)
Epoch: 12 | Batch_idx: 240 |  Loss: (0.9566) |  Loss2: (0.0000) | Acc: (66.00%) (20364/30848)
Epoch: 12 | Batch_idx: 250 |  Loss: (0.9571) |  Loss2: (0.0000) | Acc: (65.00%) (21187/32128)
Epoch: 12 | Batch_idx: 260 |  Loss: (0.9558) |  Loss2: (0.0000) | Acc: (65.00%) (22046/33408)
Epoch: 12 | Batch_idx: 270 |  Loss: (0.9558) |  Loss2: (0.0000) | Acc: (66.00%) (22901/34688)
Epoch: 12 | Batch_idx: 280 |  Loss: (0.9551) |  Loss2: (0.0000) | Acc: (66.00%) (23753/35968)
Epoch: 12 | Batch_idx: 290 |  Loss: (0.9553) |  Loss2: (0.0000) | Acc: (66.00%) (24597/37248)
Epoch: 12 | Batch_idx: 300 |  Loss: (0.9540) |  Loss2: (0.0000) | Acc: (66.00%) (25465/38528)
Epoch: 12 | Batch_idx: 310 |  Loss: (0.9538) |  Loss2: (0.0000) | Acc: (66.00%) (26321/39808)
Epoch: 12 | Batch_idx: 320 |  Loss: (0.9527) |  Loss2: (0.0000) | Acc: (66.00%) (27182/41088)
Epoch: 12 | Batch_idx: 330 |  Loss: (0.9518) |  Loss2: (0.0000) | Acc: (66.00%) (28043/42368)
Epoch: 12 | Batch_idx: 340 |  Loss: (0.9504) |  Loss2: (0.0000) | Acc: (66.00%) (28894/43648)
Epoch: 12 | Batch_idx: 350 |  Loss: (0.9497) |  Loss2: (0.0000) | Acc: (66.00%) (29730/44928)
Epoch: 12 | Batch_idx: 360 |  Loss: (0.9503) |  Loss2: (0.0000) | Acc: (66.00%) (30566/46208)
Epoch: 12 | Batch_idx: 370 |  Loss: (0.9496) |  Loss2: (0.0000) | Acc: (66.00%) (31419/47488)
Epoch: 12 | Batch_idx: 380 |  Loss: (0.9483) |  Loss2: (0.0000) | Acc: (66.00%) (32295/48768)
Epoch: 12 | Batch_idx: 390 |  Loss: (0.9472) |  Loss2: (0.0000) | Acc: (66.00%) (33130/50000)
# TEST : Loss: (0.9424) | Acc: (65.00%) (6561/10000)
percent tensor([0.5100, 0.5054, 0.5059, 0.5017, 0.5073, 0.5120, 0.5082, 0.5051, 0.5094,
        0.5063, 0.5093, 0.5067, 0.5078, 0.5038, 0.5081, 0.5072],
       device='cuda:0') torch.Size([16])
percent tensor([0.5031, 0.5065, 0.4899, 0.4936, 0.4933, 0.5045, 0.5014, 0.4940, 0.5024,
        0.4992, 0.5050, 0.4906, 0.5030, 0.5092, 0.5027, 0.5019],
       device='cuda:0') torch.Size([16])
percent tensor([0.4679, 0.4713, 0.4810, 0.4643, 0.4756, 0.4461, 0.4760, 0.4735, 0.4756,
        0.4792, 0.4757, 0.4829, 0.4774, 0.4588, 0.4650, 0.4656],
       device='cuda:0') torch.Size([16])
percent tensor([0.5139, 0.5152, 0.5289, 0.5237, 0.5320, 0.5214, 0.5228, 0.5315, 0.5188,
        0.5173, 0.5121, 0.5240, 0.5101, 0.5139, 0.5193, 0.5179],
       device='cuda:0') torch.Size([16])
percent tensor([0.5151, 0.5075, 0.5196, 0.5220, 0.5233, 0.5239, 0.5154, 0.5238, 0.5169,
        0.5111, 0.5138, 0.5158, 0.5077, 0.5152, 0.5183, 0.5149],
       device='cuda:0') torch.Size([16])
percent tensor([0.4629, 0.4573, 0.4961, 0.4999, 0.4915, 0.4621, 0.4791, 0.4742, 0.4733,
        0.4622, 0.4639, 0.4822, 0.4447, 0.4854, 0.4496, 0.4637],
       device='cuda:0') torch.Size([16])
percent tensor([0.5439, 0.5211, 0.5472, 0.5556, 0.5412, 0.5575, 0.5314, 0.5322, 0.5238,
        0.5345, 0.5349, 0.5411, 0.5231, 0.5321, 0.5234, 0.5481],
       device='cuda:0') torch.Size([16])
percent tensor([0.8653, 0.7760, 0.8432, 0.8388, 0.8576, 0.8882, 0.8235, 0.8971, 0.7521,
        0.8109, 0.7856, 0.8107, 0.7593, 0.7977, 0.8316, 0.8920],
       device='cuda:0') torch.Size([16])
Epoch: 13 | Batch_idx: 0 |  Loss: (0.9087) |  Loss2: (0.0000) | Acc: (71.00%) (92/128)
Epoch: 13 | Batch_idx: 10 |  Loss: (0.9038) |  Loss2: (0.0000) | Acc: (68.00%) (960/1408)
Epoch: 13 | Batch_idx: 20 |  Loss: (0.9270) |  Loss2: (0.0000) | Acc: (67.00%) (1823/2688)
Epoch: 13 | Batch_idx: 30 |  Loss: (0.9323) |  Loss2: (0.0000) | Acc: (67.00%) (2677/3968)
Epoch: 13 | Batch_idx: 40 |  Loss: (0.9307) |  Loss2: (0.0000) | Acc: (67.00%) (3538/5248)
Epoch: 13 | Batch_idx: 50 |  Loss: (0.9292) |  Loss2: (0.0000) | Acc: (67.00%) (4403/6528)
Epoch: 13 | Batch_idx: 60 |  Loss: (0.9219) |  Loss2: (0.0000) | Acc: (67.00%) (5287/7808)
Epoch: 13 | Batch_idx: 70 |  Loss: (0.9139) |  Loss2: (0.0000) | Acc: (68.00%) (6180/9088)
Epoch: 13 | Batch_idx: 80 |  Loss: (0.9131) |  Loss2: (0.0000) | Acc: (68.00%) (7053/10368)
Epoch: 13 | Batch_idx: 90 |  Loss: (0.9087) |  Loss2: (0.0000) | Acc: (68.00%) (7931/11648)
Epoch: 13 | Batch_idx: 100 |  Loss: (0.9055) |  Loss2: (0.0000) | Acc: (68.00%) (8809/12928)
Epoch: 13 | Batch_idx: 110 |  Loss: (0.9073) |  Loss2: (0.0000) | Acc: (68.00%) (9677/14208)
Epoch: 13 | Batch_idx: 120 |  Loss: (0.9059) |  Loss2: (0.0000) | Acc: (68.00%) (10558/15488)
Epoch: 13 | Batch_idx: 130 |  Loss: (0.9078) |  Loss2: (0.0000) | Acc: (67.00%) (11393/16768)
Epoch: 13 | Batch_idx: 140 |  Loss: (0.9051) |  Loss2: (0.0000) | Acc: (68.00%) (12284/18048)
Epoch: 13 | Batch_idx: 150 |  Loss: (0.9044) |  Loss2: (0.0000) | Acc: (68.00%) (13162/19328)
Epoch: 13 | Batch_idx: 160 |  Loss: (0.9041) |  Loss2: (0.0000) | Acc: (68.00%) (14029/20608)
Epoch: 13 | Batch_idx: 170 |  Loss: (0.9052) |  Loss2: (0.0000) | Acc: (68.00%) (14888/21888)
Epoch: 13 | Batch_idx: 180 |  Loss: (0.9037) |  Loss2: (0.0000) | Acc: (68.00%) (15775/23168)
Epoch: 13 | Batch_idx: 190 |  Loss: (0.9054) |  Loss2: (0.0000) | Acc: (67.00%) (16614/24448)
Epoch: 13 | Batch_idx: 200 |  Loss: (0.9057) |  Loss2: (0.0000) | Acc: (67.00%) (17489/25728)
Epoch: 13 | Batch_idx: 210 |  Loss: (0.9058) |  Loss2: (0.0000) | Acc: (67.00%) (18347/27008)
Epoch: 13 | Batch_idx: 220 |  Loss: (0.9049) |  Loss2: (0.0000) | Acc: (67.00%) (19223/28288)
Epoch: 13 | Batch_idx: 230 |  Loss: (0.9054) |  Loss2: (0.0000) | Acc: (67.00%) (20097/29568)
Epoch: 13 | Batch_idx: 240 |  Loss: (0.9038) |  Loss2: (0.0000) | Acc: (68.00%) (20981/30848)
Epoch: 13 | Batch_idx: 250 |  Loss: (0.9020) |  Loss2: (0.0000) | Acc: (68.00%) (21867/32128)
Epoch: 13 | Batch_idx: 260 |  Loss: (0.8999) |  Loss2: (0.0000) | Acc: (68.00%) (22755/33408)
Epoch: 13 | Batch_idx: 270 |  Loss: (0.8984) |  Loss2: (0.0000) | Acc: (68.00%) (23642/34688)
Epoch: 13 | Batch_idx: 280 |  Loss: (0.8994) |  Loss2: (0.0000) | Acc: (68.00%) (24496/35968)
Epoch: 13 | Batch_idx: 290 |  Loss: (0.8999) |  Loss2: (0.0000) | Acc: (68.00%) (25349/37248)
Epoch: 13 | Batch_idx: 300 |  Loss: (0.8991) |  Loss2: (0.0000) | Acc: (68.00%) (26222/38528)
Epoch: 13 | Batch_idx: 310 |  Loss: (0.8970) |  Loss2: (0.0000) | Acc: (68.00%) (27107/39808)
Epoch: 13 | Batch_idx: 320 |  Loss: (0.8959) |  Loss2: (0.0000) | Acc: (68.00%) (27996/41088)
Epoch: 13 | Batch_idx: 330 |  Loss: (0.8954) |  Loss2: (0.0000) | Acc: (68.00%) (28897/42368)
Epoch: 13 | Batch_idx: 340 |  Loss: (0.8952) |  Loss2: (0.0000) | Acc: (68.00%) (29774/43648)
Epoch: 13 | Batch_idx: 350 |  Loss: (0.8946) |  Loss2: (0.0000) | Acc: (68.00%) (30660/44928)
Epoch: 13 | Batch_idx: 360 |  Loss: (0.8936) |  Loss2: (0.0000) | Acc: (68.00%) (31549/46208)
Epoch: 13 | Batch_idx: 370 |  Loss: (0.8927) |  Loss2: (0.0000) | Acc: (68.00%) (32455/47488)
Epoch: 13 | Batch_idx: 380 |  Loss: (0.8917) |  Loss2: (0.0000) | Acc: (68.00%) (33357/48768)
Epoch: 13 | Batch_idx: 390 |  Loss: (0.8905) |  Loss2: (0.0000) | Acc: (68.00%) (34210/50000)
# TEST : Loss: (0.9333) | Acc: (67.00%) (6701/10000)
percent tensor([0.5101, 0.5058, 0.5053, 0.5023, 0.5069, 0.5129, 0.5080, 0.5053, 0.5091,
        0.5063, 0.5092, 0.5060, 0.5076, 0.5043, 0.5086, 0.5077],
       device='cuda:0') torch.Size([16])
percent tensor([0.5025, 0.5069, 0.4877, 0.4922, 0.4910, 0.5042, 0.5006, 0.4934, 0.5011,
        0.4987, 0.5045, 0.4883, 0.5025, 0.5098, 0.5029, 0.5014],
       device='cuda:0') torch.Size([16])
percent tensor([0.4689, 0.4745, 0.4823, 0.4634, 0.4776, 0.4464, 0.4802, 0.4716, 0.4768,
        0.4818, 0.4777, 0.4859, 0.4784, 0.4644, 0.4657, 0.4671],
       device='cuda:0') torch.Size([16])
percent tensor([0.5159, 0.5146, 0.5344, 0.5282, 0.5368, 0.5257, 0.5247, 0.5345, 0.5223,
        0.5194, 0.5132, 0.5304, 0.5123, 0.5131, 0.5212, 0.5195],
       device='cuda:0') torch.Size([16])
percent tensor([0.5169, 0.5082, 0.5247, 0.5268, 0.5260, 0.5263, 0.5163, 0.5287, 0.5179,
        0.5117, 0.5152, 0.5203, 0.5091, 0.5125, 0.5201, 0.5148],
       device='cuda:0') torch.Size([16])
percent tensor([0.4711, 0.4650, 0.5178, 0.5100, 0.5112, 0.4681, 0.4871, 0.4840, 0.4839,
        0.4753, 0.4705, 0.5008, 0.4567, 0.4825, 0.4444, 0.4637],
       device='cuda:0') torch.Size([16])
percent tensor([0.5446, 0.5244, 0.5493, 0.5528, 0.5421, 0.5508, 0.5377, 0.5254, 0.5259,
        0.5356, 0.5380, 0.5445, 0.5292, 0.5303, 0.5193, 0.5450],
       device='cuda:0') torch.Size([16])
percent tensor([0.8883, 0.7948, 0.8696, 0.8546, 0.8769, 0.8687, 0.8559, 0.8970, 0.7727,
        0.8146, 0.8147, 0.8443, 0.7844, 0.8297, 0.8459, 0.8857],
       device='cuda:0') torch.Size([16])
Epoch: 14 | Batch_idx: 0 |  Loss: (0.9144) |  Loss2: (0.0000) | Acc: (69.00%) (89/128)
Epoch: 14 | Batch_idx: 10 |  Loss: (0.8316) |  Loss2: (0.0000) | Acc: (70.00%) (999/1408)
Epoch: 14 | Batch_idx: 20 |  Loss: (0.8581) |  Loss2: (0.0000) | Acc: (69.00%) (1858/2688)
Epoch: 14 | Batch_idx: 30 |  Loss: (0.8383) |  Loss2: (0.0000) | Acc: (69.00%) (2772/3968)
Epoch: 14 | Batch_idx: 40 |  Loss: (0.8413) |  Loss2: (0.0000) | Acc: (70.00%) (3683/5248)
Epoch: 14 | Batch_idx: 50 |  Loss: (0.8394) |  Loss2: (0.0000) | Acc: (70.00%) (4586/6528)
Epoch: 14 | Batch_idx: 60 |  Loss: (0.8379) |  Loss2: (0.0000) | Acc: (70.00%) (5477/7808)
Epoch: 14 | Batch_idx: 70 |  Loss: (0.8518) |  Loss2: (0.0000) | Acc: (69.00%) (6328/9088)
Epoch: 14 | Batch_idx: 80 |  Loss: (0.8512) |  Loss2: (0.0000) | Acc: (69.00%) (7217/10368)
Epoch: 14 | Batch_idx: 90 |  Loss: (0.8461) |  Loss2: (0.0000) | Acc: (69.00%) (8148/11648)
Epoch: 14 | Batch_idx: 100 |  Loss: (0.8406) |  Loss2: (0.0000) | Acc: (70.00%) (9082/12928)
Epoch: 14 | Batch_idx: 110 |  Loss: (0.8423) |  Loss2: (0.0000) | Acc: (70.00%) (9970/14208)
Epoch: 14 | Batch_idx: 120 |  Loss: (0.8415) |  Loss2: (0.0000) | Acc: (70.00%) (10876/15488)
Epoch: 14 | Batch_idx: 130 |  Loss: (0.8427) |  Loss2: (0.0000) | Acc: (70.00%) (11767/16768)
Epoch: 14 | Batch_idx: 140 |  Loss: (0.8442) |  Loss2: (0.0000) | Acc: (70.00%) (12649/18048)
Epoch: 14 | Batch_idx: 150 |  Loss: (0.8449) |  Loss2: (0.0000) | Acc: (70.00%) (13540/19328)
Epoch: 14 | Batch_idx: 160 |  Loss: (0.8473) |  Loss2: (0.0000) | Acc: (69.00%) (14410/20608)
Epoch: 14 | Batch_idx: 170 |  Loss: (0.8465) |  Loss2: (0.0000) | Acc: (69.00%) (15313/21888)
Epoch: 14 | Batch_idx: 180 |  Loss: (0.8476) |  Loss2: (0.0000) | Acc: (69.00%) (16194/23168)
Epoch: 14 | Batch_idx: 190 |  Loss: (0.8467) |  Loss2: (0.0000) | Acc: (69.00%) (17094/24448)
Epoch: 14 | Batch_idx: 200 |  Loss: (0.8469) |  Loss2: (0.0000) | Acc: (69.00%) (17974/25728)
Epoch: 14 | Batch_idx: 210 |  Loss: (0.8450) |  Loss2: (0.0000) | Acc: (69.00%) (18886/27008)
Epoch: 14 | Batch_idx: 220 |  Loss: (0.8427) |  Loss2: (0.0000) | Acc: (70.00%) (19807/28288)
Epoch: 14 | Batch_idx: 230 |  Loss: (0.8423) |  Loss2: (0.0000) | Acc: (70.00%) (20722/29568)
Epoch: 14 | Batch_idx: 240 |  Loss: (0.8425) |  Loss2: (0.0000) | Acc: (70.00%) (21621/30848)
Epoch: 14 | Batch_idx: 250 |  Loss: (0.8445) |  Loss2: (0.0000) | Acc: (70.00%) (22496/32128)
Epoch: 14 | Batch_idx: 260 |  Loss: (0.8454) |  Loss2: (0.0000) | Acc: (69.00%) (23384/33408)
Epoch: 14 | Batch_idx: 270 |  Loss: (0.8470) |  Loss2: (0.0000) | Acc: (69.00%) (24250/34688)
Epoch: 14 | Batch_idx: 280 |  Loss: (0.8477) |  Loss2: (0.0000) | Acc: (69.00%) (25136/35968)
Epoch: 14 | Batch_idx: 290 |  Loss: (0.8468) |  Loss2: (0.0000) | Acc: (69.00%) (26034/37248)
Epoch: 14 | Batch_idx: 300 |  Loss: (0.8453) |  Loss2: (0.0000) | Acc: (69.00%) (26945/38528)
Epoch: 14 | Batch_idx: 310 |  Loss: (0.8444) |  Loss2: (0.0000) | Acc: (70.00%) (27873/39808)
Epoch: 14 | Batch_idx: 320 |  Loss: (0.8440) |  Loss2: (0.0000) | Acc: (70.00%) (28777/41088)
Epoch: 14 | Batch_idx: 330 |  Loss: (0.8437) |  Loss2: (0.0000) | Acc: (70.00%) (29678/42368)
Epoch: 14 | Batch_idx: 340 |  Loss: (0.8443) |  Loss2: (0.0000) | Acc: (70.00%) (30561/43648)
Epoch: 14 | Batch_idx: 350 |  Loss: (0.8430) |  Loss2: (0.0000) | Acc: (70.00%) (31477/44928)
Epoch: 14 | Batch_idx: 360 |  Loss: (0.8422) |  Loss2: (0.0000) | Acc: (70.00%) (32399/46208)
Epoch: 14 | Batch_idx: 370 |  Loss: (0.8414) |  Loss2: (0.0000) | Acc: (70.00%) (33311/47488)
Epoch: 14 | Batch_idx: 380 |  Loss: (0.8400) |  Loss2: (0.0000) | Acc: (70.00%) (34256/48768)
Epoch: 14 | Batch_idx: 390 |  Loss: (0.8401) |  Loss2: (0.0000) | Acc: (70.00%) (35124/50000)
# TEST : Loss: (0.8744) | Acc: (69.00%) (6901/10000)
percent tensor([0.5102, 0.5056, 0.5074, 0.5028, 0.5082, 0.5125, 0.5083, 0.5061, 0.5090,
        0.5067, 0.5089, 0.5075, 0.5075, 0.5034, 0.5085, 0.5072],
       device='cuda:0') torch.Size([16])
percent tensor([0.5025, 0.5070, 0.4882, 0.4929, 0.4915, 0.5034, 0.5014, 0.4938, 0.5019,
        0.4991, 0.5046, 0.4900, 0.5029, 0.5102, 0.5028, 0.5015],
       device='cuda:0') torch.Size([16])
percent tensor([0.4676, 0.4761, 0.4790, 0.4640, 0.4751, 0.4450, 0.4801, 0.4723, 0.4765,
        0.4815, 0.4777, 0.4839, 0.4796, 0.4679, 0.4651, 0.4680],
       device='cuda:0') torch.Size([16])
percent tensor([0.5159, 0.5160, 0.5301, 0.5260, 0.5333, 0.5245, 0.5239, 0.5321, 0.5196,
        0.5194, 0.5141, 0.5258, 0.5124, 0.5130, 0.5215, 0.5198],
       device='cuda:0') torch.Size([16])
percent tensor([0.5147, 0.5062, 0.5201, 0.5213, 0.5239, 0.5233, 0.5127, 0.5230, 0.5151,
        0.5106, 0.5128, 0.5159, 0.5071, 0.5118, 0.5188, 0.5124],
       device='cuda:0') torch.Size([16])
percent tensor([0.4606, 0.4592, 0.4911, 0.4957, 0.4928, 0.4635, 0.4722, 0.4691, 0.4710,
        0.4619, 0.4638, 0.4709, 0.4505, 0.4777, 0.4361, 0.4595],
       device='cuda:0') torch.Size([16])
percent tensor([0.5433, 0.5230, 0.5445, 0.5523, 0.5391, 0.5537, 0.5348, 0.5249, 0.5202,
        0.5328, 0.5334, 0.5337, 0.5255, 0.5291, 0.5175, 0.5483],
       device='cuda:0') torch.Size([16])
percent tensor([0.9039, 0.7929, 0.8640, 0.8673, 0.8566, 0.8877, 0.8696, 0.9009, 0.7816,
        0.8278, 0.8008, 0.8405, 0.7921, 0.8165, 0.8610, 0.9111],
       device='cuda:0') torch.Size([16])
False Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=128, out_features=16, bias=False)
True Linear(in_features=16, out_features=2, bias=False)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=128, out_features=16, bias=False)
True Linear(in_features=16, out_features=2, bias=False)
False Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=256, out_features=32, bias=False)
True Linear(in_features=32, out_features=2, bias=False)
False Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=256, out_features=32, bias=False)
True Linear(in_features=32, out_features=2, bias=False)
False Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=512, out_features=64, bias=False)
True Linear(in_features=64, out_features=2, bias=False)
False Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=512, out_features=64, bias=False)
True Linear(in_features=64, out_features=2, bias=False)
False Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1024, out_features=128, bias=False)
True Linear(in_features=128, out_features=2, bias=False)
False Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1024, out_features=128, bias=False)
True Linear(in_features=128, out_features=2, bias=False)
False Linear(in_features=512, out_features=10, bias=True)
Epoch: 15 | Batch_idx: 0 |  Loss: (0.9633) |  Loss2: (0.0000) | Acc: (60.00%) (77/128)
Epoch: 15 | Batch_idx: 10 |  Loss: (0.9380) |  Loss2: (0.0000) | Acc: (65.00%) (921/1408)
Epoch: 15 | Batch_idx: 20 |  Loss: (0.9737) |  Loss2: (0.0000) | Acc: (64.00%) (1735/2688)
Epoch: 15 | Batch_idx: 30 |  Loss: (1.0095) |  Loss2: (0.0000) | Acc: (63.00%) (2510/3968)
Epoch: 15 | Batch_idx: 40 |  Loss: (1.0325) |  Loss2: (0.0000) | Acc: (62.00%) (3264/5248)
Epoch: 15 | Batch_idx: 50 |  Loss: (1.0368) |  Loss2: (0.0000) | Acc: (61.00%) (4042/6528)
Epoch: 15 | Batch_idx: 60 |  Loss: (1.0451) |  Loss2: (0.0000) | Acc: (61.00%) (4824/7808)
Epoch: 15 | Batch_idx: 70 |  Loss: (1.0438) |  Loss2: (0.0000) | Acc: (61.00%) (5614/9088)
Epoch: 15 | Batch_idx: 80 |  Loss: (1.0377) |  Loss2: (0.0000) | Acc: (61.00%) (6427/10368)
Epoch: 15 | Batch_idx: 90 |  Loss: (1.0314) |  Loss2: (0.0000) | Acc: (62.00%) (7245/11648)
Epoch: 15 | Batch_idx: 100 |  Loss: (1.0285) |  Loss2: (0.0000) | Acc: (62.00%) (8069/12928)
Epoch: 15 | Batch_idx: 110 |  Loss: (1.0224) |  Loss2: (0.0000) | Acc: (62.00%) (8908/14208)
Epoch: 15 | Batch_idx: 120 |  Loss: (1.0217) |  Loss2: (0.0000) | Acc: (62.00%) (9706/15488)
Epoch: 15 | Batch_idx: 130 |  Loss: (1.0203) |  Loss2: (0.0000) | Acc: (62.00%) (10511/16768)
Epoch: 15 | Batch_idx: 140 |  Loss: (1.0184) |  Loss2: (0.0000) | Acc: (62.00%) (11340/18048)
Epoch: 15 | Batch_idx: 150 |  Loss: (1.0159) |  Loss2: (0.0000) | Acc: (63.00%) (12183/19328)
Epoch: 15 | Batch_idx: 160 |  Loss: (1.0154) |  Loss2: (0.0000) | Acc: (63.00%) (12996/20608)
Epoch: 15 | Batch_idx: 170 |  Loss: (1.0115) |  Loss2: (0.0000) | Acc: (63.00%) (13840/21888)
Epoch: 15 | Batch_idx: 180 |  Loss: (1.0072) |  Loss2: (0.0000) | Acc: (63.00%) (14665/23168)
Epoch: 15 | Batch_idx: 190 |  Loss: (1.0035) |  Loss2: (0.0000) | Acc: (63.00%) (15516/24448)
Epoch: 15 | Batch_idx: 200 |  Loss: (0.9994) |  Loss2: (0.0000) | Acc: (63.00%) (16358/25728)
Epoch: 15 | Batch_idx: 210 |  Loss: (0.9943) |  Loss2: (0.0000) | Acc: (63.00%) (17222/27008)
Epoch: 15 | Batch_idx: 220 |  Loss: (0.9911) |  Loss2: (0.0000) | Acc: (63.00%) (18086/28288)
Epoch: 15 | Batch_idx: 230 |  Loss: (0.9879) |  Loss2: (0.0000) | Acc: (64.00%) (18946/29568)
Epoch: 15 | Batch_idx: 240 |  Loss: (0.9858) |  Loss2: (0.0000) | Acc: (64.00%) (19800/30848)
Epoch: 15 | Batch_idx: 250 |  Loss: (0.9835) |  Loss2: (0.0000) | Acc: (64.00%) (20640/32128)
Epoch: 15 | Batch_idx: 260 |  Loss: (0.9808) |  Loss2: (0.0000) | Acc: (64.00%) (21492/33408)
Epoch: 15 | Batch_idx: 270 |  Loss: (0.9777) |  Loss2: (0.0000) | Acc: (64.00%) (22372/34688)
Epoch: 15 | Batch_idx: 280 |  Loss: (0.9728) |  Loss2: (0.0000) | Acc: (64.00%) (23260/35968)
Epoch: 15 | Batch_idx: 290 |  Loss: (0.9698) |  Loss2: (0.0000) | Acc: (64.00%) (24136/37248)
Epoch: 15 | Batch_idx: 300 |  Loss: (0.9674) |  Loss2: (0.0000) | Acc: (64.00%) (25001/38528)
Epoch: 15 | Batch_idx: 310 |  Loss: (0.9656) |  Loss2: (0.0000) | Acc: (64.00%) (25865/39808)
Epoch: 15 | Batch_idx: 320 |  Loss: (0.9630) |  Loss2: (0.0000) | Acc: (65.00%) (26747/41088)
Epoch: 15 | Batch_idx: 330 |  Loss: (0.9605) |  Loss2: (0.0000) | Acc: (65.00%) (27614/42368)
Epoch: 15 | Batch_idx: 340 |  Loss: (0.9574) |  Loss2: (0.0000) | Acc: (65.00%) (28494/43648)
Epoch: 15 | Batch_idx: 350 |  Loss: (0.9562) |  Loss2: (0.0000) | Acc: (65.00%) (29359/44928)
Epoch: 15 | Batch_idx: 360 |  Loss: (0.9552) |  Loss2: (0.0000) | Acc: (65.00%) (30205/46208)
Epoch: 15 | Batch_idx: 370 |  Loss: (0.9522) |  Loss2: (0.0000) | Acc: (65.00%) (31092/47488)
Epoch: 15 | Batch_idx: 380 |  Loss: (0.9491) |  Loss2: (0.0000) | Acc: (65.00%) (31997/48768)
Epoch: 15 | Batch_idx: 390 |  Loss: (0.9474) |  Loss2: (0.0000) | Acc: (65.00%) (32831/50000)
=> saving checkpoint 'drive/app/torch/save_Routing_Gate_2/checkpoint_015.pth.tar'
# TEST : Loss: (0.8797) | Acc: (68.00%) (6862/10000)
percent tensor([0.5016, 0.4974, 0.4948, 0.4970, 0.4960, 0.5037, 0.4975, 0.4971, 0.4994,
        0.4965, 0.5006, 0.4947, 0.4994, 0.4972, 0.5000, 0.5002],
       device='cuda:0') torch.Size([16])
percent tensor([0.5104, 0.5209, 0.4954, 0.5011, 0.5009, 0.5126, 0.5142, 0.5043, 0.5113,
        0.5109, 0.5152, 0.4993, 0.5116, 0.5244, 0.5134, 0.5109],
       device='cuda:0') torch.Size([16])
percent tensor([0.4433, 0.4535, 0.4758, 0.4445, 0.4688, 0.4097, 0.4659, 0.4601, 0.4577,
        0.4677, 0.4576, 0.4804, 0.4593, 0.4359, 0.4426, 0.4439],
       device='cuda:0') torch.Size([16])
percent tensor([0.5401, 0.5450, 0.5448, 0.5418, 0.5499, 0.5476, 0.5480, 0.5505, 0.5433,
        0.5476, 0.5442, 0.5440, 0.5390, 0.5426, 0.5457, 0.5455],
       device='cuda:0') torch.Size([16])
percent tensor([0.5430, 0.5478, 0.5128, 0.5134, 0.5131, 0.5518, 0.5324, 0.5099, 0.5484,
        0.5451, 0.5606, 0.5232, 0.5498, 0.5685, 0.5381, 0.5387],
       device='cuda:0') torch.Size([16])
percent tensor([0.4556, 0.4687, 0.4489, 0.4544, 0.4526, 0.4806, 0.4596, 0.4200, 0.4690,
        0.4606, 0.4660, 0.4305, 0.4612, 0.4949, 0.4109, 0.4515],
       device='cuda:0') torch.Size([16])
percent tensor([0.5701, 0.5361, 0.5983, 0.6030, 0.5908, 0.5872, 0.5621, 0.5931, 0.5394,
        0.5567, 0.5492, 0.5809, 0.5360, 0.5381, 0.5606, 0.5828],
       device='cuda:0') torch.Size([16])
percent tensor([0.9255, 0.8358, 0.9007, 0.9103, 0.9078, 0.9167, 0.9060, 0.9349, 0.8262,
        0.8764, 0.8491, 0.8949, 0.8132, 0.8405, 0.8839, 0.9351],
       device='cuda:0') torch.Size([16])
Epoch: 16 | Batch_idx: 0 |  Loss: (0.8749) |  Loss2: (0.0000) | Acc: (67.00%) (86/128)
Epoch: 16 | Batch_idx: 10 |  Loss: (0.8354) |  Loss2: (0.0000) | Acc: (70.00%) (986/1408)
Epoch: 16 | Batch_idx: 20 |  Loss: (0.8714) |  Loss2: (0.0000) | Acc: (68.00%) (1845/2688)
Epoch: 16 | Batch_idx: 30 |  Loss: (0.8627) |  Loss2: (0.0000) | Acc: (68.00%) (2727/3968)
Epoch: 16 | Batch_idx: 40 |  Loss: (0.8608) |  Loss2: (0.0000) | Acc: (68.00%) (3611/5248)
Epoch: 16 | Batch_idx: 50 |  Loss: (0.8618) |  Loss2: (0.0000) | Acc: (69.00%) (4505/6528)
Epoch: 16 | Batch_idx: 60 |  Loss: (0.8686) |  Loss2: (0.0000) | Acc: (68.00%) (5364/7808)
Epoch: 16 | Batch_idx: 70 |  Loss: (0.8686) |  Loss2: (0.0000) | Acc: (68.00%) (6257/9088)
Epoch: 16 | Batch_idx: 80 |  Loss: (0.8719) |  Loss2: (0.0000) | Acc: (68.00%) (7130/10368)
Epoch: 16 | Batch_idx: 90 |  Loss: (0.8730) |  Loss2: (0.0000) | Acc: (68.00%) (8005/11648)
Epoch: 16 | Batch_idx: 100 |  Loss: (0.8746) |  Loss2: (0.0000) | Acc: (68.00%) (8875/12928)
Epoch: 16 | Batch_idx: 110 |  Loss: (0.8711) |  Loss2: (0.0000) | Acc: (68.00%) (9774/14208)
Epoch: 16 | Batch_idx: 120 |  Loss: (0.8708) |  Loss2: (0.0000) | Acc: (68.00%) (10661/15488)
Epoch: 16 | Batch_idx: 130 |  Loss: (0.8669) |  Loss2: (0.0000) | Acc: (68.00%) (11565/16768)
Epoch: 16 | Batch_idx: 140 |  Loss: (0.8663) |  Loss2: (0.0000) | Acc: (68.00%) (12449/18048)
Epoch: 16 | Batch_idx: 150 |  Loss: (0.8673) |  Loss2: (0.0000) | Acc: (68.00%) (13314/19328)
Epoch: 16 | Batch_idx: 160 |  Loss: (0.8661) |  Loss2: (0.0000) | Acc: (68.00%) (14201/20608)
Epoch: 16 | Batch_idx: 170 |  Loss: (0.8629) |  Loss2: (0.0000) | Acc: (68.00%) (15099/21888)
Epoch: 16 | Batch_idx: 180 |  Loss: (0.8625) |  Loss2: (0.0000) | Acc: (69.00%) (16003/23168)
Epoch: 16 | Batch_idx: 190 |  Loss: (0.8603) |  Loss2: (0.0000) | Acc: (69.00%) (16922/24448)
Epoch: 16 | Batch_idx: 200 |  Loss: (0.8577) |  Loss2: (0.0000) | Acc: (69.00%) (17829/25728)
Epoch: 16 | Batch_idx: 210 |  Loss: (0.8565) |  Loss2: (0.0000) | Acc: (69.00%) (18719/27008)
Epoch: 16 | Batch_idx: 220 |  Loss: (0.8567) |  Loss2: (0.0000) | Acc: (69.00%) (19594/28288)
Epoch: 16 | Batch_idx: 230 |  Loss: (0.8564) |  Loss2: (0.0000) | Acc: (69.00%) (20479/29568)
Epoch: 16 | Batch_idx: 240 |  Loss: (0.8542) |  Loss2: (0.0000) | Acc: (69.00%) (21401/30848)
Epoch: 16 | Batch_idx: 250 |  Loss: (0.8532) |  Loss2: (0.0000) | Acc: (69.00%) (22296/32128)
Epoch: 16 | Batch_idx: 260 |  Loss: (0.8525) |  Loss2: (0.0000) | Acc: (69.00%) (23202/33408)
Epoch: 16 | Batch_idx: 270 |  Loss: (0.8524) |  Loss2: (0.0000) | Acc: (69.00%) (24079/34688)
Epoch: 16 | Batch_idx: 280 |  Loss: (0.8515) |  Loss2: (0.0000) | Acc: (69.00%) (24972/35968)
Epoch: 16 | Batch_idx: 290 |  Loss: (0.8498) |  Loss2: (0.0000) | Acc: (69.00%) (25897/37248)
Epoch: 16 | Batch_idx: 300 |  Loss: (0.8501) |  Loss2: (0.0000) | Acc: (69.00%) (26783/38528)
Epoch: 16 | Batch_idx: 310 |  Loss: (0.8491) |  Loss2: (0.0000) | Acc: (69.00%) (27697/39808)
Epoch: 16 | Batch_idx: 320 |  Loss: (0.8490) |  Loss2: (0.0000) | Acc: (69.00%) (28597/41088)
Epoch: 16 | Batch_idx: 330 |  Loss: (0.8488) |  Loss2: (0.0000) | Acc: (69.00%) (29509/42368)
Epoch: 16 | Batch_idx: 340 |  Loss: (0.8483) |  Loss2: (0.0000) | Acc: (69.00%) (30405/43648)
Epoch: 16 | Batch_idx: 350 |  Loss: (0.8483) |  Loss2: (0.0000) | Acc: (69.00%) (31288/44928)
Epoch: 16 | Batch_idx: 360 |  Loss: (0.8482) |  Loss2: (0.0000) | Acc: (69.00%) (32173/46208)
Epoch: 16 | Batch_idx: 370 |  Loss: (0.8456) |  Loss2: (0.0000) | Acc: (69.00%) (33117/47488)
Epoch: 16 | Batch_idx: 380 |  Loss: (0.8444) |  Loss2: (0.0000) | Acc: (69.00%) (34044/48768)
Epoch: 16 | Batch_idx: 390 |  Loss: (0.8439) |  Loss2: (0.0000) | Acc: (69.00%) (34914/50000)
# TEST : Loss: (0.8418) | Acc: (69.00%) (6994/10000)
percent tensor([0.5017, 0.4980, 0.4956, 0.4979, 0.4968, 0.5041, 0.4981, 0.4976, 0.5001,
        0.4968, 0.5010, 0.4953, 0.4996, 0.4987, 0.5003, 0.5007],
       device='cuda:0') torch.Size([16])
percent tensor([0.5122, 0.5235, 0.4981, 0.5031, 0.5036, 0.5147, 0.5168, 0.5064, 0.5133,
        0.5134, 0.5175, 0.5019, 0.5137, 0.5267, 0.5158, 0.5128],
       device='cuda:0') torch.Size([16])
percent tensor([0.4560, 0.4631, 0.4887, 0.4540, 0.4826, 0.4229, 0.4782, 0.4720, 0.4687,
        0.4788, 0.4697, 0.4943, 0.4705, 0.4399, 0.4580, 0.4538],
       device='cuda:0') torch.Size([16])
percent tensor([0.5531, 0.5594, 0.5538, 0.5503, 0.5586, 0.5593, 0.5597, 0.5593, 0.5565,
        0.5620, 0.5606, 0.5540, 0.5534, 0.5584, 0.5572, 0.5580],
       device='cuda:0') torch.Size([16])
percent tensor([0.5608, 0.5721, 0.5175, 0.5152, 0.5132, 0.5712, 0.5451, 0.5078, 0.5713,
        0.5670, 0.5904, 0.5326, 0.5756, 0.6024, 0.5507, 0.5534],
       device='cuda:0') torch.Size([16])
percent tensor([0.4570, 0.4708, 0.4415, 0.4443, 0.4426, 0.4874, 0.4547, 0.4029, 0.4746,
        0.4589, 0.4721, 0.4270, 0.4698, 0.5035, 0.4032, 0.4452],
       device='cuda:0') torch.Size([16])
percent tensor([0.5903, 0.5475, 0.6322, 0.6373, 0.6238, 0.6197, 0.5808, 0.6292, 0.5532,
        0.5729, 0.5635, 0.6118, 0.5461, 0.5484, 0.5894, 0.6106],
       device='cuda:0') torch.Size([16])
percent tensor([0.9646, 0.8981, 0.9390, 0.9462, 0.9475, 0.9562, 0.9456, 0.9637, 0.8983,
        0.9289, 0.9124, 0.9373, 0.8923, 0.9087, 0.9295, 0.9701],
       device='cuda:0') torch.Size([16])
Epoch: 17 | Batch_idx: 0 |  Loss: (0.7385) |  Loss2: (0.0000) | Acc: (75.00%) (96/128)
Epoch: 17 | Batch_idx: 10 |  Loss: (0.8310) |  Loss2: (0.0000) | Acc: (69.00%) (975/1408)
Epoch: 17 | Batch_idx: 20 |  Loss: (0.8194) |  Loss2: (0.0000) | Acc: (70.00%) (1897/2688)
Epoch: 17 | Batch_idx: 30 |  Loss: (0.8133) |  Loss2: (0.0000) | Acc: (70.00%) (2812/3968)
Epoch: 17 | Batch_idx: 40 |  Loss: (0.8235) |  Loss2: (0.0000) | Acc: (70.00%) (3710/5248)
Epoch: 17 | Batch_idx: 50 |  Loss: (0.8269) |  Loss2: (0.0000) | Acc: (70.00%) (4598/6528)
Epoch: 17 | Batch_idx: 60 |  Loss: (0.8272) |  Loss2: (0.0000) | Acc: (70.00%) (5490/7808)
Epoch: 17 | Batch_idx: 70 |  Loss: (0.8289) |  Loss2: (0.0000) | Acc: (70.00%) (6385/9088)
Epoch: 17 | Batch_idx: 80 |  Loss: (0.8270) |  Loss2: (0.0000) | Acc: (70.00%) (7297/10368)
Epoch: 17 | Batch_idx: 90 |  Loss: (0.8227) |  Loss2: (0.0000) | Acc: (70.00%) (8217/11648)
Epoch: 17 | Batch_idx: 100 |  Loss: (0.8203) |  Loss2: (0.0000) | Acc: (70.00%) (9109/12928)
Epoch: 17 | Batch_idx: 110 |  Loss: (0.8202) |  Loss2: (0.0000) | Acc: (70.00%) (10026/14208)
Epoch: 17 | Batch_idx: 120 |  Loss: (0.8211) |  Loss2: (0.0000) | Acc: (70.00%) (10915/15488)
Epoch: 17 | Batch_idx: 130 |  Loss: (0.8190) |  Loss2: (0.0000) | Acc: (70.00%) (11841/16768)
Epoch: 17 | Batch_idx: 140 |  Loss: (0.8183) |  Loss2: (0.0000) | Acc: (70.00%) (12748/18048)
Epoch: 17 | Batch_idx: 150 |  Loss: (0.8186) |  Loss2: (0.0000) | Acc: (70.00%) (13662/19328)
Epoch: 17 | Batch_idx: 160 |  Loss: (0.8191) |  Loss2: (0.0000) | Acc: (70.00%) (14564/20608)
Epoch: 17 | Batch_idx: 170 |  Loss: (0.8210) |  Loss2: (0.0000) | Acc: (70.00%) (15454/21888)
Epoch: 17 | Batch_idx: 180 |  Loss: (0.8182) |  Loss2: (0.0000) | Acc: (70.00%) (16373/23168)
Epoch: 17 | Batch_idx: 190 |  Loss: (0.8195) |  Loss2: (0.0000) | Acc: (70.00%) (17269/24448)
Epoch: 17 | Batch_idx: 200 |  Loss: (0.8203) |  Loss2: (0.0000) | Acc: (70.00%) (18174/25728)
Epoch: 17 | Batch_idx: 210 |  Loss: (0.8211) |  Loss2: (0.0000) | Acc: (70.00%) (19080/27008)
Epoch: 17 | Batch_idx: 220 |  Loss: (0.8195) |  Loss2: (0.0000) | Acc: (70.00%) (20029/28288)
Epoch: 17 | Batch_idx: 230 |  Loss: (0.8194) |  Loss2: (0.0000) | Acc: (70.00%) (20933/29568)
Epoch: 17 | Batch_idx: 240 |  Loss: (0.8203) |  Loss2: (0.0000) | Acc: (70.00%) (21838/30848)
Epoch: 17 | Batch_idx: 250 |  Loss: (0.8192) |  Loss2: (0.0000) | Acc: (70.00%) (22744/32128)
Epoch: 17 | Batch_idx: 260 |  Loss: (0.8198) |  Loss2: (0.0000) | Acc: (70.00%) (23655/33408)
Epoch: 17 | Batch_idx: 270 |  Loss: (0.8207) |  Loss2: (0.0000) | Acc: (70.00%) (24553/34688)
Epoch: 17 | Batch_idx: 280 |  Loss: (0.8213) |  Loss2: (0.0000) | Acc: (70.00%) (25462/35968)
Epoch: 17 | Batch_idx: 290 |  Loss: (0.8204) |  Loss2: (0.0000) | Acc: (70.00%) (26381/37248)
Epoch: 17 | Batch_idx: 300 |  Loss: (0.8209) |  Loss2: (0.0000) | Acc: (70.00%) (27292/38528)
Epoch: 17 | Batch_idx: 310 |  Loss: (0.8189) |  Loss2: (0.0000) | Acc: (70.00%) (28234/39808)
Epoch: 17 | Batch_idx: 320 |  Loss: (0.8178) |  Loss2: (0.0000) | Acc: (70.00%) (29155/41088)
Epoch: 17 | Batch_idx: 330 |  Loss: (0.8167) |  Loss2: (0.0000) | Acc: (70.00%) (30080/42368)
Epoch: 17 | Batch_idx: 340 |  Loss: (0.8157) |  Loss2: (0.0000) | Acc: (71.00%) (31002/43648)
Epoch: 17 | Batch_idx: 350 |  Loss: (0.8167) |  Loss2: (0.0000) | Acc: (70.00%) (31888/44928)
Epoch: 17 | Batch_idx: 360 |  Loss: (0.8165) |  Loss2: (0.0000) | Acc: (70.00%) (32800/46208)
Epoch: 17 | Batch_idx: 370 |  Loss: (0.8163) |  Loss2: (0.0000) | Acc: (70.00%) (33703/47488)
Epoch: 17 | Batch_idx: 380 |  Loss: (0.8174) |  Loss2: (0.0000) | Acc: (70.00%) (34579/48768)
Epoch: 17 | Batch_idx: 390 |  Loss: (0.8195) |  Loss2: (0.0000) | Acc: (70.00%) (35424/50000)
# TEST : Loss: (0.8319) | Acc: (70.00%) (7034/10000)
percent tensor([0.5020, 0.4988, 0.4973, 0.4988, 0.4984, 0.5046, 0.4993, 0.4984, 0.5010,
        0.4978, 0.5016, 0.4969, 0.5001, 0.4999, 0.5008, 0.5013],
       device='cuda:0') torch.Size([16])
percent tensor([0.5092, 0.5198, 0.4953, 0.5002, 0.5003, 0.5115, 0.5129, 0.5028, 0.5099,
        0.5098, 0.5144, 0.4990, 0.5107, 0.5228, 0.5124, 0.5096],
       device='cuda:0') torch.Size([16])
percent tensor([0.4604, 0.4641, 0.4925, 0.4570, 0.4867, 0.4287, 0.4808, 0.4755, 0.4714,
        0.4801, 0.4721, 0.4978, 0.4730, 0.4389, 0.4630, 0.4565],
       device='cuda:0') torch.Size([16])
percent tensor([0.5584, 0.5651, 0.5585, 0.5546, 0.5626, 0.5638, 0.5644, 0.5633, 0.5622,
        0.5677, 0.5674, 0.5586, 0.5593, 0.5652, 0.5617, 0.5627],
       device='cuda:0') torch.Size([16])
percent tensor([0.5642, 0.5799, 0.5200, 0.5156, 0.5126, 0.5736, 0.5482, 0.5064, 0.5811,
        0.5749, 0.6013, 0.5363, 0.5839, 0.6165, 0.5516, 0.5540],
       device='cuda:0') torch.Size([16])
percent tensor([0.4543, 0.4704, 0.4350, 0.4358, 0.4330, 0.4855, 0.4493, 0.3911, 0.4775,
        0.4563, 0.4745, 0.4225, 0.4722, 0.5088, 0.3963, 0.4373],
       device='cuda:0') torch.Size([16])
percent tensor([0.6001, 0.5531, 0.6498, 0.6538, 0.6415, 0.6358, 0.5916, 0.6480, 0.5600,
        0.5815, 0.5702, 0.6287, 0.5501, 0.5530, 0.6069, 0.6249],
       device='cuda:0') torch.Size([16])
percent tensor([0.9754, 0.9244, 0.9582, 0.9616, 0.9660, 0.9691, 0.9590, 0.9757, 0.9294,
        0.9515, 0.9385, 0.9570, 0.9230, 0.9338, 0.9507, 0.9791],
       device='cuda:0') torch.Size([16])
Epoch: 18 | Batch_idx: 0 |  Loss: (0.8885) |  Loss2: (0.0000) | Acc: (66.00%) (85/128)
Epoch: 18 | Batch_idx: 10 |  Loss: (0.8323) |  Loss2: (0.0000) | Acc: (69.00%) (982/1408)
Epoch: 18 | Batch_idx: 20 |  Loss: (0.8192) |  Loss2: (0.0000) | Acc: (70.00%) (1896/2688)
Epoch: 18 | Batch_idx: 30 |  Loss: (0.8199) |  Loss2: (0.0000) | Acc: (70.00%) (2801/3968)
Epoch: 18 | Batch_idx: 40 |  Loss: (0.8098) |  Loss2: (0.0000) | Acc: (71.00%) (3736/5248)
Epoch: 18 | Batch_idx: 50 |  Loss: (0.8084) |  Loss2: (0.0000) | Acc: (71.00%) (4657/6528)
Epoch: 18 | Batch_idx: 60 |  Loss: (0.8018) |  Loss2: (0.0000) | Acc: (71.00%) (5604/7808)
Epoch: 18 | Batch_idx: 70 |  Loss: (0.8090) |  Loss2: (0.0000) | Acc: (71.00%) (6488/9088)
Epoch: 18 | Batch_idx: 80 |  Loss: (0.8104) |  Loss2: (0.0000) | Acc: (71.00%) (7390/10368)
Epoch: 18 | Batch_idx: 90 |  Loss: (0.8086) |  Loss2: (0.0000) | Acc: (71.00%) (8317/11648)
Epoch: 18 | Batch_idx: 100 |  Loss: (0.8082) |  Loss2: (0.0000) | Acc: (71.00%) (9222/12928)
Epoch: 18 | Batch_idx: 110 |  Loss: (0.8100) |  Loss2: (0.0000) | Acc: (71.00%) (10103/14208)
Epoch: 18 | Batch_idx: 120 |  Loss: (0.8094) |  Loss2: (0.0000) | Acc: (71.00%) (11006/15488)
Epoch: 18 | Batch_idx: 130 |  Loss: (0.8084) |  Loss2: (0.0000) | Acc: (70.00%) (11904/16768)
Epoch: 18 | Batch_idx: 140 |  Loss: (0.8087) |  Loss2: (0.0000) | Acc: (71.00%) (12816/18048)
Epoch: 18 | Batch_idx: 150 |  Loss: (0.8102) |  Loss2: (0.0000) | Acc: (70.00%) (13704/19328)
Epoch: 18 | Batch_idx: 160 |  Loss: (0.8108) |  Loss2: (0.0000) | Acc: (70.00%) (14616/20608)
Epoch: 18 | Batch_idx: 170 |  Loss: (0.8082) |  Loss2: (0.0000) | Acc: (70.00%) (15536/21888)
Epoch: 18 | Batch_idx: 180 |  Loss: (0.8084) |  Loss2: (0.0000) | Acc: (70.00%) (16436/23168)
Epoch: 18 | Batch_idx: 190 |  Loss: (0.8093) |  Loss2: (0.0000) | Acc: (70.00%) (17333/24448)
Epoch: 18 | Batch_idx: 200 |  Loss: (0.8090) |  Loss2: (0.0000) | Acc: (70.00%) (18237/25728)
Epoch: 18 | Batch_idx: 210 |  Loss: (0.8080) |  Loss2: (0.0000) | Acc: (70.00%) (19154/27008)
Epoch: 18 | Batch_idx: 220 |  Loss: (0.8079) |  Loss2: (0.0000) | Acc: (70.00%) (20057/28288)
Epoch: 18 | Batch_idx: 230 |  Loss: (0.8089) |  Loss2: (0.0000) | Acc: (70.00%) (20948/29568)
Epoch: 18 | Batch_idx: 240 |  Loss: (0.8104) |  Loss2: (0.0000) | Acc: (70.00%) (21834/30848)
Epoch: 18 | Batch_idx: 250 |  Loss: (0.8102) |  Loss2: (0.0000) | Acc: (70.00%) (22757/32128)
Epoch: 18 | Batch_idx: 260 |  Loss: (0.8106) |  Loss2: (0.0000) | Acc: (70.00%) (23660/33408)
Epoch: 18 | Batch_idx: 270 |  Loss: (0.8114) |  Loss2: (0.0000) | Acc: (70.00%) (24560/34688)
Epoch: 18 | Batch_idx: 280 |  Loss: (0.8111) |  Loss2: (0.0000) | Acc: (70.00%) (25495/35968)
Epoch: 18 | Batch_idx: 290 |  Loss: (0.8107) |  Loss2: (0.0000) | Acc: (70.00%) (26414/37248)
Epoch: 18 | Batch_idx: 300 |  Loss: (0.8099) |  Loss2: (0.0000) | Acc: (70.00%) (27329/38528)
Epoch: 18 | Batch_idx: 310 |  Loss: (0.8105) |  Loss2: (0.0000) | Acc: (70.00%) (28217/39808)
Epoch: 18 | Batch_idx: 320 |  Loss: (0.8099) |  Loss2: (0.0000) | Acc: (70.00%) (29139/41088)
Epoch: 18 | Batch_idx: 330 |  Loss: (0.8114) |  Loss2: (0.0000) | Acc: (70.00%) (30009/42368)
Epoch: 18 | Batch_idx: 340 |  Loss: (0.8128) |  Loss2: (0.0000) | Acc: (70.00%) (30895/43648)
Epoch: 18 | Batch_idx: 350 |  Loss: (0.8124) |  Loss2: (0.0000) | Acc: (70.00%) (31823/44928)
Epoch: 18 | Batch_idx: 360 |  Loss: (0.8125) |  Loss2: (0.0000) | Acc: (70.00%) (32743/46208)
Epoch: 18 | Batch_idx: 370 |  Loss: (0.8114) |  Loss2: (0.0000) | Acc: (70.00%) (33684/47488)
Epoch: 18 | Batch_idx: 380 |  Loss: (0.8117) |  Loss2: (0.0000) | Acc: (70.00%) (34589/48768)
Epoch: 18 | Batch_idx: 390 |  Loss: (0.8109) |  Loss2: (0.0000) | Acc: (70.00%) (35474/50000)
# TEST : Loss: (0.8213) | Acc: (70.00%) (7077/10000)
percent tensor([0.5015, 0.4985, 0.4984, 0.4991, 0.4991, 0.5042, 0.4993, 0.4985, 0.5009,
        0.4979, 0.5011, 0.4978, 0.4998, 0.4996, 0.5004, 0.5010],
       device='cuda:0') torch.Size([16])
percent tensor([0.5069, 0.5167, 0.4940, 0.4986, 0.4984, 0.5090, 0.5100, 0.5005, 0.5073,
        0.5073, 0.5119, 0.4975, 0.5085, 0.5194, 0.5099, 0.5071],
       device='cuda:0') torch.Size([16])
percent tensor([0.4655, 0.4658, 0.4952, 0.4583, 0.4900, 0.4338, 0.4837, 0.4778, 0.4744,
        0.4817, 0.4761, 0.5005, 0.4767, 0.4390, 0.4677, 0.4594],
       device='cuda:0') torch.Size([16])
percent tensor([0.5595, 0.5664, 0.5603, 0.5567, 0.5635, 0.5644, 0.5655, 0.5644, 0.5637,
        0.5691, 0.5695, 0.5603, 0.5609, 0.5673, 0.5625, 0.5636],
       device='cuda:0') torch.Size([16])
percent tensor([0.5657, 0.5819, 0.5247, 0.5193, 0.5157, 0.5748, 0.5503, 0.5088, 0.5862,
        0.5779, 0.6058, 0.5410, 0.5867, 0.6220, 0.5532, 0.5533],
       device='cuda:0') torch.Size([16])
percent tensor([0.4618, 0.4804, 0.4436, 0.4458, 0.4417, 0.4915, 0.4583, 0.3996, 0.4894,
        0.4659, 0.4853, 0.4320, 0.4821, 0.5209, 0.4046, 0.4451],
       device='cuda:0') torch.Size([16])
percent tensor([0.6018, 0.5518, 0.6514, 0.6538, 0.6402, 0.6440, 0.5910, 0.6466, 0.5571,
        0.5772, 0.5688, 0.6291, 0.5482, 0.5533, 0.6086, 0.6276],
       device='cuda:0') torch.Size([16])
percent tensor([0.9816, 0.9383, 0.9659, 0.9682, 0.9717, 0.9765, 0.9680, 0.9807, 0.9422,
        0.9608, 0.9514, 0.9645, 0.9387, 0.9483, 0.9600, 0.9844],
       device='cuda:0') torch.Size([16])
Epoch: 19 | Batch_idx: 0 |  Loss: (0.6306) |  Loss2: (0.0000) | Acc: (79.00%) (102/128)
Epoch: 19 | Batch_idx: 10 |  Loss: (0.8197) |  Loss2: (0.0000) | Acc: (70.00%) (989/1408)
Epoch: 19 | Batch_idx: 20 |  Loss: (0.8045) |  Loss2: (0.0000) | Acc: (71.00%) (1918/2688)
Epoch: 19 | Batch_idx: 30 |  Loss: (0.8024) |  Loss2: (0.0000) | Acc: (71.00%) (2822/3968)
Epoch: 19 | Batch_idx: 40 |  Loss: (0.7942) |  Loss2: (0.0000) | Acc: (71.00%) (3769/5248)
Epoch: 19 | Batch_idx: 50 |  Loss: (0.7909) |  Loss2: (0.0000) | Acc: (71.00%) (4696/6528)
Epoch: 19 | Batch_idx: 60 |  Loss: (0.7817) |  Loss2: (0.0000) | Acc: (72.00%) (5650/7808)
Epoch: 19 | Batch_idx: 70 |  Loss: (0.7789) |  Loss2: (0.0000) | Acc: (72.00%) (6560/9088)
Epoch: 19 | Batch_idx: 80 |  Loss: (0.7883) |  Loss2: (0.0000) | Acc: (71.00%) (7456/10368)
Epoch: 19 | Batch_idx: 90 |  Loss: (0.7861) |  Loss2: (0.0000) | Acc: (71.00%) (8382/11648)
Epoch: 19 | Batch_idx: 100 |  Loss: (0.7890) |  Loss2: (0.0000) | Acc: (72.00%) (9309/12928)
Epoch: 19 | Batch_idx: 110 |  Loss: (0.7929) |  Loss2: (0.0000) | Acc: (71.00%) (10193/14208)
Epoch: 19 | Batch_idx: 120 |  Loss: (0.7967) |  Loss2: (0.0000) | Acc: (71.00%) (11089/15488)
Epoch: 19 | Batch_idx: 130 |  Loss: (0.7947) |  Loss2: (0.0000) | Acc: (71.00%) (12020/16768)
Epoch: 19 | Batch_idx: 140 |  Loss: (0.7928) |  Loss2: (0.0000) | Acc: (71.00%) (12944/18048)
Epoch: 19 | Batch_idx: 150 |  Loss: (0.7970) |  Loss2: (0.0000) | Acc: (71.00%) (13818/19328)
Epoch: 19 | Batch_idx: 160 |  Loss: (0.7987) |  Loss2: (0.0000) | Acc: (71.00%) (14702/20608)
Epoch: 19 | Batch_idx: 170 |  Loss: (0.7987) |  Loss2: (0.0000) | Acc: (71.00%) (15610/21888)
Epoch: 19 | Batch_idx: 180 |  Loss: (0.7981) |  Loss2: (0.0000) | Acc: (71.00%) (16538/23168)
Epoch: 19 | Batch_idx: 190 |  Loss: (0.7972) |  Loss2: (0.0000) | Acc: (71.00%) (17462/24448)
Epoch: 19 | Batch_idx: 200 |  Loss: (0.8002) |  Loss2: (0.0000) | Acc: (71.00%) (18338/25728)
Epoch: 19 | Batch_idx: 210 |  Loss: (0.8017) |  Loss2: (0.0000) | Acc: (71.00%) (19245/27008)
Epoch: 19 | Batch_idx: 220 |  Loss: (0.8011) |  Loss2: (0.0000) | Acc: (71.00%) (20173/28288)
Epoch: 19 | Batch_idx: 230 |  Loss: (0.8009) |  Loss2: (0.0000) | Acc: (71.00%) (21092/29568)
Epoch: 19 | Batch_idx: 240 |  Loss: (0.8001) |  Loss2: (0.0000) | Acc: (71.00%) (22016/30848)
Epoch: 19 | Batch_idx: 250 |  Loss: (0.8006) |  Loss2: (0.0000) | Acc: (71.00%) (22926/32128)
Epoch: 19 | Batch_idx: 260 |  Loss: (0.8027) |  Loss2: (0.0000) | Acc: (71.00%) (23818/33408)
Epoch: 19 | Batch_idx: 270 |  Loss: (0.8023) |  Loss2: (0.0000) | Acc: (71.00%) (24733/34688)
Epoch: 19 | Batch_idx: 280 |  Loss: (0.8016) |  Loss2: (0.0000) | Acc: (71.00%) (25654/35968)
Epoch: 19 | Batch_idx: 290 |  Loss: (0.8009) |  Loss2: (0.0000) | Acc: (71.00%) (26587/37248)
Epoch: 19 | Batch_idx: 300 |  Loss: (0.8015) |  Loss2: (0.0000) | Acc: (71.00%) (27485/38528)
Epoch: 19 | Batch_idx: 310 |  Loss: (0.8013) |  Loss2: (0.0000) | Acc: (71.00%) (28401/39808)
Epoch: 19 | Batch_idx: 320 |  Loss: (0.8017) |  Loss2: (0.0000) | Acc: (71.00%) (29292/41088)
Epoch: 19 | Batch_idx: 330 |  Loss: (0.8014) |  Loss2: (0.0000) | Acc: (71.00%) (30217/42368)
Epoch: 19 | Batch_idx: 340 |  Loss: (0.8028) |  Loss2: (0.0000) | Acc: (71.00%) (31110/43648)
Epoch: 19 | Batch_idx: 350 |  Loss: (0.8016) |  Loss2: (0.0000) | Acc: (71.00%) (32048/44928)
Epoch: 19 | Batch_idx: 360 |  Loss: (0.8025) |  Loss2: (0.0000) | Acc: (71.00%) (32955/46208)
Epoch: 19 | Batch_idx: 370 |  Loss: (0.8023) |  Loss2: (0.0000) | Acc: (71.00%) (33882/47488)
Epoch: 19 | Batch_idx: 380 |  Loss: (0.8022) |  Loss2: (0.0000) | Acc: (71.00%) (34807/48768)
Epoch: 19 | Batch_idx: 390 |  Loss: (0.8020) |  Loss2: (0.0000) | Acc: (71.00%) (35703/50000)
# TEST : Loss: (0.8174) | Acc: (70.00%) (7089/10000)
percent tensor([0.5026, 0.4997, 0.5003, 0.5003, 0.5009, 0.5055, 0.5008, 0.4997, 0.5022,
        0.4993, 0.5023, 0.4996, 0.5009, 0.5008, 0.5016, 0.5021],
       device='cuda:0') torch.Size([16])
percent tensor([0.5048, 0.5139, 0.4919, 0.4965, 0.4959, 0.5070, 0.5072, 0.4977, 0.5049,
        0.5047, 0.5097, 0.4953, 0.5064, 0.5165, 0.5076, 0.5049],
       device='cuda:0') torch.Size([16])
percent tensor([0.4666, 0.4653, 0.4960, 0.4575, 0.4907, 0.4343, 0.4842, 0.4785, 0.4752,
        0.4813, 0.4765, 0.5011, 0.4772, 0.4379, 0.4684, 0.4589],
       device='cuda:0') torch.Size([16])
percent tensor([0.5613, 0.5679, 0.5626, 0.5590, 0.5652, 0.5658, 0.5668, 0.5662, 0.5653,
        0.5705, 0.5715, 0.5624, 0.5626, 0.5688, 0.5644, 0.5649],
       device='cuda:0') torch.Size([16])
percent tensor([0.5685, 0.5845, 0.5293, 0.5233, 0.5196, 0.5775, 0.5525, 0.5123, 0.5899,
        0.5814, 0.6101, 0.5454, 0.5901, 0.6253, 0.5564, 0.5544],
       device='cuda:0') torch.Size([16])
percent tensor([0.4603, 0.4807, 0.4457, 0.4474, 0.4413, 0.4883, 0.4576, 0.3986, 0.4935,
        0.4659, 0.4875, 0.4352, 0.4827, 0.5244, 0.4030, 0.4417],
       device='cuda:0') torch.Size([16])
percent tensor([0.6010, 0.5483, 0.6594, 0.6614, 0.6485, 0.6503, 0.5920, 0.6547, 0.5548,
        0.5742, 0.5646, 0.6343, 0.5412, 0.5501, 0.6142, 0.6301],
       device='cuda:0') torch.Size([16])
percent tensor([0.9855, 0.9500, 0.9730, 0.9742, 0.9780, 0.9812, 0.9740, 0.9853, 0.9536,
        0.9691, 0.9618, 0.9716, 0.9505, 0.9592, 0.9684, 0.9878],
       device='cuda:0') torch.Size([16])
True Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=128, out_features=16, bias=False)
False Linear(in_features=16, out_features=2, bias=False)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=128, out_features=16, bias=False)
False Linear(in_features=16, out_features=2, bias=False)
True Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=256, out_features=32, bias=False)
False Linear(in_features=32, out_features=2, bias=False)
True Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=256, out_features=32, bias=False)
False Linear(in_features=32, out_features=2, bias=False)
True Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=512, out_features=64, bias=False)
False Linear(in_features=64, out_features=2, bias=False)
True Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=512, out_features=64, bias=False)
False Linear(in_features=64, out_features=2, bias=False)
True Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1024, out_features=128, bias=False)
False Linear(in_features=128, out_features=2, bias=False)
True Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1024, out_features=128, bias=False)
False Linear(in_features=128, out_features=2, bias=False)
True Linear(in_features=512, out_features=10, bias=True)
Epoch: 20 | Batch_idx: 0 |  Loss: (0.8735) |  Loss2: (0.0000) | Acc: (68.00%) (88/128)
Epoch: 20 | Batch_idx: 10 |  Loss: (0.7971) |  Loss2: (0.0000) | Acc: (71.00%) (1005/1408)
Epoch: 20 | Batch_idx: 20 |  Loss: (0.8120) |  Loss2: (0.0000) | Acc: (71.00%) (1913/2688)
Epoch: 20 | Batch_idx: 30 |  Loss: (0.8162) |  Loss2: (0.0000) | Acc: (70.00%) (2803/3968)
Epoch: 20 | Batch_idx: 40 |  Loss: (0.8133) |  Loss2: (0.0000) | Acc: (70.00%) (3706/5248)
Epoch: 20 | Batch_idx: 50 |  Loss: (0.8208) |  Loss2: (0.0000) | Acc: (70.00%) (4609/6528)
Epoch: 20 | Batch_idx: 60 |  Loss: (0.8167) |  Loss2: (0.0000) | Acc: (70.00%) (5515/7808)
Epoch: 20 | Batch_idx: 70 |  Loss: (0.8147) |  Loss2: (0.0000) | Acc: (70.00%) (6435/9088)
Epoch: 20 | Batch_idx: 80 |  Loss: (0.8122) |  Loss2: (0.0000) | Acc: (70.00%) (7361/10368)
Epoch: 20 | Batch_idx: 90 |  Loss: (0.8127) |  Loss2: (0.0000) | Acc: (71.00%) (8274/11648)
Epoch: 20 | Batch_idx: 100 |  Loss: (0.8098) |  Loss2: (0.0000) | Acc: (71.00%) (9199/12928)
Epoch: 20 | Batch_idx: 110 |  Loss: (0.8090) |  Loss2: (0.0000) | Acc: (71.00%) (10118/14208)
Epoch: 20 | Batch_idx: 120 |  Loss: (0.8113) |  Loss2: (0.0000) | Acc: (71.00%) (11023/15488)
Epoch: 20 | Batch_idx: 130 |  Loss: (0.8130) |  Loss2: (0.0000) | Acc: (71.00%) (11934/16768)
Epoch: 20 | Batch_idx: 140 |  Loss: (0.8115) |  Loss2: (0.0000) | Acc: (71.00%) (12862/18048)
Epoch: 20 | Batch_idx: 150 |  Loss: (0.8124) |  Loss2: (0.0000) | Acc: (71.00%) (13766/19328)
Epoch: 20 | Batch_idx: 160 |  Loss: (0.8118) |  Loss2: (0.0000) | Acc: (71.00%) (14702/20608)
Epoch: 20 | Batch_idx: 170 |  Loss: (0.8130) |  Loss2: (0.0000) | Acc: (71.00%) (15611/21888)
Epoch: 20 | Batch_idx: 180 |  Loss: (0.8123) |  Loss2: (0.0000) | Acc: (71.00%) (16529/23168)
Epoch: 20 | Batch_idx: 190 |  Loss: (0.8103) |  Loss2: (0.0000) | Acc: (71.00%) (17451/24448)
Epoch: 20 | Batch_idx: 200 |  Loss: (0.8089) |  Loss2: (0.0000) | Acc: (71.00%) (18376/25728)
Epoch: 20 | Batch_idx: 210 |  Loss: (0.8095) |  Loss2: (0.0000) | Acc: (71.00%) (19276/27008)
Epoch: 20 | Batch_idx: 220 |  Loss: (0.8098) |  Loss2: (0.0000) | Acc: (71.00%) (20180/28288)
Epoch: 20 | Batch_idx: 230 |  Loss: (0.8079) |  Loss2: (0.0000) | Acc: (71.00%) (21107/29568)
Epoch: 20 | Batch_idx: 240 |  Loss: (0.8077) |  Loss2: (0.0000) | Acc: (71.00%) (22004/30848)
Epoch: 20 | Batch_idx: 250 |  Loss: (0.8065) |  Loss2: (0.0000) | Acc: (71.00%) (22924/32128)
Epoch: 20 | Batch_idx: 260 |  Loss: (0.8054) |  Loss2: (0.0000) | Acc: (71.00%) (23854/33408)
Epoch: 20 | Batch_idx: 270 |  Loss: (0.8065) |  Loss2: (0.0000) | Acc: (71.00%) (24767/34688)
Epoch: 20 | Batch_idx: 280 |  Loss: (0.8063) |  Loss2: (0.0000) | Acc: (71.00%) (25678/35968)
Epoch: 20 | Batch_idx: 290 |  Loss: (0.8054) |  Loss2: (0.0000) | Acc: (71.00%) (26614/37248)
Epoch: 20 | Batch_idx: 300 |  Loss: (0.8040) |  Loss2: (0.0000) | Acc: (71.00%) (27546/38528)
Epoch: 20 | Batch_idx: 310 |  Loss: (0.8024) |  Loss2: (0.0000) | Acc: (71.00%) (28477/39808)
Epoch: 20 | Batch_idx: 320 |  Loss: (0.8012) |  Loss2: (0.0000) | Acc: (71.00%) (29419/41088)
Epoch: 20 | Batch_idx: 330 |  Loss: (0.8013) |  Loss2: (0.0000) | Acc: (71.00%) (30328/42368)
Epoch: 20 | Batch_idx: 340 |  Loss: (0.8021) |  Loss2: (0.0000) | Acc: (71.00%) (31248/43648)
Epoch: 20 | Batch_idx: 350 |  Loss: (0.8006) |  Loss2: (0.0000) | Acc: (71.00%) (32207/44928)
Epoch: 20 | Batch_idx: 360 |  Loss: (0.7988) |  Loss2: (0.0000) | Acc: (71.00%) (33146/46208)
Epoch: 20 | Batch_idx: 370 |  Loss: (0.7981) |  Loss2: (0.0000) | Acc: (71.00%) (34066/47488)
Epoch: 20 | Batch_idx: 380 |  Loss: (0.7982) |  Loss2: (0.0000) | Acc: (71.00%) (34979/48768)
Epoch: 20 | Batch_idx: 390 |  Loss: (0.7973) |  Loss2: (0.0000) | Acc: (71.00%) (35874/50000)
=> saving checkpoint 'drive/app/torch/save_Routing_Gate_2/checkpoint_020.pth.tar'
# TEST : Loss: (0.8653) | Acc: (70.00%) (7003/10000)
percent tensor([0.5021, 0.4994, 0.5002, 0.4998, 0.5005, 0.5049, 0.5006, 0.4999, 0.5019,
        0.4996, 0.5018, 0.4998, 0.5006, 0.5007, 0.5012, 0.5019],
       device='cuda:0') torch.Size([16])
percent tensor([0.5044, 0.5128, 0.4940, 0.4965, 0.4971, 0.5061, 0.5066, 0.4977, 0.5044,
        0.5043, 0.5087, 0.4958, 0.5057, 0.5147, 0.5070, 0.5043],
       device='cuda:0') torch.Size([16])
percent tensor([0.4728, 0.4698, 0.4965, 0.4606, 0.4933, 0.4438, 0.4862, 0.4790, 0.4752,
        0.4834, 0.4756, 0.5005, 0.4810, 0.4371, 0.4724, 0.4617],
       device='cuda:0') torch.Size([16])
percent tensor([0.5618, 0.5657, 0.5694, 0.5637, 0.5689, 0.5641, 0.5683, 0.5695, 0.5667,
        0.5720, 0.5724, 0.5673, 0.5616, 0.5639, 0.5643, 0.5667],
       device='cuda:0') torch.Size([16])
percent tensor([0.5561, 0.5717, 0.5395, 0.5485, 0.5214, 0.5685, 0.5473, 0.5285, 0.5813,
        0.5744, 0.6054, 0.5484, 0.5779, 0.6074, 0.5507, 0.5546],
       device='cuda:0') torch.Size([16])
percent tensor([0.4409, 0.4634, 0.4556, 0.4603, 0.4246, 0.4738, 0.4415, 0.3991, 0.4777,
        0.4528, 0.4819, 0.4410, 0.4564, 0.5124, 0.3915, 0.4417],
       device='cuda:0') torch.Size([16])
percent tensor([0.6005, 0.5554, 0.6515, 0.6525, 0.6496, 0.6434, 0.6004, 0.6599, 0.5700,
        0.5839, 0.5751, 0.6400, 0.5548, 0.5736, 0.6204, 0.6272],
       device='cuda:0') torch.Size([16])
percent tensor([0.9867, 0.9536, 0.9759, 0.9765, 0.9808, 0.9808, 0.9812, 0.9897, 0.9500,
        0.9753, 0.9635, 0.9811, 0.9478, 0.9563, 0.9741, 0.9878],
       device='cuda:0') torch.Size([16])
Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 3, 3, 3]) tensor(167.6199, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(781.1890, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(779.2214, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([128, 64, 3, 3]) tensor(1529.5179, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([128, 64, 1, 1]) tensor(508.3474, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([128, 128, 3, 3]) tensor(2174.7554, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([256, 128, 3, 3]) tensor(4311.9438, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([256, 128, 1, 1]) tensor(1434.9490, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([256, 256, 3, 3]) tensor(6083.2915, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([512, 256, 3, 3]) tensor(12179.4883, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([512, 256, 1, 1]) tensor(4064.5898, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([512, 512, 3, 3]) tensor(17194.3965, device='cuda:0', grad_fn=<NormBackward0>)
Epoch: 21 | Batch_idx: 0 |  Loss: (0.6924) |  Loss2: (0.0000) | Acc: (79.00%) (102/128)
Epoch: 21 | Batch_idx: 10 |  Loss: (0.7703) |  Loss2: (0.0000) | Acc: (72.00%) (1024/1408)
Epoch: 21 | Batch_idx: 20 |  Loss: (0.7517) |  Loss2: (0.0000) | Acc: (73.00%) (1973/2688)
Epoch: 21 | Batch_idx: 30 |  Loss: (0.7531) |  Loss2: (0.0000) | Acc: (73.00%) (2921/3968)
Epoch: 21 | Batch_idx: 40 |  Loss: (0.7560) |  Loss2: (0.0000) | Acc: (73.00%) (3856/5248)
Epoch: 21 | Batch_idx: 50 |  Loss: (0.7597) |  Loss2: (0.0000) | Acc: (73.00%) (4797/6528)
Epoch: 21 | Batch_idx: 60 |  Loss: (0.7582) |  Loss2: (0.0000) | Acc: (73.00%) (5731/7808)
Epoch: 21 | Batch_idx: 70 |  Loss: (0.7574) |  Loss2: (0.0000) | Acc: (73.00%) (6655/9088)
Epoch: 21 | Batch_idx: 80 |  Loss: (0.7545) |  Loss2: (0.0000) | Acc: (73.00%) (7612/10368)
Epoch: 21 | Batch_idx: 90 |  Loss: (0.7500) |  Loss2: (0.0000) | Acc: (73.00%) (8569/11648)
Epoch: 21 | Batch_idx: 100 |  Loss: (0.7492) |  Loss2: (0.0000) | Acc: (73.00%) (9509/12928)
Epoch: 21 | Batch_idx: 110 |  Loss: (0.7503) |  Loss2: (0.0000) | Acc: (73.00%) (10465/14208)
Epoch: 21 | Batch_idx: 120 |  Loss: (0.7525) |  Loss2: (0.0000) | Acc: (73.00%) (11390/15488)
Epoch: 21 | Batch_idx: 130 |  Loss: (0.7494) |  Loss2: (0.0000) | Acc: (73.00%) (12345/16768)
Epoch: 21 | Batch_idx: 140 |  Loss: (0.7462) |  Loss2: (0.0000) | Acc: (73.00%) (13315/18048)
Epoch: 21 | Batch_idx: 150 |  Loss: (0.7500) |  Loss2: (0.0000) | Acc: (73.00%) (14217/19328)
Epoch: 21 | Batch_idx: 160 |  Loss: (0.7513) |  Loss2: (0.0000) | Acc: (73.00%) (15143/20608)
Epoch: 21 | Batch_idx: 170 |  Loss: (0.7526) |  Loss2: (0.0000) | Acc: (73.00%) (16057/21888)
Epoch: 21 | Batch_idx: 180 |  Loss: (0.7484) |  Loss2: (0.0000) | Acc: (73.00%) (17027/23168)
Epoch: 21 | Batch_idx: 190 |  Loss: (0.7482) |  Loss2: (0.0000) | Acc: (73.00%) (17987/24448)
Epoch: 21 | Batch_idx: 200 |  Loss: (0.7480) |  Loss2: (0.0000) | Acc: (73.00%) (18942/25728)
Epoch: 21 | Batch_idx: 210 |  Loss: (0.7481) |  Loss2: (0.0000) | Acc: (73.00%) (19870/27008)
Epoch: 21 | Batch_idx: 220 |  Loss: (0.7478) |  Loss2: (0.0000) | Acc: (73.00%) (20802/28288)
Epoch: 21 | Batch_idx: 230 |  Loss: (0.7509) |  Loss2: (0.0000) | Acc: (73.00%) (21707/29568)
Epoch: 21 | Batch_idx: 240 |  Loss: (0.7521) |  Loss2: (0.0000) | Acc: (73.00%) (22644/30848)
Epoch: 21 | Batch_idx: 250 |  Loss: (0.7521) |  Loss2: (0.0000) | Acc: (73.00%) (23578/32128)
Epoch: 21 | Batch_idx: 260 |  Loss: (0.7503) |  Loss2: (0.0000) | Acc: (73.00%) (24544/33408)
Epoch: 21 | Batch_idx: 270 |  Loss: (0.7498) |  Loss2: (0.0000) | Acc: (73.00%) (25496/34688)
Epoch: 21 | Batch_idx: 280 |  Loss: (0.7495) |  Loss2: (0.0000) | Acc: (73.00%) (26443/35968)
Epoch: 21 | Batch_idx: 290 |  Loss: (0.7497) |  Loss2: (0.0000) | Acc: (73.00%) (27401/37248)
Epoch: 21 | Batch_idx: 300 |  Loss: (0.7495) |  Loss2: (0.0000) | Acc: (73.00%) (28349/38528)
Epoch: 21 | Batch_idx: 310 |  Loss: (0.7487) |  Loss2: (0.0000) | Acc: (73.00%) (29294/39808)
Epoch: 21 | Batch_idx: 320 |  Loss: (0.7489) |  Loss2: (0.0000) | Acc: (73.00%) (30213/41088)
Epoch: 21 | Batch_idx: 330 |  Loss: (0.7480) |  Loss2: (0.0000) | Acc: (73.00%) (31176/42368)
Epoch: 21 | Batch_idx: 340 |  Loss: (0.7469) |  Loss2: (0.0000) | Acc: (73.00%) (32133/43648)
Epoch: 21 | Batch_idx: 350 |  Loss: (0.7471) |  Loss2: (0.0000) | Acc: (73.00%) (33071/44928)
Epoch: 21 | Batch_idx: 360 |  Loss: (0.7470) |  Loss2: (0.0000) | Acc: (73.00%) (34013/46208)
Epoch: 21 | Batch_idx: 370 |  Loss: (0.7470) |  Loss2: (0.0000) | Acc: (73.00%) (34964/47488)
Epoch: 21 | Batch_idx: 380 |  Loss: (0.7456) |  Loss2: (0.0000) | Acc: (73.00%) (35940/48768)
Epoch: 21 | Batch_idx: 390 |  Loss: (0.7450) |  Loss2: (0.0000) | Acc: (73.00%) (36858/50000)
# TEST : Loss: (0.9242) | Acc: (67.00%) (6770/10000)
percent tensor([0.5017, 0.4990, 0.5004, 0.4997, 0.5004, 0.5043, 0.5002, 0.5000, 0.5013,
        0.4993, 0.5014, 0.4997, 0.5002, 0.5002, 0.5008, 0.5013],
       device='cuda:0') torch.Size([16])
percent tensor([0.5058, 0.5127, 0.4965, 0.4985, 0.4989, 0.5062, 0.5073, 0.4996, 0.5053,
        0.5054, 0.5091, 0.4983, 0.5068, 0.5140, 0.5077, 0.5049],
       device='cuda:0') torch.Size([16])
percent tensor([0.4725, 0.4778, 0.4942, 0.4604, 0.4878, 0.4425, 0.4905, 0.4805, 0.4794,
        0.4893, 0.4797, 0.5012, 0.4874, 0.4413, 0.4751, 0.4649],
       device='cuda:0') torch.Size([16])
percent tensor([0.5632, 0.5649, 0.5661, 0.5610, 0.5672, 0.5655, 0.5681, 0.5668, 0.5673,
        0.5695, 0.5754, 0.5669, 0.5626, 0.5665, 0.5651, 0.5658],
       device='cuda:0') torch.Size([16])
percent tensor([0.5658, 0.5701, 0.5415, 0.5363, 0.5319, 0.5747, 0.5529, 0.5276, 0.5850,
        0.5707, 0.6110, 0.5519, 0.5820, 0.6053, 0.5556, 0.5591],
       device='cuda:0') torch.Size([16])
percent tensor([0.4552, 0.4699, 0.4700, 0.4728, 0.4593, 0.4882, 0.4607, 0.4257, 0.4946,
        0.4666, 0.4936, 0.4552, 0.4759, 0.5181, 0.4025, 0.4506],
       device='cuda:0') torch.Size([16])
percent tensor([0.5947, 0.5558, 0.6502, 0.6624, 0.6435, 0.6376, 0.5989, 0.6474, 0.5648,
        0.5717, 0.5774, 0.6339, 0.5487, 0.5795, 0.6155, 0.6221],
       device='cuda:0') torch.Size([16])
percent tensor([0.9908, 0.9594, 0.9757, 0.9812, 0.9741, 0.9764, 0.9812, 0.9846, 0.9532,
        0.9676, 0.9699, 0.9736, 0.9647, 0.9646, 0.9722, 0.9857],
       device='cuda:0') torch.Size([16])
Epoch: 22 | Batch_idx: 0 |  Loss: (0.5563) |  Loss2: (0.0000) | Acc: (83.00%) (107/128)
Epoch: 22 | Batch_idx: 10 |  Loss: (0.6997) |  Loss2: (0.0000) | Acc: (76.00%) (1072/1408)
Epoch: 22 | Batch_idx: 20 |  Loss: (0.6878) |  Loss2: (0.0000) | Acc: (75.00%) (2027/2688)
Epoch: 22 | Batch_idx: 30 |  Loss: (0.6834) |  Loss2: (0.0000) | Acc: (76.00%) (3016/3968)
Epoch: 22 | Batch_idx: 40 |  Loss: (0.6913) |  Loss2: (0.0000) | Acc: (75.00%) (3972/5248)
Epoch: 22 | Batch_idx: 50 |  Loss: (0.6993) |  Loss2: (0.0000) | Acc: (75.00%) (4921/6528)
Epoch: 22 | Batch_idx: 60 |  Loss: (0.7032) |  Loss2: (0.0000) | Acc: (75.00%) (5871/7808)
Epoch: 22 | Batch_idx: 70 |  Loss: (0.7036) |  Loss2: (0.0000) | Acc: (75.00%) (6837/9088)
Epoch: 22 | Batch_idx: 80 |  Loss: (0.7005) |  Loss2: (0.0000) | Acc: (75.00%) (7796/10368)
Epoch: 22 | Batch_idx: 90 |  Loss: (0.7002) |  Loss2: (0.0000) | Acc: (75.00%) (8771/11648)
Epoch: 22 | Batch_idx: 100 |  Loss: (0.7045) |  Loss2: (0.0000) | Acc: (75.00%) (9720/12928)
Epoch: 22 | Batch_idx: 110 |  Loss: (0.7035) |  Loss2: (0.0000) | Acc: (75.00%) (10705/14208)
Epoch: 22 | Batch_idx: 120 |  Loss: (0.7044) |  Loss2: (0.0000) | Acc: (75.00%) (11659/15488)
Epoch: 22 | Batch_idx: 130 |  Loss: (0.7056) |  Loss2: (0.0000) | Acc: (75.00%) (12604/16768)
Epoch: 22 | Batch_idx: 140 |  Loss: (0.7097) |  Loss2: (0.0000) | Acc: (75.00%) (13540/18048)
Epoch: 22 | Batch_idx: 150 |  Loss: (0.7111) |  Loss2: (0.0000) | Acc: (74.00%) (14488/19328)
Epoch: 22 | Batch_idx: 160 |  Loss: (0.7091) |  Loss2: (0.0000) | Acc: (75.00%) (15470/20608)
Epoch: 22 | Batch_idx: 170 |  Loss: (0.7090) |  Loss2: (0.0000) | Acc: (75.00%) (16418/21888)
Epoch: 22 | Batch_idx: 180 |  Loss: (0.7109) |  Loss2: (0.0000) | Acc: (74.00%) (17349/23168)
Epoch: 22 | Batch_idx: 190 |  Loss: (0.7108) |  Loss2: (0.0000) | Acc: (74.00%) (18326/24448)
Epoch: 22 | Batch_idx: 200 |  Loss: (0.7117) |  Loss2: (0.0000) | Acc: (75.00%) (19296/25728)
Epoch: 22 | Batch_idx: 210 |  Loss: (0.7117) |  Loss2: (0.0000) | Acc: (75.00%) (20268/27008)
Epoch: 22 | Batch_idx: 220 |  Loss: (0.7132) |  Loss2: (0.0000) | Acc: (74.00%) (21208/28288)
Epoch: 22 | Batch_idx: 230 |  Loss: (0.7127) |  Loss2: (0.0000) | Acc: (75.00%) (22188/29568)
Epoch: 22 | Batch_idx: 240 |  Loss: (0.7127) |  Loss2: (0.0000) | Acc: (75.00%) (23156/30848)
Epoch: 22 | Batch_idx: 250 |  Loss: (0.7103) |  Loss2: (0.0000) | Acc: (75.00%) (24139/32128)
Epoch: 22 | Batch_idx: 260 |  Loss: (0.7088) |  Loss2: (0.0000) | Acc: (75.00%) (25133/33408)
Epoch: 22 | Batch_idx: 270 |  Loss: (0.7078) |  Loss2: (0.0000) | Acc: (75.00%) (26103/34688)
Epoch: 22 | Batch_idx: 280 |  Loss: (0.7087) |  Loss2: (0.0000) | Acc: (75.00%) (27044/35968)
Epoch: 22 | Batch_idx: 290 |  Loss: (0.7088) |  Loss2: (0.0000) | Acc: (75.00%) (28014/37248)
Epoch: 22 | Batch_idx: 300 |  Loss: (0.7083) |  Loss2: (0.0000) | Acc: (75.00%) (28974/38528)
Epoch: 22 | Batch_idx: 310 |  Loss: (0.7067) |  Loss2: (0.0000) | Acc: (75.00%) (29962/39808)
Epoch: 22 | Batch_idx: 320 |  Loss: (0.7050) |  Loss2: (0.0000) | Acc: (75.00%) (30947/41088)
Epoch: 22 | Batch_idx: 330 |  Loss: (0.7056) |  Loss2: (0.0000) | Acc: (75.00%) (31899/42368)
Epoch: 22 | Batch_idx: 340 |  Loss: (0.7040) |  Loss2: (0.0000) | Acc: (75.00%) (32888/43648)
Epoch: 22 | Batch_idx: 350 |  Loss: (0.7037) |  Loss2: (0.0000) | Acc: (75.00%) (33874/44928)
Epoch: 22 | Batch_idx: 360 |  Loss: (0.7034) |  Loss2: (0.0000) | Acc: (75.00%) (34829/46208)
Epoch: 22 | Batch_idx: 370 |  Loss: (0.7018) |  Loss2: (0.0000) | Acc: (75.00%) (35815/47488)
Epoch: 22 | Batch_idx: 380 |  Loss: (0.7013) |  Loss2: (0.0000) | Acc: (75.00%) (36783/48768)
Epoch: 22 | Batch_idx: 390 |  Loss: (0.7003) |  Loss2: (0.0000) | Acc: (75.00%) (37718/50000)
# TEST : Loss: (0.7383) | Acc: (74.00%) (7437/10000)
percent tensor([0.5022, 0.4990, 0.5011, 0.5005, 0.5012, 0.5045, 0.5003, 0.5003, 0.5016,
        0.4997, 0.5017, 0.5000, 0.5006, 0.4995, 0.5010, 0.5018],
       device='cuda:0') torch.Size([16])
percent tensor([0.5050, 0.5127, 0.4952, 0.4980, 0.4976, 0.5057, 0.5069, 0.4991, 0.5045,
        0.5048, 0.5094, 0.4964, 0.5059, 0.5142, 0.5076, 0.5045],
       device='cuda:0') torch.Size([16])
percent tensor([0.4741, 0.4764, 0.4940, 0.4645, 0.4882, 0.4472, 0.4871, 0.4789, 0.4768,
        0.4849, 0.4755, 0.4998, 0.4862, 0.4434, 0.4737, 0.4647],
       device='cuda:0') torch.Size([16])
percent tensor([0.5643, 0.5688, 0.5688, 0.5617, 0.5674, 0.5651, 0.5694, 0.5669, 0.5682,
        0.5729, 0.5763, 0.5686, 0.5659, 0.5691, 0.5671, 0.5671],
       device='cuda:0') torch.Size([16])
percent tensor([0.5598, 0.5718, 0.5508, 0.5389, 0.5285, 0.5670, 0.5549, 0.5308, 0.5890,
        0.5773, 0.6072, 0.5567, 0.5811, 0.6101, 0.5550, 0.5533],
       device='cuda:0') torch.Size([16])
percent tensor([0.4472, 0.4634, 0.4741, 0.4685, 0.4477, 0.4667, 0.4546, 0.4146, 0.4926,
        0.4675, 0.4789, 0.4505, 0.4765, 0.5172, 0.3884, 0.4364],
       device='cuda:0') torch.Size([16])
percent tensor([0.5965, 0.5534, 0.6532, 0.6528, 0.6423, 0.6389, 0.5926, 0.6398, 0.5729,
        0.5807, 0.5828, 0.6282, 0.5524, 0.5734, 0.6124, 0.6248],
       device='cuda:0') torch.Size([16])
percent tensor([0.9886, 0.9585, 0.9808, 0.9793, 0.9795, 0.9718, 0.9768, 0.9847, 0.9514,
        0.9718, 0.9674, 0.9774, 0.9595, 0.9601, 0.9724, 0.9854],
       device='cuda:0') torch.Size([16])
Epoch: 23 | Batch_idx: 0 |  Loss: (0.7072) |  Loss2: (0.0000) | Acc: (73.00%) (94/128)
Epoch: 23 | Batch_idx: 10 |  Loss: (0.7070) |  Loss2: (0.0000) | Acc: (75.00%) (1058/1408)
Epoch: 23 | Batch_idx: 20 |  Loss: (0.6791) |  Loss2: (0.0000) | Acc: (76.00%) (2047/2688)
Epoch: 23 | Batch_idx: 30 |  Loss: (0.6772) |  Loss2: (0.0000) | Acc: (76.00%) (3039/3968)
Epoch: 23 | Batch_idx: 40 |  Loss: (0.6911) |  Loss2: (0.0000) | Acc: (76.00%) (3991/5248)
Epoch: 23 | Batch_idx: 50 |  Loss: (0.6837) |  Loss2: (0.0000) | Acc: (76.00%) (4963/6528)
Epoch: 23 | Batch_idx: 60 |  Loss: (0.6871) |  Loss2: (0.0000) | Acc: (75.00%) (5931/7808)
Epoch: 23 | Batch_idx: 70 |  Loss: (0.6837) |  Loss2: (0.0000) | Acc: (76.00%) (6924/9088)
Epoch: 23 | Batch_idx: 80 |  Loss: (0.6841) |  Loss2: (0.0000) | Acc: (76.00%) (7917/10368)
Epoch: 23 | Batch_idx: 90 |  Loss: (0.6841) |  Loss2: (0.0000) | Acc: (76.00%) (8871/11648)
Epoch: 23 | Batch_idx: 100 |  Loss: (0.6812) |  Loss2: (0.0000) | Acc: (76.00%) (9885/12928)
Epoch: 23 | Batch_idx: 110 |  Loss: (0.6786) |  Loss2: (0.0000) | Acc: (76.00%) (10872/14208)
Epoch: 23 | Batch_idx: 120 |  Loss: (0.6800) |  Loss2: (0.0000) | Acc: (76.00%) (11822/15488)
Epoch: 23 | Batch_idx: 130 |  Loss: (0.6762) |  Loss2: (0.0000) | Acc: (76.00%) (12836/16768)
Epoch: 23 | Batch_idx: 140 |  Loss: (0.6769) |  Loss2: (0.0000) | Acc: (76.00%) (13795/18048)
Epoch: 23 | Batch_idx: 150 |  Loss: (0.6798) |  Loss2: (0.0000) | Acc: (76.00%) (14758/19328)
Epoch: 23 | Batch_idx: 160 |  Loss: (0.6773) |  Loss2: (0.0000) | Acc: (76.00%) (15741/20608)
Epoch: 23 | Batch_idx: 170 |  Loss: (0.6761) |  Loss2: (0.0000) | Acc: (76.00%) (16736/21888)
Epoch: 23 | Batch_idx: 180 |  Loss: (0.6767) |  Loss2: (0.0000) | Acc: (76.00%) (17711/23168)
Epoch: 23 | Batch_idx: 190 |  Loss: (0.6749) |  Loss2: (0.0000) | Acc: (76.00%) (18704/24448)
Epoch: 23 | Batch_idx: 200 |  Loss: (0.6735) |  Loss2: (0.0000) | Acc: (76.00%) (19683/25728)
Epoch: 23 | Batch_idx: 210 |  Loss: (0.6744) |  Loss2: (0.0000) | Acc: (76.00%) (20663/27008)
Epoch: 23 | Batch_idx: 220 |  Loss: (0.6727) |  Loss2: (0.0000) | Acc: (76.00%) (21668/28288)
Epoch: 23 | Batch_idx: 230 |  Loss: (0.6729) |  Loss2: (0.0000) | Acc: (76.00%) (22635/29568)
Epoch: 23 | Batch_idx: 240 |  Loss: (0.6710) |  Loss2: (0.0000) | Acc: (76.00%) (23629/30848)
Epoch: 23 | Batch_idx: 250 |  Loss: (0.6696) |  Loss2: (0.0000) | Acc: (76.00%) (24624/32128)
Epoch: 23 | Batch_idx: 260 |  Loss: (0.6693) |  Loss2: (0.0000) | Acc: (76.00%) (25607/33408)
Epoch: 23 | Batch_idx: 270 |  Loss: (0.6686) |  Loss2: (0.0000) | Acc: (76.00%) (26597/34688)
Epoch: 23 | Batch_idx: 280 |  Loss: (0.6691) |  Loss2: (0.0000) | Acc: (76.00%) (27568/35968)
Epoch: 23 | Batch_idx: 290 |  Loss: (0.6684) |  Loss2: (0.0000) | Acc: (76.00%) (28554/37248)
Epoch: 23 | Batch_idx: 300 |  Loss: (0.6688) |  Loss2: (0.0000) | Acc: (76.00%) (29521/38528)
Epoch: 23 | Batch_idx: 310 |  Loss: (0.6674) |  Loss2: (0.0000) | Acc: (76.00%) (30514/39808)
Epoch: 23 | Batch_idx: 320 |  Loss: (0.6683) |  Loss2: (0.0000) | Acc: (76.00%) (31500/41088)
Epoch: 23 | Batch_idx: 330 |  Loss: (0.6684) |  Loss2: (0.0000) | Acc: (76.00%) (32478/42368)
Epoch: 23 | Batch_idx: 340 |  Loss: (0.6682) |  Loss2: (0.0000) | Acc: (76.00%) (33452/43648)
Epoch: 23 | Batch_idx: 350 |  Loss: (0.6668) |  Loss2: (0.0000) | Acc: (76.00%) (34461/44928)
Epoch: 23 | Batch_idx: 360 |  Loss: (0.6666) |  Loss2: (0.0000) | Acc: (76.00%) (35443/46208)
Epoch: 23 | Batch_idx: 370 |  Loss: (0.6657) |  Loss2: (0.0000) | Acc: (76.00%) (36431/47488)
Epoch: 23 | Batch_idx: 380 |  Loss: (0.6664) |  Loss2: (0.0000) | Acc: (76.00%) (37406/48768)
Epoch: 23 | Batch_idx: 390 |  Loss: (0.6655) |  Loss2: (0.0000) | Acc: (76.00%) (38365/50000)
# TEST : Loss: (0.8059) | Acc: (71.00%) (7176/10000)
percent tensor([0.5018, 0.4991, 0.5012, 0.5005, 0.5009, 0.5042, 0.5004, 0.5003, 0.5012,
        0.4998, 0.5014, 0.5001, 0.5002, 0.4999, 0.5009, 0.5016],
       device='cuda:0') torch.Size([16])
percent tensor([0.5054, 0.5126, 0.4962, 0.4984, 0.4982, 0.5055, 0.5072, 0.4993, 0.5042,
        0.5054, 0.5089, 0.4979, 0.5060, 0.5147, 0.5071, 0.5045],
       device='cuda:0') torch.Size([16])
percent tensor([0.4728, 0.4778, 0.4921, 0.4634, 0.4840, 0.4388, 0.4877, 0.4847, 0.4820,
        0.4838, 0.4768, 0.4949, 0.4882, 0.4442, 0.4708, 0.4643],
       device='cuda:0') torch.Size([16])
percent tensor([0.5644, 0.5678, 0.5658, 0.5605, 0.5660, 0.5678, 0.5695, 0.5679, 0.5673,
        0.5703, 0.5771, 0.5673, 0.5644, 0.5691, 0.5692, 0.5673],
       device='cuda:0') torch.Size([16])
percent tensor([0.5619, 0.5657, 0.5459, 0.5406, 0.5273, 0.5765, 0.5536, 0.5304, 0.5821,
        0.5688, 0.6087, 0.5599, 0.5767, 0.6034, 0.5582, 0.5572],
       device='cuda:0') torch.Size([16])
percent tensor([0.4469, 0.4562, 0.4722, 0.4647, 0.4522, 0.4940, 0.4448, 0.4166, 0.4842,
        0.4546, 0.4787, 0.4512, 0.4679, 0.5053, 0.3964, 0.4479],
       device='cuda:0') torch.Size([16])
percent tensor([0.5916, 0.5523, 0.6471, 0.6598, 0.6371, 0.6391, 0.5921, 0.6382, 0.5682,
        0.5819, 0.5800, 0.6280, 0.5515, 0.5695, 0.6162, 0.6223],
       device='cuda:0') torch.Size([16])
percent tensor([0.9877, 0.9694, 0.9737, 0.9781, 0.9683, 0.9663, 0.9841, 0.9850, 0.9584,
        0.9720, 0.9712, 0.9720, 0.9604, 0.9757, 0.9758, 0.9863],
       device='cuda:0') torch.Size([16])
Epoch: 24 | Batch_idx: 0 |  Loss: (0.4123) |  Loss2: (0.0000) | Acc: (88.00%) (113/128)
Epoch: 24 | Batch_idx: 10 |  Loss: (0.6451) |  Loss2: (0.0000) | Acc: (77.00%) (1096/1408)
Epoch: 24 | Batch_idx: 20 |  Loss: (0.6215) |  Loss2: (0.0000) | Acc: (79.00%) (2124/2688)
Epoch: 24 | Batch_idx: 30 |  Loss: (0.6195) |  Loss2: (0.0000) | Acc: (78.00%) (3131/3968)
Epoch: 24 | Batch_idx: 40 |  Loss: (0.6187) |  Loss2: (0.0000) | Acc: (78.00%) (4133/5248)
Epoch: 24 | Batch_idx: 50 |  Loss: (0.6304) |  Loss2: (0.0000) | Acc: (78.00%) (5114/6528)
Epoch: 24 | Batch_idx: 60 |  Loss: (0.6276) |  Loss2: (0.0000) | Acc: (78.00%) (6119/7808)
Epoch: 24 | Batch_idx: 70 |  Loss: (0.6303) |  Loss2: (0.0000) | Acc: (78.00%) (7109/9088)
Epoch: 24 | Batch_idx: 80 |  Loss: (0.6362) |  Loss2: (0.0000) | Acc: (77.00%) (8083/10368)
Epoch: 24 | Batch_idx: 90 |  Loss: (0.6355) |  Loss2: (0.0000) | Acc: (77.00%) (9079/11648)
Epoch: 24 | Batch_idx: 100 |  Loss: (0.6382) |  Loss2: (0.0000) | Acc: (77.00%) (10067/12928)
Epoch: 24 | Batch_idx: 110 |  Loss: (0.6385) |  Loss2: (0.0000) | Acc: (77.00%) (11063/14208)
Epoch: 24 | Batch_idx: 120 |  Loss: (0.6420) |  Loss2: (0.0000) | Acc: (77.00%) (12041/15488)
Epoch: 24 | Batch_idx: 130 |  Loss: (0.6405) |  Loss2: (0.0000) | Acc: (77.00%) (13038/16768)
Epoch: 24 | Batch_idx: 140 |  Loss: (0.6388) |  Loss2: (0.0000) | Acc: (77.00%) (14043/18048)
Epoch: 24 | Batch_idx: 150 |  Loss: (0.6393) |  Loss2: (0.0000) | Acc: (77.00%) (15028/19328)
Epoch: 24 | Batch_idx: 160 |  Loss: (0.6379) |  Loss2: (0.0000) | Acc: (77.00%) (16046/20608)
Epoch: 24 | Batch_idx: 170 |  Loss: (0.6361) |  Loss2: (0.0000) | Acc: (77.00%) (17056/21888)
Epoch: 24 | Batch_idx: 180 |  Loss: (0.6341) |  Loss2: (0.0000) | Acc: (78.00%) (18080/23168)
Epoch: 24 | Batch_idx: 190 |  Loss: (0.6321) |  Loss2: (0.0000) | Acc: (78.00%) (19098/24448)
Epoch: 24 | Batch_idx: 200 |  Loss: (0.6335) |  Loss2: (0.0000) | Acc: (78.00%) (20087/25728)
Epoch: 24 | Batch_idx: 210 |  Loss: (0.6318) |  Loss2: (0.0000) | Acc: (78.00%) (21121/27008)
Epoch: 24 | Batch_idx: 220 |  Loss: (0.6332) |  Loss2: (0.0000) | Acc: (78.00%) (22105/28288)
Epoch: 24 | Batch_idx: 230 |  Loss: (0.6328) |  Loss2: (0.0000) | Acc: (78.00%) (23119/29568)
Epoch: 24 | Batch_idx: 240 |  Loss: (0.6305) |  Loss2: (0.0000) | Acc: (78.00%) (24149/30848)
Epoch: 24 | Batch_idx: 250 |  Loss: (0.6284) |  Loss2: (0.0000) | Acc: (78.00%) (25178/32128)
Epoch: 24 | Batch_idx: 260 |  Loss: (0.6282) |  Loss2: (0.0000) | Acc: (78.00%) (26188/33408)
Epoch: 24 | Batch_idx: 270 |  Loss: (0.6296) |  Loss2: (0.0000) | Acc: (78.00%) (27175/34688)
Epoch: 24 | Batch_idx: 280 |  Loss: (0.6301) |  Loss2: (0.0000) | Acc: (78.00%) (28168/35968)
Epoch: 24 | Batch_idx: 290 |  Loss: (0.6292) |  Loss2: (0.0000) | Acc: (78.00%) (29178/37248)
Epoch: 24 | Batch_idx: 300 |  Loss: (0.6302) |  Loss2: (0.0000) | Acc: (78.00%) (30158/38528)
Epoch: 24 | Batch_idx: 310 |  Loss: (0.6302) |  Loss2: (0.0000) | Acc: (78.00%) (31154/39808)
Epoch: 24 | Batch_idx: 320 |  Loss: (0.6283) |  Loss2: (0.0000) | Acc: (78.00%) (32172/41088)
Epoch: 24 | Batch_idx: 330 |  Loss: (0.6285) |  Loss2: (0.0000) | Acc: (78.00%) (33163/42368)
Epoch: 24 | Batch_idx: 340 |  Loss: (0.6284) |  Loss2: (0.0000) | Acc: (78.00%) (34169/43648)
Epoch: 24 | Batch_idx: 350 |  Loss: (0.6272) |  Loss2: (0.0000) | Acc: (78.00%) (35204/44928)
Epoch: 24 | Batch_idx: 360 |  Loss: (0.6275) |  Loss2: (0.0000) | Acc: (78.00%) (36207/46208)
Epoch: 24 | Batch_idx: 370 |  Loss: (0.6272) |  Loss2: (0.0000) | Acc: (78.00%) (37226/47488)
Epoch: 24 | Batch_idx: 380 |  Loss: (0.6263) |  Loss2: (0.0000) | Acc: (78.00%) (38229/48768)
Epoch: 24 | Batch_idx: 390 |  Loss: (0.6260) |  Loss2: (0.0000) | Acc: (78.00%) (39191/50000)
# TEST : Loss: (0.6966) | Acc: (75.00%) (7585/10000)
percent tensor([0.5020, 0.4991, 0.5013, 0.5006, 0.5013, 0.5042, 0.5003, 0.5005, 0.5015,
        0.4998, 0.5014, 0.5001, 0.5005, 0.4997, 0.5008, 0.5016],
       device='cuda:0') torch.Size([16])
percent tensor([0.5054, 0.5123, 0.4968, 0.4984, 0.4991, 0.5052, 0.5079, 0.4986, 0.5042,
        0.5060, 0.5089, 0.4991, 0.5056, 0.5142, 0.5072, 0.5045],
       device='cuda:0') torch.Size([16])
percent tensor([0.4750, 0.4811, 0.4834, 0.4589, 0.4770, 0.4480, 0.4885, 0.4779, 0.4791,
        0.4822, 0.4794, 0.4929, 0.4910, 0.4483, 0.4776, 0.4677],
       device='cuda:0') torch.Size([16])
percent tensor([0.5646, 0.5650, 0.5670, 0.5612, 0.5671, 0.5668, 0.5678, 0.5660, 0.5660,
        0.5697, 0.5770, 0.5688, 0.5648, 0.5656, 0.5677, 0.5675],
       device='cuda:0') torch.Size([16])
percent tensor([0.5607, 0.5582, 0.5536, 0.5480, 0.5354, 0.5737, 0.5470, 0.5303, 0.5787,
        0.5688, 0.6013, 0.5590, 0.5733, 0.5943, 0.5523, 0.5552],
       device='cuda:0') torch.Size([16])
percent tensor([0.4452, 0.4442, 0.4707, 0.4703, 0.4645, 0.4821, 0.4387, 0.4214, 0.4768,
        0.4489, 0.4761, 0.4628, 0.4573, 0.4936, 0.3959, 0.4472],
       device='cuda:0') torch.Size([16])
percent tensor([0.6021, 0.5589, 0.6505, 0.6568, 0.6355, 0.6361, 0.5919, 0.6394, 0.5794,
        0.5780, 0.5774, 0.6218, 0.5596, 0.5742, 0.6180, 0.6239],
       device='cuda:0') torch.Size([16])
percent tensor([0.9880, 0.9714, 0.9746, 0.9778, 0.9661, 0.9667, 0.9836, 0.9835, 0.9560,
        0.9737, 0.9656, 0.9644, 0.9654, 0.9768, 0.9735, 0.9872],
       device='cuda:0') torch.Size([16])
False Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=128, out_features=16, bias=False)
True Linear(in_features=16, out_features=2, bias=False)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=128, out_features=16, bias=False)
True Linear(in_features=16, out_features=2, bias=False)
False Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=256, out_features=32, bias=False)
True Linear(in_features=32, out_features=2, bias=False)
False Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=256, out_features=32, bias=False)
True Linear(in_features=32, out_features=2, bias=False)
False Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=512, out_features=64, bias=False)
True Linear(in_features=64, out_features=2, bias=False)
False Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=512, out_features=64, bias=False)
True Linear(in_features=64, out_features=2, bias=False)
False Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1024, out_features=128, bias=False)
True Linear(in_features=128, out_features=2, bias=False)
False Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1024, out_features=128, bias=False)
True Linear(in_features=128, out_features=2, bias=False)
False Linear(in_features=512, out_features=10, bias=True)
Epoch: 25 | Batch_idx: 0 |  Loss: (0.7219) |  Loss2: (0.0000) | Acc: (73.00%) (94/128)
Epoch: 25 | Batch_idx: 10 |  Loss: (0.6664) |  Loss2: (0.0000) | Acc: (75.00%) (1070/1408)
Epoch: 25 | Batch_idx: 20 |  Loss: (0.6927) |  Loss2: (0.0000) | Acc: (75.00%) (2023/2688)
Epoch: 25 | Batch_idx: 30 |  Loss: (0.7137) |  Loss2: (0.0000) | Acc: (74.00%) (2940/3968)
Epoch: 25 | Batch_idx: 40 |  Loss: (0.7311) |  Loss2: (0.0000) | Acc: (73.00%) (3856/5248)
Epoch: 25 | Batch_idx: 50 |  Loss: (0.7335) |  Loss2: (0.0000) | Acc: (73.00%) (4790/6528)
Epoch: 25 | Batch_idx: 60 |  Loss: (0.7360) |  Loss2: (0.0000) | Acc: (73.00%) (5739/7808)
Epoch: 25 | Batch_idx: 70 |  Loss: (0.7362) |  Loss2: (0.0000) | Acc: (73.00%) (6690/9088)
Epoch: 25 | Batch_idx: 80 |  Loss: (0.7365) |  Loss2: (0.0000) | Acc: (73.00%) (7630/10368)
Epoch: 25 | Batch_idx: 90 |  Loss: (0.7387) |  Loss2: (0.0000) | Acc: (73.00%) (8581/11648)
Epoch: 25 | Batch_idx: 100 |  Loss: (0.7353) |  Loss2: (0.0000) | Acc: (73.00%) (9548/12928)
Epoch: 25 | Batch_idx: 110 |  Loss: (0.7371) |  Loss2: (0.0000) | Acc: (73.00%) (10489/14208)
Epoch: 25 | Batch_idx: 120 |  Loss: (0.7375) |  Loss2: (0.0000) | Acc: (73.00%) (11435/15488)
Epoch: 25 | Batch_idx: 130 |  Loss: (0.7362) |  Loss2: (0.0000) | Acc: (73.00%) (12401/16768)
Epoch: 25 | Batch_idx: 140 |  Loss: (0.7362) |  Loss2: (0.0000) | Acc: (73.00%) (13346/18048)
Epoch: 25 | Batch_idx: 150 |  Loss: (0.7314) |  Loss2: (0.0000) | Acc: (74.00%) (14324/19328)
Epoch: 25 | Batch_idx: 160 |  Loss: (0.7302) |  Loss2: (0.0000) | Acc: (74.00%) (15279/20608)
Epoch: 25 | Batch_idx: 170 |  Loss: (0.7307) |  Loss2: (0.0000) | Acc: (74.00%) (16235/21888)
Epoch: 25 | Batch_idx: 180 |  Loss: (0.7285) |  Loss2: (0.0000) | Acc: (74.00%) (17200/23168)
Epoch: 25 | Batch_idx: 190 |  Loss: (0.7291) |  Loss2: (0.0000) | Acc: (74.00%) (18151/24448)
Epoch: 25 | Batch_idx: 200 |  Loss: (0.7258) |  Loss2: (0.0000) | Acc: (74.00%) (19117/25728)
Epoch: 25 | Batch_idx: 210 |  Loss: (0.7243) |  Loss2: (0.0000) | Acc: (74.00%) (20076/27008)
Epoch: 25 | Batch_idx: 220 |  Loss: (0.7212) |  Loss2: (0.0000) | Acc: (74.00%) (21064/28288)
Epoch: 25 | Batch_idx: 230 |  Loss: (0.7188) |  Loss2: (0.0000) | Acc: (74.00%) (22039/29568)
Epoch: 25 | Batch_idx: 240 |  Loss: (0.7176) |  Loss2: (0.0000) | Acc: (74.00%) (23017/30848)
Epoch: 25 | Batch_idx: 250 |  Loss: (0.7177) |  Loss2: (0.0000) | Acc: (74.00%) (23973/32128)
Epoch: 25 | Batch_idx: 260 |  Loss: (0.7153) |  Loss2: (0.0000) | Acc: (74.00%) (24969/33408)
Epoch: 25 | Batch_idx: 270 |  Loss: (0.7155) |  Loss2: (0.0000) | Acc: (74.00%) (25923/34688)
Epoch: 25 | Batch_idx: 280 |  Loss: (0.7144) |  Loss2: (0.0000) | Acc: (74.00%) (26904/35968)
Epoch: 25 | Batch_idx: 290 |  Loss: (0.7127) |  Loss2: (0.0000) | Acc: (74.00%) (27898/37248)
Epoch: 25 | Batch_idx: 300 |  Loss: (0.7107) |  Loss2: (0.0000) | Acc: (74.00%) (28874/38528)
Epoch: 25 | Batch_idx: 310 |  Loss: (0.7082) |  Loss2: (0.0000) | Acc: (75.00%) (29864/39808)
Epoch: 25 | Batch_idx: 320 |  Loss: (0.7076) |  Loss2: (0.0000) | Acc: (75.00%) (30837/41088)
Epoch: 25 | Batch_idx: 330 |  Loss: (0.7059) |  Loss2: (0.0000) | Acc: (75.00%) (31811/42368)
Epoch: 25 | Batch_idx: 340 |  Loss: (0.7041) |  Loss2: (0.0000) | Acc: (75.00%) (32815/43648)
Epoch: 25 | Batch_idx: 350 |  Loss: (0.7042) |  Loss2: (0.0000) | Acc: (75.00%) (33782/44928)
Epoch: 25 | Batch_idx: 360 |  Loss: (0.7046) |  Loss2: (0.0000) | Acc: (75.00%) (34725/46208)
Epoch: 25 | Batch_idx: 370 |  Loss: (0.7046) |  Loss2: (0.0000) | Acc: (75.00%) (35689/47488)
Epoch: 25 | Batch_idx: 380 |  Loss: (0.7028) |  Loss2: (0.0000) | Acc: (75.00%) (36681/48768)
Epoch: 25 | Batch_idx: 390 |  Loss: (0.7013) |  Loss2: (0.0000) | Acc: (75.00%) (37620/50000)
=> saving checkpoint 'drive/app/torch/save_Routing_Gate_2/checkpoint_025.pth.tar'
# TEST : Loss: (0.7024) | Acc: (75.00%) (7552/10000)
percent tensor([0.4919, 0.4870, 0.4923, 0.4941, 0.4905, 0.4929, 0.4881, 0.4918, 0.4902,
        0.4888, 0.4902, 0.4904, 0.4907, 0.4879, 0.4897, 0.4920],
       device='cuda:0') torch.Size([16])
percent tensor([0.4932, 0.4996, 0.4811, 0.4847, 0.4820, 0.4934, 0.4931, 0.4835, 0.4915,
        0.4914, 0.4965, 0.4835, 0.4934, 0.5042, 0.4941, 0.4923],
       device='cuda:0') torch.Size([16])
percent tensor([0.4718, 0.4792, 0.4924, 0.4529, 0.4850, 0.4415, 0.4901, 0.4796, 0.4764,
        0.4816, 0.4751, 0.4982, 0.4864, 0.4423, 0.4770, 0.4592],
       device='cuda:0') torch.Size([16])
percent tensor([0.5977, 0.5997, 0.5985, 0.5957, 0.6035, 0.5989, 0.6071, 0.6048, 0.5979,
        0.6041, 0.6075, 0.6013, 0.5966, 0.6008, 0.6067, 0.6019],
       device='cuda:0') torch.Size([16])
percent tensor([0.5708, 0.5453, 0.5856, 0.5824, 0.5783, 0.5928, 0.5610, 0.5772, 0.5746,
        0.5636, 0.5773, 0.5764, 0.5571, 0.5752, 0.5715, 0.5713],
       device='cuda:0') torch.Size([16])
percent tensor([0.4757, 0.4803, 0.4942, 0.5338, 0.4815, 0.5135, 0.4741, 0.4565, 0.5090,
        0.4932, 0.5110, 0.4954, 0.4872, 0.5296, 0.4116, 0.4871],
       device='cuda:0') torch.Size([16])
percent tensor([0.5959, 0.5512, 0.6547, 0.6757, 0.6516, 0.6306, 0.5977, 0.6478, 0.5757,
        0.5799, 0.5755, 0.6393, 0.5465, 0.5721, 0.6188, 0.6220],
       device='cuda:0') torch.Size([16])
percent tensor([0.9869, 0.9629, 0.9698, 0.9751, 0.9694, 0.9691, 0.9812, 0.9821, 0.9592,
        0.9716, 0.9683, 0.9694, 0.9671, 0.9734, 0.9755, 0.9871],
       device='cuda:0') torch.Size([16])
Epoch: 26 | Batch_idx: 0 |  Loss: (0.7397) |  Loss2: (0.0000) | Acc: (69.00%) (89/128)
Epoch: 26 | Batch_idx: 10 |  Loss: (0.6782) |  Loss2: (0.0000) | Acc: (75.00%) (1069/1408)
Epoch: 26 | Batch_idx: 20 |  Loss: (0.6644) |  Loss2: (0.0000) | Acc: (77.00%) (2080/2688)
Epoch: 26 | Batch_idx: 30 |  Loss: (0.6832) |  Loss2: (0.0000) | Acc: (76.00%) (3043/3968)
Epoch: 26 | Batch_idx: 40 |  Loss: (0.6865) |  Loss2: (0.0000) | Acc: (76.00%) (4019/5248)
Epoch: 26 | Batch_idx: 50 |  Loss: (0.6865) |  Loss2: (0.0000) | Acc: (76.00%) (4996/6528)
Epoch: 26 | Batch_idx: 60 |  Loss: (0.6765) |  Loss2: (0.0000) | Acc: (76.00%) (5995/7808)
Epoch: 26 | Batch_idx: 70 |  Loss: (0.6793) |  Loss2: (0.0000) | Acc: (76.00%) (6960/9088)
Epoch: 26 | Batch_idx: 80 |  Loss: (0.6756) |  Loss2: (0.0000) | Acc: (76.00%) (7956/10368)
Epoch: 26 | Batch_idx: 90 |  Loss: (0.6722) |  Loss2: (0.0000) | Acc: (76.00%) (8958/11648)
Epoch: 26 | Batch_idx: 100 |  Loss: (0.6674) |  Loss2: (0.0000) | Acc: (76.00%) (9954/12928)
Epoch: 26 | Batch_idx: 110 |  Loss: (0.6693) |  Loss2: (0.0000) | Acc: (76.00%) (10926/14208)
Epoch: 26 | Batch_idx: 120 |  Loss: (0.6685) |  Loss2: (0.0000) | Acc: (76.00%) (11915/15488)
Epoch: 26 | Batch_idx: 130 |  Loss: (0.6666) |  Loss2: (0.0000) | Acc: (76.00%) (12892/16768)
Epoch: 26 | Batch_idx: 140 |  Loss: (0.6671) |  Loss2: (0.0000) | Acc: (76.00%) (13863/18048)
Epoch: 26 | Batch_idx: 150 |  Loss: (0.6646) |  Loss2: (0.0000) | Acc: (76.00%) (14859/19328)
Epoch: 26 | Batch_idx: 160 |  Loss: (0.6636) |  Loss2: (0.0000) | Acc: (76.00%) (15856/20608)
Epoch: 26 | Batch_idx: 170 |  Loss: (0.6630) |  Loss2: (0.0000) | Acc: (76.00%) (16834/21888)
Epoch: 26 | Batch_idx: 180 |  Loss: (0.6615) |  Loss2: (0.0000) | Acc: (76.00%) (17824/23168)
Epoch: 26 | Batch_idx: 190 |  Loss: (0.6596) |  Loss2: (0.0000) | Acc: (77.00%) (18827/24448)
Epoch: 26 | Batch_idx: 200 |  Loss: (0.6585) |  Loss2: (0.0000) | Acc: (77.00%) (19817/25728)
Epoch: 26 | Batch_idx: 210 |  Loss: (0.6586) |  Loss2: (0.0000) | Acc: (77.00%) (20812/27008)
Epoch: 26 | Batch_idx: 220 |  Loss: (0.6558) |  Loss2: (0.0000) | Acc: (77.00%) (21842/28288)
Epoch: 26 | Batch_idx: 230 |  Loss: (0.6534) |  Loss2: (0.0000) | Acc: (77.00%) (22852/29568)
Epoch: 26 | Batch_idx: 240 |  Loss: (0.6502) |  Loss2: (0.0000) | Acc: (77.00%) (23877/30848)
Epoch: 26 | Batch_idx: 250 |  Loss: (0.6509) |  Loss2: (0.0000) | Acc: (77.00%) (24841/32128)
Epoch: 26 | Batch_idx: 260 |  Loss: (0.6511) |  Loss2: (0.0000) | Acc: (77.00%) (25839/33408)
Epoch: 26 | Batch_idx: 270 |  Loss: (0.6512) |  Loss2: (0.0000) | Acc: (77.00%) (26827/34688)
Epoch: 26 | Batch_idx: 280 |  Loss: (0.6511) |  Loss2: (0.0000) | Acc: (77.00%) (27821/35968)
Epoch: 26 | Batch_idx: 290 |  Loss: (0.6508) |  Loss2: (0.0000) | Acc: (77.00%) (28803/37248)
Epoch: 26 | Batch_idx: 300 |  Loss: (0.6495) |  Loss2: (0.0000) | Acc: (77.00%) (29809/38528)
Epoch: 26 | Batch_idx: 310 |  Loss: (0.6503) |  Loss2: (0.0000) | Acc: (77.00%) (30786/39808)
Epoch: 26 | Batch_idx: 320 |  Loss: (0.6492) |  Loss2: (0.0000) | Acc: (77.00%) (31806/41088)
Epoch: 26 | Batch_idx: 330 |  Loss: (0.6492) |  Loss2: (0.0000) | Acc: (77.00%) (32797/42368)
Epoch: 26 | Batch_idx: 340 |  Loss: (0.6497) |  Loss2: (0.0000) | Acc: (77.00%) (33791/43648)
Epoch: 26 | Batch_idx: 350 |  Loss: (0.6492) |  Loss2: (0.0000) | Acc: (77.00%) (34800/44928)
Epoch: 26 | Batch_idx: 360 |  Loss: (0.6498) |  Loss2: (0.0000) | Acc: (77.00%) (35785/46208)
Epoch: 26 | Batch_idx: 370 |  Loss: (0.6500) |  Loss2: (0.0000) | Acc: (77.00%) (36753/47488)
Epoch: 26 | Batch_idx: 380 |  Loss: (0.6504) |  Loss2: (0.0000) | Acc: (77.00%) (37727/48768)
Epoch: 26 | Batch_idx: 390 |  Loss: (0.6498) |  Loss2: (0.0000) | Acc: (77.00%) (38687/50000)
# TEST : Loss: (0.6689) | Acc: (76.00%) (7690/10000)
percent tensor([0.4899, 0.4844, 0.4914, 0.4930, 0.4890, 0.4901, 0.4858, 0.4908, 0.4882,
        0.4870, 0.4879, 0.4893, 0.4888, 0.4854, 0.4871, 0.4899],
       device='cuda:0') torch.Size([16])
percent tensor([0.4932, 0.5006, 0.4812, 0.4859, 0.4821, 0.4941, 0.4937, 0.4843, 0.4916,
        0.4919, 0.4965, 0.4834, 0.4934, 0.5058, 0.4949, 0.4934],
       device='cuda:0') torch.Size([16])
percent tensor([0.4725, 0.4773, 0.4950, 0.4530, 0.4873, 0.4413, 0.4912, 0.4804, 0.4731,
        0.4799, 0.4725, 0.4984, 0.4854, 0.4346, 0.4794, 0.4580],
       device='cuda:0') torch.Size([16])
percent tensor([0.6082, 0.6106, 0.6085, 0.6042, 0.6158, 0.6092, 0.6211, 0.6160, 0.6084,
        0.6141, 0.6167, 0.6117, 0.6045, 0.6147, 0.6183, 0.6118],
       device='cuda:0') torch.Size([16])
percent tensor([0.5721, 0.5368, 0.5980, 0.5927, 0.5951, 0.6011, 0.5658, 0.5906, 0.5717,
        0.5554, 0.5618, 0.5789, 0.5450, 0.5696, 0.5767, 0.5745],
       device='cuda:0') torch.Size([16])
percent tensor([0.4810, 0.4856, 0.5025, 0.5415, 0.4849, 0.5236, 0.4761, 0.4527, 0.5202,
        0.4994, 0.5178, 0.5043, 0.4931, 0.5455, 0.3984, 0.4919],
       device='cuda:0') torch.Size([16])
percent tensor([0.6006, 0.5527, 0.6686, 0.6939, 0.6670, 0.6243, 0.6088, 0.6655, 0.5806,
        0.5902, 0.5800, 0.6555, 0.5476, 0.5843, 0.6282, 0.6277],
       device='cuda:0') torch.Size([16])
percent tensor([0.9898, 0.9684, 0.9767, 0.9812, 0.9741, 0.9739, 0.9860, 0.9858, 0.9681,
        0.9773, 0.9741, 0.9751, 0.9718, 0.9777, 0.9796, 0.9900],
       device='cuda:0') torch.Size([16])
Epoch: 27 | Batch_idx: 0 |  Loss: (0.5780) |  Loss2: (0.0000) | Acc: (80.00%) (103/128)
Epoch: 27 | Batch_idx: 10 |  Loss: (0.6548) |  Loss2: (0.0000) | Acc: (77.00%) (1095/1408)
Epoch: 27 | Batch_idx: 20 |  Loss: (0.6329) |  Loss2: (0.0000) | Acc: (78.00%) (2112/2688)
Epoch: 27 | Batch_idx: 30 |  Loss: (0.6389) |  Loss2: (0.0000) | Acc: (78.00%) (3107/3968)
Epoch: 27 | Batch_idx: 40 |  Loss: (0.6376) |  Loss2: (0.0000) | Acc: (78.00%) (4103/5248)
Epoch: 27 | Batch_idx: 50 |  Loss: (0.6306) |  Loss2: (0.0000) | Acc: (78.00%) (5120/6528)
Epoch: 27 | Batch_idx: 60 |  Loss: (0.6366) |  Loss2: (0.0000) | Acc: (78.00%) (6104/7808)
Epoch: 27 | Batch_idx: 70 |  Loss: (0.6322) |  Loss2: (0.0000) | Acc: (78.00%) (7119/9088)
Epoch: 27 | Batch_idx: 80 |  Loss: (0.6321) |  Loss2: (0.0000) | Acc: (78.00%) (8131/10368)
Epoch: 27 | Batch_idx: 90 |  Loss: (0.6291) |  Loss2: (0.0000) | Acc: (78.00%) (9142/11648)
Epoch: 27 | Batch_idx: 100 |  Loss: (0.6298) |  Loss2: (0.0000) | Acc: (78.00%) (10133/12928)
Epoch: 27 | Batch_idx: 110 |  Loss: (0.6262) |  Loss2: (0.0000) | Acc: (78.00%) (11138/14208)
Epoch: 27 | Batch_idx: 120 |  Loss: (0.6273) |  Loss2: (0.0000) | Acc: (78.00%) (12127/15488)
Epoch: 27 | Batch_idx: 130 |  Loss: (0.6261) |  Loss2: (0.0000) | Acc: (78.00%) (13123/16768)
Epoch: 27 | Batch_idx: 140 |  Loss: (0.6283) |  Loss2: (0.0000) | Acc: (78.00%) (14125/18048)
Epoch: 27 | Batch_idx: 150 |  Loss: (0.6283) |  Loss2: (0.0000) | Acc: (78.00%) (15122/19328)
Epoch: 27 | Batch_idx: 160 |  Loss: (0.6276) |  Loss2: (0.0000) | Acc: (78.00%) (16131/20608)
Epoch: 27 | Batch_idx: 170 |  Loss: (0.6277) |  Loss2: (0.0000) | Acc: (78.00%) (17146/21888)
Epoch: 27 | Batch_idx: 180 |  Loss: (0.6261) |  Loss2: (0.0000) | Acc: (78.00%) (18176/23168)
Epoch: 27 | Batch_idx: 190 |  Loss: (0.6270) |  Loss2: (0.0000) | Acc: (78.00%) (19170/24448)
Epoch: 27 | Batch_idx: 200 |  Loss: (0.6276) |  Loss2: (0.0000) | Acc: (78.00%) (20166/25728)
Epoch: 27 | Batch_idx: 210 |  Loss: (0.6281) |  Loss2: (0.0000) | Acc: (78.00%) (21151/27008)
Epoch: 27 | Batch_idx: 220 |  Loss: (0.6285) |  Loss2: (0.0000) | Acc: (78.00%) (22149/28288)
Epoch: 27 | Batch_idx: 230 |  Loss: (0.6278) |  Loss2: (0.0000) | Acc: (78.00%) (23167/29568)
Epoch: 27 | Batch_idx: 240 |  Loss: (0.6270) |  Loss2: (0.0000) | Acc: (78.00%) (24159/30848)
Epoch: 27 | Batch_idx: 250 |  Loss: (0.6259) |  Loss2: (0.0000) | Acc: (78.00%) (25169/32128)
Epoch: 27 | Batch_idx: 260 |  Loss: (0.6290) |  Loss2: (0.0000) | Acc: (78.00%) (26131/33408)
Epoch: 27 | Batch_idx: 270 |  Loss: (0.6283) |  Loss2: (0.0000) | Acc: (78.00%) (27136/34688)
Epoch: 27 | Batch_idx: 280 |  Loss: (0.6284) |  Loss2: (0.0000) | Acc: (78.00%) (28132/35968)
Epoch: 27 | Batch_idx: 290 |  Loss: (0.6291) |  Loss2: (0.0000) | Acc: (78.00%) (29122/37248)
Epoch: 27 | Batch_idx: 300 |  Loss: (0.6284) |  Loss2: (0.0000) | Acc: (78.00%) (30139/38528)
Epoch: 27 | Batch_idx: 310 |  Loss: (0.6282) |  Loss2: (0.0000) | Acc: (78.00%) (31143/39808)
Epoch: 27 | Batch_idx: 320 |  Loss: (0.6288) |  Loss2: (0.0000) | Acc: (78.00%) (32138/41088)
Epoch: 27 | Batch_idx: 330 |  Loss: (0.6284) |  Loss2: (0.0000) | Acc: (78.00%) (33170/42368)
Epoch: 27 | Batch_idx: 340 |  Loss: (0.6295) |  Loss2: (0.0000) | Acc: (78.00%) (34151/43648)
Epoch: 27 | Batch_idx: 350 |  Loss: (0.6294) |  Loss2: (0.0000) | Acc: (78.00%) (35145/44928)
Epoch: 27 | Batch_idx: 360 |  Loss: (0.6283) |  Loss2: (0.0000) | Acc: (78.00%) (36147/46208)
Epoch: 27 | Batch_idx: 370 |  Loss: (0.6287) |  Loss2: (0.0000) | Acc: (78.00%) (37142/47488)
Epoch: 27 | Batch_idx: 380 |  Loss: (0.6280) |  Loss2: (0.0000) | Acc: (78.00%) (38154/48768)
Epoch: 27 | Batch_idx: 390 |  Loss: (0.6284) |  Loss2: (0.0000) | Acc: (78.00%) (39114/50000)
# TEST : Loss: (0.6506) | Acc: (77.00%) (7755/10000)
percent tensor([0.4897, 0.4840, 0.4922, 0.4932, 0.4894, 0.4894, 0.4857, 0.4914, 0.4882,
        0.4870, 0.4876, 0.4899, 0.4886, 0.4849, 0.4866, 0.4897],
       device='cuda:0') torch.Size([16])
percent tensor([0.4954, 0.5030, 0.4842, 0.4893, 0.4852, 0.4969, 0.4963, 0.4877, 0.4936,
        0.4943, 0.4981, 0.4860, 0.4953, 0.5081, 0.4974, 0.4961],
       device='cuda:0') torch.Size([16])
percent tensor([0.4774, 0.4816, 0.5031, 0.4581, 0.4954, 0.4450, 0.4984, 0.4876, 0.4759,
        0.4847, 0.4754, 0.5052, 0.4900, 0.4331, 0.4870, 0.4612],
       device='cuda:0') torch.Size([16])
percent tensor([0.6118, 0.6141, 0.6114, 0.6064, 0.6201, 0.6128, 0.6265, 0.6189, 0.6123,
        0.6171, 0.6195, 0.6145, 0.6064, 0.6213, 0.6218, 0.6149],
       device='cuda:0') torch.Size([16])
percent tensor([0.5734, 0.5347, 0.6039, 0.5959, 0.6019, 0.6058, 0.5688, 0.5954, 0.5711,
        0.5539, 0.5556, 0.5808, 0.5411, 0.5693, 0.5790, 0.5783],
       device='cuda:0') torch.Size([16])
percent tensor([0.4915, 0.4944, 0.5151, 0.5517, 0.4931, 0.5341, 0.4839, 0.4557, 0.5341,
        0.5095, 0.5272, 0.5182, 0.5053, 0.5602, 0.3952, 0.5016],
       device='cuda:0') torch.Size([16])
percent tensor([0.6016, 0.5550, 0.6833, 0.7083, 0.6840, 0.6201, 0.6188, 0.6820, 0.5878,
        0.6007, 0.5827, 0.6721, 0.5465, 0.5930, 0.6376, 0.6308],
       device='cuda:0') torch.Size([16])
percent tensor([0.9921, 0.9740, 0.9821, 0.9855, 0.9790, 0.9791, 0.9893, 0.9889, 0.9753,
        0.9820, 0.9799, 0.9805, 0.9769, 0.9822, 0.9835, 0.9924],
       device='cuda:0') torch.Size([16])
Epoch: 28 | Batch_idx: 0 |  Loss: (0.6493) |  Loss2: (0.0000) | Acc: (78.00%) (100/128)
Epoch: 28 | Batch_idx: 10 |  Loss: (0.6286) |  Loss2: (0.0000) | Acc: (77.00%) (1087/1408)
Epoch: 28 | Batch_idx: 20 |  Loss: (0.6387) |  Loss2: (0.0000) | Acc: (76.00%) (2068/2688)
Epoch: 28 | Batch_idx: 30 |  Loss: (0.6365) |  Loss2: (0.0000) | Acc: (76.00%) (3050/3968)
Epoch: 28 | Batch_idx: 40 |  Loss: (0.6350) |  Loss2: (0.0000) | Acc: (77.00%) (4055/5248)
Epoch: 28 | Batch_idx: 50 |  Loss: (0.6359) |  Loss2: (0.0000) | Acc: (77.00%) (5048/6528)
Epoch: 28 | Batch_idx: 60 |  Loss: (0.6296) |  Loss2: (0.0000) | Acc: (77.00%) (6072/7808)
Epoch: 28 | Batch_idx: 70 |  Loss: (0.6301) |  Loss2: (0.0000) | Acc: (77.00%) (7080/9088)
Epoch: 28 | Batch_idx: 80 |  Loss: (0.6295) |  Loss2: (0.0000) | Acc: (77.00%) (8069/10368)
Epoch: 28 | Batch_idx: 90 |  Loss: (0.6234) |  Loss2: (0.0000) | Acc: (78.00%) (9091/11648)
Epoch: 28 | Batch_idx: 100 |  Loss: (0.6253) |  Loss2: (0.0000) | Acc: (77.00%) (10080/12928)
Epoch: 28 | Batch_idx: 110 |  Loss: (0.6247) |  Loss2: (0.0000) | Acc: (78.00%) (11093/14208)
Epoch: 28 | Batch_idx: 120 |  Loss: (0.6280) |  Loss2: (0.0000) | Acc: (78.00%) (12084/15488)
Epoch: 28 | Batch_idx: 130 |  Loss: (0.6261) |  Loss2: (0.0000) | Acc: (78.00%) (13092/16768)
Epoch: 28 | Batch_idx: 140 |  Loss: (0.6260) |  Loss2: (0.0000) | Acc: (78.00%) (14096/18048)
Epoch: 28 | Batch_idx: 150 |  Loss: (0.6225) |  Loss2: (0.0000) | Acc: (78.00%) (15099/19328)
Epoch: 28 | Batch_idx: 160 |  Loss: (0.6228) |  Loss2: (0.0000) | Acc: (78.00%) (16108/20608)
Epoch: 28 | Batch_idx: 170 |  Loss: (0.6228) |  Loss2: (0.0000) | Acc: (78.00%) (17100/21888)
Epoch: 28 | Batch_idx: 180 |  Loss: (0.6223) |  Loss2: (0.0000) | Acc: (78.00%) (18111/23168)
Epoch: 28 | Batch_idx: 190 |  Loss: (0.6231) |  Loss2: (0.0000) | Acc: (78.00%) (19102/24448)
Epoch: 28 | Batch_idx: 200 |  Loss: (0.6239) |  Loss2: (0.0000) | Acc: (78.00%) (20107/25728)
Epoch: 28 | Batch_idx: 210 |  Loss: (0.6221) |  Loss2: (0.0000) | Acc: (78.00%) (21129/27008)
Epoch: 28 | Batch_idx: 220 |  Loss: (0.6235) |  Loss2: (0.0000) | Acc: (78.00%) (22121/28288)
Epoch: 28 | Batch_idx: 230 |  Loss: (0.6238) |  Loss2: (0.0000) | Acc: (78.00%) (23121/29568)
Epoch: 28 | Batch_idx: 240 |  Loss: (0.6229) |  Loss2: (0.0000) | Acc: (78.00%) (24123/30848)
Epoch: 28 | Batch_idx: 250 |  Loss: (0.6223) |  Loss2: (0.0000) | Acc: (78.00%) (25114/32128)
Epoch: 28 | Batch_idx: 260 |  Loss: (0.6222) |  Loss2: (0.0000) | Acc: (78.00%) (26124/33408)
Epoch: 28 | Batch_idx: 270 |  Loss: (0.6214) |  Loss2: (0.0000) | Acc: (78.00%) (27141/34688)
Epoch: 28 | Batch_idx: 280 |  Loss: (0.6192) |  Loss2: (0.0000) | Acc: (78.00%) (28198/35968)
Epoch: 28 | Batch_idx: 290 |  Loss: (0.6204) |  Loss2: (0.0000) | Acc: (78.00%) (29188/37248)
Epoch: 28 | Batch_idx: 300 |  Loss: (0.6201) |  Loss2: (0.0000) | Acc: (78.00%) (30190/38528)
Epoch: 28 | Batch_idx: 310 |  Loss: (0.6190) |  Loss2: (0.0000) | Acc: (78.00%) (31204/39808)
Epoch: 28 | Batch_idx: 320 |  Loss: (0.6183) |  Loss2: (0.0000) | Acc: (78.00%) (32219/41088)
Epoch: 28 | Batch_idx: 330 |  Loss: (0.6181) |  Loss2: (0.0000) | Acc: (78.00%) (33223/42368)
Epoch: 28 | Batch_idx: 340 |  Loss: (0.6178) |  Loss2: (0.0000) | Acc: (78.00%) (34233/43648)
Epoch: 28 | Batch_idx: 350 |  Loss: (0.6183) |  Loss2: (0.0000) | Acc: (78.00%) (35239/44928)
Epoch: 28 | Batch_idx: 360 |  Loss: (0.6192) |  Loss2: (0.0000) | Acc: (78.00%) (36240/46208)
Epoch: 28 | Batch_idx: 370 |  Loss: (0.6182) |  Loss2: (0.0000) | Acc: (78.00%) (37262/47488)
Epoch: 28 | Batch_idx: 380 |  Loss: (0.6185) |  Loss2: (0.0000) | Acc: (78.00%) (38254/48768)
Epoch: 28 | Batch_idx: 390 |  Loss: (0.6187) |  Loss2: (0.0000) | Acc: (78.00%) (39218/50000)
# TEST : Loss: (0.6421) | Acc: (77.00%) (7773/10000)
percent tensor([0.4903, 0.4843, 0.4937, 0.4941, 0.4906, 0.4897, 0.4864, 0.4928, 0.4891,
        0.4880, 0.4881, 0.4913, 0.4893, 0.4850, 0.4870, 0.4902],
       device='cuda:0') torch.Size([16])
percent tensor([0.4966, 0.5046, 0.4863, 0.4916, 0.4872, 0.4983, 0.4980, 0.4901, 0.4948,
        0.4960, 0.4992, 0.4879, 0.4966, 0.5095, 0.4989, 0.4979],
       device='cuda:0') torch.Size([16])
percent tensor([0.4771, 0.4803, 0.5054, 0.4591, 0.4969, 0.4451, 0.4992, 0.4898, 0.4734,
        0.4832, 0.4730, 0.5055, 0.4891, 0.4279, 0.4885, 0.4604],
       device='cuda:0') torch.Size([16])
percent tensor([0.6129, 0.6150, 0.6116, 0.6062, 0.6210, 0.6135, 0.6285, 0.6186, 0.6132,
        0.6174, 0.6199, 0.6147, 0.6059, 0.6248, 0.6224, 0.6155],
       device='cuda:0') torch.Size([16])
percent tensor([0.5776, 0.5340, 0.6110, 0.6013, 0.6086, 0.6135, 0.5712, 0.6002, 0.5722,
        0.5539, 0.5526, 0.5826, 0.5404, 0.5691, 0.5831, 0.5833],
       device='cuda:0') torch.Size([16])
percent tensor([0.4977, 0.5003, 0.5208, 0.5539, 0.4945, 0.5411, 0.4879, 0.4550, 0.5424,
        0.5141, 0.5326, 0.5265, 0.5133, 0.5709, 0.3921, 0.5072],
       device='cuda:0') torch.Size([16])
percent tensor([0.6118, 0.5651, 0.6973, 0.7209, 0.6975, 0.6242, 0.6339, 0.6982, 0.6021,
        0.6144, 0.5935, 0.6887, 0.5553, 0.6104, 0.6530, 0.6405],
       device='cuda:0') torch.Size([16])
percent tensor([0.9940, 0.9794, 0.9862, 0.9886, 0.9830, 0.9825, 0.9920, 0.9914, 0.9809,
        0.9862, 0.9842, 0.9848, 0.9818, 0.9867, 0.9872, 0.9943],
       device='cuda:0') torch.Size([16])
Epoch: 29 | Batch_idx: 0 |  Loss: (0.6095) |  Loss2: (0.0000) | Acc: (80.00%) (103/128)
Epoch: 29 | Batch_idx: 10 |  Loss: (0.6037) |  Loss2: (0.0000) | Acc: (78.00%) (1112/1408)
Epoch: 29 | Batch_idx: 20 |  Loss: (0.6063) |  Loss2: (0.0000) | Acc: (79.00%) (2134/2688)
Epoch: 29 | Batch_idx: 30 |  Loss: (0.6241) |  Loss2: (0.0000) | Acc: (78.00%) (3115/3968)
Epoch: 29 | Batch_idx: 40 |  Loss: (0.6249) |  Loss2: (0.0000) | Acc: (78.00%) (4109/5248)
Epoch: 29 | Batch_idx: 50 |  Loss: (0.6217) |  Loss2: (0.0000) | Acc: (78.00%) (5126/6528)
Epoch: 29 | Batch_idx: 60 |  Loss: (0.6243) |  Loss2: (0.0000) | Acc: (78.00%) (6140/7808)
Epoch: 29 | Batch_idx: 70 |  Loss: (0.6208) |  Loss2: (0.0000) | Acc: (78.00%) (7159/9088)
Epoch: 29 | Batch_idx: 80 |  Loss: (0.6202) |  Loss2: (0.0000) | Acc: (78.00%) (8165/10368)
Epoch: 29 | Batch_idx: 90 |  Loss: (0.6181) |  Loss2: (0.0000) | Acc: (78.00%) (9167/11648)
Epoch: 29 | Batch_idx: 100 |  Loss: (0.6147) |  Loss2: (0.0000) | Acc: (78.00%) (10189/12928)
Epoch: 29 | Batch_idx: 110 |  Loss: (0.6137) |  Loss2: (0.0000) | Acc: (78.00%) (11195/14208)
Epoch: 29 | Batch_idx: 120 |  Loss: (0.6104) |  Loss2: (0.0000) | Acc: (78.00%) (12213/15488)
Epoch: 29 | Batch_idx: 130 |  Loss: (0.6086) |  Loss2: (0.0000) | Acc: (78.00%) (13223/16768)
Epoch: 29 | Batch_idx: 140 |  Loss: (0.6082) |  Loss2: (0.0000) | Acc: (78.00%) (14228/18048)
Epoch: 29 | Batch_idx: 150 |  Loss: (0.6087) |  Loss2: (0.0000) | Acc: (78.00%) (15240/19328)
Epoch: 29 | Batch_idx: 160 |  Loss: (0.6093) |  Loss2: (0.0000) | Acc: (78.00%) (16266/20608)
Epoch: 29 | Batch_idx: 170 |  Loss: (0.6092) |  Loss2: (0.0000) | Acc: (78.00%) (17275/21888)
Epoch: 29 | Batch_idx: 180 |  Loss: (0.6081) |  Loss2: (0.0000) | Acc: (78.00%) (18293/23168)
Epoch: 29 | Batch_idx: 190 |  Loss: (0.6098) |  Loss2: (0.0000) | Acc: (78.00%) (19272/24448)
Epoch: 29 | Batch_idx: 200 |  Loss: (0.6101) |  Loss2: (0.0000) | Acc: (78.00%) (20273/25728)
Epoch: 29 | Batch_idx: 210 |  Loss: (0.6091) |  Loss2: (0.0000) | Acc: (78.00%) (21289/27008)
Epoch: 29 | Batch_idx: 220 |  Loss: (0.6091) |  Loss2: (0.0000) | Acc: (78.00%) (22305/28288)
Epoch: 29 | Batch_idx: 230 |  Loss: (0.6080) |  Loss2: (0.0000) | Acc: (78.00%) (23321/29568)
Epoch: 29 | Batch_idx: 240 |  Loss: (0.6079) |  Loss2: (0.0000) | Acc: (78.00%) (24330/30848)
Epoch: 29 | Batch_idx: 250 |  Loss: (0.6076) |  Loss2: (0.0000) | Acc: (78.00%) (25352/32128)
Epoch: 29 | Batch_idx: 260 |  Loss: (0.6069) |  Loss2: (0.0000) | Acc: (78.00%) (26370/33408)
Epoch: 29 | Batch_idx: 270 |  Loss: (0.6056) |  Loss2: (0.0000) | Acc: (78.00%) (27394/34688)
Epoch: 29 | Batch_idx: 280 |  Loss: (0.6058) |  Loss2: (0.0000) | Acc: (78.00%) (28408/35968)
Epoch: 29 | Batch_idx: 290 |  Loss: (0.6081) |  Loss2: (0.0000) | Acc: (78.00%) (29369/37248)
Epoch: 29 | Batch_idx: 300 |  Loss: (0.6096) |  Loss2: (0.0000) | Acc: (78.00%) (30370/38528)
Epoch: 29 | Batch_idx: 310 |  Loss: (0.6100) |  Loss2: (0.0000) | Acc: (78.00%) (31367/39808)
Epoch: 29 | Batch_idx: 320 |  Loss: (0.6105) |  Loss2: (0.0000) | Acc: (78.00%) (32368/41088)
Epoch: 29 | Batch_idx: 330 |  Loss: (0.6096) |  Loss2: (0.0000) | Acc: (78.00%) (33385/42368)
Epoch: 29 | Batch_idx: 340 |  Loss: (0.6099) |  Loss2: (0.0000) | Acc: (78.00%) (34385/43648)
Epoch: 29 | Batch_idx: 350 |  Loss: (0.6096) |  Loss2: (0.0000) | Acc: (78.00%) (35401/44928)
Epoch: 29 | Batch_idx: 360 |  Loss: (0.6093) |  Loss2: (0.0000) | Acc: (78.00%) (36407/46208)
Epoch: 29 | Batch_idx: 370 |  Loss: (0.6098) |  Loss2: (0.0000) | Acc: (78.00%) (37409/47488)
Epoch: 29 | Batch_idx: 380 |  Loss: (0.6104) |  Loss2: (0.0000) | Acc: (78.00%) (38401/48768)
Epoch: 29 | Batch_idx: 390 |  Loss: (0.6102) |  Loss2: (0.0000) | Acc: (78.00%) (39379/50000)
# TEST : Loss: (0.6367) | Acc: (78.00%) (7801/10000)
percent tensor([0.4907, 0.4845, 0.4949, 0.4948, 0.4916, 0.4898, 0.4868, 0.4938, 0.4898,
        0.4887, 0.4885, 0.4923, 0.4899, 0.4850, 0.4872, 0.4905],
       device='cuda:0') torch.Size([16])
percent tensor([0.4971, 0.5053, 0.4871, 0.4926, 0.4879, 0.4987, 0.4987, 0.4912, 0.4953,
        0.4968, 0.4995, 0.4888, 0.4971, 0.5102, 0.4996, 0.4987],
       device='cuda:0') torch.Size([16])
percent tensor([0.4802, 0.4823, 0.5107, 0.4623, 0.5024, 0.4478, 0.5036, 0.4947, 0.4742,
        0.4853, 0.4746, 0.5092, 0.4918, 0.4256, 0.4933, 0.4623],
       device='cuda:0') torch.Size([16])
percent tensor([0.6110, 0.6132, 0.6091, 0.6033, 0.6186, 0.6117, 0.6271, 0.6153, 0.6117,
        0.6151, 0.6177, 0.6123, 0.6033, 0.6256, 0.6199, 0.6132],
       device='cuda:0') torch.Size([16])
percent tensor([0.5830, 0.5413, 0.6145, 0.6020, 0.6110, 0.6189, 0.5771, 0.6025, 0.5768,
        0.5603, 0.5568, 0.5874, 0.5460, 0.5761, 0.5890, 0.5899],
       device='cuda:0') torch.Size([16])
percent tensor([0.5014, 0.5045, 0.5264, 0.5578, 0.4988, 0.5438, 0.4910, 0.4573, 0.5466,
        0.5179, 0.5336, 0.5318, 0.5177, 0.5747, 0.3909, 0.5111],
       device='cuda:0') torch.Size([16])
percent tensor([0.6106, 0.5699, 0.7017, 0.7231, 0.7021, 0.6191, 0.6364, 0.7016, 0.6074,
        0.6200, 0.5964, 0.6948, 0.5566, 0.6143, 0.6592, 0.6377],
       device='cuda:0') torch.Size([16])
percent tensor([0.9950, 0.9827, 0.9886, 0.9905, 0.9856, 0.9853, 0.9933, 0.9928, 0.9845,
        0.9888, 0.9869, 0.9873, 0.9850, 0.9891, 0.9893, 0.9953],
       device='cuda:0') torch.Size([16])
True Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=128, out_features=16, bias=False)
False Linear(in_features=16, out_features=2, bias=False)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=128, out_features=16, bias=False)
False Linear(in_features=16, out_features=2, bias=False)
True Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=256, out_features=32, bias=False)
False Linear(in_features=32, out_features=2, bias=False)
True Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=256, out_features=32, bias=False)
False Linear(in_features=32, out_features=2, bias=False)
True Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=512, out_features=64, bias=False)
False Linear(in_features=64, out_features=2, bias=False)
True Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=512, out_features=64, bias=False)
False Linear(in_features=64, out_features=2, bias=False)
True Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1024, out_features=128, bias=False)
False Linear(in_features=128, out_features=2, bias=False)
True Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1024, out_features=128, bias=False)
False Linear(in_features=128, out_features=2, bias=False)
True Linear(in_features=512, out_features=10, bias=True)
Epoch: 30 | Batch_idx: 0 |  Loss: (0.7991) |  Loss2: (0.0000) | Acc: (66.00%) (85/128)
Epoch: 30 | Batch_idx: 10 |  Loss: (0.6580) |  Loss2: (0.0000) | Acc: (75.00%) (1066/1408)
Epoch: 30 | Batch_idx: 20 |  Loss: (0.6490) |  Loss2: (0.0000) | Acc: (76.00%) (2049/2688)
Epoch: 30 | Batch_idx: 30 |  Loss: (0.6367) |  Loss2: (0.0000) | Acc: (77.00%) (3056/3968)
Epoch: 30 | Batch_idx: 40 |  Loss: (0.6322) |  Loss2: (0.0000) | Acc: (77.00%) (4061/5248)
Epoch: 30 | Batch_idx: 50 |  Loss: (0.6244) |  Loss2: (0.0000) | Acc: (77.00%) (5089/6528)
Epoch: 30 | Batch_idx: 60 |  Loss: (0.6233) |  Loss2: (0.0000) | Acc: (77.00%) (6087/7808)
Epoch: 30 | Batch_idx: 70 |  Loss: (0.6158) |  Loss2: (0.0000) | Acc: (78.00%) (7109/9088)
Epoch: 30 | Batch_idx: 80 |  Loss: (0.6193) |  Loss2: (0.0000) | Acc: (78.00%) (8092/10368)
Epoch: 30 | Batch_idx: 90 |  Loss: (0.6156) |  Loss2: (0.0000) | Acc: (78.00%) (9110/11648)
Epoch: 30 | Batch_idx: 100 |  Loss: (0.6152) |  Loss2: (0.0000) | Acc: (78.00%) (10126/12928)
Epoch: 30 | Batch_idx: 110 |  Loss: (0.6151) |  Loss2: (0.0000) | Acc: (78.00%) (11134/14208)
Epoch: 30 | Batch_idx: 120 |  Loss: (0.6172) |  Loss2: (0.0000) | Acc: (78.00%) (12127/15488)
Epoch: 30 | Batch_idx: 130 |  Loss: (0.6188) |  Loss2: (0.0000) | Acc: (78.00%) (13121/16768)
Epoch: 30 | Batch_idx: 140 |  Loss: (0.6209) |  Loss2: (0.0000) | Acc: (78.00%) (14109/18048)
Epoch: 30 | Batch_idx: 150 |  Loss: (0.6194) |  Loss2: (0.0000) | Acc: (78.00%) (15118/19328)
Epoch: 30 | Batch_idx: 160 |  Loss: (0.6196) |  Loss2: (0.0000) | Acc: (78.00%) (16129/20608)
Epoch: 30 | Batch_idx: 170 |  Loss: (0.6210) |  Loss2: (0.0000) | Acc: (78.00%) (17129/21888)
Epoch: 30 | Batch_idx: 180 |  Loss: (0.6234) |  Loss2: (0.0000) | Acc: (78.00%) (18093/23168)
Epoch: 30 | Batch_idx: 190 |  Loss: (0.6215) |  Loss2: (0.0000) | Acc: (78.00%) (19111/24448)
Epoch: 30 | Batch_idx: 200 |  Loss: (0.6208) |  Loss2: (0.0000) | Acc: (78.00%) (20120/25728)
Epoch: 30 | Batch_idx: 210 |  Loss: (0.6206) |  Loss2: (0.0000) | Acc: (78.00%) (21115/27008)
Epoch: 30 | Batch_idx: 220 |  Loss: (0.6198) |  Loss2: (0.0000) | Acc: (78.00%) (22125/28288)
Epoch: 30 | Batch_idx: 230 |  Loss: (0.6207) |  Loss2: (0.0000) | Acc: (78.00%) (23128/29568)
Epoch: 30 | Batch_idx: 240 |  Loss: (0.6187) |  Loss2: (0.0000) | Acc: (78.00%) (24146/30848)
Epoch: 30 | Batch_idx: 250 |  Loss: (0.6176) |  Loss2: (0.0000) | Acc: (78.00%) (25152/32128)
Epoch: 30 | Batch_idx: 260 |  Loss: (0.6179) |  Loss2: (0.0000) | Acc: (78.00%) (26168/33408)
Epoch: 30 | Batch_idx: 270 |  Loss: (0.6180) |  Loss2: (0.0000) | Acc: (78.00%) (27182/34688)
Epoch: 30 | Batch_idx: 280 |  Loss: (0.6162) |  Loss2: (0.0000) | Acc: (78.00%) (28210/35968)
Epoch: 30 | Batch_idx: 290 |  Loss: (0.6155) |  Loss2: (0.0000) | Acc: (78.00%) (29215/37248)
Epoch: 30 | Batch_idx: 300 |  Loss: (0.6159) |  Loss2: (0.0000) | Acc: (78.00%) (30218/38528)
Epoch: 30 | Batch_idx: 310 |  Loss: (0.6160) |  Loss2: (0.0000) | Acc: (78.00%) (31226/39808)
Epoch: 30 | Batch_idx: 320 |  Loss: (0.6156) |  Loss2: (0.0000) | Acc: (78.00%) (32228/41088)
Epoch: 30 | Batch_idx: 330 |  Loss: (0.6147) |  Loss2: (0.0000) | Acc: (78.00%) (33259/42368)
Epoch: 30 | Batch_idx: 340 |  Loss: (0.6146) |  Loss2: (0.0000) | Acc: (78.00%) (34257/43648)
Epoch: 30 | Batch_idx: 350 |  Loss: (0.6139) |  Loss2: (0.0000) | Acc: (78.00%) (35278/44928)
Epoch: 30 | Batch_idx: 360 |  Loss: (0.6120) |  Loss2: (0.0000) | Acc: (78.00%) (36318/46208)
Epoch: 30 | Batch_idx: 370 |  Loss: (0.6122) |  Loss2: (0.0000) | Acc: (78.00%) (37331/47488)
Epoch: 30 | Batch_idx: 380 |  Loss: (0.6106) |  Loss2: (0.0000) | Acc: (78.00%) (38360/48768)
Epoch: 30 | Batch_idx: 390 |  Loss: (0.6099) |  Loss2: (0.0000) | Acc: (78.00%) (39354/50000)
=> saving checkpoint 'drive/app/torch/save_Routing_Gate_2/checkpoint_030.pth.tar'
# TEST : Loss: (0.6213) | Acc: (78.00%) (7860/10000)
percent tensor([0.4912, 0.4844, 0.4963, 0.4956, 0.4932, 0.4900, 0.4877, 0.4945, 0.4905,
        0.4894, 0.4889, 0.4936, 0.4902, 0.4851, 0.4873, 0.4906],
       device='cuda:0') torch.Size([16])
percent tensor([0.4962, 0.5046, 0.4852, 0.4916, 0.4869, 0.4983, 0.4979, 0.4907, 0.4928,
        0.4956, 0.4985, 0.4883, 0.4962, 0.5079, 0.4998, 0.4981],
       device='cuda:0') torch.Size([16])
percent tensor([0.4808, 0.4840, 0.5031, 0.4617, 0.4960, 0.4441, 0.5006, 0.4966, 0.4759,
        0.4861, 0.4753, 0.5021, 0.4938, 0.4274, 0.4923, 0.4632],
       device='cuda:0') torch.Size([16])
percent tensor([0.6143, 0.6151, 0.6061, 0.6029, 0.6168, 0.6130, 0.6272, 0.6137, 0.6118,
        0.6183, 0.6224, 0.6147, 0.6047, 0.6268, 0.6229, 0.6138],
       device='cuda:0') torch.Size([16])
percent tensor([0.5781, 0.5441, 0.5969, 0.5917, 0.5981, 0.6114, 0.5828, 0.5972, 0.5846,
        0.5694, 0.5704, 0.5835, 0.5456, 0.5905, 0.5853, 0.5878],
       device='cuda:0') torch.Size([16])
percent tensor([0.5092, 0.5110, 0.5353, 0.5424, 0.5053, 0.5626, 0.4949, 0.4422, 0.5485,
        0.5108, 0.5506, 0.5167, 0.5255, 0.5884, 0.4034, 0.5113],
       device='cuda:0') torch.Size([16])
percent tensor([0.6207, 0.5863, 0.7103, 0.7173, 0.7031, 0.6313, 0.6533, 0.6958, 0.6209,
        0.6300, 0.6099, 0.7044, 0.5693, 0.6496, 0.6520, 0.6400],
       device='cuda:0') torch.Size([16])
percent tensor([0.9960, 0.9831, 0.9922, 0.9936, 0.9887, 0.9880, 0.9903, 0.9941, 0.9830,
        0.9894, 0.9895, 0.9908, 0.9849, 0.9892, 0.9902, 0.9948],
       device='cuda:0') torch.Size([16])
Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 3, 3, 3]) tensor(169.9191, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(786.7477, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(785.4124, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([128, 64, 3, 3]) tensor(1527.4688, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([128, 64, 1, 1]) tensor(506.7835, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([128, 128, 3, 3]) tensor(2183.5481, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([256, 128, 3, 3]) tensor(4304.3662, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([256, 128, 1, 1]) tensor(1429.7396, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([256, 256, 3, 3]) tensor(6076.3530, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([512, 256, 3, 3]) tensor(12134.5293, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([512, 256, 1, 1]) tensor(4048.7144, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([512, 512, 3, 3]) tensor(17118.2617, device='cuda:0', grad_fn=<NormBackward0>)
Epoch: 31 | Batch_idx: 0 |  Loss: (0.5966) |  Loss2: (0.0000) | Acc: (76.00%) (98/128)
Epoch: 31 | Batch_idx: 10 |  Loss: (0.5903) |  Loss2: (0.0000) | Acc: (79.00%) (1121/1408)
Epoch: 31 | Batch_idx: 20 |  Loss: (0.5731) |  Loss2: (0.0000) | Acc: (80.00%) (2173/2688)
Epoch: 31 | Batch_idx: 30 |  Loss: (0.5706) |  Loss2: (0.0000) | Acc: (80.00%) (3206/3968)
Epoch: 31 | Batch_idx: 40 |  Loss: (0.5745) |  Loss2: (0.0000) | Acc: (80.00%) (4234/5248)
Epoch: 31 | Batch_idx: 50 |  Loss: (0.5702) |  Loss2: (0.0000) | Acc: (80.00%) (5271/6528)
Epoch: 31 | Batch_idx: 60 |  Loss: (0.5682) |  Loss2: (0.0000) | Acc: (80.00%) (6299/7808)
Epoch: 31 | Batch_idx: 70 |  Loss: (0.5699) |  Loss2: (0.0000) | Acc: (80.00%) (7336/9088)
Epoch: 31 | Batch_idx: 80 |  Loss: (0.5688) |  Loss2: (0.0000) | Acc: (80.00%) (8364/10368)
Epoch: 31 | Batch_idx: 90 |  Loss: (0.5716) |  Loss2: (0.0000) | Acc: (80.00%) (9392/11648)
Epoch: 31 | Batch_idx: 100 |  Loss: (0.5706) |  Loss2: (0.0000) | Acc: (80.00%) (10413/12928)
Epoch: 31 | Batch_idx: 110 |  Loss: (0.5737) |  Loss2: (0.0000) | Acc: (80.00%) (11432/14208)
Epoch: 31 | Batch_idx: 120 |  Loss: (0.5734) |  Loss2: (0.0000) | Acc: (80.00%) (12446/15488)
Epoch: 31 | Batch_idx: 130 |  Loss: (0.5739) |  Loss2: (0.0000) | Acc: (80.00%) (13458/16768)
Epoch: 31 | Batch_idx: 140 |  Loss: (0.5742) |  Loss2: (0.0000) | Acc: (80.00%) (14481/18048)
Epoch: 31 | Batch_idx: 150 |  Loss: (0.5757) |  Loss2: (0.0000) | Acc: (80.00%) (15502/19328)
Epoch: 31 | Batch_idx: 160 |  Loss: (0.5748) |  Loss2: (0.0000) | Acc: (80.00%) (16539/20608)
Epoch: 31 | Batch_idx: 170 |  Loss: (0.5738) |  Loss2: (0.0000) | Acc: (80.00%) (17579/21888)
Epoch: 31 | Batch_idx: 180 |  Loss: (0.5750) |  Loss2: (0.0000) | Acc: (80.00%) (18579/23168)
Epoch: 31 | Batch_idx: 190 |  Loss: (0.5753) |  Loss2: (0.0000) | Acc: (80.00%) (19596/24448)
Epoch: 31 | Batch_idx: 200 |  Loss: (0.5752) |  Loss2: (0.0000) | Acc: (80.00%) (20615/25728)
Epoch: 31 | Batch_idx: 210 |  Loss: (0.5738) |  Loss2: (0.0000) | Acc: (80.00%) (21656/27008)
Epoch: 31 | Batch_idx: 220 |  Loss: (0.5753) |  Loss2: (0.0000) | Acc: (80.00%) (22674/28288)
Epoch: 31 | Batch_idx: 230 |  Loss: (0.5753) |  Loss2: (0.0000) | Acc: (80.00%) (23707/29568)
Epoch: 31 | Batch_idx: 240 |  Loss: (0.5770) |  Loss2: (0.0000) | Acc: (80.00%) (24711/30848)
Epoch: 31 | Batch_idx: 250 |  Loss: (0.5768) |  Loss2: (0.0000) | Acc: (80.00%) (25736/32128)
Epoch: 31 | Batch_idx: 260 |  Loss: (0.5762) |  Loss2: (0.0000) | Acc: (80.00%) (26771/33408)
Epoch: 31 | Batch_idx: 270 |  Loss: (0.5741) |  Loss2: (0.0000) | Acc: (80.00%) (27823/34688)
Epoch: 31 | Batch_idx: 280 |  Loss: (0.5752) |  Loss2: (0.0000) | Acc: (80.00%) (28823/35968)
Epoch: 31 | Batch_idx: 290 |  Loss: (0.5764) |  Loss2: (0.0000) | Acc: (80.00%) (29826/37248)
Epoch: 31 | Batch_idx: 300 |  Loss: (0.5755) |  Loss2: (0.0000) | Acc: (80.00%) (30875/38528)
Epoch: 31 | Batch_idx: 310 |  Loss: (0.5759) |  Loss2: (0.0000) | Acc: (80.00%) (31890/39808)
Epoch: 31 | Batch_idx: 320 |  Loss: (0.5745) |  Loss2: (0.0000) | Acc: (80.00%) (32947/41088)
Epoch: 31 | Batch_idx: 330 |  Loss: (0.5740) |  Loss2: (0.0000) | Acc: (80.00%) (33992/42368)
Epoch: 31 | Batch_idx: 340 |  Loss: (0.5739) |  Loss2: (0.0000) | Acc: (80.00%) (35026/43648)
Epoch: 31 | Batch_idx: 350 |  Loss: (0.5752) |  Loss2: (0.0000) | Acc: (80.00%) (36036/44928)
Epoch: 31 | Batch_idx: 360 |  Loss: (0.5759) |  Loss2: (0.0000) | Acc: (80.00%) (37047/46208)
Epoch: 31 | Batch_idx: 370 |  Loss: (0.5756) |  Loss2: (0.0000) | Acc: (80.00%) (38078/47488)
Epoch: 31 | Batch_idx: 380 |  Loss: (0.5753) |  Loss2: (0.0000) | Acc: (80.00%) (39112/48768)
Epoch: 31 | Batch_idx: 390 |  Loss: (0.5753) |  Loss2: (0.0000) | Acc: (80.00%) (40102/50000)
# TEST : Loss: (0.5987) | Acc: (79.00%) (7919/10000)
percent tensor([0.4911, 0.4844, 0.4963, 0.4949, 0.4926, 0.4897, 0.4870, 0.4940, 0.4902,
        0.4890, 0.4885, 0.4926, 0.4897, 0.4846, 0.4872, 0.4902],
       device='cuda:0') torch.Size([16])
percent tensor([0.4969, 0.5049, 0.4872, 0.4915, 0.4882, 0.4989, 0.4982, 0.4909, 0.4942,
        0.4970, 0.4995, 0.4892, 0.4970, 0.5074, 0.4995, 0.4979],
       device='cuda:0') torch.Size([16])
percent tensor([0.4852, 0.4847, 0.5129, 0.4654, 0.5033, 0.4484, 0.5019, 0.5019, 0.4786,
        0.4909, 0.4798, 0.5159, 0.5002, 0.4293, 0.4936, 0.4651],
       device='cuda:0') torch.Size([16])
percent tensor([0.6148, 0.6125, 0.6101, 0.6068, 0.6194, 0.6104, 0.6237, 0.6187, 0.6142,
        0.6153, 0.6203, 0.6134, 0.6042, 0.6210, 0.6209, 0.6138],
       device='cuda:0') torch.Size([16])
percent tensor([0.5843, 0.5407, 0.5953, 0.5885, 0.5968, 0.6154, 0.5750, 0.5920, 0.5826,
        0.5624, 0.5692, 0.5756, 0.5493, 0.5782, 0.5888, 0.5875],
       device='cuda:0') torch.Size([16])
percent tensor([0.5162, 0.5255, 0.5273, 0.5340, 0.5072, 0.5361, 0.5095, 0.4484, 0.5605,
        0.5319, 0.5635, 0.5320, 0.5527, 0.5957, 0.4130, 0.5127],
       device='cuda:0') torch.Size([16])
percent tensor([0.6049, 0.5708, 0.7005, 0.7165, 0.6908, 0.6206, 0.6279, 0.6853, 0.6069,
        0.6102, 0.5986, 0.6855, 0.5580, 0.6262, 0.6394, 0.6371],
       device='cuda:0') torch.Size([16])
percent tensor([0.9954, 0.9858, 0.9894, 0.9899, 0.9814, 0.9880, 0.9937, 0.9932, 0.9839,
        0.9889, 0.9904, 0.9885, 0.9834, 0.9867, 0.9890, 0.9954],
       device='cuda:0') torch.Size([16])
Epoch: 32 | Batch_idx: 0 |  Loss: (0.6765) |  Loss2: (0.0000) | Acc: (74.00%) (95/128)
Epoch: 32 | Batch_idx: 10 |  Loss: (0.5451) |  Loss2: (0.0000) | Acc: (80.00%) (1128/1408)
Epoch: 32 | Batch_idx: 20 |  Loss: (0.5567) |  Loss2: (0.0000) | Acc: (80.00%) (2163/2688)
Epoch: 32 | Batch_idx: 30 |  Loss: (0.5692) |  Loss2: (0.0000) | Acc: (80.00%) (3177/3968)
Epoch: 32 | Batch_idx: 40 |  Loss: (0.5646) |  Loss2: (0.0000) | Acc: (80.00%) (4210/5248)
Epoch: 32 | Batch_idx: 50 |  Loss: (0.5670) |  Loss2: (0.0000) | Acc: (80.00%) (5242/6528)
Epoch: 32 | Batch_idx: 60 |  Loss: (0.5686) |  Loss2: (0.0000) | Acc: (80.00%) (6270/7808)
Epoch: 32 | Batch_idx: 70 |  Loss: (0.5604) |  Loss2: (0.0000) | Acc: (80.00%) (7337/9088)
Epoch: 32 | Batch_idx: 80 |  Loss: (0.5608) |  Loss2: (0.0000) | Acc: (80.00%) (8364/10368)
Epoch: 32 | Batch_idx: 90 |  Loss: (0.5640) |  Loss2: (0.0000) | Acc: (80.00%) (9367/11648)
Epoch: 32 | Batch_idx: 100 |  Loss: (0.5604) |  Loss2: (0.0000) | Acc: (80.00%) (10421/12928)
Epoch: 32 | Batch_idx: 110 |  Loss: (0.5622) |  Loss2: (0.0000) | Acc: (80.00%) (11434/14208)
Epoch: 32 | Batch_idx: 120 |  Loss: (0.5612) |  Loss2: (0.0000) | Acc: (80.00%) (12463/15488)
Epoch: 32 | Batch_idx: 130 |  Loss: (0.5612) |  Loss2: (0.0000) | Acc: (80.00%) (13488/16768)
Epoch: 32 | Batch_idx: 140 |  Loss: (0.5616) |  Loss2: (0.0000) | Acc: (80.00%) (14502/18048)
Epoch: 32 | Batch_idx: 150 |  Loss: (0.5612) |  Loss2: (0.0000) | Acc: (80.00%) (15537/19328)
Epoch: 32 | Batch_idx: 160 |  Loss: (0.5594) |  Loss2: (0.0000) | Acc: (80.00%) (16577/20608)
Epoch: 32 | Batch_idx: 170 |  Loss: (0.5587) |  Loss2: (0.0000) | Acc: (80.00%) (17614/21888)
Epoch: 32 | Batch_idx: 180 |  Loss: (0.5563) |  Loss2: (0.0000) | Acc: (80.00%) (18656/23168)
Epoch: 32 | Batch_idx: 190 |  Loss: (0.5567) |  Loss2: (0.0000) | Acc: (80.00%) (19682/24448)
Epoch: 32 | Batch_idx: 200 |  Loss: (0.5573) |  Loss2: (0.0000) | Acc: (80.00%) (20699/25728)
Epoch: 32 | Batch_idx: 210 |  Loss: (0.5562) |  Loss2: (0.0000) | Acc: (80.00%) (21744/27008)
Epoch: 32 | Batch_idx: 220 |  Loss: (0.5558) |  Loss2: (0.0000) | Acc: (80.00%) (22763/28288)
Epoch: 32 | Batch_idx: 230 |  Loss: (0.5550) |  Loss2: (0.0000) | Acc: (80.00%) (23805/29568)
Epoch: 32 | Batch_idx: 240 |  Loss: (0.5548) |  Loss2: (0.0000) | Acc: (80.00%) (24831/30848)
Epoch: 32 | Batch_idx: 250 |  Loss: (0.5539) |  Loss2: (0.0000) | Acc: (80.00%) (25870/32128)
Epoch: 32 | Batch_idx: 260 |  Loss: (0.5536) |  Loss2: (0.0000) | Acc: (80.00%) (26934/33408)
Epoch: 32 | Batch_idx: 270 |  Loss: (0.5532) |  Loss2: (0.0000) | Acc: (80.00%) (27979/34688)
Epoch: 32 | Batch_idx: 280 |  Loss: (0.5529) |  Loss2: (0.0000) | Acc: (80.00%) (29013/35968)
Epoch: 32 | Batch_idx: 290 |  Loss: (0.5514) |  Loss2: (0.0000) | Acc: (80.00%) (30072/37248)
Epoch: 32 | Batch_idx: 300 |  Loss: (0.5509) |  Loss2: (0.0000) | Acc: (80.00%) (31105/38528)
Epoch: 32 | Batch_idx: 310 |  Loss: (0.5493) |  Loss2: (0.0000) | Acc: (80.00%) (32166/39808)
Epoch: 32 | Batch_idx: 320 |  Loss: (0.5489) |  Loss2: (0.0000) | Acc: (80.00%) (33206/41088)
Epoch: 32 | Batch_idx: 330 |  Loss: (0.5481) |  Loss2: (0.0000) | Acc: (80.00%) (34248/42368)
Epoch: 32 | Batch_idx: 340 |  Loss: (0.5473) |  Loss2: (0.0000) | Acc: (80.00%) (35295/43648)
Epoch: 32 | Batch_idx: 350 |  Loss: (0.5467) |  Loss2: (0.0000) | Acc: (80.00%) (36337/44928)
Epoch: 32 | Batch_idx: 360 |  Loss: (0.5466) |  Loss2: (0.0000) | Acc: (80.00%) (37386/46208)
Epoch: 32 | Batch_idx: 370 |  Loss: (0.5463) |  Loss2: (0.0000) | Acc: (80.00%) (38434/47488)
Epoch: 32 | Batch_idx: 380 |  Loss: (0.5461) |  Loss2: (0.0000) | Acc: (80.00%) (39470/48768)
Epoch: 32 | Batch_idx: 390 |  Loss: (0.5465) |  Loss2: (0.0000) | Acc: (80.00%) (40468/50000)
# TEST : Loss: (0.7151) | Acc: (76.00%) (7639/10000)
percent tensor([0.4908, 0.4844, 0.4960, 0.4950, 0.4926, 0.4897, 0.4871, 0.4940, 0.4901,
        0.4888, 0.4888, 0.4922, 0.4896, 0.4852, 0.4874, 0.4904],
       device='cuda:0') torch.Size([16])
percent tensor([0.4969, 0.5048, 0.4874, 0.4917, 0.4881, 0.4984, 0.4987, 0.4920, 0.4927,
        0.4978, 0.4991, 0.4911, 0.4970, 0.5065, 0.5002, 0.4985],
       device='cuda:0') torch.Size([16])
percent tensor([0.4839, 0.4854, 0.5019, 0.4711, 0.4922, 0.4544, 0.5003, 0.4968, 0.4704,
        0.4853, 0.4717, 0.5020, 0.4975, 0.4283, 0.4945, 0.4698],
       device='cuda:0') torch.Size([16])
percent tensor([0.6126, 0.6116, 0.6062, 0.6039, 0.6155, 0.6076, 0.6236, 0.6158, 0.6156,
        0.6146, 0.6234, 0.6132, 0.6025, 0.6221, 0.6193, 0.6123],
       device='cuda:0') torch.Size([16])
percent tensor([0.5794, 0.5430, 0.5958, 0.5877, 0.5938, 0.6178, 0.5759, 0.5978, 0.5922,
        0.5618, 0.5793, 0.5696, 0.5455, 0.5850, 0.5888, 0.5913],
       device='cuda:0') torch.Size([16])
percent tensor([0.4940, 0.5048, 0.5347, 0.5213, 0.5158, 0.5397, 0.5037, 0.4414, 0.5570,
        0.5076, 0.5398, 0.5313, 0.5154, 0.5889, 0.4047, 0.4914],
       device='cuda:0') torch.Size([16])
percent tensor([0.6175, 0.5854, 0.6960, 0.7143, 0.7007, 0.6369, 0.6311, 0.6889, 0.6334,
        0.6242, 0.6187, 0.6863, 0.5658, 0.6485, 0.6409, 0.6451],
       device='cuda:0') torch.Size([16])
percent tensor([0.9967, 0.9836, 0.9925, 0.9939, 0.9876, 0.9904, 0.9920, 0.9939, 0.9821,
        0.9914, 0.9893, 0.9905, 0.9854, 0.9913, 0.9898, 0.9955],
       device='cuda:0') torch.Size([16])
Epoch: 33 | Batch_idx: 0 |  Loss: (0.4208) |  Loss2: (0.0000) | Acc: (83.00%) (107/128)
Epoch: 33 | Batch_idx: 10 |  Loss: (0.5142) |  Loss2: (0.0000) | Acc: (80.00%) (1136/1408)
Epoch: 33 | Batch_idx: 20 |  Loss: (0.5417) |  Loss2: (0.0000) | Acc: (80.00%) (2165/2688)
Epoch: 33 | Batch_idx: 30 |  Loss: (0.5339) |  Loss2: (0.0000) | Acc: (81.00%) (3220/3968)
Epoch: 33 | Batch_idx: 40 |  Loss: (0.5456) |  Loss2: (0.0000) | Acc: (80.00%) (4250/5248)
Epoch: 33 | Batch_idx: 50 |  Loss: (0.5340) |  Loss2: (0.0000) | Acc: (81.00%) (5313/6528)
Epoch: 33 | Batch_idx: 60 |  Loss: (0.5352) |  Loss2: (0.0000) | Acc: (81.00%) (6341/7808)
Epoch: 33 | Batch_idx: 70 |  Loss: (0.5307) |  Loss2: (0.0000) | Acc: (81.00%) (7396/9088)
Epoch: 33 | Batch_idx: 80 |  Loss: (0.5335) |  Loss2: (0.0000) | Acc: (81.00%) (8429/10368)
Epoch: 33 | Batch_idx: 90 |  Loss: (0.5382) |  Loss2: (0.0000) | Acc: (81.00%) (9453/11648)
Epoch: 33 | Batch_idx: 100 |  Loss: (0.5354) |  Loss2: (0.0000) | Acc: (81.00%) (10505/12928)
Epoch: 33 | Batch_idx: 110 |  Loss: (0.5343) |  Loss2: (0.0000) | Acc: (81.00%) (11568/14208)
Epoch: 33 | Batch_idx: 120 |  Loss: (0.5299) |  Loss2: (0.0000) | Acc: (81.00%) (12644/15488)
Epoch: 33 | Batch_idx: 130 |  Loss: (0.5262) |  Loss2: (0.0000) | Acc: (81.00%) (13701/16768)
Epoch: 33 | Batch_idx: 140 |  Loss: (0.5244) |  Loss2: (0.0000) | Acc: (81.00%) (14754/18048)
Epoch: 33 | Batch_idx: 150 |  Loss: (0.5242) |  Loss2: (0.0000) | Acc: (81.00%) (15804/19328)
Epoch: 33 | Batch_idx: 160 |  Loss: (0.5248) |  Loss2: (0.0000) | Acc: (81.00%) (16839/20608)
Epoch: 33 | Batch_idx: 170 |  Loss: (0.5259) |  Loss2: (0.0000) | Acc: (81.00%) (17876/21888)
Epoch: 33 | Batch_idx: 180 |  Loss: (0.5258) |  Loss2: (0.0000) | Acc: (81.00%) (18916/23168)
Epoch: 33 | Batch_idx: 190 |  Loss: (0.5255) |  Loss2: (0.0000) | Acc: (81.00%) (19965/24448)
Epoch: 33 | Batch_idx: 200 |  Loss: (0.5278) |  Loss2: (0.0000) | Acc: (81.00%) (21003/25728)
Epoch: 33 | Batch_idx: 210 |  Loss: (0.5269) |  Loss2: (0.0000) | Acc: (81.00%) (22060/27008)
Epoch: 33 | Batch_idx: 220 |  Loss: (0.5272) |  Loss2: (0.0000) | Acc: (81.00%) (23095/28288)
Epoch: 33 | Batch_idx: 230 |  Loss: (0.5268) |  Loss2: (0.0000) | Acc: (81.00%) (24146/29568)
Epoch: 33 | Batch_idx: 240 |  Loss: (0.5268) |  Loss2: (0.0000) | Acc: (81.00%) (25189/30848)
Epoch: 33 | Batch_idx: 250 |  Loss: (0.5265) |  Loss2: (0.0000) | Acc: (81.00%) (26228/32128)
Epoch: 33 | Batch_idx: 260 |  Loss: (0.5249) |  Loss2: (0.0000) | Acc: (81.00%) (27284/33408)
Epoch: 33 | Batch_idx: 270 |  Loss: (0.5247) |  Loss2: (0.0000) | Acc: (81.00%) (28335/34688)
Epoch: 33 | Batch_idx: 280 |  Loss: (0.5254) |  Loss2: (0.0000) | Acc: (81.00%) (29380/35968)
Epoch: 33 | Batch_idx: 290 |  Loss: (0.5241) |  Loss2: (0.0000) | Acc: (81.00%) (30446/37248)
Epoch: 33 | Batch_idx: 300 |  Loss: (0.5238) |  Loss2: (0.0000) | Acc: (81.00%) (31510/38528)
Epoch: 33 | Batch_idx: 310 |  Loss: (0.5258) |  Loss2: (0.0000) | Acc: (81.00%) (32530/39808)
Epoch: 33 | Batch_idx: 320 |  Loss: (0.5271) |  Loss2: (0.0000) | Acc: (81.00%) (33554/41088)
Epoch: 33 | Batch_idx: 330 |  Loss: (0.5269) |  Loss2: (0.0000) | Acc: (81.00%) (34609/42368)
Epoch: 33 | Batch_idx: 340 |  Loss: (0.5266) |  Loss2: (0.0000) | Acc: (81.00%) (35667/43648)
Epoch: 33 | Batch_idx: 350 |  Loss: (0.5266) |  Loss2: (0.0000) | Acc: (81.00%) (36704/44928)
Epoch: 33 | Batch_idx: 360 |  Loss: (0.5261) |  Loss2: (0.0000) | Acc: (81.00%) (37751/46208)
Epoch: 33 | Batch_idx: 370 |  Loss: (0.5250) |  Loss2: (0.0000) | Acc: (81.00%) (38808/47488)
Epoch: 33 | Batch_idx: 380 |  Loss: (0.5245) |  Loss2: (0.0000) | Acc: (81.00%) (39868/48768)
Epoch: 33 | Batch_idx: 390 |  Loss: (0.5249) |  Loss2: (0.0000) | Acc: (81.00%) (40873/50000)
# TEST : Loss: (0.6489) | Acc: (77.00%) (7788/10000)
percent tensor([0.4907, 0.4849, 0.4967, 0.4954, 0.4929, 0.4896, 0.4875, 0.4944, 0.4901,
        0.4892, 0.4885, 0.4928, 0.4894, 0.4859, 0.4874, 0.4902],
       device='cuda:0') torch.Size([16])
percent tensor([0.4978, 0.5051, 0.4862, 0.4914, 0.4877, 0.4994, 0.4985, 0.4918, 0.4940,
        0.4973, 0.4999, 0.4882, 0.4976, 0.5075, 0.5007, 0.4993],
       device='cuda:0') torch.Size([16])
percent tensor([0.4885, 0.4879, 0.5016, 0.4683, 0.4942, 0.4541, 0.5026, 0.5032, 0.4794,
        0.4916, 0.4813, 0.5079, 0.5064, 0.4220, 0.4975, 0.4710],
       device='cuda:0') torch.Size([16])
percent tensor([0.6179, 0.6127, 0.6130, 0.6115, 0.6202, 0.6139, 0.6230, 0.6185, 0.6136,
        0.6152, 0.6217, 0.6157, 0.6041, 0.6227, 0.6233, 0.6163],
       device='cuda:0') torch.Size([16])
percent tensor([0.5855, 0.5396, 0.6050, 0.5986, 0.5975, 0.6214, 0.5761, 0.6005, 0.5797,
        0.5668, 0.5708, 0.5843, 0.5496, 0.5848, 0.5938, 0.5900],
       device='cuda:0') torch.Size([16])
percent tensor([0.4780, 0.5026, 0.5261, 0.5265, 0.5055, 0.5295, 0.4930, 0.4195, 0.5457,
        0.5015, 0.5369, 0.5360, 0.5037, 0.5932, 0.3994, 0.4996],
       device='cuda:0') torch.Size([16])
percent tensor([0.6144, 0.5908, 0.6879, 0.7037, 0.6861, 0.6368, 0.6295, 0.6730, 0.6013,
        0.6192, 0.6133, 0.6844, 0.5674, 0.6503, 0.6425, 0.6458],
       device='cuda:0') torch.Size([16])
percent tensor([0.9957, 0.9874, 0.9855, 0.9895, 0.9822, 0.9887, 0.9898, 0.9930, 0.9862,
        0.9897, 0.9902, 0.9875, 0.9852, 0.9921, 0.9901, 0.9942],
       device='cuda:0') torch.Size([16])
Epoch: 34 | Batch_idx: 0 |  Loss: (0.4413) |  Loss2: (0.0000) | Acc: (82.00%) (106/128)
Epoch: 34 | Batch_idx: 10 |  Loss: (0.4760) |  Loss2: (0.0000) | Acc: (83.00%) (1173/1408)
Epoch: 34 | Batch_idx: 20 |  Loss: (0.4940) |  Loss2: (0.0000) | Acc: (82.00%) (2228/2688)
Epoch: 34 | Batch_idx: 30 |  Loss: (0.5038) |  Loss2: (0.0000) | Acc: (82.00%) (3289/3968)
Epoch: 34 | Batch_idx: 40 |  Loss: (0.5079) |  Loss2: (0.0000) | Acc: (82.00%) (4323/5248)
Epoch: 34 | Batch_idx: 50 |  Loss: (0.5051) |  Loss2: (0.0000) | Acc: (82.00%) (5381/6528)
Epoch: 34 | Batch_idx: 60 |  Loss: (0.5117) |  Loss2: (0.0000) | Acc: (82.00%) (6420/7808)
Epoch: 34 | Batch_idx: 70 |  Loss: (0.5105) |  Loss2: (0.0000) | Acc: (82.00%) (7496/9088)
Epoch: 34 | Batch_idx: 80 |  Loss: (0.5057) |  Loss2: (0.0000) | Acc: (82.00%) (8564/10368)
Epoch: 34 | Batch_idx: 90 |  Loss: (0.5046) |  Loss2: (0.0000) | Acc: (82.00%) (9617/11648)
Epoch: 34 | Batch_idx: 100 |  Loss: (0.5072) |  Loss2: (0.0000) | Acc: (82.00%) (10662/12928)
Epoch: 34 | Batch_idx: 110 |  Loss: (0.5081) |  Loss2: (0.0000) | Acc: (82.00%) (11717/14208)
Epoch: 34 | Batch_idx: 120 |  Loss: (0.5057) |  Loss2: (0.0000) | Acc: (82.00%) (12789/15488)
Epoch: 34 | Batch_idx: 130 |  Loss: (0.5077) |  Loss2: (0.0000) | Acc: (82.00%) (13830/16768)
Epoch: 34 | Batch_idx: 140 |  Loss: (0.5050) |  Loss2: (0.0000) | Acc: (82.00%) (14900/18048)
Epoch: 34 | Batch_idx: 150 |  Loss: (0.5040) |  Loss2: (0.0000) | Acc: (82.00%) (15959/19328)
Epoch: 34 | Batch_idx: 160 |  Loss: (0.5036) |  Loss2: (0.0000) | Acc: (82.00%) (17039/20608)
Epoch: 34 | Batch_idx: 170 |  Loss: (0.5039) |  Loss2: (0.0000) | Acc: (82.00%) (18094/21888)
Epoch: 34 | Batch_idx: 180 |  Loss: (0.5051) |  Loss2: (0.0000) | Acc: (82.00%) (19134/23168)
Epoch: 34 | Batch_idx: 190 |  Loss: (0.5036) |  Loss2: (0.0000) | Acc: (82.00%) (20185/24448)
Epoch: 34 | Batch_idx: 200 |  Loss: (0.5042) |  Loss2: (0.0000) | Acc: (82.00%) (21231/25728)
Epoch: 34 | Batch_idx: 210 |  Loss: (0.5036) |  Loss2: (0.0000) | Acc: (82.00%) (22305/27008)
Epoch: 34 | Batch_idx: 220 |  Loss: (0.5038) |  Loss2: (0.0000) | Acc: (82.00%) (23364/28288)
Epoch: 34 | Batch_idx: 230 |  Loss: (0.5037) |  Loss2: (0.0000) | Acc: (82.00%) (24424/29568)
Epoch: 34 | Batch_idx: 240 |  Loss: (0.5058) |  Loss2: (0.0000) | Acc: (82.00%) (25464/30848)
Epoch: 34 | Batch_idx: 250 |  Loss: (0.5051) |  Loss2: (0.0000) | Acc: (82.00%) (26530/32128)
Epoch: 34 | Batch_idx: 260 |  Loss: (0.5059) |  Loss2: (0.0000) | Acc: (82.00%) (27582/33408)
Epoch: 34 | Batch_idx: 270 |  Loss: (0.5060) |  Loss2: (0.0000) | Acc: (82.00%) (28643/34688)
Epoch: 34 | Batch_idx: 280 |  Loss: (0.5063) |  Loss2: (0.0000) | Acc: (82.00%) (29698/35968)
Epoch: 34 | Batch_idx: 290 |  Loss: (0.5046) |  Loss2: (0.0000) | Acc: (82.00%) (30778/37248)
Epoch: 34 | Batch_idx: 300 |  Loss: (0.5044) |  Loss2: (0.0000) | Acc: (82.00%) (31849/38528)
Epoch: 34 | Batch_idx: 310 |  Loss: (0.5045) |  Loss2: (0.0000) | Acc: (82.00%) (32901/39808)
Epoch: 34 | Batch_idx: 320 |  Loss: (0.5057) |  Loss2: (0.0000) | Acc: (82.00%) (33938/41088)
Epoch: 34 | Batch_idx: 330 |  Loss: (0.5046) |  Loss2: (0.0000) | Acc: (82.00%) (35013/42368)
Epoch: 34 | Batch_idx: 340 |  Loss: (0.5044) |  Loss2: (0.0000) | Acc: (82.00%) (36080/43648)
Epoch: 34 | Batch_idx: 350 |  Loss: (0.5048) |  Loss2: (0.0000) | Acc: (82.00%) (37128/44928)
Epoch: 34 | Batch_idx: 360 |  Loss: (0.5043) |  Loss2: (0.0000) | Acc: (82.00%) (38209/46208)
Epoch: 34 | Batch_idx: 370 |  Loss: (0.5037) |  Loss2: (0.0000) | Acc: (82.00%) (39280/47488)
Epoch: 34 | Batch_idx: 380 |  Loss: (0.5036) |  Loss2: (0.0000) | Acc: (82.00%) (40340/48768)
Epoch: 34 | Batch_idx: 390 |  Loss: (0.5040) |  Loss2: (0.0000) | Acc: (82.00%) (41365/50000)
# TEST : Loss: (0.5899) | Acc: (79.00%) (7952/10000)
percent tensor([0.4909, 0.4852, 0.4960, 0.4954, 0.4931, 0.4897, 0.4877, 0.4943, 0.4904,
        0.4892, 0.4889, 0.4926, 0.4896, 0.4859, 0.4875, 0.4903],
       device='cuda:0') torch.Size([16])
percent tensor([0.4964, 0.5048, 0.4845, 0.4904, 0.4856, 0.4977, 0.4978, 0.4907, 0.4924,
        0.4965, 0.4990, 0.4876, 0.4968, 0.5074, 0.4999, 0.4984],
       device='cuda:0') torch.Size([16])
percent tensor([0.4920, 0.4892, 0.5206, 0.4814, 0.5087, 0.4623, 0.5080, 0.5064, 0.4778,
        0.4965, 0.4815, 0.5207, 0.5069, 0.4202, 0.5005, 0.4741],
       device='cuda:0') torch.Size([16])
percent tensor([0.6148, 0.6112, 0.6092, 0.6080, 0.6196, 0.6130, 0.6212, 0.6187, 0.6149,
        0.6139, 0.6202, 0.6125, 0.6034, 0.6227, 0.6213, 0.6149],
       device='cuda:0') torch.Size([16])
percent tensor([0.5761, 0.5350, 0.5920, 0.5901, 0.5910, 0.6177, 0.5736, 0.5922, 0.5791,
        0.5595, 0.5644, 0.5691, 0.5357, 0.5826, 0.5872, 0.5869],
       device='cuda:0') torch.Size([16])
percent tensor([0.4786, 0.4963, 0.5169, 0.5055, 0.5138, 0.5277, 0.4970, 0.4102, 0.5533,
        0.5076, 0.5268, 0.5385, 0.5174, 0.5876, 0.4012, 0.4980],
       device='cuda:0') torch.Size([16])
percent tensor([0.6089, 0.5875, 0.6867, 0.6997, 0.6882, 0.6293, 0.6274, 0.6688, 0.6200,
        0.6190, 0.6061, 0.6867, 0.5645, 0.6445, 0.6385, 0.6418],
       device='cuda:0') torch.Size([16])
percent tensor([0.9962, 0.9861, 0.9882, 0.9902, 0.9853, 0.9873, 0.9917, 0.9921, 0.9851,
        0.9907, 0.9900, 0.9890, 0.9847, 0.9894, 0.9900, 0.9950],
       device='cuda:0') torch.Size([16])
False Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=128, out_features=16, bias=False)
True Linear(in_features=16, out_features=2, bias=False)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=128, out_features=16, bias=False)
True Linear(in_features=16, out_features=2, bias=False)
False Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=256, out_features=32, bias=False)
True Linear(in_features=32, out_features=2, bias=False)
False Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=256, out_features=32, bias=False)
True Linear(in_features=32, out_features=2, bias=False)
False Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=512, out_features=64, bias=False)
True Linear(in_features=64, out_features=2, bias=False)
False Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=512, out_features=64, bias=False)
True Linear(in_features=64, out_features=2, bias=False)
False Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1024, out_features=128, bias=False)
True Linear(in_features=128, out_features=2, bias=False)
False Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1024, out_features=128, bias=False)
True Linear(in_features=128, out_features=2, bias=False)
False Linear(in_features=512, out_features=10, bias=True)
Epoch: 35 | Batch_idx: 0 |  Loss: (0.4913) |  Loss2: (0.0000) | Acc: (78.00%) (101/128)
Epoch: 35 | Batch_idx: 10 |  Loss: (0.5062) |  Loss2: (0.0000) | Acc: (82.00%) (1156/1408)
Epoch: 35 | Batch_idx: 20 |  Loss: (0.5446) |  Loss2: (0.0000) | Acc: (80.00%) (2164/2688)
Epoch: 35 | Batch_idx: 30 |  Loss: (0.5676) |  Loss2: (0.0000) | Acc: (79.00%) (3173/3968)
Epoch: 35 | Batch_idx: 40 |  Loss: (0.5689) |  Loss2: (0.0000) | Acc: (80.00%) (4200/5248)
Epoch: 35 | Batch_idx: 50 |  Loss: (0.5729) |  Loss2: (0.0000) | Acc: (79.00%) (5208/6528)
Epoch: 35 | Batch_idx: 60 |  Loss: (0.5762) |  Loss2: (0.0000) | Acc: (79.00%) (6209/7808)
Epoch: 35 | Batch_idx: 70 |  Loss: (0.5728) |  Loss2: (0.0000) | Acc: (79.00%) (7245/9088)
Epoch: 35 | Batch_idx: 80 |  Loss: (0.5697) |  Loss2: (0.0000) | Acc: (79.00%) (8266/10368)
Epoch: 35 | Batch_idx: 90 |  Loss: (0.5793) |  Loss2: (0.0000) | Acc: (79.00%) (9250/11648)
Epoch: 35 | Batch_idx: 100 |  Loss: (0.5827) |  Loss2: (0.0000) | Acc: (79.00%) (10265/12928)
Epoch: 35 | Batch_idx: 110 |  Loss: (0.5856) |  Loss2: (0.0000) | Acc: (79.00%) (11275/14208)
Epoch: 35 | Batch_idx: 120 |  Loss: (0.5822) |  Loss2: (0.0000) | Acc: (79.00%) (12320/15488)
Epoch: 35 | Batch_idx: 130 |  Loss: (0.5795) |  Loss2: (0.0000) | Acc: (79.00%) (13351/16768)
Epoch: 35 | Batch_idx: 140 |  Loss: (0.5798) |  Loss2: (0.0000) | Acc: (79.00%) (14376/18048)
Epoch: 35 | Batch_idx: 150 |  Loss: (0.5787) |  Loss2: (0.0000) | Acc: (79.00%) (15404/19328)
Epoch: 35 | Batch_idx: 160 |  Loss: (0.5792) |  Loss2: (0.0000) | Acc: (79.00%) (16422/20608)
Epoch: 35 | Batch_idx: 170 |  Loss: (0.5805) |  Loss2: (0.0000) | Acc: (79.00%) (17446/21888)
Epoch: 35 | Batch_idx: 180 |  Loss: (0.5772) |  Loss2: (0.0000) | Acc: (79.00%) (18481/23168)
Epoch: 35 | Batch_idx: 190 |  Loss: (0.5775) |  Loss2: (0.0000) | Acc: (79.00%) (19515/24448)
Epoch: 35 | Batch_idx: 200 |  Loss: (0.5747) |  Loss2: (0.0000) | Acc: (79.00%) (20564/25728)
Epoch: 35 | Batch_idx: 210 |  Loss: (0.5732) |  Loss2: (0.0000) | Acc: (79.00%) (21594/27008)
Epoch: 35 | Batch_idx: 220 |  Loss: (0.5723) |  Loss2: (0.0000) | Acc: (80.00%) (22631/28288)
Epoch: 35 | Batch_idx: 230 |  Loss: (0.5725) |  Loss2: (0.0000) | Acc: (79.00%) (23641/29568)
Epoch: 35 | Batch_idx: 240 |  Loss: (0.5707) |  Loss2: (0.0000) | Acc: (80.00%) (24684/30848)
Epoch: 35 | Batch_idx: 250 |  Loss: (0.5707) |  Loss2: (0.0000) | Acc: (80.00%) (25719/32128)
Epoch: 35 | Batch_idx: 260 |  Loss: (0.5697) |  Loss2: (0.0000) | Acc: (80.00%) (26759/33408)
Epoch: 35 | Batch_idx: 270 |  Loss: (0.5693) |  Loss2: (0.0000) | Acc: (80.00%) (27795/34688)
Epoch: 35 | Batch_idx: 280 |  Loss: (0.5682) |  Loss2: (0.0000) | Acc: (80.00%) (28865/35968)
Epoch: 35 | Batch_idx: 290 |  Loss: (0.5682) |  Loss2: (0.0000) | Acc: (80.00%) (29879/37248)
Epoch: 35 | Batch_idx: 300 |  Loss: (0.5674) |  Loss2: (0.0000) | Acc: (80.00%) (30919/38528)
Epoch: 35 | Batch_idx: 310 |  Loss: (0.5663) |  Loss2: (0.0000) | Acc: (80.00%) (31960/39808)
Epoch: 35 | Batch_idx: 320 |  Loss: (0.5651) |  Loss2: (0.0000) | Acc: (80.00%) (33007/41088)
Epoch: 35 | Batch_idx: 330 |  Loss: (0.5647) |  Loss2: (0.0000) | Acc: (80.00%) (34033/42368)
Epoch: 35 | Batch_idx: 340 |  Loss: (0.5636) |  Loss2: (0.0000) | Acc: (80.00%) (35084/43648)
Epoch: 35 | Batch_idx: 350 |  Loss: (0.5630) |  Loss2: (0.0000) | Acc: (80.00%) (36119/44928)
Epoch: 35 | Batch_idx: 360 |  Loss: (0.5624) |  Loss2: (0.0000) | Acc: (80.00%) (37161/46208)
Epoch: 35 | Batch_idx: 370 |  Loss: (0.5621) |  Loss2: (0.0000) | Acc: (80.00%) (38201/47488)
Epoch: 35 | Batch_idx: 380 |  Loss: (0.5614) |  Loss2: (0.0000) | Acc: (80.00%) (39235/48768)
Epoch: 35 | Batch_idx: 390 |  Loss: (0.5601) |  Loss2: (0.0000) | Acc: (80.00%) (40249/50000)
=> saving checkpoint 'drive/app/torch/save_Routing_Gate_2/checkpoint_035.pth.tar'
# TEST : Loss: (0.5903) | Acc: (79.00%) (7927/10000)
percent tensor([0.4999, 0.4950, 0.5013, 0.5026, 0.5002, 0.5007, 0.4969, 0.5009, 0.4990,
        0.4974, 0.4981, 0.4985, 0.4980, 0.4963, 0.4977, 0.4998],
       device='cuda:0') torch.Size([16])
percent tensor([0.5021, 0.5117, 0.4902, 0.4954, 0.4907, 0.5049, 0.5040, 0.4956, 0.4978,
        0.5022, 0.5048, 0.4933, 0.5025, 0.5137, 0.5071, 0.5047],
       device='cuda:0') torch.Size([16])
percent tensor([0.5003, 0.4971, 0.5210, 0.4803, 0.5050, 0.4841, 0.5113, 0.5047, 0.4814,
        0.5001, 0.4951, 0.5233, 0.5175, 0.4220, 0.5170, 0.4827],
       device='cuda:0') torch.Size([16])
percent tensor([0.6010, 0.6047, 0.5985, 0.5978, 0.6046, 0.5977, 0.6089, 0.5996, 0.6072,
        0.6076, 0.6180, 0.6060, 0.5995, 0.6151, 0.6061, 0.6043],
       device='cuda:0') torch.Size([16])
percent tensor([0.5932, 0.5803, 0.5750, 0.5724, 0.5523, 0.6372, 0.5793, 0.5434, 0.6051,
        0.5921, 0.6154, 0.5792, 0.5952, 0.6263, 0.5929, 0.5980],
       device='cuda:0') torch.Size([16])
percent tensor([0.4852, 0.5050, 0.5243, 0.5201, 0.5204, 0.5135, 0.5028, 0.4399, 0.5546,
        0.5151, 0.5348, 0.5482, 0.5150, 0.5792, 0.4254, 0.4952],
       device='cuda:0') torch.Size([16])
percent tensor([0.5638, 0.5452, 0.6964, 0.7015, 0.7044, 0.5939, 0.6112, 0.7007, 0.5844,
        0.5839, 0.5455, 0.6858, 0.5012, 0.5899, 0.6306, 0.6196],
       device='cuda:0') torch.Size([16])
percent tensor([0.9955, 0.9849, 0.9919, 0.9920, 0.9857, 0.9856, 0.9904, 0.9928, 0.9848,
        0.9913, 0.9900, 0.9911, 0.9833, 0.9860, 0.9911, 0.9947],
       device='cuda:0') torch.Size([16])
Epoch: 36 | Batch_idx: 0 |  Loss: (0.5101) |  Loss2: (0.0000) | Acc: (80.00%) (103/128)
Epoch: 36 | Batch_idx: 10 |  Loss: (0.4945) |  Loss2: (0.0000) | Acc: (82.00%) (1165/1408)
Epoch: 36 | Batch_idx: 20 |  Loss: (0.5036) |  Loss2: (0.0000) | Acc: (82.00%) (2213/2688)
Epoch: 36 | Batch_idx: 30 |  Loss: (0.5049) |  Loss2: (0.0000) | Acc: (82.00%) (3270/3968)
Epoch: 36 | Batch_idx: 40 |  Loss: (0.5096) |  Loss2: (0.0000) | Acc: (82.00%) (4321/5248)
Epoch: 36 | Batch_idx: 50 |  Loss: (0.5213) |  Loss2: (0.0000) | Acc: (82.00%) (5353/6528)
Epoch: 36 | Batch_idx: 60 |  Loss: (0.5249) |  Loss2: (0.0000) | Acc: (81.00%) (6394/7808)
Epoch: 36 | Batch_idx: 70 |  Loss: (0.5201) |  Loss2: (0.0000) | Acc: (82.00%) (7472/9088)
Epoch: 36 | Batch_idx: 80 |  Loss: (0.5228) |  Loss2: (0.0000) | Acc: (82.00%) (8518/10368)
Epoch: 36 | Batch_idx: 90 |  Loss: (0.5230) |  Loss2: (0.0000) | Acc: (81.00%) (9543/11648)
Epoch: 36 | Batch_idx: 100 |  Loss: (0.5204) |  Loss2: (0.0000) | Acc: (82.00%) (10602/12928)
Epoch: 36 | Batch_idx: 110 |  Loss: (0.5224) |  Loss2: (0.0000) | Acc: (81.00%) (11626/14208)
Epoch: 36 | Batch_idx: 120 |  Loss: (0.5192) |  Loss2: (0.0000) | Acc: (81.00%) (12698/15488)
Epoch: 36 | Batch_idx: 130 |  Loss: (0.5191) |  Loss2: (0.0000) | Acc: (81.00%) (13737/16768)
Epoch: 36 | Batch_idx: 140 |  Loss: (0.5157) |  Loss2: (0.0000) | Acc: (82.00%) (14809/18048)
Epoch: 36 | Batch_idx: 150 |  Loss: (0.5176) |  Loss2: (0.0000) | Acc: (81.00%) (15847/19328)
Epoch: 36 | Batch_idx: 160 |  Loss: (0.5188) |  Loss2: (0.0000) | Acc: (81.00%) (16882/20608)
Epoch: 36 | Batch_idx: 170 |  Loss: (0.5171) |  Loss2: (0.0000) | Acc: (81.00%) (17947/21888)
Epoch: 36 | Batch_idx: 180 |  Loss: (0.5167) |  Loss2: (0.0000) | Acc: (81.00%) (18992/23168)
Epoch: 36 | Batch_idx: 190 |  Loss: (0.5142) |  Loss2: (0.0000) | Acc: (82.00%) (20065/24448)
Epoch: 36 | Batch_idx: 200 |  Loss: (0.5143) |  Loss2: (0.0000) | Acc: (82.00%) (21115/25728)
Epoch: 36 | Batch_idx: 210 |  Loss: (0.5168) |  Loss2: (0.0000) | Acc: (81.00%) (22143/27008)
Epoch: 36 | Batch_idx: 220 |  Loss: (0.5184) |  Loss2: (0.0000) | Acc: (81.00%) (23183/28288)
Epoch: 36 | Batch_idx: 230 |  Loss: (0.5180) |  Loss2: (0.0000) | Acc: (81.00%) (24233/29568)
Epoch: 36 | Batch_idx: 240 |  Loss: (0.5174) |  Loss2: (0.0000) | Acc: (81.00%) (25284/30848)
Epoch: 36 | Batch_idx: 250 |  Loss: (0.5175) |  Loss2: (0.0000) | Acc: (81.00%) (26334/32128)
Epoch: 36 | Batch_idx: 260 |  Loss: (0.5154) |  Loss2: (0.0000) | Acc: (82.00%) (27413/33408)
Epoch: 36 | Batch_idx: 270 |  Loss: (0.5148) |  Loss2: (0.0000) | Acc: (82.00%) (28473/34688)
Epoch: 36 | Batch_idx: 280 |  Loss: (0.5151) |  Loss2: (0.0000) | Acc: (82.00%) (29528/35968)
Epoch: 36 | Batch_idx: 290 |  Loss: (0.5151) |  Loss2: (0.0000) | Acc: (82.00%) (30577/37248)
Epoch: 36 | Batch_idx: 300 |  Loss: (0.5136) |  Loss2: (0.0000) | Acc: (82.00%) (31654/38528)
Epoch: 36 | Batch_idx: 310 |  Loss: (0.5137) |  Loss2: (0.0000) | Acc: (82.00%) (32695/39808)
Epoch: 36 | Batch_idx: 320 |  Loss: (0.5136) |  Loss2: (0.0000) | Acc: (82.00%) (33763/41088)
Epoch: 36 | Batch_idx: 330 |  Loss: (0.5143) |  Loss2: (0.0000) | Acc: (82.00%) (34796/42368)
Epoch: 36 | Batch_idx: 340 |  Loss: (0.5146) |  Loss2: (0.0000) | Acc: (82.00%) (35834/43648)
Epoch: 36 | Batch_idx: 350 |  Loss: (0.5152) |  Loss2: (0.0000) | Acc: (82.00%) (36869/44928)
Epoch: 36 | Batch_idx: 360 |  Loss: (0.5146) |  Loss2: (0.0000) | Acc: (82.00%) (37925/46208)
Epoch: 36 | Batch_idx: 370 |  Loss: (0.5138) |  Loss2: (0.0000) | Acc: (82.00%) (39001/47488)
Epoch: 36 | Batch_idx: 380 |  Loss: (0.5131) |  Loss2: (0.0000) | Acc: (82.00%) (40052/48768)
Epoch: 36 | Batch_idx: 390 |  Loss: (0.5123) |  Loss2: (0.0000) | Acc: (82.00%) (41078/50000)
# TEST : Loss: (0.5534) | Acc: (80.00%) (8060/10000)
percent tensor([0.5014, 0.4967, 0.5013, 0.5040, 0.5006, 0.5032, 0.4981, 0.5015, 0.5001,
        0.4983, 0.4996, 0.4984, 0.4992, 0.4986, 0.4997, 0.5017],
       device='cuda:0') torch.Size([16])
percent tensor([0.5039, 0.5141, 0.4919, 0.4974, 0.4922, 0.5075, 0.5060, 0.4972, 0.4989,
        0.5041, 0.5069, 0.4951, 0.5045, 0.5151, 0.5099, 0.5069],
       device='cuda:0') torch.Size([16])
percent tensor([0.5076, 0.5049, 0.5232, 0.4819, 0.5061, 0.5003, 0.5153, 0.5051, 0.4882,
        0.5050, 0.5043, 0.5276, 0.5278, 0.4259, 0.5267, 0.4905],
       device='cuda:0') torch.Size([16])
percent tensor([0.5997, 0.6062, 0.6005, 0.5982, 0.6039, 0.5944, 0.6085, 0.5969, 0.6104,
        0.6104, 0.6230, 0.6104, 0.6030, 0.6167, 0.6040, 0.6032],
       device='cuda:0') torch.Size([16])
percent tensor([0.5976, 0.5914, 0.5732, 0.5655, 0.5331, 0.6536, 0.5740, 0.5209, 0.6158,
        0.5982, 0.6307, 0.5855, 0.6163, 0.6387, 0.5964, 0.5987],
       device='cuda:0') torch.Size([16])
percent tensor([0.4894, 0.5091, 0.5302, 0.5248, 0.5228, 0.5113, 0.5042, 0.4492, 0.5606,
        0.5252, 0.5435, 0.5581, 0.5219, 0.5825, 0.4331, 0.4941],
       device='cuda:0') torch.Size([16])
percent tensor([0.5544, 0.5300, 0.7111, 0.7164, 0.7309, 0.5947, 0.6154, 0.7312, 0.5768,
        0.5738, 0.5235, 0.6938, 0.4796, 0.5678, 0.6400, 0.6290],
       device='cuda:0') torch.Size([16])
percent tensor([0.9962, 0.9877, 0.9932, 0.9932, 0.9885, 0.9885, 0.9918, 0.9941, 0.9876,
        0.9927, 0.9918, 0.9924, 0.9865, 0.9890, 0.9926, 0.9957],
       device='cuda:0') torch.Size([16])
Epoch: 37 | Batch_idx: 0 |  Loss: (0.4990) |  Loss2: (0.0000) | Acc: (80.00%) (103/128)
Epoch: 37 | Batch_idx: 10 |  Loss: (0.4824) |  Loss2: (0.0000) | Acc: (82.00%) (1168/1408)
Epoch: 37 | Batch_idx: 20 |  Loss: (0.4870) |  Loss2: (0.0000) | Acc: (82.00%) (2222/2688)
Epoch: 37 | Batch_idx: 30 |  Loss: (0.4918) |  Loss2: (0.0000) | Acc: (82.00%) (3292/3968)
Epoch: 37 | Batch_idx: 40 |  Loss: (0.5096) |  Loss2: (0.0000) | Acc: (82.00%) (4318/5248)
Epoch: 37 | Batch_idx: 50 |  Loss: (0.5048) |  Loss2: (0.0000) | Acc: (82.00%) (5396/6528)
Epoch: 37 | Batch_idx: 60 |  Loss: (0.5034) |  Loss2: (0.0000) | Acc: (82.00%) (6453/7808)
Epoch: 37 | Batch_idx: 70 |  Loss: (0.5075) |  Loss2: (0.0000) | Acc: (82.00%) (7492/9088)
Epoch: 37 | Batch_idx: 80 |  Loss: (0.5043) |  Loss2: (0.0000) | Acc: (82.00%) (8558/10368)
Epoch: 37 | Batch_idx: 90 |  Loss: (0.5014) |  Loss2: (0.0000) | Acc: (82.00%) (9627/11648)
Epoch: 37 | Batch_idx: 100 |  Loss: (0.4943) |  Loss2: (0.0000) | Acc: (82.00%) (10720/12928)
Epoch: 37 | Batch_idx: 110 |  Loss: (0.4965) |  Loss2: (0.0000) | Acc: (82.00%) (11777/14208)
Epoch: 37 | Batch_idx: 120 |  Loss: (0.4950) |  Loss2: (0.0000) | Acc: (82.00%) (12844/15488)
Epoch: 37 | Batch_idx: 130 |  Loss: (0.4946) |  Loss2: (0.0000) | Acc: (82.00%) (13903/16768)
Epoch: 37 | Batch_idx: 140 |  Loss: (0.4972) |  Loss2: (0.0000) | Acc: (82.00%) (14954/18048)
Epoch: 37 | Batch_idx: 150 |  Loss: (0.4941) |  Loss2: (0.0000) | Acc: (83.00%) (16046/19328)
Epoch: 37 | Batch_idx: 160 |  Loss: (0.4937) |  Loss2: (0.0000) | Acc: (83.00%) (17118/20608)
Epoch: 37 | Batch_idx: 170 |  Loss: (0.4958) |  Loss2: (0.0000) | Acc: (82.00%) (18151/21888)
Epoch: 37 | Batch_idx: 180 |  Loss: (0.4993) |  Loss2: (0.0000) | Acc: (82.00%) (19199/23168)
Epoch: 37 | Batch_idx: 190 |  Loss: (0.4992) |  Loss2: (0.0000) | Acc: (82.00%) (20259/24448)
Epoch: 37 | Batch_idx: 200 |  Loss: (0.4984) |  Loss2: (0.0000) | Acc: (82.00%) (21316/25728)
Epoch: 37 | Batch_idx: 210 |  Loss: (0.4997) |  Loss2: (0.0000) | Acc: (82.00%) (22365/27008)
Epoch: 37 | Batch_idx: 220 |  Loss: (0.5001) |  Loss2: (0.0000) | Acc: (82.00%) (23423/28288)
Epoch: 37 | Batch_idx: 230 |  Loss: (0.4998) |  Loss2: (0.0000) | Acc: (82.00%) (24464/29568)
Epoch: 37 | Batch_idx: 240 |  Loss: (0.4980) |  Loss2: (0.0000) | Acc: (82.00%) (25540/30848)
Epoch: 37 | Batch_idx: 250 |  Loss: (0.4993) |  Loss2: (0.0000) | Acc: (82.00%) (26571/32128)
Epoch: 37 | Batch_idx: 260 |  Loss: (0.5007) |  Loss2: (0.0000) | Acc: (82.00%) (27620/33408)
Epoch: 37 | Batch_idx: 270 |  Loss: (0.5007) |  Loss2: (0.0000) | Acc: (82.00%) (28685/34688)
Epoch: 37 | Batch_idx: 280 |  Loss: (0.5002) |  Loss2: (0.0000) | Acc: (82.00%) (29758/35968)
Epoch: 37 | Batch_idx: 290 |  Loss: (0.5019) |  Loss2: (0.0000) | Acc: (82.00%) (30780/37248)
Epoch: 37 | Batch_idx: 300 |  Loss: (0.5014) |  Loss2: (0.0000) | Acc: (82.00%) (31837/38528)
Epoch: 37 | Batch_idx: 310 |  Loss: (0.5005) |  Loss2: (0.0000) | Acc: (82.00%) (32909/39808)
Epoch: 37 | Batch_idx: 320 |  Loss: (0.5000) |  Loss2: (0.0000) | Acc: (82.00%) (33973/41088)
Epoch: 37 | Batch_idx: 330 |  Loss: (0.4989) |  Loss2: (0.0000) | Acc: (82.00%) (35030/42368)
Epoch: 37 | Batch_idx: 340 |  Loss: (0.4986) |  Loss2: (0.0000) | Acc: (82.00%) (36086/43648)
Epoch: 37 | Batch_idx: 350 |  Loss: (0.4988) |  Loss2: (0.0000) | Acc: (82.00%) (37136/44928)
Epoch: 37 | Batch_idx: 360 |  Loss: (0.4990) |  Loss2: (0.0000) | Acc: (82.00%) (38196/46208)
Epoch: 37 | Batch_idx: 370 |  Loss: (0.4983) |  Loss2: (0.0000) | Acc: (82.00%) (39274/47488)
Epoch: 37 | Batch_idx: 380 |  Loss: (0.4987) |  Loss2: (0.0000) | Acc: (82.00%) (40319/48768)
Epoch: 37 | Batch_idx: 390 |  Loss: (0.4984) |  Loss2: (0.0000) | Acc: (82.00%) (41351/50000)
# TEST : Loss: (0.5374) | Acc: (81.00%) (8120/10000)
percent tensor([0.5026, 0.4979, 0.5017, 0.5051, 0.5012, 0.5051, 0.4991, 0.5022, 0.5010,
        0.4991, 0.5008, 0.4986, 0.5002, 0.5000, 0.5011, 0.5032],
       device='cuda:0') torch.Size([16])
percent tensor([0.5053, 0.5158, 0.4934, 0.4991, 0.4938, 0.5095, 0.5076, 0.4985, 0.5002,
        0.5056, 0.5086, 0.4968, 0.5061, 0.5163, 0.5119, 0.5087],
       device='cuda:0') torch.Size([16])
percent tensor([0.5041, 0.5025, 0.5206, 0.4780, 0.5017, 0.4999, 0.5105, 0.4996, 0.4877,
        0.5023, 0.5032, 0.5258, 0.5283, 0.4231, 0.5225, 0.4881],
       device='cuda:0') torch.Size([16])
percent tensor([0.6035, 0.6122, 0.6075, 0.6039, 0.6097, 0.5961, 0.6142, 0.6016, 0.6182,
        0.6174, 0.6311, 0.6195, 0.6097, 0.6238, 0.6078, 0.6073],
       device='cuda:0') torch.Size([16])
percent tensor([0.5983, 0.5938, 0.5760, 0.5655, 0.5292, 0.6637, 0.5727, 0.5162, 0.6211,
        0.5967, 0.6322, 0.5936, 0.6236, 0.6457, 0.6006, 0.5991],
       device='cuda:0') torch.Size([16])
percent tensor([0.4916, 0.5159, 0.5329, 0.5270, 0.5233, 0.5111, 0.5065, 0.4494, 0.5679,
        0.5330, 0.5509, 0.5661, 0.5286, 0.5910, 0.4354, 0.4942],
       device='cuda:0') torch.Size([16])
percent tensor([0.5527, 0.5257, 0.7238, 0.7285, 0.7492, 0.6015, 0.6230, 0.7514, 0.5770,
        0.5706, 0.5143, 0.7013, 0.4706, 0.5577, 0.6484, 0.6402],
       device='cuda:0') torch.Size([16])
percent tensor([0.9969, 0.9897, 0.9944, 0.9942, 0.9905, 0.9905, 0.9930, 0.9952, 0.9901,
        0.9941, 0.9933, 0.9938, 0.9889, 0.9912, 0.9939, 0.9966],
       device='cuda:0') torch.Size([16])
Epoch: 38 | Batch_idx: 0 |  Loss: (0.5360) |  Loss2: (0.0000) | Acc: (79.00%) (102/128)
Epoch: 38 | Batch_idx: 10 |  Loss: (0.4956) |  Loss2: (0.0000) | Acc: (82.00%) (1163/1408)
Epoch: 38 | Batch_idx: 20 |  Loss: (0.4931) |  Loss2: (0.0000) | Acc: (83.00%) (2239/2688)
Epoch: 38 | Batch_idx: 30 |  Loss: (0.4848) |  Loss2: (0.0000) | Acc: (83.00%) (3312/3968)
Epoch: 38 | Batch_idx: 40 |  Loss: (0.4827) |  Loss2: (0.0000) | Acc: (83.00%) (4386/5248)
Epoch: 38 | Batch_idx: 50 |  Loss: (0.4781) |  Loss2: (0.0000) | Acc: (83.00%) (5479/6528)
Epoch: 38 | Batch_idx: 60 |  Loss: (0.4807) |  Loss2: (0.0000) | Acc: (83.00%) (6541/7808)
Epoch: 38 | Batch_idx: 70 |  Loss: (0.4858) |  Loss2: (0.0000) | Acc: (83.00%) (7584/9088)
Epoch: 38 | Batch_idx: 80 |  Loss: (0.4873) |  Loss2: (0.0000) | Acc: (83.00%) (8643/10368)
Epoch: 38 | Batch_idx: 90 |  Loss: (0.4873) |  Loss2: (0.0000) | Acc: (83.00%) (9711/11648)
Epoch: 38 | Batch_idx: 100 |  Loss: (0.4893) |  Loss2: (0.0000) | Acc: (83.00%) (10767/12928)
Epoch: 38 | Batch_idx: 110 |  Loss: (0.4880) |  Loss2: (0.0000) | Acc: (83.00%) (11846/14208)
Epoch: 38 | Batch_idx: 120 |  Loss: (0.4882) |  Loss2: (0.0000) | Acc: (83.00%) (12922/15488)
Epoch: 38 | Batch_idx: 130 |  Loss: (0.4870) |  Loss2: (0.0000) | Acc: (83.00%) (13999/16768)
Epoch: 38 | Batch_idx: 140 |  Loss: (0.4876) |  Loss2: (0.0000) | Acc: (83.00%) (15061/18048)
Epoch: 38 | Batch_idx: 150 |  Loss: (0.4904) |  Loss2: (0.0000) | Acc: (83.00%) (16099/19328)
Epoch: 38 | Batch_idx: 160 |  Loss: (0.4914) |  Loss2: (0.0000) | Acc: (83.00%) (17152/20608)
Epoch: 38 | Batch_idx: 170 |  Loss: (0.4928) |  Loss2: (0.0000) | Acc: (83.00%) (18205/21888)
Epoch: 38 | Batch_idx: 180 |  Loss: (0.4916) |  Loss2: (0.0000) | Acc: (83.00%) (19291/23168)
Epoch: 38 | Batch_idx: 190 |  Loss: (0.4903) |  Loss2: (0.0000) | Acc: (83.00%) (20372/24448)
Epoch: 38 | Batch_idx: 200 |  Loss: (0.4905) |  Loss2: (0.0000) | Acc: (83.00%) (21421/25728)
Epoch: 38 | Batch_idx: 210 |  Loss: (0.4897) |  Loss2: (0.0000) | Acc: (83.00%) (22476/27008)
Epoch: 38 | Batch_idx: 220 |  Loss: (0.4908) |  Loss2: (0.0000) | Acc: (83.00%) (23523/28288)
Epoch: 38 | Batch_idx: 230 |  Loss: (0.4911) |  Loss2: (0.0000) | Acc: (83.00%) (24594/29568)
Epoch: 38 | Batch_idx: 240 |  Loss: (0.4907) |  Loss2: (0.0000) | Acc: (83.00%) (25668/30848)
Epoch: 38 | Batch_idx: 250 |  Loss: (0.4877) |  Loss2: (0.0000) | Acc: (83.00%) (26775/32128)
Epoch: 38 | Batch_idx: 260 |  Loss: (0.4874) |  Loss2: (0.0000) | Acc: (83.00%) (27848/33408)
Epoch: 38 | Batch_idx: 270 |  Loss: (0.4881) |  Loss2: (0.0000) | Acc: (83.00%) (28905/34688)
Epoch: 38 | Batch_idx: 280 |  Loss: (0.4882) |  Loss2: (0.0000) | Acc: (83.00%) (29965/35968)
Epoch: 38 | Batch_idx: 290 |  Loss: (0.4872) |  Loss2: (0.0000) | Acc: (83.00%) (31044/37248)
Epoch: 38 | Batch_idx: 300 |  Loss: (0.4877) |  Loss2: (0.0000) | Acc: (83.00%) (32100/38528)
Epoch: 38 | Batch_idx: 310 |  Loss: (0.4879) |  Loss2: (0.0000) | Acc: (83.00%) (33172/39808)
Epoch: 38 | Batch_idx: 320 |  Loss: (0.4865) |  Loss2: (0.0000) | Acc: (83.00%) (34266/41088)
Epoch: 38 | Batch_idx: 330 |  Loss: (0.4867) |  Loss2: (0.0000) | Acc: (83.00%) (35347/42368)
Epoch: 38 | Batch_idx: 340 |  Loss: (0.4871) |  Loss2: (0.0000) | Acc: (83.00%) (36401/43648)
Epoch: 38 | Batch_idx: 350 |  Loss: (0.4876) |  Loss2: (0.0000) | Acc: (83.00%) (37464/44928)
Epoch: 38 | Batch_idx: 360 |  Loss: (0.4886) |  Loss2: (0.0000) | Acc: (83.00%) (38507/46208)
Epoch: 38 | Batch_idx: 370 |  Loss: (0.4878) |  Loss2: (0.0000) | Acc: (83.00%) (39582/47488)
Epoch: 38 | Batch_idx: 380 |  Loss: (0.4876) |  Loss2: (0.0000) | Acc: (83.00%) (40664/48768)
Epoch: 38 | Batch_idx: 390 |  Loss: (0.4866) |  Loss2: (0.0000) | Acc: (83.00%) (41714/50000)
# TEST : Loss: (0.5260) | Acc: (81.00%) (8158/10000)
percent tensor([0.5026, 0.4979, 0.5013, 0.5055, 0.5008, 0.5055, 0.4990, 0.5021, 0.5009,
        0.4988, 0.5008, 0.4979, 0.5001, 0.5003, 0.5014, 0.5035],
       device='cuda:0') torch.Size([16])
percent tensor([0.5052, 0.5155, 0.4935, 0.4994, 0.4937, 0.5096, 0.5074, 0.4982, 0.5000,
        0.5055, 0.5085, 0.4970, 0.5061, 0.5156, 0.5119, 0.5086],
       device='cuda:0') torch.Size([16])
percent tensor([0.5001, 0.4991, 0.5211, 0.4759, 0.5012, 0.4995, 0.5063, 0.4970, 0.4878,
        0.4998, 0.5003, 0.5263, 0.5275, 0.4189, 0.5182, 0.4847],
       device='cuda:0') torch.Size([16])
percent tensor([0.6052, 0.6166, 0.6111, 0.6059, 0.6117, 0.5952, 0.6172, 0.6029, 0.6231,
        0.6225, 0.6372, 0.6254, 0.6147, 0.6282, 0.6091, 0.6090],
       device='cuda:0') torch.Size([16])
percent tensor([0.5992, 0.5947, 0.5773, 0.5651, 0.5261, 0.6688, 0.5712, 0.5135, 0.6246,
        0.5951, 0.6309, 0.5983, 0.6280, 0.6460, 0.6027, 0.5974],
       device='cuda:0') torch.Size([16])
percent tensor([0.4900, 0.5156, 0.5343, 0.5287, 0.5242, 0.5156, 0.5052, 0.4429, 0.5716,
        0.5341, 0.5516, 0.5698, 0.5314, 0.5955, 0.4288, 0.4923],
       device='cuda:0') torch.Size([16])
percent tensor([0.5624, 0.5338, 0.7401, 0.7440, 0.7667, 0.6191, 0.6370, 0.7694, 0.5881,
        0.5796, 0.5195, 0.7121, 0.4766, 0.5612, 0.6610, 0.6597],
       device='cuda:0') torch.Size([16])
percent tensor([0.9974, 0.9915, 0.9952, 0.9949, 0.9919, 0.9924, 0.9941, 0.9960, 0.9918,
        0.9949, 0.9944, 0.9946, 0.9911, 0.9928, 0.9950, 0.9972],
       device='cuda:0') torch.Size([16])
Epoch: 39 | Batch_idx: 0 |  Loss: (0.5331) |  Loss2: (0.0000) | Acc: (83.00%) (107/128)
Epoch: 39 | Batch_idx: 10 |  Loss: (0.5326) |  Loss2: (0.0000) | Acc: (81.00%) (1154/1408)
Epoch: 39 | Batch_idx: 20 |  Loss: (0.5256) |  Loss2: (0.0000) | Acc: (82.00%) (2205/2688)
Epoch: 39 | Batch_idx: 30 |  Loss: (0.5227) |  Loss2: (0.0000) | Acc: (82.00%) (3260/3968)
Epoch: 39 | Batch_idx: 40 |  Loss: (0.5121) |  Loss2: (0.0000) | Acc: (82.00%) (4334/5248)
Epoch: 39 | Batch_idx: 50 |  Loss: (0.5146) |  Loss2: (0.0000) | Acc: (82.00%) (5384/6528)
Epoch: 39 | Batch_idx: 60 |  Loss: (0.5098) |  Loss2: (0.0000) | Acc: (82.00%) (6441/7808)
Epoch: 39 | Batch_idx: 70 |  Loss: (0.5084) |  Loss2: (0.0000) | Acc: (82.00%) (7502/9088)
Epoch: 39 | Batch_idx: 80 |  Loss: (0.5023) |  Loss2: (0.0000) | Acc: (82.00%) (8572/10368)
Epoch: 39 | Batch_idx: 90 |  Loss: (0.5003) |  Loss2: (0.0000) | Acc: (82.00%) (9638/11648)
Epoch: 39 | Batch_idx: 100 |  Loss: (0.4974) |  Loss2: (0.0000) | Acc: (82.00%) (10728/12928)
Epoch: 39 | Batch_idx: 110 |  Loss: (0.4950) |  Loss2: (0.0000) | Acc: (83.00%) (11807/14208)
Epoch: 39 | Batch_idx: 120 |  Loss: (0.4954) |  Loss2: (0.0000) | Acc: (83.00%) (12866/15488)
Epoch: 39 | Batch_idx: 130 |  Loss: (0.4907) |  Loss2: (0.0000) | Acc: (83.00%) (13953/16768)
Epoch: 39 | Batch_idx: 140 |  Loss: (0.4904) |  Loss2: (0.0000) | Acc: (83.00%) (15017/18048)
Epoch: 39 | Batch_idx: 150 |  Loss: (0.4942) |  Loss2: (0.0000) | Acc: (83.00%) (16064/19328)
Epoch: 39 | Batch_idx: 160 |  Loss: (0.4944) |  Loss2: (0.0000) | Acc: (83.00%) (17135/20608)
Epoch: 39 | Batch_idx: 170 |  Loss: (0.4953) |  Loss2: (0.0000) | Acc: (83.00%) (18191/21888)
Epoch: 39 | Batch_idx: 180 |  Loss: (0.4927) |  Loss2: (0.0000) | Acc: (83.00%) (19284/23168)
Epoch: 39 | Batch_idx: 190 |  Loss: (0.4919) |  Loss2: (0.0000) | Acc: (83.00%) (20363/24448)
Epoch: 39 | Batch_idx: 200 |  Loss: (0.4916) |  Loss2: (0.0000) | Acc: (83.00%) (21426/25728)
Epoch: 39 | Batch_idx: 210 |  Loss: (0.4902) |  Loss2: (0.0000) | Acc: (83.00%) (22498/27008)
Epoch: 39 | Batch_idx: 220 |  Loss: (0.4893) |  Loss2: (0.0000) | Acc: (83.00%) (23572/28288)
Epoch: 39 | Batch_idx: 230 |  Loss: (0.4873) |  Loss2: (0.0000) | Acc: (83.00%) (24666/29568)
Epoch: 39 | Batch_idx: 240 |  Loss: (0.4872) |  Loss2: (0.0000) | Acc: (83.00%) (25734/30848)
Epoch: 39 | Batch_idx: 250 |  Loss: (0.4851) |  Loss2: (0.0000) | Acc: (83.00%) (26814/32128)
Epoch: 39 | Batch_idx: 260 |  Loss: (0.4825) |  Loss2: (0.0000) | Acc: (83.00%) (27901/33408)
Epoch: 39 | Batch_idx: 270 |  Loss: (0.4830) |  Loss2: (0.0000) | Acc: (83.00%) (28959/34688)
Epoch: 39 | Batch_idx: 280 |  Loss: (0.4836) |  Loss2: (0.0000) | Acc: (83.00%) (30024/35968)
Epoch: 39 | Batch_idx: 290 |  Loss: (0.4833) |  Loss2: (0.0000) | Acc: (83.00%) (31091/37248)
Epoch: 39 | Batch_idx: 300 |  Loss: (0.4827) |  Loss2: (0.0000) | Acc: (83.00%) (32158/38528)
Epoch: 39 | Batch_idx: 310 |  Loss: (0.4820) |  Loss2: (0.0000) | Acc: (83.00%) (33236/39808)
Epoch: 39 | Batch_idx: 320 |  Loss: (0.4821) |  Loss2: (0.0000) | Acc: (83.00%) (34299/41088)
Epoch: 39 | Batch_idx: 330 |  Loss: (0.4812) |  Loss2: (0.0000) | Acc: (83.00%) (35385/42368)
Epoch: 39 | Batch_idx: 340 |  Loss: (0.4808) |  Loss2: (0.0000) | Acc: (83.00%) (36445/43648)
Epoch: 39 | Batch_idx: 350 |  Loss: (0.4804) |  Loss2: (0.0000) | Acc: (83.00%) (37515/44928)
Epoch: 39 | Batch_idx: 360 |  Loss: (0.4806) |  Loss2: (0.0000) | Acc: (83.00%) (38576/46208)
Epoch: 39 | Batch_idx: 370 |  Loss: (0.4798) |  Loss2: (0.0000) | Acc: (83.00%) (39661/47488)
Epoch: 39 | Batch_idx: 380 |  Loss: (0.4806) |  Loss2: (0.0000) | Acc: (83.00%) (40711/48768)
Epoch: 39 | Batch_idx: 390 |  Loss: (0.4797) |  Loss2: (0.0000) | Acc: (83.00%) (41759/50000)
# TEST : Loss: (0.5237) | Acc: (81.00%) (8143/10000)
percent tensor([0.5028, 0.4979, 0.5009, 0.5058, 0.5005, 0.5059, 0.4988, 0.5020, 0.5008,
        0.4986, 0.5008, 0.4975, 0.5001, 0.5004, 0.5016, 0.5038],
       device='cuda:0') torch.Size([16])
percent tensor([0.5052, 0.5153, 0.4935, 0.4995, 0.4936, 0.5098, 0.5072, 0.4979, 0.4998,
        0.5052, 0.5084, 0.4970, 0.5062, 0.5151, 0.5119, 0.5086],
       device='cuda:0') torch.Size([16])
percent tensor([0.5038, 0.5033, 0.5254, 0.4812, 0.5049, 0.5073, 0.5091, 0.4996, 0.4926,
        0.5033, 0.5040, 0.5307, 0.5330, 0.4227, 0.5221, 0.4898],
       device='cuda:0') torch.Size([16])
percent tensor([0.6029, 0.6159, 0.6110, 0.6048, 0.6108, 0.5917, 0.6162, 0.6007, 0.6233,
        0.6225, 0.6380, 0.6260, 0.6147, 0.6279, 0.6067, 0.6067],
       device='cuda:0') torch.Size([16])
percent tensor([0.5950, 0.5850, 0.5768, 0.5642, 0.5253, 0.6717, 0.5656, 0.5113, 0.6213,
        0.5852, 0.6203, 0.5965, 0.6228, 0.6393, 0.5999, 0.5928],
       device='cuda:0') torch.Size([16])
percent tensor([0.4939, 0.5192, 0.5393, 0.5338, 0.5297, 0.5198, 0.5089, 0.4450, 0.5786,
        0.5394, 0.5570, 0.5739, 0.5371, 0.6018, 0.4292, 0.4966],
       device='cuda:0') torch.Size([16])
percent tensor([0.5683, 0.5376, 0.7436, 0.7474, 0.7724, 0.6331, 0.6433, 0.7723, 0.5934,
        0.5830, 0.5236, 0.7169, 0.4845, 0.5628, 0.6633, 0.6703],
       device='cuda:0') torch.Size([16])
percent tensor([0.9978, 0.9928, 0.9960, 0.9956, 0.9933, 0.9935, 0.9949, 0.9965, 0.9932,
        0.9958, 0.9953, 0.9956, 0.9923, 0.9942, 0.9955, 0.9976],
       device='cuda:0') torch.Size([16])
True Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=128, out_features=16, bias=False)
False Linear(in_features=16, out_features=2, bias=False)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=128, out_features=16, bias=False)
False Linear(in_features=16, out_features=2, bias=False)
True Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=256, out_features=32, bias=False)
False Linear(in_features=32, out_features=2, bias=False)
True Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=256, out_features=32, bias=False)
False Linear(in_features=32, out_features=2, bias=False)
True Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=512, out_features=64, bias=False)
False Linear(in_features=64, out_features=2, bias=False)
True Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=512, out_features=64, bias=False)
False Linear(in_features=64, out_features=2, bias=False)
True Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1024, out_features=128, bias=False)
False Linear(in_features=128, out_features=2, bias=False)
True Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1024, out_features=128, bias=False)
False Linear(in_features=128, out_features=2, bias=False)
True Linear(in_features=512, out_features=10, bias=True)
Epoch: 40 | Batch_idx: 0 |  Loss: (0.4355) |  Loss2: (0.0000) | Acc: (83.00%) (107/128)
Epoch: 40 | Batch_idx: 10 |  Loss: (0.4938) |  Loss2: (0.0000) | Acc: (82.00%) (1161/1408)
Epoch: 40 | Batch_idx: 20 |  Loss: (0.4818) |  Loss2: (0.0000) | Acc: (82.00%) (2226/2688)
Epoch: 40 | Batch_idx: 30 |  Loss: (0.4840) |  Loss2: (0.0000) | Acc: (82.00%) (3290/3968)
Epoch: 40 | Batch_idx: 40 |  Loss: (0.4829) |  Loss2: (0.0000) | Acc: (83.00%) (4362/5248)
Epoch: 40 | Batch_idx: 50 |  Loss: (0.4902) |  Loss2: (0.0000) | Acc: (82.00%) (5411/6528)
Epoch: 40 | Batch_idx: 60 |  Loss: (0.4975) |  Loss2: (0.0000) | Acc: (82.00%) (6457/7808)
Epoch: 40 | Batch_idx: 70 |  Loss: (0.4972) |  Loss2: (0.0000) | Acc: (82.00%) (7533/9088)
Epoch: 40 | Batch_idx: 80 |  Loss: (0.5006) |  Loss2: (0.0000) | Acc: (82.00%) (8587/10368)
Epoch: 40 | Batch_idx: 90 |  Loss: (0.4985) |  Loss2: (0.0000) | Acc: (82.00%) (9633/11648)
Epoch: 40 | Batch_idx: 100 |  Loss: (0.5033) |  Loss2: (0.0000) | Acc: (82.00%) (10668/12928)
Epoch: 40 | Batch_idx: 110 |  Loss: (0.5046) |  Loss2: (0.0000) | Acc: (82.00%) (11720/14208)
Epoch: 40 | Batch_idx: 120 |  Loss: (0.5047) |  Loss2: (0.0000) | Acc: (82.00%) (12767/15488)
Epoch: 40 | Batch_idx: 130 |  Loss: (0.5044) |  Loss2: (0.0000) | Acc: (82.00%) (13836/16768)
Epoch: 40 | Batch_idx: 140 |  Loss: (0.5061) |  Loss2: (0.0000) | Acc: (82.00%) (14868/18048)
Epoch: 40 | Batch_idx: 150 |  Loss: (0.5036) |  Loss2: (0.0000) | Acc: (82.00%) (15943/19328)
Epoch: 40 | Batch_idx: 160 |  Loss: (0.5033) |  Loss2: (0.0000) | Acc: (82.00%) (17015/20608)
Epoch: 40 | Batch_idx: 170 |  Loss: (0.5020) |  Loss2: (0.0000) | Acc: (82.00%) (18077/21888)
Epoch: 40 | Batch_idx: 180 |  Loss: (0.5020) |  Loss2: (0.0000) | Acc: (82.00%) (19131/23168)
Epoch: 40 | Batch_idx: 190 |  Loss: (0.5001) |  Loss2: (0.0000) | Acc: (82.00%) (20209/24448)
Epoch: 40 | Batch_idx: 200 |  Loss: (0.4987) |  Loss2: (0.0000) | Acc: (82.00%) (21291/25728)
Epoch: 40 | Batch_idx: 210 |  Loss: (0.4993) |  Loss2: (0.0000) | Acc: (82.00%) (22338/27008)
Epoch: 40 | Batch_idx: 220 |  Loss: (0.4980) |  Loss2: (0.0000) | Acc: (82.00%) (23409/28288)
Epoch: 40 | Batch_idx: 230 |  Loss: (0.4973) |  Loss2: (0.0000) | Acc: (82.00%) (24472/29568)
Epoch: 40 | Batch_idx: 240 |  Loss: (0.4976) |  Loss2: (0.0000) | Acc: (82.00%) (25541/30848)
Epoch: 40 | Batch_idx: 250 |  Loss: (0.4961) |  Loss2: (0.0000) | Acc: (82.00%) (26607/32128)
Epoch: 40 | Batch_idx: 260 |  Loss: (0.4969) |  Loss2: (0.0000) | Acc: (82.00%) (27651/33408)
Epoch: 40 | Batch_idx: 270 |  Loss: (0.4967) |  Loss2: (0.0000) | Acc: (82.00%) (28716/34688)
Epoch: 40 | Batch_idx: 280 |  Loss: (0.4977) |  Loss2: (0.0000) | Acc: (82.00%) (29761/35968)
Epoch: 40 | Batch_idx: 290 |  Loss: (0.4986) |  Loss2: (0.0000) | Acc: (82.00%) (30811/37248)
Epoch: 40 | Batch_idx: 300 |  Loss: (0.4986) |  Loss2: (0.0000) | Acc: (82.00%) (31873/38528)
Epoch: 40 | Batch_idx: 310 |  Loss: (0.4984) |  Loss2: (0.0000) | Acc: (82.00%) (32941/39808)
Epoch: 40 | Batch_idx: 320 |  Loss: (0.4977) |  Loss2: (0.0000) | Acc: (82.00%) (34018/41088)
Epoch: 40 | Batch_idx: 330 |  Loss: (0.4978) |  Loss2: (0.0000) | Acc: (82.00%) (35083/42368)
Epoch: 40 | Batch_idx: 340 |  Loss: (0.4978) |  Loss2: (0.0000) | Acc: (82.00%) (36139/43648)
Epoch: 40 | Batch_idx: 350 |  Loss: (0.4984) |  Loss2: (0.0000) | Acc: (82.00%) (37191/44928)
Epoch: 40 | Batch_idx: 360 |  Loss: (0.4961) |  Loss2: (0.0000) | Acc: (82.00%) (38303/46208)
Epoch: 40 | Batch_idx: 370 |  Loss: (0.4965) |  Loss2: (0.0000) | Acc: (82.00%) (39355/47488)
Epoch: 40 | Batch_idx: 380 |  Loss: (0.4963) |  Loss2: (0.0000) | Acc: (82.00%) (40419/48768)
Epoch: 40 | Batch_idx: 390 |  Loss: (0.4953) |  Loss2: (0.0000) | Acc: (82.00%) (41458/50000)
=> saving checkpoint 'drive/app/torch/save_Routing_Gate_2/checkpoint_040.pth.tar'
# TEST : Loss: (0.5770) | Acc: (79.00%) (7999/10000)
percent tensor([0.5031, 0.4976, 0.5019, 0.5054, 0.5012, 0.5064, 0.4989, 0.5023, 0.5017,
        0.4987, 0.5011, 0.4981, 0.5003, 0.4998, 0.5017, 0.5037],
       device='cuda:0') torch.Size([16])
percent tensor([0.5058, 0.5152, 0.4941, 0.5017, 0.4945, 0.5106, 0.5077, 0.4985, 0.4993,
        0.5055, 0.5084, 0.4982, 0.5065, 0.5163, 0.5120, 0.5092],
       device='cuda:0') torch.Size([16])
percent tensor([0.4958, 0.4973, 0.5185, 0.4809, 0.5005, 0.4898, 0.5033, 0.4948, 0.4883,
        0.5002, 0.4932, 0.5321, 0.5303, 0.4215, 0.5107, 0.4813],
       device='cuda:0') torch.Size([16])
percent tensor([0.6026, 0.6215, 0.6053, 0.6021, 0.6057, 0.5899, 0.6210, 0.5990, 0.6212,
        0.6273, 0.6421, 0.6244, 0.6133, 0.6372, 0.6078, 0.6081],
       device='cuda:0') torch.Size([16])
percent tensor([0.5793, 0.5807, 0.5719, 0.5709, 0.5283, 0.6626, 0.5626, 0.5091, 0.6078,
        0.5854, 0.6231, 0.5790, 0.6096, 0.6432, 0.5927, 0.5931],
       device='cuda:0') torch.Size([16])
percent tensor([0.4971, 0.5412, 0.5474, 0.5264, 0.5226, 0.5177, 0.5184, 0.4435, 0.5731,
        0.5459, 0.5692, 0.5587, 0.5407, 0.6228, 0.4342, 0.5064],
       device='cuda:0') torch.Size([16])
percent tensor([0.5736, 0.5192, 0.7418, 0.7417, 0.7759, 0.6578, 0.6166, 0.7569, 0.6067,
        0.5817, 0.5420, 0.6978, 0.4858, 0.5749, 0.6519, 0.6782],
       device='cuda:0') torch.Size([16])
percent tensor([0.9983, 0.9924, 0.9964, 0.9956, 0.9951, 0.9942, 0.9972, 0.9966, 0.9936,
        0.9959, 0.9961, 0.9943, 0.9926, 0.9956, 0.9956, 0.9975],
       device='cuda:0') torch.Size([16])
Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 3, 3, 3]) tensor(171.9091, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(790.6042, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(790.6146, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([128, 64, 3, 3]) tensor(1525.4846, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([128, 64, 1, 1]) tensor(505.2372, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([128, 128, 3, 3]) tensor(2192.8149, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([256, 128, 3, 3]) tensor(4299.0049, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([256, 128, 1, 1]) tensor(1424.6327, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([256, 256, 3, 3]) tensor(6077.0830, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([512, 256, 3, 3]) tensor(12092.2695, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([512, 256, 1, 1]) tensor(4032.9309, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([512, 512, 3, 3]) tensor(17045.9082, device='cuda:0', grad_fn=<NormBackward0>)
Epoch: 41 | Batch_idx: 0 |  Loss: (0.3653) |  Loss2: (0.0000) | Acc: (86.00%) (111/128)
Epoch: 41 | Batch_idx: 10 |  Loss: (0.4479) |  Loss2: (0.0000) | Acc: (84.00%) (1191/1408)
Epoch: 41 | Batch_idx: 20 |  Loss: (0.4473) |  Loss2: (0.0000) | Acc: (84.00%) (2270/2688)
Epoch: 41 | Batch_idx: 30 |  Loss: (0.4516) |  Loss2: (0.0000) | Acc: (83.00%) (3333/3968)
Epoch: 41 | Batch_idx: 40 |  Loss: (0.4549) |  Loss2: (0.0000) | Acc: (84.00%) (4421/5248)
Epoch: 41 | Batch_idx: 50 |  Loss: (0.4582) |  Loss2: (0.0000) | Acc: (84.00%) (5502/6528)
Epoch: 41 | Batch_idx: 60 |  Loss: (0.4528) |  Loss2: (0.0000) | Acc: (84.00%) (6585/7808)
Epoch: 41 | Batch_idx: 70 |  Loss: (0.4560) |  Loss2: (0.0000) | Acc: (84.00%) (7664/9088)
Epoch: 41 | Batch_idx: 80 |  Loss: (0.4497) |  Loss2: (0.0000) | Acc: (84.00%) (8764/10368)
Epoch: 41 | Batch_idx: 90 |  Loss: (0.4572) |  Loss2: (0.0000) | Acc: (84.00%) (9823/11648)
Epoch: 41 | Batch_idx: 100 |  Loss: (0.4596) |  Loss2: (0.0000) | Acc: (84.00%) (10877/12928)
Epoch: 41 | Batch_idx: 110 |  Loss: (0.4574) |  Loss2: (0.0000) | Acc: (84.00%) (11967/14208)
Epoch: 41 | Batch_idx: 120 |  Loss: (0.4600) |  Loss2: (0.0000) | Acc: (84.00%) (13023/15488)
Epoch: 41 | Batch_idx: 130 |  Loss: (0.4620) |  Loss2: (0.0000) | Acc: (84.00%) (14096/16768)
Epoch: 41 | Batch_idx: 140 |  Loss: (0.4636) |  Loss2: (0.0000) | Acc: (83.00%) (15157/18048)
Epoch: 41 | Batch_idx: 150 |  Loss: (0.4644) |  Loss2: (0.0000) | Acc: (83.00%) (16221/19328)
Epoch: 41 | Batch_idx: 160 |  Loss: (0.4660) |  Loss2: (0.0000) | Acc: (83.00%) (17278/20608)
Epoch: 41 | Batch_idx: 170 |  Loss: (0.4673) |  Loss2: (0.0000) | Acc: (83.00%) (18348/21888)
Epoch: 41 | Batch_idx: 180 |  Loss: (0.4688) |  Loss2: (0.0000) | Acc: (83.00%) (19408/23168)
Epoch: 41 | Batch_idx: 190 |  Loss: (0.4695) |  Loss2: (0.0000) | Acc: (83.00%) (20473/24448)
Epoch: 41 | Batch_idx: 200 |  Loss: (0.4701) |  Loss2: (0.0000) | Acc: (83.00%) (21547/25728)
Epoch: 41 | Batch_idx: 210 |  Loss: (0.4720) |  Loss2: (0.0000) | Acc: (83.00%) (22600/27008)
Epoch: 41 | Batch_idx: 220 |  Loss: (0.4722) |  Loss2: (0.0000) | Acc: (83.00%) (23673/28288)
Epoch: 41 | Batch_idx: 230 |  Loss: (0.4718) |  Loss2: (0.0000) | Acc: (83.00%) (24739/29568)
Epoch: 41 | Batch_idx: 240 |  Loss: (0.4728) |  Loss2: (0.0000) | Acc: (83.00%) (25803/30848)
Epoch: 41 | Batch_idx: 250 |  Loss: (0.4708) |  Loss2: (0.0000) | Acc: (83.00%) (26901/32128)
Epoch: 41 | Batch_idx: 260 |  Loss: (0.4692) |  Loss2: (0.0000) | Acc: (83.00%) (27989/33408)
Epoch: 41 | Batch_idx: 270 |  Loss: (0.4695) |  Loss2: (0.0000) | Acc: (83.00%) (29058/34688)
Epoch: 41 | Batch_idx: 280 |  Loss: (0.4720) |  Loss2: (0.0000) | Acc: (83.00%) (30103/35968)
Epoch: 41 | Batch_idx: 290 |  Loss: (0.4713) |  Loss2: (0.0000) | Acc: (83.00%) (31173/37248)
Epoch: 41 | Batch_idx: 300 |  Loss: (0.4723) |  Loss2: (0.0000) | Acc: (83.00%) (32231/38528)
Epoch: 41 | Batch_idx: 310 |  Loss: (0.4722) |  Loss2: (0.0000) | Acc: (83.00%) (33301/39808)
Epoch: 41 | Batch_idx: 320 |  Loss: (0.4725) |  Loss2: (0.0000) | Acc: (83.00%) (34374/41088)
Epoch: 41 | Batch_idx: 330 |  Loss: (0.4711) |  Loss2: (0.0000) | Acc: (83.00%) (35466/42368)
Epoch: 41 | Batch_idx: 340 |  Loss: (0.4717) |  Loss2: (0.0000) | Acc: (83.00%) (36527/43648)
Epoch: 41 | Batch_idx: 350 |  Loss: (0.4726) |  Loss2: (0.0000) | Acc: (83.00%) (37584/44928)
Epoch: 41 | Batch_idx: 360 |  Loss: (0.4731) |  Loss2: (0.0000) | Acc: (83.00%) (38639/46208)
Epoch: 41 | Batch_idx: 370 |  Loss: (0.4727) |  Loss2: (0.0000) | Acc: (83.00%) (39716/47488)
Epoch: 41 | Batch_idx: 380 |  Loss: (0.4722) |  Loss2: (0.0000) | Acc: (83.00%) (40798/48768)
Epoch: 41 | Batch_idx: 390 |  Loss: (0.4714) |  Loss2: (0.0000) | Acc: (83.00%) (41843/50000)
# TEST : Loss: (0.5054) | Acc: (82.00%) (8226/10000)
percent tensor([0.5031, 0.4978, 0.5018, 0.5053, 0.5008, 0.5064, 0.4989, 0.5026, 0.5019,
        0.4988, 0.5014, 0.4979, 0.5004, 0.5002, 0.5017, 0.5038],
       device='cuda:0') torch.Size([16])
percent tensor([0.5068, 0.5148, 0.4961, 0.5011, 0.4955, 0.5111, 0.5077, 0.4992, 0.4999,
        0.5062, 0.5086, 0.4992, 0.5076, 0.5145, 0.5122, 0.5088],
       device='cuda:0') torch.Size([16])
percent tensor([0.4985, 0.5022, 0.5210, 0.4760, 0.5070, 0.4916, 0.5074, 0.4978, 0.4883,
        0.4978, 0.4944, 0.5317, 0.5306, 0.4189, 0.5160, 0.4827],
       device='cuda:0') torch.Size([16])
percent tensor([0.6037, 0.6161, 0.6085, 0.6059, 0.6049, 0.5914, 0.6182, 0.6006, 0.6229,
        0.6231, 0.6411, 0.6217, 0.6133, 0.6354, 0.6080, 0.6095],
       device='cuda:0') torch.Size([16])
percent tensor([0.5870, 0.5683, 0.5897, 0.5647, 0.5447, 0.6654, 0.5603, 0.5243, 0.6162,
        0.5838, 0.6286, 0.5943, 0.6072, 0.6283, 0.5969, 0.5920],
       device='cuda:0') torch.Size([16])
percent tensor([0.5053, 0.5247, 0.5433, 0.5443, 0.5197, 0.5297, 0.5066, 0.4441, 0.5832,
        0.5478, 0.5740, 0.5619, 0.5437, 0.6213, 0.4409, 0.5167],
       device='cuda:0') torch.Size([16])
percent tensor([0.5802, 0.5309, 0.7329, 0.7352, 0.7694, 0.6572, 0.6283, 0.7498, 0.6272,
        0.5690, 0.5588, 0.6818, 0.5015, 0.5843, 0.6544, 0.6844],
       device='cuda:0') torch.Size([16])
percent tensor([0.9977, 0.9926, 0.9952, 0.9944, 0.9944, 0.9941, 0.9965, 0.9959, 0.9940,
        0.9950, 0.9940, 0.9920, 0.9913, 0.9951, 0.9950, 0.9974],
       device='cuda:0') torch.Size([16])
Epoch: 42 | Batch_idx: 0 |  Loss: (0.4103) |  Loss2: (0.0000) | Acc: (83.00%) (107/128)
Epoch: 42 | Batch_idx: 10 |  Loss: (0.4142) |  Loss2: (0.0000) | Acc: (85.00%) (1203/1408)
Epoch: 42 | Batch_idx: 20 |  Loss: (0.4355) |  Loss2: (0.0000) | Acc: (85.00%) (2291/2688)
Epoch: 42 | Batch_idx: 30 |  Loss: (0.4350) |  Loss2: (0.0000) | Acc: (84.00%) (3371/3968)
Epoch: 42 | Batch_idx: 40 |  Loss: (0.4359) |  Loss2: (0.0000) | Acc: (84.00%) (4449/5248)
Epoch: 42 | Batch_idx: 50 |  Loss: (0.4449) |  Loss2: (0.0000) | Acc: (84.00%) (5510/6528)
Epoch: 42 | Batch_idx: 60 |  Loss: (0.4477) |  Loss2: (0.0000) | Acc: (84.00%) (6587/7808)
Epoch: 42 | Batch_idx: 70 |  Loss: (0.4470) |  Loss2: (0.0000) | Acc: (84.00%) (7677/9088)
Epoch: 42 | Batch_idx: 80 |  Loss: (0.4483) |  Loss2: (0.0000) | Acc: (84.00%) (8749/10368)
Epoch: 42 | Batch_idx: 90 |  Loss: (0.4466) |  Loss2: (0.0000) | Acc: (84.00%) (9841/11648)
Epoch: 42 | Batch_idx: 100 |  Loss: (0.4480) |  Loss2: (0.0000) | Acc: (84.00%) (10912/12928)
Epoch: 42 | Batch_idx: 110 |  Loss: (0.4496) |  Loss2: (0.0000) | Acc: (84.00%) (12002/14208)
Epoch: 42 | Batch_idx: 120 |  Loss: (0.4545) |  Loss2: (0.0000) | Acc: (84.00%) (13060/15488)
Epoch: 42 | Batch_idx: 130 |  Loss: (0.4543) |  Loss2: (0.0000) | Acc: (84.00%) (14142/16768)
Epoch: 42 | Batch_idx: 140 |  Loss: (0.4532) |  Loss2: (0.0000) | Acc: (84.00%) (15232/18048)
Epoch: 42 | Batch_idx: 150 |  Loss: (0.4548) |  Loss2: (0.0000) | Acc: (84.00%) (16293/19328)
Epoch: 42 | Batch_idx: 160 |  Loss: (0.4537) |  Loss2: (0.0000) | Acc: (84.00%) (17384/20608)
Epoch: 42 | Batch_idx: 170 |  Loss: (0.4525) |  Loss2: (0.0000) | Acc: (84.00%) (18476/21888)
Epoch: 42 | Batch_idx: 180 |  Loss: (0.4517) |  Loss2: (0.0000) | Acc: (84.00%) (19559/23168)
Epoch: 42 | Batch_idx: 190 |  Loss: (0.4506) |  Loss2: (0.0000) | Acc: (84.00%) (20642/24448)
Epoch: 42 | Batch_idx: 200 |  Loss: (0.4507) |  Loss2: (0.0000) | Acc: (84.00%) (21724/25728)
Epoch: 42 | Batch_idx: 210 |  Loss: (0.4512) |  Loss2: (0.0000) | Acc: (84.00%) (22797/27008)
Epoch: 42 | Batch_idx: 220 |  Loss: (0.4502) |  Loss2: (0.0000) | Acc: (84.00%) (23890/28288)
Epoch: 42 | Batch_idx: 230 |  Loss: (0.4509) |  Loss2: (0.0000) | Acc: (84.00%) (24965/29568)
Epoch: 42 | Batch_idx: 240 |  Loss: (0.4525) |  Loss2: (0.0000) | Acc: (84.00%) (26024/30848)
Epoch: 42 | Batch_idx: 250 |  Loss: (0.4514) |  Loss2: (0.0000) | Acc: (84.00%) (27119/32128)
Epoch: 42 | Batch_idx: 260 |  Loss: (0.4526) |  Loss2: (0.0000) | Acc: (84.00%) (28194/33408)
Epoch: 42 | Batch_idx: 270 |  Loss: (0.4530) |  Loss2: (0.0000) | Acc: (84.00%) (29276/34688)
Epoch: 42 | Batch_idx: 280 |  Loss: (0.4540) |  Loss2: (0.0000) | Acc: (84.00%) (30342/35968)
Epoch: 42 | Batch_idx: 290 |  Loss: (0.4540) |  Loss2: (0.0000) | Acc: (84.00%) (31422/37248)
Epoch: 42 | Batch_idx: 300 |  Loss: (0.4543) |  Loss2: (0.0000) | Acc: (84.00%) (32490/38528)
Epoch: 42 | Batch_idx: 310 |  Loss: (0.4540) |  Loss2: (0.0000) | Acc: (84.00%) (33589/39808)
Epoch: 42 | Batch_idx: 320 |  Loss: (0.4542) |  Loss2: (0.0000) | Acc: (84.00%) (34662/41088)
Epoch: 42 | Batch_idx: 330 |  Loss: (0.4543) |  Loss2: (0.0000) | Acc: (84.00%) (35738/42368)
Epoch: 42 | Batch_idx: 340 |  Loss: (0.4542) |  Loss2: (0.0000) | Acc: (84.00%) (36830/43648)
Epoch: 42 | Batch_idx: 350 |  Loss: (0.4551) |  Loss2: (0.0000) | Acc: (84.00%) (37904/44928)
Epoch: 42 | Batch_idx: 360 |  Loss: (0.4543) |  Loss2: (0.0000) | Acc: (84.00%) (38999/46208)
Epoch: 42 | Batch_idx: 370 |  Loss: (0.4543) |  Loss2: (0.0000) | Acc: (84.00%) (40075/47488)
Epoch: 42 | Batch_idx: 380 |  Loss: (0.4544) |  Loss2: (0.0000) | Acc: (84.00%) (41164/48768)
Epoch: 42 | Batch_idx: 390 |  Loss: (0.4553) |  Loss2: (0.0000) | Acc: (84.00%) (42178/50000)
# TEST : Loss: (0.5904) | Acc: (80.00%) (8020/10000)
percent tensor([0.5031, 0.4975, 0.5022, 0.5055, 0.5014, 0.5061, 0.4988, 0.5023, 0.5019,
        0.4986, 0.5012, 0.4984, 0.5004, 0.4995, 0.5016, 0.5036],
       device='cuda:0') torch.Size([16])
percent tensor([0.5055, 0.5154, 0.4943, 0.5005, 0.4945, 0.5104, 0.5081, 0.4985, 0.4992,
        0.5062, 0.5082, 0.4982, 0.5062, 0.5158, 0.5121, 0.5090],
       device='cuda:0') torch.Size([16])
percent tensor([0.5028, 0.5045, 0.5140, 0.4703, 0.4995, 0.4948, 0.5076, 0.4971, 0.4927,
        0.4983, 0.5010, 0.5232, 0.5351, 0.4236, 0.5164, 0.4845],
       device='cuda:0') torch.Size([16])
percent tensor([0.6016, 0.6142, 0.6053, 0.6007, 0.6073, 0.5927, 0.6161, 0.5959, 0.6189,
        0.6207, 0.6384, 0.6235, 0.6121, 0.6298, 0.6048, 0.6075],
       device='cuda:0') torch.Size([16])
percent tensor([0.5784, 0.5714, 0.6025, 0.5763, 0.5588, 0.6641, 0.5661, 0.5394, 0.6125,
        0.5877, 0.6144, 0.6021, 0.6083, 0.6328, 0.5903, 0.5839],
       device='cuda:0') torch.Size([16])
percent tensor([0.4943, 0.5318, 0.5395, 0.5231, 0.5357, 0.5240, 0.5165, 0.4436, 0.5742,
        0.5412, 0.5585, 0.5692, 0.5415, 0.6270, 0.4354, 0.5075],
       device='cuda:0') torch.Size([16])
percent tensor([0.5858, 0.5533, 0.7336, 0.7523, 0.7665, 0.6401, 0.6404, 0.7470, 0.6220,
        0.5949, 0.5768, 0.7047, 0.5202, 0.6113, 0.6515, 0.6803],
       device='cuda:0') torch.Size([16])
percent tensor([0.9980, 0.9914, 0.9962, 0.9966, 0.9944, 0.9932, 0.9965, 0.9967, 0.9925,
        0.9948, 0.9946, 0.9951, 0.9897, 0.9952, 0.9948, 0.9979],
       device='cuda:0') torch.Size([16])
Epoch: 43 | Batch_idx: 0 |  Loss: (0.5395) |  Loss2: (0.0000) | Acc: (79.00%) (102/128)
Epoch: 43 | Batch_idx: 10 |  Loss: (0.4158) |  Loss2: (0.0000) | Acc: (86.00%) (1214/1408)
Epoch: 43 | Batch_idx: 20 |  Loss: (0.4556) |  Loss2: (0.0000) | Acc: (84.00%) (2265/2688)
Epoch: 43 | Batch_idx: 30 |  Loss: (0.4541) |  Loss2: (0.0000) | Acc: (84.00%) (3337/3968)
Epoch: 43 | Batch_idx: 40 |  Loss: (0.4425) |  Loss2: (0.0000) | Acc: (84.00%) (4430/5248)
Epoch: 43 | Batch_idx: 50 |  Loss: (0.4439) |  Loss2: (0.0000) | Acc: (84.00%) (5520/6528)
Epoch: 43 | Batch_idx: 60 |  Loss: (0.4357) |  Loss2: (0.0000) | Acc: (84.00%) (6636/7808)
Epoch: 43 | Batch_idx: 70 |  Loss: (0.4374) |  Loss2: (0.0000) | Acc: (84.00%) (7724/9088)
Epoch: 43 | Batch_idx: 80 |  Loss: (0.4352) |  Loss2: (0.0000) | Acc: (85.00%) (8818/10368)
Epoch: 43 | Batch_idx: 90 |  Loss: (0.4340) |  Loss2: (0.0000) | Acc: (85.00%) (9918/11648)
Epoch: 43 | Batch_idx: 100 |  Loss: (0.4339) |  Loss2: (0.0000) | Acc: (85.00%) (11012/12928)
Epoch: 43 | Batch_idx: 110 |  Loss: (0.4333) |  Loss2: (0.0000) | Acc: (85.00%) (12104/14208)
Epoch: 43 | Batch_idx: 120 |  Loss: (0.4330) |  Loss2: (0.0000) | Acc: (85.00%) (13202/15488)
Epoch: 43 | Batch_idx: 130 |  Loss: (0.4332) |  Loss2: (0.0000) | Acc: (85.00%) (14294/16768)
Epoch: 43 | Batch_idx: 140 |  Loss: (0.4377) |  Loss2: (0.0000) | Acc: (85.00%) (15365/18048)
Epoch: 43 | Batch_idx: 150 |  Loss: (0.4410) |  Loss2: (0.0000) | Acc: (85.00%) (16432/19328)
Epoch: 43 | Batch_idx: 160 |  Loss: (0.4409) |  Loss2: (0.0000) | Acc: (85.00%) (17530/20608)
Epoch: 43 | Batch_idx: 170 |  Loss: (0.4404) |  Loss2: (0.0000) | Acc: (84.00%) (18603/21888)
Epoch: 43 | Batch_idx: 180 |  Loss: (0.4394) |  Loss2: (0.0000) | Acc: (85.00%) (19695/23168)
Epoch: 43 | Batch_idx: 190 |  Loss: (0.4391) |  Loss2: (0.0000) | Acc: (85.00%) (20790/24448)
Epoch: 43 | Batch_idx: 200 |  Loss: (0.4386) |  Loss2: (0.0000) | Acc: (85.00%) (21875/25728)
Epoch: 43 | Batch_idx: 210 |  Loss: (0.4384) |  Loss2: (0.0000) | Acc: (85.00%) (22972/27008)
Epoch: 43 | Batch_idx: 220 |  Loss: (0.4393) |  Loss2: (0.0000) | Acc: (84.00%) (24039/28288)
Epoch: 43 | Batch_idx: 230 |  Loss: (0.4382) |  Loss2: (0.0000) | Acc: (85.00%) (25152/29568)
Epoch: 43 | Batch_idx: 240 |  Loss: (0.4370) |  Loss2: (0.0000) | Acc: (85.00%) (26236/30848)
Epoch: 43 | Batch_idx: 250 |  Loss: (0.4357) |  Loss2: (0.0000) | Acc: (85.00%) (27335/32128)
Epoch: 43 | Batch_idx: 260 |  Loss: (0.4346) |  Loss2: (0.0000) | Acc: (85.00%) (28436/33408)
Epoch: 43 | Batch_idx: 270 |  Loss: (0.4346) |  Loss2: (0.0000) | Acc: (85.00%) (29522/34688)
Epoch: 43 | Batch_idx: 280 |  Loss: (0.4351) |  Loss2: (0.0000) | Acc: (85.00%) (30607/35968)
Epoch: 43 | Batch_idx: 290 |  Loss: (0.4350) |  Loss2: (0.0000) | Acc: (85.00%) (31681/37248)
Epoch: 43 | Batch_idx: 300 |  Loss: (0.4343) |  Loss2: (0.0000) | Acc: (85.00%) (32772/38528)
Epoch: 43 | Batch_idx: 310 |  Loss: (0.4352) |  Loss2: (0.0000) | Acc: (85.00%) (33864/39808)
Epoch: 43 | Batch_idx: 320 |  Loss: (0.4343) |  Loss2: (0.0000) | Acc: (85.00%) (34960/41088)
Epoch: 43 | Batch_idx: 330 |  Loss: (0.4344) |  Loss2: (0.0000) | Acc: (85.00%) (36046/42368)
Epoch: 43 | Batch_idx: 340 |  Loss: (0.4353) |  Loss2: (0.0000) | Acc: (85.00%) (37121/43648)
Epoch: 43 | Batch_idx: 350 |  Loss: (0.4360) |  Loss2: (0.0000) | Acc: (85.00%) (38194/44928)
Epoch: 43 | Batch_idx: 360 |  Loss: (0.4371) |  Loss2: (0.0000) | Acc: (84.00%) (39256/46208)
Epoch: 43 | Batch_idx: 370 |  Loss: (0.4376) |  Loss2: (0.0000) | Acc: (84.00%) (40332/47488)
Epoch: 43 | Batch_idx: 380 |  Loss: (0.4386) |  Loss2: (0.0000) | Acc: (84.00%) (41395/48768)
Epoch: 43 | Batch_idx: 390 |  Loss: (0.4390) |  Loss2: (0.0000) | Acc: (84.00%) (42422/50000)
# TEST : Loss: (0.5250) | Acc: (81.00%) (8199/10000)
percent tensor([0.5029, 0.4982, 0.5023, 0.5052, 0.5018, 0.5065, 0.4997, 0.5025, 0.5020,
        0.4989, 0.5014, 0.4984, 0.5004, 0.5008, 0.5019, 0.5037],
       device='cuda:0') torch.Size([16])
percent tensor([0.5057, 0.5156, 0.4928, 0.5017, 0.4949, 0.5114, 0.5082, 0.4987, 0.5000,
        0.5064, 0.5083, 0.4969, 0.5062, 0.5165, 0.5129, 0.5091],
       device='cuda:0') torch.Size([16])
percent tensor([0.5073, 0.5100, 0.5135, 0.4762, 0.4966, 0.4965, 0.5080, 0.4950, 0.4905,
        0.5000, 0.5019, 0.5235, 0.5365, 0.4271, 0.5203, 0.4915],
       device='cuda:0') torch.Size([16])
percent tensor([0.6019, 0.6122, 0.6045, 0.6002, 0.6049, 0.5869, 0.6155, 0.5983, 0.6213,
        0.6188, 0.6398, 0.6244, 0.6151, 0.6225, 0.6047, 0.6042],
       device='cuda:0') torch.Size([16])
percent tensor([0.5774, 0.5705, 0.5950, 0.5809, 0.5570, 0.6651, 0.5745, 0.5479, 0.6096,
        0.5842, 0.6191, 0.5938, 0.6012, 0.6222, 0.5922, 0.5947],
       device='cuda:0') torch.Size([16])
percent tensor([0.4857, 0.5114, 0.5291, 0.5251, 0.5173, 0.5174, 0.4975, 0.4314, 0.5664,
        0.5108, 0.5532, 0.5566, 0.5320, 0.6009, 0.4335, 0.5023],
       device='cuda:0') torch.Size([16])
percent tensor([0.5806, 0.5418, 0.7468, 0.7423, 0.7743, 0.6618, 0.6557, 0.7629, 0.6024,
        0.5850, 0.5687, 0.6898, 0.5128, 0.5788, 0.6415, 0.6690],
       device='cuda:0') torch.Size([16])
percent tensor([0.9980, 0.9919, 0.9960, 0.9962, 0.9955, 0.9941, 0.9940, 0.9971, 0.9924,
        0.9949, 0.9948, 0.9931, 0.9927, 0.9948, 0.9947, 0.9978],
       device='cuda:0') torch.Size([16])
Epoch: 44 | Batch_idx: 0 |  Loss: (0.4024) |  Loss2: (0.0000) | Acc: (86.00%) (111/128)
Epoch: 44 | Batch_idx: 10 |  Loss: (0.4071) |  Loss2: (0.0000) | Acc: (85.00%) (1209/1408)
Epoch: 44 | Batch_idx: 20 |  Loss: (0.3986) |  Loss2: (0.0000) | Acc: (86.00%) (2312/2688)
Epoch: 44 | Batch_idx: 30 |  Loss: (0.4056) |  Loss2: (0.0000) | Acc: (85.00%) (3408/3968)
Epoch: 44 | Batch_idx: 40 |  Loss: (0.4104) |  Loss2: (0.0000) | Acc: (85.00%) (4495/5248)
Epoch: 44 | Batch_idx: 50 |  Loss: (0.4103) |  Loss2: (0.0000) | Acc: (85.00%) (5592/6528)
Epoch: 44 | Batch_idx: 60 |  Loss: (0.4066) |  Loss2: (0.0000) | Acc: (85.00%) (6708/7808)
Epoch: 44 | Batch_idx: 70 |  Loss: (0.4084) |  Loss2: (0.0000) | Acc: (85.00%) (7799/9088)
Epoch: 44 | Batch_idx: 80 |  Loss: (0.4114) |  Loss2: (0.0000) | Acc: (85.00%) (8897/10368)
Epoch: 44 | Batch_idx: 90 |  Loss: (0.4103) |  Loss2: (0.0000) | Acc: (85.00%) (10005/11648)
Epoch: 44 | Batch_idx: 100 |  Loss: (0.4133) |  Loss2: (0.0000) | Acc: (85.00%) (11094/12928)
Epoch: 44 | Batch_idx: 110 |  Loss: (0.4155) |  Loss2: (0.0000) | Acc: (85.00%) (12184/14208)
Epoch: 44 | Batch_idx: 120 |  Loss: (0.4152) |  Loss2: (0.0000) | Acc: (85.00%) (13276/15488)
Epoch: 44 | Batch_idx: 130 |  Loss: (0.4163) |  Loss2: (0.0000) | Acc: (85.00%) (14364/16768)
Epoch: 44 | Batch_idx: 140 |  Loss: (0.4184) |  Loss2: (0.0000) | Acc: (85.00%) (15442/18048)
Epoch: 44 | Batch_idx: 150 |  Loss: (0.4177) |  Loss2: (0.0000) | Acc: (85.00%) (16544/19328)
Epoch: 44 | Batch_idx: 160 |  Loss: (0.4200) |  Loss2: (0.0000) | Acc: (85.00%) (17620/20608)
Epoch: 44 | Batch_idx: 170 |  Loss: (0.4215) |  Loss2: (0.0000) | Acc: (85.00%) (18698/21888)
Epoch: 44 | Batch_idx: 180 |  Loss: (0.4233) |  Loss2: (0.0000) | Acc: (85.00%) (19766/23168)
Epoch: 44 | Batch_idx: 190 |  Loss: (0.4230) |  Loss2: (0.0000) | Acc: (85.00%) (20860/24448)
Epoch: 44 | Batch_idx: 200 |  Loss: (0.4244) |  Loss2: (0.0000) | Acc: (85.00%) (21939/25728)
Epoch: 44 | Batch_idx: 210 |  Loss: (0.4255) |  Loss2: (0.0000) | Acc: (85.00%) (23017/27008)
Epoch: 44 | Batch_idx: 220 |  Loss: (0.4253) |  Loss2: (0.0000) | Acc: (85.00%) (24111/28288)
Epoch: 44 | Batch_idx: 230 |  Loss: (0.4253) |  Loss2: (0.0000) | Acc: (85.00%) (25200/29568)
Epoch: 44 | Batch_idx: 240 |  Loss: (0.4246) |  Loss2: (0.0000) | Acc: (85.00%) (26297/30848)
Epoch: 44 | Batch_idx: 250 |  Loss: (0.4251) |  Loss2: (0.0000) | Acc: (85.00%) (27381/32128)
Epoch: 44 | Batch_idx: 260 |  Loss: (0.4261) |  Loss2: (0.0000) | Acc: (85.00%) (28462/33408)
Epoch: 44 | Batch_idx: 270 |  Loss: (0.4266) |  Loss2: (0.0000) | Acc: (85.00%) (29562/34688)
Epoch: 44 | Batch_idx: 280 |  Loss: (0.4266) |  Loss2: (0.0000) | Acc: (85.00%) (30661/35968)
Epoch: 44 | Batch_idx: 290 |  Loss: (0.4268) |  Loss2: (0.0000) | Acc: (85.00%) (31740/37248)
Epoch: 44 | Batch_idx: 300 |  Loss: (0.4268) |  Loss2: (0.0000) | Acc: (85.00%) (32831/38528)
Epoch: 44 | Batch_idx: 310 |  Loss: (0.4266) |  Loss2: (0.0000) | Acc: (85.00%) (33931/39808)
Epoch: 44 | Batch_idx: 320 |  Loss: (0.4265) |  Loss2: (0.0000) | Acc: (85.00%) (35025/41088)
Epoch: 44 | Batch_idx: 330 |  Loss: (0.4264) |  Loss2: (0.0000) | Acc: (85.00%) (36119/42368)
Epoch: 44 | Batch_idx: 340 |  Loss: (0.4270) |  Loss2: (0.0000) | Acc: (85.00%) (37202/43648)
Epoch: 44 | Batch_idx: 350 |  Loss: (0.4259) |  Loss2: (0.0000) | Acc: (85.00%) (38296/44928)
Epoch: 44 | Batch_idx: 360 |  Loss: (0.4255) |  Loss2: (0.0000) | Acc: (85.00%) (39395/46208)
Epoch: 44 | Batch_idx: 370 |  Loss: (0.4261) |  Loss2: (0.0000) | Acc: (85.00%) (40489/47488)
Epoch: 44 | Batch_idx: 380 |  Loss: (0.4256) |  Loss2: (0.0000) | Acc: (85.00%) (41587/48768)
Epoch: 44 | Batch_idx: 390 |  Loss: (0.4253) |  Loss2: (0.0000) | Acc: (85.00%) (42645/50000)
# TEST : Loss: (0.5136) | Acc: (82.00%) (8213/10000)
percent tensor([0.5029, 0.4974, 0.5020, 0.5054, 0.5014, 0.5062, 0.4988, 0.5024, 0.5018,
        0.4985, 0.5011, 0.4981, 0.5003, 0.4996, 0.5017, 0.5035],
       device='cuda:0') torch.Size([16])
percent tensor([0.5061, 0.5143, 0.4953, 0.5002, 0.4956, 0.5113, 0.5077, 0.4983, 0.5002,
        0.5051, 0.5079, 0.4979, 0.5060, 0.5147, 0.5114, 0.5081],
       device='cuda:0') torch.Size([16])
percent tensor([0.5006, 0.5102, 0.5026, 0.4751, 0.4896, 0.4932, 0.5061, 0.4973, 0.4907,
        0.4999, 0.4993, 0.5183, 0.5375, 0.4307, 0.5170, 0.4898],
       device='cuda:0') torch.Size([16])
percent tensor([0.6032, 0.6168, 0.6065, 0.6019, 0.6058, 0.5904, 0.6198, 0.5984, 0.6203,
        0.6236, 0.6434, 0.6296, 0.6159, 0.6282, 0.6082, 0.6064],
       device='cuda:0') torch.Size([16])
percent tensor([0.5685, 0.5517, 0.5911, 0.5673, 0.5574, 0.6659, 0.5479, 0.5237, 0.5993,
        0.5620, 0.6058, 0.5795, 0.5854, 0.6138, 0.5759, 0.5719],
       device='cuda:0') torch.Size([16])
percent tensor([0.4959, 0.5132, 0.5308, 0.5217, 0.5248, 0.5311, 0.4942, 0.4294, 0.5627,
        0.5109, 0.5540, 0.5594, 0.5349, 0.6021, 0.4398, 0.5002],
       device='cuda:0') torch.Size([16])
percent tensor([0.5834, 0.5611, 0.7325, 0.7421, 0.7640, 0.6626, 0.6639, 0.7596, 0.5987,
        0.5840, 0.5656, 0.6753, 0.5078, 0.6046, 0.6507, 0.6928],
       device='cuda:0') torch.Size([16])
percent tensor([0.9981, 0.9928, 0.9957, 0.9964, 0.9953, 0.9954, 0.9961, 0.9976, 0.9928,
        0.9951, 0.9941, 0.9940, 0.9912, 0.9949, 0.9952, 0.9984],
       device='cuda:0') torch.Size([16])
False Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=128, out_features=16, bias=False)
True Linear(in_features=16, out_features=2, bias=False)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=128, out_features=16, bias=False)
True Linear(in_features=16, out_features=2, bias=False)
False Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=256, out_features=32, bias=False)
True Linear(in_features=32, out_features=2, bias=False)
False Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=256, out_features=32, bias=False)
True Linear(in_features=32, out_features=2, bias=False)
False Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=512, out_features=64, bias=False)
True Linear(in_features=64, out_features=2, bias=False)
False Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=512, out_features=64, bias=False)
True Linear(in_features=64, out_features=2, bias=False)
False Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1024, out_features=128, bias=False)
True Linear(in_features=128, out_features=2, bias=False)
False Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1024, out_features=128, bias=False)
True Linear(in_features=128, out_features=2, bias=False)
False Linear(in_features=512, out_features=10, bias=True)
Epoch: 45 | Batch_idx: 0 |  Loss: (0.3992) |  Loss2: (0.0000) | Acc: (85.00%) (109/128)
Epoch: 45 | Batch_idx: 10 |  Loss: (0.4231) |  Loss2: (0.0000) | Acc: (85.00%) (1199/1408)
Epoch: 45 | Batch_idx: 20 |  Loss: (0.4226) |  Loss2: (0.0000) | Acc: (85.00%) (2294/2688)
Epoch: 45 | Batch_idx: 30 |  Loss: (0.4398) |  Loss2: (0.0000) | Acc: (84.00%) (3355/3968)
Epoch: 45 | Batch_idx: 40 |  Loss: (0.4511) |  Loss2: (0.0000) | Acc: (84.00%) (4434/5248)
Epoch: 45 | Batch_idx: 50 |  Loss: (0.4553) |  Loss2: (0.0000) | Acc: (84.00%) (5509/6528)
Epoch: 45 | Batch_idx: 60 |  Loss: (0.4540) |  Loss2: (0.0000) | Acc: (84.00%) (6596/7808)
Epoch: 45 | Batch_idx: 70 |  Loss: (0.4601) |  Loss2: (0.0000) | Acc: (84.00%) (7653/9088)
Epoch: 45 | Batch_idx: 80 |  Loss: (0.4653) |  Loss2: (0.0000) | Acc: (84.00%) (8720/10368)
Epoch: 45 | Batch_idx: 90 |  Loss: (0.4686) |  Loss2: (0.0000) | Acc: (83.00%) (9778/11648)
Epoch: 45 | Batch_idx: 100 |  Loss: (0.4701) |  Loss2: (0.0000) | Acc: (83.00%) (10843/12928)
Epoch: 45 | Batch_idx: 110 |  Loss: (0.4657) |  Loss2: (0.0000) | Acc: (83.00%) (11929/14208)
Epoch: 45 | Batch_idx: 120 |  Loss: (0.4652) |  Loss2: (0.0000) | Acc: (83.00%) (12998/15488)
Epoch: 45 | Batch_idx: 130 |  Loss: (0.4627) |  Loss2: (0.0000) | Acc: (83.00%) (14082/16768)
Epoch: 45 | Batch_idx: 140 |  Loss: (0.4626) |  Loss2: (0.0000) | Acc: (83.00%) (15156/18048)
Epoch: 45 | Batch_idx: 150 |  Loss: (0.4620) |  Loss2: (0.0000) | Acc: (84.00%) (16242/19328)
Epoch: 45 | Batch_idx: 160 |  Loss: (0.4632) |  Loss2: (0.0000) | Acc: (84.00%) (17319/20608)
Epoch: 45 | Batch_idx: 170 |  Loss: (0.4635) |  Loss2: (0.0000) | Acc: (84.00%) (18386/21888)
Epoch: 45 | Batch_idx: 180 |  Loss: (0.4620) |  Loss2: (0.0000) | Acc: (84.00%) (19465/23168)
Epoch: 45 | Batch_idx: 190 |  Loss: (0.4610) |  Loss2: (0.0000) | Acc: (84.00%) (20540/24448)
Epoch: 45 | Batch_idx: 200 |  Loss: (0.4616) |  Loss2: (0.0000) | Acc: (83.00%) (21602/25728)
Epoch: 45 | Batch_idx: 210 |  Loss: (0.4608) |  Loss2: (0.0000) | Acc: (83.00%) (22682/27008)
Epoch: 45 | Batch_idx: 220 |  Loss: (0.4601) |  Loss2: (0.0000) | Acc: (83.00%) (23756/28288)
Epoch: 45 | Batch_idx: 230 |  Loss: (0.4607) |  Loss2: (0.0000) | Acc: (83.00%) (24820/29568)
Epoch: 45 | Batch_idx: 240 |  Loss: (0.4611) |  Loss2: (0.0000) | Acc: (83.00%) (25898/30848)
Epoch: 45 | Batch_idx: 250 |  Loss: (0.4594) |  Loss2: (0.0000) | Acc: (83.00%) (26982/32128)
Epoch: 45 | Batch_idx: 260 |  Loss: (0.4592) |  Loss2: (0.0000) | Acc: (83.00%) (28053/33408)
Epoch: 45 | Batch_idx: 270 |  Loss: (0.4586) |  Loss2: (0.0000) | Acc: (83.00%) (29131/34688)
Epoch: 45 | Batch_idx: 280 |  Loss: (0.4596) |  Loss2: (0.0000) | Acc: (83.00%) (30192/35968)
Epoch: 45 | Batch_idx: 290 |  Loss: (0.4601) |  Loss2: (0.0000) | Acc: (83.00%) (31250/37248)
Epoch: 45 | Batch_idx: 300 |  Loss: (0.4598) |  Loss2: (0.0000) | Acc: (83.00%) (32335/38528)
Epoch: 45 | Batch_idx: 310 |  Loss: (0.4592) |  Loss2: (0.0000) | Acc: (83.00%) (33414/39808)
Epoch: 45 | Batch_idx: 320 |  Loss: (0.4575) |  Loss2: (0.0000) | Acc: (83.00%) (34511/41088)
Epoch: 45 | Batch_idx: 330 |  Loss: (0.4563) |  Loss2: (0.0000) | Acc: (84.00%) (35614/42368)
Epoch: 45 | Batch_idx: 340 |  Loss: (0.4557) |  Loss2: (0.0000) | Acc: (84.00%) (36698/43648)
Epoch: 45 | Batch_idx: 350 |  Loss: (0.4565) |  Loss2: (0.0000) | Acc: (84.00%) (37762/44928)
Epoch: 45 | Batch_idx: 360 |  Loss: (0.4564) |  Loss2: (0.0000) | Acc: (84.00%) (38850/46208)
Epoch: 45 | Batch_idx: 370 |  Loss: (0.4553) |  Loss2: (0.0000) | Acc: (84.00%) (39940/47488)
Epoch: 45 | Batch_idx: 380 |  Loss: (0.4547) |  Loss2: (0.0000) | Acc: (84.00%) (41034/48768)
Epoch: 45 | Batch_idx: 390 |  Loss: (0.4534) |  Loss2: (0.0000) | Acc: (84.00%) (42099/50000)
=> saving checkpoint 'drive/app/torch/save_Routing_Gate_2/checkpoint_045.pth.tar'
# TEST : Loss: (0.5080) | Acc: (82.00%) (8264/10000)
percent tensor([0.5039, 0.4985, 0.5036, 0.5066, 0.5029, 0.5066, 0.5000, 0.5040, 0.5031,
        0.4999, 0.5021, 0.4998, 0.5015, 0.5003, 0.5024, 0.5043],
       device='cuda:0') torch.Size([16])
percent tensor([0.5153, 0.5246, 0.5048, 0.5097, 0.5066, 0.5230, 0.5188, 0.5083, 0.5089,
        0.5148, 0.5168, 0.5079, 0.5143, 0.5246, 0.5224, 0.5180],
       device='cuda:0') torch.Size([16])
percent tensor([0.4986, 0.5245, 0.5119, 0.4711, 0.4953, 0.4606, 0.5204, 0.5052, 0.5021,
        0.5162, 0.5074, 0.5358, 0.5529, 0.4292, 0.5127, 0.4810],
       device='cuda:0') torch.Size([16])
percent tensor([0.6177, 0.6363, 0.6120, 0.6102, 0.6135, 0.6084, 0.6325, 0.6057, 0.6319,
        0.6401, 0.6602, 0.6393, 0.6347, 0.6422, 0.6247, 0.6228],
       device='cuda:0') torch.Size([16])
percent tensor([0.5555, 0.5401, 0.5690, 0.5591, 0.5323, 0.6701, 0.5286, 0.4921, 0.5897,
        0.5489, 0.5910, 0.5432, 0.5819, 0.6078, 0.5502, 0.5729],
       device='cuda:0') torch.Size([16])
percent tensor([0.5088, 0.5382, 0.5301, 0.5257, 0.5196, 0.5287, 0.5081, 0.4364, 0.5751,
        0.5258, 0.5652, 0.5626, 0.5487, 0.6154, 0.4580, 0.5050],
       device='cuda:0') torch.Size([16])
percent tensor([0.5908, 0.5718, 0.7462, 0.7539, 0.7844, 0.6496, 0.6672, 0.7725, 0.6264,
        0.5965, 0.5925, 0.6964, 0.5179, 0.6292, 0.6496, 0.6931],
       device='cuda:0') torch.Size([16])
percent tensor([0.9979, 0.9925, 0.9956, 0.9959, 0.9952, 0.9951, 0.9960, 0.9976, 0.9938,
        0.9951, 0.9944, 0.9934, 0.9893, 0.9959, 0.9947, 0.9982],
       device='cuda:0') torch.Size([16])
Epoch: 46 | Batch_idx: 0 |  Loss: (0.3243) |  Loss2: (0.0000) | Acc: (88.00%) (113/128)
Epoch: 46 | Batch_idx: 10 |  Loss: (0.3821) |  Loss2: (0.0000) | Acc: (86.00%) (1213/1408)
Epoch: 46 | Batch_idx: 20 |  Loss: (0.3880) |  Loss2: (0.0000) | Acc: (86.00%) (2328/2688)
Epoch: 46 | Batch_idx: 30 |  Loss: (0.4190) |  Loss2: (0.0000) | Acc: (85.00%) (3394/3968)
Epoch: 46 | Batch_idx: 40 |  Loss: (0.4167) |  Loss2: (0.0000) | Acc: (85.00%) (4482/5248)
Epoch: 46 | Batch_idx: 50 |  Loss: (0.4202) |  Loss2: (0.0000) | Acc: (85.00%) (5560/6528)
Epoch: 46 | Batch_idx: 60 |  Loss: (0.4221) |  Loss2: (0.0000) | Acc: (85.00%) (6657/7808)
Epoch: 46 | Batch_idx: 70 |  Loss: (0.4187) |  Loss2: (0.0000) | Acc: (85.00%) (7756/9088)
Epoch: 46 | Batch_idx: 80 |  Loss: (0.4196) |  Loss2: (0.0000) | Acc: (85.00%) (8847/10368)
Epoch: 46 | Batch_idx: 90 |  Loss: (0.4221) |  Loss2: (0.0000) | Acc: (85.00%) (9930/11648)
Epoch: 46 | Batch_idx: 100 |  Loss: (0.4237) |  Loss2: (0.0000) | Acc: (85.00%) (11009/12928)
Epoch: 46 | Batch_idx: 110 |  Loss: (0.4237) |  Loss2: (0.0000) | Acc: (85.00%) (12095/14208)
Epoch: 46 | Batch_idx: 120 |  Loss: (0.4221) |  Loss2: (0.0000) | Acc: (85.00%) (13202/15488)
Epoch: 46 | Batch_idx: 130 |  Loss: (0.4223) |  Loss2: (0.0000) | Acc: (85.00%) (14280/16768)
Epoch: 46 | Batch_idx: 140 |  Loss: (0.4200) |  Loss2: (0.0000) | Acc: (85.00%) (15384/18048)
Epoch: 46 | Batch_idx: 150 |  Loss: (0.4194) |  Loss2: (0.0000) | Acc: (85.00%) (16470/19328)
Epoch: 46 | Batch_idx: 160 |  Loss: (0.4207) |  Loss2: (0.0000) | Acc: (85.00%) (17549/20608)
Epoch: 46 | Batch_idx: 170 |  Loss: (0.4214) |  Loss2: (0.0000) | Acc: (85.00%) (18634/21888)
Epoch: 46 | Batch_idx: 180 |  Loss: (0.4204) |  Loss2: (0.0000) | Acc: (85.00%) (19736/23168)
Epoch: 46 | Batch_idx: 190 |  Loss: (0.4214) |  Loss2: (0.0000) | Acc: (85.00%) (20817/24448)
Epoch: 46 | Batch_idx: 200 |  Loss: (0.4214) |  Loss2: (0.0000) | Acc: (85.00%) (21902/25728)
Epoch: 46 | Batch_idx: 210 |  Loss: (0.4211) |  Loss2: (0.0000) | Acc: (85.00%) (22985/27008)
Epoch: 46 | Batch_idx: 220 |  Loss: (0.4212) |  Loss2: (0.0000) | Acc: (85.00%) (24091/28288)
Epoch: 46 | Batch_idx: 230 |  Loss: (0.4217) |  Loss2: (0.0000) | Acc: (85.00%) (25177/29568)
Epoch: 46 | Batch_idx: 240 |  Loss: (0.4213) |  Loss2: (0.0000) | Acc: (85.00%) (26275/30848)
Epoch: 46 | Batch_idx: 250 |  Loss: (0.4227) |  Loss2: (0.0000) | Acc: (85.00%) (27351/32128)
Epoch: 46 | Batch_idx: 260 |  Loss: (0.4213) |  Loss2: (0.0000) | Acc: (85.00%) (28464/33408)
Epoch: 46 | Batch_idx: 270 |  Loss: (0.4213) |  Loss2: (0.0000) | Acc: (85.00%) (29562/34688)
Epoch: 46 | Batch_idx: 280 |  Loss: (0.4215) |  Loss2: (0.0000) | Acc: (85.00%) (30648/35968)
Epoch: 46 | Batch_idx: 290 |  Loss: (0.4214) |  Loss2: (0.0000) | Acc: (85.00%) (31747/37248)
Epoch: 46 | Batch_idx: 300 |  Loss: (0.4219) |  Loss2: (0.0000) | Acc: (85.00%) (32838/38528)
Epoch: 46 | Batch_idx: 310 |  Loss: (0.4226) |  Loss2: (0.0000) | Acc: (85.00%) (33915/39808)
Epoch: 46 | Batch_idx: 320 |  Loss: (0.4233) |  Loss2: (0.0000) | Acc: (85.00%) (35006/41088)
Epoch: 46 | Batch_idx: 330 |  Loss: (0.4236) |  Loss2: (0.0000) | Acc: (85.00%) (36096/42368)
Epoch: 46 | Batch_idx: 340 |  Loss: (0.4236) |  Loss2: (0.0000) | Acc: (85.00%) (37188/43648)
Epoch: 46 | Batch_idx: 350 |  Loss: (0.4231) |  Loss2: (0.0000) | Acc: (85.00%) (38285/44928)
Epoch: 46 | Batch_idx: 360 |  Loss: (0.4236) |  Loss2: (0.0000) | Acc: (85.00%) (39375/46208)
Epoch: 46 | Batch_idx: 370 |  Loss: (0.4231) |  Loss2: (0.0000) | Acc: (85.00%) (40475/47488)
Epoch: 46 | Batch_idx: 380 |  Loss: (0.4235) |  Loss2: (0.0000) | Acc: (85.00%) (41571/48768)
Epoch: 46 | Batch_idx: 390 |  Loss: (0.4230) |  Loss2: (0.0000) | Acc: (85.00%) (42638/50000)
# TEST : Loss: (0.4845) | Acc: (83.00%) (8328/10000)
percent tensor([0.5045, 0.4990, 0.5047, 0.5073, 0.5038, 0.5069, 0.5006, 0.5050, 0.5039,
        0.5006, 0.5027, 0.5007, 0.5023, 0.5007, 0.5029, 0.5048],
       device='cuda:0') torch.Size([16])
percent tensor([0.5197, 0.5291, 0.5096, 0.5147, 0.5119, 0.5293, 0.5237, 0.5131, 0.5130,
        0.5189, 0.5204, 0.5121, 0.5180, 0.5287, 0.5276, 0.5226],
       device='cuda:0') torch.Size([16])
percent tensor([0.4917, 0.5238, 0.5083, 0.4613, 0.4907, 0.4416, 0.5201, 0.4987, 0.4992,
        0.5167, 0.5067, 0.5369, 0.5524, 0.4245, 0.5039, 0.4715],
       device='cuda:0') torch.Size([16])
percent tensor([0.6278, 0.6496, 0.6206, 0.6191, 0.6225, 0.6190, 0.6437, 0.6154, 0.6413,
        0.6532, 0.6718, 0.6500, 0.6478, 0.6529, 0.6363, 0.6345],
       device='cuda:0') torch.Size([16])
percent tensor([0.5583, 0.5433, 0.5683, 0.5585, 0.5358, 0.6778, 0.5329, 0.4879, 0.5905,
        0.5538, 0.5945, 0.5377, 0.5839, 0.6136, 0.5463, 0.5830],
       device='cuda:0') torch.Size([16])
percent tensor([0.5145, 0.5562, 0.5336, 0.5280, 0.5223, 0.5174, 0.5203, 0.4437, 0.5877,
        0.5395, 0.5796, 0.5749, 0.5593, 0.6306, 0.4677, 0.5029],
       device='cuda:0') torch.Size([16])
percent tensor([0.5965, 0.5808, 0.7545, 0.7676, 0.7948, 0.6342, 0.6738, 0.7833, 0.6327,
        0.6124, 0.6092, 0.7123, 0.5180, 0.6482, 0.6516, 0.6925],
       device='cuda:0') torch.Size([16])
percent tensor([0.9980, 0.9928, 0.9960, 0.9963, 0.9953, 0.9946, 0.9963, 0.9978, 0.9944,
        0.9955, 0.9948, 0.9937, 0.9905, 0.9961, 0.9950, 0.9984],
       device='cuda:0') torch.Size([16])
Epoch: 47 | Batch_idx: 0 |  Loss: (0.4092) |  Loss2: (0.0000) | Acc: (84.00%) (108/128)
Epoch: 47 | Batch_idx: 10 |  Loss: (0.4081) |  Loss2: (0.0000) | Acc: (85.00%) (1204/1408)
Epoch: 47 | Batch_idx: 20 |  Loss: (0.4137) |  Loss2: (0.0000) | Acc: (85.00%) (2295/2688)
Epoch: 47 | Batch_idx: 30 |  Loss: (0.4151) |  Loss2: (0.0000) | Acc: (85.00%) (3382/3968)
Epoch: 47 | Batch_idx: 40 |  Loss: (0.4066) |  Loss2: (0.0000) | Acc: (85.00%) (4491/5248)
Epoch: 47 | Batch_idx: 50 |  Loss: (0.4059) |  Loss2: (0.0000) | Acc: (85.00%) (5593/6528)
Epoch: 47 | Batch_idx: 60 |  Loss: (0.4108) |  Loss2: (0.0000) | Acc: (85.00%) (6675/7808)
Epoch: 47 | Batch_idx: 70 |  Loss: (0.4129) |  Loss2: (0.0000) | Acc: (85.00%) (7763/9088)
Epoch: 47 | Batch_idx: 80 |  Loss: (0.4092) |  Loss2: (0.0000) | Acc: (85.00%) (8876/10368)
Epoch: 47 | Batch_idx: 90 |  Loss: (0.4085) |  Loss2: (0.0000) | Acc: (85.00%) (9969/11648)
Epoch: 47 | Batch_idx: 100 |  Loss: (0.4083) |  Loss2: (0.0000) | Acc: (85.00%) (11073/12928)
Epoch: 47 | Batch_idx: 110 |  Loss: (0.4095) |  Loss2: (0.0000) | Acc: (85.00%) (12162/14208)
Epoch: 47 | Batch_idx: 120 |  Loss: (0.4093) |  Loss2: (0.0000) | Acc: (85.00%) (13257/15488)
Epoch: 47 | Batch_idx: 130 |  Loss: (0.4104) |  Loss2: (0.0000) | Acc: (85.00%) (14350/16768)
Epoch: 47 | Batch_idx: 140 |  Loss: (0.4119) |  Loss2: (0.0000) | Acc: (85.00%) (15437/18048)
Epoch: 47 | Batch_idx: 150 |  Loss: (0.4101) |  Loss2: (0.0000) | Acc: (85.00%) (16561/19328)
Epoch: 47 | Batch_idx: 160 |  Loss: (0.4099) |  Loss2: (0.0000) | Acc: (85.00%) (17652/20608)
Epoch: 47 | Batch_idx: 170 |  Loss: (0.4127) |  Loss2: (0.0000) | Acc: (85.00%) (18734/21888)
Epoch: 47 | Batch_idx: 180 |  Loss: (0.4145) |  Loss2: (0.0000) | Acc: (85.00%) (19823/23168)
Epoch: 47 | Batch_idx: 190 |  Loss: (0.4139) |  Loss2: (0.0000) | Acc: (85.00%) (20911/24448)
Epoch: 47 | Batch_idx: 200 |  Loss: (0.4139) |  Loss2: (0.0000) | Acc: (85.00%) (22013/25728)
Epoch: 47 | Batch_idx: 210 |  Loss: (0.4124) |  Loss2: (0.0000) | Acc: (85.00%) (23117/27008)
Epoch: 47 | Batch_idx: 220 |  Loss: (0.4116) |  Loss2: (0.0000) | Acc: (85.00%) (24227/28288)
Epoch: 47 | Batch_idx: 230 |  Loss: (0.4099) |  Loss2: (0.0000) | Acc: (85.00%) (25338/29568)
Epoch: 47 | Batch_idx: 240 |  Loss: (0.4085) |  Loss2: (0.0000) | Acc: (85.00%) (26466/30848)
Epoch: 47 | Batch_idx: 250 |  Loss: (0.4093) |  Loss2: (0.0000) | Acc: (85.00%) (27553/32128)
Epoch: 47 | Batch_idx: 260 |  Loss: (0.4104) |  Loss2: (0.0000) | Acc: (85.00%) (28640/33408)
Epoch: 47 | Batch_idx: 270 |  Loss: (0.4108) |  Loss2: (0.0000) | Acc: (85.00%) (29727/34688)
Epoch: 47 | Batch_idx: 280 |  Loss: (0.4117) |  Loss2: (0.0000) | Acc: (85.00%) (30809/35968)
Epoch: 47 | Batch_idx: 290 |  Loss: (0.4122) |  Loss2: (0.0000) | Acc: (85.00%) (31899/37248)
Epoch: 47 | Batch_idx: 300 |  Loss: (0.4111) |  Loss2: (0.0000) | Acc: (85.00%) (33010/38528)
Epoch: 47 | Batch_idx: 310 |  Loss: (0.4121) |  Loss2: (0.0000) | Acc: (85.00%) (34116/39808)
Epoch: 47 | Batch_idx: 320 |  Loss: (0.4114) |  Loss2: (0.0000) | Acc: (85.00%) (35221/41088)
Epoch: 47 | Batch_idx: 330 |  Loss: (0.4111) |  Loss2: (0.0000) | Acc: (85.00%) (36322/42368)
Epoch: 47 | Batch_idx: 340 |  Loss: (0.4114) |  Loss2: (0.0000) | Acc: (85.00%) (37414/43648)
Epoch: 47 | Batch_idx: 350 |  Loss: (0.4116) |  Loss2: (0.0000) | Acc: (85.00%) (38498/44928)
Epoch: 47 | Batch_idx: 360 |  Loss: (0.4113) |  Loss2: (0.0000) | Acc: (85.00%) (39609/46208)
Epoch: 47 | Batch_idx: 370 |  Loss: (0.4115) |  Loss2: (0.0000) | Acc: (85.00%) (40710/47488)
Epoch: 47 | Batch_idx: 380 |  Loss: (0.4110) |  Loss2: (0.0000) | Acc: (85.00%) (41818/48768)
Epoch: 47 | Batch_idx: 390 |  Loss: (0.4108) |  Loss2: (0.0000) | Acc: (85.00%) (42876/50000)
# TEST : Loss: (0.4737) | Acc: (83.00%) (8363/10000)
percent tensor([0.5048, 0.4996, 0.5053, 0.5079, 0.5043, 0.5070, 0.5011, 0.5057, 0.5044,
        0.5012, 0.5031, 0.5012, 0.5027, 0.5013, 0.5033, 0.5051],
       device='cuda:0') torch.Size([16])
percent tensor([0.5221, 0.5312, 0.5123, 0.5174, 0.5149, 0.5332, 0.5261, 0.5155, 0.5150,
        0.5208, 0.5222, 0.5142, 0.5199, 0.5303, 0.5305, 0.5251],
       device='cuda:0') torch.Size([16])
percent tensor([0.4963, 0.5355, 0.5098, 0.4626, 0.4919, 0.4427, 0.5280, 0.4998, 0.5049,
        0.5260, 0.5170, 0.5435, 0.5613, 0.4340, 0.5111, 0.4764],
       device='cuda:0') torch.Size([16])
percent tensor([0.6346, 0.6580, 0.6287, 0.6268, 0.6300, 0.6256, 0.6506, 0.6234, 0.6475,
        0.6616, 0.6788, 0.6585, 0.6569, 0.6577, 0.6440, 0.6423],
       device='cuda:0') torch.Size([16])
percent tensor([0.5629, 0.5428, 0.5721, 0.5634, 0.5437, 0.6869, 0.5369, 0.4947, 0.5899,
        0.5567, 0.5937, 0.5388, 0.5835, 0.6133, 0.5481, 0.5926],
       device='cuda:0') torch.Size([16])
percent tensor([0.5076, 0.5535, 0.5281, 0.5203, 0.5142, 0.5022, 0.5150, 0.4351, 0.5861,
        0.5354, 0.5790, 0.5722, 0.5546, 0.6287, 0.4612, 0.4900],
       device='cuda:0') torch.Size([16])
percent tensor([0.5966, 0.5870, 0.7526, 0.7670, 0.7926, 0.6267, 0.6687, 0.7754, 0.6369,
        0.6175, 0.6194, 0.7166, 0.5283, 0.6535, 0.6461, 0.6834],
       device='cuda:0') torch.Size([16])
percent tensor([0.9983, 0.9936, 0.9964, 0.9968, 0.9958, 0.9950, 0.9967, 0.9980, 0.9950,
        0.9960, 0.9954, 0.9943, 0.9914, 0.9966, 0.9953, 0.9985],
       device='cuda:0') torch.Size([16])
Epoch: 48 | Batch_idx: 0 |  Loss: (0.3605) |  Loss2: (0.0000) | Acc: (85.00%) (110/128)
Epoch: 48 | Batch_idx: 10 |  Loss: (0.3830) |  Loss2: (0.0000) | Acc: (86.00%) (1213/1408)
Epoch: 48 | Batch_idx: 20 |  Loss: (0.3959) |  Loss2: (0.0000) | Acc: (85.00%) (2310/2688)
Epoch: 48 | Batch_idx: 30 |  Loss: (0.3954) |  Loss2: (0.0000) | Acc: (86.00%) (3413/3968)
Epoch: 48 | Batch_idx: 40 |  Loss: (0.3993) |  Loss2: (0.0000) | Acc: (85.00%) (4498/5248)
Epoch: 48 | Batch_idx: 50 |  Loss: (0.3999) |  Loss2: (0.0000) | Acc: (85.00%) (5602/6528)
Epoch: 48 | Batch_idx: 60 |  Loss: (0.4052) |  Loss2: (0.0000) | Acc: (85.00%) (6691/7808)
Epoch: 48 | Batch_idx: 70 |  Loss: (0.4062) |  Loss2: (0.0000) | Acc: (85.00%) (7798/9088)
Epoch: 48 | Batch_idx: 80 |  Loss: (0.4083) |  Loss2: (0.0000) | Acc: (85.00%) (8887/10368)
Epoch: 48 | Batch_idx: 90 |  Loss: (0.4063) |  Loss2: (0.0000) | Acc: (85.00%) (10016/11648)
Epoch: 48 | Batch_idx: 100 |  Loss: (0.4057) |  Loss2: (0.0000) | Acc: (85.00%) (11113/12928)
Epoch: 48 | Batch_idx: 110 |  Loss: (0.4048) |  Loss2: (0.0000) | Acc: (85.00%) (12217/14208)
Epoch: 48 | Batch_idx: 120 |  Loss: (0.4044) |  Loss2: (0.0000) | Acc: (86.00%) (13336/15488)
Epoch: 48 | Batch_idx: 130 |  Loss: (0.4036) |  Loss2: (0.0000) | Acc: (86.00%) (14438/16768)
Epoch: 48 | Batch_idx: 140 |  Loss: (0.4038) |  Loss2: (0.0000) | Acc: (86.00%) (15542/18048)
Epoch: 48 | Batch_idx: 150 |  Loss: (0.4018) |  Loss2: (0.0000) | Acc: (86.00%) (16667/19328)
Epoch: 48 | Batch_idx: 160 |  Loss: (0.4035) |  Loss2: (0.0000) | Acc: (86.00%) (17765/20608)
Epoch: 48 | Batch_idx: 170 |  Loss: (0.4030) |  Loss2: (0.0000) | Acc: (86.00%) (18873/21888)
Epoch: 48 | Batch_idx: 180 |  Loss: (0.4037) |  Loss2: (0.0000) | Acc: (86.00%) (19967/23168)
Epoch: 48 | Batch_idx: 190 |  Loss: (0.4027) |  Loss2: (0.0000) | Acc: (86.00%) (21083/24448)
Epoch: 48 | Batch_idx: 200 |  Loss: (0.4048) |  Loss2: (0.0000) | Acc: (86.00%) (22166/25728)
Epoch: 48 | Batch_idx: 210 |  Loss: (0.4047) |  Loss2: (0.0000) | Acc: (86.00%) (23269/27008)
Epoch: 48 | Batch_idx: 220 |  Loss: (0.4054) |  Loss2: (0.0000) | Acc: (86.00%) (24369/28288)
Epoch: 48 | Batch_idx: 230 |  Loss: (0.4041) |  Loss2: (0.0000) | Acc: (86.00%) (25505/29568)
Epoch: 48 | Batch_idx: 240 |  Loss: (0.4052) |  Loss2: (0.0000) | Acc: (86.00%) (26596/30848)
Epoch: 48 | Batch_idx: 250 |  Loss: (0.4046) |  Loss2: (0.0000) | Acc: (86.00%) (27703/32128)
Epoch: 48 | Batch_idx: 260 |  Loss: (0.4050) |  Loss2: (0.0000) | Acc: (86.00%) (28799/33408)
Epoch: 48 | Batch_idx: 270 |  Loss: (0.4035) |  Loss2: (0.0000) | Acc: (86.00%) (29934/34688)
Epoch: 48 | Batch_idx: 280 |  Loss: (0.4028) |  Loss2: (0.0000) | Acc: (86.00%) (31041/35968)
Epoch: 48 | Batch_idx: 290 |  Loss: (0.4038) |  Loss2: (0.0000) | Acc: (86.00%) (32132/37248)
Epoch: 48 | Batch_idx: 300 |  Loss: (0.4039) |  Loss2: (0.0000) | Acc: (86.00%) (33218/38528)
Epoch: 48 | Batch_idx: 310 |  Loss: (0.4039) |  Loss2: (0.0000) | Acc: (86.00%) (34327/39808)
Epoch: 48 | Batch_idx: 320 |  Loss: (0.4037) |  Loss2: (0.0000) | Acc: (86.00%) (35422/41088)
Epoch: 48 | Batch_idx: 330 |  Loss: (0.4033) |  Loss2: (0.0000) | Acc: (86.00%) (36527/42368)
Epoch: 48 | Batch_idx: 340 |  Loss: (0.4036) |  Loss2: (0.0000) | Acc: (86.00%) (37626/43648)
Epoch: 48 | Batch_idx: 350 |  Loss: (0.4032) |  Loss2: (0.0000) | Acc: (86.00%) (38732/44928)
Epoch: 48 | Batch_idx: 360 |  Loss: (0.4040) |  Loss2: (0.0000) | Acc: (86.00%) (39821/46208)
Epoch: 48 | Batch_idx: 370 |  Loss: (0.4032) |  Loss2: (0.0000) | Acc: (86.00%) (40934/47488)
Epoch: 48 | Batch_idx: 380 |  Loss: (0.4035) |  Loss2: (0.0000) | Acc: (86.00%) (42026/48768)
Epoch: 48 | Batch_idx: 390 |  Loss: (0.4025) |  Loss2: (0.0000) | Acc: (86.00%) (43109/50000)
# TEST : Loss: (0.4664) | Acc: (83.00%) (8386/10000)
percent tensor([0.5057, 0.5004, 0.5065, 0.5088, 0.5055, 0.5077, 0.5020, 0.5068, 0.5055,
        0.5021, 0.5039, 0.5023, 0.5037, 0.5020, 0.5041, 0.5059],
       device='cuda:0') torch.Size([16])
percent tensor([0.5213, 0.5303, 0.5113, 0.5167, 0.5139, 0.5333, 0.5251, 0.5144, 0.5138,
        0.5196, 0.5211, 0.5129, 0.5188, 0.5292, 0.5300, 0.5244],
       device='cuda:0') torch.Size([16])
percent tensor([0.4928, 0.5360, 0.5084, 0.4611, 0.4904, 0.4382, 0.5271, 0.4964, 0.5039,
        0.5266, 0.5173, 0.5431, 0.5594, 0.4371, 0.5082, 0.4746],
       device='cuda:0') torch.Size([16])
percent tensor([0.6356, 0.6610, 0.6307, 0.6289, 0.6319, 0.6269, 0.6525, 0.6255, 0.6488,
        0.6649, 0.6803, 0.6611, 0.6598, 0.6590, 0.6455, 0.6446],
       device='cuda:0') torch.Size([16])
percent tensor([0.5672, 0.5440, 0.5738, 0.5654, 0.5464, 0.6945, 0.5393, 0.4957, 0.5902,
        0.5593, 0.5925, 0.5373, 0.5849, 0.6128, 0.5495, 0.5993],
       device='cuda:0') torch.Size([16])
percent tensor([0.5116, 0.5626, 0.5334, 0.5253, 0.5206, 0.4976, 0.5229, 0.4413, 0.5947,
        0.5446, 0.5875, 0.5805, 0.5598, 0.6388, 0.4649, 0.4910],
       device='cuda:0') torch.Size([16])
percent tensor([0.5970, 0.5892, 0.7559, 0.7710, 0.7964, 0.6264, 0.6692, 0.7748, 0.6409,
        0.6224, 0.6250, 0.7202, 0.5324, 0.6590, 0.6416, 0.6812],
       device='cuda:0') torch.Size([16])
percent tensor([0.9984, 0.9942, 0.9967, 0.9971, 0.9961, 0.9952, 0.9971, 0.9981, 0.9955,
        0.9964, 0.9958, 0.9947, 0.9922, 0.9968, 0.9956, 0.9986],
       device='cuda:0') torch.Size([16])
Epoch: 49 | Batch_idx: 0 |  Loss: (0.3047) |  Loss2: (0.0000) | Acc: (87.00%) (112/128)
Epoch: 49 | Batch_idx: 10 |  Loss: (0.4278) |  Loss2: (0.0000) | Acc: (85.00%) (1202/1408)
Epoch: 49 | Batch_idx: 20 |  Loss: (0.4229) |  Loss2: (0.0000) | Acc: (85.00%) (2299/2688)
Epoch: 49 | Batch_idx: 30 |  Loss: (0.4092) |  Loss2: (0.0000) | Acc: (85.00%) (3403/3968)
Epoch: 49 | Batch_idx: 40 |  Loss: (0.3999) |  Loss2: (0.0000) | Acc: (86.00%) (4523/5248)
Epoch: 49 | Batch_idx: 50 |  Loss: (0.3960) |  Loss2: (0.0000) | Acc: (86.00%) (5634/6528)
Epoch: 49 | Batch_idx: 60 |  Loss: (0.3975) |  Loss2: (0.0000) | Acc: (86.00%) (6733/7808)
Epoch: 49 | Batch_idx: 70 |  Loss: (0.4010) |  Loss2: (0.0000) | Acc: (86.00%) (7825/9088)
Epoch: 49 | Batch_idx: 80 |  Loss: (0.4046) |  Loss2: (0.0000) | Acc: (86.00%) (8921/10368)
Epoch: 49 | Batch_idx: 90 |  Loss: (0.4054) |  Loss2: (0.0000) | Acc: (86.00%) (10018/11648)
Epoch: 49 | Batch_idx: 100 |  Loss: (0.4004) |  Loss2: (0.0000) | Acc: (86.00%) (11144/12928)
Epoch: 49 | Batch_idx: 110 |  Loss: (0.4040) |  Loss2: (0.0000) | Acc: (86.00%) (12226/14208)
Epoch: 49 | Batch_idx: 120 |  Loss: (0.4023) |  Loss2: (0.0000) | Acc: (86.00%) (13341/15488)
Epoch: 49 | Batch_idx: 130 |  Loss: (0.4032) |  Loss2: (0.0000) | Acc: (86.00%) (14431/16768)
Epoch: 49 | Batch_idx: 140 |  Loss: (0.4026) |  Loss2: (0.0000) | Acc: (86.00%) (15544/18048)
Epoch: 49 | Batch_idx: 150 |  Loss: (0.4010) |  Loss2: (0.0000) | Acc: (86.00%) (16657/19328)
Epoch: 49 | Batch_idx: 160 |  Loss: (0.4010) |  Loss2: (0.0000) | Acc: (86.00%) (17757/20608)
Epoch: 49 | Batch_idx: 170 |  Loss: (0.3994) |  Loss2: (0.0000) | Acc: (86.00%) (18879/21888)
Epoch: 49 | Batch_idx: 180 |  Loss: (0.3996) |  Loss2: (0.0000) | Acc: (86.00%) (19983/23168)
Epoch: 49 | Batch_idx: 190 |  Loss: (0.4016) |  Loss2: (0.0000) | Acc: (86.00%) (21074/24448)
Epoch: 49 | Batch_idx: 200 |  Loss: (0.4009) |  Loss2: (0.0000) | Acc: (86.00%) (22187/25728)
Epoch: 49 | Batch_idx: 210 |  Loss: (0.3998) |  Loss2: (0.0000) | Acc: (86.00%) (23310/27008)
Epoch: 49 | Batch_idx: 220 |  Loss: (0.3998) |  Loss2: (0.0000) | Acc: (86.00%) (24416/28288)
Epoch: 49 | Batch_idx: 230 |  Loss: (0.4012) |  Loss2: (0.0000) | Acc: (86.00%) (25509/29568)
Epoch: 49 | Batch_idx: 240 |  Loss: (0.4011) |  Loss2: (0.0000) | Acc: (86.00%) (26609/30848)
Epoch: 49 | Batch_idx: 250 |  Loss: (0.4011) |  Loss2: (0.0000) | Acc: (86.00%) (27719/32128)
Epoch: 49 | Batch_idx: 260 |  Loss: (0.4008) |  Loss2: (0.0000) | Acc: (86.00%) (28831/33408)
Epoch: 49 | Batch_idx: 270 |  Loss: (0.4003) |  Loss2: (0.0000) | Acc: (86.00%) (29943/34688)
Epoch: 49 | Batch_idx: 280 |  Loss: (0.4002) |  Loss2: (0.0000) | Acc: (86.00%) (31048/35968)
Epoch: 49 | Batch_idx: 290 |  Loss: (0.3995) |  Loss2: (0.0000) | Acc: (86.00%) (32158/37248)
Epoch: 49 | Batch_idx: 300 |  Loss: (0.4002) |  Loss2: (0.0000) | Acc: (86.00%) (33260/38528)
Epoch: 49 | Batch_idx: 310 |  Loss: (0.4001) |  Loss2: (0.0000) | Acc: (86.00%) (34355/39808)
Epoch: 49 | Batch_idx: 320 |  Loss: (0.4005) |  Loss2: (0.0000) | Acc: (86.00%) (35459/41088)
Epoch: 49 | Batch_idx: 330 |  Loss: (0.4016) |  Loss2: (0.0000) | Acc: (86.00%) (36546/42368)
Epoch: 49 | Batch_idx: 340 |  Loss: (0.4011) |  Loss2: (0.0000) | Acc: (86.00%) (37643/43648)
Epoch: 49 | Batch_idx: 350 |  Loss: (0.4016) |  Loss2: (0.0000) | Acc: (86.00%) (38737/44928)
Epoch: 49 | Batch_idx: 360 |  Loss: (0.4021) |  Loss2: (0.0000) | Acc: (86.00%) (39836/46208)
Epoch: 49 | Batch_idx: 370 |  Loss: (0.4007) |  Loss2: (0.0000) | Acc: (86.00%) (40964/47488)
Epoch: 49 | Batch_idx: 380 |  Loss: (0.4004) |  Loss2: (0.0000) | Acc: (86.00%) (42075/48768)
Epoch: 49 | Batch_idx: 390 |  Loss: (0.4007) |  Loss2: (0.0000) | Acc: (86.00%) (43130/50000)
# TEST : Loss: (0.4639) | Acc: (83.00%) (8390/10000)
percent tensor([0.5060, 0.5008, 0.5072, 0.5095, 0.5061, 0.5080, 0.5024, 0.5076, 0.5060,
        0.5026, 0.5043, 0.5028, 0.5041, 0.5025, 0.5045, 0.5063],
       device='cuda:0') torch.Size([16])
percent tensor([0.5222, 0.5315, 0.5121, 0.5176, 0.5150, 0.5352, 0.5262, 0.5153, 0.5144,
        0.5203, 0.5217, 0.5134, 0.5195, 0.5301, 0.5315, 0.5255],
       device='cuda:0') torch.Size([16])
percent tensor([0.4993, 0.5418, 0.5124, 0.4677, 0.4948, 0.4486, 0.5323, 0.4994, 0.5083,
        0.5318, 0.5249, 0.5472, 0.5638, 0.4449, 0.5158, 0.4823],
       device='cuda:0') torch.Size([16])
percent tensor([0.6396, 0.6657, 0.6351, 0.6336, 0.6367, 0.6311, 0.6569, 0.6305, 0.6525,
        0.6694, 0.6839, 0.6655, 0.6645, 0.6628, 0.6502, 0.6494],
       device='cuda:0') torch.Size([16])
percent tensor([0.5671, 0.5439, 0.5721, 0.5629, 0.5460, 0.6923, 0.5407, 0.4967, 0.5887,
        0.5580, 0.5888, 0.5361, 0.5836, 0.6120, 0.5494, 0.5998],
       device='cuda:0') torch.Size([16])
percent tensor([0.5154, 0.5716, 0.5370, 0.5270, 0.5226, 0.4934, 0.5292, 0.4435, 0.6031,
        0.5505, 0.5960, 0.5878, 0.5659, 0.6492, 0.4684, 0.4920],
       device='cuda:0') torch.Size([16])
percent tensor([0.5992, 0.5956, 0.7576, 0.7712, 0.7960, 0.6257, 0.6689, 0.7725, 0.6466,
        0.6291, 0.6344, 0.7237, 0.5405, 0.6669, 0.6425, 0.6786],
       device='cuda:0') torch.Size([16])
percent tensor([0.9985, 0.9947, 0.9970, 0.9973, 0.9963, 0.9956, 0.9974, 0.9983, 0.9961,
        0.9968, 0.9962, 0.9951, 0.9930, 0.9971, 0.9962, 0.9988],
       device='cuda:0') torch.Size([16])
True Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=128, out_features=16, bias=False)
False Linear(in_features=16, out_features=2, bias=False)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=128, out_features=16, bias=False)
False Linear(in_features=16, out_features=2, bias=False)
True Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=256, out_features=32, bias=False)
False Linear(in_features=32, out_features=2, bias=False)
True Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=256, out_features=32, bias=False)
False Linear(in_features=32, out_features=2, bias=False)
True Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=512, out_features=64, bias=False)
False Linear(in_features=64, out_features=2, bias=False)
True Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=512, out_features=64, bias=False)
False Linear(in_features=64, out_features=2, bias=False)
True Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1024, out_features=128, bias=False)
False Linear(in_features=128, out_features=2, bias=False)
True Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1024, out_features=128, bias=False)
False Linear(in_features=128, out_features=2, bias=False)
True Linear(in_features=512, out_features=10, bias=True)
Epoch: 50 | Batch_idx: 0 |  Loss: (0.3702) |  Loss2: (0.0000) | Acc: (89.00%) (114/128)
Epoch: 50 | Batch_idx: 10 |  Loss: (0.3666) |  Loss2: (0.0000) | Acc: (86.00%) (1224/1408)
Epoch: 50 | Batch_idx: 20 |  Loss: (0.4025) |  Loss2: (0.0000) | Acc: (86.00%) (2312/2688)
Epoch: 50 | Batch_idx: 30 |  Loss: (0.4064) |  Loss2: (0.0000) | Acc: (86.00%) (3416/3968)
Epoch: 50 | Batch_idx: 40 |  Loss: (0.4058) |  Loss2: (0.0000) | Acc: (86.00%) (4519/5248)
Epoch: 50 | Batch_idx: 50 |  Loss: (0.4015) |  Loss2: (0.0000) | Acc: (86.00%) (5644/6528)
Epoch: 50 | Batch_idx: 60 |  Loss: (0.4015) |  Loss2: (0.0000) | Acc: (86.00%) (6744/7808)
Epoch: 50 | Batch_idx: 70 |  Loss: (0.4065) |  Loss2: (0.0000) | Acc: (86.00%) (7834/9088)
Epoch: 50 | Batch_idx: 80 |  Loss: (0.4078) |  Loss2: (0.0000) | Acc: (86.00%) (8933/10368)
Epoch: 50 | Batch_idx: 90 |  Loss: (0.4027) |  Loss2: (0.0000) | Acc: (86.00%) (10056/11648)
Epoch: 50 | Batch_idx: 100 |  Loss: (0.4036) |  Loss2: (0.0000) | Acc: (86.00%) (11156/12928)
Epoch: 50 | Batch_idx: 110 |  Loss: (0.4048) |  Loss2: (0.0000) | Acc: (86.00%) (12250/14208)
Epoch: 50 | Batch_idx: 120 |  Loss: (0.4056) |  Loss2: (0.0000) | Acc: (86.00%) (13344/15488)
Epoch: 50 | Batch_idx: 130 |  Loss: (0.4033) |  Loss2: (0.0000) | Acc: (86.00%) (14459/16768)
Epoch: 50 | Batch_idx: 140 |  Loss: (0.4002) |  Loss2: (0.0000) | Acc: (86.00%) (15572/18048)
Epoch: 50 | Batch_idx: 150 |  Loss: (0.4020) |  Loss2: (0.0000) | Acc: (86.00%) (16659/19328)
Epoch: 50 | Batch_idx: 160 |  Loss: (0.4025) |  Loss2: (0.0000) | Acc: (86.00%) (17764/20608)
Epoch: 50 | Batch_idx: 170 |  Loss: (0.4036) |  Loss2: (0.0000) | Acc: (86.00%) (18851/21888)
Epoch: 50 | Batch_idx: 180 |  Loss: (0.4046) |  Loss2: (0.0000) | Acc: (86.00%) (19941/23168)
Epoch: 50 | Batch_idx: 190 |  Loss: (0.4023) |  Loss2: (0.0000) | Acc: (86.00%) (21056/24448)
Epoch: 50 | Batch_idx: 200 |  Loss: (0.4033) |  Loss2: (0.0000) | Acc: (86.00%) (22149/25728)
Epoch: 50 | Batch_idx: 210 |  Loss: (0.4036) |  Loss2: (0.0000) | Acc: (86.00%) (23235/27008)
Epoch: 50 | Batch_idx: 220 |  Loss: (0.4044) |  Loss2: (0.0000) | Acc: (85.00%) (24320/28288)
Epoch: 50 | Batch_idx: 230 |  Loss: (0.4046) |  Loss2: (0.0000) | Acc: (85.00%) (25415/29568)
Epoch: 50 | Batch_idx: 240 |  Loss: (0.4051) |  Loss2: (0.0000) | Acc: (85.00%) (26520/30848)
Epoch: 50 | Batch_idx: 250 |  Loss: (0.4067) |  Loss2: (0.0000) | Acc: (85.00%) (27607/32128)
Epoch: 50 | Batch_idx: 260 |  Loss: (0.4065) |  Loss2: (0.0000) | Acc: (85.00%) (28711/33408)
Epoch: 50 | Batch_idx: 270 |  Loss: (0.4071) |  Loss2: (0.0000) | Acc: (85.00%) (29808/34688)
Epoch: 50 | Batch_idx: 280 |  Loss: (0.4067) |  Loss2: (0.0000) | Acc: (85.00%) (30909/35968)
Epoch: 50 | Batch_idx: 290 |  Loss: (0.4083) |  Loss2: (0.0000) | Acc: (85.00%) (31988/37248)
Epoch: 50 | Batch_idx: 300 |  Loss: (0.4087) |  Loss2: (0.0000) | Acc: (85.00%) (33090/38528)
Epoch: 50 | Batch_idx: 310 |  Loss: (0.4095) |  Loss2: (0.0000) | Acc: (85.00%) (34171/39808)
Epoch: 50 | Batch_idx: 320 |  Loss: (0.4090) |  Loss2: (0.0000) | Acc: (85.00%) (35281/41088)
Epoch: 50 | Batch_idx: 330 |  Loss: (0.4096) |  Loss2: (0.0000) | Acc: (85.00%) (36371/42368)
Epoch: 50 | Batch_idx: 340 |  Loss: (0.4097) |  Loss2: (0.0000) | Acc: (85.00%) (37469/43648)
Epoch: 50 | Batch_idx: 350 |  Loss: (0.4098) |  Loss2: (0.0000) | Acc: (85.00%) (38560/44928)
Epoch: 50 | Batch_idx: 360 |  Loss: (0.4096) |  Loss2: (0.0000) | Acc: (85.00%) (39668/46208)
Epoch: 50 | Batch_idx: 370 |  Loss: (0.4096) |  Loss2: (0.0000) | Acc: (85.00%) (40771/47488)
Epoch: 50 | Batch_idx: 380 |  Loss: (0.4102) |  Loss2: (0.0000) | Acc: (85.00%) (41862/48768)
Epoch: 50 | Batch_idx: 390 |  Loss: (0.4110) |  Loss2: (0.0000) | Acc: (85.00%) (42909/50000)
=> saving checkpoint 'drive/app/torch/save_Routing_Gate_2/checkpoint_050.pth.tar'
# TEST : Loss: (0.5235) | Acc: (82.00%) (8203/10000)
percent tensor([0.5062, 0.5011, 0.5076, 0.5095, 0.5063, 0.5084, 0.5026, 0.5077, 0.5061,
        0.5026, 0.5045, 0.5030, 0.5042, 0.5029, 0.5048, 0.5063],
       device='cuda:0') torch.Size([16])
percent tensor([0.5218, 0.5314, 0.5120, 0.5188, 0.5147, 0.5343, 0.5260, 0.5157, 0.5138,
        0.5208, 0.5217, 0.5129, 0.5199, 0.5299, 0.5317, 0.5257],
       device='cuda:0') torch.Size([16])
percent tensor([0.5054, 0.5447, 0.5171, 0.4675, 0.5025, 0.4621, 0.5344, 0.4937, 0.5105,
        0.5316, 0.5279, 0.5498, 0.5626, 0.4487, 0.5216, 0.4853],
       device='cuda:0') torch.Size([16])
percent tensor([0.6398, 0.6699, 0.6356, 0.6338, 0.6353, 0.6287, 0.6597, 0.6320, 0.6573,
        0.6726, 0.6863, 0.6660, 0.6686, 0.6744, 0.6526, 0.6543],
       device='cuda:0') torch.Size([16])
percent tensor([0.5555, 0.5468, 0.5678, 0.5609, 0.5487, 0.6734, 0.5420, 0.5058, 0.5851,
        0.5699, 0.5746, 0.5571, 0.5781, 0.6156, 0.5491, 0.5966],
       device='cuda:0') torch.Size([16])
percent tensor([0.4982, 0.5771, 0.5307, 0.5251, 0.5244, 0.4842, 0.5165, 0.4505, 0.5991,
        0.5516, 0.5953, 0.5926, 0.5640, 0.6601, 0.4681, 0.5016],
       device='cuda:0') torch.Size([16])
percent tensor([0.5989, 0.5836, 0.7822, 0.7804, 0.8074, 0.6531, 0.6624, 0.7764, 0.6357,
        0.6316, 0.6189, 0.7368, 0.5494, 0.6497, 0.6453, 0.6836],
       device='cuda:0') torch.Size([16])
percent tensor([0.9989, 0.9961, 0.9976, 0.9975, 0.9968, 0.9971, 0.9985, 0.9983, 0.9969,
        0.9973, 0.9970, 0.9959, 0.9959, 0.9972, 0.9962, 0.9989],
       device='cuda:0') torch.Size([16])
Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 3, 3, 3]) tensor(173.5585, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(794.1543, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(794.9026, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([128, 64, 3, 3]) tensor(1523.5181, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([128, 64, 1, 1]) tensor(503.5945, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([128, 128, 3, 3]) tensor(2201.1902, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([256, 128, 3, 3]) tensor(4294.7324, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([256, 128, 1, 1]) tensor(1419.6587, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([256, 256, 3, 3]) tensor(6081.7197, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([512, 256, 3, 3]) tensor(12052.5371, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([512, 256, 1, 1]) tensor(4017.2729, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([512, 512, 3, 3]) tensor(16975.0312, device='cuda:0', grad_fn=<NormBackward0>)
Epoch: 51 | Batch_idx: 0 |  Loss: (0.4130) |  Loss2: (0.0000) | Acc: (85.00%) (110/128)
Epoch: 51 | Batch_idx: 10 |  Loss: (0.3770) |  Loss2: (0.0000) | Acc: (87.00%) (1227/1408)
Epoch: 51 | Batch_idx: 20 |  Loss: (0.3923) |  Loss2: (0.0000) | Acc: (86.00%) (2328/2688)
Epoch: 51 | Batch_idx: 30 |  Loss: (0.3850) |  Loss2: (0.0000) | Acc: (86.00%) (3445/3968)
Epoch: 51 | Batch_idx: 40 |  Loss: (0.3927) |  Loss2: (0.0000) | Acc: (86.00%) (4544/5248)
Epoch: 51 | Batch_idx: 50 |  Loss: (0.3876) |  Loss2: (0.0000) | Acc: (86.00%) (5663/6528)
Epoch: 51 | Batch_idx: 60 |  Loss: (0.3891) |  Loss2: (0.0000) | Acc: (86.00%) (6768/7808)
Epoch: 51 | Batch_idx: 70 |  Loss: (0.3888) |  Loss2: (0.0000) | Acc: (86.00%) (7877/9088)
Epoch: 51 | Batch_idx: 80 |  Loss: (0.3909) |  Loss2: (0.0000) | Acc: (86.00%) (8988/10368)
Epoch: 51 | Batch_idx: 90 |  Loss: (0.3860) |  Loss2: (0.0000) | Acc: (86.00%) (10130/11648)
Epoch: 51 | Batch_idx: 100 |  Loss: (0.3882) |  Loss2: (0.0000) | Acc: (86.00%) (11222/12928)
Epoch: 51 | Batch_idx: 110 |  Loss: (0.3919) |  Loss2: (0.0000) | Acc: (86.00%) (12317/14208)
Epoch: 51 | Batch_idx: 120 |  Loss: (0.3915) |  Loss2: (0.0000) | Acc: (86.00%) (13421/15488)
Epoch: 51 | Batch_idx: 130 |  Loss: (0.3918) |  Loss2: (0.0000) | Acc: (86.00%) (14519/16768)
Epoch: 51 | Batch_idx: 140 |  Loss: (0.3981) |  Loss2: (0.0000) | Acc: (86.00%) (15586/18048)
Epoch: 51 | Batch_idx: 150 |  Loss: (0.3996) |  Loss2: (0.0000) | Acc: (86.00%) (16683/19328)
Epoch: 51 | Batch_idx: 160 |  Loss: (0.3974) |  Loss2: (0.0000) | Acc: (86.00%) (17803/20608)
Epoch: 51 | Batch_idx: 170 |  Loss: (0.3969) |  Loss2: (0.0000) | Acc: (86.00%) (18905/21888)
Epoch: 51 | Batch_idx: 180 |  Loss: (0.3966) |  Loss2: (0.0000) | Acc: (86.00%) (20014/23168)
Epoch: 51 | Batch_idx: 190 |  Loss: (0.3960) |  Loss2: (0.0000) | Acc: (86.00%) (21128/24448)
Epoch: 51 | Batch_idx: 200 |  Loss: (0.3962) |  Loss2: (0.0000) | Acc: (86.00%) (22221/25728)
Epoch: 51 | Batch_idx: 210 |  Loss: (0.3956) |  Loss2: (0.0000) | Acc: (86.00%) (23333/27008)
Epoch: 51 | Batch_idx: 220 |  Loss: (0.3959) |  Loss2: (0.0000) | Acc: (86.00%) (24431/28288)
Epoch: 51 | Batch_idx: 230 |  Loss: (0.3968) |  Loss2: (0.0000) | Acc: (86.00%) (25525/29568)
Epoch: 51 | Batch_idx: 240 |  Loss: (0.3978) |  Loss2: (0.0000) | Acc: (86.00%) (26619/30848)
Epoch: 51 | Batch_idx: 250 |  Loss: (0.3969) |  Loss2: (0.0000) | Acc: (86.00%) (27734/32128)
Epoch: 51 | Batch_idx: 260 |  Loss: (0.3974) |  Loss2: (0.0000) | Acc: (86.00%) (28836/33408)
Epoch: 51 | Batch_idx: 270 |  Loss: (0.3977) |  Loss2: (0.0000) | Acc: (86.00%) (29943/34688)
Epoch: 51 | Batch_idx: 280 |  Loss: (0.3982) |  Loss2: (0.0000) | Acc: (86.00%) (31044/35968)
Epoch: 51 | Batch_idx: 290 |  Loss: (0.3981) |  Loss2: (0.0000) | Acc: (86.00%) (32149/37248)
Epoch: 51 | Batch_idx: 300 |  Loss: (0.3988) |  Loss2: (0.0000) | Acc: (86.00%) (33249/38528)
Epoch: 51 | Batch_idx: 310 |  Loss: (0.3990) |  Loss2: (0.0000) | Acc: (86.00%) (34357/39808)
Epoch: 51 | Batch_idx: 320 |  Loss: (0.3986) |  Loss2: (0.0000) | Acc: (86.00%) (35463/41088)
Epoch: 51 | Batch_idx: 330 |  Loss: (0.3986) |  Loss2: (0.0000) | Acc: (86.00%) (36567/42368)
Epoch: 51 | Batch_idx: 340 |  Loss: (0.3981) |  Loss2: (0.0000) | Acc: (86.00%) (37674/43648)
Epoch: 51 | Batch_idx: 350 |  Loss: (0.3995) |  Loss2: (0.0000) | Acc: (86.00%) (38752/44928)
Epoch: 51 | Batch_idx: 360 |  Loss: (0.3997) |  Loss2: (0.0000) | Acc: (86.00%) (39852/46208)
Epoch: 51 | Batch_idx: 370 |  Loss: (0.3990) |  Loss2: (0.0000) | Acc: (86.00%) (40963/47488)
Epoch: 51 | Batch_idx: 380 |  Loss: (0.3993) |  Loss2: (0.0000) | Acc: (86.00%) (42061/48768)
Epoch: 51 | Batch_idx: 390 |  Loss: (0.3996) |  Loss2: (0.0000) | Acc: (86.00%) (43120/50000)
# TEST : Loss: (0.4849) | Acc: (83.00%) (8319/10000)
percent tensor([0.5060, 0.5008, 0.5073, 0.5094, 0.5063, 0.5079, 0.5026, 0.5074, 0.5057,
        0.5027, 0.5043, 0.5033, 0.5041, 0.5020, 0.5047, 0.5061],
       device='cuda:0') torch.Size([16])
percent tensor([0.5229, 0.5306, 0.5136, 0.5172, 0.5161, 0.5353, 0.5256, 0.5144, 0.5135,
        0.5202, 0.5215, 0.5136, 0.5198, 0.5272, 0.5314, 0.5253],
       device='cuda:0') torch.Size([16])
percent tensor([0.5003, 0.5413, 0.5226, 0.4725, 0.5021, 0.4596, 0.5290, 0.5001, 0.5116,
        0.5336, 0.5267, 0.5534, 0.5629, 0.4468, 0.5234, 0.4830],
       device='cuda:0') torch.Size([16])
percent tensor([0.6384, 0.6675, 0.6362, 0.6309, 0.6384, 0.6244, 0.6579, 0.6327, 0.6562,
        0.6704, 0.6874, 0.6664, 0.6654, 0.6700, 0.6491, 0.6494],
       device='cuda:0') torch.Size([16])
percent tensor([0.5623, 0.5396, 0.5669, 0.5567, 0.5500, 0.6875, 0.5457, 0.5042, 0.5902,
        0.5550, 0.5817, 0.5375, 0.5794, 0.6051, 0.5527, 0.6012],
       device='cuda:0') torch.Size([16])
percent tensor([0.5024, 0.5823, 0.5560, 0.5428, 0.5423, 0.4896, 0.5369, 0.4693, 0.6009,
        0.5418, 0.5984, 0.5896, 0.5596, 0.6557, 0.4698, 0.5016],
       device='cuda:0') torch.Size([16])
percent tensor([0.6057, 0.6120, 0.7774, 0.7654, 0.8052, 0.6287, 0.6838, 0.7702, 0.6599,
        0.6616, 0.6542, 0.7382, 0.5865, 0.6707, 0.6455, 0.6957],
       device='cuda:0') torch.Size([16])
percent tensor([0.9988, 0.9952, 0.9976, 0.9976, 0.9972, 0.9963, 0.9971, 0.9978, 0.9964,
        0.9963, 0.9976, 0.9968, 0.9956, 0.9965, 0.9961, 0.9985],
       device='cuda:0') torch.Size([16])
Epoch: 52 | Batch_idx: 0 |  Loss: (0.5062) |  Loss2: (0.0000) | Acc: (82.00%) (105/128)
Epoch: 52 | Batch_idx: 10 |  Loss: (0.4112) |  Loss2: (0.0000) | Acc: (85.00%) (1208/1408)
Epoch: 52 | Batch_idx: 20 |  Loss: (0.3987) |  Loss2: (0.0000) | Acc: (86.00%) (2317/2688)
Epoch: 52 | Batch_idx: 30 |  Loss: (0.3969) |  Loss2: (0.0000) | Acc: (86.00%) (3421/3968)
Epoch: 52 | Batch_idx: 40 |  Loss: (0.3799) |  Loss2: (0.0000) | Acc: (86.00%) (4552/5248)
Epoch: 52 | Batch_idx: 50 |  Loss: (0.3838) |  Loss2: (0.0000) | Acc: (86.00%) (5651/6528)
Epoch: 52 | Batch_idx: 60 |  Loss: (0.3852) |  Loss2: (0.0000) | Acc: (86.00%) (6763/7808)
Epoch: 52 | Batch_idx: 70 |  Loss: (0.3834) |  Loss2: (0.0000) | Acc: (86.00%) (7891/9088)
Epoch: 52 | Batch_idx: 80 |  Loss: (0.3803) |  Loss2: (0.0000) | Acc: (87.00%) (9024/10368)
Epoch: 52 | Batch_idx: 90 |  Loss: (0.3809) |  Loss2: (0.0000) | Acc: (87.00%) (10143/11648)
Epoch: 52 | Batch_idx: 100 |  Loss: (0.3800) |  Loss2: (0.0000) | Acc: (87.00%) (11255/12928)
Epoch: 52 | Batch_idx: 110 |  Loss: (0.3796) |  Loss2: (0.0000) | Acc: (87.00%) (12376/14208)
Epoch: 52 | Batch_idx: 120 |  Loss: (0.3795) |  Loss2: (0.0000) | Acc: (86.00%) (13472/15488)
Epoch: 52 | Batch_idx: 130 |  Loss: (0.3780) |  Loss2: (0.0000) | Acc: (87.00%) (14589/16768)
Epoch: 52 | Batch_idx: 140 |  Loss: (0.3772) |  Loss2: (0.0000) | Acc: (86.00%) (15700/18048)
Epoch: 52 | Batch_idx: 150 |  Loss: (0.3773) |  Loss2: (0.0000) | Acc: (86.00%) (16814/19328)
Epoch: 52 | Batch_idx: 160 |  Loss: (0.3791) |  Loss2: (0.0000) | Acc: (86.00%) (17922/20608)
Epoch: 52 | Batch_idx: 170 |  Loss: (0.3800) |  Loss2: (0.0000) | Acc: (86.00%) (19022/21888)
Epoch: 52 | Batch_idx: 180 |  Loss: (0.3810) |  Loss2: (0.0000) | Acc: (86.00%) (20124/23168)
Epoch: 52 | Batch_idx: 190 |  Loss: (0.3815) |  Loss2: (0.0000) | Acc: (86.00%) (21223/24448)
Epoch: 52 | Batch_idx: 200 |  Loss: (0.3806) |  Loss2: (0.0000) | Acc: (86.00%) (22338/25728)
Epoch: 52 | Batch_idx: 210 |  Loss: (0.3809) |  Loss2: (0.0000) | Acc: (86.00%) (23446/27008)
Epoch: 52 | Batch_idx: 220 |  Loss: (0.3797) |  Loss2: (0.0000) | Acc: (86.00%) (24588/28288)
Epoch: 52 | Batch_idx: 230 |  Loss: (0.3789) |  Loss2: (0.0000) | Acc: (86.00%) (25712/29568)
Epoch: 52 | Batch_idx: 240 |  Loss: (0.3792) |  Loss2: (0.0000) | Acc: (86.00%) (26818/30848)
Epoch: 52 | Batch_idx: 250 |  Loss: (0.3795) |  Loss2: (0.0000) | Acc: (86.00%) (27929/32128)
Epoch: 52 | Batch_idx: 260 |  Loss: (0.3778) |  Loss2: (0.0000) | Acc: (86.00%) (29062/33408)
Epoch: 52 | Batch_idx: 270 |  Loss: (0.3775) |  Loss2: (0.0000) | Acc: (87.00%) (30182/34688)
Epoch: 52 | Batch_idx: 280 |  Loss: (0.3779) |  Loss2: (0.0000) | Acc: (86.00%) (31289/35968)
Epoch: 52 | Batch_idx: 290 |  Loss: (0.3783) |  Loss2: (0.0000) | Acc: (86.00%) (32404/37248)
Epoch: 52 | Batch_idx: 300 |  Loss: (0.3788) |  Loss2: (0.0000) | Acc: (86.00%) (33500/38528)
Epoch: 52 | Batch_idx: 310 |  Loss: (0.3801) |  Loss2: (0.0000) | Acc: (86.00%) (34600/39808)
Epoch: 52 | Batch_idx: 320 |  Loss: (0.3808) |  Loss2: (0.0000) | Acc: (86.00%) (35715/41088)
Epoch: 52 | Batch_idx: 330 |  Loss: (0.3820) |  Loss2: (0.0000) | Acc: (86.00%) (36804/42368)
Epoch: 52 | Batch_idx: 340 |  Loss: (0.3819) |  Loss2: (0.0000) | Acc: (86.00%) (37920/43648)
Epoch: 52 | Batch_idx: 350 |  Loss: (0.3820) |  Loss2: (0.0000) | Acc: (86.00%) (39014/44928)
Epoch: 52 | Batch_idx: 360 |  Loss: (0.3833) |  Loss2: (0.0000) | Acc: (86.00%) (40103/46208)
Epoch: 52 | Batch_idx: 370 |  Loss: (0.3842) |  Loss2: (0.0000) | Acc: (86.00%) (41209/47488)
Epoch: 52 | Batch_idx: 380 |  Loss: (0.3844) |  Loss2: (0.0000) | Acc: (86.00%) (42329/48768)
Epoch: 52 | Batch_idx: 390 |  Loss: (0.3853) |  Loss2: (0.0000) | Acc: (86.00%) (43393/50000)
# TEST : Loss: (0.5203) | Acc: (81.00%) (8186/10000)
percent tensor([0.5058, 0.5011, 0.5063, 0.5089, 0.5055, 0.5074, 0.5026, 0.5073, 0.5059,
        0.5023, 0.5044, 0.5023, 0.5038, 0.5032, 0.5044, 0.5060],
       device='cuda:0') torch.Size([16])
percent tensor([0.5228, 0.5308, 0.5141, 0.5195, 0.5175, 0.5374, 0.5263, 0.5153, 0.5132,
        0.5204, 0.5211, 0.5144, 0.5188, 0.5300, 0.5321, 0.5261],
       device='cuda:0') torch.Size([16])
percent tensor([0.5097, 0.5475, 0.5289, 0.4607, 0.5071, 0.4574, 0.5440, 0.4996, 0.5124,
        0.5374, 0.5312, 0.5660, 0.5749, 0.4462, 0.5233, 0.4824],
       device='cuda:0') torch.Size([16])
percent tensor([0.6380, 0.6647, 0.6309, 0.6311, 0.6335, 0.6244, 0.6565, 0.6293, 0.6543,
        0.6664, 0.6874, 0.6609, 0.6655, 0.6665, 0.6494, 0.6483],
       device='cuda:0') torch.Size([16])
percent tensor([0.5698, 0.5503, 0.5940, 0.5686, 0.5659, 0.6858, 0.5566, 0.5207, 0.6142,
        0.5735, 0.6003, 0.5620, 0.5957, 0.6213, 0.5597, 0.6107],
       device='cuda:0') torch.Size([16])
percent tensor([0.5015, 0.5675, 0.5482, 0.5383, 0.5314, 0.5030, 0.5150, 0.4559, 0.5888,
        0.5485, 0.5909, 0.5811, 0.5525, 0.6490, 0.4766, 0.4952],
       device='cuda:0') torch.Size([16])
percent tensor([0.6036, 0.6004, 0.7627, 0.7640, 0.7905, 0.6371, 0.6773, 0.7525, 0.6642,
        0.6449, 0.6397, 0.7324, 0.5710, 0.6578, 0.6354, 0.6748],
       device='cuda:0') torch.Size([16])
percent tensor([0.9990, 0.9948, 0.9968, 0.9967, 0.9967, 0.9962, 0.9978, 0.9971, 0.9952,
        0.9969, 0.9972, 0.9956, 0.9948, 0.9972, 0.9955, 0.9987],
       device='cuda:0') torch.Size([16])
Epoch: 53 | Batch_idx: 0 |  Loss: (0.4463) |  Loss2: (0.0000) | Acc: (84.00%) (108/128)
Epoch: 53 | Batch_idx: 10 |  Loss: (0.3640) |  Loss2: (0.0000) | Acc: (87.00%) (1239/1408)
Epoch: 53 | Batch_idx: 20 |  Loss: (0.3640) |  Loss2: (0.0000) | Acc: (87.00%) (2354/2688)
Epoch: 53 | Batch_idx: 30 |  Loss: (0.3662) |  Loss2: (0.0000) | Acc: (87.00%) (3458/3968)
Epoch: 53 | Batch_idx: 40 |  Loss: (0.3705) |  Loss2: (0.0000) | Acc: (86.00%) (4562/5248)
Epoch: 53 | Batch_idx: 50 |  Loss: (0.3736) |  Loss2: (0.0000) | Acc: (86.00%) (5668/6528)
Epoch: 53 | Batch_idx: 60 |  Loss: (0.3713) |  Loss2: (0.0000) | Acc: (86.00%) (6786/7808)
Epoch: 53 | Batch_idx: 70 |  Loss: (0.3701) |  Loss2: (0.0000) | Acc: (86.00%) (7903/9088)
Epoch: 53 | Batch_idx: 80 |  Loss: (0.3689) |  Loss2: (0.0000) | Acc: (87.00%) (9029/10368)
Epoch: 53 | Batch_idx: 90 |  Loss: (0.3724) |  Loss2: (0.0000) | Acc: (86.00%) (10123/11648)
Epoch: 53 | Batch_idx: 100 |  Loss: (0.3710) |  Loss2: (0.0000) | Acc: (86.00%) (11237/12928)
Epoch: 53 | Batch_idx: 110 |  Loss: (0.3747) |  Loss2: (0.0000) | Acc: (86.00%) (12331/14208)
Epoch: 53 | Batch_idx: 120 |  Loss: (0.3751) |  Loss2: (0.0000) | Acc: (86.00%) (13436/15488)
Epoch: 53 | Batch_idx: 130 |  Loss: (0.3761) |  Loss2: (0.0000) | Acc: (86.00%) (14538/16768)
Epoch: 53 | Batch_idx: 140 |  Loss: (0.3766) |  Loss2: (0.0000) | Acc: (86.00%) (15653/18048)
Epoch: 53 | Batch_idx: 150 |  Loss: (0.3756) |  Loss2: (0.0000) | Acc: (86.00%) (16766/19328)
Epoch: 53 | Batch_idx: 160 |  Loss: (0.3757) |  Loss2: (0.0000) | Acc: (86.00%) (17886/20608)
Epoch: 53 | Batch_idx: 170 |  Loss: (0.3767) |  Loss2: (0.0000) | Acc: (86.00%) (18986/21888)
Epoch: 53 | Batch_idx: 180 |  Loss: (0.3750) |  Loss2: (0.0000) | Acc: (86.00%) (20114/23168)
Epoch: 53 | Batch_idx: 190 |  Loss: (0.3778) |  Loss2: (0.0000) | Acc: (86.00%) (21209/24448)
Epoch: 53 | Batch_idx: 200 |  Loss: (0.3779) |  Loss2: (0.0000) | Acc: (86.00%) (22313/25728)
Epoch: 53 | Batch_idx: 210 |  Loss: (0.3770) |  Loss2: (0.0000) | Acc: (86.00%) (23449/27008)
Epoch: 53 | Batch_idx: 220 |  Loss: (0.3768) |  Loss2: (0.0000) | Acc: (86.00%) (24563/28288)
Epoch: 53 | Batch_idx: 230 |  Loss: (0.3752) |  Loss2: (0.0000) | Acc: (86.00%) (25692/29568)
Epoch: 53 | Batch_idx: 240 |  Loss: (0.3739) |  Loss2: (0.0000) | Acc: (86.00%) (26825/30848)
Epoch: 53 | Batch_idx: 250 |  Loss: (0.3731) |  Loss2: (0.0000) | Acc: (86.00%) (27945/32128)
Epoch: 53 | Batch_idx: 260 |  Loss: (0.3730) |  Loss2: (0.0000) | Acc: (87.00%) (29067/33408)
Epoch: 53 | Batch_idx: 270 |  Loss: (0.3729) |  Loss2: (0.0000) | Acc: (86.00%) (30177/34688)
Epoch: 53 | Batch_idx: 280 |  Loss: (0.3734) |  Loss2: (0.0000) | Acc: (86.00%) (31288/35968)
Epoch: 53 | Batch_idx: 290 |  Loss: (0.3732) |  Loss2: (0.0000) | Acc: (87.00%) (32410/37248)
Epoch: 53 | Batch_idx: 300 |  Loss: (0.3754) |  Loss2: (0.0000) | Acc: (86.00%) (33493/38528)
Epoch: 53 | Batch_idx: 310 |  Loss: (0.3773) |  Loss2: (0.0000) | Acc: (86.00%) (34592/39808)
Epoch: 53 | Batch_idx: 320 |  Loss: (0.3779) |  Loss2: (0.0000) | Acc: (86.00%) (35694/41088)
Epoch: 53 | Batch_idx: 330 |  Loss: (0.3783) |  Loss2: (0.0000) | Acc: (86.00%) (36802/42368)
Epoch: 53 | Batch_idx: 340 |  Loss: (0.3775) |  Loss2: (0.0000) | Acc: (86.00%) (37935/43648)
Epoch: 53 | Batch_idx: 350 |  Loss: (0.3778) |  Loss2: (0.0000) | Acc: (86.00%) (39044/44928)
Epoch: 53 | Batch_idx: 360 |  Loss: (0.3781) |  Loss2: (0.0000) | Acc: (86.00%) (40150/46208)
Epoch: 53 | Batch_idx: 370 |  Loss: (0.3773) |  Loss2: (0.0000) | Acc: (86.00%) (41274/47488)
Epoch: 53 | Batch_idx: 380 |  Loss: (0.3772) |  Loss2: (0.0000) | Acc: (86.00%) (42394/48768)
Epoch: 53 | Batch_idx: 390 |  Loss: (0.3773) |  Loss2: (0.0000) | Acc: (86.00%) (43464/50000)
# TEST : Loss: (0.5906) | Acc: (80.00%) (8011/10000)
percent tensor([0.5057, 0.5013, 0.5061, 0.5086, 0.5054, 0.5076, 0.5027, 0.5071, 0.5062,
        0.5024, 0.5048, 0.5021, 0.5040, 0.5039, 0.5045, 0.5061],
       device='cuda:0') torch.Size([16])
percent tensor([0.5234, 0.5321, 0.5125, 0.5179, 0.5149, 0.5365, 0.5262, 0.5153, 0.5141,
        0.5206, 0.5226, 0.5137, 0.5203, 0.5302, 0.5321, 0.5262],
       device='cuda:0') torch.Size([16])
percent tensor([0.5138, 0.5477, 0.5364, 0.4798, 0.5134, 0.4636, 0.5410, 0.5116, 0.5130,
        0.5406, 0.5288, 0.5593, 0.5743, 0.4414, 0.5260, 0.4920],
       device='cuda:0') torch.Size([16])
percent tensor([0.6397, 0.6646, 0.6338, 0.6266, 0.6349, 0.6245, 0.6558, 0.6277, 0.6531,
        0.6675, 0.6836, 0.6672, 0.6648, 0.6639, 0.6483, 0.6480],
       device='cuda:0') torch.Size([16])
percent tensor([0.5619, 0.5442, 0.5846, 0.5579, 0.5613, 0.6774, 0.5576, 0.5224, 0.6047,
        0.5560, 0.5964, 0.5542, 0.5888, 0.6172, 0.5527, 0.5993],
       device='cuda:0') torch.Size([16])
percent tensor([0.5098, 0.5769, 0.5503, 0.5362, 0.5487, 0.4969, 0.5367, 0.4678, 0.6000,
        0.5566, 0.5927, 0.5948, 0.5557, 0.6495, 0.4685, 0.5035],
       device='cuda:0') torch.Size([16])
percent tensor([0.5942, 0.6172, 0.7569, 0.7481, 0.7801, 0.6479, 0.6663, 0.7554, 0.6576,
        0.6424, 0.6481, 0.7347, 0.5637, 0.6642, 0.6437, 0.6904],
       device='cuda:0') torch.Size([16])
percent tensor([0.9989, 0.9954, 0.9977, 0.9972, 0.9967, 0.9963, 0.9974, 0.9977, 0.9955,
        0.9971, 0.9972, 0.9969, 0.9942, 0.9966, 0.9969, 0.9988],
       device='cuda:0') torch.Size([16])
Epoch: 54 | Batch_idx: 0 |  Loss: (0.4203) |  Loss2: (0.0000) | Acc: (84.00%) (108/128)
Epoch: 54 | Batch_idx: 10 |  Loss: (0.3693) |  Loss2: (0.0000) | Acc: (87.00%) (1230/1408)
Epoch: 54 | Batch_idx: 20 |  Loss: (0.3815) |  Loss2: (0.0000) | Acc: (87.00%) (2347/2688)
Epoch: 54 | Batch_idx: 30 |  Loss: (0.3751) |  Loss2: (0.0000) | Acc: (87.00%) (3462/3968)
Epoch: 54 | Batch_idx: 40 |  Loss: (0.3758) |  Loss2: (0.0000) | Acc: (87.00%) (4585/5248)
Epoch: 54 | Batch_idx: 50 |  Loss: (0.3748) |  Loss2: (0.0000) | Acc: (87.00%) (5692/6528)
Epoch: 54 | Batch_idx: 60 |  Loss: (0.3676) |  Loss2: (0.0000) | Acc: (87.00%) (6826/7808)
Epoch: 54 | Batch_idx: 70 |  Loss: (0.3632) |  Loss2: (0.0000) | Acc: (87.00%) (7953/9088)
Epoch: 54 | Batch_idx: 80 |  Loss: (0.3646) |  Loss2: (0.0000) | Acc: (87.00%) (9073/10368)
Epoch: 54 | Batch_idx: 90 |  Loss: (0.3696) |  Loss2: (0.0000) | Acc: (87.00%) (10167/11648)
Epoch: 54 | Batch_idx: 100 |  Loss: (0.3649) |  Loss2: (0.0000) | Acc: (87.00%) (11302/12928)
Epoch: 54 | Batch_idx: 110 |  Loss: (0.3654) |  Loss2: (0.0000) | Acc: (87.00%) (12407/14208)
Epoch: 54 | Batch_idx: 120 |  Loss: (0.3636) |  Loss2: (0.0000) | Acc: (87.00%) (13538/15488)
Epoch: 54 | Batch_idx: 130 |  Loss: (0.3654) |  Loss2: (0.0000) | Acc: (87.00%) (14644/16768)
Epoch: 54 | Batch_idx: 140 |  Loss: (0.3657) |  Loss2: (0.0000) | Acc: (87.00%) (15757/18048)
Epoch: 54 | Batch_idx: 150 |  Loss: (0.3651) |  Loss2: (0.0000) | Acc: (87.00%) (16875/19328)
Epoch: 54 | Batch_idx: 160 |  Loss: (0.3654) |  Loss2: (0.0000) | Acc: (87.00%) (17994/20608)
Epoch: 54 | Batch_idx: 170 |  Loss: (0.3650) |  Loss2: (0.0000) | Acc: (87.00%) (19117/21888)
Epoch: 54 | Batch_idx: 180 |  Loss: (0.3666) |  Loss2: (0.0000) | Acc: (87.00%) (20210/23168)
Epoch: 54 | Batch_idx: 190 |  Loss: (0.3667) |  Loss2: (0.0000) | Acc: (87.00%) (21329/24448)
Epoch: 54 | Batch_idx: 200 |  Loss: (0.3690) |  Loss2: (0.0000) | Acc: (87.00%) (22424/25728)
Epoch: 54 | Batch_idx: 210 |  Loss: (0.3686) |  Loss2: (0.0000) | Acc: (87.00%) (23549/27008)
Epoch: 54 | Batch_idx: 220 |  Loss: (0.3690) |  Loss2: (0.0000) | Acc: (87.00%) (24661/28288)
Epoch: 54 | Batch_idx: 230 |  Loss: (0.3685) |  Loss2: (0.0000) | Acc: (87.00%) (25784/29568)
Epoch: 54 | Batch_idx: 240 |  Loss: (0.3669) |  Loss2: (0.0000) | Acc: (87.00%) (26918/30848)
Epoch: 54 | Batch_idx: 250 |  Loss: (0.3675) |  Loss2: (0.0000) | Acc: (87.00%) (28028/32128)
Epoch: 54 | Batch_idx: 260 |  Loss: (0.3681) |  Loss2: (0.0000) | Acc: (87.00%) (29139/33408)
Epoch: 54 | Batch_idx: 270 |  Loss: (0.3687) |  Loss2: (0.0000) | Acc: (87.00%) (30243/34688)
Epoch: 54 | Batch_idx: 280 |  Loss: (0.3675) |  Loss2: (0.0000) | Acc: (87.00%) (31377/35968)
Epoch: 54 | Batch_idx: 290 |  Loss: (0.3683) |  Loss2: (0.0000) | Acc: (87.00%) (32485/37248)
Epoch: 54 | Batch_idx: 300 |  Loss: (0.3683) |  Loss2: (0.0000) | Acc: (87.00%) (33602/38528)
Epoch: 54 | Batch_idx: 310 |  Loss: (0.3669) |  Loss2: (0.0000) | Acc: (87.00%) (34728/39808)
Epoch: 54 | Batch_idx: 320 |  Loss: (0.3673) |  Loss2: (0.0000) | Acc: (87.00%) (35840/41088)
Epoch: 54 | Batch_idx: 330 |  Loss: (0.3670) |  Loss2: (0.0000) | Acc: (87.00%) (36962/42368)
Epoch: 54 | Batch_idx: 340 |  Loss: (0.3662) |  Loss2: (0.0000) | Acc: (87.00%) (38089/43648)
Epoch: 54 | Batch_idx: 350 |  Loss: (0.3663) |  Loss2: (0.0000) | Acc: (87.00%) (39210/44928)
Epoch: 54 | Batch_idx: 360 |  Loss: (0.3670) |  Loss2: (0.0000) | Acc: (87.00%) (40320/46208)
Epoch: 54 | Batch_idx: 370 |  Loss: (0.3672) |  Loss2: (0.0000) | Acc: (87.00%) (41430/47488)
Epoch: 54 | Batch_idx: 380 |  Loss: (0.3670) |  Loss2: (0.0000) | Acc: (87.00%) (42549/48768)
Epoch: 54 | Batch_idx: 390 |  Loss: (0.3666) |  Loss2: (0.0000) | Acc: (87.00%) (43644/50000)
# TEST : Loss: (0.4925) | Acc: (82.00%) (8286/10000)
percent tensor([0.5057, 0.5013, 0.5061, 0.5087, 0.5054, 0.5078, 0.5027, 0.5073, 0.5060,
        0.5022, 0.5045, 0.5020, 0.5039, 0.5037, 0.5046, 0.5062],
       device='cuda:0') torch.Size([16])
percent tensor([0.5220, 0.5319, 0.5129, 0.5173, 0.5153, 0.5348, 0.5261, 0.5157, 0.5131,
        0.5206, 0.5213, 0.5134, 0.5190, 0.5304, 0.5313, 0.5255],
       device='cuda:0') torch.Size([16])
percent tensor([0.4983, 0.5430, 0.5091, 0.4713, 0.4950, 0.4521, 0.5309, 0.4941, 0.4989,
        0.5296, 0.5163, 0.5498, 0.5584, 0.4553, 0.5195, 0.4786],
       device='cuda:0') torch.Size([16])
percent tensor([0.6367, 0.6628, 0.6345, 0.6311, 0.6332, 0.6219, 0.6577, 0.6302, 0.6537,
        0.6686, 0.6857, 0.6639, 0.6612, 0.6666, 0.6467, 0.6465],
       device='cuda:0') torch.Size([16])
percent tensor([0.5630, 0.5487, 0.5812, 0.5633, 0.5530, 0.6745, 0.5593, 0.5160, 0.6010,
        0.5607, 0.5965, 0.5588, 0.5921, 0.6203, 0.5526, 0.5970],
       device='cuda:0') torch.Size([16])
percent tensor([0.5061, 0.5647, 0.5544, 0.5357, 0.5299, 0.4994, 0.5292, 0.4597, 0.5999,
        0.5569, 0.6024, 0.5953, 0.5505, 0.6463, 0.4593, 0.4973],
       device='cuda:0') torch.Size([16])
percent tensor([0.6203, 0.5960, 0.7720, 0.7592, 0.7933, 0.6741, 0.6797, 0.7648, 0.6565,
        0.6543, 0.6343, 0.7215, 0.5684, 0.6407, 0.6520, 0.6959],
       device='cuda:0') torch.Size([16])
percent tensor([0.9986, 0.9944, 0.9973, 0.9978, 0.9973, 0.9958, 0.9970, 0.9984, 0.9947,
        0.9973, 0.9970, 0.9962, 0.9949, 0.9955, 0.9967, 0.9987],
       device='cuda:0') torch.Size([16])
False Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=128, out_features=16, bias=False)
True Linear(in_features=16, out_features=2, bias=False)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=128, out_features=16, bias=False)
True Linear(in_features=16, out_features=2, bias=False)
False Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=256, out_features=32, bias=False)
True Linear(in_features=32, out_features=2, bias=False)
False Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=256, out_features=32, bias=False)
True Linear(in_features=32, out_features=2, bias=False)
False Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=512, out_features=64, bias=False)
True Linear(in_features=64, out_features=2, bias=False)
False Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=512, out_features=64, bias=False)
True Linear(in_features=64, out_features=2, bias=False)
False Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1024, out_features=128, bias=False)
True Linear(in_features=128, out_features=2, bias=False)
False Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1024, out_features=128, bias=False)
True Linear(in_features=128, out_features=2, bias=False)
False Linear(in_features=512, out_features=10, bias=True)
Epoch: 55 | Batch_idx: 0 |  Loss: (0.3874) |  Loss2: (0.0000) | Acc: (86.00%) (111/128)
Epoch: 55 | Batch_idx: 10 |  Loss: (0.3601) |  Loss2: (0.0000) | Acc: (87.00%) (1226/1408)
Epoch: 55 | Batch_idx: 20 |  Loss: (0.3784) |  Loss2: (0.0000) | Acc: (86.00%) (2316/2688)
Epoch: 55 | Batch_idx: 30 |  Loss: (0.3773) |  Loss2: (0.0000) | Acc: (86.00%) (3434/3968)
Epoch: 55 | Batch_idx: 40 |  Loss: (0.3810) |  Loss2: (0.0000) | Acc: (86.00%) (4543/5248)
Epoch: 55 | Batch_idx: 50 |  Loss: (0.3831) |  Loss2: (0.0000) | Acc: (86.00%) (5649/6528)
Epoch: 55 | Batch_idx: 60 |  Loss: (0.3816) |  Loss2: (0.0000) | Acc: (86.00%) (6761/7808)
Epoch: 55 | Batch_idx: 70 |  Loss: (0.3767) |  Loss2: (0.0000) | Acc: (86.00%) (7885/9088)
Epoch: 55 | Batch_idx: 80 |  Loss: (0.3792) |  Loss2: (0.0000) | Acc: (86.00%) (8993/10368)
Epoch: 55 | Batch_idx: 90 |  Loss: (0.3799) |  Loss2: (0.0000) | Acc: (86.00%) (10096/11648)
Epoch: 55 | Batch_idx: 100 |  Loss: (0.3787) |  Loss2: (0.0000) | Acc: (86.00%) (11210/12928)
Epoch: 55 | Batch_idx: 110 |  Loss: (0.3790) |  Loss2: (0.0000) | Acc: (86.00%) (12318/14208)
Epoch: 55 | Batch_idx: 120 |  Loss: (0.3806) |  Loss2: (0.0000) | Acc: (86.00%) (13428/15488)
Epoch: 55 | Batch_idx: 130 |  Loss: (0.3837) |  Loss2: (0.0000) | Acc: (86.00%) (14528/16768)
Epoch: 55 | Batch_idx: 140 |  Loss: (0.3846) |  Loss2: (0.0000) | Acc: (86.00%) (15628/18048)
Epoch: 55 | Batch_idx: 150 |  Loss: (0.3830) |  Loss2: (0.0000) | Acc: (86.00%) (16752/19328)
Epoch: 55 | Batch_idx: 160 |  Loss: (0.3832) |  Loss2: (0.0000) | Acc: (86.00%) (17856/20608)
Epoch: 55 | Batch_idx: 170 |  Loss: (0.3841) |  Loss2: (0.0000) | Acc: (86.00%) (18970/21888)
Epoch: 55 | Batch_idx: 180 |  Loss: (0.3853) |  Loss2: (0.0000) | Acc: (86.00%) (20073/23168)
Epoch: 55 | Batch_idx: 190 |  Loss: (0.3855) |  Loss2: (0.0000) | Acc: (86.00%) (21169/24448)
Epoch: 55 | Batch_idx: 200 |  Loss: (0.3871) |  Loss2: (0.0000) | Acc: (86.00%) (22261/25728)
Epoch: 55 | Batch_idx: 210 |  Loss: (0.3866) |  Loss2: (0.0000) | Acc: (86.00%) (23374/27008)
Epoch: 55 | Batch_idx: 220 |  Loss: (0.3854) |  Loss2: (0.0000) | Acc: (86.00%) (24488/28288)
Epoch: 55 | Batch_idx: 230 |  Loss: (0.3852) |  Loss2: (0.0000) | Acc: (86.00%) (25598/29568)
Epoch: 55 | Batch_idx: 240 |  Loss: (0.3851) |  Loss2: (0.0000) | Acc: (86.00%) (26719/30848)
Epoch: 55 | Batch_idx: 250 |  Loss: (0.3849) |  Loss2: (0.0000) | Acc: (86.00%) (27825/32128)
Epoch: 55 | Batch_idx: 260 |  Loss: (0.3828) |  Loss2: (0.0000) | Acc: (86.00%) (28959/33408)
Epoch: 55 | Batch_idx: 270 |  Loss: (0.3823) |  Loss2: (0.0000) | Acc: (86.00%) (30068/34688)
Epoch: 55 | Batch_idx: 280 |  Loss: (0.3811) |  Loss2: (0.0000) | Acc: (86.00%) (31192/35968)
Epoch: 55 | Batch_idx: 290 |  Loss: (0.3811) |  Loss2: (0.0000) | Acc: (86.00%) (32300/37248)
Epoch: 55 | Batch_idx: 300 |  Loss: (0.3810) |  Loss2: (0.0000) | Acc: (86.00%) (33409/38528)
Epoch: 55 | Batch_idx: 310 |  Loss: (0.3806) |  Loss2: (0.0000) | Acc: (86.00%) (34528/39808)
Epoch: 55 | Batch_idx: 320 |  Loss: (0.3810) |  Loss2: (0.0000) | Acc: (86.00%) (35640/41088)
Epoch: 55 | Batch_idx: 330 |  Loss: (0.3817) |  Loss2: (0.0000) | Acc: (86.00%) (36754/42368)
Epoch: 55 | Batch_idx: 340 |  Loss: (0.3804) |  Loss2: (0.0000) | Acc: (86.00%) (37897/43648)
Epoch: 55 | Batch_idx: 350 |  Loss: (0.3802) |  Loss2: (0.0000) | Acc: (86.00%) (39004/44928)
Epoch: 55 | Batch_idx: 360 |  Loss: (0.3793) |  Loss2: (0.0000) | Acc: (86.00%) (40141/46208)
Epoch: 55 | Batch_idx: 370 |  Loss: (0.3787) |  Loss2: (0.0000) | Acc: (86.00%) (41260/47488)
Epoch: 55 | Batch_idx: 380 |  Loss: (0.3778) |  Loss2: (0.0000) | Acc: (86.00%) (42382/48768)
Epoch: 55 | Batch_idx: 390 |  Loss: (0.3783) |  Loss2: (0.0000) | Acc: (86.00%) (43455/50000)
=> saving checkpoint 'drive/app/torch/save_Routing_Gate_2/checkpoint_055.pth.tar'
# TEST : Loss: (0.4517) | Acc: (84.00%) (8467/10000)
percent tensor([0.5080, 0.5031, 0.5093, 0.5108, 0.5083, 0.5097, 0.5052, 0.5101, 0.5086,
        0.5048, 0.5068, 0.5051, 0.5062, 0.5050, 0.5065, 0.5082],
       device='cuda:0') torch.Size([16])
percent tensor([0.5276, 0.5382, 0.5194, 0.5238, 0.5226, 0.5415, 0.5330, 0.5233, 0.5193,
        0.5268, 0.5268, 0.5199, 0.5246, 0.5365, 0.5382, 0.5316],
       device='cuda:0') torch.Size([16])
percent tensor([0.5113, 0.5570, 0.5099, 0.4706, 0.5046, 0.4530, 0.5460, 0.5048, 0.4962,
        0.5388, 0.5193, 0.5543, 0.5704, 0.4521, 0.5328, 0.4854],
       device='cuda:0') torch.Size([16])
percent tensor([0.6569, 0.6866, 0.6507, 0.6546, 0.6497, 0.6384, 0.6776, 0.6485, 0.6756,
        0.6918, 0.7113, 0.6864, 0.6874, 0.6880, 0.6676, 0.6685],
       device='cuda:0') torch.Size([16])
percent tensor([0.6244, 0.6126, 0.6025, 0.5819, 0.5768, 0.7138, 0.6209, 0.5626, 0.6388,
        0.6143, 0.6393, 0.5888, 0.6459, 0.6669, 0.6163, 0.6501],
       device='cuda:0') torch.Size([16])
percent tensor([0.5328, 0.5973, 0.5837, 0.5599, 0.5371, 0.5234, 0.5557, 0.4707, 0.6292,
        0.5895, 0.6410, 0.6237, 0.5897, 0.6782, 0.4830, 0.5300],
       device='cuda:0') torch.Size([16])
percent tensor([0.5562, 0.5694, 0.7381, 0.7233, 0.7444, 0.6433, 0.6090, 0.6795, 0.6370,
        0.6174, 0.6392, 0.7127, 0.5561, 0.6660, 0.5782, 0.6263],
       device='cuda:0') torch.Size([16])
percent tensor([0.9987, 0.9942, 0.9971, 0.9975, 0.9971, 0.9965, 0.9972, 0.9982, 0.9942,
        0.9971, 0.9974, 0.9961, 0.9951, 0.9962, 0.9970, 0.9989],
       device='cuda:0') torch.Size([16])
Epoch: 56 | Batch_idx: 0 |  Loss: (0.4121) |  Loss2: (0.0000) | Acc: (87.00%) (112/128)
Epoch: 56 | Batch_idx: 10 |  Loss: (0.3694) |  Loss2: (0.0000) | Acc: (87.00%) (1230/1408)
Epoch: 56 | Batch_idx: 20 |  Loss: (0.3661) |  Loss2: (0.0000) | Acc: (87.00%) (2357/2688)
Epoch: 56 | Batch_idx: 30 |  Loss: (0.3648) |  Loss2: (0.0000) | Acc: (87.00%) (3479/3968)
Epoch: 56 | Batch_idx: 40 |  Loss: (0.3649) |  Loss2: (0.0000) | Acc: (87.00%) (4596/5248)
Epoch: 56 | Batch_idx: 50 |  Loss: (0.3624) |  Loss2: (0.0000) | Acc: (87.00%) (5723/6528)
Epoch: 56 | Batch_idx: 60 |  Loss: (0.3601) |  Loss2: (0.0000) | Acc: (87.00%) (6841/7808)
Epoch: 56 | Batch_idx: 70 |  Loss: (0.3595) |  Loss2: (0.0000) | Acc: (87.00%) (7977/9088)
Epoch: 56 | Batch_idx: 80 |  Loss: (0.3580) |  Loss2: (0.0000) | Acc: (87.00%) (9100/10368)
Epoch: 56 | Batch_idx: 90 |  Loss: (0.3547) |  Loss2: (0.0000) | Acc: (87.00%) (10241/11648)
Epoch: 56 | Batch_idx: 100 |  Loss: (0.3541) |  Loss2: (0.0000) | Acc: (87.00%) (11376/12928)
Epoch: 56 | Batch_idx: 110 |  Loss: (0.3533) |  Loss2: (0.0000) | Acc: (88.00%) (12512/14208)
Epoch: 56 | Batch_idx: 120 |  Loss: (0.3555) |  Loss2: (0.0000) | Acc: (88.00%) (13632/15488)
Epoch: 56 | Batch_idx: 130 |  Loss: (0.3545) |  Loss2: (0.0000) | Acc: (88.00%) (14765/16768)
Epoch: 56 | Batch_idx: 140 |  Loss: (0.3547) |  Loss2: (0.0000) | Acc: (88.00%) (15888/18048)
Epoch: 56 | Batch_idx: 150 |  Loss: (0.3554) |  Loss2: (0.0000) | Acc: (88.00%) (17020/19328)
Epoch: 56 | Batch_idx: 160 |  Loss: (0.3586) |  Loss2: (0.0000) | Acc: (87.00%) (18125/20608)
Epoch: 56 | Batch_idx: 170 |  Loss: (0.3572) |  Loss2: (0.0000) | Acc: (87.00%) (19256/21888)
Epoch: 56 | Batch_idx: 180 |  Loss: (0.3552) |  Loss2: (0.0000) | Acc: (88.00%) (20400/23168)
Epoch: 56 | Batch_idx: 190 |  Loss: (0.3567) |  Loss2: (0.0000) | Acc: (87.00%) (21514/24448)
Epoch: 56 | Batch_idx: 200 |  Loss: (0.3564) |  Loss2: (0.0000) | Acc: (88.00%) (22646/25728)
Epoch: 56 | Batch_idx: 210 |  Loss: (0.3565) |  Loss2: (0.0000) | Acc: (88.00%) (23774/27008)
Epoch: 56 | Batch_idx: 220 |  Loss: (0.3561) |  Loss2: (0.0000) | Acc: (87.00%) (24893/28288)
Epoch: 56 | Batch_idx: 230 |  Loss: (0.3569) |  Loss2: (0.0000) | Acc: (87.00%) (26005/29568)
Epoch: 56 | Batch_idx: 240 |  Loss: (0.3564) |  Loss2: (0.0000) | Acc: (87.00%) (27134/30848)
Epoch: 56 | Batch_idx: 250 |  Loss: (0.3558) |  Loss2: (0.0000) | Acc: (87.00%) (28262/32128)
Epoch: 56 | Batch_idx: 260 |  Loss: (0.3561) |  Loss2: (0.0000) | Acc: (87.00%) (29383/33408)
Epoch: 56 | Batch_idx: 270 |  Loss: (0.3570) |  Loss2: (0.0000) | Acc: (87.00%) (30486/34688)
Epoch: 56 | Batch_idx: 280 |  Loss: (0.3572) |  Loss2: (0.0000) | Acc: (87.00%) (31609/35968)
Epoch: 56 | Batch_idx: 290 |  Loss: (0.3567) |  Loss2: (0.0000) | Acc: (87.00%) (32744/37248)
Epoch: 56 | Batch_idx: 300 |  Loss: (0.3557) |  Loss2: (0.0000) | Acc: (87.00%) (33885/38528)
Epoch: 56 | Batch_idx: 310 |  Loss: (0.3563) |  Loss2: (0.0000) | Acc: (87.00%) (35000/39808)
Epoch: 56 | Batch_idx: 320 |  Loss: (0.3558) |  Loss2: (0.0000) | Acc: (87.00%) (36130/41088)
Epoch: 56 | Batch_idx: 330 |  Loss: (0.3569) |  Loss2: (0.0000) | Acc: (87.00%) (37242/42368)
Epoch: 56 | Batch_idx: 340 |  Loss: (0.3566) |  Loss2: (0.0000) | Acc: (87.00%) (38370/43648)
Epoch: 56 | Batch_idx: 350 |  Loss: (0.3563) |  Loss2: (0.0000) | Acc: (87.00%) (39514/44928)
Epoch: 56 | Batch_idx: 360 |  Loss: (0.3555) |  Loss2: (0.0000) | Acc: (87.00%) (40659/46208)
Epoch: 56 | Batch_idx: 370 |  Loss: (0.3554) |  Loss2: (0.0000) | Acc: (87.00%) (41780/47488)
Epoch: 56 | Batch_idx: 380 |  Loss: (0.3557) |  Loss2: (0.0000) | Acc: (87.00%) (42907/48768)
Epoch: 56 | Batch_idx: 390 |  Loss: (0.3562) |  Loss2: (0.0000) | Acc: (87.00%) (43976/50000)
# TEST : Loss: (0.4405) | Acc: (84.00%) (8497/10000)
percent tensor([0.5082, 0.5030, 0.5103, 0.5113, 0.5090, 0.5095, 0.5054, 0.5106, 0.5089,
        0.5052, 0.5070, 0.5061, 0.5065, 0.5045, 0.5065, 0.5083],
       device='cuda:0') torch.Size([16])
percent tensor([0.5310, 0.5419, 0.5231, 0.5280, 0.5265, 0.5464, 0.5368, 0.5269, 0.5225,
        0.5300, 0.5299, 0.5235, 0.5278, 0.5398, 0.5424, 0.5354],
       device='cuda:0') torch.Size([16])
percent tensor([0.5124, 0.5553, 0.5089, 0.4642, 0.5054, 0.4471, 0.5471, 0.5085, 0.4949,
        0.5370, 0.5147, 0.5508, 0.5694, 0.4471, 0.5314, 0.4821],
       device='cuda:0') torch.Size([16])
percent tensor([0.6547, 0.6879, 0.6508, 0.6558, 0.6485, 0.6385, 0.6766, 0.6464, 0.6754,
        0.6925, 0.7133, 0.6893, 0.6887, 0.6887, 0.6676, 0.6676],
       device='cuda:0') torch.Size([16])
percent tensor([0.6257, 0.6107, 0.5975, 0.5754, 0.5750, 0.7079, 0.6220, 0.5651, 0.6331,
        0.6085, 0.6293, 0.5828, 0.6415, 0.6619, 0.6190, 0.6466],
       device='cuda:0') torch.Size([16])
percent tensor([0.5249, 0.5929, 0.5739, 0.5478, 0.5250, 0.5173, 0.5446, 0.4558, 0.6238,
        0.5791, 0.6335, 0.6132, 0.5836, 0.6773, 0.4699, 0.5194],
       device='cuda:0') torch.Size([16])
percent tensor([0.5292, 0.5600, 0.7368, 0.7220, 0.7362, 0.6254, 0.5856, 0.6569, 0.6325,
        0.6045, 0.6399, 0.7237, 0.5469, 0.6754, 0.5594, 0.5923],
       device='cuda:0') torch.Size([16])
percent tensor([0.9988, 0.9948, 0.9974, 0.9978, 0.9974, 0.9967, 0.9974, 0.9983, 0.9949,
        0.9973, 0.9976, 0.9966, 0.9954, 0.9967, 0.9972, 0.9989],
       device='cuda:0') torch.Size([16])
Epoch: 57 | Batch_idx: 0 |  Loss: (0.4172) |  Loss2: (0.0000) | Acc: (83.00%) (107/128)
Epoch: 57 | Batch_idx: 10 |  Loss: (0.3732) |  Loss2: (0.0000) | Acc: (86.00%) (1221/1408)
Epoch: 57 | Batch_idx: 20 |  Loss: (0.3621) |  Loss2: (0.0000) | Acc: (87.00%) (2357/2688)
Epoch: 57 | Batch_idx: 30 |  Loss: (0.3621) |  Loss2: (0.0000) | Acc: (87.00%) (3488/3968)
Epoch: 57 | Batch_idx: 40 |  Loss: (0.3627) |  Loss2: (0.0000) | Acc: (87.00%) (4612/5248)
Epoch: 57 | Batch_idx: 50 |  Loss: (0.3611) |  Loss2: (0.0000) | Acc: (87.00%) (5744/6528)
Epoch: 57 | Batch_idx: 60 |  Loss: (0.3597) |  Loss2: (0.0000) | Acc: (87.00%) (6867/7808)
Epoch: 57 | Batch_idx: 70 |  Loss: (0.3549) |  Loss2: (0.0000) | Acc: (87.00%) (7994/9088)
Epoch: 57 | Batch_idx: 80 |  Loss: (0.3544) |  Loss2: (0.0000) | Acc: (87.00%) (9118/10368)
Epoch: 57 | Batch_idx: 90 |  Loss: (0.3519) |  Loss2: (0.0000) | Acc: (88.00%) (10255/11648)
Epoch: 57 | Batch_idx: 100 |  Loss: (0.3505) |  Loss2: (0.0000) | Acc: (87.00%) (11372/12928)
Epoch: 57 | Batch_idx: 110 |  Loss: (0.3501) |  Loss2: (0.0000) | Acc: (87.00%) (12494/14208)
Epoch: 57 | Batch_idx: 120 |  Loss: (0.3501) |  Loss2: (0.0000) | Acc: (87.00%) (13622/15488)
Epoch: 57 | Batch_idx: 130 |  Loss: (0.3492) |  Loss2: (0.0000) | Acc: (87.00%) (14736/16768)
Epoch: 57 | Batch_idx: 140 |  Loss: (0.3510) |  Loss2: (0.0000) | Acc: (87.00%) (15851/18048)
Epoch: 57 | Batch_idx: 150 |  Loss: (0.3533) |  Loss2: (0.0000) | Acc: (87.00%) (16963/19328)
Epoch: 57 | Batch_idx: 160 |  Loss: (0.3522) |  Loss2: (0.0000) | Acc: (87.00%) (18099/20608)
Epoch: 57 | Batch_idx: 170 |  Loss: (0.3525) |  Loss2: (0.0000) | Acc: (87.00%) (19218/21888)
Epoch: 57 | Batch_idx: 180 |  Loss: (0.3524) |  Loss2: (0.0000) | Acc: (87.00%) (20327/23168)
Epoch: 57 | Batch_idx: 190 |  Loss: (0.3518) |  Loss2: (0.0000) | Acc: (87.00%) (21464/24448)
Epoch: 57 | Batch_idx: 200 |  Loss: (0.3503) |  Loss2: (0.0000) | Acc: (87.00%) (22604/25728)
Epoch: 57 | Batch_idx: 210 |  Loss: (0.3507) |  Loss2: (0.0000) | Acc: (87.00%) (23736/27008)
Epoch: 57 | Batch_idx: 220 |  Loss: (0.3513) |  Loss2: (0.0000) | Acc: (87.00%) (24865/28288)
Epoch: 57 | Batch_idx: 230 |  Loss: (0.3512) |  Loss2: (0.0000) | Acc: (87.00%) (25994/29568)
Epoch: 57 | Batch_idx: 240 |  Loss: (0.3498) |  Loss2: (0.0000) | Acc: (87.00%) (27136/30848)
Epoch: 57 | Batch_idx: 250 |  Loss: (0.3495) |  Loss2: (0.0000) | Acc: (87.00%) (28260/32128)
Epoch: 57 | Batch_idx: 260 |  Loss: (0.3484) |  Loss2: (0.0000) | Acc: (88.00%) (29401/33408)
Epoch: 57 | Batch_idx: 270 |  Loss: (0.3492) |  Loss2: (0.0000) | Acc: (87.00%) (30511/34688)
Epoch: 57 | Batch_idx: 280 |  Loss: (0.3486) |  Loss2: (0.0000) | Acc: (87.00%) (31644/35968)
Epoch: 57 | Batch_idx: 290 |  Loss: (0.3477) |  Loss2: (0.0000) | Acc: (88.00%) (32785/37248)
Epoch: 57 | Batch_idx: 300 |  Loss: (0.3470) |  Loss2: (0.0000) | Acc: (88.00%) (33927/38528)
Epoch: 57 | Batch_idx: 310 |  Loss: (0.3471) |  Loss2: (0.0000) | Acc: (88.00%) (35063/39808)
Epoch: 57 | Batch_idx: 320 |  Loss: (0.3481) |  Loss2: (0.0000) | Acc: (88.00%) (36186/41088)
Epoch: 57 | Batch_idx: 330 |  Loss: (0.3486) |  Loss2: (0.0000) | Acc: (88.00%) (37305/42368)
Epoch: 57 | Batch_idx: 340 |  Loss: (0.3489) |  Loss2: (0.0000) | Acc: (88.00%) (38427/43648)
Epoch: 57 | Batch_idx: 350 |  Loss: (0.3498) |  Loss2: (0.0000) | Acc: (88.00%) (39542/44928)
Epoch: 57 | Batch_idx: 360 |  Loss: (0.3499) |  Loss2: (0.0000) | Acc: (88.00%) (40670/46208)
Epoch: 57 | Batch_idx: 370 |  Loss: (0.3498) |  Loss2: (0.0000) | Acc: (88.00%) (41800/47488)
Epoch: 57 | Batch_idx: 380 |  Loss: (0.3499) |  Loss2: (0.0000) | Acc: (88.00%) (42916/48768)
Epoch: 57 | Batch_idx: 390 |  Loss: (0.3491) |  Loss2: (0.0000) | Acc: (88.00%) (44019/50000)
# TEST : Loss: (0.4320) | Acc: (85.00%) (8516/10000)
percent tensor([0.5088, 0.5032, 0.5118, 0.5121, 0.5101, 0.5097, 0.5059, 0.5116, 0.5096,
        0.5060, 0.5074, 0.5074, 0.5070, 0.5043, 0.5068, 0.5087],
       device='cuda:0') torch.Size([16])
percent tensor([0.5336, 0.5448, 0.5261, 0.5315, 0.5298, 0.5502, 0.5397, 0.5300, 0.5251,
        0.5326, 0.5322, 0.5263, 0.5303, 0.5425, 0.5458, 0.5385],
       device='cuda:0') torch.Size([16])
percent tensor([0.5171, 0.5561, 0.5133, 0.4653, 0.5100, 0.4511, 0.5497, 0.5146, 0.4976,
        0.5389, 0.5153, 0.5521, 0.5715, 0.4462, 0.5343, 0.4850],
       device='cuda:0') torch.Size([16])
percent tensor([0.6573, 0.6925, 0.6547, 0.6606, 0.6516, 0.6423, 0.6801, 0.6492, 0.6793,
        0.6970, 0.7191, 0.6949, 0.6930, 0.6938, 0.6718, 0.6712],
       device='cuda:0') torch.Size([16])
percent tensor([0.6254, 0.6092, 0.5971, 0.5731, 0.5749, 0.7060, 0.6213, 0.5658, 0.6326,
        0.6073, 0.6275, 0.5809, 0.6407, 0.6609, 0.6182, 0.6447],
       device='cuda:0') torch.Size([16])
percent tensor([0.5337, 0.6048, 0.5777, 0.5500, 0.5302, 0.5199, 0.5526, 0.4603, 0.6309,
        0.5887, 0.6413, 0.6169, 0.5924, 0.6869, 0.4749, 0.5238],
       device='cuda:0') torch.Size([16])
percent tensor([0.5338, 0.5778, 0.7469, 0.7318, 0.7444, 0.6248, 0.5929, 0.6633, 0.6483,
        0.6229, 0.6611, 0.7443, 0.5594, 0.6979, 0.5719, 0.5889],
       device='cuda:0') torch.Size([16])
percent tensor([0.9989, 0.9954, 0.9975, 0.9979, 0.9974, 0.9967, 0.9976, 0.9984, 0.9955,
        0.9975, 0.9981, 0.9968, 0.9959, 0.9971, 0.9974, 0.9989],
       device='cuda:0') torch.Size([16])
Epoch: 58 | Batch_idx: 0 |  Loss: (0.4070) |  Loss2: (0.0000) | Acc: (85.00%) (109/128)
Epoch: 58 | Batch_idx: 10 |  Loss: (0.3215) |  Loss2: (0.0000) | Acc: (88.00%) (1252/1408)
Epoch: 58 | Batch_idx: 20 |  Loss: (0.3517) |  Loss2: (0.0000) | Acc: (87.00%) (2360/2688)
Epoch: 58 | Batch_idx: 30 |  Loss: (0.3547) |  Loss2: (0.0000) | Acc: (88.00%) (3498/3968)
Epoch: 58 | Batch_idx: 40 |  Loss: (0.3549) |  Loss2: (0.0000) | Acc: (88.00%) (4632/5248)
Epoch: 58 | Batch_idx: 50 |  Loss: (0.3592) |  Loss2: (0.0000) | Acc: (88.00%) (5752/6528)
Epoch: 58 | Batch_idx: 60 |  Loss: (0.3577) |  Loss2: (0.0000) | Acc: (88.00%) (6878/7808)
Epoch: 58 | Batch_idx: 70 |  Loss: (0.3565) |  Loss2: (0.0000) | Acc: (87.00%) (7995/9088)
Epoch: 58 | Batch_idx: 80 |  Loss: (0.3572) |  Loss2: (0.0000) | Acc: (87.00%) (9104/10368)
Epoch: 58 | Batch_idx: 90 |  Loss: (0.3522) |  Loss2: (0.0000) | Acc: (88.00%) (10258/11648)
Epoch: 58 | Batch_idx: 100 |  Loss: (0.3580) |  Loss2: (0.0000) | Acc: (87.00%) (11372/12928)
Epoch: 58 | Batch_idx: 110 |  Loss: (0.3589) |  Loss2: (0.0000) | Acc: (87.00%) (12484/14208)
Epoch: 58 | Batch_idx: 120 |  Loss: (0.3588) |  Loss2: (0.0000) | Acc: (87.00%) (13600/15488)
Epoch: 58 | Batch_idx: 130 |  Loss: (0.3594) |  Loss2: (0.0000) | Acc: (87.00%) (14722/16768)
Epoch: 58 | Batch_idx: 140 |  Loss: (0.3590) |  Loss2: (0.0000) | Acc: (87.00%) (15842/18048)
Epoch: 58 | Batch_idx: 150 |  Loss: (0.3583) |  Loss2: (0.0000) | Acc: (87.00%) (16967/19328)
Epoch: 58 | Batch_idx: 160 |  Loss: (0.3566) |  Loss2: (0.0000) | Acc: (87.00%) (18092/20608)
Epoch: 58 | Batch_idx: 170 |  Loss: (0.3544) |  Loss2: (0.0000) | Acc: (87.00%) (19239/21888)
Epoch: 58 | Batch_idx: 180 |  Loss: (0.3543) |  Loss2: (0.0000) | Acc: (87.00%) (20365/23168)
Epoch: 58 | Batch_idx: 190 |  Loss: (0.3541) |  Loss2: (0.0000) | Acc: (87.00%) (21487/24448)
Epoch: 58 | Batch_idx: 200 |  Loss: (0.3536) |  Loss2: (0.0000) | Acc: (87.00%) (22608/25728)
Epoch: 58 | Batch_idx: 210 |  Loss: (0.3532) |  Loss2: (0.0000) | Acc: (87.00%) (23728/27008)
Epoch: 58 | Batch_idx: 220 |  Loss: (0.3525) |  Loss2: (0.0000) | Acc: (87.00%) (24858/28288)
Epoch: 58 | Batch_idx: 230 |  Loss: (0.3502) |  Loss2: (0.0000) | Acc: (87.00%) (25996/29568)
Epoch: 58 | Batch_idx: 240 |  Loss: (0.3495) |  Loss2: (0.0000) | Acc: (87.00%) (27141/30848)
Epoch: 58 | Batch_idx: 250 |  Loss: (0.3496) |  Loss2: (0.0000) | Acc: (88.00%) (28274/32128)
Epoch: 58 | Batch_idx: 260 |  Loss: (0.3496) |  Loss2: (0.0000) | Acc: (87.00%) (29397/33408)
Epoch: 58 | Batch_idx: 270 |  Loss: (0.3486) |  Loss2: (0.0000) | Acc: (88.00%) (30551/34688)
Epoch: 58 | Batch_idx: 280 |  Loss: (0.3488) |  Loss2: (0.0000) | Acc: (88.00%) (31672/35968)
Epoch: 58 | Batch_idx: 290 |  Loss: (0.3479) |  Loss2: (0.0000) | Acc: (88.00%) (32814/37248)
Epoch: 58 | Batch_idx: 300 |  Loss: (0.3481) |  Loss2: (0.0000) | Acc: (88.00%) (33934/38528)
Epoch: 58 | Batch_idx: 310 |  Loss: (0.3476) |  Loss2: (0.0000) | Acc: (88.00%) (35076/39808)
Epoch: 58 | Batch_idx: 320 |  Loss: (0.3466) |  Loss2: (0.0000) | Acc: (88.00%) (36225/41088)
Epoch: 58 | Batch_idx: 330 |  Loss: (0.3463) |  Loss2: (0.0000) | Acc: (88.00%) (37360/42368)
Epoch: 58 | Batch_idx: 340 |  Loss: (0.3459) |  Loss2: (0.0000) | Acc: (88.00%) (38485/43648)
Epoch: 58 | Batch_idx: 350 |  Loss: (0.3450) |  Loss2: (0.0000) | Acc: (88.00%) (39628/44928)
Epoch: 58 | Batch_idx: 360 |  Loss: (0.3453) |  Loss2: (0.0000) | Acc: (88.00%) (40738/46208)
Epoch: 58 | Batch_idx: 370 |  Loss: (0.3463) |  Loss2: (0.0000) | Acc: (88.00%) (41845/47488)
Epoch: 58 | Batch_idx: 380 |  Loss: (0.3455) |  Loss2: (0.0000) | Acc: (88.00%) (42982/48768)
Epoch: 58 | Batch_idx: 390 |  Loss: (0.3455) |  Loss2: (0.0000) | Acc: (88.00%) (44078/50000)
# TEST : Loss: (0.4263) | Acc: (85.00%) (8533/10000)
percent tensor([0.5102, 0.5044, 0.5137, 0.5136, 0.5119, 0.5112, 0.5074, 0.5131, 0.5111,
        0.5074, 0.5088, 0.5092, 0.5084, 0.5053, 0.5081, 0.5101],
       device='cuda:0') torch.Size([16])
percent tensor([0.5333, 0.5443, 0.5260, 0.5318, 0.5296, 0.5511, 0.5392, 0.5296, 0.5249,
        0.5319, 0.5318, 0.5260, 0.5299, 0.5422, 0.5457, 0.5385],
       device='cuda:0') torch.Size([16])
percent tensor([0.5169, 0.5558, 0.5150, 0.4666, 0.5111, 0.4501, 0.5487, 0.5169, 0.4993,
        0.5394, 0.5144, 0.5517, 0.5709, 0.4483, 0.5327, 0.4848],
       device='cuda:0') torch.Size([16])
percent tensor([0.6597, 0.6952, 0.6587, 0.6658, 0.6551, 0.6474, 0.6822, 0.6524, 0.6824,
        0.6995, 0.7226, 0.6996, 0.6965, 0.6961, 0.6752, 0.6745],
       device='cuda:0') torch.Size([16])
percent tensor([0.6229, 0.6049, 0.5958, 0.5724, 0.5759, 0.7028, 0.6193, 0.5691, 0.6293,
        0.6014, 0.6207, 0.5780, 0.6358, 0.6565, 0.6180, 0.6409],
       device='cuda:0') torch.Size([16])
percent tensor([0.5338, 0.6067, 0.5795, 0.5493, 0.5323, 0.5218, 0.5527, 0.4595, 0.6323,
        0.5899, 0.6395, 0.6161, 0.5932, 0.6887, 0.4719, 0.5245],
       device='cuda:0') torch.Size([16])
percent tensor([0.5340, 0.5859, 0.7565, 0.7403, 0.7567, 0.6252, 0.6002, 0.6758, 0.6560,
        0.6318, 0.6642, 0.7571, 0.5627, 0.7040, 0.5811, 0.5913],
       device='cuda:0') torch.Size([16])
percent tensor([0.9990, 0.9958, 0.9978, 0.9980, 0.9977, 0.9969, 0.9978, 0.9985, 0.9958,
        0.9977, 0.9982, 0.9971, 0.9961, 0.9974, 0.9976, 0.9990],
       device='cuda:0') torch.Size([16])
Epoch: 59 | Batch_idx: 0 |  Loss: (0.4062) |  Loss2: (0.0000) | Acc: (85.00%) (110/128)
Epoch: 59 | Batch_idx: 10 |  Loss: (0.3646) |  Loss2: (0.0000) | Acc: (87.00%) (1232/1408)
Epoch: 59 | Batch_idx: 20 |  Loss: (0.3648) |  Loss2: (0.0000) | Acc: (87.00%) (2345/2688)
Epoch: 59 | Batch_idx: 30 |  Loss: (0.3724) |  Loss2: (0.0000) | Acc: (87.00%) (3455/3968)
Epoch: 59 | Batch_idx: 40 |  Loss: (0.3686) |  Loss2: (0.0000) | Acc: (87.00%) (4580/5248)
Epoch: 59 | Batch_idx: 50 |  Loss: (0.3603) |  Loss2: (0.0000) | Acc: (87.00%) (5720/6528)
Epoch: 59 | Batch_idx: 60 |  Loss: (0.3605) |  Loss2: (0.0000) | Acc: (87.00%) (6852/7808)
Epoch: 59 | Batch_idx: 70 |  Loss: (0.3594) |  Loss2: (0.0000) | Acc: (87.00%) (7978/9088)
Epoch: 59 | Batch_idx: 80 |  Loss: (0.3613) |  Loss2: (0.0000) | Acc: (87.00%) (9091/10368)
Epoch: 59 | Batch_idx: 90 |  Loss: (0.3624) |  Loss2: (0.0000) | Acc: (87.00%) (10208/11648)
Epoch: 59 | Batch_idx: 100 |  Loss: (0.3551) |  Loss2: (0.0000) | Acc: (87.00%) (11361/12928)
Epoch: 59 | Batch_idx: 110 |  Loss: (0.3519) |  Loss2: (0.0000) | Acc: (87.00%) (12499/14208)
Epoch: 59 | Batch_idx: 120 |  Loss: (0.3506) |  Loss2: (0.0000) | Acc: (88.00%) (13634/15488)
Epoch: 59 | Batch_idx: 130 |  Loss: (0.3499) |  Loss2: (0.0000) | Acc: (88.00%) (14768/16768)
Epoch: 59 | Batch_idx: 140 |  Loss: (0.3495) |  Loss2: (0.0000) | Acc: (88.00%) (15906/18048)
Epoch: 59 | Batch_idx: 150 |  Loss: (0.3479) |  Loss2: (0.0000) | Acc: (88.00%) (17040/19328)
Epoch: 59 | Batch_idx: 160 |  Loss: (0.3474) |  Loss2: (0.0000) | Acc: (88.00%) (18162/20608)
Epoch: 59 | Batch_idx: 170 |  Loss: (0.3454) |  Loss2: (0.0000) | Acc: (88.00%) (19316/21888)
Epoch: 59 | Batch_idx: 180 |  Loss: (0.3457) |  Loss2: (0.0000) | Acc: (88.00%) (20442/23168)
Epoch: 59 | Batch_idx: 190 |  Loss: (0.3450) |  Loss2: (0.0000) | Acc: (88.00%) (21568/24448)
Epoch: 59 | Batch_idx: 200 |  Loss: (0.3446) |  Loss2: (0.0000) | Acc: (88.00%) (22701/25728)
Epoch: 59 | Batch_idx: 210 |  Loss: (0.3441) |  Loss2: (0.0000) | Acc: (88.00%) (23828/27008)
Epoch: 59 | Batch_idx: 220 |  Loss: (0.3440) |  Loss2: (0.0000) | Acc: (88.00%) (24939/28288)
Epoch: 59 | Batch_idx: 230 |  Loss: (0.3429) |  Loss2: (0.0000) | Acc: (88.00%) (26068/29568)
Epoch: 59 | Batch_idx: 240 |  Loss: (0.3424) |  Loss2: (0.0000) | Acc: (88.00%) (27208/30848)
Epoch: 59 | Batch_idx: 250 |  Loss: (0.3433) |  Loss2: (0.0000) | Acc: (88.00%) (28328/32128)
Epoch: 59 | Batch_idx: 260 |  Loss: (0.3429) |  Loss2: (0.0000) | Acc: (88.00%) (29472/33408)
Epoch: 59 | Batch_idx: 270 |  Loss: (0.3421) |  Loss2: (0.0000) | Acc: (88.00%) (30619/34688)
Epoch: 59 | Batch_idx: 280 |  Loss: (0.3415) |  Loss2: (0.0000) | Acc: (88.00%) (31751/35968)
Epoch: 59 | Batch_idx: 290 |  Loss: (0.3412) |  Loss2: (0.0000) | Acc: (88.00%) (32880/37248)
Epoch: 59 | Batch_idx: 300 |  Loss: (0.3408) |  Loss2: (0.0000) | Acc: (88.00%) (34018/38528)
Epoch: 59 | Batch_idx: 310 |  Loss: (0.3409) |  Loss2: (0.0000) | Acc: (88.00%) (35150/39808)
Epoch: 59 | Batch_idx: 320 |  Loss: (0.3413) |  Loss2: (0.0000) | Acc: (88.00%) (36280/41088)
Epoch: 59 | Batch_idx: 330 |  Loss: (0.3410) |  Loss2: (0.0000) | Acc: (88.00%) (37405/42368)
Epoch: 59 | Batch_idx: 340 |  Loss: (0.3421) |  Loss2: (0.0000) | Acc: (88.00%) (38519/43648)
Epoch: 59 | Batch_idx: 350 |  Loss: (0.3418) |  Loss2: (0.0000) | Acc: (88.00%) (39661/44928)
Epoch: 59 | Batch_idx: 360 |  Loss: (0.3422) |  Loss2: (0.0000) | Acc: (88.00%) (40781/46208)
Epoch: 59 | Batch_idx: 370 |  Loss: (0.3413) |  Loss2: (0.0000) | Acc: (88.00%) (41930/47488)
Epoch: 59 | Batch_idx: 380 |  Loss: (0.3420) |  Loss2: (0.0000) | Acc: (88.00%) (43053/48768)
Epoch: 59 | Batch_idx: 390 |  Loss: (0.3423) |  Loss2: (0.0000) | Acc: (88.00%) (44144/50000)
# TEST : Loss: (0.4254) | Acc: (85.00%) (8523/10000)
percent tensor([0.5102, 0.5041, 0.5143, 0.5140, 0.5122, 0.5111, 0.5073, 0.5134, 0.5113,
        0.5075, 0.5088, 0.5096, 0.5084, 0.5049, 0.5080, 0.5101],
       device='cuda:0') torch.Size([16])
percent tensor([0.5335, 0.5445, 0.5264, 0.5325, 0.5300, 0.5522, 0.5393, 0.5301, 0.5253,
        0.5319, 0.5318, 0.5264, 0.5301, 0.5425, 0.5462, 0.5389],
       device='cuda:0') torch.Size([16])
percent tensor([0.5215, 0.5578, 0.5223, 0.4737, 0.5176, 0.4563, 0.5519, 0.5241, 0.5047,
        0.5436, 0.5177, 0.5558, 0.5735, 0.4525, 0.5365, 0.4904],
       device='cuda:0') torch.Size([16])
percent tensor([0.6569, 0.6931, 0.6567, 0.6645, 0.6525, 0.6454, 0.6796, 0.6498, 0.6802,
        0.6974, 0.7210, 0.6989, 0.6951, 0.6937, 0.6734, 0.6720],
       device='cuda:0') torch.Size([16])
percent tensor([0.6226, 0.6022, 0.5996, 0.5751, 0.5797, 0.7040, 0.6192, 0.5721, 0.6297,
        0.5990, 0.6201, 0.5795, 0.6348, 0.6565, 0.6186, 0.6403],
       device='cuda:0') torch.Size([16])
percent tensor([0.5268, 0.6003, 0.5713, 0.5404, 0.5237, 0.5165, 0.5445, 0.4493, 0.6270,
        0.5822, 0.6325, 0.6041, 0.5859, 0.6852, 0.4602, 0.5167],
       device='cuda:0') torch.Size([16])
percent tensor([0.5403, 0.5947, 0.7600, 0.7454, 0.7620, 0.6238, 0.6094, 0.6843, 0.6633,
        0.6419, 0.6742, 0.7654, 0.5694, 0.7120, 0.5923, 0.5925],
       device='cuda:0') torch.Size([16])
percent tensor([0.9991, 0.9964, 0.9980, 0.9982, 0.9979, 0.9972, 0.9981, 0.9986, 0.9965,
        0.9980, 0.9984, 0.9975, 0.9966, 0.9978, 0.9978, 0.9991],
       device='cuda:0') torch.Size([16])
True Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=128, out_features=16, bias=False)
False Linear(in_features=16, out_features=2, bias=False)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=128, out_features=16, bias=False)
False Linear(in_features=16, out_features=2, bias=False)
True Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=256, out_features=32, bias=False)
False Linear(in_features=32, out_features=2, bias=False)
True Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=256, out_features=32, bias=False)
False Linear(in_features=32, out_features=2, bias=False)
True Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=512, out_features=64, bias=False)
False Linear(in_features=64, out_features=2, bias=False)
True Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=512, out_features=64, bias=False)
False Linear(in_features=64, out_features=2, bias=False)
True Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1024, out_features=128, bias=False)
False Linear(in_features=128, out_features=2, bias=False)
True Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1024, out_features=128, bias=False)
False Linear(in_features=128, out_features=2, bias=False)
True Linear(in_features=512, out_features=10, bias=True)
Epoch: 60 | Batch_idx: 0 |  Loss: (0.2986) |  Loss2: (0.0000) | Acc: (88.00%) (113/128)
Epoch: 60 | Batch_idx: 10 |  Loss: (0.3402) |  Loss2: (0.0000) | Acc: (87.00%) (1228/1408)
Epoch: 60 | Batch_idx: 20 |  Loss: (0.3336) |  Loss2: (0.0000) | Acc: (88.00%) (2372/2688)
Epoch: 60 | Batch_idx: 30 |  Loss: (0.3375) |  Loss2: (0.0000) | Acc: (88.00%) (3497/3968)
Epoch: 60 | Batch_idx: 40 |  Loss: (0.3425) |  Loss2: (0.0000) | Acc: (88.00%) (4623/5248)
Epoch: 60 | Batch_idx: 50 |  Loss: (0.3432) |  Loss2: (0.0000) | Acc: (88.00%) (5748/6528)
Epoch: 60 | Batch_idx: 60 |  Loss: (0.3491) |  Loss2: (0.0000) | Acc: (87.00%) (6858/7808)
Epoch: 60 | Batch_idx: 70 |  Loss: (0.3493) |  Loss2: (0.0000) | Acc: (87.00%) (7987/9088)
Epoch: 60 | Batch_idx: 80 |  Loss: (0.3482) |  Loss2: (0.0000) | Acc: (87.00%) (9103/10368)
Epoch: 60 | Batch_idx: 90 |  Loss: (0.3517) |  Loss2: (0.0000) | Acc: (87.00%) (10216/11648)
Epoch: 60 | Batch_idx: 100 |  Loss: (0.3499) |  Loss2: (0.0000) | Acc: (87.00%) (11339/12928)
Epoch: 60 | Batch_idx: 110 |  Loss: (0.3524) |  Loss2: (0.0000) | Acc: (87.00%) (12455/14208)
Epoch: 60 | Batch_idx: 120 |  Loss: (0.3543) |  Loss2: (0.0000) | Acc: (87.00%) (13567/15488)
Epoch: 60 | Batch_idx: 130 |  Loss: (0.3574) |  Loss2: (0.0000) | Acc: (87.00%) (14675/16768)
Epoch: 60 | Batch_idx: 140 |  Loss: (0.3565) |  Loss2: (0.0000) | Acc: (87.00%) (15814/18048)
Epoch: 60 | Batch_idx: 150 |  Loss: (0.3561) |  Loss2: (0.0000) | Acc: (87.00%) (16939/19328)
Epoch: 60 | Batch_idx: 160 |  Loss: (0.3550) |  Loss2: (0.0000) | Acc: (87.00%) (18077/20608)
Epoch: 60 | Batch_idx: 170 |  Loss: (0.3550) |  Loss2: (0.0000) | Acc: (87.00%) (19207/21888)
Epoch: 60 | Batch_idx: 180 |  Loss: (0.3539) |  Loss2: (0.0000) | Acc: (87.00%) (20344/23168)
Epoch: 60 | Batch_idx: 190 |  Loss: (0.3541) |  Loss2: (0.0000) | Acc: (87.00%) (21473/24448)
Epoch: 60 | Batch_idx: 200 |  Loss: (0.3521) |  Loss2: (0.0000) | Acc: (87.00%) (22618/25728)
Epoch: 60 | Batch_idx: 210 |  Loss: (0.3533) |  Loss2: (0.0000) | Acc: (87.00%) (23732/27008)
Epoch: 60 | Batch_idx: 220 |  Loss: (0.3537) |  Loss2: (0.0000) | Acc: (87.00%) (24843/28288)
Epoch: 60 | Batch_idx: 230 |  Loss: (0.3542) |  Loss2: (0.0000) | Acc: (87.00%) (25959/29568)
Epoch: 60 | Batch_idx: 240 |  Loss: (0.3543) |  Loss2: (0.0000) | Acc: (87.00%) (27081/30848)
Epoch: 60 | Batch_idx: 250 |  Loss: (0.3560) |  Loss2: (0.0000) | Acc: (87.00%) (28190/32128)
Epoch: 60 | Batch_idx: 260 |  Loss: (0.3558) |  Loss2: (0.0000) | Acc: (87.00%) (29317/33408)
Epoch: 60 | Batch_idx: 270 |  Loss: (0.3556) |  Loss2: (0.0000) | Acc: (87.00%) (30455/34688)
Epoch: 60 | Batch_idx: 280 |  Loss: (0.3567) |  Loss2: (0.0000) | Acc: (87.00%) (31568/35968)
Epoch: 60 | Batch_idx: 290 |  Loss: (0.3578) |  Loss2: (0.0000) | Acc: (87.00%) (32688/37248)
Epoch: 60 | Batch_idx: 300 |  Loss: (0.3595) |  Loss2: (0.0000) | Acc: (87.00%) (33782/38528)
Epoch: 60 | Batch_idx: 310 |  Loss: (0.3603) |  Loss2: (0.0000) | Acc: (87.00%) (34901/39808)
Epoch: 60 | Batch_idx: 320 |  Loss: (0.3607) |  Loss2: (0.0000) | Acc: (87.00%) (36003/41088)
Epoch: 60 | Batch_idx: 330 |  Loss: (0.3597) |  Loss2: (0.0000) | Acc: (87.00%) (37145/42368)
Epoch: 60 | Batch_idx: 340 |  Loss: (0.3598) |  Loss2: (0.0000) | Acc: (87.00%) (38274/43648)
Epoch: 60 | Batch_idx: 350 |  Loss: (0.3596) |  Loss2: (0.0000) | Acc: (87.00%) (39391/44928)
Epoch: 60 | Batch_idx: 360 |  Loss: (0.3609) |  Loss2: (0.0000) | Acc: (87.00%) (40486/46208)
Epoch: 60 | Batch_idx: 370 |  Loss: (0.3608) |  Loss2: (0.0000) | Acc: (87.00%) (41614/47488)
Epoch: 60 | Batch_idx: 380 |  Loss: (0.3614) |  Loss2: (0.0000) | Acc: (87.00%) (42720/48768)
Epoch: 60 | Batch_idx: 390 |  Loss: (0.3613) |  Loss2: (0.0000) | Acc: (87.00%) (43805/50000)
=> saving checkpoint 'drive/app/torch/save_Routing_Gate_2/checkpoint_060.pth.tar'
# TEST : Loss: (0.4858) | Acc: (83.00%) (8340/10000)
percent tensor([0.5105, 0.5043, 0.5149, 0.5143, 0.5129, 0.5116, 0.5077, 0.5133, 0.5113,
        0.5077, 0.5090, 0.5104, 0.5084, 0.5051, 0.5082, 0.5101],
       device='cuda:0') torch.Size([16])
percent tensor([0.5339, 0.5437, 0.5260, 0.5341, 0.5298, 0.5515, 0.5383, 0.5298, 0.5247,
        0.5316, 0.5320, 0.5265, 0.5304, 0.5405, 0.5461, 0.5391],
       device='cuda:0') torch.Size([16])
percent tensor([0.5220, 0.5499, 0.5388, 0.4637, 0.5226, 0.4623, 0.5482, 0.5221, 0.5081,
        0.5386, 0.5228, 0.5531, 0.5766, 0.4294, 0.5347, 0.4878],
       device='cuda:0') torch.Size([16])
percent tensor([0.6524, 0.6864, 0.6581, 0.6628, 0.6569, 0.6484, 0.6776, 0.6522, 0.6747,
        0.6877, 0.7096, 0.6980, 0.6840, 0.6949, 0.6690, 0.6665],
       device='cuda:0') torch.Size([16])
percent tensor([0.6212, 0.5852, 0.6139, 0.5765, 0.5937, 0.7107, 0.6062, 0.5680, 0.6345,
        0.5928, 0.6196, 0.5837, 0.6340, 0.6349, 0.6138, 0.6390],
       device='cuda:0') torch.Size([16])
percent tensor([0.5076, 0.5863, 0.5482, 0.5385, 0.5539, 0.5132, 0.5514, 0.4727, 0.6126,
        0.5493, 0.5985, 0.5905, 0.5600, 0.6717, 0.4550, 0.4939],
       device='cuda:0') torch.Size([16])
percent tensor([0.5301, 0.5699, 0.7453, 0.7500, 0.7837, 0.6232, 0.6299, 0.6962, 0.6659,
        0.5958, 0.6377, 0.7603, 0.5487, 0.7043, 0.5955, 0.5906],
       device='cuda:0') torch.Size([16])
percent tensor([0.9991, 0.9970, 0.9984, 0.9982, 0.9980, 0.9971, 0.9979, 0.9987, 0.9969,
        0.9982, 0.9981, 0.9981, 0.9962, 0.9984, 0.9976, 0.9988],
       device='cuda:0') torch.Size([16])
Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 3, 3, 3]) tensor(175.1655, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(797.1113, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(799.2970, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([128, 64, 3, 3]) tensor(1521.5326, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([128, 64, 1, 1]) tensor(501.9203, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([128, 128, 3, 3]) tensor(2209.9929, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([256, 128, 3, 3]) tensor(4290.7397, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([256, 128, 1, 1]) tensor(1414.6671, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([256, 256, 3, 3]) tensor(6089.5142, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([512, 256, 3, 3]) tensor(12014.0957, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([512, 256, 1, 1]) tensor(4001.6863, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([512, 512, 3, 3]) tensor(16905.4531, device='cuda:0', grad_fn=<NormBackward0>)
Epoch: 61 | Batch_idx: 0 |  Loss: (0.3895) |  Loss2: (0.0000) | Acc: (85.00%) (109/128)
Epoch: 61 | Batch_idx: 10 |  Loss: (0.3354) |  Loss2: (0.0000) | Acc: (89.00%) (1256/1408)
Epoch: 61 | Batch_idx: 20 |  Loss: (0.3372) |  Loss2: (0.0000) | Acc: (88.00%) (2386/2688)
Epoch: 61 | Batch_idx: 30 |  Loss: (0.3370) |  Loss2: (0.0000) | Acc: (88.00%) (3520/3968)
Epoch: 61 | Batch_idx: 40 |  Loss: (0.3399) |  Loss2: (0.0000) | Acc: (88.00%) (4654/5248)
Epoch: 61 | Batch_idx: 50 |  Loss: (0.3358) |  Loss2: (0.0000) | Acc: (88.00%) (5780/6528)
Epoch: 61 | Batch_idx: 60 |  Loss: (0.3348) |  Loss2: (0.0000) | Acc: (88.00%) (6924/7808)
Epoch: 61 | Batch_idx: 70 |  Loss: (0.3398) |  Loss2: (0.0000) | Acc: (88.00%) (8047/9088)
Epoch: 61 | Batch_idx: 80 |  Loss: (0.3433) |  Loss2: (0.0000) | Acc: (88.00%) (9173/10368)
Epoch: 61 | Batch_idx: 90 |  Loss: (0.3442) |  Loss2: (0.0000) | Acc: (88.00%) (10299/11648)
Epoch: 61 | Batch_idx: 100 |  Loss: (0.3416) |  Loss2: (0.0000) | Acc: (88.00%) (11439/12928)
Epoch: 61 | Batch_idx: 110 |  Loss: (0.3416) |  Loss2: (0.0000) | Acc: (88.00%) (12568/14208)
Epoch: 61 | Batch_idx: 120 |  Loss: (0.3418) |  Loss2: (0.0000) | Acc: (88.00%) (13690/15488)
Epoch: 61 | Batch_idx: 130 |  Loss: (0.3483) |  Loss2: (0.0000) | Acc: (88.00%) (14772/16768)
Epoch: 61 | Batch_idx: 140 |  Loss: (0.3497) |  Loss2: (0.0000) | Acc: (88.00%) (15909/18048)
Epoch: 61 | Batch_idx: 150 |  Loss: (0.3501) |  Loss2: (0.0000) | Acc: (88.00%) (17040/19328)
Epoch: 61 | Batch_idx: 160 |  Loss: (0.3502) |  Loss2: (0.0000) | Acc: (88.00%) (18167/20608)
Epoch: 61 | Batch_idx: 170 |  Loss: (0.3510) |  Loss2: (0.0000) | Acc: (88.00%) (19297/21888)
Epoch: 61 | Batch_idx: 180 |  Loss: (0.3497) |  Loss2: (0.0000) | Acc: (88.00%) (20426/23168)
Epoch: 61 | Batch_idx: 190 |  Loss: (0.3507) |  Loss2: (0.0000) | Acc: (88.00%) (21526/24448)
Epoch: 61 | Batch_idx: 200 |  Loss: (0.3498) |  Loss2: (0.0000) | Acc: (88.00%) (22662/25728)
Epoch: 61 | Batch_idx: 210 |  Loss: (0.3486) |  Loss2: (0.0000) | Acc: (88.00%) (23780/27008)
Epoch: 61 | Batch_idx: 220 |  Loss: (0.3485) |  Loss2: (0.0000) | Acc: (88.00%) (24900/28288)
Epoch: 61 | Batch_idx: 230 |  Loss: (0.3476) |  Loss2: (0.0000) | Acc: (88.00%) (26033/29568)
Epoch: 61 | Batch_idx: 240 |  Loss: (0.3469) |  Loss2: (0.0000) | Acc: (88.00%) (27174/30848)
Epoch: 61 | Batch_idx: 250 |  Loss: (0.3467) |  Loss2: (0.0000) | Acc: (88.00%) (28312/32128)
Epoch: 61 | Batch_idx: 260 |  Loss: (0.3469) |  Loss2: (0.0000) | Acc: (88.00%) (29440/33408)
Epoch: 61 | Batch_idx: 270 |  Loss: (0.3471) |  Loss2: (0.0000) | Acc: (88.00%) (30554/34688)
Epoch: 61 | Batch_idx: 280 |  Loss: (0.3473) |  Loss2: (0.0000) | Acc: (88.00%) (31673/35968)
Epoch: 61 | Batch_idx: 290 |  Loss: (0.3477) |  Loss2: (0.0000) | Acc: (88.00%) (32805/37248)
Epoch: 61 | Batch_idx: 300 |  Loss: (0.3472) |  Loss2: (0.0000) | Acc: (88.00%) (33939/38528)
Epoch: 61 | Batch_idx: 310 |  Loss: (0.3473) |  Loss2: (0.0000) | Acc: (88.00%) (35056/39808)
Epoch: 61 | Batch_idx: 320 |  Loss: (0.3484) |  Loss2: (0.0000) | Acc: (88.00%) (36161/41088)
Epoch: 61 | Batch_idx: 330 |  Loss: (0.3481) |  Loss2: (0.0000) | Acc: (87.00%) (37283/42368)
Epoch: 61 | Batch_idx: 340 |  Loss: (0.3479) |  Loss2: (0.0000) | Acc: (88.00%) (38414/43648)
Epoch: 61 | Batch_idx: 350 |  Loss: (0.3479) |  Loss2: (0.0000) | Acc: (87.00%) (39536/44928)
Epoch: 61 | Batch_idx: 360 |  Loss: (0.3484) |  Loss2: (0.0000) | Acc: (87.00%) (40662/46208)
Epoch: 61 | Batch_idx: 370 |  Loss: (0.3485) |  Loss2: (0.0000) | Acc: (87.00%) (41789/47488)
Epoch: 61 | Batch_idx: 380 |  Loss: (0.3490) |  Loss2: (0.0000) | Acc: (87.00%) (42886/48768)
Epoch: 61 | Batch_idx: 390 |  Loss: (0.3489) |  Loss2: (0.0000) | Acc: (87.00%) (43977/50000)
# TEST : Loss: (0.5394) | Acc: (82.00%) (8202/10000)
percent tensor([0.5106, 0.5042, 0.5156, 0.5145, 0.5133, 0.5115, 0.5078, 0.5138, 0.5116,
        0.5080, 0.5091, 0.5109, 0.5086, 0.5047, 0.5083, 0.5101],
       device='cuda:0') torch.Size([16])
percent tensor([0.5325, 0.5437, 0.5232, 0.5331, 0.5277, 0.5505, 0.5383, 0.5285, 0.5244,
        0.5310, 0.5313, 0.5240, 0.5293, 0.5443, 0.5453, 0.5383],
       device='cuda:0') torch.Size([16])
percent tensor([0.5246, 0.5460, 0.5428, 0.4675, 0.5279, 0.4575, 0.5488, 0.5265, 0.5088,
        0.5419, 0.5191, 0.5598, 0.5792, 0.4264, 0.5296, 0.4847],
       device='cuda:0') torch.Size([16])
percent tensor([0.6501, 0.6874, 0.6593, 0.6603, 0.6558, 0.6379, 0.6790, 0.6464, 0.6765,
        0.6906, 0.7128, 0.7019, 0.6866, 0.6926, 0.6662, 0.6645],
       device='cuda:0') torch.Size([16])
percent tensor([0.6182, 0.5903, 0.6106, 0.5875, 0.5886, 0.7240, 0.6062, 0.5628, 0.6321,
        0.5924, 0.6190, 0.5698, 0.6260, 0.6545, 0.6141, 0.6475],
       device='cuda:0') torch.Size([16])
percent tensor([0.5279, 0.5954, 0.5803, 0.5608, 0.5691, 0.5225, 0.5612, 0.4908, 0.6274,
        0.5633, 0.6176, 0.6155, 0.5776, 0.6714, 0.4686, 0.5220],
       device='cuda:0') torch.Size([16])
percent tensor([0.5219, 0.5638, 0.7515, 0.7545, 0.7762, 0.6218, 0.6133, 0.6932, 0.6641,
        0.5968, 0.6168, 0.7531, 0.5607, 0.6860, 0.5683, 0.5892],
       device='cuda:0') torch.Size([16])
percent tensor([0.9992, 0.9968, 0.9980, 0.9981, 0.9975, 0.9974, 0.9980, 0.9985, 0.9974,
        0.9983, 0.9986, 0.9983, 0.9974, 0.9984, 0.9978, 0.9990],
       device='cuda:0') torch.Size([16])
Epoch: 62 | Batch_idx: 0 |  Loss: (0.3950) |  Loss2: (0.0000) | Acc: (86.00%) (111/128)
Epoch: 62 | Batch_idx: 10 |  Loss: (0.3187) |  Loss2: (0.0000) | Acc: (88.00%) (1249/1408)
Epoch: 62 | Batch_idx: 20 |  Loss: (0.3198) |  Loss2: (0.0000) | Acc: (88.00%) (2390/2688)
Epoch: 62 | Batch_idx: 30 |  Loss: (0.3294) |  Loss2: (0.0000) | Acc: (88.00%) (3506/3968)
Epoch: 62 | Batch_idx: 40 |  Loss: (0.3340) |  Loss2: (0.0000) | Acc: (88.00%) (4628/5248)
Epoch: 62 | Batch_idx: 50 |  Loss: (0.3354) |  Loss2: (0.0000) | Acc: (88.00%) (5764/6528)
Epoch: 62 | Batch_idx: 60 |  Loss: (0.3371) |  Loss2: (0.0000) | Acc: (88.00%) (6891/7808)
Epoch: 62 | Batch_idx: 70 |  Loss: (0.3406) |  Loss2: (0.0000) | Acc: (88.00%) (8011/9088)
Epoch: 62 | Batch_idx: 80 |  Loss: (0.3418) |  Loss2: (0.0000) | Acc: (88.00%) (9140/10368)
Epoch: 62 | Batch_idx: 90 |  Loss: (0.3382) |  Loss2: (0.0000) | Acc: (88.00%) (10277/11648)
Epoch: 62 | Batch_idx: 100 |  Loss: (0.3369) |  Loss2: (0.0000) | Acc: (88.00%) (11413/12928)
Epoch: 62 | Batch_idx: 110 |  Loss: (0.3359) |  Loss2: (0.0000) | Acc: (88.00%) (12547/14208)
Epoch: 62 | Batch_idx: 120 |  Loss: (0.3338) |  Loss2: (0.0000) | Acc: (88.00%) (13686/15488)
Epoch: 62 | Batch_idx: 130 |  Loss: (0.3338) |  Loss2: (0.0000) | Acc: (88.00%) (14826/16768)
Epoch: 62 | Batch_idx: 140 |  Loss: (0.3344) |  Loss2: (0.0000) | Acc: (88.00%) (15958/18048)
Epoch: 62 | Batch_idx: 150 |  Loss: (0.3353) |  Loss2: (0.0000) | Acc: (88.00%) (17097/19328)
Epoch: 62 | Batch_idx: 160 |  Loss: (0.3333) |  Loss2: (0.0000) | Acc: (88.00%) (18247/20608)
Epoch: 62 | Batch_idx: 170 |  Loss: (0.3321) |  Loss2: (0.0000) | Acc: (88.00%) (19399/21888)
Epoch: 62 | Batch_idx: 180 |  Loss: (0.3331) |  Loss2: (0.0000) | Acc: (88.00%) (20530/23168)
Epoch: 62 | Batch_idx: 190 |  Loss: (0.3335) |  Loss2: (0.0000) | Acc: (88.00%) (21656/24448)
Epoch: 62 | Batch_idx: 200 |  Loss: (0.3344) |  Loss2: (0.0000) | Acc: (88.00%) (22782/25728)
Epoch: 62 | Batch_idx: 210 |  Loss: (0.3341) |  Loss2: (0.0000) | Acc: (88.00%) (23913/27008)
Epoch: 62 | Batch_idx: 220 |  Loss: (0.3340) |  Loss2: (0.0000) | Acc: (88.00%) (25048/28288)
Epoch: 62 | Batch_idx: 230 |  Loss: (0.3347) |  Loss2: (0.0000) | Acc: (88.00%) (26179/29568)
Epoch: 62 | Batch_idx: 240 |  Loss: (0.3353) |  Loss2: (0.0000) | Acc: (88.00%) (27309/30848)
Epoch: 62 | Batch_idx: 250 |  Loss: (0.3358) |  Loss2: (0.0000) | Acc: (88.00%) (28422/32128)
Epoch: 62 | Batch_idx: 260 |  Loss: (0.3345) |  Loss2: (0.0000) | Acc: (88.00%) (29561/33408)
Epoch: 62 | Batch_idx: 270 |  Loss: (0.3355) |  Loss2: (0.0000) | Acc: (88.00%) (30691/34688)
Epoch: 62 | Batch_idx: 280 |  Loss: (0.3352) |  Loss2: (0.0000) | Acc: (88.00%) (31834/35968)
Epoch: 62 | Batch_idx: 290 |  Loss: (0.3343) |  Loss2: (0.0000) | Acc: (88.00%) (32975/37248)
Epoch: 62 | Batch_idx: 300 |  Loss: (0.3341) |  Loss2: (0.0000) | Acc: (88.00%) (34113/38528)
Epoch: 62 | Batch_idx: 310 |  Loss: (0.3346) |  Loss2: (0.0000) | Acc: (88.00%) (35240/39808)
Epoch: 62 | Batch_idx: 320 |  Loss: (0.3349) |  Loss2: (0.0000) | Acc: (88.00%) (36363/41088)
Epoch: 62 | Batch_idx: 330 |  Loss: (0.3351) |  Loss2: (0.0000) | Acc: (88.00%) (37489/42368)
Epoch: 62 | Batch_idx: 340 |  Loss: (0.3351) |  Loss2: (0.0000) | Acc: (88.00%) (38629/43648)
Epoch: 62 | Batch_idx: 350 |  Loss: (0.3347) |  Loss2: (0.0000) | Acc: (88.00%) (39775/44928)
Epoch: 62 | Batch_idx: 360 |  Loss: (0.3336) |  Loss2: (0.0000) | Acc: (88.00%) (40935/46208)
Epoch: 62 | Batch_idx: 370 |  Loss: (0.3334) |  Loss2: (0.0000) | Acc: (88.00%) (42073/47488)
Epoch: 62 | Batch_idx: 380 |  Loss: (0.3341) |  Loss2: (0.0000) | Acc: (88.00%) (43186/48768)
Epoch: 62 | Batch_idx: 390 |  Loss: (0.3346) |  Loss2: (0.0000) | Acc: (88.00%) (44262/50000)
# TEST : Loss: (0.4941) | Acc: (83.00%) (8364/10000)
percent tensor([0.5104, 0.5042, 0.5155, 0.5141, 0.5130, 0.5108, 0.5076, 0.5135, 0.5114,
        0.5078, 0.5090, 0.5105, 0.5085, 0.5047, 0.5080, 0.5098],
       device='cuda:0') torch.Size([16])
percent tensor([0.5335, 0.5440, 0.5251, 0.5343, 0.5289, 0.5513, 0.5384, 0.5288, 0.5253,
        0.5307, 0.5319, 0.5246, 0.5302, 0.5426, 0.5460, 0.5391],
       device='cuda:0') torch.Size([16])
percent tensor([0.5260, 0.5542, 0.5319, 0.4667, 0.5188, 0.4657, 0.5486, 0.5206, 0.5101,
        0.5437, 0.5265, 0.5535, 0.5836, 0.4357, 0.5392, 0.4931],
       device='cuda:0') torch.Size([16])
percent tensor([0.6552, 0.6953, 0.6590, 0.6600, 0.6570, 0.6546, 0.6817, 0.6479, 0.6806,
        0.6934, 0.7191, 0.7009, 0.6960, 0.6937, 0.6764, 0.6704],
       device='cuda:0') torch.Size([16])
percent tensor([0.6153, 0.5893, 0.6184, 0.5885, 0.5998, 0.7096, 0.6099, 0.5708, 0.6389,
        0.6016, 0.6185, 0.5808, 0.6319, 0.6415, 0.6122, 0.6449],
       device='cuda:0') torch.Size([16])
percent tensor([0.5234, 0.6015, 0.5841, 0.5457, 0.5761, 0.5567, 0.5642, 0.4723, 0.6266,
        0.5773, 0.6260, 0.6143, 0.5666, 0.6746, 0.4739, 0.5253],
       device='cuda:0') torch.Size([16])
percent tensor([0.5269, 0.5964, 0.7691, 0.7437, 0.7882, 0.6467, 0.6269, 0.6872, 0.6480,
        0.6137, 0.6387, 0.7573, 0.5614, 0.6889, 0.6019, 0.6167],
       device='cuda:0') torch.Size([16])
percent tensor([0.9992, 0.9965, 0.9980, 0.9976, 0.9978, 0.9974, 0.9973, 0.9982, 0.9970,
        0.9982, 0.9986, 0.9975, 0.9966, 0.9980, 0.9978, 0.9989],
       device='cuda:0') torch.Size([16])
Epoch: 63 | Batch_idx: 0 |  Loss: (0.2585) |  Loss2: (0.0000) | Acc: (92.00%) (119/128)
Epoch: 63 | Batch_idx: 10 |  Loss: (0.3313) |  Loss2: (0.0000) | Acc: (88.00%) (1243/1408)
Epoch: 63 | Batch_idx: 20 |  Loss: (0.3207) |  Loss2: (0.0000) | Acc: (89.00%) (2394/2688)
Epoch: 63 | Batch_idx: 30 |  Loss: (0.3222) |  Loss2: (0.0000) | Acc: (88.00%) (3524/3968)
Epoch: 63 | Batch_idx: 40 |  Loss: (0.3389) |  Loss2: (0.0000) | Acc: (88.00%) (4626/5248)
Epoch: 63 | Batch_idx: 50 |  Loss: (0.3407) |  Loss2: (0.0000) | Acc: (88.00%) (5764/6528)
Epoch: 63 | Batch_idx: 60 |  Loss: (0.3404) |  Loss2: (0.0000) | Acc: (88.00%) (6893/7808)
Epoch: 63 | Batch_idx: 70 |  Loss: (0.3439) |  Loss2: (0.0000) | Acc: (88.00%) (8019/9088)
Epoch: 63 | Batch_idx: 80 |  Loss: (0.3406) |  Loss2: (0.0000) | Acc: (88.00%) (9151/10368)
Epoch: 63 | Batch_idx: 90 |  Loss: (0.3398) |  Loss2: (0.0000) | Acc: (88.00%) (10289/11648)
Epoch: 63 | Batch_idx: 100 |  Loss: (0.3396) |  Loss2: (0.0000) | Acc: (88.00%) (11421/12928)
Epoch: 63 | Batch_idx: 110 |  Loss: (0.3420) |  Loss2: (0.0000) | Acc: (88.00%) (12542/14208)
Epoch: 63 | Batch_idx: 120 |  Loss: (0.3363) |  Loss2: (0.0000) | Acc: (88.00%) (13700/15488)
Epoch: 63 | Batch_idx: 130 |  Loss: (0.3363) |  Loss2: (0.0000) | Acc: (88.00%) (14841/16768)
Epoch: 63 | Batch_idx: 140 |  Loss: (0.3351) |  Loss2: (0.0000) | Acc: (88.00%) (15983/18048)
Epoch: 63 | Batch_idx: 150 |  Loss: (0.3337) |  Loss2: (0.0000) | Acc: (88.00%) (17129/19328)
Epoch: 63 | Batch_idx: 160 |  Loss: (0.3346) |  Loss2: (0.0000) | Acc: (88.00%) (18247/20608)
Epoch: 63 | Batch_idx: 170 |  Loss: (0.3339) |  Loss2: (0.0000) | Acc: (88.00%) (19388/21888)
Epoch: 63 | Batch_idx: 180 |  Loss: (0.3341) |  Loss2: (0.0000) | Acc: (88.00%) (20517/23168)
Epoch: 63 | Batch_idx: 190 |  Loss: (0.3332) |  Loss2: (0.0000) | Acc: (88.00%) (21666/24448)
Epoch: 63 | Batch_idx: 200 |  Loss: (0.3310) |  Loss2: (0.0000) | Acc: (88.00%) (22831/25728)
Epoch: 63 | Batch_idx: 210 |  Loss: (0.3301) |  Loss2: (0.0000) | Acc: (88.00%) (23975/27008)
Epoch: 63 | Batch_idx: 220 |  Loss: (0.3312) |  Loss2: (0.0000) | Acc: (88.00%) (25099/28288)
Epoch: 63 | Batch_idx: 230 |  Loss: (0.3306) |  Loss2: (0.0000) | Acc: (88.00%) (26230/29568)
Epoch: 63 | Batch_idx: 240 |  Loss: (0.3317) |  Loss2: (0.0000) | Acc: (88.00%) (27351/30848)
Epoch: 63 | Batch_idx: 250 |  Loss: (0.3315) |  Loss2: (0.0000) | Acc: (88.00%) (28487/32128)
Epoch: 63 | Batch_idx: 260 |  Loss: (0.3321) |  Loss2: (0.0000) | Acc: (88.00%) (29613/33408)
Epoch: 63 | Batch_idx: 270 |  Loss: (0.3335) |  Loss2: (0.0000) | Acc: (88.00%) (30724/34688)
Epoch: 63 | Batch_idx: 280 |  Loss: (0.3335) |  Loss2: (0.0000) | Acc: (88.00%) (31856/35968)
Epoch: 63 | Batch_idx: 290 |  Loss: (0.3336) |  Loss2: (0.0000) | Acc: (88.00%) (32979/37248)
Epoch: 63 | Batch_idx: 300 |  Loss: (0.3340) |  Loss2: (0.0000) | Acc: (88.00%) (34118/38528)
Epoch: 63 | Batch_idx: 310 |  Loss: (0.3344) |  Loss2: (0.0000) | Acc: (88.00%) (35249/39808)
Epoch: 63 | Batch_idx: 320 |  Loss: (0.3344) |  Loss2: (0.0000) | Acc: (88.00%) (36389/41088)
Epoch: 63 | Batch_idx: 330 |  Loss: (0.3341) |  Loss2: (0.0000) | Acc: (88.00%) (37514/42368)
Epoch: 63 | Batch_idx: 340 |  Loss: (0.3324) |  Loss2: (0.0000) | Acc: (88.00%) (38675/43648)
Epoch: 63 | Batch_idx: 350 |  Loss: (0.3325) |  Loss2: (0.0000) | Acc: (88.00%) (39801/44928)
Epoch: 63 | Batch_idx: 360 |  Loss: (0.3315) |  Loss2: (0.0000) | Acc: (88.00%) (40955/46208)
Epoch: 63 | Batch_idx: 370 |  Loss: (0.3318) |  Loss2: (0.0000) | Acc: (88.00%) (42075/47488)
Epoch: 63 | Batch_idx: 380 |  Loss: (0.3314) |  Loss2: (0.0000) | Acc: (88.00%) (43211/48768)
Epoch: 63 | Batch_idx: 390 |  Loss: (0.3315) |  Loss2: (0.0000) | Acc: (88.00%) (44314/50000)
# TEST : Loss: (0.4207) | Acc: (85.00%) (8547/10000)
percent tensor([0.5105, 0.5043, 0.5157, 0.5144, 0.5131, 0.5109, 0.5079, 0.5139, 0.5116,
        0.5082, 0.5091, 0.5107, 0.5087, 0.5048, 0.5081, 0.5101],
       device='cuda:0') torch.Size([16])
percent tensor([0.5343, 0.5434, 0.5273, 0.5344, 0.5317, 0.5520, 0.5391, 0.5285, 0.5254,
        0.5319, 0.5315, 0.5265, 0.5306, 0.5419, 0.5456, 0.5388],
       device='cuda:0') torch.Size([16])
percent tensor([0.5268, 0.5476, 0.5349, 0.4628, 0.5175, 0.4645, 0.5463, 0.5228, 0.5123,
        0.5376, 0.5223, 0.5510, 0.5810, 0.4296, 0.5359, 0.4891],
       device='cuda:0') torch.Size([16])
percent tensor([0.6592, 0.6979, 0.6525, 0.6579, 0.6503, 0.6544, 0.6830, 0.6474, 0.6856,
        0.6995, 0.7243, 0.6963, 0.6997, 0.7008, 0.6755, 0.6749],
       device='cuda:0') torch.Size([16])
percent tensor([0.6183, 0.6002, 0.6285, 0.5985, 0.6055, 0.7198, 0.6198, 0.5734, 0.6355,
        0.6081, 0.6155, 0.5972, 0.6348, 0.6421, 0.6172, 0.6488],
       device='cuda:0') torch.Size([16])
percent tensor([0.5268, 0.6172, 0.5737, 0.5578, 0.5451, 0.5515, 0.5576, 0.4857, 0.6237,
        0.5853, 0.6256, 0.6242, 0.5756, 0.6838, 0.4832, 0.5284],
       device='cuda:0') torch.Size([16])
percent tensor([0.5251, 0.5986, 0.7563, 0.7317, 0.7791, 0.6372, 0.6109, 0.7008, 0.6513,
        0.6337, 0.6571, 0.7465, 0.5653, 0.6977, 0.5940, 0.5940],
       device='cuda:0') torch.Size([16])
percent tensor([0.9991, 0.9966, 0.9983, 0.9986, 0.9980, 0.9978, 0.9981, 0.9986, 0.9973,
        0.9980, 0.9984, 0.9980, 0.9964, 0.9976, 0.9977, 0.9991],
       device='cuda:0') torch.Size([16])
Epoch: 64 | Batch_idx: 0 |  Loss: (0.3071) |  Loss2: (0.0000) | Acc: (88.00%) (113/128)
Epoch: 64 | Batch_idx: 10 |  Loss: (0.3189) |  Loss2: (0.0000) | Acc: (88.00%) (1244/1408)
Epoch: 64 | Batch_idx: 20 |  Loss: (0.3153) |  Loss2: (0.0000) | Acc: (89.00%) (2397/2688)
Epoch: 64 | Batch_idx: 30 |  Loss: (0.3170) |  Loss2: (0.0000) | Acc: (88.00%) (3527/3968)
Epoch: 64 | Batch_idx: 40 |  Loss: (0.3145) |  Loss2: (0.0000) | Acc: (89.00%) (4671/5248)
Epoch: 64 | Batch_idx: 50 |  Loss: (0.3109) |  Loss2: (0.0000) | Acc: (89.00%) (5825/6528)
Epoch: 64 | Batch_idx: 60 |  Loss: (0.3111) |  Loss2: (0.0000) | Acc: (89.00%) (6983/7808)
Epoch: 64 | Batch_idx: 70 |  Loss: (0.3157) |  Loss2: (0.0000) | Acc: (89.00%) (8105/9088)
Epoch: 64 | Batch_idx: 80 |  Loss: (0.3154) |  Loss2: (0.0000) | Acc: (89.00%) (9266/10368)
Epoch: 64 | Batch_idx: 90 |  Loss: (0.3176) |  Loss2: (0.0000) | Acc: (89.00%) (10403/11648)
Epoch: 64 | Batch_idx: 100 |  Loss: (0.3189) |  Loss2: (0.0000) | Acc: (89.00%) (11544/12928)
Epoch: 64 | Batch_idx: 110 |  Loss: (0.3172) |  Loss2: (0.0000) | Acc: (89.00%) (12690/14208)
Epoch: 64 | Batch_idx: 120 |  Loss: (0.3167) |  Loss2: (0.0000) | Acc: (89.00%) (13837/15488)
Epoch: 64 | Batch_idx: 130 |  Loss: (0.3177) |  Loss2: (0.0000) | Acc: (89.00%) (14966/16768)
Epoch: 64 | Batch_idx: 140 |  Loss: (0.3196) |  Loss2: (0.0000) | Acc: (89.00%) (16094/18048)
Epoch: 64 | Batch_idx: 150 |  Loss: (0.3185) |  Loss2: (0.0000) | Acc: (89.00%) (17246/19328)
Epoch: 64 | Batch_idx: 160 |  Loss: (0.3189) |  Loss2: (0.0000) | Acc: (89.00%) (18377/20608)
Epoch: 64 | Batch_idx: 170 |  Loss: (0.3180) |  Loss2: (0.0000) | Acc: (89.00%) (19526/21888)
Epoch: 64 | Batch_idx: 180 |  Loss: (0.3185) |  Loss2: (0.0000) | Acc: (89.00%) (20651/23168)
Epoch: 64 | Batch_idx: 190 |  Loss: (0.3182) |  Loss2: (0.0000) | Acc: (89.00%) (21791/24448)
Epoch: 64 | Batch_idx: 200 |  Loss: (0.3170) |  Loss2: (0.0000) | Acc: (89.00%) (22954/25728)
Epoch: 64 | Batch_idx: 210 |  Loss: (0.3175) |  Loss2: (0.0000) | Acc: (89.00%) (24083/27008)
Epoch: 64 | Batch_idx: 220 |  Loss: (0.3186) |  Loss2: (0.0000) | Acc: (89.00%) (25219/28288)
Epoch: 64 | Batch_idx: 230 |  Loss: (0.3198) |  Loss2: (0.0000) | Acc: (89.00%) (26352/29568)
Epoch: 64 | Batch_idx: 240 |  Loss: (0.3196) |  Loss2: (0.0000) | Acc: (89.00%) (27482/30848)
Epoch: 64 | Batch_idx: 250 |  Loss: (0.3204) |  Loss2: (0.0000) | Acc: (89.00%) (28616/32128)
Epoch: 64 | Batch_idx: 260 |  Loss: (0.3208) |  Loss2: (0.0000) | Acc: (89.00%) (29746/33408)
Epoch: 64 | Batch_idx: 270 |  Loss: (0.3213) |  Loss2: (0.0000) | Acc: (88.00%) (30870/34688)
Epoch: 64 | Batch_idx: 280 |  Loss: (0.3198) |  Loss2: (0.0000) | Acc: (89.00%) (32031/35968)
Epoch: 64 | Batch_idx: 290 |  Loss: (0.3200) |  Loss2: (0.0000) | Acc: (89.00%) (33160/37248)
Epoch: 64 | Batch_idx: 300 |  Loss: (0.3209) |  Loss2: (0.0000) | Acc: (88.00%) (34284/38528)
Epoch: 64 | Batch_idx: 310 |  Loss: (0.3195) |  Loss2: (0.0000) | Acc: (89.00%) (35442/39808)
Epoch: 64 | Batch_idx: 320 |  Loss: (0.3197) |  Loss2: (0.0000) | Acc: (89.00%) (36585/41088)
Epoch: 64 | Batch_idx: 330 |  Loss: (0.3197) |  Loss2: (0.0000) | Acc: (89.00%) (37733/42368)
Epoch: 64 | Batch_idx: 340 |  Loss: (0.3198) |  Loss2: (0.0000) | Acc: (89.00%) (38881/43648)
Epoch: 64 | Batch_idx: 350 |  Loss: (0.3208) |  Loss2: (0.0000) | Acc: (89.00%) (40013/44928)
Epoch: 64 | Batch_idx: 360 |  Loss: (0.3206) |  Loss2: (0.0000) | Acc: (89.00%) (41160/46208)
Epoch: 64 | Batch_idx: 370 |  Loss: (0.3212) |  Loss2: (0.0000) | Acc: (89.00%) (42287/47488)
Epoch: 64 | Batch_idx: 380 |  Loss: (0.3208) |  Loss2: (0.0000) | Acc: (89.00%) (43426/48768)
Epoch: 64 | Batch_idx: 390 |  Loss: (0.3211) |  Loss2: (0.0000) | Acc: (89.00%) (44514/50000)
# TEST : Loss: (0.4181) | Acc: (85.00%) (8575/10000)
percent tensor([0.5103, 0.5045, 0.5144, 0.5138, 0.5122, 0.5105, 0.5076, 0.5132, 0.5115,
        0.5079, 0.5092, 0.5098, 0.5087, 0.5057, 0.5080, 0.5099],
       device='cuda:0') torch.Size([16])
percent tensor([0.5334, 0.5433, 0.5253, 0.5331, 0.5299, 0.5521, 0.5384, 0.5274, 0.5241,
        0.5306, 0.5307, 0.5254, 0.5285, 0.5428, 0.5454, 0.5385],
       device='cuda:0') torch.Size([16])
percent tensor([0.5266, 0.5551, 0.5171, 0.4686, 0.5080, 0.4654, 0.5502, 0.5202, 0.5171,
        0.5424, 0.5329, 0.5513, 0.5866, 0.4422, 0.5386, 0.4962],
       device='cuda:0') torch.Size([16])
percent tensor([0.6555, 0.6931, 0.6565, 0.6610, 0.6541, 0.6502, 0.6781, 0.6457, 0.6808,
        0.6954, 0.7220, 0.6961, 0.6919, 0.6928, 0.6720, 0.6724],
       device='cuda:0') torch.Size([16])
percent tensor([0.6115, 0.5834, 0.6308, 0.5885, 0.6031, 0.7091, 0.6120, 0.5675, 0.6267,
        0.6002, 0.6121, 0.5901, 0.6229, 0.6419, 0.6054, 0.6396],
       device='cuda:0') torch.Size([16])
percent tensor([0.5081, 0.5904, 0.5672, 0.5393, 0.5501, 0.5345, 0.5494, 0.4646, 0.6196,
        0.5533, 0.6167, 0.6073, 0.5607, 0.6674, 0.4567, 0.5060],
       device='cuda:0') torch.Size([16])
percent tensor([0.5536, 0.6214, 0.7656, 0.7391, 0.7953, 0.6621, 0.6327, 0.6995, 0.6381,
        0.6247, 0.6543, 0.7350, 0.5687, 0.6878, 0.6092, 0.6117],
       device='cuda:0') torch.Size([16])
percent tensor([0.9990, 0.9964, 0.9985, 0.9981, 0.9986, 0.9973, 0.9978, 0.9987, 0.9969,
        0.9973, 0.9980, 0.9975, 0.9966, 0.9975, 0.9974, 0.9989],
       device='cuda:0') torch.Size([16])
False Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=128, out_features=16, bias=False)
True Linear(in_features=16, out_features=2, bias=False)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=128, out_features=16, bias=False)
True Linear(in_features=16, out_features=2, bias=False)
False Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=256, out_features=32, bias=False)
True Linear(in_features=32, out_features=2, bias=False)
False Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=256, out_features=32, bias=False)
True Linear(in_features=32, out_features=2, bias=False)
False Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=512, out_features=64, bias=False)
True Linear(in_features=64, out_features=2, bias=False)
False Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=512, out_features=64, bias=False)
True Linear(in_features=64, out_features=2, bias=False)
False Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1024, out_features=128, bias=False)
True Linear(in_features=128, out_features=2, bias=False)
False Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1024, out_features=128, bias=False)
True Linear(in_features=128, out_features=2, bias=False)
False Linear(in_features=512, out_features=10, bias=True)
Epoch: 65 | Batch_idx: 0 |  Loss: (0.2887) |  Loss2: (0.0000) | Acc: (89.00%) (115/128)
Epoch: 65 | Batch_idx: 10 |  Loss: (0.3168) |  Loss2: (0.0000) | Acc: (88.00%) (1248/1408)
Epoch: 65 | Batch_idx: 20 |  Loss: (0.3225) |  Loss2: (0.0000) | Acc: (88.00%) (2384/2688)
Epoch: 65 | Batch_idx: 30 |  Loss: (0.3471) |  Loss2: (0.0000) | Acc: (87.00%) (3488/3968)
Epoch: 65 | Batch_idx: 40 |  Loss: (0.3565) |  Loss2: (0.0000) | Acc: (87.00%) (4596/5248)
Epoch: 65 | Batch_idx: 50 |  Loss: (0.3527) |  Loss2: (0.0000) | Acc: (87.00%) (5730/6528)
Epoch: 65 | Batch_idx: 60 |  Loss: (0.3595) |  Loss2: (0.0000) | Acc: (87.00%) (6836/7808)
Epoch: 65 | Batch_idx: 70 |  Loss: (0.3614) |  Loss2: (0.0000) | Acc: (87.00%) (7946/9088)
Epoch: 65 | Batch_idx: 80 |  Loss: (0.3640) |  Loss2: (0.0000) | Acc: (87.00%) (9057/10368)
Epoch: 65 | Batch_idx: 90 |  Loss: (0.3629) |  Loss2: (0.0000) | Acc: (87.00%) (10179/11648)
Epoch: 65 | Batch_idx: 100 |  Loss: (0.3661) |  Loss2: (0.0000) | Acc: (87.00%) (11298/12928)
Epoch: 65 | Batch_idx: 110 |  Loss: (0.3654) |  Loss2: (0.0000) | Acc: (87.00%) (12420/14208)
Epoch: 65 | Batch_idx: 120 |  Loss: (0.3645) |  Loss2: (0.0000) | Acc: (87.00%) (13547/15488)
Epoch: 65 | Batch_idx: 130 |  Loss: (0.3676) |  Loss2: (0.0000) | Acc: (87.00%) (14647/16768)
Epoch: 65 | Batch_idx: 140 |  Loss: (0.3656) |  Loss2: (0.0000) | Acc: (87.00%) (15770/18048)
Epoch: 65 | Batch_idx: 150 |  Loss: (0.3642) |  Loss2: (0.0000) | Acc: (87.00%) (16891/19328)
Epoch: 65 | Batch_idx: 160 |  Loss: (0.3623) |  Loss2: (0.0000) | Acc: (87.00%) (18017/20608)
Epoch: 65 | Batch_idx: 170 |  Loss: (0.3587) |  Loss2: (0.0000) | Acc: (87.00%) (19178/21888)
Epoch: 65 | Batch_idx: 180 |  Loss: (0.3576) |  Loss2: (0.0000) | Acc: (87.00%) (20302/23168)
Epoch: 65 | Batch_idx: 190 |  Loss: (0.3584) |  Loss2: (0.0000) | Acc: (87.00%) (21415/24448)
Epoch: 65 | Batch_idx: 200 |  Loss: (0.3570) |  Loss2: (0.0000) | Acc: (87.00%) (22547/25728)
Epoch: 65 | Batch_idx: 210 |  Loss: (0.3566) |  Loss2: (0.0000) | Acc: (87.00%) (23673/27008)
Epoch: 65 | Batch_idx: 220 |  Loss: (0.3556) |  Loss2: (0.0000) | Acc: (87.00%) (24802/28288)
Epoch: 65 | Batch_idx: 230 |  Loss: (0.3547) |  Loss2: (0.0000) | Acc: (87.00%) (25936/29568)
Epoch: 65 | Batch_idx: 240 |  Loss: (0.3535) |  Loss2: (0.0000) | Acc: (87.00%) (27078/30848)
Epoch: 65 | Batch_idx: 250 |  Loss: (0.3530) |  Loss2: (0.0000) | Acc: (87.00%) (28205/32128)
Epoch: 65 | Batch_idx: 260 |  Loss: (0.3526) |  Loss2: (0.0000) | Acc: (87.00%) (29326/33408)
Epoch: 65 | Batch_idx: 270 |  Loss: (0.3511) |  Loss2: (0.0000) | Acc: (87.00%) (30466/34688)
Epoch: 65 | Batch_idx: 280 |  Loss: (0.3505) |  Loss2: (0.0000) | Acc: (87.00%) (31594/35968)
Epoch: 65 | Batch_idx: 290 |  Loss: (0.3501) |  Loss2: (0.0000) | Acc: (87.00%) (32721/37248)
Epoch: 65 | Batch_idx: 300 |  Loss: (0.3500) |  Loss2: (0.0000) | Acc: (87.00%) (33846/38528)
Epoch: 65 | Batch_idx: 310 |  Loss: (0.3495) |  Loss2: (0.0000) | Acc: (87.00%) (34971/39808)
Epoch: 65 | Batch_idx: 320 |  Loss: (0.3485) |  Loss2: (0.0000) | Acc: (87.00%) (36112/41088)
Epoch: 65 | Batch_idx: 330 |  Loss: (0.3484) |  Loss2: (0.0000) | Acc: (87.00%) (37238/42368)
Epoch: 65 | Batch_idx: 340 |  Loss: (0.3485) |  Loss2: (0.0000) | Acc: (87.00%) (38352/43648)
Epoch: 65 | Batch_idx: 350 |  Loss: (0.3490) |  Loss2: (0.0000) | Acc: (87.00%) (39479/44928)
Epoch: 65 | Batch_idx: 360 |  Loss: (0.3486) |  Loss2: (0.0000) | Acc: (87.00%) (40614/46208)
Epoch: 65 | Batch_idx: 370 |  Loss: (0.3477) |  Loss2: (0.0000) | Acc: (87.00%) (41746/47488)
Epoch: 65 | Batch_idx: 380 |  Loss: (0.3464) |  Loss2: (0.0000) | Acc: (87.00%) (42898/48768)
Epoch: 65 | Batch_idx: 390 |  Loss: (0.3463) |  Loss2: (0.0000) | Acc: (87.00%) (43995/50000)
=> saving checkpoint 'drive/app/torch/save_Routing_Gate_2/checkpoint_065.pth.tar'
# TEST : Loss: (0.4367) | Acc: (85.00%) (8530/10000)
percent tensor([0.5236, 0.5159, 0.5274, 0.5264, 0.5265, 0.5254, 0.5206, 0.5259, 0.5253,
        0.5201, 0.5222, 0.5222, 0.5211, 0.5161, 0.5211, 0.5227],
       device='cuda:0') torch.Size([16])
percent tensor([0.5397, 0.5488, 0.5358, 0.5416, 0.5396, 0.5564, 0.5455, 0.5369, 0.5327,
        0.5382, 0.5368, 0.5351, 0.5355, 0.5480, 0.5509, 0.5441],
       device='cuda:0') torch.Size([16])
percent tensor([0.5504, 0.5819, 0.5365, 0.4746, 0.5248, 0.4774, 0.5762, 0.5270, 0.5353,
        0.5647, 0.5605, 0.5766, 0.6183, 0.4727, 0.5569, 0.5127],
       device='cuda:0') torch.Size([16])
percent tensor([0.6519, 0.6811, 0.6544, 0.6561, 0.6535, 0.6468, 0.6715, 0.6447, 0.6760,
        0.6852, 0.7132, 0.6930, 0.6846, 0.6822, 0.6658, 0.6656],
       device='cuda:0') torch.Size([16])
percent tensor([0.6276, 0.5909, 0.6770, 0.6176, 0.6461, 0.7468, 0.6316, 0.6067, 0.6360,
        0.6103, 0.6068, 0.6257, 0.6313, 0.6399, 0.6380, 0.6561],
       device='cuda:0') torch.Size([16])
percent tensor([0.5021, 0.5901, 0.5406, 0.5021, 0.5097, 0.5234, 0.5299, 0.4162, 0.6160,
        0.5498, 0.6233, 0.5869, 0.5682, 0.6659, 0.4417, 0.4970],
       device='cuda:0') torch.Size([16])
percent tensor([0.5619, 0.6185, 0.7739, 0.7551, 0.8064, 0.6637, 0.6415, 0.7371, 0.6249,
        0.6301, 0.6429, 0.7383, 0.5435, 0.6624, 0.6223, 0.6294],
       device='cuda:0') torch.Size([16])
percent tensor([0.9990, 0.9958, 0.9986, 0.9984, 0.9984, 0.9970, 0.9977, 0.9988, 0.9973,
        0.9972, 0.9979, 0.9970, 0.9970, 0.9969, 0.9976, 0.9990],
       device='cuda:0') torch.Size([16])
Epoch: 66 | Batch_idx: 0 |  Loss: (0.4251) |  Loss2: (0.0000) | Acc: (83.00%) (107/128)
Epoch: 66 | Batch_idx: 10 |  Loss: (0.3401) |  Loss2: (0.0000) | Acc: (87.00%) (1239/1408)
Epoch: 66 | Batch_idx: 20 |  Loss: (0.3535) |  Loss2: (0.0000) | Acc: (87.00%) (2349/2688)
Epoch: 66 | Batch_idx: 30 |  Loss: (0.3329) |  Loss2: (0.0000) | Acc: (88.00%) (3508/3968)
Epoch: 66 | Batch_idx: 40 |  Loss: (0.3328) |  Loss2: (0.0000) | Acc: (88.00%) (4640/5248)
Epoch: 66 | Batch_idx: 50 |  Loss: (0.3271) |  Loss2: (0.0000) | Acc: (88.00%) (5786/6528)
Epoch: 66 | Batch_idx: 60 |  Loss: (0.3338) |  Loss2: (0.0000) | Acc: (88.00%) (6890/7808)
Epoch: 66 | Batch_idx: 70 |  Loss: (0.3322) |  Loss2: (0.0000) | Acc: (88.00%) (8031/9088)
Epoch: 66 | Batch_idx: 80 |  Loss: (0.3334) |  Loss2: (0.0000) | Acc: (88.00%) (9155/10368)
Epoch: 66 | Batch_idx: 90 |  Loss: (0.3326) |  Loss2: (0.0000) | Acc: (88.00%) (10294/11648)
Epoch: 66 | Batch_idx: 100 |  Loss: (0.3324) |  Loss2: (0.0000) | Acc: (88.00%) (11437/12928)
Epoch: 66 | Batch_idx: 110 |  Loss: (0.3332) |  Loss2: (0.0000) | Acc: (88.00%) (12560/14208)
Epoch: 66 | Batch_idx: 120 |  Loss: (0.3301) |  Loss2: (0.0000) | Acc: (88.00%) (13714/15488)
Epoch: 66 | Batch_idx: 130 |  Loss: (0.3291) |  Loss2: (0.0000) | Acc: (88.00%) (14869/16768)
Epoch: 66 | Batch_idx: 140 |  Loss: (0.3311) |  Loss2: (0.0000) | Acc: (88.00%) (15991/18048)
Epoch: 66 | Batch_idx: 150 |  Loss: (0.3299) |  Loss2: (0.0000) | Acc: (88.00%) (17139/19328)
Epoch: 66 | Batch_idx: 160 |  Loss: (0.3292) |  Loss2: (0.0000) | Acc: (88.00%) (18274/20608)
Epoch: 66 | Batch_idx: 170 |  Loss: (0.3275) |  Loss2: (0.0000) | Acc: (88.00%) (19431/21888)
Epoch: 66 | Batch_idx: 180 |  Loss: (0.3274) |  Loss2: (0.0000) | Acc: (88.00%) (20572/23168)
Epoch: 66 | Batch_idx: 190 |  Loss: (0.3284) |  Loss2: (0.0000) | Acc: (88.00%) (21689/24448)
Epoch: 66 | Batch_idx: 200 |  Loss: (0.3259) |  Loss2: (0.0000) | Acc: (88.00%) (22854/25728)
Epoch: 66 | Batch_idx: 210 |  Loss: (0.3251) |  Loss2: (0.0000) | Acc: (88.00%) (23993/27008)
Epoch: 66 | Batch_idx: 220 |  Loss: (0.3243) |  Loss2: (0.0000) | Acc: (88.00%) (25138/28288)
Epoch: 66 | Batch_idx: 230 |  Loss: (0.3245) |  Loss2: (0.0000) | Acc: (88.00%) (26275/29568)
Epoch: 66 | Batch_idx: 240 |  Loss: (0.3238) |  Loss2: (0.0000) | Acc: (88.00%) (27417/30848)
Epoch: 66 | Batch_idx: 250 |  Loss: (0.3229) |  Loss2: (0.0000) | Acc: (88.00%) (28558/32128)
Epoch: 66 | Batch_idx: 260 |  Loss: (0.3233) |  Loss2: (0.0000) | Acc: (88.00%) (29691/33408)
Epoch: 66 | Batch_idx: 270 |  Loss: (0.3219) |  Loss2: (0.0000) | Acc: (88.00%) (30835/34688)
Epoch: 66 | Batch_idx: 280 |  Loss: (0.3229) |  Loss2: (0.0000) | Acc: (88.00%) (31955/35968)
Epoch: 66 | Batch_idx: 290 |  Loss: (0.3229) |  Loss2: (0.0000) | Acc: (88.00%) (33094/37248)
Epoch: 66 | Batch_idx: 300 |  Loss: (0.3233) |  Loss2: (0.0000) | Acc: (88.00%) (34228/38528)
Epoch: 66 | Batch_idx: 310 |  Loss: (0.3239) |  Loss2: (0.0000) | Acc: (88.00%) (35347/39808)
Epoch: 66 | Batch_idx: 320 |  Loss: (0.3258) |  Loss2: (0.0000) | Acc: (88.00%) (36464/41088)
Epoch: 66 | Batch_idx: 330 |  Loss: (0.3260) |  Loss2: (0.0000) | Acc: (88.00%) (37586/42368)
Epoch: 66 | Batch_idx: 340 |  Loss: (0.3257) |  Loss2: (0.0000) | Acc: (88.00%) (38731/43648)
Epoch: 66 | Batch_idx: 350 |  Loss: (0.3249) |  Loss2: (0.0000) | Acc: (88.00%) (39885/44928)
Epoch: 66 | Batch_idx: 360 |  Loss: (0.3250) |  Loss2: (0.0000) | Acc: (88.00%) (41015/46208)
Epoch: 66 | Batch_idx: 370 |  Loss: (0.3244) |  Loss2: (0.0000) | Acc: (88.00%) (42160/47488)
Epoch: 66 | Batch_idx: 380 |  Loss: (0.3241) |  Loss2: (0.0000) | Acc: (88.00%) (43299/48768)
Epoch: 66 | Batch_idx: 390 |  Loss: (0.3234) |  Loss2: (0.0000) | Acc: (88.00%) (44395/50000)
# TEST : Loss: (0.4208) | Acc: (85.00%) (8593/10000)
percent tensor([0.5302, 0.5214, 0.5338, 0.5328, 0.5333, 0.5327, 0.5269, 0.5321, 0.5320,
        0.5258, 0.5285, 0.5282, 0.5271, 0.5217, 0.5274, 0.5290],
       device='cuda:0') torch.Size([16])
percent tensor([0.5418, 0.5505, 0.5392, 0.5443, 0.5429, 0.5578, 0.5478, 0.5399, 0.5357,
        0.5406, 0.5390, 0.5384, 0.5380, 0.5497, 0.5526, 0.5459],
       device='cuda:0') torch.Size([16])
percent tensor([0.5520, 0.5866, 0.5320, 0.4687, 0.5208, 0.4727, 0.5793, 0.5256, 0.5368,
        0.5670, 0.5634, 0.5746, 0.6223, 0.4738, 0.5574, 0.5127],
       device='cuda:0') torch.Size([16])
percent tensor([0.6460, 0.6758, 0.6504, 0.6521, 0.6494, 0.6431, 0.6668, 0.6403, 0.6710,
        0.6809, 0.7076, 0.6893, 0.6791, 0.6786, 0.6607, 0.6607],
       device='cuda:0') torch.Size([16])
percent tensor([0.6270, 0.5902, 0.6799, 0.6216, 0.6481, 0.7512, 0.6306, 0.6075, 0.6385,
        0.6091, 0.6035, 0.6291, 0.6363, 0.6373, 0.6405, 0.6559],
       device='cuda:0') torch.Size([16])
percent tensor([0.4973, 0.5927, 0.5265, 0.4919, 0.4920, 0.5148, 0.5206, 0.3966, 0.6149,
        0.5478, 0.6291, 0.5864, 0.5745, 0.6682, 0.4358, 0.4896],
       device='cuda:0') torch.Size([16])
percent tensor([0.5612, 0.6207, 0.7826, 0.7669, 0.8174, 0.6598, 0.6473, 0.7598, 0.6255,
        0.6314, 0.6346, 0.7525, 0.5353, 0.6515, 0.6356, 0.6352],
       device='cuda:0') torch.Size([16])
percent tensor([0.9991, 0.9960, 0.9986, 0.9986, 0.9982, 0.9972, 0.9979, 0.9989, 0.9974,
        0.9974, 0.9981, 0.9973, 0.9971, 0.9972, 0.9977, 0.9990],
       device='cuda:0') torch.Size([16])
Epoch: 67 | Batch_idx: 0 |  Loss: (0.4313) |  Loss2: (0.0000) | Acc: (85.00%) (109/128)
Epoch: 67 | Batch_idx: 10 |  Loss: (0.3233) |  Loss2: (0.0000) | Acc: (89.00%) (1255/1408)
Epoch: 67 | Batch_idx: 20 |  Loss: (0.3220) |  Loss2: (0.0000) | Acc: (89.00%) (2398/2688)
Epoch: 67 | Batch_idx: 30 |  Loss: (0.3081) |  Loss2: (0.0000) | Acc: (89.00%) (3555/3968)
Epoch: 67 | Batch_idx: 40 |  Loss: (0.3077) |  Loss2: (0.0000) | Acc: (89.00%) (4696/5248)
Epoch: 67 | Batch_idx: 50 |  Loss: (0.3094) |  Loss2: (0.0000) | Acc: (89.00%) (5833/6528)
Epoch: 67 | Batch_idx: 60 |  Loss: (0.3100) |  Loss2: (0.0000) | Acc: (89.00%) (6977/7808)
Epoch: 67 | Batch_idx: 70 |  Loss: (0.3115) |  Loss2: (0.0000) | Acc: (89.00%) (8120/9088)
Epoch: 67 | Batch_idx: 80 |  Loss: (0.3112) |  Loss2: (0.0000) | Acc: (89.00%) (9263/10368)
Epoch: 67 | Batch_idx: 90 |  Loss: (0.3130) |  Loss2: (0.0000) | Acc: (89.00%) (10398/11648)
Epoch: 67 | Batch_idx: 100 |  Loss: (0.3117) |  Loss2: (0.0000) | Acc: (89.00%) (11551/12928)
Epoch: 67 | Batch_idx: 110 |  Loss: (0.3107) |  Loss2: (0.0000) | Acc: (89.00%) (12694/14208)
Epoch: 67 | Batch_idx: 120 |  Loss: (0.3116) |  Loss2: (0.0000) | Acc: (89.00%) (13823/15488)
Epoch: 67 | Batch_idx: 130 |  Loss: (0.3091) |  Loss2: (0.0000) | Acc: (89.00%) (14981/16768)
Epoch: 67 | Batch_idx: 140 |  Loss: (0.3091) |  Loss2: (0.0000) | Acc: (89.00%) (16123/18048)
Epoch: 67 | Batch_idx: 150 |  Loss: (0.3094) |  Loss2: (0.0000) | Acc: (89.00%) (17264/19328)
Epoch: 67 | Batch_idx: 160 |  Loss: (0.3091) |  Loss2: (0.0000) | Acc: (89.00%) (18405/20608)
Epoch: 67 | Batch_idx: 170 |  Loss: (0.3094) |  Loss2: (0.0000) | Acc: (89.00%) (19561/21888)
Epoch: 67 | Batch_idx: 180 |  Loss: (0.3097) |  Loss2: (0.0000) | Acc: (89.00%) (20702/23168)
Epoch: 67 | Batch_idx: 190 |  Loss: (0.3106) |  Loss2: (0.0000) | Acc: (89.00%) (21845/24448)
Epoch: 67 | Batch_idx: 200 |  Loss: (0.3108) |  Loss2: (0.0000) | Acc: (89.00%) (22984/25728)
Epoch: 67 | Batch_idx: 210 |  Loss: (0.3102) |  Loss2: (0.0000) | Acc: (89.00%) (24138/27008)
Epoch: 67 | Batch_idx: 220 |  Loss: (0.3106) |  Loss2: (0.0000) | Acc: (89.00%) (25265/28288)
Epoch: 67 | Batch_idx: 230 |  Loss: (0.3113) |  Loss2: (0.0000) | Acc: (89.00%) (26396/29568)
Epoch: 67 | Batch_idx: 240 |  Loss: (0.3113) |  Loss2: (0.0000) | Acc: (89.00%) (27527/30848)
Epoch: 67 | Batch_idx: 250 |  Loss: (0.3112) |  Loss2: (0.0000) | Acc: (89.00%) (28658/32128)
Epoch: 67 | Batch_idx: 260 |  Loss: (0.3124) |  Loss2: (0.0000) | Acc: (89.00%) (29775/33408)
Epoch: 67 | Batch_idx: 270 |  Loss: (0.3121) |  Loss2: (0.0000) | Acc: (89.00%) (30927/34688)
Epoch: 67 | Batch_idx: 280 |  Loss: (0.3120) |  Loss2: (0.0000) | Acc: (89.00%) (32074/35968)
Epoch: 67 | Batch_idx: 290 |  Loss: (0.3130) |  Loss2: (0.0000) | Acc: (89.00%) (33203/37248)
Epoch: 67 | Batch_idx: 300 |  Loss: (0.3118) |  Loss2: (0.0000) | Acc: (89.00%) (34364/38528)
Epoch: 67 | Batch_idx: 310 |  Loss: (0.3124) |  Loss2: (0.0000) | Acc: (89.00%) (35494/39808)
Epoch: 67 | Batch_idx: 320 |  Loss: (0.3131) |  Loss2: (0.0000) | Acc: (89.00%) (36622/41088)
Epoch: 67 | Batch_idx: 330 |  Loss: (0.3133) |  Loss2: (0.0000) | Acc: (89.00%) (37754/42368)
Epoch: 67 | Batch_idx: 340 |  Loss: (0.3131) |  Loss2: (0.0000) | Acc: (89.00%) (38904/43648)
Epoch: 67 | Batch_idx: 350 |  Loss: (0.3138) |  Loss2: (0.0000) | Acc: (89.00%) (40032/44928)
Epoch: 67 | Batch_idx: 360 |  Loss: (0.3144) |  Loss2: (0.0000) | Acc: (89.00%) (41159/46208)
Epoch: 67 | Batch_idx: 370 |  Loss: (0.3145) |  Loss2: (0.0000) | Acc: (89.00%) (42307/47488)
Epoch: 67 | Batch_idx: 380 |  Loss: (0.3143) |  Loss2: (0.0000) | Acc: (89.00%) (43449/48768)
Epoch: 67 | Batch_idx: 390 |  Loss: (0.3134) |  Loss2: (0.0000) | Acc: (89.00%) (44568/50000)
# TEST : Loss: (0.4107) | Acc: (86.00%) (8602/10000)
percent tensor([0.5297, 0.5197, 0.5332, 0.5326, 0.5326, 0.5325, 0.5255, 0.5311, 0.5315,
        0.5245, 0.5277, 0.5272, 0.5263, 0.5206, 0.5264, 0.5283],
       device='cuda:0') torch.Size([16])
percent tensor([0.5424, 0.5511, 0.5405, 0.5453, 0.5443, 0.5581, 0.5484, 0.5411, 0.5371,
        0.5414, 0.5397, 0.5397, 0.5390, 0.5503, 0.5531, 0.5464],
       device='cuda:0') torch.Size([16])
percent tensor([0.5557, 0.5898, 0.5381, 0.4707, 0.5266, 0.4718, 0.5849, 0.5312, 0.5417,
        0.5719, 0.5666, 0.5817, 0.6282, 0.4731, 0.5591, 0.5147],
       device='cuda:0') torch.Size([16])
percent tensor([0.6447, 0.6755, 0.6494, 0.6512, 0.6480, 0.6430, 0.6663, 0.6388, 0.6707,
        0.6815, 0.7079, 0.6890, 0.6787, 0.6799, 0.6600, 0.6599],
       device='cuda:0') torch.Size([16])
percent tensor([0.6199, 0.5837, 0.6767, 0.6174, 0.6437, 0.7492, 0.6238, 0.6008, 0.6346,
        0.6032, 0.5981, 0.6269, 0.6330, 0.6328, 0.6360, 0.6488],
       device='cuda:0') torch.Size([16])
percent tensor([0.5054, 0.6033, 0.5268, 0.4958, 0.4943, 0.5176, 0.5266, 0.4013, 0.6190,
        0.5553, 0.6364, 0.5919, 0.5833, 0.6742, 0.4437, 0.4963],
       device='cuda:0') torch.Size([16])
percent tensor([0.5587, 0.6215, 0.7855, 0.7705, 0.8238, 0.6522, 0.6516, 0.7720, 0.6261,
        0.6351, 0.6271, 0.7618, 0.5306, 0.6438, 0.6387, 0.6410],
       device='cuda:0') torch.Size([16])
percent tensor([0.9991, 0.9964, 0.9986, 0.9986, 0.9984, 0.9972, 0.9980, 0.9989, 0.9974,
        0.9975, 0.9982, 0.9975, 0.9971, 0.9974, 0.9978, 0.9990],
       device='cuda:0') torch.Size([16])
Epoch: 68 | Batch_idx: 0 |  Loss: (0.3919) |  Loss2: (0.0000) | Acc: (85.00%) (109/128)
Epoch: 68 | Batch_idx: 10 |  Loss: (0.2957) |  Loss2: (0.0000) | Acc: (89.00%) (1263/1408)
Epoch: 68 | Batch_idx: 20 |  Loss: (0.3166) |  Loss2: (0.0000) | Acc: (88.00%) (2389/2688)
Epoch: 68 | Batch_idx: 30 |  Loss: (0.3162) |  Loss2: (0.0000) | Acc: (88.00%) (3531/3968)
Epoch: 68 | Batch_idx: 40 |  Loss: (0.3143) |  Loss2: (0.0000) | Acc: (88.00%) (4663/5248)
Epoch: 68 | Batch_idx: 50 |  Loss: (0.3066) |  Loss2: (0.0000) | Acc: (89.00%) (5832/6528)
Epoch: 68 | Batch_idx: 60 |  Loss: (0.3048) |  Loss2: (0.0000) | Acc: (89.00%) (6983/7808)
Epoch: 68 | Batch_idx: 70 |  Loss: (0.3042) |  Loss2: (0.0000) | Acc: (89.00%) (8121/9088)
Epoch: 68 | Batch_idx: 80 |  Loss: (0.3038) |  Loss2: (0.0000) | Acc: (89.00%) (9259/10368)
Epoch: 68 | Batch_idx: 90 |  Loss: (0.3025) |  Loss2: (0.0000) | Acc: (89.00%) (10404/11648)
Epoch: 68 | Batch_idx: 100 |  Loss: (0.3019) |  Loss2: (0.0000) | Acc: (89.00%) (11551/12928)
Epoch: 68 | Batch_idx: 110 |  Loss: (0.3033) |  Loss2: (0.0000) | Acc: (89.00%) (12692/14208)
Epoch: 68 | Batch_idx: 120 |  Loss: (0.3081) |  Loss2: (0.0000) | Acc: (89.00%) (13808/15488)
Epoch: 68 | Batch_idx: 130 |  Loss: (0.3083) |  Loss2: (0.0000) | Acc: (89.00%) (14945/16768)
Epoch: 68 | Batch_idx: 140 |  Loss: (0.3101) |  Loss2: (0.0000) | Acc: (89.00%) (16073/18048)
Epoch: 68 | Batch_idx: 150 |  Loss: (0.3074) |  Loss2: (0.0000) | Acc: (89.00%) (17243/19328)
Epoch: 68 | Batch_idx: 160 |  Loss: (0.3085) |  Loss2: (0.0000) | Acc: (89.00%) (18360/20608)
Epoch: 68 | Batch_idx: 170 |  Loss: (0.3077) |  Loss2: (0.0000) | Acc: (89.00%) (19504/21888)
Epoch: 68 | Batch_idx: 180 |  Loss: (0.3077) |  Loss2: (0.0000) | Acc: (89.00%) (20651/23168)
Epoch: 68 | Batch_idx: 190 |  Loss: (0.3087) |  Loss2: (0.0000) | Acc: (89.00%) (21781/24448)
Epoch: 68 | Batch_idx: 200 |  Loss: (0.3104) |  Loss2: (0.0000) | Acc: (89.00%) (22901/25728)
Epoch: 68 | Batch_idx: 210 |  Loss: (0.3087) |  Loss2: (0.0000) | Acc: (89.00%) (24063/27008)
Epoch: 68 | Batch_idx: 220 |  Loss: (0.3090) |  Loss2: (0.0000) | Acc: (89.00%) (25194/28288)
Epoch: 68 | Batch_idx: 230 |  Loss: (0.3087) |  Loss2: (0.0000) | Acc: (89.00%) (26344/29568)
Epoch: 68 | Batch_idx: 240 |  Loss: (0.3081) |  Loss2: (0.0000) | Acc: (89.00%) (27494/30848)
Epoch: 68 | Batch_idx: 250 |  Loss: (0.3072) |  Loss2: (0.0000) | Acc: (89.00%) (28648/32128)
Epoch: 68 | Batch_idx: 260 |  Loss: (0.3076) |  Loss2: (0.0000) | Acc: (89.00%) (29782/33408)
Epoch: 68 | Batch_idx: 270 |  Loss: (0.3071) |  Loss2: (0.0000) | Acc: (89.00%) (30937/34688)
Epoch: 68 | Batch_idx: 280 |  Loss: (0.3056) |  Loss2: (0.0000) | Acc: (89.00%) (32112/35968)
Epoch: 68 | Batch_idx: 290 |  Loss: (0.3044) |  Loss2: (0.0000) | Acc: (89.00%) (33276/37248)
Epoch: 68 | Batch_idx: 300 |  Loss: (0.3052) |  Loss2: (0.0000) | Acc: (89.00%) (34414/38528)
Epoch: 68 | Batch_idx: 310 |  Loss: (0.3064) |  Loss2: (0.0000) | Acc: (89.00%) (35555/39808)
Epoch: 68 | Batch_idx: 320 |  Loss: (0.3059) |  Loss2: (0.0000) | Acc: (89.00%) (36724/41088)
Epoch: 68 | Batch_idx: 330 |  Loss: (0.3061) |  Loss2: (0.0000) | Acc: (89.00%) (37864/42368)
Epoch: 68 | Batch_idx: 340 |  Loss: (0.3070) |  Loss2: (0.0000) | Acc: (89.00%) (38991/43648)
Epoch: 68 | Batch_idx: 350 |  Loss: (0.3068) |  Loss2: (0.0000) | Acc: (89.00%) (40138/44928)
Epoch: 68 | Batch_idx: 360 |  Loss: (0.3060) |  Loss2: (0.0000) | Acc: (89.00%) (41298/46208)
Epoch: 68 | Batch_idx: 370 |  Loss: (0.3056) |  Loss2: (0.0000) | Acc: (89.00%) (42455/47488)
Epoch: 68 | Batch_idx: 380 |  Loss: (0.3055) |  Loss2: (0.0000) | Acc: (89.00%) (43603/48768)
Epoch: 68 | Batch_idx: 390 |  Loss: (0.3056) |  Loss2: (0.0000) | Acc: (89.00%) (44703/50000)
# TEST : Loss: (0.4068) | Acc: (86.00%) (8621/10000)
percent tensor([0.5316, 0.5207, 0.5350, 0.5345, 0.5345, 0.5349, 0.5269, 0.5326, 0.5334,
        0.5258, 0.5293, 0.5287, 0.5278, 0.5219, 0.5279, 0.5301],
       device='cuda:0') torch.Size([16])
percent tensor([0.5425, 0.5510, 0.5414, 0.5457, 0.5451, 0.5578, 0.5485, 0.5417, 0.5378,
        0.5417, 0.5399, 0.5405, 0.5395, 0.5499, 0.5530, 0.5464],
       device='cuda:0') torch.Size([16])
percent tensor([0.5527, 0.5842, 0.5399, 0.4719, 0.5277, 0.4708, 0.5825, 0.5337, 0.5407,
        0.5684, 0.5606, 0.5807, 0.6228, 0.4721, 0.5548, 0.5117],
       device='cuda:0') torch.Size([16])
percent tensor([0.6418, 0.6726, 0.6471, 0.6493, 0.6455, 0.6411, 0.6641, 0.6355, 0.6689,
        0.6800, 0.7068, 0.6867, 0.6758, 0.6794, 0.6572, 0.6577],
       device='cuda:0') torch.Size([16])
percent tensor([0.6206, 0.5861, 0.6772, 0.6165, 0.6433, 0.7505, 0.6234, 0.5979, 0.6376,
        0.6045, 0.5997, 0.6260, 0.6358, 0.6358, 0.6351, 0.6496],
       device='cuda:0') torch.Size([16])
percent tensor([0.5080, 0.6053, 0.5259, 0.4977, 0.4921, 0.5177, 0.5274, 0.4003, 0.6214,
        0.5556, 0.6408, 0.5948, 0.5879, 0.6769, 0.4434, 0.4972],
       device='cuda:0') torch.Size([16])
percent tensor([0.5541, 0.6154, 0.7809, 0.7673, 0.8207, 0.6473, 0.6469, 0.7689, 0.6242,
        0.6300, 0.6235, 0.7631, 0.5267, 0.6385, 0.6300, 0.6388],
       device='cuda:0') torch.Size([16])
percent tensor([0.9992, 0.9968, 0.9987, 0.9987, 0.9985, 0.9974, 0.9982, 0.9989, 0.9976,
        0.9978, 0.9984, 0.9977, 0.9973, 0.9977, 0.9979, 0.9991],
       device='cuda:0') torch.Size([16])
Epoch: 69 | Batch_idx: 0 |  Loss: (0.2728) |  Loss2: (0.0000) | Acc: (87.00%) (112/128)
Epoch: 69 | Batch_idx: 10 |  Loss: (0.2830) |  Loss2: (0.0000) | Acc: (89.00%) (1267/1408)
Epoch: 69 | Batch_idx: 20 |  Loss: (0.2988) |  Loss2: (0.0000) | Acc: (90.00%) (2422/2688)
Epoch: 69 | Batch_idx: 30 |  Loss: (0.3020) |  Loss2: (0.0000) | Acc: (89.00%) (3555/3968)
Epoch: 69 | Batch_idx: 40 |  Loss: (0.2983) |  Loss2: (0.0000) | Acc: (89.00%) (4707/5248)
Epoch: 69 | Batch_idx: 50 |  Loss: (0.3037) |  Loss2: (0.0000) | Acc: (89.00%) (5846/6528)
Epoch: 69 | Batch_idx: 60 |  Loss: (0.3011) |  Loss2: (0.0000) | Acc: (89.00%) (7007/7808)
Epoch: 69 | Batch_idx: 70 |  Loss: (0.3037) |  Loss2: (0.0000) | Acc: (89.00%) (8133/9088)
Epoch: 69 | Batch_idx: 80 |  Loss: (0.3001) |  Loss2: (0.0000) | Acc: (89.00%) (9299/10368)
Epoch: 69 | Batch_idx: 90 |  Loss: (0.3013) |  Loss2: (0.0000) | Acc: (89.00%) (10440/11648)
Epoch: 69 | Batch_idx: 100 |  Loss: (0.2989) |  Loss2: (0.0000) | Acc: (89.00%) (11584/12928)
Epoch: 69 | Batch_idx: 110 |  Loss: (0.3009) |  Loss2: (0.0000) | Acc: (89.00%) (12726/14208)
Epoch: 69 | Batch_idx: 120 |  Loss: (0.3021) |  Loss2: (0.0000) | Acc: (89.00%) (13869/15488)
Epoch: 69 | Batch_idx: 130 |  Loss: (0.3031) |  Loss2: (0.0000) | Acc: (89.00%) (15005/16768)
Epoch: 69 | Batch_idx: 140 |  Loss: (0.3018) |  Loss2: (0.0000) | Acc: (89.00%) (16155/18048)
Epoch: 69 | Batch_idx: 150 |  Loss: (0.3009) |  Loss2: (0.0000) | Acc: (89.00%) (17308/19328)
Epoch: 69 | Batch_idx: 160 |  Loss: (0.3035) |  Loss2: (0.0000) | Acc: (89.00%) (18439/20608)
Epoch: 69 | Batch_idx: 170 |  Loss: (0.3042) |  Loss2: (0.0000) | Acc: (89.00%) (19576/21888)
Epoch: 69 | Batch_idx: 180 |  Loss: (0.3047) |  Loss2: (0.0000) | Acc: (89.00%) (20711/23168)
Epoch: 69 | Batch_idx: 190 |  Loss: (0.3046) |  Loss2: (0.0000) | Acc: (89.00%) (21864/24448)
Epoch: 69 | Batch_idx: 200 |  Loss: (0.3044) |  Loss2: (0.0000) | Acc: (89.00%) (23019/25728)
Epoch: 69 | Batch_idx: 210 |  Loss: (0.3051) |  Loss2: (0.0000) | Acc: (89.00%) (24155/27008)
Epoch: 69 | Batch_idx: 220 |  Loss: (0.3043) |  Loss2: (0.0000) | Acc: (89.00%) (25301/28288)
Epoch: 69 | Batch_idx: 230 |  Loss: (0.3047) |  Loss2: (0.0000) | Acc: (89.00%) (26439/29568)
Epoch: 69 | Batch_idx: 240 |  Loss: (0.3051) |  Loss2: (0.0000) | Acc: (89.00%) (27574/30848)
Epoch: 69 | Batch_idx: 250 |  Loss: (0.3043) |  Loss2: (0.0000) | Acc: (89.00%) (28737/32128)
Epoch: 69 | Batch_idx: 260 |  Loss: (0.3047) |  Loss2: (0.0000) | Acc: (89.00%) (29880/33408)
Epoch: 69 | Batch_idx: 270 |  Loss: (0.3056) |  Loss2: (0.0000) | Acc: (89.00%) (31020/34688)
Epoch: 69 | Batch_idx: 280 |  Loss: (0.3050) |  Loss2: (0.0000) | Acc: (89.00%) (32178/35968)
Epoch: 69 | Batch_idx: 290 |  Loss: (0.3039) |  Loss2: (0.0000) | Acc: (89.00%) (33331/37248)
Epoch: 69 | Batch_idx: 300 |  Loss: (0.3036) |  Loss2: (0.0000) | Acc: (89.00%) (34476/38528)
Epoch: 69 | Batch_idx: 310 |  Loss: (0.3033) |  Loss2: (0.0000) | Acc: (89.00%) (35621/39808)
Epoch: 69 | Batch_idx: 320 |  Loss: (0.3030) |  Loss2: (0.0000) | Acc: (89.00%) (36773/41088)
Epoch: 69 | Batch_idx: 330 |  Loss: (0.3046) |  Loss2: (0.0000) | Acc: (89.00%) (37886/42368)
Epoch: 69 | Batch_idx: 340 |  Loss: (0.3041) |  Loss2: (0.0000) | Acc: (89.00%) (39043/43648)
Epoch: 69 | Batch_idx: 350 |  Loss: (0.3037) |  Loss2: (0.0000) | Acc: (89.00%) (40197/44928)
Epoch: 69 | Batch_idx: 360 |  Loss: (0.3038) |  Loss2: (0.0000) | Acc: (89.00%) (41342/46208)
Epoch: 69 | Batch_idx: 370 |  Loss: (0.3040) |  Loss2: (0.0000) | Acc: (89.00%) (42489/47488)
Epoch: 69 | Batch_idx: 380 |  Loss: (0.3043) |  Loss2: (0.0000) | Acc: (89.00%) (43642/48768)
Epoch: 69 | Batch_idx: 390 |  Loss: (0.3046) |  Loss2: (0.0000) | Acc: (89.00%) (44737/50000)
# TEST : Loss: (0.4029) | Acc: (86.00%) (8632/10000)
percent tensor([0.5304, 0.5186, 0.5338, 0.5336, 0.5332, 0.5339, 0.5250, 0.5309, 0.5321,
        0.5240, 0.5278, 0.5272, 0.5263, 0.5201, 0.5262, 0.5287],
       device='cuda:0') torch.Size([16])
percent tensor([0.5426, 0.5513, 0.5417, 0.5459, 0.5455, 0.5579, 0.5487, 0.5420, 0.5382,
        0.5418, 0.5401, 0.5408, 0.5398, 0.5499, 0.5532, 0.5465],
       device='cuda:0') torch.Size([16])
percent tensor([0.5469, 0.5788, 0.5405, 0.4692, 0.5259, 0.4637, 0.5785, 0.5316, 0.5374,
        0.5649, 0.5538, 0.5804, 0.6190, 0.4659, 0.5477, 0.5055],
       device='cuda:0') torch.Size([16])
percent tensor([0.6398, 0.6715, 0.6455, 0.6480, 0.6438, 0.6401, 0.6633, 0.6332, 0.6685,
        0.6797, 0.7072, 0.6857, 0.6751, 0.6807, 0.6563, 0.6562],
       device='cuda:0') torch.Size([16])
percent tensor([0.6175, 0.5856, 0.6754, 0.6132, 0.6400, 0.7484, 0.6193, 0.5938, 0.6403,
        0.6038, 0.5986, 0.6263, 0.6358, 0.6367, 0.6329, 0.6456],
       device='cuda:0') torch.Size([16])
percent tensor([0.5087, 0.6085, 0.5285, 0.5012, 0.4965, 0.5218, 0.5310, 0.4053, 0.6225,
        0.5563, 0.6424, 0.5975, 0.5920, 0.6794, 0.4449, 0.4993],
       device='cuda:0') torch.Size([16])
percent tensor([0.5498, 0.6107, 0.7775, 0.7657, 0.8186, 0.6390, 0.6454, 0.7694, 0.6238,
        0.6261, 0.6147, 0.7657, 0.5237, 0.6356, 0.6270, 0.6369],
       device='cuda:0') torch.Size([16])
percent tensor([0.9992, 0.9969, 0.9987, 0.9988, 0.9985, 0.9974, 0.9983, 0.9990, 0.9976,
        0.9979, 0.9985, 0.9979, 0.9974, 0.9979, 0.9981, 0.9992],
       device='cuda:0') torch.Size([16])
True Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=128, out_features=16, bias=False)
False Linear(in_features=16, out_features=2, bias=False)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=128, out_features=16, bias=False)
False Linear(in_features=16, out_features=2, bias=False)
True Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=256, out_features=32, bias=False)
False Linear(in_features=32, out_features=2, bias=False)
True Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=256, out_features=32, bias=False)
False Linear(in_features=32, out_features=2, bias=False)
True Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=512, out_features=64, bias=False)
False Linear(in_features=64, out_features=2, bias=False)
True Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=512, out_features=64, bias=False)
False Linear(in_features=64, out_features=2, bias=False)
True Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1024, out_features=128, bias=False)
False Linear(in_features=128, out_features=2, bias=False)
True Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1024, out_features=128, bias=False)
False Linear(in_features=128, out_features=2, bias=False)
True Linear(in_features=512, out_features=10, bias=True)
Epoch: 70 | Batch_idx: 0 |  Loss: (0.2339) |  Loss2: (0.0000) | Acc: (89.00%) (115/128)
Epoch: 70 | Batch_idx: 10 |  Loss: (0.3003) |  Loss2: (0.0000) | Acc: (89.00%) (1264/1408)
Epoch: 70 | Batch_idx: 20 |  Loss: (0.3108) |  Loss2: (0.0000) | Acc: (89.00%) (2394/2688)
Epoch: 70 | Batch_idx: 30 |  Loss: (0.3081) |  Loss2: (0.0000) | Acc: (89.00%) (3540/3968)
Epoch: 70 | Batch_idx: 40 |  Loss: (0.3149) |  Loss2: (0.0000) | Acc: (88.00%) (4670/5248)
Epoch: 70 | Batch_idx: 50 |  Loss: (0.3096) |  Loss2: (0.0000) | Acc: (89.00%) (5823/6528)
Epoch: 70 | Batch_idx: 60 |  Loss: (0.3091) |  Loss2: (0.0000) | Acc: (89.00%) (6968/7808)
Epoch: 70 | Batch_idx: 70 |  Loss: (0.3098) |  Loss2: (0.0000) | Acc: (89.00%) (8128/9088)
Epoch: 70 | Batch_idx: 80 |  Loss: (0.3100) |  Loss2: (0.0000) | Acc: (89.00%) (9273/10368)
Epoch: 70 | Batch_idx: 90 |  Loss: (0.3097) |  Loss2: (0.0000) | Acc: (89.00%) (10416/11648)
Epoch: 70 | Batch_idx: 100 |  Loss: (0.3130) |  Loss2: (0.0000) | Acc: (89.00%) (11537/12928)
Epoch: 70 | Batch_idx: 110 |  Loss: (0.3160) |  Loss2: (0.0000) | Acc: (89.00%) (12669/14208)
Epoch: 70 | Batch_idx: 120 |  Loss: (0.3137) |  Loss2: (0.0000) | Acc: (89.00%) (13834/15488)
Epoch: 70 | Batch_idx: 130 |  Loss: (0.3104) |  Loss2: (0.0000) | Acc: (89.00%) (14995/16768)
Epoch: 70 | Batch_idx: 140 |  Loss: (0.3107) |  Loss2: (0.0000) | Acc: (89.00%) (16143/18048)
Epoch: 70 | Batch_idx: 150 |  Loss: (0.3102) |  Loss2: (0.0000) | Acc: (89.00%) (17286/19328)
Epoch: 70 | Batch_idx: 160 |  Loss: (0.3107) |  Loss2: (0.0000) | Acc: (89.00%) (18421/20608)
Epoch: 70 | Batch_idx: 170 |  Loss: (0.3118) |  Loss2: (0.0000) | Acc: (89.00%) (19553/21888)
Epoch: 70 | Batch_idx: 180 |  Loss: (0.3136) |  Loss2: (0.0000) | Acc: (89.00%) (20674/23168)
Epoch: 70 | Batch_idx: 190 |  Loss: (0.3139) |  Loss2: (0.0000) | Acc: (89.00%) (21817/24448)
Epoch: 70 | Batch_idx: 200 |  Loss: (0.3165) |  Loss2: (0.0000) | Acc: (89.00%) (22928/25728)
Epoch: 70 | Batch_idx: 210 |  Loss: (0.3153) |  Loss2: (0.0000) | Acc: (89.00%) (24088/27008)
Epoch: 70 | Batch_idx: 220 |  Loss: (0.3145) |  Loss2: (0.0000) | Acc: (89.00%) (25232/28288)
Epoch: 70 | Batch_idx: 230 |  Loss: (0.3140) |  Loss2: (0.0000) | Acc: (89.00%) (26382/29568)
Epoch: 70 | Batch_idx: 240 |  Loss: (0.3145) |  Loss2: (0.0000) | Acc: (89.00%) (27519/30848)
Epoch: 70 | Batch_idx: 250 |  Loss: (0.3145) |  Loss2: (0.0000) | Acc: (89.00%) (28658/32128)
Epoch: 70 | Batch_idx: 260 |  Loss: (0.3150) |  Loss2: (0.0000) | Acc: (89.00%) (29800/33408)
Epoch: 70 | Batch_idx: 270 |  Loss: (0.3158) |  Loss2: (0.0000) | Acc: (89.00%) (30926/34688)
Epoch: 70 | Batch_idx: 280 |  Loss: (0.3164) |  Loss2: (0.0000) | Acc: (89.00%) (32062/35968)
Epoch: 70 | Batch_idx: 290 |  Loss: (0.3176) |  Loss2: (0.0000) | Acc: (89.00%) (33191/37248)
Epoch: 70 | Batch_idx: 300 |  Loss: (0.3175) |  Loss2: (0.0000) | Acc: (89.00%) (34339/38528)
Epoch: 70 | Batch_idx: 310 |  Loss: (0.3169) |  Loss2: (0.0000) | Acc: (89.00%) (35478/39808)
Epoch: 70 | Batch_idx: 320 |  Loss: (0.3173) |  Loss2: (0.0000) | Acc: (89.00%) (36620/41088)
Epoch: 70 | Batch_idx: 330 |  Loss: (0.3177) |  Loss2: (0.0000) | Acc: (89.00%) (37755/42368)
Epoch: 70 | Batch_idx: 340 |  Loss: (0.3175) |  Loss2: (0.0000) | Acc: (89.00%) (38899/43648)
Epoch: 70 | Batch_idx: 350 |  Loss: (0.3179) |  Loss2: (0.0000) | Acc: (89.00%) (40024/44928)
Epoch: 70 | Batch_idx: 360 |  Loss: (0.3179) |  Loss2: (0.0000) | Acc: (89.00%) (41165/46208)
Epoch: 70 | Batch_idx: 370 |  Loss: (0.3173) |  Loss2: (0.0000) | Acc: (89.00%) (42305/47488)
Epoch: 70 | Batch_idx: 380 |  Loss: (0.3180) |  Loss2: (0.0000) | Acc: (89.00%) (43428/48768)
Epoch: 70 | Batch_idx: 390 |  Loss: (0.3183) |  Loss2: (0.0000) | Acc: (89.00%) (44528/50000)
=> saving checkpoint 'drive/app/torch/save_Routing_Gate_2/checkpoint_070.pth.tar'
# TEST : Loss: (0.5457) | Acc: (81.00%) (8162/10000)
percent tensor([0.5289, 0.5185, 0.5329, 0.5327, 0.5323, 0.5323, 0.5240, 0.5303, 0.5305,
        0.5238, 0.5270, 0.5267, 0.5258, 0.5200, 0.5253, 0.5277],
       device='cuda:0') torch.Size([16])
percent tensor([0.5414, 0.5503, 0.5389, 0.5436, 0.5434, 0.5556, 0.5474, 0.5402, 0.5371,
        0.5406, 0.5400, 0.5391, 0.5394, 0.5466, 0.5515, 0.5448],
       device='cuda:0') torch.Size([16])
percent tensor([0.5428, 0.5877, 0.5267, 0.4746, 0.5095, 0.4623, 0.5769, 0.5393, 0.5395,
        0.5634, 0.5437, 0.5616, 0.6103, 0.4881, 0.5528, 0.5108],
       device='cuda:0') torch.Size([16])
percent tensor([0.6364, 0.6721, 0.6424, 0.6509, 0.6417, 0.6322, 0.6630, 0.6319, 0.6642,
        0.6795, 0.7002, 0.6876, 0.6751, 0.6762, 0.6571, 0.6543],
       device='cuda:0') torch.Size([16])
percent tensor([0.6007, 0.5860, 0.6451, 0.6069, 0.6164, 0.7368, 0.6099, 0.5847, 0.6289,
        0.5896, 0.5957, 0.6055, 0.6192, 0.6412, 0.6330, 0.6351],
       device='cuda:0') torch.Size([16])
percent tensor([0.5017, 0.5916, 0.5459, 0.5167, 0.5234, 0.5142, 0.5145, 0.4512, 0.6179,
        0.5533, 0.6295, 0.6085, 0.5871, 0.6655, 0.4467, 0.4940],
       device='cuda:0') torch.Size([16])
percent tensor([0.5188, 0.5506, 0.7759, 0.7621, 0.8201, 0.6363, 0.6008, 0.7480, 0.6077,
        0.5664, 0.5696, 0.7524, 0.5284, 0.5854, 0.6096, 0.6154],
       device='cuda:0') torch.Size([16])
percent tensor([0.9995, 0.9981, 0.9989, 0.9986, 0.9990, 0.9989, 0.9987, 0.9989, 0.9984,
        0.9988, 0.9988, 0.9986, 0.9986, 0.9987, 0.9985, 0.9994],
       device='cuda:0') torch.Size([16])
Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 3, 3, 3]) tensor(176.5839, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(799.9706, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(803.1032, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([128, 64, 3, 3]) tensor(1520.1484, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([128, 64, 1, 1]) tensor(500.4315, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([128, 128, 3, 3]) tensor(2218.4751, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([256, 128, 3, 3]) tensor(4288.4761, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([256, 128, 1, 1]) tensor(1409.5822, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([256, 256, 3, 3]) tensor(6098.2178, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([512, 256, 3, 3]) tensor(11976.1582, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([512, 256, 1, 1]) tensor(3986.0754, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([512, 512, 3, 3]) tensor(16836.4512, device='cuda:0', grad_fn=<NormBackward0>)
Epoch: 71 | Batch_idx: 0 |  Loss: (0.2700) |  Loss2: (0.0000) | Acc: (91.00%) (117/128)
Epoch: 71 | Batch_idx: 10 |  Loss: (0.2819) |  Loss2: (0.0000) | Acc: (90.00%) (1273/1408)
Epoch: 71 | Batch_idx: 20 |  Loss: (0.2898) |  Loss2: (0.0000) | Acc: (90.00%) (2421/2688)
Epoch: 71 | Batch_idx: 30 |  Loss: (0.2973) |  Loss2: (0.0000) | Acc: (89.00%) (3555/3968)
Epoch: 71 | Batch_idx: 40 |  Loss: (0.2992) |  Loss2: (0.0000) | Acc: (89.00%) (4700/5248)
Epoch: 71 | Batch_idx: 50 |  Loss: (0.2979) |  Loss2: (0.0000) | Acc: (89.00%) (5848/6528)
Epoch: 71 | Batch_idx: 60 |  Loss: (0.2974) |  Loss2: (0.0000) | Acc: (89.00%) (6995/7808)
Epoch: 71 | Batch_idx: 70 |  Loss: (0.2921) |  Loss2: (0.0000) | Acc: (89.00%) (8170/9088)
Epoch: 71 | Batch_idx: 80 |  Loss: (0.2949) |  Loss2: (0.0000) | Acc: (89.00%) (9309/10368)
Epoch: 71 | Batch_idx: 90 |  Loss: (0.2953) |  Loss2: (0.0000) | Acc: (89.00%) (10451/11648)
Epoch: 71 | Batch_idx: 100 |  Loss: (0.2953) |  Loss2: (0.0000) | Acc: (89.00%) (11604/12928)
Epoch: 71 | Batch_idx: 110 |  Loss: (0.2969) |  Loss2: (0.0000) | Acc: (89.00%) (12752/14208)
Epoch: 71 | Batch_idx: 120 |  Loss: (0.3008) |  Loss2: (0.0000) | Acc: (89.00%) (13886/15488)
Epoch: 71 | Batch_idx: 130 |  Loss: (0.3036) |  Loss2: (0.0000) | Acc: (89.00%) (15023/16768)
Epoch: 71 | Batch_idx: 140 |  Loss: (0.3042) |  Loss2: (0.0000) | Acc: (89.00%) (16163/18048)
Epoch: 71 | Batch_idx: 150 |  Loss: (0.3038) |  Loss2: (0.0000) | Acc: (89.00%) (17309/19328)
Epoch: 71 | Batch_idx: 160 |  Loss: (0.3031) |  Loss2: (0.0000) | Acc: (89.00%) (18459/20608)
Epoch: 71 | Batch_idx: 170 |  Loss: (0.3025) |  Loss2: (0.0000) | Acc: (89.00%) (19607/21888)
Epoch: 71 | Batch_idx: 180 |  Loss: (0.3024) |  Loss2: (0.0000) | Acc: (89.00%) (20756/23168)
Epoch: 71 | Batch_idx: 190 |  Loss: (0.3028) |  Loss2: (0.0000) | Acc: (89.00%) (21907/24448)
Epoch: 71 | Batch_idx: 200 |  Loss: (0.3023) |  Loss2: (0.0000) | Acc: (89.00%) (23058/25728)
Epoch: 71 | Batch_idx: 210 |  Loss: (0.3016) |  Loss2: (0.0000) | Acc: (89.00%) (24202/27008)
Epoch: 71 | Batch_idx: 220 |  Loss: (0.3022) |  Loss2: (0.0000) | Acc: (89.00%) (25343/28288)
Epoch: 71 | Batch_idx: 230 |  Loss: (0.3026) |  Loss2: (0.0000) | Acc: (89.00%) (26477/29568)
Epoch: 71 | Batch_idx: 240 |  Loss: (0.3009) |  Loss2: (0.0000) | Acc: (89.00%) (27646/30848)
Epoch: 71 | Batch_idx: 250 |  Loss: (0.3004) |  Loss2: (0.0000) | Acc: (89.00%) (28807/32128)
Epoch: 71 | Batch_idx: 260 |  Loss: (0.2993) |  Loss2: (0.0000) | Acc: (89.00%) (29964/33408)
Epoch: 71 | Batch_idx: 270 |  Loss: (0.2995) |  Loss2: (0.0000) | Acc: (89.00%) (31098/34688)
Epoch: 71 | Batch_idx: 280 |  Loss: (0.3004) |  Loss2: (0.0000) | Acc: (89.00%) (32234/35968)
Epoch: 71 | Batch_idx: 290 |  Loss: (0.3005) |  Loss2: (0.0000) | Acc: (89.00%) (33373/37248)
Epoch: 71 | Batch_idx: 300 |  Loss: (0.3007) |  Loss2: (0.0000) | Acc: (89.00%) (34502/38528)
Epoch: 71 | Batch_idx: 310 |  Loss: (0.3003) |  Loss2: (0.0000) | Acc: (89.00%) (35654/39808)
Epoch: 71 | Batch_idx: 320 |  Loss: (0.2998) |  Loss2: (0.0000) | Acc: (89.00%) (36812/41088)
Epoch: 71 | Batch_idx: 330 |  Loss: (0.3005) |  Loss2: (0.0000) | Acc: (89.00%) (37942/42368)
Epoch: 71 | Batch_idx: 340 |  Loss: (0.3004) |  Loss2: (0.0000) | Acc: (89.00%) (39096/43648)
Epoch: 71 | Batch_idx: 350 |  Loss: (0.3009) |  Loss2: (0.0000) | Acc: (89.00%) (40224/44928)
Epoch: 71 | Batch_idx: 360 |  Loss: (0.3013) |  Loss2: (0.0000) | Acc: (89.00%) (41367/46208)
Epoch: 71 | Batch_idx: 370 |  Loss: (0.3013) |  Loss2: (0.0000) | Acc: (89.00%) (42517/47488)
Epoch: 71 | Batch_idx: 380 |  Loss: (0.3012) |  Loss2: (0.0000) | Acc: (89.00%) (43658/48768)
Epoch: 71 | Batch_idx: 390 |  Loss: (0.3015) |  Loss2: (0.0000) | Acc: (89.00%) (44764/50000)
# TEST : Loss: (0.4375) | Acc: (85.00%) (8520/10000)
percent tensor([0.5296, 0.5193, 0.5344, 0.5343, 0.5335, 0.5332, 0.5255, 0.5320, 0.5308,
        0.5244, 0.5271, 0.5280, 0.5258, 0.5212, 0.5261, 0.5286],
       device='cuda:0') torch.Size([16])
percent tensor([0.5423, 0.5515, 0.5395, 0.5445, 0.5442, 0.5565, 0.5482, 0.5418, 0.5391,
        0.5420, 0.5413, 0.5391, 0.5408, 0.5491, 0.5524, 0.5466],
       device='cuda:0') torch.Size([16])
percent tensor([0.5302, 0.5689, 0.4995, 0.4501, 0.4968, 0.4566, 0.5643, 0.5148, 0.5212,
        0.5443, 0.5393, 0.5457, 0.5977, 0.4627, 0.5416, 0.4944],
       device='cuda:0') torch.Size([16])
percent tensor([0.6372, 0.6659, 0.6532, 0.6561, 0.6469, 0.6384, 0.6606, 0.6337, 0.6649,
        0.6798, 0.7036, 0.6868, 0.6725, 0.6744, 0.6548, 0.6553],
       device='cuda:0') torch.Size([16])
percent tensor([0.6225, 0.6038, 0.6448, 0.6019, 0.6092, 0.7237, 0.6255, 0.5955, 0.6602,
        0.6139, 0.6292, 0.6155, 0.6476, 0.6622, 0.6358, 0.6482],
       device='cuda:0') torch.Size([16])
percent tensor([0.5027, 0.5836, 0.5600, 0.5366, 0.5388, 0.5153, 0.5262, 0.4404, 0.6124,
        0.5438, 0.6155, 0.6137, 0.5654, 0.6579, 0.4529, 0.4868],
       device='cuda:0') torch.Size([16])
percent tensor([0.5656, 0.5890, 0.7963, 0.7749, 0.8192, 0.6621, 0.6381, 0.7543, 0.6418,
        0.6075, 0.6381, 0.7578, 0.5627, 0.6436, 0.6466, 0.6381],
       device='cuda:0') torch.Size([16])
percent tensor([0.9991, 0.9968, 0.9987, 0.9980, 0.9982, 0.9975, 0.9977, 0.9991, 0.9969,
        0.9978, 0.9985, 0.9978, 0.9967, 0.9975, 0.9982, 0.9990],
       device='cuda:0') torch.Size([16])
Epoch: 72 | Batch_idx: 0 |  Loss: (0.3676) |  Loss2: (0.0000) | Acc: (88.00%) (113/128)
Epoch: 72 | Batch_idx: 10 |  Loss: (0.2990) |  Loss2: (0.0000) | Acc: (88.00%) (1251/1408)
Epoch: 72 | Batch_idx: 20 |  Loss: (0.3042) |  Loss2: (0.0000) | Acc: (89.00%) (2404/2688)
Epoch: 72 | Batch_idx: 30 |  Loss: (0.3049) |  Loss2: (0.0000) | Acc: (89.00%) (3548/3968)
Epoch: 72 | Batch_idx: 40 |  Loss: (0.3010) |  Loss2: (0.0000) | Acc: (89.00%) (4707/5248)
Epoch: 72 | Batch_idx: 50 |  Loss: (0.3008) |  Loss2: (0.0000) | Acc: (89.00%) (5845/6528)
Epoch: 72 | Batch_idx: 60 |  Loss: (0.2982) |  Loss2: (0.0000) | Acc: (89.00%) (7001/7808)
Epoch: 72 | Batch_idx: 70 |  Loss: (0.2998) |  Loss2: (0.0000) | Acc: (89.00%) (8156/9088)
Epoch: 72 | Batch_idx: 80 |  Loss: (0.2986) |  Loss2: (0.0000) | Acc: (89.00%) (9314/10368)
Epoch: 72 | Batch_idx: 90 |  Loss: (0.2968) |  Loss2: (0.0000) | Acc: (89.00%) (10460/11648)
Epoch: 72 | Batch_idx: 100 |  Loss: (0.2940) |  Loss2: (0.0000) | Acc: (89.00%) (11619/12928)
Epoch: 72 | Batch_idx: 110 |  Loss: (0.2905) |  Loss2: (0.0000) | Acc: (90.00%) (12790/14208)
Epoch: 72 | Batch_idx: 120 |  Loss: (0.2899) |  Loss2: (0.0000) | Acc: (90.00%) (13952/15488)
Epoch: 72 | Batch_idx: 130 |  Loss: (0.2916) |  Loss2: (0.0000) | Acc: (89.00%) (15089/16768)
Epoch: 72 | Batch_idx: 140 |  Loss: (0.2914) |  Loss2: (0.0000) | Acc: (89.00%) (16240/18048)
Epoch: 72 | Batch_idx: 150 |  Loss: (0.2902) |  Loss2: (0.0000) | Acc: (90.00%) (17397/19328)
Epoch: 72 | Batch_idx: 160 |  Loss: (0.2919) |  Loss2: (0.0000) | Acc: (89.00%) (18537/20608)
Epoch: 72 | Batch_idx: 170 |  Loss: (0.2905) |  Loss2: (0.0000) | Acc: (89.00%) (19699/21888)
Epoch: 72 | Batch_idx: 180 |  Loss: (0.2910) |  Loss2: (0.0000) | Acc: (90.00%) (20862/23168)
Epoch: 72 | Batch_idx: 190 |  Loss: (0.2903) |  Loss2: (0.0000) | Acc: (90.00%) (22022/24448)
Epoch: 72 | Batch_idx: 200 |  Loss: (0.2906) |  Loss2: (0.0000) | Acc: (90.00%) (23176/25728)
Epoch: 72 | Batch_idx: 210 |  Loss: (0.2915) |  Loss2: (0.0000) | Acc: (90.00%) (24309/27008)
Epoch: 72 | Batch_idx: 220 |  Loss: (0.2921) |  Loss2: (0.0000) | Acc: (89.00%) (25452/28288)
Epoch: 72 | Batch_idx: 230 |  Loss: (0.2936) |  Loss2: (0.0000) | Acc: (89.00%) (26580/29568)
Epoch: 72 | Batch_idx: 240 |  Loss: (0.2939) |  Loss2: (0.0000) | Acc: (89.00%) (27726/30848)
Epoch: 72 | Batch_idx: 250 |  Loss: (0.2933) |  Loss2: (0.0000) | Acc: (89.00%) (28891/32128)
Epoch: 72 | Batch_idx: 260 |  Loss: (0.2925) |  Loss2: (0.0000) | Acc: (89.00%) (30053/33408)
Epoch: 72 | Batch_idx: 270 |  Loss: (0.2929) |  Loss2: (0.0000) | Acc: (89.00%) (31195/34688)
Epoch: 72 | Batch_idx: 280 |  Loss: (0.2931) |  Loss2: (0.0000) | Acc: (89.00%) (32339/35968)
Epoch: 72 | Batch_idx: 290 |  Loss: (0.2938) |  Loss2: (0.0000) | Acc: (89.00%) (33483/37248)
Epoch: 72 | Batch_idx: 300 |  Loss: (0.2940) |  Loss2: (0.0000) | Acc: (89.00%) (34631/38528)
Epoch: 72 | Batch_idx: 310 |  Loss: (0.2939) |  Loss2: (0.0000) | Acc: (89.00%) (35800/39808)
Epoch: 72 | Batch_idx: 320 |  Loss: (0.2934) |  Loss2: (0.0000) | Acc: (89.00%) (36958/41088)
Epoch: 72 | Batch_idx: 330 |  Loss: (0.2933) |  Loss2: (0.0000) | Acc: (89.00%) (38113/42368)
Epoch: 72 | Batch_idx: 340 |  Loss: (0.2933) |  Loss2: (0.0000) | Acc: (89.00%) (39263/43648)
Epoch: 72 | Batch_idx: 350 |  Loss: (0.2924) |  Loss2: (0.0000) | Acc: (89.00%) (40426/44928)
Epoch: 72 | Batch_idx: 360 |  Loss: (0.2926) |  Loss2: (0.0000) | Acc: (89.00%) (41568/46208)
Epoch: 72 | Batch_idx: 370 |  Loss: (0.2929) |  Loss2: (0.0000) | Acc: (89.00%) (42710/47488)
Epoch: 72 | Batch_idx: 380 |  Loss: (0.2933) |  Loss2: (0.0000) | Acc: (89.00%) (43852/48768)
Epoch: 72 | Batch_idx: 390 |  Loss: (0.2940) |  Loss2: (0.0000) | Acc: (89.00%) (44938/50000)
# TEST : Loss: (0.4305) | Acc: (85.00%) (8547/10000)
percent tensor([0.5288, 0.5184, 0.5347, 0.5344, 0.5336, 0.5331, 0.5248, 0.5318, 0.5299,
        0.5238, 0.5262, 0.5282, 0.5249, 0.5195, 0.5259, 0.5279],
       device='cuda:0') torch.Size([16])
percent tensor([0.5416, 0.5519, 0.5388, 0.5431, 0.5433, 0.5564, 0.5483, 0.5406, 0.5371,
        0.5412, 0.5397, 0.5384, 0.5393, 0.5495, 0.5525, 0.5458],
       device='cuda:0') torch.Size([16])
percent tensor([0.5478, 0.5711, 0.5427, 0.4786, 0.5281, 0.4687, 0.5680, 0.5439, 0.5395,
        0.5625, 0.5499, 0.5747, 0.6173, 0.4511, 0.5508, 0.5074],
       device='cuda:0') torch.Size([16])
percent tensor([0.6381, 0.6759, 0.6398, 0.6416, 0.6403, 0.6351, 0.6673, 0.6274, 0.6669,
        0.6791, 0.7048, 0.6835, 0.6764, 0.6872, 0.6609, 0.6547],
       device='cuda:0') torch.Size([16])
percent tensor([0.6132, 0.5860, 0.6478, 0.6077, 0.6129, 0.7305, 0.6118, 0.5857, 0.6509,
        0.6029, 0.6096, 0.6138, 0.6452, 0.6494, 0.6215, 0.6425],
       device='cuda:0') torch.Size([16])
percent tensor([0.5114, 0.5890, 0.5448, 0.5154, 0.5121, 0.4957, 0.5180, 0.4397, 0.6079,
        0.5514, 0.6106, 0.6163, 0.5717, 0.6634, 0.4385, 0.4878],
       device='cuda:0') torch.Size([16])
percent tensor([0.5495, 0.6115, 0.7832, 0.7571, 0.8136, 0.6488, 0.6396, 0.7463, 0.6472,
        0.6232, 0.6418, 0.7554, 0.5832, 0.6506, 0.6534, 0.6372],
       device='cuda:0') torch.Size([16])
percent tensor([0.9993, 0.9974, 0.9987, 0.9986, 0.9981, 0.9983, 0.9981, 0.9989, 0.9974,
        0.9984, 0.9988, 0.9984, 0.9971, 0.9977, 0.9983, 0.9991],
       device='cuda:0') torch.Size([16])
Epoch: 73 | Batch_idx: 0 |  Loss: (0.2734) |  Loss2: (0.0000) | Acc: (87.00%) (112/128)
Epoch: 73 | Batch_idx: 10 |  Loss: (0.2353) |  Loss2: (0.0000) | Acc: (91.00%) (1285/1408)
Epoch: 73 | Batch_idx: 20 |  Loss: (0.2508) |  Loss2: (0.0000) | Acc: (91.00%) (2454/2688)
Epoch: 73 | Batch_idx: 30 |  Loss: (0.2695) |  Loss2: (0.0000) | Acc: (90.00%) (3596/3968)
Epoch: 73 | Batch_idx: 40 |  Loss: (0.2751) |  Loss2: (0.0000) | Acc: (90.00%) (4748/5248)
Epoch: 73 | Batch_idx: 50 |  Loss: (0.2780) |  Loss2: (0.0000) | Acc: (90.00%) (5902/6528)
Epoch: 73 | Batch_idx: 60 |  Loss: (0.2808) |  Loss2: (0.0000) | Acc: (90.00%) (7047/7808)
Epoch: 73 | Batch_idx: 70 |  Loss: (0.2777) |  Loss2: (0.0000) | Acc: (90.00%) (8212/9088)
Epoch: 73 | Batch_idx: 80 |  Loss: (0.2756) |  Loss2: (0.0000) | Acc: (90.00%) (9378/10368)
Epoch: 73 | Batch_idx: 90 |  Loss: (0.2760) |  Loss2: (0.0000) | Acc: (90.00%) (10527/11648)
Epoch: 73 | Batch_idx: 100 |  Loss: (0.2791) |  Loss2: (0.0000) | Acc: (90.00%) (11676/12928)
Epoch: 73 | Batch_idx: 110 |  Loss: (0.2800) |  Loss2: (0.0000) | Acc: (90.00%) (12822/14208)
Epoch: 73 | Batch_idx: 120 |  Loss: (0.2780) |  Loss2: (0.0000) | Acc: (90.00%) (13990/15488)
Epoch: 73 | Batch_idx: 130 |  Loss: (0.2754) |  Loss2: (0.0000) | Acc: (90.00%) (15167/16768)
Epoch: 73 | Batch_idx: 140 |  Loss: (0.2759) |  Loss2: (0.0000) | Acc: (90.00%) (16315/18048)
Epoch: 73 | Batch_idx: 150 |  Loss: (0.2774) |  Loss2: (0.0000) | Acc: (90.00%) (17456/19328)
Epoch: 73 | Batch_idx: 160 |  Loss: (0.2765) |  Loss2: (0.0000) | Acc: (90.00%) (18629/20608)
Epoch: 73 | Batch_idx: 170 |  Loss: (0.2784) |  Loss2: (0.0000) | Acc: (90.00%) (19780/21888)
Epoch: 73 | Batch_idx: 180 |  Loss: (0.2786) |  Loss2: (0.0000) | Acc: (90.00%) (20943/23168)
Epoch: 73 | Batch_idx: 190 |  Loss: (0.2782) |  Loss2: (0.0000) | Acc: (90.00%) (22105/24448)
Epoch: 73 | Batch_idx: 200 |  Loss: (0.2785) |  Loss2: (0.0000) | Acc: (90.00%) (23271/25728)
Epoch: 73 | Batch_idx: 210 |  Loss: (0.2799) |  Loss2: (0.0000) | Acc: (90.00%) (24413/27008)
Epoch: 73 | Batch_idx: 220 |  Loss: (0.2795) |  Loss2: (0.0000) | Acc: (90.00%) (25577/28288)
Epoch: 73 | Batch_idx: 230 |  Loss: (0.2802) |  Loss2: (0.0000) | Acc: (90.00%) (26737/29568)
Epoch: 73 | Batch_idx: 240 |  Loss: (0.2819) |  Loss2: (0.0000) | Acc: (90.00%) (27880/30848)
Epoch: 73 | Batch_idx: 250 |  Loss: (0.2831) |  Loss2: (0.0000) | Acc: (90.00%) (29017/32128)
Epoch: 73 | Batch_idx: 260 |  Loss: (0.2846) |  Loss2: (0.0000) | Acc: (90.00%) (30153/33408)
Epoch: 73 | Batch_idx: 270 |  Loss: (0.2854) |  Loss2: (0.0000) | Acc: (90.00%) (31286/34688)
Epoch: 73 | Batch_idx: 280 |  Loss: (0.2850) |  Loss2: (0.0000) | Acc: (90.00%) (32447/35968)
Epoch: 73 | Batch_idx: 290 |  Loss: (0.2851) |  Loss2: (0.0000) | Acc: (90.00%) (33596/37248)
Epoch: 73 | Batch_idx: 300 |  Loss: (0.2857) |  Loss2: (0.0000) | Acc: (90.00%) (34744/38528)
Epoch: 73 | Batch_idx: 310 |  Loss: (0.2861) |  Loss2: (0.0000) | Acc: (90.00%) (35892/39808)
Epoch: 73 | Batch_idx: 320 |  Loss: (0.2858) |  Loss2: (0.0000) | Acc: (90.00%) (37053/41088)
Epoch: 73 | Batch_idx: 330 |  Loss: (0.2858) |  Loss2: (0.0000) | Acc: (90.00%) (38211/42368)
Epoch: 73 | Batch_idx: 340 |  Loss: (0.2869) |  Loss2: (0.0000) | Acc: (90.00%) (39347/43648)
Epoch: 73 | Batch_idx: 350 |  Loss: (0.2864) |  Loss2: (0.0000) | Acc: (90.00%) (40510/44928)
Epoch: 73 | Batch_idx: 360 |  Loss: (0.2861) |  Loss2: (0.0000) | Acc: (90.00%) (41677/46208)
Epoch: 73 | Batch_idx: 370 |  Loss: (0.2850) |  Loss2: (0.0000) | Acc: (90.00%) (42853/47488)
Epoch: 73 | Batch_idx: 380 |  Loss: (0.2854) |  Loss2: (0.0000) | Acc: (90.00%) (44003/48768)
Epoch: 73 | Batch_idx: 390 |  Loss: (0.2855) |  Loss2: (0.0000) | Acc: (90.00%) (45102/50000)
# TEST : Loss: (0.4554) | Acc: (84.00%) (8461/10000)
percent tensor([0.5290, 0.5185, 0.5335, 0.5337, 0.5324, 0.5323, 0.5245, 0.5314, 0.5310,
        0.5235, 0.5269, 0.5268, 0.5251, 0.5202, 0.5256, 0.5278],
       device='cuda:0') torch.Size([16])
percent tensor([0.5423, 0.5522, 0.5393, 0.5438, 0.5433, 0.5564, 0.5492, 0.5404, 0.5377,
        0.5420, 0.5410, 0.5395, 0.5403, 0.5504, 0.5527, 0.5464],
       device='cuda:0') torch.Size([16])
percent tensor([0.5480, 0.5789, 0.5406, 0.4765, 0.5308, 0.4691, 0.5778, 0.5414, 0.5392,
        0.5689, 0.5495, 0.5719, 0.6164, 0.4669, 0.5525, 0.5113],
       device='cuda:0') torch.Size([16])
percent tensor([0.6436, 0.6743, 0.6465, 0.6489, 0.6489, 0.6433, 0.6726, 0.6313, 0.6673,
        0.6777, 0.7088, 0.6937, 0.6794, 0.6795, 0.6631, 0.6587],
       device='cuda:0') torch.Size([16])
percent tensor([0.6183, 0.5928, 0.6347, 0.6111, 0.6047, 0.7387, 0.6144, 0.5805, 0.6443,
        0.6049, 0.6275, 0.6005, 0.6472, 0.6493, 0.6279, 0.6468],
       device='cuda:0') torch.Size([16])
percent tensor([0.5289, 0.6195, 0.5437, 0.5031, 0.5103, 0.5332, 0.5425, 0.4451, 0.6247,
        0.5626, 0.6470, 0.6028, 0.5871, 0.6880, 0.4623, 0.5073],
       device='cuda:0') torch.Size([16])
percent tensor([0.5396, 0.5690, 0.7836, 0.7531, 0.8179, 0.6579, 0.6335, 0.7375, 0.6185,
        0.5916, 0.6182, 0.7532, 0.5683, 0.6104, 0.6333, 0.6051],
       device='cuda:0') torch.Size([16])
percent tensor([0.9994, 0.9969, 0.9986, 0.9983, 0.9985, 0.9980, 0.9980, 0.9986, 0.9975,
        0.9983, 0.9987, 0.9982, 0.9974, 0.9975, 0.9986, 0.9992],
       device='cuda:0') torch.Size([16])
Epoch: 74 | Batch_idx: 0 |  Loss: (0.2556) |  Loss2: (0.0000) | Acc: (91.00%) (117/128)
Epoch: 74 | Batch_idx: 10 |  Loss: (0.2704) |  Loss2: (0.0000) | Acc: (90.00%) (1279/1408)
Epoch: 74 | Batch_idx: 20 |  Loss: (0.2696) |  Loss2: (0.0000) | Acc: (90.00%) (2439/2688)
Epoch: 74 | Batch_idx: 30 |  Loss: (0.2633) |  Loss2: (0.0000) | Acc: (90.00%) (3605/3968)
Epoch: 74 | Batch_idx: 40 |  Loss: (0.2635) |  Loss2: (0.0000) | Acc: (90.00%) (4763/5248)
Epoch: 74 | Batch_idx: 50 |  Loss: (0.2636) |  Loss2: (0.0000) | Acc: (90.00%) (5926/6528)
Epoch: 74 | Batch_idx: 60 |  Loss: (0.2648) |  Loss2: (0.0000) | Acc: (90.00%) (7085/7808)
Epoch: 74 | Batch_idx: 70 |  Loss: (0.2726) |  Loss2: (0.0000) | Acc: (90.00%) (8221/9088)
Epoch: 74 | Batch_idx: 80 |  Loss: (0.2740) |  Loss2: (0.0000) | Acc: (90.00%) (9373/10368)
Epoch: 74 | Batch_idx: 90 |  Loss: (0.2750) |  Loss2: (0.0000) | Acc: (90.00%) (10526/11648)
Epoch: 74 | Batch_idx: 100 |  Loss: (0.2754) |  Loss2: (0.0000) | Acc: (90.00%) (11687/12928)
Epoch: 74 | Batch_idx: 110 |  Loss: (0.2755) |  Loss2: (0.0000) | Acc: (90.00%) (12835/14208)
Epoch: 74 | Batch_idx: 120 |  Loss: (0.2718) |  Loss2: (0.0000) | Acc: (90.00%) (14002/15488)
Epoch: 74 | Batch_idx: 130 |  Loss: (0.2742) |  Loss2: (0.0000) | Acc: (90.00%) (15148/16768)
Epoch: 74 | Batch_idx: 140 |  Loss: (0.2746) |  Loss2: (0.0000) | Acc: (90.00%) (16305/18048)
Epoch: 74 | Batch_idx: 150 |  Loss: (0.2772) |  Loss2: (0.0000) | Acc: (90.00%) (17444/19328)
Epoch: 74 | Batch_idx: 160 |  Loss: (0.2774) |  Loss2: (0.0000) | Acc: (90.00%) (18601/20608)
Epoch: 74 | Batch_idx: 170 |  Loss: (0.2774) |  Loss2: (0.0000) | Acc: (90.00%) (19760/21888)
Epoch: 74 | Batch_idx: 180 |  Loss: (0.2790) |  Loss2: (0.0000) | Acc: (90.00%) (20905/23168)
Epoch: 74 | Batch_idx: 190 |  Loss: (0.2796) |  Loss2: (0.0000) | Acc: (90.00%) (22057/24448)
Epoch: 74 | Batch_idx: 200 |  Loss: (0.2793) |  Loss2: (0.0000) | Acc: (90.00%) (23217/25728)
Epoch: 74 | Batch_idx: 210 |  Loss: (0.2782) |  Loss2: (0.0000) | Acc: (90.00%) (24387/27008)
Epoch: 74 | Batch_idx: 220 |  Loss: (0.2797) |  Loss2: (0.0000) | Acc: (90.00%) (25523/28288)
Epoch: 74 | Batch_idx: 230 |  Loss: (0.2806) |  Loss2: (0.0000) | Acc: (90.00%) (26669/29568)
Epoch: 74 | Batch_idx: 240 |  Loss: (0.2805) |  Loss2: (0.0000) | Acc: (90.00%) (27828/30848)
Epoch: 74 | Batch_idx: 250 |  Loss: (0.2804) |  Loss2: (0.0000) | Acc: (90.00%) (28984/32128)
Epoch: 74 | Batch_idx: 260 |  Loss: (0.2821) |  Loss2: (0.0000) | Acc: (90.00%) (30127/33408)
Epoch: 74 | Batch_idx: 270 |  Loss: (0.2819) |  Loss2: (0.0000) | Acc: (90.00%) (31287/34688)
Epoch: 74 | Batch_idx: 280 |  Loss: (0.2824) |  Loss2: (0.0000) | Acc: (90.00%) (32438/35968)
Epoch: 74 | Batch_idx: 290 |  Loss: (0.2827) |  Loss2: (0.0000) | Acc: (90.00%) (33584/37248)
Epoch: 74 | Batch_idx: 300 |  Loss: (0.2828) |  Loss2: (0.0000) | Acc: (90.00%) (34737/38528)
Epoch: 74 | Batch_idx: 310 |  Loss: (0.2835) |  Loss2: (0.0000) | Acc: (90.00%) (35879/39808)
Epoch: 74 | Batch_idx: 320 |  Loss: (0.2844) |  Loss2: (0.0000) | Acc: (90.00%) (37017/41088)
Epoch: 74 | Batch_idx: 330 |  Loss: (0.2833) |  Loss2: (0.0000) | Acc: (90.00%) (38187/42368)
Epoch: 74 | Batch_idx: 340 |  Loss: (0.2840) |  Loss2: (0.0000) | Acc: (90.00%) (39344/43648)
Epoch: 74 | Batch_idx: 350 |  Loss: (0.2837) |  Loss2: (0.0000) | Acc: (90.00%) (40497/44928)
Epoch: 74 | Batch_idx: 360 |  Loss: (0.2841) |  Loss2: (0.0000) | Acc: (90.00%) (41649/46208)
Epoch: 74 | Batch_idx: 370 |  Loss: (0.2841) |  Loss2: (0.0000) | Acc: (90.00%) (42810/47488)
Epoch: 74 | Batch_idx: 380 |  Loss: (0.2833) |  Loss2: (0.0000) | Acc: (90.00%) (43970/48768)
Epoch: 74 | Batch_idx: 390 |  Loss: (0.2830) |  Loss2: (0.0000) | Acc: (90.00%) (45089/50000)
# TEST : Loss: (0.4604) | Acc: (84.00%) (8466/10000)
percent tensor([0.5294, 0.5198, 0.5344, 0.5339, 0.5326, 0.5331, 0.5251, 0.5321, 0.5312,
        0.5238, 0.5275, 0.5267, 0.5256, 0.5220, 0.5263, 0.5284],
       device='cuda:0') torch.Size([16])
percent tensor([0.5427, 0.5512, 0.5405, 0.5446, 0.5436, 0.5559, 0.5476, 0.5414, 0.5374,
        0.5418, 0.5405, 0.5405, 0.5403, 0.5469, 0.5523, 0.5460],
       device='cuda:0') torch.Size([16])
percent tensor([0.5462, 0.5712, 0.5409, 0.4736, 0.5319, 0.4804, 0.5672, 0.5318, 0.5231,
        0.5571, 0.5364, 0.5680, 0.6097, 0.4316, 0.5540, 0.5117],
       device='cuda:0') torch.Size([16])
percent tensor([0.6457, 0.6832, 0.6408, 0.6521, 0.6447, 0.6501, 0.6702, 0.6331, 0.6720,
        0.6843, 0.7109, 0.6894, 0.6836, 0.6887, 0.6659, 0.6658],
       device='cuda:0') torch.Size([16])
percent tensor([0.6073, 0.5915, 0.6500, 0.5964, 0.6227, 0.7266, 0.6273, 0.5895, 0.6510,
        0.6069, 0.6192, 0.6073, 0.6400, 0.6527, 0.6309, 0.6398],
       device='cuda:0') torch.Size([16])
percent tensor([0.5087, 0.6019, 0.5450, 0.5236, 0.5298, 0.5468, 0.5389, 0.4444, 0.6118,
        0.5592, 0.6206, 0.6084, 0.5839, 0.6669, 0.4502, 0.4986],
       device='cuda:0') torch.Size([16])
percent tensor([0.5378, 0.6239, 0.7805, 0.7354, 0.8130, 0.6592, 0.6620, 0.7454, 0.6597,
        0.6273, 0.6428, 0.7346, 0.5608, 0.6852, 0.6295, 0.6283],
       device='cuda:0') torch.Size([16])
percent tensor([0.9991, 0.9974, 0.9988, 0.9986, 0.9984, 0.9977, 0.9978, 0.9990, 0.9978,
        0.9980, 0.9984, 0.9985, 0.9971, 0.9975, 0.9981, 0.9987],
       device='cuda:0') torch.Size([16])
False Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=128, out_features=16, bias=False)
True Linear(in_features=16, out_features=2, bias=False)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=128, out_features=16, bias=False)
True Linear(in_features=16, out_features=2, bias=False)
False Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=256, out_features=32, bias=False)
True Linear(in_features=32, out_features=2, bias=False)
False Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=256, out_features=32, bias=False)
True Linear(in_features=32, out_features=2, bias=False)
False Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=512, out_features=64, bias=False)
True Linear(in_features=64, out_features=2, bias=False)
False Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=512, out_features=64, bias=False)
True Linear(in_features=64, out_features=2, bias=False)
False Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1024, out_features=128, bias=False)
True Linear(in_features=128, out_features=2, bias=False)
False Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1024, out_features=128, bias=False)
True Linear(in_features=128, out_features=2, bias=False)
False Linear(in_features=512, out_features=10, bias=True)
Epoch: 75 | Batch_idx: 0 |  Loss: (0.3572) |  Loss2: (0.0000) | Acc: (87.00%) (112/128)
Epoch: 75 | Batch_idx: 10 |  Loss: (0.3217) |  Loss2: (0.0000) | Acc: (88.00%) (1251/1408)
Epoch: 75 | Batch_idx: 20 |  Loss: (0.3691) |  Loss2: (0.0000) | Acc: (87.00%) (2347/2688)
Epoch: 75 | Batch_idx: 30 |  Loss: (0.3730) |  Loss2: (0.0000) | Acc: (86.00%) (3452/3968)
Epoch: 75 | Batch_idx: 40 |  Loss: (0.3774) |  Loss2: (0.0000) | Acc: (86.00%) (4562/5248)
Epoch: 75 | Batch_idx: 50 |  Loss: (0.3710) |  Loss2: (0.0000) | Acc: (87.00%) (5688/6528)
Epoch: 75 | Batch_idx: 60 |  Loss: (0.3729) |  Loss2: (0.0000) | Acc: (87.00%) (6798/7808)
Epoch: 75 | Batch_idx: 70 |  Loss: (0.3726) |  Loss2: (0.0000) | Acc: (86.00%) (7900/9088)
Epoch: 75 | Batch_idx: 80 |  Loss: (0.3710) |  Loss2: (0.0000) | Acc: (86.00%) (9019/10368)
Epoch: 75 | Batch_idx: 90 |  Loss: (0.3725) |  Loss2: (0.0000) | Acc: (86.00%) (10133/11648)
Epoch: 75 | Batch_idx: 100 |  Loss: (0.3706) |  Loss2: (0.0000) | Acc: (87.00%) (11256/12928)
Epoch: 75 | Batch_idx: 110 |  Loss: (0.3671) |  Loss2: (0.0000) | Acc: (87.00%) (12390/14208)
Epoch: 75 | Batch_idx: 120 |  Loss: (0.3623) |  Loss2: (0.0000) | Acc: (87.00%) (13528/15488)
Epoch: 75 | Batch_idx: 130 |  Loss: (0.3616) |  Loss2: (0.0000) | Acc: (87.00%) (14648/16768)
Epoch: 75 | Batch_idx: 140 |  Loss: (0.3629) |  Loss2: (0.0000) | Acc: (87.00%) (15749/18048)
Epoch: 75 | Batch_idx: 150 |  Loss: (0.3616) |  Loss2: (0.0000) | Acc: (87.00%) (16864/19328)
Epoch: 75 | Batch_idx: 160 |  Loss: (0.3579) |  Loss2: (0.0000) | Acc: (87.00%) (18012/20608)
Epoch: 75 | Batch_idx: 170 |  Loss: (0.3577) |  Loss2: (0.0000) | Acc: (87.00%) (19127/21888)
Epoch: 75 | Batch_idx: 180 |  Loss: (0.3559) |  Loss2: (0.0000) | Acc: (87.00%) (20260/23168)
Epoch: 75 | Batch_idx: 190 |  Loss: (0.3560) |  Loss2: (0.0000) | Acc: (87.00%) (21398/24448)
Epoch: 75 | Batch_idx: 200 |  Loss: (0.3556) |  Loss2: (0.0000) | Acc: (87.00%) (22526/25728)
Epoch: 75 | Batch_idx: 210 |  Loss: (0.3557) |  Loss2: (0.0000) | Acc: (87.00%) (23650/27008)
Epoch: 75 | Batch_idx: 220 |  Loss: (0.3549) |  Loss2: (0.0000) | Acc: (87.00%) (24779/28288)
Epoch: 75 | Batch_idx: 230 |  Loss: (0.3540) |  Loss2: (0.0000) | Acc: (87.00%) (25900/29568)
Epoch: 75 | Batch_idx: 240 |  Loss: (0.3549) |  Loss2: (0.0000) | Acc: (87.00%) (27018/30848)
Epoch: 75 | Batch_idx: 250 |  Loss: (0.3528) |  Loss2: (0.0000) | Acc: (87.00%) (28164/32128)
Epoch: 75 | Batch_idx: 260 |  Loss: (0.3532) |  Loss2: (0.0000) | Acc: (87.00%) (29279/33408)
Epoch: 75 | Batch_idx: 270 |  Loss: (0.3536) |  Loss2: (0.0000) | Acc: (87.00%) (30393/34688)
Epoch: 75 | Batch_idx: 280 |  Loss: (0.3524) |  Loss2: (0.0000) | Acc: (87.00%) (31528/35968)
Epoch: 75 | Batch_idx: 290 |  Loss: (0.3513) |  Loss2: (0.0000) | Acc: (87.00%) (32664/37248)
Epoch: 75 | Batch_idx: 300 |  Loss: (0.3500) |  Loss2: (0.0000) | Acc: (87.00%) (33797/38528)
Epoch: 75 | Batch_idx: 310 |  Loss: (0.3483) |  Loss2: (0.0000) | Acc: (87.00%) (34944/39808)
Epoch: 75 | Batch_idx: 320 |  Loss: (0.3487) |  Loss2: (0.0000) | Acc: (87.00%) (36071/41088)
Epoch: 75 | Batch_idx: 330 |  Loss: (0.3485) |  Loss2: (0.0000) | Acc: (87.00%) (37203/42368)
Epoch: 75 | Batch_idx: 340 |  Loss: (0.3480) |  Loss2: (0.0000) | Acc: (87.00%) (38331/43648)
Epoch: 75 | Batch_idx: 350 |  Loss: (0.3479) |  Loss2: (0.0000) | Acc: (87.00%) (39460/44928)
Epoch: 75 | Batch_idx: 360 |  Loss: (0.3475) |  Loss2: (0.0000) | Acc: (87.00%) (40588/46208)
Epoch: 75 | Batch_idx: 370 |  Loss: (0.3467) |  Loss2: (0.0000) | Acc: (87.00%) (41725/47488)
Epoch: 75 | Batch_idx: 380 |  Loss: (0.3455) |  Loss2: (0.0000) | Acc: (87.00%) (42874/48768)
Epoch: 75 | Batch_idx: 390 |  Loss: (0.3449) |  Loss2: (0.0000) | Acc: (87.00%) (43966/50000)
=> saving checkpoint 'drive/app/torch/save_Routing_Gate_2/checkpoint_075.pth.tar'
# TEST : Loss: (0.4445) | Acc: (85.00%) (8548/10000)
percent tensor([0.5294, 0.5204, 0.5354, 0.5352, 0.5336, 0.5329, 0.5257, 0.5344, 0.5315,
        0.5249, 0.5272, 0.5278, 0.5256, 0.5220, 0.5267, 0.5287],
       device='cuda:0') torch.Size([16])
percent tensor([0.5387, 0.5474, 0.5345, 0.5382, 0.5367, 0.5488, 0.5433, 0.5372, 0.5338,
        0.5386, 0.5373, 0.5354, 0.5373, 0.5443, 0.5466, 0.5415],
       device='cuda:0') torch.Size([16])
percent tensor([0.5868, 0.6092, 0.5771, 0.4940, 0.5549, 0.5021, 0.5997, 0.5465, 0.5561,
        0.5975, 0.5866, 0.6082, 0.6471, 0.4852, 0.5898, 0.5427],
       device='cuda:0') torch.Size([16])
percent tensor([0.6700, 0.7047, 0.6626, 0.6780, 0.6704, 0.6710, 0.6959, 0.6597, 0.6946,
        0.7072, 0.7314, 0.7135, 0.6991, 0.7159, 0.6892, 0.6895],
       device='cuda:0') torch.Size([16])
percent tensor([0.6159, 0.6203, 0.6566, 0.5928, 0.6273, 0.7413, 0.6378, 0.5708, 0.6729,
        0.6399, 0.6613, 0.6195, 0.6705, 0.6959, 0.6218, 0.6721],
       device='cuda:0') torch.Size([16])
percent tensor([0.4921, 0.5804, 0.5191, 0.5192, 0.5210, 0.5460, 0.5335, 0.4265, 0.5804,
        0.5364, 0.5961, 0.5753, 0.5611, 0.6582, 0.4367, 0.4882],
       device='cuda:0') torch.Size([16])
percent tensor([0.5615, 0.6505, 0.7725, 0.7564, 0.8071, 0.6782, 0.6673, 0.7419, 0.7085,
        0.6437, 0.6707, 0.7560, 0.5764, 0.7108, 0.6594, 0.6344],
       device='cuda:0') torch.Size([16])
percent tensor([0.9993, 0.9977, 0.9988, 0.9987, 0.9983, 0.9981, 0.9983, 0.9990, 0.9979,
        0.9981, 0.9985, 0.9988, 0.9977, 0.9979, 0.9982, 0.9991],
       device='cuda:0') torch.Size([16])
Epoch: 76 | Batch_idx: 0 |  Loss: (0.4488) |  Loss2: (0.0000) | Acc: (85.00%) (109/128)
Epoch: 76 | Batch_idx: 10 |  Loss: (0.2930) |  Loss2: (0.0000) | Acc: (90.00%) (1270/1408)
Epoch: 76 | Batch_idx: 20 |  Loss: (0.3122) |  Loss2: (0.0000) | Acc: (89.00%) (2399/2688)
Epoch: 76 | Batch_idx: 30 |  Loss: (0.3270) |  Loss2: (0.0000) | Acc: (88.00%) (3525/3968)
Epoch: 76 | Batch_idx: 40 |  Loss: (0.3213) |  Loss2: (0.0000) | Acc: (88.00%) (4664/5248)
Epoch: 76 | Batch_idx: 50 |  Loss: (0.3155) |  Loss2: (0.0000) | Acc: (88.00%) (5808/6528)
Epoch: 76 | Batch_idx: 60 |  Loss: (0.3147) |  Loss2: (0.0000) | Acc: (88.00%) (6948/7808)
Epoch: 76 | Batch_idx: 70 |  Loss: (0.3176) |  Loss2: (0.0000) | Acc: (88.00%) (8075/9088)
Epoch: 76 | Batch_idx: 80 |  Loss: (0.3163) |  Loss2: (0.0000) | Acc: (89.00%) (9229/10368)
Epoch: 76 | Batch_idx: 90 |  Loss: (0.3173) |  Loss2: (0.0000) | Acc: (88.00%) (10363/11648)
Epoch: 76 | Batch_idx: 100 |  Loss: (0.3156) |  Loss2: (0.0000) | Acc: (89.00%) (11515/12928)
Epoch: 76 | Batch_idx: 110 |  Loss: (0.3119) |  Loss2: (0.0000) | Acc: (89.00%) (12679/14208)
Epoch: 76 | Batch_idx: 120 |  Loss: (0.3084) |  Loss2: (0.0000) | Acc: (89.00%) (13849/15488)
Epoch: 76 | Batch_idx: 130 |  Loss: (0.3063) |  Loss2: (0.0000) | Acc: (89.00%) (15018/16768)
Epoch: 76 | Batch_idx: 140 |  Loss: (0.3056) |  Loss2: (0.0000) | Acc: (89.00%) (16166/18048)
Epoch: 76 | Batch_idx: 150 |  Loss: (0.3054) |  Loss2: (0.0000) | Acc: (89.00%) (17317/19328)
Epoch: 76 | Batch_idx: 160 |  Loss: (0.3049) |  Loss2: (0.0000) | Acc: (89.00%) (18466/20608)
Epoch: 76 | Batch_idx: 170 |  Loss: (0.3043) |  Loss2: (0.0000) | Acc: (89.00%) (19619/21888)
Epoch: 76 | Batch_idx: 180 |  Loss: (0.3029) |  Loss2: (0.0000) | Acc: (89.00%) (20775/23168)
Epoch: 76 | Batch_idx: 190 |  Loss: (0.3034) |  Loss2: (0.0000) | Acc: (89.00%) (21923/24448)
Epoch: 76 | Batch_idx: 200 |  Loss: (0.3032) |  Loss2: (0.0000) | Acc: (89.00%) (23067/25728)
Epoch: 76 | Batch_idx: 210 |  Loss: (0.3020) |  Loss2: (0.0000) | Acc: (89.00%) (24221/27008)
Epoch: 76 | Batch_idx: 220 |  Loss: (0.3019) |  Loss2: (0.0000) | Acc: (89.00%) (25366/28288)
Epoch: 76 | Batch_idx: 230 |  Loss: (0.3026) |  Loss2: (0.0000) | Acc: (89.00%) (26508/29568)
Epoch: 76 | Batch_idx: 240 |  Loss: (0.3025) |  Loss2: (0.0000) | Acc: (89.00%) (27658/30848)
Epoch: 76 | Batch_idx: 250 |  Loss: (0.3024) |  Loss2: (0.0000) | Acc: (89.00%) (28809/32128)
Epoch: 76 | Batch_idx: 260 |  Loss: (0.3024) |  Loss2: (0.0000) | Acc: (89.00%) (29957/33408)
Epoch: 76 | Batch_idx: 270 |  Loss: (0.3038) |  Loss2: (0.0000) | Acc: (89.00%) (31089/34688)
Epoch: 76 | Batch_idx: 280 |  Loss: (0.3028) |  Loss2: (0.0000) | Acc: (89.00%) (32248/35968)
Epoch: 76 | Batch_idx: 290 |  Loss: (0.3025) |  Loss2: (0.0000) | Acc: (89.00%) (33399/37248)
Epoch: 76 | Batch_idx: 300 |  Loss: (0.3018) |  Loss2: (0.0000) | Acc: (89.00%) (34556/38528)
Epoch: 76 | Batch_idx: 310 |  Loss: (0.3017) |  Loss2: (0.0000) | Acc: (89.00%) (35695/39808)
Epoch: 76 | Batch_idx: 320 |  Loss: (0.3007) |  Loss2: (0.0000) | Acc: (89.00%) (36865/41088)
Epoch: 76 | Batch_idx: 330 |  Loss: (0.3011) |  Loss2: (0.0000) | Acc: (89.00%) (37995/42368)
Epoch: 76 | Batch_idx: 340 |  Loss: (0.3005) |  Loss2: (0.0000) | Acc: (89.00%) (39146/43648)
Epoch: 76 | Batch_idx: 350 |  Loss: (0.2992) |  Loss2: (0.0000) | Acc: (89.00%) (40306/44928)
Epoch: 76 | Batch_idx: 360 |  Loss: (0.2995) |  Loss2: (0.0000) | Acc: (89.00%) (41451/46208)
Epoch: 76 | Batch_idx: 370 |  Loss: (0.2992) |  Loss2: (0.0000) | Acc: (89.00%) (42616/47488)
Epoch: 76 | Batch_idx: 380 |  Loss: (0.3000) |  Loss2: (0.0000) | Acc: (89.00%) (43744/48768)
Epoch: 76 | Batch_idx: 390 |  Loss: (0.2998) |  Loss2: (0.0000) | Acc: (89.00%) (44859/50000)
# TEST : Loss: (0.4250) | Acc: (85.00%) (8583/10000)
percent tensor([0.5284, 0.5191, 0.5357, 0.5350, 0.5338, 0.5318, 0.5248, 0.5341, 0.5308,
        0.5242, 0.5260, 0.5279, 0.5246, 0.5207, 0.5254, 0.5275],
       device='cuda:0') torch.Size([16])
percent tensor([0.5389, 0.5483, 0.5339, 0.5367, 0.5358, 0.5472, 0.5437, 0.5369, 0.5344,
        0.5393, 0.5380, 0.5351, 0.5380, 0.5456, 0.5462, 0.5412],
       device='cuda:0') torch.Size([16])
percent tensor([0.5851, 0.6105, 0.5704, 0.4916, 0.5458, 0.4933, 0.6011, 0.5468, 0.5586,
        0.5985, 0.5894, 0.6075, 0.6476, 0.4969, 0.5875, 0.5394],
       device='cuda:0') torch.Size([16])
percent tensor([0.6691, 0.7032, 0.6623, 0.6777, 0.6694, 0.6691, 0.6957, 0.6604, 0.6960,
        0.7050, 0.7307, 0.7110, 0.6976, 0.7171, 0.6871, 0.6881],
       device='cuda:0') torch.Size([16])
percent tensor([0.6124, 0.6299, 0.6509, 0.5885, 0.6211, 0.7387, 0.6376, 0.5569, 0.6768,
        0.6473, 0.6739, 0.6155, 0.6774, 0.7092, 0.6089, 0.6786],
       device='cuda:0') torch.Size([16])
percent tensor([0.5139, 0.5938, 0.5357, 0.5339, 0.5403, 0.5646, 0.5505, 0.4537, 0.5950,
        0.5536, 0.6135, 0.5862, 0.5786, 0.6655, 0.4595, 0.5219],
       device='cuda:0') torch.Size([16])
percent tensor([0.5806, 0.6661, 0.7861, 0.7675, 0.8151, 0.6905, 0.6726, 0.7456, 0.7181,
        0.6502, 0.6878, 0.7712, 0.5983, 0.7225, 0.6765, 0.6395],
       device='cuda:0') torch.Size([16])
percent tensor([0.9993, 0.9976, 0.9988, 0.9987, 0.9984, 0.9982, 0.9983, 0.9991, 0.9979,
        0.9981, 0.9986, 0.9987, 0.9979, 0.9978, 0.9982, 0.9992],
       device='cuda:0') torch.Size([16])
Epoch: 77 | Batch_idx: 0 |  Loss: (0.3387) |  Loss2: (0.0000) | Acc: (87.00%) (112/128)
Epoch: 77 | Batch_idx: 10 |  Loss: (0.2929) |  Loss2: (0.0000) | Acc: (89.00%) (1261/1408)
Epoch: 77 | Batch_idx: 20 |  Loss: (0.2821) |  Loss2: (0.0000) | Acc: (90.00%) (2422/2688)
Epoch: 77 | Batch_idx: 30 |  Loss: (0.2826) |  Loss2: (0.0000) | Acc: (90.00%) (3575/3968)
Epoch: 77 | Batch_idx: 40 |  Loss: (0.2804) |  Loss2: (0.0000) | Acc: (90.00%) (4746/5248)
Epoch: 77 | Batch_idx: 50 |  Loss: (0.2848) |  Loss2: (0.0000) | Acc: (90.00%) (5898/6528)
Epoch: 77 | Batch_idx: 60 |  Loss: (0.2824) |  Loss2: (0.0000) | Acc: (90.00%) (7057/7808)
Epoch: 77 | Batch_idx: 70 |  Loss: (0.2811) |  Loss2: (0.0000) | Acc: (90.00%) (8223/9088)
Epoch: 77 | Batch_idx: 80 |  Loss: (0.2833) |  Loss2: (0.0000) | Acc: (90.00%) (9378/10368)
Epoch: 77 | Batch_idx: 90 |  Loss: (0.2818) |  Loss2: (0.0000) | Acc: (90.00%) (10545/11648)
Epoch: 77 | Batch_idx: 100 |  Loss: (0.2809) |  Loss2: (0.0000) | Acc: (90.00%) (11698/12928)
Epoch: 77 | Batch_idx: 110 |  Loss: (0.2802) |  Loss2: (0.0000) | Acc: (90.00%) (12859/14208)
Epoch: 77 | Batch_idx: 120 |  Loss: (0.2830) |  Loss2: (0.0000) | Acc: (90.00%) (14005/15488)
Epoch: 77 | Batch_idx: 130 |  Loss: (0.2818) |  Loss2: (0.0000) | Acc: (90.00%) (15171/16768)
Epoch: 77 | Batch_idx: 140 |  Loss: (0.2815) |  Loss2: (0.0000) | Acc: (90.00%) (16326/18048)
Epoch: 77 | Batch_idx: 150 |  Loss: (0.2791) |  Loss2: (0.0000) | Acc: (90.00%) (17497/19328)
Epoch: 77 | Batch_idx: 160 |  Loss: (0.2800) |  Loss2: (0.0000) | Acc: (90.00%) (18647/20608)
Epoch: 77 | Batch_idx: 170 |  Loss: (0.2814) |  Loss2: (0.0000) | Acc: (90.00%) (19796/21888)
Epoch: 77 | Batch_idx: 180 |  Loss: (0.2809) |  Loss2: (0.0000) | Acc: (90.00%) (20953/23168)
Epoch: 77 | Batch_idx: 190 |  Loss: (0.2816) |  Loss2: (0.0000) | Acc: (90.00%) (22105/24448)
Epoch: 77 | Batch_idx: 200 |  Loss: (0.2812) |  Loss2: (0.0000) | Acc: (90.00%) (23262/25728)
Epoch: 77 | Batch_idx: 210 |  Loss: (0.2837) |  Loss2: (0.0000) | Acc: (90.00%) (24393/27008)
Epoch: 77 | Batch_idx: 220 |  Loss: (0.2842) |  Loss2: (0.0000) | Acc: (90.00%) (25546/28288)
Epoch: 77 | Batch_idx: 230 |  Loss: (0.2857) |  Loss2: (0.0000) | Acc: (90.00%) (26690/29568)
Epoch: 77 | Batch_idx: 240 |  Loss: (0.2856) |  Loss2: (0.0000) | Acc: (90.00%) (27845/30848)
Epoch: 77 | Batch_idx: 250 |  Loss: (0.2852) |  Loss2: (0.0000) | Acc: (90.00%) (29000/32128)
Epoch: 77 | Batch_idx: 260 |  Loss: (0.2858) |  Loss2: (0.0000) | Acc: (90.00%) (30151/33408)
Epoch: 77 | Batch_idx: 270 |  Loss: (0.2859) |  Loss2: (0.0000) | Acc: (90.00%) (31307/34688)
Epoch: 77 | Batch_idx: 280 |  Loss: (0.2864) |  Loss2: (0.0000) | Acc: (90.00%) (32452/35968)
Epoch: 77 | Batch_idx: 290 |  Loss: (0.2866) |  Loss2: (0.0000) | Acc: (90.00%) (33600/37248)
Epoch: 77 | Batch_idx: 300 |  Loss: (0.2870) |  Loss2: (0.0000) | Acc: (90.00%) (34745/38528)
Epoch: 77 | Batch_idx: 310 |  Loss: (0.2874) |  Loss2: (0.0000) | Acc: (90.00%) (35898/39808)
Epoch: 77 | Batch_idx: 320 |  Loss: (0.2872) |  Loss2: (0.0000) | Acc: (90.00%) (37050/41088)
Epoch: 77 | Batch_idx: 330 |  Loss: (0.2868) |  Loss2: (0.0000) | Acc: (90.00%) (38206/42368)
Epoch: 77 | Batch_idx: 340 |  Loss: (0.2862) |  Loss2: (0.0000) | Acc: (90.00%) (39381/43648)
Epoch: 77 | Batch_idx: 350 |  Loss: (0.2864) |  Loss2: (0.0000) | Acc: (90.00%) (40523/44928)
Epoch: 77 | Batch_idx: 360 |  Loss: (0.2865) |  Loss2: (0.0000) | Acc: (90.00%) (41688/46208)
Epoch: 77 | Batch_idx: 370 |  Loss: (0.2869) |  Loss2: (0.0000) | Acc: (90.00%) (42842/47488)
Epoch: 77 | Batch_idx: 380 |  Loss: (0.2864) |  Loss2: (0.0000) | Acc: (90.00%) (44006/48768)
Epoch: 77 | Batch_idx: 390 |  Loss: (0.2859) |  Loss2: (0.0000) | Acc: (90.00%) (45125/50000)
# TEST : Loss: (0.4094) | Acc: (86.00%) (8636/10000)
percent tensor([0.5293, 0.5195, 0.5379, 0.5368, 0.5358, 0.5329, 0.5257, 0.5358, 0.5320,
        0.5252, 0.5265, 0.5296, 0.5252, 0.5212, 0.5262, 0.5284],
       device='cuda:0') torch.Size([16])
percent tensor([0.5386, 0.5484, 0.5328, 0.5354, 0.5345, 0.5457, 0.5433, 0.5362, 0.5343,
        0.5392, 0.5380, 0.5344, 0.5380, 0.5460, 0.5454, 0.5407],
       device='cuda:0') torch.Size([16])
percent tensor([0.5795, 0.6076, 0.5624, 0.4832, 0.5371, 0.4824, 0.5986, 0.5416, 0.5560,
        0.5947, 0.5876, 0.6047, 0.6445, 0.4972, 0.5825, 0.5311],
       device='cuda:0') torch.Size([16])
percent tensor([0.6770, 0.7097, 0.6710, 0.6857, 0.6773, 0.6758, 0.7030, 0.6701, 0.7045,
        0.7115, 0.7378, 0.7174, 0.7041, 0.7245, 0.6939, 0.6951],
       device='cuda:0') torch.Size([16])
percent tensor([0.6227, 0.6443, 0.6560, 0.5961, 0.6274, 0.7462, 0.6502, 0.5659, 0.6913,
        0.6652, 0.6925, 0.6252, 0.6906, 0.7242, 0.6152, 0.6917],
       device='cuda:0') torch.Size([16])
percent tensor([0.5147, 0.5932, 0.5398, 0.5352, 0.5418, 0.5689, 0.5487, 0.4497, 0.5974,
        0.5545, 0.6191, 0.5897, 0.5802, 0.6645, 0.4558, 0.5267],
       device='cuda:0') torch.Size([16])
percent tensor([0.5681, 0.6597, 0.7847, 0.7627, 0.8130, 0.6860, 0.6604, 0.7329, 0.7135,
        0.6427, 0.6797, 0.7670, 0.5908, 0.7139, 0.6720, 0.6232],
       device='cuda:0') torch.Size([16])
percent tensor([0.9994, 0.9978, 0.9989, 0.9988, 0.9986, 0.9983, 0.9984, 0.9991, 0.9980,
        0.9982, 0.9987, 0.9987, 0.9980, 0.9978, 0.9983, 0.9993],
       device='cuda:0') torch.Size([16])
Epoch: 78 | Batch_idx: 0 |  Loss: (0.3056) |  Loss2: (0.0000) | Acc: (89.00%) (114/128)
Epoch: 78 | Batch_idx: 10 |  Loss: (0.2982) |  Loss2: (0.0000) | Acc: (89.00%) (1257/1408)
Epoch: 78 | Batch_idx: 20 |  Loss: (0.2913) |  Loss2: (0.0000) | Acc: (89.00%) (2417/2688)
Epoch: 78 | Batch_idx: 30 |  Loss: (0.2845) |  Loss2: (0.0000) | Acc: (90.00%) (3572/3968)
Epoch: 78 | Batch_idx: 40 |  Loss: (0.2862) |  Loss2: (0.0000) | Acc: (90.00%) (4726/5248)
Epoch: 78 | Batch_idx: 50 |  Loss: (0.2817) |  Loss2: (0.0000) | Acc: (90.00%) (5889/6528)
Epoch: 78 | Batch_idx: 60 |  Loss: (0.2785) |  Loss2: (0.0000) | Acc: (90.00%) (7063/7808)
Epoch: 78 | Batch_idx: 70 |  Loss: (0.2828) |  Loss2: (0.0000) | Acc: (90.00%) (8210/9088)
Epoch: 78 | Batch_idx: 80 |  Loss: (0.2830) |  Loss2: (0.0000) | Acc: (90.00%) (9366/10368)
Epoch: 78 | Batch_idx: 90 |  Loss: (0.2820) |  Loss2: (0.0000) | Acc: (90.00%) (10535/11648)
Epoch: 78 | Batch_idx: 100 |  Loss: (0.2814) |  Loss2: (0.0000) | Acc: (90.00%) (11696/12928)
Epoch: 78 | Batch_idx: 110 |  Loss: (0.2816) |  Loss2: (0.0000) | Acc: (90.00%) (12865/14208)
Epoch: 78 | Batch_idx: 120 |  Loss: (0.2807) |  Loss2: (0.0000) | Acc: (90.00%) (14029/15488)
Epoch: 78 | Batch_idx: 130 |  Loss: (0.2819) |  Loss2: (0.0000) | Acc: (90.00%) (15182/16768)
Epoch: 78 | Batch_idx: 140 |  Loss: (0.2818) |  Loss2: (0.0000) | Acc: (90.00%) (16337/18048)
Epoch: 78 | Batch_idx: 150 |  Loss: (0.2795) |  Loss2: (0.0000) | Acc: (90.00%) (17510/19328)
Epoch: 78 | Batch_idx: 160 |  Loss: (0.2796) |  Loss2: (0.0000) | Acc: (90.00%) (18659/20608)
Epoch: 78 | Batch_idx: 170 |  Loss: (0.2796) |  Loss2: (0.0000) | Acc: (90.00%) (19820/21888)
Epoch: 78 | Batch_idx: 180 |  Loss: (0.2790) |  Loss2: (0.0000) | Acc: (90.00%) (20986/23168)
Epoch: 78 | Batch_idx: 190 |  Loss: (0.2794) |  Loss2: (0.0000) | Acc: (90.00%) (22132/24448)
Epoch: 78 | Batch_idx: 200 |  Loss: (0.2796) |  Loss2: (0.0000) | Acc: (90.00%) (23287/25728)
Epoch: 78 | Batch_idx: 210 |  Loss: (0.2800) |  Loss2: (0.0000) | Acc: (90.00%) (24441/27008)
Epoch: 78 | Batch_idx: 220 |  Loss: (0.2816) |  Loss2: (0.0000) | Acc: (90.00%) (25571/28288)
Epoch: 78 | Batch_idx: 230 |  Loss: (0.2800) |  Loss2: (0.0000) | Acc: (90.00%) (26745/29568)
Epoch: 78 | Batch_idx: 240 |  Loss: (0.2796) |  Loss2: (0.0000) | Acc: (90.00%) (27912/30848)
Epoch: 78 | Batch_idx: 250 |  Loss: (0.2796) |  Loss2: (0.0000) | Acc: (90.00%) (29069/32128)
Epoch: 78 | Batch_idx: 260 |  Loss: (0.2801) |  Loss2: (0.0000) | Acc: (90.00%) (30209/33408)
Epoch: 78 | Batch_idx: 270 |  Loss: (0.2804) |  Loss2: (0.0000) | Acc: (90.00%) (31359/34688)
Epoch: 78 | Batch_idx: 280 |  Loss: (0.2803) |  Loss2: (0.0000) | Acc: (90.00%) (32521/35968)
Epoch: 78 | Batch_idx: 290 |  Loss: (0.2799) |  Loss2: (0.0000) | Acc: (90.00%) (33681/37248)
Epoch: 78 | Batch_idx: 300 |  Loss: (0.2801) |  Loss2: (0.0000) | Acc: (90.00%) (34833/38528)
Epoch: 78 | Batch_idx: 310 |  Loss: (0.2805) |  Loss2: (0.0000) | Acc: (90.00%) (35980/39808)
Epoch: 78 | Batch_idx: 320 |  Loss: (0.2796) |  Loss2: (0.0000) | Acc: (90.00%) (37147/41088)
Epoch: 78 | Batch_idx: 330 |  Loss: (0.2791) |  Loss2: (0.0000) | Acc: (90.00%) (38317/42368)
Epoch: 78 | Batch_idx: 340 |  Loss: (0.2791) |  Loss2: (0.0000) | Acc: (90.00%) (39477/43648)
Epoch: 78 | Batch_idx: 350 |  Loss: (0.2778) |  Loss2: (0.0000) | Acc: (90.00%) (40651/44928)
Epoch: 78 | Batch_idx: 360 |  Loss: (0.2781) |  Loss2: (0.0000) | Acc: (90.00%) (41803/46208)
Epoch: 78 | Batch_idx: 370 |  Loss: (0.2789) |  Loss2: (0.0000) | Acc: (90.00%) (42947/47488)
Epoch: 78 | Batch_idx: 380 |  Loss: (0.2785) |  Loss2: (0.0000) | Acc: (90.00%) (44116/48768)
Epoch: 78 | Batch_idx: 390 |  Loss: (0.2779) |  Loss2: (0.0000) | Acc: (90.00%) (45242/50000)
# TEST : Loss: (0.4023) | Acc: (86.00%) (8662/10000)
percent tensor([0.5288, 0.5186, 0.5381, 0.5370, 0.5359, 0.5324, 0.5251, 0.5357, 0.5316,
        0.5247, 0.5258, 0.5295, 0.5246, 0.5205, 0.5255, 0.5279],
       device='cuda:0') torch.Size([16])
percent tensor([0.5398, 0.5500, 0.5336, 0.5358, 0.5352, 0.5461, 0.5447, 0.5373, 0.5356,
        0.5406, 0.5394, 0.5354, 0.5394, 0.5476, 0.5464, 0.5416],
       device='cuda:0') torch.Size([16])
percent tensor([0.5765, 0.6040, 0.5575, 0.4819, 0.5340, 0.4797, 0.5976, 0.5407, 0.5554,
        0.5904, 0.5846, 0.6019, 0.6391, 0.5012, 0.5799, 0.5278],
       device='cuda:0') torch.Size([16])
percent tensor([0.6691, 0.7007, 0.6642, 0.6785, 0.6701, 0.6685, 0.6952, 0.6636, 0.6974,
        0.7023, 0.7291, 0.7081, 0.6951, 0.7166, 0.6854, 0.6869],
       device='cuda:0') torch.Size([16])
percent tensor([0.6165, 0.6419, 0.6512, 0.5930, 0.6243, 0.7377, 0.6483, 0.5648, 0.6903,
        0.6623, 0.6898, 0.6203, 0.6865, 0.7229, 0.6069, 0.6883],
       device='cuda:0') torch.Size([16])
percent tensor([0.5165, 0.5932, 0.5408, 0.5347, 0.5429, 0.5718, 0.5496, 0.4482, 0.5993,
        0.5574, 0.6237, 0.5890, 0.5819, 0.6646, 0.4555, 0.5336],
       device='cuda:0') torch.Size([16])
percent tensor([0.5683, 0.6591, 0.7877, 0.7666, 0.8168, 0.6879, 0.6572, 0.7315, 0.7158,
        0.6399, 0.6812, 0.7702, 0.5898, 0.7133, 0.6754, 0.6177],
       device='cuda:0') torch.Size([16])
percent tensor([0.9994, 0.9979, 0.9990, 0.9989, 0.9987, 0.9984, 0.9985, 0.9992, 0.9981,
        0.9983, 0.9988, 0.9988, 0.9981, 0.9978, 0.9983, 0.9993],
       device='cuda:0') torch.Size([16])
Epoch: 79 | Batch_idx: 0 |  Loss: (0.3291) |  Loss2: (0.0000) | Acc: (87.00%) (112/128)
Epoch: 79 | Batch_idx: 10 |  Loss: (0.2808) |  Loss2: (0.0000) | Acc: (90.00%) (1274/1408)
Epoch: 79 | Batch_idx: 20 |  Loss: (0.2603) |  Loss2: (0.0000) | Acc: (91.00%) (2453/2688)
Epoch: 79 | Batch_idx: 30 |  Loss: (0.2654) |  Loss2: (0.0000) | Acc: (90.00%) (3608/3968)
Epoch: 79 | Batch_idx: 40 |  Loss: (0.2723) |  Loss2: (0.0000) | Acc: (90.00%) (4754/5248)
Epoch: 79 | Batch_idx: 50 |  Loss: (0.2733) |  Loss2: (0.0000) | Acc: (90.00%) (5911/6528)
Epoch: 79 | Batch_idx: 60 |  Loss: (0.2769) |  Loss2: (0.0000) | Acc: (90.00%) (7055/7808)
Epoch: 79 | Batch_idx: 70 |  Loss: (0.2764) |  Loss2: (0.0000) | Acc: (90.00%) (8216/9088)
Epoch: 79 | Batch_idx: 80 |  Loss: (0.2814) |  Loss2: (0.0000) | Acc: (90.00%) (9360/10368)
Epoch: 79 | Batch_idx: 90 |  Loss: (0.2758) |  Loss2: (0.0000) | Acc: (90.00%) (10540/11648)
Epoch: 79 | Batch_idx: 100 |  Loss: (0.2767) |  Loss2: (0.0000) | Acc: (90.00%) (11699/12928)
Epoch: 79 | Batch_idx: 110 |  Loss: (0.2761) |  Loss2: (0.0000) | Acc: (90.00%) (12861/14208)
Epoch: 79 | Batch_idx: 120 |  Loss: (0.2771) |  Loss2: (0.0000) | Acc: (90.00%) (14011/15488)
Epoch: 79 | Batch_idx: 130 |  Loss: (0.2778) |  Loss2: (0.0000) | Acc: (90.00%) (15168/16768)
Epoch: 79 | Batch_idx: 140 |  Loss: (0.2758) |  Loss2: (0.0000) | Acc: (90.00%) (16334/18048)
Epoch: 79 | Batch_idx: 150 |  Loss: (0.2739) |  Loss2: (0.0000) | Acc: (90.00%) (17515/19328)
Epoch: 79 | Batch_idx: 160 |  Loss: (0.2725) |  Loss2: (0.0000) | Acc: (90.00%) (18691/20608)
Epoch: 79 | Batch_idx: 170 |  Loss: (0.2733) |  Loss2: (0.0000) | Acc: (90.00%) (19845/21888)
Epoch: 79 | Batch_idx: 180 |  Loss: (0.2725) |  Loss2: (0.0000) | Acc: (90.00%) (20999/23168)
Epoch: 79 | Batch_idx: 190 |  Loss: (0.2731) |  Loss2: (0.0000) | Acc: (90.00%) (22153/24448)
Epoch: 79 | Batch_idx: 200 |  Loss: (0.2724) |  Loss2: (0.0000) | Acc: (90.00%) (23317/25728)
Epoch: 79 | Batch_idx: 210 |  Loss: (0.2732) |  Loss2: (0.0000) | Acc: (90.00%) (24476/27008)
Epoch: 79 | Batch_idx: 220 |  Loss: (0.2730) |  Loss2: (0.0000) | Acc: (90.00%) (25638/28288)
Epoch: 79 | Batch_idx: 230 |  Loss: (0.2724) |  Loss2: (0.0000) | Acc: (90.00%) (26815/29568)
Epoch: 79 | Batch_idx: 240 |  Loss: (0.2734) |  Loss2: (0.0000) | Acc: (90.00%) (27963/30848)
Epoch: 79 | Batch_idx: 250 |  Loss: (0.2721) |  Loss2: (0.0000) | Acc: (90.00%) (29145/32128)
Epoch: 79 | Batch_idx: 260 |  Loss: (0.2730) |  Loss2: (0.0000) | Acc: (90.00%) (30295/33408)
Epoch: 79 | Batch_idx: 270 |  Loss: (0.2730) |  Loss2: (0.0000) | Acc: (90.00%) (31450/34688)
Epoch: 79 | Batch_idx: 280 |  Loss: (0.2725) |  Loss2: (0.0000) | Acc: (90.00%) (32624/35968)
Epoch: 79 | Batch_idx: 290 |  Loss: (0.2721) |  Loss2: (0.0000) | Acc: (90.00%) (33792/37248)
Epoch: 79 | Batch_idx: 300 |  Loss: (0.2720) |  Loss2: (0.0000) | Acc: (90.00%) (34967/38528)
Epoch: 79 | Batch_idx: 310 |  Loss: (0.2721) |  Loss2: (0.0000) | Acc: (90.00%) (36114/39808)
Epoch: 79 | Batch_idx: 320 |  Loss: (0.2723) |  Loss2: (0.0000) | Acc: (90.00%) (37277/41088)
Epoch: 79 | Batch_idx: 330 |  Loss: (0.2723) |  Loss2: (0.0000) | Acc: (90.00%) (38432/42368)
Epoch: 79 | Batch_idx: 340 |  Loss: (0.2722) |  Loss2: (0.0000) | Acc: (90.00%) (39597/43648)
Epoch: 79 | Batch_idx: 350 |  Loss: (0.2715) |  Loss2: (0.0000) | Acc: (90.00%) (40781/44928)
Epoch: 79 | Batch_idx: 360 |  Loss: (0.2721) |  Loss2: (0.0000) | Acc: (90.00%) (41932/46208)
Epoch: 79 | Batch_idx: 370 |  Loss: (0.2714) |  Loss2: (0.0000) | Acc: (90.00%) (43101/47488)
Epoch: 79 | Batch_idx: 380 |  Loss: (0.2714) |  Loss2: (0.0000) | Acc: (90.00%) (44262/48768)
Epoch: 79 | Batch_idx: 390 |  Loss: (0.2714) |  Loss2: (0.0000) | Acc: (90.00%) (45366/50000)
# TEST : Loss: (0.3996) | Acc: (86.00%) (8651/10000)
percent tensor([0.5280, 0.5173, 0.5377, 0.5367, 0.5354, 0.5319, 0.5240, 0.5351, 0.5307,
        0.5238, 0.5247, 0.5288, 0.5236, 0.5195, 0.5245, 0.5270],
       device='cuda:0') torch.Size([16])
percent tensor([0.5420, 0.5525, 0.5356, 0.5374, 0.5371, 0.5477, 0.5472, 0.5396, 0.5381,
        0.5430, 0.5417, 0.5376, 0.5417, 0.5504, 0.5486, 0.5436],
       device='cuda:0') torch.Size([16])
percent tensor([0.5723, 0.5986, 0.5573, 0.4806, 0.5344, 0.4761, 0.5955, 0.5394, 0.5539,
        0.5863, 0.5800, 0.6017, 0.6339, 0.4990, 0.5761, 0.5230],
       device='cuda:0') torch.Size([16])
percent tensor([0.6723, 0.7034, 0.6675, 0.6813, 0.6724, 0.6714, 0.6984, 0.6675, 0.7005,
        0.7052, 0.7319, 0.7109, 0.6975, 0.7198, 0.6885, 0.6894],
       device='cuda:0') torch.Size([16])
percent tensor([0.6151, 0.6376, 0.6550, 0.5978, 0.6276, 0.7371, 0.6477, 0.5676, 0.6890,
        0.6582, 0.6873, 0.6216, 0.6827, 0.7200, 0.6055, 0.6858],
       device='cuda:0') torch.Size([16])
percent tensor([0.5263, 0.6024, 0.5511, 0.5434, 0.5521, 0.5813, 0.5598, 0.4560, 0.6085,
        0.5692, 0.6348, 0.5986, 0.5921, 0.6711, 0.4651, 0.5469],
       device='cuda:0') torch.Size([16])
percent tensor([0.5569, 0.6550, 0.7840, 0.7595, 0.8138, 0.6816, 0.6489, 0.7251, 0.7108,
        0.6330, 0.6749, 0.7650, 0.5801, 0.7066, 0.6714, 0.6054],
       device='cuda:0') torch.Size([16])
percent tensor([0.9994, 0.9980, 0.9990, 0.9989, 0.9987, 0.9984, 0.9985, 0.9992, 0.9982,
        0.9984, 0.9988, 0.9988, 0.9982, 0.9979, 0.9983, 0.9993],
       device='cuda:0') torch.Size([16])
True Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=128, out_features=16, bias=False)
False Linear(in_features=16, out_features=2, bias=False)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=128, out_features=16, bias=False)
False Linear(in_features=16, out_features=2, bias=False)
True Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=256, out_features=32, bias=False)
False Linear(in_features=32, out_features=2, bias=False)
True Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=256, out_features=32, bias=False)
False Linear(in_features=32, out_features=2, bias=False)
True Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=512, out_features=64, bias=False)
False Linear(in_features=64, out_features=2, bias=False)
True Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=512, out_features=64, bias=False)
False Linear(in_features=64, out_features=2, bias=False)
True Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1024, out_features=128, bias=False)
False Linear(in_features=128, out_features=2, bias=False)
True Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1024, out_features=128, bias=False)
False Linear(in_features=128, out_features=2, bias=False)
True Linear(in_features=512, out_features=10, bias=True)
Epoch: 80 | Batch_idx: 0 |  Loss: (0.2083) |  Loss2: (0.0000) | Acc: (93.00%) (120/128)
Epoch: 80 | Batch_idx: 10 |  Loss: (0.2441) |  Loss2: (0.0000) | Acc: (91.00%) (1293/1408)
Epoch: 80 | Batch_idx: 20 |  Loss: (0.2388) |  Loss2: (0.0000) | Acc: (91.00%) (2467/2688)
Epoch: 80 | Batch_idx: 30 |  Loss: (0.2469) |  Loss2: (0.0000) | Acc: (91.00%) (3626/3968)
Epoch: 80 | Batch_idx: 40 |  Loss: (0.2615) |  Loss2: (0.0000) | Acc: (91.00%) (4779/5248)
Epoch: 80 | Batch_idx: 50 |  Loss: (0.2629) |  Loss2: (0.0000) | Acc: (90.00%) (5934/6528)
Epoch: 80 | Batch_idx: 60 |  Loss: (0.2623) |  Loss2: (0.0000) | Acc: (90.00%) (7104/7808)
Epoch: 80 | Batch_idx: 70 |  Loss: (0.2633) |  Loss2: (0.0000) | Acc: (90.00%) (8257/9088)
Epoch: 80 | Batch_idx: 80 |  Loss: (0.2667) |  Loss2: (0.0000) | Acc: (90.00%) (9419/10368)
Epoch: 80 | Batch_idx: 90 |  Loss: (0.2685) |  Loss2: (0.0000) | Acc: (90.00%) (10566/11648)
Epoch: 80 | Batch_idx: 100 |  Loss: (0.2683) |  Loss2: (0.0000) | Acc: (90.00%) (11730/12928)
Epoch: 80 | Batch_idx: 110 |  Loss: (0.2677) |  Loss2: (0.0000) | Acc: (90.00%) (12888/14208)
Epoch: 80 | Batch_idx: 120 |  Loss: (0.2667) |  Loss2: (0.0000) | Acc: (90.00%) (14047/15488)
Epoch: 80 | Batch_idx: 130 |  Loss: (0.2703) |  Loss2: (0.0000) | Acc: (90.00%) (15201/16768)
Epoch: 80 | Batch_idx: 140 |  Loss: (0.2694) |  Loss2: (0.0000) | Acc: (90.00%) (16363/18048)
Epoch: 80 | Batch_idx: 150 |  Loss: (0.2716) |  Loss2: (0.0000) | Acc: (90.00%) (17506/19328)
Epoch: 80 | Batch_idx: 160 |  Loss: (0.2718) |  Loss2: (0.0000) | Acc: (90.00%) (18662/20608)
Epoch: 80 | Batch_idx: 170 |  Loss: (0.2709) |  Loss2: (0.0000) | Acc: (90.00%) (19845/21888)
Epoch: 80 | Batch_idx: 180 |  Loss: (0.2723) |  Loss2: (0.0000) | Acc: (90.00%) (20992/23168)
Epoch: 80 | Batch_idx: 190 |  Loss: (0.2705) |  Loss2: (0.0000) | Acc: (90.00%) (22170/24448)
Epoch: 80 | Batch_idx: 200 |  Loss: (0.2712) |  Loss2: (0.0000) | Acc: (90.00%) (23320/25728)
Epoch: 80 | Batch_idx: 210 |  Loss: (0.2732) |  Loss2: (0.0000) | Acc: (90.00%) (24454/27008)
Epoch: 80 | Batch_idx: 220 |  Loss: (0.2742) |  Loss2: (0.0000) | Acc: (90.00%) (25618/28288)
Epoch: 80 | Batch_idx: 230 |  Loss: (0.2743) |  Loss2: (0.0000) | Acc: (90.00%) (26775/29568)
Epoch: 80 | Batch_idx: 240 |  Loss: (0.2741) |  Loss2: (0.0000) | Acc: (90.00%) (27939/30848)
Epoch: 80 | Batch_idx: 250 |  Loss: (0.2749) |  Loss2: (0.0000) | Acc: (90.00%) (29088/32128)
Epoch: 80 | Batch_idx: 260 |  Loss: (0.2759) |  Loss2: (0.0000) | Acc: (90.00%) (30245/33408)
Epoch: 80 | Batch_idx: 270 |  Loss: (0.2765) |  Loss2: (0.0000) | Acc: (90.00%) (31389/34688)
Epoch: 80 | Batch_idx: 280 |  Loss: (0.2776) |  Loss2: (0.0000) | Acc: (90.00%) (32535/35968)
Epoch: 80 | Batch_idx: 290 |  Loss: (0.2774) |  Loss2: (0.0000) | Acc: (90.00%) (33703/37248)
Epoch: 80 | Batch_idx: 300 |  Loss: (0.2780) |  Loss2: (0.0000) | Acc: (90.00%) (34847/38528)
Epoch: 80 | Batch_idx: 310 |  Loss: (0.2782) |  Loss2: (0.0000) | Acc: (90.00%) (35997/39808)
Epoch: 80 | Batch_idx: 320 |  Loss: (0.2780) |  Loss2: (0.0000) | Acc: (90.00%) (37158/41088)
Epoch: 80 | Batch_idx: 330 |  Loss: (0.2781) |  Loss2: (0.0000) | Acc: (90.00%) (38301/42368)
Epoch: 80 | Batch_idx: 340 |  Loss: (0.2779) |  Loss2: (0.0000) | Acc: (90.00%) (39462/43648)
Epoch: 80 | Batch_idx: 350 |  Loss: (0.2781) |  Loss2: (0.0000) | Acc: (90.00%) (40613/44928)
Epoch: 80 | Batch_idx: 360 |  Loss: (0.2780) |  Loss2: (0.0000) | Acc: (90.00%) (41763/46208)
Epoch: 80 | Batch_idx: 370 |  Loss: (0.2778) |  Loss2: (0.0000) | Acc: (90.00%) (42927/47488)
Epoch: 80 | Batch_idx: 380 |  Loss: (0.2781) |  Loss2: (0.0000) | Acc: (90.00%) (44082/48768)
Epoch: 80 | Batch_idx: 390 |  Loss: (0.2786) |  Loss2: (0.0000) | Acc: (90.00%) (45181/50000)
=> saving checkpoint 'drive/app/torch/save_Routing_Gate_2/checkpoint_080.pth.tar'
# TEST : Loss: (0.4239) | Acc: (86.00%) (8622/10000)
percent tensor([0.5290, 0.5178, 0.5381, 0.5370, 0.5365, 0.5329, 0.5251, 0.5340, 0.5323,
        0.5245, 0.5263, 0.5303, 0.5249, 0.5218, 0.5249, 0.5273],
       device='cuda:0') torch.Size([16])
percent tensor([0.5407, 0.5525, 0.5330, 0.5370, 0.5368, 0.5505, 0.5473, 0.5365, 0.5365,
        0.5416, 0.5414, 0.5363, 0.5400, 0.5514, 0.5496, 0.5437],
       device='cuda:0') torch.Size([16])
percent tensor([0.5665, 0.6109, 0.5379, 0.4708, 0.5161, 0.4612, 0.5992, 0.5458, 0.5604,
        0.5877, 0.5815, 0.5872, 0.6363, 0.5124, 0.5715, 0.5222],
       device='cuda:0') torch.Size([16])
percent tensor([0.6724, 0.6996, 0.6692, 0.6770, 0.6756, 0.6651, 0.6997, 0.6643, 0.6951,
        0.7016, 0.7345, 0.7084, 0.7000, 0.7143, 0.6897, 0.6880],
       device='cuda:0') torch.Size([16])
percent tensor([0.6114, 0.6212, 0.6412, 0.6007, 0.6150, 0.7315, 0.6415, 0.5753, 0.6758,
        0.6411, 0.6717, 0.6194, 0.6719, 0.6921, 0.5993, 0.6686],
       device='cuda:0') torch.Size([16])
percent tensor([0.5190, 0.5860, 0.5473, 0.5496, 0.5365, 0.5527, 0.5305, 0.4426, 0.6012,
        0.5449, 0.6207, 0.5855, 0.5812, 0.6471, 0.4481, 0.5334],
       device='cuda:0') torch.Size([16])
percent tensor([0.5535, 0.6285, 0.7924, 0.7759, 0.8275, 0.6716, 0.6336, 0.7209, 0.7007,
        0.6278, 0.6800, 0.7654, 0.5997, 0.6635, 0.6611, 0.6081],
       device='cuda:0') torch.Size([16])
percent tensor([0.9995, 0.9980, 0.9993, 0.9991, 0.9988, 0.9988, 0.9987, 0.9992, 0.9980,
        0.9985, 0.9992, 0.9985, 0.9981, 0.9984, 0.9984, 0.9995],
       device='cuda:0') torch.Size([16])
Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 3, 3, 3]) tensor(177.5551, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(802.4844, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(806.3901, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([128, 64, 3, 3]) tensor(1518.5917, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([128, 64, 1, 1]) tensor(498.7086, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([128, 128, 3, 3]) tensor(2226.4500, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([256, 128, 3, 3]) tensor(4285.9390, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([256, 128, 1, 1]) tensor(1404.4434, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([256, 256, 3, 3]) tensor(6108.0679, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([512, 256, 3, 3]) tensor(11939.9512, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([512, 256, 1, 1]) tensor(3970.6162, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([512, 512, 3, 3]) tensor(16767.7383, device='cuda:0', grad_fn=<NormBackward0>)
Epoch: 81 | Batch_idx: 0 |  Loss: (0.2229) |  Loss2: (0.0000) | Acc: (94.00%) (121/128)
Epoch: 81 | Batch_idx: 10 |  Loss: (0.2718) |  Loss2: (0.0000) | Acc: (91.00%) (1285/1408)
Epoch: 81 | Batch_idx: 20 |  Loss: (0.2831) |  Loss2: (0.0000) | Acc: (90.00%) (2439/2688)
Epoch: 81 | Batch_idx: 30 |  Loss: (0.2829) |  Loss2: (0.0000) | Acc: (90.00%) (3595/3968)
Epoch: 81 | Batch_idx: 40 |  Loss: (0.2787) |  Loss2: (0.0000) | Acc: (90.00%) (4751/5248)
Epoch: 81 | Batch_idx: 50 |  Loss: (0.2781) |  Loss2: (0.0000) | Acc: (90.00%) (5903/6528)
Epoch: 81 | Batch_idx: 60 |  Loss: (0.2790) |  Loss2: (0.0000) | Acc: (90.00%) (7068/7808)
Epoch: 81 | Batch_idx: 70 |  Loss: (0.2809) |  Loss2: (0.0000) | Acc: (90.00%) (8228/9088)
Epoch: 81 | Batch_idx: 80 |  Loss: (0.2764) |  Loss2: (0.0000) | Acc: (90.00%) (9389/10368)
Epoch: 81 | Batch_idx: 90 |  Loss: (0.2736) |  Loss2: (0.0000) | Acc: (90.00%) (10558/11648)
Epoch: 81 | Batch_idx: 100 |  Loss: (0.2711) |  Loss2: (0.0000) | Acc: (90.00%) (11736/12928)
Epoch: 81 | Batch_idx: 110 |  Loss: (0.2709) |  Loss2: (0.0000) | Acc: (90.00%) (12894/14208)
Epoch: 81 | Batch_idx: 120 |  Loss: (0.2704) |  Loss2: (0.0000) | Acc: (90.00%) (14062/15488)
Epoch: 81 | Batch_idx: 130 |  Loss: (0.2708) |  Loss2: (0.0000) | Acc: (90.00%) (15222/16768)
Epoch: 81 | Batch_idx: 140 |  Loss: (0.2697) |  Loss2: (0.0000) | Acc: (90.00%) (16385/18048)
Epoch: 81 | Batch_idx: 150 |  Loss: (0.2689) |  Loss2: (0.0000) | Acc: (90.00%) (17555/19328)
Epoch: 81 | Batch_idx: 160 |  Loss: (0.2699) |  Loss2: (0.0000) | Acc: (90.00%) (18707/20608)
Epoch: 81 | Batch_idx: 170 |  Loss: (0.2700) |  Loss2: (0.0000) | Acc: (90.00%) (19851/21888)
Epoch: 81 | Batch_idx: 180 |  Loss: (0.2710) |  Loss2: (0.0000) | Acc: (90.00%) (20998/23168)
Epoch: 81 | Batch_idx: 190 |  Loss: (0.2709) |  Loss2: (0.0000) | Acc: (90.00%) (22151/24448)
Epoch: 81 | Batch_idx: 200 |  Loss: (0.2707) |  Loss2: (0.0000) | Acc: (90.00%) (23319/25728)
Epoch: 81 | Batch_idx: 210 |  Loss: (0.2710) |  Loss2: (0.0000) | Acc: (90.00%) (24465/27008)
Epoch: 81 | Batch_idx: 220 |  Loss: (0.2702) |  Loss2: (0.0000) | Acc: (90.00%) (25633/28288)
Epoch: 81 | Batch_idx: 230 |  Loss: (0.2700) |  Loss2: (0.0000) | Acc: (90.00%) (26800/29568)
Epoch: 81 | Batch_idx: 240 |  Loss: (0.2697) |  Loss2: (0.0000) | Acc: (90.00%) (27952/30848)
Epoch: 81 | Batch_idx: 250 |  Loss: (0.2698) |  Loss2: (0.0000) | Acc: (90.00%) (29113/32128)
Epoch: 81 | Batch_idx: 260 |  Loss: (0.2687) |  Loss2: (0.0000) | Acc: (90.00%) (30285/33408)
Epoch: 81 | Batch_idx: 270 |  Loss: (0.2692) |  Loss2: (0.0000) | Acc: (90.00%) (31433/34688)
Epoch: 81 | Batch_idx: 280 |  Loss: (0.2702) |  Loss2: (0.0000) | Acc: (90.00%) (32576/35968)
Epoch: 81 | Batch_idx: 290 |  Loss: (0.2703) |  Loss2: (0.0000) | Acc: (90.00%) (33733/37248)
Epoch: 81 | Batch_idx: 300 |  Loss: (0.2712) |  Loss2: (0.0000) | Acc: (90.00%) (34885/38528)
Epoch: 81 | Batch_idx: 310 |  Loss: (0.2702) |  Loss2: (0.0000) | Acc: (90.00%) (36060/39808)
Epoch: 81 | Batch_idx: 320 |  Loss: (0.2701) |  Loss2: (0.0000) | Acc: (90.00%) (37231/41088)
Epoch: 81 | Batch_idx: 330 |  Loss: (0.2695) |  Loss2: (0.0000) | Acc: (90.00%) (38395/42368)
Epoch: 81 | Batch_idx: 340 |  Loss: (0.2693) |  Loss2: (0.0000) | Acc: (90.00%) (39558/43648)
Epoch: 81 | Batch_idx: 350 |  Loss: (0.2691) |  Loss2: (0.0000) | Acc: (90.00%) (40723/44928)
Epoch: 81 | Batch_idx: 360 |  Loss: (0.2701) |  Loss2: (0.0000) | Acc: (90.00%) (41863/46208)
Epoch: 81 | Batch_idx: 370 |  Loss: (0.2702) |  Loss2: (0.0000) | Acc: (90.00%) (43030/47488)
Epoch: 81 | Batch_idx: 380 |  Loss: (0.2697) |  Loss2: (0.0000) | Acc: (90.00%) (44196/48768)
Epoch: 81 | Batch_idx: 390 |  Loss: (0.2700) |  Loss2: (0.0000) | Acc: (90.00%) (45302/50000)
# TEST : Loss: (0.4451) | Acc: (85.00%) (8524/10000)
percent tensor([0.5292, 0.5174, 0.5387, 0.5376, 0.5376, 0.5327, 0.5254, 0.5345, 0.5325,
        0.5246, 0.5260, 0.5310, 0.5251, 0.5211, 0.5247, 0.5277],
       device='cuda:0') torch.Size([16])
percent tensor([0.5419, 0.5525, 0.5342, 0.5386, 0.5380, 0.5512, 0.5476, 0.5383, 0.5384,
        0.5426, 0.5424, 0.5373, 0.5416, 0.5513, 0.5500, 0.5445],
       device='cuda:0') torch.Size([16])
percent tensor([0.5613, 0.6052, 0.5334, 0.4626, 0.5112, 0.4504, 0.5937, 0.5469, 0.5538,
        0.5853, 0.5761, 0.5859, 0.6363, 0.4958, 0.5678, 0.5148],
       device='cuda:0') torch.Size([16])
percent tensor([0.6715, 0.6968, 0.6712, 0.6813, 0.6766, 0.6709, 0.6976, 0.6670, 0.6965,
        0.6979, 0.7313, 0.7097, 0.6965, 0.7153, 0.6911, 0.6861],
       device='cuda:0') torch.Size([16])
percent tensor([0.6423, 0.6275, 0.6756, 0.6216, 0.6465, 0.7644, 0.6533, 0.5970, 0.6944,
        0.6410, 0.6872, 0.6215, 0.6839, 0.7011, 0.6305, 0.6907],
       device='cuda:0') torch.Size([16])
percent tensor([0.5193, 0.5895, 0.5349, 0.5278, 0.5301, 0.5603, 0.5284, 0.4395, 0.6125,
        0.5548, 0.6318, 0.5964, 0.5884, 0.6535, 0.4657, 0.5488],
       device='cuda:0') torch.Size([16])
percent tensor([0.5670, 0.6388, 0.7702, 0.7531, 0.8100, 0.6689, 0.6377, 0.7116, 0.6664,
        0.6236, 0.6785, 0.7598, 0.6069, 0.6696, 0.6756, 0.6060],
       device='cuda:0') torch.Size([16])
percent tensor([0.9994, 0.9975, 0.9989, 0.9988, 0.9987, 0.9984, 0.9988, 0.9989, 0.9983,
        0.9986, 0.9989, 0.9984, 0.9977, 0.9983, 0.9982, 0.9995],
       device='cuda:0') torch.Size([16])
Epoch: 82 | Batch_idx: 0 |  Loss: (0.2514) |  Loss2: (0.0000) | Acc: (90.00%) (116/128)
Epoch: 82 | Batch_idx: 10 |  Loss: (0.2597) |  Loss2: (0.0000) | Acc: (90.00%) (1281/1408)
Epoch: 82 | Batch_idx: 20 |  Loss: (0.2606) |  Loss2: (0.0000) | Acc: (90.00%) (2436/2688)
Epoch: 82 | Batch_idx: 30 |  Loss: (0.2540) |  Loss2: (0.0000) | Acc: (91.00%) (3613/3968)
Epoch: 82 | Batch_idx: 40 |  Loss: (0.2570) |  Loss2: (0.0000) | Acc: (91.00%) (4791/5248)
Epoch: 82 | Batch_idx: 50 |  Loss: (0.2592) |  Loss2: (0.0000) | Acc: (91.00%) (5956/6528)
Epoch: 82 | Batch_idx: 60 |  Loss: (0.2555) |  Loss2: (0.0000) | Acc: (91.00%) (7136/7808)
Epoch: 82 | Batch_idx: 70 |  Loss: (0.2524) |  Loss2: (0.0000) | Acc: (91.00%) (8311/9088)
Epoch: 82 | Batch_idx: 80 |  Loss: (0.2571) |  Loss2: (0.0000) | Acc: (91.00%) (9461/10368)
Epoch: 82 | Batch_idx: 90 |  Loss: (0.2535) |  Loss2: (0.0000) | Acc: (91.00%) (10641/11648)
Epoch: 82 | Batch_idx: 100 |  Loss: (0.2540) |  Loss2: (0.0000) | Acc: (91.00%) (11803/12928)
Epoch: 82 | Batch_idx: 110 |  Loss: (0.2545) |  Loss2: (0.0000) | Acc: (91.00%) (12977/14208)
Epoch: 82 | Batch_idx: 120 |  Loss: (0.2545) |  Loss2: (0.0000) | Acc: (91.00%) (14138/15488)
Epoch: 82 | Batch_idx: 130 |  Loss: (0.2572) |  Loss2: (0.0000) | Acc: (91.00%) (15281/16768)
Epoch: 82 | Batch_idx: 140 |  Loss: (0.2572) |  Loss2: (0.0000) | Acc: (91.00%) (16442/18048)
Epoch: 82 | Batch_idx: 150 |  Loss: (0.2558) |  Loss2: (0.0000) | Acc: (91.00%) (17628/19328)
Epoch: 82 | Batch_idx: 160 |  Loss: (0.2573) |  Loss2: (0.0000) | Acc: (91.00%) (18779/20608)
Epoch: 82 | Batch_idx: 170 |  Loss: (0.2578) |  Loss2: (0.0000) | Acc: (91.00%) (19937/21888)
Epoch: 82 | Batch_idx: 180 |  Loss: (0.2598) |  Loss2: (0.0000) | Acc: (91.00%) (21083/23168)
Epoch: 82 | Batch_idx: 190 |  Loss: (0.2606) |  Loss2: (0.0000) | Acc: (90.00%) (22245/24448)
Epoch: 82 | Batch_idx: 200 |  Loss: (0.2613) |  Loss2: (0.0000) | Acc: (90.00%) (23406/25728)
Epoch: 82 | Batch_idx: 210 |  Loss: (0.2637) |  Loss2: (0.0000) | Acc: (90.00%) (24543/27008)
Epoch: 82 | Batch_idx: 220 |  Loss: (0.2636) |  Loss2: (0.0000) | Acc: (90.00%) (25711/28288)
Epoch: 82 | Batch_idx: 230 |  Loss: (0.2634) |  Loss2: (0.0000) | Acc: (90.00%) (26882/29568)
Epoch: 82 | Batch_idx: 240 |  Loss: (0.2644) |  Loss2: (0.0000) | Acc: (90.00%) (28024/30848)
Epoch: 82 | Batch_idx: 250 |  Loss: (0.2639) |  Loss2: (0.0000) | Acc: (90.00%) (29191/32128)
Epoch: 82 | Batch_idx: 260 |  Loss: (0.2644) |  Loss2: (0.0000) | Acc: (90.00%) (30350/33408)
Epoch: 82 | Batch_idx: 270 |  Loss: (0.2647) |  Loss2: (0.0000) | Acc: (90.00%) (31511/34688)
Epoch: 82 | Batch_idx: 280 |  Loss: (0.2644) |  Loss2: (0.0000) | Acc: (90.00%) (32672/35968)
Epoch: 82 | Batch_idx: 290 |  Loss: (0.2633) |  Loss2: (0.0000) | Acc: (90.00%) (33853/37248)
Epoch: 82 | Batch_idx: 300 |  Loss: (0.2616) |  Loss2: (0.0000) | Acc: (90.00%) (35039/38528)
Epoch: 82 | Batch_idx: 310 |  Loss: (0.2608) |  Loss2: (0.0000) | Acc: (90.00%) (36211/39808)
Epoch: 82 | Batch_idx: 320 |  Loss: (0.2599) |  Loss2: (0.0000) | Acc: (90.00%) (37390/41088)
Epoch: 82 | Batch_idx: 330 |  Loss: (0.2595) |  Loss2: (0.0000) | Acc: (91.00%) (38565/42368)
Epoch: 82 | Batch_idx: 340 |  Loss: (0.2605) |  Loss2: (0.0000) | Acc: (91.00%) (39720/43648)
Epoch: 82 | Batch_idx: 350 |  Loss: (0.2595) |  Loss2: (0.0000) | Acc: (91.00%) (40902/44928)
Epoch: 82 | Batch_idx: 360 |  Loss: (0.2594) |  Loss2: (0.0000) | Acc: (91.00%) (42074/46208)
Epoch: 82 | Batch_idx: 370 |  Loss: (0.2598) |  Loss2: (0.0000) | Acc: (91.00%) (43239/47488)
Epoch: 82 | Batch_idx: 380 |  Loss: (0.2601) |  Loss2: (0.0000) | Acc: (91.00%) (44393/48768)
Epoch: 82 | Batch_idx: 390 |  Loss: (0.2598) |  Loss2: (0.0000) | Acc: (91.00%) (45520/50000)
# TEST : Loss: (0.4685) | Acc: (84.00%) (8440/10000)
percent tensor([0.5288, 0.5183, 0.5379, 0.5375, 0.5358, 0.5325, 0.5248, 0.5342, 0.5319,
        0.5243, 0.5264, 0.5293, 0.5244, 0.5216, 0.5251, 0.5276],
       device='cuda:0') torch.Size([16])
percent tensor([0.5412, 0.5527, 0.5335, 0.5375, 0.5375, 0.5503, 0.5472, 0.5368, 0.5375,
        0.5424, 0.5421, 0.5366, 0.5409, 0.5524, 0.5496, 0.5441],
       device='cuda:0') torch.Size([16])
percent tensor([0.5761, 0.6161, 0.5438, 0.4839, 0.5259, 0.4719, 0.6081, 0.5590, 0.5691,
        0.5953, 0.5917, 0.5891, 0.6429, 0.5164, 0.5781, 0.5337],
       device='cuda:0') torch.Size([16])
percent tensor([0.6709, 0.6988, 0.6711, 0.6799, 0.6717, 0.6640, 0.6961, 0.6658, 0.6963,
        0.7011, 0.7310, 0.7083, 0.6961, 0.7159, 0.6890, 0.6837],
       device='cuda:0') torch.Size([16])
percent tensor([0.6294, 0.6240, 0.6580, 0.6184, 0.6410, 0.7586, 0.6537, 0.5934, 0.6821,
        0.6385, 0.6818, 0.6285, 0.6822, 0.6922, 0.6200, 0.6863],
       device='cuda:0') torch.Size([16])
percent tensor([0.5235, 0.5803, 0.5607, 0.5497, 0.5425, 0.5482, 0.5349, 0.4681, 0.6096,
        0.5472, 0.6314, 0.5934, 0.5803, 0.6526, 0.4644, 0.5350],
       device='cuda:0') torch.Size([16])
percent tensor([0.5734, 0.5871, 0.7959, 0.7770, 0.8139, 0.6746, 0.6231, 0.7399, 0.6802,
        0.6074, 0.6460, 0.7547, 0.5952, 0.6471, 0.6627, 0.6209],
       device='cuda:0') torch.Size([16])
percent tensor([0.9993, 0.9979, 0.9989, 0.9988, 0.9982, 0.9985, 0.9984, 0.9989, 0.9979,
        0.9988, 0.9988, 0.9983, 0.9979, 0.9984, 0.9986, 0.9993],
       device='cuda:0') torch.Size([16])
Epoch: 83 | Batch_idx: 0 |  Loss: (0.3375) |  Loss2: (0.0000) | Acc: (87.00%) (112/128)
Epoch: 83 | Batch_idx: 10 |  Loss: (0.2631) |  Loss2: (0.0000) | Acc: (90.00%) (1278/1408)
Epoch: 83 | Batch_idx: 20 |  Loss: (0.2597) |  Loss2: (0.0000) | Acc: (90.00%) (2440/2688)
Epoch: 83 | Batch_idx: 30 |  Loss: (0.2547) |  Loss2: (0.0000) | Acc: (91.00%) (3613/3968)
Epoch: 83 | Batch_idx: 40 |  Loss: (0.2486) |  Loss2: (0.0000) | Acc: (91.00%) (4803/5248)
Epoch: 83 | Batch_idx: 50 |  Loss: (0.2506) |  Loss2: (0.0000) | Acc: (91.00%) (5970/6528)
Epoch: 83 | Batch_idx: 60 |  Loss: (0.2531) |  Loss2: (0.0000) | Acc: (91.00%) (7129/7808)
Epoch: 83 | Batch_idx: 70 |  Loss: (0.2528) |  Loss2: (0.0000) | Acc: (91.00%) (8304/9088)
Epoch: 83 | Batch_idx: 80 |  Loss: (0.2535) |  Loss2: (0.0000) | Acc: (91.00%) (9468/10368)
Epoch: 83 | Batch_idx: 90 |  Loss: (0.2513) |  Loss2: (0.0000) | Acc: (91.00%) (10646/11648)
Epoch: 83 | Batch_idx: 100 |  Loss: (0.2545) |  Loss2: (0.0000) | Acc: (91.00%) (11796/12928)
Epoch: 83 | Batch_idx: 110 |  Loss: (0.2541) |  Loss2: (0.0000) | Acc: (91.00%) (12962/14208)
Epoch: 83 | Batch_idx: 120 |  Loss: (0.2521) |  Loss2: (0.0000) | Acc: (91.00%) (14137/15488)
Epoch: 83 | Batch_idx: 130 |  Loss: (0.2498) |  Loss2: (0.0000) | Acc: (91.00%) (15324/16768)
Epoch: 83 | Batch_idx: 140 |  Loss: (0.2530) |  Loss2: (0.0000) | Acc: (91.00%) (16490/18048)
Epoch: 83 | Batch_idx: 150 |  Loss: (0.2535) |  Loss2: (0.0000) | Acc: (91.00%) (17654/19328)
Epoch: 83 | Batch_idx: 160 |  Loss: (0.2541) |  Loss2: (0.0000) | Acc: (91.00%) (18814/20608)
Epoch: 83 | Batch_idx: 170 |  Loss: (0.2542) |  Loss2: (0.0000) | Acc: (91.00%) (19978/21888)
Epoch: 83 | Batch_idx: 180 |  Loss: (0.2537) |  Loss2: (0.0000) | Acc: (91.00%) (21149/23168)
Epoch: 83 | Batch_idx: 190 |  Loss: (0.2523) |  Loss2: (0.0000) | Acc: (91.00%) (22323/24448)
Epoch: 83 | Batch_idx: 200 |  Loss: (0.2529) |  Loss2: (0.0000) | Acc: (91.00%) (23484/25728)
Epoch: 83 | Batch_idx: 210 |  Loss: (0.2537) |  Loss2: (0.0000) | Acc: (91.00%) (24642/27008)
Epoch: 83 | Batch_idx: 220 |  Loss: (0.2541) |  Loss2: (0.0000) | Acc: (91.00%) (25805/28288)
Epoch: 83 | Batch_idx: 230 |  Loss: (0.2544) |  Loss2: (0.0000) | Acc: (91.00%) (26970/29568)
Epoch: 83 | Batch_idx: 240 |  Loss: (0.2533) |  Loss2: (0.0000) | Acc: (91.00%) (28144/30848)
Epoch: 83 | Batch_idx: 250 |  Loss: (0.2527) |  Loss2: (0.0000) | Acc: (91.00%) (29320/32128)
Epoch: 83 | Batch_idx: 260 |  Loss: (0.2527) |  Loss2: (0.0000) | Acc: (91.00%) (30491/33408)
Epoch: 83 | Batch_idx: 270 |  Loss: (0.2537) |  Loss2: (0.0000) | Acc: (91.00%) (31656/34688)
Epoch: 83 | Batch_idx: 280 |  Loss: (0.2533) |  Loss2: (0.0000) | Acc: (91.00%) (32837/35968)
Epoch: 83 | Batch_idx: 290 |  Loss: (0.2539) |  Loss2: (0.0000) | Acc: (91.00%) (33989/37248)
Epoch: 83 | Batch_idx: 300 |  Loss: (0.2539) |  Loss2: (0.0000) | Acc: (91.00%) (35160/38528)
Epoch: 83 | Batch_idx: 310 |  Loss: (0.2540) |  Loss2: (0.0000) | Acc: (91.00%) (36337/39808)
Epoch: 83 | Batch_idx: 320 |  Loss: (0.2548) |  Loss2: (0.0000) | Acc: (91.00%) (37491/41088)
Epoch: 83 | Batch_idx: 330 |  Loss: (0.2549) |  Loss2: (0.0000) | Acc: (91.00%) (38650/42368)
Epoch: 83 | Batch_idx: 340 |  Loss: (0.2548) |  Loss2: (0.0000) | Acc: (91.00%) (39826/43648)
Epoch: 83 | Batch_idx: 350 |  Loss: (0.2550) |  Loss2: (0.0000) | Acc: (91.00%) (40991/44928)
Epoch: 83 | Batch_idx: 360 |  Loss: (0.2543) |  Loss2: (0.0000) | Acc: (91.00%) (42174/46208)
Epoch: 83 | Batch_idx: 370 |  Loss: (0.2545) |  Loss2: (0.0000) | Acc: (91.00%) (43333/47488)
Epoch: 83 | Batch_idx: 380 |  Loss: (0.2546) |  Loss2: (0.0000) | Acc: (91.00%) (44500/48768)
Epoch: 83 | Batch_idx: 390 |  Loss: (0.2557) |  Loss2: (0.0000) | Acc: (91.00%) (45612/50000)
# TEST : Loss: (0.5131) | Acc: (83.00%) (8392/10000)
percent tensor([0.5293, 0.5176, 0.5394, 0.5388, 0.5374, 0.5336, 0.5251, 0.5347, 0.5317,
        0.5246, 0.5256, 0.5314, 0.5246, 0.5209, 0.5254, 0.5277],
       device='cuda:0') torch.Size([16])
percent tensor([0.5425, 0.5527, 0.5354, 0.5378, 0.5384, 0.5510, 0.5475, 0.5374, 0.5388,
        0.5429, 0.5428, 0.5377, 0.5419, 0.5509, 0.5500, 0.5445],
       device='cuda:0') torch.Size([16])
percent tensor([0.5672, 0.6072, 0.5407, 0.4757, 0.5204, 0.4599, 0.5973, 0.5467, 0.5656,
        0.5884, 0.5823, 0.5849, 0.6395, 0.5076, 0.5683, 0.5227],
       device='cuda:0') torch.Size([16])
percent tensor([0.6732, 0.6970, 0.6738, 0.6797, 0.6748, 0.6675, 0.6985, 0.6654, 0.6966,
        0.7019, 0.7308, 0.7092, 0.6980, 0.7173, 0.6871, 0.6851],
       device='cuda:0') torch.Size([16])
percent tensor([0.6198, 0.6137, 0.6608, 0.6249, 0.6488, 0.7496, 0.6418, 0.5942, 0.6795,
        0.6351, 0.6719, 0.6145, 0.6623, 0.6923, 0.6103, 0.6752],
       device='cuda:0') torch.Size([16])
percent tensor([0.5316, 0.5914, 0.5664, 0.5565, 0.5525, 0.5562, 0.5494, 0.4687, 0.6145,
        0.5537, 0.6286, 0.5999, 0.5851, 0.6516, 0.4660, 0.5366],
       device='cuda:0') torch.Size([16])
percent tensor([0.5240, 0.5976, 0.7735, 0.7390, 0.8078, 0.6578, 0.6103, 0.7198, 0.6418,
        0.6046, 0.6465, 0.7352, 0.5854, 0.6544, 0.6277, 0.5969],
       device='cuda:0') torch.Size([16])
percent tensor([0.9994, 0.9982, 0.9989, 0.9985, 0.9987, 0.9979, 0.9989, 0.9989, 0.9981,
        0.9988, 0.9989, 0.9984, 0.9982, 0.9988, 0.9989, 0.9993],
       device='cuda:0') torch.Size([16])
Epoch: 84 | Batch_idx: 0 |  Loss: (0.2638) |  Loss2: (0.0000) | Acc: (93.00%) (120/128)
Epoch: 84 | Batch_idx: 10 |  Loss: (0.2226) |  Loss2: (0.0000) | Acc: (92.00%) (1304/1408)
Epoch: 84 | Batch_idx: 20 |  Loss: (0.2426) |  Loss2: (0.0000) | Acc: (91.00%) (2469/2688)
Epoch: 84 | Batch_idx: 30 |  Loss: (0.2460) |  Loss2: (0.0000) | Acc: (91.00%) (3632/3968)
Epoch: 84 | Batch_idx: 40 |  Loss: (0.2422) |  Loss2: (0.0000) | Acc: (91.00%) (4812/5248)
Epoch: 84 | Batch_idx: 50 |  Loss: (0.2427) |  Loss2: (0.0000) | Acc: (91.00%) (5988/6528)
Epoch: 84 | Batch_idx: 60 |  Loss: (0.2422) |  Loss2: (0.0000) | Acc: (91.00%) (7159/7808)
Epoch: 84 | Batch_idx: 70 |  Loss: (0.2411) |  Loss2: (0.0000) | Acc: (91.00%) (8332/9088)
Epoch: 84 | Batch_idx: 80 |  Loss: (0.2423) |  Loss2: (0.0000) | Acc: (91.00%) (9501/10368)
Epoch: 84 | Batch_idx: 90 |  Loss: (0.2444) |  Loss2: (0.0000) | Acc: (91.00%) (10662/11648)
Epoch: 84 | Batch_idx: 100 |  Loss: (0.2438) |  Loss2: (0.0000) | Acc: (91.00%) (11838/12928)
Epoch: 84 | Batch_idx: 110 |  Loss: (0.2439) |  Loss2: (0.0000) | Acc: (91.00%) (13001/14208)
Epoch: 84 | Batch_idx: 120 |  Loss: (0.2461) |  Loss2: (0.0000) | Acc: (91.00%) (14169/15488)
Epoch: 84 | Batch_idx: 130 |  Loss: (0.2436) |  Loss2: (0.0000) | Acc: (91.00%) (15359/16768)
Epoch: 84 | Batch_idx: 140 |  Loss: (0.2434) |  Loss2: (0.0000) | Acc: (91.00%) (16536/18048)
Epoch: 84 | Batch_idx: 150 |  Loss: (0.2443) |  Loss2: (0.0000) | Acc: (91.00%) (17710/19328)
Epoch: 84 | Batch_idx: 160 |  Loss: (0.2453) |  Loss2: (0.0000) | Acc: (91.00%) (18873/20608)
Epoch: 84 | Batch_idx: 170 |  Loss: (0.2464) |  Loss2: (0.0000) | Acc: (91.00%) (20040/21888)
Epoch: 84 | Batch_idx: 180 |  Loss: (0.2469) |  Loss2: (0.0000) | Acc: (91.00%) (21198/23168)
Epoch: 84 | Batch_idx: 190 |  Loss: (0.2486) |  Loss2: (0.0000) | Acc: (91.00%) (22350/24448)
Epoch: 84 | Batch_idx: 200 |  Loss: (0.2502) |  Loss2: (0.0000) | Acc: (91.00%) (23513/25728)
Epoch: 84 | Batch_idx: 210 |  Loss: (0.2501) |  Loss2: (0.0000) | Acc: (91.00%) (24677/27008)
Epoch: 84 | Batch_idx: 220 |  Loss: (0.2511) |  Loss2: (0.0000) | Acc: (91.00%) (25833/28288)
Epoch: 84 | Batch_idx: 230 |  Loss: (0.2517) |  Loss2: (0.0000) | Acc: (91.00%) (26991/29568)
Epoch: 84 | Batch_idx: 240 |  Loss: (0.2513) |  Loss2: (0.0000) | Acc: (91.00%) (28160/30848)
Epoch: 84 | Batch_idx: 250 |  Loss: (0.2523) |  Loss2: (0.0000) | Acc: (91.00%) (29320/32128)
Epoch: 84 | Batch_idx: 260 |  Loss: (0.2525) |  Loss2: (0.0000) | Acc: (91.00%) (30491/33408)
Epoch: 84 | Batch_idx: 270 |  Loss: (0.2528) |  Loss2: (0.0000) | Acc: (91.00%) (31656/34688)
Epoch: 84 | Batch_idx: 280 |  Loss: (0.2527) |  Loss2: (0.0000) | Acc: (91.00%) (32815/35968)
Epoch: 84 | Batch_idx: 290 |  Loss: (0.2540) |  Loss2: (0.0000) | Acc: (91.00%) (33962/37248)
Epoch: 84 | Batch_idx: 300 |  Loss: (0.2542) |  Loss2: (0.0000) | Acc: (91.00%) (35123/38528)
Epoch: 84 | Batch_idx: 310 |  Loss: (0.2544) |  Loss2: (0.0000) | Acc: (91.00%) (36290/39808)
Epoch: 84 | Batch_idx: 320 |  Loss: (0.2547) |  Loss2: (0.0000) | Acc: (91.00%) (37447/41088)
Epoch: 84 | Batch_idx: 330 |  Loss: (0.2544) |  Loss2: (0.0000) | Acc: (91.00%) (38625/42368)
Epoch: 84 | Batch_idx: 340 |  Loss: (0.2540) |  Loss2: (0.0000) | Acc: (91.00%) (39801/43648)
Epoch: 84 | Batch_idx: 350 |  Loss: (0.2546) |  Loss2: (0.0000) | Acc: (91.00%) (40957/44928)
Epoch: 84 | Batch_idx: 360 |  Loss: (0.2539) |  Loss2: (0.0000) | Acc: (91.00%) (42128/46208)
Epoch: 84 | Batch_idx: 370 |  Loss: (0.2540) |  Loss2: (0.0000) | Acc: (91.00%) (43297/47488)
Epoch: 84 | Batch_idx: 380 |  Loss: (0.2535) |  Loss2: (0.0000) | Acc: (91.00%) (44464/48768)
Epoch: 84 | Batch_idx: 390 |  Loss: (0.2534) |  Loss2: (0.0000) | Acc: (91.00%) (45590/50000)
# TEST : Loss: (0.3916) | Acc: (86.00%) (8696/10000)
percent tensor([0.5301, 0.5169, 0.5432, 0.5397, 0.5402, 0.5343, 0.5261, 0.5356, 0.5327,
        0.5253, 0.5262, 0.5340, 0.5253, 0.5186, 0.5256, 0.5282],
       device='cuda:0') torch.Size([16])
percent tensor([0.5411, 0.5527, 0.5323, 0.5368, 0.5374, 0.5512, 0.5474, 0.5358, 0.5381,
        0.5414, 0.5423, 0.5350, 0.5403, 0.5545, 0.5496, 0.5439],
       device='cuda:0') torch.Size([16])
percent tensor([0.5715, 0.6089, 0.5280, 0.4693, 0.5159, 0.4674, 0.5974, 0.5489, 0.5638,
        0.5868, 0.5844, 0.5791, 0.6413, 0.5034, 0.5718, 0.5272],
       device='cuda:0') torch.Size([16])
percent tensor([0.6697, 0.6992, 0.6714, 0.6814, 0.6768, 0.6627, 0.6997, 0.6659, 0.6968,
        0.7033, 0.7309, 0.7130, 0.6995, 0.7152, 0.6864, 0.6856],
       device='cuda:0') torch.Size([16])
percent tensor([0.6120, 0.6173, 0.6436, 0.6159, 0.6279, 0.7532, 0.6407, 0.5811, 0.6701,
        0.6390, 0.6740, 0.6076, 0.6736, 0.6969, 0.6061, 0.6800],
       device='cuda:0') torch.Size([16])
percent tensor([0.5244, 0.5849, 0.5595, 0.5482, 0.5412, 0.5610, 0.5338, 0.4486, 0.6079,
        0.5446, 0.6291, 0.6192, 0.5786, 0.6585, 0.4724, 0.5351],
       device='cuda:0') torch.Size([16])
percent tensor([0.5564, 0.6036, 0.7832, 0.7625, 0.8126, 0.6469, 0.6447, 0.7258, 0.6537,
        0.6079, 0.6685, 0.7639, 0.5955, 0.6851, 0.6508, 0.5987],
       device='cuda:0') torch.Size([16])
percent tensor([0.9994, 0.9977, 0.9991, 0.9991, 0.9990, 0.9985, 0.9983, 0.9992, 0.9978,
        0.9986, 0.9989, 0.9988, 0.9983, 0.9979, 0.9986, 0.9995],
       device='cuda:0') torch.Size([16])
False Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=128, out_features=16, bias=False)
True Linear(in_features=16, out_features=2, bias=False)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=128, out_features=16, bias=False)
True Linear(in_features=16, out_features=2, bias=False)
False Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=256, out_features=32, bias=False)
True Linear(in_features=32, out_features=2, bias=False)
False Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=256, out_features=32, bias=False)
True Linear(in_features=32, out_features=2, bias=False)
False Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=512, out_features=64, bias=False)
True Linear(in_features=64, out_features=2, bias=False)
False Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=512, out_features=64, bias=False)
True Linear(in_features=64, out_features=2, bias=False)
False Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1024, out_features=128, bias=False)
True Linear(in_features=128, out_features=2, bias=False)
False Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1024, out_features=128, bias=False)
True Linear(in_features=128, out_features=2, bias=False)
False Linear(in_features=512, out_features=10, bias=True)
Epoch: 85 | Batch_idx: 0 |  Loss: (0.2469) |  Loss2: (0.0000) | Acc: (91.00%) (117/128)
Epoch: 85 | Batch_idx: 10 |  Loss: (0.2399) |  Loss2: (0.0000) | Acc: (92.00%) (1296/1408)
Epoch: 85 | Batch_idx: 20 |  Loss: (0.2517) |  Loss2: (0.0000) | Acc: (91.00%) (2454/2688)
Epoch: 85 | Batch_idx: 30 |  Loss: (0.2655) |  Loss2: (0.0000) | Acc: (90.00%) (3605/3968)
Epoch: 85 | Batch_idx: 40 |  Loss: (0.2720) |  Loss2: (0.0000) | Acc: (90.00%) (4754/5248)
Epoch: 85 | Batch_idx: 50 |  Loss: (0.2721) |  Loss2: (0.0000) | Acc: (90.00%) (5905/6528)
Epoch: 85 | Batch_idx: 60 |  Loss: (0.2745) |  Loss2: (0.0000) | Acc: (90.00%) (7053/7808)
Epoch: 85 | Batch_idx: 70 |  Loss: (0.2702) |  Loss2: (0.0000) | Acc: (90.00%) (8223/9088)
Epoch: 85 | Batch_idx: 80 |  Loss: (0.2693) |  Loss2: (0.0000) | Acc: (90.00%) (9393/10368)
Epoch: 85 | Batch_idx: 90 |  Loss: (0.2700) |  Loss2: (0.0000) | Acc: (90.00%) (10550/11648)
Epoch: 85 | Batch_idx: 100 |  Loss: (0.2701) |  Loss2: (0.0000) | Acc: (90.00%) (11704/12928)
Epoch: 85 | Batch_idx: 110 |  Loss: (0.2703) |  Loss2: (0.0000) | Acc: (90.00%) (12862/14208)
Epoch: 85 | Batch_idx: 120 |  Loss: (0.2730) |  Loss2: (0.0000) | Acc: (90.00%) (14000/15488)
Epoch: 85 | Batch_idx: 130 |  Loss: (0.2748) |  Loss2: (0.0000) | Acc: (90.00%) (15139/16768)
Epoch: 85 | Batch_idx: 140 |  Loss: (0.2768) |  Loss2: (0.0000) | Acc: (90.00%) (16287/18048)
Epoch: 85 | Batch_idx: 150 |  Loss: (0.2780) |  Loss2: (0.0000) | Acc: (90.00%) (17439/19328)
Epoch: 85 | Batch_idx: 160 |  Loss: (0.2777) |  Loss2: (0.0000) | Acc: (90.00%) (18601/20608)
Epoch: 85 | Batch_idx: 170 |  Loss: (0.2781) |  Loss2: (0.0000) | Acc: (90.00%) (19754/21888)
Epoch: 85 | Batch_idx: 180 |  Loss: (0.2758) |  Loss2: (0.0000) | Acc: (90.00%) (20929/23168)
Epoch: 85 | Batch_idx: 190 |  Loss: (0.2763) |  Loss2: (0.0000) | Acc: (90.00%) (22077/24448)
Epoch: 85 | Batch_idx: 200 |  Loss: (0.2753) |  Loss2: (0.0000) | Acc: (90.00%) (23245/25728)
Epoch: 85 | Batch_idx: 210 |  Loss: (0.2757) |  Loss2: (0.0000) | Acc: (90.00%) (24407/27008)
Epoch: 85 | Batch_idx: 220 |  Loss: (0.2753) |  Loss2: (0.0000) | Acc: (90.00%) (25577/28288)
Epoch: 85 | Batch_idx: 230 |  Loss: (0.2752) |  Loss2: (0.0000) | Acc: (90.00%) (26738/29568)
Epoch: 85 | Batch_idx: 240 |  Loss: (0.2738) |  Loss2: (0.0000) | Acc: (90.00%) (27919/30848)
Epoch: 85 | Batch_idx: 250 |  Loss: (0.2731) |  Loss2: (0.0000) | Acc: (90.00%) (29085/32128)
Epoch: 85 | Batch_idx: 260 |  Loss: (0.2728) |  Loss2: (0.0000) | Acc: (90.00%) (30245/33408)
Epoch: 85 | Batch_idx: 270 |  Loss: (0.2732) |  Loss2: (0.0000) | Acc: (90.00%) (31390/34688)
Epoch: 85 | Batch_idx: 280 |  Loss: (0.2710) |  Loss2: (0.0000) | Acc: (90.00%) (32566/35968)
Epoch: 85 | Batch_idx: 290 |  Loss: (0.2706) |  Loss2: (0.0000) | Acc: (90.00%) (33735/37248)
Epoch: 85 | Batch_idx: 300 |  Loss: (0.2712) |  Loss2: (0.0000) | Acc: (90.00%) (34889/38528)
Epoch: 85 | Batch_idx: 310 |  Loss: (0.2715) |  Loss2: (0.0000) | Acc: (90.00%) (36043/39808)
Epoch: 85 | Batch_idx: 320 |  Loss: (0.2715) |  Loss2: (0.0000) | Acc: (90.00%) (37200/41088)
Epoch: 85 | Batch_idx: 330 |  Loss: (0.2714) |  Loss2: (0.0000) | Acc: (90.00%) (38371/42368)
Epoch: 85 | Batch_idx: 340 |  Loss: (0.2712) |  Loss2: (0.0000) | Acc: (90.00%) (39540/43648)
Epoch: 85 | Batch_idx: 350 |  Loss: (0.2714) |  Loss2: (0.0000) | Acc: (90.00%) (40699/44928)
Epoch: 85 | Batch_idx: 360 |  Loss: (0.2716) |  Loss2: (0.0000) | Acc: (90.00%) (41859/46208)
Epoch: 85 | Batch_idx: 370 |  Loss: (0.2712) |  Loss2: (0.0000) | Acc: (90.00%) (43029/47488)
Epoch: 85 | Batch_idx: 380 |  Loss: (0.2721) |  Loss2: (0.0000) | Acc: (90.00%) (44174/48768)
Epoch: 85 | Batch_idx: 390 |  Loss: (0.2718) |  Loss2: (0.0000) | Acc: (90.00%) (45289/50000)
=> saving checkpoint 'drive/app/torch/save_Routing_Gate_2/checkpoint_085.pth.tar'
# TEST : Loss: (0.4050) | Acc: (86.00%) (8652/10000)
percent tensor([0.5331, 0.5202, 0.5473, 0.5440, 0.5443, 0.5376, 0.5299, 0.5402, 0.5369,
        0.5288, 0.5294, 0.5378, 0.5286, 0.5230, 0.5289, 0.5315],
       device='cuda:0') torch.Size([16])
percent tensor([0.5375, 0.5477, 0.5307, 0.5348, 0.5351, 0.5480, 0.5430, 0.5337, 0.5348,
        0.5377, 0.5381, 0.5321, 0.5358, 0.5500, 0.5454, 0.5405],
       device='cuda:0') torch.Size([16])
percent tensor([0.5851, 0.6201, 0.5259, 0.4677, 0.5123, 0.4848, 0.6034, 0.5434, 0.5701,
        0.5949, 0.6022, 0.5770, 0.6538, 0.5077, 0.5858, 0.5398],
       device='cuda:0') torch.Size([16])
percent tensor([0.6772, 0.7010, 0.6821, 0.6928, 0.6871, 0.6701, 0.7052, 0.6778, 0.7000,
        0.7056, 0.7306, 0.7212, 0.6987, 0.7163, 0.6941, 0.6920],
       device='cuda:0') torch.Size([16])
percent tensor([0.6435, 0.6166, 0.6749, 0.6520, 0.6573, 0.7910, 0.6535, 0.6097, 0.6845,
        0.6379, 0.6664, 0.6083, 0.6860, 0.6903, 0.6301, 0.7099],
       device='cuda:0') torch.Size([16])
percent tensor([0.4952, 0.5605, 0.5347, 0.5107, 0.4934, 0.5565, 0.4948, 0.3833, 0.5878,
        0.5206, 0.6085, 0.5802, 0.5725, 0.6237, 0.4231, 0.5215],
       device='cuda:0') torch.Size([16])
percent tensor([0.5323, 0.5954, 0.7613, 0.7400, 0.7860, 0.6592, 0.6331, 0.6793, 0.6384,
        0.5822, 0.6549, 0.7515, 0.5790, 0.6712, 0.6233, 0.5899],
       device='cuda:0') torch.Size([16])
percent tensor([0.9993, 0.9976, 0.9992, 0.9987, 0.9987, 0.9981, 0.9982, 0.9991, 0.9978,
        0.9985, 0.9988, 0.9987, 0.9983, 0.9982, 0.9985, 0.9995],
       device='cuda:0') torch.Size([16])
Epoch: 86 | Batch_idx: 0 |  Loss: (0.1821) |  Loss2: (0.0000) | Acc: (92.00%) (119/128)
Epoch: 86 | Batch_idx: 10 |  Loss: (0.2645) |  Loss2: (0.0000) | Acc: (90.00%) (1272/1408)
Epoch: 86 | Batch_idx: 20 |  Loss: (0.2636) |  Loss2: (0.0000) | Acc: (90.00%) (2438/2688)
Epoch: 86 | Batch_idx: 30 |  Loss: (0.2493) |  Loss2: (0.0000) | Acc: (91.00%) (3620/3968)
Epoch: 86 | Batch_idx: 40 |  Loss: (0.2481) |  Loss2: (0.0000) | Acc: (91.00%) (4790/5248)
Epoch: 86 | Batch_idx: 50 |  Loss: (0.2522) |  Loss2: (0.0000) | Acc: (91.00%) (5955/6528)
Epoch: 86 | Batch_idx: 60 |  Loss: (0.2563) |  Loss2: (0.0000) | Acc: (91.00%) (7119/7808)
Epoch: 86 | Batch_idx: 70 |  Loss: (0.2536) |  Loss2: (0.0000) | Acc: (91.00%) (8290/9088)
Epoch: 86 | Batch_idx: 80 |  Loss: (0.2510) |  Loss2: (0.0000) | Acc: (91.00%) (9463/10368)
Epoch: 86 | Batch_idx: 90 |  Loss: (0.2533) |  Loss2: (0.0000) | Acc: (91.00%) (10628/11648)
Epoch: 86 | Batch_idx: 100 |  Loss: (0.2536) |  Loss2: (0.0000) | Acc: (91.00%) (11794/12928)
Epoch: 86 | Batch_idx: 110 |  Loss: (0.2536) |  Loss2: (0.0000) | Acc: (91.00%) (12968/14208)
Epoch: 86 | Batch_idx: 120 |  Loss: (0.2530) |  Loss2: (0.0000) | Acc: (91.00%) (14137/15488)
Epoch: 86 | Batch_idx: 130 |  Loss: (0.2546) |  Loss2: (0.0000) | Acc: (91.00%) (15288/16768)
Epoch: 86 | Batch_idx: 140 |  Loss: (0.2543) |  Loss2: (0.0000) | Acc: (91.00%) (16455/18048)
Epoch: 86 | Batch_idx: 150 |  Loss: (0.2529) |  Loss2: (0.0000) | Acc: (91.00%) (17633/19328)
Epoch: 86 | Batch_idx: 160 |  Loss: (0.2525) |  Loss2: (0.0000) | Acc: (91.00%) (18796/20608)
Epoch: 86 | Batch_idx: 170 |  Loss: (0.2532) |  Loss2: (0.0000) | Acc: (91.00%) (19967/21888)
Epoch: 86 | Batch_idx: 180 |  Loss: (0.2551) |  Loss2: (0.0000) | Acc: (91.00%) (21130/23168)
Epoch: 86 | Batch_idx: 190 |  Loss: (0.2557) |  Loss2: (0.0000) | Acc: (91.00%) (22296/24448)
Epoch: 86 | Batch_idx: 200 |  Loss: (0.2545) |  Loss2: (0.0000) | Acc: (91.00%) (23476/25728)
Epoch: 86 | Batch_idx: 210 |  Loss: (0.2569) |  Loss2: (0.0000) | Acc: (91.00%) (24616/27008)
Epoch: 86 | Batch_idx: 220 |  Loss: (0.2557) |  Loss2: (0.0000) | Acc: (91.00%) (25788/28288)
Epoch: 86 | Batch_idx: 230 |  Loss: (0.2560) |  Loss2: (0.0000) | Acc: (91.00%) (26952/29568)
Epoch: 86 | Batch_idx: 240 |  Loss: (0.2569) |  Loss2: (0.0000) | Acc: (91.00%) (28108/30848)
Epoch: 86 | Batch_idx: 250 |  Loss: (0.2567) |  Loss2: (0.0000) | Acc: (91.00%) (29278/32128)
Epoch: 86 | Batch_idx: 260 |  Loss: (0.2566) |  Loss2: (0.0000) | Acc: (91.00%) (30441/33408)
Epoch: 86 | Batch_idx: 270 |  Loss: (0.2564) |  Loss2: (0.0000) | Acc: (91.00%) (31604/34688)
Epoch: 86 | Batch_idx: 280 |  Loss: (0.2555) |  Loss2: (0.0000) | Acc: (91.00%) (32773/35968)
Epoch: 86 | Batch_idx: 290 |  Loss: (0.2553) |  Loss2: (0.0000) | Acc: (91.00%) (33948/37248)
Epoch: 86 | Batch_idx: 300 |  Loss: (0.2547) |  Loss2: (0.0000) | Acc: (91.00%) (35126/38528)
Epoch: 86 | Batch_idx: 310 |  Loss: (0.2545) |  Loss2: (0.0000) | Acc: (91.00%) (36292/39808)
Epoch: 86 | Batch_idx: 320 |  Loss: (0.2548) |  Loss2: (0.0000) | Acc: (91.00%) (37461/41088)
Epoch: 86 | Batch_idx: 330 |  Loss: (0.2541) |  Loss2: (0.0000) | Acc: (91.00%) (38653/42368)
Epoch: 86 | Batch_idx: 340 |  Loss: (0.2538) |  Loss2: (0.0000) | Acc: (91.00%) (39825/43648)
Epoch: 86 | Batch_idx: 350 |  Loss: (0.2535) |  Loss2: (0.0000) | Acc: (91.00%) (40994/44928)
Epoch: 86 | Batch_idx: 360 |  Loss: (0.2526) |  Loss2: (0.0000) | Acc: (91.00%) (42180/46208)
Epoch: 86 | Batch_idx: 370 |  Loss: (0.2523) |  Loss2: (0.0000) | Acc: (91.00%) (43357/47488)
Epoch: 86 | Batch_idx: 380 |  Loss: (0.2518) |  Loss2: (0.0000) | Acc: (91.00%) (44535/48768)
Epoch: 86 | Batch_idx: 390 |  Loss: (0.2513) |  Loss2: (0.0000) | Acc: (91.00%) (45665/50000)
# TEST : Loss: (0.3874) | Acc: (86.00%) (8691/10000)
percent tensor([0.5361, 0.5228, 0.5517, 0.5481, 0.5485, 0.5410, 0.5330, 0.5442, 0.5405,
        0.5319, 0.5322, 0.5416, 0.5316, 0.5256, 0.5320, 0.5345],
       device='cuda:0') torch.Size([16])
percent tensor([0.5389, 0.5484, 0.5331, 0.5374, 0.5376, 0.5498, 0.5443, 0.5363, 0.5364,
        0.5389, 0.5387, 0.5339, 0.5364, 0.5515, 0.5463, 0.5421],
       device='cuda:0') torch.Size([16])
percent tensor([0.5805, 0.6124, 0.5281, 0.4700, 0.5168, 0.4816, 0.5977, 0.5443, 0.5694,
        0.5911, 0.5974, 0.5761, 0.6477, 0.5039, 0.5787, 0.5357],
       device='cuda:0') torch.Size([16])
percent tensor([0.6792, 0.7021, 0.6844, 0.6959, 0.6900, 0.6728, 0.7076, 0.6810, 0.7030,
        0.7069, 0.7324, 0.7235, 0.6993, 0.7192, 0.6965, 0.6939],
       device='cuda:0') torch.Size([16])
percent tensor([0.6440, 0.6094, 0.6803, 0.6553, 0.6615, 0.7952, 0.6496, 0.6119, 0.6797,
        0.6286, 0.6540, 0.6040, 0.6807, 0.6799, 0.6251, 0.7098],
       device='cuda:0') torch.Size([16])
percent tensor([0.5140, 0.5881, 0.5448, 0.5183, 0.5032, 0.5792, 0.5121, 0.3866, 0.6065,
        0.5472, 0.6274, 0.5916, 0.6007, 0.6462, 0.4331, 0.5444],
       device='cuda:0') torch.Size([16])
percent tensor([0.5376, 0.6051, 0.7603, 0.7436, 0.7853, 0.6674, 0.6354, 0.6682, 0.6497,
        0.5858, 0.6653, 0.7569, 0.5897, 0.6936, 0.6254, 0.6010],
       device='cuda:0') torch.Size([16])
percent tensor([0.9993, 0.9977, 0.9991, 0.9987, 0.9987, 0.9983, 0.9982, 0.9991, 0.9979,
        0.9985, 0.9988, 0.9986, 0.9985, 0.9981, 0.9984, 0.9995],
       device='cuda:0') torch.Size([16])
Epoch: 87 | Batch_idx: 0 |  Loss: (0.1914) |  Loss2: (0.0000) | Acc: (92.00%) (118/128)
Epoch: 87 | Batch_idx: 10 |  Loss: (0.2153) |  Loss2: (0.0000) | Acc: (92.00%) (1303/1408)
Epoch: 87 | Batch_idx: 20 |  Loss: (0.2200) |  Loss2: (0.0000) | Acc: (92.00%) (2480/2688)
Epoch: 87 | Batch_idx: 30 |  Loss: (0.2306) |  Loss2: (0.0000) | Acc: (92.00%) (3653/3968)
Epoch: 87 | Batch_idx: 40 |  Loss: (0.2366) |  Loss2: (0.0000) | Acc: (91.00%) (4823/5248)
Epoch: 87 | Batch_idx: 50 |  Loss: (0.2400) |  Loss2: (0.0000) | Acc: (91.00%) (5989/6528)
Epoch: 87 | Batch_idx: 60 |  Loss: (0.2427) |  Loss2: (0.0000) | Acc: (91.00%) (7158/7808)
Epoch: 87 | Batch_idx: 70 |  Loss: (0.2426) |  Loss2: (0.0000) | Acc: (91.00%) (8328/9088)
Epoch: 87 | Batch_idx: 80 |  Loss: (0.2423) |  Loss2: (0.0000) | Acc: (91.00%) (9489/10368)
Epoch: 87 | Batch_idx: 90 |  Loss: (0.2433) |  Loss2: (0.0000) | Acc: (91.00%) (10644/11648)
Epoch: 87 | Batch_idx: 100 |  Loss: (0.2438) |  Loss2: (0.0000) | Acc: (91.00%) (11808/12928)
Epoch: 87 | Batch_idx: 110 |  Loss: (0.2441) |  Loss2: (0.0000) | Acc: (91.00%) (12982/14208)
Epoch: 87 | Batch_idx: 120 |  Loss: (0.2425) |  Loss2: (0.0000) | Acc: (91.00%) (14165/15488)
Epoch: 87 | Batch_idx: 130 |  Loss: (0.2417) |  Loss2: (0.0000) | Acc: (91.00%) (15350/16768)
Epoch: 87 | Batch_idx: 140 |  Loss: (0.2421) |  Loss2: (0.0000) | Acc: (91.00%) (16524/18048)
Epoch: 87 | Batch_idx: 150 |  Loss: (0.2434) |  Loss2: (0.0000) | Acc: (91.00%) (17684/19328)
Epoch: 87 | Batch_idx: 160 |  Loss: (0.2440) |  Loss2: (0.0000) | Acc: (91.00%) (18859/20608)
Epoch: 87 | Batch_idx: 170 |  Loss: (0.2444) |  Loss2: (0.0000) | Acc: (91.00%) (20028/21888)
Epoch: 87 | Batch_idx: 180 |  Loss: (0.2438) |  Loss2: (0.0000) | Acc: (91.00%) (21211/23168)
Epoch: 87 | Batch_idx: 190 |  Loss: (0.2427) |  Loss2: (0.0000) | Acc: (91.00%) (22388/24448)
Epoch: 87 | Batch_idx: 200 |  Loss: (0.2417) |  Loss2: (0.0000) | Acc: (91.00%) (23570/25728)
Epoch: 87 | Batch_idx: 210 |  Loss: (0.2413) |  Loss2: (0.0000) | Acc: (91.00%) (24744/27008)
Epoch: 87 | Batch_idx: 220 |  Loss: (0.2411) |  Loss2: (0.0000) | Acc: (91.00%) (25920/28288)
Epoch: 87 | Batch_idx: 230 |  Loss: (0.2412) |  Loss2: (0.0000) | Acc: (91.00%) (27108/29568)
Epoch: 87 | Batch_idx: 240 |  Loss: (0.2415) |  Loss2: (0.0000) | Acc: (91.00%) (28283/30848)
Epoch: 87 | Batch_idx: 250 |  Loss: (0.2421) |  Loss2: (0.0000) | Acc: (91.00%) (29450/32128)
Epoch: 87 | Batch_idx: 260 |  Loss: (0.2431) |  Loss2: (0.0000) | Acc: (91.00%) (30605/33408)
Epoch: 87 | Batch_idx: 270 |  Loss: (0.2437) |  Loss2: (0.0000) | Acc: (91.00%) (31771/34688)
Epoch: 87 | Batch_idx: 280 |  Loss: (0.2432) |  Loss2: (0.0000) | Acc: (91.00%) (32936/35968)
Epoch: 87 | Batch_idx: 290 |  Loss: (0.2429) |  Loss2: (0.0000) | Acc: (91.00%) (34120/37248)
Epoch: 87 | Batch_idx: 300 |  Loss: (0.2429) |  Loss2: (0.0000) | Acc: (91.00%) (35285/38528)
Epoch: 87 | Batch_idx: 310 |  Loss: (0.2427) |  Loss2: (0.0000) | Acc: (91.00%) (36458/39808)
Epoch: 87 | Batch_idx: 320 |  Loss: (0.2428) |  Loss2: (0.0000) | Acc: (91.00%) (37626/41088)
Epoch: 87 | Batch_idx: 330 |  Loss: (0.2426) |  Loss2: (0.0000) | Acc: (91.00%) (38808/42368)
Epoch: 87 | Batch_idx: 340 |  Loss: (0.2427) |  Loss2: (0.0000) | Acc: (91.00%) (39982/43648)
Epoch: 87 | Batch_idx: 350 |  Loss: (0.2430) |  Loss2: (0.0000) | Acc: (91.00%) (41147/44928)
Epoch: 87 | Batch_idx: 360 |  Loss: (0.2427) |  Loss2: (0.0000) | Acc: (91.00%) (42320/46208)
Epoch: 87 | Batch_idx: 370 |  Loss: (0.2426) |  Loss2: (0.0000) | Acc: (91.00%) (43495/47488)
Epoch: 87 | Batch_idx: 380 |  Loss: (0.2427) |  Loss2: (0.0000) | Acc: (91.00%) (44661/48768)
Epoch: 87 | Batch_idx: 390 |  Loss: (0.2420) |  Loss2: (0.0000) | Acc: (91.00%) (45796/50000)
# TEST : Loss: (0.3803) | Acc: (87.00%) (8715/10000)
percent tensor([0.5376, 0.5240, 0.5540, 0.5503, 0.5508, 0.5429, 0.5347, 0.5462, 0.5423,
        0.5335, 0.5334, 0.5434, 0.5329, 0.5274, 0.5335, 0.5361],
       device='cuda:0') torch.Size([16])
percent tensor([0.5391, 0.5478, 0.5340, 0.5384, 0.5383, 0.5506, 0.5441, 0.5370, 0.5364,
        0.5387, 0.5384, 0.5341, 0.5360, 0.5513, 0.5462, 0.5424],
       device='cuda:0') torch.Size([16])
percent tensor([0.5784, 0.6086, 0.5268, 0.4682, 0.5160, 0.4810, 0.5942, 0.5425, 0.5670,
        0.5874, 0.5934, 0.5719, 0.6450, 0.4995, 0.5758, 0.5336],
       device='cuda:0') torch.Size([16])
percent tensor([0.6734, 0.6953, 0.6792, 0.6910, 0.6842, 0.6681, 0.7020, 0.6756, 0.6975,
        0.7002, 0.7266, 0.7180, 0.6924, 0.7135, 0.6910, 0.6881],
       device='cuda:0') torch.Size([16])
percent tensor([0.6482, 0.6069, 0.6885, 0.6640, 0.6698, 0.8033, 0.6510, 0.6184, 0.6824,
        0.6244, 0.6496, 0.6047, 0.6815, 0.6779, 0.6262, 0.7144],
       device='cuda:0') torch.Size([16])
percent tensor([0.5194, 0.5969, 0.5445, 0.5144, 0.5039, 0.5854, 0.5148, 0.3833, 0.6124,
        0.5557, 0.6323, 0.5888, 0.6120, 0.6504, 0.4309, 0.5499],
       device='cuda:0') torch.Size([16])
percent tensor([0.5454, 0.6112, 0.7646, 0.7518, 0.7919, 0.6780, 0.6407, 0.6715, 0.6569,
        0.5890, 0.6743, 0.7644, 0.5992, 0.7041, 0.6325, 0.6123],
       device='cuda:0') torch.Size([16])
percent tensor([0.9994, 0.9978, 0.9992, 0.9988, 0.9988, 0.9984, 0.9983, 0.9991, 0.9981,
        0.9986, 0.9989, 0.9987, 0.9986, 0.9981, 0.9984, 0.9996],
       device='cuda:0') torch.Size([16])
Epoch: 88 | Batch_idx: 0 |  Loss: (0.2029) |  Loss2: (0.0000) | Acc: (92.00%) (118/128)
Epoch: 88 | Batch_idx: 10 |  Loss: (0.2440) |  Loss2: (0.0000) | Acc: (91.00%) (1287/1408)
Epoch: 88 | Batch_idx: 20 |  Loss: (0.2476) |  Loss2: (0.0000) | Acc: (91.00%) (2461/2688)
Epoch: 88 | Batch_idx: 30 |  Loss: (0.2342) |  Loss2: (0.0000) | Acc: (92.00%) (3655/3968)
Epoch: 88 | Batch_idx: 40 |  Loss: (0.2317) |  Loss2: (0.0000) | Acc: (92.00%) (4838/5248)
Epoch: 88 | Batch_idx: 50 |  Loss: (0.2310) |  Loss2: (0.0000) | Acc: (92.00%) (6017/6528)
Epoch: 88 | Batch_idx: 60 |  Loss: (0.2310) |  Loss2: (0.0000) | Acc: (92.00%) (7200/7808)
Epoch: 88 | Batch_idx: 70 |  Loss: (0.2367) |  Loss2: (0.0000) | Acc: (92.00%) (8361/9088)
Epoch: 88 | Batch_idx: 80 |  Loss: (0.2362) |  Loss2: (0.0000) | Acc: (91.00%) (9537/10368)
Epoch: 88 | Batch_idx: 90 |  Loss: (0.2388) |  Loss2: (0.0000) | Acc: (91.00%) (10699/11648)
Epoch: 88 | Batch_idx: 100 |  Loss: (0.2381) |  Loss2: (0.0000) | Acc: (91.00%) (11876/12928)
Epoch: 88 | Batch_idx: 110 |  Loss: (0.2408) |  Loss2: (0.0000) | Acc: (91.00%) (13029/14208)
Epoch: 88 | Batch_idx: 120 |  Loss: (0.2427) |  Loss2: (0.0000) | Acc: (91.00%) (14187/15488)
Epoch: 88 | Batch_idx: 130 |  Loss: (0.2430) |  Loss2: (0.0000) | Acc: (91.00%) (15354/16768)
Epoch: 88 | Batch_idx: 140 |  Loss: (0.2430) |  Loss2: (0.0000) | Acc: (91.00%) (16518/18048)
Epoch: 88 | Batch_idx: 150 |  Loss: (0.2444) |  Loss2: (0.0000) | Acc: (91.00%) (17683/19328)
Epoch: 88 | Batch_idx: 160 |  Loss: (0.2430) |  Loss2: (0.0000) | Acc: (91.00%) (18866/20608)
Epoch: 88 | Batch_idx: 170 |  Loss: (0.2413) |  Loss2: (0.0000) | Acc: (91.00%) (20055/21888)
Epoch: 88 | Batch_idx: 180 |  Loss: (0.2401) |  Loss2: (0.0000) | Acc: (91.00%) (21237/23168)
Epoch: 88 | Batch_idx: 190 |  Loss: (0.2394) |  Loss2: (0.0000) | Acc: (91.00%) (22415/24448)
Epoch: 88 | Batch_idx: 200 |  Loss: (0.2396) |  Loss2: (0.0000) | Acc: (91.00%) (23592/25728)
Epoch: 88 | Batch_idx: 210 |  Loss: (0.2400) |  Loss2: (0.0000) | Acc: (91.00%) (24769/27008)
Epoch: 88 | Batch_idx: 220 |  Loss: (0.2388) |  Loss2: (0.0000) | Acc: (91.00%) (25965/28288)
Epoch: 88 | Batch_idx: 230 |  Loss: (0.2377) |  Loss2: (0.0000) | Acc: (91.00%) (27146/29568)
Epoch: 88 | Batch_idx: 240 |  Loss: (0.2378) |  Loss2: (0.0000) | Acc: (91.00%) (28318/30848)
Epoch: 88 | Batch_idx: 250 |  Loss: (0.2371) |  Loss2: (0.0000) | Acc: (91.00%) (29508/32128)
Epoch: 88 | Batch_idx: 260 |  Loss: (0.2370) |  Loss2: (0.0000) | Acc: (91.00%) (30684/33408)
Epoch: 88 | Batch_idx: 270 |  Loss: (0.2365) |  Loss2: (0.0000) | Acc: (91.00%) (31866/34688)
Epoch: 88 | Batch_idx: 280 |  Loss: (0.2372) |  Loss2: (0.0000) | Acc: (91.00%) (33026/35968)
Epoch: 88 | Batch_idx: 290 |  Loss: (0.2374) |  Loss2: (0.0000) | Acc: (91.00%) (34197/37248)
Epoch: 88 | Batch_idx: 300 |  Loss: (0.2366) |  Loss2: (0.0000) | Acc: (91.00%) (35385/38528)
Epoch: 88 | Batch_idx: 310 |  Loss: (0.2371) |  Loss2: (0.0000) | Acc: (91.00%) (36554/39808)
Epoch: 88 | Batch_idx: 320 |  Loss: (0.2364) |  Loss2: (0.0000) | Acc: (91.00%) (37735/41088)
Epoch: 88 | Batch_idx: 330 |  Loss: (0.2358) |  Loss2: (0.0000) | Acc: (91.00%) (38926/42368)
Epoch: 88 | Batch_idx: 340 |  Loss: (0.2362) |  Loss2: (0.0000) | Acc: (91.00%) (40089/43648)
Epoch: 88 | Batch_idx: 350 |  Loss: (0.2368) |  Loss2: (0.0000) | Acc: (91.00%) (41249/44928)
Epoch: 88 | Batch_idx: 360 |  Loss: (0.2363) |  Loss2: (0.0000) | Acc: (91.00%) (42424/46208)
Epoch: 88 | Batch_idx: 370 |  Loss: (0.2363) |  Loss2: (0.0000) | Acc: (91.00%) (43613/47488)
Epoch: 88 | Batch_idx: 380 |  Loss: (0.2359) |  Loss2: (0.0000) | Acc: (91.00%) (44793/48768)
Epoch: 88 | Batch_idx: 390 |  Loss: (0.2359) |  Loss2: (0.0000) | Acc: (91.00%) (45926/50000)
# TEST : Loss: (0.3757) | Acc: (87.00%) (8724/10000)
percent tensor([0.5369, 0.5228, 0.5540, 0.5503, 0.5504, 0.5421, 0.5337, 0.5458, 0.5417,
        0.5326, 0.5325, 0.5430, 0.5321, 0.5264, 0.5325, 0.5354],
       device='cuda:0') torch.Size([16])
percent tensor([0.5387, 0.5470, 0.5337, 0.5384, 0.5378, 0.5508, 0.5434, 0.5365, 0.5358,
        0.5379, 0.5377, 0.5334, 0.5350, 0.5509, 0.5457, 0.5422],
       device='cuda:0') torch.Size([16])
percent tensor([0.5815, 0.6081, 0.5358, 0.4764, 0.5272, 0.4864, 0.5964, 0.5508, 0.5719,
        0.5897, 0.5944, 0.5780, 0.6457, 0.5013, 0.5776, 0.5364],
       device='cuda:0') torch.Size([16])
percent tensor([0.6803, 0.7017, 0.6846, 0.6973, 0.6903, 0.6740, 0.7092, 0.6820, 0.7041,
        0.7063, 0.7333, 0.7250, 0.6984, 0.7202, 0.6985, 0.6944],
       device='cuda:0') torch.Size([16])
percent tensor([0.6510, 0.6061, 0.6941, 0.6676, 0.6739, 0.8079, 0.6503, 0.6226, 0.6817,
        0.6221, 0.6450, 0.6060, 0.6833, 0.6743, 0.6272, 0.7160],
       device='cuda:0') torch.Size([16])
percent tensor([0.5176, 0.5994, 0.5418, 0.5105, 0.5020, 0.5832, 0.5134, 0.3788, 0.6115,
        0.5583, 0.6310, 0.5864, 0.6120, 0.6506, 0.4268, 0.5477],
       device='cuda:0') torch.Size([16])
percent tensor([0.5616, 0.6247, 0.7721, 0.7643, 0.8027, 0.6899, 0.6555, 0.6810, 0.6715,
        0.6038, 0.6870, 0.7755, 0.6104, 0.7200, 0.6494, 0.6313],
       device='cuda:0') torch.Size([16])
percent tensor([0.9994, 0.9980, 0.9992, 0.9989, 0.9987, 0.9985, 0.9984, 0.9991, 0.9982,
        0.9987, 0.9989, 0.9988, 0.9987, 0.9982, 0.9985, 0.9996],
       device='cuda:0') torch.Size([16])
Epoch: 89 | Batch_idx: 0 |  Loss: (0.1565) |  Loss2: (0.0000) | Acc: (95.00%) (122/128)
Epoch: 89 | Batch_idx: 10 |  Loss: (0.2368) |  Loss2: (0.0000) | Acc: (91.00%) (1286/1408)
Epoch: 89 | Batch_idx: 20 |  Loss: (0.2388) |  Loss2: (0.0000) | Acc: (91.00%) (2461/2688)
Epoch: 89 | Batch_idx: 30 |  Loss: (0.2379) |  Loss2: (0.0000) | Acc: (91.00%) (3635/3968)
Epoch: 89 | Batch_idx: 40 |  Loss: (0.2422) |  Loss2: (0.0000) | Acc: (91.00%) (4808/5248)
Epoch: 89 | Batch_idx: 50 |  Loss: (0.2433) |  Loss2: (0.0000) | Acc: (91.00%) (5982/6528)
Epoch: 89 | Batch_idx: 60 |  Loss: (0.2422) |  Loss2: (0.0000) | Acc: (91.00%) (7160/7808)
Epoch: 89 | Batch_idx: 70 |  Loss: (0.2411) |  Loss2: (0.0000) | Acc: (91.00%) (8333/9088)
Epoch: 89 | Batch_idx: 80 |  Loss: (0.2416) |  Loss2: (0.0000) | Acc: (91.00%) (9508/10368)
Epoch: 89 | Batch_idx: 90 |  Loss: (0.2385) |  Loss2: (0.0000) | Acc: (91.00%) (10691/11648)
Epoch: 89 | Batch_idx: 100 |  Loss: (0.2385) |  Loss2: (0.0000) | Acc: (91.00%) (11876/12928)
Epoch: 89 | Batch_idx: 110 |  Loss: (0.2392) |  Loss2: (0.0000) | Acc: (91.00%) (13046/14208)
Epoch: 89 | Batch_idx: 120 |  Loss: (0.2381) |  Loss2: (0.0000) | Acc: (91.00%) (14229/15488)
Epoch: 89 | Batch_idx: 130 |  Loss: (0.2408) |  Loss2: (0.0000) | Acc: (91.00%) (15377/16768)
Epoch: 89 | Batch_idx: 140 |  Loss: (0.2408) |  Loss2: (0.0000) | Acc: (91.00%) (16555/18048)
Epoch: 89 | Batch_idx: 150 |  Loss: (0.2400) |  Loss2: (0.0000) | Acc: (91.00%) (17736/19328)
Epoch: 89 | Batch_idx: 160 |  Loss: (0.2384) |  Loss2: (0.0000) | Acc: (91.00%) (18920/20608)
Epoch: 89 | Batch_idx: 170 |  Loss: (0.2376) |  Loss2: (0.0000) | Acc: (91.00%) (20094/21888)
Epoch: 89 | Batch_idx: 180 |  Loss: (0.2385) |  Loss2: (0.0000) | Acc: (91.00%) (21265/23168)
Epoch: 89 | Batch_idx: 190 |  Loss: (0.2381) |  Loss2: (0.0000) | Acc: (91.00%) (22437/24448)
Epoch: 89 | Batch_idx: 200 |  Loss: (0.2383) |  Loss2: (0.0000) | Acc: (91.00%) (23605/25728)
Epoch: 89 | Batch_idx: 210 |  Loss: (0.2390) |  Loss2: (0.0000) | Acc: (91.00%) (24774/27008)
Epoch: 89 | Batch_idx: 220 |  Loss: (0.2374) |  Loss2: (0.0000) | Acc: (91.00%) (25966/28288)
Epoch: 89 | Batch_idx: 230 |  Loss: (0.2359) |  Loss2: (0.0000) | Acc: (91.00%) (27151/29568)
Epoch: 89 | Batch_idx: 240 |  Loss: (0.2352) |  Loss2: (0.0000) | Acc: (91.00%) (28331/30848)
Epoch: 89 | Batch_idx: 250 |  Loss: (0.2363) |  Loss2: (0.0000) | Acc: (91.00%) (29499/32128)
Epoch: 89 | Batch_idx: 260 |  Loss: (0.2359) |  Loss2: (0.0000) | Acc: (91.00%) (30677/33408)
Epoch: 89 | Batch_idx: 270 |  Loss: (0.2358) |  Loss2: (0.0000) | Acc: (91.00%) (31851/34688)
Epoch: 89 | Batch_idx: 280 |  Loss: (0.2342) |  Loss2: (0.0000) | Acc: (91.00%) (33050/35968)
Epoch: 89 | Batch_idx: 290 |  Loss: (0.2339) |  Loss2: (0.0000) | Acc: (91.00%) (34236/37248)
Epoch: 89 | Batch_idx: 300 |  Loss: (0.2341) |  Loss2: (0.0000) | Acc: (91.00%) (35409/38528)
Epoch: 89 | Batch_idx: 310 |  Loss: (0.2345) |  Loss2: (0.0000) | Acc: (91.00%) (36580/39808)
Epoch: 89 | Batch_idx: 320 |  Loss: (0.2346) |  Loss2: (0.0000) | Acc: (91.00%) (37760/41088)
Epoch: 89 | Batch_idx: 330 |  Loss: (0.2341) |  Loss2: (0.0000) | Acc: (91.00%) (38944/42368)
Epoch: 89 | Batch_idx: 340 |  Loss: (0.2334) |  Loss2: (0.0000) | Acc: (91.00%) (40143/43648)
Epoch: 89 | Batch_idx: 350 |  Loss: (0.2335) |  Loss2: (0.0000) | Acc: (91.00%) (41321/44928)
Epoch: 89 | Batch_idx: 360 |  Loss: (0.2333) |  Loss2: (0.0000) | Acc: (91.00%) (42504/46208)
Epoch: 89 | Batch_idx: 370 |  Loss: (0.2331) |  Loss2: (0.0000) | Acc: (91.00%) (43685/47488)
Epoch: 89 | Batch_idx: 380 |  Loss: (0.2330) |  Loss2: (0.0000) | Acc: (91.00%) (44863/48768)
Epoch: 89 | Batch_idx: 390 |  Loss: (0.2329) |  Loss2: (0.0000) | Acc: (92.00%) (46001/50000)
# TEST : Loss: (0.3712) | Acc: (87.00%) (8752/10000)
percent tensor([0.5392, 0.5251, 0.5570, 0.5530, 0.5533, 0.5445, 0.5361, 0.5486, 0.5444,
        0.5351, 0.5348, 0.5456, 0.5344, 0.5285, 0.5349, 0.5376],
       device='cuda:0') torch.Size([16])
percent tensor([0.5373, 0.5454, 0.5326, 0.5375, 0.5365, 0.5498, 0.5419, 0.5354, 0.5342,
        0.5364, 0.5361, 0.5320, 0.5332, 0.5495, 0.5442, 0.5410],
       device='cuda:0') torch.Size([16])
percent tensor([0.5815, 0.6094, 0.5365, 0.4742, 0.5272, 0.4823, 0.5972, 0.5509, 0.5724,
        0.5921, 0.5957, 0.5793, 0.6489, 0.5001, 0.5758, 0.5360],
       device='cuda:0') torch.Size([16])
percent tensor([0.6792, 0.7012, 0.6824, 0.6951, 0.6881, 0.6728, 0.7084, 0.6800, 0.7023,
        0.7050, 0.7325, 0.7235, 0.6977, 0.7186, 0.6980, 0.6931],
       device='cuda:0') torch.Size([16])
percent tensor([0.6491, 0.6063, 0.6950, 0.6683, 0.6728, 0.8079, 0.6491, 0.6200, 0.6825,
        0.6187, 0.6399, 0.6046, 0.6831, 0.6758, 0.6223, 0.7151],
       device='cuda:0') torch.Size([16])
percent tensor([0.5167, 0.6044, 0.5398, 0.5064, 0.5011, 0.5813, 0.5140, 0.3791, 0.6126,
        0.5590, 0.6305, 0.5862, 0.6146, 0.6532, 0.4266, 0.5446],
       device='cuda:0') torch.Size([16])
percent tensor([0.5577, 0.6224, 0.7758, 0.7686, 0.8086, 0.6879, 0.6567, 0.6853, 0.6713,
        0.6006, 0.6823, 0.7773, 0.6052, 0.7181, 0.6536, 0.6308],
       device='cuda:0') torch.Size([16])
percent tensor([0.9994, 0.9981, 0.9992, 0.9990, 0.9988, 0.9986, 0.9985, 0.9992, 0.9983,
        0.9987, 0.9989, 0.9988, 0.9988, 0.9982, 0.9985, 0.9996],
       device='cuda:0') torch.Size([16])
True Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=128, out_features=16, bias=False)
False Linear(in_features=16, out_features=2, bias=False)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=128, out_features=16, bias=False)
False Linear(in_features=16, out_features=2, bias=False)
True Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=256, out_features=32, bias=False)
False Linear(in_features=32, out_features=2, bias=False)
True Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=256, out_features=32, bias=False)
False Linear(in_features=32, out_features=2, bias=False)
True Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=512, out_features=64, bias=False)
False Linear(in_features=64, out_features=2, bias=False)
True Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=512, out_features=64, bias=False)
False Linear(in_features=64, out_features=2, bias=False)
True Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1024, out_features=128, bias=False)
False Linear(in_features=128, out_features=2, bias=False)
True Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1024, out_features=128, bias=False)
False Linear(in_features=128, out_features=2, bias=False)
True Linear(in_features=512, out_features=10, bias=True)
Epoch: 90 | Batch_idx: 0 |  Loss: (0.2188) |  Loss2: (0.0000) | Acc: (91.00%) (117/128)
Epoch: 90 | Batch_idx: 10 |  Loss: (0.2189) |  Loss2: (0.0000) | Acc: (92.00%) (1298/1408)
Epoch: 90 | Batch_idx: 20 |  Loss: (0.2270) |  Loss2: (0.0000) | Acc: (91.00%) (2470/2688)
Epoch: 90 | Batch_idx: 30 |  Loss: (0.2278) |  Loss2: (0.0000) | Acc: (91.00%) (3644/3968)
Epoch: 90 | Batch_idx: 40 |  Loss: (0.2395) |  Loss2: (0.0000) | Acc: (91.00%) (4793/5248)
Epoch: 90 | Batch_idx: 50 |  Loss: (0.2403) |  Loss2: (0.0000) | Acc: (91.00%) (5972/6528)
Epoch: 90 | Batch_idx: 60 |  Loss: (0.2411) |  Loss2: (0.0000) | Acc: (91.00%) (7136/7808)
Epoch: 90 | Batch_idx: 70 |  Loss: (0.2396) |  Loss2: (0.0000) | Acc: (91.00%) (8325/9088)
Epoch: 90 | Batch_idx: 80 |  Loss: (0.2398) |  Loss2: (0.0000) | Acc: (91.00%) (9499/10368)
Epoch: 90 | Batch_idx: 90 |  Loss: (0.2384) |  Loss2: (0.0000) | Acc: (91.00%) (10683/11648)
Epoch: 90 | Batch_idx: 100 |  Loss: (0.2399) |  Loss2: (0.0000) | Acc: (91.00%) (11849/12928)
Epoch: 90 | Batch_idx: 110 |  Loss: (0.2411) |  Loss2: (0.0000) | Acc: (91.00%) (13008/14208)
Epoch: 90 | Batch_idx: 120 |  Loss: (0.2431) |  Loss2: (0.0000) | Acc: (91.00%) (14175/15488)
Epoch: 90 | Batch_idx: 130 |  Loss: (0.2438) |  Loss2: (0.0000) | Acc: (91.00%) (15342/16768)
Epoch: 90 | Batch_idx: 140 |  Loss: (0.2447) |  Loss2: (0.0000) | Acc: (91.00%) (16507/18048)
Epoch: 90 | Batch_idx: 150 |  Loss: (0.2467) |  Loss2: (0.0000) | Acc: (91.00%) (17666/19328)
Epoch: 90 | Batch_idx: 160 |  Loss: (0.2448) |  Loss2: (0.0000) | Acc: (91.00%) (18851/20608)
Epoch: 90 | Batch_idx: 170 |  Loss: (0.2435) |  Loss2: (0.0000) | Acc: (91.00%) (20033/21888)
Epoch: 90 | Batch_idx: 180 |  Loss: (0.2433) |  Loss2: (0.0000) | Acc: (91.00%) (21199/23168)
Epoch: 90 | Batch_idx: 190 |  Loss: (0.2435) |  Loss2: (0.0000) | Acc: (91.00%) (22367/24448)
Epoch: 90 | Batch_idx: 200 |  Loss: (0.2441) |  Loss2: (0.0000) | Acc: (91.00%) (23535/25728)
Epoch: 90 | Batch_idx: 210 |  Loss: (0.2441) |  Loss2: (0.0000) | Acc: (91.00%) (24717/27008)
Epoch: 90 | Batch_idx: 220 |  Loss: (0.2451) |  Loss2: (0.0000) | Acc: (91.00%) (25884/28288)
Epoch: 90 | Batch_idx: 230 |  Loss: (0.2450) |  Loss2: (0.0000) | Acc: (91.00%) (27059/29568)
Epoch: 90 | Batch_idx: 240 |  Loss: (0.2453) |  Loss2: (0.0000) | Acc: (91.00%) (28223/30848)
Epoch: 90 | Batch_idx: 250 |  Loss: (0.2444) |  Loss2: (0.0000) | Acc: (91.00%) (29403/32128)
Epoch: 90 | Batch_idx: 260 |  Loss: (0.2455) |  Loss2: (0.0000) | Acc: (91.00%) (30570/33408)
Epoch: 90 | Batch_idx: 270 |  Loss: (0.2458) |  Loss2: (0.0000) | Acc: (91.00%) (31734/34688)
Epoch: 90 | Batch_idx: 280 |  Loss: (0.2451) |  Loss2: (0.0000) | Acc: (91.00%) (32920/35968)
Epoch: 90 | Batch_idx: 290 |  Loss: (0.2465) |  Loss2: (0.0000) | Acc: (91.00%) (34077/37248)
Epoch: 90 | Batch_idx: 300 |  Loss: (0.2464) |  Loss2: (0.0000) | Acc: (91.00%) (35251/38528)
Epoch: 90 | Batch_idx: 310 |  Loss: (0.2460) |  Loss2: (0.0000) | Acc: (91.00%) (36417/39808)
Epoch: 90 | Batch_idx: 320 |  Loss: (0.2462) |  Loss2: (0.0000) | Acc: (91.00%) (37587/41088)
Epoch: 90 | Batch_idx: 330 |  Loss: (0.2465) |  Loss2: (0.0000) | Acc: (91.00%) (38748/42368)
Epoch: 90 | Batch_idx: 340 |  Loss: (0.2458) |  Loss2: (0.0000) | Acc: (91.00%) (39931/43648)
Epoch: 90 | Batch_idx: 350 |  Loss: (0.2460) |  Loss2: (0.0000) | Acc: (91.00%) (41101/44928)
Epoch: 90 | Batch_idx: 360 |  Loss: (0.2461) |  Loss2: (0.0000) | Acc: (91.00%) (42269/46208)
Epoch: 90 | Batch_idx: 370 |  Loss: (0.2463) |  Loss2: (0.0000) | Acc: (91.00%) (43445/47488)
Epoch: 90 | Batch_idx: 380 |  Loss: (0.2460) |  Loss2: (0.0000) | Acc: (91.00%) (44630/48768)
Epoch: 90 | Batch_idx: 390 |  Loss: (0.2465) |  Loss2: (0.0000) | Acc: (91.00%) (45742/50000)
=> saving checkpoint 'drive/app/torch/save_Routing_Gate_2/checkpoint_090.pth.tar'
# TEST : Loss: (0.4358) | Acc: (85.00%) (8563/10000)
percent tensor([0.5379, 0.5263, 0.5520, 0.5508, 0.5490, 0.5423, 0.5355, 0.5469, 0.5444,
        0.5341, 0.5350, 0.5416, 0.5339, 0.5318, 0.5342, 0.5370],
       device='cuda:0') torch.Size([16])
percent tensor([0.5382, 0.5450, 0.5343, 0.5388, 0.5368, 0.5503, 0.5420, 0.5359, 0.5344,
        0.5371, 0.5362, 0.5339, 0.5339, 0.5475, 0.5448, 0.5415],
       device='cuda:0') torch.Size([16])
percent tensor([0.5747, 0.6080, 0.5360, 0.4745, 0.5271, 0.4728, 0.5965, 0.5537, 0.5666,
        0.5905, 0.5902, 0.5803, 0.6482, 0.5053, 0.5711, 0.5353],
       device='cuda:0') torch.Size([16])
percent tensor([0.6809, 0.7075, 0.6826, 0.6955, 0.6832, 0.6760, 0.7126, 0.6733, 0.7029,
        0.7095, 0.7418, 0.7215, 0.7040, 0.7298, 0.6988, 0.6966],
       device='cuda:0') torch.Size([16])
percent tensor([0.6390, 0.6030, 0.6896, 0.6403, 0.6718, 0.7886, 0.6298, 0.6199, 0.6851,
        0.6210, 0.6227, 0.6011, 0.6650, 0.6582, 0.6092, 0.6959],
       device='cuda:0') torch.Size([16])
percent tensor([0.5074, 0.5977, 0.5390, 0.5019, 0.5165, 0.5569, 0.5146, 0.4124, 0.6055,
        0.5521, 0.6247, 0.5553, 0.6115, 0.6592, 0.4138, 0.5278],
       device='cuda:0') torch.Size([16])
percent tensor([0.5614, 0.6042, 0.7845, 0.7936, 0.8284, 0.6954, 0.6671, 0.7168, 0.6677,
        0.6099, 0.6573, 0.7760, 0.6142, 0.7092, 0.6541, 0.6359],
       device='cuda:0') torch.Size([16])
percent tensor([0.9995, 0.9982, 0.9990, 0.9987, 0.9987, 0.9990, 0.9988, 0.9991, 0.9982,
        0.9988, 0.9984, 0.9983, 0.9984, 0.9988, 0.9988, 0.9996],
       device='cuda:0') torch.Size([16])
Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 3, 3, 3]) tensor(178.5133, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(804.5923, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(809.7484, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([128, 64, 3, 3]) tensor(1517.8181, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([128, 64, 1, 1]) tensor(497.0016, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([128, 128, 3, 3]) tensor(2234.3086, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([256, 128, 3, 3]) tensor(4284.9458, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([256, 128, 1, 1]) tensor(1399.3097, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([256, 256, 3, 3]) tensor(6119.5708, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([512, 256, 3, 3]) tensor(11904.2461, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([512, 256, 1, 1]) tensor(3955.1943, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([512, 512, 3, 3]) tensor(16699.5547, device='cuda:0', grad_fn=<NormBackward0>)
Epoch: 91 | Batch_idx: 0 |  Loss: (0.2561) |  Loss2: (0.0000) | Acc: (91.00%) (117/128)
Epoch: 91 | Batch_idx: 10 |  Loss: (0.2167) |  Loss2: (0.0000) | Acc: (92.00%) (1306/1408)
Epoch: 91 | Batch_idx: 20 |  Loss: (0.2137) |  Loss2: (0.0000) | Acc: (92.00%) (2498/2688)
Epoch: 91 | Batch_idx: 30 |  Loss: (0.2086) |  Loss2: (0.0000) | Acc: (93.00%) (3700/3968)
Epoch: 91 | Batch_idx: 40 |  Loss: (0.2009) |  Loss2: (0.0000) | Acc: (93.00%) (4903/5248)
Epoch: 91 | Batch_idx: 50 |  Loss: (0.2069) |  Loss2: (0.0000) | Acc: (93.00%) (6076/6528)
Epoch: 91 | Batch_idx: 60 |  Loss: (0.2088) |  Loss2: (0.0000) | Acc: (92.00%) (7253/7808)
Epoch: 91 | Batch_idx: 70 |  Loss: (0.2110) |  Loss2: (0.0000) | Acc: (92.00%) (8436/9088)
Epoch: 91 | Batch_idx: 80 |  Loss: (0.2172) |  Loss2: (0.0000) | Acc: (92.00%) (9587/10368)
Epoch: 91 | Batch_idx: 90 |  Loss: (0.2212) |  Loss2: (0.0000) | Acc: (92.00%) (10756/11648)
Epoch: 91 | Batch_idx: 100 |  Loss: (0.2217) |  Loss2: (0.0000) | Acc: (92.00%) (11939/12928)
Epoch: 91 | Batch_idx: 110 |  Loss: (0.2223) |  Loss2: (0.0000) | Acc: (92.00%) (13125/14208)
Epoch: 91 | Batch_idx: 120 |  Loss: (0.2224) |  Loss2: (0.0000) | Acc: (92.00%) (14303/15488)
Epoch: 91 | Batch_idx: 130 |  Loss: (0.2263) |  Loss2: (0.0000) | Acc: (92.00%) (15461/16768)
Epoch: 91 | Batch_idx: 140 |  Loss: (0.2270) |  Loss2: (0.0000) | Acc: (92.00%) (16619/18048)
Epoch: 91 | Batch_idx: 150 |  Loss: (0.2265) |  Loss2: (0.0000) | Acc: (92.00%) (17789/19328)
Epoch: 91 | Batch_idx: 160 |  Loss: (0.2278) |  Loss2: (0.0000) | Acc: (91.00%) (18959/20608)
Epoch: 91 | Batch_idx: 170 |  Loss: (0.2292) |  Loss2: (0.0000) | Acc: (91.00%) (20136/21888)
Epoch: 91 | Batch_idx: 180 |  Loss: (0.2298) |  Loss2: (0.0000) | Acc: (92.00%) (21318/23168)
Epoch: 91 | Batch_idx: 190 |  Loss: (0.2309) |  Loss2: (0.0000) | Acc: (92.00%) (22493/24448)
Epoch: 91 | Batch_idx: 200 |  Loss: (0.2318) |  Loss2: (0.0000) | Acc: (91.00%) (23669/25728)
Epoch: 91 | Batch_idx: 210 |  Loss: (0.2331) |  Loss2: (0.0000) | Acc: (91.00%) (24826/27008)
Epoch: 91 | Batch_idx: 220 |  Loss: (0.2335) |  Loss2: (0.0000) | Acc: (91.00%) (25996/28288)
Epoch: 91 | Batch_idx: 230 |  Loss: (0.2335) |  Loss2: (0.0000) | Acc: (91.00%) (27175/29568)
Epoch: 91 | Batch_idx: 240 |  Loss: (0.2341) |  Loss2: (0.0000) | Acc: (91.00%) (28339/30848)
Epoch: 91 | Batch_idx: 250 |  Loss: (0.2356) |  Loss2: (0.0000) | Acc: (91.00%) (29502/32128)
Epoch: 91 | Batch_idx: 260 |  Loss: (0.2359) |  Loss2: (0.0000) | Acc: (91.00%) (30664/33408)
Epoch: 91 | Batch_idx: 270 |  Loss: (0.2357) |  Loss2: (0.0000) | Acc: (91.00%) (31851/34688)
Epoch: 91 | Batch_idx: 280 |  Loss: (0.2364) |  Loss2: (0.0000) | Acc: (91.00%) (33012/35968)
Epoch: 91 | Batch_idx: 290 |  Loss: (0.2368) |  Loss2: (0.0000) | Acc: (91.00%) (34187/37248)
Epoch: 91 | Batch_idx: 300 |  Loss: (0.2365) |  Loss2: (0.0000) | Acc: (91.00%) (35374/38528)
Epoch: 91 | Batch_idx: 310 |  Loss: (0.2363) |  Loss2: (0.0000) | Acc: (91.00%) (36551/39808)
Epoch: 91 | Batch_idx: 320 |  Loss: (0.2372) |  Loss2: (0.0000) | Acc: (91.00%) (37724/41088)
Epoch: 91 | Batch_idx: 330 |  Loss: (0.2374) |  Loss2: (0.0000) | Acc: (91.00%) (38884/42368)
Epoch: 91 | Batch_idx: 340 |  Loss: (0.2371) |  Loss2: (0.0000) | Acc: (91.00%) (40065/43648)
Epoch: 91 | Batch_idx: 350 |  Loss: (0.2383) |  Loss2: (0.0000) | Acc: (91.00%) (41206/44928)
Epoch: 91 | Batch_idx: 360 |  Loss: (0.2395) |  Loss2: (0.0000) | Acc: (91.00%) (42368/46208)
Epoch: 91 | Batch_idx: 370 |  Loss: (0.2395) |  Loss2: (0.0000) | Acc: (91.00%) (43552/47488)
Epoch: 91 | Batch_idx: 380 |  Loss: (0.2391) |  Loss2: (0.0000) | Acc: (91.00%) (44745/48768)
Epoch: 91 | Batch_idx: 390 |  Loss: (0.2390) |  Loss2: (0.0000) | Acc: (91.00%) (45878/50000)
# TEST : Loss: (0.4216) | Acc: (85.00%) (8590/10000)
percent tensor([0.5395, 0.5254, 0.5559, 0.5532, 0.5533, 0.5442, 0.5356, 0.5480, 0.5445,
        0.5351, 0.5349, 0.5455, 0.5344, 0.5283, 0.5350, 0.5376],
       device='cuda:0') torch.Size([16])
percent tensor([0.5376, 0.5457, 0.5347, 0.5383, 0.5374, 0.5498, 0.5425, 0.5361, 0.5344,
        0.5377, 0.5359, 0.5340, 0.5333, 0.5482, 0.5446, 0.5412],
       device='cuda:0') torch.Size([16])
percent tensor([0.5750, 0.6034, 0.5348, 0.4695, 0.5194, 0.4765, 0.5912, 0.5567, 0.5634,
        0.5874, 0.5859, 0.5760, 0.6503, 0.4913, 0.5724, 0.5316],
       device='cuda:0') torch.Size([16])
percent tensor([0.6783, 0.7017, 0.6809, 0.6943, 0.6856, 0.6740, 0.7056, 0.6763, 0.7062,
        0.7085, 0.7413, 0.7205, 0.7001, 0.7260, 0.6999, 0.6936],
       device='cuda:0') torch.Size([16])
percent tensor([0.6518, 0.6343, 0.7069, 0.6611, 0.6778, 0.7917, 0.6510, 0.6401, 0.6826,
        0.6357, 0.6453, 0.6304, 0.6831, 0.6873, 0.6210, 0.7062],
       device='cuda:0') torch.Size([16])
percent tensor([0.5195, 0.6046, 0.5414, 0.5064, 0.5239, 0.5530, 0.5173, 0.3978, 0.6034,
        0.5712, 0.6353, 0.5840, 0.6213, 0.6751, 0.4456, 0.5419],
       device='cuda:0') torch.Size([16])
percent tensor([0.5682, 0.6355, 0.7832, 0.7787, 0.8345, 0.6566, 0.6449, 0.6946, 0.6925,
        0.6372, 0.6825, 0.7755, 0.6291, 0.7427, 0.6563, 0.6115],
       device='cuda:0') torch.Size([16])
percent tensor([0.9994, 0.9977, 0.9991, 0.9988, 0.9992, 0.9985, 0.9987, 0.9992, 0.9981,
        0.9983, 0.9988, 0.9985, 0.9986, 0.9979, 0.9985, 0.9994],
       device='cuda:0') torch.Size([16])
Epoch: 92 | Batch_idx: 0 |  Loss: (0.1935) |  Loss2: (0.0000) | Acc: (92.00%) (118/128)
Epoch: 92 | Batch_idx: 10 |  Loss: (0.2287) |  Loss2: (0.0000) | Acc: (91.00%) (1285/1408)
Epoch: 92 | Batch_idx: 20 |  Loss: (0.2182) |  Loss2: (0.0000) | Acc: (91.00%) (2464/2688)
Epoch: 92 | Batch_idx: 30 |  Loss: (0.2348) |  Loss2: (0.0000) | Acc: (91.00%) (3626/3968)
Epoch: 92 | Batch_idx: 40 |  Loss: (0.2294) |  Loss2: (0.0000) | Acc: (91.00%) (4807/5248)
Epoch: 92 | Batch_idx: 50 |  Loss: (0.2283) |  Loss2: (0.0000) | Acc: (91.00%) (6003/6528)
Epoch: 92 | Batch_idx: 60 |  Loss: (0.2255) |  Loss2: (0.0000) | Acc: (92.00%) (7198/7808)
Epoch: 92 | Batch_idx: 70 |  Loss: (0.2239) |  Loss2: (0.0000) | Acc: (92.00%) (8383/9088)
Epoch: 92 | Batch_idx: 80 |  Loss: (0.2243) |  Loss2: (0.0000) | Acc: (92.00%) (9573/10368)
Epoch: 92 | Batch_idx: 90 |  Loss: (0.2243) |  Loss2: (0.0000) | Acc: (92.00%) (10760/11648)
Epoch: 92 | Batch_idx: 100 |  Loss: (0.2252) |  Loss2: (0.0000) | Acc: (92.00%) (11933/12928)
Epoch: 92 | Batch_idx: 110 |  Loss: (0.2266) |  Loss2: (0.0000) | Acc: (92.00%) (13102/14208)
Epoch: 92 | Batch_idx: 120 |  Loss: (0.2247) |  Loss2: (0.0000) | Acc: (92.00%) (14294/15488)
Epoch: 92 | Batch_idx: 130 |  Loss: (0.2232) |  Loss2: (0.0000) | Acc: (92.00%) (15489/16768)
Epoch: 92 | Batch_idx: 140 |  Loss: (0.2228) |  Loss2: (0.0000) | Acc: (92.00%) (16666/18048)
Epoch: 92 | Batch_idx: 150 |  Loss: (0.2231) |  Loss2: (0.0000) | Acc: (92.00%) (17843/19328)
Epoch: 92 | Batch_idx: 160 |  Loss: (0.2237) |  Loss2: (0.0000) | Acc: (92.00%) (19024/20608)
Epoch: 92 | Batch_idx: 170 |  Loss: (0.2251) |  Loss2: (0.0000) | Acc: (92.00%) (20196/21888)
Epoch: 92 | Batch_idx: 180 |  Loss: (0.2248) |  Loss2: (0.0000) | Acc: (92.00%) (21378/23168)
Epoch: 92 | Batch_idx: 190 |  Loss: (0.2263) |  Loss2: (0.0000) | Acc: (92.00%) (22546/24448)
Epoch: 92 | Batch_idx: 200 |  Loss: (0.2275) |  Loss2: (0.0000) | Acc: (92.00%) (23727/25728)
Epoch: 92 | Batch_idx: 210 |  Loss: (0.2293) |  Loss2: (0.0000) | Acc: (92.00%) (24887/27008)
Epoch: 92 | Batch_idx: 220 |  Loss: (0.2296) |  Loss2: (0.0000) | Acc: (92.00%) (26060/28288)
Epoch: 92 | Batch_idx: 230 |  Loss: (0.2289) |  Loss2: (0.0000) | Acc: (92.00%) (27243/29568)
Epoch: 92 | Batch_idx: 240 |  Loss: (0.2297) |  Loss2: (0.0000) | Acc: (92.00%) (28417/30848)
Epoch: 92 | Batch_idx: 250 |  Loss: (0.2290) |  Loss2: (0.0000) | Acc: (92.00%) (29618/32128)
Epoch: 92 | Batch_idx: 260 |  Loss: (0.2284) |  Loss2: (0.0000) | Acc: (92.00%) (30810/33408)
Epoch: 92 | Batch_idx: 270 |  Loss: (0.2286) |  Loss2: (0.0000) | Acc: (92.00%) (31978/34688)
Epoch: 92 | Batch_idx: 280 |  Loss: (0.2295) |  Loss2: (0.0000) | Acc: (92.00%) (33144/35968)
Epoch: 92 | Batch_idx: 290 |  Loss: (0.2305) |  Loss2: (0.0000) | Acc: (92.00%) (34314/37248)
Epoch: 92 | Batch_idx: 300 |  Loss: (0.2298) |  Loss2: (0.0000) | Acc: (92.00%) (35506/38528)
Epoch: 92 | Batch_idx: 310 |  Loss: (0.2302) |  Loss2: (0.0000) | Acc: (92.00%) (36678/39808)
Epoch: 92 | Batch_idx: 320 |  Loss: (0.2302) |  Loss2: (0.0000) | Acc: (92.00%) (37857/41088)
Epoch: 92 | Batch_idx: 330 |  Loss: (0.2294) |  Loss2: (0.0000) | Acc: (92.00%) (39049/42368)
Epoch: 92 | Batch_idx: 340 |  Loss: (0.2299) |  Loss2: (0.0000) | Acc: (92.00%) (40221/43648)
Epoch: 92 | Batch_idx: 350 |  Loss: (0.2305) |  Loss2: (0.0000) | Acc: (92.00%) (41383/44928)
Epoch: 92 | Batch_idx: 360 |  Loss: (0.2314) |  Loss2: (0.0000) | Acc: (92.00%) (42557/46208)
Epoch: 92 | Batch_idx: 370 |  Loss: (0.2318) |  Loss2: (0.0000) | Acc: (92.00%) (43724/47488)
Epoch: 92 | Batch_idx: 380 |  Loss: (0.2319) |  Loss2: (0.0000) | Acc: (92.00%) (44899/48768)
Epoch: 92 | Batch_idx: 390 |  Loss: (0.2320) |  Loss2: (0.0000) | Acc: (92.00%) (46018/50000)
# TEST : Loss: (0.3964) | Acc: (86.00%) (8672/10000)
percent tensor([0.5394, 0.5261, 0.5560, 0.5520, 0.5527, 0.5447, 0.5366, 0.5484, 0.5443,
        0.5350, 0.5355, 0.5444, 0.5342, 0.5302, 0.5349, 0.5379],
       device='cuda:0') torch.Size([16])
percent tensor([0.5372, 0.5448, 0.5338, 0.5374, 0.5351, 0.5483, 0.5412, 0.5350, 0.5323,
        0.5367, 0.5352, 0.5324, 0.5332, 0.5473, 0.5435, 0.5406],
       device='cuda:0') torch.Size([16])
percent tensor([0.5869, 0.6113, 0.5421, 0.4732, 0.5297, 0.4833, 0.5985, 0.5624, 0.5808,
        0.5984, 0.5998, 0.5919, 0.6600, 0.4970, 0.5808, 0.5387],
       device='cuda:0') torch.Size([16])
percent tensor([0.6789, 0.6997, 0.6804, 0.6947, 0.6838, 0.6768, 0.7058, 0.6747, 0.6981,
        0.7049, 0.7341, 0.7150, 0.6962, 0.7151, 0.6983, 0.6950],
       device='cuda:0') torch.Size([16])
percent tensor([0.6467, 0.6173, 0.6780, 0.6522, 0.6617, 0.7940, 0.6420, 0.6136, 0.6912,
        0.6224, 0.6581, 0.6045, 0.6902, 0.6897, 0.6163, 0.7008],
       device='cuda:0') torch.Size([16])
percent tensor([0.5167, 0.6052, 0.5202, 0.5121, 0.5148, 0.5537, 0.4994, 0.4047, 0.6126,
        0.5528, 0.6324, 0.5535, 0.6119, 0.6588, 0.4319, 0.5269],
       device='cuda:0') torch.Size([16])
percent tensor([0.5590, 0.5945, 0.7695, 0.7654, 0.8327, 0.6594, 0.6156, 0.6867, 0.6340,
        0.5999, 0.6386, 0.7476, 0.5922, 0.6740, 0.6382, 0.6148],
       device='cuda:0') torch.Size([16])
percent tensor([0.9995, 0.9981, 0.9987, 0.9989, 0.9990, 0.9987, 0.9985, 0.9989, 0.9979,
        0.9987, 0.9988, 0.9984, 0.9983, 0.9986, 0.9987, 0.9993],
       device='cuda:0') torch.Size([16])
Epoch: 93 | Batch_idx: 0 |  Loss: (0.2824) |  Loss2: (0.0000) | Acc: (89.00%) (114/128)
Epoch: 93 | Batch_idx: 10 |  Loss: (0.2163) |  Loss2: (0.0000) | Acc: (93.00%) (1313/1408)
Epoch: 93 | Batch_idx: 20 |  Loss: (0.2169) |  Loss2: (0.0000) | Acc: (92.00%) (2492/2688)
Epoch: 93 | Batch_idx: 30 |  Loss: (0.2087) |  Loss2: (0.0000) | Acc: (92.00%) (3689/3968)
Epoch: 93 | Batch_idx: 40 |  Loss: (0.2064) |  Loss2: (0.0000) | Acc: (92.00%) (4878/5248)
Epoch: 93 | Batch_idx: 50 |  Loss: (0.2149) |  Loss2: (0.0000) | Acc: (92.00%) (6046/6528)
Epoch: 93 | Batch_idx: 60 |  Loss: (0.2140) |  Loss2: (0.0000) | Acc: (92.00%) (7245/7808)
Epoch: 93 | Batch_idx: 70 |  Loss: (0.2136) |  Loss2: (0.0000) | Acc: (92.00%) (8429/9088)
Epoch: 93 | Batch_idx: 80 |  Loss: (0.2149) |  Loss2: (0.0000) | Acc: (92.00%) (9599/10368)
Epoch: 93 | Batch_idx: 90 |  Loss: (0.2118) |  Loss2: (0.0000) | Acc: (92.00%) (10791/11648)
Epoch: 93 | Batch_idx: 100 |  Loss: (0.2140) |  Loss2: (0.0000) | Acc: (92.00%) (11974/12928)
Epoch: 93 | Batch_idx: 110 |  Loss: (0.2164) |  Loss2: (0.0000) | Acc: (92.00%) (13142/14208)
Epoch: 93 | Batch_idx: 120 |  Loss: (0.2174) |  Loss2: (0.0000) | Acc: (92.00%) (14315/15488)
Epoch: 93 | Batch_idx: 130 |  Loss: (0.2184) |  Loss2: (0.0000) | Acc: (92.00%) (15495/16768)
Epoch: 93 | Batch_idx: 140 |  Loss: (0.2202) |  Loss2: (0.0000) | Acc: (92.00%) (16673/18048)
Epoch: 93 | Batch_idx: 150 |  Loss: (0.2196) |  Loss2: (0.0000) | Acc: (92.00%) (17858/19328)
Epoch: 93 | Batch_idx: 160 |  Loss: (0.2206) |  Loss2: (0.0000) | Acc: (92.00%) (19042/20608)
Epoch: 93 | Batch_idx: 170 |  Loss: (0.2206) |  Loss2: (0.0000) | Acc: (92.00%) (20218/21888)
Epoch: 93 | Batch_idx: 180 |  Loss: (0.2205) |  Loss2: (0.0000) | Acc: (92.00%) (21394/23168)
Epoch: 93 | Batch_idx: 190 |  Loss: (0.2215) |  Loss2: (0.0000) | Acc: (92.00%) (22568/24448)
Epoch: 93 | Batch_idx: 200 |  Loss: (0.2219) |  Loss2: (0.0000) | Acc: (92.00%) (23746/25728)
Epoch: 93 | Batch_idx: 210 |  Loss: (0.2224) |  Loss2: (0.0000) | Acc: (92.00%) (24930/27008)
Epoch: 93 | Batch_idx: 220 |  Loss: (0.2226) |  Loss2: (0.0000) | Acc: (92.00%) (26111/28288)
Epoch: 93 | Batch_idx: 230 |  Loss: (0.2224) |  Loss2: (0.0000) | Acc: (92.00%) (27298/29568)
Epoch: 93 | Batch_idx: 240 |  Loss: (0.2226) |  Loss2: (0.0000) | Acc: (92.00%) (28475/30848)
Epoch: 93 | Batch_idx: 250 |  Loss: (0.2220) |  Loss2: (0.0000) | Acc: (92.00%) (29660/32128)
Epoch: 93 | Batch_idx: 260 |  Loss: (0.2215) |  Loss2: (0.0000) | Acc: (92.00%) (30850/33408)
Epoch: 93 | Batch_idx: 270 |  Loss: (0.2222) |  Loss2: (0.0000) | Acc: (92.00%) (32020/34688)
Epoch: 93 | Batch_idx: 280 |  Loss: (0.2225) |  Loss2: (0.0000) | Acc: (92.00%) (33198/35968)
Epoch: 93 | Batch_idx: 290 |  Loss: (0.2229) |  Loss2: (0.0000) | Acc: (92.00%) (34377/37248)
Epoch: 93 | Batch_idx: 300 |  Loss: (0.2233) |  Loss2: (0.0000) | Acc: (92.00%) (35557/38528)
Epoch: 93 | Batch_idx: 310 |  Loss: (0.2243) |  Loss2: (0.0000) | Acc: (92.00%) (36734/39808)
Epoch: 93 | Batch_idx: 320 |  Loss: (0.2242) |  Loss2: (0.0000) | Acc: (92.00%) (37915/41088)
Epoch: 93 | Batch_idx: 330 |  Loss: (0.2255) |  Loss2: (0.0000) | Acc: (92.00%) (39083/42368)
Epoch: 93 | Batch_idx: 340 |  Loss: (0.2249) |  Loss2: (0.0000) | Acc: (92.00%) (40272/43648)
Epoch: 93 | Batch_idx: 350 |  Loss: (0.2256) |  Loss2: (0.0000) | Acc: (92.00%) (41444/44928)
Epoch: 93 | Batch_idx: 360 |  Loss: (0.2253) |  Loss2: (0.0000) | Acc: (92.00%) (42626/46208)
Epoch: 93 | Batch_idx: 370 |  Loss: (0.2254) |  Loss2: (0.0000) | Acc: (92.00%) (43799/47488)
Epoch: 93 | Batch_idx: 380 |  Loss: (0.2249) |  Loss2: (0.0000) | Acc: (92.00%) (44979/48768)
Epoch: 93 | Batch_idx: 390 |  Loss: (0.2258) |  Loss2: (0.0000) | Acc: (92.00%) (46108/50000)
# TEST : Loss: (0.3998) | Acc: (86.00%) (8699/10000)
percent tensor([0.5406, 0.5252, 0.5596, 0.5543, 0.5560, 0.5450, 0.5369, 0.5496, 0.5451,
        0.5357, 0.5351, 0.5478, 0.5348, 0.5281, 0.5353, 0.5386],
       device='cuda:0') torch.Size([16])
percent tensor([0.5381, 0.5454, 0.5342, 0.5385, 0.5371, 0.5489, 0.5419, 0.5355, 0.5342,
        0.5370, 0.5358, 0.5329, 0.5339, 0.5486, 0.5442, 0.5416],
       device='cuda:0') torch.Size([16])
percent tensor([0.5737, 0.5996, 0.5268, 0.4638, 0.5208, 0.4831, 0.5874, 0.5467, 0.5613,
        0.5872, 0.5857, 0.5779, 0.6457, 0.4815, 0.5720, 0.5249],
       device='cuda:0') torch.Size([16])
percent tensor([0.6810, 0.7013, 0.6827, 0.6918, 0.6863, 0.6743, 0.7044, 0.6754, 0.7076,
        0.7085, 0.7393, 0.7199, 0.7008, 0.7183, 0.6976, 0.6936],
       device='cuda:0') torch.Size([16])
percent tensor([0.6360, 0.6134, 0.6846, 0.6382, 0.6636, 0.7875, 0.6467, 0.6187, 0.6928,
        0.6285, 0.6438, 0.6078, 0.6829, 0.6864, 0.6049, 0.6980],
       device='cuda:0') torch.Size([16])
percent tensor([0.5286, 0.6147, 0.5599, 0.5339, 0.5334, 0.5586, 0.5327, 0.3993, 0.6312,
        0.5744, 0.6322, 0.6031, 0.6401, 0.6584, 0.4402, 0.5376],
       device='cuda:0') torch.Size([16])
percent tensor([0.5520, 0.6608, 0.7706, 0.7631, 0.8306, 0.6602, 0.6564, 0.6817, 0.6665,
        0.6271, 0.6668, 0.7618, 0.6125, 0.7121, 0.6597, 0.6457],
       device='cuda:0') torch.Size([16])
percent tensor([0.9994, 0.9980, 0.9990, 0.9986, 0.9990, 0.9985, 0.9985, 0.9992, 0.9983,
        0.9984, 0.9990, 0.9990, 0.9986, 0.9986, 0.9986, 0.9994],
       device='cuda:0') torch.Size([16])
Epoch: 94 | Batch_idx: 0 |  Loss: (0.2171) |  Loss2: (0.0000) | Acc: (93.00%) (120/128)
Epoch: 94 | Batch_idx: 10 |  Loss: (0.2123) |  Loss2: (0.0000) | Acc: (92.00%) (1302/1408)
Epoch: 94 | Batch_idx: 20 |  Loss: (0.2049) |  Loss2: (0.0000) | Acc: (92.00%) (2483/2688)
Epoch: 94 | Batch_idx: 30 |  Loss: (0.2202) |  Loss2: (0.0000) | Acc: (91.00%) (3644/3968)
Epoch: 94 | Batch_idx: 40 |  Loss: (0.2223) |  Loss2: (0.0000) | Acc: (91.00%) (4820/5248)
Epoch: 94 | Batch_idx: 50 |  Loss: (0.2205) |  Loss2: (0.0000) | Acc: (92.00%) (6012/6528)
Epoch: 94 | Batch_idx: 60 |  Loss: (0.2201) |  Loss2: (0.0000) | Acc: (92.00%) (7194/7808)
Epoch: 94 | Batch_idx: 70 |  Loss: (0.2215) |  Loss2: (0.0000) | Acc: (92.00%) (8371/9088)
Epoch: 94 | Batch_idx: 80 |  Loss: (0.2210) |  Loss2: (0.0000) | Acc: (92.00%) (9561/10368)
Epoch: 94 | Batch_idx: 90 |  Loss: (0.2203) |  Loss2: (0.0000) | Acc: (92.00%) (10747/11648)
Epoch: 94 | Batch_idx: 100 |  Loss: (0.2189) |  Loss2: (0.0000) | Acc: (92.00%) (11937/12928)
Epoch: 94 | Batch_idx: 110 |  Loss: (0.2174) |  Loss2: (0.0000) | Acc: (92.00%) (13138/14208)
Epoch: 94 | Batch_idx: 120 |  Loss: (0.2167) |  Loss2: (0.0000) | Acc: (92.00%) (14334/15488)
Epoch: 94 | Batch_idx: 130 |  Loss: (0.2174) |  Loss2: (0.0000) | Acc: (92.00%) (15516/16768)
Epoch: 94 | Batch_idx: 140 |  Loss: (0.2176) |  Loss2: (0.0000) | Acc: (92.00%) (16697/18048)
Epoch: 94 | Batch_idx: 150 |  Loss: (0.2179) |  Loss2: (0.0000) | Acc: (92.00%) (17864/19328)
Epoch: 94 | Batch_idx: 160 |  Loss: (0.2192) |  Loss2: (0.0000) | Acc: (92.00%) (19041/20608)
Epoch: 94 | Batch_idx: 170 |  Loss: (0.2191) |  Loss2: (0.0000) | Acc: (92.00%) (20216/21888)
Epoch: 94 | Batch_idx: 180 |  Loss: (0.2198) |  Loss2: (0.0000) | Acc: (92.00%) (21389/23168)
Epoch: 94 | Batch_idx: 190 |  Loss: (0.2183) |  Loss2: (0.0000) | Acc: (92.00%) (22586/24448)
Epoch: 94 | Batch_idx: 200 |  Loss: (0.2190) |  Loss2: (0.0000) | Acc: (92.00%) (23772/25728)
Epoch: 94 | Batch_idx: 210 |  Loss: (0.2208) |  Loss2: (0.0000) | Acc: (92.00%) (24944/27008)
Epoch: 94 | Batch_idx: 220 |  Loss: (0.2214) |  Loss2: (0.0000) | Acc: (92.00%) (26123/28288)
Epoch: 94 | Batch_idx: 230 |  Loss: (0.2235) |  Loss2: (0.0000) | Acc: (92.00%) (27282/29568)
Epoch: 94 | Batch_idx: 240 |  Loss: (0.2233) |  Loss2: (0.0000) | Acc: (92.00%) (28473/30848)
Epoch: 94 | Batch_idx: 250 |  Loss: (0.2234) |  Loss2: (0.0000) | Acc: (92.00%) (29655/32128)
Epoch: 94 | Batch_idx: 260 |  Loss: (0.2233) |  Loss2: (0.0000) | Acc: (92.00%) (30840/33408)
Epoch: 94 | Batch_idx: 270 |  Loss: (0.2228) |  Loss2: (0.0000) | Acc: (92.00%) (32028/34688)
Epoch: 94 | Batch_idx: 280 |  Loss: (0.2233) |  Loss2: (0.0000) | Acc: (92.00%) (33186/35968)
Epoch: 94 | Batch_idx: 290 |  Loss: (0.2233) |  Loss2: (0.0000) | Acc: (92.00%) (34365/37248)
Epoch: 94 | Batch_idx: 300 |  Loss: (0.2228) |  Loss2: (0.0000) | Acc: (92.00%) (35550/38528)
Epoch: 94 | Batch_idx: 310 |  Loss: (0.2226) |  Loss2: (0.0000) | Acc: (92.00%) (36734/39808)
Epoch: 94 | Batch_idx: 320 |  Loss: (0.2223) |  Loss2: (0.0000) | Acc: (92.00%) (37929/41088)
Epoch: 94 | Batch_idx: 330 |  Loss: (0.2231) |  Loss2: (0.0000) | Acc: (92.00%) (39100/42368)
Epoch: 94 | Batch_idx: 340 |  Loss: (0.2230) |  Loss2: (0.0000) | Acc: (92.00%) (40280/43648)
Epoch: 94 | Batch_idx: 350 |  Loss: (0.2231) |  Loss2: (0.0000) | Acc: (92.00%) (41474/44928)
Epoch: 94 | Batch_idx: 360 |  Loss: (0.2233) |  Loss2: (0.0000) | Acc: (92.00%) (42650/46208)
Epoch: 94 | Batch_idx: 370 |  Loss: (0.2234) |  Loss2: (0.0000) | Acc: (92.00%) (43830/47488)
Epoch: 94 | Batch_idx: 380 |  Loss: (0.2231) |  Loss2: (0.0000) | Acc: (92.00%) (45019/48768)
Epoch: 94 | Batch_idx: 390 |  Loss: (0.2234) |  Loss2: (0.0000) | Acc: (92.00%) (46158/50000)
# TEST : Loss: (0.3985) | Acc: (87.00%) (8706/10000)
percent tensor([0.5395, 0.5264, 0.5557, 0.5535, 0.5528, 0.5450, 0.5360, 0.5487, 0.5453,
        0.5351, 0.5357, 0.5443, 0.5347, 0.5305, 0.5352, 0.5385],
       device='cuda:0') torch.Size([16])
percent tensor([0.5381, 0.5452, 0.5326, 0.5374, 0.5360, 0.5504, 0.5417, 0.5338, 0.5332,
        0.5366, 0.5362, 0.5320, 0.5338, 0.5474, 0.5442, 0.5412],
       device='cuda:0') torch.Size([16])
percent tensor([0.5788, 0.6025, 0.5571, 0.4806, 0.5411, 0.4729, 0.6005, 0.5661, 0.5686,
        0.5939, 0.5865, 0.5996, 0.6510, 0.4895, 0.5703, 0.5291],
       device='cuda:0') torch.Size([16])
percent tensor([0.6819, 0.7040, 0.6794, 0.6944, 0.6834, 0.6714, 0.7098, 0.6716, 0.7115,
        0.7119, 0.7413, 0.7238, 0.7080, 0.7271, 0.6969, 0.6953],
       device='cuda:0') torch.Size([16])
percent tensor([0.6411, 0.6181, 0.6911, 0.6503, 0.6591, 0.7851, 0.6423, 0.6165, 0.6771,
        0.6188, 0.6520, 0.6053, 0.6832, 0.6884, 0.6132, 0.6996],
       device='cuda:0') torch.Size([16])
percent tensor([0.5186, 0.6054, 0.5441, 0.5242, 0.5321, 0.5532, 0.5105, 0.4228, 0.6112,
        0.5672, 0.6297, 0.5532, 0.6193, 0.6624, 0.4283, 0.5337],
       device='cuda:0') torch.Size([16])
percent tensor([0.5725, 0.6248, 0.7530, 0.7649, 0.8267, 0.6854, 0.6524, 0.6992, 0.6876,
        0.6106, 0.6483, 0.7459, 0.6204, 0.6900, 0.6602, 0.6377],
       device='cuda:0') torch.Size([16])
percent tensor([0.9993, 0.9981, 0.9986, 0.9984, 0.9988, 0.9983, 0.9987, 0.9988, 0.9982,
        0.9983, 0.9990, 0.9983, 0.9987, 0.9979, 0.9988, 0.9993],
       device='cuda:0') torch.Size([16])
False Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=128, out_features=16, bias=False)
True Linear(in_features=16, out_features=2, bias=False)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=128, out_features=16, bias=False)
True Linear(in_features=16, out_features=2, bias=False)
False Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=256, out_features=32, bias=False)
True Linear(in_features=32, out_features=2, bias=False)
False Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=256, out_features=32, bias=False)
True Linear(in_features=32, out_features=2, bias=False)
False Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=512, out_features=64, bias=False)
True Linear(in_features=64, out_features=2, bias=False)
False Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=512, out_features=64, bias=False)
True Linear(in_features=64, out_features=2, bias=False)
False Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1024, out_features=128, bias=False)
True Linear(in_features=128, out_features=2, bias=False)
False Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1024, out_features=128, bias=False)
True Linear(in_features=128, out_features=2, bias=False)
False Linear(in_features=512, out_features=10, bias=True)
Epoch: 95 | Batch_idx: 0 |  Loss: (0.1323) |  Loss2: (0.0000) | Acc: (96.00%) (124/128)
Epoch: 95 | Batch_idx: 10 |  Loss: (0.2149) |  Loss2: (0.0000) | Acc: (92.00%) (1299/1408)
Epoch: 95 | Batch_idx: 20 |  Loss: (0.2301) |  Loss2: (0.0000) | Acc: (91.00%) (2470/2688)
Epoch: 95 | Batch_idx: 30 |  Loss: (0.2521) |  Loss2: (0.0000) | Acc: (91.00%) (3611/3968)
Epoch: 95 | Batch_idx: 40 |  Loss: (0.2593) |  Loss2: (0.0000) | Acc: (90.00%) (4764/5248)
Epoch: 95 | Batch_idx: 50 |  Loss: (0.2690) |  Loss2: (0.0000) | Acc: (90.00%) (5900/6528)
Epoch: 95 | Batch_idx: 60 |  Loss: (0.2691) |  Loss2: (0.0000) | Acc: (90.00%) (7068/7808)
Epoch: 95 | Batch_idx: 70 |  Loss: (0.2705) |  Loss2: (0.0000) | Acc: (90.00%) (8218/9088)
Epoch: 95 | Batch_idx: 80 |  Loss: (0.2732) |  Loss2: (0.0000) | Acc: (90.00%) (9369/10368)
Epoch: 95 | Batch_idx: 90 |  Loss: (0.2707) |  Loss2: (0.0000) | Acc: (90.00%) (10525/11648)
Epoch: 95 | Batch_idx: 100 |  Loss: (0.2712) |  Loss2: (0.0000) | Acc: (90.00%) (11689/12928)
Epoch: 95 | Batch_idx: 110 |  Loss: (0.2724) |  Loss2: (0.0000) | Acc: (90.00%) (12826/14208)
Epoch: 95 | Batch_idx: 120 |  Loss: (0.2707) |  Loss2: (0.0000) | Acc: (90.00%) (13990/15488)
Epoch: 95 | Batch_idx: 130 |  Loss: (0.2738) |  Loss2: (0.0000) | Acc: (90.00%) (15118/16768)
Epoch: 95 | Batch_idx: 140 |  Loss: (0.2728) |  Loss2: (0.0000) | Acc: (90.00%) (16279/18048)
Epoch: 95 | Batch_idx: 150 |  Loss: (0.2732) |  Loss2: (0.0000) | Acc: (90.00%) (17437/19328)
Epoch: 95 | Batch_idx: 160 |  Loss: (0.2723) |  Loss2: (0.0000) | Acc: (90.00%) (18593/20608)
Epoch: 95 | Batch_idx: 170 |  Loss: (0.2716) |  Loss2: (0.0000) | Acc: (90.00%) (19756/21888)
Epoch: 95 | Batch_idx: 180 |  Loss: (0.2710) |  Loss2: (0.0000) | Acc: (90.00%) (20917/23168)
Epoch: 95 | Batch_idx: 190 |  Loss: (0.2695) |  Loss2: (0.0000) | Acc: (90.00%) (22086/24448)
Epoch: 95 | Batch_idx: 200 |  Loss: (0.2684) |  Loss2: (0.0000) | Acc: (90.00%) (23259/25728)
Epoch: 95 | Batch_idx: 210 |  Loss: (0.2677) |  Loss2: (0.0000) | Acc: (90.00%) (24419/27008)
Epoch: 95 | Batch_idx: 220 |  Loss: (0.2684) |  Loss2: (0.0000) | Acc: (90.00%) (25567/28288)
Epoch: 95 | Batch_idx: 230 |  Loss: (0.2679) |  Loss2: (0.0000) | Acc: (90.00%) (26739/29568)
Epoch: 95 | Batch_idx: 240 |  Loss: (0.2663) |  Loss2: (0.0000) | Acc: (90.00%) (27913/30848)
Epoch: 95 | Batch_idx: 250 |  Loss: (0.2663) |  Loss2: (0.0000) | Acc: (90.00%) (29079/32128)
Epoch: 95 | Batch_idx: 260 |  Loss: (0.2659) |  Loss2: (0.0000) | Acc: (90.00%) (30246/33408)
Epoch: 95 | Batch_idx: 270 |  Loss: (0.2641) |  Loss2: (0.0000) | Acc: (90.00%) (31422/34688)
Epoch: 95 | Batch_idx: 280 |  Loss: (0.2629) |  Loss2: (0.0000) | Acc: (90.00%) (32599/35968)
Epoch: 95 | Batch_idx: 290 |  Loss: (0.2616) |  Loss2: (0.0000) | Acc: (90.00%) (33786/37248)
Epoch: 95 | Batch_idx: 300 |  Loss: (0.2611) |  Loss2: (0.0000) | Acc: (90.00%) (34952/38528)
Epoch: 95 | Batch_idx: 310 |  Loss: (0.2607) |  Loss2: (0.0000) | Acc: (90.00%) (36128/39808)
Epoch: 95 | Batch_idx: 320 |  Loss: (0.2606) |  Loss2: (0.0000) | Acc: (90.00%) (37297/41088)
Epoch: 95 | Batch_idx: 330 |  Loss: (0.2600) |  Loss2: (0.0000) | Acc: (90.00%) (38472/42368)
Epoch: 95 | Batch_idx: 340 |  Loss: (0.2593) |  Loss2: (0.0000) | Acc: (90.00%) (39645/43648)
Epoch: 95 | Batch_idx: 350 |  Loss: (0.2592) |  Loss2: (0.0000) | Acc: (90.00%) (40801/44928)
Epoch: 95 | Batch_idx: 360 |  Loss: (0.2592) |  Loss2: (0.0000) | Acc: (90.00%) (41965/46208)
Epoch: 95 | Batch_idx: 370 |  Loss: (0.2586) |  Loss2: (0.0000) | Acc: (90.00%) (43139/47488)
Epoch: 95 | Batch_idx: 380 |  Loss: (0.2582) |  Loss2: (0.0000) | Acc: (90.00%) (44322/48768)
Epoch: 95 | Batch_idx: 390 |  Loss: (0.2584) |  Loss2: (0.0000) | Acc: (90.00%) (45438/50000)
=> saving checkpoint 'drive/app/torch/save_Routing_Gate_2/checkpoint_095.pth.tar'
# TEST : Loss: (0.3950) | Acc: (87.00%) (8701/10000)
percent tensor([0.5358, 0.5233, 0.5514, 0.5497, 0.5481, 0.5403, 0.5319, 0.5459, 0.5412,
        0.5319, 0.5324, 0.5404, 0.5311, 0.5268, 0.5315, 0.5349],
       device='cuda:0') torch.Size([16])
percent tensor([0.5172, 0.5217, 0.5129, 0.5181, 0.5143, 0.5300, 0.5177, 0.5130, 0.5122,
        0.5146, 0.5145, 0.5105, 0.5125, 0.5244, 0.5217, 0.5206],
       device='cuda:0') torch.Size([16])
percent tensor([0.5799, 0.6110, 0.5487, 0.4695, 0.5240, 0.4700, 0.5956, 0.5503, 0.5604,
        0.5974, 0.5947, 0.5933, 0.6565, 0.4922, 0.5733, 0.5339],
       device='cuda:0') torch.Size([16])
percent tensor([0.6784, 0.7001, 0.6780, 0.6983, 0.6840, 0.6725, 0.7062, 0.6705, 0.7108,
        0.7085, 0.7415, 0.7172, 0.7036, 0.7217, 0.6942, 0.6951],
       device='cuda:0') torch.Size([16])
percent tensor([0.6430, 0.6049, 0.6882, 0.6430, 0.6401, 0.7871, 0.6371, 0.6140, 0.6465,
        0.6068, 0.6114, 0.6026, 0.6633, 0.6686, 0.6208, 0.6820],
       device='cuda:0') torch.Size([16])
percent tensor([0.5202, 0.6238, 0.5111, 0.5193, 0.5031, 0.5434, 0.5085, 0.4188, 0.6181,
        0.5738, 0.6398, 0.5663, 0.6423, 0.6725, 0.4289, 0.5339],
       device='cuda:0') torch.Size([16])
percent tensor([0.5590, 0.5939, 0.7242, 0.7486, 0.8157, 0.6765, 0.6376, 0.6787, 0.6617,
        0.5902, 0.6185, 0.7152, 0.5861, 0.6717, 0.6315, 0.6509],
       device='cuda:0') torch.Size([16])
percent tensor([0.9992, 0.9980, 0.9989, 0.9988, 0.9992, 0.9984, 0.9991, 0.9989, 0.9981,
        0.9984, 0.9988, 0.9987, 0.9987, 0.9981, 0.9987, 0.9994],
       device='cuda:0') torch.Size([16])
Epoch: 96 | Batch_idx: 0 |  Loss: (0.1857) |  Loss2: (0.0000) | Acc: (94.00%) (121/128)
Epoch: 96 | Batch_idx: 10 |  Loss: (0.2292) |  Loss2: (0.0000) | Acc: (91.00%) (1292/1408)
Epoch: 96 | Batch_idx: 20 |  Loss: (0.2406) |  Loss2: (0.0000) | Acc: (91.00%) (2464/2688)
Epoch: 96 | Batch_idx: 30 |  Loss: (0.2381) |  Loss2: (0.0000) | Acc: (91.00%) (3639/3968)
Epoch: 96 | Batch_idx: 40 |  Loss: (0.2406) |  Loss2: (0.0000) | Acc: (91.00%) (4810/5248)
Epoch: 96 | Batch_idx: 50 |  Loss: (0.2361) |  Loss2: (0.0000) | Acc: (91.00%) (5996/6528)
Epoch: 96 | Batch_idx: 60 |  Loss: (0.2357) |  Loss2: (0.0000) | Acc: (91.00%) (7175/7808)
Epoch: 96 | Batch_idx: 70 |  Loss: (0.2341) |  Loss2: (0.0000) | Acc: (91.00%) (8348/9088)
Epoch: 96 | Batch_idx: 80 |  Loss: (0.2340) |  Loss2: (0.0000) | Acc: (91.00%) (9527/10368)
Epoch: 96 | Batch_idx: 90 |  Loss: (0.2335) |  Loss2: (0.0000) | Acc: (91.00%) (10702/11648)
Epoch: 96 | Batch_idx: 100 |  Loss: (0.2341) |  Loss2: (0.0000) | Acc: (91.00%) (11871/12928)
Epoch: 96 | Batch_idx: 110 |  Loss: (0.2344) |  Loss2: (0.0000) | Acc: (91.00%) (13045/14208)
Epoch: 96 | Batch_idx: 120 |  Loss: (0.2323) |  Loss2: (0.0000) | Acc: (91.00%) (14233/15488)
Epoch: 96 | Batch_idx: 130 |  Loss: (0.2349) |  Loss2: (0.0000) | Acc: (91.00%) (15391/16768)
Epoch: 96 | Batch_idx: 140 |  Loss: (0.2350) |  Loss2: (0.0000) | Acc: (91.00%) (16554/18048)
Epoch: 96 | Batch_idx: 150 |  Loss: (0.2339) |  Loss2: (0.0000) | Acc: (91.00%) (17742/19328)
Epoch: 96 | Batch_idx: 160 |  Loss: (0.2332) |  Loss2: (0.0000) | Acc: (91.00%) (18934/20608)
Epoch: 96 | Batch_idx: 170 |  Loss: (0.2341) |  Loss2: (0.0000) | Acc: (91.00%) (20099/21888)
Epoch: 96 | Batch_idx: 180 |  Loss: (0.2325) |  Loss2: (0.0000) | Acc: (91.00%) (21292/23168)
Epoch: 96 | Batch_idx: 190 |  Loss: (0.2322) |  Loss2: (0.0000) | Acc: (91.00%) (22463/24448)
Epoch: 96 | Batch_idx: 200 |  Loss: (0.2316) |  Loss2: (0.0000) | Acc: (91.00%) (23642/25728)
Epoch: 96 | Batch_idx: 210 |  Loss: (0.2311) |  Loss2: (0.0000) | Acc: (91.00%) (24830/27008)
Epoch: 96 | Batch_idx: 220 |  Loss: (0.2302) |  Loss2: (0.0000) | Acc: (91.00%) (26014/28288)
Epoch: 96 | Batch_idx: 230 |  Loss: (0.2301) |  Loss2: (0.0000) | Acc: (91.00%) (27196/29568)
Epoch: 96 | Batch_idx: 240 |  Loss: (0.2290) |  Loss2: (0.0000) | Acc: (92.00%) (28393/30848)
Epoch: 96 | Batch_idx: 250 |  Loss: (0.2297) |  Loss2: (0.0000) | Acc: (92.00%) (29567/32128)
Epoch: 96 | Batch_idx: 260 |  Loss: (0.2294) |  Loss2: (0.0000) | Acc: (92.00%) (30755/33408)
Epoch: 96 | Batch_idx: 270 |  Loss: (0.2296) |  Loss2: (0.0000) | Acc: (92.00%) (31931/34688)
Epoch: 96 | Batch_idx: 280 |  Loss: (0.2296) |  Loss2: (0.0000) | Acc: (92.00%) (33103/35968)
Epoch: 96 | Batch_idx: 290 |  Loss: (0.2301) |  Loss2: (0.0000) | Acc: (91.00%) (34264/37248)
Epoch: 96 | Batch_idx: 300 |  Loss: (0.2311) |  Loss2: (0.0000) | Acc: (91.00%) (35426/38528)
Epoch: 96 | Batch_idx: 310 |  Loss: (0.2318) |  Loss2: (0.0000) | Acc: (91.00%) (36600/39808)
Epoch: 96 | Batch_idx: 320 |  Loss: (0.2315) |  Loss2: (0.0000) | Acc: (91.00%) (37785/41088)
Epoch: 96 | Batch_idx: 330 |  Loss: (0.2313) |  Loss2: (0.0000) | Acc: (91.00%) (38964/42368)
Epoch: 96 | Batch_idx: 340 |  Loss: (0.2323) |  Loss2: (0.0000) | Acc: (91.00%) (40123/43648)
Epoch: 96 | Batch_idx: 350 |  Loss: (0.2319) |  Loss2: (0.0000) | Acc: (91.00%) (41310/44928)
Epoch: 96 | Batch_idx: 360 |  Loss: (0.2313) |  Loss2: (0.0000) | Acc: (91.00%) (42501/46208)
Epoch: 96 | Batch_idx: 370 |  Loss: (0.2314) |  Loss2: (0.0000) | Acc: (91.00%) (43676/47488)
Epoch: 96 | Batch_idx: 380 |  Loss: (0.2304) |  Loss2: (0.0000) | Acc: (92.00%) (44873/48768)
Epoch: 96 | Batch_idx: 390 |  Loss: (0.2303) |  Loss2: (0.0000) | Acc: (91.00%) (45998/50000)
# TEST : Loss: (0.3772) | Acc: (87.00%) (8759/10000)
percent tensor([0.5365, 0.5246, 0.5532, 0.5508, 0.5496, 0.5397, 0.5334, 0.5478, 0.5424,
        0.5335, 0.5335, 0.5425, 0.5323, 0.5280, 0.5321, 0.5356],
       device='cuda:0') torch.Size([16])
percent tensor([0.5131, 0.5174, 0.5098, 0.5152, 0.5106, 0.5266, 0.5131, 0.5093, 0.5082,
        0.5106, 0.5103, 0.5069, 0.5082, 0.5205, 0.5176, 0.5170],
       device='cuda:0') torch.Size([16])
percent tensor([0.5727, 0.6090, 0.5377, 0.4633, 0.5147, 0.4708, 0.5890, 0.5391, 0.5534,
        0.5931, 0.5920, 0.5842, 0.6496, 0.4908, 0.5704, 0.5314],
       device='cuda:0') torch.Size([16])
percent tensor([0.6836, 0.7043, 0.6838, 0.7040, 0.6895, 0.6800, 0.7105, 0.6753, 0.7144,
        0.7123, 0.7476, 0.7211, 0.7062, 0.7255, 0.7002, 0.7006],
       device='cuda:0') torch.Size([16])
percent tensor([0.6513, 0.6112, 0.6938, 0.6461, 0.6462, 0.7923, 0.6483, 0.6214, 0.6496,
        0.6120, 0.6107, 0.6123, 0.6662, 0.6734, 0.6366, 0.6838],
       device='cuda:0') torch.Size([16])
percent tensor([0.5139, 0.6159, 0.5032, 0.5072, 0.4923, 0.5432, 0.4960, 0.4060, 0.6109,
        0.5648, 0.6328, 0.5570, 0.6355, 0.6607, 0.4192, 0.5253],
       device='cuda:0') torch.Size([16])
percent tensor([0.5822, 0.6059, 0.7334, 0.7590, 0.8225, 0.6918, 0.6640, 0.6891, 0.6747,
        0.6025, 0.6319, 0.7177, 0.6036, 0.6902, 0.6344, 0.6847],
       device='cuda:0') torch.Size([16])
percent tensor([0.9994, 0.9982, 0.9990, 0.9988, 0.9992, 0.9985, 0.9991, 0.9990, 0.9983,
        0.9985, 0.9990, 0.9987, 0.9989, 0.9983, 0.9988, 0.9994],
       device='cuda:0') torch.Size([16])
Epoch: 97 | Batch_idx: 0 |  Loss: (0.1317) |  Loss2: (0.0000) | Acc: (94.00%) (121/128)
Epoch: 97 | Batch_idx: 10 |  Loss: (0.2046) |  Loss2: (0.0000) | Acc: (93.00%) (1314/1408)
Epoch: 97 | Batch_idx: 20 |  Loss: (0.2062) |  Loss2: (0.0000) | Acc: (93.00%) (2504/2688)
Epoch: 97 | Batch_idx: 30 |  Loss: (0.2089) |  Loss2: (0.0000) | Acc: (93.00%) (3692/3968)
Epoch: 97 | Batch_idx: 40 |  Loss: (0.2086) |  Loss2: (0.0000) | Acc: (92.00%) (4879/5248)
Epoch: 97 | Batch_idx: 50 |  Loss: (0.2149) |  Loss2: (0.0000) | Acc: (92.00%) (6046/6528)
Epoch: 97 | Batch_idx: 60 |  Loss: (0.2182) |  Loss2: (0.0000) | Acc: (92.00%) (7209/7808)
Epoch: 97 | Batch_idx: 70 |  Loss: (0.2217) |  Loss2: (0.0000) | Acc: (92.00%) (8376/9088)
Epoch: 97 | Batch_idx: 80 |  Loss: (0.2187) |  Loss2: (0.0000) | Acc: (92.00%) (9569/10368)
Epoch: 97 | Batch_idx: 90 |  Loss: (0.2183) |  Loss2: (0.0000) | Acc: (92.00%) (10753/11648)
Epoch: 97 | Batch_idx: 100 |  Loss: (0.2195) |  Loss2: (0.0000) | Acc: (92.00%) (11937/12928)
Epoch: 97 | Batch_idx: 110 |  Loss: (0.2197) |  Loss2: (0.0000) | Acc: (92.00%) (13117/14208)
Epoch: 97 | Batch_idx: 120 |  Loss: (0.2204) |  Loss2: (0.0000) | Acc: (92.00%) (14301/15488)
Epoch: 97 | Batch_idx: 130 |  Loss: (0.2196) |  Loss2: (0.0000) | Acc: (92.00%) (15475/16768)
Epoch: 97 | Batch_idx: 140 |  Loss: (0.2188) |  Loss2: (0.0000) | Acc: (92.00%) (16668/18048)
Epoch: 97 | Batch_idx: 150 |  Loss: (0.2186) |  Loss2: (0.0000) | Acc: (92.00%) (17844/19328)
Epoch: 97 | Batch_idx: 160 |  Loss: (0.2194) |  Loss2: (0.0000) | Acc: (92.00%) (19013/20608)
Epoch: 97 | Batch_idx: 170 |  Loss: (0.2206) |  Loss2: (0.0000) | Acc: (92.00%) (20188/21888)
Epoch: 97 | Batch_idx: 180 |  Loss: (0.2199) |  Loss2: (0.0000) | Acc: (92.00%) (21376/23168)
Epoch: 97 | Batch_idx: 190 |  Loss: (0.2203) |  Loss2: (0.0000) | Acc: (92.00%) (22562/24448)
Epoch: 97 | Batch_idx: 200 |  Loss: (0.2204) |  Loss2: (0.0000) | Acc: (92.00%) (23739/25728)
Epoch: 97 | Batch_idx: 210 |  Loss: (0.2206) |  Loss2: (0.0000) | Acc: (92.00%) (24920/27008)
Epoch: 97 | Batch_idx: 220 |  Loss: (0.2204) |  Loss2: (0.0000) | Acc: (92.00%) (26094/28288)
Epoch: 97 | Batch_idx: 230 |  Loss: (0.2215) |  Loss2: (0.0000) | Acc: (92.00%) (27257/29568)
Epoch: 97 | Batch_idx: 240 |  Loss: (0.2220) |  Loss2: (0.0000) | Acc: (92.00%) (28432/30848)
Epoch: 97 | Batch_idx: 250 |  Loss: (0.2205) |  Loss2: (0.0000) | Acc: (92.00%) (29637/32128)
Epoch: 97 | Batch_idx: 260 |  Loss: (0.2206) |  Loss2: (0.0000) | Acc: (92.00%) (30818/33408)
Epoch: 97 | Batch_idx: 270 |  Loss: (0.2204) |  Loss2: (0.0000) | Acc: (92.00%) (32009/34688)
Epoch: 97 | Batch_idx: 280 |  Loss: (0.2202) |  Loss2: (0.0000) | Acc: (92.00%) (33203/35968)
Epoch: 97 | Batch_idx: 290 |  Loss: (0.2194) |  Loss2: (0.0000) | Acc: (92.00%) (34401/37248)
Epoch: 97 | Batch_idx: 300 |  Loss: (0.2185) |  Loss2: (0.0000) | Acc: (92.00%) (35596/38528)
Epoch: 97 | Batch_idx: 310 |  Loss: (0.2187) |  Loss2: (0.0000) | Acc: (92.00%) (36776/39808)
Epoch: 97 | Batch_idx: 320 |  Loss: (0.2187) |  Loss2: (0.0000) | Acc: (92.00%) (37961/41088)
Epoch: 97 | Batch_idx: 330 |  Loss: (0.2179) |  Loss2: (0.0000) | Acc: (92.00%) (39163/42368)
Epoch: 97 | Batch_idx: 340 |  Loss: (0.2183) |  Loss2: (0.0000) | Acc: (92.00%) (40344/43648)
Epoch: 97 | Batch_idx: 350 |  Loss: (0.2187) |  Loss2: (0.0000) | Acc: (92.00%) (41528/44928)
Epoch: 97 | Batch_idx: 360 |  Loss: (0.2192) |  Loss2: (0.0000) | Acc: (92.00%) (42693/46208)
Epoch: 97 | Batch_idx: 370 |  Loss: (0.2185) |  Loss2: (0.0000) | Acc: (92.00%) (43894/47488)
Epoch: 97 | Batch_idx: 380 |  Loss: (0.2183) |  Loss2: (0.0000) | Acc: (92.00%) (45079/48768)
Epoch: 97 | Batch_idx: 390 |  Loss: (0.2188) |  Loss2: (0.0000) | Acc: (92.00%) (46209/50000)
# TEST : Loss: (0.3717) | Acc: (87.00%) (8768/10000)
percent tensor([0.5333, 0.5217, 0.5511, 0.5481, 0.5471, 0.5353, 0.5305, 0.5456, 0.5395,
        0.5311, 0.5304, 0.5405, 0.5295, 0.5252, 0.5286, 0.5324],
       device='cuda:0') torch.Size([16])
percent tensor([0.5121, 0.5168, 0.5095, 0.5154, 0.5102, 0.5266, 0.5122, 0.5088, 0.5073,
        0.5100, 0.5095, 0.5064, 0.5069, 0.5200, 0.5172, 0.5167],
       device='cuda:0') torch.Size([16])
percent tensor([0.5785, 0.6181, 0.5410, 0.4664, 0.5203, 0.4785, 0.5959, 0.5416, 0.5591,
        0.6005, 0.5997, 0.5891, 0.6560, 0.4968, 0.5785, 0.5378],
       device='cuda:0') torch.Size([16])
percent tensor([0.6808, 0.7006, 0.6820, 0.7032, 0.6878, 0.6791, 0.7076, 0.6728, 0.7108,
        0.7088, 0.7450, 0.7174, 0.7009, 0.7229, 0.6981, 0.6986],
       device='cuda:0') torch.Size([16])
percent tensor([0.6553, 0.6091, 0.6942, 0.6446, 0.6484, 0.7966, 0.6519, 0.6248, 0.6475,
        0.6109, 0.6095, 0.6147, 0.6640, 0.6720, 0.6431, 0.6865],
       device='cuda:0') torch.Size([16])
percent tensor([0.5101, 0.6129, 0.4964, 0.4983, 0.4868, 0.5378, 0.4911, 0.4007, 0.6079,
        0.5607, 0.6297, 0.5513, 0.6340, 0.6546, 0.4127, 0.5182],
       device='cuda:0') torch.Size([16])
percent tensor([0.5986, 0.6163, 0.7437, 0.7696, 0.8314, 0.7003, 0.6824, 0.6991, 0.6864,
        0.6130, 0.6417, 0.7271, 0.6137, 0.7012, 0.6446, 0.7030],
       device='cuda:0') torch.Size([16])
percent tensor([0.9994, 0.9982, 0.9990, 0.9989, 0.9992, 0.9985, 0.9992, 0.9990, 0.9983,
        0.9986, 0.9990, 0.9988, 0.9989, 0.9984, 0.9988, 0.9994],
       device='cuda:0') torch.Size([16])
Epoch: 98 | Batch_idx: 0 |  Loss: (0.2657) |  Loss2: (0.0000) | Acc: (90.00%) (116/128)
Epoch: 98 | Batch_idx: 10 |  Loss: (0.2257) |  Loss2: (0.0000) | Acc: (92.00%) (1304/1408)
Epoch: 98 | Batch_idx: 20 |  Loss: (0.2130) |  Loss2: (0.0000) | Acc: (92.00%) (2490/2688)
Epoch: 98 | Batch_idx: 30 |  Loss: (0.2134) |  Loss2: (0.0000) | Acc: (92.00%) (3682/3968)
Epoch: 98 | Batch_idx: 40 |  Loss: (0.2126) |  Loss2: (0.0000) | Acc: (92.00%) (4869/5248)
Epoch: 98 | Batch_idx: 50 |  Loss: (0.2085) |  Loss2: (0.0000) | Acc: (93.00%) (6074/6528)
Epoch: 98 | Batch_idx: 60 |  Loss: (0.2049) |  Loss2: (0.0000) | Acc: (93.00%) (7271/7808)
Epoch: 98 | Batch_idx: 70 |  Loss: (0.2075) |  Loss2: (0.0000) | Acc: (93.00%) (8456/9088)
Epoch: 98 | Batch_idx: 80 |  Loss: (0.2081) |  Loss2: (0.0000) | Acc: (92.00%) (9640/10368)
Epoch: 98 | Batch_idx: 90 |  Loss: (0.2089) |  Loss2: (0.0000) | Acc: (92.00%) (10822/11648)
Epoch: 98 | Batch_idx: 100 |  Loss: (0.2088) |  Loss2: (0.0000) | Acc: (92.00%) (12009/12928)
Epoch: 98 | Batch_idx: 110 |  Loss: (0.2086) |  Loss2: (0.0000) | Acc: (92.00%) (13195/14208)
Epoch: 98 | Batch_idx: 120 |  Loss: (0.2086) |  Loss2: (0.0000) | Acc: (92.00%) (14379/15488)
Epoch: 98 | Batch_idx: 130 |  Loss: (0.2087) |  Loss2: (0.0000) | Acc: (92.00%) (15571/16768)
Epoch: 98 | Batch_idx: 140 |  Loss: (0.2075) |  Loss2: (0.0000) | Acc: (92.00%) (16773/18048)
Epoch: 98 | Batch_idx: 150 |  Loss: (0.2083) |  Loss2: (0.0000) | Acc: (92.00%) (17951/19328)
Epoch: 98 | Batch_idx: 160 |  Loss: (0.2068) |  Loss2: (0.0000) | Acc: (92.00%) (19150/20608)
Epoch: 98 | Batch_idx: 170 |  Loss: (0.2078) |  Loss2: (0.0000) | Acc: (92.00%) (20335/21888)
Epoch: 98 | Batch_idx: 180 |  Loss: (0.2087) |  Loss2: (0.0000) | Acc: (92.00%) (21513/23168)
Epoch: 98 | Batch_idx: 190 |  Loss: (0.2098) |  Loss2: (0.0000) | Acc: (92.00%) (22699/24448)
Epoch: 98 | Batch_idx: 200 |  Loss: (0.2111) |  Loss2: (0.0000) | Acc: (92.00%) (23872/25728)
Epoch: 98 | Batch_idx: 210 |  Loss: (0.2122) |  Loss2: (0.0000) | Acc: (92.00%) (25044/27008)
Epoch: 98 | Batch_idx: 220 |  Loss: (0.2121) |  Loss2: (0.0000) | Acc: (92.00%) (26241/28288)
Epoch: 98 | Batch_idx: 230 |  Loss: (0.2118) |  Loss2: (0.0000) | Acc: (92.00%) (27431/29568)
Epoch: 98 | Batch_idx: 240 |  Loss: (0.2110) |  Loss2: (0.0000) | Acc: (92.00%) (28621/30848)
Epoch: 98 | Batch_idx: 250 |  Loss: (0.2110) |  Loss2: (0.0000) | Acc: (92.00%) (29805/32128)
Epoch: 98 | Batch_idx: 260 |  Loss: (0.2119) |  Loss2: (0.0000) | Acc: (92.00%) (30989/33408)
Epoch: 98 | Batch_idx: 270 |  Loss: (0.2121) |  Loss2: (0.0000) | Acc: (92.00%) (32177/34688)
Epoch: 98 | Batch_idx: 280 |  Loss: (0.2113) |  Loss2: (0.0000) | Acc: (92.00%) (33378/35968)
Epoch: 98 | Batch_idx: 290 |  Loss: (0.2120) |  Loss2: (0.0000) | Acc: (92.00%) (34557/37248)
Epoch: 98 | Batch_idx: 300 |  Loss: (0.2118) |  Loss2: (0.0000) | Acc: (92.00%) (35750/38528)
Epoch: 98 | Batch_idx: 310 |  Loss: (0.2119) |  Loss2: (0.0000) | Acc: (92.00%) (36930/39808)
Epoch: 98 | Batch_idx: 320 |  Loss: (0.2115) |  Loss2: (0.0000) | Acc: (92.00%) (38121/41088)
Epoch: 98 | Batch_idx: 330 |  Loss: (0.2112) |  Loss2: (0.0000) | Acc: (92.00%) (39307/42368)
Epoch: 98 | Batch_idx: 340 |  Loss: (0.2118) |  Loss2: (0.0000) | Acc: (92.00%) (40487/43648)
Epoch: 98 | Batch_idx: 350 |  Loss: (0.2118) |  Loss2: (0.0000) | Acc: (92.00%) (41673/44928)
Epoch: 98 | Batch_idx: 360 |  Loss: (0.2120) |  Loss2: (0.0000) | Acc: (92.00%) (42852/46208)
Epoch: 98 | Batch_idx: 370 |  Loss: (0.2129) |  Loss2: (0.0000) | Acc: (92.00%) (44033/47488)
Epoch: 98 | Batch_idx: 380 |  Loss: (0.2132) |  Loss2: (0.0000) | Acc: (92.00%) (45220/48768)
Epoch: 98 | Batch_idx: 390 |  Loss: (0.2124) |  Loss2: (0.0000) | Acc: (92.00%) (46378/50000)
# TEST : Loss: (0.3659) | Acc: (87.00%) (8787/10000)
percent tensor([0.5332, 0.5220, 0.5519, 0.5482, 0.5478, 0.5345, 0.5309, 0.5463, 0.5398,
        0.5317, 0.5305, 0.5415, 0.5297, 0.5253, 0.5285, 0.5321],
       device='cuda:0') torch.Size([16])
percent tensor([0.5141, 0.5194, 0.5121, 0.5184, 0.5128, 0.5294, 0.5146, 0.5112, 0.5092,
        0.5124, 0.5116, 0.5087, 0.5088, 0.5226, 0.5198, 0.5192],
       device='cuda:0') torch.Size([16])
percent tensor([0.5838, 0.6241, 0.5467, 0.4689, 0.5278, 0.4840, 0.6026, 0.5454, 0.5646,
        0.6066, 0.6054, 0.5950, 0.6610, 0.4996, 0.5847, 0.5425],
       device='cuda:0') torch.Size([16])
percent tensor([0.6812, 0.7008, 0.6821, 0.7045, 0.6882, 0.6804, 0.7078, 0.6728, 0.7106,
        0.7088, 0.7459, 0.7173, 0.6999, 0.7235, 0.6991, 0.6993],
       device='cuda:0') torch.Size([16])
percent tensor([0.6541, 0.6112, 0.6919, 0.6378, 0.6469, 0.7947, 0.6551, 0.6200, 0.6474,
        0.6130, 0.6127, 0.6159, 0.6643, 0.6754, 0.6419, 0.6855],
       device='cuda:0') torch.Size([16])
percent tensor([0.5153, 0.6171, 0.5022, 0.5036, 0.4943, 0.5444, 0.4948, 0.4060, 0.6143,
        0.5633, 0.6350, 0.5558, 0.6390, 0.6569, 0.4156, 0.5214],
       device='cuda:0') torch.Size([16])
percent tensor([0.6040, 0.6172, 0.7489, 0.7746, 0.8348, 0.7060, 0.6867, 0.7013, 0.6910,
        0.6135, 0.6473, 0.7331, 0.6201, 0.7085, 0.6420, 0.7077],
       device='cuda:0') torch.Size([16])
percent tensor([0.9994, 0.9982, 0.9990, 0.9989, 0.9993, 0.9985, 0.9992, 0.9991, 0.9983,
        0.9986, 0.9990, 0.9988, 0.9989, 0.9985, 0.9988, 0.9994],
       device='cuda:0') torch.Size([16])
Epoch: 99 | Batch_idx: 0 |  Loss: (0.2477) |  Loss2: (0.0000) | Acc: (87.00%) (112/128)
Epoch: 99 | Batch_idx: 10 |  Loss: (0.2137) |  Loss2: (0.0000) | Acc: (92.00%) (1296/1408)
Epoch: 99 | Batch_idx: 20 |  Loss: (0.2180) |  Loss2: (0.0000) | Acc: (92.00%) (2475/2688)
Epoch: 99 | Batch_idx: 30 |  Loss: (0.2056) |  Loss2: (0.0000) | Acc: (92.00%) (3680/3968)
Epoch: 99 | Batch_idx: 40 |  Loss: (0.2123) |  Loss2: (0.0000) | Acc: (92.00%) (4853/5248)
Epoch: 99 | Batch_idx: 50 |  Loss: (0.2076) |  Loss2: (0.0000) | Acc: (92.00%) (6057/6528)
Epoch: 99 | Batch_idx: 60 |  Loss: (0.2059) |  Loss2: (0.0000) | Acc: (92.00%) (7240/7808)
Epoch: 99 | Batch_idx: 70 |  Loss: (0.2033) |  Loss2: (0.0000) | Acc: (92.00%) (8442/9088)
Epoch: 99 | Batch_idx: 80 |  Loss: (0.2043) |  Loss2: (0.0000) | Acc: (92.00%) (9630/10368)
Epoch: 99 | Batch_idx: 90 |  Loss: (0.2050) |  Loss2: (0.0000) | Acc: (92.00%) (10824/11648)
Epoch: 99 | Batch_idx: 100 |  Loss: (0.2058) |  Loss2: (0.0000) | Acc: (92.00%) (12011/12928)
Epoch: 99 | Batch_idx: 110 |  Loss: (0.2052) |  Loss2: (0.0000) | Acc: (92.00%) (13205/14208)
Epoch: 99 | Batch_idx: 120 |  Loss: (0.2066) |  Loss2: (0.0000) | Acc: (92.00%) (14385/15488)
Epoch: 99 | Batch_idx: 130 |  Loss: (0.2089) |  Loss2: (0.0000) | Acc: (92.00%) (15565/16768)
Epoch: 99 | Batch_idx: 140 |  Loss: (0.2071) |  Loss2: (0.0000) | Acc: (92.00%) (16779/18048)
Epoch: 99 | Batch_idx: 150 |  Loss: (0.2085) |  Loss2: (0.0000) | Acc: (92.00%) (17954/19328)
Epoch: 99 | Batch_idx: 160 |  Loss: (0.2081) |  Loss2: (0.0000) | Acc: (92.00%) (19148/20608)
Epoch: 99 | Batch_idx: 170 |  Loss: (0.2095) |  Loss2: (0.0000) | Acc: (92.00%) (20330/21888)
Epoch: 99 | Batch_idx: 180 |  Loss: (0.2083) |  Loss2: (0.0000) | Acc: (92.00%) (21526/23168)
Epoch: 99 | Batch_idx: 190 |  Loss: (0.2090) |  Loss2: (0.0000) | Acc: (92.00%) (22714/24448)
Epoch: 99 | Batch_idx: 200 |  Loss: (0.2081) |  Loss2: (0.0000) | Acc: (92.00%) (23915/25728)
Epoch: 99 | Batch_idx: 210 |  Loss: (0.2075) |  Loss2: (0.0000) | Acc: (92.00%) (25116/27008)
Epoch: 99 | Batch_idx: 220 |  Loss: (0.2081) |  Loss2: (0.0000) | Acc: (92.00%) (26297/28288)
Epoch: 99 | Batch_idx: 230 |  Loss: (0.2085) |  Loss2: (0.0000) | Acc: (92.00%) (27482/29568)
Epoch: 99 | Batch_idx: 240 |  Loss: (0.2075) |  Loss2: (0.0000) | Acc: (92.00%) (28683/30848)
Epoch: 99 | Batch_idx: 250 |  Loss: (0.2094) |  Loss2: (0.0000) | Acc: (92.00%) (29855/32128)
Epoch: 99 | Batch_idx: 260 |  Loss: (0.2092) |  Loss2: (0.0000) | Acc: (92.00%) (31047/33408)
Epoch: 99 | Batch_idx: 270 |  Loss: (0.2086) |  Loss2: (0.0000) | Acc: (92.00%) (32246/34688)
Epoch: 99 | Batch_idx: 280 |  Loss: (0.2095) |  Loss2: (0.0000) | Acc: (92.00%) (33430/35968)
Epoch: 99 | Batch_idx: 290 |  Loss: (0.2097) |  Loss2: (0.0000) | Acc: (92.00%) (34610/37248)
Epoch: 99 | Batch_idx: 300 |  Loss: (0.2103) |  Loss2: (0.0000) | Acc: (92.00%) (35789/38528)
Epoch: 99 | Batch_idx: 310 |  Loss: (0.2112) |  Loss2: (0.0000) | Acc: (92.00%) (36963/39808)
Epoch: 99 | Batch_idx: 320 |  Loss: (0.2107) |  Loss2: (0.0000) | Acc: (92.00%) (38159/41088)
Epoch: 99 | Batch_idx: 330 |  Loss: (0.2114) |  Loss2: (0.0000) | Acc: (92.00%) (39340/42368)
Epoch: 99 | Batch_idx: 340 |  Loss: (0.2105) |  Loss2: (0.0000) | Acc: (92.00%) (40547/43648)
Epoch: 99 | Batch_idx: 350 |  Loss: (0.2103) |  Loss2: (0.0000) | Acc: (92.00%) (41735/44928)
Epoch: 99 | Batch_idx: 360 |  Loss: (0.2100) |  Loss2: (0.0000) | Acc: (92.00%) (42923/46208)
Epoch: 99 | Batch_idx: 370 |  Loss: (0.2101) |  Loss2: (0.0000) | Acc: (92.00%) (44109/47488)
Epoch: 99 | Batch_idx: 380 |  Loss: (0.2099) |  Loss2: (0.0000) | Acc: (92.00%) (45311/48768)
Epoch: 99 | Batch_idx: 390 |  Loss: (0.2101) |  Loss2: (0.0000) | Acc: (92.00%) (46444/50000)
# TEST : Loss: (0.3645) | Acc: (87.00%) (8788/10000)
percent tensor([0.5351, 0.5241, 0.5548, 0.5508, 0.5506, 0.5361, 0.5334, 0.5492, 0.5419,
        0.5342, 0.5323, 0.5443, 0.5317, 0.5273, 0.5306, 0.5341],
       device='cuda:0') torch.Size([16])
percent tensor([0.5150, 0.5204, 0.5132, 0.5199, 0.5139, 0.5313, 0.5154, 0.5121, 0.5099,
        0.5133, 0.5124, 0.5098, 0.5095, 0.5237, 0.5210, 0.5205],
       device='cuda:0') torch.Size([16])
percent tensor([0.5758, 0.6200, 0.5384, 0.4609, 0.5200, 0.4768, 0.5961, 0.5362, 0.5592,
        0.6021, 0.6007, 0.5880, 0.6542, 0.4977, 0.5781, 0.5355],
       device='cuda:0') torch.Size([16])
percent tensor([0.6806, 0.7001, 0.6822, 0.7052, 0.6883, 0.6824, 0.7071, 0.6722, 0.7106,
        0.7084, 0.7459, 0.7171, 0.6981, 0.7238, 0.6989, 0.6995],
       device='cuda:0') torch.Size([16])
percent tensor([0.6573, 0.6172, 0.6904, 0.6360, 0.6465, 0.7968, 0.6585, 0.6177, 0.6514,
        0.6172, 0.6208, 0.6168, 0.6682, 0.6822, 0.6453, 0.6897],
       device='cuda:0') torch.Size([16])
percent tensor([0.5081, 0.6099, 0.4978, 0.4964, 0.4875, 0.5403, 0.4844, 0.3983, 0.6100,
        0.5582, 0.6293, 0.5505, 0.6341, 0.6482, 0.4089, 0.5117],
       device='cuda:0') torch.Size([16])
percent tensor([0.6025, 0.6176, 0.7513, 0.7785, 0.8370, 0.7096, 0.6878, 0.6995, 0.6922,
        0.6118, 0.6466, 0.7343, 0.6199, 0.7114, 0.6400, 0.7095],
       device='cuda:0') torch.Size([16])
percent tensor([0.9995, 0.9983, 0.9991, 0.9989, 0.9993, 0.9986, 0.9992, 0.9991, 0.9984,
        0.9986, 0.9990, 0.9989, 0.9990, 0.9986, 0.9988, 0.9994],
       device='cuda:0') torch.Size([16])
True Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=128, out_features=16, bias=False)
False Linear(in_features=16, out_features=2, bias=False)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=128, out_features=16, bias=False)
False Linear(in_features=16, out_features=2, bias=False)
True Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=256, out_features=32, bias=False)
False Linear(in_features=32, out_features=2, bias=False)
True Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=256, out_features=32, bias=False)
False Linear(in_features=32, out_features=2, bias=False)
True Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=512, out_features=64, bias=False)
False Linear(in_features=64, out_features=2, bias=False)
True Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=512, out_features=64, bias=False)
False Linear(in_features=64, out_features=2, bias=False)
True Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1024, out_features=128, bias=False)
False Linear(in_features=128, out_features=2, bias=False)
True Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1024, out_features=128, bias=False)
False Linear(in_features=128, out_features=2, bias=False)
True Linear(in_features=512, out_features=10, bias=True)
Epoch: 100 | Batch_idx: 0 |  Loss: (0.1938) |  Loss2: (0.0000) | Acc: (94.00%) (121/128)
Epoch: 100 | Batch_idx: 10 |  Loss: (0.2198) |  Loss2: (0.0000) | Acc: (92.00%) (1303/1408)
Epoch: 100 | Batch_idx: 20 |  Loss: (0.2215) |  Loss2: (0.0000) | Acc: (92.00%) (2487/2688)
Epoch: 100 | Batch_idx: 30 |  Loss: (0.2252) |  Loss2: (0.0000) | Acc: (92.00%) (3663/3968)
Epoch: 100 | Batch_idx: 40 |  Loss: (0.2177) |  Loss2: (0.0000) | Acc: (92.00%) (4858/5248)
Epoch: 100 | Batch_idx: 50 |  Loss: (0.2185) |  Loss2: (0.0000) | Acc: (92.00%) (6046/6528)
Epoch: 100 | Batch_idx: 60 |  Loss: (0.2192) |  Loss2: (0.0000) | Acc: (92.00%) (7230/7808)
Epoch: 100 | Batch_idx: 70 |  Loss: (0.2217) |  Loss2: (0.0000) | Acc: (92.00%) (8412/9088)
Epoch: 100 | Batch_idx: 80 |  Loss: (0.2253) |  Loss2: (0.0000) | Acc: (92.00%) (9579/10368)
Epoch: 100 | Batch_idx: 90 |  Loss: (0.2286) |  Loss2: (0.0000) | Acc: (92.00%) (10739/11648)
Epoch: 100 | Batch_idx: 100 |  Loss: (0.2288) |  Loss2: (0.0000) | Acc: (92.00%) (11909/12928)
Epoch: 100 | Batch_idx: 110 |  Loss: (0.2254) |  Loss2: (0.0000) | Acc: (92.00%) (13114/14208)
Epoch: 100 | Batch_idx: 120 |  Loss: (0.2243) |  Loss2: (0.0000) | Acc: (92.00%) (14309/15488)
Epoch: 100 | Batch_idx: 130 |  Loss: (0.2236) |  Loss2: (0.0000) | Acc: (92.00%) (15493/16768)
Epoch: 100 | Batch_idx: 140 |  Loss: (0.2255) |  Loss2: (0.0000) | Acc: (92.00%) (16666/18048)
Epoch: 100 | Batch_idx: 150 |  Loss: (0.2253) |  Loss2: (0.0000) | Acc: (92.00%) (17846/19328)
Epoch: 100 | Batch_idx: 160 |  Loss: (0.2261) |  Loss2: (0.0000) | Acc: (92.00%) (19016/20608)
Epoch: 100 | Batch_idx: 170 |  Loss: (0.2255) |  Loss2: (0.0000) | Acc: (92.00%) (20203/21888)
Epoch: 100 | Batch_idx: 180 |  Loss: (0.2246) |  Loss2: (0.0000) | Acc: (92.00%) (21383/23168)
Epoch: 100 | Batch_idx: 190 |  Loss: (0.2253) |  Loss2: (0.0000) | Acc: (92.00%) (22552/24448)
Epoch: 100 | Batch_idx: 200 |  Loss: (0.2255) |  Loss2: (0.0000) | Acc: (92.00%) (23728/25728)
Epoch: 100 | Batch_idx: 210 |  Loss: (0.2258) |  Loss2: (0.0000) | Acc: (92.00%) (24910/27008)
Epoch: 100 | Batch_idx: 220 |  Loss: (0.2261) |  Loss2: (0.0000) | Acc: (92.00%) (26083/28288)
Epoch: 100 | Batch_idx: 230 |  Loss: (0.2259) |  Loss2: (0.0000) | Acc: (92.00%) (27267/29568)
Epoch: 100 | Batch_idx: 240 |  Loss: (0.2256) |  Loss2: (0.0000) | Acc: (92.00%) (28443/30848)
Epoch: 100 | Batch_idx: 250 |  Loss: (0.2256) |  Loss2: (0.0000) | Acc: (92.00%) (29615/32128)
Epoch: 100 | Batch_idx: 260 |  Loss: (0.2254) |  Loss2: (0.0000) | Acc: (92.00%) (30795/33408)
Epoch: 100 | Batch_idx: 270 |  Loss: (0.2247) |  Loss2: (0.0000) | Acc: (92.00%) (31983/34688)
Epoch: 100 | Batch_idx: 280 |  Loss: (0.2247) |  Loss2: (0.0000) | Acc: (92.00%) (33156/35968)
Epoch: 100 | Batch_idx: 290 |  Loss: (0.2250) |  Loss2: (0.0000) | Acc: (92.00%) (34326/37248)
Epoch: 100 | Batch_idx: 300 |  Loss: (0.2253) |  Loss2: (0.0000) | Acc: (92.00%) (35501/38528)
Epoch: 100 | Batch_idx: 310 |  Loss: (0.2258) |  Loss2: (0.0000) | Acc: (92.00%) (36677/39808)
Epoch: 100 | Batch_idx: 320 |  Loss: (0.2261) |  Loss2: (0.0000) | Acc: (92.00%) (37847/41088)
Epoch: 100 | Batch_idx: 330 |  Loss: (0.2260) |  Loss2: (0.0000) | Acc: (92.00%) (39030/42368)
Epoch: 100 | Batch_idx: 340 |  Loss: (0.2255) |  Loss2: (0.0000) | Acc: (92.00%) (40214/43648)
Epoch: 100 | Batch_idx: 350 |  Loss: (0.2251) |  Loss2: (0.0000) | Acc: (92.00%) (41394/44928)
Epoch: 100 | Batch_idx: 360 |  Loss: (0.2250) |  Loss2: (0.0000) | Acc: (92.00%) (42576/46208)
Epoch: 100 | Batch_idx: 370 |  Loss: (0.2249) |  Loss2: (0.0000) | Acc: (92.00%) (43756/47488)
Epoch: 100 | Batch_idx: 380 |  Loss: (0.2247) |  Loss2: (0.0000) | Acc: (92.00%) (44940/48768)
Epoch: 100 | Batch_idx: 390 |  Loss: (0.2250) |  Loss2: (0.0000) | Acc: (92.00%) (46062/50000)
=> saving checkpoint 'drive/app/torch/save_Routing_Gate_2/checkpoint_100.pth.tar'
# TEST : Loss: (0.4251) | Acc: (86.00%) (8614/10000)
percent tensor([0.5350, 0.5235, 0.5544, 0.5495, 0.5518, 0.5355, 0.5338, 0.5473, 0.5423,
        0.5346, 0.5323, 0.5454, 0.5316, 0.5276, 0.5300, 0.5334],
       device='cuda:0') torch.Size([16])
percent tensor([0.5143, 0.5210, 0.5143, 0.5193, 0.5135, 0.5299, 0.5161, 0.5136, 0.5095,
        0.5139, 0.5125, 0.5103, 0.5093, 0.5259, 0.5208, 0.5202],
       device='cuda:0') torch.Size([16])
percent tensor([0.5751, 0.6225, 0.5221, 0.4579, 0.5124, 0.4854, 0.5950, 0.5255, 0.5592,
        0.5964, 0.6003, 0.5771, 0.6539, 0.4941, 0.5777, 0.5328],
       device='cuda:0') torch.Size([16])
percent tensor([0.6821, 0.7056, 0.6966, 0.7019, 0.6914, 0.6756, 0.7065, 0.6869, 0.7064,
        0.7134, 0.7365, 0.7258, 0.6973, 0.7264, 0.7002, 0.6960],
       device='cuda:0') torch.Size([16])
percent tensor([0.6596, 0.6164, 0.6817, 0.6375, 0.6710, 0.8121, 0.6593, 0.6171, 0.6733,
        0.6197, 0.6427, 0.6086, 0.6765, 0.6700, 0.6544, 0.7046],
       device='cuda:0') torch.Size([16])
percent tensor([0.5018, 0.5996, 0.5452, 0.4993, 0.5029, 0.5448, 0.5103, 0.3836, 0.6004,
        0.5456, 0.6184, 0.5786, 0.6154, 0.6510, 0.4227, 0.5158],
       device='cuda:0') torch.Size([16])
percent tensor([0.6181, 0.6354, 0.7706, 0.7744, 0.8325, 0.6985, 0.6969, 0.7053, 0.6713,
        0.6330, 0.6690, 0.7528, 0.6365, 0.7364, 0.6665, 0.7084],
       device='cuda:0') torch.Size([16])
percent tensor([0.9993, 0.9982, 0.9992, 0.9991, 0.9990, 0.9987, 0.9987, 0.9992, 0.9982,
        0.9988, 0.9989, 0.9989, 0.9987, 0.9981, 0.9988, 0.9993],
       device='cuda:0') torch.Size([16])
Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 3, 3, 3]) tensor(179.3221, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(807.0511, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(812.9057, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([128, 64, 3, 3]) tensor(1516.9462, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([128, 64, 1, 1]) tensor(495.3400, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([128, 128, 3, 3]) tensor(2241.8298, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([256, 128, 3, 3]) tensor(4283.8638, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([256, 128, 1, 1]) tensor(1394.2222, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([256, 256, 3, 3]) tensor(6131.5068, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([512, 256, 3, 3]) tensor(11869.5420, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([512, 256, 1, 1]) tensor(3939.8247, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([512, 512, 3, 3]) tensor(16631.9922, device='cuda:0', grad_fn=<NormBackward0>)
Epoch: 101 | Batch_idx: 0 |  Loss: (0.1914) |  Loss2: (0.0000) | Acc: (94.00%) (121/128)
Epoch: 101 | Batch_idx: 10 |  Loss: (0.2196) |  Loss2: (0.0000) | Acc: (92.00%) (1305/1408)
Epoch: 101 | Batch_idx: 20 |  Loss: (0.2086) |  Loss2: (0.0000) | Acc: (93.00%) (2501/2688)
Epoch: 101 | Batch_idx: 30 |  Loss: (0.2094) |  Loss2: (0.0000) | Acc: (92.00%) (3690/3968)
Epoch: 101 | Batch_idx: 40 |  Loss: (0.2093) |  Loss2: (0.0000) | Acc: (93.00%) (4885/5248)
Epoch: 101 | Batch_idx: 50 |  Loss: (0.2099) |  Loss2: (0.0000) | Acc: (92.00%) (6063/6528)
Epoch: 101 | Batch_idx: 60 |  Loss: (0.2064) |  Loss2: (0.0000) | Acc: (93.00%) (7271/7808)
Epoch: 101 | Batch_idx: 70 |  Loss: (0.2038) |  Loss2: (0.0000) | Acc: (93.00%) (8466/9088)
Epoch: 101 | Batch_idx: 80 |  Loss: (0.2034) |  Loss2: (0.0000) | Acc: (93.00%) (9668/10368)
Epoch: 101 | Batch_idx: 90 |  Loss: (0.2062) |  Loss2: (0.0000) | Acc: (93.00%) (10851/11648)
Epoch: 101 | Batch_idx: 100 |  Loss: (0.2106) |  Loss2: (0.0000) | Acc: (92.00%) (12019/12928)
Epoch: 101 | Batch_idx: 110 |  Loss: (0.2118) |  Loss2: (0.0000) | Acc: (92.00%) (13198/14208)
Epoch: 101 | Batch_idx: 120 |  Loss: (0.2117) |  Loss2: (0.0000) | Acc: (92.00%) (14385/15488)
Epoch: 101 | Batch_idx: 130 |  Loss: (0.2129) |  Loss2: (0.0000) | Acc: (92.00%) (15565/16768)
Epoch: 101 | Batch_idx: 140 |  Loss: (0.2162) |  Loss2: (0.0000) | Acc: (92.00%) (16735/18048)
Epoch: 101 | Batch_idx: 150 |  Loss: (0.2155) |  Loss2: (0.0000) | Acc: (92.00%) (17924/19328)
Epoch: 101 | Batch_idx: 160 |  Loss: (0.2157) |  Loss2: (0.0000) | Acc: (92.00%) (19112/20608)
Epoch: 101 | Batch_idx: 170 |  Loss: (0.2151) |  Loss2: (0.0000) | Acc: (92.00%) (20303/21888)
Epoch: 101 | Batch_idx: 180 |  Loss: (0.2164) |  Loss2: (0.0000) | Acc: (92.00%) (21476/23168)
Epoch: 101 | Batch_idx: 190 |  Loss: (0.2157) |  Loss2: (0.0000) | Acc: (92.00%) (22669/24448)
Epoch: 101 | Batch_idx: 200 |  Loss: (0.2151) |  Loss2: (0.0000) | Acc: (92.00%) (23858/25728)
Epoch: 101 | Batch_idx: 210 |  Loss: (0.2154) |  Loss2: (0.0000) | Acc: (92.00%) (25047/27008)
Epoch: 101 | Batch_idx: 220 |  Loss: (0.2158) |  Loss2: (0.0000) | Acc: (92.00%) (26228/28288)
Epoch: 101 | Batch_idx: 230 |  Loss: (0.2155) |  Loss2: (0.0000) | Acc: (92.00%) (27419/29568)
Epoch: 101 | Batch_idx: 240 |  Loss: (0.2153) |  Loss2: (0.0000) | Acc: (92.00%) (28609/30848)
Epoch: 101 | Batch_idx: 250 |  Loss: (0.2163) |  Loss2: (0.0000) | Acc: (92.00%) (29773/32128)
Epoch: 101 | Batch_idx: 260 |  Loss: (0.2172) |  Loss2: (0.0000) | Acc: (92.00%) (30950/33408)
Epoch: 101 | Batch_idx: 270 |  Loss: (0.2162) |  Loss2: (0.0000) | Acc: (92.00%) (32148/34688)
Epoch: 101 | Batch_idx: 280 |  Loss: (0.2168) |  Loss2: (0.0000) | Acc: (92.00%) (33314/35968)
Epoch: 101 | Batch_idx: 290 |  Loss: (0.2167) |  Loss2: (0.0000) | Acc: (92.00%) (34496/37248)
Epoch: 101 | Batch_idx: 300 |  Loss: (0.2177) |  Loss2: (0.0000) | Acc: (92.00%) (35657/38528)
Epoch: 101 | Batch_idx: 310 |  Loss: (0.2170) |  Loss2: (0.0000) | Acc: (92.00%) (36854/39808)
Epoch: 101 | Batch_idx: 320 |  Loss: (0.2159) |  Loss2: (0.0000) | Acc: (92.00%) (38060/41088)
Epoch: 101 | Batch_idx: 330 |  Loss: (0.2146) |  Loss2: (0.0000) | Acc: (92.00%) (39276/42368)
Epoch: 101 | Batch_idx: 340 |  Loss: (0.2139) |  Loss2: (0.0000) | Acc: (92.00%) (40480/43648)
Epoch: 101 | Batch_idx: 350 |  Loss: (0.2136) |  Loss2: (0.0000) | Acc: (92.00%) (41674/44928)
Epoch: 101 | Batch_idx: 360 |  Loss: (0.2142) |  Loss2: (0.0000) | Acc: (92.00%) (42843/46208)
Epoch: 101 | Batch_idx: 370 |  Loss: (0.2142) |  Loss2: (0.0000) | Acc: (92.00%) (44022/47488)
Epoch: 101 | Batch_idx: 380 |  Loss: (0.2138) |  Loss2: (0.0000) | Acc: (92.00%) (45220/48768)
Epoch: 101 | Batch_idx: 390 |  Loss: (0.2134) |  Loss2: (0.0000) | Acc: (92.00%) (46369/50000)
# TEST : Loss: (0.3878) | Acc: (87.00%) (8719/10000)
percent tensor([0.5338, 0.5243, 0.5517, 0.5492, 0.5488, 0.5351, 0.5335, 0.5462, 0.5401,
        0.5337, 0.5311, 0.5433, 0.5307, 0.5283, 0.5303, 0.5329],
       device='cuda:0') torch.Size([16])
percent tensor([0.5137, 0.5216, 0.5112, 0.5180, 0.5129, 0.5301, 0.5167, 0.5112, 0.5094,
        0.5135, 0.5131, 0.5081, 0.5091, 0.5275, 0.5205, 0.5201],
       device='cuda:0') torch.Size([16])
percent tensor([0.5824, 0.6326, 0.5234, 0.4727, 0.5141, 0.4900, 0.6005, 0.5332, 0.5742,
        0.6048, 0.6067, 0.5807, 0.6589, 0.5293, 0.5908, 0.5471],
       device='cuda:0') torch.Size([16])
percent tensor([0.6778, 0.7002, 0.6809, 0.6982, 0.6914, 0.6799, 0.6995, 0.6747, 0.6975,
        0.7039, 0.7380, 0.7133, 0.6946, 0.7149, 0.6982, 0.6963],
       device='cuda:0') torch.Size([16])
percent tensor([0.6676, 0.6189, 0.7146, 0.6471, 0.6768, 0.8034, 0.6676, 0.6384, 0.6764,
        0.6211, 0.6416, 0.6307, 0.6719, 0.6899, 0.6570, 0.7021],
       device='cuda:0') torch.Size([16])
percent tensor([0.5231, 0.6075, 0.5532, 0.5263, 0.5242, 0.5500, 0.5134, 0.4118, 0.6272,
        0.5710, 0.6382, 0.5621, 0.6258, 0.6608, 0.4419, 0.5412],
       device='cuda:0') torch.Size([16])
percent tensor([0.5896, 0.6381, 0.7764, 0.7748, 0.8304, 0.6889, 0.6566, 0.7008, 0.6491,
        0.6352, 0.6533, 0.7364, 0.6248, 0.7027, 0.6429, 0.6889],
       device='cuda:0') torch.Size([16])
percent tensor([0.9995, 0.9979, 0.9990, 0.9991, 0.9990, 0.9984, 0.9986, 0.9992, 0.9985,
        0.9989, 0.9991, 0.9990, 0.9989, 0.9986, 0.9989, 0.9994],
       device='cuda:0') torch.Size([16])
Epoch: 102 | Batch_idx: 0 |  Loss: (0.2097) |  Loss2: (0.0000) | Acc: (92.00%) (118/128)
Epoch: 102 | Batch_idx: 10 |  Loss: (0.1771) |  Loss2: (0.0000) | Acc: (94.00%) (1329/1408)
Epoch: 102 | Batch_idx: 20 |  Loss: (0.1892) |  Loss2: (0.0000) | Acc: (93.00%) (2520/2688)
Epoch: 102 | Batch_idx: 30 |  Loss: (0.2012) |  Loss2: (0.0000) | Acc: (93.00%) (3713/3968)
Epoch: 102 | Batch_idx: 40 |  Loss: (0.2102) |  Loss2: (0.0000) | Acc: (93.00%) (4881/5248)
Epoch: 102 | Batch_idx: 50 |  Loss: (0.2108) |  Loss2: (0.0000) | Acc: (92.00%) (6064/6528)
Epoch: 102 | Batch_idx: 60 |  Loss: (0.2081) |  Loss2: (0.0000) | Acc: (93.00%) (7267/7808)
Epoch: 102 | Batch_idx: 70 |  Loss: (0.2056) |  Loss2: (0.0000) | Acc: (93.00%) (8464/9088)
Epoch: 102 | Batch_idx: 80 |  Loss: (0.2053) |  Loss2: (0.0000) | Acc: (93.00%) (9662/10368)
Epoch: 102 | Batch_idx: 90 |  Loss: (0.2034) |  Loss2: (0.0000) | Acc: (93.00%) (10854/11648)
Epoch: 102 | Batch_idx: 100 |  Loss: (0.2050) |  Loss2: (0.0000) | Acc: (93.00%) (12037/12928)
Epoch: 102 | Batch_idx: 110 |  Loss: (0.2041) |  Loss2: (0.0000) | Acc: (93.00%) (13230/14208)
Epoch: 102 | Batch_idx: 120 |  Loss: (0.2031) |  Loss2: (0.0000) | Acc: (93.00%) (14422/15488)
Epoch: 102 | Batch_idx: 130 |  Loss: (0.2056) |  Loss2: (0.0000) | Acc: (93.00%) (15604/16768)
Epoch: 102 | Batch_idx: 140 |  Loss: (0.2057) |  Loss2: (0.0000) | Acc: (93.00%) (16794/18048)
Epoch: 102 | Batch_idx: 150 |  Loss: (0.2067) |  Loss2: (0.0000) | Acc: (92.00%) (17972/19328)
Epoch: 102 | Batch_idx: 160 |  Loss: (0.2070) |  Loss2: (0.0000) | Acc: (92.00%) (19159/20608)
Epoch: 102 | Batch_idx: 170 |  Loss: (0.2078) |  Loss2: (0.0000) | Acc: (92.00%) (20345/21888)
Epoch: 102 | Batch_idx: 180 |  Loss: (0.2062) |  Loss2: (0.0000) | Acc: (93.00%) (21548/23168)
Epoch: 102 | Batch_idx: 190 |  Loss: (0.2056) |  Loss2: (0.0000) | Acc: (93.00%) (22747/24448)
Epoch: 102 | Batch_idx: 200 |  Loss: (0.2060) |  Loss2: (0.0000) | Acc: (93.00%) (23938/25728)
Epoch: 102 | Batch_idx: 210 |  Loss: (0.2084) |  Loss2: (0.0000) | Acc: (92.00%) (25114/27008)
Epoch: 102 | Batch_idx: 220 |  Loss: (0.2087) |  Loss2: (0.0000) | Acc: (92.00%) (26303/28288)
Epoch: 102 | Batch_idx: 230 |  Loss: (0.2081) |  Loss2: (0.0000) | Acc: (92.00%) (27489/29568)
Epoch: 102 | Batch_idx: 240 |  Loss: (0.2083) |  Loss2: (0.0000) | Acc: (92.00%) (28676/30848)
Epoch: 102 | Batch_idx: 250 |  Loss: (0.2089) |  Loss2: (0.0000) | Acc: (92.00%) (29849/32128)
Epoch: 102 | Batch_idx: 260 |  Loss: (0.2089) |  Loss2: (0.0000) | Acc: (92.00%) (31035/33408)
Epoch: 102 | Batch_idx: 270 |  Loss: (0.2081) |  Loss2: (0.0000) | Acc: (92.00%) (32236/34688)
Epoch: 102 | Batch_idx: 280 |  Loss: (0.2080) |  Loss2: (0.0000) | Acc: (92.00%) (33422/35968)
Epoch: 102 | Batch_idx: 290 |  Loss: (0.2082) |  Loss2: (0.0000) | Acc: (92.00%) (34604/37248)
Epoch: 102 | Batch_idx: 300 |  Loss: (0.2084) |  Loss2: (0.0000) | Acc: (92.00%) (35785/38528)
Epoch: 102 | Batch_idx: 310 |  Loss: (0.2087) |  Loss2: (0.0000) | Acc: (92.00%) (36963/39808)
Epoch: 102 | Batch_idx: 320 |  Loss: (0.2091) |  Loss2: (0.0000) | Acc: (92.00%) (38139/41088)
Epoch: 102 | Batch_idx: 330 |  Loss: (0.2091) |  Loss2: (0.0000) | Acc: (92.00%) (39334/42368)
Epoch: 102 | Batch_idx: 340 |  Loss: (0.2098) |  Loss2: (0.0000) | Acc: (92.00%) (40511/43648)
Epoch: 102 | Batch_idx: 350 |  Loss: (0.2096) |  Loss2: (0.0000) | Acc: (92.00%) (41703/44928)
Epoch: 102 | Batch_idx: 360 |  Loss: (0.2092) |  Loss2: (0.0000) | Acc: (92.00%) (42900/46208)
Epoch: 102 | Batch_idx: 370 |  Loss: (0.2096) |  Loss2: (0.0000) | Acc: (92.00%) (44081/47488)
Epoch: 102 | Batch_idx: 380 |  Loss: (0.2093) |  Loss2: (0.0000) | Acc: (92.00%) (45269/48768)
Epoch: 102 | Batch_idx: 390 |  Loss: (0.2092) |  Loss2: (0.0000) | Acc: (92.00%) (46413/50000)
# TEST : Loss: (0.4037) | Acc: (86.00%) (8642/10000)
percent tensor([0.5356, 0.5228, 0.5591, 0.5513, 0.5554, 0.5370, 0.5351, 0.5477, 0.5422,
        0.5350, 0.5315, 0.5488, 0.5318, 0.5252, 0.5303, 0.5333],
       device='cuda:0') torch.Size([16])
percent tensor([0.5142, 0.5212, 0.5122, 0.5179, 0.5126, 0.5292, 0.5159, 0.5113, 0.5088,
        0.5133, 0.5125, 0.5083, 0.5091, 0.5248, 0.5202, 0.5198],
       device='cuda:0') torch.Size([16])
percent tensor([0.5768, 0.6285, 0.5172, 0.4631, 0.5184, 0.4882, 0.5979, 0.5368, 0.5642,
        0.6003, 0.5972, 0.5796, 0.6531, 0.5154, 0.5864, 0.5396],
       device='cuda:0') torch.Size([16])
percent tensor([0.6805, 0.7023, 0.6877, 0.7052, 0.6902, 0.6805, 0.7055, 0.6788, 0.7103,
        0.7109, 0.7448, 0.7207, 0.6997, 0.7238, 0.7002, 0.6990],
       device='cuda:0') torch.Size([16])
percent tensor([0.6515, 0.6239, 0.6841, 0.6122, 0.6594, 0.7884, 0.6510, 0.6146, 0.6608,
        0.6223, 0.6384, 0.6171, 0.6752, 0.6745, 0.6498, 0.6788],
       device='cuda:0') torch.Size([16])
percent tensor([0.5208, 0.6227, 0.5400, 0.5057, 0.5096, 0.5430, 0.5035, 0.4047, 0.6192,
        0.5688, 0.6342, 0.5853, 0.6385, 0.6577, 0.4395, 0.5249],
       device='cuda:0') torch.Size([16])
percent tensor([0.5925, 0.6163, 0.7604, 0.7848, 0.8357, 0.6798, 0.6411, 0.6797, 0.6682,
        0.6432, 0.6624, 0.7606, 0.6341, 0.7064, 0.6423, 0.6717],
       device='cuda:0') torch.Size([16])
percent tensor([0.9995, 0.9982, 0.9990, 0.9992, 0.9991, 0.9982, 0.9989, 0.9992, 0.9982,
        0.9988, 0.9990, 0.9988, 0.9988, 0.9980, 0.9988, 0.9992],
       device='cuda:0') torch.Size([16])
Epoch: 103 | Batch_idx: 0 |  Loss: (0.1972) |  Loss2: (0.0000) | Acc: (94.00%) (121/128)
Epoch: 103 | Batch_idx: 10 |  Loss: (0.2011) |  Loss2: (0.0000) | Acc: (93.00%) (1314/1408)
Epoch: 103 | Batch_idx: 20 |  Loss: (0.1988) |  Loss2: (0.0000) | Acc: (93.00%) (2513/2688)
Epoch: 103 | Batch_idx: 30 |  Loss: (0.2072) |  Loss2: (0.0000) | Acc: (93.00%) (3696/3968)
Epoch: 103 | Batch_idx: 40 |  Loss: (0.2071) |  Loss2: (0.0000) | Acc: (92.00%) (4877/5248)
Epoch: 103 | Batch_idx: 50 |  Loss: (0.2067) |  Loss2: (0.0000) | Acc: (93.00%) (6075/6528)
Epoch: 103 | Batch_idx: 60 |  Loss: (0.2021) |  Loss2: (0.0000) | Acc: (93.00%) (7275/7808)
Epoch: 103 | Batch_idx: 70 |  Loss: (0.1993) |  Loss2: (0.0000) | Acc: (93.00%) (8479/9088)
Epoch: 103 | Batch_idx: 80 |  Loss: (0.2003) |  Loss2: (0.0000) | Acc: (93.00%) (9666/10368)
Epoch: 103 | Batch_idx: 90 |  Loss: (0.1993) |  Loss2: (0.0000) | Acc: (93.00%) (10863/11648)
Epoch: 103 | Batch_idx: 100 |  Loss: (0.1982) |  Loss2: (0.0000) | Acc: (93.00%) (12063/12928)
Epoch: 103 | Batch_idx: 110 |  Loss: (0.1979) |  Loss2: (0.0000) | Acc: (93.00%) (13267/14208)
Epoch: 103 | Batch_idx: 120 |  Loss: (0.1984) |  Loss2: (0.0000) | Acc: (93.00%) (14455/15488)
Epoch: 103 | Batch_idx: 130 |  Loss: (0.1993) |  Loss2: (0.0000) | Acc: (93.00%) (15657/16768)
Epoch: 103 | Batch_idx: 140 |  Loss: (0.1983) |  Loss2: (0.0000) | Acc: (93.00%) (16855/18048)
Epoch: 103 | Batch_idx: 150 |  Loss: (0.1966) |  Loss2: (0.0000) | Acc: (93.00%) (18061/19328)
Epoch: 103 | Batch_idx: 160 |  Loss: (0.1975) |  Loss2: (0.0000) | Acc: (93.00%) (19253/20608)
Epoch: 103 | Batch_idx: 170 |  Loss: (0.1961) |  Loss2: (0.0000) | Acc: (93.00%) (20464/21888)
Epoch: 103 | Batch_idx: 180 |  Loss: (0.1955) |  Loss2: (0.0000) | Acc: (93.00%) (21661/23168)
Epoch: 103 | Batch_idx: 190 |  Loss: (0.1951) |  Loss2: (0.0000) | Acc: (93.00%) (22868/24448)
Epoch: 103 | Batch_idx: 200 |  Loss: (0.1944) |  Loss2: (0.0000) | Acc: (93.00%) (24065/25728)
Epoch: 103 | Batch_idx: 210 |  Loss: (0.1956) |  Loss2: (0.0000) | Acc: (93.00%) (25247/27008)
Epoch: 103 | Batch_idx: 220 |  Loss: (0.1964) |  Loss2: (0.0000) | Acc: (93.00%) (26430/28288)
Epoch: 103 | Batch_idx: 230 |  Loss: (0.1972) |  Loss2: (0.0000) | Acc: (93.00%) (27618/29568)
Epoch: 103 | Batch_idx: 240 |  Loss: (0.1984) |  Loss2: (0.0000) | Acc: (93.00%) (28789/30848)
Epoch: 103 | Batch_idx: 250 |  Loss: (0.1984) |  Loss2: (0.0000) | Acc: (93.00%) (29988/32128)
Epoch: 103 | Batch_idx: 260 |  Loss: (0.1990) |  Loss2: (0.0000) | Acc: (93.00%) (31170/33408)
Epoch: 103 | Batch_idx: 270 |  Loss: (0.1990) |  Loss2: (0.0000) | Acc: (93.00%) (32373/34688)
Epoch: 103 | Batch_idx: 280 |  Loss: (0.1987) |  Loss2: (0.0000) | Acc: (93.00%) (33573/35968)
Epoch: 103 | Batch_idx: 290 |  Loss: (0.1994) |  Loss2: (0.0000) | Acc: (93.00%) (34747/37248)
Epoch: 103 | Batch_idx: 300 |  Loss: (0.1995) |  Loss2: (0.0000) | Acc: (93.00%) (35944/38528)
Epoch: 103 | Batch_idx: 310 |  Loss: (0.1996) |  Loss2: (0.0000) | Acc: (93.00%) (37133/39808)
Epoch: 103 | Batch_idx: 320 |  Loss: (0.2002) |  Loss2: (0.0000) | Acc: (93.00%) (38312/41088)
Epoch: 103 | Batch_idx: 330 |  Loss: (0.2008) |  Loss2: (0.0000) | Acc: (93.00%) (39490/42368)
Epoch: 103 | Batch_idx: 340 |  Loss: (0.2008) |  Loss2: (0.0000) | Acc: (93.00%) (40682/43648)
Epoch: 103 | Batch_idx: 350 |  Loss: (0.2009) |  Loss2: (0.0000) | Acc: (93.00%) (41871/44928)
Epoch: 103 | Batch_idx: 360 |  Loss: (0.2009) |  Loss2: (0.0000) | Acc: (93.00%) (43066/46208)
Epoch: 103 | Batch_idx: 370 |  Loss: (0.2011) |  Loss2: (0.0000) | Acc: (93.00%) (44254/47488)
Epoch: 103 | Batch_idx: 380 |  Loss: (0.2021) |  Loss2: (0.0000) | Acc: (93.00%) (45429/48768)
Epoch: 103 | Batch_idx: 390 |  Loss: (0.2027) |  Loss2: (0.0000) | Acc: (93.00%) (46553/50000)
# TEST : Loss: (0.4327) | Acc: (86.00%) (8627/10000)
percent tensor([0.5356, 0.5242, 0.5545, 0.5500, 0.5516, 0.5363, 0.5344, 0.5474, 0.5413,
        0.5347, 0.5325, 0.5455, 0.5321, 0.5269, 0.5311, 0.5336],
       device='cuda:0') torch.Size([16])
percent tensor([0.5149, 0.5210, 0.5134, 0.5188, 0.5145, 0.5306, 0.5162, 0.5130, 0.5107,
        0.5135, 0.5130, 0.5099, 0.5094, 0.5259, 0.5205, 0.5205],
       device='cuda:0') torch.Size([16])
percent tensor([0.5731, 0.6236, 0.5206, 0.4581, 0.5110, 0.4784, 0.5909, 0.5314, 0.5653,
        0.5982, 0.5981, 0.5743, 0.6564, 0.4965, 0.5771, 0.5320],
       device='cuda:0') torch.Size([16])
percent tensor([0.6763, 0.6923, 0.6847, 0.7020, 0.6891, 0.6812, 0.7010, 0.6778, 0.6967,
        0.6994, 0.7315, 0.7137, 0.6829, 0.7215, 0.6966, 0.6964],
       device='cuda:0') torch.Size([16])
percent tensor([0.6488, 0.5885, 0.6866, 0.6335, 0.6632, 0.7951, 0.6379, 0.5959, 0.6684,
        0.6106, 0.6332, 0.6150, 0.6707, 0.6637, 0.6266, 0.6866],
       device='cuda:0') torch.Size([16])
percent tensor([0.5131, 0.5921, 0.5255, 0.4915, 0.4952, 0.5519, 0.5148, 0.3889, 0.6004,
        0.5490, 0.6214, 0.5525, 0.6178, 0.6435, 0.4206, 0.5180],
       device='cuda:0') torch.Size([16])
percent tensor([0.6050, 0.6186, 0.7686, 0.7696, 0.8392, 0.6964, 0.6774, 0.7069, 0.6753,
        0.6259, 0.6326, 0.7438, 0.6385, 0.7221, 0.6556, 0.6722],
       device='cuda:0') torch.Size([16])
percent tensor([0.9996, 0.9985, 0.9993, 0.9991, 0.9993, 0.9988, 0.9990, 0.9993, 0.9986,
        0.9990, 0.9986, 0.9991, 0.9990, 0.9989, 0.9990, 0.9994],
       device='cuda:0') torch.Size([16])
Epoch: 104 | Batch_idx: 0 |  Loss: (0.2611) |  Loss2: (0.0000) | Acc: (90.00%) (116/128)
Epoch: 104 | Batch_idx: 10 |  Loss: (0.1924) |  Loss2: (0.0000) | Acc: (93.00%) (1312/1408)
Epoch: 104 | Batch_idx: 20 |  Loss: (0.1981) |  Loss2: (0.0000) | Acc: (93.00%) (2504/2688)
Epoch: 104 | Batch_idx: 30 |  Loss: (0.2015) |  Loss2: (0.0000) | Acc: (93.00%) (3696/3968)
Epoch: 104 | Batch_idx: 40 |  Loss: (0.2017) |  Loss2: (0.0000) | Acc: (93.00%) (4893/5248)
Epoch: 104 | Batch_idx: 50 |  Loss: (0.1989) |  Loss2: (0.0000) | Acc: (93.00%) (6089/6528)
Epoch: 104 | Batch_idx: 60 |  Loss: (0.1950) |  Loss2: (0.0000) | Acc: (93.00%) (7296/7808)
Epoch: 104 | Batch_idx: 70 |  Loss: (0.1940) |  Loss2: (0.0000) | Acc: (93.00%) (8490/9088)
Epoch: 104 | Batch_idx: 80 |  Loss: (0.1918) |  Loss2: (0.0000) | Acc: (93.00%) (9700/10368)
Epoch: 104 | Batch_idx: 90 |  Loss: (0.1926) |  Loss2: (0.0000) | Acc: (93.00%) (10887/11648)
Epoch: 104 | Batch_idx: 100 |  Loss: (0.1944) |  Loss2: (0.0000) | Acc: (93.00%) (12070/12928)
Epoch: 104 | Batch_idx: 110 |  Loss: (0.1935) |  Loss2: (0.0000) | Acc: (93.00%) (13269/14208)
Epoch: 104 | Batch_idx: 120 |  Loss: (0.1941) |  Loss2: (0.0000) | Acc: (93.00%) (14454/15488)
Epoch: 104 | Batch_idx: 130 |  Loss: (0.1933) |  Loss2: (0.0000) | Acc: (93.00%) (15651/16768)
Epoch: 104 | Batch_idx: 140 |  Loss: (0.1949) |  Loss2: (0.0000) | Acc: (93.00%) (16817/18048)
Epoch: 104 | Batch_idx: 150 |  Loss: (0.1965) |  Loss2: (0.0000) | Acc: (93.00%) (18007/19328)
Epoch: 104 | Batch_idx: 160 |  Loss: (0.1971) |  Loss2: (0.0000) | Acc: (93.00%) (19197/20608)
Epoch: 104 | Batch_idx: 170 |  Loss: (0.1972) |  Loss2: (0.0000) | Acc: (93.00%) (20385/21888)
Epoch: 104 | Batch_idx: 180 |  Loss: (0.1992) |  Loss2: (0.0000) | Acc: (93.00%) (21559/23168)
Epoch: 104 | Batch_idx: 190 |  Loss: (0.1979) |  Loss2: (0.0000) | Acc: (93.00%) (22765/24448)
Epoch: 104 | Batch_idx: 200 |  Loss: (0.1969) |  Loss2: (0.0000) | Acc: (93.00%) (23970/25728)
Epoch: 104 | Batch_idx: 210 |  Loss: (0.1980) |  Loss2: (0.0000) | Acc: (93.00%) (25152/27008)
Epoch: 104 | Batch_idx: 220 |  Loss: (0.1975) |  Loss2: (0.0000) | Acc: (93.00%) (26351/28288)
Epoch: 104 | Batch_idx: 230 |  Loss: (0.1970) |  Loss2: (0.0000) | Acc: (93.00%) (27543/29568)
Epoch: 104 | Batch_idx: 240 |  Loss: (0.1966) |  Loss2: (0.0000) | Acc: (93.00%) (28745/30848)
Epoch: 104 | Batch_idx: 250 |  Loss: (0.1962) |  Loss2: (0.0000) | Acc: (93.00%) (29940/32128)
Epoch: 104 | Batch_idx: 260 |  Loss: (0.1959) |  Loss2: (0.0000) | Acc: (93.00%) (31131/33408)
Epoch: 104 | Batch_idx: 270 |  Loss: (0.1968) |  Loss2: (0.0000) | Acc: (93.00%) (32307/34688)
Epoch: 104 | Batch_idx: 280 |  Loss: (0.1967) |  Loss2: (0.0000) | Acc: (93.00%) (33497/35968)
Epoch: 104 | Batch_idx: 290 |  Loss: (0.1969) |  Loss2: (0.0000) | Acc: (93.00%) (34686/37248)
Epoch: 104 | Batch_idx: 300 |  Loss: (0.1968) |  Loss2: (0.0000) | Acc: (93.00%) (35877/38528)
Epoch: 104 | Batch_idx: 310 |  Loss: (0.1968) |  Loss2: (0.0000) | Acc: (93.00%) (37064/39808)
Epoch: 104 | Batch_idx: 320 |  Loss: (0.1964) |  Loss2: (0.0000) | Acc: (93.00%) (38266/41088)
Epoch: 104 | Batch_idx: 330 |  Loss: (0.1962) |  Loss2: (0.0000) | Acc: (93.00%) (39463/42368)
Epoch: 104 | Batch_idx: 340 |  Loss: (0.1968) |  Loss2: (0.0000) | Acc: (93.00%) (40644/43648)
Epoch: 104 | Batch_idx: 350 |  Loss: (0.1965) |  Loss2: (0.0000) | Acc: (93.00%) (41842/44928)
Epoch: 104 | Batch_idx: 360 |  Loss: (0.1963) |  Loss2: (0.0000) | Acc: (93.00%) (43033/46208)
Epoch: 104 | Batch_idx: 370 |  Loss: (0.1965) |  Loss2: (0.0000) | Acc: (93.00%) (44223/47488)
Epoch: 104 | Batch_idx: 380 |  Loss: (0.1975) |  Loss2: (0.0000) | Acc: (93.00%) (45393/48768)
Epoch: 104 | Batch_idx: 390 |  Loss: (0.1968) |  Loss2: (0.0000) | Acc: (93.00%) (46547/50000)
# TEST : Loss: (0.4327) | Acc: (86.00%) (8618/10000)
percent tensor([0.5351, 0.5249, 0.5558, 0.5510, 0.5528, 0.5362, 0.5350, 0.5476, 0.5420,
        0.5344, 0.5320, 0.5459, 0.5314, 0.5289, 0.5313, 0.5338],
       device='cuda:0') torch.Size([16])
percent tensor([0.5140, 0.5205, 0.5117, 0.5165, 0.5131, 0.5291, 0.5157, 0.5108, 0.5100,
        0.5127, 0.5122, 0.5087, 0.5088, 0.5252, 0.5196, 0.5191],
       device='cuda:0') torch.Size([16])
percent tensor([0.5819, 0.6274, 0.5312, 0.4718, 0.5215, 0.4896, 0.5971, 0.5397, 0.5704,
        0.6057, 0.6081, 0.5849, 0.6606, 0.5024, 0.5883, 0.5410],
       device='cuda:0') torch.Size([16])
percent tensor([0.6776, 0.6989, 0.6794, 0.6944, 0.6871, 0.6717, 0.7061, 0.6748, 0.7024,
        0.7086, 0.7363, 0.7179, 0.6949, 0.7227, 0.6940, 0.6926],
       device='cuda:0') torch.Size([16])
percent tensor([0.6354, 0.5877, 0.6810, 0.6388, 0.6702, 0.8047, 0.6451, 0.6034, 0.6602,
        0.5984, 0.6179, 0.5929, 0.6485, 0.6684, 0.6272, 0.6817],
       device='cuda:0') torch.Size([16])
percent tensor([0.5068, 0.5818, 0.5135, 0.4844, 0.4842, 0.5281, 0.4942, 0.3968, 0.5971,
        0.5125, 0.6061, 0.5390, 0.5964, 0.6256, 0.4214, 0.4881],
       device='cuda:0') torch.Size([16])
percent tensor([0.6063, 0.6092, 0.7592, 0.7648, 0.8129, 0.6635, 0.6775, 0.6990, 0.6605,
        0.6096, 0.6372, 0.7575, 0.6309, 0.6986, 0.6418, 0.6533],
       device='cuda:0') torch.Size([16])
percent tensor([0.9996, 0.9981, 0.9994, 0.9992, 0.9990, 0.9985, 0.9990, 0.9993, 0.9985,
        0.9986, 0.9988, 0.9993, 0.9987, 0.9988, 0.9988, 0.9994],
       device='cuda:0') torch.Size([16])
False Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=128, out_features=16, bias=False)
True Linear(in_features=16, out_features=2, bias=False)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=128, out_features=16, bias=False)
True Linear(in_features=16, out_features=2, bias=False)
False Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=256, out_features=32, bias=False)
True Linear(in_features=32, out_features=2, bias=False)
False Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=256, out_features=32, bias=False)
True Linear(in_features=32, out_features=2, bias=False)
False Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=512, out_features=64, bias=False)
True Linear(in_features=64, out_features=2, bias=False)
False Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=512, out_features=64, bias=False)
True Linear(in_features=64, out_features=2, bias=False)
False Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1024, out_features=128, bias=False)
True Linear(in_features=128, out_features=2, bias=False)
False Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1024, out_features=128, bias=False)
True Linear(in_features=128, out_features=2, bias=False)
False Linear(in_features=512, out_features=10, bias=True)
Epoch: 105 | Batch_idx: 0 |  Loss: (0.2173) |  Loss2: (0.0000) | Acc: (92.00%) (119/128)
Epoch: 105 | Batch_idx: 10 |  Loss: (0.2485) |  Loss2: (0.0000) | Acc: (91.00%) (1294/1408)
Epoch: 105 | Batch_idx: 20 |  Loss: (0.2465) |  Loss2: (0.0000) | Acc: (91.00%) (2457/2688)
Epoch: 105 | Batch_idx: 30 |  Loss: (0.2561) |  Loss2: (0.0000) | Acc: (91.00%) (3611/3968)
Epoch: 105 | Batch_idx: 40 |  Loss: (0.2608) |  Loss2: (0.0000) | Acc: (90.00%) (4765/5248)
Epoch: 105 | Batch_idx: 50 |  Loss: (0.2632) |  Loss2: (0.0000) | Acc: (90.00%) (5913/6528)
Epoch: 105 | Batch_idx: 60 |  Loss: (0.2691) |  Loss2: (0.0000) | Acc: (90.00%) (7056/7808)
Epoch: 105 | Batch_idx: 70 |  Loss: (0.2674) |  Loss2: (0.0000) | Acc: (90.00%) (8224/9088)
Epoch: 105 | Batch_idx: 80 |  Loss: (0.2685) |  Loss2: (0.0000) | Acc: (90.00%) (9378/10368)
Epoch: 105 | Batch_idx: 90 |  Loss: (0.2665) |  Loss2: (0.0000) | Acc: (90.00%) (10541/11648)
Epoch: 105 | Batch_idx: 100 |  Loss: (0.2658) |  Loss2: (0.0000) | Acc: (90.00%) (11701/12928)
Epoch: 105 | Batch_idx: 110 |  Loss: (0.2646) |  Loss2: (0.0000) | Acc: (90.00%) (12868/14208)
Epoch: 105 | Batch_idx: 120 |  Loss: (0.2664) |  Loss2: (0.0000) | Acc: (90.00%) (14011/15488)
Epoch: 105 | Batch_idx: 130 |  Loss: (0.2627) |  Loss2: (0.0000) | Acc: (90.00%) (15194/16768)
Epoch: 105 | Batch_idx: 140 |  Loss: (0.2626) |  Loss2: (0.0000) | Acc: (90.00%) (16350/18048)
Epoch: 105 | Batch_idx: 150 |  Loss: (0.2620) |  Loss2: (0.0000) | Acc: (90.00%) (17517/19328)
Epoch: 105 | Batch_idx: 160 |  Loss: (0.2603) |  Loss2: (0.0000) | Acc: (90.00%) (18690/20608)
Epoch: 105 | Batch_idx: 170 |  Loss: (0.2576) |  Loss2: (0.0000) | Acc: (90.00%) (19877/21888)
Epoch: 105 | Batch_idx: 180 |  Loss: (0.2565) |  Loss2: (0.0000) | Acc: (90.00%) (21054/23168)
Epoch: 105 | Batch_idx: 190 |  Loss: (0.2544) |  Loss2: (0.0000) | Acc: (90.00%) (22236/24448)
Epoch: 105 | Batch_idx: 200 |  Loss: (0.2528) |  Loss2: (0.0000) | Acc: (91.00%) (23418/25728)
Epoch: 105 | Batch_idx: 210 |  Loss: (0.2510) |  Loss2: (0.0000) | Acc: (91.00%) (24607/27008)
Epoch: 105 | Batch_idx: 220 |  Loss: (0.2501) |  Loss2: (0.0000) | Acc: (91.00%) (25790/28288)
Epoch: 105 | Batch_idx: 230 |  Loss: (0.2488) |  Loss2: (0.0000) | Acc: (91.00%) (26973/29568)
Epoch: 105 | Batch_idx: 240 |  Loss: (0.2484) |  Loss2: (0.0000) | Acc: (91.00%) (28147/30848)
Epoch: 105 | Batch_idx: 250 |  Loss: (0.2468) |  Loss2: (0.0000) | Acc: (91.00%) (29339/32128)
Epoch: 105 | Batch_idx: 260 |  Loss: (0.2460) |  Loss2: (0.0000) | Acc: (91.00%) (30517/33408)
Epoch: 105 | Batch_idx: 270 |  Loss: (0.2454) |  Loss2: (0.0000) | Acc: (91.00%) (31692/34688)
Epoch: 105 | Batch_idx: 280 |  Loss: (0.2440) |  Loss2: (0.0000) | Acc: (91.00%) (32888/35968)
Epoch: 105 | Batch_idx: 290 |  Loss: (0.2440) |  Loss2: (0.0000) | Acc: (91.00%) (34053/37248)
Epoch: 105 | Batch_idx: 300 |  Loss: (0.2424) |  Loss2: (0.0000) | Acc: (91.00%) (35250/38528)
Epoch: 105 | Batch_idx: 310 |  Loss: (0.2419) |  Loss2: (0.0000) | Acc: (91.00%) (36421/39808)
Epoch: 105 | Batch_idx: 320 |  Loss: (0.2419) |  Loss2: (0.0000) | Acc: (91.00%) (37592/41088)
Epoch: 105 | Batch_idx: 330 |  Loss: (0.2413) |  Loss2: (0.0000) | Acc: (91.00%) (38774/42368)
Epoch: 105 | Batch_idx: 340 |  Loss: (0.2401) |  Loss2: (0.0000) | Acc: (91.00%) (39965/43648)
Epoch: 105 | Batch_idx: 350 |  Loss: (0.2397) |  Loss2: (0.0000) | Acc: (91.00%) (41145/44928)
Epoch: 105 | Batch_idx: 360 |  Loss: (0.2385) |  Loss2: (0.0000) | Acc: (91.00%) (42337/46208)
Epoch: 105 | Batch_idx: 370 |  Loss: (0.2385) |  Loss2: (0.0000) | Acc: (91.00%) (43505/47488)
Epoch: 105 | Batch_idx: 380 |  Loss: (0.2383) |  Loss2: (0.0000) | Acc: (91.00%) (44683/48768)
Epoch: 105 | Batch_idx: 390 |  Loss: (0.2389) |  Loss2: (0.0000) | Acc: (91.00%) (45807/50000)
=> saving checkpoint 'drive/app/torch/save_Routing_Gate_2/checkpoint_105.pth.tar'
# TEST : Loss: (0.4050) | Acc: (86.00%) (8692/10000)
percent tensor([0.5522, 0.5415, 0.5733, 0.5690, 0.5720, 0.5527, 0.5532, 0.5673, 0.5602,
        0.5516, 0.5484, 0.5632, 0.5479, 0.5458, 0.5480, 0.5506],
       device='cuda:0') torch.Size([16])
percent tensor([0.5073, 0.5117, 0.5044, 0.5107, 0.5051, 0.5233, 0.5073, 0.5036, 0.5016,
        0.5041, 0.5038, 0.5004, 0.5007, 0.5181, 0.5122, 0.5122],
       device='cuda:0') torch.Size([16])
percent tensor([0.5966, 0.6506, 0.5470, 0.4640, 0.5322, 0.4867, 0.6204, 0.5391, 0.5804,
        0.6294, 0.6299, 0.6105, 0.6907, 0.5052, 0.6015, 0.5490],
       device='cuda:0') torch.Size([16])
percent tensor([0.6755, 0.6874, 0.6802, 0.6993, 0.6921, 0.6727, 0.7030, 0.6837, 0.7000,
        0.6962, 0.7250, 0.7088, 0.6789, 0.7184, 0.6896, 0.6872],
       device='cuda:0') torch.Size([16])
percent tensor([0.6657, 0.6296, 0.7049, 0.6257, 0.6674, 0.8255, 0.6659, 0.6041, 0.6796,
        0.6395, 0.6611, 0.5962, 0.6692, 0.6920, 0.6564, 0.7115],
       device='cuda:0') torch.Size([16])
percent tensor([0.5695, 0.6467, 0.5465, 0.5089, 0.4892, 0.5780, 0.5418, 0.3863, 0.6580,
        0.5838, 0.6852, 0.5696, 0.6706, 0.6919, 0.4683, 0.5521],
       device='cuda:0') torch.Size([16])
percent tensor([0.5677, 0.5657, 0.7107, 0.7427, 0.7875, 0.6379, 0.6468, 0.6723, 0.6331,
        0.5853, 0.6043, 0.7087, 0.5847, 0.6870, 0.6000, 0.6296],
       device='cuda:0') torch.Size([16])
percent tensor([0.9995, 0.9978, 0.9993, 0.9991, 0.9988, 0.9987, 0.9989, 0.9993, 0.9987,
        0.9987, 0.9989, 0.9989, 0.9989, 0.9988, 0.9987, 0.9993],
       device='cuda:0') torch.Size([16])





Files already downloaded and verified
USE 1 GPUs!
=> loading checkpoint 'drive/app/torch/save_Routing_Gate_2/checkpoint_105.pth.tar'

Epoch: 106 | Batch_idx: 0 |  Loss: (0.2266) |  Loss2: (0.0000) | Acc: (92.00%) (118/128)
Epoch: 106 | Batch_idx: 10 |  Loss: (0.2052) |  Loss2: (0.0000) | Acc: (93.00%) (1314/1408)
Epoch: 106 | Batch_idx: 20 |  Loss: (0.2168) |  Loss2: (0.0000) | Acc: (92.00%) (2492/2688)
Epoch: 106 | Batch_idx: 30 |  Loss: (0.2227) |  Loss2: (0.0000) | Acc: (92.00%) (3661/3968)
Epoch: 106 | Batch_idx: 40 |  Loss: (0.2271) |  Loss2: (0.0000) | Acc: (92.00%) (4841/5248)
Epoch: 106 | Batch_idx: 50 |  Loss: (0.2243) |  Loss2: (0.0000) | Acc: (92.00%) (6026/6528)
Epoch: 106 | Batch_idx: 60 |  Loss: (0.2223) |  Loss2: (0.0000) | Acc: (92.00%) (7211/7808)
Epoch: 106 | Batch_idx: 70 |  Loss: (0.2189) |  Loss2: (0.0000) | Acc: (92.00%) (8399/9088)
Epoch: 106 | Batch_idx: 80 |  Loss: (0.2209) |  Loss2: (0.0000) | Acc: (92.00%) (9579/10368)
Epoch: 106 | Batch_idx: 90 |  Loss: (0.2196) |  Loss2: (0.0000) | Acc: (92.00%) (10765/11648)
Epoch: 106 | Batch_idx: 100 |  Loss: (0.2174) |  Loss2: (0.0000) | Acc: (92.00%) (11946/12928)
Epoch: 106 | Batch_idx: 110 |  Loss: (0.2187) |  Loss2: (0.0000) | Acc: (92.00%) (13122/14208)
Epoch: 106 | Batch_idx: 120 |  Loss: (0.2171) |  Loss2: (0.0000) | Acc: (92.00%) (14308/15488)
Epoch: 106 | Batch_idx: 130 |  Loss: (0.2181) |  Loss2: (0.0000) | Acc: (92.00%) (15491/16768)
Epoch: 106 | Batch_idx: 140 |  Loss: (0.2177) |  Loss2: (0.0000) | Acc: (92.00%) (16679/18048)
Epoch: 106 | Batch_idx: 150 |  Loss: (0.2172) |  Loss2: (0.0000) | Acc: (92.00%) (17867/19328)
Epoch: 106 | Batch_idx: 160 |  Loss: (0.2175) |  Loss2: (0.0000) | Acc: (92.00%) (19048/20608)
Epoch: 106 | Batch_idx: 170 |  Loss: (0.2166) |  Loss2: (0.0000) | Acc: (92.00%) (20235/21888)
Epoch: 106 | Batch_idx: 180 |  Loss: (0.2164) |  Loss2: (0.0000) | Acc: (92.00%) (21414/23168)
Epoch: 106 | Batch_idx: 190 |  Loss: (0.2158) |  Loss2: (0.0000) | Acc: (92.00%) (22604/24448)
Epoch: 106 | Batch_idx: 200 |  Loss: (0.2157) |  Loss2: (0.0000) | Acc: (92.00%) (23792/25728)
Epoch: 106 | Batch_idx: 210 |  Loss: (0.2154) |  Loss2: (0.0000) | Acc: (92.00%) (24977/27008)
Epoch: 106 | Batch_idx: 220 |  Loss: (0.2151) |  Loss2: (0.0000) | Acc: (92.00%) (26162/28288)
Epoch: 106 | Batch_idx: 230 |  Loss: (0.2156) |  Loss2: (0.0000) | Acc: (92.00%) (27341/29568)
Epoch: 106 | Batch_idx: 240 |  Loss: (0.2166) |  Loss2: (0.0000) | Acc: (92.00%) (28507/30848)
Epoch: 106 | Batch_idx: 250 |  Loss: (0.2162) |  Loss2: (0.0000) | Acc: (92.00%) (29690/32128)
Epoch: 106 | Batch_idx: 260 |  Loss: (0.2158) |  Loss2: (0.0000) | Acc: (92.00%) (30868/33408)
Epoch: 106 | Batch_idx: 270 |  Loss: (0.2149) |  Loss2: (0.0000) | Acc: (92.00%) (32070/34688)
Epoch: 106 | Batch_idx: 280 |  Loss: (0.2152) |  Loss2: (0.0000) | Acc: (92.00%) (33251/35968)
Epoch: 106 | Batch_idx: 290 |  Loss: (0.2150) |  Loss2: (0.0000) | Acc: (92.00%) (34432/37248)
Epoch: 106 | Batch_idx: 300 |  Loss: (0.2145) |  Loss2: (0.0000) | Acc: (92.00%) (35634/38528)
Epoch: 106 | Batch_idx: 310 |  Loss: (0.2149) |  Loss2: (0.0000) | Acc: (92.00%) (36812/39808)
Epoch: 106 | Batch_idx: 320 |  Loss: (0.2144) |  Loss2: (0.0000) | Acc: (92.00%) (38008/41088)
Epoch: 106 | Batch_idx: 330 |  Loss: (0.2142) |  Loss2: (0.0000) | Acc: (92.00%) (39198/42368)
Epoch: 106 | Batch_idx: 340 |  Loss: (0.2138) |  Loss2: (0.0000) | Acc: (92.00%) (40392/43648)
Epoch: 106 | Batch_idx: 350 |  Loss: (0.2134) |  Loss2: (0.0000) | Acc: (92.00%) (41591/44928)
Epoch: 106 | Batch_idx: 360 |  Loss: (0.2126) |  Loss2: (0.0000) | Acc: (92.00%) (42786/46208)
Epoch: 106 | Batch_idx: 370 |  Loss: (0.2122) |  Loss2: (0.0000) | Acc: (92.00%) (43981/47488)
Epoch: 106 | Batch_idx: 380 |  Loss: (0.2114) |  Loss2: (0.0000) | Acc: (92.00%) (45180/48768)
Epoch: 106 | Batch_idx: 390 |  Loss: (0.2108) |  Loss2: (0.0000) | Acc: (92.00%) (46326/50000)
# TEST : Loss: (0.3818) | Acc: (87.00%) (8745/10000)
percent tensor([0.5534, 0.5407, 0.5758, 0.5709, 0.5742, 0.5534, 0.5534, 0.5690, 0.5617,
        0.5520, 0.5487, 0.5648, 0.5485, 0.5456, 0.5479, 0.5512],
       device='cuda:0') torch.Size([16])
percent tensor([0.5078, 0.5119, 0.5049, 0.5118, 0.5058, 0.5242, 0.5077, 0.5047, 0.5018,
        0.5042, 0.5037, 0.5006, 0.5005, 0.5187, 0.5128, 0.5127],
       device='cuda:0') torch.Size([16])
percent tensor([0.5929, 0.6533, 0.5444, 0.4642, 0.5306, 0.4847, 0.6210, 0.5365, 0.5797,
        0.6329, 0.6309, 0.6125, 0.6930, 0.5084, 0.5996, 0.5510],
       device='cuda:0') torch.Size([16])
percent tensor([0.6713, 0.6784, 0.6803, 0.6997, 0.6945, 0.6714, 0.6987, 0.6861, 0.6949,
        0.6879, 0.7147, 0.7032, 0.6686, 0.7115, 0.6864, 0.6817],
       device='cuda:0') torch.Size([16])
percent tensor([0.6722, 0.6387, 0.7101, 0.6323, 0.6712, 0.8303, 0.6700, 0.6037, 0.6885,
        0.6521, 0.6804, 0.6003, 0.6782, 0.7016, 0.6613, 0.7180],
       device='cuda:0') torch.Size([16])
percent tensor([0.5704, 0.6624, 0.5332, 0.4921, 0.4703, 0.5822, 0.5382, 0.3605, 0.6633,
        0.6012, 0.7009, 0.5669, 0.6864, 0.7067, 0.4633, 0.5593],
       device='cuda:0') torch.Size([16])
percent tensor([0.5671, 0.5688, 0.7191, 0.7505, 0.7969, 0.6473, 0.6502, 0.6852, 0.6324,
        0.5977, 0.6024, 0.7108, 0.5879, 0.6925, 0.6037, 0.6344],
       device='cuda:0') torch.Size([16])
percent tensor([0.9995, 0.9978, 0.9993, 0.9991, 0.9988, 0.9986, 0.9989, 0.9992, 0.9987,
        0.9987, 0.9989, 0.9989, 0.9988, 0.9988, 0.9987, 0.9993],
       device='cuda:0') torch.Size([16])
Epoch: 107 | Batch_idx: 0 |  Loss: (0.2751) |  Loss2: (0.0000) | Acc: (89.00%) (115/128)
Epoch: 107 | Batch_idx: 10 |  Loss: (0.1976) |  Loss2: (0.0000) | Acc: (92.00%) (1306/1408)
Epoch: 107 | Batch_idx: 20 |  Loss: (0.1871) |  Loss2: (0.0000) | Acc: (93.00%) (2508/2688)
Epoch: 107 | Batch_idx: 30 |  Loss: (0.1974) |  Loss2: (0.0000) | Acc: (93.00%) (3692/3968)
Epoch: 107 | Batch_idx: 40 |  Loss: (0.2018) |  Loss2: (0.0000) | Acc: (92.00%) (4874/5248)
Epoch: 107 | Batch_idx: 50 |  Loss: (0.1996) |  Loss2: (0.0000) | Acc: (92.00%) (6067/6528)
Epoch: 107 | Batch_idx: 60 |  Loss: (0.2020) |  Loss2: (0.0000) | Acc: (92.00%) (7250/7808)
Epoch: 107 | Batch_idx: 70 |  Loss: (0.2013) |  Loss2: (0.0000) | Acc: (92.00%) (8450/9088)
Epoch: 107 | Batch_idx: 80 |  Loss: (0.2026) |  Loss2: (0.0000) | Acc: (92.00%) (9629/10368)
Epoch: 107 | Batch_idx: 90 |  Loss: (0.1990) |  Loss2: (0.0000) | Acc: (93.00%) (10841/11648)
Epoch: 107 | Batch_idx: 100 |  Loss: (0.1982) |  Loss2: (0.0000) | Acc: (93.00%) (12029/12928)
Epoch: 107 | Batch_idx: 110 |  Loss: (0.2005) |  Loss2: (0.0000) | Acc: (92.00%) (13212/14208)
Epoch: 107 | Batch_idx: 120 |  Loss: (0.1991) |  Loss2: (0.0000) | Acc: (93.00%) (14407/15488)
Epoch: 107 | Batch_idx: 130 |  Loss: (0.1988) |  Loss2: (0.0000) | Acc: (93.00%) (15601/16768)
Epoch: 107 | Batch_idx: 140 |  Loss: (0.1988) |  Loss2: (0.0000) | Acc: (93.00%) (16795/18048)
Epoch: 107 | Batch_idx: 150 |  Loss: (0.2006) |  Loss2: (0.0000) | Acc: (93.00%) (17978/19328)
Epoch: 107 | Batch_idx: 160 |  Loss: (0.2009) |  Loss2: (0.0000) | Acc: (93.00%) (19170/20608)
Epoch: 107 | Batch_idx: 170 |  Loss: (0.1997) |  Loss2: (0.0000) | Acc: (93.00%) (20370/21888)
Epoch: 107 | Batch_idx: 180 |  Loss: (0.1988) |  Loss2: (0.0000) | Acc: (93.00%) (21569/23168)
Epoch: 107 | Batch_idx: 190 |  Loss: (0.1993) |  Loss2: (0.0000) | Acc: (93.00%) (22758/24448)
Epoch: 107 | Batch_idx: 200 |  Loss: (0.1993) |  Loss2: (0.0000) | Acc: (93.00%) (23947/25728)
Epoch: 107 | Batch_idx: 210 |  Loss: (0.2002) |  Loss2: (0.0000) | Acc: (93.00%) (25133/27008)
Epoch: 107 | Batch_idx: 220 |  Loss: (0.1994) |  Loss2: (0.0000) | Acc: (93.00%) (26333/28288)
Epoch: 107 | Batch_idx: 230 |  Loss: (0.2005) |  Loss2: (0.0000) | Acc: (93.00%) (27514/29568)
Epoch: 107 | Batch_idx: 240 |  Loss: (0.1998) |  Loss2: (0.0000) | Acc: (93.00%) (28712/30848)
Epoch: 107 | Batch_idx: 250 |  Loss: (0.1997) |  Loss2: (0.0000) | Acc: (93.00%) (29906/32128)
Epoch: 107 | Batch_idx: 260 |  Loss: (0.1996) |  Loss2: (0.0000) | Acc: (93.00%) (31096/33408)
Epoch: 107 | Batch_idx: 270 |  Loss: (0.2000) |  Loss2: (0.0000) | Acc: (93.00%) (32293/34688)
Epoch: 107 | Batch_idx: 280 |  Loss: (0.1990) |  Loss2: (0.0000) | Acc: (93.00%) (33498/35968)
Epoch: 107 | Batch_idx: 290 |  Loss: (0.1984) |  Loss2: (0.0000) | Acc: (93.00%) (34696/37248)
Epoch: 107 | Batch_idx: 300 |  Loss: (0.1983) |  Loss2: (0.0000) | Acc: (93.00%) (35882/38528)
Epoch: 107 | Batch_idx: 310 |  Loss: (0.1988) |  Loss2: (0.0000) | Acc: (93.00%) (37070/39808)
Epoch: 107 | Batch_idx: 320 |  Loss: (0.1991) |  Loss2: (0.0000) | Acc: (93.00%) (38254/41088)
Epoch: 107 | Batch_idx: 330 |  Loss: (0.1988) |  Loss2: (0.0000) | Acc: (93.00%) (39444/42368)
Epoch: 107 | Batch_idx: 340 |  Loss: (0.1985) |  Loss2: (0.0000) | Acc: (93.00%) (40639/43648)
Epoch: 107 | Batch_idx: 350 |  Loss: (0.1982) |  Loss2: (0.0000) | Acc: (93.00%) (41843/44928)
Epoch: 107 | Batch_idx: 360 |  Loss: (0.1970) |  Loss2: (0.0000) | Acc: (93.00%) (43056/46208)
Epoch: 107 | Batch_idx: 370 |  Loss: (0.1967) |  Loss2: (0.0000) | Acc: (93.00%) (44256/47488)
Epoch: 107 | Batch_idx: 380 |  Loss: (0.1960) |  Loss2: (0.0000) | Acc: (93.00%) (45458/48768)
Epoch: 107 | Batch_idx: 390 |  Loss: (0.1961) |  Loss2: (0.0000) | Acc: (93.00%) (46608/50000)
# TEST : Loss: (0.3717) | Acc: (87.00%) (8759/10000)
percent tensor([0.5531, 0.5386, 0.5759, 0.5705, 0.5741, 0.5530, 0.5522, 0.5683, 0.5612,
        0.5507, 0.5476, 0.5644, 0.5475, 0.5441, 0.5463, 0.5503],
       device='cuda:0') torch.Size([16])
percent tensor([0.5075, 0.5112, 0.5047, 0.5118, 0.5055, 0.5241, 0.5070, 0.5045, 0.5014,
        0.5034, 0.5030, 0.4999, 0.4999, 0.5181, 0.5124, 0.5124],
       device='cuda:0') torch.Size([16])
percent tensor([0.5881, 0.6514, 0.5430, 0.4682, 0.5311, 0.4851, 0.6181, 0.5359, 0.5784,
        0.6332, 0.6290, 0.6117, 0.6888, 0.5120, 0.5962, 0.5519],
       device='cuda:0') torch.Size([16])
percent tensor([0.6714, 0.6751, 0.6830, 0.7026, 0.6975, 0.6737, 0.6984, 0.6892, 0.6941,
        0.6849, 0.7103, 0.7022, 0.6653, 0.7098, 0.6867, 0.6815],
       device='cuda:0') torch.Size([16])
percent tensor([0.6692, 0.6368, 0.7061, 0.6291, 0.6674, 0.8289, 0.6645, 0.5999, 0.6895,
        0.6505, 0.6826, 0.5955, 0.6788, 0.7016, 0.6569, 0.7143],
       device='cuda:0') torch.Size([16])
percent tensor([0.5779, 0.6749, 0.5369, 0.4927, 0.4754, 0.5914, 0.5451, 0.3615, 0.6704,
        0.6185, 0.7130, 0.5707, 0.6975, 0.7160, 0.4707, 0.5742],
       device='cuda:0') torch.Size([16])
percent tensor([0.5684, 0.5699, 0.7346, 0.7609, 0.8114, 0.6623, 0.6526, 0.6982, 0.6362,
        0.6074, 0.5993, 0.7163, 0.5907, 0.6920, 0.6106, 0.6396],
       device='cuda:0') torch.Size([16])
percent tensor([0.9995, 0.9979, 0.9993, 0.9991, 0.9988, 0.9987, 0.9989, 0.9992, 0.9987,
        0.9988, 0.9990, 0.9988, 0.9989, 0.9989, 0.9987, 0.9993],
       device='cuda:0') torch.Size([16])
Epoch: 108 | Batch_idx: 0 |  Loss: (0.1875) |  Loss2: (0.0000) | Acc: (92.00%) (119/128)
Epoch: 108 | Batch_idx: 10 |  Loss: (0.1905) |  Loss2: (0.0000) | Acc: (93.00%) (1314/1408)
Epoch: 108 | Batch_idx: 20 |  Loss: (0.2074) |  Loss2: (0.0000) | Acc: (92.00%) (2484/2688)
Epoch: 108 | Batch_idx: 30 |  Loss: (0.1904) |  Loss2: (0.0000) | Acc: (93.00%) (3694/3968)
Epoch: 108 | Batch_idx: 40 |  Loss: (0.1882) |  Loss2: (0.0000) | Acc: (93.00%) (4891/5248)
Epoch: 108 | Batch_idx: 50 |  Loss: (0.1899) |  Loss2: (0.0000) | Acc: (93.00%) (6079/6528)
Epoch: 108 | Batch_idx: 60 |  Loss: (0.1888) |  Loss2: (0.0000) | Acc: (93.00%) (7269/7808)
Epoch: 108 | Batch_idx: 70 |  Loss: (0.1922) |  Loss2: (0.0000) | Acc: (93.00%) (8455/9088)
Epoch: 108 | Batch_idx: 80 |  Loss: (0.1918) |  Loss2: (0.0000) | Acc: (93.00%) (9653/10368)
Epoch: 108 | Batch_idx: 90 |  Loss: (0.1950) |  Loss2: (0.0000) | Acc: (93.00%) (10835/11648)
Epoch: 108 | Batch_idx: 100 |  Loss: (0.1950) |  Loss2: (0.0000) | Acc: (93.00%) (12027/12928)
Epoch: 108 | Batch_idx: 110 |  Loss: (0.1969) |  Loss2: (0.0000) | Acc: (93.00%) (13225/14208)
Epoch: 108 | Batch_idx: 120 |  Loss: (0.1974) |  Loss2: (0.0000) | Acc: (93.00%) (14417/15488)
Epoch: 108 | Batch_idx: 130 |  Loss: (0.1965) |  Loss2: (0.0000) | Acc: (93.00%) (15613/16768)
Epoch: 108 | Batch_idx: 140 |  Loss: (0.1963) |  Loss2: (0.0000) | Acc: (93.00%) (16811/18048)
Epoch: 108 | Batch_idx: 150 |  Loss: (0.1948) |  Loss2: (0.0000) | Acc: (93.00%) (18004/19328)
Epoch: 108 | Batch_idx: 160 |  Loss: (0.1945) |  Loss2: (0.0000) | Acc: (93.00%) (19206/20608)
Epoch: 108 | Batch_idx: 170 |  Loss: (0.1935) |  Loss2: (0.0000) | Acc: (93.00%) (20411/21888)
Epoch: 108 | Batch_idx: 180 |  Loss: (0.1926) |  Loss2: (0.0000) | Acc: (93.00%) (21617/23168)
Epoch: 108 | Batch_idx: 190 |  Loss: (0.1916) |  Loss2: (0.0000) | Acc: (93.00%) (22818/24448)
Epoch: 108 | Batch_idx: 200 |  Loss: (0.1922) |  Loss2: (0.0000) | Acc: (93.00%) (24011/25728)
Epoch: 108 | Batch_idx: 210 |  Loss: (0.1919) |  Loss2: (0.0000) | Acc: (93.00%) (25210/27008)
Epoch: 108 | Batch_idx: 220 |  Loss: (0.1920) |  Loss2: (0.0000) | Acc: (93.00%) (26402/28288)
Epoch: 108 | Batch_idx: 230 |  Loss: (0.1916) |  Loss2: (0.0000) | Acc: (93.00%) (27610/29568)
Epoch: 108 | Batch_idx: 240 |  Loss: (0.1904) |  Loss2: (0.0000) | Acc: (93.00%) (28820/30848)
Epoch: 108 | Batch_idx: 250 |  Loss: (0.1907) |  Loss2: (0.0000) | Acc: (93.00%) (30013/32128)
Epoch: 108 | Batch_idx: 260 |  Loss: (0.1906) |  Loss2: (0.0000) | Acc: (93.00%) (31208/33408)
Epoch: 108 | Batch_idx: 270 |  Loss: (0.1912) |  Loss2: (0.0000) | Acc: (93.00%) (32400/34688)
Epoch: 108 | Batch_idx: 280 |  Loss: (0.1913) |  Loss2: (0.0000) | Acc: (93.00%) (33598/35968)
Epoch: 108 | Batch_idx: 290 |  Loss: (0.1908) |  Loss2: (0.0000) | Acc: (93.00%) (34796/37248)
Epoch: 108 | Batch_idx: 300 |  Loss: (0.1910) |  Loss2: (0.0000) | Acc: (93.00%) (35983/38528)
Epoch: 108 | Batch_idx: 310 |  Loss: (0.1909) |  Loss2: (0.0000) | Acc: (93.00%) (37173/39808)
Epoch: 108 | Batch_idx: 320 |  Loss: (0.1909) |  Loss2: (0.0000) | Acc: (93.00%) (38370/41088)
Epoch: 108 | Batch_idx: 330 |  Loss: (0.1912) |  Loss2: (0.0000) | Acc: (93.00%) (39564/42368)
Epoch: 108 | Batch_idx: 340 |  Loss: (0.1912) |  Loss2: (0.0000) | Acc: (93.00%) (40763/43648)
Epoch: 108 | Batch_idx: 350 |  Loss: (0.1910) |  Loss2: (0.0000) | Acc: (93.00%) (41971/44928)
Epoch: 108 | Batch_idx: 360 |  Loss: (0.1909) |  Loss2: (0.0000) | Acc: (93.00%) (43167/46208)
Epoch: 108 | Batch_idx: 370 |  Loss: (0.1910) |  Loss2: (0.0000) | Acc: (93.00%) (44355/47488)
Epoch: 108 | Batch_idx: 380 |  Loss: (0.1909) |  Loss2: (0.0000) | Acc: (93.00%) (45549/48768)
Epoch: 108 | Batch_idx: 390 |  Loss: (0.1913) |  Loss2: (0.0000) | Acc: (93.00%) (46693/50000)
# TEST : Loss: (0.3679) | Acc: (87.00%) (8781/10000)
percent tensor([0.5509, 0.5351, 0.5749, 0.5691, 0.5727, 0.5505, 0.5494, 0.5663, 0.5590,
        0.5480, 0.5447, 0.5629, 0.5450, 0.5410, 0.5433, 0.5478],
       device='cuda:0') torch.Size([16])
percent tensor([0.5119, 0.5156, 0.5083, 0.5160, 0.5097, 0.5288, 0.5115, 0.5087, 0.5053,
        0.5073, 0.5070, 0.5036, 0.5037, 0.5226, 0.5170, 0.5169],
       device='cuda:0') torch.Size([16])
percent tensor([0.5832, 0.6453, 0.5452, 0.4750, 0.5354, 0.4854, 0.6144, 0.5379, 0.5767,
        0.6293, 0.6242, 0.6120, 0.6831, 0.5083, 0.5926, 0.5491],
       device='cuda:0') torch.Size([16])
percent tensor([0.6649, 0.6663, 0.6795, 0.6994, 0.6942, 0.6701, 0.6919, 0.6859, 0.6888,
        0.6771, 0.7013, 0.6954, 0.6555, 0.7037, 0.6805, 0.6753],
       device='cuda:0') torch.Size([16])
percent tensor([0.6617, 0.6334, 0.7008, 0.6255, 0.6673, 0.8280, 0.6587, 0.5975, 0.6893,
        0.6497, 0.6852, 0.5933, 0.6762, 0.7027, 0.6519, 0.7101],
       device='cuda:0') torch.Size([16])
percent tensor([0.5594, 0.6646, 0.5185, 0.4734, 0.4602, 0.5803, 0.5266, 0.3379, 0.6591,
        0.6061, 0.7026, 0.5568, 0.6902, 0.7076, 0.4496, 0.5593],
       device='cuda:0') torch.Size([16])
percent tensor([0.5788, 0.5782, 0.7546, 0.7768, 0.8242, 0.6894, 0.6663, 0.7127, 0.6523,
        0.6259, 0.6050, 0.7308, 0.6034, 0.7040, 0.6217, 0.6562],
       device='cuda:0') torch.Size([16])
percent tensor([0.9996, 0.9981, 0.9993, 0.9992, 0.9989, 0.9987, 0.9990, 0.9992, 0.9988,
        0.9989, 0.9990, 0.9990, 0.9989, 0.9990, 0.9988, 0.9994],
       device='cuda:0') torch.Size([16])
Epoch: 109 | Batch_idx: 0 |  Loss: (0.0980) |  Loss2: (0.0000) | Acc: (96.00%) (124/128)
Epoch: 109 | Batch_idx: 10 |  Loss: (0.1881) |  Loss2: (0.0000) | Acc: (93.00%) (1320/1408)
Epoch: 109 | Batch_idx: 20 |  Loss: (0.2007) |  Loss2: (0.0000) | Acc: (93.00%) (2510/2688)
Epoch: 109 | Batch_idx: 30 |  Loss: (0.2026) |  Loss2: (0.0000) | Acc: (93.00%) (3693/3968)
Epoch: 109 | Batch_idx: 40 |  Loss: (0.2050) |  Loss2: (0.0000) | Acc: (92.00%) (4876/5248)
Epoch: 109 | Batch_idx: 50 |  Loss: (0.2018) |  Loss2: (0.0000) | Acc: (92.00%) (6062/6528)
Epoch: 109 | Batch_idx: 60 |  Loss: (0.1974) |  Loss2: (0.0000) | Acc: (93.00%) (7270/7808)
Epoch: 109 | Batch_idx: 70 |  Loss: (0.2000) |  Loss2: (0.0000) | Acc: (92.00%) (8448/9088)
Epoch: 109 | Batch_idx: 80 |  Loss: (0.1968) |  Loss2: (0.0000) | Acc: (93.00%) (9653/10368)
Epoch: 109 | Batch_idx: 90 |  Loss: (0.1959) |  Loss2: (0.0000) | Acc: (93.00%) (10851/11648)
Epoch: 109 | Batch_idx: 100 |  Loss: (0.1961) |  Loss2: (0.0000) | Acc: (93.00%) (12051/12928)
Epoch: 109 | Batch_idx: 110 |  Loss: (0.1944) |  Loss2: (0.0000) | Acc: (93.00%) (13253/14208)
Epoch: 109 | Batch_idx: 120 |  Loss: (0.1923) |  Loss2: (0.0000) | Acc: (93.00%) (14453/15488)
Epoch: 109 | Batch_idx: 130 |  Loss: (0.1914) |  Loss2: (0.0000) | Acc: (93.00%) (15647/16768)
Epoch: 109 | Batch_idx: 140 |  Loss: (0.1922) |  Loss2: (0.0000) | Acc: (93.00%) (16828/18048)
Epoch: 109 | Batch_idx: 150 |  Loss: (0.1916) |  Loss2: (0.0000) | Acc: (93.00%) (18025/19328)
Epoch: 109 | Batch_idx: 160 |  Loss: (0.1914) |  Loss2: (0.0000) | Acc: (93.00%) (19227/20608)
Epoch: 109 | Batch_idx: 170 |  Loss: (0.1906) |  Loss2: (0.0000) | Acc: (93.00%) (20428/21888)
Epoch: 109 | Batch_idx: 180 |  Loss: (0.1911) |  Loss2: (0.0000) | Acc: (93.00%) (21613/23168)
Epoch: 109 | Batch_idx: 190 |  Loss: (0.1901) |  Loss2: (0.0000) | Acc: (93.00%) (22827/24448)
Epoch: 109 | Batch_idx: 200 |  Loss: (0.1897) |  Loss2: (0.0000) | Acc: (93.00%) (24027/25728)
Epoch: 109 | Batch_idx: 210 |  Loss: (0.1905) |  Loss2: (0.0000) | Acc: (93.00%) (25206/27008)
Epoch: 109 | Batch_idx: 220 |  Loss: (0.1901) |  Loss2: (0.0000) | Acc: (93.00%) (26412/28288)
Epoch: 109 | Batch_idx: 230 |  Loss: (0.1892) |  Loss2: (0.0000) | Acc: (93.00%) (27609/29568)
Epoch: 109 | Batch_idx: 240 |  Loss: (0.1886) |  Loss2: (0.0000) | Acc: (93.00%) (28805/30848)
Epoch: 109 | Batch_idx: 250 |  Loss: (0.1880) |  Loss2: (0.0000) | Acc: (93.00%) (30006/32128)
Epoch: 109 | Batch_idx: 260 |  Loss: (0.1881) |  Loss2: (0.0000) | Acc: (93.00%) (31202/33408)
Epoch: 109 | Batch_idx: 270 |  Loss: (0.1878) |  Loss2: (0.0000) | Acc: (93.00%) (32403/34688)
Epoch: 109 | Batch_idx: 280 |  Loss: (0.1876) |  Loss2: (0.0000) | Acc: (93.00%) (33615/35968)
Epoch: 109 | Batch_idx: 290 |  Loss: (0.1877) |  Loss2: (0.0000) | Acc: (93.00%) (34814/37248)
Epoch: 109 | Batch_idx: 300 |  Loss: (0.1886) |  Loss2: (0.0000) | Acc: (93.00%) (35993/38528)
Epoch: 109 | Batch_idx: 310 |  Loss: (0.1884) |  Loss2: (0.0000) | Acc: (93.00%) (37194/39808)
Epoch: 109 | Batch_idx: 320 |  Loss: (0.1893) |  Loss2: (0.0000) | Acc: (93.00%) (38385/41088)
Epoch: 109 | Batch_idx: 330 |  Loss: (0.1898) |  Loss2: (0.0000) | Acc: (93.00%) (39579/42368)
Epoch: 109 | Batch_idx: 340 |  Loss: (0.1889) |  Loss2: (0.0000) | Acc: (93.00%) (40787/43648)
Epoch: 109 | Batch_idx: 350 |  Loss: (0.1883) |  Loss2: (0.0000) | Acc: (93.00%) (41996/44928)
Epoch: 109 | Batch_idx: 360 |  Loss: (0.1880) |  Loss2: (0.0000) | Acc: (93.00%) (43203/46208)
Epoch: 109 | Batch_idx: 370 |  Loss: (0.1876) |  Loss2: (0.0000) | Acc: (93.00%) (44411/47488)
Epoch: 109 | Batch_idx: 380 |  Loss: (0.1870) |  Loss2: (0.0000) | Acc: (93.00%) (45614/48768)
Epoch: 109 | Batch_idx: 390 |  Loss: (0.1868) |  Loss2: (0.0000) | Acc: (93.00%) (46777/50000)
# TEST : Loss: (0.3634) | Acc: (88.00%) (8807/10000)
percent tensor([0.5501, 0.5334, 0.5738, 0.5680, 0.5716, 0.5498, 0.5479, 0.5651, 0.5581,
        0.5465, 0.5436, 0.5615, 0.5437, 0.5399, 0.5419, 0.5468],
       device='cuda:0') torch.Size([16])
percent tensor([0.5150, 0.5188, 0.5118, 0.5195, 0.5133, 0.5320, 0.5149, 0.5123, 0.5085,
        0.5104, 0.5100, 0.5069, 0.5068, 0.5255, 0.5203, 0.5201],
       device='cuda:0') torch.Size([16])
percent tensor([0.5803, 0.6433, 0.5437, 0.4760, 0.5344, 0.4862, 0.6119, 0.5372, 0.5749,
        0.6275, 0.6214, 0.6108, 0.6803, 0.5081, 0.5906, 0.5487],
       device='cuda:0') torch.Size([16])
percent tensor([0.6709, 0.6692, 0.6864, 0.7056, 0.7006, 0.6766, 0.6964, 0.6929, 0.6931,
        0.6803, 0.7034, 0.7002, 0.6591, 0.7067, 0.6862, 0.6800],
       device='cuda:0') torch.Size([16])
percent tensor([0.6610, 0.6340, 0.6987, 0.6257, 0.6685, 0.8257, 0.6574, 0.5997, 0.6889,
        0.6491, 0.6857, 0.5901, 0.6754, 0.7004, 0.6513, 0.7086],
       device='cuda:0') torch.Size([16])
percent tensor([0.5757, 0.6807, 0.5358, 0.4893, 0.4772, 0.5941, 0.5442, 0.3527, 0.6726,
        0.6292, 0.7166, 0.5760, 0.7040, 0.7210, 0.4693, 0.5807],
       device='cuda:0') torch.Size([16])
percent tensor([0.5748, 0.5707, 0.7620, 0.7801, 0.8311, 0.6931, 0.6648, 0.7172, 0.6511,
        0.6244, 0.5983, 0.7317, 0.5987, 0.6988, 0.6210, 0.6569],
       device='cuda:0') torch.Size([16])
percent tensor([0.9996, 0.9981, 0.9994, 0.9992, 0.9990, 0.9987, 0.9990, 0.9993, 0.9988,
        0.9989, 0.9990, 0.9990, 0.9989, 0.9989, 0.9988, 0.9994],
       device='cuda:0') torch.Size([16])
True Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=128, out_features=16, bias=False)
False Linear(in_features=16, out_features=2, bias=False)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=128, out_features=16, bias=False)
False Linear(in_features=16, out_features=2, bias=False)
True Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=256, out_features=32, bias=False)
False Linear(in_features=32, out_features=2, bias=False)
True Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=256, out_features=32, bias=False)
False Linear(in_features=32, out_features=2, bias=False)
True Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=512, out_features=64, bias=False)
False Linear(in_features=64, out_features=2, bias=False)
True Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=512, out_features=64, bias=False)
False Linear(in_features=64, out_features=2, bias=False)
True Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1024, out_features=128, bias=False)
False Linear(in_features=128, out_features=2, bias=False)
True Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1024, out_features=128, bias=False)
False Linear(in_features=128, out_features=2, bias=False)
True Linear(in_features=512, out_features=10, bias=True)
Epoch: 110 | Batch_idx: 0 |  Loss: (0.2367) |  Loss2: (0.0000) | Acc: (92.00%) (118/128)
Epoch: 110 | Batch_idx: 10 |  Loss: (0.1991) |  Loss2: (0.0000) | Acc: (92.00%) (1303/1408)
Epoch: 110 | Batch_idx: 20 |  Loss: (0.2001) |  Loss2: (0.0000) | Acc: (93.00%) (2504/2688)
Epoch: 110 | Batch_idx: 30 |  Loss: (0.1943) |  Loss2: (0.0000) | Acc: (93.00%) (3705/3968)
Epoch: 110 | Batch_idx: 40 |  Loss: (0.1940) |  Loss2: (0.0000) | Acc: (93.00%) (4893/5248)
Epoch: 110 | Batch_idx: 50 |  Loss: (0.1926) |  Loss2: (0.0000) | Acc: (93.00%) (6087/6528)
Epoch: 110 | Batch_idx: 60 |  Loss: (0.1940) |  Loss2: (0.0000) | Acc: (93.00%) (7281/7808)
Epoch: 110 | Batch_idx: 70 |  Loss: (0.1935) |  Loss2: (0.0000) | Acc: (93.00%) (8491/9088)
Epoch: 110 | Batch_idx: 80 |  Loss: (0.1941) |  Loss2: (0.0000) | Acc: (93.00%) (9690/10368)
Epoch: 110 | Batch_idx: 90 |  Loss: (0.1924) |  Loss2: (0.0000) | Acc: (93.00%) (10884/11648)
Epoch: 110 | Batch_idx: 100 |  Loss: (0.1906) |  Loss2: (0.0000) | Acc: (93.00%) (12086/12928)
Epoch: 110 | Batch_idx: 110 |  Loss: (0.1924) |  Loss2: (0.0000) | Acc: (93.00%) (13267/14208)
Epoch: 110 | Batch_idx: 120 |  Loss: (0.1944) |  Loss2: (0.0000) | Acc: (93.00%) (14460/15488)
Epoch: 110 | Batch_idx: 130 |  Loss: (0.1947) |  Loss2: (0.0000) | Acc: (93.00%) (15654/16768)
Epoch: 110 | Batch_idx: 140 |  Loss: (0.1931) |  Loss2: (0.0000) | Acc: (93.00%) (16857/18048)
Epoch: 110 | Batch_idx: 150 |  Loss: (0.1944) |  Loss2: (0.0000) | Acc: (93.00%) (18040/19328)
Epoch: 110 | Batch_idx: 160 |  Loss: (0.1941) |  Loss2: (0.0000) | Acc: (93.00%) (19235/20608)
Epoch: 110 | Batch_idx: 170 |  Loss: (0.1948) |  Loss2: (0.0000) | Acc: (93.00%) (20425/21888)
Epoch: 110 | Batch_idx: 180 |  Loss: (0.1950) |  Loss2: (0.0000) | Acc: (93.00%) (21622/23168)
Epoch: 110 | Batch_idx: 190 |  Loss: (0.1942) |  Loss2: (0.0000) | Acc: (93.00%) (22817/24448)
Epoch: 110 | Batch_idx: 200 |  Loss: (0.1962) |  Loss2: (0.0000) | Acc: (93.00%) (23994/25728)
Epoch: 110 | Batch_idx: 210 |  Loss: (0.1969) |  Loss2: (0.0000) | Acc: (93.00%) (25182/27008)
Epoch: 110 | Batch_idx: 220 |  Loss: (0.1960) |  Loss2: (0.0000) | Acc: (93.00%) (26383/28288)
Epoch: 110 | Batch_idx: 230 |  Loss: (0.1963) |  Loss2: (0.0000) | Acc: (93.00%) (27568/29568)
Epoch: 110 | Batch_idx: 240 |  Loss: (0.1967) |  Loss2: (0.0000) | Acc: (93.00%) (28764/30848)
Epoch: 110 | Batch_idx: 250 |  Loss: (0.1972) |  Loss2: (0.0000) | Acc: (93.00%) (29951/32128)
Epoch: 110 | Batch_idx: 260 |  Loss: (0.1960) |  Loss2: (0.0000) | Acc: (93.00%) (31153/33408)
Epoch: 110 | Batch_idx: 270 |  Loss: (0.1964) |  Loss2: (0.0000) | Acc: (93.00%) (32339/34688)
Epoch: 110 | Batch_idx: 280 |  Loss: (0.1969) |  Loss2: (0.0000) | Acc: (93.00%) (33525/35968)
Epoch: 110 | Batch_idx: 290 |  Loss: (0.1967) |  Loss2: (0.0000) | Acc: (93.00%) (34720/37248)
Epoch: 110 | Batch_idx: 300 |  Loss: (0.1969) |  Loss2: (0.0000) | Acc: (93.00%) (35900/38528)
Epoch: 110 | Batch_idx: 310 |  Loss: (0.1979) |  Loss2: (0.0000) | Acc: (93.00%) (37078/39808)
Epoch: 110 | Batch_idx: 320 |  Loss: (0.1982) |  Loss2: (0.0000) | Acc: (93.00%) (38264/41088)
Epoch: 110 | Batch_idx: 330 |  Loss: (0.1988) |  Loss2: (0.0000) | Acc: (93.00%) (39445/42368)
Epoch: 110 | Batch_idx: 340 |  Loss: (0.1979) |  Loss2: (0.0000) | Acc: (93.00%) (40656/43648)
Epoch: 110 | Batch_idx: 350 |  Loss: (0.1983) |  Loss2: (0.0000) | Acc: (93.00%) (41845/44928)
Epoch: 110 | Batch_idx: 360 |  Loss: (0.1989) |  Loss2: (0.0000) | Acc: (93.00%) (43033/46208)
Epoch: 110 | Batch_idx: 370 |  Loss: (0.1990) |  Loss2: (0.0000) | Acc: (93.00%) (44216/47488)
Epoch: 110 | Batch_idx: 380 |  Loss: (0.1992) |  Loss2: (0.0000) | Acc: (93.00%) (45409/48768)
Epoch: 110 | Batch_idx: 390 |  Loss: (0.1997) |  Loss2: (0.0000) | Acc: (93.00%) (46559/50000)
/usr/local/lib/python3.6/dist-packages/torch/serialization.py:241: UserWarning: Couldn't retrieve source code for container of type ResNet. It won't be checked for correctness upon loading.
  "type " + obj.__name__ + ". It won't be checked "
/usr/local/lib/python3.6/dist-packages/torch/serialization.py:241: UserWarning: Couldn't retrieve source code for container of type BasicBlock. It won't be checked for correctness upon loading.
  "type " + obj.__name__ + ". It won't be checked "
/usr/local/lib/python3.6/dist-packages/torch/serialization.py:241: UserWarning: Couldn't retrieve source code for container of type _Gate. It won't be checked for correctness upon loading.
  "type " + obj.__name__ + ". It won't be checked "
=> saving checkpoint 'drive/app/torch/save_Routing_Gate_2/checkpoint_110.pth.tar'
# TEST : Loss: (0.4411) | Acc: (85.00%) (8594/10000)
percent tensor([0.5510, 0.5328, 0.5742, 0.5682, 0.5718, 0.5492, 0.5484, 0.5663, 0.5593,
        0.5480, 0.5444, 0.5629, 0.5449, 0.5387, 0.5420, 0.5475],
       device='cuda:0') torch.Size([16])
percent tensor([0.5149, 0.5201, 0.5099, 0.5186, 0.5110, 0.5304, 0.5153, 0.5124, 0.5104,
        0.5110, 0.5120, 0.5062, 0.5084, 0.5277, 0.5210, 0.5197],
       device='cuda:0') torch.Size([16])
percent tensor([0.5775, 0.6409, 0.5464, 0.4724, 0.5338, 0.4983, 0.6075, 0.5240, 0.5601,
        0.6188, 0.6065, 0.6051, 0.6703, 0.5081, 0.5850, 0.5519],
       device='cuda:0') torch.Size([16])
percent tensor([0.6755, 0.6711, 0.6952, 0.7133, 0.7044, 0.6841, 0.6992, 0.6972, 0.7028,
        0.6802, 0.7096, 0.7081, 0.6656, 0.7110, 0.6932, 0.6841],
       device='cuda:0') torch.Size([16])
percent tensor([0.6339, 0.6212, 0.6726, 0.6114, 0.6540, 0.8121, 0.6341, 0.5861, 0.6845,
        0.6325, 0.6803, 0.5716, 0.6606, 0.6952, 0.6240, 0.7035],
       device='cuda:0') torch.Size([16])
percent tensor([0.5897, 0.6837, 0.5611, 0.5139, 0.5308, 0.6188, 0.5671, 0.3665, 0.6580,
        0.6323, 0.6868, 0.5822, 0.6916, 0.7297, 0.4679, 0.6034],
       device='cuda:0') torch.Size([16])
percent tensor([0.5721, 0.5637, 0.7823, 0.7821, 0.8547, 0.7015, 0.6588, 0.7197, 0.6837,
        0.6056, 0.5938, 0.7545, 0.6300, 0.6940, 0.6321, 0.6558],
       device='cuda:0') torch.Size([16])
percent tensor([0.9997, 0.9985, 0.9990, 0.9992, 0.9991, 0.9988, 0.9990, 0.9988, 0.9987,
        0.9992, 0.9990, 0.9988, 0.9992, 0.9993, 0.9990, 0.9994],
       device='cuda:0') torch.Size([16])
Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 3, 3, 3]) tensor(180.4874, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(810.2923, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(816.8337, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([128, 64, 3, 3]) tensor(1518.0947, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([128, 64, 1, 1]) tensor(494.5056, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([128, 128, 3, 3]) tensor(2252.3218, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([256, 128, 3, 3]) tensor(4289.1826, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([256, 128, 1, 1]) tensor(1391.3069, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([256, 256, 3, 3]) tensor(6153.2607, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([512, 256, 3, 3]) tensor(11853.0791, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([512, 256, 1, 1]) tensor(3930.6558, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([512, 512, 3, 3]) tensor(16590.6504, device='cuda:0', grad_fn=<NormBackward0>)
Epoch: 111 | Batch_idx: 0 |  Loss: (0.2361) |  Loss2: (0.0000) | Acc: (91.00%) (117/128)
Epoch: 111 | Batch_idx: 10 |  Loss: (0.1835) |  Loss2: (0.0000) | Acc: (93.00%) (1312/1408)
Epoch: 111 | Batch_idx: 20 |  Loss: (0.1969) |  Loss2: (0.0000) | Acc: (93.00%) (2501/2688)
Epoch: 111 | Batch_idx: 30 |  Loss: (0.1880) |  Loss2: (0.0000) | Acc: (93.00%) (3714/3968)
Epoch: 111 | Batch_idx: 40 |  Loss: (0.1862) |  Loss2: (0.0000) | Acc: (93.00%) (4906/5248)
Epoch: 111 | Batch_idx: 50 |  Loss: (0.1859) |  Loss2: (0.0000) | Acc: (93.00%) (6109/6528)
Epoch: 111 | Batch_idx: 60 |  Loss: (0.1853) |  Loss2: (0.0000) | Acc: (93.00%) (7308/7808)
Epoch: 111 | Batch_idx: 70 |  Loss: (0.1824) |  Loss2: (0.0000) | Acc: (93.00%) (8517/9088)
Epoch: 111 | Batch_idx: 80 |  Loss: (0.1861) |  Loss2: (0.0000) | Acc: (93.00%) (9708/10368)
Epoch: 111 | Batch_idx: 90 |  Loss: (0.1867) |  Loss2: (0.0000) | Acc: (93.00%) (10903/11648)
Epoch: 111 | Batch_idx: 100 |  Loss: (0.1847) |  Loss2: (0.0000) | Acc: (93.00%) (12106/12928)
Epoch: 111 | Batch_idx: 110 |  Loss: (0.1881) |  Loss2: (0.0000) | Acc: (93.00%) (13285/14208)
Epoch: 111 | Batch_idx: 120 |  Loss: (0.1897) |  Loss2: (0.0000) | Acc: (93.00%) (14471/15488)
Epoch: 111 | Batch_idx: 130 |  Loss: (0.1874) |  Loss2: (0.0000) | Acc: (93.00%) (15684/16768)
Epoch: 111 | Batch_idx: 140 |  Loss: (0.1849) |  Loss2: (0.0000) | Acc: (93.00%) (16889/18048)
Epoch: 111 | Batch_idx: 150 |  Loss: (0.1854) |  Loss2: (0.0000) | Acc: (93.00%) (18090/19328)
Epoch: 111 | Batch_idx: 160 |  Loss: (0.1851) |  Loss2: (0.0000) | Acc: (93.00%) (19290/20608)
Epoch: 111 | Batch_idx: 170 |  Loss: (0.1865) |  Loss2: (0.0000) | Acc: (93.00%) (20478/21888)
Epoch: 111 | Batch_idx: 180 |  Loss: (0.1866) |  Loss2: (0.0000) | Acc: (93.00%) (21667/23168)
Epoch: 111 | Batch_idx: 190 |  Loss: (0.1856) |  Loss2: (0.0000) | Acc: (93.00%) (22872/24448)
Epoch: 111 | Batch_idx: 200 |  Loss: (0.1864) |  Loss2: (0.0000) | Acc: (93.00%) (24062/25728)
Epoch: 111 | Batch_idx: 210 |  Loss: (0.1875) |  Loss2: (0.0000) | Acc: (93.00%) (25251/27008)
Epoch: 111 | Batch_idx: 220 |  Loss: (0.1869) |  Loss2: (0.0000) | Acc: (93.00%) (26450/28288)
Epoch: 111 | Batch_idx: 230 |  Loss: (0.1870) |  Loss2: (0.0000) | Acc: (93.00%) (27652/29568)
Epoch: 111 | Batch_idx: 240 |  Loss: (0.1874) |  Loss2: (0.0000) | Acc: (93.00%) (28844/30848)
Epoch: 111 | Batch_idx: 250 |  Loss: (0.1879) |  Loss2: (0.0000) | Acc: (93.00%) (30038/32128)
Epoch: 111 | Batch_idx: 260 |  Loss: (0.1884) |  Loss2: (0.0000) | Acc: (93.00%) (31221/33408)
Epoch: 111 | Batch_idx: 270 |  Loss: (0.1886) |  Loss2: (0.0000) | Acc: (93.00%) (32415/34688)
Epoch: 111 | Batch_idx: 280 |  Loss: (0.1884) |  Loss2: (0.0000) | Acc: (93.00%) (33617/35968)
Epoch: 111 | Batch_idx: 290 |  Loss: (0.1883) |  Loss2: (0.0000) | Acc: (93.00%) (34820/37248)
Epoch: 111 | Batch_idx: 300 |  Loss: (0.1891) |  Loss2: (0.0000) | Acc: (93.00%) (36007/38528)
Epoch: 111 | Batch_idx: 310 |  Loss: (0.1895) |  Loss2: (0.0000) | Acc: (93.00%) (37212/39808)
Epoch: 111 | Batch_idx: 320 |  Loss: (0.1897) |  Loss2: (0.0000) | Acc: (93.00%) (38407/41088)
Epoch: 111 | Batch_idx: 330 |  Loss: (0.1896) |  Loss2: (0.0000) | Acc: (93.00%) (39609/42368)
Epoch: 111 | Batch_idx: 340 |  Loss: (0.1896) |  Loss2: (0.0000) | Acc: (93.00%) (40807/43648)
Epoch: 111 | Batch_idx: 350 |  Loss: (0.1897) |  Loss2: (0.0000) | Acc: (93.00%) (42002/44928)
Epoch: 111 | Batch_idx: 360 |  Loss: (0.1895) |  Loss2: (0.0000) | Acc: (93.00%) (43209/46208)
Epoch: 111 | Batch_idx: 370 |  Loss: (0.1902) |  Loss2: (0.0000) | Acc: (93.00%) (44406/47488)
Epoch: 111 | Batch_idx: 380 |  Loss: (0.1897) |  Loss2: (0.0000) | Acc: (93.00%) (45611/48768)
Epoch: 111 | Batch_idx: 390 |  Loss: (0.1902) |  Loss2: (0.0000) | Acc: (93.00%) (46748/50000)
# TEST : Loss: (0.3812) | Acc: (87.00%) (8727/10000)
percent tensor([0.5496, 0.5316, 0.5730, 0.5673, 0.5695, 0.5521, 0.5458, 0.5650, 0.5566,
        0.5459, 0.5436, 0.5610, 0.5433, 0.5366, 0.5424, 0.5466],
       device='cuda:0') torch.Size([16])
percent tensor([0.5153, 0.5190, 0.5126, 0.5184, 0.5134, 0.5319, 0.5143, 0.5122, 0.5102,
        0.5108, 0.5112, 0.5076, 0.5079, 0.5252, 0.5205, 0.5194],
       device='cuda:0') torch.Size([16])
percent tensor([0.5826, 0.6502, 0.5400, 0.4731, 0.5302, 0.4788, 0.6164, 0.5392, 0.5732,
        0.6232, 0.6148, 0.6006, 0.6773, 0.5200, 0.5923, 0.5575],
       device='cuda:0') torch.Size([16])
percent tensor([0.6740, 0.6674, 0.6944, 0.7065, 0.7000, 0.6846, 0.6918, 0.6945, 0.7020,
        0.6805, 0.7139, 0.7016, 0.6653, 0.7029, 0.6893, 0.6816],
       device='cuda:0') torch.Size([16])
percent tensor([0.6725, 0.6593, 0.6871, 0.6371, 0.6679, 0.8149, 0.6781, 0.6214, 0.6873,
        0.6664, 0.7091, 0.6055, 0.6911, 0.7170, 0.6599, 0.7234],
       device='cuda:0') torch.Size([16])
percent tensor([0.5948, 0.6748, 0.5616, 0.5184, 0.5059, 0.6089, 0.5528, 0.4097, 0.6552,
        0.6376, 0.7134, 0.6071, 0.7009, 0.7202, 0.4690, 0.5933],
       device='cuda:0') torch.Size([16])
percent tensor([0.5879, 0.6229, 0.7867, 0.7804, 0.8477, 0.6841, 0.6598, 0.7080, 0.6964,
        0.6607, 0.6542, 0.7549, 0.6629, 0.7212, 0.6143, 0.6523],
       device='cuda:0') torch.Size([16])
percent tensor([0.9995, 0.9988, 0.9992, 0.9993, 0.9992, 0.9986, 0.9990, 0.9991, 0.9986,
        0.9993, 0.9991, 0.9992, 0.9991, 0.9983, 0.9991, 0.9992],
       device='cuda:0') torch.Size([16])
Epoch: 112 | Batch_idx: 0 |  Loss: (0.1611) |  Loss2: (0.0000) | Acc: (93.00%) (120/128)
Epoch: 112 | Batch_idx: 10 |  Loss: (0.1657) |  Loss2: (0.0000) | Acc: (94.00%) (1327/1408)
Epoch: 112 | Batch_idx: 20 |  Loss: (0.1793) |  Loss2: (0.0000) | Acc: (93.00%) (2523/2688)
Epoch: 112 | Batch_idx: 30 |  Loss: (0.1810) |  Loss2: (0.0000) | Acc: (93.00%) (3718/3968)
Epoch: 112 | Batch_idx: 40 |  Loss: (0.1840) |  Loss2: (0.0000) | Acc: (93.00%) (4913/5248)
Epoch: 112 | Batch_idx: 50 |  Loss: (0.1851) |  Loss2: (0.0000) | Acc: (93.00%) (6108/6528)
Epoch: 112 | Batch_idx: 60 |  Loss: (0.1877) |  Loss2: (0.0000) | Acc: (93.00%) (7298/7808)
Epoch: 112 | Batch_idx: 70 |  Loss: (0.1852) |  Loss2: (0.0000) | Acc: (93.00%) (8505/9088)
Epoch: 112 | Batch_idx: 80 |  Loss: (0.1838) |  Loss2: (0.0000) | Acc: (93.00%) (9707/10368)
Epoch: 112 | Batch_idx: 90 |  Loss: (0.1866) |  Loss2: (0.0000) | Acc: (93.00%) (10891/11648)
Epoch: 112 | Batch_idx: 100 |  Loss: (0.1854) |  Loss2: (0.0000) | Acc: (93.00%) (12095/12928)
Epoch: 112 | Batch_idx: 110 |  Loss: (0.1866) |  Loss2: (0.0000) | Acc: (93.00%) (13288/14208)
Epoch: 112 | Batch_idx: 120 |  Loss: (0.1859) |  Loss2: (0.0000) | Acc: (93.00%) (14482/15488)
Epoch: 112 | Batch_idx: 130 |  Loss: (0.1866) |  Loss2: (0.0000) | Acc: (93.00%) (15670/16768)
Epoch: 112 | Batch_idx: 140 |  Loss: (0.1882) |  Loss2: (0.0000) | Acc: (93.00%) (16849/18048)
Epoch: 112 | Batch_idx: 150 |  Loss: (0.1874) |  Loss2: (0.0000) | Acc: (93.00%) (18056/19328)
Epoch: 112 | Batch_idx: 160 |  Loss: (0.1862) |  Loss2: (0.0000) | Acc: (93.00%) (19260/20608)
Epoch: 112 | Batch_idx: 170 |  Loss: (0.1883) |  Loss2: (0.0000) | Acc: (93.00%) (20436/21888)
Epoch: 112 | Batch_idx: 180 |  Loss: (0.1868) |  Loss2: (0.0000) | Acc: (93.00%) (21645/23168)
Epoch: 112 | Batch_idx: 190 |  Loss: (0.1860) |  Loss2: (0.0000) | Acc: (93.00%) (22846/24448)
Epoch: 112 | Batch_idx: 200 |  Loss: (0.1855) |  Loss2: (0.0000) | Acc: (93.00%) (24047/25728)
Epoch: 112 | Batch_idx: 210 |  Loss: (0.1857) |  Loss2: (0.0000) | Acc: (93.00%) (25237/27008)
Epoch: 112 | Batch_idx: 220 |  Loss: (0.1846) |  Loss2: (0.0000) | Acc: (93.00%) (26445/28288)
Epoch: 112 | Batch_idx: 230 |  Loss: (0.1845) |  Loss2: (0.0000) | Acc: (93.00%) (27638/29568)
Epoch: 112 | Batch_idx: 240 |  Loss: (0.1841) |  Loss2: (0.0000) | Acc: (93.00%) (28838/30848)
Epoch: 112 | Batch_idx: 250 |  Loss: (0.1851) |  Loss2: (0.0000) | Acc: (93.00%) (30024/32128)
Epoch: 112 | Batch_idx: 260 |  Loss: (0.1854) |  Loss2: (0.0000) | Acc: (93.00%) (31213/33408)
Epoch: 112 | Batch_idx: 270 |  Loss: (0.1848) |  Loss2: (0.0000) | Acc: (93.00%) (32412/34688)
Epoch: 112 | Batch_idx: 280 |  Loss: (0.1850) |  Loss2: (0.0000) | Acc: (93.00%) (33611/35968)
Epoch: 112 | Batch_idx: 290 |  Loss: (0.1859) |  Loss2: (0.0000) | Acc: (93.00%) (34800/37248)
Epoch: 112 | Batch_idx: 300 |  Loss: (0.1859) |  Loss2: (0.0000) | Acc: (93.00%) (35998/38528)
Epoch: 112 | Batch_idx: 310 |  Loss: (0.1862) |  Loss2: (0.0000) | Acc: (93.00%) (37187/39808)
Epoch: 112 | Batch_idx: 320 |  Loss: (0.1862) |  Loss2: (0.0000) | Acc: (93.00%) (38382/41088)
Epoch: 112 | Batch_idx: 330 |  Loss: (0.1866) |  Loss2: (0.0000) | Acc: (93.00%) (39569/42368)
Epoch: 112 | Batch_idx: 340 |  Loss: (0.1863) |  Loss2: (0.0000) | Acc: (93.00%) (40768/43648)
Epoch: 112 | Batch_idx: 350 |  Loss: (0.1868) |  Loss2: (0.0000) | Acc: (93.00%) (41955/44928)
Epoch: 112 | Batch_idx: 360 |  Loss: (0.1870) |  Loss2: (0.0000) | Acc: (93.00%) (43141/46208)
Epoch: 112 | Batch_idx: 370 |  Loss: (0.1875) |  Loss2: (0.0000) | Acc: (93.00%) (44332/47488)
Epoch: 112 | Batch_idx: 380 |  Loss: (0.1877) |  Loss2: (0.0000) | Acc: (93.00%) (45532/48768)
Epoch: 112 | Batch_idx: 390 |  Loss: (0.1877) |  Loss2: (0.0000) | Acc: (93.00%) (46688/50000)
# TEST : Loss: (0.4032) | Acc: (86.00%) (8699/10000)
percent tensor([0.5519, 0.5313, 0.5763, 0.5682, 0.5728, 0.5522, 0.5468, 0.5653, 0.5583,
        0.5481, 0.5451, 0.5639, 0.5460, 0.5343, 0.5424, 0.5473],
       device='cuda:0') torch.Size([16])
percent tensor([0.5149, 0.5200, 0.5117, 0.5189, 0.5136, 0.5314, 0.5156, 0.5119, 0.5096,
        0.5115, 0.5111, 0.5073, 0.5077, 0.5261, 0.5207, 0.5195],
       device='cuda:0') torch.Size([16])
percent tensor([0.5749, 0.6524, 0.5171, 0.4696, 0.5105, 0.4853, 0.6082, 0.5357, 0.5756,
        0.6128, 0.6130, 0.5857, 0.6714, 0.5431, 0.5923, 0.5550],
       device='cuda:0') torch.Size([16])
percent tensor([0.6729, 0.6637, 0.6954, 0.7085, 0.7025, 0.6783, 0.6923, 0.6929, 0.6919,
        0.6809, 0.7061, 0.7051, 0.6641, 0.6975, 0.6859, 0.6780],
       device='cuda:0') torch.Size([16])
percent tensor([0.6530, 0.6562, 0.6917, 0.6315, 0.6742, 0.8008, 0.6681, 0.6135, 0.6825,
        0.6548, 0.6989, 0.6037, 0.6946, 0.7214, 0.6557, 0.7077],
       device='cuda:0') torch.Size([16])
percent tensor([0.5702, 0.6857, 0.5643, 0.5367, 0.5261, 0.5895, 0.5545, 0.4053, 0.6581,
        0.6423, 0.7195, 0.6205, 0.7061, 0.7288, 0.4787, 0.5874],
       device='cuda:0') torch.Size([16])
percent tensor([0.5834, 0.5968, 0.7869, 0.7751, 0.8401, 0.6810, 0.6669, 0.7104, 0.6319,
        0.6399, 0.6136, 0.7537, 0.6210, 0.6818, 0.6017, 0.6316],
       device='cuda:0') torch.Size([16])
percent tensor([0.9996, 0.9986, 0.9994, 0.9994, 0.9992, 0.9985, 0.9989, 0.9994, 0.9985,
        0.9990, 0.9992, 0.9992, 0.9993, 0.9990, 0.9991, 0.9994],
       device='cuda:0') torch.Size([16])
Epoch: 113 | Batch_idx: 0 |  Loss: (0.0971) |  Loss2: (0.0000) | Acc: (95.00%) (122/128)
Epoch: 113 | Batch_idx: 10 |  Loss: (0.1692) |  Loss2: (0.0000) | Acc: (94.00%) (1329/1408)
Epoch: 113 | Batch_idx: 20 |  Loss: (0.1721) |  Loss2: (0.0000) | Acc: (94.00%) (2543/2688)
Epoch: 113 | Batch_idx: 30 |  Loss: (0.1664) |  Loss2: (0.0000) | Acc: (94.00%) (3757/3968)
Epoch: 113 | Batch_idx: 40 |  Loss: (0.1702) |  Loss2: (0.0000) | Acc: (94.00%) (4961/5248)
Epoch: 113 | Batch_idx: 50 |  Loss: (0.1683) |  Loss2: (0.0000) | Acc: (94.00%) (6167/6528)
Epoch: 113 | Batch_idx: 60 |  Loss: (0.1665) |  Loss2: (0.0000) | Acc: (94.00%) (7378/7808)
Epoch: 113 | Batch_idx: 70 |  Loss: (0.1653) |  Loss2: (0.0000) | Acc: (94.00%) (8590/9088)
Epoch: 113 | Batch_idx: 80 |  Loss: (0.1674) |  Loss2: (0.0000) | Acc: (94.00%) (9790/10368)
Epoch: 113 | Batch_idx: 90 |  Loss: (0.1682) |  Loss2: (0.0000) | Acc: (94.00%) (11000/11648)
Epoch: 113 | Batch_idx: 100 |  Loss: (0.1707) |  Loss2: (0.0000) | Acc: (94.00%) (12194/12928)
Epoch: 113 | Batch_idx: 110 |  Loss: (0.1723) |  Loss2: (0.0000) | Acc: (94.00%) (13399/14208)
Epoch: 113 | Batch_idx: 120 |  Loss: (0.1743) |  Loss2: (0.0000) | Acc: (94.00%) (14582/15488)
Epoch: 113 | Batch_idx: 130 |  Loss: (0.1758) |  Loss2: (0.0000) | Acc: (94.00%) (15773/16768)
Epoch: 113 | Batch_idx: 140 |  Loss: (0.1765) |  Loss2: (0.0000) | Acc: (94.00%) (16969/18048)
Epoch: 113 | Batch_idx: 150 |  Loss: (0.1771) |  Loss2: (0.0000) | Acc: (93.00%) (18162/19328)
Epoch: 113 | Batch_idx: 160 |  Loss: (0.1776) |  Loss2: (0.0000) | Acc: (93.00%) (19367/20608)
Epoch: 113 | Batch_idx: 170 |  Loss: (0.1780) |  Loss2: (0.0000) | Acc: (93.00%) (20563/21888)
Epoch: 113 | Batch_idx: 180 |  Loss: (0.1772) |  Loss2: (0.0000) | Acc: (93.00%) (21767/23168)
Epoch: 113 | Batch_idx: 190 |  Loss: (0.1775) |  Loss2: (0.0000) | Acc: (93.00%) (22973/24448)
Epoch: 113 | Batch_idx: 200 |  Loss: (0.1780) |  Loss2: (0.0000) | Acc: (93.00%) (24168/25728)
Epoch: 113 | Batch_idx: 210 |  Loss: (0.1774) |  Loss2: (0.0000) | Acc: (93.00%) (25377/27008)
Epoch: 113 | Batch_idx: 220 |  Loss: (0.1777) |  Loss2: (0.0000) | Acc: (93.00%) (26573/28288)
Epoch: 113 | Batch_idx: 230 |  Loss: (0.1787) |  Loss2: (0.0000) | Acc: (93.00%) (27772/29568)
Epoch: 113 | Batch_idx: 240 |  Loss: (0.1792) |  Loss2: (0.0000) | Acc: (93.00%) (28960/30848)
Epoch: 113 | Batch_idx: 250 |  Loss: (0.1795) |  Loss2: (0.0000) | Acc: (93.00%) (30159/32128)
Epoch: 113 | Batch_idx: 260 |  Loss: (0.1806) |  Loss2: (0.0000) | Acc: (93.00%) (31355/33408)
Epoch: 113 | Batch_idx: 270 |  Loss: (0.1809) |  Loss2: (0.0000) | Acc: (93.00%) (32543/34688)
Epoch: 113 | Batch_idx: 280 |  Loss: (0.1810) |  Loss2: (0.0000) | Acc: (93.00%) (33739/35968)
Epoch: 113 | Batch_idx: 290 |  Loss: (0.1800) |  Loss2: (0.0000) | Acc: (93.00%) (34952/37248)
Epoch: 113 | Batch_idx: 300 |  Loss: (0.1813) |  Loss2: (0.0000) | Acc: (93.00%) (36134/38528)
Epoch: 113 | Batch_idx: 310 |  Loss: (0.1824) |  Loss2: (0.0000) | Acc: (93.00%) (37329/39808)
Epoch: 113 | Batch_idx: 320 |  Loss: (0.1823) |  Loss2: (0.0000) | Acc: (93.00%) (38528/41088)
Epoch: 113 | Batch_idx: 330 |  Loss: (0.1822) |  Loss2: (0.0000) | Acc: (93.00%) (39722/42368)
Epoch: 113 | Batch_idx: 340 |  Loss: (0.1829) |  Loss2: (0.0000) | Acc: (93.00%) (40918/43648)
Epoch: 113 | Batch_idx: 350 |  Loss: (0.1836) |  Loss2: (0.0000) | Acc: (93.00%) (42110/44928)
Epoch: 113 | Batch_idx: 360 |  Loss: (0.1829) |  Loss2: (0.0000) | Acc: (93.00%) (43325/46208)
Epoch: 113 | Batch_idx: 370 |  Loss: (0.1832) |  Loss2: (0.0000) | Acc: (93.00%) (44513/47488)
Epoch: 113 | Batch_idx: 380 |  Loss: (0.1832) |  Loss2: (0.0000) | Acc: (93.00%) (45715/48768)
Epoch: 113 | Batch_idx: 390 |  Loss: (0.1831) |  Loss2: (0.0000) | Acc: (93.00%) (46876/50000)
# TEST : Loss: (0.3967) | Acc: (87.00%) (8742/10000)
percent tensor([0.5504, 0.5334, 0.5746, 0.5675, 0.5706, 0.5510, 0.5473, 0.5668, 0.5593,
        0.5478, 0.5449, 0.5617, 0.5449, 0.5399, 0.5423, 0.5474],
       device='cuda:0') torch.Size([16])
percent tensor([0.5159, 0.5197, 0.5108, 0.5188, 0.5125, 0.5338, 0.5151, 0.5119, 0.5113,
        0.5100, 0.5124, 0.5064, 0.5080, 0.5270, 0.5214, 0.5203],
       device='cuda:0') torch.Size([16])
percent tensor([0.5770, 0.6478, 0.5385, 0.4790, 0.5270, 0.4783, 0.6102, 0.5402, 0.5625,
        0.6276, 0.6102, 0.6040, 0.6782, 0.5102, 0.5908, 0.5534],
       device='cuda:0') torch.Size([16])
percent tensor([0.6695, 0.6608, 0.6865, 0.7091, 0.6984, 0.6838, 0.6917, 0.6897, 0.6964,
        0.6704, 0.7021, 0.7009, 0.6613, 0.7003, 0.6834, 0.6792],
       device='cuda:0') torch.Size([16])
percent tensor([0.6497, 0.6383, 0.6840, 0.6517, 0.6677, 0.8133, 0.6591, 0.6064, 0.6864,
        0.6310, 0.6843, 0.5947, 0.6789, 0.7010, 0.6451, 0.7145],
       device='cuda:0') torch.Size([16])
percent tensor([0.5763, 0.6891, 0.5588, 0.5298, 0.5331, 0.5967, 0.5612, 0.4083, 0.6562,
        0.6463, 0.7108, 0.6169, 0.6923, 0.7334, 0.4836, 0.5748],
       device='cuda:0') torch.Size([16])
percent tensor([0.5622, 0.6070, 0.7744, 0.7626, 0.8476, 0.7023, 0.6629, 0.7096, 0.6855,
        0.6306, 0.6228, 0.7567, 0.6523, 0.6821, 0.5990, 0.6248],
       device='cuda:0') torch.Size([16])
percent tensor([0.9996, 0.9982, 0.9991, 0.9991, 0.9993, 0.9987, 0.9990, 0.9990, 0.9988,
        0.9990, 0.9992, 0.9991, 0.9987, 0.9983, 0.9989, 0.9992],
       device='cuda:0') torch.Size([16])
Epoch: 114 | Batch_idx: 0 |  Loss: (0.1386) |  Loss2: (0.0000) | Acc: (96.00%) (123/128)
Epoch: 114 | Batch_idx: 10 |  Loss: (0.1619) |  Loss2: (0.0000) | Acc: (94.00%) (1326/1408)
Epoch: 114 | Batch_idx: 20 |  Loss: (0.1666) |  Loss2: (0.0000) | Acc: (94.00%) (2531/2688)
Epoch: 114 | Batch_idx: 30 |  Loss: (0.1688) |  Loss2: (0.0000) | Acc: (94.00%) (3735/3968)
Epoch: 114 | Batch_idx: 40 |  Loss: (0.1700) |  Loss2: (0.0000) | Acc: (94.00%) (4935/5248)
Epoch: 114 | Batch_idx: 50 |  Loss: (0.1672) |  Loss2: (0.0000) | Acc: (94.00%) (6149/6528)
Epoch: 114 | Batch_idx: 60 |  Loss: (0.1678) |  Loss2: (0.0000) | Acc: (94.00%) (7364/7808)
Epoch: 114 | Batch_idx: 70 |  Loss: (0.1689) |  Loss2: (0.0000) | Acc: (94.00%) (8564/9088)
Epoch: 114 | Batch_idx: 80 |  Loss: (0.1713) |  Loss2: (0.0000) | Acc: (94.00%) (9763/10368)
Epoch: 114 | Batch_idx: 90 |  Loss: (0.1706) |  Loss2: (0.0000) | Acc: (94.00%) (10975/11648)
Epoch: 114 | Batch_idx: 100 |  Loss: (0.1677) |  Loss2: (0.0000) | Acc: (94.00%) (12194/12928)
Epoch: 114 | Batch_idx: 110 |  Loss: (0.1701) |  Loss2: (0.0000) | Acc: (94.00%) (13385/14208)
Epoch: 114 | Batch_idx: 120 |  Loss: (0.1706) |  Loss2: (0.0000) | Acc: (94.00%) (14583/15488)
Epoch: 114 | Batch_idx: 130 |  Loss: (0.1709) |  Loss2: (0.0000) | Acc: (94.00%) (15784/16768)
Epoch: 114 | Batch_idx: 140 |  Loss: (0.1713) |  Loss2: (0.0000) | Acc: (94.00%) (16988/18048)
Epoch: 114 | Batch_idx: 150 |  Loss: (0.1692) |  Loss2: (0.0000) | Acc: (94.00%) (18211/19328)
Epoch: 114 | Batch_idx: 160 |  Loss: (0.1699) |  Loss2: (0.0000) | Acc: (94.00%) (19403/20608)
Epoch: 114 | Batch_idx: 170 |  Loss: (0.1707) |  Loss2: (0.0000) | Acc: (94.00%) (20595/21888)
Epoch: 114 | Batch_idx: 180 |  Loss: (0.1721) |  Loss2: (0.0000) | Acc: (94.00%) (21785/23168)
Epoch: 114 | Batch_idx: 190 |  Loss: (0.1712) |  Loss2: (0.0000) | Acc: (94.00%) (22995/24448)
Epoch: 114 | Batch_idx: 200 |  Loss: (0.1726) |  Loss2: (0.0000) | Acc: (94.00%) (24185/25728)
Epoch: 114 | Batch_idx: 210 |  Loss: (0.1729) |  Loss2: (0.0000) | Acc: (93.00%) (25384/27008)
Epoch: 114 | Batch_idx: 220 |  Loss: (0.1728) |  Loss2: (0.0000) | Acc: (93.00%) (26580/28288)
Epoch: 114 | Batch_idx: 230 |  Loss: (0.1731) |  Loss2: (0.0000) | Acc: (93.00%) (27785/29568)
Epoch: 114 | Batch_idx: 240 |  Loss: (0.1731) |  Loss2: (0.0000) | Acc: (93.00%) (28983/30848)
Epoch: 114 | Batch_idx: 250 |  Loss: (0.1740) |  Loss2: (0.0000) | Acc: (93.00%) (30176/32128)
Epoch: 114 | Batch_idx: 260 |  Loss: (0.1731) |  Loss2: (0.0000) | Acc: (93.00%) (31384/33408)
Epoch: 114 | Batch_idx: 270 |  Loss: (0.1733) |  Loss2: (0.0000) | Acc: (93.00%) (32584/34688)
Epoch: 114 | Batch_idx: 280 |  Loss: (0.1725) |  Loss2: (0.0000) | Acc: (93.00%) (33798/35968)
Epoch: 114 | Batch_idx: 290 |  Loss: (0.1725) |  Loss2: (0.0000) | Acc: (93.00%) (34999/37248)
Epoch: 114 | Batch_idx: 300 |  Loss: (0.1735) |  Loss2: (0.0000) | Acc: (93.00%) (36192/38528)
Epoch: 114 | Batch_idx: 310 |  Loss: (0.1730) |  Loss2: (0.0000) | Acc: (93.00%) (37409/39808)
Epoch: 114 | Batch_idx: 320 |  Loss: (0.1739) |  Loss2: (0.0000) | Acc: (93.00%) (38592/41088)
Epoch: 114 | Batch_idx: 330 |  Loss: (0.1730) |  Loss2: (0.0000) | Acc: (93.00%) (39818/42368)
Epoch: 114 | Batch_idx: 340 |  Loss: (0.1735) |  Loss2: (0.0000) | Acc: (93.00%) (41015/43648)
Epoch: 114 | Batch_idx: 350 |  Loss: (0.1736) |  Loss2: (0.0000) | Acc: (93.00%) (42219/44928)
Epoch: 114 | Batch_idx: 360 |  Loss: (0.1736) |  Loss2: (0.0000) | Acc: (93.00%) (43417/46208)
Epoch: 114 | Batch_idx: 370 |  Loss: (0.1741) |  Loss2: (0.0000) | Acc: (93.00%) (44612/47488)
Epoch: 114 | Batch_idx: 380 |  Loss: (0.1738) |  Loss2: (0.0000) | Acc: (93.00%) (45824/48768)
Epoch: 114 | Batch_idx: 390 |  Loss: (0.1738) |  Loss2: (0.0000) | Acc: (93.00%) (46983/50000)
# TEST : Loss: (0.4158) | Acc: (86.00%) (8688/10000)
percent tensor([0.5492, 0.5328, 0.5760, 0.5691, 0.5712, 0.5492, 0.5470, 0.5664, 0.5570,
        0.5478, 0.5432, 0.5625, 0.5438, 0.5383, 0.5419, 0.5463],
       device='cuda:0') torch.Size([16])
percent tensor([0.5147, 0.5188, 0.5131, 0.5174, 0.5135, 0.5318, 0.5142, 0.5125, 0.5091,
        0.5103, 0.5102, 0.5065, 0.5068, 0.5234, 0.5205, 0.5186],
       device='cuda:0') torch.Size([16])
percent tensor([0.5909, 0.6474, 0.5362, 0.4819, 0.5327, 0.5020, 0.6110, 0.5422, 0.5809,
        0.6227, 0.6222, 0.6026, 0.6834, 0.5146, 0.6006, 0.5661],
       device='cuda:0') torch.Size([16])
percent tensor([0.6755, 0.6665, 0.6956, 0.7061, 0.7025, 0.6776, 0.6983, 0.6970, 0.6967,
        0.6802, 0.7066, 0.7043, 0.6643, 0.7054, 0.6895, 0.6796],
       device='cuda:0') torch.Size([16])
percent tensor([0.6523, 0.6303, 0.6820, 0.6308, 0.6698, 0.8163, 0.6485, 0.6066, 0.6770,
        0.6415, 0.6680, 0.6150, 0.6928, 0.6954, 0.6488, 0.7089],
       device='cuda:0') torch.Size([16])
percent tensor([0.5653, 0.6695, 0.5494, 0.5208, 0.5310, 0.5693, 0.5497, 0.3983, 0.6628,
        0.6343, 0.6991, 0.5904, 0.7033, 0.7211, 0.4409, 0.5731],
       device='cuda:0') torch.Size([16])
percent tensor([0.5709, 0.5955, 0.8004, 0.7687, 0.8451, 0.6714, 0.6920, 0.7201, 0.6142,
        0.6301, 0.6096, 0.7637, 0.5993, 0.7058, 0.6198, 0.6434],
       device='cuda:0') torch.Size([16])
percent tensor([0.9995, 0.9987, 0.9992, 0.9994, 0.9991, 0.9987, 0.9989, 0.9993, 0.9988,
        0.9992, 0.9990, 0.9991, 0.9989, 0.9986, 0.9990, 0.9993],
       device='cuda:0') torch.Size([16])
False Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=128, out_features=16, bias=False)
True Linear(in_features=16, out_features=2, bias=False)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=128, out_features=16, bias=False)
True Linear(in_features=16, out_features=2, bias=False)
False Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=256, out_features=32, bias=False)
True Linear(in_features=32, out_features=2, bias=False)
False Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=256, out_features=32, bias=False)
True Linear(in_features=32, out_features=2, bias=False)
False Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=512, out_features=64, bias=False)
True Linear(in_features=64, out_features=2, bias=False)
False Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=512, out_features=64, bias=False)
True Linear(in_features=64, out_features=2, bias=False)
False Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1024, out_features=128, bias=False)
True Linear(in_features=128, out_features=2, bias=False)
False Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1024, out_features=128, bias=False)
True Linear(in_features=128, out_features=2, bias=False)
False Linear(in_features=512, out_features=10, bias=True)
Epoch: 115 | Batch_idx: 0 |  Loss: (0.1696) |  Loss2: (0.0000) | Acc: (93.00%) (120/128)
Epoch: 115 | Batch_idx: 10 |  Loss: (0.1676) |  Loss2: (0.0000) | Acc: (94.00%) (1328/1408)
Epoch: 115 | Batch_idx: 20 |  Loss: (0.1810) |  Loss2: (0.0000) | Acc: (93.00%) (2519/2688)
Epoch: 115 | Batch_idx: 30 |  Loss: (0.1809) |  Loss2: (0.0000) | Acc: (93.00%) (3719/3968)
Epoch: 115 | Batch_idx: 40 |  Loss: (0.1851) |  Loss2: (0.0000) | Acc: (93.00%) (4903/5248)
Epoch: 115 | Batch_idx: 50 |  Loss: (0.1923) |  Loss2: (0.0000) | Acc: (93.00%) (6080/6528)
Epoch: 115 | Batch_idx: 60 |  Loss: (0.1954) |  Loss2: (0.0000) | Acc: (93.00%) (7264/7808)
Epoch: 115 | Batch_idx: 70 |  Loss: (0.1943) |  Loss2: (0.0000) | Acc: (93.00%) (8458/9088)
Epoch: 115 | Batch_idx: 80 |  Loss: (0.1944) |  Loss2: (0.0000) | Acc: (93.00%) (9651/10368)
Epoch: 115 | Batch_idx: 90 |  Loss: (0.1951) |  Loss2: (0.0000) | Acc: (92.00%) (10831/11648)
Epoch: 115 | Batch_idx: 100 |  Loss: (0.1976) |  Loss2: (0.0000) | Acc: (92.00%) (12023/12928)
Epoch: 115 | Batch_idx: 110 |  Loss: (0.1992) |  Loss2: (0.0000) | Acc: (92.00%) (13199/14208)
Epoch: 115 | Batch_idx: 120 |  Loss: (0.1976) |  Loss2: (0.0000) | Acc: (93.00%) (14406/15488)
Epoch: 115 | Batch_idx: 130 |  Loss: (0.1992) |  Loss2: (0.0000) | Acc: (92.00%) (15592/16768)
Epoch: 115 | Batch_idx: 140 |  Loss: (0.1999) |  Loss2: (0.0000) | Acc: (92.00%) (16776/18048)
Epoch: 115 | Batch_idx: 150 |  Loss: (0.1991) |  Loss2: (0.0000) | Acc: (93.00%) (17976/19328)
Epoch: 115 | Batch_idx: 160 |  Loss: (0.1989) |  Loss2: (0.0000) | Acc: (92.00%) (19164/20608)
Epoch: 115 | Batch_idx: 170 |  Loss: (0.1996) |  Loss2: (0.0000) | Acc: (92.00%) (20339/21888)
Epoch: 115 | Batch_idx: 180 |  Loss: (0.1990) |  Loss2: (0.0000) | Acc: (92.00%) (21532/23168)
Epoch: 115 | Batch_idx: 190 |  Loss: (0.1984) |  Loss2: (0.0000) | Acc: (92.00%) (22720/24448)
Epoch: 115 | Batch_idx: 200 |  Loss: (0.1979) |  Loss2: (0.0000) | Acc: (92.00%) (23905/25728)
Epoch: 115 | Batch_idx: 210 |  Loss: (0.1982) |  Loss2: (0.0000) | Acc: (92.00%) (25089/27008)
Epoch: 115 | Batch_idx: 220 |  Loss: (0.1986) |  Loss2: (0.0000) | Acc: (92.00%) (26274/28288)
Epoch: 115 | Batch_idx: 230 |  Loss: (0.1979) |  Loss2: (0.0000) | Acc: (92.00%) (27468/29568)
Epoch: 115 | Batch_idx: 240 |  Loss: (0.1966) |  Loss2: (0.0000) | Acc: (92.00%) (28669/30848)
Epoch: 115 | Batch_idx: 250 |  Loss: (0.1970) |  Loss2: (0.0000) | Acc: (92.00%) (29858/32128)
Epoch: 115 | Batch_idx: 260 |  Loss: (0.1960) |  Loss2: (0.0000) | Acc: (93.00%) (31075/33408)
Epoch: 115 | Batch_idx: 270 |  Loss: (0.1969) |  Loss2: (0.0000) | Acc: (92.00%) (32250/34688)
Epoch: 115 | Batch_idx: 280 |  Loss: (0.1956) |  Loss2: (0.0000) | Acc: (93.00%) (33456/35968)
Epoch: 115 | Batch_idx: 290 |  Loss: (0.1950) |  Loss2: (0.0000) | Acc: (93.00%) (34653/37248)
Epoch: 115 | Batch_idx: 300 |  Loss: (0.1952) |  Loss2: (0.0000) | Acc: (93.00%) (35845/38528)
Epoch: 115 | Batch_idx: 310 |  Loss: (0.1944) |  Loss2: (0.0000) | Acc: (93.00%) (37048/39808)
Epoch: 115 | Batch_idx: 320 |  Loss: (0.1942) |  Loss2: (0.0000) | Acc: (93.00%) (38244/41088)
Epoch: 115 | Batch_idx: 330 |  Loss: (0.1939) |  Loss2: (0.0000) | Acc: (93.00%) (39436/42368)
Epoch: 115 | Batch_idx: 340 |  Loss: (0.1939) |  Loss2: (0.0000) | Acc: (93.00%) (40627/43648)
Epoch: 115 | Batch_idx: 350 |  Loss: (0.1939) |  Loss2: (0.0000) | Acc: (93.00%) (41817/44928)
Epoch: 115 | Batch_idx: 360 |  Loss: (0.1930) |  Loss2: (0.0000) | Acc: (93.00%) (43032/46208)
Epoch: 115 | Batch_idx: 370 |  Loss: (0.1938) |  Loss2: (0.0000) | Acc: (93.00%) (44215/47488)
Epoch: 115 | Batch_idx: 380 |  Loss: (0.1931) |  Loss2: (0.0000) | Acc: (93.00%) (45421/48768)
Epoch: 115 | Batch_idx: 390 |  Loss: (0.1936) |  Loss2: (0.0000) | Acc: (93.00%) (46562/50000)
=> saving checkpoint 'drive/app/torch/save_Routing_Gate_2/checkpoint_115.pth.tar'
# TEST : Loss: (0.3852) | Acc: (87.00%) (8760/10000)
percent tensor([0.5483, 0.5317, 0.5692, 0.5648, 0.5660, 0.5477, 0.5447, 0.5624, 0.5563,
        0.5458, 0.5432, 0.5574, 0.5435, 0.5378, 0.5397, 0.5450],
       device='cuda:0') torch.Size([16])
percent tensor([0.5151, 0.5195, 0.5120, 0.5185, 0.5133, 0.5327, 0.5154, 0.5128, 0.5088,
        0.5113, 0.5106, 0.5067, 0.5075, 0.5241, 0.5214, 0.5197],
       device='cuda:0') torch.Size([16])
percent tensor([0.6108, 0.6692, 0.5551, 0.4945, 0.5469, 0.5378, 0.6287, 0.5490, 0.5914,
        0.6335, 0.6411, 0.6217, 0.6995, 0.5297, 0.6299, 0.5861],
       device='cuda:0') torch.Size([16])
percent tensor([0.6719, 0.6614, 0.6874, 0.6997, 0.6960, 0.6751, 0.6921, 0.6916, 0.6919,
        0.6746, 0.6993, 0.6972, 0.6613, 0.6961, 0.6851, 0.6755],
       device='cuda:0') torch.Size([16])
percent tensor([0.6496, 0.6304, 0.7007, 0.6139, 0.6757, 0.8140, 0.6480, 0.6007, 0.6925,
        0.6380, 0.6793, 0.6347, 0.7044, 0.7157, 0.6482, 0.6982],
       device='cuda:0') torch.Size([16])
percent tensor([0.5939, 0.6887, 0.5657, 0.5417, 0.5465, 0.5948, 0.5748, 0.3962, 0.6952,
        0.6486, 0.7364, 0.6051, 0.7269, 0.7555, 0.4701, 0.5870],
       device='cuda:0') torch.Size([16])
percent tensor([0.5350, 0.5811, 0.7894, 0.7643, 0.8315, 0.6867, 0.6484, 0.6998, 0.6357,
        0.6049, 0.6009, 0.7450, 0.6006, 0.6931, 0.6010, 0.5814],
       device='cuda:0') torch.Size([16])
percent tensor([0.9994, 0.9987, 0.9989, 0.9991, 0.9990, 0.9982, 0.9990, 0.9991, 0.9988,
        0.9991, 0.9991, 0.9991, 0.9988, 0.9988, 0.9989, 0.9992],
       device='cuda:0') torch.Size([16])
Epoch: 116 | Batch_idx: 0 |  Loss: (0.2072) |  Loss2: (0.0000) | Acc: (92.00%) (118/128)
Epoch: 116 | Batch_idx: 10 |  Loss: (0.1999) |  Loss2: (0.0000) | Acc: (92.00%) (1308/1408)
Epoch: 116 | Batch_idx: 20 |  Loss: (0.1773) |  Loss2: (0.0000) | Acc: (93.00%) (2522/2688)
Epoch: 116 | Batch_idx: 30 |  Loss: (0.1798) |  Loss2: (0.0000) | Acc: (93.00%) (3718/3968)
Epoch: 116 | Batch_idx: 40 |  Loss: (0.1760) |  Loss2: (0.0000) | Acc: (94.00%) (4935/5248)
Epoch: 116 | Batch_idx: 50 |  Loss: (0.1774) |  Loss2: (0.0000) | Acc: (93.00%) (6129/6528)
Epoch: 116 | Batch_idx: 60 |  Loss: (0.1747) |  Loss2: (0.0000) | Acc: (93.00%) (7334/7808)
Epoch: 116 | Batch_idx: 70 |  Loss: (0.1778) |  Loss2: (0.0000) | Acc: (93.00%) (8538/9088)
Epoch: 116 | Batch_idx: 80 |  Loss: (0.1823) |  Loss2: (0.0000) | Acc: (93.00%) (9716/10368)
Epoch: 116 | Batch_idx: 90 |  Loss: (0.1844) |  Loss2: (0.0000) | Acc: (93.00%) (10906/11648)
Epoch: 116 | Batch_idx: 100 |  Loss: (0.1820) |  Loss2: (0.0000) | Acc: (93.00%) (12115/12928)
Epoch: 116 | Batch_idx: 110 |  Loss: (0.1821) |  Loss2: (0.0000) | Acc: (93.00%) (13317/14208)
Epoch: 116 | Batch_idx: 120 |  Loss: (0.1821) |  Loss2: (0.0000) | Acc: (93.00%) (14514/15488)
Epoch: 116 | Batch_idx: 130 |  Loss: (0.1834) |  Loss2: (0.0000) | Acc: (93.00%) (15706/16768)
Epoch: 116 | Batch_idx: 140 |  Loss: (0.1845) |  Loss2: (0.0000) | Acc: (93.00%) (16893/18048)
Epoch: 116 | Batch_idx: 150 |  Loss: (0.1844) |  Loss2: (0.0000) | Acc: (93.00%) (18099/19328)
Epoch: 116 | Batch_idx: 160 |  Loss: (0.1834) |  Loss2: (0.0000) | Acc: (93.00%) (19300/20608)
Epoch: 116 | Batch_idx: 170 |  Loss: (0.1831) |  Loss2: (0.0000) | Acc: (93.00%) (20503/21888)
Epoch: 116 | Batch_idx: 180 |  Loss: (0.1831) |  Loss2: (0.0000) | Acc: (93.00%) (21701/23168)
Epoch: 116 | Batch_idx: 190 |  Loss: (0.1824) |  Loss2: (0.0000) | Acc: (93.00%) (22908/24448)
Epoch: 116 | Batch_idx: 200 |  Loss: (0.1816) |  Loss2: (0.0000) | Acc: (93.00%) (24118/25728)
Epoch: 116 | Batch_idx: 210 |  Loss: (0.1820) |  Loss2: (0.0000) | Acc: (93.00%) (25323/27008)
Epoch: 116 | Batch_idx: 220 |  Loss: (0.1830) |  Loss2: (0.0000) | Acc: (93.00%) (26515/28288)
Epoch: 116 | Batch_idx: 230 |  Loss: (0.1837) |  Loss2: (0.0000) | Acc: (93.00%) (27710/29568)
Epoch: 116 | Batch_idx: 240 |  Loss: (0.1835) |  Loss2: (0.0000) | Acc: (93.00%) (28904/30848)
Epoch: 116 | Batch_idx: 250 |  Loss: (0.1833) |  Loss2: (0.0000) | Acc: (93.00%) (30105/32128)
Epoch: 116 | Batch_idx: 260 |  Loss: (0.1837) |  Loss2: (0.0000) | Acc: (93.00%) (31295/33408)
Epoch: 116 | Batch_idx: 270 |  Loss: (0.1831) |  Loss2: (0.0000) | Acc: (93.00%) (32501/34688)
Epoch: 116 | Batch_idx: 280 |  Loss: (0.1829) |  Loss2: (0.0000) | Acc: (93.00%) (33698/35968)
Epoch: 116 | Batch_idx: 290 |  Loss: (0.1826) |  Loss2: (0.0000) | Acc: (93.00%) (34905/37248)
Epoch: 116 | Batch_idx: 300 |  Loss: (0.1824) |  Loss2: (0.0000) | Acc: (93.00%) (36111/38528)
Epoch: 116 | Batch_idx: 310 |  Loss: (0.1813) |  Loss2: (0.0000) | Acc: (93.00%) (37326/39808)
Epoch: 116 | Batch_idx: 320 |  Loss: (0.1820) |  Loss2: (0.0000) | Acc: (93.00%) (38514/41088)
Epoch: 116 | Batch_idx: 330 |  Loss: (0.1824) |  Loss2: (0.0000) | Acc: (93.00%) (39704/42368)
Epoch: 116 | Batch_idx: 340 |  Loss: (0.1827) |  Loss2: (0.0000) | Acc: (93.00%) (40899/43648)
Epoch: 116 | Batch_idx: 350 |  Loss: (0.1824) |  Loss2: (0.0000) | Acc: (93.00%) (42103/44928)
Epoch: 116 | Batch_idx: 360 |  Loss: (0.1816) |  Loss2: (0.0000) | Acc: (93.00%) (43318/46208)
Epoch: 116 | Batch_idx: 370 |  Loss: (0.1812) |  Loss2: (0.0000) | Acc: (93.00%) (44519/47488)
Epoch: 116 | Batch_idx: 380 |  Loss: (0.1817) |  Loss2: (0.0000) | Acc: (93.00%) (45698/48768)
Epoch: 116 | Batch_idx: 390 |  Loss: (0.1813) |  Loss2: (0.0000) | Acc: (93.00%) (46863/50000)
# TEST : Loss: (0.3749) | Acc: (87.00%) (8781/10000)
percent tensor([0.5491, 0.5315, 0.5686, 0.5629, 0.5654, 0.5484, 0.5449, 0.5608, 0.5567,
        0.5458, 0.5441, 0.5572, 0.5441, 0.5372, 0.5395, 0.5449],
       device='cuda:0') torch.Size([16])
percent tensor([0.5171, 0.5219, 0.5142, 0.5206, 0.5157, 0.5344, 0.5180, 0.5148, 0.5109,
        0.5136, 0.5128, 0.5090, 0.5098, 0.5261, 0.5236, 0.5218],
       device='cuda:0') torch.Size([16])
percent tensor([0.6070, 0.6660, 0.5541, 0.4945, 0.5439, 0.5408, 0.6241, 0.5457, 0.5861,
        0.6310, 0.6376, 0.6210, 0.6975, 0.5224, 0.6301, 0.5842],
       device='cuda:0') torch.Size([16])
percent tensor([0.6845, 0.6717, 0.6983, 0.7093, 0.7065, 0.6863, 0.7032, 0.7034, 0.7015,
        0.6849, 0.7085, 0.7080, 0.6730, 0.7046, 0.6972, 0.6869],
       device='cuda:0') torch.Size([16])
percent tensor([0.6457, 0.6307, 0.7007, 0.6221, 0.6767, 0.8127, 0.6459, 0.6041, 0.6981,
        0.6356, 0.6843, 0.6406, 0.7081, 0.7196, 0.6514, 0.6940],
       device='cuda:0') torch.Size([16])
percent tensor([0.5986, 0.6962, 0.5654, 0.5379, 0.5369, 0.5950, 0.5750, 0.3869, 0.7028,
        0.6577, 0.7502, 0.6132, 0.7373, 0.7636, 0.4763, 0.5852],
       device='cuda:0') torch.Size([16])
percent tensor([0.5221, 0.5833, 0.7943, 0.7602, 0.8303, 0.6947, 0.6323, 0.6895, 0.6437,
        0.6029, 0.6103, 0.7451, 0.6083, 0.6816, 0.6035, 0.5545],
       device='cuda:0') torch.Size([16])
percent tensor([0.9995, 0.9987, 0.9990, 0.9992, 0.9990, 0.9983, 0.9990, 0.9991, 0.9989,
        0.9992, 0.9992, 0.9992, 0.9990, 0.9989, 0.9990, 0.9992],
       device='cuda:0') torch.Size([16])
Epoch: 117 | Batch_idx: 0 |  Loss: (0.1519) |  Loss2: (0.0000) | Acc: (95.00%) (122/128)
Epoch: 117 | Batch_idx: 10 |  Loss: (0.1667) |  Loss2: (0.0000) | Acc: (94.00%) (1325/1408)
Epoch: 117 | Batch_idx: 20 |  Loss: (0.1683) |  Loss2: (0.0000) | Acc: (94.00%) (2533/2688)
Epoch: 117 | Batch_idx: 30 |  Loss: (0.1657) |  Loss2: (0.0000) | Acc: (94.00%) (3742/3968)
Epoch: 117 | Batch_idx: 40 |  Loss: (0.1642) |  Loss2: (0.0000) | Acc: (94.00%) (4948/5248)
Epoch: 117 | Batch_idx: 50 |  Loss: (0.1626) |  Loss2: (0.0000) | Acc: (94.00%) (6155/6528)
Epoch: 117 | Batch_idx: 60 |  Loss: (0.1640) |  Loss2: (0.0000) | Acc: (94.00%) (7353/7808)
Epoch: 117 | Batch_idx: 70 |  Loss: (0.1636) |  Loss2: (0.0000) | Acc: (94.00%) (8555/9088)
Epoch: 117 | Batch_idx: 80 |  Loss: (0.1669) |  Loss2: (0.0000) | Acc: (94.00%) (9750/10368)
Epoch: 117 | Batch_idx: 90 |  Loss: (0.1644) |  Loss2: (0.0000) | Acc: (94.00%) (10978/11648)
Epoch: 117 | Batch_idx: 100 |  Loss: (0.1634) |  Loss2: (0.0000) | Acc: (94.00%) (12191/12928)
Epoch: 117 | Batch_idx: 110 |  Loss: (0.1637) |  Loss2: (0.0000) | Acc: (94.00%) (13389/14208)
Epoch: 117 | Batch_idx: 120 |  Loss: (0.1673) |  Loss2: (0.0000) | Acc: (94.00%) (14574/15488)
Epoch: 117 | Batch_idx: 130 |  Loss: (0.1674) |  Loss2: (0.0000) | Acc: (94.00%) (15777/16768)
Epoch: 117 | Batch_idx: 140 |  Loss: (0.1674) |  Loss2: (0.0000) | Acc: (94.00%) (16979/18048)
Epoch: 117 | Batch_idx: 150 |  Loss: (0.1686) |  Loss2: (0.0000) | Acc: (94.00%) (18175/19328)
Epoch: 117 | Batch_idx: 160 |  Loss: (0.1686) |  Loss2: (0.0000) | Acc: (94.00%) (19380/20608)
Epoch: 117 | Batch_idx: 170 |  Loss: (0.1705) |  Loss2: (0.0000) | Acc: (93.00%) (20563/21888)
Epoch: 117 | Batch_idx: 180 |  Loss: (0.1708) |  Loss2: (0.0000) | Acc: (93.00%) (21767/23168)
Epoch: 117 | Batch_idx: 190 |  Loss: (0.1702) |  Loss2: (0.0000) | Acc: (93.00%) (22974/24448)
Epoch: 117 | Batch_idx: 200 |  Loss: (0.1713) |  Loss2: (0.0000) | Acc: (93.00%) (24172/25728)
Epoch: 117 | Batch_idx: 210 |  Loss: (0.1705) |  Loss2: (0.0000) | Acc: (93.00%) (25386/27008)
Epoch: 117 | Batch_idx: 220 |  Loss: (0.1707) |  Loss2: (0.0000) | Acc: (94.00%) (26592/28288)
Epoch: 117 | Batch_idx: 230 |  Loss: (0.1705) |  Loss2: (0.0000) | Acc: (94.00%) (27800/29568)
Epoch: 117 | Batch_idx: 240 |  Loss: (0.1713) |  Loss2: (0.0000) | Acc: (93.00%) (28997/30848)
Epoch: 117 | Batch_idx: 250 |  Loss: (0.1709) |  Loss2: (0.0000) | Acc: (94.00%) (30201/32128)
Epoch: 117 | Batch_idx: 260 |  Loss: (0.1703) |  Loss2: (0.0000) | Acc: (94.00%) (31419/33408)
Epoch: 117 | Batch_idx: 270 |  Loss: (0.1699) |  Loss2: (0.0000) | Acc: (94.00%) (32626/34688)
Epoch: 117 | Batch_idx: 280 |  Loss: (0.1699) |  Loss2: (0.0000) | Acc: (94.00%) (33832/35968)
Epoch: 117 | Batch_idx: 290 |  Loss: (0.1700) |  Loss2: (0.0000) | Acc: (94.00%) (35031/37248)
Epoch: 117 | Batch_idx: 300 |  Loss: (0.1701) |  Loss2: (0.0000) | Acc: (94.00%) (36231/38528)
Epoch: 117 | Batch_idx: 310 |  Loss: (0.1700) |  Loss2: (0.0000) | Acc: (94.00%) (37438/39808)
Epoch: 117 | Batch_idx: 320 |  Loss: (0.1700) |  Loss2: (0.0000) | Acc: (94.00%) (38644/41088)
Epoch: 117 | Batch_idx: 330 |  Loss: (0.1705) |  Loss2: (0.0000) | Acc: (94.00%) (39838/42368)
Epoch: 117 | Batch_idx: 340 |  Loss: (0.1702) |  Loss2: (0.0000) | Acc: (94.00%) (41049/43648)
Epoch: 117 | Batch_idx: 350 |  Loss: (0.1706) |  Loss2: (0.0000) | Acc: (94.00%) (42255/44928)
Epoch: 117 | Batch_idx: 360 |  Loss: (0.1711) |  Loss2: (0.0000) | Acc: (94.00%) (43449/46208)
Epoch: 117 | Batch_idx: 370 |  Loss: (0.1713) |  Loss2: (0.0000) | Acc: (94.00%) (44650/47488)
Epoch: 117 | Batch_idx: 380 |  Loss: (0.1711) |  Loss2: (0.0000) | Acc: (94.00%) (45854/48768)
Epoch: 117 | Batch_idx: 390 |  Loss: (0.1704) |  Loss2: (0.0000) | Acc: (94.00%) (47023/50000)
# TEST : Loss: (0.3651) | Acc: (88.00%) (8800/10000)
percent tensor([0.5520, 0.5335, 0.5708, 0.5643, 0.5679, 0.5512, 0.5475, 0.5626, 0.5595,
        0.5482, 0.5468, 0.5597, 0.5466, 0.5390, 0.5415, 0.5470],
       device='cuda:0') torch.Size([16])
percent tensor([0.5171, 0.5219, 0.5142, 0.5204, 0.5158, 0.5340, 0.5180, 0.5148, 0.5109,
        0.5135, 0.5126, 0.5090, 0.5099, 0.5258, 0.5236, 0.5217],
       device='cuda:0') torch.Size([16])
percent tensor([0.6092, 0.6714, 0.5572, 0.4952, 0.5483, 0.5420, 0.6301, 0.5496, 0.5893,
        0.6362, 0.6405, 0.6262, 0.7016, 0.5250, 0.6352, 0.5861],
       device='cuda:0') torch.Size([16])
percent tensor([0.6845, 0.6710, 0.6989, 0.7091, 0.7068, 0.6872, 0.7034, 0.7036, 0.7008,
        0.6835, 0.7066, 0.7078, 0.6729, 0.7032, 0.6977, 0.6870],
       device='cuda:0') torch.Size([16])
percent tensor([0.6319, 0.6183, 0.6908, 0.6141, 0.6674, 0.8012, 0.6364, 0.5988, 0.6903,
        0.6209, 0.6714, 0.6342, 0.6989, 0.7095, 0.6406, 0.6780],
       device='cuda:0') torch.Size([16])
percent tensor([0.6119, 0.7107, 0.5711, 0.5438, 0.5428, 0.5993, 0.5883, 0.3967, 0.7142,
        0.6758, 0.7645, 0.6247, 0.7473, 0.7746, 0.4904, 0.5947],
       device='cuda:0') torch.Size([16])
percent tensor([0.5206, 0.5865, 0.8039, 0.7650, 0.8391, 0.6999, 0.6335, 0.6994, 0.6498,
        0.6100, 0.6184, 0.7539, 0.6169, 0.6748, 0.6124, 0.5466],
       device='cuda:0') torch.Size([16])
percent tensor([0.9995, 0.9987, 0.9990, 0.9991, 0.9990, 0.9983, 0.9990, 0.9991, 0.9989,
        0.9992, 0.9992, 0.9991, 0.9990, 0.9989, 0.9990, 0.9991],
       device='cuda:0') torch.Size([16])
Epoch: 118 | Batch_idx: 0 |  Loss: (0.1331) |  Loss2: (0.0000) | Acc: (96.00%) (123/128)
Epoch: 118 | Batch_idx: 10 |  Loss: (0.1610) |  Loss2: (0.0000) | Acc: (95.00%) (1340/1408)
Epoch: 118 | Batch_idx: 20 |  Loss: (0.1679) |  Loss2: (0.0000) | Acc: (94.00%) (2537/2688)
Epoch: 118 | Batch_idx: 30 |  Loss: (0.1680) |  Loss2: (0.0000) | Acc: (94.00%) (3750/3968)
Epoch: 118 | Batch_idx: 40 |  Loss: (0.1707) |  Loss2: (0.0000) | Acc: (94.00%) (4948/5248)
Epoch: 118 | Batch_idx: 50 |  Loss: (0.1664) |  Loss2: (0.0000) | Acc: (94.00%) (6166/6528)
Epoch: 118 | Batch_idx: 60 |  Loss: (0.1697) |  Loss2: (0.0000) | Acc: (94.00%) (7364/7808)
Epoch: 118 | Batch_idx: 70 |  Loss: (0.1718) |  Loss2: (0.0000) | Acc: (94.00%) (8560/9088)
Epoch: 118 | Batch_idx: 80 |  Loss: (0.1712) |  Loss2: (0.0000) | Acc: (94.00%) (9768/10368)
Epoch: 118 | Batch_idx: 90 |  Loss: (0.1698) |  Loss2: (0.0000) | Acc: (94.00%) (10976/11648)
Epoch: 118 | Batch_idx: 100 |  Loss: (0.1697) |  Loss2: (0.0000) | Acc: (94.00%) (12179/12928)
Epoch: 118 | Batch_idx: 110 |  Loss: (0.1676) |  Loss2: (0.0000) | Acc: (94.00%) (13398/14208)
Epoch: 118 | Batch_idx: 120 |  Loss: (0.1674) |  Loss2: (0.0000) | Acc: (94.00%) (14602/15488)
Epoch: 118 | Batch_idx: 130 |  Loss: (0.1694) |  Loss2: (0.0000) | Acc: (94.00%) (15796/16768)
Epoch: 118 | Batch_idx: 140 |  Loss: (0.1713) |  Loss2: (0.0000) | Acc: (94.00%) (16989/18048)
Epoch: 118 | Batch_idx: 150 |  Loss: (0.1708) |  Loss2: (0.0000) | Acc: (94.00%) (18198/19328)
Epoch: 118 | Batch_idx: 160 |  Loss: (0.1706) |  Loss2: (0.0000) | Acc: (94.00%) (19401/20608)
Epoch: 118 | Batch_idx: 170 |  Loss: (0.1693) |  Loss2: (0.0000) | Acc: (94.00%) (20610/21888)
Epoch: 118 | Batch_idx: 180 |  Loss: (0.1701) |  Loss2: (0.0000) | Acc: (94.00%) (21801/23168)
Epoch: 118 | Batch_idx: 190 |  Loss: (0.1698) |  Loss2: (0.0000) | Acc: (94.00%) (23012/24448)
Epoch: 118 | Batch_idx: 200 |  Loss: (0.1689) |  Loss2: (0.0000) | Acc: (94.00%) (24226/25728)
Epoch: 118 | Batch_idx: 210 |  Loss: (0.1686) |  Loss2: (0.0000) | Acc: (94.00%) (25438/27008)
Epoch: 118 | Batch_idx: 220 |  Loss: (0.1679) |  Loss2: (0.0000) | Acc: (94.00%) (26659/28288)
Epoch: 118 | Batch_idx: 230 |  Loss: (0.1682) |  Loss2: (0.0000) | Acc: (94.00%) (27875/29568)
Epoch: 118 | Batch_idx: 240 |  Loss: (0.1685) |  Loss2: (0.0000) | Acc: (94.00%) (29083/30848)
Epoch: 118 | Batch_idx: 250 |  Loss: (0.1684) |  Loss2: (0.0000) | Acc: (94.00%) (30289/32128)
Epoch: 118 | Batch_idx: 260 |  Loss: (0.1683) |  Loss2: (0.0000) | Acc: (94.00%) (31498/33408)
Epoch: 118 | Batch_idx: 270 |  Loss: (0.1686) |  Loss2: (0.0000) | Acc: (94.00%) (32704/34688)
Epoch: 118 | Batch_idx: 280 |  Loss: (0.1693) |  Loss2: (0.0000) | Acc: (94.00%) (33889/35968)
Epoch: 118 | Batch_idx: 290 |  Loss: (0.1703) |  Loss2: (0.0000) | Acc: (94.00%) (35088/37248)
Epoch: 118 | Batch_idx: 300 |  Loss: (0.1695) |  Loss2: (0.0000) | Acc: (94.00%) (36303/38528)
Epoch: 118 | Batch_idx: 310 |  Loss: (0.1692) |  Loss2: (0.0000) | Acc: (94.00%) (37514/39808)
Epoch: 118 | Batch_idx: 320 |  Loss: (0.1689) |  Loss2: (0.0000) | Acc: (94.00%) (38725/41088)
Epoch: 118 | Batch_idx: 330 |  Loss: (0.1683) |  Loss2: (0.0000) | Acc: (94.00%) (39939/42368)
Epoch: 118 | Batch_idx: 340 |  Loss: (0.1681) |  Loss2: (0.0000) | Acc: (94.00%) (41145/43648)
Epoch: 118 | Batch_idx: 350 |  Loss: (0.1673) |  Loss2: (0.0000) | Acc: (94.00%) (42363/44928)
Epoch: 118 | Batch_idx: 360 |  Loss: (0.1669) |  Loss2: (0.0000) | Acc: (94.00%) (43577/46208)
Epoch: 118 | Batch_idx: 370 |  Loss: (0.1673) |  Loss2: (0.0000) | Acc: (94.00%) (44776/47488)
Epoch: 118 | Batch_idx: 380 |  Loss: (0.1669) |  Loss2: (0.0000) | Acc: (94.00%) (45987/48768)
Epoch: 118 | Batch_idx: 390 |  Loss: (0.1676) |  Loss2: (0.0000) | Acc: (94.00%) (47136/50000)
# TEST : Loss: (0.3585) | Acc: (88.00%) (8823/10000)
percent tensor([0.5526, 0.5335, 0.5708, 0.5634, 0.5680, 0.5512, 0.5478, 0.5621, 0.5599,
        0.5484, 0.5474, 0.5599, 0.5471, 0.5387, 0.5413, 0.5469],
       device='cuda:0') torch.Size([16])
percent tensor([0.5184, 0.5234, 0.5153, 0.5216, 0.5171, 0.5351, 0.5195, 0.5161, 0.5121,
        0.5147, 0.5138, 0.5102, 0.5112, 0.5272, 0.5249, 0.5231],
       device='cuda:0') torch.Size([16])
percent tensor([0.6057, 0.6674, 0.5560, 0.4968, 0.5473, 0.5421, 0.6269, 0.5482, 0.5861,
        0.6337, 0.6372, 0.6240, 0.6966, 0.5232, 0.6333, 0.5840],
       device='cuda:0') torch.Size([16])
percent tensor([0.6858, 0.6702, 0.6997, 0.7103, 0.7082, 0.6890, 0.7039, 0.7055, 0.7007,
        0.6832, 0.7053, 0.7078, 0.6723, 0.7032, 0.6986, 0.6882],
       device='cuda:0') torch.Size([16])
percent tensor([0.6317, 0.6194, 0.6917, 0.6171, 0.6725, 0.7966, 0.6404, 0.6065, 0.6929,
        0.6247, 0.6737, 0.6362, 0.6981, 0.7121, 0.6407, 0.6776],
       device='cuda:0') torch.Size([16])
percent tensor([0.5970, 0.7000, 0.5567, 0.5299, 0.5268, 0.5862, 0.5711, 0.3736, 0.7063,
        0.6641, 0.7589, 0.6131, 0.7396, 0.7691, 0.4741, 0.5780],
       device='cuda:0') torch.Size([16])
percent tensor([0.5260, 0.5942, 0.8097, 0.7719, 0.8415, 0.7128, 0.6341, 0.6986, 0.6620,
        0.6175, 0.6330, 0.7576, 0.6349, 0.6822, 0.6182, 0.5481],
       device='cuda:0') torch.Size([16])
percent tensor([0.9995, 0.9988, 0.9991, 0.9992, 0.9990, 0.9983, 0.9990, 0.9991, 0.9990,
        0.9992, 0.9993, 0.9992, 0.9990, 0.9989, 0.9990, 0.9991],
       device='cuda:0') torch.Size([16])
Epoch: 119 | Batch_idx: 0 |  Loss: (0.1669) |  Loss2: (0.0000) | Acc: (94.00%) (121/128)
Epoch: 119 | Batch_idx: 10 |  Loss: (0.1616) |  Loss2: (0.0000) | Acc: (94.00%) (1337/1408)
Epoch: 119 | Batch_idx: 20 |  Loss: (0.1547) |  Loss2: (0.0000) | Acc: (94.00%) (2545/2688)
Epoch: 119 | Batch_idx: 30 |  Loss: (0.1558) |  Loss2: (0.0000) | Acc: (94.00%) (3752/3968)
Epoch: 119 | Batch_idx: 40 |  Loss: (0.1606) |  Loss2: (0.0000) | Acc: (94.00%) (4958/5248)
Epoch: 119 | Batch_idx: 50 |  Loss: (0.1634) |  Loss2: (0.0000) | Acc: (94.00%) (6168/6528)
Epoch: 119 | Batch_idx: 60 |  Loss: (0.1631) |  Loss2: (0.0000) | Acc: (94.00%) (7371/7808)
Epoch: 119 | Batch_idx: 70 |  Loss: (0.1636) |  Loss2: (0.0000) | Acc: (94.00%) (8581/9088)
Epoch: 119 | Batch_idx: 80 |  Loss: (0.1611) |  Loss2: (0.0000) | Acc: (94.00%) (9801/10368)
Epoch: 119 | Batch_idx: 90 |  Loss: (0.1633) |  Loss2: (0.0000) | Acc: (94.00%) (10993/11648)
Epoch: 119 | Batch_idx: 100 |  Loss: (0.1642) |  Loss2: (0.0000) | Acc: (94.00%) (12197/12928)
Epoch: 119 | Batch_idx: 110 |  Loss: (0.1636) |  Loss2: (0.0000) | Acc: (94.00%) (13409/14208)
Epoch: 119 | Batch_idx: 120 |  Loss: (0.1665) |  Loss2: (0.0000) | Acc: (94.00%) (14610/15488)
Epoch: 119 | Batch_idx: 130 |  Loss: (0.1668) |  Loss2: (0.0000) | Acc: (94.00%) (15810/16768)
Epoch: 119 | Batch_idx: 140 |  Loss: (0.1671) |  Loss2: (0.0000) | Acc: (94.00%) (17023/18048)
Epoch: 119 | Batch_idx: 150 |  Loss: (0.1663) |  Loss2: (0.0000) | Acc: (94.00%) (18234/19328)
Epoch: 119 | Batch_idx: 160 |  Loss: (0.1656) |  Loss2: (0.0000) | Acc: (94.00%) (19450/20608)
Epoch: 119 | Batch_idx: 170 |  Loss: (0.1655) |  Loss2: (0.0000) | Acc: (94.00%) (20655/21888)
Epoch: 119 | Batch_idx: 180 |  Loss: (0.1663) |  Loss2: (0.0000) | Acc: (94.00%) (21855/23168)
Epoch: 119 | Batch_idx: 190 |  Loss: (0.1653) |  Loss2: (0.0000) | Acc: (94.00%) (23070/24448)
Epoch: 119 | Batch_idx: 200 |  Loss: (0.1668) |  Loss2: (0.0000) | Acc: (94.00%) (24262/25728)
Epoch: 119 | Batch_idx: 210 |  Loss: (0.1665) |  Loss2: (0.0000) | Acc: (94.00%) (25477/27008)
Epoch: 119 | Batch_idx: 220 |  Loss: (0.1661) |  Loss2: (0.0000) | Acc: (94.00%) (26693/28288)
Epoch: 119 | Batch_idx: 230 |  Loss: (0.1656) |  Loss2: (0.0000) | Acc: (94.00%) (27906/29568)
Epoch: 119 | Batch_idx: 240 |  Loss: (0.1660) |  Loss2: (0.0000) | Acc: (94.00%) (29117/30848)
Epoch: 119 | Batch_idx: 250 |  Loss: (0.1663) |  Loss2: (0.0000) | Acc: (94.00%) (30322/32128)
Epoch: 119 | Batch_idx: 260 |  Loss: (0.1658) |  Loss2: (0.0000) | Acc: (94.00%) (31530/33408)
Epoch: 119 | Batch_idx: 270 |  Loss: (0.1654) |  Loss2: (0.0000) | Acc: (94.00%) (32744/34688)
Epoch: 119 | Batch_idx: 280 |  Loss: (0.1646) |  Loss2: (0.0000) | Acc: (94.00%) (33958/35968)
Epoch: 119 | Batch_idx: 290 |  Loss: (0.1643) |  Loss2: (0.0000) | Acc: (94.00%) (35177/37248)
Epoch: 119 | Batch_idx: 300 |  Loss: (0.1641) |  Loss2: (0.0000) | Acc: (94.00%) (36392/38528)
Epoch: 119 | Batch_idx: 310 |  Loss: (0.1650) |  Loss2: (0.0000) | Acc: (94.00%) (37577/39808)
Epoch: 119 | Batch_idx: 320 |  Loss: (0.1644) |  Loss2: (0.0000) | Acc: (94.00%) (38796/41088)
Epoch: 119 | Batch_idx: 330 |  Loss: (0.1642) |  Loss2: (0.0000) | Acc: (94.00%) (40002/42368)
Epoch: 119 | Batch_idx: 340 |  Loss: (0.1636) |  Loss2: (0.0000) | Acc: (94.00%) (41217/43648)
Epoch: 119 | Batch_idx: 350 |  Loss: (0.1637) |  Loss2: (0.0000) | Acc: (94.00%) (42423/44928)
Epoch: 119 | Batch_idx: 360 |  Loss: (0.1639) |  Loss2: (0.0000) | Acc: (94.00%) (43629/46208)
Epoch: 119 | Batch_idx: 370 |  Loss: (0.1637) |  Loss2: (0.0000) | Acc: (94.00%) (44839/47488)
Epoch: 119 | Batch_idx: 380 |  Loss: (0.1634) |  Loss2: (0.0000) | Acc: (94.00%) (46051/48768)
Epoch: 119 | Batch_idx: 390 |  Loss: (0.1634) |  Loss2: (0.0000) | Acc: (94.00%) (47214/50000)
# TEST : Loss: (0.3584) | Acc: (87.00%) (8798/10000)
percent tensor([0.5532, 0.5334, 0.5708, 0.5631, 0.5681, 0.5523, 0.5480, 0.5617, 0.5602,
        0.5484, 0.5480, 0.5599, 0.5475, 0.5383, 0.5416, 0.5472],
       device='cuda:0') torch.Size([16])
percent tensor([0.5184, 0.5235, 0.5153, 0.5216, 0.5171, 0.5350, 0.5197, 0.5162, 0.5122,
        0.5148, 0.5138, 0.5102, 0.5113, 0.5275, 0.5250, 0.5231],
       device='cuda:0') torch.Size([16])
percent tensor([0.6025, 0.6641, 0.5530, 0.4958, 0.5443, 0.5398, 0.6241, 0.5451, 0.5830,
        0.6310, 0.6343, 0.6207, 0.6923, 0.5233, 0.6299, 0.5819],
       device='cuda:0') torch.Size([16])
percent tensor([0.6869, 0.6705, 0.7005, 0.7108, 0.7091, 0.6899, 0.7048, 0.7064, 0.7014,
        0.6836, 0.7056, 0.7082, 0.6733, 0.7038, 0.6996, 0.6890],
       device='cuda:0') torch.Size([16])
percent tensor([0.6353, 0.6244, 0.6952, 0.6203, 0.6764, 0.7962, 0.6472, 0.6151, 0.6974,
        0.6278, 0.6781, 0.6393, 0.7005, 0.7185, 0.6461, 0.6788],
       device='cuda:0') torch.Size([16])
percent tensor([0.6111, 0.7110, 0.5672, 0.5402, 0.5378, 0.5929, 0.5846, 0.3886, 0.7171,
        0.6780, 0.7694, 0.6251, 0.7486, 0.7784, 0.4887, 0.5910],
       device='cuda:0') torch.Size([16])
percent tensor([0.5312, 0.6019, 0.8184, 0.7789, 0.8501, 0.7255, 0.6411, 0.7108, 0.6699,
        0.6265, 0.6428, 0.7657, 0.6430, 0.6873, 0.6301, 0.5555],
       device='cuda:0') torch.Size([16])
percent tensor([0.9995, 0.9988, 0.9992, 0.9992, 0.9991, 0.9983, 0.9990, 0.9991, 0.9990,
        0.9992, 0.9993, 0.9992, 0.9991, 0.9989, 0.9990, 0.9991],
       device='cuda:0') torch.Size([16])
True Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=128, out_features=16, bias=False)
False Linear(in_features=16, out_features=2, bias=False)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=128, out_features=16, bias=False)
False Linear(in_features=16, out_features=2, bias=False)
True Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=256, out_features=32, bias=False)
False Linear(in_features=32, out_features=2, bias=False)
True Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=256, out_features=32, bias=False)
False Linear(in_features=32, out_features=2, bias=False)
True Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=512, out_features=64, bias=False)
False Linear(in_features=64, out_features=2, bias=False)
True Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=512, out_features=64, bias=False)
False Linear(in_features=64, out_features=2, bias=False)
True Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1024, out_features=128, bias=False)
False Linear(in_features=128, out_features=2, bias=False)
True Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1024, out_features=128, bias=False)
False Linear(in_features=128, out_features=2, bias=False)
True Linear(in_features=512, out_features=10, bias=True)
Epoch: 120 | Batch_idx: 0 |  Loss: (0.1242) |  Loss2: (0.0000) | Acc: (95.00%) (122/128)
Epoch: 120 | Batch_idx: 10 |  Loss: (0.1715) |  Loss2: (0.0000) | Acc: (94.00%) (1327/1408)
Epoch: 120 | Batch_idx: 20 |  Loss: (0.1798) |  Loss2: (0.0000) | Acc: (93.00%) (2522/2688)
Epoch: 120 | Batch_idx: 30 |  Loss: (0.1722) |  Loss2: (0.0000) | Acc: (94.00%) (3737/3968)
Epoch: 120 | Batch_idx: 40 |  Loss: (0.1719) |  Loss2: (0.0000) | Acc: (94.00%) (4945/5248)
Epoch: 120 | Batch_idx: 50 |  Loss: (0.1745) |  Loss2: (0.0000) | Acc: (94.00%) (6142/6528)
Epoch: 120 | Batch_idx: 60 |  Loss: (0.1746) |  Loss2: (0.0000) | Acc: (94.00%) (7351/7808)
Epoch: 120 | Batch_idx: 70 |  Loss: (0.1749) |  Loss2: (0.0000) | Acc: (94.00%) (8549/9088)
Epoch: 120 | Batch_idx: 80 |  Loss: (0.1743) |  Loss2: (0.0000) | Acc: (94.00%) (9747/10368)
Epoch: 120 | Batch_idx: 90 |  Loss: (0.1754) |  Loss2: (0.0000) | Acc: (94.00%) (10950/11648)
Epoch: 120 | Batch_idx: 100 |  Loss: (0.1750) |  Loss2: (0.0000) | Acc: (94.00%) (12154/12928)
Epoch: 120 | Batch_idx: 110 |  Loss: (0.1757) |  Loss2: (0.0000) | Acc: (93.00%) (13349/14208)
Epoch: 120 | Batch_idx: 120 |  Loss: (0.1758) |  Loss2: (0.0000) | Acc: (93.00%) (14546/15488)
Epoch: 120 | Batch_idx: 130 |  Loss: (0.1742) |  Loss2: (0.0000) | Acc: (94.00%) (15767/16768)
Epoch: 120 | Batch_idx: 140 |  Loss: (0.1749) |  Loss2: (0.0000) | Acc: (93.00%) (16957/18048)
Epoch: 120 | Batch_idx: 150 |  Loss: (0.1763) |  Loss2: (0.0000) | Acc: (93.00%) (18149/19328)
Epoch: 120 | Batch_idx: 160 |  Loss: (0.1761) |  Loss2: (0.0000) | Acc: (93.00%) (19358/20608)
Epoch: 120 | Batch_idx: 170 |  Loss: (0.1756) |  Loss2: (0.0000) | Acc: (93.00%) (20566/21888)
Epoch: 120 | Batch_idx: 180 |  Loss: (0.1752) |  Loss2: (0.0000) | Acc: (94.00%) (21779/23168)
Epoch: 120 | Batch_idx: 190 |  Loss: (0.1750) |  Loss2: (0.0000) | Acc: (94.00%) (22982/24448)
Epoch: 120 | Batch_idx: 200 |  Loss: (0.1756) |  Loss2: (0.0000) | Acc: (93.00%) (24173/25728)
Epoch: 120 | Batch_idx: 210 |  Loss: (0.1764) |  Loss2: (0.0000) | Acc: (93.00%) (25367/27008)
Epoch: 120 | Batch_idx: 220 |  Loss: (0.1773) |  Loss2: (0.0000) | Acc: (93.00%) (26556/28288)
Epoch: 120 | Batch_idx: 230 |  Loss: (0.1780) |  Loss2: (0.0000) | Acc: (93.00%) (27749/29568)
Epoch: 120 | Batch_idx: 240 |  Loss: (0.1780) |  Loss2: (0.0000) | Acc: (93.00%) (28949/30848)
Epoch: 120 | Batch_idx: 250 |  Loss: (0.1791) |  Loss2: (0.0000) | Acc: (93.00%) (30138/32128)
Epoch: 120 | Batch_idx: 260 |  Loss: (0.1796) |  Loss2: (0.0000) | Acc: (93.00%) (31338/33408)
Epoch: 120 | Batch_idx: 270 |  Loss: (0.1793) |  Loss2: (0.0000) | Acc: (93.00%) (32545/34688)
Epoch: 120 | Batch_idx: 280 |  Loss: (0.1800) |  Loss2: (0.0000) | Acc: (93.00%) (33734/35968)
Epoch: 120 | Batch_idx: 290 |  Loss: (0.1803) |  Loss2: (0.0000) | Acc: (93.00%) (34931/37248)
Epoch: 120 | Batch_idx: 300 |  Loss: (0.1804) |  Loss2: (0.0000) | Acc: (93.00%) (36138/38528)
Epoch: 120 | Batch_idx: 310 |  Loss: (0.1802) |  Loss2: (0.0000) | Acc: (93.00%) (37343/39808)
Epoch: 120 | Batch_idx: 320 |  Loss: (0.1801) |  Loss2: (0.0000) | Acc: (93.00%) (38547/41088)
Epoch: 120 | Batch_idx: 330 |  Loss: (0.1801) |  Loss2: (0.0000) | Acc: (93.00%) (39746/42368)
Epoch: 120 | Batch_idx: 340 |  Loss: (0.1805) |  Loss2: (0.0000) | Acc: (93.00%) (40937/43648)
Epoch: 120 | Batch_idx: 350 |  Loss: (0.1806) |  Loss2: (0.0000) | Acc: (93.00%) (42139/44928)
Epoch: 120 | Batch_idx: 360 |  Loss: (0.1808) |  Loss2: (0.0000) | Acc: (93.00%) (43335/46208)
Epoch: 120 | Batch_idx: 370 |  Loss: (0.1807) |  Loss2: (0.0000) | Acc: (93.00%) (44539/47488)
Epoch: 120 | Batch_idx: 380 |  Loss: (0.1810) |  Loss2: (0.0000) | Acc: (93.00%) (45729/48768)
Epoch: 120 | Batch_idx: 390 |  Loss: (0.1807) |  Loss2: (0.0000) | Acc: (93.00%) (46885/50000)
=> saving checkpoint 'drive/app/torch/save_Routing_Gate_2/checkpoint_120.pth.tar'
# TEST : Loss: (0.3761) | Acc: (87.00%) (8789/10000)
percent tensor([0.5544, 0.5323, 0.5740, 0.5644, 0.5709, 0.5550, 0.5480, 0.5630, 0.5606,
        0.5485, 0.5485, 0.5632, 0.5478, 0.5360, 0.5428, 0.5478],
       device='cuda:0') torch.Size([16])
percent tensor([0.5172, 0.5240, 0.5129, 0.5199, 0.5145, 0.5332, 0.5192, 0.5160, 0.5121,
        0.5144, 0.5132, 0.5096, 0.5108, 0.5297, 0.5242, 0.5224],
       device='cuda:0') torch.Size([16])
percent tensor([0.6055, 0.6680, 0.5597, 0.5077, 0.5540, 0.5340, 0.6282, 0.5522, 0.5803,
        0.6355, 0.6333, 0.6239, 0.6960, 0.5126, 0.6337, 0.5825],
       device='cuda:0') torch.Size([16])
percent tensor([0.6853, 0.6705, 0.6992, 0.7110, 0.7078, 0.6905, 0.7002, 0.7071, 0.7037,
        0.6803, 0.7101, 0.7094, 0.6736, 0.7062, 0.7020, 0.6902],
       device='cuda:0') torch.Size([16])
percent tensor([0.6331, 0.6280, 0.6941, 0.6582, 0.6760, 0.8036, 0.6548, 0.6308, 0.6901,
        0.6326, 0.6723, 0.6264, 0.6802, 0.7156, 0.6473, 0.6924],
       device='cuda:0') torch.Size([16])
percent tensor([0.5933, 0.7066, 0.5785, 0.5514, 0.5488, 0.5928, 0.5593, 0.3847, 0.6989,
        0.6877, 0.7563, 0.6462, 0.7268, 0.7640, 0.4807, 0.5893],
       device='cuda:0') torch.Size([16])
percent tensor([0.5391, 0.6215, 0.8038, 0.7323, 0.8498, 0.7333, 0.6385, 0.7189, 0.6907,
        0.6326, 0.6383, 0.7616, 0.6719, 0.6506, 0.6306, 0.5858],
       device='cuda:0') torch.Size([16])
percent tensor([0.9995, 0.9989, 0.9993, 0.9991, 0.9994, 0.9985, 0.9987, 0.9993, 0.9991,
        0.9992, 0.9993, 0.9992, 0.9989, 0.9987, 0.9991, 0.9992],
       device='cuda:0') torch.Size([16])
Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 3, 3, 3]) tensor(181.2789, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(812.4017, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(819.7361, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([128, 64, 3, 3]) tensor(1516.8558, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([128, 64, 1, 1]) tensor(492.7720, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([128, 128, 3, 3]) tensor(2259.4438, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([256, 128, 3, 3]) tensor(4288.8701, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([256, 128, 1, 1]) tensor(1386.2676, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([256, 256, 3, 3]) tensor(6167.3999, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([512, 256, 3, 3]) tensor(11818.4951, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([512, 256, 1, 1]) tensor(3915.3840, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([512, 512, 3, 3]) tensor(16524.0156, device='cuda:0', grad_fn=<NormBackward0>)
Epoch: 121 | Batch_idx: 0 |  Loss: (0.1335) |  Loss2: (0.0000) | Acc: (94.00%) (121/128)
Epoch: 121 | Batch_idx: 10 |  Loss: (0.1580) |  Loss2: (0.0000) | Acc: (95.00%) (1340/1408)
Epoch: 121 | Batch_idx: 20 |  Loss: (0.1642) |  Loss2: (0.0000) | Acc: (94.00%) (2538/2688)
Epoch: 121 | Batch_idx: 30 |  Loss: (0.1611) |  Loss2: (0.0000) | Acc: (94.00%) (3748/3968)
Epoch: 121 | Batch_idx: 40 |  Loss: (0.1624) |  Loss2: (0.0000) | Acc: (94.00%) (4956/5248)
Epoch: 121 | Batch_idx: 50 |  Loss: (0.1645) |  Loss2: (0.0000) | Acc: (94.00%) (6166/6528)
Epoch: 121 | Batch_idx: 60 |  Loss: (0.1662) |  Loss2: (0.0000) | Acc: (94.00%) (7370/7808)
Epoch: 121 | Batch_idx: 70 |  Loss: (0.1653) |  Loss2: (0.0000) | Acc: (94.00%) (8586/9088)
Epoch: 121 | Batch_idx: 80 |  Loss: (0.1634) |  Loss2: (0.0000) | Acc: (94.00%) (9803/10368)
Epoch: 121 | Batch_idx: 90 |  Loss: (0.1627) |  Loss2: (0.0000) | Acc: (94.00%) (11022/11648)
Epoch: 121 | Batch_idx: 100 |  Loss: (0.1629) |  Loss2: (0.0000) | Acc: (94.00%) (12232/12928)
Epoch: 121 | Batch_idx: 110 |  Loss: (0.1631) |  Loss2: (0.0000) | Acc: (94.00%) (13435/14208)
Epoch: 121 | Batch_idx: 120 |  Loss: (0.1625) |  Loss2: (0.0000) | Acc: (94.00%) (14646/15488)
Epoch: 121 | Batch_idx: 130 |  Loss: (0.1627) |  Loss2: (0.0000) | Acc: (94.00%) (15857/16768)
Epoch: 121 | Batch_idx: 140 |  Loss: (0.1620) |  Loss2: (0.0000) | Acc: (94.00%) (17066/18048)
Epoch: 121 | Batch_idx: 150 |  Loss: (0.1630) |  Loss2: (0.0000) | Acc: (94.00%) (18261/19328)
Epoch: 121 | Batch_idx: 160 |  Loss: (0.1635) |  Loss2: (0.0000) | Acc: (94.00%) (19470/20608)
Epoch: 121 | Batch_idx: 170 |  Loss: (0.1652) |  Loss2: (0.0000) | Acc: (94.00%) (20667/21888)
Epoch: 121 | Batch_idx: 180 |  Loss: (0.1650) |  Loss2: (0.0000) | Acc: (94.00%) (21877/23168)
Epoch: 121 | Batch_idx: 190 |  Loss: (0.1648) |  Loss2: (0.0000) | Acc: (94.00%) (23079/24448)
Epoch: 121 | Batch_idx: 200 |  Loss: (0.1662) |  Loss2: (0.0000) | Acc: (94.00%) (24274/25728)
Epoch: 121 | Batch_idx: 210 |  Loss: (0.1678) |  Loss2: (0.0000) | Acc: (94.00%) (25473/27008)
Epoch: 121 | Batch_idx: 220 |  Loss: (0.1689) |  Loss2: (0.0000) | Acc: (94.00%) (26665/28288)
Epoch: 121 | Batch_idx: 230 |  Loss: (0.1689) |  Loss2: (0.0000) | Acc: (94.00%) (27871/29568)
Epoch: 121 | Batch_idx: 240 |  Loss: (0.1690) |  Loss2: (0.0000) | Acc: (94.00%) (29083/30848)
Epoch: 121 | Batch_idx: 250 |  Loss: (0.1686) |  Loss2: (0.0000) | Acc: (94.00%) (30297/32128)
Epoch: 121 | Batch_idx: 260 |  Loss: (0.1680) |  Loss2: (0.0000) | Acc: (94.00%) (31515/33408)
Epoch: 121 | Batch_idx: 270 |  Loss: (0.1680) |  Loss2: (0.0000) | Acc: (94.00%) (32729/34688)
Epoch: 121 | Batch_idx: 280 |  Loss: (0.1676) |  Loss2: (0.0000) | Acc: (94.00%) (33939/35968)
Epoch: 121 | Batch_idx: 290 |  Loss: (0.1670) |  Loss2: (0.0000) | Acc: (94.00%) (35157/37248)
Epoch: 121 | Batch_idx: 300 |  Loss: (0.1671) |  Loss2: (0.0000) | Acc: (94.00%) (36360/38528)
Epoch: 121 | Batch_idx: 310 |  Loss: (0.1665) |  Loss2: (0.0000) | Acc: (94.00%) (37569/39808)
Epoch: 121 | Batch_idx: 320 |  Loss: (0.1664) |  Loss2: (0.0000) | Acc: (94.00%) (38787/41088)
Epoch: 121 | Batch_idx: 330 |  Loss: (0.1668) |  Loss2: (0.0000) | Acc: (94.00%) (39990/42368)
Epoch: 121 | Batch_idx: 340 |  Loss: (0.1669) |  Loss2: (0.0000) | Acc: (94.00%) (41190/43648)
Epoch: 121 | Batch_idx: 350 |  Loss: (0.1662) |  Loss2: (0.0000) | Acc: (94.00%) (42415/44928)
Epoch: 121 | Batch_idx: 360 |  Loss: (0.1669) |  Loss2: (0.0000) | Acc: (94.00%) (43615/46208)
Epoch: 121 | Batch_idx: 370 |  Loss: (0.1668) |  Loss2: (0.0000) | Acc: (94.00%) (44840/47488)
Epoch: 121 | Batch_idx: 380 |  Loss: (0.1675) |  Loss2: (0.0000) | Acc: (94.00%) (46032/48768)
Epoch: 121 | Batch_idx: 390 |  Loss: (0.1671) |  Loss2: (0.0000) | Acc: (94.00%) (47191/50000)
# TEST : Loss: (0.3929) | Acc: (87.00%) (8770/10000)
percent tensor([0.5547, 0.5319, 0.5768, 0.5641, 0.5724, 0.5551, 0.5492, 0.5624, 0.5613,
        0.5484, 0.5485, 0.5654, 0.5477, 0.5365, 0.5419, 0.5474],
       device='cuda:0') torch.Size([16])
percent tensor([0.5181, 0.5242, 0.5145, 0.5227, 0.5165, 0.5364, 0.5189, 0.5168, 0.5107,
        0.5141, 0.5135, 0.5097, 0.5108, 0.5283, 0.5257, 0.5237],
       device='cuda:0') torch.Size([16])
percent tensor([0.5966, 0.6575, 0.5400, 0.4824, 0.5333, 0.5107, 0.6196, 0.5458, 0.5827,
        0.6263, 0.6284, 0.6116, 0.6927, 0.5106, 0.6170, 0.5679],
       device='cuda:0') torch.Size([16])
percent tensor([0.6865, 0.6736, 0.6969, 0.7137, 0.7047, 0.6923, 0.7046, 0.7053, 0.6984,
        0.6837, 0.7098, 0.7080, 0.6734, 0.7103, 0.7022, 0.6903],
       device='cuda:0') torch.Size([16])
percent tensor([0.6188, 0.6176, 0.6746, 0.6323, 0.6726, 0.7944, 0.6381, 0.6011, 0.6864,
        0.6191, 0.6781, 0.6219, 0.6679, 0.6976, 0.6320, 0.6832],
       device='cuda:0') torch.Size([16])
percent tensor([0.5732, 0.7231, 0.5612, 0.5281, 0.5342, 0.6010, 0.5678, 0.3900, 0.6809,
        0.6693, 0.7435, 0.6497, 0.7227, 0.7727, 0.4797, 0.5844],
       device='cuda:0') torch.Size([16])
percent tensor([0.5461, 0.6279, 0.8036, 0.7668, 0.8494, 0.7074, 0.6310, 0.7077, 0.6828,
        0.6441, 0.6690, 0.7696, 0.6475, 0.6752, 0.6457, 0.5782],
       device='cuda:0') torch.Size([16])
percent tensor([0.9996, 0.9988, 0.9993, 0.9993, 0.9990, 0.9988, 0.9989, 0.9992, 0.9988,
        0.9994, 0.9994, 0.9993, 0.9992, 0.9991, 0.9990, 0.9992],
       device='cuda:0') torch.Size([16])
Epoch: 122 | Batch_idx: 0 |  Loss: (0.2135) |  Loss2: (0.0000) | Acc: (93.00%) (120/128)
Epoch: 122 | Batch_idx: 10 |  Loss: (0.1450) |  Loss2: (0.0000) | Acc: (95.00%) (1338/1408)
Epoch: 122 | Batch_idx: 20 |  Loss: (0.1575) |  Loss2: (0.0000) | Acc: (94.00%) (2548/2688)
Epoch: 122 | Batch_idx: 30 |  Loss: (0.1548) |  Loss2: (0.0000) | Acc: (94.00%) (3764/3968)
Epoch: 122 | Batch_idx: 40 |  Loss: (0.1580) |  Loss2: (0.0000) | Acc: (94.00%) (4968/5248)
Epoch: 122 | Batch_idx: 50 |  Loss: (0.1562) |  Loss2: (0.0000) | Acc: (94.00%) (6183/6528)
Epoch: 122 | Batch_idx: 60 |  Loss: (0.1565) |  Loss2: (0.0000) | Acc: (94.00%) (7398/7808)
Epoch: 122 | Batch_idx: 70 |  Loss: (0.1550) |  Loss2: (0.0000) | Acc: (94.00%) (8617/9088)
Epoch: 122 | Batch_idx: 80 |  Loss: (0.1571) |  Loss2: (0.0000) | Acc: (94.00%) (9814/10368)
Epoch: 122 | Batch_idx: 90 |  Loss: (0.1599) |  Loss2: (0.0000) | Acc: (94.00%) (11014/11648)
Epoch: 122 | Batch_idx: 100 |  Loss: (0.1610) |  Loss2: (0.0000) | Acc: (94.00%) (12215/12928)
Epoch: 122 | Batch_idx: 110 |  Loss: (0.1576) |  Loss2: (0.0000) | Acc: (94.00%) (13446/14208)
Epoch: 122 | Batch_idx: 120 |  Loss: (0.1571) |  Loss2: (0.0000) | Acc: (94.00%) (14665/15488)
Epoch: 122 | Batch_idx: 130 |  Loss: (0.1564) |  Loss2: (0.0000) | Acc: (94.00%) (15879/16768)
Epoch: 122 | Batch_idx: 140 |  Loss: (0.1572) |  Loss2: (0.0000) | Acc: (94.00%) (17077/18048)
Epoch: 122 | Batch_idx: 150 |  Loss: (0.1573) |  Loss2: (0.0000) | Acc: (94.00%) (18284/19328)
Epoch: 122 | Batch_idx: 160 |  Loss: (0.1577) |  Loss2: (0.0000) | Acc: (94.00%) (19498/20608)
Epoch: 122 | Batch_idx: 170 |  Loss: (0.1582) |  Loss2: (0.0000) | Acc: (94.00%) (20704/21888)
Epoch: 122 | Batch_idx: 180 |  Loss: (0.1582) |  Loss2: (0.0000) | Acc: (94.00%) (21910/23168)
Epoch: 122 | Batch_idx: 190 |  Loss: (0.1595) |  Loss2: (0.0000) | Acc: (94.00%) (23111/24448)
Epoch: 122 | Batch_idx: 200 |  Loss: (0.1606) |  Loss2: (0.0000) | Acc: (94.00%) (24308/25728)
Epoch: 122 | Batch_idx: 210 |  Loss: (0.1621) |  Loss2: (0.0000) | Acc: (94.00%) (25503/27008)
Epoch: 122 | Batch_idx: 220 |  Loss: (0.1637) |  Loss2: (0.0000) | Acc: (94.00%) (26697/28288)
Epoch: 122 | Batch_idx: 230 |  Loss: (0.1634) |  Loss2: (0.0000) | Acc: (94.00%) (27905/29568)
Epoch: 122 | Batch_idx: 240 |  Loss: (0.1627) |  Loss2: (0.0000) | Acc: (94.00%) (29115/30848)
Epoch: 122 | Batch_idx: 250 |  Loss: (0.1634) |  Loss2: (0.0000) | Acc: (94.00%) (30309/32128)
Epoch: 122 | Batch_idx: 260 |  Loss: (0.1632) |  Loss2: (0.0000) | Acc: (94.00%) (31516/33408)
Epoch: 122 | Batch_idx: 270 |  Loss: (0.1635) |  Loss2: (0.0000) | Acc: (94.00%) (32717/34688)
Epoch: 122 | Batch_idx: 280 |  Loss: (0.1635) |  Loss2: (0.0000) | Acc: (94.00%) (33919/35968)
Epoch: 122 | Batch_idx: 290 |  Loss: (0.1644) |  Loss2: (0.0000) | Acc: (94.00%) (35116/37248)
Epoch: 122 | Batch_idx: 300 |  Loss: (0.1652) |  Loss2: (0.0000) | Acc: (94.00%) (36310/38528)
Epoch: 122 | Batch_idx: 310 |  Loss: (0.1657) |  Loss2: (0.0000) | Acc: (94.00%) (37502/39808)
Epoch: 122 | Batch_idx: 320 |  Loss: (0.1650) |  Loss2: (0.0000) | Acc: (94.00%) (38722/41088)
Epoch: 122 | Batch_idx: 330 |  Loss: (0.1648) |  Loss2: (0.0000) | Acc: (94.00%) (39938/42368)
Epoch: 122 | Batch_idx: 340 |  Loss: (0.1652) |  Loss2: (0.0000) | Acc: (94.00%) (41142/43648)
Epoch: 122 | Batch_idx: 350 |  Loss: (0.1645) |  Loss2: (0.0000) | Acc: (94.00%) (42360/44928)
Epoch: 122 | Batch_idx: 360 |  Loss: (0.1656) |  Loss2: (0.0000) | Acc: (94.00%) (43542/46208)
Epoch: 122 | Batch_idx: 370 |  Loss: (0.1657) |  Loss2: (0.0000) | Acc: (94.00%) (44740/47488)
Epoch: 122 | Batch_idx: 380 |  Loss: (0.1654) |  Loss2: (0.0000) | Acc: (94.00%) (45947/48768)
Epoch: 122 | Batch_idx: 390 |  Loss: (0.1653) |  Loss2: (0.0000) | Acc: (94.00%) (47103/50000)
# TEST : Loss: (0.4004) | Acc: (87.00%) (8727/10000)
percent tensor([0.5547, 0.5341, 0.5741, 0.5642, 0.5717, 0.5571, 0.5504, 0.5622, 0.5625,
        0.5486, 0.5494, 0.5636, 0.5477, 0.5411, 0.5436, 0.5482],
       device='cuda:0') torch.Size([16])
percent tensor([0.5178, 0.5244, 0.5141, 0.5218, 0.5156, 0.5337, 0.5190, 0.5169, 0.5119,
        0.5141, 0.5138, 0.5092, 0.5113, 0.5300, 0.5250, 0.5231],
       device='cuda:0') torch.Size([16])
percent tensor([0.6121, 0.6566, 0.5659, 0.5009, 0.5543, 0.5379, 0.6217, 0.5557, 0.5794,
        0.6331, 0.6283, 0.6208, 0.6947, 0.4919, 0.6251, 0.5828],
       device='cuda:0') torch.Size([16])
percent tensor([0.6860, 0.6740, 0.6932, 0.7123, 0.7097, 0.6895, 0.7045, 0.7009, 0.7037,
        0.6803, 0.7112, 0.7067, 0.6707, 0.7101, 0.7001, 0.6871],
       device='cuda:0') torch.Size([16])
percent tensor([0.6460, 0.6242, 0.6872, 0.6281, 0.6543, 0.7962, 0.6648, 0.5892, 0.6897,
        0.6356, 0.6986, 0.6144, 0.6960, 0.7111, 0.6431, 0.7021],
       device='cuda:0') torch.Size([16])
percent tensor([0.5951, 0.7041, 0.5502, 0.5211, 0.4978, 0.6045, 0.5774, 0.4013, 0.6974,
        0.6644, 0.7641, 0.6319, 0.7367, 0.7730, 0.4869, 0.5950],
       device='cuda:0') torch.Size([16])
percent tensor([0.5385, 0.6509, 0.7856, 0.7620, 0.8371, 0.6992, 0.6570, 0.6927, 0.6951,
        0.6628, 0.6941, 0.7395, 0.6634, 0.6995, 0.6385, 0.5684],
       device='cuda:0') torch.Size([16])
percent tensor([0.9996, 0.9982, 0.9993, 0.9993, 0.9991, 0.9991, 0.9988, 0.9991, 0.9990,
        0.9990, 0.9994, 0.9993, 0.9990, 0.9988, 0.9991, 0.9993],
       device='cuda:0') torch.Size([16])
Epoch: 123 | Batch_idx: 0 |  Loss: (0.1514) |  Loss2: (0.0000) | Acc: (93.00%) (120/128)
Epoch: 123 | Batch_idx: 10 |  Loss: (0.1704) |  Loss2: (0.0000) | Acc: (93.00%) (1321/1408)
Epoch: 123 | Batch_idx: 20 |  Loss: (0.1570) |  Loss2: (0.0000) | Acc: (94.00%) (2541/2688)
Epoch: 123 | Batch_idx: 30 |  Loss: (0.1552) |  Loss2: (0.0000) | Acc: (94.00%) (3755/3968)
Epoch: 123 | Batch_idx: 40 |  Loss: (0.1535) |  Loss2: (0.0000) | Acc: (94.00%) (4965/5248)
Epoch: 123 | Batch_idx: 50 |  Loss: (0.1553) |  Loss2: (0.0000) | Acc: (94.00%) (6174/6528)
Epoch: 123 | Batch_idx: 60 |  Loss: (0.1543) |  Loss2: (0.0000) | Acc: (94.00%) (7392/7808)
Epoch: 123 | Batch_idx: 70 |  Loss: (0.1542) |  Loss2: (0.0000) | Acc: (94.00%) (8604/9088)
Epoch: 123 | Batch_idx: 80 |  Loss: (0.1554) |  Loss2: (0.0000) | Acc: (94.00%) (9809/10368)
Epoch: 123 | Batch_idx: 90 |  Loss: (0.1552) |  Loss2: (0.0000) | Acc: (94.00%) (11019/11648)
Epoch: 123 | Batch_idx: 100 |  Loss: (0.1558) |  Loss2: (0.0000) | Acc: (94.00%) (12229/12928)
Epoch: 123 | Batch_idx: 110 |  Loss: (0.1552) |  Loss2: (0.0000) | Acc: (94.00%) (13434/14208)
Epoch: 123 | Batch_idx: 120 |  Loss: (0.1575) |  Loss2: (0.0000) | Acc: (94.00%) (14638/15488)
Epoch: 123 | Batch_idx: 130 |  Loss: (0.1565) |  Loss2: (0.0000) | Acc: (94.00%) (15859/16768)
Epoch: 123 | Batch_idx: 140 |  Loss: (0.1556) |  Loss2: (0.0000) | Acc: (94.00%) (17069/18048)
Epoch: 123 | Batch_idx: 150 |  Loss: (0.1565) |  Loss2: (0.0000) | Acc: (94.00%) (18269/19328)
Epoch: 123 | Batch_idx: 160 |  Loss: (0.1570) |  Loss2: (0.0000) | Acc: (94.00%) (19477/20608)
Epoch: 123 | Batch_idx: 170 |  Loss: (0.1582) |  Loss2: (0.0000) | Acc: (94.00%) (20677/21888)
Epoch: 123 | Batch_idx: 180 |  Loss: (0.1584) |  Loss2: (0.0000) | Acc: (94.00%) (21887/23168)
Epoch: 123 | Batch_idx: 190 |  Loss: (0.1588) |  Loss2: (0.0000) | Acc: (94.00%) (23091/24448)
Epoch: 123 | Batch_idx: 200 |  Loss: (0.1586) |  Loss2: (0.0000) | Acc: (94.00%) (24304/25728)
Epoch: 123 | Batch_idx: 210 |  Loss: (0.1588) |  Loss2: (0.0000) | Acc: (94.00%) (25510/27008)
Epoch: 123 | Batch_idx: 220 |  Loss: (0.1591) |  Loss2: (0.0000) | Acc: (94.00%) (26718/28288)
Epoch: 123 | Batch_idx: 230 |  Loss: (0.1589) |  Loss2: (0.0000) | Acc: (94.00%) (27927/29568)
Epoch: 123 | Batch_idx: 240 |  Loss: (0.1599) |  Loss2: (0.0000) | Acc: (94.00%) (29118/30848)
Epoch: 123 | Batch_idx: 250 |  Loss: (0.1598) |  Loss2: (0.0000) | Acc: (94.00%) (30323/32128)
Epoch: 123 | Batch_idx: 260 |  Loss: (0.1606) |  Loss2: (0.0000) | Acc: (94.00%) (31523/33408)
Epoch: 123 | Batch_idx: 270 |  Loss: (0.1601) |  Loss2: (0.0000) | Acc: (94.00%) (32736/34688)
Epoch: 123 | Batch_idx: 280 |  Loss: (0.1617) |  Loss2: (0.0000) | Acc: (94.00%) (33931/35968)
Epoch: 123 | Batch_idx: 290 |  Loss: (0.1612) |  Loss2: (0.0000) | Acc: (94.00%) (35149/37248)
Epoch: 123 | Batch_idx: 300 |  Loss: (0.1619) |  Loss2: (0.0000) | Acc: (94.00%) (36343/38528)
Epoch: 123 | Batch_idx: 310 |  Loss: (0.1622) |  Loss2: (0.0000) | Acc: (94.00%) (37552/39808)
Epoch: 123 | Batch_idx: 320 |  Loss: (0.1621) |  Loss2: (0.0000) | Acc: (94.00%) (38751/41088)
Epoch: 123 | Batch_idx: 330 |  Loss: (0.1623) |  Loss2: (0.0000) | Acc: (94.00%) (39958/42368)
Epoch: 123 | Batch_idx: 340 |  Loss: (0.1621) |  Loss2: (0.0000) | Acc: (94.00%) (41174/43648)
Epoch: 123 | Batch_idx: 350 |  Loss: (0.1627) |  Loss2: (0.0000) | Acc: (94.00%) (42376/44928)
Epoch: 123 | Batch_idx: 360 |  Loss: (0.1632) |  Loss2: (0.0000) | Acc: (94.00%) (43576/46208)
Epoch: 123 | Batch_idx: 370 |  Loss: (0.1634) |  Loss2: (0.0000) | Acc: (94.00%) (44780/47488)
Epoch: 123 | Batch_idx: 380 |  Loss: (0.1641) |  Loss2: (0.0000) | Acc: (94.00%) (45979/48768)
Epoch: 123 | Batch_idx: 390 |  Loss: (0.1644) |  Loss2: (0.0000) | Acc: (94.00%) (47131/50000)
# TEST : Loss: (0.3961) | Acc: (87.00%) (8761/10000)
percent tensor([0.5544, 0.5322, 0.5746, 0.5637, 0.5715, 0.5556, 0.5492, 0.5620, 0.5598,
        0.5482, 0.5482, 0.5642, 0.5472, 0.5358, 0.5422, 0.5474],
       device='cuda:0') torch.Size([16])
percent tensor([0.5169, 0.5244, 0.5121, 0.5208, 0.5148, 0.5350, 0.5189, 0.5157, 0.5114,
        0.5145, 0.5139, 0.5075, 0.5103, 0.5304, 0.5255, 0.5231],
       device='cuda:0') torch.Size([16])
percent tensor([0.6135, 0.6714, 0.5682, 0.5001, 0.5551, 0.5312, 0.6366, 0.5620, 0.5961,
        0.6426, 0.6403, 0.6361, 0.7037, 0.5260, 0.6266, 0.5855],
       device='cuda:0') torch.Size([16])
percent tensor([0.6862, 0.6742, 0.6968, 0.7109, 0.7053, 0.6910, 0.7027, 0.7010, 0.6950,
        0.6847, 0.7062, 0.7087, 0.6745, 0.7022, 0.7034, 0.6891],
       device='cuda:0') torch.Size([16])
percent tensor([0.6404, 0.6317, 0.6968, 0.6529, 0.6670, 0.7952, 0.6674, 0.6064, 0.7050,
        0.6430, 0.6986, 0.6219, 0.7081, 0.7080, 0.6441, 0.6945],
       device='cuda:0') torch.Size([16])
percent tensor([0.5982, 0.7265, 0.5907, 0.5309, 0.5317, 0.6146, 0.5616, 0.3949, 0.7098,
        0.6955, 0.7742, 0.6557, 0.7531, 0.7742, 0.4779, 0.6063],
       device='cuda:0') torch.Size([16])
percent tensor([0.5584, 0.6542, 0.8133, 0.7673, 0.8551, 0.7076, 0.6678, 0.6983, 0.7041,
        0.6903, 0.7028, 0.7683, 0.6879, 0.7081, 0.6516, 0.5812],
       device='cuda:0') torch.Size([16])
percent tensor([0.9996, 0.9989, 0.9994, 0.9993, 0.9993, 0.9990, 0.9988, 0.9989, 0.9990,
        0.9994, 0.9994, 0.9992, 0.9993, 0.9989, 0.9991, 0.9992],
       device='cuda:0') torch.Size([16])
Epoch: 124 | Batch_idx: 0 |  Loss: (0.1186) |  Loss2: (0.0000) | Acc: (96.00%) (124/128)
Epoch: 124 | Batch_idx: 10 |  Loss: (0.1295) |  Loss2: (0.0000) | Acc: (95.00%) (1345/1408)
Epoch: 124 | Batch_idx: 20 |  Loss: (0.1466) |  Loss2: (0.0000) | Acc: (94.00%) (2552/2688)
Epoch: 124 | Batch_idx: 30 |  Loss: (0.1380) |  Loss2: (0.0000) | Acc: (95.00%) (3788/3968)
Epoch: 124 | Batch_idx: 40 |  Loss: (0.1357) |  Loss2: (0.0000) | Acc: (95.00%) (5010/5248)
Epoch: 124 | Batch_idx: 50 |  Loss: (0.1351) |  Loss2: (0.0000) | Acc: (95.00%) (6230/6528)
Epoch: 124 | Batch_idx: 60 |  Loss: (0.1402) |  Loss2: (0.0000) | Acc: (95.00%) (7434/7808)
Epoch: 124 | Batch_idx: 70 |  Loss: (0.1435) |  Loss2: (0.0000) | Acc: (94.00%) (8629/9088)
Epoch: 124 | Batch_idx: 80 |  Loss: (0.1442) |  Loss2: (0.0000) | Acc: (94.00%) (9844/10368)
Epoch: 124 | Batch_idx: 90 |  Loss: (0.1469) |  Loss2: (0.0000) | Acc: (94.00%) (11049/11648)
Epoch: 124 | Batch_idx: 100 |  Loss: (0.1476) |  Loss2: (0.0000) | Acc: (94.00%) (12258/12928)
Epoch: 124 | Batch_idx: 110 |  Loss: (0.1473) |  Loss2: (0.0000) | Acc: (94.00%) (13479/14208)
Epoch: 124 | Batch_idx: 120 |  Loss: (0.1456) |  Loss2: (0.0000) | Acc: (94.00%) (14708/15488)
Epoch: 124 | Batch_idx: 130 |  Loss: (0.1462) |  Loss2: (0.0000) | Acc: (94.00%) (15927/16768)
Epoch: 124 | Batch_idx: 140 |  Loss: (0.1490) |  Loss2: (0.0000) | Acc: (94.00%) (17123/18048)
Epoch: 124 | Batch_idx: 150 |  Loss: (0.1499) |  Loss2: (0.0000) | Acc: (94.00%) (18330/19328)
Epoch: 124 | Batch_idx: 160 |  Loss: (0.1500) |  Loss2: (0.0000) | Acc: (94.00%) (19548/20608)
Epoch: 124 | Batch_idx: 170 |  Loss: (0.1515) |  Loss2: (0.0000) | Acc: (94.00%) (20748/21888)
Epoch: 124 | Batch_idx: 180 |  Loss: (0.1517) |  Loss2: (0.0000) | Acc: (94.00%) (21964/23168)
Epoch: 124 | Batch_idx: 190 |  Loss: (0.1520) |  Loss2: (0.0000) | Acc: (94.00%) (23170/24448)
Epoch: 124 | Batch_idx: 200 |  Loss: (0.1516) |  Loss2: (0.0000) | Acc: (94.00%) (24385/25728)
Epoch: 124 | Batch_idx: 210 |  Loss: (0.1521) |  Loss2: (0.0000) | Acc: (94.00%) (25597/27008)
Epoch: 124 | Batch_idx: 220 |  Loss: (0.1526) |  Loss2: (0.0000) | Acc: (94.00%) (26804/28288)
Epoch: 124 | Batch_idx: 230 |  Loss: (0.1538) |  Loss2: (0.0000) | Acc: (94.00%) (28005/29568)
Epoch: 124 | Batch_idx: 240 |  Loss: (0.1551) |  Loss2: (0.0000) | Acc: (94.00%) (29199/30848)
Epoch: 124 | Batch_idx: 250 |  Loss: (0.1549) |  Loss2: (0.0000) | Acc: (94.00%) (30418/32128)
Epoch: 124 | Batch_idx: 260 |  Loss: (0.1555) |  Loss2: (0.0000) | Acc: (94.00%) (31615/33408)
Epoch: 124 | Batch_idx: 270 |  Loss: (0.1558) |  Loss2: (0.0000) | Acc: (94.00%) (32813/34688)
Epoch: 124 | Batch_idx: 280 |  Loss: (0.1559) |  Loss2: (0.0000) | Acc: (94.00%) (34028/35968)
Epoch: 124 | Batch_idx: 290 |  Loss: (0.1555) |  Loss2: (0.0000) | Acc: (94.00%) (35244/37248)
Epoch: 124 | Batch_idx: 300 |  Loss: (0.1551) |  Loss2: (0.0000) | Acc: (94.00%) (36458/38528)
Epoch: 124 | Batch_idx: 310 |  Loss: (0.1549) |  Loss2: (0.0000) | Acc: (94.00%) (37671/39808)
Epoch: 124 | Batch_idx: 320 |  Loss: (0.1553) |  Loss2: (0.0000) | Acc: (94.00%) (38876/41088)
Epoch: 124 | Batch_idx: 330 |  Loss: (0.1556) |  Loss2: (0.0000) | Acc: (94.00%) (40088/42368)
Epoch: 124 | Batch_idx: 340 |  Loss: (0.1547) |  Loss2: (0.0000) | Acc: (94.00%) (41317/43648)
Epoch: 124 | Batch_idx: 350 |  Loss: (0.1550) |  Loss2: (0.0000) | Acc: (94.00%) (42525/44928)
Epoch: 124 | Batch_idx: 360 |  Loss: (0.1544) |  Loss2: (0.0000) | Acc: (94.00%) (43748/46208)
Epoch: 124 | Batch_idx: 370 |  Loss: (0.1545) |  Loss2: (0.0000) | Acc: (94.00%) (44957/47488)
Epoch: 124 | Batch_idx: 380 |  Loss: (0.1547) |  Loss2: (0.0000) | Acc: (94.00%) (46167/48768)
Epoch: 124 | Batch_idx: 390 |  Loss: (0.1549) |  Loss2: (0.0000) | Acc: (94.00%) (47333/50000)
# TEST : Loss: (0.3992) | Acc: (87.00%) (8768/10000)
percent tensor([0.5543, 0.5320, 0.5767, 0.5655, 0.5732, 0.5551, 0.5495, 0.5635, 0.5610,
        0.5489, 0.5473, 0.5655, 0.5469, 0.5373, 0.5423, 0.5472],
       device='cuda:0') torch.Size([16])
percent tensor([0.5181, 0.5242, 0.5153, 0.5221, 0.5171, 0.5353, 0.5197, 0.5168, 0.5116,
        0.5144, 0.5137, 0.5094, 0.5110, 0.5292, 0.5254, 0.5234],
       device='cuda:0') torch.Size([16])
percent tensor([0.6075, 0.6647, 0.5417, 0.4987, 0.5378, 0.5363, 0.6202, 0.5471, 0.5821,
        0.6311, 0.6327, 0.6133, 0.6975, 0.5127, 0.6264, 0.5847],
       device='cuda:0') torch.Size([16])
percent tensor([0.6861, 0.6682, 0.7029, 0.7132, 0.7118, 0.6894, 0.6994, 0.7068, 0.6993,
        0.6802, 0.7090, 0.7051, 0.6708, 0.7010, 0.6973, 0.6877],
       device='cuda:0') torch.Size([16])
percent tensor([0.6402, 0.6161, 0.6738, 0.6405, 0.6514, 0.8069, 0.6528, 0.5821, 0.6816,
        0.6224, 0.6775, 0.5987, 0.6771, 0.7101, 0.6433, 0.6890],
       device='cuda:0') torch.Size([16])
percent tensor([0.5909, 0.7061, 0.5493, 0.5037, 0.5220, 0.6218, 0.5616, 0.3676, 0.7006,
        0.6603, 0.7641, 0.6378, 0.7369, 0.7689, 0.4896, 0.6007],
       device='cuda:0') torch.Size([16])
percent tensor([0.5327, 0.6231, 0.8054, 0.7660, 0.8442, 0.7208, 0.6623, 0.6847, 0.6535,
        0.6361, 0.6745, 0.7529, 0.6370, 0.6707, 0.6331, 0.5795],
       device='cuda:0') torch.Size([16])
percent tensor([0.9996, 0.9988, 0.9994, 0.9992, 0.9992, 0.9993, 0.9990, 0.9993, 0.9990,
        0.9993, 0.9994, 0.9994, 0.9993, 0.9988, 0.9992, 0.9993],
       device='cuda:0') torch.Size([16])
False Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=128, out_features=16, bias=False)
True Linear(in_features=16, out_features=2, bias=False)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=128, out_features=16, bias=False)
True Linear(in_features=16, out_features=2, bias=False)
False Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=256, out_features=32, bias=False)
True Linear(in_features=32, out_features=2, bias=False)
False Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=256, out_features=32, bias=False)
True Linear(in_features=32, out_features=2, bias=False)
False Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=512, out_features=64, bias=False)
True Linear(in_features=64, out_features=2, bias=False)
False Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=512, out_features=64, bias=False)
True Linear(in_features=64, out_features=2, bias=False)
False Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1024, out_features=128, bias=False)
True Linear(in_features=128, out_features=2, bias=False)
False Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1024, out_features=128, bias=False)
True Linear(in_features=128, out_features=2, bias=False)
False Linear(in_features=512, out_features=10, bias=True)
Epoch: 125 | Batch_idx: 0 |  Loss: (0.1316) |  Loss2: (0.0000) | Acc: (96.00%) (123/128)
Epoch: 125 | Batch_idx: 10 |  Loss: (0.1293) |  Loss2: (0.0000) | Acc: (96.00%) (1356/1408)
Epoch: 125 | Batch_idx: 20 |  Loss: (0.1486) |  Loss2: (0.0000) | Acc: (95.00%) (2569/2688)
Epoch: 125 | Batch_idx: 30 |  Loss: (0.1602) |  Loss2: (0.0000) | Acc: (94.00%) (3765/3968)
Epoch: 125 | Batch_idx: 40 |  Loss: (0.1674) |  Loss2: (0.0000) | Acc: (94.00%) (4956/5248)
Epoch: 125 | Batch_idx: 50 |  Loss: (0.1679) |  Loss2: (0.0000) | Acc: (94.00%) (6155/6528)
Epoch: 125 | Batch_idx: 60 |  Loss: (0.1671) |  Loss2: (0.0000) | Acc: (94.00%) (7357/7808)
Epoch: 125 | Batch_idx: 70 |  Loss: (0.1684) |  Loss2: (0.0000) | Acc: (94.00%) (8557/9088)
Epoch: 125 | Batch_idx: 80 |  Loss: (0.1699) |  Loss2: (0.0000) | Acc: (94.00%) (9758/10368)
Epoch: 125 | Batch_idx: 90 |  Loss: (0.1753) |  Loss2: (0.0000) | Acc: (93.00%) (10947/11648)
Epoch: 125 | Batch_idx: 100 |  Loss: (0.1748) |  Loss2: (0.0000) | Acc: (93.00%) (12141/12928)
Epoch: 125 | Batch_idx: 110 |  Loss: (0.1750) |  Loss2: (0.0000) | Acc: (93.00%) (13342/14208)
Epoch: 125 | Batch_idx: 120 |  Loss: (0.1745) |  Loss2: (0.0000) | Acc: (93.00%) (14550/15488)
Epoch: 125 | Batch_idx: 130 |  Loss: (0.1769) |  Loss2: (0.0000) | Acc: (93.00%) (15729/16768)
Epoch: 125 | Batch_idx: 140 |  Loss: (0.1758) |  Loss2: (0.0000) | Acc: (93.00%) (16934/18048)
Epoch: 125 | Batch_idx: 150 |  Loss: (0.1738) |  Loss2: (0.0000) | Acc: (93.00%) (18148/19328)
Epoch: 125 | Batch_idx: 160 |  Loss: (0.1732) |  Loss2: (0.0000) | Acc: (93.00%) (19354/20608)
Epoch: 125 | Batch_idx: 170 |  Loss: (0.1729) |  Loss2: (0.0000) | Acc: (93.00%) (20557/21888)
Epoch: 125 | Batch_idx: 180 |  Loss: (0.1721) |  Loss2: (0.0000) | Acc: (93.00%) (21763/23168)
Epoch: 125 | Batch_idx: 190 |  Loss: (0.1710) |  Loss2: (0.0000) | Acc: (94.00%) (22984/24448)
Epoch: 125 | Batch_idx: 200 |  Loss: (0.1702) |  Loss2: (0.0000) | Acc: (94.00%) (24188/25728)
Epoch: 125 | Batch_idx: 210 |  Loss: (0.1699) |  Loss2: (0.0000) | Acc: (94.00%) (25395/27008)
Epoch: 125 | Batch_idx: 220 |  Loss: (0.1704) |  Loss2: (0.0000) | Acc: (94.00%) (26593/28288)
Epoch: 125 | Batch_idx: 230 |  Loss: (0.1700) |  Loss2: (0.0000) | Acc: (94.00%) (27800/29568)
Epoch: 125 | Batch_idx: 240 |  Loss: (0.1693) |  Loss2: (0.0000) | Acc: (94.00%) (29011/30848)
Epoch: 125 | Batch_idx: 250 |  Loss: (0.1698) |  Loss2: (0.0000) | Acc: (94.00%) (30214/32128)
Epoch: 125 | Batch_idx: 260 |  Loss: (0.1699) |  Loss2: (0.0000) | Acc: (94.00%) (31406/33408)
Epoch: 125 | Batch_idx: 270 |  Loss: (0.1693) |  Loss2: (0.0000) | Acc: (94.00%) (32624/34688)
Epoch: 125 | Batch_idx: 280 |  Loss: (0.1678) |  Loss2: (0.0000) | Acc: (94.00%) (33844/35968)
Epoch: 125 | Batch_idx: 290 |  Loss: (0.1674) |  Loss2: (0.0000) | Acc: (94.00%) (35055/37248)
Epoch: 125 | Batch_idx: 300 |  Loss: (0.1670) |  Loss2: (0.0000) | Acc: (94.00%) (36268/38528)
Epoch: 125 | Batch_idx: 310 |  Loss: (0.1675) |  Loss2: (0.0000) | Acc: (94.00%) (37473/39808)
Epoch: 125 | Batch_idx: 320 |  Loss: (0.1680) |  Loss2: (0.0000) | Acc: (94.00%) (38676/41088)
Epoch: 125 | Batch_idx: 330 |  Loss: (0.1682) |  Loss2: (0.0000) | Acc: (94.00%) (39881/42368)
Epoch: 125 | Batch_idx: 340 |  Loss: (0.1682) |  Loss2: (0.0000) | Acc: (94.00%) (41093/43648)
Epoch: 125 | Batch_idx: 350 |  Loss: (0.1680) |  Loss2: (0.0000) | Acc: (94.00%) (42293/44928)
Epoch: 125 | Batch_idx: 360 |  Loss: (0.1683) |  Loss2: (0.0000) | Acc: (94.00%) (43493/46208)
Epoch: 125 | Batch_idx: 370 |  Loss: (0.1685) |  Loss2: (0.0000) | Acc: (94.00%) (44691/47488)
Epoch: 125 | Batch_idx: 380 |  Loss: (0.1683) |  Loss2: (0.0000) | Acc: (94.00%) (45907/48768)
Epoch: 125 | Batch_idx: 390 |  Loss: (0.1685) |  Loss2: (0.0000) | Acc: (94.00%) (47057/50000)
=> saving checkpoint 'drive/app/torch/save_Routing_Gate_2/checkpoint_125.pth.tar'
# TEST : Loss: (0.3924) | Acc: (87.00%) (8778/10000)
percent tensor([0.5493, 0.5270, 0.5689, 0.5601, 0.5661, 0.5524, 0.5435, 0.5562, 0.5543,
        0.5426, 0.5425, 0.5574, 0.5411, 0.5320, 0.5383, 0.5430],
       device='cuda:0') torch.Size([16])
percent tensor([0.5164, 0.5230, 0.5129, 0.5211, 0.5149, 0.5354, 0.5178, 0.5143, 0.5091,
        0.5121, 0.5121, 0.5064, 0.5088, 0.5278, 0.5244, 0.5226],
       device='cuda:0') torch.Size([16])
percent tensor([0.5918, 0.6608, 0.5415, 0.4843, 0.5314, 0.5124, 0.6140, 0.5395, 0.5748,
        0.6271, 0.6221, 0.6120, 0.6888, 0.5151, 0.6102, 0.5700],
       device='cuda:0') torch.Size([16])
percent tensor([0.6996, 0.6826, 0.7141, 0.7258, 0.7233, 0.7027, 0.7101, 0.7157, 0.7147,
        0.6969, 0.7263, 0.7188, 0.6869, 0.7140, 0.7082, 0.7030],
       device='cuda:0') torch.Size([16])
percent tensor([0.6434, 0.6255, 0.6801, 0.6375, 0.6579, 0.8215, 0.6559, 0.5703, 0.6950,
        0.6321, 0.6911, 0.5989, 0.6938, 0.7206, 0.6382, 0.7061],
       device='cuda:0') torch.Size([16])
percent tensor([0.5894, 0.6964, 0.5510, 0.5052, 0.5314, 0.6106, 0.5666, 0.3837, 0.6960,
        0.6623, 0.7530, 0.6293, 0.7252, 0.7616, 0.4880, 0.5896],
       device='cuda:0') torch.Size([16])
percent tensor([0.5460, 0.6328, 0.7965, 0.7612, 0.8387, 0.7027, 0.6626, 0.6777, 0.6658,
        0.6455, 0.6850, 0.7556, 0.6337, 0.6856, 0.6311, 0.5777],
       device='cuda:0') torch.Size([16])
percent tensor([0.9997, 0.9989, 0.9994, 0.9993, 0.9991, 0.9992, 0.9991, 0.9993, 0.9990,
        0.9993, 0.9993, 0.9994, 0.9993, 0.9988, 0.9991, 0.9993],
       device='cuda:0') torch.Size([16])
Epoch: 126 | Batch_idx: 0 |  Loss: (0.1173) |  Loss2: (0.0000) | Acc: (95.00%) (122/128)
Epoch: 126 | Batch_idx: 10 |  Loss: (0.1632) |  Loss2: (0.0000) | Acc: (94.00%) (1324/1408)
Epoch: 126 | Batch_idx: 20 |  Loss: (0.1578) |  Loss2: (0.0000) | Acc: (94.00%) (2543/2688)
Epoch: 126 | Batch_idx: 30 |  Loss: (0.1647) |  Loss2: (0.0000) | Acc: (94.00%) (3743/3968)
Epoch: 126 | Batch_idx: 40 |  Loss: (0.1617) |  Loss2: (0.0000) | Acc: (94.00%) (4959/5248)
Epoch: 126 | Batch_idx: 50 |  Loss: (0.1629) |  Loss2: (0.0000) | Acc: (94.00%) (6161/6528)
Epoch: 126 | Batch_idx: 60 |  Loss: (0.1663) |  Loss2: (0.0000) | Acc: (94.00%) (7357/7808)
Epoch: 126 | Batch_idx: 70 |  Loss: (0.1620) |  Loss2: (0.0000) | Acc: (94.00%) (8581/9088)
Epoch: 126 | Batch_idx: 80 |  Loss: (0.1597) |  Loss2: (0.0000) | Acc: (94.00%) (9799/10368)
Epoch: 126 | Batch_idx: 90 |  Loss: (0.1597) |  Loss2: (0.0000) | Acc: (94.00%) (11012/11648)
Epoch: 126 | Batch_idx: 100 |  Loss: (0.1593) |  Loss2: (0.0000) | Acc: (94.00%) (12218/12928)
Epoch: 126 | Batch_idx: 110 |  Loss: (0.1593) |  Loss2: (0.0000) | Acc: (94.00%) (13417/14208)
Epoch: 126 | Batch_idx: 120 |  Loss: (0.1596) |  Loss2: (0.0000) | Acc: (94.00%) (14615/15488)
Epoch: 126 | Batch_idx: 130 |  Loss: (0.1601) |  Loss2: (0.0000) | Acc: (94.00%) (15825/16768)
Epoch: 126 | Batch_idx: 140 |  Loss: (0.1615) |  Loss2: (0.0000) | Acc: (94.00%) (17024/18048)
Epoch: 126 | Batch_idx: 150 |  Loss: (0.1601) |  Loss2: (0.0000) | Acc: (94.00%) (18241/19328)
Epoch: 126 | Batch_idx: 160 |  Loss: (0.1600) |  Loss2: (0.0000) | Acc: (94.00%) (19454/20608)
Epoch: 126 | Batch_idx: 170 |  Loss: (0.1601) |  Loss2: (0.0000) | Acc: (94.00%) (20661/21888)
Epoch: 126 | Batch_idx: 180 |  Loss: (0.1605) |  Loss2: (0.0000) | Acc: (94.00%) (21860/23168)
Epoch: 126 | Batch_idx: 190 |  Loss: (0.1599) |  Loss2: (0.0000) | Acc: (94.00%) (23073/24448)
Epoch: 126 | Batch_idx: 200 |  Loss: (0.1601) |  Loss2: (0.0000) | Acc: (94.00%) (24285/25728)
Epoch: 126 | Batch_idx: 210 |  Loss: (0.1594) |  Loss2: (0.0000) | Acc: (94.00%) (25505/27008)
Epoch: 126 | Batch_idx: 220 |  Loss: (0.1598) |  Loss2: (0.0000) | Acc: (94.00%) (26713/28288)
Epoch: 126 | Batch_idx: 230 |  Loss: (0.1600) |  Loss2: (0.0000) | Acc: (94.00%) (27922/29568)
Epoch: 126 | Batch_idx: 240 |  Loss: (0.1594) |  Loss2: (0.0000) | Acc: (94.00%) (29133/30848)
Epoch: 126 | Batch_idx: 250 |  Loss: (0.1589) |  Loss2: (0.0000) | Acc: (94.00%) (30336/32128)
Epoch: 126 | Batch_idx: 260 |  Loss: (0.1593) |  Loss2: (0.0000) | Acc: (94.00%) (31546/33408)
Epoch: 126 | Batch_idx: 270 |  Loss: (0.1594) |  Loss2: (0.0000) | Acc: (94.00%) (32754/34688)
Epoch: 126 | Batch_idx: 280 |  Loss: (0.1602) |  Loss2: (0.0000) | Acc: (94.00%) (33956/35968)
Epoch: 126 | Batch_idx: 290 |  Loss: (0.1606) |  Loss2: (0.0000) | Acc: (94.00%) (35152/37248)
Epoch: 126 | Batch_idx: 300 |  Loss: (0.1599) |  Loss2: (0.0000) | Acc: (94.00%) (36374/38528)
Epoch: 126 | Batch_idx: 310 |  Loss: (0.1599) |  Loss2: (0.0000) | Acc: (94.00%) (37582/39808)
Epoch: 126 | Batch_idx: 320 |  Loss: (0.1597) |  Loss2: (0.0000) | Acc: (94.00%) (38802/41088)
Epoch: 126 | Batch_idx: 330 |  Loss: (0.1597) |  Loss2: (0.0000) | Acc: (94.00%) (40020/42368)
Epoch: 126 | Batch_idx: 340 |  Loss: (0.1604) |  Loss2: (0.0000) | Acc: (94.00%) (41219/43648)
Epoch: 126 | Batch_idx: 350 |  Loss: (0.1594) |  Loss2: (0.0000) | Acc: (94.00%) (42443/44928)
Epoch: 126 | Batch_idx: 360 |  Loss: (0.1592) |  Loss2: (0.0000) | Acc: (94.00%) (43658/46208)
Epoch: 126 | Batch_idx: 370 |  Loss: (0.1598) |  Loss2: (0.0000) | Acc: (94.00%) (44857/47488)
Epoch: 126 | Batch_idx: 380 |  Loss: (0.1598) |  Loss2: (0.0000) | Acc: (94.00%) (46070/48768)
Epoch: 126 | Batch_idx: 390 |  Loss: (0.1602) |  Loss2: (0.0000) | Acc: (94.00%) (47221/50000)
# TEST : Loss: (0.3825) | Acc: (88.00%) (8814/10000)
percent tensor([0.5505, 0.5285, 0.5687, 0.5603, 0.5667, 0.5550, 0.5448, 0.5560, 0.5550,
        0.5432, 0.5439, 0.5574, 0.5420, 0.5332, 0.5401, 0.5444],
       device='cuda:0') torch.Size([16])
percent tensor([0.5176, 0.5251, 0.5134, 0.5223, 0.5157, 0.5386, 0.5192, 0.5147, 0.5093,
        0.5129, 0.5133, 0.5066, 0.5096, 0.5293, 0.5267, 0.5244],
       device='cuda:0') torch.Size([16])
percent tensor([0.5895, 0.6652, 0.5435, 0.4829, 0.5311, 0.5019, 0.6167, 0.5410, 0.5765,
        0.6319, 0.6235, 0.6149, 0.6903, 0.5209, 0.6070, 0.5683],
       device='cuda:0') torch.Size([16])
percent tensor([0.6980, 0.6840, 0.7116, 0.7242, 0.7218, 0.7032, 0.7095, 0.7119, 0.7136,
        0.6980, 0.7280, 0.7180, 0.6883, 0.7135, 0.7073, 0.7036],
       device='cuda:0') torch.Size([16])
percent tensor([0.6356, 0.6234, 0.6799, 0.6399, 0.6590, 0.8196, 0.6523, 0.5654, 0.6958,
        0.6292, 0.6945, 0.5968, 0.6932, 0.7182, 0.6251, 0.7049],
       device='cuda:0') torch.Size([16])
percent tensor([0.5725, 0.6858, 0.5438, 0.4924, 0.5223, 0.5899, 0.5563, 0.3827, 0.6868,
        0.6491, 0.7399, 0.6154, 0.7123, 0.7549, 0.4715, 0.5643],
       device='cuda:0') torch.Size([16])
percent tensor([0.5616, 0.6496, 0.7994, 0.7681, 0.8396, 0.6997, 0.6752, 0.6866, 0.6849,
        0.6591, 0.7004, 0.7648, 0.6515, 0.6973, 0.6424, 0.5874],
       device='cuda:0') torch.Size([16])
percent tensor([0.9997, 0.9989, 0.9995, 0.9994, 0.9991, 0.9992, 0.9991, 0.9993, 0.9990,
        0.9993, 0.9994, 0.9994, 0.9993, 0.9988, 0.9991, 0.9993],
       device='cuda:0') torch.Size([16])
Epoch: 127 | Batch_idx: 0 |  Loss: (0.1857) |  Loss2: (0.0000) | Acc: (93.00%) (120/128)
Epoch: 127 | Batch_idx: 10 |  Loss: (0.1668) |  Loss2: (0.0000) | Acc: (94.00%) (1326/1408)
Epoch: 127 | Batch_idx: 20 |  Loss: (0.1612) |  Loss2: (0.0000) | Acc: (94.00%) (2541/2688)
Epoch: 127 | Batch_idx: 30 |  Loss: (0.1619) |  Loss2: (0.0000) | Acc: (94.00%) (3742/3968)
Epoch: 127 | Batch_idx: 40 |  Loss: (0.1601) |  Loss2: (0.0000) | Acc: (94.00%) (4956/5248)
Epoch: 127 | Batch_idx: 50 |  Loss: (0.1634) |  Loss2: (0.0000) | Acc: (94.00%) (6154/6528)
Epoch: 127 | Batch_idx: 60 |  Loss: (0.1616) |  Loss2: (0.0000) | Acc: (94.00%) (7368/7808)
Epoch: 127 | Batch_idx: 70 |  Loss: (0.1626) |  Loss2: (0.0000) | Acc: (94.00%) (8571/9088)
Epoch: 127 | Batch_idx: 80 |  Loss: (0.1600) |  Loss2: (0.0000) | Acc: (94.00%) (9794/10368)
Epoch: 127 | Batch_idx: 90 |  Loss: (0.1574) |  Loss2: (0.0000) | Acc: (94.00%) (11024/11648)
Epoch: 127 | Batch_idx: 100 |  Loss: (0.1590) |  Loss2: (0.0000) | Acc: (94.00%) (12234/12928)
Epoch: 127 | Batch_idx: 110 |  Loss: (0.1576) |  Loss2: (0.0000) | Acc: (94.00%) (13450/14208)
Epoch: 127 | Batch_idx: 120 |  Loss: (0.1573) |  Loss2: (0.0000) | Acc: (94.00%) (14672/15488)
Epoch: 127 | Batch_idx: 130 |  Loss: (0.1562) |  Loss2: (0.0000) | Acc: (94.00%) (15890/16768)
Epoch: 127 | Batch_idx: 140 |  Loss: (0.1564) |  Loss2: (0.0000) | Acc: (94.00%) (17103/18048)
Epoch: 127 | Batch_idx: 150 |  Loss: (0.1566) |  Loss2: (0.0000) | Acc: (94.00%) (18316/19328)
Epoch: 127 | Batch_idx: 160 |  Loss: (0.1545) |  Loss2: (0.0000) | Acc: (94.00%) (19546/20608)
Epoch: 127 | Batch_idx: 170 |  Loss: (0.1551) |  Loss2: (0.0000) | Acc: (94.00%) (20752/21888)
Epoch: 127 | Batch_idx: 180 |  Loss: (0.1550) |  Loss2: (0.0000) | Acc: (94.00%) (21968/23168)
Epoch: 127 | Batch_idx: 190 |  Loss: (0.1549) |  Loss2: (0.0000) | Acc: (94.00%) (23181/24448)
Epoch: 127 | Batch_idx: 200 |  Loss: (0.1547) |  Loss2: (0.0000) | Acc: (94.00%) (24383/25728)
Epoch: 127 | Batch_idx: 210 |  Loss: (0.1533) |  Loss2: (0.0000) | Acc: (94.00%) (25615/27008)
Epoch: 127 | Batch_idx: 220 |  Loss: (0.1541) |  Loss2: (0.0000) | Acc: (94.00%) (26816/28288)
Epoch: 127 | Batch_idx: 230 |  Loss: (0.1540) |  Loss2: (0.0000) | Acc: (94.00%) (28024/29568)
Epoch: 127 | Batch_idx: 240 |  Loss: (0.1541) |  Loss2: (0.0000) | Acc: (94.00%) (29233/30848)
Epoch: 127 | Batch_idx: 250 |  Loss: (0.1538) |  Loss2: (0.0000) | Acc: (94.00%) (30443/32128)
Epoch: 127 | Batch_idx: 260 |  Loss: (0.1540) |  Loss2: (0.0000) | Acc: (94.00%) (31645/33408)
Epoch: 127 | Batch_idx: 270 |  Loss: (0.1537) |  Loss2: (0.0000) | Acc: (94.00%) (32858/34688)
Epoch: 127 | Batch_idx: 280 |  Loss: (0.1536) |  Loss2: (0.0000) | Acc: (94.00%) (34072/35968)
Epoch: 127 | Batch_idx: 290 |  Loss: (0.1537) |  Loss2: (0.0000) | Acc: (94.00%) (35280/37248)
Epoch: 127 | Batch_idx: 300 |  Loss: (0.1529) |  Loss2: (0.0000) | Acc: (94.00%) (36511/38528)
Epoch: 127 | Batch_idx: 310 |  Loss: (0.1533) |  Loss2: (0.0000) | Acc: (94.00%) (37714/39808)
Epoch: 127 | Batch_idx: 320 |  Loss: (0.1533) |  Loss2: (0.0000) | Acc: (94.00%) (38928/41088)
Epoch: 127 | Batch_idx: 330 |  Loss: (0.1533) |  Loss2: (0.0000) | Acc: (94.00%) (40144/42368)
Epoch: 127 | Batch_idx: 340 |  Loss: (0.1539) |  Loss2: (0.0000) | Acc: (94.00%) (41344/43648)
Epoch: 127 | Batch_idx: 350 |  Loss: (0.1537) |  Loss2: (0.0000) | Acc: (94.00%) (42557/44928)
Epoch: 127 | Batch_idx: 360 |  Loss: (0.1535) |  Loss2: (0.0000) | Acc: (94.00%) (43773/46208)
Epoch: 127 | Batch_idx: 370 |  Loss: (0.1533) |  Loss2: (0.0000) | Acc: (94.00%) (44992/47488)
Epoch: 127 | Batch_idx: 380 |  Loss: (0.1526) |  Loss2: (0.0000) | Acc: (94.00%) (46224/48768)
Epoch: 127 | Batch_idx: 390 |  Loss: (0.1522) |  Loss2: (0.0000) | Acc: (94.00%) (47393/50000)
# TEST : Loss: (0.3780) | Acc: (88.00%) (8824/10000)
percent tensor([0.5526, 0.5316, 0.5697, 0.5615, 0.5684, 0.5581, 0.5475, 0.5573, 0.5568,
        0.5453, 0.5464, 0.5590, 0.5441, 0.5357, 0.5432, 0.5467],
       device='cuda:0') torch.Size([16])
percent tensor([0.5189, 0.5271, 0.5138, 0.5230, 0.5163, 0.5412, 0.5205, 0.5149, 0.5097,
        0.5138, 0.5145, 0.5070, 0.5106, 0.5309, 0.5288, 0.5260],
       device='cuda:0') torch.Size([16])
percent tensor([0.5937, 0.6729, 0.5482, 0.4850, 0.5352, 0.5011, 0.6226, 0.5474, 0.5818,
        0.6389, 0.6282, 0.6205, 0.6970, 0.5265, 0.6106, 0.5717],
       device='cuda:0') torch.Size([16])
percent tensor([0.6935, 0.6820, 0.7055, 0.7183, 0.7160, 0.6997, 0.7050, 0.7045, 0.7091,
        0.6953, 0.7253, 0.7134, 0.6862, 0.7095, 0.7031, 0.7001],
       device='cuda:0') torch.Size([16])
percent tensor([0.6311, 0.6257, 0.6783, 0.6333, 0.6538, 0.8194, 0.6517, 0.5597, 0.6934,
        0.6304, 0.6958, 0.5950, 0.6964, 0.7184, 0.6182, 0.7044],
       device='cuda:0') torch.Size([16])
percent tensor([0.5717, 0.6870, 0.5452, 0.4918, 0.5222, 0.5816, 0.5562, 0.3901, 0.6881,
        0.6473, 0.7406, 0.6120, 0.7099, 0.7567, 0.4716, 0.5541],
       device='cuda:0') torch.Size([16])
percent tensor([0.5654, 0.6513, 0.7995, 0.7689, 0.8375, 0.6947, 0.6771, 0.6867, 0.6896,
        0.6560, 0.7048, 0.7687, 0.6568, 0.7048, 0.6426, 0.5887],
       device='cuda:0') torch.Size([16])
percent tensor([0.9997, 0.9990, 0.9995, 0.9994, 0.9992, 0.9992, 0.9991, 0.9993, 0.9991,
        0.9993, 0.9994, 0.9994, 0.9993, 0.9988, 0.9991, 0.9993],
       device='cuda:0') torch.Size([16])
Epoch: 128 | Batch_idx: 0 |  Loss: (0.1504) |  Loss2: (0.0000) | Acc: (94.00%) (121/128)
Epoch: 128 | Batch_idx: 10 |  Loss: (0.1593) |  Loss2: (0.0000) | Acc: (94.00%) (1328/1408)
Epoch: 128 | Batch_idx: 20 |  Loss: (0.1620) |  Loss2: (0.0000) | Acc: (94.00%) (2532/2688)
Epoch: 128 | Batch_idx: 30 |  Loss: (0.1575) |  Loss2: (0.0000) | Acc: (94.00%) (3741/3968)
Epoch: 128 | Batch_idx: 40 |  Loss: (0.1543) |  Loss2: (0.0000) | Acc: (94.00%) (4958/5248)
Epoch: 128 | Batch_idx: 50 |  Loss: (0.1545) |  Loss2: (0.0000) | Acc: (94.00%) (6163/6528)
Epoch: 128 | Batch_idx: 60 |  Loss: (0.1570) |  Loss2: (0.0000) | Acc: (94.00%) (7373/7808)
Epoch: 128 | Batch_idx: 70 |  Loss: (0.1558) |  Loss2: (0.0000) | Acc: (94.00%) (8594/9088)
Epoch: 128 | Batch_idx: 80 |  Loss: (0.1545) |  Loss2: (0.0000) | Acc: (94.00%) (9805/10368)
Epoch: 128 | Batch_idx: 90 |  Loss: (0.1549) |  Loss2: (0.0000) | Acc: (94.00%) (11015/11648)
Epoch: 128 | Batch_idx: 100 |  Loss: (0.1539) |  Loss2: (0.0000) | Acc: (94.00%) (12232/12928)
Epoch: 128 | Batch_idx: 110 |  Loss: (0.1524) |  Loss2: (0.0000) | Acc: (94.00%) (13457/14208)
Epoch: 128 | Batch_idx: 120 |  Loss: (0.1520) |  Loss2: (0.0000) | Acc: (94.00%) (14667/15488)
Epoch: 128 | Batch_idx: 130 |  Loss: (0.1504) |  Loss2: (0.0000) | Acc: (94.00%) (15891/16768)
Epoch: 128 | Batch_idx: 140 |  Loss: (0.1490) |  Loss2: (0.0000) | Acc: (94.00%) (17117/18048)
Epoch: 128 | Batch_idx: 150 |  Loss: (0.1489) |  Loss2: (0.0000) | Acc: (94.00%) (18334/19328)
Epoch: 128 | Batch_idx: 160 |  Loss: (0.1485) |  Loss2: (0.0000) | Acc: (94.00%) (19549/20608)
Epoch: 128 | Batch_idx: 170 |  Loss: (0.1485) |  Loss2: (0.0000) | Acc: (94.00%) (20767/21888)
Epoch: 128 | Batch_idx: 180 |  Loss: (0.1477) |  Loss2: (0.0000) | Acc: (94.00%) (21996/23168)
Epoch: 128 | Batch_idx: 190 |  Loss: (0.1482) |  Loss2: (0.0000) | Acc: (94.00%) (23206/24448)
Epoch: 128 | Batch_idx: 200 |  Loss: (0.1484) |  Loss2: (0.0000) | Acc: (94.00%) (24424/25728)
Epoch: 128 | Batch_idx: 210 |  Loss: (0.1484) |  Loss2: (0.0000) | Acc: (94.00%) (25636/27008)
Epoch: 128 | Batch_idx: 220 |  Loss: (0.1468) |  Loss2: (0.0000) | Acc: (94.00%) (26863/28288)
Epoch: 128 | Batch_idx: 230 |  Loss: (0.1470) |  Loss2: (0.0000) | Acc: (94.00%) (28084/29568)
Epoch: 128 | Batch_idx: 240 |  Loss: (0.1470) |  Loss2: (0.0000) | Acc: (94.00%) (29301/30848)
Epoch: 128 | Batch_idx: 250 |  Loss: (0.1478) |  Loss2: (0.0000) | Acc: (94.00%) (30512/32128)
Epoch: 128 | Batch_idx: 260 |  Loss: (0.1479) |  Loss2: (0.0000) | Acc: (94.00%) (31732/33408)
Epoch: 128 | Batch_idx: 270 |  Loss: (0.1473) |  Loss2: (0.0000) | Acc: (95.00%) (32956/34688)
Epoch: 128 | Batch_idx: 280 |  Loss: (0.1479) |  Loss2: (0.0000) | Acc: (95.00%) (34171/35968)
Epoch: 128 | Batch_idx: 290 |  Loss: (0.1477) |  Loss2: (0.0000) | Acc: (95.00%) (35388/37248)
Epoch: 128 | Batch_idx: 300 |  Loss: (0.1476) |  Loss2: (0.0000) | Acc: (95.00%) (36605/38528)
Epoch: 128 | Batch_idx: 310 |  Loss: (0.1478) |  Loss2: (0.0000) | Acc: (94.00%) (37814/39808)
Epoch: 128 | Batch_idx: 320 |  Loss: (0.1474) |  Loss2: (0.0000) | Acc: (95.00%) (39042/41088)
Epoch: 128 | Batch_idx: 330 |  Loss: (0.1475) |  Loss2: (0.0000) | Acc: (95.00%) (40251/42368)
Epoch: 128 | Batch_idx: 340 |  Loss: (0.1478) |  Loss2: (0.0000) | Acc: (94.00%) (41462/43648)
Epoch: 128 | Batch_idx: 350 |  Loss: (0.1476) |  Loss2: (0.0000) | Acc: (94.00%) (42681/44928)
Epoch: 128 | Batch_idx: 360 |  Loss: (0.1476) |  Loss2: (0.0000) | Acc: (95.00%) (43898/46208)
Epoch: 128 | Batch_idx: 370 |  Loss: (0.1469) |  Loss2: (0.0000) | Acc: (95.00%) (45123/47488)
Epoch: 128 | Batch_idx: 380 |  Loss: (0.1468) |  Loss2: (0.0000) | Acc: (95.00%) (46345/48768)
Epoch: 128 | Batch_idx: 390 |  Loss: (0.1461) |  Loss2: (0.0000) | Acc: (95.00%) (47529/50000)
# TEST : Loss: (0.3696) | Acc: (88.00%) (8839/10000)
percent tensor([0.5555, 0.5356, 0.5719, 0.5641, 0.5712, 0.5619, 0.5512, 0.5599, 0.5596,
        0.5484, 0.5496, 0.5616, 0.5472, 0.5392, 0.5470, 0.5500],
       device='cuda:0') torch.Size([16])
percent tensor([0.5190, 0.5274, 0.5134, 0.5231, 0.5160, 0.5427, 0.5206, 0.5142, 0.5091,
        0.5134, 0.5143, 0.5064, 0.5102, 0.5313, 0.5293, 0.5264],
       device='cuda:0') torch.Size([16])
percent tensor([0.5855, 0.6676, 0.5421, 0.4785, 0.5290, 0.4886, 0.6164, 0.5414, 0.5768,
        0.6340, 0.6235, 0.6150, 0.6913, 0.5226, 0.6014, 0.5632],
       device='cuda:0') torch.Size([16])
percent tensor([0.6979, 0.6879, 0.7086, 0.7211, 0.7187, 0.7047, 0.7092, 0.7068, 0.7138,
        0.7008, 0.7317, 0.7176, 0.6922, 0.7147, 0.7071, 0.7051],
       device='cuda:0') torch.Size([16])
percent tensor([0.6288, 0.6264, 0.6773, 0.6317, 0.6538, 0.8179, 0.6521, 0.5596, 0.6933,
        0.6315, 0.6988, 0.5941, 0.6951, 0.7181, 0.6159, 0.7031],
       device='cuda:0') torch.Size([16])
percent tensor([0.5718, 0.6909, 0.5524, 0.4951, 0.5274, 0.5813, 0.5595, 0.3957, 0.6908,
        0.6532, 0.7441, 0.6149, 0.7099, 0.7596, 0.4725, 0.5489],
       device='cuda:0') torch.Size([16])
percent tensor([0.5584, 0.6519, 0.7990, 0.7694, 0.8371, 0.6885, 0.6774, 0.6825, 0.6927,
        0.6566, 0.7062, 0.7684, 0.6597, 0.7072, 0.6377, 0.5843],
       device='cuda:0') torch.Size([16])
percent tensor([0.9997, 0.9990, 0.9995, 0.9994, 0.9992, 0.9992, 0.9991, 0.9994, 0.9991,
        0.9993, 0.9994, 0.9995, 0.9993, 0.9988, 0.9992, 0.9993],
       device='cuda:0') torch.Size([16])
Epoch: 129 | Batch_idx: 0 |  Loss: (0.1022) |  Loss2: (0.0000) | Acc: (96.00%) (124/128)
Epoch: 129 | Batch_idx: 10 |  Loss: (0.1287) |  Loss2: (0.0000) | Acc: (95.00%) (1346/1408)
Epoch: 129 | Batch_idx: 20 |  Loss: (0.1402) |  Loss2: (0.0000) | Acc: (95.00%) (2567/2688)
Epoch: 129 | Batch_idx: 30 |  Loss: (0.1478) |  Loss2: (0.0000) | Acc: (95.00%) (3774/3968)
Epoch: 129 | Batch_idx: 40 |  Loss: (0.1539) |  Loss2: (0.0000) | Acc: (94.00%) (4974/5248)
Epoch: 129 | Batch_idx: 50 |  Loss: (0.1481) |  Loss2: (0.0000) | Acc: (94.00%) (6196/6528)
Epoch: 129 | Batch_idx: 60 |  Loss: (0.1483) |  Loss2: (0.0000) | Acc: (94.00%) (7407/7808)
Epoch: 129 | Batch_idx: 70 |  Loss: (0.1507) |  Loss2: (0.0000) | Acc: (94.00%) (8616/9088)
Epoch: 129 | Batch_idx: 80 |  Loss: (0.1544) |  Loss2: (0.0000) | Acc: (94.00%) (9814/10368)
Epoch: 129 | Batch_idx: 90 |  Loss: (0.1514) |  Loss2: (0.0000) | Acc: (94.00%) (11043/11648)
Epoch: 129 | Batch_idx: 100 |  Loss: (0.1507) |  Loss2: (0.0000) | Acc: (94.00%) (12262/12928)
Epoch: 129 | Batch_idx: 110 |  Loss: (0.1491) |  Loss2: (0.0000) | Acc: (94.00%) (13488/14208)
Epoch: 129 | Batch_idx: 120 |  Loss: (0.1487) |  Loss2: (0.0000) | Acc: (94.00%) (14702/15488)
Epoch: 129 | Batch_idx: 130 |  Loss: (0.1492) |  Loss2: (0.0000) | Acc: (94.00%) (15912/16768)
Epoch: 129 | Batch_idx: 140 |  Loss: (0.1482) |  Loss2: (0.0000) | Acc: (94.00%) (17134/18048)
Epoch: 129 | Batch_idx: 150 |  Loss: (0.1476) |  Loss2: (0.0000) | Acc: (94.00%) (18359/19328)
Epoch: 129 | Batch_idx: 160 |  Loss: (0.1486) |  Loss2: (0.0000) | Acc: (94.00%) (19567/20608)
Epoch: 129 | Batch_idx: 170 |  Loss: (0.1488) |  Loss2: (0.0000) | Acc: (94.00%) (20779/21888)
Epoch: 129 | Batch_idx: 180 |  Loss: (0.1494) |  Loss2: (0.0000) | Acc: (94.00%) (21989/23168)
Epoch: 129 | Batch_idx: 190 |  Loss: (0.1483) |  Loss2: (0.0000) | Acc: (94.00%) (23208/24448)
Epoch: 129 | Batch_idx: 200 |  Loss: (0.1491) |  Loss2: (0.0000) | Acc: (94.00%) (24415/25728)
Epoch: 129 | Batch_idx: 210 |  Loss: (0.1486) |  Loss2: (0.0000) | Acc: (94.00%) (25633/27008)
Epoch: 129 | Batch_idx: 220 |  Loss: (0.1485) |  Loss2: (0.0000) | Acc: (94.00%) (26848/28288)
Epoch: 129 | Batch_idx: 230 |  Loss: (0.1486) |  Loss2: (0.0000) | Acc: (94.00%) (28062/29568)
Epoch: 129 | Batch_idx: 240 |  Loss: (0.1484) |  Loss2: (0.0000) | Acc: (94.00%) (29278/30848)
Epoch: 129 | Batch_idx: 250 |  Loss: (0.1481) |  Loss2: (0.0000) | Acc: (94.00%) (30502/32128)
Epoch: 129 | Batch_idx: 260 |  Loss: (0.1470) |  Loss2: (0.0000) | Acc: (94.00%) (31728/33408)
Epoch: 129 | Batch_idx: 270 |  Loss: (0.1468) |  Loss2: (0.0000) | Acc: (94.00%) (32944/34688)
Epoch: 129 | Batch_idx: 280 |  Loss: (0.1462) |  Loss2: (0.0000) | Acc: (95.00%) (34174/35968)
Epoch: 129 | Batch_idx: 290 |  Loss: (0.1462) |  Loss2: (0.0000) | Acc: (95.00%) (35389/37248)
Epoch: 129 | Batch_idx: 300 |  Loss: (0.1470) |  Loss2: (0.0000) | Acc: (94.00%) (36600/38528)
Epoch: 129 | Batch_idx: 310 |  Loss: (0.1468) |  Loss2: (0.0000) | Acc: (95.00%) (37820/39808)
Epoch: 129 | Batch_idx: 320 |  Loss: (0.1475) |  Loss2: (0.0000) | Acc: (94.00%) (39021/41088)
Epoch: 129 | Batch_idx: 330 |  Loss: (0.1470) |  Loss2: (0.0000) | Acc: (94.00%) (40244/42368)
Epoch: 129 | Batch_idx: 340 |  Loss: (0.1472) |  Loss2: (0.0000) | Acc: (94.00%) (41458/43648)
Epoch: 129 | Batch_idx: 350 |  Loss: (0.1468) |  Loss2: (0.0000) | Acc: (94.00%) (42680/44928)
Epoch: 129 | Batch_idx: 360 |  Loss: (0.1464) |  Loss2: (0.0000) | Acc: (95.00%) (43900/46208)
Epoch: 129 | Batch_idx: 370 |  Loss: (0.1463) |  Loss2: (0.0000) | Acc: (95.00%) (45121/47488)
Epoch: 129 | Batch_idx: 380 |  Loss: (0.1465) |  Loss2: (0.0000) | Acc: (95.00%) (46341/48768)
Epoch: 129 | Batch_idx: 390 |  Loss: (0.1465) |  Loss2: (0.0000) | Acc: (95.00%) (47512/50000)
# TEST : Loss: (0.3687) | Acc: (88.00%) (8846/10000)
percent tensor([0.5516, 0.5322, 0.5670, 0.5594, 0.5663, 0.5585, 0.5471, 0.5549, 0.5552,
        0.5442, 0.5460, 0.5569, 0.5432, 0.5356, 0.5435, 0.5463],
       device='cuda:0') torch.Size([16])
percent tensor([0.5192, 0.5286, 0.5134, 0.5235, 0.5160, 0.5442, 0.5212, 0.5140, 0.5087,
        0.5137, 0.5146, 0.5062, 0.5103, 0.5320, 0.5306, 0.5271],
       device='cuda:0') torch.Size([16])
percent tensor([0.5891, 0.6700, 0.5462, 0.4844, 0.5334, 0.4946, 0.6191, 0.5445, 0.5798,
        0.6364, 0.6265, 0.6168, 0.6927, 0.5270, 0.6045, 0.5678],
       device='cuda:0') torch.Size([16])
percent tensor([0.6988, 0.6905, 0.7087, 0.7214, 0.7189, 0.7056, 0.7103, 0.7061, 0.7139,
        0.7026, 0.7336, 0.7184, 0.6946, 0.7160, 0.7087, 0.7070],
       device='cuda:0') torch.Size([16])
percent tensor([0.6404, 0.6368, 0.6890, 0.6414, 0.6631, 0.8228, 0.6643, 0.5734, 0.7037,
        0.6398, 0.7082, 0.6041, 0.7033, 0.7270, 0.6268, 0.7118],
       device='cuda:0') torch.Size([16])
percent tensor([0.5589, 0.6810, 0.5470, 0.4855, 0.5184, 0.5735, 0.5500, 0.3875, 0.6858,
        0.6429, 0.7380, 0.6038, 0.7027, 0.7546, 0.4570, 0.5375],
       device='cuda:0') torch.Size([16])
percent tensor([0.5488, 0.6442, 0.7934, 0.7643, 0.8314, 0.6879, 0.6685, 0.6740, 0.6820,
        0.6463, 0.7013, 0.7606, 0.6457, 0.6990, 0.6287, 0.5801],
       device='cuda:0') torch.Size([16])
percent tensor([0.9997, 0.9989, 0.9995, 0.9995, 0.9992, 0.9993, 0.9992, 0.9994, 0.9991,
        0.9994, 0.9994, 0.9995, 0.9993, 0.9989, 0.9992, 0.9993],
       device='cuda:0') torch.Size([16])
True Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=128, out_features=16, bias=False)
False Linear(in_features=16, out_features=2, bias=False)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=128, out_features=16, bias=False)
False Linear(in_features=16, out_features=2, bias=False)
True Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=256, out_features=32, bias=False)
False Linear(in_features=32, out_features=2, bias=False)
True Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=256, out_features=32, bias=False)
False Linear(in_features=32, out_features=2, bias=False)
True Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=512, out_features=64, bias=False)
False Linear(in_features=64, out_features=2, bias=False)
True Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=512, out_features=64, bias=False)
False Linear(in_features=64, out_features=2, bias=False)
True Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1024, out_features=128, bias=False)
False Linear(in_features=128, out_features=2, bias=False)
True Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1024, out_features=128, bias=False)
False Linear(in_features=128, out_features=2, bias=False)
True Linear(in_features=512, out_features=10, bias=True)
Epoch: 130 | Batch_idx: 0 |  Loss: (0.1095) |  Loss2: (0.0000) | Acc: (96.00%) (123/128)
Epoch: 130 | Batch_idx: 10 |  Loss: (0.1341) |  Loss2: (0.0000) | Acc: (95.00%) (1349/1408)
Epoch: 130 | Batch_idx: 20 |  Loss: (0.1406) |  Loss2: (0.0000) | Acc: (95.00%) (2570/2688)
Epoch: 130 | Batch_idx: 30 |  Loss: (0.1435) |  Loss2: (0.0000) | Acc: (95.00%) (3789/3968)
Epoch: 130 | Batch_idx: 40 |  Loss: (0.1452) |  Loss2: (0.0000) | Acc: (95.00%) (5005/5248)
Epoch: 130 | Batch_idx: 50 |  Loss: (0.1476) |  Loss2: (0.0000) | Acc: (95.00%) (6211/6528)
Epoch: 130 | Batch_idx: 60 |  Loss: (0.1475) |  Loss2: (0.0000) | Acc: (95.00%) (7424/7808)
Epoch: 130 | Batch_idx: 70 |  Loss: (0.1491) |  Loss2: (0.0000) | Acc: (95.00%) (8636/9088)
Epoch: 130 | Batch_idx: 80 |  Loss: (0.1470) |  Loss2: (0.0000) | Acc: (95.00%) (9856/10368)
Epoch: 130 | Batch_idx: 90 |  Loss: (0.1472) |  Loss2: (0.0000) | Acc: (95.00%) (11075/11648)
Epoch: 130 | Batch_idx: 100 |  Loss: (0.1469) |  Loss2: (0.0000) | Acc: (95.00%) (12289/12928)
Epoch: 130 | Batch_idx: 110 |  Loss: (0.1448) |  Loss2: (0.0000) | Acc: (95.00%) (13515/14208)
Epoch: 130 | Batch_idx: 120 |  Loss: (0.1460) |  Loss2: (0.0000) | Acc: (95.00%) (14717/15488)
Epoch: 130 | Batch_idx: 130 |  Loss: (0.1455) |  Loss2: (0.0000) | Acc: (95.00%) (15937/16768)
Epoch: 130 | Batch_idx: 140 |  Loss: (0.1466) |  Loss2: (0.0000) | Acc: (94.00%) (17144/18048)
Epoch: 130 | Batch_idx: 150 |  Loss: (0.1475) |  Loss2: (0.0000) | Acc: (94.00%) (18352/19328)
Epoch: 130 | Batch_idx: 160 |  Loss: (0.1461) |  Loss2: (0.0000) | Acc: (95.00%) (19578/20608)
Epoch: 130 | Batch_idx: 170 |  Loss: (0.1472) |  Loss2: (0.0000) | Acc: (94.00%) (20787/21888)
Epoch: 130 | Batch_idx: 180 |  Loss: (0.1472) |  Loss2: (0.0000) | Acc: (94.00%) (22006/23168)
Epoch: 130 | Batch_idx: 190 |  Loss: (0.1463) |  Loss2: (0.0000) | Acc: (95.00%) (23232/24448)
Epoch: 130 | Batch_idx: 200 |  Loss: (0.1466) |  Loss2: (0.0000) | Acc: (95.00%) (24451/25728)
Epoch: 130 | Batch_idx: 210 |  Loss: (0.1470) |  Loss2: (0.0000) | Acc: (95.00%) (25663/27008)
Epoch: 130 | Batch_idx: 220 |  Loss: (0.1468) |  Loss2: (0.0000) | Acc: (95.00%) (26882/28288)
Epoch: 130 | Batch_idx: 230 |  Loss: (0.1470) |  Loss2: (0.0000) | Acc: (95.00%) (28095/29568)
Epoch: 130 | Batch_idx: 240 |  Loss: (0.1474) |  Loss2: (0.0000) | Acc: (94.00%) (29303/30848)
Epoch: 130 | Batch_idx: 250 |  Loss: (0.1486) |  Loss2: (0.0000) | Acc: (94.00%) (30503/32128)
Epoch: 130 | Batch_idx: 260 |  Loss: (0.1480) |  Loss2: (0.0000) | Acc: (94.00%) (31726/33408)
Epoch: 130 | Batch_idx: 270 |  Loss: (0.1494) |  Loss2: (0.0000) | Acc: (94.00%) (32926/34688)
Epoch: 130 | Batch_idx: 280 |  Loss: (0.1498) |  Loss2: (0.0000) | Acc: (94.00%) (34137/35968)
Epoch: 130 | Batch_idx: 290 |  Loss: (0.1502) |  Loss2: (0.0000) | Acc: (94.00%) (35346/37248)
Epoch: 130 | Batch_idx: 300 |  Loss: (0.1503) |  Loss2: (0.0000) | Acc: (94.00%) (36567/38528)
Epoch: 130 | Batch_idx: 310 |  Loss: (0.1501) |  Loss2: (0.0000) | Acc: (94.00%) (37786/39808)
Epoch: 130 | Batch_idx: 320 |  Loss: (0.1495) |  Loss2: (0.0000) | Acc: (94.00%) (39001/41088)
Epoch: 130 | Batch_idx: 330 |  Loss: (0.1502) |  Loss2: (0.0000) | Acc: (94.00%) (40207/42368)
Epoch: 130 | Batch_idx: 340 |  Loss: (0.1509) |  Loss2: (0.0000) | Acc: (94.00%) (41412/43648)
Epoch: 130 | Batch_idx: 350 |  Loss: (0.1510) |  Loss2: (0.0000) | Acc: (94.00%) (42623/44928)
Epoch: 130 | Batch_idx: 360 |  Loss: (0.1515) |  Loss2: (0.0000) | Acc: (94.00%) (43823/46208)
Epoch: 130 | Batch_idx: 370 |  Loss: (0.1521) |  Loss2: (0.0000) | Acc: (94.00%) (45025/47488)
Epoch: 130 | Batch_idx: 380 |  Loss: (0.1523) |  Loss2: (0.0000) | Acc: (94.00%) (46235/48768)
Epoch: 130 | Batch_idx: 390 |  Loss: (0.1529) |  Loss2: (0.0000) | Acc: (94.00%) (47391/50000)
=> saving checkpoint 'drive/app/torch/save_Routing_Gate_2/checkpoint_130.pth.tar'
# TEST : Loss: (0.4215) | Acc: (87.00%) (8709/10000)
percent tensor([0.5520, 0.5326, 0.5661, 0.5586, 0.5656, 0.5573, 0.5470, 0.5541, 0.5559,
        0.5444, 0.5462, 0.5570, 0.5447, 0.5353, 0.5429, 0.5464],
       device='cuda:0') torch.Size([16])
percent tensor([0.5191, 0.5284, 0.5145, 0.5235, 0.5164, 0.5414, 0.5208, 0.5151, 0.5097,
        0.5144, 0.5142, 0.5085, 0.5113, 0.5316, 0.5294, 0.5259],
       device='cuda:0') torch.Size([16])
percent tensor([0.5879, 0.6710, 0.5301, 0.4799, 0.5241, 0.5066, 0.6214, 0.5356, 0.5785,
        0.6323, 0.6297, 0.6038, 0.6910, 0.5431, 0.6052, 0.5704],
       device='cuda:0') torch.Size([16])
percent tensor([0.6965, 0.6875, 0.7074, 0.7223, 0.7153, 0.7012, 0.7131, 0.7064, 0.7055,
        0.6972, 0.7280, 0.7211, 0.6926, 0.7169, 0.7102, 0.7052],
       device='cuda:0') torch.Size([16])
percent tensor([0.6393, 0.6554, 0.6891, 0.6271, 0.6598, 0.8022, 0.6706, 0.5853, 0.7101,
        0.6453, 0.7101, 0.6129, 0.7122, 0.7325, 0.6334, 0.6989],
       device='cuda:0') torch.Size([16])
percent tensor([0.5511, 0.6924, 0.5830, 0.4877, 0.5429, 0.5585, 0.5668, 0.4029, 0.6843,
        0.6735, 0.7445, 0.6318, 0.7056, 0.7515, 0.4674, 0.5183],
       device='cuda:0') torch.Size([16])
percent tensor([0.5696, 0.6361, 0.8147, 0.7790, 0.8543, 0.7006, 0.6665, 0.7053, 0.6754,
        0.6493, 0.6923, 0.7720, 0.6766, 0.6727, 0.6439, 0.5756],
       device='cuda:0') torch.Size([16])
percent tensor([0.9996, 0.9987, 0.9995, 0.9993, 0.9993, 0.9992, 0.9990, 0.9994, 0.9992,
        0.9995, 0.9996, 0.9994, 0.9994, 0.9992, 0.9993, 0.9993],
       device='cuda:0') torch.Size([16])
Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 3, 3, 3]) tensor(181.9097, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(813.5894, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(822.1243, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([128, 64, 3, 3]) tensor(1515.4877, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([128, 64, 1, 1]) tensor(491.0112, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([128, 128, 3, 3]) tensor(2266.0566, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([256, 128, 3, 3]) tensor(4287.9941, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([256, 128, 1, 1]) tensor(1381.1884, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([256, 256, 3, 3]) tensor(6181.6523, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([512, 256, 3, 3]) tensor(11784.1318, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([512, 256, 1, 1]) tensor(3900.1733, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([512, 512, 3, 3]) tensor(16457.4668, device='cuda:0', grad_fn=<NormBackward0>)
Epoch: 131 | Batch_idx: 0 |  Loss: (0.1156) |  Loss2: (0.0000) | Acc: (96.00%) (123/128)
Epoch: 131 | Batch_idx: 10 |  Loss: (0.1449) |  Loss2: (0.0000) | Acc: (95.00%) (1341/1408)
Epoch: 131 | Batch_idx: 20 |  Loss: (0.1436) |  Loss2: (0.0000) | Acc: (95.00%) (2561/2688)
Epoch: 131 | Batch_idx: 30 |  Loss: (0.1407) |  Loss2: (0.0000) | Acc: (95.00%) (3782/3968)
Epoch: 131 | Batch_idx: 40 |  Loss: (0.1499) |  Loss2: (0.0000) | Acc: (95.00%) (4989/5248)
Epoch: 131 | Batch_idx: 50 |  Loss: (0.1524) |  Loss2: (0.0000) | Acc: (94.00%) (6197/6528)
Epoch: 131 | Batch_idx: 60 |  Loss: (0.1531) |  Loss2: (0.0000) | Acc: (94.00%) (7404/7808)
Epoch: 131 | Batch_idx: 70 |  Loss: (0.1557) |  Loss2: (0.0000) | Acc: (94.00%) (8608/9088)
Epoch: 131 | Batch_idx: 80 |  Loss: (0.1543) |  Loss2: (0.0000) | Acc: (94.00%) (9835/10368)
Epoch: 131 | Batch_idx: 90 |  Loss: (0.1536) |  Loss2: (0.0000) | Acc: (94.00%) (11052/11648)
Epoch: 131 | Batch_idx: 100 |  Loss: (0.1507) |  Loss2: (0.0000) | Acc: (94.00%) (12278/12928)
Epoch: 131 | Batch_idx: 110 |  Loss: (0.1503) |  Loss2: (0.0000) | Acc: (94.00%) (13492/14208)
Epoch: 131 | Batch_idx: 120 |  Loss: (0.1483) |  Loss2: (0.0000) | Acc: (94.00%) (14711/15488)
Epoch: 131 | Batch_idx: 130 |  Loss: (0.1495) |  Loss2: (0.0000) | Acc: (94.00%) (15913/16768)
Epoch: 131 | Batch_idx: 140 |  Loss: (0.1519) |  Loss2: (0.0000) | Acc: (94.00%) (17110/18048)
Epoch: 131 | Batch_idx: 150 |  Loss: (0.1493) |  Loss2: (0.0000) | Acc: (94.00%) (18345/19328)
Epoch: 131 | Batch_idx: 160 |  Loss: (0.1491) |  Loss2: (0.0000) | Acc: (94.00%) (19563/20608)
Epoch: 131 | Batch_idx: 170 |  Loss: (0.1487) |  Loss2: (0.0000) | Acc: (94.00%) (20779/21888)
Epoch: 131 | Batch_idx: 180 |  Loss: (0.1482) |  Loss2: (0.0000) | Acc: (94.00%) (22001/23168)
Epoch: 131 | Batch_idx: 190 |  Loss: (0.1488) |  Loss2: (0.0000) | Acc: (94.00%) (23211/24448)
Epoch: 131 | Batch_idx: 200 |  Loss: (0.1484) |  Loss2: (0.0000) | Acc: (94.00%) (24427/25728)
Epoch: 131 | Batch_idx: 210 |  Loss: (0.1484) |  Loss2: (0.0000) | Acc: (94.00%) (25646/27008)
Epoch: 131 | Batch_idx: 220 |  Loss: (0.1476) |  Loss2: (0.0000) | Acc: (95.00%) (26875/28288)
Epoch: 131 | Batch_idx: 230 |  Loss: (0.1480) |  Loss2: (0.0000) | Acc: (94.00%) (28083/29568)
Epoch: 131 | Batch_idx: 240 |  Loss: (0.1483) |  Loss2: (0.0000) | Acc: (94.00%) (29296/30848)
Epoch: 131 | Batch_idx: 250 |  Loss: (0.1483) |  Loss2: (0.0000) | Acc: (94.00%) (30509/32128)
Epoch: 131 | Batch_idx: 260 |  Loss: (0.1480) |  Loss2: (0.0000) | Acc: (94.00%) (31728/33408)
Epoch: 131 | Batch_idx: 270 |  Loss: (0.1487) |  Loss2: (0.0000) | Acc: (94.00%) (32941/34688)
Epoch: 131 | Batch_idx: 280 |  Loss: (0.1497) |  Loss2: (0.0000) | Acc: (94.00%) (34143/35968)
Epoch: 131 | Batch_idx: 290 |  Loss: (0.1492) |  Loss2: (0.0000) | Acc: (94.00%) (35364/37248)
Epoch: 131 | Batch_idx: 300 |  Loss: (0.1491) |  Loss2: (0.0000) | Acc: (94.00%) (36580/38528)
Epoch: 131 | Batch_idx: 310 |  Loss: (0.1495) |  Loss2: (0.0000) | Acc: (94.00%) (37791/39808)
Epoch: 131 | Batch_idx: 320 |  Loss: (0.1491) |  Loss2: (0.0000) | Acc: (94.00%) (39008/41088)
Epoch: 131 | Batch_idx: 330 |  Loss: (0.1496) |  Loss2: (0.0000) | Acc: (94.00%) (40210/42368)
Epoch: 131 | Batch_idx: 340 |  Loss: (0.1501) |  Loss2: (0.0000) | Acc: (94.00%) (41414/43648)
Epoch: 131 | Batch_idx: 350 |  Loss: (0.1517) |  Loss2: (0.0000) | Acc: (94.00%) (42604/44928)
Epoch: 131 | Batch_idx: 360 |  Loss: (0.1514) |  Loss2: (0.0000) | Acc: (94.00%) (43824/46208)
Epoch: 131 | Batch_idx: 370 |  Loss: (0.1521) |  Loss2: (0.0000) | Acc: (94.00%) (45023/47488)
Epoch: 131 | Batch_idx: 380 |  Loss: (0.1524) |  Loss2: (0.0000) | Acc: (94.00%) (46234/48768)
Epoch: 131 | Batch_idx: 390 |  Loss: (0.1529) |  Loss2: (0.0000) | Acc: (94.00%) (47391/50000)
# TEST : Loss: (0.4457) | Acc: (86.00%) (8620/10000)
percent tensor([0.5516, 0.5321, 0.5666, 0.5589, 0.5653, 0.5584, 0.5463, 0.5547, 0.5558,
        0.5436, 0.5465, 0.5565, 0.5442, 0.5351, 0.5433, 0.5470],
       device='cuda:0') torch.Size([16])
percent tensor([0.5193, 0.5303, 0.5118, 0.5248, 0.5162, 0.5433, 0.5224, 0.5147, 0.5091,
        0.5155, 0.5151, 0.5084, 0.5112, 0.5345, 0.5314, 0.5274],
       device='cuda:0') torch.Size([16])
percent tensor([0.5885, 0.6757, 0.5376, 0.4852, 0.5274, 0.4985, 0.6235, 0.5492, 0.5816,
        0.6400, 0.6270, 0.6094, 0.6905, 0.5480, 0.6078, 0.5718],
       device='cuda:0') torch.Size([16])
percent tensor([0.7022, 0.6991, 0.7043, 0.7185, 0.7158, 0.7047, 0.7157, 0.7054, 0.7153,
        0.7081, 0.7395, 0.7250, 0.7015, 0.7230, 0.7169, 0.7090],
       device='cuda:0') torch.Size([16])
percent tensor([0.6415, 0.6646, 0.7032, 0.6342, 0.6575, 0.8057, 0.6667, 0.6043, 0.7097,
        0.6626, 0.7217, 0.6122, 0.7191, 0.7368, 0.6262, 0.6918],
       device='cuda:0') torch.Size([16])
percent tensor([0.5597, 0.6865, 0.5707, 0.5163, 0.5424, 0.5583, 0.5403, 0.4256, 0.6803,
        0.6544, 0.7447, 0.6362, 0.6986, 0.7482, 0.4650, 0.5330],
       device='cuda:0') torch.Size([16])
percent tensor([0.5232, 0.6156, 0.8106, 0.7677, 0.8528, 0.6668, 0.6457, 0.7127, 0.6848,
        0.6347, 0.6819, 0.7524, 0.6622, 0.6646, 0.6117, 0.5591],
       device='cuda:0') torch.Size([16])
percent tensor([0.9996, 0.9989, 0.9993, 0.9992, 0.9994, 0.9989, 0.9993, 0.9995, 0.9992,
        0.9994, 0.9995, 0.9994, 0.9994, 0.9990, 0.9991, 0.9992],
       device='cuda:0') torch.Size([16])
Epoch: 132 | Batch_idx: 0 |  Loss: (0.0977) |  Loss2: (0.0000) | Acc: (95.00%) (122/128)
Epoch: 132 | Batch_idx: 10 |  Loss: (0.1226) |  Loss2: (0.0000) | Acc: (96.00%) (1352/1408)
Epoch: 132 | Batch_idx: 20 |  Loss: (0.1368) |  Loss2: (0.0000) | Acc: (95.00%) (2564/2688)
Epoch: 132 | Batch_idx: 30 |  Loss: (0.1399) |  Loss2: (0.0000) | Acc: (95.00%) (3774/3968)
Epoch: 132 | Batch_idx: 40 |  Loss: (0.1423) |  Loss2: (0.0000) | Acc: (95.00%) (4989/5248)
Epoch: 132 | Batch_idx: 50 |  Loss: (0.1407) |  Loss2: (0.0000) | Acc: (95.00%) (6219/6528)
Epoch: 132 | Batch_idx: 60 |  Loss: (0.1450) |  Loss2: (0.0000) | Acc: (95.00%) (7431/7808)
Epoch: 132 | Batch_idx: 70 |  Loss: (0.1484) |  Loss2: (0.0000) | Acc: (95.00%) (8638/9088)
Epoch: 132 | Batch_idx: 80 |  Loss: (0.1495) |  Loss2: (0.0000) | Acc: (94.00%) (9840/10368)
Epoch: 132 | Batch_idx: 90 |  Loss: (0.1488) |  Loss2: (0.0000) | Acc: (94.00%) (11050/11648)
Epoch: 132 | Batch_idx: 100 |  Loss: (0.1481) |  Loss2: (0.0000) | Acc: (94.00%) (12273/12928)
Epoch: 132 | Batch_idx: 110 |  Loss: (0.1461) |  Loss2: (0.0000) | Acc: (94.00%) (13494/14208)
Epoch: 132 | Batch_idx: 120 |  Loss: (0.1457) |  Loss2: (0.0000) | Acc: (94.00%) (14712/15488)
Epoch: 132 | Batch_idx: 130 |  Loss: (0.1471) |  Loss2: (0.0000) | Acc: (94.00%) (15921/16768)
Epoch: 132 | Batch_idx: 140 |  Loss: (0.1460) |  Loss2: (0.0000) | Acc: (94.00%) (17143/18048)
Epoch: 132 | Batch_idx: 150 |  Loss: (0.1457) |  Loss2: (0.0000) | Acc: (94.00%) (18355/19328)
Epoch: 132 | Batch_idx: 160 |  Loss: (0.1450) |  Loss2: (0.0000) | Acc: (94.00%) (19574/20608)
Epoch: 132 | Batch_idx: 170 |  Loss: (0.1441) |  Loss2: (0.0000) | Acc: (95.00%) (20796/21888)
Epoch: 132 | Batch_idx: 180 |  Loss: (0.1450) |  Loss2: (0.0000) | Acc: (94.00%) (22008/23168)
Epoch: 132 | Batch_idx: 190 |  Loss: (0.1444) |  Loss2: (0.0000) | Acc: (95.00%) (23234/24448)
Epoch: 132 | Batch_idx: 200 |  Loss: (0.1439) |  Loss2: (0.0000) | Acc: (95.00%) (24447/25728)
Epoch: 132 | Batch_idx: 210 |  Loss: (0.1444) |  Loss2: (0.0000) | Acc: (95.00%) (25665/27008)
Epoch: 132 | Batch_idx: 220 |  Loss: (0.1456) |  Loss2: (0.0000) | Acc: (94.00%) (26873/28288)
Epoch: 132 | Batch_idx: 230 |  Loss: (0.1449) |  Loss2: (0.0000) | Acc: (95.00%) (28093/29568)
Epoch: 132 | Batch_idx: 240 |  Loss: (0.1452) |  Loss2: (0.0000) | Acc: (94.00%) (29301/30848)
Epoch: 132 | Batch_idx: 250 |  Loss: (0.1458) |  Loss2: (0.0000) | Acc: (94.00%) (30507/32128)
Epoch: 132 | Batch_idx: 260 |  Loss: (0.1456) |  Loss2: (0.0000) | Acc: (94.00%) (31732/33408)
Epoch: 132 | Batch_idx: 270 |  Loss: (0.1453) |  Loss2: (0.0000) | Acc: (95.00%) (32955/34688)
Epoch: 132 | Batch_idx: 280 |  Loss: (0.1454) |  Loss2: (0.0000) | Acc: (94.00%) (34168/35968)
Epoch: 132 | Batch_idx: 290 |  Loss: (0.1456) |  Loss2: (0.0000) | Acc: (94.00%) (35377/37248)
Epoch: 132 | Batch_idx: 300 |  Loss: (0.1454) |  Loss2: (0.0000) | Acc: (94.00%) (36593/38528)
Epoch: 132 | Batch_idx: 310 |  Loss: (0.1452) |  Loss2: (0.0000) | Acc: (94.00%) (37813/39808)
Epoch: 132 | Batch_idx: 320 |  Loss: (0.1452) |  Loss2: (0.0000) | Acc: (94.00%) (39032/41088)
Epoch: 132 | Batch_idx: 330 |  Loss: (0.1457) |  Loss2: (0.0000) | Acc: (95.00%) (40251/42368)
Epoch: 132 | Batch_idx: 340 |  Loss: (0.1454) |  Loss2: (0.0000) | Acc: (95.00%) (41476/43648)
Epoch: 132 | Batch_idx: 350 |  Loss: (0.1450) |  Loss2: (0.0000) | Acc: (95.00%) (42699/44928)
Epoch: 132 | Batch_idx: 360 |  Loss: (0.1451) |  Loss2: (0.0000) | Acc: (95.00%) (43911/46208)
Epoch: 132 | Batch_idx: 370 |  Loss: (0.1456) |  Loss2: (0.0000) | Acc: (95.00%) (45122/47488)
Epoch: 132 | Batch_idx: 380 |  Loss: (0.1464) |  Loss2: (0.0000) | Acc: (94.00%) (46321/48768)
Epoch: 132 | Batch_idx: 390 |  Loss: (0.1464) |  Loss2: (0.0000) | Acc: (94.00%) (47493/50000)
# TEST : Loss: (0.4057) | Acc: (87.00%) (8731/10000)
percent tensor([0.5515, 0.5342, 0.5659, 0.5613, 0.5646, 0.5583, 0.5475, 0.5565, 0.5560,
        0.5448, 0.5466, 0.5559, 0.5447, 0.5384, 0.5442, 0.5480],
       device='cuda:0') torch.Size([16])
percent tensor([0.5205, 0.5284, 0.5144, 0.5223, 0.5172, 0.5441, 0.5215, 0.5144, 0.5108,
        0.5145, 0.5142, 0.5095, 0.5121, 0.5319, 0.5300, 0.5265],
       device='cuda:0') torch.Size([16])
percent tensor([0.5910, 0.6670, 0.5464, 0.4888, 0.5300, 0.4884, 0.6193, 0.5482, 0.5778,
        0.6368, 0.6293, 0.6118, 0.6941, 0.5200, 0.6029, 0.5677],
       device='cuda:0') torch.Size([16])
percent tensor([0.6995, 0.6939, 0.7041, 0.7172, 0.7173, 0.7091, 0.7183, 0.7020, 0.7165,
        0.7035, 0.7404, 0.7243, 0.6948, 0.7277, 0.7141, 0.7066],
       device='cuda:0') torch.Size([16])
percent tensor([0.6251, 0.6364, 0.6887, 0.6165, 0.6618, 0.8006, 0.6571, 0.5807, 0.7157,
        0.6478, 0.7337, 0.6015, 0.7087, 0.7143, 0.6083, 0.6933],
       device='cuda:0') torch.Size([16])
percent tensor([0.5546, 0.6929, 0.5433, 0.5142, 0.5300, 0.5696, 0.5580, 0.4149, 0.6853,
        0.6472, 0.7432, 0.6238, 0.7004, 0.7534, 0.4643, 0.5305],
       device='cuda:0') torch.Size([16])
percent tensor([0.5525, 0.5955, 0.7862, 0.7552, 0.8438, 0.6815, 0.6489, 0.6809, 0.6879,
        0.6410, 0.6970, 0.7478, 0.6796, 0.6838, 0.6264, 0.5611],
       device='cuda:0') torch.Size([16])
percent tensor([0.9995, 0.9990, 0.9991, 0.9994, 0.9994, 0.9991, 0.9992, 0.9993, 0.9991,
        0.9991, 0.9996, 0.9992, 0.9993, 0.9990, 0.9992, 0.9992],
       device='cuda:0') torch.Size([16])
Epoch: 133 | Batch_idx: 0 |  Loss: (0.1933) |  Loss2: (0.0000) | Acc: (89.00%) (115/128)
Epoch: 133 | Batch_idx: 10 |  Loss: (0.1329) |  Loss2: (0.0000) | Acc: (95.00%) (1343/1408)
Epoch: 133 | Batch_idx: 20 |  Loss: (0.1227) |  Loss2: (0.0000) | Acc: (95.00%) (2574/2688)
Epoch: 133 | Batch_idx: 30 |  Loss: (0.1228) |  Loss2: (0.0000) | Acc: (95.00%) (3799/3968)
Epoch: 133 | Batch_idx: 40 |  Loss: (0.1252) |  Loss2: (0.0000) | Acc: (95.00%) (5020/5248)
Epoch: 133 | Batch_idx: 50 |  Loss: (0.1290) |  Loss2: (0.0000) | Acc: (95.00%) (6244/6528)
Epoch: 133 | Batch_idx: 60 |  Loss: (0.1307) |  Loss2: (0.0000) | Acc: (95.00%) (7465/7808)
Epoch: 133 | Batch_idx: 70 |  Loss: (0.1328) |  Loss2: (0.0000) | Acc: (95.00%) (8673/9088)
Epoch: 133 | Batch_idx: 80 |  Loss: (0.1388) |  Loss2: (0.0000) | Acc: (95.00%) (9871/10368)
Epoch: 133 | Batch_idx: 90 |  Loss: (0.1403) |  Loss2: (0.0000) | Acc: (95.00%) (11094/11648)
Epoch: 133 | Batch_idx: 100 |  Loss: (0.1405) |  Loss2: (0.0000) | Acc: (95.00%) (12316/12928)
Epoch: 133 | Batch_idx: 110 |  Loss: (0.1422) |  Loss2: (0.0000) | Acc: (95.00%) (13521/14208)
Epoch: 133 | Batch_idx: 120 |  Loss: (0.1448) |  Loss2: (0.0000) | Acc: (95.00%) (14730/15488)
Epoch: 133 | Batch_idx: 130 |  Loss: (0.1443) |  Loss2: (0.0000) | Acc: (95.00%) (15950/16768)
Epoch: 133 | Batch_idx: 140 |  Loss: (0.1445) |  Loss2: (0.0000) | Acc: (95.00%) (17163/18048)
Epoch: 133 | Batch_idx: 150 |  Loss: (0.1452) |  Loss2: (0.0000) | Acc: (95.00%) (18370/19328)
Epoch: 133 | Batch_idx: 160 |  Loss: (0.1442) |  Loss2: (0.0000) | Acc: (95.00%) (19599/20608)
Epoch: 133 | Batch_idx: 170 |  Loss: (0.1448) |  Loss2: (0.0000) | Acc: (95.00%) (20813/21888)
Epoch: 133 | Batch_idx: 180 |  Loss: (0.1444) |  Loss2: (0.0000) | Acc: (95.00%) (22032/23168)
Epoch: 133 | Batch_idx: 190 |  Loss: (0.1448) |  Loss2: (0.0000) | Acc: (95.00%) (23248/24448)
Epoch: 133 | Batch_idx: 200 |  Loss: (0.1437) |  Loss2: (0.0000) | Acc: (95.00%) (24475/25728)
Epoch: 133 | Batch_idx: 210 |  Loss: (0.1432) |  Loss2: (0.0000) | Acc: (95.00%) (25698/27008)
Epoch: 133 | Batch_idx: 220 |  Loss: (0.1427) |  Loss2: (0.0000) | Acc: (95.00%) (26922/28288)
Epoch: 133 | Batch_idx: 230 |  Loss: (0.1427) |  Loss2: (0.0000) | Acc: (95.00%) (28141/29568)
Epoch: 133 | Batch_idx: 240 |  Loss: (0.1432) |  Loss2: (0.0000) | Acc: (95.00%) (29350/30848)
Epoch: 133 | Batch_idx: 250 |  Loss: (0.1437) |  Loss2: (0.0000) | Acc: (95.00%) (30566/32128)
Epoch: 133 | Batch_idx: 260 |  Loss: (0.1438) |  Loss2: (0.0000) | Acc: (95.00%) (31778/33408)
Epoch: 133 | Batch_idx: 270 |  Loss: (0.1439) |  Loss2: (0.0000) | Acc: (95.00%) (32992/34688)
Epoch: 133 | Batch_idx: 280 |  Loss: (0.1438) |  Loss2: (0.0000) | Acc: (95.00%) (34207/35968)
Epoch: 133 | Batch_idx: 290 |  Loss: (0.1443) |  Loss2: (0.0000) | Acc: (95.00%) (35419/37248)
Epoch: 133 | Batch_idx: 300 |  Loss: (0.1439) |  Loss2: (0.0000) | Acc: (95.00%) (36642/38528)
Epoch: 133 | Batch_idx: 310 |  Loss: (0.1434) |  Loss2: (0.0000) | Acc: (95.00%) (37867/39808)
Epoch: 133 | Batch_idx: 320 |  Loss: (0.1429) |  Loss2: (0.0000) | Acc: (95.00%) (39084/41088)
Epoch: 133 | Batch_idx: 330 |  Loss: (0.1434) |  Loss2: (0.0000) | Acc: (95.00%) (40296/42368)
Epoch: 133 | Batch_idx: 340 |  Loss: (0.1439) |  Loss2: (0.0000) | Acc: (95.00%) (41494/43648)
Epoch: 133 | Batch_idx: 350 |  Loss: (0.1448) |  Loss2: (0.0000) | Acc: (95.00%) (42693/44928)
Epoch: 133 | Batch_idx: 360 |  Loss: (0.1446) |  Loss2: (0.0000) | Acc: (95.00%) (43912/46208)
Epoch: 133 | Batch_idx: 370 |  Loss: (0.1449) |  Loss2: (0.0000) | Acc: (95.00%) (45122/47488)
Epoch: 133 | Batch_idx: 380 |  Loss: (0.1445) |  Loss2: (0.0000) | Acc: (95.00%) (46355/48768)
Epoch: 133 | Batch_idx: 390 |  Loss: (0.1447) |  Loss2: (0.0000) | Acc: (95.00%) (47525/50000)
# TEST : Loss: (0.3788) | Acc: (88.00%) (8830/10000)
percent tensor([0.5513, 0.5346, 0.5649, 0.5593, 0.5638, 0.5564, 0.5470, 0.5561, 0.5557,
        0.5449, 0.5472, 0.5554, 0.5448, 0.5389, 0.5433, 0.5472],
       device='cuda:0') torch.Size([16])
percent tensor([0.5202, 0.5285, 0.5171, 0.5258, 0.5187, 0.5449, 0.5209, 0.5162, 0.5092,
        0.5155, 0.5143, 0.5113, 0.5113, 0.5299, 0.5313, 0.5274],
       device='cuda:0') torch.Size([16])
percent tensor([0.5872, 0.6659, 0.5543, 0.4899, 0.5396, 0.4972, 0.6208, 0.5484, 0.5705,
        0.6399, 0.6205, 0.6185, 0.6865, 0.5229, 0.6034, 0.5696],
       device='cuda:0') torch.Size([16])
percent tensor([0.6942, 0.6974, 0.7043, 0.7210, 0.7170, 0.7073, 0.7181, 0.7042, 0.7082,
        0.7051, 0.7341, 0.7265, 0.6893, 0.7220, 0.7163, 0.7062],
       device='cuda:0') torch.Size([16])
percent tensor([0.6336, 0.6417, 0.6850, 0.6295, 0.6770, 0.8093, 0.6604, 0.5793, 0.7088,
        0.6338, 0.7113, 0.6029, 0.7056, 0.7107, 0.6328, 0.6986],
       device='cuda:0') torch.Size([16])
percent tensor([0.5484, 0.6914, 0.5508, 0.5083, 0.5243, 0.5843, 0.5634, 0.4031, 0.6721,
        0.6293, 0.7334, 0.6217, 0.6989, 0.7486, 0.4830, 0.5480],
       device='cuda:0') torch.Size([16])
percent tensor([0.5875, 0.6288, 0.7976, 0.7651, 0.8478, 0.6831, 0.6923, 0.7092, 0.7250,
        0.6756, 0.7070, 0.7770, 0.7071, 0.6819, 0.6509, 0.5842],
       device='cuda:0') torch.Size([16])
percent tensor([0.9996, 0.9991, 0.9994, 0.9994, 0.9992, 0.9988, 0.9991, 0.9994, 0.9990,
        0.9993, 0.9996, 0.9995, 0.9993, 0.9983, 0.9990, 0.9990],
       device='cuda:0') torch.Size([16])
Epoch: 134 | Batch_idx: 0 |  Loss: (0.1470) |  Loss2: (0.0000) | Acc: (96.00%) (123/128)
Epoch: 134 | Batch_idx: 10 |  Loss: (0.1399) |  Loss2: (0.0000) | Acc: (95.00%) (1340/1408)
Epoch: 134 | Batch_idx: 20 |  Loss: (0.1375) |  Loss2: (0.0000) | Acc: (95.00%) (2561/2688)
Epoch: 134 | Batch_idx: 30 |  Loss: (0.1339) |  Loss2: (0.0000) | Acc: (95.00%) (3789/3968)
Epoch: 134 | Batch_idx: 40 |  Loss: (0.1336) |  Loss2: (0.0000) | Acc: (95.00%) (5014/5248)
Epoch: 134 | Batch_idx: 50 |  Loss: (0.1355) |  Loss2: (0.0000) | Acc: (95.00%) (6234/6528)
Epoch: 134 | Batch_idx: 60 |  Loss: (0.1363) |  Loss2: (0.0000) | Acc: (95.00%) (7452/7808)
Epoch: 134 | Batch_idx: 70 |  Loss: (0.1355) |  Loss2: (0.0000) | Acc: (95.00%) (8671/9088)
Epoch: 134 | Batch_idx: 80 |  Loss: (0.1358) |  Loss2: (0.0000) | Acc: (95.00%) (9890/10368)
Epoch: 134 | Batch_idx: 90 |  Loss: (0.1363) |  Loss2: (0.0000) | Acc: (95.00%) (11112/11648)
Epoch: 134 | Batch_idx: 100 |  Loss: (0.1377) |  Loss2: (0.0000) | Acc: (95.00%) (12333/12928)
Epoch: 134 | Batch_idx: 110 |  Loss: (0.1372) |  Loss2: (0.0000) | Acc: (95.00%) (13559/14208)
Epoch: 134 | Batch_idx: 120 |  Loss: (0.1360) |  Loss2: (0.0000) | Acc: (95.00%) (14785/15488)
Epoch: 134 | Batch_idx: 130 |  Loss: (0.1351) |  Loss2: (0.0000) | Acc: (95.00%) (16012/16768)
Epoch: 134 | Batch_idx: 140 |  Loss: (0.1365) |  Loss2: (0.0000) | Acc: (95.00%) (17227/18048)
Epoch: 134 | Batch_idx: 150 |  Loss: (0.1389) |  Loss2: (0.0000) | Acc: (95.00%) (18426/19328)
Epoch: 134 | Batch_idx: 160 |  Loss: (0.1384) |  Loss2: (0.0000) | Acc: (95.00%) (19646/20608)
Epoch: 134 | Batch_idx: 170 |  Loss: (0.1379) |  Loss2: (0.0000) | Acc: (95.00%) (20871/21888)
Epoch: 134 | Batch_idx: 180 |  Loss: (0.1384) |  Loss2: (0.0000) | Acc: (95.00%) (22081/23168)
Epoch: 134 | Batch_idx: 190 |  Loss: (0.1392) |  Loss2: (0.0000) | Acc: (95.00%) (23288/24448)
Epoch: 134 | Batch_idx: 200 |  Loss: (0.1389) |  Loss2: (0.0000) | Acc: (95.00%) (24510/25728)
Epoch: 134 | Batch_idx: 210 |  Loss: (0.1394) |  Loss2: (0.0000) | Acc: (95.00%) (25729/27008)
Epoch: 134 | Batch_idx: 220 |  Loss: (0.1385) |  Loss2: (0.0000) | Acc: (95.00%) (26962/28288)
Epoch: 134 | Batch_idx: 230 |  Loss: (0.1383) |  Loss2: (0.0000) | Acc: (95.00%) (28181/29568)
Epoch: 134 | Batch_idx: 240 |  Loss: (0.1380) |  Loss2: (0.0000) | Acc: (95.00%) (29414/30848)
Epoch: 134 | Batch_idx: 250 |  Loss: (0.1388) |  Loss2: (0.0000) | Acc: (95.00%) (30627/32128)
Epoch: 134 | Batch_idx: 260 |  Loss: (0.1382) |  Loss2: (0.0000) | Acc: (95.00%) (31852/33408)
Epoch: 134 | Batch_idx: 270 |  Loss: (0.1384) |  Loss2: (0.0000) | Acc: (95.00%) (33074/34688)
Epoch: 134 | Batch_idx: 280 |  Loss: (0.1384) |  Loss2: (0.0000) | Acc: (95.00%) (34287/35968)
Epoch: 134 | Batch_idx: 290 |  Loss: (0.1382) |  Loss2: (0.0000) | Acc: (95.00%) (35513/37248)
Epoch: 134 | Batch_idx: 300 |  Loss: (0.1387) |  Loss2: (0.0000) | Acc: (95.00%) (36721/38528)
Epoch: 134 | Batch_idx: 310 |  Loss: (0.1385) |  Loss2: (0.0000) | Acc: (95.00%) (37942/39808)
Epoch: 134 | Batch_idx: 320 |  Loss: (0.1384) |  Loss2: (0.0000) | Acc: (95.00%) (39166/41088)
Epoch: 134 | Batch_idx: 330 |  Loss: (0.1384) |  Loss2: (0.0000) | Acc: (95.00%) (40387/42368)
Epoch: 134 | Batch_idx: 340 |  Loss: (0.1385) |  Loss2: (0.0000) | Acc: (95.00%) (41598/43648)
Epoch: 134 | Batch_idx: 350 |  Loss: (0.1384) |  Loss2: (0.0000) | Acc: (95.00%) (42817/44928)
Epoch: 134 | Batch_idx: 360 |  Loss: (0.1388) |  Loss2: (0.0000) | Acc: (95.00%) (44027/46208)
Epoch: 134 | Batch_idx: 370 |  Loss: (0.1378) |  Loss2: (0.0000) | Acc: (95.00%) (45263/47488)
Epoch: 134 | Batch_idx: 380 |  Loss: (0.1384) |  Loss2: (0.0000) | Acc: (95.00%) (46471/48768)
Epoch: 134 | Batch_idx: 390 |  Loss: (0.1380) |  Loss2: (0.0000) | Acc: (95.00%) (47652/50000)
# TEST : Loss: (0.3844) | Acc: (88.00%) (8839/10000)
percent tensor([0.5514, 0.5338, 0.5662, 0.5605, 0.5648, 0.5563, 0.5479, 0.5566, 0.5559,
        0.5450, 0.5466, 0.5570, 0.5443, 0.5386, 0.5435, 0.5474],
       device='cuda:0') torch.Size([16])
percent tensor([0.5202, 0.5295, 0.5143, 0.5249, 0.5156, 0.5423, 0.5217, 0.5169, 0.5098,
        0.5153, 0.5150, 0.5086, 0.5123, 0.5328, 0.5309, 0.5274],
       device='cuda:0') torch.Size([16])
percent tensor([0.5988, 0.6663, 0.5688, 0.4920, 0.5516, 0.5034, 0.6199, 0.5571, 0.5802,
        0.6400, 0.6258, 0.6213, 0.6923, 0.5136, 0.6044, 0.5700],
       device='cuda:0') torch.Size([16])
percent tensor([0.6946, 0.6981, 0.7008, 0.7208, 0.7149, 0.7080, 0.7149, 0.7034, 0.7114,
        0.7078, 0.7352, 0.7219, 0.6938, 0.7261, 0.7152, 0.7094],
       device='cuda:0') torch.Size([16])
percent tensor([0.6317, 0.6402, 0.6979, 0.6390, 0.6863, 0.8151, 0.6624, 0.5970, 0.7178,
        0.6385, 0.7184, 0.6030, 0.7002, 0.7058, 0.6272, 0.7028],
       device='cuda:0') torch.Size([16])
percent tensor([0.5514, 0.6989, 0.5709, 0.5061, 0.5295, 0.5779, 0.5707, 0.3985, 0.6780,
        0.6537, 0.7231, 0.6334, 0.6924, 0.7487, 0.4697, 0.5352],
       device='cuda:0') torch.Size([16])
percent tensor([0.5489, 0.5931, 0.7985, 0.7433, 0.8451, 0.6831, 0.6714, 0.6784, 0.7029,
        0.6555, 0.6820, 0.7553, 0.6693, 0.6730, 0.6264, 0.5705],
       device='cuda:0') torch.Size([16])
percent tensor([0.9996, 0.9989, 0.9993, 0.9994, 0.9993, 0.9992, 0.9991, 0.9993, 0.9991,
        0.9994, 0.9996, 0.9993, 0.9991, 0.9990, 0.9992, 0.9991],
       device='cuda:0') torch.Size([16])
False Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=128, out_features=16, bias=False)
True Linear(in_features=16, out_features=2, bias=False)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=128, out_features=16, bias=False)
True Linear(in_features=16, out_features=2, bias=False)
False Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=256, out_features=32, bias=False)
True Linear(in_features=32, out_features=2, bias=False)
False Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=256, out_features=32, bias=False)
True Linear(in_features=32, out_features=2, bias=False)
False Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=512, out_features=64, bias=False)
True Linear(in_features=64, out_features=2, bias=False)
False Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=512, out_features=64, bias=False)
True Linear(in_features=64, out_features=2, bias=False)
False Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1024, out_features=128, bias=False)
True Linear(in_features=128, out_features=2, bias=False)
False Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1024, out_features=128, bias=False)
True Linear(in_features=128, out_features=2, bias=False)
False Linear(in_features=512, out_features=10, bias=True)
Epoch: 135 | Batch_idx: 0 |  Loss: (0.2228) |  Loss2: (0.0000) | Acc: (92.00%) (119/128)
Epoch: 135 | Batch_idx: 10 |  Loss: (0.1295) |  Loss2: (0.0000) | Acc: (95.00%) (1340/1408)
Epoch: 135 | Batch_idx: 20 |  Loss: (0.1348) |  Loss2: (0.0000) | Acc: (95.00%) (2556/2688)
Epoch: 135 | Batch_idx: 30 |  Loss: (0.1395) |  Loss2: (0.0000) | Acc: (95.00%) (3771/3968)
Epoch: 135 | Batch_idx: 40 |  Loss: (0.1429) |  Loss2: (0.0000) | Acc: (94.00%) (4980/5248)
Epoch: 135 | Batch_idx: 50 |  Loss: (0.1428) |  Loss2: (0.0000) | Acc: (94.00%) (6199/6528)
Epoch: 135 | Batch_idx: 60 |  Loss: (0.1471) |  Loss2: (0.0000) | Acc: (94.00%) (7401/7808)
Epoch: 135 | Batch_idx: 70 |  Loss: (0.1478) |  Loss2: (0.0000) | Acc: (94.00%) (8614/9088)
Epoch: 135 | Batch_idx: 80 |  Loss: (0.1475) |  Loss2: (0.0000) | Acc: (94.00%) (9826/10368)
Epoch: 135 | Batch_idx: 90 |  Loss: (0.1488) |  Loss2: (0.0000) | Acc: (94.00%) (11030/11648)
Epoch: 135 | Batch_idx: 100 |  Loss: (0.1474) |  Loss2: (0.0000) | Acc: (94.00%) (12253/12928)
Epoch: 135 | Batch_idx: 110 |  Loss: (0.1479) |  Loss2: (0.0000) | Acc: (94.00%) (13459/14208)
Epoch: 135 | Batch_idx: 120 |  Loss: (0.1480) |  Loss2: (0.0000) | Acc: (94.00%) (14671/15488)
Epoch: 135 | Batch_idx: 130 |  Loss: (0.1480) |  Loss2: (0.0000) | Acc: (94.00%) (15890/16768)
Epoch: 135 | Batch_idx: 140 |  Loss: (0.1486) |  Loss2: (0.0000) | Acc: (94.00%) (17099/18048)
Epoch: 135 | Batch_idx: 150 |  Loss: (0.1477) |  Loss2: (0.0000) | Acc: (94.00%) (18316/19328)
Epoch: 135 | Batch_idx: 160 |  Loss: (0.1486) |  Loss2: (0.0000) | Acc: (94.00%) (19525/20608)
Epoch: 135 | Batch_idx: 170 |  Loss: (0.1478) |  Loss2: (0.0000) | Acc: (94.00%) (20746/21888)
Epoch: 135 | Batch_idx: 180 |  Loss: (0.1489) |  Loss2: (0.0000) | Acc: (94.00%) (21945/23168)
Epoch: 135 | Batch_idx: 190 |  Loss: (0.1503) |  Loss2: (0.0000) | Acc: (94.00%) (23146/24448)
Epoch: 135 | Batch_idx: 200 |  Loss: (0.1492) |  Loss2: (0.0000) | Acc: (94.00%) (24374/25728)
Epoch: 135 | Batch_idx: 210 |  Loss: (0.1503) |  Loss2: (0.0000) | Acc: (94.00%) (25575/27008)
Epoch: 135 | Batch_idx: 220 |  Loss: (0.1501) |  Loss2: (0.0000) | Acc: (94.00%) (26784/28288)
Epoch: 135 | Batch_idx: 230 |  Loss: (0.1497) |  Loss2: (0.0000) | Acc: (94.00%) (28003/29568)
Epoch: 135 | Batch_idx: 240 |  Loss: (0.1490) |  Loss2: (0.0000) | Acc: (94.00%) (29218/30848)
Epoch: 135 | Batch_idx: 250 |  Loss: (0.1492) |  Loss2: (0.0000) | Acc: (94.00%) (30430/32128)
Epoch: 135 | Batch_idx: 260 |  Loss: (0.1485) |  Loss2: (0.0000) | Acc: (94.00%) (31653/33408)
Epoch: 135 | Batch_idx: 270 |  Loss: (0.1486) |  Loss2: (0.0000) | Acc: (94.00%) (32859/34688)
Epoch: 135 | Batch_idx: 280 |  Loss: (0.1487) |  Loss2: (0.0000) | Acc: (94.00%) (34067/35968)
Epoch: 135 | Batch_idx: 290 |  Loss: (0.1488) |  Loss2: (0.0000) | Acc: (94.00%) (35280/37248)
Epoch: 135 | Batch_idx: 300 |  Loss: (0.1486) |  Loss2: (0.0000) | Acc: (94.00%) (36497/38528)
Epoch: 135 | Batch_idx: 310 |  Loss: (0.1483) |  Loss2: (0.0000) | Acc: (94.00%) (37723/39808)
Epoch: 135 | Batch_idx: 320 |  Loss: (0.1480) |  Loss2: (0.0000) | Acc: (94.00%) (38943/41088)
Epoch: 135 | Batch_idx: 330 |  Loss: (0.1484) |  Loss2: (0.0000) | Acc: (94.00%) (40152/42368)
Epoch: 135 | Batch_idx: 340 |  Loss: (0.1481) |  Loss2: (0.0000) | Acc: (94.00%) (41361/43648)
Epoch: 135 | Batch_idx: 350 |  Loss: (0.1478) |  Loss2: (0.0000) | Acc: (94.00%) (42573/44928)
Epoch: 135 | Batch_idx: 360 |  Loss: (0.1477) |  Loss2: (0.0000) | Acc: (94.00%) (43776/46208)
Epoch: 135 | Batch_idx: 370 |  Loss: (0.1476) |  Loss2: (0.0000) | Acc: (94.00%) (44987/47488)
Epoch: 135 | Batch_idx: 380 |  Loss: (0.1477) |  Loss2: (0.0000) | Acc: (94.00%) (46204/48768)
Epoch: 135 | Batch_idx: 390 |  Loss: (0.1473) |  Loss2: (0.0000) | Acc: (94.00%) (47379/50000)
=> saving checkpoint 'drive/app/torch/save_Routing_Gate_2/checkpoint_135.pth.tar'
# TEST : Loss: (0.3700) | Acc: (88.00%) (8854/10000)
percent tensor([0.5643, 0.5491, 0.5786, 0.5731, 0.5790, 0.5687, 0.5631, 0.5713, 0.5699,
        0.5597, 0.5604, 0.5703, 0.5581, 0.5527, 0.5577, 0.5606],
       device='cuda:0') torch.Size([16])
percent tensor([0.5260, 0.5349, 0.5189, 0.5281, 0.5197, 0.5473, 0.5272, 0.5206, 0.5147,
        0.5208, 0.5207, 0.5141, 0.5179, 0.5362, 0.5363, 0.5323],
       device='cuda:0') torch.Size([16])
percent tensor([0.6043, 0.6672, 0.5760, 0.5014, 0.5573, 0.5123, 0.6237, 0.5582, 0.5841,
        0.6421, 0.6301, 0.6270, 0.6964, 0.5169, 0.6080, 0.5760],
       device='cuda:0') torch.Size([16])
percent tensor([0.6872, 0.6911, 0.6946, 0.7124, 0.7072, 0.7013, 0.7081, 0.6952, 0.7038,
        0.6992, 0.7299, 0.7149, 0.6873, 0.7155, 0.7087, 0.7028],
       device='cuda:0') torch.Size([16])
percent tensor([0.6221, 0.6417, 0.6881, 0.6453, 0.7002, 0.8053, 0.6605, 0.6070, 0.7161,
        0.6320, 0.7155, 0.6059, 0.6904, 0.7021, 0.6289, 0.7079],
       device='cuda:0') torch.Size([16])
percent tensor([0.5406, 0.6797, 0.5661, 0.5037, 0.5207, 0.5516, 0.5635, 0.3916, 0.6653,
        0.6443, 0.7098, 0.6220, 0.6746, 0.7323, 0.4556, 0.5148],
       device='cuda:0') torch.Size([16])
percent tensor([0.5436, 0.5601, 0.7945, 0.7420, 0.8414, 0.6641, 0.6735, 0.6889, 0.6924,
        0.6289, 0.6580, 0.7611, 0.6448, 0.6328, 0.6311, 0.5536],
       device='cuda:0') torch.Size([16])
percent tensor([0.9996, 0.9988, 0.9993, 0.9995, 0.9991, 0.9991, 0.9990, 0.9993, 0.9990,
        0.9993, 0.9995, 0.9993, 0.9991, 0.9991, 0.9991, 0.9991],
       device='cuda:0') torch.Size([16])
Epoch: 136 | Batch_idx: 0 |  Loss: (0.0845) |  Loss2: (0.0000) | Acc: (97.00%) (125/128)
Epoch: 136 | Batch_idx: 10 |  Loss: (0.1421) |  Loss2: (0.0000) | Acc: (95.00%) (1345/1408)
Epoch: 136 | Batch_idx: 20 |  Loss: (0.1397) |  Loss2: (0.0000) | Acc: (95.00%) (2564/2688)
Epoch: 136 | Batch_idx: 30 |  Loss: (0.1376) |  Loss2: (0.0000) | Acc: (95.00%) (3793/3968)
Epoch: 136 | Batch_idx: 40 |  Loss: (0.1430) |  Loss2: (0.0000) | Acc: (95.00%) (4999/5248)
Epoch: 136 | Batch_idx: 50 |  Loss: (0.1410) |  Loss2: (0.0000) | Acc: (95.00%) (6222/6528)
Epoch: 136 | Batch_idx: 60 |  Loss: (0.1415) |  Loss2: (0.0000) | Acc: (95.00%) (7442/7808)
Epoch: 136 | Batch_idx: 70 |  Loss: (0.1388) |  Loss2: (0.0000) | Acc: (95.00%) (8665/9088)
Epoch: 136 | Batch_idx: 80 |  Loss: (0.1406) |  Loss2: (0.0000) | Acc: (95.00%) (9874/10368)
Epoch: 136 | Batch_idx: 90 |  Loss: (0.1422) |  Loss2: (0.0000) | Acc: (95.00%) (11082/11648)
Epoch: 136 | Batch_idx: 100 |  Loss: (0.1402) |  Loss2: (0.0000) | Acc: (95.00%) (12311/12928)
Epoch: 136 | Batch_idx: 110 |  Loss: (0.1386) |  Loss2: (0.0000) | Acc: (95.00%) (13538/14208)
Epoch: 136 | Batch_idx: 120 |  Loss: (0.1366) |  Loss2: (0.0000) | Acc: (95.00%) (14766/15488)
Epoch: 136 | Batch_idx: 130 |  Loss: (0.1385) |  Loss2: (0.0000) | Acc: (95.00%) (15977/16768)
Epoch: 136 | Batch_idx: 140 |  Loss: (0.1390) |  Loss2: (0.0000) | Acc: (95.00%) (17191/18048)
Epoch: 136 | Batch_idx: 150 |  Loss: (0.1392) |  Loss2: (0.0000) | Acc: (95.00%) (18402/19328)
Epoch: 136 | Batch_idx: 160 |  Loss: (0.1378) |  Loss2: (0.0000) | Acc: (95.00%) (19639/20608)
Epoch: 136 | Batch_idx: 170 |  Loss: (0.1361) |  Loss2: (0.0000) | Acc: (95.00%) (20875/21888)
Epoch: 136 | Batch_idx: 180 |  Loss: (0.1359) |  Loss2: (0.0000) | Acc: (95.00%) (22095/23168)
Epoch: 136 | Batch_idx: 190 |  Loss: (0.1370) |  Loss2: (0.0000) | Acc: (95.00%) (23308/24448)
Epoch: 136 | Batch_idx: 200 |  Loss: (0.1364) |  Loss2: (0.0000) | Acc: (95.00%) (24538/25728)
Epoch: 136 | Batch_idx: 210 |  Loss: (0.1359) |  Loss2: (0.0000) | Acc: (95.00%) (25756/27008)
Epoch: 136 | Batch_idx: 220 |  Loss: (0.1356) |  Loss2: (0.0000) | Acc: (95.00%) (26981/28288)
Epoch: 136 | Batch_idx: 230 |  Loss: (0.1360) |  Loss2: (0.0000) | Acc: (95.00%) (28196/29568)
Epoch: 136 | Batch_idx: 240 |  Loss: (0.1362) |  Loss2: (0.0000) | Acc: (95.00%) (29407/30848)
Epoch: 136 | Batch_idx: 250 |  Loss: (0.1351) |  Loss2: (0.0000) | Acc: (95.00%) (30645/32128)
Epoch: 136 | Batch_idx: 260 |  Loss: (0.1356) |  Loss2: (0.0000) | Acc: (95.00%) (31871/33408)
Epoch: 136 | Batch_idx: 270 |  Loss: (0.1357) |  Loss2: (0.0000) | Acc: (95.00%) (33093/34688)
Epoch: 136 | Batch_idx: 280 |  Loss: (0.1356) |  Loss2: (0.0000) | Acc: (95.00%) (34310/35968)
Epoch: 136 | Batch_idx: 290 |  Loss: (0.1360) |  Loss2: (0.0000) | Acc: (95.00%) (35526/37248)
Epoch: 136 | Batch_idx: 300 |  Loss: (0.1357) |  Loss2: (0.0000) | Acc: (95.00%) (36749/38528)
Epoch: 136 | Batch_idx: 310 |  Loss: (0.1355) |  Loss2: (0.0000) | Acc: (95.00%) (37971/39808)
Epoch: 136 | Batch_idx: 320 |  Loss: (0.1357) |  Loss2: (0.0000) | Acc: (95.00%) (39185/41088)
Epoch: 136 | Batch_idx: 330 |  Loss: (0.1353) |  Loss2: (0.0000) | Acc: (95.00%) (40415/42368)
Epoch: 136 | Batch_idx: 340 |  Loss: (0.1348) |  Loss2: (0.0000) | Acc: (95.00%) (41647/43648)
Epoch: 136 | Batch_idx: 350 |  Loss: (0.1346) |  Loss2: (0.0000) | Acc: (95.00%) (42875/44928)
Epoch: 136 | Batch_idx: 360 |  Loss: (0.1346) |  Loss2: (0.0000) | Acc: (95.00%) (44099/46208)
Epoch: 136 | Batch_idx: 370 |  Loss: (0.1341) |  Loss2: (0.0000) | Acc: (95.00%) (45325/47488)
Epoch: 136 | Batch_idx: 380 |  Loss: (0.1337) |  Loss2: (0.0000) | Acc: (95.00%) (46551/48768)
Epoch: 136 | Batch_idx: 390 |  Loss: (0.1342) |  Loss2: (0.0000) | Acc: (95.00%) (47723/50000)
# TEST : Loss: (0.3601) | Acc: (88.00%) (8877/10000)
percent tensor([0.5648, 0.5503, 0.5782, 0.5728, 0.5790, 0.5688, 0.5638, 0.5712, 0.5702,
        0.5602, 0.5609, 0.5701, 0.5588, 0.5533, 0.5583, 0.5611],
       device='cuda:0') torch.Size([16])
percent tensor([0.5281, 0.5369, 0.5210, 0.5299, 0.5215, 0.5494, 0.5292, 0.5220, 0.5164,
        0.5228, 0.5229, 0.5160, 0.5200, 0.5376, 0.5384, 0.5342],
       device='cuda:0') torch.Size([16])
percent tensor([0.6025, 0.6639, 0.5717, 0.4991, 0.5507, 0.5119, 0.6204, 0.5539, 0.5810,
        0.6389, 0.6287, 0.6242, 0.6932, 0.5167, 0.6061, 0.5743],
       device='cuda:0') torch.Size([16])
percent tensor([0.6953, 0.6979, 0.7024, 0.7193, 0.7144, 0.7099, 0.7147, 0.7022, 0.7105,
        0.7064, 0.7366, 0.7217, 0.6960, 0.7205, 0.7167, 0.7105],
       device='cuda:0') torch.Size([16])
percent tensor([0.6220, 0.6476, 0.6807, 0.6394, 0.6950, 0.8032, 0.6582, 0.5965, 0.7120,
        0.6342, 0.7128, 0.6026, 0.6917, 0.7009, 0.6265, 0.7087],
       device='cuda:0') torch.Size([16])
percent tensor([0.5407, 0.6786, 0.5665, 0.5037, 0.5175, 0.5455, 0.5600, 0.3908, 0.6634,
        0.6426, 0.7082, 0.6270, 0.6745, 0.7321, 0.4501, 0.5111],
       device='cuda:0') torch.Size([16])
percent tensor([0.5575, 0.5708, 0.8069, 0.7567, 0.8487, 0.6709, 0.6790, 0.7072, 0.6992,
        0.6400, 0.6674, 0.7700, 0.6556, 0.6292, 0.6442, 0.5597],
       device='cuda:0') torch.Size([16])
percent tensor([0.9997, 0.9989, 0.9994, 0.9995, 0.9992, 0.9991, 0.9991, 0.9993, 0.9991,
        0.9994, 0.9996, 0.9993, 0.9992, 0.9990, 0.9991, 0.9991],
       device='cuda:0') torch.Size([16])
Epoch: 137 | Batch_idx: 0 |  Loss: (0.1725) |  Loss2: (0.0000) | Acc: (92.00%) (118/128)
Epoch: 137 | Batch_idx: 10 |  Loss: (0.1162) |  Loss2: (0.0000) | Acc: (95.00%) (1349/1408)
Epoch: 137 | Batch_idx: 20 |  Loss: (0.1211) |  Loss2: (0.0000) | Acc: (95.00%) (2568/2688)
Epoch: 137 | Batch_idx: 30 |  Loss: (0.1226) |  Loss2: (0.0000) | Acc: (95.00%) (3801/3968)
Epoch: 137 | Batch_idx: 40 |  Loss: (0.1273) |  Loss2: (0.0000) | Acc: (95.00%) (5021/5248)
Epoch: 137 | Batch_idx: 50 |  Loss: (0.1269) |  Loss2: (0.0000) | Acc: (95.00%) (6239/6528)
Epoch: 137 | Batch_idx: 60 |  Loss: (0.1257) |  Loss2: (0.0000) | Acc: (95.00%) (7467/7808)
Epoch: 137 | Batch_idx: 70 |  Loss: (0.1257) |  Loss2: (0.0000) | Acc: (95.00%) (8696/9088)
Epoch: 137 | Batch_idx: 80 |  Loss: (0.1276) |  Loss2: (0.0000) | Acc: (95.00%) (9914/10368)
Epoch: 137 | Batch_idx: 90 |  Loss: (0.1299) |  Loss2: (0.0000) | Acc: (95.00%) (11128/11648)
Epoch: 137 | Batch_idx: 100 |  Loss: (0.1312) |  Loss2: (0.0000) | Acc: (95.00%) (12344/12928)
Epoch: 137 | Batch_idx: 110 |  Loss: (0.1303) |  Loss2: (0.0000) | Acc: (95.00%) (13568/14208)
Epoch: 137 | Batch_idx: 120 |  Loss: (0.1309) |  Loss2: (0.0000) | Acc: (95.00%) (14792/15488)
Epoch: 137 | Batch_idx: 130 |  Loss: (0.1298) |  Loss2: (0.0000) | Acc: (95.00%) (16017/16768)
Epoch: 137 | Batch_idx: 140 |  Loss: (0.1307) |  Loss2: (0.0000) | Acc: (95.00%) (17235/18048)
Epoch: 137 | Batch_idx: 150 |  Loss: (0.1313) |  Loss2: (0.0000) | Acc: (95.00%) (18456/19328)
Epoch: 137 | Batch_idx: 160 |  Loss: (0.1308) |  Loss2: (0.0000) | Acc: (95.00%) (19687/20608)
Epoch: 137 | Batch_idx: 170 |  Loss: (0.1328) |  Loss2: (0.0000) | Acc: (95.00%) (20887/21888)
Epoch: 137 | Batch_idx: 180 |  Loss: (0.1324) |  Loss2: (0.0000) | Acc: (95.00%) (22118/23168)
Epoch: 137 | Batch_idx: 190 |  Loss: (0.1333) |  Loss2: (0.0000) | Acc: (95.00%) (23335/24448)
Epoch: 137 | Batch_idx: 200 |  Loss: (0.1332) |  Loss2: (0.0000) | Acc: (95.00%) (24559/25728)
Epoch: 137 | Batch_idx: 210 |  Loss: (0.1332) |  Loss2: (0.0000) | Acc: (95.00%) (25784/27008)
Epoch: 137 | Batch_idx: 220 |  Loss: (0.1342) |  Loss2: (0.0000) | Acc: (95.00%) (26994/28288)
Epoch: 137 | Batch_idx: 230 |  Loss: (0.1351) |  Loss2: (0.0000) | Acc: (95.00%) (28211/29568)
Epoch: 137 | Batch_idx: 240 |  Loss: (0.1350) |  Loss2: (0.0000) | Acc: (95.00%) (29427/30848)
Epoch: 137 | Batch_idx: 250 |  Loss: (0.1350) |  Loss2: (0.0000) | Acc: (95.00%) (30652/32128)
Epoch: 137 | Batch_idx: 260 |  Loss: (0.1350) |  Loss2: (0.0000) | Acc: (95.00%) (31875/33408)
Epoch: 137 | Batch_idx: 270 |  Loss: (0.1345) |  Loss2: (0.0000) | Acc: (95.00%) (33102/34688)
Epoch: 137 | Batch_idx: 280 |  Loss: (0.1343) |  Loss2: (0.0000) | Acc: (95.00%) (34324/35968)
Epoch: 137 | Batch_idx: 290 |  Loss: (0.1339) |  Loss2: (0.0000) | Acc: (95.00%) (35556/37248)
Epoch: 137 | Batch_idx: 300 |  Loss: (0.1336) |  Loss2: (0.0000) | Acc: (95.00%) (36778/38528)
Epoch: 137 | Batch_idx: 310 |  Loss: (0.1342) |  Loss2: (0.0000) | Acc: (95.00%) (37989/39808)
Epoch: 137 | Batch_idx: 320 |  Loss: (0.1340) |  Loss2: (0.0000) | Acc: (95.00%) (39208/41088)
Epoch: 137 | Batch_idx: 330 |  Loss: (0.1342) |  Loss2: (0.0000) | Acc: (95.00%) (40427/42368)
Epoch: 137 | Batch_idx: 340 |  Loss: (0.1333) |  Loss2: (0.0000) | Acc: (95.00%) (41666/43648)
Epoch: 137 | Batch_idx: 350 |  Loss: (0.1328) |  Loss2: (0.0000) | Acc: (95.00%) (42897/44928)
Epoch: 137 | Batch_idx: 360 |  Loss: (0.1326) |  Loss2: (0.0000) | Acc: (95.00%) (44124/46208)
Epoch: 137 | Batch_idx: 370 |  Loss: (0.1324) |  Loss2: (0.0000) | Acc: (95.00%) (45349/47488)
Epoch: 137 | Batch_idx: 380 |  Loss: (0.1325) |  Loss2: (0.0000) | Acc: (95.00%) (46559/48768)
Epoch: 137 | Batch_idx: 390 |  Loss: (0.1329) |  Loss2: (0.0000) | Acc: (95.00%) (47731/50000)
# TEST : Loss: (0.3533) | Acc: (88.00%) (8891/10000)
percent tensor([0.5631, 0.5486, 0.5761, 0.5705, 0.5770, 0.5667, 0.5621, 0.5689, 0.5683,
        0.5585, 0.5592, 0.5681, 0.5571, 0.5516, 0.5564, 0.5591],
       device='cuda:0') torch.Size([16])
percent tensor([0.5288, 0.5377, 0.5209, 0.5300, 0.5216, 0.5505, 0.5296, 0.5220, 0.5169,
        0.5232, 0.5240, 0.5159, 0.5207, 0.5385, 0.5392, 0.5350],
       device='cuda:0') torch.Size([16])
percent tensor([0.6097, 0.6675, 0.5782, 0.5062, 0.5575, 0.5218, 0.6259, 0.5622, 0.5862,
        0.6422, 0.6325, 0.6299, 0.6971, 0.5202, 0.6143, 0.5802],
       device='cuda:0') torch.Size([16])
percent tensor([0.6966, 0.6982, 0.7032, 0.7202, 0.7160, 0.7127, 0.7151, 0.7028, 0.7109,
        0.7071, 0.7376, 0.7222, 0.6969, 0.7204, 0.7187, 0.7122],
       device='cuda:0') torch.Size([16])
percent tensor([0.6271, 0.6544, 0.6855, 0.6448, 0.6998, 0.8075, 0.6623, 0.5967, 0.7177,
        0.6402, 0.7186, 0.6093, 0.6998, 0.7054, 0.6298, 0.7141],
       device='cuda:0') torch.Size([16])
percent tensor([0.5391, 0.6767, 0.5648, 0.5002, 0.5171, 0.5426, 0.5581, 0.3905, 0.6629,
        0.6391, 0.7062, 0.6230, 0.6736, 0.7312, 0.4403, 0.5062],
       device='cuda:0') torch.Size([16])
percent tensor([0.5570, 0.5633, 0.8094, 0.7560, 0.8511, 0.6741, 0.6763, 0.7135, 0.6961,
        0.6393, 0.6596, 0.7667, 0.6502, 0.6140, 0.6455, 0.5540],
       device='cuda:0') torch.Size([16])
percent tensor([0.9996, 0.9989, 0.9993, 0.9994, 0.9992, 0.9990, 0.9990, 0.9993, 0.9990,
        0.9993, 0.9995, 0.9993, 0.9991, 0.9990, 0.9991, 0.9991],
       device='cuda:0') torch.Size([16])
Epoch: 138 | Batch_idx: 0 |  Loss: (0.1298) |  Loss2: (0.0000) | Acc: (96.00%) (123/128)
Epoch: 138 | Batch_idx: 10 |  Loss: (0.1331) |  Loss2: (0.0000) | Acc: (95.00%) (1344/1408)
Epoch: 138 | Batch_idx: 20 |  Loss: (0.1300) |  Loss2: (0.0000) | Acc: (95.00%) (2570/2688)
Epoch: 138 | Batch_idx: 30 |  Loss: (0.1257) |  Loss2: (0.0000) | Acc: (95.00%) (3798/3968)
Epoch: 138 | Batch_idx: 40 |  Loss: (0.1277) |  Loss2: (0.0000) | Acc: (95.00%) (5018/5248)
Epoch: 138 | Batch_idx: 50 |  Loss: (0.1236) |  Loss2: (0.0000) | Acc: (95.00%) (6257/6528)
Epoch: 138 | Batch_idx: 60 |  Loss: (0.1242) |  Loss2: (0.0000) | Acc: (95.00%) (7479/7808)
Epoch: 138 | Batch_idx: 70 |  Loss: (0.1239) |  Loss2: (0.0000) | Acc: (95.00%) (8704/9088)
Epoch: 138 | Batch_idx: 80 |  Loss: (0.1270) |  Loss2: (0.0000) | Acc: (95.00%) (9919/10368)
Epoch: 138 | Batch_idx: 90 |  Loss: (0.1261) |  Loss2: (0.0000) | Acc: (95.00%) (11149/11648)
Epoch: 138 | Batch_idx: 100 |  Loss: (0.1259) |  Loss2: (0.0000) | Acc: (95.00%) (12375/12928)
Epoch: 138 | Batch_idx: 110 |  Loss: (0.1266) |  Loss2: (0.0000) | Acc: (95.00%) (13597/14208)
Epoch: 138 | Batch_idx: 120 |  Loss: (0.1276) |  Loss2: (0.0000) | Acc: (95.00%) (14815/15488)
Epoch: 138 | Batch_idx: 130 |  Loss: (0.1282) |  Loss2: (0.0000) | Acc: (95.00%) (16037/16768)
Epoch: 138 | Batch_idx: 140 |  Loss: (0.1294) |  Loss2: (0.0000) | Acc: (95.00%) (17255/18048)
Epoch: 138 | Batch_idx: 150 |  Loss: (0.1282) |  Loss2: (0.0000) | Acc: (95.00%) (18492/19328)
Epoch: 138 | Batch_idx: 160 |  Loss: (0.1290) |  Loss2: (0.0000) | Acc: (95.00%) (19717/20608)
Epoch: 138 | Batch_idx: 170 |  Loss: (0.1290) |  Loss2: (0.0000) | Acc: (95.00%) (20943/21888)
Epoch: 138 | Batch_idx: 180 |  Loss: (0.1297) |  Loss2: (0.0000) | Acc: (95.00%) (22160/23168)
Epoch: 138 | Batch_idx: 190 |  Loss: (0.1306) |  Loss2: (0.0000) | Acc: (95.00%) (23372/24448)
Epoch: 138 | Batch_idx: 200 |  Loss: (0.1304) |  Loss2: (0.0000) | Acc: (95.00%) (24593/25728)
Epoch: 138 | Batch_idx: 210 |  Loss: (0.1309) |  Loss2: (0.0000) | Acc: (95.00%) (25811/27008)
Epoch: 138 | Batch_idx: 220 |  Loss: (0.1311) |  Loss2: (0.0000) | Acc: (95.00%) (27035/28288)
Epoch: 138 | Batch_idx: 230 |  Loss: (0.1316) |  Loss2: (0.0000) | Acc: (95.00%) (28253/29568)
Epoch: 138 | Batch_idx: 240 |  Loss: (0.1318) |  Loss2: (0.0000) | Acc: (95.00%) (29482/30848)
Epoch: 138 | Batch_idx: 250 |  Loss: (0.1319) |  Loss2: (0.0000) | Acc: (95.00%) (30701/32128)
Epoch: 138 | Batch_idx: 260 |  Loss: (0.1323) |  Loss2: (0.0000) | Acc: (95.00%) (31916/33408)
Epoch: 138 | Batch_idx: 270 |  Loss: (0.1322) |  Loss2: (0.0000) | Acc: (95.00%) (33137/34688)
Epoch: 138 | Batch_idx: 280 |  Loss: (0.1321) |  Loss2: (0.0000) | Acc: (95.00%) (34367/35968)
Epoch: 138 | Batch_idx: 290 |  Loss: (0.1318) |  Loss2: (0.0000) | Acc: (95.00%) (35598/37248)
Epoch: 138 | Batch_idx: 300 |  Loss: (0.1325) |  Loss2: (0.0000) | Acc: (95.00%) (36811/38528)
Epoch: 138 | Batch_idx: 310 |  Loss: (0.1331) |  Loss2: (0.0000) | Acc: (95.00%) (38019/39808)
Epoch: 138 | Batch_idx: 320 |  Loss: (0.1330) |  Loss2: (0.0000) | Acc: (95.00%) (39234/41088)
Epoch: 138 | Batch_idx: 330 |  Loss: (0.1331) |  Loss2: (0.0000) | Acc: (95.00%) (40457/42368)
Epoch: 138 | Batch_idx: 340 |  Loss: (0.1327) |  Loss2: (0.0000) | Acc: (95.00%) (41687/43648)
Epoch: 138 | Batch_idx: 350 |  Loss: (0.1322) |  Loss2: (0.0000) | Acc: (95.00%) (42923/44928)
Epoch: 138 | Batch_idx: 360 |  Loss: (0.1325) |  Loss2: (0.0000) | Acc: (95.00%) (44137/46208)
Epoch: 138 | Batch_idx: 370 |  Loss: (0.1325) |  Loss2: (0.0000) | Acc: (95.00%) (45355/47488)
Epoch: 138 | Batch_idx: 380 |  Loss: (0.1321) |  Loss2: (0.0000) | Acc: (95.00%) (46579/48768)
Epoch: 138 | Batch_idx: 390 |  Loss: (0.1318) |  Loss2: (0.0000) | Acc: (95.00%) (47764/50000)
# TEST : Loss: (0.3501) | Acc: (89.00%) (8910/10000)
percent tensor([0.5609, 0.5465, 0.5735, 0.5680, 0.5743, 0.5642, 0.5597, 0.5663, 0.5660,
        0.5562, 0.5571, 0.5655, 0.5549, 0.5496, 0.5540, 0.5569],
       device='cuda:0') torch.Size([16])
percent tensor([0.5290, 0.5379, 0.5211, 0.5302, 0.5216, 0.5510, 0.5298, 0.5218, 0.5170,
        0.5234, 0.5244, 0.5158, 0.5207, 0.5389, 0.5395, 0.5353],
       device='cuda:0') torch.Size([16])
percent tensor([0.6062, 0.6625, 0.5758, 0.5042, 0.5546, 0.5179, 0.6228, 0.5602, 0.5831,
        0.6379, 0.6277, 0.6266, 0.6928, 0.5173, 0.6104, 0.5759],
       device='cuda:0') torch.Size([16])
percent tensor([0.6920, 0.6931, 0.7004, 0.7172, 0.7125, 0.7097, 0.7104, 0.6981, 0.7074,
        0.7025, 0.7334, 0.7180, 0.6927, 0.7159, 0.7140, 0.7081],
       device='cuda:0') torch.Size([16])
percent tensor([0.6343, 0.6650, 0.6898, 0.6516, 0.7049, 0.8140, 0.6678, 0.5993, 0.7229,
        0.6483, 0.7277, 0.6154, 0.7079, 0.7132, 0.6383, 0.7222],
       device='cuda:0') torch.Size([16])
percent tensor([0.5546, 0.6920, 0.5773, 0.5127, 0.5287, 0.5594, 0.5744, 0.4071, 0.6761,
        0.6531, 0.7203, 0.6360, 0.6884, 0.7449, 0.4535, 0.5230],
       device='cuda:0') torch.Size([16])
percent tensor([0.5510, 0.5656, 0.8131, 0.7557, 0.8523, 0.6737, 0.6722, 0.7184, 0.6940,
        0.6361, 0.6614, 0.7676, 0.6511, 0.6077, 0.6455, 0.5392],
       device='cuda:0') torch.Size([16])
percent tensor([0.9997, 0.9989, 0.9994, 0.9995, 0.9992, 0.9990, 0.9991, 0.9993, 0.9991,
        0.9994, 0.9995, 0.9993, 0.9992, 0.9990, 0.9991, 0.9992],
       device='cuda:0') torch.Size([16])
Epoch: 139 | Batch_idx: 0 |  Loss: (0.1215) |  Loss2: (0.0000) | Acc: (95.00%) (122/128)
Epoch: 139 | Batch_idx: 10 |  Loss: (0.1401) |  Loss2: (0.0000) | Acc: (94.00%) (1337/1408)
Epoch: 139 | Batch_idx: 20 |  Loss: (0.1344) |  Loss2: (0.0000) | Acc: (95.00%) (2564/2688)
Epoch: 139 | Batch_idx: 30 |  Loss: (0.1300) |  Loss2: (0.0000) | Acc: (95.00%) (3794/3968)
Epoch: 139 | Batch_idx: 40 |  Loss: (0.1310) |  Loss2: (0.0000) | Acc: (95.00%) (5021/5248)
Epoch: 139 | Batch_idx: 50 |  Loss: (0.1308) |  Loss2: (0.0000) | Acc: (95.00%) (6240/6528)
Epoch: 139 | Batch_idx: 60 |  Loss: (0.1320) |  Loss2: (0.0000) | Acc: (95.00%) (7460/7808)
Epoch: 139 | Batch_idx: 70 |  Loss: (0.1299) |  Loss2: (0.0000) | Acc: (95.00%) (8694/9088)
Epoch: 139 | Batch_idx: 80 |  Loss: (0.1303) |  Loss2: (0.0000) | Acc: (95.00%) (9914/10368)
Epoch: 139 | Batch_idx: 90 |  Loss: (0.1304) |  Loss2: (0.0000) | Acc: (95.00%) (11136/11648)
Epoch: 139 | Batch_idx: 100 |  Loss: (0.1301) |  Loss2: (0.0000) | Acc: (95.00%) (12362/12928)
Epoch: 139 | Batch_idx: 110 |  Loss: (0.1284) |  Loss2: (0.0000) | Acc: (95.00%) (13594/14208)
Epoch: 139 | Batch_idx: 120 |  Loss: (0.1294) |  Loss2: (0.0000) | Acc: (95.00%) (14811/15488)
Epoch: 139 | Batch_idx: 130 |  Loss: (0.1295) |  Loss2: (0.0000) | Acc: (95.00%) (16030/16768)
Epoch: 139 | Batch_idx: 140 |  Loss: (0.1283) |  Loss2: (0.0000) | Acc: (95.00%) (17258/18048)
Epoch: 139 | Batch_idx: 150 |  Loss: (0.1283) |  Loss2: (0.0000) | Acc: (95.00%) (18478/19328)
Epoch: 139 | Batch_idx: 160 |  Loss: (0.1291) |  Loss2: (0.0000) | Acc: (95.00%) (19702/20608)
Epoch: 139 | Batch_idx: 170 |  Loss: (0.1290) |  Loss2: (0.0000) | Acc: (95.00%) (20917/21888)
Epoch: 139 | Batch_idx: 180 |  Loss: (0.1289) |  Loss2: (0.0000) | Acc: (95.00%) (22141/23168)
Epoch: 139 | Batch_idx: 190 |  Loss: (0.1286) |  Loss2: (0.0000) | Acc: (95.00%) (23365/24448)
Epoch: 139 | Batch_idx: 200 |  Loss: (0.1277) |  Loss2: (0.0000) | Acc: (95.00%) (24596/25728)
Epoch: 139 | Batch_idx: 210 |  Loss: (0.1282) |  Loss2: (0.0000) | Acc: (95.00%) (25820/27008)
Epoch: 139 | Batch_idx: 220 |  Loss: (0.1284) |  Loss2: (0.0000) | Acc: (95.00%) (27045/28288)
Epoch: 139 | Batch_idx: 230 |  Loss: (0.1285) |  Loss2: (0.0000) | Acc: (95.00%) (28273/29568)
Epoch: 139 | Batch_idx: 240 |  Loss: (0.1281) |  Loss2: (0.0000) | Acc: (95.00%) (29492/30848)
Epoch: 139 | Batch_idx: 250 |  Loss: (0.1284) |  Loss2: (0.0000) | Acc: (95.00%) (30714/32128)
Epoch: 139 | Batch_idx: 260 |  Loss: (0.1281) |  Loss2: (0.0000) | Acc: (95.00%) (31935/33408)
Epoch: 139 | Batch_idx: 270 |  Loss: (0.1282) |  Loss2: (0.0000) | Acc: (95.00%) (33163/34688)
Epoch: 139 | Batch_idx: 280 |  Loss: (0.1288) |  Loss2: (0.0000) | Acc: (95.00%) (34381/35968)
Epoch: 139 | Batch_idx: 290 |  Loss: (0.1288) |  Loss2: (0.0000) | Acc: (95.00%) (35599/37248)
Epoch: 139 | Batch_idx: 300 |  Loss: (0.1285) |  Loss2: (0.0000) | Acc: (95.00%) (36826/38528)
Epoch: 139 | Batch_idx: 310 |  Loss: (0.1288) |  Loss2: (0.0000) | Acc: (95.00%) (38046/39808)
Epoch: 139 | Batch_idx: 320 |  Loss: (0.1288) |  Loss2: (0.0000) | Acc: (95.00%) (39272/41088)
Epoch: 139 | Batch_idx: 330 |  Loss: (0.1282) |  Loss2: (0.0000) | Acc: (95.00%) (40507/42368)
Epoch: 139 | Batch_idx: 340 |  Loss: (0.1281) |  Loss2: (0.0000) | Acc: (95.00%) (41728/43648)
Epoch: 139 | Batch_idx: 350 |  Loss: (0.1277) |  Loss2: (0.0000) | Acc: (95.00%) (42960/44928)
Epoch: 139 | Batch_idx: 360 |  Loss: (0.1276) |  Loss2: (0.0000) | Acc: (95.00%) (44184/46208)
Epoch: 139 | Batch_idx: 370 |  Loss: (0.1276) |  Loss2: (0.0000) | Acc: (95.00%) (45412/47488)
Epoch: 139 | Batch_idx: 380 |  Loss: (0.1271) |  Loss2: (0.0000) | Acc: (95.00%) (46648/48768)
Epoch: 139 | Batch_idx: 390 |  Loss: (0.1276) |  Loss2: (0.0000) | Acc: (95.00%) (47816/50000)
# TEST : Loss: (0.3461) | Acc: (89.00%) (8916/10000)
percent tensor([0.5606, 0.5463, 0.5727, 0.5675, 0.5737, 0.5639, 0.5593, 0.5656, 0.5654,
        0.5557, 0.5567, 0.5648, 0.5545, 0.5492, 0.5538, 0.5566],
       device='cuda:0') torch.Size([16])
percent tensor([0.5287, 0.5373, 0.5205, 0.5296, 0.5210, 0.5508, 0.5293, 0.5209, 0.5166,
        0.5228, 0.5242, 0.5153, 0.5203, 0.5384, 0.5390, 0.5350],
       device='cuda:0') torch.Size([16])
percent tensor([0.6030, 0.6608, 0.5730, 0.5048, 0.5519, 0.5169, 0.6200, 0.5574, 0.5809,
        0.6364, 0.6265, 0.6241, 0.6889, 0.5195, 0.6081, 0.5746],
       device='cuda:0') torch.Size([16])
percent tensor([0.6986, 0.6991, 0.7063, 0.7226, 0.7183, 0.7164, 0.7162, 0.7036, 0.7132,
        0.7090, 0.7396, 0.7239, 0.6988, 0.7217, 0.7200, 0.7144],
       device='cuda:0') torch.Size([16])
percent tensor([0.6252, 0.6587, 0.6838, 0.6468, 0.7001, 0.8096, 0.6611, 0.5888, 0.7175,
        0.6408, 0.7187, 0.6067, 0.6997, 0.7079, 0.6298, 0.7154],
       device='cuda:0') torch.Size([16])
percent tensor([0.5576, 0.6985, 0.5818, 0.5189, 0.5317, 0.5610, 0.5784, 0.4107, 0.6786,
        0.6578, 0.7234, 0.6426, 0.6915, 0.7501, 0.4573, 0.5256],
       device='cuda:0') torch.Size([16])
percent tensor([0.5653, 0.5849, 0.8238, 0.7670, 0.8587, 0.6767, 0.6832, 0.7345, 0.7100,
        0.6571, 0.6778, 0.7805, 0.6696, 0.6175, 0.6590, 0.5449],
       device='cuda:0') torch.Size([16])
percent tensor([0.9997, 0.9990, 0.9994, 0.9995, 0.9992, 0.9990, 0.9991, 0.9993, 0.9991,
        0.9994, 0.9996, 0.9993, 0.9992, 0.9990, 0.9991, 0.9992],
       device='cuda:0') torch.Size([16])
True Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=128, out_features=16, bias=False)
False Linear(in_features=16, out_features=2, bias=False)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=128, out_features=16, bias=False)
False Linear(in_features=16, out_features=2, bias=False)
True Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=256, out_features=32, bias=False)
False Linear(in_features=32, out_features=2, bias=False)
True Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=256, out_features=32, bias=False)
False Linear(in_features=32, out_features=2, bias=False)
True Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=512, out_features=64, bias=False)
False Linear(in_features=64, out_features=2, bias=False)
True Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=512, out_features=64, bias=False)
False Linear(in_features=64, out_features=2, bias=False)
True Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1024, out_features=128, bias=False)
False Linear(in_features=128, out_features=2, bias=False)
True Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1024, out_features=128, bias=False)
False Linear(in_features=128, out_features=2, bias=False)
True Linear(in_features=512, out_features=10, bias=True)
Epoch: 140 | Batch_idx: 0 |  Loss: (0.0912) |  Loss2: (0.0000) | Acc: (98.00%) (126/128)
Epoch: 140 | Batch_idx: 10 |  Loss: (0.1022) |  Loss2: (0.0000) | Acc: (97.00%) (1366/1408)
Epoch: 140 | Batch_idx: 20 |  Loss: (0.1021) |  Loss2: (0.0000) | Acc: (96.00%) (2597/2688)
Epoch: 140 | Batch_idx: 30 |  Loss: (0.1117) |  Loss2: (0.0000) | Acc: (96.00%) (3822/3968)
Epoch: 140 | Batch_idx: 40 |  Loss: (0.1167) |  Loss2: (0.0000) | Acc: (96.00%) (5049/5248)
Epoch: 140 | Batch_idx: 50 |  Loss: (0.1179) |  Loss2: (0.0000) | Acc: (96.00%) (6269/6528)
Epoch: 140 | Batch_idx: 60 |  Loss: (0.1230) |  Loss2: (0.0000) | Acc: (95.00%) (7488/7808)
Epoch: 140 | Batch_idx: 70 |  Loss: (0.1239) |  Loss2: (0.0000) | Acc: (95.00%) (8712/9088)
Epoch: 140 | Batch_idx: 80 |  Loss: (0.1247) |  Loss2: (0.0000) | Acc: (95.00%) (9931/10368)
Epoch: 140 | Batch_idx: 90 |  Loss: (0.1249) |  Loss2: (0.0000) | Acc: (95.00%) (11154/11648)
Epoch: 140 | Batch_idx: 100 |  Loss: (0.1238) |  Loss2: (0.0000) | Acc: (95.00%) (12389/12928)
Epoch: 140 | Batch_idx: 110 |  Loss: (0.1246) |  Loss2: (0.0000) | Acc: (95.00%) (13614/14208)
Epoch: 140 | Batch_idx: 120 |  Loss: (0.1257) |  Loss2: (0.0000) | Acc: (95.00%) (14824/15488)
Epoch: 140 | Batch_idx: 130 |  Loss: (0.1265) |  Loss2: (0.0000) | Acc: (95.00%) (16043/16768)
Epoch: 140 | Batch_idx: 140 |  Loss: (0.1275) |  Loss2: (0.0000) | Acc: (95.00%) (17258/18048)
Epoch: 140 | Batch_idx: 150 |  Loss: (0.1286) |  Loss2: (0.0000) | Acc: (95.00%) (18472/19328)
Epoch: 140 | Batch_idx: 160 |  Loss: (0.1295) |  Loss2: (0.0000) | Acc: (95.00%) (19683/20608)
Epoch: 140 | Batch_idx: 170 |  Loss: (0.1294) |  Loss2: (0.0000) | Acc: (95.00%) (20910/21888)
Epoch: 140 | Batch_idx: 180 |  Loss: (0.1304) |  Loss2: (0.0000) | Acc: (95.00%) (22126/23168)
Epoch: 140 | Batch_idx: 190 |  Loss: (0.1306) |  Loss2: (0.0000) | Acc: (95.00%) (23346/24448)
Epoch: 140 | Batch_idx: 200 |  Loss: (0.1308) |  Loss2: (0.0000) | Acc: (95.00%) (24565/25728)
Epoch: 140 | Batch_idx: 210 |  Loss: (0.1311) |  Loss2: (0.0000) | Acc: (95.00%) (25789/27008)
Epoch: 140 | Batch_idx: 220 |  Loss: (0.1314) |  Loss2: (0.0000) | Acc: (95.00%) (27011/28288)
Epoch: 140 | Batch_idx: 230 |  Loss: (0.1312) |  Loss2: (0.0000) | Acc: (95.00%) (28235/29568)
Epoch: 140 | Batch_idx: 240 |  Loss: (0.1301) |  Loss2: (0.0000) | Acc: (95.00%) (29477/30848)
Epoch: 140 | Batch_idx: 250 |  Loss: (0.1308) |  Loss2: (0.0000) | Acc: (95.00%) (30690/32128)
Epoch: 140 | Batch_idx: 260 |  Loss: (0.1308) |  Loss2: (0.0000) | Acc: (95.00%) (31918/33408)
Epoch: 140 | Batch_idx: 270 |  Loss: (0.1311) |  Loss2: (0.0000) | Acc: (95.00%) (33137/34688)
Epoch: 140 | Batch_idx: 280 |  Loss: (0.1315) |  Loss2: (0.0000) | Acc: (95.00%) (34349/35968)
Epoch: 140 | Batch_idx: 290 |  Loss: (0.1324) |  Loss2: (0.0000) | Acc: (95.00%) (35561/37248)
Epoch: 140 | Batch_idx: 300 |  Loss: (0.1331) |  Loss2: (0.0000) | Acc: (95.00%) (36768/38528)
Epoch: 140 | Batch_idx: 310 |  Loss: (0.1339) |  Loss2: (0.0000) | Acc: (95.00%) (37977/39808)
Epoch: 140 | Batch_idx: 320 |  Loss: (0.1340) |  Loss2: (0.0000) | Acc: (95.00%) (39189/41088)
Epoch: 140 | Batch_idx: 330 |  Loss: (0.1342) |  Loss2: (0.0000) | Acc: (95.00%) (40406/42368)
Epoch: 140 | Batch_idx: 340 |  Loss: (0.1344) |  Loss2: (0.0000) | Acc: (95.00%) (41617/43648)
Epoch: 140 | Batch_idx: 350 |  Loss: (0.1356) |  Loss2: (0.0000) | Acc: (95.00%) (42827/44928)
Epoch: 140 | Batch_idx: 360 |  Loss: (0.1358) |  Loss2: (0.0000) | Acc: (95.00%) (44045/46208)
Epoch: 140 | Batch_idx: 370 |  Loss: (0.1360) |  Loss2: (0.0000) | Acc: (95.00%) (45263/47488)
Epoch: 140 | Batch_idx: 380 |  Loss: (0.1361) |  Loss2: (0.0000) | Acc: (95.00%) (46483/48768)
Epoch: 140 | Batch_idx: 390 |  Loss: (0.1359) |  Loss2: (0.0000) | Acc: (95.00%) (47664/50000)
=> saving checkpoint 'drive/app/torch/save_Routing_Gate_2/checkpoint_140.pth.tar'
# TEST : Loss: (0.3880) | Acc: (87.00%) (8789/10000)
percent tensor([0.5610, 0.5453, 0.5748, 0.5679, 0.5749, 0.5650, 0.5586, 0.5654, 0.5648,
        0.5551, 0.5563, 0.5660, 0.5541, 0.5453, 0.5541, 0.5562],
       device='cuda:0') torch.Size([16])
percent tensor([0.5282, 0.5364, 0.5209, 0.5295, 0.5228, 0.5508, 0.5292, 0.5210, 0.5178,
        0.5215, 0.5240, 0.5149, 0.5194, 0.5410, 0.5376, 0.5345],
       device='cuda:0') torch.Size([16])
percent tensor([0.5989, 0.6644, 0.5781, 0.5116, 0.5536, 0.5060, 0.6252, 0.5661, 0.5802,
        0.6432, 0.6207, 0.6335, 0.6909, 0.5277, 0.6074, 0.5775],
       device='cuda:0') torch.Size([16])
percent tensor([0.6978, 0.6960, 0.7019, 0.7192, 0.7139, 0.7120, 0.7106, 0.7042, 0.7132,
        0.7033, 0.7331, 0.7182, 0.6968, 0.7201, 0.7149, 0.7082],
       device='cuda:0') torch.Size([16])
percent tensor([0.6462, 0.6551, 0.7238, 0.6595, 0.6967, 0.8176, 0.6668, 0.5885, 0.7220,
        0.6443, 0.7166, 0.6177, 0.7078, 0.7175, 0.6248, 0.7235],
       device='cuda:0') torch.Size([16])
percent tensor([0.5416, 0.6830, 0.5688, 0.5063, 0.5154, 0.5517, 0.5504, 0.3979, 0.6871,
        0.6430, 0.7260, 0.6218, 0.6828, 0.7510, 0.4295, 0.5133],
       device='cuda:0') torch.Size([16])
percent tensor([0.5553, 0.6249, 0.8104, 0.7542, 0.8462, 0.6821, 0.6585, 0.7286, 0.7123,
        0.6616, 0.6816, 0.7799, 0.6558, 0.6726, 0.6576, 0.5355],
       device='cuda:0') torch.Size([16])
percent tensor([0.9997, 0.9989, 0.9995, 0.9994, 0.9992, 0.9992, 0.9992, 0.9992, 0.9992,
        0.9994, 0.9994, 0.9995, 0.9993, 0.9987, 0.9992, 0.9993],
       device='cuda:0') torch.Size([16])
Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 3, 3, 3]) tensor(182.3959, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(815.2308, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(824.4874, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([128, 64, 3, 3]) tensor(1514.2899, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([128, 64, 1, 1]) tensor(489.4890, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([128, 128, 3, 3]) tensor(2271.8806, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([256, 128, 3, 3]) tensor(4286.0664, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([256, 128, 1, 1]) tensor(1376.0632, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([256, 256, 3, 3]) tensor(6195.3120, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([512, 256, 3, 3]) tensor(11749.9922, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([512, 256, 1, 1]) tensor(3884.9148, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([512, 512, 3, 3]) tensor(16391.0449, device='cuda:0', grad_fn=<NormBackward0>)
Epoch: 141 | Batch_idx: 0 |  Loss: (0.1597) |  Loss2: (0.0000) | Acc: (92.00%) (119/128)
Epoch: 141 | Batch_idx: 10 |  Loss: (0.1383) |  Loss2: (0.0000) | Acc: (94.00%) (1335/1408)
Epoch: 141 | Batch_idx: 20 |  Loss: (0.1250) |  Loss2: (0.0000) | Acc: (95.00%) (2568/2688)
Epoch: 141 | Batch_idx: 30 |  Loss: (0.1183) |  Loss2: (0.0000) | Acc: (96.00%) (3813/3968)
Epoch: 141 | Batch_idx: 40 |  Loss: (0.1174) |  Loss2: (0.0000) | Acc: (96.00%) (5048/5248)
Epoch: 141 | Batch_idx: 50 |  Loss: (0.1221) |  Loss2: (0.0000) | Acc: (95.00%) (6262/6528)
Epoch: 141 | Batch_idx: 60 |  Loss: (0.1211) |  Loss2: (0.0000) | Acc: (95.00%) (7493/7808)
Epoch: 141 | Batch_idx: 70 |  Loss: (0.1237) |  Loss2: (0.0000) | Acc: (95.00%) (8712/9088)
Epoch: 141 | Batch_idx: 80 |  Loss: (0.1263) |  Loss2: (0.0000) | Acc: (95.00%) (9927/10368)
Epoch: 141 | Batch_idx: 90 |  Loss: (0.1295) |  Loss2: (0.0000) | Acc: (95.00%) (11142/11648)
Epoch: 141 | Batch_idx: 100 |  Loss: (0.1300) |  Loss2: (0.0000) | Acc: (95.00%) (12363/12928)
Epoch: 141 | Batch_idx: 110 |  Loss: (0.1308) |  Loss2: (0.0000) | Acc: (95.00%) (13577/14208)
Epoch: 141 | Batch_idx: 120 |  Loss: (0.1306) |  Loss2: (0.0000) | Acc: (95.00%) (14807/15488)
Epoch: 141 | Batch_idx: 130 |  Loss: (0.1305) |  Loss2: (0.0000) | Acc: (95.00%) (16027/16768)
Epoch: 141 | Batch_idx: 140 |  Loss: (0.1299) |  Loss2: (0.0000) | Acc: (95.00%) (17255/18048)
Epoch: 141 | Batch_idx: 150 |  Loss: (0.1295) |  Loss2: (0.0000) | Acc: (95.00%) (18478/19328)
Epoch: 141 | Batch_idx: 160 |  Loss: (0.1293) |  Loss2: (0.0000) | Acc: (95.00%) (19702/20608)
Epoch: 141 | Batch_idx: 170 |  Loss: (0.1297) |  Loss2: (0.0000) | Acc: (95.00%) (20922/21888)
Epoch: 141 | Batch_idx: 180 |  Loss: (0.1302) |  Loss2: (0.0000) | Acc: (95.00%) (22145/23168)
Epoch: 141 | Batch_idx: 190 |  Loss: (0.1300) |  Loss2: (0.0000) | Acc: (95.00%) (23374/24448)
Epoch: 141 | Batch_idx: 200 |  Loss: (0.1305) |  Loss2: (0.0000) | Acc: (95.00%) (24581/25728)
Epoch: 141 | Batch_idx: 210 |  Loss: (0.1309) |  Loss2: (0.0000) | Acc: (95.00%) (25798/27008)
Epoch: 141 | Batch_idx: 220 |  Loss: (0.1313) |  Loss2: (0.0000) | Acc: (95.00%) (27014/28288)
Epoch: 141 | Batch_idx: 230 |  Loss: (0.1321) |  Loss2: (0.0000) | Acc: (95.00%) (28229/29568)
Epoch: 141 | Batch_idx: 240 |  Loss: (0.1320) |  Loss2: (0.0000) | Acc: (95.00%) (29451/30848)
Epoch: 141 | Batch_idx: 250 |  Loss: (0.1319) |  Loss2: (0.0000) | Acc: (95.00%) (30671/32128)
Epoch: 141 | Batch_idx: 260 |  Loss: (0.1321) |  Loss2: (0.0000) | Acc: (95.00%) (31892/33408)
Epoch: 141 | Batch_idx: 270 |  Loss: (0.1326) |  Loss2: (0.0000) | Acc: (95.00%) (33106/34688)
Epoch: 141 | Batch_idx: 280 |  Loss: (0.1319) |  Loss2: (0.0000) | Acc: (95.00%) (34336/35968)
Epoch: 141 | Batch_idx: 290 |  Loss: (0.1327) |  Loss2: (0.0000) | Acc: (95.00%) (35550/37248)
Epoch: 141 | Batch_idx: 300 |  Loss: (0.1326) |  Loss2: (0.0000) | Acc: (95.00%) (36769/38528)
Epoch: 141 | Batch_idx: 310 |  Loss: (0.1332) |  Loss2: (0.0000) | Acc: (95.00%) (37978/39808)
Epoch: 141 | Batch_idx: 320 |  Loss: (0.1327) |  Loss2: (0.0000) | Acc: (95.00%) (39208/41088)
Epoch: 141 | Batch_idx: 330 |  Loss: (0.1331) |  Loss2: (0.0000) | Acc: (95.00%) (40426/42368)
Epoch: 141 | Batch_idx: 340 |  Loss: (0.1335) |  Loss2: (0.0000) | Acc: (95.00%) (41637/43648)
Epoch: 141 | Batch_idx: 350 |  Loss: (0.1337) |  Loss2: (0.0000) | Acc: (95.00%) (42853/44928)
Epoch: 141 | Batch_idx: 360 |  Loss: (0.1338) |  Loss2: (0.0000) | Acc: (95.00%) (44071/46208)
Epoch: 141 | Batch_idx: 370 |  Loss: (0.1345) |  Loss2: (0.0000) | Acc: (95.00%) (45282/47488)
Epoch: 141 | Batch_idx: 380 |  Loss: (0.1349) |  Loss2: (0.0000) | Acc: (95.00%) (46492/48768)
Epoch: 141 | Batch_idx: 390 |  Loss: (0.1349) |  Loss2: (0.0000) | Acc: (95.00%) (47666/50000)
# TEST : Loss: (0.3872) | Acc: (88.00%) (8841/10000)
percent tensor([0.5618, 0.5450, 0.5758, 0.5681, 0.5764, 0.5659, 0.5594, 0.5656, 0.5661,
        0.5556, 0.5570, 0.5671, 0.5554, 0.5456, 0.5542, 0.5566],
       device='cuda:0') torch.Size([16])
percent tensor([0.5272, 0.5365, 0.5214, 0.5310, 0.5223, 0.5508, 0.5286, 0.5216, 0.5163,
        0.5217, 0.5223, 0.5147, 0.5182, 0.5403, 0.5378, 0.5341],
       device='cuda:0') torch.Size([16])
percent tensor([0.6018, 0.6696, 0.5731, 0.5131, 0.5523, 0.5117, 0.6321, 0.5674, 0.5777,
        0.6445, 0.6235, 0.6325, 0.6922, 0.5332, 0.6170, 0.5815],
       device='cuda:0') torch.Size([16])
percent tensor([0.7032, 0.6940, 0.7095, 0.7240, 0.7197, 0.7150, 0.7167, 0.7066, 0.7185,
        0.7125, 0.7434, 0.7251, 0.7027, 0.7247, 0.7150, 0.7116],
       device='cuda:0') torch.Size([16])
percent tensor([0.6542, 0.6677, 0.6979, 0.6414, 0.6881, 0.8028, 0.6669, 0.5857, 0.7117,
        0.6606, 0.7160, 0.6127, 0.7239, 0.7282, 0.6292, 0.7263],
       device='cuda:0') torch.Size([16])
percent tensor([0.5554, 0.6845, 0.5667, 0.4918, 0.5297, 0.5479, 0.5606, 0.4228, 0.6754,
        0.6520, 0.7477, 0.6273, 0.6937, 0.7451, 0.4637, 0.5299],
       device='cuda:0') torch.Size([16])
percent tensor([0.5340, 0.5849, 0.8140, 0.7749, 0.8548, 0.6807, 0.6646, 0.7409, 0.7084,
        0.6412, 0.6680, 0.7652, 0.6573, 0.6496, 0.6383, 0.5378],
       device='cuda:0') torch.Size([16])
percent tensor([0.9997, 0.9991, 0.9994, 0.9993, 0.9992, 0.9993, 0.9994, 0.9993, 0.9992,
        0.9994, 0.9995, 0.9996, 0.9993, 0.9989, 0.9994, 0.9994],
       device='cuda:0') torch.Size([16])
Epoch: 142 | Batch_idx: 0 |  Loss: (0.1395) |  Loss2: (0.0000) | Acc: (92.00%) (119/128)
Epoch: 142 | Batch_idx: 10 |  Loss: (0.1143) |  Loss2: (0.0000) | Acc: (96.00%) (1355/1408)
Epoch: 142 | Batch_idx: 20 |  Loss: (0.1259) |  Loss2: (0.0000) | Acc: (95.00%) (2577/2688)
Epoch: 142 | Batch_idx: 30 |  Loss: (0.1247) |  Loss2: (0.0000) | Acc: (95.00%) (3807/3968)
Epoch: 142 | Batch_idx: 40 |  Loss: (0.1211) |  Loss2: (0.0000) | Acc: (96.00%) (5050/5248)
Epoch: 142 | Batch_idx: 50 |  Loss: (0.1195) |  Loss2: (0.0000) | Acc: (96.00%) (6282/6528)
Epoch: 142 | Batch_idx: 60 |  Loss: (0.1201) |  Loss2: (0.0000) | Acc: (96.00%) (7510/7808)
Epoch: 142 | Batch_idx: 70 |  Loss: (0.1203) |  Loss2: (0.0000) | Acc: (96.00%) (8743/9088)
Epoch: 142 | Batch_idx: 80 |  Loss: (0.1211) |  Loss2: (0.0000) | Acc: (96.00%) (9970/10368)
Epoch: 142 | Batch_idx: 90 |  Loss: (0.1242) |  Loss2: (0.0000) | Acc: (95.00%) (11181/11648)
Epoch: 142 | Batch_idx: 100 |  Loss: (0.1261) |  Loss2: (0.0000) | Acc: (95.00%) (12399/12928)
Epoch: 142 | Batch_idx: 110 |  Loss: (0.1241) |  Loss2: (0.0000) | Acc: (96.00%) (13640/14208)
Epoch: 142 | Batch_idx: 120 |  Loss: (0.1226) |  Loss2: (0.0000) | Acc: (96.00%) (14872/15488)
Epoch: 142 | Batch_idx: 130 |  Loss: (0.1230) |  Loss2: (0.0000) | Acc: (96.00%) (16101/16768)
Epoch: 142 | Batch_idx: 140 |  Loss: (0.1232) |  Loss2: (0.0000) | Acc: (95.00%) (17326/18048)
Epoch: 142 | Batch_idx: 150 |  Loss: (0.1231) |  Loss2: (0.0000) | Acc: (96.00%) (18556/19328)
Epoch: 142 | Batch_idx: 160 |  Loss: (0.1238) |  Loss2: (0.0000) | Acc: (95.00%) (19772/20608)
Epoch: 142 | Batch_idx: 170 |  Loss: (0.1251) |  Loss2: (0.0000) | Acc: (95.00%) (20988/21888)
Epoch: 142 | Batch_idx: 180 |  Loss: (0.1254) |  Loss2: (0.0000) | Acc: (95.00%) (22218/23168)
Epoch: 142 | Batch_idx: 190 |  Loss: (0.1260) |  Loss2: (0.0000) | Acc: (95.00%) (23437/24448)
Epoch: 142 | Batch_idx: 200 |  Loss: (0.1265) |  Loss2: (0.0000) | Acc: (95.00%) (24651/25728)
Epoch: 142 | Batch_idx: 210 |  Loss: (0.1274) |  Loss2: (0.0000) | Acc: (95.00%) (25871/27008)
Epoch: 142 | Batch_idx: 220 |  Loss: (0.1275) |  Loss2: (0.0000) | Acc: (95.00%) (27098/28288)
Epoch: 142 | Batch_idx: 230 |  Loss: (0.1284) |  Loss2: (0.0000) | Acc: (95.00%) (28310/29568)
Epoch: 142 | Batch_idx: 240 |  Loss: (0.1289) |  Loss2: (0.0000) | Acc: (95.00%) (29522/30848)
Epoch: 142 | Batch_idx: 250 |  Loss: (0.1290) |  Loss2: (0.0000) | Acc: (95.00%) (30744/32128)
Epoch: 142 | Batch_idx: 260 |  Loss: (0.1299) |  Loss2: (0.0000) | Acc: (95.00%) (31956/33408)
Epoch: 142 | Batch_idx: 270 |  Loss: (0.1302) |  Loss2: (0.0000) | Acc: (95.00%) (33177/34688)
Epoch: 142 | Batch_idx: 280 |  Loss: (0.1305) |  Loss2: (0.0000) | Acc: (95.00%) (34404/35968)
Epoch: 142 | Batch_idx: 290 |  Loss: (0.1304) |  Loss2: (0.0000) | Acc: (95.00%) (35624/37248)
Epoch: 142 | Batch_idx: 300 |  Loss: (0.1303) |  Loss2: (0.0000) | Acc: (95.00%) (36848/38528)
Epoch: 142 | Batch_idx: 310 |  Loss: (0.1309) |  Loss2: (0.0000) | Acc: (95.00%) (38063/39808)
Epoch: 142 | Batch_idx: 320 |  Loss: (0.1311) |  Loss2: (0.0000) | Acc: (95.00%) (39282/41088)
Epoch: 142 | Batch_idx: 330 |  Loss: (0.1317) |  Loss2: (0.0000) | Acc: (95.00%) (40499/42368)
Epoch: 142 | Batch_idx: 340 |  Loss: (0.1316) |  Loss2: (0.0000) | Acc: (95.00%) (41718/43648)
Epoch: 142 | Batch_idx: 350 |  Loss: (0.1316) |  Loss2: (0.0000) | Acc: (95.00%) (42940/44928)
Epoch: 142 | Batch_idx: 360 |  Loss: (0.1318) |  Loss2: (0.0000) | Acc: (95.00%) (44154/46208)
Epoch: 142 | Batch_idx: 370 |  Loss: (0.1323) |  Loss2: (0.0000) | Acc: (95.00%) (45363/47488)
Epoch: 142 | Batch_idx: 380 |  Loss: (0.1327) |  Loss2: (0.0000) | Acc: (95.00%) (46575/48768)
Epoch: 142 | Batch_idx: 390 |  Loss: (0.1329) |  Loss2: (0.0000) | Acc: (95.00%) (47746/50000)
# TEST : Loss: (0.4142) | Acc: (87.00%) (8726/10000)
percent tensor([0.5625, 0.5453, 0.5761, 0.5684, 0.5766, 0.5673, 0.5595, 0.5659, 0.5667,
        0.5555, 0.5572, 0.5673, 0.5558, 0.5463, 0.5546, 0.5569],
       device='cuda:0') torch.Size([16])
percent tensor([0.5292, 0.5380, 0.5206, 0.5312, 0.5220, 0.5538, 0.5293, 0.5196, 0.5176,
        0.5226, 0.5248, 0.5139, 0.5198, 0.5417, 0.5395, 0.5361],
       device='cuda:0') torch.Size([16])
percent tensor([0.5957, 0.6640, 0.5626, 0.5069, 0.5478, 0.5089, 0.6261, 0.5588, 0.5816,
        0.6358, 0.6240, 0.6240, 0.6916, 0.5312, 0.6086, 0.5764],
       device='cuda:0') torch.Size([16])
percent tensor([0.7030, 0.7015, 0.7062, 0.7201, 0.7158, 0.7117, 0.7201, 0.7060, 0.7193,
        0.7092, 0.7426, 0.7255, 0.7037, 0.7303, 0.7189, 0.7119],
       device='cuda:0') torch.Size([16])
percent tensor([0.6527, 0.6610, 0.7144, 0.6586, 0.6883, 0.8202, 0.6572, 0.5939, 0.7044,
        0.6524, 0.7117, 0.6107, 0.7133, 0.7062, 0.6295, 0.7209],
       device='cuda:0') torch.Size([16])
percent tensor([0.5666, 0.6811, 0.5717, 0.4866, 0.5119, 0.5666, 0.5359, 0.3913, 0.6878,
        0.6473, 0.7255, 0.6242, 0.6892, 0.7453, 0.4546, 0.5217],
       device='cuda:0') torch.Size([16])
percent tensor([0.5671, 0.6303, 0.8390, 0.7774, 0.8628, 0.7141, 0.6678, 0.7466, 0.7087,
        0.6479, 0.6622, 0.7713, 0.6734, 0.6690, 0.6550, 0.5555],
       device='cuda:0') torch.Size([16])
percent tensor([0.9996, 0.9990, 0.9993, 0.9992, 0.9994, 0.9994, 0.9990, 0.9994, 0.9990,
        0.9994, 0.9993, 0.9994, 0.9993, 0.9990, 0.9993, 0.9993],
       device='cuda:0') torch.Size([16])
Epoch: 143 | Batch_idx: 0 |  Loss: (0.1532) |  Loss2: (0.0000) | Acc: (96.00%) (123/128)
Epoch: 143 | Batch_idx: 10 |  Loss: (0.1330) |  Loss2: (0.0000) | Acc: (95.00%) (1341/1408)
Epoch: 143 | Batch_idx: 20 |  Loss: (0.1287) |  Loss2: (0.0000) | Acc: (95.00%) (2569/2688)
Epoch: 143 | Batch_idx: 30 |  Loss: (0.1229) |  Loss2: (0.0000) | Acc: (95.00%) (3801/3968)
Epoch: 143 | Batch_idx: 40 |  Loss: (0.1207) |  Loss2: (0.0000) | Acc: (96.00%) (5040/5248)
Epoch: 143 | Batch_idx: 50 |  Loss: (0.1223) |  Loss2: (0.0000) | Acc: (95.00%) (6257/6528)
Epoch: 143 | Batch_idx: 60 |  Loss: (0.1227) |  Loss2: (0.0000) | Acc: (95.00%) (7490/7808)
Epoch: 143 | Batch_idx: 70 |  Loss: (0.1209) |  Loss2: (0.0000) | Acc: (95.00%) (8717/9088)
Epoch: 143 | Batch_idx: 80 |  Loss: (0.1220) |  Loss2: (0.0000) | Acc: (95.00%) (9938/10368)
Epoch: 143 | Batch_idx: 90 |  Loss: (0.1213) |  Loss2: (0.0000) | Acc: (95.00%) (11173/11648)
Epoch: 143 | Batch_idx: 100 |  Loss: (0.1221) |  Loss2: (0.0000) | Acc: (95.00%) (12387/12928)
Epoch: 143 | Batch_idx: 110 |  Loss: (0.1243) |  Loss2: (0.0000) | Acc: (95.00%) (13608/14208)
Epoch: 143 | Batch_idx: 120 |  Loss: (0.1250) |  Loss2: (0.0000) | Acc: (95.00%) (14833/15488)
Epoch: 143 | Batch_idx: 130 |  Loss: (0.1232) |  Loss2: (0.0000) | Acc: (95.00%) (16078/16768)
Epoch: 143 | Batch_idx: 140 |  Loss: (0.1229) |  Loss2: (0.0000) | Acc: (95.00%) (17308/18048)
Epoch: 143 | Batch_idx: 150 |  Loss: (0.1233) |  Loss2: (0.0000) | Acc: (95.00%) (18534/19328)
Epoch: 143 | Batch_idx: 160 |  Loss: (0.1229) |  Loss2: (0.0000) | Acc: (95.00%) (19764/20608)
Epoch: 143 | Batch_idx: 170 |  Loss: (0.1224) |  Loss2: (0.0000) | Acc: (95.00%) (20996/21888)
Epoch: 143 | Batch_idx: 180 |  Loss: (0.1222) |  Loss2: (0.0000) | Acc: (95.00%) (22223/23168)
Epoch: 143 | Batch_idx: 190 |  Loss: (0.1224) |  Loss2: (0.0000) | Acc: (95.00%) (23445/24448)
Epoch: 143 | Batch_idx: 200 |  Loss: (0.1235) |  Loss2: (0.0000) | Acc: (95.00%) (24665/25728)
Epoch: 143 | Batch_idx: 210 |  Loss: (0.1245) |  Loss2: (0.0000) | Acc: (95.00%) (25882/27008)
Epoch: 143 | Batch_idx: 220 |  Loss: (0.1239) |  Loss2: (0.0000) | Acc: (95.00%) (27111/28288)
Epoch: 143 | Batch_idx: 230 |  Loss: (0.1241) |  Loss2: (0.0000) | Acc: (95.00%) (28336/29568)
Epoch: 143 | Batch_idx: 240 |  Loss: (0.1250) |  Loss2: (0.0000) | Acc: (95.00%) (29550/30848)
Epoch: 143 | Batch_idx: 250 |  Loss: (0.1247) |  Loss2: (0.0000) | Acc: (95.00%) (30779/32128)
Epoch: 143 | Batch_idx: 260 |  Loss: (0.1254) |  Loss2: (0.0000) | Acc: (95.00%) (31996/33408)
Epoch: 143 | Batch_idx: 270 |  Loss: (0.1248) |  Loss2: (0.0000) | Acc: (95.00%) (33231/34688)
Epoch: 143 | Batch_idx: 280 |  Loss: (0.1261) |  Loss2: (0.0000) | Acc: (95.00%) (34447/35968)
Epoch: 143 | Batch_idx: 290 |  Loss: (0.1265) |  Loss2: (0.0000) | Acc: (95.00%) (35676/37248)
Epoch: 143 | Batch_idx: 300 |  Loss: (0.1262) |  Loss2: (0.0000) | Acc: (95.00%) (36899/38528)
Epoch: 143 | Batch_idx: 310 |  Loss: (0.1269) |  Loss2: (0.0000) | Acc: (95.00%) (38116/39808)
Epoch: 143 | Batch_idx: 320 |  Loss: (0.1270) |  Loss2: (0.0000) | Acc: (95.00%) (39339/41088)
Epoch: 143 | Batch_idx: 330 |  Loss: (0.1270) |  Loss2: (0.0000) | Acc: (95.00%) (40562/42368)
Epoch: 143 | Batch_idx: 340 |  Loss: (0.1273) |  Loss2: (0.0000) | Acc: (95.00%) (41780/43648)
Epoch: 143 | Batch_idx: 350 |  Loss: (0.1282) |  Loss2: (0.0000) | Acc: (95.00%) (42993/44928)
Epoch: 143 | Batch_idx: 360 |  Loss: (0.1285) |  Loss2: (0.0000) | Acc: (95.00%) (44205/46208)
Epoch: 143 | Batch_idx: 370 |  Loss: (0.1284) |  Loss2: (0.0000) | Acc: (95.00%) (45424/47488)
Epoch: 143 | Batch_idx: 380 |  Loss: (0.1287) |  Loss2: (0.0000) | Acc: (95.00%) (46639/48768)
Epoch: 143 | Batch_idx: 390 |  Loss: (0.1281) |  Loss2: (0.0000) | Acc: (95.00%) (47828/50000)
# TEST : Loss: (0.4142) | Acc: (87.00%) (8747/10000)
percent tensor([0.5616, 0.5464, 0.5746, 0.5682, 0.5750, 0.5659, 0.5598, 0.5654, 0.5658,
        0.5553, 0.5571, 0.5665, 0.5555, 0.5488, 0.5546, 0.5566],
       device='cuda:0') torch.Size([16])
percent tensor([0.5279, 0.5364, 0.5228, 0.5317, 0.5223, 0.5504, 0.5278, 0.5213, 0.5163,
        0.5219, 0.5223, 0.5157, 0.5198, 0.5393, 0.5369, 0.5343],
       device='cuda:0') torch.Size([16])
percent tensor([0.5984, 0.6677, 0.5563, 0.4967, 0.5439, 0.5157, 0.6299, 0.5527, 0.5842,
        0.6390, 0.6309, 0.6207, 0.6924, 0.5266, 0.6132, 0.5765],
       device='cuda:0') torch.Size([16])
percent tensor([0.6953, 0.6868, 0.7074, 0.7176, 0.7163, 0.7082, 0.7141, 0.7049, 0.7090,
        0.6984, 0.7314, 0.7244, 0.6928, 0.7199, 0.7130, 0.7084],
       device='cuda:0') torch.Size([16])
percent tensor([0.6320, 0.6479, 0.6986, 0.6432, 0.6834, 0.8094, 0.6564, 0.5732, 0.6900,
        0.6377, 0.6886, 0.5930, 0.6989, 0.6910, 0.6174, 0.7048],
       device='cuda:0') torch.Size([16])
percent tensor([0.5443, 0.6804, 0.5800, 0.5015, 0.5413, 0.5705, 0.5390, 0.4195, 0.6847,
        0.6476, 0.7198, 0.6307, 0.6743, 0.7317, 0.4593, 0.4965],
       device='cuda:0') torch.Size([16])
percent tensor([0.5498, 0.6225, 0.8149, 0.7624, 0.8468, 0.7117, 0.6689, 0.7259, 0.6753,
        0.6291, 0.6531, 0.7684, 0.6455, 0.6330, 0.6486, 0.5520],
       device='cuda:0') torch.Size([16])
percent tensor([0.9996, 0.9991, 0.9995, 0.9994, 0.9994, 0.9993, 0.9992, 0.9995, 0.9993,
        0.9995, 0.9995, 0.9996, 0.9993, 0.9991, 0.9995, 0.9993],
       device='cuda:0') torch.Size([16])
Epoch: 144 | Batch_idx: 0 |  Loss: (0.1179) |  Loss2: (0.0000) | Acc: (94.00%) (121/128)
Epoch: 144 | Batch_idx: 10 |  Loss: (0.1095) |  Loss2: (0.0000) | Acc: (96.00%) (1354/1408)
Epoch: 144 | Batch_idx: 20 |  Loss: (0.1077) |  Loss2: (0.0000) | Acc: (96.00%) (2592/2688)
Epoch: 144 | Batch_idx: 30 |  Loss: (0.1115) |  Loss2: (0.0000) | Acc: (96.00%) (3823/3968)
Epoch: 144 | Batch_idx: 40 |  Loss: (0.1147) |  Loss2: (0.0000) | Acc: (96.00%) (5043/5248)
Epoch: 144 | Batch_idx: 50 |  Loss: (0.1149) |  Loss2: (0.0000) | Acc: (96.00%) (6279/6528)
Epoch: 144 | Batch_idx: 60 |  Loss: (0.1157) |  Loss2: (0.0000) | Acc: (96.00%) (7503/7808)
Epoch: 144 | Batch_idx: 70 |  Loss: (0.1143) |  Loss2: (0.0000) | Acc: (96.00%) (8735/9088)
Epoch: 144 | Batch_idx: 80 |  Loss: (0.1146) |  Loss2: (0.0000) | Acc: (96.00%) (9965/10368)
Epoch: 144 | Batch_idx: 90 |  Loss: (0.1152) |  Loss2: (0.0000) | Acc: (96.00%) (11187/11648)
Epoch: 144 | Batch_idx: 100 |  Loss: (0.1137) |  Loss2: (0.0000) | Acc: (96.00%) (12424/12928)
Epoch: 144 | Batch_idx: 110 |  Loss: (0.1145) |  Loss2: (0.0000) | Acc: (96.00%) (13646/14208)
Epoch: 144 | Batch_idx: 120 |  Loss: (0.1151) |  Loss2: (0.0000) | Acc: (95.00%) (14864/15488)
Epoch: 144 | Batch_idx: 130 |  Loss: (0.1146) |  Loss2: (0.0000) | Acc: (95.00%) (16090/16768)
Epoch: 144 | Batch_idx: 140 |  Loss: (0.1160) |  Loss2: (0.0000) | Acc: (95.00%) (17305/18048)
Epoch: 144 | Batch_idx: 150 |  Loss: (0.1153) |  Loss2: (0.0000) | Acc: (95.00%) (18542/19328)
Epoch: 144 | Batch_idx: 160 |  Loss: (0.1153) |  Loss2: (0.0000) | Acc: (95.00%) (19767/20608)
Epoch: 144 | Batch_idx: 170 |  Loss: (0.1160) |  Loss2: (0.0000) | Acc: (95.00%) (20986/21888)
Epoch: 144 | Batch_idx: 180 |  Loss: (0.1174) |  Loss2: (0.0000) | Acc: (95.00%) (22204/23168)
Epoch: 144 | Batch_idx: 190 |  Loss: (0.1177) |  Loss2: (0.0000) | Acc: (95.00%) (23425/24448)
Epoch: 144 | Batch_idx: 200 |  Loss: (0.1180) |  Loss2: (0.0000) | Acc: (95.00%) (24649/25728)
Epoch: 144 | Batch_idx: 210 |  Loss: (0.1178) |  Loss2: (0.0000) | Acc: (95.00%) (25869/27008)
Epoch: 144 | Batch_idx: 220 |  Loss: (0.1187) |  Loss2: (0.0000) | Acc: (95.00%) (27088/28288)
Epoch: 144 | Batch_idx: 230 |  Loss: (0.1194) |  Loss2: (0.0000) | Acc: (95.00%) (28309/29568)
Epoch: 144 | Batch_idx: 240 |  Loss: (0.1196) |  Loss2: (0.0000) | Acc: (95.00%) (29530/30848)
Epoch: 144 | Batch_idx: 250 |  Loss: (0.1198) |  Loss2: (0.0000) | Acc: (95.00%) (30757/32128)
Epoch: 144 | Batch_idx: 260 |  Loss: (0.1196) |  Loss2: (0.0000) | Acc: (95.00%) (31991/33408)
Epoch: 144 | Batch_idx: 270 |  Loss: (0.1199) |  Loss2: (0.0000) | Acc: (95.00%) (33217/34688)
Epoch: 144 | Batch_idx: 280 |  Loss: (0.1202) |  Loss2: (0.0000) | Acc: (95.00%) (34440/35968)
Epoch: 144 | Batch_idx: 290 |  Loss: (0.1201) |  Loss2: (0.0000) | Acc: (95.00%) (35668/37248)
Epoch: 144 | Batch_idx: 300 |  Loss: (0.1200) |  Loss2: (0.0000) | Acc: (95.00%) (36898/38528)
Epoch: 144 | Batch_idx: 310 |  Loss: (0.1206) |  Loss2: (0.0000) | Acc: (95.00%) (38115/39808)
Epoch: 144 | Batch_idx: 320 |  Loss: (0.1207) |  Loss2: (0.0000) | Acc: (95.00%) (39337/41088)
Epoch: 144 | Batch_idx: 330 |  Loss: (0.1208) |  Loss2: (0.0000) | Acc: (95.00%) (40561/42368)
Epoch: 144 | Batch_idx: 340 |  Loss: (0.1207) |  Loss2: (0.0000) | Acc: (95.00%) (41785/43648)
Epoch: 144 | Batch_idx: 350 |  Loss: (0.1208) |  Loss2: (0.0000) | Acc: (95.00%) (43009/44928)
Epoch: 144 | Batch_idx: 360 |  Loss: (0.1208) |  Loss2: (0.0000) | Acc: (95.00%) (44238/46208)
Epoch: 144 | Batch_idx: 370 |  Loss: (0.1212) |  Loss2: (0.0000) | Acc: (95.00%) (45471/47488)
Epoch: 144 | Batch_idx: 380 |  Loss: (0.1210) |  Loss2: (0.0000) | Acc: (95.00%) (46705/48768)
Epoch: 144 | Batch_idx: 390 |  Loss: (0.1213) |  Loss2: (0.0000) | Acc: (95.00%) (47885/50000)
# TEST : Loss: (0.3948) | Acc: (88.00%) (8803/10000)
percent tensor([0.5610, 0.5452, 0.5759, 0.5670, 0.5762, 0.5650, 0.5597, 0.5652, 0.5657,
        0.5555, 0.5566, 0.5673, 0.5544, 0.5463, 0.5533, 0.5556],
       device='cuda:0') torch.Size([16])
percent tensor([0.5294, 0.5370, 0.5223, 0.5309, 0.5242, 0.5529, 0.5289, 0.5214, 0.5183,
        0.5224, 0.5244, 0.5159, 0.5206, 0.5386, 0.5386, 0.5350],
       device='cuda:0') torch.Size([16])
percent tensor([0.5975, 0.6683, 0.5680, 0.5082, 0.5429, 0.5044, 0.6291, 0.5627, 0.5866,
        0.6464, 0.6278, 0.6277, 0.6944, 0.5458, 0.6097, 0.5771],
       device='cuda:0') torch.Size([16])
percent tensor([0.6967, 0.6923, 0.7004, 0.7141, 0.7162, 0.7093, 0.7091, 0.7006, 0.7063,
        0.7017, 0.7311, 0.7166, 0.6948, 0.7156, 0.7147, 0.7091],
       device='cuda:0') torch.Size([16])
percent tensor([0.6460, 0.6522, 0.7040, 0.6324, 0.6821, 0.8187, 0.6685, 0.5769, 0.7033,
        0.6359, 0.7074, 0.5973, 0.7045, 0.7164, 0.6284, 0.7236],
       device='cuda:0') torch.Size([16])
percent tensor([0.5556, 0.6992, 0.5561, 0.5234, 0.5220, 0.5637, 0.5668, 0.4150, 0.6815,
        0.6558, 0.7274, 0.6355, 0.6869, 0.7516, 0.4722, 0.5282],
       device='cuda:0') torch.Size([16])
percent tensor([0.5397, 0.6535, 0.7952, 0.7696, 0.8526, 0.6931, 0.6811, 0.7299, 0.6974,
        0.6546, 0.6611, 0.7857, 0.6731, 0.6682, 0.6587, 0.5635],
       device='cuda:0') torch.Size([16])
percent tensor([0.9996, 0.9993, 0.9994, 0.9994, 0.9991, 0.9993, 0.9991, 0.9993, 0.9989,
        0.9994, 0.9995, 0.9994, 0.9992, 0.9990, 0.9993, 0.9991],
       device='cuda:0') torch.Size([16])
False Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=128, out_features=16, bias=False)
True Linear(in_features=16, out_features=2, bias=False)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=128, out_features=16, bias=False)
True Linear(in_features=16, out_features=2, bias=False)
False Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=256, out_features=32, bias=False)
True Linear(in_features=32, out_features=2, bias=False)
False Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=256, out_features=32, bias=False)
True Linear(in_features=32, out_features=2, bias=False)
False Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=512, out_features=64, bias=False)
True Linear(in_features=64, out_features=2, bias=False)
False Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=512, out_features=64, bias=False)
True Linear(in_features=64, out_features=2, bias=False)
False Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1024, out_features=128, bias=False)
True Linear(in_features=128, out_features=2, bias=False)
False Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1024, out_features=128, bias=False)
True Linear(in_features=128, out_features=2, bias=False)
False Linear(in_features=512, out_features=10, bias=True)
Epoch: 145 | Batch_idx: 0 |  Loss: (0.1003) |  Loss2: (0.0000) | Acc: (96.00%) (123/128)
Epoch: 145 | Batch_idx: 10 |  Loss: (0.1158) |  Loss2: (0.0000) | Acc: (96.00%) (1354/1408)
Epoch: 145 | Batch_idx: 20 |  Loss: (0.1125) |  Loss2: (0.0000) | Acc: (96.00%) (2585/2688)
Epoch: 145 | Batch_idx: 30 |  Loss: (0.1276) |  Loss2: (0.0000) | Acc: (95.00%) (3792/3968)
Epoch: 145 | Batch_idx: 40 |  Loss: (0.1279) |  Loss2: (0.0000) | Acc: (95.00%) (5020/5248)
Epoch: 145 | Batch_idx: 50 |  Loss: (0.1332) |  Loss2: (0.0000) | Acc: (95.00%) (6240/6528)
Epoch: 145 | Batch_idx: 60 |  Loss: (0.1379) |  Loss2: (0.0000) | Acc: (95.00%) (7438/7808)
Epoch: 145 | Batch_idx: 70 |  Loss: (0.1396) |  Loss2: (0.0000) | Acc: (95.00%) (8654/9088)
Epoch: 145 | Batch_idx: 80 |  Loss: (0.1410) |  Loss2: (0.0000) | Acc: (95.00%) (9869/10368)
Epoch: 145 | Batch_idx: 90 |  Loss: (0.1421) |  Loss2: (0.0000) | Acc: (95.00%) (11076/11648)
Epoch: 145 | Batch_idx: 100 |  Loss: (0.1414) |  Loss2: (0.0000) | Acc: (95.00%) (12294/12928)
Epoch: 145 | Batch_idx: 110 |  Loss: (0.1404) |  Loss2: (0.0000) | Acc: (95.00%) (13508/14208)
Epoch: 145 | Batch_idx: 120 |  Loss: (0.1440) |  Loss2: (0.0000) | Acc: (94.00%) (14702/15488)
Epoch: 145 | Batch_idx: 130 |  Loss: (0.1437) |  Loss2: (0.0000) | Acc: (94.00%) (15921/16768)
Epoch: 145 | Batch_idx: 140 |  Loss: (0.1433) |  Loss2: (0.0000) | Acc: (94.00%) (17129/18048)
Epoch: 145 | Batch_idx: 150 |  Loss: (0.1413) |  Loss2: (0.0000) | Acc: (94.00%) (18357/19328)
Epoch: 145 | Batch_idx: 160 |  Loss: (0.1415) |  Loss2: (0.0000) | Acc: (95.00%) (19578/20608)
Epoch: 145 | Batch_idx: 170 |  Loss: (0.1411) |  Loss2: (0.0000) | Acc: (94.00%) (20793/21888)
Epoch: 145 | Batch_idx: 180 |  Loss: (0.1412) |  Loss2: (0.0000) | Acc: (95.00%) (22010/23168)
Epoch: 145 | Batch_idx: 190 |  Loss: (0.1409) |  Loss2: (0.0000) | Acc: (95.00%) (23229/24448)
Epoch: 145 | Batch_idx: 200 |  Loss: (0.1402) |  Loss2: (0.0000) | Acc: (95.00%) (24451/25728)
Epoch: 145 | Batch_idx: 210 |  Loss: (0.1394) |  Loss2: (0.0000) | Acc: (95.00%) (25671/27008)
Epoch: 145 | Batch_idx: 220 |  Loss: (0.1392) |  Loss2: (0.0000) | Acc: (95.00%) (26888/28288)
Epoch: 145 | Batch_idx: 230 |  Loss: (0.1384) |  Loss2: (0.0000) | Acc: (95.00%) (28110/29568)
Epoch: 145 | Batch_idx: 240 |  Loss: (0.1383) |  Loss2: (0.0000) | Acc: (95.00%) (29333/30848)
Epoch: 145 | Batch_idx: 250 |  Loss: (0.1393) |  Loss2: (0.0000) | Acc: (95.00%) (30545/32128)
Epoch: 145 | Batch_idx: 260 |  Loss: (0.1388) |  Loss2: (0.0000) | Acc: (95.00%) (31768/33408)
Epoch: 145 | Batch_idx: 270 |  Loss: (0.1382) |  Loss2: (0.0000) | Acc: (95.00%) (32997/34688)
Epoch: 145 | Batch_idx: 280 |  Loss: (0.1381) |  Loss2: (0.0000) | Acc: (95.00%) (34216/35968)
Epoch: 145 | Batch_idx: 290 |  Loss: (0.1372) |  Loss2: (0.0000) | Acc: (95.00%) (35451/37248)
Epoch: 145 | Batch_idx: 300 |  Loss: (0.1384) |  Loss2: (0.0000) | Acc: (95.00%) (36649/38528)
Epoch: 145 | Batch_idx: 310 |  Loss: (0.1385) |  Loss2: (0.0000) | Acc: (95.00%) (37868/39808)
Epoch: 145 | Batch_idx: 320 |  Loss: (0.1383) |  Loss2: (0.0000) | Acc: (95.00%) (39096/41088)
Epoch: 145 | Batch_idx: 330 |  Loss: (0.1378) |  Loss2: (0.0000) | Acc: (95.00%) (40319/42368)
Epoch: 145 | Batch_idx: 340 |  Loss: (0.1373) |  Loss2: (0.0000) | Acc: (95.00%) (41552/43648)
Epoch: 145 | Batch_idx: 350 |  Loss: (0.1372) |  Loss2: (0.0000) | Acc: (95.00%) (42774/44928)
Epoch: 145 | Batch_idx: 360 |  Loss: (0.1368) |  Loss2: (0.0000) | Acc: (95.00%) (43996/46208)
Epoch: 145 | Batch_idx: 370 |  Loss: (0.1363) |  Loss2: (0.0000) | Acc: (95.00%) (45222/47488)
Epoch: 145 | Batch_idx: 380 |  Loss: (0.1360) |  Loss2: (0.0000) | Acc: (95.00%) (46440/48768)
Epoch: 145 | Batch_idx: 390 |  Loss: (0.1359) |  Loss2: (0.0000) | Acc: (95.00%) (47618/50000)
=> saving checkpoint 'drive/app/torch/save_Routing_Gate_2/checkpoint_145.pth.tar'
# TEST : Loss: (0.4029) | Acc: (87.00%) (8789/10000)
percent tensor([0.5562, 0.5385, 0.5714, 0.5627, 0.5715, 0.5604, 0.5540, 0.5597, 0.5607,
        0.5501, 0.5509, 0.5625, 0.5489, 0.5405, 0.5476, 0.5507],
       device='cuda:0') torch.Size([16])
percent tensor([0.5342, 0.5424, 0.5240, 0.5342, 0.5261, 0.5587, 0.5338, 0.5236, 0.5212,
        0.5269, 0.5297, 0.5183, 0.5253, 0.5434, 0.5441, 0.5403],
       device='cuda:0') torch.Size([16])
percent tensor([0.5950, 0.6713, 0.5891, 0.5066, 0.5579, 0.4819, 0.6390, 0.5707, 0.5887,
        0.6534, 0.6249, 0.6488, 0.7014, 0.5333, 0.6054, 0.5675],
       device='cuda:0') torch.Size([16])
percent tensor([0.6864, 0.6838, 0.6930, 0.7052, 0.7062, 0.7016, 0.7006, 0.6920, 0.7009,
        0.6927, 0.7249, 0.7106, 0.6877, 0.7092, 0.7062, 0.7008],
       device='cuda:0') torch.Size([16])
percent tensor([0.6284, 0.6429, 0.6981, 0.6274, 0.6742, 0.7908, 0.6559, 0.5785, 0.6946,
        0.6308, 0.6976, 0.6011, 0.6828, 0.7030, 0.6150, 0.6980],
       device='cuda:0') torch.Size([16])
percent tensor([0.5537, 0.6894, 0.5723, 0.5152, 0.5367, 0.5652, 0.5769, 0.4160, 0.6792,
        0.6535, 0.7159, 0.6291, 0.6794, 0.7474, 0.4549, 0.5289],
       device='cuda:0') torch.Size([16])
percent tensor([0.5668, 0.6886, 0.8196, 0.7922, 0.8714, 0.7279, 0.7121, 0.7519, 0.7469,
        0.6717, 0.6999, 0.8115, 0.7119, 0.6998, 0.6794, 0.5828],
       device='cuda:0') torch.Size([16])
percent tensor([0.9997, 0.9991, 0.9995, 0.9994, 0.9993, 0.9993, 0.9993, 0.9993, 0.9990,
        0.9995, 0.9995, 0.9994, 0.9993, 0.9990, 0.9993, 0.9992],
       device='cuda:0') torch.Size([16])
