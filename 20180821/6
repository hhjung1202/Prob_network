Files already downloaded and verified
USE 1 GPUs!
Epoch: 0 | Batch_idx: 0 |  Loss: (2.3189) |  Loss2: (0.0000) | Acc: (9.00%) (12/128)
Epoch: 0 | Batch_idx: 10 |  Loss: (2.3100) |  Loss2: (0.0000) | Acc: (10.00%) (141/1408)
Epoch: 0 | Batch_idx: 20 |  Loss: (2.3061) |  Loss2: (0.0000) | Acc: (9.00%) (267/2688)
Epoch: 0 | Batch_idx: 30 |  Loss: (2.3007) |  Loss2: (0.0000) | Acc: (10.00%) (419/3968)
Epoch: 0 | Batch_idx: 40 |  Loss: (2.2940) |  Loss2: (0.0000) | Acc: (12.00%) (640/5248)
Epoch: 0 | Batch_idx: 50 |  Loss: (2.2885) |  Loss2: (0.0000) | Acc: (13.00%) (856/6528)
Epoch: 0 | Batch_idx: 60 |  Loss: (2.2822) |  Loss2: (0.0000) | Acc: (14.00%) (1117/7808)
Epoch: 0 | Batch_idx: 70 |  Loss: (2.2757) |  Loss2: (0.0000) | Acc: (15.00%) (1373/9088)
Epoch: 0 | Batch_idx: 80 |  Loss: (2.2695) |  Loss2: (0.0000) | Acc: (15.00%) (1627/10368)
Epoch: 0 | Batch_idx: 90 |  Loss: (2.2618) |  Loss2: (0.0000) | Acc: (16.00%) (1883/11648)
Epoch: 0 | Batch_idx: 100 |  Loss: (2.2529) |  Loss2: (0.0000) | Acc: (16.00%) (2194/12928)
Epoch: 0 | Batch_idx: 110 |  Loss: (2.2452) |  Loss2: (0.0000) | Acc: (17.00%) (2488/14208)
Epoch: 0 | Batch_idx: 120 |  Loss: (2.2379) |  Loss2: (0.0000) | Acc: (17.00%) (2749/15488)
Epoch: 0 | Batch_idx: 130 |  Loss: (2.2306) |  Loss2: (0.0000) | Acc: (18.00%) (3056/16768)
Epoch: 0 | Batch_idx: 140 |  Loss: (2.2220) |  Loss2: (0.0000) | Acc: (18.00%) (3362/18048)
Epoch: 0 | Batch_idx: 150 |  Loss: (2.2136) |  Loss2: (0.0000) | Acc: (19.00%) (3711/19328)
Epoch: 0 | Batch_idx: 160 |  Loss: (2.2050) |  Loss2: (0.0000) | Acc: (19.00%) (4034/20608)
Epoch: 0 | Batch_idx: 170 |  Loss: (2.1972) |  Loss2: (0.0000) | Acc: (19.00%) (4354/21888)
Epoch: 0 | Batch_idx: 180 |  Loss: (2.1908) |  Loss2: (0.0000) | Acc: (20.00%) (4643/23168)
Epoch: 0 | Batch_idx: 190 |  Loss: (2.1836) |  Loss2: (0.0000) | Acc: (20.00%) (4972/24448)
Epoch: 0 | Batch_idx: 200 |  Loss: (2.1754) |  Loss2: (0.0000) | Acc: (20.00%) (5313/25728)
Epoch: 0 | Batch_idx: 210 |  Loss: (2.1686) |  Loss2: (0.0000) | Acc: (20.00%) (5632/27008)
Epoch: 0 | Batch_idx: 220 |  Loss: (2.1618) |  Loss2: (0.0000) | Acc: (21.00%) (5978/28288)
Epoch: 0 | Batch_idx: 230 |  Loss: (2.1556) |  Loss2: (0.0000) | Acc: (21.00%) (6347/29568)
Epoch: 0 | Batch_idx: 240 |  Loss: (2.1492) |  Loss2: (0.0000) | Acc: (21.00%) (6704/30848)
Epoch: 0 | Batch_idx: 250 |  Loss: (2.1430) |  Loss2: (0.0000) | Acc: (21.00%) (7035/32128)
Epoch: 0 | Batch_idx: 260 |  Loss: (2.1356) |  Loss2: (0.0000) | Acc: (22.00%) (7441/33408)
Epoch: 0 | Batch_idx: 270 |  Loss: (2.1291) |  Loss2: (0.0000) | Acc: (22.00%) (7812/34688)
Epoch: 0 | Batch_idx: 280 |  Loss: (2.1227) |  Loss2: (0.0000) | Acc: (22.00%) (8186/35968)
Epoch: 0 | Batch_idx: 290 |  Loss: (2.1166) |  Loss2: (0.0000) | Acc: (22.00%) (8553/37248)
Epoch: 0 | Batch_idx: 300 |  Loss: (2.1109) |  Loss2: (0.0000) | Acc: (23.00%) (8920/38528)
Epoch: 0 | Batch_idx: 310 |  Loss: (2.1046) |  Loss2: (0.0000) | Acc: (23.00%) (9297/39808)
Epoch: 0 | Batch_idx: 320 |  Loss: (2.0986) |  Loss2: (0.0000) | Acc: (23.00%) (9683/41088)
Epoch: 0 | Batch_idx: 330 |  Loss: (2.0934) |  Loss2: (0.0000) | Acc: (23.00%) (10064/42368)
Epoch: 0 | Batch_idx: 340 |  Loss: (2.0872) |  Loss2: (0.0000) | Acc: (23.00%) (10435/43648)
Epoch: 0 | Batch_idx: 350 |  Loss: (2.0814) |  Loss2: (0.0000) | Acc: (24.00%) (10834/44928)
Epoch: 0 | Batch_idx: 360 |  Loss: (2.0757) |  Loss2: (0.0000) | Acc: (24.00%) (11245/46208)
Epoch: 0 | Batch_idx: 370 |  Loss: (2.0711) |  Loss2: (0.0000) | Acc: (24.00%) (11625/47488)
Epoch: 0 | Batch_idx: 380 |  Loss: (2.0660) |  Loss2: (0.0000) | Acc: (24.00%) (12017/48768)
Epoch: 0 | Batch_idx: 390 |  Loss: (2.0605) |  Loss2: (0.0000) | Acc: (24.00%) (12435/50000)
/usr/local/lib/python3.6/dist-packages/torch/serialization.py:241: UserWarning: Couldn't retrieve source code for container of type ResNet. It won't be checked for correctness upon loading.
  "type " + obj.__name__ + ". It won't be checked "
/usr/local/lib/python3.6/dist-packages/torch/serialization.py:241: UserWarning: Couldn't retrieve source code for container of type BasicBlock. It won't be checked for correctness upon loading.
  "type " + obj.__name__ + ". It won't be checked "
/usr/local/lib/python3.6/dist-packages/torch/serialization.py:241: UserWarning: Couldn't retrieve source code for container of type _Gate. It won't be checked for correctness upon loading.
  "type " + obj.__name__ + ". It won't be checked "
=> saving checkpoint 'drive/app/torch/save_Routing_Gate_2/checkpoint_000.pth.tar'
# TEST : Loss: (1.8273) | Acc: (32.00%) (3259/10000)
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 3, 3, 3]) tensor(169.6008, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(767.1996, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(769.1024, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([128, 64, 3, 3]) tensor(1536.9159, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([128, 64, 1, 1]) tensor(511.5774, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([128, 128, 3, 3]) tensor(2172.9163, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([256, 128, 3, 3]) tensor(4342.8921, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([256, 128, 1, 1]) tensor(1448.3165, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([256, 256, 3, 3]) tensor(6143.1284, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([512, 256, 3, 3]) tensor(12286.0361, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([512, 256, 1, 1]) tensor(4093.1997, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([512, 512, 3, 3]) tensor(17364.7441, device='cuda:0', grad_fn=<NormBackward0>)
Epoch: 1 | Batch_idx: 0 |  Loss: (1.8682) |  Loss2: (0.0000) | Acc: (33.00%) (43/128)
Epoch: 1 | Batch_idx: 10 |  Loss: (1.8323) |  Loss2: (0.0000) | Acc: (35.00%) (493/1408)
Epoch: 1 | Batch_idx: 20 |  Loss: (1.8395) |  Loss2: (0.0000) | Acc: (33.00%) (902/2688)
Epoch: 1 | Batch_idx: 30 |  Loss: (1.8411) |  Loss2: (0.0000) | Acc: (33.00%) (1315/3968)
Epoch: 1 | Batch_idx: 40 |  Loss: (1.8390) |  Loss2: (0.0000) | Acc: (33.00%) (1733/5248)
Epoch: 1 | Batch_idx: 50 |  Loss: (1.8355) |  Loss2: (0.0000) | Acc: (33.00%) (2157/6528)
Epoch: 1 | Batch_idx: 60 |  Loss: (1.8314) |  Loss2: (0.0000) | Acc: (33.00%) (2583/7808)
Epoch: 1 | Batch_idx: 70 |  Loss: (1.8249) |  Loss2: (0.0000) | Acc: (33.00%) (3056/9088)
Epoch: 1 | Batch_idx: 80 |  Loss: (1.8204) |  Loss2: (0.0000) | Acc: (33.00%) (3473/10368)
Epoch: 1 | Batch_idx: 90 |  Loss: (1.8147) |  Loss2: (0.0000) | Acc: (33.00%) (3933/11648)
Epoch: 1 | Batch_idx: 100 |  Loss: (1.8083) |  Loss2: (0.0000) | Acc: (34.00%) (4415/12928)
Epoch: 1 | Batch_idx: 110 |  Loss: (1.8066) |  Loss2: (0.0000) | Acc: (34.00%) (4833/14208)
Epoch: 1 | Batch_idx: 120 |  Loss: (1.8035) |  Loss2: (0.0000) | Acc: (34.00%) (5286/15488)
Epoch: 1 | Batch_idx: 130 |  Loss: (1.8011) |  Loss2: (0.0000) | Acc: (34.00%) (5726/16768)
Epoch: 1 | Batch_idx: 140 |  Loss: (1.7954) |  Loss2: (0.0000) | Acc: (34.00%) (6194/18048)
Epoch: 1 | Batch_idx: 150 |  Loss: (1.7906) |  Loss2: (0.0000) | Acc: (34.00%) (6641/19328)
Epoch: 1 | Batch_idx: 160 |  Loss: (1.7874) |  Loss2: (0.0000) | Acc: (34.00%) (7085/20608)
Epoch: 1 | Batch_idx: 170 |  Loss: (1.7841) |  Loss2: (0.0000) | Acc: (34.00%) (7564/21888)
Epoch: 1 | Batch_idx: 180 |  Loss: (1.7803) |  Loss2: (0.0000) | Acc: (34.00%) (8055/23168)
Epoch: 1 | Batch_idx: 190 |  Loss: (1.7773) |  Loss2: (0.0000) | Acc: (34.00%) (8527/24448)
Epoch: 1 | Batch_idx: 200 |  Loss: (1.7723) |  Loss2: (0.0000) | Acc: (35.00%) (9025/25728)
Epoch: 1 | Batch_idx: 210 |  Loss: (1.7701) |  Loss2: (0.0000) | Acc: (35.00%) (9496/27008)
Epoch: 1 | Batch_idx: 220 |  Loss: (1.7673) |  Loss2: (0.0000) | Acc: (35.00%) (9961/28288)
Epoch: 1 | Batch_idx: 230 |  Loss: (1.7641) |  Loss2: (0.0000) | Acc: (35.00%) (10442/29568)
Epoch: 1 | Batch_idx: 240 |  Loss: (1.7616) |  Loss2: (0.0000) | Acc: (35.00%) (10900/30848)
Epoch: 1 | Batch_idx: 250 |  Loss: (1.7589) |  Loss2: (0.0000) | Acc: (35.00%) (11383/32128)
Epoch: 1 | Batch_idx: 260 |  Loss: (1.7553) |  Loss2: (0.0000) | Acc: (35.00%) (11891/33408)
Epoch: 1 | Batch_idx: 270 |  Loss: (1.7525) |  Loss2: (0.0000) | Acc: (35.00%) (12374/34688)
Epoch: 1 | Batch_idx: 280 |  Loss: (1.7497) |  Loss2: (0.0000) | Acc: (35.00%) (12854/35968)
Epoch: 1 | Batch_idx: 290 |  Loss: (1.7473) |  Loss2: (0.0000) | Acc: (35.00%) (13345/37248)
Epoch: 1 | Batch_idx: 300 |  Loss: (1.7441) |  Loss2: (0.0000) | Acc: (35.00%) (13851/38528)
Epoch: 1 | Batch_idx: 310 |  Loss: (1.7417) |  Loss2: (0.0000) | Acc: (36.00%) (14353/39808)
Epoch: 1 | Batch_idx: 320 |  Loss: (1.7387) |  Loss2: (0.0000) | Acc: (36.00%) (14857/41088)
Epoch: 1 | Batch_idx: 330 |  Loss: (1.7370) |  Loss2: (0.0000) | Acc: (36.00%) (15333/42368)
Epoch: 1 | Batch_idx: 340 |  Loss: (1.7340) |  Loss2: (0.0000) | Acc: (36.00%) (15838/43648)
Epoch: 1 | Batch_idx: 350 |  Loss: (1.7315) |  Loss2: (0.0000) | Acc: (36.00%) (16345/44928)
Epoch: 1 | Batch_idx: 360 |  Loss: (1.7285) |  Loss2: (0.0000) | Acc: (36.00%) (16847/46208)
Epoch: 1 | Batch_idx: 370 |  Loss: (1.7256) |  Loss2: (0.0000) | Acc: (36.00%) (17369/47488)
Epoch: 1 | Batch_idx: 380 |  Loss: (1.7235) |  Loss2: (0.0000) | Acc: (36.00%) (17859/48768)
Epoch: 1 | Batch_idx: 390 |  Loss: (1.7208) |  Loss2: (0.0000) | Acc: (36.00%) (18348/50000)
# TEST : Loss: (1.5934) | Acc: (39.00%) (3965/10000)
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
Epoch: 2 | Batch_idx: 0 |  Loss: (1.5799) |  Loss2: (0.0000) | Acc: (45.00%) (58/128)
Epoch: 2 | Batch_idx: 10 |  Loss: (1.6231) |  Loss2: (0.0000) | Acc: (38.00%) (541/1408)
Epoch: 2 | Batch_idx: 20 |  Loss: (1.6073) |  Loss2: (0.0000) | Acc: (39.00%) (1069/2688)
Epoch: 2 | Batch_idx: 30 |  Loss: (1.6023) |  Loss2: (0.0000) | Acc: (40.00%) (1605/3968)
Epoch: 2 | Batch_idx: 40 |  Loss: (1.6128) |  Loss2: (0.0000) | Acc: (39.00%) (2067/5248)
Epoch: 2 | Batch_idx: 50 |  Loss: (1.6057) |  Loss2: (0.0000) | Acc: (39.00%) (2609/6528)
Epoch: 2 | Batch_idx: 60 |  Loss: (1.6048) |  Loss2: (0.0000) | Acc: (40.00%) (3147/7808)
Epoch: 2 | Batch_idx: 70 |  Loss: (1.6052) |  Loss2: (0.0000) | Acc: (40.00%) (3656/9088)
Epoch: 2 | Batch_idx: 80 |  Loss: (1.5992) |  Loss2: (0.0000) | Acc: (40.00%) (4219/10368)
Epoch: 2 | Batch_idx: 90 |  Loss: (1.5929) |  Loss2: (0.0000) | Acc: (41.00%) (4776/11648)
Epoch: 2 | Batch_idx: 100 |  Loss: (1.5921) |  Loss2: (0.0000) | Acc: (41.00%) (5306/12928)
Epoch: 2 | Batch_idx: 110 |  Loss: (1.5903) |  Loss2: (0.0000) | Acc: (41.00%) (5845/14208)
Epoch: 2 | Batch_idx: 120 |  Loss: (1.5858) |  Loss2: (0.0000) | Acc: (41.00%) (6391/15488)
Epoch: 2 | Batch_idx: 130 |  Loss: (1.5850) |  Loss2: (0.0000) | Acc: (41.00%) (6941/16768)
Epoch: 2 | Batch_idx: 140 |  Loss: (1.5820) |  Loss2: (0.0000) | Acc: (41.00%) (7498/18048)
Epoch: 2 | Batch_idx: 150 |  Loss: (1.5809) |  Loss2: (0.0000) | Acc: (41.00%) (8049/19328)
Epoch: 2 | Batch_idx: 160 |  Loss: (1.5803) |  Loss2: (0.0000) | Acc: (41.00%) (8583/20608)
Epoch: 2 | Batch_idx: 170 |  Loss: (1.5773) |  Loss2: (0.0000) | Acc: (41.00%) (9128/21888)
Epoch: 2 | Batch_idx: 180 |  Loss: (1.5746) |  Loss2: (0.0000) | Acc: (41.00%) (9697/23168)
Epoch: 2 | Batch_idx: 190 |  Loss: (1.5743) |  Loss2: (0.0000) | Acc: (41.00%) (10235/24448)
Epoch: 2 | Batch_idx: 200 |  Loss: (1.5704) |  Loss2: (0.0000) | Acc: (42.00%) (10833/25728)
Epoch: 2 | Batch_idx: 210 |  Loss: (1.5688) |  Loss2: (0.0000) | Acc: (42.00%) (11383/27008)
Epoch: 2 | Batch_idx: 220 |  Loss: (1.5650) |  Loss2: (0.0000) | Acc: (42.00%) (12008/28288)
Epoch: 2 | Batch_idx: 230 |  Loss: (1.5634) |  Loss2: (0.0000) | Acc: (42.00%) (12566/29568)
Epoch: 2 | Batch_idx: 240 |  Loss: (1.5619) |  Loss2: (0.0000) | Acc: (42.00%) (13119/30848)
Epoch: 2 | Batch_idx: 250 |  Loss: (1.5605) |  Loss2: (0.0000) | Acc: (42.00%) (13669/32128)
Epoch: 2 | Batch_idx: 260 |  Loss: (1.5585) |  Loss2: (0.0000) | Acc: (42.00%) (14243/33408)
Epoch: 2 | Batch_idx: 270 |  Loss: (1.5553) |  Loss2: (0.0000) | Acc: (42.00%) (14821/34688)
Epoch: 2 | Batch_idx: 280 |  Loss: (1.5541) |  Loss2: (0.0000) | Acc: (42.00%) (15378/35968)
Epoch: 2 | Batch_idx: 290 |  Loss: (1.5523) |  Loss2: (0.0000) | Acc: (42.00%) (15942/37248)
Epoch: 2 | Batch_idx: 300 |  Loss: (1.5496) |  Loss2: (0.0000) | Acc: (42.00%) (16532/38528)
Epoch: 2 | Batch_idx: 310 |  Loss: (1.5476) |  Loss2: (0.0000) | Acc: (42.00%) (17100/39808)
Epoch: 2 | Batch_idx: 320 |  Loss: (1.5453) |  Loss2: (0.0000) | Acc: (43.00%) (17689/41088)
Epoch: 2 | Batch_idx: 330 |  Loss: (1.5440) |  Loss2: (0.0000) | Acc: (43.00%) (18261/42368)
Epoch: 2 | Batch_idx: 340 |  Loss: (1.5421) |  Loss2: (0.0000) | Acc: (43.00%) (18837/43648)
Epoch: 2 | Batch_idx: 350 |  Loss: (1.5404) |  Loss2: (0.0000) | Acc: (43.00%) (19431/44928)
Epoch: 2 | Batch_idx: 360 |  Loss: (1.5383) |  Loss2: (0.0000) | Acc: (43.00%) (20008/46208)
Epoch: 2 | Batch_idx: 370 |  Loss: (1.5360) |  Loss2: (0.0000) | Acc: (43.00%) (20617/47488)
Epoch: 2 | Batch_idx: 380 |  Loss: (1.5356) |  Loss2: (0.0000) | Acc: (43.00%) (21174/48768)
Epoch: 2 | Batch_idx: 390 |  Loss: (1.5334) |  Loss2: (0.0000) | Acc: (43.00%) (21756/50000)
# TEST : Loss: (1.4563) | Acc: (46.00%) (4623/10000)
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
Epoch: 3 | Batch_idx: 0 |  Loss: (1.3821) |  Loss2: (0.0000) | Acc: (50.00%) (65/128)
Epoch: 3 | Batch_idx: 10 |  Loss: (1.4209) |  Loss2: (0.0000) | Acc: (47.00%) (673/1408)
Epoch: 3 | Batch_idx: 20 |  Loss: (1.4364) |  Loss2: (0.0000) | Acc: (47.00%) (1289/2688)
Epoch: 3 | Batch_idx: 30 |  Loss: (1.4423) |  Loss2: (0.0000) | Acc: (47.00%) (1888/3968)
Epoch: 3 | Batch_idx: 40 |  Loss: (1.4482) |  Loss2: (0.0000) | Acc: (47.00%) (2489/5248)
Epoch: 3 | Batch_idx: 50 |  Loss: (1.4394) |  Loss2: (0.0000) | Acc: (47.00%) (3129/6528)
Epoch: 3 | Batch_idx: 60 |  Loss: (1.4425) |  Loss2: (0.0000) | Acc: (47.00%) (3724/7808)
Epoch: 3 | Batch_idx: 70 |  Loss: (1.4350) |  Loss2: (0.0000) | Acc: (47.00%) (4357/9088)
Epoch: 3 | Batch_idx: 80 |  Loss: (1.4344) |  Loss2: (0.0000) | Acc: (48.00%) (4980/10368)
Epoch: 3 | Batch_idx: 90 |  Loss: (1.4369) |  Loss2: (0.0000) | Acc: (47.00%) (5580/11648)
Epoch: 3 | Batch_idx: 100 |  Loss: (1.4366) |  Loss2: (0.0000) | Acc: (47.00%) (6166/12928)
Epoch: 3 | Batch_idx: 110 |  Loss: (1.4386) |  Loss2: (0.0000) | Acc: (47.00%) (6754/14208)
Epoch: 3 | Batch_idx: 120 |  Loss: (1.4363) |  Loss2: (0.0000) | Acc: (47.00%) (7383/15488)
Epoch: 3 | Batch_idx: 130 |  Loss: (1.4324) |  Loss2: (0.0000) | Acc: (47.00%) (8019/16768)
Epoch: 3 | Batch_idx: 140 |  Loss: (1.4273) |  Loss2: (0.0000) | Acc: (47.00%) (8639/18048)
Epoch: 3 | Batch_idx: 150 |  Loss: (1.4260) |  Loss2: (0.0000) | Acc: (47.00%) (9237/19328)
Epoch: 3 | Batch_idx: 160 |  Loss: (1.4231) |  Loss2: (0.0000) | Acc: (47.00%) (9888/20608)
Epoch: 3 | Batch_idx: 170 |  Loss: (1.4211) |  Loss2: (0.0000) | Acc: (47.00%) (10505/21888)
Epoch: 3 | Batch_idx: 180 |  Loss: (1.4189) |  Loss2: (0.0000) | Acc: (48.00%) (11143/23168)
Epoch: 3 | Batch_idx: 190 |  Loss: (1.4184) |  Loss2: (0.0000) | Acc: (48.00%) (11773/24448)
Epoch: 3 | Batch_idx: 200 |  Loss: (1.4161) |  Loss2: (0.0000) | Acc: (48.00%) (12415/25728)
Epoch: 3 | Batch_idx: 210 |  Loss: (1.4138) |  Loss2: (0.0000) | Acc: (48.00%) (13066/27008)
Epoch: 3 | Batch_idx: 220 |  Loss: (1.4120) |  Loss2: (0.0000) | Acc: (48.00%) (13714/28288)
Epoch: 3 | Batch_idx: 230 |  Loss: (1.4111) |  Loss2: (0.0000) | Acc: (48.00%) (14363/29568)
Epoch: 3 | Batch_idx: 240 |  Loss: (1.4102) |  Loss2: (0.0000) | Acc: (48.00%) (14997/30848)
Epoch: 3 | Batch_idx: 250 |  Loss: (1.4089) |  Loss2: (0.0000) | Acc: (48.00%) (15646/32128)
Epoch: 3 | Batch_idx: 260 |  Loss: (1.4071) |  Loss2: (0.0000) | Acc: (48.00%) (16281/33408)
Epoch: 3 | Batch_idx: 270 |  Loss: (1.4057) |  Loss2: (0.0000) | Acc: (48.00%) (16920/34688)
Epoch: 3 | Batch_idx: 280 |  Loss: (1.4032) |  Loss2: (0.0000) | Acc: (48.00%) (17577/35968)
Epoch: 3 | Batch_idx: 290 |  Loss: (1.4014) |  Loss2: (0.0000) | Acc: (48.00%) (18229/37248)
Epoch: 3 | Batch_idx: 300 |  Loss: (1.3995) |  Loss2: (0.0000) | Acc: (49.00%) (18889/38528)
Epoch: 3 | Batch_idx: 310 |  Loss: (1.3974) |  Loss2: (0.0000) | Acc: (49.00%) (19542/39808)
Epoch: 3 | Batch_idx: 320 |  Loss: (1.3942) |  Loss2: (0.0000) | Acc: (49.00%) (20225/41088)
Epoch: 3 | Batch_idx: 330 |  Loss: (1.3930) |  Loss2: (0.0000) | Acc: (49.00%) (20865/42368)
Epoch: 3 | Batch_idx: 340 |  Loss: (1.3917) |  Loss2: (0.0000) | Acc: (49.00%) (21516/43648)
Epoch: 3 | Batch_idx: 350 |  Loss: (1.3889) |  Loss2: (0.0000) | Acc: (49.00%) (22197/44928)
Epoch: 3 | Batch_idx: 360 |  Loss: (1.3883) |  Loss2: (0.0000) | Acc: (49.00%) (22866/46208)
Epoch: 3 | Batch_idx: 370 |  Loss: (1.3861) |  Loss2: (0.0000) | Acc: (49.00%) (23564/47488)
Epoch: 3 | Batch_idx: 380 |  Loss: (1.3838) |  Loss2: (0.0000) | Acc: (49.00%) (24240/48768)
Epoch: 3 | Batch_idx: 390 |  Loss: (1.3818) |  Loss2: (0.0000) | Acc: (49.00%) (24907/50000)
# TEST : Loss: (1.4250) | Acc: (48.00%) (4834/10000)
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
Epoch: 4 | Batch_idx: 0 |  Loss: (1.3303) |  Loss2: (0.0000) | Acc: (50.00%) (64/128)
Epoch: 4 | Batch_idx: 10 |  Loss: (1.3160) |  Loss2: (0.0000) | Acc: (52.00%) (736/1408)
Epoch: 4 | Batch_idx: 20 |  Loss: (1.3046) |  Loss2: (0.0000) | Acc: (53.00%) (1428/2688)
Epoch: 4 | Batch_idx: 30 |  Loss: (1.3092) |  Loss2: (0.0000) | Acc: (52.00%) (2100/3968)
Epoch: 4 | Batch_idx: 40 |  Loss: (1.3029) |  Loss2: (0.0000) | Acc: (53.00%) (2787/5248)
Epoch: 4 | Batch_idx: 50 |  Loss: (1.2991) |  Loss2: (0.0000) | Acc: (53.00%) (3491/6528)
Epoch: 4 | Batch_idx: 60 |  Loss: (1.2992) |  Loss2: (0.0000) | Acc: (53.00%) (4180/7808)
Epoch: 4 | Batch_idx: 70 |  Loss: (1.2972) |  Loss2: (0.0000) | Acc: (53.00%) (4889/9088)
Epoch: 4 | Batch_idx: 80 |  Loss: (1.2950) |  Loss2: (0.0000) | Acc: (53.00%) (5598/10368)
Epoch: 4 | Batch_idx: 90 |  Loss: (1.2937) |  Loss2: (0.0000) | Acc: (54.00%) (6305/11648)
Epoch: 4 | Batch_idx: 100 |  Loss: (1.2951) |  Loss2: (0.0000) | Acc: (53.00%) (6967/12928)
Epoch: 4 | Batch_idx: 110 |  Loss: (1.2922) |  Loss2: (0.0000) | Acc: (53.00%) (7655/14208)
Epoch: 4 | Batch_idx: 120 |  Loss: (1.2887) |  Loss2: (0.0000) | Acc: (53.00%) (8356/15488)
Epoch: 4 | Batch_idx: 130 |  Loss: (1.2874) |  Loss2: (0.0000) | Acc: (53.00%) (9047/16768)
Epoch: 4 | Batch_idx: 140 |  Loss: (1.2822) |  Loss2: (0.0000) | Acc: (54.00%) (9783/18048)
Epoch: 4 | Batch_idx: 150 |  Loss: (1.2813) |  Loss2: (0.0000) | Acc: (54.00%) (10476/19328)
Epoch: 4 | Batch_idx: 160 |  Loss: (1.2798) |  Loss2: (0.0000) | Acc: (54.00%) (11182/20608)
Epoch: 4 | Batch_idx: 170 |  Loss: (1.2774) |  Loss2: (0.0000) | Acc: (54.00%) (11898/21888)
Epoch: 4 | Batch_idx: 180 |  Loss: (1.2782) |  Loss2: (0.0000) | Acc: (54.00%) (12567/23168)
Epoch: 4 | Batch_idx: 190 |  Loss: (1.2775) |  Loss2: (0.0000) | Acc: (54.00%) (13272/24448)
Epoch: 4 | Batch_idx: 200 |  Loss: (1.2756) |  Loss2: (0.0000) | Acc: (54.00%) (13981/25728)
Epoch: 4 | Batch_idx: 210 |  Loss: (1.2747) |  Loss2: (0.0000) | Acc: (54.00%) (14679/27008)
Epoch: 4 | Batch_idx: 220 |  Loss: (1.2738) |  Loss2: (0.0000) | Acc: (54.00%) (15371/28288)
Epoch: 4 | Batch_idx: 230 |  Loss: (1.2719) |  Loss2: (0.0000) | Acc: (54.00%) (16080/29568)
Epoch: 4 | Batch_idx: 240 |  Loss: (1.2724) |  Loss2: (0.0000) | Acc: (54.00%) (16775/30848)
Epoch: 4 | Batch_idx: 250 |  Loss: (1.2728) |  Loss2: (0.0000) | Acc: (54.00%) (17481/32128)
Epoch: 4 | Batch_idx: 260 |  Loss: (1.2727) |  Loss2: (0.0000) | Acc: (54.00%) (18181/33408)
Epoch: 4 | Batch_idx: 270 |  Loss: (1.2728) |  Loss2: (0.0000) | Acc: (54.00%) (18888/34688)
Epoch: 4 | Batch_idx: 280 |  Loss: (1.2712) |  Loss2: (0.0000) | Acc: (54.00%) (19624/35968)
Epoch: 4 | Batch_idx: 290 |  Loss: (1.2696) |  Loss2: (0.0000) | Acc: (54.00%) (20347/37248)
Epoch: 4 | Batch_idx: 300 |  Loss: (1.2696) |  Loss2: (0.0000) | Acc: (54.00%) (21040/38528)
Epoch: 4 | Batch_idx: 310 |  Loss: (1.2692) |  Loss2: (0.0000) | Acc: (54.00%) (21753/39808)
Epoch: 4 | Batch_idx: 320 |  Loss: (1.2682) |  Loss2: (0.0000) | Acc: (54.00%) (22462/41088)
Epoch: 4 | Batch_idx: 330 |  Loss: (1.2675) |  Loss2: (0.0000) | Acc: (54.00%) (23167/42368)
Epoch: 4 | Batch_idx: 340 |  Loss: (1.2646) |  Loss2: (0.0000) | Acc: (54.00%) (23921/43648)
Epoch: 4 | Batch_idx: 350 |  Loss: (1.2632) |  Loss2: (0.0000) | Acc: (54.00%) (24658/44928)
Epoch: 4 | Batch_idx: 360 |  Loss: (1.2615) |  Loss2: (0.0000) | Acc: (54.00%) (25395/46208)
Epoch: 4 | Batch_idx: 370 |  Loss: (1.2602) |  Loss2: (0.0000) | Acc: (54.00%) (26099/47488)
Epoch: 4 | Batch_idx: 380 |  Loss: (1.2594) |  Loss2: (0.0000) | Acc: (54.00%) (26793/48768)
Epoch: 4 | Batch_idx: 390 |  Loss: (1.2579) |  Loss2: (0.0000) | Acc: (55.00%) (27509/50000)
# TEST : Loss: (1.2010) | Acc: (56.00%) (5644/10000)
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
percent tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
       device='cuda:0') torch.Size([16])
False Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=128, out_features=16, bias=False)
True Linear(in_features=16, out_features=2, bias=False)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=128, out_features=16, bias=False)
True Linear(in_features=16, out_features=2, bias=False)
False Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=256, out_features=32, bias=False)
True Linear(in_features=32, out_features=2, bias=False)
False Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=256, out_features=32, bias=False)
True Linear(in_features=32, out_features=2, bias=False)
False Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=512, out_features=64, bias=False)
True Linear(in_features=64, out_features=2, bias=False)
False Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=512, out_features=64, bias=False)
True Linear(in_features=64, out_features=2, bias=False)
False Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1024, out_features=128, bias=False)
True Linear(in_features=128, out_features=2, bias=False)
False Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1024, out_features=128, bias=False)
True Linear(in_features=128, out_features=2, bias=False)
False Linear(in_features=512, out_features=10, bias=True)
Epoch: 5 | Batch_idx: 0 |  Loss: (1.1453) |  Loss2: (0.0000) | Acc: (55.00%) (71/128)
Epoch: 5 | Batch_idx: 10 |  Loss: (1.2397) |  Loss2: (0.0000) | Acc: (55.00%) (784/1408)
Epoch: 5 | Batch_idx: 20 |  Loss: (1.3145) |  Loss2: (0.0000) | Acc: (53.00%) (1427/2688)
Epoch: 5 | Batch_idx: 30 |  Loss: (1.3587) |  Loss2: (0.0000) | Acc: (51.00%) (2049/3968)
Epoch: 5 | Batch_idx: 40 |  Loss: (1.3742) |  Loss2: (0.0000) | Acc: (51.00%) (2681/5248)
Epoch: 5 | Batch_idx: 50 |  Loss: (1.3751) |  Loss2: (0.0000) | Acc: (50.00%) (3319/6528)
Epoch: 5 | Batch_idx: 60 |  Loss: (1.3811) |  Loss2: (0.0000) | Acc: (50.00%) (3924/7808)
Epoch: 5 | Batch_idx: 70 |  Loss: (1.3792) |  Loss2: (0.0000) | Acc: (50.00%) (4568/9088)
Epoch: 5 | Batch_idx: 80 |  Loss: (1.3805) |  Loss2: (0.0000) | Acc: (50.00%) (5208/10368)
Epoch: 5 | Batch_idx: 90 |  Loss: (1.3777) |  Loss2: (0.0000) | Acc: (50.00%) (5860/11648)
Epoch: 5 | Batch_idx: 100 |  Loss: (1.3769) |  Loss2: (0.0000) | Acc: (50.00%) (6503/12928)
Epoch: 5 | Batch_idx: 110 |  Loss: (1.3782) |  Loss2: (0.0000) | Acc: (50.00%) (7148/14208)
Epoch: 5 | Batch_idx: 120 |  Loss: (1.3788) |  Loss2: (0.0000) | Acc: (50.00%) (7791/15488)
Epoch: 5 | Batch_idx: 130 |  Loss: (1.3768) |  Loss2: (0.0000) | Acc: (50.00%) (8455/16768)
Epoch: 5 | Batch_idx: 140 |  Loss: (1.3715) |  Loss2: (0.0000) | Acc: (50.00%) (9126/18048)
Epoch: 5 | Batch_idx: 150 |  Loss: (1.3671) |  Loss2: (0.0000) | Acc: (50.00%) (9817/19328)
Epoch: 5 | Batch_idx: 160 |  Loss: (1.3659) |  Loss2: (0.0000) | Acc: (50.00%) (10472/20608)
Epoch: 5 | Batch_idx: 170 |  Loss: (1.3636) |  Loss2: (0.0000) | Acc: (50.00%) (11135/21888)
Epoch: 5 | Batch_idx: 180 |  Loss: (1.3644) |  Loss2: (0.0000) | Acc: (50.00%) (11766/23168)
Epoch: 5 | Batch_idx: 190 |  Loss: (1.3630) |  Loss2: (0.0000) | Acc: (50.00%) (12414/24448)
Epoch: 5 | Batch_idx: 200 |  Loss: (1.3631) |  Loss2: (0.0000) | Acc: (50.00%) (13058/25728)
Epoch: 5 | Batch_idx: 210 |  Loss: (1.3603) |  Loss2: (0.0000) | Acc: (50.00%) (13737/27008)
Epoch: 5 | Batch_idx: 220 |  Loss: (1.3567) |  Loss2: (0.0000) | Acc: (51.00%) (14427/28288)
Epoch: 5 | Batch_idx: 230 |  Loss: (1.3570) |  Loss2: (0.0000) | Acc: (51.00%) (15102/29568)
Epoch: 5 | Batch_idx: 240 |  Loss: (1.3555) |  Loss2: (0.0000) | Acc: (51.00%) (15779/30848)
Epoch: 5 | Batch_idx: 250 |  Loss: (1.3535) |  Loss2: (0.0000) | Acc: (51.00%) (16463/32128)
Epoch: 5 | Batch_idx: 260 |  Loss: (1.3505) |  Loss2: (0.0000) | Acc: (51.00%) (17153/33408)
Epoch: 5 | Batch_idx: 270 |  Loss: (1.3494) |  Loss2: (0.0000) | Acc: (51.00%) (17800/34688)
Epoch: 5 | Batch_idx: 280 |  Loss: (1.3469) |  Loss2: (0.0000) | Acc: (51.00%) (18489/35968)
Epoch: 5 | Batch_idx: 290 |  Loss: (1.3470) |  Loss2: (0.0000) | Acc: (51.00%) (19152/37248)
Epoch: 5 | Batch_idx: 300 |  Loss: (1.3434) |  Loss2: (0.0000) | Acc: (51.00%) (19860/38528)
Epoch: 5 | Batch_idx: 310 |  Loss: (1.3416) |  Loss2: (0.0000) | Acc: (51.00%) (20553/39808)
Epoch: 5 | Batch_idx: 320 |  Loss: (1.3393) |  Loss2: (0.0000) | Acc: (51.00%) (21244/41088)
Epoch: 5 | Batch_idx: 330 |  Loss: (1.3359) |  Loss2: (0.0000) | Acc: (51.00%) (21961/42368)
Epoch: 5 | Batch_idx: 340 |  Loss: (1.3332) |  Loss2: (0.0000) | Acc: (51.00%) (22669/43648)
Epoch: 5 | Batch_idx: 350 |  Loss: (1.3313) |  Loss2: (0.0000) | Acc: (51.00%) (23353/44928)
Epoch: 5 | Batch_idx: 360 |  Loss: (1.3294) |  Loss2: (0.0000) | Acc: (52.00%) (24054/46208)
Epoch: 5 | Batch_idx: 370 |  Loss: (1.3282) |  Loss2: (0.0000) | Acc: (52.00%) (24761/47488)
Epoch: 5 | Batch_idx: 380 |  Loss: (1.3248) |  Loss2: (0.0000) | Acc: (52.00%) (25467/48768)
Epoch: 5 | Batch_idx: 390 |  Loss: (1.3232) |  Loss2: (0.0000) | Acc: (52.00%) (26149/50000)
=> saving checkpoint 'drive/app/torch/save_Routing_Gate_2/checkpoint_005.pth.tar'
# TEST : Loss: (1.2370) | Acc: (54.00%) (5495/10000)
percent tensor([0.5025, 0.5044, 0.5030, 0.5021, 0.5032, 0.5021, 0.5044, 0.5032, 0.5038,
        0.5038, 0.5034, 0.5037, 0.5029, 0.5044, 0.5031, 0.5026],
       device='cuda:0') torch.Size([16])
percent tensor([0.5102, 0.5116, 0.5080, 0.5164, 0.5100, 0.5144, 0.5101, 0.5123, 0.5104,
        0.5111, 0.5103, 0.5088, 0.5094, 0.5149, 0.5123, 0.5134],
       device='cuda:0') torch.Size([16])
percent tensor([0.4913, 0.4923, 0.4860, 0.4874, 0.4861, 0.4892, 0.4900, 0.4874, 0.4911,
        0.4884, 0.4928, 0.4856, 0.4922, 0.4952, 0.4896, 0.4900],
       device='cuda:0') torch.Size([16])
percent tensor([0.5105, 0.5061, 0.4940, 0.5057, 0.4974, 0.5140, 0.5013, 0.4994, 0.5029,
        0.5038, 0.5074, 0.4960, 0.5091, 0.5066, 0.5086, 0.5110],
       device='cuda:0') torch.Size([16])
percent tensor([0.5326, 0.5261, 0.4901, 0.5074, 0.4910, 0.5325, 0.5126, 0.5004, 0.5236,
        0.5171, 0.5305, 0.4969, 0.5346, 0.5285, 0.5240, 0.5300],
       device='cuda:0') torch.Size([16])
percent tensor([0.5131, 0.5144, 0.5173, 0.5155, 0.5171, 0.5131, 0.5150, 0.5226, 0.5136,
        0.5155, 0.5138, 0.5152, 0.5130, 0.5133, 0.5161, 0.5141],
       device='cuda:0') torch.Size([16])
percent tensor([0.4652, 0.4906, 0.5464, 0.5186, 0.5500, 0.4607, 0.5164, 0.5696, 0.4783,
        0.5181, 0.4752, 0.5285, 0.4560, 0.4781, 0.5115, 0.4792],
       device='cuda:0') torch.Size([16])
percent tensor([0.5850, 0.5716, 0.6469, 0.6360, 0.6554, 0.6137, 0.5997, 0.6750, 0.5650,
        0.6277, 0.5759, 0.6092, 0.5703, 0.5768, 0.6053, 0.6193],
       device='cuda:0') torch.Size([16])
Epoch: 6 | Batch_idx: 0 |  Loss: (1.1759) |  Loss2: (0.0000) | Acc: (60.00%) (77/128)
Epoch: 6 | Batch_idx: 10 |  Loss: (1.2451) |  Loss2: (0.0000) | Acc: (56.00%) (793/1408)
Epoch: 6 | Batch_idx: 20 |  Loss: (1.2231) |  Loss2: (0.0000) | Acc: (56.00%) (1515/2688)
Epoch: 6 | Batch_idx: 30 |  Loss: (1.2209) |  Loss2: (0.0000) | Acc: (56.00%) (2253/3968)
Epoch: 6 | Batch_idx: 40 |  Loss: (1.2245) |  Loss2: (0.0000) | Acc: (56.00%) (2948/5248)
Epoch: 6 | Batch_idx: 50 |  Loss: (1.2385) |  Loss2: (0.0000) | Acc: (55.00%) (3618/6528)
Epoch: 6 | Batch_idx: 60 |  Loss: (1.2383) |  Loss2: (0.0000) | Acc: (55.00%) (4341/7808)
Epoch: 6 | Batch_idx: 70 |  Loss: (1.2282) |  Loss2: (0.0000) | Acc: (56.00%) (5093/9088)
Epoch: 6 | Batch_idx: 80 |  Loss: (1.2287) |  Loss2: (0.0000) | Acc: (56.00%) (5819/10368)
Epoch: 6 | Batch_idx: 90 |  Loss: (1.2274) |  Loss2: (0.0000) | Acc: (56.00%) (6524/11648)
Epoch: 6 | Batch_idx: 100 |  Loss: (1.2265) |  Loss2: (0.0000) | Acc: (56.00%) (7258/12928)
Epoch: 6 | Batch_idx: 110 |  Loss: (1.2269) |  Loss2: (0.0000) | Acc: (56.00%) (7978/14208)
Epoch: 6 | Batch_idx: 120 |  Loss: (1.2280) |  Loss2: (0.0000) | Acc: (56.00%) (8684/15488)
Epoch: 6 | Batch_idx: 130 |  Loss: (1.2287) |  Loss2: (0.0000) | Acc: (56.00%) (9410/16768)
Epoch: 6 | Batch_idx: 140 |  Loss: (1.2305) |  Loss2: (0.0000) | Acc: (56.00%) (10113/18048)
Epoch: 6 | Batch_idx: 150 |  Loss: (1.2262) |  Loss2: (0.0000) | Acc: (56.00%) (10877/19328)
Epoch: 6 | Batch_idx: 160 |  Loss: (1.2256) |  Loss2: (0.0000) | Acc: (56.00%) (11627/20608)
Epoch: 6 | Batch_idx: 170 |  Loss: (1.2272) |  Loss2: (0.0000) | Acc: (56.00%) (12356/21888)
Epoch: 6 | Batch_idx: 180 |  Loss: (1.2299) |  Loss2: (0.0000) | Acc: (56.00%) (13044/23168)
Epoch: 6 | Batch_idx: 190 |  Loss: (1.2300) |  Loss2: (0.0000) | Acc: (56.00%) (13741/24448)
Epoch: 6 | Batch_idx: 200 |  Loss: (1.2317) |  Loss2: (0.0000) | Acc: (56.00%) (14443/25728)
Epoch: 6 | Batch_idx: 210 |  Loss: (1.2318) |  Loss2: (0.0000) | Acc: (56.00%) (15168/27008)
Epoch: 6 | Batch_idx: 220 |  Loss: (1.2315) |  Loss2: (0.0000) | Acc: (56.00%) (15861/28288)
Epoch: 6 | Batch_idx: 230 |  Loss: (1.2319) |  Loss2: (0.0000) | Acc: (55.00%) (16556/29568)
Epoch: 6 | Batch_idx: 240 |  Loss: (1.2294) |  Loss2: (0.0000) | Acc: (56.00%) (17284/30848)
Epoch: 6 | Batch_idx: 250 |  Loss: (1.2278) |  Loss2: (0.0000) | Acc: (56.00%) (18003/32128)
Epoch: 6 | Batch_idx: 260 |  Loss: (1.2285) |  Loss2: (0.0000) | Acc: (55.00%) (18687/33408)
Epoch: 6 | Batch_idx: 270 |  Loss: (1.2257) |  Loss2: (0.0000) | Acc: (56.00%) (19430/34688)
Epoch: 6 | Batch_idx: 280 |  Loss: (1.2251) |  Loss2: (0.0000) | Acc: (56.00%) (20144/35968)
Epoch: 6 | Batch_idx: 290 |  Loss: (1.2245) |  Loss2: (0.0000) | Acc: (56.00%) (20866/37248)
Epoch: 6 | Batch_idx: 300 |  Loss: (1.2226) |  Loss2: (0.0000) | Acc: (56.00%) (21604/38528)
Epoch: 6 | Batch_idx: 310 |  Loss: (1.2223) |  Loss2: (0.0000) | Acc: (56.00%) (22329/39808)
Epoch: 6 | Batch_idx: 320 |  Loss: (1.2216) |  Loss2: (0.0000) | Acc: (56.00%) (23073/41088)
Epoch: 6 | Batch_idx: 330 |  Loss: (1.2202) |  Loss2: (0.0000) | Acc: (56.00%) (23821/42368)
Epoch: 6 | Batch_idx: 340 |  Loss: (1.2201) |  Loss2: (0.0000) | Acc: (56.00%) (24533/43648)
Epoch: 6 | Batch_idx: 350 |  Loss: (1.2194) |  Loss2: (0.0000) | Acc: (56.00%) (25240/44928)
Epoch: 6 | Batch_idx: 360 |  Loss: (1.2198) |  Loss2: (0.0000) | Acc: (56.00%) (25963/46208)
Epoch: 6 | Batch_idx: 370 |  Loss: (1.2202) |  Loss2: (0.0000) | Acc: (56.00%) (26665/47488)
Epoch: 6 | Batch_idx: 380 |  Loss: (1.2189) |  Loss2: (0.0000) | Acc: (56.00%) (27393/48768)
Epoch: 6 | Batch_idx: 390 |  Loss: (1.2189) |  Loss2: (0.0000) | Acc: (56.00%) (28097/50000)
# TEST : Loss: (1.2005) | Acc: (56.00%) (5694/10000)
percent tensor([0.5055, 0.5094, 0.5058, 0.5046, 0.5063, 0.5043, 0.5090, 0.5069, 0.5083,
        0.5078, 0.5076, 0.5071, 0.5065, 0.5096, 0.5067, 0.5057],
       device='cuda:0') torch.Size([16])
percent tensor([0.5113, 0.5117, 0.5039, 0.5191, 0.5072, 0.5183, 0.5085, 0.5115, 0.5097,
        0.5103, 0.5106, 0.5054, 0.5095, 0.5166, 0.5142, 0.5161],
       device='cuda:0') torch.Size([16])
percent tensor([0.4764, 0.4825, 0.4735, 0.4713, 0.4744, 0.4731, 0.4798, 0.4742, 0.4796,
        0.4753, 0.4808, 0.4730, 0.4787, 0.4871, 0.4756, 0.4744],
       device='cuda:0') torch.Size([16])
percent tensor([0.5209, 0.5132, 0.4989, 0.5147, 0.5035, 0.5270, 0.5075, 0.5064, 0.5101,
        0.5105, 0.5152, 0.5004, 0.5181, 0.5136, 0.5178, 0.5218],
       device='cuda:0') torch.Size([16])
percent tensor([0.5529, 0.5425, 0.4947, 0.5142, 0.4959, 0.5536, 0.5237, 0.5052, 0.5409,
        0.5303, 0.5482, 0.5016, 0.5551, 0.5492, 0.5368, 0.5482],
       device='cuda:0') torch.Size([16])
percent tensor([0.5217, 0.5231, 0.5334, 0.5293, 0.5309, 0.5230, 0.5247, 0.5411, 0.5237,
        0.5254, 0.5224, 0.5278, 0.5210, 0.5218, 0.5265, 0.5237],
       device='cuda:0') torch.Size([16])
percent tensor([0.4523, 0.4863, 0.5720, 0.5353, 0.5748, 0.4442, 0.5226, 0.6130, 0.4758,
        0.5285, 0.4704, 0.5422, 0.4403, 0.4654, 0.5213, 0.4812],
       device='cuda:0') torch.Size([16])
percent tensor([0.6960, 0.6630, 0.7795, 0.7678, 0.7904, 0.7554, 0.7050, 0.8233, 0.6618,
        0.7567, 0.6857, 0.7179, 0.6796, 0.6797, 0.7194, 0.7713],
       device='cuda:0') torch.Size([16])
Epoch: 7 | Batch_idx: 0 |  Loss: (1.3124) |  Loss2: (0.0000) | Acc: (51.00%) (66/128)
Epoch: 7 | Batch_idx: 10 |  Loss: (1.2374) |  Loss2: (0.0000) | Acc: (55.00%) (788/1408)
Epoch: 7 | Batch_idx: 20 |  Loss: (1.2071) |  Loss2: (0.0000) | Acc: (56.00%) (1518/2688)
Epoch: 7 | Batch_idx: 30 |  Loss: (1.2232) |  Loss2: (0.0000) | Acc: (55.00%) (2215/3968)
Epoch: 7 | Batch_idx: 40 |  Loss: (1.2137) |  Loss2: (0.0000) | Acc: (56.00%) (2948/5248)
Epoch: 7 | Batch_idx: 50 |  Loss: (1.2112) |  Loss2: (0.0000) | Acc: (56.00%) (3666/6528)
Epoch: 7 | Batch_idx: 60 |  Loss: (1.2117) |  Loss2: (0.0000) | Acc: (56.00%) (4386/7808)
Epoch: 7 | Batch_idx: 70 |  Loss: (1.2168) |  Loss2: (0.0000) | Acc: (55.00%) (5057/9088)
Epoch: 7 | Batch_idx: 80 |  Loss: (1.2150) |  Loss2: (0.0000) | Acc: (55.00%) (5787/10368)
Epoch: 7 | Batch_idx: 90 |  Loss: (1.2167) |  Loss2: (0.0000) | Acc: (55.00%) (6471/11648)
Epoch: 7 | Batch_idx: 100 |  Loss: (1.2154) |  Loss2: (0.0000) | Acc: (55.00%) (7191/12928)
Epoch: 7 | Batch_idx: 110 |  Loss: (1.2118) |  Loss2: (0.0000) | Acc: (55.00%) (7900/14208)
Epoch: 7 | Batch_idx: 120 |  Loss: (1.2098) |  Loss2: (0.0000) | Acc: (55.00%) (8637/15488)
Epoch: 7 | Batch_idx: 130 |  Loss: (1.2040) |  Loss2: (0.0000) | Acc: (56.00%) (9416/16768)
Epoch: 7 | Batch_idx: 140 |  Loss: (1.1997) |  Loss2: (0.0000) | Acc: (56.00%) (10157/18048)
Epoch: 7 | Batch_idx: 150 |  Loss: (1.1976) |  Loss2: (0.0000) | Acc: (56.00%) (10908/19328)
Epoch: 7 | Batch_idx: 160 |  Loss: (1.1967) |  Loss2: (0.0000) | Acc: (56.00%) (11654/20608)
Epoch: 7 | Batch_idx: 170 |  Loss: (1.1969) |  Loss2: (0.0000) | Acc: (56.00%) (12393/21888)
Epoch: 7 | Batch_idx: 180 |  Loss: (1.1951) |  Loss2: (0.0000) | Acc: (56.00%) (13143/23168)
Epoch: 7 | Batch_idx: 190 |  Loss: (1.1970) |  Loss2: (0.0000) | Acc: (56.00%) (13862/24448)
Epoch: 7 | Batch_idx: 200 |  Loss: (1.1973) |  Loss2: (0.0000) | Acc: (56.00%) (14579/25728)
Epoch: 7 | Batch_idx: 210 |  Loss: (1.1975) |  Loss2: (0.0000) | Acc: (56.00%) (15288/27008)
Epoch: 7 | Batch_idx: 220 |  Loss: (1.1955) |  Loss2: (0.0000) | Acc: (56.00%) (16039/28288)
Epoch: 7 | Batch_idx: 230 |  Loss: (1.1963) |  Loss2: (0.0000) | Acc: (56.00%) (16745/29568)
Epoch: 7 | Batch_idx: 240 |  Loss: (1.1959) |  Loss2: (0.0000) | Acc: (56.00%) (17461/30848)
Epoch: 7 | Batch_idx: 250 |  Loss: (1.1964) |  Loss2: (0.0000) | Acc: (56.00%) (18190/32128)
Epoch: 7 | Batch_idx: 260 |  Loss: (1.1952) |  Loss2: (0.0000) | Acc: (56.00%) (18942/33408)
Epoch: 7 | Batch_idx: 270 |  Loss: (1.1934) |  Loss2: (0.0000) | Acc: (56.00%) (19692/34688)
Epoch: 7 | Batch_idx: 280 |  Loss: (1.1920) |  Loss2: (0.0000) | Acc: (56.00%) (20453/35968)
Epoch: 7 | Batch_idx: 290 |  Loss: (1.1924) |  Loss2: (0.0000) | Acc: (56.00%) (21173/37248)
Epoch: 7 | Batch_idx: 300 |  Loss: (1.1923) |  Loss2: (0.0000) | Acc: (56.00%) (21895/38528)
Epoch: 7 | Batch_idx: 310 |  Loss: (1.1930) |  Loss2: (0.0000) | Acc: (56.00%) (22593/39808)
Epoch: 7 | Batch_idx: 320 |  Loss: (1.1941) |  Loss2: (0.0000) | Acc: (56.00%) (23300/41088)
Epoch: 7 | Batch_idx: 330 |  Loss: (1.1937) |  Loss2: (0.0000) | Acc: (56.00%) (24047/42368)
Epoch: 7 | Batch_idx: 340 |  Loss: (1.1939) |  Loss2: (0.0000) | Acc: (56.00%) (24771/43648)
Epoch: 7 | Batch_idx: 350 |  Loss: (1.1926) |  Loss2: (0.0000) | Acc: (56.00%) (25526/44928)
Epoch: 7 | Batch_idx: 360 |  Loss: (1.1935) |  Loss2: (0.0000) | Acc: (56.00%) (26241/46208)
Epoch: 7 | Batch_idx: 370 |  Loss: (1.1926) |  Loss2: (0.0000) | Acc: (56.00%) (26987/47488)
Epoch: 7 | Batch_idx: 380 |  Loss: (1.1917) |  Loss2: (0.0000) | Acc: (56.00%) (27722/48768)
Epoch: 7 | Batch_idx: 390 |  Loss: (1.1915) |  Loss2: (0.0000) | Acc: (56.00%) (28396/50000)
# TEST : Loss: (1.1835) | Acc: (57.00%) (5736/10000)
percent tensor([0.5084, 0.5138, 0.5084, 0.5072, 0.5093, 0.5066, 0.5131, 0.5104, 0.5124,
        0.5114, 0.5114, 0.5102, 0.5098, 0.5141, 0.5100, 0.5086],
       device='cuda:0') torch.Size([16])
percent tensor([0.5115, 0.5114, 0.5004, 0.5199, 0.5046, 0.5198, 0.5070, 0.5104, 0.5088,
        0.5094, 0.5105, 0.5024, 0.5093, 0.5172, 0.5147, 0.5173],
       device='cuda:0') torch.Size([16])
percent tensor([0.4688, 0.4792, 0.4635, 0.4601, 0.4669, 0.4656, 0.4753, 0.4654, 0.4739,
        0.4682, 0.4755, 0.4643, 0.4719, 0.4844, 0.4696, 0.4667],
       device='cuda:0') torch.Size([16])
percent tensor([0.5263, 0.5175, 0.5045, 0.5207, 0.5096, 0.5339, 0.5124, 0.5128, 0.5155,
        0.5148, 0.5194, 0.5050, 0.5225, 0.5177, 0.5231, 0.5276],
       device='cuda:0') torch.Size([16])
percent tensor([0.5578, 0.5484, 0.5036, 0.5160, 0.5043, 0.5599, 0.5300, 0.5105, 0.5510,
        0.5362, 0.5542, 0.5072, 0.5610, 0.5588, 0.5384, 0.5536],
       device='cuda:0') torch.Size([16])
percent tensor([0.5259, 0.5274, 0.5475, 0.5405, 0.5416, 0.5285, 0.5303, 0.5547, 0.5305,
        0.5303, 0.5266, 0.5377, 0.5244, 0.5263, 0.5314, 0.5281],
       device='cuda:0') torch.Size([16])
percent tensor([0.4452, 0.4798, 0.5888, 0.5506, 0.5888, 0.4396, 0.5223, 0.6385, 0.4707,
        0.5275, 0.4625, 0.5495, 0.4300, 0.4552, 0.5214, 0.4814],
       device='cuda:0') torch.Size([16])
percent tensor([0.7429, 0.7025, 0.8337, 0.8248, 0.8401, 0.8173, 0.7496, 0.8746, 0.7013,
        0.8016, 0.7310, 0.7679, 0.7255, 0.7236, 0.7652, 0.8284],
       device='cuda:0') torch.Size([16])
Epoch: 8 | Batch_idx: 0 |  Loss: (1.1963) |  Loss2: (0.0000) | Acc: (61.00%) (79/128)
Epoch: 8 | Batch_idx: 10 |  Loss: (1.2721) |  Loss2: (0.0000) | Acc: (54.00%) (762/1408)
Epoch: 8 | Batch_idx: 20 |  Loss: (1.2213) |  Loss2: (0.0000) | Acc: (56.00%) (1519/2688)
Epoch: 8 | Batch_idx: 30 |  Loss: (1.2131) |  Loss2: (0.0000) | Acc: (56.00%) (2247/3968)
Epoch: 8 | Batch_idx: 40 |  Loss: (1.2048) |  Loss2: (0.0000) | Acc: (56.00%) (2970/5248)
Epoch: 8 | Batch_idx: 50 |  Loss: (1.1881) |  Loss2: (0.0000) | Acc: (57.00%) (3738/6528)
Epoch: 8 | Batch_idx: 60 |  Loss: (1.1828) |  Loss2: (0.0000) | Acc: (57.00%) (4464/7808)
Epoch: 8 | Batch_idx: 70 |  Loss: (1.1871) |  Loss2: (0.0000) | Acc: (56.00%) (5180/9088)
Epoch: 8 | Batch_idx: 80 |  Loss: (1.1837) |  Loss2: (0.0000) | Acc: (57.00%) (5941/10368)
Epoch: 8 | Batch_idx: 90 |  Loss: (1.1844) |  Loss2: (0.0000) | Acc: (57.00%) (6645/11648)
Epoch: 8 | Batch_idx: 100 |  Loss: (1.1899) |  Loss2: (0.0000) | Acc: (56.00%) (7334/12928)
Epoch: 8 | Batch_idx: 110 |  Loss: (1.1899) |  Loss2: (0.0000) | Acc: (56.00%) (8078/14208)
Epoch: 8 | Batch_idx: 120 |  Loss: (1.1906) |  Loss2: (0.0000) | Acc: (56.00%) (8809/15488)
Epoch: 8 | Batch_idx: 130 |  Loss: (1.1919) |  Loss2: (0.0000) | Acc: (56.00%) (9534/16768)
Epoch: 8 | Batch_idx: 140 |  Loss: (1.1940) |  Loss2: (0.0000) | Acc: (56.00%) (10251/18048)
Epoch: 8 | Batch_idx: 150 |  Loss: (1.1970) |  Loss2: (0.0000) | Acc: (56.00%) (10959/19328)
Epoch: 8 | Batch_idx: 160 |  Loss: (1.1963) |  Loss2: (0.0000) | Acc: (56.00%) (11698/20608)
Epoch: 8 | Batch_idx: 170 |  Loss: (1.1930) |  Loss2: (0.0000) | Acc: (57.00%) (12485/21888)
Epoch: 8 | Batch_idx: 180 |  Loss: (1.1925) |  Loss2: (0.0000) | Acc: (56.00%) (13205/23168)
Epoch: 8 | Batch_idx: 190 |  Loss: (1.1901) |  Loss2: (0.0000) | Acc: (57.00%) (13964/24448)
Epoch: 8 | Batch_idx: 200 |  Loss: (1.1886) |  Loss2: (0.0000) | Acc: (57.00%) (14720/25728)
Epoch: 8 | Batch_idx: 210 |  Loss: (1.1866) |  Loss2: (0.0000) | Acc: (57.00%) (15469/27008)
Epoch: 8 | Batch_idx: 220 |  Loss: (1.1845) |  Loss2: (0.0000) | Acc: (57.00%) (16229/28288)
Epoch: 8 | Batch_idx: 230 |  Loss: (1.1854) |  Loss2: (0.0000) | Acc: (57.00%) (16947/29568)
Epoch: 8 | Batch_idx: 240 |  Loss: (1.1859) |  Loss2: (0.0000) | Acc: (57.00%) (17684/30848)
Epoch: 8 | Batch_idx: 250 |  Loss: (1.1866) |  Loss2: (0.0000) | Acc: (57.00%) (18416/32128)
Epoch: 8 | Batch_idx: 260 |  Loss: (1.1876) |  Loss2: (0.0000) | Acc: (57.00%) (19122/33408)
Epoch: 8 | Batch_idx: 270 |  Loss: (1.1867) |  Loss2: (0.0000) | Acc: (57.00%) (19833/34688)
Epoch: 8 | Batch_idx: 280 |  Loss: (1.1865) |  Loss2: (0.0000) | Acc: (57.00%) (20560/35968)
Epoch: 8 | Batch_idx: 290 |  Loss: (1.1859) |  Loss2: (0.0000) | Acc: (57.00%) (21296/37248)
Epoch: 8 | Batch_idx: 300 |  Loss: (1.1877) |  Loss2: (0.0000) | Acc: (57.00%) (21982/38528)
Epoch: 8 | Batch_idx: 310 |  Loss: (1.1860) |  Loss2: (0.0000) | Acc: (57.00%) (22735/39808)
Epoch: 8 | Batch_idx: 320 |  Loss: (1.1843) |  Loss2: (0.0000) | Acc: (57.00%) (23479/41088)
Epoch: 8 | Batch_idx: 330 |  Loss: (1.1843) |  Loss2: (0.0000) | Acc: (57.00%) (24217/42368)
Epoch: 8 | Batch_idx: 340 |  Loss: (1.1839) |  Loss2: (0.0000) | Acc: (57.00%) (24960/43648)
Epoch: 8 | Batch_idx: 350 |  Loss: (1.1831) |  Loss2: (0.0000) | Acc: (57.00%) (25694/44928)
Epoch: 8 | Batch_idx: 360 |  Loss: (1.1832) |  Loss2: (0.0000) | Acc: (57.00%) (26411/46208)
Epoch: 8 | Batch_idx: 370 |  Loss: (1.1827) |  Loss2: (0.0000) | Acc: (57.00%) (27151/47488)
Epoch: 8 | Batch_idx: 380 |  Loss: (1.1827) |  Loss2: (0.0000) | Acc: (57.00%) (27912/48768)
Epoch: 8 | Batch_idx: 390 |  Loss: (1.1817) |  Loss2: (0.0000) | Acc: (57.00%) (28623/50000)
# TEST : Loss: (1.1720) | Acc: (57.00%) (5758/10000)
percent tensor([0.5087, 0.5138, 0.5085, 0.5074, 0.5094, 0.5075, 0.5131, 0.5104, 0.5124,
        0.5114, 0.5114, 0.5102, 0.5099, 0.5141, 0.5103, 0.5088],
       device='cuda:0') torch.Size([16])
percent tensor([0.5122, 0.5125, 0.4979, 0.5211, 0.5033, 0.5213, 0.5066, 0.5101, 0.5090,
        0.5097, 0.5113, 0.5003, 0.5099, 0.5189, 0.5158, 0.5189],
       device='cuda:0') torch.Size([16])
percent tensor([0.4673, 0.4807, 0.4582, 0.4543, 0.4645, 0.4644, 0.4758, 0.4615, 0.4739,
        0.4663, 0.4757, 0.4606, 0.4708, 0.4862, 0.4692, 0.4651],
       device='cuda:0') torch.Size([16])
percent tensor([0.5303, 0.5205, 0.5088, 0.5261, 0.5148, 0.5390, 0.5160, 0.5176, 0.5194,
        0.5179, 0.5222, 0.5087, 0.5257, 0.5206, 0.5269, 0.5318],
       device='cuda:0') torch.Size([16])
percent tensor([0.5596, 0.5490, 0.5073, 0.5155, 0.5089, 0.5629, 0.5309, 0.5101, 0.5552,
        0.5360, 0.5549, 0.5084, 0.5633, 0.5631, 0.5353, 0.5536],
       device='cuda:0') torch.Size([16])
percent tensor([0.5296, 0.5320, 0.5613, 0.5512, 0.5518, 0.5346, 0.5360, 0.5683, 0.5380,
        0.5351, 0.5309, 0.5475, 0.5277, 0.5313, 0.5366, 0.5323],
       device='cuda:0') torch.Size([16])
percent tensor([0.4374, 0.4720, 0.5991, 0.5586, 0.5930, 0.4369, 0.5193, 0.6528, 0.4670,
        0.5225, 0.4557, 0.5532, 0.4205, 0.4471, 0.5208, 0.4807],
       device='cuda:0') torch.Size([16])
percent tensor([0.7657, 0.7190, 0.8600, 0.8533, 0.8649, 0.8480, 0.7687, 0.8969, 0.7184,
        0.8176, 0.7481, 0.7959, 0.7469, 0.7406, 0.7869, 0.8534],
       device='cuda:0') torch.Size([16])
Epoch: 9 | Batch_idx: 0 |  Loss: (1.1813) |  Loss2: (0.0000) | Acc: (60.00%) (77/128)
Epoch: 9 | Batch_idx: 10 |  Loss: (1.1538) |  Loss2: (0.0000) | Acc: (58.00%) (824/1408)
Epoch: 9 | Batch_idx: 20 |  Loss: (1.1572) |  Loss2: (0.0000) | Acc: (57.00%) (1554/2688)
Epoch: 9 | Batch_idx: 30 |  Loss: (1.1750) |  Loss2: (0.0000) | Acc: (57.00%) (2270/3968)
Epoch: 9 | Batch_idx: 40 |  Loss: (1.1707) |  Loss2: (0.0000) | Acc: (57.00%) (2995/5248)
Epoch: 9 | Batch_idx: 50 |  Loss: (1.1664) |  Loss2: (0.0000) | Acc: (57.00%) (3731/6528)
Epoch: 9 | Batch_idx: 60 |  Loss: (1.1677) |  Loss2: (0.0000) | Acc: (57.00%) (4467/7808)
Epoch: 9 | Batch_idx: 70 |  Loss: (1.1640) |  Loss2: (0.0000) | Acc: (57.00%) (5221/9088)
Epoch: 9 | Batch_idx: 80 |  Loss: (1.1600) |  Loss2: (0.0000) | Acc: (57.00%) (5978/10368)
Epoch: 9 | Batch_idx: 90 |  Loss: (1.1676) |  Loss2: (0.0000) | Acc: (57.00%) (6700/11648)
Epoch: 9 | Batch_idx: 100 |  Loss: (1.1670) |  Loss2: (0.0000) | Acc: (57.00%) (7455/12928)
Epoch: 9 | Batch_idx: 110 |  Loss: (1.1663) |  Loss2: (0.0000) | Acc: (57.00%) (8193/14208)
Epoch: 9 | Batch_idx: 120 |  Loss: (1.1688) |  Loss2: (0.0000) | Acc: (57.00%) (8903/15488)
Epoch: 9 | Batch_idx: 130 |  Loss: (1.1705) |  Loss2: (0.0000) | Acc: (57.00%) (9624/16768)
Epoch: 9 | Batch_idx: 140 |  Loss: (1.1695) |  Loss2: (0.0000) | Acc: (57.00%) (10366/18048)
Epoch: 9 | Batch_idx: 150 |  Loss: (1.1688) |  Loss2: (0.0000) | Acc: (57.00%) (11112/19328)
Epoch: 9 | Batch_idx: 160 |  Loss: (1.1718) |  Loss2: (0.0000) | Acc: (57.00%) (11801/20608)
Epoch: 9 | Batch_idx: 170 |  Loss: (1.1706) |  Loss2: (0.0000) | Acc: (57.00%) (12541/21888)
Epoch: 9 | Batch_idx: 180 |  Loss: (1.1722) |  Loss2: (0.0000) | Acc: (57.00%) (13261/23168)
Epoch: 9 | Batch_idx: 190 |  Loss: (1.1724) |  Loss2: (0.0000) | Acc: (57.00%) (14001/24448)
Epoch: 9 | Batch_idx: 200 |  Loss: (1.1703) |  Loss2: (0.0000) | Acc: (57.00%) (14763/25728)
Epoch: 9 | Batch_idx: 210 |  Loss: (1.1706) |  Loss2: (0.0000) | Acc: (57.00%) (15510/27008)
Epoch: 9 | Batch_idx: 220 |  Loss: (1.1699) |  Loss2: (0.0000) | Acc: (57.00%) (16227/28288)
Epoch: 9 | Batch_idx: 230 |  Loss: (1.1707) |  Loss2: (0.0000) | Acc: (57.00%) (16973/29568)
Epoch: 9 | Batch_idx: 240 |  Loss: (1.1712) |  Loss2: (0.0000) | Acc: (57.00%) (17705/30848)
Epoch: 9 | Batch_idx: 250 |  Loss: (1.1699) |  Loss2: (0.0000) | Acc: (57.00%) (18431/32128)
Epoch: 9 | Batch_idx: 260 |  Loss: (1.1713) |  Loss2: (0.0000) | Acc: (57.00%) (19151/33408)
Epoch: 9 | Batch_idx: 270 |  Loss: (1.1710) |  Loss2: (0.0000) | Acc: (57.00%) (19906/34688)
Epoch: 9 | Batch_idx: 280 |  Loss: (1.1714) |  Loss2: (0.0000) | Acc: (57.00%) (20622/35968)
Epoch: 9 | Batch_idx: 290 |  Loss: (1.1717) |  Loss2: (0.0000) | Acc: (57.00%) (21341/37248)
Epoch: 9 | Batch_idx: 300 |  Loss: (1.1721) |  Loss2: (0.0000) | Acc: (57.00%) (22046/38528)
Epoch: 9 | Batch_idx: 310 |  Loss: (1.1721) |  Loss2: (0.0000) | Acc: (57.00%) (22793/39808)
Epoch: 9 | Batch_idx: 320 |  Loss: (1.1730) |  Loss2: (0.0000) | Acc: (57.00%) (23548/41088)
Epoch: 9 | Batch_idx: 330 |  Loss: (1.1737) |  Loss2: (0.0000) | Acc: (57.00%) (24278/42368)
Epoch: 9 | Batch_idx: 340 |  Loss: (1.1732) |  Loss2: (0.0000) | Acc: (57.00%) (25021/43648)
Epoch: 9 | Batch_idx: 350 |  Loss: (1.1717) |  Loss2: (0.0000) | Acc: (57.00%) (25785/44928)
Epoch: 9 | Batch_idx: 360 |  Loss: (1.1712) |  Loss2: (0.0000) | Acc: (57.00%) (26536/46208)
Epoch: 9 | Batch_idx: 370 |  Loss: (1.1712) |  Loss2: (0.0000) | Acc: (57.00%) (27291/47488)
Epoch: 9 | Batch_idx: 380 |  Loss: (1.1714) |  Loss2: (0.0000) | Acc: (57.00%) (28023/48768)
Epoch: 9 | Batch_idx: 390 |  Loss: (1.1714) |  Loss2: (0.0000) | Acc: (57.00%) (28744/50000)
# TEST : Loss: (1.1677) | Acc: (57.00%) (5776/10000)
percent tensor([0.5103, 0.5159, 0.5098, 0.5087, 0.5109, 0.5092, 0.5150, 0.5120, 0.5145,
        0.5130, 0.5133, 0.5115, 0.5115, 0.5163, 0.5122, 0.5104],
       device='cuda:0') torch.Size([16])
percent tensor([0.5129, 0.5134, 0.4960, 0.5217, 0.5023, 0.5226, 0.5066, 0.5098, 0.5093,
        0.5099, 0.5121, 0.4988, 0.5105, 0.5205, 0.5167, 0.5200],
       device='cuda:0') torch.Size([16])
percent tensor([0.4650, 0.4808, 0.4510, 0.4483, 0.4599, 0.4628, 0.4743, 0.4564, 0.4720,
        0.4629, 0.4745, 0.4549, 0.4686, 0.4869, 0.4680, 0.4630],
       device='cuda:0') torch.Size([16])
percent tensor([0.5329, 0.5225, 0.5107, 0.5292, 0.5175, 0.5428, 0.5181, 0.5203, 0.5219,
        0.5196, 0.5240, 0.5103, 0.5277, 0.5228, 0.5293, 0.5346],
       device='cuda:0') torch.Size([16])
percent tensor([0.5627, 0.5510, 0.5103, 0.5153, 0.5110, 0.5680, 0.5319, 0.5101, 0.5606,
        0.5371, 0.5581, 0.5097, 0.5669, 0.5688, 0.5338, 0.5567],
       device='cuda:0') torch.Size([16])
percent tensor([0.5321, 0.5352, 0.5748, 0.5616, 0.5617, 0.5400, 0.5404, 0.5808, 0.5442,
        0.5382, 0.5333, 0.5566, 0.5294, 0.5347, 0.5403, 0.5348],
       device='cuda:0') torch.Size([16])
percent tensor([0.4305, 0.4648, 0.6123, 0.5711, 0.6051, 0.4355, 0.5196, 0.6710, 0.4598,
        0.5199, 0.4468, 0.5595, 0.4097, 0.4379, 0.5216, 0.4813],
       device='cuda:0') torch.Size([16])
percent tensor([0.7824, 0.7307, 0.8796, 0.8724, 0.8826, 0.8694, 0.7876, 0.9149, 0.7285,
        0.8315, 0.7589, 0.8152, 0.7604, 0.7523, 0.8072, 0.8737],
       device='cuda:0') torch.Size([16])
True Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=128, out_features=16, bias=False)
False Linear(in_features=16, out_features=2, bias=False)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=128, out_features=16, bias=False)
False Linear(in_features=16, out_features=2, bias=False)
True Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=256, out_features=32, bias=False)
False Linear(in_features=32, out_features=2, bias=False)
True Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=256, out_features=32, bias=False)
False Linear(in_features=32, out_features=2, bias=False)
True Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=512, out_features=64, bias=False)
False Linear(in_features=64, out_features=2, bias=False)
True Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=512, out_features=64, bias=False)
False Linear(in_features=64, out_features=2, bias=False)
True Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1024, out_features=128, bias=False)
False Linear(in_features=128, out_features=2, bias=False)
True Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1024, out_features=128, bias=False)
False Linear(in_features=128, out_features=2, bias=False)
True Linear(in_features=512, out_features=10, bias=True)
Epoch: 10 | Batch_idx: 0 |  Loss: (1.3172) |  Loss2: (0.0000) | Acc: (54.00%) (70/128)
Epoch: 10 | Batch_idx: 10 |  Loss: (1.1735) |  Loss2: (0.0000) | Acc: (56.00%) (798/1408)
Epoch: 10 | Batch_idx: 20 |  Loss: (1.1778) |  Loss2: (0.0000) | Acc: (56.00%) (1529/2688)
Epoch: 10 | Batch_idx: 30 |  Loss: (1.1896) |  Loss2: (0.0000) | Acc: (56.00%) (2231/3968)
Epoch: 10 | Batch_idx: 40 |  Loss: (1.1873) |  Loss2: (0.0000) | Acc: (56.00%) (2961/5248)
Epoch: 10 | Batch_idx: 50 |  Loss: (1.1793) |  Loss2: (0.0000) | Acc: (56.00%) (3700/6528)
Epoch: 10 | Batch_idx: 60 |  Loss: (1.1744) |  Loss2: (0.0000) | Acc: (56.00%) (4444/7808)
Epoch: 10 | Batch_idx: 70 |  Loss: (1.1800) |  Loss2: (0.0000) | Acc: (56.00%) (5174/9088)
Epoch: 10 | Batch_idx: 80 |  Loss: (1.1784) |  Loss2: (0.0000) | Acc: (57.00%) (5922/10368)
Epoch: 10 | Batch_idx: 90 |  Loss: (1.1778) |  Loss2: (0.0000) | Acc: (57.00%) (6654/11648)
Epoch: 10 | Batch_idx: 100 |  Loss: (1.1754) |  Loss2: (0.0000) | Acc: (57.00%) (7390/12928)
Epoch: 10 | Batch_idx: 110 |  Loss: (1.1720) |  Loss2: (0.0000) | Acc: (57.00%) (8135/14208)
Epoch: 10 | Batch_idx: 120 |  Loss: (1.1673) |  Loss2: (0.0000) | Acc: (57.00%) (8897/15488)
Epoch: 10 | Batch_idx: 130 |  Loss: (1.1664) |  Loss2: (0.0000) | Acc: (57.00%) (9642/16768)
Epoch: 10 | Batch_idx: 140 |  Loss: (1.1641) |  Loss2: (0.0000) | Acc: (57.00%) (10398/18048)
Epoch: 10 | Batch_idx: 150 |  Loss: (1.1626) |  Loss2: (0.0000) | Acc: (57.00%) (11155/19328)
Epoch: 10 | Batch_idx: 160 |  Loss: (1.1609) |  Loss2: (0.0000) | Acc: (57.00%) (11908/20608)
Epoch: 10 | Batch_idx: 170 |  Loss: (1.1586) |  Loss2: (0.0000) | Acc: (57.00%) (12657/21888)
Epoch: 10 | Batch_idx: 180 |  Loss: (1.1557) |  Loss2: (0.0000) | Acc: (57.00%) (13436/23168)
Epoch: 10 | Batch_idx: 190 |  Loss: (1.1550) |  Loss2: (0.0000) | Acc: (58.00%) (14207/24448)
Epoch: 10 | Batch_idx: 200 |  Loss: (1.1517) |  Loss2: (0.0000) | Acc: (58.00%) (14997/25728)
Epoch: 10 | Batch_idx: 210 |  Loss: (1.1500) |  Loss2: (0.0000) | Acc: (58.00%) (15753/27008)
Epoch: 10 | Batch_idx: 220 |  Loss: (1.1492) |  Loss2: (0.0000) | Acc: (58.00%) (16500/28288)
Epoch: 10 | Batch_idx: 230 |  Loss: (1.1447) |  Loss2: (0.0000) | Acc: (58.00%) (17298/29568)
Epoch: 10 | Batch_idx: 240 |  Loss: (1.1412) |  Loss2: (0.0000) | Acc: (58.00%) (18089/30848)
Epoch: 10 | Batch_idx: 250 |  Loss: (1.1366) |  Loss2: (0.0000) | Acc: (58.00%) (18900/32128)
Epoch: 10 | Batch_idx: 260 |  Loss: (1.1354) |  Loss2: (0.0000) | Acc: (58.00%) (19646/33408)
Epoch: 10 | Batch_idx: 270 |  Loss: (1.1339) |  Loss2: (0.0000) | Acc: (58.00%) (20414/34688)
Epoch: 10 | Batch_idx: 280 |  Loss: (1.1330) |  Loss2: (0.0000) | Acc: (58.00%) (21191/35968)
Epoch: 10 | Batch_idx: 290 |  Loss: (1.1315) |  Loss2: (0.0000) | Acc: (58.00%) (21971/37248)
Epoch: 10 | Batch_idx: 300 |  Loss: (1.1316) |  Loss2: (0.0000) | Acc: (59.00%) (22740/38528)
Epoch: 10 | Batch_idx: 310 |  Loss: (1.1299) |  Loss2: (0.0000) | Acc: (59.00%) (23519/39808)
Epoch: 10 | Batch_idx: 320 |  Loss: (1.1280) |  Loss2: (0.0000) | Acc: (59.00%) (24320/41088)
Epoch: 10 | Batch_idx: 330 |  Loss: (1.1272) |  Loss2: (0.0000) | Acc: (59.00%) (25074/42368)
Epoch: 10 | Batch_idx: 340 |  Loss: (1.1252) |  Loss2: (0.0000) | Acc: (59.00%) (25854/43648)
Epoch: 10 | Batch_idx: 350 |  Loss: (1.1221) |  Loss2: (0.0000) | Acc: (59.00%) (26679/44928)
Epoch: 10 | Batch_idx: 360 |  Loss: (1.1206) |  Loss2: (0.0000) | Acc: (59.00%) (27475/46208)
Epoch: 10 | Batch_idx: 370 |  Loss: (1.1193) |  Loss2: (0.0000) | Acc: (59.00%) (28257/47488)
Epoch: 10 | Batch_idx: 380 |  Loss: (1.1170) |  Loss2: (0.0000) | Acc: (59.00%) (29088/48768)
Epoch: 10 | Batch_idx: 390 |  Loss: (1.1149) |  Loss2: (0.0000) | Acc: (59.00%) (29843/50000)
=> saving checkpoint 'drive/app/torch/save_Routing_Gate_2/checkpoint_010.pth.tar'
# TEST : Loss: (1.0984) | Acc: (60.00%) (6025/10000)
percent tensor([0.5104, 0.5150, 0.5116, 0.5085, 0.5120, 0.5082, 0.5154, 0.5119, 0.5147,
        0.5132, 0.5130, 0.5135, 0.5118, 0.5150, 0.5113, 0.5098],
       device='cuda:0') torch.Size([16])
percent tensor([0.5123, 0.5126, 0.4948, 0.5172, 0.5005, 0.5228, 0.5057, 0.5078, 0.5089,
        0.5074, 0.5113, 0.4961, 0.5088, 0.5222, 0.5150, 0.5186],
       device='cuda:0') torch.Size([16])
percent tensor([0.4638, 0.4816, 0.4572, 0.4504, 0.4626, 0.4594, 0.4772, 0.4584, 0.4721,
        0.4667, 0.4745, 0.4606, 0.4690, 0.4845, 0.4693, 0.4629],
       device='cuda:0') torch.Size([16])
percent tensor([0.5306, 0.5225, 0.5136, 0.5294, 0.5202, 0.5425, 0.5178, 0.5205, 0.5194,
        0.5204, 0.5239, 0.5128, 0.5262, 0.5220, 0.5282, 0.5334],
       device='cuda:0') torch.Size([16])
percent tensor([0.5448, 0.5541, 0.5019, 0.5157, 0.5133, 0.5586, 0.5338, 0.5088, 0.5468,
        0.5395, 0.5498, 0.5060, 0.5571, 0.5694, 0.5273, 0.5557],
       device='cuda:0') torch.Size([16])
percent tensor([0.5359, 0.5387, 0.5616, 0.5577, 0.5572, 0.5367, 0.5428, 0.5695, 0.5489,
        0.5359, 0.5372, 0.5474, 0.5338, 0.5385, 0.5411, 0.5358],
       device='cuda:0') torch.Size([16])
percent tensor([0.4532, 0.4763, 0.5937, 0.5574, 0.5868, 0.4258, 0.5124, 0.6545, 0.4770,
        0.5105, 0.4529, 0.5413, 0.4255, 0.4507, 0.5248, 0.4816],
       device='cuda:0') torch.Size([16])
percent tensor([0.8054, 0.7506, 0.8745, 0.8611, 0.8486, 0.8402, 0.7848, 0.9008, 0.7485,
        0.8170, 0.7702, 0.8269, 0.7608, 0.7440, 0.8380, 0.8650],
       device='cuda:0') torch.Size([16])
Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 3, 3, 3]) tensor(169.8154, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(772.4244, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(773.4403, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([128, 64, 3, 3]) tensor(1533.1578, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([128, 64, 1, 1]) tensor(509.7171, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([128, 128, 3, 3]) tensor(2167.2104, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([256, 128, 3, 3]) tensor(4325.5254, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([256, 128, 1, 1]) tensor(1442.8411, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([256, 256, 3, 3]) tensor(6114.4546, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([512, 256, 3, 3]) tensor(12232.4365, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([512, 256, 1, 1]) tensor(4076.3533, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([512, 512, 3, 3]) tensor(17275.3730, device='cuda:0', grad_fn=<NormBackward0>)
Epoch: 11 | Batch_idx: 0 |  Loss: (1.0494) |  Loss2: (0.0000) | Acc: (57.00%) (73/128)
Epoch: 11 | Batch_idx: 10 |  Loss: (1.0595) |  Loss2: (0.0000) | Acc: (61.00%) (864/1408)
Epoch: 11 | Batch_idx: 20 |  Loss: (1.0491) |  Loss2: (0.0000) | Acc: (61.00%) (1643/2688)
Epoch: 11 | Batch_idx: 30 |  Loss: (1.0475) |  Loss2: (0.0000) | Acc: (61.00%) (2450/3968)
Epoch: 11 | Batch_idx: 40 |  Loss: (1.0439) |  Loss2: (0.0000) | Acc: (61.00%) (3250/5248)
Epoch: 11 | Batch_idx: 50 |  Loss: (1.0454) |  Loss2: (0.0000) | Acc: (61.00%) (4037/6528)
Epoch: 11 | Batch_idx: 60 |  Loss: (1.0363) |  Loss2: (0.0000) | Acc: (62.00%) (4868/7808)
Epoch: 11 | Batch_idx: 70 |  Loss: (1.0343) |  Loss2: (0.0000) | Acc: (62.00%) (5689/9088)
Epoch: 11 | Batch_idx: 80 |  Loss: (1.0340) |  Loss2: (0.0000) | Acc: (62.00%) (6506/10368)
Epoch: 11 | Batch_idx: 90 |  Loss: (1.0349) |  Loss2: (0.0000) | Acc: (62.00%) (7308/11648)
Epoch: 11 | Batch_idx: 100 |  Loss: (1.0306) |  Loss2: (0.0000) | Acc: (62.00%) (8143/12928)
Epoch: 11 | Batch_idx: 110 |  Loss: (1.0290) |  Loss2: (0.0000) | Acc: (63.00%) (8959/14208)
Epoch: 11 | Batch_idx: 120 |  Loss: (1.0343) |  Loss2: (0.0000) | Acc: (62.00%) (9739/15488)
Epoch: 11 | Batch_idx: 130 |  Loss: (1.0343) |  Loss2: (0.0000) | Acc: (62.00%) (10536/16768)
Epoch: 11 | Batch_idx: 140 |  Loss: (1.0297) |  Loss2: (0.0000) | Acc: (63.00%) (11380/18048)
Epoch: 11 | Batch_idx: 150 |  Loss: (1.0305) |  Loss2: (0.0000) | Acc: (63.00%) (12181/19328)
Epoch: 11 | Batch_idx: 160 |  Loss: (1.0307) |  Loss2: (0.0000) | Acc: (62.00%) (12979/20608)
Epoch: 11 | Batch_idx: 170 |  Loss: (1.0299) |  Loss2: (0.0000) | Acc: (63.00%) (13805/21888)
Epoch: 11 | Batch_idx: 180 |  Loss: (1.0301) |  Loss2: (0.0000) | Acc: (63.00%) (14604/23168)
Epoch: 11 | Batch_idx: 190 |  Loss: (1.0295) |  Loss2: (0.0000) | Acc: (63.00%) (15408/24448)
Epoch: 11 | Batch_idx: 200 |  Loss: (1.0300) |  Loss2: (0.0000) | Acc: (63.00%) (16215/25728)
Epoch: 11 | Batch_idx: 210 |  Loss: (1.0280) |  Loss2: (0.0000) | Acc: (63.00%) (17058/27008)
Epoch: 11 | Batch_idx: 220 |  Loss: (1.0266) |  Loss2: (0.0000) | Acc: (63.00%) (17867/28288)
Epoch: 11 | Batch_idx: 230 |  Loss: (1.0260) |  Loss2: (0.0000) | Acc: (63.00%) (18682/29568)
Epoch: 11 | Batch_idx: 240 |  Loss: (1.0246) |  Loss2: (0.0000) | Acc: (63.00%) (19481/30848)
Epoch: 11 | Batch_idx: 250 |  Loss: (1.0234) |  Loss2: (0.0000) | Acc: (63.00%) (20310/32128)
Epoch: 11 | Batch_idx: 260 |  Loss: (1.0232) |  Loss2: (0.0000) | Acc: (63.00%) (21100/33408)
Epoch: 11 | Batch_idx: 270 |  Loss: (1.0215) |  Loss2: (0.0000) | Acc: (63.00%) (21923/34688)
Epoch: 11 | Batch_idx: 280 |  Loss: (1.0236) |  Loss2: (0.0000) | Acc: (63.00%) (22722/35968)
Epoch: 11 | Batch_idx: 290 |  Loss: (1.0230) |  Loss2: (0.0000) | Acc: (63.00%) (23547/37248)
Epoch: 11 | Batch_idx: 300 |  Loss: (1.0216) |  Loss2: (0.0000) | Acc: (63.00%) (24373/38528)
Epoch: 11 | Batch_idx: 310 |  Loss: (1.0207) |  Loss2: (0.0000) | Acc: (63.00%) (25189/39808)
Epoch: 11 | Batch_idx: 320 |  Loss: (1.0188) |  Loss2: (0.0000) | Acc: (63.00%) (26020/41088)
Epoch: 11 | Batch_idx: 330 |  Loss: (1.0184) |  Loss2: (0.0000) | Acc: (63.00%) (26849/42368)
Epoch: 11 | Batch_idx: 340 |  Loss: (1.0159) |  Loss2: (0.0000) | Acc: (63.00%) (27698/43648)
Epoch: 11 | Batch_idx: 350 |  Loss: (1.0145) |  Loss2: (0.0000) | Acc: (63.00%) (28539/44928)
Epoch: 11 | Batch_idx: 360 |  Loss: (1.0135) |  Loss2: (0.0000) | Acc: (63.00%) (29374/46208)
Epoch: 11 | Batch_idx: 370 |  Loss: (1.0122) |  Loss2: (0.0000) | Acc: (63.00%) (30214/47488)
Epoch: 11 | Batch_idx: 380 |  Loss: (1.0108) |  Loss2: (0.0000) | Acc: (63.00%) (31065/48768)
Epoch: 11 | Batch_idx: 390 |  Loss: (1.0103) |  Loss2: (0.0000) | Acc: (63.00%) (31869/50000)
# TEST : Loss: (0.9815) | Acc: (64.00%) (6449/10000)
percent tensor([0.5104, 0.5152, 0.5113, 0.5089, 0.5119, 0.5085, 0.5155, 0.5119, 0.5143,
        0.5133, 0.5129, 0.5132, 0.5118, 0.5152, 0.5113, 0.5099],
       device='cuda:0') torch.Size([16])
percent tensor([0.5133, 0.5133, 0.4985, 0.5188, 0.5040, 0.5237, 0.5077, 0.5097, 0.5095,
        0.5088, 0.5111, 0.4987, 0.5091, 0.5228, 0.5155, 0.5184],
       device='cuda:0') torch.Size([16])
percent tensor([0.4624, 0.4811, 0.4576, 0.4495, 0.4615, 0.4553, 0.4774, 0.4586, 0.4738,
        0.4668, 0.4729, 0.4619, 0.4689, 0.4849, 0.4677, 0.4611],
       device='cuda:0') torch.Size([16])
percent tensor([0.5299, 0.5233, 0.5173, 0.5295, 0.5224, 0.5435, 0.5195, 0.5220, 0.5212,
        0.5221, 0.5252, 0.5152, 0.5261, 0.5232, 0.5289, 0.5335],
       device='cuda:0') torch.Size([16])
percent tensor([0.5432, 0.5569, 0.5161, 0.5274, 0.5200, 0.5606, 0.5381, 0.5176, 0.5520,
        0.5416, 0.5479, 0.5158, 0.5596, 0.5732, 0.5277, 0.5568],
       device='cuda:0') torch.Size([16])
percent tensor([0.5399, 0.5391, 0.5660, 0.5665, 0.5652, 0.5424, 0.5438, 0.5707, 0.5450,
        0.5416, 0.5371, 0.5531, 0.5329, 0.5384, 0.5444, 0.5390],
       device='cuda:0') torch.Size([16])
percent tensor([0.4668, 0.4855, 0.5927, 0.5663, 0.5993, 0.4374, 0.5205, 0.6573, 0.4707,
        0.5283, 0.4655, 0.5664, 0.4273, 0.4547, 0.5370, 0.4859],
       device='cuda:0') torch.Size([16])
percent tensor([0.8156, 0.7618, 0.8701, 0.8756, 0.8619, 0.8570, 0.7753, 0.8902, 0.7355,
        0.8150, 0.7651, 0.8132, 0.7550, 0.7599, 0.8375, 0.8642],
       device='cuda:0') torch.Size([16])
Epoch: 12 | Batch_idx: 0 |  Loss: (0.9391) |  Loss2: (0.0000) | Acc: (66.00%) (85/128)
Epoch: 12 | Batch_idx: 10 |  Loss: (0.9757) |  Loss2: (0.0000) | Acc: (64.00%) (915/1408)
Epoch: 12 | Batch_idx: 20 |  Loss: (0.9651) |  Loss2: (0.0000) | Acc: (65.00%) (1753/2688)
Epoch: 12 | Batch_idx: 30 |  Loss: (0.9550) |  Loss2: (0.0000) | Acc: (65.00%) (2617/3968)
Epoch: 12 | Batch_idx: 40 |  Loss: (0.9623) |  Loss2: (0.0000) | Acc: (65.00%) (3445/5248)
Epoch: 12 | Batch_idx: 50 |  Loss: (0.9616) |  Loss2: (0.0000) | Acc: (65.00%) (4263/6528)
Epoch: 12 | Batch_idx: 60 |  Loss: (0.9542) |  Loss2: (0.0000) | Acc: (65.00%) (5140/7808)
Epoch: 12 | Batch_idx: 70 |  Loss: (0.9574) |  Loss2: (0.0000) | Acc: (65.00%) (5957/9088)
Epoch: 12 | Batch_idx: 80 |  Loss: (0.9531) |  Loss2: (0.0000) | Acc: (65.00%) (6828/10368)
Epoch: 12 | Batch_idx: 90 |  Loss: (0.9516) |  Loss2: (0.0000) | Acc: (65.00%) (7676/11648)
Epoch: 12 | Batch_idx: 100 |  Loss: (0.9494) |  Loss2: (0.0000) | Acc: (65.00%) (8521/12928)
Epoch: 12 | Batch_idx: 110 |  Loss: (0.9499) |  Loss2: (0.0000) | Acc: (65.00%) (9366/14208)
Epoch: 12 | Batch_idx: 120 |  Loss: (0.9533) |  Loss2: (0.0000) | Acc: (65.00%) (10197/15488)
Epoch: 12 | Batch_idx: 130 |  Loss: (0.9534) |  Loss2: (0.0000) | Acc: (65.00%) (11061/16768)
Epoch: 12 | Batch_idx: 140 |  Loss: (0.9539) |  Loss2: (0.0000) | Acc: (65.00%) (11907/18048)
Epoch: 12 | Batch_idx: 150 |  Loss: (0.9505) |  Loss2: (0.0000) | Acc: (66.00%) (12774/19328)
Epoch: 12 | Batch_idx: 160 |  Loss: (0.9492) |  Loss2: (0.0000) | Acc: (66.00%) (13654/20608)
Epoch: 12 | Batch_idx: 170 |  Loss: (0.9471) |  Loss2: (0.0000) | Acc: (66.00%) (14517/21888)
Epoch: 12 | Batch_idx: 180 |  Loss: (0.9469) |  Loss2: (0.0000) | Acc: (66.00%) (15375/23168)
Epoch: 12 | Batch_idx: 190 |  Loss: (0.9446) |  Loss2: (0.0000) | Acc: (66.00%) (16247/24448)
Epoch: 12 | Batch_idx: 200 |  Loss: (0.9456) |  Loss2: (0.0000) | Acc: (66.00%) (17068/25728)
Epoch: 12 | Batch_idx: 210 |  Loss: (0.9458) |  Loss2: (0.0000) | Acc: (66.00%) (17927/27008)
Epoch: 12 | Batch_idx: 220 |  Loss: (0.9461) |  Loss2: (0.0000) | Acc: (66.00%) (18777/28288)
Epoch: 12 | Batch_idx: 230 |  Loss: (0.9459) |  Loss2: (0.0000) | Acc: (66.00%) (19634/29568)
Epoch: 12 | Batch_idx: 240 |  Loss: (0.9460) |  Loss2: (0.0000) | Acc: (66.00%) (20489/30848)
Epoch: 12 | Batch_idx: 250 |  Loss: (0.9458) |  Loss2: (0.0000) | Acc: (66.00%) (21329/32128)
Epoch: 12 | Batch_idx: 260 |  Loss: (0.9452) |  Loss2: (0.0000) | Acc: (66.00%) (22210/33408)
Epoch: 12 | Batch_idx: 270 |  Loss: (0.9424) |  Loss2: (0.0000) | Acc: (66.00%) (23110/34688)
Epoch: 12 | Batch_idx: 280 |  Loss: (0.9415) |  Loss2: (0.0000) | Acc: (66.00%) (23975/35968)
Epoch: 12 | Batch_idx: 290 |  Loss: (0.9407) |  Loss2: (0.0000) | Acc: (66.00%) (24848/37248)
Epoch: 12 | Batch_idx: 300 |  Loss: (0.9397) |  Loss2: (0.0000) | Acc: (66.00%) (25723/38528)
Epoch: 12 | Batch_idx: 310 |  Loss: (0.9391) |  Loss2: (0.0000) | Acc: (66.00%) (26597/39808)
Epoch: 12 | Batch_idx: 320 |  Loss: (0.9387) |  Loss2: (0.0000) | Acc: (66.00%) (27451/41088)
Epoch: 12 | Batch_idx: 330 |  Loss: (0.9379) |  Loss2: (0.0000) | Acc: (66.00%) (28321/42368)
Epoch: 12 | Batch_idx: 340 |  Loss: (0.9372) |  Loss2: (0.0000) | Acc: (66.00%) (29188/43648)
Epoch: 12 | Batch_idx: 350 |  Loss: (0.9358) |  Loss2: (0.0000) | Acc: (66.00%) (30070/44928)
Epoch: 12 | Batch_idx: 360 |  Loss: (0.9353) |  Loss2: (0.0000) | Acc: (66.00%) (30943/46208)
Epoch: 12 | Batch_idx: 370 |  Loss: (0.9349) |  Loss2: (0.0000) | Acc: (66.00%) (31814/47488)
Epoch: 12 | Batch_idx: 380 |  Loss: (0.9340) |  Loss2: (0.0000) | Acc: (67.00%) (32677/48768)
Epoch: 12 | Batch_idx: 390 |  Loss: (0.9346) |  Loss2: (0.0000) | Acc: (66.00%) (33495/50000)
# TEST : Loss: (0.9789) | Acc: (64.00%) (6447/10000)
percent tensor([0.5104, 0.5151, 0.5114, 0.5082, 0.5117, 0.5079, 0.5154, 0.5112, 0.5140,
        0.5131, 0.5127, 0.5130, 0.5118, 0.5152, 0.5110, 0.5097],
       device='cuda:0') torch.Size([16])
percent tensor([0.5139, 0.5138, 0.4993, 0.5203, 0.5049, 0.5240, 0.5087, 0.5102, 0.5105,
        0.5099, 0.5115, 0.5010, 0.5098, 0.5236, 0.5159, 0.5187],
       device='cuda:0') torch.Size([16])
percent tensor([0.4612, 0.4801, 0.4587, 0.4477, 0.4609, 0.4529, 0.4763, 0.4587, 0.4714,
        0.4668, 0.4713, 0.4625, 0.4680, 0.4820, 0.4663, 0.4600],
       device='cuda:0') torch.Size([16])
percent tensor([0.5310, 0.5247, 0.5187, 0.5312, 0.5251, 0.5408, 0.5217, 0.5237, 0.5228,
        0.5246, 0.5261, 0.5179, 0.5275, 0.5253, 0.5285, 0.5337],
       device='cuda:0') torch.Size([16])
percent tensor([0.5452, 0.5524, 0.5087, 0.5177, 0.5172, 0.5535, 0.5361, 0.5107, 0.5527,
        0.5441, 0.5440, 0.5159, 0.5685, 0.5680, 0.5193, 0.5547],
       device='cuda:0') torch.Size([16])
percent tensor([0.5367, 0.5390, 0.5556, 0.5625, 0.5559, 0.5396, 0.5428, 0.5657, 0.5446,
        0.5377, 0.5374, 0.5465, 0.5336, 0.5437, 0.5427, 0.5380],
       device='cuda:0') torch.Size([16])
percent tensor([0.4687, 0.4962, 0.5835, 0.5795, 0.5810, 0.4416, 0.5267, 0.6568, 0.4698,
        0.5238, 0.4779, 0.5561, 0.4242, 0.4716, 0.5553, 0.4940],
       device='cuda:0') torch.Size([16])
percent tensor([0.8282, 0.7834, 0.8696, 0.8652, 0.8733, 0.8413, 0.7967, 0.9033, 0.7492,
        0.8358, 0.7762, 0.8325, 0.7614, 0.7794, 0.8139, 0.8615],
       device='cuda:0') torch.Size([16])
Epoch: 13 | Batch_idx: 0 |  Loss: (0.9714) |  Loss2: (0.0000) | Acc: (60.00%) (77/128)
Epoch: 13 | Batch_idx: 10 |  Loss: (0.8721) |  Loss2: (0.0000) | Acc: (67.00%) (952/1408)
Epoch: 13 | Batch_idx: 20 |  Loss: (0.8803) |  Loss2: (0.0000) | Acc: (67.00%) (1822/2688)
Epoch: 13 | Batch_idx: 30 |  Loss: (0.8850) |  Loss2: (0.0000) | Acc: (67.00%) (2692/3968)
Epoch: 13 | Batch_idx: 40 |  Loss: (0.8756) |  Loss2: (0.0000) | Acc: (68.00%) (3595/5248)
Epoch: 13 | Batch_idx: 50 |  Loss: (0.8860) |  Loss2: (0.0000) | Acc: (68.00%) (4464/6528)
Epoch: 13 | Batch_idx: 60 |  Loss: (0.8904) |  Loss2: (0.0000) | Acc: (68.00%) (5345/7808)
Epoch: 13 | Batch_idx: 70 |  Loss: (0.8941) |  Loss2: (0.0000) | Acc: (68.00%) (6200/9088)
Epoch: 13 | Batch_idx: 80 |  Loss: (0.8895) |  Loss2: (0.0000) | Acc: (68.00%) (7104/10368)
Epoch: 13 | Batch_idx: 90 |  Loss: (0.8878) |  Loss2: (0.0000) | Acc: (68.00%) (7996/11648)
Epoch: 13 | Batch_idx: 100 |  Loss: (0.8873) |  Loss2: (0.0000) | Acc: (68.00%) (8872/12928)
Epoch: 13 | Batch_idx: 110 |  Loss: (0.8825) |  Loss2: (0.0000) | Acc: (68.00%) (9793/14208)
Epoch: 13 | Batch_idx: 120 |  Loss: (0.8860) |  Loss2: (0.0000) | Acc: (68.00%) (10658/15488)
Epoch: 13 | Batch_idx: 130 |  Loss: (0.8855) |  Loss2: (0.0000) | Acc: (68.00%) (11546/16768)
Epoch: 13 | Batch_idx: 140 |  Loss: (0.8842) |  Loss2: (0.0000) | Acc: (68.00%) (12430/18048)
Epoch: 13 | Batch_idx: 150 |  Loss: (0.8876) |  Loss2: (0.0000) | Acc: (68.00%) (13293/19328)
Epoch: 13 | Batch_idx: 160 |  Loss: (0.8846) |  Loss2: (0.0000) | Acc: (68.00%) (14205/20608)
Epoch: 13 | Batch_idx: 170 |  Loss: (0.8851) |  Loss2: (0.0000) | Acc: (68.00%) (15089/21888)
Epoch: 13 | Batch_idx: 180 |  Loss: (0.8849) |  Loss2: (0.0000) | Acc: (68.00%) (15965/23168)
Epoch: 13 | Batch_idx: 190 |  Loss: (0.8815) |  Loss2: (0.0000) | Acc: (69.00%) (16884/24448)
Epoch: 13 | Batch_idx: 200 |  Loss: (0.8820) |  Loss2: (0.0000) | Acc: (69.00%) (17754/25728)
Epoch: 13 | Batch_idx: 210 |  Loss: (0.8806) |  Loss2: (0.0000) | Acc: (69.00%) (18646/27008)
Epoch: 13 | Batch_idx: 220 |  Loss: (0.8812) |  Loss2: (0.0000) | Acc: (69.00%) (19521/28288)
Epoch: 13 | Batch_idx: 230 |  Loss: (0.8808) |  Loss2: (0.0000) | Acc: (68.00%) (20397/29568)
Epoch: 13 | Batch_idx: 240 |  Loss: (0.8805) |  Loss2: (0.0000) | Acc: (69.00%) (21302/30848)
Epoch: 13 | Batch_idx: 250 |  Loss: (0.8810) |  Loss2: (0.0000) | Acc: (68.00%) (22162/32128)
Epoch: 13 | Batch_idx: 260 |  Loss: (0.8814) |  Loss2: (0.0000) | Acc: (68.00%) (23043/33408)
Epoch: 13 | Batch_idx: 270 |  Loss: (0.8811) |  Loss2: (0.0000) | Acc: (69.00%) (23953/34688)
Epoch: 13 | Batch_idx: 280 |  Loss: (0.8802) |  Loss2: (0.0000) | Acc: (69.00%) (24852/35968)
Epoch: 13 | Batch_idx: 290 |  Loss: (0.8808) |  Loss2: (0.0000) | Acc: (69.00%) (25726/37248)
Epoch: 13 | Batch_idx: 300 |  Loss: (0.8794) |  Loss2: (0.0000) | Acc: (69.00%) (26634/38528)
Epoch: 13 | Batch_idx: 310 |  Loss: (0.8784) |  Loss2: (0.0000) | Acc: (69.00%) (27520/39808)
Epoch: 13 | Batch_idx: 320 |  Loss: (0.8781) |  Loss2: (0.0000) | Acc: (69.00%) (28412/41088)
Epoch: 13 | Batch_idx: 330 |  Loss: (0.8776) |  Loss2: (0.0000) | Acc: (69.00%) (29301/42368)
Epoch: 13 | Batch_idx: 340 |  Loss: (0.8784) |  Loss2: (0.0000) | Acc: (69.00%) (30163/43648)
Epoch: 13 | Batch_idx: 350 |  Loss: (0.8793) |  Loss2: (0.0000) | Acc: (69.00%) (31025/44928)
Epoch: 13 | Batch_idx: 360 |  Loss: (0.8782) |  Loss2: (0.0000) | Acc: (69.00%) (31941/46208)
Epoch: 13 | Batch_idx: 370 |  Loss: (0.8774) |  Loss2: (0.0000) | Acc: (69.00%) (32820/47488)
Epoch: 13 | Batch_idx: 380 |  Loss: (0.8763) |  Loss2: (0.0000) | Acc: (69.00%) (33727/48768)
Epoch: 13 | Batch_idx: 390 |  Loss: (0.8768) |  Loss2: (0.0000) | Acc: (69.00%) (34562/50000)
# TEST : Loss: (0.9222) | Acc: (66.00%) (6684/10000)
percent tensor([0.5108, 0.5146, 0.5114, 0.5089, 0.5119, 0.5081, 0.5150, 0.5114, 0.5141,
        0.5132, 0.5131, 0.5133, 0.5122, 0.5143, 0.5111, 0.5099],
       device='cuda:0') torch.Size([16])
percent tensor([0.5121, 0.5127, 0.4991, 0.5166, 0.5037, 0.5219, 0.5074, 0.5099, 0.5086,
        0.5088, 0.5102, 0.4995, 0.5081, 0.5223, 0.5145, 0.5169],
       device='cuda:0') torch.Size([16])
percent tensor([0.4609, 0.4808, 0.4570, 0.4503, 0.4584, 0.4554, 0.4761, 0.4591, 0.4702,
        0.4672, 0.4718, 0.4622, 0.4678, 0.4833, 0.4681, 0.4618],
       device='cuda:0') torch.Size([16])
percent tensor([0.5279, 0.5227, 0.5173, 0.5267, 0.5222, 0.5383, 0.5201, 0.5214, 0.5213,
        0.5232, 0.5244, 0.5157, 0.5239, 0.5236, 0.5264, 0.5314],
       device='cuda:0') torch.Size([16])
percent tensor([0.5479, 0.5614, 0.5034, 0.5190, 0.5041, 0.5630, 0.5406, 0.5115, 0.5558,
        0.5497, 0.5554, 0.5139, 0.5663, 0.5784, 0.5322, 0.5627],
       device='cuda:0') torch.Size([16])
percent tensor([0.5413, 0.5364, 0.5600, 0.5570, 0.5608, 0.5460, 0.5415, 0.5629, 0.5487,
        0.5358, 0.5398, 0.5518, 0.5355, 0.5414, 0.5422, 0.5390],
       device='cuda:0') torch.Size([16])
percent tensor([0.4726, 0.4656, 0.5700, 0.5526, 0.5885, 0.4454, 0.5057, 0.6330, 0.4717,
        0.4926, 0.4628, 0.5470, 0.4271, 0.4589, 0.5250, 0.4866],
       device='cuda:0') torch.Size([16])
percent tensor([0.8552, 0.7593, 0.8680, 0.8694, 0.8643, 0.8298, 0.8246, 0.9040, 0.7587,
        0.8155, 0.7822, 0.8436, 0.7686, 0.7719, 0.8390, 0.8735],
       device='cuda:0') torch.Size([16])
Epoch: 14 | Batch_idx: 0 |  Loss: (0.7818) |  Loss2: (0.0000) | Acc: (73.00%) (94/128)
Epoch: 14 | Batch_idx: 10 |  Loss: (0.8522) |  Loss2: (0.0000) | Acc: (70.00%) (986/1408)
Epoch: 14 | Batch_idx: 20 |  Loss: (0.8547) |  Loss2: (0.0000) | Acc: (69.00%) (1874/2688)
Epoch: 14 | Batch_idx: 30 |  Loss: (0.8479) |  Loss2: (0.0000) | Acc: (70.00%) (2784/3968)
Epoch: 14 | Batch_idx: 40 |  Loss: (0.8480) |  Loss2: (0.0000) | Acc: (69.00%) (3669/5248)
Epoch: 14 | Batch_idx: 50 |  Loss: (0.8510) |  Loss2: (0.0000) | Acc: (69.00%) (4545/6528)
Epoch: 14 | Batch_idx: 60 |  Loss: (0.8464) |  Loss2: (0.0000) | Acc: (69.00%) (5446/7808)
Epoch: 14 | Batch_idx: 70 |  Loss: (0.8455) |  Loss2: (0.0000) | Acc: (69.00%) (6343/9088)
Epoch: 14 | Batch_idx: 80 |  Loss: (0.8438) |  Loss2: (0.0000) | Acc: (69.00%) (7239/10368)
Epoch: 14 | Batch_idx: 90 |  Loss: (0.8440) |  Loss2: (0.0000) | Acc: (69.00%) (8137/11648)
Epoch: 14 | Batch_idx: 100 |  Loss: (0.8395) |  Loss2: (0.0000) | Acc: (69.00%) (9042/12928)
Epoch: 14 | Batch_idx: 110 |  Loss: (0.8413) |  Loss2: (0.0000) | Acc: (69.00%) (9930/14208)
Epoch: 14 | Batch_idx: 120 |  Loss: (0.8415) |  Loss2: (0.0000) | Acc: (69.00%) (10817/15488)
Epoch: 14 | Batch_idx: 130 |  Loss: (0.8371) |  Loss2: (0.0000) | Acc: (70.00%) (11742/16768)
Epoch: 14 | Batch_idx: 140 |  Loss: (0.8345) |  Loss2: (0.0000) | Acc: (70.00%) (12644/18048)
Epoch: 14 | Batch_idx: 150 |  Loss: (0.8359) |  Loss2: (0.0000) | Acc: (70.00%) (13547/19328)
Epoch: 14 | Batch_idx: 160 |  Loss: (0.8357) |  Loss2: (0.0000) | Acc: (70.00%) (14447/20608)
Epoch: 14 | Batch_idx: 170 |  Loss: (0.8365) |  Loss2: (0.0000) | Acc: (70.00%) (15352/21888)
Epoch: 14 | Batch_idx: 180 |  Loss: (0.8354) |  Loss2: (0.0000) | Acc: (70.00%) (16254/23168)
Epoch: 14 | Batch_idx: 190 |  Loss: (0.8351) |  Loss2: (0.0000) | Acc: (70.00%) (17160/24448)
Epoch: 14 | Batch_idx: 200 |  Loss: (0.8355) |  Loss2: (0.0000) | Acc: (70.00%) (18065/25728)
Epoch: 14 | Batch_idx: 210 |  Loss: (0.8348) |  Loss2: (0.0000) | Acc: (70.00%) (18980/27008)
Epoch: 14 | Batch_idx: 220 |  Loss: (0.8342) |  Loss2: (0.0000) | Acc: (70.00%) (19878/28288)
Epoch: 14 | Batch_idx: 230 |  Loss: (0.8315) |  Loss2: (0.0000) | Acc: (70.00%) (20797/29568)
Epoch: 14 | Batch_idx: 240 |  Loss: (0.8329) |  Loss2: (0.0000) | Acc: (70.00%) (21694/30848)
Epoch: 14 | Batch_idx: 250 |  Loss: (0.8338) |  Loss2: (0.0000) | Acc: (70.00%) (22576/32128)
Epoch: 14 | Batch_idx: 260 |  Loss: (0.8339) |  Loss2: (0.0000) | Acc: (70.00%) (23464/33408)
Epoch: 14 | Batch_idx: 270 |  Loss: (0.8328) |  Loss2: (0.0000) | Acc: (70.00%) (24406/34688)
Epoch: 14 | Batch_idx: 280 |  Loss: (0.8307) |  Loss2: (0.0000) | Acc: (70.00%) (25344/35968)
Epoch: 14 | Batch_idx: 290 |  Loss: (0.8319) |  Loss2: (0.0000) | Acc: (70.00%) (26230/37248)
Epoch: 14 | Batch_idx: 300 |  Loss: (0.8317) |  Loss2: (0.0000) | Acc: (70.00%) (27123/38528)
Epoch: 14 | Batch_idx: 310 |  Loss: (0.8323) |  Loss2: (0.0000) | Acc: (70.00%) (28020/39808)
Epoch: 14 | Batch_idx: 320 |  Loss: (0.8320) |  Loss2: (0.0000) | Acc: (70.00%) (28933/41088)
Epoch: 14 | Batch_idx: 330 |  Loss: (0.8310) |  Loss2: (0.0000) | Acc: (70.00%) (29842/42368)
Epoch: 14 | Batch_idx: 340 |  Loss: (0.8306) |  Loss2: (0.0000) | Acc: (70.00%) (30749/43648)
Epoch: 14 | Batch_idx: 350 |  Loss: (0.8293) |  Loss2: (0.0000) | Acc: (70.00%) (31679/44928)
Epoch: 14 | Batch_idx: 360 |  Loss: (0.8284) |  Loss2: (0.0000) | Acc: (70.00%) (32593/46208)
Epoch: 14 | Batch_idx: 370 |  Loss: (0.8279) |  Loss2: (0.0000) | Acc: (70.00%) (33534/47488)
Epoch: 14 | Batch_idx: 380 |  Loss: (0.8270) |  Loss2: (0.0000) | Acc: (70.00%) (34476/48768)
Epoch: 14 | Batch_idx: 390 |  Loss: (0.8270) |  Loss2: (0.0000) | Acc: (70.00%) (35360/50000)
# TEST : Loss: (0.8164) | Acc: (70.00%) (7078/10000)
percent tensor([0.5107, 0.5144, 0.5115, 0.5086, 0.5121, 0.5085, 0.5152, 0.5109, 0.5138,
        0.5130, 0.5127, 0.5132, 0.5119, 0.5141, 0.5110, 0.5097],
       device='cuda:0') torch.Size([16])
percent tensor([0.5151, 0.5142, 0.5007, 0.5175, 0.5053, 0.5231, 0.5095, 0.5105, 0.5104,
        0.5103, 0.5120, 0.5017, 0.5106, 0.5227, 0.5159, 0.5183],
       device='cuda:0') torch.Size([16])
percent tensor([0.4611, 0.4814, 0.4584, 0.4517, 0.4613, 0.4556, 0.4774, 0.4601, 0.4710,
        0.4668, 0.4724, 0.4627, 0.4683, 0.4826, 0.4685, 0.4626],
       device='cuda:0') torch.Size([16])
percent tensor([0.5291, 0.5240, 0.5179, 0.5268, 0.5232, 0.5380, 0.5208, 0.5219, 0.5215,
        0.5251, 0.5248, 0.5168, 0.5258, 0.5237, 0.5271, 0.5323],
       device='cuda:0') torch.Size([16])
percent tensor([0.5470, 0.5569, 0.5075, 0.5220, 0.5096, 0.5656, 0.5352, 0.5083, 0.5508,
        0.5467, 0.5497, 0.5156, 0.5695, 0.5692, 0.5281, 0.5557],
       device='cuda:0') torch.Size([16])
percent tensor([0.5393, 0.5376, 0.5538, 0.5588, 0.5537, 0.5394, 0.5411, 0.5647, 0.5498,
        0.5379, 0.5389, 0.5468, 0.5363, 0.5429, 0.5422, 0.5379],
       device='cuda:0') torch.Size([16])
percent tensor([0.4737, 0.4873, 0.5682, 0.5634, 0.5782, 0.4307, 0.5275, 0.6476, 0.4919,
        0.5118, 0.4746, 0.5506, 0.4330, 0.4745, 0.5455, 0.4972],
       device='cuda:0') torch.Size([16])
percent tensor([0.8497, 0.7761, 0.8620, 0.8535, 0.8632, 0.8241, 0.8163, 0.8877, 0.7787,
        0.8219, 0.7814, 0.8577, 0.7711, 0.7825, 0.8080, 0.8690],
       device='cuda:0') torch.Size([16])
False Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=128, out_features=16, bias=False)
True Linear(in_features=16, out_features=2, bias=False)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=128, out_features=16, bias=False)
True Linear(in_features=16, out_features=2, bias=False)
False Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=256, out_features=32, bias=False)
True Linear(in_features=32, out_features=2, bias=False)
False Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=256, out_features=32, bias=False)
True Linear(in_features=32, out_features=2, bias=False)
False Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=512, out_features=64, bias=False)
True Linear(in_features=64, out_features=2, bias=False)
False Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=512, out_features=64, bias=False)
True Linear(in_features=64, out_features=2, bias=False)
False Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1024, out_features=128, bias=False)
True Linear(in_features=128, out_features=2, bias=False)
False Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1024, out_features=128, bias=False)
True Linear(in_features=128, out_features=2, bias=False)
False Linear(in_features=512, out_features=10, bias=True)
Epoch: 15 | Batch_idx: 0 |  Loss: (0.7366) |  Loss2: (0.0000) | Acc: (75.00%) (97/128)
Epoch: 15 | Batch_idx: 10 |  Loss: (0.8373) |  Loss2: (0.0000) | Acc: (68.00%) (970/1408)
Epoch: 15 | Batch_idx: 20 |  Loss: (0.8792) |  Loss2: (0.0000) | Acc: (68.00%) (1836/2688)
Epoch: 15 | Batch_idx: 30 |  Loss: (0.9162) |  Loss2: (0.0000) | Acc: (66.00%) (2653/3968)
Epoch: 15 | Batch_idx: 40 |  Loss: (0.9252) |  Loss2: (0.0000) | Acc: (66.00%) (3483/5248)
Epoch: 15 | Batch_idx: 50 |  Loss: (0.9312) |  Loss2: (0.0000) | Acc: (66.00%) (4341/6528)
Epoch: 15 | Batch_idx: 60 |  Loss: (0.9322) |  Loss2: (0.0000) | Acc: (66.00%) (5192/7808)
Epoch: 15 | Batch_idx: 70 |  Loss: (0.9334) |  Loss2: (0.0000) | Acc: (66.00%) (6044/9088)
Epoch: 15 | Batch_idx: 80 |  Loss: (0.9312) |  Loss2: (0.0000) | Acc: (66.00%) (6897/10368)
Epoch: 15 | Batch_idx: 90 |  Loss: (0.9290) |  Loss2: (0.0000) | Acc: (66.00%) (7765/11648)
Epoch: 15 | Batch_idx: 100 |  Loss: (0.9279) |  Loss2: (0.0000) | Acc: (66.00%) (8631/12928)
Epoch: 15 | Batch_idx: 110 |  Loss: (0.9257) |  Loss2: (0.0000) | Acc: (66.00%) (9511/14208)
Epoch: 15 | Batch_idx: 120 |  Loss: (0.9229) |  Loss2: (0.0000) | Acc: (67.00%) (10383/15488)
Epoch: 15 | Batch_idx: 130 |  Loss: (0.9229) |  Loss2: (0.0000) | Acc: (66.00%) (11232/16768)
Epoch: 15 | Batch_idx: 140 |  Loss: (0.9207) |  Loss2: (0.0000) | Acc: (67.00%) (12095/18048)
Epoch: 15 | Batch_idx: 150 |  Loss: (0.9182) |  Loss2: (0.0000) | Acc: (67.00%) (12951/19328)
Epoch: 15 | Batch_idx: 160 |  Loss: (0.9166) |  Loss2: (0.0000) | Acc: (67.00%) (13811/20608)
Epoch: 15 | Batch_idx: 170 |  Loss: (0.9129) |  Loss2: (0.0000) | Acc: (67.00%) (14697/21888)
Epoch: 15 | Batch_idx: 180 |  Loss: (0.9115) |  Loss2: (0.0000) | Acc: (67.00%) (15557/23168)
Epoch: 15 | Batch_idx: 190 |  Loss: (0.9093) |  Loss2: (0.0000) | Acc: (67.00%) (16442/24448)
Epoch: 15 | Batch_idx: 200 |  Loss: (0.9051) |  Loss2: (0.0000) | Acc: (67.00%) (17350/25728)
Epoch: 15 | Batch_idx: 210 |  Loss: (0.9029) |  Loss2: (0.0000) | Acc: (67.00%) (18237/27008)
Epoch: 15 | Batch_idx: 220 |  Loss: (0.9000) |  Loss2: (0.0000) | Acc: (67.00%) (19136/28288)
Epoch: 15 | Batch_idx: 230 |  Loss: (0.8980) |  Loss2: (0.0000) | Acc: (67.00%) (20027/29568)
Epoch: 15 | Batch_idx: 240 |  Loss: (0.8951) |  Loss2: (0.0000) | Acc: (67.00%) (20932/30848)
Epoch: 15 | Batch_idx: 250 |  Loss: (0.8925) |  Loss2: (0.0000) | Acc: (67.00%) (21829/32128)
Epoch: 15 | Batch_idx: 260 |  Loss: (0.8893) |  Loss2: (0.0000) | Acc: (68.00%) (22756/33408)
Epoch: 15 | Batch_idx: 270 |  Loss: (0.8890) |  Loss2: (0.0000) | Acc: (68.00%) (23638/34688)
Epoch: 15 | Batch_idx: 280 |  Loss: (0.8864) |  Loss2: (0.0000) | Acc: (68.00%) (24538/35968)
Epoch: 15 | Batch_idx: 290 |  Loss: (0.8844) |  Loss2: (0.0000) | Acc: (68.00%) (25435/37248)
Epoch: 15 | Batch_idx: 300 |  Loss: (0.8818) |  Loss2: (0.0000) | Acc: (68.00%) (26333/38528)
Epoch: 15 | Batch_idx: 310 |  Loss: (0.8809) |  Loss2: (0.0000) | Acc: (68.00%) (27239/39808)
Epoch: 15 | Batch_idx: 320 |  Loss: (0.8808) |  Loss2: (0.0000) | Acc: (68.00%) (28113/41088)
Epoch: 15 | Batch_idx: 330 |  Loss: (0.8799) |  Loss2: (0.0000) | Acc: (68.00%) (28990/42368)
Epoch: 15 | Batch_idx: 340 |  Loss: (0.8799) |  Loss2: (0.0000) | Acc: (68.00%) (29853/43648)
Epoch: 15 | Batch_idx: 350 |  Loss: (0.8788) |  Loss2: (0.0000) | Acc: (68.00%) (30774/44928)
Epoch: 15 | Batch_idx: 360 |  Loss: (0.8773) |  Loss2: (0.0000) | Acc: (68.00%) (31665/46208)
Epoch: 15 | Batch_idx: 370 |  Loss: (0.8758) |  Loss2: (0.0000) | Acc: (68.00%) (32576/47488)
Epoch: 15 | Batch_idx: 380 |  Loss: (0.8755) |  Loss2: (0.0000) | Acc: (68.00%) (33473/48768)
Epoch: 15 | Batch_idx: 390 |  Loss: (0.8741) |  Loss2: (0.0000) | Acc: (68.00%) (34352/50000)
=> saving checkpoint 'drive/app/torch/save_Routing_Gate_2/checkpoint_015.pth.tar'
# TEST : Loss: (0.8620) | Acc: (69.00%) (6953/10000)
percent tensor([0.5265, 0.5326, 0.5293, 0.5227, 0.5312, 0.5242, 0.5355, 0.5267, 0.5319,
        0.5305, 0.5298, 0.5323, 0.5281, 0.5311, 0.5274, 0.5244],
       device='cuda:0') torch.Size([16])
percent tensor([0.5273, 0.5249, 0.5028, 0.5275, 0.5124, 0.5483, 0.5183, 0.5177, 0.5176,
        0.5164, 0.5205, 0.5044, 0.5178, 0.5360, 0.5316, 0.5324],
       device='cuda:0') torch.Size([16])
percent tensor([0.4826, 0.4981, 0.4850, 0.4796, 0.4882, 0.4803, 0.4976, 0.4884, 0.4925,
        0.4887, 0.4906, 0.4888, 0.4870, 0.4988, 0.4903, 0.4853],
       device='cuda:0') torch.Size([16])
percent tensor([0.5153, 0.5093, 0.5018, 0.5091, 0.5067, 0.5290, 0.5042, 0.5036, 0.5078,
        0.5090, 0.5108, 0.4997, 0.5118, 0.5093, 0.5128, 0.5182],
       device='cuda:0') torch.Size([16])
percent tensor([0.5710, 0.5583, 0.5425, 0.5716, 0.5344, 0.6263, 0.5446, 0.5490, 0.5765,
        0.5397, 0.5558, 0.5312, 0.5791, 0.5883, 0.5493, 0.5817],
       device='cuda:0') torch.Size([16])
percent tensor([0.5672, 0.5648, 0.6015, 0.6077, 0.6021, 0.5628, 0.5754, 0.6225, 0.5815,
        0.5667, 0.5631, 0.5853, 0.5573, 0.5681, 0.5803, 0.5681],
       device='cuda:0') torch.Size([16])
percent tensor([0.4126, 0.4795, 0.5634, 0.5570, 0.5940, 0.3095, 0.5367, 0.6945, 0.4658,
        0.5230, 0.4361, 0.5270, 0.3662, 0.4233, 0.5289, 0.4518],
       device='cuda:0') torch.Size([16])
percent tensor([0.9116, 0.8584, 0.9259, 0.9103, 0.9260, 0.8806, 0.8819, 0.9405, 0.8577,
        0.8949, 0.8546, 0.9193, 0.8554, 0.8578, 0.8869, 0.9169],
       device='cuda:0') torch.Size([16])
Epoch: 16 | Batch_idx: 0 |  Loss: (0.7687) |  Loss2: (0.0000) | Acc: (71.00%) (91/128)
Epoch: 16 | Batch_idx: 10 |  Loss: (0.8210) |  Loss2: (0.0000) | Acc: (69.00%) (976/1408)
Epoch: 16 | Batch_idx: 20 |  Loss: (0.8257) |  Loss2: (0.0000) | Acc: (69.00%) (1874/2688)
Epoch: 16 | Batch_idx: 30 |  Loss: (0.8334) |  Loss2: (0.0000) | Acc: (68.00%) (2736/3968)
Epoch: 16 | Batch_idx: 40 |  Loss: (0.8129) |  Loss2: (0.0000) | Acc: (69.00%) (3672/5248)
Epoch: 16 | Batch_idx: 50 |  Loss: (0.8052) |  Loss2: (0.0000) | Acc: (70.00%) (4588/6528)
Epoch: 16 | Batch_idx: 60 |  Loss: (0.8088) |  Loss2: (0.0000) | Acc: (70.00%) (5495/7808)
Epoch: 16 | Batch_idx: 70 |  Loss: (0.8039) |  Loss2: (0.0000) | Acc: (70.00%) (6436/9088)
Epoch: 16 | Batch_idx: 80 |  Loss: (0.8104) |  Loss2: (0.0000) | Acc: (70.00%) (7330/10368)
Epoch: 16 | Batch_idx: 90 |  Loss: (0.8098) |  Loss2: (0.0000) | Acc: (70.00%) (8240/11648)
Epoch: 16 | Batch_idx: 100 |  Loss: (0.8065) |  Loss2: (0.0000) | Acc: (70.00%) (9169/12928)
Epoch: 16 | Batch_idx: 110 |  Loss: (0.8062) |  Loss2: (0.0000) | Acc: (70.00%) (10073/14208)
Epoch: 16 | Batch_idx: 120 |  Loss: (0.8053) |  Loss2: (0.0000) | Acc: (70.00%) (10990/15488)
Epoch: 16 | Batch_idx: 130 |  Loss: (0.8017) |  Loss2: (0.0000) | Acc: (71.00%) (11932/16768)
Epoch: 16 | Batch_idx: 140 |  Loss: (0.8049) |  Loss2: (0.0000) | Acc: (71.00%) (12830/18048)
Epoch: 16 | Batch_idx: 150 |  Loss: (0.8099) |  Loss2: (0.0000) | Acc: (70.00%) (13720/19328)
Epoch: 16 | Batch_idx: 160 |  Loss: (0.8109) |  Loss2: (0.0000) | Acc: (70.00%) (14627/20608)
Epoch: 16 | Batch_idx: 170 |  Loss: (0.8100) |  Loss2: (0.0000) | Acc: (71.00%) (15541/21888)
Epoch: 16 | Batch_idx: 180 |  Loss: (0.8112) |  Loss2: (0.0000) | Acc: (70.00%) (16440/23168)
Epoch: 16 | Batch_idx: 190 |  Loss: (0.8105) |  Loss2: (0.0000) | Acc: (70.00%) (17355/24448)
Epoch: 16 | Batch_idx: 200 |  Loss: (0.8104) |  Loss2: (0.0000) | Acc: (71.00%) (18267/25728)
Epoch: 16 | Batch_idx: 210 |  Loss: (0.8121) |  Loss2: (0.0000) | Acc: (70.00%) (19157/27008)
Epoch: 16 | Batch_idx: 220 |  Loss: (0.8114) |  Loss2: (0.0000) | Acc: (70.00%) (20060/28288)
Epoch: 16 | Batch_idx: 230 |  Loss: (0.8109) |  Loss2: (0.0000) | Acc: (70.00%) (20975/29568)
Epoch: 16 | Batch_idx: 240 |  Loss: (0.8104) |  Loss2: (0.0000) | Acc: (70.00%) (21900/30848)
Epoch: 16 | Batch_idx: 250 |  Loss: (0.8091) |  Loss2: (0.0000) | Acc: (71.00%) (22834/32128)
Epoch: 16 | Batch_idx: 260 |  Loss: (0.8089) |  Loss2: (0.0000) | Acc: (71.00%) (23749/33408)
Epoch: 16 | Batch_idx: 270 |  Loss: (0.8083) |  Loss2: (0.0000) | Acc: (71.00%) (24659/34688)
Epoch: 16 | Batch_idx: 280 |  Loss: (0.8085) |  Loss2: (0.0000) | Acc: (71.00%) (25565/35968)
Epoch: 16 | Batch_idx: 290 |  Loss: (0.8069) |  Loss2: (0.0000) | Acc: (71.00%) (26512/37248)
Epoch: 16 | Batch_idx: 300 |  Loss: (0.8081) |  Loss2: (0.0000) | Acc: (71.00%) (27394/38528)
Epoch: 16 | Batch_idx: 310 |  Loss: (0.8093) |  Loss2: (0.0000) | Acc: (71.00%) (28293/39808)
Epoch: 16 | Batch_idx: 320 |  Loss: (0.8092) |  Loss2: (0.0000) | Acc: (71.00%) (29199/41088)
Epoch: 16 | Batch_idx: 330 |  Loss: (0.8096) |  Loss2: (0.0000) | Acc: (71.00%) (30106/42368)
Epoch: 16 | Batch_idx: 340 |  Loss: (0.8095) |  Loss2: (0.0000) | Acc: (71.00%) (31018/43648)
Epoch: 16 | Batch_idx: 350 |  Loss: (0.8086) |  Loss2: (0.0000) | Acc: (71.00%) (31934/44928)
Epoch: 16 | Batch_idx: 360 |  Loss: (0.8084) |  Loss2: (0.0000) | Acc: (71.00%) (32860/46208)
Epoch: 16 | Batch_idx: 370 |  Loss: (0.8084) |  Loss2: (0.0000) | Acc: (71.00%) (33777/47488)
Epoch: 16 | Batch_idx: 380 |  Loss: (0.8083) |  Loss2: (0.0000) | Acc: (71.00%) (34695/48768)
Epoch: 16 | Batch_idx: 390 |  Loss: (0.8074) |  Loss2: (0.0000) | Acc: (71.00%) (35582/50000)
# TEST : Loss: (0.8282) | Acc: (70.00%) (7070/10000)
percent tensor([0.5247, 0.5292, 0.5267, 0.5206, 0.5284, 0.5253, 0.5320, 0.5235, 0.5284,
        0.5272, 0.5269, 0.5289, 0.5251, 0.5277, 0.5258, 0.5227],
       device='cuda:0') torch.Size([16])
percent tensor([0.5344, 0.5285, 0.4968, 0.5336, 0.5116, 0.5693, 0.5188, 0.5186, 0.5183,
        0.5154, 0.5227, 0.4993, 0.5194, 0.5428, 0.5420, 0.5424],
       device='cuda:0') torch.Size([16])
percent tensor([0.4851, 0.5009, 0.4888, 0.4837, 0.4915, 0.4828, 0.5005, 0.4931, 0.4960,
        0.4919, 0.4929, 0.4920, 0.4894, 0.5022, 0.4925, 0.4881],
       device='cuda:0') torch.Size([16])
percent tensor([0.5102, 0.5026, 0.4934, 0.5009, 0.4991, 0.5287, 0.4961, 0.4936, 0.5012,
        0.5013, 0.5047, 0.4908, 0.5062, 0.5033, 0.5071, 0.5139],
       device='cuda:0') torch.Size([16])
percent tensor([0.5616, 0.5371, 0.5470, 0.5767, 0.5340, 0.6366, 0.5303, 0.5509, 0.5715,
        0.5134, 0.5396, 0.5210, 0.5645, 0.5738, 0.5382, 0.5727],
       device='cuda:0') torch.Size([16])
percent tensor([0.5938, 0.5847, 0.6331, 0.6430, 0.6363, 0.5979, 0.5997, 0.6573, 0.6052,
        0.5873, 0.5833, 0.6098, 0.5760, 0.5887, 0.6094, 0.5959],
       device='cuda:0') torch.Size([16])
percent tensor([0.4210, 0.4885, 0.5644, 0.5662, 0.6090, 0.3152, 0.5401, 0.6977, 0.4724,
        0.5381, 0.4423, 0.5167, 0.3707, 0.4315, 0.5271, 0.4575],
       device='cuda:0') torch.Size([16])
percent tensor([0.9515, 0.9074, 0.9554, 0.9465, 0.9601, 0.9346, 0.9257, 0.9684, 0.9076,
        0.9372, 0.9088, 0.9510, 0.9129, 0.9111, 0.9353, 0.9568],
       device='cuda:0') torch.Size([16])
Epoch: 17 | Batch_idx: 0 |  Loss: (0.6072) |  Loss2: (0.0000) | Acc: (76.00%) (98/128)
Epoch: 17 | Batch_idx: 10 |  Loss: (0.8003) |  Loss2: (0.0000) | Acc: (71.00%) (1009/1408)
Epoch: 17 | Batch_idx: 20 |  Loss: (0.8080) |  Loss2: (0.0000) | Acc: (71.00%) (1924/2688)
Epoch: 17 | Batch_idx: 30 |  Loss: (0.8028) |  Loss2: (0.0000) | Acc: (71.00%) (2846/3968)
Epoch: 17 | Batch_idx: 40 |  Loss: (0.7889) |  Loss2: (0.0000) | Acc: (71.00%) (3777/5248)
Epoch: 17 | Batch_idx: 50 |  Loss: (0.7907) |  Loss2: (0.0000) | Acc: (71.00%) (4700/6528)
Epoch: 17 | Batch_idx: 60 |  Loss: (0.7855) |  Loss2: (0.0000) | Acc: (71.00%) (5617/7808)
Epoch: 17 | Batch_idx: 70 |  Loss: (0.7896) |  Loss2: (0.0000) | Acc: (71.00%) (6529/9088)
Epoch: 17 | Batch_idx: 80 |  Loss: (0.7937) |  Loss2: (0.0000) | Acc: (71.00%) (7429/10368)
Epoch: 17 | Batch_idx: 90 |  Loss: (0.7914) |  Loss2: (0.0000) | Acc: (71.00%) (8358/11648)
Epoch: 17 | Batch_idx: 100 |  Loss: (0.7931) |  Loss2: (0.0000) | Acc: (71.00%) (9290/12928)
Epoch: 17 | Batch_idx: 110 |  Loss: (0.7906) |  Loss2: (0.0000) | Acc: (71.00%) (10206/14208)
Epoch: 17 | Batch_idx: 120 |  Loss: (0.7897) |  Loss2: (0.0000) | Acc: (71.00%) (11129/15488)
Epoch: 17 | Batch_idx: 130 |  Loss: (0.7867) |  Loss2: (0.0000) | Acc: (71.00%) (12048/16768)
Epoch: 17 | Batch_idx: 140 |  Loss: (0.7872) |  Loss2: (0.0000) | Acc: (71.00%) (12973/18048)
Epoch: 17 | Batch_idx: 150 |  Loss: (0.7863) |  Loss2: (0.0000) | Acc: (71.00%) (13888/19328)
Epoch: 17 | Batch_idx: 160 |  Loss: (0.7878) |  Loss2: (0.0000) | Acc: (71.00%) (14801/20608)
Epoch: 17 | Batch_idx: 170 |  Loss: (0.7900) |  Loss2: (0.0000) | Acc: (71.00%) (15709/21888)
Epoch: 17 | Batch_idx: 180 |  Loss: (0.7901) |  Loss2: (0.0000) | Acc: (71.00%) (16616/23168)
Epoch: 17 | Batch_idx: 190 |  Loss: (0.7914) |  Loss2: (0.0000) | Acc: (71.00%) (17518/24448)
Epoch: 17 | Batch_idx: 200 |  Loss: (0.7904) |  Loss2: (0.0000) | Acc: (71.00%) (18431/25728)
Epoch: 17 | Batch_idx: 210 |  Loss: (0.7924) |  Loss2: (0.0000) | Acc: (71.00%) (19341/27008)
Epoch: 17 | Batch_idx: 220 |  Loss: (0.7926) |  Loss2: (0.0000) | Acc: (71.00%) (20265/28288)
Epoch: 17 | Batch_idx: 230 |  Loss: (0.7920) |  Loss2: (0.0000) | Acc: (71.00%) (21181/29568)
Epoch: 17 | Batch_idx: 240 |  Loss: (0.7931) |  Loss2: (0.0000) | Acc: (71.00%) (22102/30848)
Epoch: 17 | Batch_idx: 250 |  Loss: (0.7936) |  Loss2: (0.0000) | Acc: (71.00%) (23020/32128)
Epoch: 17 | Batch_idx: 260 |  Loss: (0.7934) |  Loss2: (0.0000) | Acc: (71.00%) (23935/33408)
Epoch: 17 | Batch_idx: 270 |  Loss: (0.7933) |  Loss2: (0.0000) | Acc: (71.00%) (24852/34688)
Epoch: 17 | Batch_idx: 280 |  Loss: (0.7935) |  Loss2: (0.0000) | Acc: (71.00%) (25754/35968)
Epoch: 17 | Batch_idx: 290 |  Loss: (0.7930) |  Loss2: (0.0000) | Acc: (71.00%) (26667/37248)
Epoch: 17 | Batch_idx: 300 |  Loss: (0.7924) |  Loss2: (0.0000) | Acc: (71.00%) (27591/38528)
Epoch: 17 | Batch_idx: 310 |  Loss: (0.7908) |  Loss2: (0.0000) | Acc: (71.00%) (28533/39808)
Epoch: 17 | Batch_idx: 320 |  Loss: (0.7905) |  Loss2: (0.0000) | Acc: (71.00%) (29468/41088)
Epoch: 17 | Batch_idx: 330 |  Loss: (0.7910) |  Loss2: (0.0000) | Acc: (71.00%) (30381/42368)
Epoch: 17 | Batch_idx: 340 |  Loss: (0.7905) |  Loss2: (0.0000) | Acc: (71.00%) (31330/43648)
Epoch: 17 | Batch_idx: 350 |  Loss: (0.7903) |  Loss2: (0.0000) | Acc: (71.00%) (32239/44928)
Epoch: 17 | Batch_idx: 360 |  Loss: (0.7910) |  Loss2: (0.0000) | Acc: (71.00%) (33159/46208)
Epoch: 17 | Batch_idx: 370 |  Loss: (0.7923) |  Loss2: (0.0000) | Acc: (71.00%) (34061/47488)
Epoch: 17 | Batch_idx: 380 |  Loss: (0.7919) |  Loss2: (0.0000) | Acc: (71.00%) (35003/48768)
Epoch: 17 | Batch_idx: 390 |  Loss: (0.7918) |  Loss2: (0.0000) | Acc: (71.00%) (35888/50000)
# TEST : Loss: (0.8144) | Acc: (71.00%) (7122/10000)
percent tensor([0.5224, 0.5255, 0.5243, 0.5181, 0.5257, 0.5251, 0.5285, 0.5202, 0.5247,
        0.5239, 0.5236, 0.5258, 0.5220, 0.5239, 0.5236, 0.5204],
       device='cuda:0') torch.Size([16])
percent tensor([0.5374, 0.5284, 0.4929, 0.5373, 0.5110, 0.5810, 0.5176, 0.5183, 0.5168,
        0.5131, 0.5221, 0.4958, 0.5189, 0.5442, 0.5474, 0.5474],
       device='cuda:0') torch.Size([16])
percent tensor([0.4846, 0.5016, 0.4880, 0.4833, 0.4902, 0.4811, 0.5009, 0.4930, 0.4974,
        0.4915, 0.4930, 0.4910, 0.4894, 0.5052, 0.4914, 0.4876],
       device='cuda:0') torch.Size([16])
percent tensor([0.5123, 0.5033, 0.4927, 0.5014, 0.4998, 0.5339, 0.4963, 0.4929, 0.5015,
        0.5017, 0.5058, 0.4902, 0.5075, 0.5040, 0.5092, 0.5170],
       device='cuda:0') torch.Size([16])
percent tensor([0.5545, 0.5299, 0.5414, 0.5707, 0.5281, 0.6396, 0.5240, 0.5458, 0.5672,
        0.4997, 0.5331, 0.5124, 0.5594, 0.5674, 0.5323, 0.5687],
       device='cuda:0') torch.Size([16])
percent tensor([0.6136, 0.5999, 0.6540, 0.6665, 0.6595, 0.6235, 0.6170, 0.6805, 0.6224,
        0.6038, 0.5988, 0.6279, 0.5908, 0.6051, 0.6304, 0.6158],
       device='cuda:0') torch.Size([16])
percent tensor([0.4518, 0.5085, 0.5696, 0.5742, 0.6170, 0.3359, 0.5524, 0.6976, 0.4929,
        0.5659, 0.4645, 0.5262, 0.3997, 0.4604, 0.5351, 0.4768],
       device='cuda:0') torch.Size([16])
percent tensor([0.9687, 0.9304, 0.9675, 0.9615, 0.9721, 0.9561, 0.9454, 0.9789, 0.9327,
        0.9564, 0.9344, 0.9657, 0.9396, 0.9352, 0.9556, 0.9730],
       device='cuda:0') torch.Size([16])
Epoch: 18 | Batch_idx: 0 |  Loss: (0.6303) |  Loss2: (0.0000) | Acc: (78.00%) (101/128)
Epoch: 18 | Batch_idx: 10 |  Loss: (0.8028) |  Loss2: (0.0000) | Acc: (70.00%) (988/1408)
Epoch: 18 | Batch_idx: 20 |  Loss: (0.7984) |  Loss2: (0.0000) | Acc: (70.00%) (1905/2688)
Epoch: 18 | Batch_idx: 30 |  Loss: (0.7965) |  Loss2: (0.0000) | Acc: (71.00%) (2822/3968)
Epoch: 18 | Batch_idx: 40 |  Loss: (0.7912) |  Loss2: (0.0000) | Acc: (71.00%) (3761/5248)
Epoch: 18 | Batch_idx: 50 |  Loss: (0.7877) |  Loss2: (0.0000) | Acc: (71.00%) (4689/6528)
Epoch: 18 | Batch_idx: 60 |  Loss: (0.7840) |  Loss2: (0.0000) | Acc: (72.00%) (5635/7808)
Epoch: 18 | Batch_idx: 70 |  Loss: (0.7784) |  Loss2: (0.0000) | Acc: (72.00%) (6577/9088)
Epoch: 18 | Batch_idx: 80 |  Loss: (0.7813) |  Loss2: (0.0000) | Acc: (72.00%) (7481/10368)
Epoch: 18 | Batch_idx: 90 |  Loss: (0.7776) |  Loss2: (0.0000) | Acc: (72.00%) (8431/11648)
Epoch: 18 | Batch_idx: 100 |  Loss: (0.7757) |  Loss2: (0.0000) | Acc: (72.00%) (9376/12928)
Epoch: 18 | Batch_idx: 110 |  Loss: (0.7707) |  Loss2: (0.0000) | Acc: (72.00%) (10307/14208)
Epoch: 18 | Batch_idx: 120 |  Loss: (0.7680) |  Loss2: (0.0000) | Acc: (72.00%) (11241/15488)
Epoch: 18 | Batch_idx: 130 |  Loss: (0.7709) |  Loss2: (0.0000) | Acc: (72.00%) (12170/16768)
Epoch: 18 | Batch_idx: 140 |  Loss: (0.7724) |  Loss2: (0.0000) | Acc: (72.00%) (13098/18048)
Epoch: 18 | Batch_idx: 150 |  Loss: (0.7745) |  Loss2: (0.0000) | Acc: (72.00%) (14016/19328)
Epoch: 18 | Batch_idx: 160 |  Loss: (0.7749) |  Loss2: (0.0000) | Acc: (72.00%) (14951/20608)
Epoch: 18 | Batch_idx: 170 |  Loss: (0.7734) |  Loss2: (0.0000) | Acc: (72.00%) (15875/21888)
Epoch: 18 | Batch_idx: 180 |  Loss: (0.7743) |  Loss2: (0.0000) | Acc: (72.00%) (16798/23168)
Epoch: 18 | Batch_idx: 190 |  Loss: (0.7731) |  Loss2: (0.0000) | Acc: (72.00%) (17727/24448)
Epoch: 18 | Batch_idx: 200 |  Loss: (0.7742) |  Loss2: (0.0000) | Acc: (72.00%) (18644/25728)
Epoch: 18 | Batch_idx: 210 |  Loss: (0.7748) |  Loss2: (0.0000) | Acc: (72.00%) (19563/27008)
Epoch: 18 | Batch_idx: 220 |  Loss: (0.7755) |  Loss2: (0.0000) | Acc: (72.00%) (20480/28288)
Epoch: 18 | Batch_idx: 230 |  Loss: (0.7769) |  Loss2: (0.0000) | Acc: (72.00%) (21410/29568)
Epoch: 18 | Batch_idx: 240 |  Loss: (0.7771) |  Loss2: (0.0000) | Acc: (72.00%) (22337/30848)
Epoch: 18 | Batch_idx: 250 |  Loss: (0.7753) |  Loss2: (0.0000) | Acc: (72.00%) (23300/32128)
Epoch: 18 | Batch_idx: 260 |  Loss: (0.7758) |  Loss2: (0.0000) | Acc: (72.00%) (24212/33408)
Epoch: 18 | Batch_idx: 270 |  Loss: (0.7763) |  Loss2: (0.0000) | Acc: (72.00%) (25137/34688)
Epoch: 18 | Batch_idx: 280 |  Loss: (0.7766) |  Loss2: (0.0000) | Acc: (72.00%) (26054/35968)
Epoch: 18 | Batch_idx: 290 |  Loss: (0.7767) |  Loss2: (0.0000) | Acc: (72.00%) (26980/37248)
Epoch: 18 | Batch_idx: 300 |  Loss: (0.7761) |  Loss2: (0.0000) | Acc: (72.00%) (27909/38528)
Epoch: 18 | Batch_idx: 310 |  Loss: (0.7751) |  Loss2: (0.0000) | Acc: (72.00%) (28848/39808)
Epoch: 18 | Batch_idx: 320 |  Loss: (0.7745) |  Loss2: (0.0000) | Acc: (72.00%) (29772/41088)
Epoch: 18 | Batch_idx: 330 |  Loss: (0.7763) |  Loss2: (0.0000) | Acc: (72.00%) (30654/42368)
Epoch: 18 | Batch_idx: 340 |  Loss: (0.7755) |  Loss2: (0.0000) | Acc: (72.00%) (31591/43648)
Epoch: 18 | Batch_idx: 350 |  Loss: (0.7758) |  Loss2: (0.0000) | Acc: (72.00%) (32520/44928)
Epoch: 18 | Batch_idx: 360 |  Loss: (0.7764) |  Loss2: (0.0000) | Acc: (72.00%) (33433/46208)
Epoch: 18 | Batch_idx: 370 |  Loss: (0.7767) |  Loss2: (0.0000) | Acc: (72.00%) (34338/47488)
Epoch: 18 | Batch_idx: 380 |  Loss: (0.7783) |  Loss2: (0.0000) | Acc: (72.00%) (35238/48768)
Epoch: 18 | Batch_idx: 390 |  Loss: (0.7779) |  Loss2: (0.0000) | Acc: (72.00%) (36131/50000)
# TEST : Loss: (0.8071) | Acc: (71.00%) (7146/10000)
percent tensor([0.5229, 0.5255, 0.5251, 0.5180, 0.5265, 0.5267, 0.5289, 0.5200, 0.5247,
        0.5240, 0.5237, 0.5266, 0.5221, 0.5234, 0.5242, 0.5206],
       device='cuda:0') torch.Size([16])
percent tensor([0.5412, 0.5311, 0.4919, 0.5409, 0.5124, 0.5894, 0.5196, 0.5203, 0.5185,
        0.5144, 0.5242, 0.4960, 0.5205, 0.5484, 0.5530, 0.5522],
       device='cuda:0') torch.Size([16])
percent tensor([0.4831, 0.5015, 0.4875, 0.4822, 0.4894, 0.4785, 0.5008, 0.4928, 0.4975,
        0.4910, 0.4924, 0.4903, 0.4887, 0.5058, 0.4898, 0.4861],
       device='cuda:0') torch.Size([16])
percent tensor([0.5140, 0.5041, 0.4917, 0.5007, 0.4999, 0.5380, 0.4965, 0.4919, 0.5018,
        0.5020, 0.5068, 0.4894, 0.5086, 0.5047, 0.5107, 0.5191],
       device='cuda:0') torch.Size([16])
percent tensor([0.5480, 0.5262, 0.5341, 0.5629, 0.5196, 0.6385, 0.5189, 0.5393, 0.5633,
        0.4924, 0.5307, 0.5063, 0.5578, 0.5618, 0.5279, 0.5632],
       device='cuda:0') torch.Size([16])
percent tensor([0.6245, 0.6080, 0.6661, 0.6816, 0.6736, 0.6381, 0.6277, 0.6952, 0.6314,
        0.6124, 0.6069, 0.6389, 0.5972, 0.6136, 0.6434, 0.6279],
       device='cuda:0') torch.Size([16])
percent tensor([0.4795, 0.5285, 0.5829, 0.5950, 0.6324, 0.3566, 0.5686, 0.7073, 0.5104,
        0.5893, 0.4856, 0.5415, 0.4230, 0.4841, 0.5495, 0.5024],
       device='cuda:0') torch.Size([16])
percent tensor([0.9761, 0.9427, 0.9759, 0.9710, 0.9802, 0.9666, 0.9572, 0.9850, 0.9456,
        0.9652, 0.9477, 0.9749, 0.9517, 0.9469, 0.9676, 0.9809],
       device='cuda:0') torch.Size([16])
Epoch: 19 | Batch_idx: 0 |  Loss: (0.5955) |  Loss2: (0.0000) | Acc: (78.00%) (100/128)
Epoch: 19 | Batch_idx: 10 |  Loss: (0.7910) |  Loss2: (0.0000) | Acc: (72.00%) (1015/1408)
Epoch: 19 | Batch_idx: 20 |  Loss: (0.7885) |  Loss2: (0.0000) | Acc: (72.00%) (1941/2688)
Epoch: 19 | Batch_idx: 30 |  Loss: (0.7807) |  Loss2: (0.0000) | Acc: (72.00%) (2874/3968)
Epoch: 19 | Batch_idx: 40 |  Loss: (0.7821) |  Loss2: (0.0000) | Acc: (72.00%) (3811/5248)
Epoch: 19 | Batch_idx: 50 |  Loss: (0.7789) |  Loss2: (0.0000) | Acc: (72.00%) (4738/6528)
Epoch: 19 | Batch_idx: 60 |  Loss: (0.7731) |  Loss2: (0.0000) | Acc: (72.00%) (5666/7808)
Epoch: 19 | Batch_idx: 70 |  Loss: (0.7771) |  Loss2: (0.0000) | Acc: (72.00%) (6581/9088)
Epoch: 19 | Batch_idx: 80 |  Loss: (0.7760) |  Loss2: (0.0000) | Acc: (72.00%) (7514/10368)
Epoch: 19 | Batch_idx: 90 |  Loss: (0.7755) |  Loss2: (0.0000) | Acc: (72.00%) (8447/11648)
Epoch: 19 | Batch_idx: 100 |  Loss: (0.7778) |  Loss2: (0.0000) | Acc: (72.00%) (9369/12928)
Epoch: 19 | Batch_idx: 110 |  Loss: (0.7772) |  Loss2: (0.0000) | Acc: (72.00%) (10290/14208)
Epoch: 19 | Batch_idx: 120 |  Loss: (0.7772) |  Loss2: (0.0000) | Acc: (72.00%) (11215/15488)
Epoch: 19 | Batch_idx: 130 |  Loss: (0.7779) |  Loss2: (0.0000) | Acc: (72.00%) (12128/16768)
Epoch: 19 | Batch_idx: 140 |  Loss: (0.7767) |  Loss2: (0.0000) | Acc: (72.00%) (13060/18048)
Epoch: 19 | Batch_idx: 150 |  Loss: (0.7802) |  Loss2: (0.0000) | Acc: (72.00%) (13979/19328)
Epoch: 19 | Batch_idx: 160 |  Loss: (0.7800) |  Loss2: (0.0000) | Acc: (72.00%) (14882/20608)
Epoch: 19 | Batch_idx: 170 |  Loss: (0.7780) |  Loss2: (0.0000) | Acc: (72.00%) (15824/21888)
Epoch: 19 | Batch_idx: 180 |  Loss: (0.7780) |  Loss2: (0.0000) | Acc: (72.00%) (16753/23168)
Epoch: 19 | Batch_idx: 190 |  Loss: (0.7764) |  Loss2: (0.0000) | Acc: (72.00%) (17675/24448)
Epoch: 19 | Batch_idx: 200 |  Loss: (0.7781) |  Loss2: (0.0000) | Acc: (72.00%) (18576/25728)
Epoch: 19 | Batch_idx: 210 |  Loss: (0.7761) |  Loss2: (0.0000) | Acc: (72.00%) (19509/27008)
Epoch: 19 | Batch_idx: 220 |  Loss: (0.7741) |  Loss2: (0.0000) | Acc: (72.00%) (20467/28288)
Epoch: 19 | Batch_idx: 230 |  Loss: (0.7743) |  Loss2: (0.0000) | Acc: (72.00%) (21396/29568)
Epoch: 19 | Batch_idx: 240 |  Loss: (0.7752) |  Loss2: (0.0000) | Acc: (72.00%) (22316/30848)
Epoch: 19 | Batch_idx: 250 |  Loss: (0.7762) |  Loss2: (0.0000) | Acc: (72.00%) (23227/32128)
Epoch: 19 | Batch_idx: 260 |  Loss: (0.7755) |  Loss2: (0.0000) | Acc: (72.00%) (24156/33408)
Epoch: 19 | Batch_idx: 270 |  Loss: (0.7740) |  Loss2: (0.0000) | Acc: (72.00%) (25098/34688)
Epoch: 19 | Batch_idx: 280 |  Loss: (0.7753) |  Loss2: (0.0000) | Acc: (72.00%) (26020/35968)
Epoch: 19 | Batch_idx: 290 |  Loss: (0.7763) |  Loss2: (0.0000) | Acc: (72.00%) (26938/37248)
Epoch: 19 | Batch_idx: 300 |  Loss: (0.7748) |  Loss2: (0.0000) | Acc: (72.00%) (27884/38528)
Epoch: 19 | Batch_idx: 310 |  Loss: (0.7737) |  Loss2: (0.0000) | Acc: (72.00%) (28826/39808)
Epoch: 19 | Batch_idx: 320 |  Loss: (0.7720) |  Loss2: (0.0000) | Acc: (72.00%) (29771/41088)
Epoch: 19 | Batch_idx: 330 |  Loss: (0.7717) |  Loss2: (0.0000) | Acc: (72.00%) (30722/42368)
Epoch: 19 | Batch_idx: 340 |  Loss: (0.7730) |  Loss2: (0.0000) | Acc: (72.00%) (31628/43648)
Epoch: 19 | Batch_idx: 350 |  Loss: (0.7731) |  Loss2: (0.0000) | Acc: (72.00%) (32545/44928)
Epoch: 19 | Batch_idx: 360 |  Loss: (0.7720) |  Loss2: (0.0000) | Acc: (72.00%) (33478/46208)
Epoch: 19 | Batch_idx: 370 |  Loss: (0.7714) |  Loss2: (0.0000) | Acc: (72.00%) (34414/47488)
Epoch: 19 | Batch_idx: 380 |  Loss: (0.7722) |  Loss2: (0.0000) | Acc: (72.00%) (35320/48768)
Epoch: 19 | Batch_idx: 390 |  Loss: (0.7728) |  Loss2: (0.0000) | Acc: (72.00%) (36192/50000)
# TEST : Loss: (0.8033) | Acc: (71.00%) (7147/10000)
percent tensor([0.5241, 0.5266, 0.5270, 0.5188, 0.5284, 0.5286, 0.5306, 0.5209, 0.5258,
        0.5253, 0.5248, 0.5285, 0.5231, 0.5242, 0.5256, 0.5216],
       device='cuda:0') torch.Size([16])
percent tensor([0.5395, 0.5278, 0.4892, 0.5395, 0.5105, 0.5900, 0.5168, 0.5178, 0.5155,
        0.5112, 0.5213, 0.4938, 0.5180, 0.5452, 0.5519, 0.5508],
       device='cuda:0') torch.Size([16])
percent tensor([0.4815, 0.5012, 0.4853, 0.4802, 0.4870, 0.4757, 0.4998, 0.4912, 0.4970,
        0.4897, 0.4915, 0.4881, 0.4876, 0.5065, 0.4880, 0.4846],
       device='cuda:0') torch.Size([16])
percent tensor([0.5174, 0.5066, 0.4930, 0.5026, 0.5022, 0.5430, 0.4987, 0.4933, 0.5039,
        0.5042, 0.5095, 0.4911, 0.5114, 0.5070, 0.5140, 0.5228],
       device='cuda:0') torch.Size([16])
percent tensor([0.5507, 0.5326, 0.5340, 0.5596, 0.5176, 0.6389, 0.5232, 0.5384, 0.5679,
        0.4955, 0.5378, 0.5104, 0.5663, 0.5659, 0.5324, 0.5654],
       device='cuda:0') torch.Size([16])
percent tensor([0.6331, 0.6146, 0.6763, 0.6923, 0.6847, 0.6497, 0.6361, 0.7063, 0.6395,
        0.6196, 0.6143, 0.6478, 0.6037, 0.6205, 0.6533, 0.6368],
       device='cuda:0') torch.Size([16])
percent tensor([0.5075, 0.5481, 0.5876, 0.6008, 0.6339, 0.3824, 0.5800, 0.6989, 0.5319,
        0.6098, 0.5105, 0.5468, 0.4586, 0.5134, 0.5511, 0.5224],
       device='cuda:0') torch.Size([16])
percent tensor([0.9815, 0.9520, 0.9806, 0.9767, 0.9847, 0.9737, 0.9645, 0.9881, 0.9551,
        0.9716, 0.9580, 0.9798, 0.9609, 0.9556, 0.9741, 0.9851],
       device='cuda:0') torch.Size([16])
True Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=128, out_features=16, bias=False)
False Linear(in_features=16, out_features=2, bias=False)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=128, out_features=16, bias=False)
False Linear(in_features=16, out_features=2, bias=False)
True Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=256, out_features=32, bias=False)
False Linear(in_features=32, out_features=2, bias=False)
True Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=256, out_features=32, bias=False)
False Linear(in_features=32, out_features=2, bias=False)
True Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=512, out_features=64, bias=False)
False Linear(in_features=64, out_features=2, bias=False)
True Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=512, out_features=64, bias=False)
False Linear(in_features=64, out_features=2, bias=False)
True Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1024, out_features=128, bias=False)
False Linear(in_features=128, out_features=2, bias=False)
True Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1024, out_features=128, bias=False)
False Linear(in_features=128, out_features=2, bias=False)
True Linear(in_features=512, out_features=10, bias=True)
Epoch: 20 | Batch_idx: 0 |  Loss: (0.6924) |  Loss2: (0.0000) | Acc: (78.00%) (100/128)
Epoch: 20 | Batch_idx: 10 |  Loss: (0.7417) |  Loss2: (0.0000) | Acc: (73.00%) (1036/1408)
Epoch: 20 | Batch_idx: 20 |  Loss: (0.7844) |  Loss2: (0.0000) | Acc: (71.00%) (1931/2688)
Epoch: 20 | Batch_idx: 30 |  Loss: (0.7914) |  Loss2: (0.0000) | Acc: (71.00%) (2840/3968)
Epoch: 20 | Batch_idx: 40 |  Loss: (0.7906) |  Loss2: (0.0000) | Acc: (71.00%) (3770/5248)
Epoch: 20 | Batch_idx: 50 |  Loss: (0.7946) |  Loss2: (0.0000) | Acc: (71.00%) (4682/6528)
Epoch: 20 | Batch_idx: 60 |  Loss: (0.8024) |  Loss2: (0.0000) | Acc: (71.00%) (5583/7808)
Epoch: 20 | Batch_idx: 70 |  Loss: (0.7983) |  Loss2: (0.0000) | Acc: (71.00%) (6503/9088)
Epoch: 20 | Batch_idx: 80 |  Loss: (0.7959) |  Loss2: (0.0000) | Acc: (71.00%) (7413/10368)
Epoch: 20 | Batch_idx: 90 |  Loss: (0.7995) |  Loss2: (0.0000) | Acc: (71.00%) (8321/11648)
Epoch: 20 | Batch_idx: 100 |  Loss: (0.8014) |  Loss2: (0.0000) | Acc: (71.00%) (9223/12928)
Epoch: 20 | Batch_idx: 110 |  Loss: (0.8001) |  Loss2: (0.0000) | Acc: (71.00%) (10147/14208)
Epoch: 20 | Batch_idx: 120 |  Loss: (0.7985) |  Loss2: (0.0000) | Acc: (71.00%) (11070/15488)
Epoch: 20 | Batch_idx: 130 |  Loss: (0.7996) |  Loss2: (0.0000) | Acc: (71.00%) (11990/16768)
Epoch: 20 | Batch_idx: 140 |  Loss: (0.8002) |  Loss2: (0.0000) | Acc: (71.00%) (12912/18048)
Epoch: 20 | Batch_idx: 150 |  Loss: (0.8017) |  Loss2: (0.0000) | Acc: (71.00%) (13813/19328)
Epoch: 20 | Batch_idx: 160 |  Loss: (0.7970) |  Loss2: (0.0000) | Acc: (71.00%) (14770/20608)
Epoch: 20 | Batch_idx: 170 |  Loss: (0.7977) |  Loss2: (0.0000) | Acc: (71.00%) (15665/21888)
Epoch: 20 | Batch_idx: 180 |  Loss: (0.7970) |  Loss2: (0.0000) | Acc: (71.00%) (16599/23168)
Epoch: 20 | Batch_idx: 190 |  Loss: (0.7953) |  Loss2: (0.0000) | Acc: (71.00%) (17524/24448)
Epoch: 20 | Batch_idx: 200 |  Loss: (0.7935) |  Loss2: (0.0000) | Acc: (71.00%) (18465/25728)
Epoch: 20 | Batch_idx: 210 |  Loss: (0.7959) |  Loss2: (0.0000) | Acc: (71.00%) (19374/27008)
Epoch: 20 | Batch_idx: 220 |  Loss: (0.7944) |  Loss2: (0.0000) | Acc: (71.00%) (20300/28288)
Epoch: 20 | Batch_idx: 230 |  Loss: (0.7932) |  Loss2: (0.0000) | Acc: (71.00%) (21235/29568)
Epoch: 20 | Batch_idx: 240 |  Loss: (0.7921) |  Loss2: (0.0000) | Acc: (71.00%) (22162/30848)
Epoch: 20 | Batch_idx: 250 |  Loss: (0.7919) |  Loss2: (0.0000) | Acc: (71.00%) (23096/32128)
Epoch: 20 | Batch_idx: 260 |  Loss: (0.7910) |  Loss2: (0.0000) | Acc: (71.00%) (24016/33408)
Epoch: 20 | Batch_idx: 270 |  Loss: (0.7910) |  Loss2: (0.0000) | Acc: (71.00%) (24943/34688)
Epoch: 20 | Batch_idx: 280 |  Loss: (0.7902) |  Loss2: (0.0000) | Acc: (71.00%) (25875/35968)
Epoch: 20 | Batch_idx: 290 |  Loss: (0.7886) |  Loss2: (0.0000) | Acc: (71.00%) (26806/37248)
Epoch: 20 | Batch_idx: 300 |  Loss: (0.7864) |  Loss2: (0.0000) | Acc: (72.00%) (27765/38528)
Epoch: 20 | Batch_idx: 310 |  Loss: (0.7849) |  Loss2: (0.0000) | Acc: (72.00%) (28717/39808)
Epoch: 20 | Batch_idx: 320 |  Loss: (0.7844) |  Loss2: (0.0000) | Acc: (72.00%) (29640/41088)
Epoch: 20 | Batch_idx: 330 |  Loss: (0.7827) |  Loss2: (0.0000) | Acc: (72.00%) (30577/42368)
Epoch: 20 | Batch_idx: 340 |  Loss: (0.7830) |  Loss2: (0.0000) | Acc: (72.00%) (31482/43648)
Epoch: 20 | Batch_idx: 350 |  Loss: (0.7817) |  Loss2: (0.0000) | Acc: (72.00%) (32418/44928)
Epoch: 20 | Batch_idx: 360 |  Loss: (0.7814) |  Loss2: (0.0000) | Acc: (72.00%) (33359/46208)
Epoch: 20 | Batch_idx: 370 |  Loss: (0.7804) |  Loss2: (0.0000) | Acc: (72.00%) (34312/47488)
Epoch: 20 | Batch_idx: 380 |  Loss: (0.7792) |  Loss2: (0.0000) | Acc: (72.00%) (35256/48768)
Epoch: 20 | Batch_idx: 390 |  Loss: (0.7775) |  Loss2: (0.0000) | Acc: (72.00%) (36207/50000)
=> saving checkpoint 'drive/app/torch/save_Routing_Gate_2/checkpoint_020.pth.tar'
# TEST : Loss: (0.8777) | Acc: (69.00%) (6963/10000)
percent tensor([0.5232, 0.5263, 0.5240, 0.5194, 0.5256, 0.5277, 0.5283, 0.5203, 0.5244,
        0.5243, 0.5242, 0.5250, 0.5222, 0.5241, 0.5253, 0.5218],
       device='cuda:0') torch.Size([16])
percent tensor([0.5416, 0.5223, 0.5024, 0.5513, 0.5227, 0.5914, 0.5165, 0.5236, 0.5177,
        0.5126, 0.5210, 0.5030, 0.5189, 0.5365, 0.5507, 0.5511],
       device='cuda:0') torch.Size([16])
percent tensor([0.4835, 0.5000, 0.4830, 0.4810, 0.4853, 0.4775, 0.4972, 0.4894, 0.4956,
        0.4878, 0.4905, 0.4864, 0.4885, 0.5022, 0.4884, 0.4842],
       device='cuda:0') torch.Size([16])
percent tensor([0.5191, 0.5069, 0.4933, 0.5087, 0.5022, 0.5443, 0.4998, 0.4971, 0.5063,
        0.5052, 0.5122, 0.4915, 0.5141, 0.5092, 0.5137, 0.5272],
       device='cuda:0') torch.Size([16])
percent tensor([0.5596, 0.5563, 0.5294, 0.5546, 0.5226, 0.6333, 0.5414, 0.5376, 0.5843,
        0.5067, 0.5527, 0.5234, 0.5831, 0.5672, 0.5390, 0.5766],
       device='cuda:0') torch.Size([16])
percent tensor([0.6249, 0.6046, 0.6755, 0.6843, 0.6877, 0.6527, 0.6281, 0.6822, 0.6324,
        0.6109, 0.6165, 0.6503, 0.5990, 0.6155, 0.6429, 0.6278],
       device='cuda:0') torch.Size([16])
percent tensor([0.4821, 0.4642, 0.5820, 0.5586, 0.6157, 0.3996, 0.5353, 0.6226, 0.4924,
        0.5444, 0.4920, 0.5474, 0.4040, 0.4931, 0.5289, 0.4823],
       device='cuda:0') torch.Size([16])
percent tensor([0.9800, 0.9438, 0.9750, 0.9811, 0.9825, 0.9695, 0.9717, 0.9849, 0.9497,
        0.9709, 0.9585, 0.9779, 0.9574, 0.9533, 0.9738, 0.9836],
       device='cuda:0') torch.Size([16])
Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 3, 3, 3]) tensor(171.3572, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(781.8544, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(780.9850, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([128, 64, 3, 3]) tensor(1532.1262, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([128, 64, 1, 1]) tensor(508.2292, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([128, 128, 3, 3]) tensor(2173.0630, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([256, 128, 3, 3]) tensor(4313.8174, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([256, 128, 1, 1]) tensor(1437.5449, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([256, 256, 3, 3]) tensor(6098.7793, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([512, 256, 3, 3]) tensor(12183.0586, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([512, 256, 1, 1]) tensor(4060.2410, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([512, 512, 3, 3]) tensor(17194.8633, device='cuda:0', grad_fn=<NormBackward0>)
Epoch: 21 | Batch_idx: 0 |  Loss: (0.8501) |  Loss2: (0.0000) | Acc: (68.00%) (88/128)
Epoch: 21 | Batch_idx: 10 |  Loss: (0.7501) |  Loss2: (0.0000) | Acc: (72.00%) (1019/1408)
Epoch: 21 | Batch_idx: 20 |  Loss: (0.7555) |  Loss2: (0.0000) | Acc: (72.00%) (1948/2688)
Epoch: 21 | Batch_idx: 30 |  Loss: (0.7513) |  Loss2: (0.0000) | Acc: (73.00%) (2903/3968)
Epoch: 21 | Batch_idx: 40 |  Loss: (0.7464) |  Loss2: (0.0000) | Acc: (73.00%) (3850/5248)
Epoch: 21 | Batch_idx: 50 |  Loss: (0.7319) |  Loss2: (0.0000) | Acc: (73.00%) (4828/6528)
Epoch: 21 | Batch_idx: 60 |  Loss: (0.7299) |  Loss2: (0.0000) | Acc: (74.00%) (5793/7808)
Epoch: 21 | Batch_idx: 70 |  Loss: (0.7285) |  Loss2: (0.0000) | Acc: (74.00%) (6759/9088)
Epoch: 21 | Batch_idx: 80 |  Loss: (0.7256) |  Loss2: (0.0000) | Acc: (74.00%) (7719/10368)
Epoch: 21 | Batch_idx: 90 |  Loss: (0.7239) |  Loss2: (0.0000) | Acc: (74.00%) (8683/11648)
Epoch: 21 | Batch_idx: 100 |  Loss: (0.7241) |  Loss2: (0.0000) | Acc: (74.00%) (9638/12928)
Epoch: 21 | Batch_idx: 110 |  Loss: (0.7233) |  Loss2: (0.0000) | Acc: (74.00%) (10587/14208)
Epoch: 21 | Batch_idx: 120 |  Loss: (0.7266) |  Loss2: (0.0000) | Acc: (74.00%) (11524/15488)
Epoch: 21 | Batch_idx: 130 |  Loss: (0.7255) |  Loss2: (0.0000) | Acc: (74.00%) (12490/16768)
Epoch: 21 | Batch_idx: 140 |  Loss: (0.7257) |  Loss2: (0.0000) | Acc: (74.00%) (13443/18048)
Epoch: 21 | Batch_idx: 150 |  Loss: (0.7304) |  Loss2: (0.0000) | Acc: (74.00%) (14367/19328)
Epoch: 21 | Batch_idx: 160 |  Loss: (0.7307) |  Loss2: (0.0000) | Acc: (74.00%) (15318/20608)
Epoch: 21 | Batch_idx: 170 |  Loss: (0.7290) |  Loss2: (0.0000) | Acc: (74.00%) (16283/21888)
Epoch: 21 | Batch_idx: 180 |  Loss: (0.7304) |  Loss2: (0.0000) | Acc: (74.00%) (17221/23168)
Epoch: 21 | Batch_idx: 190 |  Loss: (0.7295) |  Loss2: (0.0000) | Acc: (74.00%) (18173/24448)
Epoch: 21 | Batch_idx: 200 |  Loss: (0.7296) |  Loss2: (0.0000) | Acc: (74.00%) (19127/25728)
Epoch: 21 | Batch_idx: 210 |  Loss: (0.7291) |  Loss2: (0.0000) | Acc: (74.00%) (20106/27008)
Epoch: 21 | Batch_idx: 220 |  Loss: (0.7299) |  Loss2: (0.0000) | Acc: (74.00%) (21052/28288)
Epoch: 21 | Batch_idx: 230 |  Loss: (0.7299) |  Loss2: (0.0000) | Acc: (74.00%) (22010/29568)
Epoch: 21 | Batch_idx: 240 |  Loss: (0.7298) |  Loss2: (0.0000) | Acc: (74.00%) (22965/30848)
Epoch: 21 | Batch_idx: 250 |  Loss: (0.7266) |  Loss2: (0.0000) | Acc: (74.00%) (23962/32128)
Epoch: 21 | Batch_idx: 260 |  Loss: (0.7281) |  Loss2: (0.0000) | Acc: (74.00%) (24901/33408)
Epoch: 21 | Batch_idx: 270 |  Loss: (0.7287) |  Loss2: (0.0000) | Acc: (74.00%) (25857/34688)
Epoch: 21 | Batch_idx: 280 |  Loss: (0.7288) |  Loss2: (0.0000) | Acc: (74.00%) (26810/35968)
Epoch: 21 | Batch_idx: 290 |  Loss: (0.7295) |  Loss2: (0.0000) | Acc: (74.00%) (27749/37248)
Epoch: 21 | Batch_idx: 300 |  Loss: (0.7307) |  Loss2: (0.0000) | Acc: (74.00%) (28669/38528)
Epoch: 21 | Batch_idx: 310 |  Loss: (0.7308) |  Loss2: (0.0000) | Acc: (74.00%) (29607/39808)
Epoch: 21 | Batch_idx: 320 |  Loss: (0.7301) |  Loss2: (0.0000) | Acc: (74.00%) (30570/41088)
Epoch: 21 | Batch_idx: 330 |  Loss: (0.7293) |  Loss2: (0.0000) | Acc: (74.00%) (31526/42368)
Epoch: 21 | Batch_idx: 340 |  Loss: (0.7294) |  Loss2: (0.0000) | Acc: (74.00%) (32485/43648)
Epoch: 21 | Batch_idx: 350 |  Loss: (0.7293) |  Loss2: (0.0000) | Acc: (74.00%) (33442/44928)
Epoch: 21 | Batch_idx: 360 |  Loss: (0.7288) |  Loss2: (0.0000) | Acc: (74.00%) (34395/46208)
Epoch: 21 | Batch_idx: 370 |  Loss: (0.7280) |  Loss2: (0.0000) | Acc: (74.00%) (35355/47488)
Epoch: 21 | Batch_idx: 380 |  Loss: (0.7274) |  Loss2: (0.0000) | Acc: (74.00%) (36315/48768)
Epoch: 21 | Batch_idx: 390 |  Loss: (0.7276) |  Loss2: (0.0000) | Acc: (74.00%) (37229/50000)
# TEST : Loss: (0.7490) | Acc: (73.00%) (7373/10000)
percent tensor([0.5232, 0.5262, 0.5232, 0.5195, 0.5250, 0.5281, 0.5277, 0.5201, 0.5242,
        0.5239, 0.5244, 0.5245, 0.5223, 0.5243, 0.5253, 0.5221],
       device='cuda:0') torch.Size([16])
percent tensor([0.5380, 0.5235, 0.4961, 0.5487, 0.5189, 0.5888, 0.5155, 0.5214, 0.5139,
        0.5112, 0.5186, 0.4972, 0.5167, 0.5435, 0.5501, 0.5488],
       device='cuda:0') torch.Size([16])
percent tensor([0.4827, 0.5015, 0.4849, 0.4822, 0.4878, 0.4798, 0.4986, 0.4905, 0.4953,
        0.4891, 0.4906, 0.4878, 0.4886, 0.5035, 0.4902, 0.4845],
       device='cuda:0') torch.Size([16])
percent tensor([0.5165, 0.5071, 0.4898, 0.5030, 0.4999, 0.5392, 0.5002, 0.4937, 0.5068,
        0.5053, 0.5119, 0.4909, 0.5130, 0.5137, 0.5114, 0.5240],
       device='cuda:0') torch.Size([16])
percent tensor([0.5532, 0.5525, 0.5185, 0.5578, 0.5024, 0.6239, 0.5399, 0.5179, 0.5802,
        0.5092, 0.5495, 0.5202, 0.5871, 0.5892, 0.5302, 0.5681],
       device='cuda:0') torch.Size([16])
percent tensor([0.6326, 0.6180, 0.6660, 0.6923, 0.6781, 0.6482, 0.6346, 0.6921, 0.6347,
        0.6194, 0.6253, 0.6532, 0.6062, 0.6384, 0.6564, 0.6372],
       device='cuda:0') torch.Size([16])
percent tensor([0.5280, 0.5438, 0.5915, 0.5932, 0.6185, 0.4094, 0.5718, 0.6822, 0.4994,
        0.6057, 0.5236, 0.5688, 0.4362, 0.5174, 0.5660, 0.5372],
       device='cuda:0') torch.Size([16])
percent tensor([0.9768, 0.9575, 0.9808, 0.9813, 0.9822, 0.9727, 0.9710, 0.9898, 0.9568,
        0.9748, 0.9614, 0.9812, 0.9565, 0.9585, 0.9794, 0.9867],
       device='cuda:0') torch.Size([16])
Epoch: 22 | Batch_idx: 0 |  Loss: (0.6090) |  Loss2: (0.0000) | Acc: (78.00%) (100/128)
Epoch: 22 | Batch_idx: 10 |  Loss: (0.6428) |  Loss2: (0.0000) | Acc: (77.00%) (1096/1408)
Epoch: 22 | Batch_idx: 20 |  Loss: (0.6491) |  Loss2: (0.0000) | Acc: (77.00%) (2075/2688)
Epoch: 22 | Batch_idx: 30 |  Loss: (0.6585) |  Loss2: (0.0000) | Acc: (77.00%) (3056/3968)
Epoch: 22 | Batch_idx: 40 |  Loss: (0.6692) |  Loss2: (0.0000) | Acc: (76.00%) (4024/5248)
Epoch: 22 | Batch_idx: 50 |  Loss: (0.6729) |  Loss2: (0.0000) | Acc: (76.00%) (4987/6528)
Epoch: 22 | Batch_idx: 60 |  Loss: (0.6848) |  Loss2: (0.0000) | Acc: (76.00%) (5941/7808)
Epoch: 22 | Batch_idx: 70 |  Loss: (0.6865) |  Loss2: (0.0000) | Acc: (75.00%) (6897/9088)
Epoch: 22 | Batch_idx: 80 |  Loss: (0.6928) |  Loss2: (0.0000) | Acc: (75.00%) (7842/10368)
Epoch: 22 | Batch_idx: 90 |  Loss: (0.6942) |  Loss2: (0.0000) | Acc: (75.00%) (8810/11648)
Epoch: 22 | Batch_idx: 100 |  Loss: (0.6936) |  Loss2: (0.0000) | Acc: (75.00%) (9798/12928)
Epoch: 22 | Batch_idx: 110 |  Loss: (0.6907) |  Loss2: (0.0000) | Acc: (75.00%) (10792/14208)
Epoch: 22 | Batch_idx: 120 |  Loss: (0.6903) |  Loss2: (0.0000) | Acc: (75.00%) (11763/15488)
Epoch: 22 | Batch_idx: 130 |  Loss: (0.6895) |  Loss2: (0.0000) | Acc: (75.00%) (12730/16768)
Epoch: 22 | Batch_idx: 140 |  Loss: (0.6861) |  Loss2: (0.0000) | Acc: (76.00%) (13737/18048)
Epoch: 22 | Batch_idx: 150 |  Loss: (0.6841) |  Loss2: (0.0000) | Acc: (76.00%) (14716/19328)
Epoch: 22 | Batch_idx: 160 |  Loss: (0.6862) |  Loss2: (0.0000) | Acc: (76.00%) (15665/20608)
Epoch: 22 | Batch_idx: 170 |  Loss: (0.6872) |  Loss2: (0.0000) | Acc: (75.00%) (16630/21888)
Epoch: 22 | Batch_idx: 180 |  Loss: (0.6865) |  Loss2: (0.0000) | Acc: (76.00%) (17630/23168)
Epoch: 22 | Batch_idx: 190 |  Loss: (0.6884) |  Loss2: (0.0000) | Acc: (76.00%) (18582/24448)
Epoch: 22 | Batch_idx: 200 |  Loss: (0.6880) |  Loss2: (0.0000) | Acc: (75.00%) (19534/25728)
Epoch: 22 | Batch_idx: 210 |  Loss: (0.6897) |  Loss2: (0.0000) | Acc: (75.00%) (20479/27008)
Epoch: 22 | Batch_idx: 220 |  Loss: (0.6915) |  Loss2: (0.0000) | Acc: (75.00%) (21431/28288)
Epoch: 22 | Batch_idx: 230 |  Loss: (0.6897) |  Loss2: (0.0000) | Acc: (75.00%) (22417/29568)
Epoch: 22 | Batch_idx: 240 |  Loss: (0.6894) |  Loss2: (0.0000) | Acc: (75.00%) (23401/30848)
Epoch: 22 | Batch_idx: 250 |  Loss: (0.6883) |  Loss2: (0.0000) | Acc: (75.00%) (24382/32128)
Epoch: 22 | Batch_idx: 260 |  Loss: (0.6887) |  Loss2: (0.0000) | Acc: (75.00%) (25347/33408)
Epoch: 22 | Batch_idx: 270 |  Loss: (0.6887) |  Loss2: (0.0000) | Acc: (75.00%) (26298/34688)
Epoch: 22 | Batch_idx: 280 |  Loss: (0.6892) |  Loss2: (0.0000) | Acc: (75.00%) (27267/35968)
Epoch: 22 | Batch_idx: 290 |  Loss: (0.6893) |  Loss2: (0.0000) | Acc: (75.00%) (28235/37248)
Epoch: 22 | Batch_idx: 300 |  Loss: (0.6897) |  Loss2: (0.0000) | Acc: (75.00%) (29206/38528)
Epoch: 22 | Batch_idx: 310 |  Loss: (0.6889) |  Loss2: (0.0000) | Acc: (75.00%) (30201/39808)
Epoch: 22 | Batch_idx: 320 |  Loss: (0.6880) |  Loss2: (0.0000) | Acc: (75.00%) (31170/41088)
Epoch: 22 | Batch_idx: 330 |  Loss: (0.6867) |  Loss2: (0.0000) | Acc: (75.00%) (32164/42368)
Epoch: 22 | Batch_idx: 340 |  Loss: (0.6867) |  Loss2: (0.0000) | Acc: (75.00%) (33133/43648)
Epoch: 22 | Batch_idx: 350 |  Loss: (0.6862) |  Loss2: (0.0000) | Acc: (75.00%) (34116/44928)
Epoch: 22 | Batch_idx: 360 |  Loss: (0.6847) |  Loss2: (0.0000) | Acc: (75.00%) (35107/46208)
Epoch: 22 | Batch_idx: 370 |  Loss: (0.6858) |  Loss2: (0.0000) | Acc: (75.00%) (36069/47488)
Epoch: 22 | Batch_idx: 380 |  Loss: (0.6851) |  Loss2: (0.0000) | Acc: (76.00%) (37064/48768)
Epoch: 22 | Batch_idx: 390 |  Loss: (0.6857) |  Loss2: (0.0000) | Acc: (75.00%) (37993/50000)
# TEST : Loss: (0.8557) | Acc: (71.00%) (7144/10000)
percent tensor([0.5247, 0.5257, 0.5279, 0.5213, 0.5286, 0.5286, 0.5287, 0.5217, 0.5253,
        0.5251, 0.5251, 0.5277, 0.5238, 0.5221, 0.5258, 0.5229],
       device='cuda:0') torch.Size([16])
percent tensor([0.5395, 0.5247, 0.4976, 0.5450, 0.5201, 0.5863, 0.5189, 0.5224, 0.5194,
        0.5117, 0.5213, 0.5008, 0.5180, 0.5478, 0.5482, 0.5472],
       device='cuda:0') torch.Size([16])
percent tensor([0.4825, 0.4998, 0.4851, 0.4809, 0.4859, 0.4772, 0.4982, 0.4896, 0.4943,
        0.4884, 0.4903, 0.4877, 0.4890, 0.5017, 0.4890, 0.4849],
       device='cuda:0') torch.Size([16])
percent tensor([0.5175, 0.5072, 0.4920, 0.5048, 0.5012, 0.5347, 0.4998, 0.4959, 0.5049,
        0.5055, 0.5116, 0.4900, 0.5121, 0.5081, 0.5112, 0.5215],
       device='cuda:0') torch.Size([16])
percent tensor([0.5323, 0.5296, 0.5260, 0.5392, 0.5007, 0.6003, 0.5204, 0.5139, 0.5650,
        0.4930, 0.5368, 0.5145, 0.5672, 0.5663, 0.5088, 0.5446],
       device='cuda:0') torch.Size([16])
percent tensor([0.6379, 0.6220, 0.6722, 0.6764, 0.6823, 0.6484, 0.6418, 0.6942, 0.6450,
        0.6268, 0.6287, 0.6596, 0.6070, 0.6512, 0.6552, 0.6418],
       device='cuda:0') torch.Size([16])
percent tensor([0.5749, 0.5979, 0.5992, 0.5941, 0.6426, 0.4782, 0.6130, 0.6983, 0.5623,
        0.6413, 0.5653, 0.6114, 0.4806, 0.5810, 0.6056, 0.5858],
       device='cuda:0') torch.Size([16])
percent tensor([0.9846, 0.9679, 0.9808, 0.9822, 0.9817, 0.9738, 0.9782, 0.9911, 0.9556,
        0.9809, 0.9656, 0.9827, 0.9570, 0.9684, 0.9791, 0.9867],
       device='cuda:0') torch.Size([16])
Epoch: 23 | Batch_idx: 0 |  Loss: (0.6451) |  Loss2: (0.0000) | Acc: (77.00%) (99/128)
Epoch: 23 | Batch_idx: 10 |  Loss: (0.6319) |  Loss2: (0.0000) | Acc: (78.00%) (1101/1408)
Epoch: 23 | Batch_idx: 20 |  Loss: (0.6394) |  Loss2: (0.0000) | Acc: (78.00%) (2103/2688)
Epoch: 23 | Batch_idx: 30 |  Loss: (0.6418) |  Loss2: (0.0000) | Acc: (78.00%) (3102/3968)
Epoch: 23 | Batch_idx: 40 |  Loss: (0.6405) |  Loss2: (0.0000) | Acc: (78.00%) (4110/5248)
Epoch: 23 | Batch_idx: 50 |  Loss: (0.6392) |  Loss2: (0.0000) | Acc: (77.00%) (5082/6528)
Epoch: 23 | Batch_idx: 60 |  Loss: (0.6439) |  Loss2: (0.0000) | Acc: (77.00%) (6064/7808)
Epoch: 23 | Batch_idx: 70 |  Loss: (0.6489) |  Loss2: (0.0000) | Acc: (77.00%) (7040/9088)
Epoch: 23 | Batch_idx: 80 |  Loss: (0.6488) |  Loss2: (0.0000) | Acc: (77.00%) (8033/10368)
Epoch: 23 | Batch_idx: 90 |  Loss: (0.6502) |  Loss2: (0.0000) | Acc: (77.00%) (9019/11648)
Epoch: 23 | Batch_idx: 100 |  Loss: (0.6489) |  Loss2: (0.0000) | Acc: (77.00%) (10017/12928)
Epoch: 23 | Batch_idx: 110 |  Loss: (0.6473) |  Loss2: (0.0000) | Acc: (77.00%) (11017/14208)
Epoch: 23 | Batch_idx: 120 |  Loss: (0.6521) |  Loss2: (0.0000) | Acc: (77.00%) (11957/15488)
Epoch: 23 | Batch_idx: 130 |  Loss: (0.6550) |  Loss2: (0.0000) | Acc: (77.00%) (12934/16768)
Epoch: 23 | Batch_idx: 140 |  Loss: (0.6541) |  Loss2: (0.0000) | Acc: (77.00%) (13928/18048)
Epoch: 23 | Batch_idx: 150 |  Loss: (0.6556) |  Loss2: (0.0000) | Acc: (77.00%) (14925/19328)
Epoch: 23 | Batch_idx: 160 |  Loss: (0.6609) |  Loss2: (0.0000) | Acc: (76.00%) (15853/20608)
Epoch: 23 | Batch_idx: 170 |  Loss: (0.6585) |  Loss2: (0.0000) | Acc: (77.00%) (16856/21888)
Epoch: 23 | Batch_idx: 180 |  Loss: (0.6570) |  Loss2: (0.0000) | Acc: (76.00%) (17838/23168)
Epoch: 23 | Batch_idx: 190 |  Loss: (0.6568) |  Loss2: (0.0000) | Acc: (76.00%) (18822/24448)
Epoch: 23 | Batch_idx: 200 |  Loss: (0.6563) |  Loss2: (0.0000) | Acc: (76.00%) (19807/25728)
Epoch: 23 | Batch_idx: 210 |  Loss: (0.6545) |  Loss2: (0.0000) | Acc: (77.00%) (20813/27008)
Epoch: 23 | Batch_idx: 220 |  Loss: (0.6556) |  Loss2: (0.0000) | Acc: (77.00%) (21788/28288)
Epoch: 23 | Batch_idx: 230 |  Loss: (0.6549) |  Loss2: (0.0000) | Acc: (77.00%) (22782/29568)
Epoch: 23 | Batch_idx: 240 |  Loss: (0.6542) |  Loss2: (0.0000) | Acc: (77.00%) (23767/30848)
Epoch: 23 | Batch_idx: 250 |  Loss: (0.6531) |  Loss2: (0.0000) | Acc: (77.00%) (24772/32128)
Epoch: 23 | Batch_idx: 260 |  Loss: (0.6520) |  Loss2: (0.0000) | Acc: (77.00%) (25778/33408)
Epoch: 23 | Batch_idx: 270 |  Loss: (0.6527) |  Loss2: (0.0000) | Acc: (77.00%) (26753/34688)
Epoch: 23 | Batch_idx: 280 |  Loss: (0.6531) |  Loss2: (0.0000) | Acc: (77.00%) (27739/35968)
Epoch: 23 | Batch_idx: 290 |  Loss: (0.6521) |  Loss2: (0.0000) | Acc: (77.00%) (28720/37248)
Epoch: 23 | Batch_idx: 300 |  Loss: (0.6511) |  Loss2: (0.0000) | Acc: (77.00%) (29726/38528)
Epoch: 23 | Batch_idx: 310 |  Loss: (0.6506) |  Loss2: (0.0000) | Acc: (77.00%) (30718/39808)
Epoch: 23 | Batch_idx: 320 |  Loss: (0.6511) |  Loss2: (0.0000) | Acc: (77.00%) (31707/41088)
Epoch: 23 | Batch_idx: 330 |  Loss: (0.6501) |  Loss2: (0.0000) | Acc: (77.00%) (32698/42368)
Epoch: 23 | Batch_idx: 340 |  Loss: (0.6499) |  Loss2: (0.0000) | Acc: (77.00%) (33683/43648)
Epoch: 23 | Batch_idx: 350 |  Loss: (0.6497) |  Loss2: (0.0000) | Acc: (77.00%) (34679/44928)
Epoch: 23 | Batch_idx: 360 |  Loss: (0.6501) |  Loss2: (0.0000) | Acc: (77.00%) (35665/46208)
Epoch: 23 | Batch_idx: 370 |  Loss: (0.6499) |  Loss2: (0.0000) | Acc: (77.00%) (36656/47488)
Epoch: 23 | Batch_idx: 380 |  Loss: (0.6489) |  Loss2: (0.0000) | Acc: (77.00%) (37686/48768)
Epoch: 23 | Batch_idx: 390 |  Loss: (0.6474) |  Loss2: (0.0000) | Acc: (77.00%) (38671/50000)
# TEST : Loss: (0.7106) | Acc: (75.00%) (7516/10000)
percent tensor([0.5243, 0.5263, 0.5263, 0.5208, 0.5273, 0.5283, 0.5287, 0.5217, 0.5248,
        0.5252, 0.5249, 0.5267, 0.5233, 0.5238, 0.5259, 0.5230],
       device='cuda:0') torch.Size([16])
percent tensor([0.5412, 0.5207, 0.5009, 0.5446, 0.5220, 0.5823, 0.5155, 0.5237, 0.5193,
        0.5129, 0.5222, 0.5021, 0.5194, 0.5338, 0.5468, 0.5464],
       device='cuda:0') torch.Size([16])
percent tensor([0.4852, 0.5023, 0.4864, 0.4810, 0.4875, 0.4796, 0.5004, 0.4927, 0.4953,
        0.4901, 0.4919, 0.4884, 0.4908, 0.5045, 0.4908, 0.4865],
       device='cuda:0') torch.Size([16])
percent tensor([0.5174, 0.5073, 0.4979, 0.5082, 0.5060, 0.5359, 0.5009, 0.4982, 0.5070,
        0.5082, 0.5118, 0.4950, 0.5121, 0.5090, 0.5125, 0.5234],
       device='cuda:0') torch.Size([16])
percent tensor([0.5481, 0.5577, 0.5212, 0.5456, 0.5067, 0.6126, 0.5432, 0.5142, 0.5714,
        0.5107, 0.5625, 0.5285, 0.5887, 0.5903, 0.5342, 0.5673],
       device='cuda:0') torch.Size([16])
percent tensor([0.6298, 0.6080, 0.6521, 0.6667, 0.6665, 0.6345, 0.6296, 0.6746, 0.6259,
        0.6152, 0.6181, 0.6378, 0.6019, 0.6251, 0.6421, 0.6333],
       device='cuda:0') torch.Size([16])
percent tensor([0.5264, 0.5301, 0.5847, 0.5740, 0.6097, 0.4376, 0.5641, 0.6593, 0.5053,
        0.5903, 0.4968, 0.5511, 0.4154, 0.5067, 0.5586, 0.5365],
       device='cuda:0') torch.Size([16])
percent tensor([0.9831, 0.9603, 0.9784, 0.9826, 0.9795, 0.9669, 0.9794, 0.9883, 0.9568,
        0.9818, 0.9583, 0.9823, 0.9613, 0.9627, 0.9741, 0.9878],
       device='cuda:0') torch.Size([16])
Epoch: 24 | Batch_idx: 0 |  Loss: (0.6383) |  Loss2: (0.0000) | Acc: (76.00%) (98/128)
Epoch: 24 | Batch_idx: 10 |  Loss: (0.5794) |  Loss2: (0.0000) | Acc: (79.00%) (1113/1408)
Epoch: 24 | Batch_idx: 20 |  Loss: (0.6045) |  Loss2: (0.0000) | Acc: (78.00%) (2115/2688)
Epoch: 24 | Batch_idx: 30 |  Loss: (0.6091) |  Loss2: (0.0000) | Acc: (78.00%) (3132/3968)
Epoch: 24 | Batch_idx: 40 |  Loss: (0.6095) |  Loss2: (0.0000) | Acc: (78.00%) (4137/5248)
Epoch: 24 | Batch_idx: 50 |  Loss: (0.6037) |  Loss2: (0.0000) | Acc: (79.00%) (5166/6528)
Epoch: 24 | Batch_idx: 60 |  Loss: (0.6057) |  Loss2: (0.0000) | Acc: (78.00%) (6166/7808)
Epoch: 24 | Batch_idx: 70 |  Loss: (0.6106) |  Loss2: (0.0000) | Acc: (78.00%) (7159/9088)
Epoch: 24 | Batch_idx: 80 |  Loss: (0.6101) |  Loss2: (0.0000) | Acc: (78.00%) (8166/10368)
Epoch: 24 | Batch_idx: 90 |  Loss: (0.6142) |  Loss2: (0.0000) | Acc: (78.00%) (9153/11648)
Epoch: 24 | Batch_idx: 100 |  Loss: (0.6097) |  Loss2: (0.0000) | Acc: (78.00%) (10182/12928)
Epoch: 24 | Batch_idx: 110 |  Loss: (0.6085) |  Loss2: (0.0000) | Acc: (78.00%) (11201/14208)
Epoch: 24 | Batch_idx: 120 |  Loss: (0.6081) |  Loss2: (0.0000) | Acc: (78.00%) (12211/15488)
Epoch: 24 | Batch_idx: 130 |  Loss: (0.6068) |  Loss2: (0.0000) | Acc: (78.00%) (13219/16768)
Epoch: 24 | Batch_idx: 140 |  Loss: (0.6075) |  Loss2: (0.0000) | Acc: (78.00%) (14220/18048)
Epoch: 24 | Batch_idx: 150 |  Loss: (0.6104) |  Loss2: (0.0000) | Acc: (78.00%) (15217/19328)
Epoch: 24 | Batch_idx: 160 |  Loss: (0.6078) |  Loss2: (0.0000) | Acc: (78.00%) (16241/20608)
Epoch: 24 | Batch_idx: 170 |  Loss: (0.6071) |  Loss2: (0.0000) | Acc: (78.00%) (17268/21888)
Epoch: 24 | Batch_idx: 180 |  Loss: (0.6064) |  Loss2: (0.0000) | Acc: (78.00%) (18284/23168)
Epoch: 24 | Batch_idx: 190 |  Loss: (0.6099) |  Loss2: (0.0000) | Acc: (78.00%) (19266/24448)
Epoch: 24 | Batch_idx: 200 |  Loss: (0.6106) |  Loss2: (0.0000) | Acc: (78.00%) (20257/25728)
Epoch: 24 | Batch_idx: 210 |  Loss: (0.6107) |  Loss2: (0.0000) | Acc: (78.00%) (21279/27008)
Epoch: 24 | Batch_idx: 220 |  Loss: (0.6116) |  Loss2: (0.0000) | Acc: (78.00%) (22284/28288)
Epoch: 24 | Batch_idx: 230 |  Loss: (0.6105) |  Loss2: (0.0000) | Acc: (78.00%) (23303/29568)
Epoch: 24 | Batch_idx: 240 |  Loss: (0.6108) |  Loss2: (0.0000) | Acc: (78.00%) (24307/30848)
Epoch: 24 | Batch_idx: 250 |  Loss: (0.6124) |  Loss2: (0.0000) | Acc: (78.00%) (25302/32128)
Epoch: 24 | Batch_idx: 260 |  Loss: (0.6153) |  Loss2: (0.0000) | Acc: (78.00%) (26277/33408)
Epoch: 24 | Batch_idx: 270 |  Loss: (0.6179) |  Loss2: (0.0000) | Acc: (78.00%) (27237/34688)
Epoch: 24 | Batch_idx: 280 |  Loss: (0.6173) |  Loss2: (0.0000) | Acc: (78.00%) (28239/35968)
Epoch: 24 | Batch_idx: 290 |  Loss: (0.6167) |  Loss2: (0.0000) | Acc: (78.00%) (29265/37248)
Epoch: 24 | Batch_idx: 300 |  Loss: (0.6191) |  Loss2: (0.0000) | Acc: (78.00%) (30243/38528)
Epoch: 24 | Batch_idx: 310 |  Loss: (0.6176) |  Loss2: (0.0000) | Acc: (78.00%) (31255/39808)
Epoch: 24 | Batch_idx: 320 |  Loss: (0.6169) |  Loss2: (0.0000) | Acc: (78.00%) (32267/41088)
Epoch: 24 | Batch_idx: 330 |  Loss: (0.6159) |  Loss2: (0.0000) | Acc: (78.00%) (33289/42368)
Epoch: 24 | Batch_idx: 340 |  Loss: (0.6161) |  Loss2: (0.0000) | Acc: (78.00%) (34285/43648)
Epoch: 24 | Batch_idx: 350 |  Loss: (0.6165) |  Loss2: (0.0000) | Acc: (78.00%) (35297/44928)
Epoch: 24 | Batch_idx: 360 |  Loss: (0.6161) |  Loss2: (0.0000) | Acc: (78.00%) (36317/46208)
Epoch: 24 | Batch_idx: 370 |  Loss: (0.6168) |  Loss2: (0.0000) | Acc: (78.00%) (37310/47488)
Epoch: 24 | Batch_idx: 380 |  Loss: (0.6168) |  Loss2: (0.0000) | Acc: (78.00%) (38311/48768)
Epoch: 24 | Batch_idx: 390 |  Loss: (0.6182) |  Loss2: (0.0000) | Acc: (78.00%) (39261/50000)
# TEST : Loss: (0.7345) | Acc: (75.00%) (7522/10000)
percent tensor([0.5254, 0.5263, 0.5275, 0.5220, 0.5289, 0.5294, 0.5290, 0.5220, 0.5258,
        0.5249, 0.5253, 0.5273, 0.5239, 0.5230, 0.5263, 0.5235],
       device='cuda:0') torch.Size([16])
percent tensor([0.5371, 0.5200, 0.5061, 0.5433, 0.5261, 0.5812, 0.5192, 0.5229, 0.5179,
        0.5136, 0.5193, 0.5069, 0.5160, 0.5395, 0.5445, 0.5443],
       device='cuda:0') torch.Size([16])
percent tensor([0.4844, 0.5006, 0.4866, 0.4797, 0.4878, 0.4788, 0.4986, 0.4907, 0.4944,
        0.4890, 0.4895, 0.4879, 0.4888, 0.5014, 0.4890, 0.4846],
       device='cuda:0') torch.Size([16])
percent tensor([0.5177, 0.5077, 0.4966, 0.5069, 0.5060, 0.5374, 0.5034, 0.4959, 0.5076,
        0.5087, 0.5122, 0.4956, 0.5132, 0.5102, 0.5130, 0.5232],
       device='cuda:0') torch.Size([16])
percent tensor([0.5490, 0.5480, 0.5388, 0.5590, 0.5188, 0.6096, 0.5402, 0.5186, 0.5750,
        0.5114, 0.5536, 0.5376, 0.5789, 0.5827, 0.5254, 0.5594],
       device='cuda:0') torch.Size([16])
percent tensor([0.6322, 0.6081, 0.6679, 0.6757, 0.6758, 0.6366, 0.6319, 0.6857, 0.6353,
        0.6192, 0.6210, 0.6488, 0.6024, 0.6338, 0.6432, 0.6350],
       device='cuda:0') torch.Size([16])
percent tensor([0.5425, 0.5362, 0.5996, 0.5703, 0.6370, 0.4553, 0.5686, 0.6794, 0.5343,
        0.6002, 0.5139, 0.5748, 0.4546, 0.5160, 0.5688, 0.5305],
       device='cuda:0') torch.Size([16])
percent tensor([0.9819, 0.9622, 0.9728, 0.9799, 0.9781, 0.9713, 0.9765, 0.9866, 0.9581,
        0.9806, 0.9615, 0.9752, 0.9619, 0.9658, 0.9783, 0.9867],
       device='cuda:0') torch.Size([16])
False Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=128, out_features=16, bias=False)
True Linear(in_features=16, out_features=2, bias=False)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=128, out_features=16, bias=False)
True Linear(in_features=16, out_features=2, bias=False)
False Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=256, out_features=32, bias=False)
True Linear(in_features=32, out_features=2, bias=False)
False Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=256, out_features=32, bias=False)
True Linear(in_features=32, out_features=2, bias=False)
False Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=512, out_features=64, bias=False)
True Linear(in_features=64, out_features=2, bias=False)
False Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=512, out_features=64, bias=False)
True Linear(in_features=64, out_features=2, bias=False)
False Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1024, out_features=128, bias=False)
True Linear(in_features=128, out_features=2, bias=False)
False Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1024, out_features=128, bias=False)
True Linear(in_features=128, out_features=2, bias=False)
False Linear(in_features=512, out_features=10, bias=True)
Epoch: 25 | Batch_idx: 0 |  Loss: (0.7465) |  Loss2: (0.0000) | Acc: (68.00%) (88/128)
Epoch: 25 | Batch_idx: 10 |  Loss: (0.6669) |  Loss2: (0.0000) | Acc: (75.00%) (1059/1408)
Epoch: 25 | Batch_idx: 20 |  Loss: (0.7394) |  Loss2: (0.0000) | Acc: (73.00%) (1970/2688)
Epoch: 25 | Batch_idx: 30 |  Loss: (0.7674) |  Loss2: (0.0000) | Acc: (72.00%) (2890/3968)
Epoch: 25 | Batch_idx: 40 |  Loss: (0.7897) |  Loss2: (0.0000) | Acc: (72.00%) (3780/5248)
Epoch: 25 | Batch_idx: 50 |  Loss: (0.7870) |  Loss2: (0.0000) | Acc: (72.00%) (4715/6528)
Epoch: 25 | Batch_idx: 60 |  Loss: (0.7886) |  Loss2: (0.0000) | Acc: (72.00%) (5623/7808)
Epoch: 25 | Batch_idx: 70 |  Loss: (0.7995) |  Loss2: (0.0000) | Acc: (71.00%) (6502/9088)
Epoch: 25 | Batch_idx: 80 |  Loss: (0.7978) |  Loss2: (0.0000) | Acc: (71.00%) (7424/10368)
Epoch: 25 | Batch_idx: 90 |  Loss: (0.7928) |  Loss2: (0.0000) | Acc: (71.00%) (8363/11648)
Epoch: 25 | Batch_idx: 100 |  Loss: (0.7895) |  Loss2: (0.0000) | Acc: (72.00%) (9310/12928)
Epoch: 25 | Batch_idx: 110 |  Loss: (0.7825) |  Loss2: (0.0000) | Acc: (72.00%) (10273/14208)
Epoch: 25 | Batch_idx: 120 |  Loss: (0.7824) |  Loss2: (0.0000) | Acc: (72.00%) (11185/15488)
Epoch: 25 | Batch_idx: 130 |  Loss: (0.7780) |  Loss2: (0.0000) | Acc: (72.00%) (12147/16768)
Epoch: 25 | Batch_idx: 140 |  Loss: (0.7727) |  Loss2: (0.0000) | Acc: (72.00%) (13103/18048)
Epoch: 25 | Batch_idx: 150 |  Loss: (0.7689) |  Loss2: (0.0000) | Acc: (72.00%) (14064/19328)
Epoch: 25 | Batch_idx: 160 |  Loss: (0.7679) |  Loss2: (0.0000) | Acc: (72.00%) (15010/20608)
Epoch: 25 | Batch_idx: 170 |  Loss: (0.7634) |  Loss2: (0.0000) | Acc: (73.00%) (15992/21888)
Epoch: 25 | Batch_idx: 180 |  Loss: (0.7616) |  Loss2: (0.0000) | Acc: (73.00%) (16938/23168)
Epoch: 25 | Batch_idx: 190 |  Loss: (0.7622) |  Loss2: (0.0000) | Acc: (73.00%) (17870/24448)
Epoch: 25 | Batch_idx: 200 |  Loss: (0.7599) |  Loss2: (0.0000) | Acc: (73.00%) (18833/25728)
Epoch: 25 | Batch_idx: 210 |  Loss: (0.7565) |  Loss2: (0.0000) | Acc: (73.00%) (19797/27008)
Epoch: 25 | Batch_idx: 220 |  Loss: (0.7542) |  Loss2: (0.0000) | Acc: (73.00%) (20777/28288)
Epoch: 25 | Batch_idx: 230 |  Loss: (0.7501) |  Loss2: (0.0000) | Acc: (73.00%) (21758/29568)
Epoch: 25 | Batch_idx: 240 |  Loss: (0.7473) |  Loss2: (0.0000) | Acc: (73.00%) (22746/30848)
Epoch: 25 | Batch_idx: 250 |  Loss: (0.7442) |  Loss2: (0.0000) | Acc: (73.00%) (23738/32128)
Epoch: 25 | Batch_idx: 260 |  Loss: (0.7406) |  Loss2: (0.0000) | Acc: (74.00%) (24734/33408)
Epoch: 25 | Batch_idx: 270 |  Loss: (0.7386) |  Loss2: (0.0000) | Acc: (74.00%) (25705/34688)
Epoch: 25 | Batch_idx: 280 |  Loss: (0.7357) |  Loss2: (0.0000) | Acc: (74.00%) (26693/35968)
Epoch: 25 | Batch_idx: 290 |  Loss: (0.7345) |  Loss2: (0.0000) | Acc: (74.00%) (27639/37248)
Epoch: 25 | Batch_idx: 300 |  Loss: (0.7325) |  Loss2: (0.0000) | Acc: (74.00%) (28626/38528)
Epoch: 25 | Batch_idx: 310 |  Loss: (0.7312) |  Loss2: (0.0000) | Acc: (74.00%) (29582/39808)
Epoch: 25 | Batch_idx: 320 |  Loss: (0.7296) |  Loss2: (0.0000) | Acc: (74.00%) (30570/41088)
Epoch: 25 | Batch_idx: 330 |  Loss: (0.7279) |  Loss2: (0.0000) | Acc: (74.00%) (31556/42368)
Epoch: 25 | Batch_idx: 340 |  Loss: (0.7278) |  Loss2: (0.0000) | Acc: (74.00%) (32521/43648)
Epoch: 25 | Batch_idx: 350 |  Loss: (0.7253) |  Loss2: (0.0000) | Acc: (74.00%) (33532/44928)
Epoch: 25 | Batch_idx: 360 |  Loss: (0.7225) |  Loss2: (0.0000) | Acc: (74.00%) (34534/46208)
Epoch: 25 | Batch_idx: 370 |  Loss: (0.7203) |  Loss2: (0.0000) | Acc: (74.00%) (35532/47488)
Epoch: 25 | Batch_idx: 380 |  Loss: (0.7189) |  Loss2: (0.0000) | Acc: (74.00%) (36509/48768)
Epoch: 25 | Batch_idx: 390 |  Loss: (0.7171) |  Loss2: (0.0000) | Acc: (74.00%) (37456/50000)
=> saving checkpoint 'drive/app/torch/save_Routing_Gate_2/checkpoint_025.pth.tar'
# TEST : Loss: (0.6873) | Acc: (75.00%) (7591/10000)
percent tensor([0.5328, 0.5330, 0.5387, 0.5317, 0.5393, 0.5357, 0.5371, 0.5315, 0.5333,
        0.5325, 0.5312, 0.5372, 0.5310, 0.5279, 0.5331, 0.5304],
       device='cuda:0') torch.Size([16])
percent tensor([0.5379, 0.5204, 0.5120, 0.5502, 0.5306, 0.5770, 0.5219, 0.5316, 0.5221,
        0.5185, 0.5226, 0.5140, 0.5186, 0.5404, 0.5452, 0.5464],
       device='cuda:0') torch.Size([16])
percent tensor([0.4510, 0.4760, 0.4343, 0.4253, 0.4297, 0.4377, 0.4620, 0.4387, 0.4602,
        0.4554, 0.4598, 0.4402, 0.4618, 0.4740, 0.4508, 0.4495],
       device='cuda:0') torch.Size([16])
percent tensor([0.5575, 0.5393, 0.5423, 0.5563, 0.5572, 0.5746, 0.5447, 0.5487, 0.5471,
        0.5468, 0.5496, 0.5385, 0.5451, 0.5476, 0.5507, 0.5626],
       device='cuda:0') torch.Size([16])
percent tensor([0.5588, 0.5790, 0.5045, 0.5169, 0.4841, 0.6132, 0.5391, 0.4712, 0.5823,
        0.5309, 0.5690, 0.5190, 0.6157, 0.5854, 0.5130, 0.5674],
       device='cuda:0') torch.Size([16])
percent tensor([0.5821, 0.5532, 0.6656, 0.6665, 0.6690, 0.5996, 0.5904, 0.6594, 0.6048,
        0.5850, 0.5782, 0.6256, 0.5490, 0.5885, 0.5900, 0.5895],
       device='cuda:0') torch.Size([16])
percent tensor([0.6290, 0.6205, 0.6243, 0.6123, 0.6611, 0.5519, 0.6254, 0.6874, 0.6175,
        0.6624, 0.5993, 0.6244, 0.5697, 0.6166, 0.6285, 0.6174],
       device='cuda:0') torch.Size([16])
percent tensor([0.9806, 0.9653, 0.9752, 0.9820, 0.9820, 0.9752, 0.9765, 0.9871, 0.9677,
        0.9789, 0.9663, 0.9810, 0.9661, 0.9662, 0.9757, 0.9859],
       device='cuda:0') torch.Size([16])
Epoch: 26 | Batch_idx: 0 |  Loss: (0.5788) |  Loss2: (0.0000) | Acc: (77.00%) (99/128)
Epoch: 26 | Batch_idx: 10 |  Loss: (0.6483) |  Loss2: (0.0000) | Acc: (76.00%) (1075/1408)
Epoch: 26 | Batch_idx: 20 |  Loss: (0.6347) |  Loss2: (0.0000) | Acc: (77.00%) (2085/2688)
Epoch: 26 | Batch_idx: 30 |  Loss: (0.6331) |  Loss2: (0.0000) | Acc: (77.00%) (3070/3968)
Epoch: 26 | Batch_idx: 40 |  Loss: (0.6436) |  Loss2: (0.0000) | Acc: (76.00%) (4039/5248)
Epoch: 26 | Batch_idx: 50 |  Loss: (0.6475) |  Loss2: (0.0000) | Acc: (76.00%) (5017/6528)
Epoch: 26 | Batch_idx: 60 |  Loss: (0.6462) |  Loss2: (0.0000) | Acc: (77.00%) (6016/7808)
Epoch: 26 | Batch_idx: 70 |  Loss: (0.6505) |  Loss2: (0.0000) | Acc: (76.00%) (6992/9088)
Epoch: 26 | Batch_idx: 80 |  Loss: (0.6482) |  Loss2: (0.0000) | Acc: (77.00%) (7996/10368)
Epoch: 26 | Batch_idx: 90 |  Loss: (0.6500) |  Loss2: (0.0000) | Acc: (77.00%) (8995/11648)
Epoch: 26 | Batch_idx: 100 |  Loss: (0.6501) |  Loss2: (0.0000) | Acc: (77.00%) (9983/12928)
Epoch: 26 | Batch_idx: 110 |  Loss: (0.6520) |  Loss2: (0.0000) | Acc: (77.00%) (10965/14208)
Epoch: 26 | Batch_idx: 120 |  Loss: (0.6558) |  Loss2: (0.0000) | Acc: (77.00%) (11928/15488)
Epoch: 26 | Batch_idx: 130 |  Loss: (0.6561) |  Loss2: (0.0000) | Acc: (77.00%) (12913/16768)
Epoch: 26 | Batch_idx: 140 |  Loss: (0.6556) |  Loss2: (0.0000) | Acc: (77.00%) (13910/18048)
Epoch: 26 | Batch_idx: 150 |  Loss: (0.6550) |  Loss2: (0.0000) | Acc: (77.00%) (14905/19328)
Epoch: 26 | Batch_idx: 160 |  Loss: (0.6555) |  Loss2: (0.0000) | Acc: (77.00%) (15887/20608)
Epoch: 26 | Batch_idx: 170 |  Loss: (0.6556) |  Loss2: (0.0000) | Acc: (77.00%) (16875/21888)
Epoch: 26 | Batch_idx: 180 |  Loss: (0.6563) |  Loss2: (0.0000) | Acc: (77.00%) (17868/23168)
Epoch: 26 | Batch_idx: 190 |  Loss: (0.6572) |  Loss2: (0.0000) | Acc: (77.00%) (18851/24448)
Epoch: 26 | Batch_idx: 200 |  Loss: (0.6550) |  Loss2: (0.0000) | Acc: (77.00%) (19862/25728)
Epoch: 26 | Batch_idx: 210 |  Loss: (0.6540) |  Loss2: (0.0000) | Acc: (77.00%) (20871/27008)
Epoch: 26 | Batch_idx: 220 |  Loss: (0.6519) |  Loss2: (0.0000) | Acc: (77.00%) (21899/28288)
Epoch: 26 | Batch_idx: 230 |  Loss: (0.6491) |  Loss2: (0.0000) | Acc: (77.00%) (22924/29568)
Epoch: 26 | Batch_idx: 240 |  Loss: (0.6452) |  Loss2: (0.0000) | Acc: (77.00%) (23951/30848)
Epoch: 26 | Batch_idx: 250 |  Loss: (0.6451) |  Loss2: (0.0000) | Acc: (77.00%) (24946/32128)
Epoch: 26 | Batch_idx: 260 |  Loss: (0.6443) |  Loss2: (0.0000) | Acc: (77.00%) (25960/33408)
Epoch: 26 | Batch_idx: 270 |  Loss: (0.6443) |  Loss2: (0.0000) | Acc: (77.00%) (26952/34688)
Epoch: 26 | Batch_idx: 280 |  Loss: (0.6420) |  Loss2: (0.0000) | Acc: (77.00%) (27966/35968)
Epoch: 26 | Batch_idx: 290 |  Loss: (0.6413) |  Loss2: (0.0000) | Acc: (77.00%) (28974/37248)
Epoch: 26 | Batch_idx: 300 |  Loss: (0.6396) |  Loss2: (0.0000) | Acc: (77.00%) (29988/38528)
Epoch: 26 | Batch_idx: 310 |  Loss: (0.6391) |  Loss2: (0.0000) | Acc: (77.00%) (31003/39808)
Epoch: 26 | Batch_idx: 320 |  Loss: (0.6401) |  Loss2: (0.0000) | Acc: (77.00%) (31981/41088)
Epoch: 26 | Batch_idx: 330 |  Loss: (0.6396) |  Loss2: (0.0000) | Acc: (77.00%) (32980/42368)
Epoch: 26 | Batch_idx: 340 |  Loss: (0.6386) |  Loss2: (0.0000) | Acc: (77.00%) (33996/43648)
Epoch: 26 | Batch_idx: 350 |  Loss: (0.6377) |  Loss2: (0.0000) | Acc: (77.00%) (34986/44928)
Epoch: 26 | Batch_idx: 360 |  Loss: (0.6357) |  Loss2: (0.0000) | Acc: (77.00%) (36027/46208)
Epoch: 26 | Batch_idx: 370 |  Loss: (0.6346) |  Loss2: (0.0000) | Acc: (78.00%) (37048/47488)
Epoch: 26 | Batch_idx: 380 |  Loss: (0.6346) |  Loss2: (0.0000) | Acc: (78.00%) (38057/48768)
Epoch: 26 | Batch_idx: 390 |  Loss: (0.6350) |  Loss2: (0.0000) | Acc: (78.00%) (39010/50000)
# TEST : Loss: (0.6536) | Acc: (76.00%) (7675/10000)
percent tensor([0.5312, 0.5306, 0.5375, 0.5302, 0.5378, 0.5345, 0.5349, 0.5299, 0.5313,
        0.5306, 0.5292, 0.5356, 0.5291, 0.5259, 0.5313, 0.5289],
       device='cuda:0') torch.Size([16])
percent tensor([0.5395, 0.5220, 0.5140, 0.5555, 0.5337, 0.5786, 0.5239, 0.5347, 0.5243,
        0.5204, 0.5246, 0.5162, 0.5199, 0.5453, 0.5469, 0.5486],
       device='cuda:0') torch.Size([16])
percent tensor([0.4586, 0.4867, 0.4308, 0.4243, 0.4280, 0.4453, 0.4677, 0.4383, 0.4644,
        0.4631, 0.4678, 0.4407, 0.4706, 0.4807, 0.4587, 0.4582],
       device='cuda:0') torch.Size([16])
percent tensor([0.5614, 0.5413, 0.5499, 0.5658, 0.5666, 0.5800, 0.5488, 0.5560, 0.5519,
        0.5514, 0.5529, 0.5433, 0.5468, 0.5525, 0.5540, 0.5675],
       device='cuda:0') torch.Size([16])
percent tensor([0.5636, 0.5826, 0.5116, 0.5262, 0.4867, 0.6320, 0.5358, 0.4748, 0.5936,
        0.5292, 0.5701, 0.5220, 0.6287, 0.5895, 0.5066, 0.5774],
       device='cuda:0') torch.Size([16])
percent tensor([0.5964, 0.5671, 0.6905, 0.6973, 0.7012, 0.6210, 0.6072, 0.6869, 0.6234,
        0.6069, 0.5941, 0.6416, 0.5528, 0.6140, 0.6052, 0.6087],
       device='cuda:0') torch.Size([16])
percent tensor([0.6432, 0.6302, 0.6478, 0.6319, 0.6861, 0.5721, 0.6346, 0.7020, 0.6340,
        0.6829, 0.6137, 0.6369, 0.5738, 0.6370, 0.6369, 0.6339],
       device='cuda:0') torch.Size([16])
percent tensor([0.9863, 0.9734, 0.9814, 0.9869, 0.9866, 0.9818, 0.9839, 0.9907, 0.9773,
        0.9852, 0.9760, 0.9870, 0.9749, 0.9764, 0.9814, 0.9901],
       device='cuda:0') torch.Size([16])
Epoch: 27 | Batch_idx: 0 |  Loss: (0.5457) |  Loss2: (0.0000) | Acc: (82.00%) (105/128)
Epoch: 27 | Batch_idx: 10 |  Loss: (0.5803) |  Loss2: (0.0000) | Acc: (78.00%) (1108/1408)
Epoch: 27 | Batch_idx: 20 |  Loss: (0.5860) |  Loss2: (0.0000) | Acc: (78.00%) (2123/2688)
Epoch: 27 | Batch_idx: 30 |  Loss: (0.5878) |  Loss2: (0.0000) | Acc: (79.00%) (3157/3968)
Epoch: 27 | Batch_idx: 40 |  Loss: (0.6023) |  Loss2: (0.0000) | Acc: (79.00%) (4150/5248)
Epoch: 27 | Batch_idx: 50 |  Loss: (0.5941) |  Loss2: (0.0000) | Acc: (79.00%) (5180/6528)
Epoch: 27 | Batch_idx: 60 |  Loss: (0.5971) |  Loss2: (0.0000) | Acc: (79.00%) (6186/7808)
Epoch: 27 | Batch_idx: 70 |  Loss: (0.6038) |  Loss2: (0.0000) | Acc: (78.00%) (7172/9088)
Epoch: 27 | Batch_idx: 80 |  Loss: (0.6057) |  Loss2: (0.0000) | Acc: (78.00%) (8167/10368)
Epoch: 27 | Batch_idx: 90 |  Loss: (0.6040) |  Loss2: (0.0000) | Acc: (78.00%) (9179/11648)
Epoch: 27 | Batch_idx: 100 |  Loss: (0.6061) |  Loss2: (0.0000) | Acc: (78.00%) (10187/12928)
Epoch: 27 | Batch_idx: 110 |  Loss: (0.6055) |  Loss2: (0.0000) | Acc: (78.00%) (11194/14208)
Epoch: 27 | Batch_idx: 120 |  Loss: (0.6061) |  Loss2: (0.0000) | Acc: (78.00%) (12209/15488)
Epoch: 27 | Batch_idx: 130 |  Loss: (0.6085) |  Loss2: (0.0000) | Acc: (78.00%) (13205/16768)
Epoch: 27 | Batch_idx: 140 |  Loss: (0.6081) |  Loss2: (0.0000) | Acc: (78.00%) (14215/18048)
Epoch: 27 | Batch_idx: 150 |  Loss: (0.6066) |  Loss2: (0.0000) | Acc: (78.00%) (15220/19328)
Epoch: 27 | Batch_idx: 160 |  Loss: (0.6074) |  Loss2: (0.0000) | Acc: (78.00%) (16214/20608)
Epoch: 27 | Batch_idx: 170 |  Loss: (0.6075) |  Loss2: (0.0000) | Acc: (78.00%) (17238/21888)
Epoch: 27 | Batch_idx: 180 |  Loss: (0.6082) |  Loss2: (0.0000) | Acc: (78.00%) (18237/23168)
Epoch: 27 | Batch_idx: 190 |  Loss: (0.6057) |  Loss2: (0.0000) | Acc: (78.00%) (19265/24448)
Epoch: 27 | Batch_idx: 200 |  Loss: (0.6087) |  Loss2: (0.0000) | Acc: (78.00%) (20250/25728)
Epoch: 27 | Batch_idx: 210 |  Loss: (0.6088) |  Loss2: (0.0000) | Acc: (78.00%) (21270/27008)
Epoch: 27 | Batch_idx: 220 |  Loss: (0.6086) |  Loss2: (0.0000) | Acc: (78.00%) (22287/28288)
Epoch: 27 | Batch_idx: 230 |  Loss: (0.6077) |  Loss2: (0.0000) | Acc: (78.00%) (23296/29568)
Epoch: 27 | Batch_idx: 240 |  Loss: (0.6076) |  Loss2: (0.0000) | Acc: (78.00%) (24297/30848)
Epoch: 27 | Batch_idx: 250 |  Loss: (0.6097) |  Loss2: (0.0000) | Acc: (78.00%) (25274/32128)
Epoch: 27 | Batch_idx: 260 |  Loss: (0.6110) |  Loss2: (0.0000) | Acc: (78.00%) (26254/33408)
Epoch: 27 | Batch_idx: 270 |  Loss: (0.6113) |  Loss2: (0.0000) | Acc: (78.00%) (27251/34688)
Epoch: 27 | Batch_idx: 280 |  Loss: (0.6112) |  Loss2: (0.0000) | Acc: (78.00%) (28252/35968)
Epoch: 27 | Batch_idx: 290 |  Loss: (0.6115) |  Loss2: (0.0000) | Acc: (78.00%) (29237/37248)
Epoch: 27 | Batch_idx: 300 |  Loss: (0.6124) |  Loss2: (0.0000) | Acc: (78.00%) (30220/38528)
Epoch: 27 | Batch_idx: 310 |  Loss: (0.6131) |  Loss2: (0.0000) | Acc: (78.00%) (31214/39808)
Epoch: 27 | Batch_idx: 320 |  Loss: (0.6132) |  Loss2: (0.0000) | Acc: (78.00%) (32226/41088)
Epoch: 27 | Batch_idx: 330 |  Loss: (0.6136) |  Loss2: (0.0000) | Acc: (78.00%) (33219/42368)
Epoch: 27 | Batch_idx: 340 |  Loss: (0.6138) |  Loss2: (0.0000) | Acc: (78.00%) (34231/43648)
Epoch: 27 | Batch_idx: 350 |  Loss: (0.6125) |  Loss2: (0.0000) | Acc: (78.00%) (35266/44928)
Epoch: 27 | Batch_idx: 360 |  Loss: (0.6125) |  Loss2: (0.0000) | Acc: (78.00%) (36277/46208)
Epoch: 27 | Batch_idx: 370 |  Loss: (0.6127) |  Loss2: (0.0000) | Acc: (78.00%) (37284/47488)
Epoch: 27 | Batch_idx: 380 |  Loss: (0.6132) |  Loss2: (0.0000) | Acc: (78.00%) (38294/48768)
Epoch: 27 | Batch_idx: 390 |  Loss: (0.6128) |  Loss2: (0.0000) | Acc: (78.00%) (39274/50000)
# TEST : Loss: (0.6409) | Acc: (77.00%) (7725/10000)
percent tensor([0.5314, 0.5303, 0.5383, 0.5301, 0.5385, 0.5351, 0.5351, 0.5299, 0.5315,
        0.5306, 0.5291, 0.5362, 0.5290, 0.5257, 0.5314, 0.5290],
       device='cuda:0') torch.Size([16])
percent tensor([0.5387, 0.5216, 0.5126, 0.5554, 0.5328, 0.5779, 0.5235, 0.5341, 0.5241,
        0.5201, 0.5246, 0.5155, 0.5191, 0.5468, 0.5462, 0.5482],
       device='cuda:0') torch.Size([16])
percent tensor([0.4591, 0.4885, 0.4299, 0.4239, 0.4280, 0.4448, 0.4681, 0.4382, 0.4655,
        0.4647, 0.4695, 0.4407, 0.4720, 0.4820, 0.4589, 0.4591],
       device='cuda:0') torch.Size([16])
percent tensor([0.5648, 0.5434, 0.5532, 0.5710, 0.5705, 0.5844, 0.5515, 0.5593, 0.5553,
        0.5551, 0.5565, 0.5459, 0.5490, 0.5567, 0.5567, 0.5713],
       device='cuda:0') torch.Size([16])
percent tensor([0.5635, 0.5865, 0.5146, 0.5325, 0.4825, 0.6351, 0.5319, 0.4719, 0.6066,
        0.5290, 0.5756, 0.5245, 0.6390, 0.6039, 0.4992, 0.5766],
       device='cuda:0') torch.Size([16])
percent tensor([0.6135, 0.5847, 0.7122, 0.7221, 0.7260, 0.6393, 0.6271, 0.7098, 0.6416,
        0.6292, 0.6136, 0.6604, 0.5639, 0.6371, 0.6228, 0.6284],
       device='cuda:0') torch.Size([16])
percent tensor([0.6365, 0.6259, 0.6556, 0.6370, 0.6991, 0.5721, 0.6301, 0.7060, 0.6303,
        0.6883, 0.6105, 0.6371, 0.5611, 0.6341, 0.6336, 0.6357],
       device='cuda:0') torch.Size([16])
percent tensor([0.9901, 0.9802, 0.9868, 0.9905, 0.9902, 0.9861, 0.9885, 0.9934, 0.9832,
        0.9898, 0.9825, 0.9912, 0.9809, 0.9828, 0.9859, 0.9930],
       device='cuda:0') torch.Size([16])
Epoch: 28 | Batch_idx: 0 |  Loss: (0.5003) |  Loss2: (0.0000) | Acc: (82.00%) (105/128)
Epoch: 28 | Batch_idx: 10 |  Loss: (0.6090) |  Loss2: (0.0000) | Acc: (77.00%) (1090/1408)
Epoch: 28 | Batch_idx: 20 |  Loss: (0.6105) |  Loss2: (0.0000) | Acc: (77.00%) (2096/2688)
Epoch: 28 | Batch_idx: 30 |  Loss: (0.5918) |  Loss2: (0.0000) | Acc: (78.00%) (3125/3968)
Epoch: 28 | Batch_idx: 40 |  Loss: (0.5948) |  Loss2: (0.0000) | Acc: (78.00%) (4138/5248)
Epoch: 28 | Batch_idx: 50 |  Loss: (0.5934) |  Loss2: (0.0000) | Acc: (78.00%) (5150/6528)
Epoch: 28 | Batch_idx: 60 |  Loss: (0.5935) |  Loss2: (0.0000) | Acc: (78.00%) (6162/7808)
Epoch: 28 | Batch_idx: 70 |  Loss: (0.5884) |  Loss2: (0.0000) | Acc: (79.00%) (7186/9088)
Epoch: 28 | Batch_idx: 80 |  Loss: (0.5866) |  Loss2: (0.0000) | Acc: (79.00%) (8212/10368)
Epoch: 28 | Batch_idx: 90 |  Loss: (0.5886) |  Loss2: (0.0000) | Acc: (79.00%) (9219/11648)
Epoch: 28 | Batch_idx: 100 |  Loss: (0.5899) |  Loss2: (0.0000) | Acc: (79.00%) (10230/12928)
Epoch: 28 | Batch_idx: 110 |  Loss: (0.5932) |  Loss2: (0.0000) | Acc: (79.00%) (11225/14208)
Epoch: 28 | Batch_idx: 120 |  Loss: (0.5953) |  Loss2: (0.0000) | Acc: (78.00%) (12232/15488)
Epoch: 28 | Batch_idx: 130 |  Loss: (0.5959) |  Loss2: (0.0000) | Acc: (78.00%) (13234/16768)
Epoch: 28 | Batch_idx: 140 |  Loss: (0.5986) |  Loss2: (0.0000) | Acc: (78.00%) (14238/18048)
Epoch: 28 | Batch_idx: 150 |  Loss: (0.5974) |  Loss2: (0.0000) | Acc: (78.00%) (15262/19328)
Epoch: 28 | Batch_idx: 160 |  Loss: (0.5992) |  Loss2: (0.0000) | Acc: (78.00%) (16272/20608)
Epoch: 28 | Batch_idx: 170 |  Loss: (0.5983) |  Loss2: (0.0000) | Acc: (79.00%) (17296/21888)
Epoch: 28 | Batch_idx: 180 |  Loss: (0.5991) |  Loss2: (0.0000) | Acc: (78.00%) (18289/23168)
Epoch: 28 | Batch_idx: 190 |  Loss: (0.5996) |  Loss2: (0.0000) | Acc: (78.00%) (19267/24448)
Epoch: 28 | Batch_idx: 200 |  Loss: (0.5984) |  Loss2: (0.0000) | Acc: (78.00%) (20284/25728)
Epoch: 28 | Batch_idx: 210 |  Loss: (0.5999) |  Loss2: (0.0000) | Acc: (78.00%) (21296/27008)
Epoch: 28 | Batch_idx: 220 |  Loss: (0.6007) |  Loss2: (0.0000) | Acc: (78.00%) (22311/28288)
Epoch: 28 | Batch_idx: 230 |  Loss: (0.6010) |  Loss2: (0.0000) | Acc: (78.00%) (23328/29568)
Epoch: 28 | Batch_idx: 240 |  Loss: (0.6003) |  Loss2: (0.0000) | Acc: (78.00%) (24332/30848)
Epoch: 28 | Batch_idx: 250 |  Loss: (0.6010) |  Loss2: (0.0000) | Acc: (78.00%) (25337/32128)
Epoch: 28 | Batch_idx: 260 |  Loss: (0.6000) |  Loss2: (0.0000) | Acc: (78.00%) (26368/33408)
Epoch: 28 | Batch_idx: 270 |  Loss: (0.6017) |  Loss2: (0.0000) | Acc: (78.00%) (27353/34688)
Epoch: 28 | Batch_idx: 280 |  Loss: (0.6025) |  Loss2: (0.0000) | Acc: (78.00%) (28356/35968)
Epoch: 28 | Batch_idx: 290 |  Loss: (0.6037) |  Loss2: (0.0000) | Acc: (78.00%) (29339/37248)
Epoch: 28 | Batch_idx: 300 |  Loss: (0.6051) |  Loss2: (0.0000) | Acc: (78.00%) (30321/38528)
Epoch: 28 | Batch_idx: 310 |  Loss: (0.6035) |  Loss2: (0.0000) | Acc: (78.00%) (31356/39808)
Epoch: 28 | Batch_idx: 320 |  Loss: (0.6040) |  Loss2: (0.0000) | Acc: (78.00%) (32346/41088)
Epoch: 28 | Batch_idx: 330 |  Loss: (0.6055) |  Loss2: (0.0000) | Acc: (78.00%) (33327/42368)
Epoch: 28 | Batch_idx: 340 |  Loss: (0.6064) |  Loss2: (0.0000) | Acc: (78.00%) (34326/43648)
Epoch: 28 | Batch_idx: 350 |  Loss: (0.6061) |  Loss2: (0.0000) | Acc: (78.00%) (35343/44928)
Epoch: 28 | Batch_idx: 360 |  Loss: (0.6059) |  Loss2: (0.0000) | Acc: (78.00%) (36345/46208)
Epoch: 28 | Batch_idx: 370 |  Loss: (0.6047) |  Loss2: (0.0000) | Acc: (78.00%) (37378/47488)
Epoch: 28 | Batch_idx: 380 |  Loss: (0.6045) |  Loss2: (0.0000) | Acc: (78.00%) (38395/48768)
Epoch: 28 | Batch_idx: 390 |  Loss: (0.6045) |  Loss2: (0.0000) | Acc: (78.00%) (39369/50000)
# TEST : Loss: (0.6272) | Acc: (77.00%) (7764/10000)
percent tensor([0.5309, 0.5286, 0.5386, 0.5294, 0.5384, 0.5353, 0.5340, 0.5290, 0.5305,
        0.5295, 0.5280, 0.5359, 0.5280, 0.5239, 0.5305, 0.5283],
       device='cuda:0') torch.Size([16])
percent tensor([0.5397, 0.5226, 0.5130, 0.5562, 0.5333, 0.5784, 0.5244, 0.5346, 0.5255,
        0.5212, 0.5264, 0.5162, 0.5201, 0.5489, 0.5468, 0.5493],
       device='cuda:0') torch.Size([16])
percent tensor([0.4609, 0.4928, 0.4307, 0.4254, 0.4303, 0.4458, 0.4710, 0.4407, 0.4676,
        0.4685, 0.4724, 0.4429, 0.4744, 0.4847, 0.4618, 0.4615],
       device='cuda:0') torch.Size([16])
percent tensor([0.5688, 0.5466, 0.5546, 0.5746, 0.5725, 0.5888, 0.5540, 0.5601, 0.5589,
        0.5594, 0.5607, 0.5479, 0.5525, 0.5615, 0.5593, 0.5757],
       device='cuda:0') torch.Size([16])
percent tensor([0.5746, 0.5990, 0.5229, 0.5430, 0.4892, 0.6395, 0.5435, 0.4851, 0.6183,
        0.5409, 0.5891, 0.5381, 0.6544, 0.6171, 0.5131, 0.5891],
       device='cuda:0') torch.Size([16])
percent tensor([0.6248, 0.5946, 0.7238, 0.7360, 0.7398, 0.6516, 0.6390, 0.7211, 0.6518,
        0.6424, 0.6262, 0.6708, 0.5696, 0.6519, 0.6320, 0.6408],
       device='cuda:0') torch.Size([16])
percent tensor([0.6281, 0.6165, 0.6550, 0.6355, 0.7037, 0.5665, 0.6204, 0.7038, 0.6229,
        0.6871, 0.6000, 0.6284, 0.5424, 0.6286, 0.6222, 0.6315],
       device='cuda:0') torch.Size([16])
percent tensor([0.9923, 0.9840, 0.9893, 0.9924, 0.9921, 0.9887, 0.9911, 0.9949, 0.9865,
        0.9920, 0.9861, 0.9931, 0.9843, 0.9867, 0.9889, 0.9944],
       device='cuda:0') torch.Size([16])
Epoch: 29 | Batch_idx: 0 |  Loss: (0.5321) |  Loss2: (0.0000) | Acc: (79.00%) (102/128)
Epoch: 29 | Batch_idx: 10 |  Loss: (0.5634) |  Loss2: (0.0000) | Acc: (79.00%) (1121/1408)
Epoch: 29 | Batch_idx: 20 |  Loss: (0.5809) |  Loss2: (0.0000) | Acc: (79.00%) (2135/2688)
Epoch: 29 | Batch_idx: 30 |  Loss: (0.5734) |  Loss2: (0.0000) | Acc: (79.00%) (3136/3968)
Epoch: 29 | Batch_idx: 40 |  Loss: (0.5845) |  Loss2: (0.0000) | Acc: (78.00%) (4136/5248)
Epoch: 29 | Batch_idx: 50 |  Loss: (0.5983) |  Loss2: (0.0000) | Acc: (78.00%) (5108/6528)
Epoch: 29 | Batch_idx: 60 |  Loss: (0.6000) |  Loss2: (0.0000) | Acc: (78.00%) (6130/7808)
Epoch: 29 | Batch_idx: 70 |  Loss: (0.5981) |  Loss2: (0.0000) | Acc: (78.00%) (7140/9088)
Epoch: 29 | Batch_idx: 80 |  Loss: (0.6035) |  Loss2: (0.0000) | Acc: (78.00%) (8138/10368)
Epoch: 29 | Batch_idx: 90 |  Loss: (0.5996) |  Loss2: (0.0000) | Acc: (78.00%) (9173/11648)
Epoch: 29 | Batch_idx: 100 |  Loss: (0.5978) |  Loss2: (0.0000) | Acc: (78.00%) (10196/12928)
Epoch: 29 | Batch_idx: 110 |  Loss: (0.5955) |  Loss2: (0.0000) | Acc: (79.00%) (11240/14208)
Epoch: 29 | Batch_idx: 120 |  Loss: (0.5988) |  Loss2: (0.0000) | Acc: (79.00%) (12239/15488)
Epoch: 29 | Batch_idx: 130 |  Loss: (0.5986) |  Loss2: (0.0000) | Acc: (79.00%) (13257/16768)
Epoch: 29 | Batch_idx: 140 |  Loss: (0.5987) |  Loss2: (0.0000) | Acc: (79.00%) (14262/18048)
Epoch: 29 | Batch_idx: 150 |  Loss: (0.5977) |  Loss2: (0.0000) | Acc: (79.00%) (15278/19328)
Epoch: 29 | Batch_idx: 160 |  Loss: (0.5990) |  Loss2: (0.0000) | Acc: (78.00%) (16279/20608)
Epoch: 29 | Batch_idx: 170 |  Loss: (0.5990) |  Loss2: (0.0000) | Acc: (78.00%) (17286/21888)
Epoch: 29 | Batch_idx: 180 |  Loss: (0.5984) |  Loss2: (0.0000) | Acc: (79.00%) (18320/23168)
Epoch: 29 | Batch_idx: 190 |  Loss: (0.5960) |  Loss2: (0.0000) | Acc: (79.00%) (19370/24448)
Epoch: 29 | Batch_idx: 200 |  Loss: (0.5958) |  Loss2: (0.0000) | Acc: (79.00%) (20387/25728)
Epoch: 29 | Batch_idx: 210 |  Loss: (0.5935) |  Loss2: (0.0000) | Acc: (79.00%) (21417/27008)
Epoch: 29 | Batch_idx: 220 |  Loss: (0.5942) |  Loss2: (0.0000) | Acc: (79.00%) (22427/28288)
Epoch: 29 | Batch_idx: 230 |  Loss: (0.5946) |  Loss2: (0.0000) | Acc: (79.00%) (23442/29568)
Epoch: 29 | Batch_idx: 240 |  Loss: (0.5944) |  Loss2: (0.0000) | Acc: (79.00%) (24478/30848)
Epoch: 29 | Batch_idx: 250 |  Loss: (0.5937) |  Loss2: (0.0000) | Acc: (79.00%) (25516/32128)
Epoch: 29 | Batch_idx: 260 |  Loss: (0.5940) |  Loss2: (0.0000) | Acc: (79.00%) (26521/33408)
Epoch: 29 | Batch_idx: 270 |  Loss: (0.5939) |  Loss2: (0.0000) | Acc: (79.00%) (27536/34688)
Epoch: 29 | Batch_idx: 280 |  Loss: (0.5938) |  Loss2: (0.0000) | Acc: (79.00%) (28553/35968)
Epoch: 29 | Batch_idx: 290 |  Loss: (0.5930) |  Loss2: (0.0000) | Acc: (79.00%) (29580/37248)
Epoch: 29 | Batch_idx: 300 |  Loss: (0.5939) |  Loss2: (0.0000) | Acc: (79.00%) (30580/38528)
Epoch: 29 | Batch_idx: 310 |  Loss: (0.5939) |  Loss2: (0.0000) | Acc: (79.00%) (31586/39808)
Epoch: 29 | Batch_idx: 320 |  Loss: (0.5935) |  Loss2: (0.0000) | Acc: (79.00%) (32599/41088)
Epoch: 29 | Batch_idx: 330 |  Loss: (0.5954) |  Loss2: (0.0000) | Acc: (79.00%) (33585/42368)
Epoch: 29 | Batch_idx: 340 |  Loss: (0.5943) |  Loss2: (0.0000) | Acc: (79.00%) (34615/43648)
Epoch: 29 | Batch_idx: 350 |  Loss: (0.5944) |  Loss2: (0.0000) | Acc: (79.00%) (35634/44928)
Epoch: 29 | Batch_idx: 360 |  Loss: (0.5950) |  Loss2: (0.0000) | Acc: (79.00%) (36643/46208)
Epoch: 29 | Batch_idx: 370 |  Loss: (0.5947) |  Loss2: (0.0000) | Acc: (79.00%) (37667/47488)
Epoch: 29 | Batch_idx: 380 |  Loss: (0.5953) |  Loss2: (0.0000) | Acc: (79.00%) (38675/48768)
Epoch: 29 | Batch_idx: 390 |  Loss: (0.5950) |  Loss2: (0.0000) | Acc: (79.00%) (39648/50000)
# TEST : Loss: (0.6241) | Acc: (77.00%) (7797/10000)
percent tensor([0.5314, 0.5289, 0.5392, 0.5294, 0.5392, 0.5361, 0.5347, 0.5291, 0.5311,
        0.5298, 0.5286, 0.5365, 0.5282, 0.5243, 0.5310, 0.5285],
       device='cuda:0') torch.Size([16])
percent tensor([0.5431, 0.5271, 0.5160, 0.5600, 0.5370, 0.5812, 0.5288, 0.5382, 0.5297,
        0.5258, 0.5310, 0.5200, 0.5238, 0.5542, 0.5506, 0.5529],
       device='cuda:0') torch.Size([16])
percent tensor([0.4673, 0.4982, 0.4381, 0.4335, 0.4387, 0.4526, 0.4770, 0.4482, 0.4742,
        0.4752, 0.4788, 0.4501, 0.4804, 0.4905, 0.4679, 0.4682],
       device='cuda:0') torch.Size([16])
percent tensor([0.5704, 0.5479, 0.5544, 0.5751, 0.5728, 0.5906, 0.5546, 0.5596, 0.5605,
        0.5616, 0.5628, 0.5479, 0.5541, 0.5638, 0.5601, 0.5776],
       device='cuda:0') torch.Size([16])
percent tensor([0.5640, 0.5868, 0.5254, 0.5471, 0.4877, 0.6373, 0.5313, 0.4843, 0.6146,
        0.5264, 0.5760, 0.5336, 0.6447, 0.6104, 0.5009, 0.5793],
       device='cuda:0') torch.Size([16])
percent tensor([0.6306, 0.6002, 0.7295, 0.7424, 0.7477, 0.6564, 0.6446, 0.7267, 0.6575,
        0.6504, 0.6333, 0.6744, 0.5719, 0.6587, 0.6363, 0.6467],
       device='cuda:0') torch.Size([16])
percent tensor([0.6254, 0.6150, 0.6630, 0.6413, 0.7155, 0.5621, 0.6182, 0.7146, 0.6227,
        0.6919, 0.6011, 0.6318, 0.5377, 0.6277, 0.6251, 0.6314],
       device='cuda:0') torch.Size([16])
percent tensor([0.9942, 0.9872, 0.9916, 0.9941, 0.9938, 0.9910, 0.9931, 0.9960, 0.9893,
        0.9938, 0.9893, 0.9947, 0.9875, 0.9896, 0.9913, 0.9958],
       device='cuda:0') torch.Size([16])
True Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=128, out_features=16, bias=False)
False Linear(in_features=16, out_features=2, bias=False)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=128, out_features=16, bias=False)
False Linear(in_features=16, out_features=2, bias=False)
True Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=256, out_features=32, bias=False)
False Linear(in_features=32, out_features=2, bias=False)
True Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=256, out_features=32, bias=False)
False Linear(in_features=32, out_features=2, bias=False)
True Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=512, out_features=64, bias=False)
False Linear(in_features=64, out_features=2, bias=False)
True Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=512, out_features=64, bias=False)
False Linear(in_features=64, out_features=2, bias=False)
True Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1024, out_features=128, bias=False)
False Linear(in_features=128, out_features=2, bias=False)
True Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1024, out_features=128, bias=False)
False Linear(in_features=128, out_features=2, bias=False)
True Linear(in_features=512, out_features=10, bias=True)
Epoch: 30 | Batch_idx: 0 |  Loss: (0.6289) |  Loss2: (0.0000) | Acc: (79.00%) (102/128)
Epoch: 30 | Batch_idx: 10 |  Loss: (0.5879) |  Loss2: (0.0000) | Acc: (79.00%) (1116/1408)
Epoch: 30 | Batch_idx: 20 |  Loss: (0.5912) |  Loss2: (0.0000) | Acc: (78.00%) (2116/2688)
Epoch: 30 | Batch_idx: 30 |  Loss: (0.5826) |  Loss2: (0.0000) | Acc: (79.00%) (3146/3968)
Epoch: 30 | Batch_idx: 40 |  Loss: (0.5794) |  Loss2: (0.0000) | Acc: (79.00%) (4179/5248)
Epoch: 30 | Batch_idx: 50 |  Loss: (0.5863) |  Loss2: (0.0000) | Acc: (79.00%) (5182/6528)
Epoch: 30 | Batch_idx: 60 |  Loss: (0.5909) |  Loss2: (0.0000) | Acc: (79.00%) (6197/7808)
Epoch: 30 | Batch_idx: 70 |  Loss: (0.5928) |  Loss2: (0.0000) | Acc: (79.00%) (7205/9088)
Epoch: 30 | Batch_idx: 80 |  Loss: (0.5970) |  Loss2: (0.0000) | Acc: (79.00%) (8209/10368)
Epoch: 30 | Batch_idx: 90 |  Loss: (0.5989) |  Loss2: (0.0000) | Acc: (79.00%) (9228/11648)
Epoch: 30 | Batch_idx: 100 |  Loss: (0.5988) |  Loss2: (0.0000) | Acc: (79.00%) (10239/12928)
Epoch: 30 | Batch_idx: 110 |  Loss: (0.6004) |  Loss2: (0.0000) | Acc: (79.00%) (11238/14208)
Epoch: 30 | Batch_idx: 120 |  Loss: (0.5983) |  Loss2: (0.0000) | Acc: (79.00%) (12266/15488)
Epoch: 30 | Batch_idx: 130 |  Loss: (0.6011) |  Loss2: (0.0000) | Acc: (79.00%) (13255/16768)
Epoch: 30 | Batch_idx: 140 |  Loss: (0.6000) |  Loss2: (0.0000) | Acc: (79.00%) (14262/18048)
Epoch: 30 | Batch_idx: 150 |  Loss: (0.5996) |  Loss2: (0.0000) | Acc: (79.00%) (15284/19328)
Epoch: 30 | Batch_idx: 160 |  Loss: (0.5984) |  Loss2: (0.0000) | Acc: (79.00%) (16301/20608)
Epoch: 30 | Batch_idx: 170 |  Loss: (0.5971) |  Loss2: (0.0000) | Acc: (79.00%) (17339/21888)
Epoch: 30 | Batch_idx: 180 |  Loss: (0.5964) |  Loss2: (0.0000) | Acc: (79.00%) (18360/23168)
Epoch: 30 | Batch_idx: 190 |  Loss: (0.5981) |  Loss2: (0.0000) | Acc: (79.00%) (19345/24448)
Epoch: 30 | Batch_idx: 200 |  Loss: (0.5965) |  Loss2: (0.0000) | Acc: (79.00%) (20370/25728)
Epoch: 30 | Batch_idx: 210 |  Loss: (0.5943) |  Loss2: (0.0000) | Acc: (79.00%) (21410/27008)
Epoch: 30 | Batch_idx: 220 |  Loss: (0.5943) |  Loss2: (0.0000) | Acc: (79.00%) (22441/28288)
Epoch: 30 | Batch_idx: 230 |  Loss: (0.5955) |  Loss2: (0.0000) | Acc: (79.00%) (23449/29568)
Epoch: 30 | Batch_idx: 240 |  Loss: (0.5945) |  Loss2: (0.0000) | Acc: (79.00%) (24489/30848)
Epoch: 30 | Batch_idx: 250 |  Loss: (0.5931) |  Loss2: (0.0000) | Acc: (79.00%) (25507/32128)
Epoch: 30 | Batch_idx: 260 |  Loss: (0.5932) |  Loss2: (0.0000) | Acc: (79.00%) (26513/33408)
Epoch: 30 | Batch_idx: 270 |  Loss: (0.5928) |  Loss2: (0.0000) | Acc: (79.00%) (27534/34688)
Epoch: 30 | Batch_idx: 280 |  Loss: (0.5926) |  Loss2: (0.0000) | Acc: (79.00%) (28559/35968)
Epoch: 30 | Batch_idx: 290 |  Loss: (0.5929) |  Loss2: (0.0000) | Acc: (79.00%) (29568/37248)
Epoch: 30 | Batch_idx: 300 |  Loss: (0.5911) |  Loss2: (0.0000) | Acc: (79.00%) (30609/38528)
Epoch: 30 | Batch_idx: 310 |  Loss: (0.5904) |  Loss2: (0.0000) | Acc: (79.00%) (31651/39808)
Epoch: 30 | Batch_idx: 320 |  Loss: (0.5908) |  Loss2: (0.0000) | Acc: (79.00%) (32650/41088)
Epoch: 30 | Batch_idx: 330 |  Loss: (0.5915) |  Loss2: (0.0000) | Acc: (79.00%) (33660/42368)
Epoch: 30 | Batch_idx: 340 |  Loss: (0.5913) |  Loss2: (0.0000) | Acc: (79.00%) (34677/43648)
Epoch: 30 | Batch_idx: 350 |  Loss: (0.5897) |  Loss2: (0.0000) | Acc: (79.00%) (35727/44928)
Epoch: 30 | Batch_idx: 360 |  Loss: (0.5891) |  Loss2: (0.0000) | Acc: (79.00%) (36763/46208)
Epoch: 30 | Batch_idx: 370 |  Loss: (0.5904) |  Loss2: (0.0000) | Acc: (79.00%) (37762/47488)
Epoch: 30 | Batch_idx: 380 |  Loss: (0.5904) |  Loss2: (0.0000) | Acc: (79.00%) (38775/48768)
Epoch: 30 | Batch_idx: 390 |  Loss: (0.5909) |  Loss2: (0.0000) | Acc: (79.00%) (39732/50000)
=> saving checkpoint 'drive/app/torch/save_Routing_Gate_2/checkpoint_030.pth.tar'
# TEST : Loss: (0.8754) | Acc: (70.00%) (7073/10000)
percent tensor([0.5300, 0.5289, 0.5379, 0.5298, 0.5377, 0.5355, 0.5337, 0.5298, 0.5297,
        0.5297, 0.5288, 0.5349, 0.5277, 0.5243, 0.5312, 0.5287],
       device='cuda:0') torch.Size([16])
percent tensor([0.5441, 0.5291, 0.5131, 0.5552, 0.5345, 0.5823, 0.5294, 0.5339, 0.5299,
        0.5242, 0.5298, 0.5162, 0.5236, 0.5554, 0.5500, 0.5513],
       device='cuda:0') torch.Size([16])
percent tensor([0.4600, 0.4998, 0.4394, 0.4352, 0.4402, 0.4496, 0.4777, 0.4509, 0.4736,
        0.4742, 0.4792, 0.4511, 0.4773, 0.4974, 0.4682, 0.4672],
       device='cuda:0') torch.Size([16])
percent tensor([0.5757, 0.5486, 0.5537, 0.5726, 0.5718, 0.5994, 0.5558, 0.5582, 0.5614,
        0.5601, 0.5621, 0.5479, 0.5547, 0.5636, 0.5634, 0.5796],
       device='cuda:0') torch.Size([16])
percent tensor([0.5727, 0.6090, 0.5241, 0.5297, 0.4794, 0.6511, 0.5442, 0.4867, 0.6269,
        0.5308, 0.6069, 0.5464, 0.6471, 0.6448, 0.5310, 0.5839],
       device='cuda:0') torch.Size([16])
percent tensor([0.6413, 0.5906, 0.7080, 0.7163, 0.7320, 0.6722, 0.6439, 0.7023, 0.6543,
        0.6314, 0.6378, 0.6581, 0.5626, 0.6466, 0.6374, 0.6401],
       device='cuda:0') torch.Size([16])
percent tensor([0.6135, 0.5744, 0.6332, 0.6223, 0.6752, 0.5680, 0.6061, 0.6732, 0.5897,
        0.6626, 0.5713, 0.5997, 0.5165, 0.5912, 0.5986, 0.6479],
       device='cuda:0') torch.Size([16])
percent tensor([0.9956, 0.9844, 0.9931, 0.9957, 0.9933, 0.9914, 0.9935, 0.9968, 0.9858,
        0.9948, 0.9874, 0.9931, 0.9881, 0.9872, 0.9932, 0.9970],
       device='cuda:0') torch.Size([16])
Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 3, 3, 3]) tensor(173.0093, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(789.0951, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(787.4731, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([128, 64, 3, 3]) tensor(1531.9283, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([128, 64, 1, 1]) tensor(506.5796, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([128, 128, 3, 3]) tensor(2180.3145, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([256, 128, 3, 3]) tensor(4306.1831, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([256, 128, 1, 1]) tensor(1432.2743, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([256, 256, 3, 3]) tensor(6096.7612, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([512, 256, 3, 3]) tensor(12138.1953, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([512, 256, 1, 1]) tensor(4044.5195, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([512, 512, 3, 3]) tensor(17119.7383, device='cuda:0', grad_fn=<NormBackward0>)
Epoch: 31 | Batch_idx: 0 |  Loss: (0.5720) |  Loss2: (0.0000) | Acc: (81.00%) (104/128)
Epoch: 31 | Batch_idx: 10 |  Loss: (0.5408) |  Loss2: (0.0000) | Acc: (80.00%) (1130/1408)
Epoch: 31 | Batch_idx: 20 |  Loss: (0.5466) |  Loss2: (0.0000) | Acc: (80.00%) (2162/2688)
Epoch: 31 | Batch_idx: 30 |  Loss: (0.5649) |  Loss2: (0.0000) | Acc: (79.00%) (3165/3968)
Epoch: 31 | Batch_idx: 40 |  Loss: (0.5633) |  Loss2: (0.0000) | Acc: (79.00%) (4179/5248)
Epoch: 31 | Batch_idx: 50 |  Loss: (0.5618) |  Loss2: (0.0000) | Acc: (79.00%) (5213/6528)
Epoch: 31 | Batch_idx: 60 |  Loss: (0.5590) |  Loss2: (0.0000) | Acc: (80.00%) (6263/7808)
Epoch: 31 | Batch_idx: 70 |  Loss: (0.5526) |  Loss2: (0.0000) | Acc: (80.00%) (7322/9088)
Epoch: 31 | Batch_idx: 80 |  Loss: (0.5556) |  Loss2: (0.0000) | Acc: (80.00%) (8341/10368)
Epoch: 31 | Batch_idx: 90 |  Loss: (0.5566) |  Loss2: (0.0000) | Acc: (80.00%) (9379/11648)
Epoch: 31 | Batch_idx: 100 |  Loss: (0.5550) |  Loss2: (0.0000) | Acc: (80.00%) (10426/12928)
Epoch: 31 | Batch_idx: 110 |  Loss: (0.5533) |  Loss2: (0.0000) | Acc: (80.00%) (11479/14208)
Epoch: 31 | Batch_idx: 120 |  Loss: (0.5561) |  Loss2: (0.0000) | Acc: (80.00%) (12491/15488)
Epoch: 31 | Batch_idx: 130 |  Loss: (0.5566) |  Loss2: (0.0000) | Acc: (80.00%) (13515/16768)
Epoch: 31 | Batch_idx: 140 |  Loss: (0.5593) |  Loss2: (0.0000) | Acc: (80.00%) (14539/18048)
Epoch: 31 | Batch_idx: 150 |  Loss: (0.5583) |  Loss2: (0.0000) | Acc: (80.00%) (15574/19328)
Epoch: 31 | Batch_idx: 160 |  Loss: (0.5582) |  Loss2: (0.0000) | Acc: (80.00%) (16602/20608)
Epoch: 31 | Batch_idx: 170 |  Loss: (0.5549) |  Loss2: (0.0000) | Acc: (80.00%) (17655/21888)
Epoch: 31 | Batch_idx: 180 |  Loss: (0.5550) |  Loss2: (0.0000) | Acc: (80.00%) (18678/23168)
Epoch: 31 | Batch_idx: 190 |  Loss: (0.5588) |  Loss2: (0.0000) | Acc: (80.00%) (19681/24448)
Epoch: 31 | Batch_idx: 200 |  Loss: (0.5603) |  Loss2: (0.0000) | Acc: (80.00%) (20714/25728)
Epoch: 31 | Batch_idx: 210 |  Loss: (0.5627) |  Loss2: (0.0000) | Acc: (80.00%) (21729/27008)
Epoch: 31 | Batch_idx: 220 |  Loss: (0.5633) |  Loss2: (0.0000) | Acc: (80.00%) (22748/28288)
Epoch: 31 | Batch_idx: 230 |  Loss: (0.5630) |  Loss2: (0.0000) | Acc: (80.00%) (23783/29568)
Epoch: 31 | Batch_idx: 240 |  Loss: (0.5618) |  Loss2: (0.0000) | Acc: (80.00%) (24828/30848)
Epoch: 31 | Batch_idx: 250 |  Loss: (0.5603) |  Loss2: (0.0000) | Acc: (80.00%) (25870/32128)
Epoch: 31 | Batch_idx: 260 |  Loss: (0.5592) |  Loss2: (0.0000) | Acc: (80.00%) (26922/33408)
Epoch: 31 | Batch_idx: 270 |  Loss: (0.5590) |  Loss2: (0.0000) | Acc: (80.00%) (27966/34688)
Epoch: 31 | Batch_idx: 280 |  Loss: (0.5592) |  Loss2: (0.0000) | Acc: (80.00%) (28987/35968)
Epoch: 31 | Batch_idx: 290 |  Loss: (0.5596) |  Loss2: (0.0000) | Acc: (80.00%) (30014/37248)
Epoch: 31 | Batch_idx: 300 |  Loss: (0.5615) |  Loss2: (0.0000) | Acc: (80.00%) (31014/38528)
Epoch: 31 | Batch_idx: 310 |  Loss: (0.5623) |  Loss2: (0.0000) | Acc: (80.00%) (32032/39808)
Epoch: 31 | Batch_idx: 320 |  Loss: (0.5639) |  Loss2: (0.0000) | Acc: (80.00%) (33032/41088)
Epoch: 31 | Batch_idx: 330 |  Loss: (0.5632) |  Loss2: (0.0000) | Acc: (80.00%) (34080/42368)
Epoch: 31 | Batch_idx: 340 |  Loss: (0.5627) |  Loss2: (0.0000) | Acc: (80.00%) (35105/43648)
Epoch: 31 | Batch_idx: 350 |  Loss: (0.5621) |  Loss2: (0.0000) | Acc: (80.00%) (36140/44928)
Epoch: 31 | Batch_idx: 360 |  Loss: (0.5624) |  Loss2: (0.0000) | Acc: (80.00%) (37173/46208)
Epoch: 31 | Batch_idx: 370 |  Loss: (0.5633) |  Loss2: (0.0000) | Acc: (80.00%) (38202/47488)
Epoch: 31 | Batch_idx: 380 |  Loss: (0.5638) |  Loss2: (0.0000) | Acc: (80.00%) (39217/48768)
Epoch: 31 | Batch_idx: 390 |  Loss: (0.5641) |  Loss2: (0.0000) | Acc: (80.00%) (40197/50000)
# TEST : Loss: (0.6526) | Acc: (77.00%) (7758/10000)
percent tensor([0.5303, 0.5301, 0.5380, 0.5308, 0.5388, 0.5367, 0.5350, 0.5287, 0.5306,
        0.5303, 0.5294, 0.5354, 0.5279, 0.5271, 0.5322, 0.5295],
       device='cuda:0') torch.Size([16])
percent tensor([0.5488, 0.5285, 0.5191, 0.5623, 0.5398, 0.5899, 0.5304, 0.5388, 0.5312,
        0.5239, 0.5298, 0.5200, 0.5252, 0.5517, 0.5539, 0.5550],
       device='cuda:0') torch.Size([16])
percent tensor([0.4605, 0.4939, 0.4463, 0.4374, 0.4472, 0.4501, 0.4756, 0.4497, 0.4701,
        0.4731, 0.4753, 0.4563, 0.4769, 0.4865, 0.4652, 0.4649],
       device='cuda:0') torch.Size([16])
percent tensor([0.5755, 0.5511, 0.5544, 0.5714, 0.5730, 0.5970, 0.5561, 0.5596, 0.5625,
        0.5632, 0.5650, 0.5481, 0.5553, 0.5665, 0.5633, 0.5826],
       device='cuda:0') torch.Size([16])
percent tensor([0.5580, 0.5918, 0.5334, 0.5369, 0.4838, 0.6205, 0.5310, 0.4986, 0.6121,
        0.5431, 0.5913, 0.5507, 0.6424, 0.6233, 0.5181, 0.5728],
       device='cuda:0') torch.Size([16])
percent tensor([0.6418, 0.6080, 0.7035, 0.7215, 0.7228, 0.6673, 0.6562, 0.7112, 0.6610,
        0.6423, 0.6463, 0.6594, 0.5687, 0.6878, 0.6451, 0.6498],
       device='cuda:0') torch.Size([16])
percent tensor([0.6254, 0.5946, 0.6453, 0.6145, 0.6808, 0.5604, 0.6314, 0.6803, 0.6056,
        0.6517, 0.5980, 0.6199, 0.5224, 0.6326, 0.6063, 0.6537],
       device='cuda:0') torch.Size([16])
percent tensor([0.9952, 0.9859, 0.9923, 0.9955, 0.9936, 0.9911, 0.9943, 0.9960, 0.9859,
        0.9932, 0.9888, 0.9931, 0.9875, 0.9906, 0.9942, 0.9964],
       device='cuda:0') torch.Size([16])
Epoch: 32 | Batch_idx: 0 |  Loss: (0.4936) |  Loss2: (0.0000) | Acc: (81.00%) (104/128)
Epoch: 32 | Batch_idx: 10 |  Loss: (0.5186) |  Loss2: (0.0000) | Acc: (82.00%) (1163/1408)
Epoch: 32 | Batch_idx: 20 |  Loss: (0.5236) |  Loss2: (0.0000) | Acc: (82.00%) (2208/2688)
Epoch: 32 | Batch_idx: 30 |  Loss: (0.5246) |  Loss2: (0.0000) | Acc: (81.00%) (3252/3968)
Epoch: 32 | Batch_idx: 40 |  Loss: (0.5430) |  Loss2: (0.0000) | Acc: (81.00%) (4266/5248)
Epoch: 32 | Batch_idx: 50 |  Loss: (0.5444) |  Loss2: (0.0000) | Acc: (81.00%) (5300/6528)
Epoch: 32 | Batch_idx: 60 |  Loss: (0.5442) |  Loss2: (0.0000) | Acc: (81.00%) (6331/7808)
Epoch: 32 | Batch_idx: 70 |  Loss: (0.5429) |  Loss2: (0.0000) | Acc: (81.00%) (7379/9088)
Epoch: 32 | Batch_idx: 80 |  Loss: (0.5430) |  Loss2: (0.0000) | Acc: (81.00%) (8409/10368)
Epoch: 32 | Batch_idx: 90 |  Loss: (0.5363) |  Loss2: (0.0000) | Acc: (81.00%) (9475/11648)
Epoch: 32 | Batch_idx: 100 |  Loss: (0.5349) |  Loss2: (0.0000) | Acc: (81.00%) (10511/12928)
Epoch: 32 | Batch_idx: 110 |  Loss: (0.5404) |  Loss2: (0.0000) | Acc: (81.00%) (11540/14208)
Epoch: 32 | Batch_idx: 120 |  Loss: (0.5406) |  Loss2: (0.0000) | Acc: (81.00%) (12580/15488)
Epoch: 32 | Batch_idx: 130 |  Loss: (0.5385) |  Loss2: (0.0000) | Acc: (81.00%) (13635/16768)
Epoch: 32 | Batch_idx: 140 |  Loss: (0.5390) |  Loss2: (0.0000) | Acc: (81.00%) (14667/18048)
Epoch: 32 | Batch_idx: 150 |  Loss: (0.5395) |  Loss2: (0.0000) | Acc: (81.00%) (15695/19328)
Epoch: 32 | Batch_idx: 160 |  Loss: (0.5452) |  Loss2: (0.0000) | Acc: (81.00%) (16696/20608)
Epoch: 32 | Batch_idx: 170 |  Loss: (0.5452) |  Loss2: (0.0000) | Acc: (81.00%) (17738/21888)
Epoch: 32 | Batch_idx: 180 |  Loss: (0.5460) |  Loss2: (0.0000) | Acc: (81.00%) (18770/23168)
Epoch: 32 | Batch_idx: 190 |  Loss: (0.5453) |  Loss2: (0.0000) | Acc: (81.00%) (19811/24448)
Epoch: 32 | Batch_idx: 200 |  Loss: (0.5452) |  Loss2: (0.0000) | Acc: (81.00%) (20848/25728)
Epoch: 32 | Batch_idx: 210 |  Loss: (0.5426) |  Loss2: (0.0000) | Acc: (81.00%) (21915/27008)
Epoch: 32 | Batch_idx: 220 |  Loss: (0.5418) |  Loss2: (0.0000) | Acc: (81.00%) (22953/28288)
Epoch: 32 | Batch_idx: 230 |  Loss: (0.5415) |  Loss2: (0.0000) | Acc: (81.00%) (23992/29568)
Epoch: 32 | Batch_idx: 240 |  Loss: (0.5406) |  Loss2: (0.0000) | Acc: (81.00%) (25047/30848)
Epoch: 32 | Batch_idx: 250 |  Loss: (0.5404) |  Loss2: (0.0000) | Acc: (81.00%) (26094/32128)
Epoch: 32 | Batch_idx: 260 |  Loss: (0.5394) |  Loss2: (0.0000) | Acc: (81.00%) (27149/33408)
Epoch: 32 | Batch_idx: 270 |  Loss: (0.5401) |  Loss2: (0.0000) | Acc: (81.00%) (28172/34688)
Epoch: 32 | Batch_idx: 280 |  Loss: (0.5405) |  Loss2: (0.0000) | Acc: (81.00%) (29211/35968)
Epoch: 32 | Batch_idx: 290 |  Loss: (0.5409) |  Loss2: (0.0000) | Acc: (81.00%) (30242/37248)
Epoch: 32 | Batch_idx: 300 |  Loss: (0.5405) |  Loss2: (0.0000) | Acc: (81.00%) (31265/38528)
Epoch: 32 | Batch_idx: 310 |  Loss: (0.5392) |  Loss2: (0.0000) | Acc: (81.00%) (32329/39808)
Epoch: 32 | Batch_idx: 320 |  Loss: (0.5395) |  Loss2: (0.0000) | Acc: (81.00%) (33371/41088)
Epoch: 32 | Batch_idx: 330 |  Loss: (0.5382) |  Loss2: (0.0000) | Acc: (81.00%) (34423/42368)
Epoch: 32 | Batch_idx: 340 |  Loss: (0.5369) |  Loss2: (0.0000) | Acc: (81.00%) (35473/43648)
Epoch: 32 | Batch_idx: 350 |  Loss: (0.5356) |  Loss2: (0.0000) | Acc: (81.00%) (36532/44928)
Epoch: 32 | Batch_idx: 360 |  Loss: (0.5354) |  Loss2: (0.0000) | Acc: (81.00%) (37571/46208)
Epoch: 32 | Batch_idx: 370 |  Loss: (0.5362) |  Loss2: (0.0000) | Acc: (81.00%) (38610/47488)
Epoch: 32 | Batch_idx: 380 |  Loss: (0.5354) |  Loss2: (0.0000) | Acc: (81.00%) (39662/48768)
Epoch: 32 | Batch_idx: 390 |  Loss: (0.5356) |  Loss2: (0.0000) | Acc: (81.00%) (40658/50000)
# TEST : Loss: (0.6447) | Acc: (78.00%) (7816/10000)
percent tensor([0.5310, 0.5295, 0.5376, 0.5303, 0.5384, 0.5364, 0.5345, 0.5291, 0.5301,
        0.5303, 0.5298, 0.5351, 0.5285, 0.5257, 0.5314, 0.5296],
       device='cuda:0') torch.Size([16])
percent tensor([0.5436, 0.5275, 0.5130, 0.5564, 0.5339, 0.5840, 0.5271, 0.5382, 0.5310,
        0.5225, 0.5306, 0.5137, 0.5236, 0.5552, 0.5515, 0.5533],
       device='cuda:0') torch.Size([16])
percent tensor([0.4584, 0.4983, 0.4367, 0.4343, 0.4364, 0.4508, 0.4749, 0.4456, 0.4652,
        0.4741, 0.4754, 0.4483, 0.4748, 0.4919, 0.4674, 0.4658],
       device='cuda:0') torch.Size([16])
percent tensor([0.5733, 0.5463, 0.5544, 0.5699, 0.5713, 0.5951, 0.5533, 0.5609, 0.5649,
        0.5608, 0.5641, 0.5483, 0.5541, 0.5642, 0.5617, 0.5800],
       device='cuda:0') torch.Size([16])
percent tensor([0.5478, 0.5667, 0.5441, 0.5385, 0.4950, 0.6263, 0.5222, 0.4843, 0.5863,
        0.5256, 0.5640, 0.5590, 0.6208, 0.6061, 0.5116, 0.5526],
       device='cuda:0') torch.Size([16])
percent tensor([0.6418, 0.6061, 0.7008, 0.7165, 0.7302, 0.6694, 0.6519, 0.7198, 0.6628,
        0.6346, 0.6487, 0.6568, 0.5702, 0.6712, 0.6499, 0.6533],
       device='cuda:0') torch.Size([16])
percent tensor([0.6188, 0.6074, 0.6365, 0.6193, 0.6841, 0.5420, 0.6291, 0.7029, 0.6190,
        0.6644, 0.5984, 0.5947, 0.5285, 0.6321, 0.6149, 0.6518],
       device='cuda:0') torch.Size([16])
percent tensor([0.9942, 0.9868, 0.9935, 0.9944, 0.9940, 0.9876, 0.9938, 0.9968, 0.9863,
        0.9935, 0.9877, 0.9929, 0.9873, 0.9893, 0.9939, 0.9960],
       device='cuda:0') torch.Size([16])
Epoch: 33 | Batch_idx: 0 |  Loss: (0.5997) |  Loss2: (0.0000) | Acc: (79.00%) (102/128)
Epoch: 33 | Batch_idx: 10 |  Loss: (0.5171) |  Loss2: (0.0000) | Acc: (81.00%) (1148/1408)
Epoch: 33 | Batch_idx: 20 |  Loss: (0.4962) |  Loss2: (0.0000) | Acc: (82.00%) (2208/2688)
Epoch: 33 | Batch_idx: 30 |  Loss: (0.5060) |  Loss2: (0.0000) | Acc: (81.00%) (3242/3968)
Epoch: 33 | Batch_idx: 40 |  Loss: (0.5022) |  Loss2: (0.0000) | Acc: (81.00%) (4298/5248)
Epoch: 33 | Batch_idx: 50 |  Loss: (0.5056) |  Loss2: (0.0000) | Acc: (82.00%) (5354/6528)
Epoch: 33 | Batch_idx: 60 |  Loss: (0.5051) |  Loss2: (0.0000) | Acc: (82.00%) (6415/7808)
Epoch: 33 | Batch_idx: 70 |  Loss: (0.5041) |  Loss2: (0.0000) | Acc: (82.00%) (7474/9088)
Epoch: 33 | Batch_idx: 80 |  Loss: (0.5048) |  Loss2: (0.0000) | Acc: (82.00%) (8527/10368)
Epoch: 33 | Batch_idx: 90 |  Loss: (0.5054) |  Loss2: (0.0000) | Acc: (82.00%) (9567/11648)
Epoch: 33 | Batch_idx: 100 |  Loss: (0.5155) |  Loss2: (0.0000) | Acc: (81.00%) (10594/12928)
Epoch: 33 | Batch_idx: 110 |  Loss: (0.5172) |  Loss2: (0.0000) | Acc: (81.00%) (11638/14208)
Epoch: 33 | Batch_idx: 120 |  Loss: (0.5175) |  Loss2: (0.0000) | Acc: (81.00%) (12692/15488)
Epoch: 33 | Batch_idx: 130 |  Loss: (0.5181) |  Loss2: (0.0000) | Acc: (81.00%) (13744/16768)
Epoch: 33 | Batch_idx: 140 |  Loss: (0.5177) |  Loss2: (0.0000) | Acc: (81.00%) (14796/18048)
Epoch: 33 | Batch_idx: 150 |  Loss: (0.5169) |  Loss2: (0.0000) | Acc: (81.00%) (15845/19328)
Epoch: 33 | Batch_idx: 160 |  Loss: (0.5190) |  Loss2: (0.0000) | Acc: (81.00%) (16886/20608)
Epoch: 33 | Batch_idx: 170 |  Loss: (0.5199) |  Loss2: (0.0000) | Acc: (81.00%) (17928/21888)
Epoch: 33 | Batch_idx: 180 |  Loss: (0.5203) |  Loss2: (0.0000) | Acc: (81.00%) (18986/23168)
Epoch: 33 | Batch_idx: 190 |  Loss: (0.5203) |  Loss2: (0.0000) | Acc: (81.00%) (20026/24448)
Epoch: 33 | Batch_idx: 200 |  Loss: (0.5187) |  Loss2: (0.0000) | Acc: (82.00%) (21106/25728)
Epoch: 33 | Batch_idx: 210 |  Loss: (0.5203) |  Loss2: (0.0000) | Acc: (81.00%) (22143/27008)
Epoch: 33 | Batch_idx: 220 |  Loss: (0.5217) |  Loss2: (0.0000) | Acc: (81.00%) (23172/28288)
Epoch: 33 | Batch_idx: 230 |  Loss: (0.5200) |  Loss2: (0.0000) | Acc: (81.00%) (24241/29568)
Epoch: 33 | Batch_idx: 240 |  Loss: (0.5194) |  Loss2: (0.0000) | Acc: (81.00%) (25295/30848)
Epoch: 33 | Batch_idx: 250 |  Loss: (0.5193) |  Loss2: (0.0000) | Acc: (82.00%) (26349/32128)
Epoch: 33 | Batch_idx: 260 |  Loss: (0.5196) |  Loss2: (0.0000) | Acc: (81.00%) (27388/33408)
Epoch: 33 | Batch_idx: 270 |  Loss: (0.5180) |  Loss2: (0.0000) | Acc: (82.00%) (28451/34688)
Epoch: 33 | Batch_idx: 280 |  Loss: (0.5177) |  Loss2: (0.0000) | Acc: (82.00%) (29503/35968)
Epoch: 33 | Batch_idx: 290 |  Loss: (0.5172) |  Loss2: (0.0000) | Acc: (82.00%) (30548/37248)
Epoch: 33 | Batch_idx: 300 |  Loss: (0.5167) |  Loss2: (0.0000) | Acc: (82.00%) (31617/38528)
Epoch: 33 | Batch_idx: 310 |  Loss: (0.5164) |  Loss2: (0.0000) | Acc: (82.00%) (32661/39808)
Epoch: 33 | Batch_idx: 320 |  Loss: (0.5155) |  Loss2: (0.0000) | Acc: (82.00%) (33720/41088)
Epoch: 33 | Batch_idx: 330 |  Loss: (0.5153) |  Loss2: (0.0000) | Acc: (82.00%) (34769/42368)
Epoch: 33 | Batch_idx: 340 |  Loss: (0.5156) |  Loss2: (0.0000) | Acc: (82.00%) (35796/43648)
Epoch: 33 | Batch_idx: 350 |  Loss: (0.5153) |  Loss2: (0.0000) | Acc: (82.00%) (36852/44928)
Epoch: 33 | Batch_idx: 360 |  Loss: (0.5146) |  Loss2: (0.0000) | Acc: (82.00%) (37916/46208)
Epoch: 33 | Batch_idx: 370 |  Loss: (0.5150) |  Loss2: (0.0000) | Acc: (82.00%) (38956/47488)
Epoch: 33 | Batch_idx: 380 |  Loss: (0.5156) |  Loss2: (0.0000) | Acc: (81.00%) (39987/48768)
Epoch: 33 | Batch_idx: 390 |  Loss: (0.5168) |  Loss2: (0.0000) | Acc: (81.00%) (40975/50000)
# TEST : Loss: (0.6005) | Acc: (79.00%) (7923/10000)
percent tensor([0.5311, 0.5308, 0.5383, 0.5306, 0.5392, 0.5371, 0.5354, 0.5298, 0.5312,
        0.5307, 0.5296, 0.5360, 0.5286, 0.5277, 0.5320, 0.5297],
       device='cuda:0') torch.Size([16])
percent tensor([0.5472, 0.5291, 0.5146, 0.5549, 0.5368, 0.5904, 0.5304, 0.5366, 0.5339,
        0.5239, 0.5326, 0.5165, 0.5255, 0.5559, 0.5541, 0.5546],
       device='cuda:0') torch.Size([16])
percent tensor([0.4625, 0.5023, 0.4418, 0.4368, 0.4421, 0.4490, 0.4798, 0.4500, 0.4706,
        0.4780, 0.4786, 0.4543, 0.4781, 0.4960, 0.4672, 0.4676],
       device='cuda:0') torch.Size([16])
percent tensor([0.5713, 0.5476, 0.5491, 0.5664, 0.5664, 0.5942, 0.5537, 0.5560, 0.5631,
        0.5605, 0.5617, 0.5465, 0.5533, 0.5651, 0.5616, 0.5795],
       device='cuda:0') torch.Size([16])
percent tensor([0.5624, 0.5988, 0.5533, 0.5469, 0.5095, 0.6231, 0.5451, 0.5012, 0.6019,
        0.5440, 0.5853, 0.5596, 0.6351, 0.6161, 0.5291, 0.5758],
       device='cuda:0') torch.Size([16])
percent tensor([0.6397, 0.5999, 0.7037, 0.7144, 0.7280, 0.6725, 0.6515, 0.7102, 0.6650,
        0.6319, 0.6393, 0.6604, 0.5667, 0.6729, 0.6467, 0.6491],
       device='cuda:0') torch.Size([16])
percent tensor([0.6322, 0.5551, 0.6338, 0.6251, 0.6789, 0.5646, 0.6058, 0.6827, 0.5954,
        0.6371, 0.5741, 0.6047, 0.5031, 0.6051, 0.6094, 0.6489],
       device='cuda:0') torch.Size([16])
percent tensor([0.9949, 0.9821, 0.9914, 0.9937, 0.9912, 0.9901, 0.9895, 0.9959, 0.9878,
        0.9923, 0.9907, 0.9938, 0.9891, 0.9884, 0.9928, 0.9962],
       device='cuda:0') torch.Size([16])
Epoch: 34 | Batch_idx: 0 |  Loss: (0.5265) |  Loss2: (0.0000) | Acc: (83.00%) (107/128)
Epoch: 34 | Batch_idx: 10 |  Loss: (0.5100) |  Loss2: (0.0000) | Acc: (81.00%) (1143/1408)
Epoch: 34 | Batch_idx: 20 |  Loss: (0.4976) |  Loss2: (0.0000) | Acc: (82.00%) (2227/2688)
Epoch: 34 | Batch_idx: 30 |  Loss: (0.5074) |  Loss2: (0.0000) | Acc: (82.00%) (3273/3968)
Epoch: 34 | Batch_idx: 40 |  Loss: (0.5042) |  Loss2: (0.0000) | Acc: (82.00%) (4319/5248)
Epoch: 34 | Batch_idx: 50 |  Loss: (0.4982) |  Loss2: (0.0000) | Acc: (82.00%) (5391/6528)
Epoch: 34 | Batch_idx: 60 |  Loss: (0.5036) |  Loss2: (0.0000) | Acc: (82.00%) (6427/7808)
Epoch: 34 | Batch_idx: 70 |  Loss: (0.5002) |  Loss2: (0.0000) | Acc: (82.00%) (7498/9088)
Epoch: 34 | Batch_idx: 80 |  Loss: (0.5051) |  Loss2: (0.0000) | Acc: (82.00%) (8547/10368)
Epoch: 34 | Batch_idx: 90 |  Loss: (0.5073) |  Loss2: (0.0000) | Acc: (82.00%) (9597/11648)
Epoch: 34 | Batch_idx: 100 |  Loss: (0.5020) |  Loss2: (0.0000) | Acc: (82.00%) (10688/12928)
Epoch: 34 | Batch_idx: 110 |  Loss: (0.5007) |  Loss2: (0.0000) | Acc: (82.00%) (11737/14208)
Epoch: 34 | Batch_idx: 120 |  Loss: (0.4984) |  Loss2: (0.0000) | Acc: (82.00%) (12801/15488)
Epoch: 34 | Batch_idx: 130 |  Loss: (0.4972) |  Loss2: (0.0000) | Acc: (82.00%) (13872/16768)
Epoch: 34 | Batch_idx: 140 |  Loss: (0.4981) |  Loss2: (0.0000) | Acc: (82.00%) (14925/18048)
Epoch: 34 | Batch_idx: 150 |  Loss: (0.4991) |  Loss2: (0.0000) | Acc: (82.00%) (15974/19328)
Epoch: 34 | Batch_idx: 160 |  Loss: (0.4979) |  Loss2: (0.0000) | Acc: (82.00%) (17042/20608)
Epoch: 34 | Batch_idx: 170 |  Loss: (0.4993) |  Loss2: (0.0000) | Acc: (82.00%) (18079/21888)
Epoch: 34 | Batch_idx: 180 |  Loss: (0.4965) |  Loss2: (0.0000) | Acc: (82.00%) (19165/23168)
Epoch: 34 | Batch_idx: 190 |  Loss: (0.4976) |  Loss2: (0.0000) | Acc: (82.00%) (20221/24448)
Epoch: 34 | Batch_idx: 200 |  Loss: (0.4978) |  Loss2: (0.0000) | Acc: (82.00%) (21284/25728)
Epoch: 34 | Batch_idx: 210 |  Loss: (0.4981) |  Loss2: (0.0000) | Acc: (82.00%) (22339/27008)
Epoch: 34 | Batch_idx: 220 |  Loss: (0.4984) |  Loss2: (0.0000) | Acc: (82.00%) (23400/28288)
Epoch: 34 | Batch_idx: 230 |  Loss: (0.4990) |  Loss2: (0.0000) | Acc: (82.00%) (24447/29568)
Epoch: 34 | Batch_idx: 240 |  Loss: (0.4980) |  Loss2: (0.0000) | Acc: (82.00%) (25520/30848)
Epoch: 34 | Batch_idx: 250 |  Loss: (0.4969) |  Loss2: (0.0000) | Acc: (82.00%) (26600/32128)
Epoch: 34 | Batch_idx: 260 |  Loss: (0.4963) |  Loss2: (0.0000) | Acc: (82.00%) (27670/33408)
Epoch: 34 | Batch_idx: 270 |  Loss: (0.4988) |  Loss2: (0.0000) | Acc: (82.00%) (28705/34688)
Epoch: 34 | Batch_idx: 280 |  Loss: (0.4985) |  Loss2: (0.0000) | Acc: (82.00%) (29777/35968)
Epoch: 34 | Batch_idx: 290 |  Loss: (0.4995) |  Loss2: (0.0000) | Acc: (82.00%) (30827/37248)
Epoch: 34 | Batch_idx: 300 |  Loss: (0.4989) |  Loss2: (0.0000) | Acc: (82.00%) (31901/38528)
Epoch: 34 | Batch_idx: 310 |  Loss: (0.4988) |  Loss2: (0.0000) | Acc: (82.00%) (32972/39808)
Epoch: 34 | Batch_idx: 320 |  Loss: (0.4987) |  Loss2: (0.0000) | Acc: (82.00%) (34017/41088)
Epoch: 34 | Batch_idx: 330 |  Loss: (0.4996) |  Loss2: (0.0000) | Acc: (82.00%) (35063/42368)
Epoch: 34 | Batch_idx: 340 |  Loss: (0.4980) |  Loss2: (0.0000) | Acc: (82.00%) (36149/43648)
Epoch: 34 | Batch_idx: 350 |  Loss: (0.4969) |  Loss2: (0.0000) | Acc: (82.00%) (37231/44928)
Epoch: 34 | Batch_idx: 360 |  Loss: (0.4963) |  Loss2: (0.0000) | Acc: (82.00%) (38283/46208)
Epoch: 34 | Batch_idx: 370 |  Loss: (0.4956) |  Loss2: (0.0000) | Acc: (82.00%) (39348/47488)
Epoch: 34 | Batch_idx: 380 |  Loss: (0.4954) |  Loss2: (0.0000) | Acc: (82.00%) (40404/48768)
Epoch: 34 | Batch_idx: 390 |  Loss: (0.4951) |  Loss2: (0.0000) | Acc: (82.00%) (41435/50000)
# TEST : Loss: (0.5911) | Acc: (79.00%) (7992/10000)
percent tensor([0.5295, 0.5311, 0.5351, 0.5301, 0.5366, 0.5353, 0.5345, 0.5282, 0.5303,
        0.5303, 0.5294, 0.5336, 0.5278, 0.5294, 0.5316, 0.5293],
       device='cuda:0') torch.Size([16])
percent tensor([0.5474, 0.5275, 0.5192, 0.5559, 0.5411, 0.5865, 0.5298, 0.5384, 0.5314,
        0.5240, 0.5290, 0.5180, 0.5256, 0.5504, 0.5515, 0.5529],
       device='cuda:0') torch.Size([16])
percent tensor([0.4629, 0.4992, 0.4459, 0.4385, 0.4459, 0.4486, 0.4797, 0.4496, 0.4712,
        0.4766, 0.4784, 0.4565, 0.4784, 0.4931, 0.4659, 0.4674],
       device='cuda:0') torch.Size([16])
percent tensor([0.5730, 0.5518, 0.5541, 0.5686, 0.5712, 0.5938, 0.5556, 0.5604, 0.5642,
        0.5633, 0.5640, 0.5490, 0.5561, 0.5670, 0.5641, 0.5808],
       device='cuda:0') torch.Size([16])
percent tensor([0.5692, 0.5887, 0.5342, 0.5591, 0.4866, 0.6431, 0.5473, 0.4790, 0.6108,
        0.5306, 0.5964, 0.5484, 0.6303, 0.6286, 0.5287, 0.5859],
       device='cuda:0') torch.Size([16])
percent tensor([0.6386, 0.6078, 0.6880, 0.7096, 0.7127, 0.6647, 0.6474, 0.7031, 0.6644,
        0.6367, 0.6421, 0.6519, 0.5668, 0.6869, 0.6428, 0.6461],
       device='cuda:0') torch.Size([16])
percent tensor([0.6284, 0.6022, 0.6375, 0.6186, 0.6753, 0.5609, 0.6351, 0.6866, 0.6234,
        0.6748, 0.5930, 0.6112, 0.5411, 0.6179, 0.6142, 0.6427],
       device='cuda:0') torch.Size([16])
percent tensor([0.9936, 0.9856, 0.9915, 0.9950, 0.9912, 0.9888, 0.9912, 0.9945, 0.9894,
        0.9947, 0.9918, 0.9944, 0.9897, 0.9891, 0.9920, 0.9953],
       device='cuda:0') torch.Size([16])
False Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=128, out_features=16, bias=False)
True Linear(in_features=16, out_features=2, bias=False)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=128, out_features=16, bias=False)
True Linear(in_features=16, out_features=2, bias=False)
False Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=256, out_features=32, bias=False)
True Linear(in_features=32, out_features=2, bias=False)
False Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=256, out_features=32, bias=False)
True Linear(in_features=32, out_features=2, bias=False)
False Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=512, out_features=64, bias=False)
True Linear(in_features=64, out_features=2, bias=False)
False Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=512, out_features=64, bias=False)
True Linear(in_features=64, out_features=2, bias=False)
False Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1024, out_features=128, bias=False)
True Linear(in_features=128, out_features=2, bias=False)
False Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1024, out_features=128, bias=False)
True Linear(in_features=128, out_features=2, bias=False)
False Linear(in_features=512, out_features=10, bias=True)
Epoch: 35 | Batch_idx: 0 |  Loss: (0.4312) |  Loss2: (0.0000) | Acc: (85.00%) (110/128)
Epoch: 35 | Batch_idx: 10 |  Loss: (0.4628) |  Loss2: (0.0000) | Acc: (83.00%) (1170/1408)
Epoch: 35 | Batch_idx: 20 |  Loss: (0.5068) |  Loss2: (0.0000) | Acc: (81.00%) (2202/2688)
Epoch: 35 | Batch_idx: 30 |  Loss: (0.5447) |  Loss2: (0.0000) | Acc: (80.00%) (3202/3968)
Epoch: 35 | Batch_idx: 40 |  Loss: (0.5502) |  Loss2: (0.0000) | Acc: (80.00%) (4231/5248)
Epoch: 35 | Batch_idx: 50 |  Loss: (0.5548) |  Loss2: (0.0000) | Acc: (80.00%) (5245/6528)
Epoch: 35 | Batch_idx: 60 |  Loss: (0.5593) |  Loss2: (0.0000) | Acc: (80.00%) (6271/7808)
Epoch: 35 | Batch_idx: 70 |  Loss: (0.5625) |  Loss2: (0.0000) | Acc: (80.00%) (7291/9088)
Epoch: 35 | Batch_idx: 80 |  Loss: (0.5658) |  Loss2: (0.0000) | Acc: (80.00%) (8307/10368)
Epoch: 35 | Batch_idx: 90 |  Loss: (0.5718) |  Loss2: (0.0000) | Acc: (79.00%) (9304/11648)
Epoch: 35 | Batch_idx: 100 |  Loss: (0.5697) |  Loss2: (0.0000) | Acc: (80.00%) (10347/12928)
Epoch: 35 | Batch_idx: 110 |  Loss: (0.5702) |  Loss2: (0.0000) | Acc: (80.00%) (11372/14208)
Epoch: 35 | Batch_idx: 120 |  Loss: (0.5696) |  Loss2: (0.0000) | Acc: (80.00%) (12404/15488)
Epoch: 35 | Batch_idx: 130 |  Loss: (0.5679) |  Loss2: (0.0000) | Acc: (80.00%) (13441/16768)
Epoch: 35 | Batch_idx: 140 |  Loss: (0.5704) |  Loss2: (0.0000) | Acc: (80.00%) (14457/18048)
Epoch: 35 | Batch_idx: 150 |  Loss: (0.5662) |  Loss2: (0.0000) | Acc: (80.00%) (15524/19328)
Epoch: 35 | Batch_idx: 160 |  Loss: (0.5627) |  Loss2: (0.0000) | Acc: (80.00%) (16577/20608)
Epoch: 35 | Batch_idx: 170 |  Loss: (0.5606) |  Loss2: (0.0000) | Acc: (80.00%) (17621/21888)
Epoch: 35 | Batch_idx: 180 |  Loss: (0.5584) |  Loss2: (0.0000) | Acc: (80.00%) (18666/23168)
Epoch: 35 | Batch_idx: 190 |  Loss: (0.5565) |  Loss2: (0.0000) | Acc: (80.00%) (19723/24448)
Epoch: 35 | Batch_idx: 200 |  Loss: (0.5566) |  Loss2: (0.0000) | Acc: (80.00%) (20726/25728)
Epoch: 35 | Batch_idx: 210 |  Loss: (0.5569) |  Loss2: (0.0000) | Acc: (80.00%) (21772/27008)
Epoch: 35 | Batch_idx: 220 |  Loss: (0.5546) |  Loss2: (0.0000) | Acc: (80.00%) (22819/28288)
Epoch: 35 | Batch_idx: 230 |  Loss: (0.5540) |  Loss2: (0.0000) | Acc: (80.00%) (23861/29568)
Epoch: 35 | Batch_idx: 240 |  Loss: (0.5554) |  Loss2: (0.0000) | Acc: (80.00%) (24884/30848)
Epoch: 35 | Batch_idx: 250 |  Loss: (0.5570) |  Loss2: (0.0000) | Acc: (80.00%) (25896/32128)
Epoch: 35 | Batch_idx: 260 |  Loss: (0.5556) |  Loss2: (0.0000) | Acc: (80.00%) (26954/33408)
Epoch: 35 | Batch_idx: 270 |  Loss: (0.5548) |  Loss2: (0.0000) | Acc: (80.00%) (27996/34688)
Epoch: 35 | Batch_idx: 280 |  Loss: (0.5528) |  Loss2: (0.0000) | Acc: (80.00%) (29053/35968)
Epoch: 35 | Batch_idx: 290 |  Loss: (0.5528) |  Loss2: (0.0000) | Acc: (80.00%) (30095/37248)
Epoch: 35 | Batch_idx: 300 |  Loss: (0.5534) |  Loss2: (0.0000) | Acc: (80.00%) (31118/38528)
Epoch: 35 | Batch_idx: 310 |  Loss: (0.5514) |  Loss2: (0.0000) | Acc: (80.00%) (32170/39808)
Epoch: 35 | Batch_idx: 320 |  Loss: (0.5509) |  Loss2: (0.0000) | Acc: (80.00%) (33224/41088)
Epoch: 35 | Batch_idx: 330 |  Loss: (0.5509) |  Loss2: (0.0000) | Acc: (80.00%) (34259/42368)
Epoch: 35 | Batch_idx: 340 |  Loss: (0.5499) |  Loss2: (0.0000) | Acc: (80.00%) (35315/43648)
Epoch: 35 | Batch_idx: 350 |  Loss: (0.5487) |  Loss2: (0.0000) | Acc: (80.00%) (36383/44928)
Epoch: 35 | Batch_idx: 360 |  Loss: (0.5499) |  Loss2: (0.0000) | Acc: (80.00%) (37396/46208)
Epoch: 35 | Batch_idx: 370 |  Loss: (0.5486) |  Loss2: (0.0000) | Acc: (80.00%) (38463/47488)
Epoch: 35 | Batch_idx: 380 |  Loss: (0.5477) |  Loss2: (0.0000) | Acc: (81.00%) (39504/48768)
Epoch: 35 | Batch_idx: 390 |  Loss: (0.5464) |  Loss2: (0.0000) | Acc: (81.00%) (40519/50000)
=> saving checkpoint 'drive/app/torch/save_Routing_Gate_2/checkpoint_035.pth.tar'
# TEST : Loss: (0.5813) | Acc: (79.00%) (7942/10000)
percent tensor([0.5668, 0.5725, 0.5776, 0.5680, 0.5805, 0.5687, 0.5779, 0.5683, 0.5700,
        0.5712, 0.5684, 0.5767, 0.5661, 0.5651, 0.5703, 0.5660],
       device='cuda:0') torch.Size([16])
percent tensor([0.5537, 0.5337, 0.5304, 0.5636, 0.5509, 0.5921, 0.5379, 0.5480, 0.5409,
        0.5333, 0.5373, 0.5285, 0.5331, 0.5548, 0.5584, 0.5592],
       device='cuda:0') torch.Size([16])
percent tensor([0.4503, 0.4830, 0.4469, 0.4353, 0.4467, 0.4358, 0.4692, 0.4522, 0.4601,
        0.4603, 0.4584, 0.4507, 0.4628, 0.4750, 0.4543, 0.4540],
       device='cuda:0') torch.Size([16])
percent tensor([0.6095, 0.5931, 0.5821, 0.6027, 0.6024, 0.6289, 0.5963, 0.5953, 0.6012,
        0.6050, 0.6081, 0.5847, 0.5945, 0.6105, 0.6033, 0.6210],
       device='cuda:0') torch.Size([16])
percent tensor([0.5435, 0.5835, 0.5192, 0.5404, 0.4892, 0.5871, 0.5407, 0.4795, 0.5908,
        0.5327, 0.5916, 0.5303, 0.6080, 0.6168, 0.5164, 0.5559],
       device='cuda:0') torch.Size([16])
percent tensor([0.6533, 0.6184, 0.6931, 0.7179, 0.7192, 0.6837, 0.6623, 0.7083, 0.6878,
        0.6531, 0.6651, 0.6559, 0.5962, 0.6987, 0.6568, 0.6632],
       device='cuda:0') torch.Size([16])
percent tensor([0.5892, 0.5394, 0.6423, 0.6256, 0.6870, 0.5407, 0.6171, 0.7214, 0.5875,
        0.6345, 0.5217, 0.6134, 0.4559, 0.5256, 0.6181, 0.6331],
       device='cuda:0') torch.Size([16])
percent tensor([0.9951, 0.9881, 0.9896, 0.9951, 0.9892, 0.9920, 0.9935, 0.9944, 0.9912,
        0.9953, 0.9925, 0.9962, 0.9910, 0.9903, 0.9925, 0.9956],
       device='cuda:0') torch.Size([16])
Epoch: 36 | Batch_idx: 0 |  Loss: (0.5749) |  Loss2: (0.0000) | Acc: (81.00%) (104/128)
Epoch: 36 | Batch_idx: 10 |  Loss: (0.5046) |  Loss2: (0.0000) | Acc: (82.00%) (1162/1408)
Epoch: 36 | Batch_idx: 20 |  Loss: (0.5248) |  Loss2: (0.0000) | Acc: (81.00%) (2193/2688)
Epoch: 36 | Batch_idx: 30 |  Loss: (0.5385) |  Loss2: (0.0000) | Acc: (81.00%) (3224/3968)
Epoch: 36 | Batch_idx: 40 |  Loss: (0.5252) |  Loss2: (0.0000) | Acc: (82.00%) (4306/5248)
Epoch: 36 | Batch_idx: 50 |  Loss: (0.5224) |  Loss2: (0.0000) | Acc: (82.00%) (5362/6528)
Epoch: 36 | Batch_idx: 60 |  Loss: (0.5224) |  Loss2: (0.0000) | Acc: (82.00%) (6412/7808)
Epoch: 36 | Batch_idx: 70 |  Loss: (0.5183) |  Loss2: (0.0000) | Acc: (82.00%) (7470/9088)
Epoch: 36 | Batch_idx: 80 |  Loss: (0.5200) |  Loss2: (0.0000) | Acc: (82.00%) (8523/10368)
Epoch: 36 | Batch_idx: 90 |  Loss: (0.5188) |  Loss2: (0.0000) | Acc: (82.00%) (9586/11648)
Epoch: 36 | Batch_idx: 100 |  Loss: (0.5208) |  Loss2: (0.0000) | Acc: (82.00%) (10628/12928)
Epoch: 36 | Batch_idx: 110 |  Loss: (0.5201) |  Loss2: (0.0000) | Acc: (82.00%) (11688/14208)
Epoch: 36 | Batch_idx: 120 |  Loss: (0.5218) |  Loss2: (0.0000) | Acc: (82.00%) (12729/15488)
Epoch: 36 | Batch_idx: 130 |  Loss: (0.5191) |  Loss2: (0.0000) | Acc: (82.00%) (13806/16768)
Epoch: 36 | Batch_idx: 140 |  Loss: (0.5158) |  Loss2: (0.0000) | Acc: (82.00%) (14879/18048)
Epoch: 36 | Batch_idx: 150 |  Loss: (0.5131) |  Loss2: (0.0000) | Acc: (82.00%) (15936/19328)
Epoch: 36 | Batch_idx: 160 |  Loss: (0.5114) |  Loss2: (0.0000) | Acc: (82.00%) (16995/20608)
Epoch: 36 | Batch_idx: 170 |  Loss: (0.5125) |  Loss2: (0.0000) | Acc: (82.00%) (18049/21888)
Epoch: 36 | Batch_idx: 180 |  Loss: (0.5111) |  Loss2: (0.0000) | Acc: (82.00%) (19116/23168)
Epoch: 36 | Batch_idx: 190 |  Loss: (0.5126) |  Loss2: (0.0000) | Acc: (82.00%) (20151/24448)
Epoch: 36 | Batch_idx: 200 |  Loss: (0.5143) |  Loss2: (0.0000) | Acc: (82.00%) (21198/25728)
Epoch: 36 | Batch_idx: 210 |  Loss: (0.5155) |  Loss2: (0.0000) | Acc: (82.00%) (22250/27008)
Epoch: 36 | Batch_idx: 220 |  Loss: (0.5133) |  Loss2: (0.0000) | Acc: (82.00%) (23342/28288)
Epoch: 36 | Batch_idx: 230 |  Loss: (0.5128) |  Loss2: (0.0000) | Acc: (82.00%) (24388/29568)
Epoch: 36 | Batch_idx: 240 |  Loss: (0.5108) |  Loss2: (0.0000) | Acc: (82.00%) (25465/30848)
Epoch: 36 | Batch_idx: 250 |  Loss: (0.5115) |  Loss2: (0.0000) | Acc: (82.00%) (26505/32128)
Epoch: 36 | Batch_idx: 260 |  Loss: (0.5113) |  Loss2: (0.0000) | Acc: (82.00%) (27564/33408)
Epoch: 36 | Batch_idx: 270 |  Loss: (0.5096) |  Loss2: (0.0000) | Acc: (82.00%) (28634/34688)
Epoch: 36 | Batch_idx: 280 |  Loss: (0.5107) |  Loss2: (0.0000) | Acc: (82.00%) (29675/35968)
Epoch: 36 | Batch_idx: 290 |  Loss: (0.5119) |  Loss2: (0.0000) | Acc: (82.00%) (30714/37248)
Epoch: 36 | Batch_idx: 300 |  Loss: (0.5135) |  Loss2: (0.0000) | Acc: (82.00%) (31760/38528)
Epoch: 36 | Batch_idx: 310 |  Loss: (0.5133) |  Loss2: (0.0000) | Acc: (82.00%) (32830/39808)
Epoch: 36 | Batch_idx: 320 |  Loss: (0.5128) |  Loss2: (0.0000) | Acc: (82.00%) (33903/41088)
Epoch: 36 | Batch_idx: 330 |  Loss: (0.5133) |  Loss2: (0.0000) | Acc: (82.00%) (34944/42368)
Epoch: 36 | Batch_idx: 340 |  Loss: (0.5132) |  Loss2: (0.0000) | Acc: (82.00%) (35983/43648)
Epoch: 36 | Batch_idx: 350 |  Loss: (0.5124) |  Loss2: (0.0000) | Acc: (82.00%) (37052/44928)
Epoch: 36 | Batch_idx: 360 |  Loss: (0.5127) |  Loss2: (0.0000) | Acc: (82.00%) (38103/46208)
Epoch: 36 | Batch_idx: 370 |  Loss: (0.5125) |  Loss2: (0.0000) | Acc: (82.00%) (39158/47488)
Epoch: 36 | Batch_idx: 380 |  Loss: (0.5116) |  Loss2: (0.0000) | Acc: (82.00%) (40222/48768)
Epoch: 36 | Batch_idx: 390 |  Loss: (0.5118) |  Loss2: (0.0000) | Acc: (82.00%) (41236/50000)
# TEST : Loss: (0.5557) | Acc: (80.00%) (8051/10000)
percent tensor([0.5668, 0.5711, 0.5781, 0.5689, 0.5801, 0.5684, 0.5765, 0.5685, 0.5691,
        0.5707, 0.5675, 0.5764, 0.5658, 0.5632, 0.5696, 0.5658],
       device='cuda:0') torch.Size([16])
percent tensor([0.5535, 0.5341, 0.5329, 0.5652, 0.5519, 0.5919, 0.5385, 0.5489, 0.5418,
        0.5342, 0.5382, 0.5305, 0.5341, 0.5546, 0.5589, 0.5594],
       device='cuda:0') torch.Size([16])
percent tensor([0.4515, 0.4833, 0.4522, 0.4393, 0.4531, 0.4376, 0.4729, 0.4591, 0.4626,
        0.4594, 0.4569, 0.4554, 0.4629, 0.4769, 0.4573, 0.4553],
       device='cuda:0') torch.Size([16])
percent tensor([0.6186, 0.6034, 0.5887, 0.6093, 0.6080, 0.6379, 0.6039, 0.5993, 0.6094,
        0.6158, 0.6193, 0.5934, 0.6063, 0.6197, 0.6114, 0.6314],
       device='cuda:0') torch.Size([16])
percent tensor([0.5509, 0.5990, 0.5252, 0.5407, 0.4896, 0.5873, 0.5480, 0.4782, 0.6016,
        0.5461, 0.6065, 0.5374, 0.6251, 0.6261, 0.5194, 0.5602],
       device='cuda:0') torch.Size([16])
percent tensor([0.6573, 0.6230, 0.6967, 0.7215, 0.7219, 0.6934, 0.6639, 0.7075, 0.6930,
        0.6552, 0.6700, 0.6554, 0.6048, 0.7072, 0.6557, 0.6678],
       device='cuda:0') torch.Size([16])
percent tensor([0.6032, 0.5341, 0.6603, 0.6508, 0.7062, 0.5704, 0.6262, 0.7460, 0.5842,
        0.6320, 0.5117, 0.6267, 0.4522, 0.5163, 0.6344, 0.6594],
       device='cuda:0') torch.Size([16])
percent tensor([0.9958, 0.9901, 0.9910, 0.9954, 0.9908, 0.9932, 0.9943, 0.9947, 0.9925,
        0.9961, 0.9936, 0.9965, 0.9924, 0.9919, 0.9935, 0.9964],
       device='cuda:0') torch.Size([16])
Epoch: 37 | Batch_idx: 0 |  Loss: (0.4037) |  Loss2: (0.0000) | Acc: (82.00%) (106/128)
Epoch: 37 | Batch_idx: 10 |  Loss: (0.4692) |  Loss2: (0.0000) | Acc: (82.00%) (1167/1408)
Epoch: 37 | Batch_idx: 20 |  Loss: (0.5094) |  Loss2: (0.0000) | Acc: (81.00%) (2201/2688)
Epoch: 37 | Batch_idx: 30 |  Loss: (0.5065) |  Loss2: (0.0000) | Acc: (82.00%) (3260/3968)
Epoch: 37 | Batch_idx: 40 |  Loss: (0.5038) |  Loss2: (0.0000) | Acc: (82.00%) (4317/5248)
Epoch: 37 | Batch_idx: 50 |  Loss: (0.5097) |  Loss2: (0.0000) | Acc: (82.00%) (5363/6528)
Epoch: 37 | Batch_idx: 60 |  Loss: (0.5058) |  Loss2: (0.0000) | Acc: (82.00%) (6437/7808)
Epoch: 37 | Batch_idx: 70 |  Loss: (0.5087) |  Loss2: (0.0000) | Acc: (82.00%) (7487/9088)
Epoch: 37 | Batch_idx: 80 |  Loss: (0.5067) |  Loss2: (0.0000) | Acc: (82.00%) (8549/10368)
Epoch: 37 | Batch_idx: 90 |  Loss: (0.5066) |  Loss2: (0.0000) | Acc: (82.00%) (9591/11648)
Epoch: 37 | Batch_idx: 100 |  Loss: (0.5069) |  Loss2: (0.0000) | Acc: (82.00%) (10631/12928)
Epoch: 37 | Batch_idx: 110 |  Loss: (0.5069) |  Loss2: (0.0000) | Acc: (82.00%) (11681/14208)
Epoch: 37 | Batch_idx: 120 |  Loss: (0.5038) |  Loss2: (0.0000) | Acc: (82.00%) (12755/15488)
Epoch: 37 | Batch_idx: 130 |  Loss: (0.5017) |  Loss2: (0.0000) | Acc: (82.00%) (13818/16768)
Epoch: 37 | Batch_idx: 140 |  Loss: (0.5035) |  Loss2: (0.0000) | Acc: (82.00%) (14852/18048)
Epoch: 37 | Batch_idx: 150 |  Loss: (0.5018) |  Loss2: (0.0000) | Acc: (82.00%) (15910/19328)
Epoch: 37 | Batch_idx: 160 |  Loss: (0.4993) |  Loss2: (0.0000) | Acc: (82.00%) (16979/20608)
Epoch: 37 | Batch_idx: 170 |  Loss: (0.4987) |  Loss2: (0.0000) | Acc: (82.00%) (18044/21888)
Epoch: 37 | Batch_idx: 180 |  Loss: (0.4963) |  Loss2: (0.0000) | Acc: (82.00%) (19121/23168)
Epoch: 37 | Batch_idx: 190 |  Loss: (0.4964) |  Loss2: (0.0000) | Acc: (82.00%) (20189/24448)
Epoch: 37 | Batch_idx: 200 |  Loss: (0.4947) |  Loss2: (0.0000) | Acc: (82.00%) (21270/25728)
Epoch: 37 | Batch_idx: 210 |  Loss: (0.4938) |  Loss2: (0.0000) | Acc: (82.00%) (22353/27008)
Epoch: 37 | Batch_idx: 220 |  Loss: (0.4943) |  Loss2: (0.0000) | Acc: (82.00%) (23413/28288)
Epoch: 37 | Batch_idx: 230 |  Loss: (0.4954) |  Loss2: (0.0000) | Acc: (82.00%) (24468/29568)
Epoch: 37 | Batch_idx: 240 |  Loss: (0.4958) |  Loss2: (0.0000) | Acc: (82.00%) (25518/30848)
Epoch: 37 | Batch_idx: 250 |  Loss: (0.4975) |  Loss2: (0.0000) | Acc: (82.00%) (26545/32128)
Epoch: 37 | Batch_idx: 260 |  Loss: (0.4977) |  Loss2: (0.0000) | Acc: (82.00%) (27609/33408)
Epoch: 37 | Batch_idx: 270 |  Loss: (0.4981) |  Loss2: (0.0000) | Acc: (82.00%) (28649/34688)
Epoch: 37 | Batch_idx: 280 |  Loss: (0.4981) |  Loss2: (0.0000) | Acc: (82.00%) (29708/35968)
Epoch: 37 | Batch_idx: 290 |  Loss: (0.4972) |  Loss2: (0.0000) | Acc: (82.00%) (30771/37248)
Epoch: 37 | Batch_idx: 300 |  Loss: (0.4969) |  Loss2: (0.0000) | Acc: (82.00%) (31832/38528)
Epoch: 37 | Batch_idx: 310 |  Loss: (0.4962) |  Loss2: (0.0000) | Acc: (82.00%) (32898/39808)
Epoch: 37 | Batch_idx: 320 |  Loss: (0.4958) |  Loss2: (0.0000) | Acc: (82.00%) (33974/41088)
Epoch: 37 | Batch_idx: 330 |  Loss: (0.4954) |  Loss2: (0.0000) | Acc: (82.00%) (35036/42368)
Epoch: 37 | Batch_idx: 340 |  Loss: (0.4955) |  Loss2: (0.0000) | Acc: (82.00%) (36104/43648)
Epoch: 37 | Batch_idx: 350 |  Loss: (0.4952) |  Loss2: (0.0000) | Acc: (82.00%) (37169/44928)
Epoch: 37 | Batch_idx: 360 |  Loss: (0.4952) |  Loss2: (0.0000) | Acc: (82.00%) (38223/46208)
Epoch: 37 | Batch_idx: 370 |  Loss: (0.4950) |  Loss2: (0.0000) | Acc: (82.00%) (39287/47488)
Epoch: 37 | Batch_idx: 380 |  Loss: (0.4949) |  Loss2: (0.0000) | Acc: (82.00%) (40350/48768)
Epoch: 37 | Batch_idx: 390 |  Loss: (0.4948) |  Loss2: (0.0000) | Acc: (82.00%) (41373/50000)
# TEST : Loss: (0.5489) | Acc: (80.00%) (8079/10000)
percent tensor([0.5637, 0.5661, 0.5750, 0.5665, 0.5760, 0.5655, 0.5715, 0.5653, 0.5647,
        0.5666, 0.5633, 0.5724, 0.5623, 0.5582, 0.5656, 0.5627],
       device='cuda:0') torch.Size([16])
percent tensor([0.5511, 0.5313, 0.5322, 0.5637, 0.5499, 0.5906, 0.5358, 0.5471, 0.5400,
        0.5317, 0.5360, 0.5290, 0.5320, 0.5519, 0.5568, 0.5573],
       device='cuda:0') torch.Size([16])
percent tensor([0.4543, 0.4862, 0.4558, 0.4419, 0.4582, 0.4402, 0.4776, 0.4645, 0.4655,
        0.4606, 0.4578, 0.4601, 0.4654, 0.4794, 0.4618, 0.4582],
       device='cuda:0') torch.Size([16])
percent tensor([0.6207, 0.6062, 0.5899, 0.6107, 0.6077, 0.6407, 0.6044, 0.5981, 0.6114,
        0.6189, 0.6227, 0.5950, 0.6099, 0.6226, 0.6128, 0.6343],
       device='cuda:0') torch.Size([16])
percent tensor([0.5584, 0.6085, 0.5321, 0.5467, 0.4930, 0.5914, 0.5564, 0.4816, 0.6104,
        0.5545, 0.6174, 0.5450, 0.6387, 0.6325, 0.5247, 0.5655],
       device='cuda:0') torch.Size([16])
percent tensor([0.6435, 0.6083, 0.6867, 0.7133, 0.7126, 0.6891, 0.6492, 0.6928, 0.6831,
        0.6400, 0.6582, 0.6390, 0.5910, 0.7012, 0.6380, 0.6552],
       device='cuda:0') torch.Size([16])
percent tensor([0.6123, 0.5311, 0.6683, 0.6645, 0.7159, 0.5909, 0.6316, 0.7541, 0.5836,
        0.6279, 0.5087, 0.6333, 0.4523, 0.5144, 0.6388, 0.6744],
       device='cuda:0') torch.Size([16])
percent tensor([0.9967, 0.9916, 0.9929, 0.9963, 0.9927, 0.9943, 0.9953, 0.9957, 0.9940,
        0.9968, 0.9945, 0.9971, 0.9938, 0.9935, 0.9942, 0.9971],
       device='cuda:0') torch.Size([16])
Epoch: 38 | Batch_idx: 0 |  Loss: (0.3967) |  Loss2: (0.0000) | Acc: (85.00%) (109/128)
Epoch: 38 | Batch_idx: 10 |  Loss: (0.4793) |  Loss2: (0.0000) | Acc: (83.00%) (1172/1408)
Epoch: 38 | Batch_idx: 20 |  Loss: (0.4947) |  Loss2: (0.0000) | Acc: (82.00%) (2222/2688)
Epoch: 38 | Batch_idx: 30 |  Loss: (0.4941) |  Loss2: (0.0000) | Acc: (82.00%) (3286/3968)
Epoch: 38 | Batch_idx: 40 |  Loss: (0.4932) |  Loss2: (0.0000) | Acc: (82.00%) (4336/5248)
Epoch: 38 | Batch_idx: 50 |  Loss: (0.4972) |  Loss2: (0.0000) | Acc: (82.00%) (5407/6528)
Epoch: 38 | Batch_idx: 60 |  Loss: (0.4955) |  Loss2: (0.0000) | Acc: (82.00%) (6464/7808)
Epoch: 38 | Batch_idx: 70 |  Loss: (0.4910) |  Loss2: (0.0000) | Acc: (82.00%) (7541/9088)
Epoch: 38 | Batch_idx: 80 |  Loss: (0.4933) |  Loss2: (0.0000) | Acc: (82.00%) (8604/10368)
Epoch: 38 | Batch_idx: 90 |  Loss: (0.4919) |  Loss2: (0.0000) | Acc: (83.00%) (9675/11648)
Epoch: 38 | Batch_idx: 100 |  Loss: (0.4898) |  Loss2: (0.0000) | Acc: (83.00%) (10744/12928)
Epoch: 38 | Batch_idx: 110 |  Loss: (0.4873) |  Loss2: (0.0000) | Acc: (83.00%) (11812/14208)
Epoch: 38 | Batch_idx: 120 |  Loss: (0.4882) |  Loss2: (0.0000) | Acc: (83.00%) (12875/15488)
Epoch: 38 | Batch_idx: 130 |  Loss: (0.4878) |  Loss2: (0.0000) | Acc: (83.00%) (13943/16768)
Epoch: 38 | Batch_idx: 140 |  Loss: (0.4878) |  Loss2: (0.0000) | Acc: (83.00%) (14988/18048)
Epoch: 38 | Batch_idx: 150 |  Loss: (0.4859) |  Loss2: (0.0000) | Acc: (83.00%) (16062/19328)
Epoch: 38 | Batch_idx: 160 |  Loss: (0.4849) |  Loss2: (0.0000) | Acc: (83.00%) (17136/20608)
Epoch: 38 | Batch_idx: 170 |  Loss: (0.4842) |  Loss2: (0.0000) | Acc: (83.00%) (18212/21888)
Epoch: 38 | Batch_idx: 180 |  Loss: (0.4828) |  Loss2: (0.0000) | Acc: (83.00%) (19293/23168)
Epoch: 38 | Batch_idx: 190 |  Loss: (0.4823) |  Loss2: (0.0000) | Acc: (83.00%) (20361/24448)
Epoch: 38 | Batch_idx: 200 |  Loss: (0.4823) |  Loss2: (0.0000) | Acc: (83.00%) (21442/25728)
Epoch: 38 | Batch_idx: 210 |  Loss: (0.4831) |  Loss2: (0.0000) | Acc: (83.00%) (22498/27008)
Epoch: 38 | Batch_idx: 220 |  Loss: (0.4827) |  Loss2: (0.0000) | Acc: (83.00%) (23570/28288)
Epoch: 38 | Batch_idx: 230 |  Loss: (0.4825) |  Loss2: (0.0000) | Acc: (83.00%) (24645/29568)
Epoch: 38 | Batch_idx: 240 |  Loss: (0.4835) |  Loss2: (0.0000) | Acc: (83.00%) (25702/30848)
Epoch: 38 | Batch_idx: 250 |  Loss: (0.4849) |  Loss2: (0.0000) | Acc: (83.00%) (26761/32128)
Epoch: 38 | Batch_idx: 260 |  Loss: (0.4852) |  Loss2: (0.0000) | Acc: (83.00%) (27817/33408)
Epoch: 38 | Batch_idx: 270 |  Loss: (0.4864) |  Loss2: (0.0000) | Acc: (83.00%) (28878/34688)
Epoch: 38 | Batch_idx: 280 |  Loss: (0.4851) |  Loss2: (0.0000) | Acc: (83.00%) (29958/35968)
Epoch: 38 | Batch_idx: 290 |  Loss: (0.4850) |  Loss2: (0.0000) | Acc: (83.00%) (31024/37248)
Epoch: 38 | Batch_idx: 300 |  Loss: (0.4851) |  Loss2: (0.0000) | Acc: (83.00%) (32083/38528)
Epoch: 38 | Batch_idx: 310 |  Loss: (0.4853) |  Loss2: (0.0000) | Acc: (83.00%) (33147/39808)
Epoch: 38 | Batch_idx: 320 |  Loss: (0.4865) |  Loss2: (0.0000) | Acc: (83.00%) (34228/41088)
Epoch: 38 | Batch_idx: 330 |  Loss: (0.4872) |  Loss2: (0.0000) | Acc: (83.00%) (35280/42368)
Epoch: 38 | Batch_idx: 340 |  Loss: (0.4859) |  Loss2: (0.0000) | Acc: (83.00%) (36353/43648)
Epoch: 38 | Batch_idx: 350 |  Loss: (0.4854) |  Loss2: (0.0000) | Acc: (83.00%) (37428/44928)
Epoch: 38 | Batch_idx: 360 |  Loss: (0.4858) |  Loss2: (0.0000) | Acc: (83.00%) (38480/46208)
Epoch: 38 | Batch_idx: 370 |  Loss: (0.4859) |  Loss2: (0.0000) | Acc: (83.00%) (39554/47488)
Epoch: 38 | Batch_idx: 380 |  Loss: (0.4862) |  Loss2: (0.0000) | Acc: (83.00%) (40630/48768)
Epoch: 38 | Batch_idx: 390 |  Loss: (0.4875) |  Loss2: (0.0000) | Acc: (83.00%) (41638/50000)
# TEST : Loss: (0.5379) | Acc: (81.00%) (8105/10000)
percent tensor([0.5628, 0.5643, 0.5745, 0.5661, 0.5750, 0.5646, 0.5698, 0.5646, 0.5633,
        0.5654, 0.5618, 0.5714, 0.5613, 0.5562, 0.5644, 0.5619],
       device='cuda:0') torch.Size([16])
percent tensor([0.5519, 0.5314, 0.5345, 0.5655, 0.5510, 0.5919, 0.5365, 0.5485, 0.5411,
        0.5325, 0.5371, 0.5305, 0.5329, 0.5521, 0.5576, 0.5581],
       device='cuda:0') torch.Size([16])
percent tensor([0.4548, 0.4886, 0.4573, 0.4427, 0.4611, 0.4408, 0.4807, 0.4673, 0.4670,
        0.4614, 0.4588, 0.4625, 0.4666, 0.4813, 0.4641, 0.4596],
       device='cuda:0') torch.Size([16])
percent tensor([0.6196, 0.6046, 0.5876, 0.6086, 0.6034, 0.6409, 0.6006, 0.5932, 0.6097,
        0.6178, 0.6219, 0.5928, 0.6098, 0.6211, 0.6102, 0.6336],
       device='cuda:0') torch.Size([16])
percent tensor([0.5525, 0.6045, 0.5232, 0.5358, 0.4834, 0.5913, 0.5461, 0.4682, 0.6068,
        0.5489, 0.6142, 0.5314, 0.6364, 0.6290, 0.5132, 0.5597],
       device='cuda:0') torch.Size([16])
percent tensor([0.6471, 0.6115, 0.6914, 0.7183, 0.7178, 0.6979, 0.6518, 0.6950, 0.6889,
        0.6427, 0.6634, 0.6395, 0.5955, 0.7100, 0.6384, 0.6592],
       device='cuda:0') torch.Size([16])
percent tensor([0.6239, 0.5366, 0.6771, 0.6766, 0.7246, 0.6129, 0.6388, 0.7613, 0.5870,
        0.6298, 0.5109, 0.6419, 0.4552, 0.5195, 0.6459, 0.6926],
       device='cuda:0') torch.Size([16])
percent tensor([0.9970, 0.9927, 0.9936, 0.9964, 0.9936, 0.9948, 0.9957, 0.9961, 0.9946,
        0.9972, 0.9950, 0.9973, 0.9944, 0.9943, 0.9949, 0.9975],
       device='cuda:0') torch.Size([16])
Epoch: 39 | Batch_idx: 0 |  Loss: (0.6609) |  Loss2: (0.0000) | Acc: (75.00%) (96/128)
Epoch: 39 | Batch_idx: 10 |  Loss: (0.5031) |  Loss2: (0.0000) | Acc: (82.00%) (1160/1408)
Epoch: 39 | Batch_idx: 20 |  Loss: (0.4807) |  Loss2: (0.0000) | Acc: (83.00%) (2233/2688)
Epoch: 39 | Batch_idx: 30 |  Loss: (0.4786) |  Loss2: (0.0000) | Acc: (83.00%) (3296/3968)
Epoch: 39 | Batch_idx: 40 |  Loss: (0.4772) |  Loss2: (0.0000) | Acc: (83.00%) (4376/5248)
Epoch: 39 | Batch_idx: 50 |  Loss: (0.4753) |  Loss2: (0.0000) | Acc: (83.00%) (5454/6528)
Epoch: 39 | Batch_idx: 60 |  Loss: (0.4705) |  Loss2: (0.0000) | Acc: (83.00%) (6544/7808)
Epoch: 39 | Batch_idx: 70 |  Loss: (0.4711) |  Loss2: (0.0000) | Acc: (83.00%) (7624/9088)
Epoch: 39 | Batch_idx: 80 |  Loss: (0.4699) |  Loss2: (0.0000) | Acc: (84.00%) (8716/10368)
Epoch: 39 | Batch_idx: 90 |  Loss: (0.4734) |  Loss2: (0.0000) | Acc: (83.00%) (9767/11648)
Epoch: 39 | Batch_idx: 100 |  Loss: (0.4773) |  Loss2: (0.0000) | Acc: (83.00%) (10816/12928)
Epoch: 39 | Batch_idx: 110 |  Loss: (0.4791) |  Loss2: (0.0000) | Acc: (83.00%) (11882/14208)
Epoch: 39 | Batch_idx: 120 |  Loss: (0.4795) |  Loss2: (0.0000) | Acc: (83.00%) (12945/15488)
Epoch: 39 | Batch_idx: 130 |  Loss: (0.4835) |  Loss2: (0.0000) | Acc: (83.00%) (13992/16768)
Epoch: 39 | Batch_idx: 140 |  Loss: (0.4850) |  Loss2: (0.0000) | Acc: (83.00%) (15049/18048)
Epoch: 39 | Batch_idx: 150 |  Loss: (0.4851) |  Loss2: (0.0000) | Acc: (83.00%) (16119/19328)
Epoch: 39 | Batch_idx: 160 |  Loss: (0.4854) |  Loss2: (0.0000) | Acc: (83.00%) (17189/20608)
Epoch: 39 | Batch_idx: 170 |  Loss: (0.4868) |  Loss2: (0.0000) | Acc: (83.00%) (18231/21888)
Epoch: 39 | Batch_idx: 180 |  Loss: (0.4849) |  Loss2: (0.0000) | Acc: (83.00%) (19316/23168)
Epoch: 39 | Batch_idx: 190 |  Loss: (0.4858) |  Loss2: (0.0000) | Acc: (83.00%) (20377/24448)
Epoch: 39 | Batch_idx: 200 |  Loss: (0.4846) |  Loss2: (0.0000) | Acc: (83.00%) (21454/25728)
Epoch: 39 | Batch_idx: 210 |  Loss: (0.4839) |  Loss2: (0.0000) | Acc: (83.00%) (22523/27008)
Epoch: 39 | Batch_idx: 220 |  Loss: (0.4836) |  Loss2: (0.0000) | Acc: (83.00%) (23583/28288)
Epoch: 39 | Batch_idx: 230 |  Loss: (0.4812) |  Loss2: (0.0000) | Acc: (83.00%) (24678/29568)
Epoch: 39 | Batch_idx: 240 |  Loss: (0.4814) |  Loss2: (0.0000) | Acc: (83.00%) (25752/30848)
Epoch: 39 | Batch_idx: 250 |  Loss: (0.4792) |  Loss2: (0.0000) | Acc: (83.00%) (26845/32128)
Epoch: 39 | Batch_idx: 260 |  Loss: (0.4795) |  Loss2: (0.0000) | Acc: (83.00%) (27912/33408)
Epoch: 39 | Batch_idx: 270 |  Loss: (0.4791) |  Loss2: (0.0000) | Acc: (83.00%) (28976/34688)
Epoch: 39 | Batch_idx: 280 |  Loss: (0.4791) |  Loss2: (0.0000) | Acc: (83.00%) (30038/35968)
Epoch: 39 | Batch_idx: 290 |  Loss: (0.4784) |  Loss2: (0.0000) | Acc: (83.00%) (31113/37248)
Epoch: 39 | Batch_idx: 300 |  Loss: (0.4785) |  Loss2: (0.0000) | Acc: (83.00%) (32193/38528)
Epoch: 39 | Batch_idx: 310 |  Loss: (0.4790) |  Loss2: (0.0000) | Acc: (83.00%) (33254/39808)
Epoch: 39 | Batch_idx: 320 |  Loss: (0.4792) |  Loss2: (0.0000) | Acc: (83.00%) (34306/41088)
Epoch: 39 | Batch_idx: 330 |  Loss: (0.4800) |  Loss2: (0.0000) | Acc: (83.00%) (35363/42368)
Epoch: 39 | Batch_idx: 340 |  Loss: (0.4791) |  Loss2: (0.0000) | Acc: (83.00%) (36446/43648)
Epoch: 39 | Batch_idx: 350 |  Loss: (0.4789) |  Loss2: (0.0000) | Acc: (83.00%) (37520/44928)
Epoch: 39 | Batch_idx: 360 |  Loss: (0.4787) |  Loss2: (0.0000) | Acc: (83.00%) (38592/46208)
Epoch: 39 | Batch_idx: 370 |  Loss: (0.4793) |  Loss2: (0.0000) | Acc: (83.00%) (39658/47488)
Epoch: 39 | Batch_idx: 380 |  Loss: (0.4799) |  Loss2: (0.0000) | Acc: (83.00%) (40699/48768)
Epoch: 39 | Batch_idx: 390 |  Loss: (0.4806) |  Loss2: (0.0000) | Acc: (83.00%) (41724/50000)
# TEST : Loss: (0.5316) | Acc: (81.00%) (8138/10000)
percent tensor([0.5628, 0.5636, 0.5748, 0.5667, 0.5748, 0.5648, 0.5690, 0.5648, 0.5626,
        0.5651, 0.5613, 0.5711, 0.5610, 0.5552, 0.5641, 0.5620],
       device='cuda:0') torch.Size([16])
percent tensor([0.5532, 0.5323, 0.5369, 0.5675, 0.5530, 0.5938, 0.5378, 0.5503, 0.5427,
        0.5339, 0.5387, 0.5326, 0.5345, 0.5529, 0.5592, 0.5595],
       device='cuda:0') torch.Size([16])
percent tensor([0.4588, 0.4931, 0.4609, 0.4466, 0.4655, 0.4458, 0.4851, 0.4720, 0.4709,
        0.4643, 0.4625, 0.4669, 0.4712, 0.4851, 0.4697, 0.4648],
       device='cuda:0') torch.Size([16])
percent tensor([0.6196, 0.6049, 0.5870, 0.6073, 0.6007, 0.6409, 0.5992, 0.5902, 0.6095,
        0.6184, 0.6225, 0.5926, 0.6112, 0.6212, 0.6091, 0.6336],
       device='cuda:0') torch.Size([16])
percent tensor([0.5705, 0.6190, 0.5346, 0.5494, 0.4971, 0.6096, 0.5616, 0.4793, 0.6215,
        0.5624, 0.6289, 0.5434, 0.6534, 0.6429, 0.5261, 0.5772],
       device='cuda:0') torch.Size([16])
percent tensor([0.6413, 0.6040, 0.6889, 0.7175, 0.7171, 0.6978, 0.6460, 0.6901, 0.6867,
        0.6358, 0.6592, 0.6344, 0.5893, 0.7090, 0.6312, 0.6532],
       device='cuda:0') torch.Size([16])
percent tensor([0.6142, 0.5197, 0.6748, 0.6770, 0.7249, 0.6132, 0.6316, 0.7616, 0.5739,
        0.6140, 0.4935, 0.6327, 0.4340, 0.5049, 0.6398, 0.6863],
       device='cuda:0') torch.Size([16])
percent tensor([0.9974, 0.9934, 0.9943, 0.9968, 0.9945, 0.9955, 0.9963, 0.9964, 0.9954,
        0.9975, 0.9956, 0.9975, 0.9952, 0.9951, 0.9954, 0.9977],
       device='cuda:0') torch.Size([16])
True Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=128, out_features=16, bias=False)
False Linear(in_features=16, out_features=2, bias=False)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=128, out_features=16, bias=False)
False Linear(in_features=16, out_features=2, bias=False)
True Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=256, out_features=32, bias=False)
False Linear(in_features=32, out_features=2, bias=False)
True Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=256, out_features=32, bias=False)
False Linear(in_features=32, out_features=2, bias=False)
True Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=512, out_features=64, bias=False)
False Linear(in_features=64, out_features=2, bias=False)
True Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=512, out_features=64, bias=False)
False Linear(in_features=64, out_features=2, bias=False)
True Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1024, out_features=128, bias=False)
False Linear(in_features=128, out_features=2, bias=False)
True Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1024, out_features=128, bias=False)
False Linear(in_features=128, out_features=2, bias=False)
True Linear(in_features=512, out_features=10, bias=True)
Epoch: 40 | Batch_idx: 0 |  Loss: (0.4724) |  Loss2: (0.0000) | Acc: (84.00%) (108/128)
Epoch: 40 | Batch_idx: 10 |  Loss: (0.4773) |  Loss2: (0.0000) | Acc: (82.00%) (1167/1408)
Epoch: 40 | Batch_idx: 20 |  Loss: (0.4764) |  Loss2: (0.0000) | Acc: (83.00%) (2238/2688)
Epoch: 40 | Batch_idx: 30 |  Loss: (0.4712) |  Loss2: (0.0000) | Acc: (83.00%) (3324/3968)
Epoch: 40 | Batch_idx: 40 |  Loss: (0.4715) |  Loss2: (0.0000) | Acc: (83.00%) (4405/5248)
Epoch: 40 | Batch_idx: 50 |  Loss: (0.4656) |  Loss2: (0.0000) | Acc: (83.00%) (5476/6528)
Epoch: 40 | Batch_idx: 60 |  Loss: (0.4703) |  Loss2: (0.0000) | Acc: (83.00%) (6539/7808)
Epoch: 40 | Batch_idx: 70 |  Loss: (0.4679) |  Loss2: (0.0000) | Acc: (83.00%) (7620/9088)
Epoch: 40 | Batch_idx: 80 |  Loss: (0.4709) |  Loss2: (0.0000) | Acc: (83.00%) (8693/10368)
Epoch: 40 | Batch_idx: 90 |  Loss: (0.4725) |  Loss2: (0.0000) | Acc: (83.00%) (9762/11648)
Epoch: 40 | Batch_idx: 100 |  Loss: (0.4716) |  Loss2: (0.0000) | Acc: (83.00%) (10838/12928)
Epoch: 40 | Batch_idx: 110 |  Loss: (0.4712) |  Loss2: (0.0000) | Acc: (83.00%) (11910/14208)
Epoch: 40 | Batch_idx: 120 |  Loss: (0.4736) |  Loss2: (0.0000) | Acc: (83.00%) (12962/15488)
Epoch: 40 | Batch_idx: 130 |  Loss: (0.4736) |  Loss2: (0.0000) | Acc: (83.00%) (14032/16768)
Epoch: 40 | Batch_idx: 140 |  Loss: (0.4767) |  Loss2: (0.0000) | Acc: (83.00%) (15070/18048)
Epoch: 40 | Batch_idx: 150 |  Loss: (0.4796) |  Loss2: (0.0000) | Acc: (83.00%) (16108/19328)
Epoch: 40 | Batch_idx: 160 |  Loss: (0.4812) |  Loss2: (0.0000) | Acc: (83.00%) (17177/20608)
Epoch: 40 | Batch_idx: 170 |  Loss: (0.4794) |  Loss2: (0.0000) | Acc: (83.00%) (18260/21888)
Epoch: 40 | Batch_idx: 180 |  Loss: (0.4782) |  Loss2: (0.0000) | Acc: (83.00%) (19330/23168)
Epoch: 40 | Batch_idx: 190 |  Loss: (0.4793) |  Loss2: (0.0000) | Acc: (83.00%) (20388/24448)
Epoch: 40 | Batch_idx: 200 |  Loss: (0.4793) |  Loss2: (0.0000) | Acc: (83.00%) (21455/25728)
Epoch: 40 | Batch_idx: 210 |  Loss: (0.4806) |  Loss2: (0.0000) | Acc: (83.00%) (22503/27008)
Epoch: 40 | Batch_idx: 220 |  Loss: (0.4790) |  Loss2: (0.0000) | Acc: (83.00%) (23576/28288)
Epoch: 40 | Batch_idx: 230 |  Loss: (0.4788) |  Loss2: (0.0000) | Acc: (83.00%) (24652/29568)
Epoch: 40 | Batch_idx: 240 |  Loss: (0.4785) |  Loss2: (0.0000) | Acc: (83.00%) (25735/30848)
Epoch: 40 | Batch_idx: 250 |  Loss: (0.4789) |  Loss2: (0.0000) | Acc: (83.00%) (26795/32128)
Epoch: 40 | Batch_idx: 260 |  Loss: (0.4795) |  Loss2: (0.0000) | Acc: (83.00%) (27849/33408)
Epoch: 40 | Batch_idx: 270 |  Loss: (0.4791) |  Loss2: (0.0000) | Acc: (83.00%) (28936/34688)
Epoch: 40 | Batch_idx: 280 |  Loss: (0.4792) |  Loss2: (0.0000) | Acc: (83.00%) (29984/35968)
Epoch: 40 | Batch_idx: 290 |  Loss: (0.4795) |  Loss2: (0.0000) | Acc: (83.00%) (31047/37248)
Epoch: 40 | Batch_idx: 300 |  Loss: (0.4799) |  Loss2: (0.0000) | Acc: (83.00%) (32119/38528)
Epoch: 40 | Batch_idx: 310 |  Loss: (0.4809) |  Loss2: (0.0000) | Acc: (83.00%) (33166/39808)
Epoch: 40 | Batch_idx: 320 |  Loss: (0.4819) |  Loss2: (0.0000) | Acc: (83.00%) (34223/41088)
Epoch: 40 | Batch_idx: 330 |  Loss: (0.4810) |  Loss2: (0.0000) | Acc: (83.00%) (35294/42368)
Epoch: 40 | Batch_idx: 340 |  Loss: (0.4815) |  Loss2: (0.0000) | Acc: (83.00%) (36364/43648)
Epoch: 40 | Batch_idx: 350 |  Loss: (0.4798) |  Loss2: (0.0000) | Acc: (83.00%) (37453/44928)
Epoch: 40 | Batch_idx: 360 |  Loss: (0.4800) |  Loss2: (0.0000) | Acc: (83.00%) (38520/46208)
Epoch: 40 | Batch_idx: 370 |  Loss: (0.4799) |  Loss2: (0.0000) | Acc: (83.00%) (39586/47488)
Epoch: 40 | Batch_idx: 380 |  Loss: (0.4798) |  Loss2: (0.0000) | Acc: (83.00%) (40662/48768)
Epoch: 40 | Batch_idx: 390 |  Loss: (0.4806) |  Loss2: (0.0000) | Acc: (83.00%) (41675/50000)
=> saving checkpoint 'drive/app/torch/save_Routing_Gate_2/checkpoint_040.pth.tar'
# TEST : Loss: (0.6097) | Acc: (80.00%) (8001/10000)
percent tensor([0.5633, 0.5612, 0.5788, 0.5686, 0.5786, 0.5683, 0.5691, 0.5666, 0.5624,
        0.5648, 0.5608, 0.5747, 0.5610, 0.5515, 0.5647, 0.5624],
       device='cuda:0') torch.Size([16])
percent tensor([0.5529, 0.5394, 0.5341, 0.5665, 0.5485, 0.5878, 0.5418, 0.5493, 0.5431,
        0.5364, 0.5401, 0.5317, 0.5345, 0.5655, 0.5587, 0.5604],
       device='cuda:0') torch.Size([16])
percent tensor([0.4561, 0.4905, 0.4548, 0.4417, 0.4635, 0.4486, 0.4839, 0.4665, 0.4705,
        0.4619, 0.4612, 0.4640, 0.4693, 0.4850, 0.4683, 0.4620],
       device='cuda:0') torch.Size([16])
percent tensor([0.6281, 0.6085, 0.5896, 0.6088, 0.6020, 0.6488, 0.6021, 0.5877, 0.6120,
        0.6261, 0.6271, 0.5987, 0.6191, 0.6230, 0.6125, 0.6389],
       device='cuda:0') torch.Size([16])
percent tensor([0.5872, 0.6130, 0.5897, 0.5604, 0.5382, 0.6316, 0.5603, 0.4988, 0.6451,
        0.5638, 0.6372, 0.5895, 0.6736, 0.6530, 0.5318, 0.5837],
       device='cuda:0') torch.Size([16])
percent tensor([0.6558, 0.6325, 0.7287, 0.7347, 0.7430, 0.6962, 0.6741, 0.7018, 0.7061,
        0.6613, 0.6816, 0.6860, 0.6103, 0.7297, 0.6407, 0.6678],
       device='cuda:0') torch.Size([16])
percent tensor([0.6392, 0.5697, 0.6681, 0.6938, 0.7338, 0.5929, 0.6649, 0.7648, 0.5882,
        0.6533, 0.5213, 0.6375, 0.4517, 0.5710, 0.6384, 0.6993],
       device='cuda:0') torch.Size([16])
percent tensor([0.9981, 0.9941, 0.9956, 0.9974, 0.9951, 0.9960, 0.9971, 0.9977, 0.9950,
        0.9977, 0.9959, 0.9969, 0.9941, 0.9960, 0.9961, 0.9980],
       device='cuda:0') torch.Size([16])
Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 3, 3, 3]) tensor(174.3846, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(794.5485, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(792.5628, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([128, 64, 3, 3]) tensor(1531.1498, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([128, 64, 1, 1]) tensor(504.8376, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([128, 128, 3, 3]) tensor(2188.6648, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([256, 128, 3, 3]) tensor(4300.5557, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([256, 128, 1, 1]) tensor(1427.1003, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([256, 256, 3, 3]) tensor(6100.6821, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([512, 256, 3, 3]) tensor(12097.1299, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([512, 256, 1, 1]) tensor(4028.6663, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([512, 512, 3, 3]) tensor(17047.8652, device='cuda:0', grad_fn=<NormBackward0>)
Epoch: 41 | Batch_idx: 0 |  Loss: (0.5076) |  Loss2: (0.0000) | Acc: (82.00%) (106/128)
Epoch: 41 | Batch_idx: 10 |  Loss: (0.4574) |  Loss2: (0.0000) | Acc: (84.00%) (1192/1408)
Epoch: 41 | Batch_idx: 20 |  Loss: (0.4539) |  Loss2: (0.0000) | Acc: (84.00%) (2259/2688)
Epoch: 41 | Batch_idx: 30 |  Loss: (0.4645) |  Loss2: (0.0000) | Acc: (83.00%) (3321/3968)
Epoch: 41 | Batch_idx: 40 |  Loss: (0.4772) |  Loss2: (0.0000) | Acc: (83.00%) (4381/5248)
Epoch: 41 | Batch_idx: 50 |  Loss: (0.4736) |  Loss2: (0.0000) | Acc: (83.00%) (5449/6528)
Epoch: 41 | Batch_idx: 60 |  Loss: (0.4721) |  Loss2: (0.0000) | Acc: (83.00%) (6517/7808)
Epoch: 41 | Batch_idx: 70 |  Loss: (0.4738) |  Loss2: (0.0000) | Acc: (83.00%) (7581/9088)
Epoch: 41 | Batch_idx: 80 |  Loss: (0.4661) |  Loss2: (0.0000) | Acc: (83.00%) (8682/10368)
Epoch: 41 | Batch_idx: 90 |  Loss: (0.4631) |  Loss2: (0.0000) | Acc: (83.00%) (9766/11648)
Epoch: 41 | Batch_idx: 100 |  Loss: (0.4616) |  Loss2: (0.0000) | Acc: (83.00%) (10851/12928)
Epoch: 41 | Batch_idx: 110 |  Loss: (0.4620) |  Loss2: (0.0000) | Acc: (83.00%) (11913/14208)
Epoch: 41 | Batch_idx: 120 |  Loss: (0.4576) |  Loss2: (0.0000) | Acc: (84.00%) (13011/15488)
Epoch: 41 | Batch_idx: 130 |  Loss: (0.4567) |  Loss2: (0.0000) | Acc: (84.00%) (14104/16768)
Epoch: 41 | Batch_idx: 140 |  Loss: (0.4593) |  Loss2: (0.0000) | Acc: (84.00%) (15176/18048)
Epoch: 41 | Batch_idx: 150 |  Loss: (0.4605) |  Loss2: (0.0000) | Acc: (84.00%) (16239/19328)
Epoch: 41 | Batch_idx: 160 |  Loss: (0.4591) |  Loss2: (0.0000) | Acc: (84.00%) (17322/20608)
Epoch: 41 | Batch_idx: 170 |  Loss: (0.4607) |  Loss2: (0.0000) | Acc: (84.00%) (18392/21888)
Epoch: 41 | Batch_idx: 180 |  Loss: (0.4637) |  Loss2: (0.0000) | Acc: (83.00%) (19450/23168)
Epoch: 41 | Batch_idx: 190 |  Loss: (0.4624) |  Loss2: (0.0000) | Acc: (83.00%) (20532/24448)
Epoch: 41 | Batch_idx: 200 |  Loss: (0.4641) |  Loss2: (0.0000) | Acc: (83.00%) (21588/25728)
Epoch: 41 | Batch_idx: 210 |  Loss: (0.4634) |  Loss2: (0.0000) | Acc: (83.00%) (22666/27008)
Epoch: 41 | Batch_idx: 220 |  Loss: (0.4647) |  Loss2: (0.0000) | Acc: (83.00%) (23730/28288)
Epoch: 41 | Batch_idx: 230 |  Loss: (0.4637) |  Loss2: (0.0000) | Acc: (83.00%) (24817/29568)
Epoch: 41 | Batch_idx: 240 |  Loss: (0.4643) |  Loss2: (0.0000) | Acc: (83.00%) (25879/30848)
Epoch: 41 | Batch_idx: 250 |  Loss: (0.4658) |  Loss2: (0.0000) | Acc: (83.00%) (26943/32128)
Epoch: 41 | Batch_idx: 260 |  Loss: (0.4673) |  Loss2: (0.0000) | Acc: (83.00%) (27999/33408)
Epoch: 41 | Batch_idx: 270 |  Loss: (0.4682) |  Loss2: (0.0000) | Acc: (83.00%) (29066/34688)
Epoch: 41 | Batch_idx: 280 |  Loss: (0.4663) |  Loss2: (0.0000) | Acc: (83.00%) (30156/35968)
Epoch: 41 | Batch_idx: 290 |  Loss: (0.4665) |  Loss2: (0.0000) | Acc: (83.00%) (31222/37248)
Epoch: 41 | Batch_idx: 300 |  Loss: (0.4662) |  Loss2: (0.0000) | Acc: (83.00%) (32298/38528)
Epoch: 41 | Batch_idx: 310 |  Loss: (0.4664) |  Loss2: (0.0000) | Acc: (83.00%) (33386/39808)
Epoch: 41 | Batch_idx: 320 |  Loss: (0.4664) |  Loss2: (0.0000) | Acc: (83.00%) (34485/41088)
Epoch: 41 | Batch_idx: 330 |  Loss: (0.4657) |  Loss2: (0.0000) | Acc: (83.00%) (35573/42368)
Epoch: 41 | Batch_idx: 340 |  Loss: (0.4643) |  Loss2: (0.0000) | Acc: (84.00%) (36669/43648)
Epoch: 41 | Batch_idx: 350 |  Loss: (0.4639) |  Loss2: (0.0000) | Acc: (84.00%) (37759/44928)
Epoch: 41 | Batch_idx: 360 |  Loss: (0.4639) |  Loss2: (0.0000) | Acc: (84.00%) (38836/46208)
Epoch: 41 | Batch_idx: 370 |  Loss: (0.4639) |  Loss2: (0.0000) | Acc: (84.00%) (39903/47488)
Epoch: 41 | Batch_idx: 380 |  Loss: (0.4635) |  Loss2: (0.0000) | Acc: (84.00%) (40986/48768)
Epoch: 41 | Batch_idx: 390 |  Loss: (0.4633) |  Loss2: (0.0000) | Acc: (84.00%) (42013/50000)
# TEST : Loss: (0.5164) | Acc: (82.00%) (8263/10000)
percent tensor([0.5635, 0.5627, 0.5750, 0.5665, 0.5758, 0.5674, 0.5692, 0.5634, 0.5624,
        0.5644, 0.5610, 0.5724, 0.5614, 0.5547, 0.5644, 0.5624],
       device='cuda:0') torch.Size([16])
percent tensor([0.5533, 0.5372, 0.5329, 0.5668, 0.5464, 0.5916, 0.5388, 0.5538, 0.5424,
        0.5349, 0.5401, 0.5295, 0.5349, 0.5636, 0.5594, 0.5616],
       device='cuda:0') torch.Size([16])
percent tensor([0.4575, 0.4951, 0.4567, 0.4437, 0.4605, 0.4488, 0.4865, 0.4690, 0.4732,
        0.4631, 0.4615, 0.4636, 0.4699, 0.4921, 0.4697, 0.4646],
       device='cuda:0') torch.Size([16])
percent tensor([0.6206, 0.6013, 0.5883, 0.6081, 0.6014, 0.6376, 0.5984, 0.5915, 0.6078,
        0.6181, 0.6226, 0.5957, 0.6125, 0.6178, 0.6070, 0.6343],
       device='cuda:0') torch.Size([16])
percent tensor([0.5719, 0.6139, 0.5380, 0.5490, 0.5020, 0.6110, 0.5554, 0.4703, 0.6175,
        0.5526, 0.6280, 0.5504, 0.6573, 0.6413, 0.5314, 0.5735],
       device='cuda:0') torch.Size([16])
percent tensor([0.6483, 0.6148, 0.7059, 0.7130, 0.7257, 0.6977, 0.6535, 0.6944, 0.6803,
        0.6383, 0.6775, 0.6493, 0.5971, 0.7155, 0.6348, 0.6601],
       device='cuda:0') torch.Size([16])
percent tensor([0.6347, 0.5725, 0.6780, 0.6705, 0.7276, 0.6254, 0.6328, 0.7504, 0.5834,
        0.6522, 0.5303, 0.6275, 0.4566, 0.5617, 0.6463, 0.7082],
       device='cuda:0') torch.Size([16])
percent tensor([0.9978, 0.9937, 0.9951, 0.9966, 0.9959, 0.9925, 0.9961, 0.9970, 0.9946,
        0.9976, 0.9958, 0.9962, 0.9954, 0.9962, 0.9967, 0.9982],
       device='cuda:0') torch.Size([16])
Epoch: 42 | Batch_idx: 0 |  Loss: (0.4409) |  Loss2: (0.0000) | Acc: (84.00%) (108/128)
Epoch: 42 | Batch_idx: 10 |  Loss: (0.4195) |  Loss2: (0.0000) | Acc: (85.00%) (1203/1408)
Epoch: 42 | Batch_idx: 20 |  Loss: (0.4466) |  Loss2: (0.0000) | Acc: (84.00%) (2268/2688)
Epoch: 42 | Batch_idx: 30 |  Loss: (0.4442) |  Loss2: (0.0000) | Acc: (84.00%) (3345/3968)
Epoch: 42 | Batch_idx: 40 |  Loss: (0.4551) |  Loss2: (0.0000) | Acc: (83.00%) (4403/5248)
Epoch: 42 | Batch_idx: 50 |  Loss: (0.4483) |  Loss2: (0.0000) | Acc: (84.00%) (5488/6528)
Epoch: 42 | Batch_idx: 60 |  Loss: (0.4429) |  Loss2: (0.0000) | Acc: (84.00%) (6582/7808)
Epoch: 42 | Batch_idx: 70 |  Loss: (0.4476) |  Loss2: (0.0000) | Acc: (84.00%) (7644/9088)
Epoch: 42 | Batch_idx: 80 |  Loss: (0.4462) |  Loss2: (0.0000) | Acc: (84.00%) (8729/10368)
Epoch: 42 | Batch_idx: 90 |  Loss: (0.4445) |  Loss2: (0.0000) | Acc: (84.00%) (9834/11648)
Epoch: 42 | Batch_idx: 100 |  Loss: (0.4456) |  Loss2: (0.0000) | Acc: (84.00%) (10918/12928)
Epoch: 42 | Batch_idx: 110 |  Loss: (0.4466) |  Loss2: (0.0000) | Acc: (84.00%) (11999/14208)
Epoch: 42 | Batch_idx: 120 |  Loss: (0.4473) |  Loss2: (0.0000) | Acc: (84.00%) (13082/15488)
Epoch: 42 | Batch_idx: 130 |  Loss: (0.4466) |  Loss2: (0.0000) | Acc: (84.00%) (14160/16768)
Epoch: 42 | Batch_idx: 140 |  Loss: (0.4466) |  Loss2: (0.0000) | Acc: (84.00%) (15246/18048)
Epoch: 42 | Batch_idx: 150 |  Loss: (0.4482) |  Loss2: (0.0000) | Acc: (84.00%) (16305/19328)
Epoch: 42 | Batch_idx: 160 |  Loss: (0.4465) |  Loss2: (0.0000) | Acc: (84.00%) (17409/20608)
Epoch: 42 | Batch_idx: 170 |  Loss: (0.4445) |  Loss2: (0.0000) | Acc: (84.00%) (18503/21888)
Epoch: 42 | Batch_idx: 180 |  Loss: (0.4435) |  Loss2: (0.0000) | Acc: (84.00%) (19602/23168)
Epoch: 42 | Batch_idx: 190 |  Loss: (0.4432) |  Loss2: (0.0000) | Acc: (84.00%) (20684/24448)
Epoch: 42 | Batch_idx: 200 |  Loss: (0.4428) |  Loss2: (0.0000) | Acc: (84.00%) (21778/25728)
Epoch: 42 | Batch_idx: 210 |  Loss: (0.4416) |  Loss2: (0.0000) | Acc: (84.00%) (22880/27008)
Epoch: 42 | Batch_idx: 220 |  Loss: (0.4404) |  Loss2: (0.0000) | Acc: (84.00%) (23973/28288)
Epoch: 42 | Batch_idx: 230 |  Loss: (0.4395) |  Loss2: (0.0000) | Acc: (84.00%) (25062/29568)
Epoch: 42 | Batch_idx: 240 |  Loss: (0.4390) |  Loss2: (0.0000) | Acc: (84.00%) (26151/30848)
Epoch: 42 | Batch_idx: 250 |  Loss: (0.4386) |  Loss2: (0.0000) | Acc: (84.00%) (27229/32128)
Epoch: 42 | Batch_idx: 260 |  Loss: (0.4395) |  Loss2: (0.0000) | Acc: (84.00%) (28291/33408)
Epoch: 42 | Batch_idx: 270 |  Loss: (0.4388) |  Loss2: (0.0000) | Acc: (84.00%) (29392/34688)
Epoch: 42 | Batch_idx: 280 |  Loss: (0.4396) |  Loss2: (0.0000) | Acc: (84.00%) (30467/35968)
Epoch: 42 | Batch_idx: 290 |  Loss: (0.4390) |  Loss2: (0.0000) | Acc: (84.00%) (31565/37248)
Epoch: 42 | Batch_idx: 300 |  Loss: (0.4397) |  Loss2: (0.0000) | Acc: (84.00%) (32638/38528)
Epoch: 42 | Batch_idx: 310 |  Loss: (0.4394) |  Loss2: (0.0000) | Acc: (84.00%) (33734/39808)
Epoch: 42 | Batch_idx: 320 |  Loss: (0.4393) |  Loss2: (0.0000) | Acc: (84.00%) (34817/41088)
Epoch: 42 | Batch_idx: 330 |  Loss: (0.4401) |  Loss2: (0.0000) | Acc: (84.00%) (35896/42368)
Epoch: 42 | Batch_idx: 340 |  Loss: (0.4408) |  Loss2: (0.0000) | Acc: (84.00%) (36963/43648)
Epoch: 42 | Batch_idx: 350 |  Loss: (0.4416) |  Loss2: (0.0000) | Acc: (84.00%) (38033/44928)
Epoch: 42 | Batch_idx: 360 |  Loss: (0.4427) |  Loss2: (0.0000) | Acc: (84.00%) (39102/46208)
Epoch: 42 | Batch_idx: 370 |  Loss: (0.4438) |  Loss2: (0.0000) | Acc: (84.00%) (40156/47488)
Epoch: 42 | Batch_idx: 380 |  Loss: (0.4440) |  Loss2: (0.0000) | Acc: (84.00%) (41229/48768)
Epoch: 42 | Batch_idx: 390 |  Loss: (0.4440) |  Loss2: (0.0000) | Acc: (84.00%) (42269/50000)
# TEST : Loss: (0.5946) | Acc: (79.00%) (7971/10000)
percent tensor([0.5635, 0.5627, 0.5727, 0.5676, 0.5738, 0.5678, 0.5680, 0.5638, 0.5614,
        0.5641, 0.5611, 0.5700, 0.5614, 0.5540, 0.5650, 0.5629],
       device='cuda:0') torch.Size([16])
percent tensor([0.5544, 0.5311, 0.5325, 0.5671, 0.5470, 0.5909, 0.5340, 0.5501, 0.5408,
        0.5316, 0.5395, 0.5274, 0.5346, 0.5508, 0.5580, 0.5603],
       device='cuda:0') torch.Size([16])
percent tensor([0.4613, 0.5030, 0.4538, 0.4478, 0.4633, 0.4589, 0.4921, 0.4685, 0.4757,
        0.4667, 0.4689, 0.4639, 0.4746, 0.5050, 0.4751, 0.4720],
       device='cuda:0') torch.Size([16])
percent tensor([0.6225, 0.6013, 0.5900, 0.6049, 0.6004, 0.6385, 0.6002, 0.5901, 0.6083,
        0.6196, 0.6221, 0.6001, 0.6140, 0.6136, 0.6089, 0.6325],
       device='cuda:0') torch.Size([16])
percent tensor([0.5658, 0.6331, 0.5580, 0.5569, 0.5367, 0.6285, 0.5714, 0.4841, 0.6114,
        0.5684, 0.6239, 0.5704, 0.6519, 0.6653, 0.5370, 0.5833],
       device='cuda:0') torch.Size([16])
percent tensor([0.6440, 0.5914, 0.6963, 0.7080, 0.7236, 0.6905, 0.6349, 0.6815, 0.6726,
        0.6237, 0.6585, 0.6419, 0.5815, 0.6949, 0.6266, 0.6503],
       device='cuda:0') torch.Size([16])
percent tensor([0.6334, 0.5134, 0.6726, 0.6592, 0.7280, 0.5947, 0.6217, 0.7436, 0.5765,
        0.6050, 0.5066, 0.6020, 0.4368, 0.5284, 0.6293, 0.6792],
       device='cuda:0') torch.Size([16])
percent tensor([0.9980, 0.9943, 0.9961, 0.9977, 0.9968, 0.9941, 0.9965, 0.9977, 0.9941,
        0.9974, 0.9951, 0.9962, 0.9942, 0.9953, 0.9970, 0.9983],
       device='cuda:0') torch.Size([16])
Epoch: 43 | Batch_idx: 0 |  Loss: (0.4037) |  Loss2: (0.0000) | Acc: (83.00%) (107/128)
Epoch: 43 | Batch_idx: 10 |  Loss: (0.4358) |  Loss2: (0.0000) | Acc: (85.00%) (1203/1408)
Epoch: 43 | Batch_idx: 20 |  Loss: (0.4308) |  Loss2: (0.0000) | Acc: (85.00%) (2302/2688)
Epoch: 43 | Batch_idx: 30 |  Loss: (0.4272) |  Loss2: (0.0000) | Acc: (85.00%) (3405/3968)
Epoch: 43 | Batch_idx: 40 |  Loss: (0.4257) |  Loss2: (0.0000) | Acc: (85.00%) (4495/5248)
Epoch: 43 | Batch_idx: 50 |  Loss: (0.4338) |  Loss2: (0.0000) | Acc: (85.00%) (5564/6528)
Epoch: 43 | Batch_idx: 60 |  Loss: (0.4299) |  Loss2: (0.0000) | Acc: (85.00%) (6669/7808)
Epoch: 43 | Batch_idx: 70 |  Loss: (0.4346) |  Loss2: (0.0000) | Acc: (85.00%) (7744/9088)
Epoch: 43 | Batch_idx: 80 |  Loss: (0.4309) |  Loss2: (0.0000) | Acc: (85.00%) (8840/10368)
Epoch: 43 | Batch_idx: 90 |  Loss: (0.4312) |  Loss2: (0.0000) | Acc: (85.00%) (9932/11648)
Epoch: 43 | Batch_idx: 100 |  Loss: (0.4301) |  Loss2: (0.0000) | Acc: (85.00%) (11036/12928)
Epoch: 43 | Batch_idx: 110 |  Loss: (0.4291) |  Loss2: (0.0000) | Acc: (85.00%) (12142/14208)
Epoch: 43 | Batch_idx: 120 |  Loss: (0.4286) |  Loss2: (0.0000) | Acc: (85.00%) (13233/15488)
Epoch: 43 | Batch_idx: 130 |  Loss: (0.4291) |  Loss2: (0.0000) | Acc: (85.00%) (14314/16768)
Epoch: 43 | Batch_idx: 140 |  Loss: (0.4278) |  Loss2: (0.0000) | Acc: (85.00%) (15410/18048)
Epoch: 43 | Batch_idx: 150 |  Loss: (0.4270) |  Loss2: (0.0000) | Acc: (85.00%) (16493/19328)
Epoch: 43 | Batch_idx: 160 |  Loss: (0.4266) |  Loss2: (0.0000) | Acc: (85.00%) (17580/20608)
Epoch: 43 | Batch_idx: 170 |  Loss: (0.4275) |  Loss2: (0.0000) | Acc: (85.00%) (18681/21888)
Epoch: 43 | Batch_idx: 180 |  Loss: (0.4266) |  Loss2: (0.0000) | Acc: (85.00%) (19784/23168)
Epoch: 43 | Batch_idx: 190 |  Loss: (0.4261) |  Loss2: (0.0000) | Acc: (85.00%) (20873/24448)
Epoch: 43 | Batch_idx: 200 |  Loss: (0.4275) |  Loss2: (0.0000) | Acc: (85.00%) (21941/25728)
Epoch: 43 | Batch_idx: 210 |  Loss: (0.4284) |  Loss2: (0.0000) | Acc: (85.00%) (23018/27008)
Epoch: 43 | Batch_idx: 220 |  Loss: (0.4283) |  Loss2: (0.0000) | Acc: (85.00%) (24110/28288)
Epoch: 43 | Batch_idx: 230 |  Loss: (0.4274) |  Loss2: (0.0000) | Acc: (85.00%) (25210/29568)
Epoch: 43 | Batch_idx: 240 |  Loss: (0.4278) |  Loss2: (0.0000) | Acc: (85.00%) (26295/30848)
Epoch: 43 | Batch_idx: 250 |  Loss: (0.4277) |  Loss2: (0.0000) | Acc: (85.00%) (27382/32128)
Epoch: 43 | Batch_idx: 260 |  Loss: (0.4289) |  Loss2: (0.0000) | Acc: (85.00%) (28452/33408)
Epoch: 43 | Batch_idx: 270 |  Loss: (0.4283) |  Loss2: (0.0000) | Acc: (85.00%) (29555/34688)
Epoch: 43 | Batch_idx: 280 |  Loss: (0.4298) |  Loss2: (0.0000) | Acc: (85.00%) (30625/35968)
Epoch: 43 | Batch_idx: 290 |  Loss: (0.4296) |  Loss2: (0.0000) | Acc: (85.00%) (31706/37248)
Epoch: 43 | Batch_idx: 300 |  Loss: (0.4285) |  Loss2: (0.0000) | Acc: (85.00%) (32810/38528)
Epoch: 43 | Batch_idx: 310 |  Loss: (0.4291) |  Loss2: (0.0000) | Acc: (85.00%) (33885/39808)
Epoch: 43 | Batch_idx: 320 |  Loss: (0.4298) |  Loss2: (0.0000) | Acc: (85.00%) (34972/41088)
Epoch: 43 | Batch_idx: 330 |  Loss: (0.4293) |  Loss2: (0.0000) | Acc: (85.00%) (36087/42368)
Epoch: 43 | Batch_idx: 340 |  Loss: (0.4299) |  Loss2: (0.0000) | Acc: (85.00%) (37176/43648)
Epoch: 43 | Batch_idx: 350 |  Loss: (0.4306) |  Loss2: (0.0000) | Acc: (85.00%) (38241/44928)
Epoch: 43 | Batch_idx: 360 |  Loss: (0.4319) |  Loss2: (0.0000) | Acc: (85.00%) (39317/46208)
Epoch: 43 | Batch_idx: 370 |  Loss: (0.4327) |  Loss2: (0.0000) | Acc: (85.00%) (40402/47488)
Epoch: 43 | Batch_idx: 380 |  Loss: (0.4320) |  Loss2: (0.0000) | Acc: (85.00%) (41494/48768)
Epoch: 43 | Batch_idx: 390 |  Loss: (0.4316) |  Loss2: (0.0000) | Acc: (85.00%) (42559/50000)
# TEST : Loss: (0.5194) | Acc: (82.00%) (8251/10000)
percent tensor([0.5641, 0.5633, 0.5739, 0.5664, 0.5759, 0.5692, 0.5694, 0.5633, 0.5621,
        0.5650, 0.5612, 0.5720, 0.5618, 0.5552, 0.5659, 0.5629],
       device='cuda:0') torch.Size([16])
percent tensor([0.5545, 0.5344, 0.5342, 0.5665, 0.5485, 0.5908, 0.5378, 0.5541, 0.5445,
        0.5337, 0.5427, 0.5290, 0.5352, 0.5581, 0.5590, 0.5615],
       device='cuda:0') torch.Size([16])
percent tensor([0.4624, 0.4973, 0.4598, 0.4476, 0.4653, 0.4545, 0.4887, 0.4693, 0.4738,
        0.4665, 0.4647, 0.4696, 0.4753, 0.4902, 0.4734, 0.4665],
       device='cuda:0') torch.Size([16])
percent tensor([0.6225, 0.6028, 0.5893, 0.6049, 0.6031, 0.6386, 0.6015, 0.5931, 0.6120,
        0.6215, 0.6271, 0.5968, 0.6152, 0.6153, 0.6096, 0.6334],
       device='cuda:0') torch.Size([16])
percent tensor([0.5770, 0.6069, 0.5409, 0.5542, 0.5263, 0.6403, 0.5608, 0.4707, 0.6201,
        0.5588, 0.6319, 0.5596, 0.6552, 0.6454, 0.5371, 0.5889],
       device='cuda:0') torch.Size([16])
percent tensor([0.6489, 0.6203, 0.6993, 0.7129, 0.7139, 0.6947, 0.6501, 0.6843, 0.6770,
        0.6381, 0.6778, 0.6457, 0.5923, 0.7182, 0.6383, 0.6568],
       device='cuda:0') torch.Size([16])
percent tensor([0.6336, 0.5673, 0.6731, 0.6655, 0.7187, 0.5830, 0.6309, 0.7552, 0.5833,
        0.6624, 0.5426, 0.6288, 0.4776, 0.5685, 0.6215, 0.6844],
       device='cuda:0') torch.Size([16])
percent tensor([0.9969, 0.9947, 0.9962, 0.9975, 0.9963, 0.9934, 0.9950, 0.9970, 0.9935,
        0.9975, 0.9951, 0.9968, 0.9942, 0.9957, 0.9966, 0.9981],
       device='cuda:0') torch.Size([16])
Epoch: 44 | Batch_idx: 0 |  Loss: (0.2935) |  Loss2: (0.0000) | Acc: (88.00%) (113/128)
Epoch: 44 | Batch_idx: 10 |  Loss: (0.3991) |  Loss2: (0.0000) | Acc: (86.00%) (1219/1408)
Epoch: 44 | Batch_idx: 20 |  Loss: (0.4065) |  Loss2: (0.0000) | Acc: (86.00%) (2319/2688)
Epoch: 44 | Batch_idx: 30 |  Loss: (0.4068) |  Loss2: (0.0000) | Acc: (86.00%) (3422/3968)
Epoch: 44 | Batch_idx: 40 |  Loss: (0.4132) |  Loss2: (0.0000) | Acc: (85.00%) (4507/5248)
Epoch: 44 | Batch_idx: 50 |  Loss: (0.4105) |  Loss2: (0.0000) | Acc: (86.00%) (5615/6528)
Epoch: 44 | Batch_idx: 60 |  Loss: (0.4046) |  Loss2: (0.0000) | Acc: (86.00%) (6718/7808)
Epoch: 44 | Batch_idx: 70 |  Loss: (0.4090) |  Loss2: (0.0000) | Acc: (85.00%) (7803/9088)
Epoch: 44 | Batch_idx: 80 |  Loss: (0.4085) |  Loss2: (0.0000) | Acc: (85.00%) (8911/10368)
Epoch: 44 | Batch_idx: 90 |  Loss: (0.4093) |  Loss2: (0.0000) | Acc: (85.00%) (10008/11648)
Epoch: 44 | Batch_idx: 100 |  Loss: (0.4129) |  Loss2: (0.0000) | Acc: (85.00%) (11091/12928)
Epoch: 44 | Batch_idx: 110 |  Loss: (0.4140) |  Loss2: (0.0000) | Acc: (85.00%) (12174/14208)
Epoch: 44 | Batch_idx: 120 |  Loss: (0.4156) |  Loss2: (0.0000) | Acc: (85.00%) (13266/15488)
Epoch: 44 | Batch_idx: 130 |  Loss: (0.4145) |  Loss2: (0.0000) | Acc: (85.00%) (14375/16768)
Epoch: 44 | Batch_idx: 140 |  Loss: (0.4158) |  Loss2: (0.0000) | Acc: (85.00%) (15446/18048)
Epoch: 44 | Batch_idx: 150 |  Loss: (0.4167) |  Loss2: (0.0000) | Acc: (85.00%) (16537/19328)
Epoch: 44 | Batch_idx: 160 |  Loss: (0.4156) |  Loss2: (0.0000) | Acc: (85.00%) (17645/20608)
Epoch: 44 | Batch_idx: 170 |  Loss: (0.4161) |  Loss2: (0.0000) | Acc: (85.00%) (18747/21888)
Epoch: 44 | Batch_idx: 180 |  Loss: (0.4170) |  Loss2: (0.0000) | Acc: (85.00%) (19846/23168)
Epoch: 44 | Batch_idx: 190 |  Loss: (0.4184) |  Loss2: (0.0000) | Acc: (85.00%) (20931/24448)
Epoch: 44 | Batch_idx: 200 |  Loss: (0.4198) |  Loss2: (0.0000) | Acc: (85.00%) (22019/25728)
Epoch: 44 | Batch_idx: 210 |  Loss: (0.4212) |  Loss2: (0.0000) | Acc: (85.00%) (23115/27008)
Epoch: 44 | Batch_idx: 220 |  Loss: (0.4219) |  Loss2: (0.0000) | Acc: (85.00%) (24205/28288)
Epoch: 44 | Batch_idx: 230 |  Loss: (0.4203) |  Loss2: (0.0000) | Acc: (85.00%) (25321/29568)
Epoch: 44 | Batch_idx: 240 |  Loss: (0.4192) |  Loss2: (0.0000) | Acc: (85.00%) (26422/30848)
Epoch: 44 | Batch_idx: 250 |  Loss: (0.4179) |  Loss2: (0.0000) | Acc: (85.00%) (27531/32128)
Epoch: 44 | Batch_idx: 260 |  Loss: (0.4166) |  Loss2: (0.0000) | Acc: (85.00%) (28646/33408)
Epoch: 44 | Batch_idx: 270 |  Loss: (0.4164) |  Loss2: (0.0000) | Acc: (85.00%) (29741/34688)
Epoch: 44 | Batch_idx: 280 |  Loss: (0.4167) |  Loss2: (0.0000) | Acc: (85.00%) (30819/35968)
Epoch: 44 | Batch_idx: 290 |  Loss: (0.4171) |  Loss2: (0.0000) | Acc: (85.00%) (31908/37248)
Epoch: 44 | Batch_idx: 300 |  Loss: (0.4169) |  Loss2: (0.0000) | Acc: (85.00%) (33003/38528)
Epoch: 44 | Batch_idx: 310 |  Loss: (0.4178) |  Loss2: (0.0000) | Acc: (85.00%) (34084/39808)
Epoch: 44 | Batch_idx: 320 |  Loss: (0.4162) |  Loss2: (0.0000) | Acc: (85.00%) (35190/41088)
Epoch: 44 | Batch_idx: 330 |  Loss: (0.4159) |  Loss2: (0.0000) | Acc: (85.00%) (36291/42368)
Epoch: 44 | Batch_idx: 340 |  Loss: (0.4158) |  Loss2: (0.0000) | Acc: (85.00%) (37383/43648)
Epoch: 44 | Batch_idx: 350 |  Loss: (0.4156) |  Loss2: (0.0000) | Acc: (85.00%) (38481/44928)
Epoch: 44 | Batch_idx: 360 |  Loss: (0.4162) |  Loss2: (0.0000) | Acc: (85.00%) (39566/46208)
Epoch: 44 | Batch_idx: 370 |  Loss: (0.4152) |  Loss2: (0.0000) | Acc: (85.00%) (40665/47488)
Epoch: 44 | Batch_idx: 380 |  Loss: (0.4148) |  Loss2: (0.0000) | Acc: (85.00%) (41775/48768)
Epoch: 44 | Batch_idx: 390 |  Loss: (0.4150) |  Loss2: (0.0000) | Acc: (85.00%) (42828/50000)
# TEST : Loss: (0.5111) | Acc: (82.00%) (8239/10000)
percent tensor([0.5642, 0.5628, 0.5739, 0.5677, 0.5752, 0.5696, 0.5681, 0.5641, 0.5618,
        0.5646, 0.5612, 0.5713, 0.5616, 0.5530, 0.5663, 0.5633],
       device='cuda:0') torch.Size([16])
percent tensor([0.5539, 0.5324, 0.5317, 0.5648, 0.5481, 0.5902, 0.5366, 0.5510, 0.5425,
        0.5326, 0.5418, 0.5281, 0.5347, 0.5553, 0.5588, 0.5605],
       device='cuda:0') torch.Size([16])
percent tensor([0.4611, 0.4988, 0.4541, 0.4444, 0.4593, 0.4492, 0.4864, 0.4690, 0.4709,
        0.4659, 0.4638, 0.4618, 0.4741, 0.4945, 0.4715, 0.4663],
       device='cuda:0') torch.Size([16])
percent tensor([0.6193, 0.5983, 0.5881, 0.6063, 0.6002, 0.6369, 0.5976, 0.5890, 0.6067,
        0.6170, 0.6222, 0.5992, 0.6112, 0.6133, 0.6077, 0.6326],
       device='cuda:0') torch.Size([16])
percent tensor([0.5529, 0.6029, 0.5401, 0.5611, 0.5117, 0.6196, 0.5467, 0.4758, 0.6083,
        0.5595, 0.6140, 0.5679, 0.6411, 0.6457, 0.5217, 0.5722],
       device='cuda:0') torch.Size([16])
percent tensor([0.6496, 0.6212, 0.6894, 0.7070, 0.7131, 0.6899, 0.6578, 0.6874, 0.6896,
        0.6389, 0.6873, 0.6571, 0.6058, 0.7265, 0.6419, 0.6633],
       device='cuda:0') torch.Size([16])
percent tensor([0.6266, 0.5596, 0.6570, 0.6683, 0.7111, 0.5977, 0.6478, 0.7419, 0.5997,
        0.6168, 0.5446, 0.6217, 0.4655, 0.5775, 0.6356, 0.6969],
       device='cuda:0') torch.Size([16])
percent tensor([0.9967, 0.9937, 0.9966, 0.9974, 0.9969, 0.9942, 0.9962, 0.9978, 0.9947,
        0.9973, 0.9954, 0.9970, 0.9938, 0.9961, 0.9965, 0.9979],
       device='cuda:0') torch.Size([16])
False Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=128, out_features=16, bias=False)
True Linear(in_features=16, out_features=2, bias=False)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=128, out_features=16, bias=False)
True Linear(in_features=16, out_features=2, bias=False)
False Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=256, out_features=32, bias=False)
True Linear(in_features=32, out_features=2, bias=False)
False Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=256, out_features=32, bias=False)
True Linear(in_features=32, out_features=2, bias=False)
False Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=512, out_features=64, bias=False)
True Linear(in_features=64, out_features=2, bias=False)
False Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=512, out_features=64, bias=False)
True Linear(in_features=64, out_features=2, bias=False)
False Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1024, out_features=128, bias=False)
True Linear(in_features=128, out_features=2, bias=False)
False Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1024, out_features=128, bias=False)
True Linear(in_features=128, out_features=2, bias=False)
False Linear(in_features=512, out_features=10, bias=True)
Epoch: 45 | Batch_idx: 0 |  Loss: (0.3488) |  Loss2: (0.0000) | Acc: (86.00%) (111/128)
Epoch: 45 | Batch_idx: 10 |  Loss: (0.4201) |  Loss2: (0.0000) | Acc: (86.00%) (1217/1408)
Epoch: 45 | Batch_idx: 20 |  Loss: (0.4466) |  Loss2: (0.0000) | Acc: (85.00%) (2296/2688)
Epoch: 45 | Batch_idx: 30 |  Loss: (0.4785) |  Loss2: (0.0000) | Acc: (84.00%) (3350/3968)
Epoch: 45 | Batch_idx: 40 |  Loss: (0.4941) |  Loss2: (0.0000) | Acc: (83.00%) (4375/5248)
Epoch: 45 | Batch_idx: 50 |  Loss: (0.4943) |  Loss2: (0.0000) | Acc: (83.00%) (5436/6528)
Epoch: 45 | Batch_idx: 60 |  Loss: (0.4954) |  Loss2: (0.0000) | Acc: (83.00%) (6488/7808)
Epoch: 45 | Batch_idx: 70 |  Loss: (0.5027) |  Loss2: (0.0000) | Acc: (82.00%) (7529/9088)
Epoch: 45 | Batch_idx: 80 |  Loss: (0.5039) |  Loss2: (0.0000) | Acc: (82.00%) (8573/10368)
Epoch: 45 | Batch_idx: 90 |  Loss: (0.5056) |  Loss2: (0.0000) | Acc: (82.00%) (9621/11648)
Epoch: 45 | Batch_idx: 100 |  Loss: (0.5046) |  Loss2: (0.0000) | Acc: (82.00%) (10673/12928)
Epoch: 45 | Batch_idx: 110 |  Loss: (0.5065) |  Loss2: (0.0000) | Acc: (82.00%) (11713/14208)
Epoch: 45 | Batch_idx: 120 |  Loss: (0.5064) |  Loss2: (0.0000) | Acc: (82.00%) (12761/15488)
Epoch: 45 | Batch_idx: 130 |  Loss: (0.5064) |  Loss2: (0.0000) | Acc: (82.00%) (13815/16768)
Epoch: 45 | Batch_idx: 140 |  Loss: (0.5085) |  Loss2: (0.0000) | Acc: (82.00%) (14873/18048)
Epoch: 45 | Batch_idx: 150 |  Loss: (0.5071) |  Loss2: (0.0000) | Acc: (82.00%) (15944/19328)
Epoch: 45 | Batch_idx: 160 |  Loss: (0.5050) |  Loss2: (0.0000) | Acc: (82.00%) (17017/20608)
Epoch: 45 | Batch_idx: 170 |  Loss: (0.5043) |  Loss2: (0.0000) | Acc: (82.00%) (18075/21888)
Epoch: 45 | Batch_idx: 180 |  Loss: (0.5036) |  Loss2: (0.0000) | Acc: (82.00%) (19136/23168)
Epoch: 45 | Batch_idx: 190 |  Loss: (0.5034) |  Loss2: (0.0000) | Acc: (82.00%) (20207/24448)
Epoch: 45 | Batch_idx: 200 |  Loss: (0.5014) |  Loss2: (0.0000) | Acc: (82.00%) (21279/25728)
Epoch: 45 | Batch_idx: 210 |  Loss: (0.4982) |  Loss2: (0.0000) | Acc: (82.00%) (22367/27008)
Epoch: 45 | Batch_idx: 220 |  Loss: (0.4976) |  Loss2: (0.0000) | Acc: (82.00%) (23427/28288)
Epoch: 45 | Batch_idx: 230 |  Loss: (0.4962) |  Loss2: (0.0000) | Acc: (82.00%) (24492/29568)
Epoch: 45 | Batch_idx: 240 |  Loss: (0.4970) |  Loss2: (0.0000) | Acc: (82.00%) (25539/30848)
Epoch: 45 | Batch_idx: 250 |  Loss: (0.4969) |  Loss2: (0.0000) | Acc: (82.00%) (26603/32128)
Epoch: 45 | Batch_idx: 260 |  Loss: (0.4950) |  Loss2: (0.0000) | Acc: (82.00%) (27676/33408)
Epoch: 45 | Batch_idx: 270 |  Loss: (0.4941) |  Loss2: (0.0000) | Acc: (82.00%) (28752/34688)
Epoch: 45 | Batch_idx: 280 |  Loss: (0.4920) |  Loss2: (0.0000) | Acc: (82.00%) (29841/35968)
Epoch: 45 | Batch_idx: 290 |  Loss: (0.4903) |  Loss2: (0.0000) | Acc: (83.00%) (30919/37248)
Epoch: 45 | Batch_idx: 300 |  Loss: (0.4891) |  Loss2: (0.0000) | Acc: (83.00%) (32000/38528)
Epoch: 45 | Batch_idx: 310 |  Loss: (0.4871) |  Loss2: (0.0000) | Acc: (83.00%) (33090/39808)
Epoch: 45 | Batch_idx: 320 |  Loss: (0.4871) |  Loss2: (0.0000) | Acc: (83.00%) (34147/41088)
Epoch: 45 | Batch_idx: 330 |  Loss: (0.4859) |  Loss2: (0.0000) | Acc: (83.00%) (35233/42368)
Epoch: 45 | Batch_idx: 340 |  Loss: (0.4839) |  Loss2: (0.0000) | Acc: (83.00%) (36320/43648)
Epoch: 45 | Batch_idx: 350 |  Loss: (0.4815) |  Loss2: (0.0000) | Acc: (83.00%) (37434/44928)
Epoch: 45 | Batch_idx: 360 |  Loss: (0.4798) |  Loss2: (0.0000) | Acc: (83.00%) (38525/46208)
Epoch: 45 | Batch_idx: 370 |  Loss: (0.4792) |  Loss2: (0.0000) | Acc: (83.00%) (39589/47488)
Epoch: 45 | Batch_idx: 380 |  Loss: (0.4787) |  Loss2: (0.0000) | Acc: (83.00%) (40658/48768)
Epoch: 45 | Batch_idx: 390 |  Loss: (0.4772) |  Loss2: (0.0000) | Acc: (83.00%) (41707/50000)
=> saving checkpoint 'drive/app/torch/save_Routing_Gate_2/checkpoint_045.pth.tar'
# TEST : Loss: (0.5170) | Acc: (82.00%) (8239/10000)
percent tensor([0.5616, 0.5595, 0.5714, 0.5644, 0.5728, 0.5668, 0.5650, 0.5605, 0.5600,
        0.5611, 0.5583, 0.5673, 0.5589, 0.5507, 0.5628, 0.5597],
       device='cuda:0') torch.Size([16])
percent tensor([0.5420, 0.5174, 0.5119, 0.5562, 0.5297, 0.5879, 0.5185, 0.5383, 0.5293,
        0.5149, 0.5277, 0.5068, 0.5195, 0.5482, 0.5495, 0.5518],
       device='cuda:0') torch.Size([16])
percent tensor([0.4297, 0.4761, 0.4248, 0.4086, 0.4259, 0.4059, 0.4614, 0.4364, 0.4431,
        0.4400, 0.4381, 0.4350, 0.4483, 0.4682, 0.4389, 0.4307],
       device='cuda:0') torch.Size([16])
percent tensor([0.6215, 0.5982, 0.5885, 0.6105, 0.5997, 0.6444, 0.5960, 0.5894, 0.6102,
        0.6173, 0.6227, 0.6001, 0.6145, 0.6160, 0.6095, 0.6367],
       device='cuda:0') torch.Size([16])
percent tensor([0.5871, 0.6358, 0.6007, 0.5884, 0.5597, 0.6319, 0.5922, 0.5239, 0.6329,
        0.6052, 0.6466, 0.6380, 0.6819, 0.6641, 0.5598, 0.5973],
       device='cuda:0') torch.Size([16])
percent tensor([0.6122, 0.5846, 0.6587, 0.6799, 0.6818, 0.6756, 0.6247, 0.6473, 0.6586,
        0.5940, 0.6496, 0.6176, 0.5698, 0.6992, 0.6004, 0.6288],
       device='cuda:0') torch.Size([16])
percent tensor([0.5915, 0.5217, 0.6218, 0.6379, 0.6884, 0.5936, 0.6039, 0.7007, 0.5767,
        0.5812, 0.5237, 0.5581, 0.4280, 0.5616, 0.5889, 0.6620],
       device='cuda:0') torch.Size([16])
percent tensor([0.9971, 0.9938, 0.9957, 0.9976, 0.9969, 0.9951, 0.9963, 0.9981, 0.9948,
        0.9977, 0.9954, 0.9970, 0.9932, 0.9967, 0.9966, 0.9979],
       device='cuda:0') torch.Size([16])
Epoch: 46 | Batch_idx: 0 |  Loss: (0.5198) |  Loss2: (0.0000) | Acc: (83.00%) (107/128)
Epoch: 46 | Batch_idx: 10 |  Loss: (0.4665) |  Loss2: (0.0000) | Acc: (82.00%) (1164/1408)
Epoch: 46 | Batch_idx: 20 |  Loss: (0.4442) |  Loss2: (0.0000) | Acc: (84.00%) (2265/2688)
Epoch: 46 | Batch_idx: 30 |  Loss: (0.4409) |  Loss2: (0.0000) | Acc: (84.00%) (3348/3968)
Epoch: 46 | Batch_idx: 40 |  Loss: (0.4449) |  Loss2: (0.0000) | Acc: (84.00%) (4431/5248)
Epoch: 46 | Batch_idx: 50 |  Loss: (0.4449) |  Loss2: (0.0000) | Acc: (84.00%) (5520/6528)
Epoch: 46 | Batch_idx: 60 |  Loss: (0.4539) |  Loss2: (0.0000) | Acc: (84.00%) (6589/7808)
Epoch: 46 | Batch_idx: 70 |  Loss: (0.4507) |  Loss2: (0.0000) | Acc: (84.00%) (7689/9088)
Epoch: 46 | Batch_idx: 80 |  Loss: (0.4532) |  Loss2: (0.0000) | Acc: (84.00%) (8776/10368)
Epoch: 46 | Batch_idx: 90 |  Loss: (0.4535) |  Loss2: (0.0000) | Acc: (84.00%) (9859/11648)
Epoch: 46 | Batch_idx: 100 |  Loss: (0.4539) |  Loss2: (0.0000) | Acc: (84.00%) (10937/12928)
Epoch: 46 | Batch_idx: 110 |  Loss: (0.4494) |  Loss2: (0.0000) | Acc: (84.00%) (12033/14208)
Epoch: 46 | Batch_idx: 120 |  Loss: (0.4501) |  Loss2: (0.0000) | Acc: (84.00%) (13099/15488)
Epoch: 46 | Batch_idx: 130 |  Loss: (0.4501) |  Loss2: (0.0000) | Acc: (84.00%) (14186/16768)
Epoch: 46 | Batch_idx: 140 |  Loss: (0.4510) |  Loss2: (0.0000) | Acc: (84.00%) (15247/18048)
Epoch: 46 | Batch_idx: 150 |  Loss: (0.4509) |  Loss2: (0.0000) | Acc: (84.00%) (16344/19328)
Epoch: 46 | Batch_idx: 160 |  Loss: (0.4481) |  Loss2: (0.0000) | Acc: (84.00%) (17438/20608)
Epoch: 46 | Batch_idx: 170 |  Loss: (0.4472) |  Loss2: (0.0000) | Acc: (84.00%) (18524/21888)
Epoch: 46 | Batch_idx: 180 |  Loss: (0.4482) |  Loss2: (0.0000) | Acc: (84.00%) (19594/23168)
Epoch: 46 | Batch_idx: 190 |  Loss: (0.4474) |  Loss2: (0.0000) | Acc: (84.00%) (20682/24448)
Epoch: 46 | Batch_idx: 200 |  Loss: (0.4454) |  Loss2: (0.0000) | Acc: (84.00%) (21785/25728)
Epoch: 46 | Batch_idx: 210 |  Loss: (0.4445) |  Loss2: (0.0000) | Acc: (84.00%) (22881/27008)
Epoch: 46 | Batch_idx: 220 |  Loss: (0.4424) |  Loss2: (0.0000) | Acc: (84.00%) (23990/28288)
Epoch: 46 | Batch_idx: 230 |  Loss: (0.4411) |  Loss2: (0.0000) | Acc: (84.00%) (25075/29568)
Epoch: 46 | Batch_idx: 240 |  Loss: (0.4416) |  Loss2: (0.0000) | Acc: (84.00%) (26152/30848)
Epoch: 46 | Batch_idx: 250 |  Loss: (0.4414) |  Loss2: (0.0000) | Acc: (84.00%) (27240/32128)
Epoch: 46 | Batch_idx: 260 |  Loss: (0.4409) |  Loss2: (0.0000) | Acc: (84.00%) (28341/33408)
Epoch: 46 | Batch_idx: 270 |  Loss: (0.4404) |  Loss2: (0.0000) | Acc: (84.00%) (29441/34688)
Epoch: 46 | Batch_idx: 280 |  Loss: (0.4398) |  Loss2: (0.0000) | Acc: (84.00%) (30535/35968)
Epoch: 46 | Batch_idx: 290 |  Loss: (0.4403) |  Loss2: (0.0000) | Acc: (84.00%) (31613/37248)
Epoch: 46 | Batch_idx: 300 |  Loss: (0.4387) |  Loss2: (0.0000) | Acc: (84.00%) (32727/38528)
Epoch: 46 | Batch_idx: 310 |  Loss: (0.4388) |  Loss2: (0.0000) | Acc: (84.00%) (33813/39808)
Epoch: 46 | Batch_idx: 320 |  Loss: (0.4386) |  Loss2: (0.0000) | Acc: (84.00%) (34911/41088)
Epoch: 46 | Batch_idx: 330 |  Loss: (0.4380) |  Loss2: (0.0000) | Acc: (84.00%) (36012/42368)
Epoch: 46 | Batch_idx: 340 |  Loss: (0.4367) |  Loss2: (0.0000) | Acc: (85.00%) (37123/43648)
Epoch: 46 | Batch_idx: 350 |  Loss: (0.4369) |  Loss2: (0.0000) | Acc: (85.00%) (38198/44928)
Epoch: 46 | Batch_idx: 360 |  Loss: (0.4362) |  Loss2: (0.0000) | Acc: (85.00%) (39303/46208)
Epoch: 46 | Batch_idx: 370 |  Loss: (0.4359) |  Loss2: (0.0000) | Acc: (85.00%) (40394/47488)
Epoch: 46 | Batch_idx: 380 |  Loss: (0.4352) |  Loss2: (0.0000) | Acc: (85.00%) (41514/48768)
Epoch: 46 | Batch_idx: 390 |  Loss: (0.4344) |  Loss2: (0.0000) | Acc: (85.00%) (42569/50000)
# TEST : Loss: (0.4975) | Acc: (83.00%) (8307/10000)
percent tensor([0.5618, 0.5611, 0.5711, 0.5642, 0.5732, 0.5669, 0.5661, 0.5612, 0.5612,
        0.5619, 0.5592, 0.5673, 0.5594, 0.5535, 0.5635, 0.5602],
       device='cuda:0') torch.Size([16])
percent tensor([0.5434, 0.5168, 0.5088, 0.5586, 0.5289, 0.5954, 0.5166, 0.5383, 0.5297,
        0.5122, 0.5267, 0.5022, 0.5177, 0.5526, 0.5519, 0.5543],
       device='cuda:0') torch.Size([16])
percent tensor([0.4334, 0.4826, 0.4299, 0.4098, 0.4308, 0.4031, 0.4689, 0.4407, 0.4478,
        0.4477, 0.4448, 0.4436, 0.4546, 0.4712, 0.4431, 0.4339],
       device='cuda:0') torch.Size([16])
percent tensor([0.6338, 0.6080, 0.5969, 0.6225, 0.6095, 0.6592, 0.6058, 0.5996, 0.6213,
        0.6270, 0.6331, 0.6091, 0.6254, 0.6276, 0.6210, 0.6494],
       device='cuda:0') torch.Size([16])
percent tensor([0.5917, 0.6422, 0.6071, 0.5948, 0.5606, 0.6324, 0.5977, 0.5273, 0.6416,
        0.6155, 0.6571, 0.6490, 0.6922, 0.6727, 0.5623, 0.6036],
       device='cuda:0') torch.Size([16])
percent tensor([0.6182, 0.5889, 0.6648, 0.6833, 0.6861, 0.6859, 0.6284, 0.6449, 0.6680,
        0.5975, 0.6572, 0.6218, 0.5805, 0.7111, 0.6014, 0.6346],
       device='cuda:0') torch.Size([16])
percent tensor([0.6105, 0.5308, 0.6442, 0.6497, 0.7057, 0.6230, 0.6149, 0.7021, 0.5925,
        0.5914, 0.5377, 0.5671, 0.4318, 0.5803, 0.5932, 0.6783],
       device='cuda:0') torch.Size([16])
percent tensor([0.9976, 0.9944, 0.9959, 0.9978, 0.9969, 0.9958, 0.9967, 0.9983, 0.9953,
        0.9979, 0.9957, 0.9972, 0.9941, 0.9972, 0.9969, 0.9982],
       device='cuda:0') torch.Size([16])
Epoch: 47 | Batch_idx: 0 |  Loss: (0.4670) |  Loss2: (0.0000) | Acc: (83.00%) (107/128)
Epoch: 47 | Batch_idx: 10 |  Loss: (0.4042) |  Loss2: (0.0000) | Acc: (87.00%) (1228/1408)
Epoch: 47 | Batch_idx: 20 |  Loss: (0.4298) |  Loss2: (0.0000) | Acc: (85.00%) (2300/2688)
Epoch: 47 | Batch_idx: 30 |  Loss: (0.4282) |  Loss2: (0.0000) | Acc: (85.00%) (3395/3968)
Epoch: 47 | Batch_idx: 40 |  Loss: (0.4188) |  Loss2: (0.0000) | Acc: (85.00%) (4512/5248)
Epoch: 47 | Batch_idx: 50 |  Loss: (0.4245) |  Loss2: (0.0000) | Acc: (85.00%) (5584/6528)
Epoch: 47 | Batch_idx: 60 |  Loss: (0.4207) |  Loss2: (0.0000) | Acc: (85.00%) (6689/7808)
Epoch: 47 | Batch_idx: 70 |  Loss: (0.4223) |  Loss2: (0.0000) | Acc: (85.00%) (7775/9088)
Epoch: 47 | Batch_idx: 80 |  Loss: (0.4253) |  Loss2: (0.0000) | Acc: (85.00%) (8872/10368)
Epoch: 47 | Batch_idx: 90 |  Loss: (0.4265) |  Loss2: (0.0000) | Acc: (85.00%) (9962/11648)
Epoch: 47 | Batch_idx: 100 |  Loss: (0.4230) |  Loss2: (0.0000) | Acc: (85.00%) (11072/12928)
Epoch: 47 | Batch_idx: 110 |  Loss: (0.4224) |  Loss2: (0.0000) | Acc: (85.00%) (12166/14208)
Epoch: 47 | Batch_idx: 120 |  Loss: (0.4226) |  Loss2: (0.0000) | Acc: (85.00%) (13243/15488)
Epoch: 47 | Batch_idx: 130 |  Loss: (0.4208) |  Loss2: (0.0000) | Acc: (85.00%) (14357/16768)
Epoch: 47 | Batch_idx: 140 |  Loss: (0.4245) |  Loss2: (0.0000) | Acc: (85.00%) (15428/18048)
Epoch: 47 | Batch_idx: 150 |  Loss: (0.4247) |  Loss2: (0.0000) | Acc: (85.00%) (16504/19328)
Epoch: 47 | Batch_idx: 160 |  Loss: (0.4248) |  Loss2: (0.0000) | Acc: (85.00%) (17590/20608)
Epoch: 47 | Batch_idx: 170 |  Loss: (0.4236) |  Loss2: (0.0000) | Acc: (85.00%) (18700/21888)
Epoch: 47 | Batch_idx: 180 |  Loss: (0.4218) |  Loss2: (0.0000) | Acc: (85.00%) (19796/23168)
Epoch: 47 | Batch_idx: 190 |  Loss: (0.4219) |  Loss2: (0.0000) | Acc: (85.00%) (20888/24448)
Epoch: 47 | Batch_idx: 200 |  Loss: (0.4223) |  Loss2: (0.0000) | Acc: (85.00%) (21979/25728)
Epoch: 47 | Batch_idx: 210 |  Loss: (0.4202) |  Loss2: (0.0000) | Acc: (85.00%) (23100/27008)
Epoch: 47 | Batch_idx: 220 |  Loss: (0.4184) |  Loss2: (0.0000) | Acc: (85.00%) (24215/28288)
Epoch: 47 | Batch_idx: 230 |  Loss: (0.4180) |  Loss2: (0.0000) | Acc: (85.00%) (25313/29568)
Epoch: 47 | Batch_idx: 240 |  Loss: (0.4183) |  Loss2: (0.0000) | Acc: (85.00%) (26398/30848)
Epoch: 47 | Batch_idx: 250 |  Loss: (0.4199) |  Loss2: (0.0000) | Acc: (85.00%) (27462/32128)
Epoch: 47 | Batch_idx: 260 |  Loss: (0.4194) |  Loss2: (0.0000) | Acc: (85.00%) (28556/33408)
Epoch: 47 | Batch_idx: 270 |  Loss: (0.4192) |  Loss2: (0.0000) | Acc: (85.00%) (29654/34688)
Epoch: 47 | Batch_idx: 280 |  Loss: (0.4190) |  Loss2: (0.0000) | Acc: (85.00%) (30747/35968)
Epoch: 47 | Batch_idx: 290 |  Loss: (0.4196) |  Loss2: (0.0000) | Acc: (85.00%) (31828/37248)
Epoch: 47 | Batch_idx: 300 |  Loss: (0.4195) |  Loss2: (0.0000) | Acc: (85.00%) (32926/38528)
Epoch: 47 | Batch_idx: 310 |  Loss: (0.4200) |  Loss2: (0.0000) | Acc: (85.00%) (34014/39808)
Epoch: 47 | Batch_idx: 320 |  Loss: (0.4198) |  Loss2: (0.0000) | Acc: (85.00%) (35115/41088)
Epoch: 47 | Batch_idx: 330 |  Loss: (0.4204) |  Loss2: (0.0000) | Acc: (85.00%) (36198/42368)
Epoch: 47 | Batch_idx: 340 |  Loss: (0.4205) |  Loss2: (0.0000) | Acc: (85.00%) (37283/43648)
Epoch: 47 | Batch_idx: 350 |  Loss: (0.4201) |  Loss2: (0.0000) | Acc: (85.00%) (38370/44928)
Epoch: 47 | Batch_idx: 360 |  Loss: (0.4190) |  Loss2: (0.0000) | Acc: (85.00%) (39471/46208)
Epoch: 47 | Batch_idx: 370 |  Loss: (0.4196) |  Loss2: (0.0000) | Acc: (85.00%) (40545/47488)
Epoch: 47 | Batch_idx: 380 |  Loss: (0.4195) |  Loss2: (0.0000) | Acc: (85.00%) (41647/48768)
Epoch: 47 | Batch_idx: 390 |  Loss: (0.4201) |  Loss2: (0.0000) | Acc: (85.00%) (42680/50000)
# TEST : Loss: (0.4869) | Acc: (83.00%) (8347/10000)
percent tensor([0.5613, 0.5610, 0.5704, 0.5631, 0.5728, 0.5662, 0.5659, 0.5607, 0.5613,
        0.5615, 0.5588, 0.5667, 0.5589, 0.5540, 0.5631, 0.5595],
       device='cuda:0') torch.Size([16])
percent tensor([0.5472, 0.5190, 0.5099, 0.5633, 0.5316, 0.6024, 0.5184, 0.5417, 0.5331,
        0.5131, 0.5286, 0.5021, 0.5191, 0.5587, 0.5560, 0.5584],
       device='cuda:0') torch.Size([16])
percent tensor([0.4388, 0.4877, 0.4354, 0.4145, 0.4361, 0.4047, 0.4749, 0.4459, 0.4537,
        0.4544, 0.4519, 0.4508, 0.4608, 0.4762, 0.4476, 0.4394],
       device='cuda:0') torch.Size([16])
percent tensor([0.6382, 0.6106, 0.5988, 0.6264, 0.6118, 0.6652, 0.6085, 0.6023, 0.6251,
        0.6292, 0.6359, 0.6112, 0.6289, 0.6315, 0.6248, 0.6537],
       device='cuda:0') torch.Size([16])
percent tensor([0.5896, 0.6461, 0.6034, 0.5896, 0.5516, 0.6294, 0.5927, 0.5207, 0.6433,
        0.6177, 0.6588, 0.6486, 0.6971, 0.6776, 0.5585, 0.6023],
       device='cuda:0') torch.Size([16])
percent tensor([0.6266, 0.5967, 0.6735, 0.6916, 0.6952, 0.6958, 0.6365, 0.6510, 0.6798,
        0.6049, 0.6655, 0.6287, 0.5915, 0.7248, 0.6067, 0.6433],
       device='cuda:0') torch.Size([16])
percent tensor([0.6063, 0.5232, 0.6425, 0.6390, 0.7043, 0.6303, 0.6070, 0.6840, 0.5934,
        0.5834, 0.5359, 0.5551, 0.4220, 0.5850, 0.5758, 0.6701],
       device='cuda:0') torch.Size([16])
percent tensor([0.9979, 0.9949, 0.9963, 0.9980, 0.9971, 0.9961, 0.9970, 0.9985, 0.9957,
        0.9981, 0.9960, 0.9974, 0.9948, 0.9977, 0.9972, 0.9984],
       device='cuda:0') torch.Size([16])
Epoch: 48 | Batch_idx: 0 |  Loss: (0.3268) |  Loss2: (0.0000) | Acc: (89.00%) (114/128)
Epoch: 48 | Batch_idx: 10 |  Loss: (0.4370) |  Loss2: (0.0000) | Acc: (84.00%) (1191/1408)
Epoch: 48 | Batch_idx: 20 |  Loss: (0.4272) |  Loss2: (0.0000) | Acc: (85.00%) (2294/2688)
Epoch: 48 | Batch_idx: 30 |  Loss: (0.4264) |  Loss2: (0.0000) | Acc: (85.00%) (3394/3968)
Epoch: 48 | Batch_idx: 40 |  Loss: (0.4122) |  Loss2: (0.0000) | Acc: (85.00%) (4512/5248)
Epoch: 48 | Batch_idx: 50 |  Loss: (0.4057) |  Loss2: (0.0000) | Acc: (86.00%) (5632/6528)
Epoch: 48 | Batch_idx: 60 |  Loss: (0.4068) |  Loss2: (0.0000) | Acc: (86.00%) (6729/7808)
Epoch: 48 | Batch_idx: 70 |  Loss: (0.4081) |  Loss2: (0.0000) | Acc: (86.00%) (7821/9088)
Epoch: 48 | Batch_idx: 80 |  Loss: (0.4099) |  Loss2: (0.0000) | Acc: (86.00%) (8926/10368)
Epoch: 48 | Batch_idx: 90 |  Loss: (0.4108) |  Loss2: (0.0000) | Acc: (85.00%) (10016/11648)
Epoch: 48 | Batch_idx: 100 |  Loss: (0.4140) |  Loss2: (0.0000) | Acc: (85.00%) (11098/12928)
Epoch: 48 | Batch_idx: 110 |  Loss: (0.4142) |  Loss2: (0.0000) | Acc: (85.00%) (12190/14208)
Epoch: 48 | Batch_idx: 120 |  Loss: (0.4134) |  Loss2: (0.0000) | Acc: (85.00%) (13292/15488)
Epoch: 48 | Batch_idx: 130 |  Loss: (0.4143) |  Loss2: (0.0000) | Acc: (85.00%) (14386/16768)
Epoch: 48 | Batch_idx: 140 |  Loss: (0.4142) |  Loss2: (0.0000) | Acc: (85.00%) (15483/18048)
Epoch: 48 | Batch_idx: 150 |  Loss: (0.4155) |  Loss2: (0.0000) | Acc: (85.00%) (16571/19328)
Epoch: 48 | Batch_idx: 160 |  Loss: (0.4160) |  Loss2: (0.0000) | Acc: (85.00%) (17657/20608)
Epoch: 48 | Batch_idx: 170 |  Loss: (0.4151) |  Loss2: (0.0000) | Acc: (85.00%) (18760/21888)
Epoch: 48 | Batch_idx: 180 |  Loss: (0.4156) |  Loss2: (0.0000) | Acc: (85.00%) (19845/23168)
Epoch: 48 | Batch_idx: 190 |  Loss: (0.4143) |  Loss2: (0.0000) | Acc: (85.00%) (20961/24448)
Epoch: 48 | Batch_idx: 200 |  Loss: (0.4169) |  Loss2: (0.0000) | Acc: (85.00%) (22021/25728)
Epoch: 48 | Batch_idx: 210 |  Loss: (0.4162) |  Loss2: (0.0000) | Acc: (85.00%) (23120/27008)
Epoch: 48 | Batch_idx: 220 |  Loss: (0.4157) |  Loss2: (0.0000) | Acc: (85.00%) (24222/28288)
Epoch: 48 | Batch_idx: 230 |  Loss: (0.4154) |  Loss2: (0.0000) | Acc: (85.00%) (25323/29568)
Epoch: 48 | Batch_idx: 240 |  Loss: (0.4158) |  Loss2: (0.0000) | Acc: (85.00%) (26422/30848)
Epoch: 48 | Batch_idx: 250 |  Loss: (0.4164) |  Loss2: (0.0000) | Acc: (85.00%) (27514/32128)
Epoch: 48 | Batch_idx: 260 |  Loss: (0.4161) |  Loss2: (0.0000) | Acc: (85.00%) (28611/33408)
Epoch: 48 | Batch_idx: 270 |  Loss: (0.4167) |  Loss2: (0.0000) | Acc: (85.00%) (29704/34688)
Epoch: 48 | Batch_idx: 280 |  Loss: (0.4167) |  Loss2: (0.0000) | Acc: (85.00%) (30811/35968)
Epoch: 48 | Batch_idx: 290 |  Loss: (0.4147) |  Loss2: (0.0000) | Acc: (85.00%) (31939/37248)
Epoch: 48 | Batch_idx: 300 |  Loss: (0.4140) |  Loss2: (0.0000) | Acc: (85.00%) (33053/38528)
Epoch: 48 | Batch_idx: 310 |  Loss: (0.4153) |  Loss2: (0.0000) | Acc: (85.00%) (34139/39808)
Epoch: 48 | Batch_idx: 320 |  Loss: (0.4153) |  Loss2: (0.0000) | Acc: (85.00%) (35224/41088)
Epoch: 48 | Batch_idx: 330 |  Loss: (0.4154) |  Loss2: (0.0000) | Acc: (85.00%) (36317/42368)
Epoch: 48 | Batch_idx: 340 |  Loss: (0.4147) |  Loss2: (0.0000) | Acc: (85.00%) (37420/43648)
Epoch: 48 | Batch_idx: 350 |  Loss: (0.4144) |  Loss2: (0.0000) | Acc: (85.00%) (38526/44928)
Epoch: 48 | Batch_idx: 360 |  Loss: (0.4141) |  Loss2: (0.0000) | Acc: (85.00%) (39625/46208)
Epoch: 48 | Batch_idx: 370 |  Loss: (0.4129) |  Loss2: (0.0000) | Acc: (85.00%) (40749/47488)
Epoch: 48 | Batch_idx: 380 |  Loss: (0.4128) |  Loss2: (0.0000) | Acc: (85.00%) (41850/48768)
Epoch: 48 | Batch_idx: 390 |  Loss: (0.4123) |  Loss2: (0.0000) | Acc: (85.00%) (42914/50000)
# TEST : Loss: (0.4789) | Acc: (83.00%) (8367/10000)
percent tensor([0.5623, 0.5624, 0.5719, 0.5640, 0.5744, 0.5673, 0.5675, 0.5619, 0.5627,
        0.5628, 0.5600, 0.5681, 0.5600, 0.5553, 0.5643, 0.5605],
       device='cuda:0') torch.Size([16])
percent tensor([0.5485, 0.5202, 0.5103, 0.5649, 0.5328, 0.6052, 0.5193, 0.5433, 0.5349,
        0.5135, 0.5292, 0.5021, 0.5195, 0.5619, 0.5577, 0.5598],
       device='cuda:0') torch.Size([16])
percent tensor([0.4436, 0.4913, 0.4387, 0.4184, 0.4394, 0.4069, 0.4793, 0.4495, 0.4581,
        0.4591, 0.4571, 0.4555, 0.4652, 0.4803, 0.4515, 0.4441],
       device='cuda:0') torch.Size([16])
percent tensor([0.6458, 0.6166, 0.6047, 0.6335, 0.6179, 0.6734, 0.6149, 0.6092, 0.6323,
        0.6351, 0.6420, 0.6173, 0.6356, 0.6384, 0.6320, 0.6610],
       device='cuda:0') torch.Size([16])
percent tensor([0.5979, 0.6533, 0.6116, 0.5973, 0.5591, 0.6374, 0.5978, 0.5267, 0.6529,
        0.6257, 0.6668, 0.6559, 0.7058, 0.6869, 0.5623, 0.6113],
       device='cuda:0') torch.Size([16])
percent tensor([0.6365, 0.6064, 0.6822, 0.7002, 0.7044, 0.7055, 0.6468, 0.6584, 0.6906,
        0.6133, 0.6751, 0.6386, 0.6035, 0.7374, 0.6154, 0.6537],
       device='cuda:0') torch.Size([16])
percent tensor([0.6077, 0.5239, 0.6490, 0.6399, 0.7126, 0.6404, 0.6092, 0.6816, 0.5982,
        0.5833, 0.5376, 0.5527, 0.4172, 0.5893, 0.5714, 0.6722],
       device='cuda:0') torch.Size([16])
percent tensor([0.9981, 0.9953, 0.9965, 0.9981, 0.9972, 0.9964, 0.9973, 0.9986, 0.9962,
        0.9982, 0.9964, 0.9976, 0.9954, 0.9980, 0.9974, 0.9985],
       device='cuda:0') torch.Size([16])
Epoch: 49 | Batch_idx: 0 |  Loss: (0.3450) |  Loss2: (0.0000) | Acc: (87.00%) (112/128)
Epoch: 49 | Batch_idx: 10 |  Loss: (0.3787) |  Loss2: (0.0000) | Acc: (87.00%) (1236/1408)
Epoch: 49 | Batch_idx: 20 |  Loss: (0.3835) |  Loss2: (0.0000) | Acc: (87.00%) (2349/2688)
Epoch: 49 | Batch_idx: 30 |  Loss: (0.3840) |  Loss2: (0.0000) | Acc: (87.00%) (3463/3968)
Epoch: 49 | Batch_idx: 40 |  Loss: (0.3931) |  Loss2: (0.0000) | Acc: (86.00%) (4556/5248)
Epoch: 49 | Batch_idx: 50 |  Loss: (0.3957) |  Loss2: (0.0000) | Acc: (86.00%) (5658/6528)
Epoch: 49 | Batch_idx: 60 |  Loss: (0.3963) |  Loss2: (0.0000) | Acc: (86.00%) (6756/7808)
Epoch: 49 | Batch_idx: 70 |  Loss: (0.3973) |  Loss2: (0.0000) | Acc: (86.00%) (7851/9088)
Epoch: 49 | Batch_idx: 80 |  Loss: (0.3987) |  Loss2: (0.0000) | Acc: (86.00%) (8951/10368)
Epoch: 49 | Batch_idx: 90 |  Loss: (0.3984) |  Loss2: (0.0000) | Acc: (86.00%) (10055/11648)
Epoch: 49 | Batch_idx: 100 |  Loss: (0.3993) |  Loss2: (0.0000) | Acc: (86.00%) (11152/12928)
Epoch: 49 | Batch_idx: 110 |  Loss: (0.3999) |  Loss2: (0.0000) | Acc: (86.00%) (12271/14208)
Epoch: 49 | Batch_idx: 120 |  Loss: (0.4010) |  Loss2: (0.0000) | Acc: (86.00%) (13367/15488)
Epoch: 49 | Batch_idx: 130 |  Loss: (0.4004) |  Loss2: (0.0000) | Acc: (86.00%) (14482/16768)
Epoch: 49 | Batch_idx: 140 |  Loss: (0.3992) |  Loss2: (0.0000) | Acc: (86.00%) (15593/18048)
Epoch: 49 | Batch_idx: 150 |  Loss: (0.3984) |  Loss2: (0.0000) | Acc: (86.00%) (16702/19328)
Epoch: 49 | Batch_idx: 160 |  Loss: (0.4008) |  Loss2: (0.0000) | Acc: (86.00%) (17777/20608)
Epoch: 49 | Batch_idx: 170 |  Loss: (0.4018) |  Loss2: (0.0000) | Acc: (86.00%) (18877/21888)
Epoch: 49 | Batch_idx: 180 |  Loss: (0.4024) |  Loss2: (0.0000) | Acc: (86.00%) (19985/23168)
Epoch: 49 | Batch_idx: 190 |  Loss: (0.4030) |  Loss2: (0.0000) | Acc: (86.00%) (21068/24448)
Epoch: 49 | Batch_idx: 200 |  Loss: (0.4025) |  Loss2: (0.0000) | Acc: (86.00%) (22183/25728)
Epoch: 49 | Batch_idx: 210 |  Loss: (0.4025) |  Loss2: (0.0000) | Acc: (86.00%) (23284/27008)
Epoch: 49 | Batch_idx: 220 |  Loss: (0.4028) |  Loss2: (0.0000) | Acc: (86.00%) (24382/28288)
Epoch: 49 | Batch_idx: 230 |  Loss: (0.4021) |  Loss2: (0.0000) | Acc: (86.00%) (25496/29568)
Epoch: 49 | Batch_idx: 240 |  Loss: (0.4024) |  Loss2: (0.0000) | Acc: (86.00%) (26604/30848)
Epoch: 49 | Batch_idx: 250 |  Loss: (0.4026) |  Loss2: (0.0000) | Acc: (86.00%) (27707/32128)
Epoch: 49 | Batch_idx: 260 |  Loss: (0.4021) |  Loss2: (0.0000) | Acc: (86.00%) (28826/33408)
Epoch: 49 | Batch_idx: 270 |  Loss: (0.4025) |  Loss2: (0.0000) | Acc: (86.00%) (29932/34688)
Epoch: 49 | Batch_idx: 280 |  Loss: (0.4028) |  Loss2: (0.0000) | Acc: (86.00%) (31043/35968)
Epoch: 49 | Batch_idx: 290 |  Loss: (0.4029) |  Loss2: (0.0000) | Acc: (86.00%) (32129/37248)
Epoch: 49 | Batch_idx: 300 |  Loss: (0.4030) |  Loss2: (0.0000) | Acc: (86.00%) (33236/38528)
Epoch: 49 | Batch_idx: 310 |  Loss: (0.4043) |  Loss2: (0.0000) | Acc: (86.00%) (34315/39808)
Epoch: 49 | Batch_idx: 320 |  Loss: (0.4046) |  Loss2: (0.0000) | Acc: (86.00%) (35395/41088)
Epoch: 49 | Batch_idx: 330 |  Loss: (0.4043) |  Loss2: (0.0000) | Acc: (86.00%) (36498/42368)
Epoch: 49 | Batch_idx: 340 |  Loss: (0.4055) |  Loss2: (0.0000) | Acc: (86.00%) (37589/43648)
Epoch: 49 | Batch_idx: 350 |  Loss: (0.4058) |  Loss2: (0.0000) | Acc: (86.00%) (38686/44928)
Epoch: 49 | Batch_idx: 360 |  Loss: (0.4059) |  Loss2: (0.0000) | Acc: (86.00%) (39787/46208)
Epoch: 49 | Batch_idx: 370 |  Loss: (0.4052) |  Loss2: (0.0000) | Acc: (86.00%) (40904/47488)
Epoch: 49 | Batch_idx: 380 |  Loss: (0.4047) |  Loss2: (0.0000) | Acc: (86.00%) (42009/48768)
Epoch: 49 | Batch_idx: 390 |  Loss: (0.4049) |  Loss2: (0.0000) | Acc: (86.00%) (43076/50000)
# TEST : Loss: (0.4759) | Acc: (83.00%) (8381/10000)
percent tensor([0.5649, 0.5654, 0.5747, 0.5666, 0.5776, 0.5699, 0.5706, 0.5649, 0.5659,
        0.5656, 0.5628, 0.5710, 0.5627, 0.5587, 0.5671, 0.5631],
       device='cuda:0') torch.Size([16])
percent tensor([0.5484, 0.5191, 0.5094, 0.5655, 0.5323, 0.6068, 0.5183, 0.5434, 0.5349,
        0.5118, 0.5278, 0.5002, 0.5180, 0.5636, 0.5577, 0.5595],
       device='cuda:0') torch.Size([16])
percent tensor([0.4486, 0.4955, 0.4417, 0.4232, 0.4435, 0.4114, 0.4835, 0.4534, 0.4624,
        0.4640, 0.4621, 0.4600, 0.4696, 0.4849, 0.4565, 0.4497],
       device='cuda:0') torch.Size([16])
percent tensor([0.6459, 0.6155, 0.6044, 0.6339, 0.6174, 0.6744, 0.6144, 0.6090, 0.6324,
        0.6337, 0.6410, 0.6162, 0.6345, 0.6392, 0.6319, 0.6605],
       device='cuda:0') torch.Size([16])
percent tensor([0.5973, 0.6542, 0.6075, 0.5925, 0.5534, 0.6321, 0.5950, 0.5237, 0.6529,
        0.6250, 0.6669, 0.6539, 0.7065, 0.6879, 0.5601, 0.6094],
       device='cuda:0') torch.Size([16])
percent tensor([0.6321, 0.5995, 0.6804, 0.6983, 0.7014, 0.7041, 0.6418, 0.6533, 0.6872,
        0.6058, 0.6708, 0.6355, 0.5989, 0.7346, 0.6097, 0.6483],
       device='cuda:0') torch.Size([16])
percent tensor([0.6093, 0.5281, 0.6545, 0.6418, 0.7159, 0.6463, 0.6123, 0.6794, 0.6011,
        0.5868, 0.5421, 0.5541, 0.4195, 0.5889, 0.5700, 0.6731],
       device='cuda:0') torch.Size([16])
percent tensor([0.9982, 0.9959, 0.9969, 0.9983, 0.9976, 0.9968, 0.9975, 0.9987, 0.9966,
        0.9984, 0.9968, 0.9978, 0.9959, 0.9982, 0.9977, 0.9986],
       device='cuda:0') torch.Size([16])
True Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=128, out_features=16, bias=False)
False Linear(in_features=16, out_features=2, bias=False)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=128, out_features=16, bias=False)
False Linear(in_features=16, out_features=2, bias=False)
True Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=256, out_features=32, bias=False)
False Linear(in_features=32, out_features=2, bias=False)
True Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=256, out_features=32, bias=False)
False Linear(in_features=32, out_features=2, bias=False)
True Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=512, out_features=64, bias=False)
False Linear(in_features=64, out_features=2, bias=False)
True Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=512, out_features=64, bias=False)
False Linear(in_features=64, out_features=2, bias=False)
True Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1024, out_features=128, bias=False)
False Linear(in_features=128, out_features=2, bias=False)
True Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1024, out_features=128, bias=False)
False Linear(in_features=128, out_features=2, bias=False)
True Linear(in_features=512, out_features=10, bias=True)
Epoch: 50 | Batch_idx: 0 |  Loss: (0.4725) |  Loss2: (0.0000) | Acc: (83.00%) (107/128)
Epoch: 50 | Batch_idx: 10 |  Loss: (0.4065) |  Loss2: (0.0000) | Acc: (86.00%) (1218/1408)
Epoch: 50 | Batch_idx: 20 |  Loss: (0.4136) |  Loss2: (0.0000) | Acc: (85.00%) (2311/2688)
Epoch: 50 | Batch_idx: 30 |  Loss: (0.4156) |  Loss2: (0.0000) | Acc: (85.00%) (3399/3968)
Epoch: 50 | Batch_idx: 40 |  Loss: (0.4225) |  Loss2: (0.0000) | Acc: (85.00%) (4470/5248)
Epoch: 50 | Batch_idx: 50 |  Loss: (0.4209) |  Loss2: (0.0000) | Acc: (85.00%) (5554/6528)
Epoch: 50 | Batch_idx: 60 |  Loss: (0.4209) |  Loss2: (0.0000) | Acc: (85.00%) (6641/7808)
Epoch: 50 | Batch_idx: 70 |  Loss: (0.4197) |  Loss2: (0.0000) | Acc: (85.00%) (7732/9088)
Epoch: 50 | Batch_idx: 80 |  Loss: (0.4211) |  Loss2: (0.0000) | Acc: (84.00%) (8812/10368)
Epoch: 50 | Batch_idx: 90 |  Loss: (0.4185) |  Loss2: (0.0000) | Acc: (85.00%) (9923/11648)
Epoch: 50 | Batch_idx: 100 |  Loss: (0.4146) |  Loss2: (0.0000) | Acc: (85.00%) (11037/12928)
Epoch: 50 | Batch_idx: 110 |  Loss: (0.4152) |  Loss2: (0.0000) | Acc: (85.00%) (12131/14208)
Epoch: 50 | Batch_idx: 120 |  Loss: (0.4144) |  Loss2: (0.0000) | Acc: (85.00%) (13216/15488)
Epoch: 50 | Batch_idx: 130 |  Loss: (0.4142) |  Loss2: (0.0000) | Acc: (85.00%) (14303/16768)
Epoch: 50 | Batch_idx: 140 |  Loss: (0.4118) |  Loss2: (0.0000) | Acc: (85.00%) (15428/18048)
Epoch: 50 | Batch_idx: 150 |  Loss: (0.4116) |  Loss2: (0.0000) | Acc: (85.00%) (16523/19328)
Epoch: 50 | Batch_idx: 160 |  Loss: (0.4133) |  Loss2: (0.0000) | Acc: (85.00%) (17621/20608)
Epoch: 50 | Batch_idx: 170 |  Loss: (0.4117) |  Loss2: (0.0000) | Acc: (85.00%) (18727/21888)
Epoch: 50 | Batch_idx: 180 |  Loss: (0.4097) |  Loss2: (0.0000) | Acc: (85.00%) (19835/23168)
Epoch: 50 | Batch_idx: 190 |  Loss: (0.4101) |  Loss2: (0.0000) | Acc: (85.00%) (20941/24448)
Epoch: 50 | Batch_idx: 200 |  Loss: (0.4089) |  Loss2: (0.0000) | Acc: (85.00%) (22048/25728)
Epoch: 50 | Batch_idx: 210 |  Loss: (0.4089) |  Loss2: (0.0000) | Acc: (85.00%) (23154/27008)
Epoch: 50 | Batch_idx: 220 |  Loss: (0.4086) |  Loss2: (0.0000) | Acc: (85.00%) (24262/28288)
Epoch: 50 | Batch_idx: 230 |  Loss: (0.4106) |  Loss2: (0.0000) | Acc: (85.00%) (25343/29568)
Epoch: 50 | Batch_idx: 240 |  Loss: (0.4132) |  Loss2: (0.0000) | Acc: (85.00%) (26422/30848)
Epoch: 50 | Batch_idx: 250 |  Loss: (0.4141) |  Loss2: (0.0000) | Acc: (85.00%) (27512/32128)
Epoch: 50 | Batch_idx: 260 |  Loss: (0.4126) |  Loss2: (0.0000) | Acc: (85.00%) (28636/33408)
Epoch: 50 | Batch_idx: 270 |  Loss: (0.4137) |  Loss2: (0.0000) | Acc: (85.00%) (29734/34688)
Epoch: 50 | Batch_idx: 280 |  Loss: (0.4113) |  Loss2: (0.0000) | Acc: (85.00%) (30868/35968)
Epoch: 50 | Batch_idx: 290 |  Loss: (0.4119) |  Loss2: (0.0000) | Acc: (85.00%) (31974/37248)
Epoch: 50 | Batch_idx: 300 |  Loss: (0.4114) |  Loss2: (0.0000) | Acc: (85.00%) (33094/38528)
Epoch: 50 | Batch_idx: 310 |  Loss: (0.4120) |  Loss2: (0.0000) | Acc: (85.00%) (34172/39808)
Epoch: 50 | Batch_idx: 320 |  Loss: (0.4132) |  Loss2: (0.0000) | Acc: (85.00%) (35258/41088)
Epoch: 50 | Batch_idx: 330 |  Loss: (0.4121) |  Loss2: (0.0000) | Acc: (85.00%) (36380/42368)
Epoch: 50 | Batch_idx: 340 |  Loss: (0.4121) |  Loss2: (0.0000) | Acc: (85.00%) (37476/43648)
Epoch: 50 | Batch_idx: 350 |  Loss: (0.4127) |  Loss2: (0.0000) | Acc: (85.00%) (38567/44928)
Epoch: 50 | Batch_idx: 360 |  Loss: (0.4128) |  Loss2: (0.0000) | Acc: (85.00%) (39659/46208)
Epoch: 50 | Batch_idx: 370 |  Loss: (0.4131) |  Loss2: (0.0000) | Acc: (85.00%) (40748/47488)
Epoch: 50 | Batch_idx: 380 |  Loss: (0.4128) |  Loss2: (0.0000) | Acc: (85.00%) (41851/48768)
Epoch: 50 | Batch_idx: 390 |  Loss: (0.4128) |  Loss2: (0.0000) | Acc: (85.00%) (42907/50000)
=> saving checkpoint 'drive/app/torch/save_Routing_Gate_2/checkpoint_050.pth.tar'
# TEST : Loss: (0.5678) | Acc: (80.00%) (8094/10000)
percent tensor([0.5647, 0.5642, 0.5771, 0.5665, 0.5787, 0.5687, 0.5716, 0.5662, 0.5668,
        0.5655, 0.5629, 0.5731, 0.5630, 0.5589, 0.5662, 0.5629],
       device='cuda:0') torch.Size([16])
percent tensor([0.5510, 0.5206, 0.5152, 0.5672, 0.5388, 0.6050, 0.5242, 0.5440, 0.5374,
        0.5133, 0.5211, 0.5092, 0.5169, 0.5700, 0.5545, 0.5587],
       device='cuda:0') torch.Size([16])
percent tensor([0.4481, 0.4856, 0.4557, 0.4253, 0.4580, 0.4234, 0.4843, 0.4538, 0.4644,
        0.4609, 0.4576, 0.4705, 0.4673, 0.4724, 0.4578, 0.4514],
       device='cuda:0') torch.Size([16])
percent tensor([0.6461, 0.6190, 0.6042, 0.6318, 0.6217, 0.6750, 0.6179, 0.6062, 0.6313,
        0.6329, 0.6403, 0.6111, 0.6349, 0.6428, 0.6306, 0.6601],
       device='cuda:0') torch.Size([16])
percent tensor([0.6009, 0.6592, 0.5692, 0.5987, 0.5078, 0.6221, 0.5801, 0.5241, 0.6608,
        0.6143, 0.6701, 0.6106, 0.7064, 0.6908, 0.5618, 0.6243],
       device='cuda:0') torch.Size([16])
percent tensor([0.6341, 0.6078, 0.6726, 0.7058, 0.6931, 0.6940, 0.6457, 0.6606, 0.6930,
        0.6174, 0.6650, 0.6257, 0.5876, 0.7405, 0.6153, 0.6457],
       device='cuda:0') torch.Size([16])
percent tensor([0.6250, 0.5172, 0.6522, 0.6337, 0.7085, 0.6440, 0.6269, 0.6819, 0.5893,
        0.5804, 0.5375, 0.5631, 0.4215, 0.5765, 0.5572, 0.6693],
       device='cuda:0') torch.Size([16])
percent tensor([0.9985, 0.9963, 0.9968, 0.9981, 0.9967, 0.9959, 0.9983, 0.9983, 0.9978,
        0.9986, 0.9971, 0.9988, 0.9970, 0.9981, 0.9974, 0.9988],
       device='cuda:0') torch.Size([16])
Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 3, 3, 3]) tensor(175.4884, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(798.9893, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(797.0574, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([128, 64, 3, 3]) tensor(1530.0784, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([128, 64, 1, 1]) tensor(503.1285, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([128, 128, 3, 3]) tensor(2197.3333, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([256, 128, 3, 3]) tensor(4295.9854, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([256, 128, 1, 1]) tensor(1422.0435, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([256, 256, 3, 3]) tensor(6107.3984, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([512, 256, 3, 3]) tensor(12058.1826, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([512, 256, 1, 1]) tensor(4013.0066, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([512, 512, 3, 3]) tensor(16977.2598, device='cuda:0', grad_fn=<NormBackward0>)
Epoch: 51 | Batch_idx: 0 |  Loss: (0.4829) |  Loss2: (0.0000) | Acc: (82.00%) (106/128)
Epoch: 51 | Batch_idx: 10 |  Loss: (0.3887) |  Loss2: (0.0000) | Acc: (86.00%) (1218/1408)
Epoch: 51 | Batch_idx: 20 |  Loss: (0.4019) |  Loss2: (0.0000) | Acc: (86.00%) (2318/2688)
Epoch: 51 | Batch_idx: 30 |  Loss: (0.4051) |  Loss2: (0.0000) | Acc: (85.00%) (3412/3968)
Epoch: 51 | Batch_idx: 40 |  Loss: (0.3999) |  Loss2: (0.0000) | Acc: (86.00%) (4530/5248)
Epoch: 51 | Batch_idx: 50 |  Loss: (0.4040) |  Loss2: (0.0000) | Acc: (86.00%) (5623/6528)
Epoch: 51 | Batch_idx: 60 |  Loss: (0.4075) |  Loss2: (0.0000) | Acc: (85.00%) (6710/7808)
Epoch: 51 | Batch_idx: 70 |  Loss: (0.4045) |  Loss2: (0.0000) | Acc: (86.00%) (7822/9088)
Epoch: 51 | Batch_idx: 80 |  Loss: (0.4039) |  Loss2: (0.0000) | Acc: (85.00%) (8907/10368)
Epoch: 51 | Batch_idx: 90 |  Loss: (0.4038) |  Loss2: (0.0000) | Acc: (85.00%) (10007/11648)
Epoch: 51 | Batch_idx: 100 |  Loss: (0.4059) |  Loss2: (0.0000) | Acc: (85.00%) (11095/12928)
Epoch: 51 | Batch_idx: 110 |  Loss: (0.4058) |  Loss2: (0.0000) | Acc: (85.00%) (12195/14208)
Epoch: 51 | Batch_idx: 120 |  Loss: (0.4056) |  Loss2: (0.0000) | Acc: (85.00%) (13291/15488)
Epoch: 51 | Batch_idx: 130 |  Loss: (0.4035) |  Loss2: (0.0000) | Acc: (85.00%) (14395/16768)
Epoch: 51 | Batch_idx: 140 |  Loss: (0.4011) |  Loss2: (0.0000) | Acc: (85.00%) (15502/18048)
Epoch: 51 | Batch_idx: 150 |  Loss: (0.3986) |  Loss2: (0.0000) | Acc: (85.00%) (16620/19328)
Epoch: 51 | Batch_idx: 160 |  Loss: (0.3990) |  Loss2: (0.0000) | Acc: (85.00%) (17715/20608)
Epoch: 51 | Batch_idx: 170 |  Loss: (0.3981) |  Loss2: (0.0000) | Acc: (86.00%) (18826/21888)
Epoch: 51 | Batch_idx: 180 |  Loss: (0.3987) |  Loss2: (0.0000) | Acc: (85.00%) (19923/23168)
Epoch: 51 | Batch_idx: 190 |  Loss: (0.3988) |  Loss2: (0.0000) | Acc: (86.00%) (21032/24448)
Epoch: 51 | Batch_idx: 200 |  Loss: (0.3992) |  Loss2: (0.0000) | Acc: (86.00%) (22128/25728)
Epoch: 51 | Batch_idx: 210 |  Loss: (0.3981) |  Loss2: (0.0000) | Acc: (86.00%) (23235/27008)
Epoch: 51 | Batch_idx: 220 |  Loss: (0.3972) |  Loss2: (0.0000) | Acc: (86.00%) (24340/28288)
Epoch: 51 | Batch_idx: 230 |  Loss: (0.3970) |  Loss2: (0.0000) | Acc: (86.00%) (25457/29568)
Epoch: 51 | Batch_idx: 240 |  Loss: (0.3961) |  Loss2: (0.0000) | Acc: (86.00%) (26575/30848)
Epoch: 51 | Batch_idx: 250 |  Loss: (0.3964) |  Loss2: (0.0000) | Acc: (86.00%) (27673/32128)
Epoch: 51 | Batch_idx: 260 |  Loss: (0.3954) |  Loss2: (0.0000) | Acc: (86.00%) (28798/33408)
Epoch: 51 | Batch_idx: 270 |  Loss: (0.3955) |  Loss2: (0.0000) | Acc: (86.00%) (29889/34688)
Epoch: 51 | Batch_idx: 280 |  Loss: (0.3953) |  Loss2: (0.0000) | Acc: (86.00%) (30992/35968)
Epoch: 51 | Batch_idx: 290 |  Loss: (0.3948) |  Loss2: (0.0000) | Acc: (86.00%) (32102/37248)
Epoch: 51 | Batch_idx: 300 |  Loss: (0.3939) |  Loss2: (0.0000) | Acc: (86.00%) (33226/38528)
Epoch: 51 | Batch_idx: 310 |  Loss: (0.3947) |  Loss2: (0.0000) | Acc: (86.00%) (34316/39808)
Epoch: 51 | Batch_idx: 320 |  Loss: (0.3954) |  Loss2: (0.0000) | Acc: (86.00%) (35407/41088)
Epoch: 51 | Batch_idx: 330 |  Loss: (0.3957) |  Loss2: (0.0000) | Acc: (86.00%) (36503/42368)
Epoch: 51 | Batch_idx: 340 |  Loss: (0.3968) |  Loss2: (0.0000) | Acc: (86.00%) (37590/43648)
Epoch: 51 | Batch_idx: 350 |  Loss: (0.3971) |  Loss2: (0.0000) | Acc: (86.00%) (38691/44928)
Epoch: 51 | Batch_idx: 360 |  Loss: (0.3968) |  Loss2: (0.0000) | Acc: (86.00%) (39816/46208)
Epoch: 51 | Batch_idx: 370 |  Loss: (0.3968) |  Loss2: (0.0000) | Acc: (86.00%) (40917/47488)
Epoch: 51 | Batch_idx: 380 |  Loss: (0.3971) |  Loss2: (0.0000) | Acc: (86.00%) (42014/48768)
Epoch: 51 | Batch_idx: 390 |  Loss: (0.3964) |  Loss2: (0.0000) | Acc: (86.00%) (43081/50000)
# TEST : Loss: (0.5324) | Acc: (82.00%) (8222/10000)
percent tensor([0.5641, 0.5646, 0.5768, 0.5688, 0.5783, 0.5687, 0.5714, 0.5672, 0.5660,
        0.5651, 0.5615, 0.5729, 0.5625, 0.5611, 0.5668, 0.5632],
       device='cuda:0') torch.Size([16])
percent tensor([0.5516, 0.5209, 0.5199, 0.5717, 0.5413, 0.6087, 0.5233, 0.5431, 0.5373,
        0.5156, 0.5223, 0.5124, 0.5181, 0.5634, 0.5559, 0.5610],
       device='cuda:0') torch.Size([16])
percent tensor([0.4508, 0.4921, 0.4457, 0.4285, 0.4518, 0.4212, 0.4866, 0.4550, 0.4607,
        0.4616, 0.4608, 0.4637, 0.4691, 0.4787, 0.4620, 0.4533],
       device='cuda:0') torch.Size([16])
percent tensor([0.6463, 0.6182, 0.6093, 0.6292, 0.6189, 0.6728, 0.6163, 0.6068, 0.6270,
        0.6341, 0.6391, 0.6189, 0.6342, 0.6397, 0.6293, 0.6589],
       device='cuda:0') torch.Size([16])
percent tensor([0.6076, 0.6463, 0.6287, 0.5933, 0.5632, 0.6369, 0.5991, 0.5314, 0.6752,
        0.6158, 0.6758, 0.6473, 0.7159, 0.6923, 0.5602, 0.6189],
       device='cuda:0') torch.Size([16])
percent tensor([0.6378, 0.6102, 0.6912, 0.7042, 0.6998, 0.7012, 0.6521, 0.6584, 0.6873,
        0.6229, 0.6703, 0.6516, 0.6045, 0.7398, 0.6223, 0.6471],
       device='cuda:0') torch.Size([16])
percent tensor([0.6017, 0.5516, 0.6477, 0.6309, 0.6934, 0.6293, 0.6117, 0.6683, 0.5729,
        0.5975, 0.5312, 0.5383, 0.4083, 0.5936, 0.5706, 0.6609],
       device='cuda:0') torch.Size([16])
percent tensor([0.9985, 0.9957, 0.9969, 0.9987, 0.9977, 0.9954, 0.9976, 0.9983, 0.9969,
        0.9980, 0.9969, 0.9979, 0.9964, 0.9974, 0.9981, 0.9988],
       device='cuda:0') torch.Size([16])
Epoch: 52 | Batch_idx: 0 |  Loss: (0.3422) |  Loss2: (0.0000) | Acc: (89.00%) (114/128)
Epoch: 52 | Batch_idx: 10 |  Loss: (0.3791) |  Loss2: (0.0000) | Acc: (86.00%) (1221/1408)
Epoch: 52 | Batch_idx: 20 |  Loss: (0.3703) |  Loss2: (0.0000) | Acc: (86.00%) (2322/2688)
Epoch: 52 | Batch_idx: 30 |  Loss: (0.3697) |  Loss2: (0.0000) | Acc: (86.00%) (3443/3968)
Epoch: 52 | Batch_idx: 40 |  Loss: (0.3642) |  Loss2: (0.0000) | Acc: (87.00%) (4580/5248)
Epoch: 52 | Batch_idx: 50 |  Loss: (0.3641) |  Loss2: (0.0000) | Acc: (87.00%) (5685/6528)
Epoch: 52 | Batch_idx: 60 |  Loss: (0.3738) |  Loss2: (0.0000) | Acc: (86.00%) (6787/7808)
Epoch: 52 | Batch_idx: 70 |  Loss: (0.3761) |  Loss2: (0.0000) | Acc: (86.00%) (7893/9088)
Epoch: 52 | Batch_idx: 80 |  Loss: (0.3801) |  Loss2: (0.0000) | Acc: (86.00%) (8990/10368)
Epoch: 52 | Batch_idx: 90 |  Loss: (0.3819) |  Loss2: (0.0000) | Acc: (86.00%) (10101/11648)
Epoch: 52 | Batch_idx: 100 |  Loss: (0.3818) |  Loss2: (0.0000) | Acc: (86.00%) (11207/12928)
Epoch: 52 | Batch_idx: 110 |  Loss: (0.3811) |  Loss2: (0.0000) | Acc: (86.00%) (12321/14208)
Epoch: 52 | Batch_idx: 120 |  Loss: (0.3802) |  Loss2: (0.0000) | Acc: (86.00%) (13441/15488)
Epoch: 52 | Batch_idx: 130 |  Loss: (0.3803) |  Loss2: (0.0000) | Acc: (86.00%) (14551/16768)
Epoch: 52 | Batch_idx: 140 |  Loss: (0.3824) |  Loss2: (0.0000) | Acc: (86.00%) (15651/18048)
Epoch: 52 | Batch_idx: 150 |  Loss: (0.3818) |  Loss2: (0.0000) | Acc: (86.00%) (16787/19328)
Epoch: 52 | Batch_idx: 160 |  Loss: (0.3821) |  Loss2: (0.0000) | Acc: (86.00%) (17885/20608)
Epoch: 52 | Batch_idx: 170 |  Loss: (0.3846) |  Loss2: (0.0000) | Acc: (86.00%) (18965/21888)
Epoch: 52 | Batch_idx: 180 |  Loss: (0.3826) |  Loss2: (0.0000) | Acc: (86.00%) (20105/23168)
Epoch: 52 | Batch_idx: 190 |  Loss: (0.3854) |  Loss2: (0.0000) | Acc: (86.00%) (21202/24448)
Epoch: 52 | Batch_idx: 200 |  Loss: (0.3848) |  Loss2: (0.0000) | Acc: (86.00%) (22317/25728)
Epoch: 52 | Batch_idx: 210 |  Loss: (0.3828) |  Loss2: (0.0000) | Acc: (86.00%) (23451/27008)
Epoch: 52 | Batch_idx: 220 |  Loss: (0.3815) |  Loss2: (0.0000) | Acc: (86.00%) (24582/28288)
Epoch: 52 | Batch_idx: 230 |  Loss: (0.3832) |  Loss2: (0.0000) | Acc: (86.00%) (25675/29568)
Epoch: 52 | Batch_idx: 240 |  Loss: (0.3831) |  Loss2: (0.0000) | Acc: (86.00%) (26786/30848)
Epoch: 52 | Batch_idx: 250 |  Loss: (0.3826) |  Loss2: (0.0000) | Acc: (86.00%) (27892/32128)
Epoch: 52 | Batch_idx: 260 |  Loss: (0.3818) |  Loss2: (0.0000) | Acc: (86.00%) (29017/33408)
Epoch: 52 | Batch_idx: 270 |  Loss: (0.3825) |  Loss2: (0.0000) | Acc: (86.00%) (30111/34688)
Epoch: 52 | Batch_idx: 280 |  Loss: (0.3824) |  Loss2: (0.0000) | Acc: (86.00%) (31226/35968)
Epoch: 52 | Batch_idx: 290 |  Loss: (0.3836) |  Loss2: (0.0000) | Acc: (86.00%) (32314/37248)
Epoch: 52 | Batch_idx: 300 |  Loss: (0.3841) |  Loss2: (0.0000) | Acc: (86.00%) (33423/38528)
Epoch: 52 | Batch_idx: 310 |  Loss: (0.3836) |  Loss2: (0.0000) | Acc: (86.00%) (34545/39808)
Epoch: 52 | Batch_idx: 320 |  Loss: (0.3849) |  Loss2: (0.0000) | Acc: (86.00%) (35632/41088)
Epoch: 52 | Batch_idx: 330 |  Loss: (0.3851) |  Loss2: (0.0000) | Acc: (86.00%) (36732/42368)
Epoch: 52 | Batch_idx: 340 |  Loss: (0.3849) |  Loss2: (0.0000) | Acc: (86.00%) (37850/43648)
Epoch: 52 | Batch_idx: 350 |  Loss: (0.3849) |  Loss2: (0.0000) | Acc: (86.00%) (38962/44928)
Epoch: 52 | Batch_idx: 360 |  Loss: (0.3850) |  Loss2: (0.0000) | Acc: (86.00%) (40072/46208)
Epoch: 52 | Batch_idx: 370 |  Loss: (0.3842) |  Loss2: (0.0000) | Acc: (86.00%) (41196/47488)
Epoch: 52 | Batch_idx: 380 |  Loss: (0.3841) |  Loss2: (0.0000) | Acc: (86.00%) (42306/48768)
Epoch: 52 | Batch_idx: 390 |  Loss: (0.3835) |  Loss2: (0.0000) | Acc: (86.00%) (43382/50000)
# TEST : Loss: (0.5044) | Acc: (83.00%) (8339/10000)
percent tensor([0.5646, 0.5659, 0.5749, 0.5676, 0.5770, 0.5689, 0.5714, 0.5667, 0.5668,
        0.5656, 0.5628, 0.5718, 0.5629, 0.5622, 0.5671, 0.5634],
       device='cuda:0') torch.Size([16])
percent tensor([0.5536, 0.5180, 0.5197, 0.5688, 0.5435, 0.6039, 0.5258, 0.5454, 0.5379,
        0.5155, 0.5257, 0.5140, 0.5195, 0.5580, 0.5532, 0.5613],
       device='cuda:0') torch.Size([16])
percent tensor([0.4484, 0.4872, 0.4524, 0.4306, 0.4513, 0.4202, 0.4844, 0.4554, 0.4588,
        0.4601, 0.4557, 0.4641, 0.4671, 0.4744, 0.4589, 0.4501],
       device='cuda:0') torch.Size([16])
percent tensor([0.6448, 0.6171, 0.6060, 0.6272, 0.6203, 0.6709, 0.6174, 0.6089, 0.6306,
        0.6340, 0.6407, 0.6152, 0.6335, 0.6421, 0.6291, 0.6603],
       device='cuda:0') torch.Size([16])
percent tensor([0.5999, 0.6616, 0.5770, 0.5889, 0.5374, 0.6575, 0.5986, 0.5100, 0.6717,
        0.6068, 0.6661, 0.6250, 0.7052, 0.7055, 0.5793, 0.6305],
       device='cuda:0') torch.Size([16])
percent tensor([0.6439, 0.6131, 0.6705, 0.6911, 0.6927, 0.6999, 0.6530, 0.6527, 0.7002,
        0.6276, 0.6861, 0.6366, 0.6093, 0.7379, 0.6204, 0.6502],
       device='cuda:0') torch.Size([16])
percent tensor([0.6201, 0.5246, 0.6426, 0.6412, 0.7042, 0.6541, 0.6265, 0.6742, 0.5799,
        0.5834, 0.5286, 0.5494, 0.4268, 0.5544, 0.5689, 0.6661],
       device='cuda:0') torch.Size([16])
percent tensor([0.9986, 0.9960, 0.9966, 0.9981, 0.9971, 0.9974, 0.9981, 0.9986, 0.9964,
        0.9980, 0.9971, 0.9981, 0.9968, 0.9977, 0.9979, 0.9986],
       device='cuda:0') torch.Size([16])
Epoch: 53 | Batch_idx: 0 |  Loss: (0.3832) |  Loss2: (0.0000) | Acc: (89.00%) (115/128)
Epoch: 53 | Batch_idx: 10 |  Loss: (0.4007) |  Loss2: (0.0000) | Acc: (86.00%) (1222/1408)
Epoch: 53 | Batch_idx: 20 |  Loss: (0.3817) |  Loss2: (0.0000) | Acc: (87.00%) (2348/2688)
Epoch: 53 | Batch_idx: 30 |  Loss: (0.3701) |  Loss2: (0.0000) | Acc: (87.00%) (3481/3968)
Epoch: 53 | Batch_idx: 40 |  Loss: (0.3761) |  Loss2: (0.0000) | Acc: (87.00%) (4588/5248)
Epoch: 53 | Batch_idx: 50 |  Loss: (0.3733) |  Loss2: (0.0000) | Acc: (87.00%) (5710/6528)
Epoch: 53 | Batch_idx: 60 |  Loss: (0.3715) |  Loss2: (0.0000) | Acc: (87.00%) (6826/7808)
Epoch: 53 | Batch_idx: 70 |  Loss: (0.3721) |  Loss2: (0.0000) | Acc: (87.00%) (7951/9088)
Epoch: 53 | Batch_idx: 80 |  Loss: (0.3699) |  Loss2: (0.0000) | Acc: (87.00%) (9066/10368)
Epoch: 53 | Batch_idx: 90 |  Loss: (0.3713) |  Loss2: (0.0000) | Acc: (87.00%) (10184/11648)
Epoch: 53 | Batch_idx: 100 |  Loss: (0.3690) |  Loss2: (0.0000) | Acc: (87.00%) (11298/12928)
Epoch: 53 | Batch_idx: 110 |  Loss: (0.3685) |  Loss2: (0.0000) | Acc: (87.00%) (12417/14208)
Epoch: 53 | Batch_idx: 120 |  Loss: (0.3740) |  Loss2: (0.0000) | Acc: (87.00%) (13515/15488)
Epoch: 53 | Batch_idx: 130 |  Loss: (0.3734) |  Loss2: (0.0000) | Acc: (87.00%) (14638/16768)
Epoch: 53 | Batch_idx: 140 |  Loss: (0.3733) |  Loss2: (0.0000) | Acc: (87.00%) (15760/18048)
Epoch: 53 | Batch_idx: 150 |  Loss: (0.3734) |  Loss2: (0.0000) | Acc: (87.00%) (16867/19328)
Epoch: 53 | Batch_idx: 160 |  Loss: (0.3756) |  Loss2: (0.0000) | Acc: (87.00%) (17961/20608)
Epoch: 53 | Batch_idx: 170 |  Loss: (0.3722) |  Loss2: (0.0000) | Acc: (87.00%) (19105/21888)
Epoch: 53 | Batch_idx: 180 |  Loss: (0.3713) |  Loss2: (0.0000) | Acc: (87.00%) (20228/23168)
Epoch: 53 | Batch_idx: 190 |  Loss: (0.3713) |  Loss2: (0.0000) | Acc: (87.00%) (21358/24448)
Epoch: 53 | Batch_idx: 200 |  Loss: (0.3715) |  Loss2: (0.0000) | Acc: (87.00%) (22471/25728)
Epoch: 53 | Batch_idx: 210 |  Loss: (0.3710) |  Loss2: (0.0000) | Acc: (87.00%) (23603/27008)
Epoch: 53 | Batch_idx: 220 |  Loss: (0.3700) |  Loss2: (0.0000) | Acc: (87.00%) (24736/28288)
Epoch: 53 | Batch_idx: 230 |  Loss: (0.3709) |  Loss2: (0.0000) | Acc: (87.00%) (25841/29568)
Epoch: 53 | Batch_idx: 240 |  Loss: (0.3699) |  Loss2: (0.0000) | Acc: (87.00%) (26966/30848)
Epoch: 53 | Batch_idx: 250 |  Loss: (0.3689) |  Loss2: (0.0000) | Acc: (87.00%) (28100/32128)
Epoch: 53 | Batch_idx: 260 |  Loss: (0.3690) |  Loss2: (0.0000) | Acc: (87.00%) (29212/33408)
Epoch: 53 | Batch_idx: 270 |  Loss: (0.3688) |  Loss2: (0.0000) | Acc: (87.00%) (30330/34688)
Epoch: 53 | Batch_idx: 280 |  Loss: (0.3690) |  Loss2: (0.0000) | Acc: (87.00%) (31456/35968)
Epoch: 53 | Batch_idx: 290 |  Loss: (0.3694) |  Loss2: (0.0000) | Acc: (87.00%) (32564/37248)
Epoch: 53 | Batch_idx: 300 |  Loss: (0.3700) |  Loss2: (0.0000) | Acc: (87.00%) (33681/38528)
Epoch: 53 | Batch_idx: 310 |  Loss: (0.3705) |  Loss2: (0.0000) | Acc: (87.00%) (34784/39808)
Epoch: 53 | Batch_idx: 320 |  Loss: (0.3705) |  Loss2: (0.0000) | Acc: (87.00%) (35891/41088)
Epoch: 53 | Batch_idx: 330 |  Loss: (0.3712) |  Loss2: (0.0000) | Acc: (87.00%) (36987/42368)
Epoch: 53 | Batch_idx: 340 |  Loss: (0.3717) |  Loss2: (0.0000) | Acc: (87.00%) (38098/43648)
Epoch: 53 | Batch_idx: 350 |  Loss: (0.3707) |  Loss2: (0.0000) | Acc: (87.00%) (39235/44928)
Epoch: 53 | Batch_idx: 360 |  Loss: (0.3721) |  Loss2: (0.0000) | Acc: (87.00%) (40331/46208)
Epoch: 53 | Batch_idx: 370 |  Loss: (0.3721) |  Loss2: (0.0000) | Acc: (87.00%) (41440/47488)
Epoch: 53 | Batch_idx: 380 |  Loss: (0.3721) |  Loss2: (0.0000) | Acc: (87.00%) (42556/48768)
Epoch: 53 | Batch_idx: 390 |  Loss: (0.3720) |  Loss2: (0.0000) | Acc: (87.00%) (43631/50000)
# TEST : Loss: (0.5129) | Acc: (82.00%) (8297/10000)
percent tensor([0.5650, 0.5663, 0.5736, 0.5663, 0.5770, 0.5690, 0.5717, 0.5655, 0.5674,
        0.5655, 0.5632, 0.5718, 0.5632, 0.5632, 0.5670, 0.5637],
       device='cuda:0') torch.Size([16])
percent tensor([0.5524, 0.5197, 0.5198, 0.5702, 0.5427, 0.6077, 0.5229, 0.5483, 0.5346,
        0.5153, 0.5236, 0.5118, 0.5176, 0.5573, 0.5575, 0.5618],
       device='cuda:0') torch.Size([16])
percent tensor([0.4518, 0.4915, 0.4528, 0.4296, 0.4555, 0.4232, 0.4884, 0.4550, 0.4634,
        0.4633, 0.4609, 0.4673, 0.4707, 0.4811, 0.4599, 0.4535],
       device='cuda:0') torch.Size([16])
percent tensor([0.6430, 0.6149, 0.6082, 0.6313, 0.6192, 0.6708, 0.6139, 0.6133, 0.6272,
        0.6332, 0.6355, 0.6166, 0.6335, 0.6354, 0.6320, 0.6588],
       device='cuda:0') torch.Size([16])
percent tensor([0.5963, 0.6274, 0.5738, 0.5887, 0.5366, 0.6640, 0.5602, 0.4973, 0.6497,
        0.5848, 0.6492, 0.6206, 0.6800, 0.6658, 0.5612, 0.6128],
       device='cuda:0') torch.Size([16])
percent tensor([0.6338, 0.5889, 0.6877, 0.7061, 0.7074, 0.6999, 0.6460, 0.6653, 0.6893,
        0.6021, 0.6653, 0.6416, 0.5834, 0.7260, 0.6201, 0.6461],
       device='cuda:0') torch.Size([16])
percent tensor([0.6252, 0.5859, 0.6834, 0.6475, 0.7284, 0.6283, 0.6530, 0.7046, 0.6216,
        0.6266, 0.5748, 0.6087, 0.4864, 0.6156, 0.5933, 0.6759],
       device='cuda:0') torch.Size([16])
percent tensor([0.9986, 0.9964, 0.9973, 0.9981, 0.9970, 0.9953, 0.9982, 0.9989, 0.9967,
        0.9978, 0.9965, 0.9979, 0.9960, 0.9982, 0.9977, 0.9988],
       device='cuda:0') torch.Size([16])
Epoch: 54 | Batch_idx: 0 |  Loss: (0.4004) |  Loss2: (0.0000) | Acc: (87.00%) (112/128)
Epoch: 54 | Batch_idx: 10 |  Loss: (0.3684) |  Loss2: (0.0000) | Acc: (87.00%) (1238/1408)
Epoch: 54 | Batch_idx: 20 |  Loss: (0.3692) |  Loss2: (0.0000) | Acc: (87.00%) (2359/2688)
Epoch: 54 | Batch_idx: 30 |  Loss: (0.3768) |  Loss2: (0.0000) | Acc: (87.00%) (3468/3968)
Epoch: 54 | Batch_idx: 40 |  Loss: (0.3772) |  Loss2: (0.0000) | Acc: (87.00%) (4593/5248)
Epoch: 54 | Batch_idx: 50 |  Loss: (0.3721) |  Loss2: (0.0000) | Acc: (87.00%) (5719/6528)
Epoch: 54 | Batch_idx: 60 |  Loss: (0.3696) |  Loss2: (0.0000) | Acc: (87.00%) (6841/7808)
Epoch: 54 | Batch_idx: 70 |  Loss: (0.3690) |  Loss2: (0.0000) | Acc: (87.00%) (7962/9088)
Epoch: 54 | Batch_idx: 80 |  Loss: (0.3612) |  Loss2: (0.0000) | Acc: (88.00%) (9125/10368)
Epoch: 54 | Batch_idx: 90 |  Loss: (0.3586) |  Loss2: (0.0000) | Acc: (87.00%) (10248/11648)
Epoch: 54 | Batch_idx: 100 |  Loss: (0.3576) |  Loss2: (0.0000) | Acc: (87.00%) (11376/12928)
Epoch: 54 | Batch_idx: 110 |  Loss: (0.3588) |  Loss2: (0.0000) | Acc: (87.00%) (12485/14208)
Epoch: 54 | Batch_idx: 120 |  Loss: (0.3592) |  Loss2: (0.0000) | Acc: (87.00%) (13614/15488)
Epoch: 54 | Batch_idx: 130 |  Loss: (0.3590) |  Loss2: (0.0000) | Acc: (87.00%) (14730/16768)
Epoch: 54 | Batch_idx: 140 |  Loss: (0.3582) |  Loss2: (0.0000) | Acc: (87.00%) (15852/18048)
Epoch: 54 | Batch_idx: 150 |  Loss: (0.3596) |  Loss2: (0.0000) | Acc: (87.00%) (16955/19328)
Epoch: 54 | Batch_idx: 160 |  Loss: (0.3633) |  Loss2: (0.0000) | Acc: (87.00%) (18062/20608)
Epoch: 54 | Batch_idx: 170 |  Loss: (0.3655) |  Loss2: (0.0000) | Acc: (87.00%) (19153/21888)
Epoch: 54 | Batch_idx: 180 |  Loss: (0.3640) |  Loss2: (0.0000) | Acc: (87.00%) (20288/23168)
Epoch: 54 | Batch_idx: 190 |  Loss: (0.3660) |  Loss2: (0.0000) | Acc: (87.00%) (21396/24448)
Epoch: 54 | Batch_idx: 200 |  Loss: (0.3655) |  Loss2: (0.0000) | Acc: (87.00%) (22522/25728)
Epoch: 54 | Batch_idx: 210 |  Loss: (0.3658) |  Loss2: (0.0000) | Acc: (87.00%) (23629/27008)
Epoch: 54 | Batch_idx: 220 |  Loss: (0.3663) |  Loss2: (0.0000) | Acc: (87.00%) (24746/28288)
Epoch: 54 | Batch_idx: 230 |  Loss: (0.3654) |  Loss2: (0.0000) | Acc: (87.00%) (25890/29568)
Epoch: 54 | Batch_idx: 240 |  Loss: (0.3662) |  Loss2: (0.0000) | Acc: (87.00%) (26996/30848)
Epoch: 54 | Batch_idx: 250 |  Loss: (0.3676) |  Loss2: (0.0000) | Acc: (87.00%) (28094/32128)
Epoch: 54 | Batch_idx: 260 |  Loss: (0.3666) |  Loss2: (0.0000) | Acc: (87.00%) (29216/33408)
Epoch: 54 | Batch_idx: 270 |  Loss: (0.3651) |  Loss2: (0.0000) | Acc: (87.00%) (30347/34688)
Epoch: 54 | Batch_idx: 280 |  Loss: (0.3642) |  Loss2: (0.0000) | Acc: (87.00%) (31484/35968)
Epoch: 54 | Batch_idx: 290 |  Loss: (0.3643) |  Loss2: (0.0000) | Acc: (87.00%) (32606/37248)
Epoch: 54 | Batch_idx: 300 |  Loss: (0.3648) |  Loss2: (0.0000) | Acc: (87.00%) (33717/38528)
Epoch: 54 | Batch_idx: 310 |  Loss: (0.3653) |  Loss2: (0.0000) | Acc: (87.00%) (34827/39808)
Epoch: 54 | Batch_idx: 320 |  Loss: (0.3655) |  Loss2: (0.0000) | Acc: (87.00%) (35940/41088)
Epoch: 54 | Batch_idx: 330 |  Loss: (0.3663) |  Loss2: (0.0000) | Acc: (87.00%) (37054/42368)
Epoch: 54 | Batch_idx: 340 |  Loss: (0.3665) |  Loss2: (0.0000) | Acc: (87.00%) (38169/43648)
Epoch: 54 | Batch_idx: 350 |  Loss: (0.3656) |  Loss2: (0.0000) | Acc: (87.00%) (39302/44928)
Epoch: 54 | Batch_idx: 360 |  Loss: (0.3656) |  Loss2: (0.0000) | Acc: (87.00%) (40421/46208)
Epoch: 54 | Batch_idx: 370 |  Loss: (0.3660) |  Loss2: (0.0000) | Acc: (87.00%) (41540/47488)
Epoch: 54 | Batch_idx: 380 |  Loss: (0.3652) |  Loss2: (0.0000) | Acc: (87.00%) (42670/48768)
Epoch: 54 | Batch_idx: 390 |  Loss: (0.3657) |  Loss2: (0.0000) | Acc: (87.00%) (43736/50000)
# TEST : Loss: (0.4642) | Acc: (84.00%) (8403/10000)
percent tensor([0.5646, 0.5663, 0.5733, 0.5660, 0.5769, 0.5695, 0.5720, 0.5654, 0.5666,
        0.5654, 0.5628, 0.5722, 0.5629, 0.5624, 0.5672, 0.5631],
       device='cuda:0') torch.Size([16])
percent tensor([0.5508, 0.5182, 0.5175, 0.5709, 0.5411, 0.6080, 0.5218, 0.5459, 0.5324,
        0.5115, 0.5222, 0.5090, 0.5146, 0.5569, 0.5566, 0.5598],
       device='cuda:0') torch.Size([16])
percent tensor([0.4472, 0.4858, 0.4499, 0.4209, 0.4519, 0.4155, 0.4853, 0.4531, 0.4611,
        0.4599, 0.4554, 0.4654, 0.4659, 0.4741, 0.4541, 0.4473],
       device='cuda:0') torch.Size([16])
percent tensor([0.6440, 0.6180, 0.6041, 0.6321, 0.6155, 0.6681, 0.6158, 0.6101, 0.6262,
        0.6319, 0.6365, 0.6145, 0.6344, 0.6422, 0.6313, 0.6583],
       device='cuda:0') torch.Size([16])
percent tensor([0.5942, 0.6410, 0.6098, 0.6014, 0.5554, 0.6399, 0.5971, 0.5266, 0.6647,
        0.6058, 0.6634, 0.6372, 0.6937, 0.6867, 0.5689, 0.6170],
       device='cuda:0') torch.Size([16])
percent tensor([0.6371, 0.6048, 0.6877, 0.7080, 0.6995, 0.7053, 0.6496, 0.6597, 0.6862,
        0.6123, 0.6717, 0.6402, 0.5964, 0.7271, 0.6185, 0.6522],
       device='cuda:0') torch.Size([16])
percent tensor([0.6098, 0.5476, 0.6714, 0.6366, 0.7108, 0.6416, 0.6160, 0.6860, 0.5886,
        0.5828, 0.5515, 0.5583, 0.4605, 0.5708, 0.5763, 0.6634],
       device='cuda:0') torch.Size([16])
percent tensor([0.9980, 0.9964, 0.9974, 0.9981, 0.9975, 0.9948, 0.9978, 0.9982, 0.9969,
        0.9982, 0.9970, 0.9977, 0.9969, 0.9982, 0.9976, 0.9983],
       device='cuda:0') torch.Size([16])
False Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=128, out_features=16, bias=False)
True Linear(in_features=16, out_features=2, bias=False)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=128, out_features=16, bias=False)
True Linear(in_features=16, out_features=2, bias=False)
False Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=256, out_features=32, bias=False)
True Linear(in_features=32, out_features=2, bias=False)
False Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=256, out_features=32, bias=False)
True Linear(in_features=32, out_features=2, bias=False)
False Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=512, out_features=64, bias=False)
True Linear(in_features=64, out_features=2, bias=False)
False Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=512, out_features=64, bias=False)
True Linear(in_features=64, out_features=2, bias=False)
False Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1024, out_features=128, bias=False)
True Linear(in_features=128, out_features=2, bias=False)
False Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1024, out_features=128, bias=False)
True Linear(in_features=128, out_features=2, bias=False)
False Linear(in_features=512, out_features=10, bias=True)
Epoch: 55 | Batch_idx: 0 |  Loss: (0.4281) |  Loss2: (0.0000) | Acc: (87.00%) (112/128)
Epoch: 55 | Batch_idx: 10 |  Loss: (0.3493) |  Loss2: (0.0000) | Acc: (87.00%) (1230/1408)
Epoch: 55 | Batch_idx: 20 |  Loss: (0.3519) |  Loss2: (0.0000) | Acc: (87.00%) (2351/2688)
Epoch: 55 | Batch_idx: 30 |  Loss: (0.3664) |  Loss2: (0.0000) | Acc: (87.00%) (3463/3968)
Epoch: 55 | Batch_idx: 40 |  Loss: (0.3768) |  Loss2: (0.0000) | Acc: (86.00%) (4564/5248)
Epoch: 55 | Batch_idx: 50 |  Loss: (0.3804) |  Loss2: (0.0000) | Acc: (86.00%) (5668/6528)
Epoch: 55 | Batch_idx: 60 |  Loss: (0.3799) |  Loss2: (0.0000) | Acc: (86.00%) (6780/7808)
Epoch: 55 | Batch_idx: 70 |  Loss: (0.3826) |  Loss2: (0.0000) | Acc: (86.00%) (7868/9088)
Epoch: 55 | Batch_idx: 80 |  Loss: (0.3784) |  Loss2: (0.0000) | Acc: (86.00%) (8992/10368)
Epoch: 55 | Batch_idx: 90 |  Loss: (0.3855) |  Loss2: (0.0000) | Acc: (86.00%) (10080/11648)
Epoch: 55 | Batch_idx: 100 |  Loss: (0.3902) |  Loss2: (0.0000) | Acc: (86.00%) (11170/12928)
Epoch: 55 | Batch_idx: 110 |  Loss: (0.3898) |  Loss2: (0.0000) | Acc: (86.00%) (12260/14208)
Epoch: 55 | Batch_idx: 120 |  Loss: (0.3882) |  Loss2: (0.0000) | Acc: (86.00%) (13368/15488)
Epoch: 55 | Batch_idx: 130 |  Loss: (0.3872) |  Loss2: (0.0000) | Acc: (86.00%) (14473/16768)
Epoch: 55 | Batch_idx: 140 |  Loss: (0.3889) |  Loss2: (0.0000) | Acc: (86.00%) (15576/18048)
Epoch: 55 | Batch_idx: 150 |  Loss: (0.3911) |  Loss2: (0.0000) | Acc: (86.00%) (16656/19328)
Epoch: 55 | Batch_idx: 160 |  Loss: (0.3915) |  Loss2: (0.0000) | Acc: (86.00%) (17761/20608)
Epoch: 55 | Batch_idx: 170 |  Loss: (0.3938) |  Loss2: (0.0000) | Acc: (86.00%) (18850/21888)
Epoch: 55 | Batch_idx: 180 |  Loss: (0.3938) |  Loss2: (0.0000) | Acc: (86.00%) (19948/23168)
Epoch: 55 | Batch_idx: 190 |  Loss: (0.3920) |  Loss2: (0.0000) | Acc: (86.00%) (21067/24448)
Epoch: 55 | Batch_idx: 200 |  Loss: (0.3903) |  Loss2: (0.0000) | Acc: (86.00%) (22187/25728)
Epoch: 55 | Batch_idx: 210 |  Loss: (0.3875) |  Loss2: (0.0000) | Acc: (86.00%) (23327/27008)
Epoch: 55 | Batch_idx: 220 |  Loss: (0.3881) |  Loss2: (0.0000) | Acc: (86.00%) (24438/28288)
Epoch: 55 | Batch_idx: 230 |  Loss: (0.3880) |  Loss2: (0.0000) | Acc: (86.00%) (25558/29568)
Epoch: 55 | Batch_idx: 240 |  Loss: (0.3866) |  Loss2: (0.0000) | Acc: (86.00%) (26694/30848)
Epoch: 55 | Batch_idx: 250 |  Loss: (0.3846) |  Loss2: (0.0000) | Acc: (86.00%) (27839/32128)
Epoch: 55 | Batch_idx: 260 |  Loss: (0.3845) |  Loss2: (0.0000) | Acc: (86.00%) (28957/33408)
Epoch: 55 | Batch_idx: 270 |  Loss: (0.3849) |  Loss2: (0.0000) | Acc: (86.00%) (30062/34688)
Epoch: 55 | Batch_idx: 280 |  Loss: (0.3843) |  Loss2: (0.0000) | Acc: (86.00%) (31180/35968)
Epoch: 55 | Batch_idx: 290 |  Loss: (0.3828) |  Loss2: (0.0000) | Acc: (86.00%) (32309/37248)
Epoch: 55 | Batch_idx: 300 |  Loss: (0.3811) |  Loss2: (0.0000) | Acc: (86.00%) (33440/38528)
Epoch: 55 | Batch_idx: 310 |  Loss: (0.3801) |  Loss2: (0.0000) | Acc: (86.00%) (34555/39808)
Epoch: 55 | Batch_idx: 320 |  Loss: (0.3804) |  Loss2: (0.0000) | Acc: (86.00%) (35648/41088)
Epoch: 55 | Batch_idx: 330 |  Loss: (0.3803) |  Loss2: (0.0000) | Acc: (86.00%) (36760/42368)
Epoch: 55 | Batch_idx: 340 |  Loss: (0.3803) |  Loss2: (0.0000) | Acc: (86.00%) (37876/43648)
Epoch: 55 | Batch_idx: 350 |  Loss: (0.3798) |  Loss2: (0.0000) | Acc: (86.00%) (38999/44928)
Epoch: 55 | Batch_idx: 360 |  Loss: (0.3790) |  Loss2: (0.0000) | Acc: (86.00%) (40129/46208)
Epoch: 55 | Batch_idx: 370 |  Loss: (0.3786) |  Loss2: (0.0000) | Acc: (86.00%) (41246/47488)
Epoch: 55 | Batch_idx: 380 |  Loss: (0.3778) |  Loss2: (0.0000) | Acc: (86.00%) (42364/48768)
Epoch: 55 | Batch_idx: 390 |  Loss: (0.3783) |  Loss2: (0.0000) | Acc: (86.00%) (43437/50000)
=> saving checkpoint 'drive/app/torch/save_Routing_Gate_2/checkpoint_055.pth.tar'
# TEST : Loss: (0.4579) | Acc: (84.00%) (8453/10000)
percent tensor([0.5731, 0.5737, 0.5821, 0.5747, 0.5856, 0.5760, 0.5800, 0.5735, 0.5745,
        0.5738, 0.5703, 0.5816, 0.5710, 0.5680, 0.5747, 0.5706],
       device='cuda:0') torch.Size([16])
percent tensor([0.5557, 0.5216, 0.5248, 0.5698, 0.5463, 0.6072, 0.5271, 0.5499, 0.5402,
        0.5185, 0.5312, 0.5166, 0.5231, 0.5569, 0.5583, 0.5610],
       device='cuda:0') torch.Size([16])
percent tensor([0.4581, 0.4972, 0.4572, 0.4301, 0.4619, 0.4222, 0.4986, 0.4670, 0.4724,
        0.4660, 0.4629, 0.4754, 0.4766, 0.4850, 0.4667, 0.4566],
       device='cuda:0') torch.Size([16])
percent tensor([0.6429, 0.6177, 0.6067, 0.6300, 0.6152, 0.6646, 0.6160, 0.6125, 0.6275,
        0.6315, 0.6367, 0.6163, 0.6355, 0.6401, 0.6303, 0.6569],
       device='cuda:0') torch.Size([16])
percent tensor([0.5963, 0.6519, 0.6418, 0.6431, 0.5810, 0.6378, 0.6172, 0.5533, 0.6844,
        0.6015, 0.6637, 0.6630, 0.6998, 0.7038, 0.5821, 0.6142],
       device='cuda:0') torch.Size([16])
percent tensor([0.6804, 0.6416, 0.7246, 0.7476, 0.7338, 0.7494, 0.6881, 0.6894, 0.7269,
        0.6558, 0.7143, 0.6817, 0.6419, 0.7717, 0.6534, 0.6993],
       device='cuda:0') torch.Size([16])
percent tensor([0.6672, 0.5912, 0.6858, 0.6316, 0.7252, 0.6905, 0.6497, 0.7098, 0.6247,
        0.6365, 0.5939, 0.5730, 0.5185, 0.6024, 0.6157, 0.7287],
       device='cuda:0') torch.Size([16])
percent tensor([0.9983, 0.9961, 0.9971, 0.9980, 0.9972, 0.9945, 0.9977, 0.9981, 0.9966,
        0.9980, 0.9970, 0.9977, 0.9972, 0.9983, 0.9975, 0.9986],
       device='cuda:0') torch.Size([16])
Epoch: 56 | Batch_idx: 0 |  Loss: (0.3814) |  Loss2: (0.0000) | Acc: (82.00%) (106/128)
Epoch: 56 | Batch_idx: 10 |  Loss: (0.3275) |  Loss2: (0.0000) | Acc: (89.00%) (1254/1408)
Epoch: 56 | Batch_idx: 20 |  Loss: (0.3611) |  Loss2: (0.0000) | Acc: (87.00%) (2351/2688)
Epoch: 56 | Batch_idx: 30 |  Loss: (0.3617) |  Loss2: (0.0000) | Acc: (87.00%) (3469/3968)
Epoch: 56 | Batch_idx: 40 |  Loss: (0.3591) |  Loss2: (0.0000) | Acc: (87.00%) (4599/5248)
Epoch: 56 | Batch_idx: 50 |  Loss: (0.3686) |  Loss2: (0.0000) | Acc: (87.00%) (5711/6528)
Epoch: 56 | Batch_idx: 60 |  Loss: (0.3616) |  Loss2: (0.0000) | Acc: (87.00%) (6848/7808)
Epoch: 56 | Batch_idx: 70 |  Loss: (0.3594) |  Loss2: (0.0000) | Acc: (87.00%) (7975/9088)
Epoch: 56 | Batch_idx: 80 |  Loss: (0.3626) |  Loss2: (0.0000) | Acc: (87.00%) (9083/10368)
Epoch: 56 | Batch_idx: 90 |  Loss: (0.3629) |  Loss2: (0.0000) | Acc: (87.00%) (10195/11648)
Epoch: 56 | Batch_idx: 100 |  Loss: (0.3615) |  Loss2: (0.0000) | Acc: (87.00%) (11311/12928)
Epoch: 56 | Batch_idx: 110 |  Loss: (0.3609) |  Loss2: (0.0000) | Acc: (87.00%) (12440/14208)
Epoch: 56 | Batch_idx: 120 |  Loss: (0.3607) |  Loss2: (0.0000) | Acc: (87.00%) (13567/15488)
Epoch: 56 | Batch_idx: 130 |  Loss: (0.3610) |  Loss2: (0.0000) | Acc: (87.00%) (14685/16768)
Epoch: 56 | Batch_idx: 140 |  Loss: (0.3606) |  Loss2: (0.0000) | Acc: (87.00%) (15788/18048)
Epoch: 56 | Batch_idx: 150 |  Loss: (0.3587) |  Loss2: (0.0000) | Acc: (87.00%) (16930/19328)
Epoch: 56 | Batch_idx: 160 |  Loss: (0.3580) |  Loss2: (0.0000) | Acc: (87.00%) (18059/20608)
Epoch: 56 | Batch_idx: 170 |  Loss: (0.3575) |  Loss2: (0.0000) | Acc: (87.00%) (19194/21888)
Epoch: 56 | Batch_idx: 180 |  Loss: (0.3565) |  Loss2: (0.0000) | Acc: (87.00%) (20327/23168)
Epoch: 56 | Batch_idx: 190 |  Loss: (0.3583) |  Loss2: (0.0000) | Acc: (87.00%) (21438/24448)
Epoch: 56 | Batch_idx: 200 |  Loss: (0.3576) |  Loss2: (0.0000) | Acc: (87.00%) (22561/25728)
Epoch: 56 | Batch_idx: 210 |  Loss: (0.3586) |  Loss2: (0.0000) | Acc: (87.00%) (23665/27008)
Epoch: 56 | Batch_idx: 220 |  Loss: (0.3582) |  Loss2: (0.0000) | Acc: (87.00%) (24791/28288)
Epoch: 56 | Batch_idx: 230 |  Loss: (0.3577) |  Loss2: (0.0000) | Acc: (87.00%) (25921/29568)
Epoch: 56 | Batch_idx: 240 |  Loss: (0.3571) |  Loss2: (0.0000) | Acc: (87.00%) (27052/30848)
Epoch: 56 | Batch_idx: 250 |  Loss: (0.3556) |  Loss2: (0.0000) | Acc: (87.00%) (28201/32128)
Epoch: 56 | Batch_idx: 260 |  Loss: (0.3557) |  Loss2: (0.0000) | Acc: (87.00%) (29322/33408)
Epoch: 56 | Batch_idx: 270 |  Loss: (0.3556) |  Loss2: (0.0000) | Acc: (87.00%) (30445/34688)
Epoch: 56 | Batch_idx: 280 |  Loss: (0.3560) |  Loss2: (0.0000) | Acc: (87.00%) (31556/35968)
Epoch: 56 | Batch_idx: 290 |  Loss: (0.3572) |  Loss2: (0.0000) | Acc: (87.00%) (32660/37248)
Epoch: 56 | Batch_idx: 300 |  Loss: (0.3570) |  Loss2: (0.0000) | Acc: (87.00%) (33796/38528)
Epoch: 56 | Batch_idx: 310 |  Loss: (0.3569) |  Loss2: (0.0000) | Acc: (87.00%) (34922/39808)
Epoch: 56 | Batch_idx: 320 |  Loss: (0.3563) |  Loss2: (0.0000) | Acc: (87.00%) (36037/41088)
Epoch: 56 | Batch_idx: 330 |  Loss: (0.3565) |  Loss2: (0.0000) | Acc: (87.00%) (37167/42368)
Epoch: 56 | Batch_idx: 340 |  Loss: (0.3556) |  Loss2: (0.0000) | Acc: (87.00%) (38296/43648)
Epoch: 56 | Batch_idx: 350 |  Loss: (0.3563) |  Loss2: (0.0000) | Acc: (87.00%) (39419/44928)
Epoch: 56 | Batch_idx: 360 |  Loss: (0.3553) |  Loss2: (0.0000) | Acc: (87.00%) (40567/46208)
Epoch: 56 | Batch_idx: 370 |  Loss: (0.3544) |  Loss2: (0.0000) | Acc: (87.00%) (41708/47488)
Epoch: 56 | Batch_idx: 380 |  Loss: (0.3548) |  Loss2: (0.0000) | Acc: (87.00%) (42828/48768)
Epoch: 56 | Batch_idx: 390 |  Loss: (0.3555) |  Loss2: (0.0000) | Acc: (87.00%) (43897/50000)
# TEST : Loss: (0.4431) | Acc: (85.00%) (8514/10000)
percent tensor([0.5785, 0.5777, 0.5877, 0.5793, 0.5912, 0.5794, 0.5848, 0.5784, 0.5796,
        0.5786, 0.5753, 0.5873, 0.5762, 0.5707, 0.5788, 0.5750],
       device='cuda:0') torch.Size([16])
percent tensor([0.5533, 0.5196, 0.5252, 0.5661, 0.5442, 0.6006, 0.5257, 0.5484, 0.5390,
        0.5183, 0.5300, 0.5170, 0.5224, 0.5537, 0.5543, 0.5571],
       device='cuda:0') torch.Size([16])
percent tensor([0.4565, 0.4959, 0.4541, 0.4285, 0.4609, 0.4193, 0.4990, 0.4681, 0.4719,
        0.4621, 0.4591, 0.4743, 0.4753, 0.4853, 0.4666, 0.4544],
       device='cuda:0') torch.Size([16])
percent tensor([0.6408, 0.6163, 0.6062, 0.6280, 0.6133, 0.6610, 0.6143, 0.6114, 0.6265,
        0.6298, 0.6349, 0.6153, 0.6344, 0.6386, 0.6270, 0.6543],
       device='cuda:0') torch.Size([16])
percent tensor([0.5935, 0.6564, 0.6457, 0.6447, 0.5789, 0.6399, 0.6157, 0.5471, 0.6886,
        0.5978, 0.6634, 0.6663, 0.7071, 0.7049, 0.5817, 0.6124],
       device='cuda:0') torch.Size([16])
percent tensor([0.6823, 0.6421, 0.7291, 0.7530, 0.7387, 0.7578, 0.6901, 0.6869, 0.7339,
        0.6574, 0.7185, 0.6811, 0.6450, 0.7818, 0.6459, 0.7048],
       device='cuda:0') torch.Size([16])
percent tensor([0.6698, 0.5966, 0.6940, 0.6372, 0.7380, 0.6978, 0.6530, 0.7206, 0.6262,
        0.6460, 0.5945, 0.5735, 0.5150, 0.5956, 0.6226, 0.7399],
       device='cuda:0') torch.Size([16])
percent tensor([0.9984, 0.9963, 0.9974, 0.9981, 0.9974, 0.9951, 0.9978, 0.9982, 0.9969,
        0.9982, 0.9972, 0.9978, 0.9975, 0.9985, 0.9976, 0.9987],
       device='cuda:0') torch.Size([16])
Epoch: 57 | Batch_idx: 0 |  Loss: (0.2786) |  Loss2: (0.0000) | Acc: (92.00%) (119/128)
Epoch: 57 | Batch_idx: 10 |  Loss: (0.3672) |  Loss2: (0.0000) | Acc: (87.00%) (1228/1408)
Epoch: 57 | Batch_idx: 20 |  Loss: (0.3750) |  Loss2: (0.0000) | Acc: (86.00%) (2337/2688)
Epoch: 57 | Batch_idx: 30 |  Loss: (0.3754) |  Loss2: (0.0000) | Acc: (86.00%) (3445/3968)
Epoch: 57 | Batch_idx: 40 |  Loss: (0.3736) |  Loss2: (0.0000) | Acc: (86.00%) (4557/5248)
Epoch: 57 | Batch_idx: 50 |  Loss: (0.3591) |  Loss2: (0.0000) | Acc: (87.00%) (5709/6528)
Epoch: 57 | Batch_idx: 60 |  Loss: (0.3613) |  Loss2: (0.0000) | Acc: (87.00%) (6833/7808)
Epoch: 57 | Batch_idx: 70 |  Loss: (0.3550) |  Loss2: (0.0000) | Acc: (87.00%) (7980/9088)
Epoch: 57 | Batch_idx: 80 |  Loss: (0.3540) |  Loss2: (0.0000) | Acc: (87.00%) (9097/10368)
Epoch: 57 | Batch_idx: 90 |  Loss: (0.3541) |  Loss2: (0.0000) | Acc: (87.00%) (10213/11648)
Epoch: 57 | Batch_idx: 100 |  Loss: (0.3539) |  Loss2: (0.0000) | Acc: (87.00%) (11331/12928)
Epoch: 57 | Batch_idx: 110 |  Loss: (0.3541) |  Loss2: (0.0000) | Acc: (87.00%) (12438/14208)
Epoch: 57 | Batch_idx: 120 |  Loss: (0.3555) |  Loss2: (0.0000) | Acc: (87.00%) (13550/15488)
Epoch: 57 | Batch_idx: 130 |  Loss: (0.3550) |  Loss2: (0.0000) | Acc: (87.00%) (14674/16768)
Epoch: 57 | Batch_idx: 140 |  Loss: (0.3552) |  Loss2: (0.0000) | Acc: (87.00%) (15794/18048)
Epoch: 57 | Batch_idx: 150 |  Loss: (0.3562) |  Loss2: (0.0000) | Acc: (87.00%) (16904/19328)
Epoch: 57 | Batch_idx: 160 |  Loss: (0.3569) |  Loss2: (0.0000) | Acc: (87.00%) (18022/20608)
Epoch: 57 | Batch_idx: 170 |  Loss: (0.3555) |  Loss2: (0.0000) | Acc: (87.00%) (19148/21888)
Epoch: 57 | Batch_idx: 180 |  Loss: (0.3556) |  Loss2: (0.0000) | Acc: (87.00%) (20275/23168)
Epoch: 57 | Batch_idx: 190 |  Loss: (0.3564) |  Loss2: (0.0000) | Acc: (87.00%) (21393/24448)
Epoch: 57 | Batch_idx: 200 |  Loss: (0.3566) |  Loss2: (0.0000) | Acc: (87.00%) (22509/25728)
Epoch: 57 | Batch_idx: 210 |  Loss: (0.3573) |  Loss2: (0.0000) | Acc: (87.00%) (23625/27008)
Epoch: 57 | Batch_idx: 220 |  Loss: (0.3566) |  Loss2: (0.0000) | Acc: (87.00%) (24758/28288)
Epoch: 57 | Batch_idx: 230 |  Loss: (0.3550) |  Loss2: (0.0000) | Acc: (87.00%) (25886/29568)
Epoch: 57 | Batch_idx: 240 |  Loss: (0.3548) |  Loss2: (0.0000) | Acc: (87.00%) (27011/30848)
Epoch: 57 | Batch_idx: 250 |  Loss: (0.3546) |  Loss2: (0.0000) | Acc: (87.00%) (28147/32128)
Epoch: 57 | Batch_idx: 260 |  Loss: (0.3531) |  Loss2: (0.0000) | Acc: (87.00%) (29290/33408)
Epoch: 57 | Batch_idx: 270 |  Loss: (0.3519) |  Loss2: (0.0000) | Acc: (87.00%) (30431/34688)
Epoch: 57 | Batch_idx: 280 |  Loss: (0.3530) |  Loss2: (0.0000) | Acc: (87.00%) (31556/35968)
Epoch: 57 | Batch_idx: 290 |  Loss: (0.3534) |  Loss2: (0.0000) | Acc: (87.00%) (32677/37248)
Epoch: 57 | Batch_idx: 300 |  Loss: (0.3526) |  Loss2: (0.0000) | Acc: (87.00%) (33799/38528)
Epoch: 57 | Batch_idx: 310 |  Loss: (0.3527) |  Loss2: (0.0000) | Acc: (87.00%) (34917/39808)
Epoch: 57 | Batch_idx: 320 |  Loss: (0.3530) |  Loss2: (0.0000) | Acc: (87.00%) (36033/41088)
Epoch: 57 | Batch_idx: 330 |  Loss: (0.3522) |  Loss2: (0.0000) | Acc: (87.00%) (37180/42368)
Epoch: 57 | Batch_idx: 340 |  Loss: (0.3527) |  Loss2: (0.0000) | Acc: (87.00%) (38303/43648)
Epoch: 57 | Batch_idx: 350 |  Loss: (0.3518) |  Loss2: (0.0000) | Acc: (87.00%) (39438/44928)
Epoch: 57 | Batch_idx: 360 |  Loss: (0.3523) |  Loss2: (0.0000) | Acc: (87.00%) (40554/46208)
Epoch: 57 | Batch_idx: 370 |  Loss: (0.3514) |  Loss2: (0.0000) | Acc: (87.00%) (41686/47488)
Epoch: 57 | Batch_idx: 380 |  Loss: (0.3504) |  Loss2: (0.0000) | Acc: (87.00%) (42824/48768)
Epoch: 57 | Batch_idx: 390 |  Loss: (0.3509) |  Loss2: (0.0000) | Acc: (87.00%) (43911/50000)
# TEST : Loss: (0.4319) | Acc: (85.00%) (8545/10000)
percent tensor([0.5772, 0.5749, 0.5861, 0.5777, 0.5893, 0.5777, 0.5823, 0.5764, 0.5776,
        0.5764, 0.5734, 0.5854, 0.5745, 0.5673, 0.5765, 0.5730],
       device='cuda:0') torch.Size([16])
percent tensor([0.5550, 0.5213, 0.5287, 0.5669, 0.5462, 0.5984, 0.5282, 0.5508, 0.5419,
        0.5214, 0.5328, 0.5205, 0.5252, 0.5552, 0.5542, 0.5576],
       device='cuda:0') torch.Size([16])
percent tensor([0.4562, 0.4976, 0.4537, 0.4302, 0.4619, 0.4203, 0.5007, 0.4698, 0.4730,
        0.4612, 0.4578, 0.4749, 0.4758, 0.4877, 0.4687, 0.4549],
       device='cuda:0') torch.Size([16])
percent tensor([0.6447, 0.6199, 0.6129, 0.6324, 0.6188, 0.6637, 0.6188, 0.6173, 0.6313,
        0.6341, 0.6387, 0.6209, 0.6385, 0.6424, 0.6300, 0.6579],
       device='cuda:0') torch.Size([16])
percent tensor([0.5861, 0.6575, 0.6441, 0.6443, 0.5797, 0.6308, 0.6129, 0.5467, 0.6872,
        0.5923, 0.6600, 0.6640, 0.7054, 0.7057, 0.5794, 0.6069],
       device='cuda:0') torch.Size([16])
percent tensor([0.6646, 0.6229, 0.7164, 0.7418, 0.7278, 0.7502, 0.6740, 0.6687, 0.7244,
        0.6387, 0.7039, 0.6609, 0.6265, 0.7755, 0.6222, 0.6899],
       device='cuda:0') torch.Size([16])
percent tensor([0.6619, 0.5928, 0.6938, 0.6393, 0.7423, 0.6918, 0.6499, 0.7224, 0.6219,
        0.6447, 0.5938, 0.5737, 0.5053, 0.5916, 0.6212, 0.7353],
       device='cuda:0') torch.Size([16])
percent tensor([0.9984, 0.9962, 0.9975, 0.9982, 0.9975, 0.9952, 0.9977, 0.9983, 0.9969,
        0.9982, 0.9972, 0.9978, 0.9974, 0.9985, 0.9975, 0.9987],
       device='cuda:0') torch.Size([16])
Epoch: 58 | Batch_idx: 0 |  Loss: (0.4509) |  Loss2: (0.0000) | Acc: (82.00%) (106/128)
Epoch: 58 | Batch_idx: 10 |  Loss: (0.3785) |  Loss2: (0.0000) | Acc: (87.00%) (1228/1408)
Epoch: 58 | Batch_idx: 20 |  Loss: (0.3559) |  Loss2: (0.0000) | Acc: (87.00%) (2360/2688)
Epoch: 58 | Batch_idx: 30 |  Loss: (0.3561) |  Loss2: (0.0000) | Acc: (87.00%) (3484/3968)
Epoch: 58 | Batch_idx: 40 |  Loss: (0.3615) |  Loss2: (0.0000) | Acc: (87.00%) (4605/5248)
Epoch: 58 | Batch_idx: 50 |  Loss: (0.3613) |  Loss2: (0.0000) | Acc: (87.00%) (5718/6528)
Epoch: 58 | Batch_idx: 60 |  Loss: (0.3606) |  Loss2: (0.0000) | Acc: (87.00%) (6836/7808)
Epoch: 58 | Batch_idx: 70 |  Loss: (0.3570) |  Loss2: (0.0000) | Acc: (87.00%) (7972/9088)
Epoch: 58 | Batch_idx: 80 |  Loss: (0.3537) |  Loss2: (0.0000) | Acc: (87.00%) (9101/10368)
Epoch: 58 | Batch_idx: 90 |  Loss: (0.3528) |  Loss2: (0.0000) | Acc: (87.00%) (10229/11648)
Epoch: 58 | Batch_idx: 100 |  Loss: (0.3527) |  Loss2: (0.0000) | Acc: (87.00%) (11365/12928)
Epoch: 58 | Batch_idx: 110 |  Loss: (0.3537) |  Loss2: (0.0000) | Acc: (87.00%) (12501/14208)
Epoch: 58 | Batch_idx: 120 |  Loss: (0.3502) |  Loss2: (0.0000) | Acc: (88.00%) (13637/15488)
Epoch: 58 | Batch_idx: 130 |  Loss: (0.3512) |  Loss2: (0.0000) | Acc: (88.00%) (14758/16768)
Epoch: 58 | Batch_idx: 140 |  Loss: (0.3503) |  Loss2: (0.0000) | Acc: (88.00%) (15901/18048)
Epoch: 58 | Batch_idx: 150 |  Loss: (0.3467) |  Loss2: (0.0000) | Acc: (88.00%) (17064/19328)
Epoch: 58 | Batch_idx: 160 |  Loss: (0.3458) |  Loss2: (0.0000) | Acc: (88.00%) (18201/20608)
Epoch: 58 | Batch_idx: 170 |  Loss: (0.3461) |  Loss2: (0.0000) | Acc: (88.00%) (19316/21888)
Epoch: 58 | Batch_idx: 180 |  Loss: (0.3458) |  Loss2: (0.0000) | Acc: (88.00%) (20447/23168)
Epoch: 58 | Batch_idx: 190 |  Loss: (0.3453) |  Loss2: (0.0000) | Acc: (88.00%) (21584/24448)
Epoch: 58 | Batch_idx: 200 |  Loss: (0.3449) |  Loss2: (0.0000) | Acc: (88.00%) (22712/25728)
Epoch: 58 | Batch_idx: 210 |  Loss: (0.3459) |  Loss2: (0.0000) | Acc: (88.00%) (23829/27008)
Epoch: 58 | Batch_idx: 220 |  Loss: (0.3446) |  Loss2: (0.0000) | Acc: (88.00%) (24970/28288)
Epoch: 58 | Batch_idx: 230 |  Loss: (0.3441) |  Loss2: (0.0000) | Acc: (88.00%) (26107/29568)
Epoch: 58 | Batch_idx: 240 |  Loss: (0.3440) |  Loss2: (0.0000) | Acc: (88.00%) (27235/30848)
Epoch: 58 | Batch_idx: 250 |  Loss: (0.3444) |  Loss2: (0.0000) | Acc: (88.00%) (28360/32128)
Epoch: 58 | Batch_idx: 260 |  Loss: (0.3440) |  Loss2: (0.0000) | Acc: (88.00%) (29486/33408)
Epoch: 58 | Batch_idx: 270 |  Loss: (0.3443) |  Loss2: (0.0000) | Acc: (88.00%) (30614/34688)
Epoch: 58 | Batch_idx: 280 |  Loss: (0.3432) |  Loss2: (0.0000) | Acc: (88.00%) (31753/35968)
Epoch: 58 | Batch_idx: 290 |  Loss: (0.3443) |  Loss2: (0.0000) | Acc: (88.00%) (32866/37248)
Epoch: 58 | Batch_idx: 300 |  Loss: (0.3435) |  Loss2: (0.0000) | Acc: (88.00%) (34013/38528)
Epoch: 58 | Batch_idx: 310 |  Loss: (0.3435) |  Loss2: (0.0000) | Acc: (88.00%) (35136/39808)
Epoch: 58 | Batch_idx: 320 |  Loss: (0.3432) |  Loss2: (0.0000) | Acc: (88.00%) (36265/41088)
Epoch: 58 | Batch_idx: 330 |  Loss: (0.3431) |  Loss2: (0.0000) | Acc: (88.00%) (37389/42368)
Epoch: 58 | Batch_idx: 340 |  Loss: (0.3428) |  Loss2: (0.0000) | Acc: (88.00%) (38535/43648)
Epoch: 58 | Batch_idx: 350 |  Loss: (0.3434) |  Loss2: (0.0000) | Acc: (88.00%) (39648/44928)
Epoch: 58 | Batch_idx: 360 |  Loss: (0.3434) |  Loss2: (0.0000) | Acc: (88.00%) (40785/46208)
Epoch: 58 | Batch_idx: 370 |  Loss: (0.3426) |  Loss2: (0.0000) | Acc: (88.00%) (41921/47488)
Epoch: 58 | Batch_idx: 380 |  Loss: (0.3430) |  Loss2: (0.0000) | Acc: (88.00%) (43041/48768)
Epoch: 58 | Batch_idx: 390 |  Loss: (0.3426) |  Loss2: (0.0000) | Acc: (88.00%) (44131/50000)
# TEST : Loss: (0.4291) | Acc: (85.00%) (8547/10000)
percent tensor([0.5767, 0.5732, 0.5849, 0.5763, 0.5880, 0.5758, 0.5809, 0.5751, 0.5769,
        0.5750, 0.5726, 0.5842, 0.5737, 0.5655, 0.5748, 0.5717],
       device='cuda:0') torch.Size([16])
percent tensor([0.5564, 0.5225, 0.5311, 0.5678, 0.5478, 0.5979, 0.5300, 0.5531, 0.5439,
        0.5237, 0.5345, 0.5231, 0.5271, 0.5566, 0.5548, 0.5583],
       device='cuda:0') torch.Size([16])
percent tensor([0.4610, 0.5003, 0.4595, 0.4367, 0.4681, 0.4250, 0.5057, 0.4769, 0.4781,
        0.4637, 0.4607, 0.4803, 0.4794, 0.4918, 0.4738, 0.4595],
       device='cuda:0') torch.Size([16])
percent tensor([0.6441, 0.6191, 0.6142, 0.6325, 0.6193, 0.6629, 0.6186, 0.6184, 0.6319,
        0.6337, 0.6381, 0.6215, 0.6379, 0.6426, 0.6289, 0.6573],
       device='cuda:0') torch.Size([16])
percent tensor([0.5889, 0.6586, 0.6475, 0.6485, 0.5809, 0.6391, 0.6134, 0.5473, 0.6875,
        0.5903, 0.6587, 0.6643, 0.7057, 0.7057, 0.5804, 0.6123],
       device='cuda:0') torch.Size([16])
percent tensor([0.6707, 0.6263, 0.7203, 0.7480, 0.7328, 0.7578, 0.6786, 0.6696, 0.7321,
        0.6444, 0.7100, 0.6637, 0.6326, 0.7853, 0.6207, 0.6972],
       device='cuda:0') torch.Size([16])
percent tensor([0.6597, 0.5966, 0.6925, 0.6353, 0.7444, 0.6929, 0.6499, 0.7187, 0.6253,
        0.6498, 0.5977, 0.5690, 0.5092, 0.5935, 0.6170, 0.7342],
       device='cuda:0') torch.Size([16])
percent tensor([0.9985, 0.9965, 0.9975, 0.9984, 0.9976, 0.9958, 0.9978, 0.9984, 0.9972,
        0.9983, 0.9975, 0.9979, 0.9977, 0.9987, 0.9976, 0.9988],
       device='cuda:0') torch.Size([16])
Epoch: 59 | Batch_idx: 0 |  Loss: (0.4044) |  Loss2: (0.0000) | Acc: (88.00%) (113/128)
Epoch: 59 | Batch_idx: 10 |  Loss: (0.3377) |  Loss2: (0.0000) | Acc: (88.00%) (1251/1408)
Epoch: 59 | Batch_idx: 20 |  Loss: (0.3261) |  Loss2: (0.0000) | Acc: (88.00%) (2391/2688)
Epoch: 59 | Batch_idx: 30 |  Loss: (0.3324) |  Loss2: (0.0000) | Acc: (88.00%) (3526/3968)
Epoch: 59 | Batch_idx: 40 |  Loss: (0.3292) |  Loss2: (0.0000) | Acc: (89.00%) (4671/5248)
Epoch: 59 | Batch_idx: 50 |  Loss: (0.3317) |  Loss2: (0.0000) | Acc: (88.00%) (5799/6528)
Epoch: 59 | Batch_idx: 60 |  Loss: (0.3344) |  Loss2: (0.0000) | Acc: (88.00%) (6945/7808)
Epoch: 59 | Batch_idx: 70 |  Loss: (0.3342) |  Loss2: (0.0000) | Acc: (88.00%) (8084/9088)
Epoch: 59 | Batch_idx: 80 |  Loss: (0.3337) |  Loss2: (0.0000) | Acc: (88.00%) (9220/10368)
Epoch: 59 | Batch_idx: 90 |  Loss: (0.3376) |  Loss2: (0.0000) | Acc: (88.00%) (10348/11648)
Epoch: 59 | Batch_idx: 100 |  Loss: (0.3373) |  Loss2: (0.0000) | Acc: (88.00%) (11488/12928)
Epoch: 59 | Batch_idx: 110 |  Loss: (0.3360) |  Loss2: (0.0000) | Acc: (88.00%) (12629/14208)
Epoch: 59 | Batch_idx: 120 |  Loss: (0.3366) |  Loss2: (0.0000) | Acc: (88.00%) (13762/15488)
Epoch: 59 | Batch_idx: 130 |  Loss: (0.3357) |  Loss2: (0.0000) | Acc: (88.00%) (14920/16768)
Epoch: 59 | Batch_idx: 140 |  Loss: (0.3359) |  Loss2: (0.0000) | Acc: (88.00%) (16044/18048)
Epoch: 59 | Batch_idx: 150 |  Loss: (0.3359) |  Loss2: (0.0000) | Acc: (88.00%) (17180/19328)
Epoch: 59 | Batch_idx: 160 |  Loss: (0.3365) |  Loss2: (0.0000) | Acc: (88.00%) (18315/20608)
Epoch: 59 | Batch_idx: 170 |  Loss: (0.3363) |  Loss2: (0.0000) | Acc: (88.00%) (19450/21888)
Epoch: 59 | Batch_idx: 180 |  Loss: (0.3387) |  Loss2: (0.0000) | Acc: (88.00%) (20559/23168)
Epoch: 59 | Batch_idx: 190 |  Loss: (0.3387) |  Loss2: (0.0000) | Acc: (88.00%) (21691/24448)
Epoch: 59 | Batch_idx: 200 |  Loss: (0.3386) |  Loss2: (0.0000) | Acc: (88.00%) (22814/25728)
Epoch: 59 | Batch_idx: 210 |  Loss: (0.3376) |  Loss2: (0.0000) | Acc: (88.00%) (23962/27008)
Epoch: 59 | Batch_idx: 220 |  Loss: (0.3373) |  Loss2: (0.0000) | Acc: (88.00%) (25096/28288)
Epoch: 59 | Batch_idx: 230 |  Loss: (0.3369) |  Loss2: (0.0000) | Acc: (88.00%) (26233/29568)
Epoch: 59 | Batch_idx: 240 |  Loss: (0.3359) |  Loss2: (0.0000) | Acc: (88.00%) (27372/30848)
Epoch: 59 | Batch_idx: 250 |  Loss: (0.3358) |  Loss2: (0.0000) | Acc: (88.00%) (28520/32128)
Epoch: 59 | Batch_idx: 260 |  Loss: (0.3375) |  Loss2: (0.0000) | Acc: (88.00%) (29626/33408)
Epoch: 59 | Batch_idx: 270 |  Loss: (0.3373) |  Loss2: (0.0000) | Acc: (88.00%) (30772/34688)
Epoch: 59 | Batch_idx: 280 |  Loss: (0.3385) |  Loss2: (0.0000) | Acc: (88.00%) (31888/35968)
Epoch: 59 | Batch_idx: 290 |  Loss: (0.3391) |  Loss2: (0.0000) | Acc: (88.00%) (33021/37248)
Epoch: 59 | Batch_idx: 300 |  Loss: (0.3385) |  Loss2: (0.0000) | Acc: (88.00%) (34166/38528)
Epoch: 59 | Batch_idx: 310 |  Loss: (0.3388) |  Loss2: (0.0000) | Acc: (88.00%) (35292/39808)
Epoch: 59 | Batch_idx: 320 |  Loss: (0.3394) |  Loss2: (0.0000) | Acc: (88.00%) (36425/41088)
Epoch: 59 | Batch_idx: 330 |  Loss: (0.3396) |  Loss2: (0.0000) | Acc: (88.00%) (37550/42368)
Epoch: 59 | Batch_idx: 340 |  Loss: (0.3395) |  Loss2: (0.0000) | Acc: (88.00%) (38687/43648)
Epoch: 59 | Batch_idx: 350 |  Loss: (0.3408) |  Loss2: (0.0000) | Acc: (88.00%) (39783/44928)
Epoch: 59 | Batch_idx: 360 |  Loss: (0.3405) |  Loss2: (0.0000) | Acc: (88.00%) (40914/46208)
Epoch: 59 | Batch_idx: 370 |  Loss: (0.3406) |  Loss2: (0.0000) | Acc: (88.00%) (42039/47488)
Epoch: 59 | Batch_idx: 380 |  Loss: (0.3405) |  Loss2: (0.0000) | Acc: (88.00%) (43171/48768)
Epoch: 59 | Batch_idx: 390 |  Loss: (0.3403) |  Loss2: (0.0000) | Acc: (88.00%) (44266/50000)
# TEST : Loss: (0.4260) | Acc: (85.00%) (8554/10000)
percent tensor([0.5805, 0.5767, 0.5882, 0.5796, 0.5916, 0.5784, 0.5846, 0.5789, 0.5809,
        0.5786, 0.5765, 0.5879, 0.5776, 0.5691, 0.5779, 0.5750],
       device='cuda:0') torch.Size([16])
percent tensor([0.5542, 0.5194, 0.5296, 0.5651, 0.5454, 0.5944, 0.5273, 0.5507, 0.5420,
        0.5212, 0.5324, 0.5209, 0.5248, 0.5540, 0.5513, 0.5553],
       device='cuda:0') torch.Size([16])
percent tensor([0.4614, 0.5001, 0.4603, 0.4398, 0.4689, 0.4271, 0.5055, 0.4790, 0.4787,
        0.4633, 0.4600, 0.4811, 0.4802, 0.4929, 0.4750, 0.4608],
       device='cuda:0') torch.Size([16])
percent tensor([0.6456, 0.6200, 0.6186, 0.6358, 0.6232, 0.6651, 0.6201, 0.6222, 0.6347,
        0.6351, 0.6392, 0.6239, 0.6387, 0.6445, 0.6297, 0.6591],
       device='cuda:0') torch.Size([16])
percent tensor([0.5832, 0.6550, 0.6476, 0.6483, 0.5842, 0.6383, 0.6076, 0.5506, 0.6842,
        0.5828, 0.6496, 0.6601, 0.7011, 0.6975, 0.5769, 0.6107],
       device='cuda:0') torch.Size([16])
percent tensor([0.6679, 0.6225, 0.7177, 0.7468, 0.7322, 0.7576, 0.6757, 0.6637, 0.7304,
        0.6411, 0.7076, 0.6591, 0.6292, 0.7843, 0.6145, 0.6958],
       device='cuda:0') torch.Size([16])
percent tensor([0.6529, 0.5922, 0.6901, 0.6321, 0.7445, 0.6841, 0.6448, 0.7177, 0.6197,
        0.6469, 0.5934, 0.5659, 0.5019, 0.5870, 0.6121, 0.7281],
       device='cuda:0') torch.Size([16])
percent tensor([0.9987, 0.9967, 0.9977, 0.9985, 0.9978, 0.9963, 0.9980, 0.9985, 0.9974,
        0.9984, 0.9977, 0.9980, 0.9979, 0.9988, 0.9977, 0.9989],
       device='cuda:0') torch.Size([16])
True Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=128, out_features=16, bias=False)
False Linear(in_features=16, out_features=2, bias=False)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=128, out_features=16, bias=False)
False Linear(in_features=16, out_features=2, bias=False)
True Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=256, out_features=32, bias=False)
False Linear(in_features=32, out_features=2, bias=False)
True Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=256, out_features=32, bias=False)
False Linear(in_features=32, out_features=2, bias=False)
True Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=512, out_features=64, bias=False)
False Linear(in_features=64, out_features=2, bias=False)
True Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=512, out_features=64, bias=False)
False Linear(in_features=64, out_features=2, bias=False)
True Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1024, out_features=128, bias=False)
False Linear(in_features=128, out_features=2, bias=False)
True Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1024, out_features=128, bias=False)
False Linear(in_features=128, out_features=2, bias=False)
True Linear(in_features=512, out_features=10, bias=True)
Epoch: 60 | Batch_idx: 0 |  Loss: (0.4113) |  Loss2: (0.0000) | Acc: (86.00%) (111/128)
Epoch: 60 | Batch_idx: 10 |  Loss: (0.3894) |  Loss2: (0.0000) | Acc: (87.00%) (1229/1408)
Epoch: 60 | Batch_idx: 20 |  Loss: (0.3649) |  Loss2: (0.0000) | Acc: (87.00%) (2360/2688)
Epoch: 60 | Batch_idx: 30 |  Loss: (0.3632) |  Loss2: (0.0000) | Acc: (87.00%) (3466/3968)
Epoch: 60 | Batch_idx: 40 |  Loss: (0.3625) |  Loss2: (0.0000) | Acc: (87.00%) (4592/5248)
Epoch: 60 | Batch_idx: 50 |  Loss: (0.3562) |  Loss2: (0.0000) | Acc: (87.00%) (5729/6528)
Epoch: 60 | Batch_idx: 60 |  Loss: (0.3527) |  Loss2: (0.0000) | Acc: (87.00%) (6860/7808)
Epoch: 60 | Batch_idx: 70 |  Loss: (0.3493) |  Loss2: (0.0000) | Acc: (87.00%) (7994/9088)
Epoch: 60 | Batch_idx: 80 |  Loss: (0.3468) |  Loss2: (0.0000) | Acc: (88.00%) (9136/10368)
Epoch: 60 | Batch_idx: 90 |  Loss: (0.3468) |  Loss2: (0.0000) | Acc: (88.00%) (10269/11648)
Epoch: 60 | Batch_idx: 100 |  Loss: (0.3505) |  Loss2: (0.0000) | Acc: (88.00%) (11389/12928)
Epoch: 60 | Batch_idx: 110 |  Loss: (0.3519) |  Loss2: (0.0000) | Acc: (88.00%) (12509/14208)
Epoch: 60 | Batch_idx: 120 |  Loss: (0.3530) |  Loss2: (0.0000) | Acc: (88.00%) (13631/15488)
Epoch: 60 | Batch_idx: 130 |  Loss: (0.3522) |  Loss2: (0.0000) | Acc: (88.00%) (14757/16768)
Epoch: 60 | Batch_idx: 140 |  Loss: (0.3521) |  Loss2: (0.0000) | Acc: (87.00%) (15880/18048)
Epoch: 60 | Batch_idx: 150 |  Loss: (0.3516) |  Loss2: (0.0000) | Acc: (87.00%) (16999/19328)
Epoch: 60 | Batch_idx: 160 |  Loss: (0.3486) |  Loss2: (0.0000) | Acc: (88.00%) (18143/20608)
Epoch: 60 | Batch_idx: 170 |  Loss: (0.3495) |  Loss2: (0.0000) | Acc: (88.00%) (19263/21888)
Epoch: 60 | Batch_idx: 180 |  Loss: (0.3516) |  Loss2: (0.0000) | Acc: (87.00%) (20382/23168)
Epoch: 60 | Batch_idx: 190 |  Loss: (0.3526) |  Loss2: (0.0000) | Acc: (87.00%) (21505/24448)
Epoch: 60 | Batch_idx: 200 |  Loss: (0.3533) |  Loss2: (0.0000) | Acc: (87.00%) (22628/25728)
Epoch: 60 | Batch_idx: 210 |  Loss: (0.3527) |  Loss2: (0.0000) | Acc: (87.00%) (23763/27008)
Epoch: 60 | Batch_idx: 220 |  Loss: (0.3524) |  Loss2: (0.0000) | Acc: (87.00%) (24889/28288)
Epoch: 60 | Batch_idx: 230 |  Loss: (0.3519) |  Loss2: (0.0000) | Acc: (87.00%) (26016/29568)
Epoch: 60 | Batch_idx: 240 |  Loss: (0.3525) |  Loss2: (0.0000) | Acc: (88.00%) (27150/30848)
Epoch: 60 | Batch_idx: 250 |  Loss: (0.3517) |  Loss2: (0.0000) | Acc: (88.00%) (28285/32128)
Epoch: 60 | Batch_idx: 260 |  Loss: (0.3516) |  Loss2: (0.0000) | Acc: (88.00%) (29412/33408)
Epoch: 60 | Batch_idx: 270 |  Loss: (0.3521) |  Loss2: (0.0000) | Acc: (87.00%) (30523/34688)
Epoch: 60 | Batch_idx: 280 |  Loss: (0.3523) |  Loss2: (0.0000) | Acc: (87.00%) (31627/35968)
Epoch: 60 | Batch_idx: 290 |  Loss: (0.3515) |  Loss2: (0.0000) | Acc: (87.00%) (32764/37248)
Epoch: 60 | Batch_idx: 300 |  Loss: (0.3518) |  Loss2: (0.0000) | Acc: (87.00%) (33886/38528)
Epoch: 60 | Batch_idx: 310 |  Loss: (0.3508) |  Loss2: (0.0000) | Acc: (87.00%) (35020/39808)
Epoch: 60 | Batch_idx: 320 |  Loss: (0.3506) |  Loss2: (0.0000) | Acc: (88.00%) (36158/41088)
Epoch: 60 | Batch_idx: 330 |  Loss: (0.3510) |  Loss2: (0.0000) | Acc: (87.00%) (37265/42368)
Epoch: 60 | Batch_idx: 340 |  Loss: (0.3516) |  Loss2: (0.0000) | Acc: (87.00%) (38380/43648)
Epoch: 60 | Batch_idx: 350 |  Loss: (0.3506) |  Loss2: (0.0000) | Acc: (87.00%) (39528/44928)
Epoch: 60 | Batch_idx: 360 |  Loss: (0.3503) |  Loss2: (0.0000) | Acc: (87.00%) (40662/46208)
Epoch: 60 | Batch_idx: 370 |  Loss: (0.3517) |  Loss2: (0.0000) | Acc: (87.00%) (41751/47488)
Epoch: 60 | Batch_idx: 380 |  Loss: (0.3518) |  Loss2: (0.0000) | Acc: (87.00%) (42859/48768)
Epoch: 60 | Batch_idx: 390 |  Loss: (0.3512) |  Loss2: (0.0000) | Acc: (87.00%) (43946/50000)
=> saving checkpoint 'drive/app/torch/save_Routing_Gate_2/checkpoint_060.pth.tar'
# TEST : Loss: (0.5016) | Acc: (83.00%) (8336/10000)
percent tensor([0.5825, 0.5772, 0.5899, 0.5801, 0.5930, 0.5813, 0.5853, 0.5809, 0.5831,
        0.5793, 0.5784, 0.5885, 0.5791, 0.5701, 0.5791, 0.5771],
       device='cuda:0') torch.Size([16])
percent tensor([0.5559, 0.5204, 0.5262, 0.5630, 0.5415, 0.5950, 0.5267, 0.5450, 0.5436,
        0.5220, 0.5331, 0.5195, 0.5260, 0.5601, 0.5518, 0.5580],
       device='cuda:0') torch.Size([16])
percent tensor([0.4548, 0.4975, 0.4615, 0.4308, 0.4704, 0.4163, 0.5047, 0.4724, 0.4710,
        0.4613, 0.4601, 0.4835, 0.4766, 0.4845, 0.4681, 0.4518],
       device='cuda:0') torch.Size([16])
percent tensor([0.6478, 0.6210, 0.6070, 0.6344, 0.6204, 0.6693, 0.6207, 0.6139, 0.6373,
        0.6381, 0.6428, 0.6145, 0.6425, 0.6445, 0.6302, 0.6646],
       device='cuda:0') torch.Size([16])
percent tensor([0.5749, 0.6480, 0.6230, 0.6259, 0.5765, 0.6454, 0.5885, 0.5386, 0.6723,
        0.5705, 0.6487, 0.6185, 0.7022, 0.6867, 0.5621, 0.6109],
       device='cuda:0') torch.Size([16])
percent tensor([0.6659, 0.6336, 0.7110, 0.7359, 0.7415, 0.7498, 0.6964, 0.6630, 0.7391,
        0.6612, 0.7100, 0.6430, 0.6407, 0.7953, 0.6127, 0.7056],
       device='cuda:0') torch.Size([16])
percent tensor([0.6572, 0.6020, 0.6840, 0.6631, 0.7695, 0.6671, 0.6784, 0.7321, 0.6393,
        0.6470, 0.5956, 0.6058, 0.4992, 0.6229, 0.6251, 0.7290],
       device='cuda:0') torch.Size([16])
percent tensor([0.9986, 0.9965, 0.9978, 0.9983, 0.9985, 0.9973, 0.9982, 0.9987, 0.9977,
        0.9987, 0.9981, 0.9990, 0.9979, 0.9982, 0.9977, 0.9988],
       device='cuda:0') torch.Size([16])
Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 3, 3, 3]) tensor(176.6271, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(803.0413, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(801.3957, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([128, 64, 3, 3]) tensor(1528.8395, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([128, 64, 1, 1]) tensor(501.5577, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([128, 128, 3, 3]) tensor(2205.6650, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([256, 128, 3, 3]) tensor(4292.8262, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([256, 128, 1, 1]) tensor(1417.0099, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([256, 256, 3, 3]) tensor(6115.9702, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([512, 256, 3, 3]) tensor(12020.0938, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([512, 256, 1, 1]) tensor(3997.4941, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([512, 512, 3, 3]) tensor(16907.9277, device='cuda:0', grad_fn=<NormBackward0>)
Epoch: 61 | Batch_idx: 0 |  Loss: (0.4503) |  Loss2: (0.0000) | Acc: (82.00%) (105/128)
Epoch: 61 | Batch_idx: 10 |  Loss: (0.3300) |  Loss2: (0.0000) | Acc: (88.00%) (1248/1408)
Epoch: 61 | Batch_idx: 20 |  Loss: (0.3257) |  Loss2: (0.0000) | Acc: (88.00%) (2390/2688)
Epoch: 61 | Batch_idx: 30 |  Loss: (0.3285) |  Loss2: (0.0000) | Acc: (88.00%) (3516/3968)
Epoch: 61 | Batch_idx: 40 |  Loss: (0.3289) |  Loss2: (0.0000) | Acc: (88.00%) (4645/5248)
Epoch: 61 | Batch_idx: 50 |  Loss: (0.3374) |  Loss2: (0.0000) | Acc: (88.00%) (5770/6528)
Epoch: 61 | Batch_idx: 60 |  Loss: (0.3394) |  Loss2: (0.0000) | Acc: (88.00%) (6901/7808)
Epoch: 61 | Batch_idx: 70 |  Loss: (0.3393) |  Loss2: (0.0000) | Acc: (88.00%) (8030/9088)
Epoch: 61 | Batch_idx: 80 |  Loss: (0.3426) |  Loss2: (0.0000) | Acc: (88.00%) (9158/10368)
Epoch: 61 | Batch_idx: 90 |  Loss: (0.3419) |  Loss2: (0.0000) | Acc: (88.00%) (10294/11648)
Epoch: 61 | Batch_idx: 100 |  Loss: (0.3395) |  Loss2: (0.0000) | Acc: (88.00%) (11445/12928)
Epoch: 61 | Batch_idx: 110 |  Loss: (0.3385) |  Loss2: (0.0000) | Acc: (88.00%) (12576/14208)
Epoch: 61 | Batch_idx: 120 |  Loss: (0.3366) |  Loss2: (0.0000) | Acc: (88.00%) (13716/15488)
Epoch: 61 | Batch_idx: 130 |  Loss: (0.3374) |  Loss2: (0.0000) | Acc: (88.00%) (14835/16768)
Epoch: 61 | Batch_idx: 140 |  Loss: (0.3388) |  Loss2: (0.0000) | Acc: (88.00%) (15961/18048)
Epoch: 61 | Batch_idx: 150 |  Loss: (0.3380) |  Loss2: (0.0000) | Acc: (88.00%) (17104/19328)
Epoch: 61 | Batch_idx: 160 |  Loss: (0.3384) |  Loss2: (0.0000) | Acc: (88.00%) (18232/20608)
Epoch: 61 | Batch_idx: 170 |  Loss: (0.3403) |  Loss2: (0.0000) | Acc: (88.00%) (19343/21888)
Epoch: 61 | Batch_idx: 180 |  Loss: (0.3401) |  Loss2: (0.0000) | Acc: (88.00%) (20473/23168)
Epoch: 61 | Batch_idx: 190 |  Loss: (0.3391) |  Loss2: (0.0000) | Acc: (88.00%) (21611/24448)
Epoch: 61 | Batch_idx: 200 |  Loss: (0.3386) |  Loss2: (0.0000) | Acc: (88.00%) (22743/25728)
Epoch: 61 | Batch_idx: 210 |  Loss: (0.3381) |  Loss2: (0.0000) | Acc: (88.00%) (23872/27008)
Epoch: 61 | Batch_idx: 220 |  Loss: (0.3393) |  Loss2: (0.0000) | Acc: (88.00%) (25005/28288)
Epoch: 61 | Batch_idx: 230 |  Loss: (0.3384) |  Loss2: (0.0000) | Acc: (88.00%) (26144/29568)
Epoch: 61 | Batch_idx: 240 |  Loss: (0.3403) |  Loss2: (0.0000) | Acc: (88.00%) (27261/30848)
Epoch: 61 | Batch_idx: 250 |  Loss: (0.3408) |  Loss2: (0.0000) | Acc: (88.00%) (28381/32128)
Epoch: 61 | Batch_idx: 260 |  Loss: (0.3390) |  Loss2: (0.0000) | Acc: (88.00%) (29530/33408)
Epoch: 61 | Batch_idx: 270 |  Loss: (0.3383) |  Loss2: (0.0000) | Acc: (88.00%) (30663/34688)
Epoch: 61 | Batch_idx: 280 |  Loss: (0.3380) |  Loss2: (0.0000) | Acc: (88.00%) (31802/35968)
Epoch: 61 | Batch_idx: 290 |  Loss: (0.3395) |  Loss2: (0.0000) | Acc: (88.00%) (32911/37248)
Epoch: 61 | Batch_idx: 300 |  Loss: (0.3397) |  Loss2: (0.0000) | Acc: (88.00%) (34035/38528)
Epoch: 61 | Batch_idx: 310 |  Loss: (0.3394) |  Loss2: (0.0000) | Acc: (88.00%) (35165/39808)
Epoch: 61 | Batch_idx: 320 |  Loss: (0.3391) |  Loss2: (0.0000) | Acc: (88.00%) (36301/41088)
Epoch: 61 | Batch_idx: 330 |  Loss: (0.3395) |  Loss2: (0.0000) | Acc: (88.00%) (37426/42368)
Epoch: 61 | Batch_idx: 340 |  Loss: (0.3398) |  Loss2: (0.0000) | Acc: (88.00%) (38557/43648)
Epoch: 61 | Batch_idx: 350 |  Loss: (0.3411) |  Loss2: (0.0000) | Acc: (88.00%) (39669/44928)
Epoch: 61 | Batch_idx: 360 |  Loss: (0.3412) |  Loss2: (0.0000) | Acc: (88.00%) (40804/46208)
Epoch: 61 | Batch_idx: 370 |  Loss: (0.3406) |  Loss2: (0.0000) | Acc: (88.00%) (41941/47488)
Epoch: 61 | Batch_idx: 380 |  Loss: (0.3403) |  Loss2: (0.0000) | Acc: (88.00%) (43067/48768)
Epoch: 61 | Batch_idx: 390 |  Loss: (0.3404) |  Loss2: (0.0000) | Acc: (88.00%) (44155/50000)
# TEST : Loss: (0.5070) | Acc: (83.00%) (8350/10000)
percent tensor([0.5810, 0.5770, 0.5885, 0.5794, 0.5923, 0.5794, 0.5845, 0.5797, 0.5817,
        0.5786, 0.5774, 0.5872, 0.5785, 0.5696, 0.5786, 0.5760],
       device='cuda:0') torch.Size([16])
percent tensor([0.5544, 0.5230, 0.5273, 0.5649, 0.5449, 0.5972, 0.5299, 0.5481, 0.5408,
        0.5218, 0.5318, 0.5222, 0.5226, 0.5637, 0.5545, 0.5566],
       device='cuda:0') torch.Size([16])
percent tensor([0.4617, 0.5022, 0.4617, 0.4352, 0.4687, 0.4199, 0.5054, 0.4750, 0.4785,
        0.4677, 0.4642, 0.4805, 0.4844, 0.4893, 0.4741, 0.4594],
       device='cuda:0') torch.Size([16])
percent tensor([0.6477, 0.6195, 0.6124, 0.6345, 0.6245, 0.6707, 0.6197, 0.6157, 0.6331,
        0.6384, 0.6384, 0.6189, 0.6397, 0.6436, 0.6278, 0.6643],
       device='cuda:0') torch.Size([16])
percent tensor([0.5976, 0.6598, 0.6465, 0.6436, 0.5884, 0.6500, 0.5971, 0.5488, 0.6886,
        0.5983, 0.6589, 0.6627, 0.7183, 0.6919, 0.5793, 0.6320],
       device='cuda:0') torch.Size([16])
percent tensor([0.6528, 0.6377, 0.7404, 0.7499, 0.7704, 0.7430, 0.6975, 0.6807, 0.7272,
        0.6490, 0.7036, 0.6899, 0.6186, 0.7888, 0.6254, 0.6986],
       device='cuda:0') torch.Size([16])
percent tensor([0.6565, 0.6112, 0.7010, 0.6692, 0.7728, 0.6869, 0.6858, 0.7202, 0.6297,
        0.6494, 0.6011, 0.6029, 0.4995, 0.6270, 0.6313, 0.7319],
       device='cuda:0') torch.Size([16])
percent tensor([0.9986, 0.9964, 0.9980, 0.9988, 0.9979, 0.9975, 0.9983, 0.9988, 0.9978,
        0.9985, 0.9979, 0.9987, 0.9977, 0.9984, 0.9977, 0.9990],
       device='cuda:0') torch.Size([16])
Epoch: 62 | Batch_idx: 0 |  Loss: (0.4032) |  Loss2: (0.0000) | Acc: (82.00%) (105/128)
Epoch: 62 | Batch_idx: 10 |  Loss: (0.3388) |  Loss2: (0.0000) | Acc: (87.00%) (1232/1408)
Epoch: 62 | Batch_idx: 20 |  Loss: (0.3355) |  Loss2: (0.0000) | Acc: (87.00%) (2362/2688)
Epoch: 62 | Batch_idx: 30 |  Loss: (0.3380) |  Loss2: (0.0000) | Acc: (87.00%) (3487/3968)
Epoch: 62 | Batch_idx: 40 |  Loss: (0.3351) |  Loss2: (0.0000) | Acc: (87.00%) (4609/5248)
Epoch: 62 | Batch_idx: 50 |  Loss: (0.3371) |  Loss2: (0.0000) | Acc: (87.00%) (5737/6528)
Epoch: 62 | Batch_idx: 60 |  Loss: (0.3345) |  Loss2: (0.0000) | Acc: (87.00%) (6871/7808)
Epoch: 62 | Batch_idx: 70 |  Loss: (0.3306) |  Loss2: (0.0000) | Acc: (88.00%) (8020/9088)
Epoch: 62 | Batch_idx: 80 |  Loss: (0.3292) |  Loss2: (0.0000) | Acc: (88.00%) (9162/10368)
Epoch: 62 | Batch_idx: 90 |  Loss: (0.3294) |  Loss2: (0.0000) | Acc: (88.00%) (10296/11648)
Epoch: 62 | Batch_idx: 100 |  Loss: (0.3284) |  Loss2: (0.0000) | Acc: (88.00%) (11431/12928)
Epoch: 62 | Batch_idx: 110 |  Loss: (0.3291) |  Loss2: (0.0000) | Acc: (88.00%) (12554/14208)
Epoch: 62 | Batch_idx: 120 |  Loss: (0.3306) |  Loss2: (0.0000) | Acc: (88.00%) (13686/15488)
Epoch: 62 | Batch_idx: 130 |  Loss: (0.3319) |  Loss2: (0.0000) | Acc: (88.00%) (14814/16768)
Epoch: 62 | Batch_idx: 140 |  Loss: (0.3319) |  Loss2: (0.0000) | Acc: (88.00%) (15952/18048)
Epoch: 62 | Batch_idx: 150 |  Loss: (0.3292) |  Loss2: (0.0000) | Acc: (88.00%) (17101/19328)
Epoch: 62 | Batch_idx: 160 |  Loss: (0.3303) |  Loss2: (0.0000) | Acc: (88.00%) (18224/20608)
Epoch: 62 | Batch_idx: 170 |  Loss: (0.3308) |  Loss2: (0.0000) | Acc: (88.00%) (19352/21888)
Epoch: 62 | Batch_idx: 180 |  Loss: (0.3312) |  Loss2: (0.0000) | Acc: (88.00%) (20477/23168)
Epoch: 62 | Batch_idx: 190 |  Loss: (0.3345) |  Loss2: (0.0000) | Acc: (88.00%) (21586/24448)
Epoch: 62 | Batch_idx: 200 |  Loss: (0.3354) |  Loss2: (0.0000) | Acc: (88.00%) (22708/25728)
Epoch: 62 | Batch_idx: 210 |  Loss: (0.3335) |  Loss2: (0.0000) | Acc: (88.00%) (23850/27008)
Epoch: 62 | Batch_idx: 220 |  Loss: (0.3316) |  Loss2: (0.0000) | Acc: (88.00%) (25011/28288)
Epoch: 62 | Batch_idx: 230 |  Loss: (0.3321) |  Loss2: (0.0000) | Acc: (88.00%) (26144/29568)
Epoch: 62 | Batch_idx: 240 |  Loss: (0.3341) |  Loss2: (0.0000) | Acc: (88.00%) (27256/30848)
Epoch: 62 | Batch_idx: 250 |  Loss: (0.3336) |  Loss2: (0.0000) | Acc: (88.00%) (28403/32128)
Epoch: 62 | Batch_idx: 260 |  Loss: (0.3346) |  Loss2: (0.0000) | Acc: (88.00%) (29512/33408)
Epoch: 62 | Batch_idx: 270 |  Loss: (0.3351) |  Loss2: (0.0000) | Acc: (88.00%) (30634/34688)
Epoch: 62 | Batch_idx: 280 |  Loss: (0.3345) |  Loss2: (0.0000) | Acc: (88.00%) (31768/35968)
Epoch: 62 | Batch_idx: 290 |  Loss: (0.3344) |  Loss2: (0.0000) | Acc: (88.00%) (32900/37248)
Epoch: 62 | Batch_idx: 300 |  Loss: (0.3353) |  Loss2: (0.0000) | Acc: (88.00%) (34009/38528)
Epoch: 62 | Batch_idx: 310 |  Loss: (0.3349) |  Loss2: (0.0000) | Acc: (88.00%) (35142/39808)
Epoch: 62 | Batch_idx: 320 |  Loss: (0.3355) |  Loss2: (0.0000) | Acc: (88.00%) (36253/41088)
Epoch: 62 | Batch_idx: 330 |  Loss: (0.3362) |  Loss2: (0.0000) | Acc: (88.00%) (37379/42368)
Epoch: 62 | Batch_idx: 340 |  Loss: (0.3360) |  Loss2: (0.0000) | Acc: (88.00%) (38510/43648)
Epoch: 62 | Batch_idx: 350 |  Loss: (0.3356) |  Loss2: (0.0000) | Acc: (88.00%) (39642/44928)
Epoch: 62 | Batch_idx: 360 |  Loss: (0.3356) |  Loss2: (0.0000) | Acc: (88.00%) (40767/46208)
Epoch: 62 | Batch_idx: 370 |  Loss: (0.3346) |  Loss2: (0.0000) | Acc: (88.00%) (41919/47488)
Epoch: 62 | Batch_idx: 380 |  Loss: (0.3341) |  Loss2: (0.0000) | Acc: (88.00%) (43056/48768)
Epoch: 62 | Batch_idx: 390 |  Loss: (0.3352) |  Loss2: (0.0000) | Acc: (88.00%) (44139/50000)
# TEST : Loss: (0.4616) | Acc: (84.00%) (8443/10000)
percent tensor([0.5808, 0.5765, 0.5892, 0.5801, 0.5925, 0.5788, 0.5846, 0.5806, 0.5812,
        0.5798, 0.5776, 0.5887, 0.5779, 0.5686, 0.5788, 0.5760],
       device='cuda:0') torch.Size([16])
percent tensor([0.5560, 0.5213, 0.5275, 0.5617, 0.5439, 0.5931, 0.5288, 0.5483, 0.5414,
        0.5238, 0.5334, 0.5210, 0.5249, 0.5582, 0.5523, 0.5571],
       device='cuda:0') torch.Size([16])
percent tensor([0.4619, 0.5054, 0.4667, 0.4456, 0.4758, 0.4264, 0.5122, 0.4806, 0.4786,
        0.4663, 0.4646, 0.4889, 0.4826, 0.4905, 0.4777, 0.4643],
       device='cuda:0') torch.Size([16])
percent tensor([0.6464, 0.6190, 0.6175, 0.6314, 0.6259, 0.6703, 0.6210, 0.6140, 0.6323,
        0.6378, 0.6372, 0.6209, 0.6394, 0.6399, 0.6298, 0.6603],
       device='cuda:0') torch.Size([16])
percent tensor([0.5767, 0.6570, 0.6227, 0.6416, 0.5617, 0.6450, 0.5815, 0.5332, 0.6825,
        0.5902, 0.6475, 0.6458, 0.7099, 0.6870, 0.5720, 0.6087],
       device='cuda:0') torch.Size([16])
percent tensor([0.6675, 0.6273, 0.7071, 0.7339, 0.7375, 0.7332, 0.6848, 0.6548, 0.7172,
        0.6579, 0.6969, 0.6574, 0.6251, 0.7790, 0.6250, 0.6843],
       device='cuda:0') torch.Size([16])
percent tensor([0.6545, 0.5802, 0.6933, 0.6599, 0.7448, 0.6799, 0.6563, 0.6988, 0.6029,
        0.6230, 0.5837, 0.5900, 0.4727, 0.6127, 0.6173, 0.7204],
       device='cuda:0') torch.Size([16])
percent tensor([0.9987, 0.9970, 0.9979, 0.9986, 0.9978, 0.9963, 0.9981, 0.9989, 0.9975,
        0.9981, 0.9978, 0.9987, 0.9972, 0.9982, 0.9976, 0.9987],
       device='cuda:0') torch.Size([16])
Epoch: 63 | Batch_idx: 0 |  Loss: (0.2790) |  Loss2: (0.0000) | Acc: (89.00%) (114/128)
Epoch: 63 | Batch_idx: 10 |  Loss: (0.3103) |  Loss2: (0.0000) | Acc: (88.00%) (1249/1408)
Epoch: 63 | Batch_idx: 20 |  Loss: (0.3158) |  Loss2: (0.0000) | Acc: (88.00%) (2383/2688)
Epoch: 63 | Batch_idx: 30 |  Loss: (0.3263) |  Loss2: (0.0000) | Acc: (88.00%) (3517/3968)
Epoch: 63 | Batch_idx: 40 |  Loss: (0.3187) |  Loss2: (0.0000) | Acc: (88.00%) (4663/5248)
Epoch: 63 | Batch_idx: 50 |  Loss: (0.3211) |  Loss2: (0.0000) | Acc: (88.00%) (5799/6528)
Epoch: 63 | Batch_idx: 60 |  Loss: (0.3222) |  Loss2: (0.0000) | Acc: (88.00%) (6943/7808)
Epoch: 63 | Batch_idx: 70 |  Loss: (0.3238) |  Loss2: (0.0000) | Acc: (88.00%) (8067/9088)
Epoch: 63 | Batch_idx: 80 |  Loss: (0.3221) |  Loss2: (0.0000) | Acc: (88.00%) (9205/10368)
Epoch: 63 | Batch_idx: 90 |  Loss: (0.3222) |  Loss2: (0.0000) | Acc: (88.00%) (10350/11648)
Epoch: 63 | Batch_idx: 100 |  Loss: (0.3239) |  Loss2: (0.0000) | Acc: (88.00%) (11481/12928)
Epoch: 63 | Batch_idx: 110 |  Loss: (0.3227) |  Loss2: (0.0000) | Acc: (88.00%) (12613/14208)
Epoch: 63 | Batch_idx: 120 |  Loss: (0.3227) |  Loss2: (0.0000) | Acc: (88.00%) (13751/15488)
Epoch: 63 | Batch_idx: 130 |  Loss: (0.3245) |  Loss2: (0.0000) | Acc: (88.00%) (14890/16768)
Epoch: 63 | Batch_idx: 140 |  Loss: (0.3204) |  Loss2: (0.0000) | Acc: (88.00%) (16060/18048)
Epoch: 63 | Batch_idx: 150 |  Loss: (0.3211) |  Loss2: (0.0000) | Acc: (88.00%) (17192/19328)
Epoch: 63 | Batch_idx: 160 |  Loss: (0.3211) |  Loss2: (0.0000) | Acc: (88.00%) (18330/20608)
Epoch: 63 | Batch_idx: 170 |  Loss: (0.3222) |  Loss2: (0.0000) | Acc: (88.00%) (19467/21888)
Epoch: 63 | Batch_idx: 180 |  Loss: (0.3229) |  Loss2: (0.0000) | Acc: (88.00%) (20601/23168)
Epoch: 63 | Batch_idx: 190 |  Loss: (0.3228) |  Loss2: (0.0000) | Acc: (88.00%) (21732/24448)
Epoch: 63 | Batch_idx: 200 |  Loss: (0.3237) |  Loss2: (0.0000) | Acc: (88.00%) (22861/25728)
Epoch: 63 | Batch_idx: 210 |  Loss: (0.3237) |  Loss2: (0.0000) | Acc: (88.00%) (23996/27008)
Epoch: 63 | Batch_idx: 220 |  Loss: (0.3239) |  Loss2: (0.0000) | Acc: (88.00%) (25125/28288)
Epoch: 63 | Batch_idx: 230 |  Loss: (0.3241) |  Loss2: (0.0000) | Acc: (88.00%) (26258/29568)
Epoch: 63 | Batch_idx: 240 |  Loss: (0.3241) |  Loss2: (0.0000) | Acc: (88.00%) (27400/30848)
Epoch: 63 | Batch_idx: 250 |  Loss: (0.3248) |  Loss2: (0.0000) | Acc: (88.00%) (28514/32128)
Epoch: 63 | Batch_idx: 260 |  Loss: (0.3257) |  Loss2: (0.0000) | Acc: (88.00%) (29642/33408)
Epoch: 63 | Batch_idx: 270 |  Loss: (0.3257) |  Loss2: (0.0000) | Acc: (88.00%) (30772/34688)
Epoch: 63 | Batch_idx: 280 |  Loss: (0.3270) |  Loss2: (0.0000) | Acc: (88.00%) (31891/35968)
Epoch: 63 | Batch_idx: 290 |  Loss: (0.3264) |  Loss2: (0.0000) | Acc: (88.00%) (33041/37248)
Epoch: 63 | Batch_idx: 300 |  Loss: (0.3264) |  Loss2: (0.0000) | Acc: (88.00%) (34183/38528)
Epoch: 63 | Batch_idx: 310 |  Loss: (0.3273) |  Loss2: (0.0000) | Acc: (88.00%) (35304/39808)
Epoch: 63 | Batch_idx: 320 |  Loss: (0.3276) |  Loss2: (0.0000) | Acc: (88.00%) (36437/41088)
Epoch: 63 | Batch_idx: 330 |  Loss: (0.3275) |  Loss2: (0.0000) | Acc: (88.00%) (37575/42368)
Epoch: 63 | Batch_idx: 340 |  Loss: (0.3274) |  Loss2: (0.0000) | Acc: (88.00%) (38704/43648)
Epoch: 63 | Batch_idx: 350 |  Loss: (0.3267) |  Loss2: (0.0000) | Acc: (88.00%) (39849/44928)
Epoch: 63 | Batch_idx: 360 |  Loss: (0.3269) |  Loss2: (0.0000) | Acc: (88.00%) (40989/46208)
Epoch: 63 | Batch_idx: 370 |  Loss: (0.3262) |  Loss2: (0.0000) | Acc: (88.00%) (42148/47488)
Epoch: 63 | Batch_idx: 380 |  Loss: (0.3265) |  Loss2: (0.0000) | Acc: (88.00%) (43284/48768)
Epoch: 63 | Batch_idx: 390 |  Loss: (0.3264) |  Loss2: (0.0000) | Acc: (88.00%) (44378/50000)
# TEST : Loss: (0.4748) | Acc: (84.00%) (8417/10000)
percent tensor([0.5814, 0.5775, 0.5867, 0.5799, 0.5913, 0.5793, 0.5842, 0.5798, 0.5824,
        0.5794, 0.5791, 0.5859, 0.5791, 0.5702, 0.5792, 0.5764],
       device='cuda:0') torch.Size([16])
percent tensor([0.5512, 0.5202, 0.5215, 0.5572, 0.5370, 0.5934, 0.5253, 0.5463, 0.5375,
        0.5196, 0.5288, 0.5147, 0.5196, 0.5589, 0.5513, 0.5552],
       device='cuda:0') torch.Size([16])
percent tensor([0.4599, 0.5031, 0.4633, 0.4429, 0.4680, 0.4191, 0.5063, 0.4793, 0.4734,
        0.4671, 0.4647, 0.4857, 0.4830, 0.4901, 0.4740, 0.4603],
       device='cuda:0') torch.Size([16])
percent tensor([0.6417, 0.6138, 0.6082, 0.6274, 0.6155, 0.6632, 0.6145, 0.6118, 0.6313,
        0.6310, 0.6341, 0.6151, 0.6372, 0.6363, 0.6251, 0.6591],
       device='cuda:0') torch.Size([16])
percent tensor([0.5957, 0.6570, 0.6407, 0.6323, 0.5870, 0.6730, 0.5893, 0.5271, 0.6902,
        0.5883, 0.6506, 0.6458, 0.7185, 0.6893, 0.5828, 0.6286],
       device='cuda:0') torch.Size([16])
percent tensor([0.6591, 0.6161, 0.7044, 0.7206, 0.7283, 0.7516, 0.6803, 0.6591, 0.7258,
        0.6337, 0.7045, 0.6419, 0.6277, 0.7871, 0.6227, 0.6930],
       device='cuda:0') torch.Size([16])
percent tensor([0.6245, 0.5700, 0.6681, 0.6350, 0.7393, 0.6576, 0.6350, 0.6907, 0.5772,
        0.6102, 0.5671, 0.5445, 0.4446, 0.5924, 0.5960, 0.7124],
       device='cuda:0') torch.Size([16])
percent tensor([0.9987, 0.9964, 0.9979, 0.9988, 0.9986, 0.9971, 0.9970, 0.9990, 0.9974,
        0.9979, 0.9972, 0.9983, 0.9972, 0.9983, 0.9976, 0.9989],
       device='cuda:0') torch.Size([16])
Epoch: 64 | Batch_idx: 0 |  Loss: (0.2492) |  Loss2: (0.0000) | Acc: (90.00%) (116/128)
Epoch: 64 | Batch_idx: 10 |  Loss: (0.3071) |  Loss2: (0.0000) | Acc: (89.00%) (1258/1408)
Epoch: 64 | Batch_idx: 20 |  Loss: (0.3126) |  Loss2: (0.0000) | Acc: (89.00%) (2413/2688)
Epoch: 64 | Batch_idx: 30 |  Loss: (0.3114) |  Loss2: (0.0000) | Acc: (89.00%) (3566/3968)
Epoch: 64 | Batch_idx: 40 |  Loss: (0.3121) |  Loss2: (0.0000) | Acc: (89.00%) (4702/5248)
Epoch: 64 | Batch_idx: 50 |  Loss: (0.3150) |  Loss2: (0.0000) | Acc: (89.00%) (5830/6528)
Epoch: 64 | Batch_idx: 60 |  Loss: (0.3162) |  Loss2: (0.0000) | Acc: (89.00%) (6966/7808)
Epoch: 64 | Batch_idx: 70 |  Loss: (0.3148) |  Loss2: (0.0000) | Acc: (89.00%) (8111/9088)
Epoch: 64 | Batch_idx: 80 |  Loss: (0.3100) |  Loss2: (0.0000) | Acc: (89.00%) (9274/10368)
Epoch: 64 | Batch_idx: 90 |  Loss: (0.3110) |  Loss2: (0.0000) | Acc: (89.00%) (10404/11648)
Epoch: 64 | Batch_idx: 100 |  Loss: (0.3137) |  Loss2: (0.0000) | Acc: (89.00%) (11547/12928)
Epoch: 64 | Batch_idx: 110 |  Loss: (0.3164) |  Loss2: (0.0000) | Acc: (89.00%) (12681/14208)
Epoch: 64 | Batch_idx: 120 |  Loss: (0.3155) |  Loss2: (0.0000) | Acc: (89.00%) (13831/15488)
Epoch: 64 | Batch_idx: 130 |  Loss: (0.3153) |  Loss2: (0.0000) | Acc: (89.00%) (14972/16768)
Epoch: 64 | Batch_idx: 140 |  Loss: (0.3141) |  Loss2: (0.0000) | Acc: (89.00%) (16117/18048)
Epoch: 64 | Batch_idx: 150 |  Loss: (0.3157) |  Loss2: (0.0000) | Acc: (89.00%) (17241/19328)
Epoch: 64 | Batch_idx: 160 |  Loss: (0.3159) |  Loss2: (0.0000) | Acc: (89.00%) (18375/20608)
Epoch: 64 | Batch_idx: 170 |  Loss: (0.3158) |  Loss2: (0.0000) | Acc: (89.00%) (19513/21888)
Epoch: 64 | Batch_idx: 180 |  Loss: (0.3161) |  Loss2: (0.0000) | Acc: (89.00%) (20646/23168)
Epoch: 64 | Batch_idx: 190 |  Loss: (0.3142) |  Loss2: (0.0000) | Acc: (89.00%) (21806/24448)
Epoch: 64 | Batch_idx: 200 |  Loss: (0.3125) |  Loss2: (0.0000) | Acc: (89.00%) (22965/25728)
Epoch: 64 | Batch_idx: 210 |  Loss: (0.3129) |  Loss2: (0.0000) | Acc: (89.00%) (24107/27008)
Epoch: 64 | Batch_idx: 220 |  Loss: (0.3128) |  Loss2: (0.0000) | Acc: (89.00%) (25244/28288)
Epoch: 64 | Batch_idx: 230 |  Loss: (0.3138) |  Loss2: (0.0000) | Acc: (89.00%) (26390/29568)
Epoch: 64 | Batch_idx: 240 |  Loss: (0.3149) |  Loss2: (0.0000) | Acc: (89.00%) (27525/30848)
Epoch: 64 | Batch_idx: 250 |  Loss: (0.3158) |  Loss2: (0.0000) | Acc: (89.00%) (28663/32128)
Epoch: 64 | Batch_idx: 260 |  Loss: (0.3162) |  Loss2: (0.0000) | Acc: (89.00%) (29792/33408)
Epoch: 64 | Batch_idx: 270 |  Loss: (0.3156) |  Loss2: (0.0000) | Acc: (89.00%) (30938/34688)
Epoch: 64 | Batch_idx: 280 |  Loss: (0.3161) |  Loss2: (0.0000) | Acc: (89.00%) (32079/35968)
Epoch: 64 | Batch_idx: 290 |  Loss: (0.3156) |  Loss2: (0.0000) | Acc: (89.00%) (33228/37248)
Epoch: 64 | Batch_idx: 300 |  Loss: (0.3163) |  Loss2: (0.0000) | Acc: (89.00%) (34357/38528)
Epoch: 64 | Batch_idx: 310 |  Loss: (0.3170) |  Loss2: (0.0000) | Acc: (89.00%) (35485/39808)
Epoch: 64 | Batch_idx: 320 |  Loss: (0.3178) |  Loss2: (0.0000) | Acc: (89.00%) (36609/41088)
Epoch: 64 | Batch_idx: 330 |  Loss: (0.3178) |  Loss2: (0.0000) | Acc: (89.00%) (37748/42368)
Epoch: 64 | Batch_idx: 340 |  Loss: (0.3172) |  Loss2: (0.0000) | Acc: (89.00%) (38892/43648)
Epoch: 64 | Batch_idx: 350 |  Loss: (0.3180) |  Loss2: (0.0000) | Acc: (89.00%) (40025/44928)
Epoch: 64 | Batch_idx: 360 |  Loss: (0.3185) |  Loss2: (0.0000) | Acc: (89.00%) (41155/46208)
Epoch: 64 | Batch_idx: 370 |  Loss: (0.3186) |  Loss2: (0.0000) | Acc: (89.00%) (42298/47488)
Epoch: 64 | Batch_idx: 380 |  Loss: (0.3186) |  Loss2: (0.0000) | Acc: (89.00%) (43439/48768)
Epoch: 64 | Batch_idx: 390 |  Loss: (0.3183) |  Loss2: (0.0000) | Acc: (89.00%) (44544/50000)
# TEST : Loss: (0.4397) | Acc: (85.00%) (8516/10000)
percent tensor([0.5819, 0.5768, 0.5874, 0.5787, 0.5912, 0.5799, 0.5841, 0.5795, 0.5814,
        0.5788, 0.5777, 0.5863, 0.5783, 0.5696, 0.5787, 0.5766],
       device='cuda:0') torch.Size([16])
percent tensor([0.5552, 0.5216, 0.5265, 0.5596, 0.5449, 0.5960, 0.5299, 0.5466, 0.5436,
        0.5222, 0.5350, 0.5206, 0.5252, 0.5600, 0.5522, 0.5572],
       device='cuda:0') torch.Size([16])
percent tensor([0.4661, 0.5042, 0.4625, 0.4382, 0.4684, 0.4225, 0.5092, 0.4778, 0.4787,
        0.4653, 0.4658, 0.4840, 0.4867, 0.4930, 0.4743, 0.4610],
       device='cuda:0') torch.Size([16])
percent tensor([0.6445, 0.6204, 0.6134, 0.6310, 0.6238, 0.6661, 0.6209, 0.6132, 0.6327,
        0.6365, 0.6385, 0.6249, 0.6409, 0.6407, 0.6285, 0.6626],
       device='cuda:0') torch.Size([16])
percent tensor([0.5804, 0.6461, 0.6248, 0.6355, 0.5833, 0.6495, 0.5845, 0.5290, 0.6792,
        0.5937, 0.6497, 0.6557, 0.7185, 0.6871, 0.5706, 0.6145],
       device='cuda:0') torch.Size([16])
percent tensor([0.6564, 0.6129, 0.7134, 0.7331, 0.7483, 0.7416, 0.6863, 0.6591, 0.7214,
        0.6361, 0.6943, 0.6620, 0.6282, 0.7803, 0.6191, 0.6865],
       device='cuda:0') torch.Size([16])
percent tensor([0.6425, 0.5891, 0.6940, 0.6384, 0.7473, 0.6606, 0.6663, 0.7041, 0.5990,
        0.6287, 0.5878, 0.5751, 0.4803, 0.6016, 0.6009, 0.7132],
       device='cuda:0') torch.Size([16])
percent tensor([0.9985, 0.9963, 0.9967, 0.9981, 0.9966, 0.9959, 0.9977, 0.9983, 0.9977,
        0.9986, 0.9980, 0.9984, 0.9976, 0.9982, 0.9975, 0.9987],
       device='cuda:0') torch.Size([16])
False Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=128, out_features=16, bias=False)
True Linear(in_features=16, out_features=2, bias=False)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=128, out_features=16, bias=False)
True Linear(in_features=16, out_features=2, bias=False)
False Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=256, out_features=32, bias=False)
True Linear(in_features=32, out_features=2, bias=False)
False Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=256, out_features=32, bias=False)
True Linear(in_features=32, out_features=2, bias=False)
False Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=512, out_features=64, bias=False)
True Linear(in_features=64, out_features=2, bias=False)
False Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=512, out_features=64, bias=False)
True Linear(in_features=64, out_features=2, bias=False)
False Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1024, out_features=128, bias=False)
True Linear(in_features=128, out_features=2, bias=False)
False Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1024, out_features=128, bias=False)
True Linear(in_features=128, out_features=2, bias=False)
False Linear(in_features=512, out_features=10, bias=True)
Epoch: 65 | Batch_idx: 0 |  Loss: (0.2236) |  Loss2: (0.0000) | Acc: (91.00%) (117/128)
Epoch: 65 | Batch_idx: 10 |  Loss: (0.3461) |  Loss2: (0.0000) | Acc: (88.00%) (1247/1408)
Epoch: 65 | Batch_idx: 20 |  Loss: (0.3709) |  Loss2: (0.0000) | Acc: (87.00%) (2352/2688)
Epoch: 65 | Batch_idx: 30 |  Loss: (0.3686) |  Loss2: (0.0000) | Acc: (87.00%) (3462/3968)
Epoch: 65 | Batch_idx: 40 |  Loss: (0.3793) |  Loss2: (0.0000) | Acc: (86.00%) (4558/5248)
Epoch: 65 | Batch_idx: 50 |  Loss: (0.3830) |  Loss2: (0.0000) | Acc: (86.00%) (5651/6528)
Epoch: 65 | Batch_idx: 60 |  Loss: (0.3850) |  Loss2: (0.0000) | Acc: (86.00%) (6763/7808)
Epoch: 65 | Batch_idx: 70 |  Loss: (0.3816) |  Loss2: (0.0000) | Acc: (86.00%) (7896/9088)
Epoch: 65 | Batch_idx: 80 |  Loss: (0.3818) |  Loss2: (0.0000) | Acc: (86.00%) (9013/10368)
Epoch: 65 | Batch_idx: 90 |  Loss: (0.3838) |  Loss2: (0.0000) | Acc: (86.00%) (10111/11648)
Epoch: 65 | Batch_idx: 100 |  Loss: (0.3807) |  Loss2: (0.0000) | Acc: (86.00%) (11225/12928)
Epoch: 65 | Batch_idx: 110 |  Loss: (0.3802) |  Loss2: (0.0000) | Acc: (86.00%) (12332/14208)
Epoch: 65 | Batch_idx: 120 |  Loss: (0.3797) |  Loss2: (0.0000) | Acc: (86.00%) (13444/15488)
Epoch: 65 | Batch_idx: 130 |  Loss: (0.3783) |  Loss2: (0.0000) | Acc: (86.00%) (14557/16768)
Epoch: 65 | Batch_idx: 140 |  Loss: (0.3773) |  Loss2: (0.0000) | Acc: (86.00%) (15672/18048)
Epoch: 65 | Batch_idx: 150 |  Loss: (0.3770) |  Loss2: (0.0000) | Acc: (86.00%) (16784/19328)
Epoch: 65 | Batch_idx: 160 |  Loss: (0.3779) |  Loss2: (0.0000) | Acc: (86.00%) (17885/20608)
Epoch: 65 | Batch_idx: 170 |  Loss: (0.3794) |  Loss2: (0.0000) | Acc: (86.00%) (18976/21888)
Epoch: 65 | Batch_idx: 180 |  Loss: (0.3770) |  Loss2: (0.0000) | Acc: (86.00%) (20106/23168)
Epoch: 65 | Batch_idx: 190 |  Loss: (0.3756) |  Loss2: (0.0000) | Acc: (86.00%) (21233/24448)
Epoch: 65 | Batch_idx: 200 |  Loss: (0.3748) |  Loss2: (0.0000) | Acc: (86.00%) (22353/25728)
Epoch: 65 | Batch_idx: 210 |  Loss: (0.3743) |  Loss2: (0.0000) | Acc: (86.00%) (23492/27008)
Epoch: 65 | Batch_idx: 220 |  Loss: (0.3733) |  Loss2: (0.0000) | Acc: (87.00%) (24626/28288)
Epoch: 65 | Batch_idx: 230 |  Loss: (0.3722) |  Loss2: (0.0000) | Acc: (87.00%) (25754/29568)
Epoch: 65 | Batch_idx: 240 |  Loss: (0.3711) |  Loss2: (0.0000) | Acc: (87.00%) (26879/30848)
Epoch: 65 | Batch_idx: 250 |  Loss: (0.3719) |  Loss2: (0.0000) | Acc: (87.00%) (27985/32128)
Epoch: 65 | Batch_idx: 260 |  Loss: (0.3724) |  Loss2: (0.0000) | Acc: (87.00%) (29095/33408)
Epoch: 65 | Batch_idx: 270 |  Loss: (0.3718) |  Loss2: (0.0000) | Acc: (87.00%) (30222/34688)
Epoch: 65 | Batch_idx: 280 |  Loss: (0.3704) |  Loss2: (0.0000) | Acc: (87.00%) (31346/35968)
Epoch: 65 | Batch_idx: 290 |  Loss: (0.3685) |  Loss2: (0.0000) | Acc: (87.00%) (32483/37248)
Epoch: 65 | Batch_idx: 300 |  Loss: (0.3690) |  Loss2: (0.0000) | Acc: (87.00%) (33592/38528)
Epoch: 65 | Batch_idx: 310 |  Loss: (0.3688) |  Loss2: (0.0000) | Acc: (87.00%) (34705/39808)
Epoch: 65 | Batch_idx: 320 |  Loss: (0.3679) |  Loss2: (0.0000) | Acc: (87.00%) (35827/41088)
Epoch: 65 | Batch_idx: 330 |  Loss: (0.3677) |  Loss2: (0.0000) | Acc: (87.00%) (36948/42368)
Epoch: 65 | Batch_idx: 340 |  Loss: (0.3678) |  Loss2: (0.0000) | Acc: (87.00%) (38067/43648)
Epoch: 65 | Batch_idx: 350 |  Loss: (0.3676) |  Loss2: (0.0000) | Acc: (87.00%) (39188/44928)
Epoch: 65 | Batch_idx: 360 |  Loss: (0.3664) |  Loss2: (0.0000) | Acc: (87.00%) (40318/46208)
Epoch: 65 | Batch_idx: 370 |  Loss: (0.3659) |  Loss2: (0.0000) | Acc: (87.00%) (41443/47488)
Epoch: 65 | Batch_idx: 380 |  Loss: (0.3649) |  Loss2: (0.0000) | Acc: (87.00%) (42570/48768)
Epoch: 65 | Batch_idx: 390 |  Loss: (0.3652) |  Loss2: (0.0000) | Acc: (87.00%) (43648/50000)
=> saving checkpoint 'drive/app/torch/save_Routing_Gate_2/checkpoint_065.pth.tar'
# TEST : Loss: (0.4551) | Acc: (84.00%) (8470/10000)
percent tensor([0.5726, 0.5681, 0.5779, 0.5692, 0.5809, 0.5704, 0.5743, 0.5704, 0.5725,
        0.5699, 0.5700, 0.5763, 0.5699, 0.5617, 0.5693, 0.5681],
       device='cuda:0') torch.Size([16])
percent tensor([0.5612, 0.5333, 0.5359, 0.5687, 0.5543, 0.5993, 0.5415, 0.5548, 0.5487,
        0.5339, 0.5423, 0.5334, 0.5343, 0.5667, 0.5609, 0.5652],
       device='cuda:0') torch.Size([16])
percent tensor([0.4987, 0.5261, 0.4912, 0.4598, 0.4950, 0.4478, 0.5339, 0.5050, 0.5090,
        0.4920, 0.4983, 0.5100, 0.5171, 0.5159, 0.4973, 0.4881],
       device='cuda:0') torch.Size([16])
percent tensor([0.5990, 0.5793, 0.5675, 0.5877, 0.5780, 0.6156, 0.5770, 0.5707, 0.5872,
        0.5900, 0.5913, 0.5790, 0.5970, 0.5970, 0.5846, 0.6156],
       device='cuda:0') torch.Size([16])
percent tensor([0.5970, 0.6509, 0.6335, 0.6472, 0.5954, 0.6494, 0.5979, 0.5249, 0.6971,
        0.5973, 0.6721, 0.6627, 0.7254, 0.7051, 0.5728, 0.6156],
       device='cuda:0') torch.Size([16])
percent tensor([0.7044, 0.6662, 0.7542, 0.7737, 0.7822, 0.7808, 0.7259, 0.6958, 0.7533,
        0.6807, 0.7349, 0.7190, 0.6945, 0.8145, 0.6724, 0.7401],
       device='cuda:0') torch.Size([16])
percent tensor([0.5545, 0.5177, 0.6637, 0.6032, 0.7292, 0.5732, 0.6110, 0.6841, 0.5249,
        0.5700, 0.5177, 0.5375, 0.3789, 0.5545, 0.5633, 0.6376],
       device='cuda:0') torch.Size([16])
percent tensor([0.9988, 0.9967, 0.9975, 0.9985, 0.9974, 0.9958, 0.9983, 0.9987, 0.9980,
        0.9987, 0.9982, 0.9987, 0.9975, 0.9983, 0.9983, 0.9990],
       device='cuda:0') torch.Size([16])
Epoch: 66 | Batch_idx: 0 |  Loss: (0.3131) |  Loss2: (0.0000) | Acc: (89.00%) (114/128)
Epoch: 66 | Batch_idx: 10 |  Loss: (0.3325) |  Loss2: (0.0000) | Acc: (88.00%) (1242/1408)
Epoch: 66 | Batch_idx: 20 |  Loss: (0.3443) |  Loss2: (0.0000) | Acc: (87.00%) (2365/2688)
Epoch: 66 | Batch_idx: 30 |  Loss: (0.3393) |  Loss2: (0.0000) | Acc: (88.00%) (3500/3968)
Epoch: 66 | Batch_idx: 40 |  Loss: (0.3367) |  Loss2: (0.0000) | Acc: (88.00%) (4635/5248)
Epoch: 66 | Batch_idx: 50 |  Loss: (0.3399) |  Loss2: (0.0000) | Acc: (87.00%) (5741/6528)
Epoch: 66 | Batch_idx: 60 |  Loss: (0.3390) |  Loss2: (0.0000) | Acc: (88.00%) (6877/7808)
Epoch: 66 | Batch_idx: 70 |  Loss: (0.3386) |  Loss2: (0.0000) | Acc: (88.00%) (8008/9088)
Epoch: 66 | Batch_idx: 80 |  Loss: (0.3365) |  Loss2: (0.0000) | Acc: (88.00%) (9149/10368)
Epoch: 66 | Batch_idx: 90 |  Loss: (0.3371) |  Loss2: (0.0000) | Acc: (88.00%) (10290/11648)
Epoch: 66 | Batch_idx: 100 |  Loss: (0.3334) |  Loss2: (0.0000) | Acc: (88.00%) (11446/12928)
Epoch: 66 | Batch_idx: 110 |  Loss: (0.3330) |  Loss2: (0.0000) | Acc: (88.00%) (12577/14208)
Epoch: 66 | Batch_idx: 120 |  Loss: (0.3350) |  Loss2: (0.0000) | Acc: (88.00%) (13699/15488)
Epoch: 66 | Batch_idx: 130 |  Loss: (0.3359) |  Loss2: (0.0000) | Acc: (88.00%) (14821/16768)
Epoch: 66 | Batch_idx: 140 |  Loss: (0.3348) |  Loss2: (0.0000) | Acc: (88.00%) (15958/18048)
Epoch: 66 | Batch_idx: 150 |  Loss: (0.3345) |  Loss2: (0.0000) | Acc: (88.00%) (17086/19328)
Epoch: 66 | Batch_idx: 160 |  Loss: (0.3332) |  Loss2: (0.0000) | Acc: (88.00%) (18230/20608)
Epoch: 66 | Batch_idx: 170 |  Loss: (0.3350) |  Loss2: (0.0000) | Acc: (88.00%) (19362/21888)
Epoch: 66 | Batch_idx: 180 |  Loss: (0.3344) |  Loss2: (0.0000) | Acc: (88.00%) (20495/23168)
Epoch: 66 | Batch_idx: 190 |  Loss: (0.3338) |  Loss2: (0.0000) | Acc: (88.00%) (21633/24448)
Epoch: 66 | Batch_idx: 200 |  Loss: (0.3331) |  Loss2: (0.0000) | Acc: (88.00%) (22771/25728)
Epoch: 66 | Batch_idx: 210 |  Loss: (0.3339) |  Loss2: (0.0000) | Acc: (88.00%) (23898/27008)
Epoch: 66 | Batch_idx: 220 |  Loss: (0.3342) |  Loss2: (0.0000) | Acc: (88.00%) (25027/28288)
Epoch: 66 | Batch_idx: 230 |  Loss: (0.3340) |  Loss2: (0.0000) | Acc: (88.00%) (26160/29568)
Epoch: 66 | Batch_idx: 240 |  Loss: (0.3339) |  Loss2: (0.0000) | Acc: (88.00%) (27278/30848)
Epoch: 66 | Batch_idx: 250 |  Loss: (0.3351) |  Loss2: (0.0000) | Acc: (88.00%) (28410/32128)
Epoch: 66 | Batch_idx: 260 |  Loss: (0.3353) |  Loss2: (0.0000) | Acc: (88.00%) (29536/33408)
Epoch: 66 | Batch_idx: 270 |  Loss: (0.3341) |  Loss2: (0.0000) | Acc: (88.00%) (30685/34688)
Epoch: 66 | Batch_idx: 280 |  Loss: (0.3334) |  Loss2: (0.0000) | Acc: (88.00%) (31824/35968)
Epoch: 66 | Batch_idx: 290 |  Loss: (0.3334) |  Loss2: (0.0000) | Acc: (88.00%) (32963/37248)
Epoch: 66 | Batch_idx: 300 |  Loss: (0.3327) |  Loss2: (0.0000) | Acc: (88.00%) (34101/38528)
Epoch: 66 | Batch_idx: 310 |  Loss: (0.3322) |  Loss2: (0.0000) | Acc: (88.00%) (35242/39808)
Epoch: 66 | Batch_idx: 320 |  Loss: (0.3322) |  Loss2: (0.0000) | Acc: (88.00%) (36374/41088)
Epoch: 66 | Batch_idx: 330 |  Loss: (0.3318) |  Loss2: (0.0000) | Acc: (88.00%) (37509/42368)
Epoch: 66 | Batch_idx: 340 |  Loss: (0.3311) |  Loss2: (0.0000) | Acc: (88.00%) (38645/43648)
Epoch: 66 | Batch_idx: 350 |  Loss: (0.3312) |  Loss2: (0.0000) | Acc: (88.00%) (39775/44928)
Epoch: 66 | Batch_idx: 360 |  Loss: (0.3305) |  Loss2: (0.0000) | Acc: (88.00%) (40922/46208)
Epoch: 66 | Batch_idx: 370 |  Loss: (0.3300) |  Loss2: (0.0000) | Acc: (88.00%) (42067/47488)
Epoch: 66 | Batch_idx: 380 |  Loss: (0.3305) |  Loss2: (0.0000) | Acc: (88.00%) (43204/48768)
Epoch: 66 | Batch_idx: 390 |  Loss: (0.3302) |  Loss2: (0.0000) | Acc: (88.00%) (44304/50000)
# TEST : Loss: (0.4336) | Acc: (85.00%) (8557/10000)
percent tensor([0.5787, 0.5754, 0.5851, 0.5753, 0.5885, 0.5757, 0.5818, 0.5776, 0.5794,
        0.5771, 0.5765, 0.5838, 0.5763, 0.5683, 0.5757, 0.5742],
       device='cuda:0') torch.Size([16])
percent tensor([0.5546, 0.5279, 0.5299, 0.5609, 0.5474, 0.5902, 0.5357, 0.5486, 0.5425,
        0.5282, 0.5358, 0.5275, 0.5288, 0.5605, 0.5533, 0.5584],
       device='cuda:0') torch.Size([16])
percent tensor([0.5079, 0.5306, 0.4961, 0.4672, 0.5009, 0.4574, 0.5392, 0.5093, 0.5150,
        0.4980, 0.5074, 0.5144, 0.5234, 0.5227, 0.5037, 0.4979],
       device='cuda:0') torch.Size([16])
percent tensor([0.6031, 0.5825, 0.5732, 0.5917, 0.5838, 0.6163, 0.5833, 0.5776, 0.5913,
        0.5930, 0.5948, 0.5834, 0.6000, 0.6000, 0.5896, 0.6172],
       device='cuda:0') torch.Size([16])
percent tensor([0.5938, 0.6507, 0.6318, 0.6533, 0.5962, 0.6424, 0.6022, 0.5180, 0.7057,
        0.5980, 0.6862, 0.6658, 0.7221, 0.7184, 0.5726, 0.6092],
       device='cuda:0') torch.Size([16])
percent tensor([0.7021, 0.6637, 0.7467, 0.7681, 0.7751, 0.7781, 0.7199, 0.6847, 0.7545,
        0.6804, 0.7356, 0.7179, 0.7013, 0.8155, 0.6685, 0.7370],
       device='cuda:0') torch.Size([16])
percent tensor([0.5820, 0.5448, 0.6824, 0.6235, 0.7370, 0.5791, 0.6384, 0.7081, 0.5589,
        0.5931, 0.5460, 0.5727, 0.4082, 0.5889, 0.5953, 0.6530],
       device='cuda:0') torch.Size([16])
percent tensor([0.9988, 0.9968, 0.9977, 0.9986, 0.9976, 0.9959, 0.9984, 0.9987, 0.9981,
        0.9987, 0.9983, 0.9988, 0.9976, 0.9983, 0.9982, 0.9989],
       device='cuda:0') torch.Size([16])
Epoch: 67 | Batch_idx: 0 |  Loss: (0.3780) |  Loss2: (0.0000) | Acc: (89.00%) (114/128)
Epoch: 67 | Batch_idx: 10 |  Loss: (0.3324) |  Loss2: (0.0000) | Acc: (89.00%) (1255/1408)
Epoch: 67 | Batch_idx: 20 |  Loss: (0.3293) |  Loss2: (0.0000) | Acc: (89.00%) (2397/2688)
Epoch: 67 | Batch_idx: 30 |  Loss: (0.3269) |  Loss2: (0.0000) | Acc: (89.00%) (3539/3968)
Epoch: 67 | Batch_idx: 40 |  Loss: (0.3215) |  Loss2: (0.0000) | Acc: (89.00%) (4679/5248)
Epoch: 67 | Batch_idx: 50 |  Loss: (0.3198) |  Loss2: (0.0000) | Acc: (89.00%) (5820/6528)
Epoch: 67 | Batch_idx: 60 |  Loss: (0.3170) |  Loss2: (0.0000) | Acc: (89.00%) (6958/7808)
Epoch: 67 | Batch_idx: 70 |  Loss: (0.3145) |  Loss2: (0.0000) | Acc: (89.00%) (8102/9088)
Epoch: 67 | Batch_idx: 80 |  Loss: (0.3130) |  Loss2: (0.0000) | Acc: (89.00%) (9253/10368)
Epoch: 67 | Batch_idx: 90 |  Loss: (0.3166) |  Loss2: (0.0000) | Acc: (89.00%) (10373/11648)
Epoch: 67 | Batch_idx: 100 |  Loss: (0.3142) |  Loss2: (0.0000) | Acc: (89.00%) (11526/12928)
Epoch: 67 | Batch_idx: 110 |  Loss: (0.3160) |  Loss2: (0.0000) | Acc: (89.00%) (12658/14208)
Epoch: 67 | Batch_idx: 120 |  Loss: (0.3171) |  Loss2: (0.0000) | Acc: (89.00%) (13796/15488)
Epoch: 67 | Batch_idx: 130 |  Loss: (0.3183) |  Loss2: (0.0000) | Acc: (89.00%) (14935/16768)
Epoch: 67 | Batch_idx: 140 |  Loss: (0.3182) |  Loss2: (0.0000) | Acc: (89.00%) (16068/18048)
Epoch: 67 | Batch_idx: 150 |  Loss: (0.3187) |  Loss2: (0.0000) | Acc: (89.00%) (17205/19328)
Epoch: 67 | Batch_idx: 160 |  Loss: (0.3192) |  Loss2: (0.0000) | Acc: (89.00%) (18348/20608)
Epoch: 67 | Batch_idx: 170 |  Loss: (0.3178) |  Loss2: (0.0000) | Acc: (89.00%) (19499/21888)
Epoch: 67 | Batch_idx: 180 |  Loss: (0.3189) |  Loss2: (0.0000) | Acc: (89.00%) (20621/23168)
Epoch: 67 | Batch_idx: 190 |  Loss: (0.3192) |  Loss2: (0.0000) | Acc: (88.00%) (21735/24448)
Epoch: 67 | Batch_idx: 200 |  Loss: (0.3191) |  Loss2: (0.0000) | Acc: (88.00%) (22879/25728)
Epoch: 67 | Batch_idx: 210 |  Loss: (0.3202) |  Loss2: (0.0000) | Acc: (88.00%) (24011/27008)
Epoch: 67 | Batch_idx: 220 |  Loss: (0.3195) |  Loss2: (0.0000) | Acc: (88.00%) (25146/28288)
Epoch: 67 | Batch_idx: 230 |  Loss: (0.3202) |  Loss2: (0.0000) | Acc: (88.00%) (26296/29568)
Epoch: 67 | Batch_idx: 240 |  Loss: (0.3211) |  Loss2: (0.0000) | Acc: (88.00%) (27428/30848)
Epoch: 67 | Batch_idx: 250 |  Loss: (0.3225) |  Loss2: (0.0000) | Acc: (88.00%) (28539/32128)
Epoch: 67 | Batch_idx: 260 |  Loss: (0.3222) |  Loss2: (0.0000) | Acc: (88.00%) (29682/33408)
Epoch: 67 | Batch_idx: 270 |  Loss: (0.3226) |  Loss2: (0.0000) | Acc: (88.00%) (30815/34688)
Epoch: 67 | Batch_idx: 280 |  Loss: (0.3231) |  Loss2: (0.0000) | Acc: (88.00%) (31946/35968)
Epoch: 67 | Batch_idx: 290 |  Loss: (0.3225) |  Loss2: (0.0000) | Acc: (88.00%) (33088/37248)
Epoch: 67 | Batch_idx: 300 |  Loss: (0.3225) |  Loss2: (0.0000) | Acc: (88.00%) (34226/38528)
Epoch: 67 | Batch_idx: 310 |  Loss: (0.3226) |  Loss2: (0.0000) | Acc: (88.00%) (35351/39808)
Epoch: 67 | Batch_idx: 320 |  Loss: (0.3215) |  Loss2: (0.0000) | Acc: (88.00%) (36503/41088)
Epoch: 67 | Batch_idx: 330 |  Loss: (0.3207) |  Loss2: (0.0000) | Acc: (88.00%) (37651/42368)
Epoch: 67 | Batch_idx: 340 |  Loss: (0.3201) |  Loss2: (0.0000) | Acc: (88.00%) (38796/43648)
Epoch: 67 | Batch_idx: 350 |  Loss: (0.3194) |  Loss2: (0.0000) | Acc: (88.00%) (39938/44928)
Epoch: 67 | Batch_idx: 360 |  Loss: (0.3190) |  Loss2: (0.0000) | Acc: (88.00%) (41090/46208)
Epoch: 67 | Batch_idx: 370 |  Loss: (0.3188) |  Loss2: (0.0000) | Acc: (88.00%) (42232/47488)
Epoch: 67 | Batch_idx: 380 |  Loss: (0.3180) |  Loss2: (0.0000) | Acc: (88.00%) (43380/48768)
Epoch: 67 | Batch_idx: 390 |  Loss: (0.3187) |  Loss2: (0.0000) | Acc: (88.00%) (44454/50000)
# TEST : Loss: (0.4236) | Acc: (85.00%) (8573/10000)
percent tensor([0.5820, 0.5788, 0.5894, 0.5792, 0.5928, 0.5789, 0.5855, 0.5815, 0.5827,
        0.5807, 0.5797, 0.5880, 0.5796, 0.5715, 0.5791, 0.5776],
       device='cuda:0') torch.Size([16])
percent tensor([0.5531, 0.5268, 0.5293, 0.5597, 0.5462, 0.5874, 0.5346, 0.5479, 0.5412,
        0.5273, 0.5345, 0.5268, 0.5280, 0.5590, 0.5515, 0.5573],
       device='cuda:0') torch.Size([16])
percent tensor([0.5128, 0.5323, 0.4965, 0.4688, 0.5022, 0.4602, 0.5415, 0.5096, 0.5172,
        0.5011, 0.5117, 0.5156, 0.5263, 0.5263, 0.5055, 0.5027],
       device='cuda:0') torch.Size([16])
percent tensor([0.6082, 0.5869, 0.5787, 0.5964, 0.5895, 0.6192, 0.5896, 0.5840, 0.5962,
        0.5970, 0.5995, 0.5883, 0.6044, 0.6044, 0.5951, 0.6211],
       device='cuda:0') torch.Size([16])
percent tensor([0.5979, 0.6530, 0.6356, 0.6566, 0.6007, 0.6423, 0.6093, 0.5214, 0.7117,
        0.6000, 0.6964, 0.6703, 0.7236, 0.7240, 0.5780, 0.6103],
       device='cuda:0') torch.Size([16])
percent tensor([0.6969, 0.6602, 0.7377, 0.7598, 0.7662, 0.7734, 0.7137, 0.6731, 0.7502,
        0.6766, 0.7323, 0.7123, 0.7015, 0.8124, 0.6614, 0.7323],
       device='cuda:0') torch.Size([16])
percent tensor([0.5804, 0.5411, 0.6828, 0.6218, 0.7352, 0.5736, 0.6407, 0.7111, 0.5628,
        0.5864, 0.5453, 0.5734, 0.4040, 0.5943, 0.5979, 0.6483],
       device='cuda:0') torch.Size([16])
percent tensor([0.9988, 0.9970, 0.9977, 0.9987, 0.9977, 0.9962, 0.9985, 0.9987, 0.9982,
        0.9988, 0.9984, 0.9988, 0.9978, 0.9984, 0.9982, 0.9990],
       device='cuda:0') torch.Size([16])
Epoch: 68 | Batch_idx: 0 |  Loss: (0.3892) |  Loss2: (0.0000) | Acc: (89.00%) (114/128)
Epoch: 68 | Batch_idx: 10 |  Loss: (0.3165) |  Loss2: (0.0000) | Acc: (89.00%) (1254/1408)
Epoch: 68 | Batch_idx: 20 |  Loss: (0.3082) |  Loss2: (0.0000) | Acc: (89.00%) (2397/2688)
Epoch: 68 | Batch_idx: 30 |  Loss: (0.3114) |  Loss2: (0.0000) | Acc: (89.00%) (3540/3968)
Epoch: 68 | Batch_idx: 40 |  Loss: (0.3135) |  Loss2: (0.0000) | Acc: (89.00%) (4674/5248)
Epoch: 68 | Batch_idx: 50 |  Loss: (0.3162) |  Loss2: (0.0000) | Acc: (89.00%) (5820/6528)
Epoch: 68 | Batch_idx: 60 |  Loss: (0.3169) |  Loss2: (0.0000) | Acc: (89.00%) (6958/7808)
Epoch: 68 | Batch_idx: 70 |  Loss: (0.3197) |  Loss2: (0.0000) | Acc: (89.00%) (8089/9088)
Epoch: 68 | Batch_idx: 80 |  Loss: (0.3217) |  Loss2: (0.0000) | Acc: (88.00%) (9225/10368)
Epoch: 68 | Batch_idx: 90 |  Loss: (0.3236) |  Loss2: (0.0000) | Acc: (88.00%) (10354/11648)
Epoch: 68 | Batch_idx: 100 |  Loss: (0.3256) |  Loss2: (0.0000) | Acc: (88.00%) (11480/12928)
Epoch: 68 | Batch_idx: 110 |  Loss: (0.3246) |  Loss2: (0.0000) | Acc: (88.00%) (12614/14208)
Epoch: 68 | Batch_idx: 120 |  Loss: (0.3231) |  Loss2: (0.0000) | Acc: (88.00%) (13749/15488)
Epoch: 68 | Batch_idx: 130 |  Loss: (0.3208) |  Loss2: (0.0000) | Acc: (88.00%) (14905/16768)
Epoch: 68 | Batch_idx: 140 |  Loss: (0.3192) |  Loss2: (0.0000) | Acc: (88.00%) (16052/18048)
Epoch: 68 | Batch_idx: 150 |  Loss: (0.3205) |  Loss2: (0.0000) | Acc: (88.00%) (17167/19328)
Epoch: 68 | Batch_idx: 160 |  Loss: (0.3178) |  Loss2: (0.0000) | Acc: (88.00%) (18329/20608)
Epoch: 68 | Batch_idx: 170 |  Loss: (0.3178) |  Loss2: (0.0000) | Acc: (88.00%) (19473/21888)
Epoch: 68 | Batch_idx: 180 |  Loss: (0.3156) |  Loss2: (0.0000) | Acc: (89.00%) (20633/23168)
Epoch: 68 | Batch_idx: 190 |  Loss: (0.3174) |  Loss2: (0.0000) | Acc: (89.00%) (21766/24448)
Epoch: 68 | Batch_idx: 200 |  Loss: (0.3175) |  Loss2: (0.0000) | Acc: (88.00%) (22897/25728)
Epoch: 68 | Batch_idx: 210 |  Loss: (0.3170) |  Loss2: (0.0000) | Acc: (89.00%) (24046/27008)
Epoch: 68 | Batch_idx: 220 |  Loss: (0.3174) |  Loss2: (0.0000) | Acc: (89.00%) (25177/28288)
Epoch: 68 | Batch_idx: 230 |  Loss: (0.3167) |  Loss2: (0.0000) | Acc: (89.00%) (26326/29568)
Epoch: 68 | Batch_idx: 240 |  Loss: (0.3175) |  Loss2: (0.0000) | Acc: (89.00%) (27468/30848)
Epoch: 68 | Batch_idx: 250 |  Loss: (0.3177) |  Loss2: (0.0000) | Acc: (89.00%) (28598/32128)
Epoch: 68 | Batch_idx: 260 |  Loss: (0.3171) |  Loss2: (0.0000) | Acc: (89.00%) (29754/33408)
Epoch: 68 | Batch_idx: 270 |  Loss: (0.3166) |  Loss2: (0.0000) | Acc: (89.00%) (30898/34688)
Epoch: 68 | Batch_idx: 280 |  Loss: (0.3160) |  Loss2: (0.0000) | Acc: (89.00%) (32033/35968)
Epoch: 68 | Batch_idx: 290 |  Loss: (0.3145) |  Loss2: (0.0000) | Acc: (89.00%) (33193/37248)
Epoch: 68 | Batch_idx: 300 |  Loss: (0.3136) |  Loss2: (0.0000) | Acc: (89.00%) (34355/38528)
Epoch: 68 | Batch_idx: 310 |  Loss: (0.3138) |  Loss2: (0.0000) | Acc: (89.00%) (35501/39808)
Epoch: 68 | Batch_idx: 320 |  Loss: (0.3136) |  Loss2: (0.0000) | Acc: (89.00%) (36639/41088)
Epoch: 68 | Batch_idx: 330 |  Loss: (0.3135) |  Loss2: (0.0000) | Acc: (89.00%) (37779/42368)
Epoch: 68 | Batch_idx: 340 |  Loss: (0.3132) |  Loss2: (0.0000) | Acc: (89.00%) (38935/43648)
Epoch: 68 | Batch_idx: 350 |  Loss: (0.3130) |  Loss2: (0.0000) | Acc: (89.00%) (40073/44928)
Epoch: 68 | Batch_idx: 360 |  Loss: (0.3137) |  Loss2: (0.0000) | Acc: (89.00%) (41203/46208)
Epoch: 68 | Batch_idx: 370 |  Loss: (0.3143) |  Loss2: (0.0000) | Acc: (89.00%) (42331/47488)
Epoch: 68 | Batch_idx: 380 |  Loss: (0.3141) |  Loss2: (0.0000) | Acc: (89.00%) (43479/48768)
Epoch: 68 | Batch_idx: 390 |  Loss: (0.3139) |  Loss2: (0.0000) | Acc: (89.00%) (44575/50000)
# TEST : Loss: (0.4161) | Acc: (86.00%) (8617/10000)
percent tensor([0.5831, 0.5800, 0.5913, 0.5807, 0.5947, 0.5802, 0.5869, 0.5830, 0.5838,
        0.5820, 0.5807, 0.5896, 0.5805, 0.5724, 0.5804, 0.5788],
       device='cuda:0') torch.Size([16])
percent tensor([0.5544, 0.5279, 0.5313, 0.5624, 0.5483, 0.5890, 0.5360, 0.5506, 0.5428,
        0.5288, 0.5358, 0.5285, 0.5290, 0.5607, 0.5528, 0.5590],
       device='cuda:0') torch.Size([16])
percent tensor([0.5167, 0.5339, 0.4976, 0.4708, 0.5042, 0.4624, 0.5433, 0.5108, 0.5201,
        0.5041, 0.5155, 0.5171, 0.5289, 0.5295, 0.5064, 0.5066],
       device='cuda:0') torch.Size([16])
percent tensor([0.6090, 0.5871, 0.5812, 0.5981, 0.5917, 0.6193, 0.5916, 0.5868, 0.5976,
        0.5971, 0.6003, 0.5896, 0.6042, 0.6053, 0.5965, 0.6211],
       device='cuda:0') torch.Size([16])
percent tensor([0.5926, 0.6436, 0.6359, 0.6563, 0.5998, 0.6425, 0.6056, 0.5193, 0.7094,
        0.5892, 0.6933, 0.6665, 0.7147, 0.7203, 0.5745, 0.6049],
       device='cuda:0') torch.Size([16])
percent tensor([0.6884, 0.6498, 0.7283, 0.7515, 0.7577, 0.7697, 0.7025, 0.6611, 0.7430,
        0.6668, 0.7248, 0.7022, 0.6940, 0.8073, 0.6512, 0.7252],
       device='cuda:0') torch.Size([16])
percent tensor([0.5857, 0.5470, 0.6826, 0.6211, 0.7331, 0.5761, 0.6447, 0.7137, 0.5689,
        0.5874, 0.5526, 0.5747, 0.4121, 0.6025, 0.6040, 0.6506],
       device='cuda:0') torch.Size([16])
percent tensor([0.9989, 0.9971, 0.9979, 0.9988, 0.9978, 0.9964, 0.9986, 0.9988, 0.9983,
        0.9988, 0.9984, 0.9989, 0.9979, 0.9985, 0.9983, 0.9990],
       device='cuda:0') torch.Size([16])
Epoch: 69 | Batch_idx: 0 |  Loss: (0.3261) |  Loss2: (0.0000) | Acc: (86.00%) (111/128)
Epoch: 69 | Batch_idx: 10 |  Loss: (0.2750) |  Loss2: (0.0000) | Acc: (90.00%) (1279/1408)
Epoch: 69 | Batch_idx: 20 |  Loss: (0.2973) |  Loss2: (0.0000) | Acc: (90.00%) (2422/2688)
Epoch: 69 | Batch_idx: 30 |  Loss: (0.2942) |  Loss2: (0.0000) | Acc: (90.00%) (3573/3968)
Epoch: 69 | Batch_idx: 40 |  Loss: (0.2915) |  Loss2: (0.0000) | Acc: (89.00%) (4723/5248)
Epoch: 69 | Batch_idx: 50 |  Loss: (0.2948) |  Loss2: (0.0000) | Acc: (89.00%) (5875/6528)
Epoch: 69 | Batch_idx: 60 |  Loss: (0.3039) |  Loss2: (0.0000) | Acc: (89.00%) (7006/7808)
Epoch: 69 | Batch_idx: 70 |  Loss: (0.3034) |  Loss2: (0.0000) | Acc: (89.00%) (8154/9088)
Epoch: 69 | Batch_idx: 80 |  Loss: (0.3029) |  Loss2: (0.0000) | Acc: (89.00%) (9299/10368)
Epoch: 69 | Batch_idx: 90 |  Loss: (0.3047) |  Loss2: (0.0000) | Acc: (89.00%) (10435/11648)
Epoch: 69 | Batch_idx: 100 |  Loss: (0.3072) |  Loss2: (0.0000) | Acc: (89.00%) (11572/12928)
Epoch: 69 | Batch_idx: 110 |  Loss: (0.3078) |  Loss2: (0.0000) | Acc: (89.00%) (12718/14208)
Epoch: 69 | Batch_idx: 120 |  Loss: (0.3074) |  Loss2: (0.0000) | Acc: (89.00%) (13864/15488)
Epoch: 69 | Batch_idx: 130 |  Loss: (0.3061) |  Loss2: (0.0000) | Acc: (89.00%) (15017/16768)
Epoch: 69 | Batch_idx: 140 |  Loss: (0.3056) |  Loss2: (0.0000) | Acc: (89.00%) (16170/18048)
Epoch: 69 | Batch_idx: 150 |  Loss: (0.3061) |  Loss2: (0.0000) | Acc: (89.00%) (17322/19328)
Epoch: 69 | Batch_idx: 160 |  Loss: (0.3067) |  Loss2: (0.0000) | Acc: (89.00%) (18463/20608)
Epoch: 69 | Batch_idx: 170 |  Loss: (0.3075) |  Loss2: (0.0000) | Acc: (89.00%) (19602/21888)
Epoch: 69 | Batch_idx: 180 |  Loss: (0.3089) |  Loss2: (0.0000) | Acc: (89.00%) (20730/23168)
Epoch: 69 | Batch_idx: 190 |  Loss: (0.3075) |  Loss2: (0.0000) | Acc: (89.00%) (21875/24448)
Epoch: 69 | Batch_idx: 200 |  Loss: (0.3064) |  Loss2: (0.0000) | Acc: (89.00%) (23019/25728)
Epoch: 69 | Batch_idx: 210 |  Loss: (0.3081) |  Loss2: (0.0000) | Acc: (89.00%) (24134/27008)
Epoch: 69 | Batch_idx: 220 |  Loss: (0.3066) |  Loss2: (0.0000) | Acc: (89.00%) (25290/28288)
Epoch: 69 | Batch_idx: 230 |  Loss: (0.3075) |  Loss2: (0.0000) | Acc: (89.00%) (26422/29568)
Epoch: 69 | Batch_idx: 240 |  Loss: (0.3074) |  Loss2: (0.0000) | Acc: (89.00%) (27576/30848)
Epoch: 69 | Batch_idx: 250 |  Loss: (0.3063) |  Loss2: (0.0000) | Acc: (89.00%) (28733/32128)
Epoch: 69 | Batch_idx: 260 |  Loss: (0.3056) |  Loss2: (0.0000) | Acc: (89.00%) (29891/33408)
Epoch: 69 | Batch_idx: 270 |  Loss: (0.3048) |  Loss2: (0.0000) | Acc: (89.00%) (31053/34688)
Epoch: 69 | Batch_idx: 280 |  Loss: (0.3046) |  Loss2: (0.0000) | Acc: (89.00%) (32204/35968)
Epoch: 69 | Batch_idx: 290 |  Loss: (0.3040) |  Loss2: (0.0000) | Acc: (89.00%) (33368/37248)
Epoch: 69 | Batch_idx: 300 |  Loss: (0.3044) |  Loss2: (0.0000) | Acc: (89.00%) (34504/38528)
Epoch: 69 | Batch_idx: 310 |  Loss: (0.3033) |  Loss2: (0.0000) | Acc: (89.00%) (35663/39808)
Epoch: 69 | Batch_idx: 320 |  Loss: (0.3032) |  Loss2: (0.0000) | Acc: (89.00%) (36815/41088)
Epoch: 69 | Batch_idx: 330 |  Loss: (0.3041) |  Loss2: (0.0000) | Acc: (89.00%) (37949/42368)
Epoch: 69 | Batch_idx: 340 |  Loss: (0.3050) |  Loss2: (0.0000) | Acc: (89.00%) (39079/43648)
Epoch: 69 | Batch_idx: 350 |  Loss: (0.3057) |  Loss2: (0.0000) | Acc: (89.00%) (40213/44928)
Epoch: 69 | Batch_idx: 360 |  Loss: (0.3060) |  Loss2: (0.0000) | Acc: (89.00%) (41352/46208)
Epoch: 69 | Batch_idx: 370 |  Loss: (0.3055) |  Loss2: (0.0000) | Acc: (89.00%) (42505/47488)
Epoch: 69 | Batch_idx: 380 |  Loss: (0.3055) |  Loss2: (0.0000) | Acc: (89.00%) (43649/48768)
Epoch: 69 | Batch_idx: 390 |  Loss: (0.3058) |  Loss2: (0.0000) | Acc: (89.00%) (44743/50000)
# TEST : Loss: (0.4127) | Acc: (86.00%) (8620/10000)
percent tensor([0.5834, 0.5803, 0.5924, 0.5818, 0.5956, 0.5803, 0.5873, 0.5839, 0.5840,
        0.5825, 0.5809, 0.5904, 0.5807, 0.5728, 0.5807, 0.5793],
       device='cuda:0') torch.Size([16])
percent tensor([0.5549, 0.5282, 0.5322, 0.5641, 0.5495, 0.5900, 0.5365, 0.5519, 0.5432,
        0.5294, 0.5360, 0.5293, 0.5293, 0.5613, 0.5537, 0.5601],
       device='cuda:0') torch.Size([16])
percent tensor([0.5190, 0.5360, 0.4977, 0.4688, 0.5042, 0.4613, 0.5451, 0.5100, 0.5211,
        0.5069, 0.5184, 0.5181, 0.5311, 0.5309, 0.5066, 0.5082],
       device='cuda:0') torch.Size([16])
percent tensor([0.6117, 0.5883, 0.5853, 0.6018, 0.5954, 0.6217, 0.5947, 0.5909, 0.6004,
        0.5984, 0.6020, 0.5923, 0.6056, 0.6074, 0.5994, 0.6233],
       device='cuda:0') torch.Size([16])
percent tensor([0.5992, 0.6504, 0.6368, 0.6566, 0.5990, 0.6459, 0.6140, 0.5241, 0.7127,
        0.5936, 0.7008, 0.6706, 0.7191, 0.7225, 0.5837, 0.6103],
       device='cuda:0') torch.Size([16])
percent tensor([0.6846, 0.6469, 0.7234, 0.7466, 0.7529, 0.7669, 0.6983, 0.6557, 0.7394,
        0.6623, 0.7206, 0.6983, 0.6917, 0.8035, 0.6465, 0.7213],
       device='cuda:0') torch.Size([16])
percent tensor([0.5888, 0.5455, 0.6828, 0.6208, 0.7310, 0.5815, 0.6449, 0.7151, 0.5708,
        0.5826, 0.5520, 0.5735, 0.4144, 0.6036, 0.6079, 0.6524],
       device='cuda:0') torch.Size([16])
percent tensor([0.9989, 0.9973, 0.9980, 0.9989, 0.9980, 0.9966, 0.9987, 0.9988, 0.9984,
        0.9989, 0.9985, 0.9990, 0.9981, 0.9986, 0.9983, 0.9990],
       device='cuda:0') torch.Size([16])
True Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=128, out_features=16, bias=False)
False Linear(in_features=16, out_features=2, bias=False)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=128, out_features=16, bias=False)
False Linear(in_features=16, out_features=2, bias=False)
True Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=256, out_features=32, bias=False)
False Linear(in_features=32, out_features=2, bias=False)
True Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=256, out_features=32, bias=False)
False Linear(in_features=32, out_features=2, bias=False)
True Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=512, out_features=64, bias=False)
False Linear(in_features=64, out_features=2, bias=False)
True Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=512, out_features=64, bias=False)
False Linear(in_features=64, out_features=2, bias=False)
True Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1024, out_features=128, bias=False)
False Linear(in_features=128, out_features=2, bias=False)
True Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1024, out_features=128, bias=False)
False Linear(in_features=128, out_features=2, bias=False)
True Linear(in_features=512, out_features=10, bias=True)
Epoch: 70 | Batch_idx: 0 |  Loss: (0.2465) |  Loss2: (0.0000) | Acc: (90.00%) (116/128)
Epoch: 70 | Batch_idx: 10 |  Loss: (0.2922) |  Loss2: (0.0000) | Acc: (90.00%) (1272/1408)
Epoch: 70 | Batch_idx: 20 |  Loss: (0.2892) |  Loss2: (0.0000) | Acc: (90.00%) (2432/2688)
Epoch: 70 | Batch_idx: 30 |  Loss: (0.3004) |  Loss2: (0.0000) | Acc: (89.00%) (3567/3968)
Epoch: 70 | Batch_idx: 40 |  Loss: (0.2959) |  Loss2: (0.0000) | Acc: (89.00%) (4722/5248)
Epoch: 70 | Batch_idx: 50 |  Loss: (0.2982) |  Loss2: (0.0000) | Acc: (89.00%) (5863/6528)
Epoch: 70 | Batch_idx: 60 |  Loss: (0.3010) |  Loss2: (0.0000) | Acc: (89.00%) (7012/7808)
Epoch: 70 | Batch_idx: 70 |  Loss: (0.3083) |  Loss2: (0.0000) | Acc: (89.00%) (8125/9088)
Epoch: 70 | Batch_idx: 80 |  Loss: (0.3158) |  Loss2: (0.0000) | Acc: (89.00%) (9233/10368)
Epoch: 70 | Batch_idx: 90 |  Loss: (0.3150) |  Loss2: (0.0000) | Acc: (89.00%) (10381/11648)
Epoch: 70 | Batch_idx: 100 |  Loss: (0.3151) |  Loss2: (0.0000) | Acc: (89.00%) (11523/12928)
Epoch: 70 | Batch_idx: 110 |  Loss: (0.3128) |  Loss2: (0.0000) | Acc: (89.00%) (12666/14208)
Epoch: 70 | Batch_idx: 120 |  Loss: (0.3124) |  Loss2: (0.0000) | Acc: (89.00%) (13800/15488)
Epoch: 70 | Batch_idx: 130 |  Loss: (0.3117) |  Loss2: (0.0000) | Acc: (89.00%) (14939/16768)
Epoch: 70 | Batch_idx: 140 |  Loss: (0.3125) |  Loss2: (0.0000) | Acc: (89.00%) (16086/18048)
Epoch: 70 | Batch_idx: 150 |  Loss: (0.3113) |  Loss2: (0.0000) | Acc: (89.00%) (17234/19328)
Epoch: 70 | Batch_idx: 160 |  Loss: (0.3111) |  Loss2: (0.0000) | Acc: (89.00%) (18367/20608)
Epoch: 70 | Batch_idx: 170 |  Loss: (0.3097) |  Loss2: (0.0000) | Acc: (89.00%) (19525/21888)
Epoch: 70 | Batch_idx: 180 |  Loss: (0.3113) |  Loss2: (0.0000) | Acc: (89.00%) (20666/23168)
Epoch: 70 | Batch_idx: 190 |  Loss: (0.3117) |  Loss2: (0.0000) | Acc: (89.00%) (21804/24448)
Epoch: 70 | Batch_idx: 200 |  Loss: (0.3119) |  Loss2: (0.0000) | Acc: (89.00%) (22946/25728)
Epoch: 70 | Batch_idx: 210 |  Loss: (0.3114) |  Loss2: (0.0000) | Acc: (89.00%) (24083/27008)
Epoch: 70 | Batch_idx: 220 |  Loss: (0.3134) |  Loss2: (0.0000) | Acc: (89.00%) (25203/28288)
Epoch: 70 | Batch_idx: 230 |  Loss: (0.3141) |  Loss2: (0.0000) | Acc: (89.00%) (26339/29568)
Epoch: 70 | Batch_idx: 240 |  Loss: (0.3133) |  Loss2: (0.0000) | Acc: (89.00%) (27489/30848)
Epoch: 70 | Batch_idx: 250 |  Loss: (0.3125) |  Loss2: (0.0000) | Acc: (89.00%) (28632/32128)
Epoch: 70 | Batch_idx: 260 |  Loss: (0.3123) |  Loss2: (0.0000) | Acc: (89.00%) (29771/33408)
Epoch: 70 | Batch_idx: 270 |  Loss: (0.3121) |  Loss2: (0.0000) | Acc: (89.00%) (30917/34688)
Epoch: 70 | Batch_idx: 280 |  Loss: (0.3109) |  Loss2: (0.0000) | Acc: (89.00%) (32071/35968)
Epoch: 70 | Batch_idx: 290 |  Loss: (0.3103) |  Loss2: (0.0000) | Acc: (89.00%) (33227/37248)
Epoch: 70 | Batch_idx: 300 |  Loss: (0.3120) |  Loss2: (0.0000) | Acc: (89.00%) (34338/38528)
Epoch: 70 | Batch_idx: 310 |  Loss: (0.3119) |  Loss2: (0.0000) | Acc: (89.00%) (35494/39808)
Epoch: 70 | Batch_idx: 320 |  Loss: (0.3127) |  Loss2: (0.0000) | Acc: (89.00%) (36627/41088)
Epoch: 70 | Batch_idx: 330 |  Loss: (0.3131) |  Loss2: (0.0000) | Acc: (89.00%) (37778/42368)
Epoch: 70 | Batch_idx: 340 |  Loss: (0.3133) |  Loss2: (0.0000) | Acc: (89.00%) (38919/43648)
Epoch: 70 | Batch_idx: 350 |  Loss: (0.3137) |  Loss2: (0.0000) | Acc: (89.00%) (40058/44928)
Epoch: 70 | Batch_idx: 360 |  Loss: (0.3141) |  Loss2: (0.0000) | Acc: (89.00%) (41196/46208)
Epoch: 70 | Batch_idx: 370 |  Loss: (0.3146) |  Loss2: (0.0000) | Acc: (89.00%) (42329/47488)
Epoch: 70 | Batch_idx: 380 |  Loss: (0.3150) |  Loss2: (0.0000) | Acc: (89.00%) (43465/48768)
Epoch: 70 | Batch_idx: 390 |  Loss: (0.3153) |  Loss2: (0.0000) | Acc: (89.00%) (44562/50000)
=> saving checkpoint 'drive/app/torch/save_Routing_Gate_2/checkpoint_070.pth.tar'
# TEST : Loss: (0.4647) | Acc: (84.00%) (8464/10000)
percent tensor([0.5829, 0.5816, 0.5899, 0.5818, 0.5936, 0.5789, 0.5882, 0.5845, 0.5841,
        0.5827, 0.5808, 0.5891, 0.5806, 0.5759, 0.5815, 0.5794],
       device='cuda:0') torch.Size([16])
percent tensor([0.5551, 0.5291, 0.5301, 0.5625, 0.5473, 0.5874, 0.5349, 0.5526, 0.5435,
        0.5293, 0.5353, 0.5278, 0.5291, 0.5634, 0.5534, 0.5602],
       device='cuda:0') torch.Size([16])
percent tensor([0.5069, 0.5312, 0.4910, 0.4716, 0.4996, 0.4663, 0.5403, 0.5036, 0.5080,
        0.5011, 0.5059, 0.5111, 0.5178, 0.5289, 0.5062, 0.5064],
       device='cuda:0') torch.Size([16])
percent tensor([0.6112, 0.5867, 0.5829, 0.5955, 0.5948, 0.6238, 0.5938, 0.5895, 0.6028,
        0.5965, 0.6038, 0.5899, 0.6061, 0.6065, 0.5982, 0.6228],
       device='cuda:0') torch.Size([16])
percent tensor([0.5697, 0.6370, 0.6214, 0.6474, 0.5670, 0.6585, 0.6004, 0.5093, 0.7065,
        0.5759, 0.6871, 0.6527, 0.7001, 0.7132, 0.5627, 0.5979],
       device='cuda:0') torch.Size([16])
percent tensor([0.6868, 0.6333, 0.7315, 0.7439, 0.7526, 0.7677, 0.6986, 0.6642, 0.7442,
        0.6712, 0.7238, 0.6995, 0.6789, 0.7922, 0.6376, 0.7161],
       device='cuda:0') torch.Size([16])
percent tensor([0.6226, 0.5662, 0.6879, 0.6252, 0.7381, 0.6098, 0.6538, 0.7060, 0.5915,
        0.6019, 0.5712, 0.5881, 0.4550, 0.6060, 0.6177, 0.6730],
       device='cuda:0') torch.Size([16])
percent tensor([0.9988, 0.9977, 0.9983, 0.9990, 0.9986, 0.9976, 0.9982, 0.9988, 0.9980,
        0.9990, 0.9982, 0.9988, 0.9980, 0.9983, 0.9986, 0.9989],
       device='cuda:0') torch.Size([16])
Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 3, 3, 3]) tensor(177.5161, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(806.5133, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(805.5386, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([128, 64, 3, 3]) tensor(1528.3528, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([128, 64, 1, 1]) tensor(499.8806, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([128, 128, 3, 3]) tensor(2213.5002, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([256, 128, 3, 3]) tensor(4289.8594, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([256, 128, 1, 1]) tensor(1411.9564, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([256, 256, 3, 3]) tensor(6126.7715, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([512, 256, 3, 3]) tensor(11983.2158, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([512, 256, 1, 1]) tensor(3982.0315, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([512, 512, 3, 3]) tensor(16839.4492, device='cuda:0', grad_fn=<NormBackward0>)
Epoch: 71 | Batch_idx: 0 |  Loss: (0.4381) |  Loss2: (0.0000) | Acc: (83.00%) (107/128)
Epoch: 71 | Batch_idx: 10 |  Loss: (0.2965) |  Loss2: (0.0000) | Acc: (89.00%) (1261/1408)
Epoch: 71 | Batch_idx: 20 |  Loss: (0.2785) |  Loss2: (0.0000) | Acc: (90.00%) (2431/2688)
Epoch: 71 | Batch_idx: 30 |  Loss: (0.2819) |  Loss2: (0.0000) | Acc: (90.00%) (3594/3968)
Epoch: 71 | Batch_idx: 40 |  Loss: (0.2833) |  Loss2: (0.0000) | Acc: (90.00%) (4738/5248)
Epoch: 71 | Batch_idx: 50 |  Loss: (0.2853) |  Loss2: (0.0000) | Acc: (90.00%) (5895/6528)
Epoch: 71 | Batch_idx: 60 |  Loss: (0.2819) |  Loss2: (0.0000) | Acc: (90.00%) (7059/7808)
Epoch: 71 | Batch_idx: 70 |  Loss: (0.2835) |  Loss2: (0.0000) | Acc: (90.00%) (8208/9088)
Epoch: 71 | Batch_idx: 80 |  Loss: (0.2851) |  Loss2: (0.0000) | Acc: (90.00%) (9345/10368)
Epoch: 71 | Batch_idx: 90 |  Loss: (0.2904) |  Loss2: (0.0000) | Acc: (89.00%) (10478/11648)
Epoch: 71 | Batch_idx: 100 |  Loss: (0.2935) |  Loss2: (0.0000) | Acc: (89.00%) (11606/12928)
Epoch: 71 | Batch_idx: 110 |  Loss: (0.2928) |  Loss2: (0.0000) | Acc: (89.00%) (12760/14208)
Epoch: 71 | Batch_idx: 120 |  Loss: (0.2949) |  Loss2: (0.0000) | Acc: (89.00%) (13885/15488)
Epoch: 71 | Batch_idx: 130 |  Loss: (0.2954) |  Loss2: (0.0000) | Acc: (89.00%) (15025/16768)
Epoch: 71 | Batch_idx: 140 |  Loss: (0.2970) |  Loss2: (0.0000) | Acc: (89.00%) (16168/18048)
Epoch: 71 | Batch_idx: 150 |  Loss: (0.2992) |  Loss2: (0.0000) | Acc: (89.00%) (17310/19328)
Epoch: 71 | Batch_idx: 160 |  Loss: (0.3010) |  Loss2: (0.0000) | Acc: (89.00%) (18441/20608)
Epoch: 71 | Batch_idx: 170 |  Loss: (0.3008) |  Loss2: (0.0000) | Acc: (89.00%) (19588/21888)
Epoch: 71 | Batch_idx: 180 |  Loss: (0.3010) |  Loss2: (0.0000) | Acc: (89.00%) (20720/23168)
Epoch: 71 | Batch_idx: 190 |  Loss: (0.3001) |  Loss2: (0.0000) | Acc: (89.00%) (21880/24448)
Epoch: 71 | Batch_idx: 200 |  Loss: (0.2996) |  Loss2: (0.0000) | Acc: (89.00%) (23039/25728)
Epoch: 71 | Batch_idx: 210 |  Loss: (0.3009) |  Loss2: (0.0000) | Acc: (89.00%) (24169/27008)
Epoch: 71 | Batch_idx: 220 |  Loss: (0.3000) |  Loss2: (0.0000) | Acc: (89.00%) (25333/28288)
Epoch: 71 | Batch_idx: 230 |  Loss: (0.3006) |  Loss2: (0.0000) | Acc: (89.00%) (26474/29568)
Epoch: 71 | Batch_idx: 240 |  Loss: (0.3014) |  Loss2: (0.0000) | Acc: (89.00%) (27601/30848)
Epoch: 71 | Batch_idx: 250 |  Loss: (0.3021) |  Loss2: (0.0000) | Acc: (89.00%) (28732/32128)
Epoch: 71 | Batch_idx: 260 |  Loss: (0.3008) |  Loss2: (0.0000) | Acc: (89.00%) (29895/33408)
Epoch: 71 | Batch_idx: 270 |  Loss: (0.3014) |  Loss2: (0.0000) | Acc: (89.00%) (31029/34688)
Epoch: 71 | Batch_idx: 280 |  Loss: (0.3015) |  Loss2: (0.0000) | Acc: (89.00%) (32171/35968)
Epoch: 71 | Batch_idx: 290 |  Loss: (0.3030) |  Loss2: (0.0000) | Acc: (89.00%) (33291/37248)
Epoch: 71 | Batch_idx: 300 |  Loss: (0.3032) |  Loss2: (0.0000) | Acc: (89.00%) (34434/38528)
Epoch: 71 | Batch_idx: 310 |  Loss: (0.3026) |  Loss2: (0.0000) | Acc: (89.00%) (35594/39808)
Epoch: 71 | Batch_idx: 320 |  Loss: (0.3037) |  Loss2: (0.0000) | Acc: (89.00%) (36724/41088)
Epoch: 71 | Batch_idx: 330 |  Loss: (0.3049) |  Loss2: (0.0000) | Acc: (89.00%) (37840/42368)
Epoch: 71 | Batch_idx: 340 |  Loss: (0.3051) |  Loss2: (0.0000) | Acc: (89.00%) (38979/43648)
Epoch: 71 | Batch_idx: 350 |  Loss: (0.3045) |  Loss2: (0.0000) | Acc: (89.00%) (40125/44928)
Epoch: 71 | Batch_idx: 360 |  Loss: (0.3047) |  Loss2: (0.0000) | Acc: (89.00%) (41272/46208)
Epoch: 71 | Batch_idx: 370 |  Loss: (0.3048) |  Loss2: (0.0000) | Acc: (89.00%) (42421/47488)
Epoch: 71 | Batch_idx: 380 |  Loss: (0.3054) |  Loss2: (0.0000) | Acc: (89.00%) (43551/48768)
Epoch: 71 | Batch_idx: 390 |  Loss: (0.3056) |  Loss2: (0.0000) | Acc: (89.00%) (44640/50000)
# TEST : Loss: (0.4580) | Acc: (85.00%) (8518/10000)
percent tensor([0.5828, 0.5804, 0.5911, 0.5817, 0.5949, 0.5809, 0.5877, 0.5831, 0.5833,
        0.5817, 0.5802, 0.5890, 0.5800, 0.5731, 0.5819, 0.5792],
       device='cuda:0') torch.Size([16])
percent tensor([0.5547, 0.5301, 0.5247, 0.5611, 0.5456, 0.5895, 0.5363, 0.5500, 0.5429,
        0.5294, 0.5361, 0.5248, 0.5284, 0.5659, 0.5540, 0.5602],
       device='cuda:0') torch.Size([16])
percent tensor([0.5117, 0.5349, 0.4905, 0.4723, 0.4988, 0.4704, 0.5412, 0.5045, 0.5165,
        0.5057, 0.5156, 0.5116, 0.5254, 0.5361, 0.5096, 0.5110],
       device='cuda:0') torch.Size([16])
percent tensor([0.6117, 0.5863, 0.5857, 0.5973, 0.5935, 0.6262, 0.5919, 0.5923, 0.6029,
        0.5967, 0.6004, 0.5909, 0.6053, 0.6064, 0.5996, 0.6222],
       device='cuda:0') torch.Size([16])
percent tensor([0.5680, 0.6487, 0.6172, 0.6427, 0.5627, 0.6398, 0.6023, 0.5122, 0.6820,
        0.5751, 0.6814, 0.6445, 0.6970, 0.7088, 0.5646, 0.5891],
       device='cuda:0') torch.Size([16])
percent tensor([0.6743, 0.6487, 0.7107, 0.7328, 0.7317, 0.7582, 0.6998, 0.6661, 0.7280,
        0.6645, 0.7238, 0.6856, 0.6774, 0.8044, 0.6447, 0.7054],
       device='cuda:0') torch.Size([16])
percent tensor([0.6132, 0.5600, 0.6827, 0.6143, 0.7193, 0.6263, 0.6485, 0.6988, 0.5893,
        0.6049, 0.5583, 0.5752, 0.4256, 0.6230, 0.6064, 0.6846],
       device='cuda:0') torch.Size([16])
percent tensor([0.9989, 0.9975, 0.9981, 0.9992, 0.9985, 0.9971, 0.9984, 0.9984, 0.9981,
        0.9987, 0.9984, 0.9984, 0.9978, 0.9989, 0.9981, 0.9991],
       device='cuda:0') torch.Size([16])
Epoch: 72 | Batch_idx: 0 |  Loss: (0.2406) |  Loss2: (0.0000) | Acc: (94.00%) (121/128)
Epoch: 72 | Batch_idx: 10 |  Loss: (0.2543) |  Loss2: (0.0000) | Acc: (91.00%) (1293/1408)
Epoch: 72 | Batch_idx: 20 |  Loss: (0.2715) |  Loss2: (0.0000) | Acc: (91.00%) (2459/2688)
Epoch: 72 | Batch_idx: 30 |  Loss: (0.2815) |  Loss2: (0.0000) | Acc: (90.00%) (3595/3968)
Epoch: 72 | Batch_idx: 40 |  Loss: (0.2856) |  Loss2: (0.0000) | Acc: (90.00%) (4743/5248)
Epoch: 72 | Batch_idx: 50 |  Loss: (0.2913) |  Loss2: (0.0000) | Acc: (90.00%) (5878/6528)
Epoch: 72 | Batch_idx: 60 |  Loss: (0.2908) |  Loss2: (0.0000) | Acc: (90.00%) (7032/7808)
Epoch: 72 | Batch_idx: 70 |  Loss: (0.2992) |  Loss2: (0.0000) | Acc: (89.00%) (8142/9088)
Epoch: 72 | Batch_idx: 80 |  Loss: (0.2999) |  Loss2: (0.0000) | Acc: (89.00%) (9288/10368)
Epoch: 72 | Batch_idx: 90 |  Loss: (0.2984) |  Loss2: (0.0000) | Acc: (89.00%) (10439/11648)
Epoch: 72 | Batch_idx: 100 |  Loss: (0.2978) |  Loss2: (0.0000) | Acc: (89.00%) (11599/12928)
Epoch: 72 | Batch_idx: 110 |  Loss: (0.3002) |  Loss2: (0.0000) | Acc: (89.00%) (12742/14208)
Epoch: 72 | Batch_idx: 120 |  Loss: (0.2999) |  Loss2: (0.0000) | Acc: (89.00%) (13895/15488)
Epoch: 72 | Batch_idx: 130 |  Loss: (0.2992) |  Loss2: (0.0000) | Acc: (89.00%) (15050/16768)
Epoch: 72 | Batch_idx: 140 |  Loss: (0.3001) |  Loss2: (0.0000) | Acc: (89.00%) (16194/18048)
Epoch: 72 | Batch_idx: 150 |  Loss: (0.2992) |  Loss2: (0.0000) | Acc: (89.00%) (17349/19328)
Epoch: 72 | Batch_idx: 160 |  Loss: (0.2985) |  Loss2: (0.0000) | Acc: (89.00%) (18505/20608)
Epoch: 72 | Batch_idx: 170 |  Loss: (0.2976) |  Loss2: (0.0000) | Acc: (89.00%) (19659/21888)
Epoch: 72 | Batch_idx: 180 |  Loss: (0.2974) |  Loss2: (0.0000) | Acc: (89.00%) (20809/23168)
Epoch: 72 | Batch_idx: 190 |  Loss: (0.2988) |  Loss2: (0.0000) | Acc: (89.00%) (21947/24448)
Epoch: 72 | Batch_idx: 200 |  Loss: (0.2982) |  Loss2: (0.0000) | Acc: (89.00%) (23104/25728)
Epoch: 72 | Batch_idx: 210 |  Loss: (0.2969) |  Loss2: (0.0000) | Acc: (89.00%) (24264/27008)
Epoch: 72 | Batch_idx: 220 |  Loss: (0.2955) |  Loss2: (0.0000) | Acc: (89.00%) (25423/28288)
Epoch: 72 | Batch_idx: 230 |  Loss: (0.2944) |  Loss2: (0.0000) | Acc: (89.00%) (26586/29568)
Epoch: 72 | Batch_idx: 240 |  Loss: (0.2947) |  Loss2: (0.0000) | Acc: (89.00%) (27739/30848)
Epoch: 72 | Batch_idx: 250 |  Loss: (0.2962) |  Loss2: (0.0000) | Acc: (89.00%) (28873/32128)
Epoch: 72 | Batch_idx: 260 |  Loss: (0.2956) |  Loss2: (0.0000) | Acc: (89.00%) (30038/33408)
Epoch: 72 | Batch_idx: 270 |  Loss: (0.2954) |  Loss2: (0.0000) | Acc: (89.00%) (31185/34688)
Epoch: 72 | Batch_idx: 280 |  Loss: (0.2949) |  Loss2: (0.0000) | Acc: (89.00%) (32354/35968)
Epoch: 72 | Batch_idx: 290 |  Loss: (0.2950) |  Loss2: (0.0000) | Acc: (89.00%) (33503/37248)
Epoch: 72 | Batch_idx: 300 |  Loss: (0.2945) |  Loss2: (0.0000) | Acc: (89.00%) (34648/38528)
Epoch: 72 | Batch_idx: 310 |  Loss: (0.2962) |  Loss2: (0.0000) | Acc: (89.00%) (35772/39808)
Epoch: 72 | Batch_idx: 320 |  Loss: (0.2957) |  Loss2: (0.0000) | Acc: (89.00%) (36929/41088)
Epoch: 72 | Batch_idx: 330 |  Loss: (0.2970) |  Loss2: (0.0000) | Acc: (89.00%) (38060/42368)
Epoch: 72 | Batch_idx: 340 |  Loss: (0.2975) |  Loss2: (0.0000) | Acc: (89.00%) (39187/43648)
Epoch: 72 | Batch_idx: 350 |  Loss: (0.2963) |  Loss2: (0.0000) | Acc: (89.00%) (40352/44928)
Epoch: 72 | Batch_idx: 360 |  Loss: (0.2962) |  Loss2: (0.0000) | Acc: (89.00%) (41509/46208)
Epoch: 72 | Batch_idx: 370 |  Loss: (0.2964) |  Loss2: (0.0000) | Acc: (89.00%) (42658/47488)
Epoch: 72 | Batch_idx: 380 |  Loss: (0.2971) |  Loss2: (0.0000) | Acc: (89.00%) (43790/48768)
Epoch: 72 | Batch_idx: 390 |  Loss: (0.2981) |  Loss2: (0.0000) | Acc: (89.00%) (44882/50000)
# TEST : Loss: (0.4684) | Acc: (84.00%) (8465/10000)
percent tensor([0.5837, 0.5810, 0.5933, 0.5843, 0.5968, 0.5801, 0.5882, 0.5847, 0.5842,
        0.5831, 0.5803, 0.5915, 0.5810, 0.5740, 0.5820, 0.5799],
       device='cuda:0') torch.Size([16])
percent tensor([0.5552, 0.5281, 0.5252, 0.5611, 0.5439, 0.5880, 0.5341, 0.5516, 0.5444,
        0.5295, 0.5358, 0.5241, 0.5297, 0.5630, 0.5536, 0.5600],
       device='cuda:0') torch.Size([16])
percent tensor([0.5040, 0.5338, 0.4960, 0.4716, 0.5045, 0.4633, 0.5432, 0.5075, 0.5107,
        0.5054, 0.5065, 0.5169, 0.5182, 0.5315, 0.5075, 0.5020],
       device='cuda:0') torch.Size([16])
percent tensor([0.6126, 0.5881, 0.5881, 0.5993, 0.5953, 0.6228, 0.5940, 0.5951, 0.6039,
        0.6002, 0.6050, 0.5933, 0.6070, 0.6062, 0.6013, 0.6230],
       device='cuda:0') torch.Size([16])
percent tensor([0.5744, 0.6480, 0.6046, 0.6338, 0.5566, 0.6471, 0.6060, 0.4898, 0.6738,
        0.5793, 0.6826, 0.6462, 0.6948, 0.7153, 0.5696, 0.6022],
       device='cuda:0') torch.Size([16])
percent tensor([0.6879, 0.6529, 0.7177, 0.7463, 0.7383, 0.7545, 0.7065, 0.6738, 0.7363,
        0.6804, 0.7387, 0.6889, 0.6844, 0.8130, 0.6481, 0.7234],
       device='cuda:0') torch.Size([16])
percent tensor([0.6190, 0.5641, 0.6939, 0.6432, 0.7343, 0.6308, 0.6413, 0.7146, 0.5919,
        0.5987, 0.5679, 0.5727, 0.4327, 0.5977, 0.6050, 0.6812],
       device='cuda:0') torch.Size([16])
percent tensor([0.9984, 0.9977, 0.9982, 0.9988, 0.9982, 0.9977, 0.9982, 0.9989, 0.9984,
        0.9990, 0.9984, 0.9990, 0.9982, 0.9985, 0.9983, 0.9988],
       device='cuda:0') torch.Size([16])
Epoch: 73 | Batch_idx: 0 |  Loss: (0.2921) |  Loss2: (0.0000) | Acc: (90.00%) (116/128)
Epoch: 73 | Batch_idx: 10 |  Loss: (0.2833) |  Loss2: (0.0000) | Acc: (89.00%) (1260/1408)
Epoch: 73 | Batch_idx: 20 |  Loss: (0.2875) |  Loss2: (0.0000) | Acc: (90.00%) (2420/2688)
Epoch: 73 | Batch_idx: 30 |  Loss: (0.2838) |  Loss2: (0.0000) | Acc: (90.00%) (3576/3968)
Epoch: 73 | Batch_idx: 40 |  Loss: (0.2850) |  Loss2: (0.0000) | Acc: (90.00%) (4735/5248)
Epoch: 73 | Batch_idx: 50 |  Loss: (0.2801) |  Loss2: (0.0000) | Acc: (90.00%) (5901/6528)
Epoch: 73 | Batch_idx: 60 |  Loss: (0.2831) |  Loss2: (0.0000) | Acc: (90.00%) (7037/7808)
Epoch: 73 | Batch_idx: 70 |  Loss: (0.2810) |  Loss2: (0.0000) | Acc: (90.00%) (8206/9088)
Epoch: 73 | Batch_idx: 80 |  Loss: (0.2883) |  Loss2: (0.0000) | Acc: (90.00%) (9341/10368)
Epoch: 73 | Batch_idx: 90 |  Loss: (0.2882) |  Loss2: (0.0000) | Acc: (90.00%) (10502/11648)
Epoch: 73 | Batch_idx: 100 |  Loss: (0.2877) |  Loss2: (0.0000) | Acc: (90.00%) (11654/12928)
Epoch: 73 | Batch_idx: 110 |  Loss: (0.2855) |  Loss2: (0.0000) | Acc: (90.00%) (12828/14208)
Epoch: 73 | Batch_idx: 120 |  Loss: (0.2864) |  Loss2: (0.0000) | Acc: (90.00%) (13981/15488)
Epoch: 73 | Batch_idx: 130 |  Loss: (0.2861) |  Loss2: (0.0000) | Acc: (90.00%) (15135/16768)
Epoch: 73 | Batch_idx: 140 |  Loss: (0.2851) |  Loss2: (0.0000) | Acc: (90.00%) (16301/18048)
Epoch: 73 | Batch_idx: 150 |  Loss: (0.2852) |  Loss2: (0.0000) | Acc: (90.00%) (17454/19328)
Epoch: 73 | Batch_idx: 160 |  Loss: (0.2850) |  Loss2: (0.0000) | Acc: (90.00%) (18620/20608)
Epoch: 73 | Batch_idx: 170 |  Loss: (0.2845) |  Loss2: (0.0000) | Acc: (90.00%) (19781/21888)
Epoch: 73 | Batch_idx: 180 |  Loss: (0.2844) |  Loss2: (0.0000) | Acc: (90.00%) (20936/23168)
Epoch: 73 | Batch_idx: 190 |  Loss: (0.2847) |  Loss2: (0.0000) | Acc: (90.00%) (22092/24448)
Epoch: 73 | Batch_idx: 200 |  Loss: (0.2854) |  Loss2: (0.0000) | Acc: (90.00%) (23241/25728)
Epoch: 73 | Batch_idx: 210 |  Loss: (0.2861) |  Loss2: (0.0000) | Acc: (90.00%) (24389/27008)
Epoch: 73 | Batch_idx: 220 |  Loss: (0.2853) |  Loss2: (0.0000) | Acc: (90.00%) (25543/28288)
Epoch: 73 | Batch_idx: 230 |  Loss: (0.2861) |  Loss2: (0.0000) | Acc: (90.00%) (26679/29568)
Epoch: 73 | Batch_idx: 240 |  Loss: (0.2847) |  Loss2: (0.0000) | Acc: (90.00%) (27837/30848)
Epoch: 73 | Batch_idx: 250 |  Loss: (0.2853) |  Loss2: (0.0000) | Acc: (90.00%) (28974/32128)
Epoch: 73 | Batch_idx: 260 |  Loss: (0.2857) |  Loss2: (0.0000) | Acc: (90.00%) (30124/33408)
Epoch: 73 | Batch_idx: 270 |  Loss: (0.2861) |  Loss2: (0.0000) | Acc: (90.00%) (31268/34688)
Epoch: 73 | Batch_idx: 280 |  Loss: (0.2867) |  Loss2: (0.0000) | Acc: (90.00%) (32423/35968)
Epoch: 73 | Batch_idx: 290 |  Loss: (0.2883) |  Loss2: (0.0000) | Acc: (90.00%) (33549/37248)
Epoch: 73 | Batch_idx: 300 |  Loss: (0.2889) |  Loss2: (0.0000) | Acc: (90.00%) (34705/38528)
Epoch: 73 | Batch_idx: 310 |  Loss: (0.2878) |  Loss2: (0.0000) | Acc: (90.00%) (35887/39808)
Epoch: 73 | Batch_idx: 320 |  Loss: (0.2879) |  Loss2: (0.0000) | Acc: (90.00%) (37028/41088)
Epoch: 73 | Batch_idx: 330 |  Loss: (0.2888) |  Loss2: (0.0000) | Acc: (90.00%) (38161/42368)
Epoch: 73 | Batch_idx: 340 |  Loss: (0.2891) |  Loss2: (0.0000) | Acc: (90.00%) (39305/43648)
Epoch: 73 | Batch_idx: 350 |  Loss: (0.2894) |  Loss2: (0.0000) | Acc: (90.00%) (40448/44928)
Epoch: 73 | Batch_idx: 360 |  Loss: (0.2897) |  Loss2: (0.0000) | Acc: (90.00%) (41599/46208)
Epoch: 73 | Batch_idx: 370 |  Loss: (0.2902) |  Loss2: (0.0000) | Acc: (90.00%) (42754/47488)
Epoch: 73 | Batch_idx: 380 |  Loss: (0.2903) |  Loss2: (0.0000) | Acc: (90.00%) (43902/48768)
Epoch: 73 | Batch_idx: 390 |  Loss: (0.2912) |  Loss2: (0.0000) | Acc: (89.00%) (44998/50000)
# TEST : Loss: (0.4436) | Acc: (85.00%) (8565/10000)
percent tensor([0.5822, 0.5805, 0.5880, 0.5822, 0.5935, 0.5799, 0.5862, 0.5831, 0.5825,
        0.5815, 0.5794, 0.5871, 0.5794, 0.5738, 0.5813, 0.5791],
       device='cuda:0') torch.Size([16])
percent tensor([0.5568, 0.5277, 0.5328, 0.5648, 0.5484, 0.5877, 0.5348, 0.5549, 0.5463,
        0.5303, 0.5356, 0.5277, 0.5300, 0.5625, 0.5529, 0.5602],
       device='cuda:0') torch.Size([16])
percent tensor([0.5081, 0.5389, 0.4907, 0.4727, 0.5006, 0.4671, 0.5435, 0.5068, 0.5089,
        0.5083, 0.5107, 0.5162, 0.5235, 0.5296, 0.5111, 0.5085],
       device='cuda:0') torch.Size([16])
percent tensor([0.6122, 0.5870, 0.5894, 0.6021, 0.5959, 0.6225, 0.5954, 0.5920, 0.6036,
        0.5986, 0.6060, 0.5937, 0.6076, 0.6068, 0.6015, 0.6237],
       device='cuda:0') torch.Size([16])
percent tensor([0.5835, 0.6420, 0.6305, 0.6318, 0.5827, 0.6455, 0.6068, 0.5012, 0.6991,
        0.5917, 0.6892, 0.6693, 0.7180, 0.6999, 0.5719, 0.6095],
       device='cuda:0') torch.Size([16])
percent tensor([0.6724, 0.6258, 0.7331, 0.7452, 0.7567, 0.7520, 0.7057, 0.6650, 0.7396,
        0.6529, 0.7283, 0.6915, 0.6760, 0.8039, 0.6368, 0.7111],
       device='cuda:0') torch.Size([16])
percent tensor([0.6226, 0.5783, 0.6966, 0.6394, 0.7377, 0.6320, 0.6477, 0.7112, 0.5904,
        0.6011, 0.5680, 0.5667, 0.4291, 0.6083, 0.6198, 0.6745],
       device='cuda:0') torch.Size([16])
percent tensor([0.9985, 0.9974, 0.9985, 0.9992, 0.9985, 0.9976, 0.9981, 0.9990, 0.9979,
        0.9986, 0.9977, 0.9988, 0.9977, 0.9986, 0.9984, 0.9991],
       device='cuda:0') torch.Size([16])
Epoch: 74 | Batch_idx: 0 |  Loss: (0.3289) |  Loss2: (0.0000) | Acc: (86.00%) (111/128)
Epoch: 74 | Batch_idx: 10 |  Loss: (0.2832) |  Loss2: (0.0000) | Acc: (89.00%) (1267/1408)
Epoch: 74 | Batch_idx: 20 |  Loss: (0.2894) |  Loss2: (0.0000) | Acc: (89.00%) (2402/2688)
Epoch: 74 | Batch_idx: 30 |  Loss: (0.2912) |  Loss2: (0.0000) | Acc: (89.00%) (3557/3968)
Epoch: 74 | Batch_idx: 40 |  Loss: (0.2851) |  Loss2: (0.0000) | Acc: (89.00%) (4716/5248)
Epoch: 74 | Batch_idx: 50 |  Loss: (0.2851) |  Loss2: (0.0000) | Acc: (89.00%) (5872/6528)
Epoch: 74 | Batch_idx: 60 |  Loss: (0.2849) |  Loss2: (0.0000) | Acc: (89.00%) (7020/7808)
Epoch: 74 | Batch_idx: 70 |  Loss: (0.2849) |  Loss2: (0.0000) | Acc: (89.00%) (8168/9088)
Epoch: 74 | Batch_idx: 80 |  Loss: (0.2839) |  Loss2: (0.0000) | Acc: (90.00%) (9333/10368)
Epoch: 74 | Batch_idx: 90 |  Loss: (0.2832) |  Loss2: (0.0000) | Acc: (90.00%) (10495/11648)
Epoch: 74 | Batch_idx: 100 |  Loss: (0.2832) |  Loss2: (0.0000) | Acc: (90.00%) (11657/12928)
Epoch: 74 | Batch_idx: 110 |  Loss: (0.2842) |  Loss2: (0.0000) | Acc: (90.00%) (12797/14208)
Epoch: 74 | Batch_idx: 120 |  Loss: (0.2863) |  Loss2: (0.0000) | Acc: (90.00%) (13945/15488)
Epoch: 74 | Batch_idx: 130 |  Loss: (0.2845) |  Loss2: (0.0000) | Acc: (90.00%) (15111/16768)
Epoch: 74 | Batch_idx: 140 |  Loss: (0.2838) |  Loss2: (0.0000) | Acc: (90.00%) (16276/18048)
Epoch: 74 | Batch_idx: 150 |  Loss: (0.2839) |  Loss2: (0.0000) | Acc: (90.00%) (17426/19328)
Epoch: 74 | Batch_idx: 160 |  Loss: (0.2840) |  Loss2: (0.0000) | Acc: (90.00%) (18579/20608)
Epoch: 74 | Batch_idx: 170 |  Loss: (0.2832) |  Loss2: (0.0000) | Acc: (90.00%) (19732/21888)
Epoch: 74 | Batch_idx: 180 |  Loss: (0.2820) |  Loss2: (0.0000) | Acc: (90.00%) (20897/23168)
Epoch: 74 | Batch_idx: 190 |  Loss: (0.2827) |  Loss2: (0.0000) | Acc: (90.00%) (22042/24448)
Epoch: 74 | Batch_idx: 200 |  Loss: (0.2827) |  Loss2: (0.0000) | Acc: (90.00%) (23197/25728)
Epoch: 74 | Batch_idx: 210 |  Loss: (0.2825) |  Loss2: (0.0000) | Acc: (90.00%) (24362/27008)
Epoch: 74 | Batch_idx: 220 |  Loss: (0.2834) |  Loss2: (0.0000) | Acc: (90.00%) (25510/28288)
Epoch: 74 | Batch_idx: 230 |  Loss: (0.2824) |  Loss2: (0.0000) | Acc: (90.00%) (26677/29568)
Epoch: 74 | Batch_idx: 240 |  Loss: (0.2822) |  Loss2: (0.0000) | Acc: (90.00%) (27835/30848)
Epoch: 74 | Batch_idx: 250 |  Loss: (0.2826) |  Loss2: (0.0000) | Acc: (90.00%) (29003/32128)
Epoch: 74 | Batch_idx: 260 |  Loss: (0.2832) |  Loss2: (0.0000) | Acc: (90.00%) (30145/33408)
Epoch: 74 | Batch_idx: 270 |  Loss: (0.2835) |  Loss2: (0.0000) | Acc: (90.00%) (31297/34688)
Epoch: 74 | Batch_idx: 280 |  Loss: (0.2839) |  Loss2: (0.0000) | Acc: (90.00%) (32437/35968)
Epoch: 74 | Batch_idx: 290 |  Loss: (0.2834) |  Loss2: (0.0000) | Acc: (90.00%) (33591/37248)
Epoch: 74 | Batch_idx: 300 |  Loss: (0.2842) |  Loss2: (0.0000) | Acc: (90.00%) (34735/38528)
Epoch: 74 | Batch_idx: 310 |  Loss: (0.2841) |  Loss2: (0.0000) | Acc: (90.00%) (35896/39808)
Epoch: 74 | Batch_idx: 320 |  Loss: (0.2831) |  Loss2: (0.0000) | Acc: (90.00%) (37073/41088)
Epoch: 74 | Batch_idx: 330 |  Loss: (0.2841) |  Loss2: (0.0000) | Acc: (90.00%) (38206/42368)
Epoch: 74 | Batch_idx: 340 |  Loss: (0.2835) |  Loss2: (0.0000) | Acc: (90.00%) (39371/43648)
Epoch: 74 | Batch_idx: 350 |  Loss: (0.2826) |  Loss2: (0.0000) | Acc: (90.00%) (40539/44928)
Epoch: 74 | Batch_idx: 360 |  Loss: (0.2828) |  Loss2: (0.0000) | Acc: (90.00%) (41698/46208)
Epoch: 74 | Batch_idx: 370 |  Loss: (0.2821) |  Loss2: (0.0000) | Acc: (90.00%) (42871/47488)
Epoch: 74 | Batch_idx: 380 |  Loss: (0.2823) |  Loss2: (0.0000) | Acc: (90.00%) (44028/48768)
Epoch: 74 | Batch_idx: 390 |  Loss: (0.2829) |  Loss2: (0.0000) | Acc: (90.00%) (45118/50000)
# TEST : Loss: (0.4170) | Acc: (85.00%) (8589/10000)
percent tensor([0.5846, 0.5813, 0.5936, 0.5841, 0.5975, 0.5831, 0.5889, 0.5847, 0.5849,
        0.5830, 0.5803, 0.5916, 0.5808, 0.5732, 0.5835, 0.5805],
       device='cuda:0') torch.Size([16])
percent tensor([0.5560, 0.5293, 0.5292, 0.5660, 0.5472, 0.5890, 0.5356, 0.5539, 0.5429,
        0.5300, 0.5356, 0.5277, 0.5304, 0.5652, 0.5546, 0.5605],
       device='cuda:0') torch.Size([16])
percent tensor([0.5050, 0.5259, 0.4948, 0.4629, 0.5046, 0.4595, 0.5405, 0.5065, 0.5110,
        0.5045, 0.5086, 0.5153, 0.5205, 0.5193, 0.5029, 0.5019],
       device='cuda:0') torch.Size([16])
percent tensor([0.6128, 0.5879, 0.5862, 0.5996, 0.5950, 0.6258, 0.5939, 0.5907, 0.6027,
        0.5980, 0.6041, 0.5877, 0.6066, 0.6084, 0.5999, 0.6239],
       device='cuda:0') torch.Size([16])
percent tensor([0.5616, 0.6459, 0.6084, 0.6241, 0.5596, 0.6217, 0.5938, 0.4966, 0.6838,
        0.5685, 0.6745, 0.6464, 0.6953, 0.7047, 0.5648, 0.6006],
       device='cuda:0') torch.Size([16])
percent tensor([0.6768, 0.6534, 0.7330, 0.7460, 0.7592, 0.7556, 0.7183, 0.6677, 0.7395,
        0.6716, 0.7171, 0.6969, 0.6745, 0.7971, 0.6489, 0.7176],
       device='cuda:0') torch.Size([16])
percent tensor([0.6341, 0.5669, 0.6790, 0.6485, 0.7365, 0.6306, 0.6557, 0.7090, 0.6014,
        0.6080, 0.5769, 0.5699, 0.4636, 0.6023, 0.6233, 0.6872],
       device='cuda:0') torch.Size([16])
percent tensor([0.9987, 0.9975, 0.9980, 0.9989, 0.9986, 0.9975, 0.9982, 0.9987, 0.9977,
        0.9988, 0.9979, 0.9983, 0.9981, 0.9988, 0.9979, 0.9988],
       device='cuda:0') torch.Size([16])
False Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=128, out_features=16, bias=False)
True Linear(in_features=16, out_features=2, bias=False)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=128, out_features=16, bias=False)
True Linear(in_features=16, out_features=2, bias=False)
False Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=256, out_features=32, bias=False)
True Linear(in_features=32, out_features=2, bias=False)
False Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=256, out_features=32, bias=False)
True Linear(in_features=32, out_features=2, bias=False)
False Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=512, out_features=64, bias=False)
True Linear(in_features=64, out_features=2, bias=False)
False Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=512, out_features=64, bias=False)
True Linear(in_features=64, out_features=2, bias=False)
False Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1024, out_features=128, bias=False)
True Linear(in_features=128, out_features=2, bias=False)
False Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1024, out_features=128, bias=False)
True Linear(in_features=128, out_features=2, bias=False)
False Linear(in_features=512, out_features=10, bias=True)
Epoch: 75 | Batch_idx: 0 |  Loss: (0.3179) |  Loss2: (0.0000) | Acc: (89.00%) (114/128)
Epoch: 75 | Batch_idx: 10 |  Loss: (0.2912) |  Loss2: (0.0000) | Acc: (89.00%) (1262/1408)
Epoch: 75 | Batch_idx: 20 |  Loss: (0.3062) |  Loss2: (0.0000) | Acc: (89.00%) (2395/2688)
Epoch: 75 | Batch_idx: 30 |  Loss: (0.3187) |  Loss2: (0.0000) | Acc: (88.00%) (3527/3968)
Epoch: 75 | Batch_idx: 40 |  Loss: (0.3251) |  Loss2: (0.0000) | Acc: (88.00%) (4653/5248)
Epoch: 75 | Batch_idx: 50 |  Loss: (0.3268) |  Loss2: (0.0000) | Acc: (88.00%) (5792/6528)
Epoch: 75 | Batch_idx: 60 |  Loss: (0.3279) |  Loss2: (0.0000) | Acc: (88.00%) (6923/7808)
Epoch: 75 | Batch_idx: 70 |  Loss: (0.3321) |  Loss2: (0.0000) | Acc: (88.00%) (8050/9088)
Epoch: 75 | Batch_idx: 80 |  Loss: (0.3369) |  Loss2: (0.0000) | Acc: (88.00%) (9163/10368)
Epoch: 75 | Batch_idx: 90 |  Loss: (0.3402) |  Loss2: (0.0000) | Acc: (88.00%) (10280/11648)
Epoch: 75 | Batch_idx: 100 |  Loss: (0.3347) |  Loss2: (0.0000) | Acc: (88.00%) (11422/12928)
Epoch: 75 | Batch_idx: 110 |  Loss: (0.3365) |  Loss2: (0.0000) | Acc: (88.00%) (12546/14208)
Epoch: 75 | Batch_idx: 120 |  Loss: (0.3401) |  Loss2: (0.0000) | Acc: (88.00%) (13657/15488)
Epoch: 75 | Batch_idx: 130 |  Loss: (0.3402) |  Loss2: (0.0000) | Acc: (88.00%) (14783/16768)
Epoch: 75 | Batch_idx: 140 |  Loss: (0.3389) |  Loss2: (0.0000) | Acc: (88.00%) (15925/18048)
Epoch: 75 | Batch_idx: 150 |  Loss: (0.3359) |  Loss2: (0.0000) | Acc: (88.00%) (17077/19328)
Epoch: 75 | Batch_idx: 160 |  Loss: (0.3377) |  Loss2: (0.0000) | Acc: (88.00%) (18191/20608)
Epoch: 75 | Batch_idx: 170 |  Loss: (0.3378) |  Loss2: (0.0000) | Acc: (88.00%) (19323/21888)
Epoch: 75 | Batch_idx: 180 |  Loss: (0.3358) |  Loss2: (0.0000) | Acc: (88.00%) (20469/23168)
Epoch: 75 | Batch_idx: 190 |  Loss: (0.3366) |  Loss2: (0.0000) | Acc: (88.00%) (21592/24448)
Epoch: 75 | Batch_idx: 200 |  Loss: (0.3344) |  Loss2: (0.0000) | Acc: (88.00%) (22741/25728)
Epoch: 75 | Batch_idx: 210 |  Loss: (0.3314) |  Loss2: (0.0000) | Acc: (88.00%) (23896/27008)
Epoch: 75 | Batch_idx: 220 |  Loss: (0.3316) |  Loss2: (0.0000) | Acc: (88.00%) (25021/28288)
Epoch: 75 | Batch_idx: 230 |  Loss: (0.3315) |  Loss2: (0.0000) | Acc: (88.00%) (26163/29568)
Epoch: 75 | Batch_idx: 240 |  Loss: (0.3305) |  Loss2: (0.0000) | Acc: (88.00%) (27309/30848)
Epoch: 75 | Batch_idx: 250 |  Loss: (0.3302) |  Loss2: (0.0000) | Acc: (88.00%) (28447/32128)
Epoch: 75 | Batch_idx: 260 |  Loss: (0.3296) |  Loss2: (0.0000) | Acc: (88.00%) (29583/33408)
Epoch: 75 | Batch_idx: 270 |  Loss: (0.3283) |  Loss2: (0.0000) | Acc: (88.00%) (30727/34688)
Epoch: 75 | Batch_idx: 280 |  Loss: (0.3284) |  Loss2: (0.0000) | Acc: (88.00%) (31851/35968)
Epoch: 75 | Batch_idx: 290 |  Loss: (0.3282) |  Loss2: (0.0000) | Acc: (88.00%) (32981/37248)
Epoch: 75 | Batch_idx: 300 |  Loss: (0.3280) |  Loss2: (0.0000) | Acc: (88.00%) (34108/38528)
Epoch: 75 | Batch_idx: 310 |  Loss: (0.3278) |  Loss2: (0.0000) | Acc: (88.00%) (35237/39808)
Epoch: 75 | Batch_idx: 320 |  Loss: (0.3293) |  Loss2: (0.0000) | Acc: (88.00%) (36347/41088)
Epoch: 75 | Batch_idx: 330 |  Loss: (0.3287) |  Loss2: (0.0000) | Acc: (88.00%) (37493/42368)
Epoch: 75 | Batch_idx: 340 |  Loss: (0.3283) |  Loss2: (0.0000) | Acc: (88.00%) (38637/43648)
Epoch: 75 | Batch_idx: 350 |  Loss: (0.3277) |  Loss2: (0.0000) | Acc: (88.00%) (39784/44928)
Epoch: 75 | Batch_idx: 360 |  Loss: (0.3269) |  Loss2: (0.0000) | Acc: (88.00%) (40937/46208)
Epoch: 75 | Batch_idx: 370 |  Loss: (0.3269) |  Loss2: (0.0000) | Acc: (88.00%) (42068/47488)
Epoch: 75 | Batch_idx: 380 |  Loss: (0.3279) |  Loss2: (0.0000) | Acc: (88.00%) (43181/48768)
Epoch: 75 | Batch_idx: 390 |  Loss: (0.3276) |  Loss2: (0.0000) | Acc: (88.00%) (44292/50000)
=> saving checkpoint 'drive/app/torch/save_Routing_Gate_2/checkpoint_075.pth.tar'
# TEST : Loss: (0.4548) | Acc: (85.00%) (8502/10000)


Files already downloaded and verified
USE 1 GPUs!
=> loading checkpoint 'drive/app/torch/save_Routing_Gate_2/checkpoint_075.pth.tar'

Epoch: 76 | Batch_idx: 0 |  Loss: (0.2824) |  Loss2: (0.0000) | Acc: (89.00%) (115/128)
Epoch: 76 | Batch_idx: 10 |  Loss: (0.3195) |  Loss2: (0.0000) | Acc: (87.00%) (1239/1408)
Epoch: 76 | Batch_idx: 20 |  Loss: (0.3180) |  Loss2: (0.0000) | Acc: (88.00%) (2373/2688)
Epoch: 76 | Batch_idx: 30 |  Loss: (0.3145) |  Loss2: (0.0000) | Acc: (88.00%) (3510/3968)
Epoch: 76 | Batch_idx: 40 |  Loss: (0.3088) |  Loss2: (0.0000) | Acc: (88.00%) (4654/5248)
Epoch: 76 | Batch_idx: 50 |  Loss: (0.3081) |  Loss2: (0.0000) | Acc: (88.00%) (5796/6528)
Epoch: 76 | Batch_idx: 60 |  Loss: (0.3090) |  Loss2: (0.0000) | Acc: (88.00%) (6941/7808)
Epoch: 76 | Batch_idx: 70 |  Loss: (0.3143) |  Loss2: (0.0000) | Acc: (88.00%) (8062/9088)
Epoch: 76 | Batch_idx: 80 |  Loss: (0.3181) |  Loss2: (0.0000) | Acc: (88.00%) (9200/10368)
Epoch: 76 | Batch_idx: 90 |  Loss: (0.3151) |  Loss2: (0.0000) | Acc: (88.00%) (10355/11648)
Epoch: 76 | Batch_idx: 100 |  Loss: (0.3087) |  Loss2: (0.0000) | Acc: (89.00%) (11521/12928)
Epoch: 76 | Batch_idx: 110 |  Loss: (0.3086) |  Loss2: (0.0000) | Acc: (89.00%) (12672/14208)
Epoch: 76 | Batch_idx: 120 |  Loss: (0.3064) |  Loss2: (0.0000) | Acc: (89.00%) (13833/15488)
Epoch: 76 | Batch_idx: 130 |  Loss: (0.3096) |  Loss2: (0.0000) | Acc: (89.00%) (14971/16768)
Epoch: 76 | Batch_idx: 140 |  Loss: (0.3075) |  Loss2: (0.0000) | Acc: (89.00%) (16131/18048)
Epoch: 76 | Batch_idx: 150 |  Loss: (0.3039) |  Loss2: (0.0000) | Acc: (89.00%) (17299/19328)
Epoch: 76 | Batch_idx: 160 |  Loss: (0.3041) |  Loss2: (0.0000) | Acc: (89.00%) (18448/20608)
Epoch: 76 | Batch_idx: 170 |  Loss: (0.3042) |  Loss2: (0.0000) | Acc: (89.00%) (19594/21888)
Epoch: 76 | Batch_idx: 180 |  Loss: (0.3053) |  Loss2: (0.0000) | Acc: (89.00%) (20732/23168)
Epoch: 76 | Batch_idx: 190 |  Loss: (0.3046) |  Loss2: (0.0000) | Acc: (89.00%) (21877/24448)
Epoch: 76 | Batch_idx: 200 |  Loss: (0.3040) |  Loss2: (0.0000) | Acc: (89.00%) (23037/25728)
Epoch: 76 | Batch_idx: 210 |  Loss: (0.3037) |  Loss2: (0.0000) | Acc: (89.00%) (24186/27008)
Epoch: 76 | Batch_idx: 220 |  Loss: (0.3040) |  Loss2: (0.0000) | Acc: (89.00%) (25321/28288)
Epoch: 76 | Batch_idx: 230 |  Loss: (0.3034) |  Loss2: (0.0000) | Acc: (89.00%) (26469/29568)
Epoch: 76 | Batch_idx: 240 |  Loss: (0.3031) |  Loss2: (0.0000) | Acc: (89.00%) (27624/30848)
Epoch: 76 | Batch_idx: 250 |  Loss: (0.3033) |  Loss2: (0.0000) | Acc: (89.00%) (28767/32128)
Epoch: 76 | Batch_idx: 260 |  Loss: (0.3025) |  Loss2: (0.0000) | Acc: (89.00%) (29927/33408)
Epoch: 76 | Batch_idx: 270 |  Loss: (0.3027) |  Loss2: (0.0000) | Acc: (89.00%) (31064/34688)
Epoch: 76 | Batch_idx: 280 |  Loss: (0.3039) |  Loss2: (0.0000) | Acc: (89.00%) (32192/35968)
Epoch: 76 | Batch_idx: 290 |  Loss: (0.3038) |  Loss2: (0.0000) | Acc: (89.00%) (33334/37248)
Epoch: 76 | Batch_idx: 300 |  Loss: (0.3032) |  Loss2: (0.0000) | Acc: (89.00%) (34489/38528)
Epoch: 76 | Batch_idx: 310 |  Loss: (0.3025) |  Loss2: (0.0000) | Acc: (89.00%) (35655/39808)
Epoch: 76 | Batch_idx: 320 |  Loss: (0.3024) |  Loss2: (0.0000) | Acc: (89.00%) (36803/41088)
Epoch: 76 | Batch_idx: 330 |  Loss: (0.3023) |  Loss2: (0.0000) | Acc: (89.00%) (37946/42368)
Epoch: 76 | Batch_idx: 340 |  Loss: (0.3017) |  Loss2: (0.0000) | Acc: (89.00%) (39100/43648)
Epoch: 76 | Batch_idx: 350 |  Loss: (0.3014) |  Loss2: (0.0000) | Acc: (89.00%) (40257/44928)
Epoch: 76 | Batch_idx: 360 |  Loss: (0.3005) |  Loss2: (0.0000) | Acc: (89.00%) (41417/46208)
Epoch: 76 | Batch_idx: 370 |  Loss: (0.2998) |  Loss2: (0.0000) | Acc: (89.00%) (42579/47488)
Epoch: 76 | Batch_idx: 380 |  Loss: (0.2998) |  Loss2: (0.0000) | Acc: (89.00%) (43718/48768)
Epoch: 76 | Batch_idx: 390 |  Loss: (0.2996) |  Loss2: (0.0000) | Acc: (89.00%) (44823/50000)
# TEST : Loss: (0.4314) | Acc: (85.00%) (8577/10000)
percent tensor([0.5927, 0.5829, 0.6015, 0.5869, 0.6056, 0.5895, 0.5932, 0.5875, 0.5918,
        0.5872, 0.5864, 0.5999, 0.5870, 0.5703, 0.5882, 0.5849],
       device='cuda:0') torch.Size([16])
percent tensor([0.5702, 0.5389, 0.5311, 0.5821, 0.5585, 0.6124, 0.5449, 0.5668, 0.5537,
        0.5383, 0.5474, 0.5321, 0.5392, 0.5816, 0.5717, 0.5759],
       device='cuda:0') torch.Size([16])
percent tensor([0.5089, 0.5328, 0.5010, 0.4708, 0.5084, 0.4664, 0.5434, 0.5112, 0.5126,
        0.5112, 0.5140, 0.5200, 0.5262, 0.5203, 0.5075, 0.5073],
       device='cuda:0') torch.Size([16])
percent tensor([0.6116, 0.5825, 0.5898, 0.5984, 0.6004, 0.6217, 0.5969, 0.5995, 0.6015,
        0.5920, 0.5997, 0.5886, 0.6018, 0.6025, 0.6001, 0.6175],
       device='cuda:0') torch.Size([16])
percent tensor([0.5812, 0.6802, 0.6178, 0.6304, 0.5485, 0.6208, 0.6162, 0.4752, 0.7005,
        0.6154, 0.7012, 0.6807, 0.7275, 0.7394, 0.5725, 0.6184],
       device='cuda:0') torch.Size([16])
percent tensor([0.6642, 0.6359, 0.7183, 0.7236, 0.7416, 0.7490, 0.6930, 0.6555, 0.7233,
        0.6555, 0.6899, 0.6857, 0.6660, 0.7728, 0.6406, 0.7000],
       device='cuda:0') torch.Size([16])
percent tensor([0.6714, 0.5869, 0.6849, 0.6481, 0.7476, 0.6598, 0.6620, 0.7151, 0.6169,
        0.6396, 0.5928, 0.5976, 0.5436, 0.6157, 0.6405, 0.7209],
       device='cuda:0') torch.Size([16])
percent tensor([0.9989, 0.9977, 0.9985, 0.9991, 0.9987, 0.9983, 0.9983, 0.9988, 0.9981,
        0.9990, 0.9980, 0.9985, 0.9986, 0.9988, 0.9982, 0.9989],
       device='cuda:0') torch.Size([16])
Epoch: 77 | Batch_idx: 0 |  Loss: (0.2219) |  Loss2: (0.0000) | Acc: (92.00%) (119/128)
Epoch: 77 | Batch_idx: 10 |  Loss: (0.2660) |  Loss2: (0.0000) | Acc: (90.00%) (1277/1408)
Epoch: 77 | Batch_idx: 20 |  Loss: (0.2806) |  Loss2: (0.0000) | Acc: (90.00%) (2420/2688)
Epoch: 77 | Batch_idx: 30 |  Loss: (0.2865) |  Loss2: (0.0000) | Acc: (90.00%) (3576/3968)
Epoch: 77 | Batch_idx: 40 |  Loss: (0.2804) |  Loss2: (0.0000) | Acc: (90.00%) (4740/5248)
Epoch: 77 | Batch_idx: 50 |  Loss: (0.2884) |  Loss2: (0.0000) | Acc: (89.00%) (5875/6528)
Epoch: 77 | Batch_idx: 60 |  Loss: (0.2890) |  Loss2: (0.0000) | Acc: (90.00%) (7028/7808)
Epoch: 77 | Batch_idx: 70 |  Loss: (0.2872) |  Loss2: (0.0000) | Acc: (90.00%) (8186/9088)
Epoch: 77 | Batch_idx: 80 |  Loss: (0.2880) |  Loss2: (0.0000) | Acc: (90.00%) (9333/10368)
Epoch: 77 | Batch_idx: 90 |  Loss: (0.2867) |  Loss2: (0.0000) | Acc: (89.00%) (10480/11648)
Epoch: 77 | Batch_idx: 100 |  Loss: (0.2859) |  Loss2: (0.0000) | Acc: (90.00%) (11647/12928)
Epoch: 77 | Batch_idx: 110 |  Loss: (0.2857) |  Loss2: (0.0000) | Acc: (90.00%) (12799/14208)
Epoch: 77 | Batch_idx: 120 |  Loss: (0.2867) |  Loss2: (0.0000) | Acc: (90.00%) (13949/15488)
Epoch: 77 | Batch_idx: 130 |  Loss: (0.2869) |  Loss2: (0.0000) | Acc: (90.00%) (15095/16768)
Epoch: 77 | Batch_idx: 140 |  Loss: (0.2867) |  Loss2: (0.0000) | Acc: (90.00%) (16257/18048)
Epoch: 77 | Batch_idx: 150 |  Loss: (0.2860) |  Loss2: (0.0000) | Acc: (90.00%) (17402/19328)
Epoch: 77 | Batch_idx: 160 |  Loss: (0.2864) |  Loss2: (0.0000) | Acc: (90.00%) (18554/20608)
Epoch: 77 | Batch_idx: 170 |  Loss: (0.2873) |  Loss2: (0.0000) | Acc: (90.00%) (19704/21888)
Epoch: 77 | Batch_idx: 180 |  Loss: (0.2855) |  Loss2: (0.0000) | Acc: (90.00%) (20876/23168)
Epoch: 77 | Batch_idx: 190 |  Loss: (0.2844) |  Loss2: (0.0000) | Acc: (90.00%) (22031/24448)
Epoch: 77 | Batch_idx: 200 |  Loss: (0.2848) |  Loss2: (0.0000) | Acc: (90.00%) (23177/25728)
Epoch: 77 | Batch_idx: 210 |  Loss: (0.2848) |  Loss2: (0.0000) | Acc: (90.00%) (24340/27008)
Epoch: 77 | Batch_idx: 220 |  Loss: (0.2840) |  Loss2: (0.0000) | Acc: (90.00%) (25495/28288)
Epoch: 77 | Batch_idx: 230 |  Loss: (0.2841) |  Loss2: (0.0000) | Acc: (90.00%) (26655/29568)
Epoch: 77 | Batch_idx: 240 |  Loss: (0.2839) |  Loss2: (0.0000) | Acc: (90.00%) (27815/30848)
Epoch: 77 | Batch_idx: 250 |  Loss: (0.2833) |  Loss2: (0.0000) | Acc: (90.00%) (28977/32128)
Epoch: 77 | Batch_idx: 260 |  Loss: (0.2829) |  Loss2: (0.0000) | Acc: (90.00%) (30130/33408)
Epoch: 77 | Batch_idx: 270 |  Loss: (0.2832) |  Loss2: (0.0000) | Acc: (90.00%) (31284/34688)
Epoch: 77 | Batch_idx: 280 |  Loss: (0.2834) |  Loss2: (0.0000) | Acc: (90.00%) (32445/35968)
Epoch: 77 | Batch_idx: 290 |  Loss: (0.2844) |  Loss2: (0.0000) | Acc: (90.00%) (33596/37248)
Epoch: 77 | Batch_idx: 300 |  Loss: (0.2843) |  Loss2: (0.0000) | Acc: (90.00%) (34757/38528)
Epoch: 77 | Batch_idx: 310 |  Loss: (0.2839) |  Loss2: (0.0000) | Acc: (90.00%) (35916/39808)
Epoch: 77 | Batch_idx: 320 |  Loss: (0.2835) |  Loss2: (0.0000) | Acc: (90.00%) (37075/41088)
Epoch: 77 | Batch_idx: 330 |  Loss: (0.2833) |  Loss2: (0.0000) | Acc: (90.00%) (38234/42368)
Epoch: 77 | Batch_idx: 340 |  Loss: (0.2834) |  Loss2: (0.0000) | Acc: (90.00%) (39385/43648)
Epoch: 77 | Batch_idx: 350 |  Loss: (0.2832) |  Loss2: (0.0000) | Acc: (90.00%) (40543/44928)
Epoch: 77 | Batch_idx: 360 |  Loss: (0.2835) |  Loss2: (0.0000) | Acc: (90.00%) (41698/46208)
Epoch: 77 | Batch_idx: 370 |  Loss: (0.2831) |  Loss2: (0.0000) | Acc: (90.00%) (42865/47488)
Epoch: 77 | Batch_idx: 380 |  Loss: (0.2832) |  Loss2: (0.0000) | Acc: (90.00%) (44014/48768)
Epoch: 77 | Batch_idx: 390 |  Loss: (0.2826) |  Loss2: (0.0000) | Acc: (90.00%) (45132/50000)
# TEST : Loss: (0.4205) | Acc: (85.00%) (8591/10000)
percent tensor([0.5896, 0.5786, 0.5990, 0.5830, 0.6030, 0.5867, 0.5898, 0.5834, 0.5888,
        0.5834, 0.5832, 0.5972, 0.5835, 0.5657, 0.5847, 0.5811],
       device='cuda:0') torch.Size([16])
percent tensor([0.5684, 0.5371, 0.5248, 0.5800, 0.5549, 0.6122, 0.5427, 0.5633, 0.5518,
        0.5353, 0.5457, 0.5275, 0.5362, 0.5835, 0.5703, 0.5749],
       device='cuda:0') torch.Size([16])
percent tensor([0.5070, 0.5331, 0.4995, 0.4693, 0.5073, 0.4656, 0.5427, 0.5095, 0.5114,
        0.5099, 0.5123, 0.5184, 0.5248, 0.5198, 0.5066, 0.5058],
       device='cuda:0') torch.Size([16])
percent tensor([0.6117, 0.5818, 0.5905, 0.5994, 0.6020, 0.6216, 0.5981, 0.6018, 0.6018,
        0.5907, 0.5994, 0.5890, 0.6008, 0.6017, 0.6014, 0.6170],
       device='cuda:0') torch.Size([16])
percent tensor([0.5837, 0.6872, 0.6258, 0.6370, 0.5493, 0.6228, 0.6192, 0.4751, 0.7083,
        0.6228, 0.7035, 0.6891, 0.7345, 0.7500, 0.5745, 0.6229],
       device='cuda:0') torch.Size([16])
percent tensor([0.6581, 0.6317, 0.7161, 0.7205, 0.7403, 0.7485, 0.6885, 0.6512, 0.7196,
        0.6522, 0.6838, 0.6814, 0.6581, 0.7721, 0.6356, 0.6952],
       device='cuda:0') torch.Size([16])
percent tensor([0.6681, 0.5888, 0.6829, 0.6444, 0.7492, 0.6649, 0.6592, 0.7054, 0.6176,
        0.6360, 0.5950, 0.5952, 0.5495, 0.6209, 0.6325, 0.7161],
       device='cuda:0') torch.Size([16])
percent tensor([0.9989, 0.9978, 0.9984, 0.9991, 0.9987, 0.9984, 0.9983, 0.9988, 0.9981,
        0.9990, 0.9980, 0.9985, 0.9986, 0.9988, 0.9983, 0.9989],
       device='cuda:0') torch.Size([16])
Epoch: 78 | Batch_idx: 0 |  Loss: (0.2663) |  Loss2: (0.0000) | Acc: (91.00%) (117/128)
Epoch: 78 | Batch_idx: 10 |  Loss: (0.2762) |  Loss2: (0.0000) | Acc: (90.00%) (1275/1408)
Epoch: 78 | Batch_idx: 20 |  Loss: (0.2771) |  Loss2: (0.0000) | Acc: (90.00%) (2426/2688)
Epoch: 78 | Batch_idx: 30 |  Loss: (0.2748) |  Loss2: (0.0000) | Acc: (90.00%) (3593/3968)
Epoch: 78 | Batch_idx: 40 |  Loss: (0.2785) |  Loss2: (0.0000) | Acc: (90.00%) (4749/5248)
Epoch: 78 | Batch_idx: 50 |  Loss: (0.2752) |  Loss2: (0.0000) | Acc: (90.00%) (5913/6528)
Epoch: 78 | Batch_idx: 60 |  Loss: (0.2724) |  Loss2: (0.0000) | Acc: (90.00%) (7088/7808)
Epoch: 78 | Batch_idx: 70 |  Loss: (0.2774) |  Loss2: (0.0000) | Acc: (90.00%) (8230/9088)
Epoch: 78 | Batch_idx: 80 |  Loss: (0.2786) |  Loss2: (0.0000) | Acc: (90.00%) (9382/10368)
Epoch: 78 | Batch_idx: 90 |  Loss: (0.2771) |  Loss2: (0.0000) | Acc: (90.00%) (10547/11648)
Epoch: 78 | Batch_idx: 100 |  Loss: (0.2740) |  Loss2: (0.0000) | Acc: (90.00%) (11725/12928)
Epoch: 78 | Batch_idx: 110 |  Loss: (0.2725) |  Loss2: (0.0000) | Acc: (90.00%) (12890/14208)
Epoch: 78 | Batch_idx: 120 |  Loss: (0.2724) |  Loss2: (0.0000) | Acc: (90.00%) (14042/15488)
Epoch: 78 | Batch_idx: 130 |  Loss: (0.2717) |  Loss2: (0.0000) | Acc: (90.00%) (15214/16768)
Epoch: 78 | Batch_idx: 140 |  Loss: (0.2733) |  Loss2: (0.0000) | Acc: (90.00%) (16361/18048)
Epoch: 78 | Batch_idx: 150 |  Loss: (0.2720) |  Loss2: (0.0000) | Acc: (90.00%) (17532/19328)
Epoch: 78 | Batch_idx: 160 |  Loss: (0.2726) |  Loss2: (0.0000) | Acc: (90.00%) (18686/20608)
Epoch: 78 | Batch_idx: 170 |  Loss: (0.2735) |  Loss2: (0.0000) | Acc: (90.00%) (19832/21888)
Epoch: 78 | Batch_idx: 180 |  Loss: (0.2746) |  Loss2: (0.0000) | Acc: (90.00%) (20985/23168)
Epoch: 78 | Batch_idx: 190 |  Loss: (0.2722) |  Loss2: (0.0000) | Acc: (90.00%) (22166/24448)
Epoch: 78 | Batch_idx: 200 |  Loss: (0.2728) |  Loss2: (0.0000) | Acc: (90.00%) (23316/25728)
Epoch: 78 | Batch_idx: 210 |  Loss: (0.2731) |  Loss2: (0.0000) | Acc: (90.00%) (24470/27008)
Epoch: 78 | Batch_idx: 220 |  Loss: (0.2724) |  Loss2: (0.0000) | Acc: (90.00%) (25639/28288)
Epoch: 78 | Batch_idx: 230 |  Loss: (0.2727) |  Loss2: (0.0000) | Acc: (90.00%) (26779/29568)
Epoch: 78 | Batch_idx: 240 |  Loss: (0.2735) |  Loss2: (0.0000) | Acc: (90.00%) (27932/30848)
Epoch: 78 | Batch_idx: 250 |  Loss: (0.2739) |  Loss2: (0.0000) | Acc: (90.00%) (29088/32128)
Epoch: 78 | Batch_idx: 260 |  Loss: (0.2743) |  Loss2: (0.0000) | Acc: (90.00%) (30245/33408)
Epoch: 78 | Batch_idx: 270 |  Loss: (0.2741) |  Loss2: (0.0000) | Acc: (90.00%) (31399/34688)
Epoch: 78 | Batch_idx: 280 |  Loss: (0.2749) |  Loss2: (0.0000) | Acc: (90.00%) (32549/35968)
Epoch: 78 | Batch_idx: 290 |  Loss: (0.2748) |  Loss2: (0.0000) | Acc: (90.00%) (33704/37248)
Epoch: 78 | Batch_idx: 300 |  Loss: (0.2747) |  Loss2: (0.0000) | Acc: (90.00%) (34863/38528)
Epoch: 78 | Batch_idx: 310 |  Loss: (0.2750) |  Loss2: (0.0000) | Acc: (90.00%) (36017/39808)
Epoch: 78 | Batch_idx: 320 |  Loss: (0.2742) |  Loss2: (0.0000) | Acc: (90.00%) (37184/41088)
Epoch: 78 | Batch_idx: 330 |  Loss: (0.2746) |  Loss2: (0.0000) | Acc: (90.00%) (38336/42368)
Epoch: 78 | Batch_idx: 340 |  Loss: (0.2751) |  Loss2: (0.0000) | Acc: (90.00%) (39479/43648)
Epoch: 78 | Batch_idx: 350 |  Loss: (0.2751) |  Loss2: (0.0000) | Acc: (90.00%) (40649/44928)
Epoch: 78 | Batch_idx: 360 |  Loss: (0.2758) |  Loss2: (0.0000) | Acc: (90.00%) (41803/46208)
Epoch: 78 | Batch_idx: 370 |  Loss: (0.2761) |  Loss2: (0.0000) | Acc: (90.00%) (42959/47488)
Epoch: 78 | Batch_idx: 380 |  Loss: (0.2763) |  Loss2: (0.0000) | Acc: (90.00%) (44110/48768)
Epoch: 78 | Batch_idx: 390 |  Loss: (0.2767) |  Loss2: (0.0000) | Acc: (90.00%) (45212/50000)
# TEST : Loss: (0.4140) | Acc: (86.00%) (8611/10000)
percent tensor([0.5923, 0.5798, 0.6018, 0.5845, 0.6059, 0.5891, 0.5919, 0.5850, 0.5913,
        0.5850, 0.5855, 0.5999, 0.5857, 0.5663, 0.5864, 0.5829],
       device='cuda:0') torch.Size([16])
percent tensor([0.5637, 0.5319, 0.5177, 0.5752, 0.5489, 0.6098, 0.5374, 0.5573, 0.5470,
        0.5291, 0.5410, 0.5203, 0.5305, 0.5808, 0.5657, 0.5707],
       device='cuda:0') torch.Size([16])
percent tensor([0.5102, 0.5389, 0.5032, 0.4719, 0.5115, 0.4675, 0.5477, 0.5148, 0.5155,
        0.5150, 0.5166, 0.5235, 0.5299, 0.5234, 0.5119, 0.5094],
       device='cuda:0') torch.Size([16])
percent tensor([0.6132, 0.5831, 0.5927, 0.6013, 0.6050, 0.6222, 0.6009, 0.6057, 0.6037,
        0.5918, 0.6008, 0.5909, 0.6018, 0.6029, 0.6036, 0.6181],
       device='cuda:0') torch.Size([16])
percent tensor([0.5859, 0.6901, 0.6276, 0.6382, 0.5521, 0.6179, 0.6204, 0.4781, 0.7083,
        0.6281, 0.7037, 0.6925, 0.7336, 0.7536, 0.5767, 0.6232],
       device='cuda:0') torch.Size([16])
percent tensor([0.6795, 0.6536, 0.7341, 0.7386, 0.7587, 0.7653, 0.7092, 0.6717, 0.7370,
        0.6762, 0.7039, 0.7017, 0.6783, 0.7894, 0.6582, 0.7162],
       device='cuda:0') torch.Size([16])
percent tensor([0.6627, 0.5804, 0.6870, 0.6480, 0.7573, 0.6643, 0.6587, 0.7063, 0.6159,
        0.6306, 0.5882, 0.5927, 0.5456, 0.6162, 0.6266, 0.7145],
       device='cuda:0') torch.Size([16])
percent tensor([0.9990, 0.9979, 0.9983, 0.9990, 0.9987, 0.9984, 0.9985, 0.9988, 0.9982,
        0.9990, 0.9981, 0.9986, 0.9987, 0.9989, 0.9983, 0.9990],
       device='cuda:0') torch.Size([16])
Epoch: 79 | Batch_idx: 0 |  Loss: (0.2236) |  Loss2: (0.0000) | Acc: (92.00%) (118/128)
Epoch: 79 | Batch_idx: 10 |  Loss: (0.2696) |  Loss2: (0.0000) | Acc: (91.00%) (1289/1408)
Epoch: 79 | Batch_idx: 20 |  Loss: (0.2791) |  Loss2: (0.0000) | Acc: (90.00%) (2440/2688)
Epoch: 79 | Batch_idx: 30 |  Loss: (0.2708) |  Loss2: (0.0000) | Acc: (91.00%) (3611/3968)
Epoch: 79 | Batch_idx: 40 |  Loss: (0.2690) |  Loss2: (0.0000) | Acc: (91.00%) (4784/5248)
Epoch: 79 | Batch_idx: 50 |  Loss: (0.2721) |  Loss2: (0.0000) | Acc: (90.00%) (5934/6528)
Epoch: 79 | Batch_idx: 60 |  Loss: (0.2747) |  Loss2: (0.0000) | Acc: (90.00%) (7102/7808)
Epoch: 79 | Batch_idx: 70 |  Loss: (0.2713) |  Loss2: (0.0000) | Acc: (90.00%) (8262/9088)
Epoch: 79 | Batch_idx: 80 |  Loss: (0.2715) |  Loss2: (0.0000) | Acc: (90.00%) (9431/10368)
Epoch: 79 | Batch_idx: 90 |  Loss: (0.2722) |  Loss2: (0.0000) | Acc: (90.00%) (10592/11648)
Epoch: 79 | Batch_idx: 100 |  Loss: (0.2696) |  Loss2: (0.0000) | Acc: (91.00%) (11772/12928)
Epoch: 79 | Batch_idx: 110 |  Loss: (0.2732) |  Loss2: (0.0000) | Acc: (90.00%) (12920/14208)
Epoch: 79 | Batch_idx: 120 |  Loss: (0.2728) |  Loss2: (0.0000) | Acc: (90.00%) (14077/15488)
Epoch: 79 | Batch_idx: 130 |  Loss: (0.2732) |  Loss2: (0.0000) | Acc: (90.00%) (15242/16768)
Epoch: 79 | Batch_idx: 140 |  Loss: (0.2736) |  Loss2: (0.0000) | Acc: (90.00%) (16393/18048)
Epoch: 79 | Batch_idx: 150 |  Loss: (0.2727) |  Loss2: (0.0000) | Acc: (90.00%) (17566/19328)
Epoch: 79 | Batch_idx: 160 |  Loss: (0.2719) |  Loss2: (0.0000) | Acc: (90.00%) (18724/20608)
Epoch: 79 | Batch_idx: 170 |  Loss: (0.2719) |  Loss2: (0.0000) | Acc: (90.00%) (19880/21888)
Epoch: 79 | Batch_idx: 180 |  Loss: (0.2726) |  Loss2: (0.0000) | Acc: (90.00%) (21033/23168)
Epoch: 79 | Batch_idx: 190 |  Loss: (0.2733) |  Loss2: (0.0000) | Acc: (90.00%) (22191/24448)
Epoch: 79 | Batch_idx: 200 |  Loss: (0.2730) |  Loss2: (0.0000) | Acc: (90.00%) (23346/25728)
Epoch: 79 | Batch_idx: 210 |  Loss: (0.2723) |  Loss2: (0.0000) | Acc: (90.00%) (24514/27008)
Epoch: 79 | Batch_idx: 220 |  Loss: (0.2715) |  Loss2: (0.0000) | Acc: (90.00%) (25681/28288)
Epoch: 79 | Batch_idx: 230 |  Loss: (0.2718) |  Loss2: (0.0000) | Acc: (90.00%) (26840/29568)
Epoch: 79 | Batch_idx: 240 |  Loss: (0.2720) |  Loss2: (0.0000) | Acc: (90.00%) (27998/30848)
Epoch: 79 | Batch_idx: 250 |  Loss: (0.2714) |  Loss2: (0.0000) | Acc: (90.00%) (29158/32128)
Epoch: 79 | Batch_idx: 260 |  Loss: (0.2706) |  Loss2: (0.0000) | Acc: (90.00%) (30333/33408)
Epoch: 79 | Batch_idx: 270 |  Loss: (0.2716) |  Loss2: (0.0000) | Acc: (90.00%) (31474/34688)
Epoch: 79 | Batch_idx: 280 |  Loss: (0.2712) |  Loss2: (0.0000) | Acc: (90.00%) (32637/35968)
Epoch: 79 | Batch_idx: 290 |  Loss: (0.2708) |  Loss2: (0.0000) | Acc: (90.00%) (33801/37248)
Epoch: 79 | Batch_idx: 300 |  Loss: (0.2708) |  Loss2: (0.0000) | Acc: (90.00%) (34962/38528)
Epoch: 79 | Batch_idx: 310 |  Loss: (0.2695) |  Loss2: (0.0000) | Acc: (90.00%) (36135/39808)
Epoch: 79 | Batch_idx: 320 |  Loss: (0.2693) |  Loss2: (0.0000) | Acc: (90.00%) (37291/41088)
Epoch: 79 | Batch_idx: 330 |  Loss: (0.2689) |  Loss2: (0.0000) | Acc: (90.00%) (38459/42368)
Epoch: 79 | Batch_idx: 340 |  Loss: (0.2696) |  Loss2: (0.0000) | Acc: (90.00%) (39607/43648)
Epoch: 79 | Batch_idx: 350 |  Loss: (0.2706) |  Loss2: (0.0000) | Acc: (90.00%) (40753/44928)
Epoch: 79 | Batch_idx: 360 |  Loss: (0.2701) |  Loss2: (0.0000) | Acc: (90.00%) (41922/46208)
Epoch: 79 | Batch_idx: 370 |  Loss: (0.2713) |  Loss2: (0.0000) | Acc: (90.00%) (43056/47488)
Epoch: 79 | Batch_idx: 380 |  Loss: (0.2715) |  Loss2: (0.0000) | Acc: (90.00%) (44216/48768)
Epoch: 79 | Batch_idx: 390 |  Loss: (0.2721) |  Loss2: (0.0000) | Acc: (90.00%) (45322/50000)
# TEST : Loss: (0.4062) | Acc: (86.00%) (8650/10000)
percent tensor([0.5890, 0.5752, 0.5985, 0.5806, 0.6023, 0.5859, 0.5877, 0.5810, 0.5878,
        0.5808, 0.5819, 0.5962, 0.5821, 0.5619, 0.5824, 0.5791],
       device='cuda:0') torch.Size([16])
percent tensor([0.5651, 0.5334, 0.5171, 0.5766, 0.5498, 0.6117, 0.5389, 0.5576, 0.5487,
        0.5300, 0.5432, 0.5203, 0.5314, 0.5841, 0.5672, 0.5724],
       device='cuda:0') torch.Size([16])
percent tensor([0.5059, 0.5385, 0.4995, 0.4664, 0.5072, 0.4613, 0.5455, 0.5116, 0.5124,
        0.5128, 0.5136, 0.5208, 0.5284, 0.5206, 0.5087, 0.5053],
       device='cuda:0') torch.Size([16])
percent tensor([0.6123, 0.5820, 0.5928, 0.6008, 0.6056, 0.6216, 0.6009, 0.6067, 0.6031,
        0.5902, 0.5996, 0.5902, 0.6002, 0.6015, 0.6036, 0.6170],
       device='cuda:0') torch.Size([16])
percent tensor([0.5858, 0.6888, 0.6324, 0.6451, 0.5550, 0.6233, 0.6175, 0.4829, 0.7076,
        0.6275, 0.6975, 0.6955, 0.7306, 0.7537, 0.5771, 0.6263],
       device='cuda:0') torch.Size([16])
percent tensor([0.6750, 0.6513, 0.7328, 0.7367, 0.7573, 0.7648, 0.7063, 0.6687, 0.7336,
        0.6734, 0.7004, 0.6980, 0.6723, 0.7888, 0.6557, 0.7130],
       device='cuda:0') torch.Size([16])
percent tensor([0.6649, 0.5858, 0.6939, 0.6546, 0.7648, 0.6731, 0.6640, 0.7072, 0.6246,
        0.6341, 0.5955, 0.6001, 0.5534, 0.6285, 0.6261, 0.7160],
       device='cuda:0') torch.Size([16])
percent tensor([0.9990, 0.9980, 0.9985, 0.9992, 0.9989, 0.9985, 0.9985, 0.9990, 0.9983,
        0.9991, 0.9981, 0.9987, 0.9987, 0.9989, 0.9984, 0.9991],
       device='cuda:0') torch.Size([16])
True Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=128, out_features=16, bias=False)
False Linear(in_features=16, out_features=2, bias=False)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=128, out_features=16, bias=False)
False Linear(in_features=16, out_features=2, bias=False)
True Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=256, out_features=32, bias=False)
False Linear(in_features=32, out_features=2, bias=False)
True Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=256, out_features=32, bias=False)
False Linear(in_features=32, out_features=2, bias=False)
True Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=512, out_features=64, bias=False)
False Linear(in_features=64, out_features=2, bias=False)
True Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=512, out_features=64, bias=False)
False Linear(in_features=64, out_features=2, bias=False)
True Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1024, out_features=128, bias=False)
False Linear(in_features=128, out_features=2, bias=False)
True Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1024, out_features=128, bias=False)
False Linear(in_features=128, out_features=2, bias=False)
True Linear(in_features=512, out_features=10, bias=True)
Epoch: 80 | Batch_idx: 0 |  Loss: (0.2525) |  Loss2: (0.0000) | Acc: (92.00%) (118/128)
Epoch: 80 | Batch_idx: 10 |  Loss: (0.2450) |  Loss2: (0.0000) | Acc: (91.00%) (1294/1408)
Epoch: 80 | Batch_idx: 20 |  Loss: (0.2613) |  Loss2: (0.0000) | Acc: (91.00%) (2457/2688)
Epoch: 80 | Batch_idx: 30 |  Loss: (0.2625) |  Loss2: (0.0000) | Acc: (91.00%) (3614/3968)
Epoch: 80 | Batch_idx: 40 |  Loss: (0.2635) |  Loss2: (0.0000) | Acc: (91.00%) (4780/5248)
Epoch: 80 | Batch_idx: 50 |  Loss: (0.2661) |  Loss2: (0.0000) | Acc: (90.00%) (5935/6528)
Epoch: 80 | Batch_idx: 60 |  Loss: (0.2665) |  Loss2: (0.0000) | Acc: (90.00%) (7080/7808)
Epoch: 80 | Batch_idx: 70 |  Loss: (0.2635) |  Loss2: (0.0000) | Acc: (90.00%) (8256/9088)
Epoch: 80 | Batch_idx: 80 |  Loss: (0.2639) |  Loss2: (0.0000) | Acc: (90.00%) (9414/10368)
Epoch: 80 | Batch_idx: 90 |  Loss: (0.2621) |  Loss2: (0.0000) | Acc: (90.00%) (10587/11648)
Epoch: 80 | Batch_idx: 100 |  Loss: (0.2626) |  Loss2: (0.0000) | Acc: (90.00%) (11744/12928)
Epoch: 80 | Batch_idx: 110 |  Loss: (0.2646) |  Loss2: (0.0000) | Acc: (90.00%) (12900/14208)
Epoch: 80 | Batch_idx: 120 |  Loss: (0.2669) |  Loss2: (0.0000) | Acc: (90.00%) (14054/15488)
Epoch: 80 | Batch_idx: 130 |  Loss: (0.2671) |  Loss2: (0.0000) | Acc: (90.00%) (15210/16768)
Epoch: 80 | Batch_idx: 140 |  Loss: (0.2695) |  Loss2: (0.0000) | Acc: (90.00%) (16353/18048)
Epoch: 80 | Batch_idx: 150 |  Loss: (0.2688) |  Loss2: (0.0000) | Acc: (90.00%) (17515/19328)
Epoch: 80 | Batch_idx: 160 |  Loss: (0.2686) |  Loss2: (0.0000) | Acc: (90.00%) (18671/20608)
Epoch: 80 | Batch_idx: 170 |  Loss: (0.2704) |  Loss2: (0.0000) | Acc: (90.00%) (19807/21888)
Epoch: 80 | Batch_idx: 180 |  Loss: (0.2701) |  Loss2: (0.0000) | Acc: (90.00%) (20980/23168)
Epoch: 80 | Batch_idx: 190 |  Loss: (0.2699) |  Loss2: (0.0000) | Acc: (90.00%) (22146/24448)
Epoch: 80 | Batch_idx: 200 |  Loss: (0.2704) |  Loss2: (0.0000) | Acc: (90.00%) (23302/25728)
Epoch: 80 | Batch_idx: 210 |  Loss: (0.2723) |  Loss2: (0.0000) | Acc: (90.00%) (24439/27008)
Epoch: 80 | Batch_idx: 220 |  Loss: (0.2724) |  Loss2: (0.0000) | Acc: (90.00%) (25595/28288)
Epoch: 80 | Batch_idx: 230 |  Loss: (0.2731) |  Loss2: (0.0000) | Acc: (90.00%) (26748/29568)
Epoch: 80 | Batch_idx: 240 |  Loss: (0.2734) |  Loss2: (0.0000) | Acc: (90.00%) (27905/30848)
Epoch: 80 | Batch_idx: 250 |  Loss: (0.2742) |  Loss2: (0.0000) | Acc: (90.00%) (29060/32128)
Epoch: 80 | Batch_idx: 260 |  Loss: (0.2746) |  Loss2: (0.0000) | Acc: (90.00%) (30206/33408)
Epoch: 80 | Batch_idx: 270 |  Loss: (0.2758) |  Loss2: (0.0000) | Acc: (90.00%) (31355/34688)
Epoch: 80 | Batch_idx: 280 |  Loss: (0.2771) |  Loss2: (0.0000) | Acc: (90.00%) (32504/35968)
Epoch: 80 | Batch_idx: 290 |  Loss: (0.2765) |  Loss2: (0.0000) | Acc: (90.00%) (33672/37248)
Epoch: 80 | Batch_idx: 300 |  Loss: (0.2761) |  Loss2: (0.0000) | Acc: (90.00%) (34832/38528)
Epoch: 80 | Batch_idx: 310 |  Loss: (0.2753) |  Loss2: (0.0000) | Acc: (90.00%) (35999/39808)
Epoch: 80 | Batch_idx: 320 |  Loss: (0.2751) |  Loss2: (0.0000) | Acc: (90.00%) (37169/41088)
Epoch: 80 | Batch_idx: 330 |  Loss: (0.2752) |  Loss2: (0.0000) | Acc: (90.00%) (38322/42368)
Epoch: 80 | Batch_idx: 340 |  Loss: (0.2745) |  Loss2: (0.0000) | Acc: (90.00%) (39483/43648)
Epoch: 80 | Batch_idx: 350 |  Loss: (0.2755) |  Loss2: (0.0000) | Acc: (90.00%) (40616/44928)
Epoch: 80 | Batch_idx: 360 |  Loss: (0.2756) |  Loss2: (0.0000) | Acc: (90.00%) (41777/46208)
Epoch: 80 | Batch_idx: 370 |  Loss: (0.2754) |  Loss2: (0.0000) | Acc: (90.00%) (42931/47488)
Epoch: 80 | Batch_idx: 380 |  Loss: (0.2749) |  Loss2: (0.0000) | Acc: (90.00%) (44102/48768)
Epoch: 80 | Batch_idx: 390 |  Loss: (0.2753) |  Loss2: (0.0000) | Acc: (90.00%) (45212/50000)
/usr/local/lib/python3.6/dist-packages/torch/serialization.py:241: UserWarning: Couldn't retrieve source code for container of type ResNet. It won't be checked for correctness upon loading.
  "type " + obj.__name__ + ". It won't be checked "
/usr/local/lib/python3.6/dist-packages/torch/serialization.py:241: UserWarning: Couldn't retrieve source code for container of type BasicBlock. It won't be checked for correctness upon loading.
  "type " + obj.__name__ + ". It won't be checked "
/usr/local/lib/python3.6/dist-packages/torch/serialization.py:241: UserWarning: Couldn't retrieve source code for container of type _Gate. It won't be checked for correctness upon loading.
  "type " + obj.__name__ + ". It won't be checked "
=> saving checkpoint 'drive/app/torch/save_Routing_Gate_2/checkpoint_080.pth.tar'
# TEST : Loss: (0.4364) | Acc: (85.00%) (8583/10000)
percent tensor([0.5863, 0.5764, 0.5911, 0.5785, 0.5965, 0.5814, 0.5861, 0.5801, 0.5857,
        0.5793, 0.5814, 0.5894, 0.5805, 0.5672, 0.5802, 0.5785],
       device='cuda:0') torch.Size([16])
percent tensor([0.5651, 0.5332, 0.5273, 0.5755, 0.5539, 0.6077, 0.5416, 0.5560, 0.5513,
        0.5325, 0.5426, 0.5250, 0.5290, 0.5813, 0.5637, 0.5707],
       device='cuda:0') torch.Size([16])
percent tensor([0.5062, 0.5450, 0.4973, 0.4662, 0.5011, 0.4600, 0.5475, 0.5114, 0.5120,
        0.5124, 0.5110, 0.5213, 0.5290, 0.5335, 0.5109, 0.5092],
       device='cuda:0') torch.Size([16])
percent tensor([0.6139, 0.5818, 0.6044, 0.6046, 0.6105, 0.6243, 0.5996, 0.6091, 0.6049,
        0.5924, 0.5984, 0.5974, 0.5980, 0.6004, 0.6039, 0.6164],
       device='cuda:0') torch.Size([16])
percent tensor([0.5743, 0.6855, 0.6156, 0.6290, 0.5610, 0.6393, 0.6131, 0.4999, 0.6970,
        0.6181, 0.6858, 0.6870, 0.7171, 0.7560, 0.5792, 0.6291],
       device='cuda:0') torch.Size([16])
percent tensor([0.6755, 0.6488, 0.7363, 0.7489, 0.7590, 0.7734, 0.6971, 0.6643, 0.7372,
        0.6773, 0.7156, 0.6914, 0.6516, 0.7963, 0.6476, 0.7108],
       device='cuda:0') torch.Size([16])
percent tensor([0.6669, 0.5746, 0.7080, 0.6749, 0.7641, 0.6702, 0.6627, 0.7201, 0.6399,
        0.6293, 0.6071, 0.6150, 0.5230, 0.6341, 0.6175, 0.7016],
       device='cuda:0') torch.Size([16])
percent tensor([0.9991, 0.9978, 0.9985, 0.9991, 0.9982, 0.9981, 0.9986, 0.9990, 0.9987,
        0.9992, 0.9988, 0.9993, 0.9985, 0.9989, 0.9988, 0.9991],
       device='cuda:0') torch.Size([16])
Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 3, 3, 3]) tensor(178.7534, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(811.0917, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(810.7469, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([128, 64, 3, 3]) tensor(1530.3861, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([128, 64, 1, 1]) tensor(499.0330, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([128, 128, 3, 3]) tensor(2223.1860, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([256, 128, 3, 3]) tensor(4293.0444, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([256, 128, 1, 1]) tensor(1409.0775, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([256, 256, 3, 3]) tensor(6148.3906, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([512, 256, 3, 3]) tensor(11965.2793, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([512, 256, 1, 1]) tensor(3972.8035, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([512, 512, 3, 3]) tensor(16797.6172, device='cuda:0', grad_fn=<NormBackward0>)
Epoch: 81 | Batch_idx: 0 |  Loss: (0.2068) |  Loss2: (0.0000) | Acc: (92.00%) (119/128)
Epoch: 81 | Batch_idx: 10 |  Loss: (0.2633) |  Loss2: (0.0000) | Acc: (90.00%) (1279/1408)
Epoch: 81 | Batch_idx: 20 |  Loss: (0.2585) |  Loss2: (0.0000) | Acc: (90.00%) (2442/2688)
Epoch: 81 | Batch_idx: 30 |  Loss: (0.2534) |  Loss2: (0.0000) | Acc: (91.00%) (3614/3968)
Epoch: 81 | Batch_idx: 40 |  Loss: (0.2589) |  Loss2: (0.0000) | Acc: (90.00%) (4772/5248)
Epoch: 81 | Batch_idx: 50 |  Loss: (0.2604) |  Loss2: (0.0000) | Acc: (90.00%) (5933/6528)
Epoch: 81 | Batch_idx: 60 |  Loss: (0.2645) |  Loss2: (0.0000) | Acc: (90.00%) (7081/7808)
Epoch: 81 | Batch_idx: 70 |  Loss: (0.2644) |  Loss2: (0.0000) | Acc: (90.00%) (8249/9088)
Epoch: 81 | Batch_idx: 80 |  Loss: (0.2632) |  Loss2: (0.0000) | Acc: (90.00%) (9426/10368)
Epoch: 81 | Batch_idx: 90 |  Loss: (0.2663) |  Loss2: (0.0000) | Acc: (90.00%) (10579/11648)
Epoch: 81 | Batch_idx: 100 |  Loss: (0.2678) |  Loss2: (0.0000) | Acc: (90.00%) (11728/12928)
Epoch: 81 | Batch_idx: 110 |  Loss: (0.2679) |  Loss2: (0.0000) | Acc: (90.00%) (12900/14208)
Epoch: 81 | Batch_idx: 120 |  Loss: (0.2696) |  Loss2: (0.0000) | Acc: (90.00%) (14056/15488)
Epoch: 81 | Batch_idx: 130 |  Loss: (0.2697) |  Loss2: (0.0000) | Acc: (90.00%) (15219/16768)
Epoch: 81 | Batch_idx: 140 |  Loss: (0.2689) |  Loss2: (0.0000) | Acc: (90.00%) (16389/18048)
Epoch: 81 | Batch_idx: 150 |  Loss: (0.2685) |  Loss2: (0.0000) | Acc: (90.00%) (17544/19328)
Epoch: 81 | Batch_idx: 160 |  Loss: (0.2697) |  Loss2: (0.0000) | Acc: (90.00%) (18689/20608)
Epoch: 81 | Batch_idx: 170 |  Loss: (0.2700) |  Loss2: (0.0000) | Acc: (90.00%) (19841/21888)
Epoch: 81 | Batch_idx: 180 |  Loss: (0.2704) |  Loss2: (0.0000) | Acc: (90.00%) (21007/23168)
Epoch: 81 | Batch_idx: 190 |  Loss: (0.2695) |  Loss2: (0.0000) | Acc: (90.00%) (22172/24448)
Epoch: 81 | Batch_idx: 200 |  Loss: (0.2700) |  Loss2: (0.0000) | Acc: (90.00%) (23319/25728)
Epoch: 81 | Batch_idx: 210 |  Loss: (0.2695) |  Loss2: (0.0000) | Acc: (90.00%) (24487/27008)
Epoch: 81 | Batch_idx: 220 |  Loss: (0.2693) |  Loss2: (0.0000) | Acc: (90.00%) (25649/28288)
Epoch: 81 | Batch_idx: 230 |  Loss: (0.2689) |  Loss2: (0.0000) | Acc: (90.00%) (26807/29568)
Epoch: 81 | Batch_idx: 240 |  Loss: (0.2690) |  Loss2: (0.0000) | Acc: (90.00%) (27970/30848)
Epoch: 81 | Batch_idx: 250 |  Loss: (0.2698) |  Loss2: (0.0000) | Acc: (90.00%) (29121/32128)
Epoch: 81 | Batch_idx: 260 |  Loss: (0.2696) |  Loss2: (0.0000) | Acc: (90.00%) (30282/33408)
Epoch: 81 | Batch_idx: 270 |  Loss: (0.2701) |  Loss2: (0.0000) | Acc: (90.00%) (31437/34688)
Epoch: 81 | Batch_idx: 280 |  Loss: (0.2696) |  Loss2: (0.0000) | Acc: (90.00%) (32601/35968)
Epoch: 81 | Batch_idx: 290 |  Loss: (0.2686) |  Loss2: (0.0000) | Acc: (90.00%) (33772/37248)
Epoch: 81 | Batch_idx: 300 |  Loss: (0.2682) |  Loss2: (0.0000) | Acc: (90.00%) (34947/38528)
Epoch: 81 | Batch_idx: 310 |  Loss: (0.2677) |  Loss2: (0.0000) | Acc: (90.00%) (36114/39808)
Epoch: 81 | Batch_idx: 320 |  Loss: (0.2687) |  Loss2: (0.0000) | Acc: (90.00%) (37267/41088)
Epoch: 81 | Batch_idx: 330 |  Loss: (0.2691) |  Loss2: (0.0000) | Acc: (90.00%) (38411/42368)
Epoch: 81 | Batch_idx: 340 |  Loss: (0.2687) |  Loss2: (0.0000) | Acc: (90.00%) (39571/43648)
Epoch: 81 | Batch_idx: 350 |  Loss: (0.2680) |  Loss2: (0.0000) | Acc: (90.00%) (40742/44928)
Epoch: 81 | Batch_idx: 360 |  Loss: (0.2683) |  Loss2: (0.0000) | Acc: (90.00%) (41905/46208)
Epoch: 81 | Batch_idx: 370 |  Loss: (0.2681) |  Loss2: (0.0000) | Acc: (90.00%) (43078/47488)
Epoch: 81 | Batch_idx: 380 |  Loss: (0.2680) |  Loss2: (0.0000) | Acc: (90.00%) (44244/48768)
Epoch: 81 | Batch_idx: 390 |  Loss: (0.2687) |  Loss2: (0.0000) | Acc: (90.00%) (45346/50000)
# TEST : Loss: (0.4410) | Acc: (86.00%) (8612/10000)
percent tensor([0.5872, 0.5771, 0.5917, 0.5789, 0.5975, 0.5832, 0.5869, 0.5798, 0.5859,
        0.5795, 0.5813, 0.5907, 0.5807, 0.5674, 0.5809, 0.5790],
       device='cuda:0') torch.Size([16])
percent tensor([0.5631, 0.5370, 0.5247, 0.5713, 0.5505, 0.6003, 0.5435, 0.5573, 0.5551,
        0.5318, 0.5439, 0.5231, 0.5296, 0.5909, 0.5606, 0.5703],
       device='cuda:0') torch.Size([16])
percent tensor([0.5081, 0.5448, 0.4987, 0.4707, 0.5061, 0.4740, 0.5469, 0.5113, 0.5111,
        0.5133, 0.5113, 0.5207, 0.5283, 0.5239, 0.5165, 0.5103],
       device='cuda:0') torch.Size([16])
percent tensor([0.6146, 0.5823, 0.5980, 0.6032, 0.6104, 0.6212, 0.6037, 0.6107, 0.6054,
        0.5925, 0.5988, 0.5964, 0.5982, 0.6067, 0.6055, 0.6175],
       device='cuda:0') torch.Size([16])
percent tensor([0.5559, 0.6528, 0.5888, 0.5956, 0.5430, 0.6466, 0.5882, 0.4678, 0.6815,
        0.5909, 0.6750, 0.6562, 0.6977, 0.7191, 0.5586, 0.5961],
       device='cuda:0') torch.Size([16])
percent tensor([0.6738, 0.6413, 0.7183, 0.7310, 0.7513, 0.7631, 0.7081, 0.6598, 0.7332,
        0.6679, 0.7071, 0.6903, 0.6550, 0.7928, 0.6483, 0.7039],
       device='cuda:0') torch.Size([16])
percent tensor([0.6699, 0.6060, 0.7217, 0.6922, 0.7697, 0.6576, 0.6885, 0.7256, 0.6585,
        0.6429, 0.6170, 0.6415, 0.5501, 0.6920, 0.6230, 0.7158],
       device='cuda:0') torch.Size([16])
percent tensor([0.9992, 0.9982, 0.9988, 0.9990, 0.9984, 0.9969, 0.9985, 0.9985, 0.9983,
        0.9991, 0.9986, 0.9992, 0.9986, 0.9992, 0.9986, 0.9991],
       device='cuda:0') torch.Size([16])
Epoch: 82 | Batch_idx: 0 |  Loss: (0.1707) |  Loss2: (0.0000) | Acc: (94.00%) (121/128)
Epoch: 82 | Batch_idx: 10 |  Loss: (0.2590) |  Loss2: (0.0000) | Acc: (91.00%) (1288/1408)
Epoch: 82 | Batch_idx: 20 |  Loss: (0.2626) |  Loss2: (0.0000) | Acc: (91.00%) (2456/2688)
Epoch: 82 | Batch_idx: 30 |  Loss: (0.2608) |  Loss2: (0.0000) | Acc: (90.00%) (3610/3968)
Epoch: 82 | Batch_idx: 40 |  Loss: (0.2600) |  Loss2: (0.0000) | Acc: (91.00%) (4776/5248)
Epoch: 82 | Batch_idx: 50 |  Loss: (0.2548) |  Loss2: (0.0000) | Acc: (91.00%) (5949/6528)
Epoch: 82 | Batch_idx: 60 |  Loss: (0.2621) |  Loss2: (0.0000) | Acc: (90.00%) (7093/7808)
Epoch: 82 | Batch_idx: 70 |  Loss: (0.2618) |  Loss2: (0.0000) | Acc: (90.00%) (8263/9088)
Epoch: 82 | Batch_idx: 80 |  Loss: (0.2599) |  Loss2: (0.0000) | Acc: (91.00%) (9443/10368)
Epoch: 82 | Batch_idx: 90 |  Loss: (0.2578) |  Loss2: (0.0000) | Acc: (91.00%) (10618/11648)
Epoch: 82 | Batch_idx: 100 |  Loss: (0.2588) |  Loss2: (0.0000) | Acc: (91.00%) (11772/12928)
Epoch: 82 | Batch_idx: 110 |  Loss: (0.2598) |  Loss2: (0.0000) | Acc: (91.00%) (12941/14208)
Epoch: 82 | Batch_idx: 120 |  Loss: (0.2607) |  Loss2: (0.0000) | Acc: (91.00%) (14099/15488)
Epoch: 82 | Batch_idx: 130 |  Loss: (0.2618) |  Loss2: (0.0000) | Acc: (90.00%) (15257/16768)
Epoch: 82 | Batch_idx: 140 |  Loss: (0.2619) |  Loss2: (0.0000) | Acc: (91.00%) (16429/18048)
Epoch: 82 | Batch_idx: 150 |  Loss: (0.2651) |  Loss2: (0.0000) | Acc: (90.00%) (17586/19328)
Epoch: 82 | Batch_idx: 160 |  Loss: (0.2647) |  Loss2: (0.0000) | Acc: (90.00%) (18745/20608)
Epoch: 82 | Batch_idx: 170 |  Loss: (0.2647) |  Loss2: (0.0000) | Acc: (90.00%) (19914/21888)
Epoch: 82 | Batch_idx: 180 |  Loss: (0.2652) |  Loss2: (0.0000) | Acc: (90.00%) (21066/23168)
Epoch: 82 | Batch_idx: 190 |  Loss: (0.2654) |  Loss2: (0.0000) | Acc: (90.00%) (22226/24448)
Epoch: 82 | Batch_idx: 200 |  Loss: (0.2647) |  Loss2: (0.0000) | Acc: (90.00%) (23402/25728)
Epoch: 82 | Batch_idx: 210 |  Loss: (0.2658) |  Loss2: (0.0000) | Acc: (90.00%) (24549/27008)
Epoch: 82 | Batch_idx: 220 |  Loss: (0.2658) |  Loss2: (0.0000) | Acc: (90.00%) (25714/28288)
Epoch: 82 | Batch_idx: 230 |  Loss: (0.2653) |  Loss2: (0.0000) | Acc: (90.00%) (26886/29568)
Epoch: 82 | Batch_idx: 240 |  Loss: (0.2649) |  Loss2: (0.0000) | Acc: (90.00%) (28052/30848)
Epoch: 82 | Batch_idx: 250 |  Loss: (0.2661) |  Loss2: (0.0000) | Acc: (90.00%) (29202/32128)
Epoch: 82 | Batch_idx: 260 |  Loss: (0.2651) |  Loss2: (0.0000) | Acc: (90.00%) (30370/33408)
Epoch: 82 | Batch_idx: 270 |  Loss: (0.2650) |  Loss2: (0.0000) | Acc: (90.00%) (31540/34688)
Epoch: 82 | Batch_idx: 280 |  Loss: (0.2656) |  Loss2: (0.0000) | Acc: (90.00%) (32708/35968)
Epoch: 82 | Batch_idx: 290 |  Loss: (0.2651) |  Loss2: (0.0000) | Acc: (90.00%) (33884/37248)
Epoch: 82 | Batch_idx: 300 |  Loss: (0.2648) |  Loss2: (0.0000) | Acc: (90.00%) (35056/38528)
Epoch: 82 | Batch_idx: 310 |  Loss: (0.2641) |  Loss2: (0.0000) | Acc: (91.00%) (36231/39808)
Epoch: 82 | Batch_idx: 320 |  Loss: (0.2632) |  Loss2: (0.0000) | Acc: (91.00%) (37411/41088)
Epoch: 82 | Batch_idx: 330 |  Loss: (0.2641) |  Loss2: (0.0000) | Acc: (91.00%) (38562/42368)
Epoch: 82 | Batch_idx: 340 |  Loss: (0.2634) |  Loss2: (0.0000) | Acc: (91.00%) (39734/43648)
Epoch: 82 | Batch_idx: 350 |  Loss: (0.2638) |  Loss2: (0.0000) | Acc: (90.00%) (40884/44928)
Epoch: 82 | Batch_idx: 360 |  Loss: (0.2643) |  Loss2: (0.0000) | Acc: (90.00%) (42039/46208)
Epoch: 82 | Batch_idx: 370 |  Loss: (0.2650) |  Loss2: (0.0000) | Acc: (90.00%) (43186/47488)
Epoch: 82 | Batch_idx: 380 |  Loss: (0.2647) |  Loss2: (0.0000) | Acc: (90.00%) (44354/48768)
Epoch: 82 | Batch_idx: 390 |  Loss: (0.2643) |  Loss2: (0.0000) | Acc: (90.00%) (45478/50000)
# TEST : Loss: (0.4320) | Acc: (85.00%) (8580/10000)
percent tensor([0.5877, 0.5778, 0.5926, 0.5788, 0.5974, 0.5824, 0.5878, 0.5801, 0.5870,
        0.5804, 0.5824, 0.5915, 0.5812, 0.5684, 0.5808, 0.5794],
       device='cuda:0') torch.Size([16])
percent tensor([0.5632, 0.5303, 0.5212, 0.5676, 0.5494, 0.6096, 0.5392, 0.5519, 0.5496,
        0.5285, 0.5416, 0.5187, 0.5278, 0.5816, 0.5626, 0.5700],
       device='cuda:0') torch.Size([16])
percent tensor([0.5058, 0.5426, 0.4991, 0.4685, 0.5054, 0.4645, 0.5449, 0.5117, 0.5104,
        0.5107, 0.5061, 0.5220, 0.5252, 0.5281, 0.5133, 0.5071],
       device='cuda:0') torch.Size([16])
percent tensor([0.6132, 0.5813, 0.6001, 0.6009, 0.6086, 0.6217, 0.6021, 0.6088, 0.6046,
        0.5936, 0.6007, 0.5963, 0.5992, 0.6037, 0.6041, 0.6175],
       device='cuda:0') torch.Size([16])
percent tensor([0.5815, 0.6754, 0.6544, 0.6488, 0.5802, 0.6300, 0.6089, 0.5121, 0.7038,
        0.6198, 0.6801, 0.6953, 0.7271, 0.7335, 0.5728, 0.6186],
       device='cuda:0') torch.Size([16])
percent tensor([0.6688, 0.6520, 0.7306, 0.7291, 0.7497, 0.7582, 0.7070, 0.6542, 0.7384,
        0.6741, 0.7181, 0.6965, 0.6650, 0.7901, 0.6469, 0.7028],
       device='cuda:0') torch.Size([16])
percent tensor([0.6631, 0.5872, 0.7016, 0.6490, 0.7591, 0.6667, 0.6783, 0.7214, 0.6214,
        0.6187, 0.5967, 0.5793, 0.5184, 0.6479, 0.6088, 0.7084],
       device='cuda:0') torch.Size([16])
percent tensor([0.9989, 0.9977, 0.9985, 0.9992, 0.9982, 0.9979, 0.9983, 0.9990, 0.9983,
        0.9988, 0.9983, 0.9986, 0.9981, 0.9988, 0.9987, 0.9991],
       device='cuda:0') torch.Size([16])
Epoch: 83 | Batch_idx: 0 |  Loss: (0.2478) |  Loss2: (0.0000) | Acc: (92.00%) (118/128)
Epoch: 83 | Batch_idx: 10 |  Loss: (0.2477) |  Loss2: (0.0000) | Acc: (92.00%) (1297/1408)
Epoch: 83 | Batch_idx: 20 |  Loss: (0.2556) |  Loss2: (0.0000) | Acc: (91.00%) (2458/2688)
Epoch: 83 | Batch_idx: 30 |  Loss: (0.2545) |  Loss2: (0.0000) | Acc: (91.00%) (3630/3968)
Epoch: 83 | Batch_idx: 40 |  Loss: (0.2505) |  Loss2: (0.0000) | Acc: (91.00%) (4807/5248)
Epoch: 83 | Batch_idx: 50 |  Loss: (0.2515) |  Loss2: (0.0000) | Acc: (91.00%) (5982/6528)
Epoch: 83 | Batch_idx: 60 |  Loss: (0.2458) |  Loss2: (0.0000) | Acc: (91.00%) (7173/7808)
Epoch: 83 | Batch_idx: 70 |  Loss: (0.2448) |  Loss2: (0.0000) | Acc: (91.00%) (8354/9088)
Epoch: 83 | Batch_idx: 80 |  Loss: (0.2419) |  Loss2: (0.0000) | Acc: (91.00%) (9535/10368)
Epoch: 83 | Batch_idx: 90 |  Loss: (0.2419) |  Loss2: (0.0000) | Acc: (91.00%) (10712/11648)
Epoch: 83 | Batch_idx: 100 |  Loss: (0.2434) |  Loss2: (0.0000) | Acc: (91.00%) (11875/12928)
Epoch: 83 | Batch_idx: 110 |  Loss: (0.2467) |  Loss2: (0.0000) | Acc: (91.00%) (13029/14208)
Epoch: 83 | Batch_idx: 120 |  Loss: (0.2489) |  Loss2: (0.0000) | Acc: (91.00%) (14190/15488)
Epoch: 83 | Batch_idx: 130 |  Loss: (0.2506) |  Loss2: (0.0000) | Acc: (91.00%) (15358/16768)
Epoch: 83 | Batch_idx: 140 |  Loss: (0.2509) |  Loss2: (0.0000) | Acc: (91.00%) (16523/18048)
Epoch: 83 | Batch_idx: 150 |  Loss: (0.2523) |  Loss2: (0.0000) | Acc: (91.00%) (17670/19328)
Epoch: 83 | Batch_idx: 160 |  Loss: (0.2516) |  Loss2: (0.0000) | Acc: (91.00%) (18844/20608)
Epoch: 83 | Batch_idx: 170 |  Loss: (0.2511) |  Loss2: (0.0000) | Acc: (91.00%) (20022/21888)
Epoch: 83 | Batch_idx: 180 |  Loss: (0.2520) |  Loss2: (0.0000) | Acc: (91.00%) (21183/23168)
Epoch: 83 | Batch_idx: 190 |  Loss: (0.2516) |  Loss2: (0.0000) | Acc: (91.00%) (22349/24448)
Epoch: 83 | Batch_idx: 200 |  Loss: (0.2511) |  Loss2: (0.0000) | Acc: (91.00%) (23524/25728)
Epoch: 83 | Batch_idx: 210 |  Loss: (0.2496) |  Loss2: (0.0000) | Acc: (91.00%) (24706/27008)
Epoch: 83 | Batch_idx: 220 |  Loss: (0.2500) |  Loss2: (0.0000) | Acc: (91.00%) (25863/28288)
Epoch: 83 | Batch_idx: 230 |  Loss: (0.2504) |  Loss2: (0.0000) | Acc: (91.00%) (27029/29568)
Epoch: 83 | Batch_idx: 240 |  Loss: (0.2522) |  Loss2: (0.0000) | Acc: (91.00%) (28176/30848)
Epoch: 83 | Batch_idx: 250 |  Loss: (0.2530) |  Loss2: (0.0000) | Acc: (91.00%) (29341/32128)
Epoch: 83 | Batch_idx: 260 |  Loss: (0.2525) |  Loss2: (0.0000) | Acc: (91.00%) (30504/33408)
Epoch: 83 | Batch_idx: 270 |  Loss: (0.2524) |  Loss2: (0.0000) | Acc: (91.00%) (31679/34688)
Epoch: 83 | Batch_idx: 280 |  Loss: (0.2523) |  Loss2: (0.0000) | Acc: (91.00%) (32847/35968)
Epoch: 83 | Batch_idx: 290 |  Loss: (0.2530) |  Loss2: (0.0000) | Acc: (91.00%) (34015/37248)
Epoch: 83 | Batch_idx: 300 |  Loss: (0.2535) |  Loss2: (0.0000) | Acc: (91.00%) (35188/38528)
Epoch: 83 | Batch_idx: 310 |  Loss: (0.2544) |  Loss2: (0.0000) | Acc: (91.00%) (36359/39808)
Epoch: 83 | Batch_idx: 320 |  Loss: (0.2549) |  Loss2: (0.0000) | Acc: (91.00%) (37521/41088)
Epoch: 83 | Batch_idx: 330 |  Loss: (0.2554) |  Loss2: (0.0000) | Acc: (91.00%) (38686/42368)
Epoch: 83 | Batch_idx: 340 |  Loss: (0.2545) |  Loss2: (0.0000) | Acc: (91.00%) (39875/43648)
Epoch: 83 | Batch_idx: 350 |  Loss: (0.2548) |  Loss2: (0.0000) | Acc: (91.00%) (41036/44928)
Epoch: 83 | Batch_idx: 360 |  Loss: (0.2553) |  Loss2: (0.0000) | Acc: (91.00%) (42201/46208)
Epoch: 83 | Batch_idx: 370 |  Loss: (0.2554) |  Loss2: (0.0000) | Acc: (91.00%) (43364/47488)
Epoch: 83 | Batch_idx: 380 |  Loss: (0.2555) |  Loss2: (0.0000) | Acc: (91.00%) (44527/48768)
Epoch: 83 | Batch_idx: 390 |  Loss: (0.2556) |  Loss2: (0.0000) | Acc: (91.00%) (45643/50000)
# TEST : Loss: (0.4726) | Acc: (84.00%) (8489/10000)
percent tensor([0.5883, 0.5786, 0.5900, 0.5794, 0.5963, 0.5878, 0.5880, 0.5806, 0.5872,
        0.5800, 0.5835, 0.5888, 0.5822, 0.5722, 0.5831, 0.5816],
       device='cuda:0') torch.Size([16])
percent tensor([0.5673, 0.5395, 0.5196, 0.5743, 0.5490, 0.6101, 0.5425, 0.5550, 0.5545,
        0.5320, 0.5488, 0.5180, 0.5319, 0.5874, 0.5683, 0.5729],
       device='cuda:0') torch.Size([16])
percent tensor([0.5065, 0.5435, 0.5022, 0.4674, 0.5034, 0.4644, 0.5486, 0.5122, 0.5120,
        0.5141, 0.5097, 0.5264, 0.5284, 0.5304, 0.5119, 0.5068],
       device='cuda:0') torch.Size([16])
percent tensor([0.6136, 0.5813, 0.5979, 0.6024, 0.6051, 0.6193, 0.6007, 0.6098, 0.6045,
        0.5927, 0.6004, 0.5946, 0.5996, 0.5989, 0.6039, 0.6162],
       device='cuda:0') torch.Size([16])
percent tensor([0.5558, 0.6766, 0.6086, 0.6044, 0.5631, 0.6306, 0.6073, 0.4878, 0.7040,
        0.5961, 0.6838, 0.6700, 0.7071, 0.7418, 0.5776, 0.6088],
       device='cuda:0') torch.Size([16])
percent tensor([0.6841, 0.6548, 0.7382, 0.7397, 0.7650, 0.7715, 0.7085, 0.6928, 0.7502,
        0.6714, 0.7381, 0.6798, 0.6736, 0.7874, 0.6660, 0.7228],
       device='cuda:0') torch.Size([16])
percent tensor([0.6763, 0.5962, 0.7204, 0.6642, 0.7776, 0.6848, 0.6763, 0.7085, 0.6242,
        0.6453, 0.5842, 0.6162, 0.5309, 0.6365, 0.6227, 0.7296],
       device='cuda:0') torch.Size([16])
percent tensor([0.9990, 0.9979, 0.9988, 0.9989, 0.9988, 0.9985, 0.9982, 0.9987, 0.9983,
        0.9992, 0.9982, 0.9991, 0.9987, 0.9985, 0.9987, 0.9993],
       device='cuda:0') torch.Size([16])
Epoch: 84 | Batch_idx: 0 |  Loss: (0.2369) |  Loss2: (0.0000) | Acc: (91.00%) (117/128)
Epoch: 84 | Batch_idx: 10 |  Loss: (0.2345) |  Loss2: (0.0000) | Acc: (91.00%) (1291/1408)
Epoch: 84 | Batch_idx: 20 |  Loss: (0.2379) |  Loss2: (0.0000) | Acc: (91.00%) (2454/2688)
Epoch: 84 | Batch_idx: 30 |  Loss: (0.2362) |  Loss2: (0.0000) | Acc: (91.00%) (3629/3968)
Epoch: 84 | Batch_idx: 40 |  Loss: (0.2438) |  Loss2: (0.0000) | Acc: (91.00%) (4786/5248)
Epoch: 84 | Batch_idx: 50 |  Loss: (0.2470) |  Loss2: (0.0000) | Acc: (91.00%) (5953/6528)
Epoch: 84 | Batch_idx: 60 |  Loss: (0.2491) |  Loss2: (0.0000) | Acc: (91.00%) (7115/7808)
Epoch: 84 | Batch_idx: 70 |  Loss: (0.2470) |  Loss2: (0.0000) | Acc: (91.00%) (8286/9088)
Epoch: 84 | Batch_idx: 80 |  Loss: (0.2445) |  Loss2: (0.0000) | Acc: (91.00%) (9460/10368)
Epoch: 84 | Batch_idx: 90 |  Loss: (0.2434) |  Loss2: (0.0000) | Acc: (91.00%) (10631/11648)
Epoch: 84 | Batch_idx: 100 |  Loss: (0.2455) |  Loss2: (0.0000) | Acc: (91.00%) (11784/12928)
Epoch: 84 | Batch_idx: 110 |  Loss: (0.2461) |  Loss2: (0.0000) | Acc: (91.00%) (12952/14208)
Epoch: 84 | Batch_idx: 120 |  Loss: (0.2461) |  Loss2: (0.0000) | Acc: (91.00%) (14125/15488)
Epoch: 84 | Batch_idx: 130 |  Loss: (0.2494) |  Loss2: (0.0000) | Acc: (91.00%) (15272/16768)
Epoch: 84 | Batch_idx: 140 |  Loss: (0.2486) |  Loss2: (0.0000) | Acc: (91.00%) (16448/18048)
Epoch: 84 | Batch_idx: 150 |  Loss: (0.2485) |  Loss2: (0.0000) | Acc: (91.00%) (17623/19328)
Epoch: 84 | Batch_idx: 160 |  Loss: (0.2491) |  Loss2: (0.0000) | Acc: (91.00%) (18796/20608)
Epoch: 84 | Batch_idx: 170 |  Loss: (0.2488) |  Loss2: (0.0000) | Acc: (91.00%) (19963/21888)
Epoch: 84 | Batch_idx: 180 |  Loss: (0.2503) |  Loss2: (0.0000) | Acc: (91.00%) (21124/23168)
Epoch: 84 | Batch_idx: 190 |  Loss: (0.2507) |  Loss2: (0.0000) | Acc: (91.00%) (22295/24448)
Epoch: 84 | Batch_idx: 200 |  Loss: (0.2512) |  Loss2: (0.0000) | Acc: (91.00%) (23455/25728)
Epoch: 84 | Batch_idx: 210 |  Loss: (0.2497) |  Loss2: (0.0000) | Acc: (91.00%) (24641/27008)
Epoch: 84 | Batch_idx: 220 |  Loss: (0.2515) |  Loss2: (0.0000) | Acc: (91.00%) (25801/28288)
Epoch: 84 | Batch_idx: 230 |  Loss: (0.2504) |  Loss2: (0.0000) | Acc: (91.00%) (26984/29568)
Epoch: 84 | Batch_idx: 240 |  Loss: (0.2500) |  Loss2: (0.0000) | Acc: (91.00%) (28158/30848)
Epoch: 84 | Batch_idx: 250 |  Loss: (0.2495) |  Loss2: (0.0000) | Acc: (91.00%) (29321/32128)
Epoch: 84 | Batch_idx: 260 |  Loss: (0.2500) |  Loss2: (0.0000) | Acc: (91.00%) (30485/33408)
Epoch: 84 | Batch_idx: 270 |  Loss: (0.2509) |  Loss2: (0.0000) | Acc: (91.00%) (31655/34688)
Epoch: 84 | Batch_idx: 280 |  Loss: (0.2509) |  Loss2: (0.0000) | Acc: (91.00%) (32823/35968)
Epoch: 84 | Batch_idx: 290 |  Loss: (0.2503) |  Loss2: (0.0000) | Acc: (91.00%) (34000/37248)
Epoch: 84 | Batch_idx: 300 |  Loss: (0.2508) |  Loss2: (0.0000) | Acc: (91.00%) (35154/38528)
Epoch: 84 | Batch_idx: 310 |  Loss: (0.2511) |  Loss2: (0.0000) | Acc: (91.00%) (36327/39808)
Epoch: 84 | Batch_idx: 320 |  Loss: (0.2509) |  Loss2: (0.0000) | Acc: (91.00%) (37512/41088)
Epoch: 84 | Batch_idx: 330 |  Loss: (0.2503) |  Loss2: (0.0000) | Acc: (91.00%) (38692/42368)
Epoch: 84 | Batch_idx: 340 |  Loss: (0.2505) |  Loss2: (0.0000) | Acc: (91.00%) (39867/43648)
Epoch: 84 | Batch_idx: 350 |  Loss: (0.2506) |  Loss2: (0.0000) | Acc: (91.00%) (41034/44928)
Epoch: 84 | Batch_idx: 360 |  Loss: (0.2507) |  Loss2: (0.0000) | Acc: (91.00%) (42201/46208)
Epoch: 84 | Batch_idx: 370 |  Loss: (0.2501) |  Loss2: (0.0000) | Acc: (91.00%) (43385/47488)
Epoch: 84 | Batch_idx: 380 |  Loss: (0.2497) |  Loss2: (0.0000) | Acc: (91.00%) (44566/48768)
Epoch: 84 | Batch_idx: 390 |  Loss: (0.2495) |  Loss2: (0.0000) | Acc: (91.00%) (45696/50000)
# TEST : Loss: (0.3921) | Acc: (87.00%) (8705/10000)
percent tensor([0.5843, 0.5781, 0.5874, 0.5766, 0.5928, 0.5816, 0.5861, 0.5794, 0.5859,
        0.5779, 0.5821, 0.5856, 0.5797, 0.5729, 0.5798, 0.5783],
       device='cuda:0') torch.Size([16])
percent tensor([0.5651, 0.5317, 0.5242, 0.5749, 0.5540, 0.6075, 0.5386, 0.5536, 0.5469,
        0.5301, 0.5412, 0.5204, 0.5277, 0.5747, 0.5649, 0.5702],
       device='cuda:0') torch.Size([16])
percent tensor([0.5030, 0.5400, 0.4951, 0.4695, 0.5016, 0.4606, 0.5436, 0.5105, 0.5109,
        0.5069, 0.5091, 0.5168, 0.5252, 0.5233, 0.5102, 0.5039],
       device='cuda:0') torch.Size([16])
percent tensor([0.6124, 0.5823, 0.5944, 0.6000, 0.6041, 0.6172, 0.6003, 0.6071, 0.6072,
        0.5917, 0.6009, 0.5941, 0.5990, 0.6049, 0.6045, 0.6154],
       device='cuda:0') torch.Size([16])
percent tensor([0.5909, 0.6845, 0.6310, 0.6382, 0.5831, 0.6676, 0.6284, 0.5002, 0.7198,
        0.6187, 0.6889, 0.6839, 0.7219, 0.7500, 0.5962, 0.6323],
       device='cuda:0') torch.Size([16])
percent tensor([0.6765, 0.6713, 0.7302, 0.7308, 0.7562, 0.7677, 0.7131, 0.6636, 0.7457,
        0.6810, 0.7355, 0.6866, 0.6663, 0.8015, 0.6574, 0.7128],
       device='cuda:0') torch.Size([16])
percent tensor([0.6596, 0.6083, 0.7121, 0.6411, 0.7603, 0.6554, 0.6681, 0.7074, 0.6217,
        0.6424, 0.6020, 0.6243, 0.5308, 0.6503, 0.6137, 0.7043],
       device='cuda:0') torch.Size([16])
percent tensor([0.9991, 0.9984, 0.9988, 0.9991, 0.9987, 0.9978, 0.9985, 0.9990, 0.9987,
        0.9992, 0.9988, 0.9989, 0.9987, 0.9992, 0.9983, 0.9987],
       device='cuda:0') torch.Size([16])
False Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=128, out_features=16, bias=False)
True Linear(in_features=16, out_features=2, bias=False)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=128, out_features=16, bias=False)
True Linear(in_features=16, out_features=2, bias=False)
False Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=256, out_features=32, bias=False)
True Linear(in_features=32, out_features=2, bias=False)
False Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=256, out_features=32, bias=False)
True Linear(in_features=32, out_features=2, bias=False)
False Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=512, out_features=64, bias=False)
True Linear(in_features=64, out_features=2, bias=False)
False Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=512, out_features=64, bias=False)
True Linear(in_features=64, out_features=2, bias=False)
False Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1024, out_features=128, bias=False)
True Linear(in_features=128, out_features=2, bias=False)
False Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1024, out_features=128, bias=False)
True Linear(in_features=128, out_features=2, bias=False)
False Linear(in_features=512, out_features=10, bias=True)
Epoch: 85 | Batch_idx: 0 |  Loss: (0.2089) |  Loss2: (0.0000) | Acc: (93.00%) (120/128)
Epoch: 85 | Batch_idx: 10 |  Loss: (0.2187) |  Loss2: (0.0000) | Acc: (92.00%) (1298/1408)
Epoch: 85 | Batch_idx: 20 |  Loss: (0.2357) |  Loss2: (0.0000) | Acc: (91.00%) (2455/2688)
Epoch: 85 | Batch_idx: 30 |  Loss: (0.2569) |  Loss2: (0.0000) | Acc: (90.00%) (3607/3968)
Epoch: 85 | Batch_idx: 40 |  Loss: (0.2672) |  Loss2: (0.0000) | Acc: (90.00%) (4741/5248)
Epoch: 85 | Batch_idx: 50 |  Loss: (0.2680) |  Loss2: (0.0000) | Acc: (90.00%) (5899/6528)
Epoch: 85 | Batch_idx: 60 |  Loss: (0.2757) |  Loss2: (0.0000) | Acc: (90.00%) (7035/7808)
Epoch: 85 | Batch_idx: 70 |  Loss: (0.2793) |  Loss2: (0.0000) | Acc: (90.00%) (8187/9088)
Epoch: 85 | Batch_idx: 80 |  Loss: (0.2750) |  Loss2: (0.0000) | Acc: (90.00%) (9360/10368)
Epoch: 85 | Batch_idx: 90 |  Loss: (0.2787) |  Loss2: (0.0000) | Acc: (90.00%) (10502/11648)
Epoch: 85 | Batch_idx: 100 |  Loss: (0.2759) |  Loss2: (0.0000) | Acc: (90.00%) (11672/12928)
Epoch: 85 | Batch_idx: 110 |  Loss: (0.2741) |  Loss2: (0.0000) | Acc: (90.00%) (12843/14208)
Epoch: 85 | Batch_idx: 120 |  Loss: (0.2764) |  Loss2: (0.0000) | Acc: (90.00%) (13987/15488)
Epoch: 85 | Batch_idx: 130 |  Loss: (0.2777) |  Loss2: (0.0000) | Acc: (90.00%) (15137/16768)
Epoch: 85 | Batch_idx: 140 |  Loss: (0.2793) |  Loss2: (0.0000) | Acc: (90.00%) (16290/18048)
Epoch: 85 | Batch_idx: 150 |  Loss: (0.2806) |  Loss2: (0.0000) | Acc: (90.00%) (17438/19328)
Epoch: 85 | Batch_idx: 160 |  Loss: (0.2812) |  Loss2: (0.0000) | Acc: (90.00%) (18580/20608)
Epoch: 85 | Batch_idx: 170 |  Loss: (0.2803) |  Loss2: (0.0000) | Acc: (90.00%) (19738/21888)
Epoch: 85 | Batch_idx: 180 |  Loss: (0.2791) |  Loss2: (0.0000) | Acc: (90.00%) (20903/23168)
Epoch: 85 | Batch_idx: 190 |  Loss: (0.2785) |  Loss2: (0.0000) | Acc: (90.00%) (22063/24448)
Epoch: 85 | Batch_idx: 200 |  Loss: (0.2788) |  Loss2: (0.0000) | Acc: (90.00%) (23218/25728)
Epoch: 85 | Batch_idx: 210 |  Loss: (0.2781) |  Loss2: (0.0000) | Acc: (90.00%) (24377/27008)
Epoch: 85 | Batch_idx: 220 |  Loss: (0.2777) |  Loss2: (0.0000) | Acc: (90.00%) (25544/28288)
Epoch: 85 | Batch_idx: 230 |  Loss: (0.2778) |  Loss2: (0.0000) | Acc: (90.00%) (26700/29568)
Epoch: 85 | Batch_idx: 240 |  Loss: (0.2767) |  Loss2: (0.0000) | Acc: (90.00%) (27861/30848)
Epoch: 85 | Batch_idx: 250 |  Loss: (0.2774) |  Loss2: (0.0000) | Acc: (90.00%) (29009/32128)
Epoch: 85 | Batch_idx: 260 |  Loss: (0.2778) |  Loss2: (0.0000) | Acc: (90.00%) (30156/33408)
Epoch: 85 | Batch_idx: 270 |  Loss: (0.2772) |  Loss2: (0.0000) | Acc: (90.00%) (31321/34688)
Epoch: 85 | Batch_idx: 280 |  Loss: (0.2779) |  Loss2: (0.0000) | Acc: (90.00%) (32473/35968)
Epoch: 85 | Batch_idx: 290 |  Loss: (0.2770) |  Loss2: (0.0000) | Acc: (90.00%) (33645/37248)
Epoch: 85 | Batch_idx: 300 |  Loss: (0.2761) |  Loss2: (0.0000) | Acc: (90.00%) (34816/38528)
Epoch: 85 | Batch_idx: 310 |  Loss: (0.2760) |  Loss2: (0.0000) | Acc: (90.00%) (35974/39808)
Epoch: 85 | Batch_idx: 320 |  Loss: (0.2755) |  Loss2: (0.0000) | Acc: (90.00%) (37137/41088)
Epoch: 85 | Batch_idx: 330 |  Loss: (0.2755) |  Loss2: (0.0000) | Acc: (90.00%) (38300/42368)
Epoch: 85 | Batch_idx: 340 |  Loss: (0.2744) |  Loss2: (0.0000) | Acc: (90.00%) (39474/43648)
Epoch: 85 | Batch_idx: 350 |  Loss: (0.2730) |  Loss2: (0.0000) | Acc: (90.00%) (40656/44928)
Epoch: 85 | Batch_idx: 360 |  Loss: (0.2731) |  Loss2: (0.0000) | Acc: (90.00%) (41814/46208)
Epoch: 85 | Batch_idx: 370 |  Loss: (0.2724) |  Loss2: (0.0000) | Acc: (90.00%) (42990/47488)
Epoch: 85 | Batch_idx: 380 |  Loss: (0.2710) |  Loss2: (0.0000) | Acc: (90.00%) (44173/48768)
Epoch: 85 | Batch_idx: 390 |  Loss: (0.2701) |  Loss2: (0.0000) | Acc: (90.00%) (45305/50000)
=> saving checkpoint 'drive/app/torch/save_Routing_Gate_2/checkpoint_085.pth.tar'
# TEST : Loss: (0.4175) | Acc: (86.00%) (8662/10000)
percent tensor([0.5970, 0.5927, 0.6027, 0.5907, 0.6087, 0.5951, 0.6014, 0.5946, 0.5995,
        0.5935, 0.5956, 0.6013, 0.5935, 0.5861, 0.5944, 0.5919],
       device='cuda:0') torch.Size([16])
percent tensor([0.5628, 0.5369, 0.5225, 0.5778, 0.5496, 0.6069, 0.5403, 0.5548, 0.5493,
        0.5313, 0.5417, 0.5191, 0.5250, 0.5847, 0.5659, 0.5719],
       device='cuda:0') torch.Size([16])
percent tensor([0.5238, 0.5515, 0.5232, 0.4955, 0.5291, 0.4770, 0.5588, 0.5381, 0.5250,
        0.5219, 0.5222, 0.5382, 0.5424, 0.5276, 0.5279, 0.5233],
       device='cuda:0') torch.Size([16])
percent tensor([0.6032, 0.5734, 0.5881, 0.5951, 0.5979, 0.6105, 0.5912, 0.6021, 0.5982,
        0.5828, 0.5909, 0.5846, 0.5887, 0.5951, 0.5964, 0.6086],
       device='cuda:0') torch.Size([16])
percent tensor([0.5695, 0.6459, 0.6246, 0.6269, 0.5933, 0.6663, 0.6009, 0.4720, 0.7022,
        0.5818, 0.6624, 0.6575, 0.6857, 0.7260, 0.5682, 0.6049],
       device='cuda:0') torch.Size([16])
percent tensor([0.6420, 0.6341, 0.7057, 0.7014, 0.7412, 0.7503, 0.6785, 0.6334, 0.7179,
        0.6457, 0.6996, 0.6550, 0.6242, 0.7752, 0.6161, 0.6869],
       device='cuda:0') torch.Size([16])
percent tensor([0.6397, 0.5893, 0.7095, 0.6413, 0.7607, 0.6277, 0.6639, 0.7037, 0.6071,
        0.6308, 0.5919, 0.6122, 0.5096, 0.6263, 0.6089, 0.6862],
       device='cuda:0') torch.Size([16])
percent tensor([0.9990, 0.9981, 0.9989, 0.9992, 0.9988, 0.9975, 0.9986, 0.9990, 0.9987,
        0.9991, 0.9989, 0.9989, 0.9984, 0.9992, 0.9983, 0.9989],
       device='cuda:0') torch.Size([16])
Epoch: 86 | Batch_idx: 0 |  Loss: (0.2656) |  Loss2: (0.0000) | Acc: (91.00%) (117/128)
Epoch: 86 | Batch_idx: 10 |  Loss: (0.2684) |  Loss2: (0.0000) | Acc: (90.00%) (1274/1408)
Epoch: 86 | Batch_idx: 20 |  Loss: (0.2673) |  Loss2: (0.0000) | Acc: (90.00%) (2439/2688)
Epoch: 86 | Batch_idx: 30 |  Loss: (0.2653) |  Loss2: (0.0000) | Acc: (90.00%) (3595/3968)
Epoch: 86 | Batch_idx: 40 |  Loss: (0.2651) |  Loss2: (0.0000) | Acc: (90.00%) (4759/5248)
Epoch: 86 | Batch_idx: 50 |  Loss: (0.2653) |  Loss2: (0.0000) | Acc: (90.00%) (5921/6528)
Epoch: 86 | Batch_idx: 60 |  Loss: (0.2598) |  Loss2: (0.0000) | Acc: (90.00%) (7096/7808)
Epoch: 86 | Batch_idx: 70 |  Loss: (0.2588) |  Loss2: (0.0000) | Acc: (90.00%) (8265/9088)
Epoch: 86 | Batch_idx: 80 |  Loss: (0.2559) |  Loss2: (0.0000) | Acc: (91.00%) (9442/10368)
Epoch: 86 | Batch_idx: 90 |  Loss: (0.2580) |  Loss2: (0.0000) | Acc: (91.00%) (10605/11648)
Epoch: 86 | Batch_idx: 100 |  Loss: (0.2551) |  Loss2: (0.0000) | Acc: (91.00%) (11776/12928)
Epoch: 86 | Batch_idx: 110 |  Loss: (0.2569) |  Loss2: (0.0000) | Acc: (91.00%) (12934/14208)
Epoch: 86 | Batch_idx: 120 |  Loss: (0.2571) |  Loss2: (0.0000) | Acc: (91.00%) (14103/15488)
Epoch: 86 | Batch_idx: 130 |  Loss: (0.2546) |  Loss2: (0.0000) | Acc: (91.00%) (15272/16768)
Epoch: 86 | Batch_idx: 140 |  Loss: (0.2524) |  Loss2: (0.0000) | Acc: (91.00%) (16448/18048)
Epoch: 86 | Batch_idx: 150 |  Loss: (0.2519) |  Loss2: (0.0000) | Acc: (91.00%) (17620/19328)
Epoch: 86 | Batch_idx: 160 |  Loss: (0.2521) |  Loss2: (0.0000) | Acc: (91.00%) (18779/20608)
Epoch: 86 | Batch_idx: 170 |  Loss: (0.2536) |  Loss2: (0.0000) | Acc: (91.00%) (19925/21888)
Epoch: 86 | Batch_idx: 180 |  Loss: (0.2549) |  Loss2: (0.0000) | Acc: (90.00%) (21075/23168)
Epoch: 86 | Batch_idx: 190 |  Loss: (0.2549) |  Loss2: (0.0000) | Acc: (90.00%) (22232/24448)
Epoch: 86 | Batch_idx: 200 |  Loss: (0.2546) |  Loss2: (0.0000) | Acc: (90.00%) (23392/25728)
Epoch: 86 | Batch_idx: 210 |  Loss: (0.2541) |  Loss2: (0.0000) | Acc: (90.00%) (24564/27008)
Epoch: 86 | Batch_idx: 220 |  Loss: (0.2528) |  Loss2: (0.0000) | Acc: (91.00%) (25749/28288)
Epoch: 86 | Batch_idx: 230 |  Loss: (0.2536) |  Loss2: (0.0000) | Acc: (91.00%) (26917/29568)
Epoch: 86 | Batch_idx: 240 |  Loss: (0.2522) |  Loss2: (0.0000) | Acc: (91.00%) (28099/30848)
Epoch: 86 | Batch_idx: 250 |  Loss: (0.2518) |  Loss2: (0.0000) | Acc: (91.00%) (29272/32128)
Epoch: 86 | Batch_idx: 260 |  Loss: (0.2521) |  Loss2: (0.0000) | Acc: (91.00%) (30430/33408)
Epoch: 86 | Batch_idx: 270 |  Loss: (0.2530) |  Loss2: (0.0000) | Acc: (91.00%) (31587/34688)
Epoch: 86 | Batch_idx: 280 |  Loss: (0.2524) |  Loss2: (0.0000) | Acc: (91.00%) (32767/35968)
Epoch: 86 | Batch_idx: 290 |  Loss: (0.2524) |  Loss2: (0.0000) | Acc: (91.00%) (33932/37248)
Epoch: 86 | Batch_idx: 300 |  Loss: (0.2516) |  Loss2: (0.0000) | Acc: (91.00%) (35112/38528)
Epoch: 86 | Batch_idx: 310 |  Loss: (0.2519) |  Loss2: (0.0000) | Acc: (91.00%) (36264/39808)
Epoch: 86 | Batch_idx: 320 |  Loss: (0.2512) |  Loss2: (0.0000) | Acc: (91.00%) (37435/41088)
Epoch: 86 | Batch_idx: 330 |  Loss: (0.2513) |  Loss2: (0.0000) | Acc: (91.00%) (38608/42368)
Epoch: 86 | Batch_idx: 340 |  Loss: (0.2519) |  Loss2: (0.0000) | Acc: (91.00%) (39759/43648)
Epoch: 86 | Batch_idx: 350 |  Loss: (0.2515) |  Loss2: (0.0000) | Acc: (91.00%) (40933/44928)
Epoch: 86 | Batch_idx: 360 |  Loss: (0.2514) |  Loss2: (0.0000) | Acc: (91.00%) (42101/46208)
Epoch: 86 | Batch_idx: 370 |  Loss: (0.2516) |  Loss2: (0.0000) | Acc: (91.00%) (43263/47488)
Epoch: 86 | Batch_idx: 380 |  Loss: (0.2508) |  Loss2: (0.0000) | Acc: (91.00%) (44449/48768)
Epoch: 86 | Batch_idx: 390 |  Loss: (0.2504) |  Loss2: (0.0000) | Acc: (91.00%) (45584/50000)
# TEST : Loss: (0.3991) | Acc: (87.00%) (8702/10000)
percent tensor([0.5936, 0.5890, 0.6005, 0.5877, 0.6059, 0.5922, 0.5978, 0.5916, 0.5957,
        0.5904, 0.5918, 0.5987, 0.5899, 0.5821, 0.5911, 0.5885],
       device='cuda:0') torch.Size([16])
percent tensor([0.5625, 0.5367, 0.5218, 0.5785, 0.5484, 0.6076, 0.5397, 0.5538, 0.5496,
        0.5313, 0.5421, 0.5178, 0.5242, 0.5860, 0.5653, 0.5726],
       device='cuda:0') torch.Size([16])
percent tensor([0.5203, 0.5453, 0.5268, 0.4969, 0.5330, 0.4760, 0.5564, 0.5408, 0.5220,
        0.5170, 0.5156, 0.5385, 0.5363, 0.5217, 0.5254, 0.5203],
       device='cuda:0') torch.Size([16])
percent tensor([0.6087, 0.5784, 0.5925, 0.5994, 0.6030, 0.6164, 0.5955, 0.6057, 0.6021,
        0.5883, 0.5956, 0.5892, 0.5940, 0.5989, 0.6015, 0.6145],
       device='cuda:0') torch.Size([16])
percent tensor([0.5735, 0.6455, 0.6321, 0.6302, 0.6049, 0.6720, 0.6078, 0.4727, 0.7085,
        0.5791, 0.6674, 0.6585, 0.6871, 0.7307, 0.5680, 0.6061],
       device='cuda:0') torch.Size([16])
percent tensor([0.6484, 0.6382, 0.7141, 0.7100, 0.7502, 0.7597, 0.6802, 0.6352, 0.7230,
        0.6519, 0.7031, 0.6621, 0.6299, 0.7826, 0.6178, 0.6939],
       device='cuda:0') torch.Size([16])
percent tensor([0.6370, 0.5836, 0.7154, 0.6467, 0.7697, 0.6253, 0.6632, 0.7109, 0.6055,
        0.6294, 0.5896, 0.6174, 0.5030, 0.6285, 0.6143, 0.6824],
       device='cuda:0') torch.Size([16])
percent tensor([0.9990, 0.9981, 0.9988, 0.9992, 0.9988, 0.9975, 0.9987, 0.9990, 0.9987,
        0.9992, 0.9989, 0.9990, 0.9984, 0.9992, 0.9983, 0.9989],
       device='cuda:0') torch.Size([16])
Epoch: 87 | Batch_idx: 0 |  Loss: (0.2333) |  Loss2: (0.0000) | Acc: (91.00%) (117/128)
Epoch: 87 | Batch_idx: 10 |  Loss: (0.2074) |  Loss2: (0.0000) | Acc: (92.00%) (1303/1408)
Epoch: 87 | Batch_idx: 20 |  Loss: (0.2220) |  Loss2: (0.0000) | Acc: (92.00%) (2484/2688)
Epoch: 87 | Batch_idx: 30 |  Loss: (0.2289) |  Loss2: (0.0000) | Acc: (92.00%) (3653/3968)
Epoch: 87 | Batch_idx: 40 |  Loss: (0.2233) |  Loss2: (0.0000) | Acc: (92.00%) (4842/5248)
Epoch: 87 | Batch_idx: 50 |  Loss: (0.2316) |  Loss2: (0.0000) | Acc: (91.00%) (6002/6528)
Epoch: 87 | Batch_idx: 60 |  Loss: (0.2327) |  Loss2: (0.0000) | Acc: (92.00%) (7192/7808)
Epoch: 87 | Batch_idx: 70 |  Loss: (0.2357) |  Loss2: (0.0000) | Acc: (92.00%) (8363/9088)
Epoch: 87 | Batch_idx: 80 |  Loss: (0.2374) |  Loss2: (0.0000) | Acc: (91.00%) (9533/10368)
Epoch: 87 | Batch_idx: 90 |  Loss: (0.2384) |  Loss2: (0.0000) | Acc: (91.00%) (10700/11648)
Epoch: 87 | Batch_idx: 100 |  Loss: (0.2388) |  Loss2: (0.0000) | Acc: (91.00%) (11872/12928)
Epoch: 87 | Batch_idx: 110 |  Loss: (0.2371) |  Loss2: (0.0000) | Acc: (91.00%) (13064/14208)
Epoch: 87 | Batch_idx: 120 |  Loss: (0.2377) |  Loss2: (0.0000) | Acc: (91.00%) (14237/15488)
Epoch: 87 | Batch_idx: 130 |  Loss: (0.2378) |  Loss2: (0.0000) | Acc: (91.00%) (15418/16768)
Epoch: 87 | Batch_idx: 140 |  Loss: (0.2381) |  Loss2: (0.0000) | Acc: (91.00%) (16576/18048)
Epoch: 87 | Batch_idx: 150 |  Loss: (0.2382) |  Loss2: (0.0000) | Acc: (91.00%) (17747/19328)
Epoch: 87 | Batch_idx: 160 |  Loss: (0.2403) |  Loss2: (0.0000) | Acc: (91.00%) (18914/20608)
Epoch: 87 | Batch_idx: 170 |  Loss: (0.2401) |  Loss2: (0.0000) | Acc: (91.00%) (20103/21888)
Epoch: 87 | Batch_idx: 180 |  Loss: (0.2402) |  Loss2: (0.0000) | Acc: (91.00%) (21282/23168)
Epoch: 87 | Batch_idx: 190 |  Loss: (0.2399) |  Loss2: (0.0000) | Acc: (91.00%) (22458/24448)
Epoch: 87 | Batch_idx: 200 |  Loss: (0.2392) |  Loss2: (0.0000) | Acc: (91.00%) (23639/25728)
Epoch: 87 | Batch_idx: 210 |  Loss: (0.2400) |  Loss2: (0.0000) | Acc: (91.00%) (24790/27008)
Epoch: 87 | Batch_idx: 220 |  Loss: (0.2421) |  Loss2: (0.0000) | Acc: (91.00%) (25950/28288)
Epoch: 87 | Batch_idx: 230 |  Loss: (0.2428) |  Loss2: (0.0000) | Acc: (91.00%) (27118/29568)
Epoch: 87 | Batch_idx: 240 |  Loss: (0.2426) |  Loss2: (0.0000) | Acc: (91.00%) (28283/30848)
Epoch: 87 | Batch_idx: 250 |  Loss: (0.2418) |  Loss2: (0.0000) | Acc: (91.00%) (29462/32128)
Epoch: 87 | Batch_idx: 260 |  Loss: (0.2413) |  Loss2: (0.0000) | Acc: (91.00%) (30640/33408)
Epoch: 87 | Batch_idx: 270 |  Loss: (0.2412) |  Loss2: (0.0000) | Acc: (91.00%) (31816/34688)
Epoch: 87 | Batch_idx: 280 |  Loss: (0.2414) |  Loss2: (0.0000) | Acc: (91.00%) (32991/35968)
Epoch: 87 | Batch_idx: 290 |  Loss: (0.2412) |  Loss2: (0.0000) | Acc: (91.00%) (34169/37248)
Epoch: 87 | Batch_idx: 300 |  Loss: (0.2414) |  Loss2: (0.0000) | Acc: (91.00%) (35336/38528)
Epoch: 87 | Batch_idx: 310 |  Loss: (0.2417) |  Loss2: (0.0000) | Acc: (91.00%) (36502/39808)
Epoch: 87 | Batch_idx: 320 |  Loss: (0.2413) |  Loss2: (0.0000) | Acc: (91.00%) (37684/41088)
Epoch: 87 | Batch_idx: 330 |  Loss: (0.2412) |  Loss2: (0.0000) | Acc: (91.00%) (38860/42368)
Epoch: 87 | Batch_idx: 340 |  Loss: (0.2403) |  Loss2: (0.0000) | Acc: (91.00%) (40047/43648)
Epoch: 87 | Batch_idx: 350 |  Loss: (0.2410) |  Loss2: (0.0000) | Acc: (91.00%) (41211/44928)
Epoch: 87 | Batch_idx: 360 |  Loss: (0.2416) |  Loss2: (0.0000) | Acc: (91.00%) (42374/46208)
Epoch: 87 | Batch_idx: 370 |  Loss: (0.2418) |  Loss2: (0.0000) | Acc: (91.00%) (43541/47488)
Epoch: 87 | Batch_idx: 380 |  Loss: (0.2424) |  Loss2: (0.0000) | Acc: (91.00%) (44709/48768)
Epoch: 87 | Batch_idx: 390 |  Loss: (0.2419) |  Loss2: (0.0000) | Acc: (91.00%) (45848/50000)
# TEST : Loss: (0.3975) | Acc: (87.00%) (8703/10000)
percent tensor([0.5916, 0.5872, 0.5996, 0.5862, 0.6046, 0.5905, 0.5961, 0.5899, 0.5935,
        0.5889, 0.5898, 0.5974, 0.5879, 0.5798, 0.5894, 0.5866],
       device='cuda:0') torch.Size([16])
percent tensor([0.5598, 0.5338, 0.5201, 0.5774, 0.5461, 0.6060, 0.5368, 0.5513, 0.5473,
        0.5290, 0.5396, 0.5153, 0.5211, 0.5845, 0.5624, 0.5707],
       device='cuda:0') torch.Size([16])
percent tensor([0.5254, 0.5493, 0.5324, 0.5033, 0.5392, 0.4830, 0.5608, 0.5468, 0.5259,
        0.5210, 0.5191, 0.5437, 0.5403, 0.5248, 0.5316, 0.5260],
       device='cuda:0') torch.Size([16])
percent tensor([0.6141, 0.5833, 0.5977, 0.6043, 0.6087, 0.6221, 0.6005, 0.6107, 0.6068,
        0.5941, 0.6005, 0.5946, 0.5993, 0.6033, 0.6069, 0.6206],
       device='cuda:0') torch.Size([16])
percent tensor([0.5682, 0.6387, 0.6252, 0.6213, 0.6002, 0.6676, 0.6034, 0.4618, 0.7038,
        0.5705, 0.6636, 0.6504, 0.6802, 0.7244, 0.5628, 0.5973],
       device='cuda:0') torch.Size([16])
percent tensor([0.6449, 0.6349, 0.7124, 0.7086, 0.7507, 0.7609, 0.6760, 0.6317, 0.7207,
        0.6478, 0.6995, 0.6582, 0.6235, 0.7833, 0.6129, 0.6913],
       device='cuda:0') torch.Size([16])
percent tensor([0.6476, 0.5960, 0.7264, 0.6554, 0.7808, 0.6345, 0.6726, 0.7191, 0.6192,
        0.6408, 0.6044, 0.6302, 0.5169, 0.6485, 0.6258, 0.6894],
       device='cuda:0') torch.Size([16])
percent tensor([0.9990, 0.9981, 0.9988, 0.9993, 0.9989, 0.9975, 0.9987, 0.9991, 0.9988,
        0.9992, 0.9989, 0.9991, 0.9985, 0.9992, 0.9983, 0.9989],
       device='cuda:0') torch.Size([16])
Epoch: 88 | Batch_idx: 0 |  Loss: (0.2184) |  Loss2: (0.0000) | Acc: (92.00%) (118/128)
Epoch: 88 | Batch_idx: 10 |  Loss: (0.2380) |  Loss2: (0.0000) | Acc: (91.00%) (1290/1408)
Epoch: 88 | Batch_idx: 20 |  Loss: (0.2416) |  Loss2: (0.0000) | Acc: (91.00%) (2464/2688)
Epoch: 88 | Batch_idx: 30 |  Loss: (0.2458) |  Loss2: (0.0000) | Acc: (91.00%) (3636/3968)
Epoch: 88 | Batch_idx: 40 |  Loss: (0.2342) |  Loss2: (0.0000) | Acc: (91.00%) (4826/5248)
Epoch: 88 | Batch_idx: 50 |  Loss: (0.2366) |  Loss2: (0.0000) | Acc: (91.00%) (5987/6528)
Epoch: 88 | Batch_idx: 60 |  Loss: (0.2352) |  Loss2: (0.0000) | Acc: (91.00%) (7170/7808)
Epoch: 88 | Batch_idx: 70 |  Loss: (0.2377) |  Loss2: (0.0000) | Acc: (91.00%) (8336/9088)
Epoch: 88 | Batch_idx: 80 |  Loss: (0.2363) |  Loss2: (0.0000) | Acc: (91.00%) (9502/10368)
Epoch: 88 | Batch_idx: 90 |  Loss: (0.2359) |  Loss2: (0.0000) | Acc: (91.00%) (10678/11648)
Epoch: 88 | Batch_idx: 100 |  Loss: (0.2352) |  Loss2: (0.0000) | Acc: (91.00%) (11854/12928)
Epoch: 88 | Batch_idx: 110 |  Loss: (0.2356) |  Loss2: (0.0000) | Acc: (91.00%) (13032/14208)
Epoch: 88 | Batch_idx: 120 |  Loss: (0.2345) |  Loss2: (0.0000) | Acc: (91.00%) (14217/15488)
Epoch: 88 | Batch_idx: 130 |  Loss: (0.2352) |  Loss2: (0.0000) | Acc: (91.00%) (15386/16768)
Epoch: 88 | Batch_idx: 140 |  Loss: (0.2347) |  Loss2: (0.0000) | Acc: (91.00%) (16564/18048)
Epoch: 88 | Batch_idx: 150 |  Loss: (0.2344) |  Loss2: (0.0000) | Acc: (91.00%) (17755/19328)
Epoch: 88 | Batch_idx: 160 |  Loss: (0.2331) |  Loss2: (0.0000) | Acc: (91.00%) (18938/20608)
Epoch: 88 | Batch_idx: 170 |  Loss: (0.2331) |  Loss2: (0.0000) | Acc: (91.00%) (20113/21888)
Epoch: 88 | Batch_idx: 180 |  Loss: (0.2338) |  Loss2: (0.0000) | Acc: (91.00%) (21285/23168)
Epoch: 88 | Batch_idx: 190 |  Loss: (0.2343) |  Loss2: (0.0000) | Acc: (91.00%) (22457/24448)
Epoch: 88 | Batch_idx: 200 |  Loss: (0.2347) |  Loss2: (0.0000) | Acc: (91.00%) (23631/25728)
Epoch: 88 | Batch_idx: 210 |  Loss: (0.2360) |  Loss2: (0.0000) | Acc: (91.00%) (24805/27008)
Epoch: 88 | Batch_idx: 220 |  Loss: (0.2356) |  Loss2: (0.0000) | Acc: (91.00%) (25991/28288)
Epoch: 88 | Batch_idx: 230 |  Loss: (0.2353) |  Loss2: (0.0000) | Acc: (91.00%) (27171/29568)
Epoch: 88 | Batch_idx: 240 |  Loss: (0.2342) |  Loss2: (0.0000) | Acc: (91.00%) (28356/30848)
Epoch: 88 | Batch_idx: 250 |  Loss: (0.2337) |  Loss2: (0.0000) | Acc: (91.00%) (29539/32128)
Epoch: 88 | Batch_idx: 260 |  Loss: (0.2338) |  Loss2: (0.0000) | Acc: (91.00%) (30718/33408)
Epoch: 88 | Batch_idx: 270 |  Loss: (0.2332) |  Loss2: (0.0000) | Acc: (91.00%) (31904/34688)
Epoch: 88 | Batch_idx: 280 |  Loss: (0.2337) |  Loss2: (0.0000) | Acc: (91.00%) (33079/35968)
Epoch: 88 | Batch_idx: 290 |  Loss: (0.2340) |  Loss2: (0.0000) | Acc: (91.00%) (34260/37248)
Epoch: 88 | Batch_idx: 300 |  Loss: (0.2350) |  Loss2: (0.0000) | Acc: (91.00%) (35426/38528)
Epoch: 88 | Batch_idx: 310 |  Loss: (0.2347) |  Loss2: (0.0000) | Acc: (91.00%) (36605/39808)
Epoch: 88 | Batch_idx: 320 |  Loss: (0.2342) |  Loss2: (0.0000) | Acc: (91.00%) (37786/41088)
Epoch: 88 | Batch_idx: 330 |  Loss: (0.2340) |  Loss2: (0.0000) | Acc: (91.00%) (38962/42368)
Epoch: 88 | Batch_idx: 340 |  Loss: (0.2339) |  Loss2: (0.0000) | Acc: (91.00%) (40134/43648)
Epoch: 88 | Batch_idx: 350 |  Loss: (0.2342) |  Loss2: (0.0000) | Acc: (91.00%) (41307/44928)
Epoch: 88 | Batch_idx: 360 |  Loss: (0.2346) |  Loss2: (0.0000) | Acc: (91.00%) (42481/46208)
Epoch: 88 | Batch_idx: 370 |  Loss: (0.2343) |  Loss2: (0.0000) | Acc: (91.00%) (43657/47488)
Epoch: 88 | Batch_idx: 380 |  Loss: (0.2338) |  Loss2: (0.0000) | Acc: (91.00%) (44834/48768)
Epoch: 88 | Batch_idx: 390 |  Loss: (0.2336) |  Loss2: (0.0000) | Acc: (91.00%) (45977/50000)
# TEST : Loss: (0.3866) | Acc: (87.00%) (8746/10000)
percent tensor([0.5934, 0.5890, 0.6019, 0.5885, 0.6068, 0.5930, 0.5980, 0.5916, 0.5952,
        0.5908, 0.5914, 0.5995, 0.5894, 0.5816, 0.5914, 0.5885],
       device='cuda:0') torch.Size([16])
percent tensor([0.5689, 0.5436, 0.5302, 0.5870, 0.5556, 0.6148, 0.5465, 0.5611, 0.5572,
        0.5397, 0.5502, 0.5250, 0.5304, 0.5941, 0.5714, 0.5801],
       device='cuda:0') torch.Size([16])
percent tensor([0.5253, 0.5480, 0.5342, 0.5055, 0.5415, 0.4838, 0.5604, 0.5480, 0.5251,
        0.5204, 0.5172, 0.5444, 0.5382, 0.5243, 0.5314, 0.5265],
       device='cuda:0') torch.Size([16])
percent tensor([0.6223, 0.5921, 0.6047, 0.6112, 0.6160, 0.6304, 0.6086, 0.6177, 0.6141,
        0.6031, 0.6089, 0.6027, 0.6080, 0.6112, 0.6148, 0.6296],
       device='cuda:0') torch.Size([16])
percent tensor([0.5741, 0.6402, 0.6263, 0.6215, 0.6045, 0.6652, 0.6068, 0.4655, 0.7068,
        0.5739, 0.6705, 0.6518, 0.6834, 0.7276, 0.5642, 0.6003],
       device='cuda:0') torch.Size([16])
percent tensor([0.6607, 0.6472, 0.7259, 0.7238, 0.7621, 0.7737, 0.6882, 0.6450, 0.7334,
        0.6622, 0.7104, 0.6734, 0.6399, 0.7950, 0.6272, 0.7069],
       device='cuda:0') torch.Size([16])
percent tensor([0.6466, 0.5927, 0.7280, 0.6546, 0.7810, 0.6351, 0.6718, 0.7231, 0.6195,
        0.6378, 0.6047, 0.6342, 0.5150, 0.6457, 0.6309, 0.6845],
       device='cuda:0') torch.Size([16])
percent tensor([0.9990, 0.9983, 0.9988, 0.9993, 0.9988, 0.9976, 0.9987, 0.9991, 0.9989,
        0.9992, 0.9990, 0.9991, 0.9986, 0.9993, 0.9984, 0.9989],
       device='cuda:0') torch.Size([16])
Epoch: 89 | Batch_idx: 0 |  Loss: (0.2780) |  Loss2: (0.0000) | Acc: (90.00%) (116/128)
Epoch: 89 | Batch_idx: 10 |  Loss: (0.2238) |  Loss2: (0.0000) | Acc: (92.00%) (1309/1408)
Epoch: 89 | Batch_idx: 20 |  Loss: (0.2237) |  Loss2: (0.0000) | Acc: (92.00%) (2484/2688)
Epoch: 89 | Batch_idx: 30 |  Loss: (0.2218) |  Loss2: (0.0000) | Acc: (92.00%) (3665/3968)
Epoch: 89 | Batch_idx: 40 |  Loss: (0.2267) |  Loss2: (0.0000) | Acc: (92.00%) (4832/5248)
Epoch: 89 | Batch_idx: 50 |  Loss: (0.2313) |  Loss2: (0.0000) | Acc: (92.00%) (6006/6528)
Epoch: 89 | Batch_idx: 60 |  Loss: (0.2325) |  Loss2: (0.0000) | Acc: (92.00%) (7186/7808)
Epoch: 89 | Batch_idx: 70 |  Loss: (0.2300) |  Loss2: (0.0000) | Acc: (92.00%) (8367/9088)
Epoch: 89 | Batch_idx: 80 |  Loss: (0.2286) |  Loss2: (0.0000) | Acc: (92.00%) (9558/10368)
Epoch: 89 | Batch_idx: 90 |  Loss: (0.2277) |  Loss2: (0.0000) | Acc: (92.00%) (10738/11648)
Epoch: 89 | Batch_idx: 100 |  Loss: (0.2288) |  Loss2: (0.0000) | Acc: (92.00%) (11918/12928)
Epoch: 89 | Batch_idx: 110 |  Loss: (0.2313) |  Loss2: (0.0000) | Acc: (92.00%) (13078/14208)
Epoch: 89 | Batch_idx: 120 |  Loss: (0.2306) |  Loss2: (0.0000) | Acc: (92.00%) (14263/15488)
Epoch: 89 | Batch_idx: 130 |  Loss: (0.2301) |  Loss2: (0.0000) | Acc: (92.00%) (15447/16768)
Epoch: 89 | Batch_idx: 140 |  Loss: (0.2297) |  Loss2: (0.0000) | Acc: (92.00%) (16637/18048)
Epoch: 89 | Batch_idx: 150 |  Loss: (0.2291) |  Loss2: (0.0000) | Acc: (92.00%) (17825/19328)
Epoch: 89 | Batch_idx: 160 |  Loss: (0.2279) |  Loss2: (0.0000) | Acc: (92.00%) (19011/20608)
Epoch: 89 | Batch_idx: 170 |  Loss: (0.2273) |  Loss2: (0.0000) | Acc: (92.00%) (20198/21888)
Epoch: 89 | Batch_idx: 180 |  Loss: (0.2277) |  Loss2: (0.0000) | Acc: (92.00%) (21372/23168)
Epoch: 89 | Batch_idx: 190 |  Loss: (0.2291) |  Loss2: (0.0000) | Acc: (92.00%) (22547/24448)
Epoch: 89 | Batch_idx: 200 |  Loss: (0.2294) |  Loss2: (0.0000) | Acc: (92.00%) (23729/25728)
Epoch: 89 | Batch_idx: 210 |  Loss: (0.2296) |  Loss2: (0.0000) | Acc: (92.00%) (24903/27008)
Epoch: 89 | Batch_idx: 220 |  Loss: (0.2281) |  Loss2: (0.0000) | Acc: (92.00%) (26099/28288)
Epoch: 89 | Batch_idx: 230 |  Loss: (0.2286) |  Loss2: (0.0000) | Acc: (92.00%) (27271/29568)
Epoch: 89 | Batch_idx: 240 |  Loss: (0.2284) |  Loss2: (0.0000) | Acc: (92.00%) (28450/30848)
Epoch: 89 | Batch_idx: 250 |  Loss: (0.2272) |  Loss2: (0.0000) | Acc: (92.00%) (29642/32128)
Epoch: 89 | Batch_idx: 260 |  Loss: (0.2283) |  Loss2: (0.0000) | Acc: (92.00%) (30811/33408)
Epoch: 89 | Batch_idx: 270 |  Loss: (0.2292) |  Loss2: (0.0000) | Acc: (92.00%) (31984/34688)
Epoch: 89 | Batch_idx: 280 |  Loss: (0.2300) |  Loss2: (0.0000) | Acc: (92.00%) (33153/35968)
Epoch: 89 | Batch_idx: 290 |  Loss: (0.2303) |  Loss2: (0.0000) | Acc: (92.00%) (34328/37248)
Epoch: 89 | Batch_idx: 300 |  Loss: (0.2306) |  Loss2: (0.0000) | Acc: (92.00%) (35506/38528)
Epoch: 89 | Batch_idx: 310 |  Loss: (0.2304) |  Loss2: (0.0000) | Acc: (92.00%) (36683/39808)
Epoch: 89 | Batch_idx: 320 |  Loss: (0.2303) |  Loss2: (0.0000) | Acc: (92.00%) (37862/41088)
Epoch: 89 | Batch_idx: 330 |  Loss: (0.2301) |  Loss2: (0.0000) | Acc: (92.00%) (39036/42368)
Epoch: 89 | Batch_idx: 340 |  Loss: (0.2290) |  Loss2: (0.0000) | Acc: (92.00%) (40237/43648)
Epoch: 89 | Batch_idx: 350 |  Loss: (0.2286) |  Loss2: (0.0000) | Acc: (92.00%) (41441/44928)
Epoch: 89 | Batch_idx: 360 |  Loss: (0.2287) |  Loss2: (0.0000) | Acc: (92.00%) (42627/46208)
Epoch: 89 | Batch_idx: 370 |  Loss: (0.2287) |  Loss2: (0.0000) | Acc: (92.00%) (43810/47488)
Epoch: 89 | Batch_idx: 380 |  Loss: (0.2293) |  Loss2: (0.0000) | Acc: (92.00%) (44978/48768)
Epoch: 89 | Batch_idx: 390 |  Loss: (0.2293) |  Loss2: (0.0000) | Acc: (92.00%) (46115/50000)
# TEST : Loss: (0.3844) | Acc: (87.00%) (8747/10000)
percent tensor([0.5950, 0.5907, 0.6042, 0.5901, 0.6091, 0.5948, 0.6000, 0.5933, 0.5968,
        0.5926, 0.5929, 0.6018, 0.5909, 0.5828, 0.5932, 0.5902],
       device='cuda:0') torch.Size([16])
percent tensor([0.5665, 0.5409, 0.5285, 0.5845, 0.5530, 0.6114, 0.5441, 0.5586, 0.5550,
        0.5379, 0.5481, 0.5231, 0.5279, 0.5921, 0.5685, 0.5779],
       device='cuda:0') torch.Size([16])
percent tensor([0.5232, 0.5478, 0.5312, 0.5017, 0.5391, 0.4810, 0.5594, 0.5446, 0.5222,
        0.5195, 0.5157, 0.5429, 0.5366, 0.5227, 0.5297, 0.5245],
       device='cuda:0') torch.Size([16])
percent tensor([0.6222, 0.5922, 0.6033, 0.6114, 0.6152, 0.6306, 0.6080, 0.6168, 0.6134,
        0.6030, 0.6086, 0.6020, 0.6080, 0.6109, 0.6147, 0.6301],
       device='cuda:0') torch.Size([16])
percent tensor([0.5776, 0.6443, 0.6316, 0.6230, 0.6119, 0.6650, 0.6128, 0.4712, 0.7115,
        0.5785, 0.6775, 0.6539, 0.6877, 0.7300, 0.5689, 0.6009],
       device='cuda:0') torch.Size([16])
percent tensor([0.6677, 0.6539, 0.7346, 0.7329, 0.7712, 0.7815, 0.6948, 0.6515, 0.7400,
        0.6697, 0.7167, 0.6805, 0.6476, 0.8007, 0.6328, 0.7147],
       device='cuda:0') torch.Size([16])
percent tensor([0.6495, 0.5977, 0.7328, 0.6589, 0.7851, 0.6425, 0.6721, 0.7210, 0.6239,
        0.6411, 0.6083, 0.6364, 0.5209, 0.6544, 0.6334, 0.6878],
       device='cuda:0') torch.Size([16])
percent tensor([0.9991, 0.9983, 0.9988, 0.9993, 0.9990, 0.9977, 0.9988, 0.9991, 0.9989,
        0.9993, 0.9990, 0.9992, 0.9986, 0.9993, 0.9984, 0.9990],
       device='cuda:0') torch.Size([16])
True Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=128, out_features=16, bias=False)
False Linear(in_features=16, out_features=2, bias=False)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=128, out_features=16, bias=False)
False Linear(in_features=16, out_features=2, bias=False)
True Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=256, out_features=32, bias=False)
False Linear(in_features=32, out_features=2, bias=False)
True Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=256, out_features=32, bias=False)
False Linear(in_features=32, out_features=2, bias=False)
True Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=512, out_features=64, bias=False)
False Linear(in_features=64, out_features=2, bias=False)
True Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=512, out_features=64, bias=False)
False Linear(in_features=64, out_features=2, bias=False)
True Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1024, out_features=128, bias=False)
False Linear(in_features=128, out_features=2, bias=False)
True Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1024, out_features=128, bias=False)
False Linear(in_features=128, out_features=2, bias=False)
True Linear(in_features=512, out_features=10, bias=True)
Epoch: 90 | Batch_idx: 0 |  Loss: (0.3038) |  Loss2: (0.0000) | Acc: (88.00%) (113/128)
Epoch: 90 | Batch_idx: 10 |  Loss: (0.2360) |  Loss2: (0.0000) | Acc: (91.00%) (1295/1408)
Epoch: 90 | Batch_idx: 20 |  Loss: (0.2278) |  Loss2: (0.0000) | Acc: (92.00%) (2474/2688)
Epoch: 90 | Batch_idx: 30 |  Loss: (0.2302) |  Loss2: (0.0000) | Acc: (92.00%) (3651/3968)
Epoch: 90 | Batch_idx: 40 |  Loss: (0.2345) |  Loss2: (0.0000) | Acc: (91.00%) (4813/5248)
Epoch: 90 | Batch_idx: 50 |  Loss: (0.2343) |  Loss2: (0.0000) | Acc: (91.00%) (6001/6528)
Epoch: 90 | Batch_idx: 60 |  Loss: (0.2381) |  Loss2: (0.0000) | Acc: (91.00%) (7169/7808)
Epoch: 90 | Batch_idx: 70 |  Loss: (0.2347) |  Loss2: (0.0000) | Acc: (91.00%) (8353/9088)
Epoch: 90 | Batch_idx: 80 |  Loss: (0.2349) |  Loss2: (0.0000) | Acc: (91.00%) (9535/10368)
Epoch: 90 | Batch_idx: 90 |  Loss: (0.2360) |  Loss2: (0.0000) | Acc: (91.00%) (10707/11648)
Epoch: 90 | Batch_idx: 100 |  Loss: (0.2392) |  Loss2: (0.0000) | Acc: (91.00%) (11866/12928)
Epoch: 90 | Batch_idx: 110 |  Loss: (0.2386) |  Loss2: (0.0000) | Acc: (91.00%) (13045/14208)
Epoch: 90 | Batch_idx: 120 |  Loss: (0.2393) |  Loss2: (0.0000) | Acc: (91.00%) (14217/15488)
Epoch: 90 | Batch_idx: 130 |  Loss: (0.2393) |  Loss2: (0.0000) | Acc: (91.00%) (15394/16768)
Epoch: 90 | Batch_idx: 140 |  Loss: (0.2420) |  Loss2: (0.0000) | Acc: (91.00%) (16551/18048)
Epoch: 90 | Batch_idx: 150 |  Loss: (0.2440) |  Loss2: (0.0000) | Acc: (91.00%) (17715/19328)
Epoch: 90 | Batch_idx: 160 |  Loss: (0.2428) |  Loss2: (0.0000) | Acc: (91.00%) (18896/20608)
Epoch: 90 | Batch_idx: 170 |  Loss: (0.2430) |  Loss2: (0.0000) | Acc: (91.00%) (20069/21888)
Epoch: 90 | Batch_idx: 180 |  Loss: (0.2444) |  Loss2: (0.0000) | Acc: (91.00%) (21225/23168)
Epoch: 90 | Batch_idx: 190 |  Loss: (0.2447) |  Loss2: (0.0000) | Acc: (91.00%) (22402/24448)
Epoch: 90 | Batch_idx: 200 |  Loss: (0.2460) |  Loss2: (0.0000) | Acc: (91.00%) (23570/25728)
Epoch: 90 | Batch_idx: 210 |  Loss: (0.2460) |  Loss2: (0.0000) | Acc: (91.00%) (24747/27008)
Epoch: 90 | Batch_idx: 220 |  Loss: (0.2458) |  Loss2: (0.0000) | Acc: (91.00%) (25924/28288)
Epoch: 90 | Batch_idx: 230 |  Loss: (0.2453) |  Loss2: (0.0000) | Acc: (91.00%) (27098/29568)
Epoch: 90 | Batch_idx: 240 |  Loss: (0.2457) |  Loss2: (0.0000) | Acc: (91.00%) (28255/30848)
Epoch: 90 | Batch_idx: 250 |  Loss: (0.2453) |  Loss2: (0.0000) | Acc: (91.00%) (29439/32128)
Epoch: 90 | Batch_idx: 260 |  Loss: (0.2458) |  Loss2: (0.0000) | Acc: (91.00%) (30598/33408)
Epoch: 90 | Batch_idx: 270 |  Loss: (0.2464) |  Loss2: (0.0000) | Acc: (91.00%) (31761/34688)
Epoch: 90 | Batch_idx: 280 |  Loss: (0.2468) |  Loss2: (0.0000) | Acc: (91.00%) (32920/35968)
Epoch: 90 | Batch_idx: 290 |  Loss: (0.2472) |  Loss2: (0.0000) | Acc: (91.00%) (34075/37248)
Epoch: 90 | Batch_idx: 300 |  Loss: (0.2474) |  Loss2: (0.0000) | Acc: (91.00%) (35245/38528)
Epoch: 90 | Batch_idx: 310 |  Loss: (0.2472) |  Loss2: (0.0000) | Acc: (91.00%) (36415/39808)
Epoch: 90 | Batch_idx: 320 |  Loss: (0.2478) |  Loss2: (0.0000) | Acc: (91.00%) (37580/41088)
Epoch: 90 | Batch_idx: 330 |  Loss: (0.2473) |  Loss2: (0.0000) | Acc: (91.00%) (38757/42368)
Epoch: 90 | Batch_idx: 340 |  Loss: (0.2479) |  Loss2: (0.0000) | Acc: (91.00%) (39920/43648)
Epoch: 90 | Batch_idx: 350 |  Loss: (0.2483) |  Loss2: (0.0000) | Acc: (91.00%) (41082/44928)
Epoch: 90 | Batch_idx: 360 |  Loss: (0.2486) |  Loss2: (0.0000) | Acc: (91.00%) (42244/46208)
Epoch: 90 | Batch_idx: 370 |  Loss: (0.2493) |  Loss2: (0.0000) | Acc: (91.00%) (43394/47488)
Epoch: 90 | Batch_idx: 380 |  Loss: (0.2485) |  Loss2: (0.0000) | Acc: (91.00%) (44580/48768)
Epoch: 90 | Batch_idx: 390 |  Loss: (0.2489) |  Loss2: (0.0000) | Acc: (91.00%) (45702/50000)
=> saving checkpoint 'drive/app/torch/save_Routing_Gate_2/checkpoint_090.pth.tar'
# TEST : Loss: (0.4030) | Acc: (86.00%) (8674/10000)
percent tensor([0.5962, 0.5894, 0.6093, 0.5904, 0.6124, 0.5919, 0.6010, 0.5940, 0.5976,
        0.5931, 0.5912, 0.6061, 0.5910, 0.5798, 0.5910, 0.5890],
       device='cuda:0') torch.Size([16])
percent tensor([0.5668, 0.5348, 0.5270, 0.5817, 0.5525, 0.6150, 0.5431, 0.5568, 0.5567,
        0.5357, 0.5509, 0.5229, 0.5297, 0.5868, 0.5663, 0.5770],
       device='cuda:0') torch.Size([16])
percent tensor([0.5194, 0.5506, 0.5267, 0.4966, 0.5360, 0.4802, 0.5626, 0.5422, 0.5242,
        0.5215, 0.5130, 0.5463, 0.5311, 0.5384, 0.5286, 0.5220],
       device='cuda:0') torch.Size([16])
percent tensor([0.6205, 0.5907, 0.6038, 0.6114, 0.6148, 0.6304, 0.6065, 0.6143, 0.6104,
        0.6006, 0.6074, 0.6019, 0.6065, 0.6048, 0.6134, 0.6286],
       device='cuda:0') torch.Size([16])
percent tensor([0.5724, 0.6559, 0.6456, 0.6408, 0.6056, 0.6538, 0.6245, 0.5267, 0.6925,
        0.5891, 0.6674, 0.6648, 0.7014, 0.7152, 0.5835, 0.6060],
       device='cuda:0') torch.Size([16])
percent tensor([0.6687, 0.6559, 0.7213, 0.7405, 0.7471, 0.7865, 0.7030, 0.6489, 0.7290,
        0.6574, 0.7178, 0.6648, 0.6499, 0.7907, 0.6494, 0.7150],
       device='cuda:0') torch.Size([16])
percent tensor([0.6400, 0.6039, 0.7030, 0.6317, 0.7604, 0.6623, 0.6595, 0.7104, 0.6117,
        0.6237, 0.6008, 0.6051, 0.4977, 0.6593, 0.6399, 0.6845],
       device='cuda:0') torch.Size([16])
percent tensor([0.9991, 0.9985, 0.9987, 0.9991, 0.9989, 0.9979, 0.9985, 0.9988, 0.9990,
        0.9992, 0.9989, 0.9989, 0.9988, 0.9989, 0.9985, 0.9990],
       device='cuda:0') torch.Size([16])
Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 3, 3, 3]) tensor(179.3982, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(814.1867, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(814.6122, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([128, 64, 3, 3]) tensor(1529.9296, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([128, 64, 1, 1]) tensor(497.2990, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([128, 128, 3, 3]) tensor(2229.7671, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([256, 128, 3, 3]) tensor(4290.3613, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([256, 128, 1, 1]) tensor(1403.9225, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([256, 256, 3, 3]) tensor(6160.7051, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([512, 256, 3, 3]) tensor(11930.7686, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([512, 256, 1, 1]) tensor(3957.3862, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([512, 512, 3, 3]) tensor(16729.9688, device='cuda:0', grad_fn=<NormBackward0>)
Epoch: 91 | Batch_idx: 0 |  Loss: (0.2231) |  Loss2: (0.0000) | Acc: (92.00%) (119/128)
Epoch: 91 | Batch_idx: 10 |  Loss: (0.2424) |  Loss2: (0.0000) | Acc: (91.00%) (1294/1408)
Epoch: 91 | Batch_idx: 20 |  Loss: (0.2395) |  Loss2: (0.0000) | Acc: (91.00%) (2470/2688)
Epoch: 91 | Batch_idx: 30 |  Loss: (0.2396) |  Loss2: (0.0000) | Acc: (91.00%) (3640/3968)
Epoch: 91 | Batch_idx: 40 |  Loss: (0.2339) |  Loss2: (0.0000) | Acc: (92.00%) (4830/5248)
Epoch: 91 | Batch_idx: 50 |  Loss: (0.2296) |  Loss2: (0.0000) | Acc: (92.00%) (6018/6528)
Epoch: 91 | Batch_idx: 60 |  Loss: (0.2310) |  Loss2: (0.0000) | Acc: (92.00%) (7195/7808)
Epoch: 91 | Batch_idx: 70 |  Loss: (0.2345) |  Loss2: (0.0000) | Acc: (91.00%) (8357/9088)
Epoch: 91 | Batch_idx: 80 |  Loss: (0.2345) |  Loss2: (0.0000) | Acc: (91.00%) (9532/10368)
Epoch: 91 | Batch_idx: 90 |  Loss: (0.2356) |  Loss2: (0.0000) | Acc: (91.00%) (10707/11648)
Epoch: 91 | Batch_idx: 100 |  Loss: (0.2360) |  Loss2: (0.0000) | Acc: (91.00%) (11878/12928)
Epoch: 91 | Batch_idx: 110 |  Loss: (0.2357) |  Loss2: (0.0000) | Acc: (91.00%) (13051/14208)
Epoch: 91 | Batch_idx: 120 |  Loss: (0.2377) |  Loss2: (0.0000) | Acc: (91.00%) (14211/15488)
Epoch: 91 | Batch_idx: 130 |  Loss: (0.2355) |  Loss2: (0.0000) | Acc: (91.00%) (15399/16768)
Epoch: 91 | Batch_idx: 140 |  Loss: (0.2365) |  Loss2: (0.0000) | Acc: (91.00%) (16576/18048)
Epoch: 91 | Batch_idx: 150 |  Loss: (0.2362) |  Loss2: (0.0000) | Acc: (91.00%) (17749/19328)
Epoch: 91 | Batch_idx: 160 |  Loss: (0.2356) |  Loss2: (0.0000) | Acc: (91.00%) (18925/20608)
Epoch: 91 | Batch_idx: 170 |  Loss: (0.2357) |  Loss2: (0.0000) | Acc: (91.00%) (20100/21888)
Epoch: 91 | Batch_idx: 180 |  Loss: (0.2349) |  Loss2: (0.0000) | Acc: (91.00%) (21278/23168)
Epoch: 91 | Batch_idx: 190 |  Loss: (0.2353) |  Loss2: (0.0000) | Acc: (91.00%) (22456/24448)
Epoch: 91 | Batch_idx: 200 |  Loss: (0.2359) |  Loss2: (0.0000) | Acc: (91.00%) (23623/25728)
Epoch: 91 | Batch_idx: 210 |  Loss: (0.2368) |  Loss2: (0.0000) | Acc: (91.00%) (24787/27008)
Epoch: 91 | Batch_idx: 220 |  Loss: (0.2371) |  Loss2: (0.0000) | Acc: (91.00%) (25955/28288)
Epoch: 91 | Batch_idx: 230 |  Loss: (0.2373) |  Loss2: (0.0000) | Acc: (91.00%) (27134/29568)
Epoch: 91 | Batch_idx: 240 |  Loss: (0.2370) |  Loss2: (0.0000) | Acc: (91.00%) (28322/30848)
Epoch: 91 | Batch_idx: 250 |  Loss: (0.2365) |  Loss2: (0.0000) | Acc: (91.00%) (29504/32128)
Epoch: 91 | Batch_idx: 260 |  Loss: (0.2373) |  Loss2: (0.0000) | Acc: (91.00%) (30667/33408)
Epoch: 91 | Batch_idx: 270 |  Loss: (0.2376) |  Loss2: (0.0000) | Acc: (91.00%) (31838/34688)
Epoch: 91 | Batch_idx: 280 |  Loss: (0.2369) |  Loss2: (0.0000) | Acc: (91.00%) (33019/35968)
Epoch: 91 | Batch_idx: 290 |  Loss: (0.2385) |  Loss2: (0.0000) | Acc: (91.00%) (34175/37248)
Epoch: 91 | Batch_idx: 300 |  Loss: (0.2390) |  Loss2: (0.0000) | Acc: (91.00%) (35344/38528)
Epoch: 91 | Batch_idx: 310 |  Loss: (0.2395) |  Loss2: (0.0000) | Acc: (91.00%) (36503/39808)
Epoch: 91 | Batch_idx: 320 |  Loss: (0.2398) |  Loss2: (0.0000) | Acc: (91.00%) (37662/41088)
Epoch: 91 | Batch_idx: 330 |  Loss: (0.2397) |  Loss2: (0.0000) | Acc: (91.00%) (38845/42368)
Epoch: 91 | Batch_idx: 340 |  Loss: (0.2398) |  Loss2: (0.0000) | Acc: (91.00%) (40028/43648)
Epoch: 91 | Batch_idx: 350 |  Loss: (0.2404) |  Loss2: (0.0000) | Acc: (91.00%) (41195/44928)
Epoch: 91 | Batch_idx: 360 |  Loss: (0.2414) |  Loss2: (0.0000) | Acc: (91.00%) (42343/46208)
Epoch: 91 | Batch_idx: 370 |  Loss: (0.2417) |  Loss2: (0.0000) | Acc: (91.00%) (43504/47488)
Epoch: 91 | Batch_idx: 380 |  Loss: (0.2416) |  Loss2: (0.0000) | Acc: (91.00%) (44682/48768)
Epoch: 91 | Batch_idx: 390 |  Loss: (0.2423) |  Loss2: (0.0000) | Acc: (91.00%) (45799/50000)
# TEST : Loss: (0.4250) | Acc: (86.00%) (8655/10000)
percent tensor([0.5973, 0.5884, 0.6121, 0.5920, 0.6158, 0.5930, 0.6007, 0.5945, 0.5980,
        0.5937, 0.5919, 0.6085, 0.5918, 0.5755, 0.5919, 0.5892],
       device='cuda:0') torch.Size([16])
percent tensor([0.5666, 0.5367, 0.5248, 0.5825, 0.5543, 0.6150, 0.5445, 0.5566, 0.5510,
        0.5353, 0.5467, 0.5235, 0.5287, 0.5895, 0.5683, 0.5775],
       device='cuda:0') torch.Size([16])
percent tensor([0.5193, 0.5484, 0.5184, 0.4935, 0.5309, 0.4844, 0.5590, 0.5324, 0.5233,
        0.5198, 0.5150, 0.5398, 0.5320, 0.5324, 0.5289, 0.5226],
       device='cuda:0') torch.Size([16])
percent tensor([0.6211, 0.5934, 0.5976, 0.6079, 0.6109, 0.6291, 0.6081, 0.6111, 0.6101,
        0.6029, 0.6094, 0.6005, 0.6094, 0.6098, 0.6130, 0.6298],
       device='cuda:0') torch.Size([16])
percent tensor([0.5613, 0.6523, 0.6345, 0.6304, 0.5920, 0.6426, 0.6324, 0.4973, 0.7312,
        0.6045, 0.6910, 0.6586, 0.6997, 0.7446, 0.5545, 0.6006],
       device='cuda:0') torch.Size([16])
percent tensor([0.6644, 0.6498, 0.7297, 0.7288, 0.7576, 0.7769, 0.6999, 0.6568, 0.7309,
        0.6776, 0.7106, 0.6819, 0.6477, 0.7884, 0.6501, 0.7097],
       device='cuda:0') torch.Size([16])
percent tensor([0.6541, 0.5820, 0.7265, 0.6554, 0.7785, 0.6742, 0.6646, 0.7147, 0.5987,
        0.6309, 0.5983, 0.6420, 0.4988, 0.6258, 0.6442, 0.6990],
       device='cuda:0') torch.Size([16])
percent tensor([0.9990, 0.9980, 0.9988, 0.9994, 0.9990, 0.9984, 0.9989, 0.9989, 0.9989,
        0.9990, 0.9988, 0.9992, 0.9984, 0.9989, 0.9986, 0.9992],
       device='cuda:0') torch.Size([16])
Epoch: 92 | Batch_idx: 0 |  Loss: (0.1580) |  Loss2: (0.0000) | Acc: (94.00%) (121/128)
Epoch: 92 | Batch_idx: 10 |  Loss: (0.2140) |  Loss2: (0.0000) | Acc: (92.00%) (1309/1408)
Epoch: 92 | Batch_idx: 20 |  Loss: (0.2127) |  Loss2: (0.0000) | Acc: (92.00%) (2498/2688)
Epoch: 92 | Batch_idx: 30 |  Loss: (0.2122) |  Loss2: (0.0000) | Acc: (93.00%) (3693/3968)
Epoch: 92 | Batch_idx: 40 |  Loss: (0.2187) |  Loss2: (0.0000) | Acc: (92.00%) (4867/5248)
Epoch: 92 | Batch_idx: 50 |  Loss: (0.2198) |  Loss2: (0.0000) | Acc: (92.00%) (6056/6528)
Epoch: 92 | Batch_idx: 60 |  Loss: (0.2230) |  Loss2: (0.0000) | Acc: (92.00%) (7227/7808)
Epoch: 92 | Batch_idx: 70 |  Loss: (0.2243) |  Loss2: (0.0000) | Acc: (92.00%) (8408/9088)
Epoch: 92 | Batch_idx: 80 |  Loss: (0.2211) |  Loss2: (0.0000) | Acc: (92.00%) (9594/10368)
Epoch: 92 | Batch_idx: 90 |  Loss: (0.2223) |  Loss2: (0.0000) | Acc: (92.00%) (10773/11648)
Epoch: 92 | Batch_idx: 100 |  Loss: (0.2232) |  Loss2: (0.0000) | Acc: (92.00%) (11952/12928)
Epoch: 92 | Batch_idx: 110 |  Loss: (0.2221) |  Loss2: (0.0000) | Acc: (92.00%) (13143/14208)
Epoch: 92 | Batch_idx: 120 |  Loss: (0.2234) |  Loss2: (0.0000) | Acc: (92.00%) (14317/15488)
Epoch: 92 | Batch_idx: 130 |  Loss: (0.2233) |  Loss2: (0.0000) | Acc: (92.00%) (15500/16768)
Epoch: 92 | Batch_idx: 140 |  Loss: (0.2222) |  Loss2: (0.0000) | Acc: (92.00%) (16689/18048)
Epoch: 92 | Batch_idx: 150 |  Loss: (0.2251) |  Loss2: (0.0000) | Acc: (92.00%) (17844/19328)
Epoch: 92 | Batch_idx: 160 |  Loss: (0.2266) |  Loss2: (0.0000) | Acc: (92.00%) (19021/20608)
Epoch: 92 | Batch_idx: 170 |  Loss: (0.2258) |  Loss2: (0.0000) | Acc: (92.00%) (20207/21888)
Epoch: 92 | Batch_idx: 180 |  Loss: (0.2260) |  Loss2: (0.0000) | Acc: (92.00%) (21387/23168)
Epoch: 92 | Batch_idx: 190 |  Loss: (0.2276) |  Loss2: (0.0000) | Acc: (92.00%) (22546/24448)
Epoch: 92 | Batch_idx: 200 |  Loss: (0.2275) |  Loss2: (0.0000) | Acc: (92.00%) (23737/25728)
Epoch: 92 | Batch_idx: 210 |  Loss: (0.2259) |  Loss2: (0.0000) | Acc: (92.00%) (24926/27008)
Epoch: 92 | Batch_idx: 220 |  Loss: (0.2250) |  Loss2: (0.0000) | Acc: (92.00%) (26115/28288)
Epoch: 92 | Batch_idx: 230 |  Loss: (0.2246) |  Loss2: (0.0000) | Acc: (92.00%) (27303/29568)
Epoch: 92 | Batch_idx: 240 |  Loss: (0.2259) |  Loss2: (0.0000) | Acc: (92.00%) (28468/30848)
Epoch: 92 | Batch_idx: 250 |  Loss: (0.2259) |  Loss2: (0.0000) | Acc: (92.00%) (29642/32128)
Epoch: 92 | Batch_idx: 260 |  Loss: (0.2274) |  Loss2: (0.0000) | Acc: (92.00%) (30802/33408)
Epoch: 92 | Batch_idx: 270 |  Loss: (0.2281) |  Loss2: (0.0000) | Acc: (92.00%) (31981/34688)
Epoch: 92 | Batch_idx: 280 |  Loss: (0.2287) |  Loss2: (0.0000) | Acc: (92.00%) (33151/35968)
Epoch: 92 | Batch_idx: 290 |  Loss: (0.2293) |  Loss2: (0.0000) | Acc: (92.00%) (34321/37248)
Epoch: 92 | Batch_idx: 300 |  Loss: (0.2301) |  Loss2: (0.0000) | Acc: (92.00%) (35489/38528)
Epoch: 92 | Batch_idx: 310 |  Loss: (0.2306) |  Loss2: (0.0000) | Acc: (92.00%) (36670/39808)
Epoch: 92 | Batch_idx: 320 |  Loss: (0.2313) |  Loss2: (0.0000) | Acc: (92.00%) (37834/41088)
Epoch: 92 | Batch_idx: 330 |  Loss: (0.2312) |  Loss2: (0.0000) | Acc: (92.00%) (39014/42368)
Epoch: 92 | Batch_idx: 340 |  Loss: (0.2311) |  Loss2: (0.0000) | Acc: (92.00%) (40197/43648)
Epoch: 92 | Batch_idx: 350 |  Loss: (0.2310) |  Loss2: (0.0000) | Acc: (92.00%) (41377/44928)
Epoch: 92 | Batch_idx: 360 |  Loss: (0.2311) |  Loss2: (0.0000) | Acc: (92.00%) (42559/46208)
Epoch: 92 | Batch_idx: 370 |  Loss: (0.2318) |  Loss2: (0.0000) | Acc: (92.00%) (43727/47488)
Epoch: 92 | Batch_idx: 380 |  Loss: (0.2324) |  Loss2: (0.0000) | Acc: (92.00%) (44899/48768)
Epoch: 92 | Batch_idx: 390 |  Loss: (0.2321) |  Loss2: (0.0000) | Acc: (92.00%) (46036/50000)
# TEST : Loss: (0.4217) | Acc: (86.00%) (8652/10000)
percent tensor([0.5955, 0.5897, 0.6061, 0.5910, 0.6103, 0.5926, 0.5989, 0.5931, 0.5947,
        0.5921, 0.5907, 0.6040, 0.5900, 0.5782, 0.5926, 0.5884],
       device='cuda:0') torch.Size([16])
percent tensor([0.5678, 0.5336, 0.5332, 0.5856, 0.5599, 0.6143, 0.5421, 0.5597, 0.5518,
        0.5360, 0.5465, 0.5248, 0.5281, 0.5864, 0.5664, 0.5775],
       device='cuda:0') torch.Size([16])
percent tensor([0.5212, 0.5545, 0.5198, 0.4910, 0.5290, 0.4848, 0.5606, 0.5368, 0.5255,
        0.5214, 0.5180, 0.5383, 0.5361, 0.5357, 0.5301, 0.5256],
       device='cuda:0') torch.Size([16])
percent tensor([0.6217, 0.5905, 0.6023, 0.6094, 0.6154, 0.6315, 0.6080, 0.6137, 0.6122,
        0.6032, 0.6086, 0.6018, 0.6092, 0.6110, 0.6131, 0.6294],
       device='cuda:0') torch.Size([16])
percent tensor([0.5617, 0.6641, 0.6167, 0.6146, 0.5776, 0.6342, 0.6294, 0.4837, 0.7188,
        0.6150, 0.6836, 0.6614, 0.7096, 0.7396, 0.5690, 0.6003],
       device='cuda:0') torch.Size([16])
percent tensor([0.6617, 0.6373, 0.7284, 0.7313, 0.7528, 0.7800, 0.6963, 0.6662, 0.7292,
        0.6731, 0.7069, 0.6967, 0.6544, 0.7819, 0.6453, 0.7130],
       device='cuda:0') torch.Size([16])
percent tensor([0.6514, 0.5743, 0.7290, 0.6632, 0.7742, 0.6636, 0.6623, 0.7162, 0.5999,
        0.6282, 0.5930, 0.6365, 0.5081, 0.6307, 0.6304, 0.7006],
       device='cuda:0') torch.Size([16])
percent tensor([0.9990, 0.9984, 0.9991, 0.9993, 0.9989, 0.9982, 0.9987, 0.9989, 0.9989,
        0.9993, 0.9991, 0.9992, 0.9987, 0.9991, 0.9986, 0.9992],
       device='cuda:0') torch.Size([16])
Epoch: 93 | Batch_idx: 0 |  Loss: (0.2567) |  Loss2: (0.0000) | Acc: (91.00%) (117/128)
Epoch: 93 | Batch_idx: 10 |  Loss: (0.2384) |  Loss2: (0.0000) | Acc: (90.00%) (1281/1408)
Epoch: 93 | Batch_idx: 20 |  Loss: (0.2484) |  Loss2: (0.0000) | Acc: (91.00%) (2450/2688)
Epoch: 93 | Batch_idx: 30 |  Loss: (0.2252) |  Loss2: (0.0000) | Acc: (92.00%) (3658/3968)
Epoch: 93 | Batch_idx: 40 |  Loss: (0.2210) |  Loss2: (0.0000) | Acc: (92.00%) (4856/5248)
Epoch: 93 | Batch_idx: 50 |  Loss: (0.2201) |  Loss2: (0.0000) | Acc: (92.00%) (6037/6528)
Epoch: 93 | Batch_idx: 60 |  Loss: (0.2190) |  Loss2: (0.0000) | Acc: (92.00%) (7224/7808)
Epoch: 93 | Batch_idx: 70 |  Loss: (0.2176) |  Loss2: (0.0000) | Acc: (92.00%) (8421/9088)
Epoch: 93 | Batch_idx: 80 |  Loss: (0.2167) |  Loss2: (0.0000) | Acc: (92.00%) (9603/10368)
Epoch: 93 | Batch_idx: 90 |  Loss: (0.2181) |  Loss2: (0.0000) | Acc: (92.00%) (10778/11648)
Epoch: 93 | Batch_idx: 100 |  Loss: (0.2208) |  Loss2: (0.0000) | Acc: (92.00%) (11948/12928)
Epoch: 93 | Batch_idx: 110 |  Loss: (0.2200) |  Loss2: (0.0000) | Acc: (92.00%) (13132/14208)
Epoch: 93 | Batch_idx: 120 |  Loss: (0.2198) |  Loss2: (0.0000) | Acc: (92.00%) (14322/15488)
Epoch: 93 | Batch_idx: 130 |  Loss: (0.2207) |  Loss2: (0.0000) | Acc: (92.00%) (15504/16768)
Epoch: 93 | Batch_idx: 140 |  Loss: (0.2204) |  Loss2: (0.0000) | Acc: (92.00%) (16696/18048)
Epoch: 93 | Batch_idx: 150 |  Loss: (0.2230) |  Loss2: (0.0000) | Acc: (92.00%) (17862/19328)
Epoch: 93 | Batch_idx: 160 |  Loss: (0.2232) |  Loss2: (0.0000) | Acc: (92.00%) (19039/20608)
Epoch: 93 | Batch_idx: 170 |  Loss: (0.2222) |  Loss2: (0.0000) | Acc: (92.00%) (20230/21888)
Epoch: 93 | Batch_idx: 180 |  Loss: (0.2223) |  Loss2: (0.0000) | Acc: (92.00%) (21411/23168)
Epoch: 93 | Batch_idx: 190 |  Loss: (0.2220) |  Loss2: (0.0000) | Acc: (92.00%) (22600/24448)
Epoch: 93 | Batch_idx: 200 |  Loss: (0.2233) |  Loss2: (0.0000) | Acc: (92.00%) (23779/25728)
Epoch: 93 | Batch_idx: 210 |  Loss: (0.2240) |  Loss2: (0.0000) | Acc: (92.00%) (24947/27008)
Epoch: 93 | Batch_idx: 220 |  Loss: (0.2248) |  Loss2: (0.0000) | Acc: (92.00%) (26125/28288)
Epoch: 93 | Batch_idx: 230 |  Loss: (0.2253) |  Loss2: (0.0000) | Acc: (92.00%) (27297/29568)
Epoch: 93 | Batch_idx: 240 |  Loss: (0.2257) |  Loss2: (0.0000) | Acc: (92.00%) (28472/30848)
Epoch: 93 | Batch_idx: 250 |  Loss: (0.2274) |  Loss2: (0.0000) | Acc: (92.00%) (29636/32128)
Epoch: 93 | Batch_idx: 260 |  Loss: (0.2289) |  Loss2: (0.0000) | Acc: (92.00%) (30805/33408)
Epoch: 93 | Batch_idx: 270 |  Loss: (0.2292) |  Loss2: (0.0000) | Acc: (92.00%) (31966/34688)
Epoch: 93 | Batch_idx: 280 |  Loss: (0.2289) |  Loss2: (0.0000) | Acc: (92.00%) (33148/35968)
Epoch: 93 | Batch_idx: 290 |  Loss: (0.2289) |  Loss2: (0.0000) | Acc: (92.00%) (34321/37248)
Epoch: 93 | Batch_idx: 300 |  Loss: (0.2300) |  Loss2: (0.0000) | Acc: (92.00%) (35491/38528)
Epoch: 93 | Batch_idx: 310 |  Loss: (0.2304) |  Loss2: (0.0000) | Acc: (92.00%) (36653/39808)
Epoch: 93 | Batch_idx: 320 |  Loss: (0.2310) |  Loss2: (0.0000) | Acc: (92.00%) (37825/41088)
Epoch: 93 | Batch_idx: 330 |  Loss: (0.2303) |  Loss2: (0.0000) | Acc: (92.00%) (39017/42368)
Epoch: 93 | Batch_idx: 340 |  Loss: (0.2296) |  Loss2: (0.0000) | Acc: (92.00%) (40208/43648)
Epoch: 93 | Batch_idx: 350 |  Loss: (0.2292) |  Loss2: (0.0000) | Acc: (92.00%) (41390/44928)
Epoch: 93 | Batch_idx: 360 |  Loss: (0.2294) |  Loss2: (0.0000) | Acc: (92.00%) (42567/46208)
Epoch: 93 | Batch_idx: 370 |  Loss: (0.2297) |  Loss2: (0.0000) | Acc: (92.00%) (43739/47488)
Epoch: 93 | Batch_idx: 380 |  Loss: (0.2296) |  Loss2: (0.0000) | Acc: (92.00%) (44924/48768)
Epoch: 93 | Batch_idx: 390 |  Loss: (0.2296) |  Loss2: (0.0000) | Acc: (92.00%) (46066/50000)
# TEST : Loss: (0.4302) | Acc: (86.00%) (8611/10000)
percent tensor([0.5950, 0.5884, 0.6046, 0.5874, 0.6092, 0.5918, 0.5989, 0.5914, 0.5956,
        0.5910, 0.5917, 0.6015, 0.5898, 0.5782, 0.5909, 0.5885],
       device='cuda:0') torch.Size([16])
percent tensor([0.5703, 0.5348, 0.5348, 0.5845, 0.5615, 0.6143, 0.5449, 0.5604, 0.5576,
        0.5390, 0.5512, 0.5287, 0.5320, 0.5886, 0.5657, 0.5776],
       device='cuda:0') torch.Size([16])
percent tensor([0.5206, 0.5518, 0.5244, 0.4891, 0.5350, 0.4869, 0.5634, 0.5350, 0.5278,
        0.5225, 0.5204, 0.5463, 0.5361, 0.5371, 0.5310, 0.5232],
       device='cuda:0') torch.Size([16])
percent tensor([0.6224, 0.5909, 0.6053, 0.6118, 0.6194, 0.6355, 0.6098, 0.6149, 0.6124,
        0.6036, 0.6088, 0.6022, 0.6076, 0.6113, 0.6157, 0.6303],
       device='cuda:0') torch.Size([16])
percent tensor([0.5585, 0.6548, 0.6145, 0.6282, 0.5739, 0.6485, 0.6035, 0.4873, 0.7080,
        0.5867, 0.6747, 0.6430, 0.6931, 0.7345, 0.5725, 0.6084],
       device='cuda:0') torch.Size([16])
percent tensor([0.6630, 0.6218, 0.7295, 0.7304, 0.7520, 0.7846, 0.6944, 0.6482, 0.7268,
        0.6528, 0.6914, 0.6957, 0.6311, 0.7747, 0.6405, 0.7115],
       device='cuda:0') torch.Size([16])
percent tensor([0.6622, 0.5887, 0.7248, 0.6480, 0.7801, 0.6807, 0.6938, 0.7185, 0.6297,
        0.6427, 0.6092, 0.6341, 0.5222, 0.6385, 0.6267, 0.7029],
       device='cuda:0') torch.Size([16])
percent tensor([0.9992, 0.9986, 0.9979, 0.9991, 0.9987, 0.9985, 0.9987, 0.9988, 0.9990,
        0.9994, 0.9989, 0.9991, 0.9989, 0.9992, 0.9986, 0.9991],
       device='cuda:0') torch.Size([16])
Epoch: 94 | Batch_idx: 0 |  Loss: (0.1392) |  Loss2: (0.0000) | Acc: (94.00%) (121/128)
Epoch: 94 | Batch_idx: 10 |  Loss: (0.2289) |  Loss2: (0.0000) | Acc: (91.00%) (1292/1408)
Epoch: 94 | Batch_idx: 20 |  Loss: (0.2316) |  Loss2: (0.0000) | Acc: (91.00%) (2468/2688)
Epoch: 94 | Batch_idx: 30 |  Loss: (0.2269) |  Loss2: (0.0000) | Acc: (92.00%) (3653/3968)
Epoch: 94 | Batch_idx: 40 |  Loss: (0.2268) |  Loss2: (0.0000) | Acc: (91.00%) (4825/5248)
Epoch: 94 | Batch_idx: 50 |  Loss: (0.2273) |  Loss2: (0.0000) | Acc: (92.00%) (6008/6528)
Epoch: 94 | Batch_idx: 60 |  Loss: (0.2209) |  Loss2: (0.0000) | Acc: (92.00%) (7210/7808)
Epoch: 94 | Batch_idx: 70 |  Loss: (0.2174) |  Loss2: (0.0000) | Acc: (92.00%) (8408/9088)
Epoch: 94 | Batch_idx: 80 |  Loss: (0.2155) |  Loss2: (0.0000) | Acc: (92.00%) (9612/10368)
Epoch: 94 | Batch_idx: 90 |  Loss: (0.2177) |  Loss2: (0.0000) | Acc: (92.00%) (10791/11648)
Epoch: 94 | Batch_idx: 100 |  Loss: (0.2173) |  Loss2: (0.0000) | Acc: (92.00%) (11984/12928)
Epoch: 94 | Batch_idx: 110 |  Loss: (0.2175) |  Loss2: (0.0000) | Acc: (92.00%) (13173/14208)
Epoch: 94 | Batch_idx: 120 |  Loss: (0.2198) |  Loss2: (0.0000) | Acc: (92.00%) (14336/15488)
Epoch: 94 | Batch_idx: 130 |  Loss: (0.2167) |  Loss2: (0.0000) | Acc: (92.00%) (15539/16768)
Epoch: 94 | Batch_idx: 140 |  Loss: (0.2179) |  Loss2: (0.0000) | Acc: (92.00%) (16719/18048)
Epoch: 94 | Batch_idx: 150 |  Loss: (0.2178) |  Loss2: (0.0000) | Acc: (92.00%) (17906/19328)
Epoch: 94 | Batch_idx: 160 |  Loss: (0.2175) |  Loss2: (0.0000) | Acc: (92.00%) (19097/20608)
Epoch: 94 | Batch_idx: 170 |  Loss: (0.2178) |  Loss2: (0.0000) | Acc: (92.00%) (20289/21888)
Epoch: 94 | Batch_idx: 180 |  Loss: (0.2170) |  Loss2: (0.0000) | Acc: (92.00%) (21479/23168)
Epoch: 94 | Batch_idx: 190 |  Loss: (0.2182) |  Loss2: (0.0000) | Acc: (92.00%) (22645/24448)
Epoch: 94 | Batch_idx: 200 |  Loss: (0.2185) |  Loss2: (0.0000) | Acc: (92.00%) (23828/25728)
Epoch: 94 | Batch_idx: 210 |  Loss: (0.2183) |  Loss2: (0.0000) | Acc: (92.00%) (25016/27008)
Epoch: 94 | Batch_idx: 220 |  Loss: (0.2188) |  Loss2: (0.0000) | Acc: (92.00%) (26189/28288)
Epoch: 94 | Batch_idx: 230 |  Loss: (0.2185) |  Loss2: (0.0000) | Acc: (92.00%) (27381/29568)
Epoch: 94 | Batch_idx: 240 |  Loss: (0.2192) |  Loss2: (0.0000) | Acc: (92.00%) (28548/30848)
Epoch: 94 | Batch_idx: 250 |  Loss: (0.2188) |  Loss2: (0.0000) | Acc: (92.00%) (29738/32128)
Epoch: 94 | Batch_idx: 260 |  Loss: (0.2193) |  Loss2: (0.0000) | Acc: (92.00%) (30907/33408)
Epoch: 94 | Batch_idx: 270 |  Loss: (0.2190) |  Loss2: (0.0000) | Acc: (92.00%) (32096/34688)
Epoch: 94 | Batch_idx: 280 |  Loss: (0.2189) |  Loss2: (0.0000) | Acc: (92.00%) (33285/35968)
Epoch: 94 | Batch_idx: 290 |  Loss: (0.2186) |  Loss2: (0.0000) | Acc: (92.00%) (34468/37248)
Epoch: 94 | Batch_idx: 300 |  Loss: (0.2186) |  Loss2: (0.0000) | Acc: (92.00%) (35656/38528)
Epoch: 94 | Batch_idx: 310 |  Loss: (0.2191) |  Loss2: (0.0000) | Acc: (92.00%) (36823/39808)
Epoch: 94 | Batch_idx: 320 |  Loss: (0.2199) |  Loss2: (0.0000) | Acc: (92.00%) (38006/41088)
Epoch: 94 | Batch_idx: 330 |  Loss: (0.2198) |  Loss2: (0.0000) | Acc: (92.00%) (39185/42368)
Epoch: 94 | Batch_idx: 340 |  Loss: (0.2199) |  Loss2: (0.0000) | Acc: (92.00%) (40369/43648)
Epoch: 94 | Batch_idx: 350 |  Loss: (0.2200) |  Loss2: (0.0000) | Acc: (92.00%) (41540/44928)
Epoch: 94 | Batch_idx: 360 |  Loss: (0.2208) |  Loss2: (0.0000) | Acc: (92.00%) (42700/46208)
Epoch: 94 | Batch_idx: 370 |  Loss: (0.2208) |  Loss2: (0.0000) | Acc: (92.00%) (43885/47488)
Epoch: 94 | Batch_idx: 380 |  Loss: (0.2215) |  Loss2: (0.0000) | Acc: (92.00%) (45064/48768)
Epoch: 94 | Batch_idx: 390 |  Loss: (0.2215) |  Loss2: (0.0000) | Acc: (92.00%) (46209/50000)
# TEST : Loss: (0.4123) | Acc: (86.00%) (8661/10000)
percent tensor([0.5963, 0.5903, 0.6065, 0.5903, 0.6113, 0.5943, 0.6004, 0.5928, 0.5965,
        0.5926, 0.5919, 0.6044, 0.5902, 0.5791, 0.5932, 0.5896],
       device='cuda:0') torch.Size([16])
percent tensor([0.5682, 0.5389, 0.5304, 0.5873, 0.5581, 0.6115, 0.5447, 0.5631, 0.5571,
        0.5394, 0.5497, 0.5263, 0.5315, 0.5956, 0.5667, 0.5789],
       device='cuda:0') torch.Size([16])
percent tensor([0.5221, 0.5522, 0.5241, 0.4850, 0.5315, 0.4867, 0.5631, 0.5349, 0.5221,
        0.5224, 0.5154, 0.5439, 0.5355, 0.5331, 0.5294, 0.5205],
       device='cuda:0') torch.Size([16])
percent tensor([0.6215, 0.5919, 0.6001, 0.6113, 0.6142, 0.6333, 0.6076, 0.6105, 0.6130,
        0.6036, 0.6106, 0.5998, 0.6096, 0.6125, 0.6149, 0.6298],
       device='cuda:0') torch.Size([16])
percent tensor([0.5509, 0.6505, 0.6188, 0.6253, 0.5855, 0.6400, 0.6172, 0.4776, 0.7066,
        0.5925, 0.6733, 0.6583, 0.6986, 0.7412, 0.5615, 0.6048],
       device='cuda:0') torch.Size([16])
percent tensor([0.6688, 0.6383, 0.7288, 0.7254, 0.7614, 0.7809, 0.6920, 0.6445, 0.7302,
        0.6711, 0.7140, 0.6709, 0.6440, 0.7937, 0.6408, 0.7162],
       device='cuda:0') torch.Size([16])
percent tensor([0.6680, 0.6047, 0.7256, 0.6496, 0.7851, 0.6672, 0.6931, 0.7338, 0.6243,
        0.6450, 0.6165, 0.6395, 0.5198, 0.6485, 0.6393, 0.6975],
       device='cuda:0') torch.Size([16])
percent tensor([0.9992, 0.9987, 0.9984, 0.9993, 0.9989, 0.9981, 0.9991, 0.9987, 0.9989,
        0.9993, 0.9991, 0.9992, 0.9988, 0.9993, 0.9986, 0.9990],
       device='cuda:0') torch.Size([16])
False Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=128, out_features=16, bias=False)
True Linear(in_features=16, out_features=2, bias=False)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=128, out_features=16, bias=False)
True Linear(in_features=16, out_features=2, bias=False)
False Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=256, out_features=32, bias=False)
True Linear(in_features=32, out_features=2, bias=False)
False Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=256, out_features=32, bias=False)
True Linear(in_features=32, out_features=2, bias=False)
False Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=512, out_features=64, bias=False)
True Linear(in_features=64, out_features=2, bias=False)
False Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=512, out_features=64, bias=False)
True Linear(in_features=64, out_features=2, bias=False)
False Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1024, out_features=128, bias=False)
True Linear(in_features=128, out_features=2, bias=False)
False Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1024, out_features=128, bias=False)
True Linear(in_features=128, out_features=2, bias=False)
False Linear(in_features=512, out_features=10, bias=True)
Epoch: 95 | Batch_idx: 0 |  Loss: (0.2533) |  Loss2: (0.0000) | Acc: (89.00%) (114/128)
Epoch: 95 | Batch_idx: 10 |  Loss: (0.2211) |  Loss2: (0.0000) | Acc: (91.00%) (1291/1408)
Epoch: 95 | Batch_idx: 20 |  Loss: (0.2377) |  Loss2: (0.0000) | Acc: (91.00%) (2461/2688)
Epoch: 95 | Batch_idx: 30 |  Loss: (0.2478) |  Loss2: (0.0000) | Acc: (91.00%) (3614/3968)
Epoch: 95 | Batch_idx: 40 |  Loss: (0.2534) |  Loss2: (0.0000) | Acc: (90.00%) (4769/5248)
Epoch: 95 | Batch_idx: 50 |  Loss: (0.2517) |  Loss2: (0.0000) | Acc: (90.00%) (5938/6528)
Epoch: 95 | Batch_idx: 60 |  Loss: (0.2528) |  Loss2: (0.0000) | Acc: (90.00%) (7097/7808)
Epoch: 95 | Batch_idx: 70 |  Loss: (0.2539) |  Loss2: (0.0000) | Acc: (90.00%) (8266/9088)
Epoch: 95 | Batch_idx: 80 |  Loss: (0.2541) |  Loss2: (0.0000) | Acc: (91.00%) (9437/10368)
Epoch: 95 | Batch_idx: 90 |  Loss: (0.2556) |  Loss2: (0.0000) | Acc: (90.00%) (10597/11648)
Epoch: 95 | Batch_idx: 100 |  Loss: (0.2532) |  Loss2: (0.0000) | Acc: (90.00%) (11758/12928)
Epoch: 95 | Batch_idx: 110 |  Loss: (0.2530) |  Loss2: (0.0000) | Acc: (90.00%) (12929/14208)
Epoch: 95 | Batch_idx: 120 |  Loss: (0.2526) |  Loss2: (0.0000) | Acc: (91.00%) (14107/15488)
Epoch: 95 | Batch_idx: 130 |  Loss: (0.2513) |  Loss2: (0.0000) | Acc: (91.00%) (15273/16768)
Epoch: 95 | Batch_idx: 140 |  Loss: (0.2499) |  Loss2: (0.0000) | Acc: (91.00%) (16454/18048)
Epoch: 95 | Batch_idx: 150 |  Loss: (0.2495) |  Loss2: (0.0000) | Acc: (91.00%) (17630/19328)
Epoch: 95 | Batch_idx: 160 |  Loss: (0.2493) |  Loss2: (0.0000) | Acc: (91.00%) (18790/20608)
Epoch: 95 | Batch_idx: 170 |  Loss: (0.2501) |  Loss2: (0.0000) | Acc: (91.00%) (19950/21888)
Epoch: 95 | Batch_idx: 180 |  Loss: (0.2505) |  Loss2: (0.0000) | Acc: (91.00%) (21113/23168)
Epoch: 95 | Batch_idx: 190 |  Loss: (0.2512) |  Loss2: (0.0000) | Acc: (91.00%) (22271/24448)
Epoch: 95 | Batch_idx: 200 |  Loss: (0.2520) |  Loss2: (0.0000) | Acc: (91.00%) (23430/25728)
Epoch: 95 | Batch_idx: 210 |  Loss: (0.2523) |  Loss2: (0.0000) | Acc: (91.00%) (24593/27008)
Epoch: 95 | Batch_idx: 220 |  Loss: (0.2515) |  Loss2: (0.0000) | Acc: (91.00%) (25766/28288)
Epoch: 95 | Batch_idx: 230 |  Loss: (0.2519) |  Loss2: (0.0000) | Acc: (91.00%) (26930/29568)
Epoch: 95 | Batch_idx: 240 |  Loss: (0.2520) |  Loss2: (0.0000) | Acc: (91.00%) (28100/30848)
Epoch: 95 | Batch_idx: 250 |  Loss: (0.2518) |  Loss2: (0.0000) | Acc: (91.00%) (29273/32128)
Epoch: 95 | Batch_idx: 260 |  Loss: (0.2498) |  Loss2: (0.0000) | Acc: (91.00%) (30467/33408)
Epoch: 95 | Batch_idx: 270 |  Loss: (0.2491) |  Loss2: (0.0000) | Acc: (91.00%) (31641/34688)
Epoch: 95 | Batch_idx: 280 |  Loss: (0.2479) |  Loss2: (0.0000) | Acc: (91.00%) (32826/35968)
Epoch: 95 | Batch_idx: 290 |  Loss: (0.2471) |  Loss2: (0.0000) | Acc: (91.00%) (34005/37248)
Epoch: 95 | Batch_idx: 300 |  Loss: (0.2470) |  Loss2: (0.0000) | Acc: (91.00%) (35176/38528)
Epoch: 95 | Batch_idx: 310 |  Loss: (0.2467) |  Loss2: (0.0000) | Acc: (91.00%) (36354/39808)
Epoch: 95 | Batch_idx: 320 |  Loss: (0.2460) |  Loss2: (0.0000) | Acc: (91.00%) (37541/41088)
Epoch: 95 | Batch_idx: 330 |  Loss: (0.2453) |  Loss2: (0.0000) | Acc: (91.00%) (38717/42368)
Epoch: 95 | Batch_idx: 340 |  Loss: (0.2456) |  Loss2: (0.0000) | Acc: (91.00%) (39886/43648)
Epoch: 95 | Batch_idx: 350 |  Loss: (0.2457) |  Loss2: (0.0000) | Acc: (91.00%) (41051/44928)
Epoch: 95 | Batch_idx: 360 |  Loss: (0.2459) |  Loss2: (0.0000) | Acc: (91.00%) (42227/46208)
Epoch: 95 | Batch_idx: 370 |  Loss: (0.2456) |  Loss2: (0.0000) | Acc: (91.00%) (43399/47488)
Epoch: 95 | Batch_idx: 380 |  Loss: (0.2456) |  Loss2: (0.0000) | Acc: (91.00%) (44570/48768)
Epoch: 95 | Batch_idx: 390 |  Loss: (0.2453) |  Loss2: (0.0000) | Acc: (91.00%) (45703/50000)
=> saving checkpoint 'drive/app/torch/save_Routing_Gate_2/checkpoint_095.pth.tar'
# TEST : Loss: (0.4073) | Acc: (86.00%) (8680/10000)
percent tensor([0.5985, 0.5940, 0.6077, 0.5923, 0.6136, 0.5963, 0.6039, 0.5949, 0.5996,
        0.5952, 0.5950, 0.6066, 0.5930, 0.5834, 0.5959, 0.5918],
       device='cuda:0') torch.Size([16])
percent tensor([0.5823, 0.5495, 0.5458, 0.6021, 0.5744, 0.6265, 0.5575, 0.5790, 0.5728,
        0.5522, 0.5638, 0.5404, 0.5423, 0.6119, 0.5794, 0.5920],
       device='cuda:0') torch.Size([16])
percent tensor([0.5091, 0.5458, 0.5104, 0.4682, 0.5134, 0.4728, 0.5532, 0.5198, 0.5046,
        0.5087, 0.4985, 0.5321, 0.5289, 0.5177, 0.5189, 0.5092],
       device='cuda:0') torch.Size([16])
percent tensor([0.6201, 0.5856, 0.6022, 0.6163, 0.6178, 0.6358, 0.6052, 0.6130, 0.6130,
        0.6008, 0.6082, 0.5983, 0.6026, 0.6114, 0.6141, 0.6286],
       device='cuda:0') torch.Size([16])
percent tensor([0.5644, 0.6480, 0.6372, 0.6294, 0.5883, 0.6638, 0.6143, 0.4700, 0.7084,
        0.5921, 0.6599, 0.6550, 0.7125, 0.7206, 0.5528, 0.6187],
       device='cuda:0') torch.Size([16])
percent tensor([0.6510, 0.6179, 0.7157, 0.7134, 0.7450, 0.7684, 0.6708, 0.6254, 0.7165,
        0.6560, 0.7014, 0.6550, 0.6317, 0.7817, 0.6177, 0.7012],
       device='cuda:0') torch.Size([16])
percent tensor([0.6428, 0.5858, 0.7063, 0.6190, 0.7548, 0.6477, 0.6567, 0.7006, 0.6023,
        0.6198, 0.5984, 0.6129, 0.5058, 0.6209, 0.6197, 0.6646],
       device='cuda:0') torch.Size([16])
percent tensor([0.9991, 0.9986, 0.9989, 0.9993, 0.9990, 0.9981, 0.9989, 0.9988, 0.9988,
        0.9993, 0.9991, 0.9991, 0.9989, 0.9993, 0.9986, 0.9990],
       device='cuda:0') torch.Size([16])
Epoch: 96 | Batch_idx: 0 |  Loss: (0.3035) |  Loss2: (0.0000) | Acc: (91.00%) (117/128)
Epoch: 96 | Batch_idx: 10 |  Loss: (0.2679) |  Loss2: (0.0000) | Acc: (90.00%) (1276/1408)
Epoch: 96 | Batch_idx: 20 |  Loss: (0.2659) |  Loss2: (0.0000) | Acc: (90.00%) (2436/2688)
Epoch: 96 | Batch_idx: 30 |  Loss: (0.2624) |  Loss2: (0.0000) | Acc: (90.00%) (3593/3968)
Epoch: 96 | Batch_idx: 40 |  Loss: (0.2570) |  Loss2: (0.0000) | Acc: (90.00%) (4762/5248)
Epoch: 96 | Batch_idx: 50 |  Loss: (0.2485) |  Loss2: (0.0000) | Acc: (90.00%) (5935/6528)
Epoch: 96 | Batch_idx: 60 |  Loss: (0.2494) |  Loss2: (0.0000) | Acc: (91.00%) (7107/7808)
Epoch: 96 | Batch_idx: 70 |  Loss: (0.2473) |  Loss2: (0.0000) | Acc: (91.00%) (8272/9088)
Epoch: 96 | Batch_idx: 80 |  Loss: (0.2451) |  Loss2: (0.0000) | Acc: (91.00%) (9439/10368)
Epoch: 96 | Batch_idx: 90 |  Loss: (0.2454) |  Loss2: (0.0000) | Acc: (91.00%) (10604/11648)
Epoch: 96 | Batch_idx: 100 |  Loss: (0.2468) |  Loss2: (0.0000) | Acc: (90.00%) (11760/12928)
Epoch: 96 | Batch_idx: 110 |  Loss: (0.2444) |  Loss2: (0.0000) | Acc: (91.00%) (12940/14208)
Epoch: 96 | Batch_idx: 120 |  Loss: (0.2424) |  Loss2: (0.0000) | Acc: (91.00%) (14118/15488)
Epoch: 96 | Batch_idx: 130 |  Loss: (0.2374) |  Loss2: (0.0000) | Acc: (91.00%) (15330/16768)
Epoch: 96 | Batch_idx: 140 |  Loss: (0.2358) |  Loss2: (0.0000) | Acc: (91.00%) (16521/18048)
Epoch: 96 | Batch_idx: 150 |  Loss: (0.2341) |  Loss2: (0.0000) | Acc: (91.00%) (17712/19328)
Epoch: 96 | Batch_idx: 160 |  Loss: (0.2341) |  Loss2: (0.0000) | Acc: (91.00%) (18896/20608)
Epoch: 96 | Batch_idx: 170 |  Loss: (0.2353) |  Loss2: (0.0000) | Acc: (91.00%) (20070/21888)
Epoch: 96 | Batch_idx: 180 |  Loss: (0.2344) |  Loss2: (0.0000) | Acc: (91.00%) (21258/23168)
Epoch: 96 | Batch_idx: 190 |  Loss: (0.2326) |  Loss2: (0.0000) | Acc: (91.00%) (22449/24448)
Epoch: 96 | Batch_idx: 200 |  Loss: (0.2317) |  Loss2: (0.0000) | Acc: (91.00%) (23636/25728)
Epoch: 96 | Batch_idx: 210 |  Loss: (0.2321) |  Loss2: (0.0000) | Acc: (91.00%) (24811/27008)
Epoch: 96 | Batch_idx: 220 |  Loss: (0.2321) |  Loss2: (0.0000) | Acc: (91.00%) (25991/28288)
Epoch: 96 | Batch_idx: 230 |  Loss: (0.2316) |  Loss2: (0.0000) | Acc: (91.00%) (27171/29568)
Epoch: 96 | Batch_idx: 240 |  Loss: (0.2316) |  Loss2: (0.0000) | Acc: (91.00%) (28350/30848)
Epoch: 96 | Batch_idx: 250 |  Loss: (0.2302) |  Loss2: (0.0000) | Acc: (91.00%) (29541/32128)
Epoch: 96 | Batch_idx: 260 |  Loss: (0.2311) |  Loss2: (0.0000) | Acc: (91.00%) (30706/33408)
Epoch: 96 | Batch_idx: 270 |  Loss: (0.2309) |  Loss2: (0.0000) | Acc: (91.00%) (31884/34688)
Epoch: 96 | Batch_idx: 280 |  Loss: (0.2300) |  Loss2: (0.0000) | Acc: (91.00%) (33073/35968)
Epoch: 96 | Batch_idx: 290 |  Loss: (0.2292) |  Loss2: (0.0000) | Acc: (91.00%) (34267/37248)
Epoch: 96 | Batch_idx: 300 |  Loss: (0.2289) |  Loss2: (0.0000) | Acc: (92.00%) (35451/38528)
Epoch: 96 | Batch_idx: 310 |  Loss: (0.2288) |  Loss2: (0.0000) | Acc: (92.00%) (36633/39808)
Epoch: 96 | Batch_idx: 320 |  Loss: (0.2283) |  Loss2: (0.0000) | Acc: (92.00%) (37813/41088)
Epoch: 96 | Batch_idx: 330 |  Loss: (0.2279) |  Loss2: (0.0000) | Acc: (92.00%) (39000/42368)
Epoch: 96 | Batch_idx: 340 |  Loss: (0.2277) |  Loss2: (0.0000) | Acc: (92.00%) (40179/43648)
Epoch: 96 | Batch_idx: 350 |  Loss: (0.2282) |  Loss2: (0.0000) | Acc: (92.00%) (41347/44928)
Epoch: 96 | Batch_idx: 360 |  Loss: (0.2277) |  Loss2: (0.0000) | Acc: (92.00%) (42531/46208)
Epoch: 96 | Batch_idx: 370 |  Loss: (0.2281) |  Loss2: (0.0000) | Acc: (92.00%) (43700/47488)
Epoch: 96 | Batch_idx: 380 |  Loss: (0.2280) |  Loss2: (0.0000) | Acc: (92.00%) (44890/48768)
Epoch: 96 | Batch_idx: 390 |  Loss: (0.2277) |  Loss2: (0.0000) | Acc: (92.00%) (46021/50000)
# TEST : Loss: (0.3944) | Acc: (87.00%) (8706/10000)
percent tensor([0.5970, 0.5919, 0.6058, 0.5910, 0.6118, 0.5952, 0.6019, 0.5928, 0.5978,
        0.5930, 0.5932, 0.6044, 0.5909, 0.5816, 0.5942, 0.5901],
       device='cuda:0') torch.Size([16])
percent tensor([0.5870, 0.5504, 0.5493, 0.6057, 0.5771, 0.6309, 0.5594, 0.5816, 0.5773,
        0.5546, 0.5683, 0.5426, 0.5451, 0.6161, 0.5813, 0.5955],
       device='cuda:0') torch.Size([16])
percent tensor([0.5107, 0.5523, 0.5105, 0.4664, 0.5126, 0.4723, 0.5579, 0.5229, 0.5057,
        0.5101, 0.4983, 0.5349, 0.5348, 0.5195, 0.5236, 0.5112],
       device='cuda:0') torch.Size([16])
percent tensor([0.6266, 0.5890, 0.6108, 0.6245, 0.6267, 0.6416, 0.6111, 0.6216, 0.6198,
        0.6070, 0.6145, 0.6044, 0.6057, 0.6183, 0.6194, 0.6347],
       device='cuda:0') torch.Size([16])
percent tensor([0.5659, 0.6486, 0.6445, 0.6357, 0.5968, 0.6705, 0.6117, 0.4815, 0.7091,
        0.5888, 0.6507, 0.6591, 0.7116, 0.7227, 0.5554, 0.6208],
       device='cuda:0') torch.Size([16])
percent tensor([0.6412, 0.6109, 0.7090, 0.7064, 0.7407, 0.7582, 0.6627, 0.6145, 0.7119,
        0.6510, 0.6973, 0.6495, 0.6231, 0.7825, 0.6029, 0.6909],
       device='cuda:0') torch.Size([16])
percent tensor([0.6587, 0.6066, 0.7171, 0.6313, 0.7624, 0.6581, 0.6753, 0.7083, 0.6246,
        0.6409, 0.6245, 0.6314, 0.5261, 0.6412, 0.6346, 0.6771],
       device='cuda:0') torch.Size([16])
percent tensor([0.9992, 0.9986, 0.9989, 0.9993, 0.9991, 0.9981, 0.9989, 0.9988, 0.9989,
        0.9993, 0.9991, 0.9991, 0.9989, 0.9994, 0.9985, 0.9989],
       device='cuda:0') torch.Size([16])
Epoch: 97 | Batch_idx: 0 |  Loss: (0.2095) |  Loss2: (0.0000) | Acc: (92.00%) (118/128)
Epoch: 97 | Batch_idx: 10 |  Loss: (0.2197) |  Loss2: (0.0000) | Acc: (92.00%) (1302/1408)
Epoch: 97 | Batch_idx: 20 |  Loss: (0.2276) |  Loss2: (0.0000) | Acc: (91.00%) (2470/2688)
Epoch: 97 | Batch_idx: 30 |  Loss: (0.2273) |  Loss2: (0.0000) | Acc: (92.00%) (3651/3968)
Epoch: 97 | Batch_idx: 40 |  Loss: (0.2236) |  Loss2: (0.0000) | Acc: (92.00%) (4845/5248)
Epoch: 97 | Batch_idx: 50 |  Loss: (0.2309) |  Loss2: (0.0000) | Acc: (92.00%) (6007/6528)
Epoch: 97 | Batch_idx: 60 |  Loss: (0.2265) |  Loss2: (0.0000) | Acc: (92.00%) (7205/7808)
Epoch: 97 | Batch_idx: 70 |  Loss: (0.2231) |  Loss2: (0.0000) | Acc: (92.00%) (8396/9088)
Epoch: 97 | Batch_idx: 80 |  Loss: (0.2223) |  Loss2: (0.0000) | Acc: (92.00%) (9584/10368)
Epoch: 97 | Batch_idx: 90 |  Loss: (0.2189) |  Loss2: (0.0000) | Acc: (92.00%) (10792/11648)
Epoch: 97 | Batch_idx: 100 |  Loss: (0.2182) |  Loss2: (0.0000) | Acc: (92.00%) (11981/12928)
Epoch: 97 | Batch_idx: 110 |  Loss: (0.2176) |  Loss2: (0.0000) | Acc: (92.00%) (13158/14208)
Epoch: 97 | Batch_idx: 120 |  Loss: (0.2170) |  Loss2: (0.0000) | Acc: (92.00%) (14340/15488)
Epoch: 97 | Batch_idx: 130 |  Loss: (0.2145) |  Loss2: (0.0000) | Acc: (92.00%) (15546/16768)
Epoch: 97 | Batch_idx: 140 |  Loss: (0.2127) |  Loss2: (0.0000) | Acc: (92.00%) (16741/18048)
Epoch: 97 | Batch_idx: 150 |  Loss: (0.2147) |  Loss2: (0.0000) | Acc: (92.00%) (17907/19328)
Epoch: 97 | Batch_idx: 160 |  Loss: (0.2148) |  Loss2: (0.0000) | Acc: (92.00%) (19092/20608)
Epoch: 97 | Batch_idx: 170 |  Loss: (0.2152) |  Loss2: (0.0000) | Acc: (92.00%) (20277/21888)
Epoch: 97 | Batch_idx: 180 |  Loss: (0.2156) |  Loss2: (0.0000) | Acc: (92.00%) (21461/23168)
Epoch: 97 | Batch_idx: 190 |  Loss: (0.2156) |  Loss2: (0.0000) | Acc: (92.00%) (22647/24448)
Epoch: 97 | Batch_idx: 200 |  Loss: (0.2162) |  Loss2: (0.0000) | Acc: (92.00%) (23830/25728)
Epoch: 97 | Batch_idx: 210 |  Loss: (0.2166) |  Loss2: (0.0000) | Acc: (92.00%) (25011/27008)
Epoch: 97 | Batch_idx: 220 |  Loss: (0.2172) |  Loss2: (0.0000) | Acc: (92.00%) (26190/28288)
Epoch: 97 | Batch_idx: 230 |  Loss: (0.2170) |  Loss2: (0.0000) | Acc: (92.00%) (27373/29568)
Epoch: 97 | Batch_idx: 240 |  Loss: (0.2167) |  Loss2: (0.0000) | Acc: (92.00%) (28561/30848)
Epoch: 97 | Batch_idx: 250 |  Loss: (0.2173) |  Loss2: (0.0000) | Acc: (92.00%) (29734/32128)
Epoch: 97 | Batch_idx: 260 |  Loss: (0.2177) |  Loss2: (0.0000) | Acc: (92.00%) (30916/33408)
Epoch: 97 | Batch_idx: 270 |  Loss: (0.2182) |  Loss2: (0.0000) | Acc: (92.00%) (32101/34688)
Epoch: 97 | Batch_idx: 280 |  Loss: (0.2185) |  Loss2: (0.0000) | Acc: (92.00%) (33279/35968)
Epoch: 97 | Batch_idx: 290 |  Loss: (0.2198) |  Loss2: (0.0000) | Acc: (92.00%) (34445/37248)
Epoch: 97 | Batch_idx: 300 |  Loss: (0.2196) |  Loss2: (0.0000) | Acc: (92.00%) (35623/38528)
Epoch: 97 | Batch_idx: 310 |  Loss: (0.2189) |  Loss2: (0.0000) | Acc: (92.00%) (36815/39808)
Epoch: 97 | Batch_idx: 320 |  Loss: (0.2185) |  Loss2: (0.0000) | Acc: (92.00%) (38011/41088)
Epoch: 97 | Batch_idx: 330 |  Loss: (0.2185) |  Loss2: (0.0000) | Acc: (92.00%) (39199/42368)
Epoch: 97 | Batch_idx: 340 |  Loss: (0.2181) |  Loss2: (0.0000) | Acc: (92.00%) (40381/43648)
Epoch: 97 | Batch_idx: 350 |  Loss: (0.2180) |  Loss2: (0.0000) | Acc: (92.00%) (41568/44928)
Epoch: 97 | Batch_idx: 360 |  Loss: (0.2177) |  Loss2: (0.0000) | Acc: (92.00%) (42759/46208)
Epoch: 97 | Batch_idx: 370 |  Loss: (0.2178) |  Loss2: (0.0000) | Acc: (92.00%) (43940/47488)
Epoch: 97 | Batch_idx: 380 |  Loss: (0.2178) |  Loss2: (0.0000) | Acc: (92.00%) (45120/48768)
Epoch: 97 | Batch_idx: 390 |  Loss: (0.2175) |  Loss2: (0.0000) | Acc: (92.00%) (46267/50000)
# TEST : Loss: (0.3849) | Acc: (87.00%) (8725/10000)
percent tensor([0.5977, 0.5929, 0.6059, 0.5917, 0.6124, 0.5957, 0.6028, 0.5929, 0.5987,
        0.5935, 0.5942, 0.6047, 0.5914, 0.5826, 0.5949, 0.5906],
       device='cuda:0') torch.Size([16])
percent tensor([0.5890, 0.5501, 0.5508, 0.6062, 0.5782, 0.6319, 0.5600, 0.5822, 0.5794,
        0.5554, 0.5706, 0.5435, 0.5464, 0.6176, 0.5811, 0.5963],
       device='cuda:0') torch.Size([16])
percent tensor([0.5163, 0.5577, 0.5152, 0.4722, 0.5162, 0.4794, 0.5627, 0.5297, 0.5108,
        0.5134, 0.5012, 0.5397, 0.5413, 0.5248, 0.5303, 0.5174],
       device='cuda:0') torch.Size([16])
percent tensor([0.6305, 0.5902, 0.6164, 0.6289, 0.6322, 0.6461, 0.6147, 0.6268, 0.6236,
        0.6097, 0.6175, 0.6079, 0.6073, 0.6215, 0.6226, 0.6385],
       device='cuda:0') torch.Size([16])
percent tensor([0.5599, 0.6445, 0.6391, 0.6377, 0.5888, 0.6737, 0.6007, 0.4768, 0.7019,
        0.5809, 0.6380, 0.6534, 0.7050, 0.7200, 0.5496, 0.6199],
       device='cuda:0') torch.Size([16])
percent tensor([0.6410, 0.6111, 0.7074, 0.7066, 0.7420, 0.7582, 0.6637, 0.6153, 0.7109,
        0.6502, 0.6964, 0.6499, 0.6216, 0.7857, 0.6018, 0.6901],
       device='cuda:0') torch.Size([16])
percent tensor([0.6651, 0.6139, 0.7222, 0.6377, 0.7671, 0.6685, 0.6832, 0.7124, 0.6333,
        0.6488, 0.6333, 0.6368, 0.5296, 0.6456, 0.6429, 0.6844],
       device='cuda:0') torch.Size([16])
percent tensor([0.9992, 0.9987, 0.9990, 0.9993, 0.9991, 0.9982, 0.9990, 0.9989, 0.9989,
        0.9993, 0.9991, 0.9991, 0.9989, 0.9994, 0.9985, 0.9990],
       device='cuda:0') torch.Size([16])
Epoch: 98 | Batch_idx: 0 |  Loss: (0.2089) |  Loss2: (0.0000) | Acc: (93.00%) (120/128)
Epoch: 98 | Batch_idx: 10 |  Loss: (0.1807) |  Loss2: (0.0000) | Acc: (93.00%) (1320/1408)
Epoch: 98 | Batch_idx: 20 |  Loss: (0.1992) |  Loss2: (0.0000) | Acc: (93.00%) (2510/2688)
Epoch: 98 | Batch_idx: 30 |  Loss: (0.2053) |  Loss2: (0.0000) | Acc: (93.00%) (3692/3968)
Epoch: 98 | Batch_idx: 40 |  Loss: (0.2154) |  Loss2: (0.0000) | Acc: (92.00%) (4872/5248)
Epoch: 98 | Batch_idx: 50 |  Loss: (0.2117) |  Loss2: (0.0000) | Acc: (92.00%) (6069/6528)
Epoch: 98 | Batch_idx: 60 |  Loss: (0.2072) |  Loss2: (0.0000) | Acc: (93.00%) (7271/7808)
Epoch: 98 | Batch_idx: 70 |  Loss: (0.2093) |  Loss2: (0.0000) | Acc: (93.00%) (8460/9088)
Epoch: 98 | Batch_idx: 80 |  Loss: (0.2080) |  Loss2: (0.0000) | Acc: (93.00%) (9651/10368)
Epoch: 98 | Batch_idx: 90 |  Loss: (0.2075) |  Loss2: (0.0000) | Acc: (93.00%) (10843/11648)
Epoch: 98 | Batch_idx: 100 |  Loss: (0.2076) |  Loss2: (0.0000) | Acc: (93.00%) (12029/12928)
Epoch: 98 | Batch_idx: 110 |  Loss: (0.2092) |  Loss2: (0.0000) | Acc: (92.00%) (13210/14208)
Epoch: 98 | Batch_idx: 120 |  Loss: (0.2124) |  Loss2: (0.0000) | Acc: (92.00%) (14381/15488)
Epoch: 98 | Batch_idx: 130 |  Loss: (0.2130) |  Loss2: (0.0000) | Acc: (92.00%) (15563/16768)
Epoch: 98 | Batch_idx: 140 |  Loss: (0.2134) |  Loss2: (0.0000) | Acc: (92.00%) (16747/18048)
Epoch: 98 | Batch_idx: 150 |  Loss: (0.2138) |  Loss2: (0.0000) | Acc: (92.00%) (17936/19328)
Epoch: 98 | Batch_idx: 160 |  Loss: (0.2146) |  Loss2: (0.0000) | Acc: (92.00%) (19115/20608)
Epoch: 98 | Batch_idx: 170 |  Loss: (0.2158) |  Loss2: (0.0000) | Acc: (92.00%) (20288/21888)
Epoch: 98 | Batch_idx: 180 |  Loss: (0.2153) |  Loss2: (0.0000) | Acc: (92.00%) (21481/23168)
Epoch: 98 | Batch_idx: 190 |  Loss: (0.2180) |  Loss2: (0.0000) | Acc: (92.00%) (22634/24448)
Epoch: 98 | Batch_idx: 200 |  Loss: (0.2172) |  Loss2: (0.0000) | Acc: (92.00%) (23825/25728)
Epoch: 98 | Batch_idx: 210 |  Loss: (0.2158) |  Loss2: (0.0000) | Acc: (92.00%) (25020/27008)
Epoch: 98 | Batch_idx: 220 |  Loss: (0.2160) |  Loss2: (0.0000) | Acc: (92.00%) (26202/28288)
Epoch: 98 | Batch_idx: 230 |  Loss: (0.2155) |  Loss2: (0.0000) | Acc: (92.00%) (27394/29568)
Epoch: 98 | Batch_idx: 240 |  Loss: (0.2150) |  Loss2: (0.0000) | Acc: (92.00%) (28586/30848)
Epoch: 98 | Batch_idx: 250 |  Loss: (0.2142) |  Loss2: (0.0000) | Acc: (92.00%) (29778/32128)
Epoch: 98 | Batch_idx: 260 |  Loss: (0.2149) |  Loss2: (0.0000) | Acc: (92.00%) (30947/33408)
Epoch: 98 | Batch_idx: 270 |  Loss: (0.2158) |  Loss2: (0.0000) | Acc: (92.00%) (32118/34688)
Epoch: 98 | Batch_idx: 280 |  Loss: (0.2156) |  Loss2: (0.0000) | Acc: (92.00%) (33302/35968)
Epoch: 98 | Batch_idx: 290 |  Loss: (0.2154) |  Loss2: (0.0000) | Acc: (92.00%) (34495/37248)
Epoch: 98 | Batch_idx: 300 |  Loss: (0.2157) |  Loss2: (0.0000) | Acc: (92.00%) (35670/38528)
Epoch: 98 | Batch_idx: 310 |  Loss: (0.2156) |  Loss2: (0.0000) | Acc: (92.00%) (36855/39808)
Epoch: 98 | Batch_idx: 320 |  Loss: (0.2153) |  Loss2: (0.0000) | Acc: (92.00%) (38039/41088)
Epoch: 98 | Batch_idx: 330 |  Loss: (0.2153) |  Loss2: (0.0000) | Acc: (92.00%) (39217/42368)
Epoch: 98 | Batch_idx: 340 |  Loss: (0.2153) |  Loss2: (0.0000) | Acc: (92.00%) (40397/43648)
Epoch: 98 | Batch_idx: 350 |  Loss: (0.2149) |  Loss2: (0.0000) | Acc: (92.00%) (41598/44928)
Epoch: 98 | Batch_idx: 360 |  Loss: (0.2143) |  Loss2: (0.0000) | Acc: (92.00%) (42794/46208)
Epoch: 98 | Batch_idx: 370 |  Loss: (0.2136) |  Loss2: (0.0000) | Acc: (92.00%) (43983/47488)
Epoch: 98 | Batch_idx: 380 |  Loss: (0.2134) |  Loss2: (0.0000) | Acc: (92.00%) (45167/48768)
Epoch: 98 | Batch_idx: 390 |  Loss: (0.2138) |  Loss2: (0.0000) | Acc: (92.00%) (46297/50000)
# TEST : Loss: (0.3818) | Acc: (87.00%) (8756/10000)
percent tensor([0.6002, 0.5950, 0.6082, 0.5941, 0.6148, 0.5983, 0.6052, 0.5949, 0.6010,
        0.5954, 0.5965, 0.6069, 0.5935, 0.5848, 0.5972, 0.5928],
       device='cuda:0') torch.Size([16])
percent tensor([0.5876, 0.5463, 0.5479, 0.6035, 0.5751, 0.6305, 0.5566, 0.5784, 0.5778,
        0.5523, 0.5692, 0.5400, 0.5439, 0.6160, 0.5779, 0.5943],
       device='cuda:0') torch.Size([16])
percent tensor([0.5171, 0.5590, 0.5167, 0.4736, 0.5168, 0.4792, 0.5640, 0.5334, 0.5119,
        0.5136, 0.5009, 0.5416, 0.5433, 0.5253, 0.5319, 0.5177],
       device='cuda:0') torch.Size([16])
percent tensor([0.6308, 0.5893, 0.6185, 0.6306, 0.6337, 0.6464, 0.6148, 0.6278, 0.6246,
        0.6098, 0.6180, 0.6081, 0.6063, 0.6226, 0.6222, 0.6389],
       device='cuda:0') torch.Size([16])
percent tensor([0.5671, 0.6537, 0.6441, 0.6423, 0.5959, 0.6769, 0.6107, 0.4887, 0.7052,
        0.5904, 0.6442, 0.6641, 0.7129, 0.7260, 0.5602, 0.6287],
       device='cuda:0') torch.Size([16])
percent tensor([0.6392, 0.6121, 0.7073, 0.7064, 0.7416, 0.7547, 0.6641, 0.6117, 0.7105,
        0.6524, 0.6979, 0.6519, 0.6221, 0.7878, 0.5977, 0.6885],
       device='cuda:0') torch.Size([16])
percent tensor([0.6681, 0.6178, 0.7254, 0.6398, 0.7686, 0.6708, 0.6858, 0.7159, 0.6390,
        0.6528, 0.6382, 0.6401, 0.5314, 0.6454, 0.6479, 0.6869],
       device='cuda:0') torch.Size([16])
percent tensor([0.9992, 0.9988, 0.9990, 0.9993, 0.9991, 0.9982, 0.9990, 0.9989, 0.9990,
        0.9994, 0.9992, 0.9992, 0.9990, 0.9994, 0.9985, 0.9990],
       device='cuda:0') torch.Size([16])
Epoch: 99 | Batch_idx: 0 |  Loss: (0.2155) |  Loss2: (0.0000) | Acc: (93.00%) (120/128)
Epoch: 99 | Batch_idx: 10 |  Loss: (0.2054) |  Loss2: (0.0000) | Acc: (93.00%) (1318/1408)
Epoch: 99 | Batch_idx: 20 |  Loss: (0.2099) |  Loss2: (0.0000) | Acc: (92.00%) (2499/2688)
Epoch: 99 | Batch_idx: 30 |  Loss: (0.2074) |  Loss2: (0.0000) | Acc: (93.00%) (3691/3968)
Epoch: 99 | Batch_idx: 40 |  Loss: (0.2088) |  Loss2: (0.0000) | Acc: (92.00%) (4874/5248)
Epoch: 99 | Batch_idx: 50 |  Loss: (0.2123) |  Loss2: (0.0000) | Acc: (92.00%) (6057/6528)
Epoch: 99 | Batch_idx: 60 |  Loss: (0.2108) |  Loss2: (0.0000) | Acc: (92.00%) (7250/7808)
Epoch: 99 | Batch_idx: 70 |  Loss: (0.2101) |  Loss2: (0.0000) | Acc: (92.00%) (8434/9088)
Epoch: 99 | Batch_idx: 80 |  Loss: (0.2087) |  Loss2: (0.0000) | Acc: (92.00%) (9624/10368)
Epoch: 99 | Batch_idx: 90 |  Loss: (0.2121) |  Loss2: (0.0000) | Acc: (92.00%) (10789/11648)
Epoch: 99 | Batch_idx: 100 |  Loss: (0.2132) |  Loss2: (0.0000) | Acc: (92.00%) (11981/12928)
Epoch: 99 | Batch_idx: 110 |  Loss: (0.2109) |  Loss2: (0.0000) | Acc: (92.00%) (13183/14208)
Epoch: 99 | Batch_idx: 120 |  Loss: (0.2126) |  Loss2: (0.0000) | Acc: (92.00%) (14367/15488)
Epoch: 99 | Batch_idx: 130 |  Loss: (0.2112) |  Loss2: (0.0000) | Acc: (92.00%) (15566/16768)
Epoch: 99 | Batch_idx: 140 |  Loss: (0.2103) |  Loss2: (0.0000) | Acc: (92.00%) (16764/18048)
Epoch: 99 | Batch_idx: 150 |  Loss: (0.2130) |  Loss2: (0.0000) | Acc: (92.00%) (17928/19328)
Epoch: 99 | Batch_idx: 160 |  Loss: (0.2130) |  Loss2: (0.0000) | Acc: (92.00%) (19123/20608)
Epoch: 99 | Batch_idx: 170 |  Loss: (0.2125) |  Loss2: (0.0000) | Acc: (92.00%) (20314/21888)
Epoch: 99 | Batch_idx: 180 |  Loss: (0.2127) |  Loss2: (0.0000) | Acc: (92.00%) (21494/23168)
Epoch: 99 | Batch_idx: 190 |  Loss: (0.2118) |  Loss2: (0.0000) | Acc: (92.00%) (22688/24448)
Epoch: 99 | Batch_idx: 200 |  Loss: (0.2104) |  Loss2: (0.0000) | Acc: (92.00%) (23884/25728)
Epoch: 99 | Batch_idx: 210 |  Loss: (0.2101) |  Loss2: (0.0000) | Acc: (92.00%) (25063/27008)
Epoch: 99 | Batch_idx: 220 |  Loss: (0.2096) |  Loss2: (0.0000) | Acc: (92.00%) (26257/28288)
Epoch: 99 | Batch_idx: 230 |  Loss: (0.2099) |  Loss2: (0.0000) | Acc: (92.00%) (27442/29568)
Epoch: 99 | Batch_idx: 240 |  Loss: (0.2098) |  Loss2: (0.0000) | Acc: (92.00%) (28624/30848)
Epoch: 99 | Batch_idx: 250 |  Loss: (0.2102) |  Loss2: (0.0000) | Acc: (92.00%) (29801/32128)
Epoch: 99 | Batch_idx: 260 |  Loss: (0.2106) |  Loss2: (0.0000) | Acc: (92.00%) (30985/33408)
Epoch: 99 | Batch_idx: 270 |  Loss: (0.2095) |  Loss2: (0.0000) | Acc: (92.00%) (32185/34688)
Epoch: 99 | Batch_idx: 280 |  Loss: (0.2096) |  Loss2: (0.0000) | Acc: (92.00%) (33368/35968)
Epoch: 99 | Batch_idx: 290 |  Loss: (0.2089) |  Loss2: (0.0000) | Acc: (92.00%) (34564/37248)
Epoch: 99 | Batch_idx: 300 |  Loss: (0.2090) |  Loss2: (0.0000) | Acc: (92.00%) (35753/38528)
Epoch: 99 | Batch_idx: 310 |  Loss: (0.2081) |  Loss2: (0.0000) | Acc: (92.00%) (36956/39808)
Epoch: 99 | Batch_idx: 320 |  Loss: (0.2086) |  Loss2: (0.0000) | Acc: (92.00%) (38137/41088)
Epoch: 99 | Batch_idx: 330 |  Loss: (0.2088) |  Loss2: (0.0000) | Acc: (92.00%) (39321/42368)
Epoch: 99 | Batch_idx: 340 |  Loss: (0.2095) |  Loss2: (0.0000) | Acc: (92.00%) (40503/43648)
Epoch: 99 | Batch_idx: 350 |  Loss: (0.2093) |  Loss2: (0.0000) | Acc: (92.00%) (41688/44928)
Epoch: 99 | Batch_idx: 360 |  Loss: (0.2091) |  Loss2: (0.0000) | Acc: (92.00%) (42868/46208)
Epoch: 99 | Batch_idx: 370 |  Loss: (0.2088) |  Loss2: (0.0000) | Acc: (92.00%) (44063/47488)
Epoch: 99 | Batch_idx: 380 |  Loss: (0.2094) |  Loss2: (0.0000) | Acc: (92.00%) (45244/48768)
Epoch: 99 | Batch_idx: 390 |  Loss: (0.2094) |  Loss2: (0.0000) | Acc: (92.00%) (46389/50000)
# TEST : Loss: (0.3791) | Acc: (87.00%) (8770/10000)
percent tensor([0.5969, 0.5913, 0.6042, 0.5908, 0.6109, 0.5956, 0.6014, 0.5908, 0.5973,
        0.5915, 0.5930, 0.6028, 0.5897, 0.5815, 0.5938, 0.5894],
       device='cuda:0') torch.Size([16])
percent tensor([0.5865, 0.5435, 0.5457, 0.6019, 0.5728, 0.6293, 0.5542, 0.5760, 0.5765,
        0.5499, 0.5679, 0.5376, 0.5421, 0.6147, 0.5756, 0.5929],
       device='cuda:0') torch.Size([16])
percent tensor([0.5206, 0.5624, 0.5209, 0.4794, 0.5215, 0.4846, 0.5673, 0.5389, 0.5165,
        0.5160, 0.5039, 0.5447, 0.5467, 0.5297, 0.5368, 0.5214],
       device='cuda:0') torch.Size([16])
percent tensor([0.6375, 0.5947, 0.6250, 0.6366, 0.6408, 0.6524, 0.6211, 0.6350, 0.6310,
        0.6161, 0.6246, 0.6139, 0.6120, 0.6288, 0.6283, 0.6456],
       device='cuda:0') torch.Size([16])
percent tensor([0.5607, 0.6533, 0.6385, 0.6380, 0.5873, 0.6666, 0.6072, 0.4844, 0.6993,
        0.5880, 0.6400, 0.6617, 0.7094, 0.7239, 0.5585, 0.6216],
       device='cuda:0') torch.Size([16])
percent tensor([0.6366, 0.6118, 0.7053, 0.7038, 0.7434, 0.7519, 0.6631, 0.6095, 0.7107,
        0.6517, 0.6948, 0.6497, 0.6203, 0.7891, 0.5933, 0.6858],
       device='cuda:0') torch.Size([16])
percent tensor([0.6762, 0.6245, 0.7339, 0.6496, 0.7784, 0.6816, 0.6971, 0.7250, 0.6479,
        0.6604, 0.6452, 0.6501, 0.5363, 0.6513, 0.6582, 0.6964],
       device='cuda:0') torch.Size([16])
percent tensor([0.9992, 0.9987, 0.9990, 0.9993, 0.9991, 0.9983, 0.9990, 0.9989, 0.9990,
        0.9994, 0.9992, 0.9992, 0.9990, 0.9994, 0.9985, 0.9990],
       device='cuda:0') torch.Size([16])
True Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=128, out_features=16, bias=False)
False Linear(in_features=16, out_features=2, bias=False)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=128, out_features=16, bias=False)
False Linear(in_features=16, out_features=2, bias=False)
True Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=256, out_features=32, bias=False)
False Linear(in_features=32, out_features=2, bias=False)
True Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=256, out_features=32, bias=False)
False Linear(in_features=32, out_features=2, bias=False)
True Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=512, out_features=64, bias=False)
False Linear(in_features=64, out_features=2, bias=False)
True Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=512, out_features=64, bias=False)
False Linear(in_features=64, out_features=2, bias=False)
True Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1024, out_features=128, bias=False)
False Linear(in_features=128, out_features=2, bias=False)
True Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1024, out_features=128, bias=False)
False Linear(in_features=128, out_features=2, bias=False)
True Linear(in_features=512, out_features=10, bias=True)
Epoch: 100 | Batch_idx: 0 |  Loss: (0.2841) |  Loss2: (0.0000) | Acc: (85.00%) (110/128)
Epoch: 100 | Batch_idx: 10 |  Loss: (0.2147) |  Loss2: (0.0000) | Acc: (92.00%) (1300/1408)
Epoch: 100 | Batch_idx: 20 |  Loss: (0.1993) |  Loss2: (0.0000) | Acc: (93.00%) (2501/2688)
Epoch: 100 | Batch_idx: 30 |  Loss: (0.2057) |  Loss2: (0.0000) | Acc: (92.00%) (3682/3968)
Epoch: 100 | Batch_idx: 40 |  Loss: (0.2023) |  Loss2: (0.0000) | Acc: (92.00%) (4877/5248)
Epoch: 100 | Batch_idx: 50 |  Loss: (0.2040) |  Loss2: (0.0000) | Acc: (92.00%) (6063/6528)
Epoch: 100 | Batch_idx: 60 |  Loss: (0.2099) |  Loss2: (0.0000) | Acc: (92.00%) (7239/7808)
Epoch: 100 | Batch_idx: 70 |  Loss: (0.2094) |  Loss2: (0.0000) | Acc: (92.00%) (8438/9088)
Epoch: 100 | Batch_idx: 80 |  Loss: (0.2115) |  Loss2: (0.0000) | Acc: (92.00%) (9617/10368)
Epoch: 100 | Batch_idx: 90 |  Loss: (0.2096) |  Loss2: (0.0000) | Acc: (92.00%) (10808/11648)
Epoch: 100 | Batch_idx: 100 |  Loss: (0.2105) |  Loss2: (0.0000) | Acc: (92.00%) (11991/12928)
Epoch: 100 | Batch_idx: 110 |  Loss: (0.2118) |  Loss2: (0.0000) | Acc: (92.00%) (13174/14208)
Epoch: 100 | Batch_idx: 120 |  Loss: (0.2123) |  Loss2: (0.0000) | Acc: (92.00%) (14354/15488)
Epoch: 100 | Batch_idx: 130 |  Loss: (0.2149) |  Loss2: (0.0000) | Acc: (92.00%) (15532/16768)
Epoch: 100 | Batch_idx: 140 |  Loss: (0.2172) |  Loss2: (0.0000) | Acc: (92.00%) (16708/18048)
Epoch: 100 | Batch_idx: 150 |  Loss: (0.2166) |  Loss2: (0.0000) | Acc: (92.00%) (17889/19328)
Epoch: 100 | Batch_idx: 160 |  Loss: (0.2163) |  Loss2: (0.0000) | Acc: (92.00%) (19072/20608)
Epoch: 100 | Batch_idx: 170 |  Loss: (0.2176) |  Loss2: (0.0000) | Acc: (92.00%) (20243/21888)
Epoch: 100 | Batch_idx: 180 |  Loss: (0.2171) |  Loss2: (0.0000) | Acc: (92.00%) (21429/23168)
Epoch: 100 | Batch_idx: 190 |  Loss: (0.2168) |  Loss2: (0.0000) | Acc: (92.00%) (22613/24448)
Epoch: 100 | Batch_idx: 200 |  Loss: (0.2179) |  Loss2: (0.0000) | Acc: (92.00%) (23798/25728)
Epoch: 100 | Batch_idx: 210 |  Loss: (0.2174) |  Loss2: (0.0000) | Acc: (92.00%) (24983/27008)
Epoch: 100 | Batch_idx: 220 |  Loss: (0.2172) |  Loss2: (0.0000) | Acc: (92.00%) (26171/28288)
Epoch: 100 | Batch_idx: 230 |  Loss: (0.2172) |  Loss2: (0.0000) | Acc: (92.00%) (27350/29568)
Epoch: 100 | Batch_idx: 240 |  Loss: (0.2174) |  Loss2: (0.0000) | Acc: (92.00%) (28536/30848)
Epoch: 100 | Batch_idx: 250 |  Loss: (0.2167) |  Loss2: (0.0000) | Acc: (92.00%) (29731/32128)
Epoch: 100 | Batch_idx: 260 |  Loss: (0.2161) |  Loss2: (0.0000) | Acc: (92.00%) (30930/33408)
Epoch: 100 | Batch_idx: 270 |  Loss: (0.2169) |  Loss2: (0.0000) | Acc: (92.00%) (32105/34688)
Epoch: 100 | Batch_idx: 280 |  Loss: (0.2170) |  Loss2: (0.0000) | Acc: (92.00%) (33293/35968)
Epoch: 100 | Batch_idx: 290 |  Loss: (0.2161) |  Loss2: (0.0000) | Acc: (92.00%) (34488/37248)
Epoch: 100 | Batch_idx: 300 |  Loss: (0.2164) |  Loss2: (0.0000) | Acc: (92.00%) (35669/38528)
Epoch: 100 | Batch_idx: 310 |  Loss: (0.2169) |  Loss2: (0.0000) | Acc: (92.00%) (36845/39808)
Epoch: 100 | Batch_idx: 320 |  Loss: (0.2172) |  Loss2: (0.0000) | Acc: (92.00%) (38031/41088)
Epoch: 100 | Batch_idx: 330 |  Loss: (0.2175) |  Loss2: (0.0000) | Acc: (92.00%) (39208/42368)
Epoch: 100 | Batch_idx: 340 |  Loss: (0.2179) |  Loss2: (0.0000) | Acc: (92.00%) (40393/43648)
Epoch: 100 | Batch_idx: 350 |  Loss: (0.2184) |  Loss2: (0.0000) | Acc: (92.00%) (41564/44928)
Epoch: 100 | Batch_idx: 360 |  Loss: (0.2187) |  Loss2: (0.0000) | Acc: (92.00%) (42739/46208)
Epoch: 100 | Batch_idx: 370 |  Loss: (0.2188) |  Loss2: (0.0000) | Acc: (92.00%) (43911/47488)
Epoch: 100 | Batch_idx: 380 |  Loss: (0.2194) |  Loss2: (0.0000) | Acc: (92.00%) (45074/48768)
Epoch: 100 | Batch_idx: 390 |  Loss: (0.2198) |  Loss2: (0.0000) | Acc: (92.00%) (46211/50000)
=> saving checkpoint 'drive/app/torch/save_Routing_Gate_2/checkpoint_100.pth.tar'
# TEST : Loss: (0.4456) | Acc: (85.00%) (8596/10000)
percent tensor([0.5980, 0.5901, 0.6067, 0.5920, 0.6121, 0.5961, 0.6014, 0.5929, 0.5979,
        0.5919, 0.5938, 0.6040, 0.5905, 0.5801, 0.5940, 0.5902],
       device='cuda:0') torch.Size([16])
percent tensor([0.5891, 0.5422, 0.5445, 0.6039, 0.5723, 0.6336, 0.5540, 0.5698, 0.5750,
        0.5490, 0.5696, 0.5370, 0.5413, 0.6071, 0.5782, 0.5937],
       device='cuda:0') torch.Size([16])
percent tensor([0.5105, 0.5544, 0.5159, 0.4759, 0.5170, 0.4716, 0.5582, 0.5356, 0.5057,
        0.5047, 0.4933, 0.5377, 0.5342, 0.5196, 0.5278, 0.5171],
       device='cuda:0') torch.Size([16])
percent tensor([0.6396, 0.5950, 0.6286, 0.6371, 0.6424, 0.6520, 0.6220, 0.6368, 0.6348,
        0.6174, 0.6249, 0.6141, 0.6115, 0.6281, 0.6283, 0.6460],
       device='cuda:0') torch.Size([16])
percent tensor([0.5306, 0.6478, 0.6169, 0.6199, 0.5765, 0.6378, 0.5938, 0.4956, 0.6760,
        0.5743, 0.6237, 0.6585, 0.6841, 0.7147, 0.5580, 0.5839],
       device='cuda:0') torch.Size([16])
percent tensor([0.6394, 0.6082, 0.7129, 0.7145, 0.7520, 0.7331, 0.6818, 0.6216, 0.7238,
        0.6456, 0.7052, 0.6732, 0.6052, 0.7676, 0.6064, 0.6640],
       device='cuda:0') torch.Size([16])
percent tensor([0.6784, 0.6234, 0.7405, 0.6539, 0.7865, 0.6935, 0.6992, 0.7247, 0.6590,
        0.6559, 0.6549, 0.6431, 0.5355, 0.6322, 0.6651, 0.6990],
       device='cuda:0') torch.Size([16])
percent tensor([0.9992, 0.9988, 0.9989, 0.9995, 0.9991, 0.9985, 0.9986, 0.9991, 0.9990,
        0.9993, 0.9993, 0.9991, 0.9989, 0.9991, 0.9985, 0.9990],
       device='cuda:0') torch.Size([16])
Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 3, 3, 3]) tensor(179.9125, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(816.8523, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(818.1810, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([128, 64, 3, 3]) tensor(1529.1881, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([128, 64, 1, 1]) tensor(495.6948, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([128, 128, 3, 3]) tensor(2235.8674, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([256, 128, 3, 3]) tensor(4287.7852, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([256, 128, 1, 1]) tensor(1398.8790, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([256, 256, 3, 3]) tensor(6173.5264, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([512, 256, 3, 3]) tensor(11896.8438, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([512, 256, 1, 1]) tensor(3942.1116, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([512, 512, 3, 3]) tensor(16662.6387, device='cuda:0', grad_fn=<NormBackward0>)
Epoch: 101 | Batch_idx: 0 |  Loss: (0.1887) |  Loss2: (0.0000) | Acc: (93.00%) (120/128)
Epoch: 101 | Batch_idx: 10 |  Loss: (0.2200) |  Loss2: (0.0000) | Acc: (92.00%) (1301/1408)
Epoch: 101 | Batch_idx: 20 |  Loss: (0.2136) |  Loss2: (0.0000) | Acc: (92.00%) (2498/2688)
Epoch: 101 | Batch_idx: 30 |  Loss: (0.2117) |  Loss2: (0.0000) | Acc: (92.00%) (3682/3968)
Epoch: 101 | Batch_idx: 40 |  Loss: (0.2083) |  Loss2: (0.0000) | Acc: (92.00%) (4871/5248)
Epoch: 101 | Batch_idx: 50 |  Loss: (0.2082) |  Loss2: (0.0000) | Acc: (92.00%) (6054/6528)
Epoch: 101 | Batch_idx: 60 |  Loss: (0.2069) |  Loss2: (0.0000) | Acc: (92.00%) (7244/7808)
Epoch: 101 | Batch_idx: 70 |  Loss: (0.2101) |  Loss2: (0.0000) | Acc: (92.00%) (8412/9088)
Epoch: 101 | Batch_idx: 80 |  Loss: (0.2108) |  Loss2: (0.0000) | Acc: (92.00%) (9596/10368)
Epoch: 101 | Batch_idx: 90 |  Loss: (0.2133) |  Loss2: (0.0000) | Acc: (92.00%) (10769/11648)
Epoch: 101 | Batch_idx: 100 |  Loss: (0.2121) |  Loss2: (0.0000) | Acc: (92.00%) (11959/12928)
Epoch: 101 | Batch_idx: 110 |  Loss: (0.2127) |  Loss2: (0.0000) | Acc: (92.00%) (13139/14208)
Epoch: 101 | Batch_idx: 120 |  Loss: (0.2121) |  Loss2: (0.0000) | Acc: (92.00%) (14337/15488)
Epoch: 101 | Batch_idx: 130 |  Loss: (0.2152) |  Loss2: (0.0000) | Acc: (92.00%) (15503/16768)
Epoch: 101 | Batch_idx: 140 |  Loss: (0.2138) |  Loss2: (0.0000) | Acc: (92.00%) (16703/18048)
Epoch: 101 | Batch_idx: 150 |  Loss: (0.2153) |  Loss2: (0.0000) | Acc: (92.00%) (17883/19328)
Epoch: 101 | Batch_idx: 160 |  Loss: (0.2164) |  Loss2: (0.0000) | Acc: (92.00%) (19058/20608)
Epoch: 101 | Batch_idx: 170 |  Loss: (0.2164) |  Loss2: (0.0000) | Acc: (92.00%) (20241/21888)
Epoch: 101 | Batch_idx: 180 |  Loss: (0.2152) |  Loss2: (0.0000) | Acc: (92.00%) (21440/23168)
Epoch: 101 | Batch_idx: 190 |  Loss: (0.2158) |  Loss2: (0.0000) | Acc: (92.00%) (22618/24448)
Epoch: 101 | Batch_idx: 200 |  Loss: (0.2151) |  Loss2: (0.0000) | Acc: (92.00%) (23801/25728)
Epoch: 101 | Batch_idx: 210 |  Loss: (0.2148) |  Loss2: (0.0000) | Acc: (92.00%) (24991/27008)
Epoch: 101 | Batch_idx: 220 |  Loss: (0.2145) |  Loss2: (0.0000) | Acc: (92.00%) (26179/28288)
Epoch: 101 | Batch_idx: 230 |  Loss: (0.2142) |  Loss2: (0.0000) | Acc: (92.00%) (27368/29568)
Epoch: 101 | Batch_idx: 240 |  Loss: (0.2142) |  Loss2: (0.0000) | Acc: (92.00%) (28540/30848)
Epoch: 101 | Batch_idx: 250 |  Loss: (0.2153) |  Loss2: (0.0000) | Acc: (92.00%) (29715/32128)
Epoch: 101 | Batch_idx: 260 |  Loss: (0.2151) |  Loss2: (0.0000) | Acc: (92.00%) (30891/33408)
Epoch: 101 | Batch_idx: 270 |  Loss: (0.2150) |  Loss2: (0.0000) | Acc: (92.00%) (32083/34688)
Epoch: 101 | Batch_idx: 280 |  Loss: (0.2156) |  Loss2: (0.0000) | Acc: (92.00%) (33265/35968)
Epoch: 101 | Batch_idx: 290 |  Loss: (0.2156) |  Loss2: (0.0000) | Acc: (92.00%) (34457/37248)
Epoch: 101 | Batch_idx: 300 |  Loss: (0.2160) |  Loss2: (0.0000) | Acc: (92.00%) (35637/38528)
Epoch: 101 | Batch_idx: 310 |  Loss: (0.2168) |  Loss2: (0.0000) | Acc: (92.00%) (36807/39808)
Epoch: 101 | Batch_idx: 320 |  Loss: (0.2161) |  Loss2: (0.0000) | Acc: (92.00%) (38014/41088)
Epoch: 101 | Batch_idx: 330 |  Loss: (0.2158) |  Loss2: (0.0000) | Acc: (92.00%) (39205/42368)
Epoch: 101 | Batch_idx: 340 |  Loss: (0.2167) |  Loss2: (0.0000) | Acc: (92.00%) (40373/43648)
Epoch: 101 | Batch_idx: 350 |  Loss: (0.2165) |  Loss2: (0.0000) | Acc: (92.00%) (41561/44928)
Epoch: 101 | Batch_idx: 360 |  Loss: (0.2157) |  Loss2: (0.0000) | Acc: (92.00%) (42757/46208)
Epoch: 101 | Batch_idx: 370 |  Loss: (0.2153) |  Loss2: (0.0000) | Acc: (92.00%) (43941/47488)
Epoch: 101 | Batch_idx: 380 |  Loss: (0.2157) |  Loss2: (0.0000) | Acc: (92.00%) (45123/48768)
Epoch: 101 | Batch_idx: 390 |  Loss: (0.2152) |  Loss2: (0.0000) | Acc: (92.00%) (46273/50000)
# TEST : Loss: (0.4241) | Acc: (86.00%) (8600/10000)
percent tensor([0.5999, 0.5905, 0.6102, 0.5929, 0.6152, 0.5967, 0.6024, 0.5934, 0.5981,
        0.5930, 0.5933, 0.6076, 0.5913, 0.5797, 0.5947, 0.5910],
       device='cuda:0') torch.Size([16])
percent tensor([0.5840, 0.5397, 0.5449, 0.6017, 0.5750, 0.6274, 0.5534, 0.5734, 0.5754,
        0.5493, 0.5674, 0.5381, 0.5394, 0.6071, 0.5754, 0.5897],
       device='cuda:0') torch.Size([16])
percent tensor([0.5211, 0.5647, 0.5172, 0.4814, 0.5201, 0.4855, 0.5665, 0.5406, 0.5141,
        0.5147, 0.5024, 0.5422, 0.5423, 0.5291, 0.5397, 0.5241],
       device='cuda:0') torch.Size([16])
percent tensor([0.6364, 0.5947, 0.6269, 0.6344, 0.6406, 0.6497, 0.6218, 0.6405, 0.6308,
        0.6142, 0.6219, 0.6144, 0.6107, 0.6275, 0.6285, 0.6451],
       device='cuda:0') torch.Size([16])
percent tensor([0.5593, 0.6545, 0.6341, 0.6502, 0.5927, 0.6758, 0.5965, 0.5031, 0.6975,
        0.5880, 0.6458, 0.6471, 0.6974, 0.7194, 0.5584, 0.6129],
       device='cuda:0') torch.Size([16])
percent tensor([0.6439, 0.5992, 0.7120, 0.7256, 0.7532, 0.7523, 0.6692, 0.6310, 0.7191,
        0.6389, 0.7015, 0.6519, 0.6126, 0.7859, 0.6054, 0.6698],
       device='cuda:0') torch.Size([16])
percent tensor([0.6656, 0.6218, 0.7179, 0.6479, 0.7785, 0.6909, 0.7039, 0.7037, 0.6431,
        0.6472, 0.6235, 0.6438, 0.5068, 0.6509, 0.6498, 0.6881],
       device='cuda:0') torch.Size([16])
percent tensor([0.9990, 0.9985, 0.9986, 0.9994, 0.9991, 0.9984, 0.9988, 0.9989, 0.9991,
        0.9993, 0.9992, 0.9992, 0.9989, 0.9991, 0.9986, 0.9988],
       device='cuda:0') torch.Size([16])
Epoch: 102 | Batch_idx: 0 |  Loss: (0.2497) |  Loss2: (0.0000) | Acc: (91.00%) (117/128)
Epoch: 102 | Batch_idx: 10 |  Loss: (0.2037) |  Loss2: (0.0000) | Acc: (93.00%) (1312/1408)
Epoch: 102 | Batch_idx: 20 |  Loss: (0.1975) |  Loss2: (0.0000) | Acc: (93.00%) (2505/2688)
Epoch: 102 | Batch_idx: 30 |  Loss: (0.1973) |  Loss2: (0.0000) | Acc: (93.00%) (3703/3968)
Epoch: 102 | Batch_idx: 40 |  Loss: (0.1981) |  Loss2: (0.0000) | Acc: (93.00%) (4893/5248)
Epoch: 102 | Batch_idx: 50 |  Loss: (0.1991) |  Loss2: (0.0000) | Acc: (93.00%) (6083/6528)
Epoch: 102 | Batch_idx: 60 |  Loss: (0.1980) |  Loss2: (0.0000) | Acc: (93.00%) (7272/7808)
Epoch: 102 | Batch_idx: 70 |  Loss: (0.1999) |  Loss2: (0.0000) | Acc: (92.00%) (8448/9088)
Epoch: 102 | Batch_idx: 80 |  Loss: (0.2039) |  Loss2: (0.0000) | Acc: (92.00%) (9617/10368)
Epoch: 102 | Batch_idx: 90 |  Loss: (0.2049) |  Loss2: (0.0000) | Acc: (92.00%) (10793/11648)
Epoch: 102 | Batch_idx: 100 |  Loss: (0.2034) |  Loss2: (0.0000) | Acc: (92.00%) (11983/12928)
Epoch: 102 | Batch_idx: 110 |  Loss: (0.2057) |  Loss2: (0.0000) | Acc: (92.00%) (13163/14208)
Epoch: 102 | Batch_idx: 120 |  Loss: (0.2038) |  Loss2: (0.0000) | Acc: (92.00%) (14360/15488)
Epoch: 102 | Batch_idx: 130 |  Loss: (0.2051) |  Loss2: (0.0000) | Acc: (92.00%) (15530/16768)
Epoch: 102 | Batch_idx: 140 |  Loss: (0.2036) |  Loss2: (0.0000) | Acc: (92.00%) (16729/18048)
Epoch: 102 | Batch_idx: 150 |  Loss: (0.2059) |  Loss2: (0.0000) | Acc: (92.00%) (17905/19328)
Epoch: 102 | Batch_idx: 160 |  Loss: (0.2041) |  Loss2: (0.0000) | Acc: (92.00%) (19108/20608)
Epoch: 102 | Batch_idx: 170 |  Loss: (0.2042) |  Loss2: (0.0000) | Acc: (92.00%) (20299/21888)
Epoch: 102 | Batch_idx: 180 |  Loss: (0.2045) |  Loss2: (0.0000) | Acc: (92.00%) (21481/23168)
Epoch: 102 | Batch_idx: 190 |  Loss: (0.2057) |  Loss2: (0.0000) | Acc: (92.00%) (22655/24448)
Epoch: 102 | Batch_idx: 200 |  Loss: (0.2065) |  Loss2: (0.0000) | Acc: (92.00%) (23831/25728)
Epoch: 102 | Batch_idx: 210 |  Loss: (0.2074) |  Loss2: (0.0000) | Acc: (92.00%) (25009/27008)
Epoch: 102 | Batch_idx: 220 |  Loss: (0.2069) |  Loss2: (0.0000) | Acc: (92.00%) (26219/28288)
Epoch: 102 | Batch_idx: 230 |  Loss: (0.2060) |  Loss2: (0.0000) | Acc: (92.00%) (27413/29568)
Epoch: 102 | Batch_idx: 240 |  Loss: (0.2065) |  Loss2: (0.0000) | Acc: (92.00%) (28595/30848)
Epoch: 102 | Batch_idx: 250 |  Loss: (0.2068) |  Loss2: (0.0000) | Acc: (92.00%) (29773/32128)
Epoch: 102 | Batch_idx: 260 |  Loss: (0.2063) |  Loss2: (0.0000) | Acc: (92.00%) (30962/33408)
Epoch: 102 | Batch_idx: 270 |  Loss: (0.2051) |  Loss2: (0.0000) | Acc: (92.00%) (32164/34688)
Epoch: 102 | Batch_idx: 280 |  Loss: (0.2049) |  Loss2: (0.0000) | Acc: (92.00%) (33357/35968)
Epoch: 102 | Batch_idx: 290 |  Loss: (0.2056) |  Loss2: (0.0000) | Acc: (92.00%) (34540/37248)
Epoch: 102 | Batch_idx: 300 |  Loss: (0.2060) |  Loss2: (0.0000) | Acc: (92.00%) (35729/38528)
Epoch: 102 | Batch_idx: 310 |  Loss: (0.2055) |  Loss2: (0.0000) | Acc: (92.00%) (36932/39808)
Epoch: 102 | Batch_idx: 320 |  Loss: (0.2060) |  Loss2: (0.0000) | Acc: (92.00%) (38124/41088)
Epoch: 102 | Batch_idx: 330 |  Loss: (0.2071) |  Loss2: (0.0000) | Acc: (92.00%) (39294/42368)
Epoch: 102 | Batch_idx: 340 |  Loss: (0.2072) |  Loss2: (0.0000) | Acc: (92.00%) (40482/43648)
Epoch: 102 | Batch_idx: 350 |  Loss: (0.2075) |  Loss2: (0.0000) | Acc: (92.00%) (41670/44928)
Epoch: 102 | Batch_idx: 360 |  Loss: (0.2073) |  Loss2: (0.0000) | Acc: (92.00%) (42855/46208)
Epoch: 102 | Batch_idx: 370 |  Loss: (0.2075) |  Loss2: (0.0000) | Acc: (92.00%) (44045/47488)
Epoch: 102 | Batch_idx: 380 |  Loss: (0.2080) |  Loss2: (0.0000) | Acc: (92.00%) (45233/48768)
Epoch: 102 | Batch_idx: 390 |  Loss: (0.2083) |  Loss2: (0.0000) | Acc: (92.00%) (46373/50000)
# TEST : Loss: (0.4155) | Acc: (86.00%) (8689/10000)
percent tensor([0.5985, 0.5905, 0.6075, 0.5928, 0.6124, 0.5981, 0.6013, 0.5933, 0.5967,
        0.5918, 0.5923, 0.6042, 0.5894, 0.5827, 0.5949, 0.5910],
       device='cuda:0') torch.Size([16])
percent tensor([0.5811, 0.5405, 0.5374, 0.5951, 0.5664, 0.6231, 0.5533, 0.5645, 0.5758,
        0.5471, 0.5677, 0.5333, 0.5385, 0.6098, 0.5715, 0.5876],
       device='cuda:0') torch.Size([16])
percent tensor([0.5226, 0.5559, 0.5190, 0.4796, 0.5202, 0.4805, 0.5616, 0.5351, 0.5117,
        0.5065, 0.4980, 0.5391, 0.5423, 0.5216, 0.5337, 0.5186],
       device='cuda:0') torch.Size([16])
percent tensor([0.6362, 0.5946, 0.6263, 0.6331, 0.6380, 0.6485, 0.6228, 0.6350, 0.6312,
        0.6165, 0.6233, 0.6150, 0.6105, 0.6286, 0.6248, 0.6460],
       device='cuda:0') torch.Size([16])
percent tensor([0.5667, 0.6698, 0.6346, 0.6479, 0.5936, 0.6636, 0.6140, 0.5307, 0.7076,
        0.5908, 0.6639, 0.6704, 0.7158, 0.7430, 0.5698, 0.6113],
       device='cuda:0') torch.Size([16])
percent tensor([0.6331, 0.6411, 0.7076, 0.7088, 0.7382, 0.7374, 0.6868, 0.6150, 0.7217,
        0.6548, 0.7073, 0.6683, 0.6266, 0.7987, 0.5914, 0.6730],
       device='cuda:0') torch.Size([16])
percent tensor([0.6625, 0.6023, 0.7174, 0.6491, 0.7698, 0.6865, 0.7139, 0.7113, 0.6378,
        0.6433, 0.6256, 0.6502, 0.5032, 0.6338, 0.6496, 0.7024],
       device='cuda:0') torch.Size([16])
percent tensor([0.9993, 0.9984, 0.9989, 0.9993, 0.9989, 0.9989, 0.9992, 0.9987, 0.9992,
        0.9993, 0.9992, 0.9993, 0.9991, 0.9992, 0.9986, 0.9992],
       device='cuda:0') torch.Size([16])
Epoch: 103 | Batch_idx: 0 |  Loss: (0.1753) |  Loss2: (0.0000) | Acc: (92.00%) (119/128)
Epoch: 103 | Batch_idx: 10 |  Loss: (0.1730) |  Loss2: (0.0000) | Acc: (93.00%) (1321/1408)
Epoch: 103 | Batch_idx: 20 |  Loss: (0.1922) |  Loss2: (0.0000) | Acc: (93.00%) (2501/2688)
Epoch: 103 | Batch_idx: 30 |  Loss: (0.1943) |  Loss2: (0.0000) | Acc: (93.00%) (3698/3968)
Epoch: 103 | Batch_idx: 40 |  Loss: (0.2012) |  Loss2: (0.0000) | Acc: (92.00%) (4873/5248)
Epoch: 103 | Batch_idx: 50 |  Loss: (0.2015) |  Loss2: (0.0000) | Acc: (92.00%) (6063/6528)
Epoch: 103 | Batch_idx: 60 |  Loss: (0.1990) |  Loss2: (0.0000) | Acc: (92.00%) (7254/7808)
Epoch: 103 | Batch_idx: 70 |  Loss: (0.2000) |  Loss2: (0.0000) | Acc: (92.00%) (8440/9088)
Epoch: 103 | Batch_idx: 80 |  Loss: (0.1971) |  Loss2: (0.0000) | Acc: (93.00%) (9645/10368)
Epoch: 103 | Batch_idx: 90 |  Loss: (0.2012) |  Loss2: (0.0000) | Acc: (92.00%) (10826/11648)
Epoch: 103 | Batch_idx: 100 |  Loss: (0.2022) |  Loss2: (0.0000) | Acc: (92.00%) (12001/12928)
Epoch: 103 | Batch_idx: 110 |  Loss: (0.2008) |  Loss2: (0.0000) | Acc: (92.00%) (13204/14208)
Epoch: 103 | Batch_idx: 120 |  Loss: (0.2005) |  Loss2: (0.0000) | Acc: (92.00%) (14399/15488)
Epoch: 103 | Batch_idx: 130 |  Loss: (0.2000) |  Loss2: (0.0000) | Acc: (93.00%) (15596/16768)
Epoch: 103 | Batch_idx: 140 |  Loss: (0.1997) |  Loss2: (0.0000) | Acc: (93.00%) (16792/18048)
Epoch: 103 | Batch_idx: 150 |  Loss: (0.2009) |  Loss2: (0.0000) | Acc: (93.00%) (17984/19328)
Epoch: 103 | Batch_idx: 160 |  Loss: (0.1998) |  Loss2: (0.0000) | Acc: (93.00%) (19174/20608)
Epoch: 103 | Batch_idx: 170 |  Loss: (0.1987) |  Loss2: (0.0000) | Acc: (93.00%) (20373/21888)
Epoch: 103 | Batch_idx: 180 |  Loss: (0.1984) |  Loss2: (0.0000) | Acc: (93.00%) (21567/23168)
Epoch: 103 | Batch_idx: 190 |  Loss: (0.1983) |  Loss2: (0.0000) | Acc: (93.00%) (22753/24448)
Epoch: 103 | Batch_idx: 200 |  Loss: (0.1979) |  Loss2: (0.0000) | Acc: (93.00%) (23942/25728)
Epoch: 103 | Batch_idx: 210 |  Loss: (0.1985) |  Loss2: (0.0000) | Acc: (93.00%) (25123/27008)
Epoch: 103 | Batch_idx: 220 |  Loss: (0.1994) |  Loss2: (0.0000) | Acc: (93.00%) (26311/28288)
Epoch: 103 | Batch_idx: 230 |  Loss: (0.1995) |  Loss2: (0.0000) | Acc: (92.00%) (27493/29568)
Epoch: 103 | Batch_idx: 240 |  Loss: (0.1990) |  Loss2: (0.0000) | Acc: (93.00%) (28690/30848)
Epoch: 103 | Batch_idx: 250 |  Loss: (0.1987) |  Loss2: (0.0000) | Acc: (93.00%) (29887/32128)
Epoch: 103 | Batch_idx: 260 |  Loss: (0.1989) |  Loss2: (0.0000) | Acc: (93.00%) (31089/33408)
Epoch: 103 | Batch_idx: 270 |  Loss: (0.1993) |  Loss2: (0.0000) | Acc: (93.00%) (32278/34688)
Epoch: 103 | Batch_idx: 280 |  Loss: (0.2000) |  Loss2: (0.0000) | Acc: (93.00%) (33457/35968)
Epoch: 103 | Batch_idx: 290 |  Loss: (0.2006) |  Loss2: (0.0000) | Acc: (92.00%) (34629/37248)
Epoch: 103 | Batch_idx: 300 |  Loss: (0.2012) |  Loss2: (0.0000) | Acc: (92.00%) (35806/38528)
Epoch: 103 | Batch_idx: 310 |  Loss: (0.2012) |  Loss2: (0.0000) | Acc: (92.00%) (36996/39808)
Epoch: 103 | Batch_idx: 320 |  Loss: (0.2014) |  Loss2: (0.0000) | Acc: (92.00%) (38175/41088)
Epoch: 103 | Batch_idx: 330 |  Loss: (0.2018) |  Loss2: (0.0000) | Acc: (92.00%) (39360/42368)
Epoch: 103 | Batch_idx: 340 |  Loss: (0.2024) |  Loss2: (0.0000) | Acc: (92.00%) (40541/43648)
Epoch: 103 | Batch_idx: 350 |  Loss: (0.2023) |  Loss2: (0.0000) | Acc: (92.00%) (41732/44928)
Epoch: 103 | Batch_idx: 360 |  Loss: (0.2020) |  Loss2: (0.0000) | Acc: (92.00%) (42925/46208)
Epoch: 103 | Batch_idx: 370 |  Loss: (0.2028) |  Loss2: (0.0000) | Acc: (92.00%) (44102/47488)
Epoch: 103 | Batch_idx: 380 |  Loss: (0.2030) |  Loss2: (0.0000) | Acc: (92.00%) (45286/48768)
Epoch: 103 | Batch_idx: 390 |  Loss: (0.2029) |  Loss2: (0.0000) | Acc: (92.00%) (46432/50000)
# TEST : Loss: (0.3934) | Acc: (87.00%) (8733/10000)
percent tensor([0.6004, 0.5899, 0.6076, 0.5927, 0.6128, 0.5985, 0.6009, 0.5929, 0.5978,
        0.5921, 0.5940, 0.6052, 0.5917, 0.5787, 0.5951, 0.5916],
       device='cuda:0') torch.Size([16])
percent tensor([0.5856, 0.5380, 0.5451, 0.6029, 0.5743, 0.6314, 0.5526, 0.5734, 0.5724,
        0.5475, 0.5638, 0.5377, 0.5394, 0.6026, 0.5763, 0.5911],
       device='cuda:0') torch.Size([16])
percent tensor([0.5222, 0.5592, 0.5153, 0.4819, 0.5170, 0.4760, 0.5599, 0.5380, 0.5123,
        0.5098, 0.5025, 0.5362, 0.5422, 0.5235, 0.5322, 0.5246],
       device='cuda:0') torch.Size([16])
percent tensor([0.6352, 0.5936, 0.6235, 0.6348, 0.6375, 0.6467, 0.6224, 0.6362, 0.6295,
        0.6146, 0.6215, 0.6153, 0.6114, 0.6285, 0.6257, 0.6438],
       device='cuda:0') torch.Size([16])
percent tensor([0.5586, 0.6558, 0.6546, 0.6411, 0.5967, 0.6761, 0.6097, 0.4992, 0.6908,
        0.6012, 0.6536, 0.6706, 0.6922, 0.7082, 0.5731, 0.6011],
       device='cuda:0') torch.Size([16])
percent tensor([0.6389, 0.6260, 0.7013, 0.7108, 0.7395, 0.7557, 0.6759, 0.6207, 0.7134,
        0.6441, 0.6953, 0.6573, 0.6278, 0.7753, 0.6080, 0.6719],
       device='cuda:0') torch.Size([16])
percent tensor([0.6710, 0.6286, 0.7141, 0.6427, 0.7809, 0.6952, 0.6822, 0.7139, 0.6350,
        0.6458, 0.6213, 0.6256, 0.5254, 0.6605, 0.6407, 0.7007],
       device='cuda:0') torch.Size([16])
percent tensor([0.9990, 0.9987, 0.9987, 0.9991, 0.9993, 0.9980, 0.9987, 0.9989, 0.9988,
        0.9993, 0.9989, 0.9991, 0.9990, 0.9992, 0.9986, 0.9988],
       device='cuda:0') torch.Size([16])
Epoch: 104 | Batch_idx: 0 |  Loss: (0.1616) |  Loss2: (0.0000) | Acc: (93.00%) (120/128)
Epoch: 104 | Batch_idx: 10 |  Loss: (0.1902) |  Loss2: (0.0000) | Acc: (93.00%) (1313/1408)
Epoch: 104 | Batch_idx: 20 |  Loss: (0.1878) |  Loss2: (0.0000) | Acc: (93.00%) (2511/2688)
Epoch: 104 | Batch_idx: 30 |  Loss: (0.1881) |  Loss2: (0.0000) | Acc: (93.00%) (3706/3968)
Epoch: 104 | Batch_idx: 40 |  Loss: (0.1872) |  Loss2: (0.0000) | Acc: (93.00%) (4907/5248)
Epoch: 104 | Batch_idx: 50 |  Loss: (0.1934) |  Loss2: (0.0000) | Acc: (93.00%) (6091/6528)
Epoch: 104 | Batch_idx: 60 |  Loss: (0.1928) |  Loss2: (0.0000) | Acc: (93.00%) (7292/7808)
Epoch: 104 | Batch_idx: 70 |  Loss: (0.1915) |  Loss2: (0.0000) | Acc: (93.00%) (8485/9088)
Epoch: 104 | Batch_idx: 80 |  Loss: (0.1946) |  Loss2: (0.0000) | Acc: (93.00%) (9669/10368)
Epoch: 104 | Batch_idx: 90 |  Loss: (0.1933) |  Loss2: (0.0000) | Acc: (93.00%) (10866/11648)
Epoch: 104 | Batch_idx: 100 |  Loss: (0.1930) |  Loss2: (0.0000) | Acc: (93.00%) (12063/12928)
Epoch: 104 | Batch_idx: 110 |  Loss: (0.1914) |  Loss2: (0.0000) | Acc: (93.00%) (13267/14208)
Epoch: 104 | Batch_idx: 120 |  Loss: (0.1890) |  Loss2: (0.0000) | Acc: (93.00%) (14474/15488)
Epoch: 104 | Batch_idx: 130 |  Loss: (0.1904) |  Loss2: (0.0000) | Acc: (93.00%) (15659/16768)
Epoch: 104 | Batch_idx: 140 |  Loss: (0.1901) |  Loss2: (0.0000) | Acc: (93.00%) (16860/18048)
Epoch: 104 | Batch_idx: 150 |  Loss: (0.1892) |  Loss2: (0.0000) | Acc: (93.00%) (18059/19328)
Epoch: 104 | Batch_idx: 160 |  Loss: (0.1901) |  Loss2: (0.0000) | Acc: (93.00%) (19258/20608)
Epoch: 104 | Batch_idx: 170 |  Loss: (0.1897) |  Loss2: (0.0000) | Acc: (93.00%) (20462/21888)
Epoch: 104 | Batch_idx: 180 |  Loss: (0.1915) |  Loss2: (0.0000) | Acc: (93.00%) (21650/23168)
Epoch: 104 | Batch_idx: 190 |  Loss: (0.1928) |  Loss2: (0.0000) | Acc: (93.00%) (22830/24448)
Epoch: 104 | Batch_idx: 200 |  Loss: (0.1931) |  Loss2: (0.0000) | Acc: (93.00%) (24030/25728)
Epoch: 104 | Batch_idx: 210 |  Loss: (0.1920) |  Loss2: (0.0000) | Acc: (93.00%) (25227/27008)
Epoch: 104 | Batch_idx: 220 |  Loss: (0.1918) |  Loss2: (0.0000) | Acc: (93.00%) (26421/28288)
Epoch: 104 | Batch_idx: 230 |  Loss: (0.1925) |  Loss2: (0.0000) | Acc: (93.00%) (27614/29568)
Epoch: 104 | Batch_idx: 240 |  Loss: (0.1927) |  Loss2: (0.0000) | Acc: (93.00%) (28812/30848)
Epoch: 104 | Batch_idx: 250 |  Loss: (0.1935) |  Loss2: (0.0000) | Acc: (93.00%) (30000/32128)
Epoch: 104 | Batch_idx: 260 |  Loss: (0.1937) |  Loss2: (0.0000) | Acc: (93.00%) (31188/33408)
Epoch: 104 | Batch_idx: 270 |  Loss: (0.1936) |  Loss2: (0.0000) | Acc: (93.00%) (32383/34688)
Epoch: 104 | Batch_idx: 280 |  Loss: (0.1943) |  Loss2: (0.0000) | Acc: (93.00%) (33569/35968)
Epoch: 104 | Batch_idx: 290 |  Loss: (0.1939) |  Loss2: (0.0000) | Acc: (93.00%) (34759/37248)
Epoch: 104 | Batch_idx: 300 |  Loss: (0.1933) |  Loss2: (0.0000) | Acc: (93.00%) (35959/38528)
Epoch: 104 | Batch_idx: 310 |  Loss: (0.1940) |  Loss2: (0.0000) | Acc: (93.00%) (37144/39808)
Epoch: 104 | Batch_idx: 320 |  Loss: (0.1946) |  Loss2: (0.0000) | Acc: (93.00%) (38329/41088)
Epoch: 104 | Batch_idx: 330 |  Loss: (0.1950) |  Loss2: (0.0000) | Acc: (93.00%) (39517/42368)
Epoch: 104 | Batch_idx: 340 |  Loss: (0.1949) |  Loss2: (0.0000) | Acc: (93.00%) (40703/43648)
Epoch: 104 | Batch_idx: 350 |  Loss: (0.1950) |  Loss2: (0.0000) | Acc: (93.00%) (41898/44928)
Epoch: 104 | Batch_idx: 360 |  Loss: (0.1946) |  Loss2: (0.0000) | Acc: (93.00%) (43101/46208)
Epoch: 104 | Batch_idx: 370 |  Loss: (0.1950) |  Loss2: (0.0000) | Acc: (93.00%) (44285/47488)
Epoch: 104 | Batch_idx: 380 |  Loss: (0.1949) |  Loss2: (0.0000) | Acc: (93.00%) (45473/48768)
Epoch: 104 | Batch_idx: 390 |  Loss: (0.1949) |  Loss2: (0.0000) | Acc: (93.00%) (46622/50000)
# TEST : Loss: (0.3981) | Acc: (87.00%) (8752/10000)
percent tensor([0.5980, 0.5909, 0.6072, 0.5953, 0.6118, 0.5953, 0.6006, 0.5954, 0.5963,
        0.5927, 0.5918, 0.6046, 0.5900, 0.5824, 0.5946, 0.5912],
       device='cuda:0') torch.Size([16])
percent tensor([0.5823, 0.5426, 0.5353, 0.5954, 0.5641, 0.6258, 0.5524, 0.5672, 0.5736,
        0.5476, 0.5661, 0.5291, 0.5393, 0.6104, 0.5728, 0.5889],
       device='cuda:0') torch.Size([16])
percent tensor([0.5298, 0.5677, 0.5245, 0.4815, 0.5257, 0.4850, 0.5722, 0.5399, 0.5246,
        0.5197, 0.5176, 0.5448, 0.5533, 0.5321, 0.5394, 0.5284],
       device='cuda:0') torch.Size([16])
percent tensor([0.6347, 0.5952, 0.6217, 0.6293, 0.6356, 0.6478, 0.6238, 0.6360, 0.6286,
        0.6139, 0.6214, 0.6112, 0.6103, 0.6293, 0.6252, 0.6438],
       device='cuda:0') torch.Size([16])
percent tensor([0.5499, 0.6544, 0.6296, 0.6365, 0.5769, 0.6507, 0.5921, 0.4894, 0.6907,
        0.5829, 0.6530, 0.6514, 0.7040, 0.7240, 0.5540, 0.5951],
       device='cuda:0') torch.Size([16])
percent tensor([0.6285, 0.6100, 0.6969, 0.7051, 0.7355, 0.7328, 0.6666, 0.6265, 0.7091,
        0.6198, 0.6879, 0.6570, 0.6260, 0.7798, 0.5961, 0.6679],
       device='cuda:0') torch.Size([16])
percent tensor([0.6628, 0.6142, 0.7265, 0.6541, 0.7750, 0.6882, 0.6934, 0.7158, 0.6305,
        0.6452, 0.6044, 0.6563, 0.5115, 0.6332, 0.6418, 0.6911],
       device='cuda:0') torch.Size([16])
percent tensor([0.9992, 0.9987, 0.9990, 0.9995, 0.9993, 0.9985, 0.9987, 0.9992, 0.9990,
        0.9994, 0.9990, 0.9994, 0.9991, 0.9992, 0.9986, 0.9991],
       device='cuda:0') torch.Size([16])
False Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=128, out_features=16, bias=False)
True Linear(in_features=16, out_features=2, bias=False)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=128, out_features=16, bias=False)
True Linear(in_features=16, out_features=2, bias=False)
False Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=256, out_features=32, bias=False)
True Linear(in_features=32, out_features=2, bias=False)
False Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=256, out_features=32, bias=False)
True Linear(in_features=32, out_features=2, bias=False)
False Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=512, out_features=64, bias=False)
True Linear(in_features=64, out_features=2, bias=False)
False Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=512, out_features=64, bias=False)
True Linear(in_features=64, out_features=2, bias=False)
False Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1024, out_features=128, bias=False)
True Linear(in_features=128, out_features=2, bias=False)
False Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1024, out_features=128, bias=False)
True Linear(in_features=128, out_features=2, bias=False)
False Linear(in_features=512, out_features=10, bias=True)
Epoch: 105 | Batch_idx: 0 |  Loss: (0.2244) |  Loss2: (0.0000) | Acc: (92.00%) (118/128)
Epoch: 105 | Batch_idx: 10 |  Loss: (0.1958) |  Loss2: (0.0000) | Acc: (93.00%) (1316/1408)
Epoch: 105 | Batch_idx: 20 |  Loss: (0.1944) |  Loss2: (0.0000) | Acc: (93.00%) (2503/2688)
Epoch: 105 | Batch_idx: 30 |  Loss: (0.2093) |  Loss2: (0.0000) | Acc: (92.00%) (3670/3968)
Epoch: 105 | Batch_idx: 40 |  Loss: (0.2103) |  Loss2: (0.0000) | Acc: (92.00%) (4848/5248)
Epoch: 105 | Batch_idx: 50 |  Loss: (0.2179) |  Loss2: (0.0000) | Acc: (92.00%) (6021/6528)
Epoch: 105 | Batch_idx: 60 |  Loss: (0.2197) |  Loss2: (0.0000) | Acc: (92.00%) (7196/7808)
Epoch: 105 | Batch_idx: 70 |  Loss: (0.2232) |  Loss2: (0.0000) | Acc: (92.00%) (8364/9088)
Epoch: 105 | Batch_idx: 80 |  Loss: (0.2231) |  Loss2: (0.0000) | Acc: (91.00%) (9533/10368)
Epoch: 105 | Batch_idx: 90 |  Loss: (0.2223) |  Loss2: (0.0000) | Acc: (91.00%) (10714/11648)
Epoch: 105 | Batch_idx: 100 |  Loss: (0.2218) |  Loss2: (0.0000) | Acc: (92.00%) (11899/12928)
Epoch: 105 | Batch_idx: 110 |  Loss: (0.2236) |  Loss2: (0.0000) | Acc: (91.00%) (13069/14208)
Epoch: 105 | Batch_idx: 120 |  Loss: (0.2223) |  Loss2: (0.0000) | Acc: (92.00%) (14252/15488)
Epoch: 105 | Batch_idx: 130 |  Loss: (0.2209) |  Loss2: (0.0000) | Acc: (92.00%) (15447/16768)
Epoch: 105 | Batch_idx: 140 |  Loss: (0.2211) |  Loss2: (0.0000) | Acc: (92.00%) (16633/18048)
Epoch: 105 | Batch_idx: 150 |  Loss: (0.2197) |  Loss2: (0.0000) | Acc: (92.00%) (17829/19328)
Epoch: 105 | Batch_idx: 160 |  Loss: (0.2219) |  Loss2: (0.0000) | Acc: (92.00%) (18994/20608)
Epoch: 105 | Batch_idx: 170 |  Loss: (0.2225) |  Loss2: (0.0000) | Acc: (92.00%) (20167/21888)
Epoch: 105 | Batch_idx: 180 |  Loss: (0.2213) |  Loss2: (0.0000) | Acc: (92.00%) (21362/23168)
Epoch: 105 | Batch_idx: 190 |  Loss: (0.2210) |  Loss2: (0.0000) | Acc: (92.00%) (22540/24448)
Epoch: 105 | Batch_idx: 200 |  Loss: (0.2203) |  Loss2: (0.0000) | Acc: (92.00%) (23726/25728)
Epoch: 105 | Batch_idx: 210 |  Loss: (0.2198) |  Loss2: (0.0000) | Acc: (92.00%) (24903/27008)
Epoch: 105 | Batch_idx: 220 |  Loss: (0.2198) |  Loss2: (0.0000) | Acc: (92.00%) (26083/28288)
Epoch: 105 | Batch_idx: 230 |  Loss: (0.2191) |  Loss2: (0.0000) | Acc: (92.00%) (27271/29568)
Epoch: 105 | Batch_idx: 240 |  Loss: (0.2192) |  Loss2: (0.0000) | Acc: (92.00%) (28463/30848)
Epoch: 105 | Batch_idx: 250 |  Loss: (0.2193) |  Loss2: (0.0000) | Acc: (92.00%) (29638/32128)
Epoch: 105 | Batch_idx: 260 |  Loss: (0.2189) |  Loss2: (0.0000) | Acc: (92.00%) (30830/33408)
Epoch: 105 | Batch_idx: 270 |  Loss: (0.2195) |  Loss2: (0.0000) | Acc: (92.00%) (32009/34688)
Epoch: 105 | Batch_idx: 280 |  Loss: (0.2187) |  Loss2: (0.0000) | Acc: (92.00%) (33206/35968)
Epoch: 105 | Batch_idx: 290 |  Loss: (0.2185) |  Loss2: (0.0000) | Acc: (92.00%) (34393/37248)
Epoch: 105 | Batch_idx: 300 |  Loss: (0.2192) |  Loss2: (0.0000) | Acc: (92.00%) (35565/38528)
Epoch: 105 | Batch_idx: 310 |  Loss: (0.2190) |  Loss2: (0.0000) | Acc: (92.00%) (36752/39808)
Epoch: 105 | Batch_idx: 320 |  Loss: (0.2192) |  Loss2: (0.0000) | Acc: (92.00%) (37933/41088)
Epoch: 105 | Batch_idx: 330 |  Loss: (0.2188) |  Loss2: (0.0000) | Acc: (92.00%) (39119/42368)
Epoch: 105 | Batch_idx: 340 |  Loss: (0.2179) |  Loss2: (0.0000) | Acc: (92.00%) (40316/43648)
Epoch: 105 | Batch_idx: 350 |  Loss: (0.2174) |  Loss2: (0.0000) | Acc: (92.00%) (41506/44928)
Epoch: 105 | Batch_idx: 360 |  Loss: (0.2173) |  Loss2: (0.0000) | Acc: (92.00%) (42681/46208)
Epoch: 105 | Batch_idx: 370 |  Loss: (0.2170) |  Loss2: (0.0000) | Acc: (92.00%) (43871/47488)
Epoch: 105 | Batch_idx: 380 |  Loss: (0.2183) |  Loss2: (0.0000) | Acc: (92.00%) (45028/48768)
Epoch: 105 | Batch_idx: 390 |  Loss: (0.2183) |  Loss2: (0.0000) | Acc: (92.00%) (46163/50000)
=> saving checkpoint 'drive/app/torch/save_Routing_Gate_2/checkpoint_105.pth.tar'
# TEST : Loss: (0.4060) | Acc: (87.00%) (8720/10000)
percent tensor([0.5992, 0.5955, 0.6042, 0.5946, 0.6105, 0.5954, 0.6025, 0.5971, 0.5987,
        0.5952, 0.5956, 0.6027, 0.5928, 0.5878, 0.5970, 0.5931],
       device='cuda:0') torch.Size([16])
percent tensor([0.5555, 0.5162, 0.5089, 0.5686, 0.5385, 0.5994, 0.5255, 0.5420, 0.5435,
        0.5203, 0.5364, 0.5026, 0.5147, 0.5751, 0.5477, 0.5625],
       device='cuda:0') torch.Size([16])
percent tensor([0.5214, 0.5715, 0.5178, 0.4690, 0.5176, 0.4737, 0.5705, 0.5338, 0.5148,
        0.5171, 0.5156, 0.5438, 0.5553, 0.5218, 0.5416, 0.5213],
       device='cuda:0') torch.Size([16])
percent tensor([0.6389, 0.6022, 0.6205, 0.6325, 0.6347, 0.6514, 0.6287, 0.6382, 0.6311,
        0.6185, 0.6264, 0.6125, 0.6182, 0.6320, 0.6317, 0.6490],
       device='cuda:0') torch.Size([16])
percent tensor([0.5547, 0.6565, 0.6431, 0.6291, 0.5788, 0.6596, 0.5801, 0.4803, 0.6989,
        0.5922, 0.6620, 0.6564, 0.7123, 0.7344, 0.5394, 0.6038],
       device='cuda:0') torch.Size([16])
percent tensor([0.6878, 0.6687, 0.7393, 0.7489, 0.7778, 0.7717, 0.7209, 0.6828, 0.7565,
        0.6922, 0.7419, 0.7112, 0.6882, 0.8136, 0.6557, 0.7216],
       device='cuda:0') torch.Size([16])
percent tensor([0.6365, 0.6072, 0.7184, 0.6405, 0.7645, 0.6756, 0.6711, 0.6920, 0.6073,
        0.6316, 0.5927, 0.6264, 0.5030, 0.6007, 0.6154, 0.6681],
       device='cuda:0') torch.Size([16])
percent tensor([0.9992, 0.9988, 0.9988, 0.9994, 0.9993, 0.9986, 0.9987, 0.9991, 0.9990,
        0.9995, 0.9990, 0.9992, 0.9991, 0.9991, 0.9986, 0.9991],
       device='cuda:0') torch.Size([16])
Epoch: 106 | Batch_idx: 0 |  Loss: (0.2189) |  Loss2: (0.0000) | Acc: (90.00%) (116/128)
Epoch: 106 | Batch_idx: 10 |  Loss: (0.2278) |  Loss2: (0.0000) | Acc: (91.00%) (1294/1408)
Epoch: 106 | Batch_idx: 20 |  Loss: (0.2160) |  Loss2: (0.0000) | Acc: (92.00%) (2483/2688)
Epoch: 106 | Batch_idx: 30 |  Loss: (0.2058) |  Loss2: (0.0000) | Acc: (92.00%) (3681/3968)
Epoch: 106 | Batch_idx: 40 |  Loss: (0.2118) |  Loss2: (0.0000) | Acc: (92.00%) (4854/5248)
Epoch: 106 | Batch_idx: 50 |  Loss: (0.2124) |  Loss2: (0.0000) | Acc: (92.00%) (6038/6528)
Epoch: 106 | Batch_idx: 60 |  Loss: (0.2117) |  Loss2: (0.0000) | Acc: (92.00%) (7227/7808)
Epoch: 106 | Batch_idx: 70 |  Loss: (0.2088) |  Loss2: (0.0000) | Acc: (92.00%) (8420/9088)
Epoch: 106 | Batch_idx: 80 |  Loss: (0.2087) |  Loss2: (0.0000) | Acc: (92.00%) (9604/10368)
Epoch: 106 | Batch_idx: 90 |  Loss: (0.2062) |  Loss2: (0.0000) | Acc: (92.00%) (10800/11648)
Epoch: 106 | Batch_idx: 100 |  Loss: (0.2081) |  Loss2: (0.0000) | Acc: (92.00%) (11981/12928)
Epoch: 106 | Batch_idx: 110 |  Loss: (0.2060) |  Loss2: (0.0000) | Acc: (92.00%) (13178/14208)
Epoch: 106 | Batch_idx: 120 |  Loss: (0.2076) |  Loss2: (0.0000) | Acc: (92.00%) (14356/15488)
Epoch: 106 | Batch_idx: 130 |  Loss: (0.2063) |  Loss2: (0.0000) | Acc: (92.00%) (15547/16768)
Epoch: 106 | Batch_idx: 140 |  Loss: (0.2051) |  Loss2: (0.0000) | Acc: (92.00%) (16737/18048)
Epoch: 106 | Batch_idx: 150 |  Loss: (0.2039) |  Loss2: (0.0000) | Acc: (92.00%) (17935/19328)
Epoch: 106 | Batch_idx: 160 |  Loss: (0.2018) |  Loss2: (0.0000) | Acc: (92.00%) (19138/20608)
Epoch: 106 | Batch_idx: 170 |  Loss: (0.2016) |  Loss2: (0.0000) | Acc: (92.00%) (20334/21888)
Epoch: 106 | Batch_idx: 180 |  Loss: (0.2013) |  Loss2: (0.0000) | Acc: (92.00%) (21526/23168)
Epoch: 106 | Batch_idx: 190 |  Loss: (0.2000) |  Loss2: (0.0000) | Acc: (92.00%) (22724/24448)
Epoch: 106 | Batch_idx: 200 |  Loss: (0.2005) |  Loss2: (0.0000) | Acc: (92.00%) (23912/25728)
Epoch: 106 | Batch_idx: 210 |  Loss: (0.2008) |  Loss2: (0.0000) | Acc: (92.00%) (25100/27008)
Epoch: 106 | Batch_idx: 220 |  Loss: (0.2014) |  Loss2: (0.0000) | Acc: (92.00%) (26291/28288)
Epoch: 106 | Batch_idx: 230 |  Loss: (0.2008) |  Loss2: (0.0000) | Acc: (92.00%) (27484/29568)
Epoch: 106 | Batch_idx: 240 |  Loss: (0.2003) |  Loss2: (0.0000) | Acc: (92.00%) (28681/30848)
Epoch: 106 | Batch_idx: 250 |  Loss: (0.2001) |  Loss2: (0.0000) | Acc: (93.00%) (29881/32128)
Epoch: 106 | Batch_idx: 260 |  Loss: (0.2000) |  Loss2: (0.0000) | Acc: (93.00%) (31070/33408)
Epoch: 106 | Batch_idx: 270 |  Loss: (0.1994) |  Loss2: (0.0000) | Acc: (93.00%) (32260/34688)
Epoch: 106 | Batch_idx: 280 |  Loss: (0.1992) |  Loss2: (0.0000) | Acc: (93.00%) (33455/35968)
Epoch: 106 | Batch_idx: 290 |  Loss: (0.1991) |  Loss2: (0.0000) | Acc: (93.00%) (34646/37248)
Epoch: 106 | Batch_idx: 300 |  Loss: (0.1979) |  Loss2: (0.0000) | Acc: (93.00%) (35857/38528)
Epoch: 106 | Batch_idx: 310 |  Loss: (0.1977) |  Loss2: (0.0000) | Acc: (93.00%) (37052/39808)
Epoch: 106 | Batch_idx: 320 |  Loss: (0.1985) |  Loss2: (0.0000) | Acc: (93.00%) (38233/41088)
Epoch: 106 | Batch_idx: 330 |  Loss: (0.1988) |  Loss2: (0.0000) | Acc: (93.00%) (39418/42368)
Epoch: 106 | Batch_idx: 340 |  Loss: (0.1987) |  Loss2: (0.0000) | Acc: (93.00%) (40624/43648)
Epoch: 106 | Batch_idx: 350 |  Loss: (0.1993) |  Loss2: (0.0000) | Acc: (93.00%) (41800/44928)
Epoch: 106 | Batch_idx: 360 |  Loss: (0.1999) |  Loss2: (0.0000) | Acc: (93.00%) (42974/46208)
Epoch: 106 | Batch_idx: 370 |  Loss: (0.2002) |  Loss2: (0.0000) | Acc: (93.00%) (44166/47488)
Epoch: 106 | Batch_idx: 380 |  Loss: (0.1997) |  Loss2: (0.0000) | Acc: (93.00%) (45373/48768)
Epoch: 106 | Batch_idx: 390 |  Loss: (0.2001) |  Loss2: (0.0000) | Acc: (93.00%) (46511/50000)
# TEST : Loss: (0.3969) | Acc: (87.00%) (8753/10000)
percent tensor([0.5983, 0.5953, 0.6025, 0.5933, 0.6092, 0.5944, 0.6019, 0.5962, 0.5987,
        0.5947, 0.5953, 0.6018, 0.5922, 0.5885, 0.5964, 0.5924],
       device='cuda:0') torch.Size([16])
percent tensor([0.5544, 0.5169, 0.5088, 0.5651, 0.5382, 0.5952, 0.5260, 0.5413, 0.5436,
        0.5198, 0.5358, 0.5030, 0.5152, 0.5737, 0.5463, 0.5597],
       device='cuda:0') torch.Size([16])
percent tensor([0.5244, 0.5730, 0.5210, 0.4709, 0.5198, 0.4777, 0.5723, 0.5361, 0.5169,
        0.5195, 0.5180, 0.5476, 0.5599, 0.5205, 0.5454, 0.5246],
       device='cuda:0') torch.Size([16])
percent tensor([0.6395, 0.6030, 0.6201, 0.6305, 0.6343, 0.6515, 0.6291, 0.6374, 0.6311,
        0.6177, 0.6271, 0.6127, 0.6199, 0.6313, 0.6327, 0.6484],
       device='cuda:0') torch.Size([16])
percent tensor([0.5709, 0.6670, 0.6558, 0.6454, 0.5933, 0.6766, 0.5845, 0.4930, 0.7078,
        0.6075, 0.6734, 0.6668, 0.7257, 0.7382, 0.5472, 0.6240],
       device='cuda:0') torch.Size([16])
percent tensor([0.6948, 0.6723, 0.7480, 0.7542, 0.7835, 0.7809, 0.7248, 0.6865, 0.7627,
        0.6989, 0.7501, 0.7189, 0.6969, 0.8191, 0.6602, 0.7283],
       device='cuda:0') torch.Size([16])
percent tensor([0.6385, 0.6065, 0.7291, 0.6482, 0.7684, 0.6906, 0.6741, 0.6870, 0.6180,
        0.6297, 0.6022, 0.6345, 0.5081, 0.6104, 0.6113, 0.6623],
       device='cuda:0') torch.Size([16])
percent tensor([0.9992, 0.9987, 0.9989, 0.9994, 0.9993, 0.9987, 0.9987, 0.9991, 0.9991,
        0.9995, 0.9991, 0.9992, 0.9992, 0.9991, 0.9986, 0.9991],
       device='cuda:0') torch.Size([16])
Epoch: 107 | Batch_idx: 0 |  Loss: (0.1980) |  Loss2: (0.0000) | Acc: (93.00%) (120/128)
Epoch: 107 | Batch_idx: 10 |  Loss: (0.1908) |  Loss2: (0.0000) | Acc: (93.00%) (1316/1408)
Epoch: 107 | Batch_idx: 20 |  Loss: (0.2013) |  Loss2: (0.0000) | Acc: (92.00%) (2497/2688)
Epoch: 107 | Batch_idx: 30 |  Loss: (0.2033) |  Loss2: (0.0000) | Acc: (92.00%) (3677/3968)
Epoch: 107 | Batch_idx: 40 |  Loss: (0.2040) |  Loss2: (0.0000) | Acc: (92.00%) (4873/5248)
Epoch: 107 | Batch_idx: 50 |  Loss: (0.2028) |  Loss2: (0.0000) | Acc: (92.00%) (6066/6528)
Epoch: 107 | Batch_idx: 60 |  Loss: (0.2058) |  Loss2: (0.0000) | Acc: (92.00%) (7248/7808)
Epoch: 107 | Batch_idx: 70 |  Loss: (0.2044) |  Loss2: (0.0000) | Acc: (92.00%) (8440/9088)
Epoch: 107 | Batch_idx: 80 |  Loss: (0.2005) |  Loss2: (0.0000) | Acc: (92.00%) (9636/10368)
Epoch: 107 | Batch_idx: 90 |  Loss: (0.2022) |  Loss2: (0.0000) | Acc: (92.00%) (10815/11648)
Epoch: 107 | Batch_idx: 100 |  Loss: (0.2029) |  Loss2: (0.0000) | Acc: (92.00%) (12008/12928)
Epoch: 107 | Batch_idx: 110 |  Loss: (0.1993) |  Loss2: (0.0000) | Acc: (93.00%) (13214/14208)
Epoch: 107 | Batch_idx: 120 |  Loss: (0.1995) |  Loss2: (0.0000) | Acc: (92.00%) (14403/15488)
Epoch: 107 | Batch_idx: 130 |  Loss: (0.1996) |  Loss2: (0.0000) | Acc: (92.00%) (15591/16768)
Epoch: 107 | Batch_idx: 140 |  Loss: (0.1996) |  Loss2: (0.0000) | Acc: (92.00%) (16783/18048)
Epoch: 107 | Batch_idx: 150 |  Loss: (0.2016) |  Loss2: (0.0000) | Acc: (92.00%) (17960/19328)
Epoch: 107 | Batch_idx: 160 |  Loss: (0.2014) |  Loss2: (0.0000) | Acc: (92.00%) (19154/20608)
Epoch: 107 | Batch_idx: 170 |  Loss: (0.2007) |  Loss2: (0.0000) | Acc: (92.00%) (20346/21888)
Epoch: 107 | Batch_idx: 180 |  Loss: (0.1985) |  Loss2: (0.0000) | Acc: (93.00%) (21559/23168)
Epoch: 107 | Batch_idx: 190 |  Loss: (0.1971) |  Loss2: (0.0000) | Acc: (93.00%) (22768/24448)
Epoch: 107 | Batch_idx: 200 |  Loss: (0.1952) |  Loss2: (0.0000) | Acc: (93.00%) (23979/25728)
Epoch: 107 | Batch_idx: 210 |  Loss: (0.1960) |  Loss2: (0.0000) | Acc: (93.00%) (25157/27008)
Epoch: 107 | Batch_idx: 220 |  Loss: (0.1957) |  Loss2: (0.0000) | Acc: (93.00%) (26352/28288)
Epoch: 107 | Batch_idx: 230 |  Loss: (0.1957) |  Loss2: (0.0000) | Acc: (93.00%) (27550/29568)
Epoch: 107 | Batch_idx: 240 |  Loss: (0.1960) |  Loss2: (0.0000) | Acc: (93.00%) (28737/30848)
Epoch: 107 | Batch_idx: 250 |  Loss: (0.1961) |  Loss2: (0.0000) | Acc: (93.00%) (29935/32128)
Epoch: 107 | Batch_idx: 260 |  Loss: (0.1954) |  Loss2: (0.0000) | Acc: (93.00%) (31142/33408)
Epoch: 107 | Batch_idx: 270 |  Loss: (0.1957) |  Loss2: (0.0000) | Acc: (93.00%) (32327/34688)
Epoch: 107 | Batch_idx: 280 |  Loss: (0.1957) |  Loss2: (0.0000) | Acc: (93.00%) (33512/35968)
Epoch: 107 | Batch_idx: 290 |  Loss: (0.1953) |  Loss2: (0.0000) | Acc: (93.00%) (34728/37248)
Epoch: 107 | Batch_idx: 300 |  Loss: (0.1959) |  Loss2: (0.0000) | Acc: (93.00%) (35915/38528)
Epoch: 107 | Batch_idx: 310 |  Loss: (0.1952) |  Loss2: (0.0000) | Acc: (93.00%) (37120/39808)
Epoch: 107 | Batch_idx: 320 |  Loss: (0.1958) |  Loss2: (0.0000) | Acc: (93.00%) (38306/41088)
Epoch: 107 | Batch_idx: 330 |  Loss: (0.1955) |  Loss2: (0.0000) | Acc: (93.00%) (39495/42368)
Epoch: 107 | Batch_idx: 340 |  Loss: (0.1956) |  Loss2: (0.0000) | Acc: (93.00%) (40688/43648)
Epoch: 107 | Batch_idx: 350 |  Loss: (0.1953) |  Loss2: (0.0000) | Acc: (93.00%) (41891/44928)
Epoch: 107 | Batch_idx: 360 |  Loss: (0.1952) |  Loss2: (0.0000) | Acc: (93.00%) (43085/46208)
Epoch: 107 | Batch_idx: 370 |  Loss: (0.1946) |  Loss2: (0.0000) | Acc: (93.00%) (44291/47488)
Epoch: 107 | Batch_idx: 380 |  Loss: (0.1942) |  Loss2: (0.0000) | Acc: (93.00%) (45498/48768)
Epoch: 107 | Batch_idx: 390 |  Loss: (0.1941) |  Loss2: (0.0000) | Acc: (93.00%) (46646/50000)
# TEST : Loss: (0.3882) | Acc: (87.00%) (8780/10000)
percent tensor([0.5986, 0.5954, 0.6025, 0.5932, 0.6095, 0.5946, 0.6022, 0.5963, 0.5991,
        0.5948, 0.5955, 0.6020, 0.5924, 0.5888, 0.5966, 0.5925],
       device='cuda:0') torch.Size([16])
percent tensor([0.5610, 0.5239, 0.5159, 0.5719, 0.5463, 0.6003, 0.5336, 0.5491, 0.5514,
        0.5270, 0.5430, 0.5106, 0.5222, 0.5807, 0.5529, 0.5658],
       device='cuda:0') torch.Size([16])
percent tensor([0.5274, 0.5740, 0.5242, 0.4739, 0.5229, 0.4813, 0.5741, 0.5393, 0.5199,
        0.5216, 0.5200, 0.5498, 0.5623, 0.5221, 0.5477, 0.5274],
       device='cuda:0') torch.Size([16])
percent tensor([0.6376, 0.6012, 0.6185, 0.6277, 0.6324, 0.6499, 0.6278, 0.6356, 0.6291,
        0.6148, 0.6253, 0.6112, 0.6186, 0.6286, 0.6317, 0.6458],
       device='cuda:0') torch.Size([16])
percent tensor([0.5740, 0.6738, 0.6522, 0.6423, 0.5911, 0.6745, 0.5841, 0.4889, 0.7092,
        0.6152, 0.6811, 0.6703, 0.7357, 0.7347, 0.5504, 0.6259],
       device='cuda:0') torch.Size([16])
percent tensor([0.6997, 0.6748, 0.7535, 0.7588, 0.7889, 0.7865, 0.7298, 0.6940, 0.7674,
        0.7034, 0.7560, 0.7228, 0.7020, 0.8232, 0.6643, 0.7335],
       device='cuda:0') torch.Size([16])
percent tensor([0.6376, 0.6010, 0.7318, 0.6487, 0.7713, 0.6949, 0.6744, 0.6850, 0.6198,
        0.6234, 0.6025, 0.6327, 0.5028, 0.6095, 0.6036, 0.6577],
       device='cuda:0') torch.Size([16])
percent tensor([0.9993, 0.9988, 0.9989, 0.9994, 0.9993, 0.9988, 0.9988, 0.9992, 0.9991,
        0.9996, 0.9991, 0.9992, 0.9992, 0.9992, 0.9987, 0.9992],
       device='cuda:0') torch.Size([16])
Epoch: 108 | Batch_idx: 0 |  Loss: (0.1556) |  Loss2: (0.0000) | Acc: (93.00%) (120/128)
Epoch: 108 | Batch_idx: 10 |  Loss: (0.2040) |  Loss2: (0.0000) | Acc: (93.00%) (1318/1408)
Epoch: 108 | Batch_idx: 20 |  Loss: (0.1914) |  Loss2: (0.0000) | Acc: (93.00%) (2520/2688)
Epoch: 108 | Batch_idx: 30 |  Loss: (0.1936) |  Loss2: (0.0000) | Acc: (93.00%) (3709/3968)
Epoch: 108 | Batch_idx: 40 |  Loss: (0.1970) |  Loss2: (0.0000) | Acc: (93.00%) (4894/5248)
Epoch: 108 | Batch_idx: 50 |  Loss: (0.1955) |  Loss2: (0.0000) | Acc: (93.00%) (6105/6528)
Epoch: 108 | Batch_idx: 60 |  Loss: (0.1924) |  Loss2: (0.0000) | Acc: (93.00%) (7306/7808)
Epoch: 108 | Batch_idx: 70 |  Loss: (0.1887) |  Loss2: (0.0000) | Acc: (93.00%) (8513/9088)
Epoch: 108 | Batch_idx: 80 |  Loss: (0.1890) |  Loss2: (0.0000) | Acc: (93.00%) (9709/10368)
Epoch: 108 | Batch_idx: 90 |  Loss: (0.1887) |  Loss2: (0.0000) | Acc: (93.00%) (10905/11648)
Epoch: 108 | Batch_idx: 100 |  Loss: (0.1908) |  Loss2: (0.0000) | Acc: (93.00%) (12095/12928)
Epoch: 108 | Batch_idx: 110 |  Loss: (0.1912) |  Loss2: (0.0000) | Acc: (93.00%) (13289/14208)
Epoch: 108 | Batch_idx: 120 |  Loss: (0.1902) |  Loss2: (0.0000) | Acc: (93.00%) (14488/15488)
Epoch: 108 | Batch_idx: 130 |  Loss: (0.1905) |  Loss2: (0.0000) | Acc: (93.00%) (15688/16768)
Epoch: 108 | Batch_idx: 140 |  Loss: (0.1915) |  Loss2: (0.0000) | Acc: (93.00%) (16876/18048)
Epoch: 108 | Batch_idx: 150 |  Loss: (0.1931) |  Loss2: (0.0000) | Acc: (93.00%) (18056/19328)
Epoch: 108 | Batch_idx: 160 |  Loss: (0.1936) |  Loss2: (0.0000) | Acc: (93.00%) (19256/20608)
Epoch: 108 | Batch_idx: 170 |  Loss: (0.1935) |  Loss2: (0.0000) | Acc: (93.00%) (20460/21888)
Epoch: 108 | Batch_idx: 180 |  Loss: (0.1930) |  Loss2: (0.0000) | Acc: (93.00%) (21666/23168)
Epoch: 108 | Batch_idx: 190 |  Loss: (0.1937) |  Loss2: (0.0000) | Acc: (93.00%) (22852/24448)
Epoch: 108 | Batch_idx: 200 |  Loss: (0.1926) |  Loss2: (0.0000) | Acc: (93.00%) (24058/25728)
Epoch: 108 | Batch_idx: 210 |  Loss: (0.1911) |  Loss2: (0.0000) | Acc: (93.00%) (25271/27008)
Epoch: 108 | Batch_idx: 220 |  Loss: (0.1910) |  Loss2: (0.0000) | Acc: (93.00%) (26467/28288)
Epoch: 108 | Batch_idx: 230 |  Loss: (0.1899) |  Loss2: (0.0000) | Acc: (93.00%) (27676/29568)
Epoch: 108 | Batch_idx: 240 |  Loss: (0.1894) |  Loss2: (0.0000) | Acc: (93.00%) (28878/30848)
Epoch: 108 | Batch_idx: 250 |  Loss: (0.1890) |  Loss2: (0.0000) | Acc: (93.00%) (30083/32128)
Epoch: 108 | Batch_idx: 260 |  Loss: (0.1886) |  Loss2: (0.0000) | Acc: (93.00%) (31283/33408)
Epoch: 108 | Batch_idx: 270 |  Loss: (0.1888) |  Loss2: (0.0000) | Acc: (93.00%) (32474/34688)
Epoch: 108 | Batch_idx: 280 |  Loss: (0.1890) |  Loss2: (0.0000) | Acc: (93.00%) (33666/35968)
Epoch: 108 | Batch_idx: 290 |  Loss: (0.1882) |  Loss2: (0.0000) | Acc: (93.00%) (34873/37248)
Epoch: 108 | Batch_idx: 300 |  Loss: (0.1880) |  Loss2: (0.0000) | Acc: (93.00%) (36070/38528)
Epoch: 108 | Batch_idx: 310 |  Loss: (0.1892) |  Loss2: (0.0000) | Acc: (93.00%) (37248/39808)
Epoch: 108 | Batch_idx: 320 |  Loss: (0.1885) |  Loss2: (0.0000) | Acc: (93.00%) (38451/41088)
Epoch: 108 | Batch_idx: 330 |  Loss: (0.1890) |  Loss2: (0.0000) | Acc: (93.00%) (39639/42368)
Epoch: 108 | Batch_idx: 340 |  Loss: (0.1888) |  Loss2: (0.0000) | Acc: (93.00%) (40846/43648)
Epoch: 108 | Batch_idx: 350 |  Loss: (0.1890) |  Loss2: (0.0000) | Acc: (93.00%) (42039/44928)
Epoch: 108 | Batch_idx: 360 |  Loss: (0.1881) |  Loss2: (0.0000) | Acc: (93.00%) (43257/46208)
Epoch: 108 | Batch_idx: 370 |  Loss: (0.1882) |  Loss2: (0.0000) | Acc: (93.00%) (44451/47488)
Epoch: 108 | Batch_idx: 380 |  Loss: (0.1881) |  Loss2: (0.0000) | Acc: (93.00%) (45645/48768)
Epoch: 108 | Batch_idx: 390 |  Loss: (0.1879) |  Loss2: (0.0000) | Acc: (93.00%) (46808/50000)
# TEST : Loss: (0.3840) | Acc: (87.00%) (8770/10000)
percent tensor([0.5969, 0.5936, 0.6004, 0.5914, 0.6073, 0.5930, 0.6002, 0.5941, 0.5975,
        0.5929, 0.5939, 0.5999, 0.5906, 0.5874, 0.5948, 0.5908],
       device='cuda:0') torch.Size([16])
percent tensor([0.5642, 0.5274, 0.5203, 0.5755, 0.5505, 0.6025, 0.5374, 0.5533, 0.5555,
        0.5309, 0.5467, 0.5152, 0.5259, 0.5842, 0.5560, 0.5686],
       device='cuda:0') torch.Size([16])
percent tensor([0.5275, 0.5752, 0.5219, 0.4721, 0.5205, 0.4793, 0.5742, 0.5368, 0.5199,
        0.5233, 0.5218, 0.5492, 0.5632, 0.5230, 0.5470, 0.5281],
       device='cuda:0') torch.Size([16])
percent tensor([0.6420, 0.6050, 0.6226, 0.6309, 0.6364, 0.6542, 0.6324, 0.6395, 0.6334,
        0.6184, 0.6301, 0.6158, 0.6235, 0.6326, 0.6365, 0.6498],
       device='cuda:0') torch.Size([16])
percent tensor([0.5739, 0.6730, 0.6514, 0.6439, 0.5907, 0.6737, 0.5845, 0.4897, 0.7081,
        0.6167, 0.6802, 0.6689, 0.7314, 0.7388, 0.5466, 0.6291],
       device='cuda:0') torch.Size([16])
percent tensor([0.6980, 0.6735, 0.7530, 0.7562, 0.7865, 0.7859, 0.7285, 0.6906, 0.7654,
        0.7012, 0.7543, 0.7201, 0.6999, 0.8227, 0.6625, 0.7320],
       device='cuda:0') torch.Size([16])
percent tensor([0.6484, 0.6088, 0.7418, 0.6595, 0.7784, 0.7075, 0.6826, 0.6902, 0.6322,
        0.6305, 0.6133, 0.6442, 0.5146, 0.6193, 0.6084, 0.6644],
       device='cuda:0') torch.Size([16])
percent tensor([0.9993, 0.9988, 0.9989, 0.9994, 0.9993, 0.9988, 0.9988, 0.9992, 0.9992,
        0.9996, 0.9991, 0.9993, 0.9992, 0.9992, 0.9986, 0.9991],
       device='cuda:0') torch.Size([16])
Epoch: 109 | Batch_idx: 0 |  Loss: (0.2257) |  Loss2: (0.0000) | Acc: (92.00%) (118/128)
Epoch: 109 | Batch_idx: 10 |  Loss: (0.1851) |  Loss2: (0.0000) | Acc: (93.00%) (1322/1408)
Epoch: 109 | Batch_idx: 20 |  Loss: (0.2014) |  Loss2: (0.0000) | Acc: (93.00%) (2502/2688)
Epoch: 109 | Batch_idx: 30 |  Loss: (0.2004) |  Loss2: (0.0000) | Acc: (93.00%) (3694/3968)
Epoch: 109 | Batch_idx: 40 |  Loss: (0.2056) |  Loss2: (0.0000) | Acc: (93.00%) (4883/5248)
Epoch: 109 | Batch_idx: 50 |  Loss: (0.2038) |  Loss2: (0.0000) | Acc: (93.00%) (6087/6528)
Epoch: 109 | Batch_idx: 60 |  Loss: (0.2044) |  Loss2: (0.0000) | Acc: (93.00%) (7268/7808)
Epoch: 109 | Batch_idx: 70 |  Loss: (0.2001) |  Loss2: (0.0000) | Acc: (93.00%) (8467/9088)
Epoch: 109 | Batch_idx: 80 |  Loss: (0.1978) |  Loss2: (0.0000) | Acc: (93.00%) (9669/10368)
Epoch: 109 | Batch_idx: 90 |  Loss: (0.1943) |  Loss2: (0.0000) | Acc: (93.00%) (10882/11648)
Epoch: 109 | Batch_idx: 100 |  Loss: (0.1902) |  Loss2: (0.0000) | Acc: (93.00%) (12100/12928)
Epoch: 109 | Batch_idx: 110 |  Loss: (0.1891) |  Loss2: (0.0000) | Acc: (93.00%) (13297/14208)
Epoch: 109 | Batch_idx: 120 |  Loss: (0.1889) |  Loss2: (0.0000) | Acc: (93.00%) (14496/15488)
Epoch: 109 | Batch_idx: 130 |  Loss: (0.1885) |  Loss2: (0.0000) | Acc: (93.00%) (15699/16768)
Epoch: 109 | Batch_idx: 140 |  Loss: (0.1888) |  Loss2: (0.0000) | Acc: (93.00%) (16894/18048)
Epoch: 109 | Batch_idx: 150 |  Loss: (0.1871) |  Loss2: (0.0000) | Acc: (93.00%) (18106/19328)
Epoch: 109 | Batch_idx: 160 |  Loss: (0.1881) |  Loss2: (0.0000) | Acc: (93.00%) (19291/20608)
Epoch: 109 | Batch_idx: 170 |  Loss: (0.1884) |  Loss2: (0.0000) | Acc: (93.00%) (20484/21888)
Epoch: 109 | Batch_idx: 180 |  Loss: (0.1890) |  Loss2: (0.0000) | Acc: (93.00%) (21662/23168)
Epoch: 109 | Batch_idx: 190 |  Loss: (0.1885) |  Loss2: (0.0000) | Acc: (93.00%) (22869/24448)
Epoch: 109 | Batch_idx: 200 |  Loss: (0.1883) |  Loss2: (0.0000) | Acc: (93.00%) (24069/25728)
Epoch: 109 | Batch_idx: 210 |  Loss: (0.1874) |  Loss2: (0.0000) | Acc: (93.00%) (25267/27008)
Epoch: 109 | Batch_idx: 220 |  Loss: (0.1881) |  Loss2: (0.0000) | Acc: (93.00%) (26451/28288)
Epoch: 109 | Batch_idx: 230 |  Loss: (0.1877) |  Loss2: (0.0000) | Acc: (93.00%) (27663/29568)
Epoch: 109 | Batch_idx: 240 |  Loss: (0.1877) |  Loss2: (0.0000) | Acc: (93.00%) (28855/30848)
Epoch: 109 | Batch_idx: 250 |  Loss: (0.1883) |  Loss2: (0.0000) | Acc: (93.00%) (30053/32128)
Epoch: 109 | Batch_idx: 260 |  Loss: (0.1872) |  Loss2: (0.0000) | Acc: (93.00%) (31265/33408)
Epoch: 109 | Batch_idx: 270 |  Loss: (0.1870) |  Loss2: (0.0000) | Acc: (93.00%) (32466/34688)
Epoch: 109 | Batch_idx: 280 |  Loss: (0.1857) |  Loss2: (0.0000) | Acc: (93.00%) (33684/35968)
Epoch: 109 | Batch_idx: 290 |  Loss: (0.1850) |  Loss2: (0.0000) | Acc: (93.00%) (34896/37248)
Epoch: 109 | Batch_idx: 300 |  Loss: (0.1849) |  Loss2: (0.0000) | Acc: (93.00%) (36095/38528)
Epoch: 109 | Batch_idx: 310 |  Loss: (0.1847) |  Loss2: (0.0000) | Acc: (93.00%) (37300/39808)
Epoch: 109 | Batch_idx: 320 |  Loss: (0.1850) |  Loss2: (0.0000) | Acc: (93.00%) (38492/41088)
Epoch: 109 | Batch_idx: 330 |  Loss: (0.1855) |  Loss2: (0.0000) | Acc: (93.00%) (39680/42368)
Epoch: 109 | Batch_idx: 340 |  Loss: (0.1864) |  Loss2: (0.0000) | Acc: (93.00%) (40860/43648)
Epoch: 109 | Batch_idx: 350 |  Loss: (0.1860) |  Loss2: (0.0000) | Acc: (93.00%) (42070/44928)
Epoch: 109 | Batch_idx: 360 |  Loss: (0.1854) |  Loss2: (0.0000) | Acc: (93.00%) (43286/46208)
Epoch: 109 | Batch_idx: 370 |  Loss: (0.1859) |  Loss2: (0.0000) | Acc: (93.00%) (44475/47488)
Epoch: 109 | Batch_idx: 380 |  Loss: (0.1860) |  Loss2: (0.0000) | Acc: (93.00%) (45679/48768)
Epoch: 109 | Batch_idx: 390 |  Loss: (0.1861) |  Loss2: (0.0000) | Acc: (93.00%) (46835/50000)
# TEST : Loss: (0.3802) | Acc: (87.00%) (8787/10000)
percent tensor([0.5990, 0.5962, 0.6019, 0.5932, 0.6093, 0.5952, 0.6026, 0.5962, 0.6001,
        0.5950, 0.5964, 0.6017, 0.5929, 0.5904, 0.5972, 0.5929],
       device='cuda:0') torch.Size([16])
percent tensor([0.5672, 0.5297, 0.5229, 0.5785, 0.5541, 0.6061, 0.5403, 0.5564, 0.5594,
        0.5331, 0.5497, 0.5174, 0.5281, 0.5880, 0.5584, 0.5710],
       device='cuda:0') torch.Size([16])
percent tensor([0.5266, 0.5761, 0.5210, 0.4722, 0.5204, 0.4757, 0.5750, 0.5373, 0.5201,
        0.5250, 0.5227, 0.5496, 0.5635, 0.5243, 0.5463, 0.5280],
       device='cuda:0') torch.Size([16])
percent tensor([0.6413, 0.6040, 0.6222, 0.6299, 0.6361, 0.6543, 0.6320, 0.6390, 0.6324,
        0.6168, 0.6290, 0.6151, 0.6225, 0.6312, 0.6360, 0.6488],
       device='cuda:0') torch.Size([16])
percent tensor([0.5737, 0.6740, 0.6464, 0.6374, 0.5850, 0.6649, 0.5857, 0.4866, 0.7054,
        0.6144, 0.6795, 0.6706, 0.7329, 0.7364, 0.5500, 0.6247],
       device='cuda:0') torch.Size([16])
percent tensor([0.6983, 0.6727, 0.7540, 0.7561, 0.7878, 0.7867, 0.7293, 0.6907, 0.7662,
        0.7015, 0.7551, 0.7209, 0.7000, 0.8242, 0.6619, 0.7329],
       device='cuda:0') torch.Size([16])
percent tensor([0.6529, 0.6108, 0.7458, 0.6662, 0.7833, 0.7115, 0.6890, 0.6945, 0.6382,
        0.6333, 0.6182, 0.6469, 0.5172, 0.6243, 0.6072, 0.6708],
       device='cuda:0') torch.Size([16])
percent tensor([0.9993, 0.9989, 0.9990, 0.9994, 0.9993, 0.9989, 0.9989, 0.9992, 0.9992,
        0.9996, 0.9992, 0.9993, 0.9992, 0.9992, 0.9987, 0.9992],
       device='cuda:0') torch.Size([16])
True Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=128, out_features=16, bias=False)
False Linear(in_features=16, out_features=2, bias=False)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=128, out_features=16, bias=False)
False Linear(in_features=16, out_features=2, bias=False)
True Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=256, out_features=32, bias=False)
False Linear(in_features=32, out_features=2, bias=False)
True Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=256, out_features=32, bias=False)
False Linear(in_features=32, out_features=2, bias=False)
True Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=512, out_features=64, bias=False)
False Linear(in_features=64, out_features=2, bias=False)
True Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=512, out_features=64, bias=False)
False Linear(in_features=64, out_features=2, bias=False)
True Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1024, out_features=128, bias=False)
False Linear(in_features=128, out_features=2, bias=False)
True Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1024, out_features=128, bias=False)
False Linear(in_features=128, out_features=2, bias=False)
True Linear(in_features=512, out_features=10, bias=True)
Epoch: 110 | Batch_idx: 0 |  Loss: (0.2739) |  Loss2: (0.0000) | Acc: (92.00%) (118/128)
Epoch: 110 | Batch_idx: 10 |  Loss: (0.1825) |  Loss2: (0.0000) | Acc: (94.00%) (1329/1408)
Epoch: 110 | Batch_idx: 20 |  Loss: (0.1846) |  Loss2: (0.0000) | Acc: (93.00%) (2523/2688)
Epoch: 110 | Batch_idx: 30 |  Loss: (0.1792) |  Loss2: (0.0000) | Acc: (94.00%) (3731/3968)
Epoch: 110 | Batch_idx: 40 |  Loss: (0.1794) |  Loss2: (0.0000) | Acc: (94.00%) (4936/5248)
Epoch: 110 | Batch_idx: 50 |  Loss: (0.1796) |  Loss2: (0.0000) | Acc: (94.00%) (6141/6528)
Epoch: 110 | Batch_idx: 60 |  Loss: (0.1798) |  Loss2: (0.0000) | Acc: (94.00%) (7346/7808)
Epoch: 110 | Batch_idx: 70 |  Loss: (0.1789) |  Loss2: (0.0000) | Acc: (94.00%) (8553/9088)
Epoch: 110 | Batch_idx: 80 |  Loss: (0.1783) |  Loss2: (0.0000) | Acc: (94.00%) (9752/10368)
Epoch: 110 | Batch_idx: 90 |  Loss: (0.1811) |  Loss2: (0.0000) | Acc: (93.00%) (10946/11648)
Epoch: 110 | Batch_idx: 100 |  Loss: (0.1811) |  Loss2: (0.0000) | Acc: (93.00%) (12147/12928)
Epoch: 110 | Batch_idx: 110 |  Loss: (0.1815) |  Loss2: (0.0000) | Acc: (93.00%) (13351/14208)
Epoch: 110 | Batch_idx: 120 |  Loss: (0.1807) |  Loss2: (0.0000) | Acc: (93.00%) (14554/15488)
Epoch: 110 | Batch_idx: 130 |  Loss: (0.1811) |  Loss2: (0.0000) | Acc: (93.00%) (15759/16768)
Epoch: 110 | Batch_idx: 140 |  Loss: (0.1817) |  Loss2: (0.0000) | Acc: (93.00%) (16945/18048)
Epoch: 110 | Batch_idx: 150 |  Loss: (0.1823) |  Loss2: (0.0000) | Acc: (93.00%) (18151/19328)
Epoch: 110 | Batch_idx: 160 |  Loss: (0.1834) |  Loss2: (0.0000) | Acc: (93.00%) (19343/20608)
Epoch: 110 | Batch_idx: 170 |  Loss: (0.1829) |  Loss2: (0.0000) | Acc: (93.00%) (20549/21888)
Epoch: 110 | Batch_idx: 180 |  Loss: (0.1843) |  Loss2: (0.0000) | Acc: (93.00%) (21736/23168)
Epoch: 110 | Batch_idx: 190 |  Loss: (0.1852) |  Loss2: (0.0000) | Acc: (93.00%) (22929/24448)
Epoch: 110 | Batch_idx: 200 |  Loss: (0.1852) |  Loss2: (0.0000) | Acc: (93.00%) (24136/25728)
Epoch: 110 | Batch_idx: 210 |  Loss: (0.1862) |  Loss2: (0.0000) | Acc: (93.00%) (25316/27008)
Epoch: 110 | Batch_idx: 220 |  Loss: (0.1865) |  Loss2: (0.0000) | Acc: (93.00%) (26506/28288)
Epoch: 110 | Batch_idx: 230 |  Loss: (0.1867) |  Loss2: (0.0000) | Acc: (93.00%) (27701/29568)
Epoch: 110 | Batch_idx: 240 |  Loss: (0.1861) |  Loss2: (0.0000) | Acc: (93.00%) (28907/30848)
Epoch: 110 | Batch_idx: 250 |  Loss: (0.1866) |  Loss2: (0.0000) | Acc: (93.00%) (30098/32128)
Epoch: 110 | Batch_idx: 260 |  Loss: (0.1873) |  Loss2: (0.0000) | Acc: (93.00%) (31293/33408)
Epoch: 110 | Batch_idx: 270 |  Loss: (0.1873) |  Loss2: (0.0000) | Acc: (93.00%) (32478/34688)
Epoch: 110 | Batch_idx: 280 |  Loss: (0.1879) |  Loss2: (0.0000) | Acc: (93.00%) (33664/35968)
Epoch: 110 | Batch_idx: 290 |  Loss: (0.1883) |  Loss2: (0.0000) | Acc: (93.00%) (34847/37248)
Epoch: 110 | Batch_idx: 300 |  Loss: (0.1880) |  Loss2: (0.0000) | Acc: (93.00%) (36047/38528)
Epoch: 110 | Batch_idx: 310 |  Loss: (0.1887) |  Loss2: (0.0000) | Acc: (93.00%) (37236/39808)
Epoch: 110 | Batch_idx: 320 |  Loss: (0.1881) |  Loss2: (0.0000) | Acc: (93.00%) (38434/41088)
Epoch: 110 | Batch_idx: 330 |  Loss: (0.1887) |  Loss2: (0.0000) | Acc: (93.00%) (39619/42368)
Epoch: 110 | Batch_idx: 340 |  Loss: (0.1892) |  Loss2: (0.0000) | Acc: (93.00%) (40800/43648)
Epoch: 110 | Batch_idx: 350 |  Loss: (0.1893) |  Loss2: (0.0000) | Acc: (93.00%) (41990/44928)
Epoch: 110 | Batch_idx: 360 |  Loss: (0.1898) |  Loss2: (0.0000) | Acc: (93.00%) (43172/46208)
Epoch: 110 | Batch_idx: 370 |  Loss: (0.1897) |  Loss2: (0.0000) | Acc: (93.00%) (44368/47488)
Epoch: 110 | Batch_idx: 380 |  Loss: (0.1902) |  Loss2: (0.0000) | Acc: (93.00%) (45554/48768)
Epoch: 110 | Batch_idx: 390 |  Loss: (0.1905) |  Loss2: (0.0000) | Acc: (93.00%) (46694/50000)
=> saving checkpoint 'drive/app/torch/save_Routing_Gate_2/checkpoint_110.pth.tar'
# TEST : Loss: (0.4094) | Acc: (86.00%) (8690/10000)
percent tensor([0.6029, 0.5938, 0.6084, 0.5929, 0.6157, 0.5995, 0.6054, 0.5955, 0.6040,
        0.5955, 0.5980, 0.6089, 0.5949, 0.5859, 0.5980, 0.5932],
       device='cuda:0') torch.Size([16])
percent tensor([0.5654, 0.5306, 0.5239, 0.5784, 0.5515, 0.6025, 0.5408, 0.5525, 0.5598,
        0.5324, 0.5508, 0.5211, 0.5274, 0.5937, 0.5576, 0.5707],
       device='cuda:0') torch.Size([16])
percent tensor([0.5279, 0.5660, 0.5186, 0.4822, 0.5199, 0.4864, 0.5674, 0.5437, 0.5164,
        0.5161, 0.5121, 0.5423, 0.5603, 0.5161, 0.5452, 0.5269],
       device='cuda:0') torch.Size([16])
percent tensor([0.6406, 0.6022, 0.6252, 0.6347, 0.6375, 0.6513, 0.6306, 0.6395, 0.6334,
        0.6173, 0.6300, 0.6216, 0.6233, 0.6307, 0.6352, 0.6494],
       device='cuda:0') torch.Size([16])
percent tensor([0.5717, 0.6844, 0.6442, 0.6244, 0.6034, 0.6804, 0.6154, 0.5069, 0.7116,
        0.6084, 0.6858, 0.6767, 0.7187, 0.7320, 0.5773, 0.6136],
       device='cuda:0') torch.Size([16])
percent tensor([0.7065, 0.6892, 0.7610, 0.7527, 0.7972, 0.7955, 0.7405, 0.6871, 0.7766,
        0.7236, 0.7725, 0.7273, 0.7035, 0.8265, 0.6672, 0.7341],
       device='cuda:0') torch.Size([16])
percent tensor([0.6562, 0.6063, 0.7489, 0.6767, 0.7954, 0.7222, 0.7060, 0.6956, 0.6514,
        0.6356, 0.6290, 0.6440, 0.5344, 0.6163, 0.6229, 0.6818],
       device='cuda:0') torch.Size([16])
percent tensor([0.9993, 0.9988, 0.9989, 0.9991, 0.9990, 0.9987, 0.9991, 0.9993, 0.9992,
        0.9996, 0.9992, 0.9992, 0.9992, 0.9991, 0.9988, 0.9991],
       device='cuda:0') torch.Size([16])
Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 3, 3, 3]) tensor(180.3502, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(819.0783, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(821.3425, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([128, 64, 3, 3]) tensor(1528.3845, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([128, 64, 1, 1]) tensor(494.1091, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([128, 128, 3, 3]) tensor(2242.5076, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([256, 128, 3, 3]) tensor(4285.2485, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([256, 128, 1, 1]) tensor(1393.7573, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([256, 256, 3, 3]) tensor(6185.8403, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([512, 256, 3, 3]) tensor(11862.6396, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([512, 256, 1, 1]) tensor(3926.8086, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([512, 512, 3, 3]) tensor(16595.5488, device='cuda:0', grad_fn=<NormBackward0>)
Epoch: 111 | Batch_idx: 0 |  Loss: (0.1633) |  Loss2: (0.0000) | Acc: (96.00%) (123/128)
Epoch: 111 | Batch_idx: 10 |  Loss: (0.1706) |  Loss2: (0.0000) | Acc: (94.00%) (1324/1408)
Epoch: 111 | Batch_idx: 20 |  Loss: (0.1754) |  Loss2: (0.0000) | Acc: (94.00%) (2527/2688)
Epoch: 111 | Batch_idx: 30 |  Loss: (0.1800) |  Loss2: (0.0000) | Acc: (93.00%) (3714/3968)
Epoch: 111 | Batch_idx: 40 |  Loss: (0.1827) |  Loss2: (0.0000) | Acc: (93.00%) (4902/5248)
Epoch: 111 | Batch_idx: 50 |  Loss: (0.1817) |  Loss2: (0.0000) | Acc: (93.00%) (6104/6528)
Epoch: 111 | Batch_idx: 60 |  Loss: (0.1867) |  Loss2: (0.0000) | Acc: (93.00%) (7288/7808)
Epoch: 111 | Batch_idx: 70 |  Loss: (0.1871) |  Loss2: (0.0000) | Acc: (93.00%) (8489/9088)
Epoch: 111 | Batch_idx: 80 |  Loss: (0.1873) |  Loss2: (0.0000) | Acc: (93.00%) (9689/10368)
Epoch: 111 | Batch_idx: 90 |  Loss: (0.1859) |  Loss2: (0.0000) | Acc: (93.00%) (10897/11648)
Epoch: 111 | Batch_idx: 100 |  Loss: (0.1866) |  Loss2: (0.0000) | Acc: (93.00%) (12092/12928)
Epoch: 111 | Batch_idx: 110 |  Loss: (0.1872) |  Loss2: (0.0000) | Acc: (93.00%) (13294/14208)
Epoch: 111 | Batch_idx: 120 |  Loss: (0.1873) |  Loss2: (0.0000) | Acc: (93.00%) (14506/15488)
Epoch: 111 | Batch_idx: 130 |  Loss: (0.1873) |  Loss2: (0.0000) | Acc: (93.00%) (15708/16768)
Epoch: 111 | Batch_idx: 140 |  Loss: (0.1866) |  Loss2: (0.0000) | Acc: (93.00%) (16914/18048)
Epoch: 111 | Batch_idx: 150 |  Loss: (0.1834) |  Loss2: (0.0000) | Acc: (93.00%) (18143/19328)
Epoch: 111 | Batch_idx: 160 |  Loss: (0.1834) |  Loss2: (0.0000) | Acc: (93.00%) (19340/20608)
Epoch: 111 | Batch_idx: 170 |  Loss: (0.1834) |  Loss2: (0.0000) | Acc: (93.00%) (20529/21888)
Epoch: 111 | Batch_idx: 180 |  Loss: (0.1843) |  Loss2: (0.0000) | Acc: (93.00%) (21720/23168)
Epoch: 111 | Batch_idx: 190 |  Loss: (0.1832) |  Loss2: (0.0000) | Acc: (93.00%) (22928/24448)
Epoch: 111 | Batch_idx: 200 |  Loss: (0.1826) |  Loss2: (0.0000) | Acc: (93.00%) (24132/25728)
Epoch: 111 | Batch_idx: 210 |  Loss: (0.1839) |  Loss2: (0.0000) | Acc: (93.00%) (25325/27008)
Epoch: 111 | Batch_idx: 220 |  Loss: (0.1847) |  Loss2: (0.0000) | Acc: (93.00%) (26514/28288)
Epoch: 111 | Batch_idx: 230 |  Loss: (0.1851) |  Loss2: (0.0000) | Acc: (93.00%) (27704/29568)
Epoch: 111 | Batch_idx: 240 |  Loss: (0.1869) |  Loss2: (0.0000) | Acc: (93.00%) (28876/30848)
Epoch: 111 | Batch_idx: 250 |  Loss: (0.1868) |  Loss2: (0.0000) | Acc: (93.00%) (30071/32128)
Epoch: 111 | Batch_idx: 260 |  Loss: (0.1870) |  Loss2: (0.0000) | Acc: (93.00%) (31263/33408)
Epoch: 111 | Batch_idx: 270 |  Loss: (0.1871) |  Loss2: (0.0000) | Acc: (93.00%) (32458/34688)
Epoch: 111 | Batch_idx: 280 |  Loss: (0.1871) |  Loss2: (0.0000) | Acc: (93.00%) (33660/35968)
Epoch: 111 | Batch_idx: 290 |  Loss: (0.1881) |  Loss2: (0.0000) | Acc: (93.00%) (34856/37248)
Epoch: 111 | Batch_idx: 300 |  Loss: (0.1892) |  Loss2: (0.0000) | Acc: (93.00%) (36034/38528)
Epoch: 111 | Batch_idx: 310 |  Loss: (0.1898) |  Loss2: (0.0000) | Acc: (93.00%) (37215/39808)
Epoch: 111 | Batch_idx: 320 |  Loss: (0.1900) |  Loss2: (0.0000) | Acc: (93.00%) (38411/41088)
Epoch: 111 | Batch_idx: 330 |  Loss: (0.1900) |  Loss2: (0.0000) | Acc: (93.00%) (39609/42368)
Epoch: 111 | Batch_idx: 340 |  Loss: (0.1900) |  Loss2: (0.0000) | Acc: (93.00%) (40796/43648)
Epoch: 111 | Batch_idx: 350 |  Loss: (0.1898) |  Loss2: (0.0000) | Acc: (93.00%) (41996/44928)
Epoch: 111 | Batch_idx: 360 |  Loss: (0.1899) |  Loss2: (0.0000) | Acc: (93.00%) (43195/46208)
Epoch: 111 | Batch_idx: 370 |  Loss: (0.1902) |  Loss2: (0.0000) | Acc: (93.00%) (44382/47488)
Epoch: 111 | Batch_idx: 380 |  Loss: (0.1911) |  Loss2: (0.0000) | Acc: (93.00%) (45562/48768)
Epoch: 111 | Batch_idx: 390 |  Loss: (0.1915) |  Loss2: (0.0000) | Acc: (93.00%) (46708/50000)
# TEST : Loss: (0.4484) | Acc: (85.00%) (8559/10000)
percent tensor([0.6026, 0.5958, 0.6076, 0.5930, 0.6152, 0.6006, 0.6062, 0.5955, 0.6038,
        0.5959, 0.5988, 0.6074, 0.5953, 0.5893, 0.5992, 0.5943],
       device='cuda:0') torch.Size([16])
percent tensor([0.5670, 0.5322, 0.5244, 0.5789, 0.5530, 0.6056, 0.5414, 0.5570, 0.5594,
        0.5346, 0.5499, 0.5223, 0.5277, 0.5969, 0.5597, 0.5722],
       device='cuda:0') torch.Size([16])
percent tensor([0.5258, 0.5721, 0.5248, 0.4815, 0.5245, 0.4859, 0.5746, 0.5439, 0.5175,
        0.5209, 0.5140, 0.5491, 0.5573, 0.5231, 0.5473, 0.5296],
       device='cuda:0') torch.Size([16])
percent tensor([0.6430, 0.6012, 0.6259, 0.6330, 0.6389, 0.6485, 0.6308, 0.6412, 0.6369,
        0.6174, 0.6305, 0.6194, 0.6243, 0.6315, 0.6356, 0.6478],
       device='cuda:0') torch.Size([16])
percent tensor([0.5598, 0.6729, 0.6332, 0.6236, 0.5723, 0.6730, 0.6100, 0.4910, 0.7074,
        0.6177, 0.6768, 0.6750, 0.7206, 0.7522, 0.5508, 0.6226],
       device='cuda:0') torch.Size([16])
percent tensor([0.6979, 0.6647, 0.7515, 0.7515, 0.7821, 0.7961, 0.7192, 0.6861, 0.7794,
        0.7133, 0.7734, 0.7135, 0.6838, 0.8425, 0.6533, 0.7326],
       device='cuda:0') torch.Size([16])
percent tensor([0.6557, 0.5916, 0.7371, 0.6729, 0.7856, 0.7229, 0.6686, 0.6867, 0.6354,
        0.6372, 0.6298, 0.6308, 0.4965, 0.6014, 0.6125, 0.6726],
       device='cuda:0') torch.Size([16])
percent tensor([0.9992, 0.9992, 0.9991, 0.9995, 0.9992, 0.9991, 0.9985, 0.9990, 0.9993,
        0.9995, 0.9994, 0.9992, 0.9991, 0.9995, 0.9990, 0.9991],
       device='cuda:0') torch.Size([16])
Epoch: 112 | Batch_idx: 0 |  Loss: (0.2191) |  Loss2: (0.0000) | Acc: (91.00%) (117/128)
Epoch: 112 | Batch_idx: 10 |  Loss: (0.1861) |  Loss2: (0.0000) | Acc: (93.00%) (1321/1408)
Epoch: 112 | Batch_idx: 20 |  Loss: (0.1922) |  Loss2: (0.0000) | Acc: (93.00%) (2523/2688)
Epoch: 112 | Batch_idx: 30 |  Loss: (0.1878) |  Loss2: (0.0000) | Acc: (94.00%) (3731/3968)
Epoch: 112 | Batch_idx: 40 |  Loss: (0.1894) |  Loss2: (0.0000) | Acc: (93.00%) (4919/5248)
Epoch: 112 | Batch_idx: 50 |  Loss: (0.1899) |  Loss2: (0.0000) | Acc: (93.00%) (6110/6528)
Epoch: 112 | Batch_idx: 60 |  Loss: (0.1850) |  Loss2: (0.0000) | Acc: (93.00%) (7314/7808)
Epoch: 112 | Batch_idx: 70 |  Loss: (0.1798) |  Loss2: (0.0000) | Acc: (93.00%) (8532/9088)
Epoch: 112 | Batch_idx: 80 |  Loss: (0.1811) |  Loss2: (0.0000) | Acc: (93.00%) (9723/10368)
Epoch: 112 | Batch_idx: 90 |  Loss: (0.1804) |  Loss2: (0.0000) | Acc: (93.00%) (10927/11648)
Epoch: 112 | Batch_idx: 100 |  Loss: (0.1794) |  Loss2: (0.0000) | Acc: (93.00%) (12131/12928)
Epoch: 112 | Batch_idx: 110 |  Loss: (0.1815) |  Loss2: (0.0000) | Acc: (93.00%) (13318/14208)
Epoch: 112 | Batch_idx: 120 |  Loss: (0.1805) |  Loss2: (0.0000) | Acc: (93.00%) (14525/15488)
Epoch: 112 | Batch_idx: 130 |  Loss: (0.1790) |  Loss2: (0.0000) | Acc: (93.00%) (15728/16768)
Epoch: 112 | Batch_idx: 140 |  Loss: (0.1792) |  Loss2: (0.0000) | Acc: (93.00%) (16933/18048)
Epoch: 112 | Batch_idx: 150 |  Loss: (0.1783) |  Loss2: (0.0000) | Acc: (93.00%) (18139/19328)
Epoch: 112 | Batch_idx: 160 |  Loss: (0.1773) |  Loss2: (0.0000) | Acc: (93.00%) (19348/20608)
Epoch: 112 | Batch_idx: 170 |  Loss: (0.1763) |  Loss2: (0.0000) | Acc: (93.00%) (20556/21888)
Epoch: 112 | Batch_idx: 180 |  Loss: (0.1765) |  Loss2: (0.0000) | Acc: (93.00%) (21757/23168)
Epoch: 112 | Batch_idx: 190 |  Loss: (0.1781) |  Loss2: (0.0000) | Acc: (93.00%) (22933/24448)
Epoch: 112 | Batch_idx: 200 |  Loss: (0.1778) |  Loss2: (0.0000) | Acc: (93.00%) (24131/25728)
Epoch: 112 | Batch_idx: 210 |  Loss: (0.1785) |  Loss2: (0.0000) | Acc: (93.00%) (25326/27008)
Epoch: 112 | Batch_idx: 220 |  Loss: (0.1799) |  Loss2: (0.0000) | Acc: (93.00%) (26514/28288)
Epoch: 112 | Batch_idx: 230 |  Loss: (0.1808) |  Loss2: (0.0000) | Acc: (93.00%) (27709/29568)
Epoch: 112 | Batch_idx: 240 |  Loss: (0.1808) |  Loss2: (0.0000) | Acc: (93.00%) (28911/30848)
Epoch: 112 | Batch_idx: 250 |  Loss: (0.1816) |  Loss2: (0.0000) | Acc: (93.00%) (30093/32128)
Epoch: 112 | Batch_idx: 260 |  Loss: (0.1820) |  Loss2: (0.0000) | Acc: (93.00%) (31286/33408)
Epoch: 112 | Batch_idx: 270 |  Loss: (0.1824) |  Loss2: (0.0000) | Acc: (93.00%) (32475/34688)
Epoch: 112 | Batch_idx: 280 |  Loss: (0.1828) |  Loss2: (0.0000) | Acc: (93.00%) (33666/35968)
Epoch: 112 | Batch_idx: 290 |  Loss: (0.1821) |  Loss2: (0.0000) | Acc: (93.00%) (34874/37248)
Epoch: 112 | Batch_idx: 300 |  Loss: (0.1824) |  Loss2: (0.0000) | Acc: (93.00%) (36073/38528)
Epoch: 112 | Batch_idx: 310 |  Loss: (0.1827) |  Loss2: (0.0000) | Acc: (93.00%) (37270/39808)
Epoch: 112 | Batch_idx: 320 |  Loss: (0.1829) |  Loss2: (0.0000) | Acc: (93.00%) (38455/41088)
Epoch: 112 | Batch_idx: 330 |  Loss: (0.1829) |  Loss2: (0.0000) | Acc: (93.00%) (39654/42368)
Epoch: 112 | Batch_idx: 340 |  Loss: (0.1831) |  Loss2: (0.0000) | Acc: (93.00%) (40855/43648)
Epoch: 112 | Batch_idx: 350 |  Loss: (0.1835) |  Loss2: (0.0000) | Acc: (93.00%) (42050/44928)
Epoch: 112 | Batch_idx: 360 |  Loss: (0.1846) |  Loss2: (0.0000) | Acc: (93.00%) (43228/46208)
Epoch: 112 | Batch_idx: 370 |  Loss: (0.1842) |  Loss2: (0.0000) | Acc: (93.00%) (44431/47488)
Epoch: 112 | Batch_idx: 380 |  Loss: (0.1847) |  Loss2: (0.0000) | Acc: (93.00%) (45622/48768)
Epoch: 112 | Batch_idx: 390 |  Loss: (0.1848) |  Loss2: (0.0000) | Acc: (93.00%) (46778/50000)
# TEST : Loss: (0.4549) | Acc: (85.00%) (8567/10000)
percent tensor([0.6007, 0.5968, 0.6015, 0.5917, 0.6099, 0.5990, 0.6045, 0.5946, 0.6010,
        0.5946, 0.5977, 0.6019, 0.5938, 0.5912, 0.5991, 0.5944],
       device='cuda:0') torch.Size([16])
percent tensor([0.5709, 0.5305, 0.5287, 0.5803, 0.5553, 0.6062, 0.5410, 0.5578, 0.5604,
        0.5367, 0.5522, 0.5237, 0.5311, 0.5879, 0.5602, 0.5714],
       device='cuda:0') torch.Size([16])
percent tensor([0.5314, 0.5827, 0.5211, 0.4845, 0.5241, 0.4806, 0.5808, 0.5486, 0.5286,
        0.5300, 0.5250, 0.5494, 0.5667, 0.5441, 0.5494, 0.5361],
       device='cuda:0') torch.Size([16])
percent tensor([0.6443, 0.6008, 0.6299, 0.6334, 0.6411, 0.6508, 0.6300, 0.6418, 0.6389,
        0.6174, 0.6283, 0.6193, 0.6254, 0.6307, 0.6354, 0.6493],
       device='cuda:0') torch.Size([16])
percent tensor([0.5714, 0.6904, 0.6116, 0.6303, 0.5626, 0.6840, 0.5980, 0.4698, 0.7135,
        0.6312, 0.6890, 0.6566, 0.7307, 0.7603, 0.5638, 0.6405],
       device='cuda:0') torch.Size([16])
percent tensor([0.6945, 0.6830, 0.7575, 0.7559, 0.7803, 0.8009, 0.7264, 0.6773, 0.7588,
        0.7021, 0.7512, 0.7056, 0.6895, 0.8302, 0.6616, 0.7473],
       device='cuda:0') torch.Size([16])
percent tensor([0.6630, 0.5837, 0.7333, 0.6701, 0.7766, 0.7176, 0.6951, 0.6930, 0.6300,
        0.6202, 0.6193, 0.6363, 0.4956, 0.6221, 0.6156, 0.6885],
       device='cuda:0') torch.Size([16])
percent tensor([0.9995, 0.9990, 0.9991, 0.9994, 0.9989, 0.9991, 0.9989, 0.9988, 0.9993,
        0.9995, 0.9992, 0.9994, 0.9992, 0.9994, 0.9991, 0.9993],
       device='cuda:0') torch.Size([16])
Epoch: 113 | Batch_idx: 0 |  Loss: (0.1209) |  Loss2: (0.0000) | Acc: (96.00%) (124/128)
Epoch: 113 | Batch_idx: 10 |  Loss: (0.1372) |  Loss2: (0.0000) | Acc: (95.00%) (1347/1408)
Epoch: 113 | Batch_idx: 20 |  Loss: (0.1523) |  Loss2: (0.0000) | Acc: (94.00%) (2550/2688)
Epoch: 113 | Batch_idx: 30 |  Loss: (0.1648) |  Loss2: (0.0000) | Acc: (94.00%) (3750/3968)
Epoch: 113 | Batch_idx: 40 |  Loss: (0.1658) |  Loss2: (0.0000) | Acc: (94.00%) (4956/5248)
Epoch: 113 | Batch_idx: 50 |  Loss: (0.1678) |  Loss2: (0.0000) | Acc: (94.00%) (6167/6528)
Epoch: 113 | Batch_idx: 60 |  Loss: (0.1689) |  Loss2: (0.0000) | Acc: (94.00%) (7368/7808)
Epoch: 113 | Batch_idx: 70 |  Loss: (0.1681) |  Loss2: (0.0000) | Acc: (94.00%) (8575/9088)
Epoch: 113 | Batch_idx: 80 |  Loss: (0.1715) |  Loss2: (0.0000) | Acc: (94.00%) (9771/10368)
Epoch: 113 | Batch_idx: 90 |  Loss: (0.1729) |  Loss2: (0.0000) | Acc: (94.00%) (10961/11648)
Epoch: 113 | Batch_idx: 100 |  Loss: (0.1752) |  Loss2: (0.0000) | Acc: (93.00%) (12149/12928)
Epoch: 113 | Batch_idx: 110 |  Loss: (0.1774) |  Loss2: (0.0000) | Acc: (93.00%) (13337/14208)
Epoch: 113 | Batch_idx: 120 |  Loss: (0.1758) |  Loss2: (0.0000) | Acc: (93.00%) (14552/15488)
Epoch: 113 | Batch_idx: 130 |  Loss: (0.1745) |  Loss2: (0.0000) | Acc: (93.00%) (15758/16768)
Epoch: 113 | Batch_idx: 140 |  Loss: (0.1745) |  Loss2: (0.0000) | Acc: (93.00%) (16963/18048)
Epoch: 113 | Batch_idx: 150 |  Loss: (0.1748) |  Loss2: (0.0000) | Acc: (93.00%) (18166/19328)
Epoch: 113 | Batch_idx: 160 |  Loss: (0.1745) |  Loss2: (0.0000) | Acc: (93.00%) (19360/20608)
Epoch: 113 | Batch_idx: 170 |  Loss: (0.1744) |  Loss2: (0.0000) | Acc: (94.00%) (20576/21888)
Epoch: 113 | Batch_idx: 180 |  Loss: (0.1750) |  Loss2: (0.0000) | Acc: (93.00%) (21774/23168)
Epoch: 113 | Batch_idx: 190 |  Loss: (0.1757) |  Loss2: (0.0000) | Acc: (93.00%) (22971/24448)
Epoch: 113 | Batch_idx: 200 |  Loss: (0.1762) |  Loss2: (0.0000) | Acc: (93.00%) (24168/25728)
Epoch: 113 | Batch_idx: 210 |  Loss: (0.1758) |  Loss2: (0.0000) | Acc: (93.00%) (25371/27008)
Epoch: 113 | Batch_idx: 220 |  Loss: (0.1765) |  Loss2: (0.0000) | Acc: (93.00%) (26569/28288)
Epoch: 113 | Batch_idx: 230 |  Loss: (0.1771) |  Loss2: (0.0000) | Acc: (93.00%) (27760/29568)
Epoch: 113 | Batch_idx: 240 |  Loss: (0.1782) |  Loss2: (0.0000) | Acc: (93.00%) (28949/30848)
Epoch: 113 | Batch_idx: 250 |  Loss: (0.1778) |  Loss2: (0.0000) | Acc: (93.00%) (30153/32128)
Epoch: 113 | Batch_idx: 260 |  Loss: (0.1779) |  Loss2: (0.0000) | Acc: (93.00%) (31342/33408)
Epoch: 113 | Batch_idx: 270 |  Loss: (0.1787) |  Loss2: (0.0000) | Acc: (93.00%) (32533/34688)
Epoch: 113 | Batch_idx: 280 |  Loss: (0.1786) |  Loss2: (0.0000) | Acc: (93.00%) (33733/35968)
Epoch: 113 | Batch_idx: 290 |  Loss: (0.1787) |  Loss2: (0.0000) | Acc: (93.00%) (34934/37248)
Epoch: 113 | Batch_idx: 300 |  Loss: (0.1790) |  Loss2: (0.0000) | Acc: (93.00%) (36129/38528)
Epoch: 113 | Batch_idx: 310 |  Loss: (0.1789) |  Loss2: (0.0000) | Acc: (93.00%) (37330/39808)
Epoch: 113 | Batch_idx: 320 |  Loss: (0.1793) |  Loss2: (0.0000) | Acc: (93.00%) (38513/41088)
Epoch: 113 | Batch_idx: 330 |  Loss: (0.1797) |  Loss2: (0.0000) | Acc: (93.00%) (39698/42368)
Epoch: 113 | Batch_idx: 340 |  Loss: (0.1796) |  Loss2: (0.0000) | Acc: (93.00%) (40895/43648)
Epoch: 113 | Batch_idx: 350 |  Loss: (0.1803) |  Loss2: (0.0000) | Acc: (93.00%) (42083/44928)
Epoch: 113 | Batch_idx: 360 |  Loss: (0.1807) |  Loss2: (0.0000) | Acc: (93.00%) (43276/46208)
Epoch: 113 | Batch_idx: 370 |  Loss: (0.1815) |  Loss2: (0.0000) | Acc: (93.00%) (44465/47488)
Epoch: 113 | Batch_idx: 380 |  Loss: (0.1823) |  Loss2: (0.0000) | Acc: (93.00%) (45646/48768)
Epoch: 113 | Batch_idx: 390 |  Loss: (0.1830) |  Loss2: (0.0000) | Acc: (93.00%) (46790/50000)
# TEST : Loss: (0.3969) | Acc: (87.00%) (8768/10000)
percent tensor([0.6017, 0.5965, 0.6031, 0.5912, 0.6114, 0.5993, 0.6051, 0.5946, 0.6039,
        0.5950, 0.5996, 0.6033, 0.5949, 0.5899, 0.5987, 0.5942],
       device='cuda:0') torch.Size([16])
percent tensor([0.5685, 0.5273, 0.5256, 0.5816, 0.5533, 0.6060, 0.5379, 0.5570, 0.5581,
        0.5324, 0.5491, 0.5214, 0.5282, 0.5868, 0.5589, 0.5717],
       device='cuda:0') torch.Size([16])
percent tensor([0.5281, 0.5737, 0.5187, 0.4805, 0.5221, 0.4794, 0.5738, 0.5412, 0.5193,
        0.5221, 0.5157, 0.5439, 0.5624, 0.5366, 0.5454, 0.5306],
       device='cuda:0') torch.Size([16])
percent tensor([0.6399, 0.5988, 0.6277, 0.6328, 0.6397, 0.6507, 0.6263, 0.6390, 0.6330,
        0.6123, 0.6254, 0.6170, 0.6190, 0.6305, 0.6336, 0.6471],
       device='cuda:0') torch.Size([16])
percent tensor([0.5763, 0.6805, 0.6462, 0.6355, 0.5768, 0.6771, 0.6028, 0.4897, 0.7046,
        0.6354, 0.6992, 0.6859, 0.7314, 0.7456, 0.5608, 0.6321],
       device='cuda:0') torch.Size([16])
percent tensor([0.7082, 0.6937, 0.7545, 0.7642, 0.7885, 0.8043, 0.7232, 0.6776, 0.7695,
        0.7235, 0.7579, 0.7124, 0.7007, 0.8204, 0.6791, 0.7509],
       device='cuda:0') torch.Size([16])
percent tensor([0.6773, 0.6278, 0.7471, 0.6780, 0.7935, 0.7171, 0.7015, 0.7078, 0.6513,
        0.6346, 0.6308, 0.6353, 0.5344, 0.6323, 0.6435, 0.6872],
       device='cuda:0') torch.Size([16])
percent tensor([0.9995, 0.9992, 0.9992, 0.9993, 0.9994, 0.9988, 0.9991, 0.9990, 0.9992,
        0.9996, 0.9994, 0.9993, 0.9992, 0.9993, 0.9988, 0.9991],
       device='cuda:0') torch.Size([16])
Epoch: 114 | Batch_idx: 0 |  Loss: (0.1913) |  Loss2: (0.0000) | Acc: (92.00%) (119/128)
Epoch: 114 | Batch_idx: 10 |  Loss: (0.1587) |  Loss2: (0.0000) | Acc: (94.00%) (1327/1408)
Epoch: 114 | Batch_idx: 20 |  Loss: (0.1650) |  Loss2: (0.0000) | Acc: (94.00%) (2532/2688)
Epoch: 114 | Batch_idx: 30 |  Loss: (0.1626) |  Loss2: (0.0000) | Acc: (94.00%) (3749/3968)
Epoch: 114 | Batch_idx: 40 |  Loss: (0.1644) |  Loss2: (0.0000) | Acc: (94.00%) (4952/5248)
Epoch: 114 | Batch_idx: 50 |  Loss: (0.1639) |  Loss2: (0.0000) | Acc: (94.00%) (6161/6528)
Epoch: 114 | Batch_idx: 60 |  Loss: (0.1665) |  Loss2: (0.0000) | Acc: (94.00%) (7365/7808)
Epoch: 114 | Batch_idx: 70 |  Loss: (0.1656) |  Loss2: (0.0000) | Acc: (94.00%) (8578/9088)
Epoch: 114 | Batch_idx: 80 |  Loss: (0.1659) |  Loss2: (0.0000) | Acc: (94.00%) (9787/10368)
Epoch: 114 | Batch_idx: 90 |  Loss: (0.1695) |  Loss2: (0.0000) | Acc: (94.00%) (10980/11648)
Epoch: 114 | Batch_idx: 100 |  Loss: (0.1706) |  Loss2: (0.0000) | Acc: (94.00%) (12188/12928)
Epoch: 114 | Batch_idx: 110 |  Loss: (0.1743) |  Loss2: (0.0000) | Acc: (94.00%) (13375/14208)
Epoch: 114 | Batch_idx: 120 |  Loss: (0.1722) |  Loss2: (0.0000) | Acc: (94.00%) (14593/15488)
Epoch: 114 | Batch_idx: 130 |  Loss: (0.1708) |  Loss2: (0.0000) | Acc: (94.00%) (15809/16768)
Epoch: 114 | Batch_idx: 140 |  Loss: (0.1713) |  Loss2: (0.0000) | Acc: (94.00%) (17015/18048)
Epoch: 114 | Batch_idx: 150 |  Loss: (0.1704) |  Loss2: (0.0000) | Acc: (94.00%) (18229/19328)
Epoch: 114 | Batch_idx: 160 |  Loss: (0.1708) |  Loss2: (0.0000) | Acc: (94.00%) (19427/20608)
Epoch: 114 | Batch_idx: 170 |  Loss: (0.1716) |  Loss2: (0.0000) | Acc: (94.00%) (20623/21888)
Epoch: 114 | Batch_idx: 180 |  Loss: (0.1719) |  Loss2: (0.0000) | Acc: (94.00%) (21823/23168)
Epoch: 114 | Batch_idx: 190 |  Loss: (0.1723) |  Loss2: (0.0000) | Acc: (94.00%) (23016/24448)
Epoch: 114 | Batch_idx: 200 |  Loss: (0.1715) |  Loss2: (0.0000) | Acc: (94.00%) (24224/25728)
Epoch: 114 | Batch_idx: 210 |  Loss: (0.1726) |  Loss2: (0.0000) | Acc: (94.00%) (25418/27008)
Epoch: 114 | Batch_idx: 220 |  Loss: (0.1717) |  Loss2: (0.0000) | Acc: (94.00%) (26623/28288)
Epoch: 114 | Batch_idx: 230 |  Loss: (0.1719) |  Loss2: (0.0000) | Acc: (94.00%) (27821/29568)
Epoch: 114 | Batch_idx: 240 |  Loss: (0.1716) |  Loss2: (0.0000) | Acc: (94.00%) (29026/30848)
Epoch: 114 | Batch_idx: 250 |  Loss: (0.1714) |  Loss2: (0.0000) | Acc: (94.00%) (30231/32128)
Epoch: 114 | Batch_idx: 260 |  Loss: (0.1716) |  Loss2: (0.0000) | Acc: (94.00%) (31425/33408)
Epoch: 114 | Batch_idx: 270 |  Loss: (0.1719) |  Loss2: (0.0000) | Acc: (94.00%) (32617/34688)
Epoch: 114 | Batch_idx: 280 |  Loss: (0.1725) |  Loss2: (0.0000) | Acc: (94.00%) (33810/35968)
Epoch: 114 | Batch_idx: 290 |  Loss: (0.1721) |  Loss2: (0.0000) | Acc: (94.00%) (35018/37248)
Epoch: 114 | Batch_idx: 300 |  Loss: (0.1733) |  Loss2: (0.0000) | Acc: (93.00%) (36208/38528)
Epoch: 114 | Batch_idx: 310 |  Loss: (0.1742) |  Loss2: (0.0000) | Acc: (93.00%) (37399/39808)
Epoch: 114 | Batch_idx: 320 |  Loss: (0.1740) |  Loss2: (0.0000) | Acc: (93.00%) (38602/41088)
Epoch: 114 | Batch_idx: 330 |  Loss: (0.1741) |  Loss2: (0.0000) | Acc: (93.00%) (39804/42368)
Epoch: 114 | Batch_idx: 340 |  Loss: (0.1741) |  Loss2: (0.0000) | Acc: (93.00%) (41002/43648)
Epoch: 114 | Batch_idx: 350 |  Loss: (0.1745) |  Loss2: (0.0000) | Acc: (93.00%) (42194/44928)
Epoch: 114 | Batch_idx: 360 |  Loss: (0.1753) |  Loss2: (0.0000) | Acc: (93.00%) (43378/46208)
Epoch: 114 | Batch_idx: 370 |  Loss: (0.1755) |  Loss2: (0.0000) | Acc: (93.00%) (44577/47488)
Epoch: 114 | Batch_idx: 380 |  Loss: (0.1754) |  Loss2: (0.0000) | Acc: (93.00%) (45779/48768)
Epoch: 114 | Batch_idx: 390 |  Loss: (0.1759) |  Loss2: (0.0000) | Acc: (93.00%) (46935/50000)
# TEST : Loss: (0.4468) | Acc: (86.00%) (8618/10000)
percent tensor([0.6016, 0.5956, 0.6067, 0.5913, 0.6133, 0.5993, 0.6057, 0.5950, 0.6023,
        0.5953, 0.5972, 0.6064, 0.5938, 0.5880, 0.5982, 0.5929],
       device='cuda:0') torch.Size([16])
percent tensor([0.5704, 0.5285, 0.5284, 0.5821, 0.5552, 0.6058, 0.5399, 0.5539, 0.5607,
        0.5325, 0.5506, 0.5253, 0.5296, 0.5883, 0.5580, 0.5712],
       device='cuda:0') torch.Size([16])
percent tensor([0.5329, 0.5813, 0.5205, 0.4864, 0.5255, 0.4876, 0.5774, 0.5457, 0.5270,
        0.5296, 0.5214, 0.5490, 0.5666, 0.5380, 0.5526, 0.5385],
       device='cuda:0') torch.Size([16])
percent tensor([0.6420, 0.6009, 0.6232, 0.6296, 0.6367, 0.6498, 0.6323, 0.6391, 0.6356,
        0.6139, 0.6281, 0.6178, 0.6237, 0.6294, 0.6347, 0.6477],
       device='cuda:0') torch.Size([16])
percent tensor([0.5632, 0.6711, 0.6300, 0.6351, 0.5802, 0.6956, 0.6121, 0.4947, 0.7062,
        0.6231, 0.6803, 0.6526, 0.7199, 0.7416, 0.5696, 0.6420],
       device='cuda:0') torch.Size([16])
percent tensor([0.6966, 0.6907, 0.7520, 0.7550, 0.7805, 0.8014, 0.7350, 0.6780, 0.7619,
        0.7197, 0.7544, 0.7105, 0.6984, 0.8256, 0.6672, 0.7389],
       device='cuda:0') torch.Size([16])
percent tensor([0.6614, 0.6065, 0.7255, 0.6531, 0.7734, 0.7254, 0.6985, 0.6797, 0.6169,
        0.6306, 0.6320, 0.6293, 0.5153, 0.6252, 0.6210, 0.6872],
       device='cuda:0') torch.Size([16])
percent tensor([0.9993, 0.9987, 0.9988, 0.9995, 0.9991, 0.9993, 0.9989, 0.9990, 0.9991,
        0.9994, 0.9993, 0.9992, 0.9992, 0.9993, 0.9992, 0.9994],
       device='cuda:0') torch.Size([16])
False Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=128, out_features=16, bias=False)
True Linear(in_features=16, out_features=2, bias=False)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=128, out_features=16, bias=False)
True Linear(in_features=16, out_features=2, bias=False)
False Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=256, out_features=32, bias=False)
True Linear(in_features=32, out_features=2, bias=False)
False Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=256, out_features=32, bias=False)
True Linear(in_features=32, out_features=2, bias=False)
False Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=512, out_features=64, bias=False)
True Linear(in_features=64, out_features=2, bias=False)
False Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=512, out_features=64, bias=False)
True Linear(in_features=64, out_features=2, bias=False)
False Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1024, out_features=128, bias=False)
True Linear(in_features=128, out_features=2, bias=False)
False Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1024, out_features=128, bias=False)
True Linear(in_features=128, out_features=2, bias=False)
False Linear(in_features=512, out_features=10, bias=True)
Epoch: 115 | Batch_idx: 0 |  Loss: (0.1668) |  Loss2: (0.0000) | Acc: (93.00%) (120/128)
Epoch: 115 | Batch_idx: 10 |  Loss: (0.1918) |  Loss2: (0.0000) | Acc: (93.00%) (1316/1408)
Epoch: 115 | Batch_idx: 20 |  Loss: (0.2107) |  Loss2: (0.0000) | Acc: (93.00%) (2502/2688)
Epoch: 115 | Batch_idx: 30 |  Loss: (0.2134) |  Loss2: (0.0000) | Acc: (92.00%) (3685/3968)
Epoch: 115 | Batch_idx: 40 |  Loss: (0.2108) |  Loss2: (0.0000) | Acc: (92.00%) (4863/5248)
Epoch: 115 | Batch_idx: 50 |  Loss: (0.2134) |  Loss2: (0.0000) | Acc: (92.00%) (6042/6528)
Epoch: 115 | Batch_idx: 60 |  Loss: (0.2095) |  Loss2: (0.0000) | Acc: (92.00%) (7238/7808)
Epoch: 115 | Batch_idx: 70 |  Loss: (0.2085) |  Loss2: (0.0000) | Acc: (92.00%) (8425/9088)
Epoch: 115 | Batch_idx: 80 |  Loss: (0.2092) |  Loss2: (0.0000) | Acc: (92.00%) (9604/10368)
Epoch: 115 | Batch_idx: 90 |  Loss: (0.2105) |  Loss2: (0.0000) | Acc: (92.00%) (10776/11648)
Epoch: 115 | Batch_idx: 100 |  Loss: (0.2108) |  Loss2: (0.0000) | Acc: (92.00%) (11957/12928)
Epoch: 115 | Batch_idx: 110 |  Loss: (0.2095) |  Loss2: (0.0000) | Acc: (92.00%) (13148/14208)
Epoch: 115 | Batch_idx: 120 |  Loss: (0.2099) |  Loss2: (0.0000) | Acc: (92.00%) (14318/15488)
Epoch: 115 | Batch_idx: 130 |  Loss: (0.2098) |  Loss2: (0.0000) | Acc: (92.00%) (15498/16768)
Epoch: 115 | Batch_idx: 140 |  Loss: (0.2095) |  Loss2: (0.0000) | Acc: (92.00%) (16691/18048)
Epoch: 115 | Batch_idx: 150 |  Loss: (0.2075) |  Loss2: (0.0000) | Acc: (92.00%) (17883/19328)
Epoch: 115 | Batch_idx: 160 |  Loss: (0.2088) |  Loss2: (0.0000) | Acc: (92.00%) (19054/20608)
Epoch: 115 | Batch_idx: 170 |  Loss: (0.2092) |  Loss2: (0.0000) | Acc: (92.00%) (20235/21888)
Epoch: 115 | Batch_idx: 180 |  Loss: (0.2091) |  Loss2: (0.0000) | Acc: (92.00%) (21419/23168)
Epoch: 115 | Batch_idx: 190 |  Loss: (0.2091) |  Loss2: (0.0000) | Acc: (92.00%) (22592/24448)
Epoch: 115 | Batch_idx: 200 |  Loss: (0.2087) |  Loss2: (0.0000) | Acc: (92.00%) (23785/25728)
Epoch: 115 | Batch_idx: 210 |  Loss: (0.2090) |  Loss2: (0.0000) | Acc: (92.00%) (24973/27008)
Epoch: 115 | Batch_idx: 220 |  Loss: (0.2100) |  Loss2: (0.0000) | Acc: (92.00%) (26143/28288)
Epoch: 115 | Batch_idx: 230 |  Loss: (0.2094) |  Loss2: (0.0000) | Acc: (92.00%) (27331/29568)
Epoch: 115 | Batch_idx: 240 |  Loss: (0.2083) |  Loss2: (0.0000) | Acc: (92.00%) (28529/30848)
Epoch: 115 | Batch_idx: 250 |  Loss: (0.2087) |  Loss2: (0.0000) | Acc: (92.00%) (29708/32128)
Epoch: 115 | Batch_idx: 260 |  Loss: (0.2084) |  Loss2: (0.0000) | Acc: (92.00%) (30895/33408)
Epoch: 115 | Batch_idx: 270 |  Loss: (0.2080) |  Loss2: (0.0000) | Acc: (92.00%) (32085/34688)
Epoch: 115 | Batch_idx: 280 |  Loss: (0.2076) |  Loss2: (0.0000) | Acc: (92.00%) (33287/35968)
Epoch: 115 | Batch_idx: 290 |  Loss: (0.2070) |  Loss2: (0.0000) | Acc: (92.00%) (34475/37248)
Epoch: 115 | Batch_idx: 300 |  Loss: (0.2059) |  Loss2: (0.0000) | Acc: (92.00%) (35678/38528)
Epoch: 115 | Batch_idx: 310 |  Loss: (0.2059) |  Loss2: (0.0000) | Acc: (92.00%) (36863/39808)
Epoch: 115 | Batch_idx: 320 |  Loss: (0.2062) |  Loss2: (0.0000) | Acc: (92.00%) (38040/41088)
Epoch: 115 | Batch_idx: 330 |  Loss: (0.2069) |  Loss2: (0.0000) | Acc: (92.00%) (39227/42368)
Epoch: 115 | Batch_idx: 340 |  Loss: (0.2063) |  Loss2: (0.0000) | Acc: (92.00%) (40409/43648)
Epoch: 115 | Batch_idx: 350 |  Loss: (0.2058) |  Loss2: (0.0000) | Acc: (92.00%) (41599/44928)
Epoch: 115 | Batch_idx: 360 |  Loss: (0.2056) |  Loss2: (0.0000) | Acc: (92.00%) (42793/46208)
Epoch: 115 | Batch_idx: 370 |  Loss: (0.2050) |  Loss2: (0.0000) | Acc: (92.00%) (43988/47488)
Epoch: 115 | Batch_idx: 380 |  Loss: (0.2048) |  Loss2: (0.0000) | Acc: (92.00%) (45177/48768)
Epoch: 115 | Batch_idx: 390 |  Loss: (0.2040) |  Loss2: (0.0000) | Acc: (92.00%) (46334/50000)
=> saving checkpoint 'drive/app/torch/save_Routing_Gate_2/checkpoint_115.pth.tar'
# TEST : Loss: (0.4086) | Acc: (87.00%) (8736/10000)
percent tensor([0.6041, 0.5980, 0.6103, 0.5947, 0.6168, 0.6018, 0.6087, 0.5979, 0.6047,
        0.5981, 0.5987, 0.6106, 0.5959, 0.5906, 0.6007, 0.5951],
       device='cuda:0') torch.Size([16])
percent tensor([0.5760, 0.5230, 0.5336, 0.5933, 0.5575, 0.6178, 0.5370, 0.5593, 0.5640,
        0.5310, 0.5515, 0.5248, 0.5267, 0.5910, 0.5603, 0.5780],
       device='cuda:0') torch.Size([16])
percent tensor([0.5268, 0.5723, 0.5111, 0.4793, 0.5220, 0.4815, 0.5708, 0.5364, 0.5188,
        0.5192, 0.5104, 0.5353, 0.5522, 0.5363, 0.5432, 0.5315],
       device='cuda:0') torch.Size([16])
percent tensor([0.6583, 0.6154, 0.6415, 0.6496, 0.6554, 0.6625, 0.6493, 0.6586, 0.6514,
        0.6329, 0.6456, 0.6363, 0.6368, 0.6459, 0.6520, 0.6627],
       device='cuda:0') torch.Size([16])
percent tensor([0.5804, 0.6752, 0.6568, 0.6363, 0.5995, 0.7137, 0.6244, 0.5036, 0.7167,
        0.6341, 0.6869, 0.6528, 0.7289, 0.7532, 0.5671, 0.6452],
       device='cuda:0') torch.Size([16])
percent tensor([0.6797, 0.6731, 0.7380, 0.7458, 0.7644, 0.7887, 0.7171, 0.6589, 0.7467,
        0.7081, 0.7392, 0.7026, 0.6784, 0.8160, 0.6422, 0.7220],
       device='cuda:0') torch.Size([16])
percent tensor([0.6314, 0.5794, 0.6785, 0.6013, 0.7070, 0.6795, 0.6576, 0.6317, 0.6097,
        0.5960, 0.6075, 0.5979, 0.5082, 0.5755, 0.5875, 0.6420],
       device='cuda:0') torch.Size([16])
percent tensor([0.9993, 0.9987, 0.9989, 0.9995, 0.9992, 0.9989, 0.9990, 0.9990, 0.9991,
        0.9994, 0.9993, 0.9992, 0.9992, 0.9994, 0.9992, 0.9993],
       device='cuda:0') torch.Size([16])
Epoch: 116 | Batch_idx: 0 |  Loss: (0.2985) |  Loss2: (0.0000) | Acc: (86.00%) (111/128)
Epoch: 116 | Batch_idx: 10 |  Loss: (0.2014) |  Loss2: (0.0000) | Acc: (92.00%) (1299/1408)
Epoch: 116 | Batch_idx: 20 |  Loss: (0.1838) |  Loss2: (0.0000) | Acc: (93.00%) (2501/2688)
Epoch: 116 | Batch_idx: 30 |  Loss: (0.1836) |  Loss2: (0.0000) | Acc: (93.00%) (3699/3968)
Epoch: 116 | Batch_idx: 40 |  Loss: (0.1856) |  Loss2: (0.0000) | Acc: (93.00%) (4890/5248)
Epoch: 116 | Batch_idx: 50 |  Loss: (0.1838) |  Loss2: (0.0000) | Acc: (93.00%) (6098/6528)
Epoch: 116 | Batch_idx: 60 |  Loss: (0.1835) |  Loss2: (0.0000) | Acc: (93.00%) (7289/7808)
Epoch: 116 | Batch_idx: 70 |  Loss: (0.1872) |  Loss2: (0.0000) | Acc: (93.00%) (8483/9088)
Epoch: 116 | Batch_idx: 80 |  Loss: (0.1911) |  Loss2: (0.0000) | Acc: (93.00%) (9666/10368)
Epoch: 116 | Batch_idx: 90 |  Loss: (0.1900) |  Loss2: (0.0000) | Acc: (93.00%) (10867/11648)
Epoch: 116 | Batch_idx: 100 |  Loss: (0.1909) |  Loss2: (0.0000) | Acc: (93.00%) (12052/12928)
Epoch: 116 | Batch_idx: 110 |  Loss: (0.1896) |  Loss2: (0.0000) | Acc: (93.00%) (13259/14208)
Epoch: 116 | Batch_idx: 120 |  Loss: (0.1894) |  Loss2: (0.0000) | Acc: (93.00%) (14462/15488)
Epoch: 116 | Batch_idx: 130 |  Loss: (0.1891) |  Loss2: (0.0000) | Acc: (93.00%) (15645/16768)
Epoch: 116 | Batch_idx: 140 |  Loss: (0.1870) |  Loss2: (0.0000) | Acc: (93.00%) (16857/18048)
Epoch: 116 | Batch_idx: 150 |  Loss: (0.1886) |  Loss2: (0.0000) | Acc: (93.00%) (18041/19328)
Epoch: 116 | Batch_idx: 160 |  Loss: (0.1886) |  Loss2: (0.0000) | Acc: (93.00%) (19232/20608)
Epoch: 116 | Batch_idx: 170 |  Loss: (0.1871) |  Loss2: (0.0000) | Acc: (93.00%) (20439/21888)
Epoch: 116 | Batch_idx: 180 |  Loss: (0.1865) |  Loss2: (0.0000) | Acc: (93.00%) (21647/23168)
Epoch: 116 | Batch_idx: 190 |  Loss: (0.1864) |  Loss2: (0.0000) | Acc: (93.00%) (22846/24448)
Epoch: 116 | Batch_idx: 200 |  Loss: (0.1869) |  Loss2: (0.0000) | Acc: (93.00%) (24039/25728)
Epoch: 116 | Batch_idx: 210 |  Loss: (0.1855) |  Loss2: (0.0000) | Acc: (93.00%) (25259/27008)
Epoch: 116 | Batch_idx: 220 |  Loss: (0.1848) |  Loss2: (0.0000) | Acc: (93.00%) (26468/28288)
Epoch: 116 | Batch_idx: 230 |  Loss: (0.1848) |  Loss2: (0.0000) | Acc: (93.00%) (27674/29568)
Epoch: 116 | Batch_idx: 240 |  Loss: (0.1846) |  Loss2: (0.0000) | Acc: (93.00%) (28877/30848)
Epoch: 116 | Batch_idx: 250 |  Loss: (0.1835) |  Loss2: (0.0000) | Acc: (93.00%) (30087/32128)
Epoch: 116 | Batch_idx: 260 |  Loss: (0.1839) |  Loss2: (0.0000) | Acc: (93.00%) (31277/33408)
Epoch: 116 | Batch_idx: 270 |  Loss: (0.1837) |  Loss2: (0.0000) | Acc: (93.00%) (32475/34688)
Epoch: 116 | Batch_idx: 280 |  Loss: (0.1836) |  Loss2: (0.0000) | Acc: (93.00%) (33675/35968)
Epoch: 116 | Batch_idx: 290 |  Loss: (0.1841) |  Loss2: (0.0000) | Acc: (93.00%) (34861/37248)
Epoch: 116 | Batch_idx: 300 |  Loss: (0.1841) |  Loss2: (0.0000) | Acc: (93.00%) (36048/38528)
Epoch: 116 | Batch_idx: 310 |  Loss: (0.1845) |  Loss2: (0.0000) | Acc: (93.00%) (37236/39808)
Epoch: 116 | Batch_idx: 320 |  Loss: (0.1840) |  Loss2: (0.0000) | Acc: (93.00%) (38440/41088)
Epoch: 116 | Batch_idx: 330 |  Loss: (0.1838) |  Loss2: (0.0000) | Acc: (93.00%) (39637/42368)
Epoch: 116 | Batch_idx: 340 |  Loss: (0.1837) |  Loss2: (0.0000) | Acc: (93.00%) (40846/43648)
Epoch: 116 | Batch_idx: 350 |  Loss: (0.1835) |  Loss2: (0.0000) | Acc: (93.00%) (42047/44928)
Epoch: 116 | Batch_idx: 360 |  Loss: (0.1839) |  Loss2: (0.0000) | Acc: (93.00%) (43241/46208)
Epoch: 116 | Batch_idx: 370 |  Loss: (0.1837) |  Loss2: (0.0000) | Acc: (93.00%) (44436/47488)
Epoch: 116 | Batch_idx: 380 |  Loss: (0.1842) |  Loss2: (0.0000) | Acc: (93.00%) (45626/48768)
Epoch: 116 | Batch_idx: 390 |  Loss: (0.1846) |  Loss2: (0.0000) | Acc: (93.00%) (46775/50000)
# TEST : Loss: (0.3976) | Acc: (87.00%) (8774/10000)
percent tensor([0.5995, 0.5924, 0.6061, 0.5903, 0.6119, 0.5974, 0.6032, 0.5929, 0.5996,
        0.5930, 0.5937, 0.6057, 0.5909, 0.5852, 0.5955, 0.5902],
       device='cuda:0') torch.Size([16])
percent tensor([0.5854, 0.5309, 0.5415, 0.6051, 0.5671, 0.6288, 0.5459, 0.5685, 0.5737,
        0.5398, 0.5610, 0.5330, 0.5338, 0.6032, 0.5695, 0.5880],
       device='cuda:0') torch.Size([16])
percent tensor([0.5259, 0.5706, 0.5062, 0.4732, 0.5180, 0.4754, 0.5696, 0.5295, 0.5160,
        0.5165, 0.5079, 0.5302, 0.5489, 0.5361, 0.5387, 0.5291],
       device='cuda:0') torch.Size([16])
percent tensor([0.6627, 0.6206, 0.6453, 0.6536, 0.6597, 0.6649, 0.6547, 0.6627, 0.6559,
        0.6388, 0.6510, 0.6414, 0.6411, 0.6516, 0.6562, 0.6663],
       device='cuda:0') torch.Size([16])
percent tensor([0.5860, 0.6800, 0.6619, 0.6322, 0.6017, 0.7189, 0.6294, 0.5062, 0.7219,
        0.6374, 0.6913, 0.6508, 0.7334, 0.7540, 0.5725, 0.6480],
       device='cuda:0') torch.Size([16])
percent tensor([0.6905, 0.6879, 0.7442, 0.7515, 0.7675, 0.7950, 0.7287, 0.6650, 0.7549,
        0.7208, 0.7489, 0.7100, 0.6895, 0.8274, 0.6532, 0.7335],
       device='cuda:0') torch.Size([16])
percent tensor([0.6390, 0.5896, 0.6707, 0.5920, 0.6923, 0.6810, 0.6625, 0.6284, 0.6166,
        0.5975, 0.6109, 0.6018, 0.5223, 0.5784, 0.5993, 0.6445],
       device='cuda:0') torch.Size([16])
percent tensor([0.9993, 0.9988, 0.9990, 0.9996, 0.9993, 0.9989, 0.9990, 0.9991, 0.9992,
        0.9994, 0.9993, 0.9992, 0.9992, 0.9994, 0.9992, 0.9994],
       device='cuda:0') torch.Size([16])
Epoch: 117 | Batch_idx: 0 |  Loss: (0.1312) |  Loss2: (0.0000) | Acc: (94.00%) (121/128)
Epoch: 117 | Batch_idx: 10 |  Loss: (0.1742) |  Loss2: (0.0000) | Acc: (93.00%) (1314/1408)
Epoch: 117 | Batch_idx: 20 |  Loss: (0.1771) |  Loss2: (0.0000) | Acc: (93.00%) (2515/2688)
Epoch: 117 | Batch_idx: 30 |  Loss: (0.1742) |  Loss2: (0.0000) | Acc: (93.00%) (3720/3968)
Epoch: 117 | Batch_idx: 40 |  Loss: (0.1801) |  Loss2: (0.0000) | Acc: (93.00%) (4905/5248)
Epoch: 117 | Batch_idx: 50 |  Loss: (0.1855) |  Loss2: (0.0000) | Acc: (93.00%) (6089/6528)
Epoch: 117 | Batch_idx: 60 |  Loss: (0.1807) |  Loss2: (0.0000) | Acc: (93.00%) (7304/7808)
Epoch: 117 | Batch_idx: 70 |  Loss: (0.1807) |  Loss2: (0.0000) | Acc: (93.00%) (8510/9088)
Epoch: 117 | Batch_idx: 80 |  Loss: (0.1823) |  Loss2: (0.0000) | Acc: (93.00%) (9714/10368)
Epoch: 117 | Batch_idx: 90 |  Loss: (0.1783) |  Loss2: (0.0000) | Acc: (93.00%) (10933/11648)
Epoch: 117 | Batch_idx: 100 |  Loss: (0.1793) |  Loss2: (0.0000) | Acc: (93.00%) (12129/12928)
Epoch: 117 | Batch_idx: 110 |  Loss: (0.1789) |  Loss2: (0.0000) | Acc: (93.00%) (13336/14208)
Epoch: 117 | Batch_idx: 120 |  Loss: (0.1785) |  Loss2: (0.0000) | Acc: (93.00%) (14534/15488)
Epoch: 117 | Batch_idx: 130 |  Loss: (0.1790) |  Loss2: (0.0000) | Acc: (93.00%) (15726/16768)
Epoch: 117 | Batch_idx: 140 |  Loss: (0.1802) |  Loss2: (0.0000) | Acc: (93.00%) (16925/18048)
Epoch: 117 | Batch_idx: 150 |  Loss: (0.1777) |  Loss2: (0.0000) | Acc: (93.00%) (18146/19328)
Epoch: 117 | Batch_idx: 160 |  Loss: (0.1770) |  Loss2: (0.0000) | Acc: (93.00%) (19348/20608)
Epoch: 117 | Batch_idx: 170 |  Loss: (0.1770) |  Loss2: (0.0000) | Acc: (93.00%) (20551/21888)
Epoch: 117 | Batch_idx: 180 |  Loss: (0.1775) |  Loss2: (0.0000) | Acc: (93.00%) (21740/23168)
Epoch: 117 | Batch_idx: 190 |  Loss: (0.1763) |  Loss2: (0.0000) | Acc: (93.00%) (22953/24448)
Epoch: 117 | Batch_idx: 200 |  Loss: (0.1761) |  Loss2: (0.0000) | Acc: (93.00%) (24159/25728)
Epoch: 117 | Batch_idx: 210 |  Loss: (0.1773) |  Loss2: (0.0000) | Acc: (93.00%) (25347/27008)
Epoch: 117 | Batch_idx: 220 |  Loss: (0.1760) |  Loss2: (0.0000) | Acc: (93.00%) (26558/28288)
Epoch: 117 | Batch_idx: 230 |  Loss: (0.1758) |  Loss2: (0.0000) | Acc: (93.00%) (27767/29568)
Epoch: 117 | Batch_idx: 240 |  Loss: (0.1757) |  Loss2: (0.0000) | Acc: (93.00%) (28961/30848)
Epoch: 117 | Batch_idx: 250 |  Loss: (0.1751) |  Loss2: (0.0000) | Acc: (93.00%) (30176/32128)
Epoch: 117 | Batch_idx: 260 |  Loss: (0.1748) |  Loss2: (0.0000) | Acc: (93.00%) (31384/33408)
Epoch: 117 | Batch_idx: 270 |  Loss: (0.1751) |  Loss2: (0.0000) | Acc: (93.00%) (32574/34688)
Epoch: 117 | Batch_idx: 280 |  Loss: (0.1739) |  Loss2: (0.0000) | Acc: (93.00%) (33794/35968)
Epoch: 117 | Batch_idx: 290 |  Loss: (0.1738) |  Loss2: (0.0000) | Acc: (93.00%) (34990/37248)
Epoch: 117 | Batch_idx: 300 |  Loss: (0.1749) |  Loss2: (0.0000) | Acc: (93.00%) (36184/38528)
Epoch: 117 | Batch_idx: 310 |  Loss: (0.1747) |  Loss2: (0.0000) | Acc: (93.00%) (37389/39808)
Epoch: 117 | Batch_idx: 320 |  Loss: (0.1751) |  Loss2: (0.0000) | Acc: (93.00%) (38581/41088)
Epoch: 117 | Batch_idx: 330 |  Loss: (0.1750) |  Loss2: (0.0000) | Acc: (93.00%) (39790/42368)
Epoch: 117 | Batch_idx: 340 |  Loss: (0.1749) |  Loss2: (0.0000) | Acc: (93.00%) (40989/43648)
Epoch: 117 | Batch_idx: 350 |  Loss: (0.1748) |  Loss2: (0.0000) | Acc: (93.00%) (42191/44928)
Epoch: 117 | Batch_idx: 360 |  Loss: (0.1756) |  Loss2: (0.0000) | Acc: (93.00%) (43373/46208)
Epoch: 117 | Batch_idx: 370 |  Loss: (0.1753) |  Loss2: (0.0000) | Acc: (93.00%) (44587/47488)
Epoch: 117 | Batch_idx: 380 |  Loss: (0.1753) |  Loss2: (0.0000) | Acc: (93.00%) (45784/48768)
Epoch: 117 | Batch_idx: 390 |  Loss: (0.1750) |  Loss2: (0.0000) | Acc: (93.00%) (46949/50000)
# TEST : Loss: (0.3869) | Acc: (88.00%) (8808/10000)
percent tensor([0.6037, 0.5971, 0.6107, 0.5945, 0.6167, 0.6012, 0.6081, 0.5977, 0.6043,
        0.5977, 0.5982, 0.6105, 0.5953, 0.5896, 0.5998, 0.5942],
       device='cuda:0') torch.Size([16])
percent tensor([0.5807, 0.5241, 0.5359, 0.6009, 0.5620, 0.6257, 0.5397, 0.5629, 0.5688,
        0.5336, 0.5555, 0.5266, 0.5271, 0.5989, 0.5642, 0.5831],
       device='cuda:0') torch.Size([16])
percent tensor([0.5277, 0.5707, 0.5047, 0.4724, 0.5168, 0.4752, 0.5702, 0.5276, 0.5161,
        0.5170, 0.5097, 0.5286, 0.5489, 0.5373, 0.5386, 0.5302],
       device='cuda:0') torch.Size([16])
percent tensor([0.6620, 0.6202, 0.6443, 0.6526, 0.6591, 0.6628, 0.6542, 0.6618, 0.6552,
        0.6387, 0.6505, 0.6402, 0.6401, 0.6512, 0.6552, 0.6650],
       device='cuda:0') torch.Size([16])
percent tensor([0.5827, 0.6763, 0.6630, 0.6312, 0.6003, 0.7230, 0.6271, 0.5028, 0.7217,
        0.6310, 0.6861, 0.6450, 0.7303, 0.7537, 0.5653, 0.6485],
       device='cuda:0') torch.Size([16])
percent tensor([0.7024, 0.6985, 0.7528, 0.7600, 0.7746, 0.8013, 0.7391, 0.6742, 0.7627,
        0.7318, 0.7586, 0.7186, 0.6984, 0.8352, 0.6651, 0.7446],
       device='cuda:0') torch.Size([16])
percent tensor([0.6486, 0.6000, 0.6791, 0.5987, 0.6966, 0.6858, 0.6733, 0.6402, 0.6263,
        0.6051, 0.6246, 0.6155, 0.5306, 0.5899, 0.6181, 0.6523],
       device='cuda:0') torch.Size([16])
percent tensor([0.9994, 0.9989, 0.9990, 0.9996, 0.9993, 0.9990, 0.9990, 0.9991, 0.9992,
        0.9995, 0.9993, 0.9993, 0.9992, 0.9994, 0.9992, 0.9994],
       device='cuda:0') torch.Size([16])
Epoch: 118 | Batch_idx: 0 |  Loss: (0.2662) |  Loss2: (0.0000) | Acc: (92.00%) (118/128)
Epoch: 118 | Batch_idx: 10 |  Loss: (0.1916) |  Loss2: (0.0000) | Acc: (93.00%) (1316/1408)
Epoch: 118 | Batch_idx: 20 |  Loss: (0.1802) |  Loss2: (0.0000) | Acc: (94.00%) (2528/2688)
Epoch: 118 | Batch_idx: 30 |  Loss: (0.1742) |  Loss2: (0.0000) | Acc: (94.00%) (3745/3968)
Epoch: 118 | Batch_idx: 40 |  Loss: (0.1739) |  Loss2: (0.0000) | Acc: (94.00%) (4945/5248)
Epoch: 118 | Batch_idx: 50 |  Loss: (0.1750) |  Loss2: (0.0000) | Acc: (94.00%) (6143/6528)
Epoch: 118 | Batch_idx: 60 |  Loss: (0.1771) |  Loss2: (0.0000) | Acc: (94.00%) (7343/7808)
Epoch: 118 | Batch_idx: 70 |  Loss: (0.1751) |  Loss2: (0.0000) | Acc: (94.00%) (8554/9088)
Epoch: 118 | Batch_idx: 80 |  Loss: (0.1754) |  Loss2: (0.0000) | Acc: (94.00%) (9759/10368)
Epoch: 118 | Batch_idx: 90 |  Loss: (0.1747) |  Loss2: (0.0000) | Acc: (94.00%) (10966/11648)
Epoch: 118 | Batch_idx: 100 |  Loss: (0.1715) |  Loss2: (0.0000) | Acc: (94.00%) (12181/12928)
Epoch: 118 | Batch_idx: 110 |  Loss: (0.1704) |  Loss2: (0.0000) | Acc: (94.00%) (13386/14208)
Epoch: 118 | Batch_idx: 120 |  Loss: (0.1700) |  Loss2: (0.0000) | Acc: (94.00%) (14597/15488)
Epoch: 118 | Batch_idx: 130 |  Loss: (0.1703) |  Loss2: (0.0000) | Acc: (94.00%) (15800/16768)
Epoch: 118 | Batch_idx: 140 |  Loss: (0.1687) |  Loss2: (0.0000) | Acc: (94.00%) (17019/18048)
Epoch: 118 | Batch_idx: 150 |  Loss: (0.1683) |  Loss2: (0.0000) | Acc: (94.00%) (18231/19328)
Epoch: 118 | Batch_idx: 160 |  Loss: (0.1684) |  Loss2: (0.0000) | Acc: (94.00%) (19442/20608)
Epoch: 118 | Batch_idx: 170 |  Loss: (0.1690) |  Loss2: (0.0000) | Acc: (94.00%) (20636/21888)
Epoch: 118 | Batch_idx: 180 |  Loss: (0.1688) |  Loss2: (0.0000) | Acc: (94.00%) (21844/23168)
Epoch: 118 | Batch_idx: 190 |  Loss: (0.1688) |  Loss2: (0.0000) | Acc: (94.00%) (23052/24448)
Epoch: 118 | Batch_idx: 200 |  Loss: (0.1679) |  Loss2: (0.0000) | Acc: (94.00%) (24265/25728)
Epoch: 118 | Batch_idx: 210 |  Loss: (0.1680) |  Loss2: (0.0000) | Acc: (94.00%) (25467/27008)
Epoch: 118 | Batch_idx: 220 |  Loss: (0.1688) |  Loss2: (0.0000) | Acc: (94.00%) (26664/28288)
Epoch: 118 | Batch_idx: 230 |  Loss: (0.1688) |  Loss2: (0.0000) | Acc: (94.00%) (27873/29568)
Epoch: 118 | Batch_idx: 240 |  Loss: (0.1690) |  Loss2: (0.0000) | Acc: (94.00%) (29074/30848)
Epoch: 118 | Batch_idx: 250 |  Loss: (0.1681) |  Loss2: (0.0000) | Acc: (94.00%) (30288/32128)
Epoch: 118 | Batch_idx: 260 |  Loss: (0.1677) |  Loss2: (0.0000) | Acc: (94.00%) (31503/33408)
Epoch: 118 | Batch_idx: 270 |  Loss: (0.1678) |  Loss2: (0.0000) | Acc: (94.00%) (32710/34688)
Epoch: 118 | Batch_idx: 280 |  Loss: (0.1681) |  Loss2: (0.0000) | Acc: (94.00%) (33918/35968)
Epoch: 118 | Batch_idx: 290 |  Loss: (0.1685) |  Loss2: (0.0000) | Acc: (94.00%) (35124/37248)
Epoch: 118 | Batch_idx: 300 |  Loss: (0.1680) |  Loss2: (0.0000) | Acc: (94.00%) (36346/38528)
Epoch: 118 | Batch_idx: 310 |  Loss: (0.1681) |  Loss2: (0.0000) | Acc: (94.00%) (37554/39808)
Epoch: 118 | Batch_idx: 320 |  Loss: (0.1677) |  Loss2: (0.0000) | Acc: (94.00%) (38765/41088)
Epoch: 118 | Batch_idx: 330 |  Loss: (0.1671) |  Loss2: (0.0000) | Acc: (94.00%) (39994/42368)
Epoch: 118 | Batch_idx: 340 |  Loss: (0.1669) |  Loss2: (0.0000) | Acc: (94.00%) (41201/43648)
Epoch: 118 | Batch_idx: 350 |  Loss: (0.1673) |  Loss2: (0.0000) | Acc: (94.00%) (42391/44928)
Epoch: 118 | Batch_idx: 360 |  Loss: (0.1669) |  Loss2: (0.0000) | Acc: (94.00%) (43600/46208)
Epoch: 118 | Batch_idx: 370 |  Loss: (0.1674) |  Loss2: (0.0000) | Acc: (94.00%) (44806/47488)
Epoch: 118 | Batch_idx: 380 |  Loss: (0.1670) |  Loss2: (0.0000) | Acc: (94.00%) (46023/48768)
Epoch: 118 | Batch_idx: 390 |  Loss: (0.1673) |  Loss2: (0.0000) | Acc: (94.00%) (47174/50000)
# TEST : Loss: (0.3855) | Acc: (88.00%) (8800/10000)
percent tensor([0.6043, 0.5980, 0.6111, 0.5949, 0.6172, 0.6018, 0.6088, 0.5981, 0.6050,
        0.5983, 0.5990, 0.6108, 0.5959, 0.5906, 0.6004, 0.5948],
       device='cuda:0') torch.Size([16])
percent tensor([0.5761, 0.5193, 0.5297, 0.5964, 0.5567, 0.6218, 0.5349, 0.5580, 0.5643,
        0.5289, 0.5508, 0.5216, 0.5220, 0.5960, 0.5599, 0.5787],
       device='cuda:0') torch.Size([16])
percent tensor([0.5296, 0.5711, 0.5040, 0.4730, 0.5166, 0.4763, 0.5709, 0.5265, 0.5162,
        0.5178, 0.5117, 0.5267, 0.5492, 0.5375, 0.5393, 0.5319],
       device='cuda:0') torch.Size([16])
percent tensor([0.6570, 0.6168, 0.6392, 0.6475, 0.6543, 0.6573, 0.6495, 0.6564, 0.6506,
        0.6349, 0.6461, 0.6357, 0.6358, 0.6473, 0.6505, 0.6599],
       device='cuda:0') torch.Size([16])
percent tensor([0.5879, 0.6775, 0.6731, 0.6362, 0.6076, 0.7315, 0.6323, 0.5088, 0.7281,
        0.6352, 0.6916, 0.6482, 0.7321, 0.7591, 0.5658, 0.6531],
       device='cuda:0') torch.Size([16])
percent tensor([0.7059, 0.7025, 0.7563, 0.7623, 0.7762, 0.8049, 0.7426, 0.6740, 0.7662,
        0.7375, 0.7619, 0.7236, 0.7020, 0.8389, 0.6687, 0.7475],
       device='cuda:0') torch.Size([16])
percent tensor([0.6571, 0.6087, 0.6862, 0.6012, 0.7005, 0.6932, 0.6817, 0.6483, 0.6344,
        0.6131, 0.6330, 0.6241, 0.5377, 0.5974, 0.6318, 0.6589],
       device='cuda:0') torch.Size([16])
percent tensor([0.9994, 0.9989, 0.9991, 0.9996, 0.9993, 0.9991, 0.9991, 0.9991, 0.9993,
        0.9995, 0.9994, 0.9993, 0.9993, 0.9995, 0.9992, 0.9994],
       device='cuda:0') torch.Size([16])
Epoch: 119 | Batch_idx: 0 |  Loss: (0.1718) |  Loss2: (0.0000) | Acc: (94.00%) (121/128)
Epoch: 119 | Batch_idx: 10 |  Loss: (0.1740) |  Loss2: (0.0000) | Acc: (93.00%) (1315/1408)
Epoch: 119 | Batch_idx: 20 |  Loss: (0.1732) |  Loss2: (0.0000) | Acc: (94.00%) (2528/2688)
Epoch: 119 | Batch_idx: 30 |  Loss: (0.1744) |  Loss2: (0.0000) | Acc: (93.00%) (3723/3968)
Epoch: 119 | Batch_idx: 40 |  Loss: (0.1700) |  Loss2: (0.0000) | Acc: (94.00%) (4936/5248)
Epoch: 119 | Batch_idx: 50 |  Loss: (0.1676) |  Loss2: (0.0000) | Acc: (94.00%) (6144/6528)
Epoch: 119 | Batch_idx: 60 |  Loss: (0.1675) |  Loss2: (0.0000) | Acc: (94.00%) (7359/7808)
Epoch: 119 | Batch_idx: 70 |  Loss: (0.1671) |  Loss2: (0.0000) | Acc: (94.00%) (8570/9088)
Epoch: 119 | Batch_idx: 80 |  Loss: (0.1638) |  Loss2: (0.0000) | Acc: (94.00%) (9792/10368)
Epoch: 119 | Batch_idx: 90 |  Loss: (0.1635) |  Loss2: (0.0000) | Acc: (94.00%) (10999/11648)
Epoch: 119 | Batch_idx: 100 |  Loss: (0.1638) |  Loss2: (0.0000) | Acc: (94.00%) (12210/12928)
Epoch: 119 | Batch_idx: 110 |  Loss: (0.1641) |  Loss2: (0.0000) | Acc: (94.00%) (13405/14208)
Epoch: 119 | Batch_idx: 120 |  Loss: (0.1630) |  Loss2: (0.0000) | Acc: (94.00%) (14619/15488)
Epoch: 119 | Batch_idx: 130 |  Loss: (0.1638) |  Loss2: (0.0000) | Acc: (94.00%) (15829/16768)
Epoch: 119 | Batch_idx: 140 |  Loss: (0.1656) |  Loss2: (0.0000) | Acc: (94.00%) (17020/18048)
Epoch: 119 | Batch_idx: 150 |  Loss: (0.1649) |  Loss2: (0.0000) | Acc: (94.00%) (18238/19328)
Epoch: 119 | Batch_idx: 160 |  Loss: (0.1655) |  Loss2: (0.0000) | Acc: (94.00%) (19440/20608)
Epoch: 119 | Batch_idx: 170 |  Loss: (0.1646) |  Loss2: (0.0000) | Acc: (94.00%) (20651/21888)
Epoch: 119 | Batch_idx: 180 |  Loss: (0.1652) |  Loss2: (0.0000) | Acc: (94.00%) (21854/23168)
Epoch: 119 | Batch_idx: 190 |  Loss: (0.1658) |  Loss2: (0.0000) | Acc: (94.00%) (23052/24448)
Epoch: 119 | Batch_idx: 200 |  Loss: (0.1652) |  Loss2: (0.0000) | Acc: (94.00%) (24263/25728)
Epoch: 119 | Batch_idx: 210 |  Loss: (0.1648) |  Loss2: (0.0000) | Acc: (94.00%) (25478/27008)
Epoch: 119 | Batch_idx: 220 |  Loss: (0.1648) |  Loss2: (0.0000) | Acc: (94.00%) (26680/28288)
Epoch: 119 | Batch_idx: 230 |  Loss: (0.1653) |  Loss2: (0.0000) | Acc: (94.00%) (27875/29568)
Epoch: 119 | Batch_idx: 240 |  Loss: (0.1648) |  Loss2: (0.0000) | Acc: (94.00%) (29089/30848)
Epoch: 119 | Batch_idx: 250 |  Loss: (0.1649) |  Loss2: (0.0000) | Acc: (94.00%) (30301/32128)
Epoch: 119 | Batch_idx: 260 |  Loss: (0.1653) |  Loss2: (0.0000) | Acc: (94.00%) (31495/33408)
Epoch: 119 | Batch_idx: 270 |  Loss: (0.1648) |  Loss2: (0.0000) | Acc: (94.00%) (32709/34688)
Epoch: 119 | Batch_idx: 280 |  Loss: (0.1645) |  Loss2: (0.0000) | Acc: (94.00%) (33922/35968)
Epoch: 119 | Batch_idx: 290 |  Loss: (0.1649) |  Loss2: (0.0000) | Acc: (94.00%) (35126/37248)
Epoch: 119 | Batch_idx: 300 |  Loss: (0.1649) |  Loss2: (0.0000) | Acc: (94.00%) (36331/38528)
Epoch: 119 | Batch_idx: 310 |  Loss: (0.1649) |  Loss2: (0.0000) | Acc: (94.00%) (37538/39808)
Epoch: 119 | Batch_idx: 320 |  Loss: (0.1651) |  Loss2: (0.0000) | Acc: (94.00%) (38736/41088)
Epoch: 119 | Batch_idx: 330 |  Loss: (0.1645) |  Loss2: (0.0000) | Acc: (94.00%) (39957/42368)
Epoch: 119 | Batch_idx: 340 |  Loss: (0.1650) |  Loss2: (0.0000) | Acc: (94.00%) (41157/43648)
Epoch: 119 | Batch_idx: 350 |  Loss: (0.1649) |  Loss2: (0.0000) | Acc: (94.00%) (42369/44928)
Epoch: 119 | Batch_idx: 360 |  Loss: (0.1649) |  Loss2: (0.0000) | Acc: (94.00%) (43578/46208)
Epoch: 119 | Batch_idx: 370 |  Loss: (0.1656) |  Loss2: (0.0000) | Acc: (94.00%) (44774/47488)
Epoch: 119 | Batch_idx: 380 |  Loss: (0.1651) |  Loss2: (0.0000) | Acc: (94.00%) (45993/48768)
Epoch: 119 | Batch_idx: 390 |  Loss: (0.1648) |  Loss2: (0.0000) | Acc: (94.00%) (47171/50000)
# TEST : Loss: (0.3798) | Acc: (88.00%) (8811/10000)
percent tensor([0.6052, 0.5993, 0.6118, 0.5959, 0.6179, 0.6027, 0.6099, 0.5995, 0.6061,
        0.5996, 0.6000, 0.6117, 0.5969, 0.5924, 0.6014, 0.5959],
       device='cuda:0') torch.Size([16])
percent tensor([0.5853, 0.5295, 0.5387, 0.6054, 0.5658, 0.6298, 0.5448, 0.5674, 0.5741,
        0.5390, 0.5615, 0.5302, 0.5315, 0.6056, 0.5690, 0.5877],
       device='cuda:0') torch.Size([16])
percent tensor([0.5270, 0.5717, 0.4999, 0.4686, 0.5133, 0.4697, 0.5704, 0.5224, 0.5136,
        0.5186, 0.5109, 0.5255, 0.5484, 0.5367, 0.5371, 0.5289],
       device='cuda:0') torch.Size([16])
percent tensor([0.6584, 0.6186, 0.6408, 0.6496, 0.6557, 0.6579, 0.6508, 0.6577, 0.6520,
        0.6371, 0.6482, 0.6374, 0.6370, 0.6492, 0.6514, 0.6607],
       device='cuda:0') torch.Size([16])
percent tensor([0.5908, 0.6815, 0.6726, 0.6343, 0.6108, 0.7257, 0.6364, 0.5119, 0.7316,
        0.6400, 0.6996, 0.6511, 0.7354, 0.7632, 0.5694, 0.6534],
       device='cuda:0') torch.Size([16])
percent tensor([0.7113, 0.7086, 0.7596, 0.7654, 0.7781, 0.8072, 0.7467, 0.6764, 0.7718,
        0.7439, 0.7682, 0.7290, 0.7094, 0.8443, 0.6730, 0.7530],
       device='cuda:0') torch.Size([16])
percent tensor([0.6566, 0.6079, 0.6859, 0.5978, 0.6969, 0.6907, 0.6843, 0.6471, 0.6377,
        0.6101, 0.6334, 0.6258, 0.5367, 0.5973, 0.6339, 0.6559],
       device='cuda:0') torch.Size([16])
percent tensor([0.9994, 0.9989, 0.9991, 0.9996, 0.9993, 0.9991, 0.9991, 0.9991, 0.9993,
        0.9995, 0.9994, 0.9993, 0.9993, 0.9995, 0.9992, 0.9994],
       device='cuda:0') torch.Size([16])
True Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=128, out_features=16, bias=False)
False Linear(in_features=16, out_features=2, bias=False)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=128, out_features=16, bias=False)
False Linear(in_features=16, out_features=2, bias=False)
True Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=256, out_features=32, bias=False)
False Linear(in_features=32, out_features=2, bias=False)
True Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=256, out_features=32, bias=False)
False Linear(in_features=32, out_features=2, bias=False)
True Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=512, out_features=64, bias=False)
False Linear(in_features=64, out_features=2, bias=False)
True Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=512, out_features=64, bias=False)
False Linear(in_features=64, out_features=2, bias=False)
True Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1024, out_features=128, bias=False)
False Linear(in_features=128, out_features=2, bias=False)
True Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1024, out_features=128, bias=False)
False Linear(in_features=128, out_features=2, bias=False)
True Linear(in_features=512, out_features=10, bias=True)
Epoch: 120 | Batch_idx: 0 |  Loss: (0.2003) |  Loss2: (0.0000) | Acc: (92.00%) (118/128)
Epoch: 120 | Batch_idx: 10 |  Loss: (0.1554) |  Loss2: (0.0000) | Acc: (94.00%) (1331/1408)
Epoch: 120 | Batch_idx: 20 |  Loss: (0.1553) |  Loss2: (0.0000) | Acc: (94.00%) (2537/2688)
Epoch: 120 | Batch_idx: 30 |  Loss: (0.1578) |  Loss2: (0.0000) | Acc: (94.00%) (3747/3968)
Epoch: 120 | Batch_idx: 40 |  Loss: (0.1652) |  Loss2: (0.0000) | Acc: (94.00%) (4945/5248)
Epoch: 120 | Batch_idx: 50 |  Loss: (0.1689) |  Loss2: (0.0000) | Acc: (94.00%) (6149/6528)
Epoch: 120 | Batch_idx: 60 |  Loss: (0.1704) |  Loss2: (0.0000) | Acc: (94.00%) (7351/7808)
Epoch: 120 | Batch_idx: 70 |  Loss: (0.1699) |  Loss2: (0.0000) | Acc: (94.00%) (8556/9088)
Epoch: 120 | Batch_idx: 80 |  Loss: (0.1702) |  Loss2: (0.0000) | Acc: (94.00%) (9758/10368)
Epoch: 120 | Batch_idx: 90 |  Loss: (0.1683) |  Loss2: (0.0000) | Acc: (94.00%) (10968/11648)
Epoch: 120 | Batch_idx: 100 |  Loss: (0.1679) |  Loss2: (0.0000) | Acc: (94.00%) (12178/12928)
Epoch: 120 | Batch_idx: 110 |  Loss: (0.1676) |  Loss2: (0.0000) | Acc: (94.00%) (13392/14208)
Epoch: 120 | Batch_idx: 120 |  Loss: (0.1699) |  Loss2: (0.0000) | Acc: (94.00%) (14578/15488)
Epoch: 120 | Batch_idx: 130 |  Loss: (0.1695) |  Loss2: (0.0000) | Acc: (94.00%) (15785/16768)
Epoch: 120 | Batch_idx: 140 |  Loss: (0.1689) |  Loss2: (0.0000) | Acc: (94.00%) (16995/18048)
Epoch: 120 | Batch_idx: 150 |  Loss: (0.1689) |  Loss2: (0.0000) | Acc: (94.00%) (18201/19328)
Epoch: 120 | Batch_idx: 160 |  Loss: (0.1709) |  Loss2: (0.0000) | Acc: (94.00%) (19396/20608)
Epoch: 120 | Batch_idx: 170 |  Loss: (0.1711) |  Loss2: (0.0000) | Acc: (94.00%) (20598/21888)
Epoch: 120 | Batch_idx: 180 |  Loss: (0.1703) |  Loss2: (0.0000) | Acc: (94.00%) (21818/23168)
Epoch: 120 | Batch_idx: 190 |  Loss: (0.1703) |  Loss2: (0.0000) | Acc: (94.00%) (23019/24448)
Epoch: 120 | Batch_idx: 200 |  Loss: (0.1689) |  Loss2: (0.0000) | Acc: (94.00%) (24237/25728)
Epoch: 120 | Batch_idx: 210 |  Loss: (0.1698) |  Loss2: (0.0000) | Acc: (94.00%) (25441/27008)
Epoch: 120 | Batch_idx: 220 |  Loss: (0.1703) |  Loss2: (0.0000) | Acc: (94.00%) (26646/28288)
Epoch: 120 | Batch_idx: 230 |  Loss: (0.1706) |  Loss2: (0.0000) | Acc: (94.00%) (27850/29568)
Epoch: 120 | Batch_idx: 240 |  Loss: (0.1708) |  Loss2: (0.0000) | Acc: (94.00%) (29061/30848)
Epoch: 120 | Batch_idx: 250 |  Loss: (0.1717) |  Loss2: (0.0000) | Acc: (94.00%) (30259/32128)
Epoch: 120 | Batch_idx: 260 |  Loss: (0.1713) |  Loss2: (0.0000) | Acc: (94.00%) (31469/33408)
Epoch: 120 | Batch_idx: 270 |  Loss: (0.1721) |  Loss2: (0.0000) | Acc: (94.00%) (32665/34688)
Epoch: 120 | Batch_idx: 280 |  Loss: (0.1722) |  Loss2: (0.0000) | Acc: (94.00%) (33869/35968)
Epoch: 120 | Batch_idx: 290 |  Loss: (0.1719) |  Loss2: (0.0000) | Acc: (94.00%) (35070/37248)
Epoch: 120 | Batch_idx: 300 |  Loss: (0.1718) |  Loss2: (0.0000) | Acc: (94.00%) (36275/38528)
Epoch: 120 | Batch_idx: 310 |  Loss: (0.1719) |  Loss2: (0.0000) | Acc: (94.00%) (37472/39808)
Epoch: 120 | Batch_idx: 320 |  Loss: (0.1720) |  Loss2: (0.0000) | Acc: (94.00%) (38671/41088)
Epoch: 120 | Batch_idx: 330 |  Loss: (0.1716) |  Loss2: (0.0000) | Acc: (94.00%) (39878/42368)
Epoch: 120 | Batch_idx: 340 |  Loss: (0.1721) |  Loss2: (0.0000) | Acc: (94.00%) (41081/43648)
Epoch: 120 | Batch_idx: 350 |  Loss: (0.1717) |  Loss2: (0.0000) | Acc: (94.00%) (42284/44928)
Epoch: 120 | Batch_idx: 360 |  Loss: (0.1719) |  Loss2: (0.0000) | Acc: (94.00%) (43480/46208)
Epoch: 120 | Batch_idx: 370 |  Loss: (0.1725) |  Loss2: (0.0000) | Acc: (94.00%) (44674/47488)
Epoch: 120 | Batch_idx: 380 |  Loss: (0.1723) |  Loss2: (0.0000) | Acc: (94.00%) (45883/48768)
Epoch: 120 | Batch_idx: 390 |  Loss: (0.1726) |  Loss2: (0.0000) | Acc: (94.00%) (47039/50000)
=> saving checkpoint 'drive/app/torch/save_Routing_Gate_2/checkpoint_120.pth.tar'
# TEST : Loss: (0.4346) | Acc: (86.00%) (8671/10000)
percent tensor([0.6017, 0.6000, 0.6060, 0.5941, 0.6135, 0.6005, 0.6082, 0.5974, 0.6062,
        0.5979, 0.6013, 0.6045, 0.5957, 0.5966, 0.6004, 0.5952],
       device='cuda:0') torch.Size([16])
percent tensor([0.5832, 0.5282, 0.5327, 0.6000, 0.5649, 0.6256, 0.5413, 0.5681, 0.5703,
        0.5363, 0.5571, 0.5223, 0.5277, 0.6004, 0.5694, 0.5846],
       device='cuda:0') torch.Size([16])
percent tensor([0.5243, 0.5679, 0.5046, 0.4763, 0.5144, 0.4637, 0.5699, 0.5262, 0.5159,
        0.5213, 0.5118, 0.5301, 0.5515, 0.5462, 0.5334, 0.5276],
       device='cuda:0') torch.Size([16])
percent tensor([0.6618, 0.6215, 0.6463, 0.6513, 0.6598, 0.6585, 0.6506, 0.6622, 0.6589,
        0.6397, 0.6511, 0.6383, 0.6395, 0.6509, 0.6529, 0.6638],
       device='cuda:0') torch.Size([16])
percent tensor([0.5636, 0.6800, 0.6567, 0.6348, 0.5928, 0.6897, 0.6150, 0.5135, 0.7278,
        0.6189, 0.6873, 0.6608, 0.7325, 0.7544, 0.5578, 0.6397],
       device='cuda:0') torch.Size([16])
percent tensor([0.7147, 0.7018, 0.7561, 0.7572, 0.7879, 0.7945, 0.7401, 0.6855, 0.7830,
        0.7372, 0.7772, 0.7174, 0.7195, 0.8282, 0.6780, 0.7638],
       device='cuda:0') torch.Size([16])
percent tensor([0.6584, 0.6070, 0.7040, 0.6123, 0.7215, 0.6876, 0.6824, 0.6516, 0.6388,
        0.6014, 0.6142, 0.6197, 0.5169, 0.6106, 0.6400, 0.6490],
       device='cuda:0') torch.Size([16])
percent tensor([0.9995, 0.9990, 0.9989, 0.9995, 0.9993, 0.9993, 0.9991, 0.9991, 0.9993,
        0.9996, 0.9995, 0.9996, 0.9991, 0.9993, 0.9992, 0.9993],
       device='cuda:0') torch.Size([16])
Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 3, 3, 3]) tensor(180.8629, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(821.2040, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(824.1531, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([128, 64, 3, 3]) tensor(1527.7100, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([128, 64, 1, 1]) tensor(492.4558, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([128, 128, 3, 3]) tensor(2248.8721, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([256, 128, 3, 3]) tensor(4283.1206, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([256, 128, 1, 1]) tensor(1388.6658, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([256, 256, 3, 3]) tensor(6200.5811, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([512, 256, 3, 3]) tensor(11828.3838, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([512, 256, 1, 1]) tensor(3911.5557, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([512, 512, 3, 3]) tensor(16528.7559, device='cuda:0', grad_fn=<NormBackward0>)
Epoch: 121 | Batch_idx: 0 |  Loss: (0.1501) |  Loss2: (0.0000) | Acc: (93.00%) (120/128)
Epoch: 121 | Batch_idx: 10 |  Loss: (0.1811) |  Loss2: (0.0000) | Acc: (93.00%) (1317/1408)
Epoch: 121 | Batch_idx: 20 |  Loss: (0.1650) |  Loss2: (0.0000) | Acc: (94.00%) (2535/2688)
Epoch: 121 | Batch_idx: 30 |  Loss: (0.1704) |  Loss2: (0.0000) | Acc: (94.00%) (3736/3968)
Epoch: 121 | Batch_idx: 40 |  Loss: (0.1731) |  Loss2: (0.0000) | Acc: (94.00%) (4936/5248)
Epoch: 121 | Batch_idx: 50 |  Loss: (0.1684) |  Loss2: (0.0000) | Acc: (94.00%) (6150/6528)
Epoch: 121 | Batch_idx: 60 |  Loss: (0.1740) |  Loss2: (0.0000) | Acc: (93.00%) (7336/7808)
Epoch: 121 | Batch_idx: 70 |  Loss: (0.1710) |  Loss2: (0.0000) | Acc: (94.00%) (8548/9088)
Epoch: 121 | Batch_idx: 80 |  Loss: (0.1688) |  Loss2: (0.0000) | Acc: (94.00%) (9758/10368)
Epoch: 121 | Batch_idx: 90 |  Loss: (0.1691) |  Loss2: (0.0000) | Acc: (94.00%) (10965/11648)
Epoch: 121 | Batch_idx: 100 |  Loss: (0.1685) |  Loss2: (0.0000) | Acc: (94.00%) (12174/12928)
Epoch: 121 | Batch_idx: 110 |  Loss: (0.1675) |  Loss2: (0.0000) | Acc: (94.00%) (13392/14208)
Epoch: 121 | Batch_idx: 120 |  Loss: (0.1698) |  Loss2: (0.0000) | Acc: (94.00%) (14583/15488)
Epoch: 121 | Batch_idx: 130 |  Loss: (0.1707) |  Loss2: (0.0000) | Acc: (94.00%) (15786/16768)
Epoch: 121 | Batch_idx: 140 |  Loss: (0.1708) |  Loss2: (0.0000) | Acc: (94.00%) (16994/18048)
Epoch: 121 | Batch_idx: 150 |  Loss: (0.1706) |  Loss2: (0.0000) | Acc: (94.00%) (18205/19328)
Epoch: 121 | Batch_idx: 160 |  Loss: (0.1696) |  Loss2: (0.0000) | Acc: (94.00%) (19429/20608)
Epoch: 121 | Batch_idx: 170 |  Loss: (0.1696) |  Loss2: (0.0000) | Acc: (94.00%) (20641/21888)
Epoch: 121 | Batch_idx: 180 |  Loss: (0.1700) |  Loss2: (0.0000) | Acc: (94.00%) (21845/23168)
Epoch: 121 | Batch_idx: 190 |  Loss: (0.1707) |  Loss2: (0.0000) | Acc: (94.00%) (23045/24448)
Epoch: 121 | Batch_idx: 200 |  Loss: (0.1698) |  Loss2: (0.0000) | Acc: (94.00%) (24260/25728)
Epoch: 121 | Batch_idx: 210 |  Loss: (0.1692) |  Loss2: (0.0000) | Acc: (94.00%) (25464/27008)
Epoch: 121 | Batch_idx: 220 |  Loss: (0.1703) |  Loss2: (0.0000) | Acc: (94.00%) (26659/28288)
Epoch: 121 | Batch_idx: 230 |  Loss: (0.1702) |  Loss2: (0.0000) | Acc: (94.00%) (27864/29568)
Epoch: 121 | Batch_idx: 240 |  Loss: (0.1705) |  Loss2: (0.0000) | Acc: (94.00%) (29064/30848)
Epoch: 121 | Batch_idx: 250 |  Loss: (0.1702) |  Loss2: (0.0000) | Acc: (94.00%) (30268/32128)
Epoch: 121 | Batch_idx: 260 |  Loss: (0.1702) |  Loss2: (0.0000) | Acc: (94.00%) (31463/33408)
Epoch: 121 | Batch_idx: 270 |  Loss: (0.1693) |  Loss2: (0.0000) | Acc: (94.00%) (32667/34688)
Epoch: 121 | Batch_idx: 280 |  Loss: (0.1691) |  Loss2: (0.0000) | Acc: (94.00%) (33876/35968)
Epoch: 121 | Batch_idx: 290 |  Loss: (0.1694) |  Loss2: (0.0000) | Acc: (94.00%) (35075/37248)
Epoch: 121 | Batch_idx: 300 |  Loss: (0.1695) |  Loss2: (0.0000) | Acc: (94.00%) (36280/38528)
Epoch: 121 | Batch_idx: 310 |  Loss: (0.1693) |  Loss2: (0.0000) | Acc: (94.00%) (37486/39808)
Epoch: 121 | Batch_idx: 320 |  Loss: (0.1697) |  Loss2: (0.0000) | Acc: (94.00%) (38677/41088)
Epoch: 121 | Batch_idx: 330 |  Loss: (0.1701) |  Loss2: (0.0000) | Acc: (94.00%) (39882/42368)
Epoch: 121 | Batch_idx: 340 |  Loss: (0.1703) |  Loss2: (0.0000) | Acc: (94.00%) (41077/43648)
Epoch: 121 | Batch_idx: 350 |  Loss: (0.1698) |  Loss2: (0.0000) | Acc: (94.00%) (42287/44928)
Epoch: 121 | Batch_idx: 360 |  Loss: (0.1702) |  Loss2: (0.0000) | Acc: (94.00%) (43492/46208)
Epoch: 121 | Batch_idx: 370 |  Loss: (0.1705) |  Loss2: (0.0000) | Acc: (94.00%) (44695/47488)
Epoch: 121 | Batch_idx: 380 |  Loss: (0.1706) |  Loss2: (0.0000) | Acc: (94.00%) (45898/48768)
Epoch: 121 | Batch_idx: 390 |  Loss: (0.1713) |  Loss2: (0.0000) | Acc: (94.00%) (47042/50000)
# TEST : Loss: (0.4332) | Acc: (86.00%) (8677/10000)
percent tensor([0.6050, 0.5978, 0.6125, 0.5961, 0.6188, 0.6044, 0.6085, 0.5976, 0.6055,
        0.5987, 0.6000, 0.6100, 0.5965, 0.5893, 0.6011, 0.5959],
       device='cuda:0') torch.Size([16])
percent tensor([0.5771, 0.5248, 0.5295, 0.6009, 0.5670, 0.6293, 0.5419, 0.5651, 0.5686,
        0.5351, 0.5561, 0.5260, 0.5269, 0.6029, 0.5696, 0.5836],
       device='cuda:0') torch.Size([16])
percent tensor([0.5334, 0.5691, 0.5067, 0.4783, 0.5146, 0.4653, 0.5717, 0.5280, 0.5203,
        0.5231, 0.5174, 0.5361, 0.5563, 0.5334, 0.5350, 0.5286],
       device='cuda:0') torch.Size([16])
percent tensor([0.6596, 0.6197, 0.6395, 0.6522, 0.6578, 0.6617, 0.6529, 0.6563, 0.6531,
        0.6374, 0.6466, 0.6381, 0.6386, 0.6485, 0.6550, 0.6638],
       device='cuda:0') torch.Size([16])
percent tensor([0.5824, 0.6867, 0.6682, 0.6153, 0.6080, 0.6850, 0.6235, 0.5216, 0.7320,
        0.6160, 0.6945, 0.6629, 0.7420, 0.7336, 0.5621, 0.6372],
       device='cuda:0') torch.Size([16])
percent tensor([0.7113, 0.7115, 0.7607, 0.7597, 0.7947, 0.8010, 0.7421, 0.6805, 0.7612,
        0.7343, 0.7657, 0.7188, 0.7002, 0.8359, 0.6658, 0.7593],
       device='cuda:0') torch.Size([16])
percent tensor([0.6626, 0.6042, 0.6864, 0.6226, 0.7179, 0.6918, 0.6833, 0.6557, 0.6170,
        0.6273, 0.6199, 0.6263, 0.5286, 0.6314, 0.6322, 0.6577],
       device='cuda:0') torch.Size([16])
percent tensor([0.9995, 0.9990, 0.9990, 0.9992, 0.9993, 0.9991, 0.9990, 0.9993, 0.9992,
        0.9996, 0.9993, 0.9994, 0.9992, 0.9992, 0.9991, 0.9993],
       device='cuda:0') torch.Size([16])
Epoch: 122 | Batch_idx: 0 |  Loss: (0.1636) |  Loss2: (0.0000) | Acc: (92.00%) (119/128)
Epoch: 122 | Batch_idx: 10 |  Loss: (0.1446) |  Loss2: (0.0000) | Acc: (95.00%) (1339/1408)
Epoch: 122 | Batch_idx: 20 |  Loss: (0.1572) |  Loss2: (0.0000) | Acc: (94.00%) (2539/2688)
Epoch: 122 | Batch_idx: 30 |  Loss: (0.1644) |  Loss2: (0.0000) | Acc: (94.00%) (3742/3968)
Epoch: 122 | Batch_idx: 40 |  Loss: (0.1666) |  Loss2: (0.0000) | Acc: (94.00%) (4940/5248)
Epoch: 122 | Batch_idx: 50 |  Loss: (0.1631) |  Loss2: (0.0000) | Acc: (94.00%) (6156/6528)
Epoch: 122 | Batch_idx: 60 |  Loss: (0.1615) |  Loss2: (0.0000) | Acc: (94.00%) (7362/7808)
Epoch: 122 | Batch_idx: 70 |  Loss: (0.1638) |  Loss2: (0.0000) | Acc: (94.00%) (8560/9088)
Epoch: 122 | Batch_idx: 80 |  Loss: (0.1626) |  Loss2: (0.0000) | Acc: (94.00%) (9772/10368)
Epoch: 122 | Batch_idx: 90 |  Loss: (0.1646) |  Loss2: (0.0000) | Acc: (94.00%) (10965/11648)
Epoch: 122 | Batch_idx: 100 |  Loss: (0.1648) |  Loss2: (0.0000) | Acc: (94.00%) (12164/12928)
Epoch: 122 | Batch_idx: 110 |  Loss: (0.1655) |  Loss2: (0.0000) | Acc: (94.00%) (13369/14208)
Epoch: 122 | Batch_idx: 120 |  Loss: (0.1660) |  Loss2: (0.0000) | Acc: (94.00%) (14573/15488)
Epoch: 122 | Batch_idx: 130 |  Loss: (0.1681) |  Loss2: (0.0000) | Acc: (94.00%) (15769/16768)
Epoch: 122 | Batch_idx: 140 |  Loss: (0.1681) |  Loss2: (0.0000) | Acc: (94.00%) (16982/18048)
Epoch: 122 | Batch_idx: 150 |  Loss: (0.1683) |  Loss2: (0.0000) | Acc: (94.00%) (18177/19328)
Epoch: 122 | Batch_idx: 160 |  Loss: (0.1675) |  Loss2: (0.0000) | Acc: (94.00%) (19387/20608)
Epoch: 122 | Batch_idx: 170 |  Loss: (0.1656) |  Loss2: (0.0000) | Acc: (94.00%) (20610/21888)
Epoch: 122 | Batch_idx: 180 |  Loss: (0.1648) |  Loss2: (0.0000) | Acc: (94.00%) (21816/23168)
Epoch: 122 | Batch_idx: 190 |  Loss: (0.1643) |  Loss2: (0.0000) | Acc: (94.00%) (23017/24448)
Epoch: 122 | Batch_idx: 200 |  Loss: (0.1646) |  Loss2: (0.0000) | Acc: (94.00%) (24217/25728)
Epoch: 122 | Batch_idx: 210 |  Loss: (0.1643) |  Loss2: (0.0000) | Acc: (94.00%) (25434/27008)
Epoch: 122 | Batch_idx: 220 |  Loss: (0.1651) |  Loss2: (0.0000) | Acc: (94.00%) (26640/28288)
Epoch: 122 | Batch_idx: 230 |  Loss: (0.1644) |  Loss2: (0.0000) | Acc: (94.00%) (27853/29568)
Epoch: 122 | Batch_idx: 240 |  Loss: (0.1641) |  Loss2: (0.0000) | Acc: (94.00%) (29058/30848)
Epoch: 122 | Batch_idx: 250 |  Loss: (0.1640) |  Loss2: (0.0000) | Acc: (94.00%) (30261/32128)
Epoch: 122 | Batch_idx: 260 |  Loss: (0.1637) |  Loss2: (0.0000) | Acc: (94.00%) (31477/33408)
Epoch: 122 | Batch_idx: 270 |  Loss: (0.1641) |  Loss2: (0.0000) | Acc: (94.00%) (32679/34688)
Epoch: 122 | Batch_idx: 280 |  Loss: (0.1647) |  Loss2: (0.0000) | Acc: (94.00%) (33871/35968)
Epoch: 122 | Batch_idx: 290 |  Loss: (0.1653) |  Loss2: (0.0000) | Acc: (94.00%) (35066/37248)
Epoch: 122 | Batch_idx: 300 |  Loss: (0.1660) |  Loss2: (0.0000) | Acc: (94.00%) (36261/38528)
Epoch: 122 | Batch_idx: 310 |  Loss: (0.1667) |  Loss2: (0.0000) | Acc: (94.00%) (37456/39808)
Epoch: 122 | Batch_idx: 320 |  Loss: (0.1660) |  Loss2: (0.0000) | Acc: (94.00%) (38680/41088)
Epoch: 122 | Batch_idx: 330 |  Loss: (0.1664) |  Loss2: (0.0000) | Acc: (94.00%) (39882/42368)
Epoch: 122 | Batch_idx: 340 |  Loss: (0.1670) |  Loss2: (0.0000) | Acc: (94.00%) (41080/43648)
Epoch: 122 | Batch_idx: 350 |  Loss: (0.1673) |  Loss2: (0.0000) | Acc: (94.00%) (42276/44928)
Epoch: 122 | Batch_idx: 360 |  Loss: (0.1678) |  Loss2: (0.0000) | Acc: (94.00%) (43474/46208)
Epoch: 122 | Batch_idx: 370 |  Loss: (0.1680) |  Loss2: (0.0000) | Acc: (94.00%) (44674/47488)
Epoch: 122 | Batch_idx: 380 |  Loss: (0.1685) |  Loss2: (0.0000) | Acc: (94.00%) (45866/48768)
Epoch: 122 | Batch_idx: 390 |  Loss: (0.1688) |  Loss2: (0.0000) | Acc: (94.00%) (47023/50000)
# TEST : Loss: (0.4295) | Acc: (86.00%) (8699/10000)
percent tensor([0.6025, 0.6000, 0.6090, 0.5958, 0.6163, 0.6013, 0.6096, 0.5986, 0.6055,
        0.5981, 0.6007, 0.6079, 0.5955, 0.5959, 0.6011, 0.5959],
       device='cuda:0') torch.Size([16])
percent tensor([0.5751, 0.5298, 0.5308, 0.5922, 0.5609, 0.6214, 0.5424, 0.5624, 0.5666,
        0.5363, 0.5556, 0.5206, 0.5257, 0.6053, 0.5661, 0.5791],
       device='cuda:0') torch.Size([16])
percent tensor([0.5303, 0.5675, 0.5128, 0.4744, 0.5185, 0.4672, 0.5732, 0.5291, 0.5124,
        0.5213, 0.5108, 0.5412, 0.5520, 0.5340, 0.5341, 0.5287],
       device='cuda:0') torch.Size([16])
percent tensor([0.6577, 0.6190, 0.6450, 0.6457, 0.6593, 0.6570, 0.6501, 0.6592, 0.6523,
        0.6392, 0.6477, 0.6388, 0.6364, 0.6484, 0.6509, 0.6602],
       device='cuda:0') torch.Size([16])
percent tensor([0.5833, 0.6738, 0.6645, 0.6701, 0.6091, 0.7120, 0.6198, 0.5125, 0.7367,
        0.6073, 0.6830, 0.6754, 0.7377, 0.7543, 0.5682, 0.6504],
       device='cuda:0') torch.Size([16])
percent tensor([0.7106, 0.6957, 0.7753, 0.7710, 0.7965, 0.8065, 0.7425, 0.6764, 0.7781,
        0.7319, 0.7654, 0.7351, 0.7240, 0.8339, 0.6773, 0.7633],
       device='cuda:0') torch.Size([16])
percent tensor([0.6587, 0.5957, 0.6888, 0.5940, 0.7202, 0.6771, 0.6901, 0.6508, 0.6225,
        0.6214, 0.6339, 0.6242, 0.5303, 0.5922, 0.6257, 0.6534],
       device='cuda:0') torch.Size([16])
percent tensor([0.9996, 0.9991, 0.9990, 0.9995, 0.9992, 0.9991, 0.9993, 0.9990, 0.9990,
        0.9996, 0.9995, 0.9994, 0.9992, 0.9995, 0.9991, 0.9991],
       device='cuda:0') torch.Size([16])
Epoch: 123 | Batch_idx: 0 |  Loss: (0.0934) |  Loss2: (0.0000) | Acc: (97.00%) (125/128)
Epoch: 123 | Batch_idx: 10 |  Loss: (0.1637) |  Loss2: (0.0000) | Acc: (94.00%) (1325/1408)
Epoch: 123 | Batch_idx: 20 |  Loss: (0.1561) |  Loss2: (0.0000) | Acc: (94.00%) (2545/2688)
Epoch: 123 | Batch_idx: 30 |  Loss: (0.1581) |  Loss2: (0.0000) | Acc: (94.00%) (3755/3968)
Epoch: 123 | Batch_idx: 40 |  Loss: (0.1515) |  Loss2: (0.0000) | Acc: (94.00%) (4979/5248)
Epoch: 123 | Batch_idx: 50 |  Loss: (0.1528) |  Loss2: (0.0000) | Acc: (94.00%) (6185/6528)
Epoch: 123 | Batch_idx: 60 |  Loss: (0.1535) |  Loss2: (0.0000) | Acc: (94.00%) (7392/7808)
Epoch: 123 | Batch_idx: 70 |  Loss: (0.1537) |  Loss2: (0.0000) | Acc: (94.00%) (8603/9088)
Epoch: 123 | Batch_idx: 80 |  Loss: (0.1546) |  Loss2: (0.0000) | Acc: (94.00%) (9812/10368)
Epoch: 123 | Batch_idx: 90 |  Loss: (0.1547) |  Loss2: (0.0000) | Acc: (94.00%) (11015/11648)
Epoch: 123 | Batch_idx: 100 |  Loss: (0.1541) |  Loss2: (0.0000) | Acc: (94.00%) (12230/12928)
Epoch: 123 | Batch_idx: 110 |  Loss: (0.1561) |  Loss2: (0.0000) | Acc: (94.00%) (13436/14208)
Epoch: 123 | Batch_idx: 120 |  Loss: (0.1545) |  Loss2: (0.0000) | Acc: (94.00%) (14658/15488)
Epoch: 123 | Batch_idx: 130 |  Loss: (0.1555) |  Loss2: (0.0000) | Acc: (94.00%) (15859/16768)
Epoch: 123 | Batch_idx: 140 |  Loss: (0.1566) |  Loss2: (0.0000) | Acc: (94.00%) (17051/18048)
Epoch: 123 | Batch_idx: 150 |  Loss: (0.1591) |  Loss2: (0.0000) | Acc: (94.00%) (18242/19328)
Epoch: 123 | Batch_idx: 160 |  Loss: (0.1596) |  Loss2: (0.0000) | Acc: (94.00%) (19442/20608)
Epoch: 123 | Batch_idx: 170 |  Loss: (0.1590) |  Loss2: (0.0000) | Acc: (94.00%) (20658/21888)
Epoch: 123 | Batch_idx: 180 |  Loss: (0.1589) |  Loss2: (0.0000) | Acc: (94.00%) (21864/23168)
Epoch: 123 | Batch_idx: 190 |  Loss: (0.1587) |  Loss2: (0.0000) | Acc: (94.00%) (23070/24448)
Epoch: 123 | Batch_idx: 200 |  Loss: (0.1586) |  Loss2: (0.0000) | Acc: (94.00%) (24280/25728)
Epoch: 123 | Batch_idx: 210 |  Loss: (0.1598) |  Loss2: (0.0000) | Acc: (94.00%) (25487/27008)
Epoch: 123 | Batch_idx: 220 |  Loss: (0.1603) |  Loss2: (0.0000) | Acc: (94.00%) (26688/28288)
Epoch: 123 | Batch_idx: 230 |  Loss: (0.1599) |  Loss2: (0.0000) | Acc: (94.00%) (27899/29568)
Epoch: 123 | Batch_idx: 240 |  Loss: (0.1595) |  Loss2: (0.0000) | Acc: (94.00%) (29115/30848)
Epoch: 123 | Batch_idx: 250 |  Loss: (0.1597) |  Loss2: (0.0000) | Acc: (94.00%) (30323/32128)
Epoch: 123 | Batch_idx: 260 |  Loss: (0.1598) |  Loss2: (0.0000) | Acc: (94.00%) (31527/33408)
Epoch: 123 | Batch_idx: 270 |  Loss: (0.1598) |  Loss2: (0.0000) | Acc: (94.00%) (32737/34688)
Epoch: 123 | Batch_idx: 280 |  Loss: (0.1604) |  Loss2: (0.0000) | Acc: (94.00%) (33938/35968)
Epoch: 123 | Batch_idx: 290 |  Loss: (0.1605) |  Loss2: (0.0000) | Acc: (94.00%) (35150/37248)
Epoch: 123 | Batch_idx: 300 |  Loss: (0.1608) |  Loss2: (0.0000) | Acc: (94.00%) (36356/38528)
Epoch: 123 | Batch_idx: 310 |  Loss: (0.1611) |  Loss2: (0.0000) | Acc: (94.00%) (37558/39808)
Epoch: 123 | Batch_idx: 320 |  Loss: (0.1610) |  Loss2: (0.0000) | Acc: (94.00%) (38768/41088)
Epoch: 123 | Batch_idx: 330 |  Loss: (0.1620) |  Loss2: (0.0000) | Acc: (94.00%) (39962/42368)
Epoch: 123 | Batch_idx: 340 |  Loss: (0.1619) |  Loss2: (0.0000) | Acc: (94.00%) (41172/43648)
Epoch: 123 | Batch_idx: 350 |  Loss: (0.1624) |  Loss2: (0.0000) | Acc: (94.00%) (42371/44928)
Epoch: 123 | Batch_idx: 360 |  Loss: (0.1628) |  Loss2: (0.0000) | Acc: (94.00%) (43584/46208)
Epoch: 123 | Batch_idx: 370 |  Loss: (0.1629) |  Loss2: (0.0000) | Acc: (94.00%) (44797/47488)
Epoch: 123 | Batch_idx: 380 |  Loss: (0.1630) |  Loss2: (0.0000) | Acc: (94.00%) (45999/48768)
Epoch: 123 | Batch_idx: 390 |  Loss: (0.1638) |  Loss2: (0.0000) | Acc: (94.00%) (47152/50000)
# TEST : Loss: (0.3904) | Acc: (87.00%) (8752/10000)
percent tensor([0.6030, 0.5984, 0.6094, 0.5942, 0.6163, 0.6019, 0.6090, 0.5985, 0.6060,
        0.5987, 0.6010, 0.6080, 0.5961, 0.5935, 0.6005, 0.5954],
       device='cuda:0') torch.Size([16])
percent tensor([0.5802, 0.5297, 0.5324, 0.5972, 0.5651, 0.6214, 0.5438, 0.5617, 0.5717,
        0.5354, 0.5573, 0.5244, 0.5275, 0.6034, 0.5675, 0.5796],
       device='cuda:0') torch.Size([16])
percent tensor([0.5386, 0.5672, 0.5159, 0.4807, 0.5247, 0.4851, 0.5725, 0.5324, 0.5182,
        0.5228, 0.5191, 0.5411, 0.5606, 0.5338, 0.5429, 0.5384],
       device='cuda:0') torch.Size([16])
percent tensor([0.6608, 0.6200, 0.6463, 0.6497, 0.6591, 0.6604, 0.6491, 0.6590, 0.6571,
        0.6377, 0.6480, 0.6386, 0.6394, 0.6495, 0.6531, 0.6613],
       device='cuda:0') torch.Size([16])
percent tensor([0.5888, 0.7023, 0.6459, 0.6540, 0.5956, 0.6898, 0.6446, 0.5046, 0.7357,
        0.6373, 0.7075, 0.6782, 0.7454, 0.7658, 0.5872, 0.6543],
       device='cuda:0') torch.Size([16])
percent tensor([0.7133, 0.6946, 0.7640, 0.7558, 0.7931, 0.8007, 0.7502, 0.6841, 0.7818,
        0.7276, 0.7781, 0.7287, 0.7176, 0.8392, 0.6782, 0.7598],
       device='cuda:0') torch.Size([16])
percent tensor([0.6662, 0.5815, 0.6955, 0.6037, 0.7174, 0.6918, 0.6835, 0.6653, 0.6406,
        0.6172, 0.6203, 0.6154, 0.5298, 0.5752, 0.6222, 0.6597],
       device='cuda:0') torch.Size([16])
percent tensor([0.9994, 0.9988, 0.9990, 0.9994, 0.9992, 0.9992, 0.9990, 0.9990, 0.9992,
        0.9996, 0.9993, 0.9994, 0.9991, 0.9993, 0.9990, 0.9989],
       device='cuda:0') torch.Size([16])
Epoch: 124 | Batch_idx: 0 |  Loss: (0.1911) |  Loss2: (0.0000) | Acc: (93.00%) (120/128)
Epoch: 124 | Batch_idx: 10 |  Loss: (0.1521) |  Loss2: (0.0000) | Acc: (95.00%) (1342/1408)
Epoch: 124 | Batch_idx: 20 |  Loss: (0.1438) |  Loss2: (0.0000) | Acc: (95.00%) (2563/2688)
Epoch: 124 | Batch_idx: 30 |  Loss: (0.1497) |  Loss2: (0.0000) | Acc: (95.00%) (3771/3968)
Epoch: 124 | Batch_idx: 40 |  Loss: (0.1460) |  Loss2: (0.0000) | Acc: (95.00%) (4993/5248)
Epoch: 124 | Batch_idx: 50 |  Loss: (0.1541) |  Loss2: (0.0000) | Acc: (94.00%) (6182/6528)
Epoch: 124 | Batch_idx: 60 |  Loss: (0.1537) |  Loss2: (0.0000) | Acc: (94.00%) (7392/7808)
Epoch: 124 | Batch_idx: 70 |  Loss: (0.1569) |  Loss2: (0.0000) | Acc: (94.00%) (8591/9088)
Epoch: 124 | Batch_idx: 80 |  Loss: (0.1579) |  Loss2: (0.0000) | Acc: (94.00%) (9794/10368)
Epoch: 124 | Batch_idx: 90 |  Loss: (0.1578) |  Loss2: (0.0000) | Acc: (94.00%) (11008/11648)
Epoch: 124 | Batch_idx: 100 |  Loss: (0.1583) |  Loss2: (0.0000) | Acc: (94.00%) (12220/12928)
Epoch: 124 | Batch_idx: 110 |  Loss: (0.1591) |  Loss2: (0.0000) | Acc: (94.00%) (13422/14208)
Epoch: 124 | Batch_idx: 120 |  Loss: (0.1586) |  Loss2: (0.0000) | Acc: (94.00%) (14640/15488)
Epoch: 124 | Batch_idx: 130 |  Loss: (0.1596) |  Loss2: (0.0000) | Acc: (94.00%) (15842/16768)
Epoch: 124 | Batch_idx: 140 |  Loss: (0.1605) |  Loss2: (0.0000) | Acc: (94.00%) (17048/18048)
Epoch: 124 | Batch_idx: 150 |  Loss: (0.1587) |  Loss2: (0.0000) | Acc: (94.00%) (18268/19328)
Epoch: 124 | Batch_idx: 160 |  Loss: (0.1592) |  Loss2: (0.0000) | Acc: (94.00%) (19474/20608)
Epoch: 124 | Batch_idx: 170 |  Loss: (0.1592) |  Loss2: (0.0000) | Acc: (94.00%) (20683/21888)
Epoch: 124 | Batch_idx: 180 |  Loss: (0.1603) |  Loss2: (0.0000) | Acc: (94.00%) (21883/23168)
Epoch: 124 | Batch_idx: 190 |  Loss: (0.1613) |  Loss2: (0.0000) | Acc: (94.00%) (23081/24448)
Epoch: 124 | Batch_idx: 200 |  Loss: (0.1614) |  Loss2: (0.0000) | Acc: (94.00%) (24285/25728)
Epoch: 124 | Batch_idx: 210 |  Loss: (0.1611) |  Loss2: (0.0000) | Acc: (94.00%) (25497/27008)
Epoch: 124 | Batch_idx: 220 |  Loss: (0.1617) |  Loss2: (0.0000) | Acc: (94.00%) (26695/28288)
Epoch: 124 | Batch_idx: 230 |  Loss: (0.1601) |  Loss2: (0.0000) | Acc: (94.00%) (27922/29568)
Epoch: 124 | Batch_idx: 240 |  Loss: (0.1601) |  Loss2: (0.0000) | Acc: (94.00%) (29124/30848)
Epoch: 124 | Batch_idx: 250 |  Loss: (0.1592) |  Loss2: (0.0000) | Acc: (94.00%) (30340/32128)
Epoch: 124 | Batch_idx: 260 |  Loss: (0.1587) |  Loss2: (0.0000) | Acc: (94.00%) (31555/33408)
Epoch: 124 | Batch_idx: 270 |  Loss: (0.1580) |  Loss2: (0.0000) | Acc: (94.00%) (32777/34688)
Epoch: 124 | Batch_idx: 280 |  Loss: (0.1581) |  Loss2: (0.0000) | Acc: (94.00%) (33989/35968)
Epoch: 124 | Batch_idx: 290 |  Loss: (0.1588) |  Loss2: (0.0000) | Acc: (94.00%) (35197/37248)
Epoch: 124 | Batch_idx: 300 |  Loss: (0.1588) |  Loss2: (0.0000) | Acc: (94.00%) (36396/38528)
Epoch: 124 | Batch_idx: 310 |  Loss: (0.1584) |  Loss2: (0.0000) | Acc: (94.00%) (37615/39808)
Epoch: 124 | Batch_idx: 320 |  Loss: (0.1587) |  Loss2: (0.0000) | Acc: (94.00%) (38817/41088)
Epoch: 124 | Batch_idx: 330 |  Loss: (0.1590) |  Loss2: (0.0000) | Acc: (94.00%) (40018/42368)
Epoch: 124 | Batch_idx: 340 |  Loss: (0.1589) |  Loss2: (0.0000) | Acc: (94.00%) (41219/43648)
Epoch: 124 | Batch_idx: 350 |  Loss: (0.1587) |  Loss2: (0.0000) | Acc: (94.00%) (42430/44928)
Epoch: 124 | Batch_idx: 360 |  Loss: (0.1587) |  Loss2: (0.0000) | Acc: (94.00%) (43636/46208)
Epoch: 124 | Batch_idx: 370 |  Loss: (0.1586) |  Loss2: (0.0000) | Acc: (94.00%) (44852/47488)
Epoch: 124 | Batch_idx: 380 |  Loss: (0.1587) |  Loss2: (0.0000) | Acc: (94.00%) (46058/48768)
Epoch: 124 | Batch_idx: 390 |  Loss: (0.1584) |  Loss2: (0.0000) | Acc: (94.00%) (47225/50000)
# TEST : Loss: (0.4307) | Acc: (87.00%) (8745/10000)
percent tensor([0.6053, 0.5997, 0.6116, 0.5946, 0.6182, 0.6037, 0.6104, 0.5980, 0.6067,
        0.5991, 0.6009, 0.6111, 0.5972, 0.5924, 0.6017, 0.5955],
       device='cuda:0') torch.Size([16])
percent tensor([0.5783, 0.5325, 0.5285, 0.5989, 0.5597, 0.6251, 0.5450, 0.5653, 0.5705,
        0.5371, 0.5600, 0.5220, 0.5281, 0.6099, 0.5696, 0.5826],
       device='cuda:0') torch.Size([16])
percent tensor([0.5301, 0.5718, 0.5045, 0.4713, 0.5172, 0.4696, 0.5726, 0.5283, 0.5153,
        0.5236, 0.5149, 0.5378, 0.5542, 0.5283, 0.5394, 0.5306],
       device='cuda:0') torch.Size([16])
percent tensor([0.6573, 0.6174, 0.6426, 0.6493, 0.6566, 0.6588, 0.6462, 0.6583, 0.6537,
        0.6356, 0.6463, 0.6351, 0.6372, 0.6470, 0.6503, 0.6608],
       device='cuda:0') torch.Size([16])
percent tensor([0.5826, 0.6870, 0.6707, 0.6476, 0.6182, 0.6979, 0.6295, 0.5153, 0.7294,
        0.6228, 0.6843, 0.6839, 0.7332, 0.7493, 0.5691, 0.6266],
       device='cuda:0') torch.Size([16])
percent tensor([0.7049, 0.6788, 0.7599, 0.7586, 0.7864, 0.7996, 0.7320, 0.6645, 0.7641,
        0.7280, 0.7567, 0.7206, 0.6984, 0.8308, 0.6483, 0.7423],
       device='cuda:0') torch.Size([16])
percent tensor([0.6679, 0.6005, 0.6931, 0.6100, 0.7180, 0.6883, 0.6913, 0.6615, 0.6461,
        0.6240, 0.6204, 0.6138, 0.5373, 0.5922, 0.6287, 0.6570],
       device='cuda:0') torch.Size([16])
percent tensor([0.9995, 0.9990, 0.9992, 0.9996, 0.9990, 0.9990, 0.9992, 0.9990, 0.9993,
        0.9996, 0.9995, 0.9995, 0.9993, 0.9995, 0.9991, 0.9990],
       device='cuda:0') torch.Size([16])
False Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=128, out_features=16, bias=False)
True Linear(in_features=16, out_features=2, bias=False)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=128, out_features=16, bias=False)
True Linear(in_features=16, out_features=2, bias=False)
False Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=256, out_features=32, bias=False)
True Linear(in_features=32, out_features=2, bias=False)
False Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=256, out_features=32, bias=False)
True Linear(in_features=32, out_features=2, bias=False)
False Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=512, out_features=64, bias=False)
True Linear(in_features=64, out_features=2, bias=False)
False Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=512, out_features=64, bias=False)
True Linear(in_features=64, out_features=2, bias=False)
False Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1024, out_features=128, bias=False)
True Linear(in_features=128, out_features=2, bias=False)
False Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1024, out_features=128, bias=False)
True Linear(in_features=128, out_features=2, bias=False)
False Linear(in_features=512, out_features=10, bias=True)
Epoch: 125 | Batch_idx: 0 |  Loss: (0.2009) |  Loss2: (0.0000) | Acc: (92.00%) (118/128)
Epoch: 125 | Batch_idx: 10 |  Loss: (0.1589) |  Loss2: (0.0000) | Acc: (94.00%) (1337/1408)
Epoch: 125 | Batch_idx: 20 |  Loss: (0.1973) |  Loss2: (0.0000) | Acc: (93.00%) (2506/2688)
Epoch: 125 | Batch_idx: 30 |  Loss: (0.1930) |  Loss2: (0.0000) | Acc: (93.00%) (3698/3968)
Epoch: 125 | Batch_idx: 40 |  Loss: (0.1909) |  Loss2: (0.0000) | Acc: (93.00%) (4898/5248)
Epoch: 125 | Batch_idx: 50 |  Loss: (0.1901) |  Loss2: (0.0000) | Acc: (93.00%) (6089/6528)
Epoch: 125 | Batch_idx: 60 |  Loss: (0.1913) |  Loss2: (0.0000) | Acc: (93.00%) (7280/7808)
Epoch: 125 | Batch_idx: 70 |  Loss: (0.1919) |  Loss2: (0.0000) | Acc: (93.00%) (8457/9088)
Epoch: 125 | Batch_idx: 80 |  Loss: (0.1916) |  Loss2: (0.0000) | Acc: (93.00%) (9653/10368)
Epoch: 125 | Batch_idx: 90 |  Loss: (0.1892) |  Loss2: (0.0000) | Acc: (93.00%) (10862/11648)
Epoch: 125 | Batch_idx: 100 |  Loss: (0.1870) |  Loss2: (0.0000) | Acc: (93.00%) (12070/12928)
Epoch: 125 | Batch_idx: 110 |  Loss: (0.1902) |  Loss2: (0.0000) | Acc: (93.00%) (13246/14208)
Epoch: 125 | Batch_idx: 120 |  Loss: (0.1900) |  Loss2: (0.0000) | Acc: (93.00%) (14442/15488)
Epoch: 125 | Batch_idx: 130 |  Loss: (0.1904) |  Loss2: (0.0000) | Acc: (93.00%) (15630/16768)
Epoch: 125 | Batch_idx: 140 |  Loss: (0.1906) |  Loss2: (0.0000) | Acc: (93.00%) (16824/18048)
Epoch: 125 | Batch_idx: 150 |  Loss: (0.1884) |  Loss2: (0.0000) | Acc: (93.00%) (18037/19328)
Epoch: 125 | Batch_idx: 160 |  Loss: (0.1906) |  Loss2: (0.0000) | Acc: (93.00%) (19212/20608)
Epoch: 125 | Batch_idx: 170 |  Loss: (0.1902) |  Loss2: (0.0000) | Acc: (93.00%) (20403/21888)
Epoch: 125 | Batch_idx: 180 |  Loss: (0.1895) |  Loss2: (0.0000) | Acc: (93.00%) (21610/23168)
Epoch: 125 | Batch_idx: 190 |  Loss: (0.1896) |  Loss2: (0.0000) | Acc: (93.00%) (22812/24448)
Epoch: 125 | Batch_idx: 200 |  Loss: (0.1900) |  Loss2: (0.0000) | Acc: (93.00%) (24000/25728)
Epoch: 125 | Batch_idx: 210 |  Loss: (0.1904) |  Loss2: (0.0000) | Acc: (93.00%) (25180/27008)
Epoch: 125 | Batch_idx: 220 |  Loss: (0.1904) |  Loss2: (0.0000) | Acc: (93.00%) (26375/28288)
Epoch: 125 | Batch_idx: 230 |  Loss: (0.1910) |  Loss2: (0.0000) | Acc: (93.00%) (27562/29568)
Epoch: 125 | Batch_idx: 240 |  Loss: (0.1916) |  Loss2: (0.0000) | Acc: (93.00%) (28751/30848)
Epoch: 125 | Batch_idx: 250 |  Loss: (0.1915) |  Loss2: (0.0000) | Acc: (93.00%) (29940/32128)
Epoch: 125 | Batch_idx: 260 |  Loss: (0.1922) |  Loss2: (0.0000) | Acc: (93.00%) (31118/33408)
Epoch: 125 | Batch_idx: 270 |  Loss: (0.1921) |  Loss2: (0.0000) | Acc: (93.00%) (32318/34688)
Epoch: 125 | Batch_idx: 280 |  Loss: (0.1917) |  Loss2: (0.0000) | Acc: (93.00%) (33510/35968)
Epoch: 125 | Batch_idx: 290 |  Loss: (0.1912) |  Loss2: (0.0000) | Acc: (93.00%) (34704/37248)
Epoch: 125 | Batch_idx: 300 |  Loss: (0.1905) |  Loss2: (0.0000) | Acc: (93.00%) (35907/38528)
Epoch: 125 | Batch_idx: 310 |  Loss: (0.1901) |  Loss2: (0.0000) | Acc: (93.00%) (37117/39808)
Epoch: 125 | Batch_idx: 320 |  Loss: (0.1899) |  Loss2: (0.0000) | Acc: (93.00%) (38321/41088)
Epoch: 125 | Batch_idx: 330 |  Loss: (0.1898) |  Loss2: (0.0000) | Acc: (93.00%) (39522/42368)
Epoch: 125 | Batch_idx: 340 |  Loss: (0.1897) |  Loss2: (0.0000) | Acc: (93.00%) (40711/43648)
Epoch: 125 | Batch_idx: 350 |  Loss: (0.1896) |  Loss2: (0.0000) | Acc: (93.00%) (41909/44928)
Epoch: 125 | Batch_idx: 360 |  Loss: (0.1891) |  Loss2: (0.0000) | Acc: (93.00%) (43117/46208)
Epoch: 125 | Batch_idx: 370 |  Loss: (0.1885) |  Loss2: (0.0000) | Acc: (93.00%) (44320/47488)
Epoch: 125 | Batch_idx: 380 |  Loss: (0.1879) |  Loss2: (0.0000) | Acc: (93.00%) (45530/48768)
Epoch: 125 | Batch_idx: 390 |  Loss: (0.1874) |  Loss2: (0.0000) | Acc: (93.00%) (46695/50000)
=> saving checkpoint 'drive/app/torch/save_Routing_Gate_2/checkpoint_125.pth.tar'
# TEST : Loss: (0.4106) | Acc: (87.00%) (8759/10000)
percent tensor([0.6052, 0.5954, 0.6120, 0.5926, 0.6176, 0.6031, 0.6081, 0.5955, 0.6051,
        0.5970, 0.5992, 0.6108, 0.5962, 0.5869, 0.5990, 0.5939],
       device='cuda:0') torch.Size([16])
percent tensor([0.5764, 0.5290, 0.5261, 0.5937, 0.5545, 0.6235, 0.5395, 0.5576, 0.5656,
        0.5334, 0.5563, 0.5187, 0.5266, 0.6020, 0.5666, 0.5806],
       device='cuda:0') torch.Size([16])
percent tensor([0.5336, 0.5864, 0.5056, 0.4668, 0.5176, 0.4613, 0.5857, 0.5270, 0.5218,
        0.5375, 0.5289, 0.5509, 0.5651, 0.5442, 0.5425, 0.5338],
       device='cuda:0') torch.Size([16])
percent tensor([0.6505, 0.6149, 0.6343, 0.6405, 0.6454, 0.6539, 0.6389, 0.6442, 0.6453,
        0.6305, 0.6423, 0.6306, 0.6361, 0.6405, 0.6436, 0.6557],
       device='cuda:0') torch.Size([16])
percent tensor([0.5863, 0.6924, 0.6714, 0.6552, 0.6328, 0.6908, 0.6467, 0.5417, 0.7339,
        0.6313, 0.6857, 0.6928, 0.7278, 0.7533, 0.5858, 0.6369],
       device='cuda:0') torch.Size([16])
percent tensor([0.7403, 0.7088, 0.7942, 0.7961, 0.8126, 0.8212, 0.7605, 0.7057, 0.7856,
        0.7593, 0.7739, 0.7521, 0.7315, 0.8450, 0.6874, 0.7822],
       device='cuda:0') torch.Size([16])
percent tensor([0.6391, 0.5645, 0.6737, 0.5939, 0.6978, 0.6586, 0.6678, 0.6487, 0.6161,
        0.5993, 0.5878, 0.5938, 0.5009, 0.5862, 0.6017, 0.6373],
       device='cuda:0') torch.Size([16])
percent tensor([0.9995, 0.9990, 0.9990, 0.9994, 0.9987, 0.9990, 0.9993, 0.9991, 0.9993,
        0.9995, 0.9994, 0.9995, 0.9993, 0.9994, 0.9991, 0.9989],
       device='cuda:0') torch.Size([16])
Epoch: 126 | Batch_idx: 0 |  Loss: (0.1398) |  Loss2: (0.0000) | Acc: (94.00%) (121/128)
Epoch: 126 | Batch_idx: 10 |  Loss: (0.1654) |  Loss2: (0.0000) | Acc: (94.00%) (1328/1408)
Epoch: 126 | Batch_idx: 20 |  Loss: (0.1561) |  Loss2: (0.0000) | Acc: (94.00%) (2541/2688)
Epoch: 126 | Batch_idx: 30 |  Loss: (0.1556) |  Loss2: (0.0000) | Acc: (94.00%) (3749/3968)
Epoch: 126 | Batch_idx: 40 |  Loss: (0.1604) |  Loss2: (0.0000) | Acc: (94.00%) (4947/5248)
Epoch: 126 | Batch_idx: 50 |  Loss: (0.1611) |  Loss2: (0.0000) | Acc: (94.00%) (6157/6528)
Epoch: 126 | Batch_idx: 60 |  Loss: (0.1598) |  Loss2: (0.0000) | Acc: (94.00%) (7366/7808)
Epoch: 126 | Batch_idx: 70 |  Loss: (0.1619) |  Loss2: (0.0000) | Acc: (94.00%) (8563/9088)
Epoch: 126 | Batch_idx: 80 |  Loss: (0.1652) |  Loss2: (0.0000) | Acc: (94.00%) (9759/10368)
Epoch: 126 | Batch_idx: 90 |  Loss: (0.1645) |  Loss2: (0.0000) | Acc: (94.00%) (10973/11648)
Epoch: 126 | Batch_idx: 100 |  Loss: (0.1653) |  Loss2: (0.0000) | Acc: (94.00%) (12174/12928)
Epoch: 126 | Batch_idx: 110 |  Loss: (0.1669) |  Loss2: (0.0000) | Acc: (94.00%) (13373/14208)
Epoch: 126 | Batch_idx: 120 |  Loss: (0.1667) |  Loss2: (0.0000) | Acc: (94.00%) (14577/15488)
Epoch: 126 | Batch_idx: 130 |  Loss: (0.1656) |  Loss2: (0.0000) | Acc: (94.00%) (15789/16768)
Epoch: 126 | Batch_idx: 140 |  Loss: (0.1657) |  Loss2: (0.0000) | Acc: (94.00%) (17004/18048)
Epoch: 126 | Batch_idx: 150 |  Loss: (0.1654) |  Loss2: (0.0000) | Acc: (94.00%) (18208/19328)
Epoch: 126 | Batch_idx: 160 |  Loss: (0.1647) |  Loss2: (0.0000) | Acc: (94.00%) (19413/20608)
Epoch: 126 | Batch_idx: 170 |  Loss: (0.1657) |  Loss2: (0.0000) | Acc: (94.00%) (20614/21888)
Epoch: 126 | Batch_idx: 180 |  Loss: (0.1645) |  Loss2: (0.0000) | Acc: (94.00%) (21832/23168)
Epoch: 126 | Batch_idx: 190 |  Loss: (0.1652) |  Loss2: (0.0000) | Acc: (94.00%) (23028/24448)
Epoch: 126 | Batch_idx: 200 |  Loss: (0.1654) |  Loss2: (0.0000) | Acc: (94.00%) (24223/25728)
Epoch: 126 | Batch_idx: 210 |  Loss: (0.1654) |  Loss2: (0.0000) | Acc: (94.00%) (25425/27008)
Epoch: 126 | Batch_idx: 220 |  Loss: (0.1654) |  Loss2: (0.0000) | Acc: (94.00%) (26628/28288)
Epoch: 126 | Batch_idx: 230 |  Loss: (0.1661) |  Loss2: (0.0000) | Acc: (94.00%) (27821/29568)
Epoch: 126 | Batch_idx: 240 |  Loss: (0.1659) |  Loss2: (0.0000) | Acc: (94.00%) (29028/30848)
Epoch: 126 | Batch_idx: 250 |  Loss: (0.1662) |  Loss2: (0.0000) | Acc: (94.00%) (30231/32128)
Epoch: 126 | Batch_idx: 260 |  Loss: (0.1665) |  Loss2: (0.0000) | Acc: (94.00%) (31428/33408)
Epoch: 126 | Batch_idx: 270 |  Loss: (0.1672) |  Loss2: (0.0000) | Acc: (94.00%) (32619/34688)
Epoch: 126 | Batch_idx: 280 |  Loss: (0.1666) |  Loss2: (0.0000) | Acc: (94.00%) (33831/35968)
Epoch: 126 | Batch_idx: 290 |  Loss: (0.1663) |  Loss2: (0.0000) | Acc: (94.00%) (35037/37248)
Epoch: 126 | Batch_idx: 300 |  Loss: (0.1661) |  Loss2: (0.0000) | Acc: (94.00%) (36246/38528)
Epoch: 126 | Batch_idx: 310 |  Loss: (0.1659) |  Loss2: (0.0000) | Acc: (94.00%) (37462/39808)
Epoch: 126 | Batch_idx: 320 |  Loss: (0.1657) |  Loss2: (0.0000) | Acc: (94.00%) (38670/41088)
Epoch: 126 | Batch_idx: 330 |  Loss: (0.1658) |  Loss2: (0.0000) | Acc: (94.00%) (39877/42368)
Epoch: 126 | Batch_idx: 340 |  Loss: (0.1650) |  Loss2: (0.0000) | Acc: (94.00%) (41099/43648)
Epoch: 126 | Batch_idx: 350 |  Loss: (0.1655) |  Loss2: (0.0000) | Acc: (94.00%) (42290/44928)
Epoch: 126 | Batch_idx: 360 |  Loss: (0.1657) |  Loss2: (0.0000) | Acc: (94.00%) (43483/46208)
Epoch: 126 | Batch_idx: 370 |  Loss: (0.1655) |  Loss2: (0.0000) | Acc: (94.00%) (44701/47488)
Epoch: 126 | Batch_idx: 380 |  Loss: (0.1649) |  Loss2: (0.0000) | Acc: (94.00%) (45919/48768)
Epoch: 126 | Batch_idx: 390 |  Loss: (0.1650) |  Loss2: (0.0000) | Acc: (94.00%) (47081/50000)
# TEST : Loss: (0.3961) | Acc: (88.00%) (8808/10000)
percent tensor([0.6018, 0.5895, 0.6100, 0.5896, 0.6145, 0.6005, 0.6031, 0.5912, 0.6004,
        0.5925, 0.5942, 0.6078, 0.5918, 0.5805, 0.5945, 0.5899],
       device='cuda:0') torch.Size([16])
percent tensor([0.5756, 0.5274, 0.5236, 0.5924, 0.5520, 0.6229, 0.5373, 0.5543, 0.5643,
        0.5314, 0.5552, 0.5163, 0.5259, 0.6004, 0.5646, 0.5800],
       device='cuda:0') torch.Size([16])
percent tensor([0.5275, 0.5874, 0.4980, 0.4591, 0.5121, 0.4509, 0.5840, 0.5191, 0.5199,
        0.5390, 0.5301, 0.5484, 0.5625, 0.5453, 0.5373, 0.5271],
       device='cuda:0') torch.Size([16])
percent tensor([0.6576, 0.6232, 0.6383, 0.6452, 0.6491, 0.6610, 0.6449, 0.6465, 0.6518,
        0.6387, 0.6508, 0.6375, 0.6460, 0.6470, 0.6499, 0.6636],
       device='cuda:0') torch.Size([16])
percent tensor([0.5751, 0.6889, 0.6647, 0.6423, 0.6262, 0.6742, 0.6434, 0.5421, 0.7287,
        0.6264, 0.6808, 0.6869, 0.7189, 0.7528, 0.5805, 0.6265],
       device='cuda:0') torch.Size([16])
percent tensor([0.7302, 0.6981, 0.7856, 0.7860, 0.8051, 0.8115, 0.7515, 0.6998, 0.7742,
        0.7524, 0.7609, 0.7399, 0.7155, 0.8353, 0.6776, 0.7764],
       device='cuda:0') torch.Size([16])
percent tensor([0.6519, 0.5729, 0.6852, 0.6086, 0.7060, 0.6658, 0.6816, 0.6636, 0.6321,
        0.6086, 0.6010, 0.6114, 0.5119, 0.6014, 0.6188, 0.6474],
       device='cuda:0') torch.Size([16])
percent tensor([0.9995, 0.9990, 0.9991, 0.9995, 0.9987, 0.9990, 0.9994, 0.9991, 0.9994,
        0.9996, 0.9994, 0.9995, 0.9993, 0.9994, 0.9991, 0.9990],
       device='cuda:0') torch.Size([16])
Epoch: 127 | Batch_idx: 0 |  Loss: (0.1875) |  Loss2: (0.0000) | Acc: (91.00%) (117/128)
Epoch: 127 | Batch_idx: 10 |  Loss: (0.1687) |  Loss2: (0.0000) | Acc: (93.00%) (1323/1408)
Epoch: 127 | Batch_idx: 20 |  Loss: (0.1632) |  Loss2: (0.0000) | Acc: (94.00%) (2530/2688)
Epoch: 127 | Batch_idx: 30 |  Loss: (0.1630) |  Loss2: (0.0000) | Acc: (94.00%) (3731/3968)
Epoch: 127 | Batch_idx: 40 |  Loss: (0.1579) |  Loss2: (0.0000) | Acc: (94.00%) (4949/5248)
Epoch: 127 | Batch_idx: 50 |  Loss: (0.1573) |  Loss2: (0.0000) | Acc: (94.00%) (6158/6528)
Epoch: 127 | Batch_idx: 60 |  Loss: (0.1585) |  Loss2: (0.0000) | Acc: (94.00%) (7361/7808)
Epoch: 127 | Batch_idx: 70 |  Loss: (0.1588) |  Loss2: (0.0000) | Acc: (94.00%) (8568/9088)
Epoch: 127 | Batch_idx: 80 |  Loss: (0.1611) |  Loss2: (0.0000) | Acc: (94.00%) (9767/10368)
Epoch: 127 | Batch_idx: 90 |  Loss: (0.1608) |  Loss2: (0.0000) | Acc: (94.00%) (10978/11648)
Epoch: 127 | Batch_idx: 100 |  Loss: (0.1615) |  Loss2: (0.0000) | Acc: (94.00%) (12184/12928)
Epoch: 127 | Batch_idx: 110 |  Loss: (0.1621) |  Loss2: (0.0000) | Acc: (94.00%) (13388/14208)
Epoch: 127 | Batch_idx: 120 |  Loss: (0.1604) |  Loss2: (0.0000) | Acc: (94.00%) (14604/15488)
Epoch: 127 | Batch_idx: 130 |  Loss: (0.1607) |  Loss2: (0.0000) | Acc: (94.00%) (15813/16768)
Epoch: 127 | Batch_idx: 140 |  Loss: (0.1593) |  Loss2: (0.0000) | Acc: (94.00%) (17035/18048)
Epoch: 127 | Batch_idx: 150 |  Loss: (0.1584) |  Loss2: (0.0000) | Acc: (94.00%) (18258/19328)
Epoch: 127 | Batch_idx: 160 |  Loss: (0.1572) |  Loss2: (0.0000) | Acc: (94.00%) (19485/20608)
Epoch: 127 | Batch_idx: 170 |  Loss: (0.1585) |  Loss2: (0.0000) | Acc: (94.00%) (20692/21888)
Epoch: 127 | Batch_idx: 180 |  Loss: (0.1589) |  Loss2: (0.0000) | Acc: (94.00%) (21906/23168)
Epoch: 127 | Batch_idx: 190 |  Loss: (0.1587) |  Loss2: (0.0000) | Acc: (94.00%) (23117/24448)
Epoch: 127 | Batch_idx: 200 |  Loss: (0.1592) |  Loss2: (0.0000) | Acc: (94.00%) (24309/25728)
Epoch: 127 | Batch_idx: 210 |  Loss: (0.1580) |  Loss2: (0.0000) | Acc: (94.00%) (25534/27008)
Epoch: 127 | Batch_idx: 220 |  Loss: (0.1580) |  Loss2: (0.0000) | Acc: (94.00%) (26745/28288)
Epoch: 127 | Batch_idx: 230 |  Loss: (0.1590) |  Loss2: (0.0000) | Acc: (94.00%) (27951/29568)
Epoch: 127 | Batch_idx: 240 |  Loss: (0.1586) |  Loss2: (0.0000) | Acc: (94.00%) (29156/30848)
Epoch: 127 | Batch_idx: 250 |  Loss: (0.1589) |  Loss2: (0.0000) | Acc: (94.00%) (30364/32128)
Epoch: 127 | Batch_idx: 260 |  Loss: (0.1593) |  Loss2: (0.0000) | Acc: (94.00%) (31561/33408)
Epoch: 127 | Batch_idx: 270 |  Loss: (0.1588) |  Loss2: (0.0000) | Acc: (94.00%) (32779/34688)
Epoch: 127 | Batch_idx: 280 |  Loss: (0.1585) |  Loss2: (0.0000) | Acc: (94.00%) (34003/35968)
Epoch: 127 | Batch_idx: 290 |  Loss: (0.1580) |  Loss2: (0.0000) | Acc: (94.00%) (35221/37248)
Epoch: 127 | Batch_idx: 300 |  Loss: (0.1581) |  Loss2: (0.0000) | Acc: (94.00%) (36432/38528)
Epoch: 127 | Batch_idx: 310 |  Loss: (0.1588) |  Loss2: (0.0000) | Acc: (94.00%) (37628/39808)
Epoch: 127 | Batch_idx: 320 |  Loss: (0.1582) |  Loss2: (0.0000) | Acc: (94.00%) (38858/41088)
Epoch: 127 | Batch_idx: 330 |  Loss: (0.1585) |  Loss2: (0.0000) | Acc: (94.00%) (40065/42368)
Epoch: 127 | Batch_idx: 340 |  Loss: (0.1583) |  Loss2: (0.0000) | Acc: (94.00%) (41287/43648)
Epoch: 127 | Batch_idx: 350 |  Loss: (0.1583) |  Loss2: (0.0000) | Acc: (94.00%) (42491/44928)
Epoch: 127 | Batch_idx: 360 |  Loss: (0.1574) |  Loss2: (0.0000) | Acc: (94.00%) (43719/46208)
Epoch: 127 | Batch_idx: 370 |  Loss: (0.1573) |  Loss2: (0.0000) | Acc: (94.00%) (44931/47488)
Epoch: 127 | Batch_idx: 380 |  Loss: (0.1574) |  Loss2: (0.0000) | Acc: (94.00%) (46139/48768)
Epoch: 127 | Batch_idx: 390 |  Loss: (0.1580) |  Loss2: (0.0000) | Acc: (94.00%) (47299/50000)
# TEST : Loss: (0.3857) | Acc: (88.00%) (8820/10000)
percent tensor([0.6086, 0.5948, 0.6183, 0.5960, 0.6224, 0.6073, 0.6097, 0.5976, 0.6068,
        0.5989, 0.6002, 0.6157, 0.5980, 0.5848, 0.6005, 0.5959],
       device='cuda:0') torch.Size([16])
percent tensor([0.5760, 0.5276, 0.5218, 0.5917, 0.5511, 0.6246, 0.5367, 0.5531, 0.5646,
        0.5308, 0.5555, 0.5148, 0.5255, 0.6016, 0.5647, 0.5805],
       device='cuda:0') torch.Size([16])
percent tensor([0.5242, 0.5871, 0.4921, 0.4542, 0.5074, 0.4448, 0.5828, 0.5142, 0.5171,
        0.5386, 0.5292, 0.5461, 0.5602, 0.5453, 0.5338, 0.5236],
       device='cuda:0') torch.Size([16])
percent tensor([0.6578, 0.6247, 0.6364, 0.6445, 0.6465, 0.6623, 0.6444, 0.6433, 0.6521,
        0.6398, 0.6525, 0.6379, 0.6483, 0.6480, 0.6497, 0.6646],
       device='cuda:0') torch.Size([16])
percent tensor([0.5762, 0.6941, 0.6695, 0.6419, 0.6274, 0.6767, 0.6456, 0.5403, 0.7320,
        0.6332, 0.6869, 0.6912, 0.7246, 0.7569, 0.5807, 0.6329],
       device='cuda:0') torch.Size([16])
percent tensor([0.7307, 0.6948, 0.7875, 0.7867, 0.8080, 0.8141, 0.7527, 0.7030, 0.7726,
        0.7527, 0.7584, 0.7402, 0.7118, 0.8326, 0.6782, 0.7800],
       device='cuda:0') torch.Size([16])
percent tensor([0.6523, 0.5725, 0.6880, 0.6084, 0.7027, 0.6671, 0.6831, 0.6630, 0.6370,
        0.6088, 0.6061, 0.6143, 0.5140, 0.6052, 0.6208, 0.6455],
       device='cuda:0') torch.Size([16])
percent tensor([0.9995, 0.9990, 0.9991, 0.9995, 0.9989, 0.9990, 0.9994, 0.9992, 0.9994,
        0.9996, 0.9994, 0.9995, 0.9993, 0.9995, 0.9991, 0.9990],
       device='cuda:0') torch.Size([16])
Epoch: 128 | Batch_idx: 0 |  Loss: (0.1351) |  Loss2: (0.0000) | Acc: (95.00%) (122/128)
Epoch: 128 | Batch_idx: 10 |  Loss: (0.1456) |  Loss2: (0.0000) | Acc: (95.00%) (1344/1408)
Epoch: 128 | Batch_idx: 20 |  Loss: (0.1544) |  Loss2: (0.0000) | Acc: (95.00%) (2561/2688)
Epoch: 128 | Batch_idx: 30 |  Loss: (0.1551) |  Loss2: (0.0000) | Acc: (94.00%) (3767/3968)
Epoch: 128 | Batch_idx: 40 |  Loss: (0.1532) |  Loss2: (0.0000) | Acc: (95.00%) (4988/5248)
Epoch: 128 | Batch_idx: 50 |  Loss: (0.1504) |  Loss2: (0.0000) | Acc: (95.00%) (6208/6528)
Epoch: 128 | Batch_idx: 60 |  Loss: (0.1534) |  Loss2: (0.0000) | Acc: (95.00%) (7423/7808)
Epoch: 128 | Batch_idx: 70 |  Loss: (0.1529) |  Loss2: (0.0000) | Acc: (95.00%) (8635/9088)
Epoch: 128 | Batch_idx: 80 |  Loss: (0.1516) |  Loss2: (0.0000) | Acc: (95.00%) (9861/10368)
Epoch: 128 | Batch_idx: 90 |  Loss: (0.1524) |  Loss2: (0.0000) | Acc: (95.00%) (11066/11648)
Epoch: 128 | Batch_idx: 100 |  Loss: (0.1522) |  Loss2: (0.0000) | Acc: (94.00%) (12277/12928)
Epoch: 128 | Batch_idx: 110 |  Loss: (0.1531) |  Loss2: (0.0000) | Acc: (94.00%) (13476/14208)
Epoch: 128 | Batch_idx: 120 |  Loss: (0.1533) |  Loss2: (0.0000) | Acc: (94.00%) (14684/15488)
Epoch: 128 | Batch_idx: 130 |  Loss: (0.1516) |  Loss2: (0.0000) | Acc: (94.00%) (15901/16768)
Epoch: 128 | Batch_idx: 140 |  Loss: (0.1500) |  Loss2: (0.0000) | Acc: (94.00%) (17128/18048)
Epoch: 128 | Batch_idx: 150 |  Loss: (0.1515) |  Loss2: (0.0000) | Acc: (94.00%) (18319/19328)
Epoch: 128 | Batch_idx: 160 |  Loss: (0.1529) |  Loss2: (0.0000) | Acc: (94.00%) (19528/20608)
Epoch: 128 | Batch_idx: 170 |  Loss: (0.1525) |  Loss2: (0.0000) | Acc: (94.00%) (20742/21888)
Epoch: 128 | Batch_idx: 180 |  Loss: (0.1516) |  Loss2: (0.0000) | Acc: (94.00%) (21964/23168)
Epoch: 128 | Batch_idx: 190 |  Loss: (0.1527) |  Loss2: (0.0000) | Acc: (94.00%) (23170/24448)
Epoch: 128 | Batch_idx: 200 |  Loss: (0.1523) |  Loss2: (0.0000) | Acc: (94.00%) (24376/25728)
Epoch: 128 | Batch_idx: 210 |  Loss: (0.1518) |  Loss2: (0.0000) | Acc: (94.00%) (25591/27008)
Epoch: 128 | Batch_idx: 220 |  Loss: (0.1517) |  Loss2: (0.0000) | Acc: (94.00%) (26806/28288)
Epoch: 128 | Batch_idx: 230 |  Loss: (0.1518) |  Loss2: (0.0000) | Acc: (94.00%) (28014/29568)
Epoch: 128 | Batch_idx: 240 |  Loss: (0.1532) |  Loss2: (0.0000) | Acc: (94.00%) (29208/30848)
Epoch: 128 | Batch_idx: 250 |  Loss: (0.1529) |  Loss2: (0.0000) | Acc: (94.00%) (30419/32128)
Epoch: 128 | Batch_idx: 260 |  Loss: (0.1532) |  Loss2: (0.0000) | Acc: (94.00%) (31629/33408)
Epoch: 128 | Batch_idx: 270 |  Loss: (0.1528) |  Loss2: (0.0000) | Acc: (94.00%) (32840/34688)
Epoch: 128 | Batch_idx: 280 |  Loss: (0.1522) |  Loss2: (0.0000) | Acc: (94.00%) (34058/35968)
Epoch: 128 | Batch_idx: 290 |  Loss: (0.1528) |  Loss2: (0.0000) | Acc: (94.00%) (35264/37248)
Epoch: 128 | Batch_idx: 300 |  Loss: (0.1526) |  Loss2: (0.0000) | Acc: (94.00%) (36477/38528)
Epoch: 128 | Batch_idx: 310 |  Loss: (0.1524) |  Loss2: (0.0000) | Acc: (94.00%) (37690/39808)
Epoch: 128 | Batch_idx: 320 |  Loss: (0.1523) |  Loss2: (0.0000) | Acc: (94.00%) (38902/41088)
Epoch: 128 | Batch_idx: 330 |  Loss: (0.1526) |  Loss2: (0.0000) | Acc: (94.00%) (40109/42368)
Epoch: 128 | Batch_idx: 340 |  Loss: (0.1524) |  Loss2: (0.0000) | Acc: (94.00%) (41321/43648)
Epoch: 128 | Batch_idx: 350 |  Loss: (0.1524) |  Loss2: (0.0000) | Acc: (94.00%) (42536/44928)
Epoch: 128 | Batch_idx: 360 |  Loss: (0.1521) |  Loss2: (0.0000) | Acc: (94.00%) (43757/46208)
Epoch: 128 | Batch_idx: 370 |  Loss: (0.1522) |  Loss2: (0.0000) | Acc: (94.00%) (44969/47488)
Epoch: 128 | Batch_idx: 380 |  Loss: (0.1519) |  Loss2: (0.0000) | Acc: (94.00%) (46179/48768)
Epoch: 128 | Batch_idx: 390 |  Loss: (0.1512) |  Loss2: (0.0000) | Acc: (94.00%) (47359/50000)
# TEST : Loss: (0.3787) | Acc: (88.00%) (8831/10000)
percent tensor([0.6101, 0.5957, 0.6206, 0.5974, 0.6245, 0.6090, 0.6112, 0.5987, 0.6082,
        0.6002, 0.6014, 0.6178, 0.5992, 0.5852, 0.6016, 0.5970],
       device='cuda:0') torch.Size([16])
percent tensor([0.5794, 0.5307, 0.5241, 0.5949, 0.5540, 0.6283, 0.5394, 0.5558, 0.5677,
        0.5339, 0.5590, 0.5171, 0.5284, 0.6052, 0.5675, 0.5839],
       device='cuda:0') torch.Size([16])
percent tensor([0.5263, 0.5932, 0.4907, 0.4537, 0.5059, 0.4441, 0.5866, 0.5126, 0.5202,
        0.5441, 0.5352, 0.5489, 0.5652, 0.5513, 0.5363, 0.5263],
       device='cuda:0') torch.Size([16])
percent tensor([0.6615, 0.6286, 0.6389, 0.6470, 0.6486, 0.6662, 0.6472, 0.6444, 0.6557,
        0.6441, 0.6569, 0.6414, 0.6532, 0.6514, 0.6526, 0.6688],
       device='cuda:0') torch.Size([16])
percent tensor([0.5680, 0.6914, 0.6650, 0.6271, 0.6173, 0.6678, 0.6411, 0.5353, 0.7289,
        0.6235, 0.6799, 0.6888, 0.7235, 0.7538, 0.5774, 0.6235],
       device='cuda:0') torch.Size([16])
percent tensor([0.7334, 0.6996, 0.7882, 0.7874, 0.8104, 0.8154, 0.7569, 0.7078, 0.7737,
        0.7567, 0.7599, 0.7407, 0.7127, 0.8353, 0.6816, 0.7852],
       device='cuda:0') torch.Size([16])
percent tensor([0.6663, 0.5846, 0.6950, 0.6160, 0.7063, 0.6765, 0.6951, 0.6715, 0.6496,
        0.6228, 0.6217, 0.6262, 0.5307, 0.6248, 0.6335, 0.6609],
       device='cuda:0') torch.Size([16])
percent tensor([0.9995, 0.9990, 0.9991, 0.9995, 0.9988, 0.9990, 0.9993, 0.9991, 0.9994,
        0.9996, 0.9994, 0.9995, 0.9993, 0.9994, 0.9991, 0.9990],
       device='cuda:0') torch.Size([16])
Epoch: 129 | Batch_idx: 0 |  Loss: (0.1572) |  Loss2: (0.0000) | Acc: (95.00%) (122/128)
Epoch: 129 | Batch_idx: 10 |  Loss: (0.1652) |  Loss2: (0.0000) | Acc: (94.00%) (1335/1408)
Epoch: 129 | Batch_idx: 20 |  Loss: (0.1655) |  Loss2: (0.0000) | Acc: (94.00%) (2540/2688)
Epoch: 129 | Batch_idx: 30 |  Loss: (0.1583) |  Loss2: (0.0000) | Acc: (94.00%) (3756/3968)
Epoch: 129 | Batch_idx: 40 |  Loss: (0.1533) |  Loss2: (0.0000) | Acc: (94.00%) (4983/5248)
Epoch: 129 | Batch_idx: 50 |  Loss: (0.1542) |  Loss2: (0.0000) | Acc: (94.00%) (6193/6528)
Epoch: 129 | Batch_idx: 60 |  Loss: (0.1536) |  Loss2: (0.0000) | Acc: (94.00%) (7410/7808)
Epoch: 129 | Batch_idx: 70 |  Loss: (0.1554) |  Loss2: (0.0000) | Acc: (94.00%) (8621/9088)
Epoch: 129 | Batch_idx: 80 |  Loss: (0.1544) |  Loss2: (0.0000) | Acc: (94.00%) (9837/10368)
Epoch: 129 | Batch_idx: 90 |  Loss: (0.1549) |  Loss2: (0.0000) | Acc: (94.00%) (11052/11648)
Epoch: 129 | Batch_idx: 100 |  Loss: (0.1546) |  Loss2: (0.0000) | Acc: (94.00%) (12265/12928)
Epoch: 129 | Batch_idx: 110 |  Loss: (0.1537) |  Loss2: (0.0000) | Acc: (94.00%) (13483/14208)
Epoch: 129 | Batch_idx: 120 |  Loss: (0.1533) |  Loss2: (0.0000) | Acc: (94.00%) (14703/15488)
Epoch: 129 | Batch_idx: 130 |  Loss: (0.1544) |  Loss2: (0.0000) | Acc: (94.00%) (15905/16768)
Epoch: 129 | Batch_idx: 140 |  Loss: (0.1563) |  Loss2: (0.0000) | Acc: (94.00%) (17103/18048)
Epoch: 129 | Batch_idx: 150 |  Loss: (0.1558) |  Loss2: (0.0000) | Acc: (94.00%) (18318/19328)
Epoch: 129 | Batch_idx: 160 |  Loss: (0.1557) |  Loss2: (0.0000) | Acc: (94.00%) (19532/20608)
Epoch: 129 | Batch_idx: 170 |  Loss: (0.1561) |  Loss2: (0.0000) | Acc: (94.00%) (20745/21888)
Epoch: 129 | Batch_idx: 180 |  Loss: (0.1557) |  Loss2: (0.0000) | Acc: (94.00%) (21963/23168)
Epoch: 129 | Batch_idx: 190 |  Loss: (0.1553) |  Loss2: (0.0000) | Acc: (94.00%) (23184/24448)
Epoch: 129 | Batch_idx: 200 |  Loss: (0.1553) |  Loss2: (0.0000) | Acc: (94.00%) (24404/25728)
Epoch: 129 | Batch_idx: 210 |  Loss: (0.1544) |  Loss2: (0.0000) | Acc: (94.00%) (25622/27008)
Epoch: 129 | Batch_idx: 220 |  Loss: (0.1545) |  Loss2: (0.0000) | Acc: (94.00%) (26829/28288)
Epoch: 129 | Batch_idx: 230 |  Loss: (0.1546) |  Loss2: (0.0000) | Acc: (94.00%) (28039/29568)
Epoch: 129 | Batch_idx: 240 |  Loss: (0.1547) |  Loss2: (0.0000) | Acc: (94.00%) (29253/30848)
Epoch: 129 | Batch_idx: 250 |  Loss: (0.1542) |  Loss2: (0.0000) | Acc: (94.00%) (30466/32128)
Epoch: 129 | Batch_idx: 260 |  Loss: (0.1531) |  Loss2: (0.0000) | Acc: (94.00%) (31693/33408)
Epoch: 129 | Batch_idx: 270 |  Loss: (0.1524) |  Loss2: (0.0000) | Acc: (94.00%) (32917/34688)
Epoch: 129 | Batch_idx: 280 |  Loss: (0.1515) |  Loss2: (0.0000) | Acc: (94.00%) (34148/35968)
Epoch: 129 | Batch_idx: 290 |  Loss: (0.1510) |  Loss2: (0.0000) | Acc: (94.00%) (35372/37248)
Epoch: 129 | Batch_idx: 300 |  Loss: (0.1503) |  Loss2: (0.0000) | Acc: (95.00%) (36603/38528)
Epoch: 129 | Batch_idx: 310 |  Loss: (0.1497) |  Loss2: (0.0000) | Acc: (95.00%) (37827/39808)
Epoch: 129 | Batch_idx: 320 |  Loss: (0.1496) |  Loss2: (0.0000) | Acc: (95.00%) (39039/41088)
Epoch: 129 | Batch_idx: 330 |  Loss: (0.1491) |  Loss2: (0.0000) | Acc: (95.00%) (40264/42368)
Epoch: 129 | Batch_idx: 340 |  Loss: (0.1489) |  Loss2: (0.0000) | Acc: (95.00%) (41492/43648)
Epoch: 129 | Batch_idx: 350 |  Loss: (0.1485) |  Loss2: (0.0000) | Acc: (95.00%) (42716/44928)
Epoch: 129 | Batch_idx: 360 |  Loss: (0.1480) |  Loss2: (0.0000) | Acc: (95.00%) (43938/46208)
Epoch: 129 | Batch_idx: 370 |  Loss: (0.1479) |  Loss2: (0.0000) | Acc: (95.00%) (45145/47488)
Epoch: 129 | Batch_idx: 380 |  Loss: (0.1482) |  Loss2: (0.0000) | Acc: (95.00%) (46356/48768)
Epoch: 129 | Batch_idx: 390 |  Loss: (0.1486) |  Loss2: (0.0000) | Acc: (95.00%) (47521/50000)
# TEST : Loss: (0.3772) | Acc: (88.00%) (8831/10000)
percent tensor([0.6131, 0.5978, 0.6247, 0.6001, 0.6283, 0.6122, 0.6141, 0.6015, 0.6109,
        0.6031, 0.6039, 0.6216, 0.6018, 0.5868, 0.6043, 0.5995],
       device='cuda:0') torch.Size([16])
percent tensor([0.5741, 0.5251, 0.5179, 0.5889, 0.5478, 0.6225, 0.5333, 0.5491, 0.5628,
        0.5281, 0.5540, 0.5112, 0.5227, 0.6007, 0.5613, 0.5783],
       device='cuda:0') torch.Size([16])
percent tensor([0.5304, 0.5980, 0.4906, 0.4563, 0.5083, 0.4479, 0.5912, 0.5141, 0.5239,
        0.5486, 0.5403, 0.5515, 0.5687, 0.5571, 0.5412, 0.5300],
       device='cuda:0') torch.Size([16])
percent tensor([0.6605, 0.6280, 0.6369, 0.6461, 0.6465, 0.6654, 0.6454, 0.6418, 0.6551,
        0.6435, 0.6566, 0.6403, 0.6532, 0.6505, 0.6512, 0.6682],
       device='cuda:0') torch.Size([16])
percent tensor([0.5647, 0.6892, 0.6694, 0.6265, 0.6221, 0.6710, 0.6425, 0.5360, 0.7301,
        0.6213, 0.6794, 0.6875, 0.7211, 0.7549, 0.5751, 0.6246],
       device='cuda:0') torch.Size([16])
percent tensor([0.7277, 0.6917, 0.7851, 0.7823, 0.8093, 0.8143, 0.7520, 0.7044, 0.7655,
        0.7510, 0.7512, 0.7332, 0.7022, 0.8290, 0.6747, 0.7826],
       device='cuda:0') torch.Size([16])
percent tensor([0.6712, 0.5860, 0.6995, 0.6182, 0.7078, 0.6826, 0.6993, 0.6761, 0.6528,
        0.6255, 0.6240, 0.6295, 0.5309, 0.6250, 0.6382, 0.6660],
       device='cuda:0') torch.Size([16])
percent tensor([0.9995, 0.9990, 0.9992, 0.9995, 0.9990, 0.9991, 0.9994, 0.9992, 0.9994,
        0.9996, 0.9995, 0.9995, 0.9993, 0.9994, 0.9991, 0.9991],
       device='cuda:0') torch.Size([16])
True Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=128, out_features=16, bias=False)
False Linear(in_features=16, out_features=2, bias=False)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=128, out_features=16, bias=False)
False Linear(in_features=16, out_features=2, bias=False)
True Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=256, out_features=32, bias=False)
False Linear(in_features=32, out_features=2, bias=False)
True Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=256, out_features=32, bias=False)
False Linear(in_features=32, out_features=2, bias=False)
True Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=512, out_features=64, bias=False)
False Linear(in_features=64, out_features=2, bias=False)
True Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=512, out_features=64, bias=False)
False Linear(in_features=64, out_features=2, bias=False)
True Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1024, out_features=128, bias=False)
False Linear(in_features=128, out_features=2, bias=False)
True Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1024, out_features=128, bias=False)
False Linear(in_features=128, out_features=2, bias=False)
True Linear(in_features=512, out_features=10, bias=True)
Epoch: 130 | Batch_idx: 0 |  Loss: (0.1429) |  Loss2: (0.0000) | Acc: (92.00%) (118/128)
Epoch: 130 | Batch_idx: 10 |  Loss: (0.1464) |  Loss2: (0.0000) | Acc: (95.00%) (1340/1408)
Epoch: 130 | Batch_idx: 20 |  Loss: (0.1501) |  Loss2: (0.0000) | Acc: (94.00%) (2548/2688)
Epoch: 130 | Batch_idx: 30 |  Loss: (0.1501) |  Loss2: (0.0000) | Acc: (95.00%) (3770/3968)
Epoch: 130 | Batch_idx: 40 |  Loss: (0.1465) |  Loss2: (0.0000) | Acc: (95.00%) (4992/5248)
Epoch: 130 | Batch_idx: 50 |  Loss: (0.1510) |  Loss2: (0.0000) | Acc: (95.00%) (6202/6528)
Epoch: 130 | Batch_idx: 60 |  Loss: (0.1496) |  Loss2: (0.0000) | Acc: (94.00%) (7416/7808)
Epoch: 130 | Batch_idx: 70 |  Loss: (0.1522) |  Loss2: (0.0000) | Acc: (94.00%) (8627/9088)
Epoch: 130 | Batch_idx: 80 |  Loss: (0.1527) |  Loss2: (0.0000) | Acc: (94.00%) (9837/10368)
Epoch: 130 | Batch_idx: 90 |  Loss: (0.1504) |  Loss2: (0.0000) | Acc: (94.00%) (11057/11648)
Epoch: 130 | Batch_idx: 100 |  Loss: (0.1521) |  Loss2: (0.0000) | Acc: (94.00%) (12270/12928)
Epoch: 130 | Batch_idx: 110 |  Loss: (0.1532) |  Loss2: (0.0000) | Acc: (94.00%) (13481/14208)
Epoch: 130 | Batch_idx: 120 |  Loss: (0.1526) |  Loss2: (0.0000) | Acc: (94.00%) (14693/15488)
Epoch: 130 | Batch_idx: 130 |  Loss: (0.1556) |  Loss2: (0.0000) | Acc: (94.00%) (15874/16768)
Epoch: 130 | Batch_idx: 140 |  Loss: (0.1560) |  Loss2: (0.0000) | Acc: (94.00%) (17079/18048)
Epoch: 130 | Batch_idx: 150 |  Loss: (0.1576) |  Loss2: (0.0000) | Acc: (94.00%) (18276/19328)
Epoch: 130 | Batch_idx: 160 |  Loss: (0.1594) |  Loss2: (0.0000) | Acc: (94.00%) (19467/20608)
Epoch: 130 | Batch_idx: 170 |  Loss: (0.1586) |  Loss2: (0.0000) | Acc: (94.00%) (20686/21888)
Epoch: 130 | Batch_idx: 180 |  Loss: (0.1573) |  Loss2: (0.0000) | Acc: (94.00%) (21915/23168)
Epoch: 130 | Batch_idx: 190 |  Loss: (0.1571) |  Loss2: (0.0000) | Acc: (94.00%) (23124/24448)
Epoch: 130 | Batch_idx: 200 |  Loss: (0.1566) |  Loss2: (0.0000) | Acc: (94.00%) (24336/25728)
Epoch: 130 | Batch_idx: 210 |  Loss: (0.1561) |  Loss2: (0.0000) | Acc: (94.00%) (25548/27008)
Epoch: 130 | Batch_idx: 220 |  Loss: (0.1569) |  Loss2: (0.0000) | Acc: (94.00%) (26759/28288)
Epoch: 130 | Batch_idx: 230 |  Loss: (0.1569) |  Loss2: (0.0000) | Acc: (94.00%) (27971/29568)
Epoch: 130 | Batch_idx: 240 |  Loss: (0.1567) |  Loss2: (0.0000) | Acc: (94.00%) (29178/30848)
Epoch: 130 | Batch_idx: 250 |  Loss: (0.1566) |  Loss2: (0.0000) | Acc: (94.00%) (30383/32128)
Epoch: 130 | Batch_idx: 260 |  Loss: (0.1567) |  Loss2: (0.0000) | Acc: (94.00%) (31596/33408)
Epoch: 130 | Batch_idx: 270 |  Loss: (0.1567) |  Loss2: (0.0000) | Acc: (94.00%) (32804/34688)
Epoch: 130 | Batch_idx: 280 |  Loss: (0.1568) |  Loss2: (0.0000) | Acc: (94.00%) (34002/35968)
Epoch: 130 | Batch_idx: 290 |  Loss: (0.1569) |  Loss2: (0.0000) | Acc: (94.00%) (35212/37248)
Epoch: 130 | Batch_idx: 300 |  Loss: (0.1567) |  Loss2: (0.0000) | Acc: (94.00%) (36435/38528)
Epoch: 130 | Batch_idx: 310 |  Loss: (0.1566) |  Loss2: (0.0000) | Acc: (94.00%) (37643/39808)
Epoch: 130 | Batch_idx: 320 |  Loss: (0.1571) |  Loss2: (0.0000) | Acc: (94.00%) (38845/41088)
Epoch: 130 | Batch_idx: 330 |  Loss: (0.1571) |  Loss2: (0.0000) | Acc: (94.00%) (40057/42368)
Epoch: 130 | Batch_idx: 340 |  Loss: (0.1578) |  Loss2: (0.0000) | Acc: (94.00%) (41259/43648)
Epoch: 130 | Batch_idx: 350 |  Loss: (0.1574) |  Loss2: (0.0000) | Acc: (94.00%) (42470/44928)
Epoch: 130 | Batch_idx: 360 |  Loss: (0.1574) |  Loss2: (0.0000) | Acc: (94.00%) (43679/46208)
Epoch: 130 | Batch_idx: 370 |  Loss: (0.1578) |  Loss2: (0.0000) | Acc: (94.00%) (44877/47488)
Epoch: 130 | Batch_idx: 380 |  Loss: (0.1579) |  Loss2: (0.0000) | Acc: (94.00%) (46082/48768)
Epoch: 130 | Batch_idx: 390 |  Loss: (0.1578) |  Loss2: (0.0000) | Acc: (94.00%) (47250/50000)
=> saving checkpoint 'drive/app/torch/save_Routing_Gate_2/checkpoint_130.pth.tar'
# TEST : Loss: (0.4064) | Acc: (87.00%) (8750/10000)
percent tensor([0.6113, 0.5986, 0.6215, 0.5992, 0.6264, 0.6107, 0.6135, 0.6007, 0.6099,
        0.6022, 0.6033, 0.6190, 0.6004, 0.5905, 0.6039, 0.5988],
       device='cuda:0') torch.Size([16])
percent tensor([0.5756, 0.5304, 0.5193, 0.5949, 0.5535, 0.6205, 0.5387, 0.5562, 0.5621,
        0.5342, 0.5571, 0.5136, 0.5245, 0.6065, 0.5623, 0.5823],
       device='cuda:0') torch.Size([16])
percent tensor([0.5326, 0.5851, 0.5095, 0.4669, 0.5214, 0.4599, 0.5838, 0.5152, 0.5296,
        0.5424, 0.5345, 0.5548, 0.5633, 0.5433, 0.5400, 0.5265],
       device='cuda:0') torch.Size([16])
percent tensor([0.6607, 0.6263, 0.6373, 0.6464, 0.6476, 0.6658, 0.6459, 0.6440, 0.6557,
        0.6438, 0.6558, 0.6389, 0.6511, 0.6488, 0.6507, 0.6682],
       device='cuda:0') torch.Size([16])
percent tensor([0.5761, 0.6875, 0.6544, 0.6337, 0.5930, 0.6928, 0.6232, 0.5196, 0.7340,
        0.6120, 0.7010, 0.6693, 0.7248, 0.7492, 0.5799, 0.6378],
       device='cuda:0') torch.Size([16])
percent tensor([0.7242, 0.6997, 0.7715, 0.7623, 0.7987, 0.8087, 0.7631, 0.7017, 0.7743,
        0.7465, 0.7509, 0.7325, 0.7059, 0.8321, 0.6890, 0.7842],
       device='cuda:0') torch.Size([16])
percent tensor([0.6862, 0.5948, 0.7055, 0.6099, 0.7341, 0.6923, 0.7209, 0.6749, 0.6469,
        0.6285, 0.6312, 0.6254, 0.5279, 0.6156, 0.6367, 0.6835],
       device='cuda:0') torch.Size([16])
percent tensor([0.9996, 0.9988, 0.9991, 0.9995, 0.9994, 0.9992, 0.9992, 0.9990, 0.9993,
        0.9996, 0.9994, 0.9996, 0.9992, 0.9994, 0.9988, 0.9991],
       device='cuda:0') torch.Size([16])
Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 3, 3, 3]) tensor(181.2517, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(823.0416, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(826.9077, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([128, 64, 3, 3]) tensor(1526.8865, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([128, 64, 1, 1]) tensor(490.7242, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([128, 128, 3, 3]) tensor(2255.0952, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([256, 128, 3, 3]) tensor(4280.9399, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([256, 128, 1, 1]) tensor(1383.5807, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([256, 256, 3, 3]) tensor(6214.3540, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([512, 256, 3, 3]) tensor(11794.4629, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([512, 256, 1, 1]) tensor(3896.3938, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([512, 512, 3, 3]) tensor(16462.5625, device='cuda:0', grad_fn=<NormBackward0>)
Epoch: 131 | Batch_idx: 0 |  Loss: (0.1400) |  Loss2: (0.0000) | Acc: (94.00%) (121/128)
Epoch: 131 | Batch_idx: 10 |  Loss: (0.1183) |  Loss2: (0.0000) | Acc: (96.00%) (1353/1408)
Epoch: 131 | Batch_idx: 20 |  Loss: (0.1326) |  Loss2: (0.0000) | Acc: (95.00%) (2561/2688)
Epoch: 131 | Batch_idx: 30 |  Loss: (0.1422) |  Loss2: (0.0000) | Acc: (95.00%) (3774/3968)
Epoch: 131 | Batch_idx: 40 |  Loss: (0.1417) |  Loss2: (0.0000) | Acc: (95.00%) (4990/5248)
Epoch: 131 | Batch_idx: 50 |  Loss: (0.1422) |  Loss2: (0.0000) | Acc: (94.00%) (6201/6528)
Epoch: 131 | Batch_idx: 60 |  Loss: (0.1410) |  Loss2: (0.0000) | Acc: (95.00%) (7431/7808)
Epoch: 131 | Batch_idx: 70 |  Loss: (0.1443) |  Loss2: (0.0000) | Acc: (95.00%) (8637/9088)
Epoch: 131 | Batch_idx: 80 |  Loss: (0.1442) |  Loss2: (0.0000) | Acc: (95.00%) (9854/10368)
Epoch: 131 | Batch_idx: 90 |  Loss: (0.1434) |  Loss2: (0.0000) | Acc: (95.00%) (11067/11648)
Epoch: 131 | Batch_idx: 100 |  Loss: (0.1440) |  Loss2: (0.0000) | Acc: (95.00%) (12285/12928)
Epoch: 131 | Batch_idx: 110 |  Loss: (0.1435) |  Loss2: (0.0000) | Acc: (95.00%) (13512/14208)
Epoch: 131 | Batch_idx: 120 |  Loss: (0.1432) |  Loss2: (0.0000) | Acc: (95.00%) (14726/15488)
Epoch: 131 | Batch_idx: 130 |  Loss: (0.1439) |  Loss2: (0.0000) | Acc: (95.00%) (15942/16768)
Epoch: 131 | Batch_idx: 140 |  Loss: (0.1451) |  Loss2: (0.0000) | Acc: (95.00%) (17150/18048)
Epoch: 131 | Batch_idx: 150 |  Loss: (0.1454) |  Loss2: (0.0000) | Acc: (94.00%) (18360/19328)
Epoch: 131 | Batch_idx: 160 |  Loss: (0.1453) |  Loss2: (0.0000) | Acc: (94.00%) (19570/20608)
Epoch: 131 | Batch_idx: 170 |  Loss: (0.1458) |  Loss2: (0.0000) | Acc: (94.00%) (20785/21888)
Epoch: 131 | Batch_idx: 180 |  Loss: (0.1458) |  Loss2: (0.0000) | Acc: (94.00%) (22000/23168)
Epoch: 131 | Batch_idx: 190 |  Loss: (0.1477) |  Loss2: (0.0000) | Acc: (94.00%) (23192/24448)
Epoch: 131 | Batch_idx: 200 |  Loss: (0.1477) |  Loss2: (0.0000) | Acc: (94.00%) (24407/25728)
Epoch: 131 | Batch_idx: 210 |  Loss: (0.1482) |  Loss2: (0.0000) | Acc: (94.00%) (25610/27008)
Epoch: 131 | Batch_idx: 220 |  Loss: (0.1492) |  Loss2: (0.0000) | Acc: (94.00%) (26807/28288)
Epoch: 131 | Batch_idx: 230 |  Loss: (0.1500) |  Loss2: (0.0000) | Acc: (94.00%) (28017/29568)
Epoch: 131 | Batch_idx: 240 |  Loss: (0.1506) |  Loss2: (0.0000) | Acc: (94.00%) (29224/30848)
Epoch: 131 | Batch_idx: 250 |  Loss: (0.1506) |  Loss2: (0.0000) | Acc: (94.00%) (30431/32128)
Epoch: 131 | Batch_idx: 260 |  Loss: (0.1513) |  Loss2: (0.0000) | Acc: (94.00%) (31637/33408)
Epoch: 131 | Batch_idx: 270 |  Loss: (0.1521) |  Loss2: (0.0000) | Acc: (94.00%) (32845/34688)
Epoch: 131 | Batch_idx: 280 |  Loss: (0.1521) |  Loss2: (0.0000) | Acc: (94.00%) (34055/35968)
Epoch: 131 | Batch_idx: 290 |  Loss: (0.1534) |  Loss2: (0.0000) | Acc: (94.00%) (35253/37248)
Epoch: 131 | Batch_idx: 300 |  Loss: (0.1532) |  Loss2: (0.0000) | Acc: (94.00%) (36469/38528)
Epoch: 131 | Batch_idx: 310 |  Loss: (0.1530) |  Loss2: (0.0000) | Acc: (94.00%) (37674/39808)
Epoch: 131 | Batch_idx: 320 |  Loss: (0.1534) |  Loss2: (0.0000) | Acc: (94.00%) (38877/41088)
Epoch: 131 | Batch_idx: 330 |  Loss: (0.1533) |  Loss2: (0.0000) | Acc: (94.00%) (40086/42368)
Epoch: 131 | Batch_idx: 340 |  Loss: (0.1538) |  Loss2: (0.0000) | Acc: (94.00%) (41296/43648)
Epoch: 131 | Batch_idx: 350 |  Loss: (0.1536) |  Loss2: (0.0000) | Acc: (94.00%) (42511/44928)
Epoch: 131 | Batch_idx: 360 |  Loss: (0.1531) |  Loss2: (0.0000) | Acc: (94.00%) (43730/46208)
Epoch: 131 | Batch_idx: 370 |  Loss: (0.1529) |  Loss2: (0.0000) | Acc: (94.00%) (44945/47488)
Epoch: 131 | Batch_idx: 380 |  Loss: (0.1535) |  Loss2: (0.0000) | Acc: (94.00%) (46147/48768)
Epoch: 131 | Batch_idx: 390 |  Loss: (0.1537) |  Loss2: (0.0000) | Acc: (94.00%) (47314/50000)
# TEST : Loss: (0.4049) | Acc: (87.00%) (8798/10000)
percent tensor([0.6094, 0.5980, 0.6180, 0.5992, 0.6240, 0.6082, 0.6116, 0.5984, 0.6093,
        0.6013, 0.6027, 0.6151, 0.5994, 0.5893, 0.6032, 0.5988],
       device='cuda:0') torch.Size([16])
percent tensor([0.5748, 0.5254, 0.5208, 0.5949, 0.5548, 0.6190, 0.5355, 0.5564, 0.5645,
        0.5326, 0.5541, 0.5160, 0.5226, 0.6052, 0.5598, 0.5803],
       device='cuda:0') torch.Size([16])
percent tensor([0.5253, 0.5950, 0.4974, 0.4628, 0.5046, 0.4427, 0.5875, 0.5245, 0.5259,
        0.5447, 0.5344, 0.5501, 0.5651, 0.5608, 0.5362, 0.5286],
       device='cuda:0') torch.Size([16])
percent tensor([0.6592, 0.6259, 0.6319, 0.6457, 0.6445, 0.6618, 0.6441, 0.6448, 0.6534,
        0.6421, 0.6527, 0.6367, 0.6514, 0.6492, 0.6490, 0.6672],
       device='cuda:0') torch.Size([16])
percent tensor([0.5522, 0.6884, 0.6666, 0.6247, 0.5934, 0.6772, 0.6318, 0.5220, 0.7353,
        0.6101, 0.6803, 0.6737, 0.7241, 0.7514, 0.5727, 0.6249],
       device='cuda:0') torch.Size([16])
percent tensor([0.7257, 0.6997, 0.7774, 0.7708, 0.8041, 0.8034, 0.7544, 0.7132, 0.7699,
        0.7432, 0.7606, 0.7394, 0.7082, 0.8248, 0.6924, 0.7792],
       device='cuda:0') torch.Size([16])
percent tensor([0.6823, 0.5991, 0.7120, 0.6216, 0.7272, 0.7026, 0.7095, 0.6788, 0.6378,
        0.6345, 0.6404, 0.6468, 0.5332, 0.6302, 0.6473, 0.6680],
       device='cuda:0') torch.Size([16])
percent tensor([0.9994, 0.9990, 0.9992, 0.9996, 0.9995, 0.9993, 0.9992, 0.9991, 0.9993,
        0.9997, 0.9994, 0.9996, 0.9993, 0.9994, 0.9989, 0.9992],
       device='cuda:0') torch.Size([16])
Epoch: 132 | Batch_idx: 0 |  Loss: (0.1643) |  Loss2: (0.0000) | Acc: (93.00%) (120/128)
Epoch: 132 | Batch_idx: 10 |  Loss: (0.1474) |  Loss2: (0.0000) | Acc: (95.00%) (1343/1408)
Epoch: 132 | Batch_idx: 20 |  Loss: (0.1400) |  Loss2: (0.0000) | Acc: (95.00%) (2573/2688)
Epoch: 132 | Batch_idx: 30 |  Loss: (0.1456) |  Loss2: (0.0000) | Acc: (95.00%) (3774/3968)
Epoch: 132 | Batch_idx: 40 |  Loss: (0.1423) |  Loss2: (0.0000) | Acc: (95.00%) (4999/5248)
Epoch: 132 | Batch_idx: 50 |  Loss: (0.1446) |  Loss2: (0.0000) | Acc: (95.00%) (6205/6528)
Epoch: 132 | Batch_idx: 60 |  Loss: (0.1479) |  Loss2: (0.0000) | Acc: (94.00%) (7405/7808)
Epoch: 132 | Batch_idx: 70 |  Loss: (0.1506) |  Loss2: (0.0000) | Acc: (94.00%) (8623/9088)
Epoch: 132 | Batch_idx: 80 |  Loss: (0.1503) |  Loss2: (0.0000) | Acc: (94.00%) (9835/10368)
Epoch: 132 | Batch_idx: 90 |  Loss: (0.1505) |  Loss2: (0.0000) | Acc: (94.00%) (11043/11648)
Epoch: 132 | Batch_idx: 100 |  Loss: (0.1487) |  Loss2: (0.0000) | Acc: (94.00%) (12265/12928)
Epoch: 132 | Batch_idx: 110 |  Loss: (0.1474) |  Loss2: (0.0000) | Acc: (94.00%) (13489/14208)
Epoch: 132 | Batch_idx: 120 |  Loss: (0.1500) |  Loss2: (0.0000) | Acc: (94.00%) (14682/15488)
Epoch: 132 | Batch_idx: 130 |  Loss: (0.1480) |  Loss2: (0.0000) | Acc: (94.00%) (15911/16768)
Epoch: 132 | Batch_idx: 140 |  Loss: (0.1480) |  Loss2: (0.0000) | Acc: (94.00%) (17119/18048)
Epoch: 132 | Batch_idx: 150 |  Loss: (0.1487) |  Loss2: (0.0000) | Acc: (94.00%) (18336/19328)
Epoch: 132 | Batch_idx: 160 |  Loss: (0.1475) |  Loss2: (0.0000) | Acc: (94.00%) (19554/20608)
Epoch: 132 | Batch_idx: 170 |  Loss: (0.1485) |  Loss2: (0.0000) | Acc: (94.00%) (20765/21888)
Epoch: 132 | Batch_idx: 180 |  Loss: (0.1497) |  Loss2: (0.0000) | Acc: (94.00%) (21963/23168)
Epoch: 132 | Batch_idx: 190 |  Loss: (0.1506) |  Loss2: (0.0000) | Acc: (94.00%) (23162/24448)
Epoch: 132 | Batch_idx: 200 |  Loss: (0.1513) |  Loss2: (0.0000) | Acc: (94.00%) (24374/25728)
Epoch: 132 | Batch_idx: 210 |  Loss: (0.1512) |  Loss2: (0.0000) | Acc: (94.00%) (25589/27008)
Epoch: 132 | Batch_idx: 220 |  Loss: (0.1517) |  Loss2: (0.0000) | Acc: (94.00%) (26802/28288)
Epoch: 132 | Batch_idx: 230 |  Loss: (0.1518) |  Loss2: (0.0000) | Acc: (94.00%) (28017/29568)
Epoch: 132 | Batch_idx: 240 |  Loss: (0.1515) |  Loss2: (0.0000) | Acc: (94.00%) (29232/30848)
Epoch: 132 | Batch_idx: 250 |  Loss: (0.1513) |  Loss2: (0.0000) | Acc: (94.00%) (30455/32128)
Epoch: 132 | Batch_idx: 260 |  Loss: (0.1510) |  Loss2: (0.0000) | Acc: (94.00%) (31669/33408)
Epoch: 132 | Batch_idx: 270 |  Loss: (0.1507) |  Loss2: (0.0000) | Acc: (94.00%) (32885/34688)
Epoch: 132 | Batch_idx: 280 |  Loss: (0.1504) |  Loss2: (0.0000) | Acc: (94.00%) (34106/35968)
Epoch: 132 | Batch_idx: 290 |  Loss: (0.1506) |  Loss2: (0.0000) | Acc: (94.00%) (35315/37248)
Epoch: 132 | Batch_idx: 300 |  Loss: (0.1504) |  Loss2: (0.0000) | Acc: (94.00%) (36532/38528)
Epoch: 132 | Batch_idx: 310 |  Loss: (0.1501) |  Loss2: (0.0000) | Acc: (94.00%) (37746/39808)
Epoch: 132 | Batch_idx: 320 |  Loss: (0.1505) |  Loss2: (0.0000) | Acc: (94.00%) (38951/41088)
Epoch: 132 | Batch_idx: 330 |  Loss: (0.1502) |  Loss2: (0.0000) | Acc: (94.00%) (40171/42368)
Epoch: 132 | Batch_idx: 340 |  Loss: (0.1502) |  Loss2: (0.0000) | Acc: (94.00%) (41384/43648)
Epoch: 132 | Batch_idx: 350 |  Loss: (0.1509) |  Loss2: (0.0000) | Acc: (94.00%) (42582/44928)
Epoch: 132 | Batch_idx: 360 |  Loss: (0.1506) |  Loss2: (0.0000) | Acc: (94.00%) (43795/46208)
Epoch: 132 | Batch_idx: 370 |  Loss: (0.1502) |  Loss2: (0.0000) | Acc: (94.00%) (45017/47488)
Epoch: 132 | Batch_idx: 380 |  Loss: (0.1507) |  Loss2: (0.0000) | Acc: (94.00%) (46221/48768)
Epoch: 132 | Batch_idx: 390 |  Loss: (0.1504) |  Loss2: (0.0000) | Acc: (94.00%) (47390/50000)
# TEST : Loss: (0.3996) | Acc: (87.00%) (8772/10000)
percent tensor([0.6110, 0.5987, 0.6189, 0.5976, 0.6245, 0.6094, 0.6122, 0.6005, 0.6099,
        0.6020, 0.6032, 0.6172, 0.6002, 0.5908, 0.6039, 0.5992],
       device='cuda:0') torch.Size([16])
percent tensor([0.5765, 0.5278, 0.5226, 0.5935, 0.5575, 0.6244, 0.5401, 0.5536, 0.5664,
        0.5340, 0.5582, 0.5168, 0.5253, 0.6016, 0.5638, 0.5819],
       device='cuda:0') torch.Size([16])
percent tensor([0.5300, 0.5882, 0.4923, 0.4600, 0.5025, 0.4466, 0.5786, 0.5174, 0.5197,
        0.5403, 0.5347, 0.5369, 0.5645, 0.5493, 0.5356, 0.5280],
       device='cuda:0') torch.Size([16])
percent tensor([0.6570, 0.6259, 0.6329, 0.6419, 0.6426, 0.6624, 0.6439, 0.6421, 0.6510,
        0.6437, 0.6537, 0.6360, 0.6505, 0.6493, 0.6488, 0.6656],
       device='cuda:0') torch.Size([16])
percent tensor([0.5669, 0.6818, 0.6632, 0.6244, 0.5958, 0.6730, 0.6163, 0.5188, 0.7274,
        0.6157, 0.6708, 0.6555, 0.7228, 0.7609, 0.5550, 0.6210],
       device='cuda:0') torch.Size([16])
percent tensor([0.7262, 0.7098, 0.7740, 0.7611, 0.8013, 0.8057, 0.7442, 0.7091, 0.7783,
        0.7458, 0.7570, 0.7205, 0.6998, 0.8328, 0.6893, 0.7704],
       device='cuda:0') torch.Size([16])
percent tensor([0.6825, 0.6034, 0.6990, 0.6122, 0.7116, 0.6996, 0.7120, 0.6686, 0.6646,
        0.6273, 0.6575, 0.6285, 0.5429, 0.6170, 0.6511, 0.6809],
       device='cuda:0') torch.Size([16])
percent tensor([0.9995, 0.9991, 0.9991, 0.9995, 0.9995, 0.9991, 0.9993, 0.9991, 0.9993,
        0.9996, 0.9995, 0.9996, 0.9992, 0.9994, 0.9990, 0.9992],
       device='cuda:0') torch.Size([16])
Epoch: 133 | Batch_idx: 0 |  Loss: (0.1802) |  Loss2: (0.0000) | Acc: (93.00%) (120/128)
Epoch: 133 | Batch_idx: 10 |  Loss: (0.1467) |  Loss2: (0.0000) | Acc: (94.00%) (1336/1408)
Epoch: 133 | Batch_idx: 20 |  Loss: (0.1361) |  Loss2: (0.0000) | Acc: (95.00%) (2570/2688)
Epoch: 133 | Batch_idx: 30 |  Loss: (0.1404) |  Loss2: (0.0000) | Acc: (95.00%) (3780/3968)
Epoch: 133 | Batch_idx: 40 |  Loss: (0.1415) |  Loss2: (0.0000) | Acc: (95.00%) (4994/5248)
Epoch: 133 | Batch_idx: 50 |  Loss: (0.1398) |  Loss2: (0.0000) | Acc: (95.00%) (6211/6528)
Epoch: 133 | Batch_idx: 60 |  Loss: (0.1431) |  Loss2: (0.0000) | Acc: (95.00%) (7418/7808)
Epoch: 133 | Batch_idx: 70 |  Loss: (0.1412) |  Loss2: (0.0000) | Acc: (95.00%) (8646/9088)
Epoch: 133 | Batch_idx: 80 |  Loss: (0.1436) |  Loss2: (0.0000) | Acc: (95.00%) (9850/10368)
Epoch: 133 | Batch_idx: 90 |  Loss: (0.1421) |  Loss2: (0.0000) | Acc: (95.00%) (11069/11648)
Epoch: 133 | Batch_idx: 100 |  Loss: (0.1428) |  Loss2: (0.0000) | Acc: (94.00%) (12278/12928)
Epoch: 133 | Batch_idx: 110 |  Loss: (0.1437) |  Loss2: (0.0000) | Acc: (94.00%) (13495/14208)
Epoch: 133 | Batch_idx: 120 |  Loss: (0.1438) |  Loss2: (0.0000) | Acc: (94.00%) (14706/15488)
Epoch: 133 | Batch_idx: 130 |  Loss: (0.1433) |  Loss2: (0.0000) | Acc: (94.00%) (15923/16768)
Epoch: 133 | Batch_idx: 140 |  Loss: (0.1423) |  Loss2: (0.0000) | Acc: (95.00%) (17156/18048)
Epoch: 133 | Batch_idx: 150 |  Loss: (0.1420) |  Loss2: (0.0000) | Acc: (95.00%) (18376/19328)
Epoch: 133 | Batch_idx: 160 |  Loss: (0.1420) |  Loss2: (0.0000) | Acc: (95.00%) (19586/20608)
Epoch: 133 | Batch_idx: 170 |  Loss: (0.1419) |  Loss2: (0.0000) | Acc: (95.00%) (20808/21888)
Epoch: 133 | Batch_idx: 180 |  Loss: (0.1411) |  Loss2: (0.0000) | Acc: (95.00%) (22040/23168)
Epoch: 133 | Batch_idx: 190 |  Loss: (0.1414) |  Loss2: (0.0000) | Acc: (95.00%) (23257/24448)
Epoch: 133 | Batch_idx: 200 |  Loss: (0.1418) |  Loss2: (0.0000) | Acc: (95.00%) (24468/25728)
Epoch: 133 | Batch_idx: 210 |  Loss: (0.1418) |  Loss2: (0.0000) | Acc: (95.00%) (25684/27008)
Epoch: 133 | Batch_idx: 220 |  Loss: (0.1414) |  Loss2: (0.0000) | Acc: (95.00%) (26906/28288)
Epoch: 133 | Batch_idx: 230 |  Loss: (0.1416) |  Loss2: (0.0000) | Acc: (95.00%) (28127/29568)
Epoch: 133 | Batch_idx: 240 |  Loss: (0.1419) |  Loss2: (0.0000) | Acc: (95.00%) (29345/30848)
Epoch: 133 | Batch_idx: 250 |  Loss: (0.1422) |  Loss2: (0.0000) | Acc: (95.00%) (30562/32128)
Epoch: 133 | Batch_idx: 260 |  Loss: (0.1422) |  Loss2: (0.0000) | Acc: (95.00%) (31775/33408)
Epoch: 133 | Batch_idx: 270 |  Loss: (0.1420) |  Loss2: (0.0000) | Acc: (95.00%) (32991/34688)
Epoch: 133 | Batch_idx: 280 |  Loss: (0.1427) |  Loss2: (0.0000) | Acc: (95.00%) (34194/35968)
Epoch: 133 | Batch_idx: 290 |  Loss: (0.1426) |  Loss2: (0.0000) | Acc: (95.00%) (35405/37248)
Epoch: 133 | Batch_idx: 300 |  Loss: (0.1428) |  Loss2: (0.0000) | Acc: (95.00%) (36608/38528)
Epoch: 133 | Batch_idx: 310 |  Loss: (0.1436) |  Loss2: (0.0000) | Acc: (94.00%) (37810/39808)
Epoch: 133 | Batch_idx: 320 |  Loss: (0.1438) |  Loss2: (0.0000) | Acc: (94.00%) (39023/41088)
Epoch: 133 | Batch_idx: 330 |  Loss: (0.1441) |  Loss2: (0.0000) | Acc: (94.00%) (40243/42368)
Epoch: 133 | Batch_idx: 340 |  Loss: (0.1445) |  Loss2: (0.0000) | Acc: (94.00%) (41451/43648)
Epoch: 133 | Batch_idx: 350 |  Loss: (0.1442) |  Loss2: (0.0000) | Acc: (94.00%) (42670/44928)
Epoch: 133 | Batch_idx: 360 |  Loss: (0.1446) |  Loss2: (0.0000) | Acc: (94.00%) (43882/46208)
Epoch: 133 | Batch_idx: 370 |  Loss: (0.1449) |  Loss2: (0.0000) | Acc: (94.00%) (45095/47488)
Epoch: 133 | Batch_idx: 380 |  Loss: (0.1451) |  Loss2: (0.0000) | Acc: (94.00%) (46301/48768)
Epoch: 133 | Batch_idx: 390 |  Loss: (0.1457) |  Loss2: (0.0000) | Acc: (94.00%) (47459/50000)
# TEST : Loss: (0.4302) | Acc: (87.00%) (8705/10000)
percent tensor([0.6106, 0.5972, 0.6203, 0.5987, 0.6251, 0.6100, 0.6124, 0.5993, 0.6106,
        0.6017, 0.6037, 0.6172, 0.6002, 0.5906, 0.6032, 0.5998],
       device='cuda:0') torch.Size([16])
percent tensor([0.5719, 0.5224, 0.5140, 0.5878, 0.5480, 0.6180, 0.5300, 0.5525, 0.5599,
        0.5266, 0.5518, 0.5088, 0.5190, 0.5971, 0.5588, 0.5763],
       device='cuda:0') torch.Size([16])
percent tensor([0.5338, 0.5920, 0.5082, 0.4743, 0.5164, 0.4577, 0.5885, 0.5229, 0.5269,
        0.5482, 0.5401, 0.5564, 0.5708, 0.5569, 0.5410, 0.5339],
       device='cuda:0') torch.Size([16])
percent tensor([0.6595, 0.6281, 0.6331, 0.6425, 0.6413, 0.6620, 0.6454, 0.6415, 0.6569,
        0.6449, 0.6584, 0.6380, 0.6550, 0.6520, 0.6498, 0.6675],
       device='cuda:0') torch.Size([16])
percent tensor([0.5881, 0.7102, 0.6824, 0.6368, 0.6080, 0.6843, 0.6351, 0.5218, 0.7522,
        0.6411, 0.7087, 0.6876, 0.7447, 0.7808, 0.5792, 0.6388],
       device='cuda:0') torch.Size([16])
percent tensor([0.7251, 0.7123, 0.7628, 0.7529, 0.7904, 0.8034, 0.7479, 0.6964, 0.7649,
        0.7422, 0.7746, 0.7196, 0.6968, 0.8242, 0.6952, 0.7730],
       device='cuda:0') torch.Size([16])
percent tensor([0.6746, 0.6000, 0.6997, 0.6130, 0.7165, 0.7044, 0.7019, 0.6720, 0.6251,
        0.6329, 0.6456, 0.6222, 0.4948, 0.6253, 0.6457, 0.6818],
       device='cuda:0') torch.Size([16])
percent tensor([0.9995, 0.9992, 0.9991, 0.9995, 0.9993, 0.9992, 0.9993, 0.9986, 0.9993,
        0.9996, 0.9994, 0.9995, 0.9991, 0.9992, 0.9990, 0.9989],
       device='cuda:0') torch.Size([16])
Epoch: 134 | Batch_idx: 0 |  Loss: (0.1155) |  Loss2: (0.0000) | Acc: (96.00%) (123/128)
Epoch: 134 | Batch_idx: 10 |  Loss: (0.1477) |  Loss2: (0.0000) | Acc: (94.00%) (1335/1408)
Epoch: 134 | Batch_idx: 20 |  Loss: (0.1448) |  Loss2: (0.0000) | Acc: (95.00%) (2555/2688)
Epoch: 134 | Batch_idx: 30 |  Loss: (0.1444) |  Loss2: (0.0000) | Acc: (95.00%) (3775/3968)
Epoch: 134 | Batch_idx: 40 |  Loss: (0.1455) |  Loss2: (0.0000) | Acc: (94.00%) (4985/5248)
Epoch: 134 | Batch_idx: 50 |  Loss: (0.1450) |  Loss2: (0.0000) | Acc: (94.00%) (6195/6528)
Epoch: 134 | Batch_idx: 60 |  Loss: (0.1440) |  Loss2: (0.0000) | Acc: (95.00%) (7419/7808)
Epoch: 134 | Batch_idx: 70 |  Loss: (0.1426) |  Loss2: (0.0000) | Acc: (95.00%) (8638/9088)
Epoch: 134 | Batch_idx: 80 |  Loss: (0.1424) |  Loss2: (0.0000) | Acc: (95.00%) (9851/10368)
Epoch: 134 | Batch_idx: 90 |  Loss: (0.1409) |  Loss2: (0.0000) | Acc: (95.00%) (11075/11648)
Epoch: 134 | Batch_idx: 100 |  Loss: (0.1410) |  Loss2: (0.0000) | Acc: (95.00%) (12293/12928)
Epoch: 134 | Batch_idx: 110 |  Loss: (0.1413) |  Loss2: (0.0000) | Acc: (95.00%) (13513/14208)
Epoch: 134 | Batch_idx: 120 |  Loss: (0.1419) |  Loss2: (0.0000) | Acc: (95.00%) (14737/15488)
Epoch: 134 | Batch_idx: 130 |  Loss: (0.1409) |  Loss2: (0.0000) | Acc: (95.00%) (15959/16768)
Epoch: 134 | Batch_idx: 140 |  Loss: (0.1425) |  Loss2: (0.0000) | Acc: (95.00%) (17157/18048)
Epoch: 134 | Batch_idx: 150 |  Loss: (0.1423) |  Loss2: (0.0000) | Acc: (95.00%) (18375/19328)
Epoch: 134 | Batch_idx: 160 |  Loss: (0.1420) |  Loss2: (0.0000) | Acc: (95.00%) (19597/20608)
Epoch: 134 | Batch_idx: 170 |  Loss: (0.1420) |  Loss2: (0.0000) | Acc: (95.00%) (20810/21888)
Epoch: 134 | Batch_idx: 180 |  Loss: (0.1418) |  Loss2: (0.0000) | Acc: (95.00%) (22028/23168)
Epoch: 134 | Batch_idx: 190 |  Loss: (0.1413) |  Loss2: (0.0000) | Acc: (95.00%) (23255/24448)
Epoch: 134 | Batch_idx: 200 |  Loss: (0.1403) |  Loss2: (0.0000) | Acc: (95.00%) (24477/25728)
Epoch: 134 | Batch_idx: 210 |  Loss: (0.1394) |  Loss2: (0.0000) | Acc: (95.00%) (25707/27008)
Epoch: 134 | Batch_idx: 220 |  Loss: (0.1398) |  Loss2: (0.0000) | Acc: (95.00%) (26924/28288)
Epoch: 134 | Batch_idx: 230 |  Loss: (0.1401) |  Loss2: (0.0000) | Acc: (95.00%) (28136/29568)
Epoch: 134 | Batch_idx: 240 |  Loss: (0.1402) |  Loss2: (0.0000) | Acc: (95.00%) (29353/30848)
Epoch: 134 | Batch_idx: 250 |  Loss: (0.1396) |  Loss2: (0.0000) | Acc: (95.00%) (30579/32128)
Epoch: 134 | Batch_idx: 260 |  Loss: (0.1404) |  Loss2: (0.0000) | Acc: (95.00%) (31795/33408)
Epoch: 134 | Batch_idx: 270 |  Loss: (0.1404) |  Loss2: (0.0000) | Acc: (95.00%) (33014/34688)
Epoch: 134 | Batch_idx: 280 |  Loss: (0.1414) |  Loss2: (0.0000) | Acc: (95.00%) (34223/35968)
Epoch: 134 | Batch_idx: 290 |  Loss: (0.1420) |  Loss2: (0.0000) | Acc: (95.00%) (35426/37248)
Epoch: 134 | Batch_idx: 300 |  Loss: (0.1425) |  Loss2: (0.0000) | Acc: (95.00%) (36632/38528)
Epoch: 134 | Batch_idx: 310 |  Loss: (0.1423) |  Loss2: (0.0000) | Acc: (95.00%) (37849/39808)
Epoch: 134 | Batch_idx: 320 |  Loss: (0.1428) |  Loss2: (0.0000) | Acc: (95.00%) (39062/41088)
Epoch: 134 | Batch_idx: 330 |  Loss: (0.1436) |  Loss2: (0.0000) | Acc: (95.00%) (40263/42368)
Epoch: 134 | Batch_idx: 340 |  Loss: (0.1443) |  Loss2: (0.0000) | Acc: (95.00%) (41466/43648)
Epoch: 134 | Batch_idx: 350 |  Loss: (0.1440) |  Loss2: (0.0000) | Acc: (95.00%) (42691/44928)
Epoch: 134 | Batch_idx: 360 |  Loss: (0.1436) |  Loss2: (0.0000) | Acc: (95.00%) (43922/46208)
Epoch: 134 | Batch_idx: 370 |  Loss: (0.1439) |  Loss2: (0.0000) | Acc: (95.00%) (45130/47488)
Epoch: 134 | Batch_idx: 380 |  Loss: (0.1436) |  Loss2: (0.0000) | Acc: (95.00%) (46352/48768)
Epoch: 134 | Batch_idx: 390 |  Loss: (0.1440) |  Loss2: (0.0000) | Acc: (95.00%) (47509/50000)
# TEST : Loss: (0.4007) | Acc: (88.00%) (8802/10000)
percent tensor([0.6097, 0.5979, 0.6149, 0.5972, 0.6208, 0.6094, 0.6108, 0.5974, 0.6082,
        0.6009, 0.6025, 0.6128, 0.5992, 0.5908, 0.6035, 0.5990],
       device='cuda:0') torch.Size([16])
percent tensor([0.5759, 0.5197, 0.5273, 0.5983, 0.5609, 0.6232, 0.5331, 0.5600, 0.5635,
        0.5298, 0.5539, 0.5175, 0.5218, 0.5899, 0.5603, 0.5818],
       device='cuda:0') torch.Size([16])
percent tensor([0.5414, 0.6001, 0.5025, 0.4619, 0.5086, 0.4485, 0.5926, 0.5255, 0.5358,
        0.5542, 0.5511, 0.5500, 0.5787, 0.5667, 0.5400, 0.5364],
       device='cuda:0') torch.Size([16])
percent tensor([0.6605, 0.6276, 0.6364, 0.6434, 0.6430, 0.6581, 0.6461, 0.6440, 0.6580,
        0.6455, 0.6569, 0.6395, 0.6561, 0.6498, 0.6498, 0.6675],
       device='cuda:0') torch.Size([16])
percent tensor([0.5751, 0.7022, 0.6786, 0.6370, 0.6044, 0.6912, 0.6493, 0.5299, 0.7474,
        0.6519, 0.7011, 0.6825, 0.7378, 0.7792, 0.5755, 0.6422],
       device='cuda:0') torch.Size([16])
percent tensor([0.7122, 0.6915, 0.7646, 0.7620, 0.7894, 0.7963, 0.7350, 0.7050, 0.7536,
        0.7260, 0.7449, 0.7156, 0.6931, 0.8098, 0.6819, 0.7659],
       device='cuda:0') torch.Size([16])
percent tensor([0.6691, 0.5942, 0.6976, 0.6118, 0.7097, 0.6861, 0.6885, 0.6758, 0.6283,
        0.6222, 0.6491, 0.6224, 0.5224, 0.6153, 0.6281, 0.6657],
       device='cuda:0') torch.Size([16])
percent tensor([0.9994, 0.9992, 0.9989, 0.9994, 0.9993, 0.9987, 0.9992, 0.9988, 0.9994,
        0.9997, 0.9996, 0.9995, 0.9993, 0.9993, 0.9990, 0.9990],
       device='cuda:0') torch.Size([16])
False Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=128, out_features=16, bias=False)
True Linear(in_features=16, out_features=2, bias=False)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=128, out_features=16, bias=False)
True Linear(in_features=16, out_features=2, bias=False)
False Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=256, out_features=32, bias=False)
True Linear(in_features=32, out_features=2, bias=False)
False Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=256, out_features=32, bias=False)
True Linear(in_features=32, out_features=2, bias=False)
False Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=512, out_features=64, bias=False)
True Linear(in_features=64, out_features=2, bias=False)
False Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=512, out_features=64, bias=False)
True Linear(in_features=64, out_features=2, bias=False)
False Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1024, out_features=128, bias=False)
True Linear(in_features=128, out_features=2, bias=False)
False Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1024, out_features=128, bias=False)
True Linear(in_features=128, out_features=2, bias=False)
False Linear(in_features=512, out_features=10, bias=True)
Epoch: 135 | Batch_idx: 0 |  Loss: (0.1622) |  Loss2: (0.0000) | Acc: (94.00%) (121/128)
Epoch: 135 | Batch_idx: 10 |  Loss: (0.1506) |  Loss2: (0.0000) | Acc: (94.00%) (1335/1408)
Epoch: 135 | Batch_idx: 20 |  Loss: (0.1538) |  Loss2: (0.0000) | Acc: (94.00%) (2538/2688)
Epoch: 135 | Batch_idx: 30 |  Loss: (0.1638) |  Loss2: (0.0000) | Acc: (94.00%) (3730/3968)
Epoch: 135 | Batch_idx: 40 |  Loss: (0.1691) |  Loss2: (0.0000) | Acc: (93.00%) (4917/5248)
Epoch: 135 | Batch_idx: 50 |  Loss: (0.1701) |  Loss2: (0.0000) | Acc: (93.00%) (6122/6528)
Epoch: 135 | Batch_idx: 60 |  Loss: (0.1716) |  Loss2: (0.0000) | Acc: (93.00%) (7316/7808)
Epoch: 135 | Batch_idx: 70 |  Loss: (0.1675) |  Loss2: (0.0000) | Acc: (93.00%) (8531/9088)
Epoch: 135 | Batch_idx: 80 |  Loss: (0.1708) |  Loss2: (0.0000) | Acc: (93.00%) (9732/10368)
Epoch: 135 | Batch_idx: 90 |  Loss: (0.1737) |  Loss2: (0.0000) | Acc: (93.00%) (10923/11648)
Epoch: 135 | Batch_idx: 100 |  Loss: (0.1725) |  Loss2: (0.0000) | Acc: (93.00%) (12119/12928)
Epoch: 135 | Batch_idx: 110 |  Loss: (0.1708) |  Loss2: (0.0000) | Acc: (93.00%) (13328/14208)
Epoch: 135 | Batch_idx: 120 |  Loss: (0.1722) |  Loss2: (0.0000) | Acc: (93.00%) (14526/15488)
Epoch: 135 | Batch_idx: 130 |  Loss: (0.1727) |  Loss2: (0.0000) | Acc: (93.00%) (15726/16768)
Epoch: 135 | Batch_idx: 140 |  Loss: (0.1714) |  Loss2: (0.0000) | Acc: (93.00%) (16940/18048)
Epoch: 135 | Batch_idx: 150 |  Loss: (0.1708) |  Loss2: (0.0000) | Acc: (93.00%) (18146/19328)
Epoch: 135 | Batch_idx: 160 |  Loss: (0.1695) |  Loss2: (0.0000) | Acc: (93.00%) (19361/20608)
Epoch: 135 | Batch_idx: 170 |  Loss: (0.1701) |  Loss2: (0.0000) | Acc: (93.00%) (20555/21888)
Epoch: 135 | Batch_idx: 180 |  Loss: (0.1705) |  Loss2: (0.0000) | Acc: (93.00%) (21752/23168)
Epoch: 135 | Batch_idx: 190 |  Loss: (0.1719) |  Loss2: (0.0000) | Acc: (93.00%) (22949/24448)
Epoch: 135 | Batch_idx: 200 |  Loss: (0.1724) |  Loss2: (0.0000) | Acc: (93.00%) (24145/25728)
Epoch: 135 | Batch_idx: 210 |  Loss: (0.1715) |  Loss2: (0.0000) | Acc: (93.00%) (25362/27008)
Epoch: 135 | Batch_idx: 220 |  Loss: (0.1711) |  Loss2: (0.0000) | Acc: (93.00%) (26568/28288)
Epoch: 135 | Batch_idx: 230 |  Loss: (0.1698) |  Loss2: (0.0000) | Acc: (93.00%) (27784/29568)
Epoch: 135 | Batch_idx: 240 |  Loss: (0.1693) |  Loss2: (0.0000) | Acc: (93.00%) (28983/30848)
Epoch: 135 | Batch_idx: 250 |  Loss: (0.1684) |  Loss2: (0.0000) | Acc: (93.00%) (30197/32128)
Epoch: 135 | Batch_idx: 260 |  Loss: (0.1681) |  Loss2: (0.0000) | Acc: (94.00%) (31404/33408)
Epoch: 135 | Batch_idx: 270 |  Loss: (0.1682) |  Loss2: (0.0000) | Acc: (93.00%) (32599/34688)
Epoch: 135 | Batch_idx: 280 |  Loss: (0.1677) |  Loss2: (0.0000) | Acc: (94.00%) (33815/35968)
Epoch: 135 | Batch_idx: 290 |  Loss: (0.1682) |  Loss2: (0.0000) | Acc: (94.00%) (35020/37248)
Epoch: 135 | Batch_idx: 300 |  Loss: (0.1680) |  Loss2: (0.0000) | Acc: (94.00%) (36233/38528)
Epoch: 135 | Batch_idx: 310 |  Loss: (0.1672) |  Loss2: (0.0000) | Acc: (94.00%) (37441/39808)
Epoch: 135 | Batch_idx: 320 |  Loss: (0.1670) |  Loss2: (0.0000) | Acc: (94.00%) (38655/41088)
Epoch: 135 | Batch_idx: 330 |  Loss: (0.1667) |  Loss2: (0.0000) | Acc: (94.00%) (39868/42368)
Epoch: 135 | Batch_idx: 340 |  Loss: (0.1661) |  Loss2: (0.0000) | Acc: (94.00%) (41084/43648)
Epoch: 135 | Batch_idx: 350 |  Loss: (0.1655) |  Loss2: (0.0000) | Acc: (94.00%) (42302/44928)
Epoch: 135 | Batch_idx: 360 |  Loss: (0.1654) |  Loss2: (0.0000) | Acc: (94.00%) (43510/46208)
Epoch: 135 | Batch_idx: 370 |  Loss: (0.1649) |  Loss2: (0.0000) | Acc: (94.00%) (44729/47488)
Epoch: 135 | Batch_idx: 380 |  Loss: (0.1641) |  Loss2: (0.0000) | Acc: (94.00%) (45949/48768)
Epoch: 135 | Batch_idx: 390 |  Loss: (0.1644) |  Loss2: (0.0000) | Acc: (94.00%) (47105/50000)
=> saving checkpoint 'drive/app/torch/save_Routing_Gate_2/checkpoint_135.pth.tar'
# TEST : Loss: (0.4018) | Acc: (88.00%) (8816/10000)
percent tensor([0.6104, 0.5999, 0.6121, 0.5989, 0.6196, 0.6108, 0.6114, 0.5975, 0.6096,
        0.6018, 0.6039, 0.6116, 0.6004, 0.5942, 0.6055, 0.6008],
       device='cuda:0') torch.Size([16])
percent tensor([0.5777, 0.5151, 0.5368, 0.6066, 0.5650, 0.6287, 0.5296, 0.5661, 0.5628,
        0.5290, 0.5516, 0.5206, 0.5189, 0.5850, 0.5628, 0.5838],
       device='cuda:0') torch.Size([16])
percent tensor([0.5541, 0.6171, 0.5085, 0.4734, 0.5145, 0.4578, 0.6051, 0.5351, 0.5478,
        0.5678, 0.5698, 0.5560, 0.5942, 0.5865, 0.5554, 0.5498],
       device='cuda:0') torch.Size([16])
percent tensor([0.6643, 0.6289, 0.6414, 0.6510, 0.6505, 0.6637, 0.6488, 0.6524, 0.6623,
        0.6481, 0.6596, 0.6419, 0.6571, 0.6542, 0.6543, 0.6716],
       device='cuda:0') torch.Size([16])
percent tensor([0.5697, 0.6970, 0.6343, 0.5937, 0.5735, 0.6888, 0.6387, 0.4790, 0.7340,
        0.6409, 0.7063, 0.6532, 0.7447, 0.7777, 0.5543, 0.6409],
       device='cuda:0') torch.Size([16])
percent tensor([0.7202, 0.6910, 0.7853, 0.7744, 0.8078, 0.8012, 0.7430, 0.7297, 0.7588,
        0.7349, 0.7524, 0.7257, 0.6986, 0.8067, 0.6890, 0.7753],
       device='cuda:0') torch.Size([16])
percent tensor([0.6215, 0.5450, 0.6842, 0.5896, 0.7062, 0.6412, 0.6561, 0.6761, 0.5783,
        0.5791, 0.5899, 0.6028, 0.4674, 0.5405, 0.5963, 0.6289],
       device='cuda:0') torch.Size([16])
percent tensor([0.9992, 0.9991, 0.9990, 0.9995, 0.9993, 0.9986, 0.9993, 0.9990, 0.9994,
        0.9997, 0.9995, 0.9995, 0.9993, 0.9992, 0.9992, 0.9991],
       device='cuda:0') torch.Size([16])
Epoch: 136 | Batch_idx: 0 |  Loss: (0.1503) |  Loss2: (0.0000) | Acc: (94.00%) (121/128)
Epoch: 136 | Batch_idx: 10 |  Loss: (0.1592) |  Loss2: (0.0000) | Acc: (94.00%) (1326/1408)
Epoch: 136 | Batch_idx: 20 |  Loss: (0.1578) |  Loss2: (0.0000) | Acc: (94.00%) (2530/2688)
Epoch: 136 | Batch_idx: 30 |  Loss: (0.1612) |  Loss2: (0.0000) | Acc: (94.00%) (3738/3968)
Epoch: 136 | Batch_idx: 40 |  Loss: (0.1551) |  Loss2: (0.0000) | Acc: (94.00%) (4965/5248)
Epoch: 136 | Batch_idx: 50 |  Loss: (0.1503) |  Loss2: (0.0000) | Acc: (94.00%) (6183/6528)
Epoch: 136 | Batch_idx: 60 |  Loss: (0.1535) |  Loss2: (0.0000) | Acc: (94.00%) (7390/7808)
Epoch: 136 | Batch_idx: 70 |  Loss: (0.1504) |  Loss2: (0.0000) | Acc: (94.00%) (8608/9088)
Epoch: 136 | Batch_idx: 80 |  Loss: (0.1503) |  Loss2: (0.0000) | Acc: (94.00%) (9823/10368)
Epoch: 136 | Batch_idx: 90 |  Loss: (0.1503) |  Loss2: (0.0000) | Acc: (94.00%) (11034/11648)
Epoch: 136 | Batch_idx: 100 |  Loss: (0.1514) |  Loss2: (0.0000) | Acc: (94.00%) (12235/12928)
Epoch: 136 | Batch_idx: 110 |  Loss: (0.1510) |  Loss2: (0.0000) | Acc: (94.00%) (13453/14208)
Epoch: 136 | Batch_idx: 120 |  Loss: (0.1522) |  Loss2: (0.0000) | Acc: (94.00%) (14655/15488)
Epoch: 136 | Batch_idx: 130 |  Loss: (0.1520) |  Loss2: (0.0000) | Acc: (94.00%) (15868/16768)
Epoch: 136 | Batch_idx: 140 |  Loss: (0.1536) |  Loss2: (0.0000) | Acc: (94.00%) (17074/18048)
Epoch: 136 | Batch_idx: 150 |  Loss: (0.1535) |  Loss2: (0.0000) | Acc: (94.00%) (18291/19328)
Epoch: 136 | Batch_idx: 160 |  Loss: (0.1531) |  Loss2: (0.0000) | Acc: (94.00%) (19504/20608)
Epoch: 136 | Batch_idx: 170 |  Loss: (0.1527) |  Loss2: (0.0000) | Acc: (94.00%) (20712/21888)
Epoch: 136 | Batch_idx: 180 |  Loss: (0.1515) |  Loss2: (0.0000) | Acc: (94.00%) (21940/23168)
Epoch: 136 | Batch_idx: 190 |  Loss: (0.1520) |  Loss2: (0.0000) | Acc: (94.00%) (23153/24448)
Epoch: 136 | Batch_idx: 200 |  Loss: (0.1507) |  Loss2: (0.0000) | Acc: (94.00%) (24379/25728)
Epoch: 136 | Batch_idx: 210 |  Loss: (0.1504) |  Loss2: (0.0000) | Acc: (94.00%) (25600/27008)
Epoch: 136 | Batch_idx: 220 |  Loss: (0.1499) |  Loss2: (0.0000) | Acc: (94.00%) (26818/28288)
Epoch: 136 | Batch_idx: 230 |  Loss: (0.1504) |  Loss2: (0.0000) | Acc: (94.00%) (28030/29568)
Epoch: 136 | Batch_idx: 240 |  Loss: (0.1503) |  Loss2: (0.0000) | Acc: (94.00%) (29249/30848)
Epoch: 136 | Batch_idx: 250 |  Loss: (0.1497) |  Loss2: (0.0000) | Acc: (94.00%) (30475/32128)
Epoch: 136 | Batch_idx: 260 |  Loss: (0.1489) |  Loss2: (0.0000) | Acc: (94.00%) (31697/33408)
Epoch: 136 | Batch_idx: 270 |  Loss: (0.1486) |  Loss2: (0.0000) | Acc: (94.00%) (32921/34688)
Epoch: 136 | Batch_idx: 280 |  Loss: (0.1480) |  Loss2: (0.0000) | Acc: (94.00%) (34140/35968)
Epoch: 136 | Batch_idx: 290 |  Loss: (0.1478) |  Loss2: (0.0000) | Acc: (94.00%) (35362/37248)
Epoch: 136 | Batch_idx: 300 |  Loss: (0.1471) |  Loss2: (0.0000) | Acc: (94.00%) (36583/38528)
Epoch: 136 | Batch_idx: 310 |  Loss: (0.1473) |  Loss2: (0.0000) | Acc: (94.00%) (37785/39808)
Epoch: 136 | Batch_idx: 320 |  Loss: (0.1477) |  Loss2: (0.0000) | Acc: (94.00%) (38992/41088)
Epoch: 136 | Batch_idx: 330 |  Loss: (0.1473) |  Loss2: (0.0000) | Acc: (94.00%) (40218/42368)
Epoch: 136 | Batch_idx: 340 |  Loss: (0.1471) |  Loss2: (0.0000) | Acc: (94.00%) (41434/43648)
Epoch: 136 | Batch_idx: 350 |  Loss: (0.1473) |  Loss2: (0.0000) | Acc: (94.00%) (42639/44928)
Epoch: 136 | Batch_idx: 360 |  Loss: (0.1471) |  Loss2: (0.0000) | Acc: (94.00%) (43853/46208)
Epoch: 136 | Batch_idx: 370 |  Loss: (0.1467) |  Loss2: (0.0000) | Acc: (94.00%) (45078/47488)
Epoch: 136 | Batch_idx: 380 |  Loss: (0.1468) |  Loss2: (0.0000) | Acc: (94.00%) (46281/48768)
Epoch: 136 | Batch_idx: 390 |  Loss: (0.1467) |  Loss2: (0.0000) | Acc: (94.00%) (47450/50000)
# TEST : Loss: (0.3875) | Acc: (88.00%) (8854/10000)
percent tensor([0.6077, 0.5975, 0.6095, 0.5962, 0.6168, 0.6088, 0.6088, 0.5950, 0.6072,
        0.5992, 0.6016, 0.6087, 0.5977, 0.5923, 0.6031, 0.5982],
       device='cuda:0') torch.Size([16])
percent tensor([0.5676, 0.5041, 0.5276, 0.5986, 0.5559, 0.6209, 0.5195, 0.5573, 0.5540,
        0.5177, 0.5404, 0.5101, 0.5070, 0.5780, 0.5530, 0.5743],
       device='cuda:0') torch.Size([16])
percent tensor([0.5570, 0.6183, 0.5127, 0.4749, 0.5151, 0.4626, 0.6063, 0.5358, 0.5500,
        0.5704, 0.5741, 0.5586, 0.5979, 0.5861, 0.5584, 0.5535],
       device='cuda:0') torch.Size([16])
percent tensor([0.6635, 0.6254, 0.6431, 0.6526, 0.6517, 0.6662, 0.6460, 0.6526, 0.6611,
        0.6451, 0.6567, 0.6404, 0.6543, 0.6514, 0.6532, 0.6715],
       device='cuda:0') torch.Size([16])
percent tensor([0.5825, 0.7081, 0.6369, 0.6046, 0.5816, 0.7014, 0.6493, 0.4813, 0.7460,
        0.6565, 0.7250, 0.6636, 0.7599, 0.7867, 0.5624, 0.6624],
       device='cuda:0') torch.Size([16])
percent tensor([0.7059, 0.6793, 0.7763, 0.7637, 0.7993, 0.7944, 0.7306, 0.7167, 0.7491,
        0.7208, 0.7415, 0.7154, 0.6845, 0.7983, 0.6763, 0.7619],
       device='cuda:0') torch.Size([16])
percent tensor([0.6295, 0.5584, 0.6921, 0.6003, 0.7163, 0.6477, 0.6633, 0.6849, 0.5861,
        0.5869, 0.5966, 0.6152, 0.4788, 0.5479, 0.6065, 0.6349],
       device='cuda:0') torch.Size([16])
percent tensor([0.9993, 0.9991, 0.9990, 0.9995, 0.9993, 0.9987, 0.9992, 0.9989, 0.9994,
        0.9997, 0.9995, 0.9995, 0.9993, 0.9993, 0.9991, 0.9991],
       device='cuda:0') torch.Size([16])
Epoch: 137 | Batch_idx: 0 |  Loss: (0.1546) |  Loss2: (0.0000) | Acc: (95.00%) (122/128)
Epoch: 137 | Batch_idx: 10 |  Loss: (0.1318) |  Loss2: (0.0000) | Acc: (95.00%) (1346/1408)
Epoch: 137 | Batch_idx: 20 |  Loss: (0.1327) |  Loss2: (0.0000) | Acc: (95.00%) (2558/2688)
Epoch: 137 | Batch_idx: 30 |  Loss: (0.1370) |  Loss2: (0.0000) | Acc: (95.00%) (3774/3968)
Epoch: 137 | Batch_idx: 40 |  Loss: (0.1417) |  Loss2: (0.0000) | Acc: (95.00%) (4986/5248)
Epoch: 137 | Batch_idx: 50 |  Loss: (0.1435) |  Loss2: (0.0000) | Acc: (94.00%) (6198/6528)
Epoch: 137 | Batch_idx: 60 |  Loss: (0.1416) |  Loss2: (0.0000) | Acc: (95.00%) (7432/7808)
Epoch: 137 | Batch_idx: 70 |  Loss: (0.1368) |  Loss2: (0.0000) | Acc: (95.00%) (8666/9088)
Epoch: 137 | Batch_idx: 80 |  Loss: (0.1375) |  Loss2: (0.0000) | Acc: (95.00%) (9878/10368)
Epoch: 137 | Batch_idx: 90 |  Loss: (0.1378) |  Loss2: (0.0000) | Acc: (95.00%) (11093/11648)
Epoch: 137 | Batch_idx: 100 |  Loss: (0.1374) |  Loss2: (0.0000) | Acc: (95.00%) (12311/12928)
Epoch: 137 | Batch_idx: 110 |  Loss: (0.1378) |  Loss2: (0.0000) | Acc: (95.00%) (13530/14208)
Epoch: 137 | Batch_idx: 120 |  Loss: (0.1382) |  Loss2: (0.0000) | Acc: (95.00%) (14745/15488)
Epoch: 137 | Batch_idx: 130 |  Loss: (0.1376) |  Loss2: (0.0000) | Acc: (95.00%) (15969/16768)
Epoch: 137 | Batch_idx: 140 |  Loss: (0.1375) |  Loss2: (0.0000) | Acc: (95.00%) (17191/18048)
Epoch: 137 | Batch_idx: 150 |  Loss: (0.1402) |  Loss2: (0.0000) | Acc: (95.00%) (18387/19328)
Epoch: 137 | Batch_idx: 160 |  Loss: (0.1415) |  Loss2: (0.0000) | Acc: (95.00%) (19594/20608)
Epoch: 137 | Batch_idx: 170 |  Loss: (0.1421) |  Loss2: (0.0000) | Acc: (95.00%) (20804/21888)
Epoch: 137 | Batch_idx: 180 |  Loss: (0.1424) |  Loss2: (0.0000) | Acc: (95.00%) (22017/23168)
Epoch: 137 | Batch_idx: 190 |  Loss: (0.1426) |  Loss2: (0.0000) | Acc: (95.00%) (23229/24448)
Epoch: 137 | Batch_idx: 200 |  Loss: (0.1417) |  Loss2: (0.0000) | Acc: (95.00%) (24454/25728)
Epoch: 137 | Batch_idx: 210 |  Loss: (0.1414) |  Loss2: (0.0000) | Acc: (95.00%) (25681/27008)
Epoch: 137 | Batch_idx: 220 |  Loss: (0.1409) |  Loss2: (0.0000) | Acc: (95.00%) (26908/28288)
Epoch: 137 | Batch_idx: 230 |  Loss: (0.1399) |  Loss2: (0.0000) | Acc: (95.00%) (28139/29568)
Epoch: 137 | Batch_idx: 240 |  Loss: (0.1395) |  Loss2: (0.0000) | Acc: (95.00%) (29366/30848)
Epoch: 137 | Batch_idx: 250 |  Loss: (0.1395) |  Loss2: (0.0000) | Acc: (95.00%) (30577/32128)
Epoch: 137 | Batch_idx: 260 |  Loss: (0.1400) |  Loss2: (0.0000) | Acc: (95.00%) (31799/33408)
Epoch: 137 | Batch_idx: 270 |  Loss: (0.1397) |  Loss2: (0.0000) | Acc: (95.00%) (33024/34688)
Epoch: 137 | Batch_idx: 280 |  Loss: (0.1394) |  Loss2: (0.0000) | Acc: (95.00%) (34245/35968)
Epoch: 137 | Batch_idx: 290 |  Loss: (0.1401) |  Loss2: (0.0000) | Acc: (95.00%) (35453/37248)
Epoch: 137 | Batch_idx: 300 |  Loss: (0.1394) |  Loss2: (0.0000) | Acc: (95.00%) (36684/38528)
Epoch: 137 | Batch_idx: 310 |  Loss: (0.1396) |  Loss2: (0.0000) | Acc: (95.00%) (37906/39808)
Epoch: 137 | Batch_idx: 320 |  Loss: (0.1389) |  Loss2: (0.0000) | Acc: (95.00%) (39137/41088)
Epoch: 137 | Batch_idx: 330 |  Loss: (0.1388) |  Loss2: (0.0000) | Acc: (95.00%) (40348/42368)
Epoch: 137 | Batch_idx: 340 |  Loss: (0.1388) |  Loss2: (0.0000) | Acc: (95.00%) (41563/43648)
Epoch: 137 | Batch_idx: 350 |  Loss: (0.1390) |  Loss2: (0.0000) | Acc: (95.00%) (42783/44928)
Epoch: 137 | Batch_idx: 360 |  Loss: (0.1388) |  Loss2: (0.0000) | Acc: (95.00%) (44006/46208)
Epoch: 137 | Batch_idx: 370 |  Loss: (0.1385) |  Loss2: (0.0000) | Acc: (95.00%) (45237/47488)
Epoch: 137 | Batch_idx: 380 |  Loss: (0.1388) |  Loss2: (0.0000) | Acc: (95.00%) (46450/48768)
Epoch: 137 | Batch_idx: 390 |  Loss: (0.1386) |  Loss2: (0.0000) | Acc: (95.00%) (47631/50000)
# TEST : Loss: (0.3833) | Acc: (88.00%) (8857/10000)
percent tensor([0.6072, 0.5971, 0.6084, 0.5954, 0.6160, 0.6086, 0.6082, 0.5945, 0.6069,
        0.5985, 0.6013, 0.6077, 0.5972, 0.5923, 0.6028, 0.5976],
       device='cuda:0') torch.Size([16])
percent tensor([0.5743, 0.5116, 0.5337, 0.6067, 0.5636, 0.6284, 0.5271, 0.5656, 0.5617,
        0.5245, 0.5471, 0.5163, 0.5126, 0.5880, 0.5603, 0.5820],
       device='cuda:0') torch.Size([16])
percent tensor([0.5517, 0.6136, 0.5121, 0.4708, 0.5120, 0.4593, 0.6022, 0.5317, 0.5449,
        0.5660, 0.5688, 0.5557, 0.5930, 0.5798, 0.5534, 0.5489],
       device='cuda:0') torch.Size([16])
percent tensor([0.6699, 0.6298, 0.6505, 0.6604, 0.6597, 0.6750, 0.6517, 0.6604, 0.6669,
        0.6500, 0.6617, 0.6462, 0.6588, 0.6566, 0.6597, 0.6786],
       device='cuda:0') torch.Size([16])
percent tensor([0.5776, 0.7027, 0.6316, 0.6026, 0.5802, 0.6978, 0.6437, 0.4742, 0.7431,
        0.6522, 0.7254, 0.6594, 0.7580, 0.7801, 0.5547, 0.6611],
       device='cuda:0') torch.Size([16])
percent tensor([0.7066, 0.6818, 0.7752, 0.7623, 0.7989, 0.7937, 0.7305, 0.7169, 0.7502,
        0.7223, 0.7436, 0.7152, 0.6846, 0.8020, 0.6784, 0.7613],
       device='cuda:0') torch.Size([16])
percent tensor([0.6346, 0.5716, 0.6999, 0.6079, 0.7260, 0.6479, 0.6729, 0.6950, 0.5962,
        0.5972, 0.6048, 0.6259, 0.4855, 0.5566, 0.6182, 0.6398],
       device='cuda:0') torch.Size([16])
percent tensor([0.9993, 0.9992, 0.9990, 0.9995, 0.9994, 0.9986, 0.9993, 0.9989, 0.9994,
        0.9997, 0.9995, 0.9995, 0.9993, 0.9993, 0.9991, 0.9991],
       device='cuda:0') torch.Size([16])
Epoch: 138 | Batch_idx: 0 |  Loss: (0.1115) |  Loss2: (0.0000) | Acc: (96.00%) (124/128)
Epoch: 138 | Batch_idx: 10 |  Loss: (0.1469) |  Loss2: (0.0000) | Acc: (94.00%) (1333/1408)
Epoch: 138 | Batch_idx: 20 |  Loss: (0.1460) |  Loss2: (0.0000) | Acc: (94.00%) (2545/2688)
Epoch: 138 | Batch_idx: 30 |  Loss: (0.1459) |  Loss2: (0.0000) | Acc: (94.00%) (3754/3968)
Epoch: 138 | Batch_idx: 40 |  Loss: (0.1426) |  Loss2: (0.0000) | Acc: (94.00%) (4979/5248)
Epoch: 138 | Batch_idx: 50 |  Loss: (0.1408) |  Loss2: (0.0000) | Acc: (95.00%) (6202/6528)
Epoch: 138 | Batch_idx: 60 |  Loss: (0.1382) |  Loss2: (0.0000) | Acc: (95.00%) (7430/7808)
Epoch: 138 | Batch_idx: 70 |  Loss: (0.1378) |  Loss2: (0.0000) | Acc: (95.00%) (8655/9088)
Epoch: 138 | Batch_idx: 80 |  Loss: (0.1364) |  Loss2: (0.0000) | Acc: (95.00%) (9881/10368)
Epoch: 138 | Batch_idx: 90 |  Loss: (0.1392) |  Loss2: (0.0000) | Acc: (95.00%) (11084/11648)
Epoch: 138 | Batch_idx: 100 |  Loss: (0.1393) |  Loss2: (0.0000) | Acc: (95.00%) (12306/12928)
Epoch: 138 | Batch_idx: 110 |  Loss: (0.1386) |  Loss2: (0.0000) | Acc: (95.00%) (13526/14208)
Epoch: 138 | Batch_idx: 120 |  Loss: (0.1360) |  Loss2: (0.0000) | Acc: (95.00%) (14764/15488)
Epoch: 138 | Batch_idx: 130 |  Loss: (0.1353) |  Loss2: (0.0000) | Acc: (95.00%) (15984/16768)
Epoch: 138 | Batch_idx: 140 |  Loss: (0.1364) |  Loss2: (0.0000) | Acc: (95.00%) (17197/18048)
Epoch: 138 | Batch_idx: 150 |  Loss: (0.1346) |  Loss2: (0.0000) | Acc: (95.00%) (18426/19328)
Epoch: 138 | Batch_idx: 160 |  Loss: (0.1329) |  Loss2: (0.0000) | Acc: (95.00%) (19658/20608)
Epoch: 138 | Batch_idx: 170 |  Loss: (0.1330) |  Loss2: (0.0000) | Acc: (95.00%) (20887/21888)
Epoch: 138 | Batch_idx: 180 |  Loss: (0.1327) |  Loss2: (0.0000) | Acc: (95.00%) (22111/23168)
Epoch: 138 | Batch_idx: 190 |  Loss: (0.1327) |  Loss2: (0.0000) | Acc: (95.00%) (23327/24448)
Epoch: 138 | Batch_idx: 200 |  Loss: (0.1330) |  Loss2: (0.0000) | Acc: (95.00%) (24548/25728)
Epoch: 138 | Batch_idx: 210 |  Loss: (0.1328) |  Loss2: (0.0000) | Acc: (95.00%) (25772/27008)
Epoch: 138 | Batch_idx: 220 |  Loss: (0.1329) |  Loss2: (0.0000) | Acc: (95.00%) (27000/28288)
Epoch: 138 | Batch_idx: 230 |  Loss: (0.1341) |  Loss2: (0.0000) | Acc: (95.00%) (28212/29568)
Epoch: 138 | Batch_idx: 240 |  Loss: (0.1342) |  Loss2: (0.0000) | Acc: (95.00%) (29434/30848)
Epoch: 138 | Batch_idx: 250 |  Loss: (0.1349) |  Loss2: (0.0000) | Acc: (95.00%) (30654/32128)
Epoch: 138 | Batch_idx: 260 |  Loss: (0.1344) |  Loss2: (0.0000) | Acc: (95.00%) (31886/33408)
Epoch: 138 | Batch_idx: 270 |  Loss: (0.1344) |  Loss2: (0.0000) | Acc: (95.00%) (33101/34688)
Epoch: 138 | Batch_idx: 280 |  Loss: (0.1351) |  Loss2: (0.0000) | Acc: (95.00%) (34313/35968)
Epoch: 138 | Batch_idx: 290 |  Loss: (0.1348) |  Loss2: (0.0000) | Acc: (95.00%) (35540/37248)
Epoch: 138 | Batch_idx: 300 |  Loss: (0.1345) |  Loss2: (0.0000) | Acc: (95.00%) (36773/38528)
Epoch: 138 | Batch_idx: 310 |  Loss: (0.1338) |  Loss2: (0.0000) | Acc: (95.00%) (38005/39808)
Epoch: 138 | Batch_idx: 320 |  Loss: (0.1340) |  Loss2: (0.0000) | Acc: (95.00%) (39226/41088)
Epoch: 138 | Batch_idx: 330 |  Loss: (0.1334) |  Loss2: (0.0000) | Acc: (95.00%) (40462/42368)
Epoch: 138 | Batch_idx: 340 |  Loss: (0.1335) |  Loss2: (0.0000) | Acc: (95.00%) (41685/43648)
Epoch: 138 | Batch_idx: 350 |  Loss: (0.1332) |  Loss2: (0.0000) | Acc: (95.00%) (42912/44928)
Epoch: 138 | Batch_idx: 360 |  Loss: (0.1331) |  Loss2: (0.0000) | Acc: (95.00%) (44133/46208)
Epoch: 138 | Batch_idx: 370 |  Loss: (0.1331) |  Loss2: (0.0000) | Acc: (95.00%) (45360/47488)
Epoch: 138 | Batch_idx: 380 |  Loss: (0.1332) |  Loss2: (0.0000) | Acc: (95.00%) (46585/48768)
Epoch: 138 | Batch_idx: 390 |  Loss: (0.1331) |  Loss2: (0.0000) | Acc: (95.00%) (47758/50000)
# TEST : Loss: (0.3772) | Acc: (88.00%) (8882/10000)
percent tensor([0.6093, 0.5993, 0.6096, 0.5966, 0.6177, 0.6113, 0.6103, 0.5960, 0.6092,
        0.6002, 0.6036, 0.6092, 0.5992, 0.5948, 0.6052, 0.5995],
       device='cuda:0') torch.Size([16])
percent tensor([0.5759, 0.5145, 0.5348, 0.6086, 0.5656, 0.6298, 0.5298, 0.5676, 0.5646,
        0.5269, 0.5493, 0.5179, 0.5140, 0.5932, 0.5627, 0.5842],
       device='cuda:0') torch.Size([16])
percent tensor([0.5505, 0.6105, 0.5141, 0.4703, 0.5118, 0.4600, 0.6000, 0.5319, 0.5434,
        0.5645, 0.5670, 0.5556, 0.5917, 0.5747, 0.5520, 0.5474],
       device='cuda:0') torch.Size([16])
percent tensor([0.6672, 0.6265, 0.6488, 0.6591, 0.6580, 0.6744, 0.6484, 0.6585, 0.6645,
        0.6464, 0.6588, 0.6434, 0.6554, 0.6537, 0.6575, 0.6761],
       device='cuda:0') torch.Size([16])
percent tensor([0.5759, 0.7013, 0.6346, 0.6042, 0.5812, 0.6968, 0.6416, 0.4738, 0.7460,
        0.6535, 0.7284, 0.6595, 0.7605, 0.7758, 0.5524, 0.6605],
       device='cuda:0') torch.Size([16])
percent tensor([0.7105, 0.6867, 0.7791, 0.7628, 0.8018, 0.7968, 0.7334, 0.7192, 0.7536,
        0.7275, 0.7495, 0.7209, 0.6900, 0.8067, 0.6840, 0.7636],
       device='cuda:0') torch.Size([16])
percent tensor([0.6418, 0.5813, 0.7049, 0.6139, 0.7305, 0.6561, 0.6803, 0.6965, 0.6033,
        0.6040, 0.6096, 0.6336, 0.4945, 0.5585, 0.6229, 0.6453],
       device='cuda:0') torch.Size([16])
percent tensor([0.9993, 0.9992, 0.9990, 0.9995, 0.9994, 0.9987, 0.9993, 0.9989, 0.9994,
        0.9997, 0.9995, 0.9995, 0.9993, 0.9993, 0.9992, 0.9991],
       device='cuda:0') torch.Size([16])
Epoch: 139 | Batch_idx: 0 |  Loss: (0.1057) |  Loss2: (0.0000) | Acc: (98.00%) (126/128)
Epoch: 139 | Batch_idx: 10 |  Loss: (0.1312) |  Loss2: (0.0000) | Acc: (95.00%) (1347/1408)
Epoch: 139 | Batch_idx: 20 |  Loss: (0.1320) |  Loss2: (0.0000) | Acc: (95.00%) (2565/2688)
Epoch: 139 | Batch_idx: 30 |  Loss: (0.1373) |  Loss2: (0.0000) | Acc: (95.00%) (3770/3968)
Epoch: 139 | Batch_idx: 40 |  Loss: (0.1415) |  Loss2: (0.0000) | Acc: (94.00%) (4978/5248)
Epoch: 139 | Batch_idx: 50 |  Loss: (0.1410) |  Loss2: (0.0000) | Acc: (94.00%) (6196/6528)
Epoch: 139 | Batch_idx: 60 |  Loss: (0.1389) |  Loss2: (0.0000) | Acc: (95.00%) (7429/7808)
Epoch: 139 | Batch_idx: 70 |  Loss: (0.1367) |  Loss2: (0.0000) | Acc: (95.00%) (8658/9088)
Epoch: 139 | Batch_idx: 80 |  Loss: (0.1362) |  Loss2: (0.0000) | Acc: (95.00%) (9879/10368)
Epoch: 139 | Batch_idx: 90 |  Loss: (0.1331) |  Loss2: (0.0000) | Acc: (95.00%) (11114/11648)
Epoch: 139 | Batch_idx: 100 |  Loss: (0.1322) |  Loss2: (0.0000) | Acc: (95.00%) (12344/12928)
Epoch: 139 | Batch_idx: 110 |  Loss: (0.1325) |  Loss2: (0.0000) | Acc: (95.00%) (13570/14208)
Epoch: 139 | Batch_idx: 120 |  Loss: (0.1317) |  Loss2: (0.0000) | Acc: (95.00%) (14793/15488)
Epoch: 139 | Batch_idx: 130 |  Loss: (0.1327) |  Loss2: (0.0000) | Acc: (95.00%) (16002/16768)
Epoch: 139 | Batch_idx: 140 |  Loss: (0.1324) |  Loss2: (0.0000) | Acc: (95.00%) (17228/18048)
Epoch: 139 | Batch_idx: 150 |  Loss: (0.1324) |  Loss2: (0.0000) | Acc: (95.00%) (18450/19328)
Epoch: 139 | Batch_idx: 160 |  Loss: (0.1324) |  Loss2: (0.0000) | Acc: (95.00%) (19674/20608)
Epoch: 139 | Batch_idx: 170 |  Loss: (0.1317) |  Loss2: (0.0000) | Acc: (95.00%) (20903/21888)
Epoch: 139 | Batch_idx: 180 |  Loss: (0.1314) |  Loss2: (0.0000) | Acc: (95.00%) (22127/23168)
Epoch: 139 | Batch_idx: 190 |  Loss: (0.1309) |  Loss2: (0.0000) | Acc: (95.00%) (23360/24448)
Epoch: 139 | Batch_idx: 200 |  Loss: (0.1309) |  Loss2: (0.0000) | Acc: (95.00%) (24582/25728)
Epoch: 139 | Batch_idx: 210 |  Loss: (0.1311) |  Loss2: (0.0000) | Acc: (95.00%) (25797/27008)
Epoch: 139 | Batch_idx: 220 |  Loss: (0.1306) |  Loss2: (0.0000) | Acc: (95.00%) (27033/28288)
Epoch: 139 | Batch_idx: 230 |  Loss: (0.1310) |  Loss2: (0.0000) | Acc: (95.00%) (28259/29568)
Epoch: 139 | Batch_idx: 240 |  Loss: (0.1309) |  Loss2: (0.0000) | Acc: (95.00%) (29480/30848)
Epoch: 139 | Batch_idx: 250 |  Loss: (0.1314) |  Loss2: (0.0000) | Acc: (95.00%) (30700/32128)
Epoch: 139 | Batch_idx: 260 |  Loss: (0.1317) |  Loss2: (0.0000) | Acc: (95.00%) (31913/33408)
Epoch: 139 | Batch_idx: 270 |  Loss: (0.1315) |  Loss2: (0.0000) | Acc: (95.00%) (33134/34688)
Epoch: 139 | Batch_idx: 280 |  Loss: (0.1312) |  Loss2: (0.0000) | Acc: (95.00%) (34362/35968)
Epoch: 139 | Batch_idx: 290 |  Loss: (0.1313) |  Loss2: (0.0000) | Acc: (95.00%) (35583/37248)
Epoch: 139 | Batch_idx: 300 |  Loss: (0.1308) |  Loss2: (0.0000) | Acc: (95.00%) (36814/38528)
Epoch: 139 | Batch_idx: 310 |  Loss: (0.1312) |  Loss2: (0.0000) | Acc: (95.00%) (38039/39808)
Epoch: 139 | Batch_idx: 320 |  Loss: (0.1317) |  Loss2: (0.0000) | Acc: (95.00%) (39251/41088)
Epoch: 139 | Batch_idx: 330 |  Loss: (0.1309) |  Loss2: (0.0000) | Acc: (95.00%) (40492/42368)
Epoch: 139 | Batch_idx: 340 |  Loss: (0.1306) |  Loss2: (0.0000) | Acc: (95.00%) (41724/43648)
Epoch: 139 | Batch_idx: 350 |  Loss: (0.1309) |  Loss2: (0.0000) | Acc: (95.00%) (42937/44928)
Epoch: 139 | Batch_idx: 360 |  Loss: (0.1312) |  Loss2: (0.0000) | Acc: (95.00%) (44151/46208)
Epoch: 139 | Batch_idx: 370 |  Loss: (0.1315) |  Loss2: (0.0000) | Acc: (95.00%) (45378/47488)
Epoch: 139 | Batch_idx: 380 |  Loss: (0.1312) |  Loss2: (0.0000) | Acc: (95.00%) (46607/48768)
Epoch: 139 | Batch_idx: 390 |  Loss: (0.1310) |  Loss2: (0.0000) | Acc: (95.00%) (47787/50000)
# TEST : Loss: (0.3755) | Acc: (88.00%) (8882/10000)
percent tensor([0.6106, 0.6009, 0.6104, 0.5973, 0.6190, 0.6130, 0.6118, 0.5972, 0.6108,
        0.6014, 0.6052, 0.6103, 0.6005, 0.5965, 0.6066, 0.6005],
       device='cuda:0') torch.Size([16])
percent tensor([0.5740, 0.5138, 0.5339, 0.6075, 0.5644, 0.6279, 0.5292, 0.5665, 0.5635,
        0.5258, 0.5477, 0.5164, 0.5123, 0.5926, 0.5611, 0.5827],
       device='cuda:0') torch.Size([16])
percent tensor([0.5547, 0.6151, 0.5183, 0.4740, 0.5161, 0.4656, 0.6048, 0.5366, 0.5470,
        0.5689, 0.5711, 0.5607, 0.5961, 0.5792, 0.5572, 0.5525],
       device='cuda:0') torch.Size([16])
percent tensor([0.6690, 0.6277, 0.6514, 0.6619, 0.6604, 0.6775, 0.6499, 0.6605, 0.6662,
        0.6477, 0.6601, 0.6452, 0.6568, 0.6548, 0.6592, 0.6785],
       device='cuda:0') torch.Size([16])
percent tensor([0.5772, 0.6980, 0.6321, 0.6056, 0.5820, 0.6965, 0.6408, 0.4758, 0.7447,
        0.6493, 0.7259, 0.6594, 0.7595, 0.7732, 0.5533, 0.6636],
       device='cuda:0') torch.Size([16])
percent tensor([0.7060, 0.6850, 0.7742, 0.7583, 0.7978, 0.7954, 0.7303, 0.7125, 0.7501,
        0.7220, 0.7470, 0.7174, 0.6863, 0.8042, 0.6807, 0.7597],
       device='cuda:0') torch.Size([16])
percent tensor([0.6352, 0.5756, 0.7015, 0.6104, 0.7272, 0.6520, 0.6746, 0.6922, 0.5964,
        0.5957, 0.6052, 0.6283, 0.4863, 0.5519, 0.6179, 0.6364],
       device='cuda:0') torch.Size([16])
percent tensor([0.9993, 0.9992, 0.9991, 0.9995, 0.9994, 0.9987, 0.9993, 0.9990, 0.9994,
        0.9997, 0.9995, 0.9996, 0.9993, 0.9993, 0.9992, 0.9991],
       device='cuda:0') torch.Size([16])
True Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=128, out_features=16, bias=False)
False Linear(in_features=16, out_features=2, bias=False)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=128, out_features=16, bias=False)
False Linear(in_features=16, out_features=2, bias=False)
True Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=256, out_features=32, bias=False)
False Linear(in_features=32, out_features=2, bias=False)
True Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=256, out_features=32, bias=False)
False Linear(in_features=32, out_features=2, bias=False)
True Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=512, out_features=64, bias=False)
False Linear(in_features=64, out_features=2, bias=False)
True Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=512, out_features=64, bias=False)
False Linear(in_features=64, out_features=2, bias=False)
True Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1024, out_features=128, bias=False)
False Linear(in_features=128, out_features=2, bias=False)
True Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Linear(in_features=1024, out_features=128, bias=False)
False Linear(in_features=128, out_features=2, bias=False)
True Linear(in_features=512, out_features=10, bias=True)
Epoch: 140 | Batch_idx: 0 |  Loss: (0.0857) |  Loss2: (0.0000) | Acc: (98.00%) (126/128)
Epoch: 140 | Batch_idx: 10 |  Loss: (0.1209) |  Loss2: (0.0000) | Acc: (96.00%) (1353/1408)
Epoch: 140 | Batch_idx: 20 |  Loss: (0.1316) |  Loss2: (0.0000) | Acc: (95.00%) (2569/2688)
Epoch: 140 | Batch_idx: 30 |  Loss: (0.1375) |  Loss2: (0.0000) | Acc: (95.00%) (3783/3968)
Epoch: 140 | Batch_idx: 40 |  Loss: (0.1326) |  Loss2: (0.0000) | Acc: (95.00%) (5017/5248)
Epoch: 140 | Batch_idx: 50 |  Loss: (0.1356) |  Loss2: (0.0000) | Acc: (95.00%) (6230/6528)
Epoch: 140 | Batch_idx: 60 |  Loss: (0.1360) |  Loss2: (0.0000) | Acc: (95.00%) (7452/7808)
Epoch: 140 | Batch_idx: 70 |  Loss: (0.1335) |  Loss2: (0.0000) | Acc: (95.00%) (8679/9088)
Epoch: 140 | Batch_idx: 80 |  Loss: (0.1365) |  Loss2: (0.0000) | Acc: (95.00%) (9892/10368)
Epoch: 140 | Batch_idx: 90 |  Loss: (0.1373) |  Loss2: (0.0000) | Acc: (95.00%) (11110/11648)
Epoch: 140 | Batch_idx: 100 |  Loss: (0.1369) |  Loss2: (0.0000) | Acc: (95.00%) (12332/12928)
Epoch: 140 | Batch_idx: 110 |  Loss: (0.1354) |  Loss2: (0.0000) | Acc: (95.00%) (13564/14208)
Epoch: 140 | Batch_idx: 120 |  Loss: (0.1351) |  Loss2: (0.0000) | Acc: (95.00%) (14782/15488)
Epoch: 140 | Batch_idx: 130 |  Loss: (0.1335) |  Loss2: (0.0000) | Acc: (95.00%) (16014/16768)
Epoch: 140 | Batch_idx: 140 |  Loss: (0.1340) |  Loss2: (0.0000) | Acc: (95.00%) (17236/18048)
Epoch: 140 | Batch_idx: 150 |  Loss: (0.1354) |  Loss2: (0.0000) | Acc: (95.00%) (18444/19328)
Epoch: 140 | Batch_idx: 160 |  Loss: (0.1371) |  Loss2: (0.0000) | Acc: (95.00%) (19648/20608)
Epoch: 140 | Batch_idx: 170 |  Loss: (0.1381) |  Loss2: (0.0000) | Acc: (95.00%) (20858/21888)
Epoch: 140 | Batch_idx: 180 |  Loss: (0.1385) |  Loss2: (0.0000) | Acc: (95.00%) (22072/23168)
Epoch: 140 | Batch_idx: 190 |  Loss: (0.1387) |  Loss2: (0.0000) | Acc: (95.00%) (23281/24448)
Epoch: 140 | Batch_idx: 200 |  Loss: (0.1397) |  Loss2: (0.0000) | Acc: (95.00%) (24493/25728)
Epoch: 140 | Batch_idx: 210 |  Loss: (0.1401) |  Loss2: (0.0000) | Acc: (95.00%) (25704/27008)
Epoch: 140 | Batch_idx: 220 |  Loss: (0.1407) |  Loss2: (0.0000) | Acc: (95.00%) (26916/28288)
Epoch: 140 | Batch_idx: 230 |  Loss: (0.1411) |  Loss2: (0.0000) | Acc: (95.00%) (28129/29568)
Epoch: 140 | Batch_idx: 240 |  Loss: (0.1410) |  Loss2: (0.0000) | Acc: (95.00%) (29346/30848)
Epoch: 140 | Batch_idx: 250 |  Loss: (0.1419) |  Loss2: (0.0000) | Acc: (95.00%) (30557/32128)
Epoch: 140 | Batch_idx: 260 |  Loss: (0.1420) |  Loss2: (0.0000) | Acc: (95.00%) (31778/33408)
Epoch: 140 | Batch_idx: 270 |  Loss: (0.1415) |  Loss2: (0.0000) | Acc: (95.00%) (33001/34688)
Epoch: 140 | Batch_idx: 280 |  Loss: (0.1417) |  Loss2: (0.0000) | Acc: (95.00%) (34222/35968)
Epoch: 140 | Batch_idx: 290 |  Loss: (0.1428) |  Loss2: (0.0000) | Acc: (95.00%) (35428/37248)
Epoch: 140 | Batch_idx: 300 |  Loss: (0.1427) |  Loss2: (0.0000) | Acc: (95.00%) (36650/38528)
Epoch: 140 | Batch_idx: 310 |  Loss: (0.1429) |  Loss2: (0.0000) | Acc: (95.00%) (37860/39808)
Epoch: 140 | Batch_idx: 320 |  Loss: (0.1433) |  Loss2: (0.0000) | Acc: (95.00%) (39069/41088)
Epoch: 140 | Batch_idx: 330 |  Loss: (0.1436) |  Loss2: (0.0000) | Acc: (95.00%) (40273/42368)
Epoch: 140 | Batch_idx: 340 |  Loss: (0.1434) |  Loss2: (0.0000) | Acc: (95.00%) (41492/43648)
Epoch: 140 | Batch_idx: 350 |  Loss: (0.1430) |  Loss2: (0.0000) | Acc: (95.00%) (42713/44928)
Epoch: 140 | Batch_idx: 360 |  Loss: (0.1430) |  Loss2: (0.0000) | Acc: (95.00%) (43934/46208)
Epoch: 140 | Batch_idx: 370 |  Loss: (0.1427) |  Loss2: (0.0000) | Acc: (95.00%) (45162/47488)
Epoch: 140 | Batch_idx: 380 |  Loss: (0.1426) |  Loss2: (0.0000) | Acc: (95.00%) (46386/48768)
Epoch: 140 | Batch_idx: 390 |  Loss: (0.1424) |  Loss2: (0.0000) | Acc: (95.00%) (47557/50000)
=> saving checkpoint 'drive/app/torch/save_Routing_Gate_2/checkpoint_140.pth.tar'
# TEST : Loss: (0.3920) | Acc: (88.00%) (8818/10000)
percent tensor([0.6101, 0.5991, 0.6153, 0.5977, 0.6229, 0.6131, 0.6122, 0.5987, 0.6105,
        0.6007, 0.6041, 0.6129, 0.5996, 0.5934, 0.6054, 0.5995],
       device='cuda:0') torch.Size([16])
percent tensor([0.5681, 0.5200, 0.5155, 0.5950, 0.5557, 0.6174, 0.5314, 0.5566, 0.5638,
        0.5254, 0.5466, 0.5082, 0.5097, 0.6058, 0.5546, 0.5752],
       device='cuda:0') torch.Size([16])
percent tensor([0.5599, 0.6152, 0.5441, 0.4965, 0.5346, 0.4868, 0.6108, 0.5503, 0.5463,
        0.5779, 0.5682, 0.5839, 0.6000, 0.5685, 0.5702, 0.5640],
       device='cuda:0') torch.Size([16])
percent tensor([0.6668, 0.6295, 0.6512, 0.6574, 0.6593, 0.6772, 0.6521, 0.6574, 0.6642,
        0.6469, 0.6607, 0.6459, 0.6549, 0.6567, 0.6584, 0.6761],
       device='cuda:0') torch.Size([16])
percent tensor([0.5685, 0.6998, 0.6294, 0.6442, 0.5794, 0.6798, 0.6146, 0.4792, 0.7258,
        0.6513, 0.7124, 0.6711, 0.7483, 0.7535, 0.5582, 0.6631],
       device='cuda:0') torch.Size([16])
percent tensor([0.6986, 0.6785, 0.7597, 0.7528, 0.7926, 0.7957, 0.7294, 0.6952, 0.7452,
        0.7203, 0.7439, 0.7091, 0.6667, 0.8077, 0.6735, 0.7541],
       device='cuda:0') torch.Size([16])
percent tensor([0.6317, 0.5713, 0.6929, 0.5980, 0.7228, 0.6764, 0.6713, 0.6588, 0.6009,
        0.5983, 0.6018, 0.6158, 0.4945, 0.5650, 0.6030, 0.6394],
       device='cuda:0') torch.Size([16])
percent tensor([0.9994, 0.9993, 0.9991, 0.9996, 0.9995, 0.9993, 0.9994, 0.9988, 0.9994,
        0.9997, 0.9995, 0.9996, 0.9994, 0.9994, 0.9990, 0.9992],
       device='cuda:0') torch.Size([16])
Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 3, 3, 3]) tensor(181.7003, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(824.5127, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([64, 64, 3, 3]) tensor(829.4456, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([128, 64, 3, 3]) tensor(1525.8723, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([128, 64, 1, 1]) tensor(488.9810, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([128, 128, 3, 3]) tensor(2260.3228, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([256, 128, 3, 3]) tensor(4279.0161, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([256, 128, 1, 1]) tensor(1378.4674, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([256, 256, 3, 3]) tensor(6229.0239, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) torch.Size([512, 256, 3, 3]) tensor(11760.9648, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False) torch.Size([512, 256, 1, 1]) tensor(3881.3254, device='cuda:0', grad_fn=<NormBackward0>)
Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) torch.Size([512, 512, 3, 3]) tensor(16396.6738, device='cuda:0', grad_fn=<NormBackward0>)
Epoch: 141 | Batch_idx: 0 |  Loss: (0.1233) |  Loss2: (0.0000) | Acc: (96.00%) (124/128)
Epoch: 141 | Batch_idx: 10 |  Loss: (0.1206) |  Loss2: (0.0000) | Acc: (96.00%) (1354/1408)
Epoch: 141 | Batch_idx: 20 |  Loss: (0.1154) |  Loss2: (0.0000) | Acc: (96.00%) (2588/2688)
Epoch: 141 | Batch_idx: 30 |  Loss: (0.1220) |  Loss2: (0.0000) | Acc: (95.00%) (3806/3968)
Epoch: 141 | Batch_idx: 40 |  Loss: (0.1231) |  Loss2: (0.0000) | Acc: (95.00%) (5033/5248)
Epoch: 141 | Batch_idx: 50 |  Loss: (0.1244) |  Loss2: (0.0000) | Acc: (95.00%) (6255/6528)
Epoch: 141 | Batch_idx: 60 |  Loss: (0.1233) |  Loss2: (0.0000) | Acc: (95.00%) (7491/7808)
Epoch: 141 | Batch_idx: 70 |  Loss: (0.1204) |  Loss2: (0.0000) | Acc: (96.00%) (8732/9088)
Epoch: 141 | Batch_idx: 80 |  Loss: (0.1216) |  Loss2: (0.0000) | Acc: (96.00%) (9956/10368)
Epoch: 141 | Batch_idx: 90 |  Loss: (0.1219) |  Loss2: (0.0000) | Acc: (96.00%) (11189/11648)
Epoch: 141 | Batch_idx: 100 |  Loss: (0.1203) |  Loss2: (0.0000) | Acc: (96.00%) (12425/12928)
Epoch: 141 | Batch_idx: 110 |  Loss: (0.1209) |  Loss2: (0.0000) | Acc: (96.00%) (13650/14208)
Epoch: 141 | Batch_idx: 120 |  Loss: (0.1224) |  Loss2: (0.0000) | Acc: (96.00%) (14869/15488)
Epoch: 141 | Batch_idx: 130 |  Loss: (0.1238) |  Loss2: (0.0000) | Acc: (95.00%) (16090/16768)
Epoch: 141 | Batch_idx: 140 |  Loss: (0.1249) |  Loss2: (0.0000) | Acc: (95.00%) (17299/18048)
Epoch: 141 | Batch_idx: 150 |  Loss: (0.1253) |  Loss2: (0.0000) | Acc: (95.00%) (18520/19328)
Epoch: 141 | Batch_idx: 160 |  Loss: (0.1262) |  Loss2: (0.0000) | Acc: (95.00%) (19743/20608)
Epoch: 141 | Batch_idx: 170 |  Loss: (0.1265) |  Loss2: (0.0000) | Acc: (95.00%) (20963/21888)
Epoch: 141 | Batch_idx: 180 |  Loss: (0.1264) |  Loss2: (0.0000) | Acc: (95.00%) (22196/23168)
Epoch: 141 | Batch_idx: 190 |  Loss: (0.1275) |  Loss2: (0.0000) | Acc: (95.00%) (23413/24448)
Epoch: 141 | Batch_idx: 200 |  Loss: (0.1279) |  Loss2: (0.0000) | Acc: (95.00%) (24633/25728)
Epoch: 141 | Batch_idx: 210 |  Loss: (0.1285) |  Loss2: (0.0000) | Acc: (95.00%) (25855/27008)
Epoch: 141 | Batch_idx: 220 |  Loss: (0.1284) |  Loss2: (0.0000) | Acc: (95.00%) (27082/28288)
Epoch: 141 | Batch_idx: 230 |  Loss: (0.1281) |  Loss2: (0.0000) | Acc: (95.00%) (28310/29568)
Epoch: 141 | Batch_idx: 240 |  Loss: (0.1287) |  Loss2: (0.0000) | Acc: (95.00%) (29528/30848)
Epoch: 141 | Batch_idx: 250 |  Loss: (0.1286) |  Loss2: (0.0000) | Acc: (95.00%) (30748/32128)
Epoch: 141 | Batch_idx: 260 |  Loss: (0.1287) |  Loss2: (0.0000) | Acc: (95.00%) (31979/33408)
Epoch: 141 | Batch_idx: 270 |  Loss: (0.1291) |  Loss2: (0.0000) | Acc: (95.00%) (33196/34688)
Epoch: 141 | Batch_idx: 280 |  Loss: (0.1289) |  Loss2: (0.0000) | Acc: (95.00%) (34419/35968)
Epoch: 141 | Batch_idx: 290 |  Loss: (0.1287) |  Loss2: (0.0000) | Acc: (95.00%) (35645/37248)
Epoch: 141 | Batch_idx: 300 |  Loss: (0.1293) |  Loss2: (0.0000) | Acc: (95.00%) (36862/38528)
Epoch: 141 | Batch_idx: 310 |  Loss: (0.1296) |  Loss2: (0.0000) | Acc: (95.00%) (38084/39808)
Epoch: 141 | Batch_idx: 320 |  Loss: (0.1294) |  Loss2: (0.0000) | Acc: (95.00%) (39311/41088)
Epoch: 141 | Batch_idx: 330 |  Loss: (0.1288) |  Loss2: (0.0000) | Acc: (95.00%) (40547/42368)
Epoch: 141 | Batch_idx: 340 |  Loss: (0.1289) |  Loss2: (0.0000) | Acc: (95.00%) (41765/43648)
Epoch: 141 | Batch_idx: 350 |  Loss: (0.1303) |  Loss2: (0.0000) | Acc: (95.00%) (42963/44928)
Epoch: 141 | Batch_idx: 360 |  Loss: (0.1308) |  Loss2: (0.0000) | Acc: (95.00%) (44178/46208)
Epoch: 141 | Batch_idx: 370 |  Loss: (0.1315) |  Loss2: (0.0000) | Acc: (95.00%) (45396/47488)
Epoch: 141 | Batch_idx: 380 |  Loss: (0.1322) |  Loss2: (0.0000) | Acc: (95.00%) (46613/48768)
Epoch: 141 | Batch_idx: 390 |  Loss: (0.1328) |  Loss2: (0.0000) | Acc: (95.00%) (47779/50000)
# TEST : Loss: (0.4118) | Acc: (87.00%) (8792/10000)
percent tensor([0.6112, 0.5996, 0.6192, 0.5983, 0.6255, 0.6127, 0.6131, 0.6011, 0.6114,
        0.6015, 0.6048, 0.6165, 0.6005, 0.5918, 0.6050, 0.5997],
       device='cuda:0') torch.Size([16])
percent tensor([0.5685, 0.5240, 0.5221, 0.5932, 0.5621, 0.6206, 0.5384, 0.5569, 0.5684,
        0.5283, 0.5502, 0.5139, 0.5102, 0.6159, 0.5588, 0.5766],
       device='cuda:0') torch.Size([16])
percent tensor([0.5555, 0.6099, 0.5290, 0.4844, 0.5250, 0.4873, 0.6048, 0.5416, 0.5465,
        0.5690, 0.5646, 0.5722, 0.5924, 0.5700, 0.5655, 0.5595],
       device='cuda:0') torch.Size([16])
percent tensor([0.6680, 0.6264, 0.6514, 0.6608, 0.6617, 0.6807, 0.6504, 0.6565, 0.6659,
        0.6451, 0.6601, 0.6493, 0.6543, 0.6566, 0.6589, 0.6759],
       device='cuda:0') torch.Size([16])
percent tensor([0.5706, 0.6896, 0.6433, 0.6379, 0.5825, 0.7059, 0.6332, 0.4688, 0.7377,
        0.6463, 0.7203, 0.6947, 0.7595, 0.7578, 0.5698, 0.6607],
       device='cuda:0') torch.Size([16])
percent tensor([0.7070, 0.6930, 0.7717, 0.7618, 0.7895, 0.7955, 0.7416, 0.7012, 0.7515,
        0.7223, 0.7463, 0.7333, 0.6774, 0.8218, 0.6752, 0.7439],
       device='cuda:0') torch.Size([16])
percent tensor([0.6391, 0.5922, 0.7003, 0.6042, 0.7201, 0.6740, 0.6852, 0.6646, 0.5966,
        0.6044, 0.6126, 0.6010, 0.4692, 0.5868, 0.6207, 0.6343],
       device='cuda:0') torch.Size([16])
percent tensor([0.9994, 0.9992, 0.9992, 0.9995, 0.9994, 0.9989, 0.9994, 0.9992, 0.9992,
        0.9997, 0.9995, 0.9995, 0.9993, 0.9994, 0.9990, 0.9993],
       device='cuda:0') torch.Size([16])
Epoch: 142 | Batch_idx: 0 |  Loss: (0.1587) |  Loss2: (0.0000) | Acc: (93.00%) (120/128)
Epoch: 142 | Batch_idx: 10 |  Loss: (0.1184) |  Loss2: (0.0000) | Acc: (95.00%) (1349/1408)
Epoch: 142 | Batch_idx: 20 |  Loss: (0.1160) |  Loss2: (0.0000) | Acc: (95.00%) (2578/2688)
Epoch: 142 | Batch_idx: 30 |  Loss: (0.1128) |  Loss2: (0.0000) | Acc: (96.00%) (3816/3968)
Epoch: 142 | Batch_idx: 40 |  Loss: (0.1135) |  Loss2: (0.0000) | Acc: (96.00%) (5040/5248)
Epoch: 142 | Batch_idx: 50 |  Loss: (0.1169) |  Loss2: (0.0000) | Acc: (95.00%) (6256/6528)
Epoch: 142 | Batch_idx: 60 |  Loss: (0.1201) |  Loss2: (0.0000) | Acc: (95.00%) (7470/7808)
Epoch: 142 | Batch_idx: 70 |  Loss: (0.1251) |  Loss2: (0.0000) | Acc: (95.00%) (8677/9088)
Epoch: 142 | Batch_idx: 80 |  Loss: (0.1230) |  Loss2: (0.0000) | Acc: (95.00%) (9916/10368)
Epoch: 142 | Batch_idx: 90 |  Loss: (0.1229) |  Loss2: (0.0000) | Acc: (95.00%) (11142/11648)
Epoch: 142 | Batch_idx: 100 |  Loss: (0.1234) |  Loss2: (0.0000) | Acc: (95.00%) (12366/12928)
Epoch: 142 | Batch_idx: 110 |  Loss: (0.1236) |  Loss2: (0.0000) | Acc: (95.00%) (13591/14208)
Epoch: 142 | Batch_idx: 120 |  Loss: (0.1235) |  Loss2: (0.0000) | Acc: (95.00%) (14812/15488)
Epoch: 142 | Batch_idx: 130 |  Loss: (0.1227) |  Loss2: (0.0000) | Acc: (95.00%) (16038/16768)
Epoch: 142 | Batch_idx: 140 |  Loss: (0.1234) |  Loss2: (0.0000) | Acc: (95.00%) (17251/18048)
Epoch: 142 | Batch_idx: 150 |  Loss: (0.1243) |  Loss2: (0.0000) | Acc: (95.00%) (18471/19328)
Epoch: 142 | Batch_idx: 160 |  Loss: (0.1224) |  Loss2: (0.0000) | Acc: (95.00%) (19714/20608)
Epoch: 142 | Batch_idx: 170 |  Loss: (0.1234) |  Loss2: (0.0000) | Acc: (95.00%) (20932/21888)
Epoch: 142 | Batch_idx: 180 |  Loss: (0.1226) |  Loss2: (0.0000) | Acc: (95.00%) (22167/23168)
Epoch: 142 | Batch_idx: 190 |  Loss: (0.1223) |  Loss2: (0.0000) | Acc: (95.00%) (23402/24448)
Epoch: 142 | Batch_idx: 200 |  Loss: (0.1217) |  Loss2: (0.0000) | Acc: (95.00%) (24636/25728)
Epoch: 142 | Batch_idx: 210 |  Loss: (0.1223) |  Loss2: (0.0000) | Acc: (95.00%) (25856/27008)
Epoch: 142 | Batch_idx: 220 |  Loss: (0.1224) |  Loss2: (0.0000) | Acc: (95.00%) (27083/28288)
Epoch: 142 | Batch_idx: 230 |  Loss: (0.1232) |  Loss2: (0.0000) | Acc: (95.00%) (28302/29568)
Epoch: 142 | Batch_idx: 240 |  Loss: (0.1237) |  Loss2: (0.0000) | Acc: (95.00%) (29522/30848)
Epoch: 142 | Batch_idx: 250 |  Loss: (0.1243) |  Loss2: (0.0000) | Acc: (95.00%) (30736/32128)
Epoch: 142 | Batch_idx: 260 |  Loss: (0.1252) |  Loss2: (0.0000) | Acc: (95.00%) (31947/33408)
Epoch: 142 | Batch_idx: 270 |  Loss: (0.1253) |  Loss2: (0.0000) | Acc: (95.00%) (33163/34688)
Epoch: 142 | Batch_idx: 280 |  Loss: (0.1251) |  Loss2: (0.0000) | Acc: (95.00%) (34394/35968)
Epoch: 142 | Batch_idx: 290 |  Loss: (0.1253) |  Loss2: (0.0000) | Acc: (95.00%) (35615/37248)
Epoch: 142 | Batch_idx: 300 |  Loss: (0.1259) |  Loss2: (0.0000) | Acc: (95.00%) (36826/38528)
Epoch: 142 | Batch_idx: 310 |  Loss: (0.1260) |  Loss2: (0.0000) | Acc: (95.00%) (38046/39808)
Epoch: 142 | Batch_idx: 320 |  Loss: (0.1260) |  Loss2: (0.0000) | Acc: (95.00%) (39267/41088)
Epoch: 142 | Batch_idx: 330 |  Loss: (0.1270) |  Loss2: (0.0000) | Acc: (95.00%) (40482/42368)
Epoch: 142 | Batch_idx: 340 |  Loss: (0.1275) |  Loss2: (0.0000) | Acc: (95.00%) (41708/43648)
Epoch: 142 | Batch_idx: 350 |  Loss: (0.1276) |  Loss2: (0.0000) | Acc: (95.00%) (42935/44928)
Epoch: 142 | Batch_idx: 360 |  Loss: (0.1278) |  Loss2: (0.0000) | Acc: (95.00%) (44155/46208)
Epoch: 142 | Batch_idx: 370 |  Loss: (0.1284) |  Loss2: (0.0000) | Acc: (95.00%) (45371/47488)
Epoch: 142 | Batch_idx: 380 |  Loss: (0.1286) |  Loss2: (0.0000) | Acc: (95.00%) (46591/48768)
Epoch: 142 | Batch_idx: 390 |  Loss: (0.1288) |  Loss2: (0.0000) | Acc: (95.00%) (47767/50000)
# TEST : Loss: (0.4076) | Acc: (87.00%) (8761/10000)
percent tensor([0.6117, 0.6014, 0.6184, 0.6000, 0.6245, 0.6132, 0.6142, 0.6002, 0.6105,
        0.6024, 0.6043, 0.6161, 0.6009, 0.5959, 0.6064, 0.6006],
       device='cuda:0') torch.Size([16])
percent tensor([0.5724, 0.5211, 0.5248, 0.5954, 0.5607, 0.6224, 0.5328, 0.5609, 0.5705,
        0.5299, 0.5517, 0.5134, 0.5127, 0.6042, 0.5591, 0.5784],
       device='cuda:0') torch.Size([16])
percent tensor([0.5550, 0.6115, 0.5308, 0.4893, 0.5302, 0.4868, 0.6068, 0.5448, 0.5433,
        0.5666, 0.5586, 0.5743, 0.5890, 0.5699, 0.5656, 0.5579],
       device='cuda:0') torch.Size([16])
percent tensor([0.6660, 0.6267, 0.6515, 0.6595, 0.6622, 0.6755, 0.6511, 0.6594, 0.6640,
        0.6476, 0.6569, 0.6461, 0.6505, 0.6587, 0.6572, 0.6747],
       device='cuda:0') torch.Size([16])
percent tensor([0.5677, 0.6951, 0.6377, 0.6391, 0.5791, 0.6972, 0.6228, 0.4696, 0.7165,
        0.6474, 0.6977, 0.6789, 0.7472, 0.7551, 0.5670, 0.6527],
       device='cuda:0') torch.Size([16])
percent tensor([0.7046, 0.6797, 0.7787, 0.7671, 0.7964, 0.7921, 0.7464, 0.7132, 0.7556,
        0.7321, 0.7454, 0.7359, 0.6748, 0.8188, 0.6851, 0.7473],
       device='cuda:0') torch.Size([16])
percent tensor([0.6373, 0.5814, 0.7053, 0.5961, 0.7303, 0.6807, 0.6976, 0.6699, 0.6262,
        0.6076, 0.6157, 0.6186, 0.4989, 0.5850, 0.6257, 0.6415],
       device='cuda:0') torch.Size([16])
percent tensor([0.9995, 0.9993, 0.9993, 0.9996, 0.9994, 0.9992, 0.9995, 0.9991, 0.9994,
        0.9997, 0.9995, 0.9996, 0.9993, 0.9995, 0.9992, 0.9991],
       device='cuda:0') torch.Size([16])
Epoch: 143 | Batch_idx: 0 |  Loss: (0.0866) |  Loss2: (0.0000) | Acc: (96.00%) (124/128)
Epoch: 143 | Batch_idx: 10 |  Loss: (0.1290) |  Loss2: (0.0000) | Acc: (95.00%) (1339/1408)
Epoch: 143 | Batch_idx: 20 |  Loss: (0.1279) |  Loss2: (0.0000) | Acc: (95.00%) (2560/2688)
Epoch: 143 | Batch_idx: 30 |  Loss: (0.1244) |  Loss2: (0.0000) | Acc: (95.00%) (3786/3968)
Epoch: 143 | Batch_idx: 40 |  Loss: (0.1196) |  Loss2: (0.0000) | Acc: (95.00%) (5020/5248)
Epoch: 143 | Batch_idx: 50 |  Loss: (0.1193) |  Loss2: (0.0000) | Acc: (95.00%) (6249/6528)
Epoch: 143 | Batch_idx: 60 |  Loss: (0.1156) |  Loss2: (0.0000) | Acc: (95.00%) (7491/7808)
Epoch: 143 | Batch_idx: 70 |  Loss: (0.1192) |  Loss2: (0.0000) | Acc: (95.00%) (8701/9088)
Epoch: 143 | Batch_idx: 80 |  Loss: (0.1178) |  Loss2: (0.0000) | Acc: (95.00%) (9939/10368)
Epoch: 143 | Batch_idx: 90 |  Loss: (0.1185) |  Loss2: (0.0000) | Acc: (95.00%) (11162/11648)
Epoch: 143 | Batch_idx: 100 |  Loss: (0.1209) |  Loss2: (0.0000) | Acc: (95.00%) (12383/12928)
Epoch: 143 | Batch_idx: 110 |  Loss: (0.1209) |  Loss2: (0.0000) | Acc: (95.00%) (13614/14208)
Epoch: 143 | Batch_idx: 120 |  Loss: (0.1225) |  Loss2: (0.0000) | Acc: (95.00%) (14841/15488)
Epoch: 143 | Batch_idx: 130 |  Loss: (0.1233) |  Loss2: (0.0000) | Acc: (95.00%) (16057/16768)
Epoch: 143 | Batch_idx: 140 |  Loss: (0.1216) |  Loss2: (0.0000) | Acc: (95.00%) (17290/18048)
Epoch: 143 | Batch_idx: 150 |  Loss: (0.1207) |  Loss2: (0.0000) | Acc: (95.00%) (18522/19328)
Epoch: 143 | Batch_idx: 160 |  Loss: (0.1208) |  Loss2: (0.0000) | Acc: (95.00%) (19752/20608)
Epoch: 143 | Batch_idx: 170 |  Loss: (0.1210) |  Loss2: (0.0000) | Acc: (95.00%) (20978/21888)
Epoch: 143 | Batch_idx: 180 |  Loss: (0.1200) |  Loss2: (0.0000) | Acc: (95.00%) (22220/23168)
Epoch: 143 | Batch_idx: 190 |  Loss: (0.1203) |  Loss2: (0.0000) | Acc: (95.00%) (23450/24448)
Epoch: 143 | Batch_idx: 200 |  Loss: (0.1196) |  Loss2: (0.0000) | Acc: (95.00%) (24686/25728)
Epoch: 143 | Batch_idx: 210 |  Loss: (0.1196) |  Loss2: (0.0000) | Acc: (95.00%) (25912/27008)
Epoch: 143 | Batch_idx: 220 |  Loss: (0.1208) |  Loss2: (0.0000) | Acc: (95.00%) (27126/28288)
Epoch: 143 | Batch_idx: 230 |  Loss: (0.1213) |  Loss2: (0.0000) | Acc: (95.00%) (28346/29568)
Epoch: 143 | Batch_idx: 240 |  Loss: (0.1226) |  Loss2: (0.0000) | Acc: (95.00%) (29565/30848)
Epoch: 143 | Batch_idx: 250 |  Loss: (0.1226) |  Loss2: (0.0000) | Acc: (95.00%) (30789/32128)
Epoch: 143 | Batch_idx: 260 |  Loss: (0.1225) |  Loss2: (0.0000) | Acc: (95.00%) (32023/33408)
Epoch: 143 | Batch_idx: 270 |  Loss: (0.1234) |  Loss2: (0.0000) | Acc: (95.00%) (33240/34688)
Epoch: 143 | Batch_idx: 280 |  Loss: (0.1233) |  Loss2: (0.0000) | Acc: (95.00%) (34470/35968)
Epoch: 143 | Batch_idx: 290 |  Loss: (0.1241) |  Loss2: (0.0000) | Acc: (95.00%) (35681/37248)
Epoch: 143 | Batch_idx: 300 |  Loss: (0.1243) |  Loss2: (0.0000) | Acc: (95.00%) (36906/38528)
Epoch: 143 | Batch_idx: 310 |  Loss: (0.1245) |  Loss2: (0.0000) | Acc: (95.00%) (38129/39808)
Epoch: 143 | Batch_idx: 320 |  Loss: (0.1245) |  Loss2: (0.0000) | Acc: (95.00%) (39356/41088)
Epoch: 143 | Batch_idx: 330 |  Loss: (0.1249) |  Loss2: (0.0000) | Acc: (95.00%) (40572/42368)
Epoch: 143 | Batch_idx: 340 |  Loss: (0.1246) |  Loss2: (0.0000) | Acc: (95.00%) (41806/43648)
Epoch: 143 | Batch_idx: 350 |  Loss: (0.1253) |  Loss2: (0.0000) | Acc: (95.00%) (43014/44928)
Epoch: 143 | Batch_idx: 360 |  Loss: (0.1259) |  Loss2: (0.0000) | Acc: (95.00%) (44231/46208)
Epoch: 143 | Batch_idx: 370 |  Loss: (0.1261) |  Loss2: (0.0000) | Acc: (95.00%) (45455/47488)
Epoch: 143 | Batch_idx: 380 |  Loss: (0.1258) |  Loss2: (0.0000) | Acc: (95.00%) (46678/48768)
Epoch: 143 | Batch_idx: 390 |  Loss: (0.1265) |  Loss2: (0.0000) | Acc: (95.00%) (47847/50000)
# TEST : Loss: (0.4199) | Acc: (87.00%) (8757/10000)
percent tensor([0.6105, 0.5980, 0.6170, 0.5980, 0.6239, 0.6124, 0.6116, 0.5995, 0.6087,
        0.6008, 0.6030, 0.6145, 0.5992, 0.5902, 0.6046, 0.5992],
       device='cuda:0') torch.Size([16])
percent tensor([0.5740, 0.5169, 0.5289, 0.6001, 0.5683, 0.6297, 0.5352, 0.5597, 0.5659,
        0.5267, 0.5472, 0.5138, 0.5123, 0.5995, 0.5613, 0.5786],
       device='cuda:0') torch.Size([16])
percent tensor([0.5557, 0.6096, 0.5249, 0.4912, 0.5263, 0.4887, 0.6038, 0.5405, 0.5388,
        0.5665, 0.5585, 0.5720, 0.5878, 0.5670, 0.5655, 0.5602],
       device='cuda:0') torch.Size([16])
percent tensor([0.6667, 0.6256, 0.6513, 0.6607, 0.6610, 0.6794, 0.6501, 0.6557, 0.6614,
        0.6462, 0.6609, 0.6455, 0.6539, 0.6501, 0.6580, 0.6775],
       device='cuda:0') torch.Size([16])
percent tensor([0.5611, 0.7035, 0.6177, 0.6379, 0.5810, 0.7041, 0.6299, 0.4877, 0.7396,
        0.6442, 0.7225, 0.6622, 0.7408, 0.7550, 0.5687, 0.6819],
       device='cuda:0') torch.Size([16])
percent tensor([0.6986, 0.6943, 0.7613, 0.7587, 0.7923, 0.8000, 0.7401, 0.6926, 0.7569,
        0.7259, 0.7507, 0.7262, 0.6748, 0.8092, 0.6824, 0.7558],
       device='cuda:0') torch.Size([16])
percent tensor([0.6329, 0.5641, 0.6934, 0.6045, 0.7193, 0.6782, 0.6828, 0.6574, 0.5876,
        0.5981, 0.6058, 0.6072, 0.4922, 0.5698, 0.6159, 0.6365],
       device='cuda:0') torch.Size([16])
percent tensor([0.9993, 0.9993, 0.9991, 0.9994, 0.9992, 0.9993, 0.9996, 0.9989, 0.9993,
        0.9997, 0.9996, 0.9996, 0.9994, 0.9996, 0.9989, 0.9991],
       device='cuda:0') torch.Size([16])
Epoch: 144 | Batch_idx: 0 |  Loss: (0.1279) |  Loss2: (0.0000) | Acc: (96.00%) (123/128)
Epoch: 144 | Batch_idx: 10 |  Loss: (0.1071) |  Loss2: (0.0000) | Acc: (96.00%) (1353/1408)
Epoch: 144 | Batch_idx: 20 |  Loss: (0.1216) |  Loss2: (0.0000) | Acc: (95.00%) (2569/2688)
Epoch: 144 | Batch_idx: 30 |  Loss: (0.1307) |  Loss2: (0.0000) | Acc: (95.00%) (3778/3968)
Epoch: 144 | Batch_idx: 40 |  Loss: (0.1318) |  Loss2: (0.0000) | Acc: (95.00%) (5001/5248)
Epoch: 144 | Batch_idx: 50 |  Loss: (0.1356) |  Loss2: (0.0000) | Acc: (95.00%) (6206/6528)
Epoch: 144 | Batch_idx: 60 |  Loss: (0.1329) |  Loss2: (0.0000) | Acc: (95.00%) (7435/7808)
Epoch: 144 | Batch_idx: 70 |  Loss: (0.1320) |  Loss2: (0.0000) | Acc: (95.00%) (8661/9088)
Epoch: 144 | Batch_idx: 80 |  Loss: (0.1293) |  Loss2: (0.0000) | Acc: (95.00%) (9898/10368)
Epoch: 144 | Batch_idx: 90 |  Loss: (0.1316) |  Loss2: (0.0000) | Acc: (95.00%) (11104/11648)
Epoch: 144 | Batch_idx: 100 |  Loss: (0.1298) |  Loss2: (0.0000) | Acc: (95.00%) (12332/12928)
Epoch: 144 | Batch_idx: 110 |  Loss: (0.1282) |  Loss2: (0.0000) | Acc: (95.00%) (13561/14208)
Epoch: 144 | Batch_idx: 120 |  Loss: (0.1260) |  Loss2: (0.0000) | Acc: (95.00%) (14797/15488)
Epoch: 144 | Batch_idx: 130 |  Loss: (0.1250) |  Loss2: (0.0000) | Acc: (95.00%) (16024/16768)
Epoch: 144 | Batch_idx: 140 |  Loss: (0.1259) |  Loss2: (0.0000) | Acc: (95.00%) (17240/18048)
Epoch: 144 | Batch_idx: 150 |  Loss: (0.1248) |  Loss2: (0.0000) | Acc: (95.00%) (18479/19328)
Epoch: 144 | Batch_idx: 160 |  Loss: (0.1256) |  Loss2: (0.0000) | Acc: (95.00%) (19693/20608)
Epoch: 144 | Batch_idx: 170 |  Loss: (0.1270) |  Loss2: (0.0000) | Acc: (95.00%) (20907/21888)
Epoch: 144 | Batch_idx: 180 |  Loss: (0.1276) |  Loss2: (0.0000) | Acc: (95.00%) (22129/23168)
Epoch: 144 | Batch_idx: 190 |  Loss: (0.1275) |  Loss2: (0.0000) | Acc: (95.00%) (23357/24448)
Epoch: 144 | Batch_idx: 200 |  Loss: (0.1287) |  Loss2: (0.0000) | Acc: (95.00%) (24571/25728)
Epoch: 144 | Batch_idx: 210 |  Loss: (0.1288) |  Loss2: (0.0000) | Acc: (95.00%) (25797/27008)
Epoch: 144 | Batch_idx: 220 |  Loss: (0.1284) |  Loss2: (0.0000) | Acc: (95.00%) (27026/28288)
Epoch: 144 | Batch_idx: 230 |  Loss: (0.1282) |  Loss2: (0.0000) | Acc: (95.00%) (28248/29568)
Epoch: 144 | Batch_idx: 240 |  Loss: (0.1287) |  Loss2: (0.0000) | Acc: (95.00%) (29466/30848)
Epoch: 144 | Batch_idx: 250 |  Loss: (0.1292) |  Loss2: (0.0000) | Acc: (95.00%) (30677/32128)
Epoch: 144 | Batch_idx: 260 |  Loss: (0.1298) |  Loss2: (0.0000) | Acc: (95.00%) (31897/33408)
Epoch: 144 | Batch_idx: 270 |  Loss: (0.1294) |  Loss2: (0.0000) | Acc: (95.00%) (33124/34688)
Epoch: 144 | Batch_idx: 280 |  Loss: (0.1294) |  Loss2: (0.0000) | Acc: (95.00%) (34339/35968)
Epoch: 144 | Batch_idx: 290 |  Loss: (0.1294) |  Loss2: (0.0000) | Acc: (95.00%) (35555/37248)
Epoch: 144 | Batch_idx: 300 |  Loss: (0.1297) |  Loss2: (0.0000) | Acc: (95.00%) (36774/38528)
Epoch: 144 | Batch_idx: 310 |  Loss: (0.1291) |  Loss2: (0.0000) | Acc: (95.00%) (38005/39808)
Epoch: 144 | Batch_idx: 320 |  Loss: (0.1295) |  Loss2: (0.0000) | Acc: (95.00%) (39229/41088)
Epoch: 144 | Batch_idx: 330 |  Loss: (0.1297) |  Loss2: (0.0000) | Acc: (95.00%) (40455/42368)
Epoch: 144 | Batch_idx: 340 |  Loss: (0.1298) |  Loss2: (0.0000) | Acc: (95.00%) (41683/43648)
Epoch: 144 | Batch_idx: 350 |  Loss: (0.1307) |  Loss2: (0.0000) | Acc: (95.00%) (42889/44928)
Epoch: 144 | Batch_idx: 360 |  Loss: (0.1302) |  Loss2: (0.0000) | Acc: (95.00%) (44113/46208)
Epoch: 144 | Batch_idx: 370 |  Loss: (0.1306) |  Loss2: (0.0000) | Acc: (95.00%) (45332/47488)
Epoch: 144 | Batch_idx: 380 |  Loss: (0.1302) |  Loss2: (0.0000) | Acc: (95.00%) (46561/48768)
Epoch: 144 | Batch_idx: 390 |  Loss: (0.1299) |  Loss2: (0.0000) | Acc: (95.00%) (47744/50000)
# TEST : Loss: (0.3913) | Acc: (87.00%) (8789/10000)
percent tensor([0.6114, 0.5990, 0.6173, 0.5978, 0.6235, 0.6138, 0.6127, 0.6003, 0.6103,
        0.6016, 0.6047, 0.6149, 0.6004, 0.5911, 0.6058, 0.6001],
       device='cuda:0') torch.Size([16])
percent tensor([0.5705, 0.5204, 0.5246, 0.5980, 0.5622, 0.6213, 0.5366, 0.5575, 0.5665,
        0.5265, 0.5453, 0.5141, 0.5112, 0.6098, 0.5584, 0.5777],
       device='cuda:0') torch.Size([16])
percent tensor([0.5593, 0.6100, 0.5205, 0.4864, 0.5198, 0.4957, 0.6035, 0.5423, 0.5459,
        0.5660, 0.5697, 0.5647, 0.5944, 0.5737, 0.5675, 0.5644],
       device='cuda:0') torch.Size([16])
percent tensor([0.6670, 0.6290, 0.6460, 0.6587, 0.6591, 0.6839, 0.6510, 0.6521, 0.6623,
        0.6461, 0.6572, 0.6435, 0.6527, 0.6579, 0.6594, 0.6773],
       device='cuda:0') torch.Size([16])
percent tensor([0.5618, 0.6901, 0.6401, 0.6407, 0.5937, 0.7006, 0.6253, 0.4941, 0.7207,
        0.6336, 0.6976, 0.6711, 0.7357, 0.7440, 0.5658, 0.6579],
       device='cuda:0') torch.Size([16])
percent tensor([0.7094, 0.6903, 0.7893, 0.7713, 0.8054, 0.8033, 0.7402, 0.7177, 0.7661,
        0.7333, 0.7412, 0.7435, 0.6836, 0.8010, 0.6917, 0.7562],
       device='cuda:0') torch.Size([16])
percent tensor([0.6249, 0.5681, 0.6811, 0.5905, 0.7078, 0.6805, 0.6782, 0.6595, 0.6007,
        0.5927, 0.6078, 0.5947, 0.4995, 0.5768, 0.6214, 0.6400],
       device='cuda:0') torch.Size([16])
percent tensor([0.9991, 0.9993, 0.9989, 0.9996, 0.9993, 0.9993, 0.9993, 0.9990, 0.9992,
        0.9997, 0.9995, 0.9996, 0.9993, 0.9992, 0.9990, 0.9990],
       device='cuda:0') torch.Size([16])
False Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=128, out_features=16, bias=False)
True Linear(in_features=16, out_features=2, bias=False)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=128, out_features=16, bias=False)
True Linear(in_features=16, out_features=2, bias=False)
False Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=256, out_features=32, bias=False)
True Linear(in_features=32, out_features=2, bias=False)
False Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=256, out_features=32, bias=False)
True Linear(in_features=32, out_features=2, bias=False)
False Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=512, out_features=64, bias=False)
True Linear(in_features=64, out_features=2, bias=False)
False Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=512, out_features=64, bias=False)
True Linear(in_features=64, out_features=2, bias=False)
False Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1024, out_features=128, bias=False)
True Linear(in_features=128, out_features=2, bias=False)
False Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Linear(in_features=1024, out_features=128, bias=False)
True Linear(in_features=128, out_features=2, bias=False)
False Linear(in_features=512, out_features=10, bias=True)
Epoch: 145 | Batch_idx: 0 |  Loss: (0.1807) |  Loss2: (0.0000) | Acc: (94.00%) (121/128)
Epoch: 145 | Batch_idx: 10 |  Loss: (0.1329) |  Loss2: (0.0000) | Acc: (95.00%) (1342/1408)
Epoch: 145 | Batch_idx: 20 |  Loss: (0.1454) |  Loss2: (0.0000) | Acc: (95.00%) (2554/2688)
Epoch: 145 | Batch_idx: 30 |  Loss: (0.1432) |  Loss2: (0.0000) | Acc: (94.00%) (3768/3968)
Epoch: 145 | Batch_idx: 40 |  Loss: (0.1467) |  Loss2: (0.0000) | Acc: (94.00%) (4975/5248)
Epoch: 145 | Batch_idx: 50 |  Loss: (0.1483) |  Loss2: (0.0000) | Acc: (94.00%) (6192/6528)
Epoch: 145 | Batch_idx: 60 |  Loss: (0.1483) |  Loss2: (0.0000) | Acc: (94.00%) (7412/7808)
Epoch: 145 | Batch_idx: 70 |  Loss: (0.1477) |  Loss2: (0.0000) | Acc: (94.00%) (8624/9088)
Epoch: 145 | Batch_idx: 80 |  Loss: (0.1468) |  Loss2: (0.0000) | Acc: (94.00%) (9842/10368)
Epoch: 145 | Batch_idx: 90 |  Loss: (0.1463) |  Loss2: (0.0000) | Acc: (94.00%) (11060/11648)
Epoch: 145 | Batch_idx: 100 |  Loss: (0.1480) |  Loss2: (0.0000) | Acc: (94.00%) (12269/12928)
Epoch: 145 | Batch_idx: 110 |  Loss: (0.1468) |  Loss2: (0.0000) | Acc: (94.00%) (13491/14208)
Epoch: 145 | Batch_idx: 120 |  Loss: (0.1468) |  Loss2: (0.0000) | Acc: (94.00%) (14699/15488)
Epoch: 145 | Batch_idx: 130 |  Loss: (0.1458) |  Loss2: (0.0000) | Acc: (94.00%) (15914/16768)
Epoch: 145 | Batch_idx: 140 |  Loss: (0.1464) |  Loss2: (0.0000) | Acc: (94.00%) (17133/18048)
Epoch: 145 | Batch_idx: 150 |  Loss: (0.1437) |  Loss2: (0.0000) | Acc: (95.00%) (18365/19328)
Epoch: 145 | Batch_idx: 160 |  Loss: (0.1442) |  Loss2: (0.0000) | Acc: (95.00%) (19580/20608)
Epoch: 145 | Batch_idx: 170 |  Loss: (0.1430) |  Loss2: (0.0000) | Acc: (95.00%) (20809/21888)
Epoch: 145 | Batch_idx: 180 |  Loss: (0.1426) |  Loss2: (0.0000) | Acc: (95.00%) (22029/23168)
Epoch: 145 | Batch_idx: 190 |  Loss: (0.1435) |  Loss2: (0.0000) | Acc: (95.00%) (23235/24448)
Epoch: 145 | Batch_idx: 200 |  Loss: (0.1427) |  Loss2: (0.0000) | Acc: (95.00%) (24458/25728)
Epoch: 145 | Batch_idx: 210 |  Loss: (0.1430) |  Loss2: (0.0000) | Acc: (95.00%) (25668/27008)
Epoch: 145 | Batch_idx: 220 |  Loss: (0.1426) |  Loss2: (0.0000) | Acc: (95.00%) (26892/28288)
Epoch: 145 | Batch_idx: 230 |  Loss: (0.1423) |  Loss2: (0.0000) | Acc: (95.00%) (28109/29568)
Epoch: 145 | Batch_idx: 240 |  Loss: (0.1419) |  Loss2: (0.0000) | Acc: (95.00%) (29332/30848)
Epoch: 145 | Batch_idx: 250 |  Loss: (0.1419) |  Loss2: (0.0000) | Acc: (95.00%) (30544/32128)
Epoch: 145 | Batch_idx: 260 |  Loss: (0.1419) |  Loss2: (0.0000) | Acc: (95.00%) (31758/33408)
Epoch: 145 | Batch_idx: 270 |  Loss: (0.1420) |  Loss2: (0.0000) | Acc: (95.00%) (32970/34688)
Epoch: 145 | Batch_idx: 280 |  Loss: (0.1416) |  Loss2: (0.0000) | Acc: (95.00%) (34184/35968)
Epoch: 145 | Batch_idx: 290 |  Loss: (0.1406) |  Loss2: (0.0000) | Acc: (95.00%) (35413/37248)
Epoch: 145 | Batch_idx: 300 |  Loss: (0.1403) |  Loss2: (0.0000) | Acc: (95.00%) (36640/38528)
Epoch: 145 | Batch_idx: 310 |  Loss: (0.1401) |  Loss2: (0.0000) | Acc: (95.00%) (37861/39808)
Epoch: 145 | Batch_idx: 320 |  Loss: (0.1404) |  Loss2: (0.0000) | Acc: (95.00%) (39075/41088)
Epoch: 145 | Batch_idx: 330 |  Loss: (0.1395) |  Loss2: (0.0000) | Acc: (95.00%) (40305/42368)
Epoch: 145 | Batch_idx: 340 |  Loss: (0.1390) |  Loss2: (0.0000) | Acc: (95.00%) (41541/43648)
Epoch: 145 | Batch_idx: 350 |  Loss: (0.1383) |  Loss2: (0.0000) | Acc: (95.00%) (42769/44928)
Epoch: 145 | Batch_idx: 360 |  Loss: (0.1377) |  Loss2: (0.0000) | Acc: (95.00%) (44005/46208)
Epoch: 145 | Batch_idx: 370 |  Loss: (0.1375) |  Loss2: (0.0000) | Acc: (95.00%) (45231/47488)
Epoch: 145 | Batch_idx: 380 |  Loss: (0.1373) |  Loss2: (0.0000) | Acc: (95.00%) (46456/48768)
Epoch: 145 | Batch_idx: 390 |  Loss: (0.1369) |  Loss2: (0.0000) | Acc: (95.00%) (47639/50000)
=> saving checkpoint 'drive/app/torch/save_Routing_Gate_2/checkpoint_145.pth.tar'
# TEST : Loss: (0.4014) | Acc: (87.00%) (8788/10000)
percent tensor([0.6094, 0.5984, 0.6150, 0.5958, 0.6222, 0.6134, 0.6121, 0.5981, 0.6093,
        0.6003, 0.6036, 0.6133, 0.5988, 0.5920, 0.6050, 0.5987],
       device='cuda:0') torch.Size([16])
percent tensor([0.5842, 0.5345, 0.5346, 0.6127, 0.5730, 0.6335, 0.5479, 0.5695, 0.5789,
        0.5389, 0.5580, 0.5244, 0.5214, 0.6254, 0.5710, 0.5920],
       device='cuda:0') torch.Size([16])
percent tensor([0.5575, 0.5979, 0.5284, 0.4925, 0.5228, 0.5053, 0.5948, 0.5471, 0.5422,
        0.5573, 0.5604, 0.5624, 0.5901, 0.5606, 0.5645, 0.5639],
       device='cuda:0') torch.Size([16])
percent tensor([0.6443, 0.6077, 0.6267, 0.6404, 0.6389, 0.6608, 0.6290, 0.6320, 0.6415,
        0.6248, 0.6368, 0.6221, 0.6277, 0.6383, 0.6368, 0.6535],
       device='cuda:0') torch.Size([16])
percent tensor([0.5894, 0.6941, 0.6636, 0.6522, 0.6041, 0.7473, 0.6283, 0.5067, 0.7261,
        0.6393, 0.7001, 0.6652, 0.7523, 0.7410, 0.5764, 0.6845],
       device='cuda:0') torch.Size([16])
percent tensor([0.6863, 0.6671, 0.7691, 0.7526, 0.7850, 0.7901, 0.7167, 0.6960, 0.7495,
        0.7082, 0.7248, 0.7169, 0.6586, 0.7852, 0.6649, 0.7363],
       device='cuda:0') torch.Size([16])
percent tensor([0.6402, 0.5772, 0.6850, 0.6027, 0.7189, 0.6810, 0.6951, 0.6800, 0.6011,
        0.6079, 0.6171, 0.5959, 0.4954, 0.5829, 0.6247, 0.6542],
       device='cuda:0') torch.Size([16])
percent tensor([0.9993, 0.9993, 0.9992, 0.9996, 0.9993, 0.9994, 0.9994, 0.9990, 0.9993,
        0.9996, 0.9996, 0.9996, 0.9994, 0.9993, 0.9991, 0.9991],
       device='cuda:0') torch.Size([16])
