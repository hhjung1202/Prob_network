Files already downloaded and verified
USE 1 GPUs!
True Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False _Gate(
  (sig): Sigmoid()
)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False _Gate(
  (sig): Sigmoid()
)
True Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False _Gate(
  (sig): Sigmoid()
)
True Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False _Gate(
  (sig): Sigmoid()
)
True Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False _Gate(
  (sig): Sigmoid()
)
True Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False _Gate(
  (sig): Sigmoid()
)
True Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False _Gate(
  (sig): Sigmoid()
)
True Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False _Gate(
  (sig): Sigmoid()
)
True Linear(in_features=512, out_features=10, bias=True)
DataParallel(
  (module): ResNet(
    (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (layer1): Sequential(
      (0): BasicBlock(
        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (gate1): _Gate(
          (sig): Sigmoid()
        )
        (shortcut): Sequential()
      )
      (1): BasicBlock(
        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (gate1): _Gate(
          (sig): Sigmoid()
        )
        (shortcut): Sequential()
      )
    )
    (layer2): Sequential(
      (0): BasicBlock(
        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (gate1): _Gate(
          (sig): Sigmoid()
        )
        (shortcut): Sequential(
          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): BasicBlock(
        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (gate1): _Gate(
          (sig): Sigmoid()
        )
        (shortcut): Sequential()
      )
    )
    (layer3): Sequential(
      (0): BasicBlock(
        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (gate1): _Gate(
          (sig): Sigmoid()
        )
        (shortcut): Sequential(
          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): BasicBlock(
        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (gate1): _Gate(
          (sig): Sigmoid()
        )
        (shortcut): Sequential()
      )
    )
    (layer4): Sequential(
      (0): BasicBlock(
        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (gate1): _Gate(
          (sig): Sigmoid()
        )
        (shortcut): Sequential(
          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): BasicBlock(
        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (gate1): _Gate(
          (sig): Sigmoid()
        )
        (shortcut): Sequential()
      )
    )
    (linear): Linear(in_features=512, out_features=10, bias=True)
  )
)
Epoch: 0 | Batch_idx: 0 |  Loss: (2.3067) | Acc: (9.00%) (12/128)
Epoch: 0 | Batch_idx: 10 |  Loss: (2.1188) | Acc: (20.00%) (293/1408)
Epoch: 0 | Batch_idx: 20 |  Loss: (2.0182) | Acc: (23.00%) (642/2688)
Epoch: 0 | Batch_idx: 30 |  Loss: (1.9585) | Acc: (25.00%) (1028/3968)
Epoch: 0 | Batch_idx: 40 |  Loss: (1.9318) | Acc: (26.00%) (1415/5248)
Epoch: 0 | Batch_idx: 50 |  Loss: (1.9123) | Acc: (27.00%) (1785/6528)
Epoch: 0 | Batch_idx: 60 |  Loss: (1.8906) | Acc: (28.00%) (2188/7808)
Epoch: 0 | Batch_idx: 70 |  Loss: (1.8716) | Acc: (28.00%) (2609/9088)
Epoch: 0 | Batch_idx: 80 |  Loss: (1.8494) | Acc: (29.00%) (3055/10368)
Epoch: 0 | Batch_idx: 90 |  Loss: (1.8343) | Acc: (30.00%) (3511/11648)
Epoch: 0 | Batch_idx: 100 |  Loss: (1.8171) | Acc: (30.00%) (3999/12928)
Epoch: 0 | Batch_idx: 110 |  Loss: (1.8065) | Acc: (31.00%) (4441/14208)
Epoch: 0 | Batch_idx: 120 |  Loss: (1.7929) | Acc: (31.00%) (4930/15488)
Epoch: 0 | Batch_idx: 130 |  Loss: (1.7816) | Acc: (32.00%) (5412/16768)
Epoch: 0 | Batch_idx: 140 |  Loss: (1.7693) | Acc: (32.00%) (5915/18048)
Epoch: 0 | Batch_idx: 150 |  Loss: (1.7626) | Acc: (33.00%) (6392/19328)
Epoch: 0 | Batch_idx: 160 |  Loss: (1.7541) | Acc: (33.00%) (6887/20608)
Epoch: 0 | Batch_idx: 170 |  Loss: (1.7479) | Acc: (33.00%) (7360/21888)
Epoch: 0 | Batch_idx: 180 |  Loss: (1.7385) | Acc: (34.00%) (7895/23168)
Epoch: 0 | Batch_idx: 190 |  Loss: (1.7299) | Acc: (34.00%) (8407/24448)
Epoch: 0 | Batch_idx: 200 |  Loss: (1.7220) | Acc: (34.00%) (8943/25728)
Epoch: 0 | Batch_idx: 210 |  Loss: (1.7131) | Acc: (35.00%) (9475/27008)
Epoch: 0 | Batch_idx: 220 |  Loss: (1.7049) | Acc: (35.00%) (10014/28288)
Epoch: 0 | Batch_idx: 230 |  Loss: (1.6953) | Acc: (35.00%) (10592/29568)
Epoch: 0 | Batch_idx: 240 |  Loss: (1.6877) | Acc: (36.00%) (11156/30848)
Epoch: 0 | Batch_idx: 250 |  Loss: (1.6796) | Acc: (36.00%) (11740/32128)
Epoch: 0 | Batch_idx: 260 |  Loss: (1.6721) | Acc: (36.00%) (12317/33408)
Epoch: 0 | Batch_idx: 270 |  Loss: (1.6652) | Acc: (37.00%) (12888/34688)
Epoch: 0 | Batch_idx: 280 |  Loss: (1.6579) | Acc: (37.00%) (13482/35968)
Epoch: 0 | Batch_idx: 290 |  Loss: (1.6497) | Acc: (37.00%) (14073/37248)
Epoch: 0 | Batch_idx: 300 |  Loss: (1.6417) | Acc: (38.00%) (14674/38528)
Epoch: 0 | Batch_idx: 310 |  Loss: (1.6316) | Acc: (38.00%) (15321/39808)
Epoch: 0 | Batch_idx: 320 |  Loss: (1.6235) | Acc: (38.00%) (15935/41088)
Epoch: 0 | Batch_idx: 330 |  Loss: (1.6160) | Acc: (39.00%) (16566/42368)
Epoch: 0 | Batch_idx: 340 |  Loss: (1.6095) | Acc: (39.00%) (17190/43648)
Epoch: 0 | Batch_idx: 350 |  Loss: (1.6023) | Acc: (39.00%) (17829/44928)
Epoch: 0 | Batch_idx: 360 |  Loss: (1.5939) | Acc: (40.00%) (18515/46208)
Epoch: 0 | Batch_idx: 370 |  Loss: (1.5867) | Acc: (40.00%) (19178/47488)
Epoch: 0 | Batch_idx: 380 |  Loss: (1.5788) | Acc: (40.00%) (19859/48768)
Epoch: 0 | Batch_idx: 390 |  Loss: (1.5721) | Acc: (40.00%) (20482/50000)
# TEST : Loss: (1.3297) | Acc: (52.00%) (5254/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[ 0.0110,  0.0371, -0.0007],
          [ 0.1109,  0.1677, -0.0902],
          [ 0.0967, -0.0937, -0.1857]],

         [[-0.1595,  0.0829,  0.0618],
          [ 0.1157,  0.0278, -0.1490],
          [ 0.0226, -0.1345, -0.0054]],

         [[ 0.0622, -0.0772,  0.0729],
          [-0.0377,  0.0952,  0.0025],
          [ 0.1069, -0.0005, -0.2098]]],


        [[[-0.0324, -0.1294, -0.0287],
          [ 0.1095, -0.1729,  0.0246],
          [-0.0350, -0.0540, -0.0379]],

         [[-0.0956, -0.0912, -0.1290],
          [-0.0192, -0.2045,  0.0327],
          [-0.0534,  0.0592,  0.1125]],

         [[-0.1258, -0.0754, -0.0458],
          [ 0.1139, -0.1568,  0.0045],
          [-0.0513, -0.0434, -0.0641]]],


        [[[ 0.1110, -0.1263,  0.1130],
          [ 0.1562,  0.0347,  0.1801],
          [ 0.0126, -0.0896, -0.1745]],

         [[ 0.2065, -0.0196, -0.1232],
          [ 0.0766, -0.0063, -0.1271],
          [ 0.1317, -0.1975,  0.1007]],

         [[-0.0494,  0.1257, -0.1543],
          [-0.0370, -0.1625,  0.1434],
          [-0.0318, -0.0097, -0.0634]]],


        ...,


        [[[-0.0631,  0.1428, -0.1077],
          [-0.1776, -0.0367, -0.1077],
          [-0.0493,  0.1424, -0.2009]],

         [[ 0.1032,  0.0350,  0.0282],
          [ 0.1039, -0.1986,  0.0378],
          [ 0.0360,  0.1004, -0.1784]],

         [[-0.1171,  0.1830,  0.0535],
          [ 0.1559,  0.0532,  0.0733],
          [ 0.1647,  0.0667, -0.1079]]],


        [[[ 0.0291, -0.1326, -0.0390],
          [ 0.0700, -0.0162,  0.1304],
          [ 0.0462, -0.1773,  0.0210]],

         [[ 0.1833, -0.1556,  0.0313],
          [-0.1589,  0.1315, -0.1220],
          [-0.0606,  0.0454, -0.1014]],

         [[-0.0943, -0.1152,  0.0454],
          [-0.1035, -0.1968, -0.1767],
          [ 0.0368, -0.0490, -0.1394]]],


        [[[-0.1427,  0.0053, -0.1408],
          [ 0.1668,  0.0051, -0.1555],
          [ 0.2203, -0.0137, -0.0467]],

         [[ 0.0846,  0.0491, -0.2004],
          [ 0.0407, -0.0351,  0.0645],
          [-0.0549, -0.0952,  0.1854]],

         [[ 0.0665, -0.1993, -0.0277],
          [ 0.0598,  0.1689,  0.1188],
          [-0.1190, -0.0506, -0.0206]]]], device='cuda:0', requires_grad=True)

conv1_weight_grad tensor([[[[ 0.0002,  0.0006,  0.0004],
          [-0.0004,  0.0002,  0.0002],
          [-0.0009, -0.0004, -0.0001]],

         [[-0.0020, -0.0016, -0.0018],
          [-0.0022, -0.0015, -0.0015],
          [-0.0019, -0.0016, -0.0013]],

         [[-0.0032, -0.0030, -0.0034],
          [-0.0031, -0.0028, -0.0030],
          [-0.0028, -0.0025, -0.0025]]],


        [[[ 0.0004, -0.0000,  0.0018],
          [-0.0003, -0.0006,  0.0014],
          [-0.0002,  0.0001,  0.0019]],

         [[ 0.0011,  0.0004,  0.0026],
          [ 0.0003, -0.0002,  0.0022],
          [ 0.0004,  0.0005,  0.0027]],

         [[-0.0000, -0.0010,  0.0014],
          [-0.0004, -0.0011,  0.0012],
          [-0.0002, -0.0002,  0.0016]]],


        [[[-0.0043, -0.0017, -0.0018],
          [-0.0187, -0.0168, -0.0151],
          [-0.0330, -0.0337, -0.0304]],

         [[ 0.0091,  0.0107,  0.0105],
          [-0.0051, -0.0034, -0.0020],
          [-0.0179, -0.0187, -0.0162]],

         [[ 0.0181,  0.0169,  0.0165],
          [ 0.0071,  0.0064,  0.0075],
          [-0.0021, -0.0043, -0.0023]]],


        ...,


        [[[-0.0128, -0.0101, -0.0074],
          [-0.0026, -0.0020,  0.0037],
          [ 0.0022,  0.0037,  0.0069]],

         [[-0.0078, -0.0031,  0.0006],
          [ 0.0022,  0.0042,  0.0108],
          [ 0.0074,  0.0095,  0.0131]],

         [[-0.0062, -0.0026,  0.0024],
          [ 0.0035,  0.0057,  0.0141],
          [ 0.0096,  0.0119,  0.0162]]],


        [[[ 0.0098,  0.0104,  0.0142],
          [ 0.0063,  0.0091,  0.0142],
          [ 0.0009,  0.0047,  0.0098]],

         [[ 0.0064,  0.0065,  0.0106],
          [ 0.0029,  0.0049,  0.0099],
          [-0.0026,  0.0005,  0.0057]],

         [[-0.0006, -0.0017,  0.0021],
          [-0.0032, -0.0027,  0.0016],
          [-0.0061, -0.0045, -0.0003]]],


        [[[ 0.0006,  0.0008,  0.0019],
          [-0.0011, -0.0008,  0.0015],
          [ 0.0001,  0.0000,  0.0035]],

         [[ 0.0024,  0.0032,  0.0048],
          [ 0.0013,  0.0022,  0.0046],
          [ 0.0009,  0.0012,  0.0050]],

         [[ 0.0039,  0.0053,  0.0072],
          [ 0.0034,  0.0048,  0.0075],
          [ 0.0017,  0.0022,  0.0062]]]], device='cuda:0')

percentage_weight tensor([0.], device='cuda:0')

percentage_weight_grad None

False Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True _Gate(
  (sig): Sigmoid()
)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True _Gate(
  (sig): Sigmoid()
)
False Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True _Gate(
  (sig): Sigmoid()
)
False Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True _Gate(
  (sig): Sigmoid()
)
False Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True _Gate(
  (sig): Sigmoid()
)
False Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True _Gate(
  (sig): Sigmoid()
)
False Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True _Gate(
  (sig): Sigmoid()
)
False Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True _Gate(
  (sig): Sigmoid()
)
False Linear(in_features=512, out_features=10, bias=True)
Epoch: 1 | Batch_idx: 0 |  Loss: (1.1777) | Acc: (52.00%) (67/128)
Epoch: 1 | Batch_idx: 10 |  Loss: (1.5826) | Acc: (42.00%) (592/1408)
Epoch: 1 | Batch_idx: 20 |  Loss: (1.7595) | Acc: (37.00%) (1008/2688)
Epoch: 1 | Batch_idx: 30 |  Loss: (1.8344) | Acc: (34.00%) (1360/3968)
Epoch: 1 | Batch_idx: 40 |  Loss: (1.8882) | Acc: (32.00%) (1695/5248)
Epoch: 1 | Batch_idx: 50 |  Loss: (1.8992) | Acc: (31.00%) (2074/6528)
Epoch: 1 | Batch_idx: 60 |  Loss: (1.8985) | Acc: (31.00%) (2457/7808)
Epoch: 1 | Batch_idx: 70 |  Loss: (1.8972) | Acc: (31.00%) (2847/9088)
Epoch: 1 | Batch_idx: 80 |  Loss: (1.8871) | Acc: (31.00%) (3223/10368)
Epoch: 1 | Batch_idx: 90 |  Loss: (1.8706) | Acc: (31.00%) (3655/11648)
Epoch: 1 | Batch_idx: 100 |  Loss: (1.8586) | Acc: (31.00%) (4089/12928)
Epoch: 1 | Batch_idx: 110 |  Loss: (1.8489) | Acc: (31.00%) (4535/14208)
Epoch: 1 | Batch_idx: 120 |  Loss: (1.8322) | Acc: (32.00%) (5013/15488)
Epoch: 1 | Batch_idx: 130 |  Loss: (1.8240) | Acc: (32.00%) (5453/16768)
Epoch: 1 | Batch_idx: 140 |  Loss: (1.8147) | Acc: (32.00%) (5912/18048)
Epoch: 1 | Batch_idx: 150 |  Loss: (1.8049) | Acc: (33.00%) (6388/19328)
Epoch: 1 | Batch_idx: 160 |  Loss: (1.7956) | Acc: (33.00%) (6869/20608)
Epoch: 1 | Batch_idx: 170 |  Loss: (1.7842) | Acc: (33.00%) (7368/21888)
Epoch: 1 | Batch_idx: 180 |  Loss: (1.7740) | Acc: (33.00%) (7877/23168)
Epoch: 1 | Batch_idx: 190 |  Loss: (1.7671) | Acc: (34.00%) (8340/24448)
Epoch: 1 | Batch_idx: 200 |  Loss: (1.7592) | Acc: (34.00%) (8842/25728)
Epoch: 1 | Batch_idx: 210 |  Loss: (1.7505) | Acc: (34.00%) (9336/27008)
Epoch: 1 | Batch_idx: 220 |  Loss: (1.7426) | Acc: (34.00%) (9835/28288)
Epoch: 1 | Batch_idx: 230 |  Loss: (1.7335) | Acc: (35.00%) (10354/29568)
Epoch: 1 | Batch_idx: 240 |  Loss: (1.7274) | Acc: (35.00%) (10849/30848)
Epoch: 1 | Batch_idx: 250 |  Loss: (1.7200) | Acc: (35.00%) (11383/32128)
Epoch: 1 | Batch_idx: 260 |  Loss: (1.7129) | Acc: (35.00%) (11931/33408)
Epoch: 1 | Batch_idx: 270 |  Loss: (1.7065) | Acc: (35.00%) (12471/34688)
Epoch: 1 | Batch_idx: 280 |  Loss: (1.7013) | Acc: (36.00%) (12980/35968)
Epoch: 1 | Batch_idx: 290 |  Loss: (1.6952) | Acc: (36.00%) (13527/37248)
Epoch: 1 | Batch_idx: 300 |  Loss: (1.6907) | Acc: (36.00%) (14048/38528)
Epoch: 1 | Batch_idx: 310 |  Loss: (1.6859) | Acc: (36.00%) (14572/39808)
Epoch: 1 | Batch_idx: 320 |  Loss: (1.6820) | Acc: (36.00%) (15097/41088)
Epoch: 1 | Batch_idx: 330 |  Loss: (1.6773) | Acc: (36.00%) (15661/42368)
Epoch: 1 | Batch_idx: 340 |  Loss: (1.6713) | Acc: (37.00%) (16227/43648)
Epoch: 1 | Batch_idx: 350 |  Loss: (1.6684) | Acc: (37.00%) (16744/44928)
Epoch: 1 | Batch_idx: 360 |  Loss: (1.6643) | Acc: (37.00%) (17279/46208)
Epoch: 1 | Batch_idx: 370 |  Loss: (1.6602) | Acc: (37.00%) (17836/47488)
Epoch: 1 | Batch_idx: 380 |  Loss: (1.6552) | Acc: (37.00%) (18394/48768)
Epoch: 1 | Batch_idx: 390 |  Loss: (1.6508) | Acc: (37.00%) (18953/50000)
# TEST : Loss: (1.4634) | Acc: (44.00%) (4467/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[ 0.0015,  0.0268, -0.0076],
          [ 0.0995,  0.1534, -0.0938],
          [ 0.0870, -0.0969, -0.1853]],

         [[-0.1560,  0.0760,  0.0570],
          [ 0.1097,  0.0245, -0.1452],
          [ 0.0216, -0.1305, -0.0073]],

         [[ 0.0571, -0.0766,  0.0681],
          [-0.0366,  0.0890,  0.0001],
          [ 0.1019, -0.0027, -0.2037]]],


        [[[-0.0331, -0.1240, -0.0265],
          [ 0.1041, -0.1649,  0.0247],
          [-0.0335, -0.0514, -0.0360]],

         [[-0.0924, -0.0853, -0.1213],
          [-0.0201, -0.1879,  0.0308],
          [-0.0506,  0.0569,  0.1086]],

         [[-0.1200, -0.0712, -0.0436],
          [ 0.1077, -0.1485,  0.0044],
          [-0.0488, -0.0414, -0.0615]]],


        [[[ 0.1129, -0.1228,  0.1162],
          [ 0.1591,  0.0383,  0.1837],
          [ 0.0172, -0.0842, -0.1684]],

         [[ 0.2072, -0.0178, -0.1204],
          [ 0.0790, -0.0038, -0.1237],
          [ 0.1353, -0.1924,  0.1047]],

         [[-0.0495,  0.1246, -0.1538],
          [-0.0361, -0.1616,  0.1430],
          [-0.0297, -0.0078, -0.0612]]],


        ...,


        [[[-0.0613,  0.1440, -0.1064],
          [-0.1752, -0.0348, -0.1064],
          [-0.0465,  0.1445, -0.1987]],

         [[ 0.1038,  0.0353,  0.0278],
          [ 0.1050, -0.1972,  0.0377],
          [ 0.0380,  0.1017, -0.1774]],

         [[-0.1149,  0.1840,  0.0537],
          [ 0.1578,  0.0549,  0.0733],
          [ 0.1671,  0.0685, -0.1069]]],


        [[[ 0.0265, -0.1341, -0.0404],
          [ 0.0679, -0.0176,  0.1282],
          [ 0.0462, -0.1757,  0.0209]],

         [[ 0.1808, -0.1546,  0.0305],
          [-0.1563,  0.1301, -0.1202],
          [-0.0564,  0.0483, -0.0976]],

         [[-0.0946, -0.1159,  0.0421],
          [-0.1010, -0.1928, -0.1730],
          [ 0.0393, -0.0453, -0.1349]]],


        [[[-0.1396,  0.0061, -0.1385],
          [ 0.1666,  0.0054, -0.1539],
          [ 0.2194, -0.0133, -0.0464]],

         [[ 0.0839,  0.0479, -0.1992],
          [ 0.0402, -0.0359,  0.0625],
          [-0.0546, -0.0954,  0.1824]],

         [[ 0.0642, -0.2000, -0.0304],
          [ 0.0572,  0.1640,  0.1141],
          [-0.1202, -0.0535, -0.0242]]]], device='cuda:0')

conv1_weight_grad tensor([[[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        ...,


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]]], device='cuda:0')

percentage_weight tensor([0.], device='cuda:0', requires_grad=True)

percentage_weight_grad tensor([-15.6989], device='cuda:0')

Epoch: 2 | Batch_idx: 0 |  Loss: (1.4958) | Acc: (45.00%) (58/128)
Epoch: 2 | Batch_idx: 10 |  Loss: (1.4779) | Acc: (44.00%) (625/1408)
Epoch: 2 | Batch_idx: 20 |  Loss: (1.4782) | Acc: (44.00%) (1197/2688)
Epoch: 2 | Batch_idx: 30 |  Loss: (1.4856) | Acc: (43.00%) (1736/3968)
Epoch: 2 | Batch_idx: 40 |  Loss: (1.4867) | Acc: (44.00%) (2320/5248)
Epoch: 2 | Batch_idx: 50 |  Loss: (1.4881) | Acc: (44.00%) (2881/6528)
Epoch: 2 | Batch_idx: 60 |  Loss: (1.4877) | Acc: (44.00%) (3447/7808)
Epoch: 2 | Batch_idx: 70 |  Loss: (1.4878) | Acc: (44.00%) (4029/9088)
Epoch: 2 | Batch_idx: 80 |  Loss: (1.4866) | Acc: (44.00%) (4588/10368)
Epoch: 2 | Batch_idx: 90 |  Loss: (1.4817) | Acc: (44.00%) (5169/11648)
Epoch: 2 | Batch_idx: 100 |  Loss: (1.4822) | Acc: (44.00%) (5751/12928)
Epoch: 2 | Batch_idx: 110 |  Loss: (1.4819) | Acc: (44.00%) (6342/14208)
Epoch: 2 | Batch_idx: 120 |  Loss: (1.4783) | Acc: (44.00%) (6964/15488)
Epoch: 2 | Batch_idx: 130 |  Loss: (1.4771) | Acc: (44.00%) (7532/16768)
Epoch: 2 | Batch_idx: 140 |  Loss: (1.4775) | Acc: (44.00%) (8107/18048)
Epoch: 2 | Batch_idx: 150 |  Loss: (1.4778) | Acc: (44.00%) (8653/19328)
Epoch: 2 | Batch_idx: 160 |  Loss: (1.4766) | Acc: (44.00%) (9254/20608)
Epoch: 2 | Batch_idx: 170 |  Loss: (1.4743) | Acc: (45.00%) (9865/21888)
Epoch: 2 | Batch_idx: 180 |  Loss: (1.4740) | Acc: (45.00%) (10453/23168)
Epoch: 2 | Batch_idx: 190 |  Loss: (1.4719) | Acc: (45.00%) (11046/24448)
Epoch: 2 | Batch_idx: 200 |  Loss: (1.4717) | Acc: (45.00%) (11610/25728)
Epoch: 2 | Batch_idx: 210 |  Loss: (1.4720) | Acc: (45.00%) (12169/27008)
Epoch: 2 | Batch_idx: 220 |  Loss: (1.4700) | Acc: (45.00%) (12784/28288)
Epoch: 2 | Batch_idx: 230 |  Loss: (1.4719) | Acc: (45.00%) (13334/29568)
Epoch: 2 | Batch_idx: 240 |  Loss: (1.4714) | Acc: (45.00%) (13900/30848)
Epoch: 2 | Batch_idx: 250 |  Loss: (1.4705) | Acc: (45.00%) (14512/32128)
Epoch: 2 | Batch_idx: 260 |  Loss: (1.4699) | Acc: (45.00%) (15107/33408)
Epoch: 2 | Batch_idx: 270 |  Loss: (1.4698) | Acc: (45.00%) (15717/34688)
Epoch: 2 | Batch_idx: 280 |  Loss: (1.4698) | Acc: (45.00%) (16292/35968)
Epoch: 2 | Batch_idx: 290 |  Loss: (1.4693) | Acc: (45.00%) (16868/37248)
Epoch: 2 | Batch_idx: 300 |  Loss: (1.4701) | Acc: (45.00%) (17434/38528)
Epoch: 2 | Batch_idx: 310 |  Loss: (1.4689) | Acc: (45.00%) (18044/39808)
Epoch: 2 | Batch_idx: 320 |  Loss: (1.4680) | Acc: (45.00%) (18649/41088)
Epoch: 2 | Batch_idx: 330 |  Loss: (1.4676) | Acc: (45.00%) (19259/42368)
Epoch: 2 | Batch_idx: 340 |  Loss: (1.4659) | Acc: (45.00%) (19871/43648)
Epoch: 2 | Batch_idx: 350 |  Loss: (1.4655) | Acc: (45.00%) (20463/44928)
Epoch: 2 | Batch_idx: 360 |  Loss: (1.4659) | Acc: (45.00%) (21038/46208)
Epoch: 2 | Batch_idx: 370 |  Loss: (1.4645) | Acc: (45.00%) (21644/47488)
Epoch: 2 | Batch_idx: 380 |  Loss: (1.4638) | Acc: (45.00%) (22271/48768)
Epoch: 2 | Batch_idx: 390 |  Loss: (1.4638) | Acc: (45.00%) (22821/50000)
# TEST : Loss: (1.4214) | Acc: (47.00%) (4736/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[ 0.0014,  0.0253, -0.0072],
          [ 0.0934,  0.1444, -0.0886],
          [ 0.0818, -0.0913, -0.1752]],

         [[-0.1466,  0.0714,  0.0537],
          [ 0.1025,  0.0229, -0.1365],
          [ 0.0202, -0.1222, -0.0069]],

         [[ 0.0536, -0.0719,  0.0641],
          [-0.0342,  0.0832,  0.0001],
          [ 0.0955, -0.0025, -0.1915]]],


        [[[-0.0312, -0.1163, -0.0249],
          [ 0.0982, -0.1546,  0.0232],
          [-0.0320, -0.0489, -0.0343]],

         [[-0.0840, -0.0759, -0.1110],
          [-0.0182, -0.1658,  0.0282],
          [-0.0474,  0.0527,  0.1022]],

         [[-0.1115, -0.0663, -0.0409],
          [ 0.1000, -0.1377,  0.0041],
          [-0.0458, -0.0387, -0.0579]]],


        [[[ 0.1122, -0.1221,  0.1156],
          [ 0.1581,  0.0381,  0.1827],
          [ 0.0171, -0.0838, -0.1675]],

         [[ 0.2059, -0.0177, -0.1197],
          [ 0.0785, -0.0037, -0.1229],
          [ 0.1345, -0.1913,  0.1041]],

         [[-0.0492,  0.1238, -0.1528],
          [-0.0359, -0.1605,  0.1420],
          [-0.0295, -0.0077, -0.0608]]],


        ...,


        [[[-0.0612,  0.1436, -0.1061],
          [-0.1748, -0.0347, -0.1061],
          [-0.0463,  0.1442, -0.1982]],

         [[ 0.1035,  0.0352,  0.0277],
          [ 0.1047, -0.1966,  0.0376],
          [ 0.0379,  0.1014, -0.1769]],

         [[-0.1145,  0.1834,  0.0535],
          [ 0.1572,  0.0547,  0.0731],
          [ 0.1665,  0.0683, -0.1066]]],


        [[[ 0.0262, -0.1326, -0.0400],
          [ 0.0672, -0.0174,  0.1267],
          [ 0.0456, -0.1737,  0.0207]],

         [[ 0.1780, -0.1518,  0.0301],
          [-0.1534,  0.1276, -0.1180],
          [-0.0554,  0.0474, -0.0959]],

         [[-0.0919, -0.1118,  0.0407],
          [-0.0972, -0.1855, -0.1659],
          [ 0.0381, -0.0437, -0.1304]]],


        [[[-0.1375,  0.0060, -0.1363],
          [ 0.1642,  0.0053, -0.1517],
          [ 0.2163, -0.0131, -0.0458]],

         [[ 0.0827,  0.0472, -0.1961],
          [ 0.0396, -0.0354,  0.0616],
          [-0.0538, -0.0941,  0.1800]],

         [[ 0.0634, -0.1972, -0.0299],
          [ 0.0564,  0.1618,  0.1125],
          [-0.1185, -0.0527, -0.0238]]]], device='cuda:0')

conv1_weight_grad tensor([[[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        ...,


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]]], device='cuda:0')

percentage_weight tensor([0.], device='cuda:0', requires_grad=True)

percentage_weight_grad tensor([-24.8450], device='cuda:0')

True Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False _Gate(
  (sig): Sigmoid()
)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False _Gate(
  (sig): Sigmoid()
)
True Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False _Gate(
  (sig): Sigmoid()
)
True Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False _Gate(
  (sig): Sigmoid()
)
True Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False _Gate(
  (sig): Sigmoid()
)
True Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False _Gate(
  (sig): Sigmoid()
)
True Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False _Gate(
  (sig): Sigmoid()
)
True Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False _Gate(
  (sig): Sigmoid()
)
True Linear(in_features=512, out_features=10, bias=True)
Epoch: 3 | Batch_idx: 0 |  Loss: (1.3946) | Acc: (46.00%) (60/128)
Epoch: 3 | Batch_idx: 10 |  Loss: (1.6526) | Acc: (35.00%) (503/1408)
Epoch: 3 | Batch_idx: 20 |  Loss: (1.5820) | Acc: (39.00%) (1059/2688)
Epoch: 3 | Batch_idx: 30 |  Loss: (1.5396) | Acc: (41.00%) (1641/3968)
Epoch: 3 | Batch_idx: 40 |  Loss: (1.5221) | Acc: (42.00%) (2222/5248)
Epoch: 3 | Batch_idx: 50 |  Loss: (1.5055) | Acc: (43.00%) (2810/6528)
Epoch: 3 | Batch_idx: 60 |  Loss: (1.4888) | Acc: (43.00%) (3414/7808)
Epoch: 3 | Batch_idx: 70 |  Loss: (1.4819) | Acc: (44.00%) (4014/9088)
Epoch: 3 | Batch_idx: 80 |  Loss: (1.4714) | Acc: (44.00%) (4611/10368)
Epoch: 3 | Batch_idx: 90 |  Loss: (1.4554) | Acc: (45.00%) (5266/11648)
Epoch: 3 | Batch_idx: 100 |  Loss: (1.4445) | Acc: (45.00%) (5925/12928)
Epoch: 3 | Batch_idx: 110 |  Loss: (1.4299) | Acc: (46.00%) (6590/14208)
Epoch: 3 | Batch_idx: 120 |  Loss: (1.4152) | Acc: (47.00%) (7289/15488)
Epoch: 3 | Batch_idx: 130 |  Loss: (1.4054) | Acc: (47.00%) (7950/16768)
Epoch: 3 | Batch_idx: 140 |  Loss: (1.3949) | Acc: (47.00%) (8649/18048)
Epoch: 3 | Batch_idx: 150 |  Loss: (1.3854) | Acc: (48.00%) (9344/19328)
Epoch: 3 | Batch_idx: 160 |  Loss: (1.3768) | Acc: (48.00%) (10041/20608)
Epoch: 3 | Batch_idx: 170 |  Loss: (1.3634) | Acc: (49.00%) (10791/21888)
Epoch: 3 | Batch_idx: 180 |  Loss: (1.3525) | Acc: (49.00%) (11549/23168)
Epoch: 3 | Batch_idx: 190 |  Loss: (1.3445) | Acc: (50.00%) (12251/24448)
Epoch: 3 | Batch_idx: 200 |  Loss: (1.3378) | Acc: (50.00%) (12962/25728)
Epoch: 3 | Batch_idx: 210 |  Loss: (1.3326) | Acc: (50.00%) (13668/27008)
Epoch: 3 | Batch_idx: 220 |  Loss: (1.3255) | Acc: (50.00%) (14399/28288)
Epoch: 3 | Batch_idx: 230 |  Loss: (1.3177) | Acc: (51.00%) (15175/29568)
Epoch: 3 | Batch_idx: 240 |  Loss: (1.3121) | Acc: (51.00%) (15918/30848)
Epoch: 3 | Batch_idx: 250 |  Loss: (1.3043) | Acc: (51.00%) (16687/32128)
Epoch: 3 | Batch_idx: 260 |  Loss: (1.2968) | Acc: (52.00%) (17459/33408)
Epoch: 3 | Batch_idx: 270 |  Loss: (1.2908) | Acc: (52.00%) (18213/34688)
Epoch: 3 | Batch_idx: 280 |  Loss: (1.2850) | Acc: (52.00%) (18958/35968)
Epoch: 3 | Batch_idx: 290 |  Loss: (1.2783) | Acc: (53.00%) (19743/37248)
Epoch: 3 | Batch_idx: 300 |  Loss: (1.2726) | Acc: (53.00%) (20501/38528)
Epoch: 3 | Batch_idx: 310 |  Loss: (1.2696) | Acc: (53.00%) (21255/39808)
Epoch: 3 | Batch_idx: 320 |  Loss: (1.2661) | Acc: (53.00%) (22010/41088)
Epoch: 3 | Batch_idx: 330 |  Loss: (1.2610) | Acc: (53.00%) (22781/42368)
Epoch: 3 | Batch_idx: 340 |  Loss: (1.2547) | Acc: (54.00%) (23578/43648)
Epoch: 3 | Batch_idx: 350 |  Loss: (1.2496) | Acc: (54.00%) (24365/44928)
Epoch: 3 | Batch_idx: 360 |  Loss: (1.2453) | Acc: (54.00%) (25136/46208)
Epoch: 3 | Batch_idx: 370 |  Loss: (1.2408) | Acc: (54.00%) (25910/47488)
Epoch: 3 | Batch_idx: 380 |  Loss: (1.2369) | Acc: (54.00%) (26694/48768)
Epoch: 3 | Batch_idx: 390 |  Loss: (1.2332) | Acc: (54.00%) (27431/50000)
# TEST : Loss: (1.1918) | Acc: (57.00%) (5768/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-0.0476,  0.0317,  0.0205],
          [ 0.0737,  0.1563, -0.0672],
          [ 0.0928, -0.0812, -0.1506]],

         [[-0.1892,  0.0801,  0.0844],
          [ 0.0819,  0.0496, -0.1052],
          [ 0.0329, -0.1080,  0.0117]],

         [[-0.0108, -0.0784,  0.0708],
          [-0.0578,  0.0863,  0.0056],
          [ 0.0883, -0.0116, -0.1791]]],


        [[[ 0.0024, -0.1085,  0.0133],
          [ 0.1130, -0.1734,  0.0360],
          [ 0.0006, -0.0333,  0.0001]],

         [[-0.0480, -0.0823, -0.0710],
          [-0.0080, -0.2199,  0.0238],
          [-0.0141,  0.0556,  0.1253]],

         [[-0.0846, -0.0710, -0.0217],
          [ 0.0980, -0.1824, -0.0093],
          [-0.0306, -0.0549, -0.0481]]],


        [[[ 0.1222, -0.0971,  0.1398],
          [ 0.1637,  0.0625,  0.2029],
          [ 0.0183, -0.0661, -0.1550]],

         [[ 0.2274,  0.0171, -0.0837],
          [ 0.0958,  0.0307, -0.0918],
          [ 0.1404, -0.1669,  0.1201]],

         [[-0.0405,  0.1405, -0.1342],
          [-0.0343, -0.1447,  0.1514],
          [-0.0351,  0.0007, -0.0572]]],


        ...,


        [[[-0.0744,  0.1383, -0.1131],
          [-0.1890, -0.0434, -0.1198],
          [-0.0614,  0.1341, -0.2140]],

         [[ 0.0881,  0.0268,  0.0121],
          [ 0.1016, -0.1962,  0.0245],
          [ 0.0369,  0.1015, -0.1914]],

         [[-0.1224,  0.1861,  0.0452],
          [ 0.1653,  0.0709,  0.0705],
          [ 0.1680,  0.0763, -0.1176]]],


        [[[ 0.0363, -0.1363, -0.0340],
          [ 0.0605, -0.0325,  0.1207],
          [ 0.0577, -0.1581,  0.0410]],

         [[ 0.2041, -0.1421,  0.0433],
          [-0.1477,  0.1097, -0.1248],
          [-0.0207,  0.0778, -0.0649]],

         [[-0.0538, -0.1147,  0.0433],
          [-0.0967, -0.2383, -0.2094],
          [ 0.0569, -0.0516, -0.1326]]],


        [[[-0.1123,  0.0138, -0.1252],
          [ 0.1722,  0.0190, -0.1466],
          [ 0.2094, -0.0061, -0.0398]],

         [[ 0.0977,  0.0537, -0.1796],
          [ 0.0401, -0.0247,  0.0653],
          [-0.0691, -0.0950,  0.1787]],

         [[ 0.0845, -0.1858, -0.0246],
          [ 0.0692,  0.1772,  0.1166],
          [-0.1209, -0.0462, -0.0192]]]], device='cuda:0', requires_grad=True)

conv1_weight_grad tensor([[[[ 0.0004, -0.0006, -0.0015],
          [ 0.0003, -0.0003, -0.0010],
          [ 0.0002,  0.0004, -0.0005]],

         [[-0.0001, -0.0008, -0.0019],
          [-0.0001, -0.0005, -0.0015],
          [-0.0001,  0.0002, -0.0010]],

         [[-0.0004, -0.0008, -0.0019],
          [-0.0003, -0.0005, -0.0015],
          [-0.0002,  0.0001, -0.0011]]],


        [[[ 0.0033,  0.0012,  0.0026],
          [ 0.0037,  0.0017,  0.0034],
          [ 0.0036,  0.0021,  0.0035]],

         [[ 0.0017, -0.0002,  0.0012],
          [ 0.0015,  0.0000,  0.0018],
          [ 0.0012,  0.0002,  0.0018]],

         [[ 0.0009, -0.0003,  0.0009],
          [ 0.0009,  0.0001,  0.0016],
          [ 0.0011,  0.0007,  0.0020]]],


        [[[ 0.0001,  0.0008,  0.0017],
          [ 0.0005,  0.0005,  0.0013],
          [ 0.0007,  0.0005,  0.0009]],

         [[-0.0027, -0.0017, -0.0004],
          [-0.0028, -0.0024, -0.0014],
          [-0.0029, -0.0028, -0.0020]],

         [[-0.0038, -0.0036, -0.0030],
          [-0.0042, -0.0045, -0.0040],
          [-0.0041, -0.0043, -0.0040]]],


        ...,


        [[[-0.0197, -0.0223, -0.0320],
          [-0.0266, -0.0270, -0.0340],
          [-0.0111, -0.0136, -0.0227]],

         [[-0.0279, -0.0307, -0.0390],
          [-0.0380, -0.0378, -0.0420],
          [-0.0270, -0.0289, -0.0362]],

         [[-0.0258, -0.0297, -0.0368],
          [-0.0351, -0.0362, -0.0392],
          [-0.0259, -0.0291, -0.0347]]],


        [[[ 0.0035, -0.0025, -0.0002],
          [ 0.0073,  0.0008,  0.0024],
          [ 0.0065,  0.0015,  0.0028]],

         [[-0.0030, -0.0078, -0.0051],
          [ 0.0005, -0.0052, -0.0032],
          [-0.0001, -0.0044, -0.0026]],

         [[ 0.0009, -0.0020, -0.0002],
          [ 0.0038,  0.0006,  0.0022],
          [ 0.0051,  0.0034,  0.0048]]],


        [[[-0.0027, -0.0014, -0.0007],
          [-0.0011, -0.0002,  0.0003],
          [-0.0003,  0.0004,  0.0027]],

         [[-0.0038, -0.0029, -0.0025],
          [-0.0018, -0.0014, -0.0012],
          [-0.0011, -0.0005,  0.0015]],

         [[-0.0038, -0.0029, -0.0025],
          [-0.0025, -0.0021, -0.0020],
          [-0.0021, -0.0014,  0.0004]]]], device='cuda:0')

percentage_weight tensor([0.], device='cuda:0')

percentage_weight_grad tensor([-24.8450], device='cuda:0')

Epoch: 4 | Batch_idx: 0 |  Loss: (1.1397) | Acc: (60.00%) (78/128)
Epoch: 4 | Batch_idx: 10 |  Loss: (0.9948) | Acc: (64.00%) (908/1408)
Epoch: 4 | Batch_idx: 20 |  Loss: (0.9903) | Acc: (63.00%) (1717/2688)
Epoch: 4 | Batch_idx: 30 |  Loss: (0.9859) | Acc: (64.00%) (2543/3968)
Epoch: 4 | Batch_idx: 40 |  Loss: (0.9968) | Acc: (63.00%) (3341/5248)
Epoch: 4 | Batch_idx: 50 |  Loss: (0.9980) | Acc: (63.00%) (4169/6528)
Epoch: 4 | Batch_idx: 60 |  Loss: (1.0050) | Acc: (63.00%) (4981/7808)
Epoch: 4 | Batch_idx: 70 |  Loss: (1.0082) | Acc: (63.00%) (5782/9088)
Epoch: 4 | Batch_idx: 80 |  Loss: (1.0121) | Acc: (63.00%) (6592/10368)
Epoch: 4 | Batch_idx: 90 |  Loss: (1.0127) | Acc: (63.00%) (7398/11648)
Epoch: 4 | Batch_idx: 100 |  Loss: (1.0097) | Acc: (63.00%) (8237/12928)
Epoch: 4 | Batch_idx: 110 |  Loss: (1.0036) | Acc: (63.00%) (9093/14208)
Epoch: 4 | Batch_idx: 120 |  Loss: (1.0036) | Acc: (63.00%) (9912/15488)
Epoch: 4 | Batch_idx: 130 |  Loss: (0.9993) | Acc: (64.00%) (10753/16768)
Epoch: 4 | Batch_idx: 140 |  Loss: (0.9989) | Acc: (64.00%) (11566/18048)
Epoch: 4 | Batch_idx: 150 |  Loss: (0.9966) | Acc: (64.00%) (12400/19328)
Epoch: 4 | Batch_idx: 160 |  Loss: (0.9958) | Acc: (64.00%) (13234/20608)
Epoch: 4 | Batch_idx: 170 |  Loss: (0.9936) | Acc: (64.00%) (14071/21888)
Epoch: 4 | Batch_idx: 180 |  Loss: (0.9905) | Acc: (64.00%) (14933/23168)
Epoch: 4 | Batch_idx: 190 |  Loss: (0.9886) | Acc: (64.00%) (15775/24448)
Epoch: 4 | Batch_idx: 200 |  Loss: (0.9893) | Acc: (64.00%) (16592/25728)
Epoch: 4 | Batch_idx: 210 |  Loss: (0.9844) | Acc: (64.00%) (17470/27008)
Epoch: 4 | Batch_idx: 220 |  Loss: (0.9823) | Acc: (64.00%) (18329/28288)
Epoch: 4 | Batch_idx: 230 |  Loss: (0.9795) | Acc: (64.00%) (19189/29568)
Epoch: 4 | Batch_idx: 240 |  Loss: (0.9777) | Acc: (64.00%) (20041/30848)
Epoch: 4 | Batch_idx: 250 |  Loss: (0.9753) | Acc: (65.00%) (20905/32128)
Epoch: 4 | Batch_idx: 260 |  Loss: (0.9731) | Acc: (65.00%) (21777/33408)
Epoch: 4 | Batch_idx: 270 |  Loss: (0.9691) | Acc: (65.00%) (22659/34688)
Epoch: 4 | Batch_idx: 280 |  Loss: (0.9671) | Acc: (65.00%) (23533/35968)
Epoch: 4 | Batch_idx: 290 |  Loss: (0.9648) | Acc: (65.00%) (24386/37248)
Epoch: 4 | Batch_idx: 300 |  Loss: (0.9618) | Acc: (65.00%) (25253/38528)
Epoch: 4 | Batch_idx: 310 |  Loss: (0.9587) | Acc: (65.00%) (26147/39808)
Epoch: 4 | Batch_idx: 320 |  Loss: (0.9567) | Acc: (65.00%) (27030/41088)
Epoch: 4 | Batch_idx: 330 |  Loss: (0.9532) | Acc: (65.00%) (27921/42368)
Epoch: 4 | Batch_idx: 340 |  Loss: (0.9521) | Acc: (65.00%) (28793/43648)
Epoch: 4 | Batch_idx: 350 |  Loss: (0.9504) | Acc: (66.00%) (29660/44928)
Epoch: 4 | Batch_idx: 360 |  Loss: (0.9475) | Acc: (66.00%) (30557/46208)
Epoch: 4 | Batch_idx: 370 |  Loss: (0.9462) | Acc: (66.00%) (31445/47488)
Epoch: 4 | Batch_idx: 380 |  Loss: (0.9443) | Acc: (66.00%) (32325/48768)
Epoch: 4 | Batch_idx: 390 |  Loss: (0.9417) | Acc: (66.00%) (33199/50000)
# TEST : Loss: (0.9304) | Acc: (67.00%) (6796/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-0.1019,  0.0116,  0.0170],
          [ 0.0261,  0.1451, -0.0810],
          [ 0.0608, -0.1025, -0.1609]],

         [[-0.2282,  0.0658,  0.0855],
          [ 0.0480,  0.0524, -0.1077],
          [ 0.0148, -0.1149,  0.0103]],

         [[-0.0412, -0.0802,  0.0824],
          [-0.0727,  0.0978,  0.0135],
          [ 0.0790, -0.0104, -0.1650]]],


        [[[ 0.0177, -0.1058,  0.0077],
          [ 0.0959, -0.2020,  0.0184],
          [-0.0038, -0.0466, -0.0111]],

         [[-0.0456, -0.0975, -0.0774],
          [-0.0278, -0.2593,  0.0097],
          [-0.0192,  0.0372,  0.1139]],

         [[-0.0617, -0.0276,  0.0028],
          [ 0.0884, -0.1704,  0.0032],
          [-0.0323, -0.0582, -0.0454]]],


        [[[ 0.1202, -0.0951,  0.1434],
          [ 0.1634,  0.0657,  0.2068],
          [ 0.0218, -0.0588, -0.1456]],

         [[ 0.2363,  0.0279, -0.0710],
          [ 0.1066,  0.0429, -0.0783],
          [ 0.1497, -0.1525,  0.1329]],

         [[-0.0333,  0.1463, -0.1255],
          [-0.0296, -0.1392,  0.1542],
          [-0.0302,  0.0068, -0.0509]]],


        ...,


        [[[-0.0729,  0.1405, -0.1085],
          [-0.1878, -0.0424, -0.1183],
          [-0.0643,  0.1306, -0.2187]],

         [[ 0.0914,  0.0314,  0.0160],
          [ 0.1094, -0.1878,  0.0295],
          [ 0.0421,  0.1062, -0.1920]],

         [[-0.1193,  0.1936,  0.0525],
          [ 0.1776,  0.0873,  0.0833],
          [ 0.1775,  0.0883, -0.1123]]],


        [[[ 0.0431, -0.1283, -0.0244],
          [ 0.0527, -0.0438,  0.1081],
          [ 0.0507, -0.1630,  0.0275]],

         [[ 0.2226, -0.1162,  0.0701],
          [-0.1316,  0.1187, -0.1149],
          [-0.0047,  0.0910, -0.0617]],

         [[-0.0572, -0.1042,  0.0671],
          [-0.1220, -0.2793, -0.2249],
          [ 0.0445, -0.0691, -0.1527]]],


        [[[-0.0983,  0.0194, -0.1190],
          [ 0.1860,  0.0381, -0.1337],
          [ 0.2138,  0.0019, -0.0310]],

         [[ 0.0983,  0.0555, -0.1698],
          [ 0.0454, -0.0065,  0.0783],
          [-0.0671, -0.0859,  0.1875]],

         [[ 0.0754, -0.1886, -0.0280],
          [ 0.0614,  0.1791,  0.1153],
          [-0.1301, -0.0495, -0.0216]]]], device='cuda:0', requires_grad=True)

conv1_weight_grad tensor([[[[ 0.0009,  0.0021,  0.0032],
          [ 0.0023,  0.0034,  0.0030],
          [ 0.0026,  0.0027,  0.0021]],

         [[ 0.0007,  0.0021,  0.0033],
          [ 0.0023,  0.0036,  0.0031],
          [ 0.0027,  0.0029,  0.0022]],

         [[ 0.0002,  0.0017,  0.0029],
          [ 0.0018,  0.0031,  0.0026],
          [ 0.0023,  0.0025,  0.0017]]],


        [[[ 0.0021,  0.0001,  0.0022],
          [ 0.0010,  0.0002,  0.0022],
          [ 0.0019,  0.0019,  0.0035]],

         [[ 0.0033,  0.0015,  0.0039],
          [ 0.0017,  0.0009,  0.0032],
          [ 0.0021,  0.0021,  0.0040]],

         [[ 0.0008, -0.0013,  0.0007],
          [-0.0009, -0.0022, -0.0004],
          [-0.0005, -0.0012,  0.0002]]],


        [[[-0.0003,  0.0006,  0.0017],
          [-0.0008, -0.0001,  0.0001],
          [-0.0004,  0.0006,  0.0007]],

         [[ 0.0020,  0.0035,  0.0050],
          [ 0.0017,  0.0030,  0.0036],
          [ 0.0014,  0.0030,  0.0035]],

         [[ 0.0031,  0.0047,  0.0065],
          [ 0.0026,  0.0041,  0.0051],
          [ 0.0021,  0.0038,  0.0045]]],


        ...,


        [[[-0.0229, -0.0185, -0.0306],
          [-0.0261, -0.0183, -0.0308],
          [-0.0352, -0.0240, -0.0325]],

         [[-0.0295, -0.0268, -0.0378],
          [-0.0348, -0.0291, -0.0403],
          [-0.0434, -0.0329, -0.0400]],

         [[-0.0192, -0.0208, -0.0293],
          [-0.0240, -0.0210, -0.0274],
          [-0.0314, -0.0221, -0.0229]]],


        [[[-0.0007, -0.0006, -0.0004],
          [ 0.0021,  0.0025,  0.0025],
          [-0.0056, -0.0051, -0.0066]],

         [[ 0.0087,  0.0085,  0.0086],
          [ 0.0097,  0.0098,  0.0097],
          [ 0.0009,  0.0011, -0.0003]],

         [[ 0.0021,  0.0026,  0.0029],
          [ 0.0025,  0.0031,  0.0036],
          [-0.0055, -0.0050, -0.0058]]],


        [[[-0.0045, -0.0042, -0.0056],
          [-0.0037, -0.0031, -0.0031],
          [-0.0028, -0.0019, -0.0017]],

         [[-0.0042, -0.0053, -0.0082],
          [-0.0027, -0.0029, -0.0046],
          [-0.0015, -0.0008, -0.0022]],

         [[-0.0045, -0.0054, -0.0075],
          [-0.0034, -0.0035, -0.0048],
          [-0.0021, -0.0015, -0.0029]]]], device='cuda:0')

percentage_weight tensor([0.], device='cuda:0')

percentage_weight_grad tensor([-24.8450], device='cuda:0')

False Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True _Gate(
  (sig): Sigmoid()
)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True _Gate(
  (sig): Sigmoid()
)
False Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True _Gate(
  (sig): Sigmoid()
)
False Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True _Gate(
  (sig): Sigmoid()
)
False Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True _Gate(
  (sig): Sigmoid()
)
False Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True _Gate(
  (sig): Sigmoid()
)
False Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True _Gate(
  (sig): Sigmoid()
)
False Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True _Gate(
  (sig): Sigmoid()
)
False Linear(in_features=512, out_features=10, bias=True)
Epoch: 5 | Batch_idx: 0 |  Loss: (0.8820) | Acc: (71.00%) (92/128)
Epoch: 5 | Batch_idx: 10 |  Loss: (0.9990) | Acc: (66.00%) (934/1408)
Epoch: 5 | Batch_idx: 20 |  Loss: (1.1309) | Acc: (61.00%) (1652/2688)
Epoch: 5 | Batch_idx: 30 |  Loss: (1.2119) | Acc: (58.00%) (2327/3968)
Epoch: 5 | Batch_idx: 40 |  Loss: (1.2401) | Acc: (57.00%) (3035/5248)
Epoch: 5 | Batch_idx: 50 |  Loss: (1.2296) | Acc: (58.00%) (3789/6528)
Epoch: 5 | Batch_idx: 60 |  Loss: (1.2134) | Acc: (58.00%) (4561/7808)
Epoch: 5 | Batch_idx: 70 |  Loss: (1.1985) | Acc: (58.00%) (5327/9088)
Epoch: 5 | Batch_idx: 80 |  Loss: (1.1843) | Acc: (59.00%) (6122/10368)
Epoch: 5 | Batch_idx: 90 |  Loss: (1.1747) | Acc: (59.00%) (6891/11648)
Epoch: 5 | Batch_idx: 100 |  Loss: (1.1687) | Acc: (59.00%) (7656/12928)
Epoch: 5 | Batch_idx: 110 |  Loss: (1.1574) | Acc: (59.00%) (8468/14208)
Epoch: 5 | Batch_idx: 120 |  Loss: (1.1477) | Acc: (59.00%) (9284/15488)
Epoch: 5 | Batch_idx: 130 |  Loss: (1.1413) | Acc: (60.00%) (10094/16768)
Epoch: 5 | Batch_idx: 140 |  Loss: (1.1330) | Acc: (60.00%) (10909/18048)
Epoch: 5 | Batch_idx: 150 |  Loss: (1.1223) | Acc: (60.00%) (11749/19328)
Epoch: 5 | Batch_idx: 160 |  Loss: (1.1153) | Acc: (60.00%) (12568/20608)
Epoch: 5 | Batch_idx: 170 |  Loss: (1.1066) | Acc: (61.00%) (13402/21888)
Epoch: 5 | Batch_idx: 180 |  Loss: (1.1024) | Acc: (61.00%) (14229/23168)
Epoch: 5 | Batch_idx: 190 |  Loss: (1.0952) | Acc: (61.00%) (15064/24448)
Epoch: 5 | Batch_idx: 200 |  Loss: (1.0855) | Acc: (62.00%) (15954/25728)
Epoch: 5 | Batch_idx: 210 |  Loss: (1.0799) | Acc: (62.00%) (16787/27008)
Epoch: 5 | Batch_idx: 220 |  Loss: (1.0764) | Acc: (62.00%) (17625/28288)
Epoch: 5 | Batch_idx: 230 |  Loss: (1.0733) | Acc: (62.00%) (18445/29568)
Epoch: 5 | Batch_idx: 240 |  Loss: (1.0684) | Acc: (62.00%) (19292/30848)
Epoch: 5 | Batch_idx: 250 |  Loss: (1.0648) | Acc: (62.00%) (20131/32128)
Epoch: 5 | Batch_idx: 260 |  Loss: (1.0595) | Acc: (62.00%) (21006/33408)
Epoch: 5 | Batch_idx: 270 |  Loss: (1.0560) | Acc: (62.00%) (21847/34688)
Epoch: 5 | Batch_idx: 280 |  Loss: (1.0523) | Acc: (63.00%) (22696/35968)
Epoch: 5 | Batch_idx: 290 |  Loss: (1.0489) | Acc: (63.00%) (23546/37248)
Epoch: 5 | Batch_idx: 300 |  Loss: (1.0434) | Acc: (63.00%) (24416/38528)
Epoch: 5 | Batch_idx: 310 |  Loss: (1.0391) | Acc: (63.00%) (25282/39808)
Epoch: 5 | Batch_idx: 320 |  Loss: (1.0360) | Acc: (63.00%) (26131/41088)
Epoch: 5 | Batch_idx: 330 |  Loss: (1.0334) | Acc: (63.00%) (26988/42368)
Epoch: 5 | Batch_idx: 340 |  Loss: (1.0293) | Acc: (63.00%) (27874/43648)
Epoch: 5 | Batch_idx: 350 |  Loss: (1.0251) | Acc: (64.00%) (28754/44928)
Epoch: 5 | Batch_idx: 360 |  Loss: (1.0217) | Acc: (64.00%) (29643/46208)
Epoch: 5 | Batch_idx: 370 |  Loss: (1.0193) | Acc: (64.00%) (30505/47488)
Epoch: 5 | Batch_idx: 380 |  Loss: (1.0165) | Acc: (64.00%) (31388/48768)
Epoch: 5 | Batch_idx: 390 |  Loss: (1.0142) | Acc: (64.00%) (32215/50000)
# TEST : Loss: (0.8949) | Acc: (68.00%) (6837/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-0.1007,  0.0082,  0.0127],
          [ 0.0228,  0.1374, -0.0817],
          [ 0.0559, -0.1029, -0.1590]],

         [[-0.2232,  0.0612,  0.0794],
          [ 0.0443,  0.0473, -0.1075],
          [ 0.0110, -0.1150,  0.0075]],

         [[-0.0407, -0.0804,  0.0770],
          [-0.0726,  0.0919,  0.0108],
          [ 0.0740, -0.0130, -0.1622]]],


        [[[ 0.0169, -0.1023,  0.0052],
          [ 0.0919, -0.1951,  0.0153],
          [-0.0034, -0.0447, -0.0114]],

         [[-0.0456, -0.0938, -0.0783],
          [-0.0290, -0.2433,  0.0059],
          [-0.0183,  0.0371,  0.1107]],

         [[-0.0576, -0.0227,  0.0022],
          [ 0.0862, -0.1543,  0.0032],
          [-0.0279, -0.0514, -0.0413]]],


        [[[ 0.1187, -0.0937,  0.1421],
          [ 0.1614,  0.0650,  0.2047],
          [ 0.0212, -0.0588, -0.1448]],

         [[ 0.2330,  0.0271, -0.0709],
          [ 0.1046,  0.0417, -0.0784],
          [ 0.1471, -0.1521,  0.1305]],

         [[-0.0340,  0.1441, -0.1255],
          [-0.0305, -0.1391,  0.1515],
          [-0.0312,  0.0052, -0.0519]]],


        ...,


        [[[-0.0748,  0.1382, -0.1101],
          [-0.1890, -0.0439, -0.1190],
          [-0.0651,  0.1295, -0.2188]],

         [[ 0.0901,  0.0300,  0.0149],
          [ 0.1087, -0.1881,  0.0294],
          [ 0.0420,  0.1060, -0.1915]],

         [[-0.1202,  0.1925,  0.0518],
          [ 0.1770,  0.0871,  0.0835],
          [ 0.1772,  0.0883, -0.1119]]],


        [[[ 0.0438, -0.1259, -0.0230],
          [ 0.0530, -0.0418,  0.1088],
          [ 0.0522, -0.1586,  0.0306]],

         [[ 0.2201, -0.1150,  0.0694],
          [-0.1305,  0.1180, -0.1128],
          [-0.0026,  0.0931, -0.0577]],

         [[-0.0582, -0.1047,  0.0636],
          [-0.1223, -0.2718, -0.2201],
          [ 0.0457, -0.0627, -0.1448]]],


        [[[-0.0936,  0.0223, -0.1122],
          [ 0.1848,  0.0399, -0.1285],
          [ 0.2107,  0.0024, -0.0293]],

         [[ 0.0995,  0.0582, -0.1614],
          [ 0.0471, -0.0035,  0.0804],
          [-0.0645, -0.0837,  0.1862]],

         [[ 0.0766, -0.1820, -0.0228],
          [ 0.0626,  0.1785,  0.1166],
          [-0.1268, -0.0480, -0.0196]]]], device='cuda:0')

conv1_weight_grad tensor([[[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        ...,


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]]], device='cuda:0')

percentage_weight tensor([0.], device='cuda:0', requires_grad=True)

percentage_weight_grad tensor([-24.7855], device='cuda:0')

Epoch: 6 | Batch_idx: 0 |  Loss: (0.8334) | Acc: (71.00%) (91/128)
Epoch: 6 | Batch_idx: 10 |  Loss: (0.9080) | Acc: (67.00%) (955/1408)
Epoch: 6 | Batch_idx: 20 |  Loss: (0.9182) | Acc: (67.00%) (1803/2688)
Epoch: 6 | Batch_idx: 30 |  Loss: (0.9214) | Acc: (67.00%) (2672/3968)
Epoch: 6 | Batch_idx: 40 |  Loss: (0.9106) | Acc: (68.00%) (3570/5248)
Epoch: 6 | Batch_idx: 50 |  Loss: (0.9219) | Acc: (67.00%) (4424/6528)
Epoch: 6 | Batch_idx: 60 |  Loss: (0.9092) | Acc: (68.00%) (5343/7808)
Epoch: 6 | Batch_idx: 70 |  Loss: (0.9076) | Acc: (68.00%) (6224/9088)
Epoch: 6 | Batch_idx: 80 |  Loss: (0.9046) | Acc: (68.00%) (7093/10368)
Epoch: 6 | Batch_idx: 90 |  Loss: (0.9007) | Acc: (68.00%) (7998/11648)
Epoch: 6 | Batch_idx: 100 |  Loss: (0.9024) | Acc: (68.00%) (8864/12928)
Epoch: 6 | Batch_idx: 110 |  Loss: (0.9016) | Acc: (68.00%) (9737/14208)
Epoch: 6 | Batch_idx: 120 |  Loss: (0.9000) | Acc: (68.00%) (10629/15488)
Epoch: 6 | Batch_idx: 130 |  Loss: (0.9011) | Acc: (68.00%) (11517/16768)
Epoch: 6 | Batch_idx: 140 |  Loss: (0.9016) | Acc: (68.00%) (12392/18048)
Epoch: 6 | Batch_idx: 150 |  Loss: (0.9043) | Acc: (68.00%) (13258/19328)
Epoch: 6 | Batch_idx: 160 |  Loss: (0.9023) | Acc: (68.00%) (14145/20608)
Epoch: 6 | Batch_idx: 170 |  Loss: (0.9012) | Acc: (68.00%) (15026/21888)
Epoch: 6 | Batch_idx: 180 |  Loss: (0.8996) | Acc: (68.00%) (15910/23168)
Epoch: 6 | Batch_idx: 190 |  Loss: (0.8977) | Acc: (68.00%) (16807/24448)
Epoch: 6 | Batch_idx: 200 |  Loss: (0.8969) | Acc: (68.00%) (17683/25728)
Epoch: 6 | Batch_idx: 210 |  Loss: (0.8957) | Acc: (68.00%) (18569/27008)
Epoch: 6 | Batch_idx: 220 |  Loss: (0.8958) | Acc: (68.00%) (19434/28288)
Epoch: 6 | Batch_idx: 230 |  Loss: (0.8961) | Acc: (68.00%) (20316/29568)
Epoch: 6 | Batch_idx: 240 |  Loss: (0.8981) | Acc: (68.00%) (21181/30848)
Epoch: 6 | Batch_idx: 250 |  Loss: (0.8982) | Acc: (68.00%) (22037/32128)
Epoch: 6 | Batch_idx: 260 |  Loss: (0.8976) | Acc: (68.00%) (22912/33408)
Epoch: 6 | Batch_idx: 270 |  Loss: (0.8995) | Acc: (68.00%) (23746/34688)
Epoch: 6 | Batch_idx: 280 |  Loss: (0.8983) | Acc: (68.00%) (24648/35968)
Epoch: 6 | Batch_idx: 290 |  Loss: (0.8981) | Acc: (68.00%) (25539/37248)
Epoch: 6 | Batch_idx: 300 |  Loss: (0.8980) | Acc: (68.00%) (26412/38528)
Epoch: 6 | Batch_idx: 310 |  Loss: (0.8985) | Acc: (68.00%) (27296/39808)
Epoch: 6 | Batch_idx: 320 |  Loss: (0.8979) | Acc: (68.00%) (28169/41088)
Epoch: 6 | Batch_idx: 330 |  Loss: (0.8977) | Acc: (68.00%) (29028/42368)
Epoch: 6 | Batch_idx: 340 |  Loss: (0.8985) | Acc: (68.00%) (29880/43648)
Epoch: 6 | Batch_idx: 350 |  Loss: (0.8981) | Acc: (68.00%) (30757/44928)
Epoch: 6 | Batch_idx: 360 |  Loss: (0.8970) | Acc: (68.00%) (31659/46208)
Epoch: 6 | Batch_idx: 370 |  Loss: (0.8964) | Acc: (68.00%) (32556/47488)
Epoch: 6 | Batch_idx: 380 |  Loss: (0.8946) | Acc: (68.00%) (33466/48768)
Epoch: 6 | Batch_idx: 390 |  Loss: (0.8940) | Acc: (68.00%) (34332/50000)
# TEST : Loss: (0.8748) | Acc: (69.00%) (6901/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-0.0973,  0.0079,  0.0123],
          [ 0.0220,  0.1327, -0.0789],
          [ 0.0541, -0.0995, -0.1536]],

         [[-0.2158,  0.0591,  0.0768],
          [ 0.0428,  0.0457, -0.1038],
          [ 0.0106, -0.1111,  0.0072]],

         [[-0.0394, -0.0777,  0.0744],
          [-0.0701,  0.0888,  0.0104],
          [ 0.0716, -0.0126, -0.1565]]],


        [[[ 0.0163, -0.0971,  0.0050],
          [ 0.0886, -0.1853,  0.0147],
          [-0.0033, -0.0433, -0.0111]],

         [[-0.0433, -0.0847, -0.0748],
          [-0.0277, -0.2209,  0.0056],
          [-0.0177,  0.0357,  0.1072]],

         [[-0.0544, -0.0206,  0.0021],
          [ 0.0819, -0.1405,  0.0030],
          [-0.0268, -0.0491, -0.0398]]],


        [[[ 0.1169, -0.0924,  0.1402],
          [ 0.1589,  0.0642,  0.2020],
          [ 0.0209, -0.0582, -0.1431]],

         [[ 0.2297,  0.0267, -0.0699],
          [ 0.1031,  0.0411, -0.0773],
          [ 0.1451, -0.1502,  0.1288]],

         [[-0.0337,  0.1425, -0.1240],
          [-0.0302, -0.1376,  0.1497],
          [-0.0309,  0.0052, -0.0512]]],


        ...,


        [[[-0.0747,  0.1380, -0.1100],
          [-0.1887, -0.0438, -0.1188],
          [-0.0650,  0.1293, -0.2185]],

         [[ 0.0899,  0.0300,  0.0149],
          [ 0.1085, -0.1878,  0.0294],
          [ 0.0419,  0.1058, -0.1912]],

         [[-0.1200,  0.1922,  0.0517],
          [ 0.1767,  0.0870,  0.0833],
          [ 0.1769,  0.0882, -0.1117]]],


        [[[ 0.0433, -0.1245, -0.0227],
          [ 0.0524, -0.0414,  0.1075],
          [ 0.0517, -0.1570,  0.0303]],

         [[ 0.2174, -0.1134,  0.0685],
          [-0.1287,  0.1163, -0.1111],
          [-0.0026,  0.0919, -0.0569]],

         [[-0.0571, -0.1017,  0.0621],
          [-0.1192, -0.2580, -0.2103],
          [ 0.0447, -0.0607, -0.1407]]],


        [[[-0.0915,  0.0218, -0.1096],
          [ 0.1796,  0.0389, -0.1256],
          [ 0.2051,  0.0023, -0.0286]],

         [[ 0.0973,  0.0568, -0.1579],
          [ 0.0459, -0.0034,  0.0786],
          [-0.0628, -0.0817,  0.1822]],

         [[ 0.0750, -0.1780, -0.0223],
          [ 0.0611,  0.1743,  0.1141],
          [-0.1239, -0.0470, -0.0192]]]], device='cuda:0')

conv1_weight_grad tensor([[[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        ...,


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]]], device='cuda:0')

percentage_weight tensor([0.], device='cuda:0', requires_grad=True)

percentage_weight_grad tensor([-26.5406], device='cuda:0')

True Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False _Gate(
  (sig): Sigmoid()
)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False _Gate(
  (sig): Sigmoid()
)
True Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False _Gate(
  (sig): Sigmoid()
)
True Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False _Gate(
  (sig): Sigmoid()
)
True Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False _Gate(
  (sig): Sigmoid()
)
True Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False _Gate(
  (sig): Sigmoid()
)
True Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False _Gate(
  (sig): Sigmoid()
)
True Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False _Gate(
  (sig): Sigmoid()
)
True Linear(in_features=512, out_features=10, bias=True)
Epoch: 7 | Batch_idx: 0 |  Loss: (0.8902) | Acc: (71.00%) (91/128)
Epoch: 7 | Batch_idx: 10 |  Loss: (1.0827) | Acc: (60.00%) (846/1408)
Epoch: 7 | Batch_idx: 20 |  Loss: (1.0772) | Acc: (60.00%) (1617/2688)
Epoch: 7 | Batch_idx: 30 |  Loss: (1.0694) | Acc: (60.00%) (2418/3968)
Epoch: 7 | Batch_idx: 40 |  Loss: (1.0501) | Acc: (61.00%) (3244/5248)
Epoch: 7 | Batch_idx: 50 |  Loss: (1.0497) | Acc: (61.00%) (4039/6528)
Epoch: 7 | Batch_idx: 60 |  Loss: (1.0334) | Acc: (62.00%) (4892/7808)
Epoch: 7 | Batch_idx: 70 |  Loss: (1.0242) | Acc: (63.00%) (5726/9088)
Epoch: 7 | Batch_idx: 80 |  Loss: (1.0179) | Acc: (63.00%) (6566/10368)
Epoch: 7 | Batch_idx: 90 |  Loss: (1.0033) | Acc: (64.00%) (7467/11648)
Epoch: 7 | Batch_idx: 100 |  Loss: (0.9963) | Acc: (64.00%) (8336/12928)
Epoch: 7 | Batch_idx: 110 |  Loss: (0.9916) | Acc: (64.00%) (9190/14208)
Epoch: 7 | Batch_idx: 120 |  Loss: (0.9868) | Acc: (64.00%) (10049/15488)
Epoch: 7 | Batch_idx: 130 |  Loss: (0.9855) | Acc: (65.00%) (10905/16768)
Epoch: 7 | Batch_idx: 140 |  Loss: (0.9831) | Acc: (65.00%) (11747/18048)
Epoch: 7 | Batch_idx: 150 |  Loss: (0.9769) | Acc: (65.00%) (12618/19328)
Epoch: 7 | Batch_idx: 160 |  Loss: (0.9690) | Acc: (65.00%) (13517/20608)
Epoch: 7 | Batch_idx: 170 |  Loss: (0.9654) | Acc: (65.00%) (14385/21888)
Epoch: 7 | Batch_idx: 180 |  Loss: (0.9595) | Acc: (65.00%) (15274/23168)
Epoch: 7 | Batch_idx: 190 |  Loss: (0.9542) | Acc: (66.00%) (16143/24448)
Epoch: 7 | Batch_idx: 200 |  Loss: (0.9552) | Acc: (66.00%) (16996/25728)
Epoch: 7 | Batch_idx: 210 |  Loss: (0.9546) | Acc: (66.00%) (17849/27008)
Epoch: 7 | Batch_idx: 220 |  Loss: (0.9506) | Acc: (66.00%) (18728/28288)
Epoch: 7 | Batch_idx: 230 |  Loss: (0.9462) | Acc: (66.00%) (19643/29568)
Epoch: 7 | Batch_idx: 240 |  Loss: (0.9410) | Acc: (66.00%) (20547/30848)
Epoch: 7 | Batch_idx: 250 |  Loss: (0.9375) | Acc: (66.00%) (21460/32128)
Epoch: 7 | Batch_idx: 260 |  Loss: (0.9350) | Acc: (66.00%) (22349/33408)
Epoch: 7 | Batch_idx: 270 |  Loss: (0.9330) | Acc: (66.00%) (23222/34688)
Epoch: 7 | Batch_idx: 280 |  Loss: (0.9281) | Acc: (67.00%) (24143/35968)
Epoch: 7 | Batch_idx: 290 |  Loss: (0.9240) | Acc: (67.00%) (25061/37248)
Epoch: 7 | Batch_idx: 300 |  Loss: (0.9183) | Acc: (67.00%) (26004/38528)
Epoch: 7 | Batch_idx: 310 |  Loss: (0.9159) | Acc: (67.00%) (26918/39808)
Epoch: 7 | Batch_idx: 320 |  Loss: (0.9124) | Acc: (67.00%) (27827/41088)
Epoch: 7 | Batch_idx: 330 |  Loss: (0.9085) | Acc: (67.00%) (28754/42368)
Epoch: 7 | Batch_idx: 340 |  Loss: (0.9046) | Acc: (68.00%) (29685/43648)
Epoch: 7 | Batch_idx: 350 |  Loss: (0.9005) | Acc: (68.00%) (30619/44928)
Epoch: 7 | Batch_idx: 360 |  Loss: (0.8978) | Acc: (68.00%) (31541/46208)
Epoch: 7 | Batch_idx: 370 |  Loss: (0.8944) | Acc: (68.00%) (32475/47488)
Epoch: 7 | Batch_idx: 380 |  Loss: (0.8924) | Acc: (68.00%) (33408/48768)
Epoch: 7 | Batch_idx: 390 |  Loss: (0.8883) | Acc: (68.00%) (34330/50000)
# TEST : Loss: (0.8678) | Acc: (70.00%) (7052/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-0.0857,  0.0290,  0.0325],
          [ 0.0374,  0.1507, -0.0656],
          [ 0.0649, -0.0851, -0.1426]],

         [[-0.1944,  0.0800,  0.0931],
          [ 0.0614,  0.0676, -0.0912],
          [ 0.0245, -0.0963,  0.0103]],

         [[-0.0295, -0.0584,  0.0862],
          [-0.0493,  0.1050,  0.0181],
          [ 0.0839, -0.0013, -0.1423]]],


        [[[ 0.0416, -0.0726,  0.0230],
          [ 0.0741, -0.1910,  0.0248],
          [-0.0022, -0.0368,  0.0211]],

         [[-0.0339, -0.1019, -0.0793],
          [-0.0449, -0.2642, -0.0014],
          [-0.0191,  0.0276,  0.1252]],

         [[-0.0201, -0.0036,  0.0168],
          [ 0.0784, -0.1529,  0.0129],
          [-0.0302, -0.0603, -0.0188]]],


        [[[ 0.1091, -0.0942,  0.1389],
          [ 0.1507,  0.0603,  0.2013],
          [ 0.0161, -0.0581, -0.1399]],

         [[ 0.2319,  0.0320, -0.0629],
          [ 0.1075,  0.0477, -0.0660],
          [ 0.1482, -0.1400,  0.1358]],

         [[-0.0385,  0.1342, -0.1312],
          [-0.0385, -0.1447,  0.1395],
          [-0.0407, -0.0022, -0.0566]]],


        ...,


        [[[-0.0785,  0.1323, -0.1145],
          [-0.1953, -0.0522, -0.1267],
          [-0.0740,  0.1201, -0.2261]],

         [[ 0.0927,  0.0318,  0.0137],
          [ 0.1142, -0.1822,  0.0308],
          [ 0.0441,  0.1096, -0.1897]],

         [[-0.1202,  0.1943,  0.0497],
          [ 0.1824,  0.0968,  0.0877],
          [ 0.1789,  0.0946, -0.1095]]],


        [[[ 0.0356, -0.1397, -0.0315],
          [ 0.0453, -0.0585,  0.0933],
          [ 0.0570, -0.1582,  0.0284]],

         [[ 0.1954, -0.1446,  0.0460],
          [-0.1360,  0.0922, -0.1263],
          [ 0.0071,  0.0910, -0.0554]],

         [[-0.0536, -0.1219,  0.0582],
          [-0.1161, -0.3080, -0.2310],
          [ 0.0524, -0.0735, -0.1428]]],


        [[[-0.0812,  0.0049, -0.1291],
          [ 0.1878,  0.0189, -0.1522],
          [ 0.2091, -0.0074, -0.0409]],

         [[ 0.1000,  0.0422, -0.1675],
          [ 0.0519, -0.0183,  0.0591],
          [-0.0591, -0.0895,  0.1741]],

         [[ 0.0783, -0.1814, -0.0279],
          [ 0.0615,  0.1615,  0.1007],
          [-0.1285, -0.0576, -0.0230]]]], device='cuda:0', requires_grad=True)

conv1_weight_grad tensor([[[[ 7.0964e-04, -4.2304e-04, -1.3319e-03],
          [-2.5151e-04, -5.5269e-04, -8.4083e-04],
          [-2.2154e-03, -2.1203e-03, -2.2475e-03]],

         [[ 5.5458e-04, -5.3029e-04, -1.4796e-03],
          [-5.1277e-04, -7.9462e-04, -1.2162e-03],
          [-2.4447e-03, -2.3829e-03, -2.4148e-03]],

         [[ 2.7045e-04, -7.8636e-04, -1.5782e-03],
          [-9.3521e-04, -1.2130e-03, -1.3909e-03],
          [-2.5840e-03, -2.4944e-03, -2.3031e-03]]],


        [[[ 2.4804e-03,  2.0949e-03,  2.0525e-03],
          [ 1.6714e-03,  7.8327e-06,  1.3059e-03],
          [-1.4882e-03, -2.9491e-03, -1.8606e-03]],

         [[-2.0339e-04,  8.0475e-04,  1.5742e-03],
          [ 3.6621e-04, -3.4723e-04,  1.0971e-03],
          [-2.1255e-03, -3.4468e-03, -2.2645e-03]],

         [[-4.1902e-04,  5.8491e-04,  1.2090e-03],
          [ 7.5323e-04,  2.9136e-04,  1.6112e-03],
          [-9.6606e-04, -1.9177e-03, -9.2271e-04]]],


        [[[-1.1884e-04, -2.9176e-04, -2.0908e-04],
          [-5.4883e-04, -1.2159e-03, -1.6601e-03],
          [-3.1363e-03, -4.2968e-03, -4.3576e-03]],

         [[-1.0564e-04, -1.8800e-04, -1.1035e-04],
          [-4.4513e-04, -1.1261e-03, -1.6990e-03],
          [-3.0809e-03, -4.3468e-03, -4.5859e-03]],

         [[ 3.9858e-04,  5.3234e-04,  5.4347e-04],
          [ 2.6208e-04, -1.7489e-04, -7.7017e-04],
          [-2.1634e-03, -3.1655e-03, -3.4030e-03]]],


        ...,


        [[[ 2.5392e-02,  1.8559e-02,  1.8643e-02],
          [ 2.7634e-02,  1.6854e-02,  2.1591e-02],
          [ 2.5471e-02,  2.3260e-02,  2.4742e-02]],

         [[ 2.3477e-02,  1.6660e-02,  1.6901e-02],
          [ 2.3337e-02,  1.5251e-02,  2.1717e-02],
          [ 1.9453e-02,  2.0983e-02,  2.4845e-02]],

         [[ 2.3963e-02,  2.2110e-02,  2.4554e-02],
          [ 2.3994e-02,  1.9049e-02,  2.5261e-02],
          [ 1.7130e-02,  1.8905e-02,  2.2279e-02]]],


        [[[ 7.0248e-03,  5.4463e-03,  6.5654e-03],
          [ 2.4512e-03, -5.3605e-04,  2.7611e-03],
          [-2.3314e-03, -4.6890e-03, -1.1890e-03]],

         [[ 4.6524e-03,  4.6751e-03,  7.1126e-03],
          [ 1.8060e-03, -9.1301e-04,  1.9368e-03],
          [-3.2691e-03, -6.8120e-03, -4.2256e-03]],

         [[ 1.9232e-03,  1.6589e-03,  3.7995e-03],
          [ 1.2817e-03, -1.0131e-03,  1.6122e-03],
          [-1.2971e-03, -3.7594e-03, -1.6122e-03]]],


        [[[ 3.3024e-03,  1.6930e-03,  3.9992e-04],
          [ 6.0142e-05, -4.5293e-04, -1.1246e-03],
          [-9.6639e-04,  1.7553e-04, -1.0074e-03]],

         [[ 5.2400e-03,  3.3491e-03,  1.9548e-03],
          [ 2.0922e-03,  1.4636e-03,  9.3667e-04],
          [ 1.1216e-03,  2.2776e-03,  1.1222e-03]],

         [[ 5.5678e-03,  3.0165e-03,  1.2085e-03],
          [ 2.8325e-03,  1.7992e-03,  7.2923e-04],
          [ 2.1425e-03,  2.9991e-03,  1.6416e-03]]]], device='cuda:0')

percentage_weight tensor([0.], device='cuda:0')

percentage_weight_grad tensor([-26.5406], device='cuda:0')

Epoch: 8 | Batch_idx: 0 |  Loss: (0.8217) | Acc: (71.00%) (91/128)
Epoch: 8 | Batch_idx: 10 |  Loss: (0.7838) | Acc: (73.00%) (1030/1408)
Epoch: 8 | Batch_idx: 20 |  Loss: (0.7645) | Acc: (72.00%) (1958/2688)
Epoch: 8 | Batch_idx: 30 |  Loss: (0.7687) | Acc: (72.00%) (2884/3968)
Epoch: 8 | Batch_idx: 40 |  Loss: (0.7640) | Acc: (73.00%) (3836/5248)
Epoch: 8 | Batch_idx: 50 |  Loss: (0.7570) | Acc: (73.00%) (4789/6528)
Epoch: 8 | Batch_idx: 60 |  Loss: (0.7459) | Acc: (73.00%) (5772/7808)
Epoch: 8 | Batch_idx: 70 |  Loss: (0.7490) | Acc: (73.00%) (6690/9088)
Epoch: 8 | Batch_idx: 80 |  Loss: (0.7462) | Acc: (73.00%) (7644/10368)
Epoch: 8 | Batch_idx: 90 |  Loss: (0.7489) | Acc: (73.00%) (8579/11648)
Epoch: 8 | Batch_idx: 100 |  Loss: (0.7393) | Acc: (73.00%) (9562/12928)
Epoch: 8 | Batch_idx: 110 |  Loss: (0.7375) | Acc: (74.00%) (10514/14208)
Epoch: 8 | Batch_idx: 120 |  Loss: (0.7388) | Acc: (73.00%) (11459/15488)
Epoch: 8 | Batch_idx: 130 |  Loss: (0.7385) | Acc: (73.00%) (12401/16768)
Epoch: 8 | Batch_idx: 140 |  Loss: (0.7338) | Acc: (74.00%) (13384/18048)
Epoch: 8 | Batch_idx: 150 |  Loss: (0.7301) | Acc: (74.00%) (14371/19328)
Epoch: 8 | Batch_idx: 160 |  Loss: (0.7277) | Acc: (74.00%) (15319/20608)
Epoch: 8 | Batch_idx: 170 |  Loss: (0.7264) | Acc: (74.00%) (16287/21888)
Epoch: 8 | Batch_idx: 180 |  Loss: (0.7233) | Acc: (74.00%) (17251/23168)
Epoch: 8 | Batch_idx: 190 |  Loss: (0.7215) | Acc: (74.00%) (18226/24448)
Epoch: 8 | Batch_idx: 200 |  Loss: (0.7191) | Acc: (74.00%) (19209/25728)
Epoch: 8 | Batch_idx: 210 |  Loss: (0.7188) | Acc: (74.00%) (20171/27008)
Epoch: 8 | Batch_idx: 220 |  Loss: (0.7167) | Acc: (74.00%) (21147/28288)
Epoch: 8 | Batch_idx: 230 |  Loss: (0.7149) | Acc: (74.00%) (22121/29568)
Epoch: 8 | Batch_idx: 240 |  Loss: (0.7146) | Acc: (74.00%) (23091/30848)
Epoch: 8 | Batch_idx: 250 |  Loss: (0.7129) | Acc: (74.00%) (24075/32128)
Epoch: 8 | Batch_idx: 260 |  Loss: (0.7121) | Acc: (74.00%) (25047/33408)
Epoch: 8 | Batch_idx: 270 |  Loss: (0.7117) | Acc: (75.00%) (26024/34688)
Epoch: 8 | Batch_idx: 280 |  Loss: (0.7108) | Acc: (75.00%) (27005/35968)
Epoch: 8 | Batch_idx: 290 |  Loss: (0.7097) | Acc: (75.00%) (27976/37248)
Epoch: 8 | Batch_idx: 300 |  Loss: (0.7078) | Acc: (75.00%) (28961/38528)
Epoch: 8 | Batch_idx: 310 |  Loss: (0.7072) | Acc: (75.00%) (29923/39808)
Epoch: 8 | Batch_idx: 320 |  Loss: (0.7049) | Acc: (75.00%) (30928/41088)
Epoch: 8 | Batch_idx: 330 |  Loss: (0.7016) | Acc: (75.00%) (31949/42368)
Epoch: 8 | Batch_idx: 340 |  Loss: (0.6994) | Acc: (75.00%) (32970/43648)
Epoch: 8 | Batch_idx: 350 |  Loss: (0.6980) | Acc: (75.00%) (33952/44928)
Epoch: 8 | Batch_idx: 360 |  Loss: (0.6966) | Acc: (75.00%) (34945/46208)
Epoch: 8 | Batch_idx: 370 |  Loss: (0.6951) | Acc: (75.00%) (35956/47488)
Epoch: 8 | Batch_idx: 380 |  Loss: (0.6948) | Acc: (75.00%) (36932/48768)
Epoch: 8 | Batch_idx: 390 |  Loss: (0.6933) | Acc: (75.00%) (37900/50000)
# TEST : Loss: (0.7808) | Acc: (74.00%) (7437/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-0.0939,  0.0208,  0.0256],
          [ 0.0226,  0.1349, -0.0696],
          [ 0.0522, -0.0914, -0.1423]],

         [[-0.2016,  0.0657,  0.0807],
          [ 0.0431,  0.0517, -0.0958],
          [ 0.0135, -0.1015,  0.0056]],

         [[-0.0448, -0.0694,  0.0722],
          [-0.0626,  0.0876,  0.0080],
          [ 0.0707, -0.0102, -0.1399]]],


        [[[ 0.0500, -0.0682,  0.0274],
          [ 0.0538, -0.2175,  0.0058],
          [ 0.0027, -0.0294,  0.0254]],

         [[-0.0355, -0.1164, -0.0794],
          [-0.0670, -0.3009, -0.0152],
          [-0.0161,  0.0329,  0.1314]],

         [[-0.0104,  0.0075,  0.0372],
          [ 0.0617, -0.1575,  0.0135],
          [-0.0243, -0.0447, -0.0067]]],


        [[[ 0.0963, -0.1051,  0.1225],
          [ 0.1417,  0.0498,  0.1879],
          [ 0.0097, -0.0661, -0.1453]],

         [[ 0.2401,  0.0392, -0.0585],
          [ 0.1203,  0.0555, -0.0583],
          [ 0.1515, -0.1368,  0.1367]],

         [[-0.0419,  0.1274, -0.1373],
          [-0.0429, -0.1496,  0.1312],
          [-0.0467, -0.0097, -0.0596]]],


        ...,


        [[[-0.0822,  0.1289, -0.1162],
          [-0.2004, -0.0577, -0.1321],
          [-0.0807,  0.1131, -0.2339]],

         [[ 0.0904,  0.0315,  0.0125],
          [ 0.1120, -0.1824,  0.0288],
          [ 0.0384,  0.1064, -0.1952]],

         [[-0.1193,  0.2005,  0.0558],
          [ 0.1820,  0.1031,  0.0937],
          [ 0.1706,  0.0937, -0.1115]]],


        [[[ 0.0369, -0.1383, -0.0279],
          [ 0.0479, -0.0562,  0.0934],
          [ 0.0633, -0.1496,  0.0340]],

         [[ 0.1929, -0.1397,  0.0618],
          [-0.1292,  0.1031, -0.1030],
          [ 0.0204,  0.1124, -0.0240]],

         [[-0.0668, -0.1286,  0.0745],
          [-0.1485, -0.3570, -0.2373],
          [ 0.0279, -0.0898, -0.1370]]],


        [[[-0.0768,  0.0014, -0.1239],
          [ 0.1927,  0.0225, -0.1444],
          [ 0.1991, -0.0119, -0.0419]],

         [[ 0.1034,  0.0441, -0.1543],
          [ 0.0618, -0.0077,  0.0699],
          [-0.0624, -0.0881,  0.1760]],

         [[ 0.0771, -0.1779, -0.0198],
          [ 0.0605,  0.1632,  0.1062],
          [-0.1399, -0.0647, -0.0260]]]], device='cuda:0', requires_grad=True)

conv1_weight_grad tensor([[[[-0.0004, -0.0002, -0.0003],
          [-0.0007, -0.0002, -0.0002],
          [-0.0006, -0.0002, -0.0000]],

         [[-0.0003, -0.0001, -0.0002],
          [-0.0006, -0.0001, -0.0002],
          [-0.0006, -0.0002, -0.0000]],

         [[-0.0003, -0.0001, -0.0003],
          [-0.0006, -0.0002, -0.0002],
          [-0.0006, -0.0002, -0.0001]]],


        [[[ 0.0019,  0.0018,  0.0010],
          [-0.0012,  0.0009,  0.0012],
          [-0.0058, -0.0018, -0.0001]],

         [[ 0.0010,  0.0006,  0.0005],
          [-0.0021, -0.0002,  0.0009],
          [-0.0062, -0.0026, -0.0000]],

         [[ 0.0023,  0.0010,  0.0009],
          [-0.0008,  0.0001,  0.0014],
          [-0.0047, -0.0019,  0.0009]]],


        [[[-0.0008, -0.0001,  0.0003],
          [-0.0004, -0.0005, -0.0005],
          [-0.0001, -0.0006, -0.0003]],

         [[-0.0006,  0.0001,  0.0003],
          [-0.0001, -0.0002, -0.0002],
          [ 0.0001, -0.0003, -0.0002]],

         [[-0.0018, -0.0012, -0.0009],
          [-0.0013, -0.0014, -0.0015],
          [-0.0010, -0.0015, -0.0015]]],


        ...,


        [[[ 0.0813,  0.0898,  0.0961],
          [ 0.0705,  0.0778,  0.0826],
          [ 0.0459,  0.0585,  0.0682]],

         [[ 0.0764,  0.0869,  0.0945],
          [ 0.0676,  0.0755,  0.0810],
          [ 0.0379,  0.0489,  0.0583]],

         [[ 0.0711,  0.0835,  0.0964],
          [ 0.0671,  0.0746,  0.0836],
          [ 0.0408,  0.0502,  0.0614]]],


        [[[ 0.0089,  0.0026,  0.0045],
          [ 0.0042, -0.0003,  0.0027],
          [-0.0018, -0.0034, -0.0006]],

         [[ 0.0074,  0.0021,  0.0055],
          [ 0.0015, -0.0013,  0.0036],
          [-0.0045, -0.0042,  0.0005]],

         [[ 0.0072,  0.0016,  0.0032],
          [ 0.0019, -0.0010,  0.0027],
          [-0.0037, -0.0037,  0.0007]]],


        [[[-0.0022, -0.0017, -0.0010],
          [-0.0013, -0.0013, -0.0000],
          [-0.0029, -0.0023, -0.0009]],

         [[-0.0021, -0.0018, -0.0013],
          [-0.0016, -0.0016, -0.0002],
          [-0.0036, -0.0028, -0.0014]],

         [[-0.0019, -0.0016, -0.0015],
          [-0.0018, -0.0017, -0.0008],
          [-0.0038, -0.0031, -0.0018]]]], device='cuda:0')

percentage_weight tensor([0.], device='cuda:0')

percentage_weight_grad tensor([-26.5406], device='cuda:0')

False Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True _Gate(
  (sig): Sigmoid()
)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True _Gate(
  (sig): Sigmoid()
)
False Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True _Gate(
  (sig): Sigmoid()
)
False Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True _Gate(
  (sig): Sigmoid()
)
False Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True _Gate(
  (sig): Sigmoid()
)
False Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True _Gate(
  (sig): Sigmoid()
)
False Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True _Gate(
  (sig): Sigmoid()
)
False Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True _Gate(
  (sig): Sigmoid()
)
False Linear(in_features=512, out_features=10, bias=True)
Epoch: 9 | Batch_idx: 0 |  Loss: (0.6282) | Acc: (76.00%) (98/128)
Epoch: 9 | Batch_idx: 10 |  Loss: (0.6579) | Acc: (75.00%) (1069/1408)
Epoch: 9 | Batch_idx: 20 |  Loss: (0.7253) | Acc: (74.00%) (1996/2688)
Epoch: 9 | Batch_idx: 30 |  Loss: (0.7682) | Acc: (72.00%) (2889/3968)
Epoch: 9 | Batch_idx: 40 |  Loss: (0.7782) | Acc: (72.00%) (3814/5248)
Epoch: 9 | Batch_idx: 50 |  Loss: (0.7730) | Acc: (72.00%) (4756/6528)
Epoch: 9 | Batch_idx: 60 |  Loss: (0.7726) | Acc: (72.00%) (5690/7808)
Epoch: 9 | Batch_idx: 70 |  Loss: (0.7707) | Acc: (72.00%) (6625/9088)
Epoch: 9 | Batch_idx: 80 |  Loss: (0.7723) | Acc: (72.00%) (7559/10368)
Epoch: 9 | Batch_idx: 90 |  Loss: (0.7653) | Acc: (73.00%) (8534/11648)
Epoch: 9 | Batch_idx: 100 |  Loss: (0.7571) | Acc: (73.00%) (9504/12928)
Epoch: 9 | Batch_idx: 110 |  Loss: (0.7554) | Acc: (73.00%) (10459/14208)
Epoch: 9 | Batch_idx: 120 |  Loss: (0.7551) | Acc: (73.00%) (11411/15488)
Epoch: 9 | Batch_idx: 130 |  Loss: (0.7529) | Acc: (73.00%) (12375/16768)
Epoch: 9 | Batch_idx: 140 |  Loss: (0.7470) | Acc: (74.00%) (13370/18048)
Epoch: 9 | Batch_idx: 150 |  Loss: (0.7401) | Acc: (74.00%) (14363/19328)
Epoch: 9 | Batch_idx: 160 |  Loss: (0.7379) | Acc: (74.00%) (15336/20608)
Epoch: 9 | Batch_idx: 170 |  Loss: (0.7339) | Acc: (74.00%) (16329/21888)
Epoch: 9 | Batch_idx: 180 |  Loss: (0.7306) | Acc: (74.00%) (17319/23168)
Epoch: 9 | Batch_idx: 190 |  Loss: (0.7287) | Acc: (74.00%) (18290/24448)
Epoch: 9 | Batch_idx: 200 |  Loss: (0.7261) | Acc: (74.00%) (19272/25728)
Epoch: 9 | Batch_idx: 210 |  Loss: (0.7214) | Acc: (75.00%) (20284/27008)
Epoch: 9 | Batch_idx: 220 |  Loss: (0.7181) | Acc: (75.00%) (21288/28288)
Epoch: 9 | Batch_idx: 230 |  Loss: (0.7166) | Acc: (75.00%) (22270/29568)
Epoch: 9 | Batch_idx: 240 |  Loss: (0.7142) | Acc: (75.00%) (23252/30848)
Epoch: 9 | Batch_idx: 250 |  Loss: (0.7116) | Acc: (75.00%) (24247/32128)
Epoch: 9 | Batch_idx: 260 |  Loss: (0.7106) | Acc: (75.00%) (25223/33408)
Epoch: 9 | Batch_idx: 270 |  Loss: (0.7112) | Acc: (75.00%) (26174/34688)
Epoch: 9 | Batch_idx: 280 |  Loss: (0.7100) | Acc: (75.00%) (27163/35968)
Epoch: 9 | Batch_idx: 290 |  Loss: (0.7083) | Acc: (75.00%) (28140/37248)
Epoch: 9 | Batch_idx: 300 |  Loss: (0.7066) | Acc: (75.00%) (29136/38528)
Epoch: 9 | Batch_idx: 310 |  Loss: (0.7047) | Acc: (75.00%) (30148/39808)
Epoch: 9 | Batch_idx: 320 |  Loss: (0.7039) | Acc: (75.00%) (31134/41088)
Epoch: 9 | Batch_idx: 330 |  Loss: (0.7017) | Acc: (75.00%) (32149/42368)
Epoch: 9 | Batch_idx: 340 |  Loss: (0.7012) | Acc: (75.00%) (33131/43648)
Epoch: 9 | Batch_idx: 350 |  Loss: (0.6996) | Acc: (75.00%) (34134/44928)
Epoch: 9 | Batch_idx: 360 |  Loss: (0.6986) | Acc: (76.00%) (35127/46208)
Epoch: 9 | Batch_idx: 370 |  Loss: (0.6967) | Acc: (76.00%) (36117/47488)
Epoch: 9 | Batch_idx: 380 |  Loss: (0.6953) | Acc: (76.00%) (37115/48768)
Epoch: 9 | Batch_idx: 390 |  Loss: (0.6938) | Acc: (76.00%) (38084/50000)
# TEST : Loss: (0.6511) | Acc: (78.00%) (7818/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-0.0894,  0.0196,  0.0243],
          [ 0.0223,  0.1288, -0.0659],
          [ 0.0508, -0.0864, -0.1347]],

         [[-0.1917,  0.0621,  0.0767],
          [ 0.0416,  0.0494, -0.0908],
          [ 0.0138, -0.0960,  0.0055]],

         [[-0.0426, -0.0665,  0.0685],
          [-0.0589,  0.0834,  0.0076],
          [ 0.0682, -0.0092, -0.1320]]],


        [[[ 0.0430, -0.0737,  0.0227],
          [ 0.0533, -0.2100,  0.0057],
          [ 0.0048, -0.0293,  0.0237]],

         [[-0.0401, -0.1187, -0.0808],
          [-0.0633, -0.2810, -0.0139],
          [-0.0132,  0.0322,  0.1277]],

         [[-0.0170,  0.0001,  0.0327],
          [ 0.0606, -0.1484,  0.0135],
          [-0.0215, -0.0436, -0.0082]]],


        [[[ 0.0940, -0.1028,  0.1198],
          [ 0.1377,  0.0489,  0.1843],
          [ 0.0086, -0.0652, -0.1432]],

         [[ 0.2353,  0.0385, -0.0573],
          [ 0.1177,  0.0547, -0.0568],
          [ 0.1477, -0.1346,  0.1341]],

         [[-0.0411,  0.1258, -0.1352],
          [-0.0422, -0.1471,  0.1299],
          [-0.0463, -0.0094, -0.0586]]],


        ...,


        [[[-0.0846,  0.1262, -0.1190],
          [-0.2018, -0.0594, -0.1342],
          [-0.0814,  0.1120, -0.2350]],

         [[ 0.0877,  0.0287,  0.0093],
          [ 0.1099, -0.1843,  0.0262],
          [ 0.0374,  0.1053, -0.1963]],

         [[-0.1210,  0.1977,  0.0526],
          [ 0.1803,  0.1013,  0.0913],
          [ 0.1700,  0.0931, -0.1124]]],


        [[[ 0.0311, -0.1401, -0.0313],
          [ 0.0445, -0.0565,  0.0908],
          [ 0.0596, -0.1505,  0.0303]],

         [[ 0.1864, -0.1401,  0.0584],
          [-0.1292,  0.1031, -0.1028],
          [ 0.0184,  0.1105, -0.0268]],

         [[-0.0729, -0.1287,  0.0690],
          [-0.1480, -0.3370, -0.2327],
          [ 0.0254, -0.0891, -0.1403]]],


        [[[-0.0750,  0.0015, -0.1215],
          [ 0.1869,  0.0230, -0.1400],
          [ 0.1951, -0.0100, -0.0389]],

         [[ 0.1019,  0.0436, -0.1511],
          [ 0.0618, -0.0054,  0.0707],
          [-0.0581, -0.0835,  0.1756]],

         [[ 0.0757, -0.1750, -0.0201],
          [ 0.0603,  0.1612,  0.1053],
          [-0.1353, -0.0613, -0.0237]]]], device='cuda:0')

conv1_weight_grad tensor([[[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        ...,


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]]], device='cuda:0')

percentage_weight tensor([0.], device='cuda:0', requires_grad=True)

percentage_weight_grad tensor([-23.2699], device='cuda:0')

Epoch: 10 | Batch_idx: 0 |  Loss: (0.5411) | Acc: (85.00%) (109/128)
Epoch: 10 | Batch_idx: 10 |  Loss: (0.6346) | Acc: (78.00%) (1105/1408)
Epoch: 10 | Batch_idx: 20 |  Loss: (0.6247) | Acc: (78.00%) (2121/2688)
Epoch: 10 | Batch_idx: 30 |  Loss: (0.6174) | Acc: (79.00%) (3146/3968)
Epoch: 10 | Batch_idx: 40 |  Loss: (0.6177) | Acc: (79.00%) (4160/5248)
Epoch: 10 | Batch_idx: 50 |  Loss: (0.6230) | Acc: (79.00%) (5161/6528)
Epoch: 10 | Batch_idx: 60 |  Loss: (0.6289) | Acc: (78.00%) (6149/7808)
Epoch: 10 | Batch_idx: 70 |  Loss: (0.6217) | Acc: (78.00%) (7178/9088)
Epoch: 10 | Batch_idx: 80 |  Loss: (0.6273) | Acc: (78.00%) (8163/10368)
Epoch: 10 | Batch_idx: 90 |  Loss: (0.6284) | Acc: (78.00%) (9158/11648)
Epoch: 10 | Batch_idx: 100 |  Loss: (0.6260) | Acc: (78.00%) (10195/12928)
Epoch: 10 | Batch_idx: 110 |  Loss: (0.6266) | Acc: (78.00%) (11195/14208)
Epoch: 10 | Batch_idx: 120 |  Loss: (0.6303) | Acc: (78.00%) (12198/15488)
Epoch: 10 | Batch_idx: 130 |  Loss: (0.6308) | Acc: (78.00%) (13178/16768)
Epoch: 10 | Batch_idx: 140 |  Loss: (0.6275) | Acc: (78.00%) (14199/18048)
Epoch: 10 | Batch_idx: 150 |  Loss: (0.6295) | Acc: (78.00%) (15190/19328)
Epoch: 10 | Batch_idx: 160 |  Loss: (0.6309) | Acc: (78.00%) (16186/20608)
Epoch: 10 | Batch_idx: 170 |  Loss: (0.6312) | Acc: (78.00%) (17190/21888)
Epoch: 10 | Batch_idx: 180 |  Loss: (0.6338) | Acc: (78.00%) (18179/23168)
Epoch: 10 | Batch_idx: 190 |  Loss: (0.6333) | Acc: (78.00%) (19167/24448)
Epoch: 10 | Batch_idx: 200 |  Loss: (0.6351) | Acc: (78.00%) (20162/25728)
Epoch: 10 | Batch_idx: 210 |  Loss: (0.6333) | Acc: (78.00%) (21177/27008)
Epoch: 10 | Batch_idx: 220 |  Loss: (0.6316) | Acc: (78.00%) (22203/28288)
Epoch: 10 | Batch_idx: 230 |  Loss: (0.6326) | Acc: (78.00%) (23185/29568)
Epoch: 10 | Batch_idx: 240 |  Loss: (0.6339) | Acc: (78.00%) (24181/30848)
Epoch: 10 | Batch_idx: 250 |  Loss: (0.6340) | Acc: (78.00%) (25193/32128)
Epoch: 10 | Batch_idx: 260 |  Loss: (0.6341) | Acc: (78.00%) (26197/33408)
Epoch: 10 | Batch_idx: 270 |  Loss: (0.6343) | Acc: (78.00%) (27205/34688)
Epoch: 10 | Batch_idx: 280 |  Loss: (0.6332) | Acc: (78.00%) (28226/35968)
Epoch: 10 | Batch_idx: 290 |  Loss: (0.6323) | Acc: (78.00%) (29249/37248)
Epoch: 10 | Batch_idx: 300 |  Loss: (0.6327) | Acc: (78.00%) (30240/38528)
Epoch: 10 | Batch_idx: 310 |  Loss: (0.6325) | Acc: (78.00%) (31261/39808)
Epoch: 10 | Batch_idx: 320 |  Loss: (0.6328) | Acc: (78.00%) (32250/41088)
Epoch: 10 | Batch_idx: 330 |  Loss: (0.6345) | Acc: (78.00%) (33234/42368)
Epoch: 10 | Batch_idx: 340 |  Loss: (0.6358) | Acc: (78.00%) (34208/43648)
Epoch: 10 | Batch_idx: 350 |  Loss: (0.6356) | Acc: (78.00%) (35219/44928)
Epoch: 10 | Batch_idx: 360 |  Loss: (0.6342) | Acc: (78.00%) (36235/46208)
Epoch: 10 | Batch_idx: 370 |  Loss: (0.6333) | Acc: (78.00%) (37246/47488)
Epoch: 10 | Batch_idx: 380 |  Loss: (0.6333) | Acc: (78.00%) (38256/48768)
Epoch: 10 | Batch_idx: 390 |  Loss: (0.6331) | Acc: (78.00%) (39216/50000)
# TEST : Loss: (0.6308) | Acc: (78.00%) (7870/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-0.0840,  0.0184,  0.0229],
          [ 0.0210,  0.1214, -0.0619],
          [ 0.0481, -0.0814, -0.1263]],

         [[-0.1801,  0.0584,  0.0724],
          [ 0.0391,  0.0465, -0.0851],
          [ 0.0130, -0.0902,  0.0051]],

         [[-0.0400, -0.0626,  0.0646],
          [-0.0553,  0.0784,  0.0071],
          [ 0.0644, -0.0087, -0.1232]]],


        [[[ 0.0419, -0.0709,  0.0221],
          [ 0.0518, -0.1997,  0.0055],
          [ 0.0047, -0.0285,  0.0232]],

         [[-0.0389, -0.1130, -0.0786],
          [-0.0613, -0.2607, -0.0135],
          [-0.0129,  0.0312,  0.1249]],

         [[-0.0164,  0.0000,  0.0317],
          [ 0.0585, -0.1388,  0.0130],
          [-0.0209, -0.0422, -0.0080]]],


        [[[ 0.0910, -0.0999,  0.1168],
          [ 0.1334,  0.0476,  0.1797],
          [ 0.0084, -0.0639, -0.1403]],

         [[ 0.2292,  0.0375, -0.0559],
          [ 0.1145,  0.0532, -0.0554],
          [ 0.1442, -0.1317,  0.1313]],

         [[-0.0405,  0.1237, -0.1328],
          [-0.0415, -0.1446,  0.1276],
          [-0.0455, -0.0093, -0.0575]]],


        ...,


        [[[-0.0844,  0.1260, -0.1188],
          [-0.2015, -0.0594, -0.1340],
          [-0.0813,  0.1119, -0.2346]],

         [[ 0.0876,  0.0286,  0.0093],
          [ 0.1097, -0.1840,  0.0262],
          [ 0.0374,  0.1052, -0.1960]],

         [[-0.1208,  0.1973,  0.0525],
          [ 0.1800,  0.1011,  0.0911],
          [ 0.1697,  0.0930, -0.1122]]],


        [[[ 0.0308, -0.1387, -0.0310],
          [ 0.0441, -0.0559,  0.0898],
          [ 0.0591, -0.1490,  0.0300]],

         [[ 0.1843, -0.1384,  0.0577],
          [-0.1277,  0.1019, -0.1016],
          [ 0.0182,  0.1093, -0.0265]],

         [[-0.0716, -0.1250,  0.0674],
          [-0.1445, -0.3190, -0.2239],
          [ 0.0249, -0.0867, -0.1370]]],


        [[[-0.0730,  0.0014, -0.1187],
          [ 0.1801,  0.0223, -0.1367],
          [ 0.1889, -0.0098, -0.0380]],

         [[ 0.0993,  0.0426, -0.1477],
          [ 0.0598, -0.0053,  0.0691],
          [-0.0564, -0.0814,  0.1716]],

         [[ 0.0739, -0.1709, -0.0197],
          [ 0.0587,  0.1572,  0.1029],
          [-0.1321, -0.0599, -0.0232]]]], device='cuda:0')

conv1_weight_grad tensor([[[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        ...,


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]]], device='cuda:0')

percentage_weight tensor([0.], device='cuda:0', requires_grad=True)

percentage_weight_grad tensor([-24.0159], device='cuda:0')

True Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False _Gate(
  (sig): Sigmoid()
)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False _Gate(
  (sig): Sigmoid()
)
True Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False _Gate(
  (sig): Sigmoid()
)
True Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False _Gate(
  (sig): Sigmoid()
)
True Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False _Gate(
  (sig): Sigmoid()
)
True Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False _Gate(
  (sig): Sigmoid()
)
True Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False _Gate(
  (sig): Sigmoid()
)
True Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False _Gate(
  (sig): Sigmoid()
)
True Linear(in_features=512, out_features=10, bias=True)
Epoch: 11 | Batch_idx: 0 |  Loss: (0.4605) | Acc: (84.00%) (108/128)
Epoch: 11 | Batch_idx: 10 |  Loss: (0.7351) | Acc: (74.00%) (1054/1408)
Epoch: 11 | Batch_idx: 20 |  Loss: (0.7564) | Acc: (74.00%) (1994/2688)
Epoch: 11 | Batch_idx: 30 |  Loss: (0.7738) | Acc: (73.00%) (2923/3968)
Epoch: 11 | Batch_idx: 40 |  Loss: (0.7831) | Acc: (73.00%) (3867/5248)
Epoch: 11 | Batch_idx: 50 |  Loss: (0.7832) | Acc: (73.00%) (4811/6528)
Epoch: 11 | Batch_idx: 60 |  Loss: (0.7711) | Acc: (73.00%) (5777/7808)
Epoch: 11 | Batch_idx: 70 |  Loss: (0.7617) | Acc: (74.00%) (6743/9088)
Epoch: 11 | Batch_idx: 80 |  Loss: (0.7590) | Acc: (74.00%) (7709/10368)
Epoch: 11 | Batch_idx: 90 |  Loss: (0.7507) | Acc: (74.00%) (8678/11648)
Epoch: 11 | Batch_idx: 100 |  Loss: (0.7494) | Acc: (74.00%) (9622/12928)
Epoch: 11 | Batch_idx: 110 |  Loss: (0.7470) | Acc: (74.00%) (10572/14208)
Epoch: 11 | Batch_idx: 120 |  Loss: (0.7456) | Acc: (74.00%) (11535/15488)
Epoch: 11 | Batch_idx: 130 |  Loss: (0.7389) | Acc: (74.00%) (12511/16768)
Epoch: 11 | Batch_idx: 140 |  Loss: (0.7322) | Acc: (74.00%) (13531/18048)
Epoch: 11 | Batch_idx: 150 |  Loss: (0.7289) | Acc: (75.00%) (14526/19328)
Epoch: 11 | Batch_idx: 160 |  Loss: (0.7284) | Acc: (75.00%) (15502/20608)
Epoch: 11 | Batch_idx: 170 |  Loss: (0.7259) | Acc: (75.00%) (16485/21888)
Epoch: 11 | Batch_idx: 180 |  Loss: (0.7188) | Acc: (75.00%) (17504/23168)
Epoch: 11 | Batch_idx: 190 |  Loss: (0.7169) | Acc: (75.00%) (18487/24448)
Epoch: 11 | Batch_idx: 200 |  Loss: (0.7165) | Acc: (75.00%) (19456/25728)
Epoch: 11 | Batch_idx: 210 |  Loss: (0.7141) | Acc: (75.00%) (20453/27008)
Epoch: 11 | Batch_idx: 220 |  Loss: (0.7111) | Acc: (75.00%) (21452/28288)
Epoch: 11 | Batch_idx: 230 |  Loss: (0.7119) | Acc: (75.00%) (22429/29568)
Epoch: 11 | Batch_idx: 240 |  Loss: (0.7109) | Acc: (75.00%) (23405/30848)
Epoch: 11 | Batch_idx: 250 |  Loss: (0.7087) | Acc: (75.00%) (24402/32128)
Epoch: 11 | Batch_idx: 260 |  Loss: (0.7061) | Acc: (76.00%) (25420/33408)
Epoch: 11 | Batch_idx: 270 |  Loss: (0.7041) | Acc: (76.00%) (26409/34688)
Epoch: 11 | Batch_idx: 280 |  Loss: (0.7023) | Acc: (76.00%) (27406/35968)
Epoch: 11 | Batch_idx: 290 |  Loss: (0.6997) | Acc: (76.00%) (28413/37248)
Epoch: 11 | Batch_idx: 300 |  Loss: (0.6969) | Acc: (76.00%) (29422/38528)
Epoch: 11 | Batch_idx: 310 |  Loss: (0.6960) | Acc: (76.00%) (30396/39808)
Epoch: 11 | Batch_idx: 320 |  Loss: (0.6946) | Acc: (76.00%) (31385/41088)
Epoch: 11 | Batch_idx: 330 |  Loss: (0.6928) | Acc: (76.00%) (32372/42368)
Epoch: 11 | Batch_idx: 340 |  Loss: (0.6908) | Acc: (76.00%) (33369/43648)
Epoch: 11 | Batch_idx: 350 |  Loss: (0.6889) | Acc: (76.00%) (34359/44928)
Epoch: 11 | Batch_idx: 360 |  Loss: (0.6871) | Acc: (76.00%) (35372/46208)
Epoch: 11 | Batch_idx: 370 |  Loss: (0.6853) | Acc: (76.00%) (36377/47488)
Epoch: 11 | Batch_idx: 380 |  Loss: (0.6838) | Acc: (76.00%) (37375/48768)
Epoch: 11 | Batch_idx: 390 |  Loss: (0.6807) | Acc: (76.00%) (38351/50000)
# TEST : Loss: (0.6914) | Acc: (76.00%) (7659/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-0.0813,  0.0162,  0.0186],
          [ 0.0182,  0.1180, -0.0550],
          [ 0.0395, -0.0774, -0.1178]],

         [[-0.1730,  0.0519,  0.0645],
          [ 0.0339,  0.0469, -0.0776],
          [ 0.0087, -0.0824,  0.0071]],

         [[-0.0425, -0.0601,  0.0580],
          [-0.0539,  0.0770,  0.0074],
          [ 0.0564, -0.0067, -0.1132]]],


        [[[ 0.0775, -0.0459,  0.0372],
          [ 0.0644, -0.2019,  0.0039],
          [ 0.0350, -0.0034,  0.0399]],

         [[-0.0223, -0.1108, -0.0759],
          [-0.0709, -0.3078, -0.0290],
          [-0.0002,  0.0349,  0.1266]],

         [[ 0.0085,  0.0097,  0.0426],
          [ 0.0612, -0.1477,  0.0116],
          [-0.0013, -0.0285,  0.0029]]],


        [[[ 0.0640, -0.0944,  0.1193],
          [ 0.1014,  0.0514,  0.1804],
          [ 0.0227, -0.0318, -0.1117]],

         [[ 0.2077,  0.0398, -0.0522],
          [ 0.0859,  0.0490, -0.0590],
          [ 0.1390, -0.1131,  0.1378]],

         [[-0.0783,  0.0918, -0.1605],
          [-0.0904, -0.1807,  0.0882],
          [-0.0878, -0.0374, -0.0837]]],


        ...,


        [[[-0.0859,  0.1223, -0.1204],
          [-0.2082, -0.0685, -0.1378],
          [-0.0875,  0.1056, -0.2361]],

         [[ 0.0865,  0.0330,  0.0157],
          [ 0.1080, -0.1808,  0.0336],
          [ 0.0359,  0.1083, -0.1908]],

         [[-0.1163,  0.2092,  0.0629],
          [ 0.1860,  0.1158,  0.1077],
          [ 0.1737,  0.1051, -0.1012]]],


        [[[ 0.0444, -0.1369, -0.0259],
          [ 0.0563, -0.0605,  0.0868],
          [ 0.0707, -0.1466,  0.0315]],

         [[ 0.1864, -0.1445,  0.0612],
          [-0.1207,  0.0902, -0.1014],
          [ 0.0251,  0.1069, -0.0230]],

         [[-0.0561, -0.1269,  0.0736],
          [-0.1261, -0.3356, -0.2289],
          [ 0.0344, -0.0947, -0.1441]]],


        [[[-0.0622,  0.0127, -0.1167],
          [ 0.1748,  0.0297, -0.1370],
          [ 0.1603, -0.0303, -0.0452]],

         [[ 0.1116,  0.0582, -0.1429],
          [ 0.0791,  0.0201,  0.0746],
          [-0.0593, -0.0821,  0.1754]],

         [[ 0.0840, -0.1546, -0.0183],
          [ 0.0752,  0.1769,  0.1104],
          [-0.1326, -0.0602, -0.0138]]]], device='cuda:0', requires_grad=True)

conv1_weight_grad tensor([[[[-0.0001, -0.0003, -0.0002],
          [-0.0002, -0.0003, -0.0002],
          [-0.0001, -0.0002, -0.0001]],

         [[-0.0001, -0.0003, -0.0002],
          [-0.0001, -0.0003, -0.0002],
          [-0.0000, -0.0001, -0.0001]],

         [[-0.0001, -0.0003, -0.0002],
          [-0.0001, -0.0003, -0.0002],
          [ 0.0000, -0.0001, -0.0001]]],


        [[[-0.0033, -0.0003, -0.0014],
          [-0.0011,  0.0019,  0.0008],
          [ 0.0013,  0.0047,  0.0043]],

         [[-0.0050, -0.0020, -0.0028],
          [-0.0022,  0.0005, -0.0005],
          [ 0.0001,  0.0031,  0.0027]],

         [[-0.0037, -0.0009, -0.0016],
          [-0.0006,  0.0017,  0.0006],
          [ 0.0012,  0.0036,  0.0029]]],


        [[[-0.0070, -0.0067, -0.0075],
          [-0.0064, -0.0056, -0.0064],
          [-0.0047, -0.0043, -0.0040]],

         [[-0.0099, -0.0085, -0.0089],
          [-0.0094, -0.0075, -0.0082],
          [-0.0081, -0.0066, -0.0062]],

         [[-0.0138, -0.0120, -0.0123],
          [-0.0132, -0.0108, -0.0118],
          [-0.0112, -0.0095, -0.0098]]],


        ...,


        [[[ 0.0752,  0.0644,  0.0597],
          [ 0.0921,  0.0804,  0.0750],
          [ 0.0995,  0.0883,  0.0882]],

         [[ 0.0751,  0.0630,  0.0576],
          [ 0.0933,  0.0794,  0.0725],
          [ 0.1018,  0.0903,  0.0903]],

         [[ 0.0674,  0.0597,  0.0575],
          [ 0.0840,  0.0709,  0.0667],
          [ 0.0936,  0.0826,  0.0840]]],


        [[[-0.0052, -0.0022, -0.0041],
          [-0.0040, -0.0015, -0.0042],
          [-0.0038, -0.0010, -0.0031]],

         [[-0.0061, -0.0031, -0.0050],
          [-0.0051, -0.0024, -0.0049],
          [-0.0051, -0.0021, -0.0041]],

         [[-0.0045, -0.0010, -0.0027],
          [-0.0028,  0.0005, -0.0015],
          [-0.0032, -0.0001, -0.0018]]],


        [[[-0.0020, -0.0025, -0.0041],
          [ 0.0004,  0.0004, -0.0002],
          [-0.0013, -0.0007, -0.0001]],

         [[-0.0066, -0.0069, -0.0080],
          [-0.0040, -0.0040, -0.0044],
          [-0.0056, -0.0050, -0.0044]],

         [[-0.0071, -0.0072, -0.0082],
          [-0.0050, -0.0049, -0.0050],
          [-0.0065, -0.0059, -0.0053]]]], device='cuda:0')

percentage_weight tensor([0.], device='cuda:0')

percentage_weight_grad tensor([-24.0159], device='cuda:0')

Epoch: 12 | Batch_idx: 0 |  Loss: (0.7323) | Acc: (75.00%) (96/128)
Epoch: 12 | Batch_idx: 10 |  Loss: (0.6354) | Acc: (79.00%) (1114/1408)
Epoch: 12 | Batch_idx: 20 |  Loss: (0.6139) | Acc: (79.00%) (2147/2688)
Epoch: 12 | Batch_idx: 30 |  Loss: (0.6087) | Acc: (79.00%) (3154/3968)
Epoch: 12 | Batch_idx: 40 |  Loss: (0.6195) | Acc: (78.00%) (4142/5248)
Epoch: 12 | Batch_idx: 50 |  Loss: (0.6216) | Acc: (78.00%) (5139/6528)
Epoch: 12 | Batch_idx: 60 |  Loss: (0.6137) | Acc: (78.00%) (6150/7808)
Epoch: 12 | Batch_idx: 70 |  Loss: (0.6090) | Acc: (78.00%) (7172/9088)
Epoch: 12 | Batch_idx: 80 |  Loss: (0.6019) | Acc: (79.00%) (8212/10368)
Epoch: 12 | Batch_idx: 90 |  Loss: (0.5998) | Acc: (79.00%) (9229/11648)
Epoch: 12 | Batch_idx: 100 |  Loss: (0.5990) | Acc: (79.00%) (10262/12928)
Epoch: 12 | Batch_idx: 110 |  Loss: (0.5978) | Acc: (79.00%) (11279/14208)
Epoch: 12 | Batch_idx: 120 |  Loss: (0.5990) | Acc: (79.00%) (12305/15488)
Epoch: 12 | Batch_idx: 130 |  Loss: (0.5949) | Acc: (79.00%) (13346/16768)
Epoch: 12 | Batch_idx: 140 |  Loss: (0.5918) | Acc: (79.00%) (14378/18048)
Epoch: 12 | Batch_idx: 150 |  Loss: (0.5923) | Acc: (79.00%) (15386/19328)
Epoch: 12 | Batch_idx: 160 |  Loss: (0.5918) | Acc: (79.00%) (16418/20608)
Epoch: 12 | Batch_idx: 170 |  Loss: (0.5900) | Acc: (79.00%) (17462/21888)
Epoch: 12 | Batch_idx: 180 |  Loss: (0.5865) | Acc: (79.00%) (18509/23168)
Epoch: 12 | Batch_idx: 190 |  Loss: (0.5843) | Acc: (79.00%) (19548/24448)
Epoch: 12 | Batch_idx: 200 |  Loss: (0.5827) | Acc: (80.00%) (20587/25728)
Epoch: 12 | Batch_idx: 210 |  Loss: (0.5834) | Acc: (79.00%) (21593/27008)
Epoch: 12 | Batch_idx: 220 |  Loss: (0.5823) | Acc: (80.00%) (22635/28288)
Epoch: 12 | Batch_idx: 230 |  Loss: (0.5810) | Acc: (80.00%) (23684/29568)
Epoch: 12 | Batch_idx: 240 |  Loss: (0.5793) | Acc: (80.00%) (24718/30848)
Epoch: 12 | Batch_idx: 250 |  Loss: (0.5773) | Acc: (80.00%) (25773/32128)
Epoch: 12 | Batch_idx: 260 |  Loss: (0.5754) | Acc: (80.00%) (26815/33408)
Epoch: 12 | Batch_idx: 270 |  Loss: (0.5732) | Acc: (80.00%) (27873/34688)
Epoch: 12 | Batch_idx: 280 |  Loss: (0.5704) | Acc: (80.00%) (28930/35968)
Epoch: 12 | Batch_idx: 290 |  Loss: (0.5701) | Acc: (80.00%) (29977/37248)
Epoch: 12 | Batch_idx: 300 |  Loss: (0.5698) | Acc: (80.00%) (31013/38528)
Epoch: 12 | Batch_idx: 310 |  Loss: (0.5671) | Acc: (80.00%) (32087/39808)
Epoch: 12 | Batch_idx: 320 |  Loss: (0.5658) | Acc: (80.00%) (33133/41088)
Epoch: 12 | Batch_idx: 330 |  Loss: (0.5651) | Acc: (80.00%) (34174/42368)
Epoch: 12 | Batch_idx: 340 |  Loss: (0.5646) | Acc: (80.00%) (35209/43648)
Epoch: 12 | Batch_idx: 350 |  Loss: (0.5637) | Acc: (80.00%) (36250/44928)
Epoch: 12 | Batch_idx: 360 |  Loss: (0.5635) | Acc: (80.00%) (37286/46208)
Epoch: 12 | Batch_idx: 370 |  Loss: (0.5627) | Acc: (80.00%) (38317/47488)
Epoch: 12 | Batch_idx: 380 |  Loss: (0.5623) | Acc: (80.00%) (39349/48768)
Epoch: 12 | Batch_idx: 390 |  Loss: (0.5617) | Acc: (80.00%) (40347/50000)
# TEST : Loss: (0.7878) | Acc: (74.00%) (7449/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-0.0819,  0.0063,  0.0120],
          [ 0.0162,  0.1044, -0.0560],
          [ 0.0492, -0.0659, -0.1094]],

         [[-0.1639,  0.0408,  0.0573],
          [ 0.0325,  0.0372, -0.0769],
          [ 0.0223, -0.0713,  0.0046]],

         [[-0.0415, -0.0603,  0.0529],
          [-0.0475,  0.0662,  0.0020],
          [ 0.0654, -0.0026, -0.1060]]],


        [[[ 0.0860, -0.0481,  0.0403],
          [ 0.0602, -0.2195, -0.0092],
          [ 0.0273, -0.0099,  0.0316]],

         [[-0.0213, -0.1163, -0.0651],
          [-0.0852, -0.3404, -0.0385],
          [-0.0246,  0.0127,  0.1087]],

         [[ 0.0201,  0.0251,  0.0747],
          [ 0.0601, -0.1398,  0.0325],
          [-0.0167, -0.0376,  0.0057]]],


        [[[ 0.0982, -0.0716,  0.1181],
          [ 0.1230,  0.0631,  0.1806],
          [ 0.0183, -0.0444, -0.1239]],

         [[ 0.2361,  0.0594, -0.0466],
          [ 0.1085,  0.0614, -0.0511],
          [ 0.1376, -0.1224,  0.1215]],

         [[-0.0529,  0.1097, -0.1442],
          [-0.0739, -0.1673,  0.0974],
          [-0.0801, -0.0369, -0.0805]]],


        ...,


        [[[-0.0910,  0.1209, -0.1211],
          [-0.2098, -0.0678, -0.1355],
          [-0.0887,  0.1070, -0.2344]],

         [[ 0.0860,  0.0390,  0.0199],
          [ 0.1124, -0.1700,  0.0440],
          [ 0.0387,  0.1176, -0.1820]],

         [[-0.1145,  0.2180,  0.0686],
          [ 0.1926,  0.1307,  0.1212],
          [ 0.1754,  0.1151, -0.0928]]],


        [[[ 0.0446, -0.1394, -0.0240],
          [ 0.0502, -0.0716,  0.0761],
          [ 0.0683, -0.1477,  0.0306]],

         [[ 0.1734, -0.1565,  0.0581],
          [-0.1309,  0.0729, -0.1117],
          [ 0.0236,  0.1071, -0.0186]],

         [[-0.0559, -0.1208,  0.0909],
          [-0.1337, -0.3539, -0.2356],
          [ 0.0345, -0.0855, -0.1296]]],


        [[[-0.0457,  0.0154, -0.1235],
          [ 0.1639,  0.0185, -0.1503],
          [ 0.1479, -0.0351, -0.0502]],

         [[ 0.1233,  0.0605, -0.1468],
          [ 0.0756,  0.0166,  0.0658],
          [-0.0603, -0.0773,  0.1770]],

         [[ 0.0858, -0.1535, -0.0253],
          [ 0.0582,  0.1611,  0.0982],
          [-0.1474, -0.0698, -0.0184]]]], device='cuda:0', requires_grad=True)

conv1_weight_grad tensor([[[[ 0.0001,  0.0002,  0.0003],
          [ 0.0003,  0.0004,  0.0003],
          [ 0.0003,  0.0002,  0.0002]],

         [[ 0.0001,  0.0002,  0.0002],
          [ 0.0003,  0.0003,  0.0002],
          [ 0.0003,  0.0002,  0.0002]],

         [[ 0.0001,  0.0002,  0.0002],
          [ 0.0003,  0.0003,  0.0002],
          [ 0.0003,  0.0003,  0.0002]]],


        [[[-0.0285, -0.0160, -0.0230],
          [-0.0164, -0.0037, -0.0118],
          [-0.0230, -0.0114, -0.0182]],

         [[-0.0291, -0.0166, -0.0235],
          [-0.0164, -0.0041, -0.0124],
          [-0.0227, -0.0118, -0.0188]],

         [[-0.0256, -0.0147, -0.0211],
          [-0.0147, -0.0040, -0.0115],
          [-0.0212, -0.0118, -0.0181]]],


        [[[-0.0008, -0.0017, -0.0016],
          [-0.0020, -0.0035, -0.0033],
          [-0.0032, -0.0051, -0.0045]],

         [[-0.0007, -0.0018, -0.0014],
          [-0.0018, -0.0033, -0.0026],
          [-0.0026, -0.0044, -0.0034]],

         [[-0.0008, -0.0018, -0.0018],
          [-0.0017, -0.0034, -0.0033],
          [-0.0025, -0.0045, -0.0040]]],


        ...,


        [[[ 0.0167,  0.0083,  0.0044],
          [ 0.0094,  0.0007,  0.0020],
          [-0.0114, -0.0166, -0.0191]],

         [[ 0.0124,  0.0020, -0.0026],
          [ 0.0053, -0.0032, -0.0020],
          [-0.0154, -0.0197, -0.0225]],

         [[ 0.0110,  0.0026, -0.0021],
          [ 0.0035, -0.0013,  0.0003],
          [-0.0179, -0.0186, -0.0198]]],


        [[[-0.0304, -0.0221, -0.0287],
          [-0.0204, -0.0103, -0.0156],
          [-0.0291, -0.0191, -0.0218]],

         [[-0.0211, -0.0133, -0.0200],
          [-0.0098, -0.0007, -0.0065],
          [-0.0178, -0.0091, -0.0124]],

         [[-0.0140, -0.0067, -0.0125],
          [-0.0040,  0.0043, -0.0007],
          [-0.0119, -0.0043, -0.0072]]],


        [[[ 0.0021,  0.0025,  0.0023],
          [ 0.0015,  0.0009,  0.0008],
          [-0.0015, -0.0023, -0.0017]],

         [[ 0.0009,  0.0015,  0.0016],
          [ 0.0006,  0.0001,  0.0000],
          [-0.0021, -0.0029, -0.0023]],

         [[ 0.0002,  0.0010,  0.0015],
          [-0.0002, -0.0004, -0.0001],
          [-0.0022, -0.0028, -0.0020]]]], device='cuda:0')

percentage_weight tensor([0.], device='cuda:0')

percentage_weight_grad tensor([-24.0159], device='cuda:0')

False Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True _Gate(
  (sig): Sigmoid()
)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True _Gate(
  (sig): Sigmoid()
)
False Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True _Gate(
  (sig): Sigmoid()
)
False Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True _Gate(
  (sig): Sigmoid()
)
False Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True _Gate(
  (sig): Sigmoid()
)
False Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True _Gate(
  (sig): Sigmoid()
)
False Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True _Gate(
  (sig): Sigmoid()
)
False Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True _Gate(
  (sig): Sigmoid()
)
False Linear(in_features=512, out_features=10, bias=True)
Epoch: 13 | Batch_idx: 0 |  Loss: (0.6179) | Acc: (79.00%) (102/128)
Epoch: 13 | Batch_idx: 10 |  Loss: (0.6300) | Acc: (78.00%) (1104/1408)
Epoch: 13 | Batch_idx: 20 |  Loss: (0.7181) | Acc: (75.00%) (2030/2688)
Epoch: 13 | Batch_idx: 30 |  Loss: (0.7744) | Acc: (73.00%) (2932/3968)
Epoch: 13 | Batch_idx: 40 |  Loss: (0.7982) | Acc: (73.00%) (3853/5248)
Epoch: 13 | Batch_idx: 50 |  Loss: (0.8058) | Acc: (73.00%) (4792/6528)
Epoch: 13 | Batch_idx: 60 |  Loss: (0.8055) | Acc: (73.00%) (5739/7808)
Epoch: 13 | Batch_idx: 70 |  Loss: (0.7943) | Acc: (73.00%) (6717/9088)
Epoch: 13 | Batch_idx: 80 |  Loss: (0.7887) | Acc: (74.00%) (7676/10368)
Epoch: 13 | Batch_idx: 90 |  Loss: (0.7723) | Acc: (74.00%) (8679/11648)
Epoch: 13 | Batch_idx: 100 |  Loss: (0.7627) | Acc: (74.00%) (9649/12928)
Epoch: 13 | Batch_idx: 110 |  Loss: (0.7535) | Acc: (74.00%) (10632/14208)
Epoch: 13 | Batch_idx: 120 |  Loss: (0.7480) | Acc: (75.00%) (11621/15488)
Epoch: 13 | Batch_idx: 130 |  Loss: (0.7476) | Acc: (74.00%) (12572/16768)
Epoch: 13 | Batch_idx: 140 |  Loss: (0.7426) | Acc: (75.00%) (13571/18048)
Epoch: 13 | Batch_idx: 150 |  Loss: (0.7362) | Acc: (75.00%) (14563/19328)
Epoch: 13 | Batch_idx: 160 |  Loss: (0.7307) | Acc: (75.00%) (15568/20608)
Epoch: 13 | Batch_idx: 170 |  Loss: (0.7226) | Acc: (75.00%) (16590/21888)
Epoch: 13 | Batch_idx: 180 |  Loss: (0.7142) | Acc: (76.00%) (17621/23168)
Epoch: 13 | Batch_idx: 190 |  Loss: (0.7087) | Acc: (76.00%) (18643/24448)
Epoch: 13 | Batch_idx: 200 |  Loss: (0.7051) | Acc: (76.00%) (19642/25728)
Epoch: 13 | Batch_idx: 210 |  Loss: (0.6975) | Acc: (76.00%) (20680/27008)
Epoch: 13 | Batch_idx: 220 |  Loss: (0.6948) | Acc: (76.00%) (21671/28288)
Epoch: 13 | Batch_idx: 230 |  Loss: (0.6889) | Acc: (76.00%) (22704/29568)
Epoch: 13 | Batch_idx: 240 |  Loss: (0.6851) | Acc: (76.00%) (23730/30848)
Epoch: 13 | Batch_idx: 250 |  Loss: (0.6816) | Acc: (77.00%) (24760/32128)
Epoch: 13 | Batch_idx: 260 |  Loss: (0.6800) | Acc: (77.00%) (25753/33408)
Epoch: 13 | Batch_idx: 270 |  Loss: (0.6770) | Acc: (77.00%) (26772/34688)
Epoch: 13 | Batch_idx: 280 |  Loss: (0.6747) | Acc: (77.00%) (27793/35968)
Epoch: 13 | Batch_idx: 290 |  Loss: (0.6716) | Acc: (77.00%) (28822/37248)
Epoch: 13 | Batch_idx: 300 |  Loss: (0.6686) | Acc: (77.00%) (29859/38528)
Epoch: 13 | Batch_idx: 310 |  Loss: (0.6647) | Acc: (77.00%) (30910/39808)
Epoch: 13 | Batch_idx: 320 |  Loss: (0.6617) | Acc: (77.00%) (31949/41088)
Epoch: 13 | Batch_idx: 330 |  Loss: (0.6600) | Acc: (77.00%) (32967/42368)
Epoch: 13 | Batch_idx: 340 |  Loss: (0.6572) | Acc: (77.00%) (33990/43648)
Epoch: 13 | Batch_idx: 350 |  Loss: (0.6555) | Acc: (77.00%) (34997/44928)
Epoch: 13 | Batch_idx: 360 |  Loss: (0.6528) | Acc: (77.00%) (36039/46208)
Epoch: 13 | Batch_idx: 370 |  Loss: (0.6504) | Acc: (78.00%) (37071/47488)
Epoch: 13 | Batch_idx: 380 |  Loss: (0.6475) | Acc: (78.00%) (38115/48768)
Epoch: 13 | Batch_idx: 390 |  Loss: (0.6446) | Acc: (78.00%) (39117/50000)
# TEST : Loss: (0.5903) | Acc: (79.00%) (7957/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-0.0743,  0.0056,  0.0106],
          [ 0.0149,  0.0955, -0.0509],
          [ 0.0459, -0.0596, -0.0983]],

         [[-0.1483,  0.0371,  0.0522],
          [ 0.0299,  0.0341, -0.0697],
          [ 0.0211, -0.0642,  0.0043]],

         [[-0.0375, -0.0548,  0.0482],
          [-0.0428,  0.0605,  0.0019],
          [ 0.0605, -0.0019, -0.0943]]],


        [[[ 0.0978, -0.0373,  0.0499],
          [ 0.0694, -0.2081, -0.0023],
          [ 0.0386, -0.0025,  0.0390]],

         [[-0.0077, -0.1037, -0.0543],
          [-0.0735, -0.3188, -0.0310],
          [-0.0135,  0.0189,  0.1147]],

         [[ 0.0351,  0.0376,  0.0857],
          [ 0.0720, -0.1232,  0.0421],
          [-0.0037, -0.0276,  0.0153]]],


        [[[ 0.0994, -0.0663,  0.1181],
          [ 0.1224,  0.0641,  0.1789],
          [ 0.0200, -0.0413, -0.1191]],

         [[ 0.2355,  0.0620, -0.0413],
          [ 0.1100,  0.0636, -0.0459],
          [ 0.1373, -0.1169,  0.1214]],

         [[-0.0476,  0.1127, -0.1371],
          [-0.0689, -0.1604,  0.1011],
          [-0.0751, -0.0319, -0.0743]]],


        ...,


        [[[-0.0944,  0.1171, -0.1245],
          [-0.2121, -0.0701, -0.1378],
          [-0.0900,  0.1059, -0.2348]],

         [[ 0.0830,  0.0362,  0.0174],
          [ 0.1103, -0.1713,  0.0423],
          [ 0.0377,  0.1171, -0.1819]],

         [[-0.1168,  0.2151,  0.0663],
          [ 0.1908,  0.1291,  0.1195],
          [ 0.1745,  0.1149, -0.0928]]],


        [[[ 0.0543, -0.1296, -0.0140],
          [ 0.0582, -0.0653,  0.0821],
          [ 0.0778, -0.1386,  0.0381]],

         [[ 0.1796, -0.1484,  0.0658],
          [-0.1234,  0.0739, -0.1051],
          [ 0.0312,  0.1110, -0.0120]],

         [[-0.0482, -0.1141,  0.0959],
          [-0.1270, -0.3416, -0.2252],
          [ 0.0407, -0.0805, -0.1224]]],


        [[[-0.0436,  0.0149, -0.1220],
          [ 0.1566,  0.0153, -0.1497],
          [ 0.1427, -0.0365, -0.0520]],

         [[ 0.1217,  0.0596, -0.1439],
          [ 0.0719,  0.0143,  0.0627],
          [-0.0595, -0.0775,  0.1712]],

         [[ 0.0863, -0.1481, -0.0241],
          [ 0.0573,  0.1572,  0.0959],
          [-0.1433, -0.0685, -0.0187]]]], device='cuda:0')

conv1_weight_grad tensor([[[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        ...,


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]]], device='cuda:0')

percentage_weight tensor([0.], device='cuda:0', requires_grad=True)

percentage_weight_grad tensor([-22.5408], device='cuda:0')

Epoch: 14 | Batch_idx: 0 |  Loss: (0.5062) | Acc: (82.00%) (106/128)
Epoch: 14 | Batch_idx: 10 |  Loss: (0.5702) | Acc: (80.00%) (1136/1408)
Epoch: 14 | Batch_idx: 20 |  Loss: (0.5707) | Acc: (80.00%) (2166/2688)
Epoch: 14 | Batch_idx: 30 |  Loss: (0.5602) | Acc: (80.00%) (3203/3968)
Epoch: 14 | Batch_idx: 40 |  Loss: (0.5586) | Acc: (80.00%) (4247/5248)
Epoch: 14 | Batch_idx: 50 |  Loss: (0.5548) | Acc: (81.00%) (5295/6528)
Epoch: 14 | Batch_idx: 60 |  Loss: (0.5537) | Acc: (81.00%) (6331/7808)
Epoch: 14 | Batch_idx: 70 |  Loss: (0.5530) | Acc: (81.00%) (7370/9088)
Epoch: 14 | Batch_idx: 80 |  Loss: (0.5562) | Acc: (81.00%) (8406/10368)
Epoch: 14 | Batch_idx: 90 |  Loss: (0.5529) | Acc: (81.00%) (9481/11648)
Epoch: 14 | Batch_idx: 100 |  Loss: (0.5542) | Acc: (81.00%) (10526/12928)
Epoch: 14 | Batch_idx: 110 |  Loss: (0.5566) | Acc: (81.00%) (11553/14208)
Epoch: 14 | Batch_idx: 120 |  Loss: (0.5580) | Acc: (81.00%) (12606/15488)
Epoch: 14 | Batch_idx: 130 |  Loss: (0.5604) | Acc: (81.00%) (13627/16768)
Epoch: 14 | Batch_idx: 140 |  Loss: (0.5585) | Acc: (81.00%) (14679/18048)
Epoch: 14 | Batch_idx: 150 |  Loss: (0.5598) | Acc: (81.00%) (15692/19328)
Epoch: 14 | Batch_idx: 160 |  Loss: (0.5650) | Acc: (81.00%) (16699/20608)
Epoch: 14 | Batch_idx: 170 |  Loss: (0.5640) | Acc: (81.00%) (17744/21888)
Epoch: 14 | Batch_idx: 180 |  Loss: (0.5622) | Acc: (81.00%) (18792/23168)
Epoch: 14 | Batch_idx: 190 |  Loss: (0.5601) | Acc: (81.00%) (19852/24448)
Epoch: 14 | Batch_idx: 200 |  Loss: (0.5572) | Acc: (81.00%) (20930/25728)
Epoch: 14 | Batch_idx: 210 |  Loss: (0.5574) | Acc: (81.00%) (21975/27008)
Epoch: 14 | Batch_idx: 220 |  Loss: (0.5603) | Acc: (81.00%) (22987/28288)
Epoch: 14 | Batch_idx: 230 |  Loss: (0.5583) | Acc: (81.00%) (24046/29568)
Epoch: 14 | Batch_idx: 240 |  Loss: (0.5581) | Acc: (81.00%) (25083/30848)
Epoch: 14 | Batch_idx: 250 |  Loss: (0.5586) | Acc: (81.00%) (26127/32128)
Epoch: 14 | Batch_idx: 260 |  Loss: (0.5591) | Acc: (81.00%) (27166/33408)
Epoch: 14 | Batch_idx: 270 |  Loss: (0.5580) | Acc: (81.00%) (28221/34688)
Epoch: 14 | Batch_idx: 280 |  Loss: (0.5571) | Acc: (81.00%) (29271/35968)
Epoch: 14 | Batch_idx: 290 |  Loss: (0.5569) | Acc: (81.00%) (30312/37248)
Epoch: 14 | Batch_idx: 300 |  Loss: (0.5556) | Acc: (81.00%) (31364/38528)
Epoch: 14 | Batch_idx: 310 |  Loss: (0.5547) | Acc: (81.00%) (32417/39808)
Epoch: 14 | Batch_idx: 320 |  Loss: (0.5536) | Acc: (81.00%) (33477/41088)
Epoch: 14 | Batch_idx: 330 |  Loss: (0.5534) | Acc: (81.00%) (34508/42368)
Epoch: 14 | Batch_idx: 340 |  Loss: (0.5549) | Acc: (81.00%) (35543/43648)
Epoch: 14 | Batch_idx: 350 |  Loss: (0.5550) | Acc: (81.00%) (36591/44928)
Epoch: 14 | Batch_idx: 360 |  Loss: (0.5553) | Acc: (81.00%) (37635/46208)
Epoch: 14 | Batch_idx: 370 |  Loss: (0.5543) | Acc: (81.00%) (38692/47488)
Epoch: 14 | Batch_idx: 380 |  Loss: (0.5533) | Acc: (81.00%) (39740/48768)
Epoch: 14 | Batch_idx: 390 |  Loss: (0.5527) | Acc: (81.00%) (40755/50000)
# TEST : Loss: (0.5612) | Acc: (80.00%) (8077/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-0.0660,  0.0050,  0.0096],
          [ 0.0133,  0.0857, -0.0453],
          [ 0.0415, -0.0531, -0.0863]],

         [[-0.1313,  0.0332,  0.0469],
          [ 0.0266,  0.0305, -0.0618],
          [ 0.0190, -0.0570,  0.0038]],

         [[-0.0331, -0.0488,  0.0432],
          [-0.0380,  0.0540,  0.0017],
          [ 0.0543, -0.0016, -0.0821]]],


        [[[ 0.0961, -0.0364,  0.0490],
          [ 0.0680, -0.2006, -0.0022],
          [ 0.0380, -0.0025,  0.0384]],

         [[-0.0076, -0.1006, -0.0532],
          [-0.0718, -0.2997, -0.0303],
          [-0.0133,  0.0185,  0.1128]],

         [[ 0.0343,  0.0364,  0.0839],
          [ 0.0702, -0.1173,  0.0410],
          [-0.0036, -0.0270,  0.0150]]],


        [[[ 0.0957, -0.0637,  0.1138],
          [ 0.1178,  0.0616,  0.1726],
          [ 0.0194, -0.0401, -0.1158]],

         [[ 0.2288,  0.0600, -0.0401],
          [ 0.1068,  0.0616, -0.0445],
          [ 0.1334, -0.1137,  0.1182]],

         [[-0.0469,  0.1108, -0.1347],
          [-0.0678, -0.1576,  0.0993],
          [-0.0737, -0.0313, -0.0729]]],


        ...,


        [[[-0.0942,  0.1169, -0.1243],
          [-0.2117, -0.0700, -0.1375],
          [-0.0899,  0.1057, -0.2344]],

         [[ 0.0829,  0.0361,  0.0173],
          [ 0.1101, -0.1710,  0.0423],
          [ 0.0377,  0.1169, -0.1816]],

         [[-0.1165,  0.2147,  0.0662],
          [ 0.1904,  0.1289,  0.1193],
          [ 0.1742,  0.1147, -0.0926]]],


        [[[ 0.0537, -0.1279, -0.0138],
          [ 0.0575, -0.0644,  0.0809],
          [ 0.0769, -0.1369,  0.0377]],

         [[ 0.1772, -0.1459,  0.0648],
          [-0.1216,  0.0726, -0.1032],
          [ 0.0308,  0.1093, -0.0118]],

         [[-0.0473, -0.1101,  0.0933],
          [-0.1238, -0.3179, -0.2144],
          [ 0.0399, -0.0779, -0.1192]]],


        [[[-0.0424,  0.0145, -0.1186],
          [ 0.1500,  0.0148, -0.1458],
          [ 0.1377, -0.0355, -0.0507]],

         [[ 0.1181,  0.0579, -0.1401],
          [ 0.0690,  0.0138,  0.0611],
          [-0.0576, -0.0753,  0.1670]],

         [[ 0.0840, -0.1439, -0.0235],
          [ 0.0555,  0.1526,  0.0934],
          [-0.1392, -0.0667, -0.0183]]]], device='cuda:0')

conv1_weight_grad tensor([[[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        ...,


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]]], device='cuda:0')

percentage_weight tensor([0.], device='cuda:0', requires_grad=True)

percentage_weight_grad tensor([-23.2727], device='cuda:0')

True Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False _Gate(
  (sig): Sigmoid()
)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False _Gate(
  (sig): Sigmoid()
)
True Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False _Gate(
  (sig): Sigmoid()
)
True Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False _Gate(
  (sig): Sigmoid()
)
True Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False _Gate(
  (sig): Sigmoid()
)
True Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False _Gate(
  (sig): Sigmoid()
)
True Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False _Gate(
  (sig): Sigmoid()
)
True Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False _Gate(
  (sig): Sigmoid()
)
True Linear(in_features=512, out_features=10, bias=True)
Epoch: 15 | Batch_idx: 0 |  Loss: (0.5476) | Acc: (82.00%) (106/128)
Epoch: 15 | Batch_idx: 10 |  Loss: (0.6204) | Acc: (79.00%) (1115/1408)
Epoch: 15 | Batch_idx: 20 |  Loss: (0.6214) | Acc: (78.00%) (2115/2688)
Epoch: 15 | Batch_idx: 30 |  Loss: (0.6247) | Acc: (78.00%) (3120/3968)
Epoch: 15 | Batch_idx: 40 |  Loss: (0.6175) | Acc: (78.00%) (4136/5248)
Epoch: 15 | Batch_idx: 50 |  Loss: (0.6301) | Acc: (78.00%) (5108/6528)
Epoch: 15 | Batch_idx: 60 |  Loss: (0.6355) | Acc: (78.00%) (6098/7808)
Epoch: 15 | Batch_idx: 70 |  Loss: (0.6372) | Acc: (78.00%) (7103/9088)
Epoch: 15 | Batch_idx: 80 |  Loss: (0.6350) | Acc: (78.00%) (8120/10368)
Epoch: 15 | Batch_idx: 90 |  Loss: (0.6348) | Acc: (78.00%) (9126/11648)
Epoch: 15 | Batch_idx: 100 |  Loss: (0.6344) | Acc: (78.00%) (10139/12928)
Epoch: 15 | Batch_idx: 110 |  Loss: (0.6340) | Acc: (78.00%) (11146/14208)
Epoch: 15 | Batch_idx: 120 |  Loss: (0.6357) | Acc: (78.00%) (12154/15488)
Epoch: 15 | Batch_idx: 130 |  Loss: (0.6339) | Acc: (78.00%) (13173/16768)
Epoch: 15 | Batch_idx: 140 |  Loss: (0.6317) | Acc: (78.00%) (14184/18048)
Epoch: 15 | Batch_idx: 150 |  Loss: (0.6275) | Acc: (78.00%) (15203/19328)
Epoch: 15 | Batch_idx: 160 |  Loss: (0.6245) | Acc: (78.00%) (16235/20608)
Epoch: 15 | Batch_idx: 170 |  Loss: (0.6209) | Acc: (78.00%) (17268/21888)
Epoch: 15 | Batch_idx: 180 |  Loss: (0.6180) | Acc: (78.00%) (18295/23168)
Epoch: 15 | Batch_idx: 190 |  Loss: (0.6156) | Acc: (79.00%) (19321/24448)
Epoch: 15 | Batch_idx: 200 |  Loss: (0.6148) | Acc: (79.00%) (20335/25728)
Epoch: 15 | Batch_idx: 210 |  Loss: (0.6130) | Acc: (79.00%) (21361/27008)
Epoch: 15 | Batch_idx: 220 |  Loss: (0.6126) | Acc: (79.00%) (22377/28288)
Epoch: 15 | Batch_idx: 230 |  Loss: (0.6092) | Acc: (79.00%) (23426/29568)
Epoch: 15 | Batch_idx: 240 |  Loss: (0.6094) | Acc: (79.00%) (24443/30848)
Epoch: 15 | Batch_idx: 250 |  Loss: (0.6081) | Acc: (79.00%) (25454/32128)
Epoch: 15 | Batch_idx: 260 |  Loss: (0.6056) | Acc: (79.00%) (26499/33408)
Epoch: 15 | Batch_idx: 270 |  Loss: (0.6029) | Acc: (79.00%) (27559/34688)
Epoch: 15 | Batch_idx: 280 |  Loss: (0.6024) | Acc: (79.00%) (28591/35968)
Epoch: 15 | Batch_idx: 290 |  Loss: (0.6029) | Acc: (79.00%) (29604/37248)
Epoch: 15 | Batch_idx: 300 |  Loss: (0.6009) | Acc: (79.00%) (30646/38528)
Epoch: 15 | Batch_idx: 310 |  Loss: (0.5987) | Acc: (79.00%) (31698/39808)
Epoch: 15 | Batch_idx: 320 |  Loss: (0.5967) | Acc: (79.00%) (32755/41088)
Epoch: 15 | Batch_idx: 330 |  Loss: (0.5941) | Acc: (79.00%) (33808/42368)
Epoch: 15 | Batch_idx: 340 |  Loss: (0.5936) | Acc: (79.00%) (34843/43648)
Epoch: 15 | Batch_idx: 350 |  Loss: (0.5924) | Acc: (79.00%) (35875/44928)
Epoch: 15 | Batch_idx: 360 |  Loss: (0.5905) | Acc: (79.00%) (36921/46208)
Epoch: 15 | Batch_idx: 370 |  Loss: (0.5903) | Acc: (79.00%) (37933/47488)
Epoch: 15 | Batch_idx: 380 |  Loss: (0.5887) | Acc: (79.00%) (38978/48768)
Epoch: 15 | Batch_idx: 390 |  Loss: (0.5866) | Acc: (79.00%) (39987/50000)
# TEST : Loss: (0.6073) | Acc: (79.00%) (7928/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-0.0588, -0.0007,  0.0020],
          [ 0.0075,  0.0708, -0.0461],
          [ 0.0295, -0.0519, -0.0806]],

         [[-0.1130,  0.0248,  0.0348],
          [ 0.0218,  0.0237, -0.0603],
          [ 0.0116, -0.0534, -0.0032]],

         [[-0.0292, -0.0477,  0.0306],
          [-0.0357,  0.0423, -0.0072],
          [ 0.0416, -0.0072, -0.0777]]],


        [[[ 0.0862, -0.0498,  0.0406],
          [ 0.0494, -0.2281, -0.0158],
          [ 0.0270, -0.0184,  0.0262]],

         [[-0.0067, -0.1069, -0.0576],
          [-0.0834, -0.3285, -0.0439],
          [-0.0283, -0.0041,  0.0939]],

         [[ 0.0447,  0.0397,  0.0913],
          [ 0.0686, -0.1241,  0.0402],
          [-0.0113, -0.0408,  0.0050]]],


        [[[ 0.0873, -0.0594,  0.1053],
          [ 0.1090,  0.0596,  0.1628],
          [ 0.0182, -0.0306, -0.1029]],

         [[ 0.2280,  0.0706, -0.0311],
          [ 0.1080,  0.0686, -0.0377],
          [ 0.1315, -0.0985,  0.1273]],

         [[-0.0478,  0.1104, -0.1310],
          [-0.0704, -0.1569,  0.0937],
          [-0.0771, -0.0310, -0.0721]]],


        ...,


        [[[-0.0942,  0.1135, -0.1304],
          [-0.2127, -0.0763, -0.1469],
          [-0.0948,  0.0956, -0.2473]],

         [[ 0.0768,  0.0303,  0.0092],
          [ 0.1104, -0.1711,  0.0385],
          [ 0.0379,  0.1164, -0.1861]],

         [[-0.1173,  0.2159,  0.0639],
          [ 0.1985,  0.1401,  0.1266],
          [ 0.1772,  0.1214, -0.0896]]],


        [[[ 0.0473, -0.1247, -0.0062],
          [ 0.0476, -0.0689,  0.0811],
          [ 0.0812, -0.1244,  0.0432]],

         [[ 0.1601, -0.1499,  0.0669],
          [-0.1363,  0.0628, -0.1015],
          [ 0.0321,  0.1207, -0.0047]],

         [[-0.0515, -0.1056,  0.1005],
          [-0.1369, -0.3421, -0.2302],
          [ 0.0369, -0.0758, -0.1288]]],


        [[[-0.0530,  0.0005, -0.1307],
          [ 0.1247,  0.0111, -0.1534],
          [ 0.1353, -0.0197, -0.0411]],

         [[ 0.1145,  0.0583, -0.1358],
          [ 0.0598,  0.0263,  0.0622],
          [-0.0524, -0.0520,  0.1812]],

         [[ 0.0727, -0.1398, -0.0204],
          [ 0.0272,  0.1443,  0.0879],
          [-0.1618, -0.0725, -0.0177]]]], device='cuda:0', requires_grad=True)

conv1_weight_grad tensor([[[[-3.8093e-07, -7.3608e-06, -9.0135e-06],
          [ 9.8180e-06,  2.0413e-06, -5.5475e-06],
          [ 1.0389e-05,  7.3264e-06,  2.5320e-06]],

         [[ 5.0405e-08, -6.7207e-06, -8.2306e-06],
          [ 9.8336e-06,  1.7622e-06, -4.7288e-06],
          [ 1.0858e-05,  6.9232e-06,  3.0336e-06]],

         [[ 6.0831e-07, -5.1063e-06, -7.0458e-06],
          [ 1.0688e-05,  3.4688e-06, -3.3720e-06],
          [ 1.1640e-05,  7.5583e-06,  3.3982e-06]]],


        [[[-1.0699e-03, -2.5791e-03, -4.7476e-04],
          [ 1.4448e-03,  7.2250e-04,  2.9151e-03],
          [-4.3306e-04, -1.4408e-03, -4.7199e-04]],

         [[-1.2922e-03, -2.7691e-03, -1.0331e-03],
          [ 6.6215e-04,  1.3937e-05,  1.8136e-03],
          [-1.2185e-03, -2.0496e-03, -1.0953e-03]],

         [[-6.5065e-04, -2.1452e-03, -9.4472e-04],
          [ 5.0071e-04, -6.0514e-05,  1.2404e-03],
          [-5.9087e-04, -1.4878e-03, -1.0216e-03]]],


        [[[-9.0137e-05, -1.9345e-05, -6.8059e-04],
          [ 2.3640e-05,  1.1373e-05, -8.6778e-05],
          [ 6.4189e-05,  2.3038e-04,  1.5819e-04]],

         [[ 4.7296e-04,  5.9479e-04, -1.2938e-04],
          [ 6.5823e-04,  6.0545e-04,  4.3977e-04],
          [ 4.6940e-04,  6.7161e-04,  6.0172e-04]],

         [[ 3.5021e-04,  5.9421e-04, -5.2911e-05],
          [ 7.1287e-04,  8.0884e-04,  6.6950e-04],
          [ 7.1006e-04,  1.0423e-03,  9.4736e-04]]],


        ...,


        [[[ 2.5522e-02,  2.2613e-02,  1.5034e-02],
          [ 2.2598e-02,  1.9308e-02,  1.4718e-02],
          [ 1.4487e-02,  1.6019e-02,  1.1077e-02]],

         [[ 3.0226e-02,  2.8614e-02,  1.7988e-02],
          [ 2.4751e-02,  2.1198e-02,  1.3065e-02],
          [ 1.4866e-02,  1.5440e-02,  8.1119e-03]],

         [[ 2.2192e-02,  2.2543e-02,  1.2301e-02],
          [ 1.3547e-02,  1.1563e-02,  3.2316e-03],
          [ 2.8592e-03,  4.9743e-03, -2.3855e-03]]],


        [[[ 3.3761e-03,  4.1344e-04,  2.2518e-03],
          [ 6.3701e-03,  3.7464e-03,  6.2693e-03],
          [ 2.1123e-03, -7.6978e-04,  1.9082e-03]],

         [[ 9.6945e-04, -1.9598e-03, -1.0073e-04],
          [ 3.5393e-03,  9.2903e-04,  3.3374e-03],
          [ 1.4189e-04, -2.7023e-03, -9.6622e-05]],

         [[ 1.1057e-04, -2.3205e-03, -4.8414e-04],
          [ 2.0632e-03, -1.7222e-04,  2.1262e-03],
          [ 2.4306e-04, -2.2542e-03,  5.7408e-05]]],


        [[[ 1.2426e-03,  1.4372e-03, -5.8081e-04],
          [ 4.4954e-05, -2.1205e-04, -1.6366e-03],
          [ 8.4914e-05, -6.1684e-04, -1.5936e-03]],

         [[ 1.8073e-03,  1.8316e-03, -3.7227e-05],
          [ 5.2423e-04, -5.4381e-05, -1.4958e-03],
          [ 8.2902e-04,  3.9174e-05, -9.0512e-04]],

         [[ 1.1490e-03,  1.2661e-03, -1.5288e-04],
          [-2.4283e-04, -8.1916e-04, -1.9552e-03],
          [ 2.9509e-04, -2.1899e-04, -9.7656e-04]]]], device='cuda:0')

percentage_weight tensor([0.], device='cuda:0')

percentage_weight_grad tensor([-23.2727], device='cuda:0')

Epoch: 16 | Batch_idx: 0 |  Loss: (0.4733) | Acc: (83.00%) (107/128)
Epoch: 16 | Batch_idx: 10 |  Loss: (0.4705) | Acc: (84.00%) (1184/1408)
Epoch: 16 | Batch_idx: 20 |  Loss: (0.4554) | Acc: (84.00%) (2282/2688)
Epoch: 16 | Batch_idx: 30 |  Loss: (0.4770) | Acc: (83.00%) (3330/3968)
Epoch: 16 | Batch_idx: 40 |  Loss: (0.4812) | Acc: (83.00%) (4387/5248)
Epoch: 16 | Batch_idx: 50 |  Loss: (0.4830) | Acc: (83.00%) (5449/6528)
Epoch: 16 | Batch_idx: 60 |  Loss: (0.4775) | Acc: (83.00%) (6556/7808)
Epoch: 16 | Batch_idx: 70 |  Loss: (0.4854) | Acc: (83.00%) (7620/9088)
Epoch: 16 | Batch_idx: 80 |  Loss: (0.4903) | Acc: (83.00%) (8671/10368)
Epoch: 16 | Batch_idx: 90 |  Loss: (0.4935) | Acc: (83.00%) (9730/11648)
Epoch: 16 | Batch_idx: 100 |  Loss: (0.4920) | Acc: (83.00%) (10821/12928)
Epoch: 16 | Batch_idx: 110 |  Loss: (0.4943) | Acc: (83.00%) (11867/14208)
Epoch: 16 | Batch_idx: 120 |  Loss: (0.4968) | Acc: (83.00%) (12919/15488)
Epoch: 16 | Batch_idx: 130 |  Loss: (0.4983) | Acc: (83.00%) (13958/16768)
Epoch: 16 | Batch_idx: 140 |  Loss: (0.5028) | Acc: (83.00%) (14999/18048)
Epoch: 16 | Batch_idx: 150 |  Loss: (0.5041) | Acc: (82.00%) (16039/19328)
Epoch: 16 | Batch_idx: 160 |  Loss: (0.5055) | Acc: (82.00%) (17102/20608)
Epoch: 16 | Batch_idx: 170 |  Loss: (0.5020) | Acc: (83.00%) (18199/21888)
Epoch: 16 | Batch_idx: 180 |  Loss: (0.5019) | Acc: (83.00%) (19257/23168)
Epoch: 16 | Batch_idx: 190 |  Loss: (0.4999) | Acc: (83.00%) (20330/24448)
Epoch: 16 | Batch_idx: 200 |  Loss: (0.4971) | Acc: (83.00%) (21417/25728)
Epoch: 16 | Batch_idx: 210 |  Loss: (0.4975) | Acc: (83.00%) (22475/27008)
Epoch: 16 | Batch_idx: 220 |  Loss: (0.4988) | Acc: (83.00%) (23524/28288)
Epoch: 16 | Batch_idx: 230 |  Loss: (0.5004) | Acc: (83.00%) (24577/29568)
Epoch: 16 | Batch_idx: 240 |  Loss: (0.5019) | Acc: (83.00%) (25629/30848)
Epoch: 16 | Batch_idx: 250 |  Loss: (0.5034) | Acc: (83.00%) (26678/32128)
Epoch: 16 | Batch_idx: 260 |  Loss: (0.5029) | Acc: (83.00%) (27743/33408)
Epoch: 16 | Batch_idx: 270 |  Loss: (0.5034) | Acc: (83.00%) (28802/34688)
Epoch: 16 | Batch_idx: 280 |  Loss: (0.5016) | Acc: (83.00%) (29875/35968)
Epoch: 16 | Batch_idx: 290 |  Loss: (0.5012) | Acc: (83.00%) (30944/37248)
Epoch: 16 | Batch_idx: 300 |  Loss: (0.5016) | Acc: (83.00%) (31988/38528)
Epoch: 16 | Batch_idx: 310 |  Loss: (0.5020) | Acc: (83.00%) (33060/39808)
Epoch: 16 | Batch_idx: 320 |  Loss: (0.5013) | Acc: (83.00%) (34137/41088)
Epoch: 16 | Batch_idx: 330 |  Loss: (0.5001) | Acc: (83.00%) (35215/42368)
Epoch: 16 | Batch_idx: 340 |  Loss: (0.4993) | Acc: (83.00%) (36301/43648)
Epoch: 16 | Batch_idx: 350 |  Loss: (0.4973) | Acc: (83.00%) (37393/44928)
Epoch: 16 | Batch_idx: 360 |  Loss: (0.4966) | Acc: (83.00%) (38462/46208)
Epoch: 16 | Batch_idx: 370 |  Loss: (0.4965) | Acc: (83.00%) (39521/47488)
Epoch: 16 | Batch_idx: 380 |  Loss: (0.4970) | Acc: (83.00%) (40575/48768)
Epoch: 16 | Batch_idx: 390 |  Loss: (0.4978) | Acc: (83.00%) (41589/50000)
# TEST : Loss: (0.5832) | Acc: (80.00%) (8031/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-0.0500, -0.0019,  0.0007],
          [ 0.0055,  0.0591, -0.0393],
          [ 0.0249, -0.0448, -0.0671]],

         [[-0.0952,  0.0196,  0.0286],
          [ 0.0175,  0.0184, -0.0512],
          [ 0.0092, -0.0459, -0.0031]],

         [[-0.0249, -0.0418,  0.0248],
          [-0.0310,  0.0343, -0.0067],
          [ 0.0349, -0.0068, -0.0640]]],


        [[[ 0.0839, -0.0551,  0.0349],
          [ 0.0469, -0.2414, -0.0282],
          [ 0.0425, -0.0027,  0.0293]],

         [[-0.0017, -0.1037, -0.0600],
          [-0.0810, -0.3398, -0.0591],
          [-0.0122,  0.0123,  0.0934]],

         [[ 0.0447,  0.0364,  0.0859],
          [ 0.0674, -0.1367,  0.0256],
          [ 0.0002, -0.0281,  0.0017]]],


        [[[ 0.0946, -0.0352,  0.1140],
          [ 0.1214,  0.0800,  0.1774],
          [ 0.0407, -0.0045, -0.0695]],

         [[ 0.2341,  0.0907, -0.0172],
          [ 0.1232,  0.0906, -0.0158],
          [ 0.1508, -0.0684,  0.1552]],

         [[-0.0405,  0.1179, -0.1238],
          [-0.0614, -0.1449,  0.0998],
          [-0.0637, -0.0155, -0.0508]]],


        ...,


        [[[-0.0995,  0.1103, -0.1277],
          [-0.2156, -0.0796, -0.1443],
          [-0.0966,  0.0925, -0.2458]],

         [[ 0.0752,  0.0330,  0.0147],
          [ 0.1124, -0.1669,  0.0454],
          [ 0.0393,  0.1182, -0.1818]],

         [[-0.1151,  0.2247,  0.0738],
          [ 0.2048,  0.1523,  0.1404],
          [ 0.1792,  0.1277, -0.0817]]],


        [[[ 0.0564, -0.1143,  0.0005],
          [ 0.0526, -0.0666,  0.0802],
          [ 0.0907, -0.1135,  0.0439]],

         [[ 0.1627, -0.1431,  0.0667],
          [-0.1341,  0.0592, -0.1074],
          [ 0.0401,  0.1305, -0.0068]],

         [[-0.0433, -0.0928,  0.0965],
          [-0.1327, -0.3349, -0.2561],
          [ 0.0403, -0.0709, -0.1497]]],


        [[[-0.0558, -0.0087, -0.1377],
          [ 0.1015, -0.0022, -0.1526],
          [ 0.1011, -0.0435, -0.0469]],

         [[ 0.1045,  0.0501, -0.1438],
          [ 0.0412,  0.0173,  0.0568],
          [-0.0794, -0.0732,  0.1704]],

         [[ 0.0563, -0.1435, -0.0291],
          [ 0.0003,  0.1297,  0.0818],
          [-0.1905, -0.0967, -0.0286]]]], device='cuda:0', requires_grad=True)

conv1_weight_grad tensor([[[[-6.5990e-07, -1.8020e-06,  7.9890e-07],
          [-5.6350e-06, -4.4523e-06, -1.9752e-06],
          [-5.5974e-06, -3.2563e-06, -9.6835e-07]],

         [[-6.6666e-07, -1.8184e-06,  8.0608e-07],
          [-5.9096e-06, -4.6744e-06, -1.9778e-06],
          [-5.9240e-06, -3.5243e-06, -9.4641e-07]],

         [[-7.9800e-07, -1.8700e-06,  7.1141e-07],
          [-5.8565e-06, -4.7609e-06, -2.0104e-06],
          [-5.9054e-06, -3.7207e-06, -1.0480e-06]]],


        [[[-2.4486e-03, -1.4689e-03, -1.3286e-03],
          [-1.7359e-03, -4.9971e-04, -2.2148e-04],
          [-2.0947e-03, -7.4538e-04, -4.2621e-04]],

         [[-2.2402e-03, -1.5956e-03, -1.4783e-03],
          [-1.1694e-03, -4.8111e-04, -5.2086e-04],
          [-1.8421e-03, -5.8951e-04, -7.1602e-04]],

         [[-1.1488e-03,  1.6489e-04, -6.9630e-04],
          [-4.8751e-04,  9.7008e-04,  1.2586e-04],
          [-2.0527e-03, -1.6024e-04, -8.0134e-04]]],


        [[[-1.3634e-03, -1.2786e-03, -1.3976e-03],
          [-9.0798e-04, -7.9995e-04, -7.0689e-04],
          [-4.7918e-04, -6.2599e-04, -6.6843e-04]],

         [[-6.9595e-04, -5.0438e-04, -3.5096e-04],
          [-1.2183e-04,  5.0156e-05,  3.9764e-04],
          [ 5.5289e-04,  5.7758e-04,  7.6060e-04]],

         [[-2.4688e-03, -2.5209e-03, -2.5031e-03],
          [-2.0606e-03, -2.1702e-03, -2.1002e-03],
          [-1.6442e-03, -1.7798e-03, -1.8066e-03]]],


        ...,


        [[[-1.1205e-02, -1.5717e-02, -1.8580e-02],
          [ 3.7903e-03,  3.8956e-03, -1.0629e-02],
          [ 1.9319e-02,  7.5567e-03, -7.2647e-03]],

         [[-1.9898e-02, -2.3674e-02, -2.7281e-02],
          [-3.5548e-03, -2.7483e-03, -1.9603e-02],
          [ 1.1233e-02,  1.7391e-03, -1.5312e-02]],

         [[-1.8100e-02, -1.3973e-02, -1.6797e-02],
          [-6.1708e-03,  3.9188e-03, -8.2394e-03],
          [ 2.8109e-03,  4.5850e-03, -3.6894e-03]]],


        [[[ 3.7020e-03,  5.6588e-03,  7.9616e-03],
          [ 3.9660e-03,  6.6075e-03,  7.5727e-03],
          [ 6.2616e-03,  6.6195e-03,  6.7833e-03]],

         [[ 5.6727e-03,  6.6650e-03,  9.1324e-03],
          [ 4.6221e-03,  6.2032e-03,  7.7510e-03],
          [ 6.1259e-03,  5.7781e-03,  7.1425e-03]],

         [[ 1.2246e-03,  2.7038e-03,  5.0192e-03],
          [-4.6193e-04,  8.5830e-04,  2.1479e-03],
          [-1.2994e-03, -1.6029e-03,  1.0254e-04]]],


        [[[ 1.1733e-04, -4.9906e-04, -2.1894e-04],
          [ 8.9081e-04,  3.7699e-04,  1.7198e-04],
          [ 1.4012e-03,  7.0659e-04,  3.1315e-04]],

         [[ 2.6297e-04, -3.5885e-04, -1.1765e-04],
          [ 1.0484e-03,  3.9508e-04,  8.4259e-05],
          [ 1.2149e-03,  4.3131e-04,  1.3839e-04]],

         [[ 3.0515e-04, -4.8541e-07,  1.9106e-04],
          [ 8.9417e-04,  5.7802e-04,  4.5099e-04],
          [ 1.1574e-03,  5.9572e-04,  3.8060e-04]]]], device='cuda:0')

percentage_weight tensor([0.], device='cuda:0')

percentage_weight_grad tensor([-23.2727], device='cuda:0')

False Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True _Gate(
  (sig): Sigmoid()
)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True _Gate(
  (sig): Sigmoid()
)
False Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True _Gate(
  (sig): Sigmoid()
)
False Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True _Gate(
  (sig): Sigmoid()
)
False Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True _Gate(
  (sig): Sigmoid()
)
False Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True _Gate(
  (sig): Sigmoid()
)
False Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True _Gate(
  (sig): Sigmoid()
)
False Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True _Gate(
  (sig): Sigmoid()
)
False Linear(in_features=512, out_features=10, bias=True)
Epoch: 17 | Batch_idx: 0 |  Loss: (0.4364) | Acc: (82.00%) (106/128)
Epoch: 17 | Batch_idx: 10 |  Loss: (0.5450) | Acc: (81.00%) (1141/1408)
Epoch: 17 | Batch_idx: 20 |  Loss: (0.6130) | Acc: (79.00%) (2127/2688)
Epoch: 17 | Batch_idx: 30 |  Loss: (0.6537) | Acc: (77.00%) (3088/3968)
Epoch: 17 | Batch_idx: 40 |  Loss: (0.6714) | Acc: (77.00%) (4044/5248)
Epoch: 17 | Batch_idx: 50 |  Loss: (0.6773) | Acc: (76.00%) (5020/6528)
Epoch: 17 | Batch_idx: 60 |  Loss: (0.6732) | Acc: (77.00%) (6014/7808)
Epoch: 17 | Batch_idx: 70 |  Loss: (0.6696) | Acc: (77.00%) (7013/9088)
Epoch: 17 | Batch_idx: 80 |  Loss: (0.6698) | Acc: (77.00%) (7991/10368)
Epoch: 17 | Batch_idx: 90 |  Loss: (0.6624) | Acc: (77.00%) (9008/11648)
Epoch: 17 | Batch_idx: 100 |  Loss: (0.6574) | Acc: (77.00%) (10016/12928)
Epoch: 17 | Batch_idx: 110 |  Loss: (0.6504) | Acc: (77.00%) (11036/14208)
Epoch: 17 | Batch_idx: 120 |  Loss: (0.6452) | Acc: (77.00%) (12050/15488)
Epoch: 17 | Batch_idx: 130 |  Loss: (0.6348) | Acc: (78.00%) (13110/16768)
Epoch: 17 | Batch_idx: 140 |  Loss: (0.6310) | Acc: (78.00%) (14137/18048)
Epoch: 17 | Batch_idx: 150 |  Loss: (0.6261) | Acc: (78.00%) (15161/19328)
Epoch: 17 | Batch_idx: 160 |  Loss: (0.6206) | Acc: (78.00%) (16210/20608)
Epoch: 17 | Batch_idx: 170 |  Loss: (0.6150) | Acc: (78.00%) (17259/21888)
Epoch: 17 | Batch_idx: 180 |  Loss: (0.6113) | Acc: (78.00%) (18294/23168)
Epoch: 17 | Batch_idx: 190 |  Loss: (0.6074) | Acc: (79.00%) (19343/24448)
Epoch: 17 | Batch_idx: 200 |  Loss: (0.6047) | Acc: (79.00%) (20391/25728)
Epoch: 17 | Batch_idx: 210 |  Loss: (0.5999) | Acc: (79.00%) (21458/27008)
Epoch: 17 | Batch_idx: 220 |  Loss: (0.5964) | Acc: (79.00%) (22492/28288)
Epoch: 17 | Batch_idx: 230 |  Loss: (0.5941) | Acc: (79.00%) (23533/29568)
Epoch: 17 | Batch_idx: 240 |  Loss: (0.5917) | Acc: (79.00%) (24584/30848)
Epoch: 17 | Batch_idx: 250 |  Loss: (0.5890) | Acc: (79.00%) (25643/32128)
Epoch: 17 | Batch_idx: 260 |  Loss: (0.5876) | Acc: (79.00%) (26690/33408)
Epoch: 17 | Batch_idx: 270 |  Loss: (0.5851) | Acc: (80.00%) (27758/34688)
Epoch: 17 | Batch_idx: 280 |  Loss: (0.5838) | Acc: (80.00%) (28798/35968)
Epoch: 17 | Batch_idx: 290 |  Loss: (0.5808) | Acc: (80.00%) (29864/37248)
Epoch: 17 | Batch_idx: 300 |  Loss: (0.5802) | Acc: (80.00%) (30916/38528)
Epoch: 17 | Batch_idx: 310 |  Loss: (0.5786) | Acc: (80.00%) (31966/39808)
Epoch: 17 | Batch_idx: 320 |  Loss: (0.5766) | Acc: (80.00%) (33028/41088)
Epoch: 17 | Batch_idx: 330 |  Loss: (0.5745) | Acc: (80.00%) (34076/42368)
Epoch: 17 | Batch_idx: 340 |  Loss: (0.5730) | Acc: (80.00%) (35134/43648)
Epoch: 17 | Batch_idx: 350 |  Loss: (0.5702) | Acc: (80.00%) (36207/44928)
Epoch: 17 | Batch_idx: 360 |  Loss: (0.5692) | Acc: (80.00%) (37256/46208)
Epoch: 17 | Batch_idx: 370 |  Loss: (0.5671) | Acc: (80.00%) (38311/47488)
Epoch: 17 | Batch_idx: 380 |  Loss: (0.5653) | Acc: (80.00%) (39372/48768)
Epoch: 17 | Batch_idx: 390 |  Loss: (0.5637) | Acc: (80.00%) (40396/50000)
# TEST : Loss: (0.5203) | Acc: (82.00%) (8235/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-0.0405, -0.0016,  0.0005],
          [ 0.0047,  0.0490, -0.0318],
          [ 0.0211, -0.0366, -0.0533]],

         [[-0.0767,  0.0161,  0.0237],
          [ 0.0145,  0.0152, -0.0413],
          [ 0.0079, -0.0372, -0.0024]],

         [[-0.0199, -0.0341,  0.0205],
          [-0.0250,  0.0281, -0.0054],
          [ 0.0291, -0.0054, -0.0500]]],


        [[[ 0.0783, -0.0589,  0.0305],
          [ 0.0442, -0.2356, -0.0304],
          [ 0.0412, -0.0033,  0.0269]],

         [[-0.0042, -0.1040, -0.0612],
          [-0.0798, -0.3208, -0.0594],
          [-0.0121,  0.0120,  0.0906]],

         [[ 0.0414,  0.0328,  0.0828],
          [ 0.0653, -0.1326,  0.0239],
          [ 0.0002, -0.0277,  0.0005]]],


        [[[ 0.0910, -0.0320,  0.1090],
          [ 0.1166,  0.0769,  0.1694],
          [ 0.0393, -0.0039, -0.0669]],

         [[ 0.2263,  0.0878, -0.0168],
          [ 0.1190,  0.0871, -0.0157],
          [ 0.1447, -0.0667,  0.1494]],

         [[-0.0392,  0.1166, -0.1206],
          [-0.0598, -0.1416,  0.0984],
          [-0.0624, -0.0149, -0.0493]]],


        ...,


        [[[-0.0983,  0.1108, -0.1269],
          [-0.2143, -0.0788, -0.1432],
          [-0.0958,  0.0936, -0.2434]],

         [[ 0.0764,  0.0338,  0.0156],
          [ 0.1134, -0.1659,  0.0464],
          [ 0.0398,  0.1192, -0.1795]],

         [[-0.1126,  0.2259,  0.0752],
          [ 0.2063,  0.1532,  0.1416],
          [ 0.1803,  0.1291, -0.0794]]],


        [[[ 0.0525, -0.1172, -0.0037],
          [ 0.0498, -0.0680,  0.0769],
          [ 0.0870, -0.1144,  0.0416]],

         [[ 0.1568, -0.1462,  0.0610],
          [-0.1352,  0.0550, -0.1092],
          [ 0.0364,  0.1261, -0.0098]],

         [[-0.0459, -0.0961,  0.0890],
          [-0.1308, -0.3104, -0.2487],
          [ 0.0382, -0.0697, -0.1487]]],


        [[[-0.0544, -0.0078, -0.1326],
          [ 0.0977, -0.0020, -0.1475],
          [ 0.0972, -0.0424, -0.0449]],

         [[ 0.1012,  0.0493, -0.1390],
          [ 0.0390,  0.0168,  0.0558],
          [-0.0780, -0.0713,  0.1667]],

         [[ 0.0539, -0.1392, -0.0280],
          [-0.0011,  0.1250,  0.0795],
          [-0.1865, -0.0948, -0.0276]]]], device='cuda:0')

conv1_weight_grad tensor([[[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        ...,


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]]], device='cuda:0')

percentage_weight tensor([0.], device='cuda:0', requires_grad=True)

percentage_weight_grad tensor([-25.8545], device='cuda:0')

Epoch: 18 | Batch_idx: 0 |  Loss: (0.4914) | Acc: (83.00%) (107/128)
Epoch: 18 | Batch_idx: 10 |  Loss: (0.5576) | Acc: (80.00%) (1133/1408)
Epoch: 18 | Batch_idx: 20 |  Loss: (0.5385) | Acc: (81.00%) (2202/2688)
Epoch: 18 | Batch_idx: 30 |  Loss: (0.5241) | Acc: (82.00%) (3272/3968)
Epoch: 18 | Batch_idx: 40 |  Loss: (0.5061) | Acc: (82.00%) (4351/5248)
Epoch: 18 | Batch_idx: 50 |  Loss: (0.5055) | Acc: (82.00%) (5416/6528)
Epoch: 18 | Batch_idx: 60 |  Loss: (0.5056) | Acc: (83.00%) (6483/7808)
Epoch: 18 | Batch_idx: 70 |  Loss: (0.5077) | Acc: (83.00%) (7545/9088)
Epoch: 18 | Batch_idx: 80 |  Loss: (0.5067) | Acc: (83.00%) (8615/10368)
Epoch: 18 | Batch_idx: 90 |  Loss: (0.5056) | Acc: (83.00%) (9678/11648)
Epoch: 18 | Batch_idx: 100 |  Loss: (0.5077) | Acc: (83.00%) (10734/12928)
Epoch: 18 | Batch_idx: 110 |  Loss: (0.5057) | Acc: (83.00%) (11798/14208)
Epoch: 18 | Batch_idx: 120 |  Loss: (0.5041) | Acc: (83.00%) (12876/15488)
Epoch: 18 | Batch_idx: 130 |  Loss: (0.5014) | Acc: (83.00%) (13954/16768)
Epoch: 18 | Batch_idx: 140 |  Loss: (0.5014) | Acc: (83.00%) (15011/18048)
Epoch: 18 | Batch_idx: 150 |  Loss: (0.5005) | Acc: (83.00%) (16086/19328)
Epoch: 18 | Batch_idx: 160 |  Loss: (0.4996) | Acc: (83.00%) (17166/20608)
Epoch: 18 | Batch_idx: 170 |  Loss: (0.5005) | Acc: (83.00%) (18224/21888)
Epoch: 18 | Batch_idx: 180 |  Loss: (0.5000) | Acc: (83.00%) (19302/23168)
Epoch: 18 | Batch_idx: 190 |  Loss: (0.4972) | Acc: (83.00%) (20394/24448)
Epoch: 18 | Batch_idx: 200 |  Loss: (0.4966) | Acc: (83.00%) (21472/25728)
Epoch: 18 | Batch_idx: 210 |  Loss: (0.4965) | Acc: (83.00%) (22549/27008)
Epoch: 18 | Batch_idx: 220 |  Loss: (0.4957) | Acc: (83.00%) (23621/28288)
Epoch: 18 | Batch_idx: 230 |  Loss: (0.4960) | Acc: (83.00%) (24674/29568)
Epoch: 18 | Batch_idx: 240 |  Loss: (0.4954) | Acc: (83.00%) (25737/30848)
Epoch: 18 | Batch_idx: 250 |  Loss: (0.4938) | Acc: (83.00%) (26823/32128)
Epoch: 18 | Batch_idx: 260 |  Loss: (0.4930) | Acc: (83.00%) (27920/33408)
Epoch: 18 | Batch_idx: 270 |  Loss: (0.4927) | Acc: (83.00%) (28988/34688)
Epoch: 18 | Batch_idx: 280 |  Loss: (0.4914) | Acc: (83.00%) (30070/35968)
Epoch: 18 | Batch_idx: 290 |  Loss: (0.4914) | Acc: (83.00%) (31143/37248)
Epoch: 18 | Batch_idx: 300 |  Loss: (0.4915) | Acc: (83.00%) (32205/38528)
Epoch: 18 | Batch_idx: 310 |  Loss: (0.4903) | Acc: (83.00%) (33296/39808)
Epoch: 18 | Batch_idx: 320 |  Loss: (0.4896) | Acc: (83.00%) (34380/41088)
Epoch: 18 | Batch_idx: 330 |  Loss: (0.4882) | Acc: (83.00%) (35485/42368)
Epoch: 18 | Batch_idx: 340 |  Loss: (0.4874) | Acc: (83.00%) (36566/43648)
Epoch: 18 | Batch_idx: 350 |  Loss: (0.4881) | Acc: (83.00%) (37626/44928)
Epoch: 18 | Batch_idx: 360 |  Loss: (0.4886) | Acc: (83.00%) (38689/46208)
Epoch: 18 | Batch_idx: 370 |  Loss: (0.4884) | Acc: (83.00%) (39772/47488)
Epoch: 18 | Batch_idx: 380 |  Loss: (0.4892) | Acc: (83.00%) (40812/48768)
Epoch: 18 | Batch_idx: 390 |  Loss: (0.4902) | Acc: (83.00%) (41828/50000)
# TEST : Loss: (0.4923) | Acc: (83.00%) (8327/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-0.0313, -0.0012,  0.0004],
          [ 0.0037,  0.0389, -0.0247],
          [ 0.0170, -0.0287, -0.0403]],

         [[-0.0589,  0.0127,  0.0189],
          [ 0.0113,  0.0120, -0.0318],
          [ 0.0063, -0.0289, -0.0018]],

         [[-0.0152, -0.0267,  0.0162],
          [-0.0194,  0.0220, -0.0041],
          [ 0.0231, -0.0042, -0.0371]]],


        [[[ 0.0768, -0.0575,  0.0300],
          [ 0.0431, -0.2247, -0.0297],
          [ 0.0404, -0.0032,  0.0264]],

         [[-0.0041, -0.1011, -0.0601],
          [-0.0777, -0.2974, -0.0579],
          [-0.0119,  0.0117,  0.0890]],

         [[ 0.0405,  0.0318,  0.0810],
          [ 0.0635, -0.1258,  0.0232],
          [ 0.0002, -0.0269,  0.0005]]],


        [[[ 0.0855, -0.0299,  0.1027],
          [ 0.1092,  0.0719,  0.1595],
          [ 0.0373, -0.0037, -0.0641]],

         [[ 0.2168,  0.0838, -0.0160],
          [ 0.1138,  0.0831, -0.0150],
          [ 0.1384, -0.0640,  0.1435]],

         [[-0.0383,  0.1140, -0.1177],
          [-0.0585, -0.1384,  0.0961],
          [-0.0609, -0.0145, -0.0480]]],


        ...,


        [[[-0.0981,  0.1106, -0.1267],
          [-0.2139, -0.0787, -0.1429],
          [-0.0956,  0.0934, -0.2430]],

         [[ 0.0762,  0.0338,  0.0155],
          [ 0.1132, -0.1656,  0.0463],
          [ 0.0397,  0.1190, -0.1792]],

         [[-0.1124,  0.2254,  0.0750],
          [ 0.2059,  0.1528,  0.1413],
          [ 0.1800,  0.1288, -0.0793]]],


        [[[ 0.0519, -0.1157, -0.0036],
          [ 0.0492, -0.0670,  0.0759],
          [ 0.0861, -0.1130,  0.0411]],

         [[ 0.1546, -0.1435,  0.0600],
          [-0.1331,  0.0538, -0.1071],
          [ 0.0359,  0.1242, -0.0097]],

         [[-0.0450, -0.0928,  0.0866],
          [-0.1273, -0.2816, -0.2358],
          [ 0.0375, -0.0677, -0.1451]]],


        [[[-0.0526, -0.0075, -0.1276],
          [ 0.0937, -0.0019, -0.1423],
          [ 0.0937, -0.0411, -0.0435]],

         [[ 0.0977,  0.0474, -0.1339],
          [ 0.0374,  0.0162,  0.0539],
          [-0.0751, -0.0689,  0.1614]],

         [[ 0.0521, -0.1341, -0.0270],
          [-0.0010,  0.1203,  0.0767],
          [-0.1800, -0.0915, -0.0267]]]], device='cuda:0')

conv1_weight_grad tensor([[[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        ...,


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]]], device='cuda:0')

percentage_weight tensor([0.], device='cuda:0', requires_grad=True)

percentage_weight_grad tensor([-27.7257], device='cuda:0')

True Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False _Gate(
  (sig): Sigmoid()
)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False _Gate(
  (sig): Sigmoid()
)
True Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False _Gate(
  (sig): Sigmoid()
)
True Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False _Gate(
  (sig): Sigmoid()
)
True Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False _Gate(
  (sig): Sigmoid()
)
True Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False _Gate(
  (sig): Sigmoid()
)
True Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False _Gate(
  (sig): Sigmoid()
)
True Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False _Gate(
  (sig): Sigmoid()
)
True Linear(in_features=512, out_features=10, bias=True)
Epoch: 19 | Batch_idx: 0 |  Loss: (0.3382) | Acc: (85.00%) (110/128)
Epoch: 19 | Batch_idx: 10 |  Loss: (0.4619) | Acc: (83.00%) (1181/1408)
Epoch: 19 | Batch_idx: 20 |  Loss: (0.4871) | Acc: (83.00%) (2235/2688)
Epoch: 19 | Batch_idx: 30 |  Loss: (0.5077) | Acc: (82.00%) (3282/3968)
Epoch: 19 | Batch_idx: 40 |  Loss: (0.5288) | Acc: (82.00%) (4312/5248)
Epoch: 19 | Batch_idx: 50 |  Loss: (0.5506) | Acc: (81.00%) (5310/6528)
Epoch: 19 | Batch_idx: 60 |  Loss: (0.5498) | Acc: (81.00%) (6349/7808)
Epoch: 19 | Batch_idx: 70 |  Loss: (0.5480) | Acc: (81.00%) (7414/9088)
Epoch: 19 | Batch_idx: 80 |  Loss: (0.5434) | Acc: (81.00%) (8466/10368)
Epoch: 19 | Batch_idx: 90 |  Loss: (0.5409) | Acc: (81.00%) (9529/11648)
Epoch: 19 | Batch_idx: 100 |  Loss: (0.5454) | Acc: (81.00%) (10566/12928)
Epoch: 19 | Batch_idx: 110 |  Loss: (0.5469) | Acc: (81.00%) (11606/14208)
Epoch: 19 | Batch_idx: 120 |  Loss: (0.5492) | Acc: (81.00%) (12635/15488)
Epoch: 19 | Batch_idx: 130 |  Loss: (0.5512) | Acc: (81.00%) (13669/16768)
Epoch: 19 | Batch_idx: 140 |  Loss: (0.5517) | Acc: (81.00%) (14705/18048)
Epoch: 19 | Batch_idx: 150 |  Loss: (0.5538) | Acc: (81.00%) (15733/19328)
Epoch: 19 | Batch_idx: 160 |  Loss: (0.5533) | Acc: (81.00%) (16776/20608)
Epoch: 19 | Batch_idx: 170 |  Loss: (0.5514) | Acc: (81.00%) (17827/21888)
Epoch: 19 | Batch_idx: 180 |  Loss: (0.5508) | Acc: (81.00%) (18872/23168)
Epoch: 19 | Batch_idx: 190 |  Loss: (0.5506) | Acc: (81.00%) (19911/24448)
Epoch: 19 | Batch_idx: 200 |  Loss: (0.5478) | Acc: (81.00%) (20973/25728)
Epoch: 19 | Batch_idx: 210 |  Loss: (0.5457) | Acc: (81.00%) (22046/27008)
Epoch: 19 | Batch_idx: 220 |  Loss: (0.5448) | Acc: (81.00%) (23080/28288)
Epoch: 19 | Batch_idx: 230 |  Loss: (0.5431) | Acc: (81.00%) (24145/29568)
Epoch: 19 | Batch_idx: 240 |  Loss: (0.5437) | Acc: (81.00%) (25181/30848)
Epoch: 19 | Batch_idx: 250 |  Loss: (0.5437) | Acc: (81.00%) (26225/32128)
Epoch: 19 | Batch_idx: 260 |  Loss: (0.5424) | Acc: (81.00%) (27288/33408)
Epoch: 19 | Batch_idx: 270 |  Loss: (0.5414) | Acc: (81.00%) (28339/34688)
Epoch: 19 | Batch_idx: 280 |  Loss: (0.5395) | Acc: (81.00%) (29408/35968)
Epoch: 19 | Batch_idx: 290 |  Loss: (0.5371) | Acc: (81.00%) (30479/37248)
Epoch: 19 | Batch_idx: 300 |  Loss: (0.5358) | Acc: (81.00%) (31533/38528)
Epoch: 19 | Batch_idx: 310 |  Loss: (0.5338) | Acc: (81.00%) (32598/39808)
Epoch: 19 | Batch_idx: 320 |  Loss: (0.5312) | Acc: (81.00%) (33685/41088)
Epoch: 19 | Batch_idx: 330 |  Loss: (0.5310) | Acc: (81.00%) (34741/42368)
Epoch: 19 | Batch_idx: 340 |  Loss: (0.5312) | Acc: (81.00%) (35780/43648)
Epoch: 19 | Batch_idx: 350 |  Loss: (0.5301) | Acc: (82.00%) (36843/44928)
Epoch: 19 | Batch_idx: 360 |  Loss: (0.5289) | Acc: (82.00%) (37916/46208)
Epoch: 19 | Batch_idx: 370 |  Loss: (0.5274) | Acc: (82.00%) (38998/47488)
Epoch: 19 | Batch_idx: 380 |  Loss: (0.5263) | Acc: (82.00%) (40064/48768)
Epoch: 19 | Batch_idx: 390 |  Loss: (0.5241) | Acc: (82.00%) (41112/50000)
# TEST : Loss: (0.5876) | Acc: (81.00%) (8121/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-0.0252, -0.0023,  0.0028],
          [-0.0011,  0.0245, -0.0215],
          [ 0.0106, -0.0239, -0.0296]],

         [[-0.0457,  0.0074,  0.0160],
          [ 0.0047,  0.0038, -0.0273],
          [ 0.0028, -0.0235, -0.0023]],

         [[-0.0133, -0.0216,  0.0138],
          [-0.0175,  0.0120, -0.0069],
          [ 0.0164, -0.0048, -0.0272]]],


        [[[ 0.0671, -0.0690,  0.0348],
          [ 0.0379, -0.2441, -0.0265],
          [ 0.0389, -0.0062,  0.0318]],

         [[-0.0144, -0.1150, -0.0637],
          [-0.0822, -0.3215, -0.0619],
          [-0.0113,  0.0105,  0.0894]],

         [[ 0.0326,  0.0238,  0.0742],
          [ 0.0625, -0.1244,  0.0222],
          [ 0.0010, -0.0244,  0.0012]]],


        [[[ 0.0824, -0.0311,  0.0837],
          [ 0.1133,  0.0663,  0.1349],
          [ 0.0231, -0.0257, -0.0900]],

         [[ 0.2231,  0.0943, -0.0064],
          [ 0.1358,  0.1021, -0.0032],
          [ 0.1382, -0.0622,  0.1283]],

         [[-0.0145,  0.1359, -0.0881],
          [-0.0304, -0.1071,  0.1203],
          [-0.0403,  0.0049, -0.0299]]],


        ...,


        [[[-0.0997,  0.1079, -0.1312],
          [-0.2175, -0.0860, -0.1483],
          [-0.0976,  0.0875, -0.2477]],

         [[ 0.0773,  0.0374,  0.0171],
          [ 0.1147, -0.1628,  0.0501],
          [ 0.0435,  0.1225, -0.1765]],

         [[-0.1121,  0.2298,  0.0768],
          [ 0.2070,  0.1584,  0.1480],
          [ 0.1797,  0.1323, -0.0758]]],


        [[[ 0.0580, -0.1209, -0.0032],
          [ 0.0490, -0.0868,  0.0662],
          [ 0.0870, -0.1248,  0.0255]],

         [[ 0.1597, -0.1514,  0.0521],
          [-0.1234,  0.0380, -0.1088],
          [ 0.0478,  0.1221, -0.0156]],

         [[-0.0416, -0.1057,  0.0636],
          [-0.1131, -0.2894, -0.2382],
          [ 0.0444, -0.0742, -0.1634]]],


        [[[-0.0483, -0.0150, -0.1214],
          [ 0.0804, -0.0228, -0.1310],
          [ 0.0731, -0.0580, -0.0368]],

         [[ 0.1061,  0.0476, -0.1233],
          [ 0.0430,  0.0109,  0.0639],
          [-0.0742, -0.0698,  0.1677]],

         [[ 0.0515, -0.1312, -0.0239],
          [-0.0093,  0.0973,  0.0749],
          [-0.1874, -0.1087, -0.0305]]]], device='cuda:0', requires_grad=True)

conv1_weight_grad tensor([[[[-1.5681e-08, -9.4672e-06, -6.2527e-06],
          [ 1.3161e-06, -3.2304e-07, -2.0160e-07],
          [ 1.3434e-06, -2.1459e-07, -1.2906e-07]],

         [[-1.3426e-07, -9.6868e-06, -6.6377e-06],
          [ 1.2619e-06, -4.3901e-07, -3.1385e-07],
          [ 1.3140e-06, -3.2147e-07, -2.3573e-07]],

         [[-2.6693e-07, -9.1121e-06, -6.1586e-06],
          [ 1.0399e-06, -5.3881e-07, -4.2645e-07],
          [ 1.0787e-06, -4.3799e-07, -3.6218e-07]]],


        [[[-1.1615e-03, -2.2050e-03, -1.1202e-03],
          [ 2.7873e-04, -1.4802e-04,  1.2348e-03],
          [-4.0076e-03, -4.6678e-03, -2.8394e-03]],

         [[-1.2278e-03, -2.3931e-03, -1.3501e-03],
          [ 2.2717e-04, -4.5505e-04,  8.9508e-04],
          [-3.5538e-03, -4.5854e-03, -2.8347e-03]],

         [[-1.0913e-03, -1.9422e-03, -1.2699e-03],
          [-1.5724e-04, -5.9391e-04,  4.7474e-04],
          [-2.9452e-03, -3.6794e-03, -2.1741e-03]]],


        [[[-6.4190e-06, -4.0930e-05, -1.7716e-04],
          [ 5.6133e-05,  1.2159e-04,  1.2978e-04],
          [ 4.8855e-04,  5.1989e-04,  4.1396e-04]],

         [[-7.7273e-05, -2.8697e-04, -5.3470e-04],
          [ 5.9463e-05,  1.3149e-05, -7.0176e-05],
          [ 4.6438e-04,  4.3470e-04,  2.8410e-04]],

         [[-2.1829e-05, -2.9045e-04, -6.3525e-04],
          [ 6.2588e-05,  4.9285e-05, -5.7325e-05],
          [ 4.1395e-04,  4.6398e-04,  3.4105e-04]]],


        ...,


        [[[-2.3283e-02, -2.7891e-02, -2.8069e-02],
          [-1.0322e-02, -1.8626e-02, -2.4745e-02],
          [ 1.3823e-03, -3.1905e-03, -1.1538e-02]],

         [[-2.7556e-02, -3.0290e-02, -2.9676e-02],
          [-1.1792e-02, -1.8834e-02, -2.5168e-02],
          [-5.8102e-05, -3.5500e-03, -1.2078e-02]],

         [[-1.9268e-02, -2.4096e-02, -2.3523e-02],
          [-7.2315e-03, -1.5404e-02, -2.1292e-02],
          [ 2.1879e-03, -2.0084e-03, -9.1021e-03]]],


        [[[ 5.5729e-04, -9.5637e-04, -1.2136e-03],
          [ 1.1605e-03, -1.5750e-04, -4.1567e-04],
          [-3.0528e-03, -4.1948e-03, -4.1448e-03]],

         [[ 1.0974e-03, -5.7598e-04, -1.0308e-03],
          [ 1.3134e-03,  1.0611e-04, -1.1729e-05],
          [-2.6278e-03, -3.7499e-03, -3.5769e-03]],

         [[ 1.1376e-03, -1.7502e-04, -5.7143e-04],
          [ 1.2874e-03,  2.9767e-04,  1.7298e-04],
          [-1.5260e-03, -2.4503e-03, -2.2019e-03]]],


        [[[-2.6821e-04, -1.6502e-04, -2.4980e-05],
          [-3.1784e-04, -2.1314e-04, -6.4117e-05],
          [-3.1383e-04, -2.3086e-04, -1.5996e-04]],

         [[ 2.3074e-06, -8.3817e-05, -1.2125e-05],
          [-4.2357e-05, -1.1627e-04, -2.9303e-05],
          [-6.7773e-05, -1.5003e-04, -1.1962e-04]],

         [[ 1.2975e-04, -6.5210e-05, -5.8031e-05],
          [ 1.0816e-04, -8.1737e-05, -6.5760e-05],
          [ 6.0725e-05, -1.2555e-04, -1.4039e-04]]]], device='cuda:0')

percentage_weight tensor([0.], device='cuda:0')

percentage_weight_grad tensor([-27.7257], device='cuda:0')

Epoch: 20 | Batch_idx: 0 |  Loss: (0.4575) | Acc: (84.00%) (108/128)
Epoch: 20 | Batch_idx: 10 |  Loss: (0.4716) | Acc: (84.00%) (1189/1408)
Epoch: 20 | Batch_idx: 20 |  Loss: (0.4769) | Acc: (84.00%) (2261/2688)
Epoch: 20 | Batch_idx: 30 |  Loss: (0.4812) | Acc: (84.00%) (3348/3968)
Epoch: 20 | Batch_idx: 40 |  Loss: (0.4627) | Acc: (84.00%) (4451/5248)
Epoch: 20 | Batch_idx: 50 |  Loss: (0.4562) | Acc: (84.00%) (5539/6528)
Epoch: 20 | Batch_idx: 60 |  Loss: (0.4589) | Acc: (84.00%) (6614/7808)
Epoch: 20 | Batch_idx: 70 |  Loss: (0.4606) | Acc: (84.00%) (7682/9088)
Epoch: 20 | Batch_idx: 80 |  Loss: (0.4638) | Acc: (84.00%) (8746/10368)
Epoch: 20 | Batch_idx: 90 |  Loss: (0.4643) | Acc: (84.00%) (9831/11648)
Epoch: 20 | Batch_idx: 100 |  Loss: (0.4581) | Acc: (84.00%) (10923/12928)
Epoch: 20 | Batch_idx: 110 |  Loss: (0.4558) | Acc: (84.00%) (12016/14208)
Epoch: 20 | Batch_idx: 120 |  Loss: (0.4566) | Acc: (84.00%) (13097/15488)
Epoch: 20 | Batch_idx: 130 |  Loss: (0.4548) | Acc: (84.00%) (14178/16768)
Epoch: 20 | Batch_idx: 140 |  Loss: (0.4537) | Acc: (84.00%) (15275/18048)
Epoch: 20 | Batch_idx: 150 |  Loss: (0.4564) | Acc: (84.00%) (16331/19328)
Epoch: 20 | Batch_idx: 160 |  Loss: (0.4571) | Acc: (84.00%) (17399/20608)
Epoch: 20 | Batch_idx: 170 |  Loss: (0.4570) | Acc: (84.00%) (18492/21888)
Epoch: 20 | Batch_idx: 180 |  Loss: (0.4565) | Acc: (84.00%) (19577/23168)
Epoch: 20 | Batch_idx: 190 |  Loss: (0.4535) | Acc: (84.00%) (20688/24448)
Epoch: 20 | Batch_idx: 200 |  Loss: (0.4545) | Acc: (84.00%) (21763/25728)
Epoch: 20 | Batch_idx: 210 |  Loss: (0.4529) | Acc: (84.00%) (22859/27008)
Epoch: 20 | Batch_idx: 220 |  Loss: (0.4536) | Acc: (84.00%) (23929/28288)
Epoch: 20 | Batch_idx: 230 |  Loss: (0.4527) | Acc: (84.00%) (25018/29568)
Epoch: 20 | Batch_idx: 240 |  Loss: (0.4530) | Acc: (84.00%) (26093/30848)
Epoch: 20 | Batch_idx: 250 |  Loss: (0.4527) | Acc: (84.00%) (27178/32128)
Epoch: 20 | Batch_idx: 260 |  Loss: (0.4511) | Acc: (84.00%) (28272/33408)
Epoch: 20 | Batch_idx: 270 |  Loss: (0.4527) | Acc: (84.00%) (29336/34688)
Epoch: 20 | Batch_idx: 280 |  Loss: (0.4519) | Acc: (84.00%) (30418/35968)
Epoch: 20 | Batch_idx: 290 |  Loss: (0.4522) | Acc: (84.00%) (31506/37248)
Epoch: 20 | Batch_idx: 300 |  Loss: (0.4524) | Acc: (84.00%) (32587/38528)
Epoch: 20 | Batch_idx: 310 |  Loss: (0.4512) | Acc: (84.00%) (33666/39808)
Epoch: 20 | Batch_idx: 320 |  Loss: (0.4489) | Acc: (84.00%) (34770/41088)
Epoch: 20 | Batch_idx: 330 |  Loss: (0.4494) | Acc: (84.00%) (35852/42368)
Epoch: 20 | Batch_idx: 340 |  Loss: (0.4488) | Acc: (84.00%) (36949/43648)
Epoch: 20 | Batch_idx: 350 |  Loss: (0.4485) | Acc: (84.00%) (38036/44928)
Epoch: 20 | Batch_idx: 360 |  Loss: (0.4468) | Acc: (84.00%) (39152/46208)
Epoch: 20 | Batch_idx: 370 |  Loss: (0.4462) | Acc: (84.00%) (40260/47488)
Epoch: 20 | Batch_idx: 380 |  Loss: (0.4452) | Acc: (84.00%) (41371/48768)
Epoch: 20 | Batch_idx: 390 |  Loss: (0.4445) | Acc: (84.00%) (42424/50000)
# TEST : Loss: (0.5548) | Acc: (82.00%) (8209/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-0.0175, -0.0023,  0.0004],
          [-0.0015,  0.0172, -0.0151],
          [ 0.0071, -0.0171, -0.0199]],

         [[-0.0314,  0.0045,  0.0099],
          [ 0.0025,  0.0022, -0.0190],
          [ 0.0011, -0.0167, -0.0018]],

         [[-0.0093, -0.0158,  0.0084],
          [-0.0130,  0.0079, -0.0051],
          [ 0.0108, -0.0037, -0.0180]]],


        [[[ 0.0814, -0.0654,  0.0368],
          [ 0.0557, -0.2390, -0.0200],
          [ 0.0460, -0.0092,  0.0249]],

         [[-0.0034, -0.1175, -0.0657],
          [-0.0681, -0.3338, -0.0655],
          [-0.0058,  0.0011,  0.0756]],

         [[ 0.0405,  0.0146,  0.0663],
          [ 0.0706, -0.1385,  0.0177],
          [-0.0006, -0.0363, -0.0134]]],


        [[[ 0.0695, -0.0305,  0.0764],
          [ 0.0869,  0.0493,  0.1261],
          [ 0.0202, -0.0199, -0.0708]],

         [[ 0.2124,  0.0938, -0.0018],
          [ 0.1207,  0.0955,  0.0062],
          [ 0.1308, -0.0500,  0.1431]],

         [[-0.0207,  0.1287, -0.0886],
          [-0.0439, -0.1129,  0.1144],
          [-0.0501,  0.0018, -0.0219]]],


        ...,


        [[[-0.0979,  0.1110, -0.1286],
          [-0.2213, -0.0903, -0.1535],
          [-0.1023,  0.0805, -0.2564]],

         [[ 0.0769,  0.0411,  0.0190],
          [ 0.1120, -0.1626,  0.0473],
          [ 0.0405,  0.1196, -0.1830]],

         [[-0.1125,  0.2362,  0.0803],
          [ 0.2038,  0.1622,  0.1490],
          [ 0.1741,  0.1318, -0.0787]]],


        [[[ 0.0564, -0.1332, -0.0167],
          [ 0.0400, -0.1085,  0.0551],
          [ 0.0804, -0.1380,  0.0198]],

         [[ 0.1598, -0.1616,  0.0382],
          [-0.1246,  0.0141, -0.1162],
          [ 0.0492,  0.1123, -0.0172]],

         [[-0.0243, -0.1020,  0.0585],
          [-0.0977, -0.2939, -0.2265],
          [ 0.0575, -0.0714, -0.1560]]],


        [[[-0.0478, -0.0144, -0.1158],
          [ 0.0780, -0.0222, -0.1268],
          [ 0.0723, -0.0563, -0.0371]],

         [[ 0.0988,  0.0454, -0.1161],
          [ 0.0397,  0.0104,  0.0625],
          [-0.0720, -0.0676,  0.1616]],

         [[ 0.0457, -0.1263, -0.0214],
          [-0.0108,  0.0933,  0.0732],
          [-0.1812, -0.1036, -0.0278]]]], device='cuda:0', requires_grad=True)

conv1_weight_grad tensor([[[[-0.0000, -0.0000, -0.0000],
          [-0.0000, -0.0000, -0.0000],
          [-0.0000, -0.0000, -0.0000]],

         [[-0.0000, -0.0000, -0.0000],
          [-0.0000, -0.0000, -0.0000],
          [-0.0000, -0.0000, -0.0000]],

         [[-0.0000, -0.0000, -0.0000],
          [-0.0000, -0.0000, -0.0000],
          [-0.0000, -0.0000, -0.0000]]],


        [[[ 0.0054,  0.0032,  0.0013],
          [ 0.0032,  0.0008,  0.0003],
          [ 0.0030,  0.0004,  0.0001]],

         [[ 0.0042,  0.0020,  0.0002],
          [ 0.0024,  0.0004, -0.0004],
          [ 0.0021, -0.0001, -0.0006]],

         [[ 0.0028,  0.0012, -0.0002],
          [ 0.0015,  0.0001, -0.0007],
          [ 0.0015,  0.0002, -0.0006]]],


        [[[-0.0003, -0.0004, -0.0005],
          [-0.0002, -0.0001, -0.0002],
          [-0.0000,  0.0001, -0.0003]],

         [[ 0.0003,  0.0002,  0.0001],
          [ 0.0003,  0.0004,  0.0003],
          [ 0.0005,  0.0006,  0.0001]],

         [[ 0.0013,  0.0012,  0.0012],
          [ 0.0012,  0.0013,  0.0012],
          [ 0.0014,  0.0015,  0.0011]]],


        ...,


        [[[ 0.0097,  0.0098,  0.0203],
          [ 0.0272,  0.0307,  0.0397],
          [ 0.0461,  0.0494,  0.0657]],

         [[ 0.0076,  0.0096,  0.0225],
          [ 0.0249,  0.0308,  0.0425],
          [ 0.0453,  0.0505,  0.0686]],

         [[ 0.0224,  0.0243,  0.0365],
          [ 0.0358,  0.0403,  0.0501],
          [ 0.0520,  0.0542,  0.0685]]],


        [[[ 0.0107,  0.0071,  0.0079],
          [ 0.0056,  0.0030,  0.0056],
          [ 0.0071,  0.0040,  0.0051]],

         [[ 0.0080,  0.0044,  0.0056],
          [ 0.0031,  0.0006,  0.0030],
          [ 0.0036,  0.0007,  0.0018]],

         [[ 0.0046,  0.0022,  0.0038],
          [ 0.0004, -0.0009,  0.0012],
          [ 0.0008, -0.0004,  0.0005]]],


        [[[-0.0001, -0.0001, -0.0001],
          [-0.0000, -0.0001, -0.0001],
          [ 0.0001, -0.0000, -0.0001]],

         [[-0.0002, -0.0002, -0.0001],
          [-0.0001, -0.0001, -0.0001],
          [-0.0000, -0.0001, -0.0001]],

         [[-0.0001, -0.0001, -0.0001],
          [-0.0000, -0.0001, -0.0001],
          [ 0.0000, -0.0001, -0.0001]]]], device='cuda:0')

percentage_weight tensor([0.], device='cuda:0')

percentage_weight_grad tensor([-27.7257], device='cuda:0')

False Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True _Gate(
  (sig): Sigmoid()
)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True _Gate(
  (sig): Sigmoid()
)
False Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True _Gate(
  (sig): Sigmoid()
)
False Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True _Gate(
  (sig): Sigmoid()
)
False Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True _Gate(
  (sig): Sigmoid()
)
False Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True _Gate(
  (sig): Sigmoid()
)
False Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True _Gate(
  (sig): Sigmoid()
)
False Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True _Gate(
  (sig): Sigmoid()
)
False Linear(in_features=512, out_features=10, bias=True)
Epoch: 21 | Batch_idx: 0 |  Loss: (0.4691) | Acc: (84.00%) (108/128)
Epoch: 21 | Batch_idx: 10 |  Loss: (0.3851) | Acc: (88.00%) (1240/1408)
Epoch: 21 | Batch_idx: 20 |  Loss: (0.4382) | Acc: (85.00%) (2303/2688)
Epoch: 21 | Batch_idx: 30 |  Loss: (0.4582) | Acc: (84.00%) (3362/3968)
Epoch: 21 | Batch_idx: 40 |  Loss: (0.4626) | Acc: (84.00%) (4437/5248)
Epoch: 21 | Batch_idx: 50 |  Loss: (0.4586) | Acc: (84.00%) (5511/6528)
Epoch: 21 | Batch_idx: 60 |  Loss: (0.4657) | Acc: (84.00%) (6574/7808)
Epoch: 21 | Batch_idx: 70 |  Loss: (0.4665) | Acc: (84.00%) (7658/9088)
Epoch: 21 | Batch_idx: 80 |  Loss: (0.4673) | Acc: (84.00%) (8749/10368)
Epoch: 21 | Batch_idx: 90 |  Loss: (0.4698) | Acc: (84.00%) (9821/11648)
Epoch: 21 | Batch_idx: 100 |  Loss: (0.4701) | Acc: (84.00%) (10894/12928)
Epoch: 21 | Batch_idx: 110 |  Loss: (0.4684) | Acc: (84.00%) (11976/14208)
Epoch: 21 | Batch_idx: 120 |  Loss: (0.4659) | Acc: (84.00%) (13058/15488)
Epoch: 21 | Batch_idx: 130 |  Loss: (0.4639) | Acc: (84.00%) (14154/16768)
Epoch: 21 | Batch_idx: 140 |  Loss: (0.4629) | Acc: (84.00%) (15245/18048)
Epoch: 21 | Batch_idx: 150 |  Loss: (0.4634) | Acc: (84.00%) (16327/19328)
Epoch: 21 | Batch_idx: 160 |  Loss: (0.4595) | Acc: (84.00%) (17428/20608)
Epoch: 21 | Batch_idx: 170 |  Loss: (0.4559) | Acc: (84.00%) (18541/21888)
Epoch: 21 | Batch_idx: 180 |  Loss: (0.4549) | Acc: (84.00%) (19638/23168)
Epoch: 21 | Batch_idx: 190 |  Loss: (0.4515) | Acc: (84.00%) (20746/24448)
Epoch: 21 | Batch_idx: 200 |  Loss: (0.4518) | Acc: (84.00%) (21825/25728)
Epoch: 21 | Batch_idx: 210 |  Loss: (0.4497) | Acc: (84.00%) (22927/27008)
Epoch: 21 | Batch_idx: 220 |  Loss: (0.4481) | Acc: (84.00%) (24029/28288)
Epoch: 21 | Batch_idx: 230 |  Loss: (0.4458) | Acc: (84.00%) (25129/29568)
Epoch: 21 | Batch_idx: 240 |  Loss: (0.4450) | Acc: (85.00%) (26232/30848)
Epoch: 21 | Batch_idx: 250 |  Loss: (0.4434) | Acc: (85.00%) (27347/32128)
Epoch: 21 | Batch_idx: 260 |  Loss: (0.4415) | Acc: (85.00%) (28472/33408)
Epoch: 21 | Batch_idx: 270 |  Loss: (0.4396) | Acc: (85.00%) (29581/34688)
Epoch: 21 | Batch_idx: 280 |  Loss: (0.4374) | Acc: (85.00%) (30691/35968)
Epoch: 21 | Batch_idx: 290 |  Loss: (0.4358) | Acc: (85.00%) (31789/37248)
Epoch: 21 | Batch_idx: 300 |  Loss: (0.4357) | Acc: (85.00%) (32887/38528)
Epoch: 21 | Batch_idx: 310 |  Loss: (0.4363) | Acc: (85.00%) (33984/39808)
Epoch: 21 | Batch_idx: 320 |  Loss: (0.4351) | Acc: (85.00%) (35084/41088)
Epoch: 21 | Batch_idx: 330 |  Loss: (0.4355) | Acc: (85.00%) (36151/42368)
Epoch: 21 | Batch_idx: 340 |  Loss: (0.4340) | Acc: (85.00%) (37269/43648)
Epoch: 21 | Batch_idx: 350 |  Loss: (0.4328) | Acc: (85.00%) (38375/44928)
Epoch: 21 | Batch_idx: 360 |  Loss: (0.4317) | Acc: (85.00%) (39486/46208)
Epoch: 21 | Batch_idx: 370 |  Loss: (0.4299) | Acc: (85.00%) (40612/47488)
Epoch: 21 | Batch_idx: 380 |  Loss: (0.4299) | Acc: (85.00%) (41711/48768)
Epoch: 21 | Batch_idx: 390 |  Loss: (0.4292) | Acc: (85.00%) (42774/50000)
# TEST : Loss: (0.4262) | Acc: (85.00%) (8578/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-1.1059e-02, -1.5401e-03,  2.5099e-04],
          [-9.8097e-04,  1.1462e-02, -9.6199e-03],
          [ 4.9058e-03, -1.1183e-02, -1.2085e-02]],

         [[-1.9617e-02,  2.9279e-03,  6.5857e-03],
          [ 1.6330e-03,  1.4404e-03, -1.1978e-02],
          [ 7.6741e-04, -1.0733e-02, -1.0916e-03]],

         [[-5.7312e-03, -1.0245e-02,  5.4742e-03],
          [-8.3110e-03,  5.1572e-03, -3.1580e-03],
          [ 7.2789e-03, -2.3387e-03, -1.0562e-02]]],


        [[[ 7.7574e-02, -6.5529e-02,  3.6333e-02],
          [ 5.3724e-02, -2.2978e-01, -1.9399e-02],
          [ 4.4865e-02, -9.5720e-03,  2.3725e-02]],

         [[-5.4588e-03, -1.1661e-01, -6.4662e-02],
          [-6.7527e-02, -3.1583e-01, -6.3640e-02],
          [-6.3714e-03,  9.6569e-06,  7.3864e-02]],

         [[ 3.6759e-02,  1.0678e-02,  6.3222e-02],
          [ 6.7108e-02, -1.3658e-01,  1.5903e-02],
          [-2.3683e-03, -3.8548e-02, -1.5094e-02]]],


        [[[ 6.2354e-02, -2.9159e-02,  6.8699e-02],
          [ 7.8377e-02,  4.2256e-02,  1.1399e-01],
          [ 1.8108e-02, -2.0827e-02, -6.8674e-02]],

         [[ 1.9911e-01,  8.7259e-02, -2.0566e-03],
          [ 1.1366e-01,  8.8323e-02,  5.6307e-03],
          [ 1.2393e-01, -4.7523e-02,  1.3562e-01]],

         [[-1.8449e-02,  1.2556e-01, -8.4747e-02],
          [-4.0951e-02, -1.0797e-01,  1.1193e-01],
          [-4.6766e-02,  2.9636e-03, -1.9460e-02]]],


        ...,


        [[[-9.9543e-02,  1.0918e-01, -1.3047e-01],
          [-2.2248e-01, -9.1803e-02, -1.5551e-01],
          [-1.0331e-01,  7.9138e-02, -2.5799e-01]],

         [[ 7.5080e-02,  3.9295e-02,  1.6561e-02],
          [ 1.1054e-01, -1.6389e-01,  4.4852e-02],
          [ 3.9543e-02,  1.1830e-01, -1.8478e-01]],

         [[-1.1439e-01,  2.3350e-01,  7.7381e-02],
          [ 2.0171e-01,  1.5976e-01,  1.4579e-01],
          [ 1.7256e-01,  1.3016e-01, -8.0879e-02]]],


        [[[ 5.2804e-02, -1.3382e-01, -1.8452e-02],
          [ 3.8263e-02, -1.0837e-01,  5.2786e-02],
          [ 7.7865e-02, -1.3864e-01,  1.7395e-02]],

         [[ 1.5541e-01, -1.6148e-01,  3.5371e-02],
          [-1.2340e-01,  1.3426e-02, -1.1461e-01],
          [ 4.7930e-02,  1.0986e-01, -1.7966e-02]],

         [[-2.6336e-02, -1.0245e-01,  5.3969e-02],
          [-9.5354e-02, -2.7282e-01, -2.1602e-01],
          [ 5.6629e-02, -7.0846e-02, -1.5377e-01]]],


        [[[-4.5350e-02, -1.3369e-02, -1.0919e-01],
          [ 7.4439e-02, -2.1094e-02, -1.2058e-01],
          [ 6.8906e-02, -5.3981e-02, -3.5680e-02]],

         [[ 9.4604e-02,  4.3307e-02, -1.0996e-01],
          [ 3.8253e-02,  9.8263e-03,  5.9298e-02],
          [-6.8374e-02, -6.4776e-02,  1.5410e-01]],

         [[ 4.4088e-02, -1.1927e-01, -2.0133e-02],
          [-9.5538e-03,  8.8386e-02,  6.9326e-02],
          [-1.7194e-01, -9.8270e-02, -2.6413e-02]]]], device='cuda:0')

conv1_weight_grad tensor([[[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        ...,


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]]], device='cuda:0')

percentage_weight tensor([0.], device='cuda:0', requires_grad=True)

percentage_weight_grad tensor([-32.9621], device='cuda:0')

Epoch: 22 | Batch_idx: 0 |  Loss: (0.4179) | Acc: (88.00%) (113/128)
Epoch: 22 | Batch_idx: 10 |  Loss: (0.3867) | Acc: (86.00%) (1222/1408)
Epoch: 22 | Batch_idx: 20 |  Loss: (0.3966) | Acc: (86.00%) (2326/2688)
Epoch: 22 | Batch_idx: 30 |  Loss: (0.4006) | Acc: (86.00%) (3434/3968)
Epoch: 22 | Batch_idx: 40 |  Loss: (0.3961) | Acc: (86.00%) (4551/5248)
Epoch: 22 | Batch_idx: 50 |  Loss: (0.3958) | Acc: (86.00%) (5662/6528)
Epoch: 22 | Batch_idx: 60 |  Loss: (0.3969) | Acc: (86.00%) (6774/7808)
Epoch: 22 | Batch_idx: 70 |  Loss: (0.3949) | Acc: (86.00%) (7892/9088)
Epoch: 22 | Batch_idx: 80 |  Loss: (0.3960) | Acc: (86.00%) (9005/10368)
Epoch: 22 | Batch_idx: 90 |  Loss: (0.3999) | Acc: (86.00%) (10096/11648)
Epoch: 22 | Batch_idx: 100 |  Loss: (0.4010) | Acc: (86.00%) (11187/12928)
Epoch: 22 | Batch_idx: 110 |  Loss: (0.3994) | Acc: (86.00%) (12292/14208)
Epoch: 22 | Batch_idx: 120 |  Loss: (0.3991) | Acc: (86.00%) (13407/15488)
Epoch: 22 | Batch_idx: 130 |  Loss: (0.3998) | Acc: (86.00%) (14522/16768)
Epoch: 22 | Batch_idx: 140 |  Loss: (0.3999) | Acc: (86.00%) (15632/18048)
Epoch: 22 | Batch_idx: 150 |  Loss: (0.4004) | Acc: (86.00%) (16736/19328)
Epoch: 22 | Batch_idx: 160 |  Loss: (0.4017) | Acc: (86.00%) (17836/20608)
Epoch: 22 | Batch_idx: 170 |  Loss: (0.4037) | Acc: (86.00%) (18928/21888)
Epoch: 22 | Batch_idx: 180 |  Loss: (0.4004) | Acc: (86.00%) (20065/23168)
Epoch: 22 | Batch_idx: 190 |  Loss: (0.4010) | Acc: (86.00%) (21179/24448)
Epoch: 22 | Batch_idx: 200 |  Loss: (0.4008) | Acc: (86.00%) (22286/25728)
Epoch: 22 | Batch_idx: 210 |  Loss: (0.4010) | Acc: (86.00%) (23392/27008)
Epoch: 22 | Batch_idx: 220 |  Loss: (0.3999) | Acc: (86.00%) (24518/28288)
Epoch: 22 | Batch_idx: 230 |  Loss: (0.4000) | Acc: (86.00%) (25633/29568)
Epoch: 22 | Batch_idx: 240 |  Loss: (0.3989) | Acc: (86.00%) (26757/30848)
Epoch: 22 | Batch_idx: 250 |  Loss: (0.3986) | Acc: (86.00%) (27856/32128)
Epoch: 22 | Batch_idx: 260 |  Loss: (0.3971) | Acc: (86.00%) (28993/33408)
Epoch: 22 | Batch_idx: 270 |  Loss: (0.3964) | Acc: (86.00%) (30109/34688)
Epoch: 22 | Batch_idx: 280 |  Loss: (0.3964) | Acc: (86.00%) (31213/35968)
Epoch: 22 | Batch_idx: 290 |  Loss: (0.3971) | Acc: (86.00%) (32319/37248)
Epoch: 22 | Batch_idx: 300 |  Loss: (0.3971) | Acc: (86.00%) (33420/38528)
Epoch: 22 | Batch_idx: 310 |  Loss: (0.3980) | Acc: (86.00%) (34519/39808)
Epoch: 22 | Batch_idx: 320 |  Loss: (0.3972) | Acc: (86.00%) (35651/41088)
Epoch: 22 | Batch_idx: 330 |  Loss: (0.3970) | Acc: (86.00%) (36760/42368)
Epoch: 22 | Batch_idx: 340 |  Loss: (0.3963) | Acc: (86.00%) (37873/43648)
Epoch: 22 | Batch_idx: 350 |  Loss: (0.3968) | Acc: (86.00%) (38967/44928)
Epoch: 22 | Batch_idx: 360 |  Loss: (0.3967) | Acc: (86.00%) (40078/46208)
Epoch: 22 | Batch_idx: 370 |  Loss: (0.3963) | Acc: (86.00%) (41186/47488)
Epoch: 22 | Batch_idx: 380 |  Loss: (0.3963) | Acc: (86.00%) (42300/48768)
Epoch: 22 | Batch_idx: 390 |  Loss: (0.3960) | Acc: (86.00%) (43379/50000)
# TEST : Loss: (0.4166) | Acc: (86.00%) (8603/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-6.3153e-03, -9.3030e-04,  1.5513e-04],
          [-5.8914e-04,  7.0152e-03, -5.5423e-03],
          [ 3.1371e-03, -6.6415e-03, -6.5669e-03]],

         [[-1.1070e-02,  1.7481e-03,  4.0326e-03],
          [ 9.6356e-04,  8.6805e-04, -6.8134e-03],
          [ 4.8311e-04, -6.2670e-03, -5.8087e-04]],

         [[-3.1807e-03, -6.0327e-03,  3.2984e-03],
          [-4.8384e-03,  3.0613e-03, -1.7688e-03],
          [ 4.4875e-03, -1.3381e-03, -5.5151e-03]]],


        [[[ 7.6003e-02, -6.3888e-02,  3.5609e-02],
          [ 5.2419e-02, -2.1864e-01, -1.8908e-02],
          [ 4.3988e-02, -9.3411e-03,  2.3277e-02]],

         [[-5.3432e-03, -1.1331e-01, -6.3291e-02],
          [-6.5774e-02, -2.9344e-01, -6.1924e-02],
          [-6.2433e-03,  9.4099e-06,  7.2443e-02]],

         [[ 3.5909e-02,  1.0359e-02,  6.1734e-02],
          [ 6.5238e-02, -1.2912e-01,  1.5437e-02],
          [-2.3165e-03, -3.7478e-02, -1.4766e-02]]],


        [[[ 5.5365e-02, -2.5739e-02,  6.2312e-02],
          [ 6.9270e-02,  3.7208e-02,  1.0303e-01],
          [ 1.6722e-02, -1.9310e-02, -6.4272e-02]],

         [[ 1.8256e-01,  7.9443e-02, -1.8962e-03],
          [ 1.0383e-01,  8.0259e-02,  5.1899e-03],
          [ 1.1502e-01, -4.4142e-02,  1.2707e-01]],

         [[-1.7719e-02,  1.2040e-01, -8.1288e-02],
          [-3.9334e-02, -1.0355e-01,  1.0741e-01],
          [-4.4871e-02,  2.8391e-03, -1.8655e-02]]],


        ...,


        [[[-9.9336e-02,  1.0896e-01, -1.3021e-01],
          [-2.2203e-01, -9.1619e-02, -1.5519e-01],
          [-1.0310e-01,  7.8980e-02, -2.5747e-01]],

         [[ 7.4915e-02,  3.9211e-02,  1.6526e-02],
          [ 1.1030e-01, -1.6354e-01,  4.4760e-02],
          [ 3.9460e-02,  1.1806e-01, -1.8441e-01]],

         [[-1.1410e-01,  2.3292e-01,  7.7194e-02],
          [ 2.0122e-01,  1.5938e-01,  1.4545e-01],
          [ 1.7215e-01,  1.2986e-01, -8.0696e-02]]],


        [[[ 5.2183e-02, -1.3188e-01, -1.8206e-02],
          [ 3.7773e-02, -1.0650e-01,  5.1936e-02],
          [ 7.7005e-02, -1.3679e-01,  1.7173e-02]],

         [[ 1.5331e-01, -1.5842e-01,  3.4790e-02],
          [-1.2149e-01,  1.3078e-02, -1.1205e-01],
          [ 4.7333e-02,  1.0807e-01, -1.7692e-02]],

         [[-2.5838e-02, -9.9243e-02,  5.2589e-02],
          [-9.3104e-02, -2.4947e-01, -2.0348e-01],
          [ 5.5670e-02, -6.9020e-02, -1.5012e-01]]],


        [[[-4.2889e-02, -1.2543e-02, -1.0172e-01],
          [ 6.9741e-02, -1.9753e-02, -1.1322e-01],
          [ 6.4998e-02, -5.1000e-02, -3.3714e-02]],

         [[ 8.9261e-02,  4.0647e-02, -1.0289e-01],
          [ 3.5765e-02,  9.2153e-03,  5.5851e-02],
          [-6.4469e-02, -6.1233e-02,  1.4577e-01]],

         [[ 4.1644e-02, -1.1155e-01, -1.8739e-02],
          [-8.9741e-03,  8.2647e-02,  6.4953e-02],
          [-1.6176e-01, -9.2219e-02, -2.4790e-02]]]], device='cuda:0')

conv1_weight_grad tensor([[[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        ...,


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]]], device='cuda:0')

percentage_weight tensor([0.], device='cuda:0', requires_grad=True)

percentage_weight_grad tensor([-35.8800], device='cuda:0')

True Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False _Gate(
  (sig): Sigmoid()
)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False _Gate(
  (sig): Sigmoid()
)
True Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False _Gate(
  (sig): Sigmoid()
)
True Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False _Gate(
  (sig): Sigmoid()
)
True Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False _Gate(
  (sig): Sigmoid()
)
True Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False _Gate(
  (sig): Sigmoid()
)
True Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False _Gate(
  (sig): Sigmoid()
)
True Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False _Gate(
  (sig): Sigmoid()
)
True Linear(in_features=512, out_features=10, bias=True)
Epoch: 23 | Batch_idx: 0 |  Loss: (0.3432) | Acc: (88.00%) (113/128)
Epoch: 23 | Batch_idx: 10 |  Loss: (0.4254) | Acc: (85.00%) (1205/1408)
Epoch: 23 | Batch_idx: 20 |  Loss: (0.4342) | Acc: (85.00%) (2311/2688)
Epoch: 23 | Batch_idx: 30 |  Loss: (0.4701) | Acc: (84.00%) (3348/3968)
Epoch: 23 | Batch_idx: 40 |  Loss: (0.4947) | Acc: (83.00%) (4385/5248)
Epoch: 23 | Batch_idx: 50 |  Loss: (0.5068) | Acc: (83.00%) (5425/6528)
Epoch: 23 | Batch_idx: 60 |  Loss: (0.5108) | Acc: (83.00%) (6490/7808)
Epoch: 23 | Batch_idx: 70 |  Loss: (0.5103) | Acc: (83.00%) (7565/9088)
Epoch: 23 | Batch_idx: 80 |  Loss: (0.5124) | Acc: (83.00%) (8618/10368)
Epoch: 23 | Batch_idx: 90 |  Loss: (0.5088) | Acc: (83.00%) (9687/11648)
Epoch: 23 | Batch_idx: 100 |  Loss: (0.5055) | Acc: (83.00%) (10781/12928)
Epoch: 23 | Batch_idx: 110 |  Loss: (0.5061) | Acc: (83.00%) (11853/14208)
Epoch: 23 | Batch_idx: 120 |  Loss: (0.5019) | Acc: (83.00%) (12926/15488)
Epoch: 23 | Batch_idx: 130 |  Loss: (0.5003) | Acc: (83.00%) (14000/16768)
Epoch: 23 | Batch_idx: 140 |  Loss: (0.4960) | Acc: (83.00%) (15087/18048)
Epoch: 23 | Batch_idx: 150 |  Loss: (0.4948) | Acc: (83.00%) (16153/19328)
Epoch: 23 | Batch_idx: 160 |  Loss: (0.4926) | Acc: (83.00%) (17233/20608)
Epoch: 23 | Batch_idx: 170 |  Loss: (0.4921) | Acc: (83.00%) (18305/21888)
Epoch: 23 | Batch_idx: 180 |  Loss: (0.4907) | Acc: (83.00%) (19394/23168)
Epoch: 23 | Batch_idx: 190 |  Loss: (0.4897) | Acc: (83.00%) (20475/24448)
Epoch: 23 | Batch_idx: 200 |  Loss: (0.4874) | Acc: (83.00%) (21561/25728)
Epoch: 23 | Batch_idx: 210 |  Loss: (0.4842) | Acc: (83.00%) (22668/27008)
Epoch: 23 | Batch_idx: 220 |  Loss: (0.4831) | Acc: (83.00%) (23754/28288)
Epoch: 23 | Batch_idx: 230 |  Loss: (0.4844) | Acc: (83.00%) (24805/29568)
Epoch: 23 | Batch_idx: 240 |  Loss: (0.4830) | Acc: (83.00%) (25877/30848)
Epoch: 23 | Batch_idx: 250 |  Loss: (0.4825) | Acc: (83.00%) (26960/32128)
Epoch: 23 | Batch_idx: 260 |  Loss: (0.4824) | Acc: (83.00%) (28051/33408)
Epoch: 23 | Batch_idx: 270 |  Loss: (0.4807) | Acc: (84.00%) (29141/34688)
Epoch: 23 | Batch_idx: 280 |  Loss: (0.4804) | Acc: (84.00%) (30219/35968)
Epoch: 23 | Batch_idx: 290 |  Loss: (0.4785) | Acc: (84.00%) (31319/37248)
Epoch: 23 | Batch_idx: 300 |  Loss: (0.4770) | Acc: (84.00%) (32414/38528)
Epoch: 23 | Batch_idx: 310 |  Loss: (0.4776) | Acc: (84.00%) (33474/39808)
Epoch: 23 | Batch_idx: 320 |  Loss: (0.4767) | Acc: (84.00%) (34556/41088)
Epoch: 23 | Batch_idx: 330 |  Loss: (0.4763) | Acc: (84.00%) (35639/42368)
Epoch: 23 | Batch_idx: 340 |  Loss: (0.4747) | Acc: (84.00%) (36731/43648)
Epoch: 23 | Batch_idx: 350 |  Loss: (0.4737) | Acc: (84.00%) (37811/44928)
Epoch: 23 | Batch_idx: 360 |  Loss: (0.4726) | Acc: (84.00%) (38897/46208)
Epoch: 23 | Batch_idx: 370 |  Loss: (0.4716) | Acc: (84.00%) (39984/47488)
Epoch: 23 | Batch_idx: 380 |  Loss: (0.4700) | Acc: (84.00%) (41084/48768)
Epoch: 23 | Batch_idx: 390 |  Loss: (0.4696) | Acc: (84.00%) (42120/50000)
# TEST : Loss: (0.5640) | Acc: (81.00%) (8112/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-0.0035, -0.0016, -0.0009],
          [-0.0019,  0.0026, -0.0035],
          [ 0.0000, -0.0043, -0.0039]],

         [[-0.0059, -0.0006,  0.0003],
          [-0.0010, -0.0008, -0.0043],
          [-0.0016, -0.0040, -0.0009]],

         [[-0.0022, -0.0045,  0.0005],
          [-0.0041,  0.0004, -0.0018],
          [ 0.0005, -0.0015, -0.0033]]],


        [[[ 0.0677, -0.0546,  0.0512],
          [ 0.0242, -0.2205, -0.0224],
          [ 0.0458,  0.0025,  0.0312]],

         [[-0.0133, -0.1109, -0.0592],
          [-0.1007, -0.3250, -0.0819],
          [-0.0116,  0.0005,  0.0662]],

         [[ 0.0295,  0.0121,  0.0592],
          [ 0.0300, -0.1496, -0.0081],
          [-0.0146, -0.0416, -0.0280]]],


        [[[ 0.0312, -0.0257,  0.0614],
          [ 0.0410,  0.0199,  0.0858],
          [ 0.0039, -0.0447, -0.0858]],

         [[ 0.1814,  0.0972,  0.0135],
          [ 0.1197,  0.0977,  0.0139],
          [ 0.1343, -0.0400,  0.1096]],

         [[-0.0003,  0.1313, -0.0702],
          [-0.0174, -0.0837,  0.1087],
          [-0.0145,  0.0141, -0.0184]]],


        ...,


        [[[-0.0998,  0.1093, -0.1281],
          [-0.2202, -0.0902, -0.1501],
          [-0.1022,  0.0786, -0.2529]],

         [[ 0.0752,  0.0447,  0.0212],
          [ 0.1157, -0.1520,  0.0576],
          [ 0.0435,  0.1260, -0.1729]],

         [[-0.1138,  0.2454,  0.0891],
          [ 0.2121,  0.1842,  0.1708],
          [ 0.1769,  0.1460, -0.0610]]],


        [[[ 0.0486, -0.1281, -0.0155],
          [ 0.0123, -0.1305,  0.0301],
          [ 0.0662, -0.1385,  0.0086]],

         [[ 0.1581, -0.1426,  0.0472],
          [-0.1398, -0.0117, -0.1239],
          [ 0.0351,  0.1001, -0.0253]],

         [[-0.0173, -0.0758,  0.0598],
          [-0.1136, -0.2546, -0.2177],
          [ 0.0349, -0.0771, -0.1646]]],


        [[[-0.0466, -0.0222, -0.0977],
          [ 0.0583, -0.0268, -0.1075],
          [ 0.0598, -0.0508, -0.0338]],

         [[ 0.0743,  0.0285, -0.0957],
          [ 0.0216,  0.0001,  0.0521],
          [-0.0670, -0.0617,  0.1356]],

         [[ 0.0353, -0.1102, -0.0174],
          [-0.0131,  0.0693,  0.0600],
          [-0.1520, -0.0898, -0.0246]]]], device='cuda:0', requires_grad=True)

conv1_weight_grad tensor([[[[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]]],


        [[[-0.0055, -0.0012, -0.0013],
          [-0.0034, -0.0001, -0.0016],
          [-0.0003,  0.0022,  0.0006]],

         [[-0.0033,  0.0002,  0.0009],
          [-0.0029, -0.0005, -0.0014],
          [ 0.0003,  0.0019,  0.0007]],

         [[-0.0025, -0.0001,  0.0005],
          [-0.0016, -0.0002, -0.0010],
          [ 0.0014,  0.0021,  0.0010]]],


        [[[ 0.0005,  0.0002,  0.0006],
          [ 0.0000,  0.0002,  0.0007],
          [ 0.0008,  0.0013,  0.0017]],

         [[ 0.0001, -0.0002,  0.0002],
          [-0.0004, -0.0003,  0.0003],
          [ 0.0003,  0.0007,  0.0012]],

         [[ 0.0002, -0.0000,  0.0004],
          [-0.0002, -0.0001,  0.0005],
          [ 0.0003,  0.0007,  0.0012]]],


        ...,


        [[[ 0.0309,  0.0427,  0.0404],
          [ 0.0376,  0.0486,  0.0493],
          [ 0.0320,  0.0425,  0.0449]],

         [[ 0.0198,  0.0341,  0.0342],
          [ 0.0275,  0.0402,  0.0424],
          [ 0.0260,  0.0371,  0.0398]],

         [[ 0.0168,  0.0290,  0.0291],
          [ 0.0232,  0.0351,  0.0380],
          [ 0.0241,  0.0343,  0.0373]]],


        [[[-0.0008,  0.0009, -0.0006],
          [-0.0015, -0.0002, -0.0010],
          [-0.0017, -0.0005, -0.0015]],

         [[ 0.0023,  0.0037,  0.0030],
          [-0.0002,  0.0006,  0.0002],
          [-0.0000,  0.0005, -0.0004]],

         [[-0.0000,  0.0008,  0.0002],
          [-0.0004, -0.0001, -0.0005],
          [ 0.0005,  0.0003, -0.0005]]],


        [[[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [-0.0000,  0.0000, -0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [-0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [-0.0000,  0.0000,  0.0000]]]], device='cuda:0')

percentage_weight tensor([0.], device='cuda:0')

percentage_weight_grad tensor([-35.8800], device='cuda:0')

Epoch: 24 | Batch_idx: 0 |  Loss: (0.4105) | Acc: (87.00%) (112/128)
Epoch: 24 | Batch_idx: 10 |  Loss: (0.4157) | Acc: (85.00%) (1209/1408)
Epoch: 24 | Batch_idx: 20 |  Loss: (0.4141) | Acc: (86.00%) (2313/2688)
Epoch: 24 | Batch_idx: 30 |  Loss: (0.4128) | Acc: (85.00%) (3405/3968)
Epoch: 24 | Batch_idx: 40 |  Loss: (0.4140) | Acc: (85.00%) (4501/5248)
Epoch: 24 | Batch_idx: 50 |  Loss: (0.4129) | Acc: (85.00%) (5605/6528)
Epoch: 24 | Batch_idx: 60 |  Loss: (0.4048) | Acc: (86.00%) (6722/7808)
Epoch: 24 | Batch_idx: 70 |  Loss: (0.4034) | Acc: (86.00%) (7833/9088)
Epoch: 24 | Batch_idx: 80 |  Loss: (0.4024) | Acc: (86.00%) (8934/10368)
Epoch: 24 | Batch_idx: 90 |  Loss: (0.4001) | Acc: (86.00%) (10035/11648)
Epoch: 24 | Batch_idx: 100 |  Loss: (0.3997) | Acc: (86.00%) (11141/12928)
Epoch: 24 | Batch_idx: 110 |  Loss: (0.4015) | Acc: (86.00%) (12236/14208)
Epoch: 24 | Batch_idx: 120 |  Loss: (0.4045) | Acc: (86.00%) (13325/15488)
Epoch: 24 | Batch_idx: 130 |  Loss: (0.4025) | Acc: (86.00%) (14433/16768)
Epoch: 24 | Batch_idx: 140 |  Loss: (0.4024) | Acc: (86.00%) (15529/18048)
Epoch: 24 | Batch_idx: 150 |  Loss: (0.4043) | Acc: (85.00%) (16621/19328)
Epoch: 24 | Batch_idx: 160 |  Loss: (0.4043) | Acc: (86.00%) (17728/20608)
Epoch: 24 | Batch_idx: 170 |  Loss: (0.4076) | Acc: (85.00%) (18807/21888)
Epoch: 24 | Batch_idx: 180 |  Loss: (0.4090) | Acc: (85.00%) (19897/23168)
Epoch: 24 | Batch_idx: 190 |  Loss: (0.4079) | Acc: (85.00%) (21003/24448)
Epoch: 24 | Batch_idx: 200 |  Loss: (0.4066) | Acc: (85.00%) (22121/25728)
Epoch: 24 | Batch_idx: 210 |  Loss: (0.4058) | Acc: (85.00%) (23220/27008)
Epoch: 24 | Batch_idx: 220 |  Loss: (0.4064) | Acc: (85.00%) (24326/28288)
Epoch: 24 | Batch_idx: 230 |  Loss: (0.4050) | Acc: (86.00%) (25448/29568)
Epoch: 24 | Batch_idx: 240 |  Loss: (0.4044) | Acc: (86.00%) (26553/30848)
Epoch: 24 | Batch_idx: 250 |  Loss: (0.4038) | Acc: (86.00%) (27662/32128)
Epoch: 24 | Batch_idx: 260 |  Loss: (0.4032) | Acc: (86.00%) (28778/33408)
Epoch: 24 | Batch_idx: 270 |  Loss: (0.4035) | Acc: (86.00%) (29882/34688)
Epoch: 24 | Batch_idx: 280 |  Loss: (0.4032) | Acc: (86.00%) (30978/35968)
Epoch: 24 | Batch_idx: 290 |  Loss: (0.4033) | Acc: (86.00%) (32071/37248)
Epoch: 24 | Batch_idx: 300 |  Loss: (0.4027) | Acc: (86.00%) (33192/38528)
Epoch: 24 | Batch_idx: 310 |  Loss: (0.4022) | Acc: (86.00%) (34295/39808)
Epoch: 24 | Batch_idx: 320 |  Loss: (0.4016) | Acc: (86.00%) (35414/41088)
Epoch: 24 | Batch_idx: 330 |  Loss: (0.4017) | Acc: (86.00%) (36519/42368)
Epoch: 24 | Batch_idx: 340 |  Loss: (0.4012) | Acc: (86.00%) (37620/43648)
Epoch: 24 | Batch_idx: 350 |  Loss: (0.4012) | Acc: (86.00%) (38723/44928)
Epoch: 24 | Batch_idx: 360 |  Loss: (0.4010) | Acc: (86.00%) (39833/46208)
Epoch: 24 | Batch_idx: 370 |  Loss: (0.4002) | Acc: (86.00%) (40948/47488)
Epoch: 24 | Batch_idx: 380 |  Loss: (0.3991) | Acc: (86.00%) (42077/48768)
Epoch: 24 | Batch_idx: 390 |  Loss: (0.3989) | Acc: (86.00%) (43144/50000)
# TEST : Loss: (0.4801) | Acc: (83.00%) (8397/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[ 0.0002, -0.0004,  0.0013],
          [-0.0004,  0.0003, -0.0010],
          [ 0.0024, -0.0008,  0.0012]],

         [[-0.0017, -0.0009,  0.0011],
          [-0.0008, -0.0022, -0.0021],
          [ 0.0010, -0.0014,  0.0017]],

         [[-0.0021, -0.0044, -0.0007],
          [-0.0040, -0.0033, -0.0029],
          [ 0.0001, -0.0022, -0.0014]]],


        [[[ 0.0758, -0.0594,  0.0569],
          [ 0.0382, -0.2217, -0.0110],
          [ 0.0716,  0.0150,  0.0478]],

         [[ 0.0018, -0.1166, -0.0543],
          [-0.0783, -0.3198, -0.0703],
          [ 0.0145,  0.0099,  0.0793]],

         [[ 0.0419,  0.0012,  0.0602],
          [ 0.0436, -0.1637, -0.0017],
          [ 0.0103, -0.0301, -0.0125]]],


        [[[ 0.0163, -0.0305,  0.0451],
          [ 0.0043, -0.0174,  0.0515],
          [-0.0223, -0.0691, -0.1082]],

         [[ 0.1770,  0.1032,  0.0118],
          [ 0.1060,  0.0799,  0.0002],
          [ 0.1229, -0.0448,  0.0902]],

         [[ 0.0172,  0.1405, -0.0636],
          [-0.0022, -0.0709,  0.1033],
          [-0.0016,  0.0200, -0.0213]]],


        ...,


        [[[-0.1047,  0.1011, -0.1384],
          [-0.2275, -0.0987, -0.1583],
          [-0.1106,  0.0692, -0.2595]],

         [[ 0.0727,  0.0413,  0.0129],
          [ 0.1128, -0.1529,  0.0542],
          [ 0.0402,  0.1232, -0.1753]],

         [[-0.1138,  0.2455,  0.0837],
          [ 0.2118,  0.1867,  0.1709],
          [ 0.1751,  0.1451, -0.0622]]],


        [[[ 0.0536, -0.1348, -0.0075],
          [ 0.0327, -0.1266,  0.0480],
          [ 0.0966, -0.1216,  0.0305]],

         [[ 0.1674, -0.1439,  0.0615],
          [-0.1150, -0.0075, -0.0958],
          [ 0.0650,  0.1134, -0.0023]],

         [[-0.0095, -0.0927,  0.0571],
          [-0.0927, -0.2726, -0.2037],
          [ 0.0644, -0.0675, -0.1462]]],


        [[[-0.0431, -0.0207, -0.0883],
          [ 0.0535, -0.0258, -0.0989],
          [ 0.0564, -0.0464, -0.0305]],

         [[ 0.0686,  0.0255, -0.0866],
          [ 0.0196, -0.0009,  0.0476],
          [-0.0607, -0.0562,  0.1264]],

         [[ 0.0323, -0.1004, -0.0154],
          [-0.0132,  0.0615,  0.0540],
          [-0.1391, -0.0816, -0.0218]]]], device='cuda:0', requires_grad=True)

conv1_weight_grad tensor([[[[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]]],


        [[[-0.0046, -0.0007, -0.0020],
          [-0.0061, -0.0012, -0.0031],
          [-0.0039,  0.0006, -0.0014]],

         [[-0.0030,  0.0003, -0.0014],
          [-0.0054, -0.0011, -0.0034],
          [-0.0030,  0.0009, -0.0013]],

         [[-0.0017,  0.0010, -0.0014],
          [-0.0044, -0.0008, -0.0034],
          [-0.0021,  0.0012, -0.0014]]],


        [[[ 0.0002,  0.0002,  0.0006],
          [ 0.0004,  0.0009,  0.0016],
          [ 0.0010,  0.0019,  0.0026]],

         [[-0.0001, -0.0002,  0.0002],
          [ 0.0000,  0.0006,  0.0014],
          [ 0.0007,  0.0017,  0.0026]],

         [[ 0.0000,  0.0001,  0.0005],
          [-0.0000,  0.0006,  0.0014],
          [ 0.0005,  0.0015,  0.0024]]],


        ...,


        [[[ 0.0032,  0.0093,  0.0085],
          [-0.0081,  0.0047,  0.0115],
          [-0.0073,  0.0122,  0.0192]],

         [[ 0.0004,  0.0032, -0.0006],
          [-0.0101, -0.0003,  0.0045],
          [-0.0083,  0.0105,  0.0165]],

         [[ 0.0064,  0.0131,  0.0094],
          [-0.0034,  0.0091,  0.0124],
          [-0.0031,  0.0161,  0.0198]]],


        [[[ 0.0021,  0.0047,  0.0049],
          [-0.0030, -0.0002, -0.0000],
          [-0.0028,  0.0012,  0.0031]],

         [[ 0.0023,  0.0049,  0.0046],
          [-0.0031, -0.0006, -0.0009],
          [-0.0020,  0.0015,  0.0028]],

         [[ 0.0025,  0.0046,  0.0032],
          [-0.0032, -0.0010, -0.0023],
          [-0.0033,  0.0000,  0.0004]]],


        [[[ 0.0000, -0.0000, -0.0000],
          [-0.0000, -0.0000,  0.0000],
          [ 0.0000, -0.0000,  0.0000]],

         [[-0.0000,  0.0000,  0.0000],
          [-0.0000, -0.0000,  0.0000],
          [-0.0000, -0.0000,  0.0000]],

         [[ 0.0000, -0.0000,  0.0000],
          [-0.0000, -0.0000,  0.0000],
          [ 0.0000, -0.0000,  0.0000]]]], device='cuda:0')

percentage_weight tensor([0.], device='cuda:0')

percentage_weight_grad tensor([-35.8800], device='cuda:0')

False Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True _Gate(
  (sig): Sigmoid()
)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True _Gate(
  (sig): Sigmoid()
)
False Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True _Gate(
  (sig): Sigmoid()
)
False Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True _Gate(
  (sig): Sigmoid()
)
False Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True _Gate(
  (sig): Sigmoid()
)
False Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True _Gate(
  (sig): Sigmoid()
)
False Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True _Gate(
  (sig): Sigmoid()
)
False Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True _Gate(
  (sig): Sigmoid()
)
False Linear(in_features=512, out_features=10, bias=True)
Epoch: 25 | Batch_idx: 0 |  Loss: (0.4176) | Acc: (89.00%) (115/128)
Epoch: 25 | Batch_idx: 10 |  Loss: (0.4522) | Acc: (84.00%) (1193/1408)
Epoch: 25 | Batch_idx: 20 |  Loss: (0.4540) | Acc: (84.00%) (2266/2688)
Epoch: 25 | Batch_idx: 30 |  Loss: (0.4803) | Acc: (83.00%) (3313/3968)
Epoch: 25 | Batch_idx: 40 |  Loss: (0.4841) | Acc: (83.00%) (4369/5248)
Epoch: 25 | Batch_idx: 50 |  Loss: (0.4851) | Acc: (83.00%) (5431/6528)
Epoch: 25 | Batch_idx: 60 |  Loss: (0.4671) | Acc: (83.00%) (6548/7808)
Epoch: 25 | Batch_idx: 70 |  Loss: (0.4573) | Acc: (84.00%) (7653/9088)
Epoch: 25 | Batch_idx: 80 |  Loss: (0.4508) | Acc: (84.00%) (8760/10368)
Epoch: 25 | Batch_idx: 90 |  Loss: (0.4491) | Acc: (84.00%) (9856/11648)
Epoch: 25 | Batch_idx: 100 |  Loss: (0.4414) | Acc: (84.00%) (10978/12928)
Epoch: 25 | Batch_idx: 110 |  Loss: (0.4404) | Acc: (85.00%) (12077/14208)
Epoch: 25 | Batch_idx: 120 |  Loss: (0.4383) | Acc: (85.00%) (13175/15488)
Epoch: 25 | Batch_idx: 130 |  Loss: (0.4395) | Acc: (84.00%) (14242/16768)
Epoch: 25 | Batch_idx: 140 |  Loss: (0.4360) | Acc: (85.00%) (15358/18048)
Epoch: 25 | Batch_idx: 150 |  Loss: (0.4372) | Acc: (85.00%) (16435/19328)
Epoch: 25 | Batch_idx: 160 |  Loss: (0.4342) | Acc: (85.00%) (17550/20608)
Epoch: 25 | Batch_idx: 170 |  Loss: (0.4317) | Acc: (85.00%) (18665/21888)
Epoch: 25 | Batch_idx: 180 |  Loss: (0.4313) | Acc: (85.00%) (19758/23168)
Epoch: 25 | Batch_idx: 190 |  Loss: (0.4290) | Acc: (85.00%) (20862/24448)
Epoch: 25 | Batch_idx: 200 |  Loss: (0.4268) | Acc: (85.00%) (21970/25728)
Epoch: 25 | Batch_idx: 210 |  Loss: (0.4261) | Acc: (85.00%) (23068/27008)
Epoch: 25 | Batch_idx: 220 |  Loss: (0.4224) | Acc: (85.00%) (24195/28288)
Epoch: 25 | Batch_idx: 230 |  Loss: (0.4212) | Acc: (85.00%) (25305/29568)
Epoch: 25 | Batch_idx: 240 |  Loss: (0.4199) | Acc: (85.00%) (26410/30848)
Epoch: 25 | Batch_idx: 250 |  Loss: (0.4198) | Acc: (85.00%) (27508/32128)
Epoch: 25 | Batch_idx: 260 |  Loss: (0.4184) | Acc: (85.00%) (28612/33408)
Epoch: 25 | Batch_idx: 270 |  Loss: (0.4171) | Acc: (85.00%) (29722/34688)
Epoch: 25 | Batch_idx: 280 |  Loss: (0.4136) | Acc: (85.00%) (30862/35968)
Epoch: 25 | Batch_idx: 290 |  Loss: (0.4125) | Acc: (85.00%) (31989/37248)
Epoch: 25 | Batch_idx: 300 |  Loss: (0.4095) | Acc: (85.00%) (33125/38528)
Epoch: 25 | Batch_idx: 310 |  Loss: (0.4078) | Acc: (86.00%) (34263/39808)
Epoch: 25 | Batch_idx: 320 |  Loss: (0.4067) | Acc: (86.00%) (35389/41088)
Epoch: 25 | Batch_idx: 330 |  Loss: (0.4052) | Acc: (86.00%) (36515/42368)
Epoch: 25 | Batch_idx: 340 |  Loss: (0.4036) | Acc: (86.00%) (37647/43648)
Epoch: 25 | Batch_idx: 350 |  Loss: (0.4024) | Acc: (86.00%) (38777/44928)
Epoch: 25 | Batch_idx: 360 |  Loss: (0.4018) | Acc: (86.00%) (39883/46208)
Epoch: 25 | Batch_idx: 370 |  Loss: (0.4010) | Acc: (86.00%) (40997/47488)
Epoch: 25 | Batch_idx: 380 |  Loss: (0.4007) | Acc: (86.00%) (42105/48768)
Epoch: 25 | Batch_idx: 390 |  Loss: (0.4006) | Acc: (86.00%) (43184/50000)
# TEST : Loss: (0.4286) | Acc: (85.00%) (8548/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[ 0.0001, -0.0002,  0.0006],
          [-0.0002,  0.0001, -0.0004],
          [ 0.0011, -0.0003,  0.0004]],

         [[-0.0006, -0.0004,  0.0005],
          [-0.0003, -0.0009, -0.0008],
          [ 0.0004, -0.0005,  0.0005]],

         [[-0.0007, -0.0017, -0.0003],
          [-0.0015, -0.0013, -0.0010],
          [ 0.0001, -0.0008, -0.0004]]],


        [[[ 0.0783, -0.0570,  0.0581],
          [ 0.0420, -0.2141, -0.0078],
          [ 0.0741,  0.0154,  0.0497]],

         [[ 0.0051, -0.1126, -0.0511],
          [-0.0715, -0.2997, -0.0646],
          [ 0.0183,  0.0113,  0.0815]],

         [[ 0.0422,  0.0003,  0.0606],
          [ 0.0456, -0.1562,  0.0017],
          [ 0.0125, -0.0296, -0.0099]]],


        [[[ 0.0102, -0.0300,  0.0401],
          [-0.0004, -0.0208,  0.0435],
          [-0.0243, -0.0698, -0.1073]],

         [[ 0.1544,  0.0909,  0.0105],
          [ 0.0915,  0.0670, -0.0031],
          [ 0.1125, -0.0456,  0.0818]],

         [[ 0.0170,  0.1344, -0.0604],
          [-0.0010, -0.0668,  0.0971],
          [-0.0013,  0.0178, -0.0226]]],


        ...,


        [[[-0.1073,  0.0980, -0.1412],
          [-0.2306, -0.1022, -0.1616],
          [-0.1150,  0.0643, -0.2637]],

         [[ 0.0705,  0.0393,  0.0110],
          [ 0.1099, -0.1552,  0.0518],
          [ 0.0363,  0.1191, -0.1785]],

         [[-0.1169,  0.2416,  0.0804],
          [ 0.2078,  0.1828,  0.1675],
          [ 0.1706,  0.1406, -0.0658]]],


        [[[ 0.0560, -0.1331, -0.0081],
          [ 0.0372, -0.1209,  0.0493],
          [ 0.1017, -0.1158,  0.0330]],

         [[ 0.1684, -0.1420,  0.0600],
          [-0.1078, -0.0023, -0.0895],
          [ 0.0706,  0.1167,  0.0017]],

         [[-0.0082, -0.0932,  0.0547],
          [-0.0862, -0.2523, -0.1888],
          [ 0.0693, -0.0620, -0.1399]]],


        [[[-0.0393, -0.0186, -0.0778],
          [ 0.0482, -0.0231, -0.0884],
          [ 0.0514, -0.0421, -0.0276]],

         [[ 0.0623,  0.0228, -0.0770],
          [ 0.0176, -0.0009,  0.0428],
          [-0.0550, -0.0510,  0.1146]],

         [[ 0.0292, -0.0893, -0.0136],
          [-0.0119,  0.0545,  0.0481],
          [-0.1251, -0.0729, -0.0195]]]], device='cuda:0')

conv1_weight_grad tensor([[[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        ...,


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]]], device='cuda:0')

percentage_weight tensor([0.], device='cuda:0', requires_grad=True)

percentage_weight_grad tensor([-34.8709], device='cuda:0')

Epoch: 26 | Batch_idx: 0 |  Loss: (0.4117) | Acc: (86.00%) (111/128)
Epoch: 26 | Batch_idx: 10 |  Loss: (0.3864) | Acc: (87.00%) (1225/1408)
Epoch: 26 | Batch_idx: 20 |  Loss: (0.3996) | Acc: (86.00%) (2320/2688)
Epoch: 26 | Batch_idx: 30 |  Loss: (0.3852) | Acc: (86.00%) (3452/3968)
Epoch: 26 | Batch_idx: 40 |  Loss: (0.3733) | Acc: (87.00%) (4583/5248)
Epoch: 26 | Batch_idx: 50 |  Loss: (0.3727) | Acc: (87.00%) (5705/6528)
Epoch: 26 | Batch_idx: 60 |  Loss: (0.3679) | Acc: (87.00%) (6838/7808)
Epoch: 26 | Batch_idx: 70 |  Loss: (0.3713) | Acc: (87.00%) (7943/9088)
Epoch: 26 | Batch_idx: 80 |  Loss: (0.3691) | Acc: (87.00%) (9066/10368)
Epoch: 26 | Batch_idx: 90 |  Loss: (0.3700) | Acc: (87.00%) (10181/11648)
Epoch: 26 | Batch_idx: 100 |  Loss: (0.3698) | Acc: (87.00%) (11295/12928)
Epoch: 26 | Batch_idx: 110 |  Loss: (0.3671) | Acc: (87.00%) (12430/14208)
Epoch: 26 | Batch_idx: 120 |  Loss: (0.3647) | Acc: (87.00%) (13565/15488)
Epoch: 26 | Batch_idx: 130 |  Loss: (0.3632) | Acc: (87.00%) (14701/16768)
Epoch: 26 | Batch_idx: 140 |  Loss: (0.3624) | Acc: (87.00%) (15822/18048)
Epoch: 26 | Batch_idx: 150 |  Loss: (0.3623) | Acc: (87.00%) (16952/19328)
Epoch: 26 | Batch_idx: 160 |  Loss: (0.3602) | Acc: (87.00%) (18094/20608)
Epoch: 26 | Batch_idx: 170 |  Loss: (0.3605) | Acc: (87.00%) (19215/21888)
Epoch: 26 | Batch_idx: 180 |  Loss: (0.3615) | Acc: (87.00%) (20336/23168)
Epoch: 26 | Batch_idx: 190 |  Loss: (0.3623) | Acc: (87.00%) (21447/24448)
Epoch: 26 | Batch_idx: 200 |  Loss: (0.3641) | Acc: (87.00%) (22542/25728)
Epoch: 26 | Batch_idx: 210 |  Loss: (0.3654) | Acc: (87.00%) (23659/27008)
Epoch: 26 | Batch_idx: 220 |  Loss: (0.3668) | Acc: (87.00%) (24769/28288)
Epoch: 26 | Batch_idx: 230 |  Loss: (0.3664) | Acc: (87.00%) (25901/29568)
Epoch: 26 | Batch_idx: 240 |  Loss: (0.3640) | Acc: (87.00%) (27051/30848)
Epoch: 26 | Batch_idx: 250 |  Loss: (0.3638) | Acc: (87.00%) (28179/32128)
Epoch: 26 | Batch_idx: 260 |  Loss: (0.3627) | Acc: (87.00%) (29306/33408)
Epoch: 26 | Batch_idx: 270 |  Loss: (0.3632) | Acc: (87.00%) (30426/34688)
Epoch: 26 | Batch_idx: 280 |  Loss: (0.3632) | Acc: (87.00%) (31545/35968)
Epoch: 26 | Batch_idx: 290 |  Loss: (0.3627) | Acc: (87.00%) (32673/37248)
Epoch: 26 | Batch_idx: 300 |  Loss: (0.3624) | Acc: (87.00%) (33810/38528)
Epoch: 26 | Batch_idx: 310 |  Loss: (0.3632) | Acc: (87.00%) (34924/39808)
Epoch: 26 | Batch_idx: 320 |  Loss: (0.3642) | Acc: (87.00%) (36037/41088)
Epoch: 26 | Batch_idx: 330 |  Loss: (0.3642) | Acc: (87.00%) (37160/42368)
Epoch: 26 | Batch_idx: 340 |  Loss: (0.3647) | Acc: (87.00%) (38267/43648)
Epoch: 26 | Batch_idx: 350 |  Loss: (0.3653) | Acc: (87.00%) (39387/44928)
Epoch: 26 | Batch_idx: 360 |  Loss: (0.3648) | Acc: (87.00%) (40524/46208)
Epoch: 26 | Batch_idx: 370 |  Loss: (0.3656) | Acc: (87.00%) (41629/47488)
Epoch: 26 | Batch_idx: 380 |  Loss: (0.3660) | Acc: (87.00%) (42757/48768)
Epoch: 26 | Batch_idx: 390 |  Loss: (0.3656) | Acc: (87.00%) (43850/50000)
# TEST : Loss: (0.4050) | Acc: (86.00%) (8631/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[ 0.0000, -0.0001,  0.0002],
          [-0.0001,  0.0000, -0.0001],
          [ 0.0004, -0.0001,  0.0001]],

         [[-0.0002, -0.0001,  0.0002],
          [-0.0001, -0.0003, -0.0002],
          [ 0.0002, -0.0002,  0.0001]],

         [[-0.0002, -0.0005, -0.0001],
          [-0.0005, -0.0004, -0.0003],
          [ 0.0000, -0.0002, -0.0001]]],


        [[[ 0.0768, -0.0557,  0.0570],
          [ 0.0411, -0.2066, -0.0076],
          [ 0.0728,  0.0151,  0.0488]],

         [[ 0.0050, -0.1094, -0.0500],
          [-0.0697, -0.2811, -0.0628],
          [ 0.0180,  0.0110,  0.0799]],

         [[ 0.0412,  0.0003,  0.0591],
          [ 0.0443, -0.1474,  0.0016],
          [ 0.0122, -0.0288, -0.0096]]],


        [[[ 0.0090, -0.0263,  0.0367],
          [-0.0004, -0.0184,  0.0398],
          [-0.0226, -0.0650, -0.1012]],

         [[ 0.1324,  0.0772,  0.0095],
          [ 0.0780,  0.0570, -0.0028],
          [ 0.1031, -0.0421,  0.0766]],

         [[ 0.0159,  0.1256, -0.0569],
          [-0.0009, -0.0625,  0.0915],
          [-0.0013,  0.0168, -0.0215]]],


        ...,


        [[[-0.1071,  0.0978, -0.1409],
          [-0.2301, -0.1020, -0.1612],
          [-0.1148,  0.0642, -0.2631]],

         [[ 0.0704,  0.0392,  0.0109],
          [ 0.1096, -0.1548,  0.0516],
          [ 0.0362,  0.1189, -0.1781]],

         [[-0.1166,  0.2409,  0.0802],
          [ 0.2072,  0.1824,  0.1671],
          [ 0.1702,  0.1403, -0.0656]]],


        [[[ 0.0552, -0.1307, -0.0079],
          [ 0.0367, -0.1176,  0.0482],
          [ 0.1005, -0.1139,  0.0325]],

         [[ 0.1660, -0.1390,  0.0589],
          [-0.1061, -0.0022, -0.0869],
          [ 0.0697,  0.1146,  0.0017]],

         [[-0.0080, -0.0905,  0.0533],
          [-0.0843, -0.2339, -0.1780],
          [ 0.0681, -0.0605, -0.1367]]],


        [[[-0.0351, -0.0162, -0.0668],
          [ 0.0424, -0.0201, -0.0771],
          [ 0.0458, -0.0374, -0.0244]],

         [[ 0.0554,  0.0199, -0.0666],
          [ 0.0154, -0.0007,  0.0376],
          [-0.0490, -0.0454,  0.1017]],

         [[ 0.0259, -0.0774, -0.0116],
          [-0.0104,  0.0472,  0.0417],
          [-0.1100, -0.0636, -0.0170]]]], device='cuda:0')

conv1_weight_grad tensor([[[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        ...,


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]]], device='cuda:0')

percentage_weight tensor([0.], device='cuda:0', requires_grad=True)

percentage_weight_grad tensor([-32.8761], device='cuda:0')

True Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False _Gate(
  (sig): Sigmoid()
)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False _Gate(
  (sig): Sigmoid()
)
True Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False _Gate(
  (sig): Sigmoid()
)
True Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False _Gate(
  (sig): Sigmoid()
)
True Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False _Gate(
  (sig): Sigmoid()
)
True Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False _Gate(
  (sig): Sigmoid()
)
True Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False _Gate(
  (sig): Sigmoid()
)
True Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False _Gate(
  (sig): Sigmoid()
)
True Linear(in_features=512, out_features=10, bias=True)
Epoch: 27 | Batch_idx: 0 |  Loss: (0.3210) | Acc: (87.00%) (112/128)
Epoch: 27 | Batch_idx: 10 |  Loss: (0.3426) | Acc: (88.00%) (1248/1408)
Epoch: 27 | Batch_idx: 20 |  Loss: (0.3938) | Acc: (86.00%) (2338/2688)
Epoch: 27 | Batch_idx: 30 |  Loss: (0.4118) | Acc: (86.00%) (3426/3968)
Epoch: 27 | Batch_idx: 40 |  Loss: (0.4311) | Acc: (85.00%) (4498/5248)
Epoch: 27 | Batch_idx: 50 |  Loss: (0.4416) | Acc: (85.00%) (5571/6528)
Epoch: 27 | Batch_idx: 60 |  Loss: (0.4296) | Acc: (85.00%) (6691/7808)
Epoch: 27 | Batch_idx: 70 |  Loss: (0.4333) | Acc: (85.00%) (7770/9088)
Epoch: 27 | Batch_idx: 80 |  Loss: (0.4343) | Acc: (85.00%) (8865/10368)
Epoch: 27 | Batch_idx: 90 |  Loss: (0.4367) | Acc: (85.00%) (9952/11648)
Epoch: 27 | Batch_idx: 100 |  Loss: (0.4376) | Acc: (85.00%) (11030/12928)
Epoch: 27 | Batch_idx: 110 |  Loss: (0.4406) | Acc: (85.00%) (12096/14208)
Epoch: 27 | Batch_idx: 120 |  Loss: (0.4416) | Acc: (84.00%) (13158/15488)
Epoch: 27 | Batch_idx: 130 |  Loss: (0.4431) | Acc: (84.00%) (14234/16768)
Epoch: 27 | Batch_idx: 140 |  Loss: (0.4444) | Acc: (84.00%) (15312/18048)
Epoch: 27 | Batch_idx: 150 |  Loss: (0.4433) | Acc: (84.00%) (16406/19328)
Epoch: 27 | Batch_idx: 160 |  Loss: (0.4421) | Acc: (84.00%) (17508/20608)
Epoch: 27 | Batch_idx: 170 |  Loss: (0.4397) | Acc: (85.00%) (18614/21888)
Epoch: 27 | Batch_idx: 180 |  Loss: (0.4382) | Acc: (85.00%) (19714/23168)
Epoch: 27 | Batch_idx: 190 |  Loss: (0.4404) | Acc: (85.00%) (20789/24448)
Epoch: 27 | Batch_idx: 200 |  Loss: (0.4417) | Acc: (85.00%) (21879/25728)
Epoch: 27 | Batch_idx: 210 |  Loss: (0.4404) | Acc: (85.00%) (22981/27008)
Epoch: 27 | Batch_idx: 220 |  Loss: (0.4404) | Acc: (85.00%) (24073/28288)
Epoch: 27 | Batch_idx: 230 |  Loss: (0.4416) | Acc: (85.00%) (25146/29568)
Epoch: 27 | Batch_idx: 240 |  Loss: (0.4420) | Acc: (85.00%) (26230/30848)
Epoch: 27 | Batch_idx: 250 |  Loss: (0.4398) | Acc: (85.00%) (27335/32128)
Epoch: 27 | Batch_idx: 260 |  Loss: (0.4409) | Acc: (85.00%) (28423/33408)
Epoch: 27 | Batch_idx: 270 |  Loss: (0.4413) | Acc: (85.00%) (29512/34688)
Epoch: 27 | Batch_idx: 280 |  Loss: (0.4403) | Acc: (85.00%) (30603/35968)
Epoch: 27 | Batch_idx: 290 |  Loss: (0.4402) | Acc: (85.00%) (31686/37248)
Epoch: 27 | Batch_idx: 300 |  Loss: (0.4374) | Acc: (85.00%) (32806/38528)
Epoch: 27 | Batch_idx: 310 |  Loss: (0.4365) | Acc: (85.00%) (33900/39808)
Epoch: 27 | Batch_idx: 320 |  Loss: (0.4376) | Acc: (85.00%) (34985/41088)
Epoch: 27 | Batch_idx: 330 |  Loss: (0.4369) | Acc: (85.00%) (36076/42368)
Epoch: 27 | Batch_idx: 340 |  Loss: (0.4351) | Acc: (85.00%) (37185/43648)
Epoch: 27 | Batch_idx: 350 |  Loss: (0.4344) | Acc: (85.00%) (38295/44928)
Epoch: 27 | Batch_idx: 360 |  Loss: (0.4336) | Acc: (85.00%) (39395/46208)
Epoch: 27 | Batch_idx: 370 |  Loss: (0.4330) | Acc: (85.00%) (40519/47488)
Epoch: 27 | Batch_idx: 380 |  Loss: (0.4311) | Acc: (85.00%) (41650/48768)
Epoch: 27 | Batch_idx: 390 |  Loss: (0.4307) | Acc: (85.00%) (42705/50000)
# TEST : Loss: (0.5151) | Acc: (82.00%) (8287/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[ 4.7028e-06, -1.4205e-05,  5.4729e-05],
          [-1.3240e-05,  1.0967e-05, -2.3463e-05],
          [ 1.2507e-04, -2.4331e-05,  2.0887e-05]],

         [[-3.5521e-05, -2.7873e-05,  4.2793e-05],
          [-2.2532e-05, -7.3158e-05, -4.7217e-05],
          [ 4.4115e-05, -3.6798e-05,  2.3863e-05]],

         [[-3.8838e-05, -1.2793e-04, -2.4796e-05],
          [-1.0772e-04, -1.0325e-04, -6.0395e-05],
          [ 5.5530e-06, -5.0356e-05, -1.7509e-05]]],


        [[[ 5.8497e-02, -7.2372e-02,  5.9402e-02],
          [ 1.3014e-02, -2.3732e-01, -1.0943e-02],
          [ 5.4913e-02,  4.2424e-03,  4.7999e-02]],

         [[-3.0005e-03, -1.1267e-01, -3.4228e-02],
          [-9.4604e-02, -3.0544e-01, -5.4087e-02],
          [ 1.5750e-03,  6.2391e-03,  8.6769e-02]],

         [[ 4.7544e-02,  1.2507e-02,  8.4949e-02],
          [ 3.8129e-02, -1.3554e-01,  2.3242e-02],
          [ 7.9322e-03, -2.0876e-02,  4.3429e-03]]],


        [[[-3.8563e-02, -6.4729e-02,  2.8689e-02],
          [-6.3516e-02, -5.8880e-02,  2.4984e-02],
          [-8.1580e-02, -1.1302e-01, -1.3814e-01]],

         [[ 9.1580e-02,  5.5587e-02,  2.9137e-02],
          [ 3.1550e-02,  3.9521e-02,  8.8931e-03],
          [ 5.7591e-02, -7.0343e-02,  5.0980e-02]],

         [[-2.4916e-02,  8.7622e-02, -5.1697e-02],
          [-4.2331e-02, -8.4331e-02,  8.7037e-02],
          [-3.6434e-02, -1.4006e-02, -4.4074e-02]]],


        ...,


        [[[-1.0692e-01,  9.6896e-02, -1.4598e-01],
          [-2.2702e-01, -9.9654e-02, -1.6286e-01],
          [-1.1522e-01,  6.2764e-02, -2.6466e-01]],

         [[ 6.4329e-02,  3.5379e-02,  2.4599e-03],
          [ 1.1041e-01, -1.5075e-01,  4.9272e-02],
          [ 3.4175e-02,  1.1800e-01, -1.8235e-01]],

         [[-1.1617e-01,  2.4586e-01,  7.7895e-02],
          [ 2.1572e-01,  1.9775e-01,  1.7552e-01],
          [ 1.7209e-01,  1.4673e-01, -6.3436e-02]]],


        [[[ 4.2629e-02, -1.3047e-01, -1.0295e-03],
          [ 2.2274e-02, -1.3362e-01,  4.5499e-02],
          [ 9.2243e-02, -1.1541e-01,  3.1567e-02]],

         [[ 1.4619e-01, -1.3607e-01,  7.7053e-02],
          [-1.2565e-01, -2.4490e-02, -7.5577e-02],
          [ 5.9460e-02,  1.1516e-01,  1.0731e-02]],

         [[-3.7311e-02, -9.8984e-02,  6.5012e-02],
          [-1.2075e-01, -2.8116e-01, -1.8473e-01],
          [ 3.6980e-02, -7.7844e-02, -1.4707e-01]]],


        [[[-3.4279e-02, -1.4676e-02, -5.4909e-02],
          [ 3.2076e-02, -1.8843e-02, -6.6069e-02],
          [ 3.8251e-02, -3.3336e-02, -2.1604e-02]],

         [[ 4.2960e-02,  1.5591e-02, -5.5970e-02],
          [ 7.1611e-03, -2.5705e-03,  3.1263e-02],
          [-4.5304e-02, -4.0611e-02,  8.7225e-02]],

         [[ 1.8068e-02, -6.6921e-02, -9.9058e-03],
          [-1.3899e-02,  3.6888e-02,  3.3690e-02],
          [-9.6508e-02, -5.5366e-02, -1.5457e-02]]]],
       device='cuda:0', requires_grad=True)

conv1_weight_grad tensor([[[[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]]],


        [[[ 0.0057,  0.0023,  0.0039],
          [ 0.0056,  0.0024,  0.0045],
          [ 0.0063,  0.0033,  0.0049]],

         [[ 0.0039,  0.0006,  0.0020],
          [ 0.0048,  0.0014,  0.0032],
          [ 0.0059,  0.0027,  0.0043]],

         [[ 0.0030,  0.0002,  0.0013],
          [ 0.0039,  0.0010,  0.0025],
          [ 0.0049,  0.0022,  0.0035]]],


        [[[-0.0007, -0.0008, -0.0006],
          [-0.0002, -0.0003, -0.0001],
          [-0.0002, -0.0003, -0.0001]],

         [[-0.0009, -0.0010, -0.0008],
          [-0.0002, -0.0004, -0.0002],
          [-0.0001, -0.0002, -0.0001]],

         [[-0.0008, -0.0009, -0.0007],
          [-0.0002, -0.0003, -0.0001],
          [-0.0002, -0.0003, -0.0002]]],


        ...,


        [[[ 0.0043,  0.0101,  0.0073],
          [ 0.0157,  0.0236,  0.0179],
          [ 0.0316,  0.0429,  0.0375]],

         [[ 0.0210,  0.0272,  0.0222],
          [ 0.0356,  0.0437,  0.0343],
          [ 0.0510,  0.0622,  0.0514]],

         [[-0.0008,  0.0034, -0.0000],
          [ 0.0142,  0.0200,  0.0124],
          [ 0.0296,  0.0394,  0.0315]]],


        [[[ 0.0070,  0.0005,  0.0042],
          [ 0.0032, -0.0048, -0.0035],
          [ 0.0051, -0.0040, -0.0036]],

         [[ 0.0022, -0.0062, -0.0024],
          [ 0.0010, -0.0077, -0.0042],
          [ 0.0051, -0.0027, -0.0004]],

         [[ 0.0090,  0.0028,  0.0057],
          [ 0.0080,  0.0016,  0.0039],
          [ 0.0094,  0.0035,  0.0047]]],


        [[[-0.0001, -0.0000,  0.0000],
          [-0.0001, -0.0000, -0.0000],
          [-0.0001, -0.0000,  0.0000]],

         [[-0.0000, -0.0000,  0.0000],
          [-0.0000, -0.0000, -0.0000],
          [-0.0000, -0.0000,  0.0000]],

         [[-0.0000, -0.0000, -0.0000],
          [-0.0000, -0.0000, -0.0000],
          [-0.0000, -0.0000, -0.0000]]]], device='cuda:0')

percentage_weight tensor([0.], device='cuda:0')

percentage_weight_grad tensor([-32.8761], device='cuda:0')

Epoch: 28 | Batch_idx: 0 |  Loss: (0.4881) | Acc: (81.00%) (104/128)
Epoch: 28 | Batch_idx: 10 |  Loss: (0.3864) | Acc: (85.00%) (1204/1408)
Epoch: 28 | Batch_idx: 20 |  Loss: (0.3806) | Acc: (86.00%) (2322/2688)
Epoch: 28 | Batch_idx: 30 |  Loss: (0.3827) | Acc: (86.00%) (3442/3968)
Epoch: 28 | Batch_idx: 40 |  Loss: (0.3785) | Acc: (86.00%) (4556/5248)
Epoch: 28 | Batch_idx: 50 |  Loss: (0.3840) | Acc: (86.00%) (5647/6528)
Epoch: 28 | Batch_idx: 60 |  Loss: (0.3844) | Acc: (86.00%) (6767/7808)
Epoch: 28 | Batch_idx: 70 |  Loss: (0.3821) | Acc: (86.00%) (7887/9088)
Epoch: 28 | Batch_idx: 80 |  Loss: (0.3788) | Acc: (87.00%) (9030/10368)
Epoch: 28 | Batch_idx: 90 |  Loss: (0.3781) | Acc: (87.00%) (10148/11648)
Epoch: 28 | Batch_idx: 100 |  Loss: (0.3754) | Acc: (87.00%) (11289/12928)
Epoch: 28 | Batch_idx: 110 |  Loss: (0.3758) | Acc: (87.00%) (12393/14208)
Epoch: 28 | Batch_idx: 120 |  Loss: (0.3759) | Acc: (87.00%) (13506/15488)
Epoch: 28 | Batch_idx: 130 |  Loss: (0.3802) | Acc: (86.00%) (14586/16768)
Epoch: 28 | Batch_idx: 140 |  Loss: (0.3812) | Acc: (86.00%) (15692/18048)
Epoch: 28 | Batch_idx: 150 |  Loss: (0.3808) | Acc: (86.00%) (16802/19328)
Epoch: 28 | Batch_idx: 160 |  Loss: (0.3812) | Acc: (86.00%) (17914/20608)
Epoch: 28 | Batch_idx: 170 |  Loss: (0.3816) | Acc: (86.00%) (19035/21888)
Epoch: 28 | Batch_idx: 180 |  Loss: (0.3803) | Acc: (87.00%) (20158/23168)
Epoch: 28 | Batch_idx: 190 |  Loss: (0.3789) | Acc: (87.00%) (21281/24448)
Epoch: 28 | Batch_idx: 200 |  Loss: (0.3782) | Acc: (87.00%) (22397/25728)
Epoch: 28 | Batch_idx: 210 |  Loss: (0.3786) | Acc: (87.00%) (23519/27008)
Epoch: 28 | Batch_idx: 220 |  Loss: (0.3773) | Acc: (87.00%) (24642/28288)
Epoch: 28 | Batch_idx: 230 |  Loss: (0.3775) | Acc: (87.00%) (25749/29568)
Epoch: 28 | Batch_idx: 240 |  Loss: (0.3778) | Acc: (87.00%) (26866/30848)
Epoch: 28 | Batch_idx: 250 |  Loss: (0.3754) | Acc: (87.00%) (28011/32128)
Epoch: 28 | Batch_idx: 260 |  Loss: (0.3738) | Acc: (87.00%) (29149/33408)
Epoch: 28 | Batch_idx: 270 |  Loss: (0.3749) | Acc: (87.00%) (30254/34688)
Epoch: 28 | Batch_idx: 280 |  Loss: (0.3757) | Acc: (87.00%) (31365/35968)
Epoch: 28 | Batch_idx: 290 |  Loss: (0.3750) | Acc: (87.00%) (32485/37248)
Epoch: 28 | Batch_idx: 300 |  Loss: (0.3758) | Acc: (87.00%) (33594/38528)
Epoch: 28 | Batch_idx: 310 |  Loss: (0.3748) | Acc: (87.00%) (34716/39808)
Epoch: 28 | Batch_idx: 320 |  Loss: (0.3741) | Acc: (87.00%) (35827/41088)
Epoch: 28 | Batch_idx: 330 |  Loss: (0.3733) | Acc: (87.00%) (36963/42368)
Epoch: 28 | Batch_idx: 340 |  Loss: (0.3736) | Acc: (87.00%) (38073/43648)
Epoch: 28 | Batch_idx: 350 |  Loss: (0.3726) | Acc: (87.00%) (39207/44928)
Epoch: 28 | Batch_idx: 360 |  Loss: (0.3727) | Acc: (87.00%) (40320/46208)
Epoch: 28 | Batch_idx: 370 |  Loss: (0.3733) | Acc: (87.00%) (41431/47488)
Epoch: 28 | Batch_idx: 380 |  Loss: (0.3738) | Acc: (87.00%) (42546/48768)
Epoch: 28 | Batch_idx: 390 |  Loss: (0.3734) | Acc: (87.00%) (43624/50000)
# TEST : Loss: (0.4155) | Acc: (85.00%) (8577/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[ 7.3062e-07, -2.6700e-06,  1.1309e-05],
          [-2.4476e-06,  2.1580e-06, -3.7398e-06],
          [ 2.9040e-05, -4.3031e-06,  2.7756e-06]],

         [[-5.2666e-06, -5.0503e-06,  8.5988e-06],
          [-3.9240e-06, -1.3742e-05, -7.2113e-06],
          [ 9.6726e-06, -6.1286e-06,  2.9214e-06]],

         [[-5.4443e-06, -2.2316e-05, -4.6580e-06],
          [-1.8161e-05, -1.8806e-05, -8.8538e-06],
          [ 1.1293e-06, -7.8736e-06, -1.9807e-06]]],


        [[[ 6.4935e-02, -5.8872e-02,  6.5191e-02],
          [ 4.1843e-03, -2.3837e-01, -9.9889e-03],
          [ 5.2789e-02,  8.3098e-03,  5.3480e-02]],

         [[ 7.0999e-03, -9.4726e-02, -2.3956e-02],
          [-1.0303e-01, -3.0706e-01, -5.4577e-02],
          [-3.0132e-03,  9.1668e-03,  9.0167e-02]],

         [[ 5.2934e-02,  2.1951e-02,  9.1347e-02],
          [ 2.6951e-02, -1.4748e-01,  1.8637e-02],
          [ 1.6111e-03, -2.2914e-02,  3.5737e-03]]],


        [[[-4.1003e-02, -6.6653e-02,  2.0005e-02],
          [-6.4829e-02, -6.0584e-02,  1.7096e-02],
          [-7.8318e-02, -1.0772e-01, -1.3330e-01]],

         [[ 8.9301e-02,  5.4990e-02,  2.7099e-02],
          [ 3.0237e-02,  3.7850e-02,  5.7867e-03],
          [ 5.7709e-02, -6.3298e-02,  5.0923e-02]],

         [[-1.8639e-02,  8.5532e-02, -4.8730e-02],
          [-3.8229e-02, -7.7717e-02,  8.0549e-02],
          [-3.1633e-02, -9.6831e-03, -4.0006e-02]]],


        ...,


        [[[-1.1410e-01,  8.4142e-02, -1.5594e-01],
          [-2.3494e-01, -1.0819e-01, -1.6508e-01],
          [-1.2189e-01,  5.8232e-02, -2.6179e-01]],

         [[ 6.0492e-02,  2.7085e-02, -4.0669e-03],
          [ 1.0693e-01, -1.5241e-01,  5.1900e-02],
          [ 3.1639e-02,  1.1941e-01, -1.7454e-01]],

         [[-1.0911e-01,  2.4548e-01,  7.5706e-02],
          [ 2.2417e-01,  2.0560e-01,  1.8376e-01],
          [ 1.7884e-01,  1.5570e-01, -5.1924e-02]]],


        [[[ 5.1244e-02, -1.2940e-01, -5.2886e-04],
          [ 2.5057e-02, -1.4039e-01,  5.0363e-02],
          [ 9.5137e-02, -1.1565e-01,  3.2102e-02]],

         [[ 1.5342e-01, -1.3047e-01,  8.3474e-02],
          [-1.2279e-01, -2.6801e-02, -5.6325e-02],
          [ 6.0656e-02,  1.1695e-01,  1.8488e-02]],

         [[-3.3400e-02, -1.0826e-01,  5.8191e-02],
          [-1.2179e-01, -3.0383e-01, -1.7582e-01],
          [ 2.9917e-02, -8.9430e-02, -1.4786e-01]]],


        [[[-3.1995e-02, -1.2289e-02, -4.3467e-02],
          [ 2.3273e-02, -1.6241e-02, -5.3921e-02],
          [ 3.0659e-02, -2.7935e-02, -1.7058e-02]],

         [[ 3.4843e-02,  1.2328e-02, -4.4880e-02],
          [ 3.9655e-03, -3.2977e-03,  2.5865e-02],
          [-3.8249e-02, -3.4314e-02,  7.4064e-02]],

         [[ 1.3441e-02, -5.4814e-02, -7.8104e-03],
          [-1.3684e-02,  2.8566e-02,  2.7310e-02],
          [-8.0634e-02, -4.5561e-02, -1.1890e-02]]]],
       device='cuda:0', requires_grad=True)

conv1_weight_grad tensor([[[[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]]],


        [[[ 0.0057,  0.0041,  0.0033],
          [ 0.0048,  0.0021,  0.0002],
          [ 0.0068,  0.0030, -0.0005]],

         [[ 0.0026,  0.0019,  0.0023],
          [ 0.0015, -0.0001, -0.0011],
          [ 0.0033,  0.0005, -0.0023]],

         [[ 0.0008,  0.0007,  0.0014],
          [ 0.0000, -0.0007, -0.0014],
          [ 0.0017, -0.0002, -0.0025]]],


        [[[-0.0006, -0.0002,  0.0010],
          [-0.0009, -0.0005,  0.0005],
          [-0.0006, -0.0005,  0.0001]],

         [[-0.0010, -0.0011, -0.0010],
          [-0.0012, -0.0011, -0.0011],
          [-0.0012, -0.0011, -0.0011]],

         [[-0.0003, -0.0003, -0.0000],
          [-0.0006, -0.0005, -0.0002],
          [-0.0005, -0.0004, -0.0002]]],


        ...,


        [[[-0.0142, -0.0215, -0.0143],
          [-0.0242, -0.0312, -0.0234],
          [-0.0341, -0.0405, -0.0334]],

         [[-0.0030, -0.0043,  0.0019],
          [-0.0082, -0.0100, -0.0043],
          [-0.0163, -0.0180, -0.0126]],

         [[-0.0138, -0.0153, -0.0092],
          [-0.0218, -0.0238, -0.0183],
          [-0.0312, -0.0328, -0.0287]]],


        [[[ 0.0109,  0.0074,  0.0060],
          [ 0.0092,  0.0058,  0.0066],
          [ 0.0094,  0.0057,  0.0051]],

         [[ 0.0086,  0.0053,  0.0039],
          [ 0.0064,  0.0035,  0.0042],
          [ 0.0071,  0.0040,  0.0035]],

         [[ 0.0033,  0.0009,  0.0002],
          [ 0.0014, -0.0003,  0.0007],
          [ 0.0030,  0.0013,  0.0011]]],


        [[[-0.0000,  0.0000, -0.0000],
          [-0.0000,  0.0000,  0.0000],
          [-0.0000,  0.0000,  0.0000]],

         [[-0.0000,  0.0000, -0.0000],
          [-0.0000,  0.0000, -0.0000],
          [-0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]]]], device='cuda:0')

percentage_weight tensor([0.], device='cuda:0')

percentage_weight_grad tensor([-32.8761], device='cuda:0')

False Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True _Gate(
  (sig): Sigmoid()
)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True _Gate(
  (sig): Sigmoid()
)
False Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True _Gate(
  (sig): Sigmoid()
)
False Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True _Gate(
  (sig): Sigmoid()
)
False Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True _Gate(
  (sig): Sigmoid()
)
False Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True _Gate(
  (sig): Sigmoid()
)
False Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True _Gate(
  (sig): Sigmoid()
)
False Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True _Gate(
  (sig): Sigmoid()
)
False Linear(in_features=512, out_features=10, bias=True)
Epoch: 29 | Batch_idx: 0 |  Loss: (0.4486) | Acc: (86.00%) (111/128)
Epoch: 29 | Batch_idx: 10 |  Loss: (0.3527) | Acc: (88.00%) (1242/1408)
Epoch: 29 | Batch_idx: 20 |  Loss: (0.3790) | Acc: (87.00%) (2345/2688)
Epoch: 29 | Batch_idx: 30 |  Loss: (0.3857) | Acc: (86.00%) (3441/3968)
Epoch: 29 | Batch_idx: 40 |  Loss: (0.3823) | Acc: (86.00%) (4550/5248)
Epoch: 29 | Batch_idx: 50 |  Loss: (0.3779) | Acc: (86.00%) (5672/6528)
Epoch: 29 | Batch_idx: 60 |  Loss: (0.3683) | Acc: (87.00%) (6815/7808)
Epoch: 29 | Batch_idx: 70 |  Loss: (0.3621) | Acc: (87.00%) (7961/9088)
Epoch: 29 | Batch_idx: 80 |  Loss: (0.3614) | Acc: (87.00%) (9078/10368)
Epoch: 29 | Batch_idx: 90 |  Loss: (0.3601) | Acc: (87.00%) (10208/11648)
Epoch: 29 | Batch_idx: 100 |  Loss: (0.3622) | Acc: (87.00%) (11310/12928)
Epoch: 29 | Batch_idx: 110 |  Loss: (0.3611) | Acc: (87.00%) (12434/14208)
Epoch: 29 | Batch_idx: 120 |  Loss: (0.3601) | Acc: (87.00%) (13561/15488)
Epoch: 29 | Batch_idx: 130 |  Loss: (0.3620) | Acc: (87.00%) (14676/16768)
Epoch: 29 | Batch_idx: 140 |  Loss: (0.3642) | Acc: (87.00%) (15780/18048)
Epoch: 29 | Batch_idx: 150 |  Loss: (0.3622) | Acc: (87.00%) (16908/19328)
Epoch: 29 | Batch_idx: 160 |  Loss: (0.3629) | Acc: (87.00%) (18027/20608)
Epoch: 29 | Batch_idx: 170 |  Loss: (0.3615) | Acc: (87.00%) (19158/21888)
Epoch: 29 | Batch_idx: 180 |  Loss: (0.3615) | Acc: (87.00%) (20280/23168)
Epoch: 29 | Batch_idx: 190 |  Loss: (0.3596) | Acc: (87.00%) (21410/24448)
Epoch: 29 | Batch_idx: 200 |  Loss: (0.3572) | Acc: (87.00%) (22551/25728)
Epoch: 29 | Batch_idx: 210 |  Loss: (0.3568) | Acc: (87.00%) (23685/27008)
Epoch: 29 | Batch_idx: 220 |  Loss: (0.3548) | Acc: (87.00%) (24824/28288)
Epoch: 29 | Batch_idx: 230 |  Loss: (0.3546) | Acc: (87.00%) (25963/29568)
Epoch: 29 | Batch_idx: 240 |  Loss: (0.3528) | Acc: (87.00%) (27114/30848)
Epoch: 29 | Batch_idx: 250 |  Loss: (0.3516) | Acc: (87.00%) (28247/32128)
Epoch: 29 | Batch_idx: 260 |  Loss: (0.3523) | Acc: (87.00%) (29368/33408)
Epoch: 29 | Batch_idx: 270 |  Loss: (0.3508) | Acc: (87.00%) (30522/34688)
Epoch: 29 | Batch_idx: 280 |  Loss: (0.3508) | Acc: (87.00%) (31645/35968)
Epoch: 29 | Batch_idx: 290 |  Loss: (0.3516) | Acc: (87.00%) (32763/37248)
Epoch: 29 | Batch_idx: 300 |  Loss: (0.3515) | Acc: (87.00%) (33898/38528)
Epoch: 29 | Batch_idx: 310 |  Loss: (0.3509) | Acc: (88.00%) (35037/39808)
Epoch: 29 | Batch_idx: 320 |  Loss: (0.3506) | Acc: (88.00%) (36173/41088)
Epoch: 29 | Batch_idx: 330 |  Loss: (0.3501) | Acc: (88.00%) (37312/42368)
Epoch: 29 | Batch_idx: 340 |  Loss: (0.3495) | Acc: (88.00%) (38453/43648)
Epoch: 29 | Batch_idx: 350 |  Loss: (0.3492) | Acc: (88.00%) (39582/44928)
Epoch: 29 | Batch_idx: 360 |  Loss: (0.3483) | Acc: (88.00%) (40729/46208)
Epoch: 29 | Batch_idx: 370 |  Loss: (0.3480) | Acc: (88.00%) (41856/47488)
Epoch: 29 | Batch_idx: 380 |  Loss: (0.3475) | Acc: (88.00%) (43000/48768)
Epoch: 29 | Batch_idx: 390 |  Loss: (0.3466) | Acc: (88.00%) (44108/50000)
# TEST : Loss: (0.3797) | Acc: (87.00%) (8733/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[ 7.4071e-08, -3.4296e-07,  1.6339e-06],
          [-3.0800e-07,  2.9341e-07, -3.9142e-07],
          [ 4.8466e-06, -5.1249e-07,  2.3163e-07]],

         [[-5.0376e-07, -6.1984e-07,  1.1999e-06],
          [-4.5850e-07, -1.7638e-06, -7.1573e-07],
          [ 1.5038e-06, -6.7743e-07,  2.2010e-07]],

         [[-4.8563e-07, -2.6127e-06, -5.9789e-07],
          [-2.0382e-06, -2.3232e-06, -8.3504e-07],
          [ 1.5994e-07, -8.0464e-07, -1.3520e-07]]],


        [[[ 5.9812e-02, -6.0880e-02,  6.1533e-02],
          [ 6.1371e-04, -2.3240e-01, -1.0452e-02],
          [ 4.9874e-02,  8.0273e-03,  5.3645e-02]],

         [[ 4.2376e-03, -9.4860e-02, -2.5802e-02],
          [-1.0243e-01, -2.9152e-01, -5.3123e-02],
          [-3.3142e-03,  1.0520e-02,  9.0490e-02]],

         [[ 5.0960e-02,  2.0560e-02,  8.8515e-02],
          [ 2.6958e-02, -1.3838e-01,  1.9942e-02],
          [ 3.0725e-03, -1.9470e-02,  6.4579e-03]]],


        [[[-3.6837e-02, -6.1215e-02,  1.7645e-02],
          [-5.8862e-02, -5.5556e-02,  1.5455e-02],
          [-7.3395e-02, -1.0149e-01, -1.2703e-01]],

         [[ 8.3730e-02,  5.3097e-02,  2.7147e-02],
          [ 3.0348e-02,  3.7365e-02,  7.0639e-03],
          [ 5.6042e-02, -5.7876e-02,  4.9764e-02]],

         [[-1.6083e-02,  8.0261e-02, -4.5102e-02],
          [-3.4091e-02, -7.0890e-02,  7.6060e-02],
          [-2.8759e-02, -8.0443e-03, -3.7279e-02]]],


        ...,


        [[[-1.1058e-01,  8.7675e-02, -1.5218e-01],
          [-2.3178e-01, -1.0489e-01, -1.6210e-01],
          [-1.1894e-01,  6.1147e-02, -2.5874e-01]],

         [[ 6.3098e-02,  2.9896e-02, -1.4803e-03],
          [ 1.0879e-01, -1.4995e-01,  5.3396e-02],
          [ 3.3612e-02,  1.2115e-01, -1.7293e-01]],

         [[-1.0525e-01,  2.4865e-01,  7.8905e-02],
          [ 2.2660e-01,  2.0809e-01,  1.8576e-01],
          [ 1.8123e-01,  1.5793e-01, -4.9905e-02]]],


        [[[ 4.8977e-02, -1.2845e-01, -2.4071e-03],
          [ 2.2655e-02, -1.3907e-01,  4.6185e-02],
          [ 9.2764e-02, -1.1485e-01,  3.0062e-02]],

         [[ 1.4942e-01, -1.2968e-01,  8.0125e-02],
          [-1.2404e-01, -2.9176e-02, -5.9469e-02],
          [ 5.7807e-02,  1.1429e-01,  1.6195e-02]],

         [[-3.3817e-02, -1.0537e-01,  5.6198e-02],
          [-1.2061e-01, -2.8589e-01, -1.7357e-01],
          [ 2.8891e-02, -8.8141e-02, -1.4705e-01]]],


        [[[-2.6080e-02, -9.6367e-03, -3.2948e-02],
          [ 1.8734e-02, -1.2658e-02, -4.2171e-02],
          [ 2.5103e-02, -2.2551e-02, -1.3692e-02]],

         [[ 2.8264e-02,  9.6791e-03, -3.4587e-02],
          [ 3.1420e-03, -2.5799e-03,  2.0474e-02],
          [-3.0999e-02, -2.7765e-02,  5.9748e-02]],

         [[ 1.0846e-02, -4.2320e-02, -5.8735e-03],
          [-1.0806e-02,  2.2046e-02,  2.1175e-02],
          [-6.3978e-02, -3.5614e-02, -9.2726e-03]]]], device='cuda:0')

conv1_weight_grad tensor([[[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        ...,


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]]], device='cuda:0')

percentage_weight tensor([0.], device='cuda:0', requires_grad=True)

percentage_weight_grad tensor([-40.9091], device='cuda:0')

Epoch: 30 | Batch_idx: 0 |  Loss: (0.3571) | Acc: (89.00%) (115/128)
Epoch: 30 | Batch_idx: 10 |  Loss: (0.3865) | Acc: (86.00%) (1220/1408)
Epoch: 30 | Batch_idx: 20 |  Loss: (0.3549) | Acc: (88.00%) (2372/2688)
Epoch: 30 | Batch_idx: 30 |  Loss: (0.3515) | Acc: (88.00%) (3503/3968)
Epoch: 30 | Batch_idx: 40 |  Loss: (0.3444) | Acc: (88.00%) (4648/5248)
Epoch: 30 | Batch_idx: 50 |  Loss: (0.3395) | Acc: (88.00%) (5795/6528)
Epoch: 30 | Batch_idx: 60 |  Loss: (0.3387) | Acc: (88.00%) (6929/7808)
Epoch: 30 | Batch_idx: 70 |  Loss: (0.3358) | Acc: (88.00%) (8067/9088)
Epoch: 30 | Batch_idx: 80 |  Loss: (0.3301) | Acc: (89.00%) (9234/10368)
Epoch: 30 | Batch_idx: 90 |  Loss: (0.3310) | Acc: (89.00%) (10369/11648)
Epoch: 30 | Batch_idx: 100 |  Loss: (0.3321) | Acc: (89.00%) (11513/12928)
Epoch: 30 | Batch_idx: 110 |  Loss: (0.3270) | Acc: (89.00%) (12677/14208)
Epoch: 30 | Batch_idx: 120 |  Loss: (0.3270) | Acc: (89.00%) (13815/15488)
Epoch: 30 | Batch_idx: 130 |  Loss: (0.3294) | Acc: (89.00%) (14940/16768)
Epoch: 30 | Batch_idx: 140 |  Loss: (0.3304) | Acc: (89.00%) (16071/18048)
Epoch: 30 | Batch_idx: 150 |  Loss: (0.3294) | Acc: (89.00%) (17224/19328)
Epoch: 30 | Batch_idx: 160 |  Loss: (0.3276) | Acc: (89.00%) (18380/20608)
Epoch: 30 | Batch_idx: 170 |  Loss: (0.3263) | Acc: (89.00%) (19532/21888)
Epoch: 30 | Batch_idx: 180 |  Loss: (0.3246) | Acc: (89.00%) (20673/23168)
Epoch: 30 | Batch_idx: 190 |  Loss: (0.3244) | Acc: (89.00%) (21816/24448)
Epoch: 30 | Batch_idx: 200 |  Loss: (0.3243) | Acc: (89.00%) (22954/25728)
Epoch: 30 | Batch_idx: 210 |  Loss: (0.3233) | Acc: (89.00%) (24111/27008)
Epoch: 30 | Batch_idx: 220 |  Loss: (0.3226) | Acc: (89.00%) (25253/28288)
Epoch: 30 | Batch_idx: 230 |  Loss: (0.3213) | Acc: (89.00%) (26409/29568)
Epoch: 30 | Batch_idx: 240 |  Loss: (0.3215) | Acc: (89.00%) (27544/30848)
Epoch: 30 | Batch_idx: 250 |  Loss: (0.3212) | Acc: (89.00%) (28692/32128)
Epoch: 30 | Batch_idx: 260 |  Loss: (0.3218) | Acc: (89.00%) (29824/33408)
Epoch: 30 | Batch_idx: 270 |  Loss: (0.3233) | Acc: (89.00%) (30955/34688)
Epoch: 30 | Batch_idx: 280 |  Loss: (0.3221) | Acc: (89.00%) (32108/35968)
Epoch: 30 | Batch_idx: 290 |  Loss: (0.3221) | Acc: (89.00%) (33251/37248)
Epoch: 30 | Batch_idx: 300 |  Loss: (0.3216) | Acc: (89.00%) (34404/38528)
Epoch: 30 | Batch_idx: 310 |  Loss: (0.3211) | Acc: (89.00%) (35558/39808)
Epoch: 30 | Batch_idx: 320 |  Loss: (0.3206) | Acc: (89.00%) (36713/41088)
Epoch: 30 | Batch_idx: 330 |  Loss: (0.3199) | Acc: (89.00%) (37860/42368)
Epoch: 30 | Batch_idx: 340 |  Loss: (0.3199) | Acc: (89.00%) (38997/43648)
Epoch: 30 | Batch_idx: 350 |  Loss: (0.3192) | Acc: (89.00%) (40145/44928)
Epoch: 30 | Batch_idx: 360 |  Loss: (0.3195) | Acc: (89.00%) (41289/46208)
Epoch: 30 | Batch_idx: 370 |  Loss: (0.3187) | Acc: (89.00%) (42448/47488)
Epoch: 30 | Batch_idx: 380 |  Loss: (0.3185) | Acc: (89.00%) (43604/48768)
Epoch: 30 | Batch_idx: 390 |  Loss: (0.3184) | Acc: (89.00%) (44712/50000)
# TEST : Loss: (0.3686) | Acc: (87.00%) (8782/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[ 4.4080e-09, -2.7434e-08,  1.5132e-07],
          [-2.4013e-08,  2.5195e-08, -2.4242e-08],
          [ 5.3713e-07, -3.7304e-08,  1.0800e-08]],

         [[-2.7872e-08, -4.6845e-08,  1.0643e-07],
          [-3.2587e-08, -1.4095e-07, -4.1475e-08],
          [ 1.5260e-07, -4.4921e-08,  9.0235e-09]],

         [[-2.4616e-08, -1.8616e-07, -4.7785e-08],
          [-1.3774e-07, -1.7701e-07, -4.5394e-08],
          [ 1.4451e-08, -4.8366e-08, -4.8951e-09]]],


        [[[ 5.8609e-02, -5.9385e-02,  6.0331e-02],
          [ 5.9885e-04, -2.2265e-01, -1.0206e-02],
          [ 4.8914e-02,  7.8498e-03,  5.2651e-02]],

         [[ 4.1461e-03, -9.2253e-02, -2.5271e-02],
          [-9.9715e-02, -2.7402e-01, -5.1755e-02],
          [-3.2485e-03,  1.0274e-02,  8.8753e-02]],

         [[ 4.9760e-02,  1.9957e-02,  8.6493e-02],
          [ 2.6187e-02, -1.3118e-01,  1.9374e-02],
          [ 3.0056e-03, -1.8972e-02,  6.3202e-03]]],


        [[[-3.3562e-02, -5.6064e-02,  1.6352e-02],
          [-5.3701e-02, -5.0959e-02,  1.4390e-02],
          [-6.8598e-02, -9.5158e-02, -1.1979e-01]],

         [[ 7.4088e-02,  4.7291e-02,  2.4688e-02],
          [ 2.7049e-02,  3.3616e-02,  6.5016e-03],
          [ 5.1974e-02, -5.3939e-02,  4.6658e-02]],

         [[-1.4601e-02,  7.2927e-02, -4.1481e-02],
          [-3.1013e-02, -6.4696e-02,  7.0427e-02],
          [-2.6803e-02, -7.5191e-03, -3.4980e-02]]],


        ...,


        [[[-1.1032e-01,  8.7474e-02, -1.5183e-01],
          [-2.3125e-01, -1.0465e-01, -1.6174e-01],
          [-1.1867e-01,  6.1010e-02, -2.5816e-01]],

         [[ 6.2943e-02,  2.9823e-02, -1.4767e-03],
          [ 1.0853e-01, -1.4960e-01,  5.3272e-02],
          [ 3.3532e-02,  1.2087e-01, -1.7253e-01]],

         [[-1.0496e-01,  2.4797e-01,  7.8696e-02],
          [ 2.2599e-01,  2.0753e-01,  1.8528e-01],
          [ 1.8074e-01,  1.5751e-01, -4.9779e-02]]],


        [[[ 4.8372e-02, -1.2631e-01, -2.3736e-03],
          [ 2.2318e-02, -1.3526e-01,  4.5298e-02],
          [ 9.1712e-02, -1.1319e-01,  2.9671e-02]],

         [[ 1.4737e-01, -1.2717e-01,  7.8849e-02],
          [-1.2193e-01, -2.8060e-02, -5.8034e-02],
          [ 5.7093e-02,  1.1243e-01,  1.5958e-02]],

         [[-3.3197e-02, -1.0247e-01,  5.4935e-02],
          [-1.1772e-01, -2.6362e-01, -1.6576e-01],
          [ 2.8423e-02, -8.6102e-02, -1.4396e-01]]],


        [[[-2.0464e-02, -7.1742e-03, -2.3516e-02],
          [ 1.4240e-02, -9.3551e-03, -3.1271e-02],
          [ 1.9543e-02, -1.7385e-02, -1.0483e-02]],

         [[ 2.1906e-02,  7.2084e-03, -2.5195e-02],
          [ 2.3586e-03, -1.9179e-03,  1.5398e-02],
          [-2.4011e-02, -2.1464e-02,  4.5998e-02]],

         [[ 8.3482e-03, -3.0895e-02, -4.1712e-03],
          [-8.1163e-03,  1.6070e-02,  1.5518e-02],
          [-4.8289e-02, -2.6402e-02, -6.8587e-03]]]], device='cuda:0')

conv1_weight_grad tensor([[[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        ...,


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]]], device='cuda:0')

percentage_weight tensor([0.], device='cuda:0', requires_grad=True)

percentage_weight_grad tensor([-45.7708], device='cuda:0')

True Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False _Gate(
  (sig): Sigmoid()
)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False _Gate(
  (sig): Sigmoid()
)
True Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False _Gate(
  (sig): Sigmoid()
)
True Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False _Gate(
  (sig): Sigmoid()
)
True Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False _Gate(
  (sig): Sigmoid()
)
True Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False _Gate(
  (sig): Sigmoid()
)
True Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False _Gate(
  (sig): Sigmoid()
)
True Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False _Gate(
  (sig): Sigmoid()
)
True Linear(in_features=512, out_features=10, bias=True)
Epoch: 31 | Batch_idx: 0 |  Loss: (0.2879) | Acc: (91.00%) (117/128)
Epoch: 31 | Batch_idx: 10 |  Loss: (0.3478) | Acc: (88.00%) (1243/1408)
Epoch: 31 | Batch_idx: 20 |  Loss: (0.3696) | Acc: (87.00%) (2351/2688)
Epoch: 31 | Batch_idx: 30 |  Loss: (0.3946) | Acc: (86.00%) (3430/3968)
Epoch: 31 | Batch_idx: 40 |  Loss: (0.4142) | Acc: (85.00%) (4498/5248)
Epoch: 31 | Batch_idx: 50 |  Loss: (0.4117) | Acc: (86.00%) (5615/6528)
Epoch: 31 | Batch_idx: 60 |  Loss: (0.4146) | Acc: (85.00%) (6709/7808)
Epoch: 31 | Batch_idx: 70 |  Loss: (0.4178) | Acc: (85.00%) (7785/9088)
Epoch: 31 | Batch_idx: 80 |  Loss: (0.4169) | Acc: (85.00%) (8895/10368)
Epoch: 31 | Batch_idx: 90 |  Loss: (0.4158) | Acc: (85.00%) (9996/11648)
Epoch: 31 | Batch_idx: 100 |  Loss: (0.4175) | Acc: (85.00%) (11101/12928)
Epoch: 31 | Batch_idx: 110 |  Loss: (0.4193) | Acc: (85.00%) (12197/14208)
Epoch: 31 | Batch_idx: 120 |  Loss: (0.4179) | Acc: (85.00%) (13314/15488)
Epoch: 31 | Batch_idx: 130 |  Loss: (0.4137) | Acc: (86.00%) (14447/16768)
Epoch: 31 | Batch_idx: 140 |  Loss: (0.4083) | Acc: (86.00%) (15592/18048)
Epoch: 31 | Batch_idx: 150 |  Loss: (0.4071) | Acc: (86.00%) (16701/19328)
Epoch: 31 | Batch_idx: 160 |  Loss: (0.4085) | Acc: (86.00%) (17794/20608)
Epoch: 31 | Batch_idx: 170 |  Loss: (0.4090) | Acc: (86.00%) (18896/21888)
Epoch: 31 | Batch_idx: 180 |  Loss: (0.4087) | Acc: (86.00%) (19995/23168)
Epoch: 31 | Batch_idx: 190 |  Loss: (0.4081) | Acc: (86.00%) (21094/24448)
Epoch: 31 | Batch_idx: 200 |  Loss: (0.4100) | Acc: (86.00%) (22175/25728)
Epoch: 31 | Batch_idx: 210 |  Loss: (0.4095) | Acc: (86.00%) (23287/27008)
Epoch: 31 | Batch_idx: 220 |  Loss: (0.4087) | Acc: (86.00%) (24403/28288)
Epoch: 31 | Batch_idx: 230 |  Loss: (0.4097) | Acc: (86.00%) (25503/29568)
Epoch: 31 | Batch_idx: 240 |  Loss: (0.4101) | Acc: (86.00%) (26598/30848)
Epoch: 31 | Batch_idx: 250 |  Loss: (0.4099) | Acc: (86.00%) (27695/32128)
Epoch: 31 | Batch_idx: 260 |  Loss: (0.4083) | Acc: (86.00%) (28816/33408)
Epoch: 31 | Batch_idx: 270 |  Loss: (0.4095) | Acc: (86.00%) (29900/34688)
Epoch: 31 | Batch_idx: 280 |  Loss: (0.4077) | Acc: (86.00%) (31029/35968)
Epoch: 31 | Batch_idx: 290 |  Loss: (0.4075) | Acc: (86.00%) (32130/37248)
Epoch: 31 | Batch_idx: 300 |  Loss: (0.4078) | Acc: (86.00%) (33225/38528)
Epoch: 31 | Batch_idx: 310 |  Loss: (0.4076) | Acc: (86.00%) (34335/39808)
Epoch: 31 | Batch_idx: 320 |  Loss: (0.4085) | Acc: (86.00%) (35417/41088)
Epoch: 31 | Batch_idx: 330 |  Loss: (0.4079) | Acc: (86.00%) (36525/42368)
Epoch: 31 | Batch_idx: 340 |  Loss: (0.4071) | Acc: (86.00%) (37627/43648)
Epoch: 31 | Batch_idx: 350 |  Loss: (0.4077) | Acc: (86.00%) (38706/44928)
Epoch: 31 | Batch_idx: 360 |  Loss: (0.4069) | Acc: (86.00%) (39820/46208)
Epoch: 31 | Batch_idx: 370 |  Loss: (0.4064) | Acc: (86.00%) (40937/47488)
Epoch: 31 | Batch_idx: 380 |  Loss: (0.4058) | Acc: (86.00%) (42050/48768)
Epoch: 31 | Batch_idx: 390 |  Loss: (0.4060) | Acc: (86.00%) (43115/50000)
# TEST : Loss: (0.4487) | Acc: (84.00%) (8493/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[ 1.3424e-10, -1.2128e-09,  8.0401e-09],
          [-1.0279e-09,  1.2176e-09, -7.7641e-10],
          [ 3.5734e-08, -1.4646e-09,  2.4149e-10]],

         [[-7.7415e-10, -1.9281e-09,  5.3566e-09],
          [-1.2415e-09, -6.2235e-09, -1.2214e-09],
          [ 9.0915e-09, -1.5682e-09,  1.7136e-10]],

         [[-6.1196e-10, -7.1146e-09, -2.1101e-09],
          [-4.9251e-09, -7.3605e-09, -1.2330e-09],
          [ 7.4442e-10, -1.4917e-09, -7.9356e-11]]],


        [[[ 6.8997e-02, -6.0140e-02,  6.8836e-02],
          [ 1.9436e-02, -1.9728e-01,  1.2449e-02],
          [ 6.9048e-02,  2.8380e-02,  7.8154e-02]],

         [[-6.0183e-03, -1.2952e-01, -4.3671e-02],
          [-9.7585e-02, -2.9619e-01, -5.9541e-02],
          [ 3.8930e-03,  9.0511e-03,  9.2053e-02]],

         [[ 3.6472e-02, -9.6318e-03,  7.6448e-02],
          [ 2.5141e-02, -1.4030e-01,  2.1742e-02],
          [ 6.6321e-03, -1.4463e-02,  1.6017e-02]]],


        [[[-3.2773e-02, -5.4956e-02,  1.4361e-02],
          [-5.1978e-02, -5.1662e-02,  1.2640e-02],
          [-6.6227e-02, -9.2675e-02, -1.1266e-01]],

         [[ 5.1319e-02,  2.5081e-02,  1.0686e-02],
          [ 8.9996e-03,  1.2973e-02, -4.5677e-03],
          [ 3.7060e-02, -6.2236e-02,  3.4251e-02]],

         [[-2.4060e-02,  5.1995e-02, -4.7755e-02],
          [-3.9807e-02, -7.1984e-02,  5.5102e-02],
          [-3.4342e-02, -1.8179e-02, -4.1341e-02]]],


        ...,


        [[[-1.0647e-01,  9.3495e-02, -1.4131e-01],
          [-2.3515e-01, -1.0854e-01, -1.6416e-01],
          [-1.2686e-01,  5.3832e-02, -2.6448e-01]],

         [[ 7.1361e-02,  4.3175e-02,  1.4579e-02],
          [ 1.1234e-01, -1.4222e-01,  6.0743e-02],
          [ 3.0785e-02,  1.2168e-01, -1.7071e-01]],

         [[-9.9078e-02,  2.6076e-01,  9.0566e-02],
          [ 2.2939e-01,  2.1822e-01,  1.9418e-01],
          [ 1.7270e-01,  1.5803e-01, -4.8846e-02]]],


        [[[ 6.7487e-02, -1.2673e-01,  2.7295e-03],
          [ 3.1199e-02, -1.6408e-01,  3.4185e-02],
          [ 1.0054e-01, -1.2287e-01,  2.3427e-02]],

         [[ 1.7113e-01, -1.1668e-01,  9.2012e-02],
          [-9.9626e-02, -3.9881e-02, -5.1291e-02],
          [ 7.7484e-02,  1.1478e-01,  2.1100e-02]],

         [[-1.5815e-02, -9.7807e-02,  6.4875e-02],
          [-1.0683e-01, -2.9846e-01, -1.6647e-01],
          [ 4.1740e-02, -8.7862e-02, -1.4427e-01]]],


        [[[-1.7826e-02, -5.4633e-03, -1.5662e-02],
          [ 7.2338e-03, -7.0574e-03, -2.1854e-02],
          [ 1.1139e-02, -1.3987e-02, -9.5887e-03]],

         [[ 1.3879e-02,  4.0682e-03, -1.8625e-02],
          [-8.8432e-04, -2.6063e-03,  9.3655e-03],
          [-1.9614e-02, -1.6987e-02,  3.0762e-02]],

         [[ 4.8479e-03, -2.1930e-02, -5.0676e-03],
          [-6.9631e-03,  9.9609e-03,  8.5420e-03],
          [-3.5120e-02, -1.9325e-02, -7.4224e-03]]]],
       device='cuda:0', requires_grad=True)

conv1_weight_grad tensor([[[[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]]],


        [[[-0.0042, -0.0045, -0.0053],
          [ 0.0006,  0.0007,  0.0001],
          [-0.0038, -0.0040, -0.0035]],

         [[-0.0075, -0.0075, -0.0079],
          [-0.0023, -0.0019, -0.0023],
          [-0.0069, -0.0068, -0.0059]],

         [[-0.0047, -0.0045, -0.0048],
          [-0.0008, -0.0004, -0.0007],
          [-0.0051, -0.0048, -0.0039]]],


        [[[ 0.0000,  0.0000,  0.0000],
          [-0.0000,  0.0000, -0.0000],
          [-0.0000,  0.0000, -0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [-0.0000,  0.0000, -0.0000],
          [-0.0000,  0.0000, -0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [-0.0000,  0.0000, -0.0000],
          [-0.0000,  0.0000, -0.0000]]],


        ...,


        [[[ 0.0048,  0.0019,  0.0063],
          [ 0.0040,  0.0007,  0.0032],
          [ 0.0078,  0.0040, -0.0026]],

         [[ 0.0056,  0.0023,  0.0061],
          [ 0.0044,  0.0009,  0.0029],
          [ 0.0073,  0.0037, -0.0028]],

         [[ 0.0018, -0.0006,  0.0023],
          [ 0.0012, -0.0010,  0.0001],
          [ 0.0019, -0.0003, -0.0067]]],


        [[[-0.0077, -0.0093, -0.0061],
          [-0.0043, -0.0045, -0.0006],
          [-0.0070, -0.0071, -0.0032]],

         [[-0.0090, -0.0110, -0.0085],
          [-0.0048, -0.0052, -0.0021],
          [-0.0085, -0.0089, -0.0054]],

         [[-0.0033, -0.0049, -0.0028],
          [-0.0008, -0.0008,  0.0021],
          [-0.0049, -0.0049, -0.0015]]],


        [[[-0.0000, -0.0000, -0.0000],
          [-0.0000, -0.0000, -0.0000],
          [-0.0000, -0.0000, -0.0000]],

         [[-0.0000, -0.0000, -0.0000],
          [-0.0000, -0.0000, -0.0000],
          [-0.0000, -0.0000, -0.0000]],

         [[-0.0000, -0.0000, -0.0000],
          [-0.0000, -0.0000, -0.0000],
          [-0.0000, -0.0000, -0.0000]]]], device='cuda:0')

percentage_weight tensor([0.], device='cuda:0')

percentage_weight_grad tensor([-45.7708], device='cuda:0')

Epoch: 32 | Batch_idx: 0 |  Loss: (0.2763) | Acc: (91.00%) (117/128)
Epoch: 32 | Batch_idx: 10 |  Loss: (0.3721) | Acc: (87.00%) (1228/1408)
Epoch: 32 | Batch_idx: 20 |  Loss: (0.3567) | Acc: (87.00%) (2348/2688)
Epoch: 32 | Batch_idx: 30 |  Loss: (0.3561) | Acc: (87.00%) (3469/3968)
Epoch: 32 | Batch_idx: 40 |  Loss: (0.3557) | Acc: (87.00%) (4601/5248)
Epoch: 32 | Batch_idx: 50 |  Loss: (0.3560) | Acc: (87.00%) (5729/6528)
Epoch: 32 | Batch_idx: 60 |  Loss: (0.3522) | Acc: (87.00%) (6853/7808)
Epoch: 32 | Batch_idx: 70 |  Loss: (0.3545) | Acc: (87.00%) (7963/9088)
Epoch: 32 | Batch_idx: 80 |  Loss: (0.3516) | Acc: (87.00%) (9093/10368)
Epoch: 32 | Batch_idx: 90 |  Loss: (0.3535) | Acc: (87.00%) (10197/11648)
Epoch: 32 | Batch_idx: 100 |  Loss: (0.3504) | Acc: (87.00%) (11332/12928)
Epoch: 32 | Batch_idx: 110 |  Loss: (0.3507) | Acc: (87.00%) (12446/14208)
Epoch: 32 | Batch_idx: 120 |  Loss: (0.3485) | Acc: (87.00%) (13576/15488)
Epoch: 32 | Batch_idx: 130 |  Loss: (0.3509) | Acc: (87.00%) (14695/16768)
Epoch: 32 | Batch_idx: 140 |  Loss: (0.3527) | Acc: (87.00%) (15819/18048)
Epoch: 32 | Batch_idx: 150 |  Loss: (0.3531) | Acc: (87.00%) (16946/19328)
Epoch: 32 | Batch_idx: 160 |  Loss: (0.3524) | Acc: (87.00%) (18077/20608)
Epoch: 32 | Batch_idx: 170 |  Loss: (0.3506) | Acc: (87.00%) (19212/21888)
Epoch: 32 | Batch_idx: 180 |  Loss: (0.3512) | Acc: (87.00%) (20331/23168)
Epoch: 32 | Batch_idx: 190 |  Loss: (0.3495) | Acc: (87.00%) (21475/24448)
Epoch: 32 | Batch_idx: 200 |  Loss: (0.3509) | Acc: (87.00%) (22583/25728)
Epoch: 32 | Batch_idx: 210 |  Loss: (0.3492) | Acc: (87.00%) (23727/27008)
Epoch: 32 | Batch_idx: 220 |  Loss: (0.3500) | Acc: (87.00%) (24848/28288)
Epoch: 32 | Batch_idx: 230 |  Loss: (0.3490) | Acc: (87.00%) (25996/29568)
Epoch: 32 | Batch_idx: 240 |  Loss: (0.3492) | Acc: (87.00%) (27123/30848)
Epoch: 32 | Batch_idx: 250 |  Loss: (0.3502) | Acc: (87.00%) (28236/32128)
Epoch: 32 | Batch_idx: 260 |  Loss: (0.3521) | Acc: (87.00%) (29351/33408)
Epoch: 32 | Batch_idx: 270 |  Loss: (0.3540) | Acc: (87.00%) (30453/34688)
Epoch: 32 | Batch_idx: 280 |  Loss: (0.3533) | Acc: (87.00%) (31597/35968)
Epoch: 32 | Batch_idx: 290 |  Loss: (0.3528) | Acc: (87.00%) (32730/37248)
Epoch: 32 | Batch_idx: 300 |  Loss: (0.3532) | Acc: (87.00%) (33850/38528)
Epoch: 32 | Batch_idx: 310 |  Loss: (0.3522) | Acc: (87.00%) (34999/39808)
Epoch: 32 | Batch_idx: 320 |  Loss: (0.3517) | Acc: (87.00%) (36137/41088)
Epoch: 32 | Batch_idx: 330 |  Loss: (0.3510) | Acc: (87.00%) (37269/42368)
Epoch: 32 | Batch_idx: 340 |  Loss: (0.3505) | Acc: (87.00%) (38396/43648)
Epoch: 32 | Batch_idx: 350 |  Loss: (0.3509) | Acc: (87.00%) (39524/44928)
Epoch: 32 | Batch_idx: 360 |  Loss: (0.3511) | Acc: (87.00%) (40649/46208)
Epoch: 32 | Batch_idx: 370 |  Loss: (0.3517) | Acc: (87.00%) (41763/47488)
Epoch: 32 | Batch_idx: 380 |  Loss: (0.3526) | Acc: (87.00%) (42882/48768)
Epoch: 32 | Batch_idx: 390 |  Loss: (0.3523) | Acc: (87.00%) (43965/50000)
# TEST : Loss: (0.4577) | Acc: (84.00%) (8472/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[ 1.7448e-12, -2.5347e-11,  2.1216e-10],
          [-2.0620e-11,  2.8491e-11, -1.0763e-11],
          [ 1.2526e-09, -2.6323e-11,  2.1116e-12]],

         [[-8.9430e-12, -3.6800e-11,  1.3197e-10],
          [-2.1476e-11, -1.2987e-10, -1.5207e-11],
          [ 2.7727e-10, -2.4267e-11,  1.2138e-12]],

         [[-6.1321e-12, -1.2356e-10, -4.4039e-11],
          [-7.8576e-11, -1.4233e-10, -1.3841e-11],
          [ 1.8888e-11, -1.9704e-11, -4.5799e-13]]],


        [[[ 7.5752e-02, -5.2620e-02,  7.0130e-02],
          [ 1.2861e-02, -2.0195e-01,  6.2012e-03],
          [ 6.9514e-02,  3.8158e-02,  8.3309e-02]],

         [[ 2.5502e-03, -1.2193e-01, -4.7639e-02],
          [-1.0907e-01, -3.1570e-01, -7.7361e-02],
          [-3.0180e-03,  5.1804e-03,  8.1691e-02]],

         [[ 4.4766e-02, -1.0301e-03,  7.3588e-02],
          [ 1.8369e-02, -1.4790e-01,  9.2921e-03],
          [ 2.4565e-03, -1.2892e-02,  9.2051e-03]]],


        [[[-2.6660e-02, -4.6706e-02,  1.4408e-02],
          [-4.5291e-02, -4.5284e-02,  1.1943e-02],
          [-5.9748e-02, -8.3967e-02, -1.0284e-01]],

         [[ 4.7034e-02,  2.5433e-02,  1.2819e-02],
          [ 8.8208e-03,  1.3174e-02, -2.2419e-03],
          [ 3.4485e-02, -5.4634e-02,  3.2604e-02]],

         [[-1.9735e-02,  4.6813e-02, -4.1202e-02],
          [-3.5433e-02, -6.3995e-02,  4.9525e-02],
          [-3.1241e-02, -1.6596e-02, -3.7618e-02]]],


        ...,


        [[[-1.0369e-01,  9.3295e-02, -1.4307e-01],
          [-2.3383e-01, -1.0858e-01, -1.6222e-01],
          [-1.2925e-01,  5.2386e-02, -2.6148e-01]],

         [[ 7.3674e-02,  4.5055e-02,  1.3555e-02],
          [ 1.1549e-01, -1.3842e-01,  6.4185e-02],
          [ 3.0345e-02,  1.2176e-01, -1.6833e-01]],

         [[-9.2866e-02,  2.6690e-01,  9.2014e-02],
          [ 2.3643e-01,  2.2748e-01,  2.0268e-01],
          [ 1.7654e-01,  1.6500e-01, -4.0934e-02]]],


        [[[ 7.5089e-02, -1.0228e-01,  3.0482e-02],
          [ 2.6014e-02, -1.4346e-01,  5.4419e-02],
          [ 1.0484e-01, -1.0091e-01,  4.4144e-02]],

         [[ 1.4622e-01, -1.2758e-01,  9.0016e-02],
          [-1.3677e-01, -7.3390e-02, -6.2940e-02],
          [ 6.0794e-02,  1.0870e-01,  1.8052e-02]],

         [[-4.2118e-02, -1.0517e-01,  6.5985e-02],
          [-1.5174e-01, -3.3648e-01, -1.7402e-01],
          [ 1.6645e-02, -9.3730e-02, -1.4903e-01]]],


        [[[-1.2407e-02, -3.6467e-03, -9.4604e-03],
          [ 4.7240e-03, -4.7524e-03, -1.4083e-02],
          [ 7.6256e-03, -9.6891e-03, -8.3686e-03]],

         [[ 9.5336e-03,  2.4811e-03, -1.1632e-02],
          [-7.0057e-04, -1.9468e-03,  6.0644e-03],
          [-1.3525e-02, -1.1800e-02,  1.9027e-02]],

         [[ 3.1908e-03, -1.4021e-02, -3.1808e-03],
          [-4.7822e-03,  5.8433e-03,  5.1846e-03],
          [-2.3353e-02, -1.2735e-02, -6.4941e-03]]]],
       device='cuda:0', requires_grad=True)

conv1_weight_grad tensor([[[[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]]],


        [[[-0.0058, -0.0062, -0.0062],
          [-0.0030, -0.0041, -0.0044],
          [-0.0076, -0.0100, -0.0096]],

         [[-0.0052, -0.0049, -0.0051],
          [-0.0024, -0.0027, -0.0031],
          [-0.0076, -0.0089, -0.0083]],

         [[-0.0031, -0.0028, -0.0029],
          [-0.0021, -0.0025, -0.0024],
          [-0.0053, -0.0062, -0.0054]]],


        [[[-0.0000, -0.0000, -0.0000],
          [ 0.0000, -0.0000,  0.0000],
          [-0.0000, -0.0000,  0.0000]],

         [[-0.0000, -0.0000, -0.0000],
          [ 0.0000, -0.0000,  0.0000],
          [ 0.0000, -0.0000,  0.0000]],

         [[-0.0000, -0.0000, -0.0000],
          [ 0.0000, -0.0000,  0.0000],
          [-0.0000, -0.0000,  0.0000]]],


        ...,


        [[[-0.0107, -0.0020, -0.0027],
          [-0.0022,  0.0041, -0.0038],
          [-0.0029, -0.0008, -0.0119]],

         [[-0.0170, -0.0078, -0.0069],
          [-0.0117, -0.0047, -0.0105],
          [-0.0155, -0.0129, -0.0220]],

         [[-0.0118, -0.0049, -0.0028],
          [-0.0044, -0.0002, -0.0059],
          [-0.0058, -0.0055, -0.0158]]],


        [[[-0.0067, -0.0041, -0.0037],
          [-0.0061, -0.0015, -0.0006],
          [-0.0086, -0.0038, -0.0021]],

         [[-0.0088, -0.0063, -0.0067],
          [-0.0083, -0.0038, -0.0038],
          [-0.0115, -0.0065, -0.0057]],

         [[-0.0036, -0.0019, -0.0032],
          [-0.0042, -0.0006, -0.0013],
          [-0.0069, -0.0025, -0.0025]]],


        [[[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]]]], device='cuda:0')

percentage_weight tensor([0.], device='cuda:0')

percentage_weight_grad tensor([-45.7708], device='cuda:0')

False Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True _Gate(
  (sig): Sigmoid()
)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True _Gate(
  (sig): Sigmoid()
)
False Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True _Gate(
  (sig): Sigmoid()
)
False Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True _Gate(
  (sig): Sigmoid()
)
False Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True _Gate(
  (sig): Sigmoid()
)
False Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True _Gate(
  (sig): Sigmoid()
)
False Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True _Gate(
  (sig): Sigmoid()
)
False Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True _Gate(
  (sig): Sigmoid()
)
False Linear(in_features=512, out_features=10, bias=True)
Epoch: 33 | Batch_idx: 0 |  Loss: (0.2256) | Acc: (92.00%) (118/128)
Epoch: 33 | Batch_idx: 10 |  Loss: (0.3380) | Acc: (88.00%) (1249/1408)
Epoch: 33 | Batch_idx: 20 |  Loss: (0.3406) | Acc: (88.00%) (2377/2688)
Epoch: 33 | Batch_idx: 30 |  Loss: (0.3346) | Acc: (88.00%) (3517/3968)
Epoch: 33 | Batch_idx: 40 |  Loss: (0.3357) | Acc: (88.00%) (4657/5248)
Epoch: 33 | Batch_idx: 50 |  Loss: (0.3436) | Acc: (88.00%) (5775/6528)
Epoch: 33 | Batch_idx: 60 |  Loss: (0.3441) | Acc: (88.00%) (6916/7808)
Epoch: 33 | Batch_idx: 70 |  Loss: (0.3443) | Acc: (88.00%) (8055/9088)
Epoch: 33 | Batch_idx: 80 |  Loss: (0.3442) | Acc: (88.00%) (9183/10368)
Epoch: 33 | Batch_idx: 90 |  Loss: (0.3437) | Acc: (88.00%) (10315/11648)
Epoch: 33 | Batch_idx: 100 |  Loss: (0.3421) | Acc: (88.00%) (11454/12928)
Epoch: 33 | Batch_idx: 110 |  Loss: (0.3427) | Acc: (88.00%) (12584/14208)
Epoch: 33 | Batch_idx: 120 |  Loss: (0.3424) | Acc: (88.00%) (13710/15488)
Epoch: 33 | Batch_idx: 130 |  Loss: (0.3421) | Acc: (88.00%) (14826/16768)
Epoch: 33 | Batch_idx: 140 |  Loss: (0.3411) | Acc: (88.00%) (15972/18048)
Epoch: 33 | Batch_idx: 150 |  Loss: (0.3388) | Acc: (88.00%) (17124/19328)
Epoch: 33 | Batch_idx: 160 |  Loss: (0.3367) | Acc: (88.00%) (18270/20608)
Epoch: 33 | Batch_idx: 170 |  Loss: (0.3353) | Acc: (88.00%) (19412/21888)
Epoch: 33 | Batch_idx: 180 |  Loss: (0.3343) | Acc: (88.00%) (20552/23168)
Epoch: 33 | Batch_idx: 190 |  Loss: (0.3328) | Acc: (88.00%) (21696/24448)
Epoch: 33 | Batch_idx: 200 |  Loss: (0.3312) | Acc: (88.00%) (22854/25728)
Epoch: 33 | Batch_idx: 210 |  Loss: (0.3301) | Acc: (88.00%) (23998/27008)
Epoch: 33 | Batch_idx: 220 |  Loss: (0.3306) | Acc: (88.00%) (25129/28288)
Epoch: 33 | Batch_idx: 230 |  Loss: (0.3300) | Acc: (88.00%) (26284/29568)
Epoch: 33 | Batch_idx: 240 |  Loss: (0.3299) | Acc: (88.00%) (27414/30848)
Epoch: 33 | Batch_idx: 250 |  Loss: (0.3302) | Acc: (88.00%) (28546/32128)
Epoch: 33 | Batch_idx: 260 |  Loss: (0.3298) | Acc: (88.00%) (29684/33408)
Epoch: 33 | Batch_idx: 270 |  Loss: (0.3294) | Acc: (88.00%) (30819/34688)
Epoch: 33 | Batch_idx: 280 |  Loss: (0.3294) | Acc: (88.00%) (31959/35968)
Epoch: 33 | Batch_idx: 290 |  Loss: (0.3284) | Acc: (88.00%) (33115/37248)
Epoch: 33 | Batch_idx: 300 |  Loss: (0.3269) | Acc: (88.00%) (34282/38528)
Epoch: 33 | Batch_idx: 310 |  Loss: (0.3257) | Acc: (88.00%) (35427/39808)
Epoch: 33 | Batch_idx: 320 |  Loss: (0.3250) | Acc: (89.00%) (36582/41088)
Epoch: 33 | Batch_idx: 330 |  Loss: (0.3243) | Acc: (89.00%) (37734/42368)
Epoch: 33 | Batch_idx: 340 |  Loss: (0.3229) | Acc: (89.00%) (38886/43648)
Epoch: 33 | Batch_idx: 350 |  Loss: (0.3221) | Acc: (89.00%) (40039/44928)
Epoch: 33 | Batch_idx: 360 |  Loss: (0.3205) | Acc: (89.00%) (41213/46208)
Epoch: 33 | Batch_idx: 370 |  Loss: (0.3198) | Acc: (89.00%) (42373/47488)
Epoch: 33 | Batch_idx: 380 |  Loss: (0.3195) | Acc: (89.00%) (43521/48768)
Epoch: 33 | Batch_idx: 390 |  Loss: (0.3192) | Acc: (89.00%) (44614/50000)
# TEST : Loss: (0.3583) | Acc: (88.00%) (8809/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[ 7.5561e-15, -2.0316e-13,  2.2952e-12],
          [-1.5677e-13,  2.6413e-13, -5.0688e-14],
          [ 1.9486e-11, -1.7363e-13,  5.4409e-15]],

         [[-3.3204e-14, -2.6235e-13,  1.3072e-12],
          [-1.3482e-13, -1.0388e-12, -6.2262e-14],
          [ 3.6105e-12, -1.3185e-13,  2.3680e-15]],

         [[-1.8898e-14, -7.7969e-13, -3.5234e-13],
          [-4.4418e-13, -1.0319e-12, -4.9503e-14],
          [ 1.9429e-13, -8.7146e-14, -6.8071e-16]]],


        [[[ 7.7856e-02, -4.8576e-02,  7.2401e-02],
          [ 1.4560e-02, -1.9422e-01,  1.0564e-02],
          [ 7.0217e-02,  4.1095e-02,  8.7058e-02]],

         [[ 4.9602e-03, -1.1751e-01, -4.4669e-02],
          [-1.0550e-01, -3.0218e-01, -7.2341e-02],
          [-1.2467e-03,  8.2282e-03,  8.4770e-02]],

         [[ 4.6253e-02,  5.0704e-04,  7.3726e-02],
          [ 1.9646e-02, -1.4038e-01,  1.1807e-02],
          [ 3.8224e-03, -1.0127e-02,  1.2038e-02]]],


        [[[-2.2065e-02, -3.9457e-02,  1.3034e-02],
          [-3.8464e-02, -3.8815e-02,  1.0499e-02],
          [-5.2947e-02, -7.4819e-02, -9.2572e-02]],

         [[ 3.8990e-02,  2.1600e-02,  1.1301e-02],
          [ 6.9938e-03,  1.0857e-02, -2.1365e-03],
          [ 3.0082e-02, -4.8592e-02,  2.8980e-02]],

         [[-1.6407e-02,  4.0401e-02, -3.5376e-02],
          [-3.0381e-02, -5.5101e-02,  4.3330e-02],
          [-2.7770e-02, -1.4846e-02, -3.3766e-02]]],


        ...,


        [[[-1.0482e-01,  9.0241e-02, -1.4616e-01],
          [-2.3474e-01, -1.1093e-01, -1.6444e-01],
          [-1.3078e-01,  4.9756e-02, -2.6300e-01]],

         [[ 7.2727e-02,  4.2620e-02,  1.0266e-02],
          [ 1.1470e-01, -1.3986e-01,  6.1904e-02],
          [ 2.9426e-02,  1.1993e-01, -1.6940e-01]],

         [[-9.3121e-02,  2.6408e-01,  8.8648e-02],
          [ 2.3532e-01,  2.2515e-01,  2.0004e-01],
          [ 1.7510e-01,  1.6281e-01, -4.2419e-02]]],


        [[[ 7.6186e-02, -9.9044e-02,  3.1285e-02],
          [ 2.9175e-02, -1.3600e-01,  5.7269e-02],
          [ 1.0696e-01, -9.6169e-02,  4.7452e-02]],

         [[ 1.4632e-01, -1.2477e-01,  8.9711e-02],
          [-1.3213e-01, -6.7448e-02, -5.9054e-02],
          [ 6.3168e-02,  1.1086e-01,  2.1416e-02]],

         [[-4.0789e-02, -1.0336e-01,  6.4547e-02],
          [-1.4799e-01, -3.1889e-01, -1.7039e-01],
          [ 1.6974e-02, -9.2594e-02, -1.4692e-01]]],


        [[[-8.0128e-03, -2.1386e-03, -5.1384e-03],
          [ 2.8810e-03, -2.7505e-03, -8.2009e-03],
          [ 4.8555e-03, -6.0561e-03, -5.1741e-03]],

         [[ 6.0186e-03,  1.4562e-03, -6.5592e-03],
          [-4.1772e-04, -1.1392e-03,  3.6243e-03],
          [-8.5289e-03, -7.4134e-03,  1.1885e-02]],

         [[ 1.9883e-03, -7.9368e-03, -1.7133e-03],
          [-2.8507e-03,  3.2985e-03,  2.9569e-03],
          [-1.4047e-02, -7.4130e-03, -3.7726e-03]]]], device='cuda:0')

conv1_weight_grad tensor([[[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        ...,


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]]], device='cuda:0')

percentage_weight tensor([0.], device='cuda:0', requires_grad=True)

percentage_weight_grad tensor([-48.4008], device='cuda:0')

Epoch: 34 | Batch_idx: 0 |  Loss: (0.2123) | Acc: (92.00%) (119/128)
Epoch: 34 | Batch_idx: 10 |  Loss: (0.2701) | Acc: (91.00%) (1284/1408)
Epoch: 34 | Batch_idx: 20 |  Loss: (0.2789) | Acc: (90.00%) (2443/2688)
Epoch: 34 | Batch_idx: 30 |  Loss: (0.2842) | Acc: (90.00%) (3594/3968)
Epoch: 34 | Batch_idx: 40 |  Loss: (0.2920) | Acc: (90.00%) (4734/5248)
Epoch: 34 | Batch_idx: 50 |  Loss: (0.2917) | Acc: (90.00%) (5895/6528)
Epoch: 34 | Batch_idx: 60 |  Loss: (0.2906) | Acc: (90.00%) (7052/7808)
Epoch: 34 | Batch_idx: 70 |  Loss: (0.2897) | Acc: (90.00%) (8209/9088)
Epoch: 34 | Batch_idx: 80 |  Loss: (0.2917) | Acc: (90.00%) (9350/10368)
Epoch: 34 | Batch_idx: 90 |  Loss: (0.2904) | Acc: (90.00%) (10516/11648)
Epoch: 34 | Batch_idx: 100 |  Loss: (0.2915) | Acc: (90.00%) (11665/12928)
Epoch: 34 | Batch_idx: 110 |  Loss: (0.2920) | Acc: (90.00%) (12817/14208)
Epoch: 34 | Batch_idx: 120 |  Loss: (0.2936) | Acc: (90.00%) (13956/15488)
Epoch: 34 | Batch_idx: 130 |  Loss: (0.2953) | Acc: (90.00%) (15105/16768)
Epoch: 34 | Batch_idx: 140 |  Loss: (0.2940) | Acc: (90.00%) (16273/18048)
Epoch: 34 | Batch_idx: 150 |  Loss: (0.2952) | Acc: (90.00%) (17406/19328)
Epoch: 34 | Batch_idx: 160 |  Loss: (0.2941) | Acc: (90.00%) (18577/20608)
Epoch: 34 | Batch_idx: 170 |  Loss: (0.2958) | Acc: (90.00%) (19718/21888)
Epoch: 34 | Batch_idx: 180 |  Loss: (0.2965) | Acc: (90.00%) (20863/23168)
Epoch: 34 | Batch_idx: 190 |  Loss: (0.2961) | Acc: (90.00%) (22026/24448)
Epoch: 34 | Batch_idx: 200 |  Loss: (0.2960) | Acc: (90.00%) (23187/25728)
Epoch: 34 | Batch_idx: 210 |  Loss: (0.2958) | Acc: (90.00%) (24343/27008)
Epoch: 34 | Batch_idx: 220 |  Loss: (0.2961) | Acc: (90.00%) (25494/28288)
Epoch: 34 | Batch_idx: 230 |  Loss: (0.2969) | Acc: (90.00%) (26627/29568)
Epoch: 34 | Batch_idx: 240 |  Loss: (0.2968) | Acc: (90.00%) (27776/30848)
Epoch: 34 | Batch_idx: 250 |  Loss: (0.2958) | Acc: (90.00%) (28940/32128)
Epoch: 34 | Batch_idx: 260 |  Loss: (0.2960) | Acc: (90.00%) (30086/33408)
Epoch: 34 | Batch_idx: 270 |  Loss: (0.2956) | Acc: (90.00%) (31246/34688)
Epoch: 34 | Batch_idx: 280 |  Loss: (0.2954) | Acc: (90.00%) (32403/35968)
Epoch: 34 | Batch_idx: 290 |  Loss: (0.2955) | Acc: (90.00%) (33553/37248)
Epoch: 34 | Batch_idx: 300 |  Loss: (0.2955) | Acc: (90.00%) (34714/38528)
Epoch: 34 | Batch_idx: 310 |  Loss: (0.2947) | Acc: (90.00%) (35869/39808)
Epoch: 34 | Batch_idx: 320 |  Loss: (0.2944) | Acc: (90.00%) (37022/41088)
Epoch: 34 | Batch_idx: 330 |  Loss: (0.2939) | Acc: (90.00%) (38193/42368)
Epoch: 34 | Batch_idx: 340 |  Loss: (0.2939) | Acc: (90.00%) (39359/43648)
Epoch: 34 | Batch_idx: 350 |  Loss: (0.2942) | Acc: (90.00%) (40505/44928)
Epoch: 34 | Batch_idx: 360 |  Loss: (0.2938) | Acc: (90.00%) (41659/46208)
Epoch: 34 | Batch_idx: 370 |  Loss: (0.2940) | Acc: (90.00%) (42808/47488)
Epoch: 34 | Batch_idx: 380 |  Loss: (0.2940) | Acc: (90.00%) (43969/48768)
Epoch: 34 | Batch_idx: 390 |  Loss: (0.2940) | Acc: (90.00%) (45084/50000)
# TEST : Loss: (0.3454) | Acc: (88.00%) (8849/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[ 7.6479e-18, -4.6672e-16,  7.8201e-15],
          [-3.3586e-16,  7.3496e-16, -5.7418e-17],
          [ 1.0660e-13, -3.0824e-16,  2.7243e-18]],

         [[-2.7314e-17, -5.1624e-16,  3.9682e-15],
          [-2.2411e-16, -2.3802e-15, -5.8441e-17],
          [ 1.5673e-14, -1.8083e-16,  8.0883e-19]],

         [[-1.2079e-17, -1.3050e-15, -8.0748e-16],
          [-6.4221e-16, -2.0761e-15, -3.8714e-17],
          [ 6.1973e-16, -9.0736e-17, -1.5930e-19]]],


        [[[ 7.6481e-02, -4.7619e-02,  7.1185e-02],
          [ 1.4259e-02, -1.8888e-01,  1.0362e-02],
          [ 6.9065e-02,  4.0379e-02,  8.5721e-02]],

         [[ 4.8609e-03, -1.1473e-01, -4.3861e-02],
          [-1.0293e-01, -2.8952e-01, -7.0790e-02],
          [-1.2252e-03,  8.0735e-03,  8.3428e-02]],

         [[ 4.5251e-02,  4.9388e-04,  7.2259e-02],
          [ 1.9132e-02, -1.3445e-01,  1.1529e-02],
          [ 3.7489e-03, -9.9129e-03,  1.1825e-02]]],


        [[[-1.8067e-02, -3.2695e-02,  1.1059e-02],
          [-3.1496e-02, -3.2181e-02,  8.9837e-03],
          [-4.5685e-02, -6.5031e-02, -8.1433e-02]],

         [[ 3.0626e-02,  1.7228e-02,  9.2970e-03],
          [ 5.5574e-03,  8.7983e-03, -1.7966e-03],
          [ 2.5701e-02, -4.1962e-02,  2.5283e-02]],

         [[-1.3481e-02,  3.3338e-02, -2.9752e-02],
          [-2.5078e-02, -4.5840e-02,  3.6915e-02],
          [-2.3975e-02, -1.2903e-02, -2.9532e-02]]],


        ...,


        [[[-1.0454e-01,  9.0010e-02, -1.4579e-01],
          [-2.3413e-01, -1.1064e-01, -1.6403e-01],
          [-1.3045e-01,  4.9629e-02, -2.6234e-01]],

         [[ 7.2525e-02,  4.2504e-02,  1.0239e-02],
          [ 1.1439e-01, -1.3948e-01,  6.1742e-02],
          [ 2.9347e-02,  1.1961e-01, -1.6897e-01]],

         [[-9.2828e-02,  2.6325e-01,  8.8381e-02],
          [ 2.3459e-01,  2.2445e-01,  1.9944e-01],
          [ 1.7457e-01,  1.6232e-01, -4.2297e-02]]],


        [[[ 7.5407e-02, -9.7786e-02,  3.0938e-02],
          [ 2.8804e-02, -1.3328e-01,  5.6408e-02],
          [ 1.0591e-01, -9.5019e-02,  4.6938e-02]],

         [[ 1.4469e-01, -1.2294e-01,  8.8601e-02],
          [-1.3025e-01, -6.5575e-02, -5.7963e-02],
          [ 6.2506e-02,  1.0934e-01,  2.1157e-02]],

         [[-4.0215e-02, -1.0132e-01,  6.3501e-02],
          [-1.4510e-01, -2.9696e-01, -1.6491e-01],
          [ 1.6742e-02, -9.0747e-02, -1.4440e-01]]],


        [[[-4.7029e-03, -1.1156e-03, -2.4402e-03],
          [ 1.5770e-03, -1.4117e-03, -4.2411e-03],
          [ 2.8012e-03, -3.4151e-03, -2.8792e-03]],

         [[ 3.4355e-03,  7.6037e-04, -3.2613e-03],
          [-2.2216e-04, -5.9256e-04,  1.9346e-03],
          [-4.8616e-03, -4.2065e-03,  6.6968e-03]],

         [[ 1.1170e-03, -3.9647e-03, -8.0537e-04],
          [-1.5170e-03,  1.6421e-03,  1.4906e-03],
          [-7.5588e-03, -3.8318e-03, -1.9454e-03]]]], device='cuda:0')

conv1_weight_grad tensor([[[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        ...,


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]]], device='cuda:0')

percentage_weight tensor([0.], device='cuda:0', requires_grad=True)

percentage_weight_grad tensor([-51.4369], device='cuda:0')

True Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False _Gate(
  (sig): Sigmoid()
)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False _Gate(
  (sig): Sigmoid()
)
True Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False _Gate(
  (sig): Sigmoid()
)
True Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False _Gate(
  (sig): Sigmoid()
)
True Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False _Gate(
  (sig): Sigmoid()
)
True Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False _Gate(
  (sig): Sigmoid()
)
True Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False _Gate(
  (sig): Sigmoid()
)
True Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False _Gate(
  (sig): Sigmoid()
)
True Linear(in_features=512, out_features=10, bias=True)
Epoch: 35 | Batch_idx: 0 |  Loss: (0.2184) | Acc: (90.00%) (116/128)
Epoch: 35 | Batch_idx: 10 |  Loss: (0.2784) | Acc: (90.00%) (1273/1408)
Epoch: 35 | Batch_idx: 20 |  Loss: (0.3162) | Acc: (89.00%) (2397/2688)
Epoch: 35 | Batch_idx: 30 |  Loss: (0.3325) | Acc: (89.00%) (3537/3968)
Epoch: 35 | Batch_idx: 40 |  Loss: (0.3452) | Acc: (88.00%) (4641/5248)
Epoch: 35 | Batch_idx: 50 |  Loss: (0.3601) | Acc: (87.00%) (5734/6528)
Epoch: 35 | Batch_idx: 60 |  Loss: (0.3643) | Acc: (87.00%) (6840/7808)
Epoch: 35 | Batch_idx: 70 |  Loss: (0.3677) | Acc: (87.00%) (7960/9088)
Epoch: 35 | Batch_idx: 80 |  Loss: (0.3676) | Acc: (87.00%) (9087/10368)
Epoch: 35 | Batch_idx: 90 |  Loss: (0.3736) | Acc: (87.00%) (10193/11648)
Epoch: 35 | Batch_idx: 100 |  Loss: (0.3789) | Acc: (87.00%) (11288/12928)
Epoch: 35 | Batch_idx: 110 |  Loss: (0.3806) | Acc: (87.00%) (12394/14208)
Epoch: 35 | Batch_idx: 120 |  Loss: (0.3821) | Acc: (87.00%) (13510/15488)
Epoch: 35 | Batch_idx: 130 |  Loss: (0.3837) | Acc: (87.00%) (14617/16768)
Epoch: 35 | Batch_idx: 140 |  Loss: (0.3823) | Acc: (87.00%) (15739/18048)
Epoch: 35 | Batch_idx: 150 |  Loss: (0.3830) | Acc: (87.00%) (16847/19328)
Epoch: 35 | Batch_idx: 160 |  Loss: (0.3886) | Acc: (87.00%) (17932/20608)
Epoch: 35 | Batch_idx: 170 |  Loss: (0.3921) | Acc: (86.00%) (19024/21888)
Epoch: 35 | Batch_idx: 180 |  Loss: (0.3923) | Acc: (86.00%) (20124/23168)
Epoch: 35 | Batch_idx: 190 |  Loss: (0.3928) | Acc: (86.00%) (21245/24448)
Epoch: 35 | Batch_idx: 200 |  Loss: (0.3915) | Acc: (86.00%) (22360/25728)
Epoch: 35 | Batch_idx: 210 |  Loss: (0.3928) | Acc: (86.00%) (23474/27008)
Epoch: 35 | Batch_idx: 220 |  Loss: (0.3919) | Acc: (86.00%) (24589/28288)
Epoch: 35 | Batch_idx: 230 |  Loss: (0.3909) | Acc: (86.00%) (25704/29568)
Epoch: 35 | Batch_idx: 240 |  Loss: (0.3912) | Acc: (86.00%) (26816/30848)
Epoch: 35 | Batch_idx: 250 |  Loss: (0.3901) | Acc: (86.00%) (27936/32128)
Epoch: 35 | Batch_idx: 260 |  Loss: (0.3902) | Acc: (86.00%) (29034/33408)
Epoch: 35 | Batch_idx: 270 |  Loss: (0.3887) | Acc: (86.00%) (30152/34688)
Epoch: 35 | Batch_idx: 280 |  Loss: (0.3880) | Acc: (86.00%) (31263/35968)
Epoch: 35 | Batch_idx: 290 |  Loss: (0.3883) | Acc: (86.00%) (32377/37248)
Epoch: 35 | Batch_idx: 300 |  Loss: (0.3863) | Acc: (86.00%) (33517/38528)
Epoch: 35 | Batch_idx: 310 |  Loss: (0.3863) | Acc: (86.00%) (34630/39808)
Epoch: 35 | Batch_idx: 320 |  Loss: (0.3858) | Acc: (87.00%) (35752/41088)
Epoch: 35 | Batch_idx: 330 |  Loss: (0.3860) | Acc: (87.00%) (36868/42368)
Epoch: 35 | Batch_idx: 340 |  Loss: (0.3855) | Acc: (87.00%) (37983/43648)
Epoch: 35 | Batch_idx: 350 |  Loss: (0.3842) | Acc: (87.00%) (39109/44928)
Epoch: 35 | Batch_idx: 360 |  Loss: (0.3840) | Acc: (87.00%) (40229/46208)
Epoch: 35 | Batch_idx: 370 |  Loss: (0.3838) | Acc: (87.00%) (41350/47488)
Epoch: 35 | Batch_idx: 380 |  Loss: (0.3830) | Acc: (87.00%) (42478/48768)
Epoch: 35 | Batch_idx: 390 |  Loss: (0.3817) | Acc: (87.00%) (43573/50000)
# TEST : Loss: (0.4404) | Acc: (85.00%) (8536/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[ 1.0411e-21, -1.9967e-19,  5.7274e-18],
          [-1.3054e-19,  4.0876e-19, -9.1699e-21],
          [ 1.4753e-16, -9.2379e-20,  1.3373e-22]],

         [[-2.7642e-21, -1.7843e-19,  2.4846e-18],
          [-6.1301e-20, -1.0146e-18, -7.1445e-21],
          [ 1.5915e-17, -3.7808e-20,  2.2399e-23]],

         [[-8.4838e-22, -3.6038e-19, -3.4433e-19],
          [-1.4459e-19, -7.3997e-19, -3.6429e-21],
          [ 4.1504e-19, -1.2858e-20, -2.4667e-24]]],


        [[[ 9.4720e-02, -4.3996e-02,  8.6325e-02],
          [ 1.7500e-02, -2.1483e-01,  4.3845e-04],
          [ 7.0956e-02,  1.2078e-02,  6.0605e-02]],

         [[ 2.0893e-02, -1.0848e-01, -2.4437e-02],
          [-9.5947e-02, -3.0476e-01, -6.9878e-02],
          [ 5.1470e-04, -1.1716e-02,  6.6470e-02]],

         [[ 4.0652e-02, -8.8057e-03,  7.3363e-02],
          [ 7.6496e-03, -1.6478e-01, -5.7900e-03],
          [-9.0327e-03, -3.9689e-02, -1.7993e-02]]],


        [[[-2.7050e-02, -4.2532e-02, -4.6816e-03],
          [-3.2690e-02, -3.2490e-02, -3.7694e-04],
          [-4.5817e-02, -6.0515e-02, -7.5145e-02]],

         [[ 3.6832e-03, -1.1005e-02, -9.5753e-03],
          [-6.2142e-03, -3.7030e-03, -9.8092e-03],
          [ 1.1716e-02, -4.4332e-02,  1.5864e-02]],

         [[-1.6422e-02,  1.4126e-02, -3.3265e-02],
          [-1.6914e-02, -3.9788e-02,  2.5609e-02],
          [-1.6954e-02, -1.2097e-02, -2.6755e-02]]],


        ...,


        [[[-1.0657e-01,  8.7177e-02, -1.5010e-01],
          [-2.3372e-01, -1.1142e-01, -1.7061e-01],
          [-1.3967e-01,  4.4251e-02, -2.6926e-01]],

         [[ 6.6969e-02,  4.1287e-02,  6.9181e-03],
          [ 1.1499e-01, -1.3514e-01,  5.8440e-02],
          [ 2.1398e-02,  1.1813e-01, -1.7368e-01]],

         [[-9.6726e-02,  2.6387e-01,  8.5600e-02],
          [ 2.3839e-01,  2.3458e-01,  2.0087e-01],
          [ 1.6868e-01,  1.6756e-01, -4.3090e-02]]],


        [[[ 9.6550e-02, -8.5879e-02,  4.3932e-02],
          [ 3.6913e-02, -1.4083e-01,  5.3379e-02],
          [ 1.2182e-01, -9.3760e-02,  3.3925e-02]],

         [[ 1.5409e-01, -1.1736e-01,  9.7585e-02],
          [-1.2959e-01, -7.8647e-02, -5.6236e-02],
          [ 6.5181e-02,  1.0417e-01,  9.3896e-03]],

         [[-3.4837e-02, -1.0364e-01,  5.6655e-02],
          [-1.5006e-01, -3.2399e-01, -1.8164e-01],
          [ 7.8344e-03, -1.0512e-01, -1.6972e-01]]],


        [[[-2.4890e-03, -6.1264e-04, -1.1531e-03],
          [ 7.4657e-04, -6.1428e-04, -1.9719e-03],
          [ 1.6106e-03, -1.6885e-03, -1.4639e-03]],

         [[ 1.4918e-03,  4.4044e-04, -1.5889e-03],
          [-4.1428e-04, -5.0888e-05,  7.8781e-04],
          [-2.5748e-03, -2.1208e-03,  3.4307e-03]],

         [[ 4.9900e-04, -1.6023e-03, -4.5908e-04],
          [-7.1131e-04,  9.2457e-04,  5.8514e-04],
          [-3.5762e-03, -1.6915e-03, -9.6589e-04]]]],
       device='cuda:0', requires_grad=True)

conv1_weight_grad tensor([[[[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]]],


        [[[ 0.0022,  0.0020,  0.0040],
          [-0.0009, -0.0001,  0.0028],
          [-0.0032, -0.0008,  0.0012]],

         [[ 0.0017,  0.0014,  0.0036],
          [-0.0002,  0.0003,  0.0028],
          [-0.0013,  0.0005,  0.0017]],

         [[ 0.0025,  0.0015,  0.0028],
          [ 0.0011,  0.0009,  0.0024],
          [ 0.0007,  0.0017,  0.0022]]],


        [[[ 0.0000,  0.0000,  0.0001],
          [-0.0000, -0.0000, -0.0000],
          [ 0.0000, -0.0000,  0.0000]],

         [[ 0.0001,  0.0000,  0.0000],
          [-0.0000, -0.0000, -0.0000],
          [ 0.0000, -0.0000,  0.0000]],

         [[ 0.0000, -0.0000,  0.0000],
          [-0.0000, -0.0000, -0.0000],
          [-0.0000, -0.0000,  0.0000]]],


        ...,


        [[[-0.0090, -0.0106, -0.0047],
          [-0.0061, -0.0095, -0.0078],
          [ 0.0024, -0.0030, -0.0072]],

         [[ 0.0006, -0.0014,  0.0036],
          [ 0.0015, -0.0014, -0.0007],
          [ 0.0114,  0.0068,  0.0016]],

         [[-0.0059, -0.0071, -0.0000],
          [-0.0098, -0.0097, -0.0048],
          [-0.0003, -0.0015, -0.0013]]],


        [[[-0.0033, -0.0019, -0.0013],
          [-0.0043, -0.0013,  0.0003],
          [-0.0134, -0.0074, -0.0086]],

         [[-0.0066, -0.0058, -0.0052],
          [-0.0065, -0.0034, -0.0022],
          [-0.0137, -0.0073, -0.0086]],

         [[-0.0039, -0.0042, -0.0061],
          [-0.0035, -0.0018, -0.0029],
          [-0.0058, -0.0011, -0.0049]]],


        [[[-0.0000, -0.0000, -0.0000],
          [-0.0000,  0.0000,  0.0000],
          [-0.0000,  0.0000,  0.0000]],

         [[-0.0000, -0.0000, -0.0000],
          [-0.0000,  0.0000,  0.0000],
          [-0.0000,  0.0000,  0.0000]],

         [[-0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]]]], device='cuda:0')

percentage_weight tensor([0.], device='cuda:0')

percentage_weight_grad tensor([-51.4369], device='cuda:0')

Epoch: 36 | Batch_idx: 0 |  Loss: (0.3607) | Acc: (85.00%) (110/128)
Epoch: 36 | Batch_idx: 10 |  Loss: (0.3762) | Acc: (87.00%) (1226/1408)
Epoch: 36 | Batch_idx: 20 |  Loss: (0.3381) | Acc: (88.00%) (2378/2688)
Epoch: 36 | Batch_idx: 30 |  Loss: (0.3255) | Acc: (89.00%) (3532/3968)
Epoch: 36 | Batch_idx: 40 |  Loss: (0.3286) | Acc: (88.00%) (4665/5248)
Epoch: 36 | Batch_idx: 50 |  Loss: (0.3372) | Acc: (88.00%) (5782/6528)
Epoch: 36 | Batch_idx: 60 |  Loss: (0.3405) | Acc: (88.00%) (6906/7808)
Epoch: 36 | Batch_idx: 70 |  Loss: (0.3360) | Acc: (88.00%) (8051/9088)
Epoch: 36 | Batch_idx: 80 |  Loss: (0.3403) | Acc: (88.00%) (9158/10368)
Epoch: 36 | Batch_idx: 90 |  Loss: (0.3389) | Acc: (88.00%) (10299/11648)
Epoch: 36 | Batch_idx: 100 |  Loss: (0.3373) | Acc: (88.00%) (11443/12928)
Epoch: 36 | Batch_idx: 110 |  Loss: (0.3392) | Acc: (88.00%) (12568/14208)
Epoch: 36 | Batch_idx: 120 |  Loss: (0.3390) | Acc: (88.00%) (13699/15488)
Epoch: 36 | Batch_idx: 130 |  Loss: (0.3405) | Acc: (88.00%) (14825/16768)
Epoch: 36 | Batch_idx: 140 |  Loss: (0.3358) | Acc: (88.00%) (15988/18048)
Epoch: 36 | Batch_idx: 150 |  Loss: (0.3388) | Acc: (88.00%) (17107/19328)
Epoch: 36 | Batch_idx: 160 |  Loss: (0.3369) | Acc: (88.00%) (18247/20608)
Epoch: 36 | Batch_idx: 170 |  Loss: (0.3372) | Acc: (88.00%) (19378/21888)
Epoch: 36 | Batch_idx: 180 |  Loss: (0.3388) | Acc: (88.00%) (20498/23168)
Epoch: 36 | Batch_idx: 190 |  Loss: (0.3379) | Acc: (88.00%) (21640/24448)
Epoch: 36 | Batch_idx: 200 |  Loss: (0.3389) | Acc: (88.00%) (22763/25728)
Epoch: 36 | Batch_idx: 210 |  Loss: (0.3375) | Acc: (88.00%) (23906/27008)
Epoch: 36 | Batch_idx: 220 |  Loss: (0.3366) | Acc: (88.00%) (25054/28288)
Epoch: 36 | Batch_idx: 230 |  Loss: (0.3356) | Acc: (88.00%) (26194/29568)
Epoch: 36 | Batch_idx: 240 |  Loss: (0.3364) | Acc: (88.00%) (27316/30848)
Epoch: 36 | Batch_idx: 250 |  Loss: (0.3360) | Acc: (88.00%) (28445/32128)
Epoch: 36 | Batch_idx: 260 |  Loss: (0.3360) | Acc: (88.00%) (29574/33408)
Epoch: 36 | Batch_idx: 270 |  Loss: (0.3351) | Acc: (88.00%) (30703/34688)
Epoch: 36 | Batch_idx: 280 |  Loss: (0.3328) | Acc: (88.00%) (31868/35968)
Epoch: 36 | Batch_idx: 290 |  Loss: (0.3325) | Acc: (88.00%) (33013/37248)
Epoch: 36 | Batch_idx: 300 |  Loss: (0.3325) | Acc: (88.00%) (34146/38528)
Epoch: 36 | Batch_idx: 310 |  Loss: (0.3332) | Acc: (88.00%) (35269/39808)
Epoch: 36 | Batch_idx: 320 |  Loss: (0.3332) | Acc: (88.00%) (36390/41088)
Epoch: 36 | Batch_idx: 330 |  Loss: (0.3332) | Acc: (88.00%) (37525/42368)
Epoch: 36 | Batch_idx: 340 |  Loss: (0.3340) | Acc: (88.00%) (38637/43648)
Epoch: 36 | Batch_idx: 350 |  Loss: (0.3347) | Acc: (88.00%) (39758/44928)
Epoch: 36 | Batch_idx: 360 |  Loss: (0.3352) | Acc: (88.00%) (40891/46208)
Epoch: 36 | Batch_idx: 370 |  Loss: (0.3345) | Acc: (88.00%) (42039/47488)
Epoch: 36 | Batch_idx: 380 |  Loss: (0.3346) | Acc: (88.00%) (43172/48768)
Epoch: 36 | Batch_idx: 390 |  Loss: (0.3350) | Acc: (88.00%) (44276/50000)
# TEST : Loss: (0.4544) | Acc: (84.00%) (8497/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[ 6.7811e-27, -7.7592e-24,  4.9020e-22],
          [-4.3932e-24,  2.3425e-23, -7.7458e-26],
          [ 3.1242e-20, -2.0964e-24,  1.4599e-28]],

         [[-1.0981e-26, -5.0309e-24,  1.6935e-22],
          [-1.2091e-24, -3.9215e-23, -3.8972e-26],
          [ 2.1764e-21, -4.9068e-25,  7.7112e-30]],

         [[-1.7870e-27, -7.2131e-24, -1.3315e-23],
          [-2.1078e-24, -2.1857e-23, -1.2784e-26],
          [ 3.1202e-23, -8.9452e-26, -2.0715e-31]]],


        [[[ 9.7547e-02, -4.7331e-02,  7.5593e-02],
          [ 1.3962e-02, -2.1729e-01, -3.1518e-03],
          [ 7.5503e-02,  2.1631e-02,  7.0126e-02]],

         [[ 2.6199e-02, -1.1311e-01, -3.4613e-02],
          [-1.0119e-01, -3.1203e-01, -7.4311e-02],
          [-9.4307e-06, -8.3025e-03,  7.0879e-02]],

         [[ 3.7805e-02, -2.6353e-02,  5.4925e-02],
          [-6.3622e-04, -1.8012e-01, -1.4484e-02],
          [-1.0957e-02, -3.6707e-02, -1.3674e-02]]],


        [[[-2.0740e-02, -3.0737e-02, -2.7977e-04],
          [-2.6157e-02, -2.6287e-02,  1.5663e-03],
          [-3.7991e-02, -5.0401e-02, -6.1742e-02]],

         [[ 2.7006e-03, -6.0409e-03, -4.2789e-03],
          [-7.5379e-03, -4.1387e-03, -6.3528e-03],
          [ 7.2596e-03, -3.7310e-02,  1.3483e-02]],

         [[-1.2698e-02,  1.1379e-02, -2.4602e-02],
          [-1.6100e-02, -3.3621e-02,  2.1180e-02],
          [-1.6297e-02, -1.1824e-02, -2.2199e-02]]],


        ...,


        [[[-1.0142e-01,  8.8454e-02, -1.5313e-01],
          [-2.3125e-01, -1.1317e-01, -1.7522e-01],
          [-1.4036e-01,  3.8103e-02, -2.7679e-01]],

         [[ 7.5138e-02,  4.5525e-02,  4.8188e-03],
          [ 1.2092e-01, -1.3204e-01,  5.6008e-02],
          [ 2.4127e-02,  1.1555e-01, -1.8068e-01]],

         [[-9.2922e-02,  2.6331e-01,  7.5665e-02],
          [ 2.4314e-01,  2.3643e-01,  1.9443e-01],
          [ 1.6652e-01,  1.6158e-01, -5.5134e-02]]],


        [[[ 9.3435e-02, -8.5853e-02,  5.0321e-02],
          [ 2.8930e-02, -1.4959e-01,  5.4185e-02],
          [ 1.2050e-01, -9.5096e-02,  3.4143e-02]],

         [[ 1.5058e-01, -1.1691e-01,  1.0363e-01],
          [-1.4143e-01, -9.1153e-02, -5.2931e-02],
          [ 6.6734e-02,  1.0763e-01,  1.7740e-02]],

         [[-4.0272e-02, -1.0867e-01,  5.2098e-02],
          [-1.6980e-01, -3.5405e-01, -1.9547e-01],
          [ 6.7370e-03, -1.0242e-01, -1.6778e-01]]],


        [[[-3.3305e-02, -2.8510e-02, -3.6999e-02],
          [-2.8942e-02, -1.8462e-02, -1.5157e-02],
          [-1.9422e-02, -1.0361e-02,  7.4606e-03]],

         [[-3.0366e-02, -5.1701e-03, -3.7366e-02],
          [-1.8629e-03,  3.3026e-02,  2.6379e-02],
          [ 1.7012e-03,  2.7828e-02,  3.0214e-02]],

         [[-5.8763e-02, -5.2929e-02, -5.6468e-02],
          [-6.0483e-02, -4.2402e-02, -3.7322e-02],
          [-4.2466e-02, -2.7819e-02, -2.3249e-02]]]],
       device='cuda:0', requires_grad=True)

conv1_weight_grad tensor([[[[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]]],


        [[[-0.0019, -0.0020, -0.0017],
          [-0.0025, -0.0023, -0.0018],
          [-0.0009, -0.0005,  0.0004]],

         [[-0.0003,  0.0004,  0.0001],
          [-0.0003,  0.0007,  0.0001],
          [ 0.0008,  0.0018,  0.0014]],

         [[-0.0007, -0.0002, -0.0002],
          [-0.0010, -0.0001, -0.0006],
          [-0.0004,  0.0005,  0.0003]]],


        [[[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]]],


        ...,


        [[[-0.0115, -0.0208, -0.0348],
          [-0.0174, -0.0256, -0.0360],
          [-0.0294, -0.0355, -0.0411]],

         [[-0.0082, -0.0170, -0.0323],
          [-0.0122, -0.0195, -0.0316],
          [-0.0233, -0.0274, -0.0344]],

         [[-0.0189, -0.0232, -0.0346],
          [-0.0217, -0.0242, -0.0319],
          [-0.0308, -0.0296, -0.0314]]],


        [[[-0.0061, -0.0059, -0.0057],
          [-0.0009, -0.0022, -0.0036],
          [ 0.0001, -0.0025, -0.0045]],

         [[-0.0036, -0.0030, -0.0024],
          [ 0.0006,  0.0004,  0.0002],
          [ 0.0017,  0.0001, -0.0016]],

         [[-0.0033, -0.0022, -0.0009],
          [-0.0005,  0.0002,  0.0006],
          [-0.0007, -0.0009, -0.0020]]],


        [[[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]]]], device='cuda:0')

percentage_weight tensor([0.], device='cuda:0')

percentage_weight_grad tensor([-51.4369], device='cuda:0')

False Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True _Gate(
  (sig): Sigmoid()
)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True _Gate(
  (sig): Sigmoid()
)
False Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True _Gate(
  (sig): Sigmoid()
)
False Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True _Gate(
  (sig): Sigmoid()
)
False Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True _Gate(
  (sig): Sigmoid()
)
False Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True _Gate(
  (sig): Sigmoid()
)
False Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True _Gate(
  (sig): Sigmoid()
)
False Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True _Gate(
  (sig): Sigmoid()
)
False Linear(in_features=512, out_features=10, bias=True)
Epoch: 37 | Batch_idx: 0 |  Loss: (0.2207) | Acc: (92.00%) (118/128)
Epoch: 37 | Batch_idx: 10 |  Loss: (0.3146) | Acc: (89.00%) (1258/1408)
Epoch: 37 | Batch_idx: 20 |  Loss: (0.3456) | Acc: (88.00%) (2375/2688)
Epoch: 37 | Batch_idx: 30 |  Loss: (0.3554) | Acc: (88.00%) (3497/3968)
Epoch: 37 | Batch_idx: 40 |  Loss: (0.3638) | Acc: (87.00%) (4612/5248)
Epoch: 37 | Batch_idx: 50 |  Loss: (0.3548) | Acc: (88.00%) (5752/6528)
Epoch: 37 | Batch_idx: 60 |  Loss: (0.3589) | Acc: (87.00%) (6871/7808)
Epoch: 37 | Batch_idx: 70 |  Loss: (0.3546) | Acc: (87.00%) (7995/9088)
Epoch: 37 | Batch_idx: 80 |  Loss: (0.3551) | Acc: (87.00%) (9121/10368)
Epoch: 37 | Batch_idx: 90 |  Loss: (0.3549) | Acc: (87.00%) (10241/11648)
Epoch: 37 | Batch_idx: 100 |  Loss: (0.3510) | Acc: (88.00%) (11389/12928)
Epoch: 37 | Batch_idx: 110 |  Loss: (0.3518) | Acc: (88.00%) (12512/14208)
Epoch: 37 | Batch_idx: 120 |  Loss: (0.3494) | Acc: (88.00%) (13645/15488)
Epoch: 37 | Batch_idx: 130 |  Loss: (0.3464) | Acc: (88.00%) (14801/16768)
Epoch: 37 | Batch_idx: 140 |  Loss: (0.3431) | Acc: (88.00%) (15953/18048)
Epoch: 37 | Batch_idx: 150 |  Loss: (0.3415) | Acc: (88.00%) (17089/19328)
Epoch: 37 | Batch_idx: 160 |  Loss: (0.3394) | Acc: (88.00%) (18239/20608)
Epoch: 37 | Batch_idx: 170 |  Loss: (0.3393) | Acc: (88.00%) (19377/21888)
Epoch: 37 | Batch_idx: 180 |  Loss: (0.3391) | Acc: (88.00%) (20519/23168)
Epoch: 37 | Batch_idx: 190 |  Loss: (0.3379) | Acc: (88.00%) (21658/24448)
Epoch: 37 | Batch_idx: 200 |  Loss: (0.3353) | Acc: (88.00%) (22816/25728)
Epoch: 37 | Batch_idx: 210 |  Loss: (0.3341) | Acc: (88.00%) (23964/27008)
Epoch: 37 | Batch_idx: 220 |  Loss: (0.3329) | Acc: (88.00%) (25108/28288)
Epoch: 37 | Batch_idx: 230 |  Loss: (0.3321) | Acc: (88.00%) (26247/29568)
Epoch: 37 | Batch_idx: 240 |  Loss: (0.3307) | Acc: (88.00%) (27403/30848)
Epoch: 37 | Batch_idx: 250 |  Loss: (0.3305) | Acc: (88.00%) (28554/32128)
Epoch: 37 | Batch_idx: 260 |  Loss: (0.3302) | Acc: (88.00%) (29689/33408)
Epoch: 37 | Batch_idx: 270 |  Loss: (0.3296) | Acc: (88.00%) (30823/34688)
Epoch: 37 | Batch_idx: 280 |  Loss: (0.3285) | Acc: (88.00%) (31979/35968)
Epoch: 37 | Batch_idx: 290 |  Loss: (0.3269) | Acc: (88.00%) (33130/37248)
Epoch: 37 | Batch_idx: 300 |  Loss: (0.3262) | Acc: (88.00%) (34287/38528)
Epoch: 37 | Batch_idx: 310 |  Loss: (0.3251) | Acc: (89.00%) (35439/39808)
Epoch: 37 | Batch_idx: 320 |  Loss: (0.3239) | Acc: (89.00%) (36597/41088)
Epoch: 37 | Batch_idx: 330 |  Loss: (0.3225) | Acc: (89.00%) (37763/42368)
Epoch: 37 | Batch_idx: 340 |  Loss: (0.3211) | Acc: (89.00%) (38933/43648)
Epoch: 37 | Batch_idx: 350 |  Loss: (0.3205) | Acc: (89.00%) (40085/44928)
Epoch: 37 | Batch_idx: 360 |  Loss: (0.3190) | Acc: (89.00%) (41257/46208)
Epoch: 37 | Batch_idx: 370 |  Loss: (0.3189) | Acc: (89.00%) (42393/47488)
Epoch: 37 | Batch_idx: 380 |  Loss: (0.3177) | Acc: (89.00%) (43565/48768)
Epoch: 37 | Batch_idx: 390 |  Loss: (0.3175) | Acc: (89.00%) (44664/50000)
# TEST : Loss: (0.3652) | Acc: (87.00%) (8761/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-1.1617e-35, -5.3870e-30,  1.4612e-27],
          [-2.2817e-30,  3.4136e-29, -5.9362e-34],
          [ 4.1369e-25, -4.6207e-31,  3.9200e-38]],

         [[ 6.1219e-35, -1.8005e-30,  3.3808e-28],
          [-1.9077e-31, -2.6935e-29,  1.7565e-34],
          [ 1.4283e-26, -2.4400e-32,  6.4466e-39]],

         [[ 4.5046e-36, -1.1798e-30, -9.1543e-30],
          [-1.4910e-31, -8.6418e-30,  6.6984e-35],
          [ 7.4139e-29,  4.0837e-36,  1.2761e-40]]],


        [[[ 1.0029e-01, -4.2030e-02,  7.8802e-02],
          [ 1.7531e-02, -2.0779e-01,  1.9983e-04],
          [ 7.7641e-02,  2.3210e-02,  7.0749e-02]],

         [[ 2.8610e-02, -1.0821e-01, -3.1573e-02],
          [-9.6471e-02, -2.9719e-01, -7.1346e-02],
          [ 2.1393e-03, -7.7067e-03,  7.0250e-02]],

         [[ 3.8658e-02, -2.4415e-02,  5.5261e-02],
          [ 1.0525e-03, -1.7152e-01, -1.3341e-02],
          [-8.9513e-03, -3.5855e-02, -1.3414e-02]]],


        [[[-1.3892e-02, -2.1810e-02,  1.6315e-03],
          [-1.8570e-02, -2.1106e-02,  1.6499e-03],
          [-2.8803e-02, -4.0440e-02, -4.8585e-02]],

         [[ 3.6521e-03, -3.5378e-03, -1.1208e-03],
          [-5.1149e-03, -4.2955e-03, -4.0844e-03],
          [ 6.1827e-03, -2.9655e-02,  1.1551e-02]],

         [[-8.2630e-03,  8.2808e-03, -1.7290e-02],
          [-1.2294e-02, -2.7239e-02,  1.6201e-02],
          [-1.2649e-02, -1.0296e-02, -1.7175e-02]]],


        ...,


        [[[-1.0259e-01,  8.7620e-02, -1.5304e-01],
          [-2.3106e-01, -1.1301e-01, -1.7474e-01],
          [-1.3911e-01,  3.9060e-02, -2.7501e-01]],

         [[ 7.3078e-02,  4.4184e-02,  3.8281e-03],
          [ 1.1980e-01, -1.3226e-01,  5.5563e-02],
          [ 2.4687e-02,  1.1609e-01, -1.7921e-01]],

         [[-9.3523e-02,  2.6201e-01,  7.4936e-02],
          [ 2.4297e-01,  2.3624e-01,  1.9429e-01],
          [ 1.6789e-01,  1.6284e-01, -5.3405e-02]]],


        [[[ 9.2100e-02, -8.6664e-02,  4.9393e-02],
          [ 2.6906e-02, -1.5114e-01,  5.2181e-02],
          [ 1.1954e-01, -9.5720e-02,  3.3084e-02]],

         [[ 1.4896e-01, -1.1704e-01,  1.0228e-01],
          [-1.4163e-01, -9.3172e-02, -5.4498e-02],
          [ 6.6332e-02,  1.0551e-01,  1.6634e-02]],

         [[-3.8159e-02, -1.0602e-01,  5.2252e-02],
          [-1.6553e-01, -3.3746e-01, -1.9072e-01],
          [ 9.3043e-03, -9.9137e-02, -1.6456e-01]]],


        [[[-2.9480e-02, -2.4987e-02, -3.2113e-02],
          [-2.5443e-02, -1.5875e-02, -1.2678e-02],
          [-1.7010e-02, -8.8193e-03,  6.1631e-03]],

         [[-2.4984e-02, -4.2094e-03, -2.9709e-02],
          [-1.5390e-03,  2.6931e-02,  2.1035e-02],
          [ 1.3936e-03,  2.2211e-02,  2.3956e-02]],

         [[-5.0296e-02, -4.4218e-02, -4.7215e-02],
          [-5.0920e-02, -3.5118e-02, -3.1064e-02],
          [-3.6341e-02, -2.3627e-02, -2.0088e-02]]]], device='cuda:0')

conv1_weight_grad tensor([[[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        ...,


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]]], device='cuda:0')

percentage_weight tensor([0.], device='cuda:0', requires_grad=True)

percentage_weight_grad tensor([-57.7081], device='cuda:0')

Epoch: 38 | Batch_idx: 0 |  Loss: (0.4353) | Acc: (87.00%) (112/128)
Epoch: 38 | Batch_idx: 10 |  Loss: (0.3028) | Acc: (89.00%) (1254/1408)
Epoch: 38 | Batch_idx: 20 |  Loss: (0.3080) | Acc: (89.00%) (2394/2688)
Epoch: 38 | Batch_idx: 30 |  Loss: (0.3088) | Acc: (89.00%) (3536/3968)
Epoch: 38 | Batch_idx: 40 |  Loss: (0.3024) | Acc: (89.00%) (4698/5248)
Epoch: 38 | Batch_idx: 50 |  Loss: (0.3029) | Acc: (89.00%) (5847/6528)
Epoch: 38 | Batch_idx: 60 |  Loss: (0.3037) | Acc: (89.00%) (6998/7808)
Epoch: 38 | Batch_idx: 70 |  Loss: (0.2963) | Acc: (90.00%) (8185/9088)
Epoch: 38 | Batch_idx: 80 |  Loss: (0.2984) | Acc: (89.00%) (9327/10368)
Epoch: 38 | Batch_idx: 90 |  Loss: (0.2957) | Acc: (90.00%) (10499/11648)
Epoch: 38 | Batch_idx: 100 |  Loss: (0.2965) | Acc: (90.00%) (11648/12928)
Epoch: 38 | Batch_idx: 110 |  Loss: (0.2946) | Acc: (90.00%) (12817/14208)
Epoch: 38 | Batch_idx: 120 |  Loss: (0.2965) | Acc: (90.00%) (13964/15488)
Epoch: 38 | Batch_idx: 130 |  Loss: (0.2953) | Acc: (90.00%) (15124/16768)
Epoch: 38 | Batch_idx: 140 |  Loss: (0.2928) | Acc: (90.00%) (16293/18048)
Epoch: 38 | Batch_idx: 150 |  Loss: (0.2919) | Acc: (90.00%) (17455/19328)
Epoch: 38 | Batch_idx: 160 |  Loss: (0.2901) | Acc: (90.00%) (18620/20608)
Epoch: 38 | Batch_idx: 170 |  Loss: (0.2904) | Acc: (90.00%) (19772/21888)
Epoch: 38 | Batch_idx: 180 |  Loss: (0.2903) | Acc: (90.00%) (20928/23168)
Epoch: 38 | Batch_idx: 190 |  Loss: (0.2908) | Acc: (90.00%) (22089/24448)
Epoch: 38 | Batch_idx: 200 |  Loss: (0.2910) | Acc: (90.00%) (23246/25728)
Epoch: 38 | Batch_idx: 210 |  Loss: (0.2922) | Acc: (90.00%) (24397/27008)
Epoch: 38 | Batch_idx: 220 |  Loss: (0.2924) | Acc: (90.00%) (25561/28288)
Epoch: 38 | Batch_idx: 230 |  Loss: (0.2935) | Acc: (90.00%) (26706/29568)
Epoch: 38 | Batch_idx: 240 |  Loss: (0.2941) | Acc: (90.00%) (27845/30848)
Epoch: 38 | Batch_idx: 250 |  Loss: (0.2941) | Acc: (90.00%) (28996/32128)
Epoch: 38 | Batch_idx: 260 |  Loss: (0.2936) | Acc: (90.00%) (30163/33408)
Epoch: 38 | Batch_idx: 270 |  Loss: (0.2926) | Acc: (90.00%) (31337/34688)
Epoch: 38 | Batch_idx: 280 |  Loss: (0.2922) | Acc: (90.00%) (32503/35968)
Epoch: 38 | Batch_idx: 290 |  Loss: (0.2921) | Acc: (90.00%) (33669/37248)
Epoch: 38 | Batch_idx: 300 |  Loss: (0.2915) | Acc: (90.00%) (34838/38528)
Epoch: 38 | Batch_idx: 310 |  Loss: (0.2905) | Acc: (90.00%) (36006/39808)
Epoch: 38 | Batch_idx: 320 |  Loss: (0.2909) | Acc: (90.00%) (37144/41088)
Epoch: 38 | Batch_idx: 330 |  Loss: (0.2914) | Acc: (90.00%) (38295/42368)
Epoch: 38 | Batch_idx: 340 |  Loss: (0.2907) | Acc: (90.00%) (39470/43648)
Epoch: 38 | Batch_idx: 350 |  Loss: (0.2905) | Acc: (90.00%) (40641/44928)
Epoch: 38 | Batch_idx: 360 |  Loss: (0.2912) | Acc: (90.00%) (41787/46208)
Epoch: 38 | Batch_idx: 370 |  Loss: (0.2910) | Acc: (90.00%) (42942/47488)
Epoch: 38 | Batch_idx: 380 |  Loss: (0.2912) | Acc: (90.00%) (44098/48768)
Epoch: 38 | Batch_idx: 390 |  Loss: (0.2909) | Acc: (90.00%) (45217/50000)
# TEST : Loss: (0.3560) | Acc: (87.00%) (8771/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[ 5.1866e-41, -5.3545e-39, -6.5649e-36],
          [-2.4187e-39, -2.3980e-38, -6.6110e-41],
          [ 2.1916e-32, -1.7327e-40, -7.2573e-42]],

         [[ 6.6347e-41, -1.5618e-39, -7.5171e-37],
          [ 4.0638e-44, -2.6971e-38, -8.6937e-42],
          [-2.2029e-35,  1.2254e-41, -1.9897e-41]],

         [[-7.9131e-42, -5.0427e-41, -9.1721e-39],
          [ 1.2786e-40, -8.1454e-39,  2.3745e-41],
          [-2.3811e-37, -5.1934e-41, -8.7623e-42]]],


        [[[ 9.8344e-02, -4.1084e-02,  7.7283e-02],
          [ 1.7133e-02, -2.0094e-01,  1.9527e-04],
          [ 7.6217e-02,  2.2750e-02,  6.9497e-02]],

         [[ 2.7980e-02, -1.0527e-01, -3.0904e-02],
          [-9.3826e-02, -2.8114e-01, -6.9484e-02],
          [ 2.0969e-03, -7.5369e-03,  6.8928e-02]],

         [[ 3.7707e-02, -2.3669e-02,  5.3959e-02],
          [ 1.0203e-03, -1.6181e-01, -1.2951e-02],
          [-8.7527e-03, -3.4953e-02, -1.3129e-02]]],


        [[[-9.6266e-03, -1.4668e-02,  1.2049e-03],
          [-1.2139e-02, -1.4915e-02,  1.1800e-03],
          [-2.0952e-02, -3.0245e-02, -3.6909e-02]],

         [[ 2.4477e-03, -2.2349e-03, -8.0425e-04],
          [-3.2084e-03, -2.9366e-03, -2.8455e-03],
          [ 4.4610e-03, -2.1881e-02,  8.6712e-03]],

         [[-5.6083e-03,  5.6333e-03, -1.2389e-02],
          [-8.3675e-03, -1.9723e-02,  1.1603e-02],
          [-9.2977e-03, -7.7637e-03, -1.2910e-02]]],


        ...,


        [[[-1.0229e-01,  8.7371e-02, -1.5261e-01],
          [-2.3040e-01, -1.1269e-01, -1.7426e-01],
          [-1.3872e-01,  3.8950e-02, -2.7426e-01]],

         [[ 7.2853e-02,  4.4049e-02,  3.8167e-03],
          [ 1.1943e-01, -1.3186e-01,  5.5401e-02],
          [ 2.4613e-02,  1.1575e-01, -1.7870e-01]],

         [[-9.3190e-02,  2.6108e-01,  7.4684e-02],
          [ 2.4211e-01,  2.3541e-01,  1.9364e-01],
          [ 1.6731e-01,  1.6229e-01, -5.3235e-02]]],


        [[[ 9.1384e-02, -8.5940e-02,  4.9004e-02],
          [ 2.6673e-02, -1.4970e-01,  5.1717e-02],
          [ 1.1863e-01, -9.4926e-02,  3.2821e-02]],

         [[ 1.4754e-01, -1.1573e-01,  1.0127e-01],
          [-1.3996e-01, -9.1730e-02, -5.3798e-02],
          [ 6.5732e-02,  1.0438e-01,  1.6471e-02]],

         [[-3.7668e-02, -1.0419e-01,  5.1532e-02],
          [-1.6235e-01, -3.2009e-01, -1.8573e-01],
          [ 9.1900e-03, -9.7450e-02, -1.6215e-01]]],


        [[[-2.5413e-02, -2.1281e-02, -2.7028e-02],
          [-2.1751e-02, -1.3210e-02, -1.0201e-02],
          [-1.4476e-02, -7.2491e-03,  4.8842e-03]],

         [[-1.9703e-02, -3.2775e-03, -2.2472e-02],
          [-1.2198e-03,  2.1009e-02,  1.5969e-02],
          [ 1.0933e-03,  1.6880e-02,  1.8058e-02]],

         [[-4.1621e-02, -3.5527e-02, -3.7974e-02],
          [-4.1297e-02, -2.7918e-02, -2.4845e-02],
          [-3.0067e-02, -1.9368e-02, -1.6815e-02]]]], device='cuda:0')

conv1_weight_grad tensor([[[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        ...,


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]]], device='cuda:0')

percentage_weight tensor([0.], device='cuda:0', requires_grad=True)

percentage_weight_grad tensor([-61.4126], device='cuda:0')

True Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False _Gate(
  (sig): Sigmoid()
)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False _Gate(
  (sig): Sigmoid()
)
True Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False _Gate(
  (sig): Sigmoid()
)
True Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False _Gate(
  (sig): Sigmoid()
)
True Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False _Gate(
  (sig): Sigmoid()
)
True Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False _Gate(
  (sig): Sigmoid()
)
True Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False _Gate(
  (sig): Sigmoid()
)
True Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False _Gate(
  (sig): Sigmoid()
)
True Linear(in_features=512, out_features=10, bias=True)
Epoch: 39 | Batch_idx: 0 |  Loss: (0.3333) | Acc: (89.00%) (114/128)
Epoch: 39 | Batch_idx: 10 |  Loss: (0.3281) | Acc: (89.00%) (1261/1408)
Epoch: 39 | Batch_idx: 20 |  Loss: (0.3517) | Acc: (88.00%) (2379/2688)
Epoch: 39 | Batch_idx: 30 |  Loss: (0.3688) | Acc: (87.00%) (3485/3968)
Epoch: 39 | Batch_idx: 40 |  Loss: (0.3798) | Acc: (87.00%) (4591/5248)
Epoch: 39 | Batch_idx: 50 |  Loss: (0.3777) | Acc: (87.00%) (5717/6528)
Epoch: 39 | Batch_idx: 60 |  Loss: (0.3746) | Acc: (87.00%) (6853/7808)
Epoch: 39 | Batch_idx: 70 |  Loss: (0.3719) | Acc: (87.00%) (7982/9088)
Epoch: 39 | Batch_idx: 80 |  Loss: (0.3717) | Acc: (87.00%) (9099/10368)
Epoch: 39 | Batch_idx: 90 |  Loss: (0.3744) | Acc: (87.00%) (10200/11648)
Epoch: 39 | Batch_idx: 100 |  Loss: (0.3758) | Acc: (87.00%) (11310/12928)
Epoch: 39 | Batch_idx: 110 |  Loss: (0.3774) | Acc: (87.00%) (12420/14208)
Epoch: 39 | Batch_idx: 120 |  Loss: (0.3779) | Acc: (87.00%) (13540/15488)
Epoch: 39 | Batch_idx: 130 |  Loss: (0.3746) | Acc: (87.00%) (14673/16768)
Epoch: 39 | Batch_idx: 140 |  Loss: (0.3748) | Acc: (87.00%) (15785/18048)
Epoch: 39 | Batch_idx: 150 |  Loss: (0.3714) | Acc: (87.00%) (16931/19328)
Epoch: 39 | Batch_idx: 160 |  Loss: (0.3728) | Acc: (87.00%) (18041/20608)
Epoch: 39 | Batch_idx: 170 |  Loss: (0.3721) | Acc: (87.00%) (19163/21888)
Epoch: 39 | Batch_idx: 180 |  Loss: (0.3706) | Acc: (87.00%) (20292/23168)
Epoch: 39 | Batch_idx: 190 |  Loss: (0.3682) | Acc: (87.00%) (21443/24448)
Epoch: 39 | Batch_idx: 200 |  Loss: (0.3655) | Acc: (87.00%) (22593/25728)
Epoch: 39 | Batch_idx: 210 |  Loss: (0.3655) | Acc: (87.00%) (23720/27008)
Epoch: 39 | Batch_idx: 220 |  Loss: (0.3651) | Acc: (87.00%) (24838/28288)
Epoch: 39 | Batch_idx: 230 |  Loss: (0.3647) | Acc: (87.00%) (25964/29568)
Epoch: 39 | Batch_idx: 240 |  Loss: (0.3654) | Acc: (87.00%) (27068/30848)
Epoch: 39 | Batch_idx: 250 |  Loss: (0.3652) | Acc: (87.00%) (28188/32128)
Epoch: 39 | Batch_idx: 260 |  Loss: (0.3646) | Acc: (87.00%) (29323/33408)
Epoch: 39 | Batch_idx: 270 |  Loss: (0.3646) | Acc: (87.00%) (30451/34688)
Epoch: 39 | Batch_idx: 280 |  Loss: (0.3637) | Acc: (87.00%) (31582/35968)
Epoch: 39 | Batch_idx: 290 |  Loss: (0.3635) | Acc: (87.00%) (32703/37248)
Epoch: 39 | Batch_idx: 300 |  Loss: (0.3631) | Acc: (87.00%) (33831/38528)
Epoch: 39 | Batch_idx: 310 |  Loss: (0.3640) | Acc: (87.00%) (34932/39808)
Epoch: 39 | Batch_idx: 320 |  Loss: (0.3646) | Acc: (87.00%) (36051/41088)
Epoch: 39 | Batch_idx: 330 |  Loss: (0.3641) | Acc: (87.00%) (37180/42368)
Epoch: 39 | Batch_idx: 340 |  Loss: (0.3642) | Acc: (87.00%) (38291/43648)
Epoch: 39 | Batch_idx: 350 |  Loss: (0.3626) | Acc: (87.00%) (39440/44928)
Epoch: 39 | Batch_idx: 360 |  Loss: (0.3627) | Acc: (87.00%) (40561/46208)
Epoch: 39 | Batch_idx: 370 |  Loss: (0.3629) | Acc: (87.00%) (41673/47488)
Epoch: 39 | Batch_idx: 380 |  Loss: (0.3637) | Acc: (87.00%) (42784/48768)
Epoch: 39 | Batch_idx: 390 |  Loss: (0.3642) | Acc: (87.00%) (43855/50000)
# TEST : Loss: (0.5525) | Acc: (83.00%) (8328/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[ 6.0882e-41,  3.1915e-41, -3.8736e-41],
          [ 5.5840e-41,  6.7097e-41, -6.3248e-41],
          [-3.5098e-41, -5.3762e-41, -5.7648e-41]],

         [[ 6.2541e-41, -6.8453e-42,  2.4046e-41],
          [-5.1323e-41,  5.4903e-41, -8.3041e-42],
          [ 4.7913e-41,  4.5427e-41,  6.4167e-41]],

         [[-3.7130e-41, -5.7281e-41,  4.9746e-41],
          [-8.9851e-42,  7.0247e-42,  3.5963e-41],
          [ 4.4968e-42, -6.0917e-41,  4.9760e-41]]],


        [[[ 9.3868e-02, -4.1752e-02,  9.2188e-02],
          [ 1.4933e-02, -2.0687e-01,  6.3871e-03],
          [ 8.6985e-02,  2.7708e-02,  8.4969e-02]],

         [[ 2.4304e-02, -1.0529e-01, -1.3127e-02],
          [-8.7503e-02, -2.8195e-01, -5.9163e-02],
          [ 2.4547e-02,  5.4276e-03,  8.7391e-02]],

         [[ 3.5335e-02, -2.3030e-02,  7.5198e-02],
          [ 1.5438e-02, -1.4177e-01,  1.0580e-02],
          [ 2.0234e-02, -1.1260e-02,  1.6340e-02]]],


        [[[-7.3166e-04, -4.0786e-03,  1.5832e-02],
          [ 2.8537e-03, -3.1213e-03,  1.4045e-02],
          [-7.4440e-03, -1.5695e-02, -2.3806e-02]],

         [[-6.3920e-03, -1.2357e-02,  1.6893e-03],
          [-1.7651e-02, -1.4043e-02, -2.8976e-03],
          [-1.7966e-02, -3.0616e-02, -1.6702e-03]],

         [[-3.6746e-02, -2.5799e-02, -3.1426e-02],
          [-4.7395e-02, -5.1587e-02, -1.7194e-02],
          [-5.0182e-02, -4.1244e-02, -3.8510e-02]]],


        ...,


        [[[-1.0436e-01,  8.0127e-02, -1.5368e-01],
          [-2.3287e-01, -1.2104e-01, -1.7541e-01],
          [-1.4245e-01,  2.8005e-02, -2.7640e-01]],

         [[ 7.3605e-02,  4.2826e-02,  9.2282e-03],
          [ 1.2232e-01, -1.2995e-01,  6.3570e-02],
          [ 2.6580e-02,  1.1409e-01, -1.7166e-01]],

         [[-8.9495e-02,  2.6295e-01,  7.9769e-02],
          [ 2.4882e-01,  2.4359e-01,  2.0462e-01],
          [ 1.6618e-01,  1.6164e-01, -4.5996e-02]]],


        [[[ 8.2110e-02, -8.9315e-02,  6.2307e-02],
          [ 2.3929e-02, -1.5806e-01,  6.1193e-02],
          [ 1.2197e-01, -8.6220e-02,  4.8529e-02]],

         [[ 1.3652e-01, -1.1776e-01,  1.1787e-01],
          [-1.3114e-01, -9.4353e-02, -3.2997e-02],
          [ 8.3899e-02,  1.2666e-01,  4.3647e-02]],

         [[-6.3017e-02, -1.2446e-01,  5.4518e-02],
          [-1.7018e-01, -3.4975e-01, -1.6523e-01],
          [ 1.2405e-02, -8.7100e-02, -1.4444e-01]]],


        [[[-2.1213e-02, -1.7505e-02, -2.1913e-02],
          [-1.7973e-02, -1.0566e-02, -7.8332e-03],
          [-1.1895e-02, -5.7128e-03,  3.6737e-03]],

         [[-1.4757e-02, -2.4189e-03, -1.5997e-02],
          [-9.4019e-04,  1.5506e-02,  1.1404e-02],
          [ 7.9389e-04,  1.2066e-02,  1.2794e-02]],

         [[-3.3056e-02, -2.7220e-02, -2.9132e-02],
          [-3.2006e-02, -2.1118e-02, -1.8933e-02],
          [-2.3873e-02, -1.5208e-02, -1.3546e-02]]]],
       device='cuda:0', requires_grad=True)

conv1_weight_grad tensor([[[[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]]],


        [[[ 0.0006, -0.0057, -0.0048],
          [ 0.0025, -0.0040, -0.0042],
          [-0.0023, -0.0089, -0.0099]],

         [[ 0.0004, -0.0052, -0.0036],
          [ 0.0036, -0.0021, -0.0014],
          [-0.0004, -0.0063, -0.0066]],

         [[-0.0002, -0.0053, -0.0034],
          [ 0.0022, -0.0025, -0.0009],
          [-0.0006, -0.0051, -0.0045]]],


        [[[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]]],


        ...,


        [[[ 0.0405,  0.0512,  0.0703],
          [ 0.0321,  0.0381,  0.0538],
          [ 0.0289,  0.0298,  0.0440]],

         [[ 0.0483,  0.0619,  0.0799],
          [ 0.0386,  0.0492,  0.0652],
          [ 0.0387,  0.0455,  0.0603]],

         [[ 0.0317,  0.0432,  0.0584],
          [ 0.0225,  0.0315,  0.0451],
          [ 0.0230,  0.0279,  0.0408]]],


        [[[ 0.0070, -0.0010,  0.0079],
          [ 0.0088, -0.0007,  0.0085],
          [ 0.0039, -0.0026,  0.0049]],

         [[ 0.0108,  0.0027,  0.0109],
          [ 0.0139,  0.0048,  0.0139],
          [ 0.0100,  0.0037,  0.0115]],

         [[ 0.0059, -0.0027,  0.0060],
          [ 0.0101,  0.0006,  0.0095],
          [ 0.0071,  0.0012,  0.0086]]],


        [[[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]]]], device='cuda:0')

percentage_weight tensor([0.], device='cuda:0')

percentage_weight_grad tensor([-61.4126], device='cuda:0')

Epoch: 40 | Batch_idx: 0 |  Loss: (0.3420) | Acc: (89.00%) (114/128)
Epoch: 40 | Batch_idx: 10 |  Loss: (0.3760) | Acc: (85.00%) (1207/1408)
Epoch: 40 | Batch_idx: 20 |  Loss: (0.3634) | Acc: (86.00%) (2332/2688)
Epoch: 40 | Batch_idx: 30 |  Loss: (0.3401) | Acc: (87.00%) (3481/3968)
Epoch: 40 | Batch_idx: 40 |  Loss: (0.3397) | Acc: (88.00%) (4622/5248)
Epoch: 40 | Batch_idx: 50 |  Loss: (0.3357) | Acc: (88.00%) (5768/6528)
Epoch: 40 | Batch_idx: 60 |  Loss: (0.3297) | Acc: (88.00%) (6930/7808)
Epoch: 40 | Batch_idx: 70 |  Loss: (0.3257) | Acc: (88.00%) (8078/9088)
Epoch: 40 | Batch_idx: 80 |  Loss: (0.3220) | Acc: (89.00%) (9234/10368)
Epoch: 40 | Batch_idx: 90 |  Loss: (0.3201) | Acc: (89.00%) (10392/11648)
Epoch: 40 | Batch_idx: 100 |  Loss: (0.3161) | Acc: (89.00%) (11538/12928)
Epoch: 40 | Batch_idx: 110 |  Loss: (0.3135) | Acc: (89.00%) (12692/14208)
Epoch: 40 | Batch_idx: 120 |  Loss: (0.3123) | Acc: (89.00%) (13835/15488)
Epoch: 40 | Batch_idx: 130 |  Loss: (0.3124) | Acc: (89.00%) (14979/16768)
Epoch: 40 | Batch_idx: 140 |  Loss: (0.3137) | Acc: (89.00%) (16115/18048)
Epoch: 40 | Batch_idx: 150 |  Loss: (0.3151) | Acc: (89.00%) (17247/19328)
Epoch: 40 | Batch_idx: 160 |  Loss: (0.3165) | Acc: (89.00%) (18370/20608)
Epoch: 40 | Batch_idx: 170 |  Loss: (0.3154) | Acc: (89.00%) (19519/21888)
Epoch: 40 | Batch_idx: 180 |  Loss: (0.3159) | Acc: (89.00%) (20647/23168)
Epoch: 40 | Batch_idx: 190 |  Loss: (0.3170) | Acc: (89.00%) (21781/24448)
Epoch: 40 | Batch_idx: 200 |  Loss: (0.3177) | Acc: (89.00%) (22926/25728)
Epoch: 40 | Batch_idx: 210 |  Loss: (0.3190) | Acc: (89.00%) (24039/27008)
Epoch: 40 | Batch_idx: 220 |  Loss: (0.3176) | Acc: (89.00%) (25202/28288)
Epoch: 40 | Batch_idx: 230 |  Loss: (0.3171) | Acc: (89.00%) (26355/29568)
Epoch: 40 | Batch_idx: 240 |  Loss: (0.3167) | Acc: (89.00%) (27503/30848)
Epoch: 40 | Batch_idx: 250 |  Loss: (0.3179) | Acc: (89.00%) (28630/32128)
Epoch: 40 | Batch_idx: 260 |  Loss: (0.3184) | Acc: (89.00%) (29770/33408)
Epoch: 40 | Batch_idx: 270 |  Loss: (0.3182) | Acc: (89.00%) (30915/34688)
Epoch: 40 | Batch_idx: 280 |  Loss: (0.3176) | Acc: (89.00%) (32067/35968)
Epoch: 40 | Batch_idx: 290 |  Loss: (0.3173) | Acc: (89.00%) (33224/37248)
Epoch: 40 | Batch_idx: 300 |  Loss: (0.3172) | Acc: (89.00%) (34368/38528)
Epoch: 40 | Batch_idx: 310 |  Loss: (0.3157) | Acc: (89.00%) (35540/39808)
Epoch: 40 | Batch_idx: 320 |  Loss: (0.3152) | Acc: (89.00%) (36691/41088)
Epoch: 40 | Batch_idx: 330 |  Loss: (0.3151) | Acc: (89.00%) (37827/42368)
Epoch: 40 | Batch_idx: 340 |  Loss: (0.3154) | Acc: (89.00%) (38969/43648)
Epoch: 40 | Batch_idx: 350 |  Loss: (0.3158) | Acc: (89.00%) (40114/44928)
Epoch: 40 | Batch_idx: 360 |  Loss: (0.3162) | Acc: (89.00%) (41262/46208)
Epoch: 40 | Batch_idx: 370 |  Loss: (0.3160) | Acc: (89.00%) (42417/47488)
Epoch: 40 | Batch_idx: 380 |  Loss: (0.3155) | Acc: (89.00%) (43565/48768)
Epoch: 40 | Batch_idx: 390 |  Loss: (0.3156) | Acc: (89.00%) (44669/50000)
# TEST : Loss: (0.3924) | Acc: (86.00%) (8665/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-6.0005e-41,  4.8503e-41, -2.4741e-41],
          [-2.0135e-41,  2.5969e-41,  6.1836e-41],
          [-6.6860e-41,  6.4222e-42,  1.4858e-41]],

         [[-3.7108e-41, -2.0982e-41,  5.6650e-41],
          [ 5.0393e-41, -1.5208e-41, -5.3263e-42],
          [ 5.6069e-41, -6.9684e-41,  2.2588e-41]],

         [[ 6.2715e-41,  8.0407e-42,  3.3271e-41],
          [ 4.4037e-41, -6.7227e-41, -6.8863e-41],
          [ 2.7782e-41,  6.5393e-41,  5.0423e-41]]],


        [[[ 9.7749e-02, -4.9941e-02,  7.7541e-02],
          [ 1.9807e-02, -2.2597e-01, -1.4248e-02],
          [ 7.6140e-02,  5.7646e-03,  6.2307e-02]],

         [[ 2.7670e-02, -1.1234e-01, -2.5736e-02],
          [-8.1544e-02, -2.9682e-01, -7.6453e-02],
          [ 1.6120e-02, -1.0122e-02,  6.8273e-02]],

         [[ 4.5248e-02, -2.9092e-02,  6.5645e-02],
          [ 2.9848e-02, -1.5633e-01, -5.0730e-03],
          [ 2.3511e-02, -2.0814e-02,  3.4468e-03]]],


        [[[-4.1080e-03, -7.0016e-03,  9.4639e-03],
          [-1.5802e-03, -6.1782e-03,  7.7885e-03],
          [-8.4820e-03, -1.4496e-02, -2.1169e-02]],

         [[-7.9460e-03, -1.1008e-02, -1.5292e-03],
          [-1.3650e-02, -1.0574e-02, -4.5166e-03],
          [-1.4235e-02, -2.3065e-02, -3.2095e-03]],

         [[-3.0204e-02, -2.0456e-02, -2.6231e-02],
          [-3.6884e-02, -4.0599e-02, -1.3997e-02],
          [-4.0489e-02, -3.3266e-02, -3.1219e-02]]],


        ...,


        [[[-1.0795e-01,  7.6944e-02, -1.5752e-01],
          [-2.3341e-01, -1.2123e-01, -1.7684e-01],
          [-1.4448e-01,  2.7702e-02, -2.7534e-01]],

         [[ 7.0271e-02,  4.2271e-02,  7.4966e-03],
          [ 1.2043e-01, -1.2835e-01,  6.3602e-02],
          [ 2.2972e-02,  1.1334e-01, -1.7142e-01]],

         [[-9.2069e-02,  2.6569e-01,  8.3080e-02],
          [ 2.4977e-01,  2.5162e-01,  2.1308e-01],
          [ 1.6318e-01,  1.6552e-01, -3.9947e-02]]],


        [[[ 7.9294e-02, -1.0125e-01,  5.8882e-02],
          [ 2.1225e-02, -1.7400e-01,  5.1639e-02],
          [ 1.1779e-01, -1.0037e-01,  3.7220e-02]],

         [[ 1.3864e-01, -1.2452e-01,  1.1815e-01],
          [-1.2762e-01, -1.0625e-01, -3.6946e-02],
          [ 8.4383e-02,  1.1975e-01,  4.1102e-02]],

         [[-4.5749e-02, -1.1943e-01,  6.0518e-02],
          [-1.5087e-01, -3.4287e-01, -1.6785e-01],
          [ 1.9290e-02, -9.0808e-02, -1.4992e-01]]],


        [[[-1.7026e-02, -1.3800e-02, -1.6974e-02],
          [-1.4248e-02, -8.0474e-03, -5.6751e-03],
          [-9.3662e-03, -4.2721e-03,  2.6022e-03]],

         [[-1.0377e-02, -1.6686e-03, -1.0572e-02],
          [-6.6577e-04,  1.0729e-02,  7.5777e-03],
          [ 5.5418e-04,  8.0308e-03,  8.4131e-03]],

         [[-2.4970e-02, -1.9680e-02, -2.1094e-02],
          [-2.3465e-02, -1.5029e-02, -1.3596e-02],
          [-1.8028e-02, -1.1327e-02, -1.0408e-02]]]],
       device='cuda:0', requires_grad=True)

conv1_weight_grad tensor([[[[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]]],


        [[[ 0.0006, -0.0005,  0.0047],
          [ 0.0010, -0.0014,  0.0035],
          [-0.0025, -0.0045, -0.0009]],

         [[ 0.0019,  0.0006,  0.0060],
          [ 0.0031,  0.0005,  0.0056],
          [ 0.0002, -0.0022,  0.0017]],

         [[ 0.0019,  0.0004,  0.0050],
          [ 0.0034,  0.0010,  0.0052],
          [ 0.0009, -0.0011,  0.0019]]],


        [[[ 0.0000,  0.0000,  0.0001],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000, -0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000, -0.0000,  0.0000],
          [-0.0000, -0.0000, -0.0000],
          [-0.0000, -0.0000,  0.0000]]],


        ...,


        [[[ 0.0399,  0.0316,  0.0379],
          [ 0.0273,  0.0225,  0.0266],
          [ 0.0176,  0.0139,  0.0169]],

         [[ 0.0174,  0.0130,  0.0220],
          [ 0.0141,  0.0108,  0.0153],
          [ 0.0093,  0.0077,  0.0110]],

         [[ 0.0298,  0.0238,  0.0321],
          [ 0.0218,  0.0187,  0.0247],
          [ 0.0164,  0.0143,  0.0195]]],


        [[[ 0.0074,  0.0012,  0.0057],
          [ 0.0119,  0.0001,  0.0025],
          [-0.0008, -0.0122, -0.0132]],

         [[ 0.0102,  0.0046,  0.0093],
          [ 0.0137,  0.0027,  0.0061],
          [-0.0002, -0.0114, -0.0108]],

         [[ 0.0045, -0.0002,  0.0042],
          [ 0.0095,  0.0006,  0.0034],
          [-0.0018, -0.0103, -0.0103]]],


        [[[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]]]], device='cuda:0')

percentage_weight tensor([0.], device='cuda:0')

percentage_weight_grad tensor([-61.4126], device='cuda:0')

False Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True _Gate(
  (sig): Sigmoid()
)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True _Gate(
  (sig): Sigmoid()
)
False Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True _Gate(
  (sig): Sigmoid()
)
False Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True _Gate(
  (sig): Sigmoid()
)
False Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True _Gate(
  (sig): Sigmoid()
)
False Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True _Gate(
  (sig): Sigmoid()
)
False Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True _Gate(
  (sig): Sigmoid()
)
False Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True _Gate(
  (sig): Sigmoid()
)
False Linear(in_features=512, out_features=10, bias=True)
Epoch: 41 | Batch_idx: 0 |  Loss: (0.2206) | Acc: (91.00%) (117/128)
Epoch: 41 | Batch_idx: 10 |  Loss: (0.2921) | Acc: (90.00%) (1269/1408)
Epoch: 41 | Batch_idx: 20 |  Loss: (0.3244) | Acc: (88.00%) (2392/2688)
Epoch: 41 | Batch_idx: 30 |  Loss: (0.3331) | Acc: (88.00%) (3513/3968)
Epoch: 41 | Batch_idx: 40 |  Loss: (0.3519) | Acc: (87.00%) (4609/5248)
Epoch: 41 | Batch_idx: 50 |  Loss: (0.3510) | Acc: (87.00%) (5740/6528)
Epoch: 41 | Batch_idx: 60 |  Loss: (0.3507) | Acc: (87.00%) (6858/7808)
Epoch: 41 | Batch_idx: 70 |  Loss: (0.3447) | Acc: (88.00%) (8006/9088)
Epoch: 41 | Batch_idx: 80 |  Loss: (0.3415) | Acc: (88.00%) (9150/10368)
Epoch: 41 | Batch_idx: 90 |  Loss: (0.3413) | Acc: (88.00%) (10274/11648)
Epoch: 41 | Batch_idx: 100 |  Loss: (0.3339) | Acc: (88.00%) (11442/12928)
Epoch: 41 | Batch_idx: 110 |  Loss: (0.3327) | Acc: (88.00%) (12578/14208)
Epoch: 41 | Batch_idx: 120 |  Loss: (0.3295) | Acc: (88.00%) (13716/15488)
Epoch: 41 | Batch_idx: 130 |  Loss: (0.3280) | Acc: (88.00%) (14859/16768)
Epoch: 41 | Batch_idx: 140 |  Loss: (0.3249) | Acc: (88.00%) (16006/18048)
Epoch: 41 | Batch_idx: 150 |  Loss: (0.3223) | Acc: (88.00%) (17170/19328)
Epoch: 41 | Batch_idx: 160 |  Loss: (0.3199) | Acc: (88.00%) (18318/20608)
Epoch: 41 | Batch_idx: 170 |  Loss: (0.3163) | Acc: (89.00%) (19486/21888)
Epoch: 41 | Batch_idx: 180 |  Loss: (0.3141) | Acc: (89.00%) (20642/23168)
Epoch: 41 | Batch_idx: 190 |  Loss: (0.3143) | Acc: (89.00%) (21787/24448)
Epoch: 41 | Batch_idx: 200 |  Loss: (0.3142) | Acc: (89.00%) (22929/25728)
Epoch: 41 | Batch_idx: 210 |  Loss: (0.3129) | Acc: (89.00%) (24088/27008)
Epoch: 41 | Batch_idx: 220 |  Loss: (0.3120) | Acc: (89.00%) (25238/28288)
Epoch: 41 | Batch_idx: 230 |  Loss: (0.3110) | Acc: (89.00%) (26385/29568)
Epoch: 41 | Batch_idx: 240 |  Loss: (0.3106) | Acc: (89.00%) (27530/30848)
Epoch: 41 | Batch_idx: 250 |  Loss: (0.3090) | Acc: (89.00%) (28690/32128)
Epoch: 41 | Batch_idx: 260 |  Loss: (0.3086) | Acc: (89.00%) (29844/33408)
Epoch: 41 | Batch_idx: 270 |  Loss: (0.3083) | Acc: (89.00%) (30994/34688)
Epoch: 41 | Batch_idx: 280 |  Loss: (0.3073) | Acc: (89.00%) (32151/35968)
Epoch: 41 | Batch_idx: 290 |  Loss: (0.3061) | Acc: (89.00%) (33320/37248)
Epoch: 41 | Batch_idx: 300 |  Loss: (0.3060) | Acc: (89.00%) (34463/38528)
Epoch: 41 | Batch_idx: 310 |  Loss: (0.3054) | Acc: (89.00%) (35607/39808)
Epoch: 41 | Batch_idx: 320 |  Loss: (0.3055) | Acc: (89.00%) (36761/41088)
Epoch: 41 | Batch_idx: 330 |  Loss: (0.3051) | Acc: (89.00%) (37921/42368)
Epoch: 41 | Batch_idx: 340 |  Loss: (0.3044) | Acc: (89.00%) (39090/43648)
Epoch: 41 | Batch_idx: 350 |  Loss: (0.3048) | Acc: (89.00%) (40226/44928)
Epoch: 41 | Batch_idx: 360 |  Loss: (0.3036) | Acc: (89.00%) (41404/46208)
Epoch: 41 | Batch_idx: 370 |  Loss: (0.3032) | Acc: (89.00%) (42559/47488)
Epoch: 41 | Batch_idx: 380 |  Loss: (0.3021) | Acc: (89.00%) (43725/48768)
Epoch: 41 | Batch_idx: 390 |  Loss: (0.3020) | Acc: (89.00%) (44833/50000)
# TEST : Loss: (0.3447) | Acc: (88.00%) (8832/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-1.2261e-41,  4.0219e-41, -1.2875e-41],
          [ 3.7015e-41,  4.4886e-41,  5.3626e-41],
          [ 4.9027e-41, -2.2149e-41, -4.2431e-41]],

         [[ 3.1025e-41, -5.2090e-41, -3.2649e-41],
          [ 3.1227e-41,  4.2632e-41, -5.9779e-41],
          [-5.4031e-41, -7.0852e-41, -3.7007e-41]],

         [[-3.9749e-41,  6.2932e-42,  6.5769e-41],
          [ 2.9685e-41, -3.4887e-41, -1.2977e-41],
          [-6.9182e-41,  2.6022e-41,  4.3847e-42]]],


        [[[ 9.4308e-02, -5.1301e-02,  7.3055e-02],
          [ 1.9556e-02, -2.1923e-01, -1.6637e-02],
          [ 7.6087e-02,  6.8686e-03,  6.0706e-02]],

         [[ 2.5950e-02, -1.1141e-01, -2.7359e-02],
          [-7.9145e-02, -2.8321e-01, -7.6757e-02],
          [ 1.7062e-02, -8.4853e-03,  6.6865e-02]],

         [[ 4.4367e-02, -2.8244e-02,  6.4026e-02],
          [ 2.9926e-02, -1.4844e-01, -6.0335e-03],
          [ 2.4778e-02, -1.8741e-02,  3.7850e-03]]],


        [[[-3.3965e-03, -5.4934e-03,  7.4264e-03],
          [-1.2501e-03, -4.6214e-03,  5.8780e-03],
          [-6.3950e-03, -1.0502e-02, -1.6208e-02]],

         [[-5.8263e-03, -7.3564e-03, -1.3070e-03],
          [-8.5109e-03, -6.6447e-03, -3.1192e-03],
          [-9.8671e-03, -1.5528e-02, -2.2935e-03]],

         [[-2.2623e-02, -1.5073e-02, -1.9462e-02],
          [-2.7388e-02, -3.0737e-02, -1.0313e-02],
          [-3.1543e-02, -2.5845e-02, -2.3777e-02]]],


        ...,


        [[[-1.1126e-01,  7.3735e-02, -1.5973e-01],
          [-2.3558e-01, -1.2323e-01, -1.7807e-01],
          [-1.4602e-01,  2.6042e-02, -2.7591e-01]],

         [[ 6.7856e-02,  4.0292e-02,  5.8581e-03],
          [ 1.1833e-01, -1.2939e-01,  6.2660e-02],
          [ 2.1801e-02,  1.1217e-01, -1.7156e-01]],

         [[-9.5248e-02,  2.6202e-01,  8.0405e-02],
          [ 2.4665e-01,  2.4906e-01,  2.1124e-01],
          [ 1.6137e-01,  1.6405e-01, -4.0573e-02]]],


        [[[ 7.7100e-02, -1.0222e-01,  5.6564e-02],
          [ 1.8098e-02, -1.7455e-01,  4.8151e-02],
          [ 1.1659e-01, -9.9345e-02,  3.6611e-02]],

         [[ 1.3654e-01, -1.2467e-01,  1.1594e-01],
          [-1.2911e-01, -1.0709e-01, -4.0079e-02],
          [ 8.4033e-02,  1.1978e-01,  4.0972e-02]],

         [[-4.2827e-02, -1.1499e-01,  6.1611e-02],
          [-1.4935e-01, -3.2706e-01, -1.6647e-01],
          [ 2.1057e-02, -8.6423e-02, -1.4615e-01]]],


        [[[-1.3027e-02, -1.0330e-02, -1.2438e-02],
          [-1.0738e-02, -5.7762e-03, -3.8325e-03],
          [-7.0012e-03, -2.9987e-03,  1.7096e-03]],

         [[-6.7575e-03, -1.0616e-03, -6.3822e-03],
          [-4.3747e-04,  6.8503e-03,  4.6045e-03],
          [ 3.5744e-04,  4.8896e-03,  5.0474e-03]],

         [[-1.7744e-02, -1.3256e-02, -1.4236e-02],
          [-1.6078e-02, -9.9307e-03, -9.0823e-03],
          [-1.2805e-02, -7.9121e-03, -7.5513e-03]]]], device='cuda:0')

conv1_weight_grad tensor([[[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        ...,


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]]], device='cuda:0')

percentage_weight tensor([0.], device='cuda:0', requires_grad=True)

percentage_weight_grad tensor([-61.2043], device='cuda:0')

Epoch: 42 | Batch_idx: 0 |  Loss: (0.2885) | Acc: (92.00%) (119/128)
Epoch: 42 | Batch_idx: 10 |  Loss: (0.2757) | Acc: (90.00%) (1273/1408)
Epoch: 42 | Batch_idx: 20 |  Loss: (0.2863) | Acc: (90.00%) (2428/2688)
Epoch: 42 | Batch_idx: 30 |  Loss: (0.2826) | Acc: (90.00%) (3586/3968)
Epoch: 42 | Batch_idx: 40 |  Loss: (0.2803) | Acc: (90.00%) (4743/5248)
Epoch: 42 | Batch_idx: 50 |  Loss: (0.2765) | Acc: (90.00%) (5907/6528)
Epoch: 42 | Batch_idx: 60 |  Loss: (0.2791) | Acc: (90.00%) (7062/7808)
Epoch: 42 | Batch_idx: 70 |  Loss: (0.2787) | Acc: (90.00%) (8225/9088)
Epoch: 42 | Batch_idx: 80 |  Loss: (0.2801) | Acc: (90.00%) (9383/10368)
Epoch: 42 | Batch_idx: 90 |  Loss: (0.2785) | Acc: (90.00%) (10547/11648)
Epoch: 42 | Batch_idx: 100 |  Loss: (0.2763) | Acc: (90.00%) (11708/12928)
Epoch: 42 | Batch_idx: 110 |  Loss: (0.2774) | Acc: (90.00%) (12858/14208)
Epoch: 42 | Batch_idx: 120 |  Loss: (0.2775) | Acc: (90.00%) (14033/15488)
Epoch: 42 | Batch_idx: 130 |  Loss: (0.2751) | Acc: (90.00%) (15203/16768)
Epoch: 42 | Batch_idx: 140 |  Loss: (0.2732) | Acc: (90.00%) (16377/18048)
Epoch: 42 | Batch_idx: 150 |  Loss: (0.2743) | Acc: (90.00%) (17532/19328)
Epoch: 42 | Batch_idx: 160 |  Loss: (0.2746) | Acc: (90.00%) (18692/20608)
Epoch: 42 | Batch_idx: 170 |  Loss: (0.2745) | Acc: (90.00%) (19853/21888)
Epoch: 42 | Batch_idx: 180 |  Loss: (0.2732) | Acc: (90.00%) (21022/23168)
Epoch: 42 | Batch_idx: 190 |  Loss: (0.2730) | Acc: (90.00%) (22187/24448)
Epoch: 42 | Batch_idx: 200 |  Loss: (0.2727) | Acc: (90.00%) (23342/25728)
Epoch: 42 | Batch_idx: 210 |  Loss: (0.2723) | Acc: (90.00%) (24513/27008)
Epoch: 42 | Batch_idx: 220 |  Loss: (0.2731) | Acc: (90.00%) (25671/28288)
Epoch: 42 | Batch_idx: 230 |  Loss: (0.2735) | Acc: (90.00%) (26830/29568)
Epoch: 42 | Batch_idx: 240 |  Loss: (0.2729) | Acc: (90.00%) (28003/30848)
Epoch: 42 | Batch_idx: 250 |  Loss: (0.2745) | Acc: (90.00%) (29153/32128)
Epoch: 42 | Batch_idx: 260 |  Loss: (0.2758) | Acc: (90.00%) (30305/33408)
Epoch: 42 | Batch_idx: 270 |  Loss: (0.2757) | Acc: (90.00%) (31458/34688)
Epoch: 42 | Batch_idx: 280 |  Loss: (0.2755) | Acc: (90.00%) (32621/35968)
Epoch: 42 | Batch_idx: 290 |  Loss: (0.2743) | Acc: (90.00%) (33802/37248)
Epoch: 42 | Batch_idx: 300 |  Loss: (0.2731) | Acc: (90.00%) (34978/38528)
Epoch: 42 | Batch_idx: 310 |  Loss: (0.2730) | Acc: (90.00%) (36144/39808)
Epoch: 42 | Batch_idx: 320 |  Loss: (0.2740) | Acc: (90.00%) (37291/41088)
Epoch: 42 | Batch_idx: 330 |  Loss: (0.2746) | Acc: (90.00%) (38452/42368)
Epoch: 42 | Batch_idx: 340 |  Loss: (0.2749) | Acc: (90.00%) (39607/43648)
Epoch: 42 | Batch_idx: 350 |  Loss: (0.2752) | Acc: (90.00%) (40773/44928)
Epoch: 42 | Batch_idx: 360 |  Loss: (0.2750) | Acc: (90.00%) (41939/46208)
Epoch: 42 | Batch_idx: 370 |  Loss: (0.2760) | Acc: (90.00%) (43083/47488)
Epoch: 42 | Batch_idx: 380 |  Loss: (0.2761) | Acc: (90.00%) (44246/48768)
Epoch: 42 | Batch_idx: 390 |  Loss: (0.2754) | Acc: (90.00%) (45384/50000)
# TEST : Loss: (0.3379) | Acc: (88.00%) (8858/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-6.2673e-41, -2.9762e-41, -5.9094e-41],
          [-3.2830e-41, -6.8005e-42,  4.0286e-41],
          [ 5.6251e-41, -3.6196e-42, -3.7975e-43]],

         [[ 1.5557e-41,  2.8940e-41,  6.7548e-41],
          [-6.9988e-41, -4.8748e-41, -3.3584e-41],
          [-1.2109e-41,  1.9590e-41, -1.5404e-41]],

         [[-6.1715e-41, -4.1794e-41, -5.9473e-41],
          [ 2.8565e-41,  5.3179e-41, -2.9216e-41],
          [ 1.8444e-41,  7.1878e-41,  4.4379e-42]]],


        [[[ 9.2268e-02, -5.0042e-02,  7.1513e-02],
          [ 1.9068e-02, -2.1107e-01, -1.6220e-02],
          [ 7.4520e-02,  6.7126e-03,  5.9446e-02]],

         [[ 2.5330e-02, -1.0821e-01, -2.6729e-02],
          [-7.6885e-02, -2.6750e-01, -7.4592e-02],
          [ 1.6685e-02, -8.2724e-03,  6.5408e-02]],

         [[ 4.3158e-02, -2.7308e-02,  6.2333e-02],
          [ 2.8970e-02, -1.3982e-01, -5.8416e-03],
          [ 2.4164e-02, -1.8210e-02,  3.6925e-03]]],


        [[[-2.5355e-03, -3.9410e-03,  5.7414e-03],
          [-8.8677e-04, -3.1885e-03,  4.2876e-03],
          [-4.4931e-03, -7.0220e-03, -1.1636e-02]],

         [[-3.9167e-03, -4.4525e-03, -9.3232e-04],
          [-4.8158e-03, -3.8093e-03, -1.9626e-03],
          [-6.3253e-03, -9.6078e-03, -1.5125e-03]],

         [[-1.5875e-02, -1.0379e-02, -1.3451e-02],
          [-1.9087e-02, -2.1947e-02, -7.1081e-03],
          [-2.3284e-02, -1.9032e-02, -1.7064e-02]]],


        ...,


        [[[-1.1092e-01,  7.3512e-02, -1.5925e-01],
          [-2.3488e-01, -1.2287e-01, -1.7755e-01],
          [-1.4559e-01,  2.5967e-02, -2.7512e-01]],

         [[ 6.7635e-02,  4.0162e-02,  5.8395e-03],
          [ 1.1796e-01, -1.2899e-01,  6.2468e-02],
          [ 2.1734e-02,  1.1183e-01, -1.7105e-01]],

         [[-9.4886e-02,  2.6103e-01,  8.0112e-02],
          [ 2.4574e-01,  2.4816e-01,  2.1050e-01],
          [ 1.6080e-01,  1.6349e-01, -4.0438e-02]]],


        [[[ 7.6481e-02, -1.0137e-01,  5.6117e-02],
          [ 1.7942e-02, -1.7291e-01,  4.7726e-02],
          [ 1.1569e-01, -9.8512e-02,  3.6313e-02]],

         [[ 1.3516e-01, -1.2324e-01,  1.1478e-01],
          [-1.2760e-01, -1.0542e-01, -3.9564e-02],
          [ 8.3260e-02,  1.1846e-01,  4.0553e-02]],

         [[-4.2233e-02, -1.1296e-01,  6.0763e-02],
          [-1.4653e-01, -3.0982e-01, -1.6247e-01],
          [ 2.0798e-02, -8.4924e-02, -1.4398e-01]]],


        [[[-9.4032e-03, -7.2602e-03, -8.5164e-03],
          [-7.6098e-03, -3.8567e-03, -2.3754e-03],
          [-4.9118e-03, -1.9484e-03,  1.0245e-03]],

         [[-4.0061e-03, -6.1175e-04, -3.4492e-03],
          [-2.6223e-04,  3.9645e-03,  2.5083e-03],
          [ 2.0944e-04,  2.6702e-03,  2.7071e-03]],

         [[-1.1704e-02, -8.1907e-03, -8.8170e-03],
          [-1.0143e-02, -5.9934e-03, -5.5552e-03],
          [-8.4419e-03, -5.1102e-03, -5.1082e-03]]]], device='cuda:0')

conv1_weight_grad tensor([[[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        ...,


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]]], device='cuda:0')

percentage_weight tensor([0.], device='cuda:0', requires_grad=True)

percentage_weight_grad tensor([-61.8191], device='cuda:0')

True Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False _Gate(
  (sig): Sigmoid()
)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False _Gate(
  (sig): Sigmoid()
)
True Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False _Gate(
  (sig): Sigmoid()
)
True Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False _Gate(
  (sig): Sigmoid()
)
True Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False _Gate(
  (sig): Sigmoid()
)
True Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False _Gate(
  (sig): Sigmoid()
)
True Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False _Gate(
  (sig): Sigmoid()
)
True Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False _Gate(
  (sig): Sigmoid()
)
True Linear(in_features=512, out_features=10, bias=True)
Epoch: 43 | Batch_idx: 0 |  Loss: (0.1144) | Acc: (98.00%) (126/128)
Epoch: 43 | Batch_idx: 10 |  Loss: (0.2545) | Acc: (91.00%) (1295/1408)
Epoch: 43 | Batch_idx: 20 |  Loss: (0.2853) | Acc: (90.00%) (2430/2688)
Epoch: 43 | Batch_idx: 30 |  Loss: (0.3047) | Acc: (89.00%) (3564/3968)
Epoch: 43 | Batch_idx: 40 |  Loss: (0.3169) | Acc: (89.00%) (4702/5248)
Epoch: 43 | Batch_idx: 50 |  Loss: (0.3218) | Acc: (89.00%) (5823/6528)
Epoch: 43 | Batch_idx: 60 |  Loss: (0.3333) | Acc: (88.00%) (6935/7808)
Epoch: 43 | Batch_idx: 70 |  Loss: (0.3414) | Acc: (88.00%) (8044/9088)
Epoch: 43 | Batch_idx: 80 |  Loss: (0.3390) | Acc: (88.00%) (9188/10368)
Epoch: 43 | Batch_idx: 90 |  Loss: (0.3416) | Acc: (88.00%) (10316/11648)
Epoch: 43 | Batch_idx: 100 |  Loss: (0.3432) | Acc: (88.00%) (11431/12928)
Epoch: 43 | Batch_idx: 110 |  Loss: (0.3506) | Acc: (88.00%) (12523/14208)
Epoch: 43 | Batch_idx: 120 |  Loss: (0.3528) | Acc: (88.00%) (13637/15488)
Epoch: 43 | Batch_idx: 130 |  Loss: (0.3529) | Acc: (87.00%) (14753/16768)
Epoch: 43 | Batch_idx: 140 |  Loss: (0.3527) | Acc: (88.00%) (15893/18048)
Epoch: 43 | Batch_idx: 150 |  Loss: (0.3548) | Acc: (88.00%) (17011/19328)
Epoch: 43 | Batch_idx: 160 |  Loss: (0.3564) | Acc: (87.00%) (18125/20608)
Epoch: 43 | Batch_idx: 170 |  Loss: (0.3561) | Acc: (87.00%) (19249/21888)
Epoch: 43 | Batch_idx: 180 |  Loss: (0.3550) | Acc: (87.00%) (20374/23168)
Epoch: 43 | Batch_idx: 190 |  Loss: (0.3556) | Acc: (87.00%) (21484/24448)
Epoch: 43 | Batch_idx: 200 |  Loss: (0.3574) | Acc: (87.00%) (22582/25728)
Epoch: 43 | Batch_idx: 210 |  Loss: (0.3561) | Acc: (87.00%) (23719/27008)
Epoch: 43 | Batch_idx: 220 |  Loss: (0.3572) | Acc: (87.00%) (24837/28288)
Epoch: 43 | Batch_idx: 230 |  Loss: (0.3588) | Acc: (87.00%) (25946/29568)
Epoch: 43 | Batch_idx: 240 |  Loss: (0.3584) | Acc: (87.00%) (27068/30848)
Epoch: 43 | Batch_idx: 250 |  Loss: (0.3578) | Acc: (87.00%) (28196/32128)
Epoch: 43 | Batch_idx: 260 |  Loss: (0.3560) | Acc: (87.00%) (29327/33408)
Epoch: 43 | Batch_idx: 270 |  Loss: (0.3556) | Acc: (87.00%) (30458/34688)
Epoch: 43 | Batch_idx: 280 |  Loss: (0.3546) | Acc: (87.00%) (31591/35968)
Epoch: 43 | Batch_idx: 290 |  Loss: (0.3535) | Acc: (87.00%) (32733/37248)
Epoch: 43 | Batch_idx: 300 |  Loss: (0.3529) | Acc: (87.00%) (33863/38528)
Epoch: 43 | Batch_idx: 310 |  Loss: (0.3521) | Acc: (87.00%) (35012/39808)
Epoch: 43 | Batch_idx: 320 |  Loss: (0.3512) | Acc: (87.00%) (36155/41088)
Epoch: 43 | Batch_idx: 330 |  Loss: (0.3516) | Acc: (87.00%) (37276/42368)
Epoch: 43 | Batch_idx: 340 |  Loss: (0.3506) | Acc: (88.00%) (38419/43648)
Epoch: 43 | Batch_idx: 350 |  Loss: (0.3513) | Acc: (87.00%) (39531/44928)
Epoch: 43 | Batch_idx: 360 |  Loss: (0.3506) | Acc: (88.00%) (40668/46208)
Epoch: 43 | Batch_idx: 370 |  Loss: (0.3507) | Acc: (88.00%) (41805/47488)
Epoch: 43 | Batch_idx: 380 |  Loss: (0.3506) | Acc: (88.00%) (42930/48768)
Epoch: 43 | Batch_idx: 390 |  Loss: (0.3499) | Acc: (88.00%) (44035/50000)
# TEST : Loss: (0.4254) | Acc: (85.00%) (8573/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[ 7.1859e-42, -5.4519e-41, -6.7341e-41],
          [ 5.0415e-41,  4.9588e-41, -4.8406e-41],
          [-2.7090e-41, -4.2668e-41, -6.1195e-42]],

         [[-6.1616e-41, -5.8287e-41,  6.4734e-41],
          [ 5.5730e-41,  3.0564e-41,  5.9614e-41],
          [-6.2505e-41, -5.6556e-42,  4.5573e-41]],

         [[-2.5543e-41,  9.0510e-42, -2.4437e-41],
          [-2.6140e-41, -3.3155e-42, -6.8196e-41],
          [ 2.6831e-41, -3.8965e-41, -6.6682e-41]]],


        [[[ 9.7641e-02, -4.2775e-02,  8.0897e-02],
          [ 1.2504e-02, -2.3146e-01, -3.4381e-02],
          [ 7.6027e-02,  2.0428e-03,  4.5383e-02]],

         [[ 3.3945e-02, -8.8530e-02, -1.1337e-02],
          [-7.9934e-02, -2.6814e-01, -8.6781e-02],
          [ 1.6768e-02, -6.9447e-03,  5.2404e-02]],

         [[ 4.5565e-02, -1.6307e-02,  7.4939e-02],
          [ 2.4321e-02, -1.4228e-01, -1.5743e-02],
          [ 2.0526e-02, -1.9853e-02, -1.0925e-02]]],


        [[[-9.2171e-03, -1.1463e-02, -3.6036e-03],
          [-1.4203e-02, -1.7730e-02, -8.1523e-03],
          [-1.5971e-02, -2.0084e-02, -1.7954e-02]],

         [[-6.8559e-03, -9.7606e-03, -4.5958e-04],
          [-1.6728e-02, -2.1847e-02, -1.2805e-02],
          [-1.6653e-02, -2.5423e-02, -1.1134e-02]],

         [[-2.7428e-02, -2.0126e-02, -4.4397e-03],
          [-3.9144e-02, -4.2987e-02, -1.8899e-02],
          [-4.0605e-02, -4.0298e-02, -2.6267e-02]]],


        ...,


        [[[-1.1860e-01,  5.7534e-02, -1.7505e-01],
          [-2.3757e-01, -1.3285e-01, -1.9061e-01],
          [-1.4551e-01,  2.4276e-02, -2.8025e-01]],

         [[ 5.9239e-02,  3.0058e-02, -2.3111e-03],
          [ 1.1785e-01, -1.2953e-01,  5.7771e-02],
          [ 2.4758e-02,  1.1632e-01, -1.7226e-01]],

         [[-1.0057e-01,  2.5209e-01,  6.9778e-02],
          [ 2.4945e-01,  2.5261e-01,  2.0699e-01],
          [ 1.6380e-01,  1.7123e-01, -4.1177e-02]]],


        [[[ 9.9895e-02, -8.2455e-02,  8.5424e-02],
          [ 2.9436e-02, -1.7188e-01,  6.1786e-02],
          [ 1.2255e-01, -9.8670e-02,  3.4416e-02]],

         [[ 1.4813e-01, -1.0810e-01,  1.3733e-01],
          [-1.2441e-01, -1.1203e-01, -3.1047e-02],
          [ 7.7931e-02,  1.1020e-01,  3.1348e-02]],

         [[-3.5670e-02, -1.0130e-01,  7.5022e-02],
          [-1.3779e-01, -2.9558e-01, -1.5375e-01],
          [ 1.3477e-02, -9.5137e-02, -1.6358e-01]]],


        [[[-6.3216e-03, -4.7245e-03, -5.3682e-03],
          [-5.0023e-03, -2.3574e-03, -1.3257e-03],
          [-3.1894e-03, -1.1520e-03,  5.4877e-04]],

         [[-2.1176e-03, -3.1232e-04, -1.6280e-03],
          [-1.4049e-04,  2.0347e-03,  1.1955e-03],
          [ 1.0913e-04,  1.2765e-03,  1.2659e-03]],

         [[-7.0479e-03, -4.5541e-03, -4.9164e-03],
          [-5.7851e-03, -3.2380e-03, -3.0507e-03],
          [-5.0805e-03, -2.9994e-03, -3.1727e-03]]]],
       device='cuda:0', requires_grad=True)

conv1_weight_grad tensor([[[[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]]],


        [[[ 0.0030,  0.0050,  0.0048],
          [-0.0009,  0.0016,  0.0015],
          [ 0.0039,  0.0063,  0.0057]],

         [[ 0.0045,  0.0064,  0.0065],
          [-0.0004,  0.0019,  0.0021],
          [ 0.0045,  0.0067,  0.0066]],

         [[ 0.0039,  0.0053,  0.0054],
          [-0.0000,  0.0015,  0.0017],
          [ 0.0044,  0.0059,  0.0058]]],


        [[[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]]],


        ...,


        [[[ 0.0261,  0.0311,  0.0389],
          [ 0.0235,  0.0293,  0.0323],
          [ 0.0176,  0.0209,  0.0292]],

         [[ 0.0278,  0.0336,  0.0421],
          [ 0.0264,  0.0333,  0.0374],
          [ 0.0227,  0.0274,  0.0374]],

         [[ 0.0264,  0.0296,  0.0376],
          [ 0.0241,  0.0277,  0.0326],
          [ 0.0204,  0.0213,  0.0309]]],


        [[[ 0.0140,  0.0209,  0.0225],
          [ 0.0108,  0.0165,  0.0162],
          [ 0.0211,  0.0255,  0.0227]],

         [[ 0.0239,  0.0308,  0.0336],
          [ 0.0160,  0.0224,  0.0244],
          [ 0.0241,  0.0296,  0.0303]],

         [[ 0.0060,  0.0102,  0.0131],
          [ 0.0018,  0.0054,  0.0069],
          [ 0.0118,  0.0154,  0.0151]]],


        [[[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]]]], device='cuda:0')

percentage_weight tensor([0.], device='cuda:0')

percentage_weight_grad tensor([-61.8191], device='cuda:0')

Epoch: 44 | Batch_idx: 0 |  Loss: (0.2806) | Acc: (89.00%) (115/128)
Epoch: 44 | Batch_idx: 10 |  Loss: (0.3482) | Acc: (87.00%) (1233/1408)
Epoch: 44 | Batch_idx: 20 |  Loss: (0.3214) | Acc: (88.00%) (2382/2688)
Epoch: 44 | Batch_idx: 30 |  Loss: (0.3097) | Acc: (88.00%) (3528/3968)
Epoch: 44 | Batch_idx: 40 |  Loss: (0.3081) | Acc: (89.00%) (4674/5248)
Epoch: 44 | Batch_idx: 50 |  Loss: (0.3107) | Acc: (89.00%) (5824/6528)
Epoch: 44 | Batch_idx: 60 |  Loss: (0.3106) | Acc: (89.00%) (6964/7808)
Epoch: 44 | Batch_idx: 70 |  Loss: (0.3111) | Acc: (89.00%) (8104/9088)
Epoch: 44 | Batch_idx: 80 |  Loss: (0.3081) | Acc: (89.00%) (9264/10368)
Epoch: 44 | Batch_idx: 90 |  Loss: (0.3072) | Acc: (89.00%) (10409/11648)
Epoch: 44 | Batch_idx: 100 |  Loss: (0.3089) | Acc: (89.00%) (11550/12928)
Epoch: 44 | Batch_idx: 110 |  Loss: (0.3061) | Acc: (89.00%) (12723/14208)
Epoch: 44 | Batch_idx: 120 |  Loss: (0.3095) | Acc: (89.00%) (13851/15488)
Epoch: 44 | Batch_idx: 130 |  Loss: (0.3100) | Acc: (89.00%) (14982/16768)
Epoch: 44 | Batch_idx: 140 |  Loss: (0.3102) | Acc: (89.00%) (16129/18048)
Epoch: 44 | Batch_idx: 150 |  Loss: (0.3116) | Acc: (89.00%) (17274/19328)
Epoch: 44 | Batch_idx: 160 |  Loss: (0.3127) | Acc: (89.00%) (18412/20608)
Epoch: 44 | Batch_idx: 170 |  Loss: (0.3112) | Acc: (89.00%) (19572/21888)
Epoch: 44 | Batch_idx: 180 |  Loss: (0.3101) | Acc: (89.00%) (20727/23168)
Epoch: 44 | Batch_idx: 190 |  Loss: (0.3082) | Acc: (89.00%) (21888/24448)
Epoch: 44 | Batch_idx: 200 |  Loss: (0.3070) | Acc: (89.00%) (23040/25728)
Epoch: 44 | Batch_idx: 210 |  Loss: (0.3062) | Acc: (89.00%) (24191/27008)
Epoch: 44 | Batch_idx: 220 |  Loss: (0.3052) | Acc: (89.00%) (25354/28288)
Epoch: 44 | Batch_idx: 230 |  Loss: (0.3053) | Acc: (89.00%) (26488/29568)
Epoch: 44 | Batch_idx: 240 |  Loss: (0.3027) | Acc: (89.00%) (27656/30848)
Epoch: 44 | Batch_idx: 250 |  Loss: (0.3015) | Acc: (89.00%) (28833/32128)
Epoch: 44 | Batch_idx: 260 |  Loss: (0.3017) | Acc: (89.00%) (29970/33408)
Epoch: 44 | Batch_idx: 270 |  Loss: (0.3014) | Acc: (89.00%) (31119/34688)
Epoch: 44 | Batch_idx: 280 |  Loss: (0.3024) | Acc: (89.00%) (32262/35968)
Epoch: 44 | Batch_idx: 290 |  Loss: (0.3018) | Acc: (89.00%) (33408/37248)
Epoch: 44 | Batch_idx: 300 |  Loss: (0.3023) | Acc: (89.00%) (34555/38528)
Epoch: 44 | Batch_idx: 310 |  Loss: (0.3030) | Acc: (89.00%) (35694/39808)
Epoch: 44 | Batch_idx: 320 |  Loss: (0.3037) | Acc: (89.00%) (36838/41088)
Epoch: 44 | Batch_idx: 330 |  Loss: (0.3024) | Acc: (89.00%) (37999/42368)
Epoch: 44 | Batch_idx: 340 |  Loss: (0.3020) | Acc: (89.00%) (39149/43648)
Epoch: 44 | Batch_idx: 350 |  Loss: (0.3027) | Acc: (89.00%) (40295/44928)
Epoch: 44 | Batch_idx: 360 |  Loss: (0.3029) | Acc: (89.00%) (41439/46208)
Epoch: 44 | Batch_idx: 370 |  Loss: (0.3026) | Acc: (89.00%) (42586/47488)
Epoch: 44 | Batch_idx: 380 |  Loss: (0.3023) | Acc: (89.00%) (43735/48768)
Epoch: 44 | Batch_idx: 390 |  Loss: (0.3025) | Acc: (89.00%) (44845/50000)
# TEST : Loss: (0.3880) | Acc: (87.00%) (8713/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[ 9.5470e-42, -2.5993e-41, -3.8723e-41],
          [ 7.5345e-41,  5.6114e-41,  4.5105e-41],
          [ 4.7113e-41,  3.6961e-41, -4.1801e-41]],

         [[ 2.6302e-42,  3.9138e-42,  6.7792e-41],
          [ 3.1327e-41,  6.5624e-41, -2.9495e-41],
          [ 7.3260e-42,  5.3810e-41,  7.9943e-41]],

         [[ 5.5985e-41,  6.8743e-41, -1.1294e-42],
          [-3.1180e-41, -5.6324e-41,  5.4468e-41],
          [-2.7765e-41,  2.8002e-41,  7.3420e-41]]],


        [[[ 1.0215e-01, -4.1329e-02,  8.9331e-02],
          [ 1.7779e-02, -2.3855e-01, -2.7313e-02],
          [ 7.8007e-02, -3.9337e-03,  5.4974e-02]],

         [[ 3.7210e-02, -8.8288e-02, -2.2915e-03],
          [-6.8430e-02, -2.6445e-01, -7.4232e-02],
          [ 1.6739e-02, -1.5811e-02,  5.8329e-02]],

         [[ 4.9385e-02, -1.9256e-02,  8.2590e-02],
          [ 3.0731e-02, -1.5045e-01, -8.6869e-03],
          [ 1.7925e-02, -2.8882e-02, -5.2048e-03]]],


        [[[-8.1158e-03, -9.9847e-03, -3.3892e-03],
          [-1.2479e-02, -1.5244e-02, -6.6006e-03],
          [-1.4077e-02, -1.7277e-02, -1.4181e-02]],

         [[-5.9242e-03, -7.8851e-03, -1.5764e-03],
          [-1.4173e-02, -1.7968e-02, -9.7918e-03],
          [-1.4275e-02, -2.1237e-02, -8.6256e-03]],

         [[-2.0204e-02, -1.3429e-02, -3.5051e-03],
          [-3.1229e-02, -3.2937e-02, -1.1957e-02],
          [-3.3111e-02, -3.2132e-02, -1.8006e-02]]],


        ...,


        [[[-1.1761e-01,  6.6095e-02, -1.6652e-01],
          [-2.4048e-01, -1.2804e-01, -1.8278e-01],
          [-1.5493e-01,  2.2479e-02, -2.7359e-01]],

         [[ 5.7962e-02,  3.8018e-02,  5.7302e-03],
          [ 1.1463e-01, -1.2326e-01,  6.5348e-02],
          [ 1.4089e-02,  1.1394e-01, -1.6789e-01]],

         [[-9.6440e-02,  2.6523e-01,  8.2447e-02],
          [ 2.5447e-01,  2.6637e-01,  2.2051e-01],
          [ 1.6248e-01,  1.7679e-01, -3.1327e-02]]],


        [[[ 1.0538e-01, -8.2247e-02,  8.7231e-02],
          [ 4.5860e-02, -1.6461e-01,  7.2702e-02],
          [ 1.3920e-01, -9.5069e-02,  3.7910e-02]],

         [[ 1.3940e-01, -1.2629e-01,  1.2321e-01],
          [-1.1207e-01, -1.2099e-01, -3.0135e-02],
          [ 8.9590e-02,  1.0084e-01,  2.5825e-02]],

         [[-3.8354e-02, -1.1670e-01,  6.9042e-02],
          [-1.2352e-01, -3.1645e-01, -1.5068e-01],
          [ 2.6405e-02, -1.0586e-01, -1.7023e-01]]],


        [[[-3.8966e-03, -2.7986e-03, -3.0585e-03],
          [-2.9999e-03, -1.2935e-03, -6.5086e-04],
          [-1.8842e-03, -6.0690e-04,  2.5619e-04]],

         [[-9.7273e-04, -1.3749e-04, -6.5092e-04],
          [-6.5610e-05,  9.0154e-04,  4.8374e-04],
          [ 4.9258e-05,  5.1841e-04,  5.0038e-04]],

         [[-3.7975e-03, -2.2256e-03, -2.4110e-03],
          [-2.9166e-03, -1.5277e-03, -1.4684e-03],
          [-2.7353e-03, -1.5661e-03, -1.7752e-03]]]],
       device='cuda:0', requires_grad=True)

conv1_weight_grad tensor([[[[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]]],


        [[[-0.0020,  0.0001,  0.0010],
          [-0.0019, -0.0003, -0.0005],
          [-0.0012, -0.0003, -0.0029]],

         [[-0.0023, -0.0006,  0.0003],
          [-0.0021, -0.0009, -0.0010],
          [-0.0015, -0.0009, -0.0036]],

         [[-0.0019, -0.0007,  0.0005],
          [-0.0020, -0.0012, -0.0009],
          [-0.0010, -0.0006, -0.0026]]],


        [[[ 0.0001,  0.0000,  0.0001],
          [ 0.0000, -0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0001],
          [ 0.0000, -0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000, -0.0000,  0.0000],
          [-0.0000, -0.0000, -0.0000],
          [-0.0000, -0.0000,  0.0000]]],


        ...,


        [[[ 0.0302,  0.0331,  0.0326],
          [ 0.0426,  0.0405,  0.0352],
          [ 0.0354,  0.0299,  0.0263]],

         [[ 0.0186,  0.0211,  0.0230],
          [ 0.0307,  0.0283,  0.0252],
          [ 0.0287,  0.0222,  0.0201]],

         [[ 0.0194,  0.0252,  0.0264],
          [ 0.0296,  0.0311,  0.0273],
          [ 0.0284,  0.0264,  0.0241]]],


        [[[-0.0269, -0.0180, -0.0150],
          [-0.0253, -0.0177, -0.0179],
          [-0.0224, -0.0174, -0.0198]],

         [[-0.0251, -0.0161, -0.0130],
          [-0.0227, -0.0151, -0.0153],
          [-0.0201, -0.0154, -0.0182]],

         [[-0.0139, -0.0062, -0.0032],
          [-0.0127, -0.0053, -0.0048],
          [-0.0102, -0.0049, -0.0064]]],


        [[[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]]]], device='cuda:0')

percentage_weight tensor([0.], device='cuda:0')

percentage_weight_grad tensor([-61.8191], device='cuda:0')

False Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True _Gate(
  (sig): Sigmoid()
)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True _Gate(
  (sig): Sigmoid()
)
False Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True _Gate(
  (sig): Sigmoid()
)
False Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True _Gate(
  (sig): Sigmoid()
)
False Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True _Gate(
  (sig): Sigmoid()
)
False Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True _Gate(
  (sig): Sigmoid()
)
False Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True _Gate(
  (sig): Sigmoid()
)
False Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True _Gate(
  (sig): Sigmoid()
)
False Linear(in_features=512, out_features=10, bias=True)
Epoch: 45 | Batch_idx: 0 |  Loss: (0.2863) | Acc: (87.00%) (112/128)
Epoch: 45 | Batch_idx: 10 |  Loss: (0.3096) | Acc: (88.00%) (1246/1408)
Epoch: 45 | Batch_idx: 20 |  Loss: (0.3171) | Acc: (88.00%) (2378/2688)
Epoch: 45 | Batch_idx: 30 |  Loss: (0.3444) | Acc: (87.00%) (3483/3968)
Epoch: 45 | Batch_idx: 40 |  Loss: (0.3449) | Acc: (87.00%) (4605/5248)
Epoch: 45 | Batch_idx: 50 |  Loss: (0.3417) | Acc: (88.00%) (5748/6528)
Epoch: 45 | Batch_idx: 60 |  Loss: (0.3357) | Acc: (88.00%) (6877/7808)
Epoch: 45 | Batch_idx: 70 |  Loss: (0.3335) | Acc: (88.00%) (8018/9088)
Epoch: 45 | Batch_idx: 80 |  Loss: (0.3315) | Acc: (88.00%) (9173/10368)
Epoch: 45 | Batch_idx: 90 |  Loss: (0.3306) | Acc: (88.00%) (10319/11648)
Epoch: 45 | Batch_idx: 100 |  Loss: (0.3297) | Acc: (88.00%) (11461/12928)
Epoch: 45 | Batch_idx: 110 |  Loss: (0.3297) | Acc: (88.00%) (12605/14208)
Epoch: 45 | Batch_idx: 120 |  Loss: (0.3289) | Acc: (88.00%) (13734/15488)
Epoch: 45 | Batch_idx: 130 |  Loss: (0.3268) | Acc: (88.00%) (14875/16768)
Epoch: 45 | Batch_idx: 140 |  Loss: (0.3242) | Acc: (88.00%) (16032/18048)
Epoch: 45 | Batch_idx: 150 |  Loss: (0.3224) | Acc: (88.00%) (17170/19328)
Epoch: 45 | Batch_idx: 160 |  Loss: (0.3203) | Acc: (88.00%) (18330/20608)
Epoch: 45 | Batch_idx: 170 |  Loss: (0.3155) | Acc: (89.00%) (19515/21888)
Epoch: 45 | Batch_idx: 180 |  Loss: (0.3158) | Acc: (89.00%) (20657/23168)
Epoch: 45 | Batch_idx: 190 |  Loss: (0.3143) | Acc: (89.00%) (21812/24448)
Epoch: 45 | Batch_idx: 200 |  Loss: (0.3128) | Acc: (89.00%) (22961/25728)
Epoch: 45 | Batch_idx: 210 |  Loss: (0.3100) | Acc: (89.00%) (24130/27008)
Epoch: 45 | Batch_idx: 220 |  Loss: (0.3100) | Acc: (89.00%) (25278/28288)
Epoch: 45 | Batch_idx: 230 |  Loss: (0.3081) | Acc: (89.00%) (26436/29568)
Epoch: 45 | Batch_idx: 240 |  Loss: (0.3057) | Acc: (89.00%) (27613/30848)
Epoch: 45 | Batch_idx: 250 |  Loss: (0.3037) | Acc: (89.00%) (28788/32128)
Epoch: 45 | Batch_idx: 260 |  Loss: (0.3029) | Acc: (89.00%) (29944/33408)
Epoch: 45 | Batch_idx: 270 |  Loss: (0.3022) | Acc: (89.00%) (31097/34688)
Epoch: 45 | Batch_idx: 280 |  Loss: (0.3017) | Acc: (89.00%) (32238/35968)
Epoch: 45 | Batch_idx: 290 |  Loss: (0.3011) | Acc: (89.00%) (33392/37248)
Epoch: 45 | Batch_idx: 300 |  Loss: (0.3010) | Acc: (89.00%) (34538/38528)
Epoch: 45 | Batch_idx: 310 |  Loss: (0.2997) | Acc: (89.00%) (35705/39808)
Epoch: 45 | Batch_idx: 320 |  Loss: (0.2987) | Acc: (89.00%) (36865/41088)
Epoch: 45 | Batch_idx: 330 |  Loss: (0.2977) | Acc: (89.00%) (38022/42368)
Epoch: 45 | Batch_idx: 340 |  Loss: (0.2968) | Acc: (89.00%) (39193/43648)
Epoch: 45 | Batch_idx: 350 |  Loss: (0.2958) | Acc: (89.00%) (40361/44928)
Epoch: 45 | Batch_idx: 360 |  Loss: (0.2953) | Acc: (89.00%) (41521/46208)
Epoch: 45 | Batch_idx: 370 |  Loss: (0.2950) | Acc: (89.00%) (42681/47488)
Epoch: 45 | Batch_idx: 380 |  Loss: (0.2947) | Acc: (89.00%) (43837/48768)
Epoch: 45 | Batch_idx: 390 |  Loss: (0.2934) | Acc: (89.00%) (44968/50000)
# TEST : Loss: (0.3541) | Acc: (88.00%) (8816/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-1.9760e-41, -3.8581e-41,  5.1824e-41],
          [ 6.6713e-41,  4.8129e-41, -3.6980e-41],
          [-7.4204e-41,  7.5188e-41, -8.0102e-41]],

         [[ 5.1004e-41,  4.1780e-41, -4.5178e-42],
          [-4.1665e-41,  7.0878e-41,  1.0151e-41],
          [ 9.7054e-42, -6.4555e-41,  5.8071e-41]],

         [[ 5.2168e-41, -9.1281e-42, -8.4708e-42],
          [ 7.6200e-41, -7.8687e-41,  1.8933e-41],
          [-7.2268e-41, -4.2279e-41, -3.1599e-41]]],


        [[[ 1.0019e-01, -4.1456e-02,  8.5639e-02],
          [ 1.9010e-02, -2.2816e-01, -2.6887e-02],
          [ 7.8703e-02, -2.1847e-03,  5.6310e-02]],

         [[ 3.6388e-02, -8.6524e-02, -3.4080e-03],
          [-6.5139e-02, -2.4781e-01, -7.1598e-02],
          [ 1.8384e-02, -1.3625e-02,  5.9933e-02]],

         [[ 4.8572e-02, -1.8617e-02,  8.0346e-02],
          [ 3.1777e-02, -1.3973e-01, -7.0094e-03],
          [ 1.9136e-02, -2.6385e-02, -1.9573e-03]]],


        [[[-6.6780e-03, -8.1388e-03, -2.8612e-03],
          [-1.0587e-02, -1.2874e-02, -5.3972e-03],
          [-1.1906e-02, -1.4522e-02, -1.0966e-02]],

         [[-4.3409e-03, -5.4581e-03, -1.2150e-03],
          [-1.1252e-02, -1.4183e-02, -6.9297e-03],
          [-1.1437e-02, -1.7010e-02, -6.1719e-03]],

         [[-1.3749e-02, -7.9987e-03, -1.9110e-03],
          [-2.3715e-02, -2.4121e-02, -6.9341e-03],
          [-2.5740e-02, -2.4531e-02, -1.1314e-02]]],


        ...,


        [[[-1.1892e-01,  6.3701e-02, -1.6846e-01],
          [-2.4130e-01, -1.2920e-01, -1.8358e-01],
          [-1.5588e-01,  2.1557e-02, -2.7316e-01]],

         [[ 5.7072e-02,  3.6906e-02,  4.7809e-03],
          [ 1.1361e-01, -1.2348e-01,  6.4917e-02],
          [ 1.3353e-02,  1.1350e-01, -1.6701e-01]],

         [[-9.7362e-02,  2.6305e-01,  8.0832e-02],
          [ 2.5272e-01,  2.6488e-01,  2.1935e-01],
          [ 1.6129e-01,  1.7607e-01, -3.0945e-02]]],


        [[[ 1.0691e-01, -8.0491e-02,  8.7959e-02],
          [ 4.8608e-02, -1.6071e-01,  7.5233e-02],
          [ 1.4077e-01, -9.2185e-02,  4.1178e-02]],

         [[ 1.4242e-01, -1.2102e-01,  1.2636e-01],
          [-1.0541e-01, -1.1242e-01, -2.2618e-02],
          [ 9.3125e-02,  1.0479e-01,  3.2094e-02]],

         [[-3.6126e-02, -1.1433e-01,  6.8781e-02],
          [-1.1909e-01, -3.0235e-01, -1.4634e-01],
          [ 2.7243e-02, -1.0423e-01, -1.6641e-01]]],


        [[[-2.1601e-03, -1.4778e-03, -1.5400e-03],
          [-1.6082e-03, -6.2199e-04, -2.7310e-04],
          [-9.9175e-04, -2.7765e-04,  1.0107e-04]],

         [[-3.7620e-04, -5.0469e-05, -2.1231e-04],
          [-2.5893e-05,  3.3356e-04,  1.6011e-04],
          [ 1.8645e-05,  1.7236e-04,  1.6093e-04]],

         [[-1.7858e-03, -9.2863e-04, -1.0103e-03],
          [-1.2643e-03, -6.1051e-04, -6.0137e-04],
          [-1.2851e-03, -7.0870e-04, -8.7427e-04]]]], device='cuda:0')

conv1_weight_grad tensor([[[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        ...,


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]]], device='cuda:0')

percentage_weight tensor([0.], device='cuda:0', requires_grad=True)

percentage_weight_grad tensor([-64.8509], device='cuda:0')

Epoch: 46 | Batch_idx: 0 |  Loss: (0.2476) | Acc: (92.00%) (119/128)
Epoch: 46 | Batch_idx: 10 |  Loss: (0.2572) | Acc: (92.00%) (1296/1408)
Epoch: 46 | Batch_idx: 20 |  Loss: (0.2771) | Acc: (91.00%) (2450/2688)
Epoch: 46 | Batch_idx: 30 |  Loss: (0.2684) | Acc: (91.00%) (3617/3968)
Epoch: 46 | Batch_idx: 40 |  Loss: (0.2752) | Acc: (90.00%) (4774/5248)
Epoch: 46 | Batch_idx: 50 |  Loss: (0.2746) | Acc: (91.00%) (5942/6528)
Epoch: 46 | Batch_idx: 60 |  Loss: (0.2719) | Acc: (91.00%) (7109/7808)
Epoch: 46 | Batch_idx: 70 |  Loss: (0.2681) | Acc: (91.00%) (8282/9088)
Epoch: 46 | Batch_idx: 80 |  Loss: (0.2679) | Acc: (91.00%) (9451/10368)
Epoch: 46 | Batch_idx: 90 |  Loss: (0.2701) | Acc: (91.00%) (10604/11648)
Epoch: 46 | Batch_idx: 100 |  Loss: (0.2682) | Acc: (91.00%) (11779/12928)
Epoch: 46 | Batch_idx: 110 |  Loss: (0.2665) | Acc: (91.00%) (12946/14208)
Epoch: 46 | Batch_idx: 120 |  Loss: (0.2677) | Acc: (91.00%) (14102/15488)
Epoch: 46 | Batch_idx: 130 |  Loss: (0.2655) | Acc: (91.00%) (15293/16768)
Epoch: 46 | Batch_idx: 140 |  Loss: (0.2658) | Acc: (91.00%) (16465/18048)
Epoch: 46 | Batch_idx: 150 |  Loss: (0.2660) | Acc: (91.00%) (17626/19328)
Epoch: 46 | Batch_idx: 160 |  Loss: (0.2655) | Acc: (91.00%) (18792/20608)
Epoch: 46 | Batch_idx: 170 |  Loss: (0.2649) | Acc: (91.00%) (19969/21888)
Epoch: 46 | Batch_idx: 180 |  Loss: (0.2653) | Acc: (91.00%) (21134/23168)
Epoch: 46 | Batch_idx: 190 |  Loss: (0.2648) | Acc: (91.00%) (22298/24448)
Epoch: 46 | Batch_idx: 200 |  Loss: (0.2646) | Acc: (91.00%) (23473/25728)
Epoch: 46 | Batch_idx: 210 |  Loss: (0.2653) | Acc: (91.00%) (24628/27008)
Epoch: 46 | Batch_idx: 220 |  Loss: (0.2644) | Acc: (91.00%) (25796/28288)
Epoch: 46 | Batch_idx: 230 |  Loss: (0.2636) | Acc: (91.00%) (26970/29568)
Epoch: 46 | Batch_idx: 240 |  Loss: (0.2629) | Acc: (91.00%) (28138/30848)
Epoch: 46 | Batch_idx: 250 |  Loss: (0.2640) | Acc: (91.00%) (29282/32128)
Epoch: 46 | Batch_idx: 260 |  Loss: (0.2640) | Acc: (91.00%) (30438/33408)
Epoch: 46 | Batch_idx: 270 |  Loss: (0.2636) | Acc: (91.00%) (31594/34688)
Epoch: 46 | Batch_idx: 280 |  Loss: (0.2633) | Acc: (91.00%) (32767/35968)
Epoch: 46 | Batch_idx: 290 |  Loss: (0.2643) | Acc: (91.00%) (33928/37248)
Epoch: 46 | Batch_idx: 300 |  Loss: (0.2648) | Acc: (91.00%) (35090/38528)
Epoch: 46 | Batch_idx: 310 |  Loss: (0.2640) | Acc: (91.00%) (36260/39808)
Epoch: 46 | Batch_idx: 320 |  Loss: (0.2641) | Acc: (91.00%) (37429/41088)
Epoch: 46 | Batch_idx: 330 |  Loss: (0.2641) | Acc: (91.00%) (38597/42368)
Epoch: 46 | Batch_idx: 340 |  Loss: (0.2654) | Acc: (91.00%) (39757/43648)
Epoch: 46 | Batch_idx: 350 |  Loss: (0.2661) | Acc: (91.00%) (40911/44928)
Epoch: 46 | Batch_idx: 360 |  Loss: (0.2652) | Acc: (91.00%) (42096/46208)
Epoch: 46 | Batch_idx: 370 |  Loss: (0.2654) | Acc: (91.00%) (43254/47488)
Epoch: 46 | Batch_idx: 380 |  Loss: (0.2655) | Acc: (91.00%) (44418/48768)
Epoch: 46 | Batch_idx: 390 |  Loss: (0.2653) | Acc: (91.00%) (45548/50000)
# TEST : Loss: (0.3436) | Acc: (88.00%) (8818/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[ 3.2577e-41, -5.5318e-41,  1.5486e-41],
          [ 7.0306e-41,  1.5374e-41,  3.8384e-41],
          [ 3.2712e-41,  4.5048e-41, -8.4570e-41]],

         [[ 5.6896e-41,  6.9783e-41, -8.2799e-41],
          [-7.2362e-41,  7.7469e-41,  1.3007e-41],
          [-1.9586e-41,  1.6633e-41, -2.6877e-42]],

         [[-2.5271e-41, -7.6517e-41, -1.8901e-41],
          [-1.7082e-42, -7.1734e-41, -7.1056e-41],
          [-7.1407e-41,  2.2665e-41,  2.7160e-41]]],


        [[[ 9.7858e-02, -4.0237e-02,  8.3492e-02],
          [ 1.8504e-02, -2.1635e-01, -2.6061e-02],
          [ 7.6938e-02, -2.1259e-03,  5.4924e-02]],

         [[ 3.5494e-02, -8.3752e-02, -3.3180e-03],
          [-6.3242e-02, -2.3033e-01, -6.9200e-02],
          [ 1.7951e-02, -1.3233e-02,  5.8402e-02]],

         [[ 4.7227e-02, -1.7937e-02,  7.7940e-02],
          [ 3.0739e-02, -1.2968e-01, -6.7448e-03],
          [ 1.8631e-02, -2.5534e-02, -1.9012e-03]]],


        [[[-5.1638e-03, -6.2710e-03, -2.1974e-03],
          [-8.6421e-03, -1.0495e-02, -4.1850e-03],
          [-9.6514e-03, -1.1736e-02, -7.9345e-03]],

         [[-2.8556e-03, -3.4066e-03, -7.0558e-04],
          [-8.4683e-03, -1.0653e-02, -4.4976e-03],
          [-8.6666e-03, -1.2961e-02, -4.0097e-03]],

         [[-8.5876e-03, -4.2673e-03, -8.6690e-04],
          [-1.7021e-02, -1.6609e-02, -3.6101e-03],
          [-1.8966e-02, -1.7720e-02, -6.4236e-03]]],


        ...,


        [[[-1.1857e-01,  6.3516e-02, -1.6798e-01],
          [-2.4060e-01, -1.2883e-01, -1.8306e-01],
          [-1.5543e-01,  2.1496e-02, -2.7238e-01]],

         [[ 5.6897e-02,  3.6793e-02,  4.7665e-03],
          [ 1.1327e-01, -1.2311e-01,  6.4725e-02],
          [ 1.3313e-02,  1.1317e-01, -1.6653e-01]],

         [[-9.7018e-02,  2.6212e-01,  8.0554e-02],
          [ 2.5183e-01,  2.6396e-01,  2.1861e-01],
          [ 1.6074e-01,  1.7548e-01, -3.0844e-02]]],


        [[[ 1.0613e-01, -7.9843e-02,  8.7292e-02],
          [ 4.8216e-02, -1.5917e-01,  7.4579e-02],
          [ 1.3975e-01, -9.1432e-02,  4.0856e-02]],

         [[ 1.4117e-01, -1.1975e-01,  1.2519e-01],
          [-1.0431e-01, -1.1080e-01, -2.2352e-02],
          [ 9.2321e-02,  1.0370e-01,  3.1787e-02]],

         [[-3.5691e-02, -1.1247e-01,  6.7891e-02],
          [-1.1719e-01, -2.8886e-01, -1.4322e-01],
          [ 2.6923e-02, -1.0248e-01, -1.6406e-01]]],


        [[[-1.0518e-03, -6.7797e-04, -6.6648e-04],
          [-7.5156e-04, -2.5443e-04, -9.4518e-05],
          [-4.5319e-04, -1.0684e-04,  3.2425e-05]],

         [[-1.1778e-04, -1.4819e-05, -5.3902e-05],
          [-8.3110e-06,  9.8902e-05,  4.1392e-05],
          [ 5.6851e-06,  4.4807e-05,  4.0157e-05]],

         [[-7.1083e-04, -3.1917e-04, -3.4909e-04],
          [-4.5541e-04, -1.9900e-04, -2.0202e-04],
          [-5.1091e-04, -2.6909e-04, -3.6826e-04]]]], device='cuda:0')

conv1_weight_grad tensor([[[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        ...,


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]],


        [[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]],

         [[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]]], device='cuda:0')

percentage_weight tensor([0.], device='cuda:0', requires_grad=True)

percentage_weight_grad tensor([-65.5951], device='cuda:0')

True Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False _Gate(
  (sig): Sigmoid()
)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False _Gate(
  (sig): Sigmoid()
)
True Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False _Gate(
  (sig): Sigmoid()
)
True Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False _Gate(
  (sig): Sigmoid()
)
True Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False _Gate(
  (sig): Sigmoid()
)
True Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False _Gate(
  (sig): Sigmoid()
)
True Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False _Gate(
  (sig): Sigmoid()
)
True Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
True BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False _Gate(
  (sig): Sigmoid()
)
True Linear(in_features=512, out_features=10, bias=True)
Epoch: 47 | Batch_idx: 0 |  Loss: (0.1865) | Acc: (94.00%) (121/128)
Epoch: 47 | Batch_idx: 10 |  Loss: (0.2403) | Acc: (92.00%) (1300/1408)
Epoch: 47 | Batch_idx: 20 |  Loss: (0.2659) | Acc: (90.00%) (2445/2688)
Epoch: 47 | Batch_idx: 30 |  Loss: (0.2870) | Acc: (90.00%) (3583/3968)
Epoch: 47 | Batch_idx: 40 |  Loss: (0.3083) | Acc: (89.00%) (4704/5248)
Epoch: 47 | Batch_idx: 50 |  Loss: (0.3141) | Acc: (89.00%) (5836/6528)
Epoch: 47 | Batch_idx: 60 |  Loss: (0.3259) | Acc: (89.00%) (6965/7808)
Epoch: 47 | Batch_idx: 70 |  Loss: (0.3358) | Acc: (88.00%) (8073/9088)
Epoch: 47 | Batch_idx: 80 |  Loss: (0.3415) | Acc: (88.00%) (9182/10368)
Epoch: 47 | Batch_idx: 90 |  Loss: (0.3416) | Acc: (88.00%) (10308/11648)
Epoch: 47 | Batch_idx: 100 |  Loss: (0.3454) | Acc: (88.00%) (11430/12928)
Epoch: 47 | Batch_idx: 110 |  Loss: (0.3450) | Acc: (88.00%) (12572/14208)
Epoch: 47 | Batch_idx: 120 |  Loss: (0.3458) | Acc: (88.00%) (13696/15488)
Epoch: 47 | Batch_idx: 130 |  Loss: (0.3482) | Acc: (88.00%) (14807/16768)
Epoch: 47 | Batch_idx: 140 |  Loss: (0.3511) | Acc: (88.00%) (15922/18048)
Epoch: 47 | Batch_idx: 150 |  Loss: (0.3487) | Acc: (88.00%) (17064/19328)
Epoch: 47 | Batch_idx: 160 |  Loss: (0.3487) | Acc: (88.00%) (18204/20608)
Epoch: 47 | Batch_idx: 170 |  Loss: (0.3484) | Acc: (88.00%) (19335/21888)
Epoch: 47 | Batch_idx: 180 |  Loss: (0.3467) | Acc: (88.00%) (20498/23168)
Epoch: 47 | Batch_idx: 190 |  Loss: (0.3460) | Acc: (88.00%) (21630/24448)
Epoch: 47 | Batch_idx: 200 |  Loss: (0.3475) | Acc: (88.00%) (22758/25728)
Epoch: 47 | Batch_idx: 210 |  Loss: (0.3478) | Acc: (88.00%) (23881/27008)
Epoch: 47 | Batch_idx: 220 |  Loss: (0.3463) | Acc: (88.00%) (25028/28288)
Epoch: 47 | Batch_idx: 230 |  Loss: (0.3458) | Acc: (88.00%) (26173/29568)
Epoch: 47 | Batch_idx: 240 |  Loss: (0.3463) | Acc: (88.00%) (27297/30848)
Epoch: 47 | Batch_idx: 250 |  Loss: (0.3467) | Acc: (88.00%) (28423/32128)
Epoch: 47 | Batch_idx: 260 |  Loss: (0.3459) | Acc: (88.00%) (29562/33408)
Epoch: 47 | Batch_idx: 270 |  Loss: (0.3447) | Acc: (88.00%) (30714/34688)
Epoch: 47 | Batch_idx: 280 |  Loss: (0.3446) | Acc: (88.00%) (31851/35968)
Epoch: 47 | Batch_idx: 290 |  Loss: (0.3439) | Acc: (88.00%) (32988/37248)
Epoch: 47 | Batch_idx: 300 |  Loss: (0.3436) | Acc: (88.00%) (34138/38528)
Epoch: 47 | Batch_idx: 310 |  Loss: (0.3441) | Acc: (88.00%) (35259/39808)
Epoch: 47 | Batch_idx: 320 |  Loss: (0.3434) | Acc: (88.00%) (36396/41088)
Epoch: 47 | Batch_idx: 330 |  Loss: (0.3428) | Acc: (88.00%) (37533/42368)
Epoch: 47 | Batch_idx: 340 |  Loss: (0.3422) | Acc: (88.00%) (38683/43648)
Epoch: 47 | Batch_idx: 350 |  Loss: (0.3425) | Acc: (88.00%) (39804/44928)
Epoch: 47 | Batch_idx: 360 |  Loss: (0.3411) | Acc: (88.00%) (40962/46208)
Epoch: 47 | Batch_idx: 370 |  Loss: (0.3402) | Acc: (88.00%) (42101/47488)
Epoch: 47 | Batch_idx: 380 |  Loss: (0.3393) | Acc: (88.00%) (43248/48768)
Epoch: 47 | Batch_idx: 390 |  Loss: (0.3378) | Acc: (88.00%) (44360/50000)
# TEST : Loss: (0.4373) | Acc: (86.00%) (8602/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[-8.8093e-41, -1.5807e-41, -6.8348e-41],
          [-5.1666e-42, -3.7891e-42, -7.9323e-41],
          [ 3.1277e-42, -6.1485e-41, -9.3258e-41]],

         [[ 2.5658e-41,  2.1908e-41, -3.6809e-41],
          [ 4.5709e-41,  1.9891e-41, -8.1649e-41],
          [ 3.2748e-41, -2.9476e-41, -7.5587e-41]],

         [[-4.2536e-41,  1.9150e-41,  7.7450e-42],
          [-4.5027e-41,  4.1605e-42,  1.5442e-41],
          [-3.0638e-41,  5.4973e-42,  1.2805e-41]]],


        [[[ 8.3038e-02, -5.7594e-02,  7.8733e-02],
          [ 1.1370e-02, -2.3653e-01, -2.4317e-02],
          [ 8.0740e-02, -8.8624e-03,  4.7683e-02]],

         [[ 1.7484e-02, -1.0895e-01, -1.9917e-02],
          [-7.0602e-02, -2.6414e-01, -8.0593e-02],
          [ 2.3305e-02, -2.0237e-02,  4.3404e-02]],

         [[ 4.2716e-02, -2.4229e-02,  6.8787e-02],
          [ 3.5125e-02, -1.2292e-01, -6.7026e-03],
          [ 3.2694e-02, -1.5343e-02, -6.7764e-03]]],


        [[[-3.7755e-03, -4.5653e-03, -1.5934e-03],
          [-6.7498e-03, -8.1837e-03, -3.0703e-03],
          [-7.4750e-03, -9.0551e-03, -5.3499e-03]],

         [[-1.7141e-03, -1.9176e-03, -3.6366e-04],
          [-5.9906e-03, -7.5181e-03, -2.6556e-03],
          [-6.1820e-03, -9.3083e-03, -2.3703e-03]],

         [[-4.8384e-03, -1.9825e-03, -3.3016e-04],
          [-1.1365e-02, -1.0542e-02, -1.6278e-03],
          [-1.3076e-02, -1.1923e-02, -3.2208e-03]]],


        ...,


        [[[-1.1415e-01,  5.7434e-02, -1.7426e-01],
          [-2.3681e-01, -1.3046e-01, -1.8432e-01],
          [-1.5731e-01,  2.1921e-02, -2.6628e-01]],

         [[ 5.8844e-02,  3.0020e-02, -1.9693e-03],
          [ 1.1787e-01, -1.2065e-01,  6.6173e-02],
          [ 1.3116e-02,  1.1720e-01, -1.5828e-01]],

         [[-8.8021e-02,  2.6102e-01,  8.0371e-02],
          [ 2.6732e-01,  2.7665e-01,  2.2975e-01],
          [ 1.6981e-01,  1.8871e-01, -1.5083e-02]]],


        [[[ 9.6611e-02, -8.3647e-02,  9.1200e-02],
          [ 3.9850e-02, -1.6705e-01,  6.8586e-02],
          [ 1.3430e-01, -9.9932e-02,  2.9482e-02]],

         [[ 1.2774e-01, -1.2800e-01,  1.2303e-01],
          [-1.1146e-01, -1.2331e-01, -3.5625e-02],
          [ 9.2089e-02,  9.8376e-02,  2.2467e-02]],

         [[-5.6151e-02, -1.1842e-01,  6.6767e-02],
          [-1.4454e-01, -3.2036e-01, -1.6533e-01],
          [ 1.3807e-02, -1.1071e-01, -1.7677e-01]]],


        [[[-4.3691e-04, -2.6180e-04, -2.3959e-04],
          [-2.9686e-04, -8.5342e-05, -2.5814e-05],
          [-1.7415e-04, -3.3246e-05,  8.0667e-06]],

         [[-2.8434e-05, -3.3052e-06, -1.0047e-05],
          [-2.0688e-06,  2.2326e-05,  7.8891e-06],
          [ 1.3284e-06,  8.5990e-06,  7.3264e-06]],

         [[-2.3057e-04, -8.6431e-05, -9.5147e-05],
          [-1.3065e-04, -5.0485e-05, -5.3187e-05],
          [-1.6548e-04, -8.2365e-05, -1.2805e-04]]]],
       device='cuda:0', requires_grad=True)

conv1_weight_grad tensor([[[[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]]],


        [[[ 0.0073,  0.0019,  0.0034],
          [ 0.0064,  0.0023,  0.0050],
          [ 0.0019,  0.0005,  0.0041]],

         [[ 0.0074,  0.0015,  0.0037],
          [ 0.0063,  0.0013,  0.0048],
          [ 0.0018, -0.0006,  0.0037]],

         [[ 0.0067,  0.0013,  0.0031],
          [ 0.0056,  0.0011,  0.0042],
          [ 0.0012, -0.0008,  0.0030]]],


        [[[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]]],


        ...,


        [[[ 0.0179,  0.0165,  0.0292],
          [ 0.0138,  0.0144,  0.0258],
          [ 0.0125,  0.0128,  0.0215]],

         [[ 0.0189,  0.0145,  0.0282],
          [ 0.0131,  0.0114,  0.0245],
          [ 0.0110,  0.0095,  0.0211]],

         [[ 0.0179,  0.0167,  0.0297],
          [ 0.0124,  0.0144,  0.0260],
          [ 0.0107,  0.0130,  0.0232]]],


        [[[ 0.0073,  0.0075,  0.0113],
          [ 0.0047,  0.0035,  0.0093],
          [-0.0053, -0.0040,  0.0021]],

         [[ 0.0004,  0.0009,  0.0071],
          [-0.0010, -0.0026,  0.0050],
          [-0.0095, -0.0077, -0.0001]],

         [[ 0.0041,  0.0036,  0.0088],
          [ 0.0013, -0.0008,  0.0057],
          [-0.0069, -0.0057,  0.0008]]],


        [[[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]]]], device='cuda:0')

percentage_weight tensor([0.], device='cuda:0')

percentage_weight_grad tensor([-65.5951], device='cuda:0')

Epoch: 48 | Batch_idx: 0 |  Loss: (0.2823) | Acc: (91.00%) (117/128)
Epoch: 48 | Batch_idx: 10 |  Loss: (0.2643) | Acc: (91.00%) (1285/1408)
Epoch: 48 | Batch_idx: 20 |  Loss: (0.2790) | Acc: (90.00%) (2428/2688)
Epoch: 48 | Batch_idx: 30 |  Loss: (0.2854) | Acc: (90.00%) (3579/3968)
Epoch: 48 | Batch_idx: 40 |  Loss: (0.2864) | Acc: (90.00%) (4731/5248)
Epoch: 48 | Batch_idx: 50 |  Loss: (0.2845) | Acc: (90.00%) (5890/6528)
Epoch: 48 | Batch_idx: 60 |  Loss: (0.2877) | Acc: (90.00%) (7047/7808)
Epoch: 48 | Batch_idx: 70 |  Loss: (0.2926) | Acc: (90.00%) (8190/9088)
Epoch: 48 | Batch_idx: 80 |  Loss: (0.2956) | Acc: (89.00%) (9328/10368)
Epoch: 48 | Batch_idx: 90 |  Loss: (0.2935) | Acc: (90.00%) (10492/11648)
Epoch: 48 | Batch_idx: 100 |  Loss: (0.2939) | Acc: (90.00%) (11642/12928)
Epoch: 48 | Batch_idx: 110 |  Loss: (0.2940) | Acc: (90.00%) (12797/14208)
Epoch: 48 | Batch_idx: 120 |  Loss: (0.2939) | Acc: (90.00%) (13942/15488)
Epoch: 48 | Batch_idx: 130 |  Loss: (0.2930) | Acc: (90.00%) (15099/16768)
Epoch: 48 | Batch_idx: 140 |  Loss: (0.2937) | Acc: (89.00%) (16237/18048)
Epoch: 48 | Batch_idx: 150 |  Loss: (0.2939) | Acc: (89.00%) (17385/19328)
Epoch: 48 | Batch_idx: 160 |  Loss: (0.2933) | Acc: (89.00%) (18532/20608)
Epoch: 48 | Batch_idx: 170 |  Loss: (0.2943) | Acc: (89.00%) (19671/21888)
Epoch: 48 | Batch_idx: 180 |  Loss: (0.2948) | Acc: (89.00%) (20830/23168)
Epoch: 48 | Batch_idx: 190 |  Loss: (0.2954) | Acc: (89.00%) (21984/24448)
Epoch: 48 | Batch_idx: 200 |  Loss: (0.2944) | Acc: (89.00%) (23143/25728)
Epoch: 48 | Batch_idx: 210 |  Loss: (0.2948) | Acc: (89.00%) (24293/27008)
Epoch: 48 | Batch_idx: 220 |  Loss: (0.2934) | Acc: (89.00%) (25455/28288)
Epoch: 48 | Batch_idx: 230 |  Loss: (0.2946) | Acc: (89.00%) (26591/29568)
Epoch: 48 | Batch_idx: 240 |  Loss: (0.2952) | Acc: (89.00%) (27737/30848)
Epoch: 48 | Batch_idx: 250 |  Loss: (0.2954) | Acc: (89.00%) (28878/32128)
Epoch: 48 | Batch_idx: 260 |  Loss: (0.2960) | Acc: (89.00%) (30017/33408)
Epoch: 48 | Batch_idx: 270 |  Loss: (0.2965) | Acc: (89.00%) (31168/34688)
Epoch: 48 | Batch_idx: 280 |  Loss: (0.2961) | Acc: (89.00%) (32329/35968)
Epoch: 48 | Batch_idx: 290 |  Loss: (0.2962) | Acc: (89.00%) (33472/37248)
Epoch: 48 | Batch_idx: 300 |  Loss: (0.2961) | Acc: (89.00%) (34630/38528)
Epoch: 48 | Batch_idx: 310 |  Loss: (0.2961) | Acc: (89.00%) (35776/39808)
Epoch: 48 | Batch_idx: 320 |  Loss: (0.2962) | Acc: (89.00%) (36923/41088)
Epoch: 48 | Batch_idx: 330 |  Loss: (0.2964) | Acc: (89.00%) (38058/42368)
Epoch: 48 | Batch_idx: 340 |  Loss: (0.2961) | Acc: (89.00%) (39215/43648)
Epoch: 48 | Batch_idx: 350 |  Loss: (0.2965) | Acc: (89.00%) (40369/44928)
Epoch: 48 | Batch_idx: 360 |  Loss: (0.2954) | Acc: (89.00%) (41531/46208)
Epoch: 48 | Batch_idx: 370 |  Loss: (0.2949) | Acc: (89.00%) (42690/47488)
Epoch: 48 | Batch_idx: 380 |  Loss: (0.2949) | Acc: (89.00%) (43854/48768)
Epoch: 48 | Batch_idx: 390 |  Loss: (0.2951) | Acc: (89.00%) (44956/50000)
# TEST : Loss: (0.4016) | Acc: (86.00%) (8682/10000)
conv1 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)

conv1_weight Parameter containing:
tensor([[[[ 6.1657e-42,  6.7369e-41, -8.0132e-41],
          [-8.7162e-41,  7.3609e-41, -7.5676e-41],
          [-3.9204e-41,  2.8699e-42, -2.0165e-42]],

         [[ 7.9811e-41, -2.9929e-41, -8.9585e-42],
          [-7.7162e-41,  4.2260e-41, -2.3075e-41],
          [-7.3720e-41,  5.3510e-41,  9.5922e-41]],

         [[-3.7190e-41,  4.8463e-41,  8.6540e-41],
          [ 2.3826e-41, -2.6444e-41,  3.2957e-41],
          [-2.8089e-41, -9.6073e-41,  7.5908e-42]]],


        [[[ 9.3336e-02, -4.2689e-02,  7.8654e-02],
          [ 6.3315e-03, -2.4701e-01, -3.8310e-02],
          [ 7.4980e-02, -2.0930e-02,  3.8875e-02]],

         [[ 2.5513e-02, -9.8955e-02, -2.3664e-02],
          [-7.7729e-02, -2.7657e-01, -9.4136e-02],
          [ 1.8248e-02, -2.8648e-02,  3.4576e-02]],

         [[ 5.1052e-02, -1.8380e-02,  6.5074e-02],
          [ 2.9301e-02, -1.3584e-01, -1.6982e-02],
          [ 3.4639e-02, -1.5798e-02, -6.0893e-03]]],


        [[[-2.5783e-03, -3.1012e-03, -1.0771e-03],
          [-4.9958e-03, -6.0452e-03, -2.1054e-03],
          [-5.4762e-03, -6.6031e-03, -3.3095e-03]],

         [[-9.1992e-04, -9.5133e-04, -1.6196e-04],
          [-3.9295e-03, -4.9171e-03, -1.3968e-03],
          [-4.0963e-03, -6.2194e-03, -1.2485e-03]],

         [[-2.4030e-03, -7.7742e-04, -1.0144e-04],
          [-6.9465e-03, -6.0571e-03, -6.1534e-04],
          [-8.3113e-03, -7.3575e-03, -1.3868e-03]]],


        ...,


        [[[-1.1345e-01,  5.1827e-02, -1.8432e-01],
          [-2.3687e-01, -1.3489e-01, -1.9258e-01],
          [-1.6321e-01,  1.7195e-02, -2.6658e-01]],

         [[ 6.1577e-02,  2.9069e-02, -8.1373e-03],
          [ 1.1942e-01, -1.1938e-01,  6.1342e-02],
          [ 6.8289e-03,  1.1553e-01, -1.5761e-01]],

         [[-8.0051e-02,  2.6376e-01,  7.5778e-02],
          [ 2.7330e-01,  2.8297e-01,  2.2926e-01],
          [ 1.6184e-01,  1.8871e-01, -1.2296e-02]]],


        [[[ 1.1416e-01, -7.1877e-02,  9.5460e-02],
          [ 4.4541e-02, -1.7071e-01,  5.8408e-02],
          [ 1.3301e-01, -1.0412e-01,  2.2899e-02]],

         [[ 1.3634e-01, -1.2705e-01,  1.1290e-01],
          [-1.2033e-01, -1.4540e-01, -5.9748e-02],
          [ 7.8348e-02,  8.1315e-02,  8.2903e-03]],

         [[-3.1635e-02, -1.0678e-01,  6.6691e-02],
          [-1.3770e-01, -3.4133e-01, -1.8219e-01],
          [ 1.5527e-02, -1.1625e-01, -1.8026e-01]]],


        [[[-1.4935e-04, -8.1812e-05, -6.8566e-05],
          [-9.5390e-05, -2.2428e-05, -5.2654e-06],
          [-5.4096e-05, -7.9654e-06,  1.4662e-06]],

         [[-4.9797e-06, -5.2486e-07, -1.2771e-06],
          [-3.7630e-07,  3.5985e-06,  1.0310e-06],
          [ 2.2345e-07,  1.1334e-06,  9.0694e-07]],

         [[-5.8140e-05, -1.7445e-05, -1.9359e-05],
          [-2.8317e-05, -9.4010e-06, -1.0369e-05],
          [-4.1653e-05, -1.9337e-05, -3.5175e-05]]]],
       device='cuda:0', requires_grad=True)

conv1_weight_grad tensor([[[[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]]],


        [[[ 0.0091,  0.0038,  0.0090],
          [ 0.0083,  0.0033,  0.0088],
          [ 0.0081,  0.0043,  0.0091]],

         [[ 0.0079,  0.0033,  0.0091],
          [ 0.0069,  0.0023,  0.0084],
          [ 0.0068,  0.0032,  0.0082]],

         [[ 0.0060,  0.0025,  0.0086],
          [ 0.0052,  0.0015,  0.0076],
          [ 0.0052,  0.0023,  0.0074]]],


        [[[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]]],


        ...,


        [[[-0.0456, -0.0518, -0.0542],
          [-0.0353, -0.0434, -0.0457],
          [-0.0221, -0.0314, -0.0358]],

         [[-0.0371, -0.0475, -0.0518],
          [-0.0313, -0.0418, -0.0435],
          [-0.0203, -0.0305, -0.0324]],

         [[-0.0289, -0.0402, -0.0445],
          [-0.0251, -0.0373, -0.0392],
          [-0.0150, -0.0265, -0.0285]]],


        [[[ 0.0361,  0.0287,  0.0365],
          [ 0.0297,  0.0229,  0.0296],
          [ 0.0327,  0.0258,  0.0327]],

         [[ 0.0252,  0.0191,  0.0269],
          [ 0.0198,  0.0133,  0.0196],
          [ 0.0245,  0.0169,  0.0229]],

         [[ 0.0157,  0.0101,  0.0170],
          [ 0.0114,  0.0057,  0.0106],
          [ 0.0155,  0.0096,  0.0142]]],


        [[[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]]]], device='cuda:0')

percentage_weight tensor([0.], device='cuda:0')

percentage_weight_grad tensor([-65.5951], device='cuda:0')

False Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True _Gate(
  (sig): Sigmoid()
)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True _Gate(
  (sig): Sigmoid()
)
False Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True _Gate(
  (sig): Sigmoid()
)
False Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True _Gate(
  (sig): Sigmoid()
)
False Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True _Gate(
  (sig): Sigmoid()
)
False Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True _Gate(
  (sig): Sigmoid()
)
False Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True _Gate(
  (sig): Sigmoid()
)
False Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
False Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
False BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
True _Gate(
  (sig): Sigmoid()
)
False Linear(in_features=512, out_features=10, bias=True)
Epoch: 49 | Batch_idx: 0 |  Loss: (0.1897) | Acc: (92.00%) (118/128)
Epoch: 49 | Batch_idx: 10 |  Loss: (0.2926) | Acc: (89.00%) (1260/1408)
Epoch: 49 | Batch_idx: 20 |  Loss: (0.3001) | Acc: (89.00%) (2400/2688)
Epoch: 49 | Batch_idx: 30 |  Loss: (0.3210) | Acc: (88.00%) (3519/3968)
Epoch: 49 | Batch_idx: 40 |  Loss: (0.3274) | Acc: (88.00%) (4641/5248)
Epoch: 49 | Batch_idx: 50 |  Loss: (0.3280) | Acc: (88.00%) (5783/6528)
Epoch: 49 | Batch_idx: 60 |  Loss: (0.3189) | Acc: (88.00%) (6945/7808)